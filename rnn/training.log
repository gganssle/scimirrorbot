tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 446, val: 24, test: 0	
vocab size: 115	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 272371	
cloning rnn	
cloning criterion	
1/22300 (epoch 0.002), train_loss = 4.74828607, grad/param norm = 6.2527e-01, time/batch = 0.7388s	
2/22300 (epoch 0.004), train_loss = 4.47497836, grad/param norm = 1.4988e+00, time/batch = 0.6946s	
3/22300 (epoch 0.007), train_loss = 3.58212660, grad/param norm = 1.6268e+00, time/batch = 0.6904s	
4/22300 (epoch 0.009), train_loss = 3.23325036, grad/param norm = 1.2707e+00, time/batch = 0.6840s	
5/22300 (epoch 0.011), train_loss = 3.31798576, grad/param norm = 1.2306e+00, time/batch = 0.6895s	
6/22300 (epoch 0.013), train_loss = 3.21948481, grad/param norm = 8.7154e-01, time/batch = 0.6867s	
7/22300 (epoch 0.016), train_loss = 3.22112832, grad/param norm = 8.4852e-01, time/batch = 0.6962s	
8/22300 (epoch 0.018), train_loss = 3.16365812, grad/param norm = 7.4144e-01, time/batch = 0.6870s	
9/22300 (epoch 0.020), train_loss = 3.26607177, grad/param norm = 9.1796e-01, time/batch = 0.6861s	
10/22300 (epoch 0.022), train_loss = 3.14653440, grad/param norm = 6.9969e-01, time/batch = 0.6875s	
11/22300 (epoch 0.025), train_loss = 3.18906299, grad/param norm = 7.3943e-01, time/batch = 0.6857s	
12/22300 (epoch 0.027), train_loss = 3.19601957, grad/param norm = 6.7901e-01, time/batch = 0.6879s	
13/22300 (epoch 0.029), train_loss = 3.14278627, grad/param norm = 5.8503e-01, time/batch = 0.6946s	
14/22300 (epoch 0.031), train_loss = 3.22832255, grad/param norm = 5.4537e-01, time/batch = 0.6890s	
15/22300 (epoch 0.034), train_loss = 3.11516106, grad/param norm = 6.8560e-01, time/batch = 0.6881s	
16/22300 (epoch 0.036), train_loss = 3.13837181, grad/param norm = 7.7561e-01, time/batch = 0.6883s	
17/22300 (epoch 0.038), train_loss = 3.13990272, grad/param norm = 6.9816e-01, time/batch = 0.6856s	
18/22300 (epoch 0.040), train_loss = 3.15155249, grad/param norm = 7.2661e-01, time/batch = 0.6942s	
19/22300 (epoch 0.043), train_loss = 3.28288092, grad/param norm = 9.3470e-01, time/batch = 0.7030s	
20/22300 (epoch 0.045), train_loss = 3.23218917, grad/param norm = 6.3276e-01, time/batch = 0.6973s	
21/22300 (epoch 0.047), train_loss = 3.20331705, grad/param norm = 4.4192e-01, time/batch = 0.6961s	
22/22300 (epoch 0.049), train_loss = 3.14410006, grad/param norm = 6.6540e-01, time/batch = 0.6898s	
23/22300 (epoch 0.052), train_loss = 3.14293249, grad/param norm = 7.8673e-01, time/batch = 0.6901s	
24/22300 (epoch 0.054), train_loss = 3.06964803, grad/param norm = 4.9507e-01, time/batch = 0.6907s	
25/22300 (epoch 0.056), train_loss = 3.24412424, grad/param norm = 6.5027e-01, time/batch = 0.6894s	
26/22300 (epoch 0.058), train_loss = 3.09930592, grad/param norm = 8.2821e-01, time/batch = 0.6894s	
27/22300 (epoch 0.061), train_loss = 3.08467310, grad/param norm = 5.8948e-01, time/batch = 0.6877s	
28/22300 (epoch 0.063), train_loss = 3.17537625, grad/param norm = 7.7980e-01, time/batch = 0.6891s	
29/22300 (epoch 0.065), train_loss = 3.12639091, grad/param norm = 5.7153e-01, time/batch = 0.6886s	
30/22300 (epoch 0.067), train_loss = 3.20532525, grad/param norm = 6.2486e-01, time/batch = 0.6965s	
31/22300 (epoch 0.070), train_loss = 3.23436652, grad/param norm = 7.7839e-01, time/batch = 0.6943s	
32/22300 (epoch 0.072), train_loss = 3.05841329, grad/param norm = 5.6919e-01, time/batch = 0.6886s	
33/22300 (epoch 0.074), train_loss = 3.21837412, grad/param norm = 6.4552e-01, time/batch = 0.6882s	
34/22300 (epoch 0.076), train_loss = 3.21701838, grad/param norm = 5.4121e-01, time/batch = 0.6889s	
35/22300 (epoch 0.078), train_loss = 3.13701762, grad/param norm = 6.2362e-01, time/batch = 0.6894s	
36/22300 (epoch 0.081), train_loss = 3.23395962, grad/param norm = 7.6405e-01, time/batch = 0.6860s	
37/22300 (epoch 0.083), train_loss = 3.23184641, grad/param norm = 7.3695e-01, time/batch = 0.6931s	
38/22300 (epoch 0.085), train_loss = 3.20714927, grad/param norm = 5.9856e-01, time/batch = 0.6864s	
39/22300 (epoch 0.087), train_loss = 3.29490343, grad/param norm = 5.2989e-01, time/batch = 0.6862s	
40/22300 (epoch 0.090), train_loss = 3.24110210, grad/param norm = 5.6013e-01, time/batch = 0.6859s	
41/22300 (epoch 0.092), train_loss = 3.25716752, grad/param norm = 6.2429e-01, time/batch = 0.6905s	
42/22300 (epoch 0.094), train_loss = 3.22430966, grad/param norm = 7.9481e-01, time/batch = 0.6919s	
43/22300 (epoch 0.096), train_loss = 3.22826704, grad/param norm = 6.7878e-01, time/batch = 0.6889s	
44/22300 (epoch 0.099), train_loss = 3.26897556, grad/param norm = 6.2476e-01, time/batch = 0.6867s	
45/22300 (epoch 0.101), train_loss = 3.28789057, grad/param norm = 6.3417e-01, time/batch = 0.6869s	
46/22300 (epoch 0.103), train_loss = 3.16827442, grad/param norm = 7.6365e-01, time/batch = 0.6863s	
47/22300 (epoch 0.105), train_loss = 3.18683640, grad/param norm = 5.6528e-01, time/batch = 0.6880s	
48/22300 (epoch 0.108), train_loss = 3.25253001, grad/param norm = 6.7848e-01, time/batch = 0.6788s	
49/22300 (epoch 0.110), train_loss = 3.17991998, grad/param norm = 6.4132e-01, time/batch = 0.6723s	
50/22300 (epoch 0.112), train_loss = 3.15152376, grad/param norm = 5.3961e-01, time/batch = 0.6884s	
51/22300 (epoch 0.114), train_loss = 3.29867183, grad/param norm = 5.7405e-01, time/batch = 0.6874s	
52/22300 (epoch 0.117), train_loss = 3.22023522, grad/param norm = 5.7075e-01, time/batch = 0.6924s	
53/22300 (epoch 0.119), train_loss = 3.16915007, grad/param norm = 6.8398e-01, time/batch = 0.6898s	
54/22300 (epoch 0.121), train_loss = 3.17137238, grad/param norm = 7.5644e-01, time/batch = 0.6852s	
55/22300 (epoch 0.123), train_loss = 3.08275505, grad/param norm = 6.6359e-01, time/batch = 0.6943s	
56/22300 (epoch 0.126), train_loss = 3.13284518, grad/param norm = 5.9314e-01, time/batch = 0.6693s	
57/22300 (epoch 0.128), train_loss = 3.04417311, grad/param norm = 5.5616e-01, time/batch = 0.6712s	
58/22300 (epoch 0.130), train_loss = 3.10022460, grad/param norm = 5.7605e-01, time/batch = 0.6743s	
59/22300 (epoch 0.132), train_loss = 3.20595288, grad/param norm = 5.9286e-01, time/batch = 0.6779s	
60/22300 (epoch 0.135), train_loss = 3.12485582, grad/param norm = 7.3769e-01, time/batch = 0.6901s	
61/22300 (epoch 0.137), train_loss = 3.19586234, grad/param norm = 8.5424e-01, time/batch = 0.6912s	
62/22300 (epoch 0.139), train_loss = 3.22312833, grad/param norm = 8.5419e-01, time/batch = 0.6877s	
63/22300 (epoch 0.141), train_loss = 3.31049567, grad/param norm = 5.4041e-01, time/batch = 0.6868s	
64/22300 (epoch 0.143), train_loss = 3.26304632, grad/param norm = 6.0804e-01, time/batch = 0.6877s	
65/22300 (epoch 0.146), train_loss = 3.19046109, grad/param norm = 5.8653e-01, time/batch = 0.6882s	
66/22300 (epoch 0.148), train_loss = 3.16769646, grad/param norm = 5.6857e-01, time/batch = 0.6875s	
67/22300 (epoch 0.150), train_loss = 3.20698980, grad/param norm = 6.0675e-01, time/batch = 0.6891s	
68/22300 (epoch 0.152), train_loss = 3.15886909, grad/param norm = 6.8932e-01, time/batch = 0.6842s	
69/22300 (epoch 0.155), train_loss = 3.21505786, grad/param norm = 6.5161e-01, time/batch = 0.6706s	
70/22300 (epoch 0.157), train_loss = 3.07786178, grad/param norm = 5.6242e-01, time/batch = 0.6837s	
71/22300 (epoch 0.159), train_loss = 3.08838394, grad/param norm = 5.6989e-01, time/batch = 0.6925s	
72/22300 (epoch 0.161), train_loss = 3.32046064, grad/param norm = 7.4250e-01, time/batch = 0.6913s	
73/22300 (epoch 0.164), train_loss = 3.17264378, grad/param norm = 7.2123e-01, time/batch = 0.6896s	
74/22300 (epoch 0.166), train_loss = 3.25706365, grad/param norm = 5.6023e-01, time/batch = 0.6969s	
75/22300 (epoch 0.168), train_loss = 3.21794013, grad/param norm = 5.8404e-01, time/batch = 0.6958s	
76/22300 (epoch 0.170), train_loss = 3.14765603, grad/param norm = 5.1121e-01, time/batch = 0.6779s	
77/22300 (epoch 0.173), train_loss = 3.22825748, grad/param norm = 4.8635e-01, time/batch = 0.6760s	
78/22300 (epoch 0.175), train_loss = 3.13225582, grad/param norm = 5.4256e-01, time/batch = 0.6758s	
79/22300 (epoch 0.177), train_loss = 3.18588902, grad/param norm = 5.8205e-01, time/batch = 0.6755s	
80/22300 (epoch 0.179), train_loss = 3.22077873, grad/param norm = 6.2293e-01, time/batch = 0.7078s	
81/22300 (epoch 0.182), train_loss = 3.19485453, grad/param norm = 5.2977e-01, time/batch = 0.6811s	
82/22300 (epoch 0.184), train_loss = 3.26594700, grad/param norm = 4.3620e-01, time/batch = 0.6884s	
83/22300 (epoch 0.186), train_loss = 3.23440170, grad/param norm = 4.6481e-01, time/batch = 0.6856s	
84/22300 (epoch 0.188), train_loss = 3.18761937, grad/param norm = 5.1580e-01, time/batch = 0.6763s	
85/22300 (epoch 0.191), train_loss = 3.20086025, grad/param norm = 6.3314e-01, time/batch = 0.7078s	
86/22300 (epoch 0.193), train_loss = 3.15964260, grad/param norm = 9.2019e-01, time/batch = 0.7096s	
87/22300 (epoch 0.195), train_loss = 3.10596894, grad/param norm = 8.6643e-01, time/batch = 0.6918s	
88/22300 (epoch 0.197), train_loss = 3.23981243, grad/param norm = 6.6525e-01, time/batch = 0.6888s	
89/22300 (epoch 0.200), train_loss = 3.10939745, grad/param norm = 5.3064e-01, time/batch = 0.6663s	
90/22300 (epoch 0.202), train_loss = 3.20761127, grad/param norm = 5.9024e-01, time/batch = 0.6708s	
91/22300 (epoch 0.204), train_loss = 3.11288592, grad/param norm = 6.4026e-01, time/batch = 0.6864s	
92/22300 (epoch 0.206), train_loss = 3.14264859, grad/param norm = 4.7128e-01, time/batch = 0.6770s	
93/22300 (epoch 0.209), train_loss = 3.11167665, grad/param norm = 6.8914e-01, time/batch = 0.6756s	
94/22300 (epoch 0.211), train_loss = 3.05823504, grad/param norm = 6.7595e-01, time/batch = 0.6750s	
95/22300 (epoch 0.213), train_loss = 3.21733111, grad/param norm = 4.8807e-01, time/batch = 0.6733s	
96/22300 (epoch 0.215), train_loss = 3.13237265, grad/param norm = 4.3583e-01, time/batch = 0.6736s	
97/22300 (epoch 0.217), train_loss = 3.13612171, grad/param norm = 4.7232e-01, time/batch = 0.6738s	
98/22300 (epoch 0.220), train_loss = 3.10161548, grad/param norm = 8.0478e-01, time/batch = 0.6757s	
99/22300 (epoch 0.222), train_loss = 3.16505519, grad/param norm = 1.0343e+00, time/batch = 0.6606s	
100/22300 (epoch 0.224), train_loss = 3.05671510, grad/param norm = 6.9673e-01, time/batch = 0.6598s	
101/22300 (epoch 0.226), train_loss = 3.23433767, grad/param norm = 5.4771e-01, time/batch = 0.6789s	
102/22300 (epoch 0.229), train_loss = 3.16191553, grad/param norm = 5.2124e-01, time/batch = 0.6733s	
103/22300 (epoch 0.231), train_loss = 3.11177873, grad/param norm = 4.2735e-01, time/batch = 0.6734s	
104/22300 (epoch 0.233), train_loss = 3.06342682, grad/param norm = 6.3436e-01, time/batch = 0.6732s	
105/22300 (epoch 0.235), train_loss = 3.04747464, grad/param norm = 5.8657e-01, time/batch = 0.6705s	
106/22300 (epoch 0.238), train_loss = 3.04788498, grad/param norm = 6.5186e-01, time/batch = 0.6719s	
107/22300 (epoch 0.240), train_loss = 3.12378395, grad/param norm = 5.0429e-01, time/batch = 0.6730s	
108/22300 (epoch 0.242), train_loss = 3.10072987, grad/param norm = 5.2563e-01, time/batch = 0.6717s	
109/22300 (epoch 0.244), train_loss = 3.10065690, grad/param norm = 6.1522e-01, time/batch = 0.6760s	
110/22300 (epoch 0.247), train_loss = 3.09649105, grad/param norm = 1.0752e+00, time/batch = 0.6812s	
111/22300 (epoch 0.249), train_loss = 3.05542169, grad/param norm = 1.0732e+00, time/batch = 0.6846s	
112/22300 (epoch 0.251), train_loss = 3.04760914, grad/param norm = 8.2395e-01, time/batch = 0.6823s	
113/22300 (epoch 0.253), train_loss = 3.04114785, grad/param norm = 4.8087e-01, time/batch = 0.6796s	
114/22300 (epoch 0.256), train_loss = 3.14651623, grad/param norm = 4.8791e-01, time/batch = 0.6801s	
115/22300 (epoch 0.258), train_loss = 3.04354835, grad/param norm = 5.4138e-01, time/batch = 0.6772s	
116/22300 (epoch 0.260), train_loss = 2.98520796, grad/param norm = 4.7692e-01, time/batch = 0.6798s	
117/22300 (epoch 0.262), train_loss = 3.00563962, grad/param norm = 3.7862e-01, time/batch = 0.6796s	
118/22300 (epoch 0.265), train_loss = 3.04143192, grad/param norm = 8.6752e-01, time/batch = 0.6797s	
119/22300 (epoch 0.267), train_loss = 3.10950212, grad/param norm = 1.8772e+00, time/batch = 0.6881s	
120/22300 (epoch 0.269), train_loss = 3.09238713, grad/param norm = 1.3630e+00, time/batch = 0.6798s	
121/22300 (epoch 0.271), train_loss = 3.03322492, grad/param norm = 4.5799e-01, time/batch = 0.6962s	
122/22300 (epoch 0.274), train_loss = 2.88892766, grad/param norm = 3.6004e-01, time/batch = 0.6950s	
123/22300 (epoch 0.276), train_loss = 2.94348694, grad/param norm = 5.3961e-01, time/batch = 0.6993s	
124/22300 (epoch 0.278), train_loss = 2.92050237, grad/param norm = 4.6996e-01, time/batch = 0.6926s	
125/22300 (epoch 0.280), train_loss = 2.94286990, grad/param norm = 6.0325e-01, time/batch = 0.6941s	
126/22300 (epoch 0.283), train_loss = 2.87770869, grad/param norm = 7.5443e-01, time/batch = 0.6924s	
127/22300 (epoch 0.285), train_loss = 2.95488992, grad/param norm = 7.5815e-01, time/batch = 0.6927s	
128/22300 (epoch 0.287), train_loss = 2.85062628, grad/param norm = 5.0042e-01, time/batch = 0.6942s	
129/22300 (epoch 0.289), train_loss = 2.93936041, grad/param norm = 4.6449e-01, time/batch = 0.6943s	
130/22300 (epoch 0.291), train_loss = 2.86591234, grad/param norm = 5.2252e-01, time/batch = 0.6944s	
131/22300 (epoch 0.294), train_loss = 2.93309217, grad/param norm = 9.0706e-01, time/batch = 0.6994s	
132/22300 (epoch 0.296), train_loss = 3.00007996, grad/param norm = 1.2884e+00, time/batch = 0.6966s	
133/22300 (epoch 0.298), train_loss = 2.94890136, grad/param norm = 1.2113e+00, time/batch = 0.7234s	
134/22300 (epoch 0.300), train_loss = 2.91370734, grad/param norm = 7.2841e-01, time/batch = 0.7284s	
135/22300 (epoch 0.303), train_loss = 2.86713298, grad/param norm = 6.8887e-01, time/batch = 0.7331s	
136/22300 (epoch 0.305), train_loss = 2.94699613, grad/param norm = 1.0399e+00, time/batch = 0.7056s	
137/22300 (epoch 0.307), train_loss = 3.00990475, grad/param norm = 7.3676e-01, time/batch = 0.7079s	
138/22300 (epoch 0.309), train_loss = 2.96991622, grad/param norm = 3.8381e-01, time/batch = 0.7073s	
139/22300 (epoch 0.312), train_loss = 2.82941402, grad/param norm = 4.3198e-01, time/batch = 0.7080s	
140/22300 (epoch 0.314), train_loss = 2.84307961, grad/param norm = 3.5962e-01, time/batch = 0.6952s	
141/22300 (epoch 0.316), train_loss = 2.86174927, grad/param norm = 5.6403e-01, time/batch = 0.7071s	
142/22300 (epoch 0.318), train_loss = 2.99180260, grad/param norm = 1.3992e+00, time/batch = 0.6951s	
143/22300 (epoch 0.321), train_loss = 2.97731498, grad/param norm = 1.3353e+00, time/batch = 0.6948s	
144/22300 (epoch 0.323), train_loss = 2.85719348, grad/param norm = 7.1715e-01, time/batch = 0.6939s	
145/22300 (epoch 0.325), train_loss = 2.83936676, grad/param norm = 7.3560e-01, time/batch = 0.6982s	
146/22300 (epoch 0.327), train_loss = 2.90928814, grad/param norm = 7.3022e-01, time/batch = 0.6981s	
147/22300 (epoch 0.330), train_loss = 2.83456840, grad/param norm = 4.1033e-01, time/batch = 0.6982s	
148/22300 (epoch 0.332), train_loss = 2.87203146, grad/param norm = 7.9149e-01, time/batch = 0.6914s	
149/22300 (epoch 0.334), train_loss = 2.79782581, grad/param norm = 1.0376e+00, time/batch = 0.6993s	
150/22300 (epoch 0.336), train_loss = 2.84959745, grad/param norm = 9.4332e-01, time/batch = 0.6964s	
151/22300 (epoch 0.339), train_loss = 2.84762191, grad/param norm = 7.4187e-01, time/batch = 0.6953s	
152/22300 (epoch 0.341), train_loss = 2.77348830, grad/param norm = 4.6575e-01, time/batch = 0.6943s	
153/22300 (epoch 0.343), train_loss = 2.76216729, grad/param norm = 5.3602e-01, time/batch = 0.6858s	
154/22300 (epoch 0.345), train_loss = 2.78347009, grad/param norm = 5.4228e-01, time/batch = 0.6928s	
155/22300 (epoch 0.348), train_loss = 2.82508607, grad/param norm = 6.0308e-01, time/batch = 0.6956s	
156/22300 (epoch 0.350), train_loss = 2.82726892, grad/param norm = 7.1773e-01, time/batch = 0.6943s	
157/22300 (epoch 0.352), train_loss = 2.84183423, grad/param norm = 1.1038e+00, time/batch = 0.6955s	
158/22300 (epoch 0.354), train_loss = 2.87034004, grad/param norm = 1.2361e+00, time/batch = 0.6891s	
159/22300 (epoch 0.357), train_loss = 3.02886242, grad/param norm = 1.3301e+00, time/batch = 0.6945s	
160/22300 (epoch 0.359), train_loss = 2.82771584, grad/param norm = 1.2145e+00, time/batch = 0.6908s	
161/22300 (epoch 0.361), train_loss = 2.80964682, grad/param norm = 7.0940e-01, time/batch = 0.7137s	
162/22300 (epoch 0.363), train_loss = 2.96341919, grad/param norm = 7.1996e-01, time/batch = 0.6973s	
163/22300 (epoch 0.365), train_loss = 2.86690908, grad/param norm = 8.0004e-01, time/batch = 0.6988s	
164/22300 (epoch 0.368), train_loss = 2.80305513, grad/param norm = 8.2213e-01, time/batch = 0.6961s	
165/22300 (epoch 0.370), train_loss = 2.64423777, grad/param norm = 5.4392e-01, time/batch = 0.6932s	
166/22300 (epoch 0.372), train_loss = 2.68061721, grad/param norm = 6.9107e-01, time/batch = 0.6939s	
167/22300 (epoch 0.374), train_loss = 2.74565568, grad/param norm = 5.9198e-01, time/batch = 0.6931s	
168/22300 (epoch 0.377), train_loss = 2.74544943, grad/param norm = 5.2667e-01, time/batch = 0.6932s	
169/22300 (epoch 0.379), train_loss = 2.61429859, grad/param norm = 7.8390e-01, time/batch = 0.6903s	
170/22300 (epoch 0.381), train_loss = 2.74918177, grad/param norm = 9.7499e-01, time/batch = 0.6916s	
171/22300 (epoch 0.383), train_loss = 2.67393288, grad/param norm = 1.1501e+00, time/batch = 0.6909s	
172/22300 (epoch 0.386), train_loss = 2.67763583, grad/param norm = 1.2261e+00, time/batch = 0.6921s	
173/22300 (epoch 0.388), train_loss = 2.66539488, grad/param norm = 8.7055e-01, time/batch = 0.6945s	
174/22300 (epoch 0.390), train_loss = 2.76730432, grad/param norm = 8.4199e-01, time/batch = 0.6921s	
175/22300 (epoch 0.392), train_loss = 2.75770262, grad/param norm = 1.1304e+00, time/batch = 0.6915s	
176/22300 (epoch 0.395), train_loss = 2.69675986, grad/param norm = 1.1148e+00, time/batch = 0.6926s	
177/22300 (epoch 0.397), train_loss = 2.67024493, grad/param norm = 8.6558e-01, time/batch = 0.6925s	
178/22300 (epoch 0.399), train_loss = 2.78600905, grad/param norm = 6.5167e-01, time/batch = 0.6893s	
179/22300 (epoch 0.401), train_loss = 2.76478816, grad/param norm = 3.4317e-01, time/batch = 0.6894s	
180/22300 (epoch 0.404), train_loss = 2.73277259, grad/param norm = 3.1010e-01, time/batch = 0.6813s	
181/22300 (epoch 0.406), train_loss = 2.70358380, grad/param norm = 4.4966e-01, time/batch = 0.7002s	
182/22300 (epoch 0.408), train_loss = 2.75800016, grad/param norm = 3.8299e-01, time/batch = 0.6863s	
183/22300 (epoch 0.410), train_loss = 2.67440751, grad/param norm = 5.9226e-01, time/batch = 0.6887s	
184/22300 (epoch 0.413), train_loss = 2.79745997, grad/param norm = 7.3709e-01, time/batch = 0.6927s	
185/22300 (epoch 0.415), train_loss = 2.69277682, grad/param norm = 1.2080e+00, time/batch = 0.7288s	
186/22300 (epoch 0.417), train_loss = 2.80470228, grad/param norm = 1.5042e+00, time/batch = 0.6945s	
187/22300 (epoch 0.419), train_loss = 2.72086096, grad/param norm = 1.0707e+00, time/batch = 0.6900s	
188/22300 (epoch 0.422), train_loss = 2.57038705, grad/param norm = 6.6465e-01, time/batch = 0.6935s	
189/22300 (epoch 0.424), train_loss = 2.58830904, grad/param norm = 6.3095e-01, time/batch = 0.6908s	
190/22300 (epoch 0.426), train_loss = 2.76965659, grad/param norm = 7.9034e-01, time/batch = 0.6774s	
191/22300 (epoch 0.428), train_loss = 2.73399055, grad/param norm = 6.8345e-01, time/batch = 0.6945s	
192/22300 (epoch 0.430), train_loss = 2.67856158, grad/param norm = 7.3182e-01, time/batch = 0.6971s	
193/22300 (epoch 0.433), train_loss = 2.61979860, grad/param norm = 1.0028e+00, time/batch = 0.6916s	
194/22300 (epoch 0.435), train_loss = 2.77711094, grad/param norm = 1.1830e+00, time/batch = 0.6894s	
195/22300 (epoch 0.437), train_loss = 2.69434120, grad/param norm = 7.7532e-01, time/batch = 0.6869s	
196/22300 (epoch 0.439), train_loss = 2.66227930, grad/param norm = 8.3362e-01, time/batch = 0.6897s	
197/22300 (epoch 0.442), train_loss = 2.66734562, grad/param norm = 1.0499e+00, time/batch = 0.7075s	
198/22300 (epoch 0.444), train_loss = 2.89165984, grad/param norm = 9.8550e-01, time/batch = 0.7260s	
199/22300 (epoch 0.446), train_loss = 2.67026979, grad/param norm = 7.7772e-01, time/batch = 0.6926s	
200/22300 (epoch 0.448), train_loss = 2.65682940, grad/param norm = 5.1719e-01, time/batch = 0.6826s	
201/22300 (epoch 0.451), train_loss = 2.56988647, grad/param norm = 4.1845e-01, time/batch = 0.6978s	
202/22300 (epoch 0.453), train_loss = 2.56371337, grad/param norm = 4.3082e-01, time/batch = 0.6952s	
203/22300 (epoch 0.455), train_loss = 2.57373113, grad/param norm = 4.0158e-01, time/batch = 0.6943s	
204/22300 (epoch 0.457), train_loss = 2.59585128, grad/param norm = 5.0502e-01, time/batch = 0.6930s	
205/22300 (epoch 0.460), train_loss = 2.63094356, grad/param norm = 6.4410e-01, time/batch = 0.6940s	
206/22300 (epoch 0.462), train_loss = 2.60468750, grad/param norm = 7.0280e-01, time/batch = 0.6909s	
207/22300 (epoch 0.464), train_loss = 2.65884846, grad/param norm = 1.0142e+00, time/batch = 0.6907s	
208/22300 (epoch 0.466), train_loss = 2.60928554, grad/param norm = 1.0380e+00, time/batch = 0.6905s	
209/22300 (epoch 0.469), train_loss = 2.58178612, grad/param norm = 9.1060e-01, time/batch = 0.6912s	
210/22300 (epoch 0.471), train_loss = 2.64258184, grad/param norm = 9.2556e-01, time/batch = 0.6943s	
211/22300 (epoch 0.473), train_loss = 2.82141191, grad/param norm = 9.9233e-01, time/batch = 0.6963s	
212/22300 (epoch 0.475), train_loss = 2.53270447, grad/param norm = 6.2789e-01, time/batch = 0.6902s	
213/22300 (epoch 0.478), train_loss = 2.56896165, grad/param norm = 5.4979e-01, time/batch = 0.6891s	
214/22300 (epoch 0.480), train_loss = 2.63526607, grad/param norm = 6.7848e-01, time/batch = 0.6874s	
215/22300 (epoch 0.482), train_loss = 2.60243749, grad/param norm = 7.9920e-01, time/batch = 0.6891s	
216/22300 (epoch 0.484), train_loss = 2.57203193, grad/param norm = 7.4389e-01, time/batch = 0.6904s	
217/22300 (epoch 0.487), train_loss = 2.58923265, grad/param norm = 3.9419e-01, time/batch = 0.6949s	
218/22300 (epoch 0.489), train_loss = 2.60570816, grad/param norm = 3.1860e-01, time/batch = 0.7033s	
219/22300 (epoch 0.491), train_loss = 2.65090735, grad/param norm = 4.5397e-01, time/batch = 0.7037s	
220/22300 (epoch 0.493), train_loss = 2.64784178, grad/param norm = 8.1229e-01, time/batch = 0.7039s	
221/22300 (epoch 0.496), train_loss = 2.63899061, grad/param norm = 1.2314e+00, time/batch = 0.7386s	
222/22300 (epoch 0.498), train_loss = 2.65740107, grad/param norm = 1.3190e+00, time/batch = 0.7117s	
223/22300 (epoch 0.500), train_loss = 2.60469447, grad/param norm = 1.2523e+00, time/batch = 0.7021s	
224/22300 (epoch 0.502), train_loss = 2.57666150, grad/param norm = 7.3157e-01, time/batch = 0.7028s	
225/22300 (epoch 0.504), train_loss = 2.69398191, grad/param norm = 8.2729e-01, time/batch = 0.6989s	
226/22300 (epoch 0.507), train_loss = 2.59947580, grad/param norm = 1.0350e+00, time/batch = 0.6879s	
227/22300 (epoch 0.509), train_loss = 2.61665895, grad/param norm = 5.6522e-01, time/batch = 0.7075s	
228/22300 (epoch 0.511), train_loss = 2.57048187, grad/param norm = 3.9557e-01, time/batch = 0.6906s	
229/22300 (epoch 0.513), train_loss = 2.64555858, grad/param norm = 5.5068e-01, time/batch = 0.6858s	
230/22300 (epoch 0.516), train_loss = 2.59984511, grad/param norm = 4.6987e-01, time/batch = 0.6816s	
231/22300 (epoch 0.518), train_loss = 2.51117889, grad/param norm = 5.5975e-01, time/batch = 0.6828s	
232/22300 (epoch 0.520), train_loss = 2.66990139, grad/param norm = 4.1794e-01, time/batch = 0.7159s	
233/22300 (epoch 0.522), train_loss = 2.59923168, grad/param norm = 5.0615e-01, time/batch = 0.7152s	
234/22300 (epoch 0.525), train_loss = 2.57166245, grad/param norm = 4.8651e-01, time/batch = 0.6993s	
235/22300 (epoch 0.527), train_loss = 2.76577942, grad/param norm = 4.2862e-01, time/batch = 0.6926s	
236/22300 (epoch 0.529), train_loss = 2.57683942, grad/param norm = 5.3981e-01, time/batch = 0.6935s	
237/22300 (epoch 0.531), train_loss = 2.50746717, grad/param norm = 1.1074e+00, time/batch = 0.6948s	
238/22300 (epoch 0.534), train_loss = 2.67356492, grad/param norm = 1.5203e+00, time/batch = 0.6880s	
239/22300 (epoch 0.536), train_loss = 2.72756252, grad/param norm = 1.0807e+00, time/batch = 0.6826s	
240/22300 (epoch 0.538), train_loss = 2.75993420, grad/param norm = 5.3202e-01, time/batch = 0.6776s	
241/22300 (epoch 0.540), train_loss = 2.69240376, grad/param norm = 5.0047e-01, time/batch = 0.6845s	
242/22300 (epoch 0.543), train_loss = 2.55377709, grad/param norm = 5.3228e-01, time/batch = 0.6761s	
243/22300 (epoch 0.545), train_loss = 2.59315216, grad/param norm = 7.3423e-01, time/batch = 0.6700s	
244/22300 (epoch 0.547), train_loss = 2.67729463, grad/param norm = 7.3268e-01, time/batch = 0.6761s	
245/22300 (epoch 0.549), train_loss = 2.61923614, grad/param norm = 5.4181e-01, time/batch = 0.6817s	
246/22300 (epoch 0.552), train_loss = 2.55457649, grad/param norm = 4.8586e-01, time/batch = 0.6889s	
247/22300 (epoch 0.554), train_loss = 2.54616827, grad/param norm = 6.1597e-01, time/batch = 0.7027s	
248/22300 (epoch 0.556), train_loss = 2.71564554, grad/param norm = 7.3660e-01, time/batch = 0.6970s	
249/22300 (epoch 0.558), train_loss = 2.59341326, grad/param norm = 8.9622e-01, time/batch = 0.6960s	
250/22300 (epoch 0.561), train_loss = 2.65856383, grad/param norm = 8.4754e-01, time/batch = 0.6837s	
251/22300 (epoch 0.563), train_loss = 2.55741879, grad/param norm = 6.1164e-01, time/batch = 0.6937s	
252/22300 (epoch 0.565), train_loss = 2.60634844, grad/param norm = 4.8226e-01, time/batch = 0.6924s	
253/22300 (epoch 0.567), train_loss = 2.52852102, grad/param norm = 4.9633e-01, time/batch = 0.6897s	
254/22300 (epoch 0.570), train_loss = 2.60794333, grad/param norm = 4.1379e-01, time/batch = 0.6913s	
255/22300 (epoch 0.572), train_loss = 2.57310229, grad/param norm = 3.9913e-01, time/batch = 0.7207s	
256/22300 (epoch 0.574), train_loss = 2.50877334, grad/param norm = 6.6820e-01, time/batch = 0.7108s	
257/22300 (epoch 0.576), train_loss = 2.58045862, grad/param norm = 7.9445e-01, time/batch = 0.6917s	
258/22300 (epoch 0.578), train_loss = 2.52789508, grad/param norm = 6.9628e-01, time/batch = 0.6903s	
259/22300 (epoch 0.581), train_loss = 2.48484297, grad/param norm = 6.5883e-01, time/batch = 0.6991s	
260/22300 (epoch 0.583), train_loss = 2.60799581, grad/param norm = 5.9546e-01, time/batch = 0.6877s	
261/22300 (epoch 0.585), train_loss = 2.62110232, grad/param norm = 5.3607e-01, time/batch = 0.6915s	
262/22300 (epoch 0.587), train_loss = 2.55177602, grad/param norm = 5.9985e-01, time/batch = 0.6945s	
263/22300 (epoch 0.590), train_loss = 2.54954771, grad/param norm = 7.5721e-01, time/batch = 0.6920s	
264/22300 (epoch 0.592), train_loss = 2.73940341, grad/param norm = 7.0343e-01, time/batch = 0.6948s	
265/22300 (epoch 0.594), train_loss = 2.50106218, grad/param norm = 6.7971e-01, time/batch = 0.6978s	
266/22300 (epoch 0.596), train_loss = 2.63486978, grad/param norm = 6.8137e-01, time/batch = 0.6915s	
267/22300 (epoch 0.599), train_loss = 2.46538721, grad/param norm = 7.3895e-01, time/batch = 0.6835s	
268/22300 (epoch 0.601), train_loss = 2.53141113, grad/param norm = 6.3534e-01, time/batch = 0.7017s	
269/22300 (epoch 0.603), train_loss = 2.48216773, grad/param norm = 4.5523e-01, time/batch = 0.6912s	
270/22300 (epoch 0.605), train_loss = 2.46064478, grad/param norm = 3.6362e-01, time/batch = 0.6876s	
271/22300 (epoch 0.608), train_loss = 2.47893878, grad/param norm = 4.1792e-01, time/batch = 0.6946s	
272/22300 (epoch 0.610), train_loss = 2.37573540, grad/param norm = 3.7380e-01, time/batch = 0.6995s	
273/22300 (epoch 0.612), train_loss = 2.50501132, grad/param norm = 4.6478e-01, time/batch = 0.6976s	
274/22300 (epoch 0.614), train_loss = 2.54970533, grad/param norm = 4.7609e-01, time/batch = 0.6983s	
275/22300 (epoch 0.617), train_loss = 2.56655922, grad/param norm = 6.1938e-01, time/batch = 0.6958s	
276/22300 (epoch 0.619), train_loss = 2.60562912, grad/param norm = 6.3631e-01, time/batch = 0.6967s	
277/22300 (epoch 0.621), train_loss = 2.36757450, grad/param norm = 7.9894e-01, time/batch = 0.6997s	
278/22300 (epoch 0.623), train_loss = 2.52549684, grad/param norm = 1.0360e+00, time/batch = 0.6972s	
279/22300 (epoch 0.626), train_loss = 2.46923908, grad/param norm = 9.6127e-01, time/batch = 0.6968s	
280/22300 (epoch 0.628), train_loss = 2.63577796, grad/param norm = 6.8656e-01, time/batch = 0.6886s	
281/22300 (epoch 0.630), train_loss = 2.48535225, grad/param norm = 5.1034e-01, time/batch = 0.7009s	
282/22300 (epoch 0.632), train_loss = 2.52120368, grad/param norm = 4.6275e-01, time/batch = 0.6948s	
283/22300 (epoch 0.635), train_loss = 2.49901610, grad/param norm = 6.1808e-01, time/batch = 0.7104s	
284/22300 (epoch 0.637), train_loss = 2.60772912, grad/param norm = 8.8684e-01, time/batch = 0.6794s	
285/22300 (epoch 0.639), train_loss = 2.57907465, grad/param norm = 9.0779e-01, time/batch = 0.6825s	
286/22300 (epoch 0.641), train_loss = 2.55457519, grad/param norm = 6.3611e-01, time/batch = 0.6718s	
287/22300 (epoch 0.643), train_loss = 2.44737236, grad/param norm = 5.3271e-01, time/batch = 0.6891s	
288/22300 (epoch 0.646), train_loss = 2.48532950, grad/param norm = 4.4170e-01, time/batch = 0.6905s	
289/22300 (epoch 0.648), train_loss = 2.47094962, grad/param norm = 3.5613e-01, time/batch = 0.6950s	
290/22300 (epoch 0.650), train_loss = 2.63694510, grad/param norm = 4.4895e-01, time/batch = 0.6787s	
291/22300 (epoch 0.652), train_loss = 2.49884430, grad/param norm = 5.0460e-01, time/batch = 0.6858s	
292/22300 (epoch 0.655), train_loss = 2.42797305, grad/param norm = 2.9854e-01, time/batch = 0.6912s	
293/22300 (epoch 0.657), train_loss = 2.54994848, grad/param norm = 3.9411e-01, time/batch = 0.6883s	
294/22300 (epoch 0.659), train_loss = 2.43153225, grad/param norm = 6.6305e-01, time/batch = 0.6883s	
295/22300 (epoch 0.661), train_loss = 2.56107457, grad/param norm = 1.0027e+00, time/batch = 0.6804s	
296/22300 (epoch 0.664), train_loss = 2.49802574, grad/param norm = 9.3639e-01, time/batch = 0.6891s	
297/22300 (epoch 0.666), train_loss = 2.58583621, grad/param norm = 8.0291e-01, time/batch = 0.6926s	
298/22300 (epoch 0.668), train_loss = 2.59608587, grad/param norm = 7.7859e-01, time/batch = 0.6843s	
299/22300 (epoch 0.670), train_loss = 2.60008480, grad/param norm = 6.0999e-01, time/batch = 0.6852s	
300/22300 (epoch 0.673), train_loss = 2.60601475, grad/param norm = 3.2953e-01, time/batch = 0.6924s	
301/22300 (epoch 0.675), train_loss = 2.51638052, grad/param norm = 4.0235e-01, time/batch = 0.6949s	
302/22300 (epoch 0.677), train_loss = 2.51982669, grad/param norm = 4.7954e-01, time/batch = 0.6935s	
303/22300 (epoch 0.679), train_loss = 2.50347002, grad/param norm = 5.6581e-01, time/batch = 0.6924s	
304/22300 (epoch 0.682), train_loss = 2.44245442, grad/param norm = 6.1410e-01, time/batch = 0.6889s	
305/22300 (epoch 0.684), train_loss = 2.51857100, grad/param norm = 6.7142e-01, time/batch = 0.6922s	
306/22300 (epoch 0.686), train_loss = 2.45728508, grad/param norm = 6.9463e-01, time/batch = 0.6932s	
307/22300 (epoch 0.688), train_loss = 2.53368274, grad/param norm = 4.7497e-01, time/batch = 0.6888s	
308/22300 (epoch 0.691), train_loss = 2.56262146, grad/param norm = 4.2262e-01, time/batch = 0.6818s	
309/22300 (epoch 0.693), train_loss = 2.52553756, grad/param norm = 5.4622e-01, time/batch = 0.6852s	
310/22300 (epoch 0.695), train_loss = 2.49094031, grad/param norm = 6.1834e-01, time/batch = 0.6953s	
311/22300 (epoch 0.697), train_loss = 2.45377248, grad/param norm = 5.5891e-01, time/batch = 0.6987s	
312/22300 (epoch 0.700), train_loss = 2.49234254, grad/param norm = 5.5893e-01, time/batch = 0.6965s	
313/22300 (epoch 0.702), train_loss = 2.43393981, grad/param norm = 5.5872e-01, time/batch = 0.6896s	
314/22300 (epoch 0.704), train_loss = 2.53808362, grad/param norm = 4.8955e-01, time/batch = 0.6859s	
315/22300 (epoch 0.706), train_loss = 2.46059796, grad/param norm = 4.3488e-01, time/batch = 0.6798s	
316/22300 (epoch 0.709), train_loss = 2.43778338, grad/param norm = 5.8375e-01, time/batch = 0.6922s	
317/22300 (epoch 0.711), train_loss = 2.55509031, grad/param norm = 8.1516e-01, time/batch = 0.6943s	
318/22300 (epoch 0.713), train_loss = 2.39884851, grad/param norm = 7.5902e-01, time/batch = 0.6982s	
319/22300 (epoch 0.715), train_loss = 2.53721163, grad/param norm = 7.4575e-01, time/batch = 0.6969s	
320/22300 (epoch 0.717), train_loss = 2.55420987, grad/param norm = 7.7575e-01, time/batch = 0.6934s	
321/22300 (epoch 0.720), train_loss = 2.51967589, grad/param norm = 6.2222e-01, time/batch = 0.6970s	
322/22300 (epoch 0.722), train_loss = 2.54329479, grad/param norm = 5.2269e-01, time/batch = 0.6953s	
323/22300 (epoch 0.724), train_loss = 2.53571809, grad/param norm = 4.8445e-01, time/batch = 0.6951s	
324/22300 (epoch 0.726), train_loss = 2.48382939, grad/param norm = 6.1915e-01, time/batch = 0.6951s	
325/22300 (epoch 0.729), train_loss = 2.45647042, grad/param norm = 5.5591e-01, time/batch = 0.6922s	
326/22300 (epoch 0.731), train_loss = 2.49574495, grad/param norm = 4.7141e-01, time/batch = 0.6911s	
327/22300 (epoch 0.733), train_loss = 2.45546961, grad/param norm = 6.2649e-01, time/batch = 0.6936s	
328/22300 (epoch 0.735), train_loss = 2.43814064, grad/param norm = 6.0447e-01, time/batch = 0.6895s	
329/22300 (epoch 0.738), train_loss = 2.43722900, grad/param norm = 5.4770e-01, time/batch = 0.6840s	
330/22300 (epoch 0.740), train_loss = 2.42527616, grad/param norm = 4.1127e-01, time/batch = 0.6890s	
331/22300 (epoch 0.742), train_loss = 2.44440326, grad/param norm = 4.6484e-01, time/batch = 0.6939s	
332/22300 (epoch 0.744), train_loss = 2.44907983, grad/param norm = 6.9801e-01, time/batch = 0.7117s	
333/22300 (epoch 0.747), train_loss = 2.49514875, grad/param norm = 8.1641e-01, time/batch = 0.7017s	
334/22300 (epoch 0.749), train_loss = 2.49888099, grad/param norm = 5.9202e-01, time/batch = 0.7108s	
335/22300 (epoch 0.751), train_loss = 2.52621211, grad/param norm = 4.6997e-01, time/batch = 0.6823s	
336/22300 (epoch 0.753), train_loss = 2.53117683, grad/param norm = 4.8057e-01, time/batch = 0.7090s	
337/22300 (epoch 0.756), train_loss = 2.50033700, grad/param norm = 5.2263e-01, time/batch = 0.7173s	
338/22300 (epoch 0.758), train_loss = 2.36591625, grad/param norm = 3.8195e-01, time/batch = 0.6893s	
339/22300 (epoch 0.760), train_loss = 2.42333682, grad/param norm = 4.7695e-01, time/batch = 0.6909s	
340/22300 (epoch 0.762), train_loss = 2.44481756, grad/param norm = 5.6719e-01, time/batch = 0.7125s	
341/22300 (epoch 0.765), train_loss = 2.46914667, grad/param norm = 4.3677e-01, time/batch = 0.7130s	
342/22300 (epoch 0.767), train_loss = 2.48175973, grad/param norm = 4.0275e-01, time/batch = 0.6754s	
343/22300 (epoch 0.769), train_loss = 2.49905215, grad/param norm = 6.1504e-01, time/batch = 0.6757s	
344/22300 (epoch 0.771), train_loss = 2.44810318, grad/param norm = 8.7442e-01, time/batch = 0.6769s	
345/22300 (epoch 0.774), train_loss = 2.46214908, grad/param norm = 5.6522e-01, time/batch = 0.6610s	
346/22300 (epoch 0.776), train_loss = 2.38701229, grad/param norm = 4.4087e-01, time/batch = 0.6669s	
347/22300 (epoch 0.778), train_loss = 2.47040084, grad/param norm = 4.0591e-01, time/batch = 0.6728s	
348/22300 (epoch 0.780), train_loss = 2.52680942, grad/param norm = 3.8876e-01, time/batch = 0.6754s	
349/22300 (epoch 0.783), train_loss = 2.46943949, grad/param norm = 5.0777e-01, time/batch = 0.6817s	
350/22300 (epoch 0.785), train_loss = 2.55803851, grad/param norm = 3.8242e-01, time/batch = 0.6794s	
351/22300 (epoch 0.787), train_loss = 2.43763456, grad/param norm = 5.6684e-01, time/batch = 0.6783s	
352/22300 (epoch 0.789), train_loss = 2.40988219, grad/param norm = 9.5340e-01, time/batch = 0.6740s	
353/22300 (epoch 0.791), train_loss = 2.63467334, grad/param norm = 8.1303e-01, time/batch = 0.6724s	
354/22300 (epoch 0.794), train_loss = 2.52876745, grad/param norm = 5.4166e-01, time/batch = 0.6737s	
355/22300 (epoch 0.796), train_loss = 2.35920536, grad/param norm = 3.0320e-01, time/batch = 0.6719s	
356/22300 (epoch 0.798), train_loss = 2.41283364, grad/param norm = 3.8350e-01, time/batch = 0.6618s	
357/22300 (epoch 0.800), train_loss = 2.35848611, grad/param norm = 4.2960e-01, time/batch = 0.6764s	
358/22300 (epoch 0.803), train_loss = 2.37915085, grad/param norm = 4.9447e-01, time/batch = 0.6744s	
359/22300 (epoch 0.805), train_loss = 2.44531740, grad/param norm = 3.3508e-01, time/batch = 0.6777s	
360/22300 (epoch 0.807), train_loss = 2.34308865, grad/param norm = 3.5347e-01, time/batch = 0.6764s	
361/22300 (epoch 0.809), train_loss = 2.41873723, grad/param norm = 4.2116e-01, time/batch = 0.6687s	
362/22300 (epoch 0.812), train_loss = 2.45095161, grad/param norm = 6.4816e-01, time/batch = 0.6693s	
363/22300 (epoch 0.814), train_loss = 2.37359396, grad/param norm = 6.3090e-01, time/batch = 0.6738s	
364/22300 (epoch 0.816), train_loss = 2.45061136, grad/param norm = 4.4206e-01, time/batch = 0.6771s	
365/22300 (epoch 0.818), train_loss = 2.35572811, grad/param norm = 3.3031e-01, time/batch = 0.6765s	
366/22300 (epoch 0.821), train_loss = 2.51435572, grad/param norm = 3.3562e-01, time/batch = 0.6755s	
367/22300 (epoch 0.823), train_loss = 2.31328689, grad/param norm = 3.9735e-01, time/batch = 0.6754s	
368/22300 (epoch 0.825), train_loss = 2.35138575, grad/param norm = 3.9798e-01, time/batch = 0.6816s	
369/22300 (epoch 0.827), train_loss = 2.37478742, grad/param norm = 5.2535e-01, time/batch = 0.6898s	
370/22300 (epoch 0.830), train_loss = 2.39119601, grad/param norm = 8.0389e-01, time/batch = 0.6815s	
371/22300 (epoch 0.832), train_loss = 2.36212161, grad/param norm = 4.7249e-01, time/batch = 0.6938s	
372/22300 (epoch 0.834), train_loss = 2.46074793, grad/param norm = 5.8401e-01, time/batch = 0.6882s	
373/22300 (epoch 0.836), train_loss = 2.42963125, grad/param norm = 5.6680e-01, time/batch = 0.6842s	
374/22300 (epoch 0.839), train_loss = 2.51823339, grad/param norm = 4.0898e-01, time/batch = 0.6870s	
375/22300 (epoch 0.841), train_loss = 2.41383529, grad/param norm = 2.9852e-01, time/batch = 0.6929s	
376/22300 (epoch 0.843), train_loss = 2.34273785, grad/param norm = 3.7794e-01, time/batch = 0.6825s	
377/22300 (epoch 0.845), train_loss = 2.44224955, grad/param norm = 3.7901e-01, time/batch = 0.7125s	
378/22300 (epoch 0.848), train_loss = 2.37928223, grad/param norm = 4.9396e-01, time/batch = 0.7017s	
379/22300 (epoch 0.850), train_loss = 2.46421428, grad/param norm = 4.1736e-01, time/batch = 0.6941s	
380/22300 (epoch 0.852), train_loss = 2.42431753, grad/param norm = 4.0617e-01, time/batch = 0.6904s	
381/22300 (epoch 0.854), train_loss = 2.45652472, grad/param norm = 3.6147e-01, time/batch = 0.6944s	
382/22300 (epoch 0.857), train_loss = 2.32940439, grad/param norm = 3.5453e-01, time/batch = 0.6888s	
383/22300 (epoch 0.859), train_loss = 2.39189562, grad/param norm = 3.6732e-01, time/batch = 0.6811s	
384/22300 (epoch 0.861), train_loss = 2.52164582, grad/param norm = 5.4337e-01, time/batch = 0.6981s	
385/22300 (epoch 0.863), train_loss = 2.45374494, grad/param norm = 1.2625e+00, time/batch = 0.7146s	
386/22300 (epoch 0.865), train_loss = 2.38602699, grad/param norm = 1.0623e+00, time/batch = 0.6913s	
387/22300 (epoch 0.868), train_loss = 2.33961252, grad/param norm = 7.9260e-01, time/batch = 0.6851s	
388/22300 (epoch 0.870), train_loss = 2.34274979, grad/param norm = 6.1058e-01, time/batch = 0.6875s	
389/22300 (epoch 0.872), train_loss = 2.47882841, grad/param norm = 6.4342e-01, time/batch = 0.6949s	
390/22300 (epoch 0.874), train_loss = 2.56602819, grad/param norm = 5.6902e-01, time/batch = 0.6915s	
391/22300 (epoch 0.877), train_loss = 2.33009212, grad/param norm = 4.0910e-01, time/batch = 0.6903s	
392/22300 (epoch 0.879), train_loss = 2.29482568, grad/param norm = 3.5906e-01, time/batch = 0.6837s	
393/22300 (epoch 0.881), train_loss = 2.37300352, grad/param norm = 3.1900e-01, time/batch = 0.6929s	
394/22300 (epoch 0.883), train_loss = 2.46131731, grad/param norm = 4.0964e-01, time/batch = 0.6911s	
395/22300 (epoch 0.886), train_loss = 2.43607808, grad/param norm = 4.3039e-01, time/batch = 0.6929s	
396/22300 (epoch 0.888), train_loss = 2.36534366, grad/param norm = 3.8553e-01, time/batch = 0.6905s	
397/22300 (epoch 0.890), train_loss = 2.36707643, grad/param norm = 3.8465e-01, time/batch = 0.6903s	
398/22300 (epoch 0.892), train_loss = 2.38374511, grad/param norm = 2.6029e-01, time/batch = 0.6972s	
399/22300 (epoch 0.895), train_loss = 2.21661590, grad/param norm = 3.2684e-01, time/batch = 0.6985s	
400/22300 (epoch 0.897), train_loss = 2.41036437, grad/param norm = 3.4654e-01, time/batch = 0.6968s	
401/22300 (epoch 0.899), train_loss = 2.31336485, grad/param norm = 4.8601e-01, time/batch = 0.6965s	
402/22300 (epoch 0.901), train_loss = 2.36222266, grad/param norm = 5.0708e-01, time/batch = 0.6957s	
403/22300 (epoch 0.904), train_loss = 2.35484009, grad/param norm = 5.0017e-01, time/batch = 0.6960s	
404/22300 (epoch 0.906), train_loss = 2.36133264, grad/param norm = 5.6759e-01, time/batch = 0.6945s	
405/22300 (epoch 0.908), train_loss = 2.23034319, grad/param norm = 7.1984e-01, time/batch = 0.6945s	
406/22300 (epoch 0.910), train_loss = 2.38884974, grad/param norm = 5.1606e-01, time/batch = 0.6963s	
407/22300 (epoch 0.913), train_loss = 2.37867397, grad/param norm = 4.8421e-01, time/batch = 0.6963s	
408/22300 (epoch 0.915), train_loss = 2.38059304, grad/param norm = 3.6346e-01, time/batch = 0.6945s	
409/22300 (epoch 0.917), train_loss = 2.37272354, grad/param norm = 3.9827e-01, time/batch = 0.6951s	
410/22300 (epoch 0.919), train_loss = 2.33654099, grad/param norm = 3.9357e-01, time/batch = 0.6963s	
411/22300 (epoch 0.922), train_loss = 2.32162465, grad/param norm = 3.3700e-01, time/batch = 0.6990s	
412/22300 (epoch 0.924), train_loss = 2.46459788, grad/param norm = 4.1536e-01, time/batch = 0.6967s	
413/22300 (epoch 0.926), train_loss = 2.29205775, grad/param norm = 4.4419e-01, time/batch = 0.6971s	
414/22300 (epoch 0.928), train_loss = 2.37206208, grad/param norm = 4.4272e-01, time/batch = 0.6996s	
415/22300 (epoch 0.930), train_loss = 2.47379220, grad/param norm = 5.4403e-01, time/batch = 0.6941s	
416/22300 (epoch 0.933), train_loss = 2.34623496, grad/param norm = 7.6851e-01, time/batch = 0.6943s	
417/22300 (epoch 0.935), train_loss = 2.45570039, grad/param norm = 6.5348e-01, time/batch = 0.6977s	
418/22300 (epoch 0.937), train_loss = 2.40882481, grad/param norm = 3.4021e-01, time/batch = 0.7002s	
419/22300 (epoch 0.939), train_loss = 2.41177998, grad/param norm = 2.7364e-01, time/batch = 0.6897s	
420/22300 (epoch 0.942), train_loss = 2.31021803, grad/param norm = 3.0420e-01, time/batch = 0.7184s	
421/22300 (epoch 0.944), train_loss = 2.50040695, grad/param norm = 4.0923e-01, time/batch = 0.7047s	
422/22300 (epoch 0.946), train_loss = 2.31268160, grad/param norm = 4.8440e-01, time/batch = 0.7023s	
423/22300 (epoch 0.948), train_loss = 2.31870427, grad/param norm = 4.8084e-01, time/batch = 0.6982s	
424/22300 (epoch 0.951), train_loss = 2.32191332, grad/param norm = 4.1519e-01, time/batch = 0.7011s	
425/22300 (epoch 0.953), train_loss = 2.34903054, grad/param norm = 3.9108e-01, time/batch = 0.7001s	
426/22300 (epoch 0.955), train_loss = 2.49258117, grad/param norm = 4.3324e-01, time/batch = 0.7024s	
427/22300 (epoch 0.957), train_loss = 2.34125983, grad/param norm = 4.5733e-01, time/batch = 0.6948s	
428/22300 (epoch 0.960), train_loss = 2.37628489, grad/param norm = 4.7506e-01, time/batch = 0.6965s	
429/22300 (epoch 0.962), train_loss = 2.28187070, grad/param norm = 2.8034e-01, time/batch = 0.6973s	
430/22300 (epoch 0.964), train_loss = 2.38227583, grad/param norm = 3.2965e-01, time/batch = 0.6962s	
431/22300 (epoch 0.966), train_loss = 2.42013233, grad/param norm = 3.4597e-01, time/batch = 0.7004s	
432/22300 (epoch 0.969), train_loss = 2.29172710, grad/param norm = 3.8298e-01, time/batch = 0.7076s	
433/22300 (epoch 0.971), train_loss = 2.30486071, grad/param norm = 4.9308e-01, time/batch = 0.7134s	
434/22300 (epoch 0.973), train_loss = 2.36861040, grad/param norm = 4.8760e-01, time/batch = 0.6961s	
435/22300 (epoch 0.975), train_loss = 2.42361302, grad/param norm = 4.3090e-01, time/batch = 0.6954s	
436/22300 (epoch 0.978), train_loss = 2.19873398, grad/param norm = 3.1511e-01, time/batch = 0.6856s	
437/22300 (epoch 0.980), train_loss = 2.43585206, grad/param norm = 4.1213e-01, time/batch = 0.6770s	
438/22300 (epoch 0.982), train_loss = 2.30657694, grad/param norm = 5.1213e-01, time/batch = 0.6837s	
439/22300 (epoch 0.984), train_loss = 2.38948346, grad/param norm = 6.9967e-01, time/batch = 0.6827s	
440/22300 (epoch 0.987), train_loss = 2.36272638, grad/param norm = 5.1021e-01, time/batch = 0.6948s	
441/22300 (epoch 0.989), train_loss = 2.41222907, grad/param norm = 4.1919e-01, time/batch = 0.7008s	
442/22300 (epoch 0.991), train_loss = 2.33599579, grad/param norm = 4.1122e-01, time/batch = 0.6963s	
443/22300 (epoch 0.993), train_loss = 2.35993999, grad/param norm = 3.6504e-01, time/batch = 0.6913s	
444/22300 (epoch 0.996), train_loss = 2.43904417, grad/param norm = 3.1833e-01, time/batch = 0.6948s	
445/22300 (epoch 0.998), train_loss = 2.40499147, grad/param norm = 3.6039e-01, time/batch = 0.6994s	
446/22300 (epoch 1.000), train_loss = 2.29781523, grad/param norm = 3.7907e-01, time/batch = 0.7174s	
447/22300 (epoch 1.002), train_loss = 2.28113467, grad/param norm = 4.3175e-01, time/batch = 0.7291s	
448/22300 (epoch 1.004), train_loss = 2.35004477, grad/param norm = 4.9438e-01, time/batch = 0.7056s	
449/22300 (epoch 1.007), train_loss = 2.34236681, grad/param norm = 4.1423e-01, time/batch = 0.6942s	
450/22300 (epoch 1.009), train_loss = 2.24845736, grad/param norm = 3.2694e-01, time/batch = 0.6954s	
451/22300 (epoch 1.011), train_loss = 2.38460219, grad/param norm = 4.0036e-01, time/batch = 0.6967s	
452/22300 (epoch 1.013), train_loss = 2.32866199, grad/param norm = 4.6286e-01, time/batch = 0.6944s	
453/22300 (epoch 1.016), train_loss = 2.34412980, grad/param norm = 4.7952e-01, time/batch = 0.6878s	
454/22300 (epoch 1.018), train_loss = 2.32010978, grad/param norm = 5.1337e-01, time/batch = 0.6934s	
455/22300 (epoch 1.020), train_loss = 2.24772506, grad/param norm = 3.8601e-01, time/batch = 0.6893s	
456/22300 (epoch 1.022), train_loss = 2.27251579, grad/param norm = 4.3829e-01, time/batch = 0.6855s	
457/22300 (epoch 1.025), train_loss = 2.33680811, grad/param norm = 6.5363e-01, time/batch = 0.6900s	
458/22300 (epoch 1.027), train_loss = 2.41175692, grad/param norm = 7.3964e-01, time/batch = 0.6951s	
459/22300 (epoch 1.029), train_loss = 2.29087075, grad/param norm = 5.1558e-01, time/batch = 0.6966s	
460/22300 (epoch 1.031), train_loss = 2.24349854, grad/param norm = 4.4035e-01, time/batch = 0.6973s	
461/22300 (epoch 1.034), train_loss = 2.27253653, grad/param norm = 3.8911e-01, time/batch = 0.6974s	
462/22300 (epoch 1.036), train_loss = 2.24707882, grad/param norm = 5.1601e-01, time/batch = 0.6931s	
463/22300 (epoch 1.038), train_loss = 2.30592411, grad/param norm = 4.5782e-01, time/batch = 0.6978s	
464/22300 (epoch 1.040), train_loss = 2.33937899, grad/param norm = 4.7499e-01, time/batch = 0.6968s	
465/22300 (epoch 1.043), train_loss = 2.38313366, grad/param norm = 4.2891e-01, time/batch = 0.6965s	
466/22300 (epoch 1.045), train_loss = 2.25215806, grad/param norm = 2.7989e-01, time/batch = 0.6954s	
467/22300 (epoch 1.047), train_loss = 2.36474970, grad/param norm = 3.2186e-01, time/batch = 0.6980s	
468/22300 (epoch 1.049), train_loss = 2.21112760, grad/param norm = 3.3022e-01, time/batch = 0.6993s	
469/22300 (epoch 1.052), train_loss = 2.40118460, grad/param norm = 3.6519e-01, time/batch = 0.7029s	
470/22300 (epoch 1.054), train_loss = 2.25378083, grad/param norm = 3.8038e-01, time/batch = 0.7079s	
471/22300 (epoch 1.056), train_loss = 2.30946880, grad/param norm = 4.0364e-01, time/batch = 0.7005s	
472/22300 (epoch 1.058), train_loss = 2.15811434, grad/param norm = 4.1225e-01, time/batch = 0.6940s	
473/22300 (epoch 1.061), train_loss = 2.23434814, grad/param norm = 4.7736e-01, time/batch = 0.6850s	
474/22300 (epoch 1.063), train_loss = 2.37263275, grad/param norm = 3.9086e-01, time/batch = 0.6906s	
475/22300 (epoch 1.065), train_loss = 2.20551036, grad/param norm = 4.7156e-01, time/batch = 0.6921s	
476/22300 (epoch 1.067), train_loss = 2.38387347, grad/param norm = 5.5886e-01, time/batch = 0.6924s	
477/22300 (epoch 1.070), train_loss = 2.36958895, grad/param norm = 6.8941e-01, time/batch = 0.6906s	
478/22300 (epoch 1.072), train_loss = 2.31977107, grad/param norm = 4.7695e-01, time/batch = 0.6900s	
479/22300 (epoch 1.074), train_loss = 2.35247968, grad/param norm = 3.7220e-01, time/batch = 0.6938s	
480/22300 (epoch 1.076), train_loss = 2.29109270, grad/param norm = 3.3986e-01, time/batch = 0.6892s	
481/22300 (epoch 1.078), train_loss = 2.21262852, grad/param norm = 3.1154e-01, time/batch = 0.6868s	
482/22300 (epoch 1.081), train_loss = 2.29648487, grad/param norm = 5.4628e-01, time/batch = 0.6922s	
483/22300 (epoch 1.083), train_loss = 2.33128022, grad/param norm = 5.5289e-01, time/batch = 0.6835s	
484/22300 (epoch 1.085), train_loss = 2.38238800, grad/param norm = 5.7852e-01, time/batch = 0.7241s	
485/22300 (epoch 1.087), train_loss = 2.40589786, grad/param norm = 6.0391e-01, time/batch = 0.7071s	
486/22300 (epoch 1.090), train_loss = 2.34820688, grad/param norm = 4.5349e-01, time/batch = 0.6994s	
487/22300 (epoch 1.092), train_loss = 2.35568331, grad/param norm = 3.1449e-01, time/batch = 0.6967s	
488/22300 (epoch 1.094), train_loss = 2.25488818, grad/param norm = 2.9392e-01, time/batch = 0.6936s	
489/22300 (epoch 1.096), train_loss = 2.46150272, grad/param norm = 3.2275e-01, time/batch = 0.6985s	
490/22300 (epoch 1.099), train_loss = 2.37328089, grad/param norm = 3.4509e-01, time/batch = 0.7017s	
491/22300 (epoch 1.101), train_loss = 2.43016644, grad/param norm = 3.6644e-01, time/batch = 0.6990s	
492/22300 (epoch 1.103), train_loss = 2.27539137, grad/param norm = 3.8289e-01, time/batch = 0.7011s	
493/22300 (epoch 1.105), train_loss = 2.26803145, grad/param norm = 4.3494e-01, time/batch = 0.6960s	
494/22300 (epoch 1.108), train_loss = 2.41753339, grad/param norm = 4.3205e-01, time/batch = 0.6954s	
495/22300 (epoch 1.110), train_loss = 2.28845457, grad/param norm = 3.2448e-01, time/batch = 0.6971s	
496/22300 (epoch 1.112), train_loss = 2.24653213, grad/param norm = 2.9381e-01, time/batch = 0.6913s	
497/22300 (epoch 1.114), train_loss = 2.38401493, grad/param norm = 4.4757e-01, time/batch = 0.6825s	
498/22300 (epoch 1.117), train_loss = 2.38432911, grad/param norm = 3.6207e-01, time/batch = 0.6891s	
499/22300 (epoch 1.119), train_loss = 2.37811687, grad/param norm = 4.5730e-01, time/batch = 0.7001s	
500/22300 (epoch 1.121), train_loss = 2.31523159, grad/param norm = 5.9332e-01, time/batch = 0.6979s	
501/22300 (epoch 1.123), train_loss = 2.10691214, grad/param norm = 4.8649e-01, time/batch = 0.7115s	
502/22300 (epoch 1.126), train_loss = 2.21573147, grad/param norm = 3.7203e-01, time/batch = 0.6916s	
503/22300 (epoch 1.128), train_loss = 2.24805888, grad/param norm = 2.9357e-01, time/batch = 0.6919s	
504/22300 (epoch 1.130), train_loss = 2.25166180, grad/param norm = 3.4951e-01, time/batch = 0.6942s	
505/22300 (epoch 1.132), train_loss = 2.27520496, grad/param norm = 2.9949e-01, time/batch = 0.7069s	
506/22300 (epoch 1.135), train_loss = 2.23825815, grad/param norm = 3.5213e-01, time/batch = 0.7016s	
507/22300 (epoch 1.137), train_loss = 2.19666582, grad/param norm = 4.4290e-01, time/batch = 0.6946s	
508/22300 (epoch 1.139), train_loss = 2.29940508, grad/param norm = 4.0890e-01, time/batch = 0.7066s	
509/22300 (epoch 1.141), train_loss = 2.42874136, grad/param norm = 2.7294e-01, time/batch = 0.7144s	
510/22300 (epoch 1.143), train_loss = 2.31354407, grad/param norm = 2.8782e-01, time/batch = 0.7252s	
511/22300 (epoch 1.146), train_loss = 2.27038807, grad/param norm = 3.6320e-01, time/batch = 0.7391s	
512/22300 (epoch 1.148), train_loss = 2.27527178, grad/param norm = 3.6537e-01, time/batch = 0.7249s	
513/22300 (epoch 1.150), train_loss = 2.34249055, grad/param norm = 3.5418e-01, time/batch = 0.7187s	
514/22300 (epoch 1.152), train_loss = 2.34080235, grad/param norm = 4.3948e-01, time/batch = 0.7208s	
515/22300 (epoch 1.155), train_loss = 2.26261532, grad/param norm = 3.7564e-01, time/batch = 0.7140s	
516/22300 (epoch 1.157), train_loss = 2.26173216, grad/param norm = 4.8530e-01, time/batch = 0.7058s	
517/22300 (epoch 1.159), train_loss = 2.26218755, grad/param norm = 3.0575e-01, time/batch = 0.7029s	
518/22300 (epoch 1.161), train_loss = 2.28232748, grad/param norm = 3.3910e-01, time/batch = 0.7074s	
519/22300 (epoch 1.164), train_loss = 2.25933286, grad/param norm = 3.4553e-01, time/batch = 0.7328s	
520/22300 (epoch 1.166), train_loss = 2.31233280, grad/param norm = 2.5899e-01, time/batch = 0.7276s	
521/22300 (epoch 1.168), train_loss = 2.29257671, grad/param norm = 2.4934e-01, time/batch = 0.7020s	
522/22300 (epoch 1.170), train_loss = 2.31877087, grad/param norm = 3.2116e-01, time/batch = 0.6996s	
523/22300 (epoch 1.173), train_loss = 2.33198581, grad/param norm = 3.2699e-01, time/batch = 0.7017s	
524/22300 (epoch 1.175), train_loss = 2.25578429, grad/param norm = 3.2744e-01, time/batch = 0.7053s	
525/22300 (epoch 1.177), train_loss = 2.21669049, grad/param norm = 4.2470e-01, time/batch = 0.7082s	
526/22300 (epoch 1.179), train_loss = 2.20186175, grad/param norm = 5.3853e-01, time/batch = 0.6937s	
527/22300 (epoch 1.182), train_loss = 2.32349020, grad/param norm = 5.9242e-01, time/batch = 0.6924s	
528/22300 (epoch 1.184), train_loss = 2.41284180, grad/param norm = 4.5280e-01, time/batch = 0.6916s	
529/22300 (epoch 1.186), train_loss = 2.25040467, grad/param norm = 4.1546e-01, time/batch = 0.6901s	
530/22300 (epoch 1.188), train_loss = 2.35640147, grad/param norm = 3.8103e-01, time/batch = 0.6916s	
531/22300 (epoch 1.191), train_loss = 2.30140025, grad/param norm = 3.9905e-01, time/batch = 0.6964s	
532/22300 (epoch 1.193), train_loss = 2.19423715, grad/param norm = 4.4958e-01, time/batch = 0.6924s	
533/22300 (epoch 1.195), train_loss = 2.24312285, grad/param norm = 4.1941e-01, time/batch = 0.6923s	
534/22300 (epoch 1.197), train_loss = 2.27284560, grad/param norm = 4.1044e-01, time/batch = 0.6874s	
535/22300 (epoch 1.200), train_loss = 2.23630419, grad/param norm = 3.4970e-01, time/batch = 0.6934s	
536/22300 (epoch 1.202), train_loss = 2.22078448, grad/param norm = 3.6003e-01, time/batch = 0.7035s	
537/22300 (epoch 1.204), train_loss = 2.24751090, grad/param norm = 3.7144e-01, time/batch = 0.6960s	
538/22300 (epoch 1.206), train_loss = 2.14371700, grad/param norm = 2.9872e-01, time/batch = 0.7031s	
539/22300 (epoch 1.209), train_loss = 2.26583760, grad/param norm = 3.2657e-01, time/batch = 0.6951s	
540/22300 (epoch 1.211), train_loss = 2.22244765, grad/param norm = 4.0738e-01, time/batch = 0.6920s	
541/22300 (epoch 1.213), train_loss = 2.26487499, grad/param norm = 4.2137e-01, time/batch = 0.6958s	
542/22300 (epoch 1.215), train_loss = 2.36380335, grad/param norm = 3.5964e-01, time/batch = 0.6935s	
543/22300 (epoch 1.217), train_loss = 2.30609195, grad/param norm = 2.8589e-01, time/batch = 0.6917s	
544/22300 (epoch 1.220), train_loss = 2.21755106, grad/param norm = 3.2694e-01, time/batch = 0.6894s	
545/22300 (epoch 1.222), train_loss = 2.24520445, grad/param norm = 3.5168e-01, time/batch = 0.6909s	
546/22300 (epoch 1.224), train_loss = 2.15507159, grad/param norm = 3.8413e-01, time/batch = 0.6896s	
547/22300 (epoch 1.226), train_loss = 2.28501736, grad/param norm = 4.8234e-01, time/batch = 0.6943s	
548/22300 (epoch 1.229), train_loss = 2.32677869, grad/param norm = 4.1321e-01, time/batch = 0.6887s	
549/22300 (epoch 1.231), train_loss = 2.26826837, grad/param norm = 3.7185e-01, time/batch = 0.6899s	
550/22300 (epoch 1.233), train_loss = 2.35990119, grad/param norm = 3.4346e-01, time/batch = 0.6973s	
551/22300 (epoch 1.235), train_loss = 2.19694476, grad/param norm = 3.4310e-01, time/batch = 0.6911s	
552/22300 (epoch 1.238), train_loss = 2.19177940, grad/param norm = 3.3976e-01, time/batch = 0.6902s	
553/22300 (epoch 1.240), train_loss = 2.12926660, grad/param norm = 2.6474e-01, time/batch = 0.6887s	
554/22300 (epoch 1.242), train_loss = 2.29446976, grad/param norm = 2.8410e-01, time/batch = 0.6930s	
555/22300 (epoch 1.244), train_loss = 2.12263179, grad/param norm = 3.5133e-01, time/batch = 0.7005s	
556/22300 (epoch 1.247), train_loss = 2.29816211, grad/param norm = 4.0116e-01, time/batch = 0.6912s	
557/22300 (epoch 1.249), train_loss = 2.14291204, grad/param norm = 3.7310e-01, time/batch = 0.6881s	
558/22300 (epoch 1.251), train_loss = 2.16258363, grad/param norm = 3.4373e-01, time/batch = 0.6875s	
559/22300 (epoch 1.253), train_loss = 2.27085461, grad/param norm = 2.5073e-01, time/batch = 0.6906s	
560/22300 (epoch 1.256), train_loss = 2.37663353, grad/param norm = 3.0300e-01, time/batch = 0.6914s	
561/22300 (epoch 1.258), train_loss = 2.26002112, grad/param norm = 3.7288e-01, time/batch = 0.6967s	
562/22300 (epoch 1.260), train_loss = 2.26999931, grad/param norm = 5.4085e-01, time/batch = 0.6884s	
563/22300 (epoch 1.262), train_loss = 2.35003164, grad/param norm = 5.2775e-01, time/batch = 0.6824s	
564/22300 (epoch 1.265), train_loss = 2.27178659, grad/param norm = 4.8441e-01, time/batch = 0.6962s	
565/22300 (epoch 1.267), train_loss = 2.22251396, grad/param norm = 5.6624e-01, time/batch = 0.6920s	
566/22300 (epoch 1.269), train_loss = 2.16226511, grad/param norm = 3.8406e-01, time/batch = 0.6905s	
567/22300 (epoch 1.271), train_loss = 2.31519518, grad/param norm = 3.0348e-01, time/batch = 0.6886s	
568/22300 (epoch 1.274), train_loss = 2.14388373, grad/param norm = 2.8879e-01, time/batch = 0.6866s	
569/22300 (epoch 1.276), train_loss = 2.14700120, grad/param norm = 2.9702e-01, time/batch = 0.6903s	
570/22300 (epoch 1.278), train_loss = 2.18020540, grad/param norm = 3.0862e-01, time/batch = 0.6895s	
571/22300 (epoch 1.280), train_loss = 2.21485181, grad/param norm = 3.7546e-01, time/batch = 0.6943s	
572/22300 (epoch 1.283), train_loss = 2.17928986, grad/param norm = 3.7543e-01, time/batch = 0.6918s	
573/22300 (epoch 1.285), train_loss = 2.20968604, grad/param norm = 3.2693e-01, time/batch = 0.6911s	
574/22300 (epoch 1.287), train_loss = 2.10084598, grad/param norm = 2.5156e-01, time/batch = 0.6872s	
575/22300 (epoch 1.289), train_loss = 2.25417390, grad/param norm = 4.5023e-01, time/batch = 0.6872s	
576/22300 (epoch 1.291), train_loss = 2.24546722, grad/param norm = 5.8882e-01, time/batch = 0.6954s	
577/22300 (epoch 1.294), train_loss = 2.28417696, grad/param norm = 6.6837e-01, time/batch = 0.6946s	
578/22300 (epoch 1.296), train_loss = 2.36620246, grad/param norm = 4.5817e-01, time/batch = 0.6936s	
579/22300 (epoch 1.298), train_loss = 2.28982831, grad/param norm = 2.8245e-01, time/batch = 0.6910s	
580/22300 (epoch 1.300), train_loss = 2.27360657, grad/param norm = 2.6627e-01, time/batch = 0.6898s	
581/22300 (epoch 1.303), train_loss = 2.28125403, grad/param norm = 3.0895e-01, time/batch = 0.6963s	
582/22300 (epoch 1.305), train_loss = 2.31810811, grad/param norm = 4.4496e-01, time/batch = 0.6914s	
583/22300 (epoch 1.307), train_loss = 2.35544019, grad/param norm = 4.2765e-01, time/batch = 0.6899s	
584/22300 (epoch 1.309), train_loss = 2.25809102, grad/param norm = 3.8806e-01, time/batch = 0.6926s	
585/22300 (epoch 1.312), train_loss = 2.18751398, grad/param norm = 4.7724e-01, time/batch = 0.6924s	
586/22300 (epoch 1.314), train_loss = 2.20592319, grad/param norm = 3.1954e-01, time/batch = 0.6920s	
587/22300 (epoch 1.316), train_loss = 2.19543408, grad/param norm = 3.0406e-01, time/batch = 0.6989s	
588/22300 (epoch 1.318), train_loss = 2.39642772, grad/param norm = 4.7278e-01, time/batch = 0.6911s	
589/22300 (epoch 1.321), train_loss = 2.29269097, grad/param norm = 4.4361e-01, time/batch = 0.6907s	
590/22300 (epoch 1.323), train_loss = 2.20676729, grad/param norm = 2.6115e-01, time/batch = 0.6932s	
591/22300 (epoch 1.325), train_loss = 2.17479225, grad/param norm = 2.8120e-01, time/batch = 0.7008s	
592/22300 (epoch 1.327), train_loss = 2.20046500, grad/param norm = 3.0318e-01, time/batch = 0.6961s	
593/22300 (epoch 1.330), train_loss = 2.28323851, grad/param norm = 2.4467e-01, time/batch = 0.6870s	
594/22300 (epoch 1.332), train_loss = 2.25760334, grad/param norm = 3.4202e-01, time/batch = 0.7181s	
595/22300 (epoch 1.334), train_loss = 2.17714044, grad/param norm = 3.0112e-01, time/batch = 0.6929s	
596/22300 (epoch 1.336), train_loss = 2.11489319, grad/param norm = 3.0664e-01, time/batch = 0.6808s	
597/22300 (epoch 1.339), train_loss = 2.24040344, grad/param norm = 3.5230e-01, time/batch = 0.6847s	
598/22300 (epoch 1.341), train_loss = 2.17228779, grad/param norm = 3.6106e-01, time/batch = 0.6967s	
599/22300 (epoch 1.343), train_loss = 2.18227277, grad/param norm = 3.3920e-01, time/batch = 0.6848s	
600/22300 (epoch 1.345), train_loss = 2.22837114, grad/param norm = 3.2863e-01, time/batch = 0.6803s	
601/22300 (epoch 1.348), train_loss = 2.20409620, grad/param norm = 3.4187e-01, time/batch = 0.6874s	
602/22300 (epoch 1.350), train_loss = 2.20341940, grad/param norm = 3.2446e-01, time/batch = 0.6832s	
603/22300 (epoch 1.352), train_loss = 2.23662440, grad/param norm = 3.4658e-01, time/batch = 0.6835s	
604/22300 (epoch 1.354), train_loss = 2.19857637, grad/param norm = 3.6550e-01, time/batch = 0.6796s	
605/22300 (epoch 1.357), train_loss = 2.35868360, grad/param norm = 2.8670e-01, time/batch = 0.6813s	
606/22300 (epoch 1.359), train_loss = 2.21674998, grad/param norm = 3.2747e-01, time/batch = 0.6780s	
607/22300 (epoch 1.361), train_loss = 2.24662301, grad/param norm = 3.2220e-01, time/batch = 0.6777s	
608/22300 (epoch 1.363), train_loss = 2.51016395, grad/param norm = 3.6471e-01, time/batch = 0.6828s	
609/22300 (epoch 1.365), train_loss = 2.26694597, grad/param norm = 4.1674e-01, time/batch = 0.6856s	
610/22300 (epoch 1.368), train_loss = 2.19411040, grad/param norm = 3.2634e-01, time/batch = 0.6902s	
611/22300 (epoch 1.370), train_loss = 2.12764979, grad/param norm = 3.0848e-01, time/batch = 0.6900s	
612/22300 (epoch 1.372), train_loss = 2.09770032, grad/param norm = 4.6562e-01, time/batch = 0.6819s	
613/22300 (epoch 1.374), train_loss = 2.27967113, grad/param norm = 5.0157e-01, time/batch = 0.6773s	
614/22300 (epoch 1.377), train_loss = 2.23328649, grad/param norm = 4.5934e-01, time/batch = 0.6845s	
615/22300 (epoch 1.379), train_loss = 2.17284615, grad/param norm = 4.4363e-01, time/batch = 0.7168s	
616/22300 (epoch 1.381), train_loss = 2.24528705, grad/param norm = 4.7271e-01, time/batch = 0.6807s	
617/22300 (epoch 1.383), train_loss = 2.12783989, grad/param norm = 5.1458e-01, time/batch = 0.6841s	
618/22300 (epoch 1.386), train_loss = 2.13749920, grad/param norm = 4.6488e-01, time/batch = 0.6802s	
619/22300 (epoch 1.388), train_loss = 2.16658909, grad/param norm = 2.9035e-01, time/batch = 0.6938s	
620/22300 (epoch 1.390), train_loss = 2.23351029, grad/param norm = 3.0610e-01, time/batch = 0.6932s	
621/22300 (epoch 1.392), train_loss = 2.12038583, grad/param norm = 3.0716e-01, time/batch = 0.6953s	
622/22300 (epoch 1.395), train_loss = 2.12688670, grad/param norm = 2.6765e-01, time/batch = 0.6931s	
623/22300 (epoch 1.397), train_loss = 2.10743028, grad/param norm = 2.8528e-01, time/batch = 0.6946s	
624/22300 (epoch 1.399), train_loss = 2.27141696, grad/param norm = 3.6958e-01, time/batch = 0.6979s	
625/22300 (epoch 1.401), train_loss = 2.24745106, grad/param norm = 3.8631e-01, time/batch = 0.6930s	
626/22300 (epoch 1.404), train_loss = 2.33722657, grad/param norm = 3.3352e-01, time/batch = 0.6900s	
627/22300 (epoch 1.406), train_loss = 2.27141674, grad/param norm = 2.8449e-01, time/batch = 0.6938s	
628/22300 (epoch 1.408), train_loss = 2.17683331, grad/param norm = 2.8369e-01, time/batch = 0.6926s	
629/22300 (epoch 1.410), train_loss = 2.13918692, grad/param norm = 3.8815e-01, time/batch = 0.6943s	
630/22300 (epoch 1.413), train_loss = 2.32836958, grad/param norm = 3.3455e-01, time/batch = 0.6929s	
631/22300 (epoch 1.415), train_loss = 2.20003385, grad/param norm = 4.5402e-01, time/batch = 0.6980s	
632/22300 (epoch 1.417), train_loss = 2.31706966, grad/param norm = 4.3039e-01, time/batch = 0.6787s	
633/22300 (epoch 1.419), train_loss = 2.08986940, grad/param norm = 3.3452e-01, time/batch = 0.6895s	
634/22300 (epoch 1.422), train_loss = 2.07398666, grad/param norm = 2.8595e-01, time/batch = 0.6937s	
635/22300 (epoch 1.424), train_loss = 2.20135460, grad/param norm = 3.3360e-01, time/batch = 0.6952s	
636/22300 (epoch 1.426), train_loss = 2.24726649, grad/param norm = 4.9756e-01, time/batch = 0.6926s	
637/22300 (epoch 1.428), train_loss = 2.24205442, grad/param norm = 5.7803e-01, time/batch = 0.6936s	
638/22300 (epoch 1.430), train_loss = 2.17225460, grad/param norm = 4.3737e-01, time/batch = 0.6879s	
639/22300 (epoch 1.433), train_loss = 2.08082099, grad/param norm = 4.2283e-01, time/batch = 0.6939s	
640/22300 (epoch 1.435), train_loss = 2.22413264, grad/param norm = 3.4004e-01, time/batch = 0.6949s	
641/22300 (epoch 1.437), train_loss = 2.13075775, grad/param norm = 2.6585e-01, time/batch = 0.6916s	
642/22300 (epoch 1.439), train_loss = 2.16051149, grad/param norm = 3.2619e-01, time/batch = 0.6751s	
643/22300 (epoch 1.442), train_loss = 2.22024028, grad/param norm = 3.7507e-01, time/batch = 0.6918s	
644/22300 (epoch 1.444), train_loss = 2.36525999, grad/param norm = 3.3607e-01, time/batch = 0.6938s	
645/22300 (epoch 1.446), train_loss = 2.14415536, grad/param norm = 3.1633e-01, time/batch = 0.6967s	
646/22300 (epoch 1.448), train_loss = 2.10848936, grad/param norm = 3.1120e-01, time/batch = 0.6930s	
647/22300 (epoch 1.451), train_loss = 2.16723132, grad/param norm = 2.9563e-01, time/batch = 0.6942s	
648/22300 (epoch 1.453), train_loss = 2.13423765, grad/param norm = 3.2103e-01, time/batch = 0.6930s	
649/22300 (epoch 1.455), train_loss = 2.12281618, grad/param norm = 2.6554e-01, time/batch = 0.6980s	
650/22300 (epoch 1.457), train_loss = 2.12659840, grad/param norm = 3.9520e-01, time/batch = 0.7047s	
651/22300 (epoch 1.460), train_loss = 2.12009793, grad/param norm = 3.6872e-01, time/batch = 0.6981s	
652/22300 (epoch 1.462), train_loss = 2.10860499, grad/param norm = 2.7786e-01, time/batch = 0.6875s	
653/22300 (epoch 1.464), train_loss = 2.15029321, grad/param norm = 3.1000e-01, time/batch = 0.6917s	
654/22300 (epoch 1.466), train_loss = 2.14220270, grad/param norm = 2.8263e-01, time/batch = 0.6966s	
655/22300 (epoch 1.469), train_loss = 2.12607406, grad/param norm = 2.5432e-01, time/batch = 0.7000s	
656/22300 (epoch 1.471), train_loss = 2.22288146, grad/param norm = 2.4888e-01, time/batch = 0.7031s	
657/22300 (epoch 1.473), train_loss = 2.28912753, grad/param norm = 2.6843e-01, time/batch = 0.6939s	
658/22300 (epoch 1.475), train_loss = 2.06732228, grad/param norm = 2.6198e-01, time/batch = 0.6985s	
659/22300 (epoch 1.478), train_loss = 2.11957520, grad/param norm = 3.2492e-01, time/batch = 0.6984s	
660/22300 (epoch 1.480), train_loss = 2.23916438, grad/param norm = 3.8095e-01, time/batch = 0.7067s	
661/22300 (epoch 1.482), train_loss = 2.14401379, grad/param norm = 3.6102e-01, time/batch = 0.7075s	
662/22300 (epoch 1.484), train_loss = 2.10834284, grad/param norm = 4.0889e-01, time/batch = 0.7016s	
663/22300 (epoch 1.487), train_loss = 2.14086450, grad/param norm = 3.1775e-01, time/batch = 0.6979s	
664/22300 (epoch 1.489), train_loss = 2.20666644, grad/param norm = 2.7143e-01, time/batch = 0.6968s	
665/22300 (epoch 1.491), train_loss = 2.14778970, grad/param norm = 3.5017e-01, time/batch = 0.6959s	
666/22300 (epoch 1.493), train_loss = 2.28120837, grad/param norm = 4.6738e-01, time/batch = 0.6937s	
667/22300 (epoch 1.496), train_loss = 2.19530754, grad/param norm = 5.0971e-01, time/batch = 0.6945s	
668/22300 (epoch 1.498), train_loss = 2.20041027, grad/param norm = 4.2009e-01, time/batch = 0.6905s	
669/22300 (epoch 1.500), train_loss = 2.06779851, grad/param norm = 3.2743e-01, time/batch = 0.6918s	
670/22300 (epoch 1.502), train_loss = 2.16057339, grad/param norm = 3.3766e-01, time/batch = 0.6924s	
671/22300 (epoch 1.504), train_loss = 2.24091513, grad/param norm = 3.6308e-01, time/batch = 0.7023s	
672/22300 (epoch 1.507), train_loss = 2.06552493, grad/param norm = 3.1281e-01, time/batch = 0.7048s	
673/22300 (epoch 1.509), train_loss = 2.17121616, grad/param norm = 2.6711e-01, time/batch = 0.6937s	
674/22300 (epoch 1.511), train_loss = 2.10991555, grad/param norm = 3.0403e-01, time/batch = 0.6942s	
675/22300 (epoch 1.513), train_loss = 2.12726924, grad/param norm = 3.3699e-01, time/batch = 0.6968s	
676/22300 (epoch 1.516), train_loss = 2.26709930, grad/param norm = 3.5074e-01, time/batch = 0.6904s	
677/22300 (epoch 1.518), train_loss = 2.16446940, grad/param norm = 3.5096e-01, time/batch = 0.7116s	
678/22300 (epoch 1.520), train_loss = 2.27781265, grad/param norm = 3.0715e-01, time/batch = 0.6972s	
679/22300 (epoch 1.522), train_loss = 2.13664896, grad/param norm = 2.4029e-01, time/batch = 0.6935s	
680/22300 (epoch 1.525), train_loss = 2.15671355, grad/param norm = 3.0574e-01, time/batch = 0.6935s	
681/22300 (epoch 1.527), train_loss = 2.35693459, grad/param norm = 2.8393e-01, time/batch = 0.6991s	
682/22300 (epoch 1.529), train_loss = 2.14336737, grad/param norm = 3.3300e-01, time/batch = 0.7103s	
683/22300 (epoch 1.531), train_loss = 2.10294494, grad/param norm = 4.0220e-01, time/batch = 0.6984s	
684/22300 (epoch 1.534), train_loss = 2.15654556, grad/param norm = 4.9211e-01, time/batch = 0.6939s	
685/22300 (epoch 1.536), train_loss = 2.26693487, grad/param norm = 3.7603e-01, time/batch = 0.6938s	
686/22300 (epoch 1.538), train_loss = 2.38079964, grad/param norm = 2.8280e-01, time/batch = 0.6918s	
687/22300 (epoch 1.540), train_loss = 2.24318659, grad/param norm = 2.7079e-01, time/batch = 0.6912s	
688/22300 (epoch 1.543), train_loss = 2.10473062, grad/param norm = 2.5160e-01, time/batch = 0.7045s	
689/22300 (epoch 1.545), train_loss = 2.15706067, grad/param norm = 2.7433e-01, time/batch = 0.6957s	
690/22300 (epoch 1.547), train_loss = 2.26857694, grad/param norm = 3.3382e-01, time/batch = 0.7217s	
691/22300 (epoch 1.549), train_loss = 2.16145841, grad/param norm = 3.6504e-01, time/batch = 0.7307s	
692/22300 (epoch 1.552), train_loss = 2.11149227, grad/param norm = 3.5358e-01, time/batch = 0.7030s	
693/22300 (epoch 1.554), train_loss = 2.14074265, grad/param norm = 4.3459e-01, time/batch = 0.7203s	
694/22300 (epoch 1.556), train_loss = 2.31948686, grad/param norm = 4.2221e-01, time/batch = 0.7266s	
695/22300 (epoch 1.558), train_loss = 2.14077107, grad/param norm = 4.3892e-01, time/batch = 0.7221s	
696/22300 (epoch 1.561), train_loss = 2.26558576, grad/param norm = 3.4553e-01, time/batch = 0.7056s	
697/22300 (epoch 1.563), train_loss = 2.08879036, grad/param norm = 3.1108e-01, time/batch = 0.6989s	
698/22300 (epoch 1.565), train_loss = 2.20593943, grad/param norm = 2.9418e-01, time/batch = 0.7032s	
699/22300 (epoch 1.567), train_loss = 2.13481556, grad/param norm = 2.7668e-01, time/batch = 0.7100s	
700/22300 (epoch 1.570), train_loss = 2.21910795, grad/param norm = 2.9537e-01, time/batch = 0.6956s	
701/22300 (epoch 1.572), train_loss = 2.21483239, grad/param norm = 2.9306e-01, time/batch = 0.7178s	
702/22300 (epoch 1.574), train_loss = 2.03794827, grad/param norm = 2.8786e-01, time/batch = 0.7277s	
703/22300 (epoch 1.576), train_loss = 2.12658452, grad/param norm = 3.3940e-01, time/batch = 0.7424s	
704/22300 (epoch 1.578), train_loss = 2.03683217, grad/param norm = 3.9657e-01, time/batch = 0.7357s	
705/22300 (epoch 1.581), train_loss = 2.04212876, grad/param norm = 3.4169e-01, time/batch = 0.7374s	
706/22300 (epoch 1.583), train_loss = 2.19563230, grad/param norm = 3.4594e-01, time/batch = 0.7020s	
707/22300 (epoch 1.585), train_loss = 2.23476067, grad/param norm = 2.9556e-01, time/batch = 0.6855s	
708/22300 (epoch 1.587), train_loss = 2.14228284, grad/param norm = 2.9190e-01, time/batch = 0.6796s	
709/22300 (epoch 1.590), train_loss = 2.15858032, grad/param norm = 3.0216e-01, time/batch = 0.6940s	
710/22300 (epoch 1.592), train_loss = 2.31609417, grad/param norm = 3.7186e-01, time/batch = 0.6915s	
711/22300 (epoch 1.594), train_loss = 2.12233504, grad/param norm = 3.6363e-01, time/batch = 0.6966s	
712/22300 (epoch 1.596), train_loss = 2.21638064, grad/param norm = 3.2481e-01, time/batch = 0.6938s	
713/22300 (epoch 1.599), train_loss = 2.03032007, grad/param norm = 3.5478e-01, time/batch = 0.6886s	
714/22300 (epoch 1.601), train_loss = 2.11954708, grad/param norm = 3.1817e-01, time/batch = 0.6921s	
715/22300 (epoch 1.603), train_loss = 2.09510949, grad/param norm = 2.7065e-01, time/batch = 0.6992s	
716/22300 (epoch 1.605), train_loss = 2.07773366, grad/param norm = 2.9457e-01, time/batch = 0.6805s	
717/22300 (epoch 1.608), train_loss = 2.16679508, grad/param norm = 3.2264e-01, time/batch = 0.6799s	
718/22300 (epoch 1.610), train_loss = 2.08551200, grad/param norm = 2.9837e-01, time/batch = 0.6768s	
719/22300 (epoch 1.612), train_loss = 2.17382289, grad/param norm = 3.1920e-01, time/batch = 0.6804s	
720/22300 (epoch 1.614), train_loss = 2.16664492, grad/param norm = 2.6869e-01, time/batch = 0.6804s	
721/22300 (epoch 1.617), train_loss = 2.21802019, grad/param norm = 2.8274e-01, time/batch = 0.6757s	
722/22300 (epoch 1.619), train_loss = 2.26328126, grad/param norm = 2.8105e-01, time/batch = 0.6611s	
723/22300 (epoch 1.621), train_loss = 1.95175639, grad/param norm = 2.9144e-01, time/batch = 0.6593s	
724/22300 (epoch 1.623), train_loss = 2.08234969, grad/param norm = 3.0863e-01, time/batch = 0.6606s	
725/22300 (epoch 1.626), train_loss = 2.03996300, grad/param norm = 3.6652e-01, time/batch = 0.6687s	
726/22300 (epoch 1.628), train_loss = 2.14863443, grad/param norm = 3.9307e-01, time/batch = 0.7160s	
727/22300 (epoch 1.630), train_loss = 2.14435764, grad/param norm = 3.1942e-01, time/batch = 0.6822s	
728/22300 (epoch 1.632), train_loss = 2.17617247, grad/param norm = 3.0232e-01, time/batch = 0.6827s	
729/22300 (epoch 1.635), train_loss = 2.08439853, grad/param norm = 3.0920e-01, time/batch = 0.6788s	
730/22300 (epoch 1.637), train_loss = 2.20730051, grad/param norm = 3.3253e-01, time/batch = 0.6792s	
731/22300 (epoch 1.639), train_loss = 2.11724762, grad/param norm = 3.5711e-01, time/batch = 0.6809s	
732/22300 (epoch 1.641), train_loss = 2.18536771, grad/param norm = 3.1765e-01, time/batch = 0.6770s	
733/22300 (epoch 1.643), train_loss = 2.07870760, grad/param norm = 3.2857e-01, time/batch = 0.6800s	
734/22300 (epoch 1.646), train_loss = 2.11238323, grad/param norm = 4.2227e-01, time/batch = 0.6762s	
735/22300 (epoch 1.648), train_loss = 2.09985303, grad/param norm = 3.5707e-01, time/batch = 0.6760s	
736/22300 (epoch 1.650), train_loss = 2.28701416, grad/param norm = 2.5321e-01, time/batch = 0.6755s	
737/22300 (epoch 1.652), train_loss = 2.12325120, grad/param norm = 2.6774e-01, time/batch = 0.6760s	
738/22300 (epoch 1.655), train_loss = 2.11503860, grad/param norm = 2.8896e-01, time/batch = 0.6762s	
739/22300 (epoch 1.657), train_loss = 2.15953444, grad/param norm = 2.9043e-01, time/batch = 0.6745s	
740/22300 (epoch 1.659), train_loss = 2.04889723, grad/param norm = 4.3592e-01, time/batch = 0.6888s	
741/22300 (epoch 1.661), train_loss = 2.18224297, grad/param norm = 4.6545e-01, time/batch = 0.6928s	
742/22300 (epoch 1.664), train_loss = 2.10775716, grad/param norm = 3.5773e-01, time/batch = 0.6850s	
743/22300 (epoch 1.666), train_loss = 2.20334812, grad/param norm = 2.7464e-01, time/batch = 0.6834s	
744/22300 (epoch 1.668), train_loss = 2.18533343, grad/param norm = 3.0820e-01, time/batch = 0.6805s	
745/22300 (epoch 1.670), train_loss = 2.19189891, grad/param norm = 2.7054e-01, time/batch = 0.6809s	
746/22300 (epoch 1.673), train_loss = 2.24078327, grad/param norm = 2.8790e-01, time/batch = 0.6797s	
747/22300 (epoch 1.675), train_loss = 2.16944393, grad/param norm = 2.7196e-01, time/batch = 0.6815s	
748/22300 (epoch 1.677), train_loss = 2.19258405, grad/param norm = 3.1228e-01, time/batch = 0.6808s	
749/22300 (epoch 1.679), train_loss = 2.15374130, grad/param norm = 3.1002e-01, time/batch = 0.6796s	
750/22300 (epoch 1.682), train_loss = 2.11208130, grad/param norm = 2.9003e-01, time/batch = 0.6808s	
751/22300 (epoch 1.684), train_loss = 2.12020182, grad/param norm = 2.9236e-01, time/batch = 0.6869s	
752/22300 (epoch 1.686), train_loss = 2.16683619, grad/param norm = 3.0247e-01, time/batch = 0.6725s	
753/22300 (epoch 1.688), train_loss = 2.22824046, grad/param norm = 3.1716e-01, time/batch = 0.6722s	
754/22300 (epoch 1.691), train_loss = 2.22356179, grad/param norm = 3.6022e-01, time/batch = 0.6583s	
755/22300 (epoch 1.693), train_loss = 2.19765496, grad/param norm = 3.9250e-01, time/batch = 0.6733s	
756/22300 (epoch 1.695), train_loss = 2.13456260, grad/param norm = 3.6312e-01, time/batch = 0.6751s	
757/22300 (epoch 1.697), train_loss = 2.03983576, grad/param norm = 3.0372e-01, time/batch = 0.6756s	
758/22300 (epoch 1.700), train_loss = 2.16423944, grad/param norm = 2.5205e-01, time/batch = 0.6792s	
759/22300 (epoch 1.702), train_loss = 2.11302621, grad/param norm = 2.5146e-01, time/batch = 0.6752s	
760/22300 (epoch 1.704), train_loss = 2.19010670, grad/param norm = 2.4767e-01, time/batch = 0.6763s	
761/22300 (epoch 1.706), train_loss = 2.12481715, grad/param norm = 2.6078e-01, time/batch = 0.6822s	
762/22300 (epoch 1.709), train_loss = 2.07511970, grad/param norm = 2.8477e-01, time/batch = 0.6762s	
763/22300 (epoch 1.711), train_loss = 2.22294633, grad/param norm = 3.6272e-01, time/batch = 0.6818s	
764/22300 (epoch 1.713), train_loss = 2.06752380, grad/param norm = 4.1226e-01, time/batch = 0.7106s	
765/22300 (epoch 1.715), train_loss = 2.19296535, grad/param norm = 3.9461e-01, time/batch = 0.7091s	
766/22300 (epoch 1.717), train_loss = 2.24243020, grad/param norm = 4.2002e-01, time/batch = 0.6804s	
767/22300 (epoch 1.720), train_loss = 2.18619390, grad/param norm = 3.6890e-01, time/batch = 0.7083s	
768/22300 (epoch 1.722), train_loss = 2.19640419, grad/param norm = 3.8480e-01, time/batch = 0.7080s	
769/22300 (epoch 1.724), train_loss = 2.18934090, grad/param norm = 3.5512e-01, time/batch = 0.6819s	
770/22300 (epoch 1.726), train_loss = 2.17431803, grad/param norm = 2.9852e-01, time/batch = 0.6839s	
771/22300 (epoch 1.729), train_loss = 2.17407947, grad/param norm = 2.4243e-01, time/batch = 0.6855s	
772/22300 (epoch 1.731), train_loss = 2.16450398, grad/param norm = 2.8907e-01, time/batch = 0.6939s	
773/22300 (epoch 1.733), train_loss = 2.15694137, grad/param norm = 3.1488e-01, time/batch = 0.6838s	
774/22300 (epoch 1.735), train_loss = 2.12830166, grad/param norm = 3.2782e-01, time/batch = 0.6843s	
775/22300 (epoch 1.738), train_loss = 2.11399824, grad/param norm = 3.2255e-01, time/batch = 0.6887s	
776/22300 (epoch 1.740), train_loss = 2.01289850, grad/param norm = 2.5261e-01, time/batch = 0.6787s	
777/22300 (epoch 1.742), train_loss = 2.12547547, grad/param norm = 2.8110e-01, time/batch = 0.6836s	
778/22300 (epoch 1.744), train_loss = 2.11305166, grad/param norm = 3.7499e-01, time/batch = 0.6756s	
779/22300 (epoch 1.747), train_loss = 2.16799824, grad/param norm = 4.4430e-01, time/batch = 0.6746s	
780/22300 (epoch 1.749), train_loss = 2.22183307, grad/param norm = 3.3324e-01, time/batch = 0.6766s	
781/22300 (epoch 1.751), train_loss = 2.19009130, grad/param norm = 2.7040e-01, time/batch = 0.6797s	
782/22300 (epoch 1.753), train_loss = 2.16064864, grad/param norm = 2.7821e-01, time/batch = 0.6789s	
783/22300 (epoch 1.756), train_loss = 2.16383305, grad/param norm = 3.2122e-01, time/batch = 0.6779s	
784/22300 (epoch 1.758), train_loss = 2.02112829, grad/param norm = 2.7330e-01, time/batch = 0.6673s	
785/22300 (epoch 1.760), train_loss = 2.07551609, grad/param norm = 2.9722e-01, time/batch = 0.6721s	
786/22300 (epoch 1.762), train_loss = 2.16280304, grad/param norm = 3.0894e-01, time/batch = 0.6744s	
787/22300 (epoch 1.765), train_loss = 2.15511972, grad/param norm = 2.9643e-01, time/batch = 0.6773s	
788/22300 (epoch 1.767), train_loss = 2.17780734, grad/param norm = 3.3031e-01, time/batch = 0.6744s	
789/22300 (epoch 1.769), train_loss = 2.14785538, grad/param norm = 3.1457e-01, time/batch = 0.6746s	
790/22300 (epoch 1.771), train_loss = 2.08629004, grad/param norm = 4.2207e-01, time/batch = 0.6760s	
791/22300 (epoch 1.774), train_loss = 2.15894386, grad/param norm = 2.5952e-01, time/batch = 0.6782s	
792/22300 (epoch 1.776), train_loss = 2.05112905, grad/param norm = 2.1449e-01, time/batch = 0.6766s	
793/22300 (epoch 1.778), train_loss = 2.13714818, grad/param norm = 2.5177e-01, time/batch = 0.6732s	
794/22300 (epoch 1.780), train_loss = 2.21887775, grad/param norm = 2.4244e-01, time/batch = 0.6790s	
795/22300 (epoch 1.783), train_loss = 2.12972818, grad/param norm = 2.8583e-01, time/batch = 0.6768s	
796/22300 (epoch 1.785), train_loss = 2.21563808, grad/param norm = 2.7796e-01, time/batch = 0.6752s	
797/22300 (epoch 1.787), train_loss = 2.08277416, grad/param norm = 2.9754e-01, time/batch = 0.6750s	
798/22300 (epoch 1.789), train_loss = 2.03567441, grad/param norm = 3.2807e-01, time/batch = 0.6775s	
799/22300 (epoch 1.791), train_loss = 2.26839121, grad/param norm = 3.7347e-01, time/batch = 0.6746s	
800/22300 (epoch 1.794), train_loss = 2.24046822, grad/param norm = 3.0169e-01, time/batch = 0.6730s	
801/22300 (epoch 1.796), train_loss = 2.12013463, grad/param norm = 2.6886e-01, time/batch = 0.6787s	
802/22300 (epoch 1.798), train_loss = 2.12212383, grad/param norm = 2.4084e-01, time/batch = 0.6776s	
803/22300 (epoch 1.800), train_loss = 2.03120459, grad/param norm = 2.4433e-01, time/batch = 0.6756s	
804/22300 (epoch 1.803), train_loss = 2.01008028, grad/param norm = 3.3243e-01, time/batch = 0.6779s	
805/22300 (epoch 1.805), train_loss = 2.12318914, grad/param norm = 3.2243e-01, time/batch = 0.6782s	
806/22300 (epoch 1.807), train_loss = 2.09634330, grad/param norm = 2.9481e-01, time/batch = 0.6784s	
807/22300 (epoch 1.809), train_loss = 2.13605432, grad/param norm = 3.2742e-01, time/batch = 0.6771s	
808/22300 (epoch 1.812), train_loss = 2.20456889, grad/param norm = 3.8420e-01, time/batch = 0.6778s	
809/22300 (epoch 1.814), train_loss = 2.05755254, grad/param norm = 3.1003e-01, time/batch = 0.6774s	
810/22300 (epoch 1.816), train_loss = 2.17056774, grad/param norm = 2.4418e-01, time/batch = 0.6785s	
811/22300 (epoch 1.818), train_loss = 2.07341886, grad/param norm = 2.2643e-01, time/batch = 0.6805s	
812/22300 (epoch 1.821), train_loss = 2.22305244, grad/param norm = 3.3454e-01, time/batch = 0.6764s	
813/22300 (epoch 1.823), train_loss = 2.04440087, grad/param norm = 3.9407e-01, time/batch = 0.6801s	
814/22300 (epoch 1.825), train_loss = 2.01874086, grad/param norm = 2.8451e-01, time/batch = 0.6757s	
815/22300 (epoch 1.827), train_loss = 2.06360970, grad/param norm = 2.6992e-01, time/batch = 0.6757s	
816/22300 (epoch 1.830), train_loss = 2.06205368, grad/param norm = 3.0712e-01, time/batch = 0.6759s	
817/22300 (epoch 1.832), train_loss = 2.03599876, grad/param norm = 2.2022e-01, time/batch = 0.6777s	
818/22300 (epoch 1.834), train_loss = 2.20354232, grad/param norm = 2.6555e-01, time/batch = 0.6769s	
819/22300 (epoch 1.836), train_loss = 2.12855143, grad/param norm = 2.5687e-01, time/batch = 0.6778s	
820/22300 (epoch 1.839), train_loss = 2.13810587, grad/param norm = 2.5241e-01, time/batch = 0.6781s	
821/22300 (epoch 1.841), train_loss = 2.11029098, grad/param norm = 2.7877e-01, time/batch = 0.6835s	
822/22300 (epoch 1.843), train_loss = 2.06276259, grad/param norm = 3.5027e-01, time/batch = 0.6788s	
823/22300 (epoch 1.845), train_loss = 2.11305900, grad/param norm = 2.8938e-01, time/batch = 0.6773s	
824/22300 (epoch 1.848), train_loss = 2.06721351, grad/param norm = 2.9040e-01, time/batch = 0.6753s	
825/22300 (epoch 1.850), train_loss = 2.14529683, grad/param norm = 2.8453e-01, time/batch = 0.6770s	
826/22300 (epoch 1.852), train_loss = 2.10165411, grad/param norm = 2.8246e-01, time/batch = 0.6764s	
827/22300 (epoch 1.854), train_loss = 2.19613637, grad/param norm = 2.5172e-01, time/batch = 0.6750s	
828/22300 (epoch 1.857), train_loss = 2.06945523, grad/param norm = 2.7733e-01, time/batch = 0.6801s	
829/22300 (epoch 1.859), train_loss = 2.04050452, grad/param norm = 2.4736e-01, time/batch = 0.6760s	
830/22300 (epoch 1.861), train_loss = 2.16925018, grad/param norm = 2.6596e-01, time/batch = 0.6756s	
831/22300 (epoch 1.863), train_loss = 2.06617271, grad/param norm = 3.0956e-01, time/batch = 0.6807s	
832/22300 (epoch 1.865), train_loss = 1.97602300, grad/param norm = 2.9388e-01, time/batch = 0.6772s	
833/22300 (epoch 1.868), train_loss = 1.99304297, grad/param norm = 2.7904e-01, time/batch = 0.6746s	
834/22300 (epoch 1.870), train_loss = 2.03099026, grad/param norm = 2.8362e-01, time/batch = 0.6727s	
835/22300 (epoch 1.872), train_loss = 2.13990018, grad/param norm = 3.7540e-01, time/batch = 0.6689s	
836/22300 (epoch 1.874), train_loss = 2.24530101, grad/param norm = 4.6763e-01, time/batch = 0.6742s	
837/22300 (epoch 1.877), train_loss = 2.03674716, grad/param norm = 3.2784e-01, time/batch = 0.6692s	
838/22300 (epoch 1.879), train_loss = 1.92008418, grad/param norm = 2.8984e-01, time/batch = 0.6708s	
839/22300 (epoch 1.881), train_loss = 2.09579328, grad/param norm = 2.5704e-01, time/batch = 0.6700s	
840/22300 (epoch 1.883), train_loss = 2.20153752, grad/param norm = 3.2472e-01, time/batch = 0.6730s	
841/22300 (epoch 1.886), train_loss = 2.10005027, grad/param norm = 2.8375e-01, time/batch = 0.6722s	
842/22300 (epoch 1.888), train_loss = 2.04774626, grad/param norm = 2.6148e-01, time/batch = 0.6705s	
843/22300 (epoch 1.890), train_loss = 1.99966893, grad/param norm = 2.9709e-01, time/batch = 0.6796s	
844/22300 (epoch 1.892), train_loss = 2.12360503, grad/param norm = 3.0976e-01, time/batch = 0.6782s	
845/22300 (epoch 1.895), train_loss = 1.99161293, grad/param norm = 2.9946e-01, time/batch = 0.6768s	
846/22300 (epoch 1.897), train_loss = 2.13251236, grad/param norm = 2.8440e-01, time/batch = 0.6814s	
847/22300 (epoch 1.899), train_loss = 2.06723522, grad/param norm = 3.4311e-01, time/batch = 0.6733s	
848/22300 (epoch 1.901), train_loss = 2.04671840, grad/param norm = 2.9454e-01, time/batch = 0.6810s	
849/22300 (epoch 1.904), train_loss = 2.03539237, grad/param norm = 2.7141e-01, time/batch = 0.6806s	
850/22300 (epoch 1.906), train_loss = 2.09429613, grad/param norm = 2.7279e-01, time/batch = 0.6862s	
851/22300 (epoch 1.908), train_loss = 1.95529562, grad/param norm = 3.3153e-01, time/batch = 0.7171s	
852/22300 (epoch 1.910), train_loss = 2.03768111, grad/param norm = 2.5369e-01, time/batch = 0.7273s	
853/22300 (epoch 1.913), train_loss = 2.02657834, grad/param norm = 2.4661e-01, time/batch = 0.7344s	
854/22300 (epoch 1.915), train_loss = 2.08864643, grad/param norm = 2.4244e-01, time/batch = 0.7344s	
855/22300 (epoch 1.917), train_loss = 2.06817287, grad/param norm = 3.0165e-01, time/batch = 0.7017s	
856/22300 (epoch 1.919), train_loss = 2.09239918, grad/param norm = 3.4236e-01, time/batch = 0.7026s	
857/22300 (epoch 1.922), train_loss = 2.04692131, grad/param norm = 2.6520e-01, time/batch = 0.6954s	
858/22300 (epoch 1.924), train_loss = 2.11118043, grad/param norm = 3.1611e-01, time/batch = 0.6885s	
859/22300 (epoch 1.926), train_loss = 1.96601273, grad/param norm = 3.3636e-01, time/batch = 0.7019s	
860/22300 (epoch 1.928), train_loss = 2.11422133, grad/param norm = 4.5292e-01, time/batch = 0.6994s	
861/22300 (epoch 1.930), train_loss = 2.21047005, grad/param norm = 4.0196e-01, time/batch = 0.6906s	
862/22300 (epoch 1.933), train_loss = 2.05190730, grad/param norm = 3.3405e-01, time/batch = 0.6904s	
863/22300 (epoch 1.935), train_loss = 2.14500333, grad/param norm = 2.6115e-01, time/batch = 0.7372s	
864/22300 (epoch 1.937), train_loss = 2.08178208, grad/param norm = 2.6099e-01, time/batch = 0.7018s	
865/22300 (epoch 1.939), train_loss = 2.10216596, grad/param norm = 2.3569e-01, time/batch = 0.7041s	
866/22300 (epoch 1.942), train_loss = 2.08089237, grad/param norm = 2.4539e-01, time/batch = 0.6906s	
867/22300 (epoch 1.944), train_loss = 2.25695075, grad/param norm = 3.0067e-01, time/batch = 0.6868s	
868/22300 (epoch 1.946), train_loss = 2.03843080, grad/param norm = 2.7427e-01, time/batch = 0.6909s	
869/22300 (epoch 1.948), train_loss = 2.02083176, grad/param norm = 2.6241e-01, time/batch = 0.6888s	
870/22300 (epoch 1.951), train_loss = 2.02260485, grad/param norm = 2.4458e-01, time/batch = 0.6943s	
871/22300 (epoch 1.953), train_loss = 2.09024393, grad/param norm = 2.8346e-01, time/batch = 0.6872s	
872/22300 (epoch 1.955), train_loss = 2.20655816, grad/param norm = 2.6245e-01, time/batch = 0.6734s	
873/22300 (epoch 1.957), train_loss = 2.11792729, grad/param norm = 2.3976e-01, time/batch = 0.6882s	
874/22300 (epoch 1.960), train_loss = 2.12109220, grad/param norm = 3.3869e-01, time/batch = 0.6918s	
875/22300 (epoch 1.962), train_loss = 2.05472398, grad/param norm = 3.5229e-01, time/batch = 0.6909s	
876/22300 (epoch 1.964), train_loss = 2.10685977, grad/param norm = 2.7647e-01, time/batch = 0.6891s	
877/22300 (epoch 1.966), train_loss = 2.14330997, grad/param norm = 2.7092e-01, time/batch = 0.6925s	
878/22300 (epoch 1.969), train_loss = 1.98905128, grad/param norm = 2.8478e-01, time/batch = 0.6900s	
879/22300 (epoch 1.971), train_loss = 2.01699592, grad/param norm = 2.7911e-01, time/batch = 0.6905s	
880/22300 (epoch 1.973), train_loss = 2.02993786, grad/param norm = 3.1089e-01, time/batch = 0.6926s	
881/22300 (epoch 1.975), train_loss = 2.17638951, grad/param norm = 3.1935e-01, time/batch = 0.6941s	
882/22300 (epoch 1.978), train_loss = 1.89913921, grad/param norm = 2.8759e-01, time/batch = 0.6916s	
883/22300 (epoch 1.980), train_loss = 2.17209003, grad/param norm = 2.5043e-01, time/batch = 0.6878s	
884/22300 (epoch 1.982), train_loss = 1.96674466, grad/param norm = 2.2005e-01, time/batch = 0.6901s	
885/22300 (epoch 1.984), train_loss = 2.12617192, grad/param norm = 2.7743e-01, time/batch = 0.6989s	
886/22300 (epoch 1.987), train_loss = 2.05275639, grad/param norm = 2.5250e-01, time/batch = 0.6946s	
887/22300 (epoch 1.989), train_loss = 2.12692737, grad/param norm = 2.8104e-01, time/batch = 0.6939s	
888/22300 (epoch 1.991), train_loss = 2.12290379, grad/param norm = 2.8342e-01, time/batch = 0.6916s	
889/22300 (epoch 1.993), train_loss = 2.10834691, grad/param norm = 2.8457e-01, time/batch = 0.6925s	
890/22300 (epoch 1.996), train_loss = 2.15008913, grad/param norm = 2.6447e-01, time/batch = 0.6917s	
891/22300 (epoch 1.998), train_loss = 2.09912135, grad/param norm = 2.7259e-01, time/batch = 0.6962s	
892/22300 (epoch 2.000), train_loss = 2.00031653, grad/param norm = 2.7809e-01, time/batch = 0.6969s	
893/22300 (epoch 2.002), train_loss = 2.00033852, grad/param norm = 2.5962e-01, time/batch = 0.6876s	
894/22300 (epoch 2.004), train_loss = 2.12337998, grad/param norm = 2.6393e-01, time/batch = 0.6900s	
895/22300 (epoch 2.007), train_loss = 2.06876306, grad/param norm = 2.2834e-01, time/batch = 0.6936s	
896/22300 (epoch 2.009), train_loss = 2.01860180, grad/param norm = 2.5731e-01, time/batch = 0.6905s	
897/22300 (epoch 2.011), train_loss = 2.11554363, grad/param norm = 3.6067e-01, time/batch = 0.7023s	
898/22300 (epoch 2.013), train_loss = 2.06485013, grad/param norm = 4.0514e-01, time/batch = 0.6962s	
899/22300 (epoch 2.016), train_loss = 2.07138089, grad/param norm = 2.9832e-01, time/batch = 0.6997s	
900/22300 (epoch 2.018), train_loss = 2.06200587, grad/param norm = 2.7585e-01, time/batch = 0.6995s	
901/22300 (epoch 2.020), train_loss = 1.96352260, grad/param norm = 2.6517e-01, time/batch = 0.6944s	
902/22300 (epoch 2.022), train_loss = 2.00182507, grad/param norm = 2.9125e-01, time/batch = 0.6910s	
903/22300 (epoch 2.025), train_loss = 2.07426943, grad/param norm = 3.5492e-01, time/batch = 0.6929s	
904/22300 (epoch 2.027), train_loss = 2.13753381, grad/param norm = 3.2211e-01, time/batch = 0.6898s	
905/22300 (epoch 2.029), train_loss = 2.00289407, grad/param norm = 2.8897e-01, time/batch = 0.6897s	
906/22300 (epoch 2.031), train_loss = 1.94018646, grad/param norm = 2.3668e-01, time/batch = 0.6929s	
907/22300 (epoch 2.034), train_loss = 1.98627187, grad/param norm = 2.4640e-01, time/batch = 0.6893s	
908/22300 (epoch 2.036), train_loss = 1.97151947, grad/param norm = 2.9053e-01, time/batch = 0.6898s	
909/22300 (epoch 2.038), train_loss = 1.95882771, grad/param norm = 2.6608e-01, time/batch = 0.6908s	
910/22300 (epoch 2.040), train_loss = 2.07806648, grad/param norm = 2.9773e-01, time/batch = 0.6921s	
911/22300 (epoch 2.043), train_loss = 2.13563066, grad/param norm = 3.1098e-01, time/batch = 0.6975s	
912/22300 (epoch 2.045), train_loss = 1.99461705, grad/param norm = 2.2525e-01, time/batch = 0.6893s	
913/22300 (epoch 2.047), train_loss = 2.06374708, grad/param norm = 2.3416e-01, time/batch = 0.6893s	
914/22300 (epoch 2.049), train_loss = 1.94728360, grad/param norm = 2.2527e-01, time/batch = 0.6896s	
915/22300 (epoch 2.052), train_loss = 2.16347500, grad/param norm = 2.6947e-01, time/batch = 0.6879s	
916/22300 (epoch 2.054), train_loss = 1.98870679, grad/param norm = 2.4919e-01, time/batch = 0.6877s	
917/22300 (epoch 2.056), train_loss = 1.97963235, grad/param norm = 2.2651e-01, time/batch = 0.6889s	
918/22300 (epoch 2.058), train_loss = 1.85286035, grad/param norm = 2.2700e-01, time/batch = 0.6905s	
919/22300 (epoch 2.061), train_loss = 1.93419506, grad/param norm = 2.9008e-01, time/batch = 0.6890s	
920/22300 (epoch 2.063), train_loss = 2.15489892, grad/param norm = 2.8030e-01, time/batch = 0.6912s	
921/22300 (epoch 2.065), train_loss = 1.93731243, grad/param norm = 3.6104e-01, time/batch = 0.6956s	
922/22300 (epoch 2.067), train_loss = 2.10817076, grad/param norm = 3.6025e-01, time/batch = 0.6951s	
923/22300 (epoch 2.070), train_loss = 2.03785231, grad/param norm = 3.8873e-01, time/batch = 0.6900s	
924/22300 (epoch 2.072), train_loss = 2.03056843, grad/param norm = 2.7204e-01, time/batch = 0.6937s	
925/22300 (epoch 2.074), train_loss = 2.08805295, grad/param norm = 2.8472e-01, time/batch = 0.6898s	
926/22300 (epoch 2.076), train_loss = 1.96456327, grad/param norm = 2.6829e-01, time/batch = 0.6750s	
927/22300 (epoch 2.078), train_loss = 1.92996533, grad/param norm = 2.3434e-01, time/batch = 0.6780s	
928/22300 (epoch 2.081), train_loss = 2.04193930, grad/param norm = 3.0262e-01, time/batch = 0.6901s	
929/22300 (epoch 2.083), train_loss = 2.01727265, grad/param norm = 2.4008e-01, time/batch = 0.6921s	
930/22300 (epoch 2.085), train_loss = 2.10676265, grad/param norm = 2.5280e-01, time/batch = 0.6917s	
931/22300 (epoch 2.087), train_loss = 2.07108884, grad/param norm = 2.7745e-01, time/batch = 0.6962s	
932/22300 (epoch 2.090), train_loss = 2.03201535, grad/param norm = 2.7431e-01, time/batch = 0.6976s	
933/22300 (epoch 2.092), train_loss = 2.11442177, grad/param norm = 2.5279e-01, time/batch = 0.6925s	
934/22300 (epoch 2.094), train_loss = 1.94921282, grad/param norm = 2.4533e-01, time/batch = 0.6948s	
935/22300 (epoch 2.096), train_loss = 2.16629638, grad/param norm = 2.3188e-01, time/batch = 0.6949s	
936/22300 (epoch 2.099), train_loss = 2.10939359, grad/param norm = 2.5835e-01, time/batch = 0.6951s	
937/22300 (epoch 2.101), train_loss = 2.15750825, grad/param norm = 2.5561e-01, time/batch = 0.6904s	
938/22300 (epoch 2.103), train_loss = 2.05701390, grad/param norm = 2.9034e-01, time/batch = 0.7004s	
939/22300 (epoch 2.105), train_loss = 2.01517659, grad/param norm = 2.8032e-01, time/batch = 0.6951s	
940/22300 (epoch 2.108), train_loss = 2.12906560, grad/param norm = 3.1510e-01, time/batch = 0.6922s	
941/22300 (epoch 2.110), train_loss = 2.04249579, grad/param norm = 2.5410e-01, time/batch = 0.6936s	
942/22300 (epoch 2.112), train_loss = 1.98798803, grad/param norm = 2.4265e-01, time/batch = 0.7054s	
943/22300 (epoch 2.114), train_loss = 2.12735906, grad/param norm = 3.3695e-01, time/batch = 0.7288s	
944/22300 (epoch 2.117), train_loss = 2.17558506, grad/param norm = 2.7090e-01, time/batch = 0.7014s	
945/22300 (epoch 2.119), train_loss = 2.12499638, grad/param norm = 2.5241e-01, time/batch = 0.7042s	
946/22300 (epoch 2.121), train_loss = 2.04828550, grad/param norm = 2.6572e-01, time/batch = 0.7010s	
947/22300 (epoch 2.123), train_loss = 1.82254200, grad/param norm = 2.5677e-01, time/batch = 0.6908s	
948/22300 (epoch 2.126), train_loss = 1.94070034, grad/param norm = 2.5608e-01, time/batch = 0.6917s	
949/22300 (epoch 2.128), train_loss = 2.01662397, grad/param norm = 2.8020e-01, time/batch = 0.7057s	
950/22300 (epoch 2.130), train_loss = 1.99569349, grad/param norm = 2.9063e-01, time/batch = 0.7280s	
951/22300 (epoch 2.132), train_loss = 1.99592957, grad/param norm = 2.5844e-01, time/batch = 0.7006s	
952/22300 (epoch 2.135), train_loss = 1.95419459, grad/param norm = 2.5154e-01, time/batch = 0.6938s	
953/22300 (epoch 2.137), train_loss = 1.88222642, grad/param norm = 3.0197e-01, time/batch = 0.6937s	
954/22300 (epoch 2.139), train_loss = 2.05117743, grad/param norm = 3.1076e-01, time/batch = 0.6992s	
955/22300 (epoch 2.141), train_loss = 2.14223076, grad/param norm = 2.6487e-01, time/batch = 0.6936s	
956/22300 (epoch 2.143), train_loss = 2.06910469, grad/param norm = 3.1723e-01, time/batch = 0.6946s	
957/22300 (epoch 2.146), train_loss = 2.06420363, grad/param norm = 3.0392e-01, time/batch = 0.7002s	
958/22300 (epoch 2.148), train_loss = 2.02116466, grad/param norm = 2.9589e-01, time/batch = 0.6949s	
959/22300 (epoch 2.150), train_loss = 2.12100118, grad/param norm = 2.9906e-01, time/batch = 0.6919s	
960/22300 (epoch 2.152), train_loss = 2.08322852, grad/param norm = 3.7594e-01, time/batch = 0.6991s	
961/22300 (epoch 2.155), train_loss = 2.03189210, grad/param norm = 3.1422e-01, time/batch = 0.7001s	
962/22300 (epoch 2.157), train_loss = 2.01845457, grad/param norm = 3.2265e-01, time/batch = 0.7002s	
963/22300 (epoch 2.159), train_loss = 2.00273457, grad/param norm = 2.1342e-01, time/batch = 0.6944s	
964/22300 (epoch 2.161), train_loss = 2.05590343, grad/param norm = 2.6796e-01, time/batch = 0.6912s	
965/22300 (epoch 2.164), train_loss = 2.01885760, grad/param norm = 3.0737e-01, time/batch = 0.7003s	
966/22300 (epoch 2.166), train_loss = 2.04188242, grad/param norm = 2.2097e-01, time/batch = 0.6947s	
967/22300 (epoch 2.168), train_loss = 2.04716494, grad/param norm = 2.3203e-01, time/batch = 0.7020s	
968/22300 (epoch 2.170), train_loss = 2.08065106, grad/param norm = 2.2661e-01, time/batch = 0.6996s	
969/22300 (epoch 2.173), train_loss = 2.10040690, grad/param norm = 2.3982e-01, time/batch = 0.7005s	
970/22300 (epoch 2.175), train_loss = 2.00577314, grad/param norm = 3.0805e-01, time/batch = 0.6969s	
971/22300 (epoch 2.177), train_loss = 1.89595117, grad/param norm = 2.6324e-01, time/batch = 0.7004s	
972/22300 (epoch 2.179), train_loss = 1.91785107, grad/param norm = 2.5271e-01, time/batch = 0.6931s	
973/22300 (epoch 2.182), train_loss = 2.06074955, grad/param norm = 2.3263e-01, time/batch = 0.6965s	
974/22300 (epoch 2.184), train_loss = 2.13068349, grad/param norm = 2.6457e-01, time/batch = 0.6942s	
975/22300 (epoch 2.186), train_loss = 2.00167157, grad/param norm = 2.4793e-01, time/batch = 0.6954s	
976/22300 (epoch 2.188), train_loss = 2.09716025, grad/param norm = 2.4049e-01, time/batch = 0.6897s	
977/22300 (epoch 2.191), train_loss = 2.06962025, grad/param norm = 2.3719e-01, time/batch = 0.6935s	
978/22300 (epoch 2.193), train_loss = 1.93897930, grad/param norm = 2.4022e-01, time/batch = 0.6930s	
979/22300 (epoch 2.195), train_loss = 1.93298674, grad/param norm = 3.0340e-01, time/batch = 0.6911s	
980/22300 (epoch 2.197), train_loss = 2.03298410, grad/param norm = 3.3190e-01, time/batch = 0.6931s	
981/22300 (epoch 2.200), train_loss = 1.97429123, grad/param norm = 2.8776e-01, time/batch = 0.6968s	
982/22300 (epoch 2.202), train_loss = 2.00568527, grad/param norm = 3.1679e-01, time/batch = 0.6738s	
983/22300 (epoch 2.204), train_loss = 1.98053379, grad/param norm = 3.1500e-01, time/batch = 0.6858s	
984/22300 (epoch 2.206), train_loss = 1.86830253, grad/param norm = 2.7505e-01, time/batch = 0.6917s	
985/22300 (epoch 2.209), train_loss = 2.02607585, grad/param norm = 2.9594e-01, time/batch = 0.6901s	
986/22300 (epoch 2.211), train_loss = 1.96367883, grad/param norm = 3.1852e-01, time/batch = 0.6976s	
987/22300 (epoch 2.213), train_loss = 1.98178464, grad/param norm = 3.1311e-01, time/batch = 0.6881s	
988/22300 (epoch 2.215), train_loss = 2.09949537, grad/param norm = 2.7066e-01, time/batch = 0.6913s	
989/22300 (epoch 2.217), train_loss = 2.05715294, grad/param norm = 2.5748e-01, time/batch = 0.6885s	
990/22300 (epoch 2.220), train_loss = 1.98308566, grad/param norm = 3.0508e-01, time/batch = 0.6889s	
991/22300 (epoch 2.222), train_loss = 2.01763393, grad/param norm = 2.9181e-01, time/batch = 0.6922s	
992/22300 (epoch 2.224), train_loss = 1.92509934, grad/param norm = 2.3831e-01, time/batch = 0.6762s	
993/22300 (epoch 2.226), train_loss = 2.03117529, grad/param norm = 2.9875e-01, time/batch = 0.6849s	
994/22300 (epoch 2.229), train_loss = 2.06195432, grad/param norm = 2.8896e-01, time/batch = 0.6916s	
995/22300 (epoch 2.231), train_loss = 2.09254499, grad/param norm = 3.1136e-01, time/batch = 0.6922s	
996/22300 (epoch 2.233), train_loss = 2.13877260, grad/param norm = 3.0439e-01, time/batch = 0.6899s	
997/22300 (epoch 2.235), train_loss = 1.97221534, grad/param norm = 2.6640e-01, time/batch = 0.6911s	
998/22300 (epoch 2.238), train_loss = 1.93542073, grad/param norm = 2.6233e-01, time/batch = 0.6908s	
999/22300 (epoch 2.240), train_loss = 1.89282134, grad/param norm = 2.4089e-01, time/batch = 0.6907s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch2.24_2.0788.t7	
1000/22300 (epoch 2.242), train_loss = 2.01829385, grad/param norm = 2.5325e-01, time/batch = 0.6939s	
1001/22300 (epoch 2.244), train_loss = 1.84957486, grad/param norm = 2.3213e-01, time/batch = 0.6999s	
1002/22300 (epoch 2.247), train_loss = 2.04929934, grad/param norm = 2.2355e-01, time/batch = 0.6990s	
1003/22300 (epoch 2.249), train_loss = 1.91044229, grad/param norm = 2.2287e-01, time/batch = 0.6909s	
1004/22300 (epoch 2.251), train_loss = 1.88487469, grad/param norm = 2.7302e-01, time/batch = 0.6927s	
1005/22300 (epoch 2.253), train_loss = 2.00894527, grad/param norm = 2.8744e-01, time/batch = 0.6883s	
1006/22300 (epoch 2.256), train_loss = 2.16344899, grad/param norm = 3.3727e-01, time/batch = 0.6712s	
1007/22300 (epoch 2.258), train_loss = 2.03960799, grad/param norm = 2.7599e-01, time/batch = 0.6911s	
1008/22300 (epoch 2.260), train_loss = 2.03314857, grad/param norm = 2.7383e-01, time/batch = 0.6937s	
1009/22300 (epoch 2.262), train_loss = 2.06878770, grad/param norm = 2.5855e-01, time/batch = 0.7010s	
1010/22300 (epoch 2.265), train_loss = 1.99741161, grad/param norm = 2.7796e-01, time/batch = 0.6963s	
1011/22300 (epoch 2.267), train_loss = 1.96368246, grad/param norm = 2.8563e-01, time/batch = 0.6986s	
1012/22300 (epoch 2.269), train_loss = 1.95095746, grad/param norm = 3.1619e-01, time/batch = 0.6915s	
1013/22300 (epoch 2.271), train_loss = 2.10572942, grad/param norm = 3.2759e-01, time/batch = 0.6913s	
1014/22300 (epoch 2.274), train_loss = 1.92585891, grad/param norm = 2.8675e-01, time/batch = 0.6941s	
1015/22300 (epoch 2.276), train_loss = 1.89066797, grad/param norm = 2.6049e-01, time/batch = 0.6936s	
1016/22300 (epoch 2.278), train_loss = 1.92031599, grad/param norm = 2.6346e-01, time/batch = 0.6871s	
1017/22300 (epoch 2.280), train_loss = 1.96059313, grad/param norm = 2.7201e-01, time/batch = 0.7049s	
1018/22300 (epoch 2.283), train_loss = 1.89722868, grad/param norm = 2.3950e-01, time/batch = 0.6940s	
1019/22300 (epoch 2.285), train_loss = 1.92980353, grad/param norm = 2.5759e-01, time/batch = 0.6957s	
1020/22300 (epoch 2.287), train_loss = 1.92466171, grad/param norm = 3.2963e-01, time/batch = 0.6900s	
1021/22300 (epoch 2.289), train_loss = 2.02101455, grad/param norm = 3.7497e-01, time/batch = 0.6950s	
1022/22300 (epoch 2.291), train_loss = 2.00005122, grad/param norm = 3.3000e-01, time/batch = 0.6887s	
1023/22300 (epoch 2.294), train_loss = 1.97448186, grad/param norm = 3.3365e-01, time/batch = 0.6880s	
1024/22300 (epoch 2.296), train_loss = 2.11236123, grad/param norm = 3.0737e-01, time/batch = 0.6905s	
1025/22300 (epoch 2.298), train_loss = 2.04549684, grad/param norm = 3.0633e-01, time/batch = 0.6871s	
1026/22300 (epoch 2.300), train_loss = 2.04818199, grad/param norm = 2.7331e-01, time/batch = 0.6824s	
1027/22300 (epoch 2.303), train_loss = 2.01717405, grad/param norm = 2.7023e-01, time/batch = 0.6865s	
1028/22300 (epoch 2.305), train_loss = 2.11435054, grad/param norm = 3.2843e-01, time/batch = 0.6763s	
1029/22300 (epoch 2.307), train_loss = 2.08741788, grad/param norm = 3.3373e-01, time/batch = 0.6776s	
1030/22300 (epoch 2.309), train_loss = 1.98323094, grad/param norm = 2.4065e-01, time/batch = 0.6787s	
1031/22300 (epoch 2.312), train_loss = 1.91578941, grad/param norm = 2.3370e-01, time/batch = 0.6849s	
1032/22300 (epoch 2.314), train_loss = 1.98793157, grad/param norm = 2.4117e-01, time/batch = 0.6782s	
1033/22300 (epoch 2.316), train_loss = 1.97198836, grad/param norm = 2.6875e-01, time/batch = 0.6784s	
1034/22300 (epoch 2.318), train_loss = 2.16844285, grad/param norm = 3.6298e-01, time/batch = 0.6778s	
1035/22300 (epoch 2.321), train_loss = 2.09074070, grad/param norm = 3.3187e-01, time/batch = 0.6817s	
1036/22300 (epoch 2.323), train_loss = 1.99979596, grad/param norm = 2.1900e-01, time/batch = 0.6828s	
1037/22300 (epoch 2.325), train_loss = 1.93022272, grad/param norm = 2.4773e-01, time/batch = 0.6874s	
1038/22300 (epoch 2.327), train_loss = 1.94412622, grad/param norm = 2.5749e-01, time/batch = 0.7052s	
1039/22300 (epoch 2.330), train_loss = 2.01422444, grad/param norm = 2.3253e-01, time/batch = 0.7039s	
1040/22300 (epoch 2.332), train_loss = 1.99440729, grad/param norm = 2.7695e-01, time/batch = 0.7142s	
1041/22300 (epoch 2.334), train_loss = 1.91765911, grad/param norm = 2.5914e-01, time/batch = 0.7263s	
1042/22300 (epoch 2.336), train_loss = 1.92086248, grad/param norm = 2.8099e-01, time/batch = 0.7050s	
1043/22300 (epoch 2.339), train_loss = 2.03169539, grad/param norm = 3.1829e-01, time/batch = 0.7018s	
1044/22300 (epoch 2.341), train_loss = 1.96903637, grad/param norm = 3.0848e-01, time/batch = 0.6953s	
1045/22300 (epoch 2.343), train_loss = 1.98980955, grad/param norm = 2.7527e-01, time/batch = 0.6918s	
1046/22300 (epoch 2.345), train_loss = 2.02475912, grad/param norm = 2.7844e-01, time/batch = 0.6899s	
1047/22300 (epoch 2.348), train_loss = 1.94583463, grad/param norm = 2.3554e-01, time/batch = 0.6924s	
1048/22300 (epoch 2.350), train_loss = 1.93345917, grad/param norm = 2.5026e-01, time/batch = 0.6981s	
1049/22300 (epoch 2.352), train_loss = 2.00349784, grad/param norm = 2.3174e-01, time/batch = 0.6936s	
1050/22300 (epoch 2.354), train_loss = 1.97041736, grad/param norm = 2.4881e-01, time/batch = 0.6936s	
1051/22300 (epoch 2.357), train_loss = 2.14182753, grad/param norm = 2.5282e-01, time/batch = 0.6885s	
1052/22300 (epoch 2.359), train_loss = 2.01478335, grad/param norm = 3.0141e-01, time/batch = 0.6740s	
1053/22300 (epoch 2.361), train_loss = 2.02369270, grad/param norm = 2.4258e-01, time/batch = 0.6928s	
1054/22300 (epoch 2.363), train_loss = 2.22953667, grad/param norm = 3.0105e-01, time/batch = 0.6949s	
1055/22300 (epoch 2.365), train_loss = 2.02109302, grad/param norm = 3.0015e-01, time/batch = 0.6945s	
1056/22300 (epoch 2.368), train_loss = 1.98977536, grad/param norm = 2.5920e-01, time/batch = 0.6929s	
1057/22300 (epoch 2.370), train_loss = 1.96575103, grad/param norm = 2.4979e-01, time/batch = 0.6938s	
1058/22300 (epoch 2.372), train_loss = 1.85944548, grad/param norm = 2.9604e-01, time/batch = 0.6946s	
1059/22300 (epoch 2.374), train_loss = 1.97785404, grad/param norm = 2.9815e-01, time/batch = 0.6942s	
1060/22300 (epoch 2.377), train_loss = 2.01297497, grad/param norm = 2.8286e-01, time/batch = 0.6946s	
1061/22300 (epoch 2.379), train_loss = 1.96981082, grad/param norm = 2.8857e-01, time/batch = 0.6935s	
1062/22300 (epoch 2.381), train_loss = 2.00997709, grad/param norm = 2.6738e-01, time/batch = 0.6822s	
1063/22300 (epoch 2.383), train_loss = 1.88939436, grad/param norm = 3.0614e-01, time/batch = 0.6885s	
1064/22300 (epoch 2.386), train_loss = 1.94291693, grad/param norm = 3.5346e-01, time/batch = 0.6904s	
1065/22300 (epoch 2.388), train_loss = 1.94088157, grad/param norm = 2.8921e-01, time/batch = 0.6894s	
1066/22300 (epoch 2.390), train_loss = 1.96844721, grad/param norm = 2.6108e-01, time/batch = 0.6813s	
1067/22300 (epoch 2.392), train_loss = 1.89198965, grad/param norm = 2.6755e-01, time/batch = 0.6804s	
1068/22300 (epoch 2.395), train_loss = 1.92840126, grad/param norm = 2.4207e-01, time/batch = 0.6804s	
1069/22300 (epoch 2.397), train_loss = 1.85323595, grad/param norm = 2.4947e-01, time/batch = 0.6885s	
1070/22300 (epoch 2.399), train_loss = 2.02311692, grad/param norm = 2.6108e-01, time/batch = 0.6904s	
1071/22300 (epoch 2.401), train_loss = 1.96196135, grad/param norm = 2.7147e-01, time/batch = 0.6930s	
1072/22300 (epoch 2.404), train_loss = 2.04378563, grad/param norm = 2.8255e-01, time/batch = 0.6912s	
1073/22300 (epoch 2.406), train_loss = 2.08054461, grad/param norm = 2.7761e-01, time/batch = 0.6957s	
1074/22300 (epoch 2.408), train_loss = 1.94047228, grad/param norm = 2.9297e-01, time/batch = 0.6931s	
1075/22300 (epoch 2.410), train_loss = 1.93013141, grad/param norm = 3.3206e-01, time/batch = 0.6959s	
1076/22300 (epoch 2.413), train_loss = 2.08283359, grad/param norm = 2.8409e-01, time/batch = 0.6920s	
1077/22300 (epoch 2.415), train_loss = 1.93656180, grad/param norm = 2.8316e-01, time/batch = 0.6951s	
1078/22300 (epoch 2.417), train_loss = 2.06568207, grad/param norm = 2.6687e-01, time/batch = 0.6900s	
1079/22300 (epoch 2.419), train_loss = 1.86108304, grad/param norm = 2.3026e-01, time/batch = 0.6882s	
1080/22300 (epoch 2.422), train_loss = 1.89481638, grad/param norm = 2.4469e-01, time/batch = 0.6873s	
1081/22300 (epoch 2.424), train_loss = 1.99984999, grad/param norm = 2.8928e-01, time/batch = 0.6908s	
1082/22300 (epoch 2.426), train_loss = 1.98124935, grad/param norm = 3.3592e-01, time/batch = 0.6706s	
1083/22300 (epoch 2.428), train_loss = 2.03349038, grad/param norm = 3.5279e-01, time/batch = 0.6822s	
1084/22300 (epoch 2.430), train_loss = 1.94211237, grad/param norm = 2.6841e-01, time/batch = 0.6932s	
1085/22300 (epoch 2.433), train_loss = 1.86478133, grad/param norm = 2.4415e-01, time/batch = 0.6891s	
1086/22300 (epoch 2.435), train_loss = 2.00812481, grad/param norm = 2.6863e-01, time/batch = 0.6910s	
1087/22300 (epoch 2.437), train_loss = 1.87375859, grad/param norm = 2.6775e-01, time/batch = 0.6912s	
1088/22300 (epoch 2.439), train_loss = 1.89993839, grad/param norm = 2.7619e-01, time/batch = 0.6943s	
1089/22300 (epoch 2.442), train_loss = 2.02240341, grad/param norm = 3.4841e-01, time/batch = 0.6894s	
1090/22300 (epoch 2.444), train_loss = 2.07506790, grad/param norm = 2.8503e-01, time/batch = 0.6943s	
1091/22300 (epoch 2.446), train_loss = 1.95375243, grad/param norm = 2.6402e-01, time/batch = 0.6967s	
1092/22300 (epoch 2.448), train_loss = 1.86134826, grad/param norm = 2.4335e-01, time/batch = 0.6714s	
1093/22300 (epoch 2.451), train_loss = 2.00221917, grad/param norm = 2.5744e-01, time/batch = 0.6808s	
1094/22300 (epoch 2.453), train_loss = 1.90545671, grad/param norm = 2.2820e-01, time/batch = 0.6970s	
1095/22300 (epoch 2.455), train_loss = 1.90563823, grad/param norm = 2.1014e-01, time/batch = 0.6879s	
1096/22300 (epoch 2.457), train_loss = 1.88008688, grad/param norm = 2.7896e-01, time/batch = 0.6945s	
1097/22300 (epoch 2.460), train_loss = 1.89448584, grad/param norm = 2.6979e-01, time/batch = 0.7191s	
1098/22300 (epoch 2.462), train_loss = 1.89903270, grad/param norm = 2.2764e-01, time/batch = 0.7276s	
1099/22300 (epoch 2.464), train_loss = 1.90098958, grad/param norm = 2.4729e-01, time/batch = 0.7324s	
1100/22300 (epoch 2.466), train_loss = 1.93476946, grad/param norm = 2.4484e-01, time/batch = 0.7350s	
1101/22300 (epoch 2.469), train_loss = 1.93374592, grad/param norm = 2.6894e-01, time/batch = 0.7112s	
1102/22300 (epoch 2.471), train_loss = 2.04103069, grad/param norm = 2.7075e-01, time/batch = 0.7045s	
1103/22300 (epoch 2.473), train_loss = 2.08202595, grad/param norm = 2.5691e-01, time/batch = 0.7346s	
1104/22300 (epoch 2.475), train_loss = 1.87007385, grad/param norm = 2.7845e-01, time/batch = 0.7214s	
1105/22300 (epoch 2.478), train_loss = 1.88186791, grad/param norm = 2.7799e-01, time/batch = 0.6942s	
1106/22300 (epoch 2.480), train_loss = 1.97691990, grad/param norm = 2.7886e-01, time/batch = 0.6980s	
1107/22300 (epoch 2.482), train_loss = 1.92514014, grad/param norm = 2.4348e-01, time/batch = 0.7173s	
1108/22300 (epoch 2.484), train_loss = 1.88899894, grad/param norm = 2.8233e-01, time/batch = 0.7043s	
1109/22300 (epoch 2.487), train_loss = 1.89357549, grad/param norm = 2.8210e-01, time/batch = 0.6943s	
1110/22300 (epoch 2.489), train_loss = 2.00114665, grad/param norm = 2.8238e-01, time/batch = 0.7015s	
1111/22300 (epoch 2.491), train_loss = 1.91661867, grad/param norm = 2.9260e-01, time/batch = 0.7155s	
1112/22300 (epoch 2.493), train_loss = 2.04399944, grad/param norm = 3.0405e-01, time/batch = 0.7197s	
1113/22300 (epoch 2.496), train_loss = 1.98718483, grad/param norm = 3.2991e-01, time/batch = 0.7070s	
1114/22300 (epoch 2.498), train_loss = 1.98473979, grad/param norm = 2.8427e-01, time/batch = 0.6886s	
1115/22300 (epoch 2.500), train_loss = 1.82999637, grad/param norm = 2.6040e-01, time/batch = 0.6884s	
1116/22300 (epoch 2.502), train_loss = 1.96272212, grad/param norm = 2.9006e-01, time/batch = 0.6925s	
1117/22300 (epoch 2.504), train_loss = 2.00546387, grad/param norm = 3.0719e-01, time/batch = 0.6870s	
1118/22300 (epoch 2.507), train_loss = 1.87359691, grad/param norm = 2.6724e-01, time/batch = 0.6716s	
1119/22300 (epoch 2.509), train_loss = 1.96530814, grad/param norm = 2.2653e-01, time/batch = 0.7006s	
1120/22300 (epoch 2.511), train_loss = 1.85625190, grad/param norm = 2.8347e-01, time/batch = 0.7105s	
1121/22300 (epoch 2.513), train_loss = 1.84037419, grad/param norm = 2.7920e-01, time/batch = 0.7155s	
1122/22300 (epoch 2.516), train_loss = 2.07253546, grad/param norm = 2.9997e-01, time/batch = 0.7314s	
1123/22300 (epoch 2.518), train_loss = 1.96104428, grad/param norm = 3.4513e-01, time/batch = 0.6970s	
1124/22300 (epoch 2.520), train_loss = 2.07282152, grad/param norm = 2.5780e-01, time/batch = 0.7023s	
1125/22300 (epoch 2.522), train_loss = 1.89764302, grad/param norm = 2.1869e-01, time/batch = 0.7030s	
1126/22300 (epoch 2.525), train_loss = 1.88697996, grad/param norm = 2.5636e-01, time/batch = 0.6969s	
1127/22300 (epoch 2.527), train_loss = 2.14185548, grad/param norm = 2.6672e-01, time/batch = 0.7061s	
1128/22300 (epoch 2.529), train_loss = 1.90557478, grad/param norm = 2.6979e-01, time/batch = 0.6956s	
1129/22300 (epoch 2.531), train_loss = 1.90345356, grad/param norm = 2.7266e-01, time/batch = 0.7044s	
1130/22300 (epoch 2.534), train_loss = 1.86329824, grad/param norm = 2.4209e-01, time/batch = 0.6996s	
1131/22300 (epoch 2.536), train_loss = 2.02925418, grad/param norm = 2.6119e-01, time/batch = 0.7067s	
1132/22300 (epoch 2.538), train_loss = 2.17340166, grad/param norm = 2.6698e-01, time/batch = 0.7062s	
1133/22300 (epoch 2.540), train_loss = 2.03788097, grad/param norm = 2.2453e-01, time/batch = 0.7055s	
1134/22300 (epoch 2.543), train_loss = 1.87280500, grad/param norm = 2.2606e-01, time/batch = 0.6905s	
1135/22300 (epoch 2.545), train_loss = 1.91933158, grad/param norm = 2.3905e-01, time/batch = 0.6929s	
1136/22300 (epoch 2.547), train_loss = 1.99998695, grad/param norm = 2.5681e-01, time/batch = 0.6969s	
1137/22300 (epoch 2.549), train_loss = 1.94902292, grad/param norm = 2.4689e-01, time/batch = 0.6871s	
1138/22300 (epoch 2.552), train_loss = 1.84889946, grad/param norm = 2.7529e-01, time/batch = 0.6839s	
1139/22300 (epoch 2.554), train_loss = 1.93200642, grad/param norm = 3.0447e-01, time/batch = 0.6894s	
1140/22300 (epoch 2.556), train_loss = 2.04913895, grad/param norm = 2.6568e-01, time/batch = 0.6936s	
1141/22300 (epoch 2.558), train_loss = 1.90113486, grad/param norm = 3.0571e-01, time/batch = 0.6962s	
1142/22300 (epoch 2.561), train_loss = 2.03225993, grad/param norm = 2.4650e-01, time/batch = 0.6943s	
1143/22300 (epoch 2.563), train_loss = 1.83798732, grad/param norm = 2.2498e-01, time/batch = 0.6962s	
1144/22300 (epoch 2.565), train_loss = 1.99077267, grad/param norm = 2.2367e-01, time/batch = 0.6951s	
1145/22300 (epoch 2.567), train_loss = 1.94903887, grad/param norm = 2.3152e-01, time/batch = 0.6966s	
1146/22300 (epoch 2.570), train_loss = 2.00960020, grad/param norm = 2.4658e-01, time/batch = 0.6975s	
1147/22300 (epoch 2.572), train_loss = 1.99890165, grad/param norm = 2.6043e-01, time/batch = 0.7029s	
1148/22300 (epoch 2.574), train_loss = 1.82716677, grad/param norm = 2.5390e-01, time/batch = 0.6992s	
1149/22300 (epoch 2.576), train_loss = 1.84024003, grad/param norm = 2.6828e-01, time/batch = 0.6958s	
1150/22300 (epoch 2.578), train_loss = 1.73559552, grad/param norm = 2.7475e-01, time/batch = 0.6996s	
1151/22300 (epoch 2.581), train_loss = 1.81534701, grad/param norm = 2.7870e-01, time/batch = 0.7063s	
1152/22300 (epoch 2.583), train_loss = 1.94477877, grad/param norm = 2.8744e-01, time/batch = 0.6982s	
1153/22300 (epoch 2.585), train_loss = 2.02189848, grad/param norm = 2.6638e-01, time/batch = 0.6820s	
1154/22300 (epoch 2.587), train_loss = 1.95291961, grad/param norm = 2.6267e-01, time/batch = 0.6822s	
1155/22300 (epoch 2.590), train_loss = 1.93415942, grad/param norm = 2.5881e-01, time/batch = 0.6862s	
1156/22300 (epoch 2.592), train_loss = 2.08257435, grad/param norm = 2.6130e-01, time/batch = 0.6902s	
1157/22300 (epoch 2.594), train_loss = 1.94138296, grad/param norm = 2.4276e-01, time/batch = 0.6884s	
1158/22300 (epoch 2.596), train_loss = 2.01148725, grad/param norm = 3.0038e-01, time/batch = 0.6934s	
1159/22300 (epoch 2.599), train_loss = 1.80317685, grad/param norm = 3.4535e-01, time/batch = 0.6916s	
1160/22300 (epoch 2.601), train_loss = 1.92090501, grad/param norm = 2.6613e-01, time/batch = 0.6830s	
1161/22300 (epoch 2.603), train_loss = 1.88143717, grad/param norm = 2.2629e-01, time/batch = 0.6924s	
1162/22300 (epoch 2.605), train_loss = 1.86771419, grad/param norm = 2.4995e-01, time/batch = 0.6923s	
1163/22300 (epoch 2.608), train_loss = 1.98423643, grad/param norm = 2.6850e-01, time/batch = 0.6845s	
1164/22300 (epoch 2.610), train_loss = 1.93234678, grad/param norm = 2.4798e-01, time/batch = 0.6836s	
1165/22300 (epoch 2.612), train_loss = 1.99330681, grad/param norm = 2.8156e-01, time/batch = 0.6873s	
1166/22300 (epoch 2.614), train_loss = 1.96417390, grad/param norm = 2.6401e-01, time/batch = 0.6867s	
1167/22300 (epoch 2.617), train_loss = 2.04514940, grad/param norm = 2.9053e-01, time/batch = 0.6689s	
1168/22300 (epoch 2.619), train_loss = 2.13018002, grad/param norm = 2.7431e-01, time/batch = 0.6621s	
1169/22300 (epoch 2.621), train_loss = 1.73086052, grad/param norm = 2.5307e-01, time/batch = 0.6683s	
1170/22300 (epoch 2.623), train_loss = 1.88784493, grad/param norm = 2.6034e-01, time/batch = 0.6675s	
1171/22300 (epoch 2.626), train_loss = 1.78837293, grad/param norm = 2.4234e-01, time/batch = 0.6708s	
1172/22300 (epoch 2.628), train_loss = 1.90778330, grad/param norm = 2.4523e-01, time/batch = 0.6747s	
1173/22300 (epoch 2.630), train_loss = 1.93068971, grad/param norm = 2.3850e-01, time/batch = 0.6685s	
1174/22300 (epoch 2.632), train_loss = 1.96277498, grad/param norm = 2.3822e-01, time/batch = 0.6674s	
1175/22300 (epoch 2.635), train_loss = 1.83920681, grad/param norm = 2.4575e-01, time/batch = 0.6659s	
1176/22300 (epoch 2.637), train_loss = 2.00197661, grad/param norm = 2.5701e-01, time/batch = 0.6714s	
1177/22300 (epoch 2.639), train_loss = 1.94653623, grad/param norm = 3.2249e-01, time/batch = 0.6727s	
1178/22300 (epoch 2.641), train_loss = 1.98229523, grad/param norm = 2.9912e-01, time/batch = 0.6658s	
1179/22300 (epoch 2.643), train_loss = 1.87428174, grad/param norm = 2.7306e-01, time/batch = 0.6797s	
1180/22300 (epoch 2.646), train_loss = 1.87714004, grad/param norm = 2.8278e-01, time/batch = 0.6681s	
1181/22300 (epoch 2.648), train_loss = 1.86009028, grad/param norm = 2.4460e-01, time/batch = 0.6650s	
1182/22300 (epoch 2.650), train_loss = 2.10532237, grad/param norm = 2.4925e-01, time/batch = 0.6697s	
1183/22300 (epoch 2.652), train_loss = 1.91508279, grad/param norm = 2.3862e-01, time/batch = 0.6683s	
1184/22300 (epoch 2.655), train_loss = 1.93795997, grad/param norm = 2.1269e-01, time/batch = 0.6693s	
1185/22300 (epoch 2.657), train_loss = 1.94328487, grad/param norm = 2.5539e-01, time/batch = 0.6782s	
1186/22300 (epoch 2.659), train_loss = 1.81835047, grad/param norm = 3.0322e-01, time/batch = 0.6731s	
1187/22300 (epoch 2.661), train_loss = 1.95351317, grad/param norm = 3.2448e-01, time/batch = 0.6712s	
1188/22300 (epoch 2.664), train_loss = 1.87810779, grad/param norm = 2.7629e-01, time/batch = 0.6735s	
1189/22300 (epoch 2.666), train_loss = 1.98808464, grad/param norm = 2.2924e-01, time/batch = 0.6755s	
1190/22300 (epoch 2.668), train_loss = 1.95222348, grad/param norm = 2.4553e-01, time/batch = 0.6713s	
1191/22300 (epoch 2.670), train_loss = 1.99784483, grad/param norm = 2.4004e-01, time/batch = 0.6800s	
1192/22300 (epoch 2.673), train_loss = 2.00640210, grad/param norm = 2.7083e-01, time/batch = 0.6943s	
1193/22300 (epoch 2.675), train_loss = 1.98756691, grad/param norm = 2.5733e-01, time/batch = 0.6800s	
1194/22300 (epoch 2.677), train_loss = 2.01048738, grad/param norm = 2.9589e-01, time/batch = 0.6782s	
1195/22300 (epoch 2.679), train_loss = 1.98027595, grad/param norm = 2.6761e-01, time/batch = 0.6718s	
1196/22300 (epoch 2.682), train_loss = 1.94577144, grad/param norm = 2.5966e-01, time/batch = 0.6641s	
1197/22300 (epoch 2.684), train_loss = 1.90797184, grad/param norm = 2.5760e-01, time/batch = 0.6698s	
1198/22300 (epoch 2.686), train_loss = 1.96635493, grad/param norm = 2.5772e-01, time/batch = 0.6654s	
1199/22300 (epoch 2.688), train_loss = 2.03803294, grad/param norm = 2.6205e-01, time/batch = 0.6744s	
1200/22300 (epoch 2.691), train_loss = 2.01307528, grad/param norm = 2.8140e-01, time/batch = 0.6698s	
1201/22300 (epoch 2.693), train_loss = 1.98570438, grad/param norm = 3.2462e-01, time/batch = 0.6823s	
1202/22300 (epoch 2.695), train_loss = 1.89206995, grad/param norm = 2.6396e-01, time/batch = 0.6744s	
1203/22300 (epoch 2.697), train_loss = 1.77616951, grad/param norm = 2.6271e-01, time/batch = 0.6735s	
1204/22300 (epoch 2.700), train_loss = 1.93733420, grad/param norm = 2.4787e-01, time/batch = 0.6706s	
1205/22300 (epoch 2.702), train_loss = 1.94036613, grad/param norm = 2.5307e-01, time/batch = 0.6677s	
1206/22300 (epoch 2.704), train_loss = 2.01909749, grad/param norm = 2.5615e-01, time/batch = 0.6764s	
1207/22300 (epoch 2.706), train_loss = 1.89122412, grad/param norm = 2.3152e-01, time/batch = 0.6730s	
1208/22300 (epoch 2.709), train_loss = 1.83851302, grad/param norm = 2.7149e-01, time/batch = 0.6702s	
1209/22300 (epoch 2.711), train_loss = 2.01318879, grad/param norm = 3.2485e-01, time/batch = 0.6781s	
1210/22300 (epoch 2.713), train_loss = 1.86945355, grad/param norm = 3.2524e-01, time/batch = 0.6804s	
1211/22300 (epoch 2.715), train_loss = 1.95607860, grad/param norm = 2.9387e-01, time/batch = 0.6746s	
1212/22300 (epoch 2.717), train_loss = 2.08192069, grad/param norm = 3.4359e-01, time/batch = 0.6632s	
1213/22300 (epoch 2.720), train_loss = 1.96572107, grad/param norm = 2.6559e-01, time/batch = 0.6620s	
1214/22300 (epoch 2.722), train_loss = 1.95352674, grad/param norm = 3.0377e-01, time/batch = 0.6685s	
1215/22300 (epoch 2.724), train_loss = 1.97278004, grad/param norm = 3.0591e-01, time/batch = 0.6716s	
1216/22300 (epoch 2.726), train_loss = 1.96701959, grad/param norm = 2.7017e-01, time/batch = 0.6770s	
1217/22300 (epoch 2.729), train_loss = 2.01212344, grad/param norm = 2.4419e-01, time/batch = 0.6722s	
1218/22300 (epoch 2.731), train_loss = 1.96888480, grad/param norm = 2.8270e-01, time/batch = 0.6738s	
1219/22300 (epoch 2.733), train_loss = 1.99366575, grad/param norm = 2.6726e-01, time/batch = 0.6769s	
1220/22300 (epoch 2.735), train_loss = 1.91938764, grad/param norm = 2.4939e-01, time/batch = 0.6844s	
1221/22300 (epoch 2.738), train_loss = 1.92773860, grad/param norm = 2.7001e-01, time/batch = 0.6820s	
1222/22300 (epoch 2.740), train_loss = 1.74312474, grad/param norm = 2.0803e-01, time/batch = 0.6936s	
1223/22300 (epoch 2.742), train_loss = 1.91814686, grad/param norm = 2.4033e-01, time/batch = 0.7025s	
1224/22300 (epoch 2.744), train_loss = 1.90862216, grad/param norm = 2.5481e-01, time/batch = 0.6887s	
1225/22300 (epoch 2.747), train_loss = 1.91241629, grad/param norm = 2.9947e-01, time/batch = 0.6923s	
1226/22300 (epoch 2.749), train_loss = 2.07817934, grad/param norm = 2.8323e-01, time/batch = 0.6899s	
1227/22300 (epoch 2.751), train_loss = 1.95506974, grad/param norm = 2.3747e-01, time/batch = 0.6852s	
1228/22300 (epoch 2.753), train_loss = 1.95250274, grad/param norm = 2.3441e-01, time/batch = 0.6901s	
1229/22300 (epoch 2.756), train_loss = 1.94877053, grad/param norm = 2.7816e-01, time/batch = 0.6716s	
1230/22300 (epoch 2.758), train_loss = 1.79041659, grad/param norm = 2.5450e-01, time/batch = 0.6791s	
1231/22300 (epoch 2.760), train_loss = 1.85658526, grad/param norm = 2.7949e-01, time/batch = 0.7126s	
1232/22300 (epoch 2.762), train_loss = 1.96105054, grad/param norm = 2.5714e-01, time/batch = 0.6978s	
1233/22300 (epoch 2.765), train_loss = 1.97486448, grad/param norm = 2.4325e-01, time/batch = 0.6928s	
1234/22300 (epoch 2.767), train_loss = 1.98820372, grad/param norm = 2.3657e-01, time/batch = 0.6923s	
1235/22300 (epoch 2.769), train_loss = 1.93972285, grad/param norm = 2.7148e-01, time/batch = 0.6893s	
1236/22300 (epoch 2.771), train_loss = 1.87654967, grad/param norm = 3.3210e-01, time/batch = 0.6862s	
1237/22300 (epoch 2.774), train_loss = 1.95207681, grad/param norm = 2.3578e-01, time/batch = 0.6930s	
1238/22300 (epoch 2.776), train_loss = 1.84647116, grad/param norm = 1.9677e-01, time/batch = 0.6861s	
1239/22300 (epoch 2.778), train_loss = 1.95820871, grad/param norm = 2.4072e-01, time/batch = 0.6845s	
1240/22300 (epoch 2.780), train_loss = 2.00902029, grad/param norm = 2.1942e-01, time/batch = 0.6835s	
1241/22300 (epoch 2.783), train_loss = 1.93716260, grad/param norm = 2.4489e-01, time/batch = 0.6894s	
1242/22300 (epoch 2.785), train_loss = 1.98941552, grad/param norm = 2.7605e-01, time/batch = 0.6907s	
1243/22300 (epoch 2.787), train_loss = 1.85864838, grad/param norm = 2.6973e-01, time/batch = 0.6787s	
1244/22300 (epoch 2.789), train_loss = 1.85327775, grad/param norm = 2.3147e-01, time/batch = 0.6888s	
1245/22300 (epoch 2.791), train_loss = 2.03813653, grad/param norm = 2.8800e-01, time/batch = 0.6905s	
1246/22300 (epoch 2.794), train_loss = 2.02396189, grad/param norm = 2.4814e-01, time/batch = 0.6681s	
1247/22300 (epoch 2.796), train_loss = 1.95306856, grad/param norm = 2.5610e-01, time/batch = 0.6660s	
1248/22300 (epoch 2.798), train_loss = 1.93628700, grad/param norm = 2.2845e-01, time/batch = 0.6918s	
1249/22300 (epoch 2.800), train_loss = 1.81353584, grad/param norm = 2.6092e-01, time/batch = 0.6841s	
1250/22300 (epoch 2.803), train_loss = 1.78568255, grad/param norm = 2.9750e-01, time/batch = 0.6673s	
1251/22300 (epoch 2.805), train_loss = 1.91124658, grad/param norm = 2.6206e-01, time/batch = 0.6628s	
1252/22300 (epoch 2.807), train_loss = 1.90197803, grad/param norm = 2.7001e-01, time/batch = 0.6648s	
1253/22300 (epoch 2.809), train_loss = 1.95577175, grad/param norm = 2.9245e-01, time/batch = 0.6618s	
1254/22300 (epoch 2.812), train_loss = 2.02847938, grad/param norm = 3.1322e-01, time/batch = 0.6614s	
1255/22300 (epoch 2.814), train_loss = 1.88294011, grad/param norm = 2.4510e-01, time/batch = 0.6722s	
1256/22300 (epoch 2.816), train_loss = 1.98250414, grad/param norm = 2.3022e-01, time/batch = 0.6651s	
1257/22300 (epoch 2.818), train_loss = 1.90796208, grad/param norm = 2.2284e-01, time/batch = 0.6608s	
1258/22300 (epoch 2.821), train_loss = 2.04666619, grad/param norm = 2.7771e-01, time/batch = 0.6629s	
1259/22300 (epoch 2.823), train_loss = 1.83807663, grad/param norm = 2.8476e-01, time/batch = 0.6627s	
1260/22300 (epoch 2.825), train_loss = 1.83262469, grad/param norm = 2.3484e-01, time/batch = 0.6713s	
1261/22300 (epoch 2.827), train_loss = 1.87911188, grad/param norm = 2.3862e-01, time/batch = 0.6820s	
1262/22300 (epoch 2.830), train_loss = 1.89475938, grad/param norm = 2.5594e-01, time/batch = 0.6807s	
1263/22300 (epoch 2.832), train_loss = 1.82891674, grad/param norm = 2.0957e-01, time/batch = 0.6701s	
1264/22300 (epoch 2.834), train_loss = 2.05655268, grad/param norm = 2.5071e-01, time/batch = 0.6730s	
1265/22300 (epoch 2.836), train_loss = 1.95228733, grad/param norm = 2.5398e-01, time/batch = 0.6751s	
1266/22300 (epoch 2.839), train_loss = 1.92295451, grad/param norm = 2.4583e-01, time/batch = 0.6758s	
1267/22300 (epoch 2.841), train_loss = 1.88773355, grad/param norm = 2.4726e-01, time/batch = 0.6729s	
1268/22300 (epoch 2.843), train_loss = 1.85323570, grad/param norm = 2.7617e-01, time/batch = 0.6754s	
1269/22300 (epoch 2.845), train_loss = 1.90009536, grad/param norm = 2.5028e-01, time/batch = 0.6718s	
1270/22300 (epoch 2.848), train_loss = 1.88356367, grad/param norm = 2.4565e-01, time/batch = 0.6737s	
1271/22300 (epoch 2.850), train_loss = 1.92445987, grad/param norm = 2.4335e-01, time/batch = 0.6759s	
1272/22300 (epoch 2.852), train_loss = 1.93971691, grad/param norm = 2.4497e-01, time/batch = 0.6757s	
1273/22300 (epoch 2.854), train_loss = 2.01728786, grad/param norm = 2.4287e-01, time/batch = 0.6709s	
1274/22300 (epoch 2.857), train_loss = 1.87680880, grad/param norm = 3.1998e-01, time/batch = 0.6644s	
1275/22300 (epoch 2.859), train_loss = 1.81268851, grad/param norm = 2.4572e-01, time/batch = 0.6737s	
1276/22300 (epoch 2.861), train_loss = 1.92863462, grad/param norm = 2.3337e-01, time/batch = 0.6752s	
1277/22300 (epoch 2.863), train_loss = 1.83488977, grad/param norm = 2.5158e-01, time/batch = 0.6774s	
1278/22300 (epoch 2.865), train_loss = 1.77112777, grad/param norm = 2.3341e-01, time/batch = 0.6899s	
1279/22300 (epoch 2.868), train_loss = 1.80875510, grad/param norm = 2.3067e-01, time/batch = 0.6801s	
1280/22300 (epoch 2.870), train_loss = 1.85516692, grad/param norm = 2.3469e-01, time/batch = 0.6841s	
1281/22300 (epoch 2.872), train_loss = 1.92199569, grad/param norm = 2.8063e-01, time/batch = 0.6865s	
1282/22300 (epoch 2.874), train_loss = 1.99597759, grad/param norm = 3.2982e-01, time/batch = 0.7010s	
1283/22300 (epoch 2.877), train_loss = 1.81544396, grad/param norm = 2.3146e-01, time/batch = 0.6764s	
1284/22300 (epoch 2.879), train_loss = 1.69044811, grad/param norm = 2.2875e-01, time/batch = 0.6826s	
1285/22300 (epoch 2.881), train_loss = 1.86724933, grad/param norm = 2.5850e-01, time/batch = 0.6934s	
1286/22300 (epoch 2.883), train_loss = 1.97125080, grad/param norm = 3.1754e-01, time/batch = 0.6796s	
1287/22300 (epoch 2.886), train_loss = 1.87963796, grad/param norm = 2.3524e-01, time/batch = 0.6715s	
1288/22300 (epoch 2.888), train_loss = 1.84169118, grad/param norm = 2.4502e-01, time/batch = 0.6586s	
1289/22300 (epoch 2.890), train_loss = 1.75316739, grad/param norm = 2.4109e-01, time/batch = 0.6739s	
1290/22300 (epoch 2.892), train_loss = 1.96106366, grad/param norm = 2.5294e-01, time/batch = 0.6824s	
1291/22300 (epoch 2.895), train_loss = 1.84823446, grad/param norm = 2.2183e-01, time/batch = 0.6799s	
1292/22300 (epoch 2.897), train_loss = 1.95023350, grad/param norm = 2.5863e-01, time/batch = 0.6762s	
1293/22300 (epoch 2.899), train_loss = 1.87348995, grad/param norm = 2.7506e-01, time/batch = 0.6687s	
1294/22300 (epoch 2.901), train_loss = 1.83879306, grad/param norm = 2.5256e-01, time/batch = 0.6711s	
1295/22300 (epoch 2.904), train_loss = 1.81733847, grad/param norm = 2.5596e-01, time/batch = 0.6739s	
1296/22300 (epoch 2.906), train_loss = 1.90520403, grad/param norm = 2.2647e-01, time/batch = 0.6709s	
1297/22300 (epoch 2.908), train_loss = 1.79402403, grad/param norm = 2.3695e-01, time/batch = 0.6665s	
1298/22300 (epoch 2.910), train_loss = 1.83165435, grad/param norm = 2.2880e-01, time/batch = 0.6711s	
1299/22300 (epoch 2.913), train_loss = 1.83386622, grad/param norm = 2.3364e-01, time/batch = 0.6847s	
1300/22300 (epoch 2.915), train_loss = 1.94712751, grad/param norm = 2.6365e-01, time/batch = 0.6777s	
1301/22300 (epoch 2.917), train_loss = 1.87142412, grad/param norm = 2.9360e-01, time/batch = 0.6785s	
1302/22300 (epoch 2.919), train_loss = 1.94880818, grad/param norm = 3.1755e-01, time/batch = 0.6592s	
1303/22300 (epoch 2.922), train_loss = 1.88219480, grad/param norm = 2.4946e-01, time/batch = 0.6562s	
1304/22300 (epoch 2.924), train_loss = 1.87287348, grad/param norm = 2.6990e-01, time/batch = 0.6632s	
1305/22300 (epoch 2.926), train_loss = 1.72015726, grad/param norm = 2.4368e-01, time/batch = 0.6705s	
1306/22300 (epoch 2.928), train_loss = 1.90014856, grad/param norm = 2.5139e-01, time/batch = 0.6753s	
1307/22300 (epoch 2.930), train_loss = 1.94101129, grad/param norm = 2.4272e-01, time/batch = 0.6786s	
1308/22300 (epoch 2.933), train_loss = 1.86628334, grad/param norm = 2.7412e-01, time/batch = 0.6656s	
1309/22300 (epoch 2.935), train_loss = 1.97381530, grad/param norm = 2.4053e-01, time/batch = 0.6739s	
1310/22300 (epoch 2.937), train_loss = 1.87562034, grad/param norm = 2.2520e-01, time/batch = 0.6641s	
1311/22300 (epoch 2.939), train_loss = 1.90765288, grad/param norm = 2.2564e-01, time/batch = 0.6809s	
1312/22300 (epoch 2.942), train_loss = 1.94752983, grad/param norm = 2.8391e-01, time/batch = 0.6827s	
1313/22300 (epoch 2.944), train_loss = 2.06193786, grad/param norm = 2.6930e-01, time/batch = 0.6728s	
1314/22300 (epoch 2.946), train_loss = 1.84368828, grad/param norm = 2.5628e-01, time/batch = 0.6745s	
1315/22300 (epoch 2.948), train_loss = 1.86570188, grad/param norm = 2.5645e-01, time/batch = 0.6667s	
1316/22300 (epoch 2.951), train_loss = 1.80092773, grad/param norm = 2.3257e-01, time/batch = 0.6665s	
1317/22300 (epoch 2.953), train_loss = 1.87417397, grad/param norm = 2.4769e-01, time/batch = 0.6724s	
1318/22300 (epoch 2.955), train_loss = 2.01993331, grad/param norm = 2.3614e-01, time/batch = 0.6726s	
1319/22300 (epoch 2.957), train_loss = 1.97448240, grad/param norm = 2.2730e-01, time/batch = 0.6814s	
1320/22300 (epoch 2.960), train_loss = 1.95598100, grad/param norm = 2.9212e-01, time/batch = 0.6772s	
1321/22300 (epoch 2.962), train_loss = 1.90314912, grad/param norm = 3.4613e-01, time/batch = 0.6795s	
1322/22300 (epoch 2.964), train_loss = 1.91890691, grad/param norm = 2.5263e-01, time/batch = 0.6726s	
1323/22300 (epoch 2.966), train_loss = 1.92140258, grad/param norm = 2.5664e-01, time/batch = 0.6700s	
1324/22300 (epoch 2.969), train_loss = 1.79694743, grad/param norm = 2.3990e-01, time/batch = 0.6652s	
1325/22300 (epoch 2.971), train_loss = 1.83387499, grad/param norm = 2.3752e-01, time/batch = 0.6806s	
1326/22300 (epoch 2.973), train_loss = 1.79759326, grad/param norm = 2.3101e-01, time/batch = 0.6745s	
1327/22300 (epoch 2.975), train_loss = 2.03317256, grad/param norm = 2.5041e-01, time/batch = 0.6737s	
1328/22300 (epoch 2.978), train_loss = 1.69945887, grad/param norm = 2.0588e-01, time/batch = 0.6758s	
1329/22300 (epoch 2.980), train_loss = 1.96437067, grad/param norm = 2.3669e-01, time/batch = 0.6709s	
1330/22300 (epoch 2.982), train_loss = 1.77024282, grad/param norm = 2.2949e-01, time/batch = 0.6720s	
1331/22300 (epoch 2.984), train_loss = 1.92332459, grad/param norm = 2.3918e-01, time/batch = 0.6725s	
1332/22300 (epoch 2.987), train_loss = 1.85759517, grad/param norm = 2.5439e-01, time/batch = 0.6595s	
1333/22300 (epoch 2.989), train_loss = 1.94291652, grad/param norm = 2.7787e-01, time/batch = 0.6774s	
1334/22300 (epoch 2.991), train_loss = 1.97150485, grad/param norm = 2.6453e-01, time/batch = 0.6665s	
1335/22300 (epoch 2.993), train_loss = 1.93046481, grad/param norm = 2.7949e-01, time/batch = 0.6579s	
1336/22300 (epoch 2.996), train_loss = 1.98012947, grad/param norm = 2.2832e-01, time/batch = 0.6588s	
1337/22300 (epoch 2.998), train_loss = 1.90098106, grad/param norm = 2.4972e-01, time/batch = 0.6733s	
1338/22300 (epoch 3.000), train_loss = 1.82898847, grad/param norm = 2.3979e-01, time/batch = 0.6770s	
1339/22300 (epoch 3.002), train_loss = 1.86530324, grad/param norm = 2.4960e-01, time/batch = 0.6694s	
1340/22300 (epoch 3.004), train_loss = 1.92690146, grad/param norm = 2.4193e-01, time/batch = 0.6737s	
1341/22300 (epoch 3.007), train_loss = 1.87994014, grad/param norm = 2.2525e-01, time/batch = 0.6758s	
1342/22300 (epoch 3.009), train_loss = 1.84896613, grad/param norm = 2.6312e-01, time/batch = 0.6689s	
1343/22300 (epoch 3.011), train_loss = 1.95513430, grad/param norm = 2.9133e-01, time/batch = 0.6739s	
1344/22300 (epoch 3.013), train_loss = 1.83795521, grad/param norm = 3.1746e-01, time/batch = 0.6700s	
1345/22300 (epoch 3.016), train_loss = 1.85550139, grad/param norm = 2.7272e-01, time/batch = 0.6712s	
1346/22300 (epoch 3.018), train_loss = 1.90632706, grad/param norm = 2.5663e-01, time/batch = 0.6741s	
1347/22300 (epoch 3.020), train_loss = 1.78581577, grad/param norm = 2.3153e-01, time/batch = 0.6717s	
1348/22300 (epoch 3.022), train_loss = 1.84479513, grad/param norm = 2.7462e-01, time/batch = 0.6718s	
1349/22300 (epoch 3.025), train_loss = 1.87923275, grad/param norm = 2.8573e-01, time/batch = 0.6773s	
1350/22300 (epoch 3.027), train_loss = 1.99163729, grad/param norm = 2.5356e-01, time/batch = 0.6768s	
1351/22300 (epoch 3.029), train_loss = 1.80003531, grad/param norm = 2.1846e-01, time/batch = 0.6809s	
1352/22300 (epoch 3.031), train_loss = 1.71045927, grad/param norm = 1.9544e-01, time/batch = 0.6790s	
1353/22300 (epoch 3.034), train_loss = 1.78880222, grad/param norm = 2.1489e-01, time/batch = 0.6773s	
1354/22300 (epoch 3.036), train_loss = 1.75490808, grad/param norm = 2.4072e-01, time/batch = 0.6719s	
1355/22300 (epoch 3.038), train_loss = 1.74041454, grad/param norm = 2.1467e-01, time/batch = 0.6658s	
1356/22300 (epoch 3.040), train_loss = 1.89723680, grad/param norm = 2.4908e-01, time/batch = 0.6739s	
1357/22300 (epoch 3.043), train_loss = 1.94470494, grad/param norm = 2.7589e-01, time/batch = 0.6763s	
1358/22300 (epoch 3.045), train_loss = 1.82492569, grad/param norm = 2.1881e-01, time/batch = 0.6632s	
1359/22300 (epoch 3.047), train_loss = 1.87059165, grad/param norm = 2.6908e-01, time/batch = 0.6633s	
1360/22300 (epoch 3.049), train_loss = 1.77969440, grad/param norm = 2.2312e-01, time/batch = 0.6632s	
1361/22300 (epoch 3.052), train_loss = 1.96835900, grad/param norm = 2.5194e-01, time/batch = 0.6694s	
1362/22300 (epoch 3.054), train_loss = 1.82296234, grad/param norm = 2.3013e-01, time/batch = 0.6602s	
1363/22300 (epoch 3.056), train_loss = 1.76632861, grad/param norm = 2.2057e-01, time/batch = 0.6663s	
1364/22300 (epoch 3.058), train_loss = 1.65006244, grad/param norm = 2.0073e-01, time/batch = 0.6759s	
1365/22300 (epoch 3.061), train_loss = 1.72302654, grad/param norm = 2.5291e-01, time/batch = 0.6775s	
1366/22300 (epoch 3.063), train_loss = 1.98836787, grad/param norm = 2.6175e-01, time/batch = 0.6771s	
1367/22300 (epoch 3.065), train_loss = 1.73824033, grad/param norm = 2.6130e-01, time/batch = 0.6795s	
1368/22300 (epoch 3.067), train_loss = 1.88070680, grad/param norm = 2.9259e-01, time/batch = 0.6755s	
1369/22300 (epoch 3.070), train_loss = 1.83548770, grad/param norm = 3.4849e-01, time/batch = 0.6723s	
1370/22300 (epoch 3.072), train_loss = 1.87830575, grad/param norm = 2.4513e-01, time/batch = 0.6784s	
1371/22300 (epoch 3.074), train_loss = 1.85850475, grad/param norm = 2.2584e-01, time/batch = 0.6830s	
1372/22300 (epoch 3.076), train_loss = 1.72151123, grad/param norm = 2.2880e-01, time/batch = 0.6834s	
1373/22300 (epoch 3.078), train_loss = 1.74953991, grad/param norm = 2.0450e-01, time/batch = 0.6991s	
1374/22300 (epoch 3.081), train_loss = 1.88156076, grad/param norm = 2.6907e-01, time/batch = 0.6889s	
1375/22300 (epoch 3.083), train_loss = 1.85227106, grad/param norm = 2.5450e-01, time/batch = 0.6736s	
1376/22300 (epoch 3.085), train_loss = 1.94028553, grad/param norm = 2.4278e-01, time/batch = 0.6689s	
1377/22300 (epoch 3.087), train_loss = 1.85400347, grad/param norm = 2.4534e-01, time/batch = 0.6823s	
1378/22300 (epoch 3.090), train_loss = 1.81899275, grad/param norm = 2.2192e-01, time/batch = 0.6728s	
1379/22300 (epoch 3.092), train_loss = 1.91747149, grad/param norm = 2.5735e-01, time/batch = 0.6659s	
1380/22300 (epoch 3.094), train_loss = 1.74624987, grad/param norm = 2.4378e-01, time/batch = 0.6616s	
1381/22300 (epoch 3.096), train_loss = 1.94503824, grad/param norm = 2.4777e-01, time/batch = 0.6663s	
1382/22300 (epoch 3.099), train_loss = 1.91229372, grad/param norm = 2.8084e-01, time/batch = 0.6715s	
1383/22300 (epoch 3.101), train_loss = 1.97558022, grad/param norm = 2.6079e-01, time/batch = 0.6800s	
1384/22300 (epoch 3.103), train_loss = 1.92082550, grad/param norm = 3.4589e-01, time/batch = 0.6647s	
1385/22300 (epoch 3.105), train_loss = 1.84813853, grad/param norm = 2.4815e-01, time/batch = 0.6635s	
1386/22300 (epoch 3.108), train_loss = 1.91536101, grad/param norm = 2.7601e-01, time/batch = 0.6632s	
1387/22300 (epoch 3.110), train_loss = 1.84265508, grad/param norm = 2.1403e-01, time/batch = 0.6770s	
1388/22300 (epoch 3.112), train_loss = 1.80220932, grad/param norm = 2.3937e-01, time/batch = 0.6794s	
1389/22300 (epoch 3.114), train_loss = 1.92034325, grad/param norm = 2.4948e-01, time/batch = 0.6821s	
1390/22300 (epoch 3.117), train_loss = 2.02435208, grad/param norm = 2.1608e-01, time/batch = 0.6709s	
1391/22300 (epoch 3.119), train_loss = 1.89615707, grad/param norm = 2.2938e-01, time/batch = 0.7048s	
1392/22300 (epoch 3.121), train_loss = 1.88117739, grad/param norm = 2.3353e-01, time/batch = 0.6756s	
1393/22300 (epoch 3.123), train_loss = 1.67108920, grad/param norm = 2.3303e-01, time/batch = 0.6767s	
1394/22300 (epoch 3.126), train_loss = 1.76893322, grad/param norm = 2.2603e-01, time/batch = 0.6773s	
1395/22300 (epoch 3.128), train_loss = 1.82749413, grad/param norm = 2.4093e-01, time/batch = 0.6685s	
1396/22300 (epoch 3.130), train_loss = 1.82141617, grad/param norm = 2.2269e-01, time/batch = 0.6680s	
1397/22300 (epoch 3.132), train_loss = 1.79332898, grad/param norm = 2.4793e-01, time/batch = 0.6666s	
1398/22300 (epoch 3.135), train_loss = 1.75568468, grad/param norm = 2.4438e-01, time/batch = 0.6703s	
1399/22300 (epoch 3.137), train_loss = 1.63914529, grad/param norm = 2.6457e-01, time/batch = 0.6554s	
1400/22300 (epoch 3.139), train_loss = 1.85654363, grad/param norm = 2.7610e-01, time/batch = 0.6574s	
1401/22300 (epoch 3.141), train_loss = 1.94921091, grad/param norm = 2.3079e-01, time/batch = 0.6592s	
1402/22300 (epoch 3.143), train_loss = 1.88421906, grad/param norm = 2.8257e-01, time/batch = 0.6543s	
1403/22300 (epoch 3.146), train_loss = 1.92295198, grad/param norm = 2.7006e-01, time/batch = 0.6545s	
1404/22300 (epoch 3.148), train_loss = 1.81213676, grad/param norm = 2.4616e-01, time/batch = 0.6655s	
1405/22300 (epoch 3.150), train_loss = 1.93025615, grad/param norm = 2.6864e-01, time/batch = 0.6733s	
1406/22300 (epoch 3.152), train_loss = 1.91081808, grad/param norm = 2.9887e-01, time/batch = 0.6647s	
1407/22300 (epoch 3.155), train_loss = 1.81999379, grad/param norm = 2.5431e-01, time/batch = 0.6660s	
1408/22300 (epoch 3.157), train_loss = 1.86286257, grad/param norm = 2.6025e-01, time/batch = 0.6800s	
1409/22300 (epoch 3.159), train_loss = 1.82340021, grad/param norm = 2.1370e-01, time/batch = 0.6660s	
1410/22300 (epoch 3.161), train_loss = 1.89884138, grad/param norm = 2.4153e-01, time/batch = 0.6715s	
1411/22300 (epoch 3.164), train_loss = 1.81509021, grad/param norm = 2.8897e-01, time/batch = 0.6634s	
1412/22300 (epoch 3.166), train_loss = 1.84400542, grad/param norm = 2.4277e-01, time/batch = 0.6679s	
1413/22300 (epoch 3.168), train_loss = 1.86631380, grad/param norm = 2.5819e-01, time/batch = 0.6682s	
1414/22300 (epoch 3.170), train_loss = 1.89418178, grad/param norm = 2.2368e-01, time/batch = 0.6576s	
1415/22300 (epoch 3.173), train_loss = 1.96702717, grad/param norm = 2.4846e-01, time/batch = 0.6679s	
1416/22300 (epoch 3.175), train_loss = 1.80924844, grad/param norm = 2.6639e-01, time/batch = 0.6812s	
1417/22300 (epoch 3.177), train_loss = 1.67384862, grad/param norm = 2.1550e-01, time/batch = 0.6797s	
1418/22300 (epoch 3.179), train_loss = 1.70549675, grad/param norm = 2.2482e-01, time/batch = 0.6656s	
1419/22300 (epoch 3.182), train_loss = 1.87765866, grad/param norm = 2.2675e-01, time/batch = 0.6613s	
1420/22300 (epoch 3.184), train_loss = 1.96962938, grad/param norm = 2.4717e-01, time/batch = 0.6660s	
1421/22300 (epoch 3.186), train_loss = 1.84513202, grad/param norm = 2.2862e-01, time/batch = 0.6642s	
1422/22300 (epoch 3.188), train_loss = 1.92325134, grad/param norm = 2.7623e-01, time/batch = 0.6639s	
1423/22300 (epoch 3.191), train_loss = 1.91208181, grad/param norm = 2.3497e-01, time/batch = 0.6717s	
1424/22300 (epoch 3.193), train_loss = 1.75723858, grad/param norm = 2.2763e-01, time/batch = 0.6702s	
1425/22300 (epoch 3.195), train_loss = 1.71848827, grad/param norm = 2.2451e-01, time/batch = 0.6769s	
1426/22300 (epoch 3.197), train_loss = 1.85966631, grad/param norm = 2.5054e-01, time/batch = 0.6823s	
1427/22300 (epoch 3.200), train_loss = 1.78798559, grad/param norm = 2.5701e-01, time/batch = 0.6805s	
1428/22300 (epoch 3.202), train_loss = 1.82022905, grad/param norm = 2.8682e-01, time/batch = 0.6813s	
1429/22300 (epoch 3.204), train_loss = 1.79680044, grad/param norm = 2.7092e-01, time/batch = 0.6729s	
1430/22300 (epoch 3.206), train_loss = 1.65937181, grad/param norm = 2.4601e-01, time/batch = 0.6754s	
1431/22300 (epoch 3.209), train_loss = 1.83408044, grad/param norm = 2.7005e-01, time/batch = 0.6780s	
1432/22300 (epoch 3.211), train_loss = 1.76706317, grad/param norm = 2.8355e-01, time/batch = 0.6675s	
1433/22300 (epoch 3.213), train_loss = 1.76668831, grad/param norm = 2.6419e-01, time/batch = 0.6795s	
1434/22300 (epoch 3.215), train_loss = 1.94272481, grad/param norm = 2.5826e-01, time/batch = 0.6685s	
1435/22300 (epoch 3.217), train_loss = 1.86584297, grad/param norm = 2.4619e-01, time/batch = 0.6664s	
1436/22300 (epoch 3.220), train_loss = 1.79308970, grad/param norm = 2.7045e-01, time/batch = 0.6634s	
1437/22300 (epoch 3.222), train_loss = 1.83385109, grad/param norm = 2.2855e-01, time/batch = 0.6667s	
1438/22300 (epoch 3.224), train_loss = 1.74208691, grad/param norm = 2.2227e-01, time/batch = 0.6682s	
1439/22300 (epoch 3.226), train_loss = 1.84336539, grad/param norm = 2.7601e-01, time/batch = 0.6636s	
1440/22300 (epoch 3.229), train_loss = 1.89585800, grad/param norm = 2.8680e-01, time/batch = 0.6691s	
1441/22300 (epoch 3.231), train_loss = 1.97365952, grad/param norm = 2.7786e-01, time/batch = 0.6657s	
1442/22300 (epoch 3.233), train_loss = 1.94787850, grad/param norm = 2.4089e-01, time/batch = 0.6665s	
1443/22300 (epoch 3.235), train_loss = 1.78033115, grad/param norm = 2.2311e-01, time/batch = 0.6669s	
1444/22300 (epoch 3.238), train_loss = 1.73904714, grad/param norm = 2.2676e-01, time/batch = 0.6629s	
1445/22300 (epoch 3.240), train_loss = 1.70358785, grad/param norm = 2.2860e-01, time/batch = 0.6660s	
1446/22300 (epoch 3.242), train_loss = 1.81894259, grad/param norm = 2.3914e-01, time/batch = 0.6612s	
1447/22300 (epoch 3.244), train_loss = 1.57382253, grad/param norm = 2.2389e-01, time/batch = 0.6622s	
1448/22300 (epoch 3.247), train_loss = 1.86858205, grad/param norm = 2.2431e-01, time/batch = 0.6806s	
1449/22300 (epoch 3.249), train_loss = 1.74471069, grad/param norm = 2.2670e-01, time/batch = 0.6816s	
1450/22300 (epoch 3.251), train_loss = 1.66551816, grad/param norm = 2.4627e-01, time/batch = 0.6813s	
1451/22300 (epoch 3.253), train_loss = 1.79070486, grad/param norm = 2.3938e-01, time/batch = 0.6648s	
1452/22300 (epoch 3.256), train_loss = 1.94112776, grad/param norm = 2.8935e-01, time/batch = 0.6614s	
1453/22300 (epoch 3.258), train_loss = 1.89353224, grad/param norm = 2.8440e-01, time/batch = 0.6731s	
1454/22300 (epoch 3.260), train_loss = 1.87218661, grad/param norm = 2.7282e-01, time/batch = 0.6592s	
1455/22300 (epoch 3.262), train_loss = 1.89402535, grad/param norm = 2.6869e-01, time/batch = 0.6599s	
1456/22300 (epoch 3.265), train_loss = 1.82610084, grad/param norm = 2.5334e-01, time/batch = 0.6610s	
1457/22300 (epoch 3.267), train_loss = 1.77483343, grad/param norm = 2.5948e-01, time/batch = 0.6481s	
1458/22300 (epoch 3.269), train_loss = 1.78629098, grad/param norm = 2.6524e-01, time/batch = 0.6512s	
1459/22300 (epoch 3.271), train_loss = 1.89461539, grad/param norm = 2.6570e-01, time/batch = 0.6404s	
1460/22300 (epoch 3.274), train_loss = 1.74579020, grad/param norm = 2.5866e-01, time/batch = 0.6462s	
1461/22300 (epoch 3.276), train_loss = 1.68008057, grad/param norm = 2.3940e-01, time/batch = 0.6458s	
1462/22300 (epoch 3.278), train_loss = 1.72336389, grad/param norm = 2.5622e-01, time/batch = 0.6444s	
1463/22300 (epoch 3.280), train_loss = 1.77640866, grad/param norm = 2.8187e-01, time/batch = 0.6433s	
1464/22300 (epoch 3.283), train_loss = 1.69201212, grad/param norm = 2.4442e-01, time/batch = 0.6376s	
1465/22300 (epoch 3.285), train_loss = 1.77488490, grad/param norm = 2.6332e-01, time/batch = 0.6383s	
1466/22300 (epoch 3.287), train_loss = 1.78355812, grad/param norm = 2.8158e-01, time/batch = 0.6388s	
1467/22300 (epoch 3.289), train_loss = 1.80012496, grad/param norm = 2.7567e-01, time/batch = 0.6447s	
1468/22300 (epoch 3.291), train_loss = 1.80510496, grad/param norm = 2.5255e-01, time/batch = 0.6512s	
1469/22300 (epoch 3.294), train_loss = 1.74950001, grad/param norm = 2.6047e-01, time/batch = 0.6669s	
1470/22300 (epoch 3.296), train_loss = 1.93500499, grad/param norm = 2.9297e-01, time/batch = 0.6511s	
1471/22300 (epoch 3.298), train_loss = 1.85262066, grad/param norm = 3.3042e-01, time/batch = 0.6438s	
1472/22300 (epoch 3.300), train_loss = 1.88703767, grad/param norm = 2.4322e-01, time/batch = 0.6477s	
1473/22300 (epoch 3.303), train_loss = 1.80342370, grad/param norm = 2.3125e-01, time/batch = 0.6521s	
1474/22300 (epoch 3.305), train_loss = 1.94676197, grad/param norm = 2.9918e-01, time/batch = 0.6433s	
1475/22300 (epoch 3.307), train_loss = 1.86949041, grad/param norm = 2.9166e-01, time/batch = 0.6435s	
1476/22300 (epoch 3.309), train_loss = 1.80487033, grad/param norm = 2.5076e-01, time/batch = 0.6446s	
1477/22300 (epoch 3.312), train_loss = 1.73087863, grad/param norm = 2.2743e-01, time/batch = 0.6635s	
1478/22300 (epoch 3.314), train_loss = 1.83799469, grad/param norm = 2.2338e-01, time/batch = 0.6574s	
1479/22300 (epoch 3.316), train_loss = 1.79421632, grad/param norm = 2.4673e-01, time/batch = 0.6421s	
1480/22300 (epoch 3.318), train_loss = 1.95777478, grad/param norm = 3.3018e-01, time/batch = 0.6451s	
1481/22300 (epoch 3.321), train_loss = 1.90867731, grad/param norm = 2.9081e-01, time/batch = 0.6739s	
1482/22300 (epoch 3.323), train_loss = 1.83065712, grad/param norm = 2.0773e-01, time/batch = 0.6522s	
1483/22300 (epoch 3.325), train_loss = 1.71184369, grad/param norm = 2.2920e-01, time/batch = 0.6593s	
1484/22300 (epoch 3.327), train_loss = 1.76201866, grad/param norm = 2.3218e-01, time/batch = 0.6565s	
1485/22300 (epoch 3.330), train_loss = 1.84577576, grad/param norm = 2.5553e-01, time/batch = 0.6517s	
1486/22300 (epoch 3.332), train_loss = 1.77025064, grad/param norm = 2.4937e-01, time/batch = 0.6529s	
1487/22300 (epoch 3.334), train_loss = 1.70178251, grad/param norm = 2.3483e-01, time/batch = 0.6533s	
1488/22300 (epoch 3.336), train_loss = 1.77575650, grad/param norm = 2.5969e-01, time/batch = 0.6583s	
1489/22300 (epoch 3.339), train_loss = 1.84968899, grad/param norm = 2.9685e-01, time/batch = 0.6493s	
1490/22300 (epoch 3.341), train_loss = 1.82424991, grad/param norm = 3.0542e-01, time/batch = 0.6520s	
1491/22300 (epoch 3.343), train_loss = 1.82892758, grad/param norm = 2.6593e-01, time/batch = 0.6669s	
1492/22300 (epoch 3.345), train_loss = 1.84092489, grad/param norm = 2.6469e-01, time/batch = 0.6619s	
1493/22300 (epoch 3.348), train_loss = 1.75898302, grad/param norm = 2.3271e-01, time/batch = 0.6614s	
1494/22300 (epoch 3.350), train_loss = 1.70841964, grad/param norm = 2.3617e-01, time/batch = 0.6439s	
1495/22300 (epoch 3.352), train_loss = 1.85578237, grad/param norm = 2.3386e-01, time/batch = 0.6596s	
1496/22300 (epoch 3.354), train_loss = 1.81269186, grad/param norm = 2.3555e-01, time/batch = 0.6670s	
1497/22300 (epoch 3.357), train_loss = 1.94954358, grad/param norm = 2.5980e-01, time/batch = 0.6633s	
1498/22300 (epoch 3.359), train_loss = 1.84553105, grad/param norm = 2.6310e-01, time/batch = 0.6592s	
1499/22300 (epoch 3.361), train_loss = 1.87557106, grad/param norm = 2.3333e-01, time/batch = 0.6658s	
1500/22300 (epoch 3.363), train_loss = 2.01030311, grad/param norm = 2.8499e-01, time/batch = 0.6369s	
1501/22300 (epoch 3.365), train_loss = 1.84449768, grad/param norm = 2.5159e-01, time/batch = 0.6425s	
1502/22300 (epoch 3.368), train_loss = 1.84087248, grad/param norm = 2.4377e-01, time/batch = 0.6505s	
1503/22300 (epoch 3.370), train_loss = 1.81946639, grad/param norm = 2.3253e-01, time/batch = 0.6561s	
1504/22300 (epoch 3.372), train_loss = 1.69800350, grad/param norm = 2.6540e-01, time/batch = 0.6481s	
1505/22300 (epoch 3.374), train_loss = 1.75064817, grad/param norm = 2.4781e-01, time/batch = 0.6376s	
1506/22300 (epoch 3.377), train_loss = 1.84906248, grad/param norm = 2.4662e-01, time/batch = 0.6401s	
1507/22300 (epoch 3.379), train_loss = 1.80053837, grad/param norm = 2.5530e-01, time/batch = 0.6391s	
1508/22300 (epoch 3.381), train_loss = 1.85308874, grad/param norm = 2.4397e-01, time/batch = 0.6453s	
1509/22300 (epoch 3.383), train_loss = 1.71963779, grad/param norm = 2.5287e-01, time/batch = 0.6410s	
1510/22300 (epoch 3.386), train_loss = 1.80080593, grad/param norm = 2.9680e-01, time/batch = 0.6473s	
1511/22300 (epoch 3.388), train_loss = 1.77781846, grad/param norm = 2.5500e-01, time/batch = 0.6575s	
1512/22300 (epoch 3.390), train_loss = 1.77496386, grad/param norm = 2.3315e-01, time/batch = 0.6395s	
1513/22300 (epoch 3.392), train_loss = 1.72940054, grad/param norm = 2.4812e-01, time/batch = 0.6400s	
1514/22300 (epoch 3.395), train_loss = 1.73540669, grad/param norm = 2.2674e-01, time/batch = 0.6447s	
1515/22300 (epoch 3.397), train_loss = 1.63785056, grad/param norm = 2.5665e-01, time/batch = 0.6421s	
1516/22300 (epoch 3.399), train_loss = 1.82975546, grad/param norm = 2.5639e-01, time/batch = 0.6373s	
1517/22300 (epoch 3.401), train_loss = 1.75426808, grad/param norm = 2.6867e-01, time/batch = 0.6324s	
1518/22300 (epoch 3.404), train_loss = 1.82059168, grad/param norm = 2.7910e-01, time/batch = 0.6407s	
1519/22300 (epoch 3.406), train_loss = 1.93561421, grad/param norm = 2.6030e-01, time/batch = 0.6425s	
1520/22300 (epoch 3.408), train_loss = 1.78490417, grad/param norm = 2.6805e-01, time/batch = 0.6354s	
1521/22300 (epoch 3.410), train_loss = 1.76544435, grad/param norm = 2.6333e-01, time/batch = 0.6453s	
1522/22300 (epoch 3.413), train_loss = 1.84598354, grad/param norm = 2.6291e-01, time/batch = 0.6441s	
1523/22300 (epoch 3.415), train_loss = 1.72107718, grad/param norm = 2.3198e-01, time/batch = 0.6495s	
1524/22300 (epoch 3.417), train_loss = 1.88276236, grad/param norm = 2.3786e-01, time/batch = 0.6454s	
1525/22300 (epoch 3.419), train_loss = 1.69348962, grad/param norm = 2.1768e-01, time/batch = 0.6632s	
1526/22300 (epoch 3.422), train_loss = 1.76942778, grad/param norm = 2.3035e-01, time/batch = 0.6493s	
1527/22300 (epoch 3.424), train_loss = 1.84471393, grad/param norm = 2.6839e-01, time/batch = 0.6556s	
1528/22300 (epoch 3.426), train_loss = 1.77474795, grad/param norm = 2.6538e-01, time/batch = 0.6438s	
1529/22300 (epoch 3.428), train_loss = 1.89121899, grad/param norm = 2.9669e-01, time/batch = 0.6526s	
1530/22300 (epoch 3.430), train_loss = 1.77535916, grad/param norm = 2.3530e-01, time/batch = 0.6515s	
1531/22300 (epoch 3.433), train_loss = 1.72957635, grad/param norm = 1.9618e-01, time/batch = 0.6494s	
1532/22300 (epoch 3.435), train_loss = 1.83461958, grad/param norm = 2.4449e-01, time/batch = 0.6516s	
1533/22300 (epoch 3.437), train_loss = 1.67377521, grad/param norm = 2.4461e-01, time/batch = 0.6491s	
1534/22300 (epoch 3.439), train_loss = 1.70063413, grad/param norm = 2.3942e-01, time/batch = 0.6545s	
1535/22300 (epoch 3.442), train_loss = 1.83792909, grad/param norm = 2.7612e-01, time/batch = 0.6469s	
1536/22300 (epoch 3.444), train_loss = 1.83690288, grad/param norm = 2.4372e-01, time/batch = 0.6476s	
1537/22300 (epoch 3.446), train_loss = 1.75646997, grad/param norm = 2.3332e-01, time/batch = 0.6454s	
1538/22300 (epoch 3.448), train_loss = 1.65019150, grad/param norm = 2.2882e-01, time/batch = 0.6371s	
1539/22300 (epoch 3.451), train_loss = 1.87433142, grad/param norm = 2.4509e-01, time/batch = 0.6424s	
1540/22300 (epoch 3.453), train_loss = 1.74591659, grad/param norm = 2.2604e-01, time/batch = 0.6403s	
1541/22300 (epoch 3.455), train_loss = 1.76658514, grad/param norm = 2.2862e-01, time/batch = 0.6439s	
1542/22300 (epoch 3.457), train_loss = 1.69881876, grad/param norm = 2.6757e-01, time/batch = 0.6419s	
1543/22300 (epoch 3.460), train_loss = 1.72550768, grad/param norm = 2.8415e-01, time/batch = 0.6435s	
1544/22300 (epoch 3.462), train_loss = 1.73400202, grad/param norm = 2.3188e-01, time/batch = 0.6534s	
1545/22300 (epoch 3.464), train_loss = 1.73235467, grad/param norm = 2.4343e-01, time/batch = 0.6598s	
1546/22300 (epoch 3.466), train_loss = 1.78376028, grad/param norm = 2.4338e-01, time/batch = 0.6600s	
1547/22300 (epoch 3.469), train_loss = 1.76736528, grad/param norm = 2.5697e-01, time/batch = 0.6592s	
1548/22300 (epoch 3.471), train_loss = 1.86596046, grad/param norm = 2.3460e-01, time/batch = 0.6617s	
1549/22300 (epoch 3.473), train_loss = 1.90183836, grad/param norm = 2.2931e-01, time/batch = 0.6640s	
1550/22300 (epoch 3.475), train_loss = 1.73743232, grad/param norm = 2.5803e-01, time/batch = 0.6656s	
1551/22300 (epoch 3.478), train_loss = 1.70773295, grad/param norm = 2.4037e-01, time/batch = 0.6470s	
1552/22300 (epoch 3.480), train_loss = 1.75948331, grad/param norm = 2.3855e-01, time/batch = 0.6537s	
1553/22300 (epoch 3.482), train_loss = 1.72075648, grad/param norm = 2.3045e-01, time/batch = 0.6403s	
1554/22300 (epoch 3.484), train_loss = 1.69245614, grad/param norm = 2.4958e-01, time/batch = 0.6449s	
1555/22300 (epoch 3.487), train_loss = 1.70355654, grad/param norm = 2.5596e-01, time/batch = 0.6421s	
1556/22300 (epoch 3.489), train_loss = 1.82884178, grad/param norm = 2.5442e-01, time/batch = 0.6456s	
1557/22300 (epoch 3.491), train_loss = 1.71464099, grad/param norm = 2.4614e-01, time/batch = 0.6420s	
1558/22300 (epoch 3.493), train_loss = 1.86583412, grad/param norm = 2.5527e-01, time/batch = 0.6454s	
1559/22300 (epoch 3.496), train_loss = 1.80470070, grad/param norm = 2.9537e-01, time/batch = 0.6520s	
1560/22300 (epoch 3.498), train_loss = 1.81307268, grad/param norm = 2.6541e-01, time/batch = 0.6577s	
1561/22300 (epoch 3.500), train_loss = 1.66534624, grad/param norm = 2.5962e-01, time/batch = 0.6539s	
1562/22300 (epoch 3.502), train_loss = 1.78699003, grad/param norm = 2.9511e-01, time/batch = 0.6589s	
1563/22300 (epoch 3.504), train_loss = 1.78123777, grad/param norm = 2.8357e-01, time/batch = 0.6515s	
1564/22300 (epoch 3.507), train_loss = 1.71652434, grad/param norm = 2.7006e-01, time/batch = 0.6578s	
1565/22300 (epoch 3.509), train_loss = 1.81083547, grad/param norm = 2.3668e-01, time/batch = 0.6661s	
1566/22300 (epoch 3.511), train_loss = 1.64634765, grad/param norm = 2.6192e-01, time/batch = 0.6579s	
1567/22300 (epoch 3.513), train_loss = 1.63096169, grad/param norm = 2.3703e-01, time/batch = 0.6604s	
1568/22300 (epoch 3.516), train_loss = 1.88501184, grad/param norm = 2.9752e-01, time/batch = 0.6681s	
1569/22300 (epoch 3.518), train_loss = 1.77828205, grad/param norm = 3.0187e-01, time/batch = 0.6702s	
1570/22300 (epoch 3.520), train_loss = 1.89014738, grad/param norm = 2.4309e-01, time/batch = 0.6695s	
1571/22300 (epoch 3.522), train_loss = 1.70487276, grad/param norm = 2.3946e-01, time/batch = 0.6767s	
1572/22300 (epoch 3.525), train_loss = 1.69837467, grad/param norm = 2.7319e-01, time/batch = 0.6902s	
1573/22300 (epoch 3.527), train_loss = 1.95559928, grad/param norm = 2.7241e-01, time/batch = 0.6922s	
1574/22300 (epoch 3.529), train_loss = 1.72562872, grad/param norm = 2.7004e-01, time/batch = 0.6772s	
1575/22300 (epoch 3.531), train_loss = 1.74969815, grad/param norm = 2.6104e-01, time/batch = 0.6740s	
1576/22300 (epoch 3.534), train_loss = 1.65594144, grad/param norm = 2.1857e-01, time/batch = 0.6868s	
1577/22300 (epoch 3.536), train_loss = 1.87329602, grad/param norm = 2.4332e-01, time/batch = 0.6798s	
1578/22300 (epoch 3.538), train_loss = 2.02915604, grad/param norm = 2.7147e-01, time/batch = 0.6776s	
1579/22300 (epoch 3.540), train_loss = 1.89060204, grad/param norm = 2.4224e-01, time/batch = 0.6792s	
1580/22300 (epoch 3.543), train_loss = 1.69087883, grad/param norm = 2.3332e-01, time/batch = 0.6703s	
1581/22300 (epoch 3.545), train_loss = 1.72979252, grad/param norm = 2.1789e-01, time/batch = 0.6781s	
1582/22300 (epoch 3.547), train_loss = 1.77304452, grad/param norm = 2.4916e-01, time/batch = 0.6648s	
1583/22300 (epoch 3.549), train_loss = 1.79120453, grad/param norm = 2.4392e-01, time/batch = 0.6662s	
1584/22300 (epoch 3.552), train_loss = 1.65994274, grad/param norm = 2.4554e-01, time/batch = 0.6724s	
1585/22300 (epoch 3.554), train_loss = 1.75807064, grad/param norm = 2.5840e-01, time/batch = 0.6728s	
1586/22300 (epoch 3.556), train_loss = 1.86543269, grad/param norm = 2.4174e-01, time/batch = 0.6746s	
1587/22300 (epoch 3.558), train_loss = 1.70094718, grad/param norm = 2.2069e-01, time/batch = 0.6785s	
1588/22300 (epoch 3.561), train_loss = 1.87710732, grad/param norm = 2.4019e-01, time/batch = 0.6701s	
1589/22300 (epoch 3.563), train_loss = 1.66587004, grad/param norm = 2.3645e-01, time/batch = 0.6782s	
1590/22300 (epoch 3.565), train_loss = 1.81014511, grad/param norm = 2.2697e-01, time/batch = 0.6752s	
1591/22300 (epoch 3.567), train_loss = 1.78449840, grad/param norm = 2.3531e-01, time/batch = 0.6692s	
1592/22300 (epoch 3.570), train_loss = 1.87281554, grad/param norm = 2.5177e-01, time/batch = 0.6626s	
1593/22300 (epoch 3.572), train_loss = 1.81254428, grad/param norm = 2.5461e-01, time/batch = 0.6713s	
1594/22300 (epoch 3.574), train_loss = 1.67121773, grad/param norm = 2.3926e-01, time/batch = 0.6841s	
1595/22300 (epoch 3.576), train_loss = 1.61100704, grad/param norm = 2.3100e-01, time/batch = 0.6853s	
1596/22300 (epoch 3.578), train_loss = 1.52713141, grad/param norm = 2.1959e-01, time/batch = 0.6740s	
1597/22300 (epoch 3.581), train_loss = 1.63816494, grad/param norm = 2.2804e-01, time/batch = 0.6677s	
1598/22300 (epoch 3.583), train_loss = 1.72604016, grad/param norm = 2.3312e-01, time/batch = 0.6649s	
1599/22300 (epoch 3.585), train_loss = 1.84130948, grad/param norm = 2.4419e-01, time/batch = 0.6663s	
1600/22300 (epoch 3.587), train_loss = 1.81839471, grad/param norm = 2.5669e-01, time/batch = 0.6653s	
1601/22300 (epoch 3.590), train_loss = 1.75976936, grad/param norm = 2.4301e-01, time/batch = 0.6719s	
1602/22300 (epoch 3.592), train_loss = 1.90621767, grad/param norm = 2.5828e-01, time/batch = 0.6725s	
1603/22300 (epoch 3.594), train_loss = 1.79710879, grad/param norm = 2.2809e-01, time/batch = 0.6664s	
1604/22300 (epoch 3.596), train_loss = 1.78510796, grad/param norm = 2.8256e-01, time/batch = 0.6730s	
1605/22300 (epoch 3.599), train_loss = 1.59511807, grad/param norm = 2.9956e-01, time/batch = 0.6667s	
1606/22300 (epoch 3.601), train_loss = 1.74694163, grad/param norm = 2.3848e-01, time/batch = 0.6734s	
1607/22300 (epoch 3.603), train_loss = 1.74041635, grad/param norm = 2.4282e-01, time/batch = 0.6695s	
1608/22300 (epoch 3.605), train_loss = 1.68869509, grad/param norm = 2.5285e-01, time/batch = 0.6624s	
1609/22300 (epoch 3.608), train_loss = 1.84438707, grad/param norm = 2.6512e-01, time/batch = 0.6691s	
1610/22300 (epoch 3.610), train_loss = 1.82480218, grad/param norm = 2.4890e-01, time/batch = 0.6766s	
1611/22300 (epoch 3.612), train_loss = 1.85334287, grad/param norm = 2.8904e-01, time/batch = 0.6590s	
1612/22300 (epoch 3.614), train_loss = 1.82425456, grad/param norm = 2.6773e-01, time/batch = 0.6601s	
1613/22300 (epoch 3.617), train_loss = 1.88323984, grad/param norm = 2.9076e-01, time/batch = 0.6565s	
1614/22300 (epoch 3.619), train_loss = 2.02694061, grad/param norm = 2.7292e-01, time/batch = 0.6623s	
1615/22300 (epoch 3.621), train_loss = 1.57641679, grad/param norm = 2.3724e-01, time/batch = 0.6788s	
1616/22300 (epoch 3.623), train_loss = 1.72464543, grad/param norm = 2.6184e-01, time/batch = 0.6824s	
1617/22300 (epoch 3.626), train_loss = 1.62356337, grad/param norm = 2.2315e-01, time/batch = 0.6690s	
1618/22300 (epoch 3.628), train_loss = 1.71245179, grad/param norm = 2.4335e-01, time/batch = 0.6523s	
1619/22300 (epoch 3.630), train_loss = 1.76601985, grad/param norm = 2.3121e-01, time/batch = 0.6654s	
1620/22300 (epoch 3.632), train_loss = 1.79939564, grad/param norm = 2.2786e-01, time/batch = 0.6719s	
1621/22300 (epoch 3.635), train_loss = 1.65285524, grad/param norm = 2.3111e-01, time/batch = 0.6751s	
1622/22300 (epoch 3.637), train_loss = 1.86309578, grad/param norm = 2.6800e-01, time/batch = 0.6618s	
1623/22300 (epoch 3.639), train_loss = 1.80695477, grad/param norm = 3.1446e-01, time/batch = 0.6732s	
1624/22300 (epoch 3.641), train_loss = 1.80246647, grad/param norm = 2.7355e-01, time/batch = 0.6673s	
1625/22300 (epoch 3.643), train_loss = 1.72801420, grad/param norm = 2.6128e-01, time/batch = 0.6557s	
1626/22300 (epoch 3.646), train_loss = 1.69383410, grad/param norm = 2.5123e-01, time/batch = 0.6637s	
1627/22300 (epoch 3.648), train_loss = 1.66918214, grad/param norm = 2.3735e-01, time/batch = 0.6665s	
1628/22300 (epoch 3.650), train_loss = 1.93714062, grad/param norm = 2.6096e-01, time/batch = 0.6677s	
1629/22300 (epoch 3.652), train_loss = 1.74178988, grad/param norm = 2.3769e-01, time/batch = 0.6715s	
1630/22300 (epoch 3.655), train_loss = 1.81957070, grad/param norm = 2.1972e-01, time/batch = 0.6719s	
1631/22300 (epoch 3.657), train_loss = 1.78296970, grad/param norm = 2.4848e-01, time/batch = 0.6726s	
1632/22300 (epoch 3.659), train_loss = 1.63440429, grad/param norm = 2.5392e-01, time/batch = 0.6739s	
1633/22300 (epoch 3.661), train_loss = 1.75068274, grad/param norm = 2.9704e-01, time/batch = 0.6712s	
1634/22300 (epoch 3.664), train_loss = 1.70730785, grad/param norm = 2.5878e-01, time/batch = 0.6787s	
1635/22300 (epoch 3.666), train_loss = 1.80585355, grad/param norm = 2.1920e-01, time/batch = 0.6754s	
1636/22300 (epoch 3.668), train_loss = 1.76244195, grad/param norm = 2.4587e-01, time/batch = 0.6711s	
1637/22300 (epoch 3.670), train_loss = 1.85305252, grad/param norm = 2.3997e-01, time/batch = 0.6765s	
1638/22300 (epoch 3.673), train_loss = 1.80605430, grad/param norm = 2.5564e-01, time/batch = 0.6806s	
1639/22300 (epoch 3.675), train_loss = 1.85446606, grad/param norm = 2.5126e-01, time/batch = 0.6952s	
1640/22300 (epoch 3.677), train_loss = 1.87054463, grad/param norm = 2.6156e-01, time/batch = 0.6876s	
1641/22300 (epoch 3.679), train_loss = 1.85352317, grad/param norm = 2.6442e-01, time/batch = 0.6810s	
1642/22300 (epoch 3.682), train_loss = 1.79976819, grad/param norm = 2.5061e-01, time/batch = 0.6825s	
1643/22300 (epoch 3.684), train_loss = 1.75990997, grad/param norm = 2.4258e-01, time/batch = 0.6786s	
1644/22300 (epoch 3.686), train_loss = 1.83542014, grad/param norm = 2.6888e-01, time/batch = 0.6775s	
1645/22300 (epoch 3.688), train_loss = 1.88598014, grad/param norm = 2.5231e-01, time/batch = 0.6738s	
1646/22300 (epoch 3.691), train_loss = 1.83230137, grad/param norm = 2.5528e-01, time/batch = 0.6664s	
1647/22300 (epoch 3.693), train_loss = 1.82057440, grad/param norm = 2.9553e-01, time/batch = 0.6617s	
1648/22300 (epoch 3.695), train_loss = 1.70347756, grad/param norm = 2.5697e-01, time/batch = 0.6618s	
1649/22300 (epoch 3.697), train_loss = 1.55271343, grad/param norm = 2.3087e-01, time/batch = 0.6777s	
1650/22300 (epoch 3.700), train_loss = 1.74303558, grad/param norm = 2.3670e-01, time/batch = 0.6535s	
1651/22300 (epoch 3.702), train_loss = 1.79937753, grad/param norm = 2.6788e-01, time/batch = 0.6552s	
1652/22300 (epoch 3.704), train_loss = 1.87046894, grad/param norm = 2.7482e-01, time/batch = 0.6474s	
1653/22300 (epoch 3.706), train_loss = 1.68230215, grad/param norm = 2.2902e-01, time/batch = 0.6510s	
1654/22300 (epoch 3.709), train_loss = 1.63610711, grad/param norm = 2.4679e-01, time/batch = 0.6536s	
1655/22300 (epoch 3.711), train_loss = 1.80661435, grad/param norm = 2.5022e-01, time/batch = 0.6431s	
1656/22300 (epoch 3.713), train_loss = 1.70393826, grad/param norm = 2.4155e-01, time/batch = 0.6472s	
1657/22300 (epoch 3.715), train_loss = 1.76904769, grad/param norm = 2.6722e-01, time/batch = 0.6417s	
1658/22300 (epoch 3.717), train_loss = 1.96743006, grad/param norm = 3.1601e-01, time/batch = 0.6500s	
1659/22300 (epoch 3.720), train_loss = 1.79132897, grad/param norm = 2.5771e-01, time/batch = 0.6508s	
1660/22300 (epoch 3.722), train_loss = 1.77070252, grad/param norm = 2.9429e-01, time/batch = 0.6558s	
1661/22300 (epoch 3.724), train_loss = 1.83219023, grad/param norm = 2.8499e-01, time/batch = 0.6498s	
1662/22300 (epoch 3.726), train_loss = 1.78352716, grad/param norm = 2.5138e-01, time/batch = 0.6421s	
1663/22300 (epoch 3.729), train_loss = 1.85388177, grad/param norm = 2.5350e-01, time/batch = 0.6461s	
1664/22300 (epoch 3.731), train_loss = 1.81169657, grad/param norm = 2.6134e-01, time/batch = 0.6529s	
1665/22300 (epoch 3.733), train_loss = 1.86668581, grad/param norm = 2.6162e-01, time/batch = 0.6651s	
1666/22300 (epoch 3.735), train_loss = 1.76753169, grad/param norm = 2.5433e-01, time/batch = 0.6563s	
1667/22300 (epoch 3.738), train_loss = 1.78069054, grad/param norm = 2.7502e-01, time/batch = 0.6611s	
1668/22300 (epoch 3.740), train_loss = 1.55255282, grad/param norm = 2.1987e-01, time/batch = 0.6660s	
1669/22300 (epoch 3.742), train_loss = 1.73761368, grad/param norm = 2.3273e-01, time/batch = 0.6669s	
1670/22300 (epoch 3.744), train_loss = 1.80240514, grad/param norm = 2.3924e-01, time/batch = 0.6618s	
1671/22300 (epoch 3.747), train_loss = 1.72240883, grad/param norm = 2.6003e-01, time/batch = 0.6669s	
1672/22300 (epoch 3.749), train_loss = 1.96579186, grad/param norm = 2.7732e-01, time/batch = 0.6755s	
1673/22300 (epoch 3.751), train_loss = 1.79272278, grad/param norm = 2.3780e-01, time/batch = 0.6762s	
1674/22300 (epoch 3.753), train_loss = 1.80143755, grad/param norm = 2.3242e-01, time/batch = 0.6750s	
1675/22300 (epoch 3.756), train_loss = 1.76876623, grad/param norm = 2.5908e-01, time/batch = 0.6738s	
1676/22300 (epoch 3.758), train_loss = 1.63263251, grad/param norm = 2.4949e-01, time/batch = 0.6774s	
1677/22300 (epoch 3.760), train_loss = 1.71248334, grad/param norm = 2.5357e-01, time/batch = 0.6726s	
1678/22300 (epoch 3.762), train_loss = 1.76096222, grad/param norm = 2.5301e-01, time/batch = 0.6753s	
1679/22300 (epoch 3.765), train_loss = 1.81054943, grad/param norm = 2.1625e-01, time/batch = 0.6743s	
1680/22300 (epoch 3.767), train_loss = 1.85128840, grad/param norm = 2.2239e-01, time/batch = 0.6743s	
1681/22300 (epoch 3.769), train_loss = 1.77517815, grad/param norm = 2.6679e-01, time/batch = 0.6628s	
1682/22300 (epoch 3.771), train_loss = 1.70650250, grad/param norm = 2.7637e-01, time/batch = 0.6536s	
1683/22300 (epoch 3.774), train_loss = 1.79050433, grad/param norm = 2.2483e-01, time/batch = 0.6530s	
1684/22300 (epoch 3.776), train_loss = 1.66602117, grad/param norm = 2.0485e-01, time/batch = 0.6509s	
1685/22300 (epoch 3.778), train_loss = 1.84485277, grad/param norm = 2.5516e-01, time/batch = 0.6429s	
1686/22300 (epoch 3.780), train_loss = 1.85536662, grad/param norm = 2.4754e-01, time/batch = 0.6446s	
1687/22300 (epoch 3.783), train_loss = 1.81223493, grad/param norm = 2.7082e-01, time/batch = 0.6439s	
1688/22300 (epoch 3.785), train_loss = 1.77428655, grad/param norm = 2.6345e-01, time/batch = 0.6443s	
1689/22300 (epoch 3.787), train_loss = 1.69355817, grad/param norm = 2.6123e-01, time/batch = 0.6503s	
1690/22300 (epoch 3.789), train_loss = 1.73894386, grad/param norm = 2.3365e-01, time/batch = 0.6617s	
1691/22300 (epoch 3.791), train_loss = 1.87304230, grad/param norm = 2.7728e-01, time/batch = 0.6476s	
1692/22300 (epoch 3.794), train_loss = 1.84243749, grad/param norm = 2.6486e-01, time/batch = 0.6387s	
1693/22300 (epoch 3.796), train_loss = 1.81825781, grad/param norm = 2.4753e-01, time/batch = 0.6362s	
1694/22300 (epoch 3.798), train_loss = 1.78419019, grad/param norm = 2.2140e-01, time/batch = 0.6478s	
1695/22300 (epoch 3.800), train_loss = 1.61898036, grad/param norm = 2.4764e-01, time/batch = 0.6429s	
1696/22300 (epoch 3.803), train_loss = 1.61127136, grad/param norm = 2.6317e-01, time/batch = 0.6557s	
1697/22300 (epoch 3.805), train_loss = 1.74056172, grad/param norm = 2.4342e-01, time/batch = 0.6621s	
1698/22300 (epoch 3.807), train_loss = 1.74075817, grad/param norm = 2.4381e-01, time/batch = 0.6577s	
1699/22300 (epoch 3.809), train_loss = 1.80502795, grad/param norm = 2.6180e-01, time/batch = 0.6552s	
1700/22300 (epoch 3.812), train_loss = 1.86335259, grad/param norm = 2.7390e-01, time/batch = 0.6588s	
1701/22300 (epoch 3.814), train_loss = 1.72799245, grad/param norm = 2.2567e-01, time/batch = 0.6612s	
1702/22300 (epoch 3.816), train_loss = 1.84252864, grad/param norm = 2.2354e-01, time/batch = 0.6532s	
1703/22300 (epoch 3.818), train_loss = 1.78773014, grad/param norm = 2.3380e-01, time/batch = 0.6457s	
1704/22300 (epoch 3.821), train_loss = 1.91279162, grad/param norm = 2.5785e-01, time/batch = 0.6507s	
1705/22300 (epoch 3.823), train_loss = 1.67361806, grad/param norm = 2.5521e-01, time/batch = 0.6491s	
1706/22300 (epoch 3.825), train_loss = 1.70313415, grad/param norm = 2.2640e-01, time/batch = 0.6490s	
1707/22300 (epoch 3.827), train_loss = 1.73827297, grad/param norm = 2.3030e-01, time/batch = 0.6550s	
1708/22300 (epoch 3.830), train_loss = 1.73721618, grad/param norm = 2.5171e-01, time/batch = 0.6514s	
1709/22300 (epoch 3.832), train_loss = 1.67329895, grad/param norm = 2.4266e-01, time/batch = 0.6465s	
1710/22300 (epoch 3.834), train_loss = 1.91250449, grad/param norm = 2.4599e-01, time/batch = 0.6497s	
1711/22300 (epoch 3.836), train_loss = 1.77505518, grad/param norm = 2.5533e-01, time/batch = 0.6485s	
1712/22300 (epoch 3.839), train_loss = 1.77242260, grad/param norm = 2.2771e-01, time/batch = 0.6464s	
1713/22300 (epoch 3.841), train_loss = 1.72873431, grad/param norm = 2.7179e-01, time/batch = 0.6481s	
1714/22300 (epoch 3.843), train_loss = 1.70038111, grad/param norm = 2.8140e-01, time/batch = 0.6526s	
1715/22300 (epoch 3.845), train_loss = 1.74920602, grad/param norm = 2.5649e-01, time/batch = 0.6439s	
1716/22300 (epoch 3.848), train_loss = 1.73084233, grad/param norm = 2.5679e-01, time/batch = 0.6429s	
1717/22300 (epoch 3.850), train_loss = 1.79081476, grad/param norm = 2.5275e-01, time/batch = 0.6447s	
1718/22300 (epoch 3.852), train_loss = 1.80305815, grad/param norm = 2.4655e-01, time/batch = 0.6425s	
1719/22300 (epoch 3.854), train_loss = 1.88291700, grad/param norm = 2.6249e-01, time/batch = 0.6552s	
1720/22300 (epoch 3.857), train_loss = 1.70137306, grad/param norm = 2.7427e-01, time/batch = 0.6423s	
1721/22300 (epoch 3.859), train_loss = 1.64128538, grad/param norm = 2.2556e-01, time/batch = 0.6505s	
1722/22300 (epoch 3.861), train_loss = 1.74033723, grad/param norm = 2.1621e-01, time/batch = 0.6580s	
1723/22300 (epoch 3.863), train_loss = 1.65071889, grad/param norm = 2.3479e-01, time/batch = 0.6436s	
1724/22300 (epoch 3.865), train_loss = 1.62598680, grad/param norm = 2.2938e-01, time/batch = 0.6457s	
1725/22300 (epoch 3.868), train_loss = 1.66700812, grad/param norm = 2.1612e-01, time/batch = 0.6501s	
1726/22300 (epoch 3.870), train_loss = 1.71154193, grad/param norm = 2.4048e-01, time/batch = 0.6599s	
1727/22300 (epoch 3.872), train_loss = 1.76897671, grad/param norm = 2.6047e-01, time/batch = 0.6634s	
1728/22300 (epoch 3.874), train_loss = 1.80727420, grad/param norm = 2.6801e-01, time/batch = 0.6600s	
1729/22300 (epoch 3.877), train_loss = 1.65621380, grad/param norm = 2.4376e-01, time/batch = 0.6523s	
1730/22300 (epoch 3.879), train_loss = 1.54485563, grad/param norm = 2.2709e-01, time/batch = 0.6637s	
1731/22300 (epoch 3.881), train_loss = 1.70303415, grad/param norm = 2.7582e-01, time/batch = 0.6654s	
1732/22300 (epoch 3.883), train_loss = 1.78541806, grad/param norm = 3.0698e-01, time/batch = 0.6625s	
1733/22300 (epoch 3.886), train_loss = 1.71924462, grad/param norm = 2.3074e-01, time/batch = 0.6625s	
1734/22300 (epoch 3.888), train_loss = 1.68959935, grad/param norm = 2.4274e-01, time/batch = 0.6615s	
1735/22300 (epoch 3.890), train_loss = 1.56838440, grad/param norm = 2.0942e-01, time/batch = 0.6584s	
1736/22300 (epoch 3.892), train_loss = 1.80826876, grad/param norm = 2.2840e-01, time/batch = 0.6623s	
1737/22300 (epoch 3.895), train_loss = 1.73519125, grad/param norm = 2.1908e-01, time/batch = 0.6759s	
1738/22300 (epoch 3.897), train_loss = 1.79250018, grad/param norm = 2.6195e-01, time/batch = 0.6649s	
1739/22300 (epoch 3.899), train_loss = 1.71626885, grad/param norm = 2.3591e-01, time/batch = 0.6645s	
1740/22300 (epoch 3.901), train_loss = 1.67549442, grad/param norm = 2.4641e-01, time/batch = 0.6591s	
1741/22300 (epoch 3.904), train_loss = 1.64690994, grad/param norm = 2.4659e-01, time/batch = 0.6506s	
1742/22300 (epoch 3.906), train_loss = 1.77583718, grad/param norm = 2.2622e-01, time/batch = 0.6516s	
1743/22300 (epoch 3.908), train_loss = 1.68257587, grad/param norm = 2.2664e-01, time/batch = 0.6658s	
1744/22300 (epoch 3.910), train_loss = 1.67443956, grad/param norm = 2.2238e-01, time/batch = 0.6608s	
1745/22300 (epoch 3.913), train_loss = 1.68008148, grad/param norm = 2.2234e-01, time/batch = 0.6637s	
1746/22300 (epoch 3.915), train_loss = 1.84086275, grad/param norm = 2.5117e-01, time/batch = 0.6611s	
1747/22300 (epoch 3.917), train_loss = 1.70599230, grad/param norm = 2.6196e-01, time/batch = 0.6609s	
1748/22300 (epoch 3.919), train_loss = 1.79438728, grad/param norm = 2.6076e-01, time/batch = 0.6625s	
1749/22300 (epoch 3.922), train_loss = 1.76039687, grad/param norm = 2.8677e-01, time/batch = 0.6580s	
1750/22300 (epoch 3.924), train_loss = 1.68710230, grad/param norm = 2.6990e-01, time/batch = 0.6610s	
1751/22300 (epoch 3.926), train_loss = 1.53920760, grad/param norm = 2.1938e-01, time/batch = 0.6620s	
1752/22300 (epoch 3.928), train_loss = 1.76093224, grad/param norm = 2.1408e-01, time/batch = 0.6620s	
1753/22300 (epoch 3.930), train_loss = 1.77563497, grad/param norm = 2.3371e-01, time/batch = 0.6605s	
1754/22300 (epoch 3.933), train_loss = 1.72108865, grad/param norm = 2.5118e-01, time/batch = 0.6619s	
1755/22300 (epoch 3.935), train_loss = 1.83513122, grad/param norm = 2.2046e-01, time/batch = 0.6650s	
1756/22300 (epoch 3.937), train_loss = 1.73185216, grad/param norm = 2.2450e-01, time/batch = 0.6623s	
1757/22300 (epoch 3.939), train_loss = 1.76686013, grad/param norm = 2.2972e-01, time/batch = 0.6637s	
1758/22300 (epoch 3.942), train_loss = 1.83011063, grad/param norm = 2.5978e-01, time/batch = 0.6733s	
1759/22300 (epoch 3.944), train_loss = 1.92111023, grad/param norm = 2.6007e-01, time/batch = 0.6821s	
1760/22300 (epoch 3.946), train_loss = 1.69214780, grad/param norm = 2.5272e-01, time/batch = 0.6740s	
1761/22300 (epoch 3.948), train_loss = 1.72477501, grad/param norm = 2.5516e-01, time/batch = 0.6731s	
1762/22300 (epoch 3.951), train_loss = 1.61628860, grad/param norm = 2.3175e-01, time/batch = 0.6734s	
1763/22300 (epoch 3.953), train_loss = 1.71034978, grad/param norm = 2.4259e-01, time/batch = 0.6655s	
1764/22300 (epoch 3.955), train_loss = 1.88528858, grad/param norm = 2.5149e-01, time/batch = 0.6611s	
1765/22300 (epoch 3.957), train_loss = 1.85677212, grad/param norm = 2.5450e-01, time/batch = 0.6798s	
1766/22300 (epoch 3.960), train_loss = 1.84199837, grad/param norm = 3.1819e-01, time/batch = 0.6746s	
1767/22300 (epoch 3.962), train_loss = 1.79333828, grad/param norm = 3.2308e-01, time/batch = 0.6490s	
1768/22300 (epoch 3.964), train_loss = 1.75959976, grad/param norm = 2.1878e-01, time/batch = 0.6461s	
1769/22300 (epoch 3.966), train_loss = 1.75131990, grad/param norm = 2.5284e-01, time/batch = 0.6718s	
1770/22300 (epoch 3.969), train_loss = 1.63924342, grad/param norm = 2.1580e-01, time/batch = 0.6722s	
1771/22300 (epoch 3.971), train_loss = 1.68198097, grad/param norm = 2.4167e-01, time/batch = 0.6493s	
1772/22300 (epoch 3.973), train_loss = 1.65131598, grad/param norm = 2.2676e-01, time/batch = 0.6444s	
1773/22300 (epoch 3.975), train_loss = 1.92963662, grad/param norm = 2.5954e-01, time/batch = 0.6408s	
1774/22300 (epoch 3.978), train_loss = 1.57160290, grad/param norm = 2.0491e-01, time/batch = 0.6515s	
1775/22300 (epoch 3.980), train_loss = 1.78473433, grad/param norm = 2.2382e-01, time/batch = 0.6571s	
1776/22300 (epoch 3.982), train_loss = 1.61515456, grad/param norm = 2.1426e-01, time/batch = 0.6514s	
1777/22300 (epoch 3.984), train_loss = 1.77322393, grad/param norm = 2.3027e-01, time/batch = 0.6484s	
1778/22300 (epoch 3.987), train_loss = 1.68710282, grad/param norm = 2.3439e-01, time/batch = 0.6510s	
1779/22300 (epoch 3.989), train_loss = 1.79047285, grad/param norm = 2.5906e-01, time/batch = 0.6454s	
1780/22300 (epoch 3.991), train_loss = 1.84191436, grad/param norm = 2.2321e-01, time/batch = 0.6467s	
1781/22300 (epoch 3.993), train_loss = 1.79972342, grad/param norm = 2.3605e-01, time/batch = 0.6427s	
1782/22300 (epoch 3.996), train_loss = 1.86234324, grad/param norm = 2.3787e-01, time/batch = 0.6467s	
1783/22300 (epoch 3.998), train_loss = 1.73555644, grad/param norm = 2.6679e-01, time/batch = 0.6616s	
1784/22300 (epoch 4.000), train_loss = 1.67081597, grad/param norm = 2.3890e-01, time/batch = 0.6561s	
1785/22300 (epoch 4.002), train_loss = 1.76460477, grad/param norm = 2.4410e-01, time/batch = 0.6499s	
1786/22300 (epoch 4.004), train_loss = 1.76418197, grad/param norm = 2.4336e-01, time/batch = 0.6504s	
1787/22300 (epoch 4.007), train_loss = 1.72186145, grad/param norm = 2.2291e-01, time/batch = 0.6601s	
1788/22300 (epoch 4.009), train_loss = 1.69952866, grad/param norm = 2.3695e-01, time/batch = 0.6615s	
1789/22300 (epoch 4.011), train_loss = 1.82272101, grad/param norm = 2.6330e-01, time/batch = 0.6543s	
1790/22300 (epoch 4.013), train_loss = 1.67733558, grad/param norm = 2.9859e-01, time/batch = 0.6564s	
1791/22300 (epoch 4.016), train_loss = 1.69836580, grad/param norm = 2.6024e-01, time/batch = 0.6616s	
1792/22300 (epoch 4.018), train_loss = 1.79302581, grad/param norm = 2.5765e-01, time/batch = 0.6593s	
1793/22300 (epoch 4.020), train_loss = 1.65729243, grad/param norm = 2.2968e-01, time/batch = 0.6593s	
1794/22300 (epoch 4.022), train_loss = 1.70685141, grad/param norm = 2.7635e-01, time/batch = 0.6570s	
1795/22300 (epoch 4.025), train_loss = 1.72048288, grad/param norm = 2.7000e-01, time/batch = 0.6560s	
1796/22300 (epoch 4.027), train_loss = 1.86809824, grad/param norm = 2.4979e-01, time/batch = 0.6568s	
1797/22300 (epoch 4.029), train_loss = 1.64659475, grad/param norm = 2.1287e-01, time/batch = 0.6572s	
1798/22300 (epoch 4.031), train_loss = 1.54693278, grad/param norm = 1.9461e-01, time/batch = 0.6607s	
1799/22300 (epoch 4.034), train_loss = 1.61916384, grad/param norm = 2.1364e-01, time/batch = 0.6771s	
1800/22300 (epoch 4.036), train_loss = 1.55843802, grad/param norm = 2.3888e-01, time/batch = 0.6714s	
1801/22300 (epoch 4.038), train_loss = 1.57246996, grad/param norm = 2.1031e-01, time/batch = 0.6724s	
1802/22300 (epoch 4.040), train_loss = 1.74659258, grad/param norm = 2.4388e-01, time/batch = 0.6605s	
1803/22300 (epoch 4.043), train_loss = 1.79732440, grad/param norm = 2.6353e-01, time/batch = 0.6653s	
1804/22300 (epoch 4.045), train_loss = 1.68534696, grad/param norm = 2.2901e-01, time/batch = 0.6623s	
1805/22300 (epoch 4.047), train_loss = 1.71866073, grad/param norm = 2.3705e-01, time/batch = 0.6684s	
1806/22300 (epoch 4.049), train_loss = 1.63252242, grad/param norm = 2.3587e-01, time/batch = 0.6598s	
1807/22300 (epoch 4.052), train_loss = 1.79651440, grad/param norm = 2.3804e-01, time/batch = 0.6600s	
1808/22300 (epoch 4.054), train_loss = 1.69488034, grad/param norm = 2.2744e-01, time/batch = 0.6605s	
1809/22300 (epoch 4.056), train_loss = 1.57676644, grad/param norm = 2.0980e-01, time/batch = 0.6611s	
1810/22300 (epoch 4.058), train_loss = 1.50250431, grad/param norm = 1.9963e-01, time/batch = 0.6597s	
1811/22300 (epoch 4.061), train_loss = 1.57398746, grad/param norm = 2.5145e-01, time/batch = 0.6586s	
1812/22300 (epoch 4.063), train_loss = 1.83524217, grad/param norm = 2.5229e-01, time/batch = 0.6579s	
1813/22300 (epoch 4.065), train_loss = 1.60723254, grad/param norm = 2.4522e-01, time/batch = 0.6594s	
1814/22300 (epoch 4.067), train_loss = 1.69647502, grad/param norm = 2.5141e-01, time/batch = 0.6557s	
1815/22300 (epoch 4.070), train_loss = 1.64200111, grad/param norm = 2.6850e-01, time/batch = 0.6606s	
1816/22300 (epoch 4.072), train_loss = 1.73308306, grad/param norm = 2.3211e-01, time/batch = 0.6635s	
1817/22300 (epoch 4.074), train_loss = 1.70947431, grad/param norm = 2.1438e-01, time/batch = 0.6674s	
1818/22300 (epoch 4.076), train_loss = 1.54490181, grad/param norm = 2.1682e-01, time/batch = 0.6733s	
1819/22300 (epoch 4.078), train_loss = 1.60634299, grad/param norm = 2.1372e-01, time/batch = 0.6718s	
1820/22300 (epoch 4.081), train_loss = 1.74708811, grad/param norm = 2.4674e-01, time/batch = 0.6654s	
1821/22300 (epoch 4.083), train_loss = 1.72943445, grad/param norm = 2.5703e-01, time/batch = 0.6637s	
1822/22300 (epoch 4.085), train_loss = 1.81527142, grad/param norm = 2.3603e-01, time/batch = 0.6659s	
1823/22300 (epoch 4.087), train_loss = 1.70187025, grad/param norm = 2.5891e-01, time/batch = 0.6646s	
1824/22300 (epoch 4.090), train_loss = 1.65219177, grad/param norm = 2.3594e-01, time/batch = 0.6626s	
1825/22300 (epoch 4.092), train_loss = 1.73073125, grad/param norm = 2.6616e-01, time/batch = 0.6681s	
1826/22300 (epoch 4.094), train_loss = 1.57052241, grad/param norm = 2.3160e-01, time/batch = 0.6692s	
1827/22300 (epoch 4.096), train_loss = 1.78779208, grad/param norm = 2.2595e-01, time/batch = 0.6600s	
1828/22300 (epoch 4.099), train_loss = 1.74315177, grad/param norm = 2.5252e-01, time/batch = 0.6639s	
1829/22300 (epoch 4.101), train_loss = 1.82433735, grad/param norm = 2.5796e-01, time/batch = 0.6927s	
1830/22300 (epoch 4.103), train_loss = 1.76839176, grad/param norm = 2.8159e-01, time/batch = 0.6778s	
1831/22300 (epoch 4.105), train_loss = 1.71145988, grad/param norm = 2.5475e-01, time/batch = 0.6802s	
1832/22300 (epoch 4.108), train_loss = 1.75929378, grad/param norm = 2.5921e-01, time/batch = 0.6775s	
1833/22300 (epoch 4.110), train_loss = 1.69571561, grad/param norm = 2.1194e-01, time/batch = 0.6747s	
1834/22300 (epoch 4.112), train_loss = 1.65630526, grad/param norm = 2.4465e-01, time/batch = 0.6755s	
1835/22300 (epoch 4.114), train_loss = 1.78130497, grad/param norm = 2.5090e-01, time/batch = 0.6665s	
1836/22300 (epoch 4.117), train_loss = 1.89249922, grad/param norm = 2.2888e-01, time/batch = 0.6614s	
1837/22300 (epoch 4.119), train_loss = 1.71752854, grad/param norm = 2.3126e-01, time/batch = 0.6593s	
1838/22300 (epoch 4.121), train_loss = 1.75300005, grad/param norm = 2.3371e-01, time/batch = 0.6572s	
1839/22300 (epoch 4.123), train_loss = 1.55304517, grad/param norm = 2.1951e-01, time/batch = 0.6563s	
1840/22300 (epoch 4.126), train_loss = 1.62089085, grad/param norm = 2.3906e-01, time/batch = 0.6594s	
1841/22300 (epoch 4.128), train_loss = 1.69544846, grad/param norm = 2.3481e-01, time/batch = 0.6573s	
1842/22300 (epoch 4.130), train_loss = 1.70062449, grad/param norm = 2.3764e-01, time/batch = 0.6584s	
1843/22300 (epoch 4.132), train_loss = 1.62958019, grad/param norm = 2.6630e-01, time/batch = 0.6581s	
1844/22300 (epoch 4.135), train_loss = 1.60367631, grad/param norm = 2.5598e-01, time/batch = 0.6553s	
1845/22300 (epoch 4.137), train_loss = 1.44877385, grad/param norm = 2.3204e-01, time/batch = 0.6764s	
1846/22300 (epoch 4.139), train_loss = 1.70994866, grad/param norm = 2.5718e-01, time/batch = 0.6648s	
1847/22300 (epoch 4.141), train_loss = 1.79040946, grad/param norm = 2.2222e-01, time/batch = 0.6631s	
1848/22300 (epoch 4.143), train_loss = 1.71092662, grad/param norm = 2.4449e-01, time/batch = 0.6662s	
1849/22300 (epoch 4.146), train_loss = 1.79722092, grad/param norm = 2.4947e-01, time/batch = 0.6638s	
1850/22300 (epoch 4.148), train_loss = 1.64423389, grad/param norm = 2.4854e-01, time/batch = 0.6677s	
1851/22300 (epoch 4.150), train_loss = 1.76057929, grad/param norm = 2.7709e-01, time/batch = 0.6615s	
1852/22300 (epoch 4.152), train_loss = 1.76251167, grad/param norm = 2.9536e-01, time/batch = 0.6643s	
1853/22300 (epoch 4.155), train_loss = 1.65496509, grad/param norm = 2.3801e-01, time/batch = 0.6614s	
1854/22300 (epoch 4.157), train_loss = 1.76637403, grad/param norm = 2.6592e-01, time/batch = 0.6604s	
1855/22300 (epoch 4.159), train_loss = 1.70539338, grad/param norm = 2.3393e-01, time/batch = 0.6662s	
1856/22300 (epoch 4.161), train_loss = 1.76548135, grad/param norm = 2.4204e-01, time/batch = 0.6624s	
1857/22300 (epoch 4.164), train_loss = 1.65382368, grad/param norm = 3.0363e-01, time/batch = 0.6602s	
1858/22300 (epoch 4.166), train_loss = 1.68204519, grad/param norm = 2.5197e-01, time/batch = 0.6628s	
1859/22300 (epoch 4.168), train_loss = 1.69577849, grad/param norm = 2.4045e-01, time/batch = 0.6685s	
1860/22300 (epoch 4.170), train_loss = 1.72216077, grad/param norm = 2.3293e-01, time/batch = 0.6620s	
1861/22300 (epoch 4.173), train_loss = 1.84785830, grad/param norm = 2.4309e-01, time/batch = 0.6635s	
1862/22300 (epoch 4.175), train_loss = 1.64772069, grad/param norm = 2.4738e-01, time/batch = 0.6619s	
1863/22300 (epoch 4.177), train_loss = 1.49941885, grad/param norm = 2.0345e-01, time/batch = 0.6653s	
1864/22300 (epoch 4.179), train_loss = 1.56946961, grad/param norm = 2.1263e-01, time/batch = 0.6677s	
1865/22300 (epoch 4.182), train_loss = 1.74679106, grad/param norm = 2.1982e-01, time/batch = 0.6666s	
1866/22300 (epoch 4.184), train_loss = 1.84653339, grad/param norm = 2.4039e-01, time/batch = 0.6603s	
1867/22300 (epoch 4.186), train_loss = 1.70926110, grad/param norm = 2.2739e-01, time/batch = 0.6624s	
1868/22300 (epoch 4.188), train_loss = 1.78906925, grad/param norm = 2.8094e-01, time/batch = 0.6601s	
1869/22300 (epoch 4.191), train_loss = 1.79154103, grad/param norm = 2.6169e-01, time/batch = 0.6652s	
1870/22300 (epoch 4.193), train_loss = 1.61612135, grad/param norm = 2.3243e-01, time/batch = 0.6594s	
1871/22300 (epoch 4.195), train_loss = 1.56084694, grad/param norm = 2.1429e-01, time/batch = 0.6600s	
1872/22300 (epoch 4.197), train_loss = 1.71473950, grad/param norm = 2.3827e-01, time/batch = 0.6605s	
1873/22300 (epoch 4.200), train_loss = 1.63815794, grad/param norm = 2.2507e-01, time/batch = 0.6585s	
1874/22300 (epoch 4.202), train_loss = 1.65992451, grad/param norm = 2.7777e-01, time/batch = 0.6557s	
1875/22300 (epoch 4.204), train_loss = 1.61874973, grad/param norm = 2.8624e-01, time/batch = 0.6648s	
1876/22300 (epoch 4.206), train_loss = 1.51026977, grad/param norm = 2.6358e-01, time/batch = 0.6609s	
1877/22300 (epoch 4.209), train_loss = 1.67285870, grad/param norm = 2.5284e-01, time/batch = 0.6628s	
1878/22300 (epoch 4.211), train_loss = 1.60444501, grad/param norm = 2.7447e-01, time/batch = 0.6612s	
1879/22300 (epoch 4.213), train_loss = 1.60985835, grad/param norm = 2.4797e-01, time/batch = 0.6640s	
1880/22300 (epoch 4.215), train_loss = 1.81494713, grad/param norm = 2.6200e-01, time/batch = 0.6650s	
1881/22300 (epoch 4.217), train_loss = 1.71410861, grad/param norm = 2.3423e-01, time/batch = 0.6614s	
1882/22300 (epoch 4.220), train_loss = 1.64074266, grad/param norm = 2.5026e-01, time/batch = 0.6647s	
1883/22300 (epoch 4.222), train_loss = 1.67395595, grad/param norm = 2.4321e-01, time/batch = 0.6616s	
1884/22300 (epoch 4.224), train_loss = 1.59664048, grad/param norm = 2.5155e-01, time/batch = 0.6599s	
1885/22300 (epoch 4.226), train_loss = 1.70339695, grad/param norm = 2.7927e-01, time/batch = 0.6702s	
1886/22300 (epoch 4.229), train_loss = 1.75572266, grad/param norm = 2.6135e-01, time/batch = 0.6825s	
1887/22300 (epoch 4.231), train_loss = 1.82764550, grad/param norm = 2.5442e-01, time/batch = 0.6745s	
1888/22300 (epoch 4.233), train_loss = 1.79810480, grad/param norm = 2.3540e-01, time/batch = 0.6679s	
1889/22300 (epoch 4.235), train_loss = 1.60703856, grad/param norm = 2.1477e-01, time/batch = 0.6589s	
1890/22300 (epoch 4.238), train_loss = 1.59771185, grad/param norm = 2.4588e-01, time/batch = 0.6688s	
1891/22300 (epoch 4.240), train_loss = 1.54446280, grad/param norm = 2.2107e-01, time/batch = 0.6686s	
1892/22300 (epoch 4.242), train_loss = 1.66511496, grad/param norm = 2.1958e-01, time/batch = 0.6672s	
1893/22300 (epoch 4.244), train_loss = 1.38518513, grad/param norm = 2.0978e-01, time/batch = 0.6612s	
1894/22300 (epoch 4.247), train_loss = 1.72344693, grad/param norm = 2.2792e-01, time/batch = 0.6639s	
1895/22300 (epoch 4.249), train_loss = 1.59888017, grad/param norm = 2.2344e-01, time/batch = 0.6625s	
1896/22300 (epoch 4.251), train_loss = 1.50841651, grad/param norm = 2.2340e-01, time/batch = 0.6581s	
1897/22300 (epoch 4.253), train_loss = 1.61981254, grad/param norm = 2.2323e-01, time/batch = 0.6599s	
1898/22300 (epoch 4.256), train_loss = 1.77165315, grad/param norm = 2.7807e-01, time/batch = 0.6549s	
1899/22300 (epoch 4.258), train_loss = 1.79825920, grad/param norm = 2.7445e-01, time/batch = 0.6612s	
1900/22300 (epoch 4.260), train_loss = 1.73101564, grad/param norm = 2.8105e-01, time/batch = 0.6625s	
1901/22300 (epoch 4.262), train_loss = 1.73244994, grad/param norm = 2.6456e-01, time/batch = 0.6659s	
1902/22300 (epoch 4.265), train_loss = 1.67981968, grad/param norm = 2.5345e-01, time/batch = 0.6697s	
1903/22300 (epoch 4.267), train_loss = 1.63065783, grad/param norm = 2.4961e-01, time/batch = 0.6622s	
1904/22300 (epoch 4.269), train_loss = 1.65687068, grad/param norm = 2.3705e-01, time/batch = 0.6604s	
1905/22300 (epoch 4.271), train_loss = 1.70722188, grad/param norm = 2.5025e-01, time/batch = 0.6668s	
1906/22300 (epoch 4.274), train_loss = 1.60219779, grad/param norm = 2.7935e-01, time/batch = 0.6686s	
1907/22300 (epoch 4.276), train_loss = 1.50689146, grad/param norm = 2.2820e-01, time/batch = 0.6749s	
1908/22300 (epoch 4.278), train_loss = 1.52955353, grad/param norm = 2.6839e-01, time/batch = 0.6705s	
1909/22300 (epoch 4.280), train_loss = 1.59666248, grad/param norm = 2.5680e-01, time/batch = 0.6648s	
1910/22300 (epoch 4.283), train_loss = 1.50241871, grad/param norm = 2.2495e-01, time/batch = 0.6626s	
1911/22300 (epoch 4.285), train_loss = 1.63767361, grad/param norm = 2.5005e-01, time/batch = 0.6822s	
1912/22300 (epoch 4.287), train_loss = 1.63848119, grad/param norm = 2.5868e-01, time/batch = 0.6759s	
1913/22300 (epoch 4.289), train_loss = 1.63277771, grad/param norm = 2.5621e-01, time/batch = 0.6717s	
1914/22300 (epoch 4.291), train_loss = 1.65740750, grad/param norm = 2.3525e-01, time/batch = 0.6707s	
1915/22300 (epoch 4.294), train_loss = 1.56929343, grad/param norm = 2.2620e-01, time/batch = 0.6620s	
1916/22300 (epoch 4.296), train_loss = 1.77286526, grad/param norm = 2.6733e-01, time/batch = 0.6632s	
1917/22300 (epoch 4.298), train_loss = 1.70792333, grad/param norm = 2.8306e-01, time/batch = 0.6916s	
1918/22300 (epoch 4.300), train_loss = 1.75859904, grad/param norm = 2.4059e-01, time/batch = 0.6816s	
1919/22300 (epoch 4.303), train_loss = 1.64068388, grad/param norm = 2.3993e-01, time/batch = 0.6719s	
1920/22300 (epoch 4.305), train_loss = 1.79498205, grad/param norm = 2.9720e-01, time/batch = 0.6667s	
1921/22300 (epoch 4.307), train_loss = 1.71179166, grad/param norm = 2.6510e-01, time/batch = 0.6793s	
1922/22300 (epoch 4.309), train_loss = 1.65974445, grad/param norm = 2.4499e-01, time/batch = 0.6816s	
1923/22300 (epoch 4.312), train_loss = 1.56638765, grad/param norm = 2.3640e-01, time/batch = 0.6793s	
1924/22300 (epoch 4.314), train_loss = 1.69071038, grad/param norm = 2.2321e-01, time/batch = 0.6733s	
1925/22300 (epoch 4.316), train_loss = 1.65394553, grad/param norm = 2.3890e-01, time/batch = 0.6781s	
1926/22300 (epoch 4.318), train_loss = 1.78128509, grad/param norm = 2.8951e-01, time/batch = 0.6606s	
1927/22300 (epoch 4.321), train_loss = 1.74338158, grad/param norm = 2.7403e-01, time/batch = 0.6636s	
1928/22300 (epoch 4.323), train_loss = 1.68276162, grad/param norm = 2.2141e-01, time/batch = 0.6686s	
1929/22300 (epoch 4.325), train_loss = 1.55329433, grad/param norm = 2.3875e-01, time/batch = 0.6694s	
1930/22300 (epoch 4.327), train_loss = 1.62215620, grad/param norm = 2.3747e-01, time/batch = 0.6625s	
1931/22300 (epoch 4.330), train_loss = 1.70437245, grad/param norm = 2.6129e-01, time/batch = 0.6652s	
1932/22300 (epoch 4.332), train_loss = 1.58859172, grad/param norm = 2.5378e-01, time/batch = 0.6786s	
1933/22300 (epoch 4.334), train_loss = 1.53794868, grad/param norm = 2.5466e-01, time/batch = 0.6783s	
1934/22300 (epoch 4.336), train_loss = 1.62744700, grad/param norm = 2.5504e-01, time/batch = 0.6772s	
1935/22300 (epoch 4.339), train_loss = 1.71338988, grad/param norm = 2.7986e-01, time/batch = 0.6710s	
1936/22300 (epoch 4.341), train_loss = 1.68325932, grad/param norm = 2.8525e-01, time/batch = 0.6712s	
1937/22300 (epoch 4.343), train_loss = 1.71164548, grad/param norm = 2.6417e-01, time/batch = 0.6637s	
1938/22300 (epoch 4.345), train_loss = 1.67749507, grad/param norm = 2.4858e-01, time/batch = 0.6644s	
1939/22300 (epoch 4.348), train_loss = 1.60265942, grad/param norm = 2.2441e-01, time/batch = 0.6580s	
1940/22300 (epoch 4.350), train_loss = 1.52127369, grad/param norm = 2.2568e-01, time/batch = 0.6616s	
1941/22300 (epoch 4.352), train_loss = 1.70722488, grad/param norm = 2.2008e-01, time/batch = 0.6622s	
1942/22300 (epoch 4.354), train_loss = 1.69530275, grad/param norm = 2.2669e-01, time/batch = 0.6618s	
1943/22300 (epoch 4.357), train_loss = 1.78017256, grad/param norm = 2.7312e-01, time/batch = 0.6496s	
1944/22300 (epoch 4.359), train_loss = 1.69415958, grad/param norm = 2.4342e-01, time/batch = 0.6482s	
1945/22300 (epoch 4.361), train_loss = 1.74625142, grad/param norm = 2.2646e-01, time/batch = 0.6485s	
1946/22300 (epoch 4.363), train_loss = 1.84877257, grad/param norm = 2.7561e-01, time/batch = 0.6462s	
1947/22300 (epoch 4.365), train_loss = 1.68695929, grad/param norm = 2.3685e-01, time/batch = 0.6472s	
1948/22300 (epoch 4.368), train_loss = 1.72156259, grad/param norm = 2.5994e-01, time/batch = 0.6470s	
1949/22300 (epoch 4.370), train_loss = 1.67940716, grad/param norm = 2.4031e-01, time/batch = 0.6511s	
1950/22300 (epoch 4.372), train_loss = 1.55463275, grad/param norm = 2.6805e-01, time/batch = 0.6539s	
1951/22300 (epoch 4.374), train_loss = 1.57972676, grad/param norm = 2.5408e-01, time/batch = 0.6488s	
1952/22300 (epoch 4.377), train_loss = 1.71611958, grad/param norm = 2.4080e-01, time/batch = 0.6503s	
1953/22300 (epoch 4.379), train_loss = 1.64118061, grad/param norm = 2.4707e-01, time/batch = 0.6542s	
1954/22300 (epoch 4.381), train_loss = 1.73440756, grad/param norm = 2.5077e-01, time/batch = 0.6490s	
1955/22300 (epoch 4.383), train_loss = 1.55436191, grad/param norm = 2.3613e-01, time/batch = 0.6563s	
1956/22300 (epoch 4.386), train_loss = 1.66694579, grad/param norm = 2.8858e-01, time/batch = 0.6561s	
1957/22300 (epoch 4.388), train_loss = 1.61964207, grad/param norm = 2.4504e-01, time/batch = 0.6478s	
1958/22300 (epoch 4.390), train_loss = 1.62841109, grad/param norm = 2.5050e-01, time/batch = 0.6481s	
1959/22300 (epoch 4.392), train_loss = 1.60326913, grad/param norm = 2.3021e-01, time/batch = 0.6449s	
1960/22300 (epoch 4.395), train_loss = 1.57914974, grad/param norm = 2.3342e-01, time/batch = 0.6414s	
1961/22300 (epoch 4.397), train_loss = 1.46529830, grad/param norm = 2.4863e-01, time/batch = 0.6471s	
1962/22300 (epoch 4.399), train_loss = 1.65079945, grad/param norm = 2.4302e-01, time/batch = 0.6482s	
1963/22300 (epoch 4.401), train_loss = 1.57755826, grad/param norm = 2.5196e-01, time/batch = 0.6496s	
1964/22300 (epoch 4.404), train_loss = 1.63660822, grad/param norm = 2.6736e-01, time/batch = 0.6508s	
1965/22300 (epoch 4.406), train_loss = 1.81306250, grad/param norm = 2.5410e-01, time/batch = 0.6520s	
1966/22300 (epoch 4.408), train_loss = 1.64622321, grad/param norm = 2.6336e-01, time/batch = 0.6491s	
1967/22300 (epoch 4.410), train_loss = 1.63465854, grad/param norm = 2.6076e-01, time/batch = 0.6544s	
1968/22300 (epoch 4.413), train_loss = 1.67449510, grad/param norm = 2.7477e-01, time/batch = 0.6602s	
1969/22300 (epoch 4.415), train_loss = 1.57181039, grad/param norm = 2.4650e-01, time/batch = 0.6586s	
1970/22300 (epoch 4.417), train_loss = 1.72982056, grad/param norm = 2.4857e-01, time/batch = 0.6548s	
1971/22300 (epoch 4.419), train_loss = 1.56120128, grad/param norm = 2.2404e-01, time/batch = 0.6502s	
1972/22300 (epoch 4.422), train_loss = 1.64455458, grad/param norm = 2.3143e-01, time/batch = 0.6475s	
1973/22300 (epoch 4.424), train_loss = 1.71055049, grad/param norm = 2.8250e-01, time/batch = 0.6467s	
1974/22300 (epoch 4.426), train_loss = 1.61492610, grad/param norm = 2.5879e-01, time/batch = 0.6472s	
1975/22300 (epoch 4.428), train_loss = 1.74926171, grad/param norm = 2.8496e-01, time/batch = 0.6479s	
1976/22300 (epoch 4.430), train_loss = 1.65133219, grad/param norm = 2.2352e-01, time/batch = 0.6478s	
1977/22300 (epoch 4.433), train_loss = 1.60488814, grad/param norm = 1.9555e-01, time/batch = 0.6474s	
1978/22300 (epoch 4.435), train_loss = 1.68604208, grad/param norm = 2.4151e-01, time/batch = 0.6410s	
1979/22300 (epoch 4.437), train_loss = 1.54608848, grad/param norm = 2.5642e-01, time/batch = 0.6486s	
1980/22300 (epoch 4.439), train_loss = 1.54559527, grad/param norm = 2.4462e-01, time/batch = 0.6474s	
1981/22300 (epoch 4.442), train_loss = 1.67817949, grad/param norm = 2.7211e-01, time/batch = 0.6510s	
1982/22300 (epoch 4.444), train_loss = 1.64938379, grad/param norm = 2.3347e-01, time/batch = 0.6417s	
1983/22300 (epoch 4.446), train_loss = 1.58540008, grad/param norm = 2.4171e-01, time/batch = 0.6507s	
1984/22300 (epoch 4.448), train_loss = 1.45694485, grad/param norm = 2.2211e-01, time/batch = 0.6557s	
1985/22300 (epoch 4.451), train_loss = 1.77207507, grad/param norm = 2.5507e-01, time/batch = 0.6558s	
1986/22300 (epoch 4.453), train_loss = 1.59366193, grad/param norm = 2.3814e-01, time/batch = 0.6504s	
1987/22300 (epoch 4.455), train_loss = 1.66852327, grad/param norm = 2.3512e-01, time/batch = 0.6568s	
1988/22300 (epoch 4.457), train_loss = 1.57276946, grad/param norm = 2.3873e-01, time/batch = 0.6595s	
1989/22300 (epoch 4.460), train_loss = 1.57226608, grad/param norm = 2.6883e-01, time/batch = 0.6548s	
1990/22300 (epoch 4.462), train_loss = 1.60658629, grad/param norm = 2.2796e-01, time/batch = 0.6523s	
1991/22300 (epoch 4.464), train_loss = 1.60193263, grad/param norm = 2.4948e-01, time/batch = 0.6546s	
1992/22300 (epoch 4.466), train_loss = 1.64227053, grad/param norm = 2.4221e-01, time/batch = 0.6555s	
1993/22300 (epoch 4.469), train_loss = 1.60409712, grad/param norm = 2.3464e-01, time/batch = 0.6612s	
1994/22300 (epoch 4.471), train_loss = 1.70867154, grad/param norm = 2.3826e-01, time/batch = 0.6613s	
1995/22300 (epoch 4.473), train_loss = 1.76365753, grad/param norm = 2.3061e-01, time/batch = 0.6726s	
1996/22300 (epoch 4.475), train_loss = 1.62258493, grad/param norm = 2.5682e-01, time/batch = 0.6717s	
1997/22300 (epoch 4.478), train_loss = 1.55738868, grad/param norm = 2.4030e-01, time/batch = 0.6713s	
1998/22300 (epoch 4.480), train_loss = 1.56748363, grad/param norm = 2.4340e-01, time/batch = 0.6736s	
1999/22300 (epoch 4.482), train_loss = 1.54571639, grad/param norm = 2.3217e-01, time/batch = 0.6662s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch4.48_1.8146.t7	
2000/22300 (epoch 4.484), train_loss = 1.53466366, grad/param norm = 2.2012e-01, time/batch = 0.6775s	
2001/22300 (epoch 4.487), train_loss = 1.68589161, grad/param norm = 2.5349e-01, time/batch = 0.6879s	
2002/22300 (epoch 4.489), train_loss = 1.69330779, grad/param norm = 2.4779e-01, time/batch = 0.6796s	
2003/22300 (epoch 4.491), train_loss = 1.55287143, grad/param norm = 2.3074e-01, time/batch = 0.6757s	
2004/22300 (epoch 4.493), train_loss = 1.73158610, grad/param norm = 2.3987e-01, time/batch = 0.6703s	
2005/22300 (epoch 4.496), train_loss = 1.64318708, grad/param norm = 2.5843e-01, time/batch = 0.6698s	
2006/22300 (epoch 4.498), train_loss = 1.64938711, grad/param norm = 2.5670e-01, time/batch = 0.6697s	
2007/22300 (epoch 4.500), train_loss = 1.53371392, grad/param norm = 2.4224e-01, time/batch = 0.6782s	
2008/22300 (epoch 4.502), train_loss = 1.61457233, grad/param norm = 2.7010e-01, time/batch = 0.6696s	
2009/22300 (epoch 4.504), train_loss = 1.60446360, grad/param norm = 2.5712e-01, time/batch = 0.6752s	
2010/22300 (epoch 4.507), train_loss = 1.56831316, grad/param norm = 2.5434e-01, time/batch = 0.6659s	
2011/22300 (epoch 4.509), train_loss = 1.69340433, grad/param norm = 2.3992e-01, time/batch = 0.6636s	
2012/22300 (epoch 4.511), train_loss = 1.48865718, grad/param norm = 2.7532e-01, time/batch = 0.6635s	
2013/22300 (epoch 4.513), train_loss = 1.47125261, grad/param norm = 2.3122e-01, time/batch = 0.6618s	
2014/22300 (epoch 4.516), train_loss = 1.69748661, grad/param norm = 2.9166e-01, time/batch = 0.6620s	
2015/22300 (epoch 4.518), train_loss = 1.62033630, grad/param norm = 2.7515e-01, time/batch = 0.6641s	
2016/22300 (epoch 4.520), train_loss = 1.70397855, grad/param norm = 2.5691e-01, time/batch = 0.6672s	
2017/22300 (epoch 4.522), train_loss = 1.52126852, grad/param norm = 2.6430e-01, time/batch = 0.6616s	
2018/22300 (epoch 4.525), train_loss = 1.55049843, grad/param norm = 2.8785e-01, time/batch = 0.6618s	
2019/22300 (epoch 4.527), train_loss = 1.77599111, grad/param norm = 2.5996e-01, time/batch = 0.6655s	
2020/22300 (epoch 4.529), train_loss = 1.58004111, grad/param norm = 2.6110e-01, time/batch = 0.6596s	
2021/22300 (epoch 4.531), train_loss = 1.59272374, grad/param norm = 2.3770e-01, time/batch = 0.6610s	
2022/22300 (epoch 4.534), train_loss = 1.49032055, grad/param norm = 2.3110e-01, time/batch = 0.6569s	
2023/22300 (epoch 4.536), train_loss = 1.73516584, grad/param norm = 2.5083e-01, time/batch = 0.6715s	
2024/22300 (epoch 4.538), train_loss = 1.89681956, grad/param norm = 2.5181e-01, time/batch = 0.6733s	
2025/22300 (epoch 4.540), train_loss = 1.73002543, grad/param norm = 2.5551e-01, time/batch = 0.6700s	
2026/22300 (epoch 4.543), train_loss = 1.53701387, grad/param norm = 2.3077e-01, time/batch = 0.6715s	
2027/22300 (epoch 4.545), train_loss = 1.58244595, grad/param norm = 2.2541e-01, time/batch = 0.6631s	
2028/22300 (epoch 4.547), train_loss = 1.57095110, grad/param norm = 2.4376e-01, time/batch = 0.6728s	
2029/22300 (epoch 4.549), train_loss = 1.63540841, grad/param norm = 2.3481e-01, time/batch = 0.6747s	
2030/22300 (epoch 4.552), train_loss = 1.50956283, grad/param norm = 2.3563e-01, time/batch = 0.6729s	
2031/22300 (epoch 4.554), train_loss = 1.59801001, grad/param norm = 2.6485e-01, time/batch = 0.6755s	
2032/22300 (epoch 4.556), train_loss = 1.71305025, grad/param norm = 2.4904e-01, time/batch = 0.6647s	
2033/22300 (epoch 4.558), train_loss = 1.54666220, grad/param norm = 2.2713e-01, time/batch = 0.6648s	
2034/22300 (epoch 4.561), train_loss = 1.74762439, grad/param norm = 2.6208e-01, time/batch = 0.6758s	
2035/22300 (epoch 4.563), train_loss = 1.54006365, grad/param norm = 2.6233e-01, time/batch = 0.6645s	
2036/22300 (epoch 4.565), train_loss = 1.65017032, grad/param norm = 2.3967e-01, time/batch = 0.6673s	
2037/22300 (epoch 4.567), train_loss = 1.64424790, grad/param norm = 2.2450e-01, time/batch = 0.6683s	
2038/22300 (epoch 4.570), train_loss = 1.76843568, grad/param norm = 2.5703e-01, time/batch = 0.6643s	
2039/22300 (epoch 4.572), train_loss = 1.68274620, grad/param norm = 2.6122e-01, time/batch = 0.6662s	
2040/22300 (epoch 4.574), train_loss = 1.53140084, grad/param norm = 2.3721e-01, time/batch = 0.6652s	
2041/22300 (epoch 4.576), train_loss = 1.43455059, grad/param norm = 2.1381e-01, time/batch = 0.6675s	
2042/22300 (epoch 4.578), train_loss = 1.36969095, grad/param norm = 2.1854e-01, time/batch = 0.6620s	
2043/22300 (epoch 4.581), train_loss = 1.48787985, grad/param norm = 2.3445e-01, time/batch = 0.6593s	
2044/22300 (epoch 4.583), train_loss = 1.54759371, grad/param norm = 2.3586e-01, time/batch = 0.6617s	
2045/22300 (epoch 4.585), train_loss = 1.69249641, grad/param norm = 2.3760e-01, time/batch = 0.6640s	
2046/22300 (epoch 4.587), train_loss = 1.70152628, grad/param norm = 2.6345e-01, time/batch = 0.6666s	
2047/22300 (epoch 4.590), train_loss = 1.63102061, grad/param norm = 2.6314e-01, time/batch = 0.6635s	
2048/22300 (epoch 4.592), train_loss = 1.77242641, grad/param norm = 2.6819e-01, time/batch = 0.6619s	
2049/22300 (epoch 4.594), train_loss = 1.66917161, grad/param norm = 2.3527e-01, time/batch = 0.6657s	
2050/22300 (epoch 4.596), train_loss = 1.60116505, grad/param norm = 2.4776e-01, time/batch = 0.6641s	
2051/22300 (epoch 4.599), train_loss = 1.41729323, grad/param norm = 2.5343e-01, time/batch = 0.6643s	
2052/22300 (epoch 4.601), train_loss = 1.60638383, grad/param norm = 2.3563e-01, time/batch = 0.6605s	
2053/22300 (epoch 4.603), train_loss = 1.61868487, grad/param norm = 2.5389e-01, time/batch = 0.6651s	
2054/22300 (epoch 4.605), train_loss = 1.53814853, grad/param norm = 2.5997e-01, time/batch = 0.6623s	
2055/22300 (epoch 4.608), train_loss = 1.72929326, grad/param norm = 2.6724e-01, time/batch = 0.6606s	
2056/22300 (epoch 4.610), train_loss = 1.72858389, grad/param norm = 2.4917e-01, time/batch = 0.6604s	
2057/22300 (epoch 4.612), train_loss = 1.72722656, grad/param norm = 2.7995e-01, time/batch = 0.6616s	
2058/22300 (epoch 4.614), train_loss = 1.68825132, grad/param norm = 2.7113e-01, time/batch = 0.6624s	
2059/22300 (epoch 4.617), train_loss = 1.73589060, grad/param norm = 2.8312e-01, time/batch = 0.6630s	
2060/22300 (epoch 4.619), train_loss = 1.92030012, grad/param norm = 2.7010e-01, time/batch = 0.6611s	
2061/22300 (epoch 4.621), train_loss = 1.46502165, grad/param norm = 2.4254e-01, time/batch = 0.6580s	
2062/22300 (epoch 4.623), train_loss = 1.57862537, grad/param norm = 2.4511e-01, time/batch = 0.6527s	
2063/22300 (epoch 4.626), train_loss = 1.49371589, grad/param norm = 2.1460e-01, time/batch = 0.6537s	
2064/22300 (epoch 4.628), train_loss = 1.53040365, grad/param norm = 2.4305e-01, time/batch = 0.6637s	
2065/22300 (epoch 4.630), train_loss = 1.61710610, grad/param norm = 2.3838e-01, time/batch = 0.6570s	
2066/22300 (epoch 4.632), train_loss = 1.65100715, grad/param norm = 2.4310e-01, time/batch = 0.6605s	
2067/22300 (epoch 4.635), train_loss = 1.50275633, grad/param norm = 2.3037e-01, time/batch = 0.6600s	
2068/22300 (epoch 4.637), train_loss = 1.73951252, grad/param norm = 2.7307e-01, time/batch = 0.6644s	
2069/22300 (epoch 4.639), train_loss = 1.68067612, grad/param norm = 3.0478e-01, time/batch = 0.6610s	
2070/22300 (epoch 4.641), train_loss = 1.65673063, grad/param norm = 2.7250e-01, time/batch = 0.6746s	
2071/22300 (epoch 4.643), train_loss = 1.59871122, grad/param norm = 2.4707e-01, time/batch = 0.6589s	
2072/22300 (epoch 4.646), train_loss = 1.53023060, grad/param norm = 2.3481e-01, time/batch = 0.6527s	
2073/22300 (epoch 4.648), train_loss = 1.51186870, grad/param norm = 2.3287e-01, time/batch = 0.6567s	
2074/22300 (epoch 4.650), train_loss = 1.76610036, grad/param norm = 2.5190e-01, time/batch = 0.6578s	
2075/22300 (epoch 4.652), train_loss = 1.59028759, grad/param norm = 2.2844e-01, time/batch = 0.6556s	
2076/22300 (epoch 4.655), train_loss = 1.70390599, grad/param norm = 2.5034e-01, time/batch = 0.6584s	
2077/22300 (epoch 4.657), train_loss = 1.66353827, grad/param norm = 2.6496e-01, time/batch = 0.6565s	
2078/22300 (epoch 4.659), train_loss = 1.48486864, grad/param norm = 2.4528e-01, time/batch = 0.6591s	
2079/22300 (epoch 4.661), train_loss = 1.54895304, grad/param norm = 2.7899e-01, time/batch = 0.6670s	
2080/22300 (epoch 4.664), train_loss = 1.56496625, grad/param norm = 2.6241e-01, time/batch = 0.6746s	
2081/22300 (epoch 4.666), train_loss = 1.65271350, grad/param norm = 2.2663e-01, time/batch = 0.6737s	
2082/22300 (epoch 4.668), train_loss = 1.59537524, grad/param norm = 2.5526e-01, time/batch = 0.6757s	
2083/22300 (epoch 4.670), train_loss = 1.71825508, grad/param norm = 2.4026e-01, time/batch = 0.6623s	
2084/22300 (epoch 4.673), train_loss = 1.65294287, grad/param norm = 2.6131e-01, time/batch = 0.6564s	
2085/22300 (epoch 4.675), train_loss = 1.72856839, grad/param norm = 2.4899e-01, time/batch = 0.6557s	
2086/22300 (epoch 4.677), train_loss = 1.75200101, grad/param norm = 2.5135e-01, time/batch = 0.6585s	
2087/22300 (epoch 4.679), train_loss = 1.74023936, grad/param norm = 2.7384e-01, time/batch = 0.6614s	
2088/22300 (epoch 4.682), train_loss = 1.67718661, grad/param norm = 2.6055e-01, time/batch = 0.6637s	
2089/22300 (epoch 4.684), train_loss = 1.63403469, grad/param norm = 2.3363e-01, time/batch = 0.6713s	
2090/22300 (epoch 4.686), train_loss = 1.72109748, grad/param norm = 2.8479e-01, time/batch = 0.6890s	
2091/22300 (epoch 4.688), train_loss = 1.73948227, grad/param norm = 2.3885e-01, time/batch = 0.6830s	
2092/22300 (epoch 4.691), train_loss = 1.66616666, grad/param norm = 2.4843e-01, time/batch = 0.6837s	
2093/22300 (epoch 4.693), train_loss = 1.66314179, grad/param norm = 2.5608e-01, time/batch = 0.6879s	
2094/22300 (epoch 4.695), train_loss = 1.52367323, grad/param norm = 2.5065e-01, time/batch = 0.6781s	
2095/22300 (epoch 4.697), train_loss = 1.38747979, grad/param norm = 2.2117e-01, time/batch = 0.6882s	
2096/22300 (epoch 4.700), train_loss = 1.59915211, grad/param norm = 2.4554e-01, time/batch = 0.6831s	
2097/22300 (epoch 4.702), train_loss = 1.67343729, grad/param norm = 2.7813e-01, time/batch = 0.6755s	
2098/22300 (epoch 4.704), train_loss = 1.70940051, grad/param norm = 2.5043e-01, time/batch = 0.6809s	
2099/22300 (epoch 4.706), train_loss = 1.50949046, grad/param norm = 2.3738e-01, time/batch = 0.6717s	
2100/22300 (epoch 4.709), train_loss = 1.47519704, grad/param norm = 2.3687e-01, time/batch = 0.6740s	
2101/22300 (epoch 4.711), train_loss = 1.63483955, grad/param norm = 2.2636e-01, time/batch = 0.6672s	
2102/22300 (epoch 4.713), train_loss = 1.58531086, grad/param norm = 2.3784e-01, time/batch = 0.6659s	
2103/22300 (epoch 4.715), train_loss = 1.62571325, grad/param norm = 2.5404e-01, time/batch = 0.6648s	
2104/22300 (epoch 4.717), train_loss = 1.84883759, grad/param norm = 2.7516e-01, time/batch = 0.6711s	
2105/22300 (epoch 4.720), train_loss = 1.61559290, grad/param norm = 2.3802e-01, time/batch = 0.6707s	
2106/22300 (epoch 4.722), train_loss = 1.61553923, grad/param norm = 2.5697e-01, time/batch = 0.6700s	
2107/22300 (epoch 4.724), train_loss = 1.69092626, grad/param norm = 2.6728e-01, time/batch = 0.6690s	
2108/22300 (epoch 4.726), train_loss = 1.64053818, grad/param norm = 2.7186e-01, time/batch = 0.6641s	
2109/22300 (epoch 4.729), train_loss = 1.70983732, grad/param norm = 2.5519e-01, time/batch = 0.6660s	
2110/22300 (epoch 4.731), train_loss = 1.68635467, grad/param norm = 2.5715e-01, time/batch = 0.6676s	
2111/22300 (epoch 4.733), train_loss = 1.74330215, grad/param norm = 2.6764e-01, time/batch = 0.6666s	
2112/22300 (epoch 4.735), train_loss = 1.64363657, grad/param norm = 2.5933e-01, time/batch = 0.6642s	
2113/22300 (epoch 4.738), train_loss = 1.66172961, grad/param norm = 2.6504e-01, time/batch = 0.6698s	
2114/22300 (epoch 4.740), train_loss = 1.39649036, grad/param norm = 2.3055e-01, time/batch = 0.6652s	
2115/22300 (epoch 4.742), train_loss = 1.59317678, grad/param norm = 2.2804e-01, time/batch = 0.6724s	
2116/22300 (epoch 4.744), train_loss = 1.69967859, grad/param norm = 2.4610e-01, time/batch = 0.6635s	
2117/22300 (epoch 4.747), train_loss = 1.58005285, grad/param norm = 2.5405e-01, time/batch = 0.6691s	
2118/22300 (epoch 4.749), train_loss = 1.87093948, grad/param norm = 2.6460e-01, time/batch = 0.6674s	
2119/22300 (epoch 4.751), train_loss = 1.67084515, grad/param norm = 2.2837e-01, time/batch = 0.6635s	
2120/22300 (epoch 4.753), train_loss = 1.69176908, grad/param norm = 2.4332e-01, time/batch = 0.6642s	
2121/22300 (epoch 4.756), train_loss = 1.61489442, grad/param norm = 2.3952e-01, time/batch = 0.6698s	
2122/22300 (epoch 4.758), train_loss = 1.50789247, grad/param norm = 2.4168e-01, time/batch = 0.6642s	
2123/22300 (epoch 4.760), train_loss = 1.61170519, grad/param norm = 2.5864e-01, time/batch = 0.6654s	
2124/22300 (epoch 4.762), train_loss = 1.61681655, grad/param norm = 2.5995e-01, time/batch = 0.6576s	
2125/22300 (epoch 4.765), train_loss = 1.68441183, grad/param norm = 2.3283e-01, time/batch = 0.6568s	
2126/22300 (epoch 4.767), train_loss = 1.71449633, grad/param norm = 2.3972e-01, time/batch = 0.6580s	
2127/22300 (epoch 4.769), train_loss = 1.61180499, grad/param norm = 2.4845e-01, time/batch = 0.6596s	
2128/22300 (epoch 4.771), train_loss = 1.57717790, grad/param norm = 2.5440e-01, time/batch = 0.6648s	
2129/22300 (epoch 4.774), train_loss = 1.66496177, grad/param norm = 2.2637e-01, time/batch = 0.6544s	
2130/22300 (epoch 4.776), train_loss = 1.52675888, grad/param norm = 2.1201e-01, time/batch = 0.6669s	
2131/22300 (epoch 4.778), train_loss = 1.74464354, grad/param norm = 2.6799e-01, time/batch = 0.6666s	
2132/22300 (epoch 4.780), train_loss = 1.72427821, grad/param norm = 2.3905e-01, time/batch = 0.6600s	
2133/22300 (epoch 4.783), train_loss = 1.71225387, grad/param norm = 2.8170e-01, time/batch = 0.6623s	
2134/22300 (epoch 4.785), train_loss = 1.59642264, grad/param norm = 2.6945e-01, time/batch = 0.6613s	
2135/22300 (epoch 4.787), train_loss = 1.55580359, grad/param norm = 2.6170e-01, time/batch = 0.6623s	
2136/22300 (epoch 4.789), train_loss = 1.64249317, grad/param norm = 2.3241e-01, time/batch = 0.6564s	
2137/22300 (epoch 4.791), train_loss = 1.75293341, grad/param norm = 2.7078e-01, time/batch = 0.6540s	
2138/22300 (epoch 4.794), train_loss = 1.69821846, grad/param norm = 2.6171e-01, time/batch = 0.6598s	
2139/22300 (epoch 4.796), train_loss = 1.70844726, grad/param norm = 2.6155e-01, time/batch = 0.6676s	
2140/22300 (epoch 4.798), train_loss = 1.67699362, grad/param norm = 2.3315e-01, time/batch = 0.6703s	
2141/22300 (epoch 4.800), train_loss = 1.46263775, grad/param norm = 2.2971e-01, time/batch = 0.6704s	
2142/22300 (epoch 4.803), train_loss = 1.46459210, grad/param norm = 2.4257e-01, time/batch = 0.6737s	
2143/22300 (epoch 4.805), train_loss = 1.61385747, grad/param norm = 2.3188e-01, time/batch = 0.6727s	
2144/22300 (epoch 4.807), train_loss = 1.62328289, grad/param norm = 2.2629e-01, time/batch = 0.6697s	
2145/22300 (epoch 4.809), train_loss = 1.67747315, grad/param norm = 2.4843e-01, time/batch = 0.6762s	
2146/22300 (epoch 4.812), train_loss = 1.73281185, grad/param norm = 2.6984e-01, time/batch = 0.6691s	
2147/22300 (epoch 4.814), train_loss = 1.59743279, grad/param norm = 2.2890e-01, time/batch = 0.6693s	
2148/22300 (epoch 4.816), train_loss = 1.72926464, grad/param norm = 2.3567e-01, time/batch = 0.6752s	
2149/22300 (epoch 4.818), train_loss = 1.68077878, grad/param norm = 2.4992e-01, time/batch = 0.6726s	
2150/22300 (epoch 4.821), train_loss = 1.79329488, grad/param norm = 2.4860e-01, time/batch = 0.6713s	
2151/22300 (epoch 4.823), train_loss = 1.53283657, grad/param norm = 2.4647e-01, time/batch = 0.6765s	
2152/22300 (epoch 4.825), train_loss = 1.58610256, grad/param norm = 2.2686e-01, time/batch = 0.6748s	
2153/22300 (epoch 4.827), train_loss = 1.61663074, grad/param norm = 2.3085e-01, time/batch = 0.6717s	
2154/22300 (epoch 4.830), train_loss = 1.59019855, grad/param norm = 2.5673e-01, time/batch = 0.6639s	
2155/22300 (epoch 4.832), train_loss = 1.52499011, grad/param norm = 2.5329e-01, time/batch = 0.6625s	
2156/22300 (epoch 4.834), train_loss = 1.74330754, grad/param norm = 2.4376e-01, time/batch = 0.6673s	
2157/22300 (epoch 4.836), train_loss = 1.63467377, grad/param norm = 2.5069e-01, time/batch = 0.6642s	
2158/22300 (epoch 4.839), train_loss = 1.63935011, grad/param norm = 2.2508e-01, time/batch = 0.6761s	
2159/22300 (epoch 4.841), train_loss = 1.59404370, grad/param norm = 2.6065e-01, time/batch = 0.6580s	
2160/22300 (epoch 4.843), train_loss = 1.58136414, grad/param norm = 2.7368e-01, time/batch = 0.6592s	
2161/22300 (epoch 4.845), train_loss = 1.61752436, grad/param norm = 2.5637e-01, time/batch = 0.6615s	
2162/22300 (epoch 4.848), train_loss = 1.60446229, grad/param norm = 2.6949e-01, time/batch = 0.6675s	
2163/22300 (epoch 4.850), train_loss = 1.67477670, grad/param norm = 2.6695e-01, time/batch = 0.6699s	
2164/22300 (epoch 4.852), train_loss = 1.66397183, grad/param norm = 2.3839e-01, time/batch = 0.6698s	
2165/22300 (epoch 4.854), train_loss = 1.77499653, grad/param norm = 2.6323e-01, time/batch = 0.6746s	
2166/22300 (epoch 4.857), train_loss = 1.56743908, grad/param norm = 2.4745e-01, time/batch = 0.6737s	
2167/22300 (epoch 4.859), train_loss = 1.48969397, grad/param norm = 2.1856e-01, time/batch = 0.6744s	
2168/22300 (epoch 4.861), train_loss = 1.59847382, grad/param norm = 2.2663e-01, time/batch = 0.6623s	
2169/22300 (epoch 4.863), train_loss = 1.50333041, grad/param norm = 2.3353e-01, time/batch = 0.6701s	
2170/22300 (epoch 4.865), train_loss = 1.49103630, grad/param norm = 2.2824e-01, time/batch = 0.6752s	
2171/22300 (epoch 4.868), train_loss = 1.53749664, grad/param norm = 2.3304e-01, time/batch = 0.6919s	
2172/22300 (epoch 4.870), train_loss = 1.58533647, grad/param norm = 2.5457e-01, time/batch = 0.6811s	
2173/22300 (epoch 4.872), train_loss = 1.64746482, grad/param norm = 2.5456e-01, time/batch = 0.6692s	
2174/22300 (epoch 4.874), train_loss = 1.65856345, grad/param norm = 2.5500e-01, time/batch = 0.6689s	
2175/22300 (epoch 4.877), train_loss = 1.52927915, grad/param norm = 2.4097e-01, time/batch = 0.6656s	
2176/22300 (epoch 4.879), train_loss = 1.43166230, grad/param norm = 2.2704e-01, time/batch = 0.6598s	
2177/22300 (epoch 4.881), train_loss = 1.57090665, grad/param norm = 3.0623e-01, time/batch = 0.6656s	
2178/22300 (epoch 4.883), train_loss = 1.63277089, grad/param norm = 3.4101e-01, time/batch = 0.6771s	
2179/22300 (epoch 4.886), train_loss = 1.57654685, grad/param norm = 2.3862e-01, time/batch = 0.6662s	
2180/22300 (epoch 4.888), train_loss = 1.54670577, grad/param norm = 2.3241e-01, time/batch = 0.6589s	
2181/22300 (epoch 4.890), train_loss = 1.42237049, grad/param norm = 2.0187e-01, time/batch = 0.6632s	
2182/22300 (epoch 4.892), train_loss = 1.69194811, grad/param norm = 2.4522e-01, time/batch = 0.6597s	
2183/22300 (epoch 4.895), train_loss = 1.65604857, grad/param norm = 2.4043e-01, time/batch = 0.6638s	
2184/22300 (epoch 4.897), train_loss = 1.66682316, grad/param norm = 2.5974e-01, time/batch = 0.6640s	
2185/22300 (epoch 4.899), train_loss = 1.59171733, grad/param norm = 2.2514e-01, time/batch = 0.6588s	
2186/22300 (epoch 4.901), train_loss = 1.52722590, grad/param norm = 2.3073e-01, time/batch = 0.6592s	
2187/22300 (epoch 4.904), train_loss = 1.53066316, grad/param norm = 2.4814e-01, time/batch = 0.6600s	
2188/22300 (epoch 4.906), train_loss = 1.66523285, grad/param norm = 2.2256e-01, time/batch = 0.6682s	
2189/22300 (epoch 4.908), train_loss = 1.59129642, grad/param norm = 2.4304e-01, time/batch = 0.6597s	
2190/22300 (epoch 4.910), train_loss = 1.53079809, grad/param norm = 2.3305e-01, time/batch = 0.6611s	
2191/22300 (epoch 4.913), train_loss = 1.54268676, grad/param norm = 2.3071e-01, time/batch = 0.6607s	
2192/22300 (epoch 4.915), train_loss = 1.74429387, grad/param norm = 2.5999e-01, time/batch = 0.6624s	
2193/22300 (epoch 4.917), train_loss = 1.58693003, grad/param norm = 2.7742e-01, time/batch = 0.6623s	
2194/22300 (epoch 4.919), train_loss = 1.65270086, grad/param norm = 2.6704e-01, time/batch = 0.6622s	
2195/22300 (epoch 4.922), train_loss = 1.63872812, grad/param norm = 2.7941e-01, time/batch = 0.6560s	
2196/22300 (epoch 4.924), train_loss = 1.49436537, grad/param norm = 2.2754e-01, time/batch = 0.6522s	
2197/22300 (epoch 4.926), train_loss = 1.39266464, grad/param norm = 2.1561e-01, time/batch = 0.6533s	
2198/22300 (epoch 4.928), train_loss = 1.63053962, grad/param norm = 2.3815e-01, time/batch = 0.6584s	
2199/22300 (epoch 4.930), train_loss = 1.63995151, grad/param norm = 2.3919e-01, time/batch = 0.6565s	
2200/22300 (epoch 4.933), train_loss = 1.61031734, grad/param norm = 2.6994e-01, time/batch = 0.6532s	
2201/22300 (epoch 4.935), train_loss = 1.72373889, grad/param norm = 2.2643e-01, time/batch = 0.6596s	
2202/22300 (epoch 4.937), train_loss = 1.62011446, grad/param norm = 2.2891e-01, time/batch = 0.6608s	
2203/22300 (epoch 4.939), train_loss = 1.66259580, grad/param norm = 2.4694e-01, time/batch = 0.6670s	
2204/22300 (epoch 4.942), train_loss = 1.72525774, grad/param norm = 2.5272e-01, time/batch = 0.6529s	
2205/22300 (epoch 4.944), train_loss = 1.80924467, grad/param norm = 2.7184e-01, time/batch = 0.6561s	
2206/22300 (epoch 4.946), train_loss = 1.57230911, grad/param norm = 2.6738e-01, time/batch = 0.6636s	
2207/22300 (epoch 4.948), train_loss = 1.58858957, grad/param norm = 2.4703e-01, time/batch = 0.6498s	
2208/22300 (epoch 4.951), train_loss = 1.47886815, grad/param norm = 2.2741e-01, time/batch = 0.6474s	
2209/22300 (epoch 4.953), train_loss = 1.56815536, grad/param norm = 2.5201e-01, time/batch = 0.6456s	
2210/22300 (epoch 4.955), train_loss = 1.76989189, grad/param norm = 2.6056e-01, time/batch = 0.6502s	
2211/22300 (epoch 4.957), train_loss = 1.75833672, grad/param norm = 2.4981e-01, time/batch = 0.6542s	
2212/22300 (epoch 4.960), train_loss = 1.73614670, grad/param norm = 2.9819e-01, time/batch = 0.6489s	
2213/22300 (epoch 4.962), train_loss = 1.66930447, grad/param norm = 2.6403e-01, time/batch = 0.6642s	
2214/22300 (epoch 4.964), train_loss = 1.63493699, grad/param norm = 2.3731e-01, time/batch = 0.6655s	
2215/22300 (epoch 4.966), train_loss = 1.61123479, grad/param norm = 2.6820e-01, time/batch = 0.6554s	
2216/22300 (epoch 4.969), train_loss = 1.50204620, grad/param norm = 2.2112e-01, time/batch = 0.6549s	
2217/22300 (epoch 4.971), train_loss = 1.55014923, grad/param norm = 2.5342e-01, time/batch = 0.6569s	
2218/22300 (epoch 4.973), train_loss = 1.54284690, grad/param norm = 2.4010e-01, time/batch = 0.6632s	
2219/22300 (epoch 4.975), train_loss = 1.83160062, grad/param norm = 2.6633e-01, time/batch = 0.6638s	
2220/22300 (epoch 4.978), train_loss = 1.46970609, grad/param norm = 2.0662e-01, time/batch = 0.6635s	
2221/22300 (epoch 4.980), train_loss = 1.64736946, grad/param norm = 2.2370e-01, time/batch = 0.6634s	
2222/22300 (epoch 4.982), train_loss = 1.48465606, grad/param norm = 2.1876e-01, time/batch = 0.6601s	
2223/22300 (epoch 4.984), train_loss = 1.64589578, grad/param norm = 2.3439e-01, time/batch = 0.6611s	
2224/22300 (epoch 4.987), train_loss = 1.54440405, grad/param norm = 2.3508e-01, time/batch = 0.6603s	
2225/22300 (epoch 4.989), train_loss = 1.65286632, grad/param norm = 2.4905e-01, time/batch = 0.6741s	
2226/22300 (epoch 4.991), train_loss = 1.75805009, grad/param norm = 2.4549e-01, time/batch = 0.6828s	
2227/22300 (epoch 4.993), train_loss = 1.72199738, grad/param norm = 2.5170e-01, time/batch = 0.6794s	
2228/22300 (epoch 4.996), train_loss = 1.76766059, grad/param norm = 2.6349e-01, time/batch = 0.6568s	
2229/22300 (epoch 4.998), train_loss = 1.58818833, grad/param norm = 2.6943e-01, time/batch = 0.6416s	
2230/22300 (epoch 5.000), train_loss = 1.52778429, grad/param norm = 2.4094e-01, time/batch = 0.6461s	
2231/22300 (epoch 5.002), train_loss = 1.66398875, grad/param norm = 2.3894e-01, time/batch = 0.6477s	
2232/22300 (epoch 5.004), train_loss = 1.62786578, grad/param norm = 2.3388e-01, time/batch = 0.6477s	
2233/22300 (epoch 5.007), train_loss = 1.58237343, grad/param norm = 2.2419e-01, time/batch = 0.6546s	
2234/22300 (epoch 5.009), train_loss = 1.57667642, grad/param norm = 2.2585e-01, time/batch = 0.6503s	
2235/22300 (epoch 5.011), train_loss = 1.71619986, grad/param norm = 2.5395e-01, time/batch = 0.6516s	
2236/22300 (epoch 5.013), train_loss = 1.53657320, grad/param norm = 2.8033e-01, time/batch = 0.6525s	
2237/22300 (epoch 5.016), train_loss = 1.56293846, grad/param norm = 2.5370e-01, time/batch = 0.6507s	
2238/22300 (epoch 5.018), train_loss = 1.68431605, grad/param norm = 2.5757e-01, time/batch = 0.6526s	
2239/22300 (epoch 5.020), train_loss = 1.55157991, grad/param norm = 2.2762e-01, time/batch = 0.6565s	
2240/22300 (epoch 5.022), train_loss = 1.57868383, grad/param norm = 2.5374e-01, time/batch = 0.6522s	
2241/22300 (epoch 5.025), train_loss = 1.58742646, grad/param norm = 2.4717e-01, time/batch = 0.6505s	
2242/22300 (epoch 5.027), train_loss = 1.74017146, grad/param norm = 2.5310e-01, time/batch = 0.6600s	
2243/22300 (epoch 5.029), train_loss = 1.52354425, grad/param norm = 2.2225e-01, time/batch = 0.6446s	
2244/22300 (epoch 5.031), train_loss = 1.42224284, grad/param norm = 2.0732e-01, time/batch = 0.6544s	
2245/22300 (epoch 5.034), train_loss = 1.47855745, grad/param norm = 2.2062e-01, time/batch = 0.6575s	
2246/22300 (epoch 5.036), train_loss = 1.39243238, grad/param norm = 2.2827e-01, time/batch = 0.6475s	
2247/22300 (epoch 5.038), train_loss = 1.43481664, grad/param norm = 2.0582e-01, time/batch = 0.6491s	
2248/22300 (epoch 5.040), train_loss = 1.62818801, grad/param norm = 2.5735e-01, time/batch = 0.6527s	
2249/22300 (epoch 5.043), train_loss = 1.68692734, grad/param norm = 2.7269e-01, time/batch = 0.6465s	
2250/22300 (epoch 5.045), train_loss = 1.56467024, grad/param norm = 2.2493e-01, time/batch = 0.6482s	
2251/22300 (epoch 5.047), train_loss = 1.60850421, grad/param norm = 2.4242e-01, time/batch = 0.6563s	
2252/22300 (epoch 5.049), train_loss = 1.48481813, grad/param norm = 2.1765e-01, time/batch = 0.6533s	
2253/22300 (epoch 5.052), train_loss = 1.66218791, grad/param norm = 2.4028e-01, time/batch = 0.6467s	
2254/22300 (epoch 5.054), train_loss = 1.59867574, grad/param norm = 2.3511e-01, time/batch = 0.6521s	
2255/22300 (epoch 5.056), train_loss = 1.42228034, grad/param norm = 2.1602e-01, time/batch = 0.6471s	
2256/22300 (epoch 5.058), train_loss = 1.39034074, grad/param norm = 2.0060e-01, time/batch = 0.6431s	
2257/22300 (epoch 5.061), train_loss = 1.45616526, grad/param norm = 2.4868e-01, time/batch = 0.6418s	
2258/22300 (epoch 5.063), train_loss = 1.69115719, grad/param norm = 2.6098e-01, time/batch = 0.6432s	
2259/22300 (epoch 5.065), train_loss = 1.50606168, grad/param norm = 2.4236e-01, time/batch = 0.6516s	
2260/22300 (epoch 5.067), train_loss = 1.53472048, grad/param norm = 2.1798e-01, time/batch = 0.6576s	
2261/22300 (epoch 5.070), train_loss = 1.49426160, grad/param norm = 2.4557e-01, time/batch = 0.6657s	
2262/22300 (epoch 5.072), train_loss = 1.59058263, grad/param norm = 2.3391e-01, time/batch = 0.6617s	
2263/22300 (epoch 5.074), train_loss = 1.59878524, grad/param norm = 2.3149e-01, time/batch = 0.6575s	
2264/22300 (epoch 5.076), train_loss = 1.43571306, grad/param norm = 2.2305e-01, time/batch = 0.6522s	
2265/22300 (epoch 5.078), train_loss = 1.49750997, grad/param norm = 2.2059e-01, time/batch = 0.6494s	
2266/22300 (epoch 5.081), train_loss = 1.64243862, grad/param norm = 2.4043e-01, time/batch = 0.6520s	
2267/22300 (epoch 5.083), train_loss = 1.62646729, grad/param norm = 2.6229e-01, time/batch = 0.6759s	
2268/22300 (epoch 5.085), train_loss = 1.70209721, grad/param norm = 2.2737e-01, time/batch = 0.6634s	
2269/22300 (epoch 5.087), train_loss = 1.57763979, grad/param norm = 2.6412e-01, time/batch = 0.6663s	
2270/22300 (epoch 5.090), train_loss = 1.49884290, grad/param norm = 2.4579e-01, time/batch = 0.6726s	
2271/22300 (epoch 5.092), train_loss = 1.56451257, grad/param norm = 2.7055e-01, time/batch = 0.6606s	
2272/22300 (epoch 5.094), train_loss = 1.42165857, grad/param norm = 2.3082e-01, time/batch = 0.6674s	
2273/22300 (epoch 5.096), train_loss = 1.67363834, grad/param norm = 2.1806e-01, time/batch = 0.6776s	
2274/22300 (epoch 5.099), train_loss = 1.60757194, grad/param norm = 2.3558e-01, time/batch = 0.6656s	
2275/22300 (epoch 5.101), train_loss = 1.70275621, grad/param norm = 2.4833e-01, time/batch = 0.6660s	
2276/22300 (epoch 5.103), train_loss = 1.63445109, grad/param norm = 2.2809e-01, time/batch = 0.6643s	
2277/22300 (epoch 5.105), train_loss = 1.57117230, grad/param norm = 2.5013e-01, time/batch = 0.6647s	
2278/22300 (epoch 5.108), train_loss = 1.63104832, grad/param norm = 2.7063e-01, time/batch = 0.6685s	
2279/22300 (epoch 5.110), train_loss = 1.56573010, grad/param norm = 2.2130e-01, time/batch = 0.6679s	
2280/22300 (epoch 5.112), train_loss = 1.52991503, grad/param norm = 2.3803e-01, time/batch = 0.6763s	
2281/22300 (epoch 5.114), train_loss = 1.68080771, grad/param norm = 2.3955e-01, time/batch = 0.6666s	
2282/22300 (epoch 5.117), train_loss = 1.77687252, grad/param norm = 2.3334e-01, time/batch = 0.6610s	
2283/22300 (epoch 5.119), train_loss = 1.58677466, grad/param norm = 2.3281e-01, time/batch = 0.6610s	
2284/22300 (epoch 5.121), train_loss = 1.64433393, grad/param norm = 2.3278e-01, time/batch = 0.6630s	
2285/22300 (epoch 5.123), train_loss = 1.45684777, grad/param norm = 2.2979e-01, time/batch = 0.6663s	
2286/22300 (epoch 5.126), train_loss = 1.48683747, grad/param norm = 2.5429e-01, time/batch = 0.6605s	
2287/22300 (epoch 5.128), train_loss = 1.59081129, grad/param norm = 2.2556e-01, time/batch = 0.6605s	
2288/22300 (epoch 5.130), train_loss = 1.58161690, grad/param norm = 2.1965e-01, time/batch = 0.6588s	
2289/22300 (epoch 5.132), train_loss = 1.47655082, grad/param norm = 2.4527e-01, time/batch = 0.6649s	
2290/22300 (epoch 5.135), train_loss = 1.45919890, grad/param norm = 2.4306e-01, time/batch = 0.6565s	
2291/22300 (epoch 5.137), train_loss = 1.28154591, grad/param norm = 2.1916e-01, time/batch = 0.6585s	
2292/22300 (epoch 5.139), train_loss = 1.59442878, grad/param norm = 2.6285e-01, time/batch = 0.6916s	
2293/22300 (epoch 5.141), train_loss = 1.66013724, grad/param norm = 2.2299e-01, time/batch = 0.6637s	
2294/22300 (epoch 5.143), train_loss = 1.57935328, grad/param norm = 2.3320e-01, time/batch = 0.6637s	
2295/22300 (epoch 5.146), train_loss = 1.69676943, grad/param norm = 2.4862e-01, time/batch = 0.6656s	
2296/22300 (epoch 5.148), train_loss = 1.51112138, grad/param norm = 2.6378e-01, time/batch = 0.6654s	
2297/22300 (epoch 5.150), train_loss = 1.62088622, grad/param norm = 3.0105e-01, time/batch = 0.6619s	
2298/22300 (epoch 5.152), train_loss = 1.61235476, grad/param norm = 3.1205e-01, time/batch = 0.6653s	
2299/22300 (epoch 5.155), train_loss = 1.53965190, grad/param norm = 2.4444e-01, time/batch = 0.6617s	
2300/22300 (epoch 5.157), train_loss = 1.68111987, grad/param norm = 2.6686e-01, time/batch = 0.6597s	
2301/22300 (epoch 5.159), train_loss = 1.61116725, grad/param norm = 2.4023e-01, time/batch = 0.6664s	
2302/22300 (epoch 5.161), train_loss = 1.65173780, grad/param norm = 2.5265e-01, time/batch = 0.6755s	
2303/22300 (epoch 5.164), train_loss = 1.50479385, grad/param norm = 2.8399e-01, time/batch = 0.6656s	
2304/22300 (epoch 5.166), train_loss = 1.52250636, grad/param norm = 2.3486e-01, time/batch = 0.6686s	
2305/22300 (epoch 5.168), train_loss = 1.54924877, grad/param norm = 2.4319e-01, time/batch = 0.6604s	
2306/22300 (epoch 5.170), train_loss = 1.57552489, grad/param norm = 2.2729e-01, time/batch = 0.6682s	
2307/22300 (epoch 5.173), train_loss = 1.75158736, grad/param norm = 2.4846e-01, time/batch = 0.6609s	
2308/22300 (epoch 5.175), train_loss = 1.51736608, grad/param norm = 2.4534e-01, time/batch = 0.6661s	
2309/22300 (epoch 5.177), train_loss = 1.36532015, grad/param norm = 2.1660e-01, time/batch = 0.6629s	
2310/22300 (epoch 5.179), train_loss = 1.45966428, grad/param norm = 2.2009e-01, time/batch = 0.6635s	
2311/22300 (epoch 5.182), train_loss = 1.65099121, grad/param norm = 2.2875e-01, time/batch = 0.6706s	
2312/22300 (epoch 5.184), train_loss = 1.74841465, grad/param norm = 2.6244e-01, time/batch = 0.6733s	
2313/22300 (epoch 5.186), train_loss = 1.59744768, grad/param norm = 2.3121e-01, time/batch = 0.6682s	
2314/22300 (epoch 5.188), train_loss = 1.67325399, grad/param norm = 2.6483e-01, time/batch = 0.6654s	
2315/22300 (epoch 5.191), train_loss = 1.69937201, grad/param norm = 2.5856e-01, time/batch = 0.6712s	
2316/22300 (epoch 5.193), train_loss = 1.49205785, grad/param norm = 2.2848e-01, time/batch = 0.6613s	
2317/22300 (epoch 5.195), train_loss = 1.44722105, grad/param norm = 2.4040e-01, time/batch = 0.6708s	
2318/22300 (epoch 5.197), train_loss = 1.59194227, grad/param norm = 2.3222e-01, time/batch = 0.6727s	
2319/22300 (epoch 5.200), train_loss = 1.51865857, grad/param norm = 2.2219e-01, time/batch = 0.6703s	
2320/22300 (epoch 5.202), train_loss = 1.53470150, grad/param norm = 2.7328e-01, time/batch = 0.6691s	
2321/22300 (epoch 5.204), train_loss = 1.47252814, grad/param norm = 2.6528e-01, time/batch = 0.6636s	
2322/22300 (epoch 5.206), train_loss = 1.37311860, grad/param norm = 2.1659e-01, time/batch = 0.6596s	
2323/22300 (epoch 5.209), train_loss = 1.54369943, grad/param norm = 2.4363e-01, time/batch = 0.6606s	
2324/22300 (epoch 5.211), train_loss = 1.45215508, grad/param norm = 2.5132e-01, time/batch = 0.6640s	
2325/22300 (epoch 5.213), train_loss = 1.46641525, grad/param norm = 2.3110e-01, time/batch = 0.6692s	
2326/22300 (epoch 5.215), train_loss = 1.70380566, grad/param norm = 2.5052e-01, time/batch = 0.6709s	
2327/22300 (epoch 5.217), train_loss = 1.61350260, grad/param norm = 2.4506e-01, time/batch = 0.6626s	
2328/22300 (epoch 5.220), train_loss = 1.52371045, grad/param norm = 2.3860e-01, time/batch = 0.6567s	
2329/22300 (epoch 5.222), train_loss = 1.52418345, grad/param norm = 2.5133e-01, time/batch = 0.6554s	
2330/22300 (epoch 5.224), train_loss = 1.46260010, grad/param norm = 2.6531e-01, time/batch = 0.6577s	
2331/22300 (epoch 5.226), train_loss = 1.56559477, grad/param norm = 2.5551e-01, time/batch = 0.6599s	
2332/22300 (epoch 5.229), train_loss = 1.61879936, grad/param norm = 2.4511e-01, time/batch = 0.6550s	
2333/22300 (epoch 5.231), train_loss = 1.66476430, grad/param norm = 2.4623e-01, time/batch = 0.6605s	
2334/22300 (epoch 5.233), train_loss = 1.66972285, grad/param norm = 2.4531e-01, time/batch = 0.6645s	
2335/22300 (epoch 5.235), train_loss = 1.46952696, grad/param norm = 2.1542e-01, time/batch = 0.6597s	
2336/22300 (epoch 5.238), train_loss = 1.47756989, grad/param norm = 2.4500e-01, time/batch = 0.6590s	
2337/22300 (epoch 5.240), train_loss = 1.41101176, grad/param norm = 2.2251e-01, time/batch = 0.6619s	
2338/22300 (epoch 5.242), train_loss = 1.53490862, grad/param norm = 2.1835e-01, time/batch = 0.6720s	
2339/22300 (epoch 5.244), train_loss = 1.24138698, grad/param norm = 2.1654e-01, time/batch = 0.6651s	
2340/22300 (epoch 5.247), train_loss = 1.58965839, grad/param norm = 2.3584e-01, time/batch = 0.6535s	
2341/22300 (epoch 5.249), train_loss = 1.45449505, grad/param norm = 2.3398e-01, time/batch = 0.6545s	
2342/22300 (epoch 5.251), train_loss = 1.39183920, grad/param norm = 2.2731e-01, time/batch = 0.6519s	
2343/22300 (epoch 5.253), train_loss = 1.49179207, grad/param norm = 2.3530e-01, time/batch = 0.6523s	
2344/22300 (epoch 5.256), train_loss = 1.61547769, grad/param norm = 2.6523e-01, time/batch = 0.6528s	
2345/22300 (epoch 5.258), train_loss = 1.70018939, grad/param norm = 2.7705e-01, time/batch = 0.6572s	
2346/22300 (epoch 5.260), train_loss = 1.58263269, grad/param norm = 2.7311e-01, time/batch = 0.6577s	
2347/22300 (epoch 5.262), train_loss = 1.56373001, grad/param norm = 2.3898e-01, time/batch = 0.6618s	
2348/22300 (epoch 5.265), train_loss = 1.55437163, grad/param norm = 2.5283e-01, time/batch = 0.6629s	
2349/22300 (epoch 5.267), train_loss = 1.52054721, grad/param norm = 2.4995e-01, time/batch = 0.6696s	
2350/22300 (epoch 5.269), train_loss = 1.53691103, grad/param norm = 2.4906e-01, time/batch = 0.6725s	
2351/22300 (epoch 5.271), train_loss = 1.54571647, grad/param norm = 2.5298e-01, time/batch = 0.6753s	
2352/22300 (epoch 5.274), train_loss = 1.45121999, grad/param norm = 2.6989e-01, time/batch = 0.6766s	
2353/22300 (epoch 5.276), train_loss = 1.36781275, grad/param norm = 2.4138e-01, time/batch = 0.6676s	
2354/22300 (epoch 5.278), train_loss = 1.36051860, grad/param norm = 2.5881e-01, time/batch = 0.6745s	
2355/22300 (epoch 5.280), train_loss = 1.44191206, grad/param norm = 2.4014e-01, time/batch = 0.6729s	
2356/22300 (epoch 5.283), train_loss = 1.33477489, grad/param norm = 2.1231e-01, time/batch = 0.6714s	
2357/22300 (epoch 5.285), train_loss = 1.50962646, grad/param norm = 2.6129e-01, time/batch = 0.6712s	
2358/22300 (epoch 5.287), train_loss = 1.52304242, grad/param norm = 2.5430e-01, time/batch = 0.6729s	
2359/22300 (epoch 5.289), train_loss = 1.48921861, grad/param norm = 2.5221e-01, time/batch = 0.6743s	
2360/22300 (epoch 5.291), train_loss = 1.53887975, grad/param norm = 2.3504e-01, time/batch = 0.6721s	
2361/22300 (epoch 5.294), train_loss = 1.41468760, grad/param norm = 2.2224e-01, time/batch = 0.6759s	
2362/22300 (epoch 5.296), train_loss = 1.64864970, grad/param norm = 2.6582e-01, time/batch = 0.6754s	
2363/22300 (epoch 5.298), train_loss = 1.59703028, grad/param norm = 2.6328e-01, time/batch = 0.6919s	
2364/22300 (epoch 5.300), train_loss = 1.65590600, grad/param norm = 2.4470e-01, time/batch = 0.6822s	
2365/22300 (epoch 5.303), train_loss = 1.48676118, grad/param norm = 2.2572e-01, time/batch = 0.6753s	
2366/22300 (epoch 5.305), train_loss = 1.64322774, grad/param norm = 2.8764e-01, time/batch = 0.6748s	
2367/22300 (epoch 5.307), train_loss = 1.57648216, grad/param norm = 2.4998e-01, time/batch = 0.6750s	
2368/22300 (epoch 5.309), train_loss = 1.53755055, grad/param norm = 2.4854e-01, time/batch = 0.6736s	
2369/22300 (epoch 5.312), train_loss = 1.41933172, grad/param norm = 2.3974e-01, time/batch = 0.6656s	
2370/22300 (epoch 5.314), train_loss = 1.55965287, grad/param norm = 2.2925e-01, time/batch = 0.6652s	
2371/22300 (epoch 5.316), train_loss = 1.51620648, grad/param norm = 2.3465e-01, time/batch = 0.6652s	
2372/22300 (epoch 5.318), train_loss = 1.63377751, grad/param norm = 2.7859e-01, time/batch = 0.6656s	
2373/22300 (epoch 5.321), train_loss = 1.59962595, grad/param norm = 2.6737e-01, time/batch = 0.6646s	
2374/22300 (epoch 5.323), train_loss = 1.54255152, grad/param norm = 2.2114e-01, time/batch = 0.6703s	
2375/22300 (epoch 5.325), train_loss = 1.41303457, grad/param norm = 2.5188e-01, time/batch = 0.6865s	
2376/22300 (epoch 5.327), train_loss = 1.49591306, grad/param norm = 2.3434e-01, time/batch = 0.6845s	
2377/22300 (epoch 5.330), train_loss = 1.55769561, grad/param norm = 2.5503e-01, time/batch = 0.6734s	
2378/22300 (epoch 5.332), train_loss = 1.42169905, grad/param norm = 2.7374e-01, time/batch = 0.6743s	
2379/22300 (epoch 5.334), train_loss = 1.40839171, grad/param norm = 2.7079e-01, time/batch = 0.6762s	
2380/22300 (epoch 5.336), train_loss = 1.48353571, grad/param norm = 2.3601e-01, time/batch = 0.6606s	
2381/22300 (epoch 5.339), train_loss = 1.58017167, grad/param norm = 2.6549e-01, time/batch = 0.6624s	
2382/22300 (epoch 5.341), train_loss = 1.55911929, grad/param norm = 2.6654e-01, time/batch = 0.6599s	
2383/22300 (epoch 5.343), train_loss = 1.60382832, grad/param norm = 2.6358e-01, time/batch = 0.6586s	
2384/22300 (epoch 5.345), train_loss = 1.54261448, grad/param norm = 2.5627e-01, time/batch = 0.6492s	
2385/22300 (epoch 5.348), train_loss = 1.45935087, grad/param norm = 2.1911e-01, time/batch = 0.6451s	
2386/22300 (epoch 5.350), train_loss = 1.38445961, grad/param norm = 2.3159e-01, time/batch = 0.6439s	
2387/22300 (epoch 5.352), train_loss = 1.58088136, grad/param norm = 2.1762e-01, time/batch = 0.6426s	
2388/22300 (epoch 5.354), train_loss = 1.59772723, grad/param norm = 2.3067e-01, time/batch = 0.6424s	
2389/22300 (epoch 5.357), train_loss = 1.65834213, grad/param norm = 2.9609e-01, time/batch = 0.6457s	
2390/22300 (epoch 5.359), train_loss = 1.54557995, grad/param norm = 2.3719e-01, time/batch = 0.6470s	
2391/22300 (epoch 5.361), train_loss = 1.63400770, grad/param norm = 2.5814e-01, time/batch = 0.6493s	
2392/22300 (epoch 5.363), train_loss = 1.72395966, grad/param norm = 2.7942e-01, time/batch = 0.6475s	
2393/22300 (epoch 5.365), train_loss = 1.56438695, grad/param norm = 2.3714e-01, time/batch = 0.6489s	
2394/22300 (epoch 5.368), train_loss = 1.61535724, grad/param norm = 2.7331e-01, time/batch = 0.6496s	
2395/22300 (epoch 5.370), train_loss = 1.56086399, grad/param norm = 2.4907e-01, time/batch = 0.6460s	
2396/22300 (epoch 5.372), train_loss = 1.43230532, grad/param norm = 2.8000e-01, time/batch = 0.6452s	
2397/22300 (epoch 5.374), train_loss = 1.40883272, grad/param norm = 2.3520e-01, time/batch = 0.6495s	
2398/22300 (epoch 5.377), train_loss = 1.57587617, grad/param norm = 2.4578e-01, time/batch = 0.6522s	
2399/22300 (epoch 5.379), train_loss = 1.51166873, grad/param norm = 2.4536e-01, time/batch = 0.6468s	
2400/22300 (epoch 5.381), train_loss = 1.62847478, grad/param norm = 2.5204e-01, time/batch = 0.6436s	
2401/22300 (epoch 5.383), train_loss = 1.42014036, grad/param norm = 2.4390e-01, time/batch = 0.6489s	
2402/22300 (epoch 5.386), train_loss = 1.53434725, grad/param norm = 2.7639e-01, time/batch = 0.6553s	
2403/22300 (epoch 5.388), train_loss = 1.46506822, grad/param norm = 2.2855e-01, time/batch = 0.6583s	
2404/22300 (epoch 5.390), train_loss = 1.48380822, grad/param norm = 2.4437e-01, time/batch = 0.6452s	
2405/22300 (epoch 5.392), train_loss = 1.49490263, grad/param norm = 2.3368e-01, time/batch = 0.6449s	
2406/22300 (epoch 5.395), train_loss = 1.44588966, grad/param norm = 2.3996e-01, time/batch = 0.6454s	
2407/22300 (epoch 5.397), train_loss = 1.29698858, grad/param norm = 2.3284e-01, time/batch = 0.6350s	
2408/22300 (epoch 5.399), train_loss = 1.49439079, grad/param norm = 2.4259e-01, time/batch = 0.6410s	
2409/22300 (epoch 5.401), train_loss = 1.44740344, grad/param norm = 2.4284e-01, time/batch = 0.6484s	
2410/22300 (epoch 5.404), train_loss = 1.47853518, grad/param norm = 2.4460e-01, time/batch = 0.6478s	
2411/22300 (epoch 5.406), train_loss = 1.71402792, grad/param norm = 2.6954e-01, time/batch = 0.6451s	
2412/22300 (epoch 5.408), train_loss = 1.52516496, grad/param norm = 2.6829e-01, time/batch = 0.6428s	
2413/22300 (epoch 5.410), train_loss = 1.53693550, grad/param norm = 2.7508e-01, time/batch = 0.6492s	
2414/22300 (epoch 5.413), train_loss = 1.53745204, grad/param norm = 2.7769e-01, time/batch = 0.6491s	
2415/22300 (epoch 5.415), train_loss = 1.43126138, grad/param norm = 2.4753e-01, time/batch = 0.6489s	
2416/22300 (epoch 5.417), train_loss = 1.58616712, grad/param norm = 2.4800e-01, time/batch = 0.6522s	
2417/22300 (epoch 5.419), train_loss = 1.44306655, grad/param norm = 2.3963e-01, time/batch = 0.6507s	
2418/22300 (epoch 5.422), train_loss = 1.51624499, grad/param norm = 2.2756e-01, time/batch = 0.6471s	
2419/22300 (epoch 5.424), train_loss = 1.58557304, grad/param norm = 2.7443e-01, time/batch = 0.6510s	
2420/22300 (epoch 5.426), train_loss = 1.46487750, grad/param norm = 2.3822e-01, time/batch = 0.6509s	
2421/22300 (epoch 5.428), train_loss = 1.57611560, grad/param norm = 2.5282e-01, time/batch = 0.6476s	
2422/22300 (epoch 5.430), train_loss = 1.52912803, grad/param norm = 2.3430e-01, time/batch = 0.6469s	
2423/22300 (epoch 5.433), train_loss = 1.49465518, grad/param norm = 2.1431e-01, time/batch = 0.6516s	
2424/22300 (epoch 5.435), train_loss = 1.57294980, grad/param norm = 2.4318e-01, time/batch = 0.6515s	
2425/22300 (epoch 5.437), train_loss = 1.43881199, grad/param norm = 2.5994e-01, time/batch = 0.6517s	
2426/22300 (epoch 5.439), train_loss = 1.42932501, grad/param norm = 2.4858e-01, time/batch = 0.6478s	
2427/22300 (epoch 5.442), train_loss = 1.54230333, grad/param norm = 2.7470e-01, time/batch = 0.6481s	
2428/22300 (epoch 5.444), train_loss = 1.49620777, grad/param norm = 2.3510e-01, time/batch = 0.6529s	
2429/22300 (epoch 5.446), train_loss = 1.42373919, grad/param norm = 2.4032e-01, time/batch = 0.6516s	
2430/22300 (epoch 5.448), train_loss = 1.29487565, grad/param norm = 2.2049e-01, time/batch = 0.6444s	
2431/22300 (epoch 5.451), train_loss = 1.65951615, grad/param norm = 2.6389e-01, time/batch = 0.6471s	
2432/22300 (epoch 5.453), train_loss = 1.44944616, grad/param norm = 2.4905e-01, time/batch = 0.6510s	
2433/22300 (epoch 5.455), train_loss = 1.57296272, grad/param norm = 2.4124e-01, time/batch = 0.6496s	
2434/22300 (epoch 5.457), train_loss = 1.47196131, grad/param norm = 2.3458e-01, time/batch = 0.6443s	
2435/22300 (epoch 5.460), train_loss = 1.45483905, grad/param norm = 2.5186e-01, time/batch = 0.6402s	
2436/22300 (epoch 5.462), train_loss = 1.50185925, grad/param norm = 2.2348e-01, time/batch = 0.6447s	
2437/22300 (epoch 5.464), train_loss = 1.49290035, grad/param norm = 2.5182e-01, time/batch = 0.6417s	
2438/22300 (epoch 5.466), train_loss = 1.51669966, grad/param norm = 2.5445e-01, time/batch = 0.6443s	
2439/22300 (epoch 5.469), train_loss = 1.46968583, grad/param norm = 2.6027e-01, time/batch = 0.6510s	
2440/22300 (epoch 5.471), train_loss = 1.58326290, grad/param norm = 2.5820e-01, time/batch = 0.6574s	
2441/22300 (epoch 5.473), train_loss = 1.63298984, grad/param norm = 2.4606e-01, time/batch = 0.6600s	
2442/22300 (epoch 5.475), train_loss = 1.48935916, grad/param norm = 2.5089e-01, time/batch = 0.6598s	
2443/22300 (epoch 5.478), train_loss = 1.42114050, grad/param norm = 2.5622e-01, time/batch = 0.6581s	
2444/22300 (epoch 5.480), train_loss = 1.40593255, grad/param norm = 2.6862e-01, time/batch = 0.6570s	
2445/22300 (epoch 5.482), train_loss = 1.41391090, grad/param norm = 2.4430e-01, time/batch = 0.6519s	
2446/22300 (epoch 5.484), train_loss = 1.39276605, grad/param norm = 2.2332e-01, time/batch = 0.6503s	
2447/22300 (epoch 5.487), train_loss = 1.41988540, grad/param norm = 2.3470e-01, time/batch = 0.6551s	
2448/22300 (epoch 5.489), train_loss = 1.57576366, grad/param norm = 2.3724e-01, time/batch = 0.6505s	
2449/22300 (epoch 5.491), train_loss = 1.42836943, grad/param norm = 2.2899e-01, time/batch = 0.6553s	
2450/22300 (epoch 5.493), train_loss = 1.61298107, grad/param norm = 2.4976e-01, time/batch = 0.6632s	
2451/22300 (epoch 5.496), train_loss = 1.49533013, grad/param norm = 2.4991e-01, time/batch = 0.6534s	
2452/22300 (epoch 5.498), train_loss = 1.50099138, grad/param norm = 2.5813e-01, time/batch = 0.6427s	
2453/22300 (epoch 5.500), train_loss = 1.42348853, grad/param norm = 2.3570e-01, time/batch = 0.6456s	
2454/22300 (epoch 5.502), train_loss = 1.44974825, grad/param norm = 2.5634e-01, time/batch = 0.6461s	
2455/22300 (epoch 5.504), train_loss = 1.44634376, grad/param norm = 2.4209e-01, time/batch = 0.6479s	
2456/22300 (epoch 5.507), train_loss = 1.44696849, grad/param norm = 2.3623e-01, time/batch = 0.6502s	
2457/22300 (epoch 5.509), train_loss = 1.58979493, grad/param norm = 2.6010e-01, time/batch = 0.6458s	
2458/22300 (epoch 5.511), train_loss = 1.35371574, grad/param norm = 3.1643e-01, time/batch = 0.6451s	
2459/22300 (epoch 5.513), train_loss = 1.34259819, grad/param norm = 2.5277e-01, time/batch = 0.6458s	
2460/22300 (epoch 5.516), train_loss = 1.53094507, grad/param norm = 2.6332e-01, time/batch = 0.6597s	
2461/22300 (epoch 5.518), train_loss = 1.48311397, grad/param norm = 2.4993e-01, time/batch = 0.6624s	
2462/22300 (epoch 5.520), train_loss = 1.54462367, grad/param norm = 2.5787e-01, time/batch = 0.6604s	
2463/22300 (epoch 5.522), train_loss = 1.37798592, grad/param norm = 2.4604e-01, time/batch = 0.6514s	
2464/22300 (epoch 5.525), train_loss = 1.42115846, grad/param norm = 2.6923e-01, time/batch = 0.6495s	
2465/22300 (epoch 5.527), train_loss = 1.61335098, grad/param norm = 2.4433e-01, time/batch = 0.6502s	
2466/22300 (epoch 5.529), train_loss = 1.44994793, grad/param norm = 2.6504e-01, time/batch = 0.6447s	
2467/22300 (epoch 5.531), train_loss = 1.45813255, grad/param norm = 2.3131e-01, time/batch = 0.6553s	
2468/22300 (epoch 5.534), train_loss = 1.35485650, grad/param norm = 2.3672e-01, time/batch = 0.6457s	
2469/22300 (epoch 5.536), train_loss = 1.61476447, grad/param norm = 2.5130e-01, time/batch = 0.6524s	
2470/22300 (epoch 5.538), train_loss = 1.79149285, grad/param norm = 2.6368e-01, time/batch = 0.6546s	
2471/22300 (epoch 5.540), train_loss = 1.59054345, grad/param norm = 2.6019e-01, time/batch = 0.6559s	
2472/22300 (epoch 5.543), train_loss = 1.39079083, grad/param norm = 2.2226e-01, time/batch = 0.6542s	
2473/22300 (epoch 5.545), train_loss = 1.45871412, grad/param norm = 2.3807e-01, time/batch = 0.6547s	
2474/22300 (epoch 5.547), train_loss = 1.41112236, grad/param norm = 2.4440e-01, time/batch = 0.6511s	
2475/22300 (epoch 5.549), train_loss = 1.47573617, grad/param norm = 2.3499e-01, time/batch = 0.6633s	
2476/22300 (epoch 5.552), train_loss = 1.36818157, grad/param norm = 2.3330e-01, time/batch = 0.6615s	
2477/22300 (epoch 5.554), train_loss = 1.44964884, grad/param norm = 2.7108e-01, time/batch = 0.6621s	
2478/22300 (epoch 5.556), train_loss = 1.58304942, grad/param norm = 2.4795e-01, time/batch = 0.6590s	
2479/22300 (epoch 5.558), train_loss = 1.42475122, grad/param norm = 2.3301e-01, time/batch = 0.6536s	
2480/22300 (epoch 5.561), train_loss = 1.64041902, grad/param norm = 2.8526e-01, time/batch = 0.6613s	
2481/22300 (epoch 5.563), train_loss = 1.43900740, grad/param norm = 2.6403e-01, time/batch = 0.6644s	
2482/22300 (epoch 5.565), train_loss = 1.49557527, grad/param norm = 2.4105e-01, time/batch = 0.6623s	
2483/22300 (epoch 5.567), train_loss = 1.51340732, grad/param norm = 2.3461e-01, time/batch = 0.6634s	
2484/22300 (epoch 5.570), train_loss = 1.66996836, grad/param norm = 2.5536e-01, time/batch = 0.6632s	
2485/22300 (epoch 5.572), train_loss = 1.56185660, grad/param norm = 2.7081e-01, time/batch = 0.6592s	
2486/22300 (epoch 5.574), train_loss = 1.40712002, grad/param norm = 2.2980e-01, time/batch = 0.6629s	
2487/22300 (epoch 5.576), train_loss = 1.29067246, grad/param norm = 2.1123e-01, time/batch = 0.6494s	
2488/22300 (epoch 5.578), train_loss = 1.23555234, grad/param norm = 2.1965e-01, time/batch = 0.6592s	
2489/22300 (epoch 5.581), train_loss = 1.34654899, grad/param norm = 2.2687e-01, time/batch = 0.6527s	
2490/22300 (epoch 5.583), train_loss = 1.40390723, grad/param norm = 2.4111e-01, time/batch = 0.6593s	
2491/22300 (epoch 5.585), train_loss = 1.56766524, grad/param norm = 2.3922e-01, time/batch = 0.6508s	
2492/22300 (epoch 5.587), train_loss = 1.61318311, grad/param norm = 2.8822e-01, time/batch = 0.6539s	
2493/22300 (epoch 5.590), train_loss = 1.53182281, grad/param norm = 2.6518e-01, time/batch = 0.6609s	
2494/22300 (epoch 5.592), train_loss = 1.67290715, grad/param norm = 2.7918e-01, time/batch = 0.6547s	
2495/22300 (epoch 5.594), train_loss = 1.56306191, grad/param norm = 2.3747e-01, time/batch = 0.6458s	
2496/22300 (epoch 5.596), train_loss = 1.45383866, grad/param norm = 2.6193e-01, time/batch = 0.6416s	
2497/22300 (epoch 5.599), train_loss = 1.28442381, grad/param norm = 2.3755e-01, time/batch = 0.6440s	
2498/22300 (epoch 5.601), train_loss = 1.48994574, grad/param norm = 2.5887e-01, time/batch = 0.6449s	
2499/22300 (epoch 5.603), train_loss = 1.50031881, grad/param norm = 2.5212e-01, time/batch = 0.6462s	
2500/22300 (epoch 5.605), train_loss = 1.40906080, grad/param norm = 2.4623e-01, time/batch = 0.6472s	
2501/22300 (epoch 5.608), train_loss = 1.62459746, grad/param norm = 2.7246e-01, time/batch = 0.6507s	
2502/22300 (epoch 5.610), train_loss = 1.65609199, grad/param norm = 2.5253e-01, time/batch = 0.6565s	
2503/22300 (epoch 5.612), train_loss = 1.60776195, grad/param norm = 2.7975e-01, time/batch = 0.6658s	
2504/22300 (epoch 5.614), train_loss = 1.56394504, grad/param norm = 2.6807e-01, time/batch = 0.6619s	
2505/22300 (epoch 5.617), train_loss = 1.59391834, grad/param norm = 2.6056e-01, time/batch = 0.6696s	
2506/22300 (epoch 5.619), train_loss = 1.82313636, grad/param norm = 2.6073e-01, time/batch = 0.6834s	
2507/22300 (epoch 5.621), train_loss = 1.37022704, grad/param norm = 2.5243e-01, time/batch = 0.6786s	
2508/22300 (epoch 5.623), train_loss = 1.45760410, grad/param norm = 2.5372e-01, time/batch = 0.6701s	
2509/22300 (epoch 5.626), train_loss = 1.37445771, grad/param norm = 2.1839e-01, time/batch = 0.6742s	
2510/22300 (epoch 5.628), train_loss = 1.39006277, grad/param norm = 2.5423e-01, time/batch = 0.6633s	
2511/22300 (epoch 5.630), train_loss = 1.48398484, grad/param norm = 2.6062e-01, time/batch = 0.6501s	
2512/22300 (epoch 5.632), train_loss = 1.51873952, grad/param norm = 2.5685e-01, time/batch = 0.6516s	
2513/22300 (epoch 5.635), train_loss = 1.37889375, grad/param norm = 2.2765e-01, time/batch = 0.6553s	
2514/22300 (epoch 5.637), train_loss = 1.61965869, grad/param norm = 2.7318e-01, time/batch = 0.6568s	
2515/22300 (epoch 5.639), train_loss = 1.56870587, grad/param norm = 2.8740e-01, time/batch = 0.6604s	
2516/22300 (epoch 5.641), train_loss = 1.52208508, grad/param norm = 2.6271e-01, time/batch = 0.6586s	
2517/22300 (epoch 5.643), train_loss = 1.48650819, grad/param norm = 2.3682e-01, time/batch = 0.6625s	
2518/22300 (epoch 5.646), train_loss = 1.40157997, grad/param norm = 2.3879e-01, time/batch = 0.6579s	
2519/22300 (epoch 5.648), train_loss = 1.37929990, grad/param norm = 2.2448e-01, time/batch = 0.6619s	
2520/22300 (epoch 5.650), train_loss = 1.61863874, grad/param norm = 2.5657e-01, time/batch = 0.6532s	
2521/22300 (epoch 5.652), train_loss = 1.46553356, grad/param norm = 2.2867e-01, time/batch = 0.6486s	
2522/22300 (epoch 5.655), train_loss = 1.58789328, grad/param norm = 2.7829e-01, time/batch = 0.6571s	
2523/22300 (epoch 5.657), train_loss = 1.54048219, grad/param norm = 2.7312e-01, time/batch = 0.6486s	
2524/22300 (epoch 5.659), train_loss = 1.36834981, grad/param norm = 2.2763e-01, time/batch = 0.6517s	
2525/22300 (epoch 5.661), train_loss = 1.36004758, grad/param norm = 2.4330e-01, time/batch = 0.6491s	
2526/22300 (epoch 5.664), train_loss = 1.43985631, grad/param norm = 2.4749e-01, time/batch = 0.6458s	
2527/22300 (epoch 5.666), train_loss = 1.51953235, grad/param norm = 2.2857e-01, time/batch = 0.6476s	
2528/22300 (epoch 5.668), train_loss = 1.43882963, grad/param norm = 2.4559e-01, time/batch = 0.6488s	
2529/22300 (epoch 5.670), train_loss = 1.59395970, grad/param norm = 2.5303e-01, time/batch = 0.6434s	
2530/22300 (epoch 5.673), train_loss = 1.52336828, grad/param norm = 2.5197e-01, time/batch = 0.6472s	
2531/22300 (epoch 5.675), train_loss = 1.61073267, grad/param norm = 2.5661e-01, time/batch = 0.6551s	
2532/22300 (epoch 5.677), train_loss = 1.65030888, grad/param norm = 2.5958e-01, time/batch = 0.6616s	
2533/22300 (epoch 5.679), train_loss = 1.62734842, grad/param norm = 2.7879e-01, time/batch = 0.6674s	
2534/22300 (epoch 5.682), train_loss = 1.56997157, grad/param norm = 2.5313e-01, time/batch = 0.6637s	
2535/22300 (epoch 5.684), train_loss = 1.51936711, grad/param norm = 2.4478e-01, time/batch = 0.6615s	
2536/22300 (epoch 5.686), train_loss = 1.61039212, grad/param norm = 3.0771e-01, time/batch = 0.6561s	
2537/22300 (epoch 5.688), train_loss = 1.61429410, grad/param norm = 2.4964e-01, time/batch = 0.6509s	
2538/22300 (epoch 5.691), train_loss = 1.49961346, grad/param norm = 2.4645e-01, time/batch = 0.6509s	
2539/22300 (epoch 5.693), train_loss = 1.53147809, grad/param norm = 2.5191e-01, time/batch = 0.6527s	
2540/22300 (epoch 5.695), train_loss = 1.36174431, grad/param norm = 2.4586e-01, time/batch = 0.6648s	
2541/22300 (epoch 5.697), train_loss = 1.24992280, grad/param norm = 2.2347e-01, time/batch = 0.6686s	
2542/22300 (epoch 5.700), train_loss = 1.46496984, grad/param norm = 2.5318e-01, time/batch = 0.6516s	
2543/22300 (epoch 5.702), train_loss = 1.55871115, grad/param norm = 2.8729e-01, time/batch = 0.6584s	
2544/22300 (epoch 5.704), train_loss = 1.57859070, grad/param norm = 2.4901e-01, time/batch = 0.6682s	
2545/22300 (epoch 5.706), train_loss = 1.36389213, grad/param norm = 2.3212e-01, time/batch = 0.6745s	
2546/22300 (epoch 5.709), train_loss = 1.33094863, grad/param norm = 2.4154e-01, time/batch = 0.6686s	
2547/22300 (epoch 5.711), train_loss = 1.49316988, grad/param norm = 2.3370e-01, time/batch = 0.6630s	
2548/22300 (epoch 5.713), train_loss = 1.48812513, grad/param norm = 2.3267e-01, time/batch = 0.6725s	
2549/22300 (epoch 5.715), train_loss = 1.51545425, grad/param norm = 2.5795e-01, time/batch = 0.6742s	
2550/22300 (epoch 5.717), train_loss = 1.71306369, grad/param norm = 2.5543e-01, time/batch = 0.6605s	
2551/22300 (epoch 5.720), train_loss = 1.47781440, grad/param norm = 2.4164e-01, time/batch = 0.6642s	
2552/22300 (epoch 5.722), train_loss = 1.50881767, grad/param norm = 2.6394e-01, time/batch = 0.6797s	
2553/22300 (epoch 5.724), train_loss = 1.55750960, grad/param norm = 2.8172e-01, time/batch = 0.6697s	
2554/22300 (epoch 5.726), train_loss = 1.50504670, grad/param norm = 2.9378e-01, time/batch = 0.6648s	
2555/22300 (epoch 5.729), train_loss = 1.56178763, grad/param norm = 2.5339e-01, time/batch = 0.6751s	
2556/22300 (epoch 5.731), train_loss = 1.58512126, grad/param norm = 2.5334e-01, time/batch = 0.6705s	
2557/22300 (epoch 5.733), train_loss = 1.64216285, grad/param norm = 2.8180e-01, time/batch = 0.6829s	
2558/22300 (epoch 5.735), train_loss = 1.54713103, grad/param norm = 2.6639e-01, time/batch = 0.6677s	
2559/22300 (epoch 5.738), train_loss = 1.54350291, grad/param norm = 2.5581e-01, time/batch = 0.6668s	
2560/22300 (epoch 5.740), train_loss = 1.26057016, grad/param norm = 2.2241e-01, time/batch = 0.6680s	
2561/22300 (epoch 5.742), train_loss = 1.46867869, grad/param norm = 2.2899e-01, time/batch = 0.6748s	
2562/22300 (epoch 5.744), train_loss = 1.59689539, grad/param norm = 2.5524e-01, time/batch = 0.6794s	
2563/22300 (epoch 5.747), train_loss = 1.46590142, grad/param norm = 2.6918e-01, time/batch = 0.6737s	
2564/22300 (epoch 5.749), train_loss = 1.78748987, grad/param norm = 2.6300e-01, time/batch = 0.6650s	
2565/22300 (epoch 5.751), train_loss = 1.58977159, grad/param norm = 2.3489e-01, time/batch = 0.6667s	
2566/22300 (epoch 5.753), train_loss = 1.60337969, grad/param norm = 2.4507e-01, time/batch = 0.6697s	
2567/22300 (epoch 5.756), train_loss = 1.48315339, grad/param norm = 2.3411e-01, time/batch = 0.6696s	
2568/22300 (epoch 5.758), train_loss = 1.41031474, grad/param norm = 2.3578e-01, time/batch = 0.6652s	
2569/22300 (epoch 5.760), train_loss = 1.50853787, grad/param norm = 2.5732e-01, time/batch = 0.6616s	
2570/22300 (epoch 5.762), train_loss = 1.50948279, grad/param norm = 2.6818e-01, time/batch = 0.6631s	
2571/22300 (epoch 5.765), train_loss = 1.56023206, grad/param norm = 2.3491e-01, time/batch = 0.6698s	
2572/22300 (epoch 5.767), train_loss = 1.59439448, grad/param norm = 2.7254e-01, time/batch = 0.6592s	
2573/22300 (epoch 5.769), train_loss = 1.47405014, grad/param norm = 2.4718e-01, time/batch = 0.6590s	
2574/22300 (epoch 5.771), train_loss = 1.48175382, grad/param norm = 2.5331e-01, time/batch = 0.6556s	
2575/22300 (epoch 5.774), train_loss = 1.55691115, grad/param norm = 2.4027e-01, time/batch = 0.6619s	
2576/22300 (epoch 5.776), train_loss = 1.42666832, grad/param norm = 2.2289e-01, time/batch = 0.6665s	
2577/22300 (epoch 5.778), train_loss = 1.64534638, grad/param norm = 2.5409e-01, time/batch = 0.6561s	
2578/22300 (epoch 5.780), train_loss = 1.60553635, grad/param norm = 2.2172e-01, time/batch = 0.6563s	
2579/22300 (epoch 5.783), train_loss = 1.61085676, grad/param norm = 2.5250e-01, time/batch = 0.6584s	
2580/22300 (epoch 5.785), train_loss = 1.44591781, grad/param norm = 2.4849e-01, time/batch = 0.6685s	
2581/22300 (epoch 5.787), train_loss = 1.43944264, grad/param norm = 2.4977e-01, time/batch = 0.6696s	
2582/22300 (epoch 5.789), train_loss = 1.55847341, grad/param norm = 2.5613e-01, time/batch = 0.6734s	
2583/22300 (epoch 5.791), train_loss = 1.65615918, grad/param norm = 2.6846e-01, time/batch = 0.6591s	
2584/22300 (epoch 5.794), train_loss = 1.58974708, grad/param norm = 2.5333e-01, time/batch = 0.6596s	
2585/22300 (epoch 5.796), train_loss = 1.61481219, grad/param norm = 2.4754e-01, time/batch = 0.6631s	
2586/22300 (epoch 5.798), train_loss = 1.56920426, grad/param norm = 2.4937e-01, time/batch = 0.6550s	
2587/22300 (epoch 5.800), train_loss = 1.34251717, grad/param norm = 2.3550e-01, time/batch = 0.6569s	
2588/22300 (epoch 5.803), train_loss = 1.34731967, grad/param norm = 2.2754e-01, time/batch = 0.6580s	
2589/22300 (epoch 5.805), train_loss = 1.49493075, grad/param norm = 2.3067e-01, time/batch = 0.6562s	
2590/22300 (epoch 5.807), train_loss = 1.53483547, grad/param norm = 2.3443e-01, time/batch = 0.6596s	
2591/22300 (epoch 5.809), train_loss = 1.57359339, grad/param norm = 2.5926e-01, time/batch = 0.6742s	
2592/22300 (epoch 5.812), train_loss = 1.62551378, grad/param norm = 2.9625e-01, time/batch = 0.6775s	
2593/22300 (epoch 5.814), train_loss = 1.50102474, grad/param norm = 2.4603e-01, time/batch = 0.6692s	
2594/22300 (epoch 5.816), train_loss = 1.61175069, grad/param norm = 2.5354e-01, time/batch = 0.6616s	
2595/22300 (epoch 5.818), train_loss = 1.57580226, grad/param norm = 2.7144e-01, time/batch = 0.6657s	
2596/22300 (epoch 5.821), train_loss = 1.67739474, grad/param norm = 2.5101e-01, time/batch = 0.6567s	
2597/22300 (epoch 5.823), train_loss = 1.41067790, grad/param norm = 2.2248e-01, time/batch = 0.6547s	
2598/22300 (epoch 5.825), train_loss = 1.47825185, grad/param norm = 2.3997e-01, time/batch = 0.6553s	
2599/22300 (epoch 5.827), train_loss = 1.51628370, grad/param norm = 2.4321e-01, time/batch = 0.6547s	
2600/22300 (epoch 5.830), train_loss = 1.46522304, grad/param norm = 2.7388e-01, time/batch = 0.6531s	
2601/22300 (epoch 5.832), train_loss = 1.40581794, grad/param norm = 2.5840e-01, time/batch = 0.6562s	
2602/22300 (epoch 5.834), train_loss = 1.57727313, grad/param norm = 2.5062e-01, time/batch = 0.6565s	
2603/22300 (epoch 5.836), train_loss = 1.50307603, grad/param norm = 2.4708e-01, time/batch = 0.6529s	
2604/22300 (epoch 5.839), train_loss = 1.50253229, grad/param norm = 2.0685e-01, time/batch = 0.6487s	
2605/22300 (epoch 5.841), train_loss = 1.46552130, grad/param norm = 2.3488e-01, time/batch = 0.6544s	
2606/22300 (epoch 5.843), train_loss = 1.47865679, grad/param norm = 2.6233e-01, time/batch = 0.6662s	
2607/22300 (epoch 5.845), train_loss = 1.48558964, grad/param norm = 2.3736e-01, time/batch = 0.6737s	
2608/22300 (epoch 5.848), train_loss = 1.47667471, grad/param norm = 2.5591e-01, time/batch = 0.6545s	
2609/22300 (epoch 5.850), train_loss = 1.54286067, grad/param norm = 2.6119e-01, time/batch = 0.6562s	
2610/22300 (epoch 5.852), train_loss = 1.55570686, grad/param norm = 2.5774e-01, time/batch = 0.6611s	
2611/22300 (epoch 5.854), train_loss = 1.67458319, grad/param norm = 2.6785e-01, time/batch = 0.6775s	
2612/22300 (epoch 5.857), train_loss = 1.44566807, grad/param norm = 2.5040e-01, time/batch = 0.6761s	
2613/22300 (epoch 5.859), train_loss = 1.35518027, grad/param norm = 2.1997e-01, time/batch = 0.6762s	
2614/22300 (epoch 5.861), train_loss = 1.48001501, grad/param norm = 2.2964e-01, time/batch = 0.6743s	
2615/22300 (epoch 5.863), train_loss = 1.36640460, grad/param norm = 2.2699e-01, time/batch = 0.6924s	
2616/22300 (epoch 5.865), train_loss = 1.37780824, grad/param norm = 2.4052e-01, time/batch = 0.6835s	
2617/22300 (epoch 5.868), train_loss = 1.42979368, grad/param norm = 2.3636e-01, time/batch = 0.6733s	
2618/22300 (epoch 5.870), train_loss = 1.46492962, grad/param norm = 2.4237e-01, time/batch = 0.6802s	
2619/22300 (epoch 5.872), train_loss = 1.54209294, grad/param norm = 2.4570e-01, time/batch = 0.6733s	
2620/22300 (epoch 5.874), train_loss = 1.53695351, grad/param norm = 2.5714e-01, time/batch = 0.6823s	
2621/22300 (epoch 5.877), train_loss = 1.43823810, grad/param norm = 2.3671e-01, time/batch = 0.6720s	
2622/22300 (epoch 5.879), train_loss = 1.32776758, grad/param norm = 2.3506e-01, time/batch = 0.6682s	
2623/22300 (epoch 5.881), train_loss = 1.46321956, grad/param norm = 3.2434e-01, time/batch = 0.6741s	
2624/22300 (epoch 5.883), train_loss = 1.49969861, grad/param norm = 3.2257e-01, time/batch = 1.3165s	
2625/22300 (epoch 5.886), train_loss = 1.45076185, grad/param norm = 2.2313e-01, time/batch = 0.6921s	
2626/22300 (epoch 5.888), train_loss = 1.43384400, grad/param norm = 2.3075e-01, time/batch = 0.6715s	
2627/22300 (epoch 5.890), train_loss = 1.31726346, grad/param norm = 2.1237e-01, time/batch = 0.6756s	
2628/22300 (epoch 5.892), train_loss = 1.59269578, grad/param norm = 2.5697e-01, time/batch = 0.6795s	
2629/22300 (epoch 5.895), train_loss = 1.57800412, grad/param norm = 2.5792e-01, time/batch = 0.6670s	
2630/22300 (epoch 5.897), train_loss = 1.53682468, grad/param norm = 2.6199e-01, time/batch = 0.6729s	
2631/22300 (epoch 5.899), train_loss = 1.47714308, grad/param norm = 2.1507e-01, time/batch = 0.6798s	
2632/22300 (epoch 5.901), train_loss = 1.40752146, grad/param norm = 2.3436e-01, time/batch = 0.6571s	
2633/22300 (epoch 5.904), train_loss = 1.42881515, grad/param norm = 2.6160e-01, time/batch = 0.6806s	
2634/22300 (epoch 5.906), train_loss = 1.57688681, grad/param norm = 2.3660e-01, time/batch = 0.6817s	
2635/22300 (epoch 5.908), train_loss = 1.49318406, grad/param norm = 2.5722e-01, time/batch = 0.6676s	
2636/22300 (epoch 5.910), train_loss = 1.39188468, grad/param norm = 2.4322e-01, time/batch = 0.6696s	
2637/22300 (epoch 5.913), train_loss = 1.44227348, grad/param norm = 2.3467e-01, time/batch = 0.6663s	
2638/22300 (epoch 5.915), train_loss = 1.64950592, grad/param norm = 2.7112e-01, time/batch = 0.6642s	
2639/22300 (epoch 5.917), train_loss = 1.45613485, grad/param norm = 2.8083e-01, time/batch = 0.6690s	
2640/22300 (epoch 5.919), train_loss = 1.51201389, grad/param norm = 2.5678e-01, time/batch = 0.6659s	
2641/22300 (epoch 5.922), train_loss = 1.52953931, grad/param norm = 2.7016e-01, time/batch = 0.6927s	
2642/22300 (epoch 5.924), train_loss = 1.34188985, grad/param norm = 2.1076e-01, time/batch = 0.6779s	
2643/22300 (epoch 5.926), train_loss = 1.28200686, grad/param norm = 2.3676e-01, time/batch = 0.6695s	
2644/22300 (epoch 5.928), train_loss = 1.50149624, grad/param norm = 2.5039e-01, time/batch = 0.6684s	
2645/22300 (epoch 5.930), train_loss = 1.51165114, grad/param norm = 2.4808e-01, time/batch = 0.6746s	
2646/22300 (epoch 5.933), train_loss = 1.50188211, grad/param norm = 2.6707e-01, time/batch = 0.6647s	
2647/22300 (epoch 5.935), train_loss = 1.63059549, grad/param norm = 2.5154e-01, time/batch = 0.6646s	
2648/22300 (epoch 5.937), train_loss = 1.53045961, grad/param norm = 2.4585e-01, time/batch = 0.6724s	
2649/22300 (epoch 5.939), train_loss = 1.57529523, grad/param norm = 2.5357e-01, time/batch = 0.6758s	
2650/22300 (epoch 5.942), train_loss = 1.61941915, grad/param norm = 2.4482e-01, time/batch = 0.6672s	
2651/22300 (epoch 5.944), train_loss = 1.71680430, grad/param norm = 2.7969e-01, time/batch = 0.6655s	
2652/22300 (epoch 5.946), train_loss = 1.45353793, grad/param norm = 2.7184e-01, time/batch = 0.6636s	
2653/22300 (epoch 5.948), train_loss = 1.45835059, grad/param norm = 2.3553e-01, time/batch = 0.6680s	
2654/22300 (epoch 5.951), train_loss = 1.35323534, grad/param norm = 2.2346e-01, time/batch = 0.6693s	
2655/22300 (epoch 5.953), train_loss = 1.43300511, grad/param norm = 2.4545e-01, time/batch = 0.6622s	
2656/22300 (epoch 5.955), train_loss = 1.68905541, grad/param norm = 2.6428e-01, time/batch = 0.6758s	
2657/22300 (epoch 5.957), train_loss = 1.66914177, grad/param norm = 2.5173e-01, time/batch = 0.6639s	
2658/22300 (epoch 5.960), train_loss = 1.63118122, grad/param norm = 2.8373e-01, time/batch = 0.6729s	
2659/22300 (epoch 5.962), train_loss = 1.55286494, grad/param norm = 2.2763e-01, time/batch = 0.6642s	
2660/22300 (epoch 5.964), train_loss = 1.52338072, grad/param norm = 2.5788e-01, time/batch = 0.6603s	
2661/22300 (epoch 5.966), train_loss = 1.47310022, grad/param norm = 2.4745e-01, time/batch = 0.6599s	
2662/22300 (epoch 5.969), train_loss = 1.37784891, grad/param norm = 2.1499e-01, time/batch = 0.6581s	
2663/22300 (epoch 5.971), train_loss = 1.44790303, grad/param norm = 2.6475e-01, time/batch = 0.6628s	
2664/22300 (epoch 5.973), train_loss = 1.44403903, grad/param norm = 2.3779e-01, time/batch = 0.6664s	
2665/22300 (epoch 5.975), train_loss = 1.73154855, grad/param norm = 2.4814e-01, time/batch = 0.6675s	
2666/22300 (epoch 5.978), train_loss = 1.38516959, grad/param norm = 2.1388e-01, time/batch = 0.6641s	
2667/22300 (epoch 5.980), train_loss = 1.53509087, grad/param norm = 2.4620e-01, time/batch = 0.6727s	
2668/22300 (epoch 5.982), train_loss = 1.37576059, grad/param norm = 2.2369e-01, time/batch = 0.6693s	
2669/22300 (epoch 5.984), train_loss = 1.53487429, grad/param norm = 2.4952e-01, time/batch = 0.6738s	
2670/22300 (epoch 5.987), train_loss = 1.42725955, grad/param norm = 2.3507e-01, time/batch = 0.6679s	
2671/22300 (epoch 5.989), train_loss = 1.51511953, grad/param norm = 2.3998e-01, time/batch = 0.6737s	
2672/22300 (epoch 5.991), train_loss = 1.66231534, grad/param norm = 2.4847e-01, time/batch = 0.6674s	
2673/22300 (epoch 5.993), train_loss = 1.65186402, grad/param norm = 2.6228e-01, time/batch = 0.6699s	
2674/22300 (epoch 5.996), train_loss = 1.67625601, grad/param norm = 2.7544e-01, time/batch = 0.6667s	
2675/22300 (epoch 5.998), train_loss = 1.46593750, grad/param norm = 2.6680e-01, time/batch = 0.6617s	
2676/22300 (epoch 6.000), train_loss = 1.38672793, grad/param norm = 2.4264e-01, time/batch = 0.6614s	
2677/22300 (epoch 6.002), train_loss = 1.58964514, grad/param norm = 2.5330e-01, time/batch = 0.6668s	
2678/22300 (epoch 6.004), train_loss = 1.49473299, grad/param norm = 2.3510e-01, time/batch = 0.6657s	
2679/22300 (epoch 6.007), train_loss = 1.47399563, grad/param norm = 2.3913e-01, time/batch = 0.6695s	
2680/22300 (epoch 6.009), train_loss = 1.47616541, grad/param norm = 2.3759e-01, time/batch = 0.6640s	
2681/22300 (epoch 6.011), train_loss = 1.62478271, grad/param norm = 2.6283e-01, time/batch = 0.6668s	
2682/22300 (epoch 6.013), train_loss = 1.41795619, grad/param norm = 2.6947e-01, time/batch = 0.6646s	
2683/22300 (epoch 6.016), train_loss = 1.45383520, grad/param norm = 2.5646e-01, time/batch = 0.6623s	
2684/22300 (epoch 6.018), train_loss = 1.58485844, grad/param norm = 2.5661e-01, time/batch = 0.6653s	
2685/22300 (epoch 6.020), train_loss = 1.44296553, grad/param norm = 2.3042e-01, time/batch = 0.6698s	
2686/22300 (epoch 6.022), train_loss = 1.44396402, grad/param norm = 2.4480e-01, time/batch = 0.6715s	
2687/22300 (epoch 6.025), train_loss = 1.45996877, grad/param norm = 2.4474e-01, time/batch = 0.6702s	
2688/22300 (epoch 6.027), train_loss = 1.60002408, grad/param norm = 2.5075e-01, time/batch = 0.6588s	
2689/22300 (epoch 6.029), train_loss = 1.41143968, grad/param norm = 2.3037e-01, time/batch = 0.6575s	
2690/22300 (epoch 6.031), train_loss = 1.31071128, grad/param norm = 2.0981e-01, time/batch = 0.6625s	
2691/22300 (epoch 6.034), train_loss = 1.35859758, grad/param norm = 2.1903e-01, time/batch = 0.6664s	
2692/22300 (epoch 6.036), train_loss = 1.25660468, grad/param norm = 2.2475e-01, time/batch = 0.6728s	
2693/22300 (epoch 6.038), train_loss = 1.32180429, grad/param norm = 2.1417e-01, time/batch = 0.6754s	
2694/22300 (epoch 6.040), train_loss = 1.52355538, grad/param norm = 2.6498e-01, time/batch = 0.6699s	
2695/22300 (epoch 6.043), train_loss = 1.59991114, grad/param norm = 2.8740e-01, time/batch = 0.6680s	
2696/22300 (epoch 6.045), train_loss = 1.46602771, grad/param norm = 2.3119e-01, time/batch = 0.6652s	
2697/22300 (epoch 6.047), train_loss = 1.51544220, grad/param norm = 2.5456e-01, time/batch = 0.6679s	
2698/22300 (epoch 6.049), train_loss = 1.36150972, grad/param norm = 2.2150e-01, time/batch = 0.6677s	
2699/22300 (epoch 6.052), train_loss = 1.55939405, grad/param norm = 2.6136e-01, time/batch = 0.6672s	
2700/22300 (epoch 6.054), train_loss = 1.49878036, grad/param norm = 2.4345e-01, time/batch = 0.6586s	
2701/22300 (epoch 6.056), train_loss = 1.29073852, grad/param norm = 2.2201e-01, time/batch = 0.6740s	
2702/22300 (epoch 6.058), train_loss = 1.28283432, grad/param norm = 1.9840e-01, time/batch = 0.6765s	
2703/22300 (epoch 6.061), train_loss = 1.35291978, grad/param norm = 2.5226e-01, time/batch = 0.6658s	
2704/22300 (epoch 6.063), train_loss = 1.57918955, grad/param norm = 2.5393e-01, time/batch = 0.6641s	
2705/22300 (epoch 6.065), train_loss = 1.43346219, grad/param norm = 2.6842e-01, time/batch = 0.6621s	
2706/22300 (epoch 6.067), train_loss = 1.40174056, grad/param norm = 2.1397e-01, time/batch = 0.6617s	
2707/22300 (epoch 6.070), train_loss = 1.39327219, grad/param norm = 2.5460e-01, time/batch = 0.6723s	
2708/22300 (epoch 6.072), train_loss = 1.47632332, grad/param norm = 2.4519e-01, time/batch = 0.6678s	
2709/22300 (epoch 6.074), train_loss = 1.48502194, grad/param norm = 2.3419e-01, time/batch = 0.6690s	
2710/22300 (epoch 6.076), train_loss = 1.34224180, grad/param norm = 2.2705e-01, time/batch = 0.6739s	
2711/22300 (epoch 6.078), train_loss = 1.40453505, grad/param norm = 2.3140e-01, time/batch = 0.6787s	
2712/22300 (epoch 6.081), train_loss = 1.54356691, grad/param norm = 2.4126e-01, time/batch = 0.6930s	
2713/22300 (epoch 6.083), train_loss = 1.53670083, grad/param norm = 2.5823e-01, time/batch = 0.6714s	
2714/22300 (epoch 6.085), train_loss = 1.61674142, grad/param norm = 2.3201e-01, time/batch = 0.6757s	
2715/22300 (epoch 6.087), train_loss = 1.47040163, grad/param norm = 2.7315e-01, time/batch = 0.6793s	
2716/22300 (epoch 6.090), train_loss = 1.34274342, grad/param norm = 2.3269e-01, time/batch = 0.6759s	
2717/22300 (epoch 6.092), train_loss = 1.41740826, grad/param norm = 2.4675e-01, time/batch = 0.6724s	
2718/22300 (epoch 6.094), train_loss = 1.30153490, grad/param norm = 2.3237e-01, time/batch = 0.6753s	
2719/22300 (epoch 6.096), train_loss = 1.57547899, grad/param norm = 2.2812e-01, time/batch = 0.6825s	
2720/22300 (epoch 6.099), train_loss = 1.48586649, grad/param norm = 2.4205e-01, time/batch = 0.6658s	
2721/22300 (epoch 6.101), train_loss = 1.58959665, grad/param norm = 2.5630e-01, time/batch = 0.6638s	
2722/22300 (epoch 6.103), train_loss = 1.52155015, grad/param norm = 2.3000e-01, time/batch = 0.6586s	
2723/22300 (epoch 6.105), train_loss = 1.46236002, grad/param norm = 2.5069e-01, time/batch = 0.6490s	
2724/22300 (epoch 6.108), train_loss = 1.51025056, grad/param norm = 2.8415e-01, time/batch = 0.6520s	
2725/22300 (epoch 6.110), train_loss = 1.45369056, grad/param norm = 2.3365e-01, time/batch = 0.6595s	
2726/22300 (epoch 6.112), train_loss = 1.42098903, grad/param norm = 2.3202e-01, time/batch = 0.6562s	
2727/22300 (epoch 6.114), train_loss = 1.57305390, grad/param norm = 2.3161e-01, time/batch = 0.6525s	
2728/22300 (epoch 6.117), train_loss = 1.67990768, grad/param norm = 2.4481e-01, time/batch = 0.6612s	
2729/22300 (epoch 6.119), train_loss = 1.48993476, grad/param norm = 2.4277e-01, time/batch = 0.6608s	
2730/22300 (epoch 6.121), train_loss = 1.56700385, grad/param norm = 2.4738e-01, time/batch = 0.6599s	
2731/22300 (epoch 6.123), train_loss = 1.37373457, grad/param norm = 2.4409e-01, time/batch = 0.6848s	
2732/22300 (epoch 6.126), train_loss = 1.37582833, grad/param norm = 2.5699e-01, time/batch = 0.6759s	
2733/22300 (epoch 6.128), train_loss = 1.50528355, grad/param norm = 2.3567e-01, time/batch = 0.6741s	
2734/22300 (epoch 6.130), train_loss = 1.47401008, grad/param norm = 2.2360e-01, time/batch = 0.6655s	
2735/22300 (epoch 6.132), train_loss = 1.35107532, grad/param norm = 2.4322e-01, time/batch = 0.6697s	
2736/22300 (epoch 6.135), train_loss = 1.34060535, grad/param norm = 2.3396e-01, time/batch = 0.6684s	
2737/22300 (epoch 6.137), train_loss = 1.14580045, grad/param norm = 2.0888e-01, time/batch = 0.6631s	
2738/22300 (epoch 6.139), train_loss = 1.49362802, grad/param norm = 2.5205e-01, time/batch = 0.6707s	
2739/22300 (epoch 6.141), train_loss = 1.54029163, grad/param norm = 2.3482e-01, time/batch = 0.6700s	
2740/22300 (epoch 6.143), train_loss = 1.47067895, grad/param norm = 2.2423e-01, time/batch = 0.6679s	
2741/22300 (epoch 6.146), train_loss = 1.60754832, grad/param norm = 2.5398e-01, time/batch = 0.6729s	
2742/22300 (epoch 6.148), train_loss = 1.39879788, grad/param norm = 2.5924e-01, time/batch = 0.6744s	
2743/22300 (epoch 6.150), train_loss = 1.47848326, grad/param norm = 2.6871e-01, time/batch = 0.6735s	
2744/22300 (epoch 6.152), train_loss = 1.46341685, grad/param norm = 2.8740e-01, time/batch = 0.6707s	
2745/22300 (epoch 6.155), train_loss = 1.42879500, grad/param norm = 2.4132e-01, time/batch = 0.6698s	
2746/22300 (epoch 6.157), train_loss = 1.58679246, grad/param norm = 2.6667e-01, time/batch = 0.6716s	
2747/22300 (epoch 6.159), train_loss = 1.52389161, grad/param norm = 2.5389e-01, time/batch = 0.6805s	
2748/22300 (epoch 6.161), train_loss = 1.55270853, grad/param norm = 2.5575e-01, time/batch = 0.6756s	
2749/22300 (epoch 6.164), train_loss = 1.38600187, grad/param norm = 2.8094e-01, time/batch = 0.6872s	
2750/22300 (epoch 6.166), train_loss = 1.37428444, grad/param norm = 2.3729e-01, time/batch = 0.6845s	
2751/22300 (epoch 6.168), train_loss = 1.41372862, grad/param norm = 2.3664e-01, time/batch = 0.6818s	
2752/22300 (epoch 6.170), train_loss = 1.44445410, grad/param norm = 2.2299e-01, time/batch = 0.6613s	
2753/22300 (epoch 6.173), train_loss = 1.66120535, grad/param norm = 2.5267e-01, time/batch = 0.6792s	
2754/22300 (epoch 6.175), train_loss = 1.40898211, grad/param norm = 2.5861e-01, time/batch = 0.6804s	
2755/22300 (epoch 6.177), train_loss = 1.25912386, grad/param norm = 2.2173e-01, time/batch = 0.6719s	
2756/22300 (epoch 6.179), train_loss = 1.35726308, grad/param norm = 2.2594e-01, time/batch = 0.6741s	
2757/22300 (epoch 6.182), train_loss = 1.56371071, grad/param norm = 2.3549e-01, time/batch = 0.6677s	
2758/22300 (epoch 6.184), train_loss = 1.65520565, grad/param norm = 2.6068e-01, time/batch = 0.6709s	
2759/22300 (epoch 6.186), train_loss = 1.49902056, grad/param norm = 2.3528e-01, time/batch = 0.6618s	
2760/22300 (epoch 6.188), train_loss = 1.57250929, grad/param norm = 2.6058e-01, time/batch = 0.6701s	
2761/22300 (epoch 6.191), train_loss = 1.61884399, grad/param norm = 2.6011e-01, time/batch = 0.6755s	
2762/22300 (epoch 6.193), train_loss = 1.38830244, grad/param norm = 2.3345e-01, time/batch = 0.6703s	
2763/22300 (epoch 6.195), train_loss = 1.33367880, grad/param norm = 2.2880e-01, time/batch = 0.6777s	
2764/22300 (epoch 6.197), train_loss = 1.47993095, grad/param norm = 2.2362e-01, time/batch = 0.6827s	
2765/22300 (epoch 6.200), train_loss = 1.41057567, grad/param norm = 2.3371e-01, time/batch = 0.6645s	
2766/22300 (epoch 6.202), train_loss = 1.42324885, grad/param norm = 2.6604e-01, time/batch = 0.6586s	
2767/22300 (epoch 6.204), train_loss = 1.36417042, grad/param norm = 2.3557e-01, time/batch = 0.6619s	
2768/22300 (epoch 6.206), train_loss = 1.26429619, grad/param norm = 2.0585e-01, time/batch = 0.6671s	
2769/22300 (epoch 6.209), train_loss = 1.43766877, grad/param norm = 2.5819e-01, time/batch = 0.6702s	
2770/22300 (epoch 6.211), train_loss = 1.32187395, grad/param norm = 2.3884e-01, time/batch = 0.6645s	
2771/22300 (epoch 6.213), train_loss = 1.34344660, grad/param norm = 2.1983e-01, time/batch = 0.6675s	
2772/22300 (epoch 6.215), train_loss = 1.59639043, grad/param norm = 2.5727e-01, time/batch = 0.6722s	
2773/22300 (epoch 6.217), train_loss = 1.52264286, grad/param norm = 2.5243e-01, time/batch = 0.6761s	
2774/22300 (epoch 6.220), train_loss = 1.41537430, grad/param norm = 2.3172e-01, time/batch = 0.6740s	
2775/22300 (epoch 6.222), train_loss = 1.39241110, grad/param norm = 2.3803e-01, time/batch = 0.6709s	
2776/22300 (epoch 6.224), train_loss = 1.33207351, grad/param norm = 2.5158e-01, time/batch = 0.6680s	
2777/22300 (epoch 6.226), train_loss = 1.43487927, grad/param norm = 2.3392e-01, time/batch = 0.6653s	
2778/22300 (epoch 6.229), train_loss = 1.49608711, grad/param norm = 2.5690e-01, time/batch = 0.6667s	
2779/22300 (epoch 6.231), train_loss = 1.52962621, grad/param norm = 2.5875e-01, time/batch = 0.6684s	
2780/22300 (epoch 6.233), train_loss = 1.53786550, grad/param norm = 2.3961e-01, time/batch = 0.6689s	
2781/22300 (epoch 6.235), train_loss = 1.36319035, grad/param norm = 2.2882e-01, time/batch = 0.6661s	
2782/22300 (epoch 6.238), train_loss = 1.36367568, grad/param norm = 2.5031e-01, time/batch = 0.6602s	
2783/22300 (epoch 6.240), train_loss = 1.29473053, grad/param norm = 2.3299e-01, time/batch = 0.6665s	
2784/22300 (epoch 6.242), train_loss = 1.40532467, grad/param norm = 2.2417e-01, time/batch = 0.6667s	
2785/22300 (epoch 6.244), train_loss = 1.12394276, grad/param norm = 2.0916e-01, time/batch = 0.6658s	
2786/22300 (epoch 6.247), train_loss = 1.45415870, grad/param norm = 2.3866e-01, time/batch = 0.6708s	
2787/22300 (epoch 6.249), train_loss = 1.31703394, grad/param norm = 2.2671e-01, time/batch = 0.6729s	
2788/22300 (epoch 6.251), train_loss = 1.27198683, grad/param norm = 2.1058e-01, time/batch = 0.6708s	
2789/22300 (epoch 6.253), train_loss = 1.36998880, grad/param norm = 2.4956e-01, time/batch = 0.6631s	
2790/22300 (epoch 6.256), train_loss = 1.47380711, grad/param norm = 2.5601e-01, time/batch = 0.6672s	
2791/22300 (epoch 6.258), train_loss = 1.59199237, grad/param norm = 2.7608e-01, time/batch = 0.6650s	
2792/22300 (epoch 6.260), train_loss = 1.44908934, grad/param norm = 2.5835e-01, time/batch = 0.6688s	
2793/22300 (epoch 6.262), train_loss = 1.41315546, grad/param norm = 2.2775e-01, time/batch = 0.6783s	
2794/22300 (epoch 6.265), train_loss = 1.44412527, grad/param norm = 2.6187e-01, time/batch = 0.6812s	
2795/22300 (epoch 6.267), train_loss = 1.41382293, grad/param norm = 2.4240e-01, time/batch = 0.6738s	
2796/22300 (epoch 6.269), train_loss = 1.41985026, grad/param norm = 2.5755e-01, time/batch = 0.6784s	
2797/22300 (epoch 6.271), train_loss = 1.39518091, grad/param norm = 2.3976e-01, time/batch = 0.6763s	
2798/22300 (epoch 6.274), train_loss = 1.30487767, grad/param norm = 2.4065e-01, time/batch = 0.6782s	
2799/22300 (epoch 6.276), train_loss = 1.23126508, grad/param norm = 2.3356e-01, time/batch = 0.6762s	
2800/22300 (epoch 6.278), train_loss = 1.21318385, grad/param norm = 2.3551e-01, time/batch = 0.6693s	
2801/22300 (epoch 6.280), train_loss = 1.31048030, grad/param norm = 2.4119e-01, time/batch = 0.6873s	
2802/22300 (epoch 6.283), train_loss = 1.19462184, grad/param norm = 2.1882e-01, time/batch = 0.6838s	
2803/22300 (epoch 6.285), train_loss = 1.39102027, grad/param norm = 2.7086e-01, time/batch = 0.6869s	
2804/22300 (epoch 6.287), train_loss = 1.42674908, grad/param norm = 2.3831e-01, time/batch = 0.6775s	
2805/22300 (epoch 6.289), train_loss = 1.35347467, grad/param norm = 2.5221e-01, time/batch = 0.6743s	
2806/22300 (epoch 6.291), train_loss = 1.44473047, grad/param norm = 2.5772e-01, time/batch = 0.6774s	
2807/22300 (epoch 6.294), train_loss = 1.27742530, grad/param norm = 2.1340e-01, time/batch = 0.6733s	
2808/22300 (epoch 6.296), train_loss = 1.52360990, grad/param norm = 2.5892e-01, time/batch = 0.6722s	
2809/22300 (epoch 6.298), train_loss = 1.50057062, grad/param norm = 2.5883e-01, time/batch = 0.6640s	
2810/22300 (epoch 6.300), train_loss = 1.54706180, grad/param norm = 2.4983e-01, time/batch = 0.6644s	
2811/22300 (epoch 6.303), train_loss = 1.37613011, grad/param norm = 2.3502e-01, time/batch = 0.6764s	
2812/22300 (epoch 6.305), train_loss = 1.51989507, grad/param norm = 2.8573e-01, time/batch = 0.6916s	
2813/22300 (epoch 6.307), train_loss = 1.43789653, grad/param norm = 2.3928e-01, time/batch = 0.6788s	
2814/22300 (epoch 6.309), train_loss = 1.42649399, grad/param norm = 2.7847e-01, time/batch = 0.6712s	
2815/22300 (epoch 6.312), train_loss = 1.30224057, grad/param norm = 2.4066e-01, time/batch = 0.6723s	
2816/22300 (epoch 6.314), train_loss = 1.43171285, grad/param norm = 2.3502e-01, time/batch = 0.6724s	
2817/22300 (epoch 6.316), train_loss = 1.39316555, grad/param norm = 2.2720e-01, time/batch = 0.6732s	
2818/22300 (epoch 6.318), train_loss = 1.49401628, grad/param norm = 2.5292e-01, time/batch = 0.6692s	
2819/22300 (epoch 6.321), train_loss = 1.47735960, grad/param norm = 2.6487e-01, time/batch = 0.6693s	
2820/22300 (epoch 6.323), train_loss = 1.42048494, grad/param norm = 2.2553e-01, time/batch = 0.6721s	
2821/22300 (epoch 6.325), train_loss = 1.28448737, grad/param norm = 2.2450e-01, time/batch = 0.6658s	
2822/22300 (epoch 6.327), train_loss = 1.38109035, grad/param norm = 2.4599e-01, time/batch = 0.6659s	
2823/22300 (epoch 6.330), train_loss = 1.43091021, grad/param norm = 2.6379e-01, time/batch = 0.6644s	
2824/22300 (epoch 6.332), train_loss = 1.27655496, grad/param norm = 2.6325e-01, time/batch = 0.6652s	
2825/22300 (epoch 6.334), train_loss = 1.27017988, grad/param norm = 2.4431e-01, time/batch = 0.6861s	
2826/22300 (epoch 6.336), train_loss = 1.36568970, grad/param norm = 2.4055e-01, time/batch = 0.6735s	
2827/22300 (epoch 6.339), train_loss = 1.46186888, grad/param norm = 2.6255e-01, time/batch = 0.6772s	
2828/22300 (epoch 6.341), train_loss = 1.47373264, grad/param norm = 2.5308e-01, time/batch = 0.6724s	
2829/22300 (epoch 6.343), train_loss = 1.49468772, grad/param norm = 2.6686e-01, time/batch = 0.6709s	
2830/22300 (epoch 6.345), train_loss = 1.43232012, grad/param norm = 2.6364e-01, time/batch = 0.6682s	
2831/22300 (epoch 6.348), train_loss = 1.35536197, grad/param norm = 2.3077e-01, time/batch = 0.6722s	
2832/22300 (epoch 6.350), train_loss = 1.26712357, grad/param norm = 2.3808e-01, time/batch = 0.6724s	
2833/22300 (epoch 6.352), train_loss = 1.46898237, grad/param norm = 2.3436e-01, time/batch = 0.6676s	
2834/22300 (epoch 6.354), train_loss = 1.52301652, grad/param norm = 2.6427e-01, time/batch = 0.6639s	
2835/22300 (epoch 6.357), train_loss = 1.54286509, grad/param norm = 2.8770e-01, time/batch = 0.6622s	
2836/22300 (epoch 6.359), train_loss = 1.42921435, grad/param norm = 2.5049e-01, time/batch = 0.6580s	
2837/22300 (epoch 6.361), train_loss = 1.51316393, grad/param norm = 2.6294e-01, time/batch = 0.6599s	
2838/22300 (epoch 6.363), train_loss = 1.60230314, grad/param norm = 2.6799e-01, time/batch = 0.6579s	
2839/22300 (epoch 6.365), train_loss = 1.48183957, grad/param norm = 2.4593e-01, time/batch = 0.6625s	
2840/22300 (epoch 6.368), train_loss = 1.50343786, grad/param norm = 2.6757e-01, time/batch = 0.6686s	
2841/22300 (epoch 6.370), train_loss = 1.45496453, grad/param norm = 2.5827e-01, time/batch = 0.6659s	
2842/22300 (epoch 6.372), train_loss = 1.31448189, grad/param norm = 2.9029e-01, time/batch = 0.6678s	
2843/22300 (epoch 6.374), train_loss = 1.26250683, grad/param norm = 2.3653e-01, time/batch = 0.6650s	
2844/22300 (epoch 6.377), train_loss = 1.46187531, grad/param norm = 2.5718e-01, time/batch = 0.6672s	
2845/22300 (epoch 6.379), train_loss = 1.40822661, grad/param norm = 2.5709e-01, time/batch = 0.6659s	
2846/22300 (epoch 6.381), train_loss = 1.51587245, grad/param norm = 2.5629e-01, time/batch = 0.6646s	
2847/22300 (epoch 6.383), train_loss = 1.31282479, grad/param norm = 2.5974e-01, time/batch = 0.6661s	
2848/22300 (epoch 6.386), train_loss = 1.41107710, grad/param norm = 2.6855e-01, time/batch = 0.6622s	
2849/22300 (epoch 6.388), train_loss = 1.32924671, grad/param norm = 2.2467e-01, time/batch = 0.6606s	
2850/22300 (epoch 6.390), train_loss = 1.36874942, grad/param norm = 2.3945e-01, time/batch = 0.6607s	
2851/22300 (epoch 6.392), train_loss = 1.38896593, grad/param norm = 2.3800e-01, time/batch = 0.6664s	
2852/22300 (epoch 6.395), train_loss = 1.32561745, grad/param norm = 2.5107e-01, time/batch = 0.6564s	
2853/22300 (epoch 6.397), train_loss = 1.14994386, grad/param norm = 2.2200e-01, time/batch = 0.6668s	
2854/22300 (epoch 6.399), train_loss = 1.35151677, grad/param norm = 2.5428e-01, time/batch = 0.6751s	
2855/22300 (epoch 6.401), train_loss = 1.34241706, grad/param norm = 2.6109e-01, time/batch = 0.6750s	
2856/22300 (epoch 6.404), train_loss = 1.35214831, grad/param norm = 2.4566e-01, time/batch = 0.6751s	
2857/22300 (epoch 6.406), train_loss = 1.62116724, grad/param norm = 2.7143e-01, time/batch = 0.6759s	
2858/22300 (epoch 6.408), train_loss = 1.41366136, grad/param norm = 2.6674e-01, time/batch = 0.6742s	
2859/22300 (epoch 6.410), train_loss = 1.43470810, grad/param norm = 2.6233e-01, time/batch = 0.6824s	
2860/22300 (epoch 6.413), train_loss = 1.40866676, grad/param norm = 2.6375e-01, time/batch = 0.6822s	
2861/22300 (epoch 6.415), train_loss = 1.31225320, grad/param norm = 2.4798e-01, time/batch = 0.6766s	
2862/22300 (epoch 6.417), train_loss = 1.45356831, grad/param norm = 2.3697e-01, time/batch = 0.6754s	
2863/22300 (epoch 6.419), train_loss = 1.32988827, grad/param norm = 2.3844e-01, time/batch = 0.6734s	
2864/22300 (epoch 6.422), train_loss = 1.40175906, grad/param norm = 2.3454e-01, time/batch = 0.6641s	
2865/22300 (epoch 6.424), train_loss = 1.47012885, grad/param norm = 2.6855e-01, time/batch = 0.6671s	
2866/22300 (epoch 6.426), train_loss = 1.33955578, grad/param norm = 2.4834e-01, time/batch = 0.6649s	
2867/22300 (epoch 6.428), train_loss = 1.43150752, grad/param norm = 2.3754e-01, time/batch = 0.6673s	
2868/22300 (epoch 6.430), train_loss = 1.41521493, grad/param norm = 2.5060e-01, time/batch = 0.6592s	
2869/22300 (epoch 6.433), train_loss = 1.38867123, grad/param norm = 2.2795e-01, time/batch = 0.6591s	
2870/22300 (epoch 6.435), train_loss = 1.47666919, grad/param norm = 2.4475e-01, time/batch = 0.6584s	
2871/22300 (epoch 6.437), train_loss = 1.34367470, grad/param norm = 2.6761e-01, time/batch = 0.6637s	
2872/22300 (epoch 6.439), train_loss = 1.33668510, grad/param norm = 2.4015e-01, time/batch = 0.6662s	
2873/22300 (epoch 6.442), train_loss = 1.42562618, grad/param norm = 2.5162e-01, time/batch = 0.6644s	
2874/22300 (epoch 6.444), train_loss = 1.36253231, grad/param norm = 2.1875e-01, time/batch = 0.6601s	
2875/22300 (epoch 6.446), train_loss = 1.27556093, grad/param norm = 2.5045e-01, time/batch = 0.6599s	
2876/22300 (epoch 6.448), train_loss = 1.15775003, grad/param norm = 2.1628e-01, time/batch = 0.6637s	
2877/22300 (epoch 6.451), train_loss = 1.54601449, grad/param norm = 2.6979e-01, time/batch = 0.6669s	
2878/22300 (epoch 6.453), train_loss = 1.32933672, grad/param norm = 2.5360e-01, time/batch = 0.6599s	
2879/22300 (epoch 6.455), train_loss = 1.49130100, grad/param norm = 2.4863e-01, time/batch = 0.6603s	
2880/22300 (epoch 6.457), train_loss = 1.39778604, grad/param norm = 2.4686e-01, time/batch = 0.6600s	
2881/22300 (epoch 6.460), train_loss = 1.36235678, grad/param norm = 2.5810e-01, time/batch = 0.6598s	
2882/22300 (epoch 6.462), train_loss = 1.42522787, grad/param norm = 2.4376e-01, time/batch = 0.6577s	
2883/22300 (epoch 6.464), train_loss = 1.39066485, grad/param norm = 2.6112e-01, time/batch = 0.6566s	
2884/22300 (epoch 6.466), train_loss = 1.39654728, grad/param norm = 2.6273e-01, time/batch = 0.6577s	
2885/22300 (epoch 6.469), train_loss = 1.34510010, grad/param norm = 2.7125e-01, time/batch = 0.6557s	
2886/22300 (epoch 6.471), train_loss = 1.47364101, grad/param norm = 2.6523e-01, time/batch = 0.6595s	
2887/22300 (epoch 6.473), train_loss = 1.51546617, grad/param norm = 2.4973e-01, time/batch = 0.6589s	
2888/22300 (epoch 6.475), train_loss = 1.37736611, grad/param norm = 2.6165e-01, time/batch = 0.6756s	
2889/22300 (epoch 6.478), train_loss = 1.30619710, grad/param norm = 2.6677e-01, time/batch = 0.6722s	
2890/22300 (epoch 6.480), train_loss = 1.26577340, grad/param norm = 2.7219e-01, time/batch = 0.6758s	
2891/22300 (epoch 6.482), train_loss = 1.28581283, grad/param norm = 2.4099e-01, time/batch = 0.6663s	
2892/22300 (epoch 6.484), train_loss = 1.27977343, grad/param norm = 2.2151e-01, time/batch = 0.6638s	
2893/22300 (epoch 6.487), train_loss = 1.30556172, grad/param norm = 2.2618e-01, time/batch = 0.6570s	
2894/22300 (epoch 6.489), train_loss = 1.46745811, grad/param norm = 2.3697e-01, time/batch = 0.6590s	
2895/22300 (epoch 6.491), train_loss = 1.32275851, grad/param norm = 2.2589e-01, time/batch = 0.6640s	
2896/22300 (epoch 6.493), train_loss = 1.49665236, grad/param norm = 2.6313e-01, time/batch = 0.6709s	
2897/22300 (epoch 6.496), train_loss = 1.36858047, grad/param norm = 2.4823e-01, time/batch = 0.6695s	
2898/22300 (epoch 6.498), train_loss = 1.36692035, grad/param norm = 2.5402e-01, time/batch = 0.6711s	
2899/22300 (epoch 6.500), train_loss = 1.33269536, grad/param norm = 2.3030e-01, time/batch = 0.6645s	
2900/22300 (epoch 6.502), train_loss = 1.29628721, grad/param norm = 2.5494e-01, time/batch = 0.6596s	
2901/22300 (epoch 6.504), train_loss = 1.30759340, grad/param norm = 2.4731e-01, time/batch = 0.6584s	
2902/22300 (epoch 6.507), train_loss = 1.33573366, grad/param norm = 2.2360e-01, time/batch = 0.6651s	
2903/22300 (epoch 6.509), train_loss = 1.48545060, grad/param norm = 2.7026e-01, time/batch = 0.6658s	
2904/22300 (epoch 6.511), train_loss = 1.21622588, grad/param norm = 3.0527e-01, time/batch = 0.6609s	
2905/22300 (epoch 6.513), train_loss = 1.21437437, grad/param norm = 2.4808e-01, time/batch = 0.6606s	
2906/22300 (epoch 6.516), train_loss = 1.39496564, grad/param norm = 2.4382e-01, time/batch = 0.6605s	
2907/22300 (epoch 6.518), train_loss = 1.37891352, grad/param norm = 2.4242e-01, time/batch = 0.6656s	
2908/22300 (epoch 6.520), train_loss = 1.41591899, grad/param norm = 2.5519e-01, time/batch = 0.6597s	
2909/22300 (epoch 6.522), train_loss = 1.27750786, grad/param norm = 2.3583e-01, time/batch = 0.6739s	
2910/22300 (epoch 6.525), train_loss = 1.28177441, grad/param norm = 2.5232e-01, time/batch = 0.6666s	
2911/22300 (epoch 6.527), train_loss = 1.49718046, grad/param norm = 2.5876e-01, time/batch = 0.6645s	
2912/22300 (epoch 6.529), train_loss = 1.34046158, grad/param norm = 2.6283e-01, time/batch = 0.6633s	
2913/22300 (epoch 6.531), train_loss = 1.34617955, grad/param norm = 2.3401e-01, time/batch = 0.6570s	
2914/22300 (epoch 6.534), train_loss = 1.24712809, grad/param norm = 2.3575e-01, time/batch = 0.6600s	
2915/22300 (epoch 6.536), train_loss = 1.50581300, grad/param norm = 2.5183e-01, time/batch = 0.6570s	
2916/22300 (epoch 6.538), train_loss = 1.69213489, grad/param norm = 2.8684e-01, time/batch = 0.6578s	
2917/22300 (epoch 6.540), train_loss = 1.45808027, grad/param norm = 2.6635e-01, time/batch = 0.6655s	
2918/22300 (epoch 6.543), train_loss = 1.25767575, grad/param norm = 2.2800e-01, time/batch = 0.6625s	
2919/22300 (epoch 6.545), train_loss = 1.34835320, grad/param norm = 2.4997e-01, time/batch = 0.6682s	
2920/22300 (epoch 6.547), train_loss = 1.26881262, grad/param norm = 2.3621e-01, time/batch = 0.6631s	
2921/22300 (epoch 6.549), train_loss = 1.33084850, grad/param norm = 2.3820e-01, time/batch = 0.6660s	
2922/22300 (epoch 6.552), train_loss = 1.25460943, grad/param norm = 2.4672e-01, time/batch = 0.6685s	
2923/22300 (epoch 6.554), train_loss = 1.33164482, grad/param norm = 2.8633e-01, time/batch = 0.6601s	
2924/22300 (epoch 6.556), train_loss = 1.46589594, grad/param norm = 2.4087e-01, time/batch = 0.6629s	
2925/22300 (epoch 6.558), train_loss = 1.32567841, grad/param norm = 2.3554e-01, time/batch = 0.6625s	
2926/22300 (epoch 6.561), train_loss = 1.54515179, grad/param norm = 2.9207e-01, time/batch = 0.6585s	
2927/22300 (epoch 6.563), train_loss = 1.34577913, grad/param norm = 2.6109e-01, time/batch = 0.6622s	
2928/22300 (epoch 6.565), train_loss = 1.37577257, grad/param norm = 2.5218e-01, time/batch = 0.6698s	
2929/22300 (epoch 6.567), train_loss = 1.39151503, grad/param norm = 2.5353e-01, time/batch = 0.6613s	
2930/22300 (epoch 6.570), train_loss = 1.58624833, grad/param norm = 2.6960e-01, time/batch = 0.6719s	
2931/22300 (epoch 6.572), train_loss = 1.45289464, grad/param norm = 2.8865e-01, time/batch = 0.6607s	
2932/22300 (epoch 6.574), train_loss = 1.28867903, grad/param norm = 2.1242e-01, time/batch = 0.6740s	
2933/22300 (epoch 6.576), train_loss = 1.16749586, grad/param norm = 2.1453e-01, time/batch = 0.6623s	
2934/22300 (epoch 6.578), train_loss = 1.11174461, grad/param norm = 2.1548e-01, time/batch = 0.6648s	
2935/22300 (epoch 6.581), train_loss = 1.21629194, grad/param norm = 2.1285e-01, time/batch = 0.6668s	
2936/22300 (epoch 6.583), train_loss = 1.25921166, grad/param norm = 2.3177e-01, time/batch = 0.6661s	
2937/22300 (epoch 6.585), train_loss = 1.46208950, grad/param norm = 2.5058e-01, time/batch = 0.6687s	
2938/22300 (epoch 6.587), train_loss = 1.53629007, grad/param norm = 2.9848e-01, time/batch = 0.6587s	
2939/22300 (epoch 6.590), train_loss = 1.44666362, grad/param norm = 2.6224e-01, time/batch = 0.6602s	
2940/22300 (epoch 6.592), train_loss = 1.57851078, grad/param norm = 2.7489e-01, time/batch = 0.6606s	
2941/22300 (epoch 6.594), train_loss = 1.48725032, grad/param norm = 2.5190e-01, time/batch = 0.6703s	
2942/22300 (epoch 6.596), train_loss = 1.32567126, grad/param norm = 2.9371e-01, time/batch = 0.6887s	
2943/22300 (epoch 6.599), train_loss = 1.16722504, grad/param norm = 2.2832e-01, time/batch = 0.6799s	
2944/22300 (epoch 6.601), train_loss = 1.37885476, grad/param norm = 2.7134e-01, time/batch = 0.6775s	
2945/22300 (epoch 6.603), train_loss = 1.39263194, grad/param norm = 2.4978e-01, time/batch = 0.6696s	
2946/22300 (epoch 6.605), train_loss = 1.30206024, grad/param norm = 2.4835e-01, time/batch = 0.6630s	
2947/22300 (epoch 6.608), train_loss = 1.52586231, grad/param norm = 2.7453e-01, time/batch = 0.6699s	
2948/22300 (epoch 6.610), train_loss = 1.59493447, grad/param norm = 2.7083e-01, time/batch = 0.6690s	
2949/22300 (epoch 6.612), train_loss = 1.50077545, grad/param norm = 2.8693e-01, time/batch = 0.6709s	
2950/22300 (epoch 6.614), train_loss = 1.46459805, grad/param norm = 2.8149e-01, time/batch = 0.6607s	
2951/22300 (epoch 6.617), train_loss = 1.47316336, grad/param norm = 2.6484e-01, time/batch = 0.6685s	
2952/22300 (epoch 6.619), train_loss = 1.72356754, grad/param norm = 2.6309e-01, time/batch = 0.6642s	
2953/22300 (epoch 6.621), train_loss = 1.27704353, grad/param norm = 2.5066e-01, time/batch = 0.6601s	
2954/22300 (epoch 6.623), train_loss = 1.35107294, grad/param norm = 2.5596e-01, time/batch = 0.6621s	
2955/22300 (epoch 6.626), train_loss = 1.26234705, grad/param norm = 2.2398e-01, time/batch = 0.6643s	
2956/22300 (epoch 6.628), train_loss = 1.26195408, grad/param norm = 2.5964e-01, time/batch = 0.6589s	
2957/22300 (epoch 6.630), train_loss = 1.35499891, grad/param norm = 2.5712e-01, time/batch = 0.6696s	
2958/22300 (epoch 6.632), train_loss = 1.39088965, grad/param norm = 2.6185e-01, time/batch = 0.6692s	
2959/22300 (epoch 6.635), train_loss = 1.27988510, grad/param norm = 2.3190e-01, time/batch = 0.6604s	
2960/22300 (epoch 6.637), train_loss = 1.49670060, grad/param norm = 2.6953e-01, time/batch = 0.6578s	
2961/22300 (epoch 6.639), train_loss = 1.46973441, grad/param norm = 2.8168e-01, time/batch = 0.6599s	
2962/22300 (epoch 6.641), train_loss = 1.41040157, grad/param norm = 2.5489e-01, time/batch = 0.6674s	
2963/22300 (epoch 6.643), train_loss = 1.38620449, grad/param norm = 2.4690e-01, time/batch = 0.6601s	
2964/22300 (epoch 6.646), train_loss = 1.28880042, grad/param norm = 2.4678e-01, time/batch = 0.6573s	
2965/22300 (epoch 6.648), train_loss = 1.26834161, grad/param norm = 2.2608e-01, time/batch = 0.6617s	
2966/22300 (epoch 6.650), train_loss = 1.49204374, grad/param norm = 2.5298e-01, time/batch = 0.6642s	
2967/22300 (epoch 6.652), train_loss = 1.33791802, grad/param norm = 2.3406e-01, time/batch = 0.6672s	
2968/22300 (epoch 6.655), train_loss = 1.47364380, grad/param norm = 2.7527e-01, time/batch = 0.6544s	
2969/22300 (epoch 6.657), train_loss = 1.41633832, grad/param norm = 2.6470e-01, time/batch = 0.6568s	
2970/22300 (epoch 6.659), train_loss = 1.27006947, grad/param norm = 2.3356e-01, time/batch = 0.6636s	
2971/22300 (epoch 6.661), train_loss = 1.20466278, grad/param norm = 2.3079e-01, time/batch = 0.6614s	
2972/22300 (epoch 6.664), train_loss = 1.34282624, grad/param norm = 2.4987e-01, time/batch = 0.6602s	
2973/22300 (epoch 6.666), train_loss = 1.41619569, grad/param norm = 2.3420e-01, time/batch = 0.6596s	
2974/22300 (epoch 6.668), train_loss = 1.31751961, grad/param norm = 2.4792e-01, time/batch = 0.6655s	
2975/22300 (epoch 6.670), train_loss = 1.47074229, grad/param norm = 2.4914e-01, time/batch = 0.6625s	
2976/22300 (epoch 6.673), train_loss = 1.41542359, grad/param norm = 2.5620e-01, time/batch = 0.6616s	
2977/22300 (epoch 6.675), train_loss = 1.51995255, grad/param norm = 2.7281e-01, time/batch = 0.6721s	
2978/22300 (epoch 6.677), train_loss = 1.56467759, grad/param norm = 2.7510e-01, time/batch = 0.6733s	
2979/22300 (epoch 6.679), train_loss = 1.51381293, grad/param norm = 2.7801e-01, time/batch = 0.6673s	
2980/22300 (epoch 6.682), train_loss = 1.46339912, grad/param norm = 2.5861e-01, time/batch = 0.6724s	
2981/22300 (epoch 6.684), train_loss = 1.40619265, grad/param norm = 2.4967e-01, time/batch = 0.6798s	
2982/22300 (epoch 6.686), train_loss = 1.49800963, grad/param norm = 3.0309e-01, time/batch = 0.6770s	
2983/22300 (epoch 6.688), train_loss = 1.49519374, grad/param norm = 2.5776e-01, time/batch = 0.6772s	
2984/22300 (epoch 6.691), train_loss = 1.37327395, grad/param norm = 2.5869e-01, time/batch = 0.6745s	
2985/22300 (epoch 6.693), train_loss = 1.40953064, grad/param norm = 2.5280e-01, time/batch = 0.6673s	
2986/22300 (epoch 6.695), train_loss = 1.22231767, grad/param norm = 2.4853e-01, time/batch = 0.6695s	
2987/22300 (epoch 6.697), train_loss = 1.14224597, grad/param norm = 2.2942e-01, time/batch = 0.6693s	
2988/22300 (epoch 6.700), train_loss = 1.34709433, grad/param norm = 2.5456e-01, time/batch = 0.6731s	
2989/22300 (epoch 6.702), train_loss = 1.43705029, grad/param norm = 2.7170e-01, time/batch = 0.6708s	
2990/22300 (epoch 6.704), train_loss = 1.46372120, grad/param norm = 2.4619e-01, time/batch = 0.6733s	
2991/22300 (epoch 6.706), train_loss = 1.24731003, grad/param norm = 2.2684e-01, time/batch = 0.6757s	
2992/22300 (epoch 6.709), train_loss = 1.20314723, grad/param norm = 2.3155e-01, time/batch = 0.6745s	
2993/22300 (epoch 6.711), train_loss = 1.34529806, grad/param norm = 2.3019e-01, time/batch = 0.6736s	
2994/22300 (epoch 6.713), train_loss = 1.39657319, grad/param norm = 2.5141e-01, time/batch = 0.6756s	
2995/22300 (epoch 6.715), train_loss = 1.41258848, grad/param norm = 2.6555e-01, time/batch = 0.6725s	
2996/22300 (epoch 6.717), train_loss = 1.60653978, grad/param norm = 2.7297e-01, time/batch = 0.6751s	
2997/22300 (epoch 6.720), train_loss = 1.36495066, grad/param norm = 2.6139e-01, time/batch = 0.6749s	
2998/22300 (epoch 6.722), train_loss = 1.41143061, grad/param norm = 2.7498e-01, time/batch = 0.6721s	
2999/22300 (epoch 6.724), train_loss = 1.44384536, grad/param norm = 2.7100e-01, time/batch = 0.6628s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch6.73_1.6958.t7	
3000/22300 (epoch 6.726), train_loss = 1.37497747, grad/param norm = 2.6034e-01, time/batch = 0.6617s	
3001/22300 (epoch 6.729), train_loss = 1.61335243, grad/param norm = 2.8651e-01, time/batch = 0.6686s	
3002/22300 (epoch 6.731), train_loss = 1.50397534, grad/param norm = 2.7074e-01, time/batch = 0.6714s	
3003/22300 (epoch 6.733), train_loss = 1.55092756, grad/param norm = 2.8668e-01, time/batch = 0.6655s	
3004/22300 (epoch 6.735), train_loss = 1.48178376, grad/param norm = 2.8045e-01, time/batch = 0.6731s	
3005/22300 (epoch 6.738), train_loss = 1.43815288, grad/param norm = 2.5442e-01, time/batch = 0.6637s	
3006/22300 (epoch 6.740), train_loss = 1.14542797, grad/param norm = 2.1521e-01, time/batch = 0.6645s	
3007/22300 (epoch 6.742), train_loss = 1.36991516, grad/param norm = 2.2991e-01, time/batch = 0.6741s	
3008/22300 (epoch 6.744), train_loss = 1.52992991, grad/param norm = 2.7392e-01, time/batch = 0.6743s	
3009/22300 (epoch 6.747), train_loss = 1.34774649, grad/param norm = 2.7098e-01, time/batch = 0.6673s	
3010/22300 (epoch 6.749), train_loss = 1.71292866, grad/param norm = 2.7306e-01, time/batch = 0.6653s	
3011/22300 (epoch 6.751), train_loss = 1.52481139, grad/param norm = 2.5454e-01, time/batch = 0.6612s	
3012/22300 (epoch 6.753), train_loss = 1.52160742, grad/param norm = 2.7565e-01, time/batch = 0.6654s	
3013/22300 (epoch 6.756), train_loss = 1.38171987, grad/param norm = 2.3583e-01, time/batch = 0.6637s	
3014/22300 (epoch 6.758), train_loss = 1.32187072, grad/param norm = 2.2634e-01, time/batch = 0.6596s	
3015/22300 (epoch 6.760), train_loss = 1.41157909, grad/param norm = 2.5043e-01, time/batch = 0.6646s	
3016/22300 (epoch 6.762), train_loss = 1.41889826, grad/param norm = 2.9361e-01, time/batch = 0.6740s	
3017/22300 (epoch 6.765), train_loss = 1.44766641, grad/param norm = 2.4173e-01, time/batch = 0.6779s	
3018/22300 (epoch 6.767), train_loss = 1.50105799, grad/param norm = 2.6936e-01, time/batch = 0.6760s	
3019/22300 (epoch 6.769), train_loss = 1.35876312, grad/param norm = 2.5082e-01, time/batch = 0.6837s	
3020/22300 (epoch 6.771), train_loss = 1.40133747, grad/param norm = 2.7112e-01, time/batch = 0.7005s	
3021/22300 (epoch 6.774), train_loss = 1.46428253, grad/param norm = 2.5133e-01, time/batch = 0.6875s	
3022/22300 (epoch 6.776), train_loss = 1.35190639, grad/param norm = 2.3377e-01, time/batch = 0.6792s	
3023/22300 (epoch 6.778), train_loss = 1.55182335, grad/param norm = 2.5873e-01, time/batch = 0.6830s	
3024/22300 (epoch 6.780), train_loss = 1.50421521, grad/param norm = 2.2916e-01, time/batch = 0.6779s	
3025/22300 (epoch 6.783), train_loss = 1.51810770, grad/param norm = 2.5321e-01, time/batch = 0.6596s	
3026/22300 (epoch 6.785), train_loss = 1.32051670, grad/param norm = 2.5863e-01, time/batch = 0.6671s	
3027/22300 (epoch 6.787), train_loss = 1.34214663, grad/param norm = 2.4502e-01, time/batch = 0.6804s	
3028/22300 (epoch 6.789), train_loss = 1.47284875, grad/param norm = 2.5930e-01, time/batch = 0.6753s	
3029/22300 (epoch 6.791), train_loss = 1.56212614, grad/param norm = 2.6893e-01, time/batch = 0.6614s	
3030/22300 (epoch 6.794), train_loss = 1.49386414, grad/param norm = 2.7261e-01, time/batch = 0.6676s	
3031/22300 (epoch 6.796), train_loss = 1.53696529, grad/param norm = 2.7647e-01, time/batch = 0.6705s	
3032/22300 (epoch 6.798), train_loss = 1.47445815, grad/param norm = 2.5445e-01, time/batch = 0.6723s	
3033/22300 (epoch 6.800), train_loss = 1.23890033, grad/param norm = 2.2643e-01, time/batch = 0.6781s	
3034/22300 (epoch 6.803), train_loss = 1.24732723, grad/param norm = 2.1979e-01, time/batch = 0.6654s	
3035/22300 (epoch 6.805), train_loss = 1.38578699, grad/param norm = 2.3064e-01, time/batch = 0.6658s	
3036/22300 (epoch 6.807), train_loss = 1.45629998, grad/param norm = 2.6047e-01, time/batch = 0.6610s	
3037/22300 (epoch 6.809), train_loss = 1.45695530, grad/param norm = 2.7141e-01, time/batch = 0.6787s	
3038/22300 (epoch 6.812), train_loss = 1.53899131, grad/param norm = 3.0449e-01, time/batch = 0.6658s	
3039/22300 (epoch 6.814), train_loss = 1.41526670, grad/param norm = 2.4005e-01, time/batch = 0.6732s	
3040/22300 (epoch 6.816), train_loss = 1.50189567, grad/param norm = 2.6145e-01, time/batch = 0.6781s	
3041/22300 (epoch 6.818), train_loss = 1.45925516, grad/param norm = 2.6306e-01, time/batch = 0.6766s	
3042/22300 (epoch 6.821), train_loss = 1.56478127, grad/param norm = 2.4959e-01, time/batch = 0.6713s	
3043/22300 (epoch 6.823), train_loss = 1.30843121, grad/param norm = 2.2465e-01, time/batch = 0.6644s	
3044/22300 (epoch 6.825), train_loss = 1.38154723, grad/param norm = 2.5207e-01, time/batch = 0.6644s	
3045/22300 (epoch 6.827), train_loss = 1.42088657, grad/param norm = 2.5476e-01, time/batch = 0.6748s	
3046/22300 (epoch 6.830), train_loss = 1.35784574, grad/param norm = 2.8468e-01, time/batch = 0.6750s	
3047/22300 (epoch 6.832), train_loss = 1.29651203, grad/param norm = 2.5988e-01, time/batch = 0.6726s	
3048/22300 (epoch 6.834), train_loss = 1.44438411, grad/param norm = 2.5736e-01, time/batch = 0.6740s	
3049/22300 (epoch 6.836), train_loss = 1.38269301, grad/param norm = 2.4041e-01, time/batch = 0.6668s	
3050/22300 (epoch 6.839), train_loss = 1.39087764, grad/param norm = 2.1657e-01, time/batch = 0.6635s	
3051/22300 (epoch 6.841), train_loss = 1.36619598, grad/param norm = 2.5264e-01, time/batch = 0.6823s	
3052/22300 (epoch 6.843), train_loss = 1.39357724, grad/param norm = 2.7162e-01, time/batch = 0.6663s	
3053/22300 (epoch 6.845), train_loss = 1.36124300, grad/param norm = 2.2801e-01, time/batch = 0.6585s	
3054/22300 (epoch 6.848), train_loss = 1.36271898, grad/param norm = 2.3942e-01, time/batch = 0.6596s	
3055/22300 (epoch 6.850), train_loss = 1.41637700, grad/param norm = 2.3948e-01, time/batch = 0.6587s	
3056/22300 (epoch 6.852), train_loss = 1.43618032, grad/param norm = 2.6163e-01, time/batch = 0.6597s	
3057/22300 (epoch 6.854), train_loss = 1.57134012, grad/param norm = 2.7791e-01, time/batch = 0.6610s	
3058/22300 (epoch 6.857), train_loss = 1.34525189, grad/param norm = 2.6962e-01, time/batch = 0.6615s	
3059/22300 (epoch 6.859), train_loss = 1.24338656, grad/param norm = 2.3553e-01, time/batch = 0.6611s	
3060/22300 (epoch 6.861), train_loss = 1.37854199, grad/param norm = 2.3023e-01, time/batch = 0.6624s	
3061/22300 (epoch 6.863), train_loss = 1.24314364, grad/param norm = 2.2811e-01, time/batch = 0.6652s	
3062/22300 (epoch 6.865), train_loss = 1.29277671, grad/param norm = 2.6197e-01, time/batch = 0.6723s	
3063/22300 (epoch 6.868), train_loss = 1.32609553, grad/param norm = 2.3616e-01, time/batch = 0.6872s	
3064/22300 (epoch 6.870), train_loss = 1.35916730, grad/param norm = 2.4470e-01, time/batch = 0.6835s	
3065/22300 (epoch 6.872), train_loss = 1.44121837, grad/param norm = 2.4826e-01, time/batch = 0.6800s	
3066/22300 (epoch 6.874), train_loss = 1.42345013, grad/param norm = 2.6148e-01, time/batch = 0.6802s	
3067/22300 (epoch 6.877), train_loss = 1.35793381, grad/param norm = 2.3902e-01, time/batch = 0.6818s	
3068/22300 (epoch 6.879), train_loss = 1.22796807, grad/param norm = 2.2766e-01, time/batch = 0.6809s	
3069/22300 (epoch 6.881), train_loss = 1.35452480, grad/param norm = 3.0024e-01, time/batch = 0.6801s	
3070/22300 (epoch 6.883), train_loss = 1.36697609, grad/param norm = 2.7934e-01, time/batch = 0.6780s	
3071/22300 (epoch 6.886), train_loss = 1.34732624, grad/param norm = 2.1933e-01, time/batch = 0.6827s	
3072/22300 (epoch 6.888), train_loss = 1.32151642, grad/param norm = 2.3186e-01, time/batch = 0.6763s	
3073/22300 (epoch 6.890), train_loss = 1.22552174, grad/param norm = 2.1816e-01, time/batch = 0.6684s	
3074/22300 (epoch 6.892), train_loss = 1.49538278, grad/param norm = 2.6346e-01, time/batch = 0.6765s	
3075/22300 (epoch 6.895), train_loss = 1.49594742, grad/param norm = 2.7732e-01, time/batch = 0.6771s	
3076/22300 (epoch 6.897), train_loss = 1.42793978, grad/param norm = 2.7154e-01, time/batch = 0.6788s	
3077/22300 (epoch 6.899), train_loss = 1.38803625, grad/param norm = 2.2605e-01, time/batch = 0.6647s	
3078/22300 (epoch 6.901), train_loss = 1.30776750, grad/param norm = 2.4102e-01, time/batch = 0.6772s	
3079/22300 (epoch 6.904), train_loss = 1.33705178, grad/param norm = 2.6747e-01, time/batch = 0.6781s	
3080/22300 (epoch 6.906), train_loss = 1.48511719, grad/param norm = 2.5929e-01, time/batch = 0.6631s	
3081/22300 (epoch 6.908), train_loss = 1.40224933, grad/param norm = 2.6863e-01, time/batch = 0.6670s	
3082/22300 (epoch 6.910), train_loss = 1.25811783, grad/param norm = 2.3523e-01, time/batch = 0.6757s	
3083/22300 (epoch 6.913), train_loss = 1.35771780, grad/param norm = 2.4103e-01, time/batch = 0.6730s	
3084/22300 (epoch 6.915), train_loss = 1.55465324, grad/param norm = 2.7546e-01, time/batch = 0.6726s	
3085/22300 (epoch 6.917), train_loss = 1.34740174, grad/param norm = 2.7484e-01, time/batch = 0.6684s	
3086/22300 (epoch 6.919), train_loss = 1.40585296, grad/param norm = 2.7257e-01, time/batch = 0.6751s	
3087/22300 (epoch 6.922), train_loss = 1.42573273, grad/param norm = 2.6788e-01, time/batch = 0.6724s	
3088/22300 (epoch 6.924), train_loss = 1.20964698, grad/param norm = 2.0857e-01, time/batch = 0.6769s	
3089/22300 (epoch 6.926), train_loss = 1.17761384, grad/param norm = 2.3188e-01, time/batch = 0.6771s	
3090/22300 (epoch 6.928), train_loss = 1.38820994, grad/param norm = 2.4765e-01, time/batch = 0.6672s	
3091/22300 (epoch 6.930), train_loss = 1.39347945, grad/param norm = 2.5421e-01, time/batch = 0.6780s	
3092/22300 (epoch 6.933), train_loss = 1.39925073, grad/param norm = 2.6132e-01, time/batch = 0.6767s	
3093/22300 (epoch 6.935), train_loss = 1.52839717, grad/param norm = 2.6996e-01, time/batch = 0.6767s	
3094/22300 (epoch 6.937), train_loss = 1.46365648, grad/param norm = 2.5621e-01, time/batch = 0.6774s	
3095/22300 (epoch 6.939), train_loss = 1.50500006, grad/param norm = 2.5898e-01, time/batch = 0.6814s	
3096/22300 (epoch 6.942), train_loss = 1.53363494, grad/param norm = 2.5535e-01, time/batch = 0.6646s	
3097/22300 (epoch 6.944), train_loss = 1.62529948, grad/param norm = 2.9147e-01, time/batch = 0.6629s	
3098/22300 (epoch 6.946), train_loss = 1.33327017, grad/param norm = 2.5708e-01, time/batch = 0.6579s	
3099/22300 (epoch 6.948), train_loss = 1.33910992, grad/param norm = 2.2024e-01, time/batch = 0.6725s	
3100/22300 (epoch 6.951), train_loss = 1.22123337, grad/param norm = 2.1562e-01, time/batch = 0.6745s	
3101/22300 (epoch 6.953), train_loss = 1.31305466, grad/param norm = 2.5002e-01, time/batch = 0.6657s	
3102/22300 (epoch 6.955), train_loss = 1.60551669, grad/param norm = 2.6592e-01, time/batch = 0.6690s	
3103/22300 (epoch 6.957), train_loss = 1.59546077, grad/param norm = 2.5949e-01, time/batch = 0.6688s	
3104/22300 (epoch 6.960), train_loss = 1.53898342, grad/param norm = 2.9009e-01, time/batch = 0.6685s	
3105/22300 (epoch 6.962), train_loss = 1.44102396, grad/param norm = 2.3492e-01, time/batch = 0.6621s	
3106/22300 (epoch 6.964), train_loss = 1.41005195, grad/param norm = 2.5659e-01, time/batch = 0.6621s	
3107/22300 (epoch 6.966), train_loss = 1.35476706, grad/param norm = 2.3979e-01, time/batch = 0.6630s	
3108/22300 (epoch 6.969), train_loss = 1.26413589, grad/param norm = 2.1061e-01, time/batch = 0.6698s	
3109/22300 (epoch 6.971), train_loss = 1.34686903, grad/param norm = 2.6417e-01, time/batch = 0.6703s	
3110/22300 (epoch 6.973), train_loss = 1.36993633, grad/param norm = 2.5556e-01, time/batch = 0.6650s	
3111/22300 (epoch 6.975), train_loss = 1.64146615, grad/param norm = 2.4881e-01, time/batch = 0.6670s	
3112/22300 (epoch 6.978), train_loss = 1.31479918, grad/param norm = 2.2361e-01, time/batch = 0.6640s	
3113/22300 (epoch 6.980), train_loss = 1.42863162, grad/param norm = 2.5139e-01, time/batch = 0.6728s	
3114/22300 (epoch 6.982), train_loss = 1.26527578, grad/param norm = 2.2890e-01, time/batch = 0.6623s	
3115/22300 (epoch 6.984), train_loss = 1.43802175, grad/param norm = 2.4954e-01, time/batch = 0.6640s	
3116/22300 (epoch 6.987), train_loss = 1.32653634, grad/param norm = 2.3183e-01, time/batch = 0.6606s	
3117/22300 (epoch 6.989), train_loss = 1.39083001, grad/param norm = 2.3815e-01, time/batch = 0.6684s	
3118/22300 (epoch 6.991), train_loss = 1.57230114, grad/param norm = 2.5808e-01, time/batch = 0.6807s	
3119/22300 (epoch 6.993), train_loss = 1.58466004, grad/param norm = 2.6684e-01, time/batch = 0.6692s	
3120/22300 (epoch 6.996), train_loss = 1.58831876, grad/param norm = 2.7617e-01, time/batch = 0.6645s	
3121/22300 (epoch 6.998), train_loss = 1.35095675, grad/param norm = 2.6731e-01, time/batch = 0.6645s	
3122/22300 (epoch 7.000), train_loss = 1.26452834, grad/param norm = 2.4012e-01, time/batch = 0.6657s	
3123/22300 (epoch 7.002), train_loss = 1.51424079, grad/param norm = 2.6281e-01, time/batch = 0.6701s	
3124/22300 (epoch 7.004), train_loss = 1.38633784, grad/param norm = 2.3404e-01, time/batch = 0.6708s	
3125/22300 (epoch 7.007), train_loss = 1.37801465, grad/param norm = 2.4788e-01, time/batch = 0.6737s	
3126/22300 (epoch 7.009), train_loss = 1.37320333, grad/param norm = 2.3352e-01, time/batch = 0.6697s	
3127/22300 (epoch 7.011), train_loss = 1.54339669, grad/param norm = 2.6713e-01, time/batch = 0.6663s	
3128/22300 (epoch 7.013), train_loss = 1.31719855, grad/param norm = 2.5815e-01, time/batch = 0.6675s	
3129/22300 (epoch 7.016), train_loss = 1.35774849, grad/param norm = 2.7150e-01, time/batch = 0.6677s	
3130/22300 (epoch 7.018), train_loss = 1.49008043, grad/param norm = 2.6090e-01, time/batch = 0.6688s	
3131/22300 (epoch 7.020), train_loss = 1.34151870, grad/param norm = 2.3077e-01, time/batch = 0.6669s	
3132/22300 (epoch 7.022), train_loss = 1.32643775, grad/param norm = 2.4451e-01, time/batch = 0.6649s	
3133/22300 (epoch 7.025), train_loss = 1.33040330, grad/param norm = 2.3375e-01, time/batch = 0.6681s	
3134/22300 (epoch 7.027), train_loss = 1.46405989, grad/param norm = 2.4376e-01, time/batch = 0.6723s	
3135/22300 (epoch 7.029), train_loss = 1.30843580, grad/param norm = 2.4046e-01, time/batch = 0.6627s	
3136/22300 (epoch 7.031), train_loss = 1.21270311, grad/param norm = 2.1152e-01, time/batch = 0.6605s	
3137/22300 (epoch 7.034), train_loss = 1.27118085, grad/param norm = 2.3072e-01, time/batch = 0.6641s	
3138/22300 (epoch 7.036), train_loss = 1.13890859, grad/param norm = 2.2262e-01, time/batch = 0.6687s	
3139/22300 (epoch 7.038), train_loss = 1.22935664, grad/param norm = 2.2129e-01, time/batch = 0.6672s	
3140/22300 (epoch 7.040), train_loss = 1.40832032, grad/param norm = 2.5736e-01, time/batch = 0.6608s	
3141/22300 (epoch 7.043), train_loss = 1.50787165, grad/param norm = 2.7781e-01, time/batch = 0.6659s	
3142/22300 (epoch 7.045), train_loss = 1.37550615, grad/param norm = 2.2982e-01, time/batch = 0.6667s	
3143/22300 (epoch 7.047), train_loss = 1.42843099, grad/param norm = 2.6310e-01, time/batch = 0.6635s	
3144/22300 (epoch 7.049), train_loss = 1.26494157, grad/param norm = 2.3226e-01, time/batch = 0.6644s	
3145/22300 (epoch 7.052), train_loss = 1.45224574, grad/param norm = 2.6137e-01, time/batch = 0.6621s	
3146/22300 (epoch 7.054), train_loss = 1.40734298, grad/param norm = 2.5207e-01, time/batch = 0.6579s	
3147/22300 (epoch 7.056), train_loss = 1.18646653, grad/param norm = 2.3587e-01, time/batch = 0.6592s	
3148/22300 (epoch 7.058), train_loss = 1.18530808, grad/param norm = 2.0627e-01, time/batch = 0.6620s	
3149/22300 (epoch 7.061), train_loss = 1.26814287, grad/param norm = 2.6405e-01, time/batch = 0.6694s	
3150/22300 (epoch 7.063), train_loss = 1.51335006, grad/param norm = 2.6702e-01, time/batch = 0.6783s	
3151/22300 (epoch 7.065), train_loss = 1.36488221, grad/param norm = 2.7164e-01, time/batch = 0.6795s	
3152/22300 (epoch 7.067), train_loss = 1.28410454, grad/param norm = 2.1422e-01, time/batch = 0.6745s	
3153/22300 (epoch 7.070), train_loss = 1.29415056, grad/param norm = 2.5227e-01, time/batch = 0.6801s	
3154/22300 (epoch 7.072), train_loss = 1.38182153, grad/param norm = 2.5175e-01, time/batch = 0.6839s	
3155/22300 (epoch 7.074), train_loss = 1.38157705, grad/param norm = 2.2933e-01, time/batch = 0.6741s	
3156/22300 (epoch 7.076), train_loss = 1.26248378, grad/param norm = 2.2697e-01, time/batch = 0.6790s	
3157/22300 (epoch 7.078), train_loss = 1.32959327, grad/param norm = 2.3228e-01, time/batch = 0.6737s	
3158/22300 (epoch 7.081), train_loss = 1.44157824, grad/param norm = 2.4704e-01, time/batch = 0.6664s	
3159/22300 (epoch 7.083), train_loss = 1.46286860, grad/param norm = 2.7177e-01, time/batch = 0.6802s	
3160/22300 (epoch 7.085), train_loss = 1.54400283, grad/param norm = 2.4804e-01, time/batch = 0.6701s	
3161/22300 (epoch 7.087), train_loss = 1.38557076, grad/param norm = 2.7837e-01, time/batch = 0.6779s	
3162/22300 (epoch 7.090), train_loss = 1.22429107, grad/param norm = 2.3670e-01, time/batch = 0.6787s	
3163/22300 (epoch 7.092), train_loss = 1.29231418, grad/param norm = 2.3642e-01, time/batch = 0.6765s	
3164/22300 (epoch 7.094), train_loss = 1.20447504, grad/param norm = 2.4422e-01, time/batch = 0.6980s	
3165/22300 (epoch 7.096), train_loss = 1.48775860, grad/param norm = 2.4621e-01, time/batch = 0.6842s	
3166/22300 (epoch 7.099), train_loss = 1.37525700, grad/param norm = 2.4037e-01, time/batch = 0.6805s	
3167/22300 (epoch 7.101), train_loss = 1.48428015, grad/param norm = 2.5534e-01, time/batch = 0.6779s	
3168/22300 (epoch 7.103), train_loss = 1.42152170, grad/param norm = 2.3884e-01, time/batch = 0.6822s	
3169/22300 (epoch 7.105), train_loss = 1.37400499, grad/param norm = 2.5110e-01, time/batch = 0.6797s	
3170/22300 (epoch 7.108), train_loss = 1.39884458, grad/param norm = 2.6488e-01, time/batch = 0.6754s	
3171/22300 (epoch 7.110), train_loss = 1.35133450, grad/param norm = 2.3310e-01, time/batch = 0.6771s	
3172/22300 (epoch 7.112), train_loss = 1.32397480, grad/param norm = 2.2489e-01, time/batch = 0.6725s	
3173/22300 (epoch 7.114), train_loss = 1.46674202, grad/param norm = 2.2605e-01, time/batch = 0.6915s	
3174/22300 (epoch 7.117), train_loss = 1.60420949, grad/param norm = 2.5953e-01, time/batch = 0.6828s	
3175/22300 (epoch 7.119), train_loss = 1.39626305, grad/param norm = 2.4389e-01, time/batch = 0.6807s	
3176/22300 (epoch 7.121), train_loss = 1.48783434, grad/param norm = 2.6374e-01, time/batch = 0.6790s	
3177/22300 (epoch 7.123), train_loss = 1.29996175, grad/param norm = 2.5533e-01, time/batch = 0.6778s	
3178/22300 (epoch 7.126), train_loss = 1.28547936, grad/param norm = 2.4748e-01, time/batch = 0.6708s	
3179/22300 (epoch 7.128), train_loss = 1.42780483, grad/param norm = 2.4045e-01, time/batch = 0.6799s	
3180/22300 (epoch 7.130), train_loss = 1.36784071, grad/param norm = 2.2860e-01, time/batch = 0.6767s	
3181/22300 (epoch 7.132), train_loss = 1.25291908, grad/param norm = 2.4436e-01, time/batch = 0.6756s	
3182/22300 (epoch 7.135), train_loss = 1.24186327, grad/param norm = 2.4267e-01, time/batch = 0.6707s	
3183/22300 (epoch 7.137), train_loss = 1.04092565, grad/param norm = 2.0539e-01, time/batch = 0.6635s	
3184/22300 (epoch 7.139), train_loss = 1.41602775, grad/param norm = 2.5402e-01, time/batch = 0.6657s	
3185/22300 (epoch 7.141), train_loss = 1.42704541, grad/param norm = 2.4148e-01, time/batch = 0.6635s	
3186/22300 (epoch 7.143), train_loss = 1.37989278, grad/param norm = 2.2783e-01, time/batch = 0.6623s	
3187/22300 (epoch 7.146), train_loss = 1.52836163, grad/param norm = 2.5502e-01, time/batch = 0.6625s	
3188/22300 (epoch 7.148), train_loss = 1.28334411, grad/param norm = 2.4493e-01, time/batch = 0.6684s	
3189/22300 (epoch 7.150), train_loss = 1.35256209, grad/param norm = 2.6076e-01, time/batch = 0.6790s	
3190/22300 (epoch 7.152), train_loss = 1.33035371, grad/param norm = 2.6257e-01, time/batch = 0.6721s	
3191/22300 (epoch 7.155), train_loss = 1.32786049, grad/param norm = 2.5438e-01, time/batch = 0.6809s	
3192/22300 (epoch 7.157), train_loss = 1.50779134, grad/param norm = 2.8452e-01, time/batch = 0.7006s	
3193/22300 (epoch 7.159), train_loss = 1.43553040, grad/param norm = 2.6572e-01, time/batch = 0.6960s	
3194/22300 (epoch 7.161), train_loss = 1.47753880, grad/param norm = 2.6201e-01, time/batch = 0.6871s	
3195/22300 (epoch 7.164), train_loss = 1.27471712, grad/param norm = 2.6404e-01, time/batch = 0.6846s	
3196/22300 (epoch 7.166), train_loss = 1.24793056, grad/param norm = 2.1912e-01, time/batch = 0.6769s	
3197/22300 (epoch 7.168), train_loss = 1.29601815, grad/param norm = 2.2786e-01, time/batch = 0.6719s	
3198/22300 (epoch 7.170), train_loss = 1.33613465, grad/param norm = 2.3028e-01, time/batch = 0.6848s	
3199/22300 (epoch 7.173), train_loss = 1.58101935, grad/param norm = 2.5531e-01, time/batch = 0.6688s	
3200/22300 (epoch 7.175), train_loss = 1.30757216, grad/param norm = 2.5178e-01, time/batch = 0.6601s	
3201/22300 (epoch 7.177), train_loss = 1.17120649, grad/param norm = 2.2780e-01, time/batch = 0.6675s	
3202/22300 (epoch 7.179), train_loss = 1.27215685, grad/param norm = 2.4036e-01, time/batch = 0.6735s	
3203/22300 (epoch 7.182), train_loss = 1.48616963, grad/param norm = 2.4408e-01, time/batch = 0.6712s	
3204/22300 (epoch 7.184), train_loss = 1.56399056, grad/param norm = 2.5361e-01, time/batch = 0.6566s	
3205/22300 (epoch 7.186), train_loss = 1.41732869, grad/param norm = 2.4427e-01, time/batch = 0.6553s	
3206/22300 (epoch 7.188), train_loss = 1.47053752, grad/param norm = 2.5632e-01, time/batch = 0.6519s	
3207/22300 (epoch 7.191), train_loss = 1.53059514, grad/param norm = 2.6402e-01, time/batch = 0.6593s	
3208/22300 (epoch 7.193), train_loss = 1.30399910, grad/param norm = 2.3923e-01, time/batch = 0.6702s	
3209/22300 (epoch 7.195), train_loss = 1.23794486, grad/param norm = 2.3881e-01, time/batch = 0.6686s	
3210/22300 (epoch 7.197), train_loss = 1.38000433, grad/param norm = 2.3700e-01, time/batch = 0.6650s	
3211/22300 (epoch 7.200), train_loss = 1.29900621, grad/param norm = 2.2668e-01, time/batch = 0.6666s	
3212/22300 (epoch 7.202), train_loss = 1.31237364, grad/param norm = 2.6303e-01, time/batch = 0.6665s	
3213/22300 (epoch 7.204), train_loss = 1.27339594, grad/param norm = 2.3536e-01, time/batch = 0.6624s	
3214/22300 (epoch 7.206), train_loss = 1.17427879, grad/param norm = 2.1406e-01, time/batch = 0.6654s	
3215/22300 (epoch 7.209), train_loss = 1.34400443, grad/param norm = 2.5366e-01, time/batch = 0.6655s	
3216/22300 (epoch 7.211), train_loss = 1.19254524, grad/param norm = 2.3290e-01, time/batch = 0.6577s	
3217/22300 (epoch 7.213), train_loss = 1.24331780, grad/param norm = 2.2182e-01, time/batch = 0.6573s	
3218/22300 (epoch 7.215), train_loss = 1.50000418, grad/param norm = 2.6196e-01, time/batch = 0.6669s	
3219/22300 (epoch 7.217), train_loss = 1.44637496, grad/param norm = 2.6185e-01, time/batch = 0.6667s	
3220/22300 (epoch 7.220), train_loss = 1.32653665, grad/param norm = 2.3574e-01, time/batch = 0.6633s	
3221/22300 (epoch 7.222), train_loss = 1.30051746, grad/param norm = 2.4899e-01, time/batch = 0.6638s	
3222/22300 (epoch 7.224), train_loss = 1.22756723, grad/param norm = 2.4421e-01, time/batch = 0.6621s	
3223/22300 (epoch 7.226), train_loss = 1.32616712, grad/param norm = 2.3877e-01, time/batch = 0.6698s	
3224/22300 (epoch 7.229), train_loss = 1.38023494, grad/param norm = 2.4765e-01, time/batch = 0.6608s	
3225/22300 (epoch 7.231), train_loss = 1.42492764, grad/param norm = 2.5531e-01, time/batch = 0.6557s	
3226/22300 (epoch 7.233), train_loss = 1.41768036, grad/param norm = 2.3705e-01, time/batch = 0.6597s	
3227/22300 (epoch 7.235), train_loss = 1.26151469, grad/param norm = 2.3450e-01, time/batch = 0.6605s	
3228/22300 (epoch 7.238), train_loss = 1.24383045, grad/param norm = 2.4072e-01, time/batch = 0.6632s	
3229/22300 (epoch 7.240), train_loss = 1.19188876, grad/param norm = 2.3300e-01, time/batch = 0.6699s	
3230/22300 (epoch 7.242), train_loss = 1.28954406, grad/param norm = 2.3955e-01, time/batch = 0.6637s	
3231/22300 (epoch 7.244), train_loss = 1.01566216, grad/param norm = 2.1157e-01, time/batch = 0.6608s	
3232/22300 (epoch 7.247), train_loss = 1.31461638, grad/param norm = 2.4704e-01, time/batch = 0.6608s	
3233/22300 (epoch 7.249), train_loss = 1.20247538, grad/param norm = 2.3557e-01, time/batch = 0.6564s	
3234/22300 (epoch 7.251), train_loss = 1.17141485, grad/param norm = 2.1461e-01, time/batch = 0.6601s	
3235/22300 (epoch 7.253), train_loss = 1.24795353, grad/param norm = 2.5806e-01, time/batch = 0.6607s	
3236/22300 (epoch 7.256), train_loss = 1.34506992, grad/param norm = 2.5891e-01, time/batch = 0.6596s	
3237/22300 (epoch 7.258), train_loss = 1.49703699, grad/param norm = 2.6760e-01, time/batch = 0.6658s	
3238/22300 (epoch 7.260), train_loss = 1.34046517, grad/param norm = 2.5073e-01, time/batch = 0.6778s	
3239/22300 (epoch 7.262), train_loss = 1.29104227, grad/param norm = 2.3407e-01, time/batch = 0.6672s	
3240/22300 (epoch 7.265), train_loss = 1.34182381, grad/param norm = 2.5095e-01, time/batch = 0.6739s	
3241/22300 (epoch 7.267), train_loss = 1.31402967, grad/param norm = 2.3695e-01, time/batch = 0.6798s	
3242/22300 (epoch 7.269), train_loss = 1.31265370, grad/param norm = 2.7439e-01, time/batch = 0.6713s	
3243/22300 (epoch 7.271), train_loss = 1.28694070, grad/param norm = 2.6581e-01, time/batch = 0.6655s	
3244/22300 (epoch 7.274), train_loss = 1.18871190, grad/param norm = 2.5727e-01, time/batch = 0.6658s	
3245/22300 (epoch 7.276), train_loss = 1.09857223, grad/param norm = 2.1475e-01, time/batch = 0.6674s	
3246/22300 (epoch 7.278), train_loss = 1.08691742, grad/param norm = 2.2400e-01, time/batch = 0.6636s	
3247/22300 (epoch 7.280), train_loss = 1.20625311, grad/param norm = 2.5358e-01, time/batch = 0.6646s	
3248/22300 (epoch 7.283), train_loss = 1.07265012, grad/param norm = 2.1744e-01, time/batch = 0.6597s	
3249/22300 (epoch 7.285), train_loss = 1.29029861, grad/param norm = 2.6360e-01, time/batch = 0.6604s	
3250/22300 (epoch 7.287), train_loss = 1.35160648, grad/param norm = 2.5014e-01, time/batch = 0.6598s	
3251/22300 (epoch 7.289), train_loss = 1.23688311, grad/param norm = 2.5002e-01, time/batch = 0.6664s	
3252/22300 (epoch 7.291), train_loss = 1.34890612, grad/param norm = 2.5989e-01, time/batch = 0.6617s	
3253/22300 (epoch 7.294), train_loss = 1.16445039, grad/param norm = 2.1240e-01, time/batch = 0.6620s	
3254/22300 (epoch 7.296), train_loss = 1.41778977, grad/param norm = 2.5899e-01, time/batch = 0.6625s	
3255/22300 (epoch 7.298), train_loss = 1.39899006, grad/param norm = 2.5129e-01, time/batch = 0.6608s	
3256/22300 (epoch 7.300), train_loss = 1.45744166, grad/param norm = 2.6397e-01, time/batch = 0.6756s	
3257/22300 (epoch 7.303), train_loss = 1.27978687, grad/param norm = 2.4876e-01, time/batch = 0.6699s	
3258/22300 (epoch 7.305), train_loss = 1.40400023, grad/param norm = 2.7703e-01, time/batch = 0.6606s	
3259/22300 (epoch 7.307), train_loss = 1.32266432, grad/param norm = 2.5606e-01, time/batch = 0.6532s	
3260/22300 (epoch 7.309), train_loss = 1.31151678, grad/param norm = 2.7073e-01, time/batch = 0.6596s	
3261/22300 (epoch 7.312), train_loss = 1.21144332, grad/param norm = 2.3895e-01, time/batch = 0.6596s	
3262/22300 (epoch 7.314), train_loss = 1.32622569, grad/param norm = 2.5466e-01, time/batch = 0.6606s	
3263/22300 (epoch 7.316), train_loss = 1.30072377, grad/param norm = 2.4430e-01, time/batch = 0.6592s	
3264/22300 (epoch 7.318), train_loss = 1.37288176, grad/param norm = 2.5645e-01, time/batch = 0.6851s	
3265/22300 (epoch 7.321), train_loss = 1.38514945, grad/param norm = 2.7803e-01, time/batch = 0.6667s	
3266/22300 (epoch 7.323), train_loss = 1.30264020, grad/param norm = 2.2407e-01, time/batch = 0.6694s	
3267/22300 (epoch 7.325), train_loss = 1.18344424, grad/param norm = 2.2767e-01, time/batch = 0.6706s	
3268/22300 (epoch 7.327), train_loss = 1.26861884, grad/param norm = 2.4533e-01, time/batch = 0.6694s	
3269/22300 (epoch 7.330), train_loss = 1.30859197, grad/param norm = 2.5182e-01, time/batch = 0.6700s	
3270/22300 (epoch 7.332), train_loss = 1.16720405, grad/param norm = 2.4281e-01, time/batch = 0.6685s	
3271/22300 (epoch 7.334), train_loss = 1.15423105, grad/param norm = 2.3399e-01, time/batch = 0.6736s	
3272/22300 (epoch 7.336), train_loss = 1.26709477, grad/param norm = 2.5120e-01, time/batch = 0.6727s	
3273/22300 (epoch 7.339), train_loss = 1.35222570, grad/param norm = 2.6201e-01, time/batch = 0.6616s	
3274/22300 (epoch 7.341), train_loss = 1.39175327, grad/param norm = 2.5331e-01, time/batch = 0.6621s	
3275/22300 (epoch 7.343), train_loss = 1.39757843, grad/param norm = 2.6329e-01, time/batch = 0.6654s	
3276/22300 (epoch 7.345), train_loss = 1.33050379, grad/param norm = 2.6221e-01, time/batch = 0.6625s	
3277/22300 (epoch 7.348), train_loss = 1.26903896, grad/param norm = 2.4652e-01, time/batch = 0.6603s	
3278/22300 (epoch 7.350), train_loss = 1.17187370, grad/param norm = 2.4899e-01, time/batch = 0.6580s	
3279/22300 (epoch 7.352), train_loss = 1.36254090, grad/param norm = 2.4333e-01, time/batch = 0.6624s	
3280/22300 (epoch 7.354), train_loss = 1.46528063, grad/param norm = 2.8937e-01, time/batch = 0.6733s	
3281/22300 (epoch 7.357), train_loss = 1.44875078, grad/param norm = 2.7995e-01, time/batch = 0.6661s	
3282/22300 (epoch 7.359), train_loss = 1.33362730, grad/param norm = 2.6336e-01, time/batch = 0.6629s	
3283/22300 (epoch 7.361), train_loss = 1.40296431, grad/param norm = 2.5353e-01, time/batch = 0.6829s	
3284/22300 (epoch 7.363), train_loss = 1.48710574, grad/param norm = 2.6290e-01, time/batch = 0.6802s	
3285/22300 (epoch 7.365), train_loss = 1.40190274, grad/param norm = 2.6471e-01, time/batch = 0.6766s	
3286/22300 (epoch 7.368), train_loss = 1.39484230, grad/param norm = 2.6570e-01, time/batch = 0.6740s	
3287/22300 (epoch 7.370), train_loss = 1.36152155, grad/param norm = 2.7905e-01, time/batch = 0.6742s	
3288/22300 (epoch 7.372), train_loss = 1.20209408, grad/param norm = 2.8022e-01, time/batch = 0.6728s	
3289/22300 (epoch 7.374), train_loss = 1.13653421, grad/param norm = 2.4181e-01, time/batch = 0.6792s	
3290/22300 (epoch 7.377), train_loss = 1.36102807, grad/param norm = 2.7098e-01, time/batch = 0.6763s	
3291/22300 (epoch 7.379), train_loss = 1.29188042, grad/param norm = 2.4561e-01, time/batch = 0.6774s	
3292/22300 (epoch 7.381), train_loss = 1.41844983, grad/param norm = 2.6742e-01, time/batch = 0.6760s	
3293/22300 (epoch 7.383), train_loss = 1.21413107, grad/param norm = 2.6697e-01, time/batch = 0.6748s	
3294/22300 (epoch 7.386), train_loss = 1.30447596, grad/param norm = 2.6704e-01, time/batch = 0.6781s	
3295/22300 (epoch 7.388), train_loss = 1.22238261, grad/param norm = 2.3822e-01, time/batch = 0.6635s	
3296/22300 (epoch 7.390), train_loss = 1.27096314, grad/param norm = 2.4232e-01, time/batch = 0.6550s	
3297/22300 (epoch 7.392), train_loss = 1.28295754, grad/param norm = 2.4615e-01, time/batch = 0.6624s	
3298/22300 (epoch 7.395), train_loss = 1.22548614, grad/param norm = 2.6784e-01, time/batch = 0.6651s	
3299/22300 (epoch 7.397), train_loss = 1.03085825, grad/param norm = 2.3176e-01, time/batch = 0.6663s	
3300/22300 (epoch 7.399), train_loss = 1.22869312, grad/param norm = 2.5378e-01, time/batch = 0.6607s	
3301/22300 (epoch 7.401), train_loss = 1.24016557, grad/param norm = 2.6129e-01, time/batch = 0.6666s	
3302/22300 (epoch 7.404), train_loss = 1.25116557, grad/param norm = 2.5711e-01, time/batch = 0.6665s	
3303/22300 (epoch 7.406), train_loss = 1.52754615, grad/param norm = 2.8289e-01, time/batch = 0.6629s	
3304/22300 (epoch 7.408), train_loss = 1.32770529, grad/param norm = 2.7205e-01, time/batch = 0.6631s	
3305/22300 (epoch 7.410), train_loss = 1.34516858, grad/param norm = 2.6366e-01, time/batch = 0.6686s	
3306/22300 (epoch 7.413), train_loss = 1.29370355, grad/param norm = 2.5757e-01, time/batch = 0.6603s	
3307/22300 (epoch 7.415), train_loss = 1.21000533, grad/param norm = 2.4934e-01, time/batch = 0.6558s	
3308/22300 (epoch 7.417), train_loss = 1.33424862, grad/param norm = 2.3377e-01, time/batch = 0.6587s	
3309/22300 (epoch 7.419), train_loss = 1.23248734, grad/param norm = 2.4739e-01, time/batch = 0.6566s	
3310/22300 (epoch 7.422), train_loss = 1.30191216, grad/param norm = 2.3821e-01, time/batch = 0.6566s	
3311/22300 (epoch 7.424), train_loss = 1.36037485, grad/param norm = 2.5682e-01, time/batch = 0.6640s	
3312/22300 (epoch 7.426), train_loss = 1.22282271, grad/param norm = 2.4628e-01, time/batch = 0.6677s	
3313/22300 (epoch 7.428), train_loss = 1.31685914, grad/param norm = 2.3707e-01, time/batch = 0.6667s	
3314/22300 (epoch 7.430), train_loss = 1.31001510, grad/param norm = 2.7065e-01, time/batch = 0.6635s	
3315/22300 (epoch 7.433), train_loss = 1.29439035, grad/param norm = 2.5733e-01, time/batch = 0.6624s	
3316/22300 (epoch 7.435), train_loss = 1.38218143, grad/param norm = 2.5128e-01, time/batch = 0.6711s	
3317/22300 (epoch 7.437), train_loss = 1.25390538, grad/param norm = 2.5597e-01, time/batch = 0.6769s	
3318/22300 (epoch 7.439), train_loss = 1.26762006, grad/param norm = 2.4520e-01, time/batch = 0.6642s	
3319/22300 (epoch 7.442), train_loss = 1.33174204, grad/param norm = 2.6285e-01, time/batch = 0.6574s	
3320/22300 (epoch 7.444), train_loss = 1.26620819, grad/param norm = 2.3134e-01, time/batch = 0.6559s	
3321/22300 (epoch 7.446), train_loss = 1.16019677, grad/param norm = 2.5764e-01, time/batch = 0.6549s	
3322/22300 (epoch 7.448), train_loss = 1.03736934, grad/param norm = 2.1177e-01, time/batch = 0.6582s	
3323/22300 (epoch 7.451), train_loss = 1.43183374, grad/param norm = 2.6884e-01, time/batch = 0.6615s	
3324/22300 (epoch 7.453), train_loss = 1.21900951, grad/param norm = 2.5576e-01, time/batch = 0.6627s	
3325/22300 (epoch 7.455), train_loss = 1.43309287, grad/param norm = 2.7784e-01, time/batch = 0.6628s	
3326/22300 (epoch 7.457), train_loss = 1.33157121, grad/param norm = 2.5462e-01, time/batch = 0.6607s	
3327/22300 (epoch 7.460), train_loss = 1.27801673, grad/param norm = 2.5880e-01, time/batch = 0.6618s	
3328/22300 (epoch 7.462), train_loss = 1.34232218, grad/param norm = 2.4617e-01, time/batch = 0.6782s	
3329/22300 (epoch 7.464), train_loss = 1.30617627, grad/param norm = 2.6492e-01, time/batch = 0.6768s	
3330/22300 (epoch 7.466), train_loss = 1.29003961, grad/param norm = 2.5279e-01, time/batch = 0.6744s	
3331/22300 (epoch 7.469), train_loss = 1.22537640, grad/param norm = 2.5568e-01, time/batch = 0.6768s	
3332/22300 (epoch 7.471), train_loss = 1.37706549, grad/param norm = 2.5485e-01, time/batch = 0.6753s	
3333/22300 (epoch 7.473), train_loss = 1.41660666, grad/param norm = 2.5633e-01, time/batch = 0.6702s	
3334/22300 (epoch 7.475), train_loss = 1.27275305, grad/param norm = 2.7082e-01, time/batch = 0.6842s	
3335/22300 (epoch 7.478), train_loss = 1.20878055, grad/param norm = 2.6493e-01, time/batch = 0.6725s	
3336/22300 (epoch 7.480), train_loss = 1.13570969, grad/param norm = 2.5404e-01, time/batch = 0.6901s	
3337/22300 (epoch 7.482), train_loss = 1.15753839, grad/param norm = 2.3753e-01, time/batch = 0.6822s	
3338/22300 (epoch 7.484), train_loss = 1.19488780, grad/param norm = 2.4495e-01, time/batch = 0.6689s	
3339/22300 (epoch 7.487), train_loss = 1.22043727, grad/param norm = 2.2244e-01, time/batch = 0.6624s	
3340/22300 (epoch 7.489), train_loss = 1.36886093, grad/param norm = 2.4568e-01, time/batch = 0.6567s	
3341/22300 (epoch 7.491), train_loss = 1.24564978, grad/param norm = 2.3877e-01, time/batch = 0.6565s	
3342/22300 (epoch 7.493), train_loss = 1.39630569, grad/param norm = 2.7812e-01, time/batch = 0.6661s	
3343/22300 (epoch 7.496), train_loss = 1.25132591, grad/param norm = 2.5329e-01, time/batch = 0.6622s	
3344/22300 (epoch 7.498), train_loss = 1.24720051, grad/param norm = 2.6076e-01, time/batch = 0.6617s	
3345/22300 (epoch 7.500), train_loss = 1.25203798, grad/param norm = 2.4467e-01, time/batch = 0.6575s	
3346/22300 (epoch 7.502), train_loss = 1.16093863, grad/param norm = 2.4899e-01, time/batch = 0.6645s	
3347/22300 (epoch 7.504), train_loss = 1.18986241, grad/param norm = 2.5156e-01, time/batch = 0.6707s	
3348/22300 (epoch 7.507), train_loss = 1.23105533, grad/param norm = 2.2933e-01, time/batch = 0.6533s	
3349/22300 (epoch 7.509), train_loss = 1.38080341, grad/param norm = 2.6741e-01, time/batch = 0.6461s	
3350/22300 (epoch 7.511), train_loss = 1.08706516, grad/param norm = 2.5604e-01, time/batch = 0.6510s	
3351/22300 (epoch 7.513), train_loss = 1.09383331, grad/param norm = 2.2714e-01, time/batch = 0.6627s	
3352/22300 (epoch 7.516), train_loss = 1.26590082, grad/param norm = 2.3870e-01, time/batch = 0.6456s	
3353/22300 (epoch 7.518), train_loss = 1.28473995, grad/param norm = 2.4060e-01, time/batch = 0.6432s	
3354/22300 (epoch 7.520), train_loss = 1.31767444, grad/param norm = 2.6162e-01, time/batch = 0.6433s	
3355/22300 (epoch 7.522), train_loss = 1.19374769, grad/param norm = 2.3692e-01, time/batch = 0.6467s	
3356/22300 (epoch 7.525), train_loss = 1.17547834, grad/param norm = 2.4293e-01, time/batch = 0.6497s	
3357/22300 (epoch 7.527), train_loss = 1.40427541, grad/param norm = 2.7455e-01, time/batch = 0.6555s	
3358/22300 (epoch 7.529), train_loss = 1.22862379, grad/param norm = 2.7057e-01, time/batch = 0.6490s	
3359/22300 (epoch 7.531), train_loss = 1.25444297, grad/param norm = 2.3984e-01, time/batch = 0.6470s	
3360/22300 (epoch 7.534), train_loss = 1.15681475, grad/param norm = 2.4913e-01, time/batch = 0.6447s	
3361/22300 (epoch 7.536), train_loss = 1.41448520, grad/param norm = 2.5521e-01, time/batch = 0.6529s	
3362/22300 (epoch 7.538), train_loss = 1.58954761, grad/param norm = 2.8426e-01, time/batch = 0.6558s	
3363/22300 (epoch 7.540), train_loss = 1.34798202, grad/param norm = 2.6725e-01, time/batch = 0.6495s	
3364/22300 (epoch 7.543), train_loss = 1.14660272, grad/param norm = 2.2992e-01, time/batch = 0.6473s	
3365/22300 (epoch 7.545), train_loss = 1.24330478, grad/param norm = 2.6229e-01, time/batch = 0.6485s	
3366/22300 (epoch 7.547), train_loss = 1.14237532, grad/param norm = 2.3289e-01, time/batch = 0.6482s	
3367/22300 (epoch 7.549), train_loss = 1.20384703, grad/param norm = 2.3336e-01, time/batch = 0.6436s	
3368/22300 (epoch 7.552), train_loss = 1.15321457, grad/param norm = 2.4458e-01, time/batch = 0.6432s	
3369/22300 (epoch 7.554), train_loss = 1.23408466, grad/param norm = 2.7541e-01, time/batch = 0.6516s	
3370/22300 (epoch 7.556), train_loss = 1.37374071, grad/param norm = 2.5016e-01, time/batch = 0.6669s	
3371/22300 (epoch 7.558), train_loss = 1.25106455, grad/param norm = 2.6176e-01, time/batch = 0.6523s	
3372/22300 (epoch 7.561), train_loss = 1.45932601, grad/param norm = 2.8763e-01, time/batch = 0.6519s	
3373/22300 (epoch 7.563), train_loss = 1.26665213, grad/param norm = 2.6113e-01, time/batch = 0.6530s	
3374/22300 (epoch 7.565), train_loss = 1.26480300, grad/param norm = 2.4908e-01, time/batch = 0.6436s	
3375/22300 (epoch 7.567), train_loss = 1.26519882, grad/param norm = 2.4158e-01, time/batch = 0.6417s	
3376/22300 (epoch 7.570), train_loss = 1.50241019, grad/param norm = 2.9598e-01, time/batch = 0.6481s	
3377/22300 (epoch 7.572), train_loss = 1.35536078, grad/param norm = 3.0827e-01, time/batch = 0.6479s	
3378/22300 (epoch 7.574), train_loss = 1.19051519, grad/param norm = 2.0943e-01, time/batch = 0.6595s	
3379/22300 (epoch 7.576), train_loss = 1.06532146, grad/param norm = 2.1340e-01, time/batch = 0.6516s	
3380/22300 (epoch 7.578), train_loss = 1.00366927, grad/param norm = 2.1160e-01, time/batch = 0.6526s	
3381/22300 (epoch 7.581), train_loss = 1.10681930, grad/param norm = 2.1013e-01, time/batch = 0.6556s	
3382/22300 (epoch 7.583), train_loss = 1.12683665, grad/param norm = 2.3254e-01, time/batch = 0.6477s	
3383/22300 (epoch 7.585), train_loss = 1.37806023, grad/param norm = 2.6056e-01, time/batch = 0.6462s	
3384/22300 (epoch 7.587), train_loss = 1.46034787, grad/param norm = 2.8791e-01, time/batch = 0.6437s	
3385/22300 (epoch 7.590), train_loss = 1.36458480, grad/param norm = 2.6053e-01, time/batch = 0.6472s	
3386/22300 (epoch 7.592), train_loss = 1.48710773, grad/param norm = 2.8015e-01, time/batch = 0.6476s	
3387/22300 (epoch 7.594), train_loss = 1.42361087, grad/param norm = 2.5876e-01, time/batch = 0.6552s	
3388/22300 (epoch 7.596), train_loss = 1.20376551, grad/param norm = 2.6752e-01, time/batch = 0.6546s	
3389/22300 (epoch 7.599), train_loss = 1.06776645, grad/param norm = 2.2043e-01, time/batch = 0.6538s	
3390/22300 (epoch 7.601), train_loss = 1.27649250, grad/param norm = 2.7375e-01, time/batch = 0.6494s	
3391/22300 (epoch 7.603), train_loss = 1.29018155, grad/param norm = 2.6779e-01, time/batch = 0.6666s	
3392/22300 (epoch 7.605), train_loss = 1.18709647, grad/param norm = 2.5635e-01, time/batch = 0.6560s	
3393/22300 (epoch 7.608), train_loss = 1.44937534, grad/param norm = 2.8351e-01, time/batch = 0.6489s	
3394/22300 (epoch 7.610), train_loss = 1.52256022, grad/param norm = 2.7087e-01, time/batch = 0.6425s	
3395/22300 (epoch 7.612), train_loss = 1.39090630, grad/param norm = 2.8464e-01, time/batch = 0.6469s	
3396/22300 (epoch 7.614), train_loss = 1.37526240, grad/param norm = 2.7456e-01, time/batch = 0.6478s	
3397/22300 (epoch 7.617), train_loss = 1.36466212, grad/param norm = 2.6575e-01, time/batch = 0.6479s	
3398/22300 (epoch 7.619), train_loss = 1.63049954, grad/param norm = 2.8229e-01, time/batch = 0.6406s	
3399/22300 (epoch 7.621), train_loss = 1.19844802, grad/param norm = 2.5964e-01, time/batch = 0.6426s	
3400/22300 (epoch 7.623), train_loss = 1.25315453, grad/param norm = 2.4749e-01, time/batch = 0.6410s	
3401/22300 (epoch 7.626), train_loss = 1.15258717, grad/param norm = 2.1966e-01, time/batch = 0.6422s	
3402/22300 (epoch 7.628), train_loss = 1.16126219, grad/param norm = 2.5431e-01, time/batch = 0.6437s	
3403/22300 (epoch 7.630), train_loss = 1.24563718, grad/param norm = 2.4368e-01, time/batch = 0.6445s	
3404/22300 (epoch 7.632), train_loss = 1.26858029, grad/param norm = 2.6118e-01, time/batch = 0.6495s	
3405/22300 (epoch 7.635), train_loss = 1.19561074, grad/param norm = 2.4793e-01, time/batch = 0.6485s	
3406/22300 (epoch 7.637), train_loss = 1.40259669, grad/param norm = 2.7337e-01, time/batch = 0.6437s	
3407/22300 (epoch 7.639), train_loss = 1.38297875, grad/param norm = 2.9085e-01, time/batch = 0.6482s	
3408/22300 (epoch 7.641), train_loss = 1.31976764, grad/param norm = 2.4737e-01, time/batch = 0.6568s	
3409/22300 (epoch 7.643), train_loss = 1.28140509, grad/param norm = 2.4987e-01, time/batch = 0.6627s	
3410/22300 (epoch 7.646), train_loss = 1.19213823, grad/param norm = 2.6039e-01, time/batch = 0.6622s	
3411/22300 (epoch 7.648), train_loss = 1.16362092, grad/param norm = 2.2074e-01, time/batch = 0.6666s	
3412/22300 (epoch 7.650), train_loss = 1.36885339, grad/param norm = 2.5452e-01, time/batch = 0.6628s	
3413/22300 (epoch 7.652), train_loss = 1.23226185, grad/param norm = 2.3204e-01, time/batch = 0.6644s	
3414/22300 (epoch 7.655), train_loss = 1.36639170, grad/param norm = 2.7019e-01, time/batch = 0.6637s	
3415/22300 (epoch 7.657), train_loss = 1.30136459, grad/param norm = 2.6387e-01, time/batch = 0.6614s	
3416/22300 (epoch 7.659), train_loss = 1.17799342, grad/param norm = 2.4017e-01, time/batch = 0.6602s	
3417/22300 (epoch 7.661), train_loss = 1.07971677, grad/param norm = 2.3263e-01, time/batch = 0.6659s	
3418/22300 (epoch 7.664), train_loss = 1.24335996, grad/param norm = 2.5366e-01, time/batch = 0.6655s	
3419/22300 (epoch 7.666), train_loss = 1.31894874, grad/param norm = 2.4075e-01, time/batch = 0.6811s	
3420/22300 (epoch 7.668), train_loss = 1.19980373, grad/param norm = 2.3797e-01, time/batch = 0.6808s	
3421/22300 (epoch 7.670), train_loss = 1.36424608, grad/param norm = 2.5991e-01, time/batch = 0.6835s	
3422/22300 (epoch 7.673), train_loss = 1.33716643, grad/param norm = 2.6239e-01, time/batch = 0.6721s	
3423/22300 (epoch 7.675), train_loss = 1.44560445, grad/param norm = 2.9201e-01, time/batch = 0.6714s	
3424/22300 (epoch 7.677), train_loss = 1.48695355, grad/param norm = 2.9148e-01, time/batch = 0.6633s	
3425/22300 (epoch 7.679), train_loss = 1.40503252, grad/param norm = 2.8142e-01, time/batch = 0.6647s	
3426/22300 (epoch 7.682), train_loss = 1.35340343, grad/param norm = 2.6073e-01, time/batch = 0.6705s	
3427/22300 (epoch 7.684), train_loss = 1.30233744, grad/param norm = 2.5166e-01, time/batch = 0.6776s	
3428/22300 (epoch 7.686), train_loss = 1.38856000, grad/param norm = 2.9384e-01, time/batch = 0.6887s	
3429/22300 (epoch 7.688), train_loss = 1.36447513, grad/param norm = 2.5553e-01, time/batch = 0.6844s	
3430/22300 (epoch 7.691), train_loss = 1.25137346, grad/param norm = 2.4920e-01, time/batch = 0.6704s	
3431/22300 (epoch 7.693), train_loss = 1.30347847, grad/param norm = 2.5642e-01, time/batch = 0.6688s	
3432/22300 (epoch 7.695), train_loss = 1.10205592, grad/param norm = 2.4872e-01, time/batch = 0.6667s	
3433/22300 (epoch 7.697), train_loss = 1.05684633, grad/param norm = 2.4813e-01, time/batch = 0.6684s	
3434/22300 (epoch 7.700), train_loss = 1.24366739, grad/param norm = 2.5897e-01, time/batch = 0.6673s	
3435/22300 (epoch 7.702), train_loss = 1.33530480, grad/param norm = 2.6282e-01, time/batch = 0.6710s	
3436/22300 (epoch 7.704), train_loss = 1.36285697, grad/param norm = 2.4736e-01, time/batch = 0.6693s	
3437/22300 (epoch 7.706), train_loss = 1.14249578, grad/param norm = 2.3714e-01, time/batch = 0.6750s	
3438/22300 (epoch 7.709), train_loss = 1.10144553, grad/param norm = 2.3390e-01, time/batch = 0.6715s	
3439/22300 (epoch 7.711), train_loss = 1.21335502, grad/param norm = 2.3436e-01, time/batch = 0.6581s	
3440/22300 (epoch 7.713), train_loss = 1.30360015, grad/param norm = 2.6620e-01, time/batch = 0.6697s	
3441/22300 (epoch 7.715), train_loss = 1.31414269, grad/param norm = 2.7372e-01, time/batch = 0.6682s	
3442/22300 (epoch 7.717), train_loss = 1.51543975, grad/param norm = 2.8929e-01, time/batch = 0.6676s	
3443/22300 (epoch 7.720), train_loss = 1.24723139, grad/param norm = 2.6757e-01, time/batch = 0.6659s	
3444/22300 (epoch 7.722), train_loss = 1.32592955, grad/param norm = 2.7748e-01, time/batch = 0.6680s	
3445/22300 (epoch 7.724), train_loss = 1.33190123, grad/param norm = 2.6154e-01, time/batch = 0.6649s	
3446/22300 (epoch 7.726), train_loss = 1.27893898, grad/param norm = 2.6594e-01, time/batch = 0.6733s	
3447/22300 (epoch 7.729), train_loss = 1.32946805, grad/param norm = 2.8535e-01, time/batch = 0.6662s	
3448/22300 (epoch 7.731), train_loss = 1.41699423, grad/param norm = 2.7638e-01, time/batch = 0.6546s	
3449/22300 (epoch 7.733), train_loss = 1.45767981, grad/param norm = 2.9408e-01, time/batch = 0.6476s	
3450/22300 (epoch 7.735), train_loss = 1.41566394, grad/param norm = 2.8614e-01, time/batch = 0.6497s	
3451/22300 (epoch 7.738), train_loss = 1.33548807, grad/param norm = 2.6672e-01, time/batch = 0.6480s	
3452/22300 (epoch 7.740), train_loss = 1.05028068, grad/param norm = 2.1034e-01, time/batch = 0.6535s	
3453/22300 (epoch 7.742), train_loss = 1.27758083, grad/param norm = 2.4288e-01, time/batch = 0.6531s	
3454/22300 (epoch 7.744), train_loss = 1.46848252, grad/param norm = 2.7799e-01, time/batch = 0.6558s	
3455/22300 (epoch 7.747), train_loss = 1.23949767, grad/param norm = 2.3635e-01, time/batch = 0.6563s	
3456/22300 (epoch 7.749), train_loss = 1.62530974, grad/param norm = 2.7738e-01, time/batch = 0.6610s	
3457/22300 (epoch 7.751), train_loss = 1.45401922, grad/param norm = 2.6401e-01, time/batch = 0.6539s	
3458/22300 (epoch 7.753), train_loss = 1.42439965, grad/param norm = 2.7652e-01, time/batch = 0.6561s	
3459/22300 (epoch 7.756), train_loss = 1.29856517, grad/param norm = 2.5443e-01, time/batch = 0.6560s	
3460/22300 (epoch 7.758), train_loss = 1.25689023, grad/param norm = 2.4952e-01, time/batch = 0.6562s	
3461/22300 (epoch 7.760), train_loss = 1.34190590, grad/param norm = 2.7697e-01, time/batch = 0.6568s	
3462/22300 (epoch 7.762), train_loss = 1.31808252, grad/param norm = 2.7481e-01, time/batch = 0.6682s	
3463/22300 (epoch 7.765), train_loss = 1.35263781, grad/param norm = 2.5628e-01, time/batch = 0.6762s	
3464/22300 (epoch 7.767), train_loss = 1.41444952, grad/param norm = 2.8301e-01, time/batch = 0.6740s	
3465/22300 (epoch 7.769), train_loss = 1.27442738, grad/param norm = 2.6666e-01, time/batch = 0.6667s	
3466/22300 (epoch 7.771), train_loss = 1.32497070, grad/param norm = 2.8057e-01, time/batch = 0.6672s	
3467/22300 (epoch 7.774), train_loss = 1.37188280, grad/param norm = 2.5794e-01, time/batch = 0.6682s	
3468/22300 (epoch 7.776), train_loss = 1.28285163, grad/param norm = 2.5757e-01, time/batch = 0.6708s	
3469/22300 (epoch 7.778), train_loss = 1.47258680, grad/param norm = 2.5770e-01, time/batch = 0.6721s	
3470/22300 (epoch 7.780), train_loss = 1.41611816, grad/param norm = 2.5059e-01, time/batch = 0.6794s	
3471/22300 (epoch 7.783), train_loss = 1.44801543, grad/param norm = 2.6523e-01, time/batch = 0.6733s	
3472/22300 (epoch 7.785), train_loss = 1.22475189, grad/param norm = 2.5902e-01, time/batch = 0.6800s	
3473/22300 (epoch 7.787), train_loss = 1.26426691, grad/param norm = 2.3690e-01, time/batch = 0.6671s	
3474/22300 (epoch 7.789), train_loss = 1.39948329, grad/param norm = 2.5951e-01, time/batch = 0.6605s	
3475/22300 (epoch 7.791), train_loss = 1.47338012, grad/param norm = 2.5755e-01, time/batch = 0.6608s	
3476/22300 (epoch 7.794), train_loss = 1.41971124, grad/param norm = 2.9042e-01, time/batch = 0.6633s	
3477/22300 (epoch 7.796), train_loss = 1.46329796, grad/param norm = 2.8188e-01, time/batch = 0.6642s	
3478/22300 (epoch 7.798), train_loss = 1.38605920, grad/param norm = 2.5670e-01, time/batch = 0.6645s	
3479/22300 (epoch 7.800), train_loss = 1.16055454, grad/param norm = 2.3076e-01, time/batch = 0.6645s	
3480/22300 (epoch 7.803), train_loss = 1.16476388, grad/param norm = 2.2583e-01, time/batch = 0.6642s	
3481/22300 (epoch 7.805), train_loss = 1.30949924, grad/param norm = 2.3619e-01, time/batch = 0.6567s	
3482/22300 (epoch 7.807), train_loss = 1.36765762, grad/param norm = 2.6094e-01, time/batch = 0.6598s	
3483/22300 (epoch 7.809), train_loss = 1.34633109, grad/param norm = 2.6632e-01, time/batch = 0.6592s	
3484/22300 (epoch 7.812), train_loss = 1.44328944, grad/param norm = 2.9225e-01, time/batch = 0.6574s	
3485/22300 (epoch 7.814), train_loss = 1.33573364, grad/param norm = 2.3876e-01, time/batch = 0.6447s	
3486/22300 (epoch 7.816), train_loss = 1.40270635, grad/param norm = 2.5329e-01, time/batch = 0.6456s	
3487/22300 (epoch 7.818), train_loss = 1.36328306, grad/param norm = 2.4915e-01, time/batch = 0.6431s	
3488/22300 (epoch 7.821), train_loss = 1.46732494, grad/param norm = 2.5171e-01, time/batch = 0.6421s	
3489/22300 (epoch 7.823), train_loss = 1.21085118, grad/param norm = 2.2284e-01, time/batch = 0.6425s	
3490/22300 (epoch 7.825), train_loss = 1.28507650, grad/param norm = 2.4925e-01, time/batch = 0.6435s	
3491/22300 (epoch 7.827), train_loss = 1.33433107, grad/param norm = 2.7448e-01, time/batch = 0.6440s	
3492/22300 (epoch 7.830), train_loss = 1.26393544, grad/param norm = 3.0287e-01, time/batch = 0.6517s	
3493/22300 (epoch 7.832), train_loss = 1.21080270, grad/param norm = 2.5872e-01, time/batch = 0.6592s	
3494/22300 (epoch 7.834), train_loss = 1.34191182, grad/param norm = 2.6428e-01, time/batch = 0.6595s	
3495/22300 (epoch 7.836), train_loss = 1.27564795, grad/param norm = 2.3864e-01, time/batch = 0.6615s	
3496/22300 (epoch 7.839), train_loss = 1.30326806, grad/param norm = 2.3608e-01, time/batch = 0.6602s	
3497/22300 (epoch 7.841), train_loss = 1.28353181, grad/param norm = 2.6482e-01, time/batch = 0.6522s	
3498/22300 (epoch 7.843), train_loss = 1.31010340, grad/param norm = 2.7741e-01, time/batch = 0.6509s	
3499/22300 (epoch 7.845), train_loss = 1.25674982, grad/param norm = 2.2443e-01, time/batch = 0.6571s	
3500/22300 (epoch 7.848), train_loss = 1.27121751, grad/param norm = 2.3086e-01, time/batch = 0.6545s	
3501/22300 (epoch 7.850), train_loss = 1.31178539, grad/param norm = 2.4778e-01, time/batch = 0.6636s	
3502/22300 (epoch 7.852), train_loss = 1.32279661, grad/param norm = 2.7110e-01, time/batch = 0.6514s	
3503/22300 (epoch 7.854), train_loss = 1.47485742, grad/param norm = 2.8807e-01, time/batch = 0.6568s	
3504/22300 (epoch 7.857), train_loss = 1.25845253, grad/param norm = 2.7052e-01, time/batch = 0.6635s	
3505/22300 (epoch 7.859), train_loss = 1.14214139, grad/param norm = 2.3500e-01, time/batch = 0.6594s	
3506/22300 (epoch 7.861), train_loss = 1.29502059, grad/param norm = 2.3883e-01, time/batch = 0.6561s	
3507/22300 (epoch 7.863), train_loss = 1.13557769, grad/param norm = 2.2706e-01, time/batch = 0.6509s	
3508/22300 (epoch 7.865), train_loss = 1.18851551, grad/param norm = 2.5935e-01, time/batch = 0.6518s	
3509/22300 (epoch 7.868), train_loss = 1.23220802, grad/param norm = 2.3925e-01, time/batch = 0.6577s	
3510/22300 (epoch 7.870), train_loss = 1.26655951, grad/param norm = 2.3783e-01, time/batch = 0.6582s	
3511/22300 (epoch 7.872), train_loss = 1.35099360, grad/param norm = 2.6297e-01, time/batch = 0.6618s	
3512/22300 (epoch 7.874), train_loss = 1.33767863, grad/param norm = 2.6981e-01, time/batch = 0.6634s	
3513/22300 (epoch 7.877), train_loss = 1.28468068, grad/param norm = 2.3979e-01, time/batch = 0.6539s	
3514/22300 (epoch 7.879), train_loss = 1.14475273, grad/param norm = 2.2682e-01, time/batch = 0.6659s	
3515/22300 (epoch 7.881), train_loss = 1.26169027, grad/param norm = 2.8388e-01, time/batch = 0.6652s	
3516/22300 (epoch 7.883), train_loss = 1.24897734, grad/param norm = 2.5622e-01, time/batch = 0.6636s	
3517/22300 (epoch 7.886), train_loss = 1.26477893, grad/param norm = 2.3548e-01, time/batch = 0.6561s	
3518/22300 (epoch 7.888), train_loss = 1.23675627, grad/param norm = 2.5288e-01, time/batch = 0.6591s	
3519/22300 (epoch 7.890), train_loss = 1.14558252, grad/param norm = 2.2155e-01, time/batch = 0.6627s	
3520/22300 (epoch 7.892), train_loss = 1.40357263, grad/param norm = 2.6497e-01, time/batch = 0.6488s	
3521/22300 (epoch 7.895), train_loss = 1.40436829, grad/param norm = 2.7356e-01, time/batch = 0.6475s	
3522/22300 (epoch 7.897), train_loss = 1.32538264, grad/param norm = 2.5896e-01, time/batch = 0.6463s	
3523/22300 (epoch 7.899), train_loss = 1.30927200, grad/param norm = 2.4343e-01, time/batch = 0.6549s	
3524/22300 (epoch 7.901), train_loss = 1.23023555, grad/param norm = 2.4842e-01, time/batch = 0.6510s	
3525/22300 (epoch 7.904), train_loss = 1.26354182, grad/param norm = 2.6541e-01, time/batch = 0.6571s	
3526/22300 (epoch 7.906), train_loss = 1.38709592, grad/param norm = 2.6316e-01, time/batch = 0.6558s	
3527/22300 (epoch 7.908), train_loss = 1.29728496, grad/param norm = 2.5575e-01, time/batch = 0.6638s	
3528/22300 (epoch 7.910), train_loss = 1.14327662, grad/param norm = 2.3226e-01, time/batch = 0.6544s	
3529/22300 (epoch 7.913), train_loss = 1.27848307, grad/param norm = 2.4620e-01, time/batch = 0.6539s	
3530/22300 (epoch 7.915), train_loss = 1.47006634, grad/param norm = 2.7918e-01, time/batch = 0.6517s	
3531/22300 (epoch 7.917), train_loss = 1.26895771, grad/param norm = 2.6746e-01, time/batch = 0.6528s	
3532/22300 (epoch 7.919), train_loss = 1.30514077, grad/param norm = 2.5479e-01, time/batch = 0.6512s	
3533/22300 (epoch 7.922), train_loss = 1.32307202, grad/param norm = 2.6900e-01, time/batch = 0.6516s	
3534/22300 (epoch 7.924), train_loss = 1.09353154, grad/param norm = 2.1139e-01, time/batch = 0.6419s	
3535/22300 (epoch 7.926), train_loss = 1.08274776, grad/param norm = 2.2487e-01, time/batch = 0.6536s	
3536/22300 (epoch 7.928), train_loss = 1.30154374, grad/param norm = 2.5966e-01, time/batch = 0.6671s	
3537/22300 (epoch 7.930), train_loss = 1.28234454, grad/param norm = 2.4461e-01, time/batch = 0.6719s	
3538/22300 (epoch 7.933), train_loss = 1.32214182, grad/param norm = 2.6995e-01, time/batch = 0.6888s	
3539/22300 (epoch 7.935), train_loss = 1.42836574, grad/param norm = 2.7968e-01, time/batch = 0.6924s	
3540/22300 (epoch 7.937), train_loss = 1.41080892, grad/param norm = 2.5856e-01, time/batch = 0.6767s	
3541/22300 (epoch 7.939), train_loss = 1.40957645, grad/param norm = 2.6625e-01, time/batch = 0.6936s	
3542/22300 (epoch 7.942), train_loss = 1.47514770, grad/param norm = 2.7102e-01, time/batch = 0.6788s	
3543/22300 (epoch 7.944), train_loss = 1.54141353, grad/param norm = 2.8747e-01, time/batch = 0.6735s	
3544/22300 (epoch 7.946), train_loss = 1.24307818, grad/param norm = 2.8093e-01, time/batch = 0.6798s	
3545/22300 (epoch 7.948), train_loss = 1.24091212, grad/param norm = 2.3371e-01, time/batch = 0.6913s	
3546/22300 (epoch 7.951), train_loss = 1.11446967, grad/param norm = 2.1835e-01, time/batch = 0.6784s	
3547/22300 (epoch 7.953), train_loss = 1.20615721, grad/param norm = 2.5143e-01, time/batch = 0.6573s	
3548/22300 (epoch 7.955), train_loss = 1.52602893, grad/param norm = 2.7153e-01, time/batch = 0.6783s	
3549/22300 (epoch 7.957), train_loss = 1.54288101, grad/param norm = 2.6860e-01, time/batch = 0.6895s	
3550/22300 (epoch 7.960), train_loss = 1.46002147, grad/param norm = 2.9335e-01, time/batch = 0.6741s	
3551/22300 (epoch 7.962), train_loss = 1.33907755, grad/param norm = 2.4222e-01, time/batch = 0.6564s	
3552/22300 (epoch 7.964), train_loss = 1.29650072, grad/param norm = 2.5693e-01, time/batch = 0.6564s	
3553/22300 (epoch 7.966), train_loss = 1.25540138, grad/param norm = 2.5535e-01, time/batch = 0.6616s	
3554/22300 (epoch 7.969), train_loss = 1.17347629, grad/param norm = 2.1232e-01, time/batch = 0.6594s	
3555/22300 (epoch 7.971), train_loss = 1.23581400, grad/param norm = 2.4849e-01, time/batch = 0.6595s	
3556/22300 (epoch 7.973), train_loss = 1.28989802, grad/param norm = 2.5211e-01, time/batch = 0.6539s	
3557/22300 (epoch 7.975), train_loss = 1.55943553, grad/param norm = 2.6045e-01, time/batch = 0.6572s	
3558/22300 (epoch 7.978), train_loss = 1.26350886, grad/param norm = 2.3277e-01, time/batch = 0.6527s	
3559/22300 (epoch 7.980), train_loss = 1.33962579, grad/param norm = 2.5620e-01, time/batch = 0.6543s	
3560/22300 (epoch 7.982), train_loss = 1.17184335, grad/param norm = 2.3574e-01, time/batch = 0.6481s	
3561/22300 (epoch 7.984), train_loss = 1.35169776, grad/param norm = 2.4226e-01, time/batch = 0.6491s	
3562/22300 (epoch 7.987), train_loss = 1.21937241, grad/param norm = 2.3346e-01, time/batch = 0.6445s	
3563/22300 (epoch 7.989), train_loss = 1.29198506, grad/param norm = 2.4618e-01, time/batch = 0.6553s	
3564/22300 (epoch 7.991), train_loss = 1.50237059, grad/param norm = 2.7186e-01, time/batch = 0.6672s	
3565/22300 (epoch 7.993), train_loss = 1.52113657, grad/param norm = 2.7378e-01, time/batch = 0.6559s	
3566/22300 (epoch 7.996), train_loss = 1.52294693, grad/param norm = 2.9068e-01, time/batch = 0.6740s	
3567/22300 (epoch 7.998), train_loss = 1.24124676, grad/param norm = 2.5645e-01, time/batch = 0.6733s	
3568/22300 (epoch 8.000), train_loss = 1.15804843, grad/param norm = 2.4097e-01, time/batch = 0.6795s	
3569/22300 (epoch 8.002), train_loss = 1.44136363, grad/param norm = 2.7322e-01, time/batch = 0.6683s	
3570/22300 (epoch 8.004), train_loss = 1.29871996, grad/param norm = 2.3353e-01, time/batch = 0.6501s	
3571/22300 (epoch 8.007), train_loss = 1.28638589, grad/param norm = 2.4156e-01, time/batch = 0.6632s	
3572/22300 (epoch 8.009), train_loss = 1.29284365, grad/param norm = 2.4736e-01, time/batch = 0.6811s	
3573/22300 (epoch 8.011), train_loss = 1.46636550, grad/param norm = 2.7343e-01, time/batch = 0.6620s	
3574/22300 (epoch 8.013), train_loss = 1.22905309, grad/param norm = 2.4903e-01, time/batch = 0.6526s	
3575/22300 (epoch 8.016), train_loss = 1.26151196, grad/param norm = 2.7014e-01, time/batch = 0.6524s	
3576/22300 (epoch 8.018), train_loss = 1.39839776, grad/param norm = 2.6812e-01, time/batch = 0.6510s	
3577/22300 (epoch 8.020), train_loss = 1.25532499, grad/param norm = 2.3681e-01, time/batch = 0.6646s	
3578/22300 (epoch 8.022), train_loss = 1.23279412, grad/param norm = 2.5230e-01, time/batch = 0.6620s	
3579/22300 (epoch 8.025), train_loss = 1.23699692, grad/param norm = 2.3655e-01, time/batch = 0.6634s	
3580/22300 (epoch 8.027), train_loss = 1.34232498, grad/param norm = 2.4147e-01, time/batch = 0.6589s	
3581/22300 (epoch 8.029), train_loss = 1.21054616, grad/param norm = 2.4997e-01, time/batch = 0.6501s	
3582/22300 (epoch 8.031), train_loss = 1.12940608, grad/param norm = 2.1158e-01, time/batch = 0.6565s	
3583/22300 (epoch 8.034), train_loss = 1.19496592, grad/param norm = 2.4050e-01, time/batch = 0.6634s	
3584/22300 (epoch 8.036), train_loss = 1.04005655, grad/param norm = 2.2484e-01, time/batch = 0.6582s	
3585/22300 (epoch 8.038), train_loss = 1.15844180, grad/param norm = 2.2181e-01, time/batch = 0.6586s	
3586/22300 (epoch 8.040), train_loss = 1.30219587, grad/param norm = 2.5497e-01, time/batch = 0.6538s	
3587/22300 (epoch 8.043), train_loss = 1.42178701, grad/param norm = 2.6659e-01, time/batch = 0.6526s	
3588/22300 (epoch 8.045), train_loss = 1.29117894, grad/param norm = 2.2416e-01, time/batch = 0.6544s	
3589/22300 (epoch 8.047), train_loss = 1.34557295, grad/param norm = 2.6439e-01, time/batch = 0.6604s	
3590/22300 (epoch 8.049), train_loss = 1.18946294, grad/param norm = 2.4024e-01, time/batch = 0.6527s	
3591/22300 (epoch 8.052), train_loss = 1.34776335, grad/param norm = 2.5181e-01, time/batch = 0.6531s	
3592/22300 (epoch 8.054), train_loss = 1.32307844, grad/param norm = 2.7114e-01, time/batch = 0.6493s	
3593/22300 (epoch 8.056), train_loss = 1.10043788, grad/param norm = 2.6018e-01, time/batch = 0.6493s	
3594/22300 (epoch 8.058), train_loss = 1.11019052, grad/param norm = 2.1839e-01, time/batch = 0.6527s	
3595/22300 (epoch 8.061), train_loss = 1.17924673, grad/param norm = 2.6012e-01, time/batch = 0.6526s	
3596/22300 (epoch 8.063), train_loss = 1.44235260, grad/param norm = 2.7925e-01, time/batch = 0.6588s	
3597/22300 (epoch 8.065), train_loss = 1.30143617, grad/param norm = 2.7288e-01, time/batch = 0.6537s	
3598/22300 (epoch 8.067), train_loss = 1.19193247, grad/param norm = 2.2316e-01, time/batch = 0.6465s	
3599/22300 (epoch 8.070), train_loss = 1.20668535, grad/param norm = 2.5103e-01, time/batch = 0.6575s	
3600/22300 (epoch 8.072), train_loss = 1.29325347, grad/param norm = 2.6203e-01, time/batch = 0.6601s	
3601/22300 (epoch 8.074), train_loss = 1.30569198, grad/param norm = 2.3338e-01, time/batch = 0.6609s	
3602/22300 (epoch 8.076), train_loss = 1.18983198, grad/param norm = 2.3499e-01, time/batch = 0.6699s	
3603/22300 (epoch 8.078), train_loss = 1.27231131, grad/param norm = 2.4604e-01, time/batch = 0.6682s	
3604/22300 (epoch 8.081), train_loss = 1.35406371, grad/param norm = 2.5355e-01, time/batch = 0.6602s	
3605/22300 (epoch 8.083), train_loss = 1.39870599, grad/param norm = 2.9008e-01, time/batch = 0.6542s	
3606/22300 (epoch 8.085), train_loss = 1.47930209, grad/param norm = 2.5890e-01, time/batch = 0.6608s	
3607/22300 (epoch 8.087), train_loss = 1.30853696, grad/param norm = 2.8205e-01, time/batch = 0.6647s	
3608/22300 (epoch 8.090), train_loss = 1.12434161, grad/param norm = 2.3318e-01, time/batch = 0.6640s	
3609/22300 (epoch 8.092), train_loss = 1.18478624, grad/param norm = 2.3660e-01, time/batch = 0.6632s	
3610/22300 (epoch 8.094), train_loss = 1.12439460, grad/param norm = 2.4762e-01, time/batch = 0.6653s	
3611/22300 (epoch 8.096), train_loss = 1.41077758, grad/param norm = 2.5458e-01, time/batch = 0.6656s	
3612/22300 (epoch 8.099), train_loss = 1.27656322, grad/param norm = 2.4039e-01, time/batch = 0.6599s	
3613/22300 (epoch 8.101), train_loss = 1.40673619, grad/param norm = 2.6768e-01, time/batch = 0.6605s	
3614/22300 (epoch 8.103), train_loss = 1.34461468, grad/param norm = 2.5747e-01, time/batch = 0.6547s	
3615/22300 (epoch 8.105), train_loss = 1.28882826, grad/param norm = 2.7192e-01, time/batch = 0.6628s	
3616/22300 (epoch 8.108), train_loss = 1.30840592, grad/param norm = 2.5432e-01, time/batch = 0.6604s	
3617/22300 (epoch 8.110), train_loss = 1.27031510, grad/param norm = 2.3460e-01, time/batch = 0.6611s	
3618/22300 (epoch 8.112), train_loss = 1.23517699, grad/param norm = 2.1971e-01, time/batch = 0.6609s	
3619/22300 (epoch 8.114), train_loss = 1.36872404, grad/param norm = 2.2836e-01, time/batch = 0.6590s	
3620/22300 (epoch 8.117), train_loss = 1.53231493, grad/param norm = 2.6265e-01, time/batch = 0.6551s	
3621/22300 (epoch 8.119), train_loss = 1.30651084, grad/param norm = 2.4112e-01, time/batch = 0.6627s	
3622/22300 (epoch 8.121), train_loss = 1.41934889, grad/param norm = 2.7107e-01, time/batch = 0.6553s	
3623/22300 (epoch 8.123), train_loss = 1.24038856, grad/param norm = 2.6103e-01, time/batch = 0.6534s	
3624/22300 (epoch 8.126), train_loss = 1.20436090, grad/param norm = 2.4433e-01, time/batch = 0.6578s	
3625/22300 (epoch 8.128), train_loss = 1.35618269, grad/param norm = 2.3481e-01, time/batch = 0.6558s	
3626/22300 (epoch 8.130), train_loss = 1.27952584, grad/param norm = 2.3682e-01, time/batch = 0.6604s	
3627/22300 (epoch 8.132), train_loss = 1.17214189, grad/param norm = 2.4569e-01, time/batch = 0.6634s	
3628/22300 (epoch 8.135), train_loss = 1.14530131, grad/param norm = 2.3661e-01, time/batch = 0.6627s	
3629/22300 (epoch 8.137), train_loss = 0.95135010, grad/param norm = 2.0483e-01, time/batch = 0.6605s	
3630/22300 (epoch 8.139), train_loss = 1.33911946, grad/param norm = 2.5230e-01, time/batch = 0.6615s	
3631/22300 (epoch 8.141), train_loss = 1.33739176, grad/param norm = 2.4352e-01, time/batch = 0.6551s	
3632/22300 (epoch 8.143), train_loss = 1.30139593, grad/param norm = 2.4350e-01, time/batch = 0.6613s	
3633/22300 (epoch 8.146), train_loss = 1.44855767, grad/param norm = 2.6076e-01, time/batch = 0.6657s	
3634/22300 (epoch 8.148), train_loss = 1.18589432, grad/param norm = 2.3115e-01, time/batch = 0.6581s	
3635/22300 (epoch 8.150), train_loss = 1.25921943, grad/param norm = 2.5979e-01, time/batch = 0.6633s	
3636/22300 (epoch 8.152), train_loss = 1.21724997, grad/param norm = 2.6250e-01, time/batch = 0.6473s	
3637/22300 (epoch 8.155), train_loss = 1.22945247, grad/param norm = 2.5455e-01, time/batch = 0.6546s	
3638/22300 (epoch 8.157), train_loss = 1.42274402, grad/param norm = 2.7907e-01, time/batch = 0.6539s	
3639/22300 (epoch 8.159), train_loss = 1.33583211, grad/param norm = 2.6078e-01, time/batch = 0.6546s	
3640/22300 (epoch 8.161), train_loss = 1.40583884, grad/param norm = 2.6815e-01, time/batch = 0.6607s	
3641/22300 (epoch 8.164), train_loss = 1.17953606, grad/param norm = 2.5616e-01, time/batch = 0.6814s	
3642/22300 (epoch 8.166), train_loss = 1.14830981, grad/param norm = 2.0649e-01, time/batch = 0.6683s	
3643/22300 (epoch 8.168), train_loss = 1.19050711, grad/param norm = 2.2479e-01, time/batch = 0.6758s	
3644/22300 (epoch 8.170), train_loss = 1.24643032, grad/param norm = 2.2538e-01, time/batch = 0.6743s	
3645/22300 (epoch 8.173), train_loss = 1.49942477, grad/param norm = 2.7027e-01, time/batch = 0.6673s	
3646/22300 (epoch 8.175), train_loss = 1.21809941, grad/param norm = 2.4704e-01, time/batch = 0.6665s	
3647/22300 (epoch 8.177), train_loss = 1.08329511, grad/param norm = 2.3156e-01, time/batch = 0.6630s	
3648/22300 (epoch 8.179), train_loss = 1.19722195, grad/param norm = 2.4679e-01, time/batch = 0.6739s	
3649/22300 (epoch 8.182), train_loss = 1.42157190, grad/param norm = 2.5968e-01, time/batch = 0.6729s	
3650/22300 (epoch 8.184), train_loss = 1.49483582, grad/param norm = 2.5753e-01, time/batch = 0.6748s	
3651/22300 (epoch 8.186), train_loss = 1.32987122, grad/param norm = 2.3939e-01, time/batch = 0.6879s	
3652/22300 (epoch 8.188), train_loss = 1.39674439, grad/param norm = 2.5726e-01, time/batch = 0.6930s	
3653/22300 (epoch 8.191), train_loss = 1.44616540, grad/param norm = 2.6314e-01, time/batch = 0.6791s	
3654/22300 (epoch 8.193), train_loss = 1.23290213, grad/param norm = 2.3821e-01, time/batch = 0.6829s	
3655/22300 (epoch 8.195), train_loss = 1.16477605, grad/param norm = 2.6133e-01, time/batch = 0.6856s	
3656/22300 (epoch 8.197), train_loss = 1.28300226, grad/param norm = 2.3754e-01, time/batch = 0.6836s	
3657/22300 (epoch 8.200), train_loss = 1.21040240, grad/param norm = 2.4634e-01, time/batch = 0.6845s	
3658/22300 (epoch 8.202), train_loss = 1.22001375, grad/param norm = 2.6660e-01, time/batch = 0.6823s	
3659/22300 (epoch 8.204), train_loss = 1.19818854, grad/param norm = 2.4640e-01, time/batch = 0.6796s	
3660/22300 (epoch 8.206), train_loss = 1.09877186, grad/param norm = 2.1334e-01, time/batch = 0.6731s	
3661/22300 (epoch 8.209), train_loss = 1.26832247, grad/param norm = 2.5150e-01, time/batch = 0.6706s	
3662/22300 (epoch 8.211), train_loss = 1.10021834, grad/param norm = 2.3845e-01, time/batch = 0.6774s	
3663/22300 (epoch 8.213), train_loss = 1.15747420, grad/param norm = 2.2232e-01, time/batch = 0.6736s	
3664/22300 (epoch 8.215), train_loss = 1.42030073, grad/param norm = 2.6401e-01, time/batch = 0.6798s	
3665/22300 (epoch 8.217), train_loss = 1.37804162, grad/param norm = 2.7937e-01, time/batch = 0.6762s	
3666/22300 (epoch 8.220), train_loss = 1.24825576, grad/param norm = 2.4423e-01, time/batch = 0.6755s	
3667/22300 (epoch 8.222), train_loss = 1.22821190, grad/param norm = 2.6279e-01, time/batch = 0.6706s	
3668/22300 (epoch 8.224), train_loss = 1.13931910, grad/param norm = 2.3611e-01, time/batch = 0.6728s	
3669/22300 (epoch 8.226), train_loss = 1.21849388, grad/param norm = 2.4160e-01, time/batch = 0.6677s	
3670/22300 (epoch 8.229), train_loss = 1.28169411, grad/param norm = 2.6988e-01, time/batch = 0.6726s	
3671/22300 (epoch 8.231), train_loss = 1.33782255, grad/param norm = 2.5742e-01, time/batch = 0.6765s	
3672/22300 (epoch 8.233), train_loss = 1.32040502, grad/param norm = 2.4453e-01, time/batch = 0.6730s	
3673/22300 (epoch 8.235), train_loss = 1.16504326, grad/param norm = 2.4573e-01, time/batch = 0.6763s	
3674/22300 (epoch 8.238), train_loss = 1.14149836, grad/param norm = 2.3109e-01, time/batch = 0.6726s	
3675/22300 (epoch 8.240), train_loss = 1.09437706, grad/param norm = 2.1926e-01, time/batch = 0.6753s	
3676/22300 (epoch 8.242), train_loss = 1.18096219, grad/param norm = 2.3517e-01, time/batch = 0.6686s	
3677/22300 (epoch 8.244), train_loss = 0.92689491, grad/param norm = 2.1644e-01, time/batch = 0.6751s	
3678/22300 (epoch 8.247), train_loss = 1.19958267, grad/param norm = 2.4935e-01, time/batch = 0.6709s	
3679/22300 (epoch 8.249), train_loss = 1.09302824, grad/param norm = 2.4750e-01, time/batch = 0.6749s	
3680/22300 (epoch 8.251), train_loss = 1.08323655, grad/param norm = 2.2199e-01, time/batch = 0.6713s	
3681/22300 (epoch 8.253), train_loss = 1.13190418, grad/param norm = 2.5228e-01, time/batch = 0.6736s	
3682/22300 (epoch 8.256), train_loss = 1.20589631, grad/param norm = 2.3757e-01, time/batch = 0.6650s	
3683/22300 (epoch 8.258), train_loss = 1.42175396, grad/param norm = 2.6923e-01, time/batch = 0.6686s	
3684/22300 (epoch 8.260), train_loss = 1.25590452, grad/param norm = 2.6383e-01, time/batch = 0.6646s	
3685/22300 (epoch 8.262), train_loss = 1.18738596, grad/param norm = 2.4828e-01, time/batch = 0.6632s	
3686/22300 (epoch 8.265), train_loss = 1.24032773, grad/param norm = 2.6156e-01, time/batch = 0.6677s	
3687/22300 (epoch 8.267), train_loss = 1.23866821, grad/param norm = 2.5325e-01, time/batch = 0.6673s	
3688/22300 (epoch 8.269), train_loss = 1.22357020, grad/param norm = 2.7348e-01, time/batch = 0.6673s	
3689/22300 (epoch 8.271), train_loss = 1.18667701, grad/param norm = 2.5322e-01, time/batch = 0.6697s	
3690/22300 (epoch 8.274), train_loss = 1.08479354, grad/param norm = 2.4171e-01, time/batch = 0.6794s	
3691/22300 (epoch 8.276), train_loss = 1.00289361, grad/param norm = 2.1770e-01, time/batch = 0.6814s	
3692/22300 (epoch 8.278), train_loss = 0.97408610, grad/param norm = 2.2532e-01, time/batch = 0.6782s	
3693/22300 (epoch 8.280), train_loss = 1.10949755, grad/param norm = 2.4961e-01, time/batch = 0.6716s	
3694/22300 (epoch 8.283), train_loss = 0.96368237, grad/param norm = 2.0186e-01, time/batch = 0.6879s	
3695/22300 (epoch 8.285), train_loss = 1.19420948, grad/param norm = 2.6133e-01, time/batch = 0.6741s	
3696/22300 (epoch 8.287), train_loss = 1.27506540, grad/param norm = 2.5960e-01, time/batch = 0.6703s	
3697/22300 (epoch 8.289), train_loss = 1.13645621, grad/param norm = 2.4239e-01, time/batch = 0.6732s	
3698/22300 (epoch 8.291), train_loss = 1.26451117, grad/param norm = 2.7725e-01, time/batch = 0.6622s	
3699/22300 (epoch 8.294), train_loss = 1.07779489, grad/param norm = 2.2183e-01, time/batch = 0.6695s	
3700/22300 (epoch 8.296), train_loss = 1.33230220, grad/param norm = 2.6958e-01, time/batch = 0.6752s	
3701/22300 (epoch 8.298), train_loss = 1.32335743, grad/param norm = 2.5226e-01, time/batch = 0.6735s	
3702/22300 (epoch 8.300), train_loss = 1.38616268, grad/param norm = 2.6346e-01, time/batch = 0.6710s	
3703/22300 (epoch 8.303), train_loss = 1.19394014, grad/param norm = 2.6614e-01, time/batch = 0.6692s	
3704/22300 (epoch 8.305), train_loss = 1.30220900, grad/param norm = 2.7390e-01, time/batch = 0.6675s	
3705/22300 (epoch 8.307), train_loss = 1.22789379, grad/param norm = 2.6777e-01, time/batch = 0.6690s	
3706/22300 (epoch 8.309), train_loss = 1.20090205, grad/param norm = 2.4437e-01, time/batch = 0.6669s	
3707/22300 (epoch 8.312), train_loss = 1.11882275, grad/param norm = 2.4625e-01, time/batch = 0.6727s	
3708/22300 (epoch 8.314), train_loss = 1.22877925, grad/param norm = 2.5202e-01, time/batch = 0.6760s	
3709/22300 (epoch 8.316), train_loss = 1.21491372, grad/param norm = 2.6100e-01, time/batch = 0.6763s	
3710/22300 (epoch 8.318), train_loss = 1.26531362, grad/param norm = 2.5212e-01, time/batch = 0.6807s	
3711/22300 (epoch 8.321), train_loss = 1.27832816, grad/param norm = 2.6883e-01, time/batch = 0.6717s	
3712/22300 (epoch 8.323), train_loss = 1.20571824, grad/param norm = 2.2342e-01, time/batch = 0.6635s	
3713/22300 (epoch 8.325), train_loss = 1.08610764, grad/param norm = 2.3545e-01, time/batch = 0.6647s	
3714/22300 (epoch 8.327), train_loss = 1.17713878, grad/param norm = 2.5437e-01, time/batch = 0.6653s	
3715/22300 (epoch 8.330), train_loss = 1.20725473, grad/param norm = 2.5433e-01, time/batch = 0.6639s	
3716/22300 (epoch 8.332), train_loss = 1.09295516, grad/param norm = 2.5262e-01, time/batch = 0.6602s	
3717/22300 (epoch 8.334), train_loss = 1.06515614, grad/param norm = 2.3798e-01, time/batch = 0.6545s	
3718/22300 (epoch 8.336), train_loss = 1.17865517, grad/param norm = 2.5584e-01, time/batch = 0.6584s	
3719/22300 (epoch 8.339), train_loss = 1.25689001, grad/param norm = 2.6905e-01, time/batch = 0.6559s	
3720/22300 (epoch 8.341), train_loss = 1.30029885, grad/param norm = 2.6230e-01, time/batch = 0.6588s	
3721/22300 (epoch 8.343), train_loss = 1.32144497, grad/param norm = 2.6532e-01, time/batch = 0.6578s	
3722/22300 (epoch 8.345), train_loss = 1.25172933, grad/param norm = 2.8175e-01, time/batch = 0.6605s	
3723/22300 (epoch 8.348), train_loss = 1.18435140, grad/param norm = 2.6069e-01, time/batch = 0.6553s	
3724/22300 (epoch 8.350), train_loss = 1.08613037, grad/param norm = 2.5036e-01, time/batch = 0.6565s	
3725/22300 (epoch 8.352), train_loss = 1.29400080, grad/param norm = 2.6431e-01, time/batch = 0.6553s	
3726/22300 (epoch 8.354), train_loss = 1.41472998, grad/param norm = 2.9928e-01, time/batch = 0.6542s	
3727/22300 (epoch 8.357), train_loss = 1.35325807, grad/param norm = 2.6391e-01, time/batch = 0.6528s	
3728/22300 (epoch 8.359), train_loss = 1.23534498, grad/param norm = 2.4461e-01, time/batch = 0.6529s	
3729/22300 (epoch 8.361), train_loss = 1.29913381, grad/param norm = 2.4174e-01, time/batch = 0.6484s	
3730/22300 (epoch 8.363), train_loss = 1.37936019, grad/param norm = 2.4807e-01, time/batch = 0.6451s	
3731/22300 (epoch 8.365), train_loss = 1.30190644, grad/param norm = 2.7080e-01, time/batch = 0.6453s	
3732/22300 (epoch 8.368), train_loss = 1.29832667, grad/param norm = 2.8618e-01, time/batch = 0.6491s	
3733/22300 (epoch 8.370), train_loss = 1.27656882, grad/param norm = 2.7731e-01, time/batch = 0.6487s	
3734/22300 (epoch 8.372), train_loss = 1.10054563, grad/param norm = 2.5257e-01, time/batch = 0.6463s	
3735/22300 (epoch 8.374), train_loss = 1.02774293, grad/param norm = 2.4261e-01, time/batch = 0.6417s	
3736/22300 (epoch 8.377), train_loss = 1.26006924, grad/param norm = 2.6994e-01, time/batch = 0.6447s	
3737/22300 (epoch 8.379), train_loss = 1.19319137, grad/param norm = 2.4392e-01, time/batch = 0.6535s	
3738/22300 (epoch 8.381), train_loss = 1.33836114, grad/param norm = 2.8780e-01, time/batch = 0.6478s	
3739/22300 (epoch 8.383), train_loss = 1.12921291, grad/param norm = 2.5958e-01, time/batch = 0.6483s	
3740/22300 (epoch 8.386), train_loss = 1.21974013, grad/param norm = 2.7555e-01, time/batch = 0.6439s	
3741/22300 (epoch 8.388), train_loss = 1.13848925, grad/param norm = 2.4811e-01, time/batch = 0.6443s	
3742/22300 (epoch 8.390), train_loss = 1.18507218, grad/param norm = 2.4843e-01, time/batch = 0.6463s	
3743/22300 (epoch 8.392), train_loss = 1.18218303, grad/param norm = 2.5225e-01, time/batch = 0.6449s	
3744/22300 (epoch 8.395), train_loss = 1.13395539, grad/param norm = 2.6452e-01, time/batch = 0.6394s	
3745/22300 (epoch 8.397), train_loss = 0.92527925, grad/param norm = 2.3481e-01, time/batch = 0.6407s	
3746/22300 (epoch 8.399), train_loss = 1.12815113, grad/param norm = 2.4636e-01, time/batch = 0.6424s	
3747/22300 (epoch 8.401), train_loss = 1.14236542, grad/param norm = 2.4960e-01, time/batch = 0.6418s	
3748/22300 (epoch 8.404), train_loss = 1.15165452, grad/param norm = 2.6046e-01, time/batch = 0.6456s	
3749/22300 (epoch 8.406), train_loss = 1.44129094, grad/param norm = 2.9011e-01, time/batch = 0.6487s	
3750/22300 (epoch 8.408), train_loss = 1.23697497, grad/param norm = 2.6297e-01, time/batch = 0.6421s	
3751/22300 (epoch 8.410), train_loss = 1.26807244, grad/param norm = 2.7304e-01, time/batch = 0.6402s	
3752/22300 (epoch 8.413), train_loss = 1.18031047, grad/param norm = 2.4280e-01, time/batch = 0.6433s	
3753/22300 (epoch 8.415), train_loss = 1.10048648, grad/param norm = 2.3746e-01, time/batch = 0.6493s	
3754/22300 (epoch 8.417), train_loss = 1.22325904, grad/param norm = 2.4246e-01, time/batch = 0.6467s	
3755/22300 (epoch 8.419), train_loss = 1.13337237, grad/param norm = 2.4801e-01, time/batch = 0.6481s	
3756/22300 (epoch 8.422), train_loss = 1.20406452, grad/param norm = 2.3898e-01, time/batch = 0.6467s	
3757/22300 (epoch 8.424), train_loss = 1.26734418, grad/param norm = 2.5949e-01, time/batch = 0.6472s	
3758/22300 (epoch 8.426), train_loss = 1.11983589, grad/param norm = 2.6526e-01, time/batch = 0.6482s	
3759/22300 (epoch 8.428), train_loss = 1.22771550, grad/param norm = 2.5837e-01, time/batch = 0.6547s	
3760/22300 (epoch 8.430), train_loss = 1.21173022, grad/param norm = 2.7838e-01, time/batch = 0.6464s	
3761/22300 (epoch 8.433), train_loss = 1.18987273, grad/param norm = 2.4817e-01, time/batch = 0.6475s	
3762/22300 (epoch 8.435), train_loss = 1.28871309, grad/param norm = 2.6571e-01, time/batch = 0.6458s	
3763/22300 (epoch 8.437), train_loss = 1.18477634, grad/param norm = 2.5765e-01, time/batch = 0.6518s	
3764/22300 (epoch 8.439), train_loss = 1.19831147, grad/param norm = 2.4896e-01, time/batch = 0.6531s	
3765/22300 (epoch 8.442), train_loss = 1.23093681, grad/param norm = 2.5564e-01, time/batch = 0.6436s	
3766/22300 (epoch 8.444), train_loss = 1.15998808, grad/param norm = 2.1845e-01, time/batch = 0.6507s	
3767/22300 (epoch 8.446), train_loss = 1.05986180, grad/param norm = 2.5483e-01, time/batch = 0.6449s	
3768/22300 (epoch 8.448), train_loss = 0.94019207, grad/param norm = 2.1377e-01, time/batch = 0.6554s	
3769/22300 (epoch 8.451), train_loss = 1.32110180, grad/param norm = 2.6121e-01, time/batch = 0.6454s	
3770/22300 (epoch 8.453), train_loss = 1.12342911, grad/param norm = 2.4051e-01, time/batch = 0.6449s	
3771/22300 (epoch 8.455), train_loss = 1.37013770, grad/param norm = 3.1293e-01, time/batch = 0.6470s	
3772/22300 (epoch 8.457), train_loss = 1.27745148, grad/param norm = 2.6942e-01, time/batch = 0.6545s	
3773/22300 (epoch 8.460), train_loss = 1.20369205, grad/param norm = 2.6413e-01, time/batch = 0.6446s	
3774/22300 (epoch 8.462), train_loss = 1.26969015, grad/param norm = 2.4815e-01, time/batch = 0.6437s	
3775/22300 (epoch 8.464), train_loss = 1.23956019, grad/param norm = 2.6709e-01, time/batch = 0.6472s	
3776/22300 (epoch 8.466), train_loss = 1.19393489, grad/param norm = 2.4492e-01, time/batch = 0.6484s	
3777/22300 (epoch 8.469), train_loss = 1.11967515, grad/param norm = 2.4413e-01, time/batch = 0.6559s	
3778/22300 (epoch 8.471), train_loss = 1.29046728, grad/param norm = 2.4968e-01, time/batch = 0.6487s	
3779/22300 (epoch 8.473), train_loss = 1.32123129, grad/param norm = 2.5123e-01, time/batch = 0.6568s	
3780/22300 (epoch 8.475), train_loss = 1.17091420, grad/param norm = 2.7531e-01, time/batch = 0.6595s	
3781/22300 (epoch 8.478), train_loss = 1.12370409, grad/param norm = 2.6960e-01, time/batch = 0.6629s	
3782/22300 (epoch 8.480), train_loss = 1.02877391, grad/param norm = 2.4432e-01, time/batch = 0.6606s	
3783/22300 (epoch 8.482), train_loss = 1.05949982, grad/param norm = 2.4575e-01, time/batch = 0.6577s	
3784/22300 (epoch 8.484), train_loss = 1.13046741, grad/param norm = 2.6854e-01, time/batch = 0.6554s	
3785/22300 (epoch 8.487), train_loss = 1.15763192, grad/param norm = 2.2542e-01, time/batch = 0.6541s	
3786/22300 (epoch 8.489), train_loss = 1.28295584, grad/param norm = 2.5362e-01, time/batch = 0.6546s	
3787/22300 (epoch 8.491), train_loss = 1.17263199, grad/param norm = 2.4918e-01, time/batch = 0.6546s	
3788/22300 (epoch 8.493), train_loss = 1.31320226, grad/param norm = 2.7874e-01, time/batch = 0.6584s	
3789/22300 (epoch 8.496), train_loss = 1.14337713, grad/param norm = 2.4325e-01, time/batch = 0.6654s	
3790/22300 (epoch 8.498), train_loss = 1.13152823, grad/param norm = 2.6279e-01, time/batch = 0.6723s	
3791/22300 (epoch 8.500), train_loss = 1.17639763, grad/param norm = 2.5198e-01, time/batch = 0.6788s	
3792/22300 (epoch 8.502), train_loss = 1.06029947, grad/param norm = 2.4476e-01, time/batch = 0.6667s	
3793/22300 (epoch 8.504), train_loss = 1.08393490, grad/param norm = 2.4652e-01, time/batch = 0.6632s	
3794/22300 (epoch 8.507), train_loss = 1.13824391, grad/param norm = 2.3041e-01, time/batch = 0.6711s	
3795/22300 (epoch 8.509), train_loss = 1.27501172, grad/param norm = 2.6013e-01, time/batch = 0.6724s	
3796/22300 (epoch 8.511), train_loss = 1.00111363, grad/param norm = 2.5246e-01, time/batch = 0.6660s	
3797/22300 (epoch 8.513), train_loss = 0.99439895, grad/param norm = 2.2327e-01, time/batch = 0.6614s	
3798/22300 (epoch 8.516), train_loss = 1.15216080, grad/param norm = 2.4376e-01, time/batch = 0.6647s	
3799/22300 (epoch 8.518), train_loss = 1.21191725, grad/param norm = 2.4653e-01, time/batch = 0.6781s	
3800/22300 (epoch 8.520), train_loss = 1.22160791, grad/param norm = 2.5956e-01, time/batch = 0.6681s	
3801/22300 (epoch 8.522), train_loss = 1.10958803, grad/param norm = 2.3558e-01, time/batch = 0.6682s	
3802/22300 (epoch 8.525), train_loss = 1.07365643, grad/param norm = 2.4426e-01, time/batch = 0.6666s	
3803/22300 (epoch 8.527), train_loss = 1.32298885, grad/param norm = 2.7790e-01, time/batch = 0.6712s	
3804/22300 (epoch 8.529), train_loss = 1.12563388, grad/param norm = 2.6586e-01, time/batch = 0.6729s	
3805/22300 (epoch 8.531), train_loss = 1.16212681, grad/param norm = 2.4638e-01, time/batch = 0.6674s	
3806/22300 (epoch 8.534), train_loss = 1.06755246, grad/param norm = 2.5342e-01, time/batch = 0.6680s	
3807/22300 (epoch 8.536), train_loss = 1.32147956, grad/param norm = 2.5367e-01, time/batch = 0.6697s	
3808/22300 (epoch 8.538), train_loss = 1.49605901, grad/param norm = 2.6990e-01, time/batch = 0.6666s	
3809/22300 (epoch 8.540), train_loss = 1.25242202, grad/param norm = 2.7480e-01, time/batch = 0.6709s	
3810/22300 (epoch 8.543), train_loss = 1.05068181, grad/param norm = 2.2102e-01, time/batch = 0.6662s	
3811/22300 (epoch 8.545), train_loss = 1.14380771, grad/param norm = 2.6926e-01, time/batch = 0.6653s	
3812/22300 (epoch 8.547), train_loss = 1.03482154, grad/param norm = 2.2585e-01, time/batch = 0.6592s	
3813/22300 (epoch 8.549), train_loss = 1.10511021, grad/param norm = 2.4053e-01, time/batch = 0.6661s	
3814/22300 (epoch 8.552), train_loss = 1.06529999, grad/param norm = 2.4886e-01, time/batch = 0.6693s	
3815/22300 (epoch 8.554), train_loss = 1.14919029, grad/param norm = 2.7117e-01, time/batch = 0.6588s	
3816/22300 (epoch 8.556), train_loss = 1.29983694, grad/param norm = 2.5441e-01, time/batch = 0.6625s	
3817/22300 (epoch 8.558), train_loss = 1.18977206, grad/param norm = 2.7239e-01, time/batch = 0.6624s	
3818/22300 (epoch 8.561), train_loss = 1.37449604, grad/param norm = 2.9112e-01, time/batch = 0.6567s	
3819/22300 (epoch 8.563), train_loss = 1.19389066, grad/param norm = 2.5975e-01, time/batch = 0.6611s	
3820/22300 (epoch 8.565), train_loss = 1.17084045, grad/param norm = 2.5995e-01, time/batch = 0.6601s	
3821/22300 (epoch 8.567), train_loss = 1.14748788, grad/param norm = 2.4973e-01, time/batch = 0.6602s	
3822/22300 (epoch 8.570), train_loss = 1.41288243, grad/param norm = 3.1426e-01, time/batch = 0.6569s	
3823/22300 (epoch 8.572), train_loss = 1.27765228, grad/param norm = 3.1753e-01, time/batch = 0.6651s	
3824/22300 (epoch 8.574), train_loss = 1.11926433, grad/param norm = 2.1910e-01, time/batch = 0.6665s	
3825/22300 (epoch 8.576), train_loss = 0.98166587, grad/param norm = 2.1574e-01, time/batch = 0.6705s	
3826/22300 (epoch 8.578), train_loss = 0.90144254, grad/param norm = 2.0693e-01, time/batch = 0.6652s	
3827/22300 (epoch 8.581), train_loss = 1.02097192, grad/param norm = 2.1245e-01, time/batch = 0.6665s	
3828/22300 (epoch 8.583), train_loss = 1.01551449, grad/param norm = 2.2707e-01, time/batch = 0.6703s	
3829/22300 (epoch 8.585), train_loss = 1.30969943, grad/param norm = 2.6159e-01, time/batch = 0.6643s	
3830/22300 (epoch 8.587), train_loss = 1.39668949, grad/param norm = 2.9195e-01, time/batch = 0.6645s	
3831/22300 (epoch 8.590), train_loss = 1.29918974, grad/param norm = 2.8246e-01, time/batch = 0.6775s	
3832/22300 (epoch 8.592), train_loss = 1.39871296, grad/param norm = 2.6746e-01, time/batch = 0.6759s	
3833/22300 (epoch 8.594), train_loss = 1.36951731, grad/param norm = 2.7467e-01, time/batch = 0.6603s	
3834/22300 (epoch 8.596), train_loss = 1.10636444, grad/param norm = 2.4838e-01, time/batch = 0.6626s	
3835/22300 (epoch 8.599), train_loss = 0.97778305, grad/param norm = 2.1912e-01, time/batch = 0.6681s	
3836/22300 (epoch 8.601), train_loss = 1.18100974, grad/param norm = 2.5905e-01, time/batch = 0.6680s	
3837/22300 (epoch 8.603), train_loss = 1.19588193, grad/param norm = 2.6761e-01, time/batch = 0.6808s	
3838/22300 (epoch 8.605), train_loss = 1.09290289, grad/param norm = 2.6096e-01, time/batch = 0.6825s	
3839/22300 (epoch 8.608), train_loss = 1.38375092, grad/param norm = 2.8755e-01, time/batch = 0.6726s	
3840/22300 (epoch 8.610), train_loss = 1.44936218, grad/param norm = 2.6977e-01, time/batch = 0.6696s	
3841/22300 (epoch 8.612), train_loss = 1.30717866, grad/param norm = 2.9518e-01, time/batch = 0.6701s	
3842/22300 (epoch 8.614), train_loss = 1.28251174, grad/param norm = 2.7060e-01, time/batch = 0.6653s	
3843/22300 (epoch 8.617), train_loss = 1.27059206, grad/param norm = 2.6678e-01, time/batch = 0.6656s	
3844/22300 (epoch 8.619), train_loss = 1.54352194, grad/param norm = 2.9898e-01, time/batch = 0.6666s	
3845/22300 (epoch 8.621), train_loss = 1.12711167, grad/param norm = 2.5688e-01, time/batch = 0.6745s	
3846/22300 (epoch 8.623), train_loss = 1.16718792, grad/param norm = 2.6410e-01, time/batch = 0.6766s	
3847/22300 (epoch 8.626), train_loss = 1.06422801, grad/param norm = 2.2781e-01, time/batch = 0.6771s	
3848/22300 (epoch 8.628), train_loss = 1.08034627, grad/param norm = 2.5110e-01, time/batch = 0.6696s	
3849/22300 (epoch 8.630), train_loss = 1.15440267, grad/param norm = 2.3181e-01, time/batch = 0.6749s	
3850/22300 (epoch 8.632), train_loss = 1.16661617, grad/param norm = 2.4135e-01, time/batch = 0.6616s	
3851/22300 (epoch 8.635), train_loss = 1.11519946, grad/param norm = 2.4187e-01, time/batch = 0.6621s	
3852/22300 (epoch 8.637), train_loss = 1.31764543, grad/param norm = 2.6833e-01, time/batch = 0.6552s	
3853/22300 (epoch 8.639), train_loss = 1.30668531, grad/param norm = 2.9553e-01, time/batch = 0.6604s	
3854/22300 (epoch 8.641), train_loss = 1.22602511, grad/param norm = 2.4923e-01, time/batch = 0.6680s	
3855/22300 (epoch 8.643), train_loss = 1.18225737, grad/param norm = 2.5746e-01, time/batch = 0.6644s	
3856/22300 (epoch 8.646), train_loss = 1.11732826, grad/param norm = 2.7151e-01, time/batch = 0.6649s	
3857/22300 (epoch 8.648), train_loss = 1.08893807, grad/param norm = 2.1734e-01, time/batch = 0.6603s	
3858/22300 (epoch 8.650), train_loss = 1.27035262, grad/param norm = 2.4867e-01, time/batch = 0.6680s	
3859/22300 (epoch 8.652), train_loss = 1.13254265, grad/param norm = 2.3768e-01, time/batch = 0.6591s	
3860/22300 (epoch 8.655), train_loss = 1.26188548, grad/param norm = 2.7686e-01, time/batch = 0.6598s	
3861/22300 (epoch 8.657), train_loss = 1.21241419, grad/param norm = 2.7352e-01, time/batch = 0.6656s	
3862/22300 (epoch 8.659), train_loss = 1.09764980, grad/param norm = 2.5723e-01, time/batch = 0.6623s	
3863/22300 (epoch 8.661), train_loss = 0.98878658, grad/param norm = 2.4287e-01, time/batch = 0.6620s	
3864/22300 (epoch 8.664), train_loss = 1.14438827, grad/param norm = 2.6251e-01, time/batch = 0.6596s	
3865/22300 (epoch 8.666), train_loss = 1.22419426, grad/param norm = 2.4907e-01, time/batch = 0.6807s	
3866/22300 (epoch 8.668), train_loss = 1.10899907, grad/param norm = 2.3423e-01, time/batch = 0.6608s	
3867/22300 (epoch 8.670), train_loss = 1.26670612, grad/param norm = 2.6737e-01, time/batch = 0.6559s	
3868/22300 (epoch 8.673), train_loss = 1.27116611, grad/param norm = 2.5854e-01, time/batch = 0.6619s	
3869/22300 (epoch 8.675), train_loss = 1.37191242, grad/param norm = 2.9564e-01, time/batch = 0.6772s	
3870/22300 (epoch 8.677), train_loss = 1.39505214, grad/param norm = 2.7892e-01, time/batch = 0.6703s	
3871/22300 (epoch 8.679), train_loss = 1.30454776, grad/param norm = 2.6744e-01, time/batch = 0.6754s	
3872/22300 (epoch 8.682), train_loss = 1.25018069, grad/param norm = 2.6026e-01, time/batch = 0.6715s	
3873/22300 (epoch 8.684), train_loss = 1.21007206, grad/param norm = 2.5677e-01, time/batch = 0.6693s	
3874/22300 (epoch 8.686), train_loss = 1.28681281, grad/param norm = 2.8872e-01, time/batch = 0.6807s	
3875/22300 (epoch 8.688), train_loss = 1.26765655, grad/param norm = 2.6315e-01, time/batch = 0.6587s	
3876/22300 (epoch 8.691), train_loss = 1.15190417, grad/param norm = 2.4674e-01, time/batch = 0.6635s	
3877/22300 (epoch 8.693), train_loss = 1.19688032, grad/param norm = 2.5686e-01, time/batch = 0.6651s	
3878/22300 (epoch 8.695), train_loss = 0.98850735, grad/param norm = 2.4987e-01, time/batch = 0.6627s	
3879/22300 (epoch 8.697), train_loss = 0.96991289, grad/param norm = 2.3725e-01, time/batch = 0.6699s	
3880/22300 (epoch 8.700), train_loss = 1.14801549, grad/param norm = 2.6538e-01, time/batch = 0.6789s	
3881/22300 (epoch 8.702), train_loss = 1.24572560, grad/param norm = 2.7795e-01, time/batch = 0.6630s	
3882/22300 (epoch 8.704), train_loss = 1.28484586, grad/param norm = 2.6532e-01, time/batch = 0.6594s	
3883/22300 (epoch 8.706), train_loss = 1.06647426, grad/param norm = 2.5294e-01, time/batch = 0.6625s	
3884/22300 (epoch 8.709), train_loss = 1.00935993, grad/param norm = 2.3449e-01, time/batch = 0.6677s	
3885/22300 (epoch 8.711), train_loss = 1.09784190, grad/param norm = 2.2925e-01, time/batch = 0.6649s	
3886/22300 (epoch 8.713), train_loss = 1.23553525, grad/param norm = 2.7510e-01, time/batch = 0.6674s	
3887/22300 (epoch 8.715), train_loss = 1.23237407, grad/param norm = 2.7999e-01, time/batch = 0.6644s	
3888/22300 (epoch 8.717), train_loss = 1.42794110, grad/param norm = 2.9842e-01, time/batch = 0.6728s	
3889/22300 (epoch 8.720), train_loss = 1.14452272, grad/param norm = 2.5693e-01, time/batch = 0.6681s	
3890/22300 (epoch 8.722), train_loss = 1.24575573, grad/param norm = 2.8153e-01, time/batch = 0.6671s	
3891/22300 (epoch 8.724), train_loss = 1.24486578, grad/param norm = 2.6780e-01, time/batch = 0.6681s	
3892/22300 (epoch 8.726), train_loss = 1.18058693, grad/param norm = 2.7642e-01, time/batch = 0.6695s	
3893/22300 (epoch 8.729), train_loss = 1.22543753, grad/param norm = 2.7935e-01, time/batch = 0.6764s	
3894/22300 (epoch 8.731), train_loss = 1.33336420, grad/param norm = 2.7189e-01, time/batch = 0.6691s	
3895/22300 (epoch 8.733), train_loss = 1.36983353, grad/param norm = 2.9745e-01, time/batch = 0.6691s	
3896/22300 (epoch 8.735), train_loss = 1.35358160, grad/param norm = 3.0394e-01, time/batch = 0.6689s	
3897/22300 (epoch 8.738), train_loss = 1.25483218, grad/param norm = 2.9555e-01, time/batch = 0.6619s	
3898/22300 (epoch 8.740), train_loss = 0.97609799, grad/param norm = 2.2403e-01, time/batch = 0.6597s	
3899/22300 (epoch 8.742), train_loss = 1.18703739, grad/param norm = 2.4832e-01, time/batch = 0.6773s	
3900/22300 (epoch 8.744), train_loss = 1.40430280, grad/param norm = 2.7429e-01, time/batch = 0.6754s	
3901/22300 (epoch 8.747), train_loss = 1.16193027, grad/param norm = 2.3797e-01, time/batch = 0.6810s	
3902/22300 (epoch 8.749), train_loss = 1.54671010, grad/param norm = 2.8651e-01, time/batch = 0.6745s	
3903/22300 (epoch 8.751), train_loss = 1.39676647, grad/param norm = 2.6883e-01, time/batch = 0.6763s	
3904/22300 (epoch 8.753), train_loss = 1.36028161, grad/param norm = 2.9206e-01, time/batch = 0.6772s	
3905/22300 (epoch 8.756), train_loss = 1.22086138, grad/param norm = 2.8022e-01, time/batch = 0.6765s	
3906/22300 (epoch 8.758), train_loss = 1.19374299, grad/param norm = 2.5762e-01, time/batch = 0.6757s	
3907/22300 (epoch 8.760), train_loss = 1.27362564, grad/param norm = 2.8181e-01, time/batch = 0.6758s	
3908/22300 (epoch 8.762), train_loss = 1.23886159, grad/param norm = 2.7784e-01, time/batch = 0.6651s	
3909/22300 (epoch 8.765), train_loss = 1.25036888, grad/param norm = 2.5164e-01, time/batch = 0.6626s	
3910/22300 (epoch 8.767), train_loss = 1.32896935, grad/param norm = 2.7854e-01, time/batch = 0.6670s	
3911/22300 (epoch 8.769), train_loss = 1.19880423, grad/param norm = 2.7475e-01, time/batch = 0.6696s	
3912/22300 (epoch 8.771), train_loss = 1.25484207, grad/param norm = 2.9762e-01, time/batch = 0.6666s	
3913/22300 (epoch 8.774), train_loss = 1.29375910, grad/param norm = 2.7718e-01, time/batch = 0.6697s	
3914/22300 (epoch 8.776), train_loss = 1.21808358, grad/param norm = 2.5522e-01, time/batch = 0.6680s	
3915/22300 (epoch 8.778), train_loss = 1.39021386, grad/param norm = 2.6847e-01, time/batch = 0.6649s	
3916/22300 (epoch 8.780), train_loss = 1.32665029, grad/param norm = 2.5775e-01, time/batch = 0.6625s	
3917/22300 (epoch 8.783), train_loss = 1.37225820, grad/param norm = 2.7016e-01, time/batch = 0.6705s	
3918/22300 (epoch 8.785), train_loss = 1.14314650, grad/param norm = 2.5743e-01, time/batch = 0.6731s	
3919/22300 (epoch 8.787), train_loss = 1.19035722, grad/param norm = 2.4659e-01, time/batch = 0.6719s	
3920/22300 (epoch 8.789), train_loss = 1.32749888, grad/param norm = 2.6241e-01, time/batch = 0.6652s	
3921/22300 (epoch 8.791), train_loss = 1.40290574, grad/param norm = 2.5720e-01, time/batch = 0.6737s	
3922/22300 (epoch 8.794), train_loss = 1.36221503, grad/param norm = 2.9169e-01, time/batch = 0.6643s	
3923/22300 (epoch 8.796), train_loss = 1.38682107, grad/param norm = 2.7856e-01, time/batch = 0.6564s	
3924/22300 (epoch 8.798), train_loss = 1.30352466, grad/param norm = 2.5711e-01, time/batch = 0.6536s	
3925/22300 (epoch 8.800), train_loss = 1.10069825, grad/param norm = 2.3453e-01, time/batch = 0.6497s	
3926/22300 (epoch 8.803), train_loss = 1.08667831, grad/param norm = 2.2962e-01, time/batch = 0.6544s	
3927/22300 (epoch 8.805), train_loss = 1.23878460, grad/param norm = 2.4011e-01, time/batch = 0.6539s	
3928/22300 (epoch 8.807), train_loss = 1.30453065, grad/param norm = 2.6641e-01, time/batch = 0.6542s	
3929/22300 (epoch 8.809), train_loss = 1.24865668, grad/param norm = 2.6547e-01, time/batch = 0.6598s	
3930/22300 (epoch 8.812), train_loss = 1.33963699, grad/param norm = 2.8276e-01, time/batch = 0.6539s	
3931/22300 (epoch 8.814), train_loss = 1.26488164, grad/param norm = 2.5495e-01, time/batch = 0.6579s	
3932/22300 (epoch 8.816), train_loss = 1.32327686, grad/param norm = 2.5195e-01, time/batch = 0.6531s	
3933/22300 (epoch 8.818), train_loss = 1.29035918, grad/param norm = 2.4359e-01, time/batch = 0.6583s	
3934/22300 (epoch 8.821), train_loss = 1.39051298, grad/param norm = 2.7563e-01, time/batch = 0.6470s	
3935/22300 (epoch 8.823), train_loss = 1.13427423, grad/param norm = 2.2983e-01, time/batch = 0.6433s	
3936/22300 (epoch 8.825), train_loss = 1.21140082, grad/param norm = 2.5184e-01, time/batch = 0.6435s	
3937/22300 (epoch 8.827), train_loss = 1.24068056, grad/param norm = 2.6521e-01, time/batch = 0.6435s	
3938/22300 (epoch 8.830), train_loss = 1.15387717, grad/param norm = 2.7681e-01, time/batch = 0.6486s	
3939/22300 (epoch 8.832), train_loss = 1.13790133, grad/param norm = 2.4991e-01, time/batch = 0.6409s	
3940/22300 (epoch 8.834), train_loss = 1.25289058, grad/param norm = 2.7526e-01, time/batch = 0.6541s	
3941/22300 (epoch 8.836), train_loss = 1.18902255, grad/param norm = 2.4905e-01, time/batch = 0.6629s	
3942/22300 (epoch 8.839), train_loss = 1.21331384, grad/param norm = 2.4193e-01, time/batch = 0.6601s	
3943/22300 (epoch 8.841), train_loss = 1.19778331, grad/param norm = 2.6567e-01, time/batch = 0.6539s	
3944/22300 (epoch 8.843), train_loss = 1.22559958, grad/param norm = 2.8260e-01, time/batch = 0.6580s	
3945/22300 (epoch 8.845), train_loss = 1.17894210, grad/param norm = 2.3806e-01, time/batch = 0.6594s	
3946/22300 (epoch 8.848), train_loss = 1.19883386, grad/param norm = 2.3729e-01, time/batch = 0.6584s	
3947/22300 (epoch 8.850), train_loss = 1.23066642, grad/param norm = 2.5449e-01, time/batch = 0.6604s	
3948/22300 (epoch 8.852), train_loss = 1.22874546, grad/param norm = 2.5843e-01, time/batch = 0.6573s	
3949/22300 (epoch 8.854), train_loss = 1.38397445, grad/param norm = 2.8614e-01, time/batch = 0.6577s	
3950/22300 (epoch 8.857), train_loss = 1.18620412, grad/param norm = 2.7283e-01, time/batch = 0.6607s	
3951/22300 (epoch 8.859), train_loss = 1.04870656, grad/param norm = 2.3420e-01, time/batch = 0.6632s	
3952/22300 (epoch 8.861), train_loss = 1.21412252, grad/param norm = 2.3571e-01, time/batch = 0.6609s	
3953/22300 (epoch 8.863), train_loss = 1.04142932, grad/param norm = 2.3458e-01, time/batch = 0.6566s	
3954/22300 (epoch 8.865), train_loss = 1.09352679, grad/param norm = 2.3815e-01, time/batch = 0.6475s	
3955/22300 (epoch 8.868), train_loss = 1.14899025, grad/param norm = 2.3423e-01, time/batch = 0.6552s	
3956/22300 (epoch 8.870), train_loss = 1.19633445, grad/param norm = 2.5749e-01, time/batch = 0.6476s	
3957/22300 (epoch 8.872), train_loss = 1.27329141, grad/param norm = 2.7378e-01, time/batch = 0.6539s	
3958/22300 (epoch 8.874), train_loss = 1.24857746, grad/param norm = 2.7302e-01, time/batch = 0.6574s	
3959/22300 (epoch 8.877), train_loss = 1.20594112, grad/param norm = 2.3823e-01, time/batch = 0.6560s	
3960/22300 (epoch 8.879), train_loss = 1.07983546, grad/param norm = 2.4897e-01, time/batch = 0.6625s	
3961/22300 (epoch 8.881), train_loss = 1.19105775, grad/param norm = 2.9407e-01, time/batch = 0.6683s	
3962/22300 (epoch 8.883), train_loss = 1.14655856, grad/param norm = 2.5190e-01, time/batch = 0.6662s	
3963/22300 (epoch 8.886), train_loss = 1.16915761, grad/param norm = 2.4057e-01, time/batch = 0.6601s	
3964/22300 (epoch 8.888), train_loss = 1.16761679, grad/param norm = 2.7385e-01, time/batch = 0.6686s	
3965/22300 (epoch 8.890), train_loss = 1.07428809, grad/param norm = 2.2272e-01, time/batch = 0.6608s	
3966/22300 (epoch 8.892), train_loss = 1.33353511, grad/param norm = 2.7284e-01, time/batch = 0.6516s	
3967/22300 (epoch 8.895), train_loss = 1.33200877, grad/param norm = 2.8378e-01, time/batch = 0.6527s	
3968/22300 (epoch 8.897), train_loss = 1.23695491, grad/param norm = 2.6189e-01, time/batch = 0.6496s	
3969/22300 (epoch 8.899), train_loss = 1.24137226, grad/param norm = 2.5421e-01, time/batch = 0.6570s	
3970/22300 (epoch 8.901), train_loss = 1.16524388, grad/param norm = 2.5496e-01, time/batch = 0.6636s	
3971/22300 (epoch 8.904), train_loss = 1.20844727, grad/param norm = 2.5653e-01, time/batch = 0.6635s	
3972/22300 (epoch 8.906), train_loss = 1.31131200, grad/param norm = 2.6572e-01, time/batch = 0.6514s	
3973/22300 (epoch 8.908), train_loss = 1.21136999, grad/param norm = 2.5045e-01, time/batch = 0.6492s	
3974/22300 (epoch 8.910), train_loss = 1.05573381, grad/param norm = 2.4730e-01, time/batch = 0.6554s	
3975/22300 (epoch 8.913), train_loss = 1.21127900, grad/param norm = 2.5620e-01, time/batch = 0.6647s	
3976/22300 (epoch 8.915), train_loss = 1.39393823, grad/param norm = 2.7859e-01, time/batch = 0.6491s	
3977/22300 (epoch 8.917), train_loss = 1.19316273, grad/param norm = 2.6013e-01, time/batch = 0.6483s	
3978/22300 (epoch 8.919), train_loss = 1.22591661, grad/param norm = 2.4909e-01, time/batch = 0.6536s	
3979/22300 (epoch 8.922), train_loss = 1.22813542, grad/param norm = 2.6746e-01, time/batch = 0.6492s	
3980/22300 (epoch 8.924), train_loss = 0.99892810, grad/param norm = 2.0831e-01, time/batch = 0.6443s	
3981/22300 (epoch 8.926), train_loss = 0.99360310, grad/param norm = 2.1295e-01, time/batch = 0.6457s	
3982/22300 (epoch 8.928), train_loss = 1.19822201, grad/param norm = 2.3988e-01, time/batch = 0.6404s	
3983/22300 (epoch 8.930), train_loss = 1.18816426, grad/param norm = 2.3978e-01, time/batch = 0.6427s	
3984/22300 (epoch 8.933), train_loss = 1.24714520, grad/param norm = 2.5202e-01, time/batch = 0.6597s	
3985/22300 (epoch 8.935), train_loss = 1.35383631, grad/param norm = 2.7783e-01, time/batch = 0.6640s	
3986/22300 (epoch 8.937), train_loss = 1.35394130, grad/param norm = 2.7491e-01, time/batch = 0.6561s	
3987/22300 (epoch 8.939), train_loss = 1.32261106, grad/param norm = 2.9161e-01, time/batch = 0.6459s	
3988/22300 (epoch 8.942), train_loss = 1.43815171, grad/param norm = 2.9170e-01, time/batch = 0.6466s	
3989/22300 (epoch 8.944), train_loss = 1.46970738, grad/param norm = 2.9248e-01, time/batch = 0.6593s	
3990/22300 (epoch 8.946), train_loss = 1.16185445, grad/param norm = 2.8537e-01, time/batch = 0.6527s	
3991/22300 (epoch 8.948), train_loss = 1.16441199, grad/param norm = 2.5421e-01, time/batch = 0.6515s	
3992/22300 (epoch 8.951), train_loss = 1.03268863, grad/param norm = 2.3164e-01, time/batch = 0.6496s	
3993/22300 (epoch 8.953), train_loss = 1.11405278, grad/param norm = 2.5352e-01, time/batch = 0.6527s	
3994/22300 (epoch 8.955), train_loss = 1.44142477, grad/param norm = 2.7010e-01, time/batch = 0.6528s	
3995/22300 (epoch 8.957), train_loss = 1.48728260, grad/param norm = 2.6918e-01, time/batch = 0.6463s	
3996/22300 (epoch 8.960), train_loss = 1.36939190, grad/param norm = 2.8775e-01, time/batch = 0.6490s	
3997/22300 (epoch 8.962), train_loss = 1.24346144, grad/param norm = 2.3909e-01, time/batch = 0.6512s	
3998/22300 (epoch 8.964), train_loss = 1.19917542, grad/param norm = 2.5066e-01, time/batch = 0.6509s	
3999/22300 (epoch 8.966), train_loss = 1.16818865, grad/param norm = 2.5271e-01, time/batch = 0.6502s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch8.97_1.5456.t7	
4000/22300 (epoch 8.969), train_loss = 1.10234731, grad/param norm = 2.1329e-01, time/batch = 0.6477s	
4001/22300 (epoch 8.971), train_loss = 1.42458154, grad/param norm = 2.9040e-01, time/batch = 0.6571s	
4002/22300 (epoch 8.973), train_loss = 1.21762039, grad/param norm = 2.7000e-01, time/batch = 0.6624s	
4003/22300 (epoch 8.975), train_loss = 1.49332161, grad/param norm = 2.7668e-01, time/batch = 0.6576s	
4004/22300 (epoch 8.978), train_loss = 1.20718410, grad/param norm = 2.4328e-01, time/batch = 0.6578s	
4005/22300 (epoch 8.980), train_loss = 1.27874748, grad/param norm = 2.7222e-01, time/batch = 0.6536s	
4006/22300 (epoch 8.982), train_loss = 1.08858559, grad/param norm = 2.3702e-01, time/batch = 0.6499s	
4007/22300 (epoch 8.984), train_loss = 1.28288624, grad/param norm = 2.5868e-01, time/batch = 0.6539s	
4008/22300 (epoch 8.987), train_loss = 1.13221200, grad/param norm = 2.2653e-01, time/batch = 0.6547s	
4009/22300 (epoch 8.989), train_loss = 1.21558212, grad/param norm = 2.5685e-01, time/batch = 0.6558s	
4010/22300 (epoch 8.991), train_loss = 1.44379871, grad/param norm = 2.8050e-01, time/batch = 0.6555s	
4011/22300 (epoch 8.993), train_loss = 1.46386356, grad/param norm = 2.7667e-01, time/batch = 0.6528s	
4012/22300 (epoch 8.996), train_loss = 1.45705422, grad/param norm = 3.1968e-01, time/batch = 0.6525s	
4013/22300 (epoch 8.998), train_loss = 1.15776405, grad/param norm = 2.4984e-01, time/batch = 0.6509s	
4014/22300 (epoch 9.000), train_loss = 1.06661882, grad/param norm = 2.4692e-01, time/batch = 0.6588s	
4015/22300 (epoch 9.002), train_loss = 1.36795003, grad/param norm = 2.8125e-01, time/batch = 0.6491s	
4016/22300 (epoch 9.004), train_loss = 1.22433564, grad/param norm = 2.3163e-01, time/batch = 0.6504s	
4017/22300 (epoch 9.007), train_loss = 1.20694685, grad/param norm = 2.4310e-01, time/batch = 0.6569s	
4018/22300 (epoch 9.009), train_loss = 1.22636076, grad/param norm = 2.6038e-01, time/batch = 0.6565s	
4019/22300 (epoch 9.011), train_loss = 1.39908397, grad/param norm = 2.7524e-01, time/batch = 0.6543s	
4020/22300 (epoch 9.013), train_loss = 1.15245503, grad/param norm = 2.5087e-01, time/batch = 0.6582s	
4021/22300 (epoch 9.016), train_loss = 1.18980091, grad/param norm = 2.7085e-01, time/batch = 0.6574s	
4022/22300 (epoch 9.018), train_loss = 1.32279096, grad/param norm = 2.7728e-01, time/batch = 0.6570s	
4023/22300 (epoch 9.020), train_loss = 1.17951887, grad/param norm = 2.4360e-01, time/batch = 0.6495s	
4024/22300 (epoch 9.022), train_loss = 1.15167106, grad/param norm = 2.5417e-01, time/batch = 0.6621s	
4025/22300 (epoch 9.025), train_loss = 1.14850418, grad/param norm = 2.3212e-01, time/batch = 0.6626s	
4026/22300 (epoch 9.027), train_loss = 1.23307423, grad/param norm = 2.4042e-01, time/batch = 0.6495s	
4027/22300 (epoch 9.029), train_loss = 1.13064147, grad/param norm = 2.6067e-01, time/batch = 0.6524s	
4028/22300 (epoch 9.031), train_loss = 1.05688898, grad/param norm = 2.2364e-01, time/batch = 0.6559s	
4029/22300 (epoch 9.034), train_loss = 1.11989805, grad/param norm = 2.4678e-01, time/batch = 0.6511s	
4030/22300 (epoch 9.036), train_loss = 0.95718352, grad/param norm = 2.2207e-01, time/batch = 0.6519s	
4031/22300 (epoch 9.038), train_loss = 1.08105135, grad/param norm = 2.1584e-01, time/batch = 0.6551s	
4032/22300 (epoch 9.040), train_loss = 1.21600264, grad/param norm = 2.5471e-01, time/batch = 0.6579s	
4033/22300 (epoch 9.043), train_loss = 1.36613139, grad/param norm = 2.6782e-01, time/batch = 0.6598s	
4034/22300 (epoch 9.045), train_loss = 1.23104677, grad/param norm = 2.4103e-01, time/batch = 0.6526s	
4035/22300 (epoch 9.047), train_loss = 1.27713527, grad/param norm = 2.6698e-01, time/batch = 0.6526s	
4036/22300 (epoch 9.049), train_loss = 1.12856176, grad/param norm = 2.5385e-01, time/batch = 0.6563s	
4037/22300 (epoch 9.052), train_loss = 1.25993854, grad/param norm = 2.5401e-01, time/batch = 0.6529s	
4038/22300 (epoch 9.054), train_loss = 1.25383525, grad/param norm = 2.8155e-01, time/batch = 0.6521s	
4039/22300 (epoch 9.056), train_loss = 1.01154050, grad/param norm = 2.6872e-01, time/batch = 0.6482s	
4040/22300 (epoch 9.058), train_loss = 1.04559516, grad/param norm = 2.3754e-01, time/batch = 0.6479s	
4041/22300 (epoch 9.061), train_loss = 1.10000806, grad/param norm = 2.6852e-01, time/batch = 0.6572s	
4042/22300 (epoch 9.063), train_loss = 1.37604036, grad/param norm = 2.9161e-01, time/batch = 0.6541s	
4043/22300 (epoch 9.065), train_loss = 1.24703723, grad/param norm = 2.7529e-01, time/batch = 0.6569s	
4044/22300 (epoch 9.067), train_loss = 1.10925149, grad/param norm = 2.2833e-01, time/batch = 0.6614s	
4045/22300 (epoch 9.070), train_loss = 1.13354688, grad/param norm = 2.4960e-01, time/batch = 0.6606s	
4046/22300 (epoch 9.072), train_loss = 1.21629816, grad/param norm = 2.8420e-01, time/batch = 0.6635s	
4047/22300 (epoch 9.074), train_loss = 1.23051613, grad/param norm = 2.4594e-01, time/batch = 0.6518s	
4048/22300 (epoch 9.076), train_loss = 1.12880399, grad/param norm = 2.4412e-01, time/batch = 0.6542s	
4049/22300 (epoch 9.078), train_loss = 1.21025398, grad/param norm = 2.5206e-01, time/batch = 0.6589s	
4050/22300 (epoch 9.081), train_loss = 1.27113314, grad/param norm = 2.6382e-01, time/batch = 0.6729s	
4051/22300 (epoch 9.083), train_loss = 1.33379585, grad/param norm = 2.9870e-01, time/batch = 0.6518s	
4052/22300 (epoch 9.085), train_loss = 1.41535526, grad/param norm = 2.6477e-01, time/batch = 0.6625s	
4053/22300 (epoch 9.087), train_loss = 1.23217552, grad/param norm = 2.6297e-01, time/batch = 0.6671s	
4054/22300 (epoch 9.090), train_loss = 1.04797095, grad/param norm = 2.3671e-01, time/batch = 0.6628s	
4055/22300 (epoch 9.092), train_loss = 1.09236744, grad/param norm = 2.4616e-01, time/batch = 0.6575s	
4056/22300 (epoch 9.094), train_loss = 1.04649811, grad/param norm = 2.4852e-01, time/batch = 0.6589s	
4057/22300 (epoch 9.096), train_loss = 1.34255422, grad/param norm = 2.6759e-01, time/batch = 0.6536s	
4058/22300 (epoch 9.099), train_loss = 1.19544045, grad/param norm = 2.4673e-01, time/batch = 0.6567s	
4059/22300 (epoch 9.101), train_loss = 1.33769197, grad/param norm = 2.7004e-01, time/batch = 0.6561s	
4060/22300 (epoch 9.103), train_loss = 1.26652635, grad/param norm = 2.5764e-01, time/batch = 0.6584s	
4061/22300 (epoch 9.105), train_loss = 1.21529416, grad/param norm = 2.7542e-01, time/batch = 0.6559s	
4062/22300 (epoch 9.108), train_loss = 1.24122002, grad/param norm = 2.5742e-01, time/batch = 0.6597s	
4063/22300 (epoch 9.110), train_loss = 1.20832002, grad/param norm = 2.3749e-01, time/batch = 0.6788s	
4064/22300 (epoch 9.112), train_loss = 1.16018718, grad/param norm = 2.2470e-01, time/batch = 0.6660s	
4065/22300 (epoch 9.114), train_loss = 1.29185885, grad/param norm = 2.4447e-01, time/batch = 0.6644s	
4066/22300 (epoch 9.117), train_loss = 1.46040083, grad/param norm = 2.7334e-01, time/batch = 0.6649s	
4067/22300 (epoch 9.119), train_loss = 1.23625776, grad/param norm = 2.4543e-01, time/batch = 0.6578s	
4068/22300 (epoch 9.121), train_loss = 1.36268437, grad/param norm = 2.8318e-01, time/batch = 0.6583s	
4069/22300 (epoch 9.123), train_loss = 1.20543856, grad/param norm = 2.6668e-01, time/batch = 0.6562s	
4070/22300 (epoch 9.126), train_loss = 1.14388432, grad/param norm = 2.5154e-01, time/batch = 0.6642s	
4071/22300 (epoch 9.128), train_loss = 1.28721904, grad/param norm = 2.3875e-01, time/batch = 0.6541s	
4072/22300 (epoch 9.130), train_loss = 1.19730539, grad/param norm = 2.3779e-01, time/batch = 0.6541s	
4073/22300 (epoch 9.132), train_loss = 1.08818246, grad/param norm = 2.5121e-01, time/batch = 0.6560s	
4074/22300 (epoch 9.135), train_loss = 1.06400474, grad/param norm = 2.3691e-01, time/batch = 0.6595s	
4075/22300 (epoch 9.137), train_loss = 0.87214094, grad/param norm = 1.9878e-01, time/batch = 0.6530s	
4076/22300 (epoch 9.139), train_loss = 1.26155170, grad/param norm = 2.5282e-01, time/batch = 0.6499s	
4077/22300 (epoch 9.141), train_loss = 1.25958318, grad/param norm = 2.4499e-01, time/batch = 0.6603s	
4078/22300 (epoch 9.143), train_loss = 1.24410722, grad/param norm = 2.5469e-01, time/batch = 0.6656s	
4079/22300 (epoch 9.146), train_loss = 1.37146224, grad/param norm = 2.5975e-01, time/batch = 0.6613s	
4080/22300 (epoch 9.148), train_loss = 1.11104627, grad/param norm = 2.3825e-01, time/batch = 0.6639s	
4081/22300 (epoch 9.150), train_loss = 1.16220982, grad/param norm = 2.5094e-01, time/batch = 0.6723s	
4082/22300 (epoch 9.152), train_loss = 1.12297030, grad/param norm = 2.6558e-01, time/batch = 0.6736s	
4083/22300 (epoch 9.155), train_loss = 1.14272915, grad/param norm = 2.5750e-01, time/batch = 0.6660s	
4084/22300 (epoch 9.157), train_loss = 1.35863737, grad/param norm = 3.0058e-01, time/batch = 0.6660s	
4085/22300 (epoch 9.159), train_loss = 1.25919418, grad/param norm = 2.6061e-01, time/batch = 0.6646s	
4086/22300 (epoch 9.161), train_loss = 1.32945573, grad/param norm = 2.7939e-01, time/batch = 0.6619s	
4087/22300 (epoch 9.164), train_loss = 1.08325524, grad/param norm = 2.4391e-01, time/batch = 0.6625s	
4088/22300 (epoch 9.166), train_loss = 1.06753168, grad/param norm = 2.0123e-01, time/batch = 0.6675s	
4089/22300 (epoch 9.168), train_loss = 1.11392739, grad/param norm = 2.2546e-01, time/batch = 0.6696s	
4090/22300 (epoch 9.170), train_loss = 1.16395874, grad/param norm = 2.1864e-01, time/batch = 0.6651s	
4091/22300 (epoch 9.173), train_loss = 1.42055505, grad/param norm = 2.8141e-01, time/batch = 0.6671s	
4092/22300 (epoch 9.175), train_loss = 1.14039499, grad/param norm = 2.4547e-01, time/batch = 0.6675s	
4093/22300 (epoch 9.177), train_loss = 1.00648866, grad/param norm = 2.2538e-01, time/batch = 0.6653s	
4094/22300 (epoch 9.179), train_loss = 1.13079489, grad/param norm = 2.4856e-01, time/batch = 0.6512s	
4095/22300 (epoch 9.182), train_loss = 1.35756581, grad/param norm = 2.6402e-01, time/batch = 0.6529s	
4096/22300 (epoch 9.184), train_loss = 1.42759515, grad/param norm = 2.6658e-01, time/batch = 0.6555s	
4097/22300 (epoch 9.186), train_loss = 1.24439497, grad/param norm = 2.4600e-01, time/batch = 0.6566s	
4098/22300 (epoch 9.188), train_loss = 1.33781777, grad/param norm = 2.5850e-01, time/batch = 0.6513s	
4099/22300 (epoch 9.191), train_loss = 1.36283297, grad/param norm = 2.6002e-01, time/batch = 0.6485s	
4100/22300 (epoch 9.193), train_loss = 1.16593417, grad/param norm = 2.3936e-01, time/batch = 0.6480s	
4101/22300 (epoch 9.195), train_loss = 1.08990381, grad/param norm = 2.4373e-01, time/batch = 0.6545s	
4102/22300 (epoch 9.197), train_loss = 1.19790659, grad/param norm = 2.4519e-01, time/batch = 0.6535s	
4103/22300 (epoch 9.200), train_loss = 1.11704197, grad/param norm = 2.5281e-01, time/batch = 0.6520s	
4104/22300 (epoch 9.202), train_loss = 1.15137088, grad/param norm = 2.5611e-01, time/batch = 0.6540s	
4105/22300 (epoch 9.204), train_loss = 1.12999616, grad/param norm = 2.3760e-01, time/batch = 0.6526s	
4106/22300 (epoch 9.206), train_loss = 1.03463129, grad/param norm = 2.1799e-01, time/batch = 0.6532s	
4107/22300 (epoch 9.209), train_loss = 1.19395127, grad/param norm = 2.6697e-01, time/batch = 0.6529s	
4108/22300 (epoch 9.211), train_loss = 1.02446453, grad/param norm = 2.4391e-01, time/batch = 0.6529s	
4109/22300 (epoch 9.213), train_loss = 1.09508838, grad/param norm = 2.3162e-01, time/batch = 0.6565s	
4110/22300 (epoch 9.215), train_loss = 1.35223509, grad/param norm = 2.5671e-01, time/batch = 0.6515s	
4111/22300 (epoch 9.217), train_loss = 1.29799134, grad/param norm = 2.7433e-01, time/batch = 0.6555s	
4112/22300 (epoch 9.220), train_loss = 1.17415209, grad/param norm = 2.4257e-01, time/batch = 0.6610s	
4113/22300 (epoch 9.222), train_loss = 1.13567204, grad/param norm = 2.6945e-01, time/batch = 0.6478s	
4114/22300 (epoch 9.224), train_loss = 1.05071143, grad/param norm = 2.3841e-01, time/batch = 0.6482s	
4115/22300 (epoch 9.226), train_loss = 1.13972587, grad/param norm = 2.3354e-01, time/batch = 0.6512s	
4116/22300 (epoch 9.229), train_loss = 1.17600005, grad/param norm = 2.5705e-01, time/batch = 0.6504s	
4117/22300 (epoch 9.231), train_loss = 1.25172957, grad/param norm = 2.5061e-01, time/batch = 0.6450s	
4118/22300 (epoch 9.233), train_loss = 1.23227425, grad/param norm = 2.4124e-01, time/batch = 0.6513s	
4119/22300 (epoch 9.235), train_loss = 1.07215349, grad/param norm = 2.5582e-01, time/batch = 0.6552s	
4120/22300 (epoch 9.238), train_loss = 1.05551540, grad/param norm = 2.3306e-01, time/batch = 0.6535s	
4121/22300 (epoch 9.240), train_loss = 1.02001563, grad/param norm = 2.2337e-01, time/batch = 0.6565s	
4122/22300 (epoch 9.242), train_loss = 1.09829218, grad/param norm = 2.4496e-01, time/batch = 0.6492s	
4123/22300 (epoch 9.244), train_loss = 0.85850338, grad/param norm = 2.1987e-01, time/batch = 0.6559s	
4124/22300 (epoch 9.247), train_loss = 1.11363165, grad/param norm = 2.6544e-01, time/batch = 0.6518s	
4125/22300 (epoch 9.249), train_loss = 1.00534363, grad/param norm = 2.4354e-01, time/batch = 0.6502s	
4126/22300 (epoch 9.251), train_loss = 1.01103953, grad/param norm = 2.2112e-01, time/batch = 0.6564s	
4127/22300 (epoch 9.253), train_loss = 1.01877093, grad/param norm = 2.4114e-01, time/batch = 0.6539s	
4128/22300 (epoch 9.256), train_loss = 1.09936391, grad/param norm = 2.3794e-01, time/batch = 0.6502s	
4129/22300 (epoch 9.258), train_loss = 1.36378744, grad/param norm = 2.7582e-01, time/batch = 0.6521s	
4130/22300 (epoch 9.260), train_loss = 1.18125515, grad/param norm = 2.6714e-01, time/batch = 0.6597s	
4131/22300 (epoch 9.262), train_loss = 1.09489350, grad/param norm = 2.4503e-01, time/batch = 0.6642s	
4132/22300 (epoch 9.265), train_loss = 1.13528867, grad/param norm = 2.7383e-01, time/batch = 0.6618s	
4133/22300 (epoch 9.267), train_loss = 1.15605223, grad/param norm = 2.5907e-01, time/batch = 0.6621s	
4134/22300 (epoch 9.269), train_loss = 1.13890154, grad/param norm = 2.6492e-01, time/batch = 0.6619s	
4135/22300 (epoch 9.271), train_loss = 1.09795817, grad/param norm = 2.5908e-01, time/batch = 0.6613s	
4136/22300 (epoch 9.274), train_loss = 0.98319353, grad/param norm = 2.2392e-01, time/batch = 0.6599s	
4137/22300 (epoch 9.276), train_loss = 0.92612611, grad/param norm = 2.2329e-01, time/batch = 0.6660s	
4138/22300 (epoch 9.278), train_loss = 0.88430954, grad/param norm = 2.2227e-01, time/batch = 0.6610s	
4139/22300 (epoch 9.280), train_loss = 1.02862873, grad/param norm = 2.5053e-01, time/batch = 0.6570s	
4140/22300 (epoch 9.283), train_loss = 0.86606551, grad/param norm = 1.9644e-01, time/batch = 0.6461s	
4141/22300 (epoch 9.285), train_loss = 1.10207517, grad/param norm = 2.6528e-01, time/batch = 0.6510s	
4142/22300 (epoch 9.287), train_loss = 1.19512470, grad/param norm = 2.6822e-01, time/batch = 0.6565s	
4143/22300 (epoch 9.289), train_loss = 1.05961139, grad/param norm = 2.4636e-01, time/batch = 0.6523s	
4144/22300 (epoch 9.291), train_loss = 1.16937079, grad/param norm = 2.6791e-01, time/batch = 0.6763s	
4145/22300 (epoch 9.294), train_loss = 0.99448330, grad/param norm = 2.1813e-01, time/batch = 0.6538s	
4146/22300 (epoch 9.296), train_loss = 1.25508558, grad/param norm = 2.6881e-01, time/batch = 0.6492s	
4147/22300 (epoch 9.298), train_loss = 1.25608506, grad/param norm = 2.5751e-01, time/batch = 0.6466s	
4148/22300 (epoch 9.300), train_loss = 1.31450821, grad/param norm = 2.8988e-01, time/batch = 0.6486s	
4149/22300 (epoch 9.303), train_loss = 1.11997189, grad/param norm = 2.6726e-01, time/batch = 0.6513s	
4150/22300 (epoch 9.305), train_loss = 1.20531243, grad/param norm = 2.7858e-01, time/batch = 0.6565s	
4151/22300 (epoch 9.307), train_loss = 1.12841483, grad/param norm = 2.6968e-01, time/batch = 0.6640s	
4152/22300 (epoch 9.309), train_loss = 1.11836963, grad/param norm = 2.7937e-01, time/batch = 0.6532s	
4153/22300 (epoch 9.312), train_loss = 1.04185389, grad/param norm = 2.4108e-01, time/batch = 0.6555s	
4154/22300 (epoch 9.314), train_loss = 1.12652033, grad/param norm = 2.3327e-01, time/batch = 0.6617s	
4155/22300 (epoch 9.316), train_loss = 1.13116034, grad/param norm = 2.7800e-01, time/batch = 0.6550s	
4156/22300 (epoch 9.318), train_loss = 1.17659610, grad/param norm = 2.6217e-01, time/batch = 0.6495s	
4157/22300 (epoch 9.321), train_loss = 1.18764872, grad/param norm = 2.5561e-01, time/batch = 0.6494s	
4158/22300 (epoch 9.323), train_loss = 1.12670214, grad/param norm = 2.3138e-01, time/batch = 0.6636s	
4159/22300 (epoch 9.325), train_loss = 1.00691571, grad/param norm = 2.3760e-01, time/batch = 0.6491s	
4160/22300 (epoch 9.327), train_loss = 1.09727474, grad/param norm = 2.6331e-01, time/batch = 0.6496s	
4161/22300 (epoch 9.330), train_loss = 1.11978311, grad/param norm = 2.5239e-01, time/batch = 0.6650s	
4162/22300 (epoch 9.332), train_loss = 1.00583030, grad/param norm = 2.5689e-01, time/batch = 0.6601s	
4163/22300 (epoch 9.334), train_loss = 0.98070473, grad/param norm = 2.3476e-01, time/batch = 0.6592s	
4164/22300 (epoch 9.336), train_loss = 1.08751920, grad/param norm = 2.4870e-01, time/batch = 0.6597s	
4165/22300 (epoch 9.339), train_loss = 1.16989787, grad/param norm = 2.7792e-01, time/batch = 0.6596s	
4166/22300 (epoch 9.341), train_loss = 1.21825500, grad/param norm = 2.7316e-01, time/batch = 0.6599s	
4167/22300 (epoch 9.343), train_loss = 1.25216994, grad/param norm = 2.6801e-01, time/batch = 0.6599s	
4168/22300 (epoch 9.345), train_loss = 1.16011813, grad/param norm = 2.8239e-01, time/batch = 0.6611s	
4169/22300 (epoch 9.348), train_loss = 1.11312724, grad/param norm = 2.6029e-01, time/batch = 0.6639s	
4170/22300 (epoch 9.350), train_loss = 1.00162915, grad/param norm = 2.4028e-01, time/batch = 0.6579s	
4171/22300 (epoch 9.352), train_loss = 1.23231204, grad/param norm = 2.5724e-01, time/batch = 0.6570s	
4172/22300 (epoch 9.354), train_loss = 1.34057161, grad/param norm = 2.7236e-01, time/batch = 0.6574s	
4173/22300 (epoch 9.357), train_loss = 1.27786741, grad/param norm = 2.6878e-01, time/batch = 0.6531s	
4174/22300 (epoch 9.359), train_loss = 1.14590555, grad/param norm = 2.4218e-01, time/batch = 0.6556s	
4175/22300 (epoch 9.361), train_loss = 1.20656842, grad/param norm = 2.4610e-01, time/batch = 0.6526s	
4176/22300 (epoch 9.363), train_loss = 1.29841151, grad/param norm = 2.5171e-01, time/batch = 0.6524s	
4177/22300 (epoch 9.365), train_loss = 1.20614466, grad/param norm = 2.6029e-01, time/batch = 0.6506s	
4178/22300 (epoch 9.368), train_loss = 1.22450728, grad/param norm = 3.0650e-01, time/batch = 0.6417s	
4179/22300 (epoch 9.370), train_loss = 1.18950263, grad/param norm = 2.7398e-01, time/batch = 0.6484s	
4180/22300 (epoch 9.372), train_loss = 1.01737045, grad/param norm = 2.4508e-01, time/batch = 0.6536s	
4181/22300 (epoch 9.374), train_loss = 0.92427288, grad/param norm = 2.3925e-01, time/batch = 0.6460s	
4182/22300 (epoch 9.377), train_loss = 1.15066981, grad/param norm = 2.6450e-01, time/batch = 0.6510s	
4183/22300 (epoch 9.379), train_loss = 1.11597407, grad/param norm = 2.5559e-01, time/batch = 0.6537s	
4184/22300 (epoch 9.381), train_loss = 1.26915612, grad/param norm = 2.9929e-01, time/batch = 0.6579s	
4185/22300 (epoch 9.383), train_loss = 1.06874124, grad/param norm = 2.6894e-01, time/batch = 0.6532s	
4186/22300 (epoch 9.386), train_loss = 1.13016650, grad/param norm = 2.7113e-01, time/batch = 0.6514s	
4187/22300 (epoch 9.388), train_loss = 1.06231642, grad/param norm = 2.5152e-01, time/batch = 0.6476s	
4188/22300 (epoch 9.390), train_loss = 1.11569272, grad/param norm = 2.4688e-01, time/batch = 0.6494s	
4189/22300 (epoch 9.392), train_loss = 1.09753622, grad/param norm = 2.6515e-01, time/batch = 0.6553s	
4190/22300 (epoch 9.395), train_loss = 1.05309701, grad/param norm = 2.8434e-01, time/batch = 0.6469s	
4191/22300 (epoch 9.397), train_loss = 0.83021435, grad/param norm = 2.3614e-01, time/batch = 0.6490s	
4192/22300 (epoch 9.399), train_loss = 1.03833006, grad/param norm = 2.5159e-01, time/batch = 0.6540s	
4193/22300 (epoch 9.401), train_loss = 1.06614216, grad/param norm = 2.6138e-01, time/batch = 0.6484s	
4194/22300 (epoch 9.404), train_loss = 1.07058818, grad/param norm = 2.6967e-01, time/batch = 0.6526s	
4195/22300 (epoch 9.406), train_loss = 1.37134863, grad/param norm = 3.0051e-01, time/batch = 0.6518s	
4196/22300 (epoch 9.408), train_loss = 1.15826007, grad/param norm = 2.5403e-01, time/batch = 0.6489s	
4197/22300 (epoch 9.410), train_loss = 1.18890565, grad/param norm = 2.5879e-01, time/batch = 0.6482s	
4198/22300 (epoch 9.413), train_loss = 1.08767526, grad/param norm = 2.4737e-01, time/batch = 0.6454s	
4199/22300 (epoch 9.415), train_loss = 1.01652521, grad/param norm = 2.4649e-01, time/batch = 0.6584s	
4200/22300 (epoch 9.417), train_loss = 1.12901539, grad/param norm = 2.5383e-01, time/batch = 0.6559s	
4201/22300 (epoch 9.419), train_loss = 1.05083007, grad/param norm = 2.3971e-01, time/batch = 0.6536s	
4202/22300 (epoch 9.422), train_loss = 1.11780155, grad/param norm = 2.5180e-01, time/batch = 0.6524s	
4203/22300 (epoch 9.424), train_loss = 1.18087607, grad/param norm = 2.6180e-01, time/batch = 0.6505s	
4204/22300 (epoch 9.426), train_loss = 1.02219543, grad/param norm = 2.6469e-01, time/batch = 0.6470s	
4205/22300 (epoch 9.428), train_loss = 1.12202092, grad/param norm = 2.4392e-01, time/batch = 0.6488s	
4206/22300 (epoch 9.430), train_loss = 1.12165869, grad/param norm = 2.8081e-01, time/batch = 0.6496s	
4207/22300 (epoch 9.433), train_loss = 1.09256385, grad/param norm = 2.4344e-01, time/batch = 0.6520s	
4208/22300 (epoch 9.435), train_loss = 1.18639773, grad/param norm = 2.7214e-01, time/batch = 0.6492s	
4209/22300 (epoch 9.437), train_loss = 1.12371384, grad/param norm = 2.7235e-01, time/batch = 0.6438s	
4210/22300 (epoch 9.439), train_loss = 1.13639251, grad/param norm = 2.4891e-01, time/batch = 0.6528s	
4211/22300 (epoch 9.442), train_loss = 1.15728826, grad/param norm = 2.5539e-01, time/batch = 0.6559s	
4212/22300 (epoch 9.444), train_loss = 1.07859615, grad/param norm = 2.1609e-01, time/batch = 0.6465s	
4213/22300 (epoch 9.446), train_loss = 0.95489361, grad/param norm = 2.3035e-01, time/batch = 0.6510s	
4214/22300 (epoch 9.448), train_loss = 0.84743915, grad/param norm = 2.0052e-01, time/batch = 0.6516s	
4215/22300 (epoch 9.451), train_loss = 1.23155090, grad/param norm = 2.5865e-01, time/batch = 0.6570s	
4216/22300 (epoch 9.453), train_loss = 1.03874690, grad/param norm = 2.5014e-01, time/batch = 0.6557s	
4217/22300 (epoch 9.455), train_loss = 1.30431970, grad/param norm = 3.2644e-01, time/batch = 0.6487s	
4218/22300 (epoch 9.457), train_loss = 1.20343456, grad/param norm = 2.6476e-01, time/batch = 0.6449s	
4219/22300 (epoch 9.460), train_loss = 1.13068413, grad/param norm = 2.6998e-01, time/batch = 0.6462s	
4220/22300 (epoch 9.462), train_loss = 1.20645847, grad/param norm = 2.5421e-01, time/batch = 0.6534s	
4221/22300 (epoch 9.464), train_loss = 1.18303091, grad/param norm = 2.7563e-01, time/batch = 0.6521s	
4222/22300 (epoch 9.466), train_loss = 1.10496173, grad/param norm = 2.4319e-01, time/batch = 0.6543s	
4223/22300 (epoch 9.469), train_loss = 1.02713611, grad/param norm = 2.3924e-01, time/batch = 0.6524s	
4224/22300 (epoch 9.471), train_loss = 1.21130798, grad/param norm = 2.4903e-01, time/batch = 0.6507s	
4225/22300 (epoch 9.473), train_loss = 1.23121342, grad/param norm = 2.5332e-01, time/batch = 0.6530s	
4226/22300 (epoch 9.475), train_loss = 1.07305034, grad/param norm = 2.6341e-01, time/batch = 0.6572s	
4227/22300 (epoch 9.478), train_loss = 1.04285377, grad/param norm = 2.7994e-01, time/batch = 0.6602s	
4228/22300 (epoch 9.480), train_loss = 0.93813785, grad/param norm = 2.5082e-01, time/batch = 0.6635s	
4229/22300 (epoch 9.482), train_loss = 0.96922082, grad/param norm = 2.4418e-01, time/batch = 0.6589s	
4230/22300 (epoch 9.484), train_loss = 1.05705796, grad/param norm = 2.4797e-01, time/batch = 0.6554s	
4231/22300 (epoch 9.487), train_loss = 1.11099418, grad/param norm = 2.4970e-01, time/batch = 0.6484s	
4232/22300 (epoch 9.489), train_loss = 1.20713212, grad/param norm = 2.5985e-01, time/batch = 0.6469s	
4233/22300 (epoch 9.491), train_loss = 1.10010569, grad/param norm = 2.5079e-01, time/batch = 0.6498s	
4234/22300 (epoch 9.493), train_loss = 1.22280379, grad/param norm = 3.0012e-01, time/batch = 0.6553s	
4235/22300 (epoch 9.496), train_loss = 1.06411383, grad/param norm = 2.5412e-01, time/batch = 0.6692s	
4236/22300 (epoch 9.498), train_loss = 1.03042905, grad/param norm = 2.8705e-01, time/batch = 0.6496s	
4237/22300 (epoch 9.500), train_loss = 1.10085164, grad/param norm = 2.5507e-01, time/batch = 0.6633s	
4238/22300 (epoch 9.502), train_loss = 0.97660279, grad/param norm = 2.5147e-01, time/batch = 0.6666s	
4239/22300 (epoch 9.504), train_loss = 0.99635978, grad/param norm = 2.4357e-01, time/batch = 0.6654s	
4240/22300 (epoch 9.507), train_loss = 1.07649604, grad/param norm = 2.4462e-01, time/batch = 0.6559s	
4241/22300 (epoch 9.509), train_loss = 1.19981302, grad/param norm = 2.5150e-01, time/batch = 0.6558s	
4242/22300 (epoch 9.511), train_loss = 0.91803562, grad/param norm = 2.4613e-01, time/batch = 0.6507s	
4243/22300 (epoch 9.513), train_loss = 0.91051184, grad/param norm = 2.3309e-01, time/batch = 0.6637s	
4244/22300 (epoch 9.516), train_loss = 1.05908389, grad/param norm = 2.5735e-01, time/batch = 0.6629s	
4245/22300 (epoch 9.518), train_loss = 1.15500124, grad/param norm = 2.5031e-01, time/batch = 0.6565s	
4246/22300 (epoch 9.520), train_loss = 1.12844271, grad/param norm = 2.6009e-01, time/batch = 0.6494s	
4247/22300 (epoch 9.522), train_loss = 1.03329827, grad/param norm = 2.3914e-01, time/batch = 0.6538s	
4248/22300 (epoch 9.525), train_loss = 0.98518996, grad/param norm = 2.4068e-01, time/batch = 0.6510s	
4249/22300 (epoch 9.527), train_loss = 1.23632577, grad/param norm = 2.7154e-01, time/batch = 0.6541s	
4250/22300 (epoch 9.529), train_loss = 1.02854485, grad/param norm = 2.7576e-01, time/batch = 0.6460s	
4251/22300 (epoch 9.531), train_loss = 1.06783142, grad/param norm = 2.4196e-01, time/batch = 0.6465s	
4252/22300 (epoch 9.534), train_loss = 0.96880413, grad/param norm = 2.3680e-01, time/batch = 0.6522s	
4253/22300 (epoch 9.536), train_loss = 1.23165440, grad/param norm = 2.5490e-01, time/batch = 0.6514s	
4254/22300 (epoch 9.538), train_loss = 1.42734616, grad/param norm = 2.6059e-01, time/batch = 0.6507s	
4255/22300 (epoch 9.540), train_loss = 1.16354042, grad/param norm = 2.7398e-01, time/batch = 0.6546s	
4256/22300 (epoch 9.543), train_loss = 0.95681071, grad/param norm = 2.0813e-01, time/batch = 0.6581s	
4257/22300 (epoch 9.545), train_loss = 1.03999306, grad/param norm = 2.6597e-01, time/batch = 0.6531s	
4258/22300 (epoch 9.547), train_loss = 0.93552973, grad/param norm = 2.1601e-01, time/batch = 0.6562s	
4259/22300 (epoch 9.549), train_loss = 1.02686027, grad/param norm = 2.5869e-01, time/batch = 0.6526s	
4260/22300 (epoch 9.552), train_loss = 0.98478845, grad/param norm = 2.6259e-01, time/batch = 0.6615s	
4261/22300 (epoch 9.554), train_loss = 1.07640789, grad/param norm = 2.7956e-01, time/batch = 0.6803s	
4262/22300 (epoch 9.556), train_loss = 1.23948451, grad/param norm = 2.5369e-01, time/batch = 0.6654s	
4263/22300 (epoch 9.558), train_loss = 1.14368210, grad/param norm = 2.9624e-01, time/batch = 0.6542s	
4264/22300 (epoch 9.561), train_loss = 1.28888972, grad/param norm = 2.8211e-01, time/batch = 0.6679s	
4265/22300 (epoch 9.563), train_loss = 1.12669389, grad/param norm = 2.4941e-01, time/batch = 0.6683s	
4266/22300 (epoch 9.565), train_loss = 1.07737145, grad/param norm = 2.4768e-01, time/batch = 0.6654s	
4267/22300 (epoch 9.567), train_loss = 1.05989105, grad/param norm = 2.3613e-01, time/batch = 0.6643s	
4268/22300 (epoch 9.570), train_loss = 1.32935696, grad/param norm = 2.8611e-01, time/batch = 0.6617s	
4269/22300 (epoch 9.572), train_loss = 1.19120263, grad/param norm = 2.8903e-01, time/batch = 0.6648s	
4270/22300 (epoch 9.574), train_loss = 1.05450912, grad/param norm = 2.1838e-01, time/batch = 0.6679s	
4271/22300 (epoch 9.576), train_loss = 0.90838846, grad/param norm = 2.0822e-01, time/batch = 0.6664s	
4272/22300 (epoch 9.578), train_loss = 0.80791235, grad/param norm = 2.0476e-01, time/batch = 0.6698s	
4273/22300 (epoch 9.581), train_loss = 0.93691973, grad/param norm = 2.0910e-01, time/batch = 0.6745s	
4274/22300 (epoch 9.583), train_loss = 0.93079660, grad/param norm = 2.2501e-01, time/batch = 0.6678s	
4275/22300 (epoch 9.585), train_loss = 1.24788757, grad/param norm = 2.6771e-01, time/batch = 0.6597s	
4276/22300 (epoch 9.587), train_loss = 1.32632496, grad/param norm = 2.7533e-01, time/batch = 0.6635s	
4277/22300 (epoch 9.590), train_loss = 1.23692404, grad/param norm = 2.9155e-01, time/batch = 0.6755s	
4278/22300 (epoch 9.592), train_loss = 1.32221901, grad/param norm = 2.4872e-01, time/batch = 0.6757s	
4279/22300 (epoch 9.594), train_loss = 1.31362881, grad/param norm = 2.8071e-01, time/batch = 0.6847s	
4280/22300 (epoch 9.596), train_loss = 1.02770821, grad/param norm = 2.5269e-01, time/batch = 0.6662s	
4281/22300 (epoch 9.599), train_loss = 0.90907315, grad/param norm = 2.2511e-01, time/batch = 0.6804s	
4282/22300 (epoch 9.601), train_loss = 1.08698964, grad/param norm = 2.4914e-01, time/batch = 0.6715s	
4283/22300 (epoch 9.603), train_loss = 1.10846277, grad/param norm = 2.5634e-01, time/batch = 0.6676s	
4284/22300 (epoch 9.605), train_loss = 1.02205278, grad/param norm = 2.6392e-01, time/batch = 0.6715s	
4285/22300 (epoch 9.608), train_loss = 1.31968606, grad/param norm = 2.8481e-01, time/batch = 0.6761s	
4286/22300 (epoch 9.610), train_loss = 1.38975008, grad/param norm = 2.7728e-01, time/batch = 0.6817s	
4287/22300 (epoch 9.612), train_loss = 1.22006687, grad/param norm = 2.7190e-01, time/batch = 0.6559s	
4288/22300 (epoch 9.614), train_loss = 1.19498896, grad/param norm = 2.6519e-01, time/batch = 0.6602s	
4289/22300 (epoch 9.617), train_loss = 1.17859411, grad/param norm = 2.6962e-01, time/batch = 0.6801s	
4290/22300 (epoch 9.619), train_loss = 1.45423739, grad/param norm = 2.8768e-01, time/batch = 0.6696s	
4291/22300 (epoch 9.621), train_loss = 1.05926984, grad/param norm = 2.5425e-01, time/batch = 0.6678s	
4292/22300 (epoch 9.623), train_loss = 1.07849312, grad/param norm = 2.7200e-01, time/batch = 0.6810s	
4293/22300 (epoch 9.626), train_loss = 0.99167465, grad/param norm = 2.3126e-01, time/batch = 0.6822s	
4294/22300 (epoch 9.628), train_loss = 1.00275257, grad/param norm = 2.5143e-01, time/batch = 0.6820s	
4295/22300 (epoch 9.630), train_loss = 1.08417057, grad/param norm = 2.3639e-01, time/batch = 0.6825s	
4296/22300 (epoch 9.632), train_loss = 1.07338720, grad/param norm = 2.2749e-01, time/batch = 0.6802s	
4297/22300 (epoch 9.635), train_loss = 1.05961929, grad/param norm = 2.5283e-01, time/batch = 0.6825s	
4298/22300 (epoch 9.637), train_loss = 1.24715702, grad/param norm = 2.7371e-01, time/batch = 0.6809s	
4299/22300 (epoch 9.639), train_loss = 1.23045967, grad/param norm = 2.9832e-01, time/batch = 0.6802s	
4300/22300 (epoch 9.641), train_loss = 1.15226603, grad/param norm = 2.6217e-01, time/batch = 0.6838s	
4301/22300 (epoch 9.643), train_loss = 1.09180299, grad/param norm = 2.6937e-01, time/batch = 0.7033s	
4302/22300 (epoch 9.646), train_loss = 1.04353685, grad/param norm = 2.9121e-01, time/batch = 0.6954s	
4303/22300 (epoch 9.648), train_loss = 1.03508370, grad/param norm = 2.3123e-01, time/batch = 0.6956s	
4304/22300 (epoch 9.650), train_loss = 1.19264788, grad/param norm = 2.4689e-01, time/batch = 0.6925s	
4305/22300 (epoch 9.652), train_loss = 1.04104385, grad/param norm = 2.4103e-01, time/batch = 0.6938s	
4306/22300 (epoch 9.655), train_loss = 1.16074286, grad/param norm = 2.7972e-01, time/batch = 0.6975s	
4307/22300 (epoch 9.657), train_loss = 1.13410829, grad/param norm = 2.7719e-01, time/batch = 0.6963s	
4308/22300 (epoch 9.659), train_loss = 1.02752169, grad/param norm = 2.8254e-01, time/batch = 0.6934s	
4309/22300 (epoch 9.661), train_loss = 0.90996368, grad/param norm = 2.4758e-01, time/batch = 0.6934s	
4310/22300 (epoch 9.664), train_loss = 1.06285912, grad/param norm = 2.5520e-01, time/batch = 0.6920s	
4311/22300 (epoch 9.666), train_loss = 1.13947285, grad/param norm = 2.7393e-01, time/batch = 0.6899s	
4312/22300 (epoch 9.668), train_loss = 1.02990321, grad/param norm = 2.5443e-01, time/batch = 0.6890s	
4313/22300 (epoch 9.670), train_loss = 1.16990114, grad/param norm = 2.5422e-01, time/batch = 0.6821s	
4314/22300 (epoch 9.673), train_loss = 1.20652801, grad/param norm = 2.6486e-01, time/batch = 0.6835s	
4315/22300 (epoch 9.675), train_loss = 1.30443500, grad/param norm = 3.0095e-01, time/batch = 0.6847s	
4316/22300 (epoch 9.677), train_loss = 1.31796108, grad/param norm = 2.8232e-01, time/batch = 0.6843s	
4317/22300 (epoch 9.679), train_loss = 1.23151484, grad/param norm = 2.6968e-01, time/batch = 0.7015s	
4318/22300 (epoch 9.682), train_loss = 1.16904150, grad/param norm = 2.6361e-01, time/batch = 0.6865s	
4319/22300 (epoch 9.684), train_loss = 1.13305799, grad/param norm = 2.5551e-01, time/batch = 0.6986s	
4320/22300 (epoch 9.686), train_loss = 1.19237741, grad/param norm = 2.8940e-01, time/batch = 0.7103s	
4321/22300 (epoch 9.688), train_loss = 1.16868647, grad/param norm = 2.7628e-01, time/batch = 0.6932s	
4322/22300 (epoch 9.691), train_loss = 1.07976027, grad/param norm = 2.7194e-01, time/batch = 0.6821s	
4323/22300 (epoch 9.693), train_loss = 1.11182319, grad/param norm = 2.6634e-01, time/batch = 0.6833s	
4324/22300 (epoch 9.695), train_loss = 0.89654450, grad/param norm = 2.5129e-01, time/batch = 0.6825s	
4325/22300 (epoch 9.697), train_loss = 0.89466380, grad/param norm = 2.3494e-01, time/batch = 0.6845s	
4326/22300 (epoch 9.700), train_loss = 1.07015786, grad/param norm = 2.5413e-01, time/batch = 0.6823s	
4327/22300 (epoch 9.702), train_loss = 1.14438943, grad/param norm = 2.6932e-01, time/batch = 0.6816s	
4328/22300 (epoch 9.704), train_loss = 1.20868961, grad/param norm = 2.8650e-01, time/batch = 0.7178s	
4329/22300 (epoch 9.706), train_loss = 1.00156282, grad/param norm = 2.6387e-01, time/batch = 0.6829s	
4330/22300 (epoch 9.709), train_loss = 0.92458926, grad/param norm = 2.2505e-01, time/batch = 0.6902s	
4331/22300 (epoch 9.711), train_loss = 0.99809311, grad/param norm = 2.4663e-01, time/batch = 0.6871s	
4332/22300 (epoch 9.713), train_loss = 1.17404459, grad/param norm = 2.7035e-01, time/batch = 0.6883s	
4333/22300 (epoch 9.715), train_loss = 1.15062520, grad/param norm = 2.7465e-01, time/batch = 0.7050s	
4334/22300 (epoch 9.717), train_loss = 1.34253751, grad/param norm = 2.9854e-01, time/batch = 0.7065s	
4335/22300 (epoch 9.720), train_loss = 1.05461016, grad/param norm = 2.5022e-01, time/batch = 0.7056s	
4336/22300 (epoch 9.722), train_loss = 1.16967402, grad/param norm = 2.7952e-01, time/batch = 0.6998s	
4337/22300 (epoch 9.724), train_loss = 1.15347617, grad/param norm = 2.6262e-01, time/batch = 0.6879s	
4338/22300 (epoch 9.726), train_loss = 1.07856466, grad/param norm = 2.7059e-01, time/batch = 0.7058s	
4339/22300 (epoch 9.729), train_loss = 1.12770246, grad/param norm = 2.7543e-01, time/batch = 0.7015s	
4340/22300 (epoch 9.731), train_loss = 1.26503312, grad/param norm = 2.7999e-01, time/batch = 0.7045s	
4341/22300 (epoch 9.733), train_loss = 1.28411362, grad/param norm = 3.1523e-01, time/batch = 0.7077s	
4342/22300 (epoch 9.735), train_loss = 1.28889119, grad/param norm = 3.0124e-01, time/batch = 0.7159s	
4343/22300 (epoch 9.738), train_loss = 1.17891259, grad/param norm = 2.9595e-01, time/batch = 0.7032s	
4344/22300 (epoch 9.740), train_loss = 0.91992139, grad/param norm = 2.5035e-01, time/batch = 0.7042s	
4345/22300 (epoch 9.742), train_loss = 1.10745505, grad/param norm = 2.4709e-01, time/batch = 0.6994s	
4346/22300 (epoch 9.744), train_loss = 1.34335299, grad/param norm = 2.6954e-01, time/batch = 0.6997s	
4347/22300 (epoch 9.747), train_loss = 1.09780993, grad/param norm = 2.5178e-01, time/batch = 0.6986s	
4348/22300 (epoch 9.749), train_loss = 1.47048348, grad/param norm = 3.1386e-01, time/batch = 0.6993s	
4349/22300 (epoch 9.751), train_loss = 1.33338914, grad/param norm = 2.8109e-01, time/batch = 0.6985s	
4350/22300 (epoch 9.753), train_loss = 1.29037280, grad/param norm = 2.8859e-01, time/batch = 0.6980s	
4351/22300 (epoch 9.756), train_loss = 1.13034020, grad/param norm = 2.6925e-01, time/batch = 0.7018s	
4352/22300 (epoch 9.758), train_loss = 1.14624931, grad/param norm = 2.5719e-01, time/batch = 0.6999s	
4353/22300 (epoch 9.760), train_loss = 1.20715074, grad/param norm = 2.9452e-01, time/batch = 0.7015s	
4354/22300 (epoch 9.762), train_loss = 1.16439802, grad/param norm = 2.8194e-01, time/batch = 0.7004s	
4355/22300 (epoch 9.765), train_loss = 1.17066586, grad/param norm = 2.5717e-01, time/batch = 0.6992s	
4356/22300 (epoch 9.767), train_loss = 1.25763528, grad/param norm = 2.9616e-01, time/batch = 0.6987s	
4357/22300 (epoch 9.769), train_loss = 1.13685874, grad/param norm = 2.8617e-01, time/batch = 0.7007s	
4358/22300 (epoch 9.771), train_loss = 1.17435254, grad/param norm = 2.8350e-01, time/batch = 0.6998s	
4359/22300 (epoch 9.774), train_loss = 1.23526202, grad/param norm = 2.9110e-01, time/batch = 0.6980s	
4360/22300 (epoch 9.776), train_loss = 1.18303409, grad/param norm = 2.6345e-01, time/batch = 0.7001s	
4361/22300 (epoch 9.778), train_loss = 1.31458175, grad/param norm = 2.8227e-01, time/batch = 0.7034s	
4362/22300 (epoch 9.780), train_loss = 1.26646480, grad/param norm = 2.7687e-01, time/batch = 0.7042s	
4363/22300 (epoch 9.783), train_loss = 1.29523976, grad/param norm = 2.7909e-01, time/batch = 0.7014s	
4364/22300 (epoch 9.785), train_loss = 1.05860475, grad/param norm = 2.5377e-01, time/batch = 0.6985s	
4365/22300 (epoch 9.787), train_loss = 1.11196908, grad/param norm = 2.5023e-01, time/batch = 0.6985s	
4366/22300 (epoch 9.789), train_loss = 1.25576681, grad/param norm = 2.7465e-01, time/batch = 0.6966s	
4367/22300 (epoch 9.791), train_loss = 1.34604766, grad/param norm = 2.5683e-01, time/batch = 0.7001s	
4368/22300 (epoch 9.794), train_loss = 1.29389887, grad/param norm = 2.9226e-01, time/batch = 0.6998s	
4369/22300 (epoch 9.796), train_loss = 1.32215032, grad/param norm = 2.8256e-01, time/batch = 0.6986s	
4370/22300 (epoch 9.798), train_loss = 1.24812071, grad/param norm = 2.5692e-01, time/batch = 0.6984s	
4371/22300 (epoch 9.800), train_loss = 1.03614159, grad/param norm = 2.3005e-01, time/batch = 0.7103s	
4372/22300 (epoch 9.803), train_loss = 1.02924741, grad/param norm = 2.4025e-01, time/batch = 0.7101s	
4373/22300 (epoch 9.805), train_loss = 1.16437776, grad/param norm = 2.4410e-01, time/batch = 0.7018s	
4374/22300 (epoch 9.807), train_loss = 1.24560542, grad/param norm = 2.6817e-01, time/batch = 0.7018s	
4375/22300 (epoch 9.809), train_loss = 1.15493076, grad/param norm = 2.4949e-01, time/batch = 0.7054s	
4376/22300 (epoch 9.812), train_loss = 1.25268812, grad/param norm = 2.7244e-01, time/batch = 0.7026s	
4377/22300 (epoch 9.814), train_loss = 1.19496929, grad/param norm = 2.5535e-01, time/batch = 0.7010s	
4378/22300 (epoch 9.816), train_loss = 1.24275417, grad/param norm = 2.6460e-01, time/batch = 0.7005s	
4379/22300 (epoch 9.818), train_loss = 1.24190852, grad/param norm = 2.6599e-01, time/batch = 0.7002s	
4380/22300 (epoch 9.821), train_loss = 1.32062941, grad/param norm = 2.9849e-01, time/batch = 0.7076s	
4381/22300 (epoch 9.823), train_loss = 1.06118255, grad/param norm = 2.4440e-01, time/batch = 0.7057s	
4382/22300 (epoch 9.825), train_loss = 1.13757329, grad/param norm = 2.5502e-01, time/batch = 0.7013s	
4383/22300 (epoch 9.827), train_loss = 1.15086070, grad/param norm = 2.6413e-01, time/batch = 0.7012s	
4384/22300 (epoch 9.830), train_loss = 1.05890201, grad/param norm = 2.4547e-01, time/batch = 0.6994s	
4385/22300 (epoch 9.832), train_loss = 1.06861392, grad/param norm = 2.5952e-01, time/batch = 0.7192s	
4386/22300 (epoch 9.834), train_loss = 1.15951471, grad/param norm = 2.7879e-01, time/batch = 0.6983s	
4387/22300 (epoch 9.836), train_loss = 1.10728110, grad/param norm = 2.4065e-01, time/batch = 0.6986s	
4388/22300 (epoch 9.839), train_loss = 1.14684061, grad/param norm = 2.5989e-01, time/batch = 0.7000s	
4389/22300 (epoch 9.841), train_loss = 1.12485598, grad/param norm = 2.6300e-01, time/batch = 0.6993s	
4390/22300 (epoch 9.843), train_loss = 1.15552530, grad/param norm = 2.9933e-01, time/batch = 0.7018s	
4391/22300 (epoch 9.845), train_loss = 1.11592006, grad/param norm = 2.5047e-01, time/batch = 0.7037s	
4392/22300 (epoch 9.848), train_loss = 1.11556813, grad/param norm = 2.4174e-01, time/batch = 0.6996s	
4393/22300 (epoch 9.850), train_loss = 1.16281485, grad/param norm = 2.6227e-01, time/batch = 0.6989s	
4394/22300 (epoch 9.852), train_loss = 1.16219270, grad/param norm = 2.6346e-01, time/batch = 0.6932s	
4395/22300 (epoch 9.854), train_loss = 1.30418214, grad/param norm = 2.8980e-01, time/batch = 0.6941s	
4396/22300 (epoch 9.857), train_loss = 1.11907781, grad/param norm = 2.7825e-01, time/batch = 0.7001s	
4397/22300 (epoch 9.859), train_loss = 0.96762620, grad/param norm = 2.3300e-01, time/batch = 0.6977s	
4398/22300 (epoch 9.861), train_loss = 1.15327135, grad/param norm = 2.4794e-01, time/batch = 0.6989s	
4399/22300 (epoch 9.863), train_loss = 0.96070087, grad/param norm = 2.3720e-01, time/batch = 0.7041s	
4400/22300 (epoch 9.865), train_loss = 1.03022858, grad/param norm = 2.3838e-01, time/batch = 0.7002s	
4401/22300 (epoch 9.868), train_loss = 1.08150286, grad/param norm = 2.2744e-01, time/batch = 0.7068s	
4402/22300 (epoch 9.870), train_loss = 1.12934154, grad/param norm = 2.6528e-01, time/batch = 0.7152s	
4403/22300 (epoch 9.872), train_loss = 1.21213797, grad/param norm = 2.7749e-01, time/batch = 0.6881s	
4404/22300 (epoch 9.874), train_loss = 1.16656157, grad/param norm = 2.6485e-01, time/batch = 0.6874s	
4405/22300 (epoch 9.877), train_loss = 1.12566117, grad/param norm = 2.3130e-01, time/batch = 0.6834s	
4406/22300 (epoch 9.879), train_loss = 1.01537971, grad/param norm = 2.6156e-01, time/batch = 0.6820s	
4407/22300 (epoch 9.881), train_loss = 1.11513010, grad/param norm = 2.9582e-01, time/batch = 0.6826s	
4408/22300 (epoch 9.883), train_loss = 1.05638568, grad/param norm = 2.4080e-01, time/batch = 0.6820s	
4409/22300 (epoch 9.886), train_loss = 1.08176389, grad/param norm = 2.3654e-01, time/batch = 0.6821s	
4410/22300 (epoch 9.888), train_loss = 1.09061768, grad/param norm = 2.6196e-01, time/batch = 0.6969s	
4411/22300 (epoch 9.890), train_loss = 1.00701883, grad/param norm = 2.2339e-01, time/batch = 0.7087s	
4412/22300 (epoch 9.892), train_loss = 1.27378690, grad/param norm = 2.7609e-01, time/batch = 0.7315s	
4413/22300 (epoch 9.895), train_loss = 1.26629346, grad/param norm = 2.8100e-01, time/batch = 0.7255s	
4414/22300 (epoch 9.897), train_loss = 1.15305331, grad/param norm = 2.5822e-01, time/batch = 0.7099s	
4415/22300 (epoch 9.899), train_loss = 1.17836613, grad/param norm = 2.5077e-01, time/batch = 0.7150s	
4416/22300 (epoch 9.901), train_loss = 1.09139524, grad/param norm = 2.4090e-01, time/batch = 0.7090s	
4417/22300 (epoch 9.904), train_loss = 1.16627584, grad/param norm = 2.6434e-01, time/batch = 0.6908s	
4418/22300 (epoch 9.906), train_loss = 1.24742600, grad/param norm = 2.7367e-01, time/batch = 0.6844s	
4419/22300 (epoch 9.908), train_loss = 1.14108615, grad/param norm = 2.4936e-01, time/batch = 0.6814s	
4420/22300 (epoch 9.910), train_loss = 0.99275932, grad/param norm = 2.5580e-01, time/batch = 0.6830s	
4421/22300 (epoch 9.913), train_loss = 1.14229680, grad/param norm = 2.6052e-01, time/batch = 0.6821s	
4422/22300 (epoch 9.915), train_loss = 1.33833185, grad/param norm = 2.8461e-01, time/batch = 0.6820s	
4423/22300 (epoch 9.917), train_loss = 1.13262852, grad/param norm = 2.6798e-01, time/batch = 0.6803s	
4424/22300 (epoch 9.919), train_loss = 1.16659626, grad/param norm = 2.6454e-01, time/batch = 0.6919s	
4425/22300 (epoch 9.922), train_loss = 1.14041858, grad/param norm = 2.6942e-01, time/batch = 0.6944s	
4426/22300 (epoch 9.924), train_loss = 0.90279909, grad/param norm = 2.0986e-01, time/batch = 0.6947s	
4427/22300 (epoch 9.926), train_loss = 0.92101890, grad/param norm = 2.2073e-01, time/batch = 0.6940s	
4428/22300 (epoch 9.928), train_loss = 1.10643769, grad/param norm = 2.3967e-01, time/batch = 0.6943s	
4429/22300 (epoch 9.930), train_loss = 1.11779912, grad/param norm = 2.5941e-01, time/batch = 0.6932s	
4430/22300 (epoch 9.933), train_loss = 1.19183074, grad/param norm = 2.5523e-01, time/batch = 0.6920s	
4431/22300 (epoch 9.935), train_loss = 1.27460935, grad/param norm = 2.7033e-01, time/batch = 0.6999s	
4432/22300 (epoch 9.937), train_loss = 1.28615350, grad/param norm = 2.8856e-01, time/batch = 0.6954s	
4433/22300 (epoch 9.939), train_loss = 1.24158696, grad/param norm = 3.0217e-01, time/batch = 0.6933s	
4434/22300 (epoch 9.942), train_loss = 1.36812960, grad/param norm = 2.8853e-01, time/batch = 0.6960s	
4435/22300 (epoch 9.944), train_loss = 1.40559743, grad/param norm = 2.9515e-01, time/batch = 0.6965s	
4436/22300 (epoch 9.946), train_loss = 1.08784181, grad/param norm = 2.9035e-01, time/batch = 0.6962s	
4437/22300 (epoch 9.948), train_loss = 1.09222943, grad/param norm = 2.5691e-01, time/batch = 0.6954s	
4438/22300 (epoch 9.951), train_loss = 0.96082658, grad/param norm = 2.5018e-01, time/batch = 0.6956s	
4439/22300 (epoch 9.953), train_loss = 1.04499436, grad/param norm = 2.6016e-01, time/batch = 0.6942s	
4440/22300 (epoch 9.955), train_loss = 1.37125043, grad/param norm = 2.9079e-01, time/batch = 0.6943s	
4441/22300 (epoch 9.957), train_loss = 1.46019740, grad/param norm = 3.0009e-01, time/batch = 0.6982s	
4442/22300 (epoch 9.960), train_loss = 1.29324164, grad/param norm = 2.7990e-01, time/batch = 0.6993s	
4443/22300 (epoch 9.962), train_loss = 1.16874906, grad/param norm = 2.4496e-01, time/batch = 0.6983s	
4444/22300 (epoch 9.964), train_loss = 1.10758799, grad/param norm = 2.3550e-01, time/batch = 0.6958s	
4445/22300 (epoch 9.966), train_loss = 1.09940596, grad/param norm = 2.7231e-01, time/batch = 0.6958s	
4446/22300 (epoch 9.969), train_loss = 1.03079318, grad/param norm = 2.1292e-01, time/batch = 0.6982s	
4447/22300 (epoch 9.971), train_loss = 1.09088637, grad/param norm = 2.4160e-01, time/batch = 0.6969s	
4448/22300 (epoch 9.973), train_loss = 1.12977791, grad/param norm = 2.5423e-01, time/batch = 0.6950s	
4449/22300 (epoch 9.975), train_loss = 1.43329341, grad/param norm = 2.9031e-01, time/batch = 0.6979s	
4450/22300 (epoch 9.978), train_loss = 1.14434286, grad/param norm = 2.4633e-01, time/batch = 0.6944s	
4451/22300 (epoch 9.980), train_loss = 1.20741641, grad/param norm = 2.5765e-01, time/batch = 0.7035s	
4452/22300 (epoch 9.982), train_loss = 1.02439296, grad/param norm = 2.3616e-01, time/batch = 0.6908s	
4453/22300 (epoch 9.984), train_loss = 1.19668898, grad/param norm = 2.5100e-01, time/batch = 0.6896s	
4454/22300 (epoch 9.987), train_loss = 1.05477079, grad/param norm = 2.2661e-01, time/batch = 0.6949s	
4455/22300 (epoch 9.989), train_loss = 1.13429151, grad/param norm = 2.7619e-01, time/batch = 0.6998s	
4456/22300 (epoch 9.991), train_loss = 1.37292240, grad/param norm = 3.0050e-01, time/batch = 0.6942s	
4457/22300 (epoch 9.993), train_loss = 1.41894311, grad/param norm = 2.7705e-01, time/batch = 0.6966s	
4458/22300 (epoch 9.996), train_loss = 1.41011560, grad/param norm = 3.1744e-01, time/batch = 0.6951s	
4459/22300 (epoch 9.998), train_loss = 1.10761712, grad/param norm = 2.6793e-01, time/batch = 0.6976s	
decayed learning rate by a factor 0.97 to 0.00194	
4460/22300 (epoch 10.000), train_loss = 0.98214132, grad/param norm = 2.3417e-01, time/batch = 0.6980s	
4461/22300 (epoch 10.002), train_loss = 1.29828774, grad/param norm = 2.8201e-01, time/batch = 0.6974s	
4462/22300 (epoch 10.004), train_loss = 1.14524406, grad/param norm = 2.3119e-01, time/batch = 0.6966s	
4463/22300 (epoch 10.007), train_loss = 1.14723000, grad/param norm = 2.5219e-01, time/batch = 0.6975s	
4464/22300 (epoch 10.009), train_loss = 1.16632210, grad/param norm = 2.6841e-01, time/batch = 0.6955s	
4465/22300 (epoch 10.011), train_loss = 1.32755668, grad/param norm = 2.7209e-01, time/batch = 0.6953s	
4466/22300 (epoch 10.013), train_loss = 1.08447944, grad/param norm = 2.8039e-01, time/batch = 0.6984s	
4467/22300 (epoch 10.016), train_loss = 1.12848813, grad/param norm = 2.9196e-01, time/batch = 0.6973s	
4468/22300 (epoch 10.018), train_loss = 1.25528837, grad/param norm = 2.7858e-01, time/batch = 0.6962s	
4469/22300 (epoch 10.020), train_loss = 1.11512080, grad/param norm = 2.5536e-01, time/batch = 0.6965s	
4470/22300 (epoch 10.022), train_loss = 1.07367088, grad/param norm = 2.6511e-01, time/batch = 0.6971s	
4471/22300 (epoch 10.025), train_loss = 1.06508380, grad/param norm = 2.3034e-01, time/batch = 0.6888s	
4472/22300 (epoch 10.027), train_loss = 1.15594145, grad/param norm = 2.5017e-01, time/batch = 0.6800s	
4473/22300 (epoch 10.029), train_loss = 1.04884290, grad/param norm = 2.6139e-01, time/batch = 0.6938s	
4474/22300 (epoch 10.031), train_loss = 0.98788260, grad/param norm = 2.1901e-01, time/batch = 0.6973s	
4475/22300 (epoch 10.034), train_loss = 1.04747884, grad/param norm = 2.5692e-01, time/batch = 0.6957s	
4476/22300 (epoch 10.036), train_loss = 0.88127897, grad/param norm = 2.2087e-01, time/batch = 0.6991s	
4477/22300 (epoch 10.038), train_loss = 1.00377639, grad/param norm = 2.2828e-01, time/batch = 0.6967s	
4478/22300 (epoch 10.040), train_loss = 1.13742947, grad/param norm = 2.6461e-01, time/batch = 0.6965s	
4479/22300 (epoch 10.043), train_loss = 1.32505268, grad/param norm = 2.8431e-01, time/batch = 0.6983s	
4480/22300 (epoch 10.045), train_loss = 1.15875944, grad/param norm = 2.4258e-01, time/batch = 0.6983s	
4481/22300 (epoch 10.047), train_loss = 1.22334704, grad/param norm = 2.7609e-01, time/batch = 0.6995s	
4482/22300 (epoch 10.049), train_loss = 1.06967989, grad/param norm = 2.5680e-01, time/batch = 0.7031s	
4483/22300 (epoch 10.052), train_loss = 1.19540871, grad/param norm = 2.6110e-01, time/batch = 0.6978s	
4484/22300 (epoch 10.054), train_loss = 1.16421341, grad/param norm = 2.7432e-01, time/batch = 0.7164s	
4485/22300 (epoch 10.056), train_loss = 0.91069128, grad/param norm = 2.6054e-01, time/batch = 0.7150s	
4486/22300 (epoch 10.058), train_loss = 0.98353424, grad/param norm = 2.4829e-01, time/batch = 0.7020s	
4487/22300 (epoch 10.061), train_loss = 1.01291057, grad/param norm = 2.6624e-01, time/batch = 0.7003s	
4488/22300 (epoch 10.063), train_loss = 1.31465136, grad/param norm = 3.0587e-01, time/batch = 0.7188s	
4489/22300 (epoch 10.065), train_loss = 1.20569456, grad/param norm = 2.7794e-01, time/batch = 0.7313s	
4490/22300 (epoch 10.067), train_loss = 1.03253232, grad/param norm = 2.2646e-01, time/batch = 0.7060s	
4491/22300 (epoch 10.070), train_loss = 1.07327422, grad/param norm = 2.5841e-01, time/batch = 0.7049s	
4492/22300 (epoch 10.072), train_loss = 1.14027932, grad/param norm = 2.6513e-01, time/batch = 0.7002s	
4493/22300 (epoch 10.074), train_loss = 1.14733170, grad/param norm = 2.4544e-01, time/batch = 0.7022s	
4494/22300 (epoch 10.076), train_loss = 1.08134483, grad/param norm = 2.5043e-01, time/batch = 0.6969s	
4495/22300 (epoch 10.078), train_loss = 1.16492579, grad/param norm = 2.6221e-01, time/batch = 0.6976s	
4496/22300 (epoch 10.081), train_loss = 1.21174305, grad/param norm = 2.6853e-01, time/batch = 0.6966s	
4497/22300 (epoch 10.083), train_loss = 1.28727221, grad/param norm = 3.0402e-01, time/batch = 0.6938s	
4498/22300 (epoch 10.085), train_loss = 1.36365212, grad/param norm = 2.7955e-01, time/batch = 0.6921s	
4499/22300 (epoch 10.087), train_loss = 1.17190267, grad/param norm = 2.6485e-01, time/batch = 0.6942s	
4500/22300 (epoch 10.090), train_loss = 0.98280431, grad/param norm = 2.4616e-01, time/batch = 0.6975s	
4501/22300 (epoch 10.092), train_loss = 1.01492829, grad/param norm = 2.6014e-01, time/batch = 0.7009s	
4502/22300 (epoch 10.094), train_loss = 0.98516418, grad/param norm = 2.4182e-01, time/batch = 0.6981s	
4503/22300 (epoch 10.096), train_loss = 1.28901379, grad/param norm = 2.7104e-01, time/batch = 0.6968s	
4504/22300 (epoch 10.099), train_loss = 1.11506083, grad/param norm = 2.5934e-01, time/batch = 0.6987s	
4505/22300 (epoch 10.101), train_loss = 1.25395947, grad/param norm = 2.6341e-01, time/batch = 0.7037s	
4506/22300 (epoch 10.103), train_loss = 1.17771359, grad/param norm = 2.4222e-01, time/batch = 0.6971s	
4507/22300 (epoch 10.105), train_loss = 1.14623859, grad/param norm = 2.7387e-01, time/batch = 0.6940s	
4508/22300 (epoch 10.108), train_loss = 1.15707041, grad/param norm = 2.5349e-01, time/batch = 0.6950s	
4509/22300 (epoch 10.110), train_loss = 1.15264010, grad/param norm = 2.5236e-01, time/batch = 0.6971s	
4510/22300 (epoch 10.112), train_loss = 1.09208886, grad/param norm = 2.3073e-01, time/batch = 0.7065s	
4511/22300 (epoch 10.114), train_loss = 1.21241440, grad/param norm = 2.5959e-01, time/batch = 0.6990s	
4512/22300 (epoch 10.117), train_loss = 1.37220534, grad/param norm = 2.7582e-01, time/batch = 0.6813s	
4513/22300 (epoch 10.119), train_loss = 1.19922023, grad/param norm = 2.6251e-01, time/batch = 0.6837s	
4514/22300 (epoch 10.121), train_loss = 1.30321117, grad/param norm = 2.8463e-01, time/batch = 0.6783s	
4515/22300 (epoch 10.123), train_loss = 1.14338820, grad/param norm = 2.5006e-01, time/batch = 0.6787s	
4516/22300 (epoch 10.126), train_loss = 1.08990070, grad/param norm = 2.4361e-01, time/batch = 0.6752s	
4517/22300 (epoch 10.128), train_loss = 1.22805254, grad/param norm = 2.3903e-01, time/batch = 0.6761s	
4518/22300 (epoch 10.130), train_loss = 1.12173437, grad/param norm = 2.6462e-01, time/batch = 0.6794s	
4519/22300 (epoch 10.132), train_loss = 0.99776095, grad/param norm = 2.3689e-01, time/batch = 0.6747s	
4520/22300 (epoch 10.135), train_loss = 0.99366106, grad/param norm = 2.3506e-01, time/batch = 0.6716s	
4521/22300 (epoch 10.137), train_loss = 0.80672691, grad/param norm = 2.0448e-01, time/batch = 0.6803s	
4522/22300 (epoch 10.139), train_loss = 1.18869667, grad/param norm = 2.6576e-01, time/batch = 0.6718s	
4523/22300 (epoch 10.141), train_loss = 1.20500962, grad/param norm = 2.5261e-01, time/batch = 0.6769s	
4524/22300 (epoch 10.143), train_loss = 1.16971278, grad/param norm = 2.5930e-01, time/batch = 0.6808s	
4525/22300 (epoch 10.146), train_loss = 1.30409245, grad/param norm = 2.7409e-01, time/batch = 0.6832s	
4526/22300 (epoch 10.148), train_loss = 1.04618755, grad/param norm = 2.5349e-01, time/batch = 0.6810s	
4527/22300 (epoch 10.150), train_loss = 1.07951756, grad/param norm = 2.6507e-01, time/batch = 0.6803s	
4528/22300 (epoch 10.152), train_loss = 1.04362590, grad/param norm = 2.7179e-01, time/batch = 0.6825s	
4529/22300 (epoch 10.155), train_loss = 1.07545085, grad/param norm = 2.6068e-01, time/batch = 0.7121s	
4530/22300 (epoch 10.157), train_loss = 1.29836339, grad/param norm = 3.0758e-01, time/batch = 0.6704s	
4531/22300 (epoch 10.159), train_loss = 1.19827739, grad/param norm = 2.6962e-01, time/batch = 0.6802s	
4532/22300 (epoch 10.161), train_loss = 1.25295033, grad/param norm = 2.7709e-01, time/batch = 0.6821s	
4533/22300 (epoch 10.164), train_loss = 1.00759695, grad/param norm = 2.3689e-01, time/batch = 0.7048s	
4534/22300 (epoch 10.166), train_loss = 0.98973685, grad/param norm = 1.9849e-01, time/batch = 0.6955s	
4535/22300 (epoch 10.168), train_loss = 1.05388702, grad/param norm = 2.3732e-01, time/batch = 0.6858s	
4536/22300 (epoch 10.170), train_loss = 1.09710075, grad/param norm = 2.2246e-01, time/batch = 0.6840s	
4537/22300 (epoch 10.173), train_loss = 1.33437192, grad/param norm = 2.7979e-01, time/batch = 0.6897s	
4538/22300 (epoch 10.175), train_loss = 1.07349886, grad/param norm = 2.5012e-01, time/batch = 0.6842s	
4539/22300 (epoch 10.177), train_loss = 0.93887868, grad/param norm = 2.2423e-01, time/batch = 0.6802s	
4540/22300 (epoch 10.179), train_loss = 1.06715769, grad/param norm = 2.4857e-01, time/batch = 0.6801s	
4541/22300 (epoch 10.182), train_loss = 1.30828093, grad/param norm = 2.7843e-01, time/batch = 0.6822s	
4542/22300 (epoch 10.184), train_loss = 1.36856944, grad/param norm = 2.7575e-01, time/batch = 0.6826s	
4543/22300 (epoch 10.186), train_loss = 1.18348214, grad/param norm = 2.7208e-01, time/batch = 0.6697s	
4544/22300 (epoch 10.188), train_loss = 1.29700067, grad/param norm = 2.7696e-01, time/batch = 0.6822s	
4545/22300 (epoch 10.191), train_loss = 1.30770901, grad/param norm = 2.6426e-01, time/batch = 0.6823s	
4546/22300 (epoch 10.193), train_loss = 1.10783430, grad/param norm = 2.5341e-01, time/batch = 0.6810s	
4547/22300 (epoch 10.195), train_loss = 1.03431773, grad/param norm = 2.4196e-01, time/batch = 0.6809s	
4548/22300 (epoch 10.197), train_loss = 1.11265933, grad/param norm = 2.4401e-01, time/batch = 0.6805s	
4549/22300 (epoch 10.200), train_loss = 1.02775317, grad/param norm = 2.6145e-01, time/batch = 0.6761s	
4550/22300 (epoch 10.202), train_loss = 1.08145759, grad/param norm = 2.4424e-01, time/batch = 0.6784s	
4551/22300 (epoch 10.204), train_loss = 1.05640625, grad/param norm = 2.3143e-01, time/batch = 0.6902s	
4552/22300 (epoch 10.206), train_loss = 0.97827791, grad/param norm = 2.1907e-01, time/batch = 0.7133s	
4553/22300 (epoch 10.209), train_loss = 1.12831502, grad/param norm = 2.7625e-01, time/batch = 0.7357s	
4554/22300 (epoch 10.211), train_loss = 0.94934475, grad/param norm = 2.4085e-01, time/batch = 0.7220s	
4555/22300 (epoch 10.213), train_loss = 1.03097977, grad/param norm = 2.3460e-01, time/batch = 0.7334s	
4556/22300 (epoch 10.215), train_loss = 1.28936247, grad/param norm = 2.5938e-01, time/batch = 0.7330s	
4557/22300 (epoch 10.217), train_loss = 1.22617163, grad/param norm = 2.6915e-01, time/batch = 0.7403s	
4558/22300 (epoch 10.220), train_loss = 1.11287353, grad/param norm = 2.4343e-01, time/batch = 0.7329s	
4559/22300 (epoch 10.222), train_loss = 1.04673139, grad/param norm = 2.6000e-01, time/batch = 0.7170s	
4560/22300 (epoch 10.224), train_loss = 0.97566774, grad/param norm = 2.3186e-01, time/batch = 0.7330s	
4561/22300 (epoch 10.226), train_loss = 1.07466906, grad/param norm = 2.2707e-01, time/batch = 0.7320s	
4562/22300 (epoch 10.229), train_loss = 1.08023289, grad/param norm = 2.5921e-01, time/batch = 0.6997s	
4563/22300 (epoch 10.231), train_loss = 1.19107579, grad/param norm = 2.7293e-01, time/batch = 0.7080s	
4564/22300 (epoch 10.233), train_loss = 1.17630682, grad/param norm = 2.4836e-01, time/batch = 0.7024s	
4565/22300 (epoch 10.235), train_loss = 0.97920982, grad/param norm = 2.3780e-01, time/batch = 0.7052s	
4566/22300 (epoch 10.238), train_loss = 0.98168632, grad/param norm = 2.3867e-01, time/batch = 0.6985s	
4567/22300 (epoch 10.240), train_loss = 0.95156712, grad/param norm = 2.2934e-01, time/batch = 0.6990s	
4568/22300 (epoch 10.242), train_loss = 1.01694302, grad/param norm = 2.3532e-01, time/batch = 0.6984s	
4569/22300 (epoch 10.244), train_loss = 0.79225383, grad/param norm = 2.1130e-01, time/batch = 0.6993s	
4570/22300 (epoch 10.247), train_loss = 1.01872176, grad/param norm = 2.5391e-01, time/batch = 0.7004s	
4571/22300 (epoch 10.249), train_loss = 0.92169180, grad/param norm = 2.4232e-01, time/batch = 0.7026s	
4572/22300 (epoch 10.251), train_loss = 0.95351600, grad/param norm = 2.1076e-01, time/batch = 0.7030s	
4573/22300 (epoch 10.253), train_loss = 0.91348609, grad/param norm = 2.3821e-01, time/batch = 0.7021s	
4574/22300 (epoch 10.256), train_loss = 1.00671059, grad/param norm = 2.2680e-01, time/batch = 0.7178s	
4575/22300 (epoch 10.258), train_loss = 1.28627275, grad/param norm = 2.8863e-01, time/batch = 0.6848s	
4576/22300 (epoch 10.260), train_loss = 1.11059985, grad/param norm = 2.7906e-01, time/batch = 0.7005s	
4577/22300 (epoch 10.262), train_loss = 1.01733678, grad/param norm = 2.4843e-01, time/batch = 0.6983s	
4578/22300 (epoch 10.265), train_loss = 1.03126930, grad/param norm = 2.6697e-01, time/batch = 0.6991s	
4579/22300 (epoch 10.267), train_loss = 1.06564978, grad/param norm = 2.4914e-01, time/batch = 0.7287s	
4580/22300 (epoch 10.269), train_loss = 1.06338143, grad/param norm = 2.5152e-01, time/batch = 0.7136s	
4581/22300 (epoch 10.271), train_loss = 1.01088880, grad/param norm = 2.4062e-01, time/batch = 0.7099s	
4582/22300 (epoch 10.274), train_loss = 0.89538750, grad/param norm = 2.2680e-01, time/batch = 0.7024s	
4583/22300 (epoch 10.276), train_loss = 0.84628159, grad/param norm = 2.1999e-01, time/batch = 0.6986s	
4584/22300 (epoch 10.278), train_loss = 0.79515278, grad/param norm = 2.0609e-01, time/batch = 0.6876s	
4585/22300 (epoch 10.280), train_loss = 0.96201214, grad/param norm = 2.4928e-01, time/batch = 0.6982s	
4586/22300 (epoch 10.283), train_loss = 0.78288330, grad/param norm = 1.9370e-01, time/batch = 0.7017s	
4587/22300 (epoch 10.285), train_loss = 1.01079988, grad/param norm = 2.5711e-01, time/batch = 0.6947s	
4588/22300 (epoch 10.287), train_loss = 1.11767495, grad/param norm = 2.7158e-01, time/batch = 0.6976s	
4589/22300 (epoch 10.289), train_loss = 0.97697144, grad/param norm = 2.4572e-01, time/batch = 0.6977s	
4590/22300 (epoch 10.291), train_loss = 1.07763337, grad/param norm = 2.4882e-01, time/batch = 0.7016s	
4591/22300 (epoch 10.294), train_loss = 0.91772420, grad/param norm = 2.1705e-01, time/batch = 0.7005s	
4592/22300 (epoch 10.296), train_loss = 1.17504468, grad/param norm = 2.6512e-01, time/batch = 0.7010s	
4593/22300 (epoch 10.298), train_loss = 1.18724195, grad/param norm = 2.5751e-01, time/batch = 0.6962s	
4594/22300 (epoch 10.300), train_loss = 1.23468439, grad/param norm = 2.8512e-01, time/batch = 0.6861s	
4595/22300 (epoch 10.303), train_loss = 1.04528490, grad/param norm = 2.4403e-01, time/batch = 0.6836s	
4596/22300 (epoch 10.305), train_loss = 1.11886413, grad/param norm = 2.9560e-01, time/batch = 0.6982s	
4597/22300 (epoch 10.307), train_loss = 1.04786003, grad/param norm = 2.7167e-01, time/batch = 0.7342s	
4598/22300 (epoch 10.309), train_loss = 1.04086832, grad/param norm = 2.7391e-01, time/batch = 0.6969s	
4599/22300 (epoch 10.312), train_loss = 0.95686236, grad/param norm = 2.4368e-01, time/batch = 0.7010s	
4600/22300 (epoch 10.314), train_loss = 1.03298844, grad/param norm = 2.3046e-01, time/batch = 0.7018s	
4601/22300 (epoch 10.316), train_loss = 1.04359132, grad/param norm = 2.7701e-01, time/batch = 0.7037s	
4602/22300 (epoch 10.318), train_loss = 1.08980012, grad/param norm = 2.5276e-01, time/batch = 0.6980s	
4603/22300 (epoch 10.321), train_loss = 1.11951713, grad/param norm = 2.4957e-01, time/batch = 0.6962s	
4604/22300 (epoch 10.323), train_loss = 1.04934138, grad/param norm = 2.5546e-01, time/batch = 0.6923s	
4605/22300 (epoch 10.325), train_loss = 0.94119175, grad/param norm = 2.4525e-01, time/batch = 0.6899s	
4606/22300 (epoch 10.327), train_loss = 1.00815082, grad/param norm = 2.6359e-01, time/batch = 0.6958s	
4607/22300 (epoch 10.330), train_loss = 1.04452171, grad/param norm = 2.6886e-01, time/batch = 0.6951s	
4608/22300 (epoch 10.332), train_loss = 0.93256063, grad/param norm = 2.6096e-01, time/batch = 0.6946s	
4609/22300 (epoch 10.334), train_loss = 0.90843037, grad/param norm = 2.2223e-01, time/batch = 0.6930s	
4610/22300 (epoch 10.336), train_loss = 1.00867802, grad/param norm = 2.5889e-01, time/batch = 0.6949s	
4611/22300 (epoch 10.339), train_loss = 1.09447433, grad/param norm = 2.7388e-01, time/batch = 0.6940s	
4612/22300 (epoch 10.341), train_loss = 1.14734079, grad/param norm = 3.0091e-01, time/batch = 0.6925s	
4613/22300 (epoch 10.343), train_loss = 1.19330119, grad/param norm = 2.6341e-01, time/batch = 0.6927s	
4614/22300 (epoch 10.345), train_loss = 1.07670146, grad/param norm = 2.8217e-01, time/batch = 0.6882s	
4615/22300 (epoch 10.348), train_loss = 1.04550103, grad/param norm = 2.5041e-01, time/batch = 0.6841s	
4616/22300 (epoch 10.350), train_loss = 0.90748830, grad/param norm = 2.1798e-01, time/batch = 0.6922s	
4617/22300 (epoch 10.352), train_loss = 1.16769480, grad/param norm = 2.5335e-01, time/batch = 0.6909s	
4618/22300 (epoch 10.354), train_loss = 1.28343118, grad/param norm = 2.6777e-01, time/batch = 0.6974s	
4619/22300 (epoch 10.357), train_loss = 1.20059174, grad/param norm = 2.6491e-01, time/batch = 0.6960s	
4620/22300 (epoch 10.359), train_loss = 1.05563033, grad/param norm = 2.5889e-01, time/batch = 0.6981s	
4621/22300 (epoch 10.361), train_loss = 1.10466997, grad/param norm = 2.5380e-01, time/batch = 0.6998s	
4622/22300 (epoch 10.363), train_loss = 1.22912376, grad/param norm = 2.5711e-01, time/batch = 0.6964s	
4623/22300 (epoch 10.365), train_loss = 1.12091421, grad/param norm = 2.6640e-01, time/batch = 0.6971s	
4624/22300 (epoch 10.368), train_loss = 1.15052667, grad/param norm = 2.9999e-01, time/batch = 0.6944s	
4625/22300 (epoch 10.370), train_loss = 1.11068264, grad/param norm = 2.8000e-01, time/batch = 0.6961s	
4626/22300 (epoch 10.372), train_loss = 0.94590399, grad/param norm = 2.6222e-01, time/batch = 0.6957s	
4627/22300 (epoch 10.374), train_loss = 0.83722004, grad/param norm = 2.4476e-01, time/batch = 0.6938s	
4628/22300 (epoch 10.377), train_loss = 1.06565135, grad/param norm = 2.6614e-01, time/batch = 0.6986s	
4629/22300 (epoch 10.379), train_loss = 1.03574405, grad/param norm = 2.4737e-01, time/batch = 0.6981s	
4630/22300 (epoch 10.381), train_loss = 1.18989376, grad/param norm = 2.8055e-01, time/batch = 0.6941s	
4631/22300 (epoch 10.383), train_loss = 1.00401253, grad/param norm = 2.7048e-01, time/batch = 0.7064s	
4632/22300 (epoch 10.386), train_loss = 1.03671691, grad/param norm = 2.6059e-01, time/batch = 0.6971s	
4633/22300 (epoch 10.388), train_loss = 0.99944501, grad/param norm = 2.8740e-01, time/batch = 0.6965s	
4634/22300 (epoch 10.390), train_loss = 1.04908682, grad/param norm = 2.5268e-01, time/batch = 0.6973s	
4635/22300 (epoch 10.392), train_loss = 1.02243829, grad/param norm = 2.6550e-01, time/batch = 0.6975s	
4636/22300 (epoch 10.395), train_loss = 0.97362097, grad/param norm = 2.7178e-01, time/batch = 0.6965s	
4637/22300 (epoch 10.397), train_loss = 0.74231000, grad/param norm = 2.4364e-01, time/batch = 0.7031s	
4638/22300 (epoch 10.399), train_loss = 0.96001333, grad/param norm = 2.7795e-01, time/batch = 0.7331s	
4639/22300 (epoch 10.401), train_loss = 1.00364889, grad/param norm = 2.6265e-01, time/batch = 0.6932s	
4640/22300 (epoch 10.404), train_loss = 0.99984248, grad/param norm = 2.5575e-01, time/batch = 0.7037s	
4641/22300 (epoch 10.406), train_loss = 1.28226095, grad/param norm = 2.8766e-01, time/batch = 0.7037s	
4642/22300 (epoch 10.408), train_loss = 1.10602991, grad/param norm = 2.4715e-01, time/batch = 0.6996s	
4643/22300 (epoch 10.410), train_loss = 1.11853433, grad/param norm = 2.5050e-01, time/batch = 0.7008s	
4644/22300 (epoch 10.413), train_loss = 1.02290024, grad/param norm = 2.5478e-01, time/batch = 0.6980s	
4645/22300 (epoch 10.415), train_loss = 0.91537082, grad/param norm = 2.4713e-01, time/batch = 0.6979s	
4646/22300 (epoch 10.417), train_loss = 1.05424699, grad/param norm = 2.6315e-01, time/batch = 0.6974s	
4647/22300 (epoch 10.419), train_loss = 0.98032012, grad/param norm = 2.4095e-01, time/batch = 0.7016s	
4648/22300 (epoch 10.422), train_loss = 1.05267010, grad/param norm = 2.7173e-01, time/batch = 0.6965s	
4649/22300 (epoch 10.424), train_loss = 1.10421179, grad/param norm = 2.7824e-01, time/batch = 0.6958s	
4650/22300 (epoch 10.426), train_loss = 0.94301173, grad/param norm = 2.6445e-01, time/batch = 0.6964s	
4651/22300 (epoch 10.428), train_loss = 1.03071590, grad/param norm = 2.5701e-01, time/batch = 0.7009s	
4652/22300 (epoch 10.430), train_loss = 1.04508067, grad/param norm = 2.9528e-01, time/batch = 0.6977s	
4653/22300 (epoch 10.433), train_loss = 1.01043521, grad/param norm = 2.4255e-01, time/batch = 0.6979s	
4654/22300 (epoch 10.435), train_loss = 1.09610533, grad/param norm = 2.7080e-01, time/batch = 0.6960s	
4655/22300 (epoch 10.437), train_loss = 1.04941491, grad/param norm = 2.5858e-01, time/batch = 0.6909s	
4656/22300 (epoch 10.439), train_loss = 1.08348667, grad/param norm = 2.4270e-01, time/batch = 0.6935s	
4657/22300 (epoch 10.442), train_loss = 1.07419742, grad/param norm = 2.4150e-01, time/batch = 0.6971s	
4658/22300 (epoch 10.444), train_loss = 0.99753358, grad/param norm = 2.0472e-01, time/batch = 0.6945s	
4659/22300 (epoch 10.446), train_loss = 0.87142486, grad/param norm = 2.3408e-01, time/batch = 0.7056s	
4660/22300 (epoch 10.448), train_loss = 0.77680659, grad/param norm = 1.9879e-01, time/batch = 0.6990s	
4661/22300 (epoch 10.451), train_loss = 1.15005654, grad/param norm = 2.6051e-01, time/batch = 0.6985s	
4662/22300 (epoch 10.453), train_loss = 0.97558095, grad/param norm = 2.6214e-01, time/batch = 0.6966s	
4663/22300 (epoch 10.455), train_loss = 1.22718869, grad/param norm = 3.0314e-01, time/batch = 0.6954s	
4664/22300 (epoch 10.457), train_loss = 1.12694996, grad/param norm = 2.5226e-01, time/batch = 0.6922s	
4665/22300 (epoch 10.460), train_loss = 1.06851797, grad/param norm = 2.7728e-01, time/batch = 0.6945s	
4666/22300 (epoch 10.462), train_loss = 1.15478621, grad/param norm = 2.7364e-01, time/batch = 0.6943s	
4667/22300 (epoch 10.464), train_loss = 1.13182179, grad/param norm = 2.8432e-01, time/batch = 0.6939s	
4668/22300 (epoch 10.466), train_loss = 1.03871908, grad/param norm = 2.5696e-01, time/batch = 0.7129s	
4669/22300 (epoch 10.469), train_loss = 0.94936980, grad/param norm = 2.4750e-01, time/batch = 0.7231s	
4670/22300 (epoch 10.471), train_loss = 1.13744484, grad/param norm = 2.4756e-01, time/batch = 0.7061s	
4671/22300 (epoch 10.473), train_loss = 1.15562624, grad/param norm = 2.5818e-01, time/batch = 0.7000s	
4672/22300 (epoch 10.475), train_loss = 1.00182046, grad/param norm = 2.8468e-01, time/batch = 0.7086s	
4673/22300 (epoch 10.478), train_loss = 0.98880340, grad/param norm = 2.8924e-01, time/batch = 0.7060s	
4674/22300 (epoch 10.480), train_loss = 0.84856228, grad/param norm = 2.4815e-01, time/batch = 0.7036s	
4675/22300 (epoch 10.482), train_loss = 0.87873522, grad/param norm = 2.2875e-01, time/batch = 0.7039s	
4676/22300 (epoch 10.484), train_loss = 0.98312646, grad/param norm = 2.3530e-01, time/batch = 0.6973s	
4677/22300 (epoch 10.487), train_loss = 1.05797284, grad/param norm = 2.5908e-01, time/batch = 0.7015s	
4678/22300 (epoch 10.489), train_loss = 1.14136777, grad/param norm = 2.6919e-01, time/batch = 0.6950s	
4679/22300 (epoch 10.491), train_loss = 1.04789700, grad/param norm = 2.5110e-01, time/batch = 0.6937s	
4680/22300 (epoch 10.493), train_loss = 1.13526218, grad/param norm = 2.8803e-01, time/batch = 0.6943s	
4681/22300 (epoch 10.496), train_loss = 0.99814372, grad/param norm = 2.5918e-01, time/batch = 0.6958s	
4682/22300 (epoch 10.498), train_loss = 0.93934318, grad/param norm = 2.6615e-01, time/batch = 0.6990s	
4683/22300 (epoch 10.500), train_loss = 1.02566342, grad/param norm = 2.5243e-01, time/batch = 0.6948s	
4684/22300 (epoch 10.502), train_loss = 0.89186086, grad/param norm = 2.4387e-01, time/batch = 0.6964s	
4685/22300 (epoch 10.504), train_loss = 0.92063122, grad/param norm = 2.3273e-01, time/batch = 0.6959s	
4686/22300 (epoch 10.507), train_loss = 1.00493461, grad/param norm = 2.5478e-01, time/batch = 0.6952s	
4687/22300 (epoch 10.509), train_loss = 1.14148920, grad/param norm = 2.5679e-01, time/batch = 0.6943s	
4688/22300 (epoch 10.511), train_loss = 0.84660926, grad/param norm = 2.5140e-01, time/batch = 0.6956s	
4689/22300 (epoch 10.513), train_loss = 0.82765195, grad/param norm = 2.2929e-01, time/batch = 0.6952s	
4690/22300 (epoch 10.516), train_loss = 0.97302178, grad/param norm = 2.5652e-01, time/batch = 0.6756s	
4691/22300 (epoch 10.518), train_loss = 1.09282115, grad/param norm = 2.5820e-01, time/batch = 0.6912s	
4692/22300 (epoch 10.520), train_loss = 1.04912534, grad/param norm = 2.5418e-01, time/batch = 0.6974s	
4693/22300 (epoch 10.522), train_loss = 0.96181984, grad/param norm = 2.4966e-01, time/batch = 0.6954s	
4694/22300 (epoch 10.525), train_loss = 0.92118673, grad/param norm = 2.4821e-01, time/batch = 0.6956s	
4695/22300 (epoch 10.527), train_loss = 1.16120305, grad/param norm = 2.6649e-01, time/batch = 0.6952s	
4696/22300 (epoch 10.529), train_loss = 0.94434468, grad/param norm = 2.6048e-01, time/batch = 0.6953s	
4697/22300 (epoch 10.531), train_loss = 0.98482423, grad/param norm = 2.5212e-01, time/batch = 0.6914s	
4698/22300 (epoch 10.534), train_loss = 0.90561578, grad/param norm = 2.3714e-01, time/batch = 0.6913s	
4699/22300 (epoch 10.536), train_loss = 1.16125877, grad/param norm = 2.6016e-01, time/batch = 0.6949s	
4700/22300 (epoch 10.538), train_loss = 1.35860205, grad/param norm = 2.7895e-01, time/batch = 0.6807s	
4701/22300 (epoch 10.540), train_loss = 1.09587689, grad/param norm = 2.7035e-01, time/batch = 0.6885s	
4702/22300 (epoch 10.543), train_loss = 0.88604732, grad/param norm = 2.1090e-01, time/batch = 0.6935s	
4703/22300 (epoch 10.545), train_loss = 0.94013890, grad/param norm = 2.5042e-01, time/batch = 0.7006s	
4704/22300 (epoch 10.547), train_loss = 0.85101524, grad/param norm = 2.1912e-01, time/batch = 0.6975s	
4705/22300 (epoch 10.549), train_loss = 0.94854430, grad/param norm = 2.5788e-01, time/batch = 0.6913s	
4706/22300 (epoch 10.552), train_loss = 0.91157147, grad/param norm = 2.4264e-01, time/batch = 0.6956s	
4707/22300 (epoch 10.554), train_loss = 1.00692035, grad/param norm = 2.7447e-01, time/batch = 0.6907s	
4708/22300 (epoch 10.556), train_loss = 1.19241305, grad/param norm = 2.7082e-01, time/batch = 0.6970s	
4709/22300 (epoch 10.558), train_loss = 1.10281504, grad/param norm = 2.9688e-01, time/batch = 0.6914s	
4710/22300 (epoch 10.561), train_loss = 1.22863305, grad/param norm = 2.8186e-01, time/batch = 0.6887s	
4711/22300 (epoch 10.563), train_loss = 1.07297777, grad/param norm = 2.6650e-01, time/batch = 0.6936s	
4712/22300 (epoch 10.565), train_loss = 0.99855074, grad/param norm = 2.8232e-01, time/batch = 0.6927s	
4713/22300 (epoch 10.567), train_loss = 0.98584852, grad/param norm = 2.5376e-01, time/batch = 0.6910s	
4714/22300 (epoch 10.570), train_loss = 1.25769593, grad/param norm = 2.9466e-01, time/batch = 0.6955s	
4715/22300 (epoch 10.572), train_loss = 1.12605497, grad/param norm = 2.7503e-01, time/batch = 0.6922s	
4716/22300 (epoch 10.574), train_loss = 1.00003964, grad/param norm = 2.2217e-01, time/batch = 0.6916s	
4717/22300 (epoch 10.576), train_loss = 0.86197256, grad/param norm = 2.3214e-01, time/batch = 0.6932s	
4718/22300 (epoch 10.578), train_loss = 0.74389513, grad/param norm = 2.2710e-01, time/batch = 0.6917s	
4719/22300 (epoch 10.581), train_loss = 0.85861058, grad/param norm = 2.1073e-01, time/batch = 0.6946s	
4720/22300 (epoch 10.583), train_loss = 0.86734006, grad/param norm = 2.2837e-01, time/batch = 0.6943s	
4721/22300 (epoch 10.585), train_loss = 1.19784392, grad/param norm = 2.8737e-01, time/batch = 0.6971s	
4722/22300 (epoch 10.587), train_loss = 1.27279528, grad/param norm = 2.8933e-01, time/batch = 0.6974s	
4723/22300 (epoch 10.590), train_loss = 1.17562571, grad/param norm = 2.9716e-01, time/batch = 0.6976s	
4724/22300 (epoch 10.592), train_loss = 1.26504377, grad/param norm = 2.6349e-01, time/batch = 0.6913s	
4725/22300 (epoch 10.594), train_loss = 1.25784166, grad/param norm = 2.8321e-01, time/batch = 0.6915s	
4726/22300 (epoch 10.596), train_loss = 0.95663506, grad/param norm = 2.5111e-01, time/batch = 0.6969s	
4727/22300 (epoch 10.599), train_loss = 0.85600335, grad/param norm = 2.4802e-01, time/batch = 0.6852s	
4728/22300 (epoch 10.601), train_loss = 1.00023875, grad/param norm = 2.3369e-01, time/batch = 0.6938s	
4729/22300 (epoch 10.603), train_loss = 1.03246056, grad/param norm = 2.4726e-01, time/batch = 0.6915s	
4730/22300 (epoch 10.605), train_loss = 0.96226730, grad/param norm = 2.8299e-01, time/batch = 0.6769s	
4731/22300 (epoch 10.608), train_loss = 1.27318749, grad/param norm = 2.9859e-01, time/batch = 0.6897s	
4732/22300 (epoch 10.610), train_loss = 1.32838038, grad/param norm = 2.7987e-01, time/batch = 0.6818s	
4733/22300 (epoch 10.612), train_loss = 1.14962420, grad/param norm = 2.7920e-01, time/batch = 0.6783s	
4734/22300 (epoch 10.614), train_loss = 1.13237795, grad/param norm = 2.6539e-01, time/batch = 0.6810s	
4735/22300 (epoch 10.617), train_loss = 1.09494421, grad/param norm = 2.7023e-01, time/batch = 0.6799s	
4736/22300 (epoch 10.619), train_loss = 1.37096299, grad/param norm = 2.8175e-01, time/batch = 0.6784s	
4737/22300 (epoch 10.621), train_loss = 0.99376694, grad/param norm = 2.4967e-01, time/batch = 0.6786s	
4738/22300 (epoch 10.623), train_loss = 0.99869383, grad/param norm = 2.6411e-01, time/batch = 0.6958s	
4739/22300 (epoch 10.626), train_loss = 0.91827065, grad/param norm = 2.1860e-01, time/batch = 0.6908s	
4740/22300 (epoch 10.628), train_loss = 0.92387204, grad/param norm = 2.3520e-01, time/batch = 0.6921s	
4741/22300 (epoch 10.630), train_loss = 1.00013613, grad/param norm = 2.2932e-01, time/batch = 0.6963s	
4742/22300 (epoch 10.632), train_loss = 1.00398582, grad/param norm = 2.3481e-01, time/batch = 0.6941s	
4743/22300 (epoch 10.635), train_loss = 0.99481245, grad/param norm = 2.5859e-01, time/batch = 0.6966s	
4744/22300 (epoch 10.637), train_loss = 1.17354649, grad/param norm = 2.7583e-01, time/batch = 0.6958s	
4745/22300 (epoch 10.639), train_loss = 1.16749101, grad/param norm = 2.8873e-01, time/batch = 0.7130s	
4746/22300 (epoch 10.641), train_loss = 1.08903625, grad/param norm = 2.6736e-01, time/batch = 0.6935s	
4747/22300 (epoch 10.643), train_loss = 1.00369971, grad/param norm = 2.7614e-01, time/batch = 0.7264s	
4748/22300 (epoch 10.646), train_loss = 0.94977291, grad/param norm = 2.7049e-01, time/batch = 0.6945s	
4749/22300 (epoch 10.648), train_loss = 0.97272993, grad/param norm = 2.3605e-01, time/batch = 0.6801s	
4750/22300 (epoch 10.650), train_loss = 1.11927317, grad/param norm = 2.5134e-01, time/batch = 0.6788s	
4751/22300 (epoch 10.652), train_loss = 0.97222266, grad/param norm = 2.4986e-01, time/batch = 0.6822s	
4752/22300 (epoch 10.655), train_loss = 1.06192637, grad/param norm = 2.8138e-01, time/batch = 0.6817s	
4753/22300 (epoch 10.657), train_loss = 1.06591350, grad/param norm = 2.8582e-01, time/batch = 0.6828s	
4754/22300 (epoch 10.659), train_loss = 0.94910022, grad/param norm = 2.5957e-01, time/batch = 0.6916s	
4755/22300 (epoch 10.661), train_loss = 0.82584478, grad/param norm = 2.3706e-01, time/batch = 0.6827s	
4756/22300 (epoch 10.664), train_loss = 0.98315393, grad/param norm = 2.5196e-01, time/batch = 0.6815s	
4757/22300 (epoch 10.666), train_loss = 1.06604837, grad/param norm = 2.6132e-01, time/batch = 0.6839s	
4758/22300 (epoch 10.668), train_loss = 0.94549429, grad/param norm = 2.4374e-01, time/batch = 0.6793s	
4759/22300 (epoch 10.670), train_loss = 1.08467308, grad/param norm = 2.4677e-01, time/batch = 0.6771s	
4760/22300 (epoch 10.673), train_loss = 1.13863612, grad/param norm = 2.7056e-01, time/batch = 0.6790s	
4761/22300 (epoch 10.675), train_loss = 1.23347940, grad/param norm = 2.9136e-01, time/batch = 0.6854s	
4762/22300 (epoch 10.677), train_loss = 1.24899465, grad/param norm = 3.0634e-01, time/batch = 0.6852s	
4763/22300 (epoch 10.679), train_loss = 1.15557408, grad/param norm = 2.7602e-01, time/batch = 0.6770s	
4764/22300 (epoch 10.682), train_loss = 1.10785790, grad/param norm = 2.6925e-01, time/batch = 0.6766s	
4765/22300 (epoch 10.684), train_loss = 1.05836043, grad/param norm = 2.4402e-01, time/batch = 0.6771s	
4766/22300 (epoch 10.686), train_loss = 1.10534100, grad/param norm = 2.8930e-01, time/batch = 0.6765s	
4767/22300 (epoch 10.688), train_loss = 1.09906790, grad/param norm = 2.8939e-01, time/batch = 0.6776s	
4768/22300 (epoch 10.691), train_loss = 1.00782461, grad/param norm = 2.6761e-01, time/batch = 0.6767s	
4769/22300 (epoch 10.693), train_loss = 1.03266315, grad/param norm = 2.9800e-01, time/batch = 0.6786s	
4770/22300 (epoch 10.695), train_loss = 0.82876290, grad/param norm = 2.3597e-01, time/batch = 0.6807s	
4771/22300 (epoch 10.697), train_loss = 0.82483078, grad/param norm = 2.1949e-01, time/batch = 0.6682s	
4772/22300 (epoch 10.700), train_loss = 1.00191298, grad/param norm = 2.7900e-01, time/batch = 0.6790s	
4773/22300 (epoch 10.702), train_loss = 1.06268145, grad/param norm = 2.4327e-01, time/batch = 0.6792s	
4774/22300 (epoch 10.704), train_loss = 1.10673690, grad/param norm = 2.6877e-01, time/batch = 0.6781s	
4775/22300 (epoch 10.706), train_loss = 0.93662776, grad/param norm = 2.8801e-01, time/batch = 0.6782s	
4776/22300 (epoch 10.709), train_loss = 0.85634662, grad/param norm = 2.3404e-01, time/batch = 0.6773s	
4777/22300 (epoch 10.711), train_loss = 0.90818562, grad/param norm = 2.7615e-01, time/batch = 0.6775s	
4778/22300 (epoch 10.713), train_loss = 1.11817843, grad/param norm = 2.7044e-01, time/batch = 0.6776s	
4779/22300 (epoch 10.715), train_loss = 1.06849186, grad/param norm = 2.6643e-01, time/batch = 0.6788s	
4780/22300 (epoch 10.717), train_loss = 1.25246907, grad/param norm = 2.6995e-01, time/batch = 0.6782s	
4781/22300 (epoch 10.720), train_loss = 0.99616758, grad/param norm = 2.8765e-01, time/batch = 0.6657s	
4782/22300 (epoch 10.722), train_loss = 1.11041652, grad/param norm = 2.9120e-01, time/batch = 0.6678s	
4783/22300 (epoch 10.724), train_loss = 1.08027118, grad/param norm = 2.5847e-01, time/batch = 0.6802s	
4784/22300 (epoch 10.726), train_loss = 0.99921926, grad/param norm = 2.6769e-01, time/batch = 0.6801s	
4785/22300 (epoch 10.729), train_loss = 1.03903778, grad/param norm = 2.7191e-01, time/batch = 0.6762s	
4786/22300 (epoch 10.731), train_loss = 1.21061481, grad/param norm = 2.9132e-01, time/batch = 0.6787s	
4787/22300 (epoch 10.733), train_loss = 1.21078619, grad/param norm = 3.1787e-01, time/batch = 0.6818s	
4788/22300 (epoch 10.735), train_loss = 1.22550455, grad/param norm = 3.0959e-01, time/batch = 0.6774s	
4789/22300 (epoch 10.738), train_loss = 1.11916862, grad/param norm = 3.2296e-01, time/batch = 0.6758s	
4790/22300 (epoch 10.740), train_loss = 0.86766367, grad/param norm = 2.5223e-01, time/batch = 0.6776s	
4791/22300 (epoch 10.742), train_loss = 1.02641525, grad/param norm = 2.4393e-01, time/batch = 0.6770s	
4792/22300 (epoch 10.744), train_loss = 1.27653607, grad/param norm = 2.7081e-01, time/batch = 0.6637s	
4793/22300 (epoch 10.747), train_loss = 1.03008556, grad/param norm = 2.4756e-01, time/batch = 0.6831s	
4794/22300 (epoch 10.749), train_loss = 1.39472548, grad/param norm = 3.0848e-01, time/batch = 0.6774s	
4795/22300 (epoch 10.751), train_loss = 1.24590758, grad/param norm = 3.1962e-01, time/batch = 0.7000s	
4796/22300 (epoch 10.753), train_loss = 1.23289347, grad/param norm = 2.9117e-01, time/batch = 0.6971s	
4797/22300 (epoch 10.756), train_loss = 1.05036528, grad/param norm = 2.4467e-01, time/batch = 0.6953s	
4798/22300 (epoch 10.758), train_loss = 1.10189318, grad/param norm = 2.6760e-01, time/batch = 0.6932s	
4799/22300 (epoch 10.760), train_loss = 1.13475981, grad/param norm = 2.8463e-01, time/batch = 0.6947s	
4800/22300 (epoch 10.762), train_loss = 1.10143710, grad/param norm = 2.7576e-01, time/batch = 0.6940s	
4801/22300 (epoch 10.765), train_loss = 1.10724498, grad/param norm = 2.7283e-01, time/batch = 0.6979s	
4802/22300 (epoch 10.767), train_loss = 1.17903688, grad/param norm = 3.1085e-01, time/batch = 0.6931s	
4803/22300 (epoch 10.769), train_loss = 1.07110463, grad/param norm = 2.8741e-01, time/batch = 0.6943s	
4804/22300 (epoch 10.771), train_loss = 1.11497794, grad/param norm = 2.8559e-01, time/batch = 0.6943s	
4805/22300 (epoch 10.774), train_loss = 1.18096957, grad/param norm = 3.0681e-01, time/batch = 0.6930s	
4806/22300 (epoch 10.776), train_loss = 1.14350541, grad/param norm = 2.7764e-01, time/batch = 0.6944s	
4807/22300 (epoch 10.778), train_loss = 1.23972572, grad/param norm = 3.0603e-01, time/batch = 0.6962s	
4808/22300 (epoch 10.780), train_loss = 1.20943396, grad/param norm = 2.7660e-01, time/batch = 0.6934s	
4809/22300 (epoch 10.783), train_loss = 1.24825727, grad/param norm = 2.9437e-01, time/batch = 0.6924s	
4810/22300 (epoch 10.785), train_loss = 0.98837001, grad/param norm = 2.5666e-01, time/batch = 0.6909s	
4811/22300 (epoch 10.787), train_loss = 1.02899527, grad/param norm = 2.4164e-01, time/batch = 0.6907s	
4812/22300 (epoch 10.789), train_loss = 1.19715512, grad/param norm = 2.8551e-01, time/batch = 0.6832s	
4813/22300 (epoch 10.791), train_loss = 1.29505782, grad/param norm = 2.8138e-01, time/batch = 0.6930s	
4814/22300 (epoch 10.794), train_loss = 1.23703403, grad/param norm = 3.0005e-01, time/batch = 0.6916s	
4815/22300 (epoch 10.796), train_loss = 1.26316615, grad/param norm = 2.9648e-01, time/batch = 0.6930s	
4816/22300 (epoch 10.798), train_loss = 1.20455468, grad/param norm = 2.7066e-01, time/batch = 0.6931s	
4817/22300 (epoch 10.800), train_loss = 0.98935599, grad/param norm = 2.3228e-01, time/batch = 0.6950s	
4818/22300 (epoch 10.803), train_loss = 0.97518520, grad/param norm = 2.4240e-01, time/batch = 0.6930s	
4819/22300 (epoch 10.805), train_loss = 1.09524274, grad/param norm = 2.5330e-01, time/batch = 0.6953s	
4820/22300 (epoch 10.807), train_loss = 1.19101797, grad/param norm = 2.5930e-01, time/batch = 0.6998s	
4821/22300 (epoch 10.809), train_loss = 1.09439640, grad/param norm = 2.6918e-01, time/batch = 0.6961s	
4822/22300 (epoch 10.812), train_loss = 1.17664791, grad/param norm = 2.7688e-01, time/batch = 0.6945s	
4823/22300 (epoch 10.814), train_loss = 1.12546391, grad/param norm = 2.5172e-01, time/batch = 0.6924s	
4824/22300 (epoch 10.816), train_loss = 1.17273281, grad/param norm = 2.7492e-01, time/batch = 0.6938s	
4825/22300 (epoch 10.818), train_loss = 1.19163188, grad/param norm = 2.7677e-01, time/batch = 0.6922s	
4826/22300 (epoch 10.821), train_loss = 1.24466761, grad/param norm = 2.9201e-01, time/batch = 0.6934s	
4827/22300 (epoch 10.823), train_loss = 0.96825748, grad/param norm = 2.4702e-01, time/batch = 0.6935s	
4828/22300 (epoch 10.825), train_loss = 1.07579221, grad/param norm = 2.5697e-01, time/batch = 0.6930s	
4829/22300 (epoch 10.827), train_loss = 1.06251605, grad/param norm = 2.5774e-01, time/batch = 0.6959s	
4830/22300 (epoch 10.830), train_loss = 0.98794545, grad/param norm = 2.4008e-01, time/batch = 0.6963s	
4831/22300 (epoch 10.832), train_loss = 0.99601437, grad/param norm = 2.7900e-01, time/batch = 0.6992s	
4832/22300 (epoch 10.834), train_loss = 1.05167711, grad/param norm = 2.7603e-01, time/batch = 0.7105s	
4833/22300 (epoch 10.836), train_loss = 1.03995653, grad/param norm = 2.5103e-01, time/batch = 0.7151s	
4834/22300 (epoch 10.839), train_loss = 1.07855184, grad/param norm = 2.7107e-01, time/batch = 0.6984s	
4835/22300 (epoch 10.841), train_loss = 1.06721189, grad/param norm = 2.9513e-01, time/batch = 0.6959s	
4836/22300 (epoch 10.843), train_loss = 1.08310122, grad/param norm = 3.2472e-01, time/batch = 0.6942s	
4837/22300 (epoch 10.845), train_loss = 1.04879748, grad/param norm = 2.3552e-01, time/batch = 0.6795s	
4838/22300 (epoch 10.848), train_loss = 1.03334720, grad/param norm = 2.3886e-01, time/batch = 0.6802s	
4839/22300 (epoch 10.850), train_loss = 1.07556575, grad/param norm = 2.6058e-01, time/batch = 0.6977s	
4840/22300 (epoch 10.852), train_loss = 1.09186956, grad/param norm = 2.6762e-01, time/batch = 0.7069s	
4841/22300 (epoch 10.854), train_loss = 1.24613015, grad/param norm = 3.0103e-01, time/batch = 0.6958s	
4842/22300 (epoch 10.857), train_loss = 1.05311660, grad/param norm = 2.8969e-01, time/batch = 0.6833s	
4843/22300 (epoch 10.859), train_loss = 0.89968197, grad/param norm = 2.2835e-01, time/batch = 0.6798s	
4844/22300 (epoch 10.861), train_loss = 1.08837706, grad/param norm = 2.5160e-01, time/batch = 0.6818s	
4845/22300 (epoch 10.863), train_loss = 0.89876406, grad/param norm = 2.4352e-01, time/batch = 0.6780s	
4846/22300 (epoch 10.865), train_loss = 0.95737885, grad/param norm = 2.3670e-01, time/batch = 0.6861s	
4847/22300 (epoch 10.868), train_loss = 1.02534241, grad/param norm = 2.3009e-01, time/batch = 0.6774s	
4848/22300 (epoch 10.870), train_loss = 1.06569487, grad/param norm = 2.6800e-01, time/batch = 0.6792s	
4849/22300 (epoch 10.872), train_loss = 1.14135502, grad/param norm = 2.7259e-01, time/batch = 0.6832s	
4850/22300 (epoch 10.874), train_loss = 1.09457634, grad/param norm = 2.7504e-01, time/batch = 0.6805s	
4851/22300 (epoch 10.877), train_loss = 1.06537177, grad/param norm = 2.4159e-01, time/batch = 0.6805s	
4852/22300 (epoch 10.879), train_loss = 0.95514166, grad/param norm = 2.6519e-01, time/batch = 0.6763s	
4853/22300 (epoch 10.881), train_loss = 1.02124226, grad/param norm = 2.6568e-01, time/batch = 0.6770s	
4854/22300 (epoch 10.883), train_loss = 0.96985408, grad/param norm = 2.3064e-01, time/batch = 0.6771s	
4855/22300 (epoch 10.886), train_loss = 0.99424140, grad/param norm = 2.1796e-01, time/batch = 0.6796s	
4856/22300 (epoch 10.888), train_loss = 1.02204018, grad/param norm = 2.7065e-01, time/batch = 0.6783s	
4857/22300 (epoch 10.890), train_loss = 0.93383683, grad/param norm = 2.2031e-01, time/batch = 0.6748s	
4858/22300 (epoch 10.892), train_loss = 1.21687227, grad/param norm = 2.7828e-01, time/batch = 0.6784s	
4859/22300 (epoch 10.895), train_loss = 1.20465870, grad/param norm = 2.9267e-01, time/batch = 0.6778s	
4860/22300 (epoch 10.897), train_loss = 1.08807996, grad/param norm = 2.7324e-01, time/batch = 0.7013s	
4861/22300 (epoch 10.899), train_loss = 1.12725714, grad/param norm = 2.6719e-01, time/batch = 0.6980s	
4862/22300 (epoch 10.901), train_loss = 1.01502497, grad/param norm = 2.4150e-01, time/batch = 0.6822s	
4863/22300 (epoch 10.904), train_loss = 1.12188782, grad/param norm = 2.6992e-01, time/batch = 0.6753s	
4864/22300 (epoch 10.906), train_loss = 1.16856728, grad/param norm = 2.6521e-01, time/batch = 0.6825s	
4865/22300 (epoch 10.908), train_loss = 1.06309702, grad/param norm = 2.4108e-01, time/batch = 0.6998s	
4866/22300 (epoch 10.910), train_loss = 0.91855846, grad/param norm = 2.5754e-01, time/batch = 0.6988s	
4867/22300 (epoch 10.913), train_loss = 1.07688384, grad/param norm = 2.6098e-01, time/batch = 0.6965s	
4868/22300 (epoch 10.915), train_loss = 1.28689067, grad/param norm = 3.0504e-01, time/batch = 0.6977s	
4869/22300 (epoch 10.917), train_loss = 1.08248569, grad/param norm = 2.8163e-01, time/batch = 0.6972s	
4870/22300 (epoch 10.919), train_loss = 1.12656952, grad/param norm = 2.7213e-01, time/batch = 0.6952s	
4871/22300 (epoch 10.922), train_loss = 1.06122400, grad/param norm = 2.6411e-01, time/batch = 0.6981s	
4872/22300 (epoch 10.924), train_loss = 0.82036428, grad/param norm = 2.0747e-01, time/batch = 0.6986s	
4873/22300 (epoch 10.926), train_loss = 0.86099418, grad/param norm = 2.4367e-01, time/batch = 0.6984s	
4874/22300 (epoch 10.928), train_loss = 1.03209896, grad/param norm = 2.4377e-01, time/batch = 0.6913s	
4875/22300 (epoch 10.930), train_loss = 1.05240544, grad/param norm = 2.7453e-01, time/batch = 0.6925s	
4876/22300 (epoch 10.933), train_loss = 1.12409273, grad/param norm = 2.6111e-01, time/batch = 0.6936s	
4877/22300 (epoch 10.935), train_loss = 1.20337747, grad/param norm = 2.9292e-01, time/batch = 0.6924s	
4878/22300 (epoch 10.937), train_loss = 1.21966135, grad/param norm = 2.8117e-01, time/batch = 0.6994s	
4879/22300 (epoch 10.939), train_loss = 1.16179915, grad/param norm = 3.0008e-01, time/batch = 0.6966s	
4880/22300 (epoch 10.942), train_loss = 1.30927910, grad/param norm = 2.8591e-01, time/batch = 0.6911s	
4881/22300 (epoch 10.944), train_loss = 1.34144863, grad/param norm = 2.9872e-01, time/batch = 0.6976s	
4882/22300 (epoch 10.946), train_loss = 1.03381070, grad/param norm = 3.0260e-01, time/batch = 0.7098s	
4883/22300 (epoch 10.948), train_loss = 1.01718289, grad/param norm = 2.5190e-01, time/batch = 0.7014s	
4884/22300 (epoch 10.951), train_loss = 0.89660007, grad/param norm = 2.4950e-01, time/batch = 0.7031s	
4885/22300 (epoch 10.953), train_loss = 0.95822624, grad/param norm = 2.6033e-01, time/batch = 0.7000s	
4886/22300 (epoch 10.955), train_loss = 1.28822610, grad/param norm = 2.7830e-01, time/batch = 0.6975s	
4887/22300 (epoch 10.957), train_loss = 1.42573538, grad/param norm = 3.1232e-01, time/batch = 0.6932s	
4888/22300 (epoch 10.960), train_loss = 1.22036212, grad/param norm = 2.8322e-01, time/batch = 0.6969s	
4889/22300 (epoch 10.962), train_loss = 1.09607300, grad/param norm = 2.5511e-01, time/batch = 0.6960s	
4890/22300 (epoch 10.964), train_loss = 1.03872204, grad/param norm = 2.4236e-01, time/batch = 0.6952s	
4891/22300 (epoch 10.966), train_loss = 1.01375326, grad/param norm = 2.7436e-01, time/batch = 0.6992s	
4892/22300 (epoch 10.969), train_loss = 0.96069666, grad/param norm = 2.1333e-01, time/batch = 0.6889s	
4893/22300 (epoch 10.971), train_loss = 1.03851926, grad/param norm = 2.5088e-01, time/batch = 0.6951s	
4894/22300 (epoch 10.973), train_loss = 1.08474196, grad/param norm = 2.8670e-01, time/batch = 0.7079s	
4895/22300 (epoch 10.975), train_loss = 1.34729083, grad/param norm = 3.1552e-01, time/batch = 0.7135s	
4896/22300 (epoch 10.978), train_loss = 1.09006941, grad/param norm = 2.5514e-01, time/batch = 0.7130s	
4897/22300 (epoch 10.980), train_loss = 1.14735837, grad/param norm = 2.4817e-01, time/batch = 0.7096s	
4898/22300 (epoch 10.982), train_loss = 0.96216105, grad/param norm = 2.4807e-01, time/batch = 0.7143s	
4899/22300 (epoch 10.984), train_loss = 1.12069253, grad/param norm = 2.6306e-01, time/batch = 0.7123s	
4900/22300 (epoch 10.987), train_loss = 0.99596799, grad/param norm = 2.3347e-01, time/batch = 0.6981s	
4901/22300 (epoch 10.989), train_loss = 1.06548365, grad/param norm = 2.7360e-01, time/batch = 0.7215s	
4902/22300 (epoch 10.991), train_loss = 1.29767664, grad/param norm = 2.8476e-01, time/batch = 0.7061s	
4903/22300 (epoch 10.993), train_loss = 1.39448616, grad/param norm = 2.8530e-01, time/batch = 0.6932s	
4904/22300 (epoch 10.996), train_loss = 1.36076163, grad/param norm = 3.1373e-01, time/batch = 0.7007s	
4905/22300 (epoch 10.998), train_loss = 1.02920350, grad/param norm = 2.5799e-01, time/batch = 0.7100s	
decayed learning rate by a factor 0.97 to 0.0018818	
4906/22300 (epoch 11.000), train_loss = 0.92372213, grad/param norm = 2.6297e-01, time/batch = 0.7084s	
4907/22300 (epoch 11.002), train_loss = 1.26158700, grad/param norm = 3.4200e-01, time/batch = 0.6964s	
4908/22300 (epoch 11.004), train_loss = 1.06894646, grad/param norm = 2.4515e-01, time/batch = 0.7064s	
4909/22300 (epoch 11.007), train_loss = 1.09141650, grad/param norm = 2.6428e-01, time/batch = 0.6974s	
4910/22300 (epoch 11.009), train_loss = 1.08999979, grad/param norm = 2.6633e-01, time/batch = 0.7263s	
4911/22300 (epoch 11.011), train_loss = 1.26440433, grad/param norm = 2.9531e-01, time/batch = 0.7292s	
4912/22300 (epoch 11.013), train_loss = 1.03966739, grad/param norm = 2.7023e-01, time/batch = 0.6962s	
4913/22300 (epoch 11.016), train_loss = 1.05711539, grad/param norm = 2.9135e-01, time/batch = 0.6867s	
4914/22300 (epoch 11.018), train_loss = 1.19743330, grad/param norm = 2.8246e-01, time/batch = 0.6890s	
4915/22300 (epoch 11.020), train_loss = 1.05386806, grad/param norm = 2.7302e-01, time/batch = 0.6893s	
4916/22300 (epoch 11.022), train_loss = 0.99589942, grad/param norm = 2.8236e-01, time/batch = 0.6942s	
4917/22300 (epoch 11.025), train_loss = 0.99368669, grad/param norm = 2.3979e-01, time/batch = 0.6920s	
4918/22300 (epoch 11.027), train_loss = 1.07936449, grad/param norm = 2.6254e-01, time/batch = 0.7035s	
4919/22300 (epoch 11.029), train_loss = 0.97997215, grad/param norm = 2.4245e-01, time/batch = 0.6959s	
4920/22300 (epoch 11.031), train_loss = 0.93052634, grad/param norm = 2.1873e-01, time/batch = 0.6858s	
4921/22300 (epoch 11.034), train_loss = 0.98552437, grad/param norm = 2.6067e-01, time/batch = 0.6863s	
4922/22300 (epoch 11.036), train_loss = 0.82140470, grad/param norm = 2.2585e-01, time/batch = 0.6809s	
4923/22300 (epoch 11.038), train_loss = 0.93899437, grad/param norm = 2.2746e-01, time/batch = 0.6797s	
4924/22300 (epoch 11.040), train_loss = 1.05678599, grad/param norm = 2.6533e-01, time/batch = 0.6780s	
4925/22300 (epoch 11.043), train_loss = 1.27894326, grad/param norm = 2.8743e-01, time/batch = 0.6915s	
4926/22300 (epoch 11.045), train_loss = 1.09044573, grad/param norm = 2.4903e-01, time/batch = 0.7130s	
4927/22300 (epoch 11.047), train_loss = 1.17697032, grad/param norm = 2.7780e-01, time/batch = 0.6838s	
4928/22300 (epoch 11.049), train_loss = 1.01046577, grad/param norm = 2.5072e-01, time/batch = 0.6717s	
4929/22300 (epoch 11.052), train_loss = 1.14207334, grad/param norm = 2.8057e-01, time/batch = 0.6827s	
4930/22300 (epoch 11.054), train_loss = 1.10446207, grad/param norm = 2.7657e-01, time/batch = 0.6827s	
4931/22300 (epoch 11.056), train_loss = 0.81181218, grad/param norm = 2.4148e-01, time/batch = 0.6867s	
4932/22300 (epoch 11.058), train_loss = 0.93541410, grad/param norm = 2.4971e-01, time/batch = 0.7018s	
4933/22300 (epoch 11.061), train_loss = 0.91977968, grad/param norm = 2.3797e-01, time/batch = 0.6820s	
4934/22300 (epoch 11.063), train_loss = 1.26815938, grad/param norm = 3.6251e-01, time/batch = 0.6857s	
4935/22300 (epoch 11.065), train_loss = 1.14003202, grad/param norm = 2.9156e-01, time/batch = 0.7142s	
4936/22300 (epoch 11.067), train_loss = 0.98235734, grad/param norm = 2.5274e-01, time/batch = 0.7170s	
4937/22300 (epoch 11.070), train_loss = 1.02256991, grad/param norm = 2.5989e-01, time/batch = 0.7147s	
4938/22300 (epoch 11.072), train_loss = 1.09223214, grad/param norm = 2.7016e-01, time/batch = 0.7101s	
4939/22300 (epoch 11.074), train_loss = 1.08439464, grad/param norm = 2.5877e-01, time/batch = 0.6873s	
4940/22300 (epoch 11.076), train_loss = 1.03898337, grad/param norm = 2.6902e-01, time/batch = 0.6902s	
4941/22300 (epoch 11.078), train_loss = 1.11050920, grad/param norm = 2.7529e-01, time/batch = 0.7147s	
4942/22300 (epoch 11.081), train_loss = 1.16014156, grad/param norm = 2.9672e-01, time/batch = 0.6909s	
4943/22300 (epoch 11.083), train_loss = 1.24134045, grad/param norm = 2.9333e-01, time/batch = 0.6687s	
4944/22300 (epoch 11.085), train_loss = 1.30724793, grad/param norm = 2.8871e-01, time/batch = 0.6682s	
4945/22300 (epoch 11.087), train_loss = 1.10463475, grad/param norm = 2.6686e-01, time/batch = 0.6826s	
4946/22300 (epoch 11.090), train_loss = 0.91498162, grad/param norm = 2.2926e-01, time/batch = 0.7065s	
4947/22300 (epoch 11.092), train_loss = 0.95051435, grad/param norm = 2.4842e-01, time/batch = 0.7007s	
4948/22300 (epoch 11.094), train_loss = 0.94429949, grad/param norm = 2.5135e-01, time/batch = 0.6782s	
4949/22300 (epoch 11.096), train_loss = 1.23520379, grad/param norm = 2.7892e-01, time/batch = 0.7044s	
4950/22300 (epoch 11.099), train_loss = 1.02411915, grad/param norm = 2.4690e-01, time/batch = 0.6911s	
4951/22300 (epoch 11.101), train_loss = 1.19877082, grad/param norm = 2.8919e-01, time/batch = 0.6750s	
4952/22300 (epoch 11.103), train_loss = 1.11233666, grad/param norm = 2.5511e-01, time/batch = 0.6749s	
4953/22300 (epoch 11.105), train_loss = 1.08293753, grad/param norm = 2.7826e-01, time/batch = 0.6679s	
4954/22300 (epoch 11.108), train_loss = 1.08497072, grad/param norm = 2.4356e-01, time/batch = 0.6747s	
4955/22300 (epoch 11.110), train_loss = 1.08572740, grad/param norm = 2.3537e-01, time/batch = 0.6790s	
4956/22300 (epoch 11.112), train_loss = 1.03609509, grad/param norm = 2.3780e-01, time/batch = 0.6742s	
4957/22300 (epoch 11.114), train_loss = 1.15248020, grad/param norm = 2.7453e-01, time/batch = 0.6696s	
4958/22300 (epoch 11.117), train_loss = 1.29853299, grad/param norm = 2.6781e-01, time/batch = 0.6649s	
4959/22300 (epoch 11.119), train_loss = 1.14863355, grad/param norm = 2.6394e-01, time/batch = 0.6663s	
4960/22300 (epoch 11.121), train_loss = 1.24596345, grad/param norm = 2.9050e-01, time/batch = 0.6692s	
4961/22300 (epoch 11.123), train_loss = 1.09887609, grad/param norm = 2.4306e-01, time/batch = 0.6671s	
4962/22300 (epoch 11.126), train_loss = 1.05074244, grad/param norm = 2.5450e-01, time/batch = 0.6661s	
4963/22300 (epoch 11.128), train_loss = 1.17558928, grad/param norm = 2.4361e-01, time/batch = 0.6784s	
4964/22300 (epoch 11.130), train_loss = 1.05920661, grad/param norm = 2.7019e-01, time/batch = 0.6752s	
4965/22300 (epoch 11.132), train_loss = 0.91690240, grad/param norm = 2.2259e-01, time/batch = 0.6818s	
4966/22300 (epoch 11.135), train_loss = 0.92069319, grad/param norm = 2.4367e-01, time/batch = 0.6794s	
4967/22300 (epoch 11.137), train_loss = 0.74412792, grad/param norm = 2.0410e-01, time/batch = 0.6793s	
4968/22300 (epoch 11.139), train_loss = 1.11285939, grad/param norm = 2.6220e-01, time/batch = 0.6683s	
4969/22300 (epoch 11.141), train_loss = 1.14335363, grad/param norm = 2.4605e-01, time/batch = 0.6704s	
4970/22300 (epoch 11.143), train_loss = 1.08530234, grad/param norm = 2.5380e-01, time/batch = 0.6799s	
4971/22300 (epoch 11.146), train_loss = 1.22216802, grad/param norm = 2.7741e-01, time/batch = 0.6836s	
4972/22300 (epoch 11.148), train_loss = 0.96885669, grad/param norm = 2.4509e-01, time/batch = 0.6776s	
4973/22300 (epoch 11.150), train_loss = 1.01090772, grad/param norm = 2.6214e-01, time/batch = 0.6789s	
4974/22300 (epoch 11.152), train_loss = 0.95583421, grad/param norm = 2.7076e-01, time/batch = 0.6810s	
4975/22300 (epoch 11.155), train_loss = 1.00971907, grad/param norm = 2.5924e-01, time/batch = 0.6788s	
4976/22300 (epoch 11.157), train_loss = 1.22230989, grad/param norm = 3.1250e-01, time/batch = 0.6754s	
4977/22300 (epoch 11.159), train_loss = 1.14301445, grad/param norm = 2.8304e-01, time/batch = 0.6813s	
4978/22300 (epoch 11.161), train_loss = 1.18611530, grad/param norm = 2.7812e-01, time/batch = 0.6805s	
4979/22300 (epoch 11.164), train_loss = 0.93396640, grad/param norm = 2.4313e-01, time/batch = 0.6787s	
4980/22300 (epoch 11.166), train_loss = 0.92130159, grad/param norm = 2.0430e-01, time/batch = 0.6818s	
4981/22300 (epoch 11.168), train_loss = 0.99399380, grad/param norm = 2.3704e-01, time/batch = 0.6786s	
4982/22300 (epoch 11.170), train_loss = 1.04670934, grad/param norm = 2.2508e-01, time/batch = 0.6641s	
4983/22300 (epoch 11.173), train_loss = 1.25845465, grad/param norm = 2.7858e-01, time/batch = 0.7081s	
4984/22300 (epoch 11.175), train_loss = 1.02798034, grad/param norm = 2.6914e-01, time/batch = 0.6827s	
4985/22300 (epoch 11.177), train_loss = 0.87170288, grad/param norm = 2.1731e-01, time/batch = 0.6885s	
4986/22300 (epoch 11.179), train_loss = 1.01800279, grad/param norm = 2.7256e-01, time/batch = 0.6855s	
4987/22300 (epoch 11.182), train_loss = 1.25617487, grad/param norm = 2.9132e-01, time/batch = 0.6851s	
4988/22300 (epoch 11.184), train_loss = 1.30866445, grad/param norm = 2.7685e-01, time/batch = 0.6805s	
4989/22300 (epoch 11.186), train_loss = 1.13807245, grad/param norm = 2.8378e-01, time/batch = 0.6822s	
4990/22300 (epoch 11.188), train_loss = 1.25375681, grad/param norm = 2.9250e-01, time/batch = 0.6851s	
4991/22300 (epoch 11.191), train_loss = 1.26792652, grad/param norm = 2.9457e-01, time/batch = 0.6888s	
4992/22300 (epoch 11.193), train_loss = 1.05702045, grad/param norm = 2.6039e-01, time/batch = 0.6850s	
4993/22300 (epoch 11.195), train_loss = 0.97615853, grad/param norm = 2.4064e-01, time/batch = 0.6955s	
4994/22300 (epoch 11.197), train_loss = 1.04952154, grad/param norm = 2.6208e-01, time/batch = 0.6944s	
4995/22300 (epoch 11.200), train_loss = 0.94778806, grad/param norm = 2.5766e-01, time/batch = 0.6854s	
4996/22300 (epoch 11.202), train_loss = 1.01868634, grad/param norm = 2.4491e-01, time/batch = 0.6852s	
4997/22300 (epoch 11.204), train_loss = 0.98640468, grad/param norm = 2.3004e-01, time/batch = 0.6781s	
4998/22300 (epoch 11.206), train_loss = 0.92490864, grad/param norm = 2.2609e-01, time/batch = 0.6710s	
4999/22300 (epoch 11.209), train_loss = 1.04727181, grad/param norm = 2.5823e-01, time/batch = 0.6844s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch11.21_1.5009.t7	
5000/22300 (epoch 11.211), train_loss = 0.88447097, grad/param norm = 2.4715e-01, time/batch = 0.6803s	
5001/22300 (epoch 11.213), train_loss = 1.31802362, grad/param norm = 2.8571e-01, time/batch = 0.6959s	
5002/22300 (epoch 11.215), train_loss = 1.24691145, grad/param norm = 2.7162e-01, time/batch = 0.6827s	
5003/22300 (epoch 11.217), train_loss = 1.16821119, grad/param norm = 2.6937e-01, time/batch = 0.6837s	
5004/22300 (epoch 11.220), train_loss = 1.04634195, grad/param norm = 2.4934e-01, time/batch = 0.6797s	
5005/22300 (epoch 11.222), train_loss = 0.97069898, grad/param norm = 2.6217e-01, time/batch = 0.6824s	
5006/22300 (epoch 11.224), train_loss = 0.92923572, grad/param norm = 2.2632e-01, time/batch = 0.6808s	
5007/22300 (epoch 11.226), train_loss = 1.00704023, grad/param norm = 2.2825e-01, time/batch = 0.6826s	
5008/22300 (epoch 11.229), train_loss = 1.00596495, grad/param norm = 2.6821e-01, time/batch = 0.6791s	
5009/22300 (epoch 11.231), train_loss = 1.13572640, grad/param norm = 2.8690e-01, time/batch = 0.6813s	
5010/22300 (epoch 11.233), train_loss = 1.11163685, grad/param norm = 2.3893e-01, time/batch = 0.6939s	
5011/22300 (epoch 11.235), train_loss = 0.90566953, grad/param norm = 2.5425e-01, time/batch = 0.7147s	
5012/22300 (epoch 11.238), train_loss = 0.90545851, grad/param norm = 2.2703e-01, time/batch = 0.6982s	
5013/22300 (epoch 11.240), train_loss = 0.89846853, grad/param norm = 2.2768e-01, time/batch = 0.6779s	
5014/22300 (epoch 11.242), train_loss = 0.94266386, grad/param norm = 2.2929e-01, time/batch = 0.6811s	
5015/22300 (epoch 11.244), train_loss = 0.72960417, grad/param norm = 2.0934e-01, time/batch = 0.6811s	
5016/22300 (epoch 11.247), train_loss = 0.93449469, grad/param norm = 2.4587e-01, time/batch = 0.6819s	
5017/22300 (epoch 11.249), train_loss = 0.84069109, grad/param norm = 2.4156e-01, time/batch = 0.6846s	
5018/22300 (epoch 11.251), train_loss = 0.89456677, grad/param norm = 2.1778e-01, time/batch = 0.6796s	
5019/22300 (epoch 11.253), train_loss = 0.83568887, grad/param norm = 2.2584e-01, time/batch = 0.6682s	
5020/22300 (epoch 11.256), train_loss = 0.93696146, grad/param norm = 2.2691e-01, time/batch = 0.6792s	
5021/22300 (epoch 11.258), train_loss = 1.20414915, grad/param norm = 2.8790e-01, time/batch = 0.6830s	
5022/22300 (epoch 11.260), train_loss = 1.04807383, grad/param norm = 2.8365e-01, time/batch = 0.6815s	
5023/22300 (epoch 11.262), train_loss = 0.95010322, grad/param norm = 2.3150e-01, time/batch = 0.7042s	
5024/22300 (epoch 11.265), train_loss = 0.95080590, grad/param norm = 2.7608e-01, time/batch = 0.6879s	
5025/22300 (epoch 11.267), train_loss = 1.01904086, grad/param norm = 2.6689e-01, time/batch = 0.6834s	
5026/22300 (epoch 11.269), train_loss = 1.00553254, grad/param norm = 2.4917e-01, time/batch = 0.6837s	
5027/22300 (epoch 11.271), train_loss = 0.95202447, grad/param norm = 2.3893e-01, time/batch = 0.7066s	
5028/22300 (epoch 11.274), train_loss = 0.82814155, grad/param norm = 2.2745e-01, time/batch = 0.7034s	
5029/22300 (epoch 11.276), train_loss = 0.77339200, grad/param norm = 2.0568e-01, time/batch = 0.6931s	
5030/22300 (epoch 11.278), train_loss = 0.73677921, grad/param norm = 2.0338e-01, time/batch = 0.6980s	
5031/22300 (epoch 11.280), train_loss = 0.90126126, grad/param norm = 2.4745e-01, time/batch = 0.7084s	
5032/22300 (epoch 11.283), train_loss = 0.71440085, grad/param norm = 1.8673e-01, time/batch = 0.6862s	
5033/22300 (epoch 11.285), train_loss = 0.93871202, grad/param norm = 2.5468e-01, time/batch = 0.6812s	
5034/22300 (epoch 11.287), train_loss = 1.05184764, grad/param norm = 2.7597e-01, time/batch = 0.6785s	
5035/22300 (epoch 11.289), train_loss = 0.90495431, grad/param norm = 2.4140e-01, time/batch = 0.6869s	
5036/22300 (epoch 11.291), train_loss = 0.99591425, grad/param norm = 2.4567e-01, time/batch = 0.6994s	
5037/22300 (epoch 11.294), train_loss = 0.85000063, grad/param norm = 2.2481e-01, time/batch = 0.6847s	
5038/22300 (epoch 11.296), train_loss = 1.10900608, grad/param norm = 2.5874e-01, time/batch = 0.6858s	
5039/22300 (epoch 11.298), train_loss = 1.12923227, grad/param norm = 2.5533e-01, time/batch = 0.6956s	
5040/22300 (epoch 11.300), train_loss = 1.17659174, grad/param norm = 3.0068e-01, time/batch = 0.6964s	
5041/22300 (epoch 11.303), train_loss = 0.98240426, grad/param norm = 2.5398e-01, time/batch = 0.6990s	
5042/22300 (epoch 11.305), train_loss = 1.03291993, grad/param norm = 2.9473e-01, time/batch = 0.6960s	
5043/22300 (epoch 11.307), train_loss = 0.97195601, grad/param norm = 2.7515e-01, time/batch = 0.6977s	
5044/22300 (epoch 11.309), train_loss = 0.96377995, grad/param norm = 2.8435e-01, time/batch = 0.6950s	
5045/22300 (epoch 11.312), train_loss = 0.88913854, grad/param norm = 2.4722e-01, time/batch = 0.7012s	
5046/22300 (epoch 11.314), train_loss = 0.95437257, grad/param norm = 2.3158e-01, time/batch = 0.7018s	
5047/22300 (epoch 11.316), train_loss = 0.95705834, grad/param norm = 2.8128e-01, time/batch = 0.6949s	
5048/22300 (epoch 11.318), train_loss = 1.03569840, grad/param norm = 2.6477e-01, time/batch = 0.7031s	
5049/22300 (epoch 11.321), train_loss = 1.05355129, grad/param norm = 2.6472e-01, time/batch = 0.6954s	
5050/22300 (epoch 11.323), train_loss = 0.97045706, grad/param norm = 2.5771e-01, time/batch = 0.6962s	
5051/22300 (epoch 11.325), train_loss = 0.86275141, grad/param norm = 2.2742e-01, time/batch = 0.6840s	
5052/22300 (epoch 11.327), train_loss = 0.93439078, grad/param norm = 2.6970e-01, time/batch = 0.6858s	
5053/22300 (epoch 11.330), train_loss = 0.93808008, grad/param norm = 2.4525e-01, time/batch = 0.6943s	
5054/22300 (epoch 11.332), train_loss = 0.88613093, grad/param norm = 2.8257e-01, time/batch = 0.6958s	
5055/22300 (epoch 11.334), train_loss = 0.85763138, grad/param norm = 2.2775e-01, time/batch = 0.6971s	
5056/22300 (epoch 11.336), train_loss = 0.93992504, grad/param norm = 2.5573e-01, time/batch = 0.6948s	
5057/22300 (epoch 11.339), train_loss = 1.01803800, grad/param norm = 2.5178e-01, time/batch = 0.6945s	
5058/22300 (epoch 11.341), train_loss = 1.07558706, grad/param norm = 2.9407e-01, time/batch = 0.6942s	
5059/22300 (epoch 11.343), train_loss = 1.17448448, grad/param norm = 3.1277e-01, time/batch = 0.6831s	
5060/22300 (epoch 11.345), train_loss = 1.01120070, grad/param norm = 2.9515e-01, time/batch = 0.6837s	
5061/22300 (epoch 11.348), train_loss = 0.98474282, grad/param norm = 2.4562e-01, time/batch = 0.6852s	
5062/22300 (epoch 11.350), train_loss = 0.83574447, grad/param norm = 2.2634e-01, time/batch = 0.6850s	
5063/22300 (epoch 11.352), train_loss = 1.11158325, grad/param norm = 2.4871e-01, time/batch = 0.6951s	
5064/22300 (epoch 11.354), train_loss = 1.24727347, grad/param norm = 2.8034e-01, time/batch = 0.6877s	
5065/22300 (epoch 11.357), train_loss = 1.12936216, grad/param norm = 2.5720e-01, time/batch = 0.6837s	
5066/22300 (epoch 11.359), train_loss = 0.98480201, grad/param norm = 2.6269e-01, time/batch = 0.6877s	
5067/22300 (epoch 11.361), train_loss = 1.01599645, grad/param norm = 2.5198e-01, time/batch = 0.6864s	
5068/22300 (epoch 11.363), train_loss = 1.17405606, grad/param norm = 2.7257e-01, time/batch = 0.6973s	
5069/22300 (epoch 11.365), train_loss = 1.04561845, grad/param norm = 3.0198e-01, time/batch = 0.7038s	
5070/22300 (epoch 11.368), train_loss = 1.08150482, grad/param norm = 3.0952e-01, time/batch = 0.6976s	
5071/22300 (epoch 11.370), train_loss = 1.04203695, grad/param norm = 2.7813e-01, time/batch = 0.7035s	
5072/22300 (epoch 11.372), train_loss = 0.86117880, grad/param norm = 2.5315e-01, time/batch = 0.6992s	
5073/22300 (epoch 11.374), train_loss = 0.76653856, grad/param norm = 2.3682e-01, time/batch = 0.7031s	
5074/22300 (epoch 11.377), train_loss = 0.99275483, grad/param norm = 2.8276e-01, time/batch = 0.6988s	
5075/22300 (epoch 11.379), train_loss = 0.96856562, grad/param norm = 2.4468e-01, time/batch = 0.7007s	
5076/22300 (epoch 11.381), train_loss = 1.11707614, grad/param norm = 2.7565e-01, time/batch = 0.6980s	
5077/22300 (epoch 11.383), train_loss = 0.93589682, grad/param norm = 2.6085e-01, time/batch = 0.6976s	
5078/22300 (epoch 11.386), train_loss = 0.96614210, grad/param norm = 2.6052e-01, time/batch = 0.6962s	
5079/22300 (epoch 11.388), train_loss = 0.94865690, grad/param norm = 2.8964e-01, time/batch = 0.6981s	
5080/22300 (epoch 11.390), train_loss = 0.98117255, grad/param norm = 2.4845e-01, time/batch = 0.6865s	
5081/22300 (epoch 11.392), train_loss = 0.95032782, grad/param norm = 2.7167e-01, time/batch = 0.6952s	
5082/22300 (epoch 11.395), train_loss = 0.89821393, grad/param norm = 2.6079e-01, time/batch = 0.6997s	
5083/22300 (epoch 11.397), train_loss = 0.68019691, grad/param norm = 2.5220e-01, time/batch = 0.7034s	
5084/22300 (epoch 11.399), train_loss = 0.88060925, grad/param norm = 2.7196e-01, time/batch = 0.7037s	
5085/22300 (epoch 11.401), train_loss = 0.93723102, grad/param norm = 2.5566e-01, time/batch = 0.7099s	
5086/22300 (epoch 11.404), train_loss = 0.93620512, grad/param norm = 2.5442e-01, time/batch = 0.7034s	
5087/22300 (epoch 11.406), train_loss = 1.20877280, grad/param norm = 2.8482e-01, time/batch = 0.7007s	
5088/22300 (epoch 11.408), train_loss = 1.05445584, grad/param norm = 2.5398e-01, time/batch = 0.6993s	
5089/22300 (epoch 11.410), train_loss = 1.05891176, grad/param norm = 2.4947e-01, time/batch = 0.7014s	
5090/22300 (epoch 11.413), train_loss = 0.94427046, grad/param norm = 2.5583e-01, time/batch = 0.6985s	
5091/22300 (epoch 11.415), train_loss = 0.83062787, grad/param norm = 2.4883e-01, time/batch = 0.7038s	
5092/22300 (epoch 11.417), train_loss = 0.98944415, grad/param norm = 2.6479e-01, time/batch = 0.7021s	
5093/22300 (epoch 11.419), train_loss = 0.91719270, grad/param norm = 2.4340e-01, time/batch = 0.6967s	
5094/22300 (epoch 11.422), train_loss = 1.00307395, grad/param norm = 2.8022e-01, time/batch = 0.7070s	
5095/22300 (epoch 11.424), train_loss = 1.03672999, grad/param norm = 2.5986e-01, time/batch = 0.6924s	
5096/22300 (epoch 11.426), train_loss = 0.87579209, grad/param norm = 2.4712e-01, time/batch = 0.6858s	
5097/22300 (epoch 11.428), train_loss = 0.93567742, grad/param norm = 2.4973e-01, time/batch = 0.6845s	
5098/22300 (epoch 11.430), train_loss = 0.97428992, grad/param norm = 2.9390e-01, time/batch = 0.6800s	
5099/22300 (epoch 11.433), train_loss = 0.94394223, grad/param norm = 2.3925e-01, time/batch = 0.6834s	
5100/22300 (epoch 11.435), train_loss = 1.02730132, grad/param norm = 2.6949e-01, time/batch = 0.6810s	
5101/22300 (epoch 11.437), train_loss = 1.00666310, grad/param norm = 2.6443e-01, time/batch = 0.6824s	
5102/22300 (epoch 11.439), train_loss = 1.04072769, grad/param norm = 2.5736e-01, time/batch = 0.6862s	
5103/22300 (epoch 11.442), train_loss = 1.01111309, grad/param norm = 2.5092e-01, time/batch = 0.6832s	
5104/22300 (epoch 11.444), train_loss = 0.92664987, grad/param norm = 2.1452e-01, time/batch = 0.6812s	
5105/22300 (epoch 11.446), train_loss = 0.80803989, grad/param norm = 2.3490e-01, time/batch = 0.6817s	
5106/22300 (epoch 11.448), train_loss = 0.71178153, grad/param norm = 2.0708e-01, time/batch = 0.6794s	
5107/22300 (epoch 11.451), train_loss = 1.07208626, grad/param norm = 2.6200e-01, time/batch = 0.6750s	
5108/22300 (epoch 11.453), train_loss = 0.91302928, grad/param norm = 2.6531e-01, time/batch = 0.6806s	
5109/22300 (epoch 11.455), train_loss = 1.17185314, grad/param norm = 3.0020e-01, time/batch = 0.6859s	
5110/22300 (epoch 11.457), train_loss = 1.07556452, grad/param norm = 2.7160e-01, time/batch = 0.6796s	
5111/22300 (epoch 11.460), train_loss = 1.01595568, grad/param norm = 2.9350e-01, time/batch = 0.6845s	
5112/22300 (epoch 11.462), train_loss = 1.08514774, grad/param norm = 2.6387e-01, time/batch = 0.6823s	
5113/22300 (epoch 11.464), train_loss = 1.07416749, grad/param norm = 3.0039e-01, time/batch = 0.6806s	
5114/22300 (epoch 11.466), train_loss = 0.96197049, grad/param norm = 2.4824e-01, time/batch = 0.6822s	
5115/22300 (epoch 11.469), train_loss = 0.86977016, grad/param norm = 2.2690e-01, time/batch = 0.6827s	
5116/22300 (epoch 11.471), train_loss = 1.06730122, grad/param norm = 2.5149e-01, time/batch = 0.6793s	
5117/22300 (epoch 11.473), train_loss = 1.08832935, grad/param norm = 2.5608e-01, time/batch = 0.6793s	
5118/22300 (epoch 11.475), train_loss = 0.92447956, grad/param norm = 2.6525e-01, time/batch = 0.6819s	
5119/22300 (epoch 11.478), train_loss = 0.92430213, grad/param norm = 2.7456e-01, time/batch = 0.6887s	
5120/22300 (epoch 11.480), train_loss = 0.77791878, grad/param norm = 2.4514e-01, time/batch = 0.6828s	
5121/22300 (epoch 11.482), train_loss = 0.81087525, grad/param norm = 2.2972e-01, time/batch = 0.6832s	
5122/22300 (epoch 11.484), train_loss = 0.92505103, grad/param norm = 2.2863e-01, time/batch = 0.6819s	
5123/22300 (epoch 11.487), train_loss = 0.99926094, grad/param norm = 2.5150e-01, time/batch = 0.6781s	
5124/22300 (epoch 11.489), train_loss = 1.06389641, grad/param norm = 2.6818e-01, time/batch = 0.6784s	
5125/22300 (epoch 11.491), train_loss = 0.99635063, grad/param norm = 2.4789e-01, time/batch = 0.6796s	
5126/22300 (epoch 11.493), train_loss = 1.07578330, grad/param norm = 3.6667e-01, time/batch = 0.6782s	
5127/22300 (epoch 11.496), train_loss = 0.94264615, grad/param norm = 2.8399e-01, time/batch = 0.6807s	
5128/22300 (epoch 11.498), train_loss = 0.86444959, grad/param norm = 2.4872e-01, time/batch = 0.6870s	
5129/22300 (epoch 11.500), train_loss = 0.96493229, grad/param norm = 2.4560e-01, time/batch = 0.6765s	
5130/22300 (epoch 11.502), train_loss = 0.81730330, grad/param norm = 2.7459e-01, time/batch = 0.6792s	
5131/22300 (epoch 11.504), train_loss = 0.85907380, grad/param norm = 2.3604e-01, time/batch = 0.6980s	
5132/22300 (epoch 11.507), train_loss = 0.92850093, grad/param norm = 2.5265e-01, time/batch = 0.6953s	
5133/22300 (epoch 11.509), train_loss = 1.06749083, grad/param norm = 2.6287e-01, time/batch = 0.6950s	
5134/22300 (epoch 11.511), train_loss = 0.78723546, grad/param norm = 2.4312e-01, time/batch = 0.6936s	
5135/22300 (epoch 11.513), train_loss = 0.75145368, grad/param norm = 2.1371e-01, time/batch = 0.6953s	
5136/22300 (epoch 11.516), train_loss = 0.88911912, grad/param norm = 2.4193e-01, time/batch = 0.6899s	
5137/22300 (epoch 11.518), train_loss = 1.03532579, grad/param norm = 2.6529e-01, time/batch = 0.6924s	
5138/22300 (epoch 11.520), train_loss = 0.98264360, grad/param norm = 2.6473e-01, time/batch = 0.6860s	
5139/22300 (epoch 11.522), train_loss = 0.89115912, grad/param norm = 2.5657e-01, time/batch = 0.6773s	
5140/22300 (epoch 11.525), train_loss = 0.85199196, grad/param norm = 2.3658e-01, time/batch = 0.6788s	
5141/22300 (epoch 11.527), train_loss = 1.09335426, grad/param norm = 2.8189e-01, time/batch = 0.6871s	
5142/22300 (epoch 11.529), train_loss = 0.88320469, grad/param norm = 2.7044e-01, time/batch = 0.6789s	
5143/22300 (epoch 11.531), train_loss = 0.91696043, grad/param norm = 2.5758e-01, time/batch = 0.6821s	
5144/22300 (epoch 11.534), train_loss = 0.83990203, grad/param norm = 2.3166e-01, time/batch = 0.6876s	
5145/22300 (epoch 11.536), train_loss = 1.09460096, grad/param norm = 2.5385e-01, time/batch = 0.6803s	
5146/22300 (epoch 11.538), train_loss = 1.29355024, grad/param norm = 2.9380e-01, time/batch = 0.6837s	
5147/22300 (epoch 11.540), train_loss = 1.03454476, grad/param norm = 2.8766e-01, time/batch = 0.6829s	
5148/22300 (epoch 11.543), train_loss = 0.82986137, grad/param norm = 2.1733e-01, time/batch = 0.6869s	
5149/22300 (epoch 11.545), train_loss = 0.87047594, grad/param norm = 2.6782e-01, time/batch = 0.6812s	
5150/22300 (epoch 11.547), train_loss = 0.78773859, grad/param norm = 2.1907e-01, time/batch = 0.6808s	
5151/22300 (epoch 11.549), train_loss = 0.86918325, grad/param norm = 2.3880e-01, time/batch = 0.6854s	
5152/22300 (epoch 11.552), train_loss = 0.86745053, grad/param norm = 2.4517e-01, time/batch = 0.6857s	
5153/22300 (epoch 11.554), train_loss = 0.94988158, grad/param norm = 2.5653e-01, time/batch = 0.6866s	
5154/22300 (epoch 11.556), train_loss = 1.14067509, grad/param norm = 2.7065e-01, time/batch = 0.6939s	
5155/22300 (epoch 11.558), train_loss = 1.03089871, grad/param norm = 2.8421e-01, time/batch = 0.6862s	
5156/22300 (epoch 11.561), train_loss = 1.15606653, grad/param norm = 2.8067e-01, time/batch = 0.6848s	
5157/22300 (epoch 11.563), train_loss = 1.01074965, grad/param norm = 2.6342e-01, time/batch = 0.6861s	
5158/22300 (epoch 11.565), train_loss = 0.92662197, grad/param norm = 2.6759e-01, time/batch = 0.6883s	
5159/22300 (epoch 11.567), train_loss = 0.91819119, grad/param norm = 2.3570e-01, time/batch = 0.6794s	
5160/22300 (epoch 11.570), train_loss = 1.20496314, grad/param norm = 3.2675e-01, time/batch = 0.6801s	
5161/22300 (epoch 11.572), train_loss = 1.06323082, grad/param norm = 2.7991e-01, time/batch = 0.6769s	
5162/22300 (epoch 11.574), train_loss = 0.95145110, grad/param norm = 2.2716e-01, time/batch = 0.6774s	
5163/22300 (epoch 11.576), train_loss = 0.79918047, grad/param norm = 2.2534e-01, time/batch = 0.6798s	
5164/22300 (epoch 11.578), train_loss = 0.66937209, grad/param norm = 2.3262e-01, time/batch = 0.6843s	
5165/22300 (epoch 11.581), train_loss = 0.79999415, grad/param norm = 2.1809e-01, time/batch = 0.6794s	
5166/22300 (epoch 11.583), train_loss = 0.79225223, grad/param norm = 2.1455e-01, time/batch = 0.6813s	
5167/22300 (epoch 11.585), train_loss = 1.13870939, grad/param norm = 2.8752e-01, time/batch = 0.6785s	
5168/22300 (epoch 11.587), train_loss = 1.22662907, grad/param norm = 3.1104e-01, time/batch = 0.6775s	
5169/22300 (epoch 11.590), train_loss = 1.11612025, grad/param norm = 2.9265e-01, time/batch = 0.6802s	
5170/22300 (epoch 11.592), train_loss = 1.23414045, grad/param norm = 3.1825e-01, time/batch = 0.6825s	
5171/22300 (epoch 11.594), train_loss = 1.20186719, grad/param norm = 2.7418e-01, time/batch = 0.6874s	
5172/22300 (epoch 11.596), train_loss = 0.88817323, grad/param norm = 2.5020e-01, time/batch = 0.7080s	
5173/22300 (epoch 11.599), train_loss = 0.79512609, grad/param norm = 2.8867e-01, time/batch = 0.6795s	
5174/22300 (epoch 11.601), train_loss = 0.93785457, grad/param norm = 2.5178e-01, time/batch = 0.6829s	
5175/22300 (epoch 11.603), train_loss = 0.99447997, grad/param norm = 2.8485e-01, time/batch = 0.6835s	
5176/22300 (epoch 11.605), train_loss = 0.91727921, grad/param norm = 3.2094e-01, time/batch = 0.6836s	
5177/22300 (epoch 11.608), train_loss = 1.22817509, grad/param norm = 3.1570e-01, time/batch = 0.6816s	
5178/22300 (epoch 11.610), train_loss = 1.25957350, grad/param norm = 2.7171e-01, time/batch = 0.6869s	
5179/22300 (epoch 11.612), train_loss = 1.08779780, grad/param norm = 2.7889e-01, time/batch = 0.6787s	
5180/22300 (epoch 11.614), train_loss = 1.08557330, grad/param norm = 2.8172e-01, time/batch = 0.6830s	
5181/22300 (epoch 11.617), train_loss = 1.04113147, grad/param norm = 2.5369e-01, time/batch = 0.6983s	
5182/22300 (epoch 11.619), train_loss = 1.30926541, grad/param norm = 2.8517e-01, time/batch = 0.7165s	
5183/22300 (epoch 11.621), train_loss = 0.93514860, grad/param norm = 2.4973e-01, time/batch = 0.6984s	
5184/22300 (epoch 11.623), train_loss = 0.92097543, grad/param norm = 2.5727e-01, time/batch = 0.6969s	
5185/22300 (epoch 11.626), train_loss = 0.86426750, grad/param norm = 2.2265e-01, time/batch = 0.6839s	
5186/22300 (epoch 11.628), train_loss = 0.86211421, grad/param norm = 2.2320e-01, time/batch = 0.6827s	
5187/22300 (epoch 11.630), train_loss = 0.94070042, grad/param norm = 2.3333e-01, time/batch = 0.6766s	
5188/22300 (epoch 11.632), train_loss = 0.94849242, grad/param norm = 2.5638e-01, time/batch = 0.6784s	
5189/22300 (epoch 11.635), train_loss = 0.93406073, grad/param norm = 2.7345e-01, time/batch = 0.6814s	
5190/22300 (epoch 11.637), train_loss = 1.11752205, grad/param norm = 2.8816e-01, time/batch = 0.6791s	
5191/22300 (epoch 11.639), train_loss = 1.13034091, grad/param norm = 3.1912e-01, time/batch = 0.6813s	
5192/22300 (epoch 11.641), train_loss = 1.01570466, grad/param norm = 2.5952e-01, time/batch = 0.6814s	
5193/22300 (epoch 11.643), train_loss = 0.93484230, grad/param norm = 2.9045e-01, time/batch = 0.6692s	
5194/22300 (epoch 11.646), train_loss = 0.86911489, grad/param norm = 2.5063e-01, time/batch = 0.6702s	
5195/22300 (epoch 11.648), train_loss = 0.92121654, grad/param norm = 2.5288e-01, time/batch = 0.6813s	
5196/22300 (epoch 11.650), train_loss = 1.06386274, grad/param norm = 2.6488e-01, time/batch = 0.6801s	
5197/22300 (epoch 11.652), train_loss = 0.90561600, grad/param norm = 2.3286e-01, time/batch = 0.6804s	
5198/22300 (epoch 11.655), train_loss = 0.97959076, grad/param norm = 2.6945e-01, time/batch = 0.6809s	
5199/22300 (epoch 11.657), train_loss = 0.98007491, grad/param norm = 2.6101e-01, time/batch = 0.6805s	
5200/22300 (epoch 11.659), train_loss = 0.87964399, grad/param norm = 2.6623e-01, time/batch = 0.6780s	
5201/22300 (epoch 11.661), train_loss = 0.76811005, grad/param norm = 2.4482e-01, time/batch = 0.6794s	
5202/22300 (epoch 11.664), train_loss = 0.90638765, grad/param norm = 2.3257e-01, time/batch = 0.6802s	
5203/22300 (epoch 11.666), train_loss = 1.00104770, grad/param norm = 2.6459e-01, time/batch = 0.6802s	
5204/22300 (epoch 11.668), train_loss = 0.87598478, grad/param norm = 2.5447e-01, time/batch = 0.6783s	
5205/22300 (epoch 11.670), train_loss = 1.00971219, grad/param norm = 2.5132e-01, time/batch = 0.6799s	
5206/22300 (epoch 11.673), train_loss = 1.07265928, grad/param norm = 2.7804e-01, time/batch = 0.6780s	
5207/22300 (epoch 11.675), train_loss = 1.16888993, grad/param norm = 2.8567e-01, time/batch = 0.6783s	
5208/22300 (epoch 11.677), train_loss = 1.18449627, grad/param norm = 3.0380e-01, time/batch = 0.7148s	
5209/22300 (epoch 11.679), train_loss = 1.08545064, grad/param norm = 3.0886e-01, time/batch = 0.6881s	
5210/22300 (epoch 11.682), train_loss = 1.04103349, grad/param norm = 2.7912e-01, time/batch = 0.6843s	
5211/22300 (epoch 11.684), train_loss = 0.99397781, grad/param norm = 2.5785e-01, time/batch = 0.6926s	
5212/22300 (epoch 11.686), train_loss = 1.03113698, grad/param norm = 3.0144e-01, time/batch = 0.7048s	
5213/22300 (epoch 11.688), train_loss = 1.02778451, grad/param norm = 3.0803e-01, time/batch = 0.7024s	
5214/22300 (epoch 11.691), train_loss = 0.93595001, grad/param norm = 2.5123e-01, time/batch = 0.6995s	
5215/22300 (epoch 11.693), train_loss = 0.94330941, grad/param norm = 2.8219e-01, time/batch = 0.7156s	
5216/22300 (epoch 11.695), train_loss = 0.78031508, grad/param norm = 2.3579e-01, time/batch = 0.6975s	
5217/22300 (epoch 11.697), train_loss = 0.77396472, grad/param norm = 2.2673e-01, time/batch = 0.6965s	
5218/22300 (epoch 11.700), train_loss = 0.93425388, grad/param norm = 2.9150e-01, time/batch = 0.7070s	
5219/22300 (epoch 11.702), train_loss = 0.98696925, grad/param norm = 2.5511e-01, time/batch = 0.6961s	
5220/22300 (epoch 11.704), train_loss = 1.03612847, grad/param norm = 2.7049e-01, time/batch = 0.6930s	
5221/22300 (epoch 11.706), train_loss = 0.85821853, grad/param norm = 2.6783e-01, time/batch = 0.7108s	
5222/22300 (epoch 11.709), train_loss = 0.80875263, grad/param norm = 2.4584e-01, time/batch = 0.6998s	
5223/22300 (epoch 11.711), train_loss = 0.84651939, grad/param norm = 2.7186e-01, time/batch = 0.6981s	
5224/22300 (epoch 11.713), train_loss = 1.04176888, grad/param norm = 2.5602e-01, time/batch = 0.6983s	
5225/22300 (epoch 11.715), train_loss = 1.00166132, grad/param norm = 2.8205e-01, time/batch = 0.6997s	
5226/22300 (epoch 11.717), train_loss = 1.18148194, grad/param norm = 2.6975e-01, time/batch = 0.6982s	
5227/22300 (epoch 11.720), train_loss = 0.92048637, grad/param norm = 2.6845e-01, time/batch = 0.7000s	
5228/22300 (epoch 11.722), train_loss = 1.02992913, grad/param norm = 2.7253e-01, time/batch = 0.6998s	
5229/22300 (epoch 11.724), train_loss = 1.02002400, grad/param norm = 2.6714e-01, time/batch = 0.6976s	
5230/22300 (epoch 11.726), train_loss = 0.93953290, grad/param norm = 2.6790e-01, time/batch = 0.6951s	
5231/22300 (epoch 11.729), train_loss = 0.97346974, grad/param norm = 2.5672e-01, time/batch = 0.7026s	
5232/22300 (epoch 11.731), train_loss = 1.15490709, grad/param norm = 2.8116e-01, time/batch = 0.7007s	
5233/22300 (epoch 11.733), train_loss = 1.13440897, grad/param norm = 2.9598e-01, time/batch = 0.7020s	
5234/22300 (epoch 11.735), train_loss = 1.17881599, grad/param norm = 3.3247e-01, time/batch = 0.6989s	
5235/22300 (epoch 11.738), train_loss = 1.04552131, grad/param norm = 3.1006e-01, time/batch = 0.6988s	
5236/22300 (epoch 11.740), train_loss = 0.81192819, grad/param norm = 2.4133e-01, time/batch = 0.6994s	
5237/22300 (epoch 11.742), train_loss = 0.96910355, grad/param norm = 2.8638e-01, time/batch = 0.6971s	
5238/22300 (epoch 11.744), train_loss = 1.23502750, grad/param norm = 2.7965e-01, time/batch = 0.6993s	
5239/22300 (epoch 11.747), train_loss = 0.97449769, grad/param norm = 2.5251e-01, time/batch = 0.7012s	
5240/22300 (epoch 11.749), train_loss = 1.32325528, grad/param norm = 3.1505e-01, time/batch = 0.6989s	
5241/22300 (epoch 11.751), train_loss = 1.18179793, grad/param norm = 3.4903e-01, time/batch = 0.7033s	
5242/22300 (epoch 11.753), train_loss = 1.18870031, grad/param norm = 3.1178e-01, time/batch = 0.7014s	
5243/22300 (epoch 11.756), train_loss = 1.01271406, grad/param norm = 2.5557e-01, time/batch = 0.6971s	
5244/22300 (epoch 11.758), train_loss = 1.03582703, grad/param norm = 2.5015e-01, time/batch = 0.6986s	
5245/22300 (epoch 11.760), train_loss = 1.06910229, grad/param norm = 2.9742e-01, time/batch = 0.6984s	
5246/22300 (epoch 11.762), train_loss = 1.02822796, grad/param norm = 2.8342e-01, time/batch = 0.6971s	
5247/22300 (epoch 11.765), train_loss = 1.04248246, grad/param norm = 2.7178e-01, time/batch = 0.6974s	
5248/22300 (epoch 11.767), train_loss = 1.10965177, grad/param norm = 3.3985e-01, time/batch = 0.7016s	
5249/22300 (epoch 11.769), train_loss = 1.01637968, grad/param norm = 3.1280e-01, time/batch = 0.6968s	
5250/22300 (epoch 11.771), train_loss = 1.06972170, grad/param norm = 2.8441e-01, time/batch = 0.6971s	
5251/22300 (epoch 11.774), train_loss = 1.12850045, grad/param norm = 3.1131e-01, time/batch = 0.6979s	
5252/22300 (epoch 11.776), train_loss = 1.11652781, grad/param norm = 2.8703e-01, time/batch = 0.6993s	
5253/22300 (epoch 11.778), train_loss = 1.16369237, grad/param norm = 3.0024e-01, time/batch = 0.6986s	
5254/22300 (epoch 11.780), train_loss = 1.15399405, grad/param norm = 2.8874e-01, time/batch = 0.6944s	
5255/22300 (epoch 11.783), train_loss = 1.18713017, grad/param norm = 2.9818e-01, time/batch = 0.6825s	
5256/22300 (epoch 11.785), train_loss = 0.94348410, grad/param norm = 2.6633e-01, time/batch = 0.6959s	
5257/22300 (epoch 11.787), train_loss = 0.97578603, grad/param norm = 2.4715e-01, time/batch = 0.6996s	
5258/22300 (epoch 11.789), train_loss = 1.14438549, grad/param norm = 2.9459e-01, time/batch = 0.7262s	
5259/22300 (epoch 11.791), train_loss = 1.26516765, grad/param norm = 2.8940e-01, time/batch = 0.7361s	
5260/22300 (epoch 11.794), train_loss = 1.17975351, grad/param norm = 2.8689e-01, time/batch = 0.7305s	
5261/22300 (epoch 11.796), train_loss = 1.19451849, grad/param norm = 2.6853e-01, time/batch = 0.7236s	
5262/22300 (epoch 11.798), train_loss = 1.15495921, grad/param norm = 2.6678e-01, time/batch = 0.7135s	
5263/22300 (epoch 11.800), train_loss = 0.95006288, grad/param norm = 2.5268e-01, time/batch = 0.7012s	
5264/22300 (epoch 11.803), train_loss = 0.90731695, grad/param norm = 2.4917e-01, time/batch = 0.6923s	
5265/22300 (epoch 11.805), train_loss = 1.02341927, grad/param norm = 2.5250e-01, time/batch = 0.6859s	
5266/22300 (epoch 11.807), train_loss = 1.14288866, grad/param norm = 2.6931e-01, time/batch = 0.6988s	
5267/22300 (epoch 11.809), train_loss = 1.02157586, grad/param norm = 2.6887e-01, time/batch = 0.7133s	
5268/22300 (epoch 11.812), train_loss = 1.10869903, grad/param norm = 2.5066e-01, time/batch = 0.6947s	
5269/22300 (epoch 11.814), train_loss = 1.07550036, grad/param norm = 2.6766e-01, time/batch = 0.6873s	
5270/22300 (epoch 11.816), train_loss = 1.11165776, grad/param norm = 2.7112e-01, time/batch = 0.6991s	
5271/22300 (epoch 11.818), train_loss = 1.15639558, grad/param norm = 2.9216e-01, time/batch = 0.7060s	
5272/22300 (epoch 11.821), train_loss = 1.15770723, grad/param norm = 2.9819e-01, time/batch = 0.7035s	
5273/22300 (epoch 11.823), train_loss = 0.89079109, grad/param norm = 2.5143e-01, time/batch = 0.7002s	
5274/22300 (epoch 11.825), train_loss = 1.01099690, grad/param norm = 2.4209e-01, time/batch = 0.6944s	
5275/22300 (epoch 11.827), train_loss = 0.97781265, grad/param norm = 2.6305e-01, time/batch = 0.7028s	
5276/22300 (epoch 11.830), train_loss = 0.92743114, grad/param norm = 2.5983e-01, time/batch = 0.7019s	
5277/22300 (epoch 11.832), train_loss = 0.92088712, grad/param norm = 2.5563e-01, time/batch = 0.7182s	
5278/22300 (epoch 11.834), train_loss = 0.96299751, grad/param norm = 2.6323e-01, time/batch = 0.7243s	
5279/22300 (epoch 11.836), train_loss = 1.00126497, grad/param norm = 2.7058e-01, time/batch = 0.7027s	
5280/22300 (epoch 11.839), train_loss = 1.01189093, grad/param norm = 2.7327e-01, time/batch = 0.7025s	
5281/22300 (epoch 11.841), train_loss = 1.01153518, grad/param norm = 3.0839e-01, time/batch = 0.7049s	
5282/22300 (epoch 11.843), train_loss = 1.01845564, grad/param norm = 3.1934e-01, time/batch = 0.6985s	
5283/22300 (epoch 11.845), train_loss = 0.99270785, grad/param norm = 2.3337e-01, time/batch = 0.6986s	
5284/22300 (epoch 11.848), train_loss = 0.98218509, grad/param norm = 2.4014e-01, time/batch = 0.7063s	
5285/22300 (epoch 11.850), train_loss = 1.00075410, grad/param norm = 2.4093e-01, time/batch = 0.6953s	
5286/22300 (epoch 11.852), train_loss = 1.02654473, grad/param norm = 2.8524e-01, time/batch = 0.6960s	
5287/22300 (epoch 11.854), train_loss = 1.18460771, grad/param norm = 3.2285e-01, time/batch = 0.6982s	
5288/22300 (epoch 11.857), train_loss = 0.99614390, grad/param norm = 2.9184e-01, time/batch = 0.6954s	
5289/22300 (epoch 11.859), train_loss = 0.84545833, grad/param norm = 2.5218e-01, time/batch = 0.6969s	
5290/22300 (epoch 11.861), train_loss = 1.02878167, grad/param norm = 2.5859e-01, time/batch = 0.6985s	
5291/22300 (epoch 11.863), train_loss = 0.84343438, grad/param norm = 2.4437e-01, time/batch = 0.7003s	
5292/22300 (epoch 11.865), train_loss = 0.88221092, grad/param norm = 2.4491e-01, time/batch = 0.6977s	
5293/22300 (epoch 11.868), train_loss = 0.97593247, grad/param norm = 2.5000e-01, time/batch = 0.6940s	
5294/22300 (epoch 11.870), train_loss = 1.01358624, grad/param norm = 2.6461e-01, time/batch = 0.6930s	
5295/22300 (epoch 11.872), train_loss = 1.09430599, grad/param norm = 2.8224e-01, time/batch = 0.6939s	
5296/22300 (epoch 11.874), train_loss = 1.00594052, grad/param norm = 2.7705e-01, time/batch = 0.6952s	
5297/22300 (epoch 11.877), train_loss = 1.02601109, grad/param norm = 2.5947e-01, time/batch = 0.6942s	
5298/22300 (epoch 11.879), train_loss = 0.90341810, grad/param norm = 2.5904e-01, time/batch = 0.6921s	
5299/22300 (epoch 11.881), train_loss = 0.95194408, grad/param norm = 2.7178e-01, time/batch = 0.6964s	
5300/22300 (epoch 11.883), train_loss = 0.91595073, grad/param norm = 2.4391e-01, time/batch = 0.7035s	
5301/22300 (epoch 11.886), train_loss = 0.93299999, grad/param norm = 2.2056e-01, time/batch = 0.6924s	
5302/22300 (epoch 11.888), train_loss = 0.95670948, grad/param norm = 2.6759e-01, time/batch = 0.7018s	
5303/22300 (epoch 11.890), train_loss = 0.86810503, grad/param norm = 2.2118e-01, time/batch = 0.6996s	
5304/22300 (epoch 11.892), train_loss = 1.16677492, grad/param norm = 2.8294e-01, time/batch = 0.6942s	
5305/22300 (epoch 11.895), train_loss = 1.14584380, grad/param norm = 2.8994e-01, time/batch = 0.6966s	
5306/22300 (epoch 11.897), train_loss = 1.04336819, grad/param norm = 2.9952e-01, time/batch = 0.6976s	
5307/22300 (epoch 11.899), train_loss = 1.06748967, grad/param norm = 2.7847e-01, time/batch = 0.6963s	
5308/22300 (epoch 11.901), train_loss = 0.97213750, grad/param norm = 2.6084e-01, time/batch = 0.6977s	
5309/22300 (epoch 11.904), train_loss = 1.07753167, grad/param norm = 2.7795e-01, time/batch = 0.7005s	
5310/22300 (epoch 11.906), train_loss = 1.10132832, grad/param norm = 2.6233e-01, time/batch = 0.6978s	
5311/22300 (epoch 11.908), train_loss = 1.01722489, grad/param norm = 2.5612e-01, time/batch = 0.7014s	
5312/22300 (epoch 11.910), train_loss = 0.86070190, grad/param norm = 2.5574e-01, time/batch = 0.6945s	
5313/22300 (epoch 11.913), train_loss = 1.02499033, grad/param norm = 2.6487e-01, time/batch = 0.6814s	
5314/22300 (epoch 11.915), train_loss = 1.22660675, grad/param norm = 3.0154e-01, time/batch = 0.6797s	
5315/22300 (epoch 11.917), train_loss = 1.03041982, grad/param norm = 2.5904e-01, time/batch = 0.6893s	
5316/22300 (epoch 11.919), train_loss = 1.06166367, grad/param norm = 2.5399e-01, time/batch = 0.6928s	
5317/22300 (epoch 11.922), train_loss = 0.99200986, grad/param norm = 2.7325e-01, time/batch = 0.6917s	
5318/22300 (epoch 11.924), train_loss = 0.76475585, grad/param norm = 2.2739e-01, time/batch = 0.6917s	
5319/22300 (epoch 11.926), train_loss = 0.80494611, grad/param norm = 2.5908e-01, time/batch = 0.6833s	
5320/22300 (epoch 11.928), train_loss = 0.96598948, grad/param norm = 2.5333e-01, time/batch = 0.6874s	
5321/22300 (epoch 11.930), train_loss = 0.98244353, grad/param norm = 2.6249e-01, time/batch = 0.6960s	
5322/22300 (epoch 11.933), train_loss = 1.07199521, grad/param norm = 2.8029e-01, time/batch = 0.6948s	
5323/22300 (epoch 11.935), train_loss = 1.12999260, grad/param norm = 2.8569e-01, time/batch = 0.6923s	
5324/22300 (epoch 11.937), train_loss = 1.15540920, grad/param norm = 2.9883e-01, time/batch = 0.6932s	
5325/22300 (epoch 11.939), train_loss = 1.09878264, grad/param norm = 2.9846e-01, time/batch = 0.6917s	
5326/22300 (epoch 11.942), train_loss = 1.25967439, grad/param norm = 2.9663e-01, time/batch = 0.7178s	
5327/22300 (epoch 11.944), train_loss = 1.28446607, grad/param norm = 3.1695e-01, time/batch = 0.7099s	
5328/22300 (epoch 11.946), train_loss = 1.00056050, grad/param norm = 3.1290e-01, time/batch = 0.6983s	
5329/22300 (epoch 11.948), train_loss = 0.94615310, grad/param norm = 2.4468e-01, time/batch = 0.6931s	
5330/22300 (epoch 11.951), train_loss = 0.85276377, grad/param norm = 2.7002e-01, time/batch = 0.6948s	
5331/22300 (epoch 11.953), train_loss = 0.89520970, grad/param norm = 2.6462e-01, time/batch = 0.6950s	
5332/22300 (epoch 11.955), train_loss = 1.22403066, grad/param norm = 2.8775e-01, time/batch = 0.6985s	
5333/22300 (epoch 11.957), train_loss = 1.35640363, grad/param norm = 3.1984e-01, time/batch = 0.6961s	
5334/22300 (epoch 11.960), train_loss = 1.15140943, grad/param norm = 2.8495e-01, time/batch = 0.6914s	
5335/22300 (epoch 11.962), train_loss = 1.03435962, grad/param norm = 2.7851e-01, time/batch = 0.6937s	
5336/22300 (epoch 11.964), train_loss = 0.98921269, grad/param norm = 2.5666e-01, time/batch = 0.6927s	
5337/22300 (epoch 11.966), train_loss = 0.95184429, grad/param norm = 2.9821e-01, time/batch = 0.6926s	
5338/22300 (epoch 11.969), train_loss = 0.92356564, grad/param norm = 2.2719e-01, time/batch = 0.6950s	
5339/22300 (epoch 11.971), train_loss = 0.98142469, grad/param norm = 2.5480e-01, time/batch = 0.6937s	
5340/22300 (epoch 11.973), train_loss = 1.02393595, grad/param norm = 2.9843e-01, time/batch = 0.6926s	
5341/22300 (epoch 11.975), train_loss = 1.27761495, grad/param norm = 3.3408e-01, time/batch = 0.6976s	
5342/22300 (epoch 11.978), train_loss = 1.04630439, grad/param norm = 2.7417e-01, time/batch = 0.6994s	
5343/22300 (epoch 11.980), train_loss = 1.10846469, grad/param norm = 2.7071e-01, time/batch = 0.6982s	
5344/22300 (epoch 11.982), train_loss = 0.91253365, grad/param norm = 2.5277e-01, time/batch = 0.7140s	
5345/22300 (epoch 11.984), train_loss = 1.05940415, grad/param norm = 2.7321e-01, time/batch = 0.6948s	
5346/22300 (epoch 11.987), train_loss = 0.94612988, grad/param norm = 2.3680e-01, time/batch = 0.6948s	
5347/22300 (epoch 11.989), train_loss = 1.00117535, grad/param norm = 2.7742e-01, time/batch = 0.6951s	
5348/22300 (epoch 11.991), train_loss = 1.23267718, grad/param norm = 2.8240e-01, time/batch = 0.6952s	
5349/22300 (epoch 11.993), train_loss = 1.35892437, grad/param norm = 3.0244e-01, time/batch = 0.6930s	
5350/22300 (epoch 11.996), train_loss = 1.32119712, grad/param norm = 3.2793e-01, time/batch = 0.6925s	
5351/22300 (epoch 11.998), train_loss = 0.99384558, grad/param norm = 2.6989e-01, time/batch = 0.6967s	
decayed learning rate by a factor 0.97 to 0.001825346	
5352/22300 (epoch 12.000), train_loss = 0.87057567, grad/param norm = 2.6317e-01, time/batch = 0.6993s	
5353/22300 (epoch 12.002), train_loss = 1.20757068, grad/param norm = 3.3832e-01, time/batch = 0.7055s	
5354/22300 (epoch 12.004), train_loss = 0.99351774, grad/param norm = 2.3483e-01, time/batch = 0.6884s	
5355/22300 (epoch 12.007), train_loss = 1.01249107, grad/param norm = 2.4433e-01, time/batch = 0.6976s	
5356/22300 (epoch 12.009), train_loss = 1.03723276, grad/param norm = 2.6087e-01, time/batch = 0.6943s	
5357/22300 (epoch 12.011), train_loss = 1.21841879, grad/param norm = 3.1524e-01, time/batch = 0.6944s	
5358/22300 (epoch 12.013), train_loss = 0.97385229, grad/param norm = 2.5699e-01, time/batch = 0.6933s	
5359/22300 (epoch 12.016), train_loss = 0.96378530, grad/param norm = 2.7619e-01, time/batch = 0.6940s	
5360/22300 (epoch 12.018), train_loss = 1.12190407, grad/param norm = 2.7986e-01, time/batch = 0.6937s	
5361/22300 (epoch 12.020), train_loss = 0.98548919, grad/param norm = 2.7967e-01, time/batch = 0.6996s	
5362/22300 (epoch 12.022), train_loss = 0.91396892, grad/param norm = 2.7017e-01, time/batch = 0.6990s	
5363/22300 (epoch 12.025), train_loss = 0.92651334, grad/param norm = 2.4986e-01, time/batch = 0.6950s	
5364/22300 (epoch 12.027), train_loss = 1.00053497, grad/param norm = 2.5491e-01, time/batch = 0.6989s	
5365/22300 (epoch 12.029), train_loss = 0.91060006, grad/param norm = 2.4069e-01, time/batch = 0.6937s	
5366/22300 (epoch 12.031), train_loss = 0.88262828, grad/param norm = 2.1303e-01, time/batch = 0.6938s	
5367/22300 (epoch 12.034), train_loss = 0.92314191, grad/param norm = 2.5480e-01, time/batch = 0.6928s	
5368/22300 (epoch 12.036), train_loss = 0.75620469, grad/param norm = 2.1810e-01, time/batch = 0.6911s	
5369/22300 (epoch 12.038), train_loss = 0.87254153, grad/param norm = 2.2506e-01, time/batch = 0.6946s	
5370/22300 (epoch 12.040), train_loss = 0.97789146, grad/param norm = 2.4966e-01, time/batch = 0.6961s	
5371/22300 (epoch 12.043), train_loss = 1.22101053, grad/param norm = 2.8507e-01, time/batch = 0.7012s	
5372/22300 (epoch 12.045), train_loss = 1.03576747, grad/param norm = 2.5243e-01, time/batch = 0.6924s	
5373/22300 (epoch 12.047), train_loss = 1.11201658, grad/param norm = 2.7101e-01, time/batch = 0.6943s	
5374/22300 (epoch 12.049), train_loss = 0.94783510, grad/param norm = 2.5394e-01, time/batch = 0.6917s	
5375/22300 (epoch 12.052), train_loss = 1.08383718, grad/param norm = 2.9507e-01, time/batch = 0.6911s	
5376/22300 (epoch 12.054), train_loss = 1.05454796, grad/param norm = 2.8679e-01, time/batch = 0.6930s	
5377/22300 (epoch 12.056), train_loss = 0.74293055, grad/param norm = 2.3619e-01, time/batch = 0.6926s	
5378/22300 (epoch 12.058), train_loss = 0.87977187, grad/param norm = 2.5382e-01, time/batch = 0.6941s	
5379/22300 (epoch 12.061), train_loss = 0.85523525, grad/param norm = 2.3986e-01, time/batch = 0.6936s	
5380/22300 (epoch 12.063), train_loss = 1.19817843, grad/param norm = 3.2230e-01, time/batch = 0.6941s	
5381/22300 (epoch 12.065), train_loss = 1.06874315, grad/param norm = 2.7156e-01, time/batch = 0.7016s	
5382/22300 (epoch 12.067), train_loss = 0.93185140, grad/param norm = 2.8968e-01, time/batch = 0.6959s	
5383/22300 (epoch 12.070), train_loss = 0.96621863, grad/param norm = 2.6926e-01, time/batch = 0.7142s	
5384/22300 (epoch 12.072), train_loss = 1.05539336, grad/param norm = 2.7363e-01, time/batch = 0.7180s	
5385/22300 (epoch 12.074), train_loss = 1.02321873, grad/param norm = 2.6101e-01, time/batch = 0.6993s	
5386/22300 (epoch 12.076), train_loss = 0.97976481, grad/param norm = 2.6533e-01, time/batch = 0.6995s	
5387/22300 (epoch 12.078), train_loss = 1.06292498, grad/param norm = 2.6629e-01, time/batch = 0.7000s	
5388/22300 (epoch 12.081), train_loss = 1.08293105, grad/param norm = 2.7591e-01, time/batch = 0.6933s	
5389/22300 (epoch 12.083), train_loss = 1.19941992, grad/param norm = 2.9489e-01, time/batch = 0.6972s	
5390/22300 (epoch 12.085), train_loss = 1.25945591, grad/param norm = 2.9857e-01, time/batch = 0.6942s	
5391/22300 (epoch 12.087), train_loss = 1.04053356, grad/param norm = 2.6515e-01, time/batch = 0.6935s	
5392/22300 (epoch 12.090), train_loss = 0.86684003, grad/param norm = 2.3395e-01, time/batch = 0.6970s	
5393/22300 (epoch 12.092), train_loss = 0.90650580, grad/param norm = 2.7139e-01, time/batch = 0.6973s	
5394/22300 (epoch 12.094), train_loss = 0.88591848, grad/param norm = 2.4658e-01, time/batch = 0.6913s	
5395/22300 (epoch 12.096), train_loss = 1.17828845, grad/param norm = 2.9161e-01, time/batch = 0.6950s	
5396/22300 (epoch 12.099), train_loss = 0.96471944, grad/param norm = 2.5712e-01, time/batch = 0.6927s	
5397/22300 (epoch 12.101), train_loss = 1.13139937, grad/param norm = 2.8072e-01, time/batch = 0.6962s	
5398/22300 (epoch 12.103), train_loss = 1.04987330, grad/param norm = 2.6024e-01, time/batch = 0.6959s	
5399/22300 (epoch 12.105), train_loss = 1.01478028, grad/param norm = 2.8644e-01, time/batch = 0.6940s	
5400/22300 (epoch 12.108), train_loss = 1.01704529, grad/param norm = 2.3582e-01, time/batch = 0.6926s	
5401/22300 (epoch 12.110), train_loss = 1.01808217, grad/param norm = 2.3276e-01, time/batch = 0.6964s	
5402/22300 (epoch 12.112), train_loss = 0.98977507, grad/param norm = 2.4285e-01, time/batch = 0.6943s	
5403/22300 (epoch 12.114), train_loss = 1.08630292, grad/param norm = 2.6796e-01, time/batch = 0.6969s	
5404/22300 (epoch 12.117), train_loss = 1.23330017, grad/param norm = 2.6443e-01, time/batch = 0.6997s	
5405/22300 (epoch 12.119), train_loss = 1.10696188, grad/param norm = 2.5672e-01, time/batch = 0.6953s	
5406/22300 (epoch 12.121), train_loss = 1.17957764, grad/param norm = 3.0443e-01, time/batch = 0.6934s	
5407/22300 (epoch 12.123), train_loss = 1.05755229, grad/param norm = 2.4996e-01, time/batch = 0.6949s	
5408/22300 (epoch 12.126), train_loss = 1.00552210, grad/param norm = 2.5777e-01, time/batch = 0.6925s	
5409/22300 (epoch 12.128), train_loss = 1.11100484, grad/param norm = 2.5029e-01, time/batch = 0.6965s	
5410/22300 (epoch 12.130), train_loss = 0.97043387, grad/param norm = 2.6699e-01, time/batch = 0.6956s	
5411/22300 (epoch 12.132), train_loss = 0.84813373, grad/param norm = 2.1795e-01, time/batch = 0.6987s	
5412/22300 (epoch 12.135), train_loss = 0.86660328, grad/param norm = 2.4380e-01, time/batch = 0.6959s	
5413/22300 (epoch 12.137), train_loss = 0.68885707, grad/param norm = 2.0639e-01, time/batch = 0.6986s	
5414/22300 (epoch 12.139), train_loss = 1.06097279, grad/param norm = 2.6541e-01, time/batch = 0.6930s	
5415/22300 (epoch 12.141), train_loss = 1.07817801, grad/param norm = 2.4396e-01, time/batch = 0.6916s	
5416/22300 (epoch 12.143), train_loss = 1.02561614, grad/param norm = 2.5067e-01, time/batch = 0.6936s	
5417/22300 (epoch 12.146), train_loss = 1.16425903, grad/param norm = 2.8506e-01, time/batch = 0.6957s	
5418/22300 (epoch 12.148), train_loss = 0.91494960, grad/param norm = 2.4156e-01, time/batch = 0.6964s	
5419/22300 (epoch 12.150), train_loss = 0.93764246, grad/param norm = 2.5786e-01, time/batch = 0.6996s	
5420/22300 (epoch 12.152), train_loss = 0.88858557, grad/param norm = 2.6962e-01, time/batch = 0.6931s	
5421/22300 (epoch 12.155), train_loss = 0.93343758, grad/param norm = 2.5184e-01, time/batch = 0.6945s	
5422/22300 (epoch 12.157), train_loss = 1.15998168, grad/param norm = 3.1616e-01, time/batch = 0.6864s	
5423/22300 (epoch 12.159), train_loss = 1.08902640, grad/param norm = 2.8941e-01, time/batch = 0.6922s	
5424/22300 (epoch 12.161), train_loss = 1.12881611, grad/param norm = 2.8352e-01, time/batch = 0.6885s	
5425/22300 (epoch 12.164), train_loss = 0.86695340, grad/param norm = 2.3716e-01, time/batch = 0.6849s	
5426/22300 (epoch 12.166), train_loss = 0.86723292, grad/param norm = 2.1302e-01, time/batch = 0.6942s	
5427/22300 (epoch 12.168), train_loss = 0.91897416, grad/param norm = 2.2910e-01, time/batch = 0.6918s	
5428/22300 (epoch 12.170), train_loss = 1.00004049, grad/param norm = 2.2428e-01, time/batch = 0.6966s	
5429/22300 (epoch 12.173), train_loss = 1.19145289, grad/param norm = 2.8720e-01, time/batch = 0.7014s	
5430/22300 (epoch 12.175), train_loss = 0.96522729, grad/param norm = 2.6454e-01, time/batch = 0.7032s	
5431/22300 (epoch 12.177), train_loss = 0.80732335, grad/param norm = 2.1674e-01, time/batch = 0.6915s	
5432/22300 (epoch 12.179), train_loss = 0.96046192, grad/param norm = 2.4413e-01, time/batch = 0.6989s	
5433/22300 (epoch 12.182), train_loss = 1.19827470, grad/param norm = 2.9305e-01, time/batch = 0.6994s	
5434/22300 (epoch 12.184), train_loss = 1.25640088, grad/param norm = 2.8288e-01, time/batch = 0.6934s	
5435/22300 (epoch 12.186), train_loss = 1.07692438, grad/param norm = 2.8929e-01, time/batch = 0.6912s	
5436/22300 (epoch 12.188), train_loss = 1.20128728, grad/param norm = 2.9149e-01, time/batch = 0.6910s	
5437/22300 (epoch 12.191), train_loss = 1.21025890, grad/param norm = 3.0005e-01, time/batch = 0.6891s	
5438/22300 (epoch 12.193), train_loss = 1.00956841, grad/param norm = 2.7914e-01, time/batch = 0.6891s	
5439/22300 (epoch 12.195), train_loss = 0.93481484, grad/param norm = 2.6113e-01, time/batch = 0.6891s	
5440/22300 (epoch 12.197), train_loss = 0.97295947, grad/param norm = 2.7522e-01, time/batch = 0.6885s	
5441/22300 (epoch 12.200), train_loss = 0.88188528, grad/param norm = 2.6243e-01, time/batch = 0.6924s	
5442/22300 (epoch 12.202), train_loss = 0.96432201, grad/param norm = 2.5285e-01, time/batch = 0.6901s	
5443/22300 (epoch 12.204), train_loss = 0.93532913, grad/param norm = 2.3494e-01, time/batch = 0.6888s	
5444/22300 (epoch 12.206), train_loss = 0.86726315, grad/param norm = 2.2543e-01, time/batch = 0.6962s	
5445/22300 (epoch 12.209), train_loss = 0.99108041, grad/param norm = 2.6613e-01, time/batch = 0.6854s	
5446/22300 (epoch 12.211), train_loss = 0.82343779, grad/param norm = 2.5004e-01, time/batch = 0.6896s	
5447/22300 (epoch 12.213), train_loss = 0.93533595, grad/param norm = 2.3216e-01, time/batch = 0.6893s	
5448/22300 (epoch 12.215), train_loss = 1.18288132, grad/param norm = 2.7364e-01, time/batch = 0.6914s	
5449/22300 (epoch 12.217), train_loss = 1.09891300, grad/param norm = 2.6076e-01, time/batch = 0.6789s	
5450/22300 (epoch 12.220), train_loss = 0.99217635, grad/param norm = 2.6091e-01, time/batch = 0.6767s	
5451/22300 (epoch 12.222), train_loss = 0.91518413, grad/param norm = 2.7425e-01, time/batch = 0.6783s	
5452/22300 (epoch 12.224), train_loss = 0.88876690, grad/param norm = 2.4086e-01, time/batch = 0.6811s	
5453/22300 (epoch 12.226), train_loss = 0.95380845, grad/param norm = 2.4226e-01, time/batch = 0.6755s	
5454/22300 (epoch 12.229), train_loss = 0.94345054, grad/param norm = 2.7919e-01, time/batch = 0.6738s	
5455/22300 (epoch 12.231), train_loss = 1.08907344, grad/param norm = 3.0338e-01, time/batch = 0.7000s	
5456/22300 (epoch 12.233), train_loss = 1.05974600, grad/param norm = 2.5973e-01, time/batch = 0.6971s	
5457/22300 (epoch 12.235), train_loss = 0.86141990, grad/param norm = 3.0548e-01, time/batch = 0.6959s	
5458/22300 (epoch 12.238), train_loss = 0.84760495, grad/param norm = 2.3141e-01, time/batch = 0.6939s	
5459/22300 (epoch 12.240), train_loss = 0.84707758, grad/param norm = 2.2493e-01, time/batch = 0.6986s	
5460/22300 (epoch 12.242), train_loss = 0.88389637, grad/param norm = 2.3187e-01, time/batch = 0.7083s	
5461/22300 (epoch 12.244), train_loss = 0.68677140, grad/param norm = 2.1234e-01, time/batch = 0.6993s	
5462/22300 (epoch 12.247), train_loss = 0.88364739, grad/param norm = 2.6667e-01, time/batch = 0.6978s	
5463/22300 (epoch 12.249), train_loss = 0.76364531, grad/param norm = 2.4099e-01, time/batch = 0.6850s	
5464/22300 (epoch 12.251), train_loss = 0.83545748, grad/param norm = 2.2093e-01, time/batch = 0.6807s	
5465/22300 (epoch 12.253), train_loss = 0.75434625, grad/param norm = 2.2067e-01, time/batch = 0.6753s	
5466/22300 (epoch 12.256), train_loss = 0.87234592, grad/param norm = 2.2775e-01, time/batch = 0.6768s	
5467/22300 (epoch 12.258), train_loss = 1.14959836, grad/param norm = 3.0716e-01, time/batch = 0.6754s	
5468/22300 (epoch 12.260), train_loss = 0.97578399, grad/param norm = 2.6678e-01, time/batch = 0.6757s	
5469/22300 (epoch 12.262), train_loss = 0.88451678, grad/param norm = 2.3965e-01, time/batch = 0.6779s	
5470/22300 (epoch 12.265), train_loss = 0.89808194, grad/param norm = 2.8694e-01, time/batch = 0.6789s	
5471/22300 (epoch 12.267), train_loss = 0.94026875, grad/param norm = 2.5451e-01, time/batch = 0.6823s	
5472/22300 (epoch 12.269), train_loss = 0.96069629, grad/param norm = 2.7737e-01, time/batch = 0.6757s	
5473/22300 (epoch 12.271), train_loss = 0.89897426, grad/param norm = 2.3440e-01, time/batch = 0.6746s	
5474/22300 (epoch 12.274), train_loss = 0.77814216, grad/param norm = 2.3129e-01, time/batch = 0.6838s	
5475/22300 (epoch 12.276), train_loss = 0.71265175, grad/param norm = 1.9850e-01, time/batch = 0.6866s	
5476/22300 (epoch 12.278), train_loss = 0.68876329, grad/param norm = 2.0509e-01, time/batch = 0.6772s	
5477/22300 (epoch 12.280), train_loss = 0.86148263, grad/param norm = 2.5549e-01, time/batch = 0.6805s	
5478/22300 (epoch 12.283), train_loss = 0.65808157, grad/param norm = 1.7559e-01, time/batch = 0.6764s	
5479/22300 (epoch 12.285), train_loss = 0.87657215, grad/param norm = 2.5750e-01, time/batch = 0.6758s	
5480/22300 (epoch 12.287), train_loss = 0.99872442, grad/param norm = 2.8080e-01, time/batch = 0.6748s	
5481/22300 (epoch 12.289), train_loss = 0.85917400, grad/param norm = 2.4168e-01, time/batch = 0.6799s	
5482/22300 (epoch 12.291), train_loss = 0.92591540, grad/param norm = 2.5700e-01, time/batch = 0.6781s	
5483/22300 (epoch 12.294), train_loss = 0.78489886, grad/param norm = 2.1644e-01, time/batch = 0.6768s	
5484/22300 (epoch 12.296), train_loss = 1.04979191, grad/param norm = 2.7404e-01, time/batch = 0.6777s	
5485/22300 (epoch 12.298), train_loss = 1.07171890, grad/param norm = 2.6838e-01, time/batch = 0.6797s	
5486/22300 (epoch 12.300), train_loss = 1.12039482, grad/param norm = 2.9463e-01, time/batch = 0.6809s	
5487/22300 (epoch 12.303), train_loss = 0.92693983, grad/param norm = 2.6890e-01, time/batch = 0.6926s	
5488/22300 (epoch 12.305), train_loss = 0.96548136, grad/param norm = 3.1314e-01, time/batch = 0.6764s	
5489/22300 (epoch 12.307), train_loss = 0.90237565, grad/param norm = 2.6483e-01, time/batch = 0.6782s	
5490/22300 (epoch 12.309), train_loss = 0.87893888, grad/param norm = 2.5813e-01, time/batch = 0.6814s	
5491/22300 (epoch 12.312), train_loss = 0.84277769, grad/param norm = 2.5367e-01, time/batch = 0.6837s	
5492/22300 (epoch 12.314), train_loss = 0.88148853, grad/param norm = 2.4675e-01, time/batch = 0.6819s	
5493/22300 (epoch 12.316), train_loss = 0.88608370, grad/param norm = 2.8148e-01, time/batch = 0.6811s	
5494/22300 (epoch 12.318), train_loss = 0.97082646, grad/param norm = 2.6364e-01, time/batch = 0.6789s	
5495/22300 (epoch 12.321), train_loss = 0.99781414, grad/param norm = 2.7283e-01, time/batch = 0.6812s	
5496/22300 (epoch 12.323), train_loss = 0.88508615, grad/param norm = 2.4225e-01, time/batch = 0.6785s	
5497/22300 (epoch 12.325), train_loss = 0.80521051, grad/param norm = 2.4127e-01, time/batch = 0.6798s	
5498/22300 (epoch 12.327), train_loss = 0.86189878, grad/param norm = 2.5554e-01, time/batch = 0.6790s	
5499/22300 (epoch 12.330), train_loss = 0.85468539, grad/param norm = 2.4265e-01, time/batch = 0.6794s	
5500/22300 (epoch 12.332), train_loss = 0.83816046, grad/param norm = 2.9396e-01, time/batch = 0.6853s	
5501/22300 (epoch 12.334), train_loss = 0.80348573, grad/param norm = 2.2339e-01, time/batch = 0.6858s	
5502/22300 (epoch 12.336), train_loss = 0.87557049, grad/param norm = 2.4616e-01, time/batch = 0.6949s	
5503/22300 (epoch 12.339), train_loss = 0.97131502, grad/param norm = 3.2129e-01, time/batch = 0.6933s	
5504/22300 (epoch 12.341), train_loss = 1.02269449, grad/param norm = 3.0356e-01, time/batch = 0.6969s	
5505/22300 (epoch 12.343), train_loss = 1.12128495, grad/param norm = 2.9459e-01, time/batch = 0.6922s	
5506/22300 (epoch 12.345), train_loss = 0.94336429, grad/param norm = 2.7262e-01, time/batch = 0.6967s	
5507/22300 (epoch 12.348), train_loss = 0.92775208, grad/param norm = 2.3960e-01, time/batch = 0.6945s	
5508/22300 (epoch 12.350), train_loss = 0.77972862, grad/param norm = 2.2568e-01, time/batch = 0.6946s	
5509/22300 (epoch 12.352), train_loss = 1.04657986, grad/param norm = 2.5754e-01, time/batch = 0.6951s	
5510/22300 (epoch 12.354), train_loss = 1.20607479, grad/param norm = 3.0019e-01, time/batch = 0.6944s	
5511/22300 (epoch 12.357), train_loss = 1.07165267, grad/param norm = 2.5406e-01, time/batch = 0.6995s	
5512/22300 (epoch 12.359), train_loss = 0.91035229, grad/param norm = 2.5561e-01, time/batch = 0.6923s	
5513/22300 (epoch 12.361), train_loss = 0.93525360, grad/param norm = 2.3823e-01, time/batch = 0.6966s	
5514/22300 (epoch 12.363), train_loss = 1.11468114, grad/param norm = 2.8428e-01, time/batch = 0.6949s	
5515/22300 (epoch 12.365), train_loss = 0.98677428, grad/param norm = 2.9848e-01, time/batch = 0.6930s	
5516/22300 (epoch 12.368), train_loss = 0.99443316, grad/param norm = 2.9120e-01, time/batch = 0.6978s	
5517/22300 (epoch 12.370), train_loss = 0.96879367, grad/param norm = 2.7540e-01, time/batch = 0.7031s	
5518/22300 (epoch 12.372), train_loss = 0.78632095, grad/param norm = 2.5130e-01, time/batch = 0.6915s	
5519/22300 (epoch 12.374), train_loss = 0.71255892, grad/param norm = 2.5740e-01, time/batch = 0.6922s	
5520/22300 (epoch 12.377), train_loss = 0.92149384, grad/param norm = 2.8858e-01, time/batch = 0.6920s	
5521/22300 (epoch 12.379), train_loss = 0.88775280, grad/param norm = 2.4153e-01, time/batch = 0.6951s	
5522/22300 (epoch 12.381), train_loss = 1.04933696, grad/param norm = 2.6943e-01, time/batch = 0.6943s	
5523/22300 (epoch 12.383), train_loss = 0.89264624, grad/param norm = 2.7407e-01, time/batch = 0.6924s	
5524/22300 (epoch 12.386), train_loss = 0.91302580, grad/param norm = 2.6873e-01, time/batch = 0.6922s	
5525/22300 (epoch 12.388), train_loss = 0.88510589, grad/param norm = 2.9809e-01, time/batch = 0.6913s	
5526/22300 (epoch 12.390), train_loss = 0.95359018, grad/param norm = 2.6780e-01, time/batch = 0.6906s	
5527/22300 (epoch 12.392), train_loss = 0.88791615, grad/param norm = 2.5968e-01, time/batch = 0.6884s	
5528/22300 (epoch 12.395), train_loss = 0.83768739, grad/param norm = 2.6623e-01, time/batch = 0.6904s	
5529/22300 (epoch 12.397), train_loss = 0.61587440, grad/param norm = 2.4597e-01, time/batch = 0.6909s	
5530/22300 (epoch 12.399), train_loss = 0.80654198, grad/param norm = 2.5455e-01, time/batch = 0.6902s	
5531/22300 (epoch 12.401), train_loss = 0.89561413, grad/param norm = 2.8861e-01, time/batch = 0.7000s	
5532/22300 (epoch 12.404), train_loss = 0.88032207, grad/param norm = 2.4935e-01, time/batch = 0.6943s	
5533/22300 (epoch 12.406), train_loss = 1.15104069, grad/param norm = 2.9494e-01, time/batch = 0.6961s	
5534/22300 (epoch 12.408), train_loss = 1.00719511, grad/param norm = 2.5991e-01, time/batch = 0.6959s	
5535/22300 (epoch 12.410), train_loss = 1.01381670, grad/param norm = 2.6450e-01, time/batch = 0.6996s	
5536/22300 (epoch 12.413), train_loss = 0.88935054, grad/param norm = 2.4583e-01, time/batch = 0.6953s	
5537/22300 (epoch 12.415), train_loss = 0.75742929, grad/param norm = 2.3481e-01, time/batch = 0.6954s	
5538/22300 (epoch 12.417), train_loss = 0.93316275, grad/param norm = 2.5633e-01, time/batch = 0.6942s	
5539/22300 (epoch 12.419), train_loss = 0.85274815, grad/param norm = 2.2557e-01, time/batch = 0.6944s	
5540/22300 (epoch 12.422), train_loss = 0.90683726, grad/param norm = 2.5414e-01, time/batch = 0.6917s	
5541/22300 (epoch 12.424), train_loss = 0.97558305, grad/param norm = 2.5636e-01, time/batch = 0.6951s	
5542/22300 (epoch 12.426), train_loss = 0.81628832, grad/param norm = 2.6004e-01, time/batch = 0.6930s	
5543/22300 (epoch 12.428), train_loss = 0.86158398, grad/param norm = 2.4538e-01, time/batch = 0.6911s	
5544/22300 (epoch 12.430), train_loss = 0.91712245, grad/param norm = 2.8356e-01, time/batch = 0.6870s	
5545/22300 (epoch 12.433), train_loss = 0.88090151, grad/param norm = 2.4817e-01, time/batch = 0.6871s	
5546/22300 (epoch 12.435), train_loss = 0.96146219, grad/param norm = 2.6457e-01, time/batch = 0.6908s	
5547/22300 (epoch 12.437), train_loss = 0.95315992, grad/param norm = 2.7089e-01, time/batch = 0.6904s	
5548/22300 (epoch 12.439), train_loss = 0.98395253, grad/param norm = 2.6596e-01, time/batch = 0.6893s	
5549/22300 (epoch 12.442), train_loss = 0.95162503, grad/param norm = 2.4623e-01, time/batch = 0.6919s	
5550/22300 (epoch 12.444), train_loss = 0.85605496, grad/param norm = 2.2459e-01, time/batch = 0.6901s	
5551/22300 (epoch 12.446), train_loss = 0.76643592, grad/param norm = 2.5183e-01, time/batch = 0.6939s	
5552/22300 (epoch 12.448), train_loss = 0.65029684, grad/param norm = 2.0374e-01, time/batch = 0.6937s	
5553/22300 (epoch 12.451), train_loss = 1.00853965, grad/param norm = 2.6706e-01, time/batch = 0.6824s	
5554/22300 (epoch 12.453), train_loss = 0.85830148, grad/param norm = 2.6523e-01, time/batch = 0.6856s	
5555/22300 (epoch 12.455), train_loss = 1.11204330, grad/param norm = 2.9272e-01, time/batch = 0.6888s	
5556/22300 (epoch 12.457), train_loss = 1.03428500, grad/param norm = 2.6887e-01, time/batch = 0.6899s	
5557/22300 (epoch 12.460), train_loss = 0.97178366, grad/param norm = 2.8499e-01, time/batch = 0.6895s	
5558/22300 (epoch 12.462), train_loss = 1.02994468, grad/param norm = 2.7320e-01, time/batch = 0.6965s	
5559/22300 (epoch 12.464), train_loss = 1.00584290, grad/param norm = 3.1048e-01, time/batch = 0.6887s	
5560/22300 (epoch 12.466), train_loss = 0.88949504, grad/param norm = 2.4076e-01, time/batch = 0.6879s	
5561/22300 (epoch 12.469), train_loss = 0.80972047, grad/param norm = 2.1485e-01, time/batch = 0.6988s	
5562/22300 (epoch 12.471), train_loss = 1.00046429, grad/param norm = 2.4659e-01, time/batch = 0.6995s	
5563/22300 (epoch 12.473), train_loss = 1.01861209, grad/param norm = 2.6410e-01, time/batch = 0.6962s	
5564/22300 (epoch 12.475), train_loss = 0.86587700, grad/param norm = 3.0401e-01, time/batch = 0.6958s	
5565/22300 (epoch 12.478), train_loss = 0.89000457, grad/param norm = 2.9854e-01, time/batch = 0.6948s	
5566/22300 (epoch 12.480), train_loss = 0.72628639, grad/param norm = 2.4575e-01, time/batch = 0.6944s	
5567/22300 (epoch 12.482), train_loss = 0.75978777, grad/param norm = 2.4687e-01, time/batch = 0.6988s	
5568/22300 (epoch 12.484), train_loss = 0.87984507, grad/param norm = 2.4338e-01, time/batch = 0.6920s	
5569/22300 (epoch 12.487), train_loss = 0.94796495, grad/param norm = 2.3209e-01, time/batch = 0.6915s	
5570/22300 (epoch 12.489), train_loss = 1.00000362, grad/param norm = 2.5407e-01, time/batch = 0.6907s	
5571/22300 (epoch 12.491), train_loss = 0.96363807, grad/param norm = 2.6255e-01, time/batch = 0.7035s	
5572/22300 (epoch 12.493), train_loss = 0.99841448, grad/param norm = 2.7080e-01, time/batch = 0.7026s	
5573/22300 (epoch 12.496), train_loss = 0.87046828, grad/param norm = 2.4511e-01, time/batch = 0.7050s	
5574/22300 (epoch 12.498), train_loss = 0.79999635, grad/param norm = 2.7563e-01, time/batch = 0.6999s	
5575/22300 (epoch 12.500), train_loss = 0.91270427, grad/param norm = 2.5719e-01, time/batch = 0.7032s	
5576/22300 (epoch 12.502), train_loss = 0.75396280, grad/param norm = 2.6792e-01, time/batch = 0.7056s	
5577/22300 (epoch 12.504), train_loss = 0.80312116, grad/param norm = 2.4182e-01, time/batch = 0.7002s	
5578/22300 (epoch 12.507), train_loss = 0.86487669, grad/param norm = 2.6548e-01, time/batch = 0.6967s	
5579/22300 (epoch 12.509), train_loss = 1.00753463, grad/param norm = 2.7420e-01, time/batch = 0.6920s	
5580/22300 (epoch 12.511), train_loss = 0.73710400, grad/param norm = 2.5274e-01, time/batch = 0.6871s	
5581/22300 (epoch 12.513), train_loss = 0.68841064, grad/param norm = 2.1322e-01, time/batch = 0.6922s	
5582/22300 (epoch 12.516), train_loss = 0.82768434, grad/param norm = 2.5106e-01, time/batch = 0.6920s	
5583/22300 (epoch 12.518), train_loss = 0.97444755, grad/param norm = 2.5929e-01, time/batch = 0.6813s	
5584/22300 (epoch 12.520), train_loss = 0.91303667, grad/param norm = 2.5191e-01, time/batch = 0.6863s	
5585/22300 (epoch 12.522), train_loss = 0.82640601, grad/param norm = 2.6987e-01, time/batch = 0.6928s	
5586/22300 (epoch 12.525), train_loss = 0.80871422, grad/param norm = 2.7229e-01, time/batch = 0.6941s	
5587/22300 (epoch 12.527), train_loss = 1.03286259, grad/param norm = 2.8766e-01, time/batch = 0.6882s	
5588/22300 (epoch 12.529), train_loss = 0.82538345, grad/param norm = 2.8018e-01, time/batch = 0.6822s	
5589/22300 (epoch 12.531), train_loss = 0.84930009, grad/param norm = 2.6985e-01, time/batch = 0.6751s	
5590/22300 (epoch 12.534), train_loss = 0.79689121, grad/param norm = 2.3891e-01, time/batch = 0.6760s	
5591/22300 (epoch 12.536), train_loss = 1.04072973, grad/param norm = 2.4906e-01, time/batch = 0.7233s	
5592/22300 (epoch 12.538), train_loss = 1.22284342, grad/param norm = 3.0562e-01, time/batch = 0.6960s	
5593/22300 (epoch 12.540), train_loss = 0.96756889, grad/param norm = 2.9997e-01, time/batch = 0.6945s	
5594/22300 (epoch 12.543), train_loss = 0.76475132, grad/param norm = 2.0982e-01, time/batch = 0.6977s	
5595/22300 (epoch 12.545), train_loss = 0.82272082, grad/param norm = 2.8711e-01, time/batch = 0.6870s	
5596/22300 (epoch 12.547), train_loss = 0.74238167, grad/param norm = 2.4313e-01, time/batch = 0.7135s	
5597/22300 (epoch 12.549), train_loss = 0.80336761, grad/param norm = 2.4124e-01, time/batch = 0.7228s	
5598/22300 (epoch 12.552), train_loss = 0.83129689, grad/param norm = 2.4309e-01, time/batch = 0.7096s	
5599/22300 (epoch 12.554), train_loss = 0.90614353, grad/param norm = 2.8795e-01, time/batch = 0.7007s	
5600/22300 (epoch 12.556), train_loss = 1.10472874, grad/param norm = 2.7337e-01, time/batch = 0.7047s	
5601/22300 (epoch 12.558), train_loss = 0.98549876, grad/param norm = 2.9754e-01, time/batch = 0.7106s	
5602/22300 (epoch 12.561), train_loss = 1.11260179, grad/param norm = 2.7558e-01, time/batch = 0.7085s	
5603/22300 (epoch 12.563), train_loss = 0.97021457, grad/param norm = 2.5064e-01, time/batch = 0.7144s	
5604/22300 (epoch 12.565), train_loss = 0.85368974, grad/param norm = 2.6636e-01, time/batch = 0.6946s	
5605/22300 (epoch 12.567), train_loss = 0.86730120, grad/param norm = 2.3464e-01, time/batch = 0.7105s	
5606/22300 (epoch 12.570), train_loss = 1.13277969, grad/param norm = 3.0062e-01, time/batch = 0.7241s	
5607/22300 (epoch 12.572), train_loss = 0.99788361, grad/param norm = 2.5599e-01, time/batch = 0.7093s	
5608/22300 (epoch 12.574), train_loss = 0.90005086, grad/param norm = 2.3815e-01, time/batch = 0.6772s	
5609/22300 (epoch 12.576), train_loss = 0.75120918, grad/param norm = 2.3218e-01, time/batch = 0.7099s	
5610/22300 (epoch 12.578), train_loss = 0.60806492, grad/param norm = 2.2563e-01, time/batch = 0.7103s	
5611/22300 (epoch 12.581), train_loss = 0.74767737, grad/param norm = 2.3416e-01, time/batch = 0.6851s	
5612/22300 (epoch 12.583), train_loss = 0.74628875, grad/param norm = 2.2416e-01, time/batch = 0.6781s	
5613/22300 (epoch 12.585), train_loss = 1.07328920, grad/param norm = 2.7877e-01, time/batch = 0.6758s	
5614/22300 (epoch 12.587), train_loss = 1.17452558, grad/param norm = 3.0634e-01, time/batch = 0.6759s	
5615/22300 (epoch 12.590), train_loss = 1.04929020, grad/param norm = 2.8698e-01, time/batch = 0.6767s	
5616/22300 (epoch 12.592), train_loss = 1.17948737, grad/param norm = 2.9240e-01, time/batch = 0.6775s	
5617/22300 (epoch 12.594), train_loss = 1.15359147, grad/param norm = 2.7096e-01, time/batch = 0.6775s	
5618/22300 (epoch 12.596), train_loss = 0.83045680, grad/param norm = 2.4746e-01, time/batch = 0.6777s	
5619/22300 (epoch 12.599), train_loss = 0.74403984, grad/param norm = 2.4414e-01, time/batch = 0.6780s	
5620/22300 (epoch 12.601), train_loss = 0.86000844, grad/param norm = 2.3912e-01, time/batch = 0.6756s	
5621/22300 (epoch 12.603), train_loss = 0.92723054, grad/param norm = 2.8115e-01, time/batch = 0.6871s	
5622/22300 (epoch 12.605), train_loss = 0.84686522, grad/param norm = 2.9535e-01, time/batch = 0.6772s	
5623/22300 (epoch 12.608), train_loss = 1.16366433, grad/param norm = 2.9985e-01, time/batch = 0.6708s	
5624/22300 (epoch 12.610), train_loss = 1.19273123, grad/param norm = 2.9012e-01, time/batch = 0.6711s	
5625/22300 (epoch 12.612), train_loss = 1.03266510, grad/param norm = 3.3097e-01, time/batch = 0.6763s	
5626/22300 (epoch 12.614), train_loss = 1.04033669, grad/param norm = 2.8381e-01, time/batch = 0.6771s	
5627/22300 (epoch 12.617), train_loss = 1.00634345, grad/param norm = 2.6610e-01, time/batch = 0.6772s	
5628/22300 (epoch 12.619), train_loss = 1.24621985, grad/param norm = 2.8487e-01, time/batch = 0.6793s	
5629/22300 (epoch 12.621), train_loss = 0.88196029, grad/param norm = 2.4929e-01, time/batch = 0.6954s	
5630/22300 (epoch 12.623), train_loss = 0.86927093, grad/param norm = 2.7007e-01, time/batch = 0.6954s	
5631/22300 (epoch 12.626), train_loss = 0.80812650, grad/param norm = 2.1819e-01, time/batch = 0.6986s	
5632/22300 (epoch 12.628), train_loss = 0.82325083, grad/param norm = 2.4847e-01, time/batch = 0.6972s	
5633/22300 (epoch 12.630), train_loss = 0.88132212, grad/param norm = 2.3783e-01, time/batch = 0.6955s	
5634/22300 (epoch 12.632), train_loss = 0.88825664, grad/param norm = 2.5666e-01, time/batch = 0.6968s	
5635/22300 (epoch 12.635), train_loss = 0.86781036, grad/param norm = 2.6076e-01, time/batch = 0.6949s	
5636/22300 (epoch 12.637), train_loss = 1.06869142, grad/param norm = 2.8130e-01, time/batch = 0.6863s	
5637/22300 (epoch 12.639), train_loss = 1.07551901, grad/param norm = 3.2416e-01, time/batch = 0.6901s	
5638/22300 (epoch 12.641), train_loss = 0.95849063, grad/param norm = 2.7620e-01, time/batch = 0.6833s	
5639/22300 (epoch 12.643), train_loss = 0.87443067, grad/param norm = 2.7860e-01, time/batch = 0.6892s	
5640/22300 (epoch 12.646), train_loss = 0.80079625, grad/param norm = 2.3536e-01, time/batch = 0.6906s	
5641/22300 (epoch 12.648), train_loss = 0.86958225, grad/param norm = 2.7978e-01, time/batch = 0.6964s	
5642/22300 (epoch 12.650), train_loss = 0.98783924, grad/param norm = 2.5347e-01, time/batch = 0.6892s	
5643/22300 (epoch 12.652), train_loss = 0.85043309, grad/param norm = 2.4675e-01, time/batch = 0.6907s	
5644/22300 (epoch 12.655), train_loss = 0.90460674, grad/param norm = 2.6990e-01, time/batch = 0.6888s	
5645/22300 (epoch 12.657), train_loss = 0.93931199, grad/param norm = 2.8261e-01, time/batch = 0.6863s	
5646/22300 (epoch 12.659), train_loss = 0.82638754, grad/param norm = 2.7064e-01, time/batch = 0.6846s	
5647/22300 (epoch 12.661), train_loss = 0.71514822, grad/param norm = 2.4373e-01, time/batch = 0.6815s	
5648/22300 (epoch 12.664), train_loss = 0.84929632, grad/param norm = 2.3380e-01, time/batch = 0.6837s	
5649/22300 (epoch 12.666), train_loss = 0.93570260, grad/param norm = 2.5835e-01, time/batch = 0.6824s	
5650/22300 (epoch 12.668), train_loss = 0.80204071, grad/param norm = 2.3035e-01, time/batch = 0.6814s	
5651/22300 (epoch 12.670), train_loss = 0.94859382, grad/param norm = 2.6159e-01, time/batch = 0.6650s	
5652/22300 (epoch 12.673), train_loss = 1.01201033, grad/param norm = 2.8728e-01, time/batch = 0.6528s	
5653/22300 (epoch 12.675), train_loss = 1.12392651, grad/param norm = 3.1896e-01, time/batch = 0.6537s	
5654/22300 (epoch 12.677), train_loss = 1.12316910, grad/param norm = 2.9866e-01, time/batch = 0.6539s	
5655/22300 (epoch 12.679), train_loss = 1.02144094, grad/param norm = 2.9210e-01, time/batch = 0.6649s	
5656/22300 (epoch 12.682), train_loss = 0.98775539, grad/param norm = 2.7158e-01, time/batch = 0.6701s	
5657/22300 (epoch 12.684), train_loss = 0.94544031, grad/param norm = 2.3840e-01, time/batch = 0.6760s	
5658/22300 (epoch 12.686), train_loss = 0.96921614, grad/param norm = 2.8663e-01, time/batch = 0.6759s	
5659/22300 (epoch 12.688), train_loss = 0.94194482, grad/param norm = 2.6052e-01, time/batch = 0.6748s	
5660/22300 (epoch 12.691), train_loss = 0.88078950, grad/param norm = 2.4460e-01, time/batch = 0.6752s	
5661/22300 (epoch 12.693), train_loss = 0.86008110, grad/param norm = 2.7295e-01, time/batch = 0.6814s	
5662/22300 (epoch 12.695), train_loss = 0.73631747, grad/param norm = 2.5305e-01, time/batch = 0.6771s	
5663/22300 (epoch 12.697), train_loss = 0.73838647, grad/param norm = 2.3624e-01, time/batch = 0.6751s	
5664/22300 (epoch 12.700), train_loss = 0.85109005, grad/param norm = 2.5107e-01, time/batch = 0.6832s	
5665/22300 (epoch 12.702), train_loss = 0.90074195, grad/param norm = 2.4930e-01, time/batch = 0.6731s	
5666/22300 (epoch 12.704), train_loss = 0.99276013, grad/param norm = 2.8940e-01, time/batch = 0.6734s	
5667/22300 (epoch 12.706), train_loss = 0.81924107, grad/param norm = 3.1273e-01, time/batch = 0.6699s	
5668/22300 (epoch 12.709), train_loss = 0.74790224, grad/param norm = 2.4285e-01, time/batch = 0.6737s	
5669/22300 (epoch 12.711), train_loss = 0.77992960, grad/param norm = 2.6447e-01, time/batch = 0.6805s	
5670/22300 (epoch 12.713), train_loss = 0.96885855, grad/param norm = 2.6874e-01, time/batch = 0.6800s	
5671/22300 (epoch 12.715), train_loss = 0.95056133, grad/param norm = 3.0043e-01, time/batch = 0.6978s	
5672/22300 (epoch 12.717), train_loss = 1.12384847, grad/param norm = 2.6879e-01, time/batch = 0.6954s	
5673/22300 (epoch 12.720), train_loss = 0.84341955, grad/param norm = 2.5189e-01, time/batch = 0.6942s	
5674/22300 (epoch 12.722), train_loss = 0.95503765, grad/param norm = 2.6172e-01, time/batch = 0.6956s	
5675/22300 (epoch 12.724), train_loss = 0.95930908, grad/param norm = 2.5849e-01, time/batch = 0.6906s	
5676/22300 (epoch 12.726), train_loss = 0.88867782, grad/param norm = 2.9370e-01, time/batch = 0.6926s	
5677/22300 (epoch 12.729), train_loss = 0.91259717, grad/param norm = 2.7540e-01, time/batch = 0.6969s	
5678/22300 (epoch 12.731), train_loss = 1.10176619, grad/param norm = 2.8303e-01, time/batch = 0.6976s	
5679/22300 (epoch 12.733), train_loss = 1.06630729, grad/param norm = 2.9179e-01, time/batch = 0.6949s	
5680/22300 (epoch 12.735), train_loss = 1.12138083, grad/param norm = 3.3138e-01, time/batch = 0.6945s	
5681/22300 (epoch 12.738), train_loss = 0.97810992, grad/param norm = 3.0856e-01, time/batch = 0.6976s	
5682/22300 (epoch 12.740), train_loss = 0.76865980, grad/param norm = 2.4958e-01, time/batch = 0.7155s	
5683/22300 (epoch 12.742), train_loss = 0.90750222, grad/param norm = 2.6010e-01, time/batch = 0.6928s	
5684/22300 (epoch 12.744), train_loss = 1.20250922, grad/param norm = 3.1335e-01, time/batch = 0.6940s	
5685/22300 (epoch 12.747), train_loss = 0.93801856, grad/param norm = 2.5997e-01, time/batch = 0.6892s	
5686/22300 (epoch 12.749), train_loss = 1.26411871, grad/param norm = 3.6385e-01, time/batch = 0.6900s	
5687/22300 (epoch 12.751), train_loss = 1.11336847, grad/param norm = 3.4907e-01, time/batch = 0.6930s	
5688/22300 (epoch 12.753), train_loss = 1.12881209, grad/param norm = 3.0484e-01, time/batch = 0.6995s	
5689/22300 (epoch 12.756), train_loss = 0.97077310, grad/param norm = 2.8907e-01, time/batch = 0.7327s	
5690/22300 (epoch 12.758), train_loss = 0.99407541, grad/param norm = 2.6376e-01, time/batch = 0.7277s	
5691/22300 (epoch 12.760), train_loss = 1.01335774, grad/param norm = 2.8853e-01, time/batch = 0.7334s	
5692/22300 (epoch 12.762), train_loss = 0.96244864, grad/param norm = 2.6419e-01, time/batch = 0.6899s	
5693/22300 (epoch 12.765), train_loss = 0.98861537, grad/param norm = 2.7723e-01, time/batch = 0.6884s	
5694/22300 (epoch 12.767), train_loss = 1.05060103, grad/param norm = 3.1269e-01, time/batch = 0.6729s	
5695/22300 (epoch 12.769), train_loss = 0.95165529, grad/param norm = 2.8116e-01, time/batch = 0.6772s	
5696/22300 (epoch 12.771), train_loss = 1.02331008, grad/param norm = 2.7769e-01, time/batch = 0.6769s	
5697/22300 (epoch 12.774), train_loss = 1.07870000, grad/param norm = 3.0701e-01, time/batch = 0.7176s	
5698/22300 (epoch 12.776), train_loss = 1.06932052, grad/param norm = 2.8754e-01, time/batch = 0.6894s	
5699/22300 (epoch 12.778), train_loss = 1.09800462, grad/param norm = 2.9146e-01, time/batch = 0.6876s	
5700/22300 (epoch 12.780), train_loss = 1.11459328, grad/param norm = 2.8935e-01, time/batch = 0.6634s	
5701/22300 (epoch 12.783), train_loss = 1.12487941, grad/param norm = 2.9309e-01, time/batch = 0.6752s	
5702/22300 (epoch 12.785), train_loss = 0.87922447, grad/param norm = 2.6335e-01, time/batch = 0.6793s	
5703/22300 (epoch 12.787), train_loss = 0.92809287, grad/param norm = 2.5983e-01, time/batch = 0.6777s	
5704/22300 (epoch 12.789), train_loss = 1.10159303, grad/param norm = 2.8315e-01, time/batch = 0.6666s	
5705/22300 (epoch 12.791), train_loss = 1.22833007, grad/param norm = 2.9540e-01, time/batch = 0.6651s	
5706/22300 (epoch 12.794), train_loss = 1.11886584, grad/param norm = 2.9646e-01, time/batch = 0.6720s	
5707/22300 (epoch 12.796), train_loss = 1.12853713, grad/param norm = 2.7346e-01, time/batch = 0.6887s	
5708/22300 (epoch 12.798), train_loss = 1.12024906, grad/param norm = 2.6976e-01, time/batch = 0.6830s	
5709/22300 (epoch 12.800), train_loss = 0.92190508, grad/param norm = 2.7233e-01, time/batch = 0.6827s	
5710/22300 (epoch 12.803), train_loss = 0.85653668, grad/param norm = 2.4769e-01, time/batch = 0.6844s	
5711/22300 (epoch 12.805), train_loss = 0.97885666, grad/param norm = 2.6082e-01, time/batch = 0.6812s	
5712/22300 (epoch 12.807), train_loss = 1.11412926, grad/param norm = 3.1177e-01, time/batch = 0.6651s	
5713/22300 (epoch 12.809), train_loss = 0.96571008, grad/param norm = 2.6924e-01, time/batch = 0.6678s	
5714/22300 (epoch 12.812), train_loss = 1.05967619, grad/param norm = 2.5152e-01, time/batch = 0.7069s	
5715/22300 (epoch 12.814), train_loss = 1.02982610, grad/param norm = 2.7750e-01, time/batch = 0.6890s	
5716/22300 (epoch 12.816), train_loss = 1.06603740, grad/param norm = 2.6683e-01, time/batch = 0.6690s	
5717/22300 (epoch 12.818), train_loss = 1.11372151, grad/param norm = 3.1644e-01, time/batch = 0.6794s	
5718/22300 (epoch 12.821), train_loss = 1.09445449, grad/param norm = 3.0807e-01, time/batch = 0.6812s	
5719/22300 (epoch 12.823), train_loss = 0.81738358, grad/param norm = 2.4319e-01, time/batch = 0.6694s	
5720/22300 (epoch 12.825), train_loss = 0.96414647, grad/param norm = 2.5491e-01, time/batch = 0.6829s	
5721/22300 (epoch 12.827), train_loss = 0.92595935, grad/param norm = 2.6845e-01, time/batch = 0.6718s	
5722/22300 (epoch 12.830), train_loss = 0.87798969, grad/param norm = 2.6261e-01, time/batch = 0.6734s	
5723/22300 (epoch 12.832), train_loss = 0.86889451, grad/param norm = 2.5864e-01, time/batch = 0.6774s	
5724/22300 (epoch 12.834), train_loss = 0.90141124, grad/param norm = 2.7057e-01, time/batch = 0.6840s	
5725/22300 (epoch 12.836), train_loss = 0.94067283, grad/param norm = 2.7337e-01, time/batch = 0.6905s	
5726/22300 (epoch 12.839), train_loss = 0.94064348, grad/param norm = 2.5679e-01, time/batch = 0.6896s	
5727/22300 (epoch 12.841), train_loss = 0.94895431, grad/param norm = 3.1128e-01, time/batch = 0.6968s	
5728/22300 (epoch 12.843), train_loss = 0.95581789, grad/param norm = 3.0513e-01, time/batch = 0.6956s	
5729/22300 (epoch 12.845), train_loss = 0.94371933, grad/param norm = 2.4324e-01, time/batch = 0.6925s	
5730/22300 (epoch 12.848), train_loss = 0.93502437, grad/param norm = 2.4143e-01, time/batch = 0.6828s	
5731/22300 (epoch 12.850), train_loss = 0.93449951, grad/param norm = 2.3514e-01, time/batch = 0.6840s	
5732/22300 (epoch 12.852), train_loss = 0.96292893, grad/param norm = 2.8500e-01, time/batch = 0.6642s	
5733/22300 (epoch 12.854), train_loss = 1.10371333, grad/param norm = 3.0178e-01, time/batch = 0.6685s	
5734/22300 (epoch 12.857), train_loss = 0.95527902, grad/param norm = 3.2150e-01, time/batch = 0.6770s	
5735/22300 (epoch 12.859), train_loss = 0.77947552, grad/param norm = 2.6114e-01, time/batch = 0.6758s	
5736/22300 (epoch 12.861), train_loss = 0.98241007, grad/param norm = 2.7776e-01, time/batch = 0.6767s	
5737/22300 (epoch 12.863), train_loss = 0.78342160, grad/param norm = 2.3469e-01, time/batch = 0.6801s	
5738/22300 (epoch 12.865), train_loss = 0.81899424, grad/param norm = 2.6623e-01, time/batch = 0.6758s	
5739/22300 (epoch 12.868), train_loss = 0.93721415, grad/param norm = 2.4139e-01, time/batch = 0.6746s	
5740/22300 (epoch 12.870), train_loss = 0.97681814, grad/param norm = 2.7782e-01, time/batch = 0.6756s	
5741/22300 (epoch 12.872), train_loss = 1.05571384, grad/param norm = 2.8903e-01, time/batch = 0.6795s	
5742/22300 (epoch 12.874), train_loss = 0.95508514, grad/param norm = 2.9572e-01, time/batch = 0.6759s	
5743/22300 (epoch 12.877), train_loss = 0.99200992, grad/param norm = 3.0294e-01, time/batch = 0.6737s	
5744/22300 (epoch 12.879), train_loss = 0.86474915, grad/param norm = 2.8185e-01, time/batch = 0.6872s	
5745/22300 (epoch 12.881), train_loss = 0.90697916, grad/param norm = 2.7504e-01, time/batch = 0.7001s	
5746/22300 (epoch 12.883), train_loss = 0.85769423, grad/param norm = 2.4633e-01, time/batch = 0.6959s	
5747/22300 (epoch 12.886), train_loss = 0.87167491, grad/param norm = 2.3921e-01, time/batch = 0.6929s	
5748/22300 (epoch 12.888), train_loss = 0.91363822, grad/param norm = 2.6513e-01, time/batch = 0.6963s	
5749/22300 (epoch 12.890), train_loss = 0.81644558, grad/param norm = 2.2473e-01, time/batch = 0.6960s	
5750/22300 (epoch 12.892), train_loss = 1.12534032, grad/param norm = 2.8599e-01, time/batch = 0.6973s	
5751/22300 (epoch 12.895), train_loss = 1.10888496, grad/param norm = 3.0103e-01, time/batch = 0.6915s	
5752/22300 (epoch 12.897), train_loss = 0.96603792, grad/param norm = 2.8439e-01, time/batch = 0.6952s	
5753/22300 (epoch 12.899), train_loss = 1.00607874, grad/param norm = 2.7897e-01, time/batch = 0.6943s	
5754/22300 (epoch 12.901), train_loss = 0.92210952, grad/param norm = 2.6080e-01, time/batch = 0.6970s	
5755/22300 (epoch 12.904), train_loss = 1.03680175, grad/param norm = 3.1083e-01, time/batch = 0.6950s	
5756/22300 (epoch 12.906), train_loss = 1.03470954, grad/param norm = 2.5591e-01, time/batch = 0.6956s	
5757/22300 (epoch 12.908), train_loss = 0.94564670, grad/param norm = 2.5396e-01, time/batch = 0.6956s	
5758/22300 (epoch 12.910), train_loss = 0.81007717, grad/param norm = 2.4371e-01, time/batch = 0.6977s	
5759/22300 (epoch 12.913), train_loss = 0.98201941, grad/param norm = 2.6043e-01, time/batch = 0.7004s	
5760/22300 (epoch 12.915), train_loss = 1.16410494, grad/param norm = 3.0563e-01, time/batch = 0.6959s	
5761/22300 (epoch 12.917), train_loss = 0.98722471, grad/param norm = 2.7786e-01, time/batch = 0.7007s	
5762/22300 (epoch 12.919), train_loss = 0.99843652, grad/param norm = 2.5132e-01, time/batch = 0.6954s	
5763/22300 (epoch 12.922), train_loss = 0.91788828, grad/param norm = 2.6332e-01, time/batch = 0.6973s	
5764/22300 (epoch 12.924), train_loss = 0.70584426, grad/param norm = 2.3459e-01, time/batch = 0.6971s	
5765/22300 (epoch 12.926), train_loss = 0.75247490, grad/param norm = 2.4973e-01, time/batch = 0.6946s	
5766/22300 (epoch 12.928), train_loss = 0.91130812, grad/param norm = 2.6084e-01, time/batch = 0.7049s	
5767/22300 (epoch 12.930), train_loss = 0.91466980, grad/param norm = 2.5866e-01, time/batch = 0.6961s	
5768/22300 (epoch 12.933), train_loss = 1.01666331, grad/param norm = 2.8434e-01, time/batch = 0.6959s	
5769/22300 (epoch 12.935), train_loss = 1.06866886, grad/param norm = 2.8911e-01, time/batch = 0.6936s	
5770/22300 (epoch 12.937), train_loss = 1.11098486, grad/param norm = 3.0378e-01, time/batch = 0.6950s	
5771/22300 (epoch 12.939), train_loss = 1.06082335, grad/param norm = 3.0411e-01, time/batch = 0.7017s	
5772/22300 (epoch 12.942), train_loss = 1.21487355, grad/param norm = 3.2827e-01, time/batch = 0.6948s	
5773/22300 (epoch 12.944), train_loss = 1.23251554, grad/param norm = 3.2183e-01, time/batch = 0.6954s	
5774/22300 (epoch 12.946), train_loss = 0.95927613, grad/param norm = 2.8474e-01, time/batch = 0.6971s	
5775/22300 (epoch 12.948), train_loss = 0.88573915, grad/param norm = 2.4335e-01, time/batch = 0.6972s	
5776/22300 (epoch 12.951), train_loss = 0.80949055, grad/param norm = 2.7304e-01, time/batch = 0.7176s	
5777/22300 (epoch 12.953), train_loss = 0.84134295, grad/param norm = 2.7465e-01, time/batch = 0.6937s	
5778/22300 (epoch 12.955), train_loss = 1.15786588, grad/param norm = 2.9115e-01, time/batch = 0.6972s	
5779/22300 (epoch 12.957), train_loss = 1.29844803, grad/param norm = 3.1527e-01, time/batch = 0.6943s	
5780/22300 (epoch 12.960), train_loss = 1.09785744, grad/param norm = 2.8612e-01, time/batch = 0.7026s	
5781/22300 (epoch 12.962), train_loss = 0.98292119, grad/param norm = 2.8845e-01, time/batch = 0.7123s	
5782/22300 (epoch 12.964), train_loss = 0.92716512, grad/param norm = 2.3995e-01, time/batch = 0.6983s	
5783/22300 (epoch 12.966), train_loss = 0.88535428, grad/param norm = 2.9533e-01, time/batch = 0.7023s	
5784/22300 (epoch 12.969), train_loss = 0.88054242, grad/param norm = 2.2507e-01, time/batch = 0.7047s	
5785/22300 (epoch 12.971), train_loss = 0.92652407, grad/param norm = 2.6356e-01, time/batch = 0.7044s	
5786/22300 (epoch 12.973), train_loss = 0.97711524, grad/param norm = 2.8343e-01, time/batch = 0.7015s	
5787/22300 (epoch 12.975), train_loss = 1.18894604, grad/param norm = 3.1126e-01, time/batch = 0.6959s	
5788/22300 (epoch 12.978), train_loss = 1.00775146, grad/param norm = 2.8462e-01, time/batch = 0.6992s	
5789/22300 (epoch 12.980), train_loss = 1.08320238, grad/param norm = 3.5713e-01, time/batch = 0.6950s	
5790/22300 (epoch 12.982), train_loss = 0.90776178, grad/param norm = 3.3050e-01, time/batch = 0.6924s	
5791/22300 (epoch 12.984), train_loss = 0.99898748, grad/param norm = 2.6281e-01, time/batch = 0.6999s	
5792/22300 (epoch 12.987), train_loss = 0.90966683, grad/param norm = 2.6127e-01, time/batch = 0.6986s	
5793/22300 (epoch 12.989), train_loss = 0.96119389, grad/param norm = 2.8452e-01, time/batch = 0.6974s	
5794/22300 (epoch 12.991), train_loss = 1.17736776, grad/param norm = 2.9348e-01, time/batch = 0.6976s	
5795/22300 (epoch 12.993), train_loss = 1.35055204, grad/param norm = 3.1475e-01, time/batch = 0.6971s	
5796/22300 (epoch 12.996), train_loss = 1.26034634, grad/param norm = 3.1422e-01, time/batch = 0.6968s	
5797/22300 (epoch 12.998), train_loss = 0.92995887, grad/param norm = 2.5070e-01, time/batch = 0.6955s	
decayed learning rate by a factor 0.97 to 0.00177058562	
5798/22300 (epoch 13.000), train_loss = 0.83981342, grad/param norm = 2.8648e-01, time/batch = 0.6973s	
5799/22300 (epoch 13.002), train_loss = 1.19007801, grad/param norm = 3.6064e-01, time/batch = 0.6974s	
5800/22300 (epoch 13.004), train_loss = 0.93699812, grad/param norm = 2.3740e-01, time/batch = 0.6935s	
5801/22300 (epoch 13.007), train_loss = 0.96573138, grad/param norm = 2.5914e-01, time/batch = 0.7064s	
5802/22300 (epoch 13.009), train_loss = 0.98429715, grad/param norm = 2.6447e-01, time/batch = 0.7053s	
5803/22300 (epoch 13.011), train_loss = 1.17619983, grad/param norm = 3.0939e-01, time/batch = 0.7052s	
5804/22300 (epoch 13.013), train_loss = 0.93950708, grad/param norm = 2.5459e-01, time/batch = 0.7097s	
5805/22300 (epoch 13.016), train_loss = 0.89272000, grad/param norm = 2.7381e-01, time/batch = 0.6821s	
5806/22300 (epoch 13.018), train_loss = 1.06895061, grad/param norm = 2.8660e-01, time/batch = 0.7090s	
5807/22300 (epoch 13.020), train_loss = 0.91914230, grad/param norm = 2.7581e-01, time/batch = 0.6752s	
5808/22300 (epoch 13.022), train_loss = 0.85137056, grad/param norm = 2.8360e-01, time/batch = 0.6976s	
5809/22300 (epoch 13.025), train_loss = 0.87463802, grad/param norm = 2.6204e-01, time/batch = 0.6970s	
5810/22300 (epoch 13.027), train_loss = 0.95037986, grad/param norm = 2.7833e-01, time/batch = 0.6963s	
5811/22300 (epoch 13.029), train_loss = 0.85434833, grad/param norm = 2.4575e-01, time/batch = 0.6993s	
5812/22300 (epoch 13.031), train_loss = 0.84827213, grad/param norm = 2.2133e-01, time/batch = 0.7047s	
5813/22300 (epoch 13.034), train_loss = 0.87567893, grad/param norm = 2.5827e-01, time/batch = 0.6998s	
5814/22300 (epoch 13.036), train_loss = 0.69566735, grad/param norm = 2.1554e-01, time/batch = 0.6995s	
5815/22300 (epoch 13.038), train_loss = 0.83140781, grad/param norm = 2.3350e-01, time/batch = 0.6994s	
5816/22300 (epoch 13.040), train_loss = 0.91684044, grad/param norm = 2.4961e-01, time/batch = 0.6969s	
5817/22300 (epoch 13.043), train_loss = 1.19300049, grad/param norm = 2.8850e-01, time/batch = 0.6803s	
5818/22300 (epoch 13.045), train_loss = 0.98897343, grad/param norm = 2.6338e-01, time/batch = 0.6903s	
5819/22300 (epoch 13.047), train_loss = 1.07758731, grad/param norm = 2.8022e-01, time/batch = 0.6878s	
5820/22300 (epoch 13.049), train_loss = 0.90384479, grad/param norm = 2.7592e-01, time/batch = 0.6859s	
5821/22300 (epoch 13.052), train_loss = 1.02017805, grad/param norm = 2.9134e-01, time/batch = 0.6965s	
5822/22300 (epoch 13.054), train_loss = 1.00040379, grad/param norm = 2.8048e-01, time/batch = 0.6891s	
5823/22300 (epoch 13.056), train_loss = 0.70531520, grad/param norm = 2.3516e-01, time/batch = 0.6943s	
5824/22300 (epoch 13.058), train_loss = 0.84572013, grad/param norm = 2.6659e-01, time/batch = 0.6888s	
5825/22300 (epoch 13.061), train_loss = 0.81709780, grad/param norm = 2.5168e-01, time/batch = 0.6884s	
5826/22300 (epoch 13.063), train_loss = 1.12704400, grad/param norm = 3.3617e-01, time/batch = 0.6895s	
5827/22300 (epoch 13.065), train_loss = 1.02918878, grad/param norm = 2.9249e-01, time/batch = 0.6901s	
5828/22300 (epoch 13.067), train_loss = 0.89056804, grad/param norm = 3.1690e-01, time/batch = 0.6892s	
5829/22300 (epoch 13.070), train_loss = 0.92322118, grad/param norm = 2.7218e-01, time/batch = 0.6875s	
5830/22300 (epoch 13.072), train_loss = 1.01187225, grad/param norm = 2.7705e-01, time/batch = 0.6884s	
5831/22300 (epoch 13.074), train_loss = 0.97293026, grad/param norm = 2.6152e-01, time/batch = 0.7020s	
5832/22300 (epoch 13.076), train_loss = 0.95032483, grad/param norm = 2.8053e-01, time/batch = 0.6905s	
5833/22300 (epoch 13.078), train_loss = 1.02177791, grad/param norm = 2.7612e-01, time/batch = 0.6922s	
5834/22300 (epoch 13.081), train_loss = 1.03891846, grad/param norm = 2.8144e-01, time/batch = 0.6935s	
5835/22300 (epoch 13.083), train_loss = 1.14666224, grad/param norm = 3.0722e-01, time/batch = 0.6934s	
5836/22300 (epoch 13.085), train_loss = 1.19978997, grad/param norm = 3.0947e-01, time/batch = 0.6835s	
5837/22300 (epoch 13.087), train_loss = 0.99460809, grad/param norm = 2.7803e-01, time/batch = 0.6732s	
5838/22300 (epoch 13.090), train_loss = 0.83200199, grad/param norm = 2.4612e-01, time/batch = 0.6924s	
5839/22300 (epoch 13.092), train_loss = 0.85759200, grad/param norm = 2.7308e-01, time/batch = 0.6904s	
5840/22300 (epoch 13.094), train_loss = 0.83553522, grad/param norm = 2.5308e-01, time/batch = 0.6909s	
5841/22300 (epoch 13.096), train_loss = 1.10944468, grad/param norm = 2.6608e-01, time/batch = 0.6964s	
5842/22300 (epoch 13.099), train_loss = 0.89717731, grad/param norm = 2.4000e-01, time/batch = 0.7003s	
5843/22300 (epoch 13.101), train_loss = 1.05767913, grad/param norm = 2.6772e-01, time/batch = 0.6967s	
5844/22300 (epoch 13.103), train_loss = 0.97875081, grad/param norm = 2.5023e-01, time/batch = 0.6926s	
5845/22300 (epoch 13.105), train_loss = 0.93906334, grad/param norm = 2.8800e-01, time/batch = 0.6929s	
5846/22300 (epoch 13.108), train_loss = 0.97358179, grad/param norm = 2.5152e-01, time/batch = 0.6885s	
5847/22300 (epoch 13.110), train_loss = 0.98464009, grad/param norm = 2.5289e-01, time/batch = 0.6726s	
5848/22300 (epoch 13.112), train_loss = 0.95236616, grad/param norm = 2.4279e-01, time/batch = 0.6878s	
5849/22300 (epoch 13.114), train_loss = 1.04235599, grad/param norm = 3.0141e-01, time/batch = 0.6927s	
5850/22300 (epoch 13.117), train_loss = 1.17422323, grad/param norm = 2.6634e-01, time/batch = 0.6980s	
5851/22300 (epoch 13.119), train_loss = 1.05993363, grad/param norm = 2.5111e-01, time/batch = 0.7012s	
5852/22300 (epoch 13.121), train_loss = 1.12346192, grad/param norm = 2.9613e-01, time/batch = 0.7075s	
5853/22300 (epoch 13.123), train_loss = 1.01579920, grad/param norm = 2.6522e-01, time/batch = 0.6965s	
5854/22300 (epoch 13.126), train_loss = 0.96273467, grad/param norm = 2.5620e-01, time/batch = 0.7276s	
5855/22300 (epoch 13.128), train_loss = 1.06296461, grad/param norm = 2.4941e-01, time/batch = 0.7342s	
5856/22300 (epoch 13.130), train_loss = 0.90354207, grad/param norm = 2.5853e-01, time/batch = 0.7274s	
5857/22300 (epoch 13.132), train_loss = 0.79265757, grad/param norm = 2.5024e-01, time/batch = 0.7328s	
5858/22300 (epoch 13.135), train_loss = 0.82713354, grad/param norm = 2.5768e-01, time/batch = 0.7009s	
5859/22300 (epoch 13.137), train_loss = 0.64881154, grad/param norm = 2.1565e-01, time/batch = 0.7074s	
5860/22300 (epoch 13.139), train_loss = 1.03100948, grad/param norm = 2.7831e-01, time/batch = 0.7081s	
5861/22300 (epoch 13.141), train_loss = 1.02834547, grad/param norm = 2.4870e-01, time/batch = 0.7061s	
5862/22300 (epoch 13.143), train_loss = 0.97353621, grad/param norm = 2.6212e-01, time/batch = 0.7076s	
5863/22300 (epoch 13.146), train_loss = 1.11224007, grad/param norm = 2.9137e-01, time/batch = 0.6862s	
5864/22300 (epoch 13.148), train_loss = 0.84702290, grad/param norm = 2.3440e-01, time/batch = 0.6881s	
5865/22300 (epoch 13.150), train_loss = 0.88928431, grad/param norm = 2.6469e-01, time/batch = 0.6970s	
5866/22300 (epoch 13.152), train_loss = 0.81312786, grad/param norm = 2.4942e-01, time/batch = 0.6917s	
5867/22300 (epoch 13.155), train_loss = 0.88107159, grad/param norm = 2.5739e-01, time/batch = 0.6929s	
5868/22300 (epoch 13.157), train_loss = 1.09988420, grad/param norm = 3.2770e-01, time/batch = 0.6951s	
5869/22300 (epoch 13.159), train_loss = 1.02385641, grad/param norm = 2.8660e-01, time/batch = 0.6875s	
5870/22300 (epoch 13.161), train_loss = 1.07029664, grad/param norm = 3.0739e-01, time/batch = 0.6915s	
5871/22300 (epoch 13.164), train_loss = 0.82760268, grad/param norm = 2.4307e-01, time/batch = 0.7359s	
5872/22300 (epoch 13.166), train_loss = 0.81478025, grad/param norm = 2.1395e-01, time/batch = 0.7009s	
5873/22300 (epoch 13.168), train_loss = 0.85896562, grad/param norm = 2.3568e-01, time/batch = 0.7036s	
5874/22300 (epoch 13.170), train_loss = 0.95441430, grad/param norm = 2.3434e-01, time/batch = 0.6969s	
5875/22300 (epoch 13.173), train_loss = 1.12612236, grad/param norm = 2.8260e-01, time/batch = 0.6901s	
5876/22300 (epoch 13.175), train_loss = 0.93906775, grad/param norm = 2.7699e-01, time/batch = 0.6938s	
5877/22300 (epoch 13.177), train_loss = 0.75358560, grad/param norm = 2.2137e-01, time/batch = 0.6912s	
5878/22300 (epoch 13.179), train_loss = 0.91200349, grad/param norm = 2.4195e-01, time/batch = 0.6926s	
5879/22300 (epoch 13.182), train_loss = 1.13708616, grad/param norm = 2.9276e-01, time/batch = 0.6921s	
5880/22300 (epoch 13.184), train_loss = 1.20526969, grad/param norm = 2.8565e-01, time/batch = 0.7007s	
5881/22300 (epoch 13.186), train_loss = 1.02091355, grad/param norm = 2.8594e-01, time/batch = 0.7033s	
5882/22300 (epoch 13.188), train_loss = 1.16538038, grad/param norm = 3.0715e-01, time/batch = 0.6949s	
5883/22300 (epoch 13.191), train_loss = 1.15872289, grad/param norm = 3.0725e-01, time/batch = 0.6921s	
5884/22300 (epoch 13.193), train_loss = 0.97363292, grad/param norm = 2.7075e-01, time/batch = 0.6985s	
5885/22300 (epoch 13.195), train_loss = 0.87659804, grad/param norm = 2.4652e-01, time/batch = 0.6958s	
5886/22300 (epoch 13.197), train_loss = 0.90318460, grad/param norm = 2.5104e-01, time/batch = 0.7256s	
5887/22300 (epoch 13.200), train_loss = 0.84049625, grad/param norm = 2.5764e-01, time/batch = 0.7050s	
5888/22300 (epoch 13.202), train_loss = 0.91565283, grad/param norm = 2.4803e-01, time/batch = 0.6991s	
5889/22300 (epoch 13.204), train_loss = 0.89194941, grad/param norm = 2.3263e-01, time/batch = 0.6897s	
5890/22300 (epoch 13.206), train_loss = 0.81905543, grad/param norm = 2.2486e-01, time/batch = 0.6789s	
5891/22300 (epoch 13.209), train_loss = 0.93349793, grad/param norm = 2.6115e-01, time/batch = 0.6946s	
5892/22300 (epoch 13.211), train_loss = 0.78170052, grad/param norm = 2.6018e-01, time/batch = 0.6946s	
5893/22300 (epoch 13.213), train_loss = 0.88354274, grad/param norm = 2.4078e-01, time/batch = 0.6903s	
5894/22300 (epoch 13.215), train_loss = 1.14320655, grad/param norm = 2.8674e-01, time/batch = 0.6867s	
5895/22300 (epoch 13.217), train_loss = 1.03384896, grad/param norm = 2.6277e-01, time/batch = 0.6936s	
5896/22300 (epoch 13.220), train_loss = 0.92794070, grad/param norm = 2.3894e-01, time/batch = 0.6891s	
5897/22300 (epoch 13.222), train_loss = 0.86810241, grad/param norm = 2.8803e-01, time/batch = 0.6866s	
5898/22300 (epoch 13.224), train_loss = 0.84236627, grad/param norm = 2.4931e-01, time/batch = 0.6897s	
5899/22300 (epoch 13.226), train_loss = 0.89471411, grad/param norm = 2.4368e-01, time/batch = 0.6888s	
5900/22300 (epoch 13.229), train_loss = 0.88845612, grad/param norm = 2.8242e-01, time/batch = 0.6893s	
5901/22300 (epoch 13.231), train_loss = 1.02724729, grad/param norm = 2.9534e-01, time/batch = 0.6927s	
5902/22300 (epoch 13.233), train_loss = 1.02007772, grad/param norm = 2.6319e-01, time/batch = 0.6802s	
5903/22300 (epoch 13.235), train_loss = 0.79928301, grad/param norm = 2.6334e-01, time/batch = 0.6784s	
5904/22300 (epoch 13.238), train_loss = 0.79406476, grad/param norm = 2.4486e-01, time/batch = 0.6922s	
5905/22300 (epoch 13.240), train_loss = 0.79992106, grad/param norm = 2.2360e-01, time/batch = 0.6933s	
5906/22300 (epoch 13.242), train_loss = 0.81650995, grad/param norm = 2.2222e-01, time/batch = 0.6925s	
5907/22300 (epoch 13.244), train_loss = 0.63031925, grad/param norm = 2.0478e-01, time/batch = 0.6956s	
5908/22300 (epoch 13.247), train_loss = 0.82114573, grad/param norm = 2.7745e-01, time/batch = 0.6948s	
5909/22300 (epoch 13.249), train_loss = 0.69305462, grad/param norm = 2.4460e-01, time/batch = 0.6863s	
5910/22300 (epoch 13.251), train_loss = 0.78126058, grad/param norm = 2.2358e-01, time/batch = 0.6764s	
5911/22300 (epoch 13.253), train_loss = 0.69327740, grad/param norm = 2.2322e-01, time/batch = 0.6828s	
5912/22300 (epoch 13.256), train_loss = 0.80907729, grad/param norm = 2.2364e-01, time/batch = 0.6801s	
5913/22300 (epoch 13.258), train_loss = 1.08644848, grad/param norm = 2.9404e-01, time/batch = 0.6788s	
5914/22300 (epoch 13.260), train_loss = 0.91017600, grad/param norm = 2.5649e-01, time/batch = 0.6764s	
5915/22300 (epoch 13.262), train_loss = 0.82000544, grad/param norm = 2.2946e-01, time/batch = 0.6884s	
5916/22300 (epoch 13.265), train_loss = 0.82145875, grad/param norm = 2.8589e-01, time/batch = 0.7080s	
5917/22300 (epoch 13.267), train_loss = 0.88785093, grad/param norm = 2.5641e-01, time/batch = 0.6762s	
5918/22300 (epoch 13.269), train_loss = 0.91978997, grad/param norm = 2.8421e-01, time/batch = 0.6831s	
5919/22300 (epoch 13.271), train_loss = 0.86765642, grad/param norm = 2.3896e-01, time/batch = 0.6829s	
5920/22300 (epoch 13.274), train_loss = 0.74417776, grad/param norm = 2.6843e-01, time/batch = 0.6784s	
5921/22300 (epoch 13.276), train_loss = 0.66570866, grad/param norm = 1.9364e-01, time/batch = 0.7018s	
5922/22300 (epoch 13.278), train_loss = 0.64274541, grad/param norm = 2.1569e-01, time/batch = 0.7008s	
5923/22300 (epoch 13.280), train_loss = 0.81286000, grad/param norm = 2.4821e-01, time/batch = 0.6991s	
5924/22300 (epoch 13.283), train_loss = 0.61686766, grad/param norm = 1.8744e-01, time/batch = 0.7013s	
5925/22300 (epoch 13.285), train_loss = 0.81651729, grad/param norm = 2.5130e-01, time/batch = 0.6918s	
5926/22300 (epoch 13.287), train_loss = 0.93959468, grad/param norm = 2.6211e-01, time/batch = 0.6982s	
5927/22300 (epoch 13.289), train_loss = 0.80926042, grad/param norm = 2.3540e-01, time/batch = 0.6938s	
5928/22300 (epoch 13.291), train_loss = 0.86563335, grad/param norm = 2.5956e-01, time/batch = 0.6830s	
5929/22300 (epoch 13.294), train_loss = 0.74388261, grad/param norm = 2.3866e-01, time/batch = 0.6835s	
5930/22300 (epoch 13.296), train_loss = 0.97961926, grad/param norm = 2.7944e-01, time/batch = 0.6912s	
5931/22300 (epoch 13.298), train_loss = 1.01788213, grad/param norm = 2.5988e-01, time/batch = 0.7052s	
5932/22300 (epoch 13.300), train_loss = 1.06390509, grad/param norm = 2.8740e-01, time/batch = 0.6884s	
5933/22300 (epoch 13.303), train_loss = 0.85310946, grad/param norm = 2.4552e-01, time/batch = 0.6868s	
5934/22300 (epoch 13.305), train_loss = 0.91048188, grad/param norm = 3.0544e-01, time/batch = 0.6922s	
5935/22300 (epoch 13.307), train_loss = 0.84482025, grad/param norm = 2.5592e-01, time/batch = 0.6899s	
5936/22300 (epoch 13.309), train_loss = 0.81323510, grad/param norm = 2.5111e-01, time/batch = 0.6939s	
5937/22300 (epoch 13.312), train_loss = 0.79870307, grad/param norm = 2.6650e-01, time/batch = 0.6949s	
5938/22300 (epoch 13.314), train_loss = 0.81639303, grad/param norm = 2.3971e-01, time/batch = 0.6924s	
5939/22300 (epoch 13.316), train_loss = 0.83004587, grad/param norm = 2.7389e-01, time/batch = 0.6898s	
5940/22300 (epoch 13.318), train_loss = 0.90706950, grad/param norm = 2.5826e-01, time/batch = 0.6894s	
5941/22300 (epoch 13.321), train_loss = 0.95091749, grad/param norm = 2.5475e-01, time/batch = 0.6949s	
5942/22300 (epoch 13.323), train_loss = 0.81717244, grad/param norm = 2.3968e-01, time/batch = 0.6934s	
5943/22300 (epoch 13.325), train_loss = 0.75648007, grad/param norm = 2.4335e-01, time/batch = 0.6920s	
5944/22300 (epoch 13.327), train_loss = 0.79490055, grad/param norm = 2.4458e-01, time/batch = 0.6934s	
5945/22300 (epoch 13.330), train_loss = 0.79902652, grad/param norm = 2.4701e-01, time/batch = 0.6977s	
5946/22300 (epoch 13.332), train_loss = 0.78280302, grad/param norm = 2.6802e-01, time/batch = 0.6948s	
5947/22300 (epoch 13.334), train_loss = 0.76152127, grad/param norm = 2.2452e-01, time/batch = 0.6942s	
5948/22300 (epoch 13.336), train_loss = 0.82289643, grad/param norm = 2.4692e-01, time/batch = 0.6998s	
5949/22300 (epoch 13.339), train_loss = 0.90583924, grad/param norm = 2.8209e-01, time/batch = 0.6986s	
5950/22300 (epoch 13.341), train_loss = 0.97998149, grad/param norm = 3.3343e-01, time/batch = 0.7332s	
5951/22300 (epoch 13.343), train_loss = 1.05429735, grad/param norm = 2.9823e-01, time/batch = 0.6995s	
5952/22300 (epoch 13.345), train_loss = 0.86825145, grad/param norm = 2.4796e-01, time/batch = 0.7002s	
5953/22300 (epoch 13.348), train_loss = 0.86581887, grad/param norm = 2.3800e-01, time/batch = 0.6993s	
5954/22300 (epoch 13.350), train_loss = 0.74293323, grad/param norm = 2.3600e-01, time/batch = 0.6917s	
5955/22300 (epoch 13.352), train_loss = 0.99087023, grad/param norm = 2.5613e-01, time/batch = 0.6979s	
5956/22300 (epoch 13.354), train_loss = 1.15078530, grad/param norm = 2.9682e-01, time/batch = 0.6939s	
5957/22300 (epoch 13.357), train_loss = 1.01245880, grad/param norm = 2.5854e-01, time/batch = 0.6901s	
5958/22300 (epoch 13.359), train_loss = 0.86078047, grad/param norm = 2.7600e-01, time/batch = 0.6915s	
5959/22300 (epoch 13.361), train_loss = 0.85504567, grad/param norm = 2.4607e-01, time/batch = 0.6909s	
5960/22300 (epoch 13.363), train_loss = 1.05149901, grad/param norm = 2.7625e-01, time/batch = 0.6919s	
5961/22300 (epoch 13.365), train_loss = 0.91168654, grad/param norm = 2.7721e-01, time/batch = 0.6944s	
5962/22300 (epoch 13.368), train_loss = 0.92103376, grad/param norm = 2.8367e-01, time/batch = 0.6906s	
5963/22300 (epoch 13.370), train_loss = 0.90645090, grad/param norm = 2.8197e-01, time/batch = 0.6907s	
5964/22300 (epoch 13.372), train_loss = 0.73017163, grad/param norm = 2.5106e-01, time/batch = 0.6920s	
5965/22300 (epoch 13.374), train_loss = 0.66565916, grad/param norm = 2.3652e-01, time/batch = 0.6942s	
5966/22300 (epoch 13.377), train_loss = 0.86858766, grad/param norm = 2.8384e-01, time/batch = 0.6943s	
5967/22300 (epoch 13.379), train_loss = 0.82941993, grad/param norm = 2.5774e-01, time/batch = 0.6924s	
5968/22300 (epoch 13.381), train_loss = 1.00882736, grad/param norm = 2.8084e-01, time/batch = 0.6906s	
5969/22300 (epoch 13.383), train_loss = 0.84588670, grad/param norm = 2.8109e-01, time/batch = 0.6892s	
5970/22300 (epoch 13.386), train_loss = 0.86368408, grad/param norm = 2.6798e-01, time/batch = 0.6918s	
5971/22300 (epoch 13.388), train_loss = 0.81989241, grad/param norm = 3.0925e-01, time/batch = 0.6958s	
5972/22300 (epoch 13.390), train_loss = 0.92991027, grad/param norm = 2.8999e-01, time/batch = 0.6935s	
5973/22300 (epoch 13.392), train_loss = 0.83738259, grad/param norm = 2.5159e-01, time/batch = 0.6938s	
5974/22300 (epoch 13.395), train_loss = 0.78514197, grad/param norm = 2.7812e-01, time/batch = 0.6918s	
5975/22300 (epoch 13.397), train_loss = 0.56201313, grad/param norm = 2.3312e-01, time/batch = 0.6925s	
5976/22300 (epoch 13.399), train_loss = 0.73642242, grad/param norm = 2.3084e-01, time/batch = 0.7067s	
5977/22300 (epoch 13.401), train_loss = 0.85299237, grad/param norm = 2.9670e-01, time/batch = 0.6923s	
5978/22300 (epoch 13.404), train_loss = 0.81911231, grad/param norm = 2.4462e-01, time/batch = 0.6900s	
5979/22300 (epoch 13.406), train_loss = 1.11344463, grad/param norm = 3.3426e-01, time/batch = 0.6889s	
5980/22300 (epoch 13.408), train_loss = 0.97915998, grad/param norm = 3.0118e-01, time/batch = 0.6914s	
5981/22300 (epoch 13.410), train_loss = 0.97097251, grad/param norm = 2.5810e-01, time/batch = 0.6880s	
5982/22300 (epoch 13.413), train_loss = 0.82937810, grad/param norm = 2.5277e-01, time/batch = 0.6793s	
5983/22300 (epoch 13.415), train_loss = 0.71808626, grad/param norm = 2.4300e-01, time/batch = 0.9047s	
5984/22300 (epoch 13.417), train_loss = 0.88650281, grad/param norm = 2.5645e-01, time/batch = 0.9962s	
5985/22300 (epoch 13.419), train_loss = 0.81209912, grad/param norm = 2.3741e-01, time/batch = 0.9947s	
5986/22300 (epoch 13.422), train_loss = 0.83082913, grad/param norm = 2.5381e-01, time/batch = 1.0099s	
5987/22300 (epoch 13.424), train_loss = 0.91239153, grad/param norm = 2.7228e-01, time/batch = 0.9964s	
5988/22300 (epoch 13.426), train_loss = 0.75403529, grad/param norm = 2.6325e-01, time/batch = 1.6123s	
5989/22300 (epoch 13.428), train_loss = 0.79166148, grad/param norm = 2.4079e-01, time/batch = 1.8737s	
5990/22300 (epoch 13.430), train_loss = 0.85036658, grad/param norm = 2.6979e-01, time/batch = 2.3511s	
5991/22300 (epoch 13.433), train_loss = 0.82966498, grad/param norm = 2.5534e-01, time/batch = 15.8994s	
5992/22300 (epoch 13.435), train_loss = 0.90392659, grad/param norm = 2.7257e-01, time/batch = 15.9704s	
5993/22300 (epoch 13.437), train_loss = 0.89937331, grad/param norm = 2.6953e-01, time/batch = 15.8875s	
5994/22300 (epoch 13.439), train_loss = 0.93354236, grad/param norm = 2.8514e-01, time/batch = 15.6475s	
5995/22300 (epoch 13.442), train_loss = 0.90191963, grad/param norm = 2.5834e-01, time/batch = 15.6993s	
5996/22300 (epoch 13.444), train_loss = 0.80895430, grad/param norm = 2.3590e-01, time/batch = 9.5758s	
5997/22300 (epoch 13.446), train_loss = 0.72083827, grad/param norm = 2.5008e-01, time/batch = 0.6936s	
5998/22300 (epoch 13.448), train_loss = 0.60078571, grad/param norm = 2.0754e-01, time/batch = 0.6943s	
5999/22300 (epoch 13.451), train_loss = 0.96872523, grad/param norm = 2.7518e-01, time/batch = 0.6936s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch13.45_1.5511.t7	
6000/22300 (epoch 13.453), train_loss = 0.79972401, grad/param norm = 2.7090e-01, time/batch = 0.6973s	
6001/22300 (epoch 13.455), train_loss = 1.51848604, grad/param norm = 3.6219e-01, time/batch = 1.0016s	
6002/22300 (epoch 13.457), train_loss = 1.01231889, grad/param norm = 2.8820e-01, time/batch = 1.5638s	
6003/22300 (epoch 13.460), train_loss = 0.94748398, grad/param norm = 2.9382e-01, time/batch = 1.8535s	
6004/22300 (epoch 13.462), train_loss = 0.98684755, grad/param norm = 2.8395e-01, time/batch = 1.8490s	
6005/22300 (epoch 13.464), train_loss = 0.93548908, grad/param norm = 3.0158e-01, time/batch = 15.2346s	
6006/22300 (epoch 13.466), train_loss = 0.83522426, grad/param norm = 2.3731e-01, time/batch = 15.6259s	
6007/22300 (epoch 13.469), train_loss = 0.77638655, grad/param norm = 2.2347e-01, time/batch = 16.0064s	
6008/22300 (epoch 13.471), train_loss = 0.93360614, grad/param norm = 2.4256e-01, time/batch = 16.0093s	
6009/22300 (epoch 13.473), train_loss = 0.96609053, grad/param norm = 2.7010e-01, time/batch = 15.8373s	
6010/22300 (epoch 13.475), train_loss = 0.81431013, grad/param norm = 2.6403e-01, time/batch = 16.7872s	
6011/22300 (epoch 13.478), train_loss = 0.82761780, grad/param norm = 2.6421e-01, time/batch = 15.6865s	
6012/22300 (epoch 13.480), train_loss = 0.65551594, grad/param norm = 2.1866e-01, time/batch = 15.2463s	
6013/22300 (epoch 13.482), train_loss = 0.70152282, grad/param norm = 2.3304e-01, time/batch = 15.8672s	
6014/22300 (epoch 13.484), train_loss = 0.83264165, grad/param norm = 2.5948e-01, time/batch = 15.9472s	
6015/22300 (epoch 13.487), train_loss = 0.89814464, grad/param norm = 2.4761e-01, time/batch = 15.2216s	
6016/22300 (epoch 13.489), train_loss = 0.94412601, grad/param norm = 2.6938e-01, time/batch = 15.9880s	
6017/22300 (epoch 13.491), train_loss = 0.92054744, grad/param norm = 2.6583e-01, time/batch = 14.5629s	
6018/22300 (epoch 13.493), train_loss = 0.94086577, grad/param norm = 3.1859e-01, time/batch = 15.2842s	
6019/22300 (epoch 13.496), train_loss = 0.80370277, grad/param norm = 2.2588e-01, time/batch = 15.6101s	
6020/22300 (epoch 13.498), train_loss = 0.73947351, grad/param norm = 2.4018e-01, time/batch = 18.6228s	
6021/22300 (epoch 13.500), train_loss = 0.87332553, grad/param norm = 2.4553e-01, time/batch = 15.8100s	
6022/22300 (epoch 13.502), train_loss = 0.68892151, grad/param norm = 2.8250e-01, time/batch = 16.5382s	
6023/22300 (epoch 13.504), train_loss = 0.73319626, grad/param norm = 2.2521e-01, time/batch = 16.6246s	
6024/22300 (epoch 13.507), train_loss = 0.78371505, grad/param norm = 2.6222e-01, time/batch = 15.3762s	
6025/22300 (epoch 13.509), train_loss = 0.93254986, grad/param norm = 2.6481e-01, time/batch = 16.3967s	
6026/22300 (epoch 13.511), train_loss = 0.69039647, grad/param norm = 2.4767e-01, time/batch = 15.8689s	
6027/22300 (epoch 13.513), train_loss = 0.64366633, grad/param norm = 2.0796e-01, time/batch = 16.2275s	
6028/22300 (epoch 13.516), train_loss = 0.77026003, grad/param norm = 2.5367e-01, time/batch = 16.9652s	
6029/22300 (epoch 13.518), train_loss = 0.93172261, grad/param norm = 2.5687e-01, time/batch = 16.4262s	
6030/22300 (epoch 13.520), train_loss = 0.86292135, grad/param norm = 2.3974e-01, time/batch = 16.1191s	
6031/22300 (epoch 13.522), train_loss = 0.77666950, grad/param norm = 2.5565e-01, time/batch = 15.5224s	
6032/22300 (epoch 13.525), train_loss = 0.74403214, grad/param norm = 2.7199e-01, time/batch = 15.0462s	
6033/22300 (epoch 13.527), train_loss = 0.95085233, grad/param norm = 2.5500e-01, time/batch = 15.9673s	
6034/22300 (epoch 13.529), train_loss = 0.77179095, grad/param norm = 2.4321e-01, time/batch = 17.1252s	
6035/22300 (epoch 13.531), train_loss = 0.79715965, grad/param norm = 2.6744e-01, time/batch = 16.7380s	
6036/22300 (epoch 13.534), train_loss = 0.71838742, grad/param norm = 2.4200e-01, time/batch = 16.2349s	
6037/22300 (epoch 13.536), train_loss = 0.99353175, grad/param norm = 2.6437e-01, time/batch = 16.3685s	
6038/22300 (epoch 13.538), train_loss = 1.19431809, grad/param norm = 3.0703e-01, time/batch = 17.8892s	
6039/22300 (epoch 13.540), train_loss = 0.91858198, grad/param norm = 3.0547e-01, time/batch = 15.1595s	
6040/22300 (epoch 13.543), train_loss = 0.73560582, grad/param norm = 2.2939e-01, time/batch = 16.3727s	
6041/22300 (epoch 13.545), train_loss = 0.74778777, grad/param norm = 2.7694e-01, time/batch = 15.6626s	
6042/22300 (epoch 13.547), train_loss = 0.69393054, grad/param norm = 2.4810e-01, time/batch = 15.7556s	
6043/22300 (epoch 13.549), train_loss = 0.73896870, grad/param norm = 2.3599e-01, time/batch = 15.6174s	
6044/22300 (epoch 13.552), train_loss = 0.78755355, grad/param norm = 2.5695e-01, time/batch = 15.0546s	
6045/22300 (epoch 13.554), train_loss = 0.85624523, grad/param norm = 3.0427e-01, time/batch = 15.6675s	
6046/22300 (epoch 13.556), train_loss = 1.06475706, grad/param norm = 2.8440e-01, time/batch = 15.1148s	
6047/22300 (epoch 13.558), train_loss = 0.94889128, grad/param norm = 3.1326e-01, time/batch = 17.7095s	
6048/22300 (epoch 13.561), train_loss = 1.08742519, grad/param norm = 3.0151e-01, time/batch = 15.4653s	
6049/22300 (epoch 13.563), train_loss = 0.94586060, grad/param norm = 2.6154e-01, time/batch = 15.1099s	
6050/22300 (epoch 13.565), train_loss = 0.80700876, grad/param norm = 2.5844e-01, time/batch = 16.1864s	
6051/22300 (epoch 13.567), train_loss = 0.80644699, grad/param norm = 2.3524e-01, time/batch = 18.1303s	
6052/22300 (epoch 13.570), train_loss = 1.10058518, grad/param norm = 3.1104e-01, time/batch = 16.3794s	
6053/22300 (epoch 13.572), train_loss = 0.94601818, grad/param norm = 2.5832e-01, time/batch = 16.9689s	
6054/22300 (epoch 13.574), train_loss = 0.85757249, grad/param norm = 2.4990e-01, time/batch = 16.7913s	
6055/22300 (epoch 13.576), train_loss = 0.71642063, grad/param norm = 2.2423e-01, time/batch = 15.7884s	
6056/22300 (epoch 13.578), train_loss = 0.55868616, grad/param norm = 2.1874e-01, time/batch = 19.2722s	
6057/22300 (epoch 13.581), train_loss = 0.70179134, grad/param norm = 2.4708e-01, time/batch = 17.1349s	
6058/22300 (epoch 13.583), train_loss = 0.71007492, grad/param norm = 2.3847e-01, time/batch = 15.3055s	
6059/22300 (epoch 13.585), train_loss = 1.02664684, grad/param norm = 2.9150e-01, time/batch = 15.5354s	
6060/22300 (epoch 13.587), train_loss = 1.12353430, grad/param norm = 3.1365e-01, time/batch = 17.5528s	
6061/22300 (epoch 13.590), train_loss = 1.02257795, grad/param norm = 3.1030e-01, time/batch = 16.6331s	
6062/22300 (epoch 13.592), train_loss = 1.13899791, grad/param norm = 2.9238e-01, time/batch = 16.7039s	
6063/22300 (epoch 13.594), train_loss = 1.10857692, grad/param norm = 2.8254e-01, time/batch = 15.0286s	
6064/22300 (epoch 13.596), train_loss = 0.77919838, grad/param norm = 2.5485e-01, time/batch = 16.7351s	
6065/22300 (epoch 13.599), train_loss = 0.67948805, grad/param norm = 2.2753e-01, time/batch = 16.8979s	
6066/22300 (epoch 13.601), train_loss = 0.80618796, grad/param norm = 2.4065e-01, time/batch = 16.0576s	
6067/22300 (epoch 13.603), train_loss = 0.85389464, grad/param norm = 2.7473e-01, time/batch = 16.4454s	
6068/22300 (epoch 13.605), train_loss = 0.78254734, grad/param norm = 2.7413e-01, time/batch = 16.4376s	
6069/22300 (epoch 13.608), train_loss = 1.10868689, grad/param norm = 3.0787e-01, time/batch = 16.4051s	
6070/22300 (epoch 13.610), train_loss = 1.15027610, grad/param norm = 2.9424e-01, time/batch = 15.5383s	
6071/22300 (epoch 13.612), train_loss = 1.00927015, grad/param norm = 3.5163e-01, time/batch = 16.7228s	
6072/22300 (epoch 13.614), train_loss = 0.99125139, grad/param norm = 2.8704e-01, time/batch = 17.1435s	
6073/22300 (epoch 13.617), train_loss = 0.96714770, grad/param norm = 2.8074e-01, time/batch = 15.9788s	
6074/22300 (epoch 13.619), train_loss = 1.19038546, grad/param norm = 3.2506e-01, time/batch = 17.8803s	
6075/22300 (epoch 13.621), train_loss = 0.81666555, grad/param norm = 2.5562e-01, time/batch = 17.2161s	
6076/22300 (epoch 13.623), train_loss = 0.80722136, grad/param norm = 2.4882e-01, time/batch = 17.6243s	
6077/22300 (epoch 13.626), train_loss = 0.74403096, grad/param norm = 2.0149e-01, time/batch = 28.5830s	
6078/22300 (epoch 13.628), train_loss = 0.78374260, grad/param norm = 2.4971e-01, time/batch = 16.0764s	
6079/22300 (epoch 13.630), train_loss = 0.83555512, grad/param norm = 2.5190e-01, time/batch = 18.0423s	
6080/22300 (epoch 13.632), train_loss = 0.84402731, grad/param norm = 2.7258e-01, time/batch = 15.8644s	
6081/22300 (epoch 13.635), train_loss = 0.80296292, grad/param norm = 2.2904e-01, time/batch = 16.7169s	
6082/22300 (epoch 13.637), train_loss = 1.00818713, grad/param norm = 2.5389e-01, time/batch = 18.9622s	
6083/22300 (epoch 13.639), train_loss = 1.02607885, grad/param norm = 3.6140e-01, time/batch = 16.7019s	
6084/22300 (epoch 13.641), train_loss = 0.91529453, grad/param norm = 2.7449e-01, time/batch = 15.9565s	
6085/22300 (epoch 13.643), train_loss = 0.82716296, grad/param norm = 2.8010e-01, time/batch = 16.1319s	
6086/22300 (epoch 13.646), train_loss = 0.76420475, grad/param norm = 2.5504e-01, time/batch = 17.8986s	
6087/22300 (epoch 13.648), train_loss = 0.81065398, grad/param norm = 2.6146e-01, time/batch = 15.2207s	
6088/22300 (epoch 13.650), train_loss = 0.93678667, grad/param norm = 2.5531e-01, time/batch = 17.6337s	
6089/22300 (epoch 13.652), train_loss = 0.78656645, grad/param norm = 2.4221e-01, time/batch = 15.6291s	
6090/22300 (epoch 13.655), train_loss = 0.85753625, grad/param norm = 3.0013e-01, time/batch = 16.6166s	
6091/22300 (epoch 13.657), train_loss = 0.89681877, grad/param norm = 2.8408e-01, time/batch = 15.5642s	
6092/22300 (epoch 13.659), train_loss = 0.77323816, grad/param norm = 2.5593e-01, time/batch = 18.1258s	
6093/22300 (epoch 13.661), train_loss = 0.65905931, grad/param norm = 2.3684e-01, time/batch = 17.4766s	
6094/22300 (epoch 13.664), train_loss = 0.79986032, grad/param norm = 2.2887e-01, time/batch = 16.1118s	
6095/22300 (epoch 13.666), train_loss = 0.88538331, grad/param norm = 2.6303e-01, time/batch = 17.3854s	
6096/22300 (epoch 13.668), train_loss = 0.75160121, grad/param norm = 2.2765e-01, time/batch = 16.5519s	
6097/22300 (epoch 13.670), train_loss = 0.91395920, grad/param norm = 2.7016e-01, time/batch = 16.1285s	
6098/22300 (epoch 13.673), train_loss = 0.95587052, grad/param norm = 2.6820e-01, time/batch = 16.0447s	
6099/22300 (epoch 13.675), train_loss = 1.07417681, grad/param norm = 3.1836e-01, time/batch = 16.9741s	
6100/22300 (epoch 13.677), train_loss = 1.06323115, grad/param norm = 2.8826e-01, time/batch = 17.0584s	
6101/22300 (epoch 13.679), train_loss = 0.98263794, grad/param norm = 3.2121e-01, time/batch = 15.4007s	
6102/22300 (epoch 13.682), train_loss = 0.93766698, grad/param norm = 2.8267e-01, time/batch = 15.1930s	
6103/22300 (epoch 13.684), train_loss = 0.92161889, grad/param norm = 2.5165e-01, time/batch = 16.4773s	
6104/22300 (epoch 13.686), train_loss = 0.90460246, grad/param norm = 2.7710e-01, time/batch = 16.4412s	
6105/22300 (epoch 13.688), train_loss = 0.88188497, grad/param norm = 2.6413e-01, time/batch = 15.1265s	
6106/22300 (epoch 13.691), train_loss = 0.82582712, grad/param norm = 2.5414e-01, time/batch = 17.1427s	
6107/22300 (epoch 13.693), train_loss = 0.79957229, grad/param norm = 2.6789e-01, time/batch = 15.4783s	
6108/22300 (epoch 13.695), train_loss = 0.69145858, grad/param norm = 2.4366e-01, time/batch = 16.9407s	
6109/22300 (epoch 13.697), train_loss = 0.70209965, grad/param norm = 2.3173e-01, time/batch = 15.9601s	
6110/22300 (epoch 13.700), train_loss = 0.80137247, grad/param norm = 2.5178e-01, time/batch = 17.1395s	
6111/22300 (epoch 13.702), train_loss = 0.83702778, grad/param norm = 2.4083e-01, time/batch = 17.1132s	
6112/22300 (epoch 13.704), train_loss = 0.93980258, grad/param norm = 3.2231e-01, time/batch = 16.1990s	
6113/22300 (epoch 13.706), train_loss = 0.76597668, grad/param norm = 2.6487e-01, time/batch = 16.9590s	
6114/22300 (epoch 13.709), train_loss = 0.69117592, grad/param norm = 2.2717e-01, time/batch = 16.0746s	
6115/22300 (epoch 13.711), train_loss = 0.71910283, grad/param norm = 2.3352e-01, time/batch = 17.7105s	
6116/22300 (epoch 13.713), train_loss = 0.90300782, grad/param norm = 2.5825e-01, time/batch = 16.6344s	
6117/22300 (epoch 13.715), train_loss = 0.89005586, grad/param norm = 2.6771e-01, time/batch = 17.0510s	
6118/22300 (epoch 13.717), train_loss = 1.06459934, grad/param norm = 2.8042e-01, time/batch = 15.1300s	
6119/22300 (epoch 13.720), train_loss = 0.80173751, grad/param norm = 2.5412e-01, time/batch = 15.8006s	
6120/22300 (epoch 13.722), train_loss = 0.90185966, grad/param norm = 2.7125e-01, time/batch = 16.4682s	
6121/22300 (epoch 13.724), train_loss = 0.92117972, grad/param norm = 2.6937e-01, time/batch = 15.2895s	
6122/22300 (epoch 13.726), train_loss = 0.82764809, grad/param norm = 2.7614e-01, time/batch = 18.0631s	
6123/22300 (epoch 13.729), train_loss = 0.85500695, grad/param norm = 2.5884e-01, time/batch = 15.3739s	
6124/22300 (epoch 13.731), train_loss = 1.05386128, grad/param norm = 2.9679e-01, time/batch = 16.1192s	
6125/22300 (epoch 13.733), train_loss = 1.02310297, grad/param norm = 2.9977e-01, time/batch = 16.4015s	
6126/22300 (epoch 13.735), train_loss = 1.07077358, grad/param norm = 3.1748e-01, time/batch = 17.5590s	
6127/22300 (epoch 13.738), train_loss = 0.93341126, grad/param norm = 3.1710e-01, time/batch = 15.9694s	
6128/22300 (epoch 13.740), train_loss = 0.72398119, grad/param norm = 2.4633e-01, time/batch = 17.6341s	
6129/22300 (epoch 13.742), train_loss = 0.84686128, grad/param norm = 2.7049e-01, time/batch = 15.7849s	
6130/22300 (epoch 13.744), train_loss = 1.16613776, grad/param norm = 3.0762e-01, time/batch = 16.4454s	
6131/22300 (epoch 13.747), train_loss = 0.89029611, grad/param norm = 2.4286e-01, time/batch = 15.7269s	
6132/22300 (epoch 13.749), train_loss = 1.24463271, grad/param norm = 3.7302e-01, time/batch = 16.3141s	
6133/22300 (epoch 13.751), train_loss = 1.08130486, grad/param norm = 3.2929e-01, time/batch = 17.5457s	
6134/22300 (epoch 13.753), train_loss = 1.07137953, grad/param norm = 2.9755e-01, time/batch = 15.4722s	
6135/22300 (epoch 13.756), train_loss = 0.92875329, grad/param norm = 2.6150e-01, time/batch = 16.3683s	
6136/22300 (epoch 13.758), train_loss = 0.93863758, grad/param norm = 2.6386e-01, time/batch = 15.8907s	
6137/22300 (epoch 13.760), train_loss = 0.93822435, grad/param norm = 2.8944e-01, time/batch = 17.9638s	
6138/22300 (epoch 13.762), train_loss = 0.92324077, grad/param norm = 2.8910e-01, time/batch = 17.5505s	
6139/22300 (epoch 13.765), train_loss = 0.92492496, grad/param norm = 2.5830e-01, time/batch = 16.4610s	
6140/22300 (epoch 13.767), train_loss = 0.97811655, grad/param norm = 2.7483e-01, time/batch = 16.3146s	
6141/22300 (epoch 13.769), train_loss = 0.90097072, grad/param norm = 2.8092e-01, time/batch = 16.1948s	
6142/22300 (epoch 13.771), train_loss = 0.98083497, grad/param norm = 3.0138e-01, time/batch = 15.1972s	
6143/22300 (epoch 13.774), train_loss = 1.03521236, grad/param norm = 2.9905e-01, time/batch = 15.4694s	
6144/22300 (epoch 13.776), train_loss = 1.03438782, grad/param norm = 2.7402e-01, time/batch = 18.1408s	
6145/22300 (epoch 13.778), train_loss = 1.04779607, grad/param norm = 3.1614e-01, time/batch = 15.2764s	
6146/22300 (epoch 13.780), train_loss = 1.04935028, grad/param norm = 2.9523e-01, time/batch = 16.5421s	
6147/22300 (epoch 13.783), train_loss = 1.07843543, grad/param norm = 3.0067e-01, time/batch = 16.4065s	
6148/22300 (epoch 13.785), train_loss = 0.83129355, grad/param norm = 2.7075e-01, time/batch = 14.6422s	
6149/22300 (epoch 13.787), train_loss = 0.87583612, grad/param norm = 2.9381e-01, time/batch = 17.0488s	
6150/22300 (epoch 13.789), train_loss = 1.06796418, grad/param norm = 3.4710e-01, time/batch = 16.6282s	
6151/22300 (epoch 13.791), train_loss = 1.19866178, grad/param norm = 3.2382e-01, time/batch = 16.1168s	
6152/22300 (epoch 13.794), train_loss = 1.06308685, grad/param norm = 2.9244e-01, time/batch = 16.6416s	
6153/22300 (epoch 13.796), train_loss = 1.09445553, grad/param norm = 2.9642e-01, time/batch = 16.8848s	
6154/22300 (epoch 13.798), train_loss = 1.08249449, grad/param norm = 2.7429e-01, time/batch = 16.5464s	
6155/22300 (epoch 13.800), train_loss = 0.87372957, grad/param norm = 2.8163e-01, time/batch = 16.8048s	
6156/22300 (epoch 13.803), train_loss = 0.80514860, grad/param norm = 2.5318e-01, time/batch = 15.7178s	
6157/22300 (epoch 13.805), train_loss = 0.94514406, grad/param norm = 2.7431e-01, time/batch = 16.0403s	
6158/22300 (epoch 13.807), train_loss = 1.08489883, grad/param norm = 3.1667e-01, time/batch = 15.1556s	
6159/22300 (epoch 13.809), train_loss = 0.89438826, grad/param norm = 2.6739e-01, time/batch = 15.5565s	
6160/22300 (epoch 13.812), train_loss = 1.00633394, grad/param norm = 2.5665e-01, time/batch = 16.0438s	
6161/22300 (epoch 13.814), train_loss = 0.98561205, grad/param norm = 2.7768e-01, time/batch = 18.2159s	
6162/22300 (epoch 13.816), train_loss = 1.01124568, grad/param norm = 2.6184e-01, time/batch = 16.6256s	
6163/22300 (epoch 13.818), train_loss = 1.05788866, grad/param norm = 3.1341e-01, time/batch = 15.8568s	
6164/22300 (epoch 13.821), train_loss = 1.02917289, grad/param norm = 3.0443e-01, time/batch = 17.7911s	
6165/22300 (epoch 13.823), train_loss = 0.75594369, grad/param norm = 2.4600e-01, time/batch = 15.0524s	
6166/22300 (epoch 13.825), train_loss = 0.90860161, grad/param norm = 2.6199e-01, time/batch = 17.6200s	
6167/22300 (epoch 13.827), train_loss = 0.87890671, grad/param norm = 2.7611e-01, time/batch = 15.2941s	
6168/22300 (epoch 13.830), train_loss = 0.82975056, grad/param norm = 2.8296e-01, time/batch = 18.3086s	
6169/22300 (epoch 13.832), train_loss = 0.82227320, grad/param norm = 2.6543e-01, time/batch = 15.5560s	
6170/22300 (epoch 13.834), train_loss = 0.84080263, grad/param norm = 3.1566e-01, time/batch = 15.2868s	
6171/22300 (epoch 13.836), train_loss = 0.89149673, grad/param norm = 2.7500e-01, time/batch = 15.9731s	
6172/22300 (epoch 13.839), train_loss = 0.88678349, grad/param norm = 2.6292e-01, time/batch = 17.3061s	
6173/22300 (epoch 13.841), train_loss = 0.91264644, grad/param norm = 3.1663e-01, time/batch = 15.4634s	
6174/22300 (epoch 13.843), train_loss = 0.90648089, grad/param norm = 2.7709e-01, time/batch = 16.0404s	
6175/22300 (epoch 13.845), train_loss = 0.88935994, grad/param norm = 2.4110e-01, time/batch = 16.7202s	
6176/22300 (epoch 13.848), train_loss = 0.89876436, grad/param norm = 2.5098e-01, time/batch = 16.8074s	
6177/22300 (epoch 13.850), train_loss = 0.89161119, grad/param norm = 2.3782e-01, time/batch = 15.5462s	
6178/22300 (epoch 13.852), train_loss = 0.90162380, grad/param norm = 2.8001e-01, time/batch = 15.2934s	
6179/22300 (epoch 13.854), train_loss = 1.06468110, grad/param norm = 3.0396e-01, time/batch = 16.6251s	
6180/22300 (epoch 13.857), train_loss = 0.88405387, grad/param norm = 2.7807e-01, time/batch = 15.8805s	
6181/22300 (epoch 13.859), train_loss = 0.73283096, grad/param norm = 2.4079e-01, time/batch = 17.3849s	
6182/22300 (epoch 13.861), train_loss = 0.93582773, grad/param norm = 2.5372e-01, time/batch = 16.0330s	
6183/22300 (epoch 13.863), train_loss = 0.74732272, grad/param norm = 2.3494e-01, time/batch = 16.8059s	
6184/22300 (epoch 13.865), train_loss = 0.75684581, grad/param norm = 2.4350e-01, time/batch = 17.8985s	
6185/22300 (epoch 13.868), train_loss = 0.89323876, grad/param norm = 2.3027e-01, time/batch = 15.1944s	
6186/22300 (epoch 13.870), train_loss = 0.94904731, grad/param norm = 3.1160e-01, time/batch = 17.7875s	
6187/22300 (epoch 13.872), train_loss = 1.03296323, grad/param norm = 3.2329e-01, time/batch = 15.8112s	
6188/22300 (epoch 13.874), train_loss = 0.92460875, grad/param norm = 2.8758e-01, time/batch = 16.7261s	
6189/22300 (epoch 13.877), train_loss = 0.91157455, grad/param norm = 2.6334e-01, time/batch = 15.5351s	
6190/22300 (epoch 13.879), train_loss = 0.81722138, grad/param norm = 2.5711e-01, time/batch = 18.3873s	
6191/22300 (epoch 13.881), train_loss = 0.82889343, grad/param norm = 2.4342e-01, time/batch = 16.8063s	
6192/22300 (epoch 13.883), train_loss = 0.80032109, grad/param norm = 2.3443e-01, time/batch = 15.3018s	
6193/22300 (epoch 13.886), train_loss = 0.80825204, grad/param norm = 2.5679e-01, time/batch = 16.6323s	
6194/22300 (epoch 13.888), train_loss = 0.86124046, grad/param norm = 2.6811e-01, time/batch = 16.8905s	
6195/22300 (epoch 13.890), train_loss = 0.77686714, grad/param norm = 2.2360e-01, time/batch = 15.9868s	
6196/22300 (epoch 13.892), train_loss = 1.06735085, grad/param norm = 2.7657e-01, time/batch = 16.1184s	
6197/22300 (epoch 13.895), train_loss = 1.06226322, grad/param norm = 3.2531e-01, time/batch = 16.6511s	
6198/22300 (epoch 13.897), train_loss = 0.94636516, grad/param norm = 3.1195e-01, time/batch = 16.0608s	
6199/22300 (epoch 13.899), train_loss = 0.95205035, grad/param norm = 2.8211e-01, time/batch = 16.6355s	
6200/22300 (epoch 13.901), train_loss = 0.88430372, grad/param norm = 2.7897e-01, time/batch = 14.9051s	
6201/22300 (epoch 13.904), train_loss = 0.98381020, grad/param norm = 2.8147e-01, time/batch = 16.8855s	
6202/22300 (epoch 13.906), train_loss = 0.97628615, grad/param norm = 2.4948e-01, time/batch = 15.8773s	
6203/22300 (epoch 13.908), train_loss = 0.90252274, grad/param norm = 2.6087e-01, time/batch = 16.6168s	
6204/22300 (epoch 13.910), train_loss = 0.75280923, grad/param norm = 2.4171e-01, time/batch = 16.7037s	
6205/22300 (epoch 13.913), train_loss = 0.95214006, grad/param norm = 2.6794e-01, time/batch = 16.5384s	
6206/22300 (epoch 13.915), train_loss = 1.11611010, grad/param norm = 2.9709e-01, time/batch = 16.9460s	
6207/22300 (epoch 13.917), train_loss = 0.90086554, grad/param norm = 2.5664e-01, time/batch = 15.6257s	
6208/22300 (epoch 13.919), train_loss = 0.96117412, grad/param norm = 2.6195e-01, time/batch = 17.3057s	
6209/22300 (epoch 13.922), train_loss = 0.85298386, grad/param norm = 2.5620e-01, time/batch = 18.2197s	
6210/22300 (epoch 13.924), train_loss = 0.66054159, grad/param norm = 2.2641e-01, time/batch = 16.7109s	
6211/22300 (epoch 13.926), train_loss = 0.71336000, grad/param norm = 2.9593e-01, time/batch = 15.4645s	
6212/22300 (epoch 13.928), train_loss = 0.86328123, grad/param norm = 2.6871e-01, time/batch = 18.8628s	
6213/22300 (epoch 13.930), train_loss = 0.87031490, grad/param norm = 2.6936e-01, time/batch = 17.3136s	
6214/22300 (epoch 13.933), train_loss = 0.96831411, grad/param norm = 3.1655e-01, time/batch = 15.1316s	
6215/22300 (epoch 13.935), train_loss = 1.01860729, grad/param norm = 3.0683e-01, time/batch = 16.2386s	
6216/22300 (epoch 13.937), train_loss = 1.06337361, grad/param norm = 2.9755e-01, time/batch = 16.2962s	
6217/22300 (epoch 13.939), train_loss = 1.01861537, grad/param norm = 3.1630e-01, time/batch = 15.7133s	
6218/22300 (epoch 13.942), train_loss = 1.17691902, grad/param norm = 3.4605e-01, time/batch = 15.1257s	
6219/22300 (epoch 13.944), train_loss = 1.18965765, grad/param norm = 3.2707e-01, time/batch = 15.7212s	
6220/22300 (epoch 13.946), train_loss = 0.92453423, grad/param norm = 2.7545e-01, time/batch = 18.0276s	
6221/22300 (epoch 13.948), train_loss = 0.82290579, grad/param norm = 2.3699e-01, time/batch = 15.4394s	
6222/22300 (epoch 13.951), train_loss = 0.76389677, grad/param norm = 2.7199e-01, time/batch = 16.1183s	
6223/22300 (epoch 13.953), train_loss = 0.79557263, grad/param norm = 2.9614e-01, time/batch = 16.3878s	
6224/22300 (epoch 13.955), train_loss = 1.10413615, grad/param norm = 2.9898e-01, time/batch = 17.3056s	
6225/22300 (epoch 13.957), train_loss = 1.22470948, grad/param norm = 3.1291e-01, time/batch = 15.8052s	
6226/22300 (epoch 13.960), train_loss = 1.06074899, grad/param norm = 2.8516e-01, time/batch = 17.5654s	
6227/22300 (epoch 13.962), train_loss = 0.92111926, grad/param norm = 2.8073e-01, time/batch = 16.2809s	
6228/22300 (epoch 13.964), train_loss = 0.89228803, grad/param norm = 2.4820e-01, time/batch = 15.8874s	
6229/22300 (epoch 13.966), train_loss = 0.80979331, grad/param norm = 2.5796e-01, time/batch = 15.2874s	
6230/22300 (epoch 13.969), train_loss = 0.84248169, grad/param norm = 2.3800e-01, time/batch = 16.7126s	
6231/22300 (epoch 13.971), train_loss = 0.89337184, grad/param norm = 2.5129e-01, time/batch = 18.2959s	
6232/22300 (epoch 13.973), train_loss = 0.92783674, grad/param norm = 2.7440e-01, time/batch = 16.4580s	
6233/22300 (epoch 13.975), train_loss = 1.12653889, grad/param norm = 3.2571e-01, time/batch = 17.7155s	
6234/22300 (epoch 13.978), train_loss = 0.96705595, grad/param norm = 2.8325e-01, time/batch = 16.8011s	
6235/22300 (epoch 13.980), train_loss = 1.03380138, grad/param norm = 2.9151e-01, time/batch = 16.3051s	
6236/22300 (epoch 13.982), train_loss = 0.81245403, grad/param norm = 2.5058e-01, time/batch = 15.6527s	
6237/22300 (epoch 13.984), train_loss = 0.94225035, grad/param norm = 2.7131e-01, time/batch = 16.9622s	
6238/22300 (epoch 13.987), train_loss = 0.86030906, grad/param norm = 2.4956e-01, time/batch = 17.4625s	
6239/22300 (epoch 13.989), train_loss = 0.89647624, grad/param norm = 2.5372e-01, time/batch = 15.8561s	
6240/22300 (epoch 13.991), train_loss = 1.13614029, grad/param norm = 3.0685e-01, time/batch = 16.2143s	
6241/22300 (epoch 13.993), train_loss = 1.30052767, grad/param norm = 3.1919e-01, time/batch = 15.4756s	
6242/22300 (epoch 13.996), train_loss = 1.22583602, grad/param norm = 3.4771e-01, time/batch = 16.1075s	
6243/22300 (epoch 13.998), train_loss = 0.91374518, grad/param norm = 2.7703e-01, time/batch = 15.8747s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
6244/22300 (epoch 14.000), train_loss = 0.78996521, grad/param norm = 2.7077e-01, time/batch = 15.8916s	
6245/22300 (epoch 14.002), train_loss = 1.11799721, grad/param norm = 3.1459e-01, time/batch = 16.2390s	
6246/22300 (epoch 14.004), train_loss = 0.89194261, grad/param norm = 2.5102e-01, time/batch = 18.6135s	
6247/22300 (epoch 14.007), train_loss = 0.95662845, grad/param norm = 3.0315e-01, time/batch = 15.3995s	
6248/22300 (epoch 14.009), train_loss = 0.95462556, grad/param norm = 2.8090e-01, time/batch = 15.8119s	
6249/22300 (epoch 14.011), train_loss = 1.14236449, grad/param norm = 3.2246e-01, time/batch = 15.6946s	
6250/22300 (epoch 14.013), train_loss = 0.89982556, grad/param norm = 2.6971e-01, time/batch = 16.5435s	
6251/22300 (epoch 14.016), train_loss = 0.85072581, grad/param norm = 2.9979e-01, time/batch = 17.1179s	
6252/22300 (epoch 14.018), train_loss = 1.01773892, grad/param norm = 2.7655e-01, time/batch = 15.9886s	
6253/22300 (epoch 14.020), train_loss = 0.87589736, grad/param norm = 2.9639e-01, time/batch = 18.7099s	
6254/22300 (epoch 14.022), train_loss = 0.80334825, grad/param norm = 2.6735e-01, time/batch = 15.6301s	
6255/22300 (epoch 14.025), train_loss = 0.82456073, grad/param norm = 2.6374e-01, time/batch = 19.6961s	
6256/22300 (epoch 14.027), train_loss = 0.86695080, grad/param norm = 2.4278e-01, time/batch = 15.3090s	
6257/22300 (epoch 14.029), train_loss = 0.81531487, grad/param norm = 2.5163e-01, time/batch = 16.6898s	
6258/22300 (epoch 14.031), train_loss = 0.80581668, grad/param norm = 2.2466e-01, time/batch = 15.7787s	
6259/22300 (epoch 14.034), train_loss = 0.83687834, grad/param norm = 2.6043e-01, time/batch = 16.8913s	
6260/22300 (epoch 14.036), train_loss = 0.65237344, grad/param norm = 2.2136e-01, time/batch = 16.5592s	
6261/22300 (epoch 14.038), train_loss = 0.80459919, grad/param norm = 2.3833e-01, time/batch = 15.9815s	
6262/22300 (epoch 14.040), train_loss = 0.87675558, grad/param norm = 2.5973e-01, time/batch = 17.6525s	
6263/22300 (epoch 14.043), train_loss = 1.13840769, grad/param norm = 2.8402e-01, time/batch = 14.9775s	
6264/22300 (epoch 14.045), train_loss = 0.94589791, grad/param norm = 3.0232e-01, time/batch = 17.3059s	
6265/22300 (epoch 14.047), train_loss = 1.03696774, grad/param norm = 2.9885e-01, time/batch = 16.4712s	
6266/22300 (epoch 14.049), train_loss = 0.85252002, grad/param norm = 2.6966e-01, time/batch = 16.9507s	
6267/22300 (epoch 14.052), train_loss = 0.95767922, grad/param norm = 2.9215e-01, time/batch = 18.6436s	
6268/22300 (epoch 14.054), train_loss = 0.96620008, grad/param norm = 2.8248e-01, time/batch = 16.3092s	
6269/22300 (epoch 14.056), train_loss = 0.64739333, grad/param norm = 2.2880e-01, time/batch = 17.6303s	
6270/22300 (epoch 14.058), train_loss = 0.80727695, grad/param norm = 2.4491e-01, time/batch = 15.6992s	
6271/22300 (epoch 14.061), train_loss = 0.77382884, grad/param norm = 2.5042e-01, time/batch = 15.4760s	
6272/22300 (epoch 14.063), train_loss = 1.07071015, grad/param norm = 3.0580e-01, time/batch = 15.3869s	
6273/22300 (epoch 14.065), train_loss = 0.98853196, grad/param norm = 2.8880e-01, time/batch = 14.5678s	
6274/22300 (epoch 14.067), train_loss = 0.83763671, grad/param norm = 2.9649e-01, time/batch = 17.6458s	
6275/22300 (epoch 14.070), train_loss = 0.88512993, grad/param norm = 2.7365e-01, time/batch = 15.2624s	
6276/22300 (epoch 14.072), train_loss = 0.97818609, grad/param norm = 3.0185e-01, time/batch = 15.2364s	
6277/22300 (epoch 14.074), train_loss = 0.94394442, grad/param norm = 2.7450e-01, time/batch = 17.2913s	
6278/22300 (epoch 14.076), train_loss = 0.90455494, grad/param norm = 2.7937e-01, time/batch = 16.5526s	
6279/22300 (epoch 14.078), train_loss = 0.99661286, grad/param norm = 3.4465e-01, time/batch = 16.5414s	
6280/22300 (epoch 14.081), train_loss = 0.99247346, grad/param norm = 3.1004e-01, time/batch = 16.0506s	
6281/22300 (epoch 14.083), train_loss = 1.11304478, grad/param norm = 3.0155e-01, time/batch = 17.4666s	
6282/22300 (epoch 14.085), train_loss = 1.14245956, grad/param norm = 3.1904e-01, time/batch = 17.2069s	
6283/22300 (epoch 14.087), train_loss = 0.95980128, grad/param norm = 2.8902e-01, time/batch = 16.2982s	
6284/22300 (epoch 14.090), train_loss = 0.78420048, grad/param norm = 2.4016e-01, time/batch = 15.2721s	
6285/22300 (epoch 14.092), train_loss = 0.79892962, grad/param norm = 2.7211e-01, time/batch = 17.6331s	
6286/22300 (epoch 14.094), train_loss = 0.76169205, grad/param norm = 2.3164e-01, time/batch = 16.7296s	
6287/22300 (epoch 14.096), train_loss = 1.07613245, grad/param norm = 2.6675e-01, time/batch = 15.3969s	
6288/22300 (epoch 14.099), train_loss = 0.85098180, grad/param norm = 2.4973e-01, time/batch = 17.2978s	
6289/22300 (epoch 14.101), train_loss = 0.99819116, grad/param norm = 2.7321e-01, time/batch = 18.4620s	
6290/22300 (epoch 14.103), train_loss = 0.92815502, grad/param norm = 2.6935e-01, time/batch = 15.8714s	
6291/22300 (epoch 14.105), train_loss = 0.88365938, grad/param norm = 3.0211e-01, time/batch = 16.9660s	
6292/22300 (epoch 14.108), train_loss = 0.94112213, grad/param norm = 2.6054e-01, time/batch = 18.2168s	
6293/22300 (epoch 14.110), train_loss = 0.93230513, grad/param norm = 2.5309e-01, time/batch = 21.6426s	
6294/22300 (epoch 14.112), train_loss = 0.90540148, grad/param norm = 2.5514e-01, time/batch = 22.7928s	
6295/22300 (epoch 14.114), train_loss = 0.99646439, grad/param norm = 2.9334e-01, time/batch = 14.6415s	
6296/22300 (epoch 14.117), train_loss = 1.14326355, grad/param norm = 2.8758e-01, time/batch = 16.0207s	
6297/22300 (epoch 14.119), train_loss = 1.02514568, grad/param norm = 2.4684e-01, time/batch = 15.9866s	
6298/22300 (epoch 14.121), train_loss = 1.08038067, grad/param norm = 2.9272e-01, time/batch = 15.6649s	
6299/22300 (epoch 14.123), train_loss = 0.99555567, grad/param norm = 2.6666e-01, time/batch = 15.4535s	
6300/22300 (epoch 14.126), train_loss = 0.94031383, grad/param norm = 2.7126e-01, time/batch = 16.0482s	
6301/22300 (epoch 14.128), train_loss = 1.01870754, grad/param norm = 2.6120e-01, time/batch = 17.4576s	
6302/22300 (epoch 14.130), train_loss = 0.84750588, grad/param norm = 2.7012e-01, time/batch = 16.8851s	
6303/22300 (epoch 14.132), train_loss = 0.73325459, grad/param norm = 2.1520e-01, time/batch = 16.6474s	
6304/22300 (epoch 14.135), train_loss = 0.76808934, grad/param norm = 2.4077e-01, time/batch = 15.3896s	
6305/22300 (epoch 14.137), train_loss = 0.62537605, grad/param norm = 2.2410e-01, time/batch = 17.0595s	
6306/22300 (epoch 14.139), train_loss = 0.98021876, grad/param norm = 2.8396e-01, time/batch = 17.3087s	
6307/22300 (epoch 14.141), train_loss = 0.98965764, grad/param norm = 2.4794e-01, time/batch = 15.6339s	
6308/22300 (epoch 14.143), train_loss = 0.93878200, grad/param norm = 2.9339e-01, time/batch = 16.8163s	
6309/22300 (epoch 14.146), train_loss = 1.06473804, grad/param norm = 2.8772e-01, time/batch = 16.6489s	
6310/22300 (epoch 14.148), train_loss = 0.79203197, grad/param norm = 2.4098e-01, time/batch = 16.5428s	
6311/22300 (epoch 14.150), train_loss = 0.84263691, grad/param norm = 2.5354e-01, time/batch = 16.7008s	
6312/22300 (epoch 14.152), train_loss = 0.77362837, grad/param norm = 2.6741e-01, time/batch = 17.0553s	
6313/22300 (epoch 14.155), train_loss = 0.81671300, grad/param norm = 2.4735e-01, time/batch = 15.7300s	
6314/22300 (epoch 14.157), train_loss = 1.02292907, grad/param norm = 3.1977e-01, time/batch = 16.0212s	
6315/22300 (epoch 14.159), train_loss = 0.96179489, grad/param norm = 2.7049e-01, time/batch = 15.0273s	
6316/22300 (epoch 14.161), train_loss = 1.01684767, grad/param norm = 3.0639e-01, time/batch = 16.8903s	
6317/22300 (epoch 14.164), train_loss = 0.77090428, grad/param norm = 2.5273e-01, time/batch = 15.7140s	
6318/22300 (epoch 14.166), train_loss = 0.75412976, grad/param norm = 2.0628e-01, time/batch = 16.9637s	
6319/22300 (epoch 14.168), train_loss = 0.81334514, grad/param norm = 2.4170e-01, time/batch = 16.2357s	
6320/22300 (epoch 14.170), train_loss = 0.92443045, grad/param norm = 2.5057e-01, time/batch = 17.2879s	
6321/22300 (epoch 14.173), train_loss = 1.07043956, grad/param norm = 2.9132e-01, time/batch = 17.1514s	
6322/22300 (epoch 14.175), train_loss = 0.89171757, grad/param norm = 2.5583e-01, time/batch = 14.9708s	
6323/22300 (epoch 14.177), train_loss = 0.71006038, grad/param norm = 2.4382e-01, time/batch = 18.1154s	
6324/22300 (epoch 14.179), train_loss = 0.86592768, grad/param norm = 2.5574e-01, time/batch = 15.9878s	
6325/22300 (epoch 14.182), train_loss = 1.08544042, grad/param norm = 2.9468e-01, time/batch = 16.7200s	
6326/22300 (epoch 14.184), train_loss = 1.17761288, grad/param norm = 3.0218e-01, time/batch = 15.2412s	
6327/22300 (epoch 14.186), train_loss = 0.98666545, grad/param norm = 2.9629e-01, time/batch = 18.5464s	
6328/22300 (epoch 14.188), train_loss = 1.13117810, grad/param norm = 3.0199e-01, time/batch = 16.6846s	
6329/22300 (epoch 14.191), train_loss = 1.11540220, grad/param norm = 3.1536e-01, time/batch = 15.1218s	
6330/22300 (epoch 14.193), train_loss = 0.95096823, grad/param norm = 3.1234e-01, time/batch = 14.6544s	
6331/22300 (epoch 14.195), train_loss = 0.85098864, grad/param norm = 2.5802e-01, time/batch = 14.8182s	
6332/22300 (epoch 14.197), train_loss = 0.85964399, grad/param norm = 2.5660e-01, time/batch = 17.8058s	
6333/22300 (epoch 14.200), train_loss = 0.79206434, grad/param norm = 2.5324e-01, time/batch = 14.9625s	
6334/22300 (epoch 14.202), train_loss = 0.88124815, grad/param norm = 2.5163e-01, time/batch = 18.2971s	
6335/22300 (epoch 14.204), train_loss = 0.86467876, grad/param norm = 2.5732e-01, time/batch = 16.7017s	
6336/22300 (epoch 14.206), train_loss = 0.78449772, grad/param norm = 2.4494e-01, time/batch = 16.8675s	
6337/22300 (epoch 14.209), train_loss = 0.87432289, grad/param norm = 2.5955e-01, time/batch = 14.8245s	
6338/22300 (epoch 14.211), train_loss = 0.72302751, grad/param norm = 2.5646e-01, time/batch = 16.7803s	
6339/22300 (epoch 14.213), train_loss = 0.84842577, grad/param norm = 2.3661e-01, time/batch = 15.9518s	
6340/22300 (epoch 14.215), train_loss = 1.10637196, grad/param norm = 2.9713e-01, time/batch = 16.2882s	
6341/22300 (epoch 14.217), train_loss = 1.00166502, grad/param norm = 2.7663e-01, time/batch = 15.5765s	
6342/22300 (epoch 14.220), train_loss = 0.88076639, grad/param norm = 2.5254e-01, time/batch = 17.4573s	
6343/22300 (epoch 14.222), train_loss = 0.79382001, grad/param norm = 2.6297e-01, time/batch = 18.0217s	
6344/22300 (epoch 14.224), train_loss = 0.80233984, grad/param norm = 2.4267e-01, time/batch = 15.6383s	
6345/22300 (epoch 14.226), train_loss = 0.84430760, grad/param norm = 2.3210e-01, time/batch = 16.3954s	
6346/22300 (epoch 14.229), train_loss = 0.83434210, grad/param norm = 2.8993e-01, time/batch = 16.5588s	
6347/22300 (epoch 14.231), train_loss = 1.00208020, grad/param norm = 3.6002e-01, time/batch = 17.2108s	
6348/22300 (epoch 14.233), train_loss = 0.95782578, grad/param norm = 2.7576e-01, time/batch = 15.3209s	
6349/22300 (epoch 14.235), train_loss = 0.73567067, grad/param norm = 2.5469e-01, time/batch = 15.8016s	
6350/22300 (epoch 14.238), train_loss = 0.75085687, grad/param norm = 2.4115e-01, time/batch = 16.1246s	
6351/22300 (epoch 14.240), train_loss = 0.74813338, grad/param norm = 2.3140e-01, time/batch = 15.7126s	
6352/22300 (epoch 14.242), train_loss = 0.76763973, grad/param norm = 2.3506e-01, time/batch = 15.6321s	
6353/22300 (epoch 14.244), train_loss = 0.59451872, grad/param norm = 2.2632e-01, time/batch = 15.3906s	
6354/22300 (epoch 14.247), train_loss = 0.77834529, grad/param norm = 2.8185e-01, time/batch = 18.0513s	
6355/22300 (epoch 14.249), train_loss = 0.63736568, grad/param norm = 2.5031e-01, time/batch = 16.3770s	
6356/22300 (epoch 14.251), train_loss = 0.74190538, grad/param norm = 2.2713e-01, time/batch = 17.1884s	
6357/22300 (epoch 14.253), train_loss = 0.65452804, grad/param norm = 2.5566e-01, time/batch = 15.9763s	
6358/22300 (epoch 14.256), train_loss = 0.75993213, grad/param norm = 2.2652e-01, time/batch = 15.7785s	
6359/22300 (epoch 14.258), train_loss = 1.02668900, grad/param norm = 2.9110e-01, time/batch = 16.2026s	
6360/22300 (epoch 14.260), train_loss = 0.88092742, grad/param norm = 2.7693e-01, time/batch = 15.9834s	
6361/22300 (epoch 14.262), train_loss = 0.77854355, grad/param norm = 2.3349e-01, time/batch = 18.2930s	
6362/22300 (epoch 14.265), train_loss = 0.75912325, grad/param norm = 2.4590e-01, time/batch = 15.3909s	
6363/22300 (epoch 14.267), train_loss = 0.82066924, grad/param norm = 2.4746e-01, time/batch = 16.6396s	
6364/22300 (epoch 14.269), train_loss = 0.87305252, grad/param norm = 2.9590e-01, time/batch = 17.1456s	
6365/22300 (epoch 14.271), train_loss = 0.82616497, grad/param norm = 2.3539e-01, time/batch = 16.1436s	
6366/22300 (epoch 14.274), train_loss = 0.68852225, grad/param norm = 2.4583e-01, time/batch = 15.8832s	
6367/22300 (epoch 14.276), train_loss = 0.63188767, grad/param norm = 1.9965e-01, time/batch = 16.0630s	
6368/22300 (epoch 14.278), train_loss = 0.59703743, grad/param norm = 2.2147e-01, time/batch = 15.5689s	
6369/22300 (epoch 14.280), train_loss = 0.77313457, grad/param norm = 2.5891e-01, time/batch = 16.7761s	
6370/22300 (epoch 14.283), train_loss = 0.57868403, grad/param norm = 1.8284e-01, time/batch = 17.2969s	
6371/22300 (epoch 14.285), train_loss = 0.76759188, grad/param norm = 2.6466e-01, time/batch = 16.7044s	
6372/22300 (epoch 14.287), train_loss = 0.89781133, grad/param norm = 2.7029e-01, time/batch = 18.2184s	
6373/22300 (epoch 14.289), train_loss = 0.76656746, grad/param norm = 2.4453e-01, time/batch = 15.7046s	
6374/22300 (epoch 14.291), train_loss = 0.81231937, grad/param norm = 2.7378e-01, time/batch = 16.2843s	
6375/22300 (epoch 14.294), train_loss = 0.69964494, grad/param norm = 2.2253e-01, time/batch = 15.8782s	
6376/22300 (epoch 14.296), train_loss = 0.92435915, grad/param norm = 2.9404e-01, time/batch = 15.4625s	
6377/22300 (epoch 14.298), train_loss = 0.98409944, grad/param norm = 2.6660e-01, time/batch = 15.0496s	
6378/22300 (epoch 14.300), train_loss = 1.01803231, grad/param norm = 2.8179e-01, time/batch = 17.2277s	
6379/22300 (epoch 14.303), train_loss = 0.82174376, grad/param norm = 2.4820e-01, time/batch = 18.8738s	
6380/22300 (epoch 14.305), train_loss = 0.84830787, grad/param norm = 3.0765e-01, time/batch = 16.1400s	
6381/22300 (epoch 14.307), train_loss = 0.79444529, grad/param norm = 2.8312e-01, time/batch = 15.9735s	
6382/22300 (epoch 14.309), train_loss = 0.76034765, grad/param norm = 2.5754e-01, time/batch = 16.7242s	
6383/22300 (epoch 14.312), train_loss = 0.74138565, grad/param norm = 2.6236e-01, time/batch = 18.0414s	
6384/22300 (epoch 14.314), train_loss = 0.77573887, grad/param norm = 2.4361e-01, time/batch = 15.3833s	
6385/22300 (epoch 14.316), train_loss = 0.77583301, grad/param norm = 2.5072e-01, time/batch = 16.1593s	
6386/22300 (epoch 14.318), train_loss = 0.83021948, grad/param norm = 2.3636e-01, time/batch = 15.5710s	
6387/22300 (epoch 14.321), train_loss = 0.90298031, grad/param norm = 2.6446e-01, time/batch = 14.8779s	
6388/22300 (epoch 14.323), train_loss = 0.74766834, grad/param norm = 2.3526e-01, time/batch = 15.1426s	
6389/22300 (epoch 14.325), train_loss = 0.70302667, grad/param norm = 2.3879e-01, time/batch = 15.7854s	
6390/22300 (epoch 14.327), train_loss = 0.74177143, grad/param norm = 2.4977e-01, time/batch = 16.5592s	
6391/22300 (epoch 14.330), train_loss = 0.76434165, grad/param norm = 2.6075e-01, time/batch = 15.3725s	
6392/22300 (epoch 14.332), train_loss = 0.75339954, grad/param norm = 2.8143e-01, time/batch = 16.7752s	
6393/22300 (epoch 14.334), train_loss = 0.73431108, grad/param norm = 2.7204e-01, time/batch = 16.7209s	
6394/22300 (epoch 14.336), train_loss = 0.79059534, grad/param norm = 2.8148e-01, time/batch = 15.2902s	
6395/22300 (epoch 14.339), train_loss = 0.84597008, grad/param norm = 2.9368e-01, time/batch = 15.6362s	
6396/22300 (epoch 14.341), train_loss = 0.91588923, grad/param norm = 3.0057e-01, time/batch = 17.5385s	
6397/22300 (epoch 14.343), train_loss = 0.98810265, grad/param norm = 2.6817e-01, time/batch = 15.4923s	
6398/22300 (epoch 14.345), train_loss = 0.82582752, grad/param norm = 2.8091e-01, time/batch = 17.4636s	
6399/22300 (epoch 14.348), train_loss = 0.83122508, grad/param norm = 2.6344e-01, time/batch = 15.8768s	
6400/22300 (epoch 14.350), train_loss = 0.68949319, grad/param norm = 2.2740e-01, time/batch = 17.8844s	
6401/22300 (epoch 14.352), train_loss = 0.94057087, grad/param norm = 2.6191e-01, time/batch = 18.5414s	
6402/22300 (epoch 14.354), train_loss = 1.08072833, grad/param norm = 2.7639e-01, time/batch = 16.0472s	
6403/22300 (epoch 14.357), train_loss = 0.95996183, grad/param norm = 2.7235e-01, time/batch = 17.6921s	
6404/22300 (epoch 14.359), train_loss = 0.79265578, grad/param norm = 2.5588e-01, time/batch = 16.2186s	
6405/22300 (epoch 14.361), train_loss = 0.80062154, grad/param norm = 2.6401e-01, time/batch = 16.2770s	
6406/22300 (epoch 14.363), train_loss = 1.01083087, grad/param norm = 2.9521e-01, time/batch = 16.3007s	
6407/22300 (epoch 14.365), train_loss = 0.86372680, grad/param norm = 2.9597e-01, time/batch = 18.5514s	
6408/22300 (epoch 14.368), train_loss = 0.87629047, grad/param norm = 3.3326e-01, time/batch = 18.4645s	
6409/22300 (epoch 14.370), train_loss = 0.86077747, grad/param norm = 2.9776e-01, time/batch = 16.3004s	
6410/22300 (epoch 14.372), train_loss = 0.69239305, grad/param norm = 2.5184e-01, time/batch = 16.3578s	
6411/22300 (epoch 14.374), train_loss = 0.64393409, grad/param norm = 2.5891e-01, time/batch = 16.3229s	
6412/22300 (epoch 14.377), train_loss = 0.81419342, grad/param norm = 2.9310e-01, time/batch = 15.9327s	
6413/22300 (epoch 14.379), train_loss = 0.79697274, grad/param norm = 2.6521e-01, time/batch = 15.2833s	
6414/22300 (epoch 14.381), train_loss = 0.95549057, grad/param norm = 2.6267e-01, time/batch = 16.6419s	
6415/22300 (epoch 14.383), train_loss = 0.79915290, grad/param norm = 2.8149e-01, time/batch = 16.6549s	
6416/22300 (epoch 14.386), train_loss = 0.80950512, grad/param norm = 2.5682e-01, time/batch = 16.9606s	
6417/22300 (epoch 14.388), train_loss = 0.75288719, grad/param norm = 2.8781e-01, time/batch = 16.7211s	
6418/22300 (epoch 14.390), train_loss = 0.87883739, grad/param norm = 2.7861e-01, time/batch = 17.3189s	
6419/22300 (epoch 14.392), train_loss = 0.78333784, grad/param norm = 2.6336e-01, time/batch = 15.5558s	
6420/22300 (epoch 14.395), train_loss = 0.73339274, grad/param norm = 2.8012e-01, time/batch = 17.2532s	
6421/22300 (epoch 14.397), train_loss = 0.52452033, grad/param norm = 2.2829e-01, time/batch = 19.8654s	
6422/22300 (epoch 14.399), train_loss = 0.69433511, grad/param norm = 2.6234e-01, time/batch = 17.2966s	
6423/22300 (epoch 14.401), train_loss = 0.78819332, grad/param norm = 2.5991e-01, time/batch = 16.0987s	
6424/22300 (epoch 14.404), train_loss = 0.74715562, grad/param norm = 2.3724e-01, time/batch = 15.2802s	
6425/22300 (epoch 14.406), train_loss = 1.07595328, grad/param norm = 3.2983e-01, time/batch = 16.1324s	
6426/22300 (epoch 14.408), train_loss = 0.92946326, grad/param norm = 2.8729e-01, time/batch = 19.1327s	
6427/22300 (epoch 14.410), train_loss = 0.92111090, grad/param norm = 2.7345e-01, time/batch = 16.2902s	
6428/22300 (epoch 14.413), train_loss = 0.77110309, grad/param norm = 2.4730e-01, time/batch = 15.7144s	
6429/22300 (epoch 14.415), train_loss = 0.65679141, grad/param norm = 2.2528e-01, time/batch = 16.7188s	
6430/22300 (epoch 14.417), train_loss = 0.85097566, grad/param norm = 2.6341e-01, time/batch = 16.8926s	
6431/22300 (epoch 14.419), train_loss = 0.77375984, grad/param norm = 2.3530e-01, time/batch = 16.2221s	
6432/22300 (epoch 14.422), train_loss = 0.77252972, grad/param norm = 2.4565e-01, time/batch = 15.9772s	
6433/22300 (epoch 14.424), train_loss = 0.85410981, grad/param norm = 2.7009e-01, time/batch = 17.2203s	
6434/22300 (epoch 14.426), train_loss = 0.70553614, grad/param norm = 2.6333e-01, time/batch = 16.2934s	
6435/22300 (epoch 14.428), train_loss = 0.74213833, grad/param norm = 2.3601e-01, time/batch = 15.1938s	
6436/22300 (epoch 14.430), train_loss = 0.80490372, grad/param norm = 2.7779e-01, time/batch = 16.4610s	
6437/22300 (epoch 14.433), train_loss = 0.78878366, grad/param norm = 2.5366e-01, time/batch = 15.1731s	
6438/22300 (epoch 14.435), train_loss = 0.85406033, grad/param norm = 2.8210e-01, time/batch = 14.8919s	
6439/22300 (epoch 14.437), train_loss = 0.84664848, grad/param norm = 2.6169e-01, time/batch = 17.3849s	
6440/22300 (epoch 14.439), train_loss = 0.88287647, grad/param norm = 2.8362e-01, time/batch = 16.3112s	
6441/22300 (epoch 14.442), train_loss = 0.85542168, grad/param norm = 2.7578e-01, time/batch = 17.1334s	
6442/22300 (epoch 14.444), train_loss = 0.76358639, grad/param norm = 2.3282e-01, time/batch = 15.6449s	
6443/22300 (epoch 14.446), train_loss = 0.68074313, grad/param norm = 2.4495e-01, time/batch = 15.5579s	
6444/22300 (epoch 14.448), train_loss = 0.54884300, grad/param norm = 1.9057e-01, time/batch = 17.2007s	
6445/22300 (epoch 14.451), train_loss = 0.90942081, grad/param norm = 2.6693e-01, time/batch = 15.7819s	
6446/22300 (epoch 14.453), train_loss = 0.75859483, grad/param norm = 2.7573e-01, time/batch = 15.4615s	
6447/22300 (epoch 14.455), train_loss = 1.03069154, grad/param norm = 3.1939e-01, time/batch = 16.8008s	
6448/22300 (epoch 14.457), train_loss = 0.94714778, grad/param norm = 2.5763e-01, time/batch = 17.0479s	
6449/22300 (epoch 14.460), train_loss = 0.88912409, grad/param norm = 2.7690e-01, time/batch = 15.2739s	
6450/22300 (epoch 14.462), train_loss = 0.95764257, grad/param norm = 2.5844e-01, time/batch = 16.4666s	
6451/22300 (epoch 14.464), train_loss = 0.87981863, grad/param norm = 2.8934e-01, time/batch = 15.2852s	
6452/22300 (epoch 14.466), train_loss = 0.78799449, grad/param norm = 2.3806e-01, time/batch = 17.2075s	
6453/22300 (epoch 14.469), train_loss = 0.73559727, grad/param norm = 2.3461e-01, time/batch = 15.6196s	
6454/22300 (epoch 14.471), train_loss = 0.89703871, grad/param norm = 2.5245e-01, time/batch = 17.7213s	
6455/22300 (epoch 14.473), train_loss = 0.91419381, grad/param norm = 2.9394e-01, time/batch = 17.2237s	
6456/22300 (epoch 14.475), train_loss = 0.75099505, grad/param norm = 2.4391e-01, time/batch = 16.3693s	
6457/22300 (epoch 14.478), train_loss = 0.77906727, grad/param norm = 2.6616e-01, time/batch = 16.4641s	
6458/22300 (epoch 14.480), train_loss = 0.60720184, grad/param norm = 2.3500e-01, time/batch = 16.3866s	
6459/22300 (epoch 14.482), train_loss = 0.65840664, grad/param norm = 2.2622e-01, time/batch = 15.2070s	
6460/22300 (epoch 14.484), train_loss = 0.78848266, grad/param norm = 2.4959e-01, time/batch = 15.7149s	
6461/22300 (epoch 14.487), train_loss = 0.84525421, grad/param norm = 2.4655e-01, time/batch = 17.4734s	
6462/22300 (epoch 14.489), train_loss = 0.89110746, grad/param norm = 2.7957e-01, time/batch = 17.0527s	
6463/22300 (epoch 14.491), train_loss = 0.87017848, grad/param norm = 2.5452e-01, time/batch = 17.0467s	
6464/22300 (epoch 14.493), train_loss = 0.88712227, grad/param norm = 3.3752e-01, time/batch = 16.3867s	
6465/22300 (epoch 14.496), train_loss = 0.76529653, grad/param norm = 2.6529e-01, time/batch = 17.0428s	
6466/22300 (epoch 14.498), train_loss = 0.69403834, grad/param norm = 2.4061e-01, time/batch = 16.8111s	
6467/22300 (epoch 14.500), train_loss = 0.83798927, grad/param norm = 2.4627e-01, time/batch = 15.1003s	
6468/22300 (epoch 14.502), train_loss = 0.64295641, grad/param norm = 2.8182e-01, time/batch = 17.8894s	
6469/22300 (epoch 14.504), train_loss = 0.68427498, grad/param norm = 2.4197e-01, time/batch = 16.6400s	
6470/22300 (epoch 14.507), train_loss = 0.73770990, grad/param norm = 2.6723e-01, time/batch = 18.1235s	
6471/22300 (epoch 14.509), train_loss = 0.89283138, grad/param norm = 2.6658e-01, time/batch = 16.4650s	
6472/22300 (epoch 14.511), train_loss = 0.64656378, grad/param norm = 2.4346e-01, time/batch = 15.7268s	
6473/22300 (epoch 14.513), train_loss = 0.61295240, grad/param norm = 2.0906e-01, time/batch = 18.2087s	
6474/22300 (epoch 14.516), train_loss = 0.71670131, grad/param norm = 2.5121e-01, time/batch = 15.8041s	
6475/22300 (epoch 14.518), train_loss = 0.87700556, grad/param norm = 2.5123e-01, time/batch = 16.1386s	
6476/22300 (epoch 14.520), train_loss = 0.80963169, grad/param norm = 2.5719e-01, time/batch = 15.2300s	
6477/22300 (epoch 14.522), train_loss = 0.73993489, grad/param norm = 2.6052e-01, time/batch = 16.9791s	
6478/22300 (epoch 14.525), train_loss = 0.69836316, grad/param norm = 2.5022e-01, time/batch = 16.7825s	
6479/22300 (epoch 14.527), train_loss = 0.91563261, grad/param norm = 2.9286e-01, time/batch = 17.6386s	
6480/22300 (epoch 14.529), train_loss = 0.75342533, grad/param norm = 2.7642e-01, time/batch = 15.6380s	
6481/22300 (epoch 14.531), train_loss = 0.75975732, grad/param norm = 2.5154e-01, time/batch = 15.5011s	
6482/22300 (epoch 14.534), train_loss = 0.69334731, grad/param norm = 2.5938e-01, time/batch = 17.9634s	
6483/22300 (epoch 14.536), train_loss = 0.94884087, grad/param norm = 2.5241e-01, time/batch = 17.1302s	
6484/22300 (epoch 14.538), train_loss = 1.15757118, grad/param norm = 3.0102e-01, time/batch = 15.7701s	
6485/22300 (epoch 14.540), train_loss = 0.86274671, grad/param norm = 2.9088e-01, time/batch = 15.2970s	
6486/22300 (epoch 14.543), train_loss = 0.69361259, grad/param norm = 2.3890e-01, time/batch = 18.2178s	
6487/22300 (epoch 14.545), train_loss = 0.70025975, grad/param norm = 2.8513e-01, time/batch = 17.6323s	
6488/22300 (epoch 14.547), train_loss = 0.64414956, grad/param norm = 2.4844e-01, time/batch = 15.3173s	
6489/22300 (epoch 14.549), train_loss = 0.69732594, grad/param norm = 2.5105e-01, time/batch = 16.6304s	
6490/22300 (epoch 14.552), train_loss = 0.72142422, grad/param norm = 2.4722e-01, time/batch = 18.2298s	
6491/22300 (epoch 14.554), train_loss = 0.80291237, grad/param norm = 2.9324e-01, time/batch = 18.7153s	
6492/22300 (epoch 14.556), train_loss = 1.02042634, grad/param norm = 2.8384e-01, time/batch = 16.2833s	
6493/22300 (epoch 14.558), train_loss = 0.90779609, grad/param norm = 3.0528e-01, time/batch = 17.4821s	
6494/22300 (epoch 14.561), train_loss = 1.04609603, grad/param norm = 3.1415e-01, time/batch = 15.2526s	
6495/22300 (epoch 14.563), train_loss = 0.89807849, grad/param norm = 2.6973e-01, time/batch = 17.8658s	
6496/22300 (epoch 14.565), train_loss = 0.75962838, grad/param norm = 2.8810e-01, time/batch = 15.6075s	
6497/22300 (epoch 14.567), train_loss = 0.76163531, grad/param norm = 2.4929e-01, time/batch = 17.2246s	
6498/22300 (epoch 14.570), train_loss = 1.04899685, grad/param norm = 3.0800e-01, time/batch = 16.5463s	
6499/22300 (epoch 14.572), train_loss = 0.88636462, grad/param norm = 2.6249e-01, time/batch = 16.3764s	
6500/22300 (epoch 14.574), train_loss = 0.79826499, grad/param norm = 2.2973e-01, time/batch = 15.5428s	
6501/22300 (epoch 14.576), train_loss = 0.67512906, grad/param norm = 2.1123e-01, time/batch = 16.1413s	
6502/22300 (epoch 14.578), train_loss = 0.51617554, grad/param norm = 2.1161e-01, time/batch = 16.9530s	
6503/22300 (epoch 14.581), train_loss = 0.66280683, grad/param norm = 2.5510e-01, time/batch = 15.0414s	
6504/22300 (epoch 14.583), train_loss = 0.67299050, grad/param norm = 2.5152e-01, time/batch = 17.8675s	
6505/22300 (epoch 14.585), train_loss = 0.98695327, grad/param norm = 3.0176e-01, time/batch = 16.4855s	
6506/22300 (epoch 14.587), train_loss = 1.08389876, grad/param norm = 3.1262e-01, time/batch = 17.1397s	
6507/22300 (epoch 14.590), train_loss = 1.00914349, grad/param norm = 3.2595e-01, time/batch = 15.6479s	
6508/22300 (epoch 14.592), train_loss = 1.09722975, grad/param norm = 2.8572e-01, time/batch = 16.4816s	
6509/22300 (epoch 14.594), train_loss = 1.07192921, grad/param norm = 2.7504e-01, time/batch = 18.2975s	
6510/22300 (epoch 14.596), train_loss = 0.73658641, grad/param norm = 2.5829e-01, time/batch = 27.2407s	
6511/22300 (epoch 14.599), train_loss = 0.63663222, grad/param norm = 2.3193e-01, time/batch = 16.2078s	
6512/22300 (epoch 14.601), train_loss = 0.75509095, grad/param norm = 2.4245e-01, time/batch = 15.5145s	
6513/22300 (epoch 14.603), train_loss = 0.81269522, grad/param norm = 2.7038e-01, time/batch = 15.1834s	
6514/22300 (epoch 14.605), train_loss = 0.74249138, grad/param norm = 2.5109e-01, time/batch = 14.8239s	
6515/22300 (epoch 14.608), train_loss = 1.05892479, grad/param norm = 2.8718e-01, time/batch = 15.8991s	
6516/22300 (epoch 14.610), train_loss = 1.10504523, grad/param norm = 3.1881e-01, time/batch = 15.4843s	
6517/22300 (epoch 14.612), train_loss = 0.94678274, grad/param norm = 3.2167e-01, time/batch = 15.1234s	
6518/22300 (epoch 14.614), train_loss = 0.96223540, grad/param norm = 2.9364e-01, time/batch = 15.3057s	
6519/22300 (epoch 14.617), train_loss = 0.90352669, grad/param norm = 2.6729e-01, time/batch = 17.3130s	
6520/22300 (epoch 14.619), train_loss = 1.12763996, grad/param norm = 3.1173e-01, time/batch = 17.6323s	
6521/22300 (epoch 14.621), train_loss = 0.78423505, grad/param norm = 2.5229e-01, time/batch = 15.3736s	
6522/22300 (epoch 14.623), train_loss = 0.75702114, grad/param norm = 2.3652e-01, time/batch = 17.8017s	
6523/22300 (epoch 14.626), train_loss = 0.70211664, grad/param norm = 1.9853e-01, time/batch = 16.0351s	
6524/22300 (epoch 14.628), train_loss = 0.71571018, grad/param norm = 2.2831e-01, time/batch = 15.9581s	
6525/22300 (epoch 14.630), train_loss = 0.78882206, grad/param norm = 2.3890e-01, time/batch = 15.6453s	
6526/22300 (epoch 14.632), train_loss = 0.79276110, grad/param norm = 2.6194e-01, time/batch = 16.8967s	
6527/22300 (epoch 14.635), train_loss = 0.77152941, grad/param norm = 2.4260e-01, time/batch = 16.7294s	
6528/22300 (epoch 14.637), train_loss = 0.96522972, grad/param norm = 2.8204e-01, time/batch = 16.2065s	
6529/22300 (epoch 14.639), train_loss = 0.97796450, grad/param norm = 3.3287e-01, time/batch = 15.4007s	
6530/22300 (epoch 14.641), train_loss = 0.85396318, grad/param norm = 2.8238e-01, time/batch = 16.0781s	
6531/22300 (epoch 14.643), train_loss = 0.78485780, grad/param norm = 2.7394e-01, time/batch = 16.4649s	
6532/22300 (epoch 14.646), train_loss = 0.71596112, grad/param norm = 2.4566e-01, time/batch = 14.8922s	
6533/22300 (epoch 14.648), train_loss = 0.76273872, grad/param norm = 2.6389e-01, time/batch = 17.9731s	
6534/22300 (epoch 14.650), train_loss = 0.89567739, grad/param norm = 2.6444e-01, time/batch = 18.1345s	
6535/22300 (epoch 14.652), train_loss = 0.74821560, grad/param norm = 2.3276e-01, time/batch = 15.1276s	
6536/22300 (epoch 14.655), train_loss = 0.80488415, grad/param norm = 3.1370e-01, time/batch = 16.3639s	
6537/22300 (epoch 14.657), train_loss = 0.83757610, grad/param norm = 2.6280e-01, time/batch = 17.1407s	
6538/22300 (epoch 14.659), train_loss = 0.72342990, grad/param norm = 2.6551e-01, time/batch = 17.2882s	
6539/22300 (epoch 14.661), train_loss = 0.61719827, grad/param norm = 2.3308e-01, time/batch = 17.3754s	
6540/22300 (epoch 14.664), train_loss = 0.74533131, grad/param norm = 2.3550e-01, time/batch = 16.1033s	
6541/22300 (epoch 14.666), train_loss = 0.86171910, grad/param norm = 2.7284e-01, time/batch = 16.1225s	
6542/22300 (epoch 14.668), train_loss = 0.70214791, grad/param norm = 2.2069e-01, time/batch = 16.1474s	
6543/22300 (epoch 14.670), train_loss = 0.88669517, grad/param norm = 2.8460e-01, time/batch = 15.4611s	
6544/22300 (epoch 14.673), train_loss = 0.90460329, grad/param norm = 2.9574e-01, time/batch = 15.2754s	
6545/22300 (epoch 14.675), train_loss = 1.01364722, grad/param norm = 3.0475e-01, time/batch = 14.8427s	
6546/22300 (epoch 14.677), train_loss = 1.02410233, grad/param norm = 3.0839e-01, time/batch = 15.3378s	
6547/22300 (epoch 14.679), train_loss = 0.92932394, grad/param norm = 3.3750e-01, time/batch = 15.0280s	
6548/22300 (epoch 14.682), train_loss = 0.87812517, grad/param norm = 2.8204e-01, time/batch = 14.8385s	
6549/22300 (epoch 14.684), train_loss = 0.88771104, grad/param norm = 2.6328e-01, time/batch = 15.0124s	
6550/22300 (epoch 14.686), train_loss = 0.86157491, grad/param norm = 2.8967e-01, time/batch = 16.8559s	
6551/22300 (epoch 14.688), train_loss = 0.82912426, grad/param norm = 2.8031e-01, time/batch = 16.4482s	
6552/22300 (epoch 14.691), train_loss = 0.77222528, grad/param norm = 2.5651e-01, time/batch = 15.4886s	
6553/22300 (epoch 14.693), train_loss = 0.77005376, grad/param norm = 2.8811e-01, time/batch = 17.9633s	
6554/22300 (epoch 14.695), train_loss = 0.64508579, grad/param norm = 2.2350e-01, time/batch = 16.2183s	
6555/22300 (epoch 14.697), train_loss = 0.67492823, grad/param norm = 2.3786e-01, time/batch = 15.8518s	
6556/22300 (epoch 14.700), train_loss = 0.74005011, grad/param norm = 2.8202e-01, time/batch = 16.4036s	
6557/22300 (epoch 14.702), train_loss = 0.76403323, grad/param norm = 2.2987e-01, time/batch = 16.8757s	
6558/22300 (epoch 14.704), train_loss = 0.87894924, grad/param norm = 2.8224e-01, time/batch = 16.8931s	
6559/22300 (epoch 14.706), train_loss = 0.71579191, grad/param norm = 2.4734e-01, time/batch = 15.8888s	
6560/22300 (epoch 14.709), train_loss = 0.64235401, grad/param norm = 2.3245e-01, time/batch = 17.6176s	
6561/22300 (epoch 14.711), train_loss = 0.65830417, grad/param norm = 2.2866e-01, time/batch = 15.4543s	
6562/22300 (epoch 14.713), train_loss = 0.83689625, grad/param norm = 2.4157e-01, time/batch = 15.9715s	
6563/22300 (epoch 14.715), train_loss = 0.82558208, grad/param norm = 2.6910e-01, time/batch = 16.4021s	
6564/22300 (epoch 14.717), train_loss = 1.01961920, grad/param norm = 2.9322e-01, time/batch = 18.4436s	
6565/22300 (epoch 14.720), train_loss = 0.74986635, grad/param norm = 2.6686e-01, time/batch = 17.5482s	
6566/22300 (epoch 14.722), train_loss = 0.83772681, grad/param norm = 2.6451e-01, time/batch = 18.1343s	
6567/22300 (epoch 14.724), train_loss = 0.87517519, grad/param norm = 2.8864e-01, time/batch = 17.9713s	
6568/22300 (epoch 14.726), train_loss = 0.77650187, grad/param norm = 2.7465e-01, time/batch = 15.5266s	
6569/22300 (epoch 14.729), train_loss = 0.81911934, grad/param norm = 2.5127e-01, time/batch = 19.1192s	
6570/22300 (epoch 14.731), train_loss = 1.01018914, grad/param norm = 3.1245e-01, time/batch = 16.0532s	
6571/22300 (epoch 14.733), train_loss = 0.98372046, grad/param norm = 2.9968e-01, time/batch = 17.2853s	
6572/22300 (epoch 14.735), train_loss = 1.02335056, grad/param norm = 3.3924e-01, time/batch = 17.1187s	
6573/22300 (epoch 14.738), train_loss = 0.88084719, grad/param norm = 3.3259e-01, time/batch = 18.2136s	
6574/22300 (epoch 14.740), train_loss = 0.68260814, grad/param norm = 2.6001e-01, time/batch = 17.8870s	
6575/22300 (epoch 14.742), train_loss = 0.79982346, grad/param norm = 2.4973e-01, time/batch = 15.6755s	
6576/22300 (epoch 14.744), train_loss = 1.10814777, grad/param norm = 3.0542e-01, time/batch = 17.8912s	
6577/22300 (epoch 14.747), train_loss = 0.86759248, grad/param norm = 2.4743e-01, time/batch = 15.8939s	
6578/22300 (epoch 14.749), train_loss = 1.17565477, grad/param norm = 3.2327e-01, time/batch = 17.2022s	
6579/22300 (epoch 14.751), train_loss = 1.01803926, grad/param norm = 3.6536e-01, time/batch = 16.0633s	
6580/22300 (epoch 14.753), train_loss = 1.03251203, grad/param norm = 3.0167e-01, time/batch = 17.9735s	
6581/22300 (epoch 14.756), train_loss = 0.87867852, grad/param norm = 2.6615e-01, time/batch = 17.1265s	
6582/22300 (epoch 14.758), train_loss = 0.88401631, grad/param norm = 2.7861e-01, time/batch = 16.0360s	
6583/22300 (epoch 14.760), train_loss = 0.88834053, grad/param norm = 2.7753e-01, time/batch = 15.7875s	
6584/22300 (epoch 14.762), train_loss = 0.87055891, grad/param norm = 3.1358e-01, time/batch = 15.3303s	
6585/22300 (epoch 14.765), train_loss = 0.88270097, grad/param norm = 2.7513e-01, time/batch = 17.0444s	
6586/22300 (epoch 14.767), train_loss = 0.94287159, grad/param norm = 2.9582e-01, time/batch = 14.8000s	
6587/22300 (epoch 14.769), train_loss = 0.86260948, grad/param norm = 3.1371e-01, time/batch = 16.7225s	
6588/22300 (epoch 14.771), train_loss = 0.95176817, grad/param norm = 3.1223e-01, time/batch = 16.0468s	
6589/22300 (epoch 14.774), train_loss = 0.98973763, grad/param norm = 3.6087e-01, time/batch = 16.6079s	
6590/22300 (epoch 14.776), train_loss = 1.01251106, grad/param norm = 2.8586e-01, time/batch = 16.0380s	
6591/22300 (epoch 14.778), train_loss = 1.00891644, grad/param norm = 3.3285e-01, time/batch = 18.6963s	
6592/22300 (epoch 14.780), train_loss = 0.99860301, grad/param norm = 3.1777e-01, time/batch = 18.1271s	
6593/22300 (epoch 14.783), train_loss = 1.05453570, grad/param norm = 3.2718e-01, time/batch = 16.2159s	
6594/22300 (epoch 14.785), train_loss = 0.80256100, grad/param norm = 2.9636e-01, time/batch = 15.2970s	
6595/22300 (epoch 14.787), train_loss = 0.81309913, grad/param norm = 2.5746e-01, time/batch = 17.7178s	
6596/22300 (epoch 14.789), train_loss = 1.01646311, grad/param norm = 2.9629e-01, time/batch = 16.6919s	
6597/22300 (epoch 14.791), train_loss = 1.15593779, grad/param norm = 3.0283e-01, time/batch = 16.8025s	
6598/22300 (epoch 14.794), train_loss = 1.02743728, grad/param norm = 3.3947e-01, time/batch = 17.2136s	
6599/22300 (epoch 14.796), train_loss = 1.02908796, grad/param norm = 2.9709e-01, time/batch = 17.8144s	
6600/22300 (epoch 14.798), train_loss = 1.07521983, grad/param norm = 3.0889e-01, time/batch = 15.6251s	
6601/22300 (epoch 14.800), train_loss = 0.82756031, grad/param norm = 2.5804e-01, time/batch = 16.3884s	
6602/22300 (epoch 14.803), train_loss = 0.75970169, grad/param norm = 2.4195e-01, time/batch = 15.8160s	
6603/22300 (epoch 14.805), train_loss = 0.88908887, grad/param norm = 2.6681e-01, time/batch = 17.1147s	
6604/22300 (epoch 14.807), train_loss = 1.03529092, grad/param norm = 3.0660e-01, time/batch = 15.8901s	
6605/22300 (epoch 14.809), train_loss = 0.86065305, grad/param norm = 2.7862e-01, time/batch = 18.5378s	
6606/22300 (epoch 14.812), train_loss = 0.97179420, grad/param norm = 2.6806e-01, time/batch = 17.1293s	
6607/22300 (epoch 14.814), train_loss = 0.92810674, grad/param norm = 2.8843e-01, time/batch = 16.3732s	
6608/22300 (epoch 14.816), train_loss = 0.97357579, grad/param norm = 2.7887e-01, time/batch = 14.9311s	
6609/22300 (epoch 14.818), train_loss = 1.02590798, grad/param norm = 3.2548e-01, time/batch = 16.8835s	
6610/22300 (epoch 14.821), train_loss = 0.97753028, grad/param norm = 3.3244e-01, time/batch = 18.1275s	
6611/22300 (epoch 14.823), train_loss = 0.70055397, grad/param norm = 2.3410e-01, time/batch = 15.1397s	
6612/22300 (epoch 14.825), train_loss = 0.85951096, grad/param norm = 2.7803e-01, time/batch = 17.1461s	
6613/22300 (epoch 14.827), train_loss = 0.84463312, grad/param norm = 2.8686e-01, time/batch = 17.0602s	
6614/22300 (epoch 14.830), train_loss = 0.79872033, grad/param norm = 2.9846e-01, time/batch = 15.2047s	
6615/22300 (epoch 14.832), train_loss = 0.79670878, grad/param norm = 3.2462e-01, time/batch = 16.9634s	
6616/22300 (epoch 14.834), train_loss = 0.78376245, grad/param norm = 2.7102e-01, time/batch = 17.0697s	
6617/22300 (epoch 14.836), train_loss = 0.85628075, grad/param norm = 2.7095e-01, time/batch = 17.3893s	
6618/22300 (epoch 14.839), train_loss = 0.83002097, grad/param norm = 2.6340e-01, time/batch = 16.0381s	
6619/22300 (epoch 14.841), train_loss = 0.87719129, grad/param norm = 3.0159e-01, time/batch = 16.9728s	
6620/22300 (epoch 14.843), train_loss = 0.84464428, grad/param norm = 2.7805e-01, time/batch = 15.6228s	
6621/22300 (epoch 14.845), train_loss = 0.84758583, grad/param norm = 2.5982e-01, time/batch = 16.9639s	
6622/22300 (epoch 14.848), train_loss = 0.86220072, grad/param norm = 2.6442e-01, time/batch = 14.8937s	
6623/22300 (epoch 14.850), train_loss = 0.85854445, grad/param norm = 2.3942e-01, time/batch = 16.5187s	
6624/22300 (epoch 14.852), train_loss = 0.86280082, grad/param norm = 2.7578e-01, time/batch = 18.4443s	
6625/22300 (epoch 14.854), train_loss = 1.01485158, grad/param norm = 3.0224e-01, time/batch = 15.6422s	
6626/22300 (epoch 14.857), train_loss = 0.86887018, grad/param norm = 3.2022e-01, time/batch = 15.9671s	
6627/22300 (epoch 14.859), train_loss = 0.69032572, grad/param norm = 2.3265e-01, time/batch = 17.0573s	
6628/22300 (epoch 14.861), train_loss = 0.88446003, grad/param norm = 2.6268e-01, time/batch = 17.5524s	
6629/22300 (epoch 14.863), train_loss = 0.71774264, grad/param norm = 2.4000e-01, time/batch = 16.0476s	
6630/22300 (epoch 14.865), train_loss = 0.71537917, grad/param norm = 2.4567e-01, time/batch = 18.3836s	
6631/22300 (epoch 14.868), train_loss = 0.85753588, grad/param norm = 2.5019e-01, time/batch = 19.0393s	
6632/22300 (epoch 14.870), train_loss = 0.90254712, grad/param norm = 2.9861e-01, time/batch = 16.0484s	
6633/22300 (epoch 14.872), train_loss = 0.96457943, grad/param norm = 2.6876e-01, time/batch = 15.7939s	
6634/22300 (epoch 14.874), train_loss = 0.88254360, grad/param norm = 3.1356e-01, time/batch = 14.7298s	
6635/22300 (epoch 14.877), train_loss = 0.88837403, grad/param norm = 2.7303e-01, time/batch = 15.5397s	
6636/22300 (epoch 14.879), train_loss = 0.78084246, grad/param norm = 2.6373e-01, time/batch = 15.4326s	
6637/22300 (epoch 14.881), train_loss = 0.79908486, grad/param norm = 2.6278e-01, time/batch = 15.9136s	
6638/22300 (epoch 14.883), train_loss = 0.75355345, grad/param norm = 2.4857e-01, time/batch = 15.0797s	
6639/22300 (epoch 14.886), train_loss = 0.75699965, grad/param norm = 2.6557e-01, time/batch = 18.1342s	
6640/22300 (epoch 14.888), train_loss = 0.81065149, grad/param norm = 2.6080e-01, time/batch = 15.8591s	
6641/22300 (epoch 14.890), train_loss = 0.75413399, grad/param norm = 2.3110e-01, time/batch = 16.7940s	
6642/22300 (epoch 14.892), train_loss = 1.01733379, grad/param norm = 2.6920e-01, time/batch = 18.1183s	
6643/22300 (epoch 14.895), train_loss = 1.01663845, grad/param norm = 3.1634e-01, time/batch = 15.4779s	
6644/22300 (epoch 14.897), train_loss = 0.88354083, grad/param norm = 3.0936e-01, time/batch = 17.0419s	
6645/22300 (epoch 14.899), train_loss = 0.89853758, grad/param norm = 2.7809e-01, time/batch = 15.8904s	
6646/22300 (epoch 14.901), train_loss = 0.84028539, grad/param norm = 2.7466e-01, time/batch = 18.7976s	
6647/22300 (epoch 14.904), train_loss = 0.94249233, grad/param norm = 2.9408e-01, time/batch = 15.9766s	
6648/22300 (epoch 14.906), train_loss = 0.93581932, grad/param norm = 2.6219e-01, time/batch = 18.5374s	
6649/22300 (epoch 14.908), train_loss = 0.85498660, grad/param norm = 2.6566e-01, time/batch = 16.5626s	
6650/22300 (epoch 14.910), train_loss = 0.71619660, grad/param norm = 2.4547e-01, time/batch = 15.6426s	
6651/22300 (epoch 14.913), train_loss = 0.91782356, grad/param norm = 2.8480e-01, time/batch = 16.9669s	
6652/22300 (epoch 14.915), train_loss = 1.07449979, grad/param norm = 2.9785e-01, time/batch = 17.4797s	
6653/22300 (epoch 14.917), train_loss = 0.85362048, grad/param norm = 2.6511e-01, time/batch = 15.7660s	
6654/22300 (epoch 14.919), train_loss = 0.91151346, grad/param norm = 2.5370e-01, time/batch = 15.9390s	
6655/22300 (epoch 14.922), train_loss = 0.79991716, grad/param norm = 2.4926e-01, time/batch = 15.4542s	
6656/22300 (epoch 14.924), train_loss = 0.61800940, grad/param norm = 2.3975e-01, time/batch = 15.0483s	
6657/22300 (epoch 14.926), train_loss = 0.68396169, grad/param norm = 2.8554e-01, time/batch = 17.0432s	
6658/22300 (epoch 14.928), train_loss = 0.81815852, grad/param norm = 2.5647e-01, time/batch = 16.0327s	
6659/22300 (epoch 14.930), train_loss = 0.81519669, grad/param norm = 2.7554e-01, time/batch = 16.8817s	
6660/22300 (epoch 14.933), train_loss = 0.89779746, grad/param norm = 2.7252e-01, time/batch = 18.7014s	
6661/22300 (epoch 14.935), train_loss = 0.96474315, grad/param norm = 3.0088e-01, time/batch = 17.2924s	
6662/22300 (epoch 14.937), train_loss = 1.03704311, grad/param norm = 2.9804e-01, time/batch = 15.5391s	
6663/22300 (epoch 14.939), train_loss = 0.99384871, grad/param norm = 3.5041e-01, time/batch = 15.1533s	
6664/22300 (epoch 14.942), train_loss = 1.12927282, grad/param norm = 3.5269e-01, time/batch = 18.4511s	
6665/22300 (epoch 14.944), train_loss = 1.15218581, grad/param norm = 3.3984e-01, time/batch = 15.8731s	
6666/22300 (epoch 14.946), train_loss = 0.86985950, grad/param norm = 2.7824e-01, time/batch = 18.6220s	
6667/22300 (epoch 14.948), train_loss = 0.77941826, grad/param norm = 2.4661e-01, time/batch = 16.5546s	
6668/22300 (epoch 14.951), train_loss = 0.71739162, grad/param norm = 2.5015e-01, time/batch = 15.8740s	
6669/22300 (epoch 14.953), train_loss = 0.75330996, grad/param norm = 2.9807e-01, time/batch = 16.7286s	
6670/22300 (epoch 14.955), train_loss = 1.05871738, grad/param norm = 2.9265e-01, time/batch = 18.3795s	
6671/22300 (epoch 14.957), train_loss = 1.19446119, grad/param norm = 3.5093e-01, time/batch = 17.7861s	
6672/22300 (epoch 14.960), train_loss = 1.01456243, grad/param norm = 2.9997e-01, time/batch = 16.6855s	
6673/22300 (epoch 14.962), train_loss = 0.87578269, grad/param norm = 2.8811e-01, time/batch = 17.7036s	
6674/22300 (epoch 14.964), train_loss = 0.84556324, grad/param norm = 2.4517e-01, time/batch = 15.5738s	
6675/22300 (epoch 14.966), train_loss = 0.75519682, grad/param norm = 2.6326e-01, time/batch = 17.2070s	
6676/22300 (epoch 14.969), train_loss = 0.79989969, grad/param norm = 2.3319e-01, time/batch = 15.8132s	
6677/22300 (epoch 14.971), train_loss = 0.84138754, grad/param norm = 2.4320e-01, time/batch = 16.8829s	
6678/22300 (epoch 14.973), train_loss = 0.89766230, grad/param norm = 2.8857e-01, time/batch = 18.2966s	
6679/22300 (epoch 14.975), train_loss = 1.06495659, grad/param norm = 3.6891e-01, time/batch = 17.2940s	
6680/22300 (epoch 14.978), train_loss = 0.93649854, grad/param norm = 3.2591e-01, time/batch = 15.9585s	
6681/22300 (epoch 14.980), train_loss = 0.99388139, grad/param norm = 3.4245e-01, time/batch = 17.0259s	
6682/22300 (epoch 14.982), train_loss = 0.78794728, grad/param norm = 2.9851e-01, time/batch = 14.7829s	
6683/22300 (epoch 14.984), train_loss = 0.88863868, grad/param norm = 2.6822e-01, time/batch = 15.6499s	
6684/22300 (epoch 14.987), train_loss = 0.80714951, grad/param norm = 2.6680e-01, time/batch = 17.3881s	
6685/22300 (epoch 14.989), train_loss = 0.85475123, grad/param norm = 2.5988e-01, time/batch = 15.4542s	
6686/22300 (epoch 14.991), train_loss = 1.11252458, grad/param norm = 3.1364e-01, time/batch = 16.0350s	
6687/22300 (epoch 14.993), train_loss = 1.28807303, grad/param norm = 3.6293e-01, time/batch = 16.5579s	
6688/22300 (epoch 14.996), train_loss = 1.18220345, grad/param norm = 3.5809e-01, time/batch = 16.3969s	
6689/22300 (epoch 14.998), train_loss = 0.87689501, grad/param norm = 2.7451e-01, time/batch = 17.7129s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
6690/22300 (epoch 15.000), train_loss = 0.75977414, grad/param norm = 2.7932e-01, time/batch = 15.4001s	
6691/22300 (epoch 15.002), train_loss = 1.10878776, grad/param norm = 2.9781e-01, time/batch = 15.4770s	
6692/22300 (epoch 15.004), train_loss = 0.85952345, grad/param norm = 2.5644e-01, time/batch = 14.5758s	
6693/22300 (epoch 15.007), train_loss = 0.88626107, grad/param norm = 2.9955e-01, time/batch = 16.8812s	
6694/22300 (epoch 15.009), train_loss = 0.89874008, grad/param norm = 2.7702e-01, time/batch = 15.8762s	
6695/22300 (epoch 15.011), train_loss = 1.09401473, grad/param norm = 3.1745e-01, time/batch = 18.2192s	
6696/22300 (epoch 15.013), train_loss = 0.85736639, grad/param norm = 2.7347e-01, time/batch = 18.2856s	
6697/22300 (epoch 15.016), train_loss = 0.78001587, grad/param norm = 2.7363e-01, time/batch = 15.3114s	
6698/22300 (epoch 15.018), train_loss = 0.98795938, grad/param norm = 3.0534e-01, time/batch = 15.1125s	
6699/22300 (epoch 15.020), train_loss = 0.82824305, grad/param norm = 3.0431e-01, time/batch = 17.2292s	
6700/22300 (epoch 15.022), train_loss = 0.76854929, grad/param norm = 2.5558e-01, time/batch = 16.1392s	
6701/22300 (epoch 15.025), train_loss = 0.76448833, grad/param norm = 2.5022e-01, time/batch = 16.5529s	
6702/22300 (epoch 15.027), train_loss = 0.80986611, grad/param norm = 2.4038e-01, time/batch = 17.9647s	
6703/22300 (epoch 15.029), train_loss = 0.77757146, grad/param norm = 2.4929e-01, time/batch = 17.0496s	
6704/22300 (epoch 15.031), train_loss = 0.76151098, grad/param norm = 2.3006e-01, time/batch = 14.8557s	
6705/22300 (epoch 15.034), train_loss = 0.78393225, grad/param norm = 2.4322e-01, time/batch = 15.6508s	
6706/22300 (epoch 15.036), train_loss = 0.61330723, grad/param norm = 2.3353e-01, time/batch = 17.4644s	
6707/22300 (epoch 15.038), train_loss = 0.76544625, grad/param norm = 2.4552e-01, time/batch = 18.5395s	
6708/22300 (epoch 15.040), train_loss = 0.82787785, grad/param norm = 2.6256e-01, time/batch = 16.4455s	
6709/22300 (epoch 15.043), train_loss = 1.10301756, grad/param norm = 3.0194e-01, time/batch = 17.2229s	
6710/22300 (epoch 15.045), train_loss = 0.89860505, grad/param norm = 2.6736e-01, time/batch = 15.4821s	
6711/22300 (epoch 15.047), train_loss = 0.99000787, grad/param norm = 2.9341e-01, time/batch = 17.2049s	
6712/22300 (epoch 15.049), train_loss = 0.83122314, grad/param norm = 2.8530e-01, time/batch = 15.5614s	
6713/22300 (epoch 15.052), train_loss = 0.90808759, grad/param norm = 3.2239e-01, time/batch = 17.7900s	
6714/22300 (epoch 15.054), train_loss = 0.92978452, grad/param norm = 2.9702e-01, time/batch = 18.3787s	
6715/22300 (epoch 15.056), train_loss = 0.60589012, grad/param norm = 2.3326e-01, time/batch = 16.0551s	
6716/22300 (epoch 15.058), train_loss = 0.75556782, grad/param norm = 2.4602e-01, time/batch = 16.0428s	
6717/22300 (epoch 15.061), train_loss = 0.73132482, grad/param norm = 2.5499e-01, time/batch = 14.7083s	
6718/22300 (epoch 15.063), train_loss = 1.03295134, grad/param norm = 3.5690e-01, time/batch = 15.6705s	
6719/22300 (epoch 15.065), train_loss = 0.96278019, grad/param norm = 2.9808e-01, time/batch = 15.4002s	
6720/22300 (epoch 15.067), train_loss = 0.78777011, grad/param norm = 2.6988e-01, time/batch = 17.8840s	
6721/22300 (epoch 15.070), train_loss = 0.83677020, grad/param norm = 2.4464e-01, time/batch = 17.6346s	
6722/22300 (epoch 15.072), train_loss = 0.93204770, grad/param norm = 3.0194e-01, time/batch = 17.6197s	
6723/22300 (epoch 15.074), train_loss = 0.91290687, grad/param norm = 3.0984e-01, time/batch = 16.0151s	
6724/22300 (epoch 15.076), train_loss = 0.86873691, grad/param norm = 2.9811e-01, time/batch = 18.4546s	
6725/22300 (epoch 15.078), train_loss = 0.94696270, grad/param norm = 2.7109e-01, time/batch = 16.6832s	
6726/22300 (epoch 15.081), train_loss = 0.96177430, grad/param norm = 3.1152e-01, time/batch = 30.6203s	
6727/22300 (epoch 15.083), train_loss = 1.06222884, grad/param norm = 2.9459e-01, time/batch = 16.3237s	
6728/22300 (epoch 15.085), train_loss = 1.12554298, grad/param norm = 3.5632e-01, time/batch = 15.4613s	
6729/22300 (epoch 15.087), train_loss = 0.92145728, grad/param norm = 2.6886e-01, time/batch = 17.3008s	
6730/22300 (epoch 15.090), train_loss = 0.75897679, grad/param norm = 2.3297e-01, time/batch = 17.8686s	
6731/22300 (epoch 15.092), train_loss = 0.74588454, grad/param norm = 2.8127e-01, time/batch = 16.0628s	
6732/22300 (epoch 15.094), train_loss = 0.73186167, grad/param norm = 2.5034e-01, time/batch = 16.0362s	
6733/22300 (epoch 15.096), train_loss = 1.03919757, grad/param norm = 2.7720e-01, time/batch = 15.2350s	
6734/22300 (epoch 15.099), train_loss = 0.80336259, grad/param norm = 2.4213e-01, time/batch = 17.4813s	
6735/22300 (epoch 15.101), train_loss = 0.95433661, grad/param norm = 2.8473e-01, time/batch = 17.3693s	
6736/22300 (epoch 15.103), train_loss = 0.86508943, grad/param norm = 2.6270e-01, time/batch = 17.9579s	
6737/22300 (epoch 15.105), train_loss = 0.82258863, grad/param norm = 2.8208e-01, time/batch = 17.4492s	
6738/22300 (epoch 15.108), train_loss = 0.88980652, grad/param norm = 2.5090e-01, time/batch = 17.2979s	
6739/22300 (epoch 15.110), train_loss = 0.89245686, grad/param norm = 2.5597e-01, time/batch = 15.4640s	
6740/22300 (epoch 15.112), train_loss = 0.85369203, grad/param norm = 2.5269e-01, time/batch = 16.6366s	
6741/22300 (epoch 15.114), train_loss = 0.94936239, grad/param norm = 2.9908e-01, time/batch = 17.8140s	
6742/22300 (epoch 15.117), train_loss = 1.09741826, grad/param norm = 2.7719e-01, time/batch = 16.6393s	
6743/22300 (epoch 15.119), train_loss = 0.98998009, grad/param norm = 2.5334e-01, time/batch = 17.1368s	
6744/22300 (epoch 15.121), train_loss = 1.03687578, grad/param norm = 2.9832e-01, time/batch = 16.5430s	
6745/22300 (epoch 15.123), train_loss = 0.97577501, grad/param norm = 2.7261e-01, time/batch = 15.7975s	
6746/22300 (epoch 15.126), train_loss = 0.89379054, grad/param norm = 2.6256e-01, time/batch = 16.4589s	
6747/22300 (epoch 15.128), train_loss = 0.97763836, grad/param norm = 2.6486e-01, time/batch = 15.5345s	
6748/22300 (epoch 15.130), train_loss = 0.80270714, grad/param norm = 2.6944e-01, time/batch = 18.1320s	
6749/22300 (epoch 15.132), train_loss = 0.69600004, grad/param norm = 2.5364e-01, time/batch = 17.7200s	
6750/22300 (epoch 15.135), train_loss = 0.74170001, grad/param norm = 2.7098e-01, time/batch = 15.2739s	
6751/22300 (epoch 15.137), train_loss = 0.57729975, grad/param norm = 2.1688e-01, time/batch = 16.1393s	
6752/22300 (epoch 15.139), train_loss = 0.93285663, grad/param norm = 2.9662e-01, time/batch = 17.0607s	
6753/22300 (epoch 15.141), train_loss = 0.94490078, grad/param norm = 2.5936e-01, time/batch = 16.3782s	
6754/22300 (epoch 15.143), train_loss = 0.87852940, grad/param norm = 2.6815e-01, time/batch = 16.4526s	
6755/22300 (epoch 15.146), train_loss = 1.00698711, grad/param norm = 2.9209e-01, time/batch = 16.8855s	
6756/22300 (epoch 15.148), train_loss = 0.76542666, grad/param norm = 2.5796e-01, time/batch = 19.5435s	
6757/22300 (epoch 15.150), train_loss = 0.79648955, grad/param norm = 2.5008e-01, time/batch = 15.0190s	
6758/22300 (epoch 15.152), train_loss = 0.70409357, grad/param norm = 2.4603e-01, time/batch = 14.6663s	
6759/22300 (epoch 15.155), train_loss = 0.76557410, grad/param norm = 2.5053e-01, time/batch = 15.5708s	
6760/22300 (epoch 15.157), train_loss = 0.97674859, grad/param norm = 3.1719e-01, time/batch = 15.7742s	
6761/22300 (epoch 15.159), train_loss = 0.91384972, grad/param norm = 2.7408e-01, time/batch = 15.3001s	
6762/22300 (epoch 15.161), train_loss = 0.99754713, grad/param norm = 3.3043e-01, time/batch = 16.6465s	
6763/22300 (epoch 15.164), train_loss = 0.73107768, grad/param norm = 2.3999e-01, time/batch = 16.7249s	
6764/22300 (epoch 15.166), train_loss = 0.70573086, grad/param norm = 2.0630e-01, time/batch = 15.1207s	
6765/22300 (epoch 15.168), train_loss = 0.76396861, grad/param norm = 2.4362e-01, time/batch = 17.0538s	
6766/22300 (epoch 15.170), train_loss = 0.88326435, grad/param norm = 2.5214e-01, time/batch = 16.4692s	
6767/22300 (epoch 15.173), train_loss = 1.03578467, grad/param norm = 2.9369e-01, time/batch = 16.8588s	
6768/22300 (epoch 15.175), train_loss = 0.84580744, grad/param norm = 2.6102e-01, time/batch = 16.8110s	
6769/22300 (epoch 15.177), train_loss = 0.67345898, grad/param norm = 2.3757e-01, time/batch = 15.4593s	
6770/22300 (epoch 15.179), train_loss = 0.81980711, grad/param norm = 2.5030e-01, time/batch = 15.9891s	
6771/22300 (epoch 15.182), train_loss = 1.02291125, grad/param norm = 2.8515e-01, time/batch = 17.7082s	
6772/22300 (epoch 15.184), train_loss = 1.13072489, grad/param norm = 3.0255e-01, time/batch = 16.6429s	
6773/22300 (epoch 15.186), train_loss = 0.92624746, grad/param norm = 2.7433e-01, time/batch = 17.7967s	
6774/22300 (epoch 15.188), train_loss = 1.10260309, grad/param norm = 2.9324e-01, time/batch = 16.7272s	
6775/22300 (epoch 15.191), train_loss = 1.06635366, grad/param norm = 2.6946e-01, time/batch = 15.1958s	
6776/22300 (epoch 15.193), train_loss = 0.89064838, grad/param norm = 2.8719e-01, time/batch = 17.4559s	
6777/22300 (epoch 15.195), train_loss = 0.80192337, grad/param norm = 2.6541e-01, time/batch = 17.4800s	
6778/22300 (epoch 15.197), train_loss = 0.84861566, grad/param norm = 3.2047e-01, time/batch = 17.5387s	
6779/22300 (epoch 15.200), train_loss = 0.74487389, grad/param norm = 2.7191e-01, time/batch = 16.7059s	
6780/22300 (epoch 15.202), train_loss = 0.82660995, grad/param norm = 2.5058e-01, time/batch = 17.5632s	
6781/22300 (epoch 15.204), train_loss = 0.81353572, grad/param norm = 2.5285e-01, time/batch = 16.8836s	
6782/22300 (epoch 15.206), train_loss = 0.73747423, grad/param norm = 2.2335e-01, time/batch = 15.9694s	
6783/22300 (epoch 15.209), train_loss = 0.83401361, grad/param norm = 2.6084e-01, time/batch = 16.3806s	
6784/22300 (epoch 15.211), train_loss = 0.68283246, grad/param norm = 2.5260e-01, time/batch = 16.2989s	
6785/22300 (epoch 15.213), train_loss = 0.80831990, grad/param norm = 2.2982e-01, time/batch = 15.9491s	
6786/22300 (epoch 15.215), train_loss = 1.05248494, grad/param norm = 3.0009e-01, time/batch = 15.3075s	
6787/22300 (epoch 15.217), train_loss = 0.96555760, grad/param norm = 3.0667e-01, time/batch = 16.0632s	
6788/22300 (epoch 15.220), train_loss = 0.85961069, grad/param norm = 2.9258e-01, time/batch = 16.3215s	
6789/22300 (epoch 15.222), train_loss = 0.76283864, grad/param norm = 2.5631e-01, time/batch = 17.4581s	
6790/22300 (epoch 15.224), train_loss = 0.76541803, grad/param norm = 2.3812e-01, time/batch = 15.7294s	
6791/22300 (epoch 15.226), train_loss = 0.80320088, grad/param norm = 2.3269e-01, time/batch = 16.8784s	
6792/22300 (epoch 15.229), train_loss = 0.78665499, grad/param norm = 2.7626e-01, time/batch = 16.6277s	
6793/22300 (epoch 15.231), train_loss = 0.95781994, grad/param norm = 3.1391e-01, time/batch = 16.0438s	
6794/22300 (epoch 15.233), train_loss = 0.89103466, grad/param norm = 2.6260e-01, time/batch = 15.6550s	
6795/22300 (epoch 15.235), train_loss = 0.68709192, grad/param norm = 2.4454e-01, time/batch = 17.0539s	
6796/22300 (epoch 15.238), train_loss = 0.69583653, grad/param norm = 2.2669e-01, time/batch = 17.0525s	
6797/22300 (epoch 15.240), train_loss = 0.71243160, grad/param norm = 2.4187e-01, time/batch = 17.4400s	
6798/22300 (epoch 15.242), train_loss = 0.71311113, grad/param norm = 2.4326e-01, time/batch = 15.9636s	
6799/22300 (epoch 15.244), train_loss = 0.56726069, grad/param norm = 2.4357e-01, time/batch = 15.4771s	
6800/22300 (epoch 15.247), train_loss = 0.73622640, grad/param norm = 2.9485e-01, time/batch = 15.7113s	
6801/22300 (epoch 15.249), train_loss = 0.58826091, grad/param norm = 2.5715e-01, time/batch = 15.4455s	
6802/22300 (epoch 15.251), train_loss = 0.71911985, grad/param norm = 2.4764e-01, time/batch = 17.3823s	
6803/22300 (epoch 15.253), train_loss = 0.59102733, grad/param norm = 2.1255e-01, time/batch = 17.7989s	
6804/22300 (epoch 15.256), train_loss = 0.69989034, grad/param norm = 2.1459e-01, time/batch = 15.0663s	
6805/22300 (epoch 15.258), train_loss = 0.98943450, grad/param norm = 2.9766e-01, time/batch = 16.2943s	
6806/22300 (epoch 15.260), train_loss = 0.83516090, grad/param norm = 2.7503e-01, time/batch = 16.8861s	
6807/22300 (epoch 15.262), train_loss = 0.72365029, grad/param norm = 2.6091e-01, time/batch = 18.2122s	
6808/22300 (epoch 15.265), train_loss = 0.71378414, grad/param norm = 2.5835e-01, time/batch = 17.6363s	
6809/22300 (epoch 15.267), train_loss = 0.76245569, grad/param norm = 2.3852e-01, time/batch = 16.4508s	
6810/22300 (epoch 15.269), train_loss = 0.83699368, grad/param norm = 3.0993e-01, time/batch = 17.4585s	
6811/22300 (epoch 15.271), train_loss = 0.81531204, grad/param norm = 2.4609e-01, time/batch = 15.2302s	
6812/22300 (epoch 15.274), train_loss = 0.64821009, grad/param norm = 2.3913e-01, time/batch = 18.3065s	
6813/22300 (epoch 15.276), train_loss = 0.60313262, grad/param norm = 2.1486e-01, time/batch = 16.3104s	
6814/22300 (epoch 15.278), train_loss = 0.56178218, grad/param norm = 2.1361e-01, time/batch = 17.8741s	
6815/22300 (epoch 15.280), train_loss = 0.71501516, grad/param norm = 2.5083e-01, time/batch = 16.3780s	
6816/22300 (epoch 15.283), train_loss = 0.53456988, grad/param norm = 1.7391e-01, time/batch = 17.4801s	
6817/22300 (epoch 15.285), train_loss = 0.72069915, grad/param norm = 2.5908e-01, time/batch = 15.4703s	
6818/22300 (epoch 15.287), train_loss = 0.83645362, grad/param norm = 2.5388e-01, time/batch = 16.1251s	
6819/22300 (epoch 15.289), train_loss = 0.72308004, grad/param norm = 2.3311e-01, time/batch = 16.5462s	
6820/22300 (epoch 15.291), train_loss = 0.75753999, grad/param norm = 2.4979e-01, time/batch = 17.3911s	
6821/22300 (epoch 15.294), train_loss = 0.65687750, grad/param norm = 2.3242e-01, time/batch = 17.7103s	
6822/22300 (epoch 15.296), train_loss = 0.86857117, grad/param norm = 2.7520e-01, time/batch = 17.7999s	
6823/22300 (epoch 15.298), train_loss = 0.93247317, grad/param norm = 2.7689e-01, time/batch = 15.1982s	
6824/22300 (epoch 15.300), train_loss = 0.98069821, grad/param norm = 2.9930e-01, time/batch = 16.6387s	
6825/22300 (epoch 15.303), train_loss = 0.76687620, grad/param norm = 2.3890e-01, time/batch = 15.4585s	
6826/22300 (epoch 15.305), train_loss = 0.80437097, grad/param norm = 2.7965e-01, time/batch = 17.0483s	
6827/22300 (epoch 15.307), train_loss = 0.75249666, grad/param norm = 2.5453e-01, time/batch = 15.0441s	
6828/22300 (epoch 15.309), train_loss = 0.72352784, grad/param norm = 2.8506e-01, time/batch = 18.7829s	
6829/22300 (epoch 15.312), train_loss = 0.68419792, grad/param norm = 2.5072e-01, time/batch = 14.9684s	
6830/22300 (epoch 15.314), train_loss = 0.71948522, grad/param norm = 2.4852e-01, time/batch = 19.1294s	
6831/22300 (epoch 15.316), train_loss = 0.74656932, grad/param norm = 2.7444e-01, time/batch = 16.7335s	
6832/22300 (epoch 15.318), train_loss = 0.79282893, grad/param norm = 2.4234e-01, time/batch = 15.7871s	
6833/22300 (epoch 15.321), train_loss = 0.87476311, grad/param norm = 2.5441e-01, time/batch = 16.2169s	
6834/22300 (epoch 15.323), train_loss = 0.71097074, grad/param norm = 2.3474e-01, time/batch = 15.6517s	
6835/22300 (epoch 15.325), train_loss = 0.66068431, grad/param norm = 2.3494e-01, time/batch = 16.6542s	
6836/22300 (epoch 15.327), train_loss = 0.69222803, grad/param norm = 2.4328e-01, time/batch = 17.2157s	
6837/22300 (epoch 15.330), train_loss = 0.73235379, grad/param norm = 2.9462e-01, time/batch = 15.2880s	
6838/22300 (epoch 15.332), train_loss = 0.71444158, grad/param norm = 2.9870e-01, time/batch = 17.0535s	
6839/22300 (epoch 15.334), train_loss = 0.69174666, grad/param norm = 2.7762e-01, time/batch = 16.5519s	
6840/22300 (epoch 15.336), train_loss = 0.73102625, grad/param norm = 2.2368e-01, time/batch = 14.7385s	
6841/22300 (epoch 15.339), train_loss = 0.79715695, grad/param norm = 2.8001e-01, time/batch = 16.3052s	
6842/22300 (epoch 15.341), train_loss = 0.87970107, grad/param norm = 3.0936e-01, time/batch = 17.4728s	
6843/22300 (epoch 15.343), train_loss = 0.93433406, grad/param norm = 2.7958e-01, time/batch = 17.6263s	
6844/22300 (epoch 15.345), train_loss = 0.77890367, grad/param norm = 2.6068e-01, time/batch = 16.1293s	
6845/22300 (epoch 15.348), train_loss = 0.77289592, grad/param norm = 2.4569e-01, time/batch = 15.9606s	
6846/22300 (epoch 15.350), train_loss = 0.64172621, grad/param norm = 2.1949e-01, time/batch = 15.8856s	
6847/22300 (epoch 15.352), train_loss = 0.87660331, grad/param norm = 2.6339e-01, time/batch = 15.7908s	
6848/22300 (epoch 15.354), train_loss = 1.04060816, grad/param norm = 3.0426e-01, time/batch = 17.3009s	
6849/22300 (epoch 15.357), train_loss = 0.90515725, grad/param norm = 2.5210e-01, time/batch = 16.9646s	
6850/22300 (epoch 15.359), train_loss = 0.72341178, grad/param norm = 2.6372e-01, time/batch = 14.2569s	
6851/22300 (epoch 15.361), train_loss = 0.73930539, grad/param norm = 2.8664e-01, time/batch = 6.9414s	
6852/22300 (epoch 15.363), train_loss = 0.96475417, grad/param norm = 2.8309e-01, time/batch = 0.6417s	
6853/22300 (epoch 15.365), train_loss = 0.81729518, grad/param norm = 3.0555e-01, time/batch = 0.6509s	
6854/22300 (epoch 15.368), train_loss = 0.82089325, grad/param norm = 3.2139e-01, time/batch = 0.6441s	
6855/22300 (epoch 15.370), train_loss = 0.81167334, grad/param norm = 2.8089e-01, time/batch = 0.6594s	
6856/22300 (epoch 15.372), train_loss = 0.65998110, grad/param norm = 2.7531e-01, time/batch = 0.6586s	
6857/22300 (epoch 15.374), train_loss = 0.59905944, grad/param norm = 2.3517e-01, time/batch = 0.6591s	
6858/22300 (epoch 15.377), train_loss = 0.76803272, grad/param norm = 2.6934e-01, time/batch = 0.6600s	
6859/22300 (epoch 15.379), train_loss = 0.75012087, grad/param norm = 2.5381e-01, time/batch = 0.9487s	
6860/22300 (epoch 15.381), train_loss = 0.90272231, grad/param norm = 2.7229e-01, time/batch = 0.9727s	
6861/22300 (epoch 15.383), train_loss = 0.76367243, grad/param norm = 2.8096e-01, time/batch = 0.9844s	
6862/22300 (epoch 15.386), train_loss = 0.76982944, grad/param norm = 2.6755e-01, time/batch = 0.9988s	
6863/22300 (epoch 15.388), train_loss = 0.69858008, grad/param norm = 2.6238e-01, time/batch = 0.9766s	
6864/22300 (epoch 15.390), train_loss = 0.82032763, grad/param norm = 2.7667e-01, time/batch = 1.7182s	
6865/22300 (epoch 15.392), train_loss = 0.75426081, grad/param norm = 2.5827e-01, time/batch = 1.8237s	
6866/22300 (epoch 15.395), train_loss = 0.66702461, grad/param norm = 2.5919e-01, time/batch = 3.2553s	
6867/22300 (epoch 15.397), train_loss = 0.47868717, grad/param norm = 2.0871e-01, time/batch = 16.6398s	
6868/22300 (epoch 15.399), train_loss = 0.65401987, grad/param norm = 2.7522e-01, time/batch = 18.2259s	
6869/22300 (epoch 15.401), train_loss = 0.75836020, grad/param norm = 2.8650e-01, time/batch = 15.8849s	
6870/22300 (epoch 15.404), train_loss = 0.72675048, grad/param norm = 2.8095e-01, time/batch = 17.0684s	
6871/22300 (epoch 15.406), train_loss = 1.02770258, grad/param norm = 3.1283e-01, time/batch = 16.2245s	
6872/22300 (epoch 15.408), train_loss = 0.88464588, grad/param norm = 2.6886e-01, time/batch = 16.7088s	
6873/22300 (epoch 15.410), train_loss = 0.87343334, grad/param norm = 2.7603e-01, time/batch = 16.4429s	
6874/22300 (epoch 15.413), train_loss = 0.73468812, grad/param norm = 2.3275e-01, time/batch = 16.3773s	
6875/22300 (epoch 15.415), train_loss = 0.63396868, grad/param norm = 2.4910e-01, time/batch = 16.3050s	
6876/22300 (epoch 15.417), train_loss = 0.81252035, grad/param norm = 2.5854e-01, time/batch = 16.0548s	
6877/22300 (epoch 15.419), train_loss = 0.73311135, grad/param norm = 2.3582e-01, time/batch = 18.2965s	
6878/22300 (epoch 15.422), train_loss = 0.71961952, grad/param norm = 2.6978e-01, time/batch = 16.1313s	
6879/22300 (epoch 15.424), train_loss = 0.80657239, grad/param norm = 2.6746e-01, time/batch = 17.4365s	
6880/22300 (epoch 15.426), train_loss = 0.67932330, grad/param norm = 2.9180e-01, time/batch = 16.7229s	
6881/22300 (epoch 15.428), train_loss = 0.70967740, grad/param norm = 2.6006e-01, time/batch = 15.7874s	
6882/22300 (epoch 15.430), train_loss = 0.77486264, grad/param norm = 2.9972e-01, time/batch = 16.9447s	
6883/22300 (epoch 15.433), train_loss = 0.74853408, grad/param norm = 2.6680e-01, time/batch = 15.9148s	
6884/22300 (epoch 15.435), train_loss = 0.80280388, grad/param norm = 2.7508e-01, time/batch = 17.7088s	
6885/22300 (epoch 15.437), train_loss = 0.81334391, grad/param norm = 3.0153e-01, time/batch = 16.7222s	
6886/22300 (epoch 15.439), train_loss = 0.84947898, grad/param norm = 3.1827e-01, time/batch = 15.2014s	
6887/22300 (epoch 15.442), train_loss = 0.79560093, grad/param norm = 2.5189e-01, time/batch = 15.3059s	
6888/22300 (epoch 15.444), train_loss = 0.71418230, grad/param norm = 2.2487e-01, time/batch = 15.5633s	
6889/22300 (epoch 15.446), train_loss = 0.64011420, grad/param norm = 2.4656e-01, time/batch = 18.8714s	
6890/22300 (epoch 15.448), train_loss = 0.53060865, grad/param norm = 2.1492e-01, time/batch = 17.3863s	
6891/22300 (epoch 15.451), train_loss = 0.86157726, grad/param norm = 2.6106e-01, time/batch = 17.0359s	
6892/22300 (epoch 15.453), train_loss = 0.72014311, grad/param norm = 2.6333e-01, time/batch = 16.1114s	
6893/22300 (epoch 15.455), train_loss = 0.97035990, grad/param norm = 3.2483e-01, time/batch = 17.4467s	
6894/22300 (epoch 15.457), train_loss = 0.89741864, grad/param norm = 2.6744e-01, time/batch = 14.7197s	
6895/22300 (epoch 15.460), train_loss = 0.83800491, grad/param norm = 2.8319e-01, time/batch = 17.4543s	
6896/22300 (epoch 15.462), train_loss = 0.91620137, grad/param norm = 2.5467e-01, time/batch = 16.6241s	
6897/22300 (epoch 15.464), train_loss = 0.82858912, grad/param norm = 2.8555e-01, time/batch = 17.9502s	
6898/22300 (epoch 15.466), train_loss = 0.74315929, grad/param norm = 2.3109e-01, time/batch = 16.3919s	
6899/22300 (epoch 15.469), train_loss = 0.70309507, grad/param norm = 2.2538e-01, time/batch = 16.7230s	
6900/22300 (epoch 15.471), train_loss = 0.86646054, grad/param norm = 2.6103e-01, time/batch = 17.2232s	
6901/22300 (epoch 15.473), train_loss = 0.84746824, grad/param norm = 2.5134e-01, time/batch = 15.6332s	
6902/22300 (epoch 15.475), train_loss = 0.72535302, grad/param norm = 3.1866e-01, time/batch = 15.9478s	
6903/22300 (epoch 15.478), train_loss = 0.77573683, grad/param norm = 3.0700e-01, time/batch = 14.9024s	
6904/22300 (epoch 15.480), train_loss = 0.56655463, grad/param norm = 2.1642e-01, time/batch = 18.7784s	
6905/22300 (epoch 15.482), train_loss = 0.61617264, grad/param norm = 2.1904e-01, time/batch = 16.2274s	
6906/22300 (epoch 15.484), train_loss = 0.75090344, grad/param norm = 2.5500e-01, time/batch = 15.7862s	
6907/22300 (epoch 15.487), train_loss = 0.80712902, grad/param norm = 2.4173e-01, time/batch = 15.7130s	
6908/22300 (epoch 15.489), train_loss = 0.84671394, grad/param norm = 2.6708e-01, time/batch = 16.9604s	
6909/22300 (epoch 15.491), train_loss = 0.83731959, grad/param norm = 2.6561e-01, time/batch = 16.0432s	
6910/22300 (epoch 15.493), train_loss = 0.82098379, grad/param norm = 2.8012e-01, time/batch = 15.1180s	
6911/22300 (epoch 15.496), train_loss = 0.71832220, grad/param norm = 2.3159e-01, time/batch = 17.7166s	
6912/22300 (epoch 15.498), train_loss = 0.64770505, grad/param norm = 2.5129e-01, time/batch = 15.3922s	
6913/22300 (epoch 15.500), train_loss = 0.78641417, grad/param norm = 2.4879e-01, time/batch = 16.0151s	
6914/22300 (epoch 15.502), train_loss = 0.59468608, grad/param norm = 2.7320e-01, time/batch = 17.4680s	
6915/22300 (epoch 15.504), train_loss = 0.62162120, grad/param norm = 2.2956e-01, time/batch = 18.5259s	
6916/22300 (epoch 15.507), train_loss = 0.69629485, grad/param norm = 2.7128e-01, time/batch = 15.1222s	
6917/22300 (epoch 15.509), train_loss = 0.83415033, grad/param norm = 2.7449e-01, time/batch = 18.2964s	
6918/22300 (epoch 15.511), train_loss = 0.58654791, grad/param norm = 2.2939e-01, time/batch = 16.4715s	
6919/22300 (epoch 15.513), train_loss = 0.58080738, grad/param norm = 2.1060e-01, time/batch = 16.7121s	
6920/22300 (epoch 15.516), train_loss = 0.66976836, grad/param norm = 2.4782e-01, time/batch = 15.7008s	
6921/22300 (epoch 15.518), train_loss = 0.83503438, grad/param norm = 2.5782e-01, time/batch = 18.2806s	
6922/22300 (epoch 15.520), train_loss = 0.75653331, grad/param norm = 2.6564e-01, time/batch = 15.9653s	
6923/22300 (epoch 15.522), train_loss = 0.69239443, grad/param norm = 2.4789e-01, time/batch = 16.2848s	
6924/22300 (epoch 15.525), train_loss = 0.65786133, grad/param norm = 2.5390e-01, time/batch = 16.7152s	
6925/22300 (epoch 15.527), train_loss = 0.87608441, grad/param norm = 3.2268e-01, time/batch = 16.7284s	
6926/22300 (epoch 15.529), train_loss = 0.72187154, grad/param norm = 2.5579e-01, time/batch = 16.0476s	
6927/22300 (epoch 15.531), train_loss = 0.71281673, grad/param norm = 2.4762e-01, time/batch = 17.1409s	
6928/22300 (epoch 15.534), train_loss = 0.64499257, grad/param norm = 2.2631e-01, time/batch = 18.1902s	
6929/22300 (epoch 15.536), train_loss = 0.92097367, grad/param norm = 2.6539e-01, time/batch = 17.6323s	
6930/22300 (epoch 15.538), train_loss = 1.12798701, grad/param norm = 2.9817e-01, time/batch = 15.8055s	
6931/22300 (epoch 15.540), train_loss = 0.82184324, grad/param norm = 2.9238e-01, time/batch = 15.4900s	
6932/22300 (epoch 15.543), train_loss = 0.65983359, grad/param norm = 2.2574e-01, time/batch = 17.7070s	
6933/22300 (epoch 15.545), train_loss = 0.63401091, grad/param norm = 2.7480e-01, time/batch = 15.4554s	
6934/22300 (epoch 15.547), train_loss = 0.59024261, grad/param norm = 2.2075e-01, time/batch = 17.2022s	
6935/22300 (epoch 15.549), train_loss = 0.64534038, grad/param norm = 2.3804e-01, time/batch = 17.3789s	
6936/22300 (epoch 15.552), train_loss = 0.68776625, grad/param norm = 2.6066e-01, time/batch = 17.8146s	
6937/22300 (epoch 15.554), train_loss = 0.77755551, grad/param norm = 2.9287e-01, time/batch = 15.5515s	
6938/22300 (epoch 15.556), train_loss = 1.00025687, grad/param norm = 3.1949e-01, time/batch = 16.1479s	
6939/22300 (epoch 15.558), train_loss = 0.86990091, grad/param norm = 3.0804e-01, time/batch = 16.3785s	
6940/22300 (epoch 15.561), train_loss = 0.97753425, grad/param norm = 3.0251e-01, time/batch = 17.3853s	
6941/22300 (epoch 15.563), train_loss = 0.86448982, grad/param norm = 2.6362e-01, time/batch = 17.7137s	
6942/22300 (epoch 15.565), train_loss = 0.72062075, grad/param norm = 2.5629e-01, time/batch = 16.7973s	
6943/22300 (epoch 15.567), train_loss = 0.72696354, grad/param norm = 2.4481e-01, time/batch = 19.6212s	
6944/22300 (epoch 15.570), train_loss = 0.98989726, grad/param norm = 3.1310e-01, time/batch = 15.3879s	
6945/22300 (epoch 15.572), train_loss = 0.87346618, grad/param norm = 2.6147e-01, time/batch = 16.6313s	
6946/22300 (epoch 15.574), train_loss = 0.75518222, grad/param norm = 2.3817e-01, time/batch = 15.2975s	
6947/22300 (epoch 15.576), train_loss = 0.64269528, grad/param norm = 2.1170e-01, time/batch = 18.1001s	
6948/22300 (epoch 15.578), train_loss = 0.47404451, grad/param norm = 2.3550e-01, time/batch = 16.3756s	
6949/22300 (epoch 15.581), train_loss = 0.63793631, grad/param norm = 2.4848e-01, time/batch = 17.5976s	
6950/22300 (epoch 15.583), train_loss = 0.63010678, grad/param norm = 2.5018e-01, time/batch = 15.8131s	
6951/22300 (epoch 15.585), train_loss = 0.93448014, grad/param norm = 2.8745e-01, time/batch = 15.6056s	
6952/22300 (epoch 15.587), train_loss = 1.05982866, grad/param norm = 3.3618e-01, time/batch = 18.3885s	
6953/22300 (epoch 15.590), train_loss = 0.97783472, grad/param norm = 3.5037e-01, time/batch = 15.5278s	
6954/22300 (epoch 15.592), train_loss = 1.06146911, grad/param norm = 2.9616e-01, time/batch = 18.0578s	
6955/22300 (epoch 15.594), train_loss = 1.04208184, grad/param norm = 2.9934e-01, time/batch = 30.7036s	
6956/22300 (epoch 15.596), train_loss = 0.69525473, grad/param norm = 2.5107e-01, time/batch = 15.2952s	
6957/22300 (epoch 15.599), train_loss = 0.60679111, grad/param norm = 2.4450e-01, time/batch = 17.2960s	
6958/22300 (epoch 15.601), train_loss = 0.72203647, grad/param norm = 2.8795e-01, time/batch = 18.1922s	
6959/22300 (epoch 15.603), train_loss = 0.76882863, grad/param norm = 2.6719e-01, time/batch = 17.0297s	
6960/22300 (epoch 15.605), train_loss = 0.71054524, grad/param norm = 2.6437e-01, time/batch = 17.4678s	
6961/22300 (epoch 15.608), train_loss = 1.03483357, grad/param norm = 3.1403e-01, time/batch = 15.3735s	
6962/22300 (epoch 15.610), train_loss = 1.05596287, grad/param norm = 2.9826e-01, time/batch = 16.0504s	
6963/22300 (epoch 15.612), train_loss = 0.91272845, grad/param norm = 3.1811e-01, time/batch = 15.3937s	
6964/22300 (epoch 15.614), train_loss = 0.93200796, grad/param norm = 3.1724e-01, time/batch = 17.7011s	
6965/22300 (epoch 15.617), train_loss = 0.86722050, grad/param norm = 2.8472e-01, time/batch = 15.8167s	
6966/22300 (epoch 15.619), train_loss = 1.06850475, grad/param norm = 2.9338e-01, time/batch = 17.9737s	
6967/22300 (epoch 15.621), train_loss = 0.74937551, grad/param norm = 2.6158e-01, time/batch = 15.5474s	
6968/22300 (epoch 15.623), train_loss = 0.71211876, grad/param norm = 2.3302e-01, time/batch = 15.4509s	
6969/22300 (epoch 15.626), train_loss = 0.67112977, grad/param norm = 2.0577e-01, time/batch = 18.6167s	
6970/22300 (epoch 15.628), train_loss = 0.67704766, grad/param norm = 2.2185e-01, time/batch = 16.2349s	
6971/22300 (epoch 15.630), train_loss = 0.74602238, grad/param norm = 2.2939e-01, time/batch = 17.8922s	
6972/22300 (epoch 15.632), train_loss = 0.75551541, grad/param norm = 2.5535e-01, time/batch = 15.2670s	
6973/22300 (epoch 15.635), train_loss = 0.73288563, grad/param norm = 2.5794e-01, time/batch = 16.3192s	
6974/22300 (epoch 15.637), train_loss = 0.92487308, grad/param norm = 3.1163e-01, time/batch = 16.5506s	
6975/22300 (epoch 15.639), train_loss = 0.95333344, grad/param norm = 3.1053e-01, time/batch = 17.3012s	
6976/22300 (epoch 15.641), train_loss = 0.79968948, grad/param norm = 2.4763e-01, time/batch = 15.0458s	
6977/22300 (epoch 15.643), train_loss = 0.73914544, grad/param norm = 2.6581e-01, time/batch = 15.1312s	
6978/22300 (epoch 15.646), train_loss = 0.68141182, grad/param norm = 2.6511e-01, time/batch = 17.0561s	
6979/22300 (epoch 15.648), train_loss = 0.70850857, grad/param norm = 2.5059e-01, time/batch = 15.9696s	
6980/22300 (epoch 15.650), train_loss = 0.85028437, grad/param norm = 2.6512e-01, time/batch = 15.2864s	
6981/22300 (epoch 15.652), train_loss = 0.71425723, grad/param norm = 2.5747e-01, time/batch = 18.3664s	
6982/22300 (epoch 15.655), train_loss = 0.76503808, grad/param norm = 2.9102e-01, time/batch = 17.7114s	
6983/22300 (epoch 15.657), train_loss = 0.78825944, grad/param norm = 2.5505e-01, time/batch = 16.0347s	
6984/22300 (epoch 15.659), train_loss = 0.69177836, grad/param norm = 2.4407e-01, time/batch = 16.8894s	
6985/22300 (epoch 15.661), train_loss = 0.58272223, grad/param norm = 2.1845e-01, time/batch = 16.9776s	
6986/22300 (epoch 15.664), train_loss = 0.69612866, grad/param norm = 2.2257e-01, time/batch = 16.3154s	
6987/22300 (epoch 15.666), train_loss = 0.79706480, grad/param norm = 2.4934e-01, time/batch = 16.4734s	
6988/22300 (epoch 15.668), train_loss = 0.66622343, grad/param norm = 2.2900e-01, time/batch = 16.8169s	
6989/22300 (epoch 15.670), train_loss = 0.82879981, grad/param norm = 2.5459e-01, time/batch = 15.0004s	
6990/22300 (epoch 15.673), train_loss = 0.87053336, grad/param norm = 2.7086e-01, time/batch = 16.0269s	
6991/22300 (epoch 15.675), train_loss = 0.98069274, grad/param norm = 3.1777e-01, time/batch = 16.3072s	
6992/22300 (epoch 15.677), train_loss = 0.97390287, grad/param norm = 2.9182e-01, time/batch = 16.3486s	
6993/22300 (epoch 15.679), train_loss = 0.87881737, grad/param norm = 3.4394e-01, time/batch = 15.3047s	
6994/22300 (epoch 15.682), train_loss = 0.82478485, grad/param norm = 2.7714e-01, time/batch = 15.1481s	
6995/22300 (epoch 15.684), train_loss = 0.82641950, grad/param norm = 2.7035e-01, time/batch = 17.4720s	
6996/22300 (epoch 15.686), train_loss = 0.82399840, grad/param norm = 2.9332e-01, time/batch = 17.7798s	
6997/22300 (epoch 15.688), train_loss = 0.79460168, grad/param norm = 2.6415e-01, time/batch = 16.3919s	
6998/22300 (epoch 15.691), train_loss = 0.73957573, grad/param norm = 2.6488e-01, time/batch = 15.7232s	
6999/22300 (epoch 15.693), train_loss = 0.70235895, grad/param norm = 2.4853e-01, time/batch = 16.8768s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch15.70_1.5591.t7	
7000/22300 (epoch 15.695), train_loss = 0.61174548, grad/param norm = 2.2463e-01, time/batch = 16.3035s	
7001/22300 (epoch 15.697), train_loss = 1.12151137, grad/param norm = 3.2940e-01, time/batch = 18.6913s	
7002/22300 (epoch 15.700), train_loss = 0.71098851, grad/param norm = 3.0736e-01, time/batch = 16.4678s	
7003/22300 (epoch 15.702), train_loss = 0.71775326, grad/param norm = 2.2912e-01, time/batch = 16.9731s	
7004/22300 (epoch 15.704), train_loss = 0.83123446, grad/param norm = 2.8312e-01, time/batch = 14.6553s	
7005/22300 (epoch 15.706), train_loss = 0.68920913, grad/param norm = 2.6901e-01, time/batch = 16.7782s	
7006/22300 (epoch 15.709), train_loss = 0.59877031, grad/param norm = 2.4258e-01, time/batch = 15.3087s	
7007/22300 (epoch 15.711), train_loss = 0.62719123, grad/param norm = 2.3538e-01, time/batch = 16.2267s	
7008/22300 (epoch 15.713), train_loss = 0.80079460, grad/param norm = 2.4610e-01, time/batch = 15.3937s	
7009/22300 (epoch 15.715), train_loss = 0.77366765, grad/param norm = 2.5835e-01, time/batch = 16.1220s	
7010/22300 (epoch 15.717), train_loss = 0.97774597, grad/param norm = 2.8389e-01, time/batch = 15.8739s	
7011/22300 (epoch 15.720), train_loss = 0.70230000, grad/param norm = 2.5367e-01, time/batch = 15.2682s	
7012/22300 (epoch 15.722), train_loss = 0.79310763, grad/param norm = 2.5804e-01, time/batch = 17.3108s	
7013/22300 (epoch 15.724), train_loss = 0.82516829, grad/param norm = 2.8551e-01, time/batch = 16.8757s	
7014/22300 (epoch 15.726), train_loss = 0.72971169, grad/param norm = 2.8040e-01, time/batch = 16.0369s	
7015/22300 (epoch 15.729), train_loss = 0.76165359, grad/param norm = 2.6778e-01, time/batch = 15.6974s	
7016/22300 (epoch 15.731), train_loss = 0.96726129, grad/param norm = 3.2184e-01, time/batch = 17.4838s	
7017/22300 (epoch 15.733), train_loss = 0.94929712, grad/param norm = 3.1048e-01, time/batch = 15.3907s	
7018/22300 (epoch 15.735), train_loss = 0.96620450, grad/param norm = 3.2344e-01, time/batch = 16.6497s	
7019/22300 (epoch 15.738), train_loss = 0.80650925, grad/param norm = 3.1543e-01, time/batch = 17.2906s	
7020/22300 (epoch 15.740), train_loss = 0.65224377, grad/param norm = 2.6512e-01, time/batch = 15.0307s	
7021/22300 (epoch 15.742), train_loss = 0.77277712, grad/param norm = 2.6941e-01, time/batch = 15.5468s	
7022/22300 (epoch 15.744), train_loss = 1.07413915, grad/param norm = 3.1580e-01, time/batch = 15.7114s	
7023/22300 (epoch 15.747), train_loss = 0.83810441, grad/param norm = 2.6194e-01, time/batch = 16.4774s	
7024/22300 (epoch 15.749), train_loss = 1.14163632, grad/param norm = 3.9211e-01, time/batch = 17.2143s	
7025/22300 (epoch 15.751), train_loss = 0.97794070, grad/param norm = 3.3323e-01, time/batch = 15.4817s	
7026/22300 (epoch 15.753), train_loss = 1.02675402, grad/param norm = 3.6657e-01, time/batch = 16.6448s	
7027/22300 (epoch 15.756), train_loss = 0.85596893, grad/param norm = 2.7996e-01, time/batch = 18.9572s	
7028/22300 (epoch 15.758), train_loss = 0.84992461, grad/param norm = 2.7612e-01, time/batch = 16.0372s	
7029/22300 (epoch 15.760), train_loss = 0.83986438, grad/param norm = 2.8598e-01, time/batch = 15.9344s	
7030/22300 (epoch 15.762), train_loss = 0.83888300, grad/param norm = 2.9983e-01, time/batch = 15.1971s	
7031/22300 (epoch 15.765), train_loss = 0.84580577, grad/param norm = 2.9699e-01, time/batch = 17.7932s	
7032/22300 (epoch 15.767), train_loss = 0.89210242, grad/param norm = 2.9355e-01, time/batch = 16.3836s	
7033/22300 (epoch 15.769), train_loss = 0.81180972, grad/param norm = 2.8415e-01, time/batch = 16.6424s	
7034/22300 (epoch 15.771), train_loss = 0.90405931, grad/param norm = 2.9988e-01, time/batch = 15.6228s	
7035/22300 (epoch 15.774), train_loss = 0.94119732, grad/param norm = 3.3352e-01, time/batch = 17.3045s	
7036/22300 (epoch 15.776), train_loss = 1.01542290, grad/param norm = 3.3068e-01, time/batch = 16.6253s	
7037/22300 (epoch 15.778), train_loss = 0.98716907, grad/param norm = 3.2642e-01, time/batch = 15.2849s	
7038/22300 (epoch 15.780), train_loss = 0.94913853, grad/param norm = 3.0871e-01, time/batch = 17.6380s	
7039/22300 (epoch 15.783), train_loss = 1.01184161, grad/param norm = 3.3997e-01, time/batch = 15.7132s	
7040/22300 (epoch 15.785), train_loss = 0.75506911, grad/param norm = 2.7379e-01, time/batch = 15.3958s	
7041/22300 (epoch 15.787), train_loss = 0.78064739, grad/param norm = 2.7190e-01, time/batch = 14.8770s	
7042/22300 (epoch 15.789), train_loss = 0.96831767, grad/param norm = 2.8119e-01, time/batch = 17.6468s	
7043/22300 (epoch 15.791), train_loss = 1.13248773, grad/param norm = 3.0770e-01, time/batch = 16.0685s	
7044/22300 (epoch 15.794), train_loss = 0.97876360, grad/param norm = 3.2264e-01, time/batch = 17.3779s	
7045/22300 (epoch 15.796), train_loss = 0.98551793, grad/param norm = 3.1921e-01, time/batch = 15.7995s	
7046/22300 (epoch 15.798), train_loss = 1.04346911, grad/param norm = 2.8895e-01, time/batch = 15.8559s	
7047/22300 (epoch 15.800), train_loss = 0.80539147, grad/param norm = 2.9619e-01, time/batch = 18.6127s	
7048/22300 (epoch 15.803), train_loss = 0.73001839, grad/param norm = 2.3265e-01, time/batch = 16.5488s	
7049/22300 (epoch 15.805), train_loss = 0.85320659, grad/param norm = 2.6198e-01, time/batch = 17.5548s	
7050/22300 (epoch 15.807), train_loss = 0.99782022, grad/param norm = 3.4023e-01, time/batch = 15.2081s	
7051/22300 (epoch 15.809), train_loss = 0.80123596, grad/param norm = 2.7361e-01, time/batch = 17.0594s	
7052/22300 (epoch 15.812), train_loss = 0.92655414, grad/param norm = 2.7114e-01, time/batch = 18.0439s	
7053/22300 (epoch 15.814), train_loss = 0.89491625, grad/param norm = 2.7835e-01, time/batch = 14.9518s	
7054/22300 (epoch 15.816), train_loss = 0.92993196, grad/param norm = 2.8033e-01, time/batch = 15.6286s	
7055/22300 (epoch 15.818), train_loss = 0.97499507, grad/param norm = 2.9860e-01, time/batch = 16.5570s	
7056/22300 (epoch 15.821), train_loss = 0.94183750, grad/param norm = 3.5372e-01, time/batch = 18.3037s	
7057/22300 (epoch 15.823), train_loss = 0.65986817, grad/param norm = 2.6686e-01, time/batch = 15.6319s	
7058/22300 (epoch 15.825), train_loss = 0.81334913, grad/param norm = 2.5170e-01, time/batch = 16.5477s	
7059/22300 (epoch 15.827), train_loss = 0.80141323, grad/param norm = 2.9212e-01, time/batch = 15.4701s	
7060/22300 (epoch 15.830), train_loss = 0.74754494, grad/param norm = 2.8848e-01, time/batch = 18.4583s	
7061/22300 (epoch 15.832), train_loss = 0.75275094, grad/param norm = 2.8094e-01, time/batch = 15.5542s	
7062/22300 (epoch 15.834), train_loss = 0.75345885, grad/param norm = 3.2830e-01, time/batch = 16.1287s	
7063/22300 (epoch 15.836), train_loss = 0.83335805, grad/param norm = 2.9832e-01, time/batch = 15.3859s	
7064/22300 (epoch 15.839), train_loss = 0.78351499, grad/param norm = 2.7568e-01, time/batch = 16.6337s	
7065/22300 (epoch 15.841), train_loss = 0.82729325, grad/param norm = 3.0703e-01, time/batch = 17.2957s	
7066/22300 (epoch 15.843), train_loss = 0.81991487, grad/param norm = 3.1346e-01, time/batch = 16.4545s	
7067/22300 (epoch 15.845), train_loss = 0.81959864, grad/param norm = 2.7157e-01, time/batch = 18.2920s	
7068/22300 (epoch 15.848), train_loss = 0.81756979, grad/param norm = 2.5892e-01, time/batch = 15.5531s	
7069/22300 (epoch 15.850), train_loss = 0.82452337, grad/param norm = 2.5627e-01, time/batch = 18.1341s	
7070/22300 (epoch 15.852), train_loss = 0.80013511, grad/param norm = 2.6787e-01, time/batch = 16.6984s	
7071/22300 (epoch 15.854), train_loss = 0.97464013, grad/param norm = 3.1189e-01, time/batch = 17.0349s	
7072/22300 (epoch 15.857), train_loss = 0.81651579, grad/param norm = 2.9425e-01, time/batch = 17.0544s	
7073/22300 (epoch 15.859), train_loss = 0.65387208, grad/param norm = 2.2499e-01, time/batch = 17.7990s	
7074/22300 (epoch 15.861), train_loss = 0.83805980, grad/param norm = 2.7895e-01, time/batch = 18.6995s	
7075/22300 (epoch 15.863), train_loss = 0.68238115, grad/param norm = 2.6556e-01, time/batch = 16.5250s	
7076/22300 (epoch 15.865), train_loss = 0.67756918, grad/param norm = 2.3384e-01, time/batch = 15.0666s	
7077/22300 (epoch 15.868), train_loss = 0.80009645, grad/param norm = 2.5292e-01, time/batch = 15.1615s	
7078/22300 (epoch 15.870), train_loss = 0.86411981, grad/param norm = 3.1542e-01, time/batch = 16.9623s	
7079/22300 (epoch 15.872), train_loss = 0.91732444, grad/param norm = 2.7940e-01, time/batch = 16.0476s	
7080/22300 (epoch 15.874), train_loss = 0.85329861, grad/param norm = 3.3621e-01, time/batch = 17.0482s	
7081/22300 (epoch 15.877), train_loss = 0.85392748, grad/param norm = 2.7650e-01, time/batch = 14.7482s	
7082/22300 (epoch 15.879), train_loss = 0.75222217, grad/param norm = 2.9012e-01, time/batch = 15.9648s	
7083/22300 (epoch 15.881), train_loss = 0.75513050, grad/param norm = 2.5397e-01, time/batch = 16.6403s	
7084/22300 (epoch 15.883), train_loss = 0.71563850, grad/param norm = 2.7257e-01, time/batch = 17.3790s	
7085/22300 (epoch 15.886), train_loss = 0.71342055, grad/param norm = 2.3325e-01, time/batch = 16.8057s	
7086/22300 (epoch 15.888), train_loss = 0.77304036, grad/param norm = 2.8332e-01, time/batch = 15.9649s	
7087/22300 (epoch 15.890), train_loss = 0.71712983, grad/param norm = 2.2442e-01, time/batch = 17.3798s	
7088/22300 (epoch 15.892), train_loss = 0.99645193, grad/param norm = 2.8634e-01, time/batch = 15.6136s	
7089/22300 (epoch 15.895), train_loss = 1.00321628, grad/param norm = 3.2525e-01, time/batch = 17.2896s	
7090/22300 (epoch 15.897), train_loss = 0.83748497, grad/param norm = 3.1833e-01, time/batch = 16.3668s	
7091/22300 (epoch 15.899), train_loss = 0.86697081, grad/param norm = 3.0379e-01, time/batch = 18.4520s	
7092/22300 (epoch 15.901), train_loss = 0.80614447, grad/param norm = 2.8307e-01, time/batch = 15.5959s	
7093/22300 (epoch 15.904), train_loss = 0.89626352, grad/param norm = 2.7810e-01, time/batch = 15.1366s	
7094/22300 (epoch 15.906), train_loss = 0.86680762, grad/param norm = 2.6902e-01, time/batch = 16.7002s	
7095/22300 (epoch 15.908), train_loss = 0.81998738, grad/param norm = 2.5369e-01, time/batch = 15.4923s	
7096/22300 (epoch 15.910), train_loss = 0.67107768, grad/param norm = 2.5401e-01, time/batch = 16.9662s	
7097/22300 (epoch 15.913), train_loss = 0.91506476, grad/param norm = 2.9640e-01, time/batch = 16.5498s	
7098/22300 (epoch 15.915), train_loss = 1.02032877, grad/param norm = 2.9532e-01, time/batch = 16.7173s	
7099/22300 (epoch 15.917), train_loss = 0.81029202, grad/param norm = 2.8119e-01, time/batch = 17.7729s	
7100/22300 (epoch 15.919), train_loss = 0.87233775, grad/param norm = 2.8076e-01, time/batch = 15.2378s	
7101/22300 (epoch 15.922), train_loss = 0.77635393, grad/param norm = 2.5649e-01, time/batch = 15.8043s	
7102/22300 (epoch 15.924), train_loss = 0.57215074, grad/param norm = 2.3499e-01, time/batch = 16.9658s	
7103/22300 (epoch 15.926), train_loss = 0.64888989, grad/param norm = 2.5785e-01, time/batch = 18.2306s	
7104/22300 (epoch 15.928), train_loss = 0.77734893, grad/param norm = 2.7660e-01, time/batch = 15.4294s	
7105/22300 (epoch 15.930), train_loss = 0.77468121, grad/param norm = 2.8823e-01, time/batch = 15.6282s	
7106/22300 (epoch 15.933), train_loss = 0.86878288, grad/param norm = 2.9593e-01, time/batch = 18.4597s	
7107/22300 (epoch 15.935), train_loss = 0.90380188, grad/param norm = 3.1228e-01, time/batch = 16.8748s	
7108/22300 (epoch 15.937), train_loss = 1.00322091, grad/param norm = 3.0617e-01, time/batch = 17.3023s	
7109/22300 (epoch 15.939), train_loss = 0.92920234, grad/param norm = 3.0416e-01, time/batch = 16.4743s	
7110/22300 (epoch 15.942), train_loss = 1.06948627, grad/param norm = 3.3398e-01, time/batch = 18.5446s	
7111/22300 (epoch 15.944), train_loss = 1.12143773, grad/param norm = 3.3957e-01, time/batch = 16.4606s	
7112/22300 (epoch 15.946), train_loss = 0.84698515, grad/param norm = 2.7903e-01, time/batch = 16.0333s	
7113/22300 (epoch 15.948), train_loss = 0.74771332, grad/param norm = 2.6069e-01, time/batch = 15.1484s	
7114/22300 (epoch 15.951), train_loss = 0.67405137, grad/param norm = 2.4944e-01, time/batch = 17.7882s	
7115/22300 (epoch 15.953), train_loss = 0.70577511, grad/param norm = 2.8504e-01, time/batch = 15.6051s	
7116/22300 (epoch 15.955), train_loss = 1.02256319, grad/param norm = 2.9046e-01, time/batch = 17.7256s	
7117/22300 (epoch 15.957), train_loss = 1.12494405, grad/param norm = 3.2679e-01, time/batch = 17.3934s	
7118/22300 (epoch 15.960), train_loss = 0.98173407, grad/param norm = 2.9371e-01, time/batch = 15.3000s	
7119/22300 (epoch 15.962), train_loss = 0.83148423, grad/param norm = 3.0442e-01, time/batch = 18.0493s	
7120/22300 (epoch 15.964), train_loss = 0.80506756, grad/param norm = 2.7941e-01, time/batch = 16.4650s	
7121/22300 (epoch 15.966), train_loss = 0.73368668, grad/param norm = 3.0250e-01, time/batch = 15.6446s	
7122/22300 (epoch 15.969), train_loss = 0.76359683, grad/param norm = 2.4086e-01, time/batch = 15.4549s	
7123/22300 (epoch 15.971), train_loss = 0.83363080, grad/param norm = 2.8638e-01, time/batch = 16.4894s	
7124/22300 (epoch 15.973), train_loss = 0.85806337, grad/param norm = 3.1531e-01, time/batch = 17.9608s	
7125/22300 (epoch 15.975), train_loss = 1.00431695, grad/param norm = 3.4357e-01, time/batch = 16.3791s	
7126/22300 (epoch 15.978), train_loss = 0.89707931, grad/param norm = 2.8631e-01, time/batch = 16.4603s	
7127/22300 (epoch 15.980), train_loss = 0.95012667, grad/param norm = 2.8628e-01, time/batch = 14.9480s	
7128/22300 (epoch 15.982), train_loss = 0.74630740, grad/param norm = 2.7644e-01, time/batch = 19.0355s	
7129/22300 (epoch 15.984), train_loss = 0.86472495, grad/param norm = 3.0681e-01, time/batch = 14.8798s	
7130/22300 (epoch 15.987), train_loss = 0.77740928, grad/param norm = 2.7205e-01, time/batch = 17.7725s	
7131/22300 (epoch 15.989), train_loss = 0.80091296, grad/param norm = 2.6018e-01, time/batch = 15.7975s	
7132/22300 (epoch 15.991), train_loss = 1.07245359, grad/param norm = 2.9646e-01, time/batch = 16.3051s	
7133/22300 (epoch 15.993), train_loss = 1.26385204, grad/param norm = 3.5014e-01, time/batch = 17.3681s	
7134/22300 (epoch 15.996), train_loss = 1.15878162, grad/param norm = 3.5051e-01, time/batch = 18.3852s	
7135/22300 (epoch 15.998), train_loss = 0.84661396, grad/param norm = 2.7107e-01, time/batch = 19.2940s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
7136/22300 (epoch 16.000), train_loss = 0.74087374, grad/param norm = 2.9365e-01, time/batch = 15.4789s	
7137/22300 (epoch 16.002), train_loss = 1.07806666, grad/param norm = 3.1861e-01, time/batch = 16.4500s	
7138/22300 (epoch 16.004), train_loss = 0.84272296, grad/param norm = 2.8823e-01, time/batch = 17.5621s	
7139/22300 (epoch 16.007), train_loss = 0.84298799, grad/param norm = 2.9569e-01, time/batch = 18.2045s	
7140/22300 (epoch 16.009), train_loss = 0.85687633, grad/param norm = 2.8059e-01, time/batch = 15.2903s	
7141/22300 (epoch 16.011), train_loss = 1.04418741, grad/param norm = 3.1588e-01, time/batch = 16.5415s	
7142/22300 (epoch 16.013), train_loss = 0.82179175, grad/param norm = 2.7606e-01, time/batch = 15.2104s	
7143/22300 (epoch 16.016), train_loss = 0.74236350, grad/param norm = 2.7756e-01, time/batch = 15.8049s	
7144/22300 (epoch 16.018), train_loss = 0.92709133, grad/param norm = 2.8136e-01, time/batch = 17.3056s	
7145/22300 (epoch 16.020), train_loss = 0.77845551, grad/param norm = 2.8946e-01, time/batch = 16.2951s	
7146/22300 (epoch 16.022), train_loss = 0.73683211, grad/param norm = 2.7807e-01, time/batch = 16.8120s	
7147/22300 (epoch 16.025), train_loss = 0.73664004, grad/param norm = 2.8718e-01, time/batch = 17.0351s	
7148/22300 (epoch 16.027), train_loss = 0.77024484, grad/param norm = 2.4572e-01, time/batch = 15.4608s	
7149/22300 (epoch 16.029), train_loss = 0.75864212, grad/param norm = 2.5247e-01, time/batch = 16.5691s	
7150/22300 (epoch 16.031), train_loss = 0.73689187, grad/param norm = 2.4213e-01, time/batch = 17.1206s	
7151/22300 (epoch 16.034), train_loss = 0.74486658, grad/param norm = 2.4151e-01, time/batch = 17.6304s	
7152/22300 (epoch 16.036), train_loss = 0.57344436, grad/param norm = 2.1657e-01, time/batch = 16.6903s	
7153/22300 (epoch 16.038), train_loss = 0.72938430, grad/param norm = 2.3625e-01, time/batch = 17.5575s	
7154/22300 (epoch 16.040), train_loss = 0.79023674, grad/param norm = 2.6128e-01, time/batch = 16.3594s	
7155/22300 (epoch 16.043), train_loss = 1.05222602, grad/param norm = 2.8578e-01, time/batch = 15.3004s	
7156/22300 (epoch 16.045), train_loss = 0.84865694, grad/param norm = 2.5335e-01, time/batch = 16.3201s	
7157/22300 (epoch 16.047), train_loss = 0.95112332, grad/param norm = 3.0598e-01, time/batch = 17.5412s	
7158/22300 (epoch 16.049), train_loss = 0.78834339, grad/param norm = 3.0713e-01, time/batch = 17.3694s	
7159/22300 (epoch 16.052), train_loss = 0.85595714, grad/param norm = 2.7968e-01, time/batch = 17.5498s	
7160/22300 (epoch 16.054), train_loss = 0.87272535, grad/param norm = 2.8146e-01, time/batch = 17.0671s	
7161/22300 (epoch 16.056), train_loss = 0.57652078, grad/param norm = 2.3814e-01, time/batch = 16.2007s	
7162/22300 (epoch 16.058), train_loss = 0.72975635, grad/param norm = 2.5913e-01, time/batch = 15.2118s	
7163/22300 (epoch 16.061), train_loss = 0.71707261, grad/param norm = 2.8730e-01, time/batch = 16.8775s	
7164/22300 (epoch 16.063), train_loss = 0.99932609, grad/param norm = 3.8044e-01, time/batch = 17.2517s	
7165/22300 (epoch 16.065), train_loss = 0.95261932, grad/param norm = 3.1918e-01, time/batch = 27.7103s	
7166/22300 (epoch 16.067), train_loss = 0.75985978, grad/param norm = 2.6866e-01, time/batch = 16.1545s	
7167/22300 (epoch 16.070), train_loss = 0.79654439, grad/param norm = 3.0336e-01, time/batch = 16.1302s	
7168/22300 (epoch 16.072), train_loss = 0.88488282, grad/param norm = 2.9500e-01, time/batch = 16.0698s	
7169/22300 (epoch 16.074), train_loss = 0.87924952, grad/param norm = 2.9185e-01, time/batch = 17.9649s	
7170/22300 (epoch 16.076), train_loss = 0.81867102, grad/param norm = 2.8020e-01, time/batch = 15.9726s	
7171/22300 (epoch 16.078), train_loss = 0.90553603, grad/param norm = 2.9176e-01, time/batch = 15.5683s	
7172/22300 (epoch 16.081), train_loss = 0.93311592, grad/param norm = 3.1631e-01, time/batch = 17.4691s	
7173/22300 (epoch 16.083), train_loss = 1.03081057, grad/param norm = 3.1041e-01, time/batch = 17.4509s	
7174/22300 (epoch 16.085), train_loss = 1.08650768, grad/param norm = 3.3372e-01, time/batch = 18.2021s	
7175/22300 (epoch 16.087), train_loss = 0.89727241, grad/param norm = 2.8335e-01, time/batch = 16.4648s	
7176/22300 (epoch 16.090), train_loss = 0.73337757, grad/param norm = 2.6770e-01, time/batch = 16.2370s	
7177/22300 (epoch 16.092), train_loss = 0.69496466, grad/param norm = 2.8075e-01, time/batch = 16.5665s	
7178/22300 (epoch 16.094), train_loss = 0.70146321, grad/param norm = 2.4348e-01, time/batch = 15.2438s	
7179/22300 (epoch 16.096), train_loss = 1.02111490, grad/param norm = 2.9968e-01, time/batch = 17.2169s	
7180/22300 (epoch 16.099), train_loss = 0.75664924, grad/param norm = 2.2853e-01, time/batch = 17.6463s	
7181/22300 (epoch 16.101), train_loss = 0.91928463, grad/param norm = 2.8011e-01, time/batch = 15.6153s	
7182/22300 (epoch 16.103), train_loss = 0.85741411, grad/param norm = 2.9648e-01, time/batch = 15.8616s	
7183/22300 (epoch 16.105), train_loss = 0.77936044, grad/param norm = 2.9627e-01, time/batch = 16.1431s	
7184/22300 (epoch 16.108), train_loss = 0.84098392, grad/param norm = 2.5310e-01, time/batch = 15.9805s	
7185/22300 (epoch 16.110), train_loss = 0.85471355, grad/param norm = 2.6112e-01, time/batch = 16.9471s	
7186/22300 (epoch 16.112), train_loss = 0.84405921, grad/param norm = 2.7662e-01, time/batch = 15.1171s	
7187/22300 (epoch 16.114), train_loss = 0.90717796, grad/param norm = 2.8825e-01, time/batch = 16.8062s	
7188/22300 (epoch 16.117), train_loss = 1.04150538, grad/param norm = 2.8143e-01, time/batch = 16.8067s	
7189/22300 (epoch 16.119), train_loss = 0.97112679, grad/param norm = 2.8231e-01, time/batch = 16.6301s	
7190/22300 (epoch 16.121), train_loss = 0.99556370, grad/param norm = 2.7807e-01, time/batch = 15.8087s	
7191/22300 (epoch 16.123), train_loss = 0.93585795, grad/param norm = 2.8685e-01, time/batch = 14.7109s	
7192/22300 (epoch 16.126), train_loss = 0.85274420, grad/param norm = 2.5996e-01, time/batch = 17.7222s	
7193/22300 (epoch 16.128), train_loss = 0.93524132, grad/param norm = 2.6988e-01, time/batch = 15.8827s	
7194/22300 (epoch 16.130), train_loss = 0.76639593, grad/param norm = 2.8515e-01, time/batch = 14.7404s	
7195/22300 (epoch 16.132), train_loss = 0.65030136, grad/param norm = 2.3184e-01, time/batch = 16.0254s	
7196/22300 (epoch 16.135), train_loss = 0.69458390, grad/param norm = 2.6244e-01, time/batch = 16.7021s	
7197/22300 (epoch 16.137), train_loss = 0.54766310, grad/param norm = 2.1768e-01, time/batch = 17.1256s	
7198/22300 (epoch 16.139), train_loss = 0.87045594, grad/param norm = 2.7958e-01, time/batch = 16.3091s	
7199/22300 (epoch 16.141), train_loss = 0.90605908, grad/param norm = 2.5631e-01, time/batch = 16.9468s	
7200/22300 (epoch 16.143), train_loss = 0.84224638, grad/param norm = 2.8254e-01, time/batch = 15.6629s	
7201/22300 (epoch 16.146), train_loss = 0.96937059, grad/param norm = 3.0836e-01, time/batch = 15.5380s	
7202/22300 (epoch 16.148), train_loss = 0.72287357, grad/param norm = 2.7915e-01, time/batch = 15.8145s	
7203/22300 (epoch 16.150), train_loss = 0.76707529, grad/param norm = 2.3759e-01, time/batch = 16.8895s	
7204/22300 (epoch 16.152), train_loss = 0.67144536, grad/param norm = 2.5876e-01, time/batch = 15.7178s	
7205/22300 (epoch 16.155), train_loss = 0.72445772, grad/param norm = 2.4388e-01, time/batch = 17.3958s	
7206/22300 (epoch 16.157), train_loss = 0.93538471, grad/param norm = 3.2444e-01, time/batch = 16.3717s	
7207/22300 (epoch 16.159), train_loss = 0.87968253, grad/param norm = 2.8732e-01, time/batch = 16.6351s	
7208/22300 (epoch 16.161), train_loss = 0.95796003, grad/param norm = 3.4627e-01, time/batch = 17.1346s	
7209/22300 (epoch 16.164), train_loss = 0.70376910, grad/param norm = 2.6080e-01, time/batch = 15.8112s	
7210/22300 (epoch 16.166), train_loss = 0.67267812, grad/param norm = 2.1783e-01, time/batch = 18.0461s	
7211/22300 (epoch 16.168), train_loss = 0.71107559, grad/param norm = 2.3693e-01, time/batch = 15.8100s	
7212/22300 (epoch 16.170), train_loss = 0.84262464, grad/param norm = 2.5703e-01, time/batch = 17.2140s	
7213/22300 (epoch 16.173), train_loss = 0.98334150, grad/param norm = 3.0634e-01, time/batch = 17.4663s	
7214/22300 (epoch 16.175), train_loss = 0.80345423, grad/param norm = 2.6570e-01, time/batch = 15.8801s	
7215/22300 (epoch 16.177), train_loss = 0.63602745, grad/param norm = 2.3774e-01, time/batch = 15.3603s	
7216/22300 (epoch 16.179), train_loss = 0.79773949, grad/param norm = 2.6756e-01, time/batch = 17.2086s	
7217/22300 (epoch 16.182), train_loss = 0.98082412, grad/param norm = 2.6537e-01, time/batch = 17.3939s	
7218/22300 (epoch 16.184), train_loss = 1.09026818, grad/param norm = 3.1260e-01, time/batch = 17.5322s	
7219/22300 (epoch 16.186), train_loss = 0.86972523, grad/param norm = 2.6902e-01, time/batch = 17.0338s	
7220/22300 (epoch 16.188), train_loss = 1.08034645, grad/param norm = 3.3376e-01, time/batch = 15.9831s	
7221/22300 (epoch 16.191), train_loss = 1.03758408, grad/param norm = 3.1254e-01, time/batch = 18.1210s	
7222/22300 (epoch 16.193), train_loss = 0.85678473, grad/param norm = 2.8272e-01, time/batch = 15.6413s	
7223/22300 (epoch 16.195), train_loss = 0.78206373, grad/param norm = 2.9035e-01, time/batch = 15.4695s	
7224/22300 (epoch 16.197), train_loss = 0.79988243, grad/param norm = 2.9409e-01, time/batch = 18.8865s	
7225/22300 (epoch 16.200), train_loss = 0.71511778, grad/param norm = 2.9224e-01, time/batch = 16.8045s	
7226/22300 (epoch 16.202), train_loss = 0.77926996, grad/param norm = 2.5165e-01, time/batch = 15.8627s	
7227/22300 (epoch 16.204), train_loss = 0.78158600, grad/param norm = 2.6820e-01, time/batch = 15.8765s	
7228/22300 (epoch 16.206), train_loss = 0.70750701, grad/param norm = 2.5918e-01, time/batch = 17.9639s	
7229/22300 (epoch 16.209), train_loss = 0.80237321, grad/param norm = 2.7235e-01, time/batch = 15.1374s	
7230/22300 (epoch 16.211), train_loss = 0.64230955, grad/param norm = 2.3497e-01, time/batch = 17.5410s	
7231/22300 (epoch 16.213), train_loss = 0.78715067, grad/param norm = 2.5112e-01, time/batch = 16.1358s	
7232/22300 (epoch 16.215), train_loss = 1.01653995, grad/param norm = 3.1257e-01, time/batch = 16.6911s	
7233/22300 (epoch 16.217), train_loss = 0.93192034, grad/param norm = 2.8217e-01, time/batch = 15.6998s	
7234/22300 (epoch 16.220), train_loss = 0.79591591, grad/param norm = 2.6301e-01, time/batch = 15.7232s	
7235/22300 (epoch 16.222), train_loss = 0.71434550, grad/param norm = 2.5824e-01, time/batch = 18.5489s	
7236/22300 (epoch 16.224), train_loss = 0.73510654, grad/param norm = 2.7012e-01, time/batch = 15.7206s	
7237/22300 (epoch 16.226), train_loss = 0.78127331, grad/param norm = 2.5853e-01, time/batch = 17.2812s	
7238/22300 (epoch 16.229), train_loss = 0.74837357, grad/param norm = 2.8979e-01, time/batch = 17.3876s	
7239/22300 (epoch 16.231), train_loss = 0.91006960, grad/param norm = 2.9595e-01, time/batch = 16.8720s	
7240/22300 (epoch 16.233), train_loss = 0.84127527, grad/param norm = 2.6436e-01, time/batch = 15.8929s	
7241/22300 (epoch 16.235), train_loss = 0.65196781, grad/param norm = 2.5623e-01, time/batch = 17.5485s	
7242/22300 (epoch 16.238), train_loss = 0.66310748, grad/param norm = 2.2744e-01, time/batch = 14.5722s	
7243/22300 (epoch 16.240), train_loss = 0.65358536, grad/param norm = 2.1490e-01, time/batch = 16.2057s	
7244/22300 (epoch 16.242), train_loss = 0.69207040, grad/param norm = 2.7683e-01, time/batch = 16.9408s	
7245/22300 (epoch 16.244), train_loss = 0.52340153, grad/param norm = 2.1638e-01, time/batch = 15.7132s	
7246/22300 (epoch 16.247), train_loss = 0.69017007, grad/param norm = 2.7789e-01, time/batch = 15.2978s	
7247/22300 (epoch 16.249), train_loss = 0.55475466, grad/param norm = 2.5601e-01, time/batch = 16.1318s	
7248/22300 (epoch 16.251), train_loss = 0.67827038, grad/param norm = 2.4330e-01, time/batch = 17.2182s	
7249/22300 (epoch 16.253), train_loss = 0.56685963, grad/param norm = 2.2950e-01, time/batch = 16.4537s	
7250/22300 (epoch 16.256), train_loss = 0.65843761, grad/param norm = 2.3263e-01, time/batch = 16.8093s	
7251/22300 (epoch 16.258), train_loss = 0.94342923, grad/param norm = 3.0264e-01, time/batch = 16.8016s	
7252/22300 (epoch 16.260), train_loss = 0.78921375, grad/param norm = 2.6191e-01, time/batch = 16.6329s	
7253/22300 (epoch 16.262), train_loss = 0.66065067, grad/param norm = 2.2001e-01, time/batch = 17.2249s	
7254/22300 (epoch 16.265), train_loss = 0.66014210, grad/param norm = 2.5413e-01, time/batch = 16.8740s	
7255/22300 (epoch 16.267), train_loss = 0.73595812, grad/param norm = 2.3714e-01, time/batch = 15.3758s	
7256/22300 (epoch 16.269), train_loss = 0.79868792, grad/param norm = 2.9421e-01, time/batch = 15.7079s	
7257/22300 (epoch 16.271), train_loss = 0.78781648, grad/param norm = 2.5239e-01, time/batch = 15.2478s	
7258/22300 (epoch 16.274), train_loss = 0.60987324, grad/param norm = 2.2733e-01, time/batch = 15.5471s	
7259/22300 (epoch 16.276), train_loss = 0.57431456, grad/param norm = 2.1811e-01, time/batch = 15.7878s	
7260/22300 (epoch 16.278), train_loss = 0.53195859, grad/param norm = 2.3139e-01, time/batch = 17.8954s	
7261/22300 (epoch 16.280), train_loss = 0.67691612, grad/param norm = 2.4396e-01, time/batch = 17.6251s	
7262/22300 (epoch 16.283), train_loss = 0.52018246, grad/param norm = 1.8494e-01, time/batch = 15.0647s	
7263/22300 (epoch 16.285), train_loss = 0.68412366, grad/param norm = 2.7592e-01, time/batch = 16.8048s	
7264/22300 (epoch 16.287), train_loss = 0.79386967, grad/param norm = 2.5663e-01, time/batch = 17.1463s	
7265/22300 (epoch 16.289), train_loss = 0.68715972, grad/param norm = 2.4441e-01, time/batch = 16.0469s	
7266/22300 (epoch 16.291), train_loss = 0.70658356, grad/param norm = 2.6645e-01, time/batch = 15.7353s	
7267/22300 (epoch 16.294), train_loss = 0.60746724, grad/param norm = 2.1668e-01, time/batch = 16.3937s	
7268/22300 (epoch 16.296), train_loss = 0.82112800, grad/param norm = 2.7020e-01, time/batch = 17.3847s	
7269/22300 (epoch 16.298), train_loss = 0.88596782, grad/param norm = 2.6494e-01, time/batch = 15.2244s	
7270/22300 (epoch 16.300), train_loss = 0.92560737, grad/param norm = 2.7139e-01, time/batch = 16.5411s	
7271/22300 (epoch 16.303), train_loss = 0.74042167, grad/param norm = 2.7712e-01, time/batch = 17.9236s	
7272/22300 (epoch 16.305), train_loss = 0.77860450, grad/param norm = 3.0438e-01, time/batch = 14.9490s	
7273/22300 (epoch 16.307), train_loss = 0.72798711, grad/param norm = 2.7673e-01, time/batch = 17.4694s	
7274/22300 (epoch 16.309), train_loss = 0.66661165, grad/param norm = 2.6630e-01, time/batch = 15.8140s	
7275/22300 (epoch 16.312), train_loss = 0.62524722, grad/param norm = 2.3277e-01, time/batch = 15.7990s	
7276/22300 (epoch 16.314), train_loss = 0.70029021, grad/param norm = 2.6921e-01, time/batch = 16.3149s	
7277/22300 (epoch 16.316), train_loss = 0.72301711, grad/param norm = 2.7221e-01, time/batch = 16.8516s	
7278/22300 (epoch 16.318), train_loss = 0.75043243, grad/param norm = 2.3910e-01, time/batch = 16.6470s	
7279/22300 (epoch 16.321), train_loss = 0.84940516, grad/param norm = 2.5980e-01, time/batch = 15.7018s	
7280/22300 (epoch 16.323), train_loss = 0.66687210, grad/param norm = 2.3082e-01, time/batch = 15.4398s	
7281/22300 (epoch 16.325), train_loss = 0.62482243, grad/param norm = 2.3126e-01, time/batch = 16.5435s	
7282/22300 (epoch 16.327), train_loss = 0.64996594, grad/param norm = 2.4681e-01, time/batch = 16.3880s	
7283/22300 (epoch 16.330), train_loss = 0.68620480, grad/param norm = 2.7237e-01, time/batch = 16.3099s	
7284/22300 (epoch 16.332), train_loss = 0.65048695, grad/param norm = 2.7249e-01, time/batch = 15.9712s	
7285/22300 (epoch 16.334), train_loss = 0.65562408, grad/param norm = 2.6297e-01, time/batch = 17.3151s	
7286/22300 (epoch 16.336), train_loss = 0.69414803, grad/param norm = 2.6778e-01, time/batch = 17.1363s	
7287/22300 (epoch 16.339), train_loss = 0.75718445, grad/param norm = 2.7715e-01, time/batch = 16.2931s	
7288/22300 (epoch 16.341), train_loss = 0.81884054, grad/param norm = 2.8612e-01, time/batch = 16.6333s	
7289/22300 (epoch 16.343), train_loss = 0.88387378, grad/param norm = 2.8131e-01, time/batch = 17.6296s	
7290/22300 (epoch 16.345), train_loss = 0.73573511, grad/param norm = 2.8162e-01, time/batch = 16.3794s	
7291/22300 (epoch 16.348), train_loss = 0.73040928, grad/param norm = 2.3957e-01, time/batch = 16.1309s	
7292/22300 (epoch 16.350), train_loss = 0.60850377, grad/param norm = 2.3766e-01, time/batch = 16.7314s	
7293/22300 (epoch 16.352), train_loss = 0.83232518, grad/param norm = 2.6598e-01, time/batch = 15.2311s	
7294/22300 (epoch 16.354), train_loss = 0.99867615, grad/param norm = 3.0576e-01, time/batch = 15.7171s	
7295/22300 (epoch 16.357), train_loss = 0.86616501, grad/param norm = 2.9396e-01, time/batch = 15.8972s	
7296/22300 (epoch 16.359), train_loss = 0.68686932, grad/param norm = 2.6961e-01, time/batch = 16.8885s	
7297/22300 (epoch 16.361), train_loss = 0.68094271, grad/param norm = 2.5245e-01, time/batch = 18.7070s	
7298/22300 (epoch 16.363), train_loss = 0.94026153, grad/param norm = 2.9352e-01, time/batch = 15.1982s	
7299/22300 (epoch 16.365), train_loss = 0.77045446, grad/param norm = 3.1421e-01, time/batch = 17.9386s	
7300/22300 (epoch 16.368), train_loss = 0.77207348, grad/param norm = 3.2394e-01, time/batch = 18.0358s	
7301/22300 (epoch 16.370), train_loss = 0.76892527, grad/param norm = 2.9632e-01, time/batch = 16.3713s	
7302/22300 (epoch 16.372), train_loss = 0.62972263, grad/param norm = 2.7593e-01, time/batch = 15.1150s	
7303/22300 (epoch 16.374), train_loss = 0.55839085, grad/param norm = 2.4661e-01, time/batch = 17.1242s	
7304/22300 (epoch 16.377), train_loss = 0.73658011, grad/param norm = 3.1313e-01, time/batch = 15.1831s	
7305/22300 (epoch 16.379), train_loss = 0.72203605, grad/param norm = 2.7162e-01, time/batch = 16.3684s	
7306/22300 (epoch 16.381), train_loss = 0.86574595, grad/param norm = 2.9176e-01, time/batch = 18.0525s	
7307/22300 (epoch 16.383), train_loss = 0.72080296, grad/param norm = 2.9967e-01, time/batch = 17.1300s	
7308/22300 (epoch 16.386), train_loss = 0.72049051, grad/param norm = 2.5520e-01, time/batch = 15.1002s	
7309/22300 (epoch 16.388), train_loss = 0.65146545, grad/param norm = 2.5235e-01, time/batch = 16.3641s	
7310/22300 (epoch 16.390), train_loss = 0.80640276, grad/param norm = 3.1283e-01, time/batch = 15.7058s	
7311/22300 (epoch 16.392), train_loss = 0.72532624, grad/param norm = 2.6996e-01, time/batch = 15.8076s	
7312/22300 (epoch 16.395), train_loss = 0.62734926, grad/param norm = 2.5249e-01, time/batch = 15.2199s	
7313/22300 (epoch 16.397), train_loss = 0.45948455, grad/param norm = 2.2114e-01, time/batch = 15.3151s	
7314/22300 (epoch 16.399), train_loss = 0.62945758, grad/param norm = 2.9083e-01, time/batch = 16.2069s	
7315/22300 (epoch 16.401), train_loss = 0.70036004, grad/param norm = 2.6400e-01, time/batch = 16.7967s	
7316/22300 (epoch 16.404), train_loss = 0.68576843, grad/param norm = 2.4706e-01, time/batch = 16.6391s	
7317/22300 (epoch 16.406), train_loss = 0.99580896, grad/param norm = 3.3869e-01, time/batch = 17.0530s	
7318/22300 (epoch 16.408), train_loss = 0.84926323, grad/param norm = 2.6571e-01, time/batch = 16.2955s	
7319/22300 (epoch 16.410), train_loss = 0.83073084, grad/param norm = 2.5498e-01, time/batch = 17.3838s	
7320/22300 (epoch 16.413), train_loss = 0.69768246, grad/param norm = 2.4926e-01, time/batch = 15.1431s	
7321/22300 (epoch 16.415), train_loss = 0.59547456, grad/param norm = 2.6497e-01, time/batch = 16.1573s	
7322/22300 (epoch 16.417), train_loss = 0.78248798, grad/param norm = 2.8363e-01, time/batch = 15.6410s	
7323/22300 (epoch 16.419), train_loss = 0.68419525, grad/param norm = 2.2176e-01, time/batch = 15.7605s	
7324/22300 (epoch 16.422), train_loss = 0.67327013, grad/param norm = 2.3869e-01, time/batch = 17.1232s	
7325/22300 (epoch 16.424), train_loss = 0.76433444, grad/param norm = 2.7240e-01, time/batch = 17.8825s	
7326/22300 (epoch 16.426), train_loss = 0.61411489, grad/param norm = 2.4770e-01, time/batch = 16.0407s	
7327/22300 (epoch 16.428), train_loss = 0.64604151, grad/param norm = 2.4404e-01, time/batch = 15.7143s	
7328/22300 (epoch 16.430), train_loss = 0.72587041, grad/param norm = 2.7154e-01, time/batch = 18.2184s	
7329/22300 (epoch 16.433), train_loss = 0.71144153, grad/param norm = 2.4309e-01, time/batch = 16.0633s	
7330/22300 (epoch 16.435), train_loss = 0.77610378, grad/param norm = 3.2494e-01, time/batch = 16.3005s	
7331/22300 (epoch 16.437), train_loss = 0.75703384, grad/param norm = 2.7192e-01, time/batch = 15.3883s	
7332/22300 (epoch 16.439), train_loss = 0.80883252, grad/param norm = 3.1486e-01, time/batch = 17.5577s	
7333/22300 (epoch 16.442), train_loss = 0.75457790, grad/param norm = 2.5117e-01, time/batch = 17.3836s	
7334/22300 (epoch 16.444), train_loss = 0.67988952, grad/param norm = 2.6425e-01, time/batch = 15.7215s	
7335/22300 (epoch 16.446), train_loss = 0.60757756, grad/param norm = 2.5076e-01, time/batch = 16.9689s	
7336/22300 (epoch 16.448), train_loss = 0.49540818, grad/param norm = 2.2603e-01, time/batch = 16.9501s	
7337/22300 (epoch 16.451), train_loss = 0.81821265, grad/param norm = 3.0157e-01, time/batch = 18.4690s	
7338/22300 (epoch 16.453), train_loss = 0.68699428, grad/param norm = 2.5728e-01, time/batch = 16.0576s	
7339/22300 (epoch 16.455), train_loss = 0.90508785, grad/param norm = 3.3057e-01, time/batch = 15.5366s	
7340/22300 (epoch 16.457), train_loss = 0.87787770, grad/param norm = 3.0382e-01, time/batch = 14.8624s	
7341/22300 (epoch 16.460), train_loss = 0.81965252, grad/param norm = 3.1063e-01, time/batch = 17.3678s	
7342/22300 (epoch 16.462), train_loss = 0.87946520, grad/param norm = 2.5700e-01, time/batch = 16.3870s	
7343/22300 (epoch 16.464), train_loss = 0.78600807, grad/param norm = 2.8263e-01, time/batch = 16.7224s	
7344/22300 (epoch 16.466), train_loss = 0.70333497, grad/param norm = 2.3868e-01, time/batch = 15.5741s	
7345/22300 (epoch 16.469), train_loss = 0.67979321, grad/param norm = 2.4356e-01, time/batch = 16.6865s	
7346/22300 (epoch 16.471), train_loss = 0.83391373, grad/param norm = 2.5949e-01, time/batch = 18.0510s	
7347/22300 (epoch 16.473), train_loss = 0.77692063, grad/param norm = 2.2134e-01, time/batch = 17.8927s	
7348/22300 (epoch 16.475), train_loss = 0.68710458, grad/param norm = 2.6683e-01, time/batch = 16.6353s	
7349/22300 (epoch 16.478), train_loss = 0.72169879, grad/param norm = 2.7048e-01, time/batch = 15.9628s	
7350/22300 (epoch 16.480), train_loss = 0.53262697, grad/param norm = 2.3461e-01, time/batch = 17.6393s	
7351/22300 (epoch 16.482), train_loss = 0.57642959, grad/param norm = 2.0839e-01, time/batch = 17.5601s	
7352/22300 (epoch 16.484), train_loss = 0.72484540, grad/param norm = 2.6283e-01, time/batch = 15.4797s	
7353/22300 (epoch 16.487), train_loss = 0.76603254, grad/param norm = 2.4104e-01, time/batch = 16.1258s	
7354/22300 (epoch 16.489), train_loss = 0.82542296, grad/param norm = 2.7553e-01, time/batch = 15.2262s	
7355/22300 (epoch 16.491), train_loss = 0.80797504, grad/param norm = 2.7764e-01, time/batch = 17.4724s	
7356/22300 (epoch 16.493), train_loss = 0.78614947, grad/param norm = 2.7726e-01, time/batch = 15.6226s	
7357/22300 (epoch 16.496), train_loss = 0.67708219, grad/param norm = 2.3581e-01, time/batch = 17.0656s	
7358/22300 (epoch 16.498), train_loss = 0.60252534, grad/param norm = 2.4162e-01, time/batch = 15.6049s	
7359/22300 (epoch 16.500), train_loss = 0.75800533, grad/param norm = 2.5906e-01, time/batch = 16.8918s	
7360/22300 (epoch 16.502), train_loss = 0.57323796, grad/param norm = 3.1649e-01, time/batch = 15.0452s	
7361/22300 (epoch 16.504), train_loss = 0.58836566, grad/param norm = 2.2012e-01, time/batch = 17.6279s	
7362/22300 (epoch 16.507), train_loss = 0.65374721, grad/param norm = 2.4903e-01, time/batch = 15.8829s	
7363/22300 (epoch 16.509), train_loss = 0.79482068, grad/param norm = 2.8111e-01, time/batch = 16.3743s	
7364/22300 (epoch 16.511), train_loss = 0.54631092, grad/param norm = 2.3580e-01, time/batch = 17.5512s	
7365/22300 (epoch 16.513), train_loss = 0.55004738, grad/param norm = 2.0848e-01, time/batch = 14.3160s	
7366/22300 (epoch 16.516), train_loss = 0.63261706, grad/param norm = 2.5256e-01, time/batch = 15.5480s	
7367/22300 (epoch 16.518), train_loss = 0.79054591, grad/param norm = 2.4036e-01, time/batch = 15.5498s	
7368/22300 (epoch 16.520), train_loss = 0.71276806, grad/param norm = 2.5847e-01, time/batch = 16.4581s	
7369/22300 (epoch 16.522), train_loss = 0.65494713, grad/param norm = 2.6169e-01, time/batch = 16.8148s	
7370/22300 (epoch 16.525), train_loss = 0.61456543, grad/param norm = 2.3110e-01, time/batch = 15.8675s	
7371/22300 (epoch 16.527), train_loss = 0.83931749, grad/param norm = 3.1488e-01, time/batch = 17.3840s	
7372/22300 (epoch 16.529), train_loss = 0.70345050, grad/param norm = 2.7041e-01, time/batch = 15.2836s	
7373/22300 (epoch 16.531), train_loss = 0.67236060, grad/param norm = 2.5539e-01, time/batch = 17.3053s	
7374/22300 (epoch 16.534), train_loss = 0.61497186, grad/param norm = 2.1095e-01, time/batch = 15.9749s	
7375/22300 (epoch 16.536), train_loss = 0.88133553, grad/param norm = 2.6112e-01, time/batch = 18.3072s	
7376/22300 (epoch 16.538), train_loss = 1.07187161, grad/param norm = 2.8077e-01, time/batch = 15.4084s	
7377/22300 (epoch 16.540), train_loss = 0.75979139, grad/param norm = 2.8670e-01, time/batch = 16.3913s	
7378/22300 (epoch 16.543), train_loss = 0.62751133, grad/param norm = 2.2335e-01, time/batch = 15.7028s	
7379/22300 (epoch 16.545), train_loss = 0.58892544, grad/param norm = 2.6989e-01, time/batch = 15.4073s	
7380/22300 (epoch 16.547), train_loss = 0.57005688, grad/param norm = 2.4081e-01, time/batch = 17.9535s	
7381/22300 (epoch 16.549), train_loss = 0.60878104, grad/param norm = 2.3266e-01, time/batch = 22.3792s	
7382/22300 (epoch 16.552), train_loss = 0.64540321, grad/param norm = 2.5520e-01, time/batch = 24.5961s	
7383/22300 (epoch 16.554), train_loss = 0.73925134, grad/param norm = 3.7351e-01, time/batch = 16.6514s	
7384/22300 (epoch 16.556), train_loss = 0.97464033, grad/param norm = 3.6077e-01, time/batch = 15.7875s	
7385/22300 (epoch 16.558), train_loss = 0.82469752, grad/param norm = 3.0457e-01, time/batch = 17.2229s	
7386/22300 (epoch 16.561), train_loss = 0.95314129, grad/param norm = 3.2877e-01, time/batch = 15.7688s	
7387/22300 (epoch 16.563), train_loss = 0.84343755, grad/param norm = 3.0238e-01, time/batch = 18.6245s	
7388/22300 (epoch 16.565), train_loss = 0.70601409, grad/param norm = 3.1666e-01, time/batch = 16.6525s	
7389/22300 (epoch 16.567), train_loss = 0.69357289, grad/param norm = 2.5283e-01, time/batch = 16.8728s	
7390/22300 (epoch 16.570), train_loss = 0.96345769, grad/param norm = 3.2318e-01, time/batch = 17.7052s	
7391/22300 (epoch 16.572), train_loss = 0.86183910, grad/param norm = 2.6981e-01, time/batch = 17.2033s	
7392/22300 (epoch 16.574), train_loss = 0.72460094, grad/param norm = 2.3983e-01, time/batch = 16.9619s	
7393/22300 (epoch 16.576), train_loss = 0.60012412, grad/param norm = 2.1219e-01, time/batch = 17.9746s	
7394/22300 (epoch 16.578), train_loss = 0.44250116, grad/param norm = 2.0020e-01, time/batch = 17.6263s	
7395/22300 (epoch 16.581), train_loss = 0.60480110, grad/param norm = 2.5073e-01, time/batch = 15.4744s	
7396/22300 (epoch 16.583), train_loss = 0.58877698, grad/param norm = 2.2235e-01, time/batch = 15.8758s	
7397/22300 (epoch 16.585), train_loss = 0.89749006, grad/param norm = 3.0889e-01, time/batch = 18.4523s	
7398/22300 (epoch 16.587), train_loss = 1.02369754, grad/param norm = 3.3553e-01, time/batch = 16.6169s	
7399/22300 (epoch 16.590), train_loss = 0.94536843, grad/param norm = 3.4660e-01, time/batch = 17.5542s	
7400/22300 (epoch 16.592), train_loss = 1.04657560, grad/param norm = 3.5516e-01, time/batch = 15.6042s	
7401/22300 (epoch 16.594), train_loss = 1.01376392, grad/param norm = 3.0161e-01, time/batch = 18.3594s	
7402/22300 (epoch 16.596), train_loss = 0.67271574, grad/param norm = 2.7469e-01, time/batch = 15.7306s	
7403/22300 (epoch 16.599), train_loss = 0.56848342, grad/param norm = 2.4495e-01, time/batch = 16.4030s	
7404/22300 (epoch 16.601), train_loss = 0.66436449, grad/param norm = 2.9389e-01, time/batch = 16.0520s	
7405/22300 (epoch 16.603), train_loss = 0.74177812, grad/param norm = 2.7430e-01, time/batch = 17.2102s	
7406/22300 (epoch 16.605), train_loss = 0.67919364, grad/param norm = 2.5704e-01, time/batch = 16.0500s	
7407/22300 (epoch 16.608), train_loss = 0.99414045, grad/param norm = 3.0293e-01, time/batch = 16.4595s	
7408/22300 (epoch 16.610), train_loss = 1.01799641, grad/param norm = 3.2330e-01, time/batch = 16.6560s	
7409/22300 (epoch 16.612), train_loss = 0.86457021, grad/param norm = 2.9444e-01, time/batch = 15.4642s	
7410/22300 (epoch 16.614), train_loss = 0.89506519, grad/param norm = 3.0977e-01, time/batch = 17.7161s	
7411/22300 (epoch 16.617), train_loss = 0.85312284, grad/param norm = 3.2383e-01, time/batch = 17.4786s	
7412/22300 (epoch 16.619), train_loss = 1.02843554, grad/param norm = 3.0795e-01, time/batch = 15.3952s	
7413/22300 (epoch 16.621), train_loss = 0.71276572, grad/param norm = 2.3466e-01, time/batch = 16.7275s	
7414/22300 (epoch 16.623), train_loss = 0.68283772, grad/param norm = 2.3362e-01, time/batch = 16.8896s	
7415/22300 (epoch 16.626), train_loss = 0.63216473, grad/param norm = 2.0583e-01, time/batch = 17.2751s	
7416/22300 (epoch 16.628), train_loss = 0.63953273, grad/param norm = 2.1181e-01, time/batch = 15.3443s	
7417/22300 (epoch 16.630), train_loss = 0.71879371, grad/param norm = 2.5480e-01, time/batch = 15.1237s	
7418/22300 (epoch 16.632), train_loss = 0.72512201, grad/param norm = 2.7203e-01, time/batch = 16.2405s	
7419/22300 (epoch 16.635), train_loss = 0.70029464, grad/param norm = 2.8052e-01, time/batch = 16.7762s	
7420/22300 (epoch 16.637), train_loss = 0.86305793, grad/param norm = 2.7430e-01, time/batch = 15.4671s	
7421/22300 (epoch 16.639), train_loss = 0.92443656, grad/param norm = 3.2891e-01, time/batch = 18.4548s	
7422/22300 (epoch 16.641), train_loss = 0.77905278, grad/param norm = 2.7963e-01, time/batch = 15.8840s	
7423/22300 (epoch 16.643), train_loss = 0.73185523, grad/param norm = 2.9427e-01, time/batch = 16.3822s	
7424/22300 (epoch 16.646), train_loss = 0.64903931, grad/param norm = 2.4477e-01, time/batch = 15.1364s	
7425/22300 (epoch 16.648), train_loss = 0.68593724, grad/param norm = 2.6004e-01, time/batch = 16.0297s	
7426/22300 (epoch 16.650), train_loss = 0.80220474, grad/param norm = 2.7109e-01, time/batch = 17.0603s	
7427/22300 (epoch 16.652), train_loss = 0.67762483, grad/param norm = 2.4438e-01, time/batch = 16.3029s	
7428/22300 (epoch 16.655), train_loss = 0.70855204, grad/param norm = 2.8089e-01, time/batch = 16.3037s	
7429/22300 (epoch 16.657), train_loss = 0.75594255, grad/param norm = 2.6862e-01, time/batch = 15.9048s	
7430/22300 (epoch 16.659), train_loss = 0.67123776, grad/param norm = 2.8730e-01, time/batch = 15.3098s	
7431/22300 (epoch 16.661), train_loss = 0.55590803, grad/param norm = 2.2416e-01, time/batch = 15.1349s	
7432/22300 (epoch 16.664), train_loss = 0.65314816, grad/param norm = 2.2511e-01, time/batch = 17.1350s	
7433/22300 (epoch 16.666), train_loss = 0.76300901, grad/param norm = 2.5448e-01, time/batch = 16.0437s	
7434/22300 (epoch 16.668), train_loss = 0.64578295, grad/param norm = 2.5500e-01, time/batch = 16.1157s	
7435/22300 (epoch 16.670), train_loss = 0.79381941, grad/param norm = 2.5522e-01, time/batch = 16.3664s	
7436/22300 (epoch 16.673), train_loss = 0.82624895, grad/param norm = 2.7194e-01, time/batch = 16.5510s	
7437/22300 (epoch 16.675), train_loss = 0.95502216, grad/param norm = 3.1800e-01, time/batch = 16.8094s	
7438/22300 (epoch 16.677), train_loss = 0.91988403, grad/param norm = 2.9365e-01, time/batch = 15.8546s	
7439/22300 (epoch 16.679), train_loss = 0.81409181, grad/param norm = 3.3554e-01, time/batch = 17.0347s	
7440/22300 (epoch 16.682), train_loss = 0.78707296, grad/param norm = 2.8996e-01, time/batch = 16.5544s	
7441/22300 (epoch 16.684), train_loss = 0.78377929, grad/param norm = 2.7879e-01, time/batch = 15.8172s	
7442/22300 (epoch 16.686), train_loss = 0.78087874, grad/param norm = 2.7740e-01, time/batch = 16.5484s	
7443/22300 (epoch 16.688), train_loss = 0.75908339, grad/param norm = 2.9986e-01, time/batch = 16.5518s	
7444/22300 (epoch 16.691), train_loss = 0.69886923, grad/param norm = 2.6344e-01, time/batch = 17.7878s	
7445/22300 (epoch 16.693), train_loss = 0.65678357, grad/param norm = 2.4720e-01, time/batch = 15.4554s	
7446/22300 (epoch 16.695), train_loss = 0.58294329, grad/param norm = 2.4099e-01, time/batch = 18.4794s	
7447/22300 (epoch 16.697), train_loss = 0.64450907, grad/param norm = 2.4155e-01, time/batch = 15.9011s	
7448/22300 (epoch 16.700), train_loss = 0.66687096, grad/param norm = 2.5482e-01, time/batch = 15.9711s	
7449/22300 (epoch 16.702), train_loss = 0.67054270, grad/param norm = 2.5469e-01, time/batch = 15.6382s	
7450/22300 (epoch 16.704), train_loss = 0.78442379, grad/param norm = 3.0588e-01, time/batch = 17.5500s	
7451/22300 (epoch 16.706), train_loss = 0.64443426, grad/param norm = 2.5859e-01, time/batch = 17.0502s	
7452/22300 (epoch 16.709), train_loss = 0.56795012, grad/param norm = 2.3447e-01, time/batch = 17.7120s	
7453/22300 (epoch 16.711), train_loss = 0.57719835, grad/param norm = 2.3302e-01, time/batch = 15.6263s	
7454/22300 (epoch 16.713), train_loss = 0.75637289, grad/param norm = 2.6635e-01, time/batch = 16.7132s	
7455/22300 (epoch 16.715), train_loss = 0.73462808, grad/param norm = 2.7305e-01, time/batch = 15.8158s	
7456/22300 (epoch 16.717), train_loss = 0.92840277, grad/param norm = 2.7173e-01, time/batch = 16.5311s	
7457/22300 (epoch 16.720), train_loss = 0.65863997, grad/param norm = 2.6136e-01, time/batch = 17.4558s	
7458/22300 (epoch 16.722), train_loss = 0.75831417, grad/param norm = 2.4998e-01, time/batch = 15.3228s	
7459/22300 (epoch 16.724), train_loss = 0.79354315, grad/param norm = 2.7560e-01, time/batch = 17.3873s	
7460/22300 (epoch 16.726), train_loss = 0.67996156, grad/param norm = 2.5789e-01, time/batch = 15.6193s	
7461/22300 (epoch 16.729), train_loss = 0.73214721, grad/param norm = 2.6383e-01, time/batch = 16.1294s	
7462/22300 (epoch 16.731), train_loss = 0.93107459, grad/param norm = 3.2691e-01, time/batch = 15.7744s	
7463/22300 (epoch 16.733), train_loss = 0.92231163, grad/param norm = 2.9375e-01, time/batch = 16.8822s	
7464/22300 (epoch 16.735), train_loss = 0.95077097, grad/param norm = 4.0399e-01, time/batch = 16.1377s	
7465/22300 (epoch 16.738), train_loss = 0.76013976, grad/param norm = 3.0243e-01, time/batch = 16.4470s	
7466/22300 (epoch 16.740), train_loss = 0.62752232, grad/param norm = 2.5367e-01, time/batch = 17.5455s	
7467/22300 (epoch 16.742), train_loss = 0.74123368, grad/param norm = 2.8469e-01, time/batch = 15.4775s	
7468/22300 (epoch 16.744), train_loss = 1.00644800, grad/param norm = 2.9338e-01, time/batch = 17.7279s	
7469/22300 (epoch 16.747), train_loss = 0.80843722, grad/param norm = 2.5313e-01, time/batch = 16.1460s	
7470/22300 (epoch 16.749), train_loss = 1.08890259, grad/param norm = 3.2651e-01, time/batch = 17.9629s	
7471/22300 (epoch 16.751), train_loss = 0.91660903, grad/param norm = 3.3507e-01, time/batch = 16.0567s	
7472/22300 (epoch 16.753), train_loss = 0.95763506, grad/param norm = 3.0924e-01, time/batch = 17.2228s	
7473/22300 (epoch 16.756), train_loss = 0.82440639, grad/param norm = 2.7608e-01, time/batch = 17.0395s	
7474/22300 (epoch 16.758), train_loss = 0.81341909, grad/param norm = 2.7615e-01, time/batch = 16.0321s	
7475/22300 (epoch 16.760), train_loss = 0.78570674, grad/param norm = 2.8419e-01, time/batch = 17.5438s	
7476/22300 (epoch 16.762), train_loss = 0.79767958, grad/param norm = 3.0639e-01, time/batch = 16.9650s	
7477/22300 (epoch 16.765), train_loss = 0.79824031, grad/param norm = 2.8585e-01, time/batch = 18.0365s	
7478/22300 (epoch 16.767), train_loss = 0.82767844, grad/param norm = 2.8144e-01, time/batch = 15.4817s	
7479/22300 (epoch 16.769), train_loss = 0.79460673, grad/param norm = 3.0160e-01, time/batch = 16.2090s	
7480/22300 (epoch 16.771), train_loss = 0.85373649, grad/param norm = 2.9116e-01, time/batch = 17.7997s	
7481/22300 (epoch 16.774), train_loss = 0.92629668, grad/param norm = 3.5024e-01, time/batch = 16.0523s	
7482/22300 (epoch 16.776), train_loss = 0.97854685, grad/param norm = 3.4802e-01, time/batch = 16.2983s	
7483/22300 (epoch 16.778), train_loss = 0.93056568, grad/param norm = 3.1641e-01, time/batch = 15.6231s	
7484/22300 (epoch 16.780), train_loss = 0.92297223, grad/param norm = 3.3110e-01, time/batch = 17.0250s	
7485/22300 (epoch 16.783), train_loss = 0.97129246, grad/param norm = 3.1025e-01, time/batch = 16.2065s	
7486/22300 (epoch 16.785), train_loss = 0.72563390, grad/param norm = 2.6825e-01, time/batch = 15.0753s	
7487/22300 (epoch 16.787), train_loss = 0.74756632, grad/param norm = 2.9600e-01, time/batch = 16.2385s	
7488/22300 (epoch 16.789), train_loss = 0.96466321, grad/param norm = 3.7681e-01, time/batch = 15.0574s	
7489/22300 (epoch 16.791), train_loss = 1.12917958, grad/param norm = 3.4156e-01, time/batch = 16.0262s	
7490/22300 (epoch 16.794), train_loss = 0.96768433, grad/param norm = 3.7127e-01, time/batch = 17.6955s	
7491/22300 (epoch 16.796), train_loss = 0.94888530, grad/param norm = 3.0831e-01, time/batch = 15.0643s	
7492/22300 (epoch 16.798), train_loss = 1.02568069, grad/param norm = 3.1047e-01, time/batch = 17.1387s	
7493/22300 (epoch 16.800), train_loss = 0.76492373, grad/param norm = 2.7539e-01, time/batch = 14.9004s	
7494/22300 (epoch 16.803), train_loss = 0.71657987, grad/param norm = 2.7096e-01, time/batch = 17.2171s	
7495/22300 (epoch 16.805), train_loss = 0.82066998, grad/param norm = 2.9466e-01, time/batch = 16.8866s	
7496/22300 (epoch 16.807), train_loss = 0.97071772, grad/param norm = 3.4984e-01, time/batch = 15.7226s	
7497/22300 (epoch 16.809), train_loss = 0.75564415, grad/param norm = 2.7577e-01, time/batch = 17.4693s	
7498/22300 (epoch 16.812), train_loss = 0.88643636, grad/param norm = 2.7409e-01, time/batch = 16.2681s	
7499/22300 (epoch 16.814), train_loss = 0.85749731, grad/param norm = 2.6906e-01, time/batch = 17.3875s	
7500/22300 (epoch 16.816), train_loss = 0.88763085, grad/param norm = 2.7897e-01, time/batch = 16.2957s	
7501/22300 (epoch 16.818), train_loss = 0.95380887, grad/param norm = 3.1866e-01, time/batch = 18.3765s	
7502/22300 (epoch 16.821), train_loss = 0.88517005, grad/param norm = 2.9054e-01, time/batch = 17.7161s	
7503/22300 (epoch 16.823), train_loss = 0.63784330, grad/param norm = 3.2723e-01, time/batch = 16.1911s	
7504/22300 (epoch 16.825), train_loss = 0.74546699, grad/param norm = 2.5499e-01, time/batch = 18.2949s	
7505/22300 (epoch 16.827), train_loss = 0.75364898, grad/param norm = 2.7631e-01, time/batch = 16.4806s	
7506/22300 (epoch 16.830), train_loss = 0.69678845, grad/param norm = 3.0795e-01, time/batch = 16.4627s	
7507/22300 (epoch 16.832), train_loss = 0.70944707, grad/param norm = 2.8507e-01, time/batch = 16.1907s	
7508/22300 (epoch 16.834), train_loss = 0.68074645, grad/param norm = 2.5788e-01, time/batch = 15.6520s	
7509/22300 (epoch 16.836), train_loss = 0.80593304, grad/param norm = 3.0260e-01, time/batch = 15.9037s	
7510/22300 (epoch 16.839), train_loss = 0.76246435, grad/param norm = 3.0481e-01, time/batch = 15.4509s	
7511/22300 (epoch 16.841), train_loss = 0.78858974, grad/param norm = 3.2388e-01, time/batch = 18.3810s	
7512/22300 (epoch 16.843), train_loss = 0.78923330, grad/param norm = 2.9063e-01, time/batch = 16.8098s	
7513/22300 (epoch 16.845), train_loss = 0.76817525, grad/param norm = 2.6600e-01, time/batch = 16.8139s	
7514/22300 (epoch 16.848), train_loss = 0.78609931, grad/param norm = 2.7834e-01, time/batch = 15.5500s	
7515/22300 (epoch 16.850), train_loss = 0.76390258, grad/param norm = 2.4300e-01, time/batch = 17.2904s	
7516/22300 (epoch 16.852), train_loss = 0.77648528, grad/param norm = 2.8946e-01, time/batch = 16.4651s	
7517/22300 (epoch 16.854), train_loss = 0.97537312, grad/param norm = 3.2416e-01, time/batch = 16.8637s	
7518/22300 (epoch 16.857), train_loss = 0.78354835, grad/param norm = 3.0467e-01, time/batch = 15.6719s	
7519/22300 (epoch 16.859), train_loss = 0.62637094, grad/param norm = 2.4758e-01, time/batch = 16.3153s	
7520/22300 (epoch 16.861), train_loss = 0.80690113, grad/param norm = 2.3897e-01, time/batch = 18.7952s	
7521/22300 (epoch 16.863), train_loss = 0.63934314, grad/param norm = 2.4232e-01, time/batch = 15.6441s	
7522/22300 (epoch 16.865), train_loss = 0.64917466, grad/param norm = 2.2780e-01, time/batch = 17.7199s	
7523/22300 (epoch 16.868), train_loss = 0.76721871, grad/param norm = 2.4285e-01, time/batch = 15.9698s	
7524/22300 (epoch 16.870), train_loss = 0.83263465, grad/param norm = 3.0095e-01, time/batch = 14.6733s	
7525/22300 (epoch 16.872), train_loss = 0.88611915, grad/param norm = 2.7773e-01, time/batch = 15.6371s	
7526/22300 (epoch 16.874), train_loss = 0.79825843, grad/param norm = 3.1114e-01, time/batch = 16.6108s	
7527/22300 (epoch 16.877), train_loss = 0.79304494, grad/param norm = 2.6194e-01, time/batch = 16.6350s	
7528/22300 (epoch 16.879), train_loss = 0.70172248, grad/param norm = 2.6558e-01, time/batch = 15.6387s	
7529/22300 (epoch 16.881), train_loss = 0.70744128, grad/param norm = 2.5201e-01, time/batch = 16.0498s	
7530/22300 (epoch 16.883), train_loss = 0.69393550, grad/param norm = 2.5125e-01, time/batch = 17.1453s	
7531/22300 (epoch 16.886), train_loss = 0.68352640, grad/param norm = 2.5099e-01, time/batch = 18.2123s	
7532/22300 (epoch 16.888), train_loss = 0.72505907, grad/param norm = 2.5509e-01, time/batch = 16.1748s	
7533/22300 (epoch 16.890), train_loss = 0.68565979, grad/param norm = 2.1982e-01, time/batch = 17.3679s	
7534/22300 (epoch 16.892), train_loss = 0.95847646, grad/param norm = 2.7653e-01, time/batch = 16.0610s	
7535/22300 (epoch 16.895), train_loss = 0.93665869, grad/param norm = 2.9825e-01, time/batch = 15.9661s	
7536/22300 (epoch 16.897), train_loss = 0.80885385, grad/param norm = 3.0497e-01, time/batch = 15.2303s	
7537/22300 (epoch 16.899), train_loss = 0.82390370, grad/param norm = 3.0749e-01, time/batch = 15.0490s	
7538/22300 (epoch 16.901), train_loss = 0.77729785, grad/param norm = 2.7982e-01, time/batch = 17.1231s	
7539/22300 (epoch 16.904), train_loss = 0.85839833, grad/param norm = 3.0800e-01, time/batch = 15.2696s	
7540/22300 (epoch 16.906), train_loss = 0.83425169, grad/param norm = 2.9615e-01, time/batch = 17.3487s	
7541/22300 (epoch 16.908), train_loss = 0.78280420, grad/param norm = 2.6257e-01, time/batch = 16.4767s	
7542/22300 (epoch 16.910), train_loss = 0.63973580, grad/param norm = 2.6663e-01, time/batch = 16.9751s	
7543/22300 (epoch 16.913), train_loss = 0.85225828, grad/param norm = 2.9567e-01, time/batch = 9.3277s	
7544/22300 (epoch 16.915), train_loss = 0.97590975, grad/param norm = 3.1075e-01, time/batch = 0.6613s	
7545/22300 (epoch 16.917), train_loss = 0.77727080, grad/param norm = 2.6653e-01, time/batch = 0.6514s	
7546/22300 (epoch 16.919), train_loss = 0.83761350, grad/param norm = 2.6267e-01, time/batch = 0.6612s	
7547/22300 (epoch 16.922), train_loss = 0.74390336, grad/param norm = 2.9027e-01, time/batch = 0.6728s	
7548/22300 (epoch 16.924), train_loss = 0.53857232, grad/param norm = 2.2643e-01, time/batch = 0.6753s	
7549/22300 (epoch 16.926), train_loss = 0.62331202, grad/param norm = 2.3481e-01, time/batch = 0.6728s	
7550/22300 (epoch 16.928), train_loss = 0.73904226, grad/param norm = 2.5180e-01, time/batch = 0.6700s	
7551/22300 (epoch 16.930), train_loss = 0.72941262, grad/param norm = 2.6310e-01, time/batch = 0.9843s	
7552/22300 (epoch 16.933), train_loss = 0.83485901, grad/param norm = 2.8461e-01, time/batch = 0.9820s	
7553/22300 (epoch 16.935), train_loss = 0.86669120, grad/param norm = 3.0691e-01, time/batch = 0.9828s	
7554/22300 (epoch 16.937), train_loss = 0.95103249, grad/param norm = 3.0561e-01, time/batch = 0.9884s	
7555/22300 (epoch 16.939), train_loss = 0.88469623, grad/param norm = 3.0161e-01, time/batch = 0.9670s	
7556/22300 (epoch 16.942), train_loss = 1.00695387, grad/param norm = 3.1154e-01, time/batch = 1.6973s	
7557/22300 (epoch 16.944), train_loss = 1.08195585, grad/param norm = 3.7394e-01, time/batch = 1.8301s	
7558/22300 (epoch 16.946), train_loss = 0.80923723, grad/param norm = 2.7947e-01, time/batch = 3.2986s	
7559/22300 (epoch 16.948), train_loss = 0.71818973, grad/param norm = 2.9722e-01, time/batch = 15.7328s	
7560/22300 (epoch 16.951), train_loss = 0.65834167, grad/param norm = 2.7881e-01, time/batch = 14.6612s	
7561/22300 (epoch 16.953), train_loss = 0.70546323, grad/param norm = 3.0501e-01, time/batch = 15.1458s	
7562/22300 (epoch 16.955), train_loss = 0.98274184, grad/param norm = 3.1008e-01, time/batch = 16.0715s	
7563/22300 (epoch 16.957), train_loss = 1.09742671, grad/param norm = 3.6523e-01, time/batch = 16.5639s	
7564/22300 (epoch 16.960), train_loss = 0.92948108, grad/param norm = 2.8541e-01, time/batch = 17.7217s	
7565/22300 (epoch 16.962), train_loss = 0.76667296, grad/param norm = 2.7449e-01, time/batch = 15.1266s	
7566/22300 (epoch 16.964), train_loss = 0.77543616, grad/param norm = 2.8918e-01, time/batch = 17.2142s	
7567/22300 (epoch 16.966), train_loss = 0.69867008, grad/param norm = 2.8210e-01, time/batch = 17.0343s	
7568/22300 (epoch 16.969), train_loss = 0.73923336, grad/param norm = 2.2654e-01, time/batch = 16.2794s	
7569/22300 (epoch 16.971), train_loss = 0.76531349, grad/param norm = 2.3122e-01, time/batch = 16.7778s	
7570/22300 (epoch 16.973), train_loss = 0.80951677, grad/param norm = 3.0406e-01, time/batch = 16.3033s	
7571/22300 (epoch 16.975), train_loss = 0.98120919, grad/param norm = 3.1726e-01, time/batch = 18.0385s	
7572/22300 (epoch 16.978), train_loss = 0.86250457, grad/param norm = 3.1173e-01, time/batch = 15.7573s	
7573/22300 (epoch 16.980), train_loss = 0.91046380, grad/param norm = 3.6008e-01, time/batch = 18.1334s	
7574/22300 (epoch 16.982), train_loss = 0.72832776, grad/param norm = 2.7212e-01, time/batch = 19.6160s	
7575/22300 (epoch 16.984), train_loss = 0.84943719, grad/param norm = 3.0190e-01, time/batch = 15.5377s	
7576/22300 (epoch 16.987), train_loss = 0.71964364, grad/param norm = 2.5635e-01, time/batch = 16.8879s	
7577/22300 (epoch 16.989), train_loss = 0.77277191, grad/param norm = 2.6796e-01, time/batch = 15.3877s	
7578/22300 (epoch 16.991), train_loss = 1.03473514, grad/param norm = 3.1329e-01, time/batch = 17.9702s	
7579/22300 (epoch 16.993), train_loss = 1.22581243, grad/param norm = 3.5442e-01, time/batch = 15.7077s	
7580/22300 (epoch 16.996), train_loss = 1.10426234, grad/param norm = 3.3537e-01, time/batch = 18.6307s	
7581/22300 (epoch 16.998), train_loss = 0.80677335, grad/param norm = 3.0110e-01, time/batch = 19.3618s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
7582/22300 (epoch 17.000), train_loss = 0.67254564, grad/param norm = 2.7527e-01, time/batch = 16.2967s	
7583/22300 (epoch 17.002), train_loss = 1.07235057, grad/param norm = 3.2696e-01, time/batch = 19.1215s	
7584/22300 (epoch 17.004), train_loss = 0.81471287, grad/param norm = 2.7673e-01, time/batch = 14.9520s	
7585/22300 (epoch 17.007), train_loss = 0.81525812, grad/param norm = 2.8838e-01, time/batch = 17.5036s	
7586/22300 (epoch 17.009), train_loss = 0.82236003, grad/param norm = 2.6363e-01, time/batch = 14.9908s	
7587/22300 (epoch 17.011), train_loss = 0.99474939, grad/param norm = 3.3783e-01, time/batch = 18.4685s	
7588/22300 (epoch 17.013), train_loss = 0.79803583, grad/param norm = 2.9155e-01, time/batch = 17.3855s	
7589/22300 (epoch 17.016), train_loss = 0.72234677, grad/param norm = 3.1013e-01, time/batch = 16.5121s	
7590/22300 (epoch 17.018), train_loss = 0.90169464, grad/param norm = 3.1343e-01, time/batch = 17.7106s	
7591/22300 (epoch 17.020), train_loss = 0.75356909, grad/param norm = 2.9924e-01, time/batch = 17.3949s	
7592/22300 (epoch 17.022), train_loss = 0.71200249, grad/param norm = 2.8637e-01, time/batch = 17.1380s	
7593/22300 (epoch 17.025), train_loss = 0.67956776, grad/param norm = 2.5787e-01, time/batch = 15.3521s	
7594/22300 (epoch 17.027), train_loss = 0.72261289, grad/param norm = 2.4179e-01, time/batch = 17.8088s	
7595/22300 (epoch 17.029), train_loss = 0.70631703, grad/param norm = 2.4794e-01, time/batch = 16.3053s	
7596/22300 (epoch 17.031), train_loss = 0.69710195, grad/param norm = 2.3882e-01, time/batch = 15.8954s	
7597/22300 (epoch 17.034), train_loss = 0.70237776, grad/param norm = 2.3310e-01, time/batch = 17.0458s	
7598/22300 (epoch 17.036), train_loss = 0.56630632, grad/param norm = 2.2168e-01, time/batch = 16.2280s	
7599/22300 (epoch 17.038), train_loss = 0.68905110, grad/param norm = 2.3795e-01, time/batch = 18.4676s	
7600/22300 (epoch 17.040), train_loss = 0.74609168, grad/param norm = 2.6528e-01, time/batch = 17.1980s	
7601/22300 (epoch 17.043), train_loss = 1.02289463, grad/param norm = 2.8856e-01, time/batch = 16.9269s	
7602/22300 (epoch 17.045), train_loss = 0.81603683, grad/param norm = 2.5212e-01, time/batch = 16.9691s	
7603/22300 (epoch 17.047), train_loss = 0.88704294, grad/param norm = 2.9797e-01, time/batch = 16.9615s	
7604/22300 (epoch 17.049), train_loss = 0.73981486, grad/param norm = 2.7419e-01, time/batch = 16.4698s	
7605/22300 (epoch 17.052), train_loss = 0.82350881, grad/param norm = 2.7191e-01, time/batch = 16.2294s	
7606/22300 (epoch 17.054), train_loss = 0.81568185, grad/param norm = 2.5341e-01, time/batch = 18.3866s	
7607/22300 (epoch 17.056), train_loss = 0.54509108, grad/param norm = 2.2429e-01, time/batch = 14.9599s	
7608/22300 (epoch 17.058), train_loss = 0.70414136, grad/param norm = 2.7027e-01, time/batch = 19.4545s	
7609/22300 (epoch 17.061), train_loss = 0.68027296, grad/param norm = 2.6425e-01, time/batch = 18.9592s	
7610/22300 (epoch 17.063), train_loss = 0.95467428, grad/param norm = 3.5410e-01, time/batch = 24.5228s	
7611/22300 (epoch 17.065), train_loss = 0.91754231, grad/param norm = 2.9803e-01, time/batch = 20.4615s	
7612/22300 (epoch 17.067), train_loss = 0.73753678, grad/param norm = 3.1094e-01, time/batch = 18.2974s	
7613/22300 (epoch 17.070), train_loss = 0.76028677, grad/param norm = 2.5253e-01, time/batch = 16.4642s	
7614/22300 (epoch 17.072), train_loss = 0.85658213, grad/param norm = 3.1326e-01, time/batch = 17.1338s	
7615/22300 (epoch 17.074), train_loss = 0.86249938, grad/param norm = 3.2163e-01, time/batch = 16.8124s	
7616/22300 (epoch 17.076), train_loss = 0.78566065, grad/param norm = 2.9154e-01, time/batch = 17.4547s	
7617/22300 (epoch 17.078), train_loss = 0.86876301, grad/param norm = 2.8009e-01, time/batch = 14.4894s	
7618/22300 (epoch 17.081), train_loss = 0.89169419, grad/param norm = 3.1950e-01, time/batch = 16.2873s	
7619/22300 (epoch 17.083), train_loss = 1.00593908, grad/param norm = 3.1049e-01, time/batch = 18.1904s	
7620/22300 (epoch 17.085), train_loss = 1.04539934, grad/param norm = 3.4107e-01, time/batch = 16.1988s	
7621/22300 (epoch 17.087), train_loss = 0.86668240, grad/param norm = 2.8762e-01, time/batch = 18.9548s	
7622/22300 (epoch 17.090), train_loss = 0.69855738, grad/param norm = 2.4411e-01, time/batch = 15.7702s	
7623/22300 (epoch 17.092), train_loss = 0.65268986, grad/param norm = 2.4719e-01, time/batch = 16.9453s	
7624/22300 (epoch 17.094), train_loss = 0.67037081, grad/param norm = 2.9062e-01, time/batch = 15.7999s	
7625/22300 (epoch 17.096), train_loss = 0.97742214, grad/param norm = 3.1676e-01, time/batch = 18.4735s	
7626/22300 (epoch 17.099), train_loss = 0.73835781, grad/param norm = 2.6538e-01, time/batch = 17.1481s	
7627/22300 (epoch 17.101), train_loss = 0.89574937, grad/param norm = 2.9446e-01, time/batch = 15.3513s	
7628/22300 (epoch 17.103), train_loss = 0.81011934, grad/param norm = 2.8803e-01, time/batch = 18.2194s	
7629/22300 (epoch 17.105), train_loss = 0.74658560, grad/param norm = 3.1954e-01, time/batch = 16.5739s	
7630/22300 (epoch 17.108), train_loss = 0.83895643, grad/param norm = 2.8991e-01, time/batch = 17.2228s	
7631/22300 (epoch 17.110), train_loss = 0.83026708, grad/param norm = 2.5675e-01, time/batch = 15.9086s	
7632/22300 (epoch 17.112), train_loss = 0.80300813, grad/param norm = 2.5613e-01, time/batch = 16.7014s	
7633/22300 (epoch 17.114), train_loss = 0.87231988, grad/param norm = 2.9493e-01, time/batch = 15.9035s	
7634/22300 (epoch 17.117), train_loss = 1.00328504, grad/param norm = 3.0177e-01, time/batch = 15.7882s	
7635/22300 (epoch 17.119), train_loss = 0.93577054, grad/param norm = 3.0173e-01, time/batch = 16.0310s	
7636/22300 (epoch 17.121), train_loss = 0.98383471, grad/param norm = 3.2537e-01, time/batch = 17.0391s	
7637/22300 (epoch 17.123), train_loss = 0.92772243, grad/param norm = 2.7534e-01, time/batch = 16.7169s	
7638/22300 (epoch 17.126), train_loss = 0.81551299, grad/param norm = 2.6888e-01, time/batch = 15.6310s	
7639/22300 (epoch 17.128), train_loss = 0.89328883, grad/param norm = 2.6752e-01, time/batch = 18.3748s	
7640/22300 (epoch 17.130), train_loss = 0.70908873, grad/param norm = 2.5593e-01, time/batch = 16.7921s	
7641/22300 (epoch 17.132), train_loss = 0.61504162, grad/param norm = 2.4771e-01, time/batch = 17.6146s	
7642/22300 (epoch 17.135), train_loss = 0.66722659, grad/param norm = 2.4961e-01, time/batch = 16.2868s	
7643/22300 (epoch 17.137), train_loss = 0.52682702, grad/param norm = 2.1136e-01, time/batch = 18.3841s	
7644/22300 (epoch 17.139), train_loss = 0.82850696, grad/param norm = 2.8022e-01, time/batch = 16.5083s	
7645/22300 (epoch 17.141), train_loss = 0.87053793, grad/param norm = 2.5340e-01, time/batch = 15.1872s	
7646/22300 (epoch 17.143), train_loss = 0.81554875, grad/param norm = 2.8808e-01, time/batch = 16.8888s	
7647/22300 (epoch 17.146), train_loss = 0.92479481, grad/param norm = 2.9693e-01, time/batch = 15.6587s	
7648/22300 (epoch 17.148), train_loss = 0.67267374, grad/param norm = 2.7028e-01, time/batch = 15.7804s	
7649/22300 (epoch 17.150), train_loss = 0.73710601, grad/param norm = 2.4375e-01, time/batch = 16.0425s	
7650/22300 (epoch 17.152), train_loss = 0.64218229, grad/param norm = 2.6720e-01, time/batch = 18.1407s	
7651/22300 (epoch 17.155), train_loss = 0.68453702, grad/param norm = 2.6716e-01, time/batch = 17.2136s	
7652/22300 (epoch 17.157), train_loss = 0.86744787, grad/param norm = 2.9594e-01, time/batch = 15.7223s	
7653/22300 (epoch 17.159), train_loss = 0.87046839, grad/param norm = 2.9907e-01, time/batch = 16.0256s	
7654/22300 (epoch 17.161), train_loss = 0.91781159, grad/param norm = 3.4188e-01, time/batch = 16.2132s	
7655/22300 (epoch 17.164), train_loss = 0.65499554, grad/param norm = 2.3658e-01, time/batch = 16.3000s	
7656/22300 (epoch 17.166), train_loss = 0.64243398, grad/param norm = 2.5344e-01, time/batch = 15.4583s	
7657/22300 (epoch 17.168), train_loss = 0.67915905, grad/param norm = 2.6540e-01, time/batch = 16.3915s	
7658/22300 (epoch 17.170), train_loss = 0.80522663, grad/param norm = 2.6322e-01, time/batch = 15.6610s	
7659/22300 (epoch 17.173), train_loss = 0.93985542, grad/param norm = 3.1221e-01, time/batch = 18.1246s	
7660/22300 (epoch 17.175), train_loss = 0.76553866, grad/param norm = 2.5028e-01, time/batch = 17.0525s	
7661/22300 (epoch 17.177), train_loss = 0.60618728, grad/param norm = 2.3518e-01, time/batch = 17.9606s	
7662/22300 (epoch 17.179), train_loss = 0.74846214, grad/param norm = 2.3762e-01, time/batch = 16.7192s	
7663/22300 (epoch 17.182), train_loss = 0.94837219, grad/param norm = 2.8557e-01, time/batch = 16.2123s	
7664/22300 (epoch 17.184), train_loss = 1.04641533, grad/param norm = 3.1091e-01, time/batch = 16.1270s	
7665/22300 (epoch 17.186), train_loss = 0.83883209, grad/param norm = 2.9195e-01, time/batch = 15.9016s	
7666/22300 (epoch 17.188), train_loss = 1.03828158, grad/param norm = 3.0461e-01, time/batch = 17.6285s	
7667/22300 (epoch 17.191), train_loss = 0.99589785, grad/param norm = 3.0171e-01, time/batch = 15.3911s	
7668/22300 (epoch 17.193), train_loss = 0.82246760, grad/param norm = 3.0549e-01, time/batch = 15.2860s	
7669/22300 (epoch 17.195), train_loss = 0.74105141, grad/param norm = 2.4705e-01, time/batch = 15.7178s	
7670/22300 (epoch 17.197), train_loss = 0.76288027, grad/param norm = 2.9506e-01, time/batch = 17.1386s	
7671/22300 (epoch 17.200), train_loss = 0.67114494, grad/param norm = 2.5565e-01, time/batch = 16.7070s	
7672/22300 (epoch 17.202), train_loss = 0.74884292, grad/param norm = 2.5950e-01, time/batch = 16.8792s	
7673/22300 (epoch 17.204), train_loss = 0.75048039, grad/param norm = 2.8271e-01, time/batch = 15.3289s	
7674/22300 (epoch 17.206), train_loss = 0.67117211, grad/param norm = 2.3878e-01, time/batch = 15.9801s	
7675/22300 (epoch 17.209), train_loss = 0.76723892, grad/param norm = 2.7307e-01, time/batch = 18.2936s	
7676/22300 (epoch 17.211), train_loss = 0.60519914, grad/param norm = 2.3751e-01, time/batch = 15.4437s	
7677/22300 (epoch 17.213), train_loss = 0.74179761, grad/param norm = 2.5791e-01, time/batch = 18.2833s	
7678/22300 (epoch 17.215), train_loss = 0.96208707, grad/param norm = 3.2958e-01, time/batch = 15.8850s	
7679/22300 (epoch 17.217), train_loss = 0.90896196, grad/param norm = 3.3366e-01, time/batch = 17.6416s	
7680/22300 (epoch 17.220), train_loss = 0.78369270, grad/param norm = 2.9013e-01, time/batch = 17.6424s	
7681/22300 (epoch 17.222), train_loss = 0.70720698, grad/param norm = 2.8728e-01, time/batch = 15.6310s	
7682/22300 (epoch 17.224), train_loss = 0.70401492, grad/param norm = 2.6070e-01, time/batch = 19.2949s	
7683/22300 (epoch 17.226), train_loss = 0.75147735, grad/param norm = 2.4251e-01, time/batch = 16.6539s	
7684/22300 (epoch 17.229), train_loss = 0.71866513, grad/param norm = 2.9136e-01, time/batch = 17.7917s	
7685/22300 (epoch 17.231), train_loss = 0.86993139, grad/param norm = 3.1970e-01, time/batch = 15.1519s	
7686/22300 (epoch 17.233), train_loss = 0.82415235, grad/param norm = 3.0607e-01, time/batch = 17.5413s	
7687/22300 (epoch 17.235), train_loss = 0.60966073, grad/param norm = 2.5239e-01, time/batch = 15.0671s	
7688/22300 (epoch 17.238), train_loss = 0.62535208, grad/param norm = 2.1520e-01, time/batch = 16.3034s	
7689/22300 (epoch 17.240), train_loss = 0.63686724, grad/param norm = 2.3024e-01, time/batch = 16.7139s	
7690/22300 (epoch 17.242), train_loss = 0.67519456, grad/param norm = 2.8616e-01, time/batch = 15.5107s	
7691/22300 (epoch 17.244), train_loss = 0.49812396, grad/param norm = 2.4499e-01, time/batch = 17.7179s	
7692/22300 (epoch 17.247), train_loss = 0.63752930, grad/param norm = 2.6585e-01, time/batch = 15.5981s	
7693/22300 (epoch 17.249), train_loss = 0.50031779, grad/param norm = 2.1540e-01, time/batch = 17.7045s	
7694/22300 (epoch 17.251), train_loss = 0.65280050, grad/param norm = 2.4262e-01, time/batch = 16.3204s	
7695/22300 (epoch 17.253), train_loss = 0.52681323, grad/param norm = 2.2952e-01, time/batch = 16.8823s	
7696/22300 (epoch 17.256), train_loss = 0.61395758, grad/param norm = 2.3838e-01, time/batch = 15.4819s	
7697/22300 (epoch 17.258), train_loss = 0.88865442, grad/param norm = 2.7372e-01, time/batch = 16.3946s	
7698/22300 (epoch 17.260), train_loss = 0.74668617, grad/param norm = 2.6774e-01, time/batch = 18.2163s	
7699/22300 (epoch 17.262), train_loss = 0.64335492, grad/param norm = 2.4103e-01, time/batch = 15.8001s	
7700/22300 (epoch 17.265), train_loss = 0.62394996, grad/param norm = 2.3915e-01, time/batch = 17.2958s	
7701/22300 (epoch 17.267), train_loss = 0.69517566, grad/param norm = 2.3962e-01, time/batch = 17.7201s	
7702/22300 (epoch 17.269), train_loss = 0.76237425, grad/param norm = 3.0708e-01, time/batch = 15.4492s	
7703/22300 (epoch 17.271), train_loss = 0.76177619, grad/param norm = 2.4911e-01, time/batch = 16.9550s	
7704/22300 (epoch 17.274), train_loss = 0.57818699, grad/param norm = 2.2594e-01, time/batch = 17.3862s	
7705/22300 (epoch 17.276), train_loss = 0.53774723, grad/param norm = 2.1761e-01, time/batch = 17.6344s	
7706/22300 (epoch 17.278), train_loss = 0.50288573, grad/param norm = 2.2012e-01, time/batch = 15.5109s	
7707/22300 (epoch 17.280), train_loss = 0.67389337, grad/param norm = 2.7059e-01, time/batch = 15.4480s	
7708/22300 (epoch 17.283), train_loss = 0.47850677, grad/param norm = 1.6818e-01, time/batch = 16.7899s	
7709/22300 (epoch 17.285), train_loss = 0.63271160, grad/param norm = 2.6950e-01, time/batch = 16.8988s	
7710/22300 (epoch 17.287), train_loss = 0.76394184, grad/param norm = 2.9707e-01, time/batch = 15.4690s	
7711/22300 (epoch 17.289), train_loss = 0.63815885, grad/param norm = 2.3672e-01, time/batch = 17.4538s	
7712/22300 (epoch 17.291), train_loss = 0.67450756, grad/param norm = 2.5518e-01, time/batch = 17.5422s	
7713/22300 (epoch 17.294), train_loss = 0.59322580, grad/param norm = 2.3705e-01, time/batch = 15.9739s	
7714/22300 (epoch 17.296), train_loss = 0.79687340, grad/param norm = 2.9254e-01, time/batch = 15.9449s	
7715/22300 (epoch 17.298), train_loss = 0.85309640, grad/param norm = 2.7271e-01, time/batch = 17.5611s	
7716/22300 (epoch 17.300), train_loss = 0.91298582, grad/param norm = 2.9525e-01, time/batch = 16.1474s	
7717/22300 (epoch 17.303), train_loss = 0.70752884, grad/param norm = 2.9417e-01, time/batch = 16.1995s	
7718/22300 (epoch 17.305), train_loss = 0.73184544, grad/param norm = 3.0499e-01, time/batch = 16.1264s	
7719/22300 (epoch 17.307), train_loss = 0.66876409, grad/param norm = 2.3715e-01, time/batch = 16.8862s	
7720/22300 (epoch 17.309), train_loss = 0.62784211, grad/param norm = 2.4170e-01, time/batch = 16.9679s	
7721/22300 (epoch 17.312), train_loss = 0.57977976, grad/param norm = 2.2178e-01, time/batch = 17.4479s	
7722/22300 (epoch 17.314), train_loss = 0.65368954, grad/param norm = 2.6339e-01, time/batch = 16.3977s	
7723/22300 (epoch 17.316), train_loss = 0.68646108, grad/param norm = 2.8207e-01, time/batch = 19.4640s	
7724/22300 (epoch 17.318), train_loss = 0.72297053, grad/param norm = 2.5785e-01, time/batch = 15.0466s	
7725/22300 (epoch 17.321), train_loss = 0.82383117, grad/param norm = 2.8263e-01, time/batch = 17.2879s	
7726/22300 (epoch 17.323), train_loss = 0.63500714, grad/param norm = 2.2412e-01, time/batch = 16.0211s	
7727/22300 (epoch 17.325), train_loss = 0.58629101, grad/param norm = 2.3808e-01, time/batch = 18.2900s	
7728/22300 (epoch 17.327), train_loss = 0.60464671, grad/param norm = 2.5304e-01, time/batch = 17.3129s	
7729/22300 (epoch 17.330), train_loss = 0.66305870, grad/param norm = 3.0822e-01, time/batch = 16.0704s	
7730/22300 (epoch 17.332), train_loss = 0.62598644, grad/param norm = 2.8237e-01, time/batch = 16.4493s	
7731/22300 (epoch 17.334), train_loss = 0.61507690, grad/param norm = 2.3814e-01, time/batch = 15.7805s	
7732/22300 (epoch 17.336), train_loss = 0.65479266, grad/param norm = 2.3752e-01, time/batch = 16.2099s	
7733/22300 (epoch 17.339), train_loss = 0.74743560, grad/param norm = 3.1484e-01, time/batch = 14.8716s	
7734/22300 (epoch 17.341), train_loss = 0.79415485, grad/param norm = 3.2006e-01, time/batch = 17.8912s	
7735/22300 (epoch 17.343), train_loss = 0.87328521, grad/param norm = 3.1485e-01, time/batch = 17.0329s	
7736/22300 (epoch 17.345), train_loss = 0.70447439, grad/param norm = 2.8674e-01, time/batch = 16.3847s	
7737/22300 (epoch 17.348), train_loss = 0.72492364, grad/param norm = 2.6746e-01, time/batch = 16.2280s	
7738/22300 (epoch 17.350), train_loss = 0.58280731, grad/param norm = 2.4197e-01, time/batch = 17.0560s	
7739/22300 (epoch 17.352), train_loss = 0.78300826, grad/param norm = 2.5778e-01, time/batch = 16.3023s	
7740/22300 (epoch 17.354), train_loss = 0.96925860, grad/param norm = 3.3146e-01, time/batch = 17.1277s	
7741/22300 (epoch 17.357), train_loss = 0.82099130, grad/param norm = 2.6056e-01, time/batch = 14.7110s	
7742/22300 (epoch 17.359), train_loss = 0.64922886, grad/param norm = 2.6860e-01, time/batch = 15.4832s	
7743/22300 (epoch 17.361), train_loss = 0.65245960, grad/param norm = 2.4112e-01, time/batch = 17.6186s	
7744/22300 (epoch 17.363), train_loss = 0.87795547, grad/param norm = 2.9505e-01, time/batch = 14.9794s	
7745/22300 (epoch 17.365), train_loss = 0.72645719, grad/param norm = 2.8229e-01, time/batch = 19.0511s	
7746/22300 (epoch 17.368), train_loss = 0.72914737, grad/param norm = 3.0528e-01, time/batch = 16.0618s	
7747/22300 (epoch 17.370), train_loss = 0.74609332, grad/param norm = 3.2792e-01, time/batch = 18.6310s	
7748/22300 (epoch 17.372), train_loss = 0.61810510, grad/param norm = 2.8858e-01, time/batch = 18.7970s	
7749/22300 (epoch 17.374), train_loss = 0.52463337, grad/param norm = 2.4393e-01, time/batch = 15.1961s	
7750/22300 (epoch 17.377), train_loss = 0.70338133, grad/param norm = 3.0235e-01, time/batch = 16.4693s	
7751/22300 (epoch 17.379), train_loss = 0.69785603, grad/param norm = 2.7442e-01, time/batch = 15.9427s	
7752/22300 (epoch 17.381), train_loss = 0.84055863, grad/param norm = 2.8727e-01, time/batch = 16.2608s	
7753/22300 (epoch 17.383), train_loss = 0.68834922, grad/param norm = 2.9840e-01, time/batch = 15.6371s	
7754/22300 (epoch 17.386), train_loss = 0.70443521, grad/param norm = 2.7462e-01, time/batch = 15.7966s	
7755/22300 (epoch 17.388), train_loss = 0.62102024, grad/param norm = 3.1919e-01, time/batch = 15.3104s	
7756/22300 (epoch 17.390), train_loss = 0.73121106, grad/param norm = 2.9961e-01, time/batch = 17.1336s	
7757/22300 (epoch 17.392), train_loss = 0.70386060, grad/param norm = 2.9506e-01, time/batch = 15.7125s	
7758/22300 (epoch 17.395), train_loss = 0.59310130, grad/param norm = 2.6409e-01, time/batch = 17.7904s	
7759/22300 (epoch 17.397), train_loss = 0.42286436, grad/param norm = 2.0641e-01, time/batch = 17.0489s	
7760/22300 (epoch 17.399), train_loss = 0.58258940, grad/param norm = 2.5017e-01, time/batch = 16.3019s	
7761/22300 (epoch 17.401), train_loss = 0.69058249, grad/param norm = 3.2964e-01, time/batch = 16.0484s	
7762/22300 (epoch 17.404), train_loss = 0.66561828, grad/param norm = 2.8793e-01, time/batch = 16.3702s	
7763/22300 (epoch 17.406), train_loss = 0.95199078, grad/param norm = 3.2432e-01, time/batch = 16.7146s	
7764/22300 (epoch 17.408), train_loss = 0.80649914, grad/param norm = 2.8105e-01, time/batch = 16.0425s	
7765/22300 (epoch 17.410), train_loss = 0.80964441, grad/param norm = 2.7666e-01, time/batch = 17.6414s	
7766/22300 (epoch 17.413), train_loss = 0.67879942, grad/param norm = 2.6185e-01, time/batch = 15.2807s	
7767/22300 (epoch 17.415), train_loss = 0.57346010, grad/param norm = 2.7865e-01, time/batch = 16.8737s	
7768/22300 (epoch 17.417), train_loss = 0.72452492, grad/param norm = 2.5128e-01, time/batch = 15.7079s	
7769/22300 (epoch 17.419), train_loss = 0.64822662, grad/param norm = 2.2650e-01, time/batch = 17.6360s	
7770/22300 (epoch 17.422), train_loss = 0.65499394, grad/param norm = 2.7354e-01, time/batch = 16.3197s	
7771/22300 (epoch 17.424), train_loss = 0.72501096, grad/param norm = 2.7800e-01, time/batch = 15.1326s	
7772/22300 (epoch 17.426), train_loss = 0.59338577, grad/param norm = 2.8593e-01, time/batch = 18.0547s	
7773/22300 (epoch 17.428), train_loss = 0.61536446, grad/param norm = 2.4134e-01, time/batch = 16.7286s	
7774/22300 (epoch 17.430), train_loss = 0.71127573, grad/param norm = 2.9435e-01, time/batch = 15.9487s	
7775/22300 (epoch 17.433), train_loss = 0.68009414, grad/param norm = 2.6282e-01, time/batch = 15.4698s	
7776/22300 (epoch 17.435), train_loss = 0.71147758, grad/param norm = 2.7507e-01, time/batch = 15.8969s	
7777/22300 (epoch 17.437), train_loss = 0.72082972, grad/param norm = 3.0379e-01, time/batch = 17.6357s	
7778/22300 (epoch 17.439), train_loss = 0.75931710, grad/param norm = 2.9131e-01, time/batch = 16.6370s	
7779/22300 (epoch 17.442), train_loss = 0.72920029, grad/param norm = 2.6099e-01, time/batch = 15.4732s	
7780/22300 (epoch 17.444), train_loss = 0.65005443, grad/param norm = 2.5270e-01, time/batch = 16.3026s	
7781/22300 (epoch 17.446), train_loss = 0.58923539, grad/param norm = 2.5776e-01, time/batch = 17.3120s	
7782/22300 (epoch 17.448), train_loss = 0.48296625, grad/param norm = 2.1889e-01, time/batch = 15.7252s	
7783/22300 (epoch 17.451), train_loss = 0.76787189, grad/param norm = 2.6590e-01, time/batch = 17.4734s	
7784/22300 (epoch 17.453), train_loss = 0.63201846, grad/param norm = 2.3492e-01, time/batch = 15.7388s	
7785/22300 (epoch 17.455), train_loss = 0.85950322, grad/param norm = 3.1769e-01, time/batch = 15.5227s	
7786/22300 (epoch 17.457), train_loss = 0.84441127, grad/param norm = 3.0604e-01, time/batch = 16.7115s	
7787/22300 (epoch 17.460), train_loss = 0.78930236, grad/param norm = 2.9290e-01, time/batch = 17.0640s	
7788/22300 (epoch 17.462), train_loss = 0.85396666, grad/param norm = 2.6544e-01, time/batch = 18.4504s	
7789/22300 (epoch 17.464), train_loss = 0.74554678, grad/param norm = 2.5841e-01, time/batch = 16.0445s	
7790/22300 (epoch 17.466), train_loss = 0.67449761, grad/param norm = 2.3032e-01, time/batch = 15.3771s	
7791/22300 (epoch 17.469), train_loss = 0.62914979, grad/param norm = 2.1999e-01, time/batch = 16.3679s	
7792/22300 (epoch 17.471), train_loss = 0.78200307, grad/param norm = 2.4109e-01, time/batch = 17.6412s	
7793/22300 (epoch 17.473), train_loss = 0.76263788, grad/param norm = 2.5302e-01, time/batch = 16.2995s	
7794/22300 (epoch 17.475), train_loss = 0.66824142, grad/param norm = 2.5399e-01, time/batch = 17.2353s	
7795/22300 (epoch 17.478), train_loss = 0.69226946, grad/param norm = 2.5333e-01, time/batch = 17.6281s	
7796/22300 (epoch 17.480), train_loss = 0.49009255, grad/param norm = 2.0886e-01, time/batch = 15.5269s	
7797/22300 (epoch 17.482), train_loss = 0.54292234, grad/param norm = 2.3195e-01, time/batch = 17.7136s	
7798/22300 (epoch 17.484), train_loss = 0.69505867, grad/param norm = 2.8843e-01, time/batch = 15.5507s	
7799/22300 (epoch 17.487), train_loss = 0.73391473, grad/param norm = 2.5241e-01, time/batch = 16.9802s	
7800/22300 (epoch 17.489), train_loss = 0.78276238, grad/param norm = 2.8258e-01, time/batch = 15.0626s	
7801/22300 (epoch 17.491), train_loss = 0.77025510, grad/param norm = 2.6861e-01, time/batch = 16.7337s	
7802/22300 (epoch 17.493), train_loss = 0.74381004, grad/param norm = 3.2767e-01, time/batch = 17.6298s	
7803/22300 (epoch 17.496), train_loss = 0.63504576, grad/param norm = 2.0835e-01, time/batch = 15.0443s	
7804/22300 (epoch 17.498), train_loss = 0.55173473, grad/param norm = 2.4038e-01, time/batch = 14.8992s	
7805/22300 (epoch 17.500), train_loss = 0.71711716, grad/param norm = 2.5056e-01, time/batch = 17.1313s	
7806/22300 (epoch 17.502), train_loss = 0.52664686, grad/param norm = 2.6850e-01, time/batch = 18.9411s	
7807/22300 (epoch 17.504), train_loss = 0.56363463, grad/param norm = 2.2495e-01, time/batch = 16.7903s	
7808/22300 (epoch 17.507), train_loss = 0.61824998, grad/param norm = 2.5485e-01, time/batch = 16.3081s	
7809/22300 (epoch 17.509), train_loss = 0.76679166, grad/param norm = 2.9527e-01, time/batch = 15.7282s	
7810/22300 (epoch 17.511), train_loss = 0.51885277, grad/param norm = 2.4322e-01, time/batch = 16.7300s	
7811/22300 (epoch 17.513), train_loss = 0.51708829, grad/param norm = 2.1214e-01, time/batch = 16.2091s	
7812/22300 (epoch 17.516), train_loss = 0.59621337, grad/param norm = 2.4759e-01, time/batch = 15.9534s	
7813/22300 (epoch 17.518), train_loss = 0.78046918, grad/param norm = 2.8873e-01, time/batch = 17.8063s	
7814/22300 (epoch 17.520), train_loss = 0.68372935, grad/param norm = 2.9091e-01, time/batch = 15.7687s	
7815/22300 (epoch 17.522), train_loss = 0.61699492, grad/param norm = 2.4702e-01, time/batch = 17.7841s	
7816/22300 (epoch 17.525), train_loss = 0.57928907, grad/param norm = 2.4235e-01, time/batch = 15.8887s	
7817/22300 (epoch 17.527), train_loss = 0.81897796, grad/param norm = 3.1086e-01, time/batch = 18.6390s	
7818/22300 (epoch 17.529), train_loss = 0.67790478, grad/param norm = 2.8964e-01, time/batch = 15.0213s	
7819/22300 (epoch 17.531), train_loss = 0.63571503, grad/param norm = 2.3922e-01, time/batch = 16.5602s	
7820/22300 (epoch 17.534), train_loss = 0.61179213, grad/param norm = 2.4756e-01, time/batch = 18.2030s	
7821/22300 (epoch 17.536), train_loss = 0.85628598, grad/param norm = 2.6851e-01, time/batch = 17.4712s	
7822/22300 (epoch 17.538), train_loss = 1.04181640, grad/param norm = 3.0720e-01, time/batch = 14.9775s	
7823/22300 (epoch 17.540), train_loss = 0.71005108, grad/param norm = 2.7459e-01, time/batch = 16.3655s	
7824/22300 (epoch 17.543), train_loss = 0.59572353, grad/param norm = 2.4314e-01, time/batch = 19.4544s	
7825/22300 (epoch 17.545), train_loss = 0.55876513, grad/param norm = 2.7167e-01, time/batch = 30.3770s	
7826/22300 (epoch 17.547), train_loss = 0.53809978, grad/param norm = 2.4360e-01, time/batch = 15.6423s	
7827/22300 (epoch 17.549), train_loss = 0.58602064, grad/param norm = 2.6128e-01, time/batch = 15.7153s	
7828/22300 (epoch 17.552), train_loss = 0.62333138, grad/param norm = 2.6107e-01, time/batch = 15.2098s	
7829/22300 (epoch 17.554), train_loss = 0.72467625, grad/param norm = 3.0387e-01, time/batch = 16.7198s	
7830/22300 (epoch 17.556), train_loss = 0.95187538, grad/param norm = 3.2969e-01, time/batch = 17.2248s	
7831/22300 (epoch 17.558), train_loss = 0.77811259, grad/param norm = 2.9659e-01, time/batch = 16.1014s	
7832/22300 (epoch 17.561), train_loss = 0.94626963, grad/param norm = 3.3294e-01, time/batch = 16.3017s	
7833/22300 (epoch 17.563), train_loss = 0.79932736, grad/param norm = 2.8895e-01, time/batch = 15.8781s	
7834/22300 (epoch 17.565), train_loss = 0.64668858, grad/param norm = 2.6781e-01, time/batch = 18.1316s	
7835/22300 (epoch 17.567), train_loss = 0.66926384, grad/param norm = 2.5783e-01, time/batch = 15.4368s	
7836/22300 (epoch 17.570), train_loss = 0.91560757, grad/param norm = 3.3272e-01, time/batch = 17.2887s	
7837/22300 (epoch 17.572), train_loss = 0.85307309, grad/param norm = 2.8460e-01, time/batch = 16.1499s	
7838/22300 (epoch 17.574), train_loss = 0.67747301, grad/param norm = 2.4984e-01, time/batch = 16.9663s	
7839/22300 (epoch 17.576), train_loss = 0.56703011, grad/param norm = 2.0986e-01, time/batch = 15.9736s	
7840/22300 (epoch 17.578), train_loss = 0.40573208, grad/param norm = 2.0480e-01, time/batch = 16.8859s	
7841/22300 (epoch 17.581), train_loss = 0.56839591, grad/param norm = 2.3907e-01, time/batch = 16.5432s	
7842/22300 (epoch 17.583), train_loss = 0.57691857, grad/param norm = 2.3647e-01, time/batch = 16.1290s	
7843/22300 (epoch 17.585), train_loss = 0.85732159, grad/param norm = 3.4064e-01, time/batch = 16.6213s	
7844/22300 (epoch 17.587), train_loss = 0.98560228, grad/param norm = 3.4940e-01, time/batch = 15.0768s	
7845/22300 (epoch 17.590), train_loss = 0.93033310, grad/param norm = 3.5576e-01, time/batch = 17.5702s	
7846/22300 (epoch 17.592), train_loss = 1.00458960, grad/param norm = 3.0759e-01, time/batch = 15.3677s	
7847/22300 (epoch 17.594), train_loss = 0.98440490, grad/param norm = 3.0644e-01, time/batch = 18.5484s	
7848/22300 (epoch 17.596), train_loss = 0.63864082, grad/param norm = 2.4736e-01, time/batch = 16.7878s	
7849/22300 (epoch 17.599), train_loss = 0.54283438, grad/param norm = 2.2500e-01, time/batch = 16.2231s	
7850/22300 (epoch 17.601), train_loss = 0.62741228, grad/param norm = 2.6825e-01, time/batch = 16.3203s	
7851/22300 (epoch 17.603), train_loss = 0.70125708, grad/param norm = 2.7679e-01, time/batch = 16.0257s	
7852/22300 (epoch 17.605), train_loss = 0.64605314, grad/param norm = 2.5398e-01, time/batch = 18.8015s	
7853/22300 (epoch 17.608), train_loss = 0.97149723, grad/param norm = 3.2444e-01, time/batch = 15.2080s	
7854/22300 (epoch 17.610), train_loss = 0.97799786, grad/param norm = 3.3736e-01, time/batch = 16.7772s	
7855/22300 (epoch 17.612), train_loss = 0.82481687, grad/param norm = 3.2126e-01, time/batch = 18.0518s	
7856/22300 (epoch 17.614), train_loss = 0.86294834, grad/param norm = 3.2051e-01, time/batch = 17.7038s	
7857/22300 (epoch 17.617), train_loss = 0.78510091, grad/param norm = 2.6852e-01, time/batch = 15.5635s	
7858/22300 (epoch 17.619), train_loss = 0.99303310, grad/param norm = 2.8926e-01, time/batch = 15.8208s	
7859/22300 (epoch 17.621), train_loss = 0.68311271, grad/param norm = 2.4816e-01, time/batch = 17.6941s	
7860/22300 (epoch 17.623), train_loss = 0.63138998, grad/param norm = 2.3578e-01, time/batch = 15.2658s	
7861/22300 (epoch 17.626), train_loss = 0.61056787, grad/param norm = 2.3237e-01, time/batch = 17.3868s	
7862/22300 (epoch 17.628), train_loss = 0.60726294, grad/param norm = 2.2333e-01, time/batch = 15.4919s	
7863/22300 (epoch 17.630), train_loss = 0.67983910, grad/param norm = 2.4076e-01, time/batch = 16.6412s	
7864/22300 (epoch 17.632), train_loss = 0.69285768, grad/param norm = 2.6054e-01, time/batch = 16.4555s	
7865/22300 (epoch 17.635), train_loss = 0.66851986, grad/param norm = 2.5035e-01, time/batch = 17.3823s	
7866/22300 (epoch 17.637), train_loss = 0.81417353, grad/param norm = 2.7814e-01, time/batch = 18.3499s	
7867/22300 (epoch 17.639), train_loss = 0.88677550, grad/param norm = 3.5401e-01, time/batch = 17.3818s	
7868/22300 (epoch 17.641), train_loss = 0.75620066, grad/param norm = 2.8853e-01, time/batch = 15.3618s	
7869/22300 (epoch 17.643), train_loss = 0.69379029, grad/param norm = 2.9898e-01, time/batch = 16.2056s	
7870/22300 (epoch 17.646), train_loss = 0.62144334, grad/param norm = 2.6583e-01, time/batch = 18.3658s	
7871/22300 (epoch 17.648), train_loss = 0.64539118, grad/param norm = 2.4786e-01, time/batch = 16.1825s	
7872/22300 (epoch 17.650), train_loss = 0.76290560, grad/param norm = 2.9781e-01, time/batch = 17.6851s	
7873/22300 (epoch 17.652), train_loss = 0.65107412, grad/param norm = 2.6125e-01, time/batch = 15.4587s	
7874/22300 (epoch 17.655), train_loss = 0.66981903, grad/param norm = 2.8039e-01, time/batch = 16.8809s	
7875/22300 (epoch 17.657), train_loss = 0.73438797, grad/param norm = 2.8293e-01, time/batch = 15.6377s	
7876/22300 (epoch 17.659), train_loss = 0.63975078, grad/param norm = 2.8881e-01, time/batch = 16.2208s	
7877/22300 (epoch 17.661), train_loss = 0.51812159, grad/param norm = 2.1982e-01, time/batch = 17.3130s	
7878/22300 (epoch 17.664), train_loss = 0.61609739, grad/param norm = 2.2345e-01, time/batch = 15.9622s	
7879/22300 (epoch 17.666), train_loss = 0.73602174, grad/param norm = 2.5456e-01, time/batch = 15.2025s	
7880/22300 (epoch 17.668), train_loss = 0.62657848, grad/param norm = 2.6127e-01, time/batch = 17.2087s	
7881/22300 (epoch 17.670), train_loss = 0.76077168, grad/param norm = 2.7991e-01, time/batch = 17.5435s	
7882/22300 (epoch 17.673), train_loss = 0.81287583, grad/param norm = 2.9328e-01, time/batch = 15.4711s	
7883/22300 (epoch 17.675), train_loss = 0.89741886, grad/param norm = 2.8986e-01, time/batch = 17.3790s	
7884/22300 (epoch 17.677), train_loss = 0.92959481, grad/param norm = 3.3770e-01, time/batch = 16.1256s	
7885/22300 (epoch 17.679), train_loss = 0.78031562, grad/param norm = 3.0515e-01, time/batch = 16.1345s	
7886/22300 (epoch 17.682), train_loss = 0.75783197, grad/param norm = 2.9240e-01, time/batch = 15.7372s	
7887/22300 (epoch 17.684), train_loss = 0.74050069, grad/param norm = 2.5811e-01, time/batch = 15.6414s	
7888/22300 (epoch 17.686), train_loss = 0.75144909, grad/param norm = 2.6689e-01, time/batch = 19.1995s	
7889/22300 (epoch 17.688), train_loss = 0.72195754, grad/param norm = 2.9731e-01, time/batch = 15.1104s	
7890/22300 (epoch 17.691), train_loss = 0.66751279, grad/param norm = 2.5915e-01, time/batch = 18.1401s	
7891/22300 (epoch 17.693), train_loss = 0.61462026, grad/param norm = 2.3879e-01, time/batch = 17.7982s	
7892/22300 (epoch 17.695), train_loss = 0.55941365, grad/param norm = 2.3968e-01, time/batch = 17.2057s	
7893/22300 (epoch 17.697), train_loss = 0.61724918, grad/param norm = 2.6065e-01, time/batch = 14.7260s	
7894/22300 (epoch 17.700), train_loss = 0.62220931, grad/param norm = 2.6031e-01, time/batch = 16.9605s	
7895/22300 (epoch 17.702), train_loss = 0.64219873, grad/param norm = 2.4150e-01, time/batch = 18.7938s	
7896/22300 (epoch 17.704), train_loss = 0.75194061, grad/param norm = 3.0666e-01, time/batch = 15.0527s	
7897/22300 (epoch 17.706), train_loss = 0.63781149, grad/param norm = 2.9311e-01, time/batch = 15.0469s	
7898/22300 (epoch 17.709), train_loss = 0.53552074, grad/param norm = 2.2228e-01, time/batch = 16.5545s	
7899/22300 (epoch 17.711), train_loss = 0.56348877, grad/param norm = 2.8464e-01, time/batch = 16.7136s	
7900/22300 (epoch 17.713), train_loss = 0.72635293, grad/param norm = 2.6084e-01, time/batch = 16.2035s	
7901/22300 (epoch 17.715), train_loss = 0.70346702, grad/param norm = 2.6234e-01, time/batch = 16.5438s	
7902/22300 (epoch 17.717), train_loss = 0.88530662, grad/param norm = 2.8286e-01, time/batch = 17.8870s	
7903/22300 (epoch 17.720), train_loss = 0.62997340, grad/param norm = 2.6038e-01, time/batch = 15.8949s	
7904/22300 (epoch 17.722), train_loss = 0.72834524, grad/param norm = 2.8845e-01, time/batch = 15.4007s	
7905/22300 (epoch 17.724), train_loss = 0.79642341, grad/param norm = 3.1218e-01, time/batch = 16.2953s	
7906/22300 (epoch 17.726), train_loss = 0.66020559, grad/param norm = 2.7774e-01, time/batch = 18.0448s	
7907/22300 (epoch 17.729), train_loss = 0.68964568, grad/param norm = 2.7022e-01, time/batch = 15.8802s	
7908/22300 (epoch 17.731), train_loss = 0.86783563, grad/param norm = 3.1068e-01, time/batch = 15.5488s	
7909/22300 (epoch 17.733), train_loss = 0.88377904, grad/param norm = 2.8505e-01, time/batch = 17.0524s	
7910/22300 (epoch 17.735), train_loss = 0.92723482, grad/param norm = 3.3911e-01, time/batch = 15.3846s	
7911/22300 (epoch 17.738), train_loss = 0.72381705, grad/param norm = 3.1908e-01, time/batch = 16.3942s	
7912/22300 (epoch 17.740), train_loss = 0.61007440, grad/param norm = 2.6224e-01, time/batch = 16.4730s	
7913/22300 (epoch 17.742), train_loss = 0.69485900, grad/param norm = 2.6160e-01, time/batch = 17.4669s	
7914/22300 (epoch 17.744), train_loss = 1.00273247, grad/param norm = 3.4964e-01, time/batch = 16.1171s	
7915/22300 (epoch 17.747), train_loss = 0.78796281, grad/param norm = 2.6624e-01, time/batch = 15.0181s	
7916/22300 (epoch 17.749), train_loss = 1.06767908, grad/param norm = 4.0270e-01, time/batch = 16.0345s	
7917/22300 (epoch 17.751), train_loss = 0.89670970, grad/param norm = 3.5179e-01, time/batch = 18.7095s	
7918/22300 (epoch 17.753), train_loss = 0.94859590, grad/param norm = 3.5172e-01, time/batch = 15.7097s	
7919/22300 (epoch 17.756), train_loss = 0.80383177, grad/param norm = 3.0422e-01, time/batch = 16.4000s	
7920/22300 (epoch 17.758), train_loss = 0.76995288, grad/param norm = 2.6992e-01, time/batch = 15.9365s	
7921/22300 (epoch 17.760), train_loss = 0.76336463, grad/param norm = 2.8286e-01, time/batch = 17.1263s	
7922/22300 (epoch 17.762), train_loss = 0.75998958, grad/param norm = 2.9236e-01, time/batch = 15.4730s	
7923/22300 (epoch 17.765), train_loss = 0.76018657, grad/param norm = 2.6513e-01, time/batch = 16.9586s	
7924/22300 (epoch 17.767), train_loss = 0.81068549, grad/param norm = 3.2601e-01, time/batch = 15.8973s	
7925/22300 (epoch 17.769), train_loss = 0.72508891, grad/param norm = 2.7784e-01, time/batch = 15.3951s	
7926/22300 (epoch 17.771), train_loss = 0.82305335, grad/param norm = 3.1490e-01, time/batch = 16.0601s	
7927/22300 (epoch 17.774), train_loss = 0.87951504, grad/param norm = 3.5963e-01, time/batch = 16.1169s	
7928/22300 (epoch 17.776), train_loss = 0.91486394, grad/param norm = 3.0940e-01, time/batch = 16.4752s	
7929/22300 (epoch 17.778), train_loss = 0.90034959, grad/param norm = 3.2395e-01, time/batch = 15.1360s	
7930/22300 (epoch 17.780), train_loss = 0.85309944, grad/param norm = 2.6969e-01, time/batch = 16.8166s	
7931/22300 (epoch 17.783), train_loss = 0.94477988, grad/param norm = 3.3638e-01, time/batch = 16.2244s	
7932/22300 (epoch 17.785), train_loss = 0.70163485, grad/param norm = 2.7453e-01, time/batch = 16.4589s	
7933/22300 (epoch 17.787), train_loss = 0.69934097, grad/param norm = 2.8238e-01, time/batch = 18.0929s	
7934/22300 (epoch 17.789), train_loss = 0.90803561, grad/param norm = 3.0415e-01, time/batch = 17.3478s	
7935/22300 (epoch 17.791), train_loss = 1.07080361, grad/param norm = 3.5119e-01, time/batch = 16.8087s	
7936/22300 (epoch 17.794), train_loss = 0.91451075, grad/param norm = 3.4647e-01, time/batch = 15.5402s	
7937/22300 (epoch 17.796), train_loss = 0.89554602, grad/param norm = 3.0873e-01, time/batch = 16.3898s	
7938/22300 (epoch 17.798), train_loss = 1.00633091, grad/param norm = 3.1763e-01, time/batch = 18.0278s	
7939/22300 (epoch 17.800), train_loss = 0.72708459, grad/param norm = 2.6038e-01, time/batch = 17.0510s	
7940/22300 (epoch 17.803), train_loss = 0.68771164, grad/param norm = 2.5791e-01, time/batch = 16.1422s	
7941/22300 (epoch 17.805), train_loss = 0.80556718, grad/param norm = 2.9349e-01, time/batch = 15.9695s	
7942/22300 (epoch 17.807), train_loss = 0.93516360, grad/param norm = 3.5432e-01, time/batch = 18.2140s	
7943/22300 (epoch 17.809), train_loss = 0.75408184, grad/param norm = 3.3134e-01, time/batch = 14.9728s	
7944/22300 (epoch 17.812), train_loss = 0.88216039, grad/param norm = 3.0686e-01, time/batch = 17.2341s	
7945/22300 (epoch 17.814), train_loss = 0.83054332, grad/param norm = 2.7696e-01, time/batch = 14.9664s	
7946/22300 (epoch 17.816), train_loss = 0.85401825, grad/param norm = 2.8918e-01, time/batch = 15.7040s	
7947/22300 (epoch 17.818), train_loss = 0.92556276, grad/param norm = 3.1561e-01, time/batch = 15.7976s	
7948/22300 (epoch 17.821), train_loss = 0.85169640, grad/param norm = 3.3753e-01, time/batch = 18.3767s	
7949/22300 (epoch 17.823), train_loss = 0.59427445, grad/param norm = 2.6618e-01, time/batch = 16.4657s	
7950/22300 (epoch 17.825), train_loss = 0.72326309, grad/param norm = 2.7840e-01, time/batch = 17.8604s	
7951/22300 (epoch 17.827), train_loss = 0.72581453, grad/param norm = 2.8464e-01, time/batch = 16.5570s	
7952/22300 (epoch 17.830), train_loss = 0.66891006, grad/param norm = 2.8644e-01, time/batch = 16.3688s	
7953/22300 (epoch 17.832), train_loss = 0.67181834, grad/param norm = 2.8337e-01, time/batch = 17.6409s	
7954/22300 (epoch 17.834), train_loss = 0.64957886, grad/param norm = 2.7073e-01, time/batch = 16.3126s	
7955/22300 (epoch 17.836), train_loss = 0.75419701, grad/param norm = 2.8609e-01, time/batch = 18.3678s	
7956/22300 (epoch 17.839), train_loss = 0.71081707, grad/param norm = 2.9024e-01, time/batch = 16.4503s	
7957/22300 (epoch 17.841), train_loss = 0.75550144, grad/param norm = 3.0868e-01, time/batch = 16.3919s	
7958/22300 (epoch 17.843), train_loss = 0.75521140, grad/param norm = 2.9686e-01, time/batch = 16.6390s	
7959/22300 (epoch 17.845), train_loss = 0.72204959, grad/param norm = 2.6383e-01, time/batch = 16.9644s	
7960/22300 (epoch 17.848), train_loss = 0.74742844, grad/param norm = 2.8977e-01, time/batch = 16.5616s	
7961/22300 (epoch 17.850), train_loss = 0.72039294, grad/param norm = 2.4131e-01, time/batch = 16.8741s	
7962/22300 (epoch 17.852), train_loss = 0.74681366, grad/param norm = 3.3414e-01, time/batch = 16.5189s	
7963/22300 (epoch 17.854), train_loss = 0.96704182, grad/param norm = 3.4093e-01, time/batch = 15.8812s	
7964/22300 (epoch 17.857), train_loss = 0.77535651, grad/param norm = 3.2765e-01, time/batch = 17.5307s	
7965/22300 (epoch 17.859), train_loss = 0.61002623, grad/param norm = 2.4145e-01, time/batch = 16.1485s	
7966/22300 (epoch 17.861), train_loss = 0.78000321, grad/param norm = 2.5097e-01, time/batch = 17.2140s	
7967/22300 (epoch 17.863), train_loss = 0.59310217, grad/param norm = 2.3137e-01, time/batch = 17.0598s	
7968/22300 (epoch 17.865), train_loss = 0.61165079, grad/param norm = 2.2257e-01, time/batch = 15.2609s	
7969/22300 (epoch 17.868), train_loss = 0.74304196, grad/param norm = 2.5550e-01, time/batch = 15.6467s	
7970/22300 (epoch 17.870), train_loss = 0.80134564, grad/param norm = 3.0241e-01, time/batch = 15.7068s	
7971/22300 (epoch 17.872), train_loss = 0.84376255, grad/param norm = 2.6295e-01, time/batch = 17.2983s	
7972/22300 (epoch 17.874), train_loss = 0.76923315, grad/param norm = 3.2067e-01, time/batch = 15.4316s	
7973/22300 (epoch 17.877), train_loss = 0.78427530, grad/param norm = 2.9354e-01, time/batch = 16.4655s	
7974/22300 (epoch 17.879), train_loss = 0.68678932, grad/param norm = 2.6824e-01, time/batch = 16.3944s	
7975/22300 (epoch 17.881), train_loss = 0.66740585, grad/param norm = 2.5038e-01, time/batch = 17.8745s	
7976/22300 (epoch 17.883), train_loss = 0.65260861, grad/param norm = 2.6150e-01, time/batch = 16.8789s	
7977/22300 (epoch 17.886), train_loss = 0.64824477, grad/param norm = 2.5802e-01, time/batch = 15.3061s	
7978/22300 (epoch 17.888), train_loss = 0.70203093, grad/param norm = 2.6909e-01, time/batch = 17.7189s	
7979/22300 (epoch 17.890), train_loss = 0.65450482, grad/param norm = 2.3383e-01, time/batch = 15.7830s	
7980/22300 (epoch 17.892), train_loss = 0.92547818, grad/param norm = 2.8083e-01, time/batch = 15.3141s	
7981/22300 (epoch 17.895), train_loss = 0.93783699, grad/param norm = 3.1172e-01, time/batch = 18.5417s	
7982/22300 (epoch 17.897), train_loss = 0.76483943, grad/param norm = 3.0897e-01, time/batch = 16.7153s	
7983/22300 (epoch 17.899), train_loss = 0.78234962, grad/param norm = 2.6353e-01, time/batch = 14.8735s	
7984/22300 (epoch 17.901), train_loss = 0.73282959, grad/param norm = 2.8731e-01, time/batch = 16.4860s	
7985/22300 (epoch 17.904), train_loss = 0.82352302, grad/param norm = 2.8659e-01, time/batch = 15.8084s	
7986/22300 (epoch 17.906), train_loss = 0.79610668, grad/param norm = 2.6214e-01, time/batch = 15.7989s	
7987/22300 (epoch 17.908), train_loss = 0.74027969, grad/param norm = 2.5737e-01, time/batch = 14.6177s	
7988/22300 (epoch 17.910), train_loss = 0.60412756, grad/param norm = 2.4517e-01, time/batch = 16.1505s	
7989/22300 (epoch 17.913), train_loss = 0.82812923, grad/param norm = 2.7442e-01, time/batch = 16.5471s	
7990/22300 (epoch 17.915), train_loss = 0.93397004, grad/param norm = 2.9977e-01, time/batch = 15.0468s	
7991/22300 (epoch 17.917), train_loss = 0.77404437, grad/param norm = 3.1131e-01, time/batch = 16.5611s	
7992/22300 (epoch 17.919), train_loss = 0.81225369, grad/param norm = 2.6111e-01, time/batch = 16.2266s	
7993/22300 (epoch 17.922), train_loss = 0.71577492, grad/param norm = 2.7583e-01, time/batch = 18.2969s	
7994/22300 (epoch 17.924), train_loss = 0.52413036, grad/param norm = 2.4659e-01, time/batch = 15.7193s	
7995/22300 (epoch 17.926), train_loss = 0.60698650, grad/param norm = 2.5769e-01, time/batch = 17.7699s	
7996/22300 (epoch 17.928), train_loss = 0.71121964, grad/param norm = 2.6285e-01, time/batch = 16.2976s	
7997/22300 (epoch 17.930), train_loss = 0.69359854, grad/param norm = 2.5241e-01, time/batch = 14.6269s	
7998/22300 (epoch 17.933), train_loss = 0.78750104, grad/param norm = 2.7095e-01, time/batch = 15.9678s	
7999/22300 (epoch 17.935), train_loss = 0.82523789, grad/param norm = 2.9736e-01, time/batch = 18.0491s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch17.94_1.5318.t7	
8000/22300 (epoch 17.937), train_loss = 0.94515594, grad/param norm = 3.3423e-01, time/batch = 16.8027s	
8001/22300 (epoch 17.939), train_loss = 1.47217586, grad/param norm = 4.4163e-01, time/batch = 16.5584s	
8002/22300 (epoch 17.942), train_loss = 1.00930560, grad/param norm = 3.2356e-01, time/batch = 16.7034s	
8003/22300 (epoch 17.944), train_loss = 1.05554887, grad/param norm = 3.3401e-01, time/batch = 15.7778s	
8004/22300 (epoch 17.946), train_loss = 0.77017775, grad/param norm = 3.0349e-01, time/batch = 18.4544s	
8005/22300 (epoch 17.948), train_loss = 0.67416185, grad/param norm = 2.7113e-01, time/batch = 17.8858s	
8006/22300 (epoch 17.951), train_loss = 0.61280768, grad/param norm = 2.4801e-01, time/batch = 16.1365s	
8007/22300 (epoch 17.953), train_loss = 0.67079899, grad/param norm = 3.0581e-01, time/batch = 17.3782s	
8008/22300 (epoch 17.955), train_loss = 0.97438196, grad/param norm = 3.2617e-01, time/batch = 16.5168s	
8009/22300 (epoch 17.957), train_loss = 1.04436615, grad/param norm = 3.2871e-01, time/batch = 18.4431s	
8010/22300 (epoch 17.960), train_loss = 0.90809948, grad/param norm = 3.1352e-01, time/batch = 17.8046s	
8011/22300 (epoch 17.962), train_loss = 0.75481495, grad/param norm = 2.7960e-01, time/batch = 17.0439s	
8012/22300 (epoch 17.964), train_loss = 0.75144842, grad/param norm = 2.8164e-01, time/batch = 20.1978s	
8013/22300 (epoch 17.966), train_loss = 0.67004673, grad/param norm = 2.9851e-01, time/batch = 15.2056s	
8014/22300 (epoch 17.969), train_loss = 0.72474706, grad/param norm = 2.4845e-01, time/batch = 18.4694s	
8015/22300 (epoch 17.971), train_loss = 0.76443266, grad/param norm = 2.8473e-01, time/batch = 17.0644s	
8016/22300 (epoch 17.973), train_loss = 0.77987479, grad/param norm = 2.9695e-01, time/batch = 17.5304s	
8017/22300 (epoch 17.975), train_loss = 0.94345966, grad/param norm = 3.1182e-01, time/batch = 16.0292s	
8018/22300 (epoch 17.978), train_loss = 0.82225888, grad/param norm = 2.8727e-01, time/batch = 16.2288s	
8019/22300 (epoch 17.980), train_loss = 0.88423553, grad/param norm = 2.9726e-01, time/batch = 16.2076s	
8020/22300 (epoch 17.982), train_loss = 0.65569513, grad/param norm = 2.6049e-01, time/batch = 16.1459s	
8021/22300 (epoch 17.984), train_loss = 0.78947177, grad/param norm = 2.6778e-01, time/batch = 18.3736s	
8022/22300 (epoch 17.987), train_loss = 0.70489835, grad/param norm = 2.9971e-01, time/batch = 16.7237s	
8023/22300 (epoch 17.989), train_loss = 0.72918807, grad/param norm = 2.6021e-01, time/batch = 16.5470s	
8024/22300 (epoch 17.991), train_loss = 1.01173865, grad/param norm = 3.5153e-01, time/batch = 16.0645s	
8025/22300 (epoch 17.993), train_loss = 1.21096698, grad/param norm = 3.6950e-01, time/batch = 17.2210s	
8026/22300 (epoch 17.996), train_loss = 1.08033500, grad/param norm = 3.4587e-01, time/batch = 15.5746s	
8027/22300 (epoch 17.998), train_loss = 0.77100372, grad/param norm = 2.8082e-01, time/batch = 15.4734s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
8028/22300 (epoch 18.000), train_loss = 0.65785364, grad/param norm = 2.8989e-01, time/batch = 15.7084s	
8029/22300 (epoch 18.002), train_loss = 1.06625118, grad/param norm = 3.4899e-01, time/batch = 16.0533s	
8030/22300 (epoch 18.004), train_loss = 0.76980358, grad/param norm = 2.6670e-01, time/batch = 18.9516s	
8031/22300 (epoch 18.007), train_loss = 0.80148249, grad/param norm = 2.9249e-01, time/batch = 16.2220s	
8032/22300 (epoch 18.009), train_loss = 0.79110104, grad/param norm = 2.9718e-01, time/batch = 15.4257s	
8033/22300 (epoch 18.011), train_loss = 0.96773581, grad/param norm = 3.3464e-01, time/batch = 17.6211s	
8034/22300 (epoch 18.013), train_loss = 0.78199222, grad/param norm = 2.8854e-01, time/batch = 22.4640s	
8035/22300 (epoch 18.016), train_loss = 0.68341466, grad/param norm = 2.8360e-01, time/batch = 25.4464s	
8036/22300 (epoch 18.018), train_loss = 0.85924935, grad/param norm = 3.0841e-01, time/batch = 16.7162s	
8037/22300 (epoch 18.020), train_loss = 0.71851719, grad/param norm = 3.0237e-01, time/batch = 15.1843s	
8038/22300 (epoch 18.022), train_loss = 0.67854979, grad/param norm = 2.7817e-01, time/batch = 15.4695s	
8039/22300 (epoch 18.025), train_loss = 0.65977232, grad/param norm = 2.8199e-01, time/batch = 19.0401s	
8040/22300 (epoch 18.027), train_loss = 0.68336835, grad/param norm = 2.3436e-01, time/batch = 18.3605s	
8041/22300 (epoch 18.029), train_loss = 0.67496248, grad/param norm = 2.5393e-01, time/batch = 16.4793s	
8042/22300 (epoch 18.031), train_loss = 0.66659288, grad/param norm = 2.2942e-01, time/batch = 15.9469s	
8043/22300 (epoch 18.034), train_loss = 0.68817250, grad/param norm = 2.3928e-01, time/batch = 16.0633s	
8044/22300 (epoch 18.036), train_loss = 0.53594516, grad/param norm = 2.3349e-01, time/batch = 15.8045s	
8045/22300 (epoch 18.038), train_loss = 0.69101950, grad/param norm = 2.7196e-01, time/batch = 15.2366s	
8046/22300 (epoch 18.040), train_loss = 0.73474899, grad/param norm = 2.6551e-01, time/batch = 17.8914s	
8047/22300 (epoch 18.043), train_loss = 0.98013977, grad/param norm = 3.0083e-01, time/batch = 17.1222s	
8048/22300 (epoch 18.045), train_loss = 0.78713904, grad/param norm = 2.4164e-01, time/batch = 16.0374s	
8049/22300 (epoch 18.047), train_loss = 0.85132039, grad/param norm = 2.9330e-01, time/batch = 17.0497s	
8050/22300 (epoch 18.049), train_loss = 0.71536323, grad/param norm = 3.1642e-01, time/batch = 16.8135s	
8051/22300 (epoch 18.052), train_loss = 0.81128577, grad/param norm = 2.9145e-01, time/batch = 17.5340s	
8052/22300 (epoch 18.054), train_loss = 0.77821146, grad/param norm = 2.7153e-01, time/batch = 16.4678s	
8053/22300 (epoch 18.056), train_loss = 0.50063497, grad/param norm = 2.0143e-01, time/batch = 15.7134s	
8054/22300 (epoch 18.058), train_loss = 0.67339970, grad/param norm = 2.6233e-01, time/batch = 16.5560s	
8055/22300 (epoch 18.061), train_loss = 0.65684728, grad/param norm = 2.9019e-01, time/batch = 15.3100s	
8056/22300 (epoch 18.063), train_loss = 0.96852737, grad/param norm = 4.2808e-01, time/batch = 17.7270s	
8057/22300 (epoch 18.065), train_loss = 0.90033893, grad/param norm = 3.1071e-01, time/batch = 16.9611s	
8058/22300 (epoch 18.067), train_loss = 0.70835091, grad/param norm = 2.9940e-01, time/batch = 16.6424s	
8059/22300 (epoch 18.070), train_loss = 0.75024636, grad/param norm = 3.1191e-01, time/batch = 15.8051s	
8060/22300 (epoch 18.072), train_loss = 0.82341789, grad/param norm = 2.9156e-01, time/batch = 17.3844s	
8061/22300 (epoch 18.074), train_loss = 0.81983250, grad/param norm = 2.9590e-01, time/batch = 18.1221s	
8062/22300 (epoch 18.076), train_loss = 0.74233251, grad/param norm = 2.8395e-01, time/batch = 16.0432s	
8063/22300 (epoch 18.078), train_loss = 0.84787623, grad/param norm = 2.8589e-01, time/batch = 15.7430s	
8064/22300 (epoch 18.081), train_loss = 0.86812941, grad/param norm = 3.0422e-01, time/batch = 14.8725s	
8065/22300 (epoch 18.083), train_loss = 0.94778310, grad/param norm = 2.8723e-01, time/batch = 18.1463s	
8066/22300 (epoch 18.085), train_loss = 0.99172462, grad/param norm = 3.1459e-01, time/batch = 15.5186s	
8067/22300 (epoch 18.087), train_loss = 0.82293703, grad/param norm = 2.7040e-01, time/batch = 16.0689s	
8068/22300 (epoch 18.090), train_loss = 0.68470568, grad/param norm = 2.5950e-01, time/batch = 15.4570s	
8069/22300 (epoch 18.092), train_loss = 0.63099241, grad/param norm = 2.4907e-01, time/batch = 15.2664s	
8070/22300 (epoch 18.094), train_loss = 0.62867494, grad/param norm = 2.4550e-01, time/batch = 15.2887s	
8071/22300 (epoch 18.096), train_loss = 0.91725590, grad/param norm = 2.8758e-01, time/batch = 15.2911s	
8072/22300 (epoch 18.099), train_loss = 0.70050969, grad/param norm = 2.7053e-01, time/batch = 17.2167s	
8073/22300 (epoch 18.101), train_loss = 0.85560107, grad/param norm = 3.2457e-01, time/batch = 16.3101s	
8074/22300 (epoch 18.103), train_loss = 0.77544411, grad/param norm = 2.6797e-01, time/batch = 16.3929s	
8075/22300 (epoch 18.105), train_loss = 0.70175263, grad/param norm = 3.0024e-01, time/batch = 17.1381s	
8076/22300 (epoch 18.108), train_loss = 0.78969594, grad/param norm = 2.7267e-01, time/batch = 19.4468s	
8077/22300 (epoch 18.110), train_loss = 0.81934045, grad/param norm = 2.6613e-01, time/batch = 15.8157s	
8078/22300 (epoch 18.112), train_loss = 0.75789865, grad/param norm = 2.4650e-01, time/batch = 14.9082s	
8079/22300 (epoch 18.114), train_loss = 0.85059866, grad/param norm = 2.9839e-01, time/batch = 15.5481s	
8080/22300 (epoch 18.117), train_loss = 0.97002456, grad/param norm = 2.9897e-01, time/batch = 17.5323s	
8081/22300 (epoch 18.119), train_loss = 0.89398672, grad/param norm = 2.9602e-01, time/batch = 15.2049s	
8082/22300 (epoch 18.121), train_loss = 0.94453958, grad/param norm = 3.0112e-01, time/batch = 17.7278s	
8083/22300 (epoch 18.123), train_loss = 0.92544839, grad/param norm = 3.6611e-01, time/batch = 15.6090s	
8084/22300 (epoch 18.126), train_loss = 0.81755286, grad/param norm = 2.9280e-01, time/batch = 16.6315s	
8085/22300 (epoch 18.128), train_loss = 0.86304067, grad/param norm = 2.5533e-01, time/batch = 17.9621s	
8086/22300 (epoch 18.130), train_loss = 0.68021446, grad/param norm = 2.6022e-01, time/batch = 15.9002s	
8087/22300 (epoch 18.132), train_loss = 0.59456623, grad/param norm = 2.4495e-01, time/batch = 16.2326s	
8088/22300 (epoch 18.135), train_loss = 0.64175993, grad/param norm = 3.0002e-01, time/batch = 15.4637s	
8089/22300 (epoch 18.137), train_loss = 0.49642802, grad/param norm = 2.0570e-01, time/batch = 17.8920s	
8090/22300 (epoch 18.139), train_loss = 0.77426020, grad/param norm = 2.9488e-01, time/batch = 15.3361s	
8091/22300 (epoch 18.141), train_loss = 0.86494142, grad/param norm = 2.7223e-01, time/batch = 17.0445s	
8092/22300 (epoch 18.143), train_loss = 0.78043781, grad/param norm = 2.7202e-01, time/batch = 17.5406s	
8093/22300 (epoch 18.146), train_loss = 0.88654066, grad/param norm = 2.9754e-01, time/batch = 16.6422s	
8094/22300 (epoch 18.148), train_loss = 0.64147744, grad/param norm = 2.5178e-01, time/batch = 16.6238s	
8095/22300 (epoch 18.150), train_loss = 0.73117789, grad/param norm = 3.0095e-01, time/batch = 15.3814s	
8096/22300 (epoch 18.152), train_loss = 0.63388359, grad/param norm = 2.7359e-01, time/batch = 17.3794s	
8097/22300 (epoch 18.155), train_loss = 0.64568248, grad/param norm = 2.5642e-01, time/batch = 15.7133s	
8098/22300 (epoch 18.157), train_loss = 0.83333034, grad/param norm = 3.1107e-01, time/batch = 17.8738s	
8099/22300 (epoch 18.159), train_loss = 0.86103206, grad/param norm = 2.9486e-01, time/batch = 16.5566s	
8100/22300 (epoch 18.161), train_loss = 0.87185427, grad/param norm = 3.2503e-01, time/batch = 16.8027s	
8101/22300 (epoch 18.164), train_loss = 0.63157001, grad/param norm = 2.4703e-01, time/batch = 18.3771s	
8102/22300 (epoch 18.166), train_loss = 0.60756191, grad/param norm = 2.1974e-01, time/batch = 15.4382s	
8103/22300 (epoch 18.168), train_loss = 0.64793892, grad/param norm = 2.7351e-01, time/batch = 19.1097s	
8104/22300 (epoch 18.170), train_loss = 0.77867265, grad/param norm = 2.5513e-01, time/batch = 16.2431s	
8105/22300 (epoch 18.173), train_loss = 0.89634627, grad/param norm = 3.0568e-01, time/batch = 17.8632s	
8106/22300 (epoch 18.175), train_loss = 0.73379660, grad/param norm = 2.6478e-01, time/batch = 15.5016s	
8107/22300 (epoch 18.177), train_loss = 0.58219040, grad/param norm = 2.4253e-01, time/batch = 17.7938s	
8108/22300 (epoch 18.179), train_loss = 0.72145553, grad/param norm = 2.6214e-01, time/batch = 17.9661s	
8109/22300 (epoch 18.182), train_loss = 0.93087082, grad/param norm = 2.8706e-01, time/batch = 15.1560s	
8110/22300 (epoch 18.184), train_loss = 0.99900212, grad/param norm = 2.8386e-01, time/batch = 15.8146s	
8111/22300 (epoch 18.186), train_loss = 0.80697101, grad/param norm = 2.5933e-01, time/batch = 16.8112s	
8112/22300 (epoch 18.188), train_loss = 1.00996823, grad/param norm = 3.4107e-01, time/batch = 18.7837s	
8113/22300 (epoch 18.191), train_loss = 0.94231192, grad/param norm = 2.9927e-01, time/batch = 16.3032s	
8114/22300 (epoch 18.193), train_loss = 0.79264759, grad/param norm = 3.1316e-01, time/batch = 17.3806s	
8115/22300 (epoch 18.195), train_loss = 0.71846232, grad/param norm = 2.7192e-01, time/batch = 14.8216s	
8116/22300 (epoch 18.197), train_loss = 0.72155876, grad/param norm = 2.9806e-01, time/batch = 16.7298s	
8117/22300 (epoch 18.200), train_loss = 0.64714804, grad/param norm = 2.7384e-01, time/batch = 17.1477s	
8118/22300 (epoch 18.202), train_loss = 0.71191685, grad/param norm = 2.5813e-01, time/batch = 16.0651s	
8119/22300 (epoch 18.204), train_loss = 0.74096537, grad/param norm = 2.6401e-01, time/batch = 19.1998s	
8120/22300 (epoch 18.206), train_loss = 0.65876660, grad/param norm = 2.8215e-01, time/batch = 15.2990s	
8121/22300 (epoch 18.209), train_loss = 0.74183685, grad/param norm = 2.7928e-01, time/batch = 18.6358s	
8122/22300 (epoch 18.211), train_loss = 0.58188717, grad/param norm = 2.5206e-01, time/batch = 17.1407s	
8123/22300 (epoch 18.213), train_loss = 0.70932348, grad/param norm = 2.5040e-01, time/batch = 15.7825s	
8124/22300 (epoch 18.215), train_loss = 0.91914562, grad/param norm = 2.9468e-01, time/batch = 16.1344s	
8125/22300 (epoch 18.217), train_loss = 0.89891537, grad/param norm = 3.3667e-01, time/batch = 16.3855s	
8126/22300 (epoch 18.220), train_loss = 0.74169221, grad/param norm = 2.7539e-01, time/batch = 17.3720s	
8127/22300 (epoch 18.222), train_loss = 0.66320402, grad/param norm = 2.5716e-01, time/batch = 16.0596s	
8128/22300 (epoch 18.224), train_loss = 0.67798670, grad/param norm = 2.5520e-01, time/batch = 17.8858s	
8129/22300 (epoch 18.226), train_loss = 0.72248151, grad/param norm = 2.5401e-01, time/batch = 15.5622s	
8130/22300 (epoch 18.229), train_loss = 0.66113642, grad/param norm = 2.7684e-01, time/batch = 16.3119s	
8131/22300 (epoch 18.231), train_loss = 0.86126260, grad/param norm = 3.3497e-01, time/batch = 14.9523s	
8132/22300 (epoch 18.233), train_loss = 0.76046058, grad/param norm = 2.6780e-01, time/batch = 17.7032s	
8133/22300 (epoch 18.235), train_loss = 0.58696791, grad/param norm = 2.7247e-01, time/batch = 15.3524s	
8134/22300 (epoch 18.238), train_loss = 0.59752162, grad/param norm = 2.1533e-01, time/batch = 15.4007s	
8135/22300 (epoch 18.240), train_loss = 0.60933610, grad/param norm = 2.3492e-01, time/batch = 15.2422s	
8136/22300 (epoch 18.242), train_loss = 0.65492105, grad/param norm = 2.5623e-01, time/batch = 16.2160s	
8137/22300 (epoch 18.244), train_loss = 0.46378517, grad/param norm = 2.3362e-01, time/batch = 18.1359s	
8138/22300 (epoch 18.247), train_loss = 0.61260036, grad/param norm = 2.6224e-01, time/batch = 15.2223s	
8139/22300 (epoch 18.249), train_loss = 0.47066497, grad/param norm = 2.1770e-01, time/batch = 17.6392s	
8140/22300 (epoch 18.251), train_loss = 0.61279471, grad/param norm = 2.3378e-01, time/batch = 16.8735s	
8141/22300 (epoch 18.253), train_loss = 0.48813256, grad/param norm = 2.2025e-01, time/batch = 16.7569s	
8142/22300 (epoch 18.256), train_loss = 0.58374185, grad/param norm = 2.3876e-01, time/batch = 15.5598s	
8143/22300 (epoch 18.258), train_loss = 0.84286738, grad/param norm = 2.7085e-01, time/batch = 17.6376s	
8144/22300 (epoch 18.260), train_loss = 0.71922456, grad/param norm = 2.7243e-01, time/batch = 17.3855s	
8145/22300 (epoch 18.262), train_loss = 0.61326702, grad/param norm = 2.7673e-01, time/batch = 16.6242s	
8146/22300 (epoch 18.265), train_loss = 0.58681629, grad/param norm = 2.5092e-01, time/batch = 15.4060s	
8147/22300 (epoch 18.267), train_loss = 0.67327397, grad/param norm = 2.4606e-01, time/batch = 17.1451s	
8148/22300 (epoch 18.269), train_loss = 0.72309375, grad/param norm = 2.7369e-01, time/batch = 17.7033s	
8149/22300 (epoch 18.271), train_loss = 0.73907124, grad/param norm = 2.5196e-01, time/batch = 16.3839s	
8150/22300 (epoch 18.274), train_loss = 0.54791261, grad/param norm = 2.2993e-01, time/batch = 15.6363s	
8151/22300 (epoch 18.276), train_loss = 0.51688831, grad/param norm = 2.4696e-01, time/batch = 17.7849s	
8152/22300 (epoch 18.278), train_loss = 0.48275386, grad/param norm = 2.1474e-01, time/batch = 16.2220s	
8153/22300 (epoch 18.280), train_loss = 0.63454674, grad/param norm = 2.5712e-01, time/batch = 16.1288s	
8154/22300 (epoch 18.283), train_loss = 0.47243758, grad/param norm = 2.0352e-01, time/batch = 15.3138s	
8155/22300 (epoch 18.285), train_loss = 0.60863268, grad/param norm = 2.6307e-01, time/batch = 17.4664s	
8156/22300 (epoch 18.287), train_loss = 0.74478752, grad/param norm = 2.7460e-01, time/batch = 15.6306s	
8157/22300 (epoch 18.289), train_loss = 0.64254863, grad/param norm = 2.6386e-01, time/batch = 18.6349s	
8158/22300 (epoch 18.291), train_loss = 0.64244658, grad/param norm = 2.6438e-01, time/batch = 17.3926s	
8159/22300 (epoch 18.294), train_loss = 0.54951471, grad/param norm = 2.0623e-01, time/batch = 16.7185s	
8160/22300 (epoch 18.296), train_loss = 0.75302381, grad/param norm = 2.9970e-01, time/batch = 16.9742s	
8161/22300 (epoch 18.298), train_loss = 0.81697767, grad/param norm = 2.7772e-01, time/batch = 15.9093s	
8162/22300 (epoch 18.300), train_loss = 0.88734765, grad/param norm = 2.9857e-01, time/batch = 15.5117s	
8163/22300 (epoch 18.303), train_loss = 0.71274610, grad/param norm = 3.2797e-01, time/batch = 15.2621s	
8164/22300 (epoch 18.305), train_loss = 0.72335626, grad/param norm = 3.3986e-01, time/batch = 15.2961s	
8165/22300 (epoch 18.307), train_loss = 0.66903308, grad/param norm = 2.8503e-01, time/batch = 15.3243s	
8166/22300 (epoch 18.309), train_loss = 0.61718044, grad/param norm = 2.8217e-01, time/batch = 14.7535s	
8167/22300 (epoch 18.312), train_loss = 0.53534446, grad/param norm = 2.1689e-01, time/batch = 15.3260s	
8168/22300 (epoch 18.314), train_loss = 0.60230471, grad/param norm = 2.3946e-01, time/batch = 14.4703s	
8169/22300 (epoch 18.316), train_loss = 0.64532424, grad/param norm = 2.8693e-01, time/batch = 15.0546s	
8170/22300 (epoch 18.318), train_loss = 0.66781906, grad/param norm = 2.3336e-01, time/batch = 16.3996s	
8171/22300 (epoch 18.321), train_loss = 0.77462137, grad/param norm = 2.5430e-01, time/batch = 16.3679s	
8172/22300 (epoch 18.323), train_loss = 0.59524918, grad/param norm = 2.3161e-01, time/batch = 17.7126s	
8173/22300 (epoch 18.325), train_loss = 0.55633604, grad/param norm = 2.3254e-01, time/batch = 17.7733s	
8174/22300 (epoch 18.327), train_loss = 0.59034819, grad/param norm = 2.6787e-01, time/batch = 15.4702s	
8175/22300 (epoch 18.330), train_loss = 0.62163051, grad/param norm = 2.9809e-01, time/batch = 16.3145s	
8176/22300 (epoch 18.332), train_loss = 0.56426030, grad/param norm = 2.1768e-01, time/batch = 17.3077s	
8177/22300 (epoch 18.334), train_loss = 0.59634266, grad/param norm = 2.5442e-01, time/batch = 17.0327s	
8178/22300 (epoch 18.336), train_loss = 0.62004054, grad/param norm = 2.3718e-01, time/batch = 16.2642s	
8179/22300 (epoch 18.339), train_loss = 0.71779713, grad/param norm = 2.8524e-01, time/batch = 17.9552s	
8180/22300 (epoch 18.341), train_loss = 0.74679984, grad/param norm = 2.8515e-01, time/batch = 15.4757s	
8181/22300 (epoch 18.343), train_loss = 0.81513921, grad/param norm = 2.7608e-01, time/batch = 17.1321s	
8182/22300 (epoch 18.345), train_loss = 0.67755261, grad/param norm = 2.9757e-01, time/batch = 16.5550s	
8183/22300 (epoch 18.348), train_loss = 0.66340373, grad/param norm = 2.4553e-01, time/batch = 15.1920s	
8184/22300 (epoch 18.350), train_loss = 0.53866552, grad/param norm = 2.0721e-01, time/batch = 15.4865s	
8185/22300 (epoch 18.352), train_loss = 0.72475349, grad/param norm = 2.4180e-01, time/batch = 16.3917s	
8186/22300 (epoch 18.354), train_loss = 0.92513688, grad/param norm = 2.7961e-01, time/batch = 17.2707s	
8187/22300 (epoch 18.357), train_loss = 0.79027691, grad/param norm = 2.4373e-01, time/batch = 15.5394s	
8188/22300 (epoch 18.359), train_loss = 0.60629753, grad/param norm = 2.4304e-01, time/batch = 17.2195s	
8189/22300 (epoch 18.361), train_loss = 0.61740770, grad/param norm = 2.6692e-01, time/batch = 14.9006s	
8190/22300 (epoch 18.363), train_loss = 0.85490543, grad/param norm = 3.1461e-01, time/batch = 17.0511s	
8191/22300 (epoch 18.365), train_loss = 0.66937553, grad/param norm = 2.9880e-01, time/batch = 17.9662s	
8192/22300 (epoch 18.368), train_loss = 0.70855686, grad/param norm = 3.1806e-01, time/batch = 17.1135s	
8193/22300 (epoch 18.370), train_loss = 0.69286726, grad/param norm = 2.8507e-01, time/batch = 16.4799s	
8194/22300 (epoch 18.372), train_loss = 0.56850333, grad/param norm = 2.4798e-01, time/batch = 17.2233s	
8195/22300 (epoch 18.374), train_loss = 0.49144372, grad/param norm = 2.2297e-01, time/batch = 19.2960s	
8196/22300 (epoch 18.377), train_loss = 0.64641816, grad/param norm = 3.0427e-01, time/batch = 16.0095s	
8197/22300 (epoch 18.379), train_loss = 0.64943788, grad/param norm = 2.8668e-01, time/batch = 16.5677s	
8198/22300 (epoch 18.381), train_loss = 0.80383908, grad/param norm = 2.8444e-01, time/batch = 15.9833s	
8199/22300 (epoch 18.383), train_loss = 0.66519078, grad/param norm = 2.9827e-01, time/batch = 17.7771s	
8200/22300 (epoch 18.386), train_loss = 0.67521450, grad/param norm = 2.8540e-01, time/batch = 16.5538s	
8201/22300 (epoch 18.388), train_loss = 0.59243564, grad/param norm = 2.6034e-01, time/batch = 16.9793s	
8202/22300 (epoch 18.390), train_loss = 0.72111528, grad/param norm = 2.7771e-01, time/batch = 18.2147s	
8203/22300 (epoch 18.392), train_loss = 0.64435669, grad/param norm = 2.6161e-01, time/batch = 15.8783s	
8204/22300 (epoch 18.395), train_loss = 0.56861563, grad/param norm = 2.6533e-01, time/batch = 15.2673s	
8205/22300 (epoch 18.397), train_loss = 0.38746912, grad/param norm = 1.9523e-01, time/batch = 15.0760s	
8206/22300 (epoch 18.399), train_loss = 0.56249306, grad/param norm = 2.6585e-01, time/batch = 18.1286s	
8207/22300 (epoch 18.401), train_loss = 0.65365445, grad/param norm = 2.8082e-01, time/batch = 16.9755s	
8208/22300 (epoch 18.404), train_loss = 0.63606188, grad/param norm = 2.5538e-01, time/batch = 18.5267s	
8209/22300 (epoch 18.406), train_loss = 0.91241686, grad/param norm = 3.1901e-01, time/batch = 15.6981s	
8210/22300 (epoch 18.408), train_loss = 0.78364926, grad/param norm = 2.6251e-01, time/batch = 17.2044s	
8211/22300 (epoch 18.410), train_loss = 0.79221480, grad/param norm = 2.8979e-01, time/batch = 17.7240s	
8212/22300 (epoch 18.413), train_loss = 0.65437129, grad/param norm = 2.8452e-01, time/batch = 16.4799s	
8213/22300 (epoch 18.415), train_loss = 0.52704664, grad/param norm = 2.5788e-01, time/batch = 17.1231s	
8214/22300 (epoch 18.417), train_loss = 0.69892053, grad/param norm = 2.8317e-01, time/batch = 16.7974s	
8215/22300 (epoch 18.419), train_loss = 0.60901385, grad/param norm = 2.2801e-01, time/batch = 16.4703s	
8216/22300 (epoch 18.422), train_loss = 0.63030298, grad/param norm = 2.8652e-01, time/batch = 16.4754s	
8217/22300 (epoch 18.424), train_loss = 0.70357090, grad/param norm = 2.8020e-01, time/batch = 15.8834s	
8218/22300 (epoch 18.426), train_loss = 0.54155915, grad/param norm = 2.6062e-01, time/batch = 15.0536s	
8219/22300 (epoch 18.428), train_loss = 0.60347931, grad/param norm = 2.7972e-01, time/batch = 16.0517s	
8220/22300 (epoch 18.430), train_loss = 0.67691198, grad/param norm = 2.8888e-01, time/batch = 16.6351s	
8221/22300 (epoch 18.433), train_loss = 0.64212784, grad/param norm = 2.3637e-01, time/batch = 15.5165s	
8222/22300 (epoch 18.435), train_loss = 0.66513102, grad/param norm = 2.8019e-01, time/batch = 17.2277s	
8223/22300 (epoch 18.437), train_loss = 0.68079823, grad/param norm = 2.6958e-01, time/batch = 15.8126s	
8224/22300 (epoch 18.439), train_loss = 0.70998906, grad/param norm = 2.5411e-01, time/batch = 17.3851s	
8225/22300 (epoch 18.442), train_loss = 0.69545873, grad/param norm = 2.6586e-01, time/batch = 15.7189s	
8226/22300 (epoch 18.444), train_loss = 0.60469088, grad/param norm = 2.2511e-01, time/batch = 18.6242s	
8227/22300 (epoch 18.446), train_loss = 0.55142815, grad/param norm = 2.3944e-01, time/batch = 17.0271s	
8228/22300 (epoch 18.448), train_loss = 0.43998216, grad/param norm = 2.0464e-01, time/batch = 15.5349s	
8229/22300 (epoch 18.451), train_loss = 0.72824525, grad/param norm = 2.9523e-01, time/batch = 17.8980s	
8230/22300 (epoch 18.453), train_loss = 0.61361441, grad/param norm = 2.4187e-01, time/batch = 18.1319s	
8231/22300 (epoch 18.455), train_loss = 0.83623562, grad/param norm = 3.3556e-01, time/batch = 16.9559s	
8232/22300 (epoch 18.457), train_loss = 0.82991055, grad/param norm = 3.0258e-01, time/batch = 3.4481s	
8233/22300 (epoch 18.460), train_loss = 0.75956030, grad/param norm = 2.8900e-01, time/batch = 0.6583s	
8234/22300 (epoch 18.462), train_loss = 0.82695961, grad/param norm = 2.7586e-01, time/batch = 0.6621s	
8235/22300 (epoch 18.464), train_loss = 0.70450433, grad/param norm = 2.7265e-01, time/batch = 0.6658s	
8236/22300 (epoch 18.466), train_loss = 0.65549742, grad/param norm = 2.8652e-01, time/batch = 0.6635s	
8237/22300 (epoch 18.469), train_loss = 0.62365558, grad/param norm = 2.5114e-01, time/batch = 0.6619s	
8238/22300 (epoch 18.471), train_loss = 0.76387383, grad/param norm = 2.5548e-01, time/batch = 0.6662s	
8239/22300 (epoch 18.473), train_loss = 0.74252162, grad/param norm = 2.8160e-01, time/batch = 0.7524s	
8240/22300 (epoch 18.475), train_loss = 0.63405196, grad/param norm = 2.6439e-01, time/batch = 0.9677s	
8241/22300 (epoch 18.478), train_loss = 0.67817865, grad/param norm = 2.9266e-01, time/batch = 0.9733s	
8242/22300 (epoch 18.480), train_loss = 0.46977079, grad/param norm = 2.3870e-01, time/batch = 0.9747s	
8243/22300 (epoch 18.482), train_loss = 0.51960981, grad/param norm = 2.5853e-01, time/batch = 0.9831s	
8244/22300 (epoch 18.484), train_loss = 0.67512363, grad/param norm = 2.6726e-01, time/batch = 1.1387s	
8245/22300 (epoch 18.487), train_loss = 0.69987600, grad/param norm = 2.3246e-01, time/batch = 1.8290s	
8246/22300 (epoch 18.489), train_loss = 0.72938919, grad/param norm = 2.5661e-01, time/batch = 1.8156s	
8247/22300 (epoch 18.491), train_loss = 0.74875891, grad/param norm = 3.3970e-01, time/batch = 9.2090s	
8248/22300 (epoch 18.493), train_loss = 0.69812562, grad/param norm = 3.0689e-01, time/batch = 16.5530s	
8249/22300 (epoch 18.496), train_loss = 0.62846307, grad/param norm = 2.1957e-01, time/batch = 16.5457s	
8250/22300 (epoch 18.498), train_loss = 0.51899104, grad/param norm = 2.3705e-01, time/batch = 16.5452s	
8251/22300 (epoch 18.500), train_loss = 0.71816028, grad/param norm = 2.7001e-01, time/batch = 15.9773s	
8252/22300 (epoch 18.502), train_loss = 0.49495755, grad/param norm = 2.7380e-01, time/batch = 16.0335s	
8253/22300 (epoch 18.504), train_loss = 0.52337661, grad/param norm = 2.0696e-01, time/batch = 16.3730s	
8254/22300 (epoch 18.507), train_loss = 0.58783376, grad/param norm = 2.5416e-01, time/batch = 18.0512s	
8255/22300 (epoch 18.509), train_loss = 0.74773273, grad/param norm = 2.8112e-01, time/batch = 15.0540s	
8256/22300 (epoch 18.511), train_loss = 0.48091075, grad/param norm = 2.1498e-01, time/batch = 17.9635s	
8257/22300 (epoch 18.513), train_loss = 0.50095757, grad/param norm = 2.2713e-01, time/batch = 15.8453s	
8258/22300 (epoch 18.516), train_loss = 0.56713835, grad/param norm = 2.5877e-01, time/batch = 15.8621s	
8259/22300 (epoch 18.518), train_loss = 0.74869363, grad/param norm = 2.6578e-01, time/batch = 17.1345s	
8260/22300 (epoch 18.520), train_loss = 0.65807507, grad/param norm = 2.6868e-01, time/batch = 16.3856s	
8261/22300 (epoch 18.522), train_loss = 0.60322126, grad/param norm = 2.5480e-01, time/batch = 17.3804s	
8262/22300 (epoch 18.525), train_loss = 0.54550931, grad/param norm = 2.2610e-01, time/batch = 17.3106s	
8263/22300 (epoch 18.527), train_loss = 0.78034270, grad/param norm = 3.4826e-01, time/batch = 17.6393s	
8264/22300 (epoch 18.529), train_loss = 0.65427166, grad/param norm = 2.7670e-01, time/batch = 29.2871s	
8265/22300 (epoch 18.531), train_loss = 0.60531920, grad/param norm = 2.4137e-01, time/batch = 14.4145s	
8266/22300 (epoch 18.534), train_loss = 0.58500676, grad/param norm = 2.4137e-01, time/batch = 17.0582s	
8267/22300 (epoch 18.536), train_loss = 0.83445914, grad/param norm = 2.6707e-01, time/batch = 16.2094s	
8268/22300 (epoch 18.538), train_loss = 1.01683082, grad/param norm = 3.1228e-01, time/batch = 17.3161s	
8269/22300 (epoch 18.540), train_loss = 0.66301723, grad/param norm = 2.5027e-01, time/batch = 16.9724s	
8270/22300 (epoch 18.543), train_loss = 0.56738547, grad/param norm = 2.3627e-01, time/batch = 15.8140s	
8271/22300 (epoch 18.545), train_loss = 0.54681900, grad/param norm = 3.0265e-01, time/batch = 15.9020s	
8272/22300 (epoch 18.547), train_loss = 0.49089312, grad/param norm = 2.1684e-01, time/batch = 16.0446s	
8273/22300 (epoch 18.549), train_loss = 0.55566979, grad/param norm = 2.3949e-01, time/batch = 18.6311s	
8274/22300 (epoch 18.552), train_loss = 0.58441208, grad/param norm = 2.6614e-01, time/batch = 15.5537s	
8275/22300 (epoch 18.554), train_loss = 0.68140027, grad/param norm = 2.7676e-01, time/batch = 15.5307s	
8276/22300 (epoch 18.556), train_loss = 0.91913609, grad/param norm = 3.4222e-01, time/batch = 15.8704s	
8277/22300 (epoch 18.558), train_loss = 0.74166866, grad/param norm = 2.8677e-01, time/batch = 17.2969s	
8278/22300 (epoch 18.561), train_loss = 0.89824181, grad/param norm = 3.3195e-01, time/batch = 17.2977s	
8279/22300 (epoch 18.563), train_loss = 0.79192303, grad/param norm = 3.3740e-01, time/batch = 18.2998s	
8280/22300 (epoch 18.565), train_loss = 0.63353839, grad/param norm = 3.0824e-01, time/batch = 17.1264s	
8281/22300 (epoch 18.567), train_loss = 0.64573932, grad/param norm = 2.4912e-01, time/batch = 15.7674s	
8282/22300 (epoch 18.570), train_loss = 0.88424481, grad/param norm = 3.2284e-01, time/batch = 15.2852s	
8283/22300 (epoch 18.572), train_loss = 0.80550006, grad/param norm = 2.9824e-01, time/batch = 16.9041s	
8284/22300 (epoch 18.574), train_loss = 0.65592485, grad/param norm = 2.4818e-01, time/batch = 17.6358s	
8285/22300 (epoch 18.576), train_loss = 0.54202052, grad/param norm = 2.3852e-01, time/batch = 17.2094s	
8286/22300 (epoch 18.578), train_loss = 0.38813179, grad/param norm = 2.1456e-01, time/batch = 16.2237s	
8287/22300 (epoch 18.581), train_loss = 0.53695527, grad/param norm = 2.3118e-01, time/batch = 18.1255s	
8288/22300 (epoch 18.583), train_loss = 0.54909786, grad/param norm = 2.3841e-01, time/batch = 15.8141s	
8289/22300 (epoch 18.585), train_loss = 0.82460331, grad/param norm = 3.1079e-01, time/batch = 16.7963s	
8290/22300 (epoch 18.587), train_loss = 0.93655123, grad/param norm = 3.1072e-01, time/batch = 15.8011s	
8291/22300 (epoch 18.590), train_loss = 0.87463848, grad/param norm = 3.4514e-01, time/batch = 18.2283s	
8292/22300 (epoch 18.592), train_loss = 0.96147330, grad/param norm = 3.0572e-01, time/batch = 15.9307s	
8293/22300 (epoch 18.594), train_loss = 0.96299021, grad/param norm = 3.2099e-01, time/batch = 16.3029s	
8294/22300 (epoch 18.596), train_loss = 0.61097388, grad/param norm = 2.5399e-01, time/batch = 16.9637s	
8295/22300 (epoch 18.599), train_loss = 0.52261466, grad/param norm = 3.2273e-01, time/batch = 17.2880s	
8296/22300 (epoch 18.601), train_loss = 0.60384475, grad/param norm = 2.7773e-01, time/batch = 16.0725s	
8297/22300 (epoch 18.603), train_loss = 0.67771842, grad/param norm = 2.6574e-01, time/batch = 17.2959s	
8298/22300 (epoch 18.605), train_loss = 0.62967821, grad/param norm = 2.8049e-01, time/batch = 16.2658s	
8299/22300 (epoch 18.608), train_loss = 0.95016483, grad/param norm = 3.3104e-01, time/batch = 16.0289s	
8300/22300 (epoch 18.610), train_loss = 0.92503068, grad/param norm = 3.0388e-01, time/batch = 16.5448s	
8301/22300 (epoch 18.612), train_loss = 0.79800657, grad/param norm = 3.2238e-01, time/batch = 15.8941s	
8302/22300 (epoch 18.614), train_loss = 0.83097472, grad/param norm = 3.5183e-01, time/batch = 17.0336s	
8303/22300 (epoch 18.617), train_loss = 0.75534828, grad/param norm = 2.9226e-01, time/batch = 15.2095s	
8304/22300 (epoch 18.619), train_loss = 0.95781082, grad/param norm = 3.2076e-01, time/batch = 16.3723s	
8305/22300 (epoch 18.621), train_loss = 0.66956244, grad/param norm = 2.5203e-01, time/batch = 17.1253s	
8306/22300 (epoch 18.623), train_loss = 0.61405872, grad/param norm = 2.3247e-01, time/batch = 17.3831s	
8307/22300 (epoch 18.626), train_loss = 0.57679406, grad/param norm = 2.3430e-01, time/batch = 16.7024s	
8308/22300 (epoch 18.628), train_loss = 0.57596263, grad/param norm = 2.1065e-01, time/batch = 16.6187s	
8309/22300 (epoch 18.630), train_loss = 0.66402268, grad/param norm = 2.3971e-01, time/batch = 17.7247s	
8310/22300 (epoch 18.632), train_loss = 0.66036261, grad/param norm = 2.6411e-01, time/batch = 16.0418s	
8311/22300 (epoch 18.635), train_loss = 0.65917517, grad/param norm = 2.6490e-01, time/batch = 17.4632s	
8312/22300 (epoch 18.637), train_loss = 0.78871391, grad/param norm = 2.8593e-01, time/batch = 16.7949s	
8313/22300 (epoch 18.639), train_loss = 0.85312618, grad/param norm = 3.8769e-01, time/batch = 14.6926s	
8314/22300 (epoch 18.641), train_loss = 0.73178238, grad/param norm = 2.8625e-01, time/batch = 14.3267s	
8315/22300 (epoch 18.643), train_loss = 0.63913063, grad/param norm = 2.6730e-01, time/batch = 15.8146s	
8316/22300 (epoch 18.646), train_loss = 0.59831159, grad/param norm = 2.5315e-01, time/batch = 15.5676s	
8317/22300 (epoch 18.648), train_loss = 0.62554368, grad/param norm = 2.4770e-01, time/batch = 16.2879s	
8318/22300 (epoch 18.650), train_loss = 0.74349502, grad/param norm = 2.8854e-01, time/batch = 14.7211s	
8319/22300 (epoch 18.652), train_loss = 0.61708306, grad/param norm = 2.5047e-01, time/batch = 16.9769s	
8320/22300 (epoch 18.655), train_loss = 0.61682948, grad/param norm = 2.5368e-01, time/batch = 15.8734s	
8321/22300 (epoch 18.657), train_loss = 0.68775833, grad/param norm = 2.7876e-01, time/batch = 16.2000s	
8322/22300 (epoch 18.659), train_loss = 0.59835108, grad/param norm = 2.5655e-01, time/batch = 17.3909s	
8323/22300 (epoch 18.661), train_loss = 0.49161277, grad/param norm = 2.1029e-01, time/batch = 16.7983s	
8324/22300 (epoch 18.664), train_loss = 0.59364172, grad/param norm = 2.3048e-01, time/batch = 16.6043s	
8325/22300 (epoch 18.666), train_loss = 0.69740505, grad/param norm = 2.4100e-01, time/batch = 15.8788s	
8326/22300 (epoch 18.668), train_loss = 0.58218991, grad/param norm = 2.5544e-01, time/batch = 17.0354s	
8327/22300 (epoch 18.670), train_loss = 0.72548053, grad/param norm = 2.7215e-01, time/batch = 17.2233s	
8328/22300 (epoch 18.673), train_loss = 0.78449285, grad/param norm = 3.0011e-01, time/batch = 17.2043s	
8329/22300 (epoch 18.675), train_loss = 0.87523053, grad/param norm = 3.3852e-01, time/batch = 14.6397s	
8330/22300 (epoch 18.677), train_loss = 0.90705657, grad/param norm = 3.2514e-01, time/batch = 15.8863s	
8331/22300 (epoch 18.679), train_loss = 0.73517205, grad/param norm = 3.0597e-01, time/batch = 18.2024s	
8332/22300 (epoch 18.682), train_loss = 0.72266586, grad/param norm = 3.0194e-01, time/batch = 16.1254s	
8333/22300 (epoch 18.684), train_loss = 0.71487371, grad/param norm = 2.6192e-01, time/batch = 16.5736s	
8334/22300 (epoch 18.686), train_loss = 0.70982600, grad/param norm = 2.6150e-01, time/batch = 18.8934s	
8335/22300 (epoch 18.688), train_loss = 0.69726885, grad/param norm = 3.0350e-01, time/batch = 15.3119s	
8336/22300 (epoch 18.691), train_loss = 0.63141486, grad/param norm = 2.6737e-01, time/batch = 16.3120s	
8337/22300 (epoch 18.693), train_loss = 0.58418144, grad/param norm = 2.6001e-01, time/batch = 15.3215s	
8338/22300 (epoch 18.695), train_loss = 0.52743692, grad/param norm = 2.4197e-01, time/batch = 16.9863s	
8339/22300 (epoch 18.697), train_loss = 0.56805518, grad/param norm = 2.4513e-01, time/batch = 14.9818s	
8340/22300 (epoch 18.700), train_loss = 0.59314171, grad/param norm = 2.6676e-01, time/batch = 16.9625s	
8341/22300 (epoch 18.702), train_loss = 0.59831336, grad/param norm = 2.2590e-01, time/batch = 16.7992s	
8342/22300 (epoch 18.704), train_loss = 0.71728383, grad/param norm = 3.0304e-01, time/batch = 15.8777s	
8343/22300 (epoch 18.706), train_loss = 0.58762438, grad/param norm = 2.6275e-01, time/batch = 17.3930s	
8344/22300 (epoch 18.709), train_loss = 0.49361296, grad/param norm = 2.1252e-01, time/batch = 16.1322s	
8345/22300 (epoch 18.711), train_loss = 0.52204499, grad/param norm = 2.5044e-01, time/batch = 15.0218s	
8346/22300 (epoch 18.713), train_loss = 0.69934231, grad/param norm = 2.7080e-01, time/batch = 17.0489s	
8347/22300 (epoch 18.715), train_loss = 0.66700865, grad/param norm = 2.4663e-01, time/batch = 16.1931s	
8348/22300 (epoch 18.717), train_loss = 0.86228533, grad/param norm = 2.7304e-01, time/batch = 16.1969s	
8349/22300 (epoch 18.720), train_loss = 0.59748211, grad/param norm = 2.9833e-01, time/batch = 18.5427s	
8350/22300 (epoch 18.722), train_loss = 0.69401016, grad/param norm = 2.6899e-01, time/batch = 15.7104s	
8351/22300 (epoch 18.724), train_loss = 0.74883458, grad/param norm = 2.6761e-01, time/batch = 16.8091s	
8352/22300 (epoch 18.726), train_loss = 0.62056636, grad/param norm = 2.9038e-01, time/batch = 16.4772s	
8353/22300 (epoch 18.729), train_loss = 0.66428333, grad/param norm = 2.6589e-01, time/batch = 16.3870s	
8354/22300 (epoch 18.731), train_loss = 0.85584467, grad/param norm = 3.3786e-01, time/batch = 16.4795s	
8355/22300 (epoch 18.733), train_loss = 0.86844980, grad/param norm = 3.1801e-01, time/batch = 16.5599s	
8356/22300 (epoch 18.735), train_loss = 0.88888577, grad/param norm = 3.6737e-01, time/batch = 17.5612s	
8357/22300 (epoch 18.738), train_loss = 0.66450989, grad/param norm = 2.9226e-01, time/batch = 15.4619s	
8358/22300 (epoch 18.740), train_loss = 0.58410073, grad/param norm = 2.7616e-01, time/batch = 18.1328s	
8359/22300 (epoch 18.742), train_loss = 0.68896627, grad/param norm = 2.8486e-01, time/batch = 15.7976s	
8360/22300 (epoch 18.744), train_loss = 0.94893864, grad/param norm = 3.2585e-01, time/batch = 17.2826s	
8361/22300 (epoch 18.747), train_loss = 0.74416526, grad/param norm = 2.5205e-01, time/batch = 16.6956s	
8362/22300 (epoch 18.749), train_loss = 0.98512758, grad/param norm = 3.2148e-01, time/batch = 16.8923s	
8363/22300 (epoch 18.751), train_loss = 0.88263858, grad/param norm = 3.8114e-01, time/batch = 15.8548s	
8364/22300 (epoch 18.753), train_loss = 0.88820197, grad/param norm = 3.4037e-01, time/batch = 16.0557s	
8365/22300 (epoch 18.756), train_loss = 0.79530132, grad/param norm = 3.3977e-01, time/batch = 15.0731s	
8366/22300 (epoch 18.758), train_loss = 0.75273745, grad/param norm = 2.7688e-01, time/batch = 16.7176s	
8367/22300 (epoch 18.760), train_loss = 0.73493363, grad/param norm = 2.7012e-01, time/batch = 18.4639s	
8368/22300 (epoch 18.762), train_loss = 0.71909912, grad/param norm = 2.6297e-01, time/batch = 16.1419s	
8369/22300 (epoch 18.765), train_loss = 0.76083253, grad/param norm = 3.4279e-01, time/batch = 16.0537s	
8370/22300 (epoch 18.767), train_loss = 0.77665304, grad/param norm = 2.9780e-01, time/batch = 15.3846s	
8371/22300 (epoch 18.769), train_loss = 0.71289477, grad/param norm = 3.3421e-01, time/batch = 17.6141s	
8372/22300 (epoch 18.771), train_loss = 0.80082997, grad/param norm = 3.1406e-01, time/batch = 17.6263s	
8373/22300 (epoch 18.774), train_loss = 0.85511883, grad/param norm = 4.1623e-01, time/batch = 16.1462s	
8374/22300 (epoch 18.776), train_loss = 0.88803960, grad/param norm = 3.1700e-01, time/batch = 15.5501s	
8375/22300 (epoch 18.778), train_loss = 0.85252486, grad/param norm = 2.7833e-01, time/batch = 16.4581s	
8376/22300 (epoch 18.780), train_loss = 0.85046682, grad/param norm = 3.4186e-01, time/batch = 17.6396s	
8377/22300 (epoch 18.783), train_loss = 0.92422037, grad/param norm = 3.6785e-01, time/batch = 16.5589s	
8378/22300 (epoch 18.785), train_loss = 0.68204799, grad/param norm = 2.8401e-01, time/batch = 17.1384s	
8379/22300 (epoch 18.787), train_loss = 0.68347819, grad/param norm = 2.8908e-01, time/batch = 14.8136s	
8380/22300 (epoch 18.789), train_loss = 0.89602861, grad/param norm = 3.1681e-01, time/batch = 17.7966s	
8381/22300 (epoch 18.791), train_loss = 1.02954984, grad/param norm = 3.3554e-01, time/batch = 16.9526s	
8382/22300 (epoch 18.794), train_loss = 0.89029442, grad/param norm = 3.7876e-01, time/batch = 15.7127s	
8383/22300 (epoch 18.796), train_loss = 0.88698725, grad/param norm = 3.4196e-01, time/batch = 16.8032s	
8384/22300 (epoch 18.798), train_loss = 0.97005366, grad/param norm = 3.0478e-01, time/batch = 17.2145s	
8385/22300 (epoch 18.800), train_loss = 0.70903936, grad/param norm = 3.0199e-01, time/batch = 15.7738s	
8386/22300 (epoch 18.803), train_loss = 0.66458817, grad/param norm = 2.5733e-01, time/batch = 15.6941s	
8387/22300 (epoch 18.805), train_loss = 0.78312021, grad/param norm = 2.8796e-01, time/batch = 16.6493s	
8388/22300 (epoch 18.807), train_loss = 0.90156260, grad/param norm = 3.3605e-01, time/batch = 16.8892s	
8389/22300 (epoch 18.809), train_loss = 0.67922440, grad/param norm = 2.6119e-01, time/batch = 16.4673s	
8390/22300 (epoch 18.812), train_loss = 0.83909153, grad/param norm = 3.0126e-01, time/batch = 17.0456s	
8391/22300 (epoch 18.814), train_loss = 0.80109203, grad/param norm = 2.7965e-01, time/batch = 16.9764s	
8392/22300 (epoch 18.816), train_loss = 0.77983458, grad/param norm = 2.6259e-01, time/batch = 15.8255s	
8393/22300 (epoch 18.818), train_loss = 0.89468024, grad/param norm = 3.0600e-01, time/batch = 16.6382s	
8394/22300 (epoch 18.821), train_loss = 0.81260152, grad/param norm = 3.0452e-01, time/batch = 17.3854s	
8395/22300 (epoch 18.823), train_loss = 0.56643064, grad/param norm = 2.8813e-01, time/batch = 15.9728s	
8396/22300 (epoch 18.825), train_loss = 0.66395354, grad/param norm = 2.5263e-01, time/batch = 16.1246s	
8397/22300 (epoch 18.827), train_loss = 0.73143541, grad/param norm = 2.9051e-01, time/batch = 16.7809s	
8398/22300 (epoch 18.830), train_loss = 0.63854499, grad/param norm = 2.6280e-01, time/batch = 16.0465s	
8399/22300 (epoch 18.832), train_loss = 0.64851821, grad/param norm = 2.9007e-01, time/batch = 16.7203s	
8400/22300 (epoch 18.834), train_loss = 0.61844619, grad/param norm = 2.5123e-01, time/batch = 17.0567s	
8401/22300 (epoch 18.836), train_loss = 0.74510322, grad/param norm = 3.1416e-01, time/batch = 16.2287s	
8402/22300 (epoch 18.839), train_loss = 0.69346171, grad/param norm = 2.9447e-01, time/batch = 18.2994s	
8403/22300 (epoch 18.841), train_loss = 0.72325601, grad/param norm = 2.8868e-01, time/batch = 18.0449s	
8404/22300 (epoch 18.843), train_loss = 0.71812735, grad/param norm = 2.5862e-01, time/batch = 15.1724s	
8405/22300 (epoch 18.845), train_loss = 0.68926810, grad/param norm = 2.7314e-01, time/batch = 15.3410s	
8406/22300 (epoch 18.848), train_loss = 0.72286577, grad/param norm = 2.7938e-01, time/batch = 15.1810s	
8407/22300 (epoch 18.850), train_loss = 0.71340664, grad/param norm = 2.6596e-01, time/batch = 14.9223s	
8408/22300 (epoch 18.852), train_loss = 0.70422814, grad/param norm = 2.9038e-01, time/batch = 16.0453s	
8409/22300 (epoch 18.854), train_loss = 0.91143748, grad/param norm = 3.0512e-01, time/batch = 16.6367s	
8410/22300 (epoch 18.857), train_loss = 0.74488450, grad/param norm = 3.3259e-01, time/batch = 15.8994s	
8411/22300 (epoch 18.859), train_loss = 0.60501838, grad/param norm = 2.6013e-01, time/batch = 16.0652s	
8412/22300 (epoch 18.861), train_loss = 0.76757331, grad/param norm = 2.6260e-01, time/batch = 16.3882s	
8413/22300 (epoch 18.863), train_loss = 0.58196956, grad/param norm = 2.7241e-01, time/batch = 14.8771s	
8414/22300 (epoch 18.865), train_loss = 0.58352847, grad/param norm = 2.3547e-01, time/batch = 18.7151s	
8415/22300 (epoch 18.868), train_loss = 0.70537741, grad/param norm = 2.4466e-01, time/batch = 16.3720s	
8416/22300 (epoch 18.870), train_loss = 0.76838726, grad/param norm = 3.2686e-01, time/batch = 15.7220s	
8417/22300 (epoch 18.872), train_loss = 0.83145634, grad/param norm = 3.1330e-01, time/batch = 15.8038s	
8418/22300 (epoch 18.874), train_loss = 0.77339265, grad/param norm = 3.3807e-01, time/batch = 16.7669s	
8419/22300 (epoch 18.877), train_loss = 0.75264259, grad/param norm = 2.9148e-01, time/batch = 15.3964s	
8420/22300 (epoch 18.879), train_loss = 0.64185045, grad/param norm = 2.6095e-01, time/batch = 16.0708s	
8421/22300 (epoch 18.881), train_loss = 0.64481678, grad/param norm = 2.8929e-01, time/batch = 16.7096s	
8422/22300 (epoch 18.883), train_loss = 0.61575622, grad/param norm = 2.3964e-01, time/batch = 17.0463s	
8423/22300 (epoch 18.886), train_loss = 0.61440559, grad/param norm = 2.5529e-01, time/batch = 16.3882s	
8424/22300 (epoch 18.888), train_loss = 0.68165148, grad/param norm = 2.7028e-01, time/batch = 15.5405s	
8425/22300 (epoch 18.890), train_loss = 0.61437802, grad/param norm = 2.0469e-01, time/batch = 19.3015s	
8426/22300 (epoch 18.892), train_loss = 0.90898580, grad/param norm = 2.7750e-01, time/batch = 15.3521s	
8427/22300 (epoch 18.895), train_loss = 0.87930522, grad/param norm = 3.0853e-01, time/batch = 17.1378s	
8428/22300 (epoch 18.897), train_loss = 0.72756758, grad/param norm = 3.3369e-01, time/batch = 15.9039s	
8429/22300 (epoch 18.899), train_loss = 0.74498301, grad/param norm = 2.8662e-01, time/batch = 16.5556s	
8430/22300 (epoch 18.901), train_loss = 0.70212421, grad/param norm = 2.6520e-01, time/batch = 16.0292s	
8431/22300 (epoch 18.904), train_loss = 0.76507218, grad/param norm = 2.5073e-01, time/batch = 17.7137s	
8432/22300 (epoch 18.906), train_loss = 0.75640305, grad/param norm = 2.5833e-01, time/batch = 18.4607s	
8433/22300 (epoch 18.908), train_loss = 0.70384372, grad/param norm = 2.5490e-01, time/batch = 16.2117s	
8434/22300 (epoch 18.910), train_loss = 0.58008001, grad/param norm = 2.6175e-01, time/batch = 18.7977s	
8435/22300 (epoch 18.913), train_loss = 0.79658451, grad/param norm = 2.9333e-01, time/batch = 16.3850s	
8436/22300 (epoch 18.915), train_loss = 0.91763925, grad/param norm = 3.3039e-01, time/batch = 16.2969s	
8437/22300 (epoch 18.917), train_loss = 0.73662299, grad/param norm = 2.9632e-01, time/batch = 14.8701s	
8438/22300 (epoch 18.919), train_loss = 0.78225291, grad/param norm = 2.6029e-01, time/batch = 17.2983s	
8439/22300 (epoch 18.922), train_loss = 0.69904234, grad/param norm = 2.7719e-01, time/batch = 18.3766s	
8440/22300 (epoch 18.924), train_loss = 0.50136303, grad/param norm = 2.3197e-01, time/batch = 15.0534s	
8441/22300 (epoch 18.926), train_loss = 0.58942508, grad/param norm = 2.6871e-01, time/batch = 14.5759s	
8442/22300 (epoch 18.928), train_loss = 0.68841464, grad/param norm = 2.8211e-01, time/batch = 16.8835s	
8443/22300 (epoch 18.930), train_loss = 0.67376738, grad/param norm = 2.6484e-01, time/batch = 18.7954s	
8444/22300 (epoch 18.933), train_loss = 0.78093914, grad/param norm = 3.0615e-01, time/batch = 16.4688s	
8445/22300 (epoch 18.935), train_loss = 0.80077825, grad/param norm = 3.4202e-01, time/batch = 17.8090s	
8446/22300 (epoch 18.937), train_loss = 0.88319309, grad/param norm = 3.1542e-01, time/batch = 14.4201s	
8447/22300 (epoch 18.939), train_loss = 0.82337857, grad/param norm = 2.7679e-01, time/batch = 15.9037s	
8448/22300 (epoch 18.942), train_loss = 0.99040441, grad/param norm = 3.5836e-01, time/batch = 16.1209s	
8449/22300 (epoch 18.944), train_loss = 1.02742534, grad/param norm = 3.6370e-01, time/batch = 18.3481s	
8450/22300 (epoch 18.946), train_loss = 0.72764981, grad/param norm = 2.8729e-01, time/batch = 17.1316s	
8451/22300 (epoch 18.948), train_loss = 0.63344169, grad/param norm = 2.3655e-01, time/batch = 15.3036s	
8452/22300 (epoch 18.951), train_loss = 0.59454276, grad/param norm = 2.5557e-01, time/batch = 15.9566s	
8453/22300 (epoch 18.953), train_loss = 0.62909969, grad/param norm = 2.8290e-01, time/batch = 14.8685s	
8454/22300 (epoch 18.955), train_loss = 0.91525434, grad/param norm = 2.9000e-01, time/batch = 17.7186s	
8455/22300 (epoch 18.957), train_loss = 1.01838407, grad/param norm = 3.5896e-01, time/batch = 17.8699s	
8456/22300 (epoch 18.960), train_loss = 0.87383686, grad/param norm = 3.1300e-01, time/batch = 16.1532s	
8457/22300 (epoch 18.962), train_loss = 0.71629767, grad/param norm = 3.0239e-01, time/batch = 18.6341s	
8458/22300 (epoch 18.964), train_loss = 0.71531819, grad/param norm = 2.8029e-01, time/batch = 15.4814s	
8459/22300 (epoch 18.966), train_loss = 0.64459243, grad/param norm = 2.6800e-01, time/batch = 17.3723s	
8460/22300 (epoch 18.969), train_loss = 0.68484778, grad/param norm = 2.4019e-01, time/batch = 15.4471s	
8461/22300 (epoch 18.971), train_loss = 0.71717430, grad/param norm = 2.6931e-01, time/batch = 18.6199s	
8462/22300 (epoch 18.973), train_loss = 0.73290404, grad/param norm = 2.7852e-01, time/batch = 16.4613s	
8463/22300 (epoch 18.975), train_loss = 0.91410885, grad/param norm = 3.2187e-01, time/batch = 15.4445s	
8464/22300 (epoch 18.978), train_loss = 0.78476182, grad/param norm = 2.7348e-01, time/batch = 16.4876s	
8465/22300 (epoch 18.980), train_loss = 0.87539292, grad/param norm = 3.1585e-01, time/batch = 16.5448s	
8466/22300 (epoch 18.982), train_loss = 0.62818440, grad/param norm = 2.7404e-01, time/batch = 17.1464s	
8467/22300 (epoch 18.984), train_loss = 0.77876608, grad/param norm = 2.7810e-01, time/batch = 16.2795s	
8468/22300 (epoch 18.987), train_loss = 0.66904567, grad/param norm = 2.6971e-01, time/batch = 17.8103s	
8469/22300 (epoch 18.989), train_loss = 0.69114189, grad/param norm = 2.7708e-01, time/batch = 15.1413s	
8470/22300 (epoch 18.991), train_loss = 0.96930810, grad/param norm = 3.2983e-01, time/batch = 15.3186s	
8471/22300 (epoch 18.993), train_loss = 1.17124200, grad/param norm = 3.5238e-01, time/batch = 15.1237s	
8472/22300 (epoch 18.996), train_loss = 1.06224436, grad/param norm = 3.5490e-01, time/batch = 17.2226s	
8473/22300 (epoch 18.998), train_loss = 0.75646270, grad/param norm = 3.0524e-01, time/batch = 15.0664s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
8474/22300 (epoch 19.000), train_loss = 0.62839503, grad/param norm = 2.9498e-01, time/batch = 16.8764s	
8475/22300 (epoch 19.002), train_loss = 1.00602759, grad/param norm = 3.1971e-01, time/batch = 15.5417s	
8476/22300 (epoch 19.004), train_loss = 0.74427356, grad/param norm = 2.7008e-01, time/batch = 16.2904s	
8477/22300 (epoch 19.007), train_loss = 0.76643721, grad/param norm = 3.1572e-01, time/batch = 18.3692s	
8478/22300 (epoch 19.009), train_loss = 0.76532777, grad/param norm = 2.9154e-01, time/batch = 16.1232s	
8479/22300 (epoch 19.011), train_loss = 0.97262600, grad/param norm = 3.7038e-01, time/batch = 17.2986s	
8480/22300 (epoch 19.013), train_loss = 0.75165614, grad/param norm = 2.7924e-01, time/batch = 30.1244s	
8481/22300 (epoch 19.016), train_loss = 0.69026867, grad/param norm = 3.4473e-01, time/batch = 15.8120s	
8482/22300 (epoch 19.018), train_loss = 0.83809006, grad/param norm = 3.2319e-01, time/batch = 17.0412s	
8483/22300 (epoch 19.020), train_loss = 0.68171953, grad/param norm = 2.7976e-01, time/batch = 16.4723s	
8484/22300 (epoch 19.022), train_loss = 0.63837016, grad/param norm = 2.7879e-01, time/batch = 17.7212s	
8485/22300 (epoch 19.025), train_loss = 0.62654522, grad/param norm = 2.8435e-01, time/batch = 16.6156s	
8486/22300 (epoch 19.027), train_loss = 0.65293055, grad/param norm = 2.4696e-01, time/batch = 16.2944s	
8487/22300 (epoch 19.029), train_loss = 0.64009452, grad/param norm = 2.3601e-01, time/batch = 16.3084s	
8488/22300 (epoch 19.031), train_loss = 0.64762990, grad/param norm = 2.2897e-01, time/batch = 16.6349s	
8489/22300 (epoch 19.034), train_loss = 0.65801133, grad/param norm = 2.5248e-01, time/batch = 17.6305s	
8490/22300 (epoch 19.036), train_loss = 0.51888703, grad/param norm = 2.2617e-01, time/batch = 16.2083s	
8491/22300 (epoch 19.038), train_loss = 0.64747476, grad/param norm = 2.4165e-01, time/batch = 15.2050s	
8492/22300 (epoch 19.040), train_loss = 0.68081212, grad/param norm = 2.8132e-01, time/batch = 17.9684s	
8493/22300 (epoch 19.043), train_loss = 0.95204294, grad/param norm = 2.8306e-01, time/batch = 16.2133s	
8494/22300 (epoch 19.045), train_loss = 0.77791403, grad/param norm = 2.5738e-01, time/batch = 16.4737s	
8495/22300 (epoch 19.047), train_loss = 0.81743724, grad/param norm = 3.0048e-01, time/batch = 17.2990s	
8496/22300 (epoch 19.049), train_loss = 0.69084526, grad/param norm = 2.8434e-01, time/batch = 14.4908s	
8497/22300 (epoch 19.052), train_loss = 0.78088421, grad/param norm = 2.7634e-01, time/batch = 15.3567s	
8498/22300 (epoch 19.054), train_loss = 0.73407698, grad/param norm = 2.5770e-01, time/batch = 16.8028s	
8499/22300 (epoch 19.056), train_loss = 0.48265276, grad/param norm = 2.1773e-01, time/batch = 16.3912s	
8500/22300 (epoch 19.058), train_loss = 0.64565043, grad/param norm = 2.4615e-01, time/batch = 17.2896s	
8501/22300 (epoch 19.061), train_loss = 0.63142727, grad/param norm = 2.8944e-01, time/batch = 18.5356s	
8502/22300 (epoch 19.063), train_loss = 0.88004853, grad/param norm = 3.6220e-01, time/batch = 15.9739s	
8503/22300 (epoch 19.065), train_loss = 0.86826341, grad/param norm = 3.0127e-01, time/batch = 16.4703s	
8504/22300 (epoch 19.067), train_loss = 0.68428640, grad/param norm = 3.0840e-01, time/batch = 15.1418s	
8505/22300 (epoch 19.070), train_loss = 0.72067084, grad/param norm = 2.9727e-01, time/batch = 15.9037s	
8506/22300 (epoch 19.072), train_loss = 0.80178373, grad/param norm = 2.9897e-01, time/batch = 15.9725s	
8507/22300 (epoch 19.074), train_loss = 0.78053200, grad/param norm = 2.9178e-01, time/batch = 18.3749s	
8508/22300 (epoch 19.076), train_loss = 0.71151048, grad/param norm = 2.9114e-01, time/batch = 17.1111s	
8509/22300 (epoch 19.078), train_loss = 0.81557919, grad/param norm = 2.7441e-01, time/batch = 17.4045s	
8510/22300 (epoch 19.081), train_loss = 0.83102972, grad/param norm = 3.2225e-01, time/batch = 16.8123s	
8511/22300 (epoch 19.083), train_loss = 0.92359620, grad/param norm = 2.8079e-01, time/batch = 15.3608s	
8512/22300 (epoch 19.085), train_loss = 0.95864290, grad/param norm = 3.5236e-01, time/batch = 16.0225s	
8513/22300 (epoch 19.087), train_loss = 0.81441403, grad/param norm = 2.8487e-01, time/batch = 17.3823s	
8514/22300 (epoch 19.090), train_loss = 0.66316542, grad/param norm = 2.3552e-01, time/batch = 15.7117s	
8515/22300 (epoch 19.092), train_loss = 0.57959072, grad/param norm = 2.2704e-01, time/batch = 14.9268s	
8516/22300 (epoch 19.094), train_loss = 0.61923740, grad/param norm = 2.7930e-01, time/batch = 17.2957s	
8517/22300 (epoch 19.096), train_loss = 0.90649584, grad/param norm = 3.2985e-01, time/batch = 16.7258s	
8518/22300 (epoch 19.099), train_loss = 0.66961165, grad/param norm = 2.6943e-01, time/batch = 16.5693s	
8519/22300 (epoch 19.101), train_loss = 0.83184016, grad/param norm = 3.0630e-01, time/batch = 15.3997s	
8520/22300 (epoch 19.103), train_loss = 0.73293349, grad/param norm = 2.9034e-01, time/batch = 15.5690s	
8521/22300 (epoch 19.105), train_loss = 0.67945308, grad/param norm = 3.0924e-01, time/batch = 18.8651s	
8522/22300 (epoch 19.108), train_loss = 0.75321842, grad/param norm = 2.5790e-01, time/batch = 15.6381s	
8523/22300 (epoch 19.110), train_loss = 0.79661742, grad/param norm = 2.6769e-01, time/batch = 17.8715s	
8524/22300 (epoch 19.112), train_loss = 0.73547738, grad/param norm = 2.6290e-01, time/batch = 15.9777s	
8525/22300 (epoch 19.114), train_loss = 0.81924241, grad/param norm = 2.9312e-01, time/batch = 18.1255s	
8526/22300 (epoch 19.117), train_loss = 0.97574907, grad/param norm = 3.5065e-01, time/batch = 15.2685s	
8527/22300 (epoch 19.119), train_loss = 0.88076648, grad/param norm = 3.0066e-01, time/batch = 15.2491s	
8528/22300 (epoch 19.121), train_loss = 0.93182360, grad/param norm = 3.6573e-01, time/batch = 18.2847s	
8529/22300 (epoch 19.123), train_loss = 0.88723969, grad/param norm = 2.9481e-01, time/batch = 17.3749s	
8530/22300 (epoch 19.126), train_loss = 0.77784523, grad/param norm = 2.8421e-01, time/batch = 16.3949s	
8531/22300 (epoch 19.128), train_loss = 0.83229985, grad/param norm = 2.8243e-01, time/batch = 16.6274s	
8532/22300 (epoch 19.130), train_loss = 0.65520478, grad/param norm = 2.5152e-01, time/batch = 18.4601s	
8533/22300 (epoch 19.132), train_loss = 0.57803969, grad/param norm = 2.6349e-01, time/batch = 15.1980s	
8534/22300 (epoch 19.135), train_loss = 0.63212223, grad/param norm = 3.0549e-01, time/batch = 16.8899s	
8535/22300 (epoch 19.137), train_loss = 0.48231571, grad/param norm = 2.4468e-01, time/batch = 14.9843s	
8536/22300 (epoch 19.139), train_loss = 0.74813136, grad/param norm = 2.9070e-01, time/batch = 18.3632s	
8537/22300 (epoch 19.141), train_loss = 0.82253628, grad/param norm = 2.6304e-01, time/batch = 17.8741s	
8538/22300 (epoch 19.143), train_loss = 0.76255960, grad/param norm = 2.8052e-01, time/batch = 15.0391s	
8539/22300 (epoch 19.146), train_loss = 0.85653300, grad/param norm = 3.0148e-01, time/batch = 16.7985s	
8540/22300 (epoch 19.148), train_loss = 0.62694393, grad/param norm = 2.7193e-01, time/batch = 15.1255s	
8541/22300 (epoch 19.150), train_loss = 0.69210593, grad/param norm = 2.5994e-01, time/batch = 16.9671s	
8542/22300 (epoch 19.152), train_loss = 0.57045641, grad/param norm = 2.3893e-01, time/batch = 15.8785s	
8543/22300 (epoch 19.155), train_loss = 0.61919375, grad/param norm = 2.4603e-01, time/batch = 17.9588s	
8544/22300 (epoch 19.157), train_loss = 0.81060959, grad/param norm = 3.2032e-01, time/batch = 15.1405s	
8545/22300 (epoch 19.159), train_loss = 0.82129242, grad/param norm = 2.8211e-01, time/batch = 17.0544s	
8546/22300 (epoch 19.161), train_loss = 0.82554229, grad/param norm = 3.1248e-01, time/batch = 16.7331s	
8547/22300 (epoch 19.164), train_loss = 0.58856456, grad/param norm = 2.3379e-01, time/batch = 17.1954s	
8548/22300 (epoch 19.166), train_loss = 0.57375300, grad/param norm = 2.1931e-01, time/batch = 15.5099s	
8549/22300 (epoch 19.168), train_loss = 0.61315005, grad/param norm = 2.5414e-01, time/batch = 16.8107s	
8550/22300 (epoch 19.170), train_loss = 0.76129226, grad/param norm = 2.6548e-01, time/batch = 18.3065s	
8551/22300 (epoch 19.173), train_loss = 0.86887608, grad/param norm = 2.9423e-01, time/batch = 15.1206s	
8552/22300 (epoch 19.175), train_loss = 0.72875605, grad/param norm = 2.9310e-01, time/batch = 14.8155s	
8553/22300 (epoch 19.177), train_loss = 0.55884460, grad/param norm = 2.3816e-01, time/batch = 15.6483s	
8554/22300 (epoch 19.179), train_loss = 0.68510602, grad/param norm = 2.3489e-01, time/batch = 17.3703s	
8555/22300 (epoch 19.182), train_loss = 0.88812382, grad/param norm = 2.9315e-01, time/batch = 16.4846s	
8556/22300 (epoch 19.184), train_loss = 0.99041787, grad/param norm = 3.0351e-01, time/batch = 18.2840s	
8557/22300 (epoch 19.186), train_loss = 0.77007676, grad/param norm = 2.8173e-01, time/batch = 16.8069s	
8558/22300 (epoch 19.188), train_loss = 0.99219942, grad/param norm = 3.8421e-01, time/batch = 15.9729s	
8559/22300 (epoch 19.191), train_loss = 0.91174114, grad/param norm = 3.0765e-01, time/batch = 18.4653s	
8560/22300 (epoch 19.193), train_loss = 0.75767015, grad/param norm = 3.1540e-01, time/batch = 16.3775s	
8561/22300 (epoch 19.195), train_loss = 0.69173918, grad/param norm = 2.9241e-01, time/batch = 16.5607s	
8562/22300 (epoch 19.197), train_loss = 0.70419167, grad/param norm = 2.9105e-01, time/batch = 15.1918s	
8563/22300 (epoch 19.200), train_loss = 0.59856169, grad/param norm = 2.4680e-01, time/batch = 16.0581s	
8564/22300 (epoch 19.202), train_loss = 0.67434779, grad/param norm = 2.7729e-01, time/batch = 18.2817s	
8565/22300 (epoch 19.204), train_loss = 0.71251405, grad/param norm = 2.7402e-01, time/batch = 16.1179s	
8566/22300 (epoch 19.206), train_loss = 0.64073425, grad/param norm = 2.4334e-01, time/batch = 16.2209s	
8567/22300 (epoch 19.209), train_loss = 0.71541743, grad/param norm = 3.0280e-01, time/batch = 17.6407s	
8568/22300 (epoch 19.211), train_loss = 0.56540456, grad/param norm = 2.8972e-01, time/batch = 17.1429s	
8569/22300 (epoch 19.213), train_loss = 0.69960436, grad/param norm = 2.7629e-01, time/batch = 17.1129s	
8570/22300 (epoch 19.215), train_loss = 0.88484174, grad/param norm = 2.8237e-01, time/batch = 15.3919s	
8571/22300 (epoch 19.217), train_loss = 0.86229785, grad/param norm = 3.0543e-01, time/batch = 15.4660s	
8572/22300 (epoch 19.220), train_loss = 0.70390736, grad/param norm = 2.5970e-01, time/batch = 16.4734s	
8573/22300 (epoch 19.222), train_loss = 0.63351479, grad/param norm = 2.7894e-01, time/batch = 14.9318s	
8574/22300 (epoch 19.224), train_loss = 0.64732396, grad/param norm = 2.4457e-01, time/batch = 16.9721s	
8575/22300 (epoch 19.226), train_loss = 0.69509880, grad/param norm = 2.5196e-01, time/batch = 17.6382s	
8576/22300 (epoch 19.229), train_loss = 0.63863078, grad/param norm = 2.6946e-01, time/batch = 16.7197s	
8577/22300 (epoch 19.231), train_loss = 0.81646268, grad/param norm = 3.2376e-01, time/batch = 15.7899s	
8578/22300 (epoch 19.233), train_loss = 0.75535528, grad/param norm = 3.2523e-01, time/batch = 16.6297s	
8579/22300 (epoch 19.235), train_loss = 0.58577010, grad/param norm = 2.7575e-01, time/batch = 16.8030s	
8580/22300 (epoch 19.238), train_loss = 0.58059605, grad/param norm = 2.2513e-01, time/batch = 15.6455s	
8581/22300 (epoch 19.240), train_loss = 0.58643918, grad/param norm = 2.1744e-01, time/batch = 15.6523s	
8582/22300 (epoch 19.242), train_loss = 0.62216601, grad/param norm = 2.9531e-01, time/batch = 16.1497s	
8583/22300 (epoch 19.244), train_loss = 0.44624531, grad/param norm = 2.0835e-01, time/batch = 16.9749s	
8584/22300 (epoch 19.247), train_loss = 0.58928337, grad/param norm = 2.4852e-01, time/batch = 14.8236s	
8585/22300 (epoch 19.249), train_loss = 0.46413344, grad/param norm = 2.3336e-01, time/batch = 16.7208s	
8586/22300 (epoch 19.251), train_loss = 0.60455186, grad/param norm = 2.3175e-01, time/batch = 18.6236s	
8587/22300 (epoch 19.253), train_loss = 0.44578846, grad/param norm = 2.1245e-01, time/batch = 15.8620s	
8588/22300 (epoch 19.256), train_loss = 0.54374706, grad/param norm = 2.1012e-01, time/batch = 16.9055s	
8589/22300 (epoch 19.258), train_loss = 0.82507794, grad/param norm = 3.0912e-01, time/batch = 14.5784s	
8590/22300 (epoch 19.260), train_loss = 0.70081300, grad/param norm = 2.8753e-01, time/batch = 15.6401s	
8591/22300 (epoch 19.262), train_loss = 0.57382954, grad/param norm = 2.4857e-01, time/batch = 16.2268s	
8592/22300 (epoch 19.265), train_loss = 0.56002858, grad/param norm = 2.3799e-01, time/batch = 15.8185s	
8593/22300 (epoch 19.267), train_loss = 0.63485937, grad/param norm = 2.4991e-01, time/batch = 16.0690s	
8594/22300 (epoch 19.269), train_loss = 0.70087776, grad/param norm = 2.7656e-01, time/batch = 15.4732s	
8595/22300 (epoch 19.271), train_loss = 0.70311498, grad/param norm = 2.4077e-01, time/batch = 15.0688s	
8596/22300 (epoch 19.274), train_loss = 0.53733150, grad/param norm = 2.5008e-01, time/batch = 16.2989s	
8597/22300 (epoch 19.276), train_loss = 0.48915149, grad/param norm = 2.1848e-01, time/batch = 15.9777s	
8598/22300 (epoch 19.278), train_loss = 0.46983364, grad/param norm = 2.1515e-01, time/batch = 16.8795s	
8599/22300 (epoch 19.280), train_loss = 0.61085666, grad/param norm = 2.7926e-01, time/batch = 15.5245s	
8600/22300 (epoch 19.283), train_loss = 0.43505512, grad/param norm = 1.9419e-01, time/batch = 16.7296s	
8601/22300 (epoch 19.285), train_loss = 0.57748887, grad/param norm = 2.6554e-01, time/batch = 18.6345s	
8602/22300 (epoch 19.287), train_loss = 0.71167899, grad/param norm = 2.7839e-01, time/batch = 15.4653s	
8603/22300 (epoch 19.289), train_loss = 0.59514455, grad/param norm = 2.2689e-01, time/batch = 16.5384s	
8604/22300 (epoch 19.291), train_loss = 0.62114888, grad/param norm = 2.7497e-01, time/batch = 17.2315s	
8605/22300 (epoch 19.294), train_loss = 0.52133085, grad/param norm = 2.0367e-01, time/batch = 16.3879s	
8606/22300 (epoch 19.296), train_loss = 0.71437397, grad/param norm = 2.9873e-01, time/batch = 15.4575s	
8607/22300 (epoch 19.298), train_loss = 0.79087407, grad/param norm = 2.9382e-01, time/batch = 17.7129s	
8608/22300 (epoch 19.300), train_loss = 0.84983475, grad/param norm = 2.8892e-01, time/batch = 17.4564s	
8609/22300 (epoch 19.303), train_loss = 0.66788843, grad/param norm = 3.0561e-01, time/batch = 15.9736s	
8610/22300 (epoch 19.305), train_loss = 0.68914664, grad/param norm = 3.0772e-01, time/batch = 15.8874s	
8611/22300 (epoch 19.307), train_loss = 0.63070123, grad/param norm = 2.5590e-01, time/batch = 15.3933s	
8612/22300 (epoch 19.309), train_loss = 0.58202346, grad/param norm = 2.4908e-01, time/batch = 16.1182s	
8613/22300 (epoch 19.312), train_loss = 0.52271794, grad/param norm = 2.2920e-01, time/batch = 15.3095s	
8614/22300 (epoch 19.314), train_loss = 0.58942072, grad/param norm = 2.5741e-01, time/batch = 17.1382s	
8615/22300 (epoch 19.316), train_loss = 0.59895033, grad/param norm = 2.4709e-01, time/batch = 16.7773s	
8616/22300 (epoch 19.318), train_loss = 0.65884902, grad/param norm = 2.6564e-01, time/batch = 17.2155s	
8617/22300 (epoch 19.321), train_loss = 0.75392876, grad/param norm = 2.6690e-01, time/batch = 14.7057s	
8618/22300 (epoch 19.323), train_loss = 0.56851273, grad/param norm = 2.2358e-01, time/batch = 16.0482s	
8619/22300 (epoch 19.325), train_loss = 0.52522366, grad/param norm = 2.6023e-01, time/batch = 19.0469s	
8620/22300 (epoch 19.327), train_loss = 0.54909357, grad/param norm = 2.6038e-01, time/batch = 16.2049s	
8621/22300 (epoch 19.330), train_loss = 0.59540986, grad/param norm = 3.0804e-01, time/batch = 16.4899s	
8622/22300 (epoch 19.332), train_loss = 0.55842101, grad/param norm = 2.5882e-01, time/batch = 17.9727s	
8623/22300 (epoch 19.334), train_loss = 0.58713061, grad/param norm = 2.5731e-01, time/batch = 14.6102s	
8624/22300 (epoch 19.336), train_loss = 0.60011381, grad/param norm = 2.7455e-01, time/batch = 16.5357s	
8625/22300 (epoch 19.339), train_loss = 0.68379806, grad/param norm = 2.8641e-01, time/batch = 16.8874s	
8626/22300 (epoch 19.341), train_loss = 0.71764770, grad/param norm = 2.7505e-01, time/batch = 17.3099s	
8627/22300 (epoch 19.343), train_loss = 0.80620772, grad/param norm = 3.0052e-01, time/batch = 15.1654s	
8628/22300 (epoch 19.345), train_loss = 0.61516873, grad/param norm = 2.3637e-01, time/batch = 17.9683s	
8629/22300 (epoch 19.348), train_loss = 0.62603710, grad/param norm = 2.3260e-01, time/batch = 16.3104s	
8630/22300 (epoch 19.350), train_loss = 0.53069776, grad/param norm = 2.6318e-01, time/batch = 17.1199s	
8631/22300 (epoch 19.352), train_loss = 0.70735786, grad/param norm = 2.6698e-01, time/batch = 15.9220s	
8632/22300 (epoch 19.354), train_loss = 0.91636018, grad/param norm = 3.2546e-01, time/batch = 18.4512s	
8633/22300 (epoch 19.357), train_loss = 0.75430704, grad/param norm = 2.4994e-01, time/batch = 16.3490s	
8634/22300 (epoch 19.359), train_loss = 0.59367658, grad/param norm = 2.5016e-01, time/batch = 16.3007s	
8635/22300 (epoch 19.361), train_loss = 0.58799914, grad/param norm = 2.4816e-01, time/batch = 14.7365s	
8636/22300 (epoch 19.363), train_loss = 0.83092204, grad/param norm = 3.6061e-01, time/batch = 15.3242s	
8637/22300 (epoch 19.365), train_loss = 0.64051500, grad/param norm = 2.9532e-01, time/batch = 16.8956s	
8638/22300 (epoch 19.368), train_loss = 0.66250293, grad/param norm = 3.1280e-01, time/batch = 16.6091s	
8639/22300 (epoch 19.370), train_loss = 0.66178178, grad/param norm = 2.9258e-01, time/batch = 17.7722s	
8640/22300 (epoch 19.372), train_loss = 0.54235386, grad/param norm = 2.6726e-01, time/batch = 17.5465s	
8641/22300 (epoch 19.374), train_loss = 0.48823894, grad/param norm = 2.4199e-01, time/batch = 17.3629s	
8642/22300 (epoch 19.377), train_loss = 0.62617539, grad/param norm = 3.2272e-01, time/batch = 16.0554s	
8643/22300 (epoch 19.379), train_loss = 0.62284325, grad/param norm = 2.8465e-01, time/batch = 16.9766s	
8644/22300 (epoch 19.381), train_loss = 0.77859770, grad/param norm = 2.6449e-01, time/batch = 14.9864s	
8645/22300 (epoch 19.383), train_loss = 0.63199699, grad/param norm = 3.2708e-01, time/batch = 15.7981s	
8646/22300 (epoch 19.386), train_loss = 0.62496453, grad/param norm = 2.8063e-01, time/batch = 15.5575s	
8647/22300 (epoch 19.388), train_loss = 0.57828655, grad/param norm = 2.9360e-01, time/batch = 16.4062s	
8648/22300 (epoch 19.390), train_loss = 0.68198551, grad/param norm = 2.8531e-01, time/batch = 17.7892s	
8649/22300 (epoch 19.392), train_loss = 0.63564931, grad/param norm = 2.9405e-01, time/batch = 15.4471s	
8650/22300 (epoch 19.395), train_loss = 0.54698365, grad/param norm = 2.8937e-01, time/batch = 16.5381s	
8651/22300 (epoch 19.397), train_loss = 0.36609230, grad/param norm = 2.1042e-01, time/batch = 15.8624s	
8652/22300 (epoch 19.399), train_loss = 0.53586098, grad/param norm = 2.5692e-01, time/batch = 17.8886s	
8653/22300 (epoch 19.401), train_loss = 0.61792264, grad/param norm = 2.6273e-01, time/batch = 15.3977s	
8654/22300 (epoch 19.404), train_loss = 0.62136911, grad/param norm = 2.6738e-01, time/batch = 16.1215s	
8655/22300 (epoch 19.406), train_loss = 0.86756386, grad/param norm = 3.4007e-01, time/batch = 16.0695s	
8656/22300 (epoch 19.408), train_loss = 0.74104603, grad/param norm = 2.7041e-01, time/batch = 16.7088s	
8657/22300 (epoch 19.410), train_loss = 0.75704229, grad/param norm = 2.7414e-01, time/batch = 16.2371s	
8658/22300 (epoch 19.413), train_loss = 0.63449731, grad/param norm = 3.2063e-01, time/batch = 18.0465s	
8659/22300 (epoch 19.415), train_loss = 0.49094061, grad/param norm = 2.4127e-01, time/batch = 18.3874s	
8660/22300 (epoch 19.417), train_loss = 0.67973906, grad/param norm = 2.7715e-01, time/batch = 15.3108s	
8661/22300 (epoch 19.419), train_loss = 0.58160017, grad/param norm = 2.3311e-01, time/batch = 17.1515s	
8662/22300 (epoch 19.422), train_loss = 0.59061267, grad/param norm = 2.6593e-01, time/batch = 14.6549s	
8663/22300 (epoch 19.424), train_loss = 0.65475332, grad/param norm = 2.6543e-01, time/batch = 16.4429s	
8664/22300 (epoch 19.426), train_loss = 0.53657421, grad/param norm = 3.6954e-01, time/batch = 17.0327s	
8665/22300 (epoch 19.428), train_loss = 0.57295561, grad/param norm = 2.9881e-01, time/batch = 17.5469s	
8666/22300 (epoch 19.430), train_loss = 0.64430288, grad/param norm = 2.6087e-01, time/batch = 15.2181s	
8667/22300 (epoch 19.433), train_loss = 0.61929739, grad/param norm = 2.5293e-01, time/batch = 15.7277s	
8668/22300 (epoch 19.435), train_loss = 0.63983165, grad/param norm = 2.9183e-01, time/batch = 16.1532s	
8669/22300 (epoch 19.437), train_loss = 0.65646408, grad/param norm = 2.8080e-01, time/batch = 15.1941s	
8670/22300 (epoch 19.439), train_loss = 0.69053676, grad/param norm = 2.8773e-01, time/batch = 17.8799s	
8671/22300 (epoch 19.442), train_loss = 0.67007559, grad/param norm = 2.5428e-01, time/batch = 17.5354s	
8672/22300 (epoch 19.444), train_loss = 0.58253275, grad/param norm = 2.1032e-01, time/batch = 16.5462s	
8673/22300 (epoch 19.446), train_loss = 0.54722206, grad/param norm = 2.6789e-01, time/batch = 17.9611s	
8674/22300 (epoch 19.448), train_loss = 0.40877526, grad/param norm = 1.8462e-01, time/batch = 15.6507s	
8675/22300 (epoch 19.451), train_loss = 0.70712054, grad/param norm = 2.9269e-01, time/batch = 17.7274s	
8676/22300 (epoch 19.453), train_loss = 0.58486074, grad/param norm = 2.3702e-01, time/batch = 16.6325s	
8677/22300 (epoch 19.455), train_loss = 0.80896318, grad/param norm = 3.4414e-01, time/batch = 18.2841s	
8678/22300 (epoch 19.457), train_loss = 0.79145160, grad/param norm = 2.9212e-01, time/batch = 16.7888s	
8679/22300 (epoch 19.460), train_loss = 0.74370718, grad/param norm = 3.0733e-01, time/batch = 15.7887s	
8680/22300 (epoch 19.462), train_loss = 0.78457000, grad/param norm = 2.7194e-01, time/batch = 15.4501s	
8681/22300 (epoch 19.464), train_loss = 0.70344445, grad/param norm = 2.9160e-01, time/batch = 15.3550s	
8682/22300 (epoch 19.466), train_loss = 0.61652005, grad/param norm = 2.6578e-01, time/batch = 17.2313s	
8683/22300 (epoch 19.469), train_loss = 0.57481941, grad/param norm = 2.3520e-01, time/batch = 16.5568s	
8684/22300 (epoch 19.471), train_loss = 0.73412432, grad/param norm = 2.6181e-01, time/batch = 16.8098s	
8685/22300 (epoch 19.473), train_loss = 0.68644224, grad/param norm = 2.4103e-01, time/batch = 16.0483s	
8686/22300 (epoch 19.475), train_loss = 0.61105598, grad/param norm = 2.6445e-01, time/batch = 16.9864s	
8687/22300 (epoch 19.478), train_loss = 0.62230709, grad/param norm = 2.5093e-01, time/batch = 16.2059s	
8688/22300 (epoch 19.480), train_loss = 0.44611344, grad/param norm = 2.6562e-01, time/batch = 17.2942s	
8689/22300 (epoch 19.482), train_loss = 0.48336653, grad/param norm = 2.2057e-01, time/batch = 16.7988s	
8690/22300 (epoch 19.484), train_loss = 0.63807139, grad/param norm = 2.6746e-01, time/batch = 16.6328s	
8691/22300 (epoch 19.487), train_loss = 0.68097664, grad/param norm = 2.4247e-01, time/batch = 18.0460s	
8692/22300 (epoch 19.489), train_loss = 0.71366637, grad/param norm = 2.8285e-01, time/batch = 15.7783s	
8693/22300 (epoch 19.491), train_loss = 0.69892639, grad/param norm = 2.9163e-01, time/batch = 16.5421s	
8694/22300 (epoch 19.493), train_loss = 0.68418355, grad/param norm = 3.4177e-01, time/batch = 17.6367s	
8695/22300 (epoch 19.496), train_loss = 0.58644489, grad/param norm = 2.1016e-01, time/batch = 19.0337s	
8696/22300 (epoch 19.498), train_loss = 0.49271785, grad/param norm = 2.3335e-01, time/batch = 30.0697s	
8697/22300 (epoch 19.500), train_loss = 0.67557375, grad/param norm = 2.5011e-01, time/batch = 17.3013s	
8698/22300 (epoch 19.502), train_loss = 0.47990187, grad/param norm = 2.9124e-01, time/batch = 16.0445s	
8699/22300 (epoch 19.504), train_loss = 0.49880569, grad/param norm = 2.6305e-01, time/batch = 16.1342s	
8700/22300 (epoch 19.507), train_loss = 0.57598558, grad/param norm = 2.9313e-01, time/batch = 15.8073s	
8701/22300 (epoch 19.509), train_loss = 0.71299271, grad/param norm = 3.1403e-01, time/batch = 15.1799s	
8702/22300 (epoch 19.511), train_loss = 0.46478570, grad/param norm = 2.3762e-01, time/batch = 15.1351s	
8703/22300 (epoch 19.513), train_loss = 0.48183193, grad/param norm = 2.2522e-01, time/batch = 17.1357s	
8704/22300 (epoch 19.516), train_loss = 0.55842763, grad/param norm = 2.5660e-01, time/batch = 16.0262s	
8705/22300 (epoch 19.518), train_loss = 0.71662147, grad/param norm = 2.6425e-01, time/batch = 17.9559s	
8706/22300 (epoch 19.520), train_loss = 0.60112253, grad/param norm = 2.6611e-01, time/batch = 15.5671s	
8707/22300 (epoch 19.522), train_loss = 0.58185109, grad/param norm = 2.5810e-01, time/batch = 15.2120s	
8708/22300 (epoch 19.525), train_loss = 0.51883057, grad/param norm = 2.3745e-01, time/batch = 15.6216s	
8709/22300 (epoch 19.527), train_loss = 0.72705292, grad/param norm = 2.9306e-01, time/batch = 16.6906s	
8710/22300 (epoch 19.529), train_loss = 0.61281274, grad/param norm = 2.5427e-01, time/batch = 14.9679s	
8711/22300 (epoch 19.531), train_loss = 0.56696535, grad/param norm = 2.2332e-01, time/batch = 14.6732s	
8712/22300 (epoch 19.534), train_loss = 0.54988514, grad/param norm = 2.3790e-01, time/batch = 14.8999s	
8713/22300 (epoch 19.536), train_loss = 0.80247181, grad/param norm = 2.5753e-01, time/batch = 16.2687s	
8714/22300 (epoch 19.538), train_loss = 0.96582970, grad/param norm = 2.9846e-01, time/batch = 17.1819s	
8715/22300 (epoch 19.540), train_loss = 0.64516474, grad/param norm = 3.1488e-01, time/batch = 16.4543s	
8716/22300 (epoch 19.543), train_loss = 0.56437976, grad/param norm = 2.3081e-01, time/batch = 16.4661s	
8717/22300 (epoch 19.545), train_loss = 0.48078511, grad/param norm = 2.5263e-01, time/batch = 15.2215s	
8718/22300 (epoch 19.547), train_loss = 0.48096179, grad/param norm = 2.4426e-01, time/batch = 15.2689s	
8719/22300 (epoch 19.549), train_loss = 0.53340042, grad/param norm = 2.3400e-01, time/batch = 15.3957s	
8720/22300 (epoch 19.552), train_loss = 0.55167386, grad/param norm = 2.4590e-01, time/batch = 15.4441s	
8721/22300 (epoch 19.554), train_loss = 0.65423498, grad/param norm = 2.4914e-01, time/batch = 15.3628s	
8722/22300 (epoch 19.556), train_loss = 0.88567221, grad/param norm = 3.2940e-01, time/batch = 16.9019s	
8723/22300 (epoch 19.558), train_loss = 0.71507388, grad/param norm = 2.7883e-01, time/batch = 15.0413s	
8724/22300 (epoch 19.561), train_loss = 0.88751703, grad/param norm = 3.3709e-01, time/batch = 16.1253s	
8725/22300 (epoch 19.563), train_loss = 0.75617605, grad/param norm = 2.9335e-01, time/batch = 14.9792s	
8726/22300 (epoch 19.565), train_loss = 0.58346018, grad/param norm = 2.7897e-01, time/batch = 15.1560s	
8727/22300 (epoch 19.567), train_loss = 0.60040352, grad/param norm = 2.4502e-01, time/batch = 15.4515s	
8728/22300 (epoch 19.570), train_loss = 0.83986861, grad/param norm = 3.0486e-01, time/batch = 16.2187s	
8729/22300 (epoch 19.572), train_loss = 0.78764335, grad/param norm = 2.8511e-01, time/batch = 14.4864s	
8730/22300 (epoch 19.574), train_loss = 0.62441969, grad/param norm = 2.3028e-01, time/batch = 15.3791s	
8731/22300 (epoch 19.576), train_loss = 0.51614773, grad/param norm = 2.1228e-01, time/batch = 17.1385s	
8732/22300 (epoch 19.578), train_loss = 0.36394876, grad/param norm = 2.0271e-01, time/batch = 14.7535s	
8733/22300 (epoch 19.581), train_loss = 0.50953283, grad/param norm = 2.3057e-01, time/batch = 14.9791s	
8734/22300 (epoch 19.583), train_loss = 0.53173092, grad/param norm = 2.2510e-01, time/batch = 14.9884s	
8735/22300 (epoch 19.585), train_loss = 0.79149498, grad/param norm = 3.2333e-01, time/batch = 15.2003s	
8736/22300 (epoch 19.587), train_loss = 0.92496244, grad/param norm = 3.1258e-01, time/batch = 16.5399s	
8737/22300 (epoch 19.590), train_loss = 0.82823155, grad/param norm = 3.5339e-01, time/batch = 15.8633s	
8738/22300 (epoch 19.592), train_loss = 0.93775369, grad/param norm = 3.8022e-01, time/batch = 15.5509s	
8739/22300 (epoch 19.594), train_loss = 0.94345378, grad/param norm = 3.6074e-01, time/batch = 16.0529s	
8740/22300 (epoch 19.596), train_loss = 0.62089228, grad/param norm = 3.2066e-01, time/batch = 15.8662s	
8741/22300 (epoch 19.599), train_loss = 0.48416705, grad/param norm = 2.2322e-01, time/batch = 16.3062s	
8742/22300 (epoch 19.601), train_loss = 0.55797227, grad/param norm = 2.7191e-01, time/batch = 16.2571s	
8743/22300 (epoch 19.603), train_loss = 0.63426669, grad/param norm = 2.5055e-01, time/batch = 17.0334s	
8744/22300 (epoch 19.605), train_loss = 0.56627367, grad/param norm = 2.5079e-01, time/batch = 15.1367s	
8745/22300 (epoch 19.608), train_loss = 0.94421891, grad/param norm = 3.8517e-01, time/batch = 15.4640s	
8746/22300 (epoch 19.610), train_loss = 0.93420527, grad/param norm = 3.5159e-01, time/batch = 15.8187s	
8747/22300 (epoch 19.612), train_loss = 0.75752297, grad/param norm = 3.0963e-01, time/batch = 16.6275s	
8748/22300 (epoch 19.614), train_loss = 0.78488980, grad/param norm = 2.9991e-01, time/batch = 15.8095s	
8749/22300 (epoch 19.617), train_loss = 0.71107745, grad/param norm = 2.8170e-01, time/batch = 15.2415s	
8750/22300 (epoch 19.619), train_loss = 0.90567450, grad/param norm = 2.9730e-01, time/batch = 16.6263s	
8751/22300 (epoch 19.621), train_loss = 0.62894054, grad/param norm = 2.5912e-01, time/batch = 16.3536s	
8752/22300 (epoch 19.623), train_loss = 0.60602844, grad/param norm = 2.5736e-01, time/batch = 15.3541s	
8753/22300 (epoch 19.626), train_loss = 0.56031075, grad/param norm = 2.4529e-01, time/batch = 15.3076s	
8754/22300 (epoch 19.628), train_loss = 0.56593139, grad/param norm = 2.1962e-01, time/batch = 15.8130s	
8755/22300 (epoch 19.630), train_loss = 0.62243793, grad/param norm = 2.3328e-01, time/batch = 15.3616s	
8756/22300 (epoch 19.632), train_loss = 0.62094618, grad/param norm = 2.5801e-01, time/batch = 15.5475s	
8757/22300 (epoch 19.635), train_loss = 0.63349878, grad/param norm = 2.7981e-01, time/batch = 15.4039s	
8758/22300 (epoch 19.637), train_loss = 0.74766782, grad/param norm = 2.9704e-01, time/batch = 16.1060s	
8759/22300 (epoch 19.639), train_loss = 0.80999736, grad/param norm = 2.8910e-01, time/batch = 15.6409s	
8760/22300 (epoch 19.641), train_loss = 0.69326493, grad/param norm = 2.6506e-01, time/batch = 17.0338s	
8761/22300 (epoch 19.643), train_loss = 0.62869485, grad/param norm = 3.0368e-01, time/batch = 14.9687s	
8762/22300 (epoch 19.646), train_loss = 0.56695079, grad/param norm = 2.4430e-01, time/batch = 15.8835s	
8763/22300 (epoch 19.648), train_loss = 0.62284364, grad/param norm = 2.7566e-01, time/batch = 15.8108s	
8764/22300 (epoch 19.650), train_loss = 0.71010325, grad/param norm = 2.9157e-01, time/batch = 15.0572s	
8765/22300 (epoch 19.652), train_loss = 0.59717869, grad/param norm = 2.5009e-01, time/batch = 16.3909s	
8766/22300 (epoch 19.655), train_loss = 0.60516405, grad/param norm = 2.7503e-01, time/batch = 16.2022s	
8767/22300 (epoch 19.657), train_loss = 0.66005920, grad/param norm = 2.6301e-01, time/batch = 15.8204s	
8768/22300 (epoch 19.659), train_loss = 0.57733390, grad/param norm = 2.5270e-01, time/batch = 14.6462s	
8769/22300 (epoch 19.661), train_loss = 0.46618227, grad/param norm = 1.9939e-01, time/batch = 15.2208s	
8770/22300 (epoch 19.664), train_loss = 0.56369971, grad/param norm = 2.1980e-01, time/batch = 15.2032s	
8771/22300 (epoch 19.666), train_loss = 0.69240764, grad/param norm = 2.6190e-01, time/batch = 15.6368s	
8772/22300 (epoch 19.668), train_loss = 0.54973160, grad/param norm = 2.1668e-01, time/batch = 14.6477s	
8773/22300 (epoch 19.670), train_loss = 0.69172361, grad/param norm = 2.6772e-01, time/batch = 14.8131s	
8774/22300 (epoch 19.673), train_loss = 0.75123252, grad/param norm = 3.0593e-01, time/batch = 15.5496s	
8775/22300 (epoch 19.675), train_loss = 0.84039508, grad/param norm = 3.1380e-01, time/batch = 18.4467s	
8776/22300 (epoch 19.677), train_loss = 0.86477590, grad/param norm = 3.2517e-01, time/batch = 16.9559s	
8777/22300 (epoch 19.679), train_loss = 0.71072700, grad/param norm = 2.7779e-01, time/batch = 16.3848s	
8778/22300 (epoch 19.682), train_loss = 0.70120459, grad/param norm = 3.0264e-01, time/batch = 15.2943s	
8779/22300 (epoch 19.684), train_loss = 0.67338938, grad/param norm = 2.6581e-01, time/batch = 15.6850s	
8780/22300 (epoch 19.686), train_loss = 0.68340499, grad/param norm = 2.5131e-01, time/batch = 15.5448s	
8781/22300 (epoch 19.688), train_loss = 0.64581559, grad/param norm = 2.9758e-01, time/batch = 16.4617s	
8782/22300 (epoch 19.691), train_loss = 0.59091232, grad/param norm = 2.7479e-01, time/batch = 16.3793s	
8783/22300 (epoch 19.693), train_loss = 0.57660504, grad/param norm = 2.6805e-01, time/batch = 14.5747s	
8784/22300 (epoch 19.695), train_loss = 0.51255880, grad/param norm = 2.7105e-01, time/batch = 16.9765s	
8785/22300 (epoch 19.697), train_loss = 0.55675603, grad/param norm = 2.3710e-01, time/batch = 15.4524s	
8786/22300 (epoch 19.700), train_loss = 0.56614180, grad/param norm = 2.4577e-01, time/batch = 17.0395s	
8787/22300 (epoch 19.702), train_loss = 0.58564708, grad/param norm = 2.4218e-01, time/batch = 15.3131s	
8788/22300 (epoch 19.704), train_loss = 0.66252230, grad/param norm = 2.8237e-01, time/batch = 15.4871s	
8789/22300 (epoch 19.706), train_loss = 0.55047488, grad/param norm = 2.4639e-01, time/batch = 15.4593s	
8790/22300 (epoch 19.709), train_loss = 0.47059822, grad/param norm = 2.2694e-01, time/batch = 15.9420s	
8791/22300 (epoch 19.711), train_loss = 0.47548811, grad/param norm = 2.1226e-01, time/batch = 15.8594s	
8792/22300 (epoch 19.713), train_loss = 0.66189098, grad/param norm = 2.7699e-01, time/batch = 16.0512s	
8793/22300 (epoch 19.715), train_loss = 0.66056748, grad/param norm = 2.9050e-01, time/batch = 15.2103s	
8794/22300 (epoch 19.717), train_loss = 0.81827822, grad/param norm = 2.6622e-01, time/batch = 14.8846s	
8795/22300 (epoch 19.720), train_loss = 0.56812985, grad/param norm = 2.3938e-01, time/batch = 14.9767s	
8796/22300 (epoch 19.722), train_loss = 0.65614086, grad/param norm = 2.7746e-01, time/batch = 14.9944s	
8797/22300 (epoch 19.724), train_loss = 0.73225970, grad/param norm = 3.1519e-01, time/batch = 16.3126s	
8798/22300 (epoch 19.726), train_loss = 0.60231206, grad/param norm = 2.8956e-01, time/batch = 17.1461s	
8799/22300 (epoch 19.729), train_loss = 0.64929809, grad/param norm = 2.9978e-01, time/batch = 15.2682s	
8800/22300 (epoch 19.731), train_loss = 0.82152051, grad/param norm = 3.0620e-01, time/batch = 16.7025s	
8801/22300 (epoch 19.733), train_loss = 0.86200920, grad/param norm = 3.2844e-01, time/batch = 15.9750s	
8802/22300 (epoch 19.735), train_loss = 0.85854904, grad/param norm = 3.3476e-01, time/batch = 16.9722s	
8803/22300 (epoch 19.738), train_loss = 0.65245606, grad/param norm = 3.1060e-01, time/batch = 17.7827s	
8804/22300 (epoch 19.740), train_loss = 0.57274460, grad/param norm = 2.6051e-01, time/batch = 15.9553s	
8805/22300 (epoch 19.742), train_loss = 0.63877206, grad/param norm = 2.6937e-01, time/batch = 18.5389s	
8806/22300 (epoch 19.744), train_loss = 0.90347096, grad/param norm = 3.2924e-01, time/batch = 16.3924s	
8807/22300 (epoch 19.747), train_loss = 0.72096039, grad/param norm = 2.6518e-01, time/batch = 17.7051s	
8808/22300 (epoch 19.749), train_loss = 0.93534227, grad/param norm = 3.0225e-01, time/batch = 17.0426s	
8809/22300 (epoch 19.751), train_loss = 0.82798075, grad/param norm = 3.5824e-01, time/batch = 16.1025s	
8810/22300 (epoch 19.753), train_loss = 0.84578173, grad/param norm = 3.0417e-01, time/batch = 15.7342s	
8811/22300 (epoch 19.756), train_loss = 0.74879205, grad/param norm = 2.8258e-01, time/batch = 17.0486s	
8812/22300 (epoch 19.758), train_loss = 0.69325618, grad/param norm = 2.6714e-01, time/batch = 17.6237s	
8813/22300 (epoch 19.760), train_loss = 0.70316740, grad/param norm = 2.6385e-01, time/batch = 15.7716s	
8814/22300 (epoch 19.762), train_loss = 0.68388286, grad/param norm = 2.8036e-01, time/batch = 15.4653s	
8815/22300 (epoch 19.765), train_loss = 0.70562479, grad/param norm = 2.8082e-01, time/batch = 16.2162s	
8816/22300 (epoch 19.767), train_loss = 0.72094894, grad/param norm = 2.8171e-01, time/batch = 17.6378s	
8817/22300 (epoch 19.769), train_loss = 0.66900611, grad/param norm = 2.7847e-01, time/batch = 15.8800s	
8818/22300 (epoch 19.771), train_loss = 0.76355824, grad/param norm = 3.1201e-01, time/batch = 15.4826s	
8819/22300 (epoch 19.774), train_loss = 0.81943949, grad/param norm = 4.3357e-01, time/batch = 17.8027s	
8820/22300 (epoch 19.776), train_loss = 0.85513832, grad/param norm = 3.3917e-01, time/batch = 17.0546s	
8821/22300 (epoch 19.778), train_loss = 0.83984418, grad/param norm = 3.1273e-01, time/batch = 16.2967s	
8822/22300 (epoch 19.780), train_loss = 0.82962246, grad/param norm = 3.0087e-01, time/batch = 16.1158s	
8823/22300 (epoch 19.783), train_loss = 0.89396815, grad/param norm = 3.2967e-01, time/batch = 15.2959s	
8824/22300 (epoch 19.785), train_loss = 0.64761401, grad/param norm = 2.5860e-01, time/batch = 17.3962s	
8825/22300 (epoch 19.787), train_loss = 0.64680069, grad/param norm = 2.7214e-01, time/batch = 17.3717s	
8826/22300 (epoch 19.789), train_loss = 0.86989417, grad/param norm = 3.3339e-01, time/batch = 16.8882s	
8827/22300 (epoch 19.791), train_loss = 1.00371698, grad/param norm = 3.3005e-01, time/batch = 16.5415s	
8828/22300 (epoch 19.794), train_loss = 0.88002965, grad/param norm = 3.7783e-01, time/batch = 15.8061s	
8829/22300 (epoch 19.796), train_loss = 0.86657069, grad/param norm = 3.3196e-01, time/batch = 15.3183s	
8830/22300 (epoch 19.798), train_loss = 0.94772000, grad/param norm = 3.0034e-01, time/batch = 14.2314s	
8831/22300 (epoch 19.800), train_loss = 0.68901983, grad/param norm = 2.6833e-01, time/batch = 17.2080s	
8832/22300 (epoch 19.803), train_loss = 0.63343056, grad/param norm = 2.7113e-01, time/batch = 17.7116s	
8833/22300 (epoch 19.805), train_loss = 0.72726706, grad/param norm = 2.6529e-01, time/batch = 15.2192s	
8834/22300 (epoch 19.807), train_loss = 0.86592801, grad/param norm = 3.1672e-01, time/batch = 15.2459s	
8835/22300 (epoch 19.809), train_loss = 0.65442139, grad/param norm = 2.9174e-01, time/batch = 15.7264s	
8836/22300 (epoch 19.812), train_loss = 0.78795039, grad/param norm = 3.1199e-01, time/batch = 16.5503s	
8837/22300 (epoch 19.814), train_loss = 0.79126366, grad/param norm = 2.8787e-01, time/batch = 16.4694s	
8838/22300 (epoch 19.816), train_loss = 0.78018223, grad/param norm = 2.8929e-01, time/batch = 14.7991s	
8839/22300 (epoch 19.818), train_loss = 0.88199906, grad/param norm = 3.1552e-01, time/batch = 18.0626s	
8840/22300 (epoch 19.821), train_loss = 0.78534560, grad/param norm = 3.8594e-01, time/batch = 16.2544s	
8841/22300 (epoch 19.823), train_loss = 0.55088564, grad/param norm = 2.9281e-01, time/batch = 18.5354s	
8842/22300 (epoch 19.825), train_loss = 0.64673577, grad/param norm = 2.9142e-01, time/batch = 15.1462s	
8843/22300 (epoch 19.827), train_loss = 0.68756286, grad/param norm = 2.9649e-01, time/batch = 16.3485s	
8844/22300 (epoch 19.830), train_loss = 0.64414539, grad/param norm = 3.1408e-01, time/batch = 15.7105s	
8845/22300 (epoch 19.832), train_loss = 0.62924927, grad/param norm = 2.9922e-01, time/batch = 18.9672s	
8846/22300 (epoch 19.834), train_loss = 0.60738464, grad/param norm = 2.7172e-01, time/batch = 15.2011s	
8847/22300 (epoch 19.836), train_loss = 0.72508796, grad/param norm = 3.0322e-01, time/batch = 16.7970s	
8848/22300 (epoch 19.839), train_loss = 0.64881748, grad/param norm = 2.6421e-01, time/batch = 16.7190s	
8849/22300 (epoch 19.841), train_loss = 0.69181901, grad/param norm = 3.0478e-01, time/batch = 16.2980s	
8850/22300 (epoch 19.843), train_loss = 0.67630430, grad/param norm = 2.5295e-01, time/batch = 14.4112s	
8851/22300 (epoch 19.845), train_loss = 0.67393106, grad/param norm = 2.5204e-01, time/batch = 15.4738s	
8852/22300 (epoch 19.848), train_loss = 0.68967457, grad/param norm = 2.7025e-01, time/batch = 16.1395s	
8853/22300 (epoch 19.850), train_loss = 0.64855019, grad/param norm = 2.3390e-01, time/batch = 15.7147s	
8854/22300 (epoch 19.852), train_loss = 0.66402274, grad/param norm = 2.8366e-01, time/batch = 16.1536s	
8855/22300 (epoch 19.854), train_loss = 0.88479790, grad/param norm = 3.1701e-01, time/batch = 15.9691s	
8856/22300 (epoch 19.857), train_loss = 0.73424322, grad/param norm = 3.4641e-01, time/batch = 17.5452s	
8857/22300 (epoch 19.859), train_loss = 0.56188674, grad/param norm = 2.5724e-01, time/batch = 15.6253s	
8858/22300 (epoch 19.861), train_loss = 0.74513941, grad/param norm = 2.8170e-01, time/batch = 16.9685s	
8859/22300 (epoch 19.863), train_loss = 0.57293680, grad/param norm = 2.5665e-01, time/batch = 16.1346s	
8860/22300 (epoch 19.865), train_loss = 0.55231622, grad/param norm = 2.3562e-01, time/batch = 15.3822s	
8861/22300 (epoch 19.868), train_loss = 0.69776584, grad/param norm = 3.1326e-01, time/batch = 17.3802s	
8862/22300 (epoch 19.870), train_loss = 0.75743515, grad/param norm = 3.4450e-01, time/batch = 16.2897s	
8863/22300 (epoch 19.872), train_loss = 0.80648274, grad/param norm = 2.8829e-01, time/batch = 16.3862s	
8864/22300 (epoch 19.874), train_loss = 0.72374574, grad/param norm = 2.8584e-01, time/batch = 15.8265s	
8865/22300 (epoch 19.877), train_loss = 0.71568052, grad/param norm = 2.7566e-01, time/batch = 17.1042s	
8866/22300 (epoch 19.879), train_loss = 0.61567551, grad/param norm = 2.5361e-01, time/batch = 15.8800s	
8867/22300 (epoch 19.881), train_loss = 0.59910558, grad/param norm = 2.4744e-01, time/batch = 15.8710s	
8868/22300 (epoch 19.883), train_loss = 0.59571636, grad/param norm = 2.5681e-01, time/batch = 16.6130s	
8869/22300 (epoch 19.886), train_loss = 0.57658092, grad/param norm = 2.5705e-01, time/batch = 16.8826s	
8870/22300 (epoch 19.888), train_loss = 0.64651046, grad/param norm = 2.5414e-01, time/batch = 17.1370s	
8871/22300 (epoch 19.890), train_loss = 0.59994698, grad/param norm = 2.4548e-01, time/batch = 16.3106s	
8872/22300 (epoch 19.892), train_loss = 0.87749010, grad/param norm = 3.0173e-01, time/batch = 18.2143s	
8873/22300 (epoch 19.895), train_loss = 0.85338356, grad/param norm = 2.9338e-01, time/batch = 15.3825s	
8874/22300 (epoch 19.897), train_loss = 0.69926334, grad/param norm = 3.0600e-01, time/batch = 17.2958s	
8875/22300 (epoch 19.899), train_loss = 0.68812207, grad/param norm = 2.6063e-01, time/batch = 18.3814s	
8876/22300 (epoch 19.901), train_loss = 0.70087789, grad/param norm = 3.1826e-01, time/batch = 15.5674s	
8877/22300 (epoch 19.904), train_loss = 0.76146743, grad/param norm = 2.8699e-01, time/batch = 15.4818s	
8878/22300 (epoch 19.906), train_loss = 0.74543970, grad/param norm = 2.8352e-01, time/batch = 15.3762s	
8879/22300 (epoch 19.908), train_loss = 0.68426082, grad/param norm = 2.5577e-01, time/batch = 16.3863s	
8880/22300 (epoch 19.910), train_loss = 0.58136777, grad/param norm = 3.4418e-01, time/batch = 17.2886s	
8881/22300 (epoch 19.913), train_loss = 0.77763401, grad/param norm = 2.9194e-01, time/batch = 16.5515s	
8882/22300 (epoch 19.915), train_loss = 0.88668002, grad/param norm = 3.1012e-01, time/batch = 16.6294s	
8883/22300 (epoch 19.917), train_loss = 0.72173788, grad/param norm = 2.9271e-01, time/batch = 17.2251s	
8884/22300 (epoch 19.919), train_loss = 0.74472653, grad/param norm = 2.4101e-01, time/batch = 15.8032s	
8885/22300 (epoch 19.922), train_loss = 0.66336335, grad/param norm = 2.8159e-01, time/batch = 17.0396s	
8886/22300 (epoch 19.924), train_loss = 0.46910943, grad/param norm = 2.3980e-01, time/batch = 16.8919s	
8887/22300 (epoch 19.926), train_loss = 0.56701999, grad/param norm = 2.5738e-01, time/batch = 17.5485s	
8888/22300 (epoch 19.928), train_loss = 0.65635749, grad/param norm = 2.8180e-01, time/batch = 16.1384s	
8889/22300 (epoch 19.930), train_loss = 0.64665359, grad/param norm = 2.4908e-01, time/batch = 17.3848s	
8890/22300 (epoch 19.933), train_loss = 0.74148449, grad/param norm = 2.5629e-01, time/batch = 17.2951s	
8891/22300 (epoch 19.935), train_loss = 0.76038159, grad/param norm = 3.4054e-01, time/batch = 15.7964s	
8892/22300 (epoch 19.937), train_loss = 0.86173224, grad/param norm = 3.3438e-01, time/batch = 16.5549s	
8893/22300 (epoch 19.939), train_loss = 0.79976114, grad/param norm = 3.0509e-01, time/batch = 15.1158s	
8894/22300 (epoch 19.942), train_loss = 0.94634934, grad/param norm = 3.4803e-01, time/batch = 15.4624s	
8895/22300 (epoch 19.944), train_loss = 1.01389335, grad/param norm = 3.6912e-01, time/batch = 17.1374s	
8896/22300 (epoch 19.946), train_loss = 0.74326395, grad/param norm = 3.2993e-01, time/batch = 16.6352s	
8897/22300 (epoch 19.948), train_loss = 0.59795775, grad/param norm = 2.1258e-01, time/batch = 18.3081s	
8898/22300 (epoch 19.951), train_loss = 0.56116117, grad/param norm = 2.6036e-01, time/batch = 16.0389s	
8899/22300 (epoch 19.953), train_loss = 0.61061196, grad/param norm = 2.7880e-01, time/batch = 17.9699s	
8900/22300 (epoch 19.955), train_loss = 0.88432271, grad/param norm = 3.1650e-01, time/batch = 16.2355s	
8901/22300 (epoch 19.957), train_loss = 0.97714681, grad/param norm = 3.2255e-01, time/batch = 15.7983s	
8902/22300 (epoch 19.960), train_loss = 0.82816368, grad/param norm = 2.8934e-01, time/batch = 15.6199s	
8903/22300 (epoch 19.962), train_loss = 0.68389626, grad/param norm = 2.9849e-01, time/batch = 16.3740s	
8904/22300 (epoch 19.964), train_loss = 0.67147160, grad/param norm = 2.7538e-01, time/batch = 14.7307s	
8905/22300 (epoch 19.966), train_loss = 0.58176338, grad/param norm = 2.4448e-01, time/batch = 16.7079s	
8906/22300 (epoch 19.969), train_loss = 0.64327064, grad/param norm = 2.3527e-01, time/batch = 16.5654s	
8907/22300 (epoch 19.971), train_loss = 0.67424795, grad/param norm = 2.4145e-01, time/batch = 15.5589s	
8908/22300 (epoch 19.973), train_loss = 0.70524036, grad/param norm = 2.7474e-01, time/batch = 15.6751s	
8909/22300 (epoch 19.975), train_loss = 0.87578837, grad/param norm = 3.3563e-01, time/batch = 16.3826s	
8910/22300 (epoch 19.978), train_loss = 0.77551906, grad/param norm = 3.3185e-01, time/batch = 15.3981s	
8911/22300 (epoch 19.980), train_loss = 0.85902505, grad/param norm = 3.1230e-01, time/batch = 15.9722s	
8912/22300 (epoch 19.982), train_loss = 0.60657641, grad/param norm = 2.9225e-01, time/batch = 18.7073s	
8913/22300 (epoch 19.984), train_loss = 0.74029370, grad/param norm = 2.7010e-01, time/batch = 15.2884s	
8914/22300 (epoch 19.987), train_loss = 0.64490220, grad/param norm = 3.0007e-01, time/batch = 18.2999s	
8915/22300 (epoch 19.989), train_loss = 0.66244854, grad/param norm = 2.8476e-01, time/batch = 15.3721s	
8916/22300 (epoch 19.991), train_loss = 0.94889131, grad/param norm = 3.5280e-01, time/batch = 18.0811s	
8917/22300 (epoch 19.993), train_loss = 1.14328191, grad/param norm = 3.7424e-01, time/batch = 28.5033s	
8918/22300 (epoch 19.996), train_loss = 1.01221953, grad/param norm = 3.2356e-01, time/batch = 15.9771s	
8919/22300 (epoch 19.998), train_loss = 0.73562212, grad/param norm = 2.8279e-01, time/batch = 17.2063s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
8920/22300 (epoch 20.000), train_loss = 0.60521592, grad/param norm = 2.6795e-01, time/batch = 16.6540s	
8921/22300 (epoch 20.002), train_loss = 0.97272957, grad/param norm = 3.3424e-01, time/batch = 16.2233s	
8922/22300 (epoch 20.004), train_loss = 0.72599893, grad/param norm = 2.7519e-01, time/batch = 16.6236s	
8923/22300 (epoch 20.007), train_loss = 0.72131653, grad/param norm = 2.8706e-01, time/batch = 15.2131s	
8924/22300 (epoch 20.009), train_loss = 0.75554341, grad/param norm = 2.9612e-01, time/batch = 17.7094s	
8925/22300 (epoch 20.011), train_loss = 0.90720061, grad/param norm = 3.2235e-01, time/batch = 15.6406s	
8926/22300 (epoch 20.013), train_loss = 0.72057536, grad/param norm = 2.5696e-01, time/batch = 16.9337s	
8927/22300 (epoch 20.016), train_loss = 0.64703714, grad/param norm = 3.0936e-01, time/batch = 18.0359s	
8928/22300 (epoch 20.018), train_loss = 0.77861116, grad/param norm = 2.7225e-01, time/batch = 15.9661s	
8929/22300 (epoch 20.020), train_loss = 0.65920309, grad/param norm = 2.8756e-01, time/batch = 17.7196s	
8930/22300 (epoch 20.022), train_loss = 0.60790488, grad/param norm = 2.9632e-01, time/batch = 15.8646s	
8931/22300 (epoch 20.025), train_loss = 0.58716152, grad/param norm = 2.3913e-01, time/batch = 14.8883s	
8932/22300 (epoch 20.027), train_loss = 0.62603149, grad/param norm = 2.3304e-01, time/batch = 17.5601s	
8933/22300 (epoch 20.029), train_loss = 0.60202131, grad/param norm = 2.3021e-01, time/batch = 18.2901s	
8934/22300 (epoch 20.031), train_loss = 0.60851603, grad/param norm = 2.2129e-01, time/batch = 6.2363s	
8935/22300 (epoch 20.034), train_loss = 0.63413059, grad/param norm = 2.5779e-01, time/batch = 0.6781s	
8936/22300 (epoch 20.036), train_loss = 0.50423914, grad/param norm = 2.1271e-01, time/batch = 0.6688s	
8937/22300 (epoch 20.038), train_loss = 0.64017887, grad/param norm = 2.7142e-01, time/batch = 0.6608s	
8938/22300 (epoch 20.040), train_loss = 0.65013348, grad/param norm = 2.6661e-01, time/batch = 0.6674s	
8939/22300 (epoch 20.043), train_loss = 0.92481995, grad/param norm = 2.9762e-01, time/batch = 0.6522s	
8940/22300 (epoch 20.045), train_loss = 0.75456811, grad/param norm = 2.7677e-01, time/batch = 0.6640s	
8941/22300 (epoch 20.047), train_loss = 0.78996530, grad/param norm = 2.9261e-01, time/batch = 0.7125s	
8942/22300 (epoch 20.049), train_loss = 0.66220196, grad/param norm = 2.8075e-01, time/batch = 0.9679s	
8943/22300 (epoch 20.052), train_loss = 0.77521900, grad/param norm = 3.1179e-01, time/batch = 0.9694s	
8944/22300 (epoch 20.054), train_loss = 0.70766273, grad/param norm = 2.6203e-01, time/batch = 0.9685s	
8945/22300 (epoch 20.056), train_loss = 0.45255273, grad/param norm = 2.0879e-01, time/batch = 0.9694s	
8946/22300 (epoch 20.058), train_loss = 0.61191025, grad/param norm = 2.5954e-01, time/batch = 0.9709s	
8947/22300 (epoch 20.061), train_loss = 0.61185665, grad/param norm = 2.9397e-01, time/batch = 1.7997s	
8948/22300 (epoch 20.063), train_loss = 0.87416050, grad/param norm = 4.0568e-01, time/batch = 1.8092s	
8949/22300 (epoch 20.065), train_loss = 0.84187900, grad/param norm = 3.3342e-01, time/batch = 6.0783s	
8950/22300 (epoch 20.067), train_loss = 0.66898652, grad/param norm = 3.2942e-01, time/batch = 16.9813s	
8951/22300 (epoch 20.070), train_loss = 0.67002304, grad/param norm = 2.8104e-01, time/batch = 17.3021s	
8952/22300 (epoch 20.072), train_loss = 0.79312281, grad/param norm = 3.3083e-01, time/batch = 16.8031s	
8953/22300 (epoch 20.074), train_loss = 0.74252805, grad/param norm = 3.0392e-01, time/batch = 16.4005s	
8954/22300 (epoch 20.076), train_loss = 0.68430210, grad/param norm = 2.8767e-01, time/batch = 15.0404s	
8955/22300 (epoch 20.078), train_loss = 0.80185114, grad/param norm = 3.0630e-01, time/batch = 15.4723s	
8956/22300 (epoch 20.081), train_loss = 0.80966476, grad/param norm = 3.0853e-01, time/batch = 18.3127s	
8957/22300 (epoch 20.083), train_loss = 0.90036753, grad/param norm = 3.1912e-01, time/batch = 16.1166s	
8958/22300 (epoch 20.085), train_loss = 0.94068548, grad/param norm = 3.4524e-01, time/batch = 17.8678s	
8959/22300 (epoch 20.087), train_loss = 0.76439730, grad/param norm = 2.7170e-01, time/batch = 15.2309s	
8960/22300 (epoch 20.090), train_loss = 0.65110557, grad/param norm = 2.7362e-01, time/batch = 16.6446s	
8961/22300 (epoch 20.092), train_loss = 0.57172736, grad/param norm = 2.4775e-01, time/batch = 16.0359s	
8962/22300 (epoch 20.094), train_loss = 0.58446969, grad/param norm = 2.6362e-01, time/batch = 17.4644s	
8963/22300 (epoch 20.096), train_loss = 0.90210061, grad/param norm = 3.9434e-01, time/batch = 17.4644s	
8964/22300 (epoch 20.099), train_loss = 0.65366346, grad/param norm = 3.0714e-01, time/batch = 15.7935s	
8965/22300 (epoch 20.101), train_loss = 0.81379928, grad/param norm = 3.2789e-01, time/batch = 15.9621s	
8966/22300 (epoch 20.103), train_loss = 0.71660648, grad/param norm = 2.6933e-01, time/batch = 14.9405s	
8967/22300 (epoch 20.105), train_loss = 0.64211864, grad/param norm = 3.0487e-01, time/batch = 16.9602s	
8968/22300 (epoch 20.108), train_loss = 0.74150038, grad/param norm = 2.9898e-01, time/batch = 16.6429s	
8969/22300 (epoch 20.110), train_loss = 0.76364229, grad/param norm = 2.7284e-01, time/batch = 17.5464s	
8970/22300 (epoch 20.112), train_loss = 0.72933905, grad/param norm = 2.6718e-01, time/batch = 15.1434s	
8971/22300 (epoch 20.114), train_loss = 0.81538762, grad/param norm = 3.1879e-01, time/batch = 17.5619s	
8972/22300 (epoch 20.117), train_loss = 0.90454883, grad/param norm = 2.8632e-01, time/batch = 15.1330s	
8973/22300 (epoch 20.119), train_loss = 0.82914207, grad/param norm = 3.0049e-01, time/batch = 15.3760s	
8974/22300 (epoch 20.121), train_loss = 0.88849342, grad/param norm = 2.9343e-01, time/batch = 15.9549s	
8975/22300 (epoch 20.123), train_loss = 0.88227799, grad/param norm = 3.1734e-01, time/batch = 17.7169s	
8976/22300 (epoch 20.126), train_loss = 0.74814406, grad/param norm = 3.0197e-01, time/batch = 16.6388s	
8977/22300 (epoch 20.128), train_loss = 0.81259260, grad/param norm = 2.7698e-01, time/batch = 15.7991s	
8978/22300 (epoch 20.130), train_loss = 0.64932487, grad/param norm = 2.6816e-01, time/batch = 16.3778s	
8979/22300 (epoch 20.132), train_loss = 0.53823164, grad/param norm = 2.3072e-01, time/batch = 17.9492s	
8980/22300 (epoch 20.135), train_loss = 0.58720430, grad/param norm = 2.8693e-01, time/batch = 17.2147s	
8981/22300 (epoch 20.137), train_loss = 0.47506809, grad/param norm = 2.5660e-01, time/batch = 16.8794s	
8982/22300 (epoch 20.139), train_loss = 0.73673405, grad/param norm = 3.2489e-01, time/batch = 15.2751s	
8983/22300 (epoch 20.141), train_loss = 0.78221656, grad/param norm = 2.7044e-01, time/batch = 16.3985s	
8984/22300 (epoch 20.143), train_loss = 0.72214682, grad/param norm = 2.6189e-01, time/batch = 16.0355s	
8985/22300 (epoch 20.146), train_loss = 0.82363128, grad/param norm = 2.9382e-01, time/batch = 17.4659s	
8986/22300 (epoch 20.148), train_loss = 0.59692437, grad/param norm = 2.4785e-01, time/batch = 15.6387s	
8987/22300 (epoch 20.150), train_loss = 0.66129887, grad/param norm = 2.9900e-01, time/batch = 16.0512s	
8988/22300 (epoch 20.152), train_loss = 0.56757188, grad/param norm = 2.9052e-01, time/batch = 15.4126s	
8989/22300 (epoch 20.155), train_loss = 0.58742247, grad/param norm = 2.4997e-01, time/batch = 17.6306s	
8990/22300 (epoch 20.157), train_loss = 0.76267406, grad/param norm = 2.9084e-01, time/batch = 15.7397s	
8991/22300 (epoch 20.159), train_loss = 0.79452986, grad/param norm = 2.9730e-01, time/batch = 17.1232s	
8992/22300 (epoch 20.161), train_loss = 0.79062524, grad/param norm = 2.9107e-01, time/batch = 16.5373s	
8993/22300 (epoch 20.164), train_loss = 0.57264141, grad/param norm = 2.2557e-01, time/batch = 15.6143s	
8994/22300 (epoch 20.166), train_loss = 0.55318893, grad/param norm = 2.1466e-01, time/batch = 16.3670s	
8995/22300 (epoch 20.168), train_loss = 0.58061826, grad/param norm = 2.4582e-01, time/batch = 17.2026s	
8996/22300 (epoch 20.170), train_loss = 0.71727565, grad/param norm = 2.5899e-01, time/batch = 15.2872s	
8997/22300 (epoch 20.173), train_loss = 0.85321993, grad/param norm = 3.1689e-01, time/batch = 16.0661s	
8998/22300 (epoch 20.175), train_loss = 0.68779826, grad/param norm = 3.0334e-01, time/batch = 17.7144s	
8999/22300 (epoch 20.177), train_loss = 0.55155455, grad/param norm = 2.8936e-01, time/batch = 15.0363s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch20.18_1.5129.t7	
9000/22300 (epoch 20.179), train_loss = 0.67670789, grad/param norm = 2.5120e-01, time/batch = 18.1369s	
9001/22300 (epoch 20.182), train_loss = 1.44771201, grad/param norm = 3.5944e-01, time/batch = 17.6412s	
9002/22300 (epoch 20.184), train_loss = 0.98615511, grad/param norm = 3.3659e-01, time/batch = 17.3896s	
9003/22300 (epoch 20.186), train_loss = 0.77605533, grad/param norm = 3.0368e-01, time/batch = 17.2260s	
9004/22300 (epoch 20.188), train_loss = 0.94168813, grad/param norm = 3.0101e-01, time/batch = 14.9853s	
9005/22300 (epoch 20.191), train_loss = 0.89767930, grad/param norm = 3.2468e-01, time/batch = 18.4724s	
9006/22300 (epoch 20.193), train_loss = 0.72893493, grad/param norm = 3.2625e-01, time/batch = 15.2121s	
9007/22300 (epoch 20.195), train_loss = 0.67001625, grad/param norm = 2.4877e-01, time/batch = 17.0428s	
9008/22300 (epoch 20.197), train_loss = 0.63493542, grad/param norm = 2.5580e-01, time/batch = 16.3669s	
9009/22300 (epoch 20.200), train_loss = 0.57732237, grad/param norm = 2.6203e-01, time/batch = 15.3594s	
9010/22300 (epoch 20.202), train_loss = 0.64917821, grad/param norm = 2.6192e-01, time/batch = 18.1330s	
9011/22300 (epoch 20.204), train_loss = 0.68007449, grad/param norm = 2.5126e-01, time/batch = 16.4470s	
9012/22300 (epoch 20.206), train_loss = 0.59953785, grad/param norm = 2.4016e-01, time/batch = 18.2966s	
9013/22300 (epoch 20.209), train_loss = 0.69308329, grad/param norm = 2.9470e-01, time/batch = 15.5504s	
9014/22300 (epoch 20.211), train_loss = 0.54326937, grad/param norm = 2.7472e-01, time/batch = 15.0387s	
9015/22300 (epoch 20.213), train_loss = 0.67407817, grad/param norm = 2.5753e-01, time/batch = 16.2122s	
9016/22300 (epoch 20.215), train_loss = 0.84775475, grad/param norm = 2.9005e-01, time/batch = 16.5675s	
9017/22300 (epoch 20.217), train_loss = 0.85232589, grad/param norm = 3.4400e-01, time/batch = 16.4333s	
9018/22300 (epoch 20.220), train_loss = 0.67788206, grad/param norm = 2.7387e-01, time/batch = 16.7971s	
9019/22300 (epoch 20.222), train_loss = 0.62092771, grad/param norm = 3.2578e-01, time/batch = 17.4696s	
9020/22300 (epoch 20.224), train_loss = 0.62919382, grad/param norm = 2.6353e-01, time/batch = 17.0682s	
9021/22300 (epoch 20.226), train_loss = 0.67509769, grad/param norm = 2.4769e-01, time/batch = 16.8085s	
9022/22300 (epoch 20.229), train_loss = 0.62451280, grad/param norm = 3.2639e-01, time/batch = 15.5540s	
9023/22300 (epoch 20.231), train_loss = 0.79230866, grad/param norm = 3.3183e-01, time/batch = 15.7912s	
9024/22300 (epoch 20.233), train_loss = 0.70343306, grad/param norm = 2.5388e-01, time/batch = 15.0657s	
9025/22300 (epoch 20.235), train_loss = 0.55043772, grad/param norm = 2.4633e-01, time/batch = 17.7843s	
9026/22300 (epoch 20.238), train_loss = 0.54312563, grad/param norm = 2.0808e-01, time/batch = 15.3071s	
9027/22300 (epoch 20.240), train_loss = 0.56210187, grad/param norm = 2.1199e-01, time/batch = 17.6322s	
9028/22300 (epoch 20.242), train_loss = 0.59069716, grad/param norm = 2.7855e-01, time/batch = 16.4803s	
9029/22300 (epoch 20.244), train_loss = 0.42581920, grad/param norm = 2.4646e-01, time/batch = 16.1430s	
9030/22300 (epoch 20.247), train_loss = 0.56306439, grad/param norm = 2.5018e-01, time/batch = 17.5343s	
9031/22300 (epoch 20.249), train_loss = 0.43125726, grad/param norm = 1.9577e-01, time/batch = 16.1535s	
9032/22300 (epoch 20.251), train_loss = 0.56748509, grad/param norm = 2.2839e-01, time/batch = 16.4762s	
9033/22300 (epoch 20.253), train_loss = 0.42779415, grad/param norm = 2.2214e-01, time/batch = 16.0510s	
9034/22300 (epoch 20.256), train_loss = 0.51878893, grad/param norm = 2.5464e-01, time/batch = 15.9706s	
9035/22300 (epoch 20.258), train_loss = 0.79109564, grad/param norm = 2.8459e-01, time/batch = 14.9047s	
9036/22300 (epoch 20.260), train_loss = 0.68774843, grad/param norm = 3.2969e-01, time/batch = 16.0394s	
9037/22300 (epoch 20.262), train_loss = 0.55671812, grad/param norm = 2.4268e-01, time/batch = 16.9412s	
9038/22300 (epoch 20.265), train_loss = 0.53528529, grad/param norm = 2.4233e-01, time/batch = 15.6287s	
9039/22300 (epoch 20.267), train_loss = 0.60284971, grad/param norm = 2.3697e-01, time/batch = 17.1476s	
9040/22300 (epoch 20.269), train_loss = 0.69190479, grad/param norm = 3.1074e-01, time/batch = 15.0620s	
9041/22300 (epoch 20.271), train_loss = 0.68760637, grad/param norm = 2.7293e-01, time/batch = 15.7240s	
9042/22300 (epoch 20.274), train_loss = 0.53449164, grad/param norm = 2.7074e-01, time/batch = 16.8873s	
9043/22300 (epoch 20.276), train_loss = 0.46579340, grad/param norm = 2.4756e-01, time/batch = 15.7950s	
9044/22300 (epoch 20.278), train_loss = 0.45342389, grad/param norm = 2.0767e-01, time/batch = 15.5706s	
9045/22300 (epoch 20.280), train_loss = 0.57702277, grad/param norm = 2.6576e-01, time/batch = 16.3007s	
9046/22300 (epoch 20.283), train_loss = 0.41227869, grad/param norm = 1.7602e-01, time/batch = 19.2967s	
9047/22300 (epoch 20.285), train_loss = 0.54755615, grad/param norm = 2.7785e-01, time/batch = 15.7989s	
9048/22300 (epoch 20.287), train_loss = 0.66023855, grad/param norm = 2.5049e-01, time/batch = 16.2238s	
9049/22300 (epoch 20.289), train_loss = 0.58445546, grad/param norm = 2.3865e-01, time/batch = 17.2183s	
9050/22300 (epoch 20.291), train_loss = 0.59550006, grad/param norm = 2.4757e-01, time/batch = 17.0509s	
9051/22300 (epoch 20.294), train_loss = 0.51788955, grad/param norm = 2.1720e-01, time/batch = 15.8598s	
9052/22300 (epoch 20.296), train_loss = 0.66665831, grad/param norm = 2.7332e-01, time/batch = 15.9658s	
9053/22300 (epoch 20.298), train_loss = 0.73619782, grad/param norm = 2.5684e-01, time/batch = 15.4796s	
9054/22300 (epoch 20.300), train_loss = 0.84325351, grad/param norm = 3.0932e-01, time/batch = 17.2694s	
9055/22300 (epoch 20.303), train_loss = 0.63127688, grad/param norm = 2.9350e-01, time/batch = 16.5476s	
9056/22300 (epoch 20.305), train_loss = 0.67148318, grad/param norm = 3.6147e-01, time/batch = 16.6306s	
9057/22300 (epoch 20.307), train_loss = 0.59139419, grad/param norm = 2.5930e-01, time/batch = 15.8187s	
9058/22300 (epoch 20.309), train_loss = 0.57454463, grad/param norm = 2.7619e-01, time/batch = 16.0329s	
9059/22300 (epoch 20.312), train_loss = 0.49531342, grad/param norm = 2.1470e-01, time/batch = 16.5462s	
9060/22300 (epoch 20.314), train_loss = 0.54964411, grad/param norm = 2.4849e-01, time/batch = 15.7922s	
9061/22300 (epoch 20.316), train_loss = 0.60296353, grad/param norm = 2.9692e-01, time/batch = 17.7145s	
9062/22300 (epoch 20.318), train_loss = 0.63440202, grad/param norm = 2.5391e-01, time/batch = 15.8983s	
9063/22300 (epoch 20.321), train_loss = 0.72612989, grad/param norm = 2.6677e-01, time/batch = 16.2118s	
9064/22300 (epoch 20.323), train_loss = 0.55819660, grad/param norm = 2.4822e-01, time/batch = 15.4717s	
9065/22300 (epoch 20.325), train_loss = 0.50578765, grad/param norm = 2.2640e-01, time/batch = 16.9718s	
9066/22300 (epoch 20.327), train_loss = 0.50932404, grad/param norm = 2.2873e-01, time/batch = 16.0635s	
9067/22300 (epoch 20.330), train_loss = 0.55708191, grad/param norm = 2.7174e-01, time/batch = 17.1472s	
9068/22300 (epoch 20.332), train_loss = 0.54026034, grad/param norm = 2.7402e-01, time/batch = 16.3953s	
9069/22300 (epoch 20.334), train_loss = 0.54393813, grad/param norm = 2.6369e-01, time/batch = 15.0840s	
9070/22300 (epoch 20.336), train_loss = 0.56651248, grad/param norm = 2.3065e-01, time/batch = 18.3050s	
9071/22300 (epoch 20.339), train_loss = 0.68427601, grad/param norm = 3.0034e-01, time/batch = 15.7359s	
9072/22300 (epoch 20.341), train_loss = 0.68796404, grad/param norm = 3.0138e-01, time/batch = 15.7062s	
9073/22300 (epoch 20.343), train_loss = 0.76483975, grad/param norm = 2.9737e-01, time/batch = 16.4612s	
9074/22300 (epoch 20.345), train_loss = 0.60292540, grad/param norm = 2.4831e-01, time/batch = 14.6112s	
9075/22300 (epoch 20.348), train_loss = 0.59805584, grad/param norm = 2.5287e-01, time/batch = 17.5460s	
9076/22300 (epoch 20.350), train_loss = 0.50564745, grad/param norm = 2.4221e-01, time/batch = 17.0438s	
9077/22300 (epoch 20.352), train_loss = 0.68139969, grad/param norm = 2.7593e-01, time/batch = 16.5588s	
9078/22300 (epoch 20.354), train_loss = 0.88510834, grad/param norm = 3.1726e-01, time/batch = 15.8143s	
9079/22300 (epoch 20.357), train_loss = 0.72817596, grad/param norm = 2.5383e-01, time/batch = 15.8084s	
9080/22300 (epoch 20.359), train_loss = 0.56862663, grad/param norm = 2.7272e-01, time/batch = 16.5505s	
9081/22300 (epoch 20.361), train_loss = 0.54429227, grad/param norm = 2.3600e-01, time/batch = 16.2098s	
9082/22300 (epoch 20.363), train_loss = 0.77405636, grad/param norm = 3.0013e-01, time/batch = 16.1170s	
9083/22300 (epoch 20.365), train_loss = 0.62329623, grad/param norm = 2.8438e-01, time/batch = 18.9575s	
9084/22300 (epoch 20.368), train_loss = 0.62091592, grad/param norm = 3.0188e-01, time/batch = 15.3121s	
9085/22300 (epoch 20.370), train_loss = 0.62906271, grad/param norm = 2.6865e-01, time/batch = 17.3034s	
9086/22300 (epoch 20.372), train_loss = 0.52331603, grad/param norm = 2.6199e-01, time/batch = 17.3983s	
9087/22300 (epoch 20.374), train_loss = 0.45293494, grad/param norm = 2.5273e-01, time/batch = 17.3665s	
9088/22300 (epoch 20.377), train_loss = 0.58586076, grad/param norm = 2.5045e-01, time/batch = 14.7291s	
9089/22300 (epoch 20.379), train_loss = 0.60426606, grad/param norm = 3.8764e-01, time/batch = 16.8882s	
9090/22300 (epoch 20.381), train_loss = 0.75676938, grad/param norm = 2.9256e-01, time/batch = 17.7953s	
9091/22300 (epoch 20.383), train_loss = 0.59710627, grad/param norm = 3.0945e-01, time/batch = 16.2821s	
9092/22300 (epoch 20.386), train_loss = 0.63970536, grad/param norm = 3.1648e-01, time/batch = 16.3086s	
9093/22300 (epoch 20.388), train_loss = 0.53376502, grad/param norm = 2.3631e-01, time/batch = 15.5585s	
9094/22300 (epoch 20.390), train_loss = 0.64699037, grad/param norm = 3.1078e-01, time/batch = 17.0476s	
9095/22300 (epoch 20.392), train_loss = 0.62877713, grad/param norm = 3.0569e-01, time/batch = 17.2169s	
9096/22300 (epoch 20.395), train_loss = 0.51662859, grad/param norm = 2.6075e-01, time/batch = 16.2216s	
9097/22300 (epoch 20.397), train_loss = 0.35842529, grad/param norm = 1.9702e-01, time/batch = 15.1960s	
9098/22300 (epoch 20.399), train_loss = 0.51001579, grad/param norm = 2.6195e-01, time/batch = 16.3032s	
9099/22300 (epoch 20.401), train_loss = 0.59574122, grad/param norm = 2.7317e-01, time/batch = 17.5555s	
9100/22300 (epoch 20.404), train_loss = 0.56860428, grad/param norm = 2.3598e-01, time/batch = 15.5731s	
9101/22300 (epoch 20.406), train_loss = 0.86084049, grad/param norm = 3.4662e-01, time/batch = 16.5111s	
9102/22300 (epoch 20.408), train_loss = 0.71496949, grad/param norm = 2.6857e-01, time/batch = 15.2177s	
9103/22300 (epoch 20.410), train_loss = 0.75231177, grad/param norm = 2.7544e-01, time/batch = 15.9095s	
9104/22300 (epoch 20.413), train_loss = 0.59335751, grad/param norm = 2.8267e-01, time/batch = 16.6420s	
9105/22300 (epoch 20.415), train_loss = 0.47862707, grad/param norm = 2.7618e-01, time/batch = 17.5380s	
9106/22300 (epoch 20.417), train_loss = 0.65975422, grad/param norm = 3.0541e-01, time/batch = 15.6514s	
9107/22300 (epoch 20.419), train_loss = 0.55427819, grad/param norm = 2.3036e-01, time/batch = 17.4835s	
9108/22300 (epoch 20.422), train_loss = 0.54864318, grad/param norm = 2.4982e-01, time/batch = 15.3899s	
9109/22300 (epoch 20.424), train_loss = 0.63570085, grad/param norm = 2.8954e-01, time/batch = 16.2697s	
9110/22300 (epoch 20.426), train_loss = 0.49011983, grad/param norm = 2.5802e-01, time/batch = 15.7921s	
9111/22300 (epoch 20.428), train_loss = 0.52049336, grad/param norm = 2.4506e-01, time/batch = 17.2292s	
9112/22300 (epoch 20.430), train_loss = 0.62128958, grad/param norm = 2.9295e-01, time/batch = 18.4597s	
9113/22300 (epoch 20.433), train_loss = 0.59545686, grad/param norm = 2.7614e-01, time/batch = 17.1935s	
9114/22300 (epoch 20.435), train_loss = 0.60260785, grad/param norm = 3.2083e-01, time/batch = 15.8773s	
9115/22300 (epoch 20.437), train_loss = 0.63292995, grad/param norm = 3.0357e-01, time/batch = 15.2150s	
9116/22300 (epoch 20.439), train_loss = 0.70842891, grad/param norm = 3.2521e-01, time/batch = 16.3799s	
9117/22300 (epoch 20.442), train_loss = 0.63793192, grad/param norm = 2.6623e-01, time/batch = 16.1586s	
9118/22300 (epoch 20.444), train_loss = 0.55015434, grad/param norm = 2.1407e-01, time/batch = 16.8704s	
9119/22300 (epoch 20.446), train_loss = 0.53920651, grad/param norm = 2.8515e-01, time/batch = 15.8902s	
9120/22300 (epoch 20.448), train_loss = 0.40042053, grad/param norm = 2.0951e-01, time/batch = 15.7120s	
9121/22300 (epoch 20.451), train_loss = 0.67967822, grad/param norm = 2.8808e-01, time/batch = 19.1290s	
9122/22300 (epoch 20.453), train_loss = 0.57109310, grad/param norm = 2.4423e-01, time/batch = 16.7228s	
9123/22300 (epoch 20.455), train_loss = 0.76676523, grad/param norm = 3.1608e-01, time/batch = 16.5337s	
9124/22300 (epoch 20.457), train_loss = 0.79339646, grad/param norm = 3.4866e-01, time/batch = 15.7855s	
9125/22300 (epoch 20.460), train_loss = 0.72264326, grad/param norm = 3.1132e-01, time/batch = 14.3137s	
9126/22300 (epoch 20.462), train_loss = 0.74301850, grad/param norm = 2.8498e-01, time/batch = 15.3015s	
9127/22300 (epoch 20.464), train_loss = 0.67131050, grad/param norm = 2.6805e-01, time/batch = 17.0430s	
9128/22300 (epoch 20.466), train_loss = 0.58066677, grad/param norm = 2.4584e-01, time/batch = 17.8791s	
9129/22300 (epoch 20.469), train_loss = 0.54846332, grad/param norm = 2.3004e-01, time/batch = 17.3072s	
9130/22300 (epoch 20.471), train_loss = 0.69038832, grad/param norm = 2.3814e-01, time/batch = 15.3068s	
9131/22300 (epoch 20.473), train_loss = 0.66563403, grad/param norm = 2.5282e-01, time/batch = 16.7090s	
9132/22300 (epoch 20.475), train_loss = 0.59189604, grad/param norm = 2.9598e-01, time/batch = 18.0413s	
9133/22300 (epoch 20.478), train_loss = 0.61113271, grad/param norm = 2.8585e-01, time/batch = 15.8598s	
9134/22300 (epoch 20.480), train_loss = 0.41737980, grad/param norm = 2.4743e-01, time/batch = 15.6892s	
9135/22300 (epoch 20.482), train_loss = 0.47208195, grad/param norm = 2.5359e-01, time/batch = 17.1110s	
9136/22300 (epoch 20.484), train_loss = 0.61005711, grad/param norm = 2.6004e-01, time/batch = 15.4392s	
9137/22300 (epoch 20.487), train_loss = 0.67507212, grad/param norm = 2.6561e-01, time/batch = 17.2132s	
9138/22300 (epoch 20.489), train_loss = 0.69118737, grad/param norm = 2.5402e-01, time/batch = 15.1225s	
9139/22300 (epoch 20.491), train_loss = 0.69967005, grad/param norm = 2.9128e-01, time/batch = 17.0449s	
9140/22300 (epoch 20.493), train_loss = 0.63335878, grad/param norm = 3.1801e-01, time/batch = 17.2190s	
9141/22300 (epoch 20.496), train_loss = 0.59897784, grad/param norm = 2.5469e-01, time/batch = 18.1332s	
9142/22300 (epoch 20.498), train_loss = 0.45599518, grad/param norm = 2.1448e-01, time/batch = 29.4785s	
9143/22300 (epoch 20.500), train_loss = 0.64832818, grad/param norm = 2.7687e-01, time/batch = 15.9886s	
9144/22300 (epoch 20.502), train_loss = 0.44188024, grad/param norm = 2.7066e-01, time/batch = 16.7823s	
9145/22300 (epoch 20.504), train_loss = 0.46399490, grad/param norm = 2.1503e-01, time/batch = 15.3799s	
9146/22300 (epoch 20.507), train_loss = 0.54090938, grad/param norm = 2.6490e-01, time/batch = 16.6865s	
9147/22300 (epoch 20.509), train_loss = 0.67656390, grad/param norm = 2.8852e-01, time/batch = 16.2304s	
9148/22300 (epoch 20.511), train_loss = 0.42250849, grad/param norm = 2.0503e-01, time/batch = 16.3713s	
9149/22300 (epoch 20.513), train_loss = 0.43863206, grad/param norm = 2.1450e-01, time/batch = 18.9574s	
9150/22300 (epoch 20.516), train_loss = 0.51762259, grad/param norm = 2.3997e-01, time/batch = 15.1388s	
9151/22300 (epoch 20.518), train_loss = 0.69737987, grad/param norm = 3.2421e-01, time/batch = 16.9563s	
9152/22300 (epoch 20.520), train_loss = 0.58118297, grad/param norm = 2.7776e-01, time/batch = 15.8130s	
9153/22300 (epoch 20.522), train_loss = 0.55499312, grad/param norm = 2.7493e-01, time/batch = 17.8923s	
9154/22300 (epoch 20.525), train_loss = 0.49597394, grad/param norm = 2.4448e-01, time/batch = 16.7247s	
9155/22300 (epoch 20.527), train_loss = 0.69609731, grad/param norm = 3.0001e-01, time/batch = 15.9375s	
9156/22300 (epoch 20.529), train_loss = 0.59142177, grad/param norm = 3.1997e-01, time/batch = 16.4657s	
9157/22300 (epoch 20.531), train_loss = 0.55988899, grad/param norm = 2.5377e-01, time/batch = 15.7286s	
9158/22300 (epoch 20.534), train_loss = 0.54100390, grad/param norm = 2.2881e-01, time/batch = 16.9757s	
9159/22300 (epoch 20.536), train_loss = 0.76865007, grad/param norm = 2.7526e-01, time/batch = 15.3894s	
9160/22300 (epoch 20.538), train_loss = 0.95617818, grad/param norm = 3.0822e-01, time/batch = 17.3579s	
9161/22300 (epoch 20.540), train_loss = 0.61997601, grad/param norm = 2.8463e-01, time/batch = 16.1556s	
9162/22300 (epoch 20.543), train_loss = 0.53832602, grad/param norm = 2.2722e-01, time/batch = 17.2127s	
9163/22300 (epoch 20.545), train_loss = 0.45812387, grad/param norm = 2.4361e-01, time/batch = 16.9620s	
9164/22300 (epoch 20.547), train_loss = 0.45333087, grad/param norm = 2.4747e-01, time/batch = 17.8932s	
9165/22300 (epoch 20.549), train_loss = 0.49901905, grad/param norm = 2.3856e-01, time/batch = 16.1387s	
9166/22300 (epoch 20.552), train_loss = 0.52818171, grad/param norm = 2.6173e-01, time/batch = 15.0671s	
9167/22300 (epoch 20.554), train_loss = 0.63161496, grad/param norm = 2.8249e-01, time/batch = 14.9712s	
9168/22300 (epoch 20.556), train_loss = 0.86843412, grad/param norm = 3.3418e-01, time/batch = 16.6389s	
9169/22300 (epoch 20.558), train_loss = 0.69829703, grad/param norm = 2.7955e-01, time/batch = 17.9583s	
9170/22300 (epoch 20.561), train_loss = 0.83717055, grad/param norm = 3.1790e-01, time/batch = 16.3762s	
9171/22300 (epoch 20.563), train_loss = 0.73979106, grad/param norm = 3.1432e-01, time/batch = 18.3077s	
9172/22300 (epoch 20.565), train_loss = 0.56809080, grad/param norm = 2.8475e-01, time/batch = 16.0091s	
9173/22300 (epoch 20.567), train_loss = 0.57571274, grad/param norm = 2.4120e-01, time/batch = 16.5549s	
9174/22300 (epoch 20.570), train_loss = 0.79631905, grad/param norm = 3.0137e-01, time/batch = 16.3172s	
9175/22300 (epoch 20.572), train_loss = 0.74114559, grad/param norm = 2.9105e-01, time/batch = 15.6566s	
9176/22300 (epoch 20.574), train_loss = 0.61049125, grad/param norm = 2.4597e-01, time/batch = 16.5292s	
9177/22300 (epoch 20.576), train_loss = 0.50043881, grad/param norm = 2.3058e-01, time/batch = 15.1067s	
9178/22300 (epoch 20.578), train_loss = 0.33543777, grad/param norm = 1.7288e-01, time/batch = 16.8230s	
9179/22300 (epoch 20.581), train_loss = 0.48899792, grad/param norm = 2.3929e-01, time/batch = 14.8157s	
9180/22300 (epoch 20.583), train_loss = 0.51412240, grad/param norm = 2.5078e-01, time/batch = 17.5545s	
9181/22300 (epoch 20.585), train_loss = 0.75134670, grad/param norm = 3.3547e-01, time/batch = 15.2679s	
9182/22300 (epoch 20.587), train_loss = 0.92291825, grad/param norm = 3.4170e-01, time/batch = 16.9811s	
9183/22300 (epoch 20.590), train_loss = 0.81819162, grad/param norm = 3.3871e-01, time/batch = 16.6508s	
9184/22300 (epoch 20.592), train_loss = 0.89205612, grad/param norm = 3.3073e-01, time/batch = 16.5556s	
9185/22300 (epoch 20.594), train_loss = 0.90067689, grad/param norm = 3.4898e-01, time/batch = 14.8889s	
9186/22300 (epoch 20.596), train_loss = 0.57439389, grad/param norm = 2.4620e-01, time/batch = 15.9654s	
9187/22300 (epoch 20.599), train_loss = 0.47226506, grad/param norm = 2.5958e-01, time/batch = 16.4581s	
9188/22300 (epoch 20.601), train_loss = 0.55006033, grad/param norm = 2.4173e-01, time/batch = 16.7108s	
9189/22300 (epoch 20.603), train_loss = 0.63561918, grad/param norm = 2.6790e-01, time/batch = 15.3168s	
9190/22300 (epoch 20.605), train_loss = 0.56747580, grad/param norm = 2.5345e-01, time/batch = 15.0466s	
9191/22300 (epoch 20.608), train_loss = 0.87903870, grad/param norm = 3.3284e-01, time/batch = 17.3783s	
9192/22300 (epoch 20.610), train_loss = 0.90371373, grad/param norm = 3.2533e-01, time/batch = 15.5370s	
9193/22300 (epoch 20.612), train_loss = 0.72944972, grad/param norm = 3.0183e-01, time/batch = 18.1371s	
9194/22300 (epoch 20.614), train_loss = 0.76984548, grad/param norm = 3.1374e-01, time/batch = 15.8757s	
9195/22300 (epoch 20.617), train_loss = 0.67790310, grad/param norm = 2.7299e-01, time/batch = 16.5446s	
9196/22300 (epoch 20.619), train_loss = 0.88842770, grad/param norm = 2.9131e-01, time/batch = 16.0205s	
9197/22300 (epoch 20.621), train_loss = 0.60103539, grad/param norm = 2.5542e-01, time/batch = 16.5710s	
9198/22300 (epoch 20.623), train_loss = 0.56739676, grad/param norm = 2.5087e-01, time/batch = 16.9839s	
9199/22300 (epoch 20.626), train_loss = 0.52901238, grad/param norm = 2.2230e-01, time/batch = 15.9801s	
9200/22300 (epoch 20.628), train_loss = 0.55079407, grad/param norm = 2.1548e-01, time/batch = 18.0506s	
9201/22300 (epoch 20.630), train_loss = 0.59945668, grad/param norm = 2.6147e-01, time/batch = 16.5413s	
9202/22300 (epoch 20.632), train_loss = 0.59400915, grad/param norm = 2.8566e-01, time/batch = 14.9275s	
9203/22300 (epoch 20.635), train_loss = 0.60455181, grad/param norm = 2.5685e-01, time/batch = 16.6326s	
9204/22300 (epoch 20.637), train_loss = 0.71189241, grad/param norm = 2.9872e-01, time/batch = 16.2201s	
9205/22300 (epoch 20.639), train_loss = 0.80703048, grad/param norm = 3.5703e-01, time/batch = 16.8776s	
9206/22300 (epoch 20.641), train_loss = 0.66949300, grad/param norm = 2.8055e-01, time/batch = 16.3708s	
9207/22300 (epoch 20.643), train_loss = 0.57688452, grad/param norm = 2.7049e-01, time/batch = 15.4363s	
9208/22300 (epoch 20.646), train_loss = 0.53964093, grad/param norm = 2.5348e-01, time/batch = 15.4859s	
9209/22300 (epoch 20.648), train_loss = 0.57285818, grad/param norm = 2.3196e-01, time/batch = 17.8920s	
9210/22300 (epoch 20.650), train_loss = 0.69362815, grad/param norm = 3.0166e-01, time/batch = 15.6313s	
9211/22300 (epoch 20.652), train_loss = 0.57494571, grad/param norm = 2.4902e-01, time/batch = 18.9508s	
9212/22300 (epoch 20.655), train_loss = 0.56634371, grad/param norm = 2.6669e-01, time/batch = 16.1926s	
9213/22300 (epoch 20.657), train_loss = 0.62655795, grad/param norm = 2.6048e-01, time/batch = 15.9739s	
9214/22300 (epoch 20.659), train_loss = 0.55322408, grad/param norm = 2.7177e-01, time/batch = 15.2317s	
9215/22300 (epoch 20.661), train_loss = 0.45607247, grad/param norm = 2.2928e-01, time/batch = 17.8870s	
9216/22300 (epoch 20.664), train_loss = 0.53063069, grad/param norm = 2.0892e-01, time/batch = 15.9773s	
9217/22300 (epoch 20.666), train_loss = 0.67620688, grad/param norm = 2.8535e-01, time/batch = 15.4657s	
9218/22300 (epoch 20.668), train_loss = 0.53810869, grad/param norm = 2.4777e-01, time/batch = 17.8842s	
9219/22300 (epoch 20.670), train_loss = 0.68259673, grad/param norm = 2.7923e-01, time/batch = 17.1298s	
9220/22300 (epoch 20.673), train_loss = 0.72761609, grad/param norm = 3.0065e-01, time/batch = 18.2883s	
9221/22300 (epoch 20.675), train_loss = 0.82302673, grad/param norm = 3.1943e-01, time/batch = 15.5598s	
9222/22300 (epoch 20.677), train_loss = 0.84525262, grad/param norm = 3.2870e-01, time/batch = 15.5340s	
9223/22300 (epoch 20.679), train_loss = 0.69114535, grad/param norm = 3.2627e-01, time/batch = 15.0443s	
9224/22300 (epoch 20.682), train_loss = 0.66342240, grad/param norm = 3.3388e-01, time/batch = 16.7960s	
9225/22300 (epoch 20.684), train_loss = 0.67377428, grad/param norm = 2.6931e-01, time/batch = 17.7110s	
9226/22300 (epoch 20.686), train_loss = 0.66541326, grad/param norm = 2.7034e-01, time/batch = 15.7366s	
9227/22300 (epoch 20.688), train_loss = 0.60103745, grad/param norm = 2.6195e-01, time/batch = 17.3914s	
9228/22300 (epoch 20.691), train_loss = 0.55735165, grad/param norm = 2.7416e-01, time/batch = 15.3700s	
9229/22300 (epoch 20.693), train_loss = 0.54138770, grad/param norm = 2.6516e-01, time/batch = 16.1450s	
9230/22300 (epoch 20.695), train_loss = 0.47997702, grad/param norm = 2.3918e-01, time/batch = 14.9704s	
9231/22300 (epoch 20.697), train_loss = 0.52061790, grad/param norm = 2.3298e-01, time/batch = 17.1176s	
9232/22300 (epoch 20.700), train_loss = 0.53518578, grad/param norm = 2.4883e-01, time/batch = 15.1903s	
9233/22300 (epoch 20.702), train_loss = 0.53095735, grad/param norm = 2.2121e-01, time/batch = 14.9944s	
9234/22300 (epoch 20.704), train_loss = 0.64472597, grad/param norm = 3.2493e-01, time/batch = 14.9036s	
9235/22300 (epoch 20.706), train_loss = 0.53163734, grad/param norm = 2.5424e-01, time/batch = 15.5574s	
9236/22300 (epoch 20.709), train_loss = 0.42911784, grad/param norm = 2.0441e-01, time/batch = 14.8002s	
9237/22300 (epoch 20.711), train_loss = 0.46893431, grad/param norm = 2.2069e-01, time/batch = 14.4237s	
9238/22300 (epoch 20.713), train_loss = 0.61970441, grad/param norm = 2.5417e-01, time/batch = 14.6514s	
9239/22300 (epoch 20.715), train_loss = 0.62886166, grad/param norm = 2.6750e-01, time/batch = 14.5649s	
9240/22300 (epoch 20.717), train_loss = 0.79003741, grad/param norm = 2.7386e-01, time/batch = 14.9724s	
9241/22300 (epoch 20.720), train_loss = 0.56507089, grad/param norm = 2.5754e-01, time/batch = 16.8108s	
9242/22300 (epoch 20.722), train_loss = 0.63628089, grad/param norm = 2.6341e-01, time/batch = 16.6296s	
9243/22300 (epoch 20.724), train_loss = 0.69414697, grad/param norm = 3.1035e-01, time/batch = 14.8001s	
9244/22300 (epoch 20.726), train_loss = 0.57408136, grad/param norm = 2.7383e-01, time/batch = 15.8801s	
9245/22300 (epoch 20.729), train_loss = 0.63059947, grad/param norm = 3.2584e-01, time/batch = 14.9463s	
9246/22300 (epoch 20.731), train_loss = 0.80089506, grad/param norm = 3.1688e-01, time/batch = 16.1512s	
9247/22300 (epoch 20.733), train_loss = 0.81785455, grad/param norm = 3.5893e-01, time/batch = 15.9699s	
9248/22300 (epoch 20.735), train_loss = 0.80660670, grad/param norm = 3.1432e-01, time/batch = 16.0600s	
9249/22300 (epoch 20.738), train_loss = 0.62545420, grad/param norm = 3.1989e-01, time/batch = 16.6428s	
9250/22300 (epoch 20.740), train_loss = 0.55930875, grad/param norm = 2.5365e-01, time/batch = 17.8045s	
9251/22300 (epoch 20.742), train_loss = 0.60596433, grad/param norm = 2.5211e-01, time/batch = 15.2072s	
9252/22300 (epoch 20.744), train_loss = 0.88643808, grad/param norm = 2.9191e-01, time/batch = 16.1290s	
9253/22300 (epoch 20.747), train_loss = 0.72333965, grad/param norm = 2.9069e-01, time/batch = 16.1388s	
9254/22300 (epoch 20.749), train_loss = 0.93545144, grad/param norm = 4.1341e-01, time/batch = 16.8751s	
9255/22300 (epoch 20.751), train_loss = 0.80570889, grad/param norm = 4.3503e-01, time/batch = 14.9810s	
9256/22300 (epoch 20.753), train_loss = 0.85295456, grad/param norm = 3.3877e-01, time/batch = 16.7738s	
9257/22300 (epoch 20.756), train_loss = 0.74750491, grad/param norm = 3.1883e-01, time/batch = 15.6406s	
9258/22300 (epoch 20.758), train_loss = 0.65935107, grad/param norm = 2.5877e-01, time/batch = 15.4436s	
9259/22300 (epoch 20.760), train_loss = 0.69799070, grad/param norm = 2.7565e-01, time/batch = 15.0446s	
9260/22300 (epoch 20.762), train_loss = 0.66444064, grad/param norm = 2.7175e-01, time/batch = 17.1460s	
9261/22300 (epoch 20.765), train_loss = 0.68160885, grad/param norm = 2.7185e-01, time/batch = 17.7982s	
9262/22300 (epoch 20.767), train_loss = 0.71681764, grad/param norm = 2.8577e-01, time/batch = 17.0416s	
9263/22300 (epoch 20.769), train_loss = 0.66412560, grad/param norm = 3.2432e-01, time/batch = 16.8644s	
9264/22300 (epoch 20.771), train_loss = 0.74937566, grad/param norm = 3.1362e-01, time/batch = 16.8077s	
9265/22300 (epoch 20.774), train_loss = 0.78836277, grad/param norm = 3.8484e-01, time/batch = 14.6601s	
9266/22300 (epoch 20.776), train_loss = 0.84775060, grad/param norm = 3.8024e-01, time/batch = 17.8853s	
9267/22300 (epoch 20.778), train_loss = 0.79679236, grad/param norm = 3.0892e-01, time/batch = 15.8081s	
9268/22300 (epoch 20.780), train_loss = 0.79929578, grad/param norm = 3.2643e-01, time/batch = 18.5464s	
9269/22300 (epoch 20.783), train_loss = 0.88596537, grad/param norm = 3.6867e-01, time/batch = 15.4543s	
9270/22300 (epoch 20.785), train_loss = 0.64267143, grad/param norm = 2.8722e-01, time/batch = 15.7133s	
9271/22300 (epoch 20.787), train_loss = 0.60000483, grad/param norm = 2.6786e-01, time/batch = 14.4807s	
9272/22300 (epoch 20.789), train_loss = 0.85700902, grad/param norm = 3.3462e-01, time/batch = 14.6123s	
9273/22300 (epoch 20.791), train_loss = 0.97788972, grad/param norm = 3.3191e-01, time/batch = 14.6437s	
9274/22300 (epoch 20.794), train_loss = 0.80455275, grad/param norm = 3.4369e-01, time/batch = 14.3202s	
9275/22300 (epoch 20.796), train_loss = 0.83889605, grad/param norm = 3.1041e-01, time/batch = 16.1419s	
9276/22300 (epoch 20.798), train_loss = 0.91748526, grad/param norm = 3.1906e-01, time/batch = 16.2345s	
9277/22300 (epoch 20.800), train_loss = 0.64094960, grad/param norm = 2.6209e-01, time/batch = 15.7759s	
9278/22300 (epoch 20.803), train_loss = 0.62318398, grad/param norm = 2.4941e-01, time/batch = 18.1190s	
9279/22300 (epoch 20.805), train_loss = 0.73071319, grad/param norm = 2.7427e-01, time/batch = 16.3716s	
9280/22300 (epoch 20.807), train_loss = 0.84496003, grad/param norm = 3.2396e-01, time/batch = 16.2776s	
9281/22300 (epoch 20.809), train_loss = 0.65469862, grad/param norm = 3.1029e-01, time/batch = 17.1098s	
9282/22300 (epoch 20.812), train_loss = 0.77428040, grad/param norm = 3.2249e-01, time/batch = 17.9692s	
9283/22300 (epoch 20.814), train_loss = 0.76314247, grad/param norm = 2.7670e-01, time/batch = 16.9867s	
9284/22300 (epoch 20.816), train_loss = 0.74091210, grad/param norm = 2.6430e-01, time/batch = 15.3832s	
9285/22300 (epoch 20.818), train_loss = 0.85089688, grad/param norm = 3.2712e-01, time/batch = 17.1865s	
9286/22300 (epoch 20.821), train_loss = 0.75194252, grad/param norm = 3.4476e-01, time/batch = 15.9874s	
9287/22300 (epoch 20.823), train_loss = 0.51753110, grad/param norm = 2.6761e-01, time/batch = 15.4407s	
9288/22300 (epoch 20.825), train_loss = 0.62404584, grad/param norm = 3.0368e-01, time/batch = 15.7820s	
9289/22300 (epoch 20.827), train_loss = 0.66676811, grad/param norm = 2.8909e-01, time/batch = 17.3939s	
9290/22300 (epoch 20.830), train_loss = 0.59696039, grad/param norm = 3.1603e-01, time/batch = 17.2098s	
9291/22300 (epoch 20.832), train_loss = 0.61140520, grad/param norm = 3.3765e-01, time/batch = 16.2337s	
9292/22300 (epoch 20.834), train_loss = 0.57057894, grad/param norm = 2.7487e-01, time/batch = 18.3781s	
9293/22300 (epoch 20.836), train_loss = 0.68102162, grad/param norm = 2.9959e-01, time/batch = 16.0852s	
9294/22300 (epoch 20.839), train_loss = 0.63155601, grad/param norm = 2.6508e-01, time/batch = 17.0629s	
9295/22300 (epoch 20.841), train_loss = 0.66852230, grad/param norm = 3.2237e-01, time/batch = 16.4647s	
9296/22300 (epoch 20.843), train_loss = 0.65420374, grad/param norm = 2.7053e-01, time/batch = 15.9652s	
9297/22300 (epoch 20.845), train_loss = 0.63406823, grad/param norm = 2.4487e-01, time/batch = 15.7969s	
9298/22300 (epoch 20.848), train_loss = 0.63918670, grad/param norm = 2.5251e-01, time/batch = 16.6301s	
9299/22300 (epoch 20.850), train_loss = 0.62572453, grad/param norm = 2.5430e-01, time/batch = 15.8091s	
9300/22300 (epoch 20.852), train_loss = 0.64012608, grad/param norm = 2.9461e-01, time/batch = 15.5655s	
9301/22300 (epoch 20.854), train_loss = 0.85005028, grad/param norm = 3.2441e-01, time/batch = 19.6211s	
9302/22300 (epoch 20.857), train_loss = 0.68829015, grad/param norm = 3.2773e-01, time/batch = 15.6283s	
9303/22300 (epoch 20.859), train_loss = 0.54970617, grad/param norm = 2.6366e-01, time/batch = 17.4873s	
9304/22300 (epoch 20.861), train_loss = 0.72442976, grad/param norm = 3.0142e-01, time/batch = 15.0709s	
9305/22300 (epoch 20.863), train_loss = 0.55495533, grad/param norm = 2.2979e-01, time/batch = 17.5432s	
9306/22300 (epoch 20.865), train_loss = 0.51650374, grad/param norm = 2.0891e-01, time/batch = 15.2256s	
9307/22300 (epoch 20.868), train_loss = 0.66232955, grad/param norm = 2.4015e-01, time/batch = 15.2424s	
9308/22300 (epoch 20.870), train_loss = 0.71785721, grad/param norm = 3.2574e-01, time/batch = 15.5713s	
9309/22300 (epoch 20.872), train_loss = 0.78973990, grad/param norm = 3.3843e-01, time/batch = 15.5072s	
9310/22300 (epoch 20.874), train_loss = 0.71053764, grad/param norm = 2.8305e-01, time/batch = 15.6699s	
9311/22300 (epoch 20.877), train_loss = 0.68166204, grad/param norm = 2.7275e-01, time/batch = 15.5812s	
9312/22300 (epoch 20.879), train_loss = 0.58971084, grad/param norm = 2.6079e-01, time/batch = 15.2055s	
9313/22300 (epoch 20.881), train_loss = 0.56546953, grad/param norm = 2.3600e-01, time/batch = 15.6153s	
9314/22300 (epoch 20.883), train_loss = 0.54726709, grad/param norm = 2.4269e-01, time/batch = 17.2208s	
9315/22300 (epoch 20.886), train_loss = 0.54443077, grad/param norm = 2.4688e-01, time/batch = 16.8022s	
9316/22300 (epoch 20.888), train_loss = 0.59309540, grad/param norm = 2.5230e-01, time/batch = 17.2172s	
9317/22300 (epoch 20.890), train_loss = 0.58050617, grad/param norm = 2.1481e-01, time/batch = 14.9562s	
9318/22300 (epoch 20.892), train_loss = 0.84586373, grad/param norm = 2.9885e-01, time/batch = 16.2096s	
9319/22300 (epoch 20.895), train_loss = 0.83612775, grad/param norm = 3.0913e-01, time/batch = 15.9035s	
9320/22300 (epoch 20.897), train_loss = 0.68779674, grad/param norm = 3.5212e-01, time/batch = 17.0373s	
9321/22300 (epoch 20.899), train_loss = 0.67175768, grad/param norm = 2.7922e-01, time/batch = 16.5352s	
9322/22300 (epoch 20.901), train_loss = 0.69048279, grad/param norm = 3.0903e-01, time/batch = 18.0445s	
9323/22300 (epoch 20.904), train_loss = 0.72430626, grad/param norm = 2.8088e-01, time/batch = 17.6381s	
9324/22300 (epoch 20.906), train_loss = 0.71600400, grad/param norm = 2.7836e-01, time/batch = 15.2679s	
9325/22300 (epoch 20.908), train_loss = 0.66572606, grad/param norm = 2.7801e-01, time/batch = 18.1492s	
9326/22300 (epoch 20.910), train_loss = 0.54594512, grad/param norm = 2.6734e-01, time/batch = 15.6530s	
9327/22300 (epoch 20.913), train_loss = 0.73896564, grad/param norm = 2.8529e-01, time/batch = 16.3761s	
9328/22300 (epoch 20.915), train_loss = 0.85382376, grad/param norm = 3.2176e-01, time/batch = 16.6291s	
9329/22300 (epoch 20.917), train_loss = 0.71213092, grad/param norm = 2.7927e-01, time/batch = 16.8005s	
9330/22300 (epoch 20.919), train_loss = 0.73387364, grad/param norm = 2.5740e-01, time/batch = 17.9642s	
9331/22300 (epoch 20.922), train_loss = 0.64751585, grad/param norm = 2.8053e-01, time/batch = 15.7337s	
9332/22300 (epoch 20.924), train_loss = 0.44944948, grad/param norm = 2.3615e-01, time/batch = 17.3895s	
9333/22300 (epoch 20.926), train_loss = 0.54102529, grad/param norm = 2.6313e-01, time/batch = 17.9471s	
9334/22300 (epoch 20.928), train_loss = 0.61970836, grad/param norm = 2.8217e-01, time/batch = 16.0347s	
9335/22300 (epoch 20.930), train_loss = 0.61496545, grad/param norm = 2.5369e-01, time/batch = 15.8757s	
9336/22300 (epoch 20.933), train_loss = 0.72518720, grad/param norm = 2.8911e-01, time/batch = 17.8580s	
9337/22300 (epoch 20.935), train_loss = 0.73596035, grad/param norm = 3.4050e-01, time/batch = 15.9074s	
9338/22300 (epoch 20.937), train_loss = 0.83542255, grad/param norm = 3.1883e-01, time/batch = 14.4878s	
9339/22300 (epoch 20.939), train_loss = 0.77484678, grad/param norm = 3.1950e-01, time/batch = 15.7977s	
9340/22300 (epoch 20.942), train_loss = 0.90572594, grad/param norm = 3.3146e-01, time/batch = 17.3783s	
9341/22300 (epoch 20.944), train_loss = 0.98523545, grad/param norm = 3.7667e-01, time/batch = 18.2006s	
9342/22300 (epoch 20.946), train_loss = 0.71030128, grad/param norm = 3.1842e-01, time/batch = 16.7825s	
9343/22300 (epoch 20.948), train_loss = 0.58173446, grad/param norm = 2.3615e-01, time/batch = 18.9644s	
9344/22300 (epoch 20.951), train_loss = 0.53297312, grad/param norm = 2.5705e-01, time/batch = 15.6435s	
9345/22300 (epoch 20.953), train_loss = 0.58758238, grad/param norm = 2.6933e-01, time/batch = 16.3794s	
9346/22300 (epoch 20.955), train_loss = 0.84928624, grad/param norm = 2.9464e-01, time/batch = 16.3930s	
9347/22300 (epoch 20.957), train_loss = 0.91850689, grad/param norm = 3.0367e-01, time/batch = 17.5519s	
9348/22300 (epoch 20.960), train_loss = 0.80732488, grad/param norm = 3.0932e-01, time/batch = 16.7191s	
9349/22300 (epoch 20.962), train_loss = 0.62940807, grad/param norm = 2.5964e-01, time/batch = 15.0558s	
9350/22300 (epoch 20.964), train_loss = 0.64032588, grad/param norm = 2.5893e-01, time/batch = 16.0540s	
9351/22300 (epoch 20.966), train_loss = 0.57582889, grad/param norm = 2.8789e-01, time/batch = 15.6028s	
9352/22300 (epoch 20.969), train_loss = 0.63734152, grad/param norm = 2.4822e-01, time/batch = 17.9451s	
9353/22300 (epoch 20.971), train_loss = 0.65387491, grad/param norm = 2.8227e-01, time/batch = 15.4671s	
9354/22300 (epoch 20.973), train_loss = 0.68556155, grad/param norm = 2.8692e-01, time/batch = 15.9009s	
9355/22300 (epoch 20.975), train_loss = 0.84572913, grad/param norm = 3.3703e-01, time/batch = 15.4850s	
9356/22300 (epoch 20.978), train_loss = 0.75454356, grad/param norm = 2.9604e-01, time/batch = 16.7155s	
9357/22300 (epoch 20.980), train_loss = 0.81616667, grad/param norm = 2.8364e-01, time/batch = 14.8797s	
9358/22300 (epoch 20.982), train_loss = 0.57503431, grad/param norm = 2.7952e-01, time/batch = 18.0361s	
9359/22300 (epoch 20.984), train_loss = 0.71151984, grad/param norm = 2.6369e-01, time/batch = 16.0704s	
9360/22300 (epoch 20.987), train_loss = 0.60096532, grad/param norm = 2.8184e-01, time/batch = 27.0949s	
9361/22300 (epoch 20.989), train_loss = 0.63133598, grad/param norm = 3.0903e-01, time/batch = 19.1154s	
9362/22300 (epoch 20.991), train_loss = 0.92586543, grad/param norm = 4.1085e-01, time/batch = 16.6439s	
9363/22300 (epoch 20.993), train_loss = 1.13866774, grad/param norm = 4.0346e-01, time/batch = 16.0390s	
9364/22300 (epoch 20.996), train_loss = 1.00903099, grad/param norm = 3.7492e-01, time/batch = 16.6480s	
9365/22300 (epoch 20.998), train_loss = 0.72399279, grad/param norm = 3.2501e-01, time/batch = 17.3027s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
9366/22300 (epoch 21.000), train_loss = 0.57291529, grad/param norm = 2.7106e-01, time/batch = 15.8942s	
9367/22300 (epoch 21.002), train_loss = 0.96618072, grad/param norm = 3.3786e-01, time/batch = 14.6150s	
9368/22300 (epoch 21.004), train_loss = 0.70298364, grad/param norm = 2.8396e-01, time/batch = 16.4813s	
9369/22300 (epoch 21.007), train_loss = 0.70777436, grad/param norm = 2.8585e-01, time/batch = 15.3447s	
9370/22300 (epoch 21.009), train_loss = 0.70916336, grad/param norm = 2.5752e-01, time/batch = 15.7281s	
9371/22300 (epoch 21.011), train_loss = 0.87314624, grad/param norm = 3.0512e-01, time/batch = 18.6254s	
9372/22300 (epoch 21.013), train_loss = 0.69898551, grad/param norm = 2.4980e-01, time/batch = 16.0523s	
9373/22300 (epoch 21.016), train_loss = 0.62221507, grad/param norm = 2.8466e-01, time/batch = 16.7976s	
9374/22300 (epoch 21.018), train_loss = 0.75790292, grad/param norm = 3.0901e-01, time/batch = 15.6350s	
9375/22300 (epoch 21.020), train_loss = 0.63081206, grad/param norm = 2.8378e-01, time/batch = 16.3923s	
9376/22300 (epoch 21.022), train_loss = 0.56796098, grad/param norm = 2.8359e-01, time/batch = 16.9729s	
9377/22300 (epoch 21.025), train_loss = 0.57367072, grad/param norm = 2.5978e-01, time/batch = 14.4111s	
9378/22300 (epoch 21.027), train_loss = 0.59288498, grad/param norm = 2.4125e-01, time/batch = 15.5940s	
9379/22300 (epoch 21.029), train_loss = 0.59426072, grad/param norm = 2.5604e-01, time/batch = 16.6321s	
9380/22300 (epoch 21.031), train_loss = 0.58799048, grad/param norm = 2.0915e-01, time/batch = 15.5678s	
9381/22300 (epoch 21.034), train_loss = 0.60327290, grad/param norm = 2.6858e-01, time/batch = 15.8069s	
9382/22300 (epoch 21.036), train_loss = 0.48596195, grad/param norm = 2.1997e-01, time/batch = 17.0431s	
9383/22300 (epoch 21.038), train_loss = 0.59307622, grad/param norm = 2.5659e-01, time/batch = 15.6105s	
9384/22300 (epoch 21.040), train_loss = 0.63634781, grad/param norm = 2.8777e-01, time/batch = 17.6411s	
9385/22300 (epoch 21.043), train_loss = 0.92005448, grad/param norm = 3.1020e-01, time/batch = 16.1243s	
9386/22300 (epoch 21.045), train_loss = 0.72846056, grad/param norm = 2.6149e-01, time/batch = 17.7052s	
9387/22300 (epoch 21.047), train_loss = 0.77922074, grad/param norm = 3.1802e-01, time/batch = 15.4549s	
9388/22300 (epoch 21.049), train_loss = 0.63541664, grad/param norm = 2.5375e-01, time/batch = 17.5472s	
9389/22300 (epoch 21.052), train_loss = 0.76261114, grad/param norm = 3.2137e-01, time/batch = 17.7098s	
9390/22300 (epoch 21.054), train_loss = 0.70794644, grad/param norm = 2.9375e-01, time/batch = 15.4918s	
9391/22300 (epoch 21.056), train_loss = 0.43054210, grad/param norm = 2.0556e-01, time/batch = 19.2940s	
9392/22300 (epoch 21.058), train_loss = 0.58923756, grad/param norm = 2.6819e-01, time/batch = 16.4442s	
9393/22300 (epoch 21.061), train_loss = 0.57870458, grad/param norm = 2.7986e-01, time/batch = 18.7958s	
9394/22300 (epoch 21.063), train_loss = 0.82597468, grad/param norm = 4.2183e-01, time/batch = 16.6411s	
9395/22300 (epoch 21.065), train_loss = 0.84587492, grad/param norm = 3.6070e-01, time/batch = 14.9919s	
9396/22300 (epoch 21.067), train_loss = 0.60193966, grad/param norm = 2.6284e-01, time/batch = 17.7938s	
9397/22300 (epoch 21.070), train_loss = 0.64372997, grad/param norm = 2.8019e-01, time/batch = 15.7309s	
9398/22300 (epoch 21.072), train_loss = 0.75084848, grad/param norm = 3.1692e-01, time/batch = 18.4567s	
9399/22300 (epoch 21.074), train_loss = 0.72199470, grad/param norm = 3.2554e-01, time/batch = 15.4623s	
9400/22300 (epoch 21.076), train_loss = 0.70092281, grad/param norm = 3.7168e-01, time/batch = 18.3674s	
9401/22300 (epoch 21.078), train_loss = 0.79047193, grad/param norm = 3.0478e-01, time/batch = 15.1341s	
9402/22300 (epoch 21.081), train_loss = 0.78504568, grad/param norm = 3.0476e-01, time/batch = 15.4395s	
9403/22300 (epoch 21.083), train_loss = 0.89288779, grad/param norm = 3.1813e-01, time/batch = 15.6326s	
9404/22300 (epoch 21.085), train_loss = 0.88109182, grad/param norm = 3.1211e-01, time/batch = 19.0535s	
9405/22300 (epoch 21.087), train_loss = 0.73737922, grad/param norm = 2.7923e-01, time/batch = 16.6397s	
9406/22300 (epoch 21.090), train_loss = 0.63083302, grad/param norm = 2.6489e-01, time/batch = 15.7250s	
9407/22300 (epoch 21.092), train_loss = 0.56114290, grad/param norm = 2.4862e-01, time/batch = 14.5533s	
9408/22300 (epoch 21.094), train_loss = 0.55535961, grad/param norm = 2.8236e-01, time/batch = 16.2027s	
9409/22300 (epoch 21.096), train_loss = 0.86106937, grad/param norm = 3.3400e-01, time/batch = 17.0456s	
9410/22300 (epoch 21.099), train_loss = 0.62394899, grad/param norm = 2.6892e-01, time/batch = 15.4822s	
9411/22300 (epoch 21.101), train_loss = 0.77078439, grad/param norm = 2.9511e-01, time/batch = 17.5577s	
9412/22300 (epoch 21.103), train_loss = 0.67986611, grad/param norm = 2.6546e-01, time/batch = 16.7253s	
9413/22300 (epoch 21.105), train_loss = 0.59610131, grad/param norm = 2.7273e-01, time/batch = 15.7788s	
9414/22300 (epoch 21.108), train_loss = 0.70808021, grad/param norm = 2.7218e-01, time/batch = 16.2877s	
9415/22300 (epoch 21.110), train_loss = 0.72927227, grad/param norm = 2.6657e-01, time/batch = 16.4751s	
9416/22300 (epoch 21.112), train_loss = 0.69629915, grad/param norm = 2.6578e-01, time/batch = 16.9681s	
9417/22300 (epoch 21.114), train_loss = 0.77505164, grad/param norm = 2.9841e-01, time/batch = 16.1070s	
9418/22300 (epoch 21.117), train_loss = 0.87772014, grad/param norm = 2.9503e-01, time/batch = 16.9647s	
9419/22300 (epoch 21.119), train_loss = 0.79355018, grad/param norm = 3.0705e-01, time/batch = 16.4728s	
9420/22300 (epoch 21.121), train_loss = 0.86876494, grad/param norm = 3.2712e-01, time/batch = 17.4764s	
9421/22300 (epoch 21.123), train_loss = 0.87251156, grad/param norm = 3.1398e-01, time/batch = 15.3812s	
9422/22300 (epoch 21.126), train_loss = 0.73545384, grad/param norm = 2.8833e-01, time/batch = 19.2110s	
9423/22300 (epoch 21.128), train_loss = 0.79246730, grad/param norm = 2.9206e-01, time/batch = 15.2911s	
9424/22300 (epoch 21.130), train_loss = 0.60085592, grad/param norm = 2.3523e-01, time/batch = 16.8809s	
9425/22300 (epoch 21.132), train_loss = 0.50791230, grad/param norm = 2.2527e-01, time/batch = 16.8897s	
9426/22300 (epoch 21.135), train_loss = 0.56660308, grad/param norm = 3.0789e-01, time/batch = 16.3099s	
9427/22300 (epoch 21.137), train_loss = 0.43157066, grad/param norm = 2.2217e-01, time/batch = 17.9723s	
9428/22300 (epoch 21.139), train_loss = 0.69178980, grad/param norm = 3.0752e-01, time/batch = 15.8544s	
9429/22300 (epoch 21.141), train_loss = 0.78824805, grad/param norm = 2.7883e-01, time/batch = 18.4702s	
9430/22300 (epoch 21.143), train_loss = 0.71677575, grad/param norm = 3.1965e-01, time/batch = 15.6452s	
9431/22300 (epoch 21.146), train_loss = 0.80264606, grad/param norm = 3.0534e-01, time/batch = 16.4543s	
9432/22300 (epoch 21.148), train_loss = 0.57655191, grad/param norm = 2.4832e-01, time/batch = 16.6382s	
9433/22300 (epoch 21.150), train_loss = 0.65840242, grad/param norm = 2.8461e-01, time/batch = 16.6205s	
9434/22300 (epoch 21.152), train_loss = 0.55089398, grad/param norm = 2.8229e-01, time/batch = 17.2970s	
9435/22300 (epoch 21.155), train_loss = 0.54181254, grad/param norm = 2.3849e-01, time/batch = 16.3848s	
9436/22300 (epoch 21.157), train_loss = 0.72777989, grad/param norm = 3.0218e-01, time/batch = 16.0641s	
9437/22300 (epoch 21.159), train_loss = 0.77317660, grad/param norm = 3.4458e-01, time/batch = 16.0576s	
9438/22300 (epoch 21.161), train_loss = 0.76135983, grad/param norm = 2.9836e-01, time/batch = 16.3605s	
9439/22300 (epoch 21.164), train_loss = 0.56759586, grad/param norm = 2.3163e-01, time/batch = 16.6394s	
9440/22300 (epoch 21.166), train_loss = 0.52856033, grad/param norm = 2.3342e-01, time/batch = 15.1307s	
9441/22300 (epoch 21.168), train_loss = 0.54627080, grad/param norm = 2.4359e-01, time/batch = 16.2052s	
9442/22300 (epoch 21.170), train_loss = 0.69333628, grad/param norm = 2.8286e-01, time/batch = 16.6405s	
9443/22300 (epoch 21.173), train_loss = 0.82230204, grad/param norm = 2.9852e-01, time/batch = 16.9626s	
9444/22300 (epoch 21.175), train_loss = 0.66562778, grad/param norm = 2.7227e-01, time/batch = 17.5508s	
9445/22300 (epoch 21.177), train_loss = 0.46800137, grad/param norm = 2.1027e-01, time/batch = 16.1833s	
9446/22300 (epoch 21.179), train_loss = 0.63505103, grad/param norm = 2.3708e-01, time/batch = 15.6450s	
9447/22300 (epoch 21.182), train_loss = 0.85964797, grad/param norm = 2.8880e-01, time/batch = 16.4018s	
9448/22300 (epoch 21.184), train_loss = 0.93354435, grad/param norm = 2.9847e-01, time/batch = 16.5598s	
9449/22300 (epoch 21.186), train_loss = 0.71829963, grad/param norm = 2.8969e-01, time/batch = 17.1198s	
9450/22300 (epoch 21.188), train_loss = 0.93222230, grad/param norm = 3.2222e-01, time/batch = 15.8780s	
9451/22300 (epoch 21.191), train_loss = 0.86335504, grad/param norm = 3.7267e-01, time/batch = 16.3932s	
9452/22300 (epoch 21.193), train_loss = 0.71295644, grad/param norm = 3.2343e-01, time/batch = 16.4701s	
9453/22300 (epoch 21.195), train_loss = 0.64752274, grad/param norm = 2.7986e-01, time/batch = 15.3095s	
9454/22300 (epoch 21.197), train_loss = 0.62828699, grad/param norm = 3.0099e-01, time/batch = 17.4579s	
9455/22300 (epoch 21.200), train_loss = 0.55680936, grad/param norm = 2.6607e-01, time/batch = 16.5622s	
9456/22300 (epoch 21.202), train_loss = 0.62287072, grad/param norm = 2.6786e-01, time/batch = 15.3698s	
9457/22300 (epoch 21.204), train_loss = 0.65988235, grad/param norm = 2.7422e-01, time/batch = 15.3910s	
9458/22300 (epoch 21.206), train_loss = 0.57036224, grad/param norm = 2.3154e-01, time/batch = 15.5553s	
9459/22300 (epoch 21.209), train_loss = 0.66393277, grad/param norm = 2.8359e-01, time/batch = 15.0591s	
9460/22300 (epoch 21.211), train_loss = 0.52881872, grad/param norm = 2.7367e-01, time/batch = 16.7974s	
9461/22300 (epoch 21.213), train_loss = 0.64516307, grad/param norm = 2.6807e-01, time/batch = 17.0469s	
9462/22300 (epoch 21.215), train_loss = 0.83096066, grad/param norm = 3.2097e-01, time/batch = 15.2062s	
9463/22300 (epoch 21.217), train_loss = 0.82434295, grad/param norm = 3.0450e-01, time/batch = 18.5461s	
9464/22300 (epoch 21.220), train_loss = 0.64329152, grad/param norm = 2.5064e-01, time/batch = 16.6323s	
9465/22300 (epoch 21.222), train_loss = 0.57717119, grad/param norm = 2.5137e-01, time/batch = 17.7931s	
9466/22300 (epoch 21.224), train_loss = 0.60300159, grad/param norm = 2.4428e-01, time/batch = 17.3975s	
9467/22300 (epoch 21.226), train_loss = 0.64569783, grad/param norm = 2.5007e-01, time/batch = 18.5314s	
9468/22300 (epoch 21.229), train_loss = 0.59623261, grad/param norm = 3.0447e-01, time/batch = 15.7159s	
9469/22300 (epoch 21.231), train_loss = 0.77038283, grad/param norm = 3.5820e-01, time/batch = 17.3929s	
9470/22300 (epoch 21.233), train_loss = 0.70042099, grad/param norm = 2.9738e-01, time/batch = 16.4688s	
9471/22300 (epoch 21.235), train_loss = 0.52841552, grad/param norm = 2.7570e-01, time/batch = 15.8935s	
9472/22300 (epoch 21.238), train_loss = 0.54180882, grad/param norm = 2.3782e-01, time/batch = 17.4629s	
9473/22300 (epoch 21.240), train_loss = 0.53918531, grad/param norm = 2.1292e-01, time/batch = 16.3877s	
9474/22300 (epoch 21.242), train_loss = 0.57626938, grad/param norm = 2.8809e-01, time/batch = 17.2001s	
9475/22300 (epoch 21.244), train_loss = 0.39147522, grad/param norm = 2.0947e-01, time/batch = 15.5950s	
9476/22300 (epoch 21.247), train_loss = 0.54798911, grad/param norm = 2.4517e-01, time/batch = 15.8535s	
9477/22300 (epoch 21.249), train_loss = 0.40649025, grad/param norm = 2.2211e-01, time/batch = 15.0832s	
9478/22300 (epoch 21.251), train_loss = 0.54666668, grad/param norm = 2.3826e-01, time/batch = 14.4772s	
9479/22300 (epoch 21.253), train_loss = 0.41342928, grad/param norm = 2.2911e-01, time/batch = 14.8863s	
9480/22300 (epoch 21.256), train_loss = 0.49368078, grad/param norm = 2.3845e-01, time/batch = 14.8852s	
9481/22300 (epoch 21.258), train_loss = 0.75164568, grad/param norm = 2.8800e-01, time/batch = 15.6355s	
9482/22300 (epoch 21.260), train_loss = 0.62697160, grad/param norm = 2.5401e-01, time/batch = 16.8475s	
9483/22300 (epoch 21.262), train_loss = 0.52727014, grad/param norm = 2.3452e-01, time/batch = 17.3771s	
9484/22300 (epoch 21.265), train_loss = 0.50663414, grad/param norm = 2.4986e-01, time/batch = 17.6963s	
9485/22300 (epoch 21.267), train_loss = 0.57998334, grad/param norm = 2.6903e-01, time/batch = 17.5431s	
9486/22300 (epoch 21.269), train_loss = 0.66624554, grad/param norm = 2.7954e-01, time/batch = 15.3559s	
9487/22300 (epoch 21.271), train_loss = 0.65309618, grad/param norm = 2.3630e-01, time/batch = 18.7089s	
9488/22300 (epoch 21.274), train_loss = 0.49442344, grad/param norm = 2.3771e-01, time/batch = 15.5760s	
9489/22300 (epoch 21.276), train_loss = 0.45272127, grad/param norm = 2.3506e-01, time/batch = 17.7208s	
9490/22300 (epoch 21.278), train_loss = 0.41903283, grad/param norm = 1.8016e-01, time/batch = 17.7952s	
9491/22300 (epoch 21.280), train_loss = 0.54989171, grad/param norm = 2.9761e-01, time/batch = 16.7996s	
9492/22300 (epoch 21.283), train_loss = 0.40352093, grad/param norm = 2.0628e-01, time/batch = 16.8955s	
9493/22300 (epoch 21.285), train_loss = 0.53218579, grad/param norm = 2.7970e-01, time/batch = 15.1889s	
9494/22300 (epoch 21.287), train_loss = 0.64757727, grad/param norm = 2.6410e-01, time/batch = 14.8770s	
9495/22300 (epoch 21.289), train_loss = 0.57600820, grad/param norm = 2.7567e-01, time/batch = 16.7060s	
9496/22300 (epoch 21.291), train_loss = 0.58544556, grad/param norm = 2.4482e-01, time/batch = 17.2195s	
9497/22300 (epoch 21.294), train_loss = 0.49582827, grad/param norm = 2.2209e-01, time/batch = 16.2857s	
9498/22300 (epoch 21.296), train_loss = 0.62031674, grad/param norm = 2.7476e-01, time/batch = 14.9775s	
9499/22300 (epoch 21.298), train_loss = 0.73048667, grad/param norm = 2.8602e-01, time/batch = 15.2861s	
9500/22300 (epoch 21.300), train_loss = 0.78717221, grad/param norm = 2.7717e-01, time/batch = 16.8665s	
9501/22300 (epoch 21.303), train_loss = 0.61705650, grad/param norm = 3.2123e-01, time/batch = 15.6455s	
9502/22300 (epoch 21.305), train_loss = 0.63311231, grad/param norm = 3.3368e-01, time/batch = 17.2317s	
9503/22300 (epoch 21.307), train_loss = 0.55465143, grad/param norm = 2.6416e-01, time/batch = 16.8866s	
9504/22300 (epoch 21.309), train_loss = 0.54510091, grad/param norm = 2.7366e-01, time/batch = 15.7785s	
9505/22300 (epoch 21.312), train_loss = 0.46839499, grad/param norm = 2.1779e-01, time/batch = 17.5514s	
9506/22300 (epoch 21.314), train_loss = 0.52956533, grad/param norm = 2.6443e-01, time/batch = 16.0717s	
9507/22300 (epoch 21.316), train_loss = 0.56030821, grad/param norm = 2.5130e-01, time/batch = 16.4635s	
9508/22300 (epoch 21.318), train_loss = 0.60716700, grad/param norm = 2.5130e-01, time/batch = 15.5682s	
9509/22300 (epoch 21.321), train_loss = 0.71895424, grad/param norm = 2.7806e-01, time/batch = 16.5555s	
9510/22300 (epoch 21.323), train_loss = 0.52948037, grad/param norm = 2.3515e-01, time/batch = 16.3882s	
9511/22300 (epoch 21.325), train_loss = 0.47403751, grad/param norm = 2.1871e-01, time/batch = 15.6480s	
9512/22300 (epoch 21.327), train_loss = 0.49753428, grad/param norm = 2.4228e-01, time/batch = 15.3270s	
9513/22300 (epoch 21.330), train_loss = 0.52828997, grad/param norm = 2.7251e-01, time/batch = 15.7373s	
9514/22300 (epoch 21.332), train_loss = 0.49688473, grad/param norm = 2.5265e-01, time/batch = 15.3568s	
9515/22300 (epoch 21.334), train_loss = 0.54751289, grad/param norm = 2.7580e-01, time/batch = 16.2017s	
9516/22300 (epoch 21.336), train_loss = 0.55164341, grad/param norm = 2.5998e-01, time/batch = 16.2351s	
9517/22300 (epoch 21.339), train_loss = 0.63458943, grad/param norm = 2.8085e-01, time/batch = 16.3663s	
9518/22300 (epoch 21.341), train_loss = 0.65654223, grad/param norm = 2.8334e-01, time/batch = 16.2246s	
9519/22300 (epoch 21.343), train_loss = 0.74730504, grad/param norm = 2.9547e-01, time/batch = 15.7958s	
9520/22300 (epoch 21.345), train_loss = 0.57466628, grad/param norm = 2.5169e-01, time/batch = 16.0608s	
9521/22300 (epoch 21.348), train_loss = 0.56958818, grad/param norm = 2.3768e-01, time/batch = 17.4666s	
9522/22300 (epoch 21.350), train_loss = 0.49694883, grad/param norm = 2.4994e-01, time/batch = 17.1967s	
9523/22300 (epoch 21.352), train_loss = 0.63241821, grad/param norm = 2.3708e-01, time/batch = 16.2086s	
9524/22300 (epoch 21.354), train_loss = 0.86048510, grad/param norm = 3.4829e-01, time/batch = 16.1374s	
9525/22300 (epoch 21.357), train_loss = 0.71141330, grad/param norm = 2.5113e-01, time/batch = 16.6546s	
9526/22300 (epoch 21.359), train_loss = 0.52588629, grad/param norm = 2.5099e-01, time/batch = 15.4653s	
9527/22300 (epoch 21.361), train_loss = 0.53919652, grad/param norm = 3.0900e-01, time/batch = 16.7973s	
9528/22300 (epoch 21.363), train_loss = 0.73481195, grad/param norm = 3.1391e-01, time/batch = 16.6987s	
9529/22300 (epoch 21.365), train_loss = 0.60108539, grad/param norm = 2.7206e-01, time/batch = 15.9847s	
9530/22300 (epoch 21.368), train_loss = 0.61746033, grad/param norm = 3.0366e-01, time/batch = 15.6325s	
9531/22300 (epoch 21.370), train_loss = 0.59816356, grad/param norm = 2.5269e-01, time/batch = 17.7937s	
9532/22300 (epoch 21.372), train_loss = 0.49298312, grad/param norm = 2.4534e-01, time/batch = 16.9747s	
9533/22300 (epoch 21.374), train_loss = 0.45606073, grad/param norm = 2.4473e-01, time/batch = 15.5609s	
9534/22300 (epoch 21.377), train_loss = 0.56389643, grad/param norm = 2.9201e-01, time/batch = 16.2281s	
9535/22300 (epoch 21.379), train_loss = 0.57096417, grad/param norm = 3.0793e-01, time/batch = 16.7265s	
9536/22300 (epoch 21.381), train_loss = 0.74794847, grad/param norm = 3.4057e-01, time/batch = 16.6223s	
9537/22300 (epoch 21.383), train_loss = 0.59818139, grad/param norm = 3.3022e-01, time/batch = 15.7219s	
9538/22300 (epoch 21.386), train_loss = 0.60977821, grad/param norm = 3.1379e-01, time/batch = 17.1533s	
9539/22300 (epoch 21.388), train_loss = 0.53131188, grad/param norm = 2.5944e-01, time/batch = 16.3894s	
9540/22300 (epoch 21.390), train_loss = 0.62513458, grad/param norm = 3.0134e-01, time/batch = 17.0570s	
9541/22300 (epoch 21.392), train_loss = 0.57322069, grad/param norm = 2.5687e-01, time/batch = 15.2314s	
9542/22300 (epoch 21.395), train_loss = 0.49548195, grad/param norm = 2.5603e-01, time/batch = 17.1353s	
9543/22300 (epoch 21.397), train_loss = 0.33374780, grad/param norm = 1.8789e-01, time/batch = 15.4041s	
9544/22300 (epoch 21.399), train_loss = 0.47962181, grad/param norm = 2.6216e-01, time/batch = 16.3768s	
9545/22300 (epoch 21.401), train_loss = 0.55171586, grad/param norm = 2.5099e-01, time/batch = 15.6407s	
9546/22300 (epoch 21.404), train_loss = 0.54961986, grad/param norm = 2.4233e-01, time/batch = 17.0560s	
9547/22300 (epoch 21.406), train_loss = 0.83246271, grad/param norm = 3.2891e-01, time/batch = 17.0568s	
9548/22300 (epoch 21.408), train_loss = 0.68497762, grad/param norm = 2.9189e-01, time/batch = 15.0446s	
9549/22300 (epoch 21.410), train_loss = 0.74783423, grad/param norm = 4.3012e-01, time/batch = 15.5381s	
9550/22300 (epoch 21.413), train_loss = 0.55329210, grad/param norm = 2.4328e-01, time/batch = 15.7288s	
9551/22300 (epoch 21.415), train_loss = 0.45547208, grad/param norm = 2.6347e-01, time/batch = 19.1099s	
9552/22300 (epoch 21.417), train_loss = 0.63899685, grad/param norm = 2.9225e-01, time/batch = 15.9604s	
9553/22300 (epoch 21.419), train_loss = 0.53737176, grad/param norm = 2.2468e-01, time/batch = 16.2187s	
9554/22300 (epoch 21.422), train_loss = 0.54011900, grad/param norm = 2.5860e-01, time/batch = 16.8890s	
9555/22300 (epoch 21.424), train_loss = 0.60438604, grad/param norm = 3.0211e-01, time/batch = 16.4630s	
9556/22300 (epoch 21.426), train_loss = 0.46409617, grad/param norm = 2.7570e-01, time/batch = 16.5649s	
9557/22300 (epoch 21.428), train_loss = 0.51038538, grad/param norm = 2.7409e-01, time/batch = 16.4815s	
9558/22300 (epoch 21.430), train_loss = 0.61425389, grad/param norm = 3.1540e-01, time/batch = 16.1470s	
9559/22300 (epoch 21.433), train_loss = 0.55066709, grad/param norm = 2.0100e-01, time/batch = 16.3318s	
9560/22300 (epoch 21.435), train_loss = 0.58773898, grad/param norm = 3.0094e-01, time/batch = 17.5448s	
9561/22300 (epoch 21.437), train_loss = 0.60628179, grad/param norm = 2.7762e-01, time/batch = 15.6346s	
9562/22300 (epoch 21.439), train_loss = 0.65848187, grad/param norm = 2.7080e-01, time/batch = 17.1942s	
9563/22300 (epoch 21.442), train_loss = 0.61534744, grad/param norm = 2.8336e-01, time/batch = 17.3636s	
9564/22300 (epoch 21.444), train_loss = 0.53877158, grad/param norm = 2.3683e-01, time/batch = 16.1590s	
9565/22300 (epoch 21.446), train_loss = 0.50381913, grad/param norm = 2.8498e-01, time/batch = 15.2914s	
9566/22300 (epoch 21.448), train_loss = 0.36363706, grad/param norm = 1.7524e-01, time/batch = 15.4688s	
9567/22300 (epoch 21.451), train_loss = 0.65310737, grad/param norm = 2.9447e-01, time/batch = 18.1216s	
9568/22300 (epoch 21.453), train_loss = 0.53602381, grad/param norm = 2.5941e-01, time/batch = 15.7188s	
9569/22300 (epoch 21.455), train_loss = 0.72995889, grad/param norm = 3.0755e-01, time/batch = 18.6984s	
9570/22300 (epoch 21.457), train_loss = 0.74465830, grad/param norm = 3.1181e-01, time/batch = 16.6466s	
9571/22300 (epoch 21.460), train_loss = 0.68479135, grad/param norm = 2.8455e-01, time/batch = 16.0579s	
9572/22300 (epoch 21.462), train_loss = 0.72494122, grad/param norm = 2.8875e-01, time/batch = 16.6554s	
9573/22300 (epoch 21.464), train_loss = 0.65229543, grad/param norm = 3.3896e-01, time/batch = 15.4514s	
9574/22300 (epoch 21.466), train_loss = 0.56828281, grad/param norm = 2.9646e-01, time/batch = 16.5419s	
9575/22300 (epoch 21.469), train_loss = 0.53646784, grad/param norm = 2.4114e-01, time/batch = 17.2393s	
9576/22300 (epoch 21.471), train_loss = 0.68154514, grad/param norm = 2.7048e-01, time/batch = 18.4690s	
9577/22300 (epoch 21.473), train_loss = 0.63263929, grad/param norm = 2.4062e-01, time/batch = 29.8583s	
9578/22300 (epoch 21.475), train_loss = 0.55722859, grad/param norm = 3.0638e-01, time/batch = 14.9468s	
9579/22300 (epoch 21.478), train_loss = 0.59410356, grad/param norm = 3.2187e-01, time/batch = 16.5466s	
9580/22300 (epoch 21.480), train_loss = 0.39484910, grad/param norm = 2.3051e-01, time/batch = 16.1575s	
9581/22300 (epoch 21.482), train_loss = 0.44395906, grad/param norm = 2.1268e-01, time/batch = 17.4734s	
9582/22300 (epoch 21.484), train_loss = 0.58621972, grad/param norm = 2.7690e-01, time/batch = 18.4592s	
9583/22300 (epoch 21.487), train_loss = 0.64952815, grad/param norm = 2.4727e-01, time/batch = 16.2249s	
9584/22300 (epoch 21.489), train_loss = 0.64013882, grad/param norm = 2.5700e-01, time/batch = 16.8860s	
9585/22300 (epoch 21.491), train_loss = 0.66985679, grad/param norm = 2.7973e-01, time/batch = 16.4448s	
9586/22300 (epoch 21.493), train_loss = 0.62435135, grad/param norm = 3.2424e-01, time/batch = 15.2755s	
9587/22300 (epoch 21.496), train_loss = 0.57049728, grad/param norm = 2.2787e-01, time/batch = 16.0392s	
9588/22300 (epoch 21.498), train_loss = 0.43211055, grad/param norm = 2.0239e-01, time/batch = 19.4581s	
9589/22300 (epoch 21.500), train_loss = 0.63072068, grad/param norm = 3.0131e-01, time/batch = 15.9809s	
9590/22300 (epoch 21.502), train_loss = 0.42093225, grad/param norm = 2.7599e-01, time/batch = 16.0376s	
9591/22300 (epoch 21.504), train_loss = 0.44010675, grad/param norm = 2.2067e-01, time/batch = 15.7106s	
9592/22300 (epoch 21.507), train_loss = 0.50044234, grad/param norm = 2.6108e-01, time/batch = 17.6463s	
9593/22300 (epoch 21.509), train_loss = 0.64377415, grad/param norm = 2.7075e-01, time/batch = 18.0519s	
9594/22300 (epoch 21.511), train_loss = 0.40593238, grad/param norm = 2.0806e-01, time/batch = 16.7947s	
9595/22300 (epoch 21.513), train_loss = 0.44042005, grad/param norm = 2.2945e-01, time/batch = 19.6182s	
9596/22300 (epoch 21.516), train_loss = 0.51223752, grad/param norm = 2.8989e-01, time/batch = 16.3908s	
9597/22300 (epoch 21.518), train_loss = 0.68673982, grad/param norm = 3.9355e-01, time/batch = 15.9671s	
9598/22300 (epoch 21.520), train_loss = 0.55934482, grad/param norm = 2.6452e-01, time/batch = 16.0691s	
9599/22300 (epoch 21.522), train_loss = 0.55444750, grad/param norm = 2.5715e-01, time/batch = 17.4705s	
9600/22300 (epoch 21.525), train_loss = 0.48463749, grad/param norm = 2.3816e-01, time/batch = 16.7137s	
9601/22300 (epoch 21.527), train_loss = 0.68792359, grad/param norm = 3.6817e-01, time/batch = 16.3647s	
9602/22300 (epoch 21.529), train_loss = 0.59819422, grad/param norm = 3.0812e-01, time/batch = 15.9587s	
9603/22300 (epoch 21.531), train_loss = 0.54088989, grad/param norm = 2.2119e-01, time/batch = 15.2202s	
9604/22300 (epoch 21.534), train_loss = 0.51108630, grad/param norm = 2.4049e-01, time/batch = 16.2254s	
9605/22300 (epoch 21.536), train_loss = 0.75986099, grad/param norm = 2.7625e-01, time/batch = 16.3608s	
9606/22300 (epoch 21.538), train_loss = 0.93824315, grad/param norm = 3.0730e-01, time/batch = 16.3582s	
9607/22300 (epoch 21.540), train_loss = 0.60307709, grad/param norm = 2.8100e-01, time/batch = 16.5468s	
9608/22300 (epoch 21.543), train_loss = 0.51134650, grad/param norm = 2.2354e-01, time/batch = 16.4669s	
9609/22300 (epoch 21.545), train_loss = 0.43850050, grad/param norm = 2.2880e-01, time/batch = 16.0612s	
9610/22300 (epoch 21.547), train_loss = 0.44393167, grad/param norm = 2.6280e-01, time/batch = 16.3007s	
9611/22300 (epoch 21.549), train_loss = 0.48525970, grad/param norm = 2.5447e-01, time/batch = 15.5300s	
9612/22300 (epoch 21.552), train_loss = 0.50019227, grad/param norm = 2.5648e-01, time/batch = 16.3489s	
9613/22300 (epoch 21.554), train_loss = 0.60538651, grad/param norm = 2.9335e-01, time/batch = 14.4060s	
9614/22300 (epoch 21.556), train_loss = 0.83664217, grad/param norm = 3.4083e-01, time/batch = 15.8080s	
9615/22300 (epoch 21.558), train_loss = 0.66375899, grad/param norm = 3.0240e-01, time/batch = 17.6271s	
9616/22300 (epoch 21.561), train_loss = 0.82224547, grad/param norm = 3.7292e-01, time/batch = 14.9092s	
9617/22300 (epoch 21.563), train_loss = 0.75242572, grad/param norm = 3.7282e-01, time/batch = 17.8871s	
9618/22300 (epoch 21.565), train_loss = 0.57265110, grad/param norm = 3.2817e-01, time/batch = 16.6233s	
9619/22300 (epoch 21.567), train_loss = 0.55588413, grad/param norm = 2.4338e-01, time/batch = 16.8994s	
9620/22300 (epoch 21.570), train_loss = 0.78200861, grad/param norm = 3.3016e-01, time/batch = 16.8891s	
9621/22300 (epoch 21.572), train_loss = 0.73285046, grad/param norm = 2.9482e-01, time/batch = 16.1376s	
9622/22300 (epoch 21.574), train_loss = 0.57095801, grad/param norm = 2.2821e-01, time/batch = 17.2053s	
9623/22300 (epoch 21.576), train_loss = 0.48650926, grad/param norm = 2.0434e-01, time/batch = 17.3704s	
9624/22300 (epoch 21.578), train_loss = 0.33552429, grad/param norm = 2.3122e-01, time/batch = 16.8692s	
9625/22300 (epoch 21.581), train_loss = 0.45481007, grad/param norm = 2.0618e-01, time/batch = 16.7323s	
9626/22300 (epoch 21.583), train_loss = 0.50853422, grad/param norm = 2.4287e-01, time/batch = 16.1333s	
9627/22300 (epoch 21.585), train_loss = 0.71569011, grad/param norm = 3.2411e-01, time/batch = 17.3874s	
9628/22300 (epoch 21.587), train_loss = 0.90184047, grad/param norm = 3.2778e-01, time/batch = 16.3946s	
9629/22300 (epoch 21.590), train_loss = 0.78401696, grad/param norm = 3.5988e-01, time/batch = 15.2981s	
9630/22300 (epoch 21.592), train_loss = 0.89723184, grad/param norm = 3.5630e-01, time/batch = 13.8490s	
9631/22300 (epoch 21.594), train_loss = 0.84961734, grad/param norm = 3.1076e-01, time/batch = 0.6869s	
9632/22300 (epoch 21.596), train_loss = 0.55798795, grad/param norm = 2.7750e-01, time/batch = 0.6675s	
9633/22300 (epoch 21.599), train_loss = 0.45752169, grad/param norm = 2.5103e-01, time/batch = 0.6749s	
9634/22300 (epoch 21.601), train_loss = 0.50974575, grad/param norm = 2.7528e-01, time/batch = 0.6869s	
9635/22300 (epoch 21.603), train_loss = 0.61227080, grad/param norm = 2.6408e-01, time/batch = 0.6764s	
9636/22300 (epoch 21.605), train_loss = 0.56474043, grad/param norm = 2.5941e-01, time/batch = 0.6975s	
9637/22300 (epoch 21.608), train_loss = 0.86145055, grad/param norm = 3.3619e-01, time/batch = 0.6801s	
9638/22300 (epoch 21.610), train_loss = 0.85377229, grad/param norm = 3.0163e-01, time/batch = 0.9230s	
9639/22300 (epoch 21.612), train_loss = 0.71509568, grad/param norm = 3.1925e-01, time/batch = 0.9660s	
9640/22300 (epoch 21.614), train_loss = 0.74142938, grad/param norm = 3.0975e-01, time/batch = 0.9580s	
9641/22300 (epoch 21.617), train_loss = 0.67756788, grad/param norm = 3.1746e-01, time/batch = 0.9699s	
9642/22300 (epoch 21.619), train_loss = 0.85007901, grad/param norm = 2.8454e-01, time/batch = 0.9697s	
9643/22300 (epoch 21.621), train_loss = 0.57532357, grad/param norm = 2.5870e-01, time/batch = 1.5705s	
9644/22300 (epoch 21.623), train_loss = 0.56555596, grad/param norm = 2.5626e-01, time/batch = 1.7873s	
9645/22300 (epoch 21.626), train_loss = 0.51356322, grad/param norm = 2.5455e-01, time/batch = 1.8240s	
9646/22300 (epoch 21.628), train_loss = 0.54428735, grad/param norm = 2.3813e-01, time/batch = 15.7551s	
9647/22300 (epoch 21.630), train_loss = 0.55868950, grad/param norm = 2.3292e-01, time/batch = 18.2997s	
9648/22300 (epoch 21.632), train_loss = 0.57680826, grad/param norm = 3.1177e-01, time/batch = 15.4643s	
9649/22300 (epoch 21.635), train_loss = 0.58789342, grad/param norm = 2.5033e-01, time/batch = 17.2909s	
9650/22300 (epoch 21.637), train_loss = 0.67499012, grad/param norm = 2.7285e-01, time/batch = 16.5672s	
9651/22300 (epoch 21.639), train_loss = 0.77191516, grad/param norm = 2.9138e-01, time/batch = 15.8986s	
9652/22300 (epoch 21.641), train_loss = 0.65406604, grad/param norm = 2.8323e-01, time/batch = 16.4397s	
9653/22300 (epoch 21.643), train_loss = 0.55741192, grad/param norm = 2.6814e-01, time/batch = 16.2921s	
9654/22300 (epoch 21.646), train_loss = 0.53061721, grad/param norm = 2.6659e-01, time/batch = 17.2626s	
9655/22300 (epoch 21.648), train_loss = 0.55999107, grad/param norm = 2.4902e-01, time/batch = 16.4543s	
9656/22300 (epoch 21.650), train_loss = 0.65734606, grad/param norm = 3.2317e-01, time/batch = 16.3074s	
9657/22300 (epoch 21.652), train_loss = 0.53889791, grad/param norm = 2.5399e-01, time/batch = 15.4830s	
9658/22300 (epoch 21.655), train_loss = 0.52219922, grad/param norm = 2.5541e-01, time/batch = 18.0383s	
9659/22300 (epoch 21.657), train_loss = 0.60643010, grad/param norm = 2.8275e-01, time/batch = 16.7894s	
9660/22300 (epoch 21.659), train_loss = 0.54869076, grad/param norm = 2.8966e-01, time/batch = 18.1235s	
9661/22300 (epoch 21.661), train_loss = 0.43817080, grad/param norm = 2.1746e-01, time/batch = 14.9546s	
9662/22300 (epoch 21.664), train_loss = 0.51961787, grad/param norm = 2.7937e-01, time/batch = 15.8636s	
9663/22300 (epoch 21.666), train_loss = 0.67334297, grad/param norm = 3.1188e-01, time/batch = 16.9631s	
9664/22300 (epoch 21.668), train_loss = 0.51309119, grad/param norm = 2.5986e-01, time/batch = 16.8123s	
9665/22300 (epoch 21.670), train_loss = 0.66256886, grad/param norm = 2.7525e-01, time/batch = 17.7081s	
9666/22300 (epoch 21.673), train_loss = 0.71661728, grad/param norm = 3.0592e-01, time/batch = 15.6349s	
9667/22300 (epoch 21.675), train_loss = 0.81550516, grad/param norm = 3.9144e-01, time/batch = 17.2282s	
9668/22300 (epoch 21.677), train_loss = 0.82645588, grad/param norm = 3.1344e-01, time/batch = 16.0589s	
9669/22300 (epoch 21.679), train_loss = 0.65865010, grad/param norm = 3.3021e-01, time/batch = 17.5400s	
9670/22300 (epoch 21.682), train_loss = 0.63221742, grad/param norm = 2.7063e-01, time/batch = 17.8694s	
9671/22300 (epoch 21.684), train_loss = 0.62736846, grad/param norm = 3.0881e-01, time/batch = 16.3589s	
9672/22300 (epoch 21.686), train_loss = 0.63004171, grad/param norm = 2.5677e-01, time/batch = 16.6253s	
9673/22300 (epoch 21.688), train_loss = 0.59197525, grad/param norm = 2.8411e-01, time/batch = 16.3026s	
9674/22300 (epoch 21.691), train_loss = 0.53257480, grad/param norm = 2.5983e-01, time/batch = 17.6359s	
9675/22300 (epoch 21.693), train_loss = 0.53088020, grad/param norm = 2.6586e-01, time/batch = 15.7901s	
9676/22300 (epoch 21.695), train_loss = 0.46029672, grad/param norm = 2.3251e-01, time/batch = 16.8798s	
9677/22300 (epoch 21.697), train_loss = 0.50689438, grad/param norm = 2.4371e-01, time/batch = 16.8752s	
9678/22300 (epoch 21.700), train_loss = 0.51421618, grad/param norm = 2.6572e-01, time/batch = 18.4520s	
9679/22300 (epoch 21.702), train_loss = 0.50747129, grad/param norm = 2.3817e-01, time/batch = 16.7187s	
9680/22300 (epoch 21.704), train_loss = 0.60994411, grad/param norm = 2.9202e-01, time/batch = 15.5510s	
9681/22300 (epoch 21.706), train_loss = 0.52344171, grad/param norm = 2.4300e-01, time/batch = 16.2208s	
9682/22300 (epoch 21.709), train_loss = 0.42860368, grad/param norm = 2.2353e-01, time/batch = 15.8180s	
9683/22300 (epoch 21.711), train_loss = 0.43494414, grad/param norm = 2.1114e-01, time/batch = 18.2929s	
9684/22300 (epoch 21.713), train_loss = 0.60846385, grad/param norm = 2.8640e-01, time/batch = 17.3817s	
9685/22300 (epoch 21.715), train_loss = 0.60114778, grad/param norm = 2.5753e-01, time/batch = 16.2867s	
9686/22300 (epoch 21.717), train_loss = 0.77996166, grad/param norm = 2.9714e-01, time/batch = 16.1361s	
9687/22300 (epoch 21.720), train_loss = 0.50550734, grad/param norm = 2.2792e-01, time/batch = 15.5503s	
9688/22300 (epoch 21.722), train_loss = 0.61526349, grad/param norm = 2.7431e-01, time/batch = 17.1376s	
9689/22300 (epoch 21.724), train_loss = 0.68123596, grad/param norm = 3.1135e-01, time/batch = 16.9695s	
9690/22300 (epoch 21.726), train_loss = 0.54187666, grad/param norm = 2.8683e-01, time/batch = 17.2784s	
9691/22300 (epoch 21.729), train_loss = 0.60149595, grad/param norm = 2.8329e-01, time/batch = 16.2777s	
9692/22300 (epoch 21.731), train_loss = 0.79433061, grad/param norm = 3.2365e-01, time/batch = 17.2925s	
9693/22300 (epoch 21.733), train_loss = 0.78780208, grad/param norm = 3.2699e-01, time/batch = 16.6490s	
9694/22300 (epoch 21.735), train_loss = 0.80667271, grad/param norm = 3.5623e-01, time/batch = 16.1467s	
9695/22300 (epoch 21.738), train_loss = 0.59714313, grad/param norm = 3.0840e-01, time/batch = 16.0705s	
9696/22300 (epoch 21.740), train_loss = 0.54352397, grad/param norm = 2.7456e-01, time/batch = 18.2189s	
9697/22300 (epoch 21.742), train_loss = 0.58665038, grad/param norm = 2.7531e-01, time/batch = 17.0569s	
9698/22300 (epoch 21.744), train_loss = 0.84515350, grad/param norm = 2.9245e-01, time/batch = 14.9686s	
9699/22300 (epoch 21.747), train_loss = 0.67636514, grad/param norm = 2.5611e-01, time/batch = 15.9434s	
9700/22300 (epoch 21.749), train_loss = 0.87037456, grad/param norm = 2.9845e-01, time/batch = 17.7179s	
9701/22300 (epoch 21.751), train_loss = 0.76223274, grad/param norm = 3.4709e-01, time/batch = 15.4869s	
9702/22300 (epoch 21.753), train_loss = 0.82198027, grad/param norm = 3.2912e-01, time/batch = 14.8079s	
9703/22300 (epoch 21.756), train_loss = 0.70113430, grad/param norm = 2.7764e-01, time/batch = 17.7269s	
9704/22300 (epoch 21.758), train_loss = 0.64849213, grad/param norm = 2.7164e-01, time/batch = 16.0617s	
9705/22300 (epoch 21.760), train_loss = 0.66639115, grad/param norm = 2.7799e-01, time/batch = 14.8783s	
9706/22300 (epoch 21.762), train_loss = 0.65864917, grad/param norm = 3.5639e-01, time/batch = 17.6220s	
9707/22300 (epoch 21.765), train_loss = 0.67741421, grad/param norm = 3.1983e-01, time/batch = 17.3037s	
9708/22300 (epoch 21.767), train_loss = 0.70678117, grad/param norm = 3.1658e-01, time/batch = 17.2928s	
9709/22300 (epoch 21.769), train_loss = 0.63314473, grad/param norm = 2.7831e-01, time/batch = 16.0394s	
9710/22300 (epoch 21.771), train_loss = 0.71935193, grad/param norm = 3.1933e-01, time/batch = 15.9491s	
9711/22300 (epoch 21.774), train_loss = 0.74985082, grad/param norm = 3.2838e-01, time/batch = 16.5684s	
9712/22300 (epoch 21.776), train_loss = 0.81882954, grad/param norm = 3.1724e-01, time/batch = 16.5487s	
9713/22300 (epoch 21.778), train_loss = 0.78159819, grad/param norm = 3.2013e-01, time/batch = 15.5309s	
9714/22300 (epoch 21.780), train_loss = 0.79267153, grad/param norm = 3.2319e-01, time/batch = 16.7376s	
9715/22300 (epoch 21.783), train_loss = 0.85694428, grad/param norm = 3.5350e-01, time/batch = 16.6626s	
9716/22300 (epoch 21.785), train_loss = 0.61740665, grad/param norm = 3.2543e-01, time/batch = 15.7006s	
9717/22300 (epoch 21.787), train_loss = 0.56989400, grad/param norm = 2.6653e-01, time/batch = 17.1404s	
9718/22300 (epoch 21.789), train_loss = 0.82140772, grad/param norm = 3.5243e-01, time/batch = 15.4786s	
9719/22300 (epoch 21.791), train_loss = 0.96329380, grad/param norm = 3.6881e-01, time/batch = 16.7011s	
9720/22300 (epoch 21.794), train_loss = 0.80864128, grad/param norm = 3.9036e-01, time/batch = 15.4691s	
9721/22300 (epoch 21.796), train_loss = 0.79588451, grad/param norm = 3.4584e-01, time/batch = 16.0608s	
9722/22300 (epoch 21.798), train_loss = 0.89697351, grad/param norm = 3.1501e-01, time/batch = 17.8852s	
9723/22300 (epoch 21.800), train_loss = 0.63404657, grad/param norm = 2.7550e-01, time/batch = 15.7065s	
9724/22300 (epoch 21.803), train_loss = 0.60344215, grad/param norm = 2.6262e-01, time/batch = 17.9389s	
9725/22300 (epoch 21.805), train_loss = 0.68617437, grad/param norm = 2.8799e-01, time/batch = 18.2960s	
9726/22300 (epoch 21.807), train_loss = 0.82963786, grad/param norm = 3.6094e-01, time/batch = 16.9581s	
9727/22300 (epoch 21.809), train_loss = 0.64161616, grad/param norm = 3.3187e-01, time/batch = 14.9776s	
9728/22300 (epoch 21.812), train_loss = 0.74940846, grad/param norm = 3.0380e-01, time/batch = 17.6409s	
9729/22300 (epoch 21.814), train_loss = 0.73335679, grad/param norm = 2.9992e-01, time/batch = 17.1310s	
9730/22300 (epoch 21.816), train_loss = 0.73203384, grad/param norm = 2.7779e-01, time/batch = 15.5436s	
9731/22300 (epoch 21.818), train_loss = 0.83949567, grad/param norm = 3.0415e-01, time/batch = 17.5442s	
9732/22300 (epoch 21.821), train_loss = 0.71671767, grad/param norm = 3.0245e-01, time/batch = 16.8900s	
9733/22300 (epoch 21.823), train_loss = 0.50637144, grad/param norm = 2.9922e-01, time/batch = 17.5454s	
9734/22300 (epoch 21.825), train_loss = 0.58050034, grad/param norm = 3.0723e-01, time/batch = 15.7578s	
9735/22300 (epoch 21.827), train_loss = 0.65429878, grad/param norm = 3.1834e-01, time/batch = 16.6460s	
9736/22300 (epoch 21.830), train_loss = 0.59329055, grad/param norm = 3.0412e-01, time/batch = 15.7947s	
9737/22300 (epoch 21.832), train_loss = 0.56911174, grad/param norm = 2.7887e-01, time/batch = 17.6193s	
9738/22300 (epoch 21.834), train_loss = 0.53691378, grad/param norm = 2.7943e-01, time/batch = 15.8152s	
9739/22300 (epoch 21.836), train_loss = 0.63416108, grad/param norm = 2.9987e-01, time/batch = 16.1931s	
9740/22300 (epoch 21.839), train_loss = 0.58965394, grad/param norm = 2.6022e-01, time/batch = 15.0363s	
9741/22300 (epoch 21.841), train_loss = 0.65977145, grad/param norm = 3.2718e-01, time/batch = 17.1265s	
9742/22300 (epoch 21.843), train_loss = 0.63218532, grad/param norm = 2.8318e-01, time/batch = 17.5453s	
9743/22300 (epoch 21.845), train_loss = 0.61641915, grad/param norm = 2.9880e-01, time/batch = 16.2998s	
9744/22300 (epoch 21.848), train_loss = 0.59825165, grad/param norm = 2.5326e-01, time/batch = 18.3640s	
9745/22300 (epoch 21.850), train_loss = 0.61551531, grad/param norm = 2.6460e-01, time/batch = 15.3027s	
9746/22300 (epoch 21.852), train_loss = 0.59438859, grad/param norm = 2.6952e-01, time/batch = 15.9030s	
9747/22300 (epoch 21.854), train_loss = 0.83192552, grad/param norm = 3.3093e-01, time/batch = 17.6437s	
9748/22300 (epoch 21.857), train_loss = 0.66112301, grad/param norm = 3.3845e-01, time/batch = 17.2930s	
9749/22300 (epoch 21.859), train_loss = 0.51984368, grad/param norm = 2.3615e-01, time/batch = 18.2041s	
9750/22300 (epoch 21.861), train_loss = 0.70572807, grad/param norm = 2.5430e-01, time/batch = 17.2256s	
9751/22300 (epoch 21.863), train_loss = 0.56359786, grad/param norm = 2.8328e-01, time/batch = 16.4679s	
9752/22300 (epoch 21.865), train_loss = 0.50266560, grad/param norm = 2.1381e-01, time/batch = 15.8778s	
9753/22300 (epoch 21.868), train_loss = 0.65185705, grad/param norm = 2.4882e-01, time/batch = 18.0478s	
9754/22300 (epoch 21.870), train_loss = 0.68929055, grad/param norm = 2.9995e-01, time/batch = 15.3604s	
9755/22300 (epoch 21.872), train_loss = 0.75310072, grad/param norm = 3.1064e-01, time/batch = 17.3092s	
9756/22300 (epoch 21.874), train_loss = 0.68748468, grad/param norm = 3.2161e-01, time/batch = 15.3198s	
9757/22300 (epoch 21.877), train_loss = 0.67196644, grad/param norm = 3.1381e-01, time/batch = 19.1265s	
9758/22300 (epoch 21.879), train_loss = 0.53951442, grad/param norm = 2.2903e-01, time/batch = 16.5400s	
9759/22300 (epoch 21.881), train_loss = 0.55530116, grad/param norm = 2.5300e-01, time/batch = 16.6183s	
9760/22300 (epoch 21.883), train_loss = 0.54788845, grad/param norm = 2.8403e-01, time/batch = 17.8016s	
9761/22300 (epoch 21.886), train_loss = 0.53820962, grad/param norm = 2.6372e-01, time/batch = 15.6380s	
9762/22300 (epoch 21.888), train_loss = 0.57536222, grad/param norm = 2.6670e-01, time/batch = 16.7916s	
9763/22300 (epoch 21.890), train_loss = 0.56251635, grad/param norm = 2.7947e-01, time/batch = 18.1355s	
9764/22300 (epoch 21.892), train_loss = 0.83297152, grad/param norm = 3.1076e-01, time/batch = 17.4020s	
9765/22300 (epoch 21.895), train_loss = 0.81021689, grad/param norm = 3.3369e-01, time/batch = 15.9806s	
9766/22300 (epoch 21.897), train_loss = 0.63077602, grad/param norm = 2.9271e-01, time/batch = 16.3808s	
9767/22300 (epoch 21.899), train_loss = 0.64186280, grad/param norm = 2.5310e-01, time/batch = 18.1388s	
9768/22300 (epoch 21.901), train_loss = 0.67939246, grad/param norm = 3.3655e-01, time/batch = 15.7488s	
9769/22300 (epoch 21.904), train_loss = 0.70296683, grad/param norm = 2.7629e-01, time/batch = 17.7830s	
9770/22300 (epoch 21.906), train_loss = 0.70425491, grad/param norm = 2.8943e-01, time/batch = 15.5473s	
9771/22300 (epoch 21.908), train_loss = 0.63055947, grad/param norm = 2.3655e-01, time/batch = 18.1052s	
9772/22300 (epoch 21.910), train_loss = 0.52489079, grad/param norm = 2.3512e-01, time/batch = 17.7303s	
9773/22300 (epoch 21.913), train_loss = 0.72643638, grad/param norm = 2.8647e-01, time/batch = 15.7164s	
9774/22300 (epoch 21.915), train_loss = 0.82704719, grad/param norm = 3.3819e-01, time/batch = 17.1402s	
9775/22300 (epoch 21.917), train_loss = 0.70645468, grad/param norm = 2.8770e-01, time/batch = 16.7987s	
9776/22300 (epoch 21.919), train_loss = 0.72584592, grad/param norm = 3.0302e-01, time/batch = 16.7117s	
9777/22300 (epoch 21.922), train_loss = 0.63694713, grad/param norm = 3.0005e-01, time/batch = 16.3075s	
9778/22300 (epoch 21.924), train_loss = 0.44037129, grad/param norm = 2.6418e-01, time/batch = 15.2894s	
9779/22300 (epoch 21.926), train_loss = 0.51727611, grad/param norm = 2.6313e-01, time/batch = 16.2856s	
9780/22300 (epoch 21.928), train_loss = 0.61344080, grad/param norm = 3.1061e-01, time/batch = 17.0606s	
9781/22300 (epoch 21.930), train_loss = 0.58458452, grad/param norm = 2.3743e-01, time/batch = 16.2294s	
9782/22300 (epoch 21.933), train_loss = 0.68497725, grad/param norm = 2.8308e-01, time/batch = 14.9551s	
9783/22300 (epoch 21.935), train_loss = 0.69528760, grad/param norm = 3.0463e-01, time/batch = 15.3846s	
9784/22300 (epoch 21.937), train_loss = 0.81076261, grad/param norm = 3.4390e-01, time/batch = 16.3038s	
9785/22300 (epoch 21.939), train_loss = 0.76445106, grad/param norm = 3.1838e-01, time/batch = 17.5520s	
9786/22300 (epoch 21.942), train_loss = 0.86950485, grad/param norm = 3.4047e-01, time/batch = 15.2065s	
9787/22300 (epoch 21.944), train_loss = 0.95537184, grad/param norm = 3.8382e-01, time/batch = 18.7799s	
9788/22300 (epoch 21.946), train_loss = 0.66854863, grad/param norm = 2.8598e-01, time/batch = 14.9924s	
9789/22300 (epoch 21.948), train_loss = 0.55573182, grad/param norm = 2.1912e-01, time/batch = 17.5734s	
9790/22300 (epoch 21.951), train_loss = 0.52468615, grad/param norm = 2.6776e-01, time/batch = 17.5509s	
9791/22300 (epoch 21.953), train_loss = 0.57485917, grad/param norm = 2.8665e-01, time/batch = 15.2816s	
9792/22300 (epoch 21.955), train_loss = 0.81018103, grad/param norm = 2.9717e-01, time/batch = 16.0370s	
9793/22300 (epoch 21.957), train_loss = 0.89834661, grad/param norm = 3.1953e-01, time/batch = 16.7146s	
9794/22300 (epoch 21.960), train_loss = 0.80666632, grad/param norm = 3.1529e-01, time/batch = 18.1249s	
9795/22300 (epoch 21.962), train_loss = 0.59154924, grad/param norm = 2.4516e-01, time/batch = 16.7035s	
9796/22300 (epoch 21.964), train_loss = 0.62256619, grad/param norm = 2.7965e-01, time/batch = 18.3727s	
9797/22300 (epoch 21.966), train_loss = 0.54021798, grad/param norm = 2.6428e-01, time/batch = 15.0443s	
9798/22300 (epoch 21.969), train_loss = 0.62330914, grad/param norm = 2.5573e-01, time/batch = 15.6140s	
9799/22300 (epoch 21.971), train_loss = 0.63770781, grad/param norm = 2.4793e-01, time/batch = 15.9741s	
9800/22300 (epoch 21.973), train_loss = 0.64763789, grad/param norm = 2.9952e-01, time/batch = 17.6404s	
9801/22300 (epoch 21.975), train_loss = 0.83790035, grad/param norm = 3.2590e-01, time/batch = 17.3037s	
9802/22300 (epoch 21.978), train_loss = 0.72477801, grad/param norm = 2.8532e-01, time/batch = 15.7298s	
9803/22300 (epoch 21.980), train_loss = 0.78724004, grad/param norm = 3.4100e-01, time/batch = 16.9035s	
9804/22300 (epoch 21.982), train_loss = 0.55336879, grad/param norm = 2.7855e-01, time/batch = 15.4082s	
9805/22300 (epoch 21.984), train_loss = 0.67154693, grad/param norm = 2.6003e-01, time/batch = 16.1180s	
9806/22300 (epoch 21.987), train_loss = 0.59232881, grad/param norm = 3.0699e-01, time/batch = 32.0086s	
9807/22300 (epoch 21.989), train_loss = 0.60261613, grad/param norm = 2.6948e-01, time/batch = 15.6509s	
9808/22300 (epoch 21.991), train_loss = 0.87525930, grad/param norm = 3.2192e-01, time/batch = 16.7179s	
9809/22300 (epoch 21.993), train_loss = 1.08107235, grad/param norm = 3.7390e-01, time/batch = 16.3049s	
9810/22300 (epoch 21.996), train_loss = 1.00674245, grad/param norm = 3.7779e-01, time/batch = 18.7823s	
9811/22300 (epoch 21.998), train_loss = 0.68016762, grad/param norm = 2.6993e-01, time/batch = 18.4613s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
9812/22300 (epoch 22.000), train_loss = 0.55664606, grad/param norm = 2.6670e-01, time/batch = 16.1218s	
9813/22300 (epoch 22.002), train_loss = 0.93722088, grad/param norm = 3.2998e-01, time/batch = 16.5148s	
9814/22300 (epoch 22.004), train_loss = 0.67518187, grad/param norm = 2.6735e-01, time/batch = 16.1385s	
9815/22300 (epoch 22.007), train_loss = 0.68580178, grad/param norm = 3.3338e-01, time/batch = 15.1073s	
9816/22300 (epoch 22.009), train_loss = 0.69010038, grad/param norm = 3.0230e-01, time/batch = 15.1564s	
9817/22300 (epoch 22.011), train_loss = 0.87017024, grad/param norm = 3.3894e-01, time/batch = 13.9881s	
9818/22300 (epoch 22.013), train_loss = 0.68730189, grad/param norm = 3.2064e-01, time/batch = 16.5735s	
9819/22300 (epoch 22.016), train_loss = 0.60941156, grad/param norm = 3.0427e-01, time/batch = 15.4859s	
9820/22300 (epoch 22.018), train_loss = 0.74223990, grad/param norm = 3.5796e-01, time/batch = 16.4737s	
9821/22300 (epoch 22.020), train_loss = 0.60551609, grad/param norm = 3.0752e-01, time/batch = 17.9646s	
9822/22300 (epoch 22.022), train_loss = 0.54639274, grad/param norm = 2.6670e-01, time/batch = 16.8776s	
9823/22300 (epoch 22.025), train_loss = 0.55617950, grad/param norm = 2.5886e-01, time/batch = 15.1377s	
9824/22300 (epoch 22.027), train_loss = 0.56799056, grad/param norm = 2.3007e-01, time/batch = 15.9786s	
9825/22300 (epoch 22.029), train_loss = 0.56360149, grad/param norm = 2.6547e-01, time/batch = 16.0568s	
9826/22300 (epoch 22.031), train_loss = 0.56319272, grad/param norm = 2.0032e-01, time/batch = 18.0410s	
9827/22300 (epoch 22.034), train_loss = 0.58923763, grad/param norm = 2.6251e-01, time/batch = 15.2827s	
9828/22300 (epoch 22.036), train_loss = 0.47383083, grad/param norm = 2.2285e-01, time/batch = 16.5656s	
9829/22300 (epoch 22.038), train_loss = 0.57108909, grad/param norm = 2.7191e-01, time/batch = 15.9660s	
9830/22300 (epoch 22.040), train_loss = 0.61130406, grad/param norm = 2.6472e-01, time/batch = 15.5548s	
9831/22300 (epoch 22.043), train_loss = 0.86918265, grad/param norm = 2.9566e-01, time/batch = 17.3866s	
9832/22300 (epoch 22.045), train_loss = 0.70772485, grad/param norm = 2.5681e-01, time/batch = 17.3879s	
9833/22300 (epoch 22.047), train_loss = 0.75249362, grad/param norm = 3.1770e-01, time/batch = 16.6386s	
9834/22300 (epoch 22.049), train_loss = 0.63784238, grad/param norm = 3.0428e-01, time/batch = 16.4742s	
9835/22300 (epoch 22.052), train_loss = 0.73603662, grad/param norm = 2.9650e-01, time/batch = 17.6361s	
9836/22300 (epoch 22.054), train_loss = 0.66980603, grad/param norm = 2.6766e-01, time/batch = 15.9859s	
9837/22300 (epoch 22.056), train_loss = 0.40638814, grad/param norm = 2.0923e-01, time/batch = 16.8762s	
9838/22300 (epoch 22.058), train_loss = 0.57502567, grad/param norm = 2.5667e-01, time/batch = 16.0557s	
9839/22300 (epoch 22.061), train_loss = 0.53923405, grad/param norm = 2.8288e-01, time/batch = 16.9732s	
9840/22300 (epoch 22.063), train_loss = 0.79917464, grad/param norm = 4.7677e-01, time/batch = 16.3935s	
9841/22300 (epoch 22.065), train_loss = 0.80991968, grad/param norm = 3.3767e-01, time/batch = 15.1801s	
9842/22300 (epoch 22.067), train_loss = 0.60590984, grad/param norm = 3.1550e-01, time/batch = 16.3683s	
9843/22300 (epoch 22.070), train_loss = 0.63664972, grad/param norm = 3.2731e-01, time/batch = 15.9850s	
9844/22300 (epoch 22.072), train_loss = 0.71313591, grad/param norm = 2.9418e-01, time/batch = 16.9713s	
9845/22300 (epoch 22.074), train_loss = 0.68401280, grad/param norm = 3.1127e-01, time/batch = 15.2890s	
9846/22300 (epoch 22.076), train_loss = 0.68836149, grad/param norm = 3.1574e-01, time/batch = 18.1445s	
9847/22300 (epoch 22.078), train_loss = 0.78828919, grad/param norm = 3.0983e-01, time/batch = 15.6206s	
9848/22300 (epoch 22.081), train_loss = 0.76841340, grad/param norm = 3.5433e-01, time/batch = 17.1317s	
9849/22300 (epoch 22.083), train_loss = 0.87274506, grad/param norm = 3.1243e-01, time/batch = 14.8981s	
9850/22300 (epoch 22.085), train_loss = 0.87061297, grad/param norm = 3.0541e-01, time/batch = 17.2961s	
9851/22300 (epoch 22.087), train_loss = 0.71220031, grad/param norm = 2.6875e-01, time/batch = 16.8041s	
9852/22300 (epoch 22.090), train_loss = 0.59653378, grad/param norm = 2.4075e-01, time/batch = 14.8924s	
9853/22300 (epoch 22.092), train_loss = 0.52801068, grad/param norm = 2.4245e-01, time/batch = 16.8117s	
9854/22300 (epoch 22.094), train_loss = 0.53207737, grad/param norm = 2.8633e-01, time/batch = 17.5538s	
9855/22300 (epoch 22.096), train_loss = 0.86570312, grad/param norm = 3.7653e-01, time/batch = 16.9552s	
9856/22300 (epoch 22.099), train_loss = 0.62624291, grad/param norm = 3.2096e-01, time/batch = 15.6411s	
9857/22300 (epoch 22.101), train_loss = 0.72258358, grad/param norm = 2.8181e-01, time/batch = 18.3766s	
9858/22300 (epoch 22.103), train_loss = 0.64902130, grad/param norm = 2.6148e-01, time/batch = 17.8160s	
9859/22300 (epoch 22.105), train_loss = 0.57848862, grad/param norm = 2.7170e-01, time/batch = 17.1211s	
9860/22300 (epoch 22.108), train_loss = 0.67948720, grad/param norm = 2.6544e-01, time/batch = 15.7505s	
9861/22300 (epoch 22.110), train_loss = 0.72448922, grad/param norm = 2.6513e-01, time/batch = 15.4762s	
9862/22300 (epoch 22.112), train_loss = 0.67455675, grad/param norm = 2.5694e-01, time/batch = 16.5469s	
9863/22300 (epoch 22.114), train_loss = 0.74803741, grad/param norm = 3.2647e-01, time/batch = 15.7899s	
9864/22300 (epoch 22.117), train_loss = 0.85784266, grad/param norm = 3.3142e-01, time/batch = 15.7011s	
9865/22300 (epoch 22.119), train_loss = 0.76950448, grad/param norm = 2.8942e-01, time/batch = 15.4856s	
9866/22300 (epoch 22.121), train_loss = 0.85781076, grad/param norm = 3.4225e-01, time/batch = 16.7928s	
9867/22300 (epoch 22.123), train_loss = 0.84918124, grad/param norm = 3.5059e-01, time/batch = 16.8146s	
9868/22300 (epoch 22.126), train_loss = 0.71954694, grad/param norm = 3.1622e-01, time/batch = 17.2284s	
9869/22300 (epoch 22.128), train_loss = 0.75103413, grad/param norm = 2.9679e-01, time/batch = 15.0442s	
9870/22300 (epoch 22.130), train_loss = 0.59426188, grad/param norm = 2.4031e-01, time/batch = 15.2111s	
9871/22300 (epoch 22.132), train_loss = 0.48756304, grad/param norm = 2.3455e-01, time/batch = 16.7242s	
9872/22300 (epoch 22.135), train_loss = 0.52984922, grad/param norm = 2.6499e-01, time/batch = 15.1155s	
9873/22300 (epoch 22.137), train_loss = 0.39492174, grad/param norm = 1.9860e-01, time/batch = 18.1386s	
9874/22300 (epoch 22.139), train_loss = 0.66832601, grad/param norm = 3.3710e-01, time/batch = 15.4422s	
9875/22300 (epoch 22.141), train_loss = 0.74385246, grad/param norm = 2.6569e-01, time/batch = 18.3816s	
9876/22300 (epoch 22.143), train_loss = 0.68178740, grad/param norm = 2.5920e-01, time/batch = 17.8872s	
9877/22300 (epoch 22.146), train_loss = 0.77476770, grad/param norm = 2.9616e-01, time/batch = 17.5389s	
9878/22300 (epoch 22.148), train_loss = 0.54014711, grad/param norm = 2.5050e-01, time/batch = 16.3815s	
9879/22300 (epoch 22.150), train_loss = 0.61271537, grad/param norm = 2.4270e-01, time/batch = 17.4774s	
9880/22300 (epoch 22.152), train_loss = 0.52888489, grad/param norm = 2.6341e-01, time/batch = 16.7768s	
9881/22300 (epoch 22.155), train_loss = 0.52547335, grad/param norm = 2.3237e-01, time/batch = 15.1928s	
9882/22300 (epoch 22.157), train_loss = 0.72659964, grad/param norm = 3.2252e-01, time/batch = 15.2941s	
9883/22300 (epoch 22.159), train_loss = 0.74041704, grad/param norm = 2.8941e-01, time/batch = 18.0585s	
9884/22300 (epoch 22.161), train_loss = 0.72078285, grad/param norm = 2.9994e-01, time/batch = 16.0574s	
9885/22300 (epoch 22.164), train_loss = 0.53867082, grad/param norm = 2.2823e-01, time/batch = 16.7146s	
9886/22300 (epoch 22.166), train_loss = 0.50048849, grad/param norm = 2.1544e-01, time/batch = 16.3198s	
9887/22300 (epoch 22.168), train_loss = 0.51516785, grad/param norm = 2.5232e-01, time/batch = 15.8119s	
9888/22300 (epoch 22.170), train_loss = 0.66001970, grad/param norm = 2.7730e-01, time/batch = 16.3143s	
9889/22300 (epoch 22.173), train_loss = 0.76703337, grad/param norm = 2.9637e-01, time/batch = 16.7948s	
9890/22300 (epoch 22.175), train_loss = 0.62278892, grad/param norm = 2.7335e-01, time/batch = 15.5550s	
9891/22300 (epoch 22.177), train_loss = 0.46537126, grad/param norm = 2.2306e-01, time/batch = 18.4589s	
9892/22300 (epoch 22.179), train_loss = 0.63734400, grad/param norm = 2.5505e-01, time/batch = 15.8857s	
9893/22300 (epoch 22.182), train_loss = 0.82799497, grad/param norm = 2.7976e-01, time/batch = 15.3719s	
9894/22300 (epoch 22.184), train_loss = 0.89808900, grad/param norm = 3.3303e-01, time/batch = 15.2262s	
9895/22300 (epoch 22.186), train_loss = 0.69818990, grad/param norm = 3.1396e-01, time/batch = 20.2373s	
9896/22300 (epoch 22.188), train_loss = 0.90076699, grad/param norm = 3.0007e-01, time/batch = 19.3275s	
9897/22300 (epoch 22.191), train_loss = 0.83189154, grad/param norm = 3.2775e-01, time/batch = 18.4460s	
9898/22300 (epoch 22.193), train_loss = 0.70565200, grad/param norm = 3.6441e-01, time/batch = 22.0020s	
9899/22300 (epoch 22.195), train_loss = 0.63041828, grad/param norm = 2.7436e-01, time/batch = 21.6629s	
9900/22300 (epoch 22.197), train_loss = 0.59898072, grad/param norm = 2.7900e-01, time/batch = 19.2308s	
9901/22300 (epoch 22.200), train_loss = 0.52645900, grad/param norm = 2.4810e-01, time/batch = 19.8061s	
9902/22300 (epoch 22.202), train_loss = 0.59901826, grad/param norm = 2.7276e-01, time/batch = 20.4698s	
9903/22300 (epoch 22.204), train_loss = 0.62559316, grad/param norm = 2.6418e-01, time/batch = 20.3990s	
9904/22300 (epoch 22.206), train_loss = 0.54707036, grad/param norm = 2.4432e-01, time/batch = 20.1004s	
9905/22300 (epoch 22.209), train_loss = 0.62521277, grad/param norm = 2.7525e-01, time/batch = 19.7547s	
9906/22300 (epoch 22.211), train_loss = 0.49407924, grad/param norm = 2.7605e-01, time/batch = 20.9208s	
9907/22300 (epoch 22.213), train_loss = 0.61338358, grad/param norm = 2.5227e-01, time/batch = 21.5636s	
9908/22300 (epoch 22.215), train_loss = 0.82828968, grad/param norm = 3.2088e-01, time/batch = 21.0768s	
9909/22300 (epoch 22.217), train_loss = 0.77897589, grad/param norm = 3.0555e-01, time/batch = 22.8295s	
9910/22300 (epoch 22.220), train_loss = 0.61549991, grad/param norm = 2.8556e-01, time/batch = 19.9033s	
9911/22300 (epoch 22.222), train_loss = 0.56086952, grad/param norm = 2.5340e-01, time/batch = 21.0847s	
9912/22300 (epoch 22.224), train_loss = 0.55937816, grad/param norm = 2.3018e-01, time/batch = 23.1394s	
9913/22300 (epoch 22.226), train_loss = 0.62210346, grad/param norm = 2.4878e-01, time/batch = 23.1385s	
9914/22300 (epoch 22.229), train_loss = 0.55451131, grad/param norm = 3.0000e-01, time/batch = 27.7982s	
9915/22300 (epoch 22.231), train_loss = 0.74120561, grad/param norm = 3.4677e-01, time/batch = 18.1943s	
9916/22300 (epoch 22.233), train_loss = 0.67801213, grad/param norm = 2.9972e-01, time/batch = 16.1207s	
9917/22300 (epoch 22.235), train_loss = 0.49744737, grad/param norm = 2.5006e-01, time/batch = 16.8869s	
9918/22300 (epoch 22.238), train_loss = 0.50652892, grad/param norm = 2.1696e-01, time/batch = 16.8742s	
9919/22300 (epoch 22.240), train_loss = 0.52745992, grad/param norm = 2.2246e-01, time/batch = 17.6026s	
9920/22300 (epoch 22.242), train_loss = 0.56525743, grad/param norm = 2.8274e-01, time/batch = 17.4694s	
9921/22300 (epoch 22.244), train_loss = 0.38308718, grad/param norm = 2.3046e-01, time/batch = 17.3975s	
9922/22300 (epoch 22.247), train_loss = 0.53085397, grad/param norm = 2.6574e-01, time/batch = 15.6361s	
9923/22300 (epoch 22.249), train_loss = 0.37668124, grad/param norm = 1.8821e-01, time/batch = 16.7887s	
9924/22300 (epoch 22.251), train_loss = 0.52595545, grad/param norm = 2.3098e-01, time/batch = 17.4765s	
9925/22300 (epoch 22.253), train_loss = 0.38733138, grad/param norm = 2.2745e-01, time/batch = 17.5453s	
9926/22300 (epoch 22.256), train_loss = 0.46751932, grad/param norm = 2.5344e-01, time/batch = 15.6281s	
9927/22300 (epoch 22.258), train_loss = 0.73106249, grad/param norm = 3.0045e-01, time/batch = 16.3082s	
9928/22300 (epoch 22.260), train_loss = 0.63101090, grad/param norm = 2.7017e-01, time/batch = 15.1525s	
9929/22300 (epoch 22.262), train_loss = 0.50909559, grad/param norm = 2.4036e-01, time/batch = 16.3052s	
9930/22300 (epoch 22.265), train_loss = 0.49742972, grad/param norm = 2.9141e-01, time/batch = 15.0587s	
9931/22300 (epoch 22.267), train_loss = 0.54677109, grad/param norm = 2.2798e-01, time/batch = 14.7878s	
9932/22300 (epoch 22.269), train_loss = 0.64045362, grad/param norm = 2.9879e-01, time/batch = 14.4189s	
9933/22300 (epoch 22.271), train_loss = 0.62995565, grad/param norm = 2.2294e-01, time/batch = 16.1240s	
9934/22300 (epoch 22.274), train_loss = 0.46910316, grad/param norm = 2.2076e-01, time/batch = 16.4761s	
9935/22300 (epoch 22.276), train_loss = 0.43086684, grad/param norm = 2.3972e-01, time/batch = 17.9729s	
9936/22300 (epoch 22.278), train_loss = 0.40276744, grad/param norm = 2.0404e-01, time/batch = 15.0717s	
9937/22300 (epoch 22.280), train_loss = 0.50882183, grad/param norm = 2.5037e-01, time/batch = 16.0412s	
9938/22300 (epoch 22.283), train_loss = 0.39059144, grad/param norm = 2.0474e-01, time/batch = 16.5620s	
9939/22300 (epoch 22.285), train_loss = 0.50379305, grad/param norm = 2.6638e-01, time/batch = 16.1385s	
9940/22300 (epoch 22.287), train_loss = 0.63089624, grad/param norm = 2.7120e-01, time/batch = 15.9645s	
9941/22300 (epoch 22.289), train_loss = 0.55829836, grad/param norm = 2.6121e-01, time/batch = 18.6128s	
9942/22300 (epoch 22.291), train_loss = 0.57011141, grad/param norm = 2.6210e-01, time/batch = 15.3943s	
9943/22300 (epoch 22.294), train_loss = 0.47036995, grad/param norm = 1.8929e-01, time/batch = 17.0558s	
9944/22300 (epoch 22.296), train_loss = 0.59543908, grad/param norm = 2.9807e-01, time/batch = 15.0052s	
9945/22300 (epoch 22.298), train_loss = 0.70602911, grad/param norm = 2.7772e-01, time/batch = 17.0537s	
9946/22300 (epoch 22.300), train_loss = 0.76214844, grad/param norm = 2.9014e-01, time/batch = 16.9023s	
9947/22300 (epoch 22.303), train_loss = 0.57615324, grad/param norm = 2.2867e-01, time/batch = 17.2315s	
9948/22300 (epoch 22.305), train_loss = 0.59713894, grad/param norm = 3.0348e-01, time/batch = 16.2188s	
9949/22300 (epoch 22.307), train_loss = 0.55968338, grad/param norm = 2.7804e-01, time/batch = 17.1339s	
9950/22300 (epoch 22.309), train_loss = 0.52525777, grad/param norm = 2.4915e-01, time/batch = 16.9699s	
9951/22300 (epoch 22.312), train_loss = 0.46321359, grad/param norm = 2.1618e-01, time/batch = 15.2347s	
9952/22300 (epoch 22.314), train_loss = 0.51742226, grad/param norm = 2.6999e-01, time/batch = 18.4598s	
9953/22300 (epoch 22.316), train_loss = 0.52928556, grad/param norm = 2.5294e-01, time/batch = 18.4601s	
9954/22300 (epoch 22.318), train_loss = 0.56632362, grad/param norm = 2.3937e-01, time/batch = 16.1985s	
9955/22300 (epoch 22.321), train_loss = 0.68580225, grad/param norm = 2.8179e-01, time/batch = 15.8192s	
9956/22300 (epoch 22.323), train_loss = 0.50357338, grad/param norm = 2.4723e-01, time/batch = 15.2115s	
9957/22300 (epoch 22.325), train_loss = 0.45476247, grad/param norm = 2.1140e-01, time/batch = 15.1133s	
9958/22300 (epoch 22.327), train_loss = 0.47778932, grad/param norm = 2.4121e-01, time/batch = 17.9344s	
9959/22300 (epoch 22.330), train_loss = 0.51650155, grad/param norm = 2.9909e-01, time/batch = 17.4673s	
9960/22300 (epoch 22.332), train_loss = 0.48031909, grad/param norm = 2.4350e-01, time/batch = 16.6424s	
9961/22300 (epoch 22.334), train_loss = 0.51715324, grad/param norm = 2.6426e-01, time/batch = 15.9735s	
9962/22300 (epoch 22.336), train_loss = 0.53735609, grad/param norm = 2.5885e-01, time/batch = 16.4567s	
9963/22300 (epoch 22.339), train_loss = 0.62344898, grad/param norm = 2.8721e-01, time/batch = 15.3238s	
9964/22300 (epoch 22.341), train_loss = 0.65447112, grad/param norm = 3.2130e-01, time/batch = 15.3216s	
9965/22300 (epoch 22.343), train_loss = 0.71557066, grad/param norm = 3.3146e-01, time/batch = 16.1522s	
9966/22300 (epoch 22.345), train_loss = 0.56112901, grad/param norm = 2.3985e-01, time/batch = 15.3041s	
9967/22300 (epoch 22.348), train_loss = 0.55254048, grad/param norm = 2.3732e-01, time/batch = 18.2196s	
9968/22300 (epoch 22.350), train_loss = 0.48849238, grad/param norm = 2.5961e-01, time/batch = 16.0647s	
9969/22300 (epoch 22.352), train_loss = 0.60709245, grad/param norm = 2.5893e-01, time/batch = 15.7858s	
9970/22300 (epoch 22.354), train_loss = 0.83367316, grad/param norm = 3.2396e-01, time/batch = 17.0457s	
9971/22300 (epoch 22.357), train_loss = 0.69378812, grad/param norm = 2.5048e-01, time/batch = 18.2978s	
9972/22300 (epoch 22.359), train_loss = 0.50907322, grad/param norm = 2.5144e-01, time/batch = 16.3713s	
9973/22300 (epoch 22.361), train_loss = 0.50742890, grad/param norm = 2.7178e-01, time/batch = 16.1308s	
9974/22300 (epoch 22.363), train_loss = 0.69447887, grad/param norm = 2.8729e-01, time/batch = 16.1932s	
9975/22300 (epoch 22.365), train_loss = 0.57918467, grad/param norm = 2.8488e-01, time/batch = 17.3148s	
9976/22300 (epoch 22.368), train_loss = 0.59716437, grad/param norm = 3.8900e-01, time/batch = 17.1394s	
9977/22300 (epoch 22.370), train_loss = 0.57576898, grad/param norm = 2.7824e-01, time/batch = 15.7326s	
9978/22300 (epoch 22.372), train_loss = 0.46207029, grad/param norm = 2.2958e-01, time/batch = 15.7176s	
9979/22300 (epoch 22.374), train_loss = 0.40855476, grad/param norm = 2.1193e-01, time/batch = 18.5474s	
9980/22300 (epoch 22.377), train_loss = 0.54526606, grad/param norm = 2.6065e-01, time/batch = 15.7085s	
9981/22300 (epoch 22.379), train_loss = 0.52957346, grad/param norm = 2.8740e-01, time/batch = 17.1437s	
9982/22300 (epoch 22.381), train_loss = 0.68879709, grad/param norm = 2.7621e-01, time/batch = 16.2325s	
9983/22300 (epoch 22.383), train_loss = 0.53326423, grad/param norm = 2.5345e-01, time/batch = 18.1210s	
9984/22300 (epoch 22.386), train_loss = 0.55723756, grad/param norm = 2.5773e-01, time/batch = 15.6243s	
9985/22300 (epoch 22.388), train_loss = 0.49061401, grad/param norm = 2.4701e-01, time/batch = 16.1315s	
9986/22300 (epoch 22.390), train_loss = 0.58646896, grad/param norm = 2.9780e-01, time/batch = 15.5698s	
9987/22300 (epoch 22.392), train_loss = 0.56828963, grad/param norm = 3.2423e-01, time/batch = 15.3043s	
9988/22300 (epoch 22.395), train_loss = 0.45836304, grad/param norm = 2.3089e-01, time/batch = 16.9529s	
9989/22300 (epoch 22.397), train_loss = 0.31517018, grad/param norm = 1.9164e-01, time/batch = 16.6475s	
9990/22300 (epoch 22.399), train_loss = 0.45885621, grad/param norm = 2.7432e-01, time/batch = 15.2804s	
9991/22300 (epoch 22.401), train_loss = 0.56439749, grad/param norm = 3.4570e-01, time/batch = 16.2042s	
9992/22300 (epoch 22.404), train_loss = 0.54111255, grad/param norm = 2.8354e-01, time/batch = 18.6963s	
9993/22300 (epoch 22.406), train_loss = 0.79161747, grad/param norm = 3.2916e-01, time/batch = 16.9737s	
9994/22300 (epoch 22.408), train_loss = 0.66637780, grad/param norm = 2.8831e-01, time/batch = 15.2360s	
9995/22300 (epoch 22.410), train_loss = 0.73412370, grad/param norm = 2.8642e-01, time/batch = 15.6413s	
9996/22300 (epoch 22.413), train_loss = 0.56478462, grad/param norm = 3.0132e-01, time/batch = 16.7207s	
9997/22300 (epoch 22.415), train_loss = 0.42013681, grad/param norm = 2.4503e-01, time/batch = 16.6439s	
9998/22300 (epoch 22.417), train_loss = 0.61313964, grad/param norm = 2.7205e-01, time/batch = 16.4655s	
9999/22300 (epoch 22.419), train_loss = 0.52738916, grad/param norm = 2.3697e-01, time/batch = 16.4733s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch22.42_1.5911.t7	
10000/22300 (epoch 22.422), train_loss = 0.51379305, grad/param norm = 2.6854e-01, time/batch = 14.9247s	
10001/22300 (epoch 22.424), train_loss = 1.25344244, grad/param norm = 4.4679e-01, time/batch = 17.0370s	
10002/22300 (epoch 22.426), train_loss = 0.45505771, grad/param norm = 2.9007e-01, time/batch = 16.3898s	
10003/22300 (epoch 22.428), train_loss = 0.48192536, grad/param norm = 2.4605e-01, time/batch = 17.6994s	
10004/22300 (epoch 22.430), train_loss = 0.57945005, grad/param norm = 2.8439e-01, time/batch = 16.2911s	
10005/22300 (epoch 22.433), train_loss = 0.55367920, grad/param norm = 2.6757e-01, time/batch = 17.9695s	
10006/22300 (epoch 22.435), train_loss = 0.55010418, grad/param norm = 2.6328e-01, time/batch = 16.8885s	
10007/22300 (epoch 22.437), train_loss = 0.59356474, grad/param norm = 3.1266e-01, time/batch = 15.3059s	
10008/22300 (epoch 22.439), train_loss = 0.66459069, grad/param norm = 3.2368e-01, time/batch = 18.7274s	
10009/22300 (epoch 22.442), train_loss = 0.58176504, grad/param norm = 2.4701e-01, time/batch = 17.1932s	
10010/22300 (epoch 22.444), train_loss = 0.50669396, grad/param norm = 2.1309e-01, time/batch = 19.0111s	
10011/22300 (epoch 22.446), train_loss = 0.51256905, grad/param norm = 3.2800e-01, time/batch = 29.9687s	
10012/22300 (epoch 22.448), train_loss = 0.35971028, grad/param norm = 1.8235e-01, time/batch = 19.9160s	
10013/22300 (epoch 22.451), train_loss = 0.61771030, grad/param norm = 2.6317e-01, time/batch = 15.2942s	
10014/22300 (epoch 22.453), train_loss = 0.52688683, grad/param norm = 2.3034e-01, time/batch = 15.8176s	
10015/22300 (epoch 22.455), train_loss = 0.70223872, grad/param norm = 3.2791e-01, time/batch = 17.8914s	
10016/22300 (epoch 22.457), train_loss = 0.71337790, grad/param norm = 2.6017e-01, time/batch = 17.2955s	
10017/22300 (epoch 22.460), train_loss = 0.68250055, grad/param norm = 2.9652e-01, time/batch = 17.1122s	
10018/22300 (epoch 22.462), train_loss = 0.69300051, grad/param norm = 2.6412e-01, time/batch = 18.2708s	
10019/22300 (epoch 22.464), train_loss = 0.62877577, grad/param norm = 2.8167e-01, time/batch = 15.9604s	
10020/22300 (epoch 22.466), train_loss = 0.52794009, grad/param norm = 2.4692e-01, time/batch = 16.8679s	
10021/22300 (epoch 22.469), train_loss = 0.51080942, grad/param norm = 2.3066e-01, time/batch = 16.5221s	
10022/22300 (epoch 22.471), train_loss = 0.64790345, grad/param norm = 2.5238e-01, time/batch = 15.6512s	
10023/22300 (epoch 22.473), train_loss = 0.62113612, grad/param norm = 2.4561e-01, time/batch = 18.3679s	
10024/22300 (epoch 22.475), train_loss = 0.52754179, grad/param norm = 2.8080e-01, time/batch = 16.6272s	
10025/22300 (epoch 22.478), train_loss = 0.55426978, grad/param norm = 2.6629e-01, time/batch = 15.2225s	
10026/22300 (epoch 22.480), train_loss = 0.39101147, grad/param norm = 2.4150e-01, time/batch = 17.0636s	
10027/22300 (epoch 22.482), train_loss = 0.44519188, grad/param norm = 2.2835e-01, time/batch = 16.7975s	
10028/22300 (epoch 22.484), train_loss = 0.56299258, grad/param norm = 2.6672e-01, time/batch = 17.8707s	
10029/22300 (epoch 22.487), train_loss = 0.62925045, grad/param norm = 2.6708e-01, time/batch = 17.3836s	
10030/22300 (epoch 22.489), train_loss = 0.63415016, grad/param norm = 2.6859e-01, time/batch = 17.0357s	
10031/22300 (epoch 22.491), train_loss = 0.63887550, grad/param norm = 3.0003e-01, time/batch = 16.9499s	
10032/22300 (epoch 22.493), train_loss = 0.59363750, grad/param norm = 3.3781e-01, time/batch = 17.6446s	
10033/22300 (epoch 22.496), train_loss = 0.53841351, grad/param norm = 2.2411e-01, time/batch = 17.2946s	
10034/22300 (epoch 22.498), train_loss = 0.43571701, grad/param norm = 2.2386e-01, time/batch = 15.6100s	
10035/22300 (epoch 22.500), train_loss = 0.61230672, grad/param norm = 3.2836e-01, time/batch = 18.1115s	
10036/22300 (epoch 22.502), train_loss = 0.40579046, grad/param norm = 2.7581e-01, time/batch = 17.8897s	
10037/22300 (epoch 22.504), train_loss = 0.42770902, grad/param norm = 2.2534e-01, time/batch = 16.1036s	
10038/22300 (epoch 22.507), train_loss = 0.50102489, grad/param norm = 2.4587e-01, time/batch = 15.4759s	
10039/22300 (epoch 22.509), train_loss = 0.59643307, grad/param norm = 2.5060e-01, time/batch = 16.5673s	
10040/22300 (epoch 22.511), train_loss = 0.37260839, grad/param norm = 1.9652e-01, time/batch = 17.9770s	
10041/22300 (epoch 22.513), train_loss = 0.41001426, grad/param norm = 2.2970e-01, time/batch = 15.2970s	
10042/22300 (epoch 22.516), train_loss = 0.48633361, grad/param norm = 2.6373e-01, time/batch = 15.8767s	
10043/22300 (epoch 22.518), train_loss = 0.64475880, grad/param norm = 2.9724e-01, time/batch = 14.6315s	
10044/22300 (epoch 22.520), train_loss = 0.52415102, grad/param norm = 2.6537e-01, time/batch = 18.0466s	
10045/22300 (epoch 22.522), train_loss = 0.52233469, grad/param norm = 2.5949e-01, time/batch = 15.1023s	
10046/22300 (epoch 22.525), train_loss = 0.45083963, grad/param norm = 2.4710e-01, time/batch = 18.0463s	
10047/22300 (epoch 22.527), train_loss = 0.66244568, grad/param norm = 3.3176e-01, time/batch = 15.8960s	
10048/22300 (epoch 22.529), train_loss = 0.57107879, grad/param norm = 2.6756e-01, time/batch = 16.2789s	
10049/22300 (epoch 22.531), train_loss = 0.53225633, grad/param norm = 2.7897e-01, time/batch = 15.7942s	
10050/22300 (epoch 22.534), train_loss = 0.49134228, grad/param norm = 2.1325e-01, time/batch = 15.9752s	
10051/22300 (epoch 22.536), train_loss = 0.71830818, grad/param norm = 2.4796e-01, time/batch = 16.1313s	
10052/22300 (epoch 22.538), train_loss = 0.90212349, grad/param norm = 3.0917e-01, time/batch = 16.9783s	
10053/22300 (epoch 22.540), train_loss = 0.57581899, grad/param norm = 2.7708e-01, time/batch = 16.5412s	
10054/22300 (epoch 22.543), train_loss = 0.49710052, grad/param norm = 2.2797e-01, time/batch = 17.3117s	
10055/22300 (epoch 22.545), train_loss = 0.44041342, grad/param norm = 2.8846e-01, time/batch = 16.9725s	
10056/22300 (epoch 22.547), train_loss = 0.40002755, grad/param norm = 2.2832e-01, time/batch = 15.8022s	
10057/22300 (epoch 22.549), train_loss = 0.45745746, grad/param norm = 2.5233e-01, time/batch = 14.8811s	
10058/22300 (epoch 22.552), train_loss = 0.48045193, grad/param norm = 2.6419e-01, time/batch = 16.3648s	
10059/22300 (epoch 22.554), train_loss = 0.58912239, grad/param norm = 2.5662e-01, time/batch = 17.9452s	
10060/22300 (epoch 22.556), train_loss = 0.78611929, grad/param norm = 3.2737e-01, time/batch = 15.4570s	
10061/22300 (epoch 22.558), train_loss = 0.62831621, grad/param norm = 2.8893e-01, time/batch = 17.8074s	
10062/22300 (epoch 22.561), train_loss = 0.76839177, grad/param norm = 3.2474e-01, time/batch = 17.0590s	
10063/22300 (epoch 22.563), train_loss = 0.71374684, grad/param norm = 3.2491e-01, time/batch = 16.4342s	
10064/22300 (epoch 22.565), train_loss = 0.52719178, grad/param norm = 2.8162e-01, time/batch = 16.4810s	
10065/22300 (epoch 22.567), train_loss = 0.51950252, grad/param norm = 2.1601e-01, time/batch = 16.3184s	
10066/22300 (epoch 22.570), train_loss = 0.77411486, grad/param norm = 3.4340e-01, time/batch = 17.5528s	
10067/22300 (epoch 22.572), train_loss = 0.70084961, grad/param norm = 2.7881e-01, time/batch = 15.1327s	
10068/22300 (epoch 22.574), train_loss = 0.56135072, grad/param norm = 2.4528e-01, time/batch = 16.6126s	
10069/22300 (epoch 22.576), train_loss = 0.48428528, grad/param norm = 2.5332e-01, time/batch = 17.4623s	
10070/22300 (epoch 22.578), train_loss = 0.31088568, grad/param norm = 1.9942e-01, time/batch = 16.6397s	
10071/22300 (epoch 22.581), train_loss = 0.43171839, grad/param norm = 2.1500e-01, time/batch = 18.5424s	
10072/22300 (epoch 22.583), train_loss = 0.47542454, grad/param norm = 2.2443e-01, time/batch = 16.8897s	
10073/22300 (epoch 22.585), train_loss = 0.68922145, grad/param norm = 3.0539e-01, time/batch = 16.4737s	
10074/22300 (epoch 22.587), train_loss = 0.85585189, grad/param norm = 3.3169e-01, time/batch = 15.5545s	
10075/22300 (epoch 22.590), train_loss = 0.76376565, grad/param norm = 3.3141e-01, time/batch = 17.4647s	
10076/22300 (epoch 22.592), train_loss = 0.84157997, grad/param norm = 3.1613e-01, time/batch = 14.5582s	
10077/22300 (epoch 22.594), train_loss = 0.84201855, grad/param norm = 3.3928e-01, time/batch = 16.6310s	
10078/22300 (epoch 22.596), train_loss = 0.54017184, grad/param norm = 2.5531e-01, time/batch = 16.4450s	
10079/22300 (epoch 22.599), train_loss = 0.42066312, grad/param norm = 2.3506e-01, time/batch = 17.3019s	
10080/22300 (epoch 22.601), train_loss = 0.49663584, grad/param norm = 2.4608e-01, time/batch = 15.4862s	
10081/22300 (epoch 22.603), train_loss = 0.56897958, grad/param norm = 2.5141e-01, time/batch = 16.6236s	
10082/22300 (epoch 22.605), train_loss = 0.52455684, grad/param norm = 2.4329e-01, time/batch = 16.6331s	
10083/22300 (epoch 22.608), train_loss = 0.84039027, grad/param norm = 3.2479e-01, time/batch = 16.8963s	
10084/22300 (epoch 22.610), train_loss = 0.84483442, grad/param norm = 3.4579e-01, time/batch = 16.4098s	
10085/22300 (epoch 22.612), train_loss = 0.68044782, grad/param norm = 3.3590e-01, time/batch = 15.1911s	
10086/22300 (epoch 22.614), train_loss = 0.72487293, grad/param norm = 3.3087e-01, time/batch = 18.7166s	
10087/22300 (epoch 22.617), train_loss = 0.67656326, grad/param norm = 3.1922e-01, time/batch = 16.9868s	
10088/22300 (epoch 22.619), train_loss = 0.82087066, grad/param norm = 3.3399e-01, time/batch = 15.3073s	
10089/22300 (epoch 22.621), train_loss = 0.57424576, grad/param norm = 2.8841e-01, time/batch = 17.3040s	
10090/22300 (epoch 22.623), train_loss = 0.54171135, grad/param norm = 2.5436e-01, time/batch = 14.6391s	
10091/22300 (epoch 22.626), train_loss = 0.48700009, grad/param norm = 2.3186e-01, time/batch = 15.0084s	
10092/22300 (epoch 22.628), train_loss = 0.50695633, grad/param norm = 2.2132e-01, time/batch = 14.6299s	
10093/22300 (epoch 22.630), train_loss = 0.57649878, grad/param norm = 2.6780e-01, time/batch = 17.5435s	
10094/22300 (epoch 22.632), train_loss = 0.54090324, grad/param norm = 2.5775e-01, time/batch = 17.1277s	
10095/22300 (epoch 22.635), train_loss = 0.56994947, grad/param norm = 2.7721e-01, time/batch = 18.5344s	
10096/22300 (epoch 22.637), train_loss = 0.65019722, grad/param norm = 3.0148e-01, time/batch = 15.2287s	
10097/22300 (epoch 22.639), train_loss = 0.75860168, grad/param norm = 3.1825e-01, time/batch = 15.2879s	
10098/22300 (epoch 22.641), train_loss = 0.60845342, grad/param norm = 2.5297e-01, time/batch = 16.6523s	
10099/22300 (epoch 22.643), train_loss = 0.53916496, grad/param norm = 2.7391e-01, time/batch = 17.1996s	
10100/22300 (epoch 22.646), train_loss = 0.50200602, grad/param norm = 2.5880e-01, time/batch = 15.6193s	
10101/22300 (epoch 22.648), train_loss = 0.55511927, grad/param norm = 2.4008e-01, time/batch = 15.2946s	
10102/22300 (epoch 22.650), train_loss = 0.62046984, grad/param norm = 2.9263e-01, time/batch = 16.8985s	
10103/22300 (epoch 22.652), train_loss = 0.51383093, grad/param norm = 2.2986e-01, time/batch = 15.3814s	
10104/22300 (epoch 22.655), train_loss = 0.50583425, grad/param norm = 2.5372e-01, time/batch = 15.1458s	
10105/22300 (epoch 22.657), train_loss = 0.58433292, grad/param norm = 2.5997e-01, time/batch = 18.8661s	
10106/22300 (epoch 22.659), train_loss = 0.51139901, grad/param norm = 2.4102e-01, time/batch = 17.2261s	
10107/22300 (epoch 22.661), train_loss = 0.42884283, grad/param norm = 2.4227e-01, time/batch = 15.8085s	
10108/22300 (epoch 22.664), train_loss = 0.48950853, grad/param norm = 2.3340e-01, time/batch = 16.3091s	
10109/22300 (epoch 22.666), train_loss = 0.63360684, grad/param norm = 2.9840e-01, time/batch = 16.8771s	
10110/22300 (epoch 22.668), train_loss = 0.50500613, grad/param norm = 2.6630e-01, time/batch = 16.7156s	
10111/22300 (epoch 22.670), train_loss = 0.63723023, grad/param norm = 3.0426e-01, time/batch = 15.9764s	
10112/22300 (epoch 22.673), train_loss = 0.67751631, grad/param norm = 3.0980e-01, time/batch = 15.5383s	
10113/22300 (epoch 22.675), train_loss = 0.74474576, grad/param norm = 3.0959e-01, time/batch = 15.6347s	
10114/22300 (epoch 22.677), train_loss = 0.78024156, grad/param norm = 3.0644e-01, time/batch = 15.9799s	
10115/22300 (epoch 22.679), train_loss = 0.65276121, grad/param norm = 3.3245e-01, time/batch = 17.0637s	
10116/22300 (epoch 22.682), train_loss = 0.60479050, grad/param norm = 2.7209e-01, time/batch = 16.8860s	
10117/22300 (epoch 22.684), train_loss = 0.60966315, grad/param norm = 2.8553e-01, time/batch = 16.7977s	
10118/22300 (epoch 22.686), train_loss = 0.60203381, grad/param norm = 2.4216e-01, time/batch = 18.7748s	
10119/22300 (epoch 22.688), train_loss = 0.56708748, grad/param norm = 3.0021e-01, time/batch = 16.3984s	
10120/22300 (epoch 22.691), train_loss = 0.53253409, grad/param norm = 2.8537e-01, time/batch = 16.7258s	
10121/22300 (epoch 22.693), train_loss = 0.51258324, grad/param norm = 2.6543e-01, time/batch = 15.6071s	
10122/22300 (epoch 22.695), train_loss = 0.45494356, grad/param norm = 2.4382e-01, time/batch = 17.7116s	
10123/22300 (epoch 22.697), train_loss = 0.48127036, grad/param norm = 2.1964e-01, time/batch = 17.2312s	
10124/22300 (epoch 22.700), train_loss = 0.49629810, grad/param norm = 2.5441e-01, time/batch = 16.9662s	
10125/22300 (epoch 22.702), train_loss = 0.47471210, grad/param norm = 2.3619e-01, time/batch = 17.0387s	
10126/22300 (epoch 22.704), train_loss = 0.58249384, grad/param norm = 2.9388e-01, time/batch = 17.7969s	
10127/22300 (epoch 22.706), train_loss = 0.51667041, grad/param norm = 2.9820e-01, time/batch = 16.2965s	
10128/22300 (epoch 22.709), train_loss = 0.41279481, grad/param norm = 2.2633e-01, time/batch = 16.0544s	
10129/22300 (epoch 22.711), train_loss = 0.41761282, grad/param norm = 2.0262e-01, time/batch = 16.2841s	
10130/22300 (epoch 22.713), train_loss = 0.58830893, grad/param norm = 3.1175e-01, time/batch = 16.3834s	
10131/22300 (epoch 22.715), train_loss = 0.57588233, grad/param norm = 2.5140e-01, time/batch = 17.7822s	
10132/22300 (epoch 22.717), train_loss = 0.75235578, grad/param norm = 2.8248e-01, time/batch = 16.1319s	
10133/22300 (epoch 22.720), train_loss = 0.51521463, grad/param norm = 2.7564e-01, time/batch = 17.0666s	
10134/22300 (epoch 22.722), train_loss = 0.60031988, grad/param norm = 2.6627e-01, time/batch = 16.0621s	
10135/22300 (epoch 22.724), train_loss = 0.66074060, grad/param norm = 2.9359e-01, time/batch = 16.2252s	
10136/22300 (epoch 22.726), train_loss = 0.51693659, grad/param norm = 3.0532e-01, time/batch = 15.5828s	
10137/22300 (epoch 22.729), train_loss = 0.58902921, grad/param norm = 2.6731e-01, time/batch = 16.9633s	
10138/22300 (epoch 22.731), train_loss = 0.77394452, grad/param norm = 3.1069e-01, time/batch = 16.7131s	
10139/22300 (epoch 22.733), train_loss = 0.77815676, grad/param norm = 3.3882e-01, time/batch = 15.1540s	
10140/22300 (epoch 22.735), train_loss = 0.79091214, grad/param norm = 3.2056e-01, time/batch = 17.7263s	
10141/22300 (epoch 22.738), train_loss = 0.57433282, grad/param norm = 2.9003e-01, time/batch = 16.0623s	
10142/22300 (epoch 22.740), train_loss = 0.52577629, grad/param norm = 2.5514e-01, time/batch = 17.6941s	
10143/22300 (epoch 22.742), train_loss = 0.54402721, grad/param norm = 2.4127e-01, time/batch = 15.4185s	
10144/22300 (epoch 22.744), train_loss = 0.84805021, grad/param norm = 3.0995e-01, time/batch = 17.1483s	
10145/22300 (epoch 22.747), train_loss = 0.66753135, grad/param norm = 2.5827e-01, time/batch = 16.4621s	
10146/22300 (epoch 22.749), train_loss = 0.85792638, grad/param norm = 3.4630e-01, time/batch = 15.8925s	
10147/22300 (epoch 22.751), train_loss = 0.75132853, grad/param norm = 4.0295e-01, time/batch = 15.5708s	
10148/22300 (epoch 22.753), train_loss = 0.79553832, grad/param norm = 3.3031e-01, time/batch = 15.3161s	
10149/22300 (epoch 22.756), train_loss = 0.70544841, grad/param norm = 3.6238e-01, time/batch = 17.2947s	
10150/22300 (epoch 22.758), train_loss = 0.63580017, grad/param norm = 2.8173e-01, time/batch = 15.2753s	
10151/22300 (epoch 22.760), train_loss = 0.67648776, grad/param norm = 3.0831e-01, time/batch = 18.9612s	
10152/22300 (epoch 22.762), train_loss = 0.64782950, grad/param norm = 2.9123e-01, time/batch = 16.3204s	
10153/22300 (epoch 22.765), train_loss = 0.65228755, grad/param norm = 3.3377e-01, time/batch = 15.5165s	
10154/22300 (epoch 22.767), train_loss = 0.65451353, grad/param norm = 2.8916e-01, time/batch = 15.2800s	
10155/22300 (epoch 22.769), train_loss = 0.60296718, grad/param norm = 2.8895e-01, time/batch = 16.9807s	
10156/22300 (epoch 22.771), train_loss = 0.71107184, grad/param norm = 3.1227e-01, time/batch = 15.2309s	
10157/22300 (epoch 22.774), train_loss = 0.72846096, grad/param norm = 3.2233e-01, time/batch = 15.8570s	
10158/22300 (epoch 22.776), train_loss = 0.79920564, grad/param norm = 3.2046e-01, time/batch = 17.6229s	
10159/22300 (epoch 22.778), train_loss = 0.74480539, grad/param norm = 3.3421e-01, time/batch = 16.8917s	
10160/22300 (epoch 22.780), train_loss = 0.76937518, grad/param norm = 3.4580e-01, time/batch = 16.9850s	
10161/22300 (epoch 22.783), train_loss = 0.76838441, grad/param norm = 3.1089e-01, time/batch = 15.1151s	
10162/22300 (epoch 22.785), train_loss = 0.59765031, grad/param norm = 2.6547e-01, time/batch = 14.9036s	
10163/22300 (epoch 22.787), train_loss = 0.56290765, grad/param norm = 2.8335e-01, time/batch = 17.3034s	
10164/22300 (epoch 22.789), train_loss = 0.77607788, grad/param norm = 3.0534e-01, time/batch = 15.8774s	
10165/22300 (epoch 22.791), train_loss = 0.94159789, grad/param norm = 3.3404e-01, time/batch = 14.7156s	
10166/22300 (epoch 22.794), train_loss = 0.79772282, grad/param norm = 3.6140e-01, time/batch = 14.6367s	
10167/22300 (epoch 22.796), train_loss = 0.73876960, grad/param norm = 2.9633e-01, time/batch = 17.3172s	
10168/22300 (epoch 22.798), train_loss = 0.85909083, grad/param norm = 2.9954e-01, time/batch = 16.4727s	
10169/22300 (epoch 22.800), train_loss = 0.58694111, grad/param norm = 2.5590e-01, time/batch = 15.2149s	
10170/22300 (epoch 22.803), train_loss = 0.56364310, grad/param norm = 2.3177e-01, time/batch = 17.3840s	
10171/22300 (epoch 22.805), train_loss = 0.67488680, grad/param norm = 2.9263e-01, time/batch = 18.1301s	
10172/22300 (epoch 22.807), train_loss = 0.79332474, grad/param norm = 3.4643e-01, time/batch = 15.2003s	
10173/22300 (epoch 22.809), train_loss = 0.59312331, grad/param norm = 2.7396e-01, time/batch = 18.5472s	
10174/22300 (epoch 22.812), train_loss = 0.71079027, grad/param norm = 3.3476e-01, time/batch = 16.2338s	
10175/22300 (epoch 22.814), train_loss = 0.70860948, grad/param norm = 2.8687e-01, time/batch = 17.5512s	
10176/22300 (epoch 22.816), train_loss = 0.68213888, grad/param norm = 2.6446e-01, time/batch = 16.3119s	
10177/22300 (epoch 22.818), train_loss = 0.80644224, grad/param norm = 3.2649e-01, time/batch = 16.5681s	
10178/22300 (epoch 22.821), train_loss = 0.68395587, grad/param norm = 3.0543e-01, time/batch = 16.1290s	
10179/22300 (epoch 22.823), train_loss = 0.46145088, grad/param norm = 2.1987e-01, time/batch = 16.6206s	
10180/22300 (epoch 22.825), train_loss = 0.55661871, grad/param norm = 2.8242e-01, time/batch = 16.3813s	
10181/22300 (epoch 22.827), train_loss = 0.60568872, grad/param norm = 2.6988e-01, time/batch = 15.2785s	
10182/22300 (epoch 22.830), train_loss = 0.55354515, grad/param norm = 2.5741e-01, time/batch = 17.7033s	
10183/22300 (epoch 22.832), train_loss = 0.53611118, grad/param norm = 2.4714e-01, time/batch = 16.0421s	
10184/22300 (epoch 22.834), train_loss = 0.53223844, grad/param norm = 2.8526e-01, time/batch = 17.8727s	
10185/22300 (epoch 22.836), train_loss = 0.62260389, grad/param norm = 2.8724e-01, time/batch = 16.9782s	
10186/22300 (epoch 22.839), train_loss = 0.59982104, grad/param norm = 2.8939e-01, time/batch = 16.0568s	
10187/22300 (epoch 22.841), train_loss = 0.63988561, grad/param norm = 3.4049e-01, time/batch = 15.9533s	
10188/22300 (epoch 22.843), train_loss = 0.60556508, grad/param norm = 2.7698e-01, time/batch = 18.7033s	
10189/22300 (epoch 22.845), train_loss = 0.58000326, grad/param norm = 2.4760e-01, time/batch = 17.8065s	
10190/22300 (epoch 22.848), train_loss = 0.59488136, grad/param norm = 2.8114e-01, time/batch = 15.7854s	
10191/22300 (epoch 22.850), train_loss = 0.61103078, grad/param norm = 2.6257e-01, time/batch = 16.2964s	
10192/22300 (epoch 22.852), train_loss = 0.55545236, grad/param norm = 2.5218e-01, time/batch = 16.4897s	
10193/22300 (epoch 22.854), train_loss = 0.82514382, grad/param norm = 3.5288e-01, time/batch = 17.2264s	
10194/22300 (epoch 22.857), train_loss = 0.66476329, grad/param norm = 3.7957e-01, time/batch = 16.4769s	
10195/22300 (epoch 22.859), train_loss = 0.52581411, grad/param norm = 2.7881e-01, time/batch = 14.9874s	
10196/22300 (epoch 22.861), train_loss = 0.68072697, grad/param norm = 2.7841e-01, time/batch = 17.0646s	
10197/22300 (epoch 22.863), train_loss = 0.53756852, grad/param norm = 2.8363e-01, time/batch = 15.8042s	
10198/22300 (epoch 22.865), train_loss = 0.48828408, grad/param norm = 2.2416e-01, time/batch = 18.7213s	
10199/22300 (epoch 22.868), train_loss = 0.62248522, grad/param norm = 2.7827e-01, time/batch = 14.7949s	
10200/22300 (epoch 22.870), train_loss = 0.66984194, grad/param norm = 2.7871e-01, time/batch = 15.7732s	
10201/22300 (epoch 22.872), train_loss = 0.72775172, grad/param norm = 2.8773e-01, time/batch = 16.8821s	
10202/22300 (epoch 22.874), train_loss = 0.64318574, grad/param norm = 3.0163e-01, time/batch = 15.2475s	
10203/22300 (epoch 22.877), train_loss = 0.65486637, grad/param norm = 3.0259e-01, time/batch = 14.2595s	
10204/22300 (epoch 22.879), train_loss = 0.54545006, grad/param norm = 2.5636e-01, time/batch = 16.4613s	
10205/22300 (epoch 22.881), train_loss = 0.53431189, grad/param norm = 3.2497e-01, time/batch = 17.6404s	
10206/22300 (epoch 22.883), train_loss = 0.54073774, grad/param norm = 3.1195e-01, time/batch = 16.9739s	
10207/22300 (epoch 22.886), train_loss = 0.52652433, grad/param norm = 2.8021e-01, time/batch = 17.7257s	
10208/22300 (epoch 22.888), train_loss = 0.55454194, grad/param norm = 2.4553e-01, time/batch = 15.5143s	
10209/22300 (epoch 22.890), train_loss = 0.53176059, grad/param norm = 2.2175e-01, time/batch = 16.1442s	
10210/22300 (epoch 22.892), train_loss = 0.80225396, grad/param norm = 2.9463e-01, time/batch = 16.3105s	
10211/22300 (epoch 22.895), train_loss = 0.78479267, grad/param norm = 3.4494e-01, time/batch = 16.5392s	
10212/22300 (epoch 22.897), train_loss = 0.60715109, grad/param norm = 3.0682e-01, time/batch = 15.5539s	
10213/22300 (epoch 22.899), train_loss = 0.60855575, grad/param norm = 2.6081e-01, time/batch = 16.6430s	
10214/22300 (epoch 22.901), train_loss = 0.62679705, grad/param norm = 2.5211e-01, time/batch = 17.5587s	
10215/22300 (epoch 22.904), train_loss = 0.66672164, grad/param norm = 2.8491e-01, time/batch = 15.2288s	
10216/22300 (epoch 22.906), train_loss = 0.67818219, grad/param norm = 2.9454e-01, time/batch = 17.2280s	
10217/22300 (epoch 22.908), train_loss = 0.59867526, grad/param norm = 2.4915e-01, time/batch = 16.4665s	
10218/22300 (epoch 22.910), train_loss = 0.50005674, grad/param norm = 2.8417e-01, time/batch = 15.5441s	
10219/22300 (epoch 22.913), train_loss = 0.69061484, grad/param norm = 2.8060e-01, time/batch = 15.8952s	
10220/22300 (epoch 22.915), train_loss = 0.79596172, grad/param norm = 3.3895e-01, time/batch = 15.5715s	
10221/22300 (epoch 22.917), train_loss = 0.66554035, grad/param norm = 2.7862e-01, time/batch = 17.9552s	
10222/22300 (epoch 22.919), train_loss = 0.67952251, grad/param norm = 2.5556e-01, time/batch = 18.1223s	
10223/22300 (epoch 22.922), train_loss = 0.60569391, grad/param norm = 2.8174e-01, time/batch = 17.2874s	
10224/22300 (epoch 22.924), train_loss = 0.42809800, grad/param norm = 2.5556e-01, time/batch = 14.6942s	
10225/22300 (epoch 22.926), train_loss = 0.50442172, grad/param norm = 2.4273e-01, time/batch = 19.1342s	
10226/22300 (epoch 22.928), train_loss = 0.58046991, grad/param norm = 2.8480e-01, time/batch = 27.4961s	
10227/22300 (epoch 22.930), train_loss = 0.56227299, grad/param norm = 2.5425e-01, time/batch = 17.7615s	
10228/22300 (epoch 22.933), train_loss = 0.65877104, grad/param norm = 2.9405e-01, time/batch = 18.5579s	
10229/22300 (epoch 22.935), train_loss = 0.66453875, grad/param norm = 3.1555e-01, time/batch = 16.1107s	
10230/22300 (epoch 22.937), train_loss = 0.76714248, grad/param norm = 3.7088e-01, time/batch = 17.6509s	
10231/22300 (epoch 22.939), train_loss = 0.72314274, grad/param norm = 3.1278e-01, time/batch = 16.5526s	
10232/22300 (epoch 22.942), train_loss = 0.85277627, grad/param norm = 3.5332e-01, time/batch = 16.7747s	
10233/22300 (epoch 22.944), train_loss = 0.93918113, grad/param norm = 4.2187e-01, time/batch = 15.8727s	
10234/22300 (epoch 22.946), train_loss = 0.64108294, grad/param norm = 2.9778e-01, time/batch = 16.7331s	
10235/22300 (epoch 22.948), train_loss = 0.55578257, grad/param norm = 2.4346e-01, time/batch = 16.5357s	
10236/22300 (epoch 22.951), train_loss = 0.50150539, grad/param norm = 2.3330e-01, time/batch = 15.2120s	
10237/22300 (epoch 22.953), train_loss = 0.56558553, grad/param norm = 2.8934e-01, time/batch = 16.2699s	
10238/22300 (epoch 22.955), train_loss = 0.80022152, grad/param norm = 3.2024e-01, time/batch = 15.6066s	
10239/22300 (epoch 22.957), train_loss = 0.89159372, grad/param norm = 3.1489e-01, time/batch = 17.2974s	
10240/22300 (epoch 22.960), train_loss = 0.76412145, grad/param norm = 2.9798e-01, time/batch = 16.2076s	
10241/22300 (epoch 22.962), train_loss = 0.56753107, grad/param norm = 2.5990e-01, time/batch = 16.7233s	
10242/22300 (epoch 22.964), train_loss = 0.60348703, grad/param norm = 2.5918e-01, time/batch = 15.9873s	
10243/22300 (epoch 22.966), train_loss = 0.53192008, grad/param norm = 2.8529e-01, time/batch = 16.5476s	
10244/22300 (epoch 22.969), train_loss = 0.61023640, grad/param norm = 2.8763e-01, time/batch = 16.2940s	
10245/22300 (epoch 22.971), train_loss = 0.61920670, grad/param norm = 2.9584e-01, time/batch = 16.0511s	
10246/22300 (epoch 22.973), train_loss = 0.64508041, grad/param norm = 3.0301e-01, time/batch = 17.1415s	
10247/22300 (epoch 22.975), train_loss = 0.81327784, grad/param norm = 3.2966e-01, time/batch = 15.1361s	
10248/22300 (epoch 22.978), train_loss = 0.71524427, grad/param norm = 3.0705e-01, time/batch = 18.5492s	
10249/22300 (epoch 22.980), train_loss = 0.80522969, grad/param norm = 3.0275e-01, time/batch = 17.8201s	
10250/22300 (epoch 22.982), train_loss = 0.51697603, grad/param norm = 2.5638e-01, time/batch = 16.4626s	
10251/22300 (epoch 22.984), train_loss = 0.65826811, grad/param norm = 2.6037e-01, time/batch = 15.7293s	
10252/22300 (epoch 22.987), train_loss = 0.55885106, grad/param norm = 2.4937e-01, time/batch = 17.5664s	
10253/22300 (epoch 22.989), train_loss = 0.56502362, grad/param norm = 2.7363e-01, time/batch = 16.9561s	
10254/22300 (epoch 22.991), train_loss = 0.86854783, grad/param norm = 3.6715e-01, time/batch = 15.2141s	
10255/22300 (epoch 22.993), train_loss = 1.05223026, grad/param norm = 3.9282e-01, time/batch = 15.6891s	
10256/22300 (epoch 22.996), train_loss = 1.01778911, grad/param norm = 4.2698e-01, time/batch = 18.7012s	
10257/22300 (epoch 22.998), train_loss = 0.65926710, grad/param norm = 3.0073e-01, time/batch = 16.7553s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
10258/22300 (epoch 23.000), train_loss = 0.52414394, grad/param norm = 2.4863e-01, time/batch = 16.4762s	
10259/22300 (epoch 23.002), train_loss = 0.90131864, grad/param norm = 3.2922e-01, time/batch = 18.6145s	
10260/22300 (epoch 23.004), train_loss = 0.64120963, grad/param norm = 2.4605e-01, time/batch = 17.0435s	
10261/22300 (epoch 23.007), train_loss = 0.66521979, grad/param norm = 2.8262e-01, time/batch = 15.8540s	
10262/22300 (epoch 23.009), train_loss = 0.68708862, grad/param norm = 2.9452e-01, time/batch = 15.8112s	
10263/22300 (epoch 23.011), train_loss = 0.85174529, grad/param norm = 3.2586e-01, time/batch = 15.8129s	
10264/22300 (epoch 23.013), train_loss = 0.65913937, grad/param norm = 2.6275e-01, time/batch = 17.2178s	
10265/22300 (epoch 23.016), train_loss = 0.56736300, grad/param norm = 2.8570e-01, time/batch = 16.0609s	
10266/22300 (epoch 23.018), train_loss = 0.70262596, grad/param norm = 3.3960e-01, time/batch = 16.4799s	
10267/22300 (epoch 23.020), train_loss = 0.58113674, grad/param norm = 2.5622e-01, time/batch = 17.9706s	
10268/22300 (epoch 23.022), train_loss = 0.54216979, grad/param norm = 3.0898e-01, time/batch = 15.7305s	
10269/22300 (epoch 23.025), train_loss = 0.53420141, grad/param norm = 2.4456e-01, time/batch = 17.5289s	
10270/22300 (epoch 23.027), train_loss = 0.53449100, grad/param norm = 2.2330e-01, time/batch = 17.6292s	
10271/22300 (epoch 23.029), train_loss = 0.54410935, grad/param norm = 2.3723e-01, time/batch = 15.2753s	
10272/22300 (epoch 23.031), train_loss = 0.54476766, grad/param norm = 2.1592e-01, time/batch = 16.0495s	
10273/22300 (epoch 23.034), train_loss = 0.55261544, grad/param norm = 2.4962e-01, time/batch = 15.8224s	
10274/22300 (epoch 23.036), train_loss = 0.45049149, grad/param norm = 2.1182e-01, time/batch = 16.9583s	
10275/22300 (epoch 23.038), train_loss = 0.53744585, grad/param norm = 2.5857e-01, time/batch = 16.3505s	
10276/22300 (epoch 23.040), train_loss = 0.58007760, grad/param norm = 2.6648e-01, time/batch = 17.1324s	
10277/22300 (epoch 23.043), train_loss = 0.85426802, grad/param norm = 3.1645e-01, time/batch = 17.5623s	
10278/22300 (epoch 23.045), train_loss = 0.69308258, grad/param norm = 2.8531e-01, time/batch = 16.8061s	
10279/22300 (epoch 23.047), train_loss = 0.73823103, grad/param norm = 3.0618e-01, time/batch = 16.2029s	
10280/22300 (epoch 23.049), train_loss = 0.60416999, grad/param norm = 2.7861e-01, time/batch = 17.2125s	
10281/22300 (epoch 23.052), train_loss = 0.70065033, grad/param norm = 3.0047e-01, time/batch = 16.2090s	
10282/22300 (epoch 23.054), train_loss = 0.66270366, grad/param norm = 2.7375e-01, time/batch = 17.0888s	
10283/22300 (epoch 23.056), train_loss = 0.39074508, grad/param norm = 2.1278e-01, time/batch = 17.2893s	
10284/22300 (epoch 23.058), train_loss = 0.55681273, grad/param norm = 2.6929e-01, time/batch = 17.6506s	
10285/22300 (epoch 23.061), train_loss = 0.52103520, grad/param norm = 2.7599e-01, time/batch = 16.5643s	
10286/22300 (epoch 23.063), train_loss = 0.75047642, grad/param norm = 3.8246e-01, time/batch = 15.6394s	
10287/22300 (epoch 23.065), train_loss = 0.79025172, grad/param norm = 3.5719e-01, time/batch = 16.8994s	
10288/22300 (epoch 23.067), train_loss = 0.55931882, grad/param norm = 2.6439e-01, time/batch = 17.0583s	
10289/22300 (epoch 23.070), train_loss = 0.62970486, grad/param norm = 3.4828e-01, time/batch = 16.1067s	
10290/22300 (epoch 23.072), train_loss = 0.71416369, grad/param norm = 3.3579e-01, time/batch = 16.4607s	
10291/22300 (epoch 23.074), train_loss = 0.66450795, grad/param norm = 2.9541e-01, time/batch = 18.4641s	
10292/22300 (epoch 23.076), train_loss = 0.63697844, grad/param norm = 2.8647e-01, time/batch = 16.5810s	
10293/22300 (epoch 23.078), train_loss = 0.73787795, grad/param norm = 3.0045e-01, time/batch = 15.7988s	
10294/22300 (epoch 23.081), train_loss = 0.71769244, grad/param norm = 2.9940e-01, time/batch = 19.0437s	
10295/22300 (epoch 23.083), train_loss = 0.87398016, grad/param norm = 3.7435e-01, time/batch = 15.9724s	
10296/22300 (epoch 23.085), train_loss = 0.82659425, grad/param norm = 3.0972e-01, time/batch = 15.5470s	
10297/22300 (epoch 23.087), train_loss = 0.70158652, grad/param norm = 2.8294e-01, time/batch = 16.3568s	
10298/22300 (epoch 23.090), train_loss = 0.57921146, grad/param norm = 2.7313e-01, time/batch = 16.6202s	
10299/22300 (epoch 23.092), train_loss = 0.51234629, grad/param norm = 2.4359e-01, time/batch = 15.1429s	
10300/22300 (epoch 23.094), train_loss = 0.50433150, grad/param norm = 2.4825e-01, time/batch = 17.6155s	
10301/22300 (epoch 23.096), train_loss = 0.81219603, grad/param norm = 3.6845e-01, time/batch = 17.1354s	
10302/22300 (epoch 23.099), train_loss = 0.57394656, grad/param norm = 2.5956e-01, time/batch = 19.1984s	
10303/22300 (epoch 23.101), train_loss = 0.70395758, grad/param norm = 2.9293e-01, time/batch = 17.6482s	
10304/22300 (epoch 23.103), train_loss = 0.62611230, grad/param norm = 2.5115e-01, time/batch = 14.8237s	
10305/22300 (epoch 23.105), train_loss = 0.55732487, grad/param norm = 2.6444e-01, time/batch = 16.3099s	
10306/22300 (epoch 23.108), train_loss = 0.64415601, grad/param norm = 2.7116e-01, time/batch = 15.6179s	
10307/22300 (epoch 23.110), train_loss = 0.69484149, grad/param norm = 2.8245e-01, time/batch = 16.7099s	
10308/22300 (epoch 23.112), train_loss = 0.64930137, grad/param norm = 2.6991e-01, time/batch = 17.3022s	
10309/22300 (epoch 23.114), train_loss = 0.73749057, grad/param norm = 3.0222e-01, time/batch = 16.6375s	
10310/22300 (epoch 23.117), train_loss = 0.85305848, grad/param norm = 3.6574e-01, time/batch = 15.3460s	
10311/22300 (epoch 23.119), train_loss = 0.73753035, grad/param norm = 2.9853e-01, time/batch = 16.5531s	
10312/22300 (epoch 23.121), train_loss = 0.81736915, grad/param norm = 3.3433e-01, time/batch = 16.4786s	
10313/22300 (epoch 23.123), train_loss = 0.82586343, grad/param norm = 3.1020e-01, time/batch = 15.3246s	
10314/22300 (epoch 23.126), train_loss = 0.69308121, grad/param norm = 3.5805e-01, time/batch = 17.5633s	
10315/22300 (epoch 23.128), train_loss = 0.74941014, grad/param norm = 3.0586e-01, time/batch = 10.1501s	
10316/22300 (epoch 23.130), train_loss = 0.57150780, grad/param norm = 2.4425e-01, time/batch = 0.6704s	
10317/22300 (epoch 23.132), train_loss = 0.47106909, grad/param norm = 2.2943e-01, time/batch = 0.6679s	
10318/22300 (epoch 23.135), train_loss = 0.50377689, grad/param norm = 2.5944e-01, time/batch = 0.6638s	
10319/22300 (epoch 23.137), train_loss = 0.37558973, grad/param norm = 2.0942e-01, time/batch = 0.6678s	
10320/22300 (epoch 23.139), train_loss = 0.64865814, grad/param norm = 2.9728e-01, time/batch = 0.6719s	
10321/22300 (epoch 23.141), train_loss = 0.72265175, grad/param norm = 2.6998e-01, time/batch = 0.6678s	
10322/22300 (epoch 23.143), train_loss = 0.65625840, grad/param norm = 2.8261e-01, time/batch = 0.6668s	
10323/22300 (epoch 23.146), train_loss = 0.73558442, grad/param norm = 2.8531e-01, time/batch = 0.9563s	
10324/22300 (epoch 23.148), train_loss = 0.51725697, grad/param norm = 2.4011e-01, time/batch = 0.9755s	
10325/22300 (epoch 23.150), train_loss = 0.58697312, grad/param norm = 2.8053e-01, time/batch = 0.9725s	
10326/22300 (epoch 23.152), train_loss = 0.49445336, grad/param norm = 2.6912e-01, time/batch = 0.9784s	
10327/22300 (epoch 23.155), train_loss = 0.51143025, grad/param norm = 2.2818e-01, time/batch = 0.9660s	
10328/22300 (epoch 23.157), train_loss = 0.68195166, grad/param norm = 3.0101e-01, time/batch = 1.6410s	
10329/22300 (epoch 23.159), train_loss = 0.72411800, grad/param norm = 3.0776e-01, time/batch = 1.7859s	
10330/22300 (epoch 23.161), train_loss = 0.70611218, grad/param norm = 3.0695e-01, time/batch = 1.7520s	
10331/22300 (epoch 23.164), train_loss = 0.52328320, grad/param norm = 2.1586e-01, time/batch = 16.2430s	
10332/22300 (epoch 23.166), train_loss = 0.48309362, grad/param norm = 2.1388e-01, time/batch = 16.6448s	
10333/22300 (epoch 23.168), train_loss = 0.51297401, grad/param norm = 2.7699e-01, time/batch = 15.5450s	
10334/22300 (epoch 23.170), train_loss = 0.62432126, grad/param norm = 2.3766e-01, time/batch = 18.1214s	
10335/22300 (epoch 23.173), train_loss = 0.77357919, grad/param norm = 3.1876e-01, time/batch = 16.6470s	
10336/22300 (epoch 23.175), train_loss = 0.63085737, grad/param norm = 2.9303e-01, time/batch = 17.2104s	
10337/22300 (epoch 23.177), train_loss = 0.44562773, grad/param norm = 2.1865e-01, time/batch = 16.4723s	
10338/22300 (epoch 23.179), train_loss = 0.61251796, grad/param norm = 2.6239e-01, time/batch = 15.7200s	
10339/22300 (epoch 23.182), train_loss = 0.82827722, grad/param norm = 3.0484e-01, time/batch = 15.4534s	
10340/22300 (epoch 23.184), train_loss = 0.88604093, grad/param norm = 2.8252e-01, time/batch = 14.9670s	
10341/22300 (epoch 23.186), train_loss = 0.67284564, grad/param norm = 2.8488e-01, time/batch = 15.5689s	
10342/22300 (epoch 23.188), train_loss = 0.89262630, grad/param norm = 3.8997e-01, time/batch = 17.4698s	
10343/22300 (epoch 23.191), train_loss = 0.79596531, grad/param norm = 3.4590e-01, time/batch = 15.3967s	
10344/22300 (epoch 23.193), train_loss = 0.67050022, grad/param norm = 3.1564e-01, time/batch = 15.6162s	
10345/22300 (epoch 23.195), train_loss = 0.61281228, grad/param norm = 3.0608e-01, time/batch = 17.2235s	
10346/22300 (epoch 23.197), train_loss = 0.58570475, grad/param norm = 2.6291e-01, time/batch = 16.5760s	
10347/22300 (epoch 23.200), train_loss = 0.50375070, grad/param norm = 2.9012e-01, time/batch = 16.4646s	
10348/22300 (epoch 23.202), train_loss = 0.56741439, grad/param norm = 2.5573e-01, time/batch = 15.9703s	
10349/22300 (epoch 23.204), train_loss = 0.61487109, grad/param norm = 2.7193e-01, time/batch = 16.4804s	
10350/22300 (epoch 23.206), train_loss = 0.53615151, grad/param norm = 2.6608e-01, time/batch = 14.9711s	
10351/22300 (epoch 23.209), train_loss = 0.62675680, grad/param norm = 2.8952e-01, time/batch = 16.3004s	
10352/22300 (epoch 23.211), train_loss = 0.47471575, grad/param norm = 2.6514e-01, time/batch = 15.6194s	
10353/22300 (epoch 23.213), train_loss = 0.60565306, grad/param norm = 2.7803e-01, time/batch = 16.8767s	
10354/22300 (epoch 23.215), train_loss = 0.77409699, grad/param norm = 2.9276e-01, time/batch = 16.7201s	
10355/22300 (epoch 23.217), train_loss = 0.77722115, grad/param norm = 3.1934e-01, time/batch = 16.1256s	
10356/22300 (epoch 23.220), train_loss = 0.58519089, grad/param norm = 2.5725e-01, time/batch = 16.8124s	
10357/22300 (epoch 23.222), train_loss = 0.55445812, grad/param norm = 2.7439e-01, time/batch = 17.5426s	
10358/22300 (epoch 23.224), train_loss = 0.55170192, grad/param norm = 2.2992e-01, time/batch = 16.7677s	
10359/22300 (epoch 23.226), train_loss = 0.60048890, grad/param norm = 2.4924e-01, time/batch = 16.2942s	
10360/22300 (epoch 23.229), train_loss = 0.53741476, grad/param norm = 2.9860e-01, time/batch = 18.4752s	
10361/22300 (epoch 23.231), train_loss = 0.73626576, grad/param norm = 3.4586e-01, time/batch = 16.8963s	
10362/22300 (epoch 23.233), train_loss = 0.66220305, grad/param norm = 3.1580e-01, time/batch = 16.2120s	
10363/22300 (epoch 23.235), train_loss = 0.49363222, grad/param norm = 2.3221e-01, time/batch = 15.7980s	
10364/22300 (epoch 23.238), train_loss = 0.49601793, grad/param norm = 2.3114e-01, time/batch = 17.9584s	
10365/22300 (epoch 23.240), train_loss = 0.50485764, grad/param norm = 2.4444e-01, time/batch = 17.3701s	
10366/22300 (epoch 23.242), train_loss = 0.53258366, grad/param norm = 2.8179e-01, time/batch = 16.7339s	
10367/22300 (epoch 23.244), train_loss = 0.37486552, grad/param norm = 2.3008e-01, time/batch = 17.3790s	
10368/22300 (epoch 23.247), train_loss = 0.50397729, grad/param norm = 2.4683e-01, time/batch = 16.8924s	
10369/22300 (epoch 23.249), train_loss = 0.35029661, grad/param norm = 2.0041e-01, time/batch = 16.0501s	
10370/22300 (epoch 23.251), train_loss = 0.49703335, grad/param norm = 2.3773e-01, time/batch = 16.8206s	
10371/22300 (epoch 23.253), train_loss = 0.37453187, grad/param norm = 2.0963e-01, time/batch = 16.2882s	
10372/22300 (epoch 23.256), train_loss = 0.44491543, grad/param norm = 2.3066e-01, time/batch = 16.1354s	
10373/22300 (epoch 23.258), train_loss = 0.68747393, grad/param norm = 3.2818e-01, time/batch = 17.7002s	
10374/22300 (epoch 23.260), train_loss = 0.60974263, grad/param norm = 2.8779e-01, time/batch = 15.0549s	
10375/22300 (epoch 23.262), train_loss = 0.49871662, grad/param norm = 2.5308e-01, time/batch = 16.7090s	
10376/22300 (epoch 23.265), train_loss = 0.46400581, grad/param norm = 2.5628e-01, time/batch = 16.4660s	
10377/22300 (epoch 23.267), train_loss = 0.52741050, grad/param norm = 2.3389e-01, time/batch = 18.9509s	
10378/22300 (epoch 23.269), train_loss = 0.58258159, grad/param norm = 2.4176e-01, time/batch = 15.5658s	
10379/22300 (epoch 23.271), train_loss = 0.62277583, grad/param norm = 2.4012e-01, time/batch = 16.5328s	
10380/22300 (epoch 23.274), train_loss = 0.47724058, grad/param norm = 2.6987e-01, time/batch = 15.5551s	
10381/22300 (epoch 23.276), train_loss = 0.40497587, grad/param norm = 2.1836e-01, time/batch = 17.4777s	
10382/22300 (epoch 23.278), train_loss = 0.39554895, grad/param norm = 1.7900e-01, time/batch = 16.5654s	
10383/22300 (epoch 23.280), train_loss = 0.49629111, grad/param norm = 2.6007e-01, time/batch = 15.0926s	
10384/22300 (epoch 23.283), train_loss = 0.38361300, grad/param norm = 1.8314e-01, time/batch = 14.8124s	
10385/22300 (epoch 23.285), train_loss = 0.48464023, grad/param norm = 2.9046e-01, time/batch = 15.9860s	
10386/22300 (epoch 23.287), train_loss = 0.60693341, grad/param norm = 2.7496e-01, time/batch = 15.5645s	
10387/22300 (epoch 23.289), train_loss = 0.54745795, grad/param norm = 2.7217e-01, time/batch = 15.9437s	
10388/22300 (epoch 23.291), train_loss = 0.55738444, grad/param norm = 2.8887e-01, time/batch = 18.3699s	
10389/22300 (epoch 23.294), train_loss = 0.45128455, grad/param norm = 2.0667e-01, time/batch = 17.2243s	
10390/22300 (epoch 23.296), train_loss = 0.57005175, grad/param norm = 2.8013e-01, time/batch = 16.3117s	
10391/22300 (epoch 23.298), train_loss = 0.66309722, grad/param norm = 2.5326e-01, time/batch = 15.7219s	
10392/22300 (epoch 23.300), train_loss = 0.74564848, grad/param norm = 3.0243e-01, time/batch = 18.3670s	
10393/22300 (epoch 23.303), train_loss = 0.58146182, grad/param norm = 2.7521e-01, time/batch = 16.7955s	
10394/22300 (epoch 23.305), train_loss = 0.61536771, grad/param norm = 3.8137e-01, time/batch = 16.7912s	
10395/22300 (epoch 23.307), train_loss = 0.54533471, grad/param norm = 2.7662e-01, time/batch = 17.1386s	
10396/22300 (epoch 23.309), train_loss = 0.50964918, grad/param norm = 2.4608e-01, time/batch = 16.3143s	
10397/22300 (epoch 23.312), train_loss = 0.43369778, grad/param norm = 2.1256e-01, time/batch = 17.0580s	
10398/22300 (epoch 23.314), train_loss = 0.47466550, grad/param norm = 2.3522e-01, time/batch = 15.7180s	
10399/22300 (epoch 23.316), train_loss = 0.49951635, grad/param norm = 2.5015e-01, time/batch = 17.0435s	
10400/22300 (epoch 23.318), train_loss = 0.56390903, grad/param norm = 2.8936e-01, time/batch = 18.2986s	
10401/22300 (epoch 23.321), train_loss = 0.66771039, grad/param norm = 2.6809e-01, time/batch = 16.3720s	
10402/22300 (epoch 23.323), train_loss = 0.48538549, grad/param norm = 2.3252e-01, time/batch = 15.2393s	
10403/22300 (epoch 23.325), train_loss = 0.45194472, grad/param norm = 2.6828e-01, time/batch = 16.2985s	
10404/22300 (epoch 23.327), train_loss = 0.46701924, grad/param norm = 2.6474e-01, time/batch = 16.7300s	
10405/22300 (epoch 23.330), train_loss = 0.48407674, grad/param norm = 2.6312e-01, time/batch = 16.1140s	
10406/22300 (epoch 23.332), train_loss = 0.47194055, grad/param norm = 2.7612e-01, time/batch = 17.5349s	
10407/22300 (epoch 23.334), train_loss = 0.51239523, grad/param norm = 2.5911e-01, time/batch = 14.7511s	
10408/22300 (epoch 23.336), train_loss = 0.51989658, grad/param norm = 2.3851e-01, time/batch = 15.5082s	
10409/22300 (epoch 23.339), train_loss = 0.58241849, grad/param norm = 2.8255e-01, time/batch = 14.9790s	
10410/22300 (epoch 23.341), train_loss = 0.63405969, grad/param norm = 3.0662e-01, time/batch = 15.8800s	
10411/22300 (epoch 23.343), train_loss = 0.69957043, grad/param norm = 3.1013e-01, time/batch = 16.6445s	
10412/22300 (epoch 23.345), train_loss = 0.52901049, grad/param norm = 2.4763e-01, time/batch = 17.1097s	
10413/22300 (epoch 23.348), train_loss = 0.53025969, grad/param norm = 2.4300e-01, time/batch = 16.6269s	
10414/22300 (epoch 23.350), train_loss = 0.45885970, grad/param norm = 2.5280e-01, time/batch = 16.4026s	
10415/22300 (epoch 23.352), train_loss = 0.58476368, grad/param norm = 2.5269e-01, time/batch = 16.0555s	
10416/22300 (epoch 23.354), train_loss = 0.80438622, grad/param norm = 3.2759e-01, time/batch = 14.8727s	
10417/22300 (epoch 23.357), train_loss = 0.68476008, grad/param norm = 2.4000e-01, time/batch = 17.3817s	
10418/22300 (epoch 23.359), train_loss = 0.49207858, grad/param norm = 2.7614e-01, time/batch = 14.4695s	
10419/22300 (epoch 23.361), train_loss = 0.49131628, grad/param norm = 2.6110e-01, time/batch = 17.8148s	
10420/22300 (epoch 23.363), train_loss = 0.67125736, grad/param norm = 2.8726e-01, time/batch = 14.9760s	
10421/22300 (epoch 23.365), train_loss = 0.53909123, grad/param norm = 2.4587e-01, time/batch = 14.7502s	
10422/22300 (epoch 23.368), train_loss = 0.56966045, grad/param norm = 3.2317e-01, time/batch = 14.9056s	
10423/22300 (epoch 23.370), train_loss = 0.54142214, grad/param norm = 2.4335e-01, time/batch = 15.5671s	
10424/22300 (epoch 23.372), train_loss = 0.44255671, grad/param norm = 2.4050e-01, time/batch = 15.3591s	
10425/22300 (epoch 23.374), train_loss = 0.39701757, grad/param norm = 2.2639e-01, time/batch = 17.1303s	
10426/22300 (epoch 23.377), train_loss = 0.52046830, grad/param norm = 2.5629e-01, time/batch = 15.4565s	
10427/22300 (epoch 23.379), train_loss = 0.50833486, grad/param norm = 2.7265e-01, time/batch = 14.8747s	
10428/22300 (epoch 23.381), train_loss = 0.66886843, grad/param norm = 2.8179e-01, time/batch = 16.0449s	
10429/22300 (epoch 23.383), train_loss = 0.55007291, grad/param norm = 3.0982e-01, time/batch = 18.7788s	
10430/22300 (epoch 23.386), train_loss = 0.54195145, grad/param norm = 2.5856e-01, time/batch = 15.5577s	
10431/22300 (epoch 23.388), train_loss = 0.48563559, grad/param norm = 2.9699e-01, time/batch = 15.7952s	
10432/22300 (epoch 23.390), train_loss = 0.56769692, grad/param norm = 3.1280e-01, time/batch = 17.8753s	
10433/22300 (epoch 23.392), train_loss = 0.55704850, grad/param norm = 3.2772e-01, time/batch = 16.3898s	
10434/22300 (epoch 23.395), train_loss = 0.43473386, grad/param norm = 2.1824e-01, time/batch = 17.6305s	
10435/22300 (epoch 23.397), train_loss = 0.31219374, grad/param norm = 2.1552e-01, time/batch = 14.9746s	
10436/22300 (epoch 23.399), train_loss = 0.42733008, grad/param norm = 2.0962e-01, time/batch = 18.2021s	
10437/22300 (epoch 23.401), train_loss = 0.50114058, grad/param norm = 2.4063e-01, time/batch = 16.7170s	
10438/22300 (epoch 23.404), train_loss = 0.50760724, grad/param norm = 2.5781e-01, time/batch = 16.9615s	
10439/22300 (epoch 23.406), train_loss = 0.76315499, grad/param norm = 3.4417e-01, time/batch = 15.1984s	
10440/22300 (epoch 23.408), train_loss = 0.65161027, grad/param norm = 3.0326e-01, time/batch = 15.6203s	
10441/22300 (epoch 23.410), train_loss = 0.66920394, grad/param norm = 2.6212e-01, time/batch = 16.8098s	
10442/22300 (epoch 23.413), train_loss = 0.50280511, grad/param norm = 2.6101e-01, time/batch = 16.4626s	
10443/22300 (epoch 23.415), train_loss = 0.39512160, grad/param norm = 2.2922e-01, time/batch = 17.5472s	
10444/22300 (epoch 23.417), train_loss = 0.58902242, grad/param norm = 2.8955e-01, time/batch = 17.2328s	
10445/22300 (epoch 23.419), train_loss = 0.49744530, grad/param norm = 2.1988e-01, time/batch = 16.3103s	
10446/22300 (epoch 23.422), train_loss = 0.48592121, grad/param norm = 2.5371e-01, time/batch = 15.2412s	
10447/22300 (epoch 23.424), train_loss = 0.58244901, grad/param norm = 2.9518e-01, time/batch = 16.1520s	
10448/22300 (epoch 23.426), train_loss = 0.43000272, grad/param norm = 2.5876e-01, time/batch = 16.7852s	
10449/22300 (epoch 23.428), train_loss = 0.45423679, grad/param norm = 2.4079e-01, time/batch = 16.2100s	
10450/22300 (epoch 23.430), train_loss = 0.56122088, grad/param norm = 2.8540e-01, time/batch = 16.4680s	
10451/22300 (epoch 23.433), train_loss = 0.52742058, grad/param norm = 2.4251e-01, time/batch = 16.5618s	
10452/22300 (epoch 23.435), train_loss = 0.53259730, grad/param norm = 2.9499e-01, time/batch = 19.0471s	
10453/22300 (epoch 23.437), train_loss = 0.56416166, grad/param norm = 2.9101e-01, time/batch = 16.1323s	
10454/22300 (epoch 23.439), train_loss = 0.61964393, grad/param norm = 3.0510e-01, time/batch = 16.6350s	
10455/22300 (epoch 23.442), train_loss = 0.56636810, grad/param norm = 2.8215e-01, time/batch = 18.1356s	
10456/22300 (epoch 23.444), train_loss = 0.48285478, grad/param norm = 2.4219e-01, time/batch = 24.2818s	
10457/22300 (epoch 23.446), train_loss = 0.46444320, grad/param norm = 2.4714e-01, time/batch = 21.9216s	
10458/22300 (epoch 23.448), train_loss = 0.34147858, grad/param norm = 1.8167e-01, time/batch = 15.1214s	
10459/22300 (epoch 23.451), train_loss = 0.59069049, grad/param norm = 2.5339e-01, time/batch = 16.9384s	
10460/22300 (epoch 23.453), train_loss = 0.49562726, grad/param norm = 2.3885e-01, time/batch = 16.4534s	
10461/22300 (epoch 23.455), train_loss = 0.68204487, grad/param norm = 3.2861e-01, time/batch = 16.6470s	
10462/22300 (epoch 23.457), train_loss = 0.72160114, grad/param norm = 3.1086e-01, time/batch = 17.0585s	
10463/22300 (epoch 23.460), train_loss = 0.64210664, grad/param norm = 2.6837e-01, time/batch = 17.0351s	
10464/22300 (epoch 23.462), train_loss = 0.69324555, grad/param norm = 2.8851e-01, time/batch = 16.8850s	
10465/22300 (epoch 23.464), train_loss = 0.61413435, grad/param norm = 3.2534e-01, time/batch = 16.3920s	
10466/22300 (epoch 23.466), train_loss = 0.52631764, grad/param norm = 2.6619e-01, time/batch = 16.3812s	
10467/22300 (epoch 23.469), train_loss = 0.50792126, grad/param norm = 2.5153e-01, time/batch = 17.7174s	
10468/22300 (epoch 23.471), train_loss = 0.64025570, grad/param norm = 2.3453e-01, time/batch = 17.8023s	
10469/22300 (epoch 23.473), train_loss = 0.58906599, grad/param norm = 2.3628e-01, time/batch = 15.5640s	
10470/22300 (epoch 23.475), train_loss = 0.50279901, grad/param norm = 2.9789e-01, time/batch = 15.6931s	
10471/22300 (epoch 23.478), train_loss = 0.52457653, grad/param norm = 2.5689e-01, time/batch = 15.2144s	
10472/22300 (epoch 23.480), train_loss = 0.37047174, grad/param norm = 2.7264e-01, time/batch = 17.9813s	
10473/22300 (epoch 23.482), train_loss = 0.40371111, grad/param norm = 2.6268e-01, time/batch = 16.3859s	
10474/22300 (epoch 23.484), train_loss = 0.56781692, grad/param norm = 3.4699e-01, time/batch = 17.5524s	
10475/22300 (epoch 23.487), train_loss = 0.61984559, grad/param norm = 2.6013e-01, time/batch = 15.9843s	
10476/22300 (epoch 23.489), train_loss = 0.62720492, grad/param norm = 2.9569e-01, time/batch = 17.3135s	
10477/22300 (epoch 23.491), train_loss = 0.61522388, grad/param norm = 2.8217e-01, time/batch = 15.3855s	
10478/22300 (epoch 23.493), train_loss = 0.57052677, grad/param norm = 3.8410e-01, time/batch = 19.3783s	
10479/22300 (epoch 23.496), train_loss = 0.54413937, grad/param norm = 2.4116e-01, time/batch = 17.6351s	
10480/22300 (epoch 23.498), train_loss = 0.41398300, grad/param norm = 2.9675e-01, time/batch = 17.1263s	
10481/22300 (epoch 23.500), train_loss = 0.57760026, grad/param norm = 2.8335e-01, time/batch = 15.6507s	
10482/22300 (epoch 23.502), train_loss = 0.38197660, grad/param norm = 2.5908e-01, time/batch = 15.1341s	
10483/22300 (epoch 23.504), train_loss = 0.41155287, grad/param norm = 2.0337e-01, time/batch = 16.1297s	
10484/22300 (epoch 23.507), train_loss = 0.47202099, grad/param norm = 2.4795e-01, time/batch = 16.6342s	
10485/22300 (epoch 23.509), train_loss = 0.60236749, grad/param norm = 2.7271e-01, time/batch = 15.3761s	
10486/22300 (epoch 23.511), train_loss = 0.36152000, grad/param norm = 1.8723e-01, time/batch = 16.4637s	
10487/22300 (epoch 23.513), train_loss = 0.39630160, grad/param norm = 2.1444e-01, time/batch = 17.5228s	
10488/22300 (epoch 23.516), train_loss = 0.46277773, grad/param norm = 2.4251e-01, time/batch = 15.3881s	
10489/22300 (epoch 23.518), train_loss = 0.61832159, grad/param norm = 2.7396e-01, time/batch = 16.0529s	
10490/22300 (epoch 23.520), train_loss = 0.50779939, grad/param norm = 2.6237e-01, time/batch = 16.0515s	
10491/22300 (epoch 23.522), train_loss = 0.49722122, grad/param norm = 2.2479e-01, time/batch = 15.7611s	
10492/22300 (epoch 23.525), train_loss = 0.43631799, grad/param norm = 2.5995e-01, time/batch = 16.2614s	
10493/22300 (epoch 23.527), train_loss = 0.63537388, grad/param norm = 2.8121e-01, time/batch = 16.3893s	
10494/22300 (epoch 23.529), train_loss = 0.54281637, grad/param norm = 2.7024e-01, time/batch = 17.0496s	
10495/22300 (epoch 23.531), train_loss = 0.49155101, grad/param norm = 2.2470e-01, time/batch = 16.1916s	
10496/22300 (epoch 23.534), train_loss = 0.46526837, grad/param norm = 2.2532e-01, time/batch = 18.2886s	
10497/22300 (epoch 23.536), train_loss = 0.71221137, grad/param norm = 2.4714e-01, time/batch = 17.2220s	
10498/22300 (epoch 23.538), train_loss = 0.89213120, grad/param norm = 3.5838e-01, time/batch = 17.4619s	
10499/22300 (epoch 23.540), train_loss = 0.56730821, grad/param norm = 3.0694e-01, time/batch = 15.9011s	
10500/22300 (epoch 23.543), train_loss = 0.48936377, grad/param norm = 2.3552e-01, time/batch = 17.4717s	
10501/22300 (epoch 23.545), train_loss = 0.41314668, grad/param norm = 2.3616e-01, time/batch = 16.4619s	
10502/22300 (epoch 23.547), train_loss = 0.40020516, grad/param norm = 2.4529e-01, time/batch = 16.5859s	
10503/22300 (epoch 23.549), train_loss = 0.43955260, grad/param norm = 2.4586e-01, time/batch = 16.8752s	
10504/22300 (epoch 23.552), train_loss = 0.46750222, grad/param norm = 2.6775e-01, time/batch = 15.7464s	
10505/22300 (epoch 23.554), train_loss = 0.57358755, grad/param norm = 2.8116e-01, time/batch = 17.6324s	
10506/22300 (epoch 23.556), train_loss = 0.78710934, grad/param norm = 3.9933e-01, time/batch = 16.9593s	
10507/22300 (epoch 23.558), train_loss = 0.64152053, grad/param norm = 3.3910e-01, time/batch = 18.1411s	
10508/22300 (epoch 23.561), train_loss = 0.77368816, grad/param norm = 3.5003e-01, time/batch = 16.2322s	
10509/22300 (epoch 23.563), train_loss = 0.69225277, grad/param norm = 3.4132e-01, time/batch = 17.3622s	
10510/22300 (epoch 23.565), train_loss = 0.51886905, grad/param norm = 2.6773e-01, time/batch = 17.8012s	
10511/22300 (epoch 23.567), train_loss = 0.51905195, grad/param norm = 2.7115e-01, time/batch = 15.9867s	
10512/22300 (epoch 23.570), train_loss = 0.72018053, grad/param norm = 3.0834e-01, time/batch = 16.3705s	
10513/22300 (epoch 23.572), train_loss = 0.66570009, grad/param norm = 2.4012e-01, time/batch = 16.2041s	
10514/22300 (epoch 23.574), train_loss = 0.53738436, grad/param norm = 2.2706e-01, time/batch = 17.8956s	
10515/22300 (epoch 23.576), train_loss = 0.44377514, grad/param norm = 2.0754e-01, time/batch = 18.0515s	
10516/22300 (epoch 23.578), train_loss = 0.29231993, grad/param norm = 2.0328e-01, time/batch = 16.0290s	
10517/22300 (epoch 23.581), train_loss = 0.41896424, grad/param norm = 2.2057e-01, time/batch = 15.9468s	
10518/22300 (epoch 23.583), train_loss = 0.44997624, grad/param norm = 2.1362e-01, time/batch = 17.1496s	
10519/22300 (epoch 23.585), train_loss = 0.65940591, grad/param norm = 2.8489e-01, time/batch = 15.6435s	
10520/22300 (epoch 23.587), train_loss = 0.84702879, grad/param norm = 3.3110e-01, time/batch = 15.4621s	
10521/22300 (epoch 23.590), train_loss = 0.70660798, grad/param norm = 3.4016e-01, time/batch = 17.3031s	
10522/22300 (epoch 23.592), train_loss = 0.80978647, grad/param norm = 3.4301e-01, time/batch = 15.9044s	
10523/22300 (epoch 23.594), train_loss = 0.82607424, grad/param norm = 3.4597e-01, time/batch = 18.0506s	
10524/22300 (epoch 23.596), train_loss = 0.51559162, grad/param norm = 2.7308e-01, time/batch = 17.2077s	
10525/22300 (epoch 23.599), train_loss = 0.42067923, grad/param norm = 2.8954e-01, time/batch = 15.9797s	
10526/22300 (epoch 23.601), train_loss = 0.48121463, grad/param norm = 2.4888e-01, time/batch = 16.3965s	
10527/22300 (epoch 23.603), train_loss = 0.56801937, grad/param norm = 2.6798e-01, time/batch = 16.2197s	
10528/22300 (epoch 23.605), train_loss = 0.51393055, grad/param norm = 2.5000e-01, time/batch = 17.4598s	
10529/22300 (epoch 23.608), train_loss = 0.79017275, grad/param norm = 3.1957e-01, time/batch = 16.1485s	
10530/22300 (epoch 23.610), train_loss = 0.80995078, grad/param norm = 3.0472e-01, time/batch = 15.7141s	
10531/22300 (epoch 23.612), train_loss = 0.65715920, grad/param norm = 2.8457e-01, time/batch = 15.7225s	
10532/22300 (epoch 23.614), train_loss = 0.68331676, grad/param norm = 3.2698e-01, time/batch = 17.9763s	
10533/22300 (epoch 23.617), train_loss = 0.63409968, grad/param norm = 2.5395e-01, time/batch = 15.6934s	
10534/22300 (epoch 23.619), train_loss = 0.78719799, grad/param norm = 2.8904e-01, time/batch = 15.7765s	
10535/22300 (epoch 23.621), train_loss = 0.53273237, grad/param norm = 2.6461e-01, time/batch = 15.3884s	
10536/22300 (epoch 23.623), train_loss = 0.52750895, grad/param norm = 2.3515e-01, time/batch = 15.9961s	
10537/22300 (epoch 23.626), train_loss = 0.45293895, grad/param norm = 2.1376e-01, time/batch = 16.6941s	
10538/22300 (epoch 23.628), train_loss = 0.49207014, grad/param norm = 2.4419e-01, time/batch = 15.5436s	
10539/22300 (epoch 23.630), train_loss = 0.54619318, grad/param norm = 2.6462e-01, time/batch = 17.4656s	
10540/22300 (epoch 23.632), train_loss = 0.51173789, grad/param norm = 2.7719e-01, time/batch = 16.1495s	
10541/22300 (epoch 23.635), train_loss = 0.56286584, grad/param norm = 2.7945e-01, time/batch = 17.1260s	
10542/22300 (epoch 23.637), train_loss = 0.62389438, grad/param norm = 3.0695e-01, time/batch = 17.6271s	
10543/22300 (epoch 23.639), train_loss = 0.74062940, grad/param norm = 3.0299e-01, time/batch = 16.5633s	
10544/22300 (epoch 23.641), train_loss = 0.59277061, grad/param norm = 2.7598e-01, time/batch = 15.2355s	
10545/22300 (epoch 23.643), train_loss = 0.51441588, grad/param norm = 2.7641e-01, time/batch = 15.2811s	
10546/22300 (epoch 23.646), train_loss = 0.47647829, grad/param norm = 2.3322e-01, time/batch = 17.4669s	
10547/22300 (epoch 23.648), train_loss = 0.54062513, grad/param norm = 2.2805e-01, time/batch = 15.7330s	
10548/22300 (epoch 23.650), train_loss = 0.58738698, grad/param norm = 2.7057e-01, time/batch = 16.3269s	
10549/22300 (epoch 23.652), train_loss = 0.51937674, grad/param norm = 2.7467e-01, time/batch = 17.3648s	
10550/22300 (epoch 23.655), train_loss = 0.48679390, grad/param norm = 2.5369e-01, time/batch = 17.3730s	
10551/22300 (epoch 23.657), train_loss = 0.56725780, grad/param norm = 3.2183e-01, time/batch = 17.8072s	
10552/22300 (epoch 23.659), train_loss = 0.51925237, grad/param norm = 2.8603e-01, time/batch = 15.9756s	
10553/22300 (epoch 23.661), train_loss = 0.40510885, grad/param norm = 2.2710e-01, time/batch = 15.9664s	
10554/22300 (epoch 23.664), train_loss = 0.46845929, grad/param norm = 2.1235e-01, time/batch = 16.1229s	
10555/22300 (epoch 23.666), train_loss = 0.61720810, grad/param norm = 2.7406e-01, time/batch = 16.3784s	
10556/22300 (epoch 23.668), train_loss = 0.46912148, grad/param norm = 2.3778e-01, time/batch = 15.9021s	
10557/22300 (epoch 23.670), train_loss = 0.60202355, grad/param norm = 2.9552e-01, time/batch = 16.7945s	
10558/22300 (epoch 23.673), train_loss = 0.67349253, grad/param norm = 3.0477e-01, time/batch = 17.6252s	
10559/22300 (epoch 23.675), train_loss = 0.73267102, grad/param norm = 3.7501e-01, time/batch = 17.4571s	
10560/22300 (epoch 23.677), train_loss = 0.77414930, grad/param norm = 3.2031e-01, time/batch = 16.4194s	
10561/22300 (epoch 23.679), train_loss = 0.61694436, grad/param norm = 3.0150e-01, time/batch = 17.2188s	
10562/22300 (epoch 23.682), train_loss = 0.58578969, grad/param norm = 2.7696e-01, time/batch = 16.8712s	
10563/22300 (epoch 23.684), train_loss = 0.56889248, grad/param norm = 2.8075e-01, time/batch = 16.0385s	
10564/22300 (epoch 23.686), train_loss = 0.57513903, grad/param norm = 2.6224e-01, time/batch = 17.3604s	
10565/22300 (epoch 23.688), train_loss = 0.53571046, grad/param norm = 2.7328e-01, time/batch = 15.7120s	
10566/22300 (epoch 23.691), train_loss = 0.49736520, grad/param norm = 2.5897e-01, time/batch = 16.1561s	
10567/22300 (epoch 23.693), train_loss = 0.47864293, grad/param norm = 2.4906e-01, time/batch = 15.5454s	
10568/22300 (epoch 23.695), train_loss = 0.42918303, grad/param norm = 2.1291e-01, time/batch = 17.3835s	
10569/22300 (epoch 23.697), train_loss = 0.46323374, grad/param norm = 2.2053e-01, time/batch = 16.6972s	
10570/22300 (epoch 23.700), train_loss = 0.47209442, grad/param norm = 2.6125e-01, time/batch = 17.1347s	
10571/22300 (epoch 23.702), train_loss = 0.45479109, grad/param norm = 2.2688e-01, time/batch = 17.2866s	
10572/22300 (epoch 23.704), train_loss = 0.56506690, grad/param norm = 2.9618e-01, time/batch = 16.9791s	
10573/22300 (epoch 23.706), train_loss = 0.47271898, grad/param norm = 2.3348e-01, time/batch = 17.1229s	
10574/22300 (epoch 23.709), train_loss = 0.39401012, grad/param norm = 2.3656e-01, time/batch = 15.4670s	
10575/22300 (epoch 23.711), train_loss = 0.39490844, grad/param norm = 1.8070e-01, time/batch = 17.4555s	
10576/22300 (epoch 23.713), train_loss = 0.56597911, grad/param norm = 2.8648e-01, time/batch = 16.3917s	
10577/22300 (epoch 23.715), train_loss = 0.55205888, grad/param norm = 2.4465e-01, time/batch = 17.3882s	
10578/22300 (epoch 23.717), train_loss = 0.71647240, grad/param norm = 2.6167e-01, time/batch = 14.8128s	
10579/22300 (epoch 23.720), train_loss = 0.46629052, grad/param norm = 2.1149e-01, time/batch = 15.5661s	
10580/22300 (epoch 23.722), train_loss = 0.58139449, grad/param norm = 2.7417e-01, time/batch = 16.1562s	
10581/22300 (epoch 23.724), train_loss = 0.63469482, grad/param norm = 3.1936e-01, time/batch = 16.1809s	
10582/22300 (epoch 23.726), train_loss = 0.51246094, grad/param norm = 2.9134e-01, time/batch = 15.5342s	
10583/22300 (epoch 23.729), train_loss = 0.54038131, grad/param norm = 2.4266e-01, time/batch = 15.9465s	
10584/22300 (epoch 23.731), train_loss = 0.73120087, grad/param norm = 2.8397e-01, time/batch = 17.5359s	
10585/22300 (epoch 23.733), train_loss = 0.75956521, grad/param norm = 3.2345e-01, time/batch = 16.6820s	
10586/22300 (epoch 23.735), train_loss = 0.79092958, grad/param norm = 3.4723e-01, time/batch = 17.5529s	
10587/22300 (epoch 23.738), train_loss = 0.58139524, grad/param norm = 3.4572e-01, time/batch = 17.7308s	
10588/22300 (epoch 23.740), train_loss = 0.50652806, grad/param norm = 2.6587e-01, time/batch = 16.7275s	
10589/22300 (epoch 23.742), train_loss = 0.52786138, grad/param norm = 2.7199e-01, time/batch = 17.6241s	
10590/22300 (epoch 23.744), train_loss = 0.80361096, grad/param norm = 3.0410e-01, time/batch = 17.5513s	
10591/22300 (epoch 23.747), train_loss = 0.64227451, grad/param norm = 2.5972e-01, time/batch = 15.8796s	
10592/22300 (epoch 23.749), train_loss = 0.83201169, grad/param norm = 3.5241e-01, time/batch = 15.6256s	
10593/22300 (epoch 23.751), train_loss = 0.70834401, grad/param norm = 3.5752e-01, time/batch = 18.5279s	
10594/22300 (epoch 23.753), train_loss = 0.75856634, grad/param norm = 3.1287e-01, time/batch = 17.7248s	
10595/22300 (epoch 23.756), train_loss = 0.66772682, grad/param norm = 2.8073e-01, time/batch = 16.3804s	
10596/22300 (epoch 23.758), train_loss = 0.61029896, grad/param norm = 2.6867e-01, time/batch = 15.2006s	
10597/22300 (epoch 23.760), train_loss = 0.62899837, grad/param norm = 2.7394e-01, time/batch = 18.0576s	
10598/22300 (epoch 23.762), train_loss = 0.60391242, grad/param norm = 3.2989e-01, time/batch = 16.0424s	
10599/22300 (epoch 23.765), train_loss = 0.61818188, grad/param norm = 3.1598e-01, time/batch = 15.7475s	
10600/22300 (epoch 23.767), train_loss = 0.64430315, grad/param norm = 2.6934e-01, time/batch = 14.9941s	
10601/22300 (epoch 23.769), train_loss = 0.61723282, grad/param norm = 3.2096e-01, time/batch = 17.6399s	
10602/22300 (epoch 23.771), train_loss = 0.67081089, grad/param norm = 3.0629e-01, time/batch = 17.2244s	
10603/22300 (epoch 23.774), train_loss = 0.69307878, grad/param norm = 3.0124e-01, time/batch = 15.8772s	
10604/22300 (epoch 23.776), train_loss = 0.75049535, grad/param norm = 3.0846e-01, time/batch = 17.3095s	
10605/22300 (epoch 23.778), train_loss = 0.72808867, grad/param norm = 3.0971e-01, time/batch = 16.7309s	
10606/22300 (epoch 23.780), train_loss = 0.73194544, grad/param norm = 3.4030e-01, time/batch = 17.6182s	
10607/22300 (epoch 23.783), train_loss = 0.78674103, grad/param norm = 3.5374e-01, time/batch = 16.8037s	
10608/22300 (epoch 23.785), train_loss = 0.58609461, grad/param norm = 2.8758e-01, time/batch = 16.5733s	
10609/22300 (epoch 23.787), train_loss = 0.54559431, grad/param norm = 2.5105e-01, time/batch = 15.8801s	
10610/22300 (epoch 23.789), train_loss = 0.75735495, grad/param norm = 3.5087e-01, time/batch = 15.6418s	
10611/22300 (epoch 23.791), train_loss = 0.93013531, grad/param norm = 3.7498e-01, time/batch = 15.6261s	
10612/22300 (epoch 23.794), train_loss = 0.77353812, grad/param norm = 3.8152e-01, time/batch = 15.1942s	
10613/22300 (epoch 23.796), train_loss = 0.74665343, grad/param norm = 3.3303e-01, time/batch = 14.8861s	
10614/22300 (epoch 23.798), train_loss = 0.85150041, grad/param norm = 2.8800e-01, time/batch = 15.7147s	
10615/22300 (epoch 23.800), train_loss = 0.59381024, grad/param norm = 2.4266e-01, time/batch = 15.9899s	
10616/22300 (epoch 23.803), train_loss = 0.54272958, grad/param norm = 2.2559e-01, time/batch = 15.2423s	
10617/22300 (epoch 23.805), train_loss = 0.67114950, grad/param norm = 2.8609e-01, time/batch = 17.0566s	
10618/22300 (epoch 23.807), train_loss = 0.76718708, grad/param norm = 3.2153e-01, time/batch = 17.1917s	
10619/22300 (epoch 23.809), train_loss = 0.58461506, grad/param norm = 3.4476e-01, time/batch = 14.8703s	
10620/22300 (epoch 23.812), train_loss = 0.68421937, grad/param norm = 2.9828e-01, time/batch = 16.5553s	
10621/22300 (epoch 23.814), train_loss = 0.68420273, grad/param norm = 2.7607e-01, time/batch = 15.9584s	
10622/22300 (epoch 23.816), train_loss = 0.68278751, grad/param norm = 2.8975e-01, time/batch = 17.7260s	
10623/22300 (epoch 23.818), train_loss = 0.78246150, grad/param norm = 3.0263e-01, time/batch = 15.5437s	
10624/22300 (epoch 23.821), train_loss = 0.66823895, grad/param norm = 2.9129e-01, time/batch = 18.0520s	
10625/22300 (epoch 23.823), train_loss = 0.46674944, grad/param norm = 2.7777e-01, time/batch = 15.1339s	
10626/22300 (epoch 23.825), train_loss = 0.50919855, grad/param norm = 2.8889e-01, time/batch = 17.8053s	
10627/22300 (epoch 23.827), train_loss = 0.59718645, grad/param norm = 2.8822e-01, time/batch = 14.8732s	
10628/22300 (epoch 23.830), train_loss = 0.56629337, grad/param norm = 3.3089e-01, time/batch = 15.6336s	
10629/22300 (epoch 23.832), train_loss = 0.53735611, grad/param norm = 3.0863e-01, time/batch = 17.8389s	
10630/22300 (epoch 23.834), train_loss = 0.48672907, grad/param norm = 2.8021e-01, time/batch = 15.6146s	
10631/22300 (epoch 23.836), train_loss = 0.61581504, grad/param norm = 3.2642e-01, time/batch = 17.0560s	
10632/22300 (epoch 23.839), train_loss = 0.57058056, grad/param norm = 3.0017e-01, time/batch = 15.4619s	
10633/22300 (epoch 23.841), train_loss = 0.57913790, grad/param norm = 3.1430e-01, time/batch = 15.7053s	
10634/22300 (epoch 23.843), train_loss = 0.57192429, grad/param norm = 2.6183e-01, time/batch = 18.8762s	
10635/22300 (epoch 23.845), train_loss = 0.55135095, grad/param norm = 2.4660e-01, time/batch = 16.5492s	
10636/22300 (epoch 23.848), train_loss = 0.56178886, grad/param norm = 2.4700e-01, time/batch = 15.8938s	
10637/22300 (epoch 23.850), train_loss = 0.57624903, grad/param norm = 2.4601e-01, time/batch = 16.9829s	
10638/22300 (epoch 23.852), train_loss = 0.53698812, grad/param norm = 2.6089e-01, time/batch = 16.3857s	
10639/22300 (epoch 23.854), train_loss = 0.75541680, grad/param norm = 3.2492e-01, time/batch = 15.8002s	
10640/22300 (epoch 23.857), train_loss = 0.61783780, grad/param norm = 2.8795e-01, time/batch = 16.7348s	
10641/22300 (epoch 23.859), train_loss = 0.49861608, grad/param norm = 2.7454e-01, time/batch = 16.7752s	
10642/22300 (epoch 23.861), train_loss = 0.65712954, grad/param norm = 2.7089e-01, time/batch = 16.5706s	
10643/22300 (epoch 23.863), train_loss = 0.50412715, grad/param norm = 2.4922e-01, time/batch = 14.7899s	
10644/22300 (epoch 23.865), train_loss = 0.46961159, grad/param norm = 2.3903e-01, time/batch = 18.8815s	
10645/22300 (epoch 23.868), train_loss = 0.60144606, grad/param norm = 2.6854e-01, time/batch = 15.4630s	
10646/22300 (epoch 23.870), train_loss = 0.65497722, grad/param norm = 3.1234e-01, time/batch = 16.0404s	
10647/22300 (epoch 23.872), train_loss = 0.71285212, grad/param norm = 2.9459e-01, time/batch = 16.7146s	
10648/22300 (epoch 23.874), train_loss = 0.62548978, grad/param norm = 2.8353e-01, time/batch = 16.8710s	
10649/22300 (epoch 23.877), train_loss = 0.61906159, grad/param norm = 2.8551e-01, time/batch = 17.3031s	
10650/22300 (epoch 23.879), train_loss = 0.52677531, grad/param norm = 2.3795e-01, time/batch = 15.6214s	
10651/22300 (epoch 23.881), train_loss = 0.50979378, grad/param norm = 2.6017e-01, time/batch = 19.5320s	
10652/22300 (epoch 23.883), train_loss = 0.49534548, grad/param norm = 2.3097e-01, time/batch = 18.4535s	
10653/22300 (epoch 23.886), train_loss = 0.49378230, grad/param norm = 2.6875e-01, time/batch = 16.5463s	
10654/22300 (epoch 23.888), train_loss = 0.53332489, grad/param norm = 2.2119e-01, time/batch = 15.7907s	
10655/22300 (epoch 23.890), train_loss = 0.52025890, grad/param norm = 2.2980e-01, time/batch = 14.2518s	
10656/22300 (epoch 23.892), train_loss = 0.75552926, grad/param norm = 2.8444e-01, time/batch = 16.6527s	
10657/22300 (epoch 23.895), train_loss = 0.74462963, grad/param norm = 3.3204e-01, time/batch = 16.5525s	
10658/22300 (epoch 23.897), train_loss = 0.56879627, grad/param norm = 2.7317e-01, time/batch = 16.2286s	
10659/22300 (epoch 23.899), train_loss = 0.58586114, grad/param norm = 2.9657e-01, time/batch = 15.3038s	
10660/22300 (epoch 23.901), train_loss = 0.63115232, grad/param norm = 3.2857e-01, time/batch = 17.2987s	
10661/22300 (epoch 23.904), train_loss = 0.65001785, grad/param norm = 2.7082e-01, time/batch = 15.6898s	
10662/22300 (epoch 23.906), train_loss = 0.64897021, grad/param norm = 3.1116e-01, time/batch = 17.6167s	
10663/22300 (epoch 23.908), train_loss = 0.58509532, grad/param norm = 2.4462e-01, time/batch = 15.9702s	
10664/22300 (epoch 23.910), train_loss = 0.49939934, grad/param norm = 2.6576e-01, time/batch = 15.1063s	
10665/22300 (epoch 23.913), train_loss = 0.67566377, grad/param norm = 2.8849e-01, time/batch = 16.2135s	
10666/22300 (epoch 23.915), train_loss = 0.77350482, grad/param norm = 3.1603e-01, time/batch = 15.8114s	
10667/22300 (epoch 23.917), train_loss = 0.63628873, grad/param norm = 2.7977e-01, time/batch = 17.0602s	
10668/22300 (epoch 23.919), train_loss = 0.64727902, grad/param norm = 2.4481e-01, time/batch = 16.4537s	
10669/22300 (epoch 23.922), train_loss = 0.57513341, grad/param norm = 2.5762e-01, time/batch = 17.2754s	
10670/22300 (epoch 23.924), train_loss = 0.39971834, grad/param norm = 2.3852e-01, time/batch = 15.6575s	
10671/22300 (epoch 23.926), train_loss = 0.48735232, grad/param norm = 2.1585e-01, time/batch = 17.9632s	
10672/22300 (epoch 23.928), train_loss = 0.57595988, grad/param norm = 2.9776e-01, time/batch = 31.6158s	
10673/22300 (epoch 23.930), train_loss = 0.53957405, grad/param norm = 2.4595e-01, time/batch = 15.4995s	
10674/22300 (epoch 23.933), train_loss = 0.63655047, grad/param norm = 2.8475e-01, time/batch = 16.4442s	
10675/22300 (epoch 23.935), train_loss = 0.63260794, grad/param norm = 2.9665e-01, time/batch = 15.1948s	
10676/22300 (epoch 23.937), train_loss = 0.76551717, grad/param norm = 3.4364e-01, time/batch = 17.8960s	
10677/22300 (epoch 23.939), train_loss = 0.71134558, grad/param norm = 3.3270e-01, time/batch = 15.0472s	
10678/22300 (epoch 23.942), train_loss = 0.83379983, grad/param norm = 3.6835e-01, time/batch = 16.1333s	
10679/22300 (epoch 23.944), train_loss = 0.91584290, grad/param norm = 3.9616e-01, time/batch = 16.6226s	
10680/22300 (epoch 23.946), train_loss = 0.64347735, grad/param norm = 3.1240e-01, time/batch = 17.6397s	
10681/22300 (epoch 23.948), train_loss = 0.53829566, grad/param norm = 2.6756e-01, time/batch = 16.1211s	
10682/22300 (epoch 23.951), train_loss = 0.46869465, grad/param norm = 2.2819e-01, time/batch = 15.8764s	
10683/22300 (epoch 23.953), train_loss = 0.52940343, grad/param norm = 2.6431e-01, time/batch = 17.5520s	
10684/22300 (epoch 23.955), train_loss = 0.75287798, grad/param norm = 3.0178e-01, time/batch = 17.6503s	
10685/22300 (epoch 23.957), train_loss = 0.82997906, grad/param norm = 2.8170e-01, time/batch = 16.5303s	
10686/22300 (epoch 23.960), train_loss = 0.72811637, grad/param norm = 3.1856e-01, time/batch = 16.9865s	
10687/22300 (epoch 23.962), train_loss = 0.53031645, grad/param norm = 2.6611e-01, time/batch = 17.0576s	
10688/22300 (epoch 23.964), train_loss = 0.59096320, grad/param norm = 2.8365e-01, time/batch = 17.8912s	
10689/22300 (epoch 23.966), train_loss = 0.50837327, grad/param norm = 2.5255e-01, time/batch = 15.1290s	
10690/22300 (epoch 23.969), train_loss = 0.59355230, grad/param norm = 2.9501e-01, time/batch = 18.6173s	
10691/22300 (epoch 23.971), train_loss = 0.61334914, grad/param norm = 2.9610e-01, time/batch = 17.0726s	
10692/22300 (epoch 23.973), train_loss = 0.60719556, grad/param norm = 3.1831e-01, time/batch = 16.9722s	
10693/22300 (epoch 23.975), train_loss = 0.76919762, grad/param norm = 3.1136e-01, time/batch = 15.7340s	
10694/22300 (epoch 23.978), train_loss = 0.68380453, grad/param norm = 2.8559e-01, time/batch = 18.3895s	
10695/22300 (epoch 23.980), train_loss = 0.76271957, grad/param norm = 3.2455e-01, time/batch = 17.5553s	
10696/22300 (epoch 23.982), train_loss = 0.50696124, grad/param norm = 2.9848e-01, time/batch = 15.8840s	
10697/22300 (epoch 23.984), train_loss = 0.62691530, grad/param norm = 2.6892e-01, time/batch = 17.2143s	
10698/22300 (epoch 23.987), train_loss = 0.54849255, grad/param norm = 2.8454e-01, time/batch = 15.8801s	
10699/22300 (epoch 23.989), train_loss = 0.54300554, grad/param norm = 2.6866e-01, time/batch = 16.6859s	
10700/22300 (epoch 23.991), train_loss = 0.83382508, grad/param norm = 3.6095e-01, time/batch = 17.6365s	
10701/22300 (epoch 23.993), train_loss = 1.03333944, grad/param norm = 3.8943e-01, time/batch = 17.2146s	
10702/22300 (epoch 23.996), train_loss = 0.97644137, grad/param norm = 3.5340e-01, time/batch = 17.3025s	
10703/22300 (epoch 23.998), train_loss = 0.62317551, grad/param norm = 2.7699e-01, time/batch = 16.4467s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
10704/22300 (epoch 24.000), train_loss = 0.51037593, grad/param norm = 2.4964e-01, time/batch = 15.7349s	
10705/22300 (epoch 24.002), train_loss = 0.88781686, grad/param norm = 3.2496e-01, time/batch = 17.6437s	
10706/22300 (epoch 24.004), train_loss = 0.63648166, grad/param norm = 2.5766e-01, time/batch = 15.5948s	
10707/22300 (epoch 24.007), train_loss = 0.62940734, grad/param norm = 2.6915e-01, time/batch = 16.3841s	
10708/22300 (epoch 24.009), train_loss = 0.64662596, grad/param norm = 2.9671e-01, time/batch = 17.8093s	
10709/22300 (epoch 24.011), train_loss = 0.81525129, grad/param norm = 3.4124e-01, time/batch = 17.2187s	
10710/22300 (epoch 24.013), train_loss = 0.64696880, grad/param norm = 2.8023e-01, time/batch = 16.5527s	
10711/22300 (epoch 24.016), train_loss = 0.57319040, grad/param norm = 2.9749e-01, time/batch = 18.9685s	
10712/22300 (epoch 24.018), train_loss = 0.66434463, grad/param norm = 2.9804e-01, time/batch = 15.8169s	
10713/22300 (epoch 24.020), train_loss = 0.55245045, grad/param norm = 2.9590e-01, time/batch = 16.3177s	
10714/22300 (epoch 24.022), train_loss = 0.50556689, grad/param norm = 2.6244e-01, time/batch = 16.1413s	
10715/22300 (epoch 24.025), train_loss = 0.53164901, grad/param norm = 2.6247e-01, time/batch = 17.1416s	
10716/22300 (epoch 24.027), train_loss = 0.52528322, grad/param norm = 2.3757e-01, time/batch = 15.7979s	
10717/22300 (epoch 24.029), train_loss = 0.54609669, grad/param norm = 2.4632e-01, time/batch = 16.2203s	
10718/22300 (epoch 24.031), train_loss = 0.53852454, grad/param norm = 2.8152e-01, time/batch = 15.4271s	
10719/22300 (epoch 24.034), train_loss = 0.52494830, grad/param norm = 2.6015e-01, time/batch = 15.5231s	
10720/22300 (epoch 24.036), train_loss = 0.44475553, grad/param norm = 2.1531e-01, time/batch = 16.4849s	
10721/22300 (epoch 24.038), train_loss = 0.51561859, grad/param norm = 2.7340e-01, time/batch = 15.5622s	
10722/22300 (epoch 24.040), train_loss = 0.56336101, grad/param norm = 3.4677e-01, time/batch = 18.5394s	
10723/22300 (epoch 24.043), train_loss = 0.83463345, grad/param norm = 3.0798e-01, time/batch = 17.8162s	
10724/22300 (epoch 24.045), train_loss = 0.68259613, grad/param norm = 2.7796e-01, time/batch = 16.3009s	
10725/22300 (epoch 24.047), train_loss = 0.73008723, grad/param norm = 3.2202e-01, time/batch = 15.6421s	
10726/22300 (epoch 24.049), train_loss = 0.57871931, grad/param norm = 3.0858e-01, time/batch = 18.4681s	
10727/22300 (epoch 24.052), train_loss = 0.69111037, grad/param norm = 3.2370e-01, time/batch = 15.7887s	
10728/22300 (epoch 24.054), train_loss = 0.64012217, grad/param norm = 2.8542e-01, time/batch = 15.7278s	
10729/22300 (epoch 24.056), train_loss = 0.36566372, grad/param norm = 2.0494e-01, time/batch = 15.3201s	
10730/22300 (epoch 24.058), train_loss = 0.52960048, grad/param norm = 2.3985e-01, time/batch = 16.8723s	
10731/22300 (epoch 24.061), train_loss = 0.49160557, grad/param norm = 2.9085e-01, time/batch = 17.4640s	
10732/22300 (epoch 24.063), train_loss = 0.72804993, grad/param norm = 3.3775e-01, time/batch = 15.2264s	
10733/22300 (epoch 24.065), train_loss = 0.75276961, grad/param norm = 3.2046e-01, time/batch = 16.8932s	
10734/22300 (epoch 24.067), train_loss = 0.55430433, grad/param norm = 2.8784e-01, time/batch = 17.1337s	
10735/22300 (epoch 24.070), train_loss = 0.59158454, grad/param norm = 2.7629e-01, time/batch = 15.9341s	
10736/22300 (epoch 24.072), train_loss = 0.69786676, grad/param norm = 3.2658e-01, time/batch = 16.3827s	
10737/22300 (epoch 24.074), train_loss = 0.64331912, grad/param norm = 3.0929e-01, time/batch = 16.2295s	
10738/22300 (epoch 24.076), train_loss = 0.62380164, grad/param norm = 2.9738e-01, time/batch = 16.3997s	
10739/22300 (epoch 24.078), train_loss = 0.70052336, grad/param norm = 2.9447e-01, time/batch = 14.9654s	
10740/22300 (epoch 24.081), train_loss = 0.70212069, grad/param norm = 2.9269e-01, time/batch = 16.2207s	
10741/22300 (epoch 24.083), train_loss = 0.82941574, grad/param norm = 3.3531e-01, time/batch = 16.3726s	
10742/22300 (epoch 24.085), train_loss = 0.80438486, grad/param norm = 3.4250e-01, time/batch = 16.8971s	
10743/22300 (epoch 24.087), train_loss = 0.68007027, grad/param norm = 2.9086e-01, time/batch = 15.5458s	
10744/22300 (epoch 24.090), train_loss = 0.57460389, grad/param norm = 2.7426e-01, time/batch = 16.9633s	
10745/22300 (epoch 24.092), train_loss = 0.50833167, grad/param norm = 2.5620e-01, time/batch = 16.5178s	
10746/22300 (epoch 24.094), train_loss = 0.48607722, grad/param norm = 2.4714e-01, time/batch = 16.2236s	
10747/22300 (epoch 24.096), train_loss = 0.79419327, grad/param norm = 3.6223e-01, time/batch = 16.6196s	
10748/22300 (epoch 24.099), train_loss = 0.53996075, grad/param norm = 2.6134e-01, time/batch = 15.2857s	
10749/22300 (epoch 24.101), train_loss = 0.67091826, grad/param norm = 2.6646e-01, time/batch = 15.5654s	
10750/22300 (epoch 24.103), train_loss = 0.60230035, grad/param norm = 2.3897e-01, time/batch = 16.2977s	
10751/22300 (epoch 24.105), train_loss = 0.51232045, grad/param norm = 2.9055e-01, time/batch = 18.8759s	
10752/22300 (epoch 24.108), train_loss = 0.63894999, grad/param norm = 2.6349e-01, time/batch = 15.8082s	
10753/22300 (epoch 24.110), train_loss = 0.67720632, grad/param norm = 2.7907e-01, time/batch = 16.4513s	
10754/22300 (epoch 24.112), train_loss = 0.61702955, grad/param norm = 2.3709e-01, time/batch = 16.3858s	
10755/22300 (epoch 24.114), train_loss = 0.70742095, grad/param norm = 2.9250e-01, time/batch = 17.9494s	
10756/22300 (epoch 24.117), train_loss = 0.79743150, grad/param norm = 2.8223e-01, time/batch = 18.0525s	
10757/22300 (epoch 24.119), train_loss = 0.73023221, grad/param norm = 3.1328e-01, time/batch = 15.7189s	
10758/22300 (epoch 24.121), train_loss = 0.80819537, grad/param norm = 3.4203e-01, time/batch = 15.6381s	
10759/22300 (epoch 24.123), train_loss = 0.79760650, grad/param norm = 3.0421e-01, time/batch = 17.8883s	
10760/22300 (epoch 24.126), train_loss = 0.66723581, grad/param norm = 2.9025e-01, time/batch = 17.7125s	
10761/22300 (epoch 24.128), train_loss = 0.69968107, grad/param norm = 3.0712e-01, time/batch = 16.1991s	
10762/22300 (epoch 24.130), train_loss = 0.54344014, grad/param norm = 2.6216e-01, time/batch = 17.0435s	
10763/22300 (epoch 24.132), train_loss = 0.43527117, grad/param norm = 2.0718e-01, time/batch = 17.1995s	
10764/22300 (epoch 24.135), train_loss = 0.47776258, grad/param norm = 2.5319e-01, time/batch = 16.1302s	
10765/22300 (epoch 24.137), train_loss = 0.37149031, grad/param norm = 2.0450e-01, time/batch = 18.7956s	
10766/22300 (epoch 24.139), train_loss = 0.62060139, grad/param norm = 3.2194e-01, time/batch = 15.7290s	
10767/22300 (epoch 24.141), train_loss = 0.68415053, grad/param norm = 2.4690e-01, time/batch = 15.5421s	
10768/22300 (epoch 24.143), train_loss = 0.63443661, grad/param norm = 3.1356e-01, time/batch = 15.0445s	
10769/22300 (epoch 24.146), train_loss = 0.72644923, grad/param norm = 3.0388e-01, time/batch = 16.8822s	
10770/22300 (epoch 24.148), train_loss = 0.49804553, grad/param norm = 2.3554e-01, time/batch = 16.0623s	
10771/22300 (epoch 24.150), train_loss = 0.57263151, grad/param norm = 2.5641e-01, time/batch = 16.3037s	
10772/22300 (epoch 24.152), train_loss = 0.49054601, grad/param norm = 2.6580e-01, time/batch = 16.3851s	
10773/22300 (epoch 24.155), train_loss = 0.48504894, grad/param norm = 2.2593e-01, time/batch = 16.2266s	
10774/22300 (epoch 24.157), train_loss = 0.66323128, grad/param norm = 3.1972e-01, time/batch = 15.2218s	
10775/22300 (epoch 24.159), train_loss = 0.71676564, grad/param norm = 3.3764e-01, time/batch = 16.4676s	
10776/22300 (epoch 24.161), train_loss = 0.70274058, grad/param norm = 3.1251e-01, time/batch = 14.7313s	
10777/22300 (epoch 24.164), train_loss = 0.51948664, grad/param norm = 2.4623e-01, time/batch = 17.2248s	
10778/22300 (epoch 24.166), train_loss = 0.46822600, grad/param norm = 2.1554e-01, time/batch = 17.8042s	
10779/22300 (epoch 24.168), train_loss = 0.47733436, grad/param norm = 2.5160e-01, time/batch = 16.2676s	
10780/22300 (epoch 24.170), train_loss = 0.61637321, grad/param norm = 2.6375e-01, time/batch = 16.6491s	
10781/22300 (epoch 24.173), train_loss = 0.74191450, grad/param norm = 3.1149e-01, time/batch = 16.9698s	
10782/22300 (epoch 24.175), train_loss = 0.60830153, grad/param norm = 3.0486e-01, time/batch = 16.4812s	
10783/22300 (epoch 24.177), train_loss = 0.43640836, grad/param norm = 2.6712e-01, time/batch = 16.1011s	
10784/22300 (epoch 24.179), train_loss = 0.59334286, grad/param norm = 2.5549e-01, time/batch = 16.4032s	
10785/22300 (epoch 24.182), train_loss = 0.77924125, grad/param norm = 2.7962e-01, time/batch = 14.7104s	
10786/22300 (epoch 24.184), train_loss = 0.88152557, grad/param norm = 3.3244e-01, time/batch = 15.9498s	
10787/22300 (epoch 24.186), train_loss = 0.64519471, grad/param norm = 3.0850e-01, time/batch = 17.5498s	
10788/22300 (epoch 24.188), train_loss = 0.86326929, grad/param norm = 3.4279e-01, time/batch = 15.3258s	
10789/22300 (epoch 24.191), train_loss = 0.75804025, grad/param norm = 3.1716e-01, time/batch = 17.0373s	
10790/22300 (epoch 24.193), train_loss = 0.63320475, grad/param norm = 2.6248e-01, time/batch = 15.9604s	
10791/22300 (epoch 24.195), train_loss = 0.57741129, grad/param norm = 2.8134e-01, time/batch = 15.2316s	
10792/22300 (epoch 24.197), train_loss = 0.57107263, grad/param norm = 3.0944e-01, time/batch = 16.3906s	
10793/22300 (epoch 24.200), train_loss = 0.48623976, grad/param norm = 2.3024e-01, time/batch = 15.5362s	
10794/22300 (epoch 24.202), train_loss = 0.54332995, grad/param norm = 2.7282e-01, time/batch = 14.9775s	
10795/22300 (epoch 24.204), train_loss = 0.58680158, grad/param norm = 2.5166e-01, time/batch = 14.3269s	
10796/22300 (epoch 24.206), train_loss = 0.51994364, grad/param norm = 2.5190e-01, time/batch = 15.3942s	
10797/22300 (epoch 24.209), train_loss = 0.57263377, grad/param norm = 2.5466e-01, time/batch = 17.6906s	
10798/22300 (epoch 24.211), train_loss = 0.46043935, grad/param norm = 2.8022e-01, time/batch = 17.1249s	
10799/22300 (epoch 24.213), train_loss = 0.60033037, grad/param norm = 2.6601e-01, time/batch = 17.0345s	
10800/22300 (epoch 24.215), train_loss = 0.75157501, grad/param norm = 2.8783e-01, time/batch = 17.1402s	
10801/22300 (epoch 24.217), train_loss = 0.74498786, grad/param norm = 2.9960e-01, time/batch = 16.6304s	
10802/22300 (epoch 24.220), train_loss = 0.56435076, grad/param norm = 2.8703e-01, time/batch = 16.3087s	
10803/22300 (epoch 24.222), train_loss = 0.52964949, grad/param norm = 2.5984e-01, time/batch = 18.0435s	
10804/22300 (epoch 24.224), train_loss = 0.54069068, grad/param norm = 2.5499e-01, time/batch = 16.2323s	
10805/22300 (epoch 24.226), train_loss = 0.57651583, grad/param norm = 2.4632e-01, time/batch = 15.3930s	
10806/22300 (epoch 24.229), train_loss = 0.50436621, grad/param norm = 2.7855e-01, time/batch = 16.7873s	
10807/22300 (epoch 24.231), train_loss = 0.69705150, grad/param norm = 3.4726e-01, time/batch = 15.3874s	
10808/22300 (epoch 24.233), train_loss = 0.62897146, grad/param norm = 3.0767e-01, time/batch = 15.2080s	
10809/22300 (epoch 24.235), train_loss = 0.48382857, grad/param norm = 2.6218e-01, time/batch = 16.7217s	
10810/22300 (epoch 24.238), train_loss = 0.47615350, grad/param norm = 2.3758e-01, time/batch = 18.5491s	
10811/22300 (epoch 24.240), train_loss = 0.47668643, grad/param norm = 2.1283e-01, time/batch = 16.8962s	
10812/22300 (epoch 24.242), train_loss = 0.49392369, grad/param norm = 2.3365e-01, time/batch = 16.5589s	
10813/22300 (epoch 24.244), train_loss = 0.34317229, grad/param norm = 1.8809e-01, time/batch = 15.6278s	
10814/22300 (epoch 24.247), train_loss = 0.47305208, grad/param norm = 2.3613e-01, time/batch = 17.2283s	
10815/22300 (epoch 24.249), train_loss = 0.34455206, grad/param norm = 2.0027e-01, time/batch = 14.9304s	
10816/22300 (epoch 24.251), train_loss = 0.45720660, grad/param norm = 2.2029e-01, time/batch = 14.8231s	
10817/22300 (epoch 24.253), train_loss = 0.36021039, grad/param norm = 2.6168e-01, time/batch = 17.0504s	
10818/22300 (epoch 24.256), train_loss = 0.41493404, grad/param norm = 2.1794e-01, time/batch = 16.9897s	
10819/22300 (epoch 24.258), train_loss = 0.66108101, grad/param norm = 2.7008e-01, time/batch = 16.1472s	
10820/22300 (epoch 24.260), train_loss = 0.58461913, grad/param norm = 2.8054e-01, time/batch = 16.1350s	
10821/22300 (epoch 24.262), train_loss = 0.46250007, grad/param norm = 2.3941e-01, time/batch = 18.8755s	
10822/22300 (epoch 24.265), train_loss = 0.44063007, grad/param norm = 2.6513e-01, time/batch = 17.6238s	
10823/22300 (epoch 24.267), train_loss = 0.49714483, grad/param norm = 2.3568e-01, time/batch = 15.2391s	
10824/22300 (epoch 24.269), train_loss = 0.58613477, grad/param norm = 2.7716e-01, time/batch = 17.9555s	
10825/22300 (epoch 24.271), train_loss = 0.61135405, grad/param norm = 2.5376e-01, time/batch = 15.6479s	
10826/22300 (epoch 24.274), train_loss = 0.45193327, grad/param norm = 2.5042e-01, time/batch = 16.5509s	
10827/22300 (epoch 24.276), train_loss = 0.40168165, grad/param norm = 2.3341e-01, time/batch = 15.8692s	
10828/22300 (epoch 24.278), train_loss = 0.38043192, grad/param norm = 2.0250e-01, time/batch = 15.3818s	
10829/22300 (epoch 24.280), train_loss = 0.46751848, grad/param norm = 2.4085e-01, time/batch = 16.2075s	
10830/22300 (epoch 24.283), train_loss = 0.36921480, grad/param norm = 2.0378e-01, time/batch = 15.3568s	
10831/22300 (epoch 24.285), train_loss = 0.45310821, grad/param norm = 2.5859e-01, time/batch = 18.2066s	
10832/22300 (epoch 24.287), train_loss = 0.58354962, grad/param norm = 2.4580e-01, time/batch = 18.7002s	
10833/22300 (epoch 24.289), train_loss = 0.51905989, grad/param norm = 2.3359e-01, time/batch = 15.2753s	
10834/22300 (epoch 24.291), train_loss = 0.53381064, grad/param norm = 2.6174e-01, time/batch = 16.5325s	
10835/22300 (epoch 24.294), train_loss = 0.41635436, grad/param norm = 1.9459e-01, time/batch = 15.9074s	
10836/22300 (epoch 24.296), train_loss = 0.54743397, grad/param norm = 3.0964e-01, time/batch = 18.1373s	
10837/22300 (epoch 24.298), train_loss = 0.65842323, grad/param norm = 2.9610e-01, time/batch = 15.9664s	
10838/22300 (epoch 24.300), train_loss = 0.73239156, grad/param norm = 2.7349e-01, time/batch = 16.7327s	
10839/22300 (epoch 24.303), train_loss = 0.54270535, grad/param norm = 2.3329e-01, time/batch = 15.4785s	
10840/22300 (epoch 24.305), train_loss = 0.54177430, grad/param norm = 3.2404e-01, time/batch = 16.6455s	
10841/22300 (epoch 24.307), train_loss = 0.50399280, grad/param norm = 2.8541e-01, time/batch = 15.9036s	
10842/22300 (epoch 24.309), train_loss = 0.47765556, grad/param norm = 2.3694e-01, time/batch = 17.2294s	
10843/22300 (epoch 24.312), train_loss = 0.41931854, grad/param norm = 2.0693e-01, time/batch = 16.6996s	
10844/22300 (epoch 24.314), train_loss = 0.48193726, grad/param norm = 2.7369e-01, time/batch = 15.1385s	
10845/22300 (epoch 24.316), train_loss = 0.48728751, grad/param norm = 2.5162e-01, time/batch = 16.8866s	
10846/22300 (epoch 24.318), train_loss = 0.53977619, grad/param norm = 2.5855e-01, time/batch = 14.9457s	
10847/22300 (epoch 24.321), train_loss = 0.65059479, grad/param norm = 2.8758e-01, time/batch = 18.1203s	
10848/22300 (epoch 24.323), train_loss = 0.46717053, grad/param norm = 2.2561e-01, time/batch = 15.8672s	
10849/22300 (epoch 24.325), train_loss = 0.44128657, grad/param norm = 2.6345e-01, time/batch = 18.3735s	
10850/22300 (epoch 24.327), train_loss = 0.43173842, grad/param norm = 2.0684e-01, time/batch = 15.2158s	
10851/22300 (epoch 24.330), train_loss = 0.46238751, grad/param norm = 3.1049e-01, time/batch = 17.3060s	
10852/22300 (epoch 24.332), train_loss = 0.44979197, grad/param norm = 2.5673e-01, time/batch = 16.7156s	
10853/22300 (epoch 24.334), train_loss = 0.48974996, grad/param norm = 2.7005e-01, time/batch = 17.9053s	
10854/22300 (epoch 24.336), train_loss = 0.48442963, grad/param norm = 2.3022e-01, time/batch = 16.3116s	
10855/22300 (epoch 24.339), train_loss = 0.55769013, grad/param norm = 2.8162e-01, time/batch = 16.2153s	
10856/22300 (epoch 24.341), train_loss = 0.59074932, grad/param norm = 2.5941e-01, time/batch = 18.3548s	
10857/22300 (epoch 24.343), train_loss = 0.66437073, grad/param norm = 3.1421e-01, time/batch = 18.7869s	
10858/22300 (epoch 24.345), train_loss = 0.51225439, grad/param norm = 2.4547e-01, time/batch = 16.7169s	
10859/22300 (epoch 24.348), train_loss = 0.50158447, grad/param norm = 2.5322e-01, time/batch = 15.5717s	
10860/22300 (epoch 24.350), train_loss = 0.42573129, grad/param norm = 2.2058e-01, time/batch = 17.6236s	
10861/22300 (epoch 24.352), train_loss = 0.57397356, grad/param norm = 2.8350e-01, time/batch = 16.7791s	
10862/22300 (epoch 24.354), train_loss = 0.79904028, grad/param norm = 3.4281e-01, time/batch = 16.3776s	
10863/22300 (epoch 24.357), train_loss = 0.64322367, grad/param norm = 2.4729e-01, time/batch = 18.1228s	
10864/22300 (epoch 24.359), train_loss = 0.45762131, grad/param norm = 2.9587e-01, time/batch = 16.3685s	
10865/22300 (epoch 24.361), train_loss = 0.48967093, grad/param norm = 2.7918e-01, time/batch = 16.0480s	
10866/22300 (epoch 24.363), train_loss = 0.63905742, grad/param norm = 2.8244e-01, time/batch = 15.9747s	
10867/22300 (epoch 24.365), train_loss = 0.54610397, grad/param norm = 2.6996e-01, time/batch = 17.8099s	
10868/22300 (epoch 24.368), train_loss = 0.55377858, grad/param norm = 3.1392e-01, time/batch = 16.4698s	
10869/22300 (epoch 24.370), train_loss = 0.52005043, grad/param norm = 2.4579e-01, time/batch = 16.3890s	
10870/22300 (epoch 24.372), train_loss = 0.41538323, grad/param norm = 2.3218e-01, time/batch = 18.5310s	
10871/22300 (epoch 24.374), train_loss = 0.39703905, grad/param norm = 2.3330e-01, time/batch = 16.9077s	
10872/22300 (epoch 24.377), train_loss = 0.49557106, grad/param norm = 2.8583e-01, time/batch = 16.4739s	
10873/22300 (epoch 24.379), train_loss = 0.48738878, grad/param norm = 2.7847e-01, time/batch = 15.4718s	
10874/22300 (epoch 24.381), train_loss = 0.62602449, grad/param norm = 2.7756e-01, time/batch = 17.2994s	
10875/22300 (epoch 24.383), train_loss = 0.52741541, grad/param norm = 2.5228e-01, time/batch = 16.4599s	
10876/22300 (epoch 24.386), train_loss = 0.52510722, grad/param norm = 3.0688e-01, time/batch = 17.0435s	
10877/22300 (epoch 24.388), train_loss = 0.45833111, grad/param norm = 2.6621e-01, time/batch = 16.5321s	
10878/22300 (epoch 24.390), train_loss = 0.54001800, grad/param norm = 3.1910e-01, time/batch = 17.1425s	
10879/22300 (epoch 24.392), train_loss = 0.54170638, grad/param norm = 3.0120e-01, time/batch = 15.7345s	
10880/22300 (epoch 24.395), train_loss = 0.44238032, grad/param norm = 2.4357e-01, time/batch = 16.4689s	
10881/22300 (epoch 24.397), train_loss = 0.28359324, grad/param norm = 1.7138e-01, time/batch = 15.6441s	
10882/22300 (epoch 24.399), train_loss = 0.43868948, grad/param norm = 2.3917e-01, time/batch = 16.8884s	
10883/22300 (epoch 24.401), train_loss = 0.51142019, grad/param norm = 3.0108e-01, time/batch = 17.1979s	
10884/22300 (epoch 24.404), train_loss = 0.48626731, grad/param norm = 2.6610e-01, time/batch = 16.2150s	
10885/22300 (epoch 24.406), train_loss = 0.75623166, grad/param norm = 3.4669e-01, time/batch = 17.8089s	
10886/22300 (epoch 24.408), train_loss = 0.61444754, grad/param norm = 2.9998e-01, time/batch = 15.7376s	
10887/22300 (epoch 24.410), train_loss = 0.64882897, grad/param norm = 2.9616e-01, time/batch = 25.2650s	
10888/22300 (epoch 24.413), train_loss = 0.49300950, grad/param norm = 2.8653e-01, time/batch = 22.0823s	
10889/22300 (epoch 24.415), train_loss = 0.39006627, grad/param norm = 2.7659e-01, time/batch = 16.9726s	
10890/22300 (epoch 24.417), train_loss = 0.58443939, grad/param norm = 3.1410e-01, time/batch = 15.3551s	
10891/22300 (epoch 24.419), train_loss = 0.48728252, grad/param norm = 2.3285e-01, time/batch = 17.9719s	
10892/22300 (epoch 24.422), train_loss = 0.46290946, grad/param norm = 2.5571e-01, time/batch = 15.5542s	
10893/22300 (epoch 24.424), train_loss = 0.54172265, grad/param norm = 2.5108e-01, time/batch = 15.6022s	
10894/22300 (epoch 24.426), train_loss = 0.39885160, grad/param norm = 2.4781e-01, time/batch = 15.5729s	
10895/22300 (epoch 24.428), train_loss = 0.45081002, grad/param norm = 2.5755e-01, time/batch = 17.3851s	
10896/22300 (epoch 24.430), train_loss = 0.53114812, grad/param norm = 2.9405e-01, time/batch = 16.0460s	
10897/22300 (epoch 24.433), train_loss = 0.50509072, grad/param norm = 2.3258e-01, time/batch = 16.3733s	
10898/22300 (epoch 24.435), train_loss = 0.49418445, grad/param norm = 2.6016e-01, time/batch = 16.8965s	
10899/22300 (epoch 24.437), train_loss = 0.55513209, grad/param norm = 3.0257e-01, time/batch = 16.1288s	
10900/22300 (epoch 24.439), train_loss = 0.59317225, grad/param norm = 2.7373e-01, time/batch = 17.1280s	
10901/22300 (epoch 24.442), train_loss = 0.54711393, grad/param norm = 2.5620e-01, time/batch = 15.7249s	
10902/22300 (epoch 24.444), train_loss = 0.46393885, grad/param norm = 2.1385e-01, time/batch = 17.5595s	
10903/22300 (epoch 24.446), train_loss = 0.45503919, grad/param norm = 3.0467e-01, time/batch = 16.8010s	
10904/22300 (epoch 24.448), train_loss = 0.32657387, grad/param norm = 1.6694e-01, time/batch = 16.2866s	
10905/22300 (epoch 24.451), train_loss = 0.59193931, grad/param norm = 2.9591e-01, time/batch = 15.8686s	
10906/22300 (epoch 24.453), train_loss = 0.47966994, grad/param norm = 2.4651e-01, time/batch = 17.8796s	
10907/22300 (epoch 24.455), train_loss = 0.63367545, grad/param norm = 2.7190e-01, time/batch = 15.9470s	
10908/22300 (epoch 24.457), train_loss = 0.69894101, grad/param norm = 3.3735e-01, time/batch = 15.7173s	
10909/22300 (epoch 24.460), train_loss = 0.62160898, grad/param norm = 3.0771e-01, time/batch = 14.8356s	
10910/22300 (epoch 24.462), train_loss = 0.66141331, grad/param norm = 2.9614e-01, time/batch = 17.2746s	
10911/22300 (epoch 24.464), train_loss = 0.60403267, grad/param norm = 3.2780e-01, time/batch = 16.5350s	
10912/22300 (epoch 24.466), train_loss = 0.48914387, grad/param norm = 2.4263e-01, time/batch = 15.5507s	
10913/22300 (epoch 24.469), train_loss = 0.47868197, grad/param norm = 2.3204e-01, time/batch = 16.4791s	
10914/22300 (epoch 24.471), train_loss = 0.61202981, grad/param norm = 2.4208e-01, time/batch = 16.2076s	
10915/22300 (epoch 24.473), train_loss = 0.59229341, grad/param norm = 2.7977e-01, time/batch = 15.5286s	
10916/22300 (epoch 24.475), train_loss = 0.47774366, grad/param norm = 2.7919e-01, time/batch = 18.3708s	
10917/22300 (epoch 24.478), train_loss = 0.50405582, grad/param norm = 2.7858e-01, time/batch = 14.9127s	
10918/22300 (epoch 24.480), train_loss = 0.35858157, grad/param norm = 1.9615e-01, time/batch = 18.7831s	
10919/22300 (epoch 24.482), train_loss = 0.39392395, grad/param norm = 2.3060e-01, time/batch = 15.7171s	
10920/22300 (epoch 24.484), train_loss = 0.51179045, grad/param norm = 2.5532e-01, time/batch = 19.5368s	
10921/22300 (epoch 24.487), train_loss = 0.61419632, grad/param norm = 2.9497e-01, time/batch = 17.2163s	
10922/22300 (epoch 24.489), train_loss = 0.59631745, grad/param norm = 2.5998e-01, time/batch = 15.0251s	
10923/22300 (epoch 24.491), train_loss = 0.61854251, grad/param norm = 3.2176e-01, time/batch = 15.2378s	
10924/22300 (epoch 24.493), train_loss = 0.56121941, grad/param norm = 3.3833e-01, time/batch = 15.4017s	
10925/22300 (epoch 24.496), train_loss = 0.50695669, grad/param norm = 2.1480e-01, time/batch = 14.7959s	
10926/22300 (epoch 24.498), train_loss = 0.39157376, grad/param norm = 2.1190e-01, time/batch = 15.8782s	
10927/22300 (epoch 24.500), train_loss = 0.55988908, grad/param norm = 2.9032e-01, time/batch = 16.3118s	
10928/22300 (epoch 24.502), train_loss = 0.36765915, grad/param norm = 2.8015e-01, time/batch = 18.2998s	
10929/22300 (epoch 24.504), train_loss = 0.37866116, grad/param norm = 1.9503e-01, time/batch = 14.9527s	
10930/22300 (epoch 24.507), train_loss = 0.46348896, grad/param norm = 2.8529e-01, time/batch = 14.8171s	
10931/22300 (epoch 24.509), train_loss = 0.58217494, grad/param norm = 2.9146e-01, time/batch = 16.4565s	
10932/22300 (epoch 24.511), train_loss = 0.35247095, grad/param norm = 2.3009e-01, time/batch = 17.7922s	
10933/22300 (epoch 24.513), train_loss = 0.37249315, grad/param norm = 2.1816e-01, time/batch = 15.5459s	
10934/22300 (epoch 24.516), train_loss = 0.45837089, grad/param norm = 2.7230e-01, time/batch = 15.2124s	
10935/22300 (epoch 24.518), train_loss = 0.60925645, grad/param norm = 3.0584e-01, time/batch = 16.5742s	
10936/22300 (epoch 24.520), train_loss = 0.48263666, grad/param norm = 2.9432e-01, time/batch = 18.2078s	
10937/22300 (epoch 24.522), train_loss = 0.48946098, grad/param norm = 2.5905e-01, time/batch = 15.8773s	
10938/22300 (epoch 24.525), train_loss = 0.43068116, grad/param norm = 2.3872e-01, time/batch = 17.3730s	
10939/22300 (epoch 24.527), train_loss = 0.64393695, grad/param norm = 3.3440e-01, time/batch = 17.1438s	
10940/22300 (epoch 24.529), train_loss = 0.50687968, grad/param norm = 2.7389e-01, time/batch = 17.8791s	
10941/22300 (epoch 24.531), train_loss = 0.48411122, grad/param norm = 2.6594e-01, time/batch = 15.2193s	
10942/22300 (epoch 24.534), train_loss = 0.46184206, grad/param norm = 2.3497e-01, time/batch = 18.7803s	
10943/22300 (epoch 24.536), train_loss = 0.68314254, grad/param norm = 2.5696e-01, time/batch = 17.5487s	
10944/22300 (epoch 24.538), train_loss = 0.87366906, grad/param norm = 3.8054e-01, time/batch = 15.0519s	
10945/22300 (epoch 24.540), train_loss = 0.53798221, grad/param norm = 2.6204e-01, time/batch = 15.9590s	
10946/22300 (epoch 24.543), train_loss = 0.47538643, grad/param norm = 2.3838e-01, time/batch = 16.3723s	
10947/22300 (epoch 24.545), train_loss = 0.39728316, grad/param norm = 2.5963e-01, time/batch = 18.8772s	
10948/22300 (epoch 24.547), train_loss = 0.37412567, grad/param norm = 2.1718e-01, time/batch = 15.4665s	
10949/22300 (epoch 24.549), train_loss = 0.41332350, grad/param norm = 2.3788e-01, time/batch = 16.5705s	
10950/22300 (epoch 24.552), train_loss = 0.42786083, grad/param norm = 2.1646e-01, time/batch = 17.1326s	
10951/22300 (epoch 24.554), train_loss = 0.54166722, grad/param norm = 2.9183e-01, time/batch = 16.0375s	
10952/22300 (epoch 24.556), train_loss = 0.72659789, grad/param norm = 3.1423e-01, time/batch = 16.2281s	
10953/22300 (epoch 24.558), train_loss = 0.58956222, grad/param norm = 2.8247e-01, time/batch = 16.8974s	
10954/22300 (epoch 24.561), train_loss = 0.75249962, grad/param norm = 3.5340e-01, time/batch = 15.2127s	
10955/22300 (epoch 24.563), train_loss = 0.69665653, grad/param norm = 3.6315e-01, time/batch = 16.0500s	
10956/22300 (epoch 24.565), train_loss = 0.51191410, grad/param norm = 3.0940e-01, time/batch = 15.2933s	
10957/22300 (epoch 24.567), train_loss = 0.50910283, grad/param norm = 2.5210e-01, time/batch = 16.5576s	
10958/22300 (epoch 24.570), train_loss = 0.70583293, grad/param norm = 3.2649e-01, time/batch = 16.7071s	
10959/22300 (epoch 24.572), train_loss = 0.66408852, grad/param norm = 2.9868e-01, time/batch = 15.9561s	
10960/22300 (epoch 24.574), train_loss = 0.52683331, grad/param norm = 2.5945e-01, time/batch = 17.2123s	
10961/22300 (epoch 24.576), train_loss = 0.46488180, grad/param norm = 2.6023e-01, time/batch = 16.7226s	
10962/22300 (epoch 24.578), train_loss = 0.29241482, grad/param norm = 1.9169e-01, time/batch = 17.2139s	
10963/22300 (epoch 24.581), train_loss = 0.38600126, grad/param norm = 2.1696e-01, time/batch = 16.8851s	
10964/22300 (epoch 24.583), train_loss = 0.44316490, grad/param norm = 2.3559e-01, time/batch = 15.9018s	
10965/22300 (epoch 24.585), train_loss = 0.63336810, grad/param norm = 2.7917e-01, time/batch = 18.0469s	
10966/22300 (epoch 24.587), train_loss = 0.80302316, grad/param norm = 3.3075e-01, time/batch = 15.9566s	
10967/22300 (epoch 24.590), train_loss = 0.70184612, grad/param norm = 3.0641e-01, time/batch = 17.9517s	
10968/22300 (epoch 24.592), train_loss = 0.79185991, grad/param norm = 3.2068e-01, time/batch = 16.8886s	
10969/22300 (epoch 24.594), train_loss = 0.79637118, grad/param norm = 3.5029e-01, time/batch = 16.6843s	
10970/22300 (epoch 24.596), train_loss = 0.51266127, grad/param norm = 2.7617e-01, time/batch = 15.7078s	
10971/22300 (epoch 24.599), train_loss = 0.40083113, grad/param norm = 2.9001e-01, time/batch = 16.7015s	
10972/22300 (epoch 24.601), train_loss = 0.46739080, grad/param norm = 2.7071e-01, time/batch = 17.4630s	
10973/22300 (epoch 24.603), train_loss = 0.55029582, grad/param norm = 2.8808e-01, time/batch = 15.4699s	
10974/22300 (epoch 24.605), train_loss = 0.48961395, grad/param norm = 2.6314e-01, time/batch = 15.2100s	
10975/22300 (epoch 24.608), train_loss = 0.81329156, grad/param norm = 3.8020e-01, time/batch = 18.3784s	
10976/22300 (epoch 24.610), train_loss = 0.79985804, grad/param norm = 3.3151e-01, time/batch = 15.9594s	
10977/22300 (epoch 24.612), train_loss = 0.62975760, grad/param norm = 3.0249e-01, time/batch = 15.8759s	
10978/22300 (epoch 24.614), train_loss = 0.66494637, grad/param norm = 2.9658e-01, time/batch = 16.4014s	
10979/22300 (epoch 24.617), train_loss = 0.60299849, grad/param norm = 2.5707e-01, time/batch = 15.5502s	
10980/22300 (epoch 24.619), train_loss = 0.77065410, grad/param norm = 3.3673e-01, time/batch = 17.0439s	
10981/22300 (epoch 24.621), train_loss = 0.51302844, grad/param norm = 2.6921e-01, time/batch = 18.3539s	
10982/22300 (epoch 24.623), train_loss = 0.50909192, grad/param norm = 2.6389e-01, time/batch = 16.3729s	
10983/22300 (epoch 24.626), train_loss = 0.45399278, grad/param norm = 2.3438e-01, time/batch = 17.9678s	
10984/22300 (epoch 24.628), train_loss = 0.46333078, grad/param norm = 2.2945e-01, time/batch = 15.8758s	
10985/22300 (epoch 24.630), train_loss = 0.52977616, grad/param norm = 2.5954e-01, time/batch = 17.9556s	
10986/22300 (epoch 24.632), train_loss = 0.48653158, grad/param norm = 2.5148e-01, time/batch = 16.6152s	
10987/22300 (epoch 24.635), train_loss = 0.53397568, grad/param norm = 2.7942e-01, time/batch = 16.4547s	
10988/22300 (epoch 24.637), train_loss = 0.62386042, grad/param norm = 2.9466e-01, time/batch = 15.8142s	
10989/22300 (epoch 24.639), train_loss = 0.72920653, grad/param norm = 3.2907e-01, time/batch = 15.0590s	
10990/22300 (epoch 24.641), train_loss = 0.57188335, grad/param norm = 2.6395e-01, time/batch = 18.1284s	
10991/22300 (epoch 24.643), train_loss = 0.48135570, grad/param norm = 2.8235e-01, time/batch = 15.1310s	
10992/22300 (epoch 24.646), train_loss = 0.47991431, grad/param norm = 3.2270e-01, time/batch = 17.3924s	
10993/22300 (epoch 24.648), train_loss = 0.52531276, grad/param norm = 2.2737e-01, time/batch = 17.0524s	
10994/22300 (epoch 24.650), train_loss = 0.60017459, grad/param norm = 2.8891e-01, time/batch = 16.7119s	
10995/22300 (epoch 24.652), train_loss = 0.47453733, grad/param norm = 2.2070e-01, time/batch = 16.5368s	
10996/22300 (epoch 24.655), train_loss = 0.46645853, grad/param norm = 2.6720e-01, time/batch = 16.8741s	
10997/22300 (epoch 24.657), train_loss = 0.51626722, grad/param norm = 2.5772e-01, time/batch = 15.1540s	
10998/22300 (epoch 24.659), train_loss = 0.46856997, grad/param norm = 2.6908e-01, time/batch = 15.9793s	
10999/22300 (epoch 24.661), train_loss = 0.39265428, grad/param norm = 2.2436e-01, time/batch = 15.2754s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch24.66_1.5989.t7	
11000/22300 (epoch 24.664), train_loss = 0.46134588, grad/param norm = 2.2806e-01, time/batch = 16.2151s	
11001/22300 (epoch 24.666), train_loss = 1.28593840, grad/param norm = 5.1959e-01, time/batch = 18.6280s	
11002/22300 (epoch 24.668), train_loss = 0.46181240, grad/param norm = 2.8775e-01, time/batch = 14.3273s	
11003/22300 (epoch 24.670), train_loss = 0.59507781, grad/param norm = 3.1185e-01, time/batch = 17.6856s	
11004/22300 (epoch 24.673), train_loss = 0.65696219, grad/param norm = 3.0935e-01, time/batch = 15.2881s	
11005/22300 (epoch 24.675), train_loss = 0.70896541, grad/param norm = 3.3381e-01, time/batch = 17.8877s	
11006/22300 (epoch 24.677), train_loss = 0.77625000, grad/param norm = 3.4665e-01, time/batch = 17.5442s	
11007/22300 (epoch 24.679), train_loss = 0.63033844, grad/param norm = 3.6685e-01, time/batch = 15.4638s	
11008/22300 (epoch 24.682), train_loss = 0.55941387, grad/param norm = 2.6860e-01, time/batch = 16.0678s	
11009/22300 (epoch 24.684), train_loss = 0.54779818, grad/param norm = 2.7430e-01, time/batch = 16.8003s	
11010/22300 (epoch 24.686), train_loss = 0.56245880, grad/param norm = 2.6415e-01, time/batch = 17.0690s	
11011/22300 (epoch 24.688), train_loss = 0.52025773, grad/param norm = 3.3309e-01, time/batch = 15.7599s	
11012/22300 (epoch 24.691), train_loss = 0.50054077, grad/param norm = 2.6943e-01, time/batch = 18.7806s	
11013/22300 (epoch 24.693), train_loss = 0.46713056, grad/param norm = 2.5346e-01, time/batch = 17.8831s	
11014/22300 (epoch 24.695), train_loss = 0.41652322, grad/param norm = 2.1784e-01, time/batch = 16.5443s	
11015/22300 (epoch 24.697), train_loss = 0.43749290, grad/param norm = 2.0613e-01, time/batch = 15.7324s	
11016/22300 (epoch 24.700), train_loss = 0.46281608, grad/param norm = 2.4701e-01, time/batch = 14.7330s	
11017/22300 (epoch 24.702), train_loss = 0.42382923, grad/param norm = 2.1899e-01, time/batch = 16.4544s	
11018/22300 (epoch 24.704), train_loss = 0.54484060, grad/param norm = 3.1340e-01, time/batch = 15.5557s	
11019/22300 (epoch 24.706), train_loss = 0.46679745, grad/param norm = 2.3839e-01, time/batch = 15.9510s	
11020/22300 (epoch 24.709), train_loss = 0.38389447, grad/param norm = 2.3360e-01, time/batch = 17.0598s	
11021/22300 (epoch 24.711), train_loss = 0.38514573, grad/param norm = 1.7986e-01, time/batch = 15.3621s	
11022/22300 (epoch 24.713), train_loss = 0.54458181, grad/param norm = 2.6192e-01, time/batch = 16.0646s	
11023/22300 (epoch 24.715), train_loss = 0.54840805, grad/param norm = 2.4467e-01, time/batch = 17.2327s	
11024/22300 (epoch 24.717), train_loss = 0.70802807, grad/param norm = 3.0694e-01, time/batch = 17.4714s	
11025/22300 (epoch 24.720), train_loss = 0.46738787, grad/param norm = 2.5338e-01, time/batch = 15.3549s	
11026/22300 (epoch 24.722), train_loss = 0.55709070, grad/param norm = 2.5050e-01, time/batch = 16.1365s	
11027/22300 (epoch 24.724), train_loss = 0.60522672, grad/param norm = 3.2015e-01, time/batch = 16.5623s	
11028/22300 (epoch 24.726), train_loss = 0.48664192, grad/param norm = 2.9188e-01, time/batch = 16.6435s	
11029/22300 (epoch 24.729), train_loss = 0.53388597, grad/param norm = 2.9586e-01, time/batch = 16.2973s	
11030/22300 (epoch 24.731), train_loss = 0.70358832, grad/param norm = 2.8470e-01, time/batch = 16.5495s	
11031/22300 (epoch 24.733), train_loss = 0.71614401, grad/param norm = 3.4770e-01, time/batch = 17.7200s	
11032/22300 (epoch 24.735), train_loss = 0.74536633, grad/param norm = 3.3694e-01, time/batch = 15.1127s	
11033/22300 (epoch 24.738), train_loss = 0.55354242, grad/param norm = 3.2028e-01, time/batch = 15.0703s	
11034/22300 (epoch 24.740), train_loss = 0.48346970, grad/param norm = 2.6343e-01, time/batch = 16.4829s	
11035/22300 (epoch 24.742), train_loss = 0.50385810, grad/param norm = 2.4154e-01, time/batch = 15.4394s	
11036/22300 (epoch 24.744), train_loss = 0.76787032, grad/param norm = 3.2843e-01, time/batch = 16.2964s	
11037/22300 (epoch 24.747), train_loss = 0.61837666, grad/param norm = 2.7846e-01, time/batch = 16.9657s	
11038/22300 (epoch 24.749), train_loss = 0.79220930, grad/param norm = 3.4826e-01, time/batch = 15.2990s	
11039/22300 (epoch 24.751), train_loss = 0.68914185, grad/param norm = 3.6947e-01, time/batch = 17.5452s	
11040/22300 (epoch 24.753), train_loss = 0.73915388, grad/param norm = 3.2935e-01, time/batch = 15.3924s	
11041/22300 (epoch 24.756), train_loss = 0.62495650, grad/param norm = 2.6201e-01, time/batch = 17.8785s	
11042/22300 (epoch 24.758), train_loss = 0.58551322, grad/param norm = 2.7298e-01, time/batch = 15.4073s	
11043/22300 (epoch 24.760), train_loss = 0.60491256, grad/param norm = 2.8695e-01, time/batch = 17.0324s	
11044/22300 (epoch 24.762), train_loss = 0.60675511, grad/param norm = 3.2612e-01, time/batch = 17.9742s	
11045/22300 (epoch 24.765), train_loss = 0.61501082, grad/param norm = 3.2401e-01, time/batch = 17.1380s	
11046/22300 (epoch 24.767), train_loss = 0.61494040, grad/param norm = 2.6931e-01, time/batch = 16.5599s	
11047/22300 (epoch 24.769), train_loss = 0.58342414, grad/param norm = 3.1160e-01, time/batch = 15.3891s	
11048/22300 (epoch 24.771), train_loss = 0.67276244, grad/param norm = 3.2299e-01, time/batch = 15.5488s	
11049/22300 (epoch 24.774), train_loss = 0.70731805, grad/param norm = 3.6143e-01, time/batch = 17.3862s	
11050/22300 (epoch 24.776), train_loss = 0.71399015, grad/param norm = 2.7264e-01, time/batch = 16.3638s	
11051/22300 (epoch 24.778), train_loss = 0.69697035, grad/param norm = 2.9476e-01, time/batch = 15.9713s	
11052/22300 (epoch 24.780), train_loss = 0.70527514, grad/param norm = 3.2935e-01, time/batch = 17.2942s	
11053/22300 (epoch 24.783), train_loss = 0.75147442, grad/param norm = 3.5233e-01, time/batch = 17.2096s	
11054/22300 (epoch 24.785), train_loss = 0.55995508, grad/param norm = 2.6166e-01, time/batch = 16.2051s	
11055/22300 (epoch 24.787), train_loss = 0.51679669, grad/param norm = 2.4260e-01, time/batch = 15.3222s	
11056/22300 (epoch 24.789), train_loss = 0.73485279, grad/param norm = 3.6000e-01, time/batch = 15.4000s	
11057/22300 (epoch 24.791), train_loss = 0.91738350, grad/param norm = 3.7475e-01, time/batch = 15.2041s	
11058/22300 (epoch 24.794), train_loss = 0.74050691, grad/param norm = 3.4408e-01, time/batch = 15.4057s	
11059/22300 (epoch 24.796), train_loss = 0.70907204, grad/param norm = 3.3776e-01, time/batch = 16.4806s	
11060/22300 (epoch 24.798), train_loss = 0.82539499, grad/param norm = 3.2199e-01, time/batch = 15.2246s	
11061/22300 (epoch 24.800), train_loss = 0.58094821, grad/param norm = 2.5523e-01, time/batch = 18.1392s	
11062/22300 (epoch 24.803), train_loss = 0.54733543, grad/param norm = 2.4258e-01, time/batch = 16.2086s	
11063/22300 (epoch 24.805), train_loss = 0.62279124, grad/param norm = 2.7601e-01, time/batch = 19.0408s	
11064/22300 (epoch 24.807), train_loss = 0.76109764, grad/param norm = 4.0442e-01, time/batch = 15.0626s	
11065/22300 (epoch 24.809), train_loss = 0.56053457, grad/param norm = 3.2048e-01, time/batch = 16.7994s	
11066/22300 (epoch 24.812), train_loss = 0.68069505, grad/param norm = 3.0613e-01, time/batch = 16.2480s	
11067/22300 (epoch 24.814), train_loss = 0.65653054, grad/param norm = 2.7888e-01, time/batch = 18.7989s	
11068/22300 (epoch 24.816), train_loss = 0.64481597, grad/param norm = 2.6720e-01, time/batch = 18.1332s	
11069/22300 (epoch 24.818), train_loss = 0.77289209, grad/param norm = 3.0871e-01, time/batch = 15.3787s	
11070/22300 (epoch 24.821), train_loss = 0.63945981, grad/param norm = 3.3060e-01, time/batch = 18.4565s	
11071/22300 (epoch 24.823), train_loss = 0.44523264, grad/param norm = 2.3024e-01, time/batch = 17.0485s	
11072/22300 (epoch 24.825), train_loss = 0.48478891, grad/param norm = 2.6675e-01, time/batch = 16.5253s	
11073/22300 (epoch 24.827), train_loss = 0.57550458, grad/param norm = 2.8401e-01, time/batch = 17.4657s	
11074/22300 (epoch 24.830), train_loss = 0.54139990, grad/param norm = 2.9938e-01, time/batch = 16.3181s	
11075/22300 (epoch 24.832), train_loss = 0.51397086, grad/param norm = 2.9021e-01, time/batch = 16.1153s	
11076/22300 (epoch 24.834), train_loss = 0.48378995, grad/param norm = 2.7504e-01, time/batch = 15.2921s	
11077/22300 (epoch 24.836), train_loss = 0.58316534, grad/param norm = 2.9820e-01, time/batch = 18.8002s	
11078/22300 (epoch 24.839), train_loss = 0.52417926, grad/param norm = 2.4629e-01, time/batch = 16.3216s	
11079/22300 (epoch 24.841), train_loss = 0.58862618, grad/param norm = 3.1553e-01, time/batch = 17.2930s	
11080/22300 (epoch 24.843), train_loss = 0.55155241, grad/param norm = 2.8106e-01, time/batch = 15.8914s	
11081/22300 (epoch 24.845), train_loss = 0.53741702, grad/param norm = 2.9269e-01, time/batch = 17.0589s	
11082/22300 (epoch 24.848), train_loss = 0.54486305, grad/param norm = 3.2251e-01, time/batch = 15.6191s	
11083/22300 (epoch 24.850), train_loss = 0.54716829, grad/param norm = 2.2938e-01, time/batch = 15.5499s	
11084/22300 (epoch 24.852), train_loss = 0.52283609, grad/param norm = 3.3948e-01, time/batch = 16.1822s	
11085/22300 (epoch 24.854), train_loss = 0.77884276, grad/param norm = 3.3406e-01, time/batch = 16.0450s	
11086/22300 (epoch 24.857), train_loss = 0.63917620, grad/param norm = 3.9087e-01, time/batch = 17.6143s	
11087/22300 (epoch 24.859), train_loss = 0.48856459, grad/param norm = 2.5346e-01, time/batch = 16.7846s	
11088/22300 (epoch 24.861), train_loss = 0.65180484, grad/param norm = 3.0063e-01, time/batch = 16.6352s	
11089/22300 (epoch 24.863), train_loss = 0.49925624, grad/param norm = 2.8134e-01, time/batch = 17.4621s	
11090/22300 (epoch 24.865), train_loss = 0.44018202, grad/param norm = 2.0058e-01, time/batch = 16.7042s	
11091/22300 (epoch 24.868), train_loss = 0.58280159, grad/param norm = 2.3822e-01, time/batch = 17.6366s	
11092/22300 (epoch 24.870), train_loss = 0.60545012, grad/param norm = 2.6295e-01, time/batch = 16.8165s	
11093/22300 (epoch 24.872), train_loss = 0.67777188, grad/param norm = 3.0383e-01, time/batch = 15.8716s	
11094/22300 (epoch 24.874), train_loss = 0.61018539, grad/param norm = 2.9818e-01, time/batch = 15.4528s	
11095/22300 (epoch 24.877), train_loss = 0.58865001, grad/param norm = 2.8513e-01, time/batch = 17.8014s	
11096/22300 (epoch 24.879), train_loss = 0.50121698, grad/param norm = 2.2363e-01, time/batch = 18.9708s	
11097/22300 (epoch 24.881), train_loss = 0.47677458, grad/param norm = 2.3006e-01, time/batch = 24.4191s	
11098/22300 (epoch 24.883), train_loss = 0.48456911, grad/param norm = 2.9823e-01, time/batch = 21.2447s	
11099/22300 (epoch 24.886), train_loss = 0.46018184, grad/param norm = 2.3720e-01, time/batch = 17.8679s	
11100/22300 (epoch 24.888), train_loss = 0.51674027, grad/param norm = 2.6396e-01, time/batch = 15.7677s	
11101/22300 (epoch 24.890), train_loss = 0.49520694, grad/param norm = 2.1360e-01, time/batch = 16.2273s	
11102/22300 (epoch 24.892), train_loss = 0.73382782, grad/param norm = 2.7536e-01, time/batch = 15.4380s	
11103/22300 (epoch 24.895), train_loss = 0.69309132, grad/param norm = 2.9971e-01, time/batch = 17.7073s	
11104/22300 (epoch 24.897), train_loss = 0.56609981, grad/param norm = 2.4874e-01, time/batch = 15.5644s	
11105/22300 (epoch 24.899), train_loss = 0.56263470, grad/param norm = 2.6660e-01, time/batch = 15.7858s	
11106/22300 (epoch 24.901), train_loss = 0.60512408, grad/param norm = 2.6146e-01, time/batch = 16.3091s	
11107/22300 (epoch 24.904), train_loss = 0.63410055, grad/param norm = 2.8159e-01, time/batch = 14.9709s	
11108/22300 (epoch 24.906), train_loss = 0.62481646, grad/param norm = 2.8673e-01, time/batch = 16.1361s	
11109/22300 (epoch 24.908), train_loss = 0.55268084, grad/param norm = 2.4304e-01, time/batch = 16.2153s	
11110/22300 (epoch 24.910), train_loss = 0.46499233, grad/param norm = 2.4573e-01, time/batch = 16.5418s	
11111/22300 (epoch 24.913), train_loss = 0.63917629, grad/param norm = 2.7717e-01, time/batch = 15.9596s	
11112/22300 (epoch 24.915), train_loss = 0.72473609, grad/param norm = 2.6899e-01, time/batch = 17.7189s	
11113/22300 (epoch 24.917), train_loss = 0.62275632, grad/param norm = 2.9148e-01, time/batch = 16.6354s	
11114/22300 (epoch 24.919), train_loss = 0.64950822, grad/param norm = 2.6756e-01, time/batch = 17.3004s	
11115/22300 (epoch 24.922), train_loss = 0.57933350, grad/param norm = 3.3143e-01, time/batch = 15.5554s	
11116/22300 (epoch 24.924), train_loss = 0.37798028, grad/param norm = 2.1448e-01, time/batch = 15.8987s	
11117/22300 (epoch 24.926), train_loss = 0.45911755, grad/param norm = 2.1491e-01, time/batch = 15.7277s	
11118/22300 (epoch 24.928), train_loss = 0.53170644, grad/param norm = 2.4842e-01, time/batch = 16.1108s	
11119/22300 (epoch 24.930), train_loss = 0.53775058, grad/param norm = 2.5156e-01, time/batch = 16.7209s	
11120/22300 (epoch 24.933), train_loss = 0.61260017, grad/param norm = 2.6395e-01, time/batch = 16.7990s	
11121/22300 (epoch 24.935), train_loss = 0.59201176, grad/param norm = 2.6276e-01, time/batch = 16.3132s	
11122/22300 (epoch 24.937), train_loss = 0.73660448, grad/param norm = 3.5133e-01, time/batch = 16.1043s	
11123/22300 (epoch 24.939), train_loss = 0.67081361, grad/param norm = 3.0269e-01, time/batch = 16.0664s	
11124/22300 (epoch 24.942), train_loss = 0.78749562, grad/param norm = 3.4305e-01, time/batch = 15.1400s	
11125/22300 (epoch 24.944), train_loss = 0.89085132, grad/param norm = 3.8600e-01, time/batch = 15.5446s	
11126/22300 (epoch 24.946), train_loss = 0.60773164, grad/param norm = 2.8920e-01, time/batch = 16.5319s	
11127/22300 (epoch 24.948), train_loss = 0.50983271, grad/param norm = 2.4408e-01, time/batch = 18.7879s	
11128/22300 (epoch 24.951), train_loss = 0.44609961, grad/param norm = 2.2301e-01, time/batch = 15.3646s	
11129/22300 (epoch 24.953), train_loss = 0.50406102, grad/param norm = 2.8312e-01, time/batch = 15.9651s	
11130/22300 (epoch 24.955), train_loss = 0.76633692, grad/param norm = 3.5148e-01, time/batch = 15.2270s	
11131/22300 (epoch 24.957), train_loss = 0.82477896, grad/param norm = 3.0552e-01, time/batch = 17.5404s	
11132/22300 (epoch 24.960), train_loss = 0.73936820, grad/param norm = 3.1937e-01, time/batch = 14.4964s	
11133/22300 (epoch 24.962), train_loss = 0.50517203, grad/param norm = 2.7204e-01, time/batch = 14.9377s	
11134/22300 (epoch 24.964), train_loss = 0.54204239, grad/param norm = 2.8402e-01, time/batch = 15.8984s	
11135/22300 (epoch 24.966), train_loss = 0.50455244, grad/param norm = 3.0239e-01, time/batch = 16.9821s	
11136/22300 (epoch 24.969), train_loss = 0.55543119, grad/param norm = 2.5950e-01, time/batch = 16.3022s	
11137/22300 (epoch 24.971), train_loss = 0.57345169, grad/param norm = 2.5534e-01, time/batch = 15.7317s	
11138/22300 (epoch 24.973), train_loss = 0.57591263, grad/param norm = 2.6535e-01, time/batch = 16.7123s	
11139/22300 (epoch 24.975), train_loss = 0.77437803, grad/param norm = 3.5568e-01, time/batch = 17.1506s	
11140/22300 (epoch 24.978), train_loss = 0.68273459, grad/param norm = 3.4407e-01, time/batch = 16.3881s	
11141/22300 (epoch 24.980), train_loss = 0.74214631, grad/param norm = 3.1566e-01, time/batch = 16.4721s	
11142/22300 (epoch 24.982), train_loss = 0.47786522, grad/param norm = 2.6652e-01, time/batch = 15.7078s	
11143/22300 (epoch 24.984), train_loss = 0.59642247, grad/param norm = 2.7104e-01, time/batch = 16.7888s	
11144/22300 (epoch 24.987), train_loss = 0.55036005, grad/param norm = 3.2747e-01, time/batch = 16.0343s	
11145/22300 (epoch 24.989), train_loss = 0.53576124, grad/param norm = 3.0866e-01, time/batch = 15.7088s	
11146/22300 (epoch 24.991), train_loss = 0.81010229, grad/param norm = 3.4447e-01, time/batch = 16.2859s	
11147/22300 (epoch 24.993), train_loss = 1.00662364, grad/param norm = 3.9206e-01, time/batch = 18.6181s	
11148/22300 (epoch 24.996), train_loss = 0.92541878, grad/param norm = 3.1668e-01, time/batch = 15.9558s	
11149/22300 (epoch 24.998), train_loss = 0.61598626, grad/param norm = 3.3012e-01, time/batch = 19.3742s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
11150/22300 (epoch 25.000), train_loss = 0.48224760, grad/param norm = 2.6371e-01, time/batch = 17.1419s	
11151/22300 (epoch 25.002), train_loss = 0.85394581, grad/param norm = 2.9240e-01, time/batch = 17.2786s	
11152/22300 (epoch 25.004), train_loss = 0.61085780, grad/param norm = 2.6323e-01, time/batch = 16.5554s	
11153/22300 (epoch 25.007), train_loss = 0.62257201, grad/param norm = 3.1337e-01, time/batch = 15.7456s	
11154/22300 (epoch 25.009), train_loss = 0.65610242, grad/param norm = 3.2184e-01, time/batch = 17.9668s	
11155/22300 (epoch 25.011), train_loss = 0.79411890, grad/param norm = 3.1882e-01, time/batch = 15.8883s	
11156/22300 (epoch 25.013), train_loss = 0.62880299, grad/param norm = 2.7121e-01, time/batch = 17.5521s	
11157/22300 (epoch 25.016), train_loss = 0.53000669, grad/param norm = 2.9303e-01, time/batch = 18.3032s	
11158/22300 (epoch 25.018), train_loss = 0.65157848, grad/param norm = 3.1845e-01, time/batch = 15.6386s	
11159/22300 (epoch 25.020), train_loss = 0.53006613, grad/param norm = 2.5331e-01, time/batch = 16.9292s	
11160/22300 (epoch 25.022), train_loss = 0.48723140, grad/param norm = 2.9796e-01, time/batch = 15.1313s	
11161/22300 (epoch 25.025), train_loss = 0.51338787, grad/param norm = 2.6107e-01, time/batch = 16.2097s	
11162/22300 (epoch 25.027), train_loss = 0.50223275, grad/param norm = 2.3449e-01, time/batch = 15.4658s	
11163/22300 (epoch 25.029), train_loss = 0.51508755, grad/param norm = 2.2789e-01, time/batch = 17.8905s	
11164/22300 (epoch 25.031), train_loss = 0.52931179, grad/param norm = 2.5697e-01, time/batch = 16.8121s	
11165/22300 (epoch 25.034), train_loss = 0.52809886, grad/param norm = 2.9146e-01, time/batch = 15.2782s	
11166/22300 (epoch 25.036), train_loss = 0.44567848, grad/param norm = 2.4823e-01, time/batch = 16.7107s	
11167/22300 (epoch 25.038), train_loss = 0.50255169, grad/param norm = 2.6303e-01, time/batch = 15.8737s	
11168/22300 (epoch 25.040), train_loss = 0.55215417, grad/param norm = 2.6579e-01, time/batch = 17.4667s	
11169/22300 (epoch 25.043), train_loss = 0.82132196, grad/param norm = 3.2371e-01, time/batch = 16.1273s	
11170/22300 (epoch 25.045), train_loss = 0.65827691, grad/param norm = 2.8448e-01, time/batch = 17.7722s	
11171/22300 (epoch 25.047), train_loss = 0.70027528, grad/param norm = 3.0813e-01, time/batch = 15.6459s	
11172/22300 (epoch 25.049), train_loss = 0.56298574, grad/param norm = 2.5946e-01, time/batch = 15.7140s	
11173/22300 (epoch 25.052), train_loss = 0.66044735, grad/param norm = 3.2211e-01, time/batch = 15.2545s	
11174/22300 (epoch 25.054), train_loss = 0.61083261, grad/param norm = 2.6708e-01, time/batch = 15.8804s	
11175/22300 (epoch 25.056), train_loss = 0.34244015, grad/param norm = 1.8649e-01, time/batch = 15.1045s	
11176/22300 (epoch 25.058), train_loss = 0.53746769, grad/param norm = 2.4876e-01, time/batch = 15.1788s	
11177/22300 (epoch 25.061), train_loss = 0.48098143, grad/param norm = 2.5606e-01, time/batch = 15.3438s	
11178/22300 (epoch 25.063), train_loss = 0.72407289, grad/param norm = 3.8272e-01, time/batch = 15.2214s	
11179/22300 (epoch 25.065), train_loss = 0.73509087, grad/param norm = 3.8121e-01, time/batch = 16.7363s	
11180/22300 (epoch 25.067), train_loss = 0.53670115, grad/param norm = 3.2162e-01, time/batch = 15.6307s	
11181/22300 (epoch 25.070), train_loss = 0.55017184, grad/param norm = 2.3888e-01, time/batch = 15.4725s	
11182/22300 (epoch 25.072), train_loss = 0.67228993, grad/param norm = 3.4089e-01, time/batch = 18.5461s	
11183/22300 (epoch 25.074), train_loss = 0.62222666, grad/param norm = 3.3646e-01, time/batch = 16.2735s	
11184/22300 (epoch 25.076), train_loss = 0.62213611, grad/param norm = 3.1357e-01, time/batch = 15.0689s	
11185/22300 (epoch 25.078), train_loss = 0.71965222, grad/param norm = 3.6096e-01, time/batch = 15.5521s	
11186/22300 (epoch 25.081), train_loss = 0.69500110, grad/param norm = 3.2000e-01, time/batch = 16.6430s	
11187/22300 (epoch 25.083), train_loss = 0.81685368, grad/param norm = 3.4985e-01, time/batch = 18.0594s	
11188/22300 (epoch 25.085), train_loss = 0.81210550, grad/param norm = 3.7377e-01, time/batch = 16.5230s	
11189/22300 (epoch 25.087), train_loss = 0.66367008, grad/param norm = 2.8138e-01, time/batch = 17.9745s	
11190/22300 (epoch 25.090), train_loss = 0.54320837, grad/param norm = 2.7411e-01, time/batch = 15.8093s	
11191/22300 (epoch 25.092), train_loss = 0.48126522, grad/param norm = 2.3387e-01, time/batch = 15.1208s	
11192/22300 (epoch 25.094), train_loss = 0.46345299, grad/param norm = 2.3779e-01, time/batch = 16.8932s	
11193/22300 (epoch 25.096), train_loss = 0.77509304, grad/param norm = 3.2516e-01, time/batch = 16.0707s	
11194/22300 (epoch 25.099), train_loss = 0.52108751, grad/param norm = 2.5531e-01, time/batch = 18.9573s	
11195/22300 (epoch 25.101), train_loss = 0.68254603, grad/param norm = 3.3477e-01, time/batch = 15.6836s	
11196/22300 (epoch 25.103), train_loss = 0.58296609, grad/param norm = 2.6149e-01, time/batch = 16.4759s	
11197/22300 (epoch 25.105), train_loss = 0.49003658, grad/param norm = 2.6032e-01, time/batch = 15.7986s	
11198/22300 (epoch 25.108), train_loss = 0.61688681, grad/param norm = 2.6390e-01, time/batch = 15.3529s	
11199/22300 (epoch 25.110), train_loss = 0.66960243, grad/param norm = 2.9480e-01, time/batch = 15.6507s	
11200/22300 (epoch 25.112), train_loss = 0.59861424, grad/param norm = 2.6780e-01, time/batch = 16.6441s	
11201/22300 (epoch 25.114), train_loss = 0.69565866, grad/param norm = 3.3218e-01, time/batch = 18.9663s	
11202/22300 (epoch 25.117), train_loss = 0.78920249, grad/param norm = 3.1841e-01, time/batch = 16.1319s	
11203/22300 (epoch 25.119), train_loss = 0.69740290, grad/param norm = 3.0243e-01, time/batch = 16.4609s	
11204/22300 (epoch 25.121), train_loss = 0.80482607, grad/param norm = 3.1712e-01, time/batch = 15.4679s	
11205/22300 (epoch 25.123), train_loss = 0.77492227, grad/param norm = 3.0750e-01, time/batch = 18.7927s	
11206/22300 (epoch 25.126), train_loss = 0.62605635, grad/param norm = 2.6690e-01, time/batch = 17.0110s	
11207/22300 (epoch 25.128), train_loss = 0.68151762, grad/param norm = 3.4946e-01, time/batch = 17.1350s	
11208/22300 (epoch 25.130), train_loss = 0.52538237, grad/param norm = 2.4905e-01, time/batch = 15.2150s	
11209/22300 (epoch 25.132), train_loss = 0.42834062, grad/param norm = 2.1106e-01, time/batch = 16.9668s	
11210/22300 (epoch 25.135), train_loss = 0.46286719, grad/param norm = 2.8619e-01, time/batch = 16.8497s	
11211/22300 (epoch 25.137), train_loss = 0.35744722, grad/param norm = 2.1492e-01, time/batch = 17.7981s	
11212/22300 (epoch 25.139), train_loss = 0.56521494, grad/param norm = 2.9779e-01, time/batch = 14.9611s	
11213/22300 (epoch 25.141), train_loss = 0.67654443, grad/param norm = 2.5955e-01, time/batch = 15.5521s	
11214/22300 (epoch 25.143), train_loss = 0.61835226, grad/param norm = 3.0622e-01, time/batch = 17.3858s	
11215/22300 (epoch 25.146), train_loss = 0.70066973, grad/param norm = 3.2537e-01, time/batch = 17.3108s	
11216/22300 (epoch 25.148), train_loss = 0.48131622, grad/param norm = 2.4041e-01, time/batch = 15.4514s	
11217/22300 (epoch 25.150), train_loss = 0.54347323, grad/param norm = 2.7361e-01, time/batch = 15.6329s	
11218/22300 (epoch 25.152), train_loss = 0.47008002, grad/param norm = 2.8398e-01, time/batch = 16.5713s	
11219/22300 (epoch 25.155), train_loss = 0.46822290, grad/param norm = 2.1279e-01, time/batch = 17.1584s	
11220/22300 (epoch 25.157), train_loss = 0.62839091, grad/param norm = 2.9559e-01, time/batch = 15.6156s	
11221/22300 (epoch 25.159), train_loss = 0.67791342, grad/param norm = 3.4325e-01, time/batch = 16.6450s	
11222/22300 (epoch 25.161), train_loss = 0.65808621, grad/param norm = 2.8954e-01, time/batch = 17.0549s	
11223/22300 (epoch 25.164), train_loss = 0.49063210, grad/param norm = 2.2103e-01, time/batch = 18.0372s	
11224/22300 (epoch 25.166), train_loss = 0.45178494, grad/param norm = 2.1470e-01, time/batch = 16.3557s	
11225/22300 (epoch 25.168), train_loss = 0.46080624, grad/param norm = 2.4349e-01, time/batch = 15.7045s	
11226/22300 (epoch 25.170), train_loss = 0.59248809, grad/param norm = 2.7940e-01, time/batch = 15.4864s	
11227/22300 (epoch 25.173), train_loss = 0.69877048, grad/param norm = 3.1805e-01, time/batch = 15.8929s	
11228/22300 (epoch 25.175), train_loss = 0.58135302, grad/param norm = 2.7590e-01, time/batch = 16.8006s	
11229/22300 (epoch 25.177), train_loss = 0.41521988, grad/param norm = 2.4099e-01, time/batch = 18.2945s	
11230/22300 (epoch 25.179), train_loss = 0.59081890, grad/param norm = 3.0295e-01, time/batch = 16.1398s	
11231/22300 (epoch 25.182), train_loss = 0.77854670, grad/param norm = 3.2787e-01, time/batch = 15.9617s	
11232/22300 (epoch 25.184), train_loss = 0.82087050, grad/param norm = 3.2292e-01, time/batch = 16.7947s	
11233/22300 (epoch 25.186), train_loss = 0.61572653, grad/param norm = 2.8010e-01, time/batch = 15.9676s	
11234/22300 (epoch 25.188), train_loss = 0.81726348, grad/param norm = 3.1060e-01, time/batch = 15.1031s	
11235/22300 (epoch 25.191), train_loss = 0.71617472, grad/param norm = 3.1839e-01, time/batch = 16.1244s	
11236/22300 (epoch 25.193), train_loss = 0.61934175, grad/param norm = 3.1959e-01, time/batch = 17.8792s	
11237/22300 (epoch 25.195), train_loss = 0.56943306, grad/param norm = 2.6465e-01, time/batch = 18.2152s	
11238/22300 (epoch 25.197), train_loss = 0.51899466, grad/param norm = 2.6182e-01, time/batch = 15.8145s	
11239/22300 (epoch 25.200), train_loss = 0.47431355, grad/param norm = 2.5979e-01, time/batch = 15.2038s	
11240/22300 (epoch 25.202), train_loss = 0.53604230, grad/param norm = 2.7210e-01, time/batch = 14.8295s	
11241/22300 (epoch 25.204), train_loss = 0.57886380, grad/param norm = 2.6501e-01, time/batch = 18.7663s	
11242/22300 (epoch 25.206), train_loss = 0.49219220, grad/param norm = 2.4425e-01, time/batch = 15.7902s	
11243/22300 (epoch 25.209), train_loss = 0.57301883, grad/param norm = 3.0633e-01, time/batch = 16.3051s	
11244/22300 (epoch 25.211), train_loss = 0.45511829, grad/param norm = 2.9239e-01, time/batch = 16.7228s	
11245/22300 (epoch 25.213), train_loss = 0.56920471, grad/param norm = 2.7510e-01, time/batch = 14.4072s	
11246/22300 (epoch 25.215), train_loss = 0.74151729, grad/param norm = 3.0376e-01, time/batch = 15.9552s	
11247/22300 (epoch 25.217), train_loss = 0.74494477, grad/param norm = 3.0671e-01, time/batch = 17.5354s	
11248/22300 (epoch 25.220), train_loss = 0.54768442, grad/param norm = 2.4787e-01, time/batch = 15.7265s	
11249/22300 (epoch 25.222), train_loss = 0.52276173, grad/param norm = 2.6259e-01, time/batch = 16.3916s	
11250/22300 (epoch 25.224), train_loss = 0.53242915, grad/param norm = 2.7451e-01, time/batch = 15.3714s	
11251/22300 (epoch 25.226), train_loss = 0.56568501, grad/param norm = 2.2521e-01, time/batch = 15.2238s	
11252/22300 (epoch 25.229), train_loss = 0.49424810, grad/param norm = 2.8902e-01, time/batch = 16.4706s	
11253/22300 (epoch 25.231), train_loss = 0.69188047, grad/param norm = 4.0223e-01, time/batch = 15.9416s	
11254/22300 (epoch 25.233), train_loss = 0.60277636, grad/param norm = 3.1581e-01, time/batch = 17.1878s	
11255/22300 (epoch 25.235), train_loss = 0.46238204, grad/param norm = 2.1640e-01, time/batch = 15.9685s	
11256/22300 (epoch 25.238), train_loss = 0.47656307, grad/param norm = 2.4461e-01, time/batch = 18.1141s	
11257/22300 (epoch 25.240), train_loss = 0.46864963, grad/param norm = 2.1569e-01, time/batch = 16.0523s	
11258/22300 (epoch 25.242), train_loss = 0.47729200, grad/param norm = 2.7095e-01, time/batch = 18.4688s	
11259/22300 (epoch 25.244), train_loss = 0.33948815, grad/param norm = 2.3948e-01, time/batch = 16.0660s	
11260/22300 (epoch 25.247), train_loss = 0.48075621, grad/param norm = 2.9293e-01, time/batch = 12.0004s	
11261/22300 (epoch 25.249), train_loss = 0.33639008, grad/param norm = 2.2614e-01, time/batch = 0.6574s	
11262/22300 (epoch 25.251), train_loss = 0.45546244, grad/param norm = 2.3521e-01, time/batch = 0.6544s	
11263/22300 (epoch 25.253), train_loss = 0.32228188, grad/param norm = 1.7029e-01, time/batch = 0.6684s	
11264/22300 (epoch 25.256), train_loss = 0.40827168, grad/param norm = 2.2637e-01, time/batch = 0.6611s	
11265/22300 (epoch 25.258), train_loss = 0.62910835, grad/param norm = 3.2714e-01, time/batch = 0.6567s	
11266/22300 (epoch 25.260), train_loss = 0.59358762, grad/param norm = 2.8856e-01, time/batch = 0.6436s	
11267/22300 (epoch 25.262), train_loss = 0.44166244, grad/param norm = 2.1443e-01, time/batch = 0.6479s	
11268/22300 (epoch 25.265), train_loss = 0.43501717, grad/param norm = 2.7065e-01, time/batch = 0.6465s	
11269/22300 (epoch 25.267), train_loss = 0.48323763, grad/param norm = 2.4101e-01, time/batch = 0.6453s	
11270/22300 (epoch 25.269), train_loss = 0.55465124, grad/param norm = 2.9358e-01, time/batch = 0.6432s	
11271/22300 (epoch 25.271), train_loss = 0.60035500, grad/param norm = 2.5163e-01, time/batch = 0.6497s	
11272/22300 (epoch 25.274), train_loss = 0.42451398, grad/param norm = 2.4018e-01, time/batch = 0.6533s	
11273/22300 (epoch 25.276), train_loss = 0.37101998, grad/param norm = 1.9782e-01, time/batch = 0.6455s	
11274/22300 (epoch 25.278), train_loss = 0.37692473, grad/param norm = 2.2161e-01, time/batch = 0.6491s	
11275/22300 (epoch 25.280), train_loss = 0.43344609, grad/param norm = 2.3193e-01, time/batch = 0.6480s	
11276/22300 (epoch 25.283), train_loss = 0.34449134, grad/param norm = 1.6851e-01, time/batch = 0.9518s	
11277/22300 (epoch 25.285), train_loss = 0.43497703, grad/param norm = 2.4981e-01, time/batch = 0.9536s	
11278/22300 (epoch 25.287), train_loss = 0.55118334, grad/param norm = 2.5997e-01, time/batch = 0.9948s	
11279/22300 (epoch 25.289), train_loss = 0.50647850, grad/param norm = 2.2745e-01, time/batch = 0.9598s	
11280/22300 (epoch 25.291), train_loss = 0.50766230, grad/param norm = 3.0318e-01, time/batch = 0.9698s	
11281/22300 (epoch 25.294), train_loss = 0.42640647, grad/param norm = 2.4063e-01, time/batch = 1.7034s	
11282/22300 (epoch 25.296), train_loss = 0.53404763, grad/param norm = 3.1430e-01, time/batch = 1.8190s	
11283/22300 (epoch 25.298), train_loss = 0.64786000, grad/param norm = 2.9085e-01, time/batch = 3.6395s	
11284/22300 (epoch 25.300), train_loss = 0.70211255, grad/param norm = 2.9467e-01, time/batch = 15.7392s	
11285/22300 (epoch 25.303), train_loss = 0.52586371, grad/param norm = 2.3231e-01, time/batch = 16.3042s	
11286/22300 (epoch 25.305), train_loss = 0.55442142, grad/param norm = 3.7756e-01, time/batch = 15.8690s	
11287/22300 (epoch 25.307), train_loss = 0.52300041, grad/param norm = 3.4158e-01, time/batch = 17.7991s	
11288/22300 (epoch 25.309), train_loss = 0.46583640, grad/param norm = 3.1884e-01, time/batch = 17.1068s	
11289/22300 (epoch 25.312), train_loss = 0.40566206, grad/param norm = 2.3316e-01, time/batch = 16.4542s	
11290/22300 (epoch 25.314), train_loss = 0.43714404, grad/param norm = 2.2978e-01, time/batch = 15.3553s	
11291/22300 (epoch 25.316), train_loss = 0.45976494, grad/param norm = 2.8164e-01, time/batch = 17.6380s	
11292/22300 (epoch 25.318), train_loss = 0.51942381, grad/param norm = 2.9024e-01, time/batch = 16.4598s	
11293/22300 (epoch 25.321), train_loss = 0.61594554, grad/param norm = 2.6346e-01, time/batch = 15.3046s	
11294/22300 (epoch 25.323), train_loss = 0.45678477, grad/param norm = 2.4706e-01, time/batch = 15.8089s	
11295/22300 (epoch 25.325), train_loss = 0.40967011, grad/param norm = 2.1833e-01, time/batch = 16.8676s	
11296/22300 (epoch 25.327), train_loss = 0.42721219, grad/param norm = 2.3788e-01, time/batch = 18.5042s	
11297/22300 (epoch 25.330), train_loss = 0.45710573, grad/param norm = 2.9870e-01, time/batch = 16.6232s	
11298/22300 (epoch 25.332), train_loss = 0.41718054, grad/param norm = 2.3213e-01, time/batch = 19.2795s	
11299/22300 (epoch 25.334), train_loss = 0.46638032, grad/param norm = 2.5156e-01, time/batch = 18.2947s	
11300/22300 (epoch 25.336), train_loss = 0.48815750, grad/param norm = 2.7259e-01, time/batch = 16.0413s	
11301/22300 (epoch 25.339), train_loss = 0.54115444, grad/param norm = 2.5224e-01, time/batch = 15.4710s	
11302/22300 (epoch 25.341), train_loss = 0.60029367, grad/param norm = 3.1364e-01, time/batch = 16.5500s	
11303/22300 (epoch 25.343), train_loss = 0.66593589, grad/param norm = 3.4851e-01, time/batch = 16.7195s	
11304/22300 (epoch 25.345), train_loss = 0.48823587, grad/param norm = 2.1903e-01, time/batch = 16.9592s	
11305/22300 (epoch 25.348), train_loss = 0.48432452, grad/param norm = 2.4406e-01, time/batch = 16.5595s	
11306/22300 (epoch 25.350), train_loss = 0.42153185, grad/param norm = 2.3516e-01, time/batch = 17.8959s	
11307/22300 (epoch 25.352), train_loss = 0.55605555, grad/param norm = 2.9747e-01, time/batch = 16.2988s	
11308/22300 (epoch 25.354), train_loss = 0.78138473, grad/param norm = 3.7395e-01, time/batch = 14.9479s	
11309/22300 (epoch 25.357), train_loss = 0.65162161, grad/param norm = 2.7398e-01, time/batch = 15.8880s	
11310/22300 (epoch 25.359), train_loss = 0.44229081, grad/param norm = 2.4697e-01, time/batch = 17.0382s	
11311/22300 (epoch 25.361), train_loss = 0.45666524, grad/param norm = 2.9411e-01, time/batch = 15.3015s	
11312/22300 (epoch 25.363), train_loss = 0.62778869, grad/param norm = 3.3213e-01, time/batch = 17.0531s	
11313/22300 (epoch 25.365), train_loss = 0.51420994, grad/param norm = 3.0451e-01, time/batch = 17.5410s	
11314/22300 (epoch 25.368), train_loss = 0.53120192, grad/param norm = 3.5975e-01, time/batch = 15.2065s	
11315/22300 (epoch 25.370), train_loss = 0.50564165, grad/param norm = 2.6399e-01, time/batch = 17.3675s	
11316/22300 (epoch 25.372), train_loss = 0.40265798, grad/param norm = 2.1367e-01, time/batch = 16.4737s	
11317/22300 (epoch 25.374), train_loss = 0.36980376, grad/param norm = 2.1136e-01, time/batch = 17.8872s	
11318/22300 (epoch 25.377), train_loss = 0.51254705, grad/param norm = 2.9344e-01, time/batch = 15.5440s	
11319/22300 (epoch 25.379), train_loss = 0.47365039, grad/param norm = 2.3308e-01, time/batch = 16.9736s	
11320/22300 (epoch 25.381), train_loss = 0.60417563, grad/param norm = 2.8969e-01, time/batch = 16.4737s	
11321/22300 (epoch 25.383), train_loss = 0.51965296, grad/param norm = 3.1101e-01, time/batch = 16.6877s	
11322/22300 (epoch 25.386), train_loss = 0.50054632, grad/param norm = 2.5665e-01, time/batch = 17.2057s	
11323/22300 (epoch 25.388), train_loss = 0.43990059, grad/param norm = 2.9986e-01, time/batch = 17.6330s	
11324/22300 (epoch 25.390), train_loss = 0.50904689, grad/param norm = 2.7683e-01, time/batch = 17.9582s	
11325/22300 (epoch 25.392), train_loss = 0.50561816, grad/param norm = 2.7476e-01, time/batch = 15.6219s	
11326/22300 (epoch 25.395), train_loss = 0.42418489, grad/param norm = 2.5274e-01, time/batch = 16.8896s	
11327/22300 (epoch 25.397), train_loss = 0.28407208, grad/param norm = 1.7337e-01, time/batch = 15.7063s	
11328/22300 (epoch 25.399), train_loss = 0.42515103, grad/param norm = 2.5440e-01, time/batch = 16.4611s	
11329/22300 (epoch 25.401), train_loss = 0.50338495, grad/param norm = 3.1326e-01, time/batch = 17.2913s	
11330/22300 (epoch 25.404), train_loss = 0.47481117, grad/param norm = 2.5637e-01, time/batch = 15.8997s	
11331/22300 (epoch 25.406), train_loss = 0.72136797, grad/param norm = 3.1718e-01, time/batch = 15.8765s	
11332/22300 (epoch 25.408), train_loss = 0.59009858, grad/param norm = 2.5929e-01, time/batch = 16.3924s	
11333/22300 (epoch 25.410), train_loss = 0.63304370, grad/param norm = 2.8089e-01, time/batch = 15.3920s	
11334/22300 (epoch 25.413), train_loss = 0.48233573, grad/param norm = 2.9841e-01, time/batch = 16.9823s	
11335/22300 (epoch 25.415), train_loss = 0.36040538, grad/param norm = 2.1513e-01, time/batch = 17.4377s	
11336/22300 (epoch 25.417), train_loss = 0.55012935, grad/param norm = 2.6706e-01, time/batch = 27.8157s	
11337/22300 (epoch 25.419), train_loss = 0.47122593, grad/param norm = 2.3827e-01, time/batch = 17.2385s	
11338/22300 (epoch 25.422), train_loss = 0.43743993, grad/param norm = 2.6914e-01, time/batch = 15.6333s	
11339/22300 (epoch 25.424), train_loss = 0.55130731, grad/param norm = 3.5116e-01, time/batch = 15.8736s	
11340/22300 (epoch 25.426), train_loss = 0.37952927, grad/param norm = 2.3639e-01, time/batch = 15.8097s	
11341/22300 (epoch 25.428), train_loss = 0.45219555, grad/param norm = 2.7682e-01, time/batch = 15.9524s	
11342/22300 (epoch 25.430), train_loss = 0.52099668, grad/param norm = 3.0150e-01, time/batch = 15.4823s	
11343/22300 (epoch 25.433), train_loss = 0.50250087, grad/param norm = 2.4787e-01, time/batch = 15.6894s	
11344/22300 (epoch 25.435), train_loss = 0.48948535, grad/param norm = 2.5025e-01, time/batch = 15.4699s	
11345/22300 (epoch 25.437), train_loss = 0.53027901, grad/param norm = 2.7884e-01, time/batch = 15.6336s	
11346/22300 (epoch 25.439), train_loss = 0.59262024, grad/param norm = 2.8574e-01, time/batch = 15.9301s	
11347/22300 (epoch 25.442), train_loss = 0.52974696, grad/param norm = 2.9913e-01, time/batch = 15.6496s	
11348/22300 (epoch 25.444), train_loss = 0.44820877, grad/param norm = 2.2877e-01, time/batch = 15.8023s	
11349/22300 (epoch 25.446), train_loss = 0.42724136, grad/param norm = 2.3375e-01, time/batch = 15.7046s	
11350/22300 (epoch 25.448), train_loss = 0.31869968, grad/param norm = 2.1860e-01, time/batch = 15.5667s	
11351/22300 (epoch 25.451), train_loss = 0.57581933, grad/param norm = 3.0423e-01, time/batch = 15.8874s	
11352/22300 (epoch 25.453), train_loss = 0.45391701, grad/param norm = 2.3367e-01, time/batch = 15.8858s	
11353/22300 (epoch 25.455), train_loss = 0.62090498, grad/param norm = 3.0069e-01, time/batch = 15.8105s	
11354/22300 (epoch 25.457), train_loss = 0.69202266, grad/param norm = 3.1640e-01, time/batch = 15.9516s	
11355/22300 (epoch 25.460), train_loss = 0.60668638, grad/param norm = 2.5942e-01, time/batch = 15.8126s	
11356/22300 (epoch 25.462), train_loss = 0.64456903, grad/param norm = 2.9184e-01, time/batch = 15.8794s	
11357/22300 (epoch 25.464), train_loss = 0.55396990, grad/param norm = 2.6246e-01, time/batch = 15.6541s	
11358/22300 (epoch 25.466), train_loss = 0.47199003, grad/param norm = 2.3901e-01, time/batch = 15.8891s	
11359/22300 (epoch 25.469), train_loss = 0.45547628, grad/param norm = 2.4893e-01, time/batch = 15.7145s	
11360/22300 (epoch 25.471), train_loss = 0.60280967, grad/param norm = 2.5323e-01, time/batch = 15.7349s	
11361/22300 (epoch 25.473), train_loss = 0.54328835, grad/param norm = 2.6042e-01, time/batch = 15.8395s	
11362/22300 (epoch 25.475), train_loss = 0.46976192, grad/param norm = 2.5914e-01, time/batch = 15.7190s	
11363/22300 (epoch 25.478), train_loss = 0.47781706, grad/param norm = 2.7619e-01, time/batch = 15.8493s	
11364/22300 (epoch 25.480), train_loss = 0.34676953, grad/param norm = 2.8313e-01, time/batch = 15.8058s	
11365/22300 (epoch 25.482), train_loss = 0.38858062, grad/param norm = 2.3704e-01, time/batch = 15.7764s	
11366/22300 (epoch 25.484), train_loss = 0.49767404, grad/param norm = 2.3925e-01, time/batch = 15.7253s	
11367/22300 (epoch 25.487), train_loss = 0.57712456, grad/param norm = 2.3626e-01, time/batch = 15.9421s	
11368/22300 (epoch 25.489), train_loss = 0.56254230, grad/param norm = 2.4637e-01, time/batch = 16.0452s	
11369/22300 (epoch 25.491), train_loss = 0.57211288, grad/param norm = 2.6660e-01, time/batch = 15.8526s	
11370/22300 (epoch 25.493), train_loss = 0.50923606, grad/param norm = 2.8649e-01, time/batch = 15.8072s	
11371/22300 (epoch 25.496), train_loss = 0.51255596, grad/param norm = 2.3520e-01, time/batch = 16.2243s	
11372/22300 (epoch 25.498), train_loss = 0.36944476, grad/param norm = 2.1928e-01, time/batch = 15.8659s	
11373/22300 (epoch 25.500), train_loss = 0.53162878, grad/param norm = 3.0661e-01, time/batch = 16.0822s	
11374/22300 (epoch 25.502), train_loss = 0.34160501, grad/param norm = 2.1769e-01, time/batch = 15.8738s	
11375/22300 (epoch 25.504), train_loss = 0.37046765, grad/param norm = 2.2431e-01, time/batch = 15.7947s	
11376/22300 (epoch 25.507), train_loss = 0.44188060, grad/param norm = 2.6031e-01, time/batch = 15.9738s	
11377/22300 (epoch 25.509), train_loss = 0.56167443, grad/param norm = 2.8545e-01, time/batch = 16.2045s	
11378/22300 (epoch 25.511), train_loss = 0.32697921, grad/param norm = 1.8030e-01, time/batch = 16.1292s	
11379/22300 (epoch 25.513), train_loss = 0.36475405, grad/param norm = 2.1073e-01, time/batch = 16.0519s	
11380/22300 (epoch 25.516), train_loss = 0.43969728, grad/param norm = 2.5981e-01, time/batch = 15.8766s	
11381/22300 (epoch 25.518), train_loss = 0.58053944, grad/param norm = 2.8346e-01, time/batch = 16.2015s	
11382/22300 (epoch 25.520), train_loss = 0.46075376, grad/param norm = 2.6601e-01, time/batch = 15.7974s	
11383/22300 (epoch 25.522), train_loss = 0.47580387, grad/param norm = 2.4418e-01, time/batch = 15.8495s	
11384/22300 (epoch 25.525), train_loss = 0.40825424, grad/param norm = 2.7115e-01, time/batch = 15.9754s	
11385/22300 (epoch 25.527), train_loss = 0.64033156, grad/param norm = 3.7716e-01, time/batch = 15.9452s	
11386/22300 (epoch 25.529), train_loss = 0.51215744, grad/param norm = 2.6948e-01, time/batch = 15.8713s	
11387/22300 (epoch 25.531), train_loss = 0.46522298, grad/param norm = 2.6264e-01, time/batch = 15.7136s	
11388/22300 (epoch 25.534), train_loss = 0.44236831, grad/param norm = 2.4072e-01, time/batch = 15.8614s	
11389/22300 (epoch 25.536), train_loss = 0.68434629, grad/param norm = 2.6423e-01, time/batch = 15.8036s	
11390/22300 (epoch 25.538), train_loss = 0.82510560, grad/param norm = 3.5595e-01, time/batch = 15.7097s	
11391/22300 (epoch 25.540), train_loss = 0.52693480, grad/param norm = 2.9289e-01, time/batch = 15.7245s	
11392/22300 (epoch 25.543), train_loss = 0.47702139, grad/param norm = 2.3954e-01, time/batch = 16.0187s	
11393/22300 (epoch 25.545), train_loss = 0.37219380, grad/param norm = 2.2850e-01, time/batch = 15.8865s	
11394/22300 (epoch 25.547), train_loss = 0.37001674, grad/param norm = 2.4740e-01, time/batch = 15.8061s	
11395/22300 (epoch 25.549), train_loss = 0.41045349, grad/param norm = 2.3621e-01, time/batch = 15.8050s	
11396/22300 (epoch 25.552), train_loss = 0.40884442, grad/param norm = 2.3017e-01, time/batch = 16.1360s	
11397/22300 (epoch 25.554), train_loss = 0.56056335, grad/param norm = 2.8372e-01, time/batch = 15.8153s	
11398/22300 (epoch 25.556), train_loss = 0.74269324, grad/param norm = 3.9309e-01, time/batch = 16.1124s	
11399/22300 (epoch 25.558), train_loss = 0.59194726, grad/param norm = 3.0591e-01, time/batch = 15.9185s	
11400/22300 (epoch 25.561), train_loss = 0.71422409, grad/param norm = 3.5285e-01, time/batch = 15.7865s	
11401/22300 (epoch 25.563), train_loss = 0.64575216, grad/param norm = 3.3506e-01, time/batch = 15.9574s	
11402/22300 (epoch 25.565), train_loss = 0.46843515, grad/param norm = 2.7036e-01, time/batch = 15.8687s	
11403/22300 (epoch 25.567), train_loss = 0.47028189, grad/param norm = 2.3207e-01, time/batch = 16.0809s	
11404/22300 (epoch 25.570), train_loss = 0.67552670, grad/param norm = 3.0103e-01, time/batch = 15.7400s	
11405/22300 (epoch 25.572), train_loss = 0.64249886, grad/param norm = 2.9598e-01, time/batch = 15.6532s	
11406/22300 (epoch 25.574), train_loss = 0.49758814, grad/param norm = 2.4537e-01, time/batch = 16.0891s	
11407/22300 (epoch 25.576), train_loss = 0.43197352, grad/param norm = 2.2281e-01, time/batch = 15.8137s	
11408/22300 (epoch 25.578), train_loss = 0.26444512, grad/param norm = 1.7667e-01, time/batch = 16.0557s	
11409/22300 (epoch 25.581), train_loss = 0.37274628, grad/param norm = 2.0316e-01, time/batch = 16.0390s	
11410/22300 (epoch 25.583), train_loss = 0.43655748, grad/param norm = 2.2127e-01, time/batch = 15.9515s	
11411/22300 (epoch 25.585), train_loss = 0.62369430, grad/param norm = 3.1841e-01, time/batch = 16.0474s	
11412/22300 (epoch 25.587), train_loss = 0.81148489, grad/param norm = 3.4009e-01, time/batch = 15.5020s	
11413/22300 (epoch 25.590), train_loss = 0.69028797, grad/param norm = 3.8155e-01, time/batch = 15.7090s	
11414/22300 (epoch 25.592), train_loss = 0.74865138, grad/param norm = 3.5861e-01, time/batch = 15.7453s	
11415/22300 (epoch 25.594), train_loss = 0.78036078, grad/param norm = 3.7037e-01, time/batch = 16.8605s	
11416/22300 (epoch 25.596), train_loss = 0.48288215, grad/param norm = 2.4778e-01, time/batch = 15.9445s	
11417/22300 (epoch 25.599), train_loss = 0.38897310, grad/param norm = 2.4571e-01, time/batch = 14.8124s	
11418/22300 (epoch 25.601), train_loss = 0.45367648, grad/param norm = 2.4742e-01, time/batch = 15.3727s	
11419/22300 (epoch 25.603), train_loss = 0.50162411, grad/param norm = 2.2472e-01, time/batch = 15.5514s	
11420/22300 (epoch 25.605), train_loss = 0.47614718, grad/param norm = 2.5116e-01, time/batch = 15.0456s	
11421/22300 (epoch 25.608), train_loss = 0.76120683, grad/param norm = 3.2511e-01, time/batch = 15.6168s	
11422/22300 (epoch 25.610), train_loss = 0.75771226, grad/param norm = 3.0800e-01, time/batch = 15.3588s	
11423/22300 (epoch 25.612), train_loss = 0.61669029, grad/param norm = 3.1145e-01, time/batch = 15.2951s	
11424/22300 (epoch 25.614), train_loss = 0.63655228, grad/param norm = 3.0280e-01, time/batch = 16.5509s	
11425/22300 (epoch 25.617), train_loss = 0.60522027, grad/param norm = 2.7707e-01, time/batch = 15.4078s	
11426/22300 (epoch 25.619), train_loss = 0.72725016, grad/param norm = 2.8205e-01, time/batch = 15.2653s	
11427/22300 (epoch 25.621), train_loss = 0.47069501, grad/param norm = 2.3097e-01, time/batch = 16.0477s	
11428/22300 (epoch 25.623), train_loss = 0.48825841, grad/param norm = 2.7091e-01, time/batch = 14.8853s	
11429/22300 (epoch 25.626), train_loss = 0.44434071, grad/param norm = 2.5174e-01, time/batch = 15.2067s	
11430/22300 (epoch 25.628), train_loss = 0.46708163, grad/param norm = 2.3073e-01, time/batch = 15.2999s	
11431/22300 (epoch 25.630), train_loss = 0.53754583, grad/param norm = 3.1708e-01, time/batch = 15.7455s	
11432/22300 (epoch 25.632), train_loss = 0.47889104, grad/param norm = 3.0047e-01, time/batch = 15.3689s	
11433/22300 (epoch 25.635), train_loss = 0.49744302, grad/param norm = 2.5681e-01, time/batch = 17.2929s	
11434/22300 (epoch 25.637), train_loss = 0.57430390, grad/param norm = 2.8581e-01, time/batch = 16.1307s	
11435/22300 (epoch 25.639), train_loss = 0.69285047, grad/param norm = 3.3055e-01, time/batch = 16.2203s	
11436/22300 (epoch 25.641), train_loss = 0.55995121, grad/param norm = 2.8620e-01, time/batch = 18.9387s	
11437/22300 (epoch 25.643), train_loss = 0.46841417, grad/param norm = 2.6675e-01, time/batch = 14.9728s	
11438/22300 (epoch 25.646), train_loss = 0.45240310, grad/param norm = 2.7635e-01, time/batch = 16.8080s	
11439/22300 (epoch 25.648), train_loss = 0.50910399, grad/param norm = 2.4322e-01, time/batch = 16.5384s	
11440/22300 (epoch 25.650), train_loss = 0.58616946, grad/param norm = 3.2337e-01, time/batch = 16.2727s	
11441/22300 (epoch 25.652), train_loss = 0.49423539, grad/param norm = 2.7063e-01, time/batch = 15.4098s	
11442/22300 (epoch 25.655), train_loss = 0.45900097, grad/param norm = 2.6206e-01, time/batch = 14.8064s	
11443/22300 (epoch 25.657), train_loss = 0.52233901, grad/param norm = 2.7285e-01, time/batch = 15.0376s	
11444/22300 (epoch 25.659), train_loss = 0.47837851, grad/param norm = 2.6209e-01, time/batch = 15.5861s	
11445/22300 (epoch 25.661), train_loss = 0.37454593, grad/param norm = 2.1677e-01, time/batch = 15.6488s	
11446/22300 (epoch 25.664), train_loss = 0.44508259, grad/param norm = 2.2664e-01, time/batch = 14.5552s	
11447/22300 (epoch 25.666), train_loss = 0.59699192, grad/param norm = 2.6614e-01, time/batch = 14.1774s	
11448/22300 (epoch 25.668), train_loss = 0.42677488, grad/param norm = 2.2997e-01, time/batch = 14.5673s	
11449/22300 (epoch 25.670), train_loss = 0.55358533, grad/param norm = 2.4627e-01, time/batch = 14.8823s	
11450/22300 (epoch 25.673), train_loss = 0.64151918, grad/param norm = 3.3148e-01, time/batch = 15.1351s	
11451/22300 (epoch 25.675), train_loss = 0.69483322, grad/param norm = 3.0774e-01, time/batch = 14.8140s	
11452/22300 (epoch 25.677), train_loss = 0.75876470, grad/param norm = 3.8881e-01, time/batch = 14.4833s	
11453/22300 (epoch 25.679), train_loss = 0.57959848, grad/param norm = 3.1146e-01, time/batch = 14.8080s	
11454/22300 (epoch 25.682), train_loss = 0.54928801, grad/param norm = 2.5645e-01, time/batch = 14.8230s	
11455/22300 (epoch 25.684), train_loss = 0.50413617, grad/param norm = 2.6394e-01, time/batch = 14.8249s	
11456/22300 (epoch 25.686), train_loss = 0.52226930, grad/param norm = 2.5923e-01, time/batch = 15.2000s	
11457/22300 (epoch 25.688), train_loss = 0.48008379, grad/param norm = 2.3142e-01, time/batch = 15.4325s	
11458/22300 (epoch 25.691), train_loss = 0.46982281, grad/param norm = 2.8906e-01, time/batch = 14.4150s	
11459/22300 (epoch 25.693), train_loss = 0.44235173, grad/param norm = 2.3776e-01, time/batch = 14.6492s	
11460/22300 (epoch 25.695), train_loss = 0.39831135, grad/param norm = 2.1622e-01, time/batch = 15.2823s	
11461/22300 (epoch 25.697), train_loss = 0.43302000, grad/param norm = 2.3061e-01, time/batch = 14.8933s	
11462/22300 (epoch 25.700), train_loss = 0.42662187, grad/param norm = 2.3842e-01, time/batch = 14.2535s	
11463/22300 (epoch 25.702), train_loss = 0.40793453, grad/param norm = 2.1205e-01, time/batch = 15.2678s	
11464/22300 (epoch 25.704), train_loss = 0.49988019, grad/param norm = 2.6347e-01, time/batch = 14.7107s	
11465/22300 (epoch 25.706), train_loss = 0.45328065, grad/param norm = 2.5159e-01, time/batch = 15.0622s	
11466/22300 (epoch 25.709), train_loss = 0.35844789, grad/param norm = 2.2621e-01, time/batch = 14.3411s	
11467/22300 (epoch 25.711), train_loss = 0.37469078, grad/param norm = 2.1224e-01, time/batch = 14.4139s	
11468/22300 (epoch 25.713), train_loss = 0.53795017, grad/param norm = 2.6598e-01, time/batch = 14.8139s	
11469/22300 (epoch 25.715), train_loss = 0.51953809, grad/param norm = 2.5677e-01, time/batch = 14.3160s	
11470/22300 (epoch 25.717), train_loss = 0.68815296, grad/param norm = 2.7438e-01, time/batch = 14.1701s	
11471/22300 (epoch 25.720), train_loss = 0.45857948, grad/param norm = 2.8718e-01, time/batch = 14.5748s	
11472/22300 (epoch 25.722), train_loss = 0.55100695, grad/param norm = 3.6694e-01, time/batch = 14.1555s	
11473/22300 (epoch 25.724), train_loss = 0.62679678, grad/param norm = 3.1831e-01, time/batch = 14.3307s	
11474/22300 (epoch 25.726), train_loss = 0.47128247, grad/param norm = 2.6439e-01, time/batch = 14.4159s	
11475/22300 (epoch 25.729), train_loss = 0.52438091, grad/param norm = 2.5940e-01, time/batch = 15.2003s	
11476/22300 (epoch 25.731), train_loss = 0.68958813, grad/param norm = 3.0794e-01, time/batch = 14.0775s	
11477/22300 (epoch 25.733), train_loss = 0.69846960, grad/param norm = 3.2666e-01, time/batch = 14.3242s	
11478/22300 (epoch 25.735), train_loss = 0.73502482, grad/param norm = 3.0700e-01, time/batch = 15.2787s	
11479/22300 (epoch 25.738), train_loss = 0.54719062, grad/param norm = 3.0986e-01, time/batch = 15.6435s	
11480/22300 (epoch 25.740), train_loss = 0.46719686, grad/param norm = 2.1029e-01, time/batch = 14.8131s	
11481/22300 (epoch 25.742), train_loss = 0.48684546, grad/param norm = 3.1288e-01, time/batch = 14.7336s	
11482/22300 (epoch 25.744), train_loss = 0.75804048, grad/param norm = 3.1289e-01, time/batch = 14.8708s	
11483/22300 (epoch 25.747), train_loss = 0.63234913, grad/param norm = 2.9869e-01, time/batch = 14.2538s	
11484/22300 (epoch 25.749), train_loss = 0.77793641, grad/param norm = 3.5767e-01, time/batch = 15.2552s	
11485/22300 (epoch 25.751), train_loss = 0.65773050, grad/param norm = 3.7860e-01, time/batch = 14.8858s	
11486/22300 (epoch 25.753), train_loss = 0.70231386, grad/param norm = 3.0713e-01, time/batch = 14.8103s	
11487/22300 (epoch 25.756), train_loss = 0.62271923, grad/param norm = 3.1068e-01, time/batch = 15.4057s	
11488/22300 (epoch 25.758), train_loss = 0.56283265, grad/param norm = 2.7455e-01, time/batch = 14.6816s	
11489/22300 (epoch 25.760), train_loss = 0.60392201, grad/param norm = 3.1686e-01, time/batch = 15.1143s	
11490/22300 (epoch 25.762), train_loss = 0.54997136, grad/param norm = 2.6090e-01, time/batch = 14.8097s	
11491/22300 (epoch 25.765), train_loss = 0.57046149, grad/param norm = 2.9150e-01, time/batch = 15.6597s	
11492/22300 (epoch 25.767), train_loss = 0.59554969, grad/param norm = 2.8998e-01, time/batch = 14.3206s	
11493/22300 (epoch 25.769), train_loss = 0.55971472, grad/param norm = 3.1679e-01, time/batch = 14.9789s	
11494/22300 (epoch 25.771), train_loss = 0.64926078, grad/param norm = 3.2081e-01, time/batch = 14.5704s	
11495/22300 (epoch 25.774), train_loss = 0.68664753, grad/param norm = 3.5166e-01, time/batch = 14.8994s	
11496/22300 (epoch 25.776), train_loss = 0.70158583, grad/param norm = 2.9292e-01, time/batch = 15.1703s	
11497/22300 (epoch 25.778), train_loss = 0.67439668, grad/param norm = 3.4584e-01, time/batch = 14.9643s	
11498/22300 (epoch 25.780), train_loss = 0.67539012, grad/param norm = 3.2103e-01, time/batch = 14.2442s	
11499/22300 (epoch 25.783), train_loss = 0.73826017, grad/param norm = 3.2459e-01, time/batch = 14.8277s	
11500/22300 (epoch 25.785), train_loss = 0.53528974, grad/param norm = 2.8449e-01, time/batch = 14.8166s	
11501/22300 (epoch 25.787), train_loss = 0.49464423, grad/param norm = 2.5435e-01, time/batch = 14.7245s	
11502/22300 (epoch 25.789), train_loss = 0.73383884, grad/param norm = 3.6072e-01, time/batch = 15.2541s	
11503/22300 (epoch 25.791), train_loss = 0.89350698, grad/param norm = 3.8687e-01, time/batch = 14.9382s	
11504/22300 (epoch 25.794), train_loss = 0.72886788, grad/param norm = 3.8134e-01, time/batch = 14.4414s	
11505/22300 (epoch 25.796), train_loss = 0.67451762, grad/param norm = 3.1655e-01, time/batch = 15.1164s	
11506/22300 (epoch 25.798), train_loss = 0.81737617, grad/param norm = 3.6348e-01, time/batch = 15.5014s	
11507/22300 (epoch 25.800), train_loss = 0.55321954, grad/param norm = 2.9947e-01, time/batch = 15.5255s	
11508/22300 (epoch 25.803), train_loss = 0.51786579, grad/param norm = 2.3690e-01, time/batch = 15.3958s	
11509/22300 (epoch 25.805), train_loss = 0.62679571, grad/param norm = 2.8692e-01, time/batch = 15.0965s	
11510/22300 (epoch 25.807), train_loss = 0.73535525, grad/param norm = 3.3501e-01, time/batch = 14.7713s	
11511/22300 (epoch 25.809), train_loss = 0.55074909, grad/param norm = 2.6673e-01, time/batch = 15.1460s	
11512/22300 (epoch 25.812), train_loss = 0.64666043, grad/param norm = 3.1444e-01, time/batch = 14.6995s	
11513/22300 (epoch 25.814), train_loss = 0.62366867, grad/param norm = 2.9180e-01, time/batch = 15.8816s	
11514/22300 (epoch 25.816), train_loss = 0.62538290, grad/param norm = 2.7157e-01, time/batch = 14.7653s	
11515/22300 (epoch 25.818), train_loss = 0.74210593, grad/param norm = 3.2865e-01, time/batch = 15.1824s	
11516/22300 (epoch 25.821), train_loss = 0.63232466, grad/param norm = 2.8299e-01, time/batch = 15.0209s	
11517/22300 (epoch 25.823), train_loss = 0.41763887, grad/param norm = 2.3103e-01, time/batch = 15.0196s	
11518/22300 (epoch 25.825), train_loss = 0.49578630, grad/param norm = 3.1720e-01, time/batch = 14.7594s	
11519/22300 (epoch 25.827), train_loss = 0.54088945, grad/param norm = 2.8920e-01, time/batch = 14.7795s	
11520/22300 (epoch 25.830), train_loss = 0.50923764, grad/param norm = 3.0031e-01, time/batch = 15.5403s	
11521/22300 (epoch 25.832), train_loss = 0.47859770, grad/param norm = 2.7474e-01, time/batch = 14.8522s	
11522/22300 (epoch 25.834), train_loss = 0.46564081, grad/param norm = 2.9552e-01, time/batch = 14.2092s	
11523/22300 (epoch 25.836), train_loss = 0.56083304, grad/param norm = 3.0773e-01, time/batch = 14.4481s	
11524/22300 (epoch 25.839), train_loss = 0.50930803, grad/param norm = 2.3990e-01, time/batch = 14.7767s	
11525/22300 (epoch 25.841), train_loss = 0.53924926, grad/param norm = 3.1292e-01, time/batch = 15.1132s	
11526/22300 (epoch 25.843), train_loss = 0.56065997, grad/param norm = 3.2598e-01, time/batch = 14.8548s	
11527/22300 (epoch 25.845), train_loss = 0.51195641, grad/param norm = 2.3683e-01, time/batch = 15.2630s	
11528/22300 (epoch 25.848), train_loss = 0.53323842, grad/param norm = 3.1006e-01, time/batch = 14.9223s	
11529/22300 (epoch 25.850), train_loss = 0.52910513, grad/param norm = 2.4327e-01, time/batch = 15.0812s	
11530/22300 (epoch 25.852), train_loss = 0.49401460, grad/param norm = 2.5607e-01, time/batch = 14.7764s	
11531/22300 (epoch 25.854), train_loss = 0.76717616, grad/param norm = 3.5990e-01, time/batch = 14.7003s	
11532/22300 (epoch 25.857), train_loss = 0.61395815, grad/param norm = 3.4979e-01, time/batch = 14.7741s	
11533/22300 (epoch 25.859), train_loss = 0.46995682, grad/param norm = 2.4857e-01, time/batch = 14.9211s	
11534/22300 (epoch 25.861), train_loss = 0.62479181, grad/param norm = 3.2773e-01, time/batch = 14.7718s	
11535/22300 (epoch 25.863), train_loss = 0.47200844, grad/param norm = 2.5824e-01, time/batch = 14.5304s	
11536/22300 (epoch 25.865), train_loss = 0.43399015, grad/param norm = 2.0836e-01, time/batch = 14.4482s	
11537/22300 (epoch 25.868), train_loss = 0.56427286, grad/param norm = 2.8493e-01, time/batch = 14.9865s	
11538/22300 (epoch 25.870), train_loss = 0.61318130, grad/param norm = 2.9488e-01, time/batch = 14.9020s	
11539/22300 (epoch 25.872), train_loss = 0.64994696, grad/param norm = 2.7305e-01, time/batch = 14.7624s	
11540/22300 (epoch 25.874), train_loss = 0.59059480, grad/param norm = 3.0761e-01, time/batch = 15.4586s	
11541/22300 (epoch 25.877), train_loss = 0.57589153, grad/param norm = 2.6774e-01, time/batch = 14.9789s	
11542/22300 (epoch 25.879), train_loss = 0.50127912, grad/param norm = 2.3970e-01, time/batch = 14.8896s	
11543/22300 (epoch 25.881), train_loss = 0.46018390, grad/param norm = 2.4353e-01, time/batch = 15.0789s	
11544/22300 (epoch 25.883), train_loss = 0.47772205, grad/param norm = 2.8722e-01, time/batch = 14.9319s	
11545/22300 (epoch 25.886), train_loss = 0.45176381, grad/param norm = 2.5830e-01, time/batch = 15.2528s	
11546/22300 (epoch 25.888), train_loss = 0.50523064, grad/param norm = 2.4554e-01, time/batch = 15.1721s	
11547/22300 (epoch 25.890), train_loss = 0.49778815, grad/param norm = 2.9722e-01, time/batch = 14.5186s	
11548/22300 (epoch 25.892), train_loss = 0.73177201, grad/param norm = 3.2461e-01, time/batch = 15.3796s	
11549/22300 (epoch 25.895), train_loss = 0.67391146, grad/param norm = 3.0851e-01, time/batch = 15.0213s	
11550/22300 (epoch 25.897), train_loss = 0.53290143, grad/param norm = 2.8549e-01, time/batch = 17.0311s	
11551/22300 (epoch 25.899), train_loss = 0.54832924, grad/param norm = 2.7046e-01, time/batch = 16.0621s	
11552/22300 (epoch 25.901), train_loss = 0.60047792, grad/param norm = 3.1803e-01, time/batch = 15.5839s	
11553/22300 (epoch 25.904), train_loss = 0.62213940, grad/param norm = 2.6943e-01, time/batch = 15.7521s	
11554/22300 (epoch 25.906), train_loss = 0.59394841, grad/param norm = 2.6746e-01, time/batch = 15.8068s	
11555/22300 (epoch 25.908), train_loss = 0.52810101, grad/param norm = 2.7070e-01, time/batch = 14.6543s	
11556/22300 (epoch 25.910), train_loss = 0.46517639, grad/param norm = 2.7882e-01, time/batch = 15.0580s	
11557/22300 (epoch 25.913), train_loss = 0.61402460, grad/param norm = 2.9444e-01, time/batch = 16.5990s	
11558/22300 (epoch 25.915), train_loss = 0.72202908, grad/param norm = 2.9659e-01, time/batch = 16.4701s	
11559/22300 (epoch 25.917), train_loss = 0.58494487, grad/param norm = 2.6532e-01, time/batch = 15.7192s	
11560/22300 (epoch 25.919), train_loss = 0.63156280, grad/param norm = 2.6943e-01, time/batch = 15.3016s	
11561/22300 (epoch 25.922), train_loss = 0.57781056, grad/param norm = 3.4511e-01, time/batch = 15.8117s	
11562/22300 (epoch 25.924), train_loss = 0.37188109, grad/param norm = 2.3353e-01, time/batch = 14.9375s	
11563/22300 (epoch 25.926), train_loss = 0.45570089, grad/param norm = 2.6164e-01, time/batch = 15.6998s	
11564/22300 (epoch 25.928), train_loss = 0.54313123, grad/param norm = 3.2522e-01, time/batch = 15.3329s	
11565/22300 (epoch 25.930), train_loss = 0.52524716, grad/param norm = 2.7409e-01, time/batch = 15.3151s	
11566/22300 (epoch 25.933), train_loss = 0.59931225, grad/param norm = 2.8289e-01, time/batch = 14.9026s	
11567/22300 (epoch 25.935), train_loss = 0.58844467, grad/param norm = 3.1932e-01, time/batch = 16.4657s	
11568/22300 (epoch 25.937), train_loss = 0.70322392, grad/param norm = 3.4985e-01, time/batch = 29.9866s	
11569/22300 (epoch 25.939), train_loss = 0.65145405, grad/param norm = 3.2124e-01, time/batch = 15.3888s	
11570/22300 (epoch 25.942), train_loss = 0.76427283, grad/param norm = 3.5880e-01, time/batch = 15.6752s	
11571/22300 (epoch 25.944), train_loss = 0.82833124, grad/param norm = 3.6379e-01, time/batch = 15.4558s	
11572/22300 (epoch 25.946), train_loss = 0.59211233, grad/param norm = 2.9995e-01, time/batch = 14.4741s	
11573/22300 (epoch 25.948), train_loss = 0.51291159, grad/param norm = 2.7089e-01, time/batch = 14.8067s	
11574/22300 (epoch 25.951), train_loss = 0.42747801, grad/param norm = 2.1529e-01, time/batch = 14.4901s	
11575/22300 (epoch 25.953), train_loss = 0.49101011, grad/param norm = 2.5695e-01, time/batch = 14.7941s	
11576/22300 (epoch 25.955), train_loss = 0.70211747, grad/param norm = 2.8796e-01, time/batch = 14.2479s	
11577/22300 (epoch 25.957), train_loss = 0.80402219, grad/param norm = 3.1143e-01, time/batch = 14.6681s	
11578/22300 (epoch 25.960), train_loss = 0.69897078, grad/param norm = 3.2947e-01, time/batch = 14.8051s	
11579/22300 (epoch 25.962), train_loss = 0.48679105, grad/param norm = 2.5256e-01, time/batch = 14.7354s	
11580/22300 (epoch 25.964), train_loss = 0.51652969, grad/param norm = 2.7406e-01, time/batch = 14.1731s	
11581/22300 (epoch 25.966), train_loss = 0.50007512, grad/param norm = 2.9431e-01, time/batch = 14.5809s	
11582/22300 (epoch 25.969), train_loss = 0.54507940, grad/param norm = 2.5250e-01, time/batch = 14.2487s	
11583/22300 (epoch 25.971), train_loss = 0.54493461, grad/param norm = 2.6027e-01, time/batch = 14.5697s	
11584/22300 (epoch 25.973), train_loss = 0.55428118, grad/param norm = 2.8328e-01, time/batch = 14.3263s	
11585/22300 (epoch 25.975), train_loss = 0.73942959, grad/param norm = 3.2393e-01, time/batch = 14.4085s	
11586/22300 (epoch 25.978), train_loss = 0.64980404, grad/param norm = 3.0249e-01, time/batch = 13.9266s	
11587/22300 (epoch 25.980), train_loss = 0.73294345, grad/param norm = 3.6884e-01, time/batch = 14.8916s	
11588/22300 (epoch 25.982), train_loss = 0.45883925, grad/param norm = 2.5628e-01, time/batch = 14.1801s	
11589/22300 (epoch 25.984), train_loss = 0.56501060, grad/param norm = 2.7814e-01, time/batch = 15.1329s	
11590/22300 (epoch 25.987), train_loss = 0.52698639, grad/param norm = 2.9752e-01, time/batch = 14.8859s	
11591/22300 (epoch 25.989), train_loss = 0.49401058, grad/param norm = 2.6400e-01, time/batch = 15.8229s	
11592/22300 (epoch 25.991), train_loss = 0.79632514, grad/param norm = 3.5028e-01, time/batch = 15.0947s	
11593/22300 (epoch 25.993), train_loss = 1.00443637, grad/param norm = 4.0806e-01, time/batch = 14.5111s	
11594/22300 (epoch 25.996), train_loss = 0.94990347, grad/param norm = 4.1997e-01, time/batch = 14.5014s	
11595/22300 (epoch 25.998), train_loss = 0.60797998, grad/param norm = 3.0055e-01, time/batch = 14.7268s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
11596/22300 (epoch 26.000), train_loss = 0.49653256, grad/param norm = 3.1894e-01, time/batch = 14.8804s	
11597/22300 (epoch 26.002), train_loss = 0.84399809, grad/param norm = 3.1381e-01, time/batch = 14.7187s	
11598/22300 (epoch 26.004), train_loss = 0.60444212, grad/param norm = 2.7473e-01, time/batch = 14.7278s	
11599/22300 (epoch 26.007), train_loss = 0.64503681, grad/param norm = 3.6197e-01, time/batch = 14.7262s	
11600/22300 (epoch 26.009), train_loss = 0.63658442, grad/param norm = 3.1679e-01, time/batch = 14.2530s	
11601/22300 (epoch 26.011), train_loss = 0.80167433, grad/param norm = 3.3869e-01, time/batch = 14.5724s	
11602/22300 (epoch 26.013), train_loss = 0.61490632, grad/param norm = 2.6486e-01, time/batch = 14.3325s	
11603/22300 (epoch 26.016), train_loss = 0.50079605, grad/param norm = 3.0491e-01, time/batch = 14.6488s	
11604/22300 (epoch 26.018), train_loss = 0.61563416, grad/param norm = 3.1318e-01, time/batch = 14.4149s	
11605/22300 (epoch 26.020), train_loss = 0.53871697, grad/param norm = 2.9601e-01, time/batch = 14.2414s	
11606/22300 (epoch 26.022), train_loss = 0.48893121, grad/param norm = 3.1363e-01, time/batch = 14.2635s	
11607/22300 (epoch 26.025), train_loss = 0.48092193, grad/param norm = 2.4124e-01, time/batch = 14.7959s	
11608/22300 (epoch 26.027), train_loss = 0.48397461, grad/param norm = 2.3436e-01, time/batch = 14.6325s	
11609/22300 (epoch 26.029), train_loss = 0.49259124, grad/param norm = 2.2353e-01, time/batch = 14.2425s	
11610/22300 (epoch 26.031), train_loss = 0.49053836, grad/param norm = 2.5627e-01, time/batch = 14.1693s	
11611/22300 (epoch 26.034), train_loss = 0.51082600, grad/param norm = 2.8518e-01, time/batch = 14.5449s	
11612/22300 (epoch 26.036), train_loss = 0.42000796, grad/param norm = 2.2644e-01, time/batch = 14.8964s	
11613/22300 (epoch 26.038), train_loss = 0.46760465, grad/param norm = 2.9137e-01, time/batch = 17.2200s	
11614/22300 (epoch 26.040), train_loss = 0.52424088, grad/param norm = 2.8731e-01, time/batch = 14.2432s	
11615/22300 (epoch 26.043), train_loss = 0.76887995, grad/param norm = 2.9664e-01, time/batch = 14.4713s	
11616/22300 (epoch 26.045), train_loss = 0.65218895, grad/param norm = 2.8460e-01, time/batch = 14.7264s	
11617/22300 (epoch 26.047), train_loss = 0.66598647, grad/param norm = 2.7900e-01, time/batch = 14.8141s	
11618/22300 (epoch 26.049), train_loss = 0.54126599, grad/param norm = 3.1697e-01, time/batch = 15.2706s	
11619/22300 (epoch 26.052), train_loss = 0.62914872, grad/param norm = 3.1539e-01, time/batch = 15.3540s	
11620/22300 (epoch 26.054), train_loss = 0.60227827, grad/param norm = 2.9789e-01, time/batch = 14.5787s	
11621/22300 (epoch 26.056), train_loss = 0.34137755, grad/param norm = 2.5082e-01, time/batch = 15.5203s	
11622/22300 (epoch 26.058), train_loss = 0.52001047, grad/param norm = 2.8531e-01, time/batch = 14.5573s	
11623/22300 (epoch 26.061), train_loss = 0.47460158, grad/param norm = 3.0533e-01, time/batch = 15.3021s	
11624/22300 (epoch 26.063), train_loss = 0.70592114, grad/param norm = 3.9810e-01, time/batch = 14.5703s	
11625/22300 (epoch 26.065), train_loss = 0.73270208, grad/param norm = 3.5636e-01, time/batch = 14.8806s	
11626/22300 (epoch 26.067), train_loss = 0.52406858, grad/param norm = 2.9445e-01, time/batch = 15.4941s	
11627/22300 (epoch 26.070), train_loss = 0.57050599, grad/param norm = 3.3309e-01, time/batch = 15.0412s	
11628/22300 (epoch 26.072), train_loss = 0.63667435, grad/param norm = 2.9793e-01, time/batch = 14.4699s	
11629/22300 (epoch 26.074), train_loss = 0.59837129, grad/param norm = 3.5569e-01, time/batch = 14.9010s	
11630/22300 (epoch 26.076), train_loss = 0.61999063, grad/param norm = 3.0287e-01, time/batch = 14.6495s	
11631/22300 (epoch 26.078), train_loss = 0.67524528, grad/param norm = 3.0131e-01, time/batch = 14.8110s	
11632/22300 (epoch 26.081), train_loss = 0.69391211, grad/param norm = 3.2164e-01, time/batch = 14.7389s	
11633/22300 (epoch 26.083), train_loss = 0.79806435, grad/param norm = 3.5481e-01, time/batch = 14.8228s	
11634/22300 (epoch 26.085), train_loss = 0.79149486, grad/param norm = 3.2868e-01, time/batch = 14.8150s	
11635/22300 (epoch 26.087), train_loss = 0.65502869, grad/param norm = 2.8881e-01, time/batch = 15.1403s	
11636/22300 (epoch 26.090), train_loss = 0.54163319, grad/param norm = 2.7189e-01, time/batch = 15.0422s	
11637/22300 (epoch 26.092), train_loss = 0.48333320, grad/param norm = 3.0125e-01, time/batch = 14.7445s	
11638/22300 (epoch 26.094), train_loss = 0.43969542, grad/param norm = 2.4986e-01, time/batch = 14.9523s	
11639/22300 (epoch 26.096), train_loss = 0.76528135, grad/param norm = 3.7565e-01, time/batch = 14.6970s	
11640/22300 (epoch 26.099), train_loss = 0.50799934, grad/param norm = 2.5920e-01, time/batch = 14.1559s	
11641/22300 (epoch 26.101), train_loss = 0.65615696, grad/param norm = 3.2317e-01, time/batch = 14.0114s	
11642/22300 (epoch 26.103), train_loss = 0.56811333, grad/param norm = 2.7842e-01, time/batch = 14.9838s	
11643/22300 (epoch 26.105), train_loss = 0.48456196, grad/param norm = 2.5692e-01, time/batch = 14.5579s	
11644/22300 (epoch 26.108), train_loss = 0.58582064, grad/param norm = 2.4992e-01, time/batch = 14.4921s	
11645/22300 (epoch 26.110), train_loss = 0.65312310, grad/param norm = 2.7107e-01, time/batch = 14.5697s	
11646/22300 (epoch 26.112), train_loss = 0.58074730, grad/param norm = 2.5825e-01, time/batch = 14.4091s	
11647/22300 (epoch 26.114), train_loss = 0.66729273, grad/param norm = 3.1811e-01, time/batch = 15.1272s	
11648/22300 (epoch 26.117), train_loss = 0.75171222, grad/param norm = 3.0182e-01, time/batch = 14.2512s	
11649/22300 (epoch 26.119), train_loss = 0.69700554, grad/param norm = 3.3778e-01, time/batch = 14.4065s	
11650/22300 (epoch 26.121), train_loss = 0.77047804, grad/param norm = 3.6242e-01, time/batch = 14.4165s	
11651/22300 (epoch 26.123), train_loss = 0.77155580, grad/param norm = 3.2287e-01, time/batch = 14.3227s	
11652/22300 (epoch 26.126), train_loss = 0.62803268, grad/param norm = 3.0376e-01, time/batch = 15.2079s	
11653/22300 (epoch 26.128), train_loss = 0.67450954, grad/param norm = 3.2432e-01, time/batch = 14.2368s	
11654/22300 (epoch 26.130), train_loss = 0.50772441, grad/param norm = 2.4396e-01, time/batch = 15.6611s	
11655/22300 (epoch 26.132), train_loss = 0.40618561, grad/param norm = 2.2428e-01, time/batch = 16.2968s	
11656/22300 (epoch 26.135), train_loss = 0.44206905, grad/param norm = 2.7206e-01, time/batch = 16.3600s	
11657/22300 (epoch 26.137), train_loss = 0.34778789, grad/param norm = 2.2511e-01, time/batch = 17.8854s	
11658/22300 (epoch 26.139), train_loss = 0.57044080, grad/param norm = 2.9440e-01, time/batch = 15.0593s	
11659/22300 (epoch 26.141), train_loss = 0.64840495, grad/param norm = 2.6050e-01, time/batch = 15.6178s	
11660/22300 (epoch 26.143), train_loss = 0.58047252, grad/param norm = 2.7935e-01, time/batch = 15.5078s	
11661/22300 (epoch 26.146), train_loss = 0.68525335, grad/param norm = 4.0535e-01, time/batch = 18.1323s	
11662/22300 (epoch 26.148), train_loss = 0.47898039, grad/param norm = 2.7184e-01, time/batch = 17.0258s	
11663/22300 (epoch 26.150), train_loss = 0.54950621, grad/param norm = 3.0498e-01, time/batch = 15.4335s	
11664/22300 (epoch 26.152), train_loss = 0.44445105, grad/param norm = 2.6838e-01, time/batch = 15.3094s	
11665/22300 (epoch 26.155), train_loss = 0.47074789, grad/param norm = 2.6567e-01, time/batch = 15.3767s	
11666/22300 (epoch 26.157), train_loss = 0.63906296, grad/param norm = 3.1813e-01, time/batch = 15.2243s	
11667/22300 (epoch 26.159), train_loss = 0.66176227, grad/param norm = 3.3455e-01, time/batch = 15.5473s	
11668/22300 (epoch 26.161), train_loss = 0.68309173, grad/param norm = 3.4335e-01, time/batch = 15.6934s	
11669/22300 (epoch 26.164), train_loss = 0.48217351, grad/param norm = 2.0135e-01, time/batch = 15.4847s	
11670/22300 (epoch 26.166), train_loss = 0.43050996, grad/param norm = 1.9774e-01, time/batch = 15.8065s	
11671/22300 (epoch 26.168), train_loss = 0.46152307, grad/param norm = 2.9222e-01, time/batch = 15.6259s	
11672/22300 (epoch 26.170), train_loss = 0.57286747, grad/param norm = 2.8625e-01, time/batch = 15.5658s	
11673/22300 (epoch 26.173), train_loss = 0.67746772, grad/param norm = 3.0419e-01, time/batch = 15.5392s	
11674/22300 (epoch 26.175), train_loss = 0.54501432, grad/param norm = 2.6162e-01, time/batch = 16.3720s	
11675/22300 (epoch 26.177), train_loss = 0.39253422, grad/param norm = 2.3815e-01, time/batch = 15.9794s	
11676/22300 (epoch 26.179), train_loss = 0.57193883, grad/param norm = 2.6843e-01, time/batch = 16.5620s	
11677/22300 (epoch 26.182), train_loss = 0.73531000, grad/param norm = 2.8784e-01, time/batch = 15.7095s	
11678/22300 (epoch 26.184), train_loss = 0.80433249, grad/param norm = 3.2374e-01, time/batch = 15.4459s	
11679/22300 (epoch 26.186), train_loss = 0.59349845, grad/param norm = 2.7589e-01, time/batch = 15.6512s	
11680/22300 (epoch 26.188), train_loss = 0.79688791, grad/param norm = 3.1032e-01, time/batch = 15.4027s	
11681/22300 (epoch 26.191), train_loss = 0.70334559, grad/param norm = 3.2656e-01, time/batch = 16.1447s	
11682/22300 (epoch 26.193), train_loss = 0.59926287, grad/param norm = 3.1718e-01, time/batch = 16.0398s	
11683/22300 (epoch 26.195), train_loss = 0.56769757, grad/param norm = 2.9527e-01, time/batch = 15.4738s	
11684/22300 (epoch 26.197), train_loss = 0.52607867, grad/param norm = 2.9690e-01, time/batch = 15.2155s	
11685/22300 (epoch 26.200), train_loss = 0.44893509, grad/param norm = 2.4918e-01, time/batch = 16.1219s	
11686/22300 (epoch 26.202), train_loss = 0.50295377, grad/param norm = 2.4677e-01, time/batch = 17.8725s	
11687/22300 (epoch 26.204), train_loss = 0.54781015, grad/param norm = 2.6279e-01, time/batch = 18.4691s	
11688/22300 (epoch 26.206), train_loss = 0.47900363, grad/param norm = 2.6818e-01, time/batch = 15.5380s	
11689/22300 (epoch 26.209), train_loss = 0.53499913, grad/param norm = 2.5027e-01, time/batch = 15.9464s	
11690/22300 (epoch 26.211), train_loss = 0.43685048, grad/param norm = 2.9620e-01, time/batch = 15.3508s	
11691/22300 (epoch 26.213), train_loss = 0.56509022, grad/param norm = 3.1892e-01, time/batch = 17.3635s	
11692/22300 (epoch 26.215), train_loss = 0.72365757, grad/param norm = 3.4458e-01, time/batch = 16.1401s	
11693/22300 (epoch 26.217), train_loss = 0.74327619, grad/param norm = 3.1284e-01, time/batch = 15.0425s	
11694/22300 (epoch 26.220), train_loss = 0.52036508, grad/param norm = 2.5551e-01, time/batch = 15.3644s	
11695/22300 (epoch 26.222), train_loss = 0.49642775, grad/param norm = 2.6586e-01, time/batch = 16.4489s	
11696/22300 (epoch 26.224), train_loss = 0.52842308, grad/param norm = 3.0185e-01, time/batch = 15.7694s	
11697/22300 (epoch 26.226), train_loss = 0.58019350, grad/param norm = 3.0727e-01, time/batch = 15.4734s	
11698/22300 (epoch 26.229), train_loss = 0.46005771, grad/param norm = 3.0149e-01, time/batch = 16.8729s	
11699/22300 (epoch 26.231), train_loss = 0.68901879, grad/param norm = 3.9947e-01, time/batch = 17.8737s	
11700/22300 (epoch 26.233), train_loss = 0.57125138, grad/param norm = 2.9672e-01, time/batch = 15.2006s	
11701/22300 (epoch 26.235), train_loss = 0.45377373, grad/param norm = 2.6941e-01, time/batch = 15.6195s	
11702/22300 (epoch 26.238), train_loss = 0.43827059, grad/param norm = 2.2348e-01, time/batch = 16.5949s	
11703/22300 (epoch 26.240), train_loss = 0.47038561, grad/param norm = 2.0038e-01, time/batch = 18.6144s	
11704/22300 (epoch 26.242), train_loss = 0.46614393, grad/param norm = 2.4771e-01, time/batch = 15.6424s	
11705/22300 (epoch 26.244), train_loss = 0.31614468, grad/param norm = 1.9822e-01, time/batch = 15.5261s	
11706/22300 (epoch 26.247), train_loss = 0.43587099, grad/param norm = 2.1966e-01, time/batch = 15.6363s	
11707/22300 (epoch 26.249), train_loss = 0.31157186, grad/param norm = 1.9314e-01, time/batch = 15.9961s	
11708/22300 (epoch 26.251), train_loss = 0.40910467, grad/param norm = 1.9757e-01, time/batch = 15.8970s	
11709/22300 (epoch 26.253), train_loss = 0.31072448, grad/param norm = 2.4267e-01, time/batch = 15.8843s	
11710/22300 (epoch 26.256), train_loss = 0.40568471, grad/param norm = 2.5360e-01, time/batch = 15.7203s	
11711/22300 (epoch 26.258), train_loss = 0.59702351, grad/param norm = 2.7045e-01, time/batch = 15.8679s	
11712/22300 (epoch 26.260), train_loss = 0.56059170, grad/param norm = 2.8300e-01, time/batch = 15.8092s	
11713/22300 (epoch 26.262), train_loss = 0.42992262, grad/param norm = 2.3402e-01, time/batch = 15.7052s	
11714/22300 (epoch 26.265), train_loss = 0.40862819, grad/param norm = 2.4892e-01, time/batch = 15.6233s	
11715/22300 (epoch 26.267), train_loss = 0.45200891, grad/param norm = 2.2510e-01, time/batch = 15.7051s	
11716/22300 (epoch 26.269), train_loss = 0.53116946, grad/param norm = 2.8710e-01, time/batch = 15.6362s	
11717/22300 (epoch 26.271), train_loss = 0.61127898, grad/param norm = 3.2185e-01, time/batch = 15.6459s	
11718/22300 (epoch 26.274), train_loss = 0.42268976, grad/param norm = 2.4075e-01, time/batch = 15.4714s	
11719/22300 (epoch 26.276), train_loss = 0.36810815, grad/param norm = 2.1515e-01, time/batch = 15.7998s	
11720/22300 (epoch 26.278), train_loss = 0.35730861, grad/param norm = 1.9681e-01, time/batch = 15.7207s	
11721/22300 (epoch 26.280), train_loss = 0.44441870, grad/param norm = 2.5389e-01, time/batch = 15.9055s	
11722/22300 (epoch 26.283), train_loss = 0.33810976, grad/param norm = 1.8864e-01, time/batch = 15.6960s	
11723/22300 (epoch 26.285), train_loss = 0.42484927, grad/param norm = 2.8095e-01, time/batch = 15.7059s	
11724/22300 (epoch 26.287), train_loss = 0.55029864, grad/param norm = 2.6122e-01, time/batch = 15.8191s	
11725/22300 (epoch 26.289), train_loss = 0.48029721, grad/param norm = 2.2141e-01, time/batch = 15.8145s	
11726/22300 (epoch 26.291), train_loss = 0.50230644, grad/param norm = 2.4267e-01, time/batch = 15.7840s	
11727/22300 (epoch 26.294), train_loss = 0.38997289, grad/param norm = 1.8900e-01, time/batch = 15.5498s	
11728/22300 (epoch 26.296), train_loss = 0.49808306, grad/param norm = 2.7196e-01, time/batch = 15.8158s	
11729/22300 (epoch 26.298), train_loss = 0.61377628, grad/param norm = 2.7208e-01, time/batch = 15.8749s	
11730/22300 (epoch 26.300), train_loss = 0.66353509, grad/param norm = 2.7043e-01, time/batch = 15.9162s	
11731/22300 (epoch 26.303), train_loss = 0.50404174, grad/param norm = 2.2827e-01, time/batch = 16.1706s	
11732/22300 (epoch 26.305), train_loss = 0.53294620, grad/param norm = 3.5990e-01, time/batch = 15.8713s	
11733/22300 (epoch 26.307), train_loss = 0.47485794, grad/param norm = 2.9716e-01, time/batch = 15.8956s	
11734/22300 (epoch 26.309), train_loss = 0.44612005, grad/param norm = 2.5673e-01, time/batch = 16.0214s	
11735/22300 (epoch 26.312), train_loss = 0.37302240, grad/param norm = 1.8983e-01, time/batch = 15.9480s	
11736/22300 (epoch 26.314), train_loss = 0.42326963, grad/param norm = 2.5039e-01, time/batch = 15.9704s	
11737/22300 (epoch 26.316), train_loss = 0.43546153, grad/param norm = 2.3793e-01, time/batch = 15.6238s	
11738/22300 (epoch 26.318), train_loss = 0.49250929, grad/param norm = 2.7484e-01, time/batch = 15.7875s	
11739/22300 (epoch 26.321), train_loss = 0.61990538, grad/param norm = 2.8965e-01, time/batch = 15.7109s	
11740/22300 (epoch 26.323), train_loss = 0.43320249, grad/param norm = 2.5104e-01, time/batch = 15.7238s	
11741/22300 (epoch 26.325), train_loss = 0.39716909, grad/param norm = 2.3196e-01, time/batch = 15.9675s	
11742/22300 (epoch 26.327), train_loss = 0.41219048, grad/param norm = 2.1564e-01, time/batch = 15.8674s	
11743/22300 (epoch 26.330), train_loss = 0.41927926, grad/param norm = 2.6280e-01, time/batch = 15.7969s	
11744/22300 (epoch 26.332), train_loss = 0.39602287, grad/param norm = 2.2617e-01, time/batch = 15.8586s	
11745/22300 (epoch 26.334), train_loss = 0.45351597, grad/param norm = 2.8084e-01, time/batch = 15.6107s	
11746/22300 (epoch 26.336), train_loss = 0.46973765, grad/param norm = 2.5416e-01, time/batch = 15.6445s	
11747/22300 (epoch 26.339), train_loss = 0.54593262, grad/param norm = 2.8561e-01, time/batch = 15.6183s	
11748/22300 (epoch 26.341), train_loss = 0.54321783, grad/param norm = 2.5355e-01, time/batch = 15.5714s	
11749/22300 (epoch 26.343), train_loss = 0.62518790, grad/param norm = 3.0971e-01, time/batch = 15.7158s	
11750/22300 (epoch 26.345), train_loss = 0.48379042, grad/param norm = 2.7725e-01, time/batch = 15.7980s	
11751/22300 (epoch 26.348), train_loss = 0.47977966, grad/param norm = 2.4240e-01, time/batch = 16.2972s	
11752/22300 (epoch 26.350), train_loss = 0.40520277, grad/param norm = 2.1434e-01, time/batch = 15.9613s	
11753/22300 (epoch 26.352), train_loss = 0.52805547, grad/param norm = 2.6905e-01, time/batch = 15.8661s	
11754/22300 (epoch 26.354), train_loss = 0.74236210, grad/param norm = 3.2041e-01, time/batch = 15.8110s	
11755/22300 (epoch 26.357), train_loss = 0.61814997, grad/param norm = 2.4011e-01, time/batch = 15.7410s	
11756/22300 (epoch 26.359), train_loss = 0.43450426, grad/param norm = 2.5550e-01, time/batch = 15.7289s	
11757/22300 (epoch 26.361), train_loss = 0.43310191, grad/param norm = 2.6728e-01, time/batch = 15.7118s	
11758/22300 (epoch 26.363), train_loss = 0.61815159, grad/param norm = 3.1236e-01, time/batch = 15.8797s	
11759/22300 (epoch 26.365), train_loss = 0.49225216, grad/param norm = 2.6487e-01, time/batch = 15.8569s	
11760/22300 (epoch 26.368), train_loss = 0.49555155, grad/param norm = 3.0385e-01, time/batch = 15.7967s	
11761/22300 (epoch 26.370), train_loss = 0.47284484, grad/param norm = 2.3938e-01, time/batch = 16.1930s	
11762/22300 (epoch 26.372), train_loss = 0.37946756, grad/param norm = 2.1939e-01, time/batch = 15.8918s	
11763/22300 (epoch 26.374), train_loss = 0.34551351, grad/param norm = 2.0032e-01, time/batch = 15.8328s	
11764/22300 (epoch 26.377), train_loss = 0.47713571, grad/param norm = 2.6876e-01, time/batch = 15.8826s	
11765/22300 (epoch 26.379), train_loss = 0.45819293, grad/param norm = 3.3685e-01, time/batch = 15.8038s	
11766/22300 (epoch 26.381), train_loss = 0.59004937, grad/param norm = 2.8034e-01, time/batch = 15.5610s	
11767/22300 (epoch 26.383), train_loss = 0.48111793, grad/param norm = 2.3898e-01, time/batch = 16.0097s	
11768/22300 (epoch 26.386), train_loss = 0.49571422, grad/param norm = 2.4452e-01, time/batch = 15.8024s	
11769/22300 (epoch 26.388), train_loss = 0.42771183, grad/param norm = 2.5094e-01, time/batch = 15.6329s	
11770/22300 (epoch 26.390), train_loss = 0.49893696, grad/param norm = 2.9259e-01, time/batch = 15.8726s	
11771/22300 (epoch 26.392), train_loss = 0.50473540, grad/param norm = 3.1341e-01, time/batch = 15.6883s	
11772/22300 (epoch 26.395), train_loss = 0.40931262, grad/param norm = 2.3943e-01, time/batch = 15.8890s	
11773/22300 (epoch 26.397), train_loss = 0.27132343, grad/param norm = 2.1127e-01, time/batch = 15.7350s	
11774/22300 (epoch 26.399), train_loss = 0.40232294, grad/param norm = 2.4494e-01, time/batch = 15.8121s	
11775/22300 (epoch 26.401), train_loss = 0.46096009, grad/param norm = 2.9445e-01, time/batch = 15.8575s	
11776/22300 (epoch 26.404), train_loss = 0.46493713, grad/param norm = 2.5333e-01, time/batch = 15.7219s	
11777/22300 (epoch 26.406), train_loss = 0.70514564, grad/param norm = 3.2736e-01, time/batch = 15.4871s	
11778/22300 (epoch 26.408), train_loss = 0.59288807, grad/param norm = 3.1953e-01, time/batch = 15.6323s	
11779/22300 (epoch 26.410), train_loss = 0.61248593, grad/param norm = 3.1963e-01, time/batch = 15.6042s	
11780/22300 (epoch 26.413), train_loss = 0.43288813, grad/param norm = 2.5210e-01, time/batch = 15.7504s	
11781/22300 (epoch 26.415), train_loss = 0.35882031, grad/param norm = 2.3046e-01, time/batch = 14.5428s	
11782/22300 (epoch 26.417), train_loss = 0.53517637, grad/param norm = 2.9262e-01, time/batch = 14.0895s	
11783/22300 (epoch 26.419), train_loss = 0.45366195, grad/param norm = 2.2629e-01, time/batch = 14.5611s	
11784/22300 (epoch 26.422), train_loss = 0.42827407, grad/param norm = 2.4886e-01, time/batch = 14.6606s	
11785/22300 (epoch 26.424), train_loss = 0.50700722, grad/param norm = 2.5093e-01, time/batch = 13.9262s	
11786/22300 (epoch 26.426), train_loss = 0.38255059, grad/param norm = 2.7421e-01, time/batch = 14.2500s	
11787/22300 (epoch 26.428), train_loss = 0.40067822, grad/param norm = 2.4251e-01, time/batch = 14.3780s	
11788/22300 (epoch 26.430), train_loss = 0.48860451, grad/param norm = 3.2148e-01, time/batch = 14.4943s	
11789/22300 (epoch 26.433), train_loss = 0.48294367, grad/param norm = 2.9123e-01, time/batch = 15.1965s	
11790/22300 (epoch 26.435), train_loss = 0.46194301, grad/param norm = 2.6276e-01, time/batch = 14.8116s	
11791/22300 (epoch 26.437), train_loss = 0.53205415, grad/param norm = 3.0122e-01, time/batch = 14.9589s	
11792/22300 (epoch 26.439), train_loss = 0.58587388, grad/param norm = 3.0294e-01, time/batch = 15.2985s	
11793/22300 (epoch 26.442), train_loss = 0.52490081, grad/param norm = 2.6869e-01, time/batch = 14.4899s	
11794/22300 (epoch 26.444), train_loss = 0.41463841, grad/param norm = 2.1251e-01, time/batch = 14.3377s	
11795/22300 (epoch 26.446), train_loss = 0.43469616, grad/param norm = 2.8496e-01, time/batch = 14.5594s	
11796/22300 (epoch 26.448), train_loss = 0.30988962, grad/param norm = 1.6412e-01, time/batch = 14.4831s	
11797/22300 (epoch 26.451), train_loss = 0.53473725, grad/param norm = 2.4858e-01, time/batch = 14.5744s	
11798/22300 (epoch 26.453), train_loss = 0.44131186, grad/param norm = 2.5286e-01, time/batch = 14.6543s	
11799/22300 (epoch 26.455), train_loss = 0.61153251, grad/param norm = 3.7066e-01, time/batch = 14.6542s	
11800/22300 (epoch 26.457), train_loss = 0.65730257, grad/param norm = 2.9108e-01, time/batch = 28.7762s	
11801/22300 (epoch 26.460), train_loss = 0.60246509, grad/param norm = 3.3377e-01, time/batch = 14.8965s	
11802/22300 (epoch 26.462), train_loss = 0.61427121, grad/param norm = 2.7325e-01, time/batch = 15.5916s	
11803/22300 (epoch 26.464), train_loss = 0.56476487, grad/param norm = 2.9920e-01, time/batch = 15.4348s	
11804/22300 (epoch 26.466), train_loss = 0.44461322, grad/param norm = 2.3927e-01, time/batch = 14.8210s	
11805/22300 (epoch 26.469), train_loss = 0.43878253, grad/param norm = 1.9831e-01, time/batch = 14.4109s	
11806/22300 (epoch 26.471), train_loss = 0.57461743, grad/param norm = 2.5531e-01, time/batch = 14.6554s	
11807/22300 (epoch 26.473), train_loss = 0.51753265, grad/param norm = 2.4629e-01, time/batch = 14.8206s	
11808/22300 (epoch 26.475), train_loss = 0.46174167, grad/param norm = 3.0279e-01, time/batch = 14.9794s	
11809/22300 (epoch 26.478), train_loss = 0.45099261, grad/param norm = 2.3593e-01, time/batch = 14.5031s	
11810/22300 (epoch 26.480), train_loss = 0.32614773, grad/param norm = 2.1386e-01, time/batch = 14.8141s	
11811/22300 (epoch 26.482), train_loss = 0.37131064, grad/param norm = 2.1991e-01, time/batch = 14.8967s	
11812/22300 (epoch 26.484), train_loss = 0.49394041, grad/param norm = 2.6583e-01, time/batch = 14.7084s	
11813/22300 (epoch 26.487), train_loss = 0.54312950, grad/param norm = 2.3836e-01, time/batch = 14.7244s	
11814/22300 (epoch 26.489), train_loss = 0.57429537, grad/param norm = 2.9017e-01, time/batch = 14.2376s	
11815/22300 (epoch 26.491), train_loss = 0.57050089, grad/param norm = 3.4547e-01, time/batch = 14.7185s	
11816/22300 (epoch 26.493), train_loss = 0.52711497, grad/param norm = 3.9915e-01, time/batch = 15.3442s	
11817/22300 (epoch 26.496), train_loss = 0.50080530, grad/param norm = 2.4309e-01, time/batch = 14.6507s	
11818/22300 (epoch 26.498), train_loss = 0.35846521, grad/param norm = 2.2784e-01, time/batch = 14.4204s	
11819/22300 (epoch 26.500), train_loss = 0.51072903, grad/param norm = 2.7818e-01, time/batch = 14.9702s	
11820/22300 (epoch 26.502), train_loss = 0.34728376, grad/param norm = 2.4977e-01, time/batch = 14.4883s	
11821/22300 (epoch 26.504), train_loss = 0.36336357, grad/param norm = 2.2150e-01, time/batch = 14.6484s	
11822/22300 (epoch 26.507), train_loss = 0.44297427, grad/param norm = 2.7803e-01, time/batch = 15.4981s	
11823/22300 (epoch 26.509), train_loss = 0.52744610, grad/param norm = 2.5113e-01, time/batch = 15.4502s	
11824/22300 (epoch 26.511), train_loss = 0.33334046, grad/param norm = 2.3636e-01, time/batch = 14.4923s	
11825/22300 (epoch 26.513), train_loss = 0.36045117, grad/param norm = 2.4797e-01, time/batch = 15.0394s	
11826/22300 (epoch 26.516), train_loss = 0.42309597, grad/param norm = 2.6976e-01, time/batch = 14.9799s	
11827/22300 (epoch 26.518), train_loss = 0.55310238, grad/param norm = 3.0893e-01, time/batch = 15.0514s	
11828/22300 (epoch 26.520), train_loss = 0.44004881, grad/param norm = 2.5841e-01, time/batch = 14.5780s	
11829/22300 (epoch 26.522), train_loss = 0.46210212, grad/param norm = 2.4607e-01, time/batch = 15.2058s	
11830/22300 (epoch 26.525), train_loss = 0.38565270, grad/param norm = 2.2942e-01, time/batch = 14.9715s	
11831/22300 (epoch 26.527), train_loss = 0.60517039, grad/param norm = 3.5628e-01, time/batch = 14.4817s	
11832/22300 (epoch 26.529), train_loss = 0.48657780, grad/param norm = 2.9254e-01, time/batch = 14.0838s	
11833/22300 (epoch 26.531), train_loss = 0.44689505, grad/param norm = 2.6820e-01, time/batch = 14.6352s	
11834/22300 (epoch 26.534), train_loss = 0.44452754, grad/param norm = 2.2595e-01, time/batch = 14.3441s	
11835/22300 (epoch 26.536), train_loss = 0.65914338, grad/param norm = 2.7365e-01, time/batch = 14.8094s	
11836/22300 (epoch 26.538), train_loss = 0.83155905, grad/param norm = 3.7461e-01, time/batch = 14.8060s	
11837/22300 (epoch 26.540), train_loss = 0.49222051, grad/param norm = 2.6753e-01, time/batch = 14.3373s	
11838/22300 (epoch 26.543), train_loss = 0.45134798, grad/param norm = 2.7584e-01, time/batch = 14.4181s	
11839/22300 (epoch 26.545), train_loss = 0.36039279, grad/param norm = 2.2483e-01, time/batch = 15.1693s	
11840/22300 (epoch 26.547), train_loss = 0.34504852, grad/param norm = 2.4192e-01, time/batch = 14.5692s	
11841/22300 (epoch 26.549), train_loss = 0.39616916, grad/param norm = 2.3350e-01, time/batch = 14.7238s	
11842/22300 (epoch 26.552), train_loss = 0.41095066, grad/param norm = 2.4987e-01, time/batch = 14.5795s	
11843/22300 (epoch 26.554), train_loss = 0.54355162, grad/param norm = 3.0571e-01, time/batch = 15.3274s	
11844/22300 (epoch 26.556), train_loss = 0.70043576, grad/param norm = 3.4219e-01, time/batch = 14.9395s	
11845/22300 (epoch 26.558), train_loss = 0.57526112, grad/param norm = 3.1907e-01, time/batch = 15.3755s	
11846/22300 (epoch 26.561), train_loss = 0.70020294, grad/param norm = 3.2361e-01, time/batch = 15.3026s	
11847/22300 (epoch 26.563), train_loss = 0.62307178, grad/param norm = 2.8605e-01, time/batch = 15.5778s	
11848/22300 (epoch 26.565), train_loss = 0.46045303, grad/param norm = 2.5847e-01, time/batch = 15.2141s	
11849/22300 (epoch 26.567), train_loss = 0.46149259, grad/param norm = 2.6918e-01, time/batch = 16.1473s	
11850/22300 (epoch 26.570), train_loss = 0.69918783, grad/param norm = 3.5933e-01, time/batch = 16.4634s	
11851/22300 (epoch 26.572), train_loss = 0.59343159, grad/param norm = 2.3914e-01, time/batch = 15.4635s	
11852/22300 (epoch 26.574), train_loss = 0.48898752, grad/param norm = 2.2729e-01, time/batch = 14.5674s	
11853/22300 (epoch 26.576), train_loss = 0.41168482, grad/param norm = 2.3639e-01, time/batch = 16.3122s	
11854/22300 (epoch 26.578), train_loss = 0.25528529, grad/param norm = 1.7931e-01, time/batch = 17.5316s	
11855/22300 (epoch 26.581), train_loss = 0.36073529, grad/param norm = 2.3134e-01, time/batch = 17.8627s	
11856/22300 (epoch 26.583), train_loss = 0.42772935, grad/param norm = 2.2900e-01, time/batch = 16.0522s	
11857/22300 (epoch 26.585), train_loss = 0.61202675, grad/param norm = 3.5374e-01, time/batch = 16.3185s	
11858/22300 (epoch 26.587), train_loss = 0.78436672, grad/param norm = 3.5168e-01, time/batch = 15.6996s	
11859/22300 (epoch 26.590), train_loss = 0.65225586, grad/param norm = 3.7794e-01, time/batch = 16.0427s	
11860/22300 (epoch 26.592), train_loss = 0.75589474, grad/param norm = 3.5981e-01, time/batch = 15.6171s	
11861/22300 (epoch 26.594), train_loss = 0.73098190, grad/param norm = 3.1840e-01, time/batch = 15.4802s	
11862/22300 (epoch 26.596), train_loss = 0.46852147, grad/param norm = 2.7320e-01, time/batch = 15.2116s	
11863/22300 (epoch 26.599), train_loss = 0.35890540, grad/param norm = 2.3828e-01, time/batch = 15.4641s	
11864/22300 (epoch 26.601), train_loss = 0.43765694, grad/param norm = 2.4057e-01, time/batch = 17.4640s	
11865/22300 (epoch 26.603), train_loss = 0.49347569, grad/param norm = 2.5810e-01, time/batch = 16.6879s	
11866/22300 (epoch 26.605), train_loss = 0.45003380, grad/param norm = 2.6018e-01, time/batch = 17.6280s	
11867/22300 (epoch 26.608), train_loss = 0.74219766, grad/param norm = 3.3797e-01, time/batch = 17.2806s	
11868/22300 (epoch 26.610), train_loss = 0.76626377, grad/param norm = 3.3765e-01, time/batch = 16.2915s	
11869/22300 (epoch 26.612), train_loss = 0.59786096, grad/param norm = 3.0974e-01, time/batch = 15.5417s	
11870/22300 (epoch 26.614), train_loss = 0.60535788, grad/param norm = 3.0725e-01, time/batch = 15.8903s	
11871/22300 (epoch 26.617), train_loss = 0.59675177, grad/param norm = 2.7947e-01, time/batch = 14.8123s	
11872/22300 (epoch 26.619), train_loss = 0.72615215, grad/param norm = 3.1749e-01, time/batch = 16.2303s	
11873/22300 (epoch 26.621), train_loss = 0.47245356, grad/param norm = 2.7285e-01, time/batch = 15.3792s	
11874/22300 (epoch 26.623), train_loss = 0.47499428, grad/param norm = 2.6867e-01, time/batch = 16.7126s	
11875/22300 (epoch 26.626), train_loss = 0.42505290, grad/param norm = 2.3100e-01, time/batch = 17.8818s	
11876/22300 (epoch 26.628), train_loss = 0.44423090, grad/param norm = 2.4118e-01, time/batch = 16.0409s	
11877/22300 (epoch 26.630), train_loss = 0.51931353, grad/param norm = 2.6913e-01, time/batch = 17.2074s	
11878/22300 (epoch 26.632), train_loss = 0.45947824, grad/param norm = 2.5622e-01, time/batch = 16.3078s	
11879/22300 (epoch 26.635), train_loss = 0.48856960, grad/param norm = 2.2963e-01, time/batch = 15.8247s	
11880/22300 (epoch 26.637), train_loss = 0.55008406, grad/param norm = 2.7724e-01, time/batch = 15.5770s	
11881/22300 (epoch 26.639), train_loss = 0.68166144, grad/param norm = 3.0429e-01, time/batch = 14.9729s	
11882/22300 (epoch 26.641), train_loss = 0.53989895, grad/param norm = 2.6490e-01, time/batch = 14.6651s	
11883/22300 (epoch 26.643), train_loss = 0.44890274, grad/param norm = 2.6781e-01, time/batch = 14.4985s	
11884/22300 (epoch 26.646), train_loss = 0.42451142, grad/param norm = 2.5367e-01, time/batch = 15.2775s	
11885/22300 (epoch 26.648), train_loss = 0.50212466, grad/param norm = 2.3714e-01, time/batch = 14.4091s	
11886/22300 (epoch 26.650), train_loss = 0.56889765, grad/param norm = 3.2516e-01, time/batch = 14.2472s	
11887/22300 (epoch 26.652), train_loss = 0.45138455, grad/param norm = 2.2184e-01, time/batch = 14.9534s	
11888/22300 (epoch 26.655), train_loss = 0.43363372, grad/param norm = 2.5904e-01, time/batch = 14.9512s	
11889/22300 (epoch 26.657), train_loss = 0.49401034, grad/param norm = 2.6652e-01, time/batch = 14.8003s	
11890/22300 (epoch 26.659), train_loss = 0.43978889, grad/param norm = 2.3646e-01, time/batch = 14.3259s	
11891/22300 (epoch 26.661), train_loss = 0.37045414, grad/param norm = 2.2163e-01, time/batch = 14.4141s	
11892/22300 (epoch 26.664), train_loss = 0.42221793, grad/param norm = 2.1841e-01, time/batch = 14.5714s	
11893/22300 (epoch 26.666), train_loss = 0.57190415, grad/param norm = 2.7086e-01, time/batch = 14.6478s	
11894/22300 (epoch 26.668), train_loss = 0.42224254, grad/param norm = 2.5260e-01, time/batch = 14.4799s	
11895/22300 (epoch 26.670), train_loss = 0.54503873, grad/param norm = 3.2442e-01, time/batch = 14.1512s	
11896/22300 (epoch 26.673), train_loss = 0.59622317, grad/param norm = 2.5686e-01, time/batch = 15.1066s	
11897/22300 (epoch 26.675), train_loss = 0.65529938, grad/param norm = 2.9372e-01, time/batch = 14.2446s	
11898/22300 (epoch 26.677), train_loss = 0.71112232, grad/param norm = 3.5033e-01, time/batch = 14.3365s	
11899/22300 (epoch 26.679), train_loss = 0.56358083, grad/param norm = 3.3084e-01, time/batch = 14.1700s	
11900/22300 (epoch 26.682), train_loss = 0.51518082, grad/param norm = 2.6674e-01, time/batch = 14.2441s	
11901/22300 (epoch 26.684), train_loss = 0.49352850, grad/param norm = 2.4724e-01, time/batch = 14.3199s	
11902/22300 (epoch 26.686), train_loss = 0.52186668, grad/param norm = 2.7038e-01, time/batch = 14.2391s	
11903/22300 (epoch 26.688), train_loss = 0.45782523, grad/param norm = 2.2637e-01, time/batch = 14.4949s	
11904/22300 (epoch 26.691), train_loss = 0.45372361, grad/param norm = 2.4935e-01, time/batch = 14.4137s	
11905/22300 (epoch 26.693), train_loss = 0.40629816, grad/param norm = 2.1327e-01, time/batch = 14.4057s	
11906/22300 (epoch 26.695), train_loss = 0.38929683, grad/param norm = 2.0676e-01, time/batch = 14.5741s	
11907/22300 (epoch 26.697), train_loss = 0.42148714, grad/param norm = 2.1401e-01, time/batch = 15.2374s	
11908/22300 (epoch 26.700), train_loss = 0.43085406, grad/param norm = 2.6210e-01, time/batch = 14.9664s	
11909/22300 (epoch 26.702), train_loss = 0.38154872, grad/param norm = 2.1616e-01, time/batch = 15.1144s	
11910/22300 (epoch 26.704), train_loss = 0.51075556, grad/param norm = 3.1307e-01, time/batch = 14.7278s	
11911/22300 (epoch 26.706), train_loss = 0.41053316, grad/param norm = 2.3325e-01, time/batch = 14.5596s	
11912/22300 (epoch 26.709), train_loss = 0.34609969, grad/param norm = 2.0685e-01, time/batch = 14.7303s	
11913/22300 (epoch 26.711), train_loss = 0.34765417, grad/param norm = 1.9099e-01, time/batch = 15.1925s	
11914/22300 (epoch 26.713), train_loss = 0.50060615, grad/param norm = 2.3560e-01, time/batch = 14.4137s	
11915/22300 (epoch 26.715), train_loss = 0.49578686, grad/param norm = 2.4568e-01, time/batch = 14.6525s	
11916/22300 (epoch 26.717), train_loss = 0.67644591, grad/param norm = 2.9978e-01, time/batch = 14.4785s	
11917/22300 (epoch 26.720), train_loss = 0.43688031, grad/param norm = 2.8712e-01, time/batch = 15.2091s	
11918/22300 (epoch 26.722), train_loss = 0.52172237, grad/param norm = 2.7243e-01, time/batch = 14.4992s	
11919/22300 (epoch 26.724), train_loss = 0.59046608, grad/param norm = 3.2178e-01, time/batch = 14.9714s	
11920/22300 (epoch 26.726), train_loss = 0.44173148, grad/param norm = 2.6056e-01, time/batch = 14.2379s	
11921/22300 (epoch 26.729), train_loss = 0.49006745, grad/param norm = 2.8540e-01, time/batch = 15.0395s	
11922/22300 (epoch 26.731), train_loss = 0.66747127, grad/param norm = 3.2994e-01, time/batch = 15.1991s	
11923/22300 (epoch 26.733), train_loss = 0.67866388, grad/param norm = 3.0879e-01, time/batch = 14.5775s	
11924/22300 (epoch 26.735), train_loss = 0.71942589, grad/param norm = 3.2909e-01, time/batch = 14.7341s	
11925/22300 (epoch 26.738), train_loss = 0.52920078, grad/param norm = 2.8388e-01, time/batch = 15.1991s	
11926/22300 (epoch 26.740), train_loss = 0.46888928, grad/param norm = 2.4192e-01, time/batch = 14.7347s	
11927/22300 (epoch 26.742), train_loss = 0.45083204, grad/param norm = 2.4006e-01, time/batch = 14.4060s	
11928/22300 (epoch 26.744), train_loss = 0.76682264, grad/param norm = 3.4371e-01, time/batch = 14.3328s	
11929/22300 (epoch 26.747), train_loss = 0.60812764, grad/param norm = 2.9723e-01, time/batch = 14.7930s	
11930/22300 (epoch 26.749), train_loss = 0.73672047, grad/param norm = 3.7105e-01, time/batch = 14.4092s	
11931/22300 (epoch 26.751), train_loss = 0.65901869, grad/param norm = 4.0905e-01, time/batch = 15.3314s	
11932/22300 (epoch 26.753), train_loss = 0.68947686, grad/param norm = 3.1839e-01, time/batch = 15.0933s	
11933/22300 (epoch 26.756), train_loss = 0.59178455, grad/param norm = 2.6982e-01, time/batch = 15.2542s	
11934/22300 (epoch 26.758), train_loss = 0.52280502, grad/param norm = 2.4004e-01, time/batch = 14.4147s	
11935/22300 (epoch 26.760), train_loss = 0.57088514, grad/param norm = 2.7138e-01, time/batch = 14.8879s	
11936/22300 (epoch 26.762), train_loss = 0.56637403, grad/param norm = 2.9498e-01, time/batch = 14.4150s	
11937/22300 (epoch 26.765), train_loss = 0.57708254, grad/param norm = 3.0659e-01, time/batch = 14.6556s	
11938/22300 (epoch 26.767), train_loss = 0.57697535, grad/param norm = 2.8896e-01, time/batch = 14.7183s	
11939/22300 (epoch 26.769), train_loss = 0.54333050, grad/param norm = 3.0623e-01, time/batch = 14.7279s	
11940/22300 (epoch 26.771), train_loss = 0.61728055, grad/param norm = 3.7177e-01, time/batch = 14.6293s	
11941/22300 (epoch 26.774), train_loss = 0.64921223, grad/param norm = 3.3781e-01, time/batch = 14.8167s	
11942/22300 (epoch 26.776), train_loss = 0.68170505, grad/param norm = 2.8489e-01, time/batch = 14.3203s	
11943/22300 (epoch 26.778), train_loss = 0.66645478, grad/param norm = 3.1764e-01, time/batch = 15.0386s	
11944/22300 (epoch 26.780), train_loss = 0.67571176, grad/param norm = 3.4639e-01, time/batch = 14.7109s	
11945/22300 (epoch 26.783), train_loss = 0.70547235, grad/param norm = 3.6938e-01, time/batch = 14.8198s	
11946/22300 (epoch 26.785), train_loss = 0.53658156, grad/param norm = 3.0902e-01, time/batch = 14.7274s	
11947/22300 (epoch 26.787), train_loss = 0.49616565, grad/param norm = 2.9112e-01, time/batch = 14.4187s	
11948/22300 (epoch 26.789), train_loss = 0.72416907, grad/param norm = 3.5096e-01, time/batch = 14.4971s	
11949/22300 (epoch 26.791), train_loss = 0.88448166, grad/param norm = 3.5542e-01, time/batch = 14.9690s	
11950/22300 (epoch 26.794), train_loss = 0.69623452, grad/param norm = 3.6044e-01, time/batch = 14.8042s	
11951/22300 (epoch 26.796), train_loss = 0.66114453, grad/param norm = 3.5134e-01, time/batch = 15.1704s	
11952/22300 (epoch 26.798), train_loss = 0.79946757, grad/param norm = 3.2538e-01, time/batch = 14.0877s	
11953/22300 (epoch 26.800), train_loss = 0.54367763, grad/param norm = 2.5839e-01, time/batch = 14.8596s	
11954/22300 (epoch 26.803), train_loss = 0.52449753, grad/param norm = 2.5358e-01, time/batch = 14.3277s	
11955/22300 (epoch 26.805), train_loss = 0.58935802, grad/param norm = 2.8083e-01, time/batch = 14.2441s	
11956/22300 (epoch 26.807), train_loss = 0.69691162, grad/param norm = 3.3127e-01, time/batch = 14.2468s	
11957/22300 (epoch 26.809), train_loss = 0.53469656, grad/param norm = 3.1889e-01, time/batch = 14.6019s	
11958/22300 (epoch 26.812), train_loss = 0.61090440, grad/param norm = 2.9029e-01, time/batch = 15.0158s	
11959/22300 (epoch 26.814), train_loss = 0.61706603, grad/param norm = 2.9799e-01, time/batch = 15.0264s	
11960/22300 (epoch 26.816), train_loss = 0.63014590, grad/param norm = 2.9899e-01, time/batch = 15.0416s	
11961/22300 (epoch 26.818), train_loss = 0.72475036, grad/param norm = 3.7179e-01, time/batch = 14.9753s	
11962/22300 (epoch 26.821), train_loss = 0.60968284, grad/param norm = 3.2706e-01, time/batch = 14.7968s	
11963/22300 (epoch 26.823), train_loss = 0.41010875, grad/param norm = 2.5345e-01, time/batch = 15.2319s	
11964/22300 (epoch 26.825), train_loss = 0.46023746, grad/param norm = 2.8170e-01, time/batch = 15.1412s	
11965/22300 (epoch 26.827), train_loss = 0.52198979, grad/param norm = 2.8540e-01, time/batch = 15.8205s	
11966/22300 (epoch 26.830), train_loss = 0.50354572, grad/param norm = 2.5339e-01, time/batch = 15.4863s	
11967/22300 (epoch 26.832), train_loss = 0.47711887, grad/param norm = 2.6153e-01, time/batch = 16.5675s	
11968/22300 (epoch 26.834), train_loss = 0.41400996, grad/param norm = 2.2081e-01, time/batch = 15.0487s	
11969/22300 (epoch 26.836), train_loss = 0.53782611, grad/param norm = 2.8584e-01, time/batch = 15.2953s	
11970/22300 (epoch 26.839), train_loss = 0.51833713, grad/param norm = 2.9979e-01, time/batch = 15.7241s	
11971/22300 (epoch 26.841), train_loss = 0.55722325, grad/param norm = 3.3524e-01, time/batch = 16.7987s	
11972/22300 (epoch 26.843), train_loss = 0.51061442, grad/param norm = 2.8642e-01, time/batch = 16.5039s	
11973/22300 (epoch 26.845), train_loss = 0.48282910, grad/param norm = 2.3628e-01, time/batch = 15.5656s	
11974/22300 (epoch 26.848), train_loss = 0.50779887, grad/param norm = 2.8337e-01, time/batch = 16.2273s	
11975/22300 (epoch 26.850), train_loss = 0.53190030, grad/param norm = 2.4615e-01, time/batch = 19.0214s	
11976/22300 (epoch 26.852), train_loss = 0.47736097, grad/param norm = 2.8339e-01, time/batch = 17.3576s	
11977/22300 (epoch 26.854), train_loss = 0.75130676, grad/param norm = 3.7968e-01, time/batch = 15.9423s	
11978/22300 (epoch 26.857), train_loss = 0.59583382, grad/param norm = 3.4079e-01, time/batch = 15.5556s	
11979/22300 (epoch 26.859), train_loss = 0.44548185, grad/param norm = 2.2934e-01, time/batch = 17.4634s	
11980/22300 (epoch 26.861), train_loss = 0.60722336, grad/param norm = 2.6901e-01, time/batch = 16.4603s	
11981/22300 (epoch 26.863), train_loss = 0.45300426, grad/param norm = 2.7141e-01, time/batch = 17.4656s	
11982/22300 (epoch 26.865), train_loss = 0.41862260, grad/param norm = 2.2331e-01, time/batch = 18.3625s	
11983/22300 (epoch 26.868), train_loss = 0.56348102, grad/param norm = 2.7092e-01, time/batch = 15.8904s	
11984/22300 (epoch 26.870), train_loss = 0.58311214, grad/param norm = 2.9349e-01, time/batch = 16.8840s	
11985/22300 (epoch 26.872), train_loss = 0.65984992, grad/param norm = 3.0545e-01, time/batch = 16.8115s	
11986/22300 (epoch 26.874), train_loss = 0.57590108, grad/param norm = 2.8368e-01, time/batch = 15.5389s	
11987/22300 (epoch 26.877), train_loss = 0.57873264, grad/param norm = 2.9743e-01, time/batch = 15.1025s	
11988/22300 (epoch 26.879), train_loss = 0.48207908, grad/param norm = 2.9347e-01, time/batch = 17.9812s	
11989/22300 (epoch 26.881), train_loss = 0.44960447, grad/param norm = 2.6122e-01, time/batch = 17.5517s	
11990/22300 (epoch 26.883), train_loss = 0.43455628, grad/param norm = 2.3914e-01, time/batch = 15.6704s	
11991/22300 (epoch 26.886), train_loss = 0.42217596, grad/param norm = 2.3706e-01, time/batch = 15.5095s	
11992/22300 (epoch 26.888), train_loss = 0.47894424, grad/param norm = 2.3495e-01, time/batch = 15.2010s	
11993/22300 (epoch 26.890), train_loss = 0.47332708, grad/param norm = 2.2775e-01, time/batch = 15.0958s	
11994/22300 (epoch 26.892), train_loss = 0.68315242, grad/param norm = 3.2367e-01, time/batch = 15.1316s	
11995/22300 (epoch 26.895), train_loss = 0.66375310, grad/param norm = 3.5684e-01, time/batch = 15.0596s	
11996/22300 (epoch 26.897), train_loss = 0.53825333, grad/param norm = 2.9622e-01, time/batch = 15.1822s	
11997/22300 (epoch 26.899), train_loss = 0.50868959, grad/param norm = 2.3470e-01, time/batch = 15.4033s	
11998/22300 (epoch 26.901), train_loss = 0.58108250, grad/param norm = 2.8711e-01, time/batch = 16.4738s	
11999/22300 (epoch 26.904), train_loss = 0.61951062, grad/param norm = 2.7262e-01, time/batch = 14.5856s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch26.91_1.5578.t7	
12000/22300 (epoch 26.906), train_loss = 0.57466020, grad/param norm = 2.4225e-01, time/batch = 14.8901s	
12001/22300 (epoch 26.908), train_loss = 1.09062466, grad/param norm = 3.5689e-01, time/batch = 17.3017s	
12002/22300 (epoch 26.910), train_loss = 0.44421507, grad/param norm = 2.5998e-01, time/batch = 15.4394s	
12003/22300 (epoch 26.913), train_loss = 0.60209234, grad/param norm = 3.0449e-01, time/batch = 17.9513s	
12004/22300 (epoch 26.915), train_loss = 0.70746820, grad/param norm = 2.9085e-01, time/batch = 15.0700s	
12005/22300 (epoch 26.917), train_loss = 0.59417925, grad/param norm = 2.9780e-01, time/batch = 17.5331s	
12006/22300 (epoch 26.919), train_loss = 0.61303609, grad/param norm = 2.8050e-01, time/batch = 17.1419s	
12007/22300 (epoch 26.922), train_loss = 0.54443492, grad/param norm = 3.0374e-01, time/batch = 16.9520s	
12008/22300 (epoch 26.924), train_loss = 0.35646810, grad/param norm = 2.1397e-01, time/batch = 15.5414s	
12009/22300 (epoch 26.926), train_loss = 0.42303627, grad/param norm = 2.0499e-01, time/batch = 16.1369s	
12010/22300 (epoch 26.928), train_loss = 0.52110465, grad/param norm = 3.2077e-01, time/batch = 16.6185s	
12011/22300 (epoch 26.930), train_loss = 0.49387814, grad/param norm = 2.8729e-01, time/batch = 15.5266s	
12012/22300 (epoch 26.933), train_loss = 0.58931172, grad/param norm = 2.8347e-01, time/batch = 15.7343s	
12013/22300 (epoch 26.935), train_loss = 0.57715862, grad/param norm = 2.9657e-01, time/batch = 15.7840s	
12014/22300 (epoch 26.937), train_loss = 0.66537439, grad/param norm = 3.1486e-01, time/batch = 15.6337s	
12015/22300 (epoch 26.939), train_loss = 0.62387857, grad/param norm = 2.9079e-01, time/batch = 15.9437s	
12016/22300 (epoch 26.942), train_loss = 0.74057392, grad/param norm = 3.3150e-01, time/batch = 15.7075s	
12017/22300 (epoch 26.944), train_loss = 0.84782781, grad/param norm = 4.2026e-01, time/batch = 15.4755s	
12018/22300 (epoch 26.946), train_loss = 0.57404518, grad/param norm = 2.8022e-01, time/batch = 15.7907s	
12019/22300 (epoch 26.948), train_loss = 0.46628329, grad/param norm = 2.2667e-01, time/batch = 15.9646s	
12020/22300 (epoch 26.951), train_loss = 0.40947773, grad/param norm = 2.2982e-01, time/batch = 15.9637s	
12021/22300 (epoch 26.953), train_loss = 0.46858957, grad/param norm = 2.6685e-01, time/batch = 15.7989s	
12022/22300 (epoch 26.955), train_loss = 0.66662029, grad/param norm = 2.8259e-01, time/batch = 15.7971s	
12023/22300 (epoch 26.957), train_loss = 0.78784213, grad/param norm = 3.3011e-01, time/batch = 15.5630s	
12024/22300 (epoch 26.960), train_loss = 0.67514157, grad/param norm = 3.1969e-01, time/batch = 15.9976s	
12025/22300 (epoch 26.962), train_loss = 0.47930073, grad/param norm = 2.6936e-01, time/batch = 15.9596s	
12026/22300 (epoch 26.964), train_loss = 0.52257488, grad/param norm = 3.4798e-01, time/batch = 25.4132s	
12027/22300 (epoch 26.966), train_loss = 0.44199516, grad/param norm = 2.6430e-01, time/batch = 20.0747s	
12028/22300 (epoch 26.969), train_loss = 0.52485593, grad/param norm = 2.5615e-01, time/batch = 15.5979s	
12029/22300 (epoch 26.971), train_loss = 0.54358198, grad/param norm = 2.7421e-01, time/batch = 15.9587s	
12030/22300 (epoch 26.973), train_loss = 0.53948796, grad/param norm = 2.7171e-01, time/batch = 15.9176s	
12031/22300 (epoch 26.975), train_loss = 0.71496873, grad/param norm = 3.3342e-01, time/batch = 15.9424s	
12032/22300 (epoch 26.978), train_loss = 0.64536688, grad/param norm = 2.9684e-01, time/batch = 15.5477s	
12033/22300 (epoch 26.980), train_loss = 0.70585580, grad/param norm = 2.7241e-01, time/batch = 15.8871s	
12034/22300 (epoch 26.982), train_loss = 0.43734665, grad/param norm = 2.6367e-01, time/batch = 15.8204s	
12035/22300 (epoch 26.984), train_loss = 0.56138934, grad/param norm = 2.6268e-01, time/batch = 15.7277s	
12036/22300 (epoch 26.987), train_loss = 0.51746181, grad/param norm = 2.9239e-01, time/batch = 15.6968s	
12037/22300 (epoch 26.989), train_loss = 0.48410019, grad/param norm = 2.7179e-01, time/batch = 15.6990s	
12038/22300 (epoch 26.991), train_loss = 0.76381790, grad/param norm = 3.8047e-01, time/batch = 15.3256s	
12039/22300 (epoch 26.993), train_loss = 0.96686578, grad/param norm = 3.8841e-01, time/batch = 15.5699s	
12040/22300 (epoch 26.996), train_loss = 0.88596049, grad/param norm = 3.6061e-01, time/batch = 15.7969s	
12041/22300 (epoch 26.998), train_loss = 0.58156032, grad/param norm = 2.6368e-01, time/batch = 16.6883s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
12042/22300 (epoch 27.000), train_loss = 0.44801305, grad/param norm = 2.4124e-01, time/batch = 15.8023s	
12043/22300 (epoch 27.002), train_loss = 0.83651059, grad/param norm = 3.1093e-01, time/batch = 15.8178s	
12044/22300 (epoch 27.004), train_loss = 0.57655233, grad/param norm = 2.8033e-01, time/batch = 15.9543s	
12045/22300 (epoch 27.007), train_loss = 0.58464185, grad/param norm = 2.6597e-01, time/batch = 15.7948s	
12046/22300 (epoch 27.009), train_loss = 0.62404713, grad/param norm = 3.1184e-01, time/batch = 15.4871s	
12047/22300 (epoch 27.011), train_loss = 0.78365361, grad/param norm = 3.6675e-01, time/batch = 15.6949s	
12048/22300 (epoch 27.013), train_loss = 0.61051726, grad/param norm = 3.2253e-01, time/batch = 15.9629s	
12049/22300 (epoch 27.016), train_loss = 0.49523485, grad/param norm = 3.0391e-01, time/batch = 15.5539s	
12050/22300 (epoch 27.018), train_loss = 0.61749091, grad/param norm = 3.6528e-01, time/batch = 15.8127s	
12051/22300 (epoch 27.020), train_loss = 0.53300968, grad/param norm = 3.1575e-01, time/batch = 15.6365s	
12052/22300 (epoch 27.022), train_loss = 0.47423617, grad/param norm = 3.0581e-01, time/batch = 15.8909s	
12053/22300 (epoch 27.025), train_loss = 0.47298152, grad/param norm = 2.5466e-01, time/batch = 15.7539s	
12054/22300 (epoch 27.027), train_loss = 0.46136949, grad/param norm = 2.2108e-01, time/batch = 15.7143s	
12055/22300 (epoch 27.029), train_loss = 0.47858836, grad/param norm = 2.0753e-01, time/batch = 15.6914s	
12056/22300 (epoch 27.031), train_loss = 0.48539866, grad/param norm = 2.4952e-01, time/batch = 15.8839s	
12057/22300 (epoch 27.034), train_loss = 0.48819344, grad/param norm = 2.7426e-01, time/batch = 16.2077s	
12058/22300 (epoch 27.036), train_loss = 0.40368372, grad/param norm = 1.9580e-01, time/batch = 15.9828s	
12059/22300 (epoch 27.038), train_loss = 0.44570860, grad/param norm = 2.3806e-01, time/batch = 15.7877s	
12060/22300 (epoch 27.040), train_loss = 0.49525327, grad/param norm = 2.6922e-01, time/batch = 16.0640s	
12061/22300 (epoch 27.043), train_loss = 0.76434545, grad/param norm = 3.0498e-01, time/batch = 16.1094s	
12062/22300 (epoch 27.045), train_loss = 0.63213060, grad/param norm = 3.0866e-01, time/batch = 15.9827s	
12063/22300 (epoch 27.047), train_loss = 0.63930959, grad/param norm = 2.9925e-01, time/batch = 15.6260s	
12064/22300 (epoch 27.049), train_loss = 0.54612205, grad/param norm = 3.1825e-01, time/batch = 15.7185s	
12065/22300 (epoch 27.052), train_loss = 0.62946806, grad/param norm = 3.5668e-01, time/batch = 15.9727s	
12066/22300 (epoch 27.054), train_loss = 0.61604005, grad/param norm = 3.1995e-01, time/batch = 15.8003s	
12067/22300 (epoch 27.056), train_loss = 0.30719905, grad/param norm = 1.9597e-01, time/batch = 16.2242s	
12068/22300 (epoch 27.058), train_loss = 0.49150690, grad/param norm = 2.3970e-01, time/batch = 15.9357s	
12069/22300 (epoch 27.061), train_loss = 0.43773187, grad/param norm = 2.9318e-01, time/batch = 16.0612s	
12070/22300 (epoch 27.063), train_loss = 0.67525884, grad/param norm = 3.7344e-01, time/batch = 15.7932s	
12071/22300 (epoch 27.065), train_loss = 0.72758193, grad/param norm = 3.8173e-01, time/batch = 16.2036s	
12072/22300 (epoch 27.067), train_loss = 0.52064150, grad/param norm = 3.1704e-01, time/batch = 16.0538s	
12073/22300 (epoch 27.070), train_loss = 0.52911975, grad/param norm = 2.5866e-01, time/batch = 15.7783s	
12074/22300 (epoch 27.072), train_loss = 0.62202762, grad/param norm = 3.3140e-01, time/batch = 15.9304s	
12075/22300 (epoch 27.074), train_loss = 0.56956552, grad/param norm = 2.9591e-01, time/batch = 15.8801s	
12076/22300 (epoch 27.076), train_loss = 0.57805246, grad/param norm = 2.6757e-01, time/batch = 15.8163s	
12077/22300 (epoch 27.078), train_loss = 0.66539457, grad/param norm = 3.2450e-01, time/batch = 15.8187s	
12078/22300 (epoch 27.081), train_loss = 0.65975238, grad/param norm = 3.3128e-01, time/batch = 15.9484s	
12079/22300 (epoch 27.083), train_loss = 0.75777062, grad/param norm = 3.3737e-01, time/batch = 15.6516s	
12080/22300 (epoch 27.085), train_loss = 0.76009480, grad/param norm = 3.4597e-01, time/batch = 15.7313s	
12081/22300 (epoch 27.087), train_loss = 0.62237945, grad/param norm = 2.8435e-01, time/batch = 16.0395s	
12082/22300 (epoch 27.090), train_loss = 0.53837564, grad/param norm = 2.8385e-01, time/batch = 15.9672s	
12083/22300 (epoch 27.092), train_loss = 0.43507759, grad/param norm = 2.5325e-01, time/batch = 15.4926s	
12084/22300 (epoch 27.094), train_loss = 0.43778455, grad/param norm = 2.3942e-01, time/batch = 15.7669s	
12085/22300 (epoch 27.096), train_loss = 0.73967493, grad/param norm = 3.5515e-01, time/batch = 15.5497s	
12086/22300 (epoch 27.099), train_loss = 0.49419422, grad/param norm = 2.5718e-01, time/batch = 15.5821s	
12087/22300 (epoch 27.101), train_loss = 0.66032504, grad/param norm = 4.0544e-01, time/batch = 15.9548s	
12088/22300 (epoch 27.103), train_loss = 0.55729227, grad/param norm = 2.6604e-01, time/batch = 16.1272s	
12089/22300 (epoch 27.105), train_loss = 0.48326836, grad/param norm = 2.8415e-01, time/batch = 16.1983s	
12090/22300 (epoch 27.108), train_loss = 0.59339950, grad/param norm = 2.7509e-01, time/batch = 16.1208s	
12091/22300 (epoch 27.110), train_loss = 0.63005544, grad/param norm = 2.8249e-01, time/batch = 16.1285s	
12092/22300 (epoch 27.112), train_loss = 0.56868649, grad/param norm = 2.5356e-01, time/batch = 15.9383s	
12093/22300 (epoch 27.114), train_loss = 0.63395011, grad/param norm = 2.8648e-01, time/batch = 15.9254s	
12094/22300 (epoch 27.117), train_loss = 0.74240287, grad/param norm = 3.0428e-01, time/batch = 15.8980s	
12095/22300 (epoch 27.119), train_loss = 0.70005661, grad/param norm = 3.0472e-01, time/batch = 15.7557s	
12096/22300 (epoch 27.121), train_loss = 0.75694065, grad/param norm = 3.4205e-01, time/batch = 15.6283s	
12097/22300 (epoch 27.123), train_loss = 0.77318598, grad/param norm = 3.1434e-01, time/batch = 15.8528s	
12098/22300 (epoch 27.126), train_loss = 0.58886479, grad/param norm = 2.7690e-01, time/batch = 15.6565s	
12099/22300 (epoch 27.128), train_loss = 0.63145813, grad/param norm = 2.9245e-01, time/batch = 15.5635s	
12100/22300 (epoch 27.130), train_loss = 0.52606303, grad/param norm = 3.4479e-01, time/batch = 15.4773s	
12101/22300 (epoch 27.132), train_loss = 0.41366850, grad/param norm = 2.5763e-01, time/batch = 15.9404s	
12102/22300 (epoch 27.135), train_loss = 0.42989875, grad/param norm = 2.4956e-01, time/batch = 15.8161s	
12103/22300 (epoch 27.137), train_loss = 0.33637187, grad/param norm = 2.0552e-01, time/batch = 15.7799s	
12104/22300 (epoch 27.139), train_loss = 0.53784778, grad/param norm = 2.7724e-01, time/batch = 15.5482s	
12105/22300 (epoch 27.141), train_loss = 0.63517197, grad/param norm = 2.6341e-01, time/batch = 15.7998s	
12106/22300 (epoch 27.143), train_loss = 0.56923200, grad/param norm = 2.7658e-01, time/batch = 15.7372s	
12107/22300 (epoch 27.146), train_loss = 0.67094057, grad/param norm = 3.2686e-01, time/batch = 15.8089s	
12108/22300 (epoch 27.148), train_loss = 0.46202535, grad/param norm = 2.8019e-01, time/batch = 15.7055s	
12109/22300 (epoch 27.150), train_loss = 0.52469869, grad/param norm = 2.6729e-01, time/batch = 15.6499s	
12110/22300 (epoch 27.152), train_loss = 0.45416889, grad/param norm = 3.0187e-01, time/batch = 15.9485s	
12111/22300 (epoch 27.155), train_loss = 0.44955441, grad/param norm = 2.3263e-01, time/batch = 15.9564s	
12112/22300 (epoch 27.157), train_loss = 0.60467165, grad/param norm = 3.1191e-01, time/batch = 15.8744s	
12113/22300 (epoch 27.159), train_loss = 0.63408974, grad/param norm = 2.9304e-01, time/batch = 15.4849s	
12114/22300 (epoch 27.161), train_loss = 0.62977628, grad/param norm = 3.0195e-01, time/batch = 15.4694s	
12115/22300 (epoch 27.164), train_loss = 0.48585096, grad/param norm = 2.5052e-01, time/batch = 15.6818s	
12116/22300 (epoch 27.166), train_loss = 0.41408643, grad/param norm = 1.9661e-01, time/batch = 15.7402s	
12117/22300 (epoch 27.168), train_loss = 0.42433741, grad/param norm = 2.5114e-01, time/batch = 15.7616s	
12118/22300 (epoch 27.170), train_loss = 0.54942840, grad/param norm = 2.6407e-01, time/batch = 15.7545s	
12119/22300 (epoch 27.173), train_loss = 0.66949110, grad/param norm = 3.2705e-01, time/batch = 16.1654s	
12120/22300 (epoch 27.175), train_loss = 0.55309238, grad/param norm = 2.6996e-01, time/batch = 15.8801s	
12121/22300 (epoch 27.177), train_loss = 0.38794741, grad/param norm = 2.2781e-01, time/batch = 15.8462s	
12122/22300 (epoch 27.179), train_loss = 0.54367107, grad/param norm = 2.7603e-01, time/batch = 15.8096s	
12123/22300 (epoch 27.182), train_loss = 0.74453535, grad/param norm = 3.4423e-01, time/batch = 15.8888s	
12124/22300 (epoch 27.184), train_loss = 0.78279613, grad/param norm = 2.9149e-01, time/batch = 15.8142s	
12125/22300 (epoch 27.186), train_loss = 0.57368521, grad/param norm = 2.7215e-01, time/batch = 16.1367s	
12126/22300 (epoch 27.188), train_loss = 0.80018018, grad/param norm = 3.5264e-01, time/batch = 15.9876s	
12127/22300 (epoch 27.191), train_loss = 0.69670815, grad/param norm = 3.1901e-01, time/batch = 15.9640s	
12128/22300 (epoch 27.193), train_loss = 0.57745802, grad/param norm = 2.9897e-01, time/batch = 15.7240s	
12129/22300 (epoch 27.195), train_loss = 0.54703110, grad/param norm = 2.7246e-01, time/batch = 15.7147s	
12130/22300 (epoch 27.197), train_loss = 0.49359094, grad/param norm = 2.6284e-01, time/batch = 15.8364s	
12131/22300 (epoch 27.200), train_loss = 0.43106969, grad/param norm = 2.3624e-01, time/batch = 16.1088s	
12132/22300 (epoch 27.202), train_loss = 0.47137639, grad/param norm = 2.6017e-01, time/batch = 16.1447s	
12133/22300 (epoch 27.204), train_loss = 0.53554823, grad/param norm = 2.7684e-01, time/batch = 15.9780s	
12134/22300 (epoch 27.206), train_loss = 0.46352766, grad/param norm = 2.4330e-01, time/batch = 15.9418s	
12135/22300 (epoch 27.209), train_loss = 0.50981181, grad/param norm = 2.5348e-01, time/batch = 15.9787s	
12136/22300 (epoch 27.211), train_loss = 0.41713934, grad/param norm = 2.5105e-01, time/batch = 15.9692s	
12137/22300 (epoch 27.213), train_loss = 0.56047507, grad/param norm = 2.8414e-01, time/batch = 15.8069s	
12138/22300 (epoch 27.215), train_loss = 0.70117981, grad/param norm = 3.2943e-01, time/batch = 15.6218s	
12139/22300 (epoch 27.217), train_loss = 0.70162001, grad/param norm = 3.1292e-01, time/batch = 15.7943s	
12140/22300 (epoch 27.220), train_loss = 0.49051069, grad/param norm = 2.3545e-01, time/batch = 15.8006s	
12141/22300 (epoch 27.222), train_loss = 0.47764676, grad/param norm = 2.4347e-01, time/batch = 15.8838s	
12142/22300 (epoch 27.224), train_loss = 0.50525425, grad/param norm = 2.5614e-01, time/batch = 16.1026s	
12143/22300 (epoch 27.226), train_loss = 0.53462548, grad/param norm = 2.3842e-01, time/batch = 15.7279s	
12144/22300 (epoch 27.229), train_loss = 0.45933364, grad/param norm = 2.9819e-01, time/batch = 15.9667s	
12145/22300 (epoch 27.231), train_loss = 0.63337703, grad/param norm = 2.6935e-01, time/batch = 15.9215s	
12146/22300 (epoch 27.233), train_loss = 0.55969734, grad/param norm = 2.6936e-01, time/batch = 16.0135s	
12147/22300 (epoch 27.235), train_loss = 0.41575980, grad/param norm = 2.1829e-01, time/batch = 16.0345s	
12148/22300 (epoch 27.238), train_loss = 0.43432441, grad/param norm = 2.3358e-01, time/batch = 15.9579s	
12149/22300 (epoch 27.240), train_loss = 0.45527459, grad/param norm = 2.3798e-01, time/batch = 15.8343s	
12150/22300 (epoch 27.242), train_loss = 0.44394144, grad/param norm = 2.6261e-01, time/batch = 15.6776s	
12151/22300 (epoch 27.244), train_loss = 0.30057881, grad/param norm = 1.8884e-01, time/batch = 15.7867s	
12152/22300 (epoch 27.247), train_loss = 0.42913752, grad/param norm = 2.3203e-01, time/batch = 15.9771s	
12153/22300 (epoch 27.249), train_loss = 0.29840937, grad/param norm = 1.8873e-01, time/batch = 16.0176s	
12154/22300 (epoch 27.251), train_loss = 0.41901404, grad/param norm = 2.2838e-01, time/batch = 15.8829s	
12155/22300 (epoch 27.253), train_loss = 0.28026859, grad/param norm = 1.8235e-01, time/batch = 16.0050s	
12156/22300 (epoch 27.256), train_loss = 0.37332339, grad/param norm = 2.1590e-01, time/batch = 15.9793s	
12157/22300 (epoch 27.258), train_loss = 0.60467192, grad/param norm = 3.0657e-01, time/batch = 16.0252s	
12158/22300 (epoch 27.260), train_loss = 0.53836878, grad/param norm = 2.5901e-01, time/batch = 15.8049s	
12159/22300 (epoch 27.262), train_loss = 0.42115503, grad/param norm = 2.3636e-01, time/batch = 15.8437s	
12160/22300 (epoch 27.265), train_loss = 0.38550241, grad/param norm = 2.3484e-01, time/batch = 15.7939s	
12161/22300 (epoch 27.267), train_loss = 0.45062676, grad/param norm = 2.3761e-01, time/batch = 15.9634s	
12162/22300 (epoch 27.269), train_loss = 0.52444698, grad/param norm = 2.6647e-01, time/batch = 15.8980s	
12163/22300 (epoch 27.271), train_loss = 0.58553577, grad/param norm = 2.6294e-01, time/batch = 16.3725s	
12164/22300 (epoch 27.274), train_loss = 0.40186735, grad/param norm = 2.3127e-01, time/batch = 15.5509s	
12165/22300 (epoch 27.276), train_loss = 0.35935049, grad/param norm = 2.0780e-01, time/batch = 15.6231s	
12166/22300 (epoch 27.278), train_loss = 0.34447186, grad/param norm = 1.8245e-01, time/batch = 15.3693s	
12167/22300 (epoch 27.280), train_loss = 0.42622398, grad/param norm = 2.2537e-01, time/batch = 17.1976s	
12168/22300 (epoch 27.283), train_loss = 0.31656590, grad/param norm = 1.8250e-01, time/batch = 14.9363s	
12169/22300 (epoch 27.285), train_loss = 0.40754614, grad/param norm = 2.7500e-01, time/batch = 15.9743s	
12170/22300 (epoch 27.287), train_loss = 0.53291233, grad/param norm = 2.5419e-01, time/batch = 17.7976s	
12171/22300 (epoch 27.289), train_loss = 0.47470590, grad/param norm = 2.2623e-01, time/batch = 18.1883s	
12172/22300 (epoch 27.291), train_loss = 0.48712015, grad/param norm = 2.6325e-01, time/batch = 15.7174s	
12173/22300 (epoch 27.294), train_loss = 0.36933335, grad/param norm = 1.7426e-01, time/batch = 17.3961s	
12174/22300 (epoch 27.296), train_loss = 0.47757605, grad/param norm = 2.8189e-01, time/batch = 17.7969s	
12175/22300 (epoch 27.298), train_loss = 0.59034886, grad/param norm = 2.6118e-01, time/batch = 15.2602s	
12176/22300 (epoch 27.300), train_loss = 0.64774168, grad/param norm = 3.0998e-01, time/batch = 16.6305s	
12177/22300 (epoch 27.303), train_loss = 0.47979937, grad/param norm = 2.3923e-01, time/batch = 15.4034s	
12178/22300 (epoch 27.305), train_loss = 0.51909216, grad/param norm = 3.4778e-01, time/batch = 16.8879s	
12179/22300 (epoch 27.307), train_loss = 0.45235704, grad/param norm = 2.4359e-01, time/batch = 15.9705s	
12180/22300 (epoch 27.309), train_loss = 0.41201652, grad/param norm = 2.3266e-01, time/batch = 15.1347s	
12181/22300 (epoch 27.312), train_loss = 0.37504234, grad/param norm = 2.0510e-01, time/batch = 16.9798s	
12182/22300 (epoch 27.314), train_loss = 0.41113497, grad/param norm = 2.8080e-01, time/batch = 15.2841s	
12183/22300 (epoch 27.316), train_loss = 0.41446195, grad/param norm = 2.4868e-01, time/batch = 15.8348s	
12184/22300 (epoch 27.318), train_loss = 0.48255519, grad/param norm = 2.6225e-01, time/batch = 15.3415s	
12185/22300 (epoch 27.321), train_loss = 0.56535813, grad/param norm = 2.6505e-01, time/batch = 16.6894s	
12186/22300 (epoch 27.323), train_loss = 0.40775183, grad/param norm = 2.2658e-01, time/batch = 15.0997s	
12187/22300 (epoch 27.325), train_loss = 0.37363937, grad/param norm = 1.9992e-01, time/batch = 16.3056s	
12188/22300 (epoch 27.327), train_loss = 0.38779405, grad/param norm = 2.2272e-01, time/batch = 16.3040s	
12189/22300 (epoch 27.330), train_loss = 0.41543271, grad/param norm = 2.7615e-01, time/batch = 16.5594s	
12190/22300 (epoch 27.332), train_loss = 0.39977841, grad/param norm = 2.4895e-01, time/batch = 15.6299s	
12191/22300 (epoch 27.334), train_loss = 0.43835753, grad/param norm = 2.5136e-01, time/batch = 18.3078s	
12192/22300 (epoch 27.336), train_loss = 0.45840122, grad/param norm = 2.5399e-01, time/batch = 15.7276s	
12193/22300 (epoch 27.339), train_loss = 0.50772816, grad/param norm = 2.9871e-01, time/batch = 17.5383s	
12194/22300 (epoch 27.341), train_loss = 0.54017489, grad/param norm = 2.7934e-01, time/batch = 15.9330s	
12195/22300 (epoch 27.343), train_loss = 0.61139500, grad/param norm = 2.9781e-01, time/batch = 15.3707s	
12196/22300 (epoch 27.345), train_loss = 0.45766572, grad/param norm = 2.3105e-01, time/batch = 15.8876s	
12197/22300 (epoch 27.348), train_loss = 0.46023832, grad/param norm = 2.3065e-01, time/batch = 16.0261s	
12198/22300 (epoch 27.350), train_loss = 0.39157406, grad/param norm = 2.3469e-01, time/batch = 15.6386s	
12199/22300 (epoch 27.352), train_loss = 0.52445934, grad/param norm = 3.0671e-01, time/batch = 17.2062s	
12200/22300 (epoch 27.354), train_loss = 0.72237729, grad/param norm = 3.2392e-01, time/batch = 15.4885s	
12201/22300 (epoch 27.357), train_loss = 0.59319490, grad/param norm = 2.4431e-01, time/batch = 16.2918s	
12202/22300 (epoch 27.359), train_loss = 0.40884734, grad/param norm = 2.4661e-01, time/batch = 16.9637s	
12203/22300 (epoch 27.361), train_loss = 0.42888181, grad/param norm = 2.5816e-01, time/batch = 17.3878s	
12204/22300 (epoch 27.363), train_loss = 0.56592721, grad/param norm = 2.7161e-01, time/batch = 15.4126s	
12205/22300 (epoch 27.365), train_loss = 0.46154556, grad/param norm = 2.6634e-01, time/batch = 15.4414s	
12206/22300 (epoch 27.368), train_loss = 0.46287363, grad/param norm = 3.2028e-01, time/batch = 15.1652s	
12207/22300 (epoch 27.370), train_loss = 0.45078500, grad/param norm = 2.6953e-01, time/batch = 14.9115s	
12208/22300 (epoch 27.372), train_loss = 0.38661736, grad/param norm = 2.5151e-01, time/batch = 14.7967s	
12209/22300 (epoch 27.374), train_loss = 0.33515474, grad/param norm = 2.1381e-01, time/batch = 15.3426s	
12210/22300 (epoch 27.377), train_loss = 0.45633059, grad/param norm = 2.6715e-01, time/batch = 16.5250s	
12211/22300 (epoch 27.379), train_loss = 0.43574432, grad/param norm = 2.6082e-01, time/batch = 17.8696s	
12212/22300 (epoch 27.381), train_loss = 0.57330102, grad/param norm = 2.7407e-01, time/batch = 15.4737s	
12213/22300 (epoch 27.383), train_loss = 0.47654334, grad/param norm = 2.9059e-01, time/batch = 15.1974s	
12214/22300 (epoch 27.386), train_loss = 0.45932313, grad/param norm = 2.5122e-01, time/batch = 15.9755s	
12215/22300 (epoch 27.388), train_loss = 0.40069092, grad/param norm = 2.7021e-01, time/batch = 15.8487s	
12216/22300 (epoch 27.390), train_loss = 0.48377291, grad/param norm = 3.8033e-01, time/batch = 15.4291s	
12217/22300 (epoch 27.392), train_loss = 0.46566112, grad/param norm = 2.7200e-01, time/batch = 14.9008s	
12218/22300 (epoch 27.395), train_loss = 0.40879898, grad/param norm = 2.5537e-01, time/batch = 15.7866s	
12219/22300 (epoch 27.397), train_loss = 0.24924859, grad/param norm = 1.7982e-01, time/batch = 16.8088s	
12220/22300 (epoch 27.399), train_loss = 0.37327625, grad/param norm = 2.1007e-01, time/batch = 15.4780s	
12221/22300 (epoch 27.401), train_loss = 0.45651675, grad/param norm = 2.9105e-01, time/batch = 15.4911s	
12222/22300 (epoch 27.404), train_loss = 0.45073593, grad/param norm = 2.6407e-01, time/batch = 16.9633s	
12223/22300 (epoch 27.406), train_loss = 0.68263884, grad/param norm = 3.0521e-01, time/batch = 15.5350s	
12224/22300 (epoch 27.408), train_loss = 0.57427646, grad/param norm = 2.8553e-01, time/batch = 16.6464s	
12225/22300 (epoch 27.410), train_loss = 0.59562612, grad/param norm = 3.4863e-01, time/batch = 16.7808s	
12226/22300 (epoch 27.413), train_loss = 0.41204531, grad/param norm = 2.3829e-01, time/batch = 16.5522s	
12227/22300 (epoch 27.415), train_loss = 0.32914940, grad/param norm = 2.2415e-01, time/batch = 15.6215s	
12228/22300 (epoch 27.417), train_loss = 0.51076254, grad/param norm = 2.7711e-01, time/batch = 16.1301s	
12229/22300 (epoch 27.419), train_loss = 0.43927667, grad/param norm = 2.2503e-01, time/batch = 17.3001s	
12230/22300 (epoch 27.422), train_loss = 0.43767263, grad/param norm = 3.6616e-01, time/batch = 18.0488s	
12231/22300 (epoch 27.424), train_loss = 0.52520854, grad/param norm = 3.6301e-01, time/batch = 16.6196s	
12232/22300 (epoch 27.426), train_loss = 0.36572254, grad/param norm = 2.8253e-01, time/batch = 16.6167s	
12233/22300 (epoch 27.428), train_loss = 0.39048922, grad/param norm = 2.4227e-01, time/batch = 15.6309s	
12234/22300 (epoch 27.430), train_loss = 0.47652503, grad/param norm = 3.0273e-01, time/batch = 16.7933s	
12235/22300 (epoch 27.433), train_loss = 0.47228993, grad/param norm = 2.6790e-01, time/batch = 17.2964s	
12236/22300 (epoch 27.435), train_loss = 0.46423251, grad/param norm = 2.8087e-01, time/batch = 16.7070s	
12237/22300 (epoch 27.437), train_loss = 0.50544773, grad/param norm = 2.8873e-01, time/batch = 17.5622s	
12238/22300 (epoch 27.439), train_loss = 0.55728427, grad/param norm = 2.8610e-01, time/batch = 16.4515s	
12239/22300 (epoch 27.442), train_loss = 0.49841619, grad/param norm = 2.6674e-01, time/batch = 18.1126s	
12240/22300 (epoch 27.444), train_loss = 0.40357926, grad/param norm = 2.1825e-01, time/batch = 17.1116s	
12241/22300 (epoch 27.446), train_loss = 0.42956149, grad/param norm = 3.1975e-01, time/batch = 15.8425s	
12242/22300 (epoch 27.448), train_loss = 0.30657491, grad/param norm = 2.0828e-01, time/batch = 15.2304s	
12243/22300 (epoch 27.451), train_loss = 0.53544665, grad/param norm = 2.8269e-01, time/batch = 15.5596s	
12244/22300 (epoch 27.453), train_loss = 0.40716752, grad/param norm = 2.1615e-01, time/batch = 16.1342s	
12245/22300 (epoch 27.455), train_loss = 0.58834780, grad/param norm = 3.0954e-01, time/batch = 15.4145s	
12246/22300 (epoch 27.457), train_loss = 0.66625043, grad/param norm = 3.3108e-01, time/batch = 17.1940s	
12247/22300 (epoch 27.460), train_loss = 0.56954386, grad/param norm = 3.0507e-01, time/batch = 17.2182s	
12248/22300 (epoch 27.462), train_loss = 0.62727260, grad/param norm = 3.3180e-01, time/batch = 17.1310s	
12249/22300 (epoch 27.464), train_loss = 0.54102290, grad/param norm = 3.2381e-01, time/batch = 30.9121s	
12250/22300 (epoch 27.466), train_loss = 0.44773601, grad/param norm = 2.6512e-01, time/batch = 16.8495s	
12251/22300 (epoch 27.469), train_loss = 0.43330889, grad/param norm = 2.0583e-01, time/batch = 15.1031s	
12252/22300 (epoch 27.471), train_loss = 0.55538206, grad/param norm = 2.3885e-01, time/batch = 15.3061s	
12253/22300 (epoch 27.473), train_loss = 0.51941206, grad/param norm = 2.7520e-01, time/batch = 15.7819s	
12254/22300 (epoch 27.475), train_loss = 0.43176179, grad/param norm = 2.4993e-01, time/batch = 15.2960s	
12255/22300 (epoch 27.478), train_loss = 0.45118012, grad/param norm = 2.8028e-01, time/batch = 15.3797s	
12256/22300 (epoch 27.480), train_loss = 0.31076272, grad/param norm = 2.1293e-01, time/batch = 15.2895s	
12257/22300 (epoch 27.482), train_loss = 0.36000024, grad/param norm = 2.2972e-01, time/batch = 15.0756s	
12258/22300 (epoch 27.484), train_loss = 0.49105936, grad/param norm = 2.7637e-01, time/batch = 15.2329s	
12259/22300 (epoch 27.487), train_loss = 0.55026439, grad/param norm = 2.7079e-01, time/batch = 15.6014s	
12260/22300 (epoch 27.489), train_loss = 0.56224893, grad/param norm = 2.9630e-01, time/batch = 15.2149s	
12261/22300 (epoch 27.491), train_loss = 0.56537285, grad/param norm = 3.1462e-01, time/batch = 15.3133s	
12262/22300 (epoch 27.493), train_loss = 0.48890571, grad/param norm = 3.3568e-01, time/batch = 15.2937s	
12263/22300 (epoch 27.496), train_loss = 0.47463274, grad/param norm = 2.4125e-01, time/batch = 15.5939s	
12264/22300 (epoch 27.498), train_loss = 0.35624775, grad/param norm = 2.0853e-01, time/batch = 15.3104s	
12265/22300 (epoch 27.500), train_loss = 0.48652216, grad/param norm = 2.6093e-01, time/batch = 15.2293s	
12266/22300 (epoch 27.502), train_loss = 0.31737854, grad/param norm = 2.4486e-01, time/batch = 15.2219s	
12267/22300 (epoch 27.504), train_loss = 0.33481303, grad/param norm = 2.0259e-01, time/batch = 15.3896s	
12268/22300 (epoch 27.507), train_loss = 0.40796168, grad/param norm = 2.5347e-01, time/batch = 15.1191s	
12269/22300 (epoch 27.509), train_loss = 0.51821635, grad/param norm = 2.6143e-01, time/batch = 15.0633s	
12270/22300 (epoch 27.511), train_loss = 0.31457686, grad/param norm = 2.1828e-01, time/batch = 14.9050s	
12271/22300 (epoch 27.513), train_loss = 0.34584959, grad/param norm = 2.3661e-01, time/batch = 15.2997s	
12272/22300 (epoch 27.516), train_loss = 0.39694829, grad/param norm = 2.3976e-01, time/batch = 15.1457s	
12273/22300 (epoch 27.518), train_loss = 0.54459002, grad/param norm = 3.2457e-01, time/batch = 15.4689s	
12274/22300 (epoch 27.520), train_loss = 0.43306505, grad/param norm = 2.7716e-01, time/batch = 15.3598s	
12275/22300 (epoch 27.522), train_loss = 0.43280176, grad/param norm = 2.1143e-01, time/batch = 15.8133s	
12276/22300 (epoch 27.525), train_loss = 0.36533394, grad/param norm = 2.3059e-01, time/batch = 15.2941s	
12277/22300 (epoch 27.527), train_loss = 0.59172873, grad/param norm = 3.7891e-01, time/batch = 15.1312s	
12278/22300 (epoch 27.529), train_loss = 0.48677728, grad/param norm = 2.7979e-01, time/batch = 15.4191s	
12279/22300 (epoch 27.531), train_loss = 0.44095979, grad/param norm = 2.5108e-01, time/batch = 15.7067s	
12280/22300 (epoch 27.534), train_loss = 0.42037504, grad/param norm = 2.5027e-01, time/batch = 14.8308s	
12281/22300 (epoch 27.536), train_loss = 0.65665937, grad/param norm = 2.5422e-01, time/batch = 15.2281s	
12282/22300 (epoch 27.538), train_loss = 0.77213210, grad/param norm = 3.1426e-01, time/batch = 14.9908s	
12283/22300 (epoch 27.540), train_loss = 0.47444537, grad/param norm = 2.5571e-01, time/batch = 15.8356s	
12284/22300 (epoch 27.543), train_loss = 0.43138720, grad/param norm = 2.1803e-01, time/batch = 15.0674s	
12285/22300 (epoch 27.545), train_loss = 0.34213360, grad/param norm = 2.3504e-01, time/batch = 14.9073s	
12286/22300 (epoch 27.547), train_loss = 0.32878787, grad/param norm = 2.2139e-01, time/batch = 15.0639s	
12287/22300 (epoch 27.549), train_loss = 0.39149525, grad/param norm = 2.4250e-01, time/batch = 15.4078s	
12288/22300 (epoch 27.552), train_loss = 0.39772761, grad/param norm = 2.4665e-01, time/batch = 15.3898s	
12289/22300 (epoch 27.554), train_loss = 0.51049886, grad/param norm = 3.0717e-01, time/batch = 15.2820s	
12290/22300 (epoch 27.556), train_loss = 0.69102390, grad/param norm = 3.4051e-01, time/batch = 15.2270s	
12291/22300 (epoch 27.558), train_loss = 0.53862291, grad/param norm = 2.8623e-01, time/batch = 15.3986s	
12292/22300 (epoch 27.561), train_loss = 0.67409734, grad/param norm = 3.3910e-01, time/batch = 15.1518s	
12293/22300 (epoch 27.563), train_loss = 0.60455857, grad/param norm = 3.2794e-01, time/batch = 15.1574s	
12294/22300 (epoch 27.565), train_loss = 0.45902293, grad/param norm = 2.7943e-01, time/batch = 15.3034s	
12295/22300 (epoch 27.567), train_loss = 0.45379055, grad/param norm = 2.6990e-01, time/batch = 15.3148s	
12296/22300 (epoch 27.570), train_loss = 0.63923751, grad/param norm = 3.1728e-01, time/batch = 15.3656s	
12297/22300 (epoch 27.572), train_loss = 0.62234566, grad/param norm = 3.0590e-01, time/batch = 15.0756s	
12298/22300 (epoch 27.574), train_loss = 0.48187005, grad/param norm = 2.4053e-01, time/batch = 15.4602s	
12299/22300 (epoch 27.576), train_loss = 0.41173497, grad/param norm = 2.0649e-01, time/batch = 15.3675s	
12300/22300 (epoch 27.578), train_loss = 0.25312206, grad/param norm = 1.7826e-01, time/batch = 15.3735s	
12301/22300 (epoch 27.581), train_loss = 0.35757577, grad/param norm = 2.5253e-01, time/batch = 15.3009s	
12302/22300 (epoch 27.583), train_loss = 0.40991267, grad/param norm = 1.9783e-01, time/batch = 15.3081s	
12303/22300 (epoch 27.585), train_loss = 0.60448969, grad/param norm = 3.8913e-01, time/batch = 14.9772s	
12304/22300 (epoch 27.587), train_loss = 0.76351377, grad/param norm = 3.4093e-01, time/batch = 15.3111s	
12305/22300 (epoch 27.590), train_loss = 0.64000533, grad/param norm = 3.7975e-01, time/batch = 15.0798s	
12306/22300 (epoch 27.592), train_loss = 0.74226771, grad/param norm = 3.7751e-01, time/batch = 15.3646s	
12307/22300 (epoch 27.594), train_loss = 0.72405365, grad/param norm = 3.6654e-01, time/batch = 15.3884s	
12308/22300 (epoch 27.596), train_loss = 0.44614318, grad/param norm = 2.6480e-01, time/batch = 15.1524s	
12309/22300 (epoch 27.599), train_loss = 0.35566855, grad/param norm = 2.5452e-01, time/batch = 14.9719s	
12310/22300 (epoch 27.601), train_loss = 0.42275623, grad/param norm = 2.3856e-01, time/batch = 15.0569s	
12311/22300 (epoch 27.603), train_loss = 0.49163782, grad/param norm = 2.6949e-01, time/batch = 15.2998s	
12312/22300 (epoch 27.605), train_loss = 0.42908961, grad/param norm = 2.5198e-01, time/batch = 14.9860s	
12313/22300 (epoch 27.608), train_loss = 0.73943398, grad/param norm = 3.4736e-01, time/batch = 15.0780s	
12314/22300 (epoch 27.610), train_loss = 0.76151852, grad/param norm = 3.3978e-01, time/batch = 15.6085s	
12315/22300 (epoch 27.612), train_loss = 0.54155254, grad/param norm = 2.8947e-01, time/batch = 15.2823s	
12316/22300 (epoch 27.614), train_loss = 0.61612377, grad/param norm = 3.3881e-01, time/batch = 15.3543s	
12317/22300 (epoch 27.617), train_loss = 0.58353360, grad/param norm = 2.7636e-01, time/batch = 15.2152s	
12318/22300 (epoch 27.619), train_loss = 0.68887020, grad/param norm = 3.5916e-01, time/batch = 15.5999s	
12319/22300 (epoch 27.621), train_loss = 0.43983719, grad/param norm = 2.5473e-01, time/batch = 15.4939s	
12320/22300 (epoch 27.623), train_loss = 0.45783745, grad/param norm = 2.3701e-01, time/batch = 15.4354s	
12321/22300 (epoch 27.626), train_loss = 0.42903475, grad/param norm = 2.7392e-01, time/batch = 15.2184s	
12322/22300 (epoch 27.628), train_loss = 0.43932883, grad/param norm = 2.3282e-01, time/batch = 15.4285s	
12323/22300 (epoch 27.630), train_loss = 0.49736906, grad/param norm = 2.7409e-01, time/batch = 14.9643s	
12324/22300 (epoch 27.632), train_loss = 0.45211927, grad/param norm = 3.1429e-01, time/batch = 15.2185s	
12325/22300 (epoch 27.635), train_loss = 0.49568973, grad/param norm = 2.7212e-01, time/batch = 14.9689s	
12326/22300 (epoch 27.637), train_loss = 0.54854754, grad/param norm = 2.6391e-01, time/batch = 15.3043s	
12327/22300 (epoch 27.639), train_loss = 0.63780429, grad/param norm = 3.0548e-01, time/batch = 15.2401s	
12328/22300 (epoch 27.641), train_loss = 0.52999458, grad/param norm = 2.7960e-01, time/batch = 15.2267s	
12329/22300 (epoch 27.643), train_loss = 0.43028605, grad/param norm = 3.6210e-01, time/batch = 15.3673s	
12330/22300 (epoch 27.646), train_loss = 0.41740541, grad/param norm = 2.7249e-01, time/batch = 15.3495s	
12331/22300 (epoch 27.648), train_loss = 0.51237748, grad/param norm = 2.7483e-01, time/batch = 15.7299s	
12332/22300 (epoch 27.650), train_loss = 0.52439186, grad/param norm = 2.8058e-01, time/batch = 15.8160s	
12333/22300 (epoch 27.652), train_loss = 0.45139854, grad/param norm = 2.0888e-01, time/batch = 17.2820s	
12334/22300 (epoch 27.655), train_loss = 0.42488032, grad/param norm = 2.6996e-01, time/batch = 15.9664s	
12335/22300 (epoch 27.657), train_loss = 0.48461174, grad/param norm = 2.7220e-01, time/batch = 17.4647s	
12336/22300 (epoch 27.659), train_loss = 0.43587408, grad/param norm = 2.6710e-01, time/batch = 15.9005s	
12337/22300 (epoch 27.661), train_loss = 0.34529053, grad/param norm = 2.2926e-01, time/batch = 15.4440s	
12338/22300 (epoch 27.664), train_loss = 0.40408117, grad/param norm = 2.1508e-01, time/batch = 17.1324s	
12339/22300 (epoch 27.666), train_loss = 0.56636390, grad/param norm = 3.0165e-01, time/batch = 18.3870s	
12340/22300 (epoch 27.668), train_loss = 0.40065928, grad/param norm = 2.4935e-01, time/batch = 16.3754s	
12341/22300 (epoch 27.670), train_loss = 0.52978383, grad/param norm = 2.7564e-01, time/batch = 16.1386s	
12342/22300 (epoch 27.673), train_loss = 0.59095177, grad/param norm = 3.1541e-01, time/batch = 17.9668s	
12343/22300 (epoch 27.675), train_loss = 0.65395396, grad/param norm = 2.9563e-01, time/batch = 18.1296s	
12344/22300 (epoch 27.677), train_loss = 0.68621780, grad/param norm = 3.1521e-01, time/batch = 16.2818s	
12345/22300 (epoch 27.679), train_loss = 0.53569672, grad/param norm = 3.3975e-01, time/batch = 16.2825s	
12346/22300 (epoch 27.682), train_loss = 0.48168863, grad/param norm = 2.6730e-01, time/batch = 16.3859s	
12347/22300 (epoch 27.684), train_loss = 0.47825950, grad/param norm = 2.9485e-01, time/batch = 15.7180s	
12348/22300 (epoch 27.686), train_loss = 0.49605439, grad/param norm = 2.5076e-01, time/batch = 16.9185s	
12349/22300 (epoch 27.688), train_loss = 0.47724622, grad/param norm = 3.0740e-01, time/batch = 16.6460s	
12350/22300 (epoch 27.691), train_loss = 0.42306655, grad/param norm = 2.6279e-01, time/batch = 16.1921s	
12351/22300 (epoch 27.693), train_loss = 0.41972328, grad/param norm = 2.4598e-01, time/batch = 16.1935s	
12352/22300 (epoch 27.695), train_loss = 0.37828298, grad/param norm = 2.0356e-01, time/batch = 15.8131s	
12353/22300 (epoch 27.697), train_loss = 0.42146128, grad/param norm = 2.1190e-01, time/batch = 16.2973s	
12354/22300 (epoch 27.700), train_loss = 0.39357445, grad/param norm = 2.2869e-01, time/batch = 17.8633s	
12355/22300 (epoch 27.702), train_loss = 0.35852237, grad/param norm = 1.8994e-01, time/batch = 15.3757s	
12356/22300 (epoch 27.704), train_loss = 0.49367478, grad/param norm = 3.0073e-01, time/batch = 15.4496s	
12357/22300 (epoch 27.706), train_loss = 0.39807726, grad/param norm = 2.0858e-01, time/batch = 16.8477s	
12358/22300 (epoch 27.709), train_loss = 0.32264964, grad/param norm = 1.9765e-01, time/batch = 15.6443s	
12359/22300 (epoch 27.711), train_loss = 0.33710069, grad/param norm = 1.9147e-01, time/batch = 15.5961s	
12360/22300 (epoch 27.713), train_loss = 0.48674209, grad/param norm = 2.4196e-01, time/batch = 14.8939s	
12361/22300 (epoch 27.715), train_loss = 0.47036193, grad/param norm = 2.3571e-01, time/batch = 15.4773s	
12362/22300 (epoch 27.717), train_loss = 0.65374014, grad/param norm = 2.7384e-01, time/batch = 15.0655s	
12363/22300 (epoch 27.720), train_loss = 0.43387839, grad/param norm = 2.7201e-01, time/batch = 14.8260s	
12364/22300 (epoch 27.722), train_loss = 0.49463755, grad/param norm = 2.1743e-01, time/batch = 15.1679s	
12365/22300 (epoch 27.724), train_loss = 0.53417636, grad/param norm = 2.5755e-01, time/batch = 15.2698s	
12366/22300 (epoch 27.726), train_loss = 0.43039791, grad/param norm = 2.8095e-01, time/batch = 15.3873s	
12367/22300 (epoch 27.729), train_loss = 0.49051924, grad/param norm = 2.7050e-01, time/batch = 15.2155s	
12368/22300 (epoch 27.731), train_loss = 0.66486494, grad/param norm = 3.5729e-01, time/batch = 15.2016s	
12369/22300 (epoch 27.733), train_loss = 0.64032016, grad/param norm = 3.1992e-01, time/batch = 14.7532s	
12370/22300 (epoch 27.735), train_loss = 0.70185635, grad/param norm = 4.2379e-01, time/batch = 14.8325s	
12371/22300 (epoch 27.738), train_loss = 0.56770229, grad/param norm = 4.2263e-01, time/batch = 15.4202s	
12372/22300 (epoch 27.740), train_loss = 0.46233929, grad/param norm = 2.8759e-01, time/batch = 14.5561s	
12373/22300 (epoch 27.742), train_loss = 0.44666021, grad/param norm = 2.5392e-01, time/batch = 14.0891s	
12374/22300 (epoch 27.744), train_loss = 0.71662635, grad/param norm = 2.9877e-01, time/batch = 14.6400s	
12375/22300 (epoch 27.747), train_loss = 0.56033258, grad/param norm = 2.7633e-01, time/batch = 15.3550s	
12376/22300 (epoch 27.749), train_loss = 0.69524848, grad/param norm = 3.4311e-01, time/batch = 14.4076s	
12377/22300 (epoch 27.751), train_loss = 0.64043524, grad/param norm = 3.7383e-01, time/batch = 14.1733s	
12378/22300 (epoch 27.753), train_loss = 0.69267814, grad/param norm = 3.5184e-01, time/batch = 14.7236s	
12379/22300 (epoch 27.756), train_loss = 0.56861419, grad/param norm = 3.1303e-01, time/batch = 14.4827s	
12380/22300 (epoch 27.758), train_loss = 0.54726657, grad/param norm = 2.7242e-01, time/batch = 14.4066s	
12381/22300 (epoch 27.760), train_loss = 0.54767073, grad/param norm = 2.6266e-01, time/batch = 14.5563s	
12382/22300 (epoch 27.762), train_loss = 0.53008231, grad/param norm = 2.7207e-01, time/batch = 14.6411s	
12383/22300 (epoch 27.765), train_loss = 0.53804375, grad/param norm = 2.9754e-01, time/batch = 14.2401s	
12384/22300 (epoch 27.767), train_loss = 0.57407394, grad/param norm = 3.0942e-01, time/batch = 14.0954s	
12385/22300 (epoch 27.769), train_loss = 0.51681067, grad/param norm = 3.0773e-01, time/batch = 14.4937s	
12386/22300 (epoch 27.771), train_loss = 0.62552806, grad/param norm = 3.5248e-01, time/batch = 14.6374s	
12387/22300 (epoch 27.774), train_loss = 0.62187625, grad/param norm = 3.4151e-01, time/batch = 14.6999s	
12388/22300 (epoch 27.776), train_loss = 0.65199303, grad/param norm = 2.7568e-01, time/batch = 15.2546s	
12389/22300 (epoch 27.778), train_loss = 0.62606628, grad/param norm = 3.5809e-01, time/batch = 14.8007s	
12390/22300 (epoch 27.780), train_loss = 0.64636080, grad/param norm = 3.0294e-01, time/batch = 15.3584s	
12391/22300 (epoch 27.783), train_loss = 0.67661785, grad/param norm = 3.0647e-01, time/batch = 15.5333s	
12392/22300 (epoch 27.785), train_loss = 0.49134192, grad/param norm = 2.5372e-01, time/batch = 14.9544s	
12393/22300 (epoch 27.787), train_loss = 0.46703215, grad/param norm = 2.9651e-01, time/batch = 14.7327s	
12394/22300 (epoch 27.789), train_loss = 0.69697981, grad/param norm = 3.6967e-01, time/batch = 14.4867s	
12395/22300 (epoch 27.791), train_loss = 0.83244042, grad/param norm = 3.6923e-01, time/batch = 14.7942s	
12396/22300 (epoch 27.794), train_loss = 0.67592654, grad/param norm = 3.3550e-01, time/batch = 14.3275s	
12397/22300 (epoch 27.796), train_loss = 0.62568017, grad/param norm = 3.5959e-01, time/batch = 14.1648s	
12398/22300 (epoch 27.798), train_loss = 0.77001359, grad/param norm = 3.0808e-01, time/batch = 14.3287s	
12399/22300 (epoch 27.800), train_loss = 0.53717438, grad/param norm = 2.6962e-01, time/batch = 15.0304s	
12400/22300 (epoch 27.803), train_loss = 0.47291929, grad/param norm = 2.3016e-01, time/batch = 14.1654s	
12401/22300 (epoch 27.805), train_loss = 0.56849865, grad/param norm = 2.9141e-01, time/batch = 14.5683s	
12402/22300 (epoch 27.807), train_loss = 0.67456800, grad/param norm = 3.2413e-01, time/batch = 14.5813s	
12403/22300 (epoch 27.809), train_loss = 0.52815786, grad/param norm = 2.9092e-01, time/batch = 15.6717s	
12404/22300 (epoch 27.812), train_loss = 0.59282656, grad/param norm = 2.9868e-01, time/batch = 15.0173s	
12405/22300 (epoch 27.814), train_loss = 0.60465760, grad/param norm = 3.1293e-01, time/batch = 14.8960s	
12406/22300 (epoch 27.816), train_loss = 0.60342094, grad/param norm = 3.0256e-01, time/batch = 14.5915s	
12407/22300 (epoch 27.818), train_loss = 0.69381482, grad/param norm = 3.5919e-01, time/batch = 15.3523s	
12408/22300 (epoch 27.821), train_loss = 0.58116288, grad/param norm = 2.8619e-01, time/batch = 14.7946s	
12409/22300 (epoch 27.823), train_loss = 0.38150028, grad/param norm = 2.3029e-01, time/batch = 15.1072s	
12410/22300 (epoch 27.825), train_loss = 0.43457183, grad/param norm = 2.7244e-01, time/batch = 15.5325s	
12411/22300 (epoch 27.827), train_loss = 0.51105370, grad/param norm = 2.9427e-01, time/batch = 15.7780s	
12412/22300 (epoch 27.830), train_loss = 0.49817275, grad/param norm = 3.2306e-01, time/batch = 15.5472s	
12413/22300 (epoch 27.832), train_loss = 0.45376104, grad/param norm = 2.3525e-01, time/batch = 15.3456s	
12414/22300 (epoch 27.834), train_loss = 0.40707278, grad/param norm = 2.4891e-01, time/batch = 14.8830s	
12415/22300 (epoch 27.836), train_loss = 0.49995834, grad/param norm = 2.8427e-01, time/batch = 15.0307s	
12416/22300 (epoch 27.839), train_loss = 0.48847327, grad/param norm = 2.9934e-01, time/batch = 14.5045s	
12417/22300 (epoch 27.841), train_loss = 0.52411545, grad/param norm = 3.5845e-01, time/batch = 14.9082s	
12418/22300 (epoch 27.843), train_loss = 0.48876101, grad/param norm = 2.8137e-01, time/batch = 14.2351s	
12419/22300 (epoch 27.845), train_loss = 0.48884268, grad/param norm = 2.4507e-01, time/batch = 14.9606s	
12420/22300 (epoch 27.848), train_loss = 0.49790783, grad/param norm = 3.1767e-01, time/batch = 14.3215s	
12421/22300 (epoch 27.850), train_loss = 0.50976201, grad/param norm = 2.5177e-01, time/batch = 14.3480s	
12422/22300 (epoch 27.852), train_loss = 0.47047920, grad/param norm = 2.9459e-01, time/batch = 14.1681s	
12423/22300 (epoch 27.854), train_loss = 0.72487248, grad/param norm = 3.3118e-01, time/batch = 15.0353s	
12424/22300 (epoch 27.857), train_loss = 0.54372803, grad/param norm = 2.7183e-01, time/batch = 14.9585s	
12425/22300 (epoch 27.859), train_loss = 0.44708537, grad/param norm = 2.4361e-01, time/batch = 14.6579s	
12426/22300 (epoch 27.861), train_loss = 0.58773785, grad/param norm = 3.0251e-01, time/batch = 14.4781s	
12427/22300 (epoch 27.863), train_loss = 0.44011823, grad/param norm = 2.8929e-01, time/batch = 15.6527s	
12428/22300 (epoch 27.865), train_loss = 0.40391809, grad/param norm = 2.6154e-01, time/batch = 14.2518s	
12429/22300 (epoch 27.868), train_loss = 0.55502487, grad/param norm = 2.8791e-01, time/batch = 14.3260s	
12430/22300 (epoch 27.870), train_loss = 0.58302516, grad/param norm = 3.0381e-01, time/batch = 14.2461s	
12431/22300 (epoch 27.872), train_loss = 0.61844820, grad/param norm = 2.6671e-01, time/batch = 14.6566s	
12432/22300 (epoch 27.874), train_loss = 0.56318273, grad/param norm = 3.0615e-01, time/batch = 14.4141s	
12433/22300 (epoch 27.877), train_loss = 0.53733992, grad/param norm = 2.4662e-01, time/batch = 14.8162s	
12434/22300 (epoch 27.879), train_loss = 0.46467242, grad/param norm = 2.4461e-01, time/batch = 14.0008s	
12435/22300 (epoch 27.881), train_loss = 0.42132400, grad/param norm = 2.4368e-01, time/batch = 15.0374s	
12436/22300 (epoch 27.883), train_loss = 0.44149640, grad/param norm = 3.4065e-01, time/batch = 15.4261s	
12437/22300 (epoch 27.886), train_loss = 0.43497258, grad/param norm = 2.9615e-01, time/batch = 14.5404s	
12438/22300 (epoch 27.888), train_loss = 0.47173327, grad/param norm = 2.7042e-01, time/batch = 14.6463s	
12439/22300 (epoch 27.890), train_loss = 0.45483174, grad/param norm = 3.2586e-01, time/batch = 14.9598s	
12440/22300 (epoch 27.892), train_loss = 0.71195191, grad/param norm = 3.4320e-01, time/batch = 14.7260s	
12441/22300 (epoch 27.895), train_loss = 0.65821653, grad/param norm = 3.3568e-01, time/batch = 14.4117s	
12442/22300 (epoch 27.897), train_loss = 0.50551270, grad/param norm = 2.5958e-01, time/batch = 14.6548s	
12443/22300 (epoch 27.899), train_loss = 0.50351724, grad/param norm = 2.3216e-01, time/batch = 15.1761s	
12444/22300 (epoch 27.901), train_loss = 0.57322278, grad/param norm = 3.0440e-01, time/batch = 14.7234s	
12445/22300 (epoch 27.904), train_loss = 0.61941574, grad/param norm = 3.7646e-01, time/batch = 14.6538s	
12446/22300 (epoch 27.906), train_loss = 0.57286265, grad/param norm = 2.7520e-01, time/batch = 14.6544s	
12447/22300 (epoch 27.908), train_loss = 0.50448181, grad/param norm = 2.3400e-01, time/batch = 14.8072s	
12448/22300 (epoch 27.910), train_loss = 0.43117340, grad/param norm = 2.1650e-01, time/batch = 14.3416s	
12449/22300 (epoch 27.913), train_loss = 0.60783091, grad/param norm = 3.0507e-01, time/batch = 14.6556s	
12450/22300 (epoch 27.915), train_loss = 0.65708214, grad/param norm = 2.4982e-01, time/batch = 14.5808s	
12451/22300 (epoch 27.917), train_loss = 0.57846208, grad/param norm = 2.7272e-01, time/batch = 14.8155s	
12452/22300 (epoch 27.919), train_loss = 0.58553372, grad/param norm = 2.3881e-01, time/batch = 14.4952s	
12453/22300 (epoch 27.922), train_loss = 0.50968304, grad/param norm = 2.6911e-01, time/batch = 14.8858s	
12454/22300 (epoch 27.924), train_loss = 0.35463524, grad/param norm = 2.6935e-01, time/batch = 14.7330s	
12455/22300 (epoch 27.926), train_loss = 0.41883825, grad/param norm = 2.1566e-01, time/batch = 15.7735s	
12456/22300 (epoch 27.928), train_loss = 0.47418309, grad/param norm = 2.5811e-01, time/batch = 15.3955s	
12457/22300 (epoch 27.930), train_loss = 0.47859559, grad/param norm = 2.7539e-01, time/batch = 16.5648s	
12458/22300 (epoch 27.933), train_loss = 0.56010650, grad/param norm = 2.6930e-01, time/batch = 15.9637s	
12459/22300 (epoch 27.935), train_loss = 0.54599498, grad/param norm = 2.7965e-01, time/batch = 15.5177s	
12460/22300 (epoch 27.937), train_loss = 0.64517682, grad/param norm = 3.2114e-01, time/batch = 18.1929s	
12461/22300 (epoch 27.939), train_loss = 0.61864581, grad/param norm = 3.6970e-01, time/batch = 16.1370s	
12462/22300 (epoch 27.942), train_loss = 0.73668959, grad/param norm = 3.8402e-01, time/batch = 18.1160s	
12463/22300 (epoch 27.944), train_loss = 0.78552883, grad/param norm = 4.1502e-01, time/batch = 14.5744s	
12464/22300 (epoch 27.946), train_loss = 0.56175322, grad/param norm = 3.5345e-01, time/batch = 17.2862s	
12465/22300 (epoch 27.948), train_loss = 0.46156961, grad/param norm = 2.2389e-01, time/batch = 15.3953s	
12466/22300 (epoch 27.951), train_loss = 0.40419675, grad/param norm = 2.3479e-01, time/batch = 14.7857s	
12467/22300 (epoch 27.953), train_loss = 0.47106884, grad/param norm = 2.8513e-01, time/batch = 14.8868s	
12468/22300 (epoch 27.955), train_loss = 0.67927983, grad/param norm = 3.3441e-01, time/batch = 15.8636s	
12469/22300 (epoch 27.957), train_loss = 0.77696489, grad/param norm = 3.5258e-01, time/batch = 15.0661s	
12470/22300 (epoch 27.960), train_loss = 0.66420464, grad/param norm = 2.9876e-01, time/batch = 16.3761s	
12471/22300 (epoch 27.962), train_loss = 0.45034211, grad/param norm = 2.7207e-01, time/batch = 15.9008s	
12472/22300 (epoch 27.964), train_loss = 0.50819540, grad/param norm = 2.7779e-01, time/batch = 15.6352s	
12473/22300 (epoch 27.966), train_loss = 0.44411479, grad/param norm = 2.4511e-01, time/batch = 16.0664s	
12474/22300 (epoch 27.969), train_loss = 0.51399882, grad/param norm = 2.6037e-01, time/batch = 15.6006s	
12475/22300 (epoch 27.971), train_loss = 0.51723212, grad/param norm = 2.5348e-01, time/batch = 15.6879s	
12476/22300 (epoch 27.973), train_loss = 0.53201630, grad/param norm = 3.5480e-01, time/batch = 15.5193s	
12477/22300 (epoch 27.975), train_loss = 0.70644714, grad/param norm = 3.3205e-01, time/batch = 15.8979s	
12478/22300 (epoch 27.978), train_loss = 0.62257934, grad/param norm = 2.9783e-01, time/batch = 16.4424s	
12479/22300 (epoch 27.980), train_loss = 0.68609437, grad/param norm = 2.9801e-01, time/batch = 18.7978s	
12480/22300 (epoch 27.982), train_loss = 0.43022070, grad/param norm = 3.0336e-01, time/batch = 15.8859s	
12481/22300 (epoch 27.984), train_loss = 0.53569266, grad/param norm = 2.6103e-01, time/batch = 21.9799s	
12482/22300 (epoch 27.987), train_loss = 0.46813045, grad/param norm = 2.5143e-01, time/batch = 22.4618s	
12483/22300 (epoch 27.989), train_loss = 0.44848750, grad/param norm = 2.6879e-01, time/batch = 14.6369s	
12484/22300 (epoch 27.991), train_loss = 0.73744726, grad/param norm = 3.0824e-01, time/batch = 16.2083s	
12485/22300 (epoch 27.993), train_loss = 0.93941313, grad/param norm = 3.6409e-01, time/batch = 15.5540s	
12486/22300 (epoch 27.996), train_loss = 0.88039202, grad/param norm = 3.7095e-01, time/batch = 16.2255s	
12487/22300 (epoch 27.998), train_loss = 0.55295967, grad/param norm = 3.1400e-01, time/batch = 15.2934s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
12488/22300 (epoch 28.000), train_loss = 0.46295470, grad/param norm = 2.8173e-01, time/batch = 16.0050s	
12489/22300 (epoch 28.002), train_loss = 0.82659418, grad/param norm = 3.2582e-01, time/batch = 15.8009s	
12490/22300 (epoch 28.004), train_loss = 0.56810703, grad/param norm = 2.4478e-01, time/batch = 14.9904s	
12491/22300 (epoch 28.007), train_loss = 0.60222286, grad/param norm = 3.6915e-01, time/batch = 16.6309s	
12492/22300 (epoch 28.009), train_loss = 0.58613690, grad/param norm = 2.9432e-01, time/batch = 15.6674s	
12493/22300 (epoch 28.011), train_loss = 0.74179498, grad/param norm = 3.3038e-01, time/batch = 15.1311s	
12494/22300 (epoch 28.013), train_loss = 0.57272650, grad/param norm = 2.4577e-01, time/batch = 18.4507s	
12495/22300 (epoch 28.016), train_loss = 0.45893938, grad/param norm = 2.8822e-01, time/batch = 16.1277s	
12496/22300 (epoch 28.018), train_loss = 0.58446330, grad/param norm = 3.2671e-01, time/batch = 15.6795s	
12497/22300 (epoch 28.020), train_loss = 0.51400611, grad/param norm = 2.8255e-01, time/batch = 15.4586s	
12498/22300 (epoch 28.022), train_loss = 0.46143976, grad/param norm = 3.2902e-01, time/batch = 17.1041s	
12499/22300 (epoch 28.025), train_loss = 0.48231296, grad/param norm = 2.7425e-01, time/batch = 16.8686s	
12500/22300 (epoch 28.027), train_loss = 0.44621668, grad/param norm = 2.1340e-01, time/batch = 16.6395s	
12501/22300 (epoch 28.029), train_loss = 0.45966073, grad/param norm = 2.1654e-01, time/batch = 16.1387s	
12502/22300 (epoch 28.031), train_loss = 0.45662732, grad/param norm = 2.4093e-01, time/batch = 15.8804s	
12503/22300 (epoch 28.034), train_loss = 0.45376857, grad/param norm = 2.2397e-01, time/batch = 15.2135s	
12504/22300 (epoch 28.036), train_loss = 0.39459799, grad/param norm = 1.9517e-01, time/batch = 16.4689s	
12505/22300 (epoch 28.038), train_loss = 0.41765534, grad/param norm = 2.4169e-01, time/batch = 15.8131s	
12506/22300 (epoch 28.040), train_loss = 0.51171997, grad/param norm = 3.2147e-01, time/batch = 16.7128s	
12507/22300 (epoch 28.043), train_loss = 0.74216414, grad/param norm = 3.3115e-01, time/batch = 15.3946s	
12508/22300 (epoch 28.045), train_loss = 0.61611120, grad/param norm = 2.8557e-01, time/batch = 16.8887s	
12509/22300 (epoch 28.047), train_loss = 0.63775344, grad/param norm = 2.9729e-01, time/batch = 16.7986s	
12510/22300 (epoch 28.049), train_loss = 0.49291310, grad/param norm = 2.4344e-01, time/batch = 15.5077s	
12511/22300 (epoch 28.052), train_loss = 0.59449421, grad/param norm = 3.5475e-01, time/batch = 15.7932s	
12512/22300 (epoch 28.054), train_loss = 0.58827664, grad/param norm = 3.3457e-01, time/batch = 15.5811s	
12513/22300 (epoch 28.056), train_loss = 0.31061218, grad/param norm = 2.0171e-01, time/batch = 17.0523s	
12514/22300 (epoch 28.058), train_loss = 0.48187985, grad/param norm = 2.7868e-01, time/batch = 15.5379s	
12515/22300 (epoch 28.061), train_loss = 0.46830482, grad/param norm = 3.1325e-01, time/batch = 17.8808s	
12516/22300 (epoch 28.063), train_loss = 0.68230637, grad/param norm = 3.9348e-01, time/batch = 15.7408s	
12517/22300 (epoch 28.065), train_loss = 0.70534873, grad/param norm = 3.7262e-01, time/batch = 15.4595s	
12518/22300 (epoch 28.067), train_loss = 0.47171705, grad/param norm = 2.9102e-01, time/batch = 5.7719s	
12519/22300 (epoch 28.070), train_loss = 0.53537080, grad/param norm = 3.2638e-01, time/batch = 0.6622s	
12520/22300 (epoch 28.072), train_loss = 0.62281473, grad/param norm = 3.8231e-01, time/batch = 0.6559s	
12521/22300 (epoch 28.074), train_loss = 0.56227886, grad/param norm = 3.1244e-01, time/batch = 0.6590s	
12522/22300 (epoch 28.076), train_loss = 0.57603269, grad/param norm = 3.3427e-01, time/batch = 0.6530s	
12523/22300 (epoch 28.078), train_loss = 0.64221926, grad/param norm = 2.9534e-01, time/batch = 0.6616s	
12524/22300 (epoch 28.081), train_loss = 0.66653234, grad/param norm = 3.2579e-01, time/batch = 0.6613s	
12525/22300 (epoch 28.083), train_loss = 0.74911641, grad/param norm = 3.2916e-01, time/batch = 0.6651s	
12526/22300 (epoch 28.085), train_loss = 0.73022845, grad/param norm = 3.4059e-01, time/batch = 0.6746s	
12527/22300 (epoch 28.087), train_loss = 0.61520097, grad/param norm = 2.9908e-01, time/batch = 0.6768s	
12528/22300 (epoch 28.090), train_loss = 0.50192389, grad/param norm = 2.4622e-01, time/batch = 0.6806s	
12529/22300 (epoch 28.092), train_loss = 0.44147826, grad/param norm = 2.6025e-01, time/batch = 0.6978s	
12530/22300 (epoch 28.094), train_loss = 0.41588264, grad/param norm = 2.3996e-01, time/batch = 0.6999s	
12531/22300 (epoch 28.096), train_loss = 0.74824915, grad/param norm = 4.3879e-01, time/batch = 0.6757s	
12532/22300 (epoch 28.099), train_loss = 0.48874230, grad/param norm = 2.9241e-01, time/batch = 0.6854s	
12533/22300 (epoch 28.101), train_loss = 0.63380252, grad/param norm = 3.3271e-01, time/batch = 0.9857s	
12534/22300 (epoch 28.103), train_loss = 0.54156110, grad/param norm = 3.1039e-01, time/batch = 0.9872s	
12535/22300 (epoch 28.105), train_loss = 0.45044861, grad/param norm = 2.9371e-01, time/batch = 0.9942s	
12536/22300 (epoch 28.108), train_loss = 0.56393206, grad/param norm = 2.7973e-01, time/batch = 1.0181s	
12537/22300 (epoch 28.110), train_loss = 0.62177883, grad/param norm = 2.9681e-01, time/batch = 1.0022s	
12538/22300 (epoch 28.112), train_loss = 0.56336200, grad/param norm = 2.4656e-01, time/batch = 1.7737s	
12539/22300 (epoch 28.114), train_loss = 0.62757385, grad/param norm = 3.0511e-01, time/batch = 1.9646s	
12540/22300 (epoch 28.117), train_loss = 0.72160760, grad/param norm = 3.1967e-01, time/batch = 6.2612s	
12541/22300 (epoch 28.119), train_loss = 0.66142645, grad/param norm = 3.1053e-01, time/batch = 16.8014s	
12542/22300 (epoch 28.121), train_loss = 0.72417653, grad/param norm = 3.1917e-01, time/batch = 16.3133s	
12543/22300 (epoch 28.123), train_loss = 0.72451304, grad/param norm = 3.0350e-01, time/batch = 17.2202s	
12544/22300 (epoch 28.126), train_loss = 0.58264233, grad/param norm = 3.1069e-01, time/batch = 16.3106s	
12545/22300 (epoch 28.128), train_loss = 0.59521759, grad/param norm = 3.2351e-01, time/batch = 15.1873s	
12546/22300 (epoch 28.130), train_loss = 0.50626127, grad/param norm = 2.9830e-01, time/batch = 14.9448s	
12547/22300 (epoch 28.132), train_loss = 0.39018139, grad/param norm = 2.2617e-01, time/batch = 14.6521s	
12548/22300 (epoch 28.135), train_loss = 0.42101222, grad/param norm = 2.7353e-01, time/batch = 15.4657s	
12549/22300 (epoch 28.137), train_loss = 0.32741868, grad/param norm = 2.1006e-01, time/batch = 15.2198s	
12550/22300 (epoch 28.139), train_loss = 0.54072627, grad/param norm = 3.7501e-01, time/batch = 15.3559s	
12551/22300 (epoch 28.141), train_loss = 0.61209280, grad/param norm = 2.5322e-01, time/batch = 15.4446s	
12552/22300 (epoch 28.143), train_loss = 0.54831853, grad/param norm = 2.5913e-01, time/batch = 15.3137s	
12553/22300 (epoch 28.146), train_loss = 0.63477605, grad/param norm = 2.9746e-01, time/batch = 15.7989s	
12554/22300 (epoch 28.148), train_loss = 0.43966641, grad/param norm = 2.5034e-01, time/batch = 14.9704s	
12555/22300 (epoch 28.150), train_loss = 0.49668885, grad/param norm = 2.6454e-01, time/batch = 16.8007s	
12556/22300 (epoch 28.152), train_loss = 0.41164246, grad/param norm = 2.6636e-01, time/batch = 16.3907s	
12557/22300 (epoch 28.155), train_loss = 0.44324761, grad/param norm = 2.6380e-01, time/batch = 17.1317s	
12558/22300 (epoch 28.157), train_loss = 0.59107833, grad/param norm = 3.4674e-01, time/batch = 16.3020s	
12559/22300 (epoch 28.159), train_loss = 0.61940792, grad/param norm = 3.4654e-01, time/batch = 15.8725s	
12560/22300 (epoch 28.161), train_loss = 0.61864197, grad/param norm = 3.2156e-01, time/batch = 16.3034s	
12561/22300 (epoch 28.164), train_loss = 0.46407698, grad/param norm = 2.2975e-01, time/batch = 16.8026s	
12562/22300 (epoch 28.166), train_loss = 0.41898785, grad/param norm = 2.1750e-01, time/batch = 16.2177s	
12563/22300 (epoch 28.168), train_loss = 0.43186796, grad/param norm = 3.0000e-01, time/batch = 14.8065s	
12564/22300 (epoch 28.170), train_loss = 0.53619377, grad/param norm = 2.7243e-01, time/batch = 15.0575s	
12565/22300 (epoch 28.173), train_loss = 0.65393895, grad/param norm = 3.4048e-01, time/batch = 15.0325s	
12566/22300 (epoch 28.175), train_loss = 0.52811812, grad/param norm = 2.7323e-01, time/batch = 15.6420s	
12567/22300 (epoch 28.177), train_loss = 0.37094603, grad/param norm = 2.2625e-01, time/batch = 16.2137s	
12568/22300 (epoch 28.179), train_loss = 0.52594365, grad/param norm = 2.4405e-01, time/batch = 15.1429s	
12569/22300 (epoch 28.182), train_loss = 0.72082446, grad/param norm = 3.3333e-01, time/batch = 16.6074s	
12570/22300 (epoch 28.184), train_loss = 0.77700992, grad/param norm = 3.0888e-01, time/batch = 15.6361s	
12571/22300 (epoch 28.186), train_loss = 0.56081936, grad/param norm = 2.9837e-01, time/batch = 15.8170s	
12572/22300 (epoch 28.188), train_loss = 0.75493760, grad/param norm = 3.3855e-01, time/batch = 16.1939s	
12573/22300 (epoch 28.191), train_loss = 0.70135872, grad/param norm = 3.3581e-01, time/batch = 14.9467s	
12574/22300 (epoch 28.193), train_loss = 0.56337661, grad/param norm = 3.1896e-01, time/batch = 15.4108s	
12575/22300 (epoch 28.195), train_loss = 0.52115381, grad/param norm = 2.5905e-01, time/batch = 15.0614s	
12576/22300 (epoch 28.197), train_loss = 0.47114132, grad/param norm = 2.8443e-01, time/batch = 14.8157s	
12577/22300 (epoch 28.200), train_loss = 0.42320288, grad/param norm = 2.4671e-01, time/batch = 16.0665s	
12578/22300 (epoch 28.202), train_loss = 0.48053519, grad/param norm = 3.1085e-01, time/batch = 15.3907s	
12579/22300 (epoch 28.204), train_loss = 0.51227473, grad/param norm = 2.5435e-01, time/batch = 15.4592s	
12580/22300 (epoch 28.206), train_loss = 0.46041048, grad/param norm = 2.9423e-01, time/batch = 15.1478s	
12581/22300 (epoch 28.209), train_loss = 0.51486204, grad/param norm = 2.7497e-01, time/batch = 15.9087s	
12582/22300 (epoch 28.211), train_loss = 0.41663411, grad/param norm = 2.7968e-01, time/batch = 16.3197s	
12583/22300 (epoch 28.213), train_loss = 0.54357305, grad/param norm = 2.6911e-01, time/batch = 15.9522s	
12584/22300 (epoch 28.215), train_loss = 0.69623834, grad/param norm = 3.3828e-01, time/batch = 15.5679s	
12585/22300 (epoch 28.217), train_loss = 0.67431675, grad/param norm = 3.0983e-01, time/batch = 14.9882s	
12586/22300 (epoch 28.220), train_loss = 0.48617573, grad/param norm = 2.3716e-01, time/batch = 18.2908s	
12587/22300 (epoch 28.222), train_loss = 0.44713886, grad/param norm = 2.4329e-01, time/batch = 17.7905s	
12588/22300 (epoch 28.224), train_loss = 0.47859603, grad/param norm = 2.6491e-01, time/batch = 15.5202s	
12589/22300 (epoch 28.226), train_loss = 0.51122948, grad/param norm = 2.5072e-01, time/batch = 15.8118s	
12590/22300 (epoch 28.229), train_loss = 0.43960963, grad/param norm = 2.8152e-01, time/batch = 16.2120s	
12591/22300 (epoch 28.231), train_loss = 0.62776597, grad/param norm = 3.4017e-01, time/batch = 16.8759s	
12592/22300 (epoch 28.233), train_loss = 0.56215545, grad/param norm = 3.3587e-01, time/batch = 15.6380s	
12593/22300 (epoch 28.235), train_loss = 0.41531968, grad/param norm = 2.3350e-01, time/batch = 17.1797s	
12594/22300 (epoch 28.238), train_loss = 0.42712454, grad/param norm = 2.4283e-01, time/batch = 15.0801s	
12595/22300 (epoch 28.240), train_loss = 0.43614534, grad/param norm = 1.9991e-01, time/batch = 14.8558s	
12596/22300 (epoch 28.242), train_loss = 0.43646226, grad/param norm = 2.7204e-01, time/batch = 15.0179s	
12597/22300 (epoch 28.244), train_loss = 0.29347894, grad/param norm = 1.9059e-01, time/batch = 16.5581s	
12598/22300 (epoch 28.247), train_loss = 0.41465903, grad/param norm = 2.5392e-01, time/batch = 16.9707s	
12599/22300 (epoch 28.249), train_loss = 0.29302976, grad/param norm = 2.1565e-01, time/batch = 15.8740s	
12600/22300 (epoch 28.251), train_loss = 0.38866777, grad/param norm = 2.0818e-01, time/batch = 16.2005s	
12601/22300 (epoch 28.253), train_loss = 0.28532571, grad/param norm = 2.0188e-01, time/batch = 17.0480s	
12602/22300 (epoch 28.256), train_loss = 0.37149366, grad/param norm = 2.5337e-01, time/batch = 17.1315s	
12603/22300 (epoch 28.258), train_loss = 0.53743562, grad/param norm = 2.8543e-01, time/batch = 15.5403s	
12604/22300 (epoch 28.260), train_loss = 0.53290475, grad/param norm = 2.5705e-01, time/batch = 15.8164s	
12605/22300 (epoch 28.262), train_loss = 0.41241166, grad/param norm = 2.2663e-01, time/batch = 16.2351s	
12606/22300 (epoch 28.265), train_loss = 0.39577794, grad/param norm = 3.1489e-01, time/batch = 16.0434s	
12607/22300 (epoch 28.267), train_loss = 0.45825896, grad/param norm = 2.6957e-01, time/batch = 15.1470s	
12608/22300 (epoch 28.269), train_loss = 0.51656061, grad/param norm = 2.8497e-01, time/batch = 15.6363s	
12609/22300 (epoch 28.271), train_loss = 0.55032850, grad/param norm = 2.4081e-01, time/batch = 18.2012s	
12610/22300 (epoch 28.274), train_loss = 0.39919659, grad/param norm = 2.4377e-01, time/batch = 15.8062s	
12611/22300 (epoch 28.276), train_loss = 0.34462178, grad/param norm = 1.7794e-01, time/batch = 15.7144s	
12612/22300 (epoch 28.278), train_loss = 0.34999310, grad/param norm = 2.1625e-01, time/batch = 15.5931s	
12613/22300 (epoch 28.280), train_loss = 0.40098885, grad/param norm = 2.1253e-01, time/batch = 16.0641s	
12614/22300 (epoch 28.283), train_loss = 0.30768053, grad/param norm = 1.5953e-01, time/batch = 15.1996s	
12615/22300 (epoch 28.285), train_loss = 0.38987447, grad/param norm = 2.3111e-01, time/batch = 16.1222s	
12616/22300 (epoch 28.287), train_loss = 0.50763535, grad/param norm = 2.4637e-01, time/batch = 14.8779s	
12617/22300 (epoch 28.289), train_loss = 0.46863793, grad/param norm = 2.7464e-01, time/batch = 16.3828s	
12618/22300 (epoch 28.291), train_loss = 0.46356838, grad/param norm = 2.4516e-01, time/batch = 15.3943s	
12619/22300 (epoch 28.294), train_loss = 0.36269701, grad/param norm = 1.9867e-01, time/batch = 15.3989s	
12620/22300 (epoch 28.296), train_loss = 0.45955867, grad/param norm = 3.1202e-01, time/batch = 15.8704s	
12621/22300 (epoch 28.298), train_loss = 0.58511076, grad/param norm = 2.9436e-01, time/batch = 14.4011s	
12622/22300 (epoch 28.300), train_loss = 0.63328647, grad/param norm = 2.7802e-01, time/batch = 15.8094s	
12623/22300 (epoch 28.303), train_loss = 0.47133371, grad/param norm = 2.3700e-01, time/batch = 16.3016s	
12624/22300 (epoch 28.305), train_loss = 0.47982470, grad/param norm = 3.0763e-01, time/batch = 18.1282s	
12625/22300 (epoch 28.307), train_loss = 0.44089440, grad/param norm = 2.7175e-01, time/batch = 15.1275s	
12626/22300 (epoch 28.309), train_loss = 0.40382356, grad/param norm = 2.5389e-01, time/batch = 16.4789s	
12627/22300 (epoch 28.312), train_loss = 0.35313661, grad/param norm = 1.9324e-01, time/batch = 15.8137s	
12628/22300 (epoch 28.314), train_loss = 0.39248025, grad/param norm = 2.6488e-01, time/batch = 15.0340s	
12629/22300 (epoch 28.316), train_loss = 0.39804818, grad/param norm = 2.5354e-01, time/batch = 15.6192s	
12630/22300 (epoch 28.318), train_loss = 0.45786538, grad/param norm = 2.6165e-01, time/batch = 15.4799s	
12631/22300 (epoch 28.321), train_loss = 0.57796171, grad/param norm = 2.6632e-01, time/batch = 15.3894s	
12632/22300 (epoch 28.323), train_loss = 0.40807427, grad/param norm = 2.4352e-01, time/batch = 14.9598s	
12633/22300 (epoch 28.325), train_loss = 0.37113115, grad/param norm = 2.6599e-01, time/batch = 16.5318s	
12634/22300 (epoch 28.327), train_loss = 0.38545583, grad/param norm = 2.4351e-01, time/batch = 17.9596s	
12635/22300 (epoch 28.330), train_loss = 0.39972008, grad/param norm = 3.4180e-01, time/batch = 17.2164s	
12636/22300 (epoch 28.332), train_loss = 0.37461346, grad/param norm = 2.1728e-01, time/batch = 16.5482s	
12637/22300 (epoch 28.334), train_loss = 0.43294713, grad/param norm = 2.4682e-01, time/batch = 16.5407s	
12638/22300 (epoch 28.336), train_loss = 0.44365012, grad/param norm = 2.3913e-01, time/batch = 14.9780s	
12639/22300 (epoch 28.339), train_loss = 0.51395318, grad/param norm = 2.9667e-01, time/batch = 18.1231s	
12640/22300 (epoch 28.341), train_loss = 0.54096595, grad/param norm = 3.1164e-01, time/batch = 16.7635s	
12641/22300 (epoch 28.343), train_loss = 0.61042167, grad/param norm = 3.1987e-01, time/batch = 16.0557s	
12642/22300 (epoch 28.345), train_loss = 0.45891375, grad/param norm = 2.4683e-01, time/batch = 18.2211s	
12643/22300 (epoch 28.348), train_loss = 0.44452996, grad/param norm = 2.3861e-01, time/batch = 16.7015s	
12644/22300 (epoch 28.350), train_loss = 0.39644243, grad/param norm = 2.4999e-01, time/batch = 15.4839s	
12645/22300 (epoch 28.352), train_loss = 0.49472034, grad/param norm = 2.7624e-01, time/batch = 15.5786s	
12646/22300 (epoch 28.354), train_loss = 0.70682534, grad/param norm = 2.9981e-01, time/batch = 15.2772s	
12647/22300 (epoch 28.357), train_loss = 0.60770312, grad/param norm = 3.0742e-01, time/batch = 15.3847s	
12648/22300 (epoch 28.359), train_loss = 0.40000196, grad/param norm = 2.6492e-01, time/batch = 15.1560s	
12649/22300 (epoch 28.361), train_loss = 0.40880454, grad/param norm = 2.5788e-01, time/batch = 15.1381s	
12650/22300 (epoch 28.363), train_loss = 0.56445271, grad/param norm = 3.0423e-01, time/batch = 15.1283s	
12651/22300 (epoch 28.365), train_loss = 0.46788448, grad/param norm = 3.0603e-01, time/batch = 15.7348s	
12652/22300 (epoch 28.368), train_loss = 0.47310850, grad/param norm = 3.2413e-01, time/batch = 15.4937s	
12653/22300 (epoch 28.370), train_loss = 0.43377799, grad/param norm = 2.2531e-01, time/batch = 15.6919s	
12654/22300 (epoch 28.372), train_loss = 0.36020877, grad/param norm = 2.3799e-01, time/batch = 15.3675s	
12655/22300 (epoch 28.374), train_loss = 0.31614232, grad/param norm = 2.0475e-01, time/batch = 15.6156s	
12656/22300 (epoch 28.377), train_loss = 0.45671100, grad/param norm = 2.8603e-01, time/batch = 14.8830s	
12657/22300 (epoch 28.379), train_loss = 0.41974969, grad/param norm = 2.6199e-01, time/batch = 15.1360s	
12658/22300 (epoch 28.381), train_loss = 0.53947735, grad/param norm = 2.5874e-01, time/batch = 17.7040s	
12659/22300 (epoch 28.383), train_loss = 0.48672031, grad/param norm = 3.0290e-01, time/batch = 15.2180s	
12660/22300 (epoch 28.386), train_loss = 0.46659561, grad/param norm = 2.7378e-01, time/batch = 16.0560s	
12661/22300 (epoch 28.388), train_loss = 0.36853621, grad/param norm = 2.2949e-01, time/batch = 16.2011s	
12662/22300 (epoch 28.390), train_loss = 0.45172268, grad/param norm = 3.0412e-01, time/batch = 17.0110s	
12663/22300 (epoch 28.392), train_loss = 0.44801247, grad/param norm = 3.1835e-01, time/batch = 15.5461s	
12664/22300 (epoch 28.395), train_loss = 0.37317125, grad/param norm = 2.2610e-01, time/batch = 14.7301s	
12665/22300 (epoch 28.397), train_loss = 0.26437425, grad/param norm = 2.3063e-01, time/batch = 16.6286s	
12666/22300 (epoch 28.399), train_loss = 0.37257211, grad/param norm = 2.4551e-01, time/batch = 16.1397s	
12667/22300 (epoch 28.401), train_loss = 0.43700406, grad/param norm = 3.0512e-01, time/batch = 15.9700s	
12668/22300 (epoch 28.404), train_loss = 0.44189580, grad/param norm = 2.8767e-01, time/batch = 16.2973s	
12669/22300 (epoch 28.406), train_loss = 0.64367995, grad/param norm = 3.1177e-01, time/batch = 15.8994s	
12670/22300 (epoch 28.408), train_loss = 0.53247180, grad/param norm = 2.5144e-01, time/batch = 15.1757s	
12671/22300 (epoch 28.410), train_loss = 0.58003192, grad/param norm = 3.1059e-01, time/batch = 14.5011s	
12672/22300 (epoch 28.413), train_loss = 0.40471171, grad/param norm = 2.4257e-01, time/batch = 15.1993s	
12673/22300 (epoch 28.415), train_loss = 0.32157238, grad/param norm = 2.2884e-01, time/batch = 14.4195s	
12674/22300 (epoch 28.417), train_loss = 0.48797864, grad/param norm = 2.5592e-01, time/batch = 14.6506s	
12675/22300 (epoch 28.419), train_loss = 0.42327905, grad/param norm = 2.1432e-01, time/batch = 14.4891s	
12676/22300 (epoch 28.422), train_loss = 0.40099548, grad/param norm = 2.9353e-01, time/batch = 14.6668s	
12677/22300 (epoch 28.424), train_loss = 0.47886385, grad/param norm = 2.5137e-01, time/batch = 14.8989s	
12678/22300 (epoch 28.426), train_loss = 0.33519521, grad/param norm = 2.3640e-01, time/batch = 14.9697s	
12679/22300 (epoch 28.428), train_loss = 0.36650977, grad/param norm = 2.1921e-01, time/batch = 14.7249s	
12680/22300 (epoch 28.430), train_loss = 0.44031110, grad/param norm = 3.0591e-01, time/batch = 14.8095s	
12681/22300 (epoch 28.433), train_loss = 0.44119768, grad/param norm = 2.4506e-01, time/batch = 14.5862s	
12682/22300 (epoch 28.435), train_loss = 0.41308140, grad/param norm = 2.6084e-01, time/batch = 15.3472s	
12683/22300 (epoch 28.437), train_loss = 0.49452992, grad/param norm = 3.2185e-01, time/batch = 14.4223s	
12684/22300 (epoch 28.439), train_loss = 0.55463940, grad/param norm = 3.0135e-01, time/batch = 14.7317s	
12685/22300 (epoch 28.442), train_loss = 0.47631910, grad/param norm = 2.7325e-01, time/batch = 14.5641s	
12686/22300 (epoch 28.444), train_loss = 0.38993638, grad/param norm = 2.1886e-01, time/batch = 15.0528s	
12687/22300 (epoch 28.446), train_loss = 0.40558028, grad/param norm = 2.3951e-01, time/batch = 15.2026s	
12688/22300 (epoch 28.448), train_loss = 0.29431150, grad/param norm = 1.7068e-01, time/batch = 14.3347s	
12689/22300 (epoch 28.451), train_loss = 0.51236298, grad/param norm = 2.7863e-01, time/batch = 14.1714s	
12690/22300 (epoch 28.453), train_loss = 0.40004592, grad/param norm = 2.2865e-01, time/batch = 14.7928s	
12691/22300 (epoch 28.455), train_loss = 0.57779191, grad/param norm = 3.1624e-01, time/batch = 14.7404s	
12692/22300 (epoch 28.457), train_loss = 0.65118219, grad/param norm = 3.1845e-01, time/batch = 14.4202s	
12693/22300 (epoch 28.460), train_loss = 0.54707873, grad/param norm = 2.6993e-01, time/batch = 14.4957s	
12694/22300 (epoch 28.462), train_loss = 0.58903224, grad/param norm = 2.8725e-01, time/batch = 14.7252s	
12695/22300 (epoch 28.464), train_loss = 0.51813234, grad/param norm = 2.8362e-01, time/batch = 14.6570s	
12696/22300 (epoch 28.466), train_loss = 0.42865433, grad/param norm = 2.1594e-01, time/batch = 14.7759s	
12697/22300 (epoch 28.469), train_loss = 0.40558173, grad/param norm = 1.9680e-01, time/batch = 14.2428s	
12698/22300 (epoch 28.471), train_loss = 0.54336696, grad/param norm = 2.5676e-01, time/batch = 14.4662s	
12699/22300 (epoch 28.473), train_loss = 0.48263447, grad/param norm = 2.5082e-01, time/batch = 14.1655s	
12700/22300 (epoch 28.475), train_loss = 0.41746406, grad/param norm = 2.7834e-01, time/batch = 14.4830s	
12701/22300 (epoch 28.478), train_loss = 0.42670115, grad/param norm = 3.0382e-01, time/batch = 14.3281s	
12702/22300 (epoch 28.480), train_loss = 0.31493129, grad/param norm = 2.6936e-01, time/batch = 14.9414s	
12703/22300 (epoch 28.482), train_loss = 0.35419794, grad/param norm = 2.4739e-01, time/batch = 14.4787s	
12704/22300 (epoch 28.484), train_loss = 0.45100935, grad/param norm = 2.3829e-01, time/batch = 14.4202s	
12705/22300 (epoch 28.487), train_loss = 0.51899978, grad/param norm = 2.4456e-01, time/batch = 14.2520s	
12706/22300 (epoch 28.489), train_loss = 0.51244676, grad/param norm = 2.2740e-01, time/batch = 14.7272s	
12707/22300 (epoch 28.491), train_loss = 0.54869412, grad/param norm = 2.9954e-01, time/batch = 15.5845s	
12708/22300 (epoch 28.493), train_loss = 0.49516662, grad/param norm = 4.1583e-01, time/batch = 14.4043s	
12709/22300 (epoch 28.496), train_loss = 0.46567148, grad/param norm = 2.3174e-01, time/batch = 14.5859s	
12710/22300 (epoch 28.498), train_loss = 0.33693352, grad/param norm = 2.2915e-01, time/batch = 14.8232s	
12711/22300 (epoch 28.500), train_loss = 0.48416661, grad/param norm = 2.9099e-01, time/batch = 15.5505s	
12712/22300 (epoch 28.502), train_loss = 0.31854676, grad/param norm = 2.3223e-01, time/batch = 14.3389s	
12713/22300 (epoch 28.504), train_loss = 0.32305563, grad/param norm = 2.0573e-01, time/batch = 14.6513s	
12714/22300 (epoch 28.507), train_loss = 0.41112541, grad/param norm = 2.5328e-01, time/batch = 14.4911s	
12715/22300 (epoch 28.509), train_loss = 0.50064773, grad/param norm = 2.5532e-01, time/batch = 14.8897s	
12716/22300 (epoch 28.511), train_loss = 0.28998789, grad/param norm = 1.8982e-01, time/batch = 14.8079s	
12717/22300 (epoch 28.513), train_loss = 0.32880967, grad/param norm = 2.0426e-01, time/batch = 14.7776s	
12718/22300 (epoch 28.516), train_loss = 0.40140872, grad/param norm = 2.7970e-01, time/batch = 14.3972s	
12719/22300 (epoch 28.518), train_loss = 0.51672645, grad/param norm = 2.8758e-01, time/batch = 14.6385s	
12720/22300 (epoch 28.520), train_loss = 0.41533140, grad/param norm = 2.3349e-01, time/batch = 14.0932s	
12721/22300 (epoch 28.522), train_loss = 0.42874961, grad/param norm = 2.2944e-01, time/batch = 15.5210s	
12722/22300 (epoch 28.525), train_loss = 0.35003256, grad/param norm = 2.3157e-01, time/batch = 15.3534s	
12723/22300 (epoch 28.527), train_loss = 0.56648990, grad/param norm = 3.1992e-01, time/batch = 15.5382s	
12724/22300 (epoch 28.529), train_loss = 0.46342749, grad/param norm = 2.5967e-01, time/batch = 14.5002s	
12725/22300 (epoch 28.531), train_loss = 0.42610006, grad/param norm = 2.7380e-01, time/batch = 15.3452s	
12726/22300 (epoch 28.534), train_loss = 0.41645951, grad/param norm = 2.3160e-01, time/batch = 15.4421s	
12727/22300 (epoch 28.536), train_loss = 0.60685805, grad/param norm = 2.5020e-01, time/batch = 14.8111s	
12728/22300 (epoch 28.538), train_loss = 0.76521909, grad/param norm = 3.5140e-01, time/batch = 15.6456s	
12729/22300 (epoch 28.540), train_loss = 0.46223362, grad/param norm = 2.5350e-01, time/batch = 14.5831s	
12730/22300 (epoch 28.543), train_loss = 0.40791893, grad/param norm = 2.0779e-01, time/batch = 14.8239s	
12731/22300 (epoch 28.545), train_loss = 0.33104686, grad/param norm = 2.2714e-01, time/batch = 27.3410s	
12732/22300 (epoch 28.547), train_loss = 0.32090112, grad/param norm = 2.5835e-01, time/batch = 14.8899s	
12733/22300 (epoch 28.549), train_loss = 0.37771006, grad/param norm = 2.3146e-01, time/batch = 14.4504s	
12734/22300 (epoch 28.552), train_loss = 0.38430802, grad/param norm = 2.8721e-01, time/batch = 14.5607s	
12735/22300 (epoch 28.554), train_loss = 0.48047456, grad/param norm = 2.5150e-01, time/batch = 14.4882s	
12736/22300 (epoch 28.556), train_loss = 0.66670819, grad/param norm = 4.5137e-01, time/batch = 14.1630s	
12737/22300 (epoch 28.558), train_loss = 0.53426117, grad/param norm = 3.0884e-01, time/batch = 14.3874s	
12738/22300 (epoch 28.561), train_loss = 0.65826325, grad/param norm = 3.0537e-01, time/batch = 15.4366s	
12739/22300 (epoch 28.563), train_loss = 0.58010912, grad/param norm = 3.3123e-01, time/batch = 14.4927s	
12740/22300 (epoch 28.565), train_loss = 0.45997244, grad/param norm = 3.1542e-01, time/batch = 14.4107s	
12741/22300 (epoch 28.567), train_loss = 0.45236904, grad/param norm = 3.0918e-01, time/batch = 14.2528s	
12742/22300 (epoch 28.570), train_loss = 0.61080321, grad/param norm = 3.1766e-01, time/batch = 14.9536s	
12743/22300 (epoch 28.572), train_loss = 0.58329937, grad/param norm = 2.9047e-01, time/batch = 14.3222s	
12744/22300 (epoch 28.574), train_loss = 0.47423717, grad/param norm = 2.5952e-01, time/batch = 14.2532s	
12745/22300 (epoch 28.576), train_loss = 0.38753560, grad/param norm = 1.8816e-01, time/batch = 14.4205s	
12746/22300 (epoch 28.578), train_loss = 0.22806137, grad/param norm = 1.4284e-01, time/batch = 14.8912s	
12747/22300 (epoch 28.581), train_loss = 0.35059126, grad/param norm = 2.4422e-01, time/batch = 15.2789s	
12748/22300 (epoch 28.583), train_loss = 0.39253077, grad/param norm = 2.3528e-01, time/batch = 15.2029s	
12749/22300 (epoch 28.585), train_loss = 0.55286356, grad/param norm = 2.8030e-01, time/batch = 14.4180s	
12750/22300 (epoch 28.587), train_loss = 0.74437733, grad/param norm = 3.1213e-01, time/batch = 15.2151s	
12751/22300 (epoch 28.590), train_loss = 0.60586469, grad/param norm = 3.2164e-01, time/batch = 15.2926s	
12752/22300 (epoch 28.592), train_loss = 0.73228630, grad/param norm = 3.7669e-01, time/batch = 14.6616s	
12753/22300 (epoch 28.594), train_loss = 0.69151883, grad/param norm = 3.4533e-01, time/batch = 14.8227s	
12754/22300 (epoch 28.596), train_loss = 0.44597688, grad/param norm = 2.5083e-01, time/batch = 14.8159s	
12755/22300 (epoch 28.599), train_loss = 0.33763938, grad/param norm = 2.5223e-01, time/batch = 15.0591s	
12756/22300 (epoch 28.601), train_loss = 0.41071083, grad/param norm = 2.5036e-01, time/batch = 14.5844s	
12757/22300 (epoch 28.603), train_loss = 0.44094992, grad/param norm = 2.3402e-01, time/batch = 14.1760s	
12758/22300 (epoch 28.605), train_loss = 0.43193449, grad/param norm = 2.4649e-01, time/batch = 14.9764s	
12759/22300 (epoch 28.608), train_loss = 0.71871411, grad/param norm = 3.1880e-01, time/batch = 14.9163s	
12760/22300 (epoch 28.610), train_loss = 0.71876581, grad/param norm = 2.9909e-01, time/batch = 15.1273s	
12761/22300 (epoch 28.612), train_loss = 0.56357209, grad/param norm = 3.3181e-01, time/batch = 15.2946s	
12762/22300 (epoch 28.614), train_loss = 0.57084528, grad/param norm = 3.2529e-01, time/batch = 15.3469s	
12763/22300 (epoch 28.617), train_loss = 0.56885913, grad/param norm = 2.8095e-01, time/batch = 15.0742s	
12764/22300 (epoch 28.619), train_loss = 0.69178777, grad/param norm = 3.3246e-01, time/batch = 14.8981s	
12765/22300 (epoch 28.621), train_loss = 0.43893805, grad/param norm = 2.5537e-01, time/batch = 15.1080s	
12766/22300 (epoch 28.623), train_loss = 0.43767207, grad/param norm = 2.4103e-01, time/batch = 15.1164s	
12767/22300 (epoch 28.626), train_loss = 0.40487834, grad/param norm = 2.5342e-01, time/batch = 15.1438s	
12768/22300 (epoch 28.628), train_loss = 0.39803734, grad/param norm = 1.9993e-01, time/batch = 14.9035s	
12769/22300 (epoch 28.630), train_loss = 0.48279953, grad/param norm = 2.5697e-01, time/batch = 15.3623s	
12770/22300 (epoch 28.632), train_loss = 0.42122949, grad/param norm = 2.5454e-01, time/batch = 15.5038s	
12771/22300 (epoch 28.635), train_loss = 0.45717800, grad/param norm = 2.5960e-01, time/batch = 16.2256s	
12772/22300 (epoch 28.637), train_loss = 0.53349547, grad/param norm = 2.7814e-01, time/batch = 16.0632s	
12773/22300 (epoch 28.639), train_loss = 0.64201870, grad/param norm = 3.4252e-01, time/batch = 15.8966s	
12774/22300 (epoch 28.641), train_loss = 0.51945485, grad/param norm = 2.8535e-01, time/batch = 16.1443s	
12775/22300 (epoch 28.643), train_loss = 0.41120705, grad/param norm = 2.5232e-01, time/batch = 16.4664s	
12776/22300 (epoch 28.646), train_loss = 0.39352378, grad/param norm = 2.5710e-01, time/batch = 15.9060s	
12777/22300 (epoch 28.648), train_loss = 0.47448033, grad/param norm = 2.2822e-01, time/batch = 15.8508s	
12778/22300 (epoch 28.650), train_loss = 0.52666316, grad/param norm = 3.0464e-01, time/batch = 15.6206s	
12779/22300 (epoch 28.652), train_loss = 0.43811867, grad/param norm = 2.4673e-01, time/batch = 15.3745s	
12780/22300 (epoch 28.655), train_loss = 0.39571551, grad/param norm = 2.3351e-01, time/batch = 16.0242s	
12781/22300 (epoch 28.657), train_loss = 0.45739258, grad/param norm = 2.8615e-01, time/batch = 15.5357s	
12782/22300 (epoch 28.659), train_loss = 0.43312905, grad/param norm = 2.9327e-01, time/batch = 14.6638s	
12783/22300 (epoch 28.661), train_loss = 0.33330225, grad/param norm = 2.0528e-01, time/batch = 15.0648s	
12784/22300 (epoch 28.664), train_loss = 0.39718765, grad/param norm = 2.1272e-01, time/batch = 15.7208s	
12785/22300 (epoch 28.666), train_loss = 0.52168442, grad/param norm = 2.7534e-01, time/batch = 15.7825s	
12786/22300 (epoch 28.668), train_loss = 0.41574987, grad/param norm = 3.1598e-01, time/batch = 15.8141s	
12787/22300 (epoch 28.670), train_loss = 0.49956058, grad/param norm = 2.5274e-01, time/batch = 15.0692s	
12788/22300 (epoch 28.673), train_loss = 0.58016452, grad/param norm = 2.9622e-01, time/batch = 15.7453s	
12789/22300 (epoch 28.675), train_loss = 0.61913097, grad/param norm = 3.1705e-01, time/batch = 15.6759s	
12790/22300 (epoch 28.677), train_loss = 0.67308351, grad/param norm = 3.1706e-01, time/batch = 15.8941s	
12791/22300 (epoch 28.679), train_loss = 0.50842962, grad/param norm = 2.7751e-01, time/batch = 16.1161s	
12792/22300 (epoch 28.682), train_loss = 0.48752123, grad/param norm = 2.4817e-01, time/batch = 16.0550s	
12793/22300 (epoch 28.684), train_loss = 0.43135173, grad/param norm = 2.1172e-01, time/batch = 15.8700s	
12794/22300 (epoch 28.686), train_loss = 0.47351208, grad/param norm = 2.5909e-01, time/batch = 16.0196s	
12795/22300 (epoch 28.688), train_loss = 0.43577432, grad/param norm = 2.4160e-01, time/batch = 15.7221s	
12796/22300 (epoch 28.691), train_loss = 0.39888357, grad/param norm = 2.5218e-01, time/batch = 15.8765s	
12797/22300 (epoch 28.693), train_loss = 0.38598104, grad/param norm = 2.4356e-01, time/batch = 15.9758s	
12798/22300 (epoch 28.695), train_loss = 0.38411725, grad/param norm = 2.5438e-01, time/batch = 15.9775s	
12799/22300 (epoch 28.697), train_loss = 0.39699358, grad/param norm = 2.1376e-01, time/batch = 15.9727s	
12800/22300 (epoch 28.700), train_loss = 0.40509678, grad/param norm = 2.7554e-01, time/batch = 15.9393s	
12801/22300 (epoch 28.702), train_loss = 0.34376188, grad/param norm = 1.8996e-01, time/batch = 16.1417s	
12802/22300 (epoch 28.704), train_loss = 0.47117741, grad/param norm = 3.1590e-01, time/batch = 15.9808s	
12803/22300 (epoch 28.706), train_loss = 0.37516528, grad/param norm = 2.1197e-01, time/batch = 15.9459s	
12804/22300 (epoch 28.709), train_loss = 0.33096367, grad/param norm = 2.3804e-01, time/batch = 15.8836s	
12805/22300 (epoch 28.711), train_loss = 0.32894805, grad/param norm = 1.9660e-01, time/batch = 15.8468s	
12806/22300 (epoch 28.713), train_loss = 0.46427794, grad/param norm = 2.1355e-01, time/batch = 15.9834s	
12807/22300 (epoch 28.715), train_loss = 0.44598899, grad/param norm = 2.2331e-01, time/batch = 15.7915s	
12808/22300 (epoch 28.717), train_loss = 0.63734360, grad/param norm = 2.7011e-01, time/batch = 15.8821s	
12809/22300 (epoch 28.720), train_loss = 0.38931513, grad/param norm = 2.3012e-01, time/batch = 15.8772s	
12810/22300 (epoch 28.722), train_loss = 0.49140729, grad/param norm = 2.4434e-01, time/batch = 15.8045s	
12811/22300 (epoch 28.724), train_loss = 0.52400806, grad/param norm = 2.8434e-01, time/batch = 16.1044s	
12812/22300 (epoch 28.726), train_loss = 0.41020369, grad/param norm = 2.8568e-01, time/batch = 15.9656s	
12813/22300 (epoch 28.729), train_loss = 0.45904897, grad/param norm = 2.3614e-01, time/batch = 15.7150s	
12814/22300 (epoch 28.731), train_loss = 0.64750689, grad/param norm = 3.5787e-01, time/batch = 15.7299s	
12815/22300 (epoch 28.733), train_loss = 0.64321896, grad/param norm = 3.3999e-01, time/batch = 15.8546s	
12816/22300 (epoch 28.735), train_loss = 0.65844860, grad/param norm = 3.0505e-01, time/batch = 16.0900s	
12817/22300 (epoch 28.738), train_loss = 0.47911661, grad/param norm = 3.1962e-01, time/batch = 15.8803s	
12818/22300 (epoch 28.740), train_loss = 0.43861865, grad/param norm = 2.2778e-01, time/batch = 15.5392s	
12819/22300 (epoch 28.742), train_loss = 0.40760343, grad/param norm = 2.2332e-01, time/batch = 15.7810s	
12820/22300 (epoch 28.744), train_loss = 0.67956650, grad/param norm = 3.0071e-01, time/batch = 16.0445s	
12821/22300 (epoch 28.747), train_loss = 0.54032482, grad/param norm = 2.5651e-01, time/batch = 15.9346s	
12822/22300 (epoch 28.749), train_loss = 0.68065154, grad/param norm = 3.6301e-01, time/batch = 15.9589s	
12823/22300 (epoch 28.751), train_loss = 0.62419380, grad/param norm = 3.6059e-01, time/batch = 16.1165s	
12824/22300 (epoch 28.753), train_loss = 0.65897792, grad/param norm = 3.2302e-01, time/batch = 16.0297s	
12825/22300 (epoch 28.756), train_loss = 0.56348684, grad/param norm = 3.1500e-01, time/batch = 15.9715s	
12826/22300 (epoch 28.758), train_loss = 0.50581839, grad/param norm = 2.7964e-01, time/batch = 15.9426s	
12827/22300 (epoch 28.760), train_loss = 0.56034263, grad/param norm = 3.0217e-01, time/batch = 16.0216s	
12828/22300 (epoch 28.762), train_loss = 0.51996311, grad/param norm = 2.9029e-01, time/batch = 15.9532s	
12829/22300 (epoch 28.765), train_loss = 0.52945967, grad/param norm = 3.2699e-01, time/batch = 15.9666s	
12830/22300 (epoch 28.767), train_loss = 0.54803510, grad/param norm = 3.1557e-01, time/batch = 15.9528s	
12831/22300 (epoch 28.769), train_loss = 0.49141894, grad/param norm = 2.8096e-01, time/batch = 16.0396s	
12832/22300 (epoch 28.771), train_loss = 0.57606451, grad/param norm = 2.9969e-01, time/batch = 16.0505s	
12833/22300 (epoch 28.774), train_loss = 0.60123955, grad/param norm = 3.7065e-01, time/batch = 15.9452s	
12834/22300 (epoch 28.776), train_loss = 0.65879958, grad/param norm = 3.3626e-01, time/batch = 16.1096s	
12835/22300 (epoch 28.778), train_loss = 0.62058867, grad/param norm = 3.0012e-01, time/batch = 15.5675s	
12836/22300 (epoch 28.780), train_loss = 0.63287405, grad/param norm = 3.5860e-01, time/batch = 15.8418s	
12837/22300 (epoch 28.783), train_loss = 0.69244272, grad/param norm = 3.6690e-01, time/batch = 15.9371s	
12838/22300 (epoch 28.785), train_loss = 0.49424120, grad/param norm = 2.9541e-01, time/batch = 15.7952s	
12839/22300 (epoch 28.787), train_loss = 0.48207461, grad/param norm = 2.7524e-01, time/batch = 15.9742s	
12840/22300 (epoch 28.789), train_loss = 0.70959479, grad/param norm = 4.5697e-01, time/batch = 16.0733s	
12841/22300 (epoch 28.791), train_loss = 0.86882842, grad/param norm = 4.1495e-01, time/batch = 16.1232s	
12842/22300 (epoch 28.794), train_loss = 0.65798456, grad/param norm = 3.7282e-01, time/batch = 16.0627s	
12843/22300 (epoch 28.796), train_loss = 0.61228681, grad/param norm = 3.2584e-01, time/batch = 16.0558s	
12844/22300 (epoch 28.798), train_loss = 0.74158948, grad/param norm = 3.6091e-01, time/batch = 16.1460s	
12845/22300 (epoch 28.800), train_loss = 0.51429411, grad/param norm = 2.6378e-01, time/batch = 15.7981s	
12846/22300 (epoch 28.803), train_loss = 0.46929804, grad/param norm = 2.5352e-01, time/batch = 15.9743s	
12847/22300 (epoch 28.805), train_loss = 0.55973760, grad/param norm = 3.2871e-01, time/batch = 15.9644s	
12848/22300 (epoch 28.807), train_loss = 0.68718181, grad/param norm = 4.0202e-01, time/batch = 15.9760s	
12849/22300 (epoch 28.809), train_loss = 0.49543223, grad/param norm = 2.9313e-01, time/batch = 16.1012s	
12850/22300 (epoch 28.812), train_loss = 0.57684335, grad/param norm = 3.2988e-01, time/batch = 16.2221s	
12851/22300 (epoch 28.814), train_loss = 0.58300313, grad/param norm = 3.3660e-01, time/batch = 16.3053s	
12852/22300 (epoch 28.816), train_loss = 0.57701039, grad/param norm = 2.8647e-01, time/batch = 15.9629s	
12853/22300 (epoch 28.818), train_loss = 0.68147549, grad/param norm = 3.6114e-01, time/batch = 15.9619s	
12854/22300 (epoch 28.821), train_loss = 0.57306626, grad/param norm = 2.8491e-01, time/batch = 15.8980s	
12855/22300 (epoch 28.823), train_loss = 0.37760432, grad/param norm = 2.0142e-01, time/batch = 15.9878s	
12856/22300 (epoch 28.825), train_loss = 0.41783620, grad/param norm = 2.9618e-01, time/batch = 15.7816s	
12857/22300 (epoch 28.827), train_loss = 0.49771381, grad/param norm = 3.0135e-01, time/batch = 15.6287s	
12858/22300 (epoch 28.830), train_loss = 0.49350157, grad/param norm = 2.9200e-01, time/batch = 15.9387s	
12859/22300 (epoch 28.832), train_loss = 0.44089792, grad/param norm = 2.5575e-01, time/batch = 16.1027s	
12860/22300 (epoch 28.834), train_loss = 0.39312469, grad/param norm = 2.6401e-01, time/batch = 16.1635s	
12861/22300 (epoch 28.836), train_loss = 0.49498884, grad/param norm = 3.0905e-01, time/batch = 16.1853s	
12862/22300 (epoch 28.839), train_loss = 0.51548528, grad/param norm = 3.7309e-01, time/batch = 16.2905s	
12863/22300 (epoch 28.841), train_loss = 0.51385001, grad/param norm = 3.3037e-01, time/batch = 16.1278s	
12864/22300 (epoch 28.843), train_loss = 0.48044666, grad/param norm = 2.5885e-01, time/batch = 16.1483s	
12865/22300 (epoch 28.845), train_loss = 0.46537688, grad/param norm = 2.4414e-01, time/batch = 16.0689s	
12866/22300 (epoch 28.848), train_loss = 0.48731411, grad/param norm = 2.7837e-01, time/batch = 16.2229s	
12867/22300 (epoch 28.850), train_loss = 0.48709102, grad/param norm = 2.4252e-01, time/batch = 16.2136s	
12868/22300 (epoch 28.852), train_loss = 0.45764213, grad/param norm = 2.7215e-01, time/batch = 16.2014s	
12869/22300 (epoch 28.854), train_loss = 0.71470341, grad/param norm = 3.3643e-01, time/batch = 16.1400s	
12870/22300 (epoch 28.857), train_loss = 0.55821578, grad/param norm = 3.6904e-01, time/batch = 16.2224s	
12871/22300 (epoch 28.859), train_loss = 0.43909528, grad/param norm = 2.7643e-01, time/batch = 16.5314s	
12872/22300 (epoch 28.861), train_loss = 0.59232965, grad/param norm = 2.8616e-01, time/batch = 16.3064s	
12873/22300 (epoch 28.863), train_loss = 0.41227262, grad/param norm = 2.6553e-01, time/batch = 15.7011s	
12874/22300 (epoch 28.865), train_loss = 0.38894482, grad/param norm = 2.2041e-01, time/batch = 16.0282s	
12875/22300 (epoch 28.868), train_loss = 0.51368480, grad/param norm = 2.5235e-01, time/batch = 15.8411s	
12876/22300 (epoch 28.870), train_loss = 0.54855536, grad/param norm = 2.9466e-01, time/batch = 15.8927s	
12877/22300 (epoch 28.872), train_loss = 0.60332927, grad/param norm = 2.8888e-01, time/batch = 15.7309s	
12878/22300 (epoch 28.874), train_loss = 0.52703432, grad/param norm = 2.7168e-01, time/batch = 15.7159s	
12879/22300 (epoch 28.877), train_loss = 0.55007215, grad/param norm = 2.9842e-01, time/batch = 16.1100s	
12880/22300 (epoch 28.879), train_loss = 0.46014416, grad/param norm = 2.4847e-01, time/batch = 16.3227s	
12881/22300 (epoch 28.881), train_loss = 0.39657792, grad/param norm = 2.2716e-01, time/batch = 15.4891s	
12882/22300 (epoch 28.883), train_loss = 0.41727315, grad/param norm = 2.9150e-01, time/batch = 15.7205s	
12883/22300 (epoch 28.886), train_loss = 0.41517547, grad/param norm = 2.7267e-01, time/batch = 14.7896s	
12884/22300 (epoch 28.888), train_loss = 0.46673496, grad/param norm = 2.6679e-01, time/batch = 15.4145s	
12885/22300 (epoch 28.890), train_loss = 0.44815095, grad/param norm = 2.3469e-01, time/batch = 15.5433s	
12886/22300 (epoch 28.892), train_loss = 0.68427934, grad/param norm = 3.0097e-01, time/batch = 15.0441s	
12887/22300 (epoch 28.895), train_loss = 0.61479709, grad/param norm = 3.0316e-01, time/batch = 15.2358s	
12888/22300 (epoch 28.897), train_loss = 0.50392006, grad/param norm = 2.9452e-01, time/batch = 15.3830s	
12889/22300 (epoch 28.899), train_loss = 0.50563365, grad/param norm = 2.6596e-01, time/batch = 15.8693s	
12890/22300 (epoch 28.901), train_loss = 0.53047827, grad/param norm = 2.4713e-01, time/batch = 15.3042s	
12891/22300 (epoch 28.904), train_loss = 0.57336193, grad/param norm = 2.8464e-01, time/batch = 16.0415s	
12892/22300 (epoch 28.906), train_loss = 0.57076669, grad/param norm = 3.2412e-01, time/batch = 15.3081s	
12893/22300 (epoch 28.908), train_loss = 0.48226212, grad/param norm = 2.3972e-01, time/batch = 14.8099s	
12894/22300 (epoch 28.910), train_loss = 0.41532439, grad/param norm = 2.1720e-01, time/batch = 15.2689s	
12895/22300 (epoch 28.913), train_loss = 0.57203749, grad/param norm = 2.9377e-01, time/batch = 16.0617s	
12896/22300 (epoch 28.915), train_loss = 0.67785765, grad/param norm = 3.3347e-01, time/batch = 15.6805s	
12897/22300 (epoch 28.917), train_loss = 0.56738317, grad/param norm = 2.9498e-01, time/batch = 16.3345s	
12898/22300 (epoch 28.919), train_loss = 0.55640101, grad/param norm = 2.4880e-01, time/batch = 15.3852s	
12899/22300 (epoch 28.922), train_loss = 0.52970071, grad/param norm = 3.6534e-01, time/batch = 15.3960s	
12900/22300 (epoch 28.924), train_loss = 0.34081213, grad/param norm = 2.4451e-01, time/batch = 18.1331s	
12901/22300 (epoch 28.926), train_loss = 0.42626582, grad/param norm = 2.6701e-01, time/batch = 16.0597s	
12902/22300 (epoch 28.928), train_loss = 0.46321544, grad/param norm = 2.5827e-01, time/batch = 15.7782s	
12903/22300 (epoch 28.930), train_loss = 0.45327088, grad/param norm = 2.5569e-01, time/batch = 15.5726s	
12904/22300 (epoch 28.933), train_loss = 0.54109903, grad/param norm = 2.8146e-01, time/batch = 15.6472s	
12905/22300 (epoch 28.935), train_loss = 0.53302267, grad/param norm = 3.1256e-01, time/batch = 15.5382s	
12906/22300 (epoch 28.937), train_loss = 0.61474142, grad/param norm = 3.4976e-01, time/batch = 15.3098s	
12907/22300 (epoch 28.939), train_loss = 0.58969819, grad/param norm = 3.1280e-01, time/batch = 15.4838s	
12908/22300 (epoch 28.942), train_loss = 0.70530333, grad/param norm = 3.7350e-01, time/batch = 16.0270s	
12909/22300 (epoch 28.944), train_loss = 0.77414687, grad/param norm = 4.2293e-01, time/batch = 15.6319s	
12910/22300 (epoch 28.946), train_loss = 0.53332647, grad/param norm = 2.7750e-01, time/batch = 15.3934s	
12911/22300 (epoch 28.948), train_loss = 0.45474272, grad/param norm = 2.3360e-01, time/batch = 15.2966s	
12912/22300 (epoch 28.951), train_loss = 0.37984235, grad/param norm = 2.3087e-01, time/batch = 17.4505s	
12913/22300 (epoch 28.953), train_loss = 0.44866521, grad/param norm = 2.6499e-01, time/batch = 15.6378s	
12914/22300 (epoch 28.955), train_loss = 0.64038079, grad/param norm = 2.9172e-01, time/batch = 15.7241s	
12915/22300 (epoch 28.957), train_loss = 0.74391490, grad/param norm = 3.3780e-01, time/batch = 17.2019s	
12916/22300 (epoch 28.960), train_loss = 0.64299539, grad/param norm = 2.8558e-01, time/batch = 15.9679s	
12917/22300 (epoch 28.962), train_loss = 0.43401520, grad/param norm = 2.6486e-01, time/batch = 17.2958s	
12918/22300 (epoch 28.964), train_loss = 0.48780875, grad/param norm = 2.8409e-01, time/batch = 15.6382s	
12919/22300 (epoch 28.966), train_loss = 0.40306740, grad/param norm = 2.2484e-01, time/batch = 18.5470s	
12920/22300 (epoch 28.969), train_loss = 0.48201875, grad/param norm = 2.7581e-01, time/batch = 15.5507s	
12921/22300 (epoch 28.971), train_loss = 0.51540964, grad/param norm = 3.3128e-01, time/batch = 16.0124s	
12922/22300 (epoch 28.973), train_loss = 0.52155877, grad/param norm = 2.8262e-01, time/batch = 16.5228s	
12923/22300 (epoch 28.975), train_loss = 0.69381004, grad/param norm = 3.7547e-01, time/batch = 15.7376s	
12924/22300 (epoch 28.978), train_loss = 0.61604417, grad/param norm = 2.8187e-01, time/batch = 15.7658s	
12925/22300 (epoch 28.980), train_loss = 0.67064306, grad/param norm = 3.2735e-01, time/batch = 16.8841s	
12926/22300 (epoch 28.982), train_loss = 0.41214615, grad/param norm = 2.7629e-01, time/batch = 17.4725s	
12927/22300 (epoch 28.984), train_loss = 0.51377841, grad/param norm = 2.7269e-01, time/batch = 14.9466s	
12928/22300 (epoch 28.987), train_loss = 0.48348355, grad/param norm = 2.7216e-01, time/batch = 17.1290s	
12929/22300 (epoch 28.989), train_loss = 0.43624807, grad/param norm = 2.7425e-01, time/batch = 15.2818s	
12930/22300 (epoch 28.991), train_loss = 0.72587682, grad/param norm = 3.6439e-01, time/batch = 15.9793s	
12931/22300 (epoch 28.993), train_loss = 0.90075930, grad/param norm = 3.3522e-01, time/batch = 16.1058s	
12932/22300 (epoch 28.996), train_loss = 0.87502486, grad/param norm = 3.5634e-01, time/batch = 15.9605s	
12933/22300 (epoch 28.998), train_loss = 0.53521188, grad/param norm = 3.1835e-01, time/batch = 17.1428s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
12934/22300 (epoch 29.000), train_loss = 0.43431045, grad/param norm = 2.4099e-01, time/batch = 15.2848s	
12935/22300 (epoch 29.002), train_loss = 0.79845963, grad/param norm = 2.9624e-01, time/batch = 15.1530s	
12936/22300 (epoch 29.004), train_loss = 0.54964759, grad/param norm = 2.5296e-01, time/batch = 16.4798s	
12937/22300 (epoch 29.007), train_loss = 0.56753677, grad/param norm = 2.9845e-01, time/batch = 17.0571s	
12938/22300 (epoch 29.009), train_loss = 0.60205891, grad/param norm = 3.2013e-01, time/batch = 16.1783s	
12939/22300 (epoch 29.011), train_loss = 0.70651701, grad/param norm = 2.9000e-01, time/batch = 17.6321s	
12940/22300 (epoch 29.013), train_loss = 0.55442829, grad/param norm = 2.5823e-01, time/batch = 15.2226s	
12941/22300 (epoch 29.016), train_loss = 0.44762560, grad/param norm = 2.7742e-01, time/batch = 17.1306s	
12942/22300 (epoch 29.018), train_loss = 0.54779609, grad/param norm = 3.1326e-01, time/batch = 15.4304s	
12943/22300 (epoch 29.020), train_loss = 0.50756181, grad/param norm = 3.1430e-01, time/batch = 15.3383s	
12944/22300 (epoch 29.022), train_loss = 0.41937895, grad/param norm = 2.6941e-01, time/batch = 15.4461s	
12945/22300 (epoch 29.025), train_loss = 0.44121427, grad/param norm = 2.4363e-01, time/batch = 15.3889s	
12946/22300 (epoch 29.027), train_loss = 0.41270073, grad/param norm = 2.0408e-01, time/batch = 14.8845s	
12947/22300 (epoch 29.029), train_loss = 0.46512009, grad/param norm = 2.4417e-01, time/batch = 16.6398s	
12948/22300 (epoch 29.031), train_loss = 0.43222583, grad/param norm = 2.0292e-01, time/batch = 15.4722s	
12949/22300 (epoch 29.034), train_loss = 0.44349195, grad/param norm = 2.6665e-01, time/batch = 16.8771s	
12950/22300 (epoch 29.036), train_loss = 0.39507979, grad/param norm = 2.3404e-01, time/batch = 16.2047s	
12951/22300 (epoch 29.038), train_loss = 0.41137281, grad/param norm = 2.5028e-01, time/batch = 15.1535s	
12952/22300 (epoch 29.040), train_loss = 0.46205009, grad/param norm = 2.7410e-01, time/batch = 15.6448s	
12953/22300 (epoch 29.043), train_loss = 0.72760178, grad/param norm = 3.1285e-01, time/batch = 15.7087s	
12954/22300 (epoch 29.045), train_loss = 0.59582808, grad/param norm = 2.9010e-01, time/batch = 15.0689s	
12955/22300 (epoch 29.047), train_loss = 0.62840958, grad/param norm = 2.8918e-01, time/batch = 15.9801s	
12956/22300 (epoch 29.049), train_loss = 0.48767856, grad/param norm = 2.5111e-01, time/batch = 17.8805s	
12957/22300 (epoch 29.052), train_loss = 0.56993219, grad/param norm = 2.9364e-01, time/batch = 26.2546s	
12958/22300 (epoch 29.054), train_loss = 0.54460576, grad/param norm = 2.6420e-01, time/batch = 17.1233s	
12959/22300 (epoch 29.056), train_loss = 0.29613316, grad/param norm = 1.9050e-01, time/batch = 17.1353s	
12960/22300 (epoch 29.058), train_loss = 0.46953795, grad/param norm = 2.9110e-01, time/batch = 15.4423s	
12961/22300 (epoch 29.061), train_loss = 0.42019968, grad/param norm = 2.6153e-01, time/batch = 15.6547s	
12962/22300 (epoch 29.063), train_loss = 0.63959582, grad/param norm = 3.9033e-01, time/batch = 15.6857s	
12963/22300 (epoch 29.065), train_loss = 0.68674277, grad/param norm = 3.8458e-01, time/batch = 15.5309s	
12964/22300 (epoch 29.067), train_loss = 0.44714709, grad/param norm = 2.5798e-01, time/batch = 15.3645s	
12965/22300 (epoch 29.070), train_loss = 0.50270184, grad/param norm = 2.8613e-01, time/batch = 15.0555s	
12966/22300 (epoch 29.072), train_loss = 0.58894704, grad/param norm = 2.9212e-01, time/batch = 14.8656s	
12967/22300 (epoch 29.074), train_loss = 0.54767606, grad/param norm = 3.1634e-01, time/batch = 15.9743s	
12968/22300 (epoch 29.076), train_loss = 0.56785637, grad/param norm = 3.0876e-01, time/batch = 15.2067s	
12969/22300 (epoch 29.078), train_loss = 0.67357618, grad/param norm = 3.9941e-01, time/batch = 15.5587s	
12970/22300 (epoch 29.081), train_loss = 0.66880876, grad/param norm = 3.9479e-01, time/batch = 14.8839s	
12971/22300 (epoch 29.083), train_loss = 0.75823481, grad/param norm = 3.4276e-01, time/batch = 15.1239s	
12972/22300 (epoch 29.085), train_loss = 0.69407507, grad/param norm = 3.0451e-01, time/batch = 15.2187s	
12973/22300 (epoch 29.087), train_loss = 0.61283504, grad/param norm = 3.2336e-01, time/batch = 16.4648s	
12974/22300 (epoch 29.090), train_loss = 0.53138519, grad/param norm = 3.5355e-01, time/batch = 16.3838s	
12975/22300 (epoch 29.092), train_loss = 0.43282928, grad/param norm = 2.5465e-01, time/batch = 16.5324s	
12976/22300 (epoch 29.094), train_loss = 0.41908660, grad/param norm = 2.7483e-01, time/batch = 15.9723s	
12977/22300 (epoch 29.096), train_loss = 0.68511549, grad/param norm = 3.8192e-01, time/batch = 15.7871s	
12978/22300 (epoch 29.099), train_loss = 0.48863428, grad/param norm = 3.1666e-01, time/batch = 15.0693s	
12979/22300 (epoch 29.101), train_loss = 0.62200932, grad/param norm = 3.5262e-01, time/batch = 15.2034s	
12980/22300 (epoch 29.103), train_loss = 0.53803882, grad/param norm = 2.8511e-01, time/batch = 16.7265s	
12981/22300 (epoch 29.105), train_loss = 0.43619997, grad/param norm = 2.6296e-01, time/batch = 15.5996s	
12982/22300 (epoch 29.108), train_loss = 0.56644009, grad/param norm = 3.2898e-01, time/batch = 15.7000s	
12983/22300 (epoch 29.110), train_loss = 0.62319676, grad/param norm = 2.9156e-01, time/batch = 15.5824s	
12984/22300 (epoch 29.112), train_loss = 0.52998612, grad/param norm = 2.2905e-01, time/batch = 16.3717s	
12985/22300 (epoch 29.114), train_loss = 0.61736018, grad/param norm = 3.1931e-01, time/batch = 15.7317s	
12986/22300 (epoch 29.117), train_loss = 0.74543109, grad/param norm = 3.7166e-01, time/batch = 17.2728s	
12987/22300 (epoch 29.119), train_loss = 0.65271846, grad/param norm = 3.0487e-01, time/batch = 15.4152s	
12988/22300 (epoch 29.121), train_loss = 0.72453898, grad/param norm = 3.1166e-01, time/batch = 15.0600s	
12989/22300 (epoch 29.123), train_loss = 0.71262773, grad/param norm = 3.0939e-01, time/batch = 15.3598s	
12990/22300 (epoch 29.126), train_loss = 0.56685289, grad/param norm = 2.6860e-01, time/batch = 14.9479s	
12991/22300 (epoch 29.128), train_loss = 0.57762376, grad/param norm = 2.8792e-01, time/batch = 15.3961s	
12992/22300 (epoch 29.130), train_loss = 0.45840395, grad/param norm = 2.1477e-01, time/batch = 15.7517s	
12993/22300 (epoch 29.132), train_loss = 0.38177343, grad/param norm = 2.5249e-01, time/batch = 17.2118s	
12994/22300 (epoch 29.135), train_loss = 0.40596832, grad/param norm = 2.7976e-01, time/batch = 15.8392s	
12995/22300 (epoch 29.137), train_loss = 0.32058598, grad/param norm = 2.1722e-01, time/batch = 15.9005s	
12996/22300 (epoch 29.139), train_loss = 0.49514150, grad/param norm = 2.9289e-01, time/batch = 15.6696s	
12997/22300 (epoch 29.141), train_loss = 0.60221719, grad/param norm = 2.7382e-01, time/batch = 15.0478s	
12998/22300 (epoch 29.143), train_loss = 0.53203975, grad/param norm = 2.6884e-01, time/batch = 16.0049s	
12999/22300 (epoch 29.146), train_loss = 0.64167342, grad/param norm = 3.3304e-01, time/batch = 14.8845s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch29.15_1.5762.t7	
13000/22300 (epoch 29.148), train_loss = 0.42115209, grad/param norm = 2.8681e-01, time/batch = 16.4218s	
13001/22300 (epoch 29.150), train_loss = 1.19818949, grad/param norm = 3.8939e-01, time/batch = 15.1240s	
13002/22300 (epoch 29.152), train_loss = 0.40839441, grad/param norm = 2.4418e-01, time/batch = 16.8860s	
13003/22300 (epoch 29.155), train_loss = 0.43012641, grad/param norm = 3.0858e-01, time/batch = 16.0484s	
13004/22300 (epoch 29.157), train_loss = 0.58505098, grad/param norm = 3.8894e-01, time/batch = 15.6306s	
13005/22300 (epoch 29.159), train_loss = 0.62299029, grad/param norm = 3.2307e-01, time/batch = 15.0641s	
13006/22300 (epoch 29.161), train_loss = 0.59995792, grad/param norm = 2.8742e-01, time/batch = 18.6262s	
13007/22300 (epoch 29.164), train_loss = 0.43938317, grad/param norm = 2.3862e-01, time/batch = 15.3633s	
13008/22300 (epoch 29.166), train_loss = 0.39272310, grad/param norm = 2.0424e-01, time/batch = 18.5310s	
13009/22300 (epoch 29.168), train_loss = 0.43124389, grad/param norm = 3.3480e-01, time/batch = 15.4722s	
13010/22300 (epoch 29.170), train_loss = 0.54393400, grad/param norm = 3.0358e-01, time/batch = 15.5912s	
13011/22300 (epoch 29.173), train_loss = 0.67363146, grad/param norm = 3.5953e-01, time/batch = 15.4556s	
13012/22300 (epoch 29.175), train_loss = 0.51911521, grad/param norm = 2.7123e-01, time/batch = 15.1577s	
13013/22300 (epoch 29.177), train_loss = 0.37426865, grad/param norm = 2.4057e-01, time/batch = 15.1387s	
13014/22300 (epoch 29.179), train_loss = 0.50589275, grad/param norm = 2.4500e-01, time/batch = 15.5088s	
13015/22300 (epoch 29.182), train_loss = 0.70799822, grad/param norm = 3.3163e-01, time/batch = 15.1716s	
13016/22300 (epoch 29.184), train_loss = 0.76470281, grad/param norm = 3.5014e-01, time/batch = 16.4799s	
13017/22300 (epoch 29.186), train_loss = 0.55193466, grad/param norm = 2.8738e-01, time/batch = 16.3209s	
13018/22300 (epoch 29.188), train_loss = 0.73810344, grad/param norm = 3.3030e-01, time/batch = 16.3641s	
13019/22300 (epoch 29.191), train_loss = 0.66644925, grad/param norm = 3.5367e-01, time/batch = 14.6377s	
13020/22300 (epoch 29.193), train_loss = 0.57002141, grad/param norm = 3.6134e-01, time/batch = 15.6533s	
13021/22300 (epoch 29.195), train_loss = 0.54201066, grad/param norm = 3.2012e-01, time/batch = 16.8872s	
13022/22300 (epoch 29.197), train_loss = 0.46906907, grad/param norm = 2.7552e-01, time/batch = 15.7939s	
13023/22300 (epoch 29.200), train_loss = 0.41973049, grad/param norm = 2.7800e-01, time/batch = 15.8982s	
13024/22300 (epoch 29.202), train_loss = 0.45218425, grad/param norm = 2.4925e-01, time/batch = 14.9852s	
13025/22300 (epoch 29.204), train_loss = 0.52724734, grad/param norm = 2.8332e-01, time/batch = 16.1168s	
13026/22300 (epoch 29.206), train_loss = 0.43460446, grad/param norm = 2.6751e-01, time/batch = 15.2763s	
13027/22300 (epoch 29.209), train_loss = 0.48366489, grad/param norm = 2.7510e-01, time/batch = 15.9510s	
13028/22300 (epoch 29.211), train_loss = 0.38791222, grad/param norm = 2.7090e-01, time/batch = 15.4538s	
13029/22300 (epoch 29.213), train_loss = 0.52282159, grad/param norm = 2.6155e-01, time/batch = 15.0737s	
13030/22300 (epoch 29.215), train_loss = 0.65730483, grad/param norm = 3.1463e-01, time/batch = 15.2982s	
13031/22300 (epoch 29.217), train_loss = 0.67673014, grad/param norm = 3.0626e-01, time/batch = 15.9842s	
13032/22300 (epoch 29.220), train_loss = 0.47466513, grad/param norm = 2.3378e-01, time/batch = 15.3111s	
13033/22300 (epoch 29.222), train_loss = 0.45893775, grad/param norm = 2.6285e-01, time/batch = 15.0546s	
13034/22300 (epoch 29.224), train_loss = 0.46601105, grad/param norm = 2.5937e-01, time/batch = 15.8496s	
13035/22300 (epoch 29.226), train_loss = 0.50898672, grad/param norm = 2.7064e-01, time/batch = 16.0573s	
13036/22300 (epoch 29.229), train_loss = 0.41582067, grad/param norm = 2.5642e-01, time/batch = 16.6478s	
13037/22300 (epoch 29.231), train_loss = 0.64483571, grad/param norm = 4.0306e-01, time/batch = 16.4425s	
13038/22300 (epoch 29.233), train_loss = 0.54014119, grad/param norm = 3.0371e-01, time/batch = 16.2178s	
13039/22300 (epoch 29.235), train_loss = 0.42020941, grad/param norm = 2.6515e-01, time/batch = 16.4648s	
13040/22300 (epoch 29.238), train_loss = 0.41555772, grad/param norm = 2.3555e-01, time/batch = 16.3687s	
13041/22300 (epoch 29.240), train_loss = 0.43521972, grad/param norm = 2.2344e-01, time/batch = 15.7891s	
13042/22300 (epoch 29.242), train_loss = 0.41519339, grad/param norm = 2.8525e-01, time/batch = 16.4326s	
13043/22300 (epoch 29.244), train_loss = 0.28900791, grad/param norm = 1.8818e-01, time/batch = 16.4005s	
13044/22300 (epoch 29.247), train_loss = 0.38629497, grad/param norm = 2.0351e-01, time/batch = 17.0458s	
13045/22300 (epoch 29.249), train_loss = 0.28048374, grad/param norm = 1.9468e-01, time/batch = 16.1301s	
13046/22300 (epoch 29.251), train_loss = 0.38748587, grad/param norm = 2.1746e-01, time/batch = 15.9791s	
13047/22300 (epoch 29.253), train_loss = 0.26785931, grad/param norm = 2.2124e-01, time/batch = 16.3738s	
13048/22300 (epoch 29.256), train_loss = 0.38008064, grad/param norm = 2.9570e-01, time/batch = 15.2294s	
13049/22300 (epoch 29.258), train_loss = 0.54931822, grad/param norm = 2.8724e-01, time/batch = 15.6265s	
13050/22300 (epoch 29.260), train_loss = 0.53014880, grad/param norm = 2.7925e-01, time/batch = 14.9888s	
13051/22300 (epoch 29.262), train_loss = 0.39525739, grad/param norm = 2.2025e-01, time/batch = 15.1316s	
13052/22300 (epoch 29.265), train_loss = 0.37903593, grad/param norm = 2.5207e-01, time/batch = 15.5073s	
13053/22300 (epoch 29.267), train_loss = 0.44151547, grad/param norm = 2.4970e-01, time/batch = 16.5345s	
13054/22300 (epoch 29.269), train_loss = 0.49350371, grad/param norm = 3.4229e-01, time/batch = 15.1469s	
13055/22300 (epoch 29.271), train_loss = 0.55654806, grad/param norm = 2.7348e-01, time/batch = 16.4496s	
13056/22300 (epoch 29.274), train_loss = 0.41098308, grad/param norm = 2.7879e-01, time/batch = 15.6523s	
13057/22300 (epoch 29.276), train_loss = 0.33455357, grad/param norm = 1.9629e-01, time/batch = 16.3762s	
13058/22300 (epoch 29.278), train_loss = 0.33734039, grad/param norm = 2.2906e-01, time/batch = 15.3874s	
13059/22300 (epoch 29.280), train_loss = 0.40693856, grad/param norm = 2.4575e-01, time/batch = 15.0177s	
13060/22300 (epoch 29.283), train_loss = 0.30405213, grad/param norm = 1.8239e-01, time/batch = 16.1901s	
13061/22300 (epoch 29.285), train_loss = 0.38842485, grad/param norm = 2.8585e-01, time/batch = 15.6376s	
13062/22300 (epoch 29.287), train_loss = 0.48985342, grad/param norm = 2.3742e-01, time/batch = 15.5399s	
13063/22300 (epoch 29.289), train_loss = 0.45274339, grad/param norm = 2.3963e-01, time/batch = 15.2979s	
13064/22300 (epoch 29.291), train_loss = 0.46590870, grad/param norm = 2.6346e-01, time/batch = 15.8728s	
13065/22300 (epoch 29.294), train_loss = 0.35022100, grad/param norm = 2.0198e-01, time/batch = 15.2358s	
13066/22300 (epoch 29.296), train_loss = 0.42709408, grad/param norm = 2.5974e-01, time/batch = 15.1540s	
13067/22300 (epoch 29.298), train_loss = 0.56170616, grad/param norm = 2.5737e-01, time/batch = 15.3685s	
13068/22300 (epoch 29.300), train_loss = 0.61477535, grad/param norm = 2.8645e-01, time/batch = 15.5999s	
13069/22300 (epoch 29.303), train_loss = 0.46692152, grad/param norm = 2.5450e-01, time/batch = 15.5483s	
13070/22300 (epoch 29.305), train_loss = 0.47639186, grad/param norm = 2.7635e-01, time/batch = 15.6398s	
13071/22300 (epoch 29.307), train_loss = 0.42119876, grad/param norm = 2.5584e-01, time/batch = 15.6261s	
13072/22300 (epoch 29.309), train_loss = 0.37823136, grad/param norm = 2.1428e-01, time/batch = 15.5423s	
13073/22300 (epoch 29.312), train_loss = 0.34826815, grad/param norm = 1.9612e-01, time/batch = 15.4679s	
13074/22300 (epoch 29.314), train_loss = 0.38896908, grad/param norm = 2.6449e-01, time/batch = 15.4793s	
13075/22300 (epoch 29.316), train_loss = 0.39621121, grad/param norm = 3.0285e-01, time/batch = 15.5277s	
13076/22300 (epoch 29.318), train_loss = 0.44165892, grad/param norm = 2.6424e-01, time/batch = 15.3249s	
13077/22300 (epoch 29.321), train_loss = 0.52889441, grad/param norm = 2.5400e-01, time/batch = 15.2198s	
13078/22300 (epoch 29.323), train_loss = 0.38457392, grad/param norm = 2.1045e-01, time/batch = 15.5488s	
13079/22300 (epoch 29.325), train_loss = 0.34712654, grad/param norm = 1.9426e-01, time/batch = 15.8494s	
13080/22300 (epoch 29.327), train_loss = 0.35403214, grad/param norm = 1.9211e-01, time/batch = 15.5348s	
13081/22300 (epoch 29.330), train_loss = 0.37347123, grad/param norm = 2.7828e-01, time/batch = 15.5490s	
13082/22300 (epoch 29.332), train_loss = 0.37182785, grad/param norm = 2.5697e-01, time/batch = 15.5678s	
13083/22300 (epoch 29.334), train_loss = 0.42662319, grad/param norm = 2.9599e-01, time/batch = 15.6111s	
13084/22300 (epoch 29.336), train_loss = 0.44441282, grad/param norm = 2.4506e-01, time/batch = 15.3120s	
13085/22300 (epoch 29.339), train_loss = 0.48718707, grad/param norm = 2.5942e-01, time/batch = 15.7165s	
13086/22300 (epoch 29.341), train_loss = 0.52532987, grad/param norm = 2.9601e-01, time/batch = 15.4686s	
13087/22300 (epoch 29.343), train_loss = 0.56038109, grad/param norm = 3.1842e-01, time/batch = 15.2330s	
13088/22300 (epoch 29.345), train_loss = 0.44406928, grad/param norm = 2.4603e-01, time/batch = 15.2284s	
13089/22300 (epoch 29.348), train_loss = 0.43349832, grad/param norm = 2.2509e-01, time/batch = 15.6991s	
13090/22300 (epoch 29.350), train_loss = 0.35663530, grad/param norm = 2.0464e-01, time/batch = 15.4321s	
13091/22300 (epoch 29.352), train_loss = 0.47974375, grad/param norm = 2.6399e-01, time/batch = 15.9281s	
13092/22300 (epoch 29.354), train_loss = 0.67486400, grad/param norm = 2.9055e-01, time/batch = 15.2444s	
13093/22300 (epoch 29.357), train_loss = 0.56596255, grad/param norm = 2.5991e-01, time/batch = 15.3011s	
13094/22300 (epoch 29.359), train_loss = 0.39315090, grad/param norm = 2.7028e-01, time/batch = 15.6203s	
13095/22300 (epoch 29.361), train_loss = 0.41406529, grad/param norm = 2.6949e-01, time/batch = 15.3870s	
13096/22300 (epoch 29.363), train_loss = 0.53646624, grad/param norm = 2.6383e-01, time/batch = 15.3810s	
13097/22300 (epoch 29.365), train_loss = 0.43133272, grad/param norm = 2.7649e-01, time/batch = 15.1463s	
13098/22300 (epoch 29.368), train_loss = 0.44013213, grad/param norm = 3.0843e-01, time/batch = 15.3703s	
13099/22300 (epoch 29.370), train_loss = 0.42777460, grad/param norm = 2.3884e-01, time/batch = 15.7735s	
13100/22300 (epoch 29.372), train_loss = 0.34456278, grad/param norm = 2.1771e-01, time/batch = 15.3566s	
13101/22300 (epoch 29.374), train_loss = 0.32343033, grad/param norm = 2.1642e-01, time/batch = 15.5659s	
13102/22300 (epoch 29.377), train_loss = 0.44411513, grad/param norm = 2.8571e-01, time/batch = 15.7213s	
13103/22300 (epoch 29.379), train_loss = 0.42213464, grad/param norm = 3.1587e-01, time/batch = 15.5489s	
13104/22300 (epoch 29.381), train_loss = 0.54091644, grad/param norm = 2.8410e-01, time/batch = 15.4775s	
13105/22300 (epoch 29.383), train_loss = 0.45685400, grad/param norm = 2.4772e-01, time/batch = 15.4784s	
13106/22300 (epoch 29.386), train_loss = 0.43465336, grad/param norm = 2.3285e-01, time/batch = 15.6320s	
13107/22300 (epoch 29.388), train_loss = 0.36375419, grad/param norm = 2.6117e-01, time/batch = 15.4982s	
13108/22300 (epoch 29.390), train_loss = 0.41223403, grad/param norm = 2.4895e-01, time/batch = 15.5480s	
13109/22300 (epoch 29.392), train_loss = 0.42946362, grad/param norm = 3.1474e-01, time/batch = 15.5467s	
13110/22300 (epoch 29.395), train_loss = 0.34286610, grad/param norm = 2.0894e-01, time/batch = 15.3971s	
13111/22300 (epoch 29.397), train_loss = 0.23715431, grad/param norm = 1.7752e-01, time/batch = 15.3780s	
13112/22300 (epoch 29.399), train_loss = 0.34370466, grad/param norm = 1.9818e-01, time/batch = 15.6330s	
13113/22300 (epoch 29.401), train_loss = 0.40738980, grad/param norm = 2.5228e-01, time/batch = 15.6916s	
13114/22300 (epoch 29.404), train_loss = 0.42808618, grad/param norm = 3.3483e-01, time/batch = 15.5494s	
13115/22300 (epoch 29.406), train_loss = 0.65429865, grad/param norm = 3.4451e-01, time/batch = 15.5633s	
13116/22300 (epoch 29.408), train_loss = 0.53673212, grad/param norm = 2.8454e-01, time/batch = 15.2290s	
13117/22300 (epoch 29.410), train_loss = 0.55639727, grad/param norm = 3.4241e-01, time/batch = 15.3929s	
13118/22300 (epoch 29.413), train_loss = 0.39832723, grad/param norm = 2.3188e-01, time/batch = 15.2308s	
13119/22300 (epoch 29.415), train_loss = 0.30823540, grad/param norm = 2.1275e-01, time/batch = 15.0817s	
13120/22300 (epoch 29.417), train_loss = 0.46886973, grad/param norm = 2.4964e-01, time/batch = 15.3920s	
13121/22300 (epoch 29.419), train_loss = 0.39615256, grad/param norm = 1.8711e-01, time/batch = 15.8627s	
13122/22300 (epoch 29.422), train_loss = 0.36505364, grad/param norm = 2.2816e-01, time/batch = 15.2333s	
13123/22300 (epoch 29.424), train_loss = 0.46682656, grad/param norm = 2.7546e-01, time/batch = 15.4691s	
13124/22300 (epoch 29.426), train_loss = 0.32883551, grad/param norm = 2.1262e-01, time/batch = 15.7795s	
13125/22300 (epoch 29.428), train_loss = 0.34976356, grad/param norm = 2.3520e-01, time/batch = 15.5178s	
13126/22300 (epoch 29.430), train_loss = 0.42286003, grad/param norm = 2.5387e-01, time/batch = 15.7538s	
13127/22300 (epoch 29.433), train_loss = 0.42329700, grad/param norm = 2.2313e-01, time/batch = 15.6463s	
13128/22300 (epoch 29.435), train_loss = 0.41397792, grad/param norm = 2.4639e-01, time/batch = 15.4761s	
13129/22300 (epoch 29.437), train_loss = 0.50585262, grad/param norm = 3.4494e-01, time/batch = 15.6807s	
13130/22300 (epoch 29.439), train_loss = 0.55020678, grad/param norm = 2.7821e-01, time/batch = 15.4038s	
13131/22300 (epoch 29.442), train_loss = 0.47943202, grad/param norm = 3.1453e-01, time/batch = 15.7261s	
13132/22300 (epoch 29.444), train_loss = 0.39209706, grad/param norm = 2.4358e-01, time/batch = 15.7947s	
13133/22300 (epoch 29.446), train_loss = 0.39991953, grad/param norm = 2.6645e-01, time/batch = 15.6890s	
13134/22300 (epoch 29.448), train_loss = 0.29468851, grad/param norm = 1.8009e-01, time/batch = 15.5333s	
13135/22300 (epoch 29.451), train_loss = 0.50087001, grad/param norm = 3.2119e-01, time/batch = 15.4688s	
13136/22300 (epoch 29.453), train_loss = 0.40444168, grad/param norm = 2.5365e-01, time/batch = 15.3838s	
13137/22300 (epoch 29.455), train_loss = 0.58495833, grad/param norm = 3.4853e-01, time/batch = 15.6312s	
13138/22300 (epoch 29.457), train_loss = 0.62698501, grad/param norm = 3.1734e-01, time/batch = 15.6102s	
13139/22300 (epoch 29.460), train_loss = 0.55965107, grad/param norm = 3.1399e-01, time/batch = 15.5933s	
13140/22300 (epoch 29.462), train_loss = 0.58131874, grad/param norm = 2.8705e-01, time/batch = 15.5943s	
13141/22300 (epoch 29.464), train_loss = 0.51504026, grad/param norm = 3.2611e-01, time/batch = 15.9607s	
13142/22300 (epoch 29.466), train_loss = 0.41089275, grad/param norm = 2.1283e-01, time/batch = 15.3171s	
13143/22300 (epoch 29.469), train_loss = 0.39612867, grad/param norm = 2.0646e-01, time/batch = 15.5528s	
13144/22300 (epoch 29.471), train_loss = 0.53746673, grad/param norm = 2.4610e-01, time/batch = 15.6899s	
13145/22300 (epoch 29.473), train_loss = 0.46619631, grad/param norm = 2.2301e-01, time/batch = 15.7241s	
13146/22300 (epoch 29.475), train_loss = 0.40548575, grad/param norm = 2.8222e-01, time/batch = 15.4073s	
13147/22300 (epoch 29.478), train_loss = 0.41884685, grad/param norm = 2.5393e-01, time/batch = 15.4820s	
13148/22300 (epoch 29.480), train_loss = 0.29554023, grad/param norm = 2.0203e-01, time/batch = 15.2937s	
13149/22300 (epoch 29.482), train_loss = 0.34090911, grad/param norm = 2.1658e-01, time/batch = 15.8615s	
13150/22300 (epoch 29.484), train_loss = 0.44532583, grad/param norm = 2.4807e-01, time/batch = 15.5132s	
13151/22300 (epoch 29.487), train_loss = 0.52659535, grad/param norm = 2.5002e-01, time/batch = 16.3193s	
13152/22300 (epoch 29.489), train_loss = 0.53027988, grad/param norm = 2.7765e-01, time/batch = 16.1971s	
13153/22300 (epoch 29.491), train_loss = 0.52554860, grad/param norm = 2.9294e-01, time/batch = 16.2036s	
13154/22300 (epoch 29.493), train_loss = 0.44896791, grad/param norm = 3.1911e-01, time/batch = 16.1387s	
13155/22300 (epoch 29.496), train_loss = 0.45345145, grad/param norm = 2.1364e-01, time/batch = 15.9873s	
13156/22300 (epoch 29.498), train_loss = 0.32769228, grad/param norm = 2.1432e-01, time/batch = 16.2877s	
13157/22300 (epoch 29.500), train_loss = 0.44864285, grad/param norm = 2.3884e-01, time/batch = 16.0533s	
13158/22300 (epoch 29.502), train_loss = 0.29055012, grad/param norm = 2.4483e-01, time/batch = 16.0335s	
13159/22300 (epoch 29.504), train_loss = 0.32574069, grad/param norm = 2.0594e-01, time/batch = 16.2985s	
13160/22300 (epoch 29.507), train_loss = 0.38178228, grad/param norm = 2.3955e-01, time/batch = 16.2304s	
13161/22300 (epoch 29.509), train_loss = 0.49889874, grad/param norm = 2.6180e-01, time/batch = 16.4521s	
13162/22300 (epoch 29.511), train_loss = 0.28707342, grad/param norm = 2.2740e-01, time/batch = 16.3091s	
13163/22300 (epoch 29.513), train_loss = 0.33403661, grad/param norm = 2.4445e-01, time/batch = 15.9496s	
13164/22300 (epoch 29.516), train_loss = 0.37953200, grad/param norm = 2.6811e-01, time/batch = 16.2119s	
13165/22300 (epoch 29.518), train_loss = 0.49260449, grad/param norm = 2.5548e-01, time/batch = 16.0559s	
13166/22300 (epoch 29.520), train_loss = 0.41510544, grad/param norm = 2.3263e-01, time/batch = 15.9507s	
13167/22300 (epoch 29.522), train_loss = 0.42633490, grad/param norm = 2.2561e-01, time/batch = 16.0087s	
13168/22300 (epoch 29.525), train_loss = 0.34457168, grad/param norm = 2.2441e-01, time/batch = 16.0698s	
13169/22300 (epoch 29.527), train_loss = 0.53420676, grad/param norm = 2.8752e-01, time/batch = 15.9762s	
13170/22300 (epoch 29.529), train_loss = 0.47033906, grad/param norm = 2.9041e-01, time/batch = 15.8450s	
13171/22300 (epoch 29.531), train_loss = 0.39558633, grad/param norm = 2.1865e-01, time/batch = 16.4325s	
13172/22300 (epoch 29.534), train_loss = 0.39719348, grad/param norm = 2.1588e-01, time/batch = 16.3725s	
13173/22300 (epoch 29.536), train_loss = 0.60820575, grad/param norm = 2.4880e-01, time/batch = 16.4678s	
13174/22300 (epoch 29.538), train_loss = 0.74451619, grad/param norm = 3.2009e-01, time/batch = 16.2637s	
13175/22300 (epoch 29.540), train_loss = 0.45691786, grad/param norm = 2.5787e-01, time/batch = 16.4580s	
13176/22300 (epoch 29.543), train_loss = 0.41176652, grad/param norm = 2.5250e-01, time/batch = 15.8423s	
13177/22300 (epoch 29.545), train_loss = 0.30717755, grad/param norm = 2.2588e-01, time/batch = 15.8534s	
13178/22300 (epoch 29.547), train_loss = 0.30200745, grad/param norm = 2.0771e-01, time/batch = 30.1483s	
13179/22300 (epoch 29.549), train_loss = 0.37639526, grad/param norm = 2.4705e-01, time/batch = 16.1112s	
13180/22300 (epoch 29.552), train_loss = 0.35723921, grad/param norm = 2.2503e-01, time/batch = 15.8832s	
13181/22300 (epoch 29.554), train_loss = 0.47680002, grad/param norm = 2.7672e-01, time/batch = 16.0475s	
13182/22300 (epoch 29.556), train_loss = 0.67992596, grad/param norm = 4.2091e-01, time/batch = 15.9836s	
13183/22300 (epoch 29.558), train_loss = 0.51279082, grad/param norm = 2.9004e-01, time/batch = 15.9681s	
13184/22300 (epoch 29.561), train_loss = 0.67597345, grad/param norm = 3.8119e-01, time/batch = 16.1210s	
13185/22300 (epoch 29.563), train_loss = 0.57373842, grad/param norm = 3.6609e-01, time/batch = 16.1047s	
13186/22300 (epoch 29.565), train_loss = 0.44677295, grad/param norm = 3.0084e-01, time/batch = 16.2242s	
13187/22300 (epoch 29.567), train_loss = 0.41890813, grad/param norm = 2.2098e-01, time/batch = 15.9772s	
13188/22300 (epoch 29.570), train_loss = 0.61242478, grad/param norm = 3.1816e-01, time/batch = 16.1150s	
13189/22300 (epoch 29.572), train_loss = 0.57131976, grad/param norm = 2.9930e-01, time/batch = 16.0609s	
13190/22300 (epoch 29.574), train_loss = 0.44441849, grad/param norm = 2.5490e-01, time/batch = 16.0541s	
13191/22300 (epoch 29.576), train_loss = 0.37541371, grad/param norm = 2.1419e-01, time/batch = 15.9624s	
13192/22300 (epoch 29.578), train_loss = 0.24373394, grad/param norm = 1.9707e-01, time/batch = 16.1370s	
13193/22300 (epoch 29.581), train_loss = 0.33671697, grad/param norm = 2.1268e-01, time/batch = 15.8565s	
13194/22300 (epoch 29.583), train_loss = 0.38579091, grad/param norm = 2.0290e-01, time/batch = 15.8873s	
13195/22300 (epoch 29.585), train_loss = 0.54295737, grad/param norm = 2.8702e-01, time/batch = 16.1117s	
13196/22300 (epoch 29.587), train_loss = 0.74654064, grad/param norm = 3.6660e-01, time/batch = 16.1981s	
13197/22300 (epoch 29.590), train_loss = 0.59182772, grad/param norm = 3.3551e-01, time/batch = 16.2167s	
13198/22300 (epoch 29.592), train_loss = 0.70056488, grad/param norm = 3.5139e-01, time/batch = 15.9579s	
13199/22300 (epoch 29.594), train_loss = 0.70255380, grad/param norm = 3.9763e-01, time/batch = 16.1122s	
13200/22300 (epoch 29.596), train_loss = 0.42037090, grad/param norm = 2.3479e-01, time/batch = 16.2225s	
13201/22300 (epoch 29.599), train_loss = 0.32912023, grad/param norm = 2.2485e-01, time/batch = 16.0694s	
13202/22300 (epoch 29.601), train_loss = 0.37068468, grad/param norm = 2.1523e-01, time/batch = 16.2032s	
13203/22300 (epoch 29.603), train_loss = 0.43548900, grad/param norm = 2.5538e-01, time/batch = 16.1071s	
13204/22300 (epoch 29.605), train_loss = 0.41603446, grad/param norm = 2.5502e-01, time/batch = 16.3163s	
13205/22300 (epoch 29.608), train_loss = 0.66727265, grad/param norm = 2.9231e-01, time/batch = 16.3145s	
13206/22300 (epoch 29.610), train_loss = 0.71422062, grad/param norm = 3.1122e-01, time/batch = 16.2922s	
13207/22300 (epoch 29.612), train_loss = 0.53567055, grad/param norm = 2.9317e-01, time/batch = 15.9671s	
13208/22300 (epoch 29.614), train_loss = 0.56338535, grad/param norm = 3.4407e-01, time/batch = 16.2113s	
13209/22300 (epoch 29.617), train_loss = 0.53542210, grad/param norm = 2.5214e-01, time/batch = 16.0491s	
13210/22300 (epoch 29.619), train_loss = 0.64407228, grad/param norm = 2.9167e-01, time/batch = 16.2074s	
13211/22300 (epoch 29.621), train_loss = 0.42677875, grad/param norm = 2.7404e-01, time/batch = 16.2954s	
13212/22300 (epoch 29.623), train_loss = 0.43703315, grad/param norm = 2.5331e-01, time/batch = 16.2888s	
13213/22300 (epoch 29.626), train_loss = 0.39248970, grad/param norm = 2.3097e-01, time/batch = 16.1303s	
13214/22300 (epoch 29.628), train_loss = 0.40398215, grad/param norm = 2.5167e-01, time/batch = 15.8171s	
13215/22300 (epoch 29.630), train_loss = 0.46938994, grad/param norm = 2.4583e-01, time/batch = 15.9037s	
13216/22300 (epoch 29.632), train_loss = 0.40019080, grad/param norm = 2.5596e-01, time/batch = 16.1442s	
13217/22300 (epoch 29.635), train_loss = 0.45215407, grad/param norm = 2.3662e-01, time/batch = 16.1248s	
13218/22300 (epoch 29.637), train_loss = 0.52246642, grad/param norm = 2.6783e-01, time/batch = 16.1928s	
13219/22300 (epoch 29.639), train_loss = 0.60876806, grad/param norm = 2.9505e-01, time/batch = 15.9809s	
13220/22300 (epoch 29.641), train_loss = 0.49695883, grad/param norm = 2.5361e-01, time/batch = 15.8077s	
13221/22300 (epoch 29.643), train_loss = 0.39922294, grad/param norm = 3.2086e-01, time/batch = 16.2898s	
13222/22300 (epoch 29.646), train_loss = 0.37665883, grad/param norm = 2.2679e-01, time/batch = 16.2921s	
13223/22300 (epoch 29.648), train_loss = 0.48220061, grad/param norm = 2.3200e-01, time/batch = 15.9830s	
13224/22300 (epoch 29.650), train_loss = 0.50675168, grad/param norm = 2.5945e-01, time/batch = 16.0593s	
13225/22300 (epoch 29.652), train_loss = 0.42263979, grad/param norm = 2.3794e-01, time/batch = 16.0896s	
13226/22300 (epoch 29.655), train_loss = 0.37768548, grad/param norm = 2.4825e-01, time/batch = 15.8970s	
13227/22300 (epoch 29.657), train_loss = 0.44771338, grad/param norm = 4.3639e-01, time/batch = 15.7400s	
13228/22300 (epoch 29.659), train_loss = 0.40901680, grad/param norm = 2.6937e-01, time/batch = 15.7207s	
13229/22300 (epoch 29.661), train_loss = 0.33092212, grad/param norm = 2.4162e-01, time/batch = 15.9291s	
13230/22300 (epoch 29.664), train_loss = 0.38273180, grad/param norm = 2.1895e-01, time/batch = 16.8815s	
13231/22300 (epoch 29.666), train_loss = 0.50498522, grad/param norm = 2.7877e-01, time/batch = 15.6944s	
13232/22300 (epoch 29.668), train_loss = 0.36705955, grad/param norm = 1.9411e-01, time/batch = 15.7722s	
13233/22300 (epoch 29.670), train_loss = 0.49030364, grad/param norm = 2.8335e-01, time/batch = 15.5914s	
13234/22300 (epoch 29.673), train_loss = 0.55175939, grad/param norm = 2.8607e-01, time/batch = 15.2256s	
13235/22300 (epoch 29.675), train_loss = 0.62909107, grad/param norm = 3.7482e-01, time/batch = 15.1079s	
13236/22300 (epoch 29.677), train_loss = 0.68400980, grad/param norm = 3.8573e-01, time/batch = 15.1354s	
13237/22300 (epoch 29.679), train_loss = 0.52226380, grad/param norm = 3.1612e-01, time/batch = 15.4971s	
13238/22300 (epoch 29.682), train_loss = 0.44965561, grad/param norm = 2.6169e-01, time/batch = 15.5204s	
13239/22300 (epoch 29.684), train_loss = 0.43744847, grad/param norm = 2.3910e-01, time/batch = 15.8160s	
13240/22300 (epoch 29.686), train_loss = 0.44887623, grad/param norm = 2.2578e-01, time/batch = 15.2004s	
13241/22300 (epoch 29.688), train_loss = 0.39740299, grad/param norm = 2.2209e-01, time/batch = 15.5147s	
13242/22300 (epoch 29.691), train_loss = 0.37859378, grad/param norm = 2.4553e-01, time/batch = 14.9724s	
13243/22300 (epoch 29.693), train_loss = 0.35271351, grad/param norm = 2.1317e-01, time/batch = 17.7986s	
13244/22300 (epoch 29.695), train_loss = 0.37771198, grad/param norm = 2.3224e-01, time/batch = 15.7306s	
13245/22300 (epoch 29.697), train_loss = 0.38745737, grad/param norm = 2.0036e-01, time/batch = 16.2246s	
13246/22300 (epoch 29.700), train_loss = 0.40398565, grad/param norm = 3.0521e-01, time/batch = 14.9046s	
13247/22300 (epoch 29.702), train_loss = 0.33589601, grad/param norm = 1.9079e-01, time/batch = 17.3737s	
13248/22300 (epoch 29.704), train_loss = 0.45240267, grad/param norm = 3.1024e-01, time/batch = 15.3040s	
13249/22300 (epoch 29.706), train_loss = 0.38392056, grad/param norm = 2.6522e-01, time/batch = 16.1301s	
13250/22300 (epoch 29.709), train_loss = 0.32453060, grad/param norm = 2.0183e-01, time/batch = 15.5726s	
13251/22300 (epoch 29.711), train_loss = 0.32649605, grad/param norm = 2.0387e-01, time/batch = 15.2171s	
13252/22300 (epoch 29.713), train_loss = 0.45126567, grad/param norm = 2.2079e-01, time/batch = 0.6702s	
13253/22300 (epoch 29.715), train_loss = 0.44619864, grad/param norm = 2.3433e-01, time/batch = 0.6593s	
13254/22300 (epoch 29.717), train_loss = 0.61485781, grad/param norm = 2.8756e-01, time/batch = 0.6546s	
13255/22300 (epoch 29.720), train_loss = 0.39704255, grad/param norm = 2.7189e-01, time/batch = 0.6647s	
13256/22300 (epoch 29.722), train_loss = 0.47828681, grad/param norm = 2.7920e-01, time/batch = 0.6779s	
13257/22300 (epoch 29.724), train_loss = 0.55005628, grad/param norm = 3.2841e-01, time/batch = 0.6704s	
13258/22300 (epoch 29.726), train_loss = 0.40079658, grad/param norm = 2.5333e-01, time/batch = 0.6728s	
13259/22300 (epoch 29.729), train_loss = 0.46359036, grad/param norm = 2.8746e-01, time/batch = 0.8665s	
13260/22300 (epoch 29.731), train_loss = 0.61939967, grad/param norm = 3.1381e-01, time/batch = 0.9739s	
13261/22300 (epoch 29.733), train_loss = 0.58974862, grad/param norm = 2.9987e-01, time/batch = 0.9811s	
13262/22300 (epoch 29.735), train_loss = 0.66073347, grad/param norm = 3.7530e-01, time/batch = 0.9758s	
13263/22300 (epoch 29.738), train_loss = 0.47959559, grad/param norm = 3.6296e-01, time/batch = 0.9967s	
13264/22300 (epoch 29.740), train_loss = 0.42070494, grad/param norm = 2.3056e-01, time/batch = 1.5662s	
13265/22300 (epoch 29.742), train_loss = 0.40923760, grad/param norm = 2.8499e-01, time/batch = 1.9363s	
13266/22300 (epoch 29.744), train_loss = 0.68674486, grad/param norm = 3.1536e-01, time/batch = 1.8134s	
13267/22300 (epoch 29.747), train_loss = 0.52135083, grad/param norm = 2.5392e-01, time/batch = 15.3816s	
13268/22300 (epoch 29.749), train_loss = 0.67124470, grad/param norm = 3.4913e-01, time/batch = 16.1388s	
13269/22300 (epoch 29.751), train_loss = 0.61073746, grad/param norm = 3.6295e-01, time/batch = 15.9552s	
13270/22300 (epoch 29.753), train_loss = 0.64588371, grad/param norm = 3.5877e-01, time/batch = 17.1320s	
13271/22300 (epoch 29.756), train_loss = 0.53689728, grad/param norm = 2.8041e-01, time/batch = 15.5095s	
13272/22300 (epoch 29.758), train_loss = 0.49738398, grad/param norm = 2.6004e-01, time/batch = 14.8059s	
13273/22300 (epoch 29.760), train_loss = 0.55398711, grad/param norm = 3.0935e-01, time/batch = 15.0681s	
13274/22300 (epoch 29.762), train_loss = 0.51641139, grad/param norm = 2.8773e-01, time/batch = 15.2820s	
13275/22300 (epoch 29.765), train_loss = 0.48890372, grad/param norm = 2.8072e-01, time/batch = 15.7705s	
13276/22300 (epoch 29.767), train_loss = 0.53458925, grad/param norm = 3.1111e-01, time/batch = 16.4752s	
13277/22300 (epoch 29.769), train_loss = 0.51534562, grad/param norm = 3.2700e-01, time/batch = 15.6678s	
13278/22300 (epoch 29.771), train_loss = 0.56054815, grad/param norm = 2.8680e-01, time/batch = 17.6220s	
13279/22300 (epoch 29.774), train_loss = 0.60452027, grad/param norm = 3.5689e-01, time/batch = 16.1171s	
13280/22300 (epoch 29.776), train_loss = 0.63170119, grad/param norm = 2.8593e-01, time/batch = 15.0625s	
13281/22300 (epoch 29.778), train_loss = 0.61645526, grad/param norm = 3.2827e-01, time/batch = 16.8883s	
13282/22300 (epoch 29.780), train_loss = 0.59463281, grad/param norm = 3.3213e-01, time/batch = 15.1407s	
13283/22300 (epoch 29.783), train_loss = 0.64019874, grad/param norm = 3.5530e-01, time/batch = 16.2200s	
13284/22300 (epoch 29.785), train_loss = 0.47494957, grad/param norm = 2.7323e-01, time/batch = 16.0414s	
13285/22300 (epoch 29.787), train_loss = 0.46105724, grad/param norm = 2.8147e-01, time/batch = 15.1131s	
13286/22300 (epoch 29.789), train_loss = 0.67569031, grad/param norm = 4.2097e-01, time/batch = 15.2223s	
13287/22300 (epoch 29.791), train_loss = 0.81921864, grad/param norm = 3.8928e-01, time/batch = 15.0557s	
13288/22300 (epoch 29.794), train_loss = 0.63445854, grad/param norm = 3.7189e-01, time/batch = 15.8408s	
13289/22300 (epoch 29.796), train_loss = 0.59674641, grad/param norm = 2.9808e-01, time/batch = 15.4248s	
13290/22300 (epoch 29.798), train_loss = 0.72305646, grad/param norm = 2.9771e-01, time/batch = 15.2267s	
13291/22300 (epoch 29.800), train_loss = 0.51303468, grad/param norm = 3.1595e-01, time/batch = 16.1421s	
13292/22300 (epoch 29.803), train_loss = 0.45844741, grad/param norm = 2.4868e-01, time/batch = 15.5456s	
13293/22300 (epoch 29.805), train_loss = 0.55065013, grad/param norm = 2.9742e-01, time/batch = 16.5450s	
13294/22300 (epoch 29.807), train_loss = 0.68934975, grad/param norm = 4.2140e-01, time/batch = 16.7249s	
13295/22300 (epoch 29.809), train_loss = 0.53212341, grad/param norm = 3.8205e-01, time/batch = 16.1376s	
13296/22300 (epoch 29.812), train_loss = 0.55864528, grad/param norm = 2.8731e-01, time/batch = 16.4312s	
13297/22300 (epoch 29.814), train_loss = 0.57559019, grad/param norm = 3.4679e-01, time/batch = 16.3913s	
13298/22300 (epoch 29.816), train_loss = 0.58129006, grad/param norm = 3.0128e-01, time/batch = 16.4813s	
13299/22300 (epoch 29.818), train_loss = 0.65196096, grad/param norm = 3.1282e-01, time/batch = 15.9374s	
13300/22300 (epoch 29.821), train_loss = 0.58243888, grad/param norm = 2.9410e-01, time/batch = 14.8138s	
13301/22300 (epoch 29.823), train_loss = 0.35854975, grad/param norm = 2.2617e-01, time/batch = 15.1375s	
13302/22300 (epoch 29.825), train_loss = 0.41290562, grad/param norm = 2.8907e-01, time/batch = 15.3133s	
13303/22300 (epoch 29.827), train_loss = 0.47395379, grad/param norm = 2.8114e-01, time/batch = 15.4646s	
13304/22300 (epoch 29.830), train_loss = 0.48120556, grad/param norm = 3.2547e-01, time/batch = 15.3195s	
13305/22300 (epoch 29.832), train_loss = 0.42518737, grad/param norm = 2.3773e-01, time/batch = 15.4675s	
13306/22300 (epoch 29.834), train_loss = 0.38307489, grad/param norm = 2.3525e-01, time/batch = 15.4831s	
13307/22300 (epoch 29.836), train_loss = 0.47315264, grad/param norm = 2.7880e-01, time/batch = 15.5455s	
13308/22300 (epoch 29.839), train_loss = 0.46380340, grad/param norm = 2.4664e-01, time/batch = 15.8099s	
13309/22300 (epoch 29.841), train_loss = 0.48554943, grad/param norm = 2.9312e-01, time/batch = 15.6388s	
13310/22300 (epoch 29.843), train_loss = 0.45874900, grad/param norm = 2.5802e-01, time/batch = 15.8141s	
13311/22300 (epoch 29.845), train_loss = 0.45933992, grad/param norm = 2.6470e-01, time/batch = 16.2583s	
13312/22300 (epoch 29.848), train_loss = 0.46993436, grad/param norm = 2.9053e-01, time/batch = 15.6832s	
13313/22300 (epoch 29.850), train_loss = 0.48785058, grad/param norm = 2.6485e-01, time/batch = 15.4598s	
13314/22300 (epoch 29.852), train_loss = 0.44406008, grad/param norm = 3.0491e-01, time/batch = 15.6134s	
13315/22300 (epoch 29.854), train_loss = 0.65150829, grad/param norm = 3.2103e-01, time/batch = 15.7094s	
13316/22300 (epoch 29.857), train_loss = 0.54771676, grad/param norm = 3.4834e-01, time/batch = 15.7214s	
13317/22300 (epoch 29.859), train_loss = 0.40619898, grad/param norm = 2.0874e-01, time/batch = 15.6965s	
13318/22300 (epoch 29.861), train_loss = 0.56424635, grad/param norm = 2.7744e-01, time/batch = 15.5487s	
13319/22300 (epoch 29.863), train_loss = 0.40330964, grad/param norm = 2.8855e-01, time/batch = 15.6379s	
13320/22300 (epoch 29.865), train_loss = 0.40387289, grad/param norm = 2.5049e-01, time/batch = 15.7282s	
13321/22300 (epoch 29.868), train_loss = 0.51425127, grad/param norm = 3.2334e-01, time/batch = 15.7031s	
13322/22300 (epoch 29.870), train_loss = 0.51791276, grad/param norm = 2.8965e-01, time/batch = 15.5491s	
13323/22300 (epoch 29.872), train_loss = 0.58539607, grad/param norm = 2.5481e-01, time/batch = 15.0705s	
13324/22300 (epoch 29.874), train_loss = 0.53494568, grad/param norm = 3.0472e-01, time/batch = 15.3871s	
13325/22300 (epoch 29.877), train_loss = 0.51921412, grad/param norm = 2.7166e-01, time/batch = 15.6197s	
13326/22300 (epoch 29.879), train_loss = 0.43757325, grad/param norm = 2.5534e-01, time/batch = 15.5332s	
13327/22300 (epoch 29.881), train_loss = 0.40721462, grad/param norm = 2.5218e-01, time/batch = 15.2273s	
13328/22300 (epoch 29.883), train_loss = 0.40350634, grad/param norm = 2.6890e-01, time/batch = 15.3995s	
13329/22300 (epoch 29.886), train_loss = 0.39201197, grad/param norm = 3.0021e-01, time/batch = 15.6373s	
13330/22300 (epoch 29.888), train_loss = 0.44758795, grad/param norm = 2.6617e-01, time/batch = 15.5367s	
13331/22300 (epoch 29.890), train_loss = 0.44967928, grad/param norm = 2.6576e-01, time/batch = 15.3659s	
13332/22300 (epoch 29.892), train_loss = 0.64402870, grad/param norm = 3.2250e-01, time/batch = 15.2285s	
13333/22300 (epoch 29.895), train_loss = 0.62273890, grad/param norm = 3.4121e-01, time/batch = 15.5641s	
13334/22300 (epoch 29.897), train_loss = 0.51107308, grad/param norm = 3.5498e-01, time/batch = 15.8695s	
13335/22300 (epoch 29.899), train_loss = 0.46862118, grad/param norm = 2.7769e-01, time/batch = 15.3110s	
13336/22300 (epoch 29.901), train_loss = 0.53346376, grad/param norm = 2.8037e-01, time/batch = 14.9888s	
13337/22300 (epoch 29.904), train_loss = 0.57651338, grad/param norm = 3.0078e-01, time/batch = 15.2097s	
13338/22300 (epoch 29.906), train_loss = 0.53380797, grad/param norm = 2.3740e-01, time/batch = 15.3040s	
13339/22300 (epoch 29.908), train_loss = 0.45479417, grad/param norm = 2.4818e-01, time/batch = 15.3959s	
13340/22300 (epoch 29.910), train_loss = 0.41482973, grad/param norm = 2.2193e-01, time/batch = 15.3141s	
13341/22300 (epoch 29.913), train_loss = 0.55734164, grad/param norm = 2.8424e-01, time/batch = 15.4579s	
13342/22300 (epoch 29.915), train_loss = 0.65183604, grad/param norm = 2.8729e-01, time/batch = 15.0733s	
13343/22300 (epoch 29.917), train_loss = 0.53055644, grad/param norm = 2.6495e-01, time/batch = 15.0692s	
13344/22300 (epoch 29.919), train_loss = 0.55315533, grad/param norm = 2.5090e-01, time/batch = 15.4405s	
13345/22300 (epoch 29.922), train_loss = 0.51587418, grad/param norm = 3.1767e-01, time/batch = 15.6007s	
13346/22300 (epoch 29.924), train_loss = 0.31730021, grad/param norm = 2.0564e-01, time/batch = 15.0615s	
13347/22300 (epoch 29.926), train_loss = 0.39455820, grad/param norm = 2.1565e-01, time/batch = 15.6548s	
13348/22300 (epoch 29.928), train_loss = 0.46587790, grad/param norm = 3.4456e-01, time/batch = 15.3854s	
13349/22300 (epoch 29.930), train_loss = 0.44907844, grad/param norm = 2.6971e-01, time/batch = 15.5280s	
13350/22300 (epoch 29.933), train_loss = 0.53528854, grad/param norm = 2.7439e-01, time/batch = 15.3822s	
13351/22300 (epoch 29.935), train_loss = 0.50409361, grad/param norm = 2.9757e-01, time/batch = 15.2286s	
13352/22300 (epoch 29.937), train_loss = 0.59322517, grad/param norm = 2.9488e-01, time/batch = 15.6359s	
13353/22300 (epoch 29.939), train_loss = 0.54880894, grad/param norm = 3.0007e-01, time/batch = 15.6982s	
13354/22300 (epoch 29.942), train_loss = 0.69612961, grad/param norm = 3.4045e-01, time/batch = 15.4632s	
13355/22300 (epoch 29.944), train_loss = 0.74260939, grad/param norm = 3.6384e-01, time/batch = 15.7099s	
13356/22300 (epoch 29.946), train_loss = 0.53849464, grad/param norm = 3.2983e-01, time/batch = 15.6505s	
13357/22300 (epoch 29.948), train_loss = 0.44256143, grad/param norm = 2.1105e-01, time/batch = 15.2925s	
13358/22300 (epoch 29.951), train_loss = 0.36593123, grad/param norm = 2.3161e-01, time/batch = 15.4126s	
13359/22300 (epoch 29.953), train_loss = 0.43309752, grad/param norm = 2.8485e-01, time/batch = 15.6536s	
13360/22300 (epoch 29.955), train_loss = 0.61688468, grad/param norm = 2.9376e-01, time/batch = 15.3964s	
13361/22300 (epoch 29.957), train_loss = 0.69164706, grad/param norm = 2.7586e-01, time/batch = 15.9377s	
13362/22300 (epoch 29.960), train_loss = 0.61543957, grad/param norm = 2.8495e-01, time/batch = 15.5433s	
13363/22300 (epoch 29.962), train_loss = 0.44472634, grad/param norm = 3.5917e-01, time/batch = 15.5727s	
13364/22300 (epoch 29.964), train_loss = 0.46137345, grad/param norm = 2.4822e-01, time/batch = 15.6227s	
13365/22300 (epoch 29.966), train_loss = 0.41151341, grad/param norm = 2.4572e-01, time/batch = 15.6316s	
13366/22300 (epoch 29.969), train_loss = 0.47335668, grad/param norm = 2.8021e-01, time/batch = 15.5429s	
13367/22300 (epoch 29.971), train_loss = 0.48916670, grad/param norm = 2.7350e-01, time/batch = 15.6033s	
13368/22300 (epoch 29.973), train_loss = 0.50357548, grad/param norm = 2.8656e-01, time/batch = 15.1392s	
13369/22300 (epoch 29.975), train_loss = 0.66483939, grad/param norm = 3.7051e-01, time/batch = 15.2212s	
13370/22300 (epoch 29.978), train_loss = 0.60033008, grad/param norm = 3.0708e-01, time/batch = 14.9871s	
13371/22300 (epoch 29.980), train_loss = 0.69559804, grad/param norm = 3.3721e-01, time/batch = 15.2960s	
13372/22300 (epoch 29.982), train_loss = 0.40120327, grad/param norm = 2.8099e-01, time/batch = 15.3828s	
13373/22300 (epoch 29.984), train_loss = 0.49279685, grad/param norm = 2.6012e-01, time/batch = 15.5408s	
13374/22300 (epoch 29.987), train_loss = 0.45688542, grad/param norm = 2.4921e-01, time/batch = 15.1439s	
13375/22300 (epoch 29.989), train_loss = 0.41289407, grad/param norm = 2.4928e-01, time/batch = 15.1311s	
13376/22300 (epoch 29.991), train_loss = 0.71942085, grad/param norm = 4.0250e-01, time/batch = 15.4464s	
13377/22300 (epoch 29.993), train_loss = 0.91931637, grad/param norm = 3.8331e-01, time/batch = 15.3886s	
13378/22300 (epoch 29.996), train_loss = 0.84952077, grad/param norm = 3.5156e-01, time/batch = 15.7380s	
13379/22300 (epoch 29.998), train_loss = 0.50430012, grad/param norm = 2.8112e-01, time/batch = 16.0358s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
13380/22300 (epoch 30.000), train_loss = 0.42151425, grad/param norm = 2.5951e-01, time/batch = 15.9749s	
13381/22300 (epoch 30.002), train_loss = 0.78209275, grad/param norm = 2.9905e-01, time/batch = 16.2380s	
13382/22300 (epoch 30.004), train_loss = 0.53460865, grad/param norm = 2.8088e-01, time/batch = 16.1060s	
13383/22300 (epoch 30.007), train_loss = 0.56589982, grad/param norm = 3.3879e-01, time/batch = 16.0519s	
13384/22300 (epoch 30.009), train_loss = 0.59830668, grad/param norm = 3.4903e-01, time/batch = 16.3778s	
13385/22300 (epoch 30.011), train_loss = 0.71712316, grad/param norm = 3.1570e-01, time/batch = 16.3696s	
13386/22300 (epoch 30.013), train_loss = 0.53392164, grad/param norm = 2.1148e-01, time/batch = 16.1751s	
13387/22300 (epoch 30.016), train_loss = 0.44197034, grad/param norm = 2.9134e-01, time/batch = 16.1816s	
13388/22300 (epoch 30.018), train_loss = 0.53548060, grad/param norm = 3.2288e-01, time/batch = 15.9768s	
13389/22300 (epoch 30.020), train_loss = 0.46420813, grad/param norm = 2.7260e-01, time/batch = 15.8959s	
13390/22300 (epoch 30.022), train_loss = 0.40578664, grad/param norm = 2.8484e-01, time/batch = 16.3158s	
13391/22300 (epoch 30.025), train_loss = 0.43270430, grad/param norm = 2.3123e-01, time/batch = 16.0320s	
13392/22300 (epoch 30.027), train_loss = 0.42515627, grad/param norm = 2.1497e-01, time/batch = 16.3821s	
13393/22300 (epoch 30.029), train_loss = 0.45431309, grad/param norm = 2.7803e-01, time/batch = 16.2751s	
13394/22300 (epoch 30.031), train_loss = 0.43806078, grad/param norm = 2.4522e-01, time/batch = 16.2287s	
13395/22300 (epoch 30.034), train_loss = 0.41513905, grad/param norm = 2.2152e-01, time/batch = 16.3804s	
13396/22300 (epoch 30.036), train_loss = 0.37275206, grad/param norm = 1.9907e-01, time/batch = 16.3023s	
13397/22300 (epoch 30.038), train_loss = 0.38456155, grad/param norm = 2.2567e-01, time/batch = 16.2151s	
13398/22300 (epoch 30.040), train_loss = 0.45703988, grad/param norm = 2.8957e-01, time/batch = 16.3881s	
13399/22300 (epoch 30.043), train_loss = 0.69179086, grad/param norm = 3.1523e-01, time/batch = 16.0491s	
13400/22300 (epoch 30.045), train_loss = 0.57757349, grad/param norm = 2.9706e-01, time/batch = 16.3078s	
13401/22300 (epoch 30.047), train_loss = 0.60597615, grad/param norm = 3.0364e-01, time/batch = 16.4753s	
13402/22300 (epoch 30.049), train_loss = 0.47908348, grad/param norm = 2.4971e-01, time/batch = 15.9647s	
13403/22300 (epoch 30.052), train_loss = 0.56209177, grad/param norm = 3.6596e-01, time/batch = 16.1341s	
13404/22300 (epoch 30.054), train_loss = 0.55468282, grad/param norm = 2.8734e-01, time/batch = 15.9595s	
13405/22300 (epoch 30.056), train_loss = 0.28427075, grad/param norm = 2.0850e-01, time/batch = 15.9007s	
13406/22300 (epoch 30.058), train_loss = 0.46974367, grad/param norm = 2.9733e-01, time/batch = 16.0502s	
13407/22300 (epoch 30.061), train_loss = 0.41505910, grad/param norm = 2.8269e-01, time/batch = 16.0393s	
13408/22300 (epoch 30.063), train_loss = 0.63931579, grad/param norm = 4.4525e-01, time/batch = 16.2072s	
13409/22300 (epoch 30.065), train_loss = 0.67936054, grad/param norm = 4.0262e-01, time/batch = 16.2179s	
13410/22300 (epoch 30.067), train_loss = 0.44087573, grad/param norm = 2.3923e-01, time/batch = 15.9705s	
13411/22300 (epoch 30.070), train_loss = 0.50668316, grad/param norm = 2.9349e-01, time/batch = 16.3786s	
13412/22300 (epoch 30.072), train_loss = 0.54916839, grad/param norm = 3.1826e-01, time/batch = 16.3671s	
13413/22300 (epoch 30.074), train_loss = 0.51439754, grad/param norm = 2.5894e-01, time/batch = 16.0076s	
13414/22300 (epoch 30.076), train_loss = 0.53558454, grad/param norm = 2.9538e-01, time/batch = 16.0662s	
13415/22300 (epoch 30.078), train_loss = 0.64866739, grad/param norm = 3.6467e-01, time/batch = 15.9645s	
13416/22300 (epoch 30.081), train_loss = 0.65230610, grad/param norm = 3.9517e-01, time/batch = 16.0675s	
13417/22300 (epoch 30.083), train_loss = 0.75829421, grad/param norm = 3.9771e-01, time/batch = 27.7454s	
13418/22300 (epoch 30.085), train_loss = 0.67974131, grad/param norm = 3.2252e-01, time/batch = 17.7028s	
13419/22300 (epoch 30.087), train_loss = 0.57675485, grad/param norm = 2.8579e-01, time/batch = 15.8481s	
13420/22300 (epoch 30.090), train_loss = 0.51931254, grad/param norm = 3.0798e-01, time/batch = 15.9060s	
13421/22300 (epoch 30.092), train_loss = 0.43515813, grad/param norm = 2.8275e-01, time/batch = 16.0892s	
13422/22300 (epoch 30.094), train_loss = 0.42231158, grad/param norm = 2.9926e-01, time/batch = 16.0121s	
13423/22300 (epoch 30.096), train_loss = 0.67964384, grad/param norm = 3.6040e-01, time/batch = 16.1747s	
13424/22300 (epoch 30.099), train_loss = 0.44177275, grad/param norm = 2.3056e-01, time/batch = 16.2173s	
13425/22300 (epoch 30.101), train_loss = 0.59483953, grad/param norm = 3.0163e-01, time/batch = 16.3130s	
13426/22300 (epoch 30.103), train_loss = 0.50717864, grad/param norm = 2.8291e-01, time/batch = 16.1541s	
13427/22300 (epoch 30.105), train_loss = 0.40297601, grad/param norm = 2.7054e-01, time/batch = 16.2092s	
13428/22300 (epoch 30.108), train_loss = 0.52876850, grad/param norm = 2.6147e-01, time/batch = 16.4657s	
13429/22300 (epoch 30.110), train_loss = 0.59031459, grad/param norm = 2.8434e-01, time/batch = 16.2210s	
13430/22300 (epoch 30.112), train_loss = 0.55963496, grad/param norm = 2.9496e-01, time/batch = 16.1285s	
13431/22300 (epoch 30.114), train_loss = 0.58233846, grad/param norm = 3.2133e-01, time/batch = 16.3703s	
13432/22300 (epoch 30.117), train_loss = 0.68136472, grad/param norm = 2.9970e-01, time/batch = 16.1316s	
13433/22300 (epoch 30.119), train_loss = 0.61583903, grad/param norm = 2.9335e-01, time/batch = 16.3207s	
13434/22300 (epoch 30.121), train_loss = 0.73072450, grad/param norm = 3.5227e-01, time/batch = 16.3046s	
13435/22300 (epoch 30.123), train_loss = 0.73619388, grad/param norm = 3.2797e-01, time/batch = 16.1133s	
13436/22300 (epoch 30.126), train_loss = 0.54186383, grad/param norm = 2.4653e-01, time/batch = 15.9918s	
13437/22300 (epoch 30.128), train_loss = 0.56463287, grad/param norm = 2.9781e-01, time/batch = 16.2345s	
13438/22300 (epoch 30.130), train_loss = 0.45242025, grad/param norm = 2.4198e-01, time/batch = 16.0746s	
13439/22300 (epoch 30.132), train_loss = 0.34728147, grad/param norm = 2.0168e-01, time/batch = 16.0380s	
13440/22300 (epoch 30.135), train_loss = 0.37339419, grad/param norm = 2.6166e-01, time/batch = 16.0731s	
13441/22300 (epoch 30.137), train_loss = 0.30935959, grad/param norm = 2.4940e-01, time/batch = 16.3200s	
13442/22300 (epoch 30.139), train_loss = 0.47164268, grad/param norm = 2.6015e-01, time/batch = 16.2194s	
13443/22300 (epoch 30.141), train_loss = 0.57639284, grad/param norm = 2.7020e-01, time/batch = 15.9894s	
13444/22300 (epoch 30.143), train_loss = 0.52566204, grad/param norm = 3.1179e-01, time/batch = 16.1350s	
13445/22300 (epoch 30.146), train_loss = 0.63391259, grad/param norm = 3.7474e-01, time/batch = 15.9903s	
13446/22300 (epoch 30.148), train_loss = 0.41814183, grad/param norm = 2.7767e-01, time/batch = 16.1761s	
13447/22300 (epoch 30.150), train_loss = 0.48521437, grad/param norm = 3.0284e-01, time/batch = 16.2261s	
13448/22300 (epoch 30.152), train_loss = 0.38710100, grad/param norm = 2.7245e-01, time/batch = 16.3207s	
13449/22300 (epoch 30.155), train_loss = 0.42787448, grad/param norm = 2.7626e-01, time/batch = 16.1496s	
13450/22300 (epoch 30.157), train_loss = 0.56204335, grad/param norm = 3.9501e-01, time/batch = 16.2281s	
13451/22300 (epoch 30.159), train_loss = 0.59283736, grad/param norm = 3.5200e-01, time/batch = 16.4329s	
13452/22300 (epoch 30.161), train_loss = 0.57435020, grad/param norm = 3.1516e-01, time/batch = 16.4784s	
13453/22300 (epoch 30.164), train_loss = 0.43379537, grad/param norm = 2.5502e-01, time/batch = 16.4102s	
13454/22300 (epoch 30.166), train_loss = 0.36895876, grad/param norm = 1.9093e-01, time/batch = 16.4005s	
13455/22300 (epoch 30.168), train_loss = 0.37942242, grad/param norm = 2.5407e-01, time/batch = 16.3982s	
13456/22300 (epoch 30.170), train_loss = 0.52059362, grad/param norm = 3.1862e-01, time/batch = 16.3924s	
13457/22300 (epoch 30.173), train_loss = 0.62120985, grad/param norm = 3.3340e-01, time/batch = 16.4046s	
13458/22300 (epoch 30.175), train_loss = 0.51980471, grad/param norm = 3.0109e-01, time/batch = 16.4804s	
13459/22300 (epoch 30.177), train_loss = 0.37702260, grad/param norm = 2.5436e-01, time/batch = 16.2403s	
13460/22300 (epoch 30.179), train_loss = 0.50788567, grad/param norm = 2.7707e-01, time/batch = 16.2728s	
13461/22300 (epoch 30.182), train_loss = 0.66708573, grad/param norm = 3.2387e-01, time/batch = 16.4673s	
13462/22300 (epoch 30.184), train_loss = 0.74758777, grad/param norm = 3.0490e-01, time/batch = 16.4706s	
13463/22300 (epoch 30.186), train_loss = 0.56018967, grad/param norm = 3.1134e-01, time/batch = 16.1580s	
13464/22300 (epoch 30.188), train_loss = 0.75107429, grad/param norm = 3.9091e-01, time/batch = 16.2807s	
13465/22300 (epoch 30.191), train_loss = 0.63944128, grad/param norm = 3.2676e-01, time/batch = 16.3190s	
13466/22300 (epoch 30.193), train_loss = 0.56154711, grad/param norm = 3.1972e-01, time/batch = 16.2142s	
13467/22300 (epoch 30.195), train_loss = 0.49353204, grad/param norm = 2.6812e-01, time/batch = 15.9783s	
13468/22300 (epoch 30.197), train_loss = 0.44950457, grad/param norm = 2.6248e-01, time/batch = 15.9734s	
13469/22300 (epoch 30.200), train_loss = 0.39535244, grad/param norm = 2.4723e-01, time/batch = 15.9728s	
13470/22300 (epoch 30.202), train_loss = 0.44289857, grad/param norm = 2.1615e-01, time/batch = 16.1893s	
13471/22300 (epoch 30.204), train_loss = 0.49419437, grad/param norm = 2.5115e-01, time/batch = 16.2920s	
13472/22300 (epoch 30.206), train_loss = 0.42904767, grad/param norm = 2.4603e-01, time/batch = 16.2332s	
13473/22300 (epoch 30.209), train_loss = 0.44793747, grad/param norm = 2.2891e-01, time/batch = 16.0698s	
13474/22300 (epoch 30.211), train_loss = 0.38072441, grad/param norm = 2.5320e-01, time/batch = 16.0799s	
13475/22300 (epoch 30.213), train_loss = 0.49616981, grad/param norm = 2.6385e-01, time/batch = 16.0717s	
13476/22300 (epoch 30.215), train_loss = 0.65254830, grad/param norm = 3.3785e-01, time/batch = 16.2125s	
13477/22300 (epoch 30.217), train_loss = 0.66286608, grad/param norm = 3.5671e-01, time/batch = 16.1428s	
13478/22300 (epoch 30.220), train_loss = 0.46819690, grad/param norm = 2.4911e-01, time/batch = 16.1781s	
13479/22300 (epoch 30.222), train_loss = 0.44035339, grad/param norm = 2.5156e-01, time/batch = 16.3040s	
13480/22300 (epoch 30.224), train_loss = 0.45551259, grad/param norm = 2.7299e-01, time/batch = 16.3268s	
13481/22300 (epoch 30.226), train_loss = 0.47860916, grad/param norm = 2.2823e-01, time/batch = 16.2830s	
13482/22300 (epoch 30.229), train_loss = 0.39103039, grad/param norm = 2.4597e-01, time/batch = 16.1169s	
13483/22300 (epoch 30.231), train_loss = 0.61355542, grad/param norm = 3.2735e-01, time/batch = 16.1169s	
13484/22300 (epoch 30.233), train_loss = 0.54010961, grad/param norm = 3.5368e-01, time/batch = 15.9861s	
13485/22300 (epoch 30.235), train_loss = 0.38756525, grad/param norm = 2.2350e-01, time/batch = 16.2295s	
13486/22300 (epoch 30.238), train_loss = 0.40616516, grad/param norm = 2.4131e-01, time/batch = 16.3568s	
13487/22300 (epoch 30.240), train_loss = 0.41816650, grad/param norm = 2.0943e-01, time/batch = 16.0643s	
13488/22300 (epoch 30.242), train_loss = 0.40176146, grad/param norm = 2.5846e-01, time/batch = 16.0648s	
13489/22300 (epoch 30.244), train_loss = 0.26727017, grad/param norm = 1.7365e-01, time/batch = 16.0468s	
13490/22300 (epoch 30.247), train_loss = 0.38752000, grad/param norm = 2.1838e-01, time/batch = 16.2102s	
13491/22300 (epoch 30.249), train_loss = 0.26862884, grad/param norm = 1.7926e-01, time/batch = 16.2344s	
13492/22300 (epoch 30.251), train_loss = 0.36303124, grad/param norm = 2.0246e-01, time/batch = 16.0572s	
13493/22300 (epoch 30.253), train_loss = 0.25044449, grad/param norm = 1.8650e-01, time/batch = 16.0277s	
13494/22300 (epoch 30.256), train_loss = 0.33103288, grad/param norm = 1.7588e-01, time/batch = 16.0575s	
13495/22300 (epoch 30.258), train_loss = 0.51750279, grad/param norm = 3.2154e-01, time/batch = 16.1495s	
13496/22300 (epoch 30.260), train_loss = 0.51180759, grad/param norm = 2.7842e-01, time/batch = 16.2994s	
13497/22300 (epoch 30.262), train_loss = 0.38456400, grad/param norm = 2.2079e-01, time/batch = 15.9691s	
13498/22300 (epoch 30.265), train_loss = 0.35294142, grad/param norm = 2.2831e-01, time/batch = 15.9775s	
13499/22300 (epoch 30.267), train_loss = 0.40079209, grad/param norm = 2.2628e-01, time/batch = 15.7579s	
13500/22300 (epoch 30.269), train_loss = 0.47153068, grad/param norm = 2.9725e-01, time/batch = 15.9800s	
13501/22300 (epoch 30.271), train_loss = 0.53087700, grad/param norm = 2.7603e-01, time/batch = 16.2708s	
13502/22300 (epoch 30.274), train_loss = 0.39703408, grad/param norm = 2.5311e-01, time/batch = 16.3075s	
13503/22300 (epoch 30.276), train_loss = 0.32760286, grad/param norm = 1.9037e-01, time/batch = 16.0239s	
13504/22300 (epoch 30.278), train_loss = 0.33066964, grad/param norm = 1.8504e-01, time/batch = 16.0856s	
13505/22300 (epoch 30.280), train_loss = 0.38371136, grad/param norm = 2.2931e-01, time/batch = 16.1485s	
13506/22300 (epoch 30.283), train_loss = 0.28539727, grad/param norm = 1.7825e-01, time/batch = 15.8791s	
13507/22300 (epoch 30.285), train_loss = 0.35804858, grad/param norm = 2.4432e-01, time/batch = 15.9797s	
13508/22300 (epoch 30.287), train_loss = 0.48684749, grad/param norm = 2.3848e-01, time/batch = 15.8659s	
13509/22300 (epoch 30.289), train_loss = 0.43520171, grad/param norm = 2.3664e-01, time/batch = 16.1160s	
13510/22300 (epoch 30.291), train_loss = 0.46070232, grad/param norm = 3.2156e-01, time/batch = 15.9837s	
13511/22300 (epoch 30.294), train_loss = 0.34224528, grad/param norm = 2.0263e-01, time/batch = 16.3700s	
13512/22300 (epoch 30.296), train_loss = 0.43522908, grad/param norm = 3.0793e-01, time/batch = 16.1859s	
13513/22300 (epoch 30.298), train_loss = 0.54512576, grad/param norm = 2.9090e-01, time/batch = 16.1501s	
13514/22300 (epoch 30.300), train_loss = 0.59987536, grad/param norm = 2.9717e-01, time/batch = 15.9057s	
13515/22300 (epoch 30.303), train_loss = 0.45259966, grad/param norm = 2.8562e-01, time/batch = 16.1393s	
13516/22300 (epoch 30.305), train_loss = 0.45865314, grad/param norm = 3.0174e-01, time/batch = 16.3104s	
13517/22300 (epoch 30.307), train_loss = 0.40206498, grad/param norm = 2.6605e-01, time/batch = 16.0593s	
13518/22300 (epoch 30.309), train_loss = 0.37511740, grad/param norm = 2.2907e-01, time/batch = 15.8937s	
13519/22300 (epoch 30.312), train_loss = 0.34171091, grad/param norm = 1.8860e-01, time/batch = 15.7635s	
13520/22300 (epoch 30.314), train_loss = 0.36808839, grad/param norm = 2.3877e-01, time/batch = 16.2095s	
13521/22300 (epoch 30.316), train_loss = 0.36330192, grad/param norm = 2.4308e-01, time/batch = 16.0885s	
13522/22300 (epoch 30.318), train_loss = 0.41502994, grad/param norm = 2.4984e-01, time/batch = 16.0045s	
13523/22300 (epoch 30.321), train_loss = 0.50965190, grad/param norm = 2.4672e-01, time/batch = 16.1631s	
13524/22300 (epoch 30.323), train_loss = 0.36862637, grad/param norm = 2.3350e-01, time/batch = 16.0366s	
13525/22300 (epoch 30.325), train_loss = 0.34491674, grad/param norm = 2.2729e-01, time/batch = 15.9425s	
13526/22300 (epoch 30.327), train_loss = 0.35163619, grad/param norm = 1.9253e-01, time/batch = 16.1367s	
13527/22300 (epoch 30.330), train_loss = 0.36624301, grad/param norm = 2.4895e-01, time/batch = 16.1147s	
13528/22300 (epoch 30.332), train_loss = 0.34577975, grad/param norm = 2.2857e-01, time/batch = 16.0412s	
13529/22300 (epoch 30.334), train_loss = 0.39728977, grad/param norm = 2.4193e-01, time/batch = 15.9717s	
13530/22300 (epoch 30.336), train_loss = 0.42431135, grad/param norm = 2.5888e-01, time/batch = 15.4616s	
13531/22300 (epoch 30.339), train_loss = 0.46781406, grad/param norm = 2.6655e-01, time/batch = 15.6814s	
13532/22300 (epoch 30.341), train_loss = 0.48878609, grad/param norm = 2.7676e-01, time/batch = 15.0768s	
13533/22300 (epoch 30.343), train_loss = 0.52534386, grad/param norm = 2.6794e-01, time/batch = 14.8185s	
13534/22300 (epoch 30.345), train_loss = 0.41544086, grad/param norm = 2.3206e-01, time/batch = 15.5868s	
13535/22300 (epoch 30.348), train_loss = 0.41793760, grad/param norm = 2.1379e-01, time/batch = 14.4059s	
13536/22300 (epoch 30.350), train_loss = 0.35015316, grad/param norm = 2.5735e-01, time/batch = 14.3383s	
13537/22300 (epoch 30.352), train_loss = 0.45754966, grad/param norm = 2.5724e-01, time/batch = 14.8931s	
13538/22300 (epoch 30.354), train_loss = 0.66463408, grad/param norm = 3.7707e-01, time/batch = 14.6388s	
13539/22300 (epoch 30.357), train_loss = 0.56940864, grad/param norm = 2.7132e-01, time/batch = 14.6414s	
13540/22300 (epoch 30.359), train_loss = 0.38019011, grad/param norm = 2.9646e-01, time/batch = 14.0980s	
13541/22300 (epoch 30.361), train_loss = 0.39623028, grad/param norm = 3.5387e-01, time/batch = 15.5922s	
13542/22300 (epoch 30.363), train_loss = 0.53877423, grad/param norm = 3.3526e-01, time/batch = 15.0078s	
13543/22300 (epoch 30.365), train_loss = 0.38907255, grad/param norm = 2.4287e-01, time/batch = 14.6610s	
13544/22300 (epoch 30.368), train_loss = 0.40569965, grad/param norm = 2.8345e-01, time/batch = 14.3408s	
13545/22300 (epoch 30.370), train_loss = 0.40962551, grad/param norm = 2.6341e-01, time/batch = 15.0379s	
13546/22300 (epoch 30.372), train_loss = 0.33110525, grad/param norm = 2.4081e-01, time/batch = 14.8734s	
13547/22300 (epoch 30.374), train_loss = 0.31178999, grad/param norm = 2.0551e-01, time/batch = 15.4971s	
13548/22300 (epoch 30.377), train_loss = 0.43225491, grad/param norm = 2.6719e-01, time/batch = 15.0420s	
13549/22300 (epoch 30.379), train_loss = 0.38749234, grad/param norm = 2.3534e-01, time/batch = 14.8918s	
13550/22300 (epoch 30.381), train_loss = 0.51009511, grad/param norm = 2.6733e-01, time/batch = 14.7890s	
13551/22300 (epoch 30.383), train_loss = 0.43309090, grad/param norm = 2.6399e-01, time/batch = 15.2951s	
13552/22300 (epoch 30.386), train_loss = 0.43565805, grad/param norm = 2.7623e-01, time/batch = 14.8961s	
13553/22300 (epoch 30.388), train_loss = 0.35802737, grad/param norm = 2.6930e-01, time/batch = 14.6596s	
13554/22300 (epoch 30.390), train_loss = 0.39134759, grad/param norm = 2.6843e-01, time/batch = 14.9042s	
13555/22300 (epoch 30.392), train_loss = 0.44391953, grad/param norm = 3.0315e-01, time/batch = 15.1293s	
13556/22300 (epoch 30.395), train_loss = 0.34092406, grad/param norm = 2.0530e-01, time/batch = 15.0433s	
13557/22300 (epoch 30.397), train_loss = 0.22476802, grad/param norm = 1.6272e-01, time/batch = 15.2528s	
13558/22300 (epoch 30.399), train_loss = 0.33579013, grad/param norm = 2.2944e-01, time/batch = 15.0449s	
13559/22300 (epoch 30.401), train_loss = 0.37954947, grad/param norm = 2.4205e-01, time/batch = 14.9505s	
13560/22300 (epoch 30.404), train_loss = 0.40314020, grad/param norm = 2.8205e-01, time/batch = 14.3175s	
13561/22300 (epoch 30.406), train_loss = 0.62539929, grad/param norm = 3.0846e-01, time/batch = 15.3757s	
13562/22300 (epoch 30.408), train_loss = 0.51509698, grad/param norm = 2.9258e-01, time/batch = 14.7921s	
13563/22300 (epoch 30.410), train_loss = 0.53838142, grad/param norm = 3.4375e-01, time/batch = 14.5583s	
13564/22300 (epoch 30.413), train_loss = 0.37734957, grad/param norm = 2.5958e-01, time/batch = 14.8723s	
13565/22300 (epoch 30.415), train_loss = 0.30535891, grad/param norm = 2.6015e-01, time/batch = 15.2327s	
13566/22300 (epoch 30.417), train_loss = 0.45302397, grad/param norm = 2.6641e-01, time/batch = 15.0331s	
13567/22300 (epoch 30.419), train_loss = 0.40162168, grad/param norm = 2.2340e-01, time/batch = 14.3278s	
13568/22300 (epoch 30.422), train_loss = 0.37105297, grad/param norm = 2.7335e-01, time/batch = 14.7137s	
13569/22300 (epoch 30.424), train_loss = 0.45882863, grad/param norm = 3.0258e-01, time/batch = 14.4708s	
13570/22300 (epoch 30.426), train_loss = 0.31888731, grad/param norm = 2.2804e-01, time/batch = 14.0743s	
13571/22300 (epoch 30.428), train_loss = 0.34310898, grad/param norm = 2.0157e-01, time/batch = 14.7377s	
13572/22300 (epoch 30.430), train_loss = 0.42143569, grad/param norm = 2.8918e-01, time/batch = 14.1590s	
13573/22300 (epoch 30.433), train_loss = 0.41667664, grad/param norm = 2.3860e-01, time/batch = 14.2497s	
13574/22300 (epoch 30.435), train_loss = 0.41571054, grad/param norm = 2.4693e-01, time/batch = 14.5649s	
13575/22300 (epoch 30.437), train_loss = 0.47118446, grad/param norm = 3.4825e-01, time/batch = 15.1091s	
13576/22300 (epoch 30.439), train_loss = 0.51279853, grad/param norm = 2.6753e-01, time/batch = 14.7190s	
13577/22300 (epoch 30.442), train_loss = 0.44410540, grad/param norm = 2.2920e-01, time/batch = 14.3961s	
13578/22300 (epoch 30.444), train_loss = 0.35070038, grad/param norm = 1.7666e-01, time/batch = 14.2191s	
13579/22300 (epoch 30.446), train_loss = 0.38452597, grad/param norm = 2.4444e-01, time/batch = 15.2536s	
13580/22300 (epoch 30.448), train_loss = 0.27678488, grad/param norm = 1.9923e-01, time/batch = 14.6177s	
13581/22300 (epoch 30.451), train_loss = 0.47955017, grad/param norm = 2.5957e-01, time/batch = 14.6588s	
13582/22300 (epoch 30.453), train_loss = 0.36359686, grad/param norm = 2.2368e-01, time/batch = 14.2495s	
13583/22300 (epoch 30.455), train_loss = 0.52217837, grad/param norm = 2.6927e-01, time/batch = 15.6084s	
13584/22300 (epoch 30.457), train_loss = 0.63907169, grad/param norm = 3.2560e-01, time/batch = 14.9124s	
13585/22300 (epoch 30.460), train_loss = 0.54303930, grad/param norm = 3.3671e-01, time/batch = 14.8291s	
13586/22300 (epoch 30.462), train_loss = 0.55968715, grad/param norm = 2.8427e-01, time/batch = 15.1987s	
13587/22300 (epoch 30.464), train_loss = 0.48834148, grad/param norm = 2.9588e-01, time/batch = 15.5192s	
13588/22300 (epoch 30.466), train_loss = 0.40424760, grad/param norm = 2.4946e-01, time/batch = 14.5482s	
13589/22300 (epoch 30.469), train_loss = 0.38855520, grad/param norm = 1.8593e-01, time/batch = 14.6504s	
13590/22300 (epoch 30.471), train_loss = 0.51378412, grad/param norm = 2.2602e-01, time/batch = 14.1725s	
13591/22300 (epoch 30.473), train_loss = 0.46075386, grad/param norm = 2.2986e-01, time/batch = 14.8869s	
13592/22300 (epoch 30.475), train_loss = 0.38352204, grad/param norm = 2.7113e-01, time/batch = 14.5002s	
13593/22300 (epoch 30.478), train_loss = 0.41655428, grad/param norm = 2.6970e-01, time/batch = 14.9611s	
13594/22300 (epoch 30.480), train_loss = 0.30906032, grad/param norm = 2.1303e-01, time/batch = 14.9522s	
13595/22300 (epoch 30.482), train_loss = 0.32936511, grad/param norm = 2.2595e-01, time/batch = 15.2809s	
13596/22300 (epoch 30.484), train_loss = 0.42461718, grad/param norm = 2.3115e-01, time/batch = 14.6541s	
13597/22300 (epoch 30.487), train_loss = 0.50900978, grad/param norm = 2.6612e-01, time/batch = 14.7310s	
13598/22300 (epoch 30.489), train_loss = 0.49596892, grad/param norm = 2.5398e-01, time/batch = 14.8922s	
13599/22300 (epoch 30.491), train_loss = 0.51946960, grad/param norm = 2.9675e-01, time/batch = 15.1227s	
13600/22300 (epoch 30.493), train_loss = 0.43891982, grad/param norm = 3.7186e-01, time/batch = 14.0922s	
13601/22300 (epoch 30.496), train_loss = 0.44196474, grad/param norm = 2.4614e-01, time/batch = 14.5738s	
13602/22300 (epoch 30.498), train_loss = 0.32393413, grad/param norm = 2.1215e-01, time/batch = 14.4304s	
13603/22300 (epoch 30.500), train_loss = 0.44789820, grad/param norm = 2.6547e-01, time/batch = 15.2658s	
13604/22300 (epoch 30.502), train_loss = 0.28872750, grad/param norm = 2.3491e-01, time/batch = 14.8109s	
13605/22300 (epoch 30.504), train_loss = 0.29763386, grad/param norm = 2.0217e-01, time/batch = 14.5054s	
13606/22300 (epoch 30.507), train_loss = 0.36496508, grad/param norm = 2.1184e-01, time/batch = 15.1467s	
13607/22300 (epoch 30.509), train_loss = 0.49293443, grad/param norm = 2.7466e-01, time/batch = 15.4451s	
13608/22300 (epoch 30.511), train_loss = 0.27139812, grad/param norm = 1.7518e-01, time/batch = 15.4471s	
13609/22300 (epoch 30.513), train_loss = 0.32308963, grad/param norm = 2.3940e-01, time/batch = 14.8596s	
13610/22300 (epoch 30.516), train_loss = 0.36706697, grad/param norm = 2.1966e-01, time/batch = 14.2507s	
13611/22300 (epoch 30.518), train_loss = 0.47816838, grad/param norm = 2.5809e-01, time/batch = 15.0459s	
13612/22300 (epoch 30.520), train_loss = 0.40371128, grad/param norm = 2.7883e-01, time/batch = 14.4188s	
13613/22300 (epoch 30.522), train_loss = 0.40351564, grad/param norm = 2.2667e-01, time/batch = 15.0529s	
13614/22300 (epoch 30.525), train_loss = 0.32280188, grad/param norm = 2.2111e-01, time/batch = 14.4174s	
13615/22300 (epoch 30.527), train_loss = 0.50133687, grad/param norm = 2.8166e-01, time/batch = 15.4281s	
13616/22300 (epoch 30.529), train_loss = 0.44684789, grad/param norm = 2.4666e-01, time/batch = 14.6406s	
13617/22300 (epoch 30.531), train_loss = 0.37585010, grad/param norm = 2.1590e-01, time/batch = 14.2377s	
13618/22300 (epoch 30.534), train_loss = 0.38715720, grad/param norm = 2.5153e-01, time/batch = 14.7249s	
13619/22300 (epoch 30.536), train_loss = 0.61220688, grad/param norm = 2.5892e-01, time/batch = 15.4474s	
13620/22300 (epoch 30.538), train_loss = 0.76296374, grad/param norm = 3.3561e-01, time/batch = 15.3214s	
13621/22300 (epoch 30.540), train_loss = 0.44181206, grad/param norm = 2.4358e-01, time/batch = 17.5513s	
13622/22300 (epoch 30.543), train_loss = 0.39746575, grad/param norm = 2.1130e-01, time/batch = 15.9598s	
13623/22300 (epoch 30.545), train_loss = 0.30113674, grad/param norm = 2.1415e-01, time/batch = 15.8735s	
13624/22300 (epoch 30.547), train_loss = 0.27900770, grad/param norm = 1.9366e-01, time/batch = 15.1505s	
13625/22300 (epoch 30.549), train_loss = 0.33586969, grad/param norm = 2.2165e-01, time/batch = 15.8711s	
13626/22300 (epoch 30.552), train_loss = 0.35106593, grad/param norm = 2.3491e-01, time/batch = 17.3675s	
13627/22300 (epoch 30.554), train_loss = 0.44746715, grad/param norm = 2.4794e-01, time/batch = 14.7396s	
13628/22300 (epoch 30.556), train_loss = 0.64515305, grad/param norm = 3.7456e-01, time/batch = 16.4640s	
13629/22300 (epoch 30.558), train_loss = 0.48087936, grad/param norm = 3.1897e-01, time/batch = 15.5350s	
13630/22300 (epoch 30.561), train_loss = 0.66640798, grad/param norm = 3.5435e-01, time/batch = 14.8890s	
13631/22300 (epoch 30.563), train_loss = 0.53093699, grad/param norm = 2.9412e-01, time/batch = 15.3846s	
13632/22300 (epoch 30.565), train_loss = 0.42181408, grad/param norm = 3.0901e-01, time/batch = 14.9848s	
13633/22300 (epoch 30.567), train_loss = 0.40960947, grad/param norm = 2.3933e-01, time/batch = 15.7679s	
13634/22300 (epoch 30.570), train_loss = 0.56122541, grad/param norm = 3.1757e-01, time/batch = 17.0324s	
13635/22300 (epoch 30.572), train_loss = 0.56335808, grad/param norm = 3.2939e-01, time/batch = 16.5703s	
13636/22300 (epoch 30.574), train_loss = 0.42455483, grad/param norm = 2.5790e-01, time/batch = 15.2057s	
13637/22300 (epoch 30.576), train_loss = 0.36952386, grad/param norm = 1.8853e-01, time/batch = 15.8571s	
13638/22300 (epoch 30.578), train_loss = 0.23427041, grad/param norm = 2.0421e-01, time/batch = 15.6016s	
13639/22300 (epoch 30.581), train_loss = 0.32047888, grad/param norm = 2.2072e-01, time/batch = 15.4752s	
13640/22300 (epoch 30.583), train_loss = 0.37805921, grad/param norm = 2.1241e-01, time/batch = 14.6595s	
13641/22300 (epoch 30.585), train_loss = 0.55506237, grad/param norm = 3.7883e-01, time/batch = 16.7147s	
13642/22300 (epoch 30.587), train_loss = 0.71112741, grad/param norm = 3.2788e-01, time/batch = 15.0693s	
13643/22300 (epoch 30.590), train_loss = 0.58764013, grad/param norm = 3.4023e-01, time/batch = 17.8819s	
13644/22300 (epoch 30.592), train_loss = 0.69778566, grad/param norm = 3.3298e-01, time/batch = 15.0394s	
13645/22300 (epoch 30.594), train_loss = 0.65461084, grad/param norm = 3.6455e-01, time/batch = 19.7911s	
13646/22300 (epoch 30.596), train_loss = 0.40565206, grad/param norm = 2.3550e-01, time/batch = 25.8668s	
13647/22300 (epoch 30.599), train_loss = 0.33719284, grad/param norm = 2.6596e-01, time/batch = 17.6466s	
13648/22300 (epoch 30.601), train_loss = 0.37774814, grad/param norm = 2.7095e-01, time/batch = 15.1236s	
13649/22300 (epoch 30.603), train_loss = 0.43638151, grad/param norm = 2.6925e-01, time/batch = 17.5439s	
13650/22300 (epoch 30.605), train_loss = 0.41025632, grad/param norm = 2.3957e-01, time/batch = 15.9425s	
13651/22300 (epoch 30.608), train_loss = 0.68839963, grad/param norm = 3.3889e-01, time/batch = 18.4421s	
13652/22300 (epoch 30.610), train_loss = 0.71315236, grad/param norm = 3.6144e-01, time/batch = 15.3002s	
13653/22300 (epoch 30.612), train_loss = 0.53162933, grad/param norm = 3.1408e-01, time/batch = 15.4518s	
13654/22300 (epoch 30.614), train_loss = 0.54747906, grad/param norm = 3.4891e-01, time/batch = 17.7872s	
13655/22300 (epoch 30.617), train_loss = 0.53665869, grad/param norm = 2.6897e-01, time/batch = 16.9445s	
13656/22300 (epoch 30.619), train_loss = 0.63932965, grad/param norm = 3.3753e-01, time/batch = 16.5376s	
13657/22300 (epoch 30.621), train_loss = 0.41056982, grad/param norm = 2.5435e-01, time/batch = 17.3809s	
13658/22300 (epoch 30.623), train_loss = 0.44312595, grad/param norm = 2.8329e-01, time/batch = 18.1284s	
13659/22300 (epoch 30.626), train_loss = 0.37668994, grad/param norm = 2.0873e-01, time/batch = 16.4508s	
13660/22300 (epoch 30.628), train_loss = 0.39457273, grad/param norm = 2.2029e-01, time/batch = 15.6389s	
13661/22300 (epoch 30.630), train_loss = 0.46883468, grad/param norm = 2.8751e-01, time/batch = 15.8089s	
13662/22300 (epoch 30.632), train_loss = 0.39182349, grad/param norm = 2.5706e-01, time/batch = 16.8632s	
13663/22300 (epoch 30.635), train_loss = 0.43625812, grad/param norm = 2.5275e-01, time/batch = 16.4786s	
13664/22300 (epoch 30.637), train_loss = 0.49500235, grad/param norm = 2.8066e-01, time/batch = 14.9799s	
13665/22300 (epoch 30.639), train_loss = 0.60563617, grad/param norm = 3.0367e-01, time/batch = 18.2884s	
13666/22300 (epoch 30.641), train_loss = 0.48561983, grad/param norm = 2.6456e-01, time/batch = 15.1350s	
13667/22300 (epoch 30.643), train_loss = 0.38032260, grad/param norm = 2.4847e-01, time/batch = 17.0601s	
13668/22300 (epoch 30.646), train_loss = 0.37264721, grad/param norm = 2.8511e-01, time/batch = 14.7301s	
13669/22300 (epoch 30.648), train_loss = 0.47018305, grad/param norm = 2.2740e-01, time/batch = 15.7159s	
13670/22300 (epoch 30.650), train_loss = 0.48688765, grad/param norm = 2.6058e-01, time/batch = 16.1334s	
13671/22300 (epoch 30.652), train_loss = 0.40472819, grad/param norm = 2.4830e-01, time/batch = 16.3564s	
13672/22300 (epoch 30.655), train_loss = 0.36554354, grad/param norm = 2.5681e-01, time/batch = 17.0471s	
13673/22300 (epoch 30.657), train_loss = 0.42400783, grad/param norm = 2.6080e-01, time/batch = 17.0377s	
13674/22300 (epoch 30.659), train_loss = 0.39526393, grad/param norm = 2.4654e-01, time/batch = 14.9400s	
13675/22300 (epoch 30.661), train_loss = 0.33151369, grad/param norm = 2.2083e-01, time/batch = 17.9410s	
13676/22300 (epoch 30.664), train_loss = 0.36487692, grad/param norm = 2.0850e-01, time/batch = 15.5550s	
13677/22300 (epoch 30.666), train_loss = 0.47954178, grad/param norm = 2.5225e-01, time/batch = 15.4415s	
13678/22300 (epoch 30.668), train_loss = 0.36435044, grad/param norm = 2.2623e-01, time/batch = 15.3042s	
13679/22300 (epoch 30.670), train_loss = 0.47005071, grad/param norm = 2.6029e-01, time/batch = 16.2265s	
13680/22300 (epoch 30.673), train_loss = 0.56557070, grad/param norm = 3.1725e-01, time/batch = 15.4937s	
13681/22300 (epoch 30.675), train_loss = 0.62575394, grad/param norm = 3.8049e-01, time/batch = 15.3560s	
13682/22300 (epoch 30.677), train_loss = 0.65932724, grad/param norm = 3.3262e-01, time/batch = 17.5413s	
13683/22300 (epoch 30.679), train_loss = 0.49555952, grad/param norm = 3.0098e-01, time/batch = 16.0473s	
13684/22300 (epoch 30.682), train_loss = 0.44514493, grad/param norm = 2.3601e-01, time/batch = 17.3709s	
13685/22300 (epoch 30.684), train_loss = 0.42548981, grad/param norm = 2.7336e-01, time/batch = 15.8923s	
13686/22300 (epoch 30.686), train_loss = 0.43609320, grad/param norm = 2.4391e-01, time/batch = 17.8885s	
13687/22300 (epoch 30.688), train_loss = 0.40255610, grad/param norm = 3.1804e-01, time/batch = 15.9614s	
13688/22300 (epoch 30.691), train_loss = 0.37926748, grad/param norm = 3.0135e-01, time/batch = 15.5579s	
13689/22300 (epoch 30.693), train_loss = 0.36534304, grad/param norm = 2.3989e-01, time/batch = 17.0400s	
13690/22300 (epoch 30.695), train_loss = 0.36078388, grad/param norm = 2.0386e-01, time/batch = 15.7380s	
13691/22300 (epoch 30.697), train_loss = 0.38753852, grad/param norm = 2.2571e-01, time/batch = 17.2176s	
13692/22300 (epoch 30.700), train_loss = 0.36116450, grad/param norm = 2.1696e-01, time/batch = 15.7512s	
13693/22300 (epoch 30.702), train_loss = 0.30141467, grad/param norm = 1.7740e-01, time/batch = 16.7902s	
13694/22300 (epoch 30.704), train_loss = 0.44806964, grad/param norm = 3.1915e-01, time/batch = 16.3924s	
13695/22300 (epoch 30.706), train_loss = 0.35973408, grad/param norm = 2.2119e-01, time/batch = 14.6482s	
13696/22300 (epoch 30.709), train_loss = 0.31085756, grad/param norm = 1.9695e-01, time/batch = 14.6332s	
13697/22300 (epoch 30.711), train_loss = 0.29734402, grad/param norm = 1.7533e-01, time/batch = 15.5434s	
13698/22300 (epoch 30.713), train_loss = 0.44838939, grad/param norm = 2.7449e-01, time/batch = 16.2449s	
13699/22300 (epoch 30.715), train_loss = 0.42558740, grad/param norm = 2.6287e-01, time/batch = 17.6768s	
13700/22300 (epoch 30.717), train_loss = 0.60696000, grad/param norm = 2.8429e-01, time/batch = 15.0534s	
13701/22300 (epoch 30.720), train_loss = 0.39024735, grad/param norm = 2.4388e-01, time/batch = 15.7118s	
13702/22300 (epoch 30.722), train_loss = 0.44686520, grad/param norm = 2.4723e-01, time/batch = 15.5837s	
13703/22300 (epoch 30.724), train_loss = 0.50850902, grad/param norm = 3.4421e-01, time/batch = 15.6506s	
13704/22300 (epoch 30.726), train_loss = 0.39325203, grad/param norm = 2.5874e-01, time/batch = 15.6426s	
13705/22300 (epoch 30.729), train_loss = 0.45368993, grad/param norm = 2.8531e-01, time/batch = 16.9713s	
13706/22300 (epoch 30.731), train_loss = 0.57862190, grad/param norm = 3.0190e-01, time/batch = 17.3912s	
13707/22300 (epoch 30.733), train_loss = 0.56010421, grad/param norm = 3.2699e-01, time/batch = 15.3190s	
13708/22300 (epoch 30.735), train_loss = 0.60647813, grad/param norm = 3.3074e-01, time/batch = 17.1409s	
13709/22300 (epoch 30.738), train_loss = 0.45644999, grad/param norm = 3.0825e-01, time/batch = 16.7229s	
13710/22300 (epoch 30.740), train_loss = 0.41167920, grad/param norm = 2.4584e-01, time/batch = 15.1030s	
13711/22300 (epoch 30.742), train_loss = 0.38140658, grad/param norm = 2.4872e-01, time/batch = 16.7048s	
13712/22300 (epoch 30.744), train_loss = 0.66041271, grad/param norm = 2.9258e-01, time/batch = 16.7228s	
13713/22300 (epoch 30.747), train_loss = 0.51086016, grad/param norm = 2.7463e-01, time/batch = 15.7769s	
13714/22300 (epoch 30.749), train_loss = 0.66866962, grad/param norm = 5.2572e-01, time/batch = 15.4550s	
13715/22300 (epoch 30.751), train_loss = 0.61709642, grad/param norm = 4.7557e-01, time/batch = 17.3941s	
13716/22300 (epoch 30.753), train_loss = 0.64869913, grad/param norm = 3.2782e-01, time/batch = 17.0622s	
13717/22300 (epoch 30.756), train_loss = 0.54358680, grad/param norm = 2.8935e-01, time/batch = 17.7103s	
13718/22300 (epoch 30.758), train_loss = 0.46996532, grad/param norm = 2.7356e-01, time/batch = 15.7724s	
13719/22300 (epoch 30.760), train_loss = 0.50945880, grad/param norm = 2.7826e-01, time/batch = 16.2225s	
13720/22300 (epoch 30.762), train_loss = 0.52191727, grad/param norm = 2.9887e-01, time/batch = 15.4533s	
13721/22300 (epoch 30.765), train_loss = 0.49800055, grad/param norm = 2.9181e-01, time/batch = 15.9681s	
13722/22300 (epoch 30.767), train_loss = 0.51969566, grad/param norm = 2.7421e-01, time/batch = 16.5427s	
13723/22300 (epoch 30.769), train_loss = 0.47350737, grad/param norm = 2.6564e-01, time/batch = 18.0505s	
13724/22300 (epoch 30.771), train_loss = 0.54238823, grad/param norm = 3.1898e-01, time/batch = 16.3210s	
13725/22300 (epoch 30.774), train_loss = 0.58018164, grad/param norm = 3.3442e-01, time/batch = 15.3149s	
13726/22300 (epoch 30.776), train_loss = 0.61892174, grad/param norm = 2.9731e-01, time/batch = 17.7961s	
13727/22300 (epoch 30.778), train_loss = 0.58913343, grad/param norm = 3.2153e-01, time/batch = 18.1364s	
13728/22300 (epoch 30.780), train_loss = 0.58041579, grad/param norm = 2.7272e-01, time/batch = 15.7064s	
13729/22300 (epoch 30.783), train_loss = 0.60808804, grad/param norm = 3.3427e-01, time/batch = 16.3707s	
13730/22300 (epoch 30.785), train_loss = 0.44419698, grad/param norm = 2.8986e-01, time/batch = 15.3179s	
13731/22300 (epoch 30.787), train_loss = 0.44509418, grad/param norm = 2.5927e-01, time/batch = 17.8919s	
13732/22300 (epoch 30.789), train_loss = 0.66221489, grad/param norm = 3.6129e-01, time/batch = 15.8026s	
13733/22300 (epoch 30.791), train_loss = 0.81544222, grad/param norm = 3.9079e-01, time/batch = 17.2123s	
13734/22300 (epoch 30.794), train_loss = 0.59459702, grad/param norm = 2.9325e-01, time/batch = 14.6719s	
13735/22300 (epoch 30.796), train_loss = 0.57144418, grad/param norm = 2.9816e-01, time/batch = 17.2864s	
13736/22300 (epoch 30.798), train_loss = 0.72700217, grad/param norm = 3.1322e-01, time/batch = 15.6053s	
13737/22300 (epoch 30.800), train_loss = 0.49910491, grad/param norm = 2.7427e-01, time/batch = 16.4055s	
13738/22300 (epoch 30.803), train_loss = 0.45512801, grad/param norm = 2.3899e-01, time/batch = 16.2298s	
13739/22300 (epoch 30.805), train_loss = 0.50753875, grad/param norm = 2.7920e-01, time/batch = 17.0469s	
13740/22300 (epoch 30.807), train_loss = 0.65815842, grad/param norm = 3.1719e-01, time/batch = 16.3063s	
13741/22300 (epoch 30.809), train_loss = 0.47210450, grad/param norm = 2.9349e-01, time/batch = 17.2324s	
13742/22300 (epoch 30.812), train_loss = 0.54763712, grad/param norm = 3.4329e-01, time/batch = 16.4062s	
13743/22300 (epoch 30.814), train_loss = 0.54151900, grad/param norm = 3.3202e-01, time/batch = 15.1230s	
13744/22300 (epoch 30.816), train_loss = 0.54507938, grad/param norm = 2.8762e-01, time/batch = 17.3584s	
13745/22300 (epoch 30.818), train_loss = 0.64443961, grad/param norm = 3.4024e-01, time/batch = 16.9708s	
13746/22300 (epoch 30.821), train_loss = 0.55685785, grad/param norm = 2.9668e-01, time/batch = 16.8439s	
13747/22300 (epoch 30.823), train_loss = 0.35522298, grad/param norm = 2.2158e-01, time/batch = 16.4855s	
13748/22300 (epoch 30.825), train_loss = 0.38850621, grad/param norm = 2.4234e-01, time/batch = 16.8807s	
13749/22300 (epoch 30.827), train_loss = 0.45816179, grad/param norm = 3.0035e-01, time/batch = 16.5526s	
13750/22300 (epoch 30.830), train_loss = 0.45149520, grad/param norm = 2.5203e-01, time/batch = 16.4687s	
13751/22300 (epoch 30.832), train_loss = 0.42856238, grad/param norm = 2.7560e-01, time/batch = 15.5670s	
13752/22300 (epoch 30.834), train_loss = 0.36727314, grad/param norm = 2.4352e-01, time/batch = 17.9663s	
13753/22300 (epoch 30.836), train_loss = 0.46019503, grad/param norm = 2.8336e-01, time/batch = 17.7129s	
13754/22300 (epoch 30.839), train_loss = 0.44367810, grad/param norm = 2.7336e-01, time/batch = 16.3678s	
13755/22300 (epoch 30.841), train_loss = 0.47728487, grad/param norm = 3.2267e-01, time/batch = 17.9751s	
13756/22300 (epoch 30.843), train_loss = 0.45772615, grad/param norm = 2.4663e-01, time/batch = 14.9644s	
13757/22300 (epoch 30.845), train_loss = 0.42985317, grad/param norm = 2.3031e-01, time/batch = 15.3860s	
13758/22300 (epoch 30.848), train_loss = 0.43270711, grad/param norm = 2.6073e-01, time/batch = 16.5691s	
13759/22300 (epoch 30.850), train_loss = 0.47444695, grad/param norm = 2.6362e-01, time/batch = 16.5574s	
13760/22300 (epoch 30.852), train_loss = 0.42299864, grad/param norm = 2.4500e-01, time/batch = 16.3744s	
13761/22300 (epoch 30.854), train_loss = 0.67867213, grad/param norm = 3.4205e-01, time/batch = 15.2858s	
13762/22300 (epoch 30.857), train_loss = 0.52148574, grad/param norm = 3.0142e-01, time/batch = 18.8685s	
13763/22300 (epoch 30.859), train_loss = 0.41412381, grad/param norm = 2.4927e-01, time/batch = 16.5620s	
13764/22300 (epoch 30.861), train_loss = 0.55080308, grad/param norm = 2.7522e-01, time/batch = 17.0500s	
13765/22300 (epoch 30.863), train_loss = 0.36597691, grad/param norm = 2.2979e-01, time/batch = 15.7113s	
13766/22300 (epoch 30.865), train_loss = 0.35926755, grad/param norm = 2.2172e-01, time/batch = 16.8082s	
13767/22300 (epoch 30.868), train_loss = 0.48708205, grad/param norm = 2.2580e-01, time/batch = 16.8055s	
13768/22300 (epoch 30.870), train_loss = 0.50628358, grad/param norm = 2.9274e-01, time/batch = 16.5353s	
13769/22300 (epoch 30.872), train_loss = 0.56504435, grad/param norm = 2.7135e-01, time/batch = 16.8016s	
13770/22300 (epoch 30.874), train_loss = 0.50847264, grad/param norm = 3.4270e-01, time/batch = 17.2283s	
13771/22300 (epoch 30.877), train_loss = 0.51072943, grad/param norm = 2.9764e-01, time/batch = 18.4511s	
13772/22300 (epoch 30.879), train_loss = 0.42102769, grad/param norm = 2.2833e-01, time/batch = 16.3789s	
13773/22300 (epoch 30.881), train_loss = 0.38219729, grad/param norm = 2.4356e-01, time/batch = 16.1427s	
13774/22300 (epoch 30.883), train_loss = 0.39887789, grad/param norm = 3.1213e-01, time/batch = 15.2203s	
13775/22300 (epoch 30.886), train_loss = 0.38205276, grad/param norm = 2.4465e-01, time/batch = 17.3843s	
13776/22300 (epoch 30.888), train_loss = 0.45000773, grad/param norm = 2.6165e-01, time/batch = 15.4036s	
13777/22300 (epoch 30.890), train_loss = 0.41843457, grad/param norm = 2.1980e-01, time/batch = 18.7138s	
13778/22300 (epoch 30.892), train_loss = 0.63908157, grad/param norm = 3.4613e-01, time/batch = 17.1237s	
13779/22300 (epoch 30.895), train_loss = 0.59230061, grad/param norm = 3.3690e-01, time/batch = 15.4462s	
13780/22300 (epoch 30.897), train_loss = 0.48030869, grad/param norm = 3.2196e-01, time/batch = 15.3291s	
13781/22300 (epoch 30.899), train_loss = 0.46358830, grad/param norm = 2.5341e-01, time/batch = 15.6039s	
13782/22300 (epoch 30.901), train_loss = 0.51608896, grad/param norm = 2.8163e-01, time/batch = 17.1230s	
13783/22300 (epoch 30.904), train_loss = 0.55287385, grad/param norm = 2.8616e-01, time/batch = 15.4299s	
13784/22300 (epoch 30.906), train_loss = 0.51322564, grad/param norm = 2.8823e-01, time/batch = 16.0772s	
13785/22300 (epoch 30.908), train_loss = 0.44194219, grad/param norm = 2.1301e-01, time/batch = 17.3898s	
13786/22300 (epoch 30.910), train_loss = 0.39131178, grad/param norm = 2.1983e-01, time/batch = 16.7081s	
13787/22300 (epoch 30.913), train_loss = 0.54531211, grad/param norm = 2.9359e-01, time/batch = 16.8022s	
13788/22300 (epoch 30.915), train_loss = 0.63585854, grad/param norm = 3.1176e-01, time/batch = 17.1317s	
13789/22300 (epoch 30.917), train_loss = 0.54268512, grad/param norm = 3.2827e-01, time/batch = 16.8739s	
13790/22300 (epoch 30.919), train_loss = 0.51453160, grad/param norm = 2.3525e-01, time/batch = 15.5423s	
13791/22300 (epoch 30.922), train_loss = 0.50416251, grad/param norm = 3.2104e-01, time/batch = 16.5727s	
13792/22300 (epoch 30.924), train_loss = 0.31179247, grad/param norm = 2.1366e-01, time/batch = 16.4829s	
13793/22300 (epoch 30.926), train_loss = 0.38366084, grad/param norm = 2.0121e-01, time/batch = 16.3029s	
13794/22300 (epoch 30.928), train_loss = 0.43736584, grad/param norm = 2.9472e-01, time/batch = 17.2192s	
13795/22300 (epoch 30.930), train_loss = 0.42522502, grad/param norm = 2.5196e-01, time/batch = 15.4647s	
13796/22300 (epoch 30.933), train_loss = 0.51209103, grad/param norm = 2.5658e-01, time/batch = 17.8807s	
13797/22300 (epoch 30.935), train_loss = 0.51052058, grad/param norm = 3.7169e-01, time/batch = 15.3203s	
13798/22300 (epoch 30.937), train_loss = 0.60888344, grad/param norm = 3.9537e-01, time/batch = 16.5300s	
13799/22300 (epoch 30.939), train_loss = 0.54881745, grad/param norm = 3.1310e-01, time/batch = 17.4816s	
13800/22300 (epoch 30.942), train_loss = 0.67566098, grad/param norm = 3.7087e-01, time/batch = 16.3032s	
13801/22300 (epoch 30.944), train_loss = 0.71893541, grad/param norm = 4.2268e-01, time/batch = 15.5993s	
13802/22300 (epoch 30.946), train_loss = 0.50440265, grad/param norm = 2.7161e-01, time/batch = 16.7976s	
13803/22300 (epoch 30.948), train_loss = 0.42335043, grad/param norm = 2.2962e-01, time/batch = 15.7335s	
13804/22300 (epoch 30.951), train_loss = 0.35526368, grad/param norm = 2.4095e-01, time/batch = 15.3135s	
13805/22300 (epoch 30.953), train_loss = 0.42880334, grad/param norm = 3.2836e-01, time/batch = 15.1434s	
13806/22300 (epoch 30.955), train_loss = 0.59756146, grad/param norm = 2.6401e-01, time/batch = 16.2268s	
13807/22300 (epoch 30.957), train_loss = 0.69842563, grad/param norm = 2.8970e-01, time/batch = 17.2266s	
13808/22300 (epoch 30.960), train_loss = 0.61955698, grad/param norm = 3.2577e-01, time/batch = 15.7108s	
13809/22300 (epoch 30.962), train_loss = 0.39731914, grad/param norm = 2.5518e-01, time/batch = 17.2047s	
13810/22300 (epoch 30.964), train_loss = 0.44258936, grad/param norm = 2.7354e-01, time/batch = 15.5723s	
13811/22300 (epoch 30.966), train_loss = 0.39428487, grad/param norm = 2.2450e-01, time/batch = 15.3254s	
13812/22300 (epoch 30.969), train_loss = 0.45264337, grad/param norm = 2.4712e-01, time/batch = 15.5446s	
13813/22300 (epoch 30.971), train_loss = 0.49824985, grad/param norm = 3.0956e-01, time/batch = 17.3157s	
13814/22300 (epoch 30.973), train_loss = 0.46312463, grad/param norm = 2.4974e-01, time/batch = 16.6454s	
13815/22300 (epoch 30.975), train_loss = 0.64807020, grad/param norm = 3.7654e-01, time/batch = 16.8805s	
13816/22300 (epoch 30.978), train_loss = 0.60036830, grad/param norm = 2.9138e-01, time/batch = 17.2020s	
13817/22300 (epoch 30.980), train_loss = 0.66462493, grad/param norm = 3.4087e-01, time/batch = 14.7979s	
13818/22300 (epoch 30.982), train_loss = 0.37799516, grad/param norm = 2.8420e-01, time/batch = 18.7124s	
13819/22300 (epoch 30.984), train_loss = 0.47169993, grad/param norm = 2.3048e-01, time/batch = 15.7809s	
13820/22300 (epoch 30.987), train_loss = 0.45494050, grad/param norm = 2.8590e-01, time/batch = 16.4336s	
13821/22300 (epoch 30.989), train_loss = 0.38524677, grad/param norm = 2.4811e-01, time/batch = 15.7139s	
13822/22300 (epoch 30.991), train_loss = 0.67714736, grad/param norm = 3.3518e-01, time/batch = 18.0335s	
13823/22300 (epoch 30.993), train_loss = 0.88648220, grad/param norm = 3.6306e-01, time/batch = 16.0680s	
13824/22300 (epoch 30.996), train_loss = 0.83504783, grad/param norm = 3.9340e-01, time/batch = 18.6280s	
13825/22300 (epoch 30.998), train_loss = 0.51425899, grad/param norm = 2.7574e-01, time/batch = 16.8146s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
13826/22300 (epoch 31.000), train_loss = 0.41897599, grad/param norm = 2.8180e-01, time/batch = 16.4548s	
13827/22300 (epoch 31.002), train_loss = 0.76574905, grad/param norm = 2.8778e-01, time/batch = 16.2088s	
13828/22300 (epoch 31.004), train_loss = 0.52013305, grad/param norm = 2.3054e-01, time/batch = 15.1108s	
13829/22300 (epoch 31.007), train_loss = 0.55722915, grad/param norm = 3.1959e-01, time/batch = 17.4686s	
13830/22300 (epoch 31.009), train_loss = 0.58333461, grad/param norm = 3.3428e-01, time/batch = 15.5374s	
13831/22300 (epoch 31.011), train_loss = 0.73170590, grad/param norm = 3.5883e-01, time/batch = 15.5824s	
13832/22300 (epoch 31.013), train_loss = 0.53995393, grad/param norm = 2.7210e-01, time/batch = 17.8757s	
13833/22300 (epoch 31.016), train_loss = 0.44181997, grad/param norm = 3.1436e-01, time/batch = 16.8848s	
13834/22300 (epoch 31.018), train_loss = 0.50896869, grad/param norm = 3.3369e-01, time/batch = 16.1471s	
13835/22300 (epoch 31.020), train_loss = 0.46787608, grad/param norm = 2.9467e-01, time/batch = 15.9827s	
13836/22300 (epoch 31.022), train_loss = 0.41378427, grad/param norm = 3.2200e-01, time/batch = 18.0491s	
13837/22300 (epoch 31.025), train_loss = 0.42007003, grad/param norm = 2.5436e-01, time/batch = 15.4499s	
13838/22300 (epoch 31.027), train_loss = 0.39622737, grad/param norm = 2.0599e-01, time/batch = 17.2868s	
13839/22300 (epoch 31.029), train_loss = 0.44695999, grad/param norm = 2.4941e-01, time/batch = 15.1321s	
13840/22300 (epoch 31.031), train_loss = 0.42160511, grad/param norm = 2.1737e-01, time/batch = 15.6119s	
13841/22300 (epoch 31.034), train_loss = 0.41258557, grad/param norm = 2.5191e-01, time/batch = 15.9674s	
13842/22300 (epoch 31.036), train_loss = 0.37236317, grad/param norm = 2.2143e-01, time/batch = 16.6474s	
13843/22300 (epoch 31.038), train_loss = 0.38158151, grad/param norm = 2.5199e-01, time/batch = 16.2936s	
13844/22300 (epoch 31.040), train_loss = 0.43982962, grad/param norm = 3.7391e-01, time/batch = 18.0213s	
13845/22300 (epoch 31.043), train_loss = 0.68144840, grad/param norm = 3.3513e-01, time/batch = 18.3641s	
13846/22300 (epoch 31.045), train_loss = 0.57697696, grad/param norm = 2.8582e-01, time/batch = 16.1379s	
13847/22300 (epoch 31.047), train_loss = 0.60109471, grad/param norm = 3.0971e-01, time/batch = 17.1382s	
13848/22300 (epoch 31.049), train_loss = 0.46072324, grad/param norm = 2.6535e-01, time/batch = 15.0361s	
13849/22300 (epoch 31.052), train_loss = 0.55018820, grad/param norm = 3.2550e-01, time/batch = 18.0431s	
13850/22300 (epoch 31.054), train_loss = 0.52548231, grad/param norm = 2.6742e-01, time/batch = 16.8269s	
13851/22300 (epoch 31.056), train_loss = 0.27863303, grad/param norm = 1.8474e-01, time/batch = 16.8808s	
13852/22300 (epoch 31.058), train_loss = 0.44192548, grad/param norm = 2.4827e-01, time/batch = 16.0433s	
13853/22300 (epoch 31.061), train_loss = 0.41052398, grad/param norm = 2.7915e-01, time/batch = 17.0306s	
13854/22300 (epoch 31.063), train_loss = 0.62443364, grad/param norm = 4.6984e-01, time/batch = 16.3155s	
13855/22300 (epoch 31.065), train_loss = 0.67457563, grad/param norm = 3.8407e-01, time/batch = 15.4406s	
13856/22300 (epoch 31.067), train_loss = 0.43256517, grad/param norm = 2.5962e-01, time/batch = 16.8191s	
13857/22300 (epoch 31.070), train_loss = 0.47082125, grad/param norm = 2.5813e-01, time/batch = 15.8131s	
13858/22300 (epoch 31.072), train_loss = 0.55944920, grad/param norm = 3.5613e-01, time/batch = 16.9710s	
13859/22300 (epoch 31.074), train_loss = 0.54629168, grad/param norm = 3.2516e-01, time/batch = 16.7256s	
13860/22300 (epoch 31.076), train_loss = 0.51601097, grad/param norm = 3.2207e-01, time/batch = 17.7901s	
13861/22300 (epoch 31.078), train_loss = 0.63878332, grad/param norm = 3.5149e-01, time/batch = 15.9779s	
13862/22300 (epoch 31.081), train_loss = 0.62547639, grad/param norm = 3.3247e-01, time/batch = 26.4879s	
13863/22300 (epoch 31.083), train_loss = 0.70453595, grad/param norm = 3.5703e-01, time/batch = 19.7594s	
13864/22300 (epoch 31.085), train_loss = 0.68460656, grad/param norm = 3.3254e-01, time/batch = 17.4581s	
13865/22300 (epoch 31.087), train_loss = 0.54936140, grad/param norm = 2.5851e-01, time/batch = 16.0324s	
13866/22300 (epoch 31.090), train_loss = 0.50679574, grad/param norm = 2.8477e-01, time/batch = 17.0555s	
13867/22300 (epoch 31.092), train_loss = 0.40516308, grad/param norm = 2.4383e-01, time/batch = 18.2891s	
13868/22300 (epoch 31.094), train_loss = 0.38440579, grad/param norm = 2.6974e-01, time/batch = 16.9537s	
13869/22300 (epoch 31.096), train_loss = 0.67194217, grad/param norm = 3.9142e-01, time/batch = 17.9611s	
13870/22300 (epoch 31.099), train_loss = 0.42188222, grad/param norm = 2.3017e-01, time/batch = 16.8064s	
13871/22300 (epoch 31.101), train_loss = 0.59634871, grad/param norm = 4.1928e-01, time/batch = 15.9638s	
13872/22300 (epoch 31.103), train_loss = 0.49811196, grad/param norm = 2.5952e-01, time/batch = 15.2083s	
13873/22300 (epoch 31.105), train_loss = 0.39258252, grad/param norm = 3.0480e-01, time/batch = 15.9554s	
13874/22300 (epoch 31.108), train_loss = 0.53323696, grad/param norm = 2.7293e-01, time/batch = 15.9756s	
13875/22300 (epoch 31.110), train_loss = 0.58343464, grad/param norm = 2.8517e-01, time/batch = 15.7212s	
13876/22300 (epoch 31.112), train_loss = 0.52455583, grad/param norm = 2.5473e-01, time/batch = 16.1145s	
13877/22300 (epoch 31.114), train_loss = 0.57331659, grad/param norm = 2.7628e-01, time/batch = 15.3997s	
13878/22300 (epoch 31.117), train_loss = 0.66909053, grad/param norm = 2.9463e-01, time/batch = 18.7910s	
13879/22300 (epoch 31.119), train_loss = 0.60680057, grad/param norm = 3.2980e-01, time/batch = 17.7166s	
13880/22300 (epoch 31.121), train_loss = 0.67818712, grad/param norm = 3.0202e-01, time/batch = 17.3877s	
13881/22300 (epoch 31.123), train_loss = 0.68683527, grad/param norm = 3.1518e-01, time/batch = 15.2999s	
13882/22300 (epoch 31.126), train_loss = 0.55070173, grad/param norm = 2.9899e-01, time/batch = 17.8104s	
13883/22300 (epoch 31.128), train_loss = 0.53594580, grad/param norm = 3.1315e-01, time/batch = 16.5338s	
13884/22300 (epoch 31.130), train_loss = 0.44479757, grad/param norm = 2.3220e-01, time/batch = 16.8925s	
13885/22300 (epoch 31.132), train_loss = 0.36393142, grad/param norm = 2.3462e-01, time/batch = 16.8121s	
13886/22300 (epoch 31.135), train_loss = 0.38018075, grad/param norm = 2.7691e-01, time/batch = 16.9727s	
13887/22300 (epoch 31.137), train_loss = 0.29910649, grad/param norm = 2.0222e-01, time/batch = 17.6234s	
13888/22300 (epoch 31.139), train_loss = 0.47819640, grad/param norm = 3.0576e-01, time/batch = 17.7941s	
13889/22300 (epoch 31.141), train_loss = 0.58088514, grad/param norm = 2.6794e-01, time/batch = 16.3955s	
13890/22300 (epoch 31.143), train_loss = 0.50836703, grad/param norm = 2.8357e-01, time/batch = 16.0228s	
13891/22300 (epoch 31.146), train_loss = 0.59459867, grad/param norm = 3.1240e-01, time/batch = 17.2794s	
13892/22300 (epoch 31.148), train_loss = 0.41240513, grad/param norm = 3.2926e-01, time/batch = 17.6251s	
13893/22300 (epoch 31.150), train_loss = 0.45394660, grad/param norm = 2.8082e-01, time/batch = 15.8029s	
13894/22300 (epoch 31.152), train_loss = 0.38832028, grad/param norm = 2.8575e-01, time/batch = 16.5295s	
13895/22300 (epoch 31.155), train_loss = 0.39154173, grad/param norm = 2.2790e-01, time/batch = 16.7442s	
13896/22300 (epoch 31.157), train_loss = 0.55766676, grad/param norm = 3.8540e-01, time/batch = 17.6223s	
13897/22300 (epoch 31.159), train_loss = 0.56556690, grad/param norm = 3.0277e-01, time/batch = 15.8599s	
13898/22300 (epoch 31.161), train_loss = 0.56265379, grad/param norm = 3.1756e-01, time/batch = 15.8817s	
13899/22300 (epoch 31.164), train_loss = 0.40837771, grad/param norm = 2.2897e-01, time/batch = 15.1938s	
13900/22300 (epoch 31.166), train_loss = 0.37245878, grad/param norm = 1.9833e-01, time/batch = 17.2883s	
13901/22300 (epoch 31.168), train_loss = 0.38577400, grad/param norm = 2.8765e-01, time/batch = 15.1478s	
13902/22300 (epoch 31.170), train_loss = 0.51712461, grad/param norm = 3.0229e-01, time/batch = 16.0293s	
13903/22300 (epoch 31.173), train_loss = 0.58628621, grad/param norm = 2.9805e-01, time/batch = 17.1449s	
13904/22300 (epoch 31.175), train_loss = 0.49650638, grad/param norm = 3.7520e-01, time/batch = 16.3719s	
13905/22300 (epoch 31.177), train_loss = 0.34728257, grad/param norm = 2.1070e-01, time/batch = 16.7262s	
13906/22300 (epoch 31.179), train_loss = 0.47172644, grad/param norm = 2.3488e-01, time/batch = 16.8087s	
13907/22300 (epoch 31.182), train_loss = 0.67522518, grad/param norm = 3.3349e-01, time/batch = 17.3958s	
13908/22300 (epoch 31.184), train_loss = 0.71972367, grad/param norm = 3.4679e-01, time/batch = 15.8552s	
13909/22300 (epoch 31.186), train_loss = 0.53218459, grad/param norm = 3.0982e-01, time/batch = 15.9056s	
13910/22300 (epoch 31.188), train_loss = 0.73269895, grad/param norm = 3.5100e-01, time/batch = 16.0665s	
13911/22300 (epoch 31.191), train_loss = 0.61293599, grad/param norm = 3.5240e-01, time/batch = 17.3731s	
13912/22300 (epoch 31.193), train_loss = 0.55776847, grad/param norm = 4.5138e-01, time/batch = 15.7238s	
13913/22300 (epoch 31.195), train_loss = 0.50996162, grad/param norm = 2.6315e-01, time/batch = 17.8845s	
13914/22300 (epoch 31.197), train_loss = 0.46756247, grad/param norm = 2.8963e-01, time/batch = 16.8900s	
13915/22300 (epoch 31.200), train_loss = 0.39946228, grad/param norm = 2.9257e-01, time/batch = 16.6368s	
13916/22300 (epoch 31.202), train_loss = 0.42795778, grad/param norm = 2.7580e-01, time/batch = 15.4740s	
13917/22300 (epoch 31.204), train_loss = 0.49574430, grad/param norm = 2.6887e-01, time/batch = 15.3076s	
13918/22300 (epoch 31.206), train_loss = 0.41329976, grad/param norm = 2.6506e-01, time/batch = 15.0431s	
13919/22300 (epoch 31.209), train_loss = 0.45933143, grad/param norm = 2.6978e-01, time/batch = 14.9067s	
13920/22300 (epoch 31.211), train_loss = 0.36176990, grad/param norm = 2.5176e-01, time/batch = 16.5669s	
13921/22300 (epoch 31.213), train_loss = 0.49270925, grad/param norm = 2.7630e-01, time/batch = 15.4651s	
13922/22300 (epoch 31.215), train_loss = 0.64938547, grad/param norm = 3.4876e-01, time/batch = 16.8096s	
13923/22300 (epoch 31.217), train_loss = 0.66061196, grad/param norm = 3.2045e-01, time/batch = 16.6246s	
13924/22300 (epoch 31.220), train_loss = 0.44232543, grad/param norm = 2.1398e-01, time/batch = 15.2082s	
13925/22300 (epoch 31.222), train_loss = 0.42195850, grad/param norm = 2.4222e-01, time/batch = 16.8036s	
13926/22300 (epoch 31.224), train_loss = 0.44102610, grad/param norm = 2.6789e-01, time/batch = 16.2147s	
13927/22300 (epoch 31.226), train_loss = 0.47241434, grad/param norm = 2.5653e-01, time/batch = 15.5525s	
13928/22300 (epoch 31.229), train_loss = 0.38631371, grad/param norm = 2.5785e-01, time/batch = 14.6584s	
13929/22300 (epoch 31.231), train_loss = 0.58654638, grad/param norm = 2.7512e-01, time/batch = 16.1486s	
13930/22300 (epoch 31.233), train_loss = 0.48589121, grad/param norm = 2.7257e-01, time/batch = 17.3022s	
13931/22300 (epoch 31.235), train_loss = 0.37121188, grad/param norm = 2.0464e-01, time/batch = 17.6146s	
13932/22300 (epoch 31.238), train_loss = 0.40645466, grad/param norm = 2.3114e-01, time/batch = 17.6208s	
13933/22300 (epoch 31.240), train_loss = 0.40944599, grad/param norm = 2.0156e-01, time/batch = 16.5613s	
13934/22300 (epoch 31.242), train_loss = 0.37345993, grad/param norm = 2.4193e-01, time/batch = 17.0959s	
13935/22300 (epoch 31.244), train_loss = 0.26439339, grad/param norm = 1.7889e-01, time/batch = 16.8046s	
13936/22300 (epoch 31.247), train_loss = 0.37794301, grad/param norm = 2.0391e-01, time/batch = 17.5545s	
13937/22300 (epoch 31.249), train_loss = 0.25563463, grad/param norm = 1.6823e-01, time/batch = 15.8864s	
13938/22300 (epoch 31.251), train_loss = 0.34830517, grad/param norm = 1.9574e-01, time/batch = 16.1406s	
13939/22300 (epoch 31.253), train_loss = 0.25862734, grad/param norm = 2.4161e-01, time/batch = 15.3525s	
13940/22300 (epoch 31.256), train_loss = 0.33345646, grad/param norm = 2.4179e-01, time/batch = 16.9644s	
13941/22300 (epoch 31.258), train_loss = 0.51503493, grad/param norm = 3.0440e-01, time/batch = 15.7908s	
13942/22300 (epoch 31.260), train_loss = 0.51817124, grad/param norm = 2.8861e-01, time/batch = 17.7950s	
13943/22300 (epoch 31.262), train_loss = 0.38336059, grad/param norm = 2.6827e-01, time/batch = 18.3107s	
13944/22300 (epoch 31.265), train_loss = 0.35881073, grad/param norm = 2.7558e-01, time/batch = 14.9840s	
13945/22300 (epoch 31.267), train_loss = 0.37918529, grad/param norm = 2.0340e-01, time/batch = 16.7958s	
13946/22300 (epoch 31.269), train_loss = 0.46130733, grad/param norm = 2.9954e-01, time/batch = 17.6394s	
13947/22300 (epoch 31.271), train_loss = 0.51967636, grad/param norm = 2.7427e-01, time/batch = 16.6309s	
13948/22300 (epoch 31.274), train_loss = 0.36671532, grad/param norm = 2.1488e-01, time/batch = 15.3925s	
13949/22300 (epoch 31.276), train_loss = 0.31323403, grad/param norm = 1.8955e-01, time/batch = 17.7081s	
13950/22300 (epoch 31.278), train_loss = 0.31087234, grad/param norm = 1.8613e-01, time/batch = 15.2779s	
13951/22300 (epoch 31.280), train_loss = 0.37842776, grad/param norm = 2.4671e-01, time/batch = 17.0225s	
13952/22300 (epoch 31.283), train_loss = 0.29382116, grad/param norm = 1.7492e-01, time/batch = 16.2216s	
13953/22300 (epoch 31.285), train_loss = 0.35216589, grad/param norm = 2.9488e-01, time/batch = 16.5291s	
13954/22300 (epoch 31.287), train_loss = 0.46636011, grad/param norm = 2.7819e-01, time/batch = 17.8078s	
13955/22300 (epoch 31.289), train_loss = 0.41372582, grad/param norm = 2.2756e-01, time/batch = 16.0551s	
13956/22300 (epoch 31.291), train_loss = 0.42321775, grad/param norm = 2.6380e-01, time/batch = 17.3192s	
13957/22300 (epoch 31.294), train_loss = 0.32109934, grad/param norm = 1.9119e-01, time/batch = 17.4754s	
13958/22300 (epoch 31.296), train_loss = 0.43029960, grad/param norm = 2.9681e-01, time/batch = 17.4631s	
13959/22300 (epoch 31.298), train_loss = 0.56404799, grad/param norm = 3.4361e-01, time/batch = 15.0282s	
13960/22300 (epoch 31.300), train_loss = 0.58769885, grad/param norm = 3.0000e-01, time/batch = 16.6465s	
13961/22300 (epoch 31.303), train_loss = 0.45778750, grad/param norm = 2.9611e-01, time/batch = 17.8005s	
13962/22300 (epoch 31.305), train_loss = 0.44976644, grad/param norm = 3.2174e-01, time/batch = 14.9539s	
13963/22300 (epoch 31.307), train_loss = 0.41472204, grad/param norm = 3.0582e-01, time/batch = 15.3743s	
13964/22300 (epoch 31.309), train_loss = 0.34169048, grad/param norm = 2.1725e-01, time/batch = 15.4900s	
13965/22300 (epoch 31.312), train_loss = 0.32632972, grad/param norm = 1.8878e-01, time/batch = 17.0622s	
13966/22300 (epoch 31.314), train_loss = 0.37111097, grad/param norm = 2.2964e-01, time/batch = 16.4683s	
13967/22300 (epoch 31.316), train_loss = 0.38116591, grad/param norm = 3.0048e-01, time/batch = 15.6577s	
13968/22300 (epoch 31.318), train_loss = 0.41657863, grad/param norm = 2.7396e-01, time/batch = 15.7482s	
13969/22300 (epoch 31.321), train_loss = 0.49880054, grad/param norm = 2.6736e-01, time/batch = 17.4544s	
13970/22300 (epoch 31.323), train_loss = 0.35201621, grad/param norm = 2.0048e-01, time/batch = 5.8187s	
13971/22300 (epoch 31.325), train_loss = 0.34116296, grad/param norm = 2.5386e-01, time/batch = 0.6638s	
13972/22300 (epoch 31.327), train_loss = 0.34424036, grad/param norm = 2.1585e-01, time/batch = 0.6711s	
13973/22300 (epoch 31.330), train_loss = 0.35690057, grad/param norm = 2.8525e-01, time/batch = 0.6753s	
13974/22300 (epoch 31.332), train_loss = 0.34678482, grad/param norm = 2.2033e-01, time/batch = 0.6625s	
13975/22300 (epoch 31.334), train_loss = 0.38393575, grad/param norm = 2.4708e-01, time/batch = 0.6586s	
13976/22300 (epoch 31.336), train_loss = 0.39539982, grad/param norm = 2.4725e-01, time/batch = 0.6565s	
13977/22300 (epoch 31.339), train_loss = 0.46649256, grad/param norm = 2.9940e-01, time/batch = 0.7041s	
13978/22300 (epoch 31.341), train_loss = 0.49197606, grad/param norm = 2.7470e-01, time/batch = 0.9823s	
13979/22300 (epoch 31.343), train_loss = 0.55860538, grad/param norm = 3.5320e-01, time/batch = 0.9666s	
13980/22300 (epoch 31.345), train_loss = 0.42435115, grad/param norm = 2.5506e-01, time/batch = 0.9694s	
13981/22300 (epoch 31.348), train_loss = 0.41282507, grad/param norm = 2.1492e-01, time/batch = 0.9700s	
13982/22300 (epoch 31.350), train_loss = 0.34248567, grad/param norm = 2.4182e-01, time/batch = 0.9880s	
13983/22300 (epoch 31.352), train_loss = 0.45492133, grad/param norm = 2.6232e-01, time/batch = 1.7800s	
13984/22300 (epoch 31.354), train_loss = 0.65923855, grad/param norm = 3.2469e-01, time/batch = 1.8063s	
13985/22300 (epoch 31.357), train_loss = 0.53684316, grad/param norm = 2.8117e-01, time/batch = 5.2465s	
13986/22300 (epoch 31.359), train_loss = 0.35141243, grad/param norm = 2.3879e-01, time/batch = 14.9961s	
13987/22300 (epoch 31.361), train_loss = 0.38170438, grad/param norm = 3.1256e-01, time/batch = 14.9514s	
13988/22300 (epoch 31.363), train_loss = 0.50565246, grad/param norm = 3.1408e-01, time/batch = 15.8038s	
13989/22300 (epoch 31.365), train_loss = 0.39788440, grad/param norm = 3.1742e-01, time/batch = 15.2059s	
13990/22300 (epoch 31.368), train_loss = 0.42115945, grad/param norm = 2.9959e-01, time/batch = 16.9753s	
13991/22300 (epoch 31.370), train_loss = 0.40378053, grad/param norm = 2.3301e-01, time/batch = 15.9767s	
13992/22300 (epoch 31.372), train_loss = 0.30644128, grad/param norm = 2.1146e-01, time/batch = 15.8793s	
13993/22300 (epoch 31.374), train_loss = 0.29579498, grad/param norm = 2.1179e-01, time/batch = 17.7188s	
13994/22300 (epoch 31.377), train_loss = 0.40786797, grad/param norm = 2.3902e-01, time/batch = 16.6498s	
13995/22300 (epoch 31.379), train_loss = 0.37770213, grad/param norm = 2.8340e-01, time/batch = 17.3732s	
13996/22300 (epoch 31.381), train_loss = 0.51193280, grad/param norm = 2.9378e-01, time/batch = 16.7920s	
13997/22300 (epoch 31.383), train_loss = 0.42214205, grad/param norm = 2.6217e-01, time/batch = 17.3019s	
13998/22300 (epoch 31.386), train_loss = 0.42154558, grad/param norm = 2.3537e-01, time/batch = 16.0946s	
13999/22300 (epoch 31.388), train_loss = 0.35541350, grad/param norm = 3.7387e-01, time/batch = 14.9553s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch31.39_1.6217.t7	
14000/22300 (epoch 31.390), train_loss = 0.37703262, grad/param norm = 2.7890e-01, time/batch = 15.8018s	
14001/22300 (epoch 31.392), train_loss = 1.20826302, grad/param norm = 4.2261e-01, time/batch = 16.2145s	
14002/22300 (epoch 31.395), train_loss = 0.34822465, grad/param norm = 2.1700e-01, time/batch = 17.2952s	
14003/22300 (epoch 31.397), train_loss = 0.22854498, grad/param norm = 1.8811e-01, time/batch = 18.1352s	
14004/22300 (epoch 31.399), train_loss = 0.33666287, grad/param norm = 2.3732e-01, time/batch = 15.3700s	
14005/22300 (epoch 31.401), train_loss = 0.42014843, grad/param norm = 2.8828e-01, time/batch = 17.2177s	
14006/22300 (epoch 31.404), train_loss = 0.40678187, grad/param norm = 2.5170e-01, time/batch = 19.3845s	
14007/22300 (epoch 31.406), train_loss = 0.59092168, grad/param norm = 2.7153e-01, time/batch = 16.7635s	
14008/22300 (epoch 31.408), train_loss = 0.49488523, grad/param norm = 2.6076e-01, time/batch = 16.7881s	
14009/22300 (epoch 31.410), train_loss = 0.50616854, grad/param norm = 2.7688e-01, time/batch = 17.5509s	
14010/22300 (epoch 31.413), train_loss = 0.37563324, grad/param norm = 2.4004e-01, time/batch = 16.1571s	
14011/22300 (epoch 31.415), train_loss = 0.28688692, grad/param norm = 2.1603e-01, time/batch = 16.7914s	
14012/22300 (epoch 31.417), train_loss = 0.45490463, grad/param norm = 2.8953e-01, time/batch = 17.3930s	
14013/22300 (epoch 31.419), train_loss = 0.37958788, grad/param norm = 2.1150e-01, time/batch = 18.0381s	
14014/22300 (epoch 31.422), train_loss = 0.36003572, grad/param norm = 2.8212e-01, time/batch = 15.0054s	
14015/22300 (epoch 31.424), train_loss = 0.45311435, grad/param norm = 2.7542e-01, time/batch = 15.7752s	
14016/22300 (epoch 31.426), train_loss = 0.31703116, grad/param norm = 2.3272e-01, time/batch = 16.2206s	
14017/22300 (epoch 31.428), train_loss = 0.32286669, grad/param norm = 2.0807e-01, time/batch = 18.1848s	
14018/22300 (epoch 31.430), train_loss = 0.38775406, grad/param norm = 2.6847e-01, time/batch = 15.1313s	
14019/22300 (epoch 31.433), train_loss = 0.38939730, grad/param norm = 1.9280e-01, time/batch = 18.3814s	
14020/22300 (epoch 31.435), train_loss = 0.39157219, grad/param norm = 2.8829e-01, time/batch = 17.6412s	
14021/22300 (epoch 31.437), train_loss = 0.45781683, grad/param norm = 2.8773e-01, time/batch = 17.4638s	
14022/22300 (epoch 31.439), train_loss = 0.51205741, grad/param norm = 3.2913e-01, time/batch = 17.5515s	
14023/22300 (epoch 31.442), train_loss = 0.44580240, grad/param norm = 2.6910e-01, time/batch = 17.5594s	
14024/22300 (epoch 31.444), train_loss = 0.36029502, grad/param norm = 2.2258e-01, time/batch = 17.8849s	
14025/22300 (epoch 31.446), train_loss = 0.37846245, grad/param norm = 2.3827e-01, time/batch = 15.3016s	
14026/22300 (epoch 31.448), train_loss = 0.27783934, grad/param norm = 1.9217e-01, time/batch = 16.0543s	
14027/22300 (epoch 31.451), train_loss = 0.46162204, grad/param norm = 2.8605e-01, time/batch = 15.1734s	
14028/22300 (epoch 31.453), train_loss = 0.38179211, grad/param norm = 2.4639e-01, time/batch = 17.2154s	
14029/22300 (epoch 31.455), train_loss = 0.50176060, grad/param norm = 2.6340e-01, time/batch = 17.4454s	
14030/22300 (epoch 31.457), train_loss = 0.60926044, grad/param norm = 3.1886e-01, time/batch = 15.5361s	
14031/22300 (epoch 31.460), train_loss = 0.51505973, grad/param norm = 2.8083e-01, time/batch = 18.6266s	
14032/22300 (epoch 31.462), train_loss = 0.53699658, grad/param norm = 2.8043e-01, time/batch = 16.1200s	
14033/22300 (epoch 31.464), train_loss = 0.47993631, grad/param norm = 3.0554e-01, time/batch = 18.4620s	
14034/22300 (epoch 31.466), train_loss = 0.40888931, grad/param norm = 2.3512e-01, time/batch = 15.8845s	
14035/22300 (epoch 31.469), train_loss = 0.37194046, grad/param norm = 2.1236e-01, time/batch = 16.9747s	
14036/22300 (epoch 31.471), train_loss = 0.50422105, grad/param norm = 2.6614e-01, time/batch = 15.6039s	
14037/22300 (epoch 31.473), train_loss = 0.44908204, grad/param norm = 2.6672e-01, time/batch = 15.4081s	
14038/22300 (epoch 31.475), train_loss = 0.37321151, grad/param norm = 2.8137e-01, time/batch = 17.6362s	
14039/22300 (epoch 31.478), train_loss = 0.37751630, grad/param norm = 2.4126e-01, time/batch = 17.1362s	
14040/22300 (epoch 31.480), train_loss = 0.28233215, grad/param norm = 2.0886e-01, time/batch = 16.7097s	
14041/22300 (epoch 31.482), train_loss = 0.33831132, grad/param norm = 2.3241e-01, time/batch = 15.9063s	
14042/22300 (epoch 31.484), train_loss = 0.43006448, grad/param norm = 2.5010e-01, time/batch = 16.9595s	
14043/22300 (epoch 31.487), train_loss = 0.49104160, grad/param norm = 2.4379e-01, time/batch = 15.1334s	
14044/22300 (epoch 31.489), train_loss = 0.49754945, grad/param norm = 2.6010e-01, time/batch = 17.9754s	
14045/22300 (epoch 31.491), train_loss = 0.50989204, grad/param norm = 3.0251e-01, time/batch = 16.4895s	
14046/22300 (epoch 31.493), train_loss = 0.41292415, grad/param norm = 3.1002e-01, time/batch = 17.0515s	
14047/22300 (epoch 31.496), train_loss = 0.43760136, grad/param norm = 2.4824e-01, time/batch = 17.2917s	
14048/22300 (epoch 31.498), train_loss = 0.31987040, grad/param norm = 2.2377e-01, time/batch = 15.5616s	
14049/22300 (epoch 31.500), train_loss = 0.42949023, grad/param norm = 2.5458e-01, time/batch = 16.3918s	
14050/22300 (epoch 31.502), train_loss = 0.27175434, grad/param norm = 2.1014e-01, time/batch = 15.3896s	
14051/22300 (epoch 31.504), train_loss = 0.28705287, grad/param norm = 1.8207e-01, time/batch = 18.2069s	
14052/22300 (epoch 31.507), train_loss = 0.34457207, grad/param norm = 2.2234e-01, time/batch = 15.8067s	
14053/22300 (epoch 31.509), train_loss = 0.47602652, grad/param norm = 2.8735e-01, time/batch = 15.7190s	
14054/22300 (epoch 31.511), train_loss = 0.27155549, grad/param norm = 1.9735e-01, time/batch = 15.0556s	
14055/22300 (epoch 31.513), train_loss = 0.29881409, grad/param norm = 2.0151e-01, time/batch = 17.5511s	
14056/22300 (epoch 31.516), train_loss = 0.34815816, grad/param norm = 2.2108e-01, time/batch = 15.5626s	
14057/22300 (epoch 31.518), train_loss = 0.45971287, grad/param norm = 2.7179e-01, time/batch = 16.3028s	
14058/22300 (epoch 31.520), train_loss = 0.38720408, grad/param norm = 2.2081e-01, time/batch = 14.9094s	
14059/22300 (epoch 31.522), train_loss = 0.40067408, grad/param norm = 2.2547e-01, time/batch = 16.4090s	
14060/22300 (epoch 31.525), train_loss = 0.32502744, grad/param norm = 2.2703e-01, time/batch = 16.8173s	
14061/22300 (epoch 31.527), train_loss = 0.49239626, grad/param norm = 2.8268e-01, time/batch = 16.7126s	
14062/22300 (epoch 31.529), train_loss = 0.43123283, grad/param norm = 2.5888e-01, time/batch = 17.9494s	
14063/22300 (epoch 31.531), train_loss = 0.37579148, grad/param norm = 2.2157e-01, time/batch = 16.4503s	
14064/22300 (epoch 31.534), train_loss = 0.36814084, grad/param norm = 1.9695e-01, time/batch = 16.1239s	
14065/22300 (epoch 31.536), train_loss = 0.57349013, grad/param norm = 2.4983e-01, time/batch = 16.2911s	
14066/22300 (epoch 31.538), train_loss = 0.73043701, grad/param norm = 3.4383e-01, time/batch = 17.5579s	
14067/22300 (epoch 31.540), train_loss = 0.44887815, grad/param norm = 3.1862e-01, time/batch = 17.3890s	
14068/22300 (epoch 31.543), train_loss = 0.40852469, grad/param norm = 2.6368e-01, time/batch = 17.0158s	
14069/22300 (epoch 31.545), train_loss = 0.28945080, grad/param norm = 2.0421e-01, time/batch = 15.3889s	
14070/22300 (epoch 31.547), train_loss = 0.29141102, grad/param norm = 2.4616e-01, time/batch = 16.0691s	
14071/22300 (epoch 31.549), train_loss = 0.34997536, grad/param norm = 2.4096e-01, time/batch = 16.1942s	
14072/22300 (epoch 31.552), train_loss = 0.33845904, grad/param norm = 2.4392e-01, time/batch = 15.6153s	
14073/22300 (epoch 31.554), train_loss = 0.44719956, grad/param norm = 2.6379e-01, time/batch = 17.5601s	
14074/22300 (epoch 31.556), train_loss = 0.61320433, grad/param norm = 3.8540e-01, time/batch = 17.2273s	
14075/22300 (epoch 31.558), train_loss = 0.45529898, grad/param norm = 2.5548e-01, time/batch = 17.7838s	
14076/22300 (epoch 31.561), train_loss = 0.61256213, grad/param norm = 3.0266e-01, time/batch = 17.5610s	
14077/22300 (epoch 31.563), train_loss = 0.52067259, grad/param norm = 3.2875e-01, time/batch = 16.1394s	
14078/22300 (epoch 31.565), train_loss = 0.39422649, grad/param norm = 2.6566e-01, time/batch = 18.0530s	
14079/22300 (epoch 31.567), train_loss = 0.38734703, grad/param norm = 2.4173e-01, time/batch = 15.3673s	
14080/22300 (epoch 31.570), train_loss = 0.59825760, grad/param norm = 4.0310e-01, time/batch = 15.9685s	
14081/22300 (epoch 31.572), train_loss = 0.53660042, grad/param norm = 2.9226e-01, time/batch = 16.7189s	
14082/22300 (epoch 31.574), train_loss = 0.41349106, grad/param norm = 2.3809e-01, time/batch = 16.1328s	
14083/22300 (epoch 31.576), train_loss = 0.36743523, grad/param norm = 2.1249e-01, time/batch = 15.6374s	
14084/22300 (epoch 31.578), train_loss = 0.22854995, grad/param norm = 1.6386e-01, time/batch = 16.8097s	
14085/22300 (epoch 31.581), train_loss = 0.30906831, grad/param norm = 2.0290e-01, time/batch = 18.2926s	
14086/22300 (epoch 31.583), train_loss = 0.37357129, grad/param norm = 2.1865e-01, time/batch = 24.6704s	
14087/22300 (epoch 31.585), train_loss = 0.50827915, grad/param norm = 3.1730e-01, time/batch = 20.5901s	
14088/22300 (epoch 31.587), train_loss = 0.71990585, grad/param norm = 3.4838e-01, time/batch = 16.4452s	
14089/22300 (epoch 31.590), train_loss = 0.56441168, grad/param norm = 3.7769e-01, time/batch = 15.6890s	
14090/22300 (epoch 31.592), train_loss = 0.67601024, grad/param norm = 3.5589e-01, time/batch = 16.6334s	
14091/22300 (epoch 31.594), train_loss = 0.62332002, grad/param norm = 3.3744e-01, time/batch = 18.0336s	
14092/22300 (epoch 31.596), train_loss = 0.40516888, grad/param norm = 2.6202e-01, time/batch = 16.4755s	
14093/22300 (epoch 31.599), train_loss = 0.30779587, grad/param norm = 2.5682e-01, time/batch = 16.2189s	
14094/22300 (epoch 31.601), train_loss = 0.36696725, grad/param norm = 2.4274e-01, time/batch = 17.3221s	
14095/22300 (epoch 31.603), train_loss = 0.40984514, grad/param norm = 2.6446e-01, time/batch = 16.4778s	
14096/22300 (epoch 31.605), train_loss = 0.38953223, grad/param norm = 3.0985e-01, time/batch = 15.8728s	
14097/22300 (epoch 31.608), train_loss = 0.66708915, grad/param norm = 3.7024e-01, time/batch = 17.2908s	
14098/22300 (epoch 31.610), train_loss = 0.73075091, grad/param norm = 3.5757e-01, time/batch = 16.6336s	
14099/22300 (epoch 31.612), train_loss = 0.52618725, grad/param norm = 3.0293e-01, time/batch = 16.9687s	
14100/22300 (epoch 31.614), train_loss = 0.51928399, grad/param norm = 3.9081e-01, time/batch = 16.6393s	
14101/22300 (epoch 31.617), train_loss = 0.50670608, grad/param norm = 2.5701e-01, time/batch = 15.8968s	
14102/22300 (epoch 31.619), train_loss = 0.64600002, grad/param norm = 3.4254e-01, time/batch = 17.5311s	
14103/22300 (epoch 31.621), train_loss = 0.39003531, grad/param norm = 2.6721e-01, time/batch = 16.0466s	
14104/22300 (epoch 31.623), train_loss = 0.40477935, grad/param norm = 2.4922e-01, time/batch = 17.5385s	
14105/22300 (epoch 31.626), train_loss = 0.36796844, grad/param norm = 2.2303e-01, time/batch = 15.3081s	
14106/22300 (epoch 31.628), train_loss = 0.38176424, grad/param norm = 2.0426e-01, time/batch = 17.2208s	
14107/22300 (epoch 31.630), train_loss = 0.44993129, grad/param norm = 2.4660e-01, time/batch = 16.3117s	
14108/22300 (epoch 31.632), train_loss = 0.38045940, grad/param norm = 2.4600e-01, time/batch = 17.7974s	
14109/22300 (epoch 31.635), train_loss = 0.42939399, grad/param norm = 2.4538e-01, time/batch = 15.9520s	
14110/22300 (epoch 31.637), train_loss = 0.47494687, grad/param norm = 2.4039e-01, time/batch = 15.4683s	
14111/22300 (epoch 31.639), train_loss = 0.57481454, grad/param norm = 3.1026e-01, time/batch = 17.3148s	
14112/22300 (epoch 31.641), train_loss = 0.45778924, grad/param norm = 2.2779e-01, time/batch = 16.9773s	
14113/22300 (epoch 31.643), train_loss = 0.37377795, grad/param norm = 2.5233e-01, time/batch = 17.2988s	
14114/22300 (epoch 31.646), train_loss = 0.34688518, grad/param norm = 2.2380e-01, time/batch = 15.7714s	
14115/22300 (epoch 31.648), train_loss = 0.45725865, grad/param norm = 2.2179e-01, time/batch = 18.1191s	
14116/22300 (epoch 31.650), train_loss = 0.47306372, grad/param norm = 2.7097e-01, time/batch = 15.9723s	
14117/22300 (epoch 31.652), train_loss = 0.40749479, grad/param norm = 2.7983e-01, time/batch = 18.7816s	
14118/22300 (epoch 31.655), train_loss = 0.36272468, grad/param norm = 2.5811e-01, time/batch = 16.1210s	
14119/22300 (epoch 31.657), train_loss = 0.39207718, grad/param norm = 2.6263e-01, time/batch = 15.3679s	
14120/22300 (epoch 31.659), train_loss = 0.39506054, grad/param norm = 2.6318e-01, time/batch = 15.2842s	
14121/22300 (epoch 31.661), train_loss = 0.29967398, grad/param norm = 1.9305e-01, time/batch = 15.1855s	
14122/22300 (epoch 31.664), train_loss = 0.35426142, grad/param norm = 2.1019e-01, time/batch = 15.1652s	
14123/22300 (epoch 31.666), train_loss = 0.45787062, grad/param norm = 2.4105e-01, time/batch = 14.5187s	
14124/22300 (epoch 31.668), train_loss = 0.33989261, grad/param norm = 1.9821e-01, time/batch = 14.7749s	
14125/22300 (epoch 31.670), train_loss = 0.45937821, grad/param norm = 2.6108e-01, time/batch = 15.6081s	
14126/22300 (epoch 31.673), train_loss = 0.52112515, grad/param norm = 2.7566e-01, time/batch = 15.9017s	
14127/22300 (epoch 31.675), train_loss = 0.58523334, grad/param norm = 3.4060e-01, time/batch = 15.6171s	
14128/22300 (epoch 31.677), train_loss = 0.61922964, grad/param norm = 3.0340e-01, time/batch = 18.5576s	
14129/22300 (epoch 31.679), train_loss = 0.47663090, grad/param norm = 3.2072e-01, time/batch = 15.5357s	
14130/22300 (epoch 31.682), train_loss = 0.43625473, grad/param norm = 3.0473e-01, time/batch = 17.1070s	
14131/22300 (epoch 31.684), train_loss = 0.42802208, grad/param norm = 2.8573e-01, time/batch = 18.5434s	
14132/22300 (epoch 31.686), train_loss = 0.42037835, grad/param norm = 2.6182e-01, time/batch = 17.4720s	
14133/22300 (epoch 31.688), train_loss = 0.38482497, grad/param norm = 2.3979e-01, time/batch = 15.6214s	
14134/22300 (epoch 31.691), train_loss = 0.37009494, grad/param norm = 2.8530e-01, time/batch = 16.1404s	
14135/22300 (epoch 31.693), train_loss = 0.35040353, grad/param norm = 2.4284e-01, time/batch = 17.8000s	
14136/22300 (epoch 31.695), train_loss = 0.36764340, grad/param norm = 2.3956e-01, time/batch = 15.5527s	
14137/22300 (epoch 31.697), train_loss = 0.38188926, grad/param norm = 2.1335e-01, time/batch = 19.0294s	
14138/22300 (epoch 31.700), train_loss = 0.35046619, grad/param norm = 2.3080e-01, time/batch = 16.2339s	
14139/22300 (epoch 31.702), train_loss = 0.29376681, grad/param norm = 1.9589e-01, time/batch = 18.0292s	
14140/22300 (epoch 31.704), train_loss = 0.41372817, grad/param norm = 2.5933e-01, time/batch = 15.5609s	
14141/22300 (epoch 31.706), train_loss = 0.35829437, grad/param norm = 3.0114e-01, time/batch = 17.2632s	
14142/22300 (epoch 31.709), train_loss = 0.30016942, grad/param norm = 2.1392e-01, time/batch = 16.3676s	
14143/22300 (epoch 31.711), train_loss = 0.29632297, grad/param norm = 2.0698e-01, time/batch = 15.3018s	
14144/22300 (epoch 31.713), train_loss = 0.43064831, grad/param norm = 2.2685e-01, time/batch = 15.0421s	
14145/22300 (epoch 31.715), train_loss = 0.41245161, grad/param norm = 2.1824e-01, time/batch = 14.5891s	
14146/22300 (epoch 31.717), train_loss = 0.57731966, grad/param norm = 2.5613e-01, time/batch = 14.7232s	
14147/22300 (epoch 31.720), train_loss = 0.36823416, grad/param norm = 2.2159e-01, time/batch = 15.8878s	
14148/22300 (epoch 31.722), train_loss = 0.43225149, grad/param norm = 2.3322e-01, time/batch = 15.9613s	
14149/22300 (epoch 31.724), train_loss = 0.48415881, grad/param norm = 3.1733e-01, time/batch = 18.6421s	
14150/22300 (epoch 31.726), train_loss = 0.39153743, grad/param norm = 2.8061e-01, time/batch = 17.4537s	
14151/22300 (epoch 31.729), train_loss = 0.42639882, grad/param norm = 2.5218e-01, time/batch = 15.8897s	
14152/22300 (epoch 31.731), train_loss = 0.57383290, grad/param norm = 3.1698e-01, time/batch = 16.8216s	
14153/22300 (epoch 31.733), train_loss = 0.55037495, grad/param norm = 3.1205e-01, time/batch = 16.0599s	
14154/22300 (epoch 31.735), train_loss = 0.59421924, grad/param norm = 2.9897e-01, time/batch = 16.7938s	
14155/22300 (epoch 31.738), train_loss = 0.42711856, grad/param norm = 3.0288e-01, time/batch = 16.3907s	
14156/22300 (epoch 31.740), train_loss = 0.39543731, grad/param norm = 2.3223e-01, time/batch = 17.4770s	
14157/22300 (epoch 31.742), train_loss = 0.35382818, grad/param norm = 2.0462e-01, time/batch = 17.3731s	
14158/22300 (epoch 31.744), train_loss = 0.62043454, grad/param norm = 2.8135e-01, time/batch = 16.4397s	
14159/22300 (epoch 31.747), train_loss = 0.48991237, grad/param norm = 2.3576e-01, time/batch = 16.5223s	
14160/22300 (epoch 31.749), train_loss = 0.65488573, grad/param norm = 3.7140e-01, time/batch = 16.5404s	
14161/22300 (epoch 31.751), train_loss = 0.56792675, grad/param norm = 3.6738e-01, time/batch = 17.0504s	
14162/22300 (epoch 31.753), train_loss = 0.58922193, grad/param norm = 3.0512e-01, time/batch = 16.9706s	
14163/22300 (epoch 31.756), train_loss = 0.52376086, grad/param norm = 2.9969e-01, time/batch = 16.2325s	
14164/22300 (epoch 31.758), train_loss = 0.46922095, grad/param norm = 2.6662e-01, time/batch = 17.8942s	
14165/22300 (epoch 31.760), train_loss = 0.51058074, grad/param norm = 2.9073e-01, time/batch = 14.8060s	
14166/22300 (epoch 31.762), train_loss = 0.47276307, grad/param norm = 2.9586e-01, time/batch = 16.5438s	
14167/22300 (epoch 31.765), train_loss = 0.47791312, grad/param norm = 2.4877e-01, time/batch = 16.4787s	
14168/22300 (epoch 31.767), train_loss = 0.48300022, grad/param norm = 2.7231e-01, time/batch = 16.5568s	
14169/22300 (epoch 31.769), train_loss = 0.44876193, grad/param norm = 2.3777e-01, time/batch = 16.2801s	
14170/22300 (epoch 31.771), train_loss = 0.52215881, grad/param norm = 3.1642e-01, time/batch = 15.8142s	
14171/22300 (epoch 31.774), train_loss = 0.57444010, grad/param norm = 3.3738e-01, time/batch = 18.3828s	
14172/22300 (epoch 31.776), train_loss = 0.57546429, grad/param norm = 2.5220e-01, time/batch = 16.4471s	
14173/22300 (epoch 31.778), train_loss = 0.56944588, grad/param norm = 3.1319e-01, time/batch = 17.1370s	
14174/22300 (epoch 31.780), train_loss = 0.56285739, grad/param norm = 3.0135e-01, time/batch = 16.1578s	
14175/22300 (epoch 31.783), train_loss = 0.60664676, grad/param norm = 3.3341e-01, time/batch = 17.8830s	
14176/22300 (epoch 31.785), train_loss = 0.43253690, grad/param norm = 2.7661e-01, time/batch = 15.5250s	
14177/22300 (epoch 31.787), train_loss = 0.43076115, grad/param norm = 2.8346e-01, time/batch = 16.8826s	
14178/22300 (epoch 31.789), train_loss = 0.61291864, grad/param norm = 3.1133e-01, time/batch = 15.8304s	
14179/22300 (epoch 31.791), train_loss = 0.75194512, grad/param norm = 3.6348e-01, time/batch = 15.3825s	
14180/22300 (epoch 31.794), train_loss = 0.62335666, grad/param norm = 3.5430e-01, time/batch = 16.5578s	
14181/22300 (epoch 31.796), train_loss = 0.53856634, grad/param norm = 2.6997e-01, time/batch = 15.5475s	
14182/22300 (epoch 31.798), train_loss = 0.69088392, grad/param norm = 3.0514e-01, time/batch = 18.3691s	
14183/22300 (epoch 31.800), train_loss = 0.47922126, grad/param norm = 2.7462e-01, time/batch = 15.7850s	
14184/22300 (epoch 31.803), train_loss = 0.43467857, grad/param norm = 2.5744e-01, time/batch = 15.9058s	
14185/22300 (epoch 31.805), train_loss = 0.51649178, grad/param norm = 2.9316e-01, time/batch = 15.5351s	
14186/22300 (epoch 31.807), train_loss = 0.64945746, grad/param norm = 3.1747e-01, time/batch = 16.4670s	
14187/22300 (epoch 31.809), train_loss = 0.45944909, grad/param norm = 2.9128e-01, time/batch = 14.9536s	
14188/22300 (epoch 31.812), train_loss = 0.53606306, grad/param norm = 3.0947e-01, time/batch = 16.9845s	
14189/22300 (epoch 31.814), train_loss = 0.51575805, grad/param norm = 2.7819e-01, time/batch = 14.9028s	
14190/22300 (epoch 31.816), train_loss = 0.50433164, grad/param norm = 2.4420e-01, time/batch = 16.0558s	
14191/22300 (epoch 31.818), train_loss = 0.61806746, grad/param norm = 3.1718e-01, time/batch = 18.2944s	
14192/22300 (epoch 31.821), train_loss = 0.53052282, grad/param norm = 2.8937e-01, time/batch = 17.2370s	
14193/22300 (epoch 31.823), train_loss = 0.33582452, grad/param norm = 2.1629e-01, time/batch = 16.6386s	
14194/22300 (epoch 31.825), train_loss = 0.38787311, grad/param norm = 2.7643e-01, time/batch = 16.1210s	
14195/22300 (epoch 31.827), train_loss = 0.44447610, grad/param norm = 2.7582e-01, time/batch = 18.0388s	
14196/22300 (epoch 31.830), train_loss = 0.44135587, grad/param norm = 3.0367e-01, time/batch = 16.2271s	
14197/22300 (epoch 31.832), train_loss = 0.39751578, grad/param norm = 2.3873e-01, time/batch = 15.3841s	
14198/22300 (epoch 31.834), train_loss = 0.35423300, grad/param norm = 2.4441e-01, time/batch = 14.4855s	
14199/22300 (epoch 31.836), train_loss = 0.44439190, grad/param norm = 3.1878e-01, time/batch = 18.1319s	
14200/22300 (epoch 31.839), train_loss = 0.46088476, grad/param norm = 2.9784e-01, time/batch = 17.1345s	
14201/22300 (epoch 31.841), train_loss = 0.50058192, grad/param norm = 4.1887e-01, time/batch = 16.1168s	
14202/22300 (epoch 31.843), train_loss = 0.43686965, grad/param norm = 2.6594e-01, time/batch = 19.2854s	
14203/22300 (epoch 31.845), train_loss = 0.42803571, grad/param norm = 2.4568e-01, time/batch = 16.9015s	
14204/22300 (epoch 31.848), train_loss = 0.45852168, grad/param norm = 3.4678e-01, time/batch = 15.9057s	
14205/22300 (epoch 31.850), train_loss = 0.45435166, grad/param norm = 2.4339e-01, time/batch = 15.9502s	
14206/22300 (epoch 31.852), train_loss = 0.41621909, grad/param norm = 2.9963e-01, time/batch = 17.3038s	
14207/22300 (epoch 31.854), train_loss = 0.63602084, grad/param norm = 3.0938e-01, time/batch = 15.4258s	
14208/22300 (epoch 31.857), train_loss = 0.51047643, grad/param norm = 3.2448e-01, time/batch = 16.5503s	
14209/22300 (epoch 31.859), train_loss = 0.38744100, grad/param norm = 2.3123e-01, time/batch = 17.4599s	
14210/22300 (epoch 31.861), train_loss = 0.55370493, grad/param norm = 4.0190e-01, time/batch = 16.5584s	
14211/22300 (epoch 31.863), train_loss = 0.37477675, grad/param norm = 2.5851e-01, time/batch = 16.8794s	
14212/22300 (epoch 31.865), train_loss = 0.38186736, grad/param norm = 2.8729e-01, time/batch = 15.6002s	
14213/22300 (epoch 31.868), train_loss = 0.48933038, grad/param norm = 2.7421e-01, time/batch = 17.4813s	
14214/22300 (epoch 31.870), train_loss = 0.50285593, grad/param norm = 2.9596e-01, time/batch = 15.6534s	
14215/22300 (epoch 31.872), train_loss = 0.59089242, grad/param norm = 3.3010e-01, time/batch = 17.3821s	
14216/22300 (epoch 31.874), train_loss = 0.52812363, grad/param norm = 4.1877e-01, time/batch = 17.2055s	
14217/22300 (epoch 31.877), train_loss = 0.47855822, grad/param norm = 2.9526e-01, time/batch = 16.8064s	
14218/22300 (epoch 31.879), train_loss = 0.42125170, grad/param norm = 2.6331e-01, time/batch = 17.2856s	
14219/22300 (epoch 31.881), train_loss = 0.37182237, grad/param norm = 2.2160e-01, time/batch = 14.9538s	
14220/22300 (epoch 31.883), train_loss = 0.39773263, grad/param norm = 3.3854e-01, time/batch = 16.3114s	
14221/22300 (epoch 31.886), train_loss = 0.37241416, grad/param norm = 2.5630e-01, time/batch = 17.3933s	
14222/22300 (epoch 31.888), train_loss = 0.44092378, grad/param norm = 2.7320e-01, time/batch = 17.0388s	
14223/22300 (epoch 31.890), train_loss = 0.41540592, grad/param norm = 2.3953e-01, time/batch = 16.0407s	
14224/22300 (epoch 31.892), train_loss = 0.62335011, grad/param norm = 3.0228e-01, time/batch = 16.6442s	
14225/22300 (epoch 31.895), train_loss = 0.55771200, grad/param norm = 3.1912e-01, time/batch = 16.7308s	
14226/22300 (epoch 31.897), train_loss = 0.45600542, grad/param norm = 3.0515e-01, time/batch = 14.4740s	
14227/22300 (epoch 31.899), train_loss = 0.44575426, grad/param norm = 2.5893e-01, time/batch = 16.6477s	
14228/22300 (epoch 31.901), train_loss = 0.49906745, grad/param norm = 2.5510e-01, time/batch = 16.2304s	
14229/22300 (epoch 31.904), train_loss = 0.52530086, grad/param norm = 2.7560e-01, time/batch = 16.3965s	
14230/22300 (epoch 31.906), train_loss = 0.48470009, grad/param norm = 2.5836e-01, time/batch = 15.7719s	
14231/22300 (epoch 31.908), train_loss = 0.42755165, grad/param norm = 2.2416e-01, time/batch = 19.5396s	
14232/22300 (epoch 31.910), train_loss = 0.38769117, grad/param norm = 2.2202e-01, time/batch = 15.1578s	
14233/22300 (epoch 31.913), train_loss = 0.52920553, grad/param norm = 2.8260e-01, time/batch = 16.1198s	
14234/22300 (epoch 31.915), train_loss = 0.61500755, grad/param norm = 2.7828e-01, time/batch = 15.3051s	
14235/22300 (epoch 31.917), train_loss = 0.50872951, grad/param norm = 2.9601e-01, time/batch = 16.4011s	
14236/22300 (epoch 31.919), train_loss = 0.50193918, grad/param norm = 2.3857e-01, time/batch = 17.6444s	
14237/22300 (epoch 31.922), train_loss = 0.49022342, grad/param norm = 3.0608e-01, time/batch = 15.6293s	
14238/22300 (epoch 31.924), train_loss = 0.32255871, grad/param norm = 2.3152e-01, time/batch = 16.5543s	
14239/22300 (epoch 31.926), train_loss = 0.37462683, grad/param norm = 1.8898e-01, time/batch = 15.2168s	
14240/22300 (epoch 31.928), train_loss = 0.41079070, grad/param norm = 2.5510e-01, time/batch = 16.4852s	
14241/22300 (epoch 31.930), train_loss = 0.41577405, grad/param norm = 2.4761e-01, time/batch = 15.9450s	
14242/22300 (epoch 31.933), train_loss = 0.49452441, grad/param norm = 2.4838e-01, time/batch = 15.9029s	
14243/22300 (epoch 31.935), train_loss = 0.48046240, grad/param norm = 3.1711e-01, time/batch = 15.6585s	
14244/22300 (epoch 31.937), train_loss = 0.58520821, grad/param norm = 3.6390e-01, time/batch = 16.8724s	
14245/22300 (epoch 31.939), train_loss = 0.54600238, grad/param norm = 3.3896e-01, time/batch = 16.2732s	
14246/22300 (epoch 31.942), train_loss = 0.62055352, grad/param norm = 3.0806e-01, time/batch = 17.9716s	
14247/22300 (epoch 31.944), train_loss = 0.67539972, grad/param norm = 3.6693e-01, time/batch = 16.7218s	
14248/22300 (epoch 31.946), train_loss = 0.49926922, grad/param norm = 2.8144e-01, time/batch = 16.2091s	
14249/22300 (epoch 31.948), train_loss = 0.41514234, grad/param norm = 1.9047e-01, time/batch = 16.4093s	
14250/22300 (epoch 31.951), train_loss = 0.34505957, grad/param norm = 2.0347e-01, time/batch = 15.0572s	
14251/22300 (epoch 31.953), train_loss = 0.42359646, grad/param norm = 2.9928e-01, time/batch = 17.1401s	
14252/22300 (epoch 31.955), train_loss = 0.60431723, grad/param norm = 3.0153e-01, time/batch = 15.2294s	
14253/22300 (epoch 31.957), train_loss = 0.68847915, grad/param norm = 3.0550e-01, time/batch = 14.9939s	
14254/22300 (epoch 31.960), train_loss = 0.57150371, grad/param norm = 2.7151e-01, time/batch = 15.8008s	
14255/22300 (epoch 31.962), train_loss = 0.38983961, grad/param norm = 2.8234e-01, time/batch = 17.7972s	
14256/22300 (epoch 31.964), train_loss = 0.43624794, grad/param norm = 2.8312e-01, time/batch = 16.2981s	
14257/22300 (epoch 31.966), train_loss = 0.40181354, grad/param norm = 2.5278e-01, time/batch = 17.4680s	
14258/22300 (epoch 31.969), train_loss = 0.43685197, grad/param norm = 2.2348e-01, time/batch = 18.4688s	
14259/22300 (epoch 31.971), train_loss = 0.46210208, grad/param norm = 2.4965e-01, time/batch = 15.2991s	
14260/22300 (epoch 31.973), train_loss = 0.45500962, grad/param norm = 2.5597e-01, time/batch = 16.7933s	
14261/22300 (epoch 31.975), train_loss = 0.59975323, grad/param norm = 3.1962e-01, time/batch = 17.6350s	
14262/22300 (epoch 31.978), train_loss = 0.56587904, grad/param norm = 2.9997e-01, time/batch = 17.1911s	
14263/22300 (epoch 31.980), train_loss = 0.64493384, grad/param norm = 3.1077e-01, time/batch = 15.5445s	
14264/22300 (epoch 31.982), train_loss = 0.37494082, grad/param norm = 2.5386e-01, time/batch = 16.0472s	
14265/22300 (epoch 31.984), train_loss = 0.49023204, grad/param norm = 2.7380e-01, time/batch = 15.7210s	
14266/22300 (epoch 31.987), train_loss = 0.43206201, grad/param norm = 2.9894e-01, time/batch = 16.3025s	
14267/22300 (epoch 31.989), train_loss = 0.37955364, grad/param norm = 2.1673e-01, time/batch = 15.6976s	
14268/22300 (epoch 31.991), train_loss = 0.68327650, grad/param norm = 3.5271e-01, time/batch = 17.0735s	
14269/22300 (epoch 31.993), train_loss = 0.84571837, grad/param norm = 3.4499e-01, time/batch = 17.2217s	
14270/22300 (epoch 31.996), train_loss = 0.82016470, grad/param norm = 4.2305e-01, time/batch = 15.7031s	
14271/22300 (epoch 31.998), train_loss = 0.48734248, grad/param norm = 2.5761e-01, time/batch = 16.5429s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
14272/22300 (epoch 32.000), train_loss = 0.39109856, grad/param norm = 2.3867e-01, time/batch = 17.1869s	
14273/22300 (epoch 32.002), train_loss = 0.75346284, grad/param norm = 3.1444e-01, time/batch = 16.9685s	
14274/22300 (epoch 32.004), train_loss = 0.53077543, grad/param norm = 2.4353e-01, time/batch = 17.3132s	
14275/22300 (epoch 32.007), train_loss = 0.52716628, grad/param norm = 3.0233e-01, time/batch = 16.2428s	
14276/22300 (epoch 32.009), train_loss = 0.55043292, grad/param norm = 3.2875e-01, time/batch = 17.5617s	
14277/22300 (epoch 32.011), train_loss = 0.68203293, grad/param norm = 3.1337e-01, time/batch = 15.8775s	
14278/22300 (epoch 32.013), train_loss = 0.52075484, grad/param norm = 2.7006e-01, time/batch = 15.7194s	
14279/22300 (epoch 32.016), train_loss = 0.41914392, grad/param norm = 2.9291e-01, time/batch = 16.3045s	
14280/22300 (epoch 32.018), train_loss = 0.49701837, grad/param norm = 3.0804e-01, time/batch = 18.1547s	
14281/22300 (epoch 32.020), train_loss = 0.44621922, grad/param norm = 2.8377e-01, time/batch = 16.5401s	
14282/22300 (epoch 32.022), train_loss = 0.37435992, grad/param norm = 2.9454e-01, time/batch = 17.6420s	
14283/22300 (epoch 32.025), train_loss = 0.39406327, grad/param norm = 2.1327e-01, time/batch = 17.1230s	
14284/22300 (epoch 32.027), train_loss = 0.38192317, grad/param norm = 2.1250e-01, time/batch = 15.7003s	
14285/22300 (epoch 32.029), train_loss = 0.41322379, grad/param norm = 2.3842e-01, time/batch = 18.6184s	
14286/22300 (epoch 32.031), train_loss = 0.41234227, grad/param norm = 2.6180e-01, time/batch = 15.3075s	
14287/22300 (epoch 32.034), train_loss = 0.41531941, grad/param norm = 2.5749e-01, time/batch = 18.8084s	
14288/22300 (epoch 32.036), train_loss = 0.36128976, grad/param norm = 2.1936e-01, time/batch = 16.0453s	
14289/22300 (epoch 32.038), train_loss = 0.35337973, grad/param norm = 2.2650e-01, time/batch = 17.0728s	
14290/22300 (epoch 32.040), train_loss = 0.40793247, grad/param norm = 2.4735e-01, time/batch = 18.8860s	
14291/22300 (epoch 32.043), train_loss = 0.67087500, grad/param norm = 3.6512e-01, time/batch = 16.0660s	
14292/22300 (epoch 32.045), train_loss = 0.55698643, grad/param norm = 2.8566e-01, time/batch = 15.6478s	
14293/22300 (epoch 32.047), train_loss = 0.56881926, grad/param norm = 3.0482e-01, time/batch = 17.0691s	
14294/22300 (epoch 32.049), train_loss = 0.43269947, grad/param norm = 2.4620e-01, time/batch = 16.7184s	
14295/22300 (epoch 32.052), train_loss = 0.54526749, grad/param norm = 3.3630e-01, time/batch = 15.3445s	
14296/22300 (epoch 32.054), train_loss = 0.52367337, grad/param norm = 2.7354e-01, time/batch = 16.3726s	
14297/22300 (epoch 32.056), train_loss = 0.27505431, grad/param norm = 1.9215e-01, time/batch = 14.9306s	
14298/22300 (epoch 32.058), train_loss = 0.43574558, grad/param norm = 2.9420e-01, time/batch = 15.8144s	
14299/22300 (epoch 32.061), train_loss = 0.39057549, grad/param norm = 2.8728e-01, time/batch = 18.4609s	
14300/22300 (epoch 32.063), train_loss = 0.59040810, grad/param norm = 3.6153e-01, time/batch = 16.4752s	
14301/22300 (epoch 32.065), train_loss = 0.67555413, grad/param norm = 4.0365e-01, time/batch = 16.1326s	
14302/22300 (epoch 32.067), train_loss = 0.39809426, grad/param norm = 2.5009e-01, time/batch = 28.4838s	
14303/22300 (epoch 32.070), train_loss = 0.49031605, grad/param norm = 3.8034e-01, time/batch = 17.9137s	
14304/22300 (epoch 32.072), train_loss = 0.53524000, grad/param norm = 3.2926e-01, time/batch = 15.1282s	
14305/22300 (epoch 32.074), train_loss = 0.51492168, grad/param norm = 2.9229e-01, time/batch = 15.4581s	
14306/22300 (epoch 32.076), train_loss = 0.53870915, grad/param norm = 3.5426e-01, time/batch = 18.3835s	
14307/22300 (epoch 32.078), train_loss = 0.66014549, grad/param norm = 4.4359e-01, time/batch = 16.6399s	
14308/22300 (epoch 32.081), train_loss = 0.61190058, grad/param norm = 3.4960e-01, time/batch = 18.4475s	
14309/22300 (epoch 32.083), train_loss = 0.69719047, grad/param norm = 3.8019e-01, time/batch = 17.2935s	
14310/22300 (epoch 32.085), train_loss = 0.65408565, grad/param norm = 3.3593e-01, time/batch = 17.3103s	
14311/22300 (epoch 32.087), train_loss = 0.53512225, grad/param norm = 2.6658e-01, time/batch = 16.6422s	
14312/22300 (epoch 32.090), train_loss = 0.48941585, grad/param norm = 2.6811e-01, time/batch = 14.9670s	
14313/22300 (epoch 32.092), train_loss = 0.38997406, grad/param norm = 2.5471e-01, time/batch = 15.0464s	
14314/22300 (epoch 32.094), train_loss = 0.38464599, grad/param norm = 2.6755e-01, time/batch = 17.3814s	
14315/22300 (epoch 32.096), train_loss = 0.66020134, grad/param norm = 3.6773e-01, time/batch = 17.6300s	
14316/22300 (epoch 32.099), train_loss = 0.43235906, grad/param norm = 3.2126e-01, time/batch = 16.5613s	
14317/22300 (epoch 32.101), train_loss = 0.55944039, grad/param norm = 2.9259e-01, time/batch = 17.7072s	
14318/22300 (epoch 32.103), train_loss = 0.48319570, grad/param norm = 2.7172e-01, time/batch = 17.2386s	
14319/22300 (epoch 32.105), train_loss = 0.38732953, grad/param norm = 2.6751e-01, time/batch = 14.9801s	
14320/22300 (epoch 32.108), train_loss = 0.50470249, grad/param norm = 2.3447e-01, time/batch = 16.9627s	
14321/22300 (epoch 32.110), train_loss = 0.60814982, grad/param norm = 3.1492e-01, time/batch = 16.6397s	
14322/22300 (epoch 32.112), train_loss = 0.52751464, grad/param norm = 2.7135e-01, time/batch = 16.1313s	
14323/22300 (epoch 32.114), train_loss = 0.56108502, grad/param norm = 3.3034e-01, time/batch = 14.9637s	
14324/22300 (epoch 32.117), train_loss = 0.65750994, grad/param norm = 2.7257e-01, time/batch = 18.2238s	
14325/22300 (epoch 32.119), train_loss = 0.58735824, grad/param norm = 3.1004e-01, time/batch = 16.8068s	
14326/22300 (epoch 32.121), train_loss = 0.67514520, grad/param norm = 3.3320e-01, time/batch = 16.7024s	
14327/22300 (epoch 32.123), train_loss = 0.70037681, grad/param norm = 3.3634e-01, time/batch = 16.2303s	
14328/22300 (epoch 32.126), train_loss = 0.54919850, grad/param norm = 3.2209e-01, time/batch = 17.2169s	
14329/22300 (epoch 32.128), train_loss = 0.52772643, grad/param norm = 3.3773e-01, time/batch = 18.5456s	
14330/22300 (epoch 32.130), train_loss = 0.43584803, grad/param norm = 2.2913e-01, time/batch = 15.7966s	
14331/22300 (epoch 32.132), train_loss = 0.34117616, grad/param norm = 2.1498e-01, time/batch = 15.6422s	
14332/22300 (epoch 32.135), train_loss = 0.35632534, grad/param norm = 2.8399e-01, time/batch = 18.3772s	
14333/22300 (epoch 32.137), train_loss = 0.29440092, grad/param norm = 2.1879e-01, time/batch = 16.0973s	
14334/22300 (epoch 32.139), train_loss = 0.45857262, grad/param norm = 2.8858e-01, time/batch = 16.7985s	
14335/22300 (epoch 32.141), train_loss = 0.56484545, grad/param norm = 2.6119e-01, time/batch = 16.8940s	
14336/22300 (epoch 32.143), train_loss = 0.48959111, grad/param norm = 2.8567e-01, time/batch = 16.3969s	
14337/22300 (epoch 32.146), train_loss = 0.58821168, grad/param norm = 3.4928e-01, time/batch = 16.1076s	
14338/22300 (epoch 32.148), train_loss = 0.38845116, grad/param norm = 2.2668e-01, time/batch = 15.2812s	
14339/22300 (epoch 32.150), train_loss = 0.43823722, grad/param norm = 2.6664e-01, time/batch = 15.6542s	
14340/22300 (epoch 32.152), train_loss = 0.35460112, grad/param norm = 2.4475e-01, time/batch = 16.3944s	
14341/22300 (epoch 32.155), train_loss = 0.39124266, grad/param norm = 2.3603e-01, time/batch = 16.0323s	
14342/22300 (epoch 32.157), train_loss = 0.54368800, grad/param norm = 3.8369e-01, time/batch = 16.2160s	
14343/22300 (epoch 32.159), train_loss = 0.54236674, grad/param norm = 2.8781e-01, time/batch = 17.3137s	
14344/22300 (epoch 32.161), train_loss = 0.53411067, grad/param norm = 3.0142e-01, time/batch = 15.2914s	
14345/22300 (epoch 32.164), train_loss = 0.40327645, grad/param norm = 2.3759e-01, time/batch = 17.0312s	
14346/22300 (epoch 32.166), train_loss = 0.34611843, grad/param norm = 2.0114e-01, time/batch = 17.3087s	
14347/22300 (epoch 32.168), train_loss = 0.37307835, grad/param norm = 2.5293e-01, time/batch = 17.1173s	
14348/22300 (epoch 32.170), train_loss = 0.48523609, grad/param norm = 2.9061e-01, time/batch = 15.8662s	
14349/22300 (epoch 32.173), train_loss = 0.57990813, grad/param norm = 3.3246e-01, time/batch = 17.0447s	
14350/22300 (epoch 32.175), train_loss = 0.49879787, grad/param norm = 3.1301e-01, time/batch = 15.0387s	
14351/22300 (epoch 32.177), train_loss = 0.33274042, grad/param norm = 2.6845e-01, time/batch = 16.3184s	
14352/22300 (epoch 32.179), train_loss = 0.47347808, grad/param norm = 2.4612e-01, time/batch = 16.9663s	
14353/22300 (epoch 32.182), train_loss = 0.65523047, grad/param norm = 3.3855e-01, time/batch = 18.0632s	
14354/22300 (epoch 32.184), train_loss = 0.68403362, grad/param norm = 3.1502e-01, time/batch = 16.5508s	
14355/22300 (epoch 32.186), train_loss = 0.51830050, grad/param norm = 2.8934e-01, time/batch = 15.8901s	
14356/22300 (epoch 32.188), train_loss = 0.68978902, grad/param norm = 3.1428e-01, time/batch = 17.3121s	
14357/22300 (epoch 32.191), train_loss = 0.58954928, grad/param norm = 2.8705e-01, time/batch = 15.6548s	
14358/22300 (epoch 32.193), train_loss = 0.51851264, grad/param norm = 3.0320e-01, time/batch = 15.2207s	
14359/22300 (epoch 32.195), train_loss = 0.46132414, grad/param norm = 2.5429e-01, time/batch = 15.2213s	
14360/22300 (epoch 32.197), train_loss = 0.42036529, grad/param norm = 2.7414e-01, time/batch = 17.7215s	
14361/22300 (epoch 32.200), train_loss = 0.39521768, grad/param norm = 3.1986e-01, time/batch = 18.1356s	
14362/22300 (epoch 32.202), train_loss = 0.40274647, grad/param norm = 2.3704e-01, time/batch = 16.8882s	
14363/22300 (epoch 32.204), train_loss = 0.47462084, grad/param norm = 2.6885e-01, time/batch = 16.3901s	
14364/22300 (epoch 32.206), train_loss = 0.41930258, grad/param norm = 2.8329e-01, time/batch = 16.0149s	
14365/22300 (epoch 32.209), train_loss = 0.45478265, grad/param norm = 2.8503e-01, time/batch = 17.6890s	
14366/22300 (epoch 32.211), train_loss = 0.35881081, grad/param norm = 2.2530e-01, time/batch = 15.4684s	
14367/22300 (epoch 32.213), train_loss = 0.49029494, grad/param norm = 3.2506e-01, time/batch = 17.9479s	
14368/22300 (epoch 32.215), train_loss = 0.63678858, grad/param norm = 3.5199e-01, time/batch = 17.0502s	
14369/22300 (epoch 32.217), train_loss = 0.64369225, grad/param norm = 3.4826e-01, time/batch = 17.7069s	
14370/22300 (epoch 32.220), train_loss = 0.44669119, grad/param norm = 2.4605e-01, time/batch = 15.5614s	
14371/22300 (epoch 32.222), train_loss = 0.40979766, grad/param norm = 2.0209e-01, time/batch = 15.6402s	
14372/22300 (epoch 32.224), train_loss = 0.42998307, grad/param norm = 2.5350e-01, time/batch = 19.1310s	
14373/22300 (epoch 32.226), train_loss = 0.47923294, grad/param norm = 3.0923e-01, time/batch = 15.9632s	
14374/22300 (epoch 32.229), train_loss = 0.36993768, grad/param norm = 2.4252e-01, time/batch = 17.9553s	
14375/22300 (epoch 32.231), train_loss = 0.61949843, grad/param norm = 4.5839e-01, time/batch = 15.5008s	
14376/22300 (epoch 32.233), train_loss = 0.48336098, grad/param norm = 2.9075e-01, time/batch = 17.3804s	
14377/22300 (epoch 32.235), train_loss = 0.38213136, grad/param norm = 2.5603e-01, time/batch = 15.7105s	
14378/22300 (epoch 32.238), train_loss = 0.38654412, grad/param norm = 2.1705e-01, time/batch = 15.1081s	
14379/22300 (epoch 32.240), train_loss = 0.39126575, grad/param norm = 2.1778e-01, time/batch = 17.8060s	
14380/22300 (epoch 32.242), train_loss = 0.36483197, grad/param norm = 3.0232e-01, time/batch = 17.0224s	
14381/22300 (epoch 32.244), train_loss = 0.25473039, grad/param norm = 1.7266e-01, time/batch = 17.2124s	
14382/22300 (epoch 32.247), train_loss = 0.35576017, grad/param norm = 2.2265e-01, time/batch = 15.9013s	
14383/22300 (epoch 32.249), train_loss = 0.25139138, grad/param norm = 1.8808e-01, time/batch = 18.5421s	
14384/22300 (epoch 32.251), train_loss = 0.33052711, grad/param norm = 1.9331e-01, time/batch = 16.1920s	
14385/22300 (epoch 32.253), train_loss = 0.22933468, grad/param norm = 2.0416e-01, time/batch = 16.0595s	
14386/22300 (epoch 32.256), train_loss = 0.32751819, grad/param norm = 1.8829e-01, time/batch = 17.0671s	
14387/22300 (epoch 32.258), train_loss = 0.50065243, grad/param norm = 2.8250e-01, time/batch = 17.3738s	
14388/22300 (epoch 32.260), train_loss = 0.47415287, grad/param norm = 2.3297e-01, time/batch = 15.7290s	
14389/22300 (epoch 32.262), train_loss = 0.37617743, grad/param norm = 2.1567e-01, time/batch = 17.9619s	
14390/22300 (epoch 32.265), train_loss = 0.33639839, grad/param norm = 2.4409e-01, time/batch = 17.4849s	
14391/22300 (epoch 32.267), train_loss = 0.37964619, grad/param norm = 2.1833e-01, time/batch = 15.6413s	
14392/22300 (epoch 32.269), train_loss = 0.46934880, grad/param norm = 3.3787e-01, time/batch = 17.0484s	
14393/22300 (epoch 32.271), train_loss = 0.52128705, grad/param norm = 3.0150e-01, time/batch = 15.9759s	
14394/22300 (epoch 32.274), train_loss = 0.37735087, grad/param norm = 2.6981e-01, time/batch = 15.5447s	
14395/22300 (epoch 32.276), train_loss = 0.29446464, grad/param norm = 1.6558e-01, time/batch = 16.0604s	
14396/22300 (epoch 32.278), train_loss = 0.32363206, grad/param norm = 2.3299e-01, time/batch = 18.0545s	
14397/22300 (epoch 32.280), train_loss = 0.37689922, grad/param norm = 2.2858e-01, time/batch = 16.4035s	
14398/22300 (epoch 32.283), train_loss = 0.27133800, grad/param norm = 1.5364e-01, time/batch = 15.6463s	
14399/22300 (epoch 32.285), train_loss = 0.32901084, grad/param norm = 2.3976e-01, time/batch = 17.4683s	
14400/22300 (epoch 32.287), train_loss = 0.45459843, grad/param norm = 2.3426e-01, time/batch = 16.0692s	
14401/22300 (epoch 32.289), train_loss = 0.41084110, grad/param norm = 2.1986e-01, time/batch = 15.4669s	
14402/22300 (epoch 32.291), train_loss = 0.41528507, grad/param norm = 2.4548e-01, time/batch = 16.1015s	
14403/22300 (epoch 32.294), train_loss = 0.32472936, grad/param norm = 1.8520e-01, time/batch = 15.7198s	
14404/22300 (epoch 32.296), train_loss = 0.41871186, grad/param norm = 3.0785e-01, time/batch = 16.7296s	
14405/22300 (epoch 32.298), train_loss = 0.52849089, grad/param norm = 2.7653e-01, time/batch = 15.1196s	
14406/22300 (epoch 32.300), train_loss = 0.57999360, grad/param norm = 2.9776e-01, time/batch = 15.9673s	
14407/22300 (epoch 32.303), train_loss = 0.45343015, grad/param norm = 2.8557e-01, time/batch = 17.7989s	
14408/22300 (epoch 32.305), train_loss = 0.44532080, grad/param norm = 3.0716e-01, time/batch = 17.8010s	
14409/22300 (epoch 32.307), train_loss = 0.38582904, grad/param norm = 2.6177e-01, time/batch = 16.4690s	
14410/22300 (epoch 32.309), train_loss = 0.34535238, grad/param norm = 2.1995e-01, time/batch = 16.8733s	
14411/22300 (epoch 32.312), train_loss = 0.31245209, grad/param norm = 1.8959e-01, time/batch = 16.4704s	
14412/22300 (epoch 32.314), train_loss = 0.35034620, grad/param norm = 2.4878e-01, time/batch = 16.8854s	
14413/22300 (epoch 32.316), train_loss = 0.35436607, grad/param norm = 2.2633e-01, time/batch = 17.2203s	
14414/22300 (epoch 32.318), train_loss = 0.38494403, grad/param norm = 2.0917e-01, time/batch = 17.3979s	
14415/22300 (epoch 32.321), train_loss = 0.48107921, grad/param norm = 2.5557e-01, time/batch = 15.5800s	
14416/22300 (epoch 32.323), train_loss = 0.36441302, grad/param norm = 2.4373e-01, time/batch = 16.0583s	
14417/22300 (epoch 32.325), train_loss = 0.31797674, grad/param norm = 2.0069e-01, time/batch = 17.2287s	
14418/22300 (epoch 32.327), train_loss = 0.32178892, grad/param norm = 1.7128e-01, time/batch = 16.7217s	
14419/22300 (epoch 32.330), train_loss = 0.34391632, grad/param norm = 2.6374e-01, time/batch = 18.2168s	
14420/22300 (epoch 32.332), train_loss = 0.31067248, grad/param norm = 1.7130e-01, time/batch = 15.9165s	
14421/22300 (epoch 32.334), train_loss = 0.37960337, grad/param norm = 2.4073e-01, time/batch = 15.5703s	
14422/22300 (epoch 32.336), train_loss = 0.39429110, grad/param norm = 2.1667e-01, time/batch = 18.6327s	
14423/22300 (epoch 32.339), train_loss = 0.44966627, grad/param norm = 2.6918e-01, time/batch = 15.5575s	
14424/22300 (epoch 32.341), train_loss = 0.46560666, grad/param norm = 2.6447e-01, time/batch = 18.2922s	
14425/22300 (epoch 32.343), train_loss = 0.50748133, grad/param norm = 3.1925e-01, time/batch = 15.7059s	
14426/22300 (epoch 32.345), train_loss = 0.41046959, grad/param norm = 2.7641e-01, time/batch = 18.3885s	
14427/22300 (epoch 32.348), train_loss = 0.40425422, grad/param norm = 2.5164e-01, time/batch = 15.5576s	
14428/22300 (epoch 32.350), train_loss = 0.30993703, grad/param norm = 2.0746e-01, time/batch = 17.4749s	
14429/22300 (epoch 32.352), train_loss = 0.44460987, grad/param norm = 2.7425e-01, time/batch = 15.1136s	
14430/22300 (epoch 32.354), train_loss = 0.64552957, grad/param norm = 3.4640e-01, time/batch = 17.5483s	
14431/22300 (epoch 32.357), train_loss = 0.52309528, grad/param norm = 2.4992e-01, time/batch = 15.7226s	
14432/22300 (epoch 32.359), train_loss = 0.35461096, grad/param norm = 2.2419e-01, time/batch = 17.9702s	
14433/22300 (epoch 32.361), train_loss = 0.37094937, grad/param norm = 2.8280e-01, time/batch = 16.6271s	
14434/22300 (epoch 32.363), train_loss = 0.49497886, grad/param norm = 3.0782e-01, time/batch = 15.5431s	
14435/22300 (epoch 32.365), train_loss = 0.35119643, grad/param norm = 2.1867e-01, time/batch = 17.7215s	
14436/22300 (epoch 32.368), train_loss = 0.39577329, grad/param norm = 2.6632e-01, time/batch = 16.2293s	
14437/22300 (epoch 32.370), train_loss = 0.38979856, grad/param norm = 2.4599e-01, time/batch = 15.4377s	
14438/22300 (epoch 32.372), train_loss = 0.30354547, grad/param norm = 1.9695e-01, time/batch = 16.1973s	
14439/22300 (epoch 32.374), train_loss = 0.28653942, grad/param norm = 2.0976e-01, time/batch = 16.7305s	
14440/22300 (epoch 32.377), train_loss = 0.39276959, grad/param norm = 3.0573e-01, time/batch = 16.6310s	
14441/22300 (epoch 32.379), train_loss = 0.36757533, grad/param norm = 2.3602e-01, time/batch = 15.4553s	
14442/22300 (epoch 32.381), train_loss = 0.49627400, grad/param norm = 3.0243e-01, time/batch = 17.8022s	
14443/22300 (epoch 32.383), train_loss = 0.40962100, grad/param norm = 2.7224e-01, time/batch = 16.0678s	
14444/22300 (epoch 32.386), train_loss = 0.41229464, grad/param norm = 2.3934e-01, time/batch = 17.8075s	
14445/22300 (epoch 32.388), train_loss = 0.34798219, grad/param norm = 2.5270e-01, time/batch = 15.1909s	
14446/22300 (epoch 32.390), train_loss = 0.35622987, grad/param norm = 2.5056e-01, time/batch = 17.8892s	
14447/22300 (epoch 32.392), train_loss = 0.41488913, grad/param norm = 3.3216e-01, time/batch = 15.9962s	
14448/22300 (epoch 32.395), train_loss = 0.32936066, grad/param norm = 2.1754e-01, time/batch = 16.9533s	
14449/22300 (epoch 32.397), train_loss = 0.21768471, grad/param norm = 1.7545e-01, time/batch = 17.2165s	
14450/22300 (epoch 32.399), train_loss = 0.31397849, grad/param norm = 2.2765e-01, time/batch = 17.7303s	
14451/22300 (epoch 32.401), train_loss = 0.36735098, grad/param norm = 2.3393e-01, time/batch = 18.2007s	
14452/22300 (epoch 32.404), train_loss = 0.38477303, grad/param norm = 2.5140e-01, time/batch = 15.7162s	
14453/22300 (epoch 32.406), train_loss = 0.61459293, grad/param norm = 3.4976e-01, time/batch = 16.6343s	
14454/22300 (epoch 32.408), train_loss = 0.47969463, grad/param norm = 3.1721e-01, time/batch = 17.7739s	
14455/22300 (epoch 32.410), train_loss = 0.48996472, grad/param norm = 2.9939e-01, time/batch = 16.9701s	
14456/22300 (epoch 32.413), train_loss = 0.36669572, grad/param norm = 2.6357e-01, time/batch = 16.2930s	
14457/22300 (epoch 32.415), train_loss = 0.28011553, grad/param norm = 2.0756e-01, time/batch = 17.1200s	
14458/22300 (epoch 32.417), train_loss = 0.44425072, grad/param norm = 2.8785e-01, time/batch = 16.1440s	
14459/22300 (epoch 32.419), train_loss = 0.37125045, grad/param norm = 2.3143e-01, time/batch = 15.7014s	
14460/22300 (epoch 32.422), train_loss = 0.32527230, grad/param norm = 2.3098e-01, time/batch = 16.7357s	
14461/22300 (epoch 32.424), train_loss = 0.41781835, grad/param norm = 2.5288e-01, time/batch = 17.3918s	
14462/22300 (epoch 32.426), train_loss = 0.31435020, grad/param norm = 2.2567e-01, time/batch = 16.1089s	
14463/22300 (epoch 32.428), train_loss = 0.31544069, grad/param norm = 2.3706e-01, time/batch = 17.8861s	
14464/22300 (epoch 32.430), train_loss = 0.38551652, grad/param norm = 2.4226e-01, time/batch = 15.3153s	
14465/22300 (epoch 32.433), train_loss = 0.38253532, grad/param norm = 2.2268e-01, time/batch = 18.0523s	
14466/22300 (epoch 32.435), train_loss = 0.38117273, grad/param norm = 2.4533e-01, time/batch = 16.6250s	
14467/22300 (epoch 32.437), train_loss = 0.44698052, grad/param norm = 3.2507e-01, time/batch = 17.7898s	
14468/22300 (epoch 32.439), train_loss = 0.49116777, grad/param norm = 2.5000e-01, time/batch = 15.6521s	
14469/22300 (epoch 32.442), train_loss = 0.42261625, grad/param norm = 2.9283e-01, time/batch = 18.4519s	
14470/22300 (epoch 32.444), train_loss = 0.36422600, grad/param norm = 2.6744e-01, time/batch = 17.6488s	
14471/22300 (epoch 32.446), train_loss = 0.35113408, grad/param norm = 2.4372e-01, time/batch = 16.6243s	
14472/22300 (epoch 32.448), train_loss = 0.26715016, grad/param norm = 2.0023e-01, time/batch = 16.2696s	
14473/22300 (epoch 32.451), train_loss = 0.46691101, grad/param norm = 3.1881e-01, time/batch = 16.2765s	
14474/22300 (epoch 32.453), train_loss = 0.35758073, grad/param norm = 2.7601e-01, time/batch = 18.2723s	
14475/22300 (epoch 32.455), train_loss = 0.50263361, grad/param norm = 3.5943e-01, time/batch = 16.0291s	
14476/22300 (epoch 32.457), train_loss = 0.58563158, grad/param norm = 3.2344e-01, time/batch = 17.2810s	
14477/22300 (epoch 32.460), train_loss = 0.50155255, grad/param norm = 2.5093e-01, time/batch = 16.7221s	
14478/22300 (epoch 32.462), train_loss = 0.52717531, grad/param norm = 2.9304e-01, time/batch = 16.1404s	
14479/22300 (epoch 32.464), train_loss = 0.45572601, grad/param norm = 2.7630e-01, time/batch = 16.3076s	
14480/22300 (epoch 32.466), train_loss = 0.38631240, grad/param norm = 2.3062e-01, time/batch = 17.3005s	
14481/22300 (epoch 32.469), train_loss = 0.36918386, grad/param norm = 2.0910e-01, time/batch = 16.7939s	
14482/22300 (epoch 32.471), train_loss = 0.47922688, grad/param norm = 2.2845e-01, time/batch = 16.5654s	
14483/22300 (epoch 32.473), train_loss = 0.42078452, grad/param norm = 2.0085e-01, time/batch = 15.7379s	
14484/22300 (epoch 32.475), train_loss = 0.38859358, grad/param norm = 2.6586e-01, time/batch = 15.3957s	
14485/22300 (epoch 32.478), train_loss = 0.38460049, grad/param norm = 2.3673e-01, time/batch = 15.4604s	
14486/22300 (epoch 32.480), train_loss = 0.27327188, grad/param norm = 2.1687e-01, time/batch = 14.7337s	
14487/22300 (epoch 32.482), train_loss = 0.31994750, grad/param norm = 2.3858e-01, time/batch = 16.0663s	
14488/22300 (epoch 32.484), train_loss = 0.41190142, grad/param norm = 2.5034e-01, time/batch = 15.8018s	
14489/22300 (epoch 32.487), train_loss = 0.46614403, grad/param norm = 2.4124e-01, time/batch = 14.8308s	
14490/22300 (epoch 32.489), train_loss = 0.48823671, grad/param norm = 2.8439e-01, time/batch = 15.6198s	
14491/22300 (epoch 32.491), train_loss = 0.49299982, grad/param norm = 2.8780e-01, time/batch = 14.4810s	
14492/22300 (epoch 32.493), train_loss = 0.41603140, grad/param norm = 3.6873e-01, time/batch = 15.4421s	
14493/22300 (epoch 32.496), train_loss = 0.41218043, grad/param norm = 2.0322e-01, time/batch = 16.2669s	
14494/22300 (epoch 32.498), train_loss = 0.30679613, grad/param norm = 2.0126e-01, time/batch = 19.1268s	
14495/22300 (epoch 32.500), train_loss = 0.41347524, grad/param norm = 2.5132e-01, time/batch = 15.7170s	
14496/22300 (epoch 32.502), train_loss = 0.27466298, grad/param norm = 2.5609e-01, time/batch = 17.2183s	
14497/22300 (epoch 32.504), train_loss = 0.28993758, grad/param norm = 1.9321e-01, time/batch = 16.3194s	
14498/22300 (epoch 32.507), train_loss = 0.34339595, grad/param norm = 2.1360e-01, time/batch = 17.3112s	
14499/22300 (epoch 32.509), train_loss = 0.47808817, grad/param norm = 2.9310e-01, time/batch = 16.1131s	
14500/22300 (epoch 32.511), train_loss = 0.27161580, grad/param norm = 2.1185e-01, time/batch = 17.8808s	
14501/22300 (epoch 32.513), train_loss = 0.30136166, grad/param norm = 1.9190e-01, time/batch = 15.7186s	
14502/22300 (epoch 32.516), train_loss = 0.34608012, grad/param norm = 2.1967e-01, time/batch = 15.8937s	
14503/22300 (epoch 32.518), train_loss = 0.43316801, grad/param norm = 2.3954e-01, time/batch = 16.1102s	
14504/22300 (epoch 32.520), train_loss = 0.37198408, grad/param norm = 2.3314e-01, time/batch = 17.0515s	
14505/22300 (epoch 32.522), train_loss = 0.38458572, grad/param norm = 2.3884e-01, time/batch = 17.9030s	
14506/22300 (epoch 32.525), train_loss = 0.30298053, grad/param norm = 2.2998e-01, time/batch = 15.4040s	
14507/22300 (epoch 32.527), train_loss = 0.48627285, grad/param norm = 3.0827e-01, time/batch = 15.8095s	
14508/22300 (epoch 32.529), train_loss = 0.43674826, grad/param norm = 2.8266e-01, time/batch = 16.0820s	
14509/22300 (epoch 32.531), train_loss = 0.35552903, grad/param norm = 2.5561e-01, time/batch = 16.8022s	
14510/22300 (epoch 32.534), train_loss = 0.37675988, grad/param norm = 2.5164e-01, time/batch = 15.7076s	
14511/22300 (epoch 32.536), train_loss = 0.56806122, grad/param norm = 2.3462e-01, time/batch = 16.0555s	
14512/22300 (epoch 32.538), train_loss = 0.71548543, grad/param norm = 3.2820e-01, time/batch = 14.9814s	
14513/22300 (epoch 32.540), train_loss = 0.41809333, grad/param norm = 2.4814e-01, time/batch = 15.4482s	
14514/22300 (epoch 32.543), train_loss = 0.38157338, grad/param norm = 2.0249e-01, time/batch = 15.5599s	
14515/22300 (epoch 32.545), train_loss = 0.27862396, grad/param norm = 2.0195e-01, time/batch = 15.0707s	
14516/22300 (epoch 32.547), train_loss = 0.27114740, grad/param norm = 1.9516e-01, time/batch = 15.1598s	
14517/22300 (epoch 32.549), train_loss = 0.31393188, grad/param norm = 2.1310e-01, time/batch = 22.4435s	
14518/22300 (epoch 32.552), train_loss = 0.32161514, grad/param norm = 2.2654e-01, time/batch = 25.0576s	
14519/22300 (epoch 32.554), train_loss = 0.42198761, grad/param norm = 2.4807e-01, time/batch = 17.2177s	
14520/22300 (epoch 32.556), train_loss = 0.60197729, grad/param norm = 3.8137e-01, time/batch = 15.9700s	
14521/22300 (epoch 32.558), train_loss = 0.47217596, grad/param norm = 3.5010e-01, time/batch = 18.9666s	
14522/22300 (epoch 32.561), train_loss = 0.63060631, grad/param norm = 3.7291e-01, time/batch = 16.7219s	
14523/22300 (epoch 32.563), train_loss = 0.53475315, grad/param norm = 3.8817e-01, time/batch = 16.2941s	
14524/22300 (epoch 32.565), train_loss = 0.39367250, grad/param norm = 3.0108e-01, time/batch = 16.7074s	
14525/22300 (epoch 32.567), train_loss = 0.39568305, grad/param norm = 2.3969e-01, time/batch = 17.0739s	
14526/22300 (epoch 32.570), train_loss = 0.55389292, grad/param norm = 3.7015e-01, time/batch = 16.8896s	
14527/22300 (epoch 32.572), train_loss = 0.54165281, grad/param norm = 2.9111e-01, time/batch = 15.9603s	
14528/22300 (epoch 32.574), train_loss = 0.40555595, grad/param norm = 2.2484e-01, time/batch = 16.2148s	
14529/22300 (epoch 32.576), train_loss = 0.35186785, grad/param norm = 2.1658e-01, time/batch = 15.2691s	
14530/22300 (epoch 32.578), train_loss = 0.20280894, grad/param norm = 1.5623e-01, time/batch = 17.1445s	
14531/22300 (epoch 32.581), train_loss = 0.30652011, grad/param norm = 2.2517e-01, time/batch = 15.7168s	
14532/22300 (epoch 32.583), train_loss = 0.35171352, grad/param norm = 2.1165e-01, time/batch = 18.4467s	
14533/22300 (epoch 32.585), train_loss = 0.52410745, grad/param norm = 4.4737e-01, time/batch = 15.3532s	
14534/22300 (epoch 32.587), train_loss = 0.70508399, grad/param norm = 3.7867e-01, time/batch = 17.0250s	
14535/22300 (epoch 32.590), train_loss = 0.57590358, grad/param norm = 3.9664e-01, time/batch = 16.2910s	
14536/22300 (epoch 32.592), train_loss = 0.64346051, grad/param norm = 3.4584e-01, time/batch = 16.7329s	
14537/22300 (epoch 32.594), train_loss = 0.62070810, grad/param norm = 3.3710e-01, time/batch = 17.2758s	
14538/22300 (epoch 32.596), train_loss = 0.40738880, grad/param norm = 2.7172e-01, time/batch = 15.7265s	
14539/22300 (epoch 32.599), train_loss = 0.30799326, grad/param norm = 2.4670e-01, time/batch = 18.1400s	
14540/22300 (epoch 32.601), train_loss = 0.35365969, grad/param norm = 2.8775e-01, time/batch = 17.8741s	
14541/22300 (epoch 32.603), train_loss = 0.40099417, grad/param norm = 2.9395e-01, time/batch = 16.6456s	
14542/22300 (epoch 32.605), train_loss = 0.39809135, grad/param norm = 2.9267e-01, time/batch = 16.3946s	
14543/22300 (epoch 32.608), train_loss = 0.66223409, grad/param norm = 3.5015e-01, time/batch = 17.3090s	
14544/22300 (epoch 32.610), train_loss = 0.69552547, grad/param norm = 3.2710e-01, time/batch = 17.8839s	
14545/22300 (epoch 32.612), train_loss = 0.51318446, grad/param norm = 3.2257e-01, time/batch = 15.8140s	
14546/22300 (epoch 32.614), train_loss = 0.54197629, grad/param norm = 3.5170e-01, time/batch = 18.0424s	
14547/22300 (epoch 32.617), train_loss = 0.53050168, grad/param norm = 2.5787e-01, time/batch = 16.1528s	
14548/22300 (epoch 32.619), train_loss = 0.60244272, grad/param norm = 3.1117e-01, time/batch = 17.9418s	
14549/22300 (epoch 32.621), train_loss = 0.38106993, grad/param norm = 2.6457e-01, time/batch = 17.1379s	
14550/22300 (epoch 32.623), train_loss = 0.38858545, grad/param norm = 2.5773e-01, time/batch = 15.8049s	
14551/22300 (epoch 32.626), train_loss = 0.37352259, grad/param norm = 2.4556e-01, time/batch = 18.6295s	
14552/22300 (epoch 32.628), train_loss = 0.37577462, grad/param norm = 2.3146e-01, time/batch = 15.9289s	
14553/22300 (epoch 32.630), train_loss = 0.43380842, grad/param norm = 2.4138e-01, time/batch = 15.4513s	
14554/22300 (epoch 32.632), train_loss = 0.37167481, grad/param norm = 2.6152e-01, time/batch = 16.5380s	
14555/22300 (epoch 32.635), train_loss = 0.41628992, grad/param norm = 2.4278e-01, time/batch = 17.7078s	
14556/22300 (epoch 32.637), train_loss = 0.46351915, grad/param norm = 2.3708e-01, time/batch = 16.4759s	
14557/22300 (epoch 32.639), train_loss = 0.57288107, grad/param norm = 3.3444e-01, time/batch = 17.3899s	
14558/22300 (epoch 32.641), train_loss = 0.46717795, grad/param norm = 2.8931e-01, time/batch = 15.6527s	
14559/22300 (epoch 32.643), train_loss = 0.35463214, grad/param norm = 2.4340e-01, time/batch = 15.8697s	
14560/22300 (epoch 32.646), train_loss = 0.34529443, grad/param norm = 2.1024e-01, time/batch = 16.2340s	
14561/22300 (epoch 32.648), train_loss = 0.44826104, grad/param norm = 2.4607e-01, time/batch = 15.1213s	
14562/22300 (epoch 32.650), train_loss = 0.47664413, grad/param norm = 2.7516e-01, time/batch = 16.4808s	
14563/22300 (epoch 32.652), train_loss = 0.38073004, grad/param norm = 2.3105e-01, time/batch = 15.3782s	
14564/22300 (epoch 32.655), train_loss = 0.32396926, grad/param norm = 2.1311e-01, time/batch = 15.1296s	
14565/22300 (epoch 32.657), train_loss = 0.37976456, grad/param norm = 2.5712e-01, time/batch = 16.2260s	
14566/22300 (epoch 32.659), train_loss = 0.37807815, grad/param norm = 2.3558e-01, time/batch = 16.5524s	
14567/22300 (epoch 32.661), train_loss = 0.30241577, grad/param norm = 2.4117e-01, time/batch = 17.3659s	
14568/22300 (epoch 32.664), train_loss = 0.35641730, grad/param norm = 2.2098e-01, time/batch = 18.0249s	
14569/22300 (epoch 32.666), train_loss = 0.46633592, grad/param norm = 2.6243e-01, time/batch = 18.1337s	
14570/22300 (epoch 32.668), train_loss = 0.33941377, grad/param norm = 2.1460e-01, time/batch = 15.5463s	
14571/22300 (epoch 32.670), train_loss = 0.44449509, grad/param norm = 2.4777e-01, time/batch = 15.8898s	
14572/22300 (epoch 32.673), train_loss = 0.49262608, grad/param norm = 2.7469e-01, time/batch = 15.2249s	
14573/22300 (epoch 32.675), train_loss = 0.56668358, grad/param norm = 3.1305e-01, time/batch = 16.2386s	
14574/22300 (epoch 32.677), train_loss = 0.62783391, grad/param norm = 3.2088e-01, time/batch = 15.4650s	
14575/22300 (epoch 32.679), train_loss = 0.46802835, grad/param norm = 3.0491e-01, time/batch = 17.3101s	
14576/22300 (epoch 32.682), train_loss = 0.40445121, grad/param norm = 2.3385e-01, time/batch = 17.9638s	
14577/22300 (epoch 32.684), train_loss = 0.40767667, grad/param norm = 2.0622e-01, time/batch = 17.1324s	
14578/22300 (epoch 32.686), train_loss = 0.40646617, grad/param norm = 2.7886e-01, time/batch = 16.2389s	
14579/22300 (epoch 32.688), train_loss = 0.38025306, grad/param norm = 2.5654e-01, time/batch = 17.2115s	
14580/22300 (epoch 32.691), train_loss = 0.33750450, grad/param norm = 2.2745e-01, time/batch = 16.5437s	
14581/22300 (epoch 32.693), train_loss = 0.34020925, grad/param norm = 2.8193e-01, time/batch = 16.6066s	
14582/22300 (epoch 32.695), train_loss = 0.35073847, grad/param norm = 2.1429e-01, time/batch = 15.6099s	
14583/22300 (epoch 32.697), train_loss = 0.37470108, grad/param norm = 2.4316e-01, time/batch = 17.6478s	
14584/22300 (epoch 32.700), train_loss = 0.34926679, grad/param norm = 2.3496e-01, time/batch = 16.9526s	
14585/22300 (epoch 32.702), train_loss = 0.28212117, grad/param norm = 1.8438e-01, time/batch = 15.2274s	
14586/22300 (epoch 32.704), train_loss = 0.37702637, grad/param norm = 2.6545e-01, time/batch = 15.3337s	
14587/22300 (epoch 32.706), train_loss = 0.33553208, grad/param norm = 2.0908e-01, time/batch = 15.5652s	
14588/22300 (epoch 32.709), train_loss = 0.29219761, grad/param norm = 2.1819e-01, time/batch = 15.6467s	
14589/22300 (epoch 32.711), train_loss = 0.27323627, grad/param norm = 1.5095e-01, time/batch = 15.9209s	
14590/22300 (epoch 32.713), train_loss = 0.41536653, grad/param norm = 2.2548e-01, time/batch = 15.2969s	
14591/22300 (epoch 32.715), train_loss = 0.41092016, grad/param norm = 2.4226e-01, time/batch = 16.4630s	
14592/22300 (epoch 32.717), train_loss = 0.56584848, grad/param norm = 2.6302e-01, time/batch = 16.2987s	
14593/22300 (epoch 32.720), train_loss = 0.35536213, grad/param norm = 2.4306e-01, time/batch = 17.5375s	
14594/22300 (epoch 32.722), train_loss = 0.41484889, grad/param norm = 2.5337e-01, time/batch = 16.3191s	
14595/22300 (epoch 32.724), train_loss = 0.45979048, grad/param norm = 2.9719e-01, time/batch = 16.8031s	
14596/22300 (epoch 32.726), train_loss = 0.36498673, grad/param norm = 2.8038e-01, time/batch = 16.1339s	
14597/22300 (epoch 32.729), train_loss = 0.41073351, grad/param norm = 2.4738e-01, time/batch = 17.6385s	
14598/22300 (epoch 32.731), train_loss = 0.56849529, grad/param norm = 4.1221e-01, time/batch = 18.2629s	
14599/22300 (epoch 32.733), train_loss = 0.54671103, grad/param norm = 3.0685e-01, time/batch = 15.9121s	
14600/22300 (epoch 32.735), train_loss = 0.60648610, grad/param norm = 3.4777e-01, time/batch = 16.2818s	
14601/22300 (epoch 32.738), train_loss = 0.43622703, grad/param norm = 3.1376e-01, time/batch = 17.2218s	
14602/22300 (epoch 32.740), train_loss = 0.39162381, grad/param norm = 2.4947e-01, time/batch = 18.2898s	
14603/22300 (epoch 32.742), train_loss = 0.34781519, grad/param norm = 2.3057e-01, time/batch = 16.1423s	
14604/22300 (epoch 32.744), train_loss = 0.61847052, grad/param norm = 3.2395e-01, time/batch = 16.7272s	
14605/22300 (epoch 32.747), train_loss = 0.49129171, grad/param norm = 2.5502e-01, time/batch = 17.4016s	
14606/22300 (epoch 32.749), train_loss = 0.59927276, grad/param norm = 3.2594e-01, time/batch = 16.5830s	
14607/22300 (epoch 32.751), train_loss = 0.56035639, grad/param norm = 4.0473e-01, time/batch = 15.3997s	
14608/22300 (epoch 32.753), train_loss = 0.60526573, grad/param norm = 3.6028e-01, time/batch = 16.1541s	
14609/22300 (epoch 32.756), train_loss = 0.51054609, grad/param norm = 2.7207e-01, time/batch = 17.1439s	
14610/22300 (epoch 32.758), train_loss = 0.44360874, grad/param norm = 2.4664e-01, time/batch = 15.1989s	
14611/22300 (epoch 32.760), train_loss = 0.48034212, grad/param norm = 2.6708e-01, time/batch = 16.8889s	
14612/22300 (epoch 32.762), train_loss = 0.45845983, grad/param norm = 2.8690e-01, time/batch = 14.9244s	
14613/22300 (epoch 32.765), train_loss = 0.47853880, grad/param norm = 3.3868e-01, time/batch = 15.6140s	
14614/22300 (epoch 32.767), train_loss = 0.47953872, grad/param norm = 2.9123e-01, time/batch = 15.2268s	
14615/22300 (epoch 32.769), train_loss = 0.46166925, grad/param norm = 2.9882e-01, time/batch = 16.8775s	
14616/22300 (epoch 32.771), train_loss = 0.51108252, grad/param norm = 2.9154e-01, time/batch = 15.3148s	
14617/22300 (epoch 32.774), train_loss = 0.56327657, grad/param norm = 3.7707e-01, time/batch = 15.0613s	
14618/22300 (epoch 32.776), train_loss = 0.56256988, grad/param norm = 2.8401e-01, time/batch = 15.4468s	
14619/22300 (epoch 32.778), train_loss = 0.55306762, grad/param norm = 3.0976e-01, time/batch = 16.9601s	
14620/22300 (epoch 32.780), train_loss = 0.55338997, grad/param norm = 3.0169e-01, time/batch = 16.8973s	
14621/22300 (epoch 32.783), train_loss = 0.57278314, grad/param norm = 3.2678e-01, time/batch = 15.8678s	
14622/22300 (epoch 32.785), train_loss = 0.44517368, grad/param norm = 3.0550e-01, time/batch = 16.8841s	
14623/22300 (epoch 32.787), train_loss = 0.41908457, grad/param norm = 2.7308e-01, time/batch = 15.8868s	
14624/22300 (epoch 32.789), train_loss = 0.61620722, grad/param norm = 4.0856e-01, time/batch = 17.8923s	
14625/22300 (epoch 32.791), train_loss = 0.74668329, grad/param norm = 4.0236e-01, time/batch = 15.0386s	
14626/22300 (epoch 32.794), train_loss = 0.58184405, grad/param norm = 3.2607e-01, time/batch = 18.4661s	
14627/22300 (epoch 32.796), train_loss = 0.54356650, grad/param norm = 3.1431e-01, time/batch = 15.9011s	
14628/22300 (epoch 32.798), train_loss = 0.69263526, grad/param norm = 3.7064e-01, time/batch = 16.1452s	
14629/22300 (epoch 32.800), train_loss = 0.49384652, grad/param norm = 3.1826e-01, time/batch = 16.4778s	
14630/22300 (epoch 32.803), train_loss = 0.41048558, grad/param norm = 2.3591e-01, time/batch = 15.8821s	
14631/22300 (epoch 32.805), train_loss = 0.47644741, grad/param norm = 2.5442e-01, time/batch = 15.8624s	
14632/22300 (epoch 32.807), train_loss = 0.60601328, grad/param norm = 3.2754e-01, time/batch = 16.1422s	
14633/22300 (epoch 32.809), train_loss = 0.44929166, grad/param norm = 2.9946e-01, time/batch = 15.8928s	
14634/22300 (epoch 32.812), train_loss = 0.51183028, grad/param norm = 2.9840e-01, time/batch = 17.6213s	
14635/22300 (epoch 32.814), train_loss = 0.51159745, grad/param norm = 3.2807e-01, time/batch = 15.6542s	
14636/22300 (epoch 32.816), train_loss = 0.53353165, grad/param norm = 3.1747e-01, time/batch = 16.0408s	
14637/22300 (epoch 32.818), train_loss = 0.60738048, grad/param norm = 3.0394e-01, time/batch = 17.2068s	
14638/22300 (epoch 32.821), train_loss = 0.51999287, grad/param norm = 3.1804e-01, time/batch = 17.3897s	
14639/22300 (epoch 32.823), train_loss = 0.34949211, grad/param norm = 2.7284e-01, time/batch = 17.1982s	
14640/22300 (epoch 32.825), train_loss = 0.37296618, grad/param norm = 2.5862e-01, time/batch = 15.9575s	
14641/22300 (epoch 32.827), train_loss = 0.42370738, grad/param norm = 2.4785e-01, time/batch = 14.5617s	
14642/22300 (epoch 32.830), train_loss = 0.41229273, grad/param norm = 2.5384e-01, time/batch = 14.3962s	
14643/22300 (epoch 32.832), train_loss = 0.39571687, grad/param norm = 2.6922e-01, time/batch = 15.1694s	
14644/22300 (epoch 32.834), train_loss = 0.32925289, grad/param norm = 2.1320e-01, time/batch = 14.4824s	
14645/22300 (epoch 32.836), train_loss = 0.41405020, grad/param norm = 2.5989e-01, time/batch = 14.7192s	
14646/22300 (epoch 32.839), train_loss = 0.42431369, grad/param norm = 2.9751e-01, time/batch = 15.8763s	
14647/22300 (epoch 32.841), train_loss = 0.45314337, grad/param norm = 3.2959e-01, time/batch = 15.3938s	
14648/22300 (epoch 32.843), train_loss = 0.42541259, grad/param norm = 2.4357e-01, time/batch = 17.1419s	
14649/22300 (epoch 32.845), train_loss = 0.41205541, grad/param norm = 2.3293e-01, time/batch = 16.7257s	
14650/22300 (epoch 32.848), train_loss = 0.41410894, grad/param norm = 2.7215e-01, time/batch = 17.2242s	
14651/22300 (epoch 32.850), train_loss = 0.41771944, grad/param norm = 2.0640e-01, time/batch = 16.1292s	
14652/22300 (epoch 32.852), train_loss = 0.40010711, grad/param norm = 2.6025e-01, time/batch = 18.9831s	
14653/22300 (epoch 32.854), train_loss = 0.63331947, grad/param norm = 3.3605e-01, time/batch = 16.2256s	
14654/22300 (epoch 32.857), train_loss = 0.48945960, grad/param norm = 2.9244e-01, time/batch = 15.1540s	
14655/22300 (epoch 32.859), train_loss = 0.37899431, grad/param norm = 2.1245e-01, time/batch = 15.7069s	
14656/22300 (epoch 32.861), train_loss = 0.51388087, grad/param norm = 2.5402e-01, time/batch = 17.1509s	
14657/22300 (epoch 32.863), train_loss = 0.36337858, grad/param norm = 2.7193e-01, time/batch = 16.6885s	
14658/22300 (epoch 32.865), train_loss = 0.35252967, grad/param norm = 2.3497e-01, time/batch = 16.0507s	
14659/22300 (epoch 32.868), train_loss = 0.46530821, grad/param norm = 2.4144e-01, time/batch = 17.4714s	
14660/22300 (epoch 32.870), train_loss = 0.45954166, grad/param norm = 2.5834e-01, time/batch = 16.3814s	
14661/22300 (epoch 32.872), train_loss = 0.56719744, grad/param norm = 2.9789e-01, time/batch = 16.0204s	
14662/22300 (epoch 32.874), train_loss = 0.49814102, grad/param norm = 3.2219e-01, time/batch = 3.8848s	
14663/22300 (epoch 32.877), train_loss = 0.45870379, grad/param norm = 2.4521e-01, time/batch = 0.6687s	
14664/22300 (epoch 32.879), train_loss = 0.42192180, grad/param norm = 2.4517e-01, time/batch = 0.6637s	
14665/22300 (epoch 32.881), train_loss = 0.35001158, grad/param norm = 2.1309e-01, time/batch = 0.6647s	
14666/22300 (epoch 32.883), train_loss = 0.36483408, grad/param norm = 2.6569e-01, time/batch = 0.6583s	
14667/22300 (epoch 32.886), train_loss = 0.34142612, grad/param norm = 2.6781e-01, time/batch = 0.6549s	
14668/22300 (epoch 32.888), train_loss = 0.41593046, grad/param norm = 2.5674e-01, time/batch = 0.6563s	
14669/22300 (epoch 32.890), train_loss = 0.39839589, grad/param norm = 2.5337e-01, time/batch = 0.7366s	
14670/22300 (epoch 32.892), train_loss = 0.63117664, grad/param norm = 3.5451e-01, time/batch = 0.9638s	
14671/22300 (epoch 32.895), train_loss = 0.57126150, grad/param norm = 4.1538e-01, time/batch = 0.9649s	
14672/22300 (epoch 32.897), train_loss = 0.44438716, grad/param norm = 3.0571e-01, time/batch = 0.9616s	
14673/22300 (epoch 32.899), train_loss = 0.43227909, grad/param norm = 2.5800e-01, time/batch = 0.9512s	
14674/22300 (epoch 32.901), train_loss = 0.49950222, grad/param norm = 2.8528e-01, time/batch = 1.0315s	
14675/22300 (epoch 32.904), train_loss = 0.52169107, grad/param norm = 2.8234e-01, time/batch = 1.7982s	
14676/22300 (epoch 32.906), train_loss = 0.49178362, grad/param norm = 2.9354e-01, time/batch = 1.8726s	
14677/22300 (epoch 32.908), train_loss = 0.42807732, grad/param norm = 2.4791e-01, time/batch = 6.8630s	
14678/22300 (epoch 32.910), train_loss = 0.37731978, grad/param norm = 2.2568e-01, time/batch = 16.2179s	
14679/22300 (epoch 32.913), train_loss = 0.51568348, grad/param norm = 2.9111e-01, time/batch = 17.3815s	
14680/22300 (epoch 32.915), train_loss = 0.60316891, grad/param norm = 2.7461e-01, time/batch = 15.8709s	
14681/22300 (epoch 32.917), train_loss = 0.50531297, grad/param norm = 2.7550e-01, time/batch = 16.2945s	
14682/22300 (epoch 32.919), train_loss = 0.49697424, grad/param norm = 2.3451e-01, time/batch = 18.6973s	
14683/22300 (epoch 32.922), train_loss = 0.48848584, grad/param norm = 3.8444e-01, time/batch = 15.6968s	
14684/22300 (epoch 32.924), train_loss = 0.29945572, grad/param norm = 2.2280e-01, time/batch = 16.6258s	
14685/22300 (epoch 32.926), train_loss = 0.37724286, grad/param norm = 2.4997e-01, time/batch = 16.1546s	
14686/22300 (epoch 32.928), train_loss = 0.40042165, grad/param norm = 2.5511e-01, time/batch = 18.5335s	
14687/22300 (epoch 32.930), train_loss = 0.40227902, grad/param norm = 2.3623e-01, time/batch = 15.4683s	
14688/22300 (epoch 32.933), train_loss = 0.50736490, grad/param norm = 3.1296e-01, time/batch = 14.7253s	
14689/22300 (epoch 32.935), train_loss = 0.48908253, grad/param norm = 3.5115e-01, time/batch = 15.1410s	
14690/22300 (epoch 32.937), train_loss = 0.55914812, grad/param norm = 3.5960e-01, time/batch = 16.4732s	
14691/22300 (epoch 32.939), train_loss = 0.52156958, grad/param norm = 3.4691e-01, time/batch = 16.2355s	
14692/22300 (epoch 32.942), train_loss = 0.65198150, grad/param norm = 3.8889e-01, time/batch = 16.2995s	
14693/22300 (epoch 32.944), train_loss = 0.69153377, grad/param norm = 4.3928e-01, time/batch = 18.1385s	
14694/22300 (epoch 32.946), train_loss = 0.49204069, grad/param norm = 3.0123e-01, time/batch = 16.4548s	
14695/22300 (epoch 32.948), train_loss = 0.40121773, grad/param norm = 2.1550e-01, time/batch = 16.5619s	
14696/22300 (epoch 32.951), train_loss = 0.33127225, grad/param norm = 2.4645e-01, time/batch = 15.5811s	
14697/22300 (epoch 32.953), train_loss = 0.39723647, grad/param norm = 2.8748e-01, time/batch = 17.2220s	
14698/22300 (epoch 32.955), train_loss = 0.57723447, grad/param norm = 3.0475e-01, time/batch = 15.3110s	
14699/22300 (epoch 32.957), train_loss = 0.65214038, grad/param norm = 3.0566e-01, time/batch = 16.8167s	
14700/22300 (epoch 32.960), train_loss = 0.57062926, grad/param norm = 2.9646e-01, time/batch = 17.3163s	
14701/22300 (epoch 32.962), train_loss = 0.38223622, grad/param norm = 2.7473e-01, time/batch = 15.6449s	
14702/22300 (epoch 32.964), train_loss = 0.40867231, grad/param norm = 2.7560e-01, time/batch = 15.4758s	
14703/22300 (epoch 32.966), train_loss = 0.38853306, grad/param norm = 2.6037e-01, time/batch = 15.9667s	
14704/22300 (epoch 32.969), train_loss = 0.42720811, grad/param norm = 2.7884e-01, time/batch = 17.2252s	
14705/22300 (epoch 32.971), train_loss = 0.45375290, grad/param norm = 2.5925e-01, time/batch = 15.7329s	
14706/22300 (epoch 32.973), train_loss = 0.46550919, grad/param norm = 2.9781e-01, time/batch = 16.3807s	
14707/22300 (epoch 32.975), train_loss = 0.61147734, grad/param norm = 3.5767e-01, time/batch = 16.2381s	
14708/22300 (epoch 32.978), train_loss = 0.56155146, grad/param norm = 3.0845e-01, time/batch = 17.2243s	
14709/22300 (epoch 32.980), train_loss = 0.64361779, grad/param norm = 3.6032e-01, time/batch = 15.6263s	
14710/22300 (epoch 32.982), train_loss = 0.35551698, grad/param norm = 2.7448e-01, time/batch = 18.5414s	
14711/22300 (epoch 32.984), train_loss = 0.44097424, grad/param norm = 2.2598e-01, time/batch = 17.8756s	
14712/22300 (epoch 32.987), train_loss = 0.41647738, grad/param norm = 2.5796e-01, time/batch = 16.0414s	
14713/22300 (epoch 32.989), train_loss = 0.39258973, grad/param norm = 3.0355e-01, time/batch = 17.1290s	
14714/22300 (epoch 32.991), train_loss = 0.64542103, grad/param norm = 3.2050e-01, time/batch = 16.3950s	
14715/22300 (epoch 32.993), train_loss = 0.83907226, grad/param norm = 3.6255e-01, time/batch = 17.0570s	
14716/22300 (epoch 32.996), train_loss = 0.81883336, grad/param norm = 4.1738e-01, time/batch = 17.0460s	
14717/22300 (epoch 32.998), train_loss = 0.47553683, grad/param norm = 2.4119e-01, time/batch = 16.4693s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
14718/22300 (epoch 33.000), train_loss = 0.38106596, grad/param norm = 2.5244e-01, time/batch = 16.7145s	
14719/22300 (epoch 33.002), train_loss = 0.74831207, grad/param norm = 3.1783e-01, time/batch = 16.6412s	
14720/22300 (epoch 33.004), train_loss = 0.50295815, grad/param norm = 2.4483e-01, time/batch = 15.8777s	
14721/22300 (epoch 33.007), train_loss = 0.52647588, grad/param norm = 3.3882e-01, time/batch = 16.1596s	
14722/22300 (epoch 33.009), train_loss = 0.55827590, grad/param norm = 3.1854e-01, time/batch = 18.8902s	
14723/22300 (epoch 33.011), train_loss = 0.68117227, grad/param norm = 3.6660e-01, time/batch = 15.8090s	
14724/22300 (epoch 33.013), train_loss = 0.51132310, grad/param norm = 2.5989e-01, time/batch = 17.3870s	
14725/22300 (epoch 33.016), train_loss = 0.41201887, grad/param norm = 2.7921e-01, time/batch = 15.3989s	
14726/22300 (epoch 33.018), train_loss = 0.48262863, grad/param norm = 3.5280e-01, time/batch = 17.0560s	
14727/22300 (epoch 33.020), train_loss = 0.43966213, grad/param norm = 2.7660e-01, time/batch = 17.0437s	
14728/22300 (epoch 33.022), train_loss = 0.38194523, grad/param norm = 2.9972e-01, time/batch = 16.3043s	
14729/22300 (epoch 33.025), train_loss = 0.40831269, grad/param norm = 2.5527e-01, time/batch = 16.7228s	
14730/22300 (epoch 33.027), train_loss = 0.38764934, grad/param norm = 2.5557e-01, time/batch = 16.4413s	
14731/22300 (epoch 33.029), train_loss = 0.40525884, grad/param norm = 2.2193e-01, time/batch = 17.9756s	
14732/22300 (epoch 33.031), train_loss = 0.39467217, grad/param norm = 2.4065e-01, time/batch = 16.0515s	
14733/22300 (epoch 33.034), train_loss = 0.40275985, grad/param norm = 2.6676e-01, time/batch = 16.7939s	
14734/22300 (epoch 33.036), train_loss = 0.34706353, grad/param norm = 1.8780e-01, time/batch = 16.1354s	
14735/22300 (epoch 33.038), train_loss = 0.36247845, grad/param norm = 2.4978e-01, time/batch = 18.6343s	
14736/22300 (epoch 33.040), train_loss = 0.40479558, grad/param norm = 2.6216e-01, time/batch = 17.9698s	
14737/22300 (epoch 33.043), train_loss = 0.63445873, grad/param norm = 3.3140e-01, time/batch = 15.5183s	
14738/22300 (epoch 33.045), train_loss = 0.53782800, grad/param norm = 2.6032e-01, time/batch = 17.5404s	
14739/22300 (epoch 33.047), train_loss = 0.56112572, grad/param norm = 3.0669e-01, time/batch = 16.4109s	
14740/22300 (epoch 33.049), train_loss = 0.41988103, grad/param norm = 2.2133e-01, time/batch = 16.6093s	
14741/22300 (epoch 33.052), train_loss = 0.51793639, grad/param norm = 3.4306e-01, time/batch = 15.4440s	
14742/22300 (epoch 33.054), train_loss = 0.50740782, grad/param norm = 2.9241e-01, time/batch = 17.0570s	
14743/22300 (epoch 33.056), train_loss = 0.26153368, grad/param norm = 1.9262e-01, time/batch = 16.0715s	
14744/22300 (epoch 33.058), train_loss = 0.43379029, grad/param norm = 2.8899e-01, time/batch = 17.4683s	
14745/22300 (epoch 33.061), train_loss = 0.38270971, grad/param norm = 2.7400e-01, time/batch = 17.7031s	
14746/22300 (epoch 33.063), train_loss = 0.60773404, grad/param norm = 4.0573e-01, time/batch = 15.8146s	
14747/22300 (epoch 33.065), train_loss = 0.64655899, grad/param norm = 3.6545e-01, time/batch = 15.1233s	
14748/22300 (epoch 33.067), train_loss = 0.38096109, grad/param norm = 2.4184e-01, time/batch = 30.8006s	
14749/22300 (epoch 33.070), train_loss = 0.47103522, grad/param norm = 2.6975e-01, time/batch = 16.2337s	
14750/22300 (epoch 33.072), train_loss = 0.53296481, grad/param norm = 3.8312e-01, time/batch = 16.4680s	
14751/22300 (epoch 33.074), train_loss = 0.48279615, grad/param norm = 2.5634e-01, time/batch = 17.9571s	
14752/22300 (epoch 33.076), train_loss = 0.50679146, grad/param norm = 2.9312e-01, time/batch = 16.5364s	
14753/22300 (epoch 33.078), train_loss = 0.57506132, grad/param norm = 2.8838e-01, time/batch = 17.2180s	
14754/22300 (epoch 33.081), train_loss = 0.60328505, grad/param norm = 3.4420e-01, time/batch = 16.6238s	
14755/22300 (epoch 33.083), train_loss = 0.69447849, grad/param norm = 3.6987e-01, time/batch = 17.5642s	
14756/22300 (epoch 33.085), train_loss = 0.66869099, grad/param norm = 3.7926e-01, time/batch = 15.5607s	
14757/22300 (epoch 33.087), train_loss = 0.53958975, grad/param norm = 3.1313e-01, time/batch = 18.3781s	
14758/22300 (epoch 33.090), train_loss = 0.47663131, grad/param norm = 2.6604e-01, time/batch = 15.3787s	
14759/22300 (epoch 33.092), train_loss = 0.39634131, grad/param norm = 2.8276e-01, time/batch = 16.5700s	
14760/22300 (epoch 33.094), train_loss = 0.36578634, grad/param norm = 2.3120e-01, time/batch = 17.8055s	
14761/22300 (epoch 33.096), train_loss = 0.64032946, grad/param norm = 3.4557e-01, time/batch = 16.9751s	
14762/22300 (epoch 33.099), train_loss = 0.41373979, grad/param norm = 2.2178e-01, time/batch = 16.2320s	
14763/22300 (epoch 33.101), train_loss = 0.55390084, grad/param norm = 2.8341e-01, time/batch = 17.2197s	
14764/22300 (epoch 33.103), train_loss = 0.43889173, grad/param norm = 2.2433e-01, time/batch = 17.4740s	
14765/22300 (epoch 33.105), train_loss = 0.35990213, grad/param norm = 2.4764e-01, time/batch = 17.6816s	
14766/22300 (epoch 33.108), train_loss = 0.50404272, grad/param norm = 2.7036e-01, time/batch = 16.4015s	
14767/22300 (epoch 33.110), train_loss = 0.54904330, grad/param norm = 2.6762e-01, time/batch = 16.1899s	
14768/22300 (epoch 33.112), train_loss = 0.50359862, grad/param norm = 2.7595e-01, time/batch = 16.3912s	
14769/22300 (epoch 33.114), train_loss = 0.55105241, grad/param norm = 2.8926e-01, time/batch = 16.0641s	
14770/22300 (epoch 33.117), train_loss = 0.61551878, grad/param norm = 3.1385e-01, time/batch = 16.3009s	
14771/22300 (epoch 33.119), train_loss = 0.55592300, grad/param norm = 2.9113e-01, time/batch = 18.2066s	
14772/22300 (epoch 33.121), train_loss = 0.64869799, grad/param norm = 3.2521e-01, time/batch = 15.7008s	
14773/22300 (epoch 33.123), train_loss = 0.67437578, grad/param norm = 3.0173e-01, time/batch = 17.7845s	
14774/22300 (epoch 33.126), train_loss = 0.50560564, grad/param norm = 2.7495e-01, time/batch = 16.2289s	
14775/22300 (epoch 33.128), train_loss = 0.51394618, grad/param norm = 3.0134e-01, time/batch = 17.5355s	
14776/22300 (epoch 33.130), train_loss = 0.42065034, grad/param norm = 2.3455e-01, time/batch = 15.1377s	
14777/22300 (epoch 33.132), train_loss = 0.32041266, grad/param norm = 2.0841e-01, time/batch = 14.9663s	
14778/22300 (epoch 33.135), train_loss = 0.35100490, grad/param norm = 2.6379e-01, time/batch = 17.4517s	
14779/22300 (epoch 33.137), train_loss = 0.27781723, grad/param norm = 1.9716e-01, time/batch = 15.6526s	
14780/22300 (epoch 33.139), train_loss = 0.43156305, grad/param norm = 2.8216e-01, time/batch = 16.5629s	
14781/22300 (epoch 33.141), train_loss = 0.54547571, grad/param norm = 2.5807e-01, time/batch = 16.8922s	
14782/22300 (epoch 33.143), train_loss = 0.47170912, grad/param norm = 2.7397e-01, time/batch = 18.3589s	
14783/22300 (epoch 33.146), train_loss = 0.57058251, grad/param norm = 3.2727e-01, time/batch = 16.1902s	
14784/22300 (epoch 33.148), train_loss = 0.39502603, grad/param norm = 2.7134e-01, time/batch = 17.2121s	
14785/22300 (epoch 33.150), train_loss = 0.43887247, grad/param norm = 2.5863e-01, time/batch = 15.4933s	
14786/22300 (epoch 33.152), train_loss = 0.35402768, grad/param norm = 2.5223e-01, time/batch = 16.3835s	
14787/22300 (epoch 33.155), train_loss = 0.40893395, grad/param norm = 2.8497e-01, time/batch = 17.4645s	
14788/22300 (epoch 33.157), train_loss = 0.50369905, grad/param norm = 3.3123e-01, time/batch = 16.2007s	
14789/22300 (epoch 33.159), train_loss = 0.53041049, grad/param norm = 2.8852e-01, time/batch = 16.7155s	
14790/22300 (epoch 33.161), train_loss = 0.53304396, grad/param norm = 2.8716e-01, time/batch = 16.2976s	
14791/22300 (epoch 33.164), train_loss = 0.39578270, grad/param norm = 2.3363e-01, time/batch = 18.0537s	
14792/22300 (epoch 33.166), train_loss = 0.32665600, grad/param norm = 1.9127e-01, time/batch = 15.5655s	
14793/22300 (epoch 33.168), train_loss = 0.36393180, grad/param norm = 2.8352e-01, time/batch = 16.7294s	
14794/22300 (epoch 33.170), train_loss = 0.47660114, grad/param norm = 2.9127e-01, time/batch = 15.4510s	
14795/22300 (epoch 33.173), train_loss = 0.54726701, grad/param norm = 3.1534e-01, time/batch = 16.6991s	
14796/22300 (epoch 33.175), train_loss = 0.48775282, grad/param norm = 3.7044e-01, time/batch = 15.8277s	
14797/22300 (epoch 33.177), train_loss = 0.34620147, grad/param norm = 2.5351e-01, time/batch = 16.0514s	
14798/22300 (epoch 33.179), train_loss = 0.45686851, grad/param norm = 2.5577e-01, time/batch = 15.9470s	
14799/22300 (epoch 33.182), train_loss = 0.61670800, grad/param norm = 3.1070e-01, time/batch = 16.8788s	
14800/22300 (epoch 33.184), train_loss = 0.66861326, grad/param norm = 3.1971e-01, time/batch = 18.0303s	
14801/22300 (epoch 33.186), train_loss = 0.51708721, grad/param norm = 3.5561e-01, time/batch = 16.2731s	
14802/22300 (epoch 33.188), train_loss = 0.68200001, grad/param norm = 3.5405e-01, time/batch = 14.9250s	
14803/22300 (epoch 33.191), train_loss = 0.57606014, grad/param norm = 3.4494e-01, time/batch = 14.7294s	
14804/22300 (epoch 33.193), train_loss = 0.51221400, grad/param norm = 3.0795e-01, time/batch = 17.3651s	
14805/22300 (epoch 33.195), train_loss = 0.47670374, grad/param norm = 3.2874e-01, time/batch = 15.7117s	
14806/22300 (epoch 33.197), train_loss = 0.41271168, grad/param norm = 2.4792e-01, time/batch = 17.8864s	
14807/22300 (epoch 33.200), train_loss = 0.36570435, grad/param norm = 2.4612e-01, time/batch = 16.8168s	
14808/22300 (epoch 33.202), train_loss = 0.39213618, grad/param norm = 2.1668e-01, time/batch = 17.4594s	
14809/22300 (epoch 33.204), train_loss = 0.47558333, grad/param norm = 2.5685e-01, time/batch = 16.5587s	
14810/22300 (epoch 33.206), train_loss = 0.38068408, grad/param norm = 2.5674e-01, time/batch = 17.0488s	
14811/22300 (epoch 33.209), train_loss = 0.41328408, grad/param norm = 2.3572e-01, time/batch = 17.8757s	
14812/22300 (epoch 33.211), train_loss = 0.34416193, grad/param norm = 2.8147e-01, time/batch = 15.9418s	
14813/22300 (epoch 33.213), train_loss = 0.47068585, grad/param norm = 2.4562e-01, time/batch = 17.3753s	
14814/22300 (epoch 33.215), train_loss = 0.59675167, grad/param norm = 2.9400e-01, time/batch = 15.9006s	
14815/22300 (epoch 33.217), train_loss = 0.61706657, grad/param norm = 3.0399e-01, time/batch = 16.0387s	
14816/22300 (epoch 33.220), train_loss = 0.43937938, grad/param norm = 2.3914e-01, time/batch = 16.2270s	
14817/22300 (epoch 33.222), train_loss = 0.40285077, grad/param norm = 3.2724e-01, time/batch = 16.5550s	
14818/22300 (epoch 33.224), train_loss = 0.41411003, grad/param norm = 2.8449e-01, time/batch = 16.9816s	
14819/22300 (epoch 33.226), train_loss = 0.45114354, grad/param norm = 2.7750e-01, time/batch = 15.9713s	
14820/22300 (epoch 33.229), train_loss = 0.36993314, grad/param norm = 2.6985e-01, time/batch = 15.9503s	
14821/22300 (epoch 33.231), train_loss = 0.57049391, grad/param norm = 3.1662e-01, time/batch = 16.0588s	
14822/22300 (epoch 33.233), train_loss = 0.46984309, grad/param norm = 2.6602e-01, time/batch = 17.5573s	
14823/22300 (epoch 33.235), train_loss = 0.35879832, grad/param norm = 2.2293e-01, time/batch = 16.7176s	
14824/22300 (epoch 33.238), train_loss = 0.38941335, grad/param norm = 2.3908e-01, time/batch = 16.1390s	
14825/22300 (epoch 33.240), train_loss = 0.37888285, grad/param norm = 1.9509e-01, time/batch = 17.7288s	
14826/22300 (epoch 33.242), train_loss = 0.35370745, grad/param norm = 2.5180e-01, time/batch = 15.2263s	
14827/22300 (epoch 33.244), train_loss = 0.24842865, grad/param norm = 1.8427e-01, time/batch = 16.5644s	
14828/22300 (epoch 33.247), train_loss = 0.34357906, grad/param norm = 2.0060e-01, time/batch = 17.3199s	
14829/22300 (epoch 33.249), train_loss = 0.24993080, grad/param norm = 1.9219e-01, time/batch = 17.4494s	
14830/22300 (epoch 33.251), train_loss = 0.32876279, grad/param norm = 2.0827e-01, time/batch = 15.3450s	
14831/22300 (epoch 33.253), train_loss = 0.22716569, grad/param norm = 1.9149e-01, time/batch = 16.7243s	
14832/22300 (epoch 33.256), train_loss = 0.31774546, grad/param norm = 1.9159e-01, time/batch = 16.0133s	
14833/22300 (epoch 33.258), train_loss = 0.46642387, grad/param norm = 2.9428e-01, time/batch = 15.8980s	
14834/22300 (epoch 33.260), train_loss = 0.47065009, grad/param norm = 2.9392e-01, time/batch = 16.4779s	
14835/22300 (epoch 33.262), train_loss = 0.36047931, grad/param norm = 2.1999e-01, time/batch = 17.8749s	
14836/22300 (epoch 33.265), train_loss = 0.34011095, grad/param norm = 2.7130e-01, time/batch = 16.8041s	
14837/22300 (epoch 33.267), train_loss = 0.35904674, grad/param norm = 2.2274e-01, time/batch = 18.2575s	
14838/22300 (epoch 33.269), train_loss = 0.44148162, grad/param norm = 3.0131e-01, time/batch = 17.0428s	
14839/22300 (epoch 33.271), train_loss = 0.48695427, grad/param norm = 2.4396e-01, time/batch = 17.3233s	
14840/22300 (epoch 33.274), train_loss = 0.36096706, grad/param norm = 3.2157e-01, time/batch = 16.2027s	
14841/22300 (epoch 33.276), train_loss = 0.29710930, grad/param norm = 1.8436e-01, time/batch = 18.1256s	
14842/22300 (epoch 33.278), train_loss = 0.31162327, grad/param norm = 2.0699e-01, time/batch = 15.9738s	
14843/22300 (epoch 33.280), train_loss = 0.35535655, grad/param norm = 2.2597e-01, time/batch = 18.6242s	
14844/22300 (epoch 33.283), train_loss = 0.27383002, grad/param norm = 1.7134e-01, time/batch = 17.8642s	
14845/22300 (epoch 33.285), train_loss = 0.30797918, grad/param norm = 2.3403e-01, time/batch = 18.2285s	
14846/22300 (epoch 33.287), train_loss = 0.44312689, grad/param norm = 2.3496e-01, time/batch = 16.8862s	
14847/22300 (epoch 33.289), train_loss = 0.40049827, grad/param norm = 2.1780e-01, time/batch = 15.8682s	
14848/22300 (epoch 33.291), train_loss = 0.40003525, grad/param norm = 2.3779e-01, time/batch = 15.5583s	
14849/22300 (epoch 33.294), train_loss = 0.31865159, grad/param norm = 1.8721e-01, time/batch = 16.4685s	
14850/22300 (epoch 33.296), train_loss = 0.39182240, grad/param norm = 3.0008e-01, time/batch = 19.1132s	
14851/22300 (epoch 33.298), train_loss = 0.51497007, grad/param norm = 2.6570e-01, time/batch = 15.6212s	
14852/22300 (epoch 33.300), train_loss = 0.58167199, grad/param norm = 3.1403e-01, time/batch = 17.0676s	
14853/22300 (epoch 33.303), train_loss = 0.44269426, grad/param norm = 2.5969e-01, time/batch = 15.4745s	
14854/22300 (epoch 33.305), train_loss = 0.43263188, grad/param norm = 3.4262e-01, time/batch = 17.3488s	
14855/22300 (epoch 33.307), train_loss = 0.38178109, grad/param norm = 2.6560e-01, time/batch = 16.7109s	
14856/22300 (epoch 33.309), train_loss = 0.33030955, grad/param norm = 1.9861e-01, time/batch = 15.3360s	
14857/22300 (epoch 33.312), train_loss = 0.30995694, grad/param norm = 2.0116e-01, time/batch = 18.0412s	
14858/22300 (epoch 33.314), train_loss = 0.33396253, grad/param norm = 2.6749e-01, time/batch = 16.7897s	
14859/22300 (epoch 33.316), train_loss = 0.32864681, grad/param norm = 2.2385e-01, time/batch = 16.6315s	
14860/22300 (epoch 33.318), train_loss = 0.37954560, grad/param norm = 2.6714e-01, time/batch = 16.8986s	
14861/22300 (epoch 33.321), train_loss = 0.47099473, grad/param norm = 2.5428e-01, time/batch = 17.1347s	
14862/22300 (epoch 33.323), train_loss = 0.32626866, grad/param norm = 2.1469e-01, time/batch = 17.4656s	
14863/22300 (epoch 33.325), train_loss = 0.31458860, grad/param norm = 2.2648e-01, time/batch = 17.9755s	
14864/22300 (epoch 33.327), train_loss = 0.33203523, grad/param norm = 1.9230e-01, time/batch = 17.7147s	
14865/22300 (epoch 33.330), train_loss = 0.33803812, grad/param norm = 2.4880e-01, time/batch = 15.6323s	
14866/22300 (epoch 33.332), train_loss = 0.32429395, grad/param norm = 2.1647e-01, time/batch = 17.1663s	
14867/22300 (epoch 33.334), train_loss = 0.35255487, grad/param norm = 2.1304e-01, time/batch = 15.6287s	
14868/22300 (epoch 33.336), train_loss = 0.38385172, grad/param norm = 2.2063e-01, time/batch = 16.7913s	
14869/22300 (epoch 33.339), train_loss = 0.42437773, grad/param norm = 2.6338e-01, time/batch = 17.1299s	
14870/22300 (epoch 33.341), train_loss = 0.44569646, grad/param norm = 2.9580e-01, time/batch = 17.7843s	
14871/22300 (epoch 33.343), train_loss = 0.48833833, grad/param norm = 3.1041e-01, time/batch = 18.2984s	
14872/22300 (epoch 33.345), train_loss = 0.38223254, grad/param norm = 2.2884e-01, time/batch = 17.6824s	
14873/22300 (epoch 33.348), train_loss = 0.38089917, grad/param norm = 2.0154e-01, time/batch = 15.8042s	
14874/22300 (epoch 33.350), train_loss = 0.31201914, grad/param norm = 2.1148e-01, time/batch = 15.7251s	
14875/22300 (epoch 33.352), train_loss = 0.42490957, grad/param norm = 2.7969e-01, time/batch = 17.2859s	
14876/22300 (epoch 33.354), train_loss = 0.61324113, grad/param norm = 3.1111e-01, time/batch = 17.8890s	
14877/22300 (epoch 33.357), train_loss = 0.52291079, grad/param norm = 2.8969e-01, time/batch = 16.2831s	
14878/22300 (epoch 33.359), train_loss = 0.33525918, grad/param norm = 2.5160e-01, time/batch = 16.7958s	
14879/22300 (epoch 33.361), train_loss = 0.36731631, grad/param norm = 2.7317e-01, time/batch = 15.1151s	
14880/22300 (epoch 33.363), train_loss = 0.46789074, grad/param norm = 2.6569e-01, time/batch = 17.3016s	
14881/22300 (epoch 33.365), train_loss = 0.34553312, grad/param norm = 2.7571e-01, time/batch = 14.2488s	
14882/22300 (epoch 33.368), train_loss = 0.35820970, grad/param norm = 2.4363e-01, time/batch = 17.2944s	
14883/22300 (epoch 33.370), train_loss = 0.36934692, grad/param norm = 2.3230e-01, time/batch = 15.4488s	
14884/22300 (epoch 33.372), train_loss = 0.28022779, grad/param norm = 2.1314e-01, time/batch = 18.2999s	
14885/22300 (epoch 33.374), train_loss = 0.28207341, grad/param norm = 1.8714e-01, time/batch = 16.2996s	
14886/22300 (epoch 33.377), train_loss = 0.38682078, grad/param norm = 2.4928e-01, time/batch = 16.0643s	
14887/22300 (epoch 33.379), train_loss = 0.37353005, grad/param norm = 3.0772e-01, time/batch = 15.6245s	
14888/22300 (epoch 33.381), train_loss = 0.45627117, grad/param norm = 3.0050e-01, time/batch = 18.3833s	
14889/22300 (epoch 33.383), train_loss = 0.38750161, grad/param norm = 2.8044e-01, time/batch = 17.5624s	
14890/22300 (epoch 33.386), train_loss = 0.39138852, grad/param norm = 2.2816e-01, time/batch = 16.5717s	
14891/22300 (epoch 33.388), train_loss = 0.30645948, grad/param norm = 2.1967e-01, time/batch = 16.3994s	
14892/22300 (epoch 33.390), train_loss = 0.34465814, grad/param norm = 2.6704e-01, time/batch = 15.0691s	
14893/22300 (epoch 33.392), train_loss = 0.38427413, grad/param norm = 2.4953e-01, time/batch = 16.9483s	
14894/22300 (epoch 33.395), train_loss = 0.30635735, grad/param norm = 1.8246e-01, time/batch = 16.4702s	
14895/22300 (epoch 33.397), train_loss = 0.20960332, grad/param norm = 1.4545e-01, time/batch = 17.5564s	
14896/22300 (epoch 33.399), train_loss = 0.32896602, grad/param norm = 2.8189e-01, time/batch = 16.8080s	
14897/22300 (epoch 33.401), train_loss = 0.37999716, grad/param norm = 2.7669e-01, time/batch = 15.8866s	
14898/22300 (epoch 33.404), train_loss = 0.38969344, grad/param norm = 2.5466e-01, time/batch = 17.5218s	
14899/22300 (epoch 33.406), train_loss = 0.58559953, grad/param norm = 3.0024e-01, time/batch = 16.5522s	
14900/22300 (epoch 33.408), train_loss = 0.46613519, grad/param norm = 2.8176e-01, time/batch = 17.6282s	
14901/22300 (epoch 33.410), train_loss = 0.47506907, grad/param norm = 3.1126e-01, time/batch = 15.2357s	
14902/22300 (epoch 33.413), train_loss = 0.36873944, grad/param norm = 2.7987e-01, time/batch = 16.4756s	
14903/22300 (epoch 33.415), train_loss = 0.28595721, grad/param norm = 2.6607e-01, time/batch = 15.6419s	
14904/22300 (epoch 33.417), train_loss = 0.42780702, grad/param norm = 2.6919e-01, time/batch = 17.1959s	
14905/22300 (epoch 33.419), train_loss = 0.36292203, grad/param norm = 2.1243e-01, time/batch = 16.2357s	
14906/22300 (epoch 33.422), train_loss = 0.34887428, grad/param norm = 2.7968e-01, time/batch = 16.9684s	
14907/22300 (epoch 33.424), train_loss = 0.40615384, grad/param norm = 2.8495e-01, time/batch = 15.9025s	
14908/22300 (epoch 33.426), train_loss = 0.29371530, grad/param norm = 2.2573e-01, time/batch = 16.5192s	
14909/22300 (epoch 33.428), train_loss = 0.32590905, grad/param norm = 2.5496e-01, time/batch = 17.2184s	
14910/22300 (epoch 33.430), train_loss = 0.36841312, grad/param norm = 2.4142e-01, time/batch = 16.7330s	
14911/22300 (epoch 33.433), train_loss = 0.36887189, grad/param norm = 2.3126e-01, time/batch = 16.5385s	
14912/22300 (epoch 33.435), train_loss = 0.36257420, grad/param norm = 2.4106e-01, time/batch = 16.8966s	
14913/22300 (epoch 33.437), train_loss = 0.41308616, grad/param norm = 2.6109e-01, time/batch = 18.7113s	
14914/22300 (epoch 33.439), train_loss = 0.45867342, grad/param norm = 2.6785e-01, time/batch = 17.3811s	
14915/22300 (epoch 33.442), train_loss = 0.42121913, grad/param norm = 2.4369e-01, time/batch = 15.7000s	
14916/22300 (epoch 33.444), train_loss = 0.33636640, grad/param norm = 2.4117e-01, time/batch = 18.6353s	
14917/22300 (epoch 33.446), train_loss = 0.35311959, grad/param norm = 2.3385e-01, time/batch = 17.2325s	
14918/22300 (epoch 33.448), train_loss = 0.25304784, grad/param norm = 1.6069e-01, time/batch = 16.5494s	
14919/22300 (epoch 33.451), train_loss = 0.43614447, grad/param norm = 2.9115e-01, time/batch = 14.9951s	
14920/22300 (epoch 33.453), train_loss = 0.33675574, grad/param norm = 2.2193e-01, time/batch = 16.0709s	
14921/22300 (epoch 33.455), train_loss = 0.50613024, grad/param norm = 3.2710e-01, time/batch = 16.1019s	
14922/22300 (epoch 33.457), train_loss = 0.58924950, grad/param norm = 3.1267e-01, time/batch = 15.9503s	
14923/22300 (epoch 33.460), train_loss = 0.48194351, grad/param norm = 2.8141e-01, time/batch = 15.9061s	
14924/22300 (epoch 33.462), train_loss = 0.49178562, grad/param norm = 2.6136e-01, time/batch = 16.8651s	
14925/22300 (epoch 33.464), train_loss = 0.46192109, grad/param norm = 3.5819e-01, time/batch = 17.7078s	
14926/22300 (epoch 33.466), train_loss = 0.35938695, grad/param norm = 1.9851e-01, time/batch = 16.6277s	
14927/22300 (epoch 33.469), train_loss = 0.35788559, grad/param norm = 2.2006e-01, time/batch = 16.5581s	
14928/22300 (epoch 33.471), train_loss = 0.48169413, grad/param norm = 2.6008e-01, time/batch = 15.3208s	
14929/22300 (epoch 33.473), train_loss = 0.41145365, grad/param norm = 2.1220e-01, time/batch = 16.5637s	
14930/22300 (epoch 33.475), train_loss = 0.36118302, grad/param norm = 2.5594e-01, time/batch = 15.8266s	
14931/22300 (epoch 33.478), train_loss = 0.36863892, grad/param norm = 2.8198e-01, time/batch = 16.2053s	
14932/22300 (epoch 33.480), train_loss = 0.28067108, grad/param norm = 2.6006e-01, time/batch = 16.9665s	
14933/22300 (epoch 33.482), train_loss = 0.30325535, grad/param norm = 1.9469e-01, time/batch = 15.2359s	
14934/22300 (epoch 33.484), train_loss = 0.42459728, grad/param norm = 2.6453e-01, time/batch = 16.2978s	
14935/22300 (epoch 33.487), train_loss = 0.47662536, grad/param norm = 2.4772e-01, time/batch = 16.8931s	
14936/22300 (epoch 33.489), train_loss = 0.47962921, grad/param norm = 2.6077e-01, time/batch = 18.1280s	
14937/22300 (epoch 33.491), train_loss = 0.47629794, grad/param norm = 2.9042e-01, time/batch = 15.1137s	
14938/22300 (epoch 33.493), train_loss = 0.40040318, grad/param norm = 3.4319e-01, time/batch = 16.7959s	
14939/22300 (epoch 33.496), train_loss = 0.40439023, grad/param norm = 2.1351e-01, time/batch = 15.6479s	
14940/22300 (epoch 33.498), train_loss = 0.27917113, grad/param norm = 1.8906e-01, time/batch = 16.2911s	
14941/22300 (epoch 33.500), train_loss = 0.39983664, grad/param norm = 2.5886e-01, time/batch = 17.4693s	
14942/22300 (epoch 33.502), train_loss = 0.25362169, grad/param norm = 1.9339e-01, time/batch = 16.1330s	
14943/22300 (epoch 33.504), train_loss = 0.27960473, grad/param norm = 1.9605e-01, time/batch = 16.9800s	
14944/22300 (epoch 33.507), train_loss = 0.33315566, grad/param norm = 2.4350e-01, time/batch = 16.7070s	
14945/22300 (epoch 33.509), train_loss = 0.44077918, grad/param norm = 2.3620e-01, time/batch = 18.0589s	
14946/22300 (epoch 33.511), train_loss = 0.24946419, grad/param norm = 1.9873e-01, time/batch = 15.2387s	
14947/22300 (epoch 33.513), train_loss = 0.29463330, grad/param norm = 2.0431e-01, time/batch = 17.1208s	
14948/22300 (epoch 33.516), train_loss = 0.35437131, grad/param norm = 2.5496e-01, time/batch = 17.5338s	
14949/22300 (epoch 33.518), train_loss = 0.42744990, grad/param norm = 2.6773e-01, time/batch = 15.5646s	
14950/22300 (epoch 33.520), train_loss = 0.35102897, grad/param norm = 2.2412e-01, time/batch = 18.4701s	
14951/22300 (epoch 33.522), train_loss = 0.35858479, grad/param norm = 1.9288e-01, time/batch = 15.0257s	
14952/22300 (epoch 33.525), train_loss = 0.29482729, grad/param norm = 2.0341e-01, time/batch = 18.0434s	
14953/22300 (epoch 33.527), train_loss = 0.46909889, grad/param norm = 2.8066e-01, time/batch = 15.7307s	
14954/22300 (epoch 33.529), train_loss = 0.41549057, grad/param norm = 3.0794e-01, time/batch = 15.7676s	
14955/22300 (epoch 33.531), train_loss = 0.34814174, grad/param norm = 2.1643e-01, time/batch = 16.2700s	
14956/22300 (epoch 33.534), train_loss = 0.36274719, grad/param norm = 2.4489e-01, time/batch = 18.0535s	
14957/22300 (epoch 33.536), train_loss = 0.55068205, grad/param norm = 2.7480e-01, time/batch = 16.5627s	
14958/22300 (epoch 33.538), train_loss = 0.69435640, grad/param norm = 3.8767e-01, time/batch = 15.3861s	
14959/22300 (epoch 33.540), train_loss = 0.43356827, grad/param norm = 3.6890e-01, time/batch = 16.7225s	
14960/22300 (epoch 33.543), train_loss = 0.38420827, grad/param norm = 2.3392e-01, time/batch = 17.4036s	
14961/22300 (epoch 33.545), train_loss = 0.27307921, grad/param norm = 2.3015e-01, time/batch = 16.5626s	
14962/22300 (epoch 33.547), train_loss = 0.25385230, grad/param norm = 1.9406e-01, time/batch = 30.5275s	
14963/22300 (epoch 33.549), train_loss = 0.30082703, grad/param norm = 1.9069e-01, time/batch = 15.9993s	
14964/22300 (epoch 33.552), train_loss = 0.32218209, grad/param norm = 2.4507e-01, time/batch = 16.6352s	
14965/22300 (epoch 33.554), train_loss = 0.42109007, grad/param norm = 2.8277e-01, time/batch = 15.8725s	
14966/22300 (epoch 33.556), train_loss = 0.57424973, grad/param norm = 3.5592e-01, time/batch = 15.6758s	
14967/22300 (epoch 33.558), train_loss = 0.43580706, grad/param norm = 2.8426e-01, time/batch = 17.6491s	
14968/22300 (epoch 33.561), train_loss = 0.59240667, grad/param norm = 2.7770e-01, time/batch = 16.2985s	
14969/22300 (epoch 33.563), train_loss = 0.50364762, grad/param norm = 3.1409e-01, time/batch = 15.9702s	
14970/22300 (epoch 33.565), train_loss = 0.37683814, grad/param norm = 2.1981e-01, time/batch = 16.3715s	
14971/22300 (epoch 33.567), train_loss = 0.37286147, grad/param norm = 2.4380e-01, time/batch = 19.1219s	
14972/22300 (epoch 33.570), train_loss = 0.53615111, grad/param norm = 3.3314e-01, time/batch = 15.4696s	
14973/22300 (epoch 33.572), train_loss = 0.52322959, grad/param norm = 2.8496e-01, time/batch = 16.2178s	
14974/22300 (epoch 33.574), train_loss = 0.38856049, grad/param norm = 2.3820e-01, time/batch = 17.7163s	
14975/22300 (epoch 33.576), train_loss = 0.35007223, grad/param norm = 2.1621e-01, time/batch = 17.1860s	
14976/22300 (epoch 33.578), train_loss = 0.21413413, grad/param norm = 1.9518e-01, time/batch = 17.8859s	
14977/22300 (epoch 33.581), train_loss = 0.29237973, grad/param norm = 2.1779e-01, time/batch = 17.8082s	
14978/22300 (epoch 33.583), train_loss = 0.34519051, grad/param norm = 1.9543e-01, time/batch = 17.7999s	
14979/22300 (epoch 33.585), train_loss = 0.49342571, grad/param norm = 3.4014e-01, time/batch = 17.1997s	
14980/22300 (epoch 33.587), train_loss = 0.69142032, grad/param norm = 4.3500e-01, time/batch = 15.3988s	
14981/22300 (epoch 33.590), train_loss = 0.58860413, grad/param norm = 4.7583e-01, time/batch = 16.2307s	
14982/22300 (epoch 33.592), train_loss = 0.65829767, grad/param norm = 3.5948e-01, time/batch = 17.2059s	
14983/22300 (epoch 33.594), train_loss = 0.63391568, grad/param norm = 4.0279e-01, time/batch = 17.0569s	
14984/22300 (epoch 33.596), train_loss = 0.38384862, grad/param norm = 2.4030e-01, time/batch = 15.6515s	
14985/22300 (epoch 33.599), train_loss = 0.28446403, grad/param norm = 2.3287e-01, time/batch = 17.1390s	
14986/22300 (epoch 33.601), train_loss = 0.34565663, grad/param norm = 2.3800e-01, time/batch = 15.5193s	
14987/22300 (epoch 33.603), train_loss = 0.38730427, grad/param norm = 2.4618e-01, time/batch = 15.8568s	
14988/22300 (epoch 33.605), train_loss = 0.36651518, grad/param norm = 2.7874e-01, time/batch = 15.6263s	
14989/22300 (epoch 33.608), train_loss = 0.63873490, grad/param norm = 3.4881e-01, time/batch = 17.1992s	
14990/22300 (epoch 33.610), train_loss = 0.67353970, grad/param norm = 3.5490e-01, time/batch = 15.2873s	
14991/22300 (epoch 33.612), train_loss = 0.48673139, grad/param norm = 2.7381e-01, time/batch = 17.5630s	
14992/22300 (epoch 33.614), train_loss = 0.51726250, grad/param norm = 3.0884e-01, time/batch = 17.3090s	
14993/22300 (epoch 33.617), train_loss = 0.49533074, grad/param norm = 2.6128e-01, time/batch = 16.1287s	
14994/22300 (epoch 33.619), train_loss = 0.55934432, grad/param norm = 3.0330e-01, time/batch = 18.3018s	
14995/22300 (epoch 33.621), train_loss = 0.35744971, grad/param norm = 2.3501e-01, time/batch = 16.4836s	
14996/22300 (epoch 33.623), train_loss = 0.38278249, grad/param norm = 2.4516e-01, time/batch = 17.1975s	
14997/22300 (epoch 33.626), train_loss = 0.34513402, grad/param norm = 2.3651e-01, time/batch = 15.5265s	
14998/22300 (epoch 33.628), train_loss = 0.35383803, grad/param norm = 1.9023e-01, time/batch = 15.9448s	
14999/22300 (epoch 33.630), train_loss = 0.43528743, grad/param norm = 2.5454e-01, time/batch = 16.9007s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch33.63_1.6663.t7	
15000/22300 (epoch 33.632), train_loss = 0.37038241, grad/param norm = 2.9538e-01, time/batch = 16.2107s	
15001/22300 (epoch 33.635), train_loss = 1.02216556, grad/param norm = 4.2444e-01, time/batch = 18.0482s	
15002/22300 (epoch 33.637), train_loss = 0.45847090, grad/param norm = 2.7198e-01, time/batch = 15.4620s	
15003/22300 (epoch 33.639), train_loss = 0.56649786, grad/param norm = 2.9275e-01, time/batch = 16.7197s	
15004/22300 (epoch 33.641), train_loss = 0.43596680, grad/param norm = 2.4808e-01, time/batch = 16.1485s	
15005/22300 (epoch 33.643), train_loss = 0.36605827, grad/param norm = 2.9836e-01, time/batch = 16.7187s	
15006/22300 (epoch 33.646), train_loss = 0.32492116, grad/param norm = 2.0197e-01, time/batch = 16.7102s	
15007/22300 (epoch 33.648), train_loss = 0.44611438, grad/param norm = 2.3419e-01, time/batch = 16.6416s	
15008/22300 (epoch 33.650), train_loss = 0.47163511, grad/param norm = 3.0394e-01, time/batch = 18.3888s	
15009/22300 (epoch 33.652), train_loss = 0.38952139, grad/param norm = 2.4600e-01, time/batch = 15.9498s	
15010/22300 (epoch 33.655), train_loss = 0.34236075, grad/param norm = 2.8512e-01, time/batch = 17.5687s	
15011/22300 (epoch 33.657), train_loss = 0.38720539, grad/param norm = 2.6011e-01, time/batch = 15.6570s	
15012/22300 (epoch 33.659), train_loss = 0.38912953, grad/param norm = 3.1283e-01, time/batch = 16.4700s	
15013/22300 (epoch 33.661), train_loss = 0.30291871, grad/param norm = 2.3598e-01, time/batch = 16.3717s	
15014/22300 (epoch 33.664), train_loss = 0.34531498, grad/param norm = 1.9948e-01, time/batch = 16.1439s	
15015/22300 (epoch 33.666), train_loss = 0.43086212, grad/param norm = 2.6331e-01, time/batch = 15.3038s	
15016/22300 (epoch 33.668), train_loss = 0.33176641, grad/param norm = 2.8830e-01, time/batch = 17.1173s	
15017/22300 (epoch 33.670), train_loss = 0.43648923, grad/param norm = 2.6830e-01, time/batch = 17.4709s	
15018/22300 (epoch 33.673), train_loss = 0.51850202, grad/param norm = 3.4905e-01, time/batch = 16.4093s	
15019/22300 (epoch 33.675), train_loss = 0.53211618, grad/param norm = 3.1394e-01, time/batch = 19.0318s	
15020/22300 (epoch 33.677), train_loss = 0.60720996, grad/param norm = 3.2525e-01, time/batch = 16.2848s	
15021/22300 (epoch 33.679), train_loss = 0.43314367, grad/param norm = 3.0730e-01, time/batch = 16.1055s	
15022/22300 (epoch 33.682), train_loss = 0.41095246, grad/param norm = 2.5482e-01, time/batch = 16.8246s	
15023/22300 (epoch 33.684), train_loss = 0.38983727, grad/param norm = 2.3429e-01, time/batch = 16.8569s	
15024/22300 (epoch 33.686), train_loss = 0.37933908, grad/param norm = 2.1996e-01, time/batch = 16.9483s	
15025/22300 (epoch 33.688), train_loss = 0.35805455, grad/param norm = 2.6980e-01, time/batch = 17.4780s	
15026/22300 (epoch 33.691), train_loss = 0.32269621, grad/param norm = 2.3519e-01, time/batch = 18.7046s	
15027/22300 (epoch 33.693), train_loss = 0.30693984, grad/param norm = 2.3977e-01, time/batch = 17.2027s	
15028/22300 (epoch 33.695), train_loss = 0.33558514, grad/param norm = 1.8847e-01, time/batch = 17.1562s	
15029/22300 (epoch 33.697), train_loss = 0.35924633, grad/param norm = 1.9039e-01, time/batch = 14.6542s	
15030/22300 (epoch 33.700), train_loss = 0.31317762, grad/param norm = 2.1699e-01, time/batch = 16.7235s	
15031/22300 (epoch 33.702), train_loss = 0.28395241, grad/param norm = 1.9203e-01, time/batch = 18.1151s	
15032/22300 (epoch 33.704), train_loss = 0.38178343, grad/param norm = 2.7384e-01, time/batch = 16.3893s	
15033/22300 (epoch 33.706), train_loss = 0.34191477, grad/param norm = 2.4558e-01, time/batch = 16.7744s	
15034/22300 (epoch 33.709), train_loss = 0.27791845, grad/param norm = 2.0582e-01, time/batch = 15.2717s	
15035/22300 (epoch 33.711), train_loss = 0.27398033, grad/param norm = 1.8218e-01, time/batch = 17.2981s	
15036/22300 (epoch 33.713), train_loss = 0.40295766, grad/param norm = 2.3628e-01, time/batch = 16.6420s	
15037/22300 (epoch 33.715), train_loss = 0.39141939, grad/param norm = 2.5651e-01, time/batch = 16.7134s	
15038/22300 (epoch 33.717), train_loss = 0.55275262, grad/param norm = 2.7697e-01, time/batch = 16.3054s	
15039/22300 (epoch 33.720), train_loss = 0.34398721, grad/param norm = 2.4483e-01, time/batch = 14.6700s	
15040/22300 (epoch 33.722), train_loss = 0.42909804, grad/param norm = 3.2545e-01, time/batch = 17.8771s	
15041/22300 (epoch 33.724), train_loss = 0.44282180, grad/param norm = 2.7551e-01, time/batch = 15.2885s	
15042/22300 (epoch 33.726), train_loss = 0.36489783, grad/param norm = 2.9192e-01, time/batch = 16.6295s	
15043/22300 (epoch 33.729), train_loss = 0.40225435, grad/param norm = 2.4927e-01, time/batch = 17.1380s	
15044/22300 (epoch 33.731), train_loss = 0.53491243, grad/param norm = 3.5757e-01, time/batch = 18.3765s	
15045/22300 (epoch 33.733), train_loss = 0.53751853, grad/param norm = 3.4077e-01, time/batch = 16.7809s	
15046/22300 (epoch 33.735), train_loss = 0.56802021, grad/param norm = 3.7910e-01, time/batch = 17.0516s	
15047/22300 (epoch 33.738), train_loss = 0.41745821, grad/param norm = 2.9630e-01, time/batch = 16.0779s	
15048/22300 (epoch 33.740), train_loss = 0.37615494, grad/param norm = 2.3805e-01, time/batch = 15.8867s	
15049/22300 (epoch 33.742), train_loss = 0.33465137, grad/param norm = 2.0968e-01, time/batch = 16.1568s	
15050/22300 (epoch 33.744), train_loss = 0.61329581, grad/param norm = 3.0120e-01, time/batch = 16.4581s	
15051/22300 (epoch 33.747), train_loss = 0.48396940, grad/param norm = 2.3029e-01, time/batch = 18.9632s	
15052/22300 (epoch 33.749), train_loss = 0.59241313, grad/param norm = 3.9165e-01, time/batch = 17.0471s	
15053/22300 (epoch 33.751), train_loss = 0.54759120, grad/param norm = 3.3458e-01, time/batch = 16.0285s	
15054/22300 (epoch 33.753), train_loss = 0.56209896, grad/param norm = 3.5247e-01, time/batch = 16.7201s	
15055/22300 (epoch 33.756), train_loss = 0.49651430, grad/param norm = 2.6640e-01, time/batch = 16.8019s	
15056/22300 (epoch 33.758), train_loss = 0.43863138, grad/param norm = 2.4544e-01, time/batch = 16.2953s	
15057/22300 (epoch 33.760), train_loss = 0.48743604, grad/param norm = 3.0058e-01, time/batch = 17.7203s	
15058/22300 (epoch 33.762), train_loss = 0.47383473, grad/param norm = 3.2992e-01, time/batch = 17.7907s	
15059/22300 (epoch 33.765), train_loss = 0.47320823, grad/param norm = 3.2104e-01, time/batch = 16.2836s	
15060/22300 (epoch 33.767), train_loss = 0.45252018, grad/param norm = 2.6900e-01, time/batch = 16.5485s	
15061/22300 (epoch 33.769), train_loss = 0.43812288, grad/param norm = 2.7542e-01, time/batch = 15.4806s	
15062/22300 (epoch 33.771), train_loss = 0.49938424, grad/param norm = 3.0614e-01, time/batch = 16.7806s	
15063/22300 (epoch 33.774), train_loss = 0.55490207, grad/param norm = 3.8021e-01, time/batch = 15.3948s	
15064/22300 (epoch 33.776), train_loss = 0.55821029, grad/param norm = 2.9469e-01, time/batch = 15.8156s	
15065/22300 (epoch 33.778), train_loss = 0.54702972, grad/param norm = 3.3569e-01, time/batch = 16.2283s	
15066/22300 (epoch 33.780), train_loss = 0.53105404, grad/param norm = 2.9421e-01, time/batch = 17.2122s	
15067/22300 (epoch 33.783), train_loss = 0.56371718, grad/param norm = 2.9747e-01, time/batch = 16.7129s	
15068/22300 (epoch 33.785), train_loss = 0.42001330, grad/param norm = 3.0186e-01, time/batch = 17.6163s	
15069/22300 (epoch 33.787), train_loss = 0.43565491, grad/param norm = 3.2185e-01, time/batch = 17.4429s	
15070/22300 (epoch 33.789), train_loss = 0.61067629, grad/param norm = 3.4643e-01, time/batch = 15.6909s	
15071/22300 (epoch 33.791), train_loss = 0.69921582, grad/param norm = 3.3642e-01, time/batch = 16.8087s	
15072/22300 (epoch 33.794), train_loss = 0.58842110, grad/param norm = 3.7231e-01, time/batch = 18.0546s	
15073/22300 (epoch 33.796), train_loss = 0.52857210, grad/param norm = 3.1611e-01, time/batch = 16.9666s	
15074/22300 (epoch 33.798), train_loss = 0.66781354, grad/param norm = 3.1554e-01, time/batch = 16.2140s	
15075/22300 (epoch 33.800), train_loss = 0.45084902, grad/param norm = 2.7977e-01, time/batch = 15.3665s	
15076/22300 (epoch 33.803), train_loss = 0.39317746, grad/param norm = 2.2482e-01, time/batch = 17.9700s	
15077/22300 (epoch 33.805), train_loss = 0.48321749, grad/param norm = 3.0873e-01, time/batch = 15.2897s	
15078/22300 (epoch 33.807), train_loss = 0.61546543, grad/param norm = 3.0903e-01, time/batch = 17.0512s	
15079/22300 (epoch 33.809), train_loss = 0.44644330, grad/param norm = 3.0319e-01, time/batch = 17.9734s	
15080/22300 (epoch 33.812), train_loss = 0.53145204, grad/param norm = 3.3888e-01, time/batch = 16.3600s	
15081/22300 (epoch 33.814), train_loss = 0.48255680, grad/param norm = 2.7931e-01, time/batch = 18.7849s	
15082/22300 (epoch 33.816), train_loss = 0.51288288, grad/param norm = 2.9348e-01, time/batch = 16.6407s	
15083/22300 (epoch 33.818), train_loss = 0.55155707, grad/param norm = 3.0381e-01, time/batch = 17.3868s	
15084/22300 (epoch 33.821), train_loss = 0.49775366, grad/param norm = 2.4286e-01, time/batch = 15.6251s	
15085/22300 (epoch 33.823), train_loss = 0.31830497, grad/param norm = 2.3364e-01, time/batch = 16.7824s	
15086/22300 (epoch 33.825), train_loss = 0.35307769, grad/param norm = 2.6737e-01, time/batch = 16.1305s	
15087/22300 (epoch 33.827), train_loss = 0.40003274, grad/param norm = 2.4050e-01, time/batch = 16.4787s	
15088/22300 (epoch 33.830), train_loss = 0.41247184, grad/param norm = 3.0507e-01, time/batch = 15.8709s	
15089/22300 (epoch 33.832), train_loss = 0.37143491, grad/param norm = 2.2607e-01, time/batch = 16.7005s	
15090/22300 (epoch 33.834), train_loss = 0.32489801, grad/param norm = 2.2855e-01, time/batch = 17.7960s	
15091/22300 (epoch 33.836), train_loss = 0.40306742, grad/param norm = 2.4654e-01, time/batch = 15.2201s	
15092/22300 (epoch 33.839), train_loss = 0.43829102, grad/param norm = 2.9367e-01, time/batch = 16.1400s	
15093/22300 (epoch 33.841), train_loss = 0.40809831, grad/param norm = 3.0707e-01, time/batch = 16.1464s	
15094/22300 (epoch 33.843), train_loss = 0.40347221, grad/param norm = 2.4906e-01, time/batch = 17.9689s	
15095/22300 (epoch 33.845), train_loss = 0.40658110, grad/param norm = 2.3535e-01, time/batch = 17.0434s	
15096/22300 (epoch 33.848), train_loss = 0.42561385, grad/param norm = 2.7129e-01, time/batch = 15.1044s	
15097/22300 (epoch 33.850), train_loss = 0.43380716, grad/param norm = 2.3188e-01, time/batch = 17.2221s	
15098/22300 (epoch 33.852), train_loss = 0.39549028, grad/param norm = 3.0986e-01, time/batch = 16.5140s	
15099/22300 (epoch 33.854), train_loss = 0.62490997, grad/param norm = 3.3421e-01, time/batch = 18.3719s	
15100/22300 (epoch 33.857), train_loss = 0.47560950, grad/param norm = 3.2034e-01, time/batch = 15.9812s	
15101/22300 (epoch 33.859), train_loss = 0.37654195, grad/param norm = 2.4429e-01, time/batch = 17.4431s	
15102/22300 (epoch 33.861), train_loss = 0.50146094, grad/param norm = 2.7673e-01, time/batch = 16.6325s	
15103/22300 (epoch 33.863), train_loss = 0.34087565, grad/param norm = 2.2093e-01, time/batch = 17.3927s	
15104/22300 (epoch 33.865), train_loss = 0.33630628, grad/param norm = 2.4657e-01, time/batch = 18.1381s	
15105/22300 (epoch 33.868), train_loss = 0.45750251, grad/param norm = 2.6798e-01, time/batch = 15.5595s	
15106/22300 (epoch 33.870), train_loss = 0.47656493, grad/param norm = 2.7888e-01, time/batch = 17.6425s	
15107/22300 (epoch 33.872), train_loss = 0.54888102, grad/param norm = 3.1258e-01, time/batch = 16.9803s	
15108/22300 (epoch 33.874), train_loss = 0.47755066, grad/param norm = 3.3401e-01, time/batch = 18.4593s	
15109/22300 (epoch 33.877), train_loss = 0.44247751, grad/param norm = 2.5125e-01, time/batch = 15.7060s	
15110/22300 (epoch 33.879), train_loss = 0.40566786, grad/param norm = 2.4790e-01, time/batch = 17.2904s	
15111/22300 (epoch 33.881), train_loss = 0.35790881, grad/param norm = 2.6476e-01, time/batch = 15.3142s	
15112/22300 (epoch 33.883), train_loss = 0.34567416, grad/param norm = 2.0881e-01, time/batch = 15.2934s	
15113/22300 (epoch 33.886), train_loss = 0.33735343, grad/param norm = 2.9831e-01, time/batch = 16.3771s	
15114/22300 (epoch 33.888), train_loss = 0.39470980, grad/param norm = 2.3654e-01, time/batch = 18.5478s	
15115/22300 (epoch 33.890), train_loss = 0.38085221, grad/param norm = 2.0031e-01, time/batch = 17.6486s	
15116/22300 (epoch 33.892), train_loss = 0.61167383, grad/param norm = 2.9744e-01, time/batch = 15.7108s	
15117/22300 (epoch 33.895), train_loss = 0.53843624, grad/param norm = 3.4112e-01, time/batch = 16.8839s	
15118/22300 (epoch 33.897), train_loss = 0.42595262, grad/param norm = 3.2552e-01, time/batch = 16.0599s	
15119/22300 (epoch 33.899), train_loss = 0.40551632, grad/param norm = 2.2567e-01, time/batch = 14.7820s	
15120/22300 (epoch 33.901), train_loss = 0.48474097, grad/param norm = 3.3080e-01, time/batch = 16.3112s	
15121/22300 (epoch 33.904), train_loss = 0.51312292, grad/param norm = 2.8186e-01, time/batch = 18.0365s	
15122/22300 (epoch 33.906), train_loss = 0.48145371, grad/param norm = 2.7159e-01, time/batch = 17.0543s	
15123/22300 (epoch 33.908), train_loss = 0.40736066, grad/param norm = 2.0932e-01, time/batch = 15.8106s	
15124/22300 (epoch 33.910), train_loss = 0.37769375, grad/param norm = 2.1630e-01, time/batch = 18.7056s	
15125/22300 (epoch 33.913), train_loss = 0.50316630, grad/param norm = 3.0217e-01, time/batch = 17.0489s	
15126/22300 (epoch 33.915), train_loss = 0.58954405, grad/param norm = 3.0486e-01, time/batch = 17.3760s	
15127/22300 (epoch 33.917), train_loss = 0.50781650, grad/param norm = 3.6287e-01, time/batch = 15.2896s	
15128/22300 (epoch 33.919), train_loss = 0.48690635, grad/param norm = 2.3927e-01, time/batch = 16.6560s	
15129/22300 (epoch 33.922), train_loss = 0.43508245, grad/param norm = 2.2432e-01, time/batch = 16.9432s	
15130/22300 (epoch 33.924), train_loss = 0.29231674, grad/param norm = 2.3433e-01, time/batch = 15.0341s	
15131/22300 (epoch 33.926), train_loss = 0.36319555, grad/param norm = 2.1726e-01, time/batch = 16.4620s	
15132/22300 (epoch 33.928), train_loss = 0.39025477, grad/param norm = 2.5104e-01, time/batch = 17.3959s	
15133/22300 (epoch 33.930), train_loss = 0.37963083, grad/param norm = 2.5037e-01, time/batch = 17.3122s	
15134/22300 (epoch 33.933), train_loss = 0.48522569, grad/param norm = 3.4214e-01, time/batch = 15.0393s	
15135/22300 (epoch 33.935), train_loss = 0.45945197, grad/param norm = 2.8221e-01, time/batch = 15.2957s	
15136/22300 (epoch 33.937), train_loss = 0.54359300, grad/param norm = 3.7114e-01, time/batch = 15.9620s	
15137/22300 (epoch 33.939), train_loss = 0.49961284, grad/param norm = 3.1899e-01, time/batch = 17.2906s	
15138/22300 (epoch 33.942), train_loss = 0.60474554, grad/param norm = 3.1367e-01, time/batch = 16.6427s	
15139/22300 (epoch 33.944), train_loss = 0.65328673, grad/param norm = 4.1630e-01, time/batch = 17.2107s	
15140/22300 (epoch 33.946), train_loss = 0.49014016, grad/param norm = 2.5872e-01, time/batch = 15.8162s	
15141/22300 (epoch 33.948), train_loss = 0.39334336, grad/param norm = 1.9983e-01, time/batch = 15.9469s	
15142/22300 (epoch 33.951), train_loss = 0.32161136, grad/param norm = 2.2090e-01, time/batch = 16.8140s	
15143/22300 (epoch 33.953), train_loss = 0.37983964, grad/param norm = 2.7331e-01, time/batch = 17.0598s	
15144/22300 (epoch 33.955), train_loss = 0.56143319, grad/param norm = 2.9527e-01, time/batch = 17.3148s	
15145/22300 (epoch 33.957), train_loss = 0.64295246, grad/param norm = 3.0292e-01, time/batch = 15.3957s	
15146/22300 (epoch 33.960), train_loss = 0.56906536, grad/param norm = 2.7674e-01, time/batch = 16.9688s	
15147/22300 (epoch 33.962), train_loss = 0.35238237, grad/param norm = 2.6747e-01, time/batch = 15.6385s	
15148/22300 (epoch 33.964), train_loss = 0.41596497, grad/param norm = 3.5590e-01, time/batch = 14.7924s	
15149/22300 (epoch 33.966), train_loss = 0.38358457, grad/param norm = 2.7470e-01, time/batch = 15.3240s	
15150/22300 (epoch 33.969), train_loss = 0.41322578, grad/param norm = 2.4105e-01, time/batch = 16.6233s	
15151/22300 (epoch 33.971), train_loss = 0.44216077, grad/param norm = 2.4717e-01, time/batch = 16.8913s	
15152/22300 (epoch 33.973), train_loss = 0.45156594, grad/param norm = 2.7407e-01, time/batch = 16.0401s	
15153/22300 (epoch 33.975), train_loss = 0.58678251, grad/param norm = 3.2224e-01, time/batch = 15.8950s	
15154/22300 (epoch 33.978), train_loss = 0.53244072, grad/param norm = 2.9057e-01, time/batch = 15.8153s	
15155/22300 (epoch 33.980), train_loss = 0.62206158, grad/param norm = 3.3838e-01, time/batch = 16.6919s	
15156/22300 (epoch 33.982), train_loss = 0.36229579, grad/param norm = 2.7734e-01, time/batch = 14.9814s	
15157/22300 (epoch 33.984), train_loss = 0.43610152, grad/param norm = 2.5818e-01, time/batch = 18.6253s	
15158/22300 (epoch 33.987), train_loss = 0.42909610, grad/param norm = 2.8555e-01, time/batch = 16.8231s	
15159/22300 (epoch 33.989), train_loss = 0.37960033, grad/param norm = 2.5316e-01, time/batch = 15.3986s	
15160/22300 (epoch 33.991), train_loss = 0.65507802, grad/param norm = 3.7100e-01, time/batch = 16.2087s	
15161/22300 (epoch 33.993), train_loss = 0.82168351, grad/param norm = 3.7869e-01, time/batch = 17.5282s	
15162/22300 (epoch 33.996), train_loss = 0.75315530, grad/param norm = 3.3742e-01, time/batch = 14.5891s	
15163/22300 (epoch 33.998), train_loss = 0.47763261, grad/param norm = 2.7429e-01, time/batch = 14.9856s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
15164/22300 (epoch 34.000), train_loss = 0.38125489, grad/param norm = 2.4968e-01, time/batch = 16.2972s	
15165/22300 (epoch 34.002), train_loss = 0.74574460, grad/param norm = 3.3224e-01, time/batch = 17.5537s	
15166/22300 (epoch 34.004), train_loss = 0.51007744, grad/param norm = 2.5148e-01, time/batch = 16.8811s	
15167/22300 (epoch 34.007), train_loss = 0.49492499, grad/param norm = 2.6986e-01, time/batch = 15.3673s	
15168/22300 (epoch 34.009), train_loss = 0.55480295, grad/param norm = 3.5412e-01, time/batch = 17.0395s	
15169/22300 (epoch 34.011), train_loss = 0.62434676, grad/param norm = 3.3035e-01, time/batch = 18.0509s	
15170/22300 (epoch 34.013), train_loss = 0.50008535, grad/param norm = 2.4326e-01, time/batch = 18.0994s	
15171/22300 (epoch 34.016), train_loss = 0.41488147, grad/param norm = 3.1677e-01, time/batch = 26.5991s	
15172/22300 (epoch 34.018), train_loss = 0.45773566, grad/param norm = 2.9335e-01, time/batch = 17.3862s	
15173/22300 (epoch 34.020), train_loss = 0.42758955, grad/param norm = 2.7628e-01, time/batch = 15.5200s	
15174/22300 (epoch 34.022), train_loss = 0.34743975, grad/param norm = 2.7311e-01, time/batch = 17.2046s	
15175/22300 (epoch 34.025), train_loss = 0.38498074, grad/param norm = 2.3844e-01, time/batch = 17.7170s	
15176/22300 (epoch 34.027), train_loss = 0.36715467, grad/param norm = 2.0934e-01, time/batch = 18.2919s	
15177/22300 (epoch 34.029), train_loss = 0.40891487, grad/param norm = 2.2947e-01, time/batch = 15.6352s	
15178/22300 (epoch 34.031), train_loss = 0.38596096, grad/param norm = 2.4918e-01, time/batch = 17.2393s	
15179/22300 (epoch 34.034), train_loss = 0.37788472, grad/param norm = 2.2090e-01, time/batch = 16.9366s	
15180/22300 (epoch 34.036), train_loss = 0.34698991, grad/param norm = 2.0152e-01, time/batch = 16.4748s	
15181/22300 (epoch 34.038), train_loss = 0.34166606, grad/param norm = 2.7777e-01, time/batch = 15.9525s	
15182/22300 (epoch 34.040), train_loss = 0.39332402, grad/param norm = 2.7446e-01, time/batch = 16.7079s	
15183/22300 (epoch 34.043), train_loss = 0.60984857, grad/param norm = 3.1568e-01, time/batch = 15.9516s	
15184/22300 (epoch 34.045), train_loss = 0.50774167, grad/param norm = 2.7417e-01, time/batch = 15.8641s	
15185/22300 (epoch 34.047), train_loss = 0.56323912, grad/param norm = 3.2451e-01, time/batch = 15.2147s	
15186/22300 (epoch 34.049), train_loss = 0.42848219, grad/param norm = 2.6484e-01, time/batch = 16.2365s	
15187/22300 (epoch 34.052), train_loss = 0.48689919, grad/param norm = 2.6479e-01, time/batch = 18.4545s	
15188/22300 (epoch 34.054), train_loss = 0.48791293, grad/param norm = 2.5102e-01, time/batch = 17.2927s	
15189/22300 (epoch 34.056), train_loss = 0.24748711, grad/param norm = 1.7950e-01, time/batch = 17.7270s	
15190/22300 (epoch 34.058), train_loss = 0.41285345, grad/param norm = 2.6114e-01, time/batch = 16.2401s	
15191/22300 (epoch 34.061), train_loss = 0.34823916, grad/param norm = 2.2951e-01, time/batch = 15.3029s	
15192/22300 (epoch 34.063), train_loss = 0.55971649, grad/param norm = 3.5571e-01, time/batch = 17.0370s	
15193/22300 (epoch 34.065), train_loss = 0.64922852, grad/param norm = 4.2611e-01, time/batch = 16.3146s	
15194/22300 (epoch 34.067), train_loss = 0.38829456, grad/param norm = 2.9871e-01, time/batch = 15.7133s	
15195/22300 (epoch 34.070), train_loss = 0.46038586, grad/param norm = 2.6878e-01, time/batch = 15.5542s	
15196/22300 (epoch 34.072), train_loss = 0.50881465, grad/param norm = 3.6644e-01, time/batch = 16.9405s	
15197/22300 (epoch 34.074), train_loss = 0.48971222, grad/param norm = 3.3134e-01, time/batch = 15.0663s	
15198/22300 (epoch 34.076), train_loss = 0.47969988, grad/param norm = 2.8128e-01, time/batch = 15.9775s	
15199/22300 (epoch 34.078), train_loss = 0.58892747, grad/param norm = 3.1378e-01, time/batch = 15.7135s	
15200/22300 (epoch 34.081), train_loss = 0.57576036, grad/param norm = 3.1022e-01, time/batch = 17.2976s	
15201/22300 (epoch 34.083), train_loss = 0.66421162, grad/param norm = 3.4564e-01, time/batch = 18.1365s	
15202/22300 (epoch 34.085), train_loss = 0.63531919, grad/param norm = 3.8388e-01, time/batch = 15.7222s	
15203/22300 (epoch 34.087), train_loss = 0.52552766, grad/param norm = 3.2968e-01, time/batch = 15.1334s	
15204/22300 (epoch 34.090), train_loss = 0.48755667, grad/param norm = 2.9802e-01, time/batch = 17.3139s	
15205/22300 (epoch 34.092), train_loss = 0.37726335, grad/param norm = 2.8382e-01, time/batch = 18.8513s	
15206/22300 (epoch 34.094), train_loss = 0.36763421, grad/param norm = 2.4489e-01, time/batch = 16.4470s	
15207/22300 (epoch 34.096), train_loss = 0.63173033, grad/param norm = 4.2240e-01, time/batch = 16.3773s	
15208/22300 (epoch 34.099), train_loss = 0.42077013, grad/param norm = 2.7491e-01, time/batch = 16.2134s	
15209/22300 (epoch 34.101), train_loss = 0.53364663, grad/param norm = 3.1622e-01, time/batch = 16.3561s	
15210/22300 (epoch 34.103), train_loss = 0.45557029, grad/param norm = 2.9359e-01, time/batch = 17.9591s	
15211/22300 (epoch 34.105), train_loss = 0.36208308, grad/param norm = 2.3953e-01, time/batch = 16.7056s	
15212/22300 (epoch 34.108), train_loss = 0.48882908, grad/param norm = 2.5382e-01, time/batch = 17.7228s	
15213/22300 (epoch 34.110), train_loss = 0.58532231, grad/param norm = 3.2106e-01, time/batch = 16.5560s	
15214/22300 (epoch 34.112), train_loss = 0.48915129, grad/param norm = 2.3568e-01, time/batch = 18.5606s	
15215/22300 (epoch 34.114), train_loss = 0.53652728, grad/param norm = 3.0919e-01, time/batch = 15.6492s	
15216/22300 (epoch 34.117), train_loss = 0.63028688, grad/param norm = 3.0400e-01, time/batch = 15.9783s	
15217/22300 (epoch 34.119), train_loss = 0.55380044, grad/param norm = 3.1175e-01, time/batch = 15.9599s	
15218/22300 (epoch 34.121), train_loss = 0.63463576, grad/param norm = 3.1137e-01, time/batch = 17.4574s	
15219/22300 (epoch 34.123), train_loss = 0.64032621, grad/param norm = 3.1173e-01, time/batch = 17.3105s	
15220/22300 (epoch 34.126), train_loss = 0.50591520, grad/param norm = 2.8919e-01, time/batch = 17.2862s	
15221/22300 (epoch 34.128), train_loss = 0.49868572, grad/param norm = 3.2485e-01, time/batch = 16.5380s	
15222/22300 (epoch 34.130), train_loss = 0.42797222, grad/param norm = 2.8116e-01, time/batch = 16.2950s	
15223/22300 (epoch 34.132), train_loss = 0.31234250, grad/param norm = 2.2669e-01, time/batch = 17.6190s	
15224/22300 (epoch 34.135), train_loss = 0.34176569, grad/param norm = 2.3892e-01, time/batch = 15.5718s	
15225/22300 (epoch 34.137), train_loss = 0.27609809, grad/param norm = 2.2983e-01, time/batch = 15.3936s	
15226/22300 (epoch 34.139), train_loss = 0.41261847, grad/param norm = 2.5587e-01, time/batch = 15.9519s	
15227/22300 (epoch 34.141), train_loss = 0.53709646, grad/param norm = 2.6214e-01, time/batch = 15.8793s	
15228/22300 (epoch 34.143), train_loss = 0.46799900, grad/param norm = 3.0146e-01, time/batch = 18.0575s	
15229/22300 (epoch 34.146), train_loss = 0.54672851, grad/param norm = 2.8353e-01, time/batch = 17.1564s	
15230/22300 (epoch 34.148), train_loss = 0.36100934, grad/param norm = 2.4577e-01, time/batch = 17.5481s	
15231/22300 (epoch 34.150), train_loss = 0.41104248, grad/param norm = 2.7858e-01, time/batch = 16.8082s	
15232/22300 (epoch 34.152), train_loss = 0.35205516, grad/param norm = 2.9022e-01, time/batch = 16.8203s	
15233/22300 (epoch 34.155), train_loss = 0.36858967, grad/param norm = 2.3335e-01, time/batch = 14.2472s	
15234/22300 (epoch 34.157), train_loss = 0.48641424, grad/param norm = 2.8943e-01, time/batch = 15.0385s	
15235/22300 (epoch 34.159), train_loss = 0.51397743, grad/param norm = 3.1822e-01, time/batch = 15.1346s	
15236/22300 (epoch 34.161), train_loss = 0.53805397, grad/param norm = 3.5085e-01, time/batch = 15.9816s	
15237/22300 (epoch 34.164), train_loss = 0.37354943, grad/param norm = 2.6753e-01, time/batch = 16.3970s	
15238/22300 (epoch 34.166), train_loss = 0.33571606, grad/param norm = 2.1513e-01, time/batch = 16.2059s	
15239/22300 (epoch 34.168), train_loss = 0.35123408, grad/param norm = 2.8686e-01, time/batch = 16.4784s	
15240/22300 (epoch 34.170), train_loss = 0.45555036, grad/param norm = 2.3978e-01, time/batch = 17.4650s	
15241/22300 (epoch 34.173), train_loss = 0.54108643, grad/param norm = 3.5337e-01, time/batch = 16.4569s	
15242/22300 (epoch 34.175), train_loss = 0.47428716, grad/param norm = 3.0492e-01, time/batch = 16.1405s	
15243/22300 (epoch 34.177), train_loss = 0.30888332, grad/param norm = 2.0519e-01, time/batch = 16.9798s	
15244/22300 (epoch 34.179), train_loss = 0.44612592, grad/param norm = 2.5372e-01, time/batch = 14.9823s	
15245/22300 (epoch 34.182), train_loss = 0.62219709, grad/param norm = 3.2903e-01, time/batch = 15.8811s	
15246/22300 (epoch 34.184), train_loss = 0.65477932, grad/param norm = 2.8980e-01, time/batch = 16.5397s	
15247/22300 (epoch 34.186), train_loss = 0.47206099, grad/param norm = 2.6777e-01, time/batch = 15.3782s	
15248/22300 (epoch 34.188), train_loss = 0.65108811, grad/param norm = 3.3135e-01, time/batch = 17.4642s	
15249/22300 (epoch 34.191), train_loss = 0.55647991, grad/param norm = 3.1211e-01, time/batch = 16.0593s	
15250/22300 (epoch 34.193), train_loss = 0.49009603, grad/param norm = 3.0147e-01, time/batch = 18.7233s	
15251/22300 (epoch 34.195), train_loss = 0.44697560, grad/param norm = 2.9247e-01, time/batch = 16.4008s	
15252/22300 (epoch 34.197), train_loss = 0.39337227, grad/param norm = 2.5126e-01, time/batch = 15.2770s	
15253/22300 (epoch 34.200), train_loss = 0.37917791, grad/param norm = 3.0201e-01, time/batch = 16.2136s	
15254/22300 (epoch 34.202), train_loss = 0.37885873, grad/param norm = 2.3941e-01, time/batch = 16.8877s	
15255/22300 (epoch 34.204), train_loss = 0.46685390, grad/param norm = 2.7726e-01, time/batch = 17.9620s	
15256/22300 (epoch 34.206), train_loss = 0.40053934, grad/param norm = 2.7580e-01, time/batch = 17.8761s	
15257/22300 (epoch 34.209), train_loss = 0.40828488, grad/param norm = 2.7863e-01, time/batch = 16.4705s	
15258/22300 (epoch 34.211), train_loss = 0.35412830, grad/param norm = 2.5772e-01, time/batch = 16.0630s	
15259/22300 (epoch 34.213), train_loss = 0.44503515, grad/param norm = 2.3931e-01, time/batch = 18.2727s	
15260/22300 (epoch 34.215), train_loss = 0.57427999, grad/param norm = 2.8068e-01, time/batch = 19.7358s	
15261/22300 (epoch 34.217), train_loss = 0.61676678, grad/param norm = 2.9538e-01, time/batch = 19.0047s	
15262/22300 (epoch 34.220), train_loss = 0.42163976, grad/param norm = 2.3184e-01, time/batch = 21.4943s	
15263/22300 (epoch 34.222), train_loss = 0.40092956, grad/param norm = 2.5432e-01, time/batch = 22.0676s	
15264/22300 (epoch 34.224), train_loss = 0.40042930, grad/param norm = 2.2764e-01, time/batch = 20.3429s	
15265/22300 (epoch 34.226), train_loss = 0.42829511, grad/param norm = 2.2853e-01, time/batch = 21.4093s	
15266/22300 (epoch 34.229), train_loss = 0.36021954, grad/param norm = 2.5584e-01, time/batch = 22.1666s	
15267/22300 (epoch 34.231), train_loss = 0.55122955, grad/param norm = 3.3248e-01, time/batch = 20.7142s	
15268/22300 (epoch 34.233), train_loss = 0.46982914, grad/param norm = 2.9992e-01, time/batch = 20.7350s	
15269/22300 (epoch 34.235), train_loss = 0.35177039, grad/param norm = 2.1879e-01, time/batch = 19.7600s	
15270/22300 (epoch 34.238), train_loss = 0.38402510, grad/param norm = 2.3635e-01, time/batch = 20.4105s	
15271/22300 (epoch 34.240), train_loss = 0.37277951, grad/param norm = 2.0619e-01, time/batch = 19.8153s	
15272/22300 (epoch 34.242), train_loss = 0.34758794, grad/param norm = 3.6807e-01, time/batch = 23.7268s	
15273/22300 (epoch 34.244), train_loss = 0.24602649, grad/param norm = 1.7855e-01, time/batch = 21.1038s	
15274/22300 (epoch 34.247), train_loss = 0.34217341, grad/param norm = 2.5623e-01, time/batch = 22.0490s	
15275/22300 (epoch 34.249), train_loss = 0.23612375, grad/param norm = 1.6548e-01, time/batch = 18.1957s	
15276/22300 (epoch 34.251), train_loss = 0.33256180, grad/param norm = 2.1362e-01, time/batch = 20.9948s	
15277/22300 (epoch 34.253), train_loss = 0.22499241, grad/param norm = 2.2363e-01, time/batch = 20.9920s	
15278/22300 (epoch 34.256), train_loss = 0.30727719, grad/param norm = 1.8675e-01, time/batch = 20.9589s	
15279/22300 (epoch 34.258), train_loss = 0.48240300, grad/param norm = 3.0496e-01, time/batch = 24.1780s	
15280/22300 (epoch 34.260), train_loss = 0.46842009, grad/param norm = 2.5715e-01, time/batch = 26.6858s	
15281/22300 (epoch 34.262), train_loss = 0.35285762, grad/param norm = 2.1901e-01, time/batch = 16.9722s	
15282/22300 (epoch 34.265), train_loss = 0.31906875, grad/param norm = 2.3841e-01, time/batch = 16.4025s	
15283/22300 (epoch 34.267), train_loss = 0.34895649, grad/param norm = 2.0087e-01, time/batch = 15.7166s	
15284/22300 (epoch 34.269), train_loss = 0.42869636, grad/param norm = 3.1039e-01, time/batch = 17.8056s	
15285/22300 (epoch 34.271), train_loss = 0.48757890, grad/param norm = 2.4992e-01, time/batch = 17.3930s	
15286/22300 (epoch 34.274), train_loss = 0.33334841, grad/param norm = 2.4106e-01, time/batch = 15.2270s	
15287/22300 (epoch 34.276), train_loss = 0.28164156, grad/param norm = 1.7793e-01, time/batch = 16.5550s	
15288/22300 (epoch 34.278), train_loss = 0.28291642, grad/param norm = 1.8550e-01, time/batch = 17.8951s	
15289/22300 (epoch 34.280), train_loss = 0.34152876, grad/param norm = 1.9678e-01, time/batch = 17.0287s	
15290/22300 (epoch 34.283), train_loss = 0.27059203, grad/param norm = 1.7799e-01, time/batch = 16.6955s	
15291/22300 (epoch 34.285), train_loss = 0.30283544, grad/param norm = 2.4637e-01, time/batch = 17.3685s	
15292/22300 (epoch 34.287), train_loss = 0.42257238, grad/param norm = 2.1981e-01, time/batch = 16.3149s	
15293/22300 (epoch 34.289), train_loss = 0.37935395, grad/param norm = 2.1270e-01, time/batch = 15.7262s	
15294/22300 (epoch 34.291), train_loss = 0.37716589, grad/param norm = 2.1406e-01, time/batch = 17.9730s	
15295/22300 (epoch 34.294), train_loss = 0.31278927, grad/param norm = 1.9397e-01, time/batch = 17.2944s	
15296/22300 (epoch 34.296), train_loss = 0.39148559, grad/param norm = 3.1524e-01, time/batch = 17.0570s	
15297/22300 (epoch 34.298), train_loss = 0.51111902, grad/param norm = 3.4870e-01, time/batch = 16.0709s	
15298/22300 (epoch 34.300), train_loss = 0.55123545, grad/param norm = 3.0329e-01, time/batch = 15.2111s	
15299/22300 (epoch 34.303), train_loss = 0.41877460, grad/param norm = 2.6935e-01, time/batch = 18.9609s	
15300/22300 (epoch 34.305), train_loss = 0.40869741, grad/param norm = 3.1037e-01, time/batch = 16.0457s	
15301/22300 (epoch 34.307), train_loss = 0.37406916, grad/param norm = 2.6632e-01, time/batch = 15.8469s	
15302/22300 (epoch 34.309), train_loss = 0.31290053, grad/param norm = 1.9921e-01, time/batch = 16.5668s	
15303/22300 (epoch 34.312), train_loss = 0.30335727, grad/param norm = 2.4065e-01, time/batch = 17.7190s	
15304/22300 (epoch 34.314), train_loss = 0.33219535, grad/param norm = 2.3555e-01, time/batch = 15.6254s	
15305/22300 (epoch 34.316), train_loss = 0.34847560, grad/param norm = 2.8349e-01, time/batch = 15.8797s	
15306/22300 (epoch 34.318), train_loss = 0.35814757, grad/param norm = 2.0567e-01, time/batch = 15.8283s	
15307/22300 (epoch 34.321), train_loss = 0.45449162, grad/param norm = 2.3034e-01, time/batch = 15.4614s	
15308/22300 (epoch 34.323), train_loss = 0.32679031, grad/param norm = 2.4220e-01, time/batch = 17.6823s	
15309/22300 (epoch 34.325), train_loss = 0.29329092, grad/param norm = 1.9313e-01, time/batch = 16.0696s	
15310/22300 (epoch 34.327), train_loss = 0.30410755, grad/param norm = 1.9388e-01, time/batch = 16.0536s	
15311/22300 (epoch 34.330), train_loss = 0.33285696, grad/param norm = 3.1274e-01, time/batch = 14.9752s	
15312/22300 (epoch 34.332), train_loss = 0.30305077, grad/param norm = 2.1319e-01, time/batch = 18.0476s	
15313/22300 (epoch 34.334), train_loss = 0.35891254, grad/param norm = 2.8407e-01, time/batch = 17.3098s	
15314/22300 (epoch 34.336), train_loss = 0.37082743, grad/param norm = 2.5259e-01, time/batch = 17.1981s	
15315/22300 (epoch 34.339), train_loss = 0.42940959, grad/param norm = 3.1396e-01, time/batch = 15.9484s	
15316/22300 (epoch 34.341), train_loss = 0.42072111, grad/param norm = 2.3971e-01, time/batch = 16.8990s	
15317/22300 (epoch 34.343), train_loss = 0.47240451, grad/param norm = 3.1767e-01, time/batch = 16.6237s	
15318/22300 (epoch 34.345), train_loss = 0.38654618, grad/param norm = 2.7289e-01, time/batch = 15.7111s	
15319/22300 (epoch 34.348), train_loss = 0.37536961, grad/param norm = 2.2145e-01, time/batch = 15.2015s	
15320/22300 (epoch 34.350), train_loss = 0.30085073, grad/param norm = 2.3948e-01, time/batch = 16.9781s	
15321/22300 (epoch 34.352), train_loss = 0.40772973, grad/param norm = 2.4839e-01, time/batch = 15.5719s	
15322/22300 (epoch 34.354), train_loss = 0.60839814, grad/param norm = 3.3188e-01, time/batch = 16.9531s	
15323/22300 (epoch 34.357), train_loss = 0.54611943, grad/param norm = 2.6685e-01, time/batch = 14.6588s	
15324/22300 (epoch 34.359), train_loss = 0.32922670, grad/param norm = 2.0720e-01, time/batch = 14.4231s	
15325/22300 (epoch 34.361), train_loss = 0.34367929, grad/param norm = 2.5552e-01, time/batch = 14.5917s	
15326/22300 (epoch 34.363), train_loss = 0.46690367, grad/param norm = 2.9931e-01, time/batch = 15.7038s	
15327/22300 (epoch 34.365), train_loss = 0.33793979, grad/param norm = 2.3590e-01, time/batch = 17.1805s	
15328/22300 (epoch 34.368), train_loss = 0.37294598, grad/param norm = 3.5795e-01, time/batch = 15.0585s	
15329/22300 (epoch 34.370), train_loss = 0.36465879, grad/param norm = 2.5049e-01, time/batch = 17.8567s	
15330/22300 (epoch 34.372), train_loss = 0.25938972, grad/param norm = 1.9192e-01, time/batch = 15.4021s	
15331/22300 (epoch 34.374), train_loss = 0.25748398, grad/param norm = 1.5512e-01, time/batch = 17.7069s	
15332/22300 (epoch 34.377), train_loss = 0.37796586, grad/param norm = 2.9796e-01, time/batch = 16.1517s	
15333/22300 (epoch 34.379), train_loss = 0.34068806, grad/param norm = 2.2028e-01, time/batch = 16.7143s	
15334/22300 (epoch 34.381), train_loss = 0.44865614, grad/param norm = 3.3474e-01, time/batch = 15.4732s	
15335/22300 (epoch 34.383), train_loss = 0.37491212, grad/param norm = 2.5295e-01, time/batch = 17.3821s	
15336/22300 (epoch 34.386), train_loss = 0.39347468, grad/param norm = 2.3170e-01, time/batch = 16.7289s	
15337/22300 (epoch 34.388), train_loss = 0.31943228, grad/param norm = 2.6576e-01, time/batch = 15.5614s	
15338/22300 (epoch 34.390), train_loss = 0.32962301, grad/param norm = 2.5759e-01, time/batch = 15.3020s	
15339/22300 (epoch 34.392), train_loss = 0.37055113, grad/param norm = 2.4865e-01, time/batch = 16.5654s	
15340/22300 (epoch 34.395), train_loss = 0.30414641, grad/param norm = 2.1538e-01, time/batch = 17.6135s	
15341/22300 (epoch 34.397), train_loss = 0.21753373, grad/param norm = 1.7290e-01, time/batch = 17.2014s	
15342/22300 (epoch 34.399), train_loss = 0.32092572, grad/param norm = 2.7565e-01, time/batch = 17.1403s	
15343/22300 (epoch 34.401), train_loss = 0.34640595, grad/param norm = 2.6588e-01, time/batch = 16.8114s	
15344/22300 (epoch 34.404), train_loss = 0.36565936, grad/param norm = 2.1954e-01, time/batch = 13.4260s	
15345/22300 (epoch 34.406), train_loss = 0.54746426, grad/param norm = 3.0331e-01, time/batch = 0.6596s	
15346/22300 (epoch 34.408), train_loss = 0.42938210, grad/param norm = 2.3079e-01, time/batch = 0.6593s	
15347/22300 (epoch 34.410), train_loss = 0.46139501, grad/param norm = 2.8754e-01, time/batch = 0.6620s	
15348/22300 (epoch 34.413), train_loss = 0.33993439, grad/param norm = 2.7315e-01, time/batch = 0.6617s	
15349/22300 (epoch 34.415), train_loss = 0.27093812, grad/param norm = 2.4660e-01, time/batch = 0.6572s	
15350/22300 (epoch 34.417), train_loss = 0.41512787, grad/param norm = 2.4490e-01, time/batch = 0.6599s	
15351/22300 (epoch 34.419), train_loss = 0.36604106, grad/param norm = 2.1455e-01, time/batch = 0.6711s	
15352/22300 (epoch 34.422), train_loss = 0.33046998, grad/param norm = 2.6625e-01, time/batch = 0.8810s	
15353/22300 (epoch 34.424), train_loss = 0.39793494, grad/param norm = 2.6749e-01, time/batch = 0.9785s	
15354/22300 (epoch 34.426), train_loss = 0.28911686, grad/param norm = 2.3884e-01, time/batch = 0.9703s	
15355/22300 (epoch 34.428), train_loss = 0.29940138, grad/param norm = 2.3059e-01, time/batch = 0.9547s	
15356/22300 (epoch 34.430), train_loss = 0.36262526, grad/param norm = 3.0997e-01, time/batch = 0.9536s	
15357/22300 (epoch 34.433), train_loss = 0.37177302, grad/param norm = 2.2343e-01, time/batch = 1.3756s	
15358/22300 (epoch 34.435), train_loss = 0.35987424, grad/param norm = 2.6353e-01, time/batch = 1.7762s	
15359/22300 (epoch 34.437), train_loss = 0.40755372, grad/param norm = 2.6301e-01, time/batch = 1.7634s	
15360/22300 (epoch 34.439), train_loss = 0.44243064, grad/param norm = 2.4532e-01, time/batch = 11.7039s	
15361/22300 (epoch 34.442), train_loss = 0.40261034, grad/param norm = 2.4168e-01, time/batch = 16.2342s	
15362/22300 (epoch 34.444), train_loss = 0.33834463, grad/param norm = 2.6947e-01, time/batch = 17.9371s	
15363/22300 (epoch 34.446), train_loss = 0.33179965, grad/param norm = 2.1559e-01, time/batch = 18.8791s	
15364/22300 (epoch 34.448), train_loss = 0.25728569, grad/param norm = 1.8556e-01, time/batch = 16.7033s	
15365/22300 (epoch 34.451), train_loss = 0.42431904, grad/param norm = 2.6099e-01, time/batch = 17.4379s	
15366/22300 (epoch 34.453), train_loss = 0.34186950, grad/param norm = 2.5174e-01, time/batch = 16.6994s	
15367/22300 (epoch 34.455), train_loss = 0.46896125, grad/param norm = 3.0605e-01, time/batch = 16.8132s	
15368/22300 (epoch 34.457), train_loss = 0.59134369, grad/param norm = 3.5213e-01, time/batch = 15.8129s	
15369/22300 (epoch 34.460), train_loss = 0.49031979, grad/param norm = 3.1438e-01, time/batch = 17.0538s	
15370/22300 (epoch 34.462), train_loss = 0.49516835, grad/param norm = 2.5059e-01, time/batch = 15.5428s	
15371/22300 (epoch 34.464), train_loss = 0.42713305, grad/param norm = 2.6678e-01, time/batch = 15.4148s	
15372/22300 (epoch 34.466), train_loss = 0.35504420, grad/param norm = 2.5490e-01, time/batch = 16.1455s	
15373/22300 (epoch 34.469), train_loss = 0.33764737, grad/param norm = 1.8722e-01, time/batch = 15.0739s	
15374/22300 (epoch 34.471), train_loss = 0.46988335, grad/param norm = 2.5622e-01, time/batch = 16.3842s	
15375/22300 (epoch 34.473), train_loss = 0.40531757, grad/param norm = 2.3082e-01, time/batch = 17.7955s	
15376/22300 (epoch 34.475), train_loss = 0.35324220, grad/param norm = 2.4114e-01, time/batch = 17.6151s	
15377/22300 (epoch 34.478), train_loss = 0.38153985, grad/param norm = 2.9794e-01, time/batch = 18.1309s	
15378/22300 (epoch 34.480), train_loss = 0.27894789, grad/param norm = 2.2740e-01, time/batch = 16.8160s	
15379/22300 (epoch 34.482), train_loss = 0.30167920, grad/param norm = 2.1124e-01, time/batch = 17.2295s	
15380/22300 (epoch 34.484), train_loss = 0.38417769, grad/param norm = 2.5261e-01, time/batch = 15.4779s	
15381/22300 (epoch 34.487), train_loss = 0.44882461, grad/param norm = 2.2544e-01, time/batch = 17.6138s	
15382/22300 (epoch 34.489), train_loss = 0.44943208, grad/param norm = 2.4886e-01, time/batch = 17.0600s	
15383/22300 (epoch 34.491), train_loss = 0.45010158, grad/param norm = 2.7580e-01, time/batch = 15.7997s	
15384/22300 (epoch 34.493), train_loss = 0.38781913, grad/param norm = 3.6890e-01, time/batch = 15.3612s	
15385/22300 (epoch 34.496), train_loss = 0.40403558, grad/param norm = 2.4248e-01, time/batch = 17.9329s	
15386/22300 (epoch 34.498), train_loss = 0.27776669, grad/param norm = 1.9577e-01, time/batch = 16.8965s	
15387/22300 (epoch 34.500), train_loss = 0.39645430, grad/param norm = 2.4699e-01, time/batch = 15.8131s	
15388/22300 (epoch 34.502), train_loss = 0.24555124, grad/param norm = 1.8851e-01, time/batch = 15.2150s	
15389/22300 (epoch 34.504), train_loss = 0.27593973, grad/param norm = 2.2330e-01, time/batch = 17.8759s	
15390/22300 (epoch 34.507), train_loss = 0.32509309, grad/param norm = 2.3387e-01, time/batch = 16.9019s	
15391/22300 (epoch 34.509), train_loss = 0.42326185, grad/param norm = 2.3608e-01, time/batch = 16.7991s	
15392/22300 (epoch 34.511), train_loss = 0.25454966, grad/param norm = 1.7757e-01, time/batch = 14.9921s	
15393/22300 (epoch 34.513), train_loss = 0.28331004, grad/param norm = 2.6725e-01, time/batch = 17.2342s	
15394/22300 (epoch 34.516), train_loss = 0.33396368, grad/param norm = 2.2815e-01, time/batch = 18.5263s	
15395/22300 (epoch 34.518), train_loss = 0.40412096, grad/param norm = 2.4814e-01, time/batch = 26.4028s	
15396/22300 (epoch 34.520), train_loss = 0.34809626, grad/param norm = 2.7034e-01, time/batch = 20.9650s	
15397/22300 (epoch 34.522), train_loss = 0.36169714, grad/param norm = 2.7063e-01, time/batch = 15.3020s	
15398/22300 (epoch 34.525), train_loss = 0.28958058, grad/param norm = 2.0592e-01, time/batch = 18.2915s	
15399/22300 (epoch 34.527), train_loss = 0.45078392, grad/param norm = 3.0899e-01, time/batch = 16.9690s	
15400/22300 (epoch 34.529), train_loss = 0.39089789, grad/param norm = 2.6711e-01, time/batch = 17.3732s	
15401/22300 (epoch 34.531), train_loss = 0.33950467, grad/param norm = 2.3250e-01, time/batch = 17.8686s	
15402/22300 (epoch 34.534), train_loss = 0.36754957, grad/param norm = 2.3699e-01, time/batch = 16.1449s	
15403/22300 (epoch 34.536), train_loss = 0.53264020, grad/param norm = 2.3370e-01, time/batch = 14.0868s	
15404/22300 (epoch 34.538), train_loss = 0.66709428, grad/param norm = 3.8833e-01, time/batch = 14.6439s	
15405/22300 (epoch 34.540), train_loss = 0.40665021, grad/param norm = 2.7100e-01, time/batch = 15.1360s	
15406/22300 (epoch 34.543), train_loss = 0.38733815, grad/param norm = 2.4461e-01, time/batch = 17.1428s	
15407/22300 (epoch 34.545), train_loss = 0.26554258, grad/param norm = 2.1503e-01, time/batch = 16.4931s	
15408/22300 (epoch 34.547), train_loss = 0.25369757, grad/param norm = 2.8138e-01, time/batch = 15.2137s	
15409/22300 (epoch 34.549), train_loss = 0.32445698, grad/param norm = 2.8859e-01, time/batch = 18.6117s	
15410/22300 (epoch 34.552), train_loss = 0.32660812, grad/param norm = 2.6166e-01, time/batch = 16.8100s	
15411/22300 (epoch 34.554), train_loss = 0.40419745, grad/param norm = 2.4159e-01, time/batch = 17.1988s	
15412/22300 (epoch 34.556), train_loss = 0.55236181, grad/param norm = 3.2515e-01, time/batch = 15.8962s	
15413/22300 (epoch 34.558), train_loss = 0.39946006, grad/param norm = 2.2674e-01, time/batch = 17.5580s	
15414/22300 (epoch 34.561), train_loss = 0.55656935, grad/param norm = 3.1527e-01, time/batch = 15.8209s	
15415/22300 (epoch 34.563), train_loss = 0.49313471, grad/param norm = 3.4694e-01, time/batch = 16.2321s	
15416/22300 (epoch 34.565), train_loss = 0.37940920, grad/param norm = 4.0041e-01, time/batch = 16.8031s	
15417/22300 (epoch 34.567), train_loss = 0.39349270, grad/param norm = 2.8996e-01, time/batch = 15.3290s	
15418/22300 (epoch 34.570), train_loss = 0.56536021, grad/param norm = 3.9441e-01, time/batch = 17.2370s	
15419/22300 (epoch 34.572), train_loss = 0.52214656, grad/param norm = 3.3374e-01, time/batch = 15.3913s	
15420/22300 (epoch 34.574), train_loss = 0.38268763, grad/param norm = 2.5168e-01, time/batch = 18.5557s	
15421/22300 (epoch 34.576), train_loss = 0.33189175, grad/param norm = 1.9144e-01, time/batch = 17.7240s	
15422/22300 (epoch 34.578), train_loss = 0.22018918, grad/param norm = 1.8221e-01, time/batch = 14.9582s	
15423/22300 (epoch 34.581), train_loss = 0.29966715, grad/param norm = 2.2697e-01, time/batch = 15.0484s	
15424/22300 (epoch 34.583), train_loss = 0.34991762, grad/param norm = 2.3532e-01, time/batch = 15.5280s	
15425/22300 (epoch 34.585), train_loss = 0.47725239, grad/param norm = 3.5249e-01, time/batch = 17.6313s	
15426/22300 (epoch 34.587), train_loss = 0.67703119, grad/param norm = 3.5385e-01, time/batch = 15.4613s	
15427/22300 (epoch 34.590), train_loss = 0.52625903, grad/param norm = 3.3794e-01, time/batch = 17.4605s	
15428/22300 (epoch 34.592), train_loss = 0.63561703, grad/param norm = 3.3381e-01, time/batch = 17.1345s	
15429/22300 (epoch 34.594), train_loss = 0.58175022, grad/param norm = 3.1025e-01, time/batch = 17.6323s	
15430/22300 (epoch 34.596), train_loss = 0.36714682, grad/param norm = 2.3757e-01, time/batch = 17.3471s	
15431/22300 (epoch 34.599), train_loss = 0.28033093, grad/param norm = 2.7988e-01, time/batch = 16.6348s	
15432/22300 (epoch 34.601), train_loss = 0.34027718, grad/param norm = 2.4776e-01, time/batch = 17.3911s	
15433/22300 (epoch 34.603), train_loss = 0.34699524, grad/param norm = 2.0894e-01, time/batch = 15.0651s	
15434/22300 (epoch 34.605), train_loss = 0.36883948, grad/param norm = 2.5477e-01, time/batch = 17.2282s	
15435/22300 (epoch 34.608), train_loss = 0.60358051, grad/param norm = 2.9433e-01, time/batch = 14.8911s	
15436/22300 (epoch 34.610), train_loss = 0.66574848, grad/param norm = 3.2971e-01, time/batch = 15.7108s	
15437/22300 (epoch 34.612), train_loss = 0.47640065, grad/param norm = 2.5411e-01, time/batch = 15.7050s	
15438/22300 (epoch 34.614), train_loss = 0.48185533, grad/param norm = 3.2461e-01, time/batch = 18.2159s	
15439/22300 (epoch 34.617), train_loss = 0.47669067, grad/param norm = 2.5627e-01, time/batch = 17.4722s	
15440/22300 (epoch 34.619), train_loss = 0.54326557, grad/param norm = 2.6199e-01, time/batch = 16.0696s	
15441/22300 (epoch 34.621), train_loss = 0.33900834, grad/param norm = 2.5072e-01, time/batch = 15.0600s	
15442/22300 (epoch 34.623), train_loss = 0.37273249, grad/param norm = 3.0700e-01, time/batch = 17.6408s	
15443/22300 (epoch 34.626), train_loss = 0.35239681, grad/param norm = 2.1426e-01, time/batch = 15.0505s	
15444/22300 (epoch 34.628), train_loss = 0.34406444, grad/param norm = 2.2004e-01, time/batch = 16.1390s	
15445/22300 (epoch 34.630), train_loss = 0.41724389, grad/param norm = 2.8544e-01, time/batch = 16.7964s	
15446/22300 (epoch 34.632), train_loss = 0.33674663, grad/param norm = 2.5573e-01, time/batch = 16.6368s	
15447/22300 (epoch 34.635), train_loss = 0.38357876, grad/param norm = 2.2447e-01, time/batch = 18.2787s	
15448/22300 (epoch 34.637), train_loss = 0.45438683, grad/param norm = 2.7565e-01, time/batch = 16.3816s	
15449/22300 (epoch 34.639), train_loss = 0.54549979, grad/param norm = 3.1961e-01, time/batch = 17.2140s	
15450/22300 (epoch 34.641), train_loss = 0.46440264, grad/param norm = 2.8149e-01, time/batch = 15.4485s	
15451/22300 (epoch 34.643), train_loss = 0.33808710, grad/param norm = 2.4047e-01, time/batch = 15.1490s	
15452/22300 (epoch 34.646), train_loss = 0.33114905, grad/param norm = 2.2884e-01, time/batch = 16.8925s	
15453/22300 (epoch 34.648), train_loss = 0.43009560, grad/param norm = 1.9663e-01, time/batch = 16.5587s	
15454/22300 (epoch 34.650), train_loss = 0.45648574, grad/param norm = 2.7820e-01, time/batch = 16.9780s	
15455/22300 (epoch 34.652), train_loss = 0.37216208, grad/param norm = 2.3963e-01, time/batch = 15.9228s	
15456/22300 (epoch 34.655), train_loss = 0.31771462, grad/param norm = 2.3292e-01, time/batch = 18.0419s	
15457/22300 (epoch 34.657), train_loss = 0.36388964, grad/param norm = 2.7313e-01, time/batch = 16.9889s	
15458/22300 (epoch 34.659), train_loss = 0.35179545, grad/param norm = 2.3820e-01, time/batch = 16.3933s	
15459/22300 (epoch 34.661), train_loss = 0.28563381, grad/param norm = 2.2012e-01, time/batch = 15.3021s	
15460/22300 (epoch 34.664), train_loss = 0.33818303, grad/param norm = 2.3401e-01, time/batch = 18.2996s	
15461/22300 (epoch 34.666), train_loss = 0.45484831, grad/param norm = 2.9849e-01, time/batch = 16.6426s	
15462/22300 (epoch 34.668), train_loss = 0.31664995, grad/param norm = 2.2602e-01, time/batch = 14.8889s	
15463/22300 (epoch 34.670), train_loss = 0.40549164, grad/param norm = 2.2854e-01, time/batch = 17.6237s	
15464/22300 (epoch 34.673), train_loss = 0.47646491, grad/param norm = 2.5817e-01, time/batch = 17.7910s	
15465/22300 (epoch 34.675), train_loss = 0.54992023, grad/param norm = 3.4292e-01, time/batch = 16.3832s	
15466/22300 (epoch 34.677), train_loss = 0.61707961, grad/param norm = 3.4208e-01, time/batch = 16.3030s	
15467/22300 (epoch 34.679), train_loss = 0.43400119, grad/param norm = 2.9411e-01, time/batch = 17.9580s	
15468/22300 (epoch 34.682), train_loss = 0.40118497, grad/param norm = 2.7204e-01, time/batch = 15.8955s	
15469/22300 (epoch 34.684), train_loss = 0.38074170, grad/param norm = 2.4431e-01, time/batch = 15.1497s	
15470/22300 (epoch 34.686), train_loss = 0.37584507, grad/param norm = 2.7978e-01, time/batch = 16.3977s	
15471/22300 (epoch 34.688), train_loss = 0.35678760, grad/param norm = 2.4904e-01, time/batch = 16.6401s	
15472/22300 (epoch 34.691), train_loss = 0.33412856, grad/param norm = 3.0671e-01, time/batch = 16.2800s	
15473/22300 (epoch 34.693), train_loss = 0.32657743, grad/param norm = 2.6667e-01, time/batch = 14.8116s	
15474/22300 (epoch 34.695), train_loss = 0.33984177, grad/param norm = 2.0934e-01, time/batch = 16.4805s	
15475/22300 (epoch 34.697), train_loss = 0.35947588, grad/param norm = 2.1784e-01, time/batch = 17.4483s	
15476/22300 (epoch 34.700), train_loss = 0.32133305, grad/param norm = 2.1193e-01, time/batch = 16.3844s	
15477/22300 (epoch 34.702), train_loss = 0.26381227, grad/param norm = 1.8076e-01, time/batch = 15.9781s	
15478/22300 (epoch 34.704), train_loss = 0.36291784, grad/param norm = 2.9602e-01, time/batch = 16.7945s	
15479/22300 (epoch 34.706), train_loss = 0.32694251, grad/param norm = 2.5244e-01, time/batch = 14.7185s	
15480/22300 (epoch 34.709), train_loss = 0.28809638, grad/param norm = 2.4630e-01, time/batch = 15.8068s	
15481/22300 (epoch 34.711), train_loss = 0.27288666, grad/param norm = 1.8942e-01, time/batch = 18.6226s	
15482/22300 (epoch 34.713), train_loss = 0.39887033, grad/param norm = 2.5758e-01, time/batch = 16.3118s	
15483/22300 (epoch 34.715), train_loss = 0.40403452, grad/param norm = 2.5757e-01, time/batch = 16.4737s	
15484/22300 (epoch 34.717), train_loss = 0.53377614, grad/param norm = 2.4766e-01, time/batch = 15.4609s	
15485/22300 (epoch 34.720), train_loss = 0.35632572, grad/param norm = 2.6217e-01, time/batch = 17.6517s	
15486/22300 (epoch 34.722), train_loss = 0.39523558, grad/param norm = 2.4001e-01, time/batch = 16.2311s	
15487/22300 (epoch 34.724), train_loss = 0.45085654, grad/param norm = 4.0529e-01, time/batch = 15.3880s	
15488/22300 (epoch 34.726), train_loss = 0.33588746, grad/param norm = 2.3104e-01, time/batch = 16.4780s	
15489/22300 (epoch 34.729), train_loss = 0.42225130, grad/param norm = 2.7869e-01, time/batch = 16.9776s	
15490/22300 (epoch 34.731), train_loss = 0.52473849, grad/param norm = 3.0902e-01, time/batch = 18.0651s	
15491/22300 (epoch 34.733), train_loss = 0.50936622, grad/param norm = 3.1394e-01, time/batch = 16.6952s	
15492/22300 (epoch 34.735), train_loss = 0.55405238, grad/param norm = 3.2572e-01, time/batch = 18.6948s	
15493/22300 (epoch 34.738), train_loss = 0.39847483, grad/param norm = 3.1250e-01, time/batch = 16.4685s	
15494/22300 (epoch 34.740), train_loss = 0.37907985, grad/param norm = 2.2880e-01, time/batch = 16.8655s	
15495/22300 (epoch 34.742), train_loss = 0.32544121, grad/param norm = 2.1154e-01, time/batch = 15.1977s	
15496/22300 (epoch 34.744), train_loss = 0.56667981, grad/param norm = 2.9693e-01, time/batch = 15.3184s	
15497/22300 (epoch 34.747), train_loss = 0.45747470, grad/param norm = 2.3999e-01, time/batch = 16.0727s	
15498/22300 (epoch 34.749), train_loss = 0.58355340, grad/param norm = 3.4454e-01, time/batch = 16.8812s	
15499/22300 (epoch 34.751), train_loss = 0.52975540, grad/param norm = 3.5739e-01, time/batch = 19.1944s	
15500/22300 (epoch 34.753), train_loss = 0.54757255, grad/param norm = 3.2663e-01, time/batch = 17.0507s	
15501/22300 (epoch 34.756), train_loss = 0.49208889, grad/param norm = 2.7742e-01, time/batch = 15.1167s	
15502/22300 (epoch 34.758), train_loss = 0.43621325, grad/param norm = 2.7787e-01, time/batch = 15.4346s	
15503/22300 (epoch 34.760), train_loss = 0.46232408, grad/param norm = 2.7338e-01, time/batch = 17.1515s	
15504/22300 (epoch 34.762), train_loss = 0.43380366, grad/param norm = 2.7621e-01, time/batch = 16.4814s	
15505/22300 (epoch 34.765), train_loss = 0.43065383, grad/param norm = 2.5796e-01, time/batch = 16.2183s	
15506/22300 (epoch 34.767), train_loss = 0.41979715, grad/param norm = 2.3560e-01, time/batch = 17.3029s	
15507/22300 (epoch 34.769), train_loss = 0.40838994, grad/param norm = 2.4618e-01, time/batch = 16.3067s	
15508/22300 (epoch 34.771), train_loss = 0.47879497, grad/param norm = 2.8110e-01, time/batch = 16.2881s	
15509/22300 (epoch 34.774), train_loss = 0.50289622, grad/param norm = 2.9053e-01, time/batch = 15.5590s	
15510/22300 (epoch 34.776), train_loss = 0.53602094, grad/param norm = 2.6967e-01, time/batch = 17.6354s	
15511/22300 (epoch 34.778), train_loss = 0.54605631, grad/param norm = 3.7767e-01, time/batch = 15.7286s	
15512/22300 (epoch 34.780), train_loss = 0.51978305, grad/param norm = 3.0996e-01, time/batch = 15.9483s	
15513/22300 (epoch 34.783), train_loss = 0.54458584, grad/param norm = 3.4881e-01, time/batch = 15.7272s	
15514/22300 (epoch 34.785), train_loss = 0.40493405, grad/param norm = 2.7697e-01, time/batch = 17.7986s	
15515/22300 (epoch 34.787), train_loss = 0.39946090, grad/param norm = 2.9470e-01, time/batch = 17.8964s	
15516/22300 (epoch 34.789), train_loss = 0.59228367, grad/param norm = 3.4301e-01, time/batch = 16.6300s	
15517/22300 (epoch 34.791), train_loss = 0.67716173, grad/param norm = 3.2464e-01, time/batch = 17.5517s	
15518/22300 (epoch 34.794), train_loss = 0.57662629, grad/param norm = 3.5286e-01, time/batch = 18.2187s	
15519/22300 (epoch 34.796), train_loss = 0.50120830, grad/param norm = 3.3151e-01, time/batch = 17.0492s	
15520/22300 (epoch 34.798), train_loss = 0.66286833, grad/param norm = 3.2981e-01, time/batch = 16.1085s	
15521/22300 (epoch 34.800), train_loss = 0.46088576, grad/param norm = 2.8244e-01, time/batch = 16.7241s	
15522/22300 (epoch 34.803), train_loss = 0.40032235, grad/param norm = 2.5045e-01, time/batch = 17.2269s	
15523/22300 (epoch 34.805), train_loss = 0.46514079, grad/param norm = 2.6564e-01, time/batch = 15.9824s	
15524/22300 (epoch 34.807), train_loss = 0.61696047, grad/param norm = 3.8147e-01, time/batch = 15.8171s	
15525/22300 (epoch 34.809), train_loss = 0.43051759, grad/param norm = 2.5775e-01, time/batch = 15.3078s	
15526/22300 (epoch 34.812), train_loss = 0.47506740, grad/param norm = 2.8289e-01, time/batch = 16.4857s	
15527/22300 (epoch 34.814), train_loss = 0.45795788, grad/param norm = 2.9635e-01, time/batch = 15.5480s	
15528/22300 (epoch 34.816), train_loss = 0.51117278, grad/param norm = 3.0155e-01, time/batch = 17.4005s	
15529/22300 (epoch 34.818), train_loss = 0.56172274, grad/param norm = 3.6965e-01, time/batch = 16.5660s	
15530/22300 (epoch 34.821), train_loss = 0.51089536, grad/param norm = 2.8830e-01, time/batch = 16.7989s	
15531/22300 (epoch 34.823), train_loss = 0.32095123, grad/param norm = 2.3217e-01, time/batch = 15.7830s	
15532/22300 (epoch 34.825), train_loss = 0.33686318, grad/param norm = 2.3815e-01, time/batch = 17.4561s	
15533/22300 (epoch 34.827), train_loss = 0.40327339, grad/param norm = 2.8047e-01, time/batch = 16.2674s	
15534/22300 (epoch 34.830), train_loss = 0.39337886, grad/param norm = 2.9548e-01, time/batch = 15.7902s	
15535/22300 (epoch 34.832), train_loss = 0.37538935, grad/param norm = 2.5497e-01, time/batch = 16.0663s	
15536/22300 (epoch 34.834), train_loss = 0.32598304, grad/param norm = 2.5914e-01, time/batch = 17.7942s	
15537/22300 (epoch 34.836), train_loss = 0.39279312, grad/param norm = 2.5762e-01, time/batch = 16.9691s	
15538/22300 (epoch 34.839), train_loss = 0.40529329, grad/param norm = 3.1434e-01, time/batch = 15.0263s	
15539/22300 (epoch 34.841), train_loss = 0.41822473, grad/param norm = 3.0032e-01, time/batch = 16.8135s	
15540/22300 (epoch 34.843), train_loss = 0.40693617, grad/param norm = 2.7589e-01, time/batch = 16.3975s	
15541/22300 (epoch 34.845), train_loss = 0.40339918, grad/param norm = 2.9399e-01, time/batch = 15.8957s	
15542/22300 (epoch 34.848), train_loss = 0.39772232, grad/param norm = 2.5781e-01, time/batch = 16.1408s	
15543/22300 (epoch 34.850), train_loss = 0.41059355, grad/param norm = 2.2732e-01, time/batch = 17.7179s	
15544/22300 (epoch 34.852), train_loss = 0.38753053, grad/param norm = 2.8643e-01, time/batch = 16.9054s	
15545/22300 (epoch 34.854), train_loss = 0.59329073, grad/param norm = 3.4648e-01, time/batch = 15.3827s	
15546/22300 (epoch 34.857), train_loss = 0.46433272, grad/param norm = 3.0838e-01, time/batch = 17.5554s	
15547/22300 (epoch 34.859), train_loss = 0.39078423, grad/param norm = 2.6013e-01, time/batch = 18.5395s	
15548/22300 (epoch 34.861), train_loss = 0.48241787, grad/param norm = 2.6274e-01, time/batch = 16.8842s	
15549/22300 (epoch 34.863), train_loss = 0.33166101, grad/param norm = 2.9676e-01, time/batch = 15.5425s	
15550/22300 (epoch 34.865), train_loss = 0.32776761, grad/param norm = 2.2669e-01, time/batch = 16.0250s	
15551/22300 (epoch 34.868), train_loss = 0.44396452, grad/param norm = 2.8365e-01, time/batch = 15.0456s	
15552/22300 (epoch 34.870), train_loss = 0.45423037, grad/param norm = 2.9541e-01, time/batch = 15.6314s	
15553/22300 (epoch 34.872), train_loss = 0.54438634, grad/param norm = 2.7340e-01, time/batch = 18.2961s	
15554/22300 (epoch 34.874), train_loss = 0.45435994, grad/param norm = 3.0582e-01, time/batch = 16.1277s	
15555/22300 (epoch 34.877), train_loss = 0.43642400, grad/param norm = 2.5558e-01, time/batch = 17.4691s	
15556/22300 (epoch 34.879), train_loss = 0.39492123, grad/param norm = 2.3766e-01, time/batch = 15.9956s	
15557/22300 (epoch 34.881), train_loss = 0.31911913, grad/param norm = 2.1110e-01, time/batch = 15.7011s	
15558/22300 (epoch 34.883), train_loss = 0.35223530, grad/param norm = 2.5787e-01, time/batch = 16.3976s	
15559/22300 (epoch 34.886), train_loss = 0.31725443, grad/param norm = 2.3741e-01, time/batch = 16.9777s	
15560/22300 (epoch 34.888), train_loss = 0.38837237, grad/param norm = 2.5163e-01, time/batch = 15.5496s	
15561/22300 (epoch 34.890), train_loss = 0.37626023, grad/param norm = 2.5027e-01, time/batch = 17.2214s	
15562/22300 (epoch 34.892), train_loss = 0.58832545, grad/param norm = 3.0617e-01, time/batch = 17.5519s	
15563/22300 (epoch 34.895), train_loss = 0.51053683, grad/param norm = 2.8254e-01, time/batch = 15.2292s	
15564/22300 (epoch 34.897), train_loss = 0.41057572, grad/param norm = 2.8610e-01, time/batch = 17.7230s	
15565/22300 (epoch 34.899), train_loss = 0.40390497, grad/param norm = 2.5994e-01, time/batch = 16.0557s	
15566/22300 (epoch 34.901), train_loss = 0.47735103, grad/param norm = 2.5528e-01, time/batch = 16.8067s	
15567/22300 (epoch 34.904), train_loss = 0.48158398, grad/param norm = 2.8042e-01, time/batch = 15.8061s	
15568/22300 (epoch 34.906), train_loss = 0.47142261, grad/param norm = 2.7662e-01, time/batch = 16.2121s	
15569/22300 (epoch 34.908), train_loss = 0.39846419, grad/param norm = 2.1742e-01, time/batch = 17.2956s	
15570/22300 (epoch 34.910), train_loss = 0.35750305, grad/param norm = 2.2462e-01, time/batch = 15.2853s	
15571/22300 (epoch 34.913), train_loss = 0.49039709, grad/param norm = 3.1693e-01, time/batch = 18.9771s	
15572/22300 (epoch 34.915), train_loss = 0.56595305, grad/param norm = 2.7550e-01, time/batch = 17.5452s	
15573/22300 (epoch 34.917), train_loss = 0.50430794, grad/param norm = 3.6520e-01, time/batch = 17.4509s	
15574/22300 (epoch 34.919), train_loss = 0.49498370, grad/param norm = 2.9654e-01, time/batch = 15.6144s	
15575/22300 (epoch 34.922), train_loss = 0.46789574, grad/param norm = 3.3628e-01, time/batch = 17.3746s	
15576/22300 (epoch 34.924), train_loss = 0.28701965, grad/param norm = 2.0182e-01, time/batch = 14.9898s	
15577/22300 (epoch 34.926), train_loss = 0.38254272, grad/param norm = 2.4048e-01, time/batch = 17.5553s	
15578/22300 (epoch 34.928), train_loss = 0.38217994, grad/param norm = 2.7959e-01, time/batch = 17.9555s	
15579/22300 (epoch 34.930), train_loss = 0.37768576, grad/param norm = 2.9517e-01, time/batch = 16.0928s	
15580/22300 (epoch 34.933), train_loss = 0.45575585, grad/param norm = 2.8961e-01, time/batch = 17.4740s	
15581/22300 (epoch 34.935), train_loss = 0.43049113, grad/param norm = 2.7279e-01, time/batch = 15.4606s	
15582/22300 (epoch 34.937), train_loss = 0.53551822, grad/param norm = 3.4333e-01, time/batch = 18.2149s	
15583/22300 (epoch 34.939), train_loss = 0.47700082, grad/param norm = 3.2102e-01, time/batch = 16.4674s	
15584/22300 (epoch 34.942), train_loss = 0.58549467, grad/param norm = 3.4133e-01, time/batch = 15.4657s	
15585/22300 (epoch 34.944), train_loss = 0.65804364, grad/param norm = 4.0632e-01, time/batch = 15.8940s	
15586/22300 (epoch 34.946), train_loss = 0.47735946, grad/param norm = 2.9697e-01, time/batch = 15.9734s	
15587/22300 (epoch 34.948), train_loss = 0.42137674, grad/param norm = 2.7476e-01, time/batch = 17.9634s	
15588/22300 (epoch 34.951), train_loss = 0.32826259, grad/param norm = 2.3610e-01, time/batch = 15.7753s	
15589/22300 (epoch 34.953), train_loss = 0.37679330, grad/param norm = 2.8481e-01, time/batch = 18.1327s	
15590/22300 (epoch 34.955), train_loss = 0.54880236, grad/param norm = 2.7855e-01, time/batch = 17.1245s	
15591/22300 (epoch 34.957), train_loss = 0.64788696, grad/param norm = 3.2860e-01, time/batch = 15.7160s	
15592/22300 (epoch 34.960), train_loss = 0.52992264, grad/param norm = 2.3817e-01, time/batch = 15.1430s	
15593/22300 (epoch 34.962), train_loss = 0.35117550, grad/param norm = 2.5530e-01, time/batch = 16.7285s	
15594/22300 (epoch 34.964), train_loss = 0.39222095, grad/param norm = 2.6532e-01, time/batch = 16.4822s	
15595/22300 (epoch 34.966), train_loss = 0.39394290, grad/param norm = 2.8248e-01, time/batch = 16.6287s	
15596/22300 (epoch 34.969), train_loss = 0.42992568, grad/param norm = 2.7338e-01, time/batch = 16.5466s	
15597/22300 (epoch 34.971), train_loss = 0.44349305, grad/param norm = 2.7533e-01, time/batch = 16.9740s	
15598/22300 (epoch 34.973), train_loss = 0.42649896, grad/param norm = 3.2035e-01, time/batch = 17.9602s	
15599/22300 (epoch 34.975), train_loss = 0.57908662, grad/param norm = 4.0644e-01, time/batch = 16.9503s	
15600/22300 (epoch 34.978), train_loss = 0.55146171, grad/param norm = 3.2812e-01, time/batch = 16.7076s	
15601/22300 (epoch 34.980), train_loss = 0.60707372, grad/param norm = 4.1815e-01, time/batch = 16.2121s	
15602/22300 (epoch 34.982), train_loss = 0.36244516, grad/param norm = 3.3646e-01, time/batch = 15.7488s	
15603/22300 (epoch 34.984), train_loss = 0.43305779, grad/param norm = 2.7380e-01, time/batch = 14.9656s	
15604/22300 (epoch 34.987), train_loss = 0.42535841, grad/param norm = 3.1490e-01, time/batch = 15.4050s	
15605/22300 (epoch 34.989), train_loss = 0.36230812, grad/param norm = 2.8043e-01, time/batch = 15.3032s	
15606/22300 (epoch 34.991), train_loss = 0.62561419, grad/param norm = 3.6384e-01, time/batch = 17.2078s	
15607/22300 (epoch 34.993), train_loss = 0.79910859, grad/param norm = 3.6267e-01, time/batch = 16.0815s	
15608/22300 (epoch 34.996), train_loss = 0.75286048, grad/param norm = 3.5815e-01, time/batch = 15.6495s	
15609/22300 (epoch 34.998), train_loss = 0.47235027, grad/param norm = 2.6801e-01, time/batch = 17.8070s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
15610/22300 (epoch 35.000), train_loss = 0.39104715, grad/param norm = 2.6012e-01, time/batch = 31.6263s	
15611/22300 (epoch 35.002), train_loss = 0.74503680, grad/param norm = 3.1860e-01, time/batch = 16.6563s	
15612/22300 (epoch 35.004), train_loss = 0.49760912, grad/param norm = 2.6970e-01, time/batch = 15.1305s	
15613/22300 (epoch 35.007), train_loss = 0.51314753, grad/param norm = 3.1199e-01, time/batch = 16.7057s	
15614/22300 (epoch 35.009), train_loss = 0.53215033, grad/param norm = 3.2468e-01, time/batch = 16.3570s	
15615/22300 (epoch 35.011), train_loss = 0.63954990, grad/param norm = 3.8982e-01, time/batch = 15.5690s	
15616/22300 (epoch 35.013), train_loss = 0.49751979, grad/param norm = 2.8327e-01, time/batch = 16.3810s	
15617/22300 (epoch 35.016), train_loss = 0.40954916, grad/param norm = 3.1896e-01, time/batch = 16.0515s	
15618/22300 (epoch 35.018), train_loss = 0.44883332, grad/param norm = 3.1411e-01, time/batch = 17.0576s	
15619/22300 (epoch 35.020), train_loss = 0.41440470, grad/param norm = 2.5867e-01, time/batch = 17.7198s	
15620/22300 (epoch 35.022), train_loss = 0.35721803, grad/param norm = 2.9977e-01, time/batch = 17.3590s	
15621/22300 (epoch 35.025), train_loss = 0.37572414, grad/param norm = 2.4106e-01, time/batch = 16.4586s	
15622/22300 (epoch 35.027), train_loss = 0.36505096, grad/param norm = 2.2014e-01, time/batch = 18.5458s	
15623/22300 (epoch 35.029), train_loss = 0.38831469, grad/param norm = 2.6153e-01, time/batch = 16.1369s	
15624/22300 (epoch 35.031), train_loss = 0.35121331, grad/param norm = 2.0697e-01, time/batch = 18.4674s	
15625/22300 (epoch 35.034), train_loss = 0.38402450, grad/param norm = 2.6815e-01, time/batch = 15.3888s	
15626/22300 (epoch 35.036), train_loss = 0.34337331, grad/param norm = 2.1677e-01, time/batch = 16.6395s	
15627/22300 (epoch 35.038), train_loss = 0.32042560, grad/param norm = 2.2966e-01, time/batch = 17.3659s	
15628/22300 (epoch 35.040), train_loss = 0.40363174, grad/param norm = 2.9320e-01, time/batch = 16.0604s	
15629/22300 (epoch 35.043), train_loss = 0.60308536, grad/param norm = 3.4631e-01, time/batch = 16.3760s	
15630/22300 (epoch 35.045), train_loss = 0.50964582, grad/param norm = 2.6925e-01, time/batch = 17.2189s	
15631/22300 (epoch 35.047), train_loss = 0.52396021, grad/param norm = 2.8754e-01, time/batch = 18.1360s	
15632/22300 (epoch 35.049), train_loss = 0.41243119, grad/param norm = 2.3919e-01, time/batch = 16.1473s	
15633/22300 (epoch 35.052), train_loss = 0.50312929, grad/param norm = 3.3634e-01, time/batch = 17.4733s	
15634/22300 (epoch 35.054), train_loss = 0.48740731, grad/param norm = 2.7460e-01, time/batch = 16.7080s	
15635/22300 (epoch 35.056), train_loss = 0.24236766, grad/param norm = 1.8787e-01, time/batch = 15.8955s	
15636/22300 (epoch 35.058), train_loss = 0.41008025, grad/param norm = 2.6631e-01, time/batch = 15.6676s	
15637/22300 (epoch 35.061), train_loss = 0.35923667, grad/param norm = 2.5599e-01, time/batch = 16.8002s	
15638/22300 (epoch 35.063), train_loss = 0.54460237, grad/param norm = 3.8256e-01, time/batch = 15.1490s	
15639/22300 (epoch 35.065), train_loss = 0.60115175, grad/param norm = 3.1781e-01, time/batch = 17.3862s	
15640/22300 (epoch 35.067), train_loss = 0.35686299, grad/param norm = 2.3389e-01, time/batch = 15.0529s	
15641/22300 (epoch 35.070), train_loss = 0.43280461, grad/param norm = 3.3142e-01, time/batch = 15.9914s	
15642/22300 (epoch 35.072), train_loss = 0.48492529, grad/param norm = 2.8419e-01, time/batch = 17.6278s	
15643/22300 (epoch 35.074), train_loss = 0.47428026, grad/param norm = 2.8478e-01, time/batch = 15.5577s	
15644/22300 (epoch 35.076), train_loss = 0.47756798, grad/param norm = 3.4106e-01, time/batch = 18.8847s	
15645/22300 (epoch 35.078), train_loss = 0.57528782, grad/param norm = 3.3894e-01, time/batch = 15.0272s	
15646/22300 (epoch 35.081), train_loss = 0.56799144, grad/param norm = 3.7416e-01, time/batch = 17.7953s	
15647/22300 (epoch 35.083), train_loss = 0.62263717, grad/param norm = 3.6463e-01, time/batch = 16.5521s	
15648/22300 (epoch 35.085), train_loss = 0.59829292, grad/param norm = 3.3519e-01, time/batch = 15.0343s	
15649/22300 (epoch 35.087), train_loss = 0.51274468, grad/param norm = 3.1868e-01, time/batch = 16.9637s	
15650/22300 (epoch 35.090), train_loss = 0.46570561, grad/param norm = 3.0312e-01, time/batch = 16.0691s	
15651/22300 (epoch 35.092), train_loss = 0.35826401, grad/param norm = 2.3059e-01, time/batch = 16.9015s	
15652/22300 (epoch 35.094), train_loss = 0.36983953, grad/param norm = 2.7839e-01, time/batch = 15.9619s	
15653/22300 (epoch 35.096), train_loss = 0.60866140, grad/param norm = 3.1525e-01, time/batch = 19.2887s	
15654/22300 (epoch 35.099), train_loss = 0.39839922, grad/param norm = 2.3533e-01, time/batch = 16.7311s	
15655/22300 (epoch 35.101), train_loss = 0.51474540, grad/param norm = 2.8635e-01, time/batch = 17.6086s	
15656/22300 (epoch 35.103), train_loss = 0.43963568, grad/param norm = 2.5820e-01, time/batch = 15.8603s	
15657/22300 (epoch 35.105), train_loss = 0.35382730, grad/param norm = 2.6875e-01, time/batch = 18.6179s	
15658/22300 (epoch 35.108), train_loss = 0.47683333, grad/param norm = 2.6188e-01, time/batch = 15.4810s	
15659/22300 (epoch 35.110), train_loss = 0.52405432, grad/param norm = 2.8068e-01, time/batch = 15.4528s	
15660/22300 (epoch 35.112), train_loss = 0.48208853, grad/param norm = 2.5071e-01, time/batch = 18.2020s	
15661/22300 (epoch 35.114), train_loss = 0.52478841, grad/param norm = 3.2662e-01, time/batch = 16.8140s	
15662/22300 (epoch 35.117), train_loss = 0.59927241, grad/param norm = 2.7213e-01, time/batch = 16.3871s	
15663/22300 (epoch 35.119), train_loss = 0.54778420, grad/param norm = 3.1036e-01, time/batch = 16.2213s	
15664/22300 (epoch 35.121), train_loss = 0.64076098, grad/param norm = 3.3806e-01, time/batch = 17.6455s	
15665/22300 (epoch 35.123), train_loss = 0.62805577, grad/param norm = 2.9971e-01, time/batch = 15.4923s	
15666/22300 (epoch 35.126), train_loss = 0.49334214, grad/param norm = 2.4805e-01, time/batch = 15.8898s	
15667/22300 (epoch 35.128), train_loss = 0.48610180, grad/param norm = 3.0417e-01, time/batch = 16.1805s	
15668/22300 (epoch 35.130), train_loss = 0.42211734, grad/param norm = 2.8584e-01, time/batch = 16.8186s	
15669/22300 (epoch 35.132), train_loss = 0.29471786, grad/param norm = 1.7577e-01, time/batch = 18.0603s	
15670/22300 (epoch 35.135), train_loss = 0.32158706, grad/param norm = 2.7002e-01, time/batch = 16.9391s	
15671/22300 (epoch 35.137), train_loss = 0.25910051, grad/param norm = 2.1004e-01, time/batch = 19.4565s	
15672/22300 (epoch 35.139), train_loss = 0.40968225, grad/param norm = 3.0722e-01, time/batch = 16.0267s	
15673/22300 (epoch 35.141), train_loss = 0.52960337, grad/param norm = 2.5993e-01, time/batch = 16.0632s	
15674/22300 (epoch 35.143), train_loss = 0.44683443, grad/param norm = 2.5072e-01, time/batch = 15.4518s	
15675/22300 (epoch 35.146), train_loss = 0.54460179, grad/param norm = 3.3945e-01, time/batch = 17.7174s	
15676/22300 (epoch 35.148), train_loss = 0.35309554, grad/param norm = 2.5473e-01, time/batch = 17.5583s	
15677/22300 (epoch 35.150), train_loss = 0.38151645, grad/param norm = 2.4388e-01, time/batch = 15.7074s	
15678/22300 (epoch 35.152), train_loss = 0.35316779, grad/param norm = 3.2199e-01, time/batch = 15.9099s	
15679/22300 (epoch 35.155), train_loss = 0.36887323, grad/param norm = 2.5300e-01, time/batch = 18.1346s	
15680/22300 (epoch 35.157), train_loss = 0.45949053, grad/param norm = 2.7359e-01, time/batch = 17.3682s	
15681/22300 (epoch 35.159), train_loss = 0.50320434, grad/param norm = 3.2848e-01, time/batch = 15.3835s	
15682/22300 (epoch 35.161), train_loss = 0.50635837, grad/param norm = 3.1149e-01, time/batch = 17.5403s	
15683/22300 (epoch 35.164), train_loss = 0.35954657, grad/param norm = 2.5856e-01, time/batch = 16.7312s	
15684/22300 (epoch 35.166), train_loss = 0.31739560, grad/param norm = 2.2684e-01, time/batch = 15.2985s	
15685/22300 (epoch 35.168), train_loss = 0.33506220, grad/param norm = 2.4882e-01, time/batch = 15.9807s	
15686/22300 (epoch 35.170), train_loss = 0.43736749, grad/param norm = 2.5653e-01, time/batch = 18.1326s	
15687/22300 (epoch 35.173), train_loss = 0.53724558, grad/param norm = 3.6135e-01, time/batch = 16.9462s	
15688/22300 (epoch 35.175), train_loss = 0.45261341, grad/param norm = 3.0207e-01, time/batch = 17.2397s	
15689/22300 (epoch 35.177), train_loss = 0.30922533, grad/param norm = 2.4293e-01, time/batch = 15.8225s	
15690/22300 (epoch 35.179), train_loss = 0.44024266, grad/param norm = 2.5420e-01, time/batch = 18.1370s	
15691/22300 (epoch 35.182), train_loss = 0.59869350, grad/param norm = 3.1748e-01, time/batch = 15.5460s	
15692/22300 (epoch 35.184), train_loss = 0.65104039, grad/param norm = 3.8387e-01, time/batch = 16.8978s	
15693/22300 (epoch 35.186), train_loss = 0.48030418, grad/param norm = 3.3061e-01, time/batch = 16.2773s	
15694/22300 (epoch 35.188), train_loss = 0.65930249, grad/param norm = 3.6503e-01, time/batch = 17.4456s	
15695/22300 (epoch 35.191), train_loss = 0.54309266, grad/param norm = 3.1198e-01, time/batch = 15.6290s	
15696/22300 (epoch 35.193), train_loss = 0.48459881, grad/param norm = 3.1049e-01, time/batch = 15.3668s	
15697/22300 (epoch 35.195), train_loss = 0.45048374, grad/param norm = 3.1169e-01, time/batch = 17.4758s	
15698/22300 (epoch 35.197), train_loss = 0.39382753, grad/param norm = 2.4821e-01, time/batch = 16.5247s	
15699/22300 (epoch 35.200), train_loss = 0.36836819, grad/param norm = 2.6432e-01, time/batch = 18.1986s	
15700/22300 (epoch 35.202), train_loss = 0.38380997, grad/param norm = 2.5727e-01, time/batch = 16.2365s	
15701/22300 (epoch 35.204), train_loss = 0.42705846, grad/param norm = 2.3509e-01, time/batch = 17.4765s	
15702/22300 (epoch 35.206), train_loss = 0.37584350, grad/param norm = 2.8995e-01, time/batch = 16.5225s	
15703/22300 (epoch 35.209), train_loss = 0.39868648, grad/param norm = 2.6617e-01, time/batch = 17.7118s	
15704/22300 (epoch 35.211), train_loss = 0.32002786, grad/param norm = 2.4212e-01, time/batch = 17.5396s	
15705/22300 (epoch 35.213), train_loss = 0.47429767, grad/param norm = 3.4340e-01, time/batch = 15.6146s	
15706/22300 (epoch 35.215), train_loss = 0.57346848, grad/param norm = 3.4969e-01, time/batch = 16.6267s	
15707/22300 (epoch 35.217), train_loss = 0.59522745, grad/param norm = 2.9401e-01, time/batch = 17.2189s	
15708/22300 (epoch 35.220), train_loss = 0.41072588, grad/param norm = 2.4173e-01, time/batch = 16.1526s	
15709/22300 (epoch 35.222), train_loss = 0.39339229, grad/param norm = 3.8103e-01, time/batch = 15.2940s	
15710/22300 (epoch 35.224), train_loss = 0.37549737, grad/param norm = 2.3927e-01, time/batch = 16.0485s	
15711/22300 (epoch 35.226), train_loss = 0.42028015, grad/param norm = 2.2868e-01, time/batch = 15.5326s	
15712/22300 (epoch 35.229), train_loss = 0.37478364, grad/param norm = 2.6147e-01, time/batch = 15.8139s	
15713/22300 (epoch 35.231), train_loss = 0.54828376, grad/param norm = 3.3016e-01, time/batch = 15.7071s	
15714/22300 (epoch 35.233), train_loss = 0.43773766, grad/param norm = 2.6343e-01, time/batch = 18.2240s	
15715/22300 (epoch 35.235), train_loss = 0.34858821, grad/param norm = 2.4098e-01, time/batch = 17.6353s	
15716/22300 (epoch 35.238), train_loss = 0.36071667, grad/param norm = 2.1424e-01, time/batch = 15.7893s	
15717/22300 (epoch 35.240), train_loss = 0.36355348, grad/param norm = 1.9326e-01, time/batch = 17.4644s	
15718/22300 (epoch 35.242), train_loss = 0.34348327, grad/param norm = 2.5348e-01, time/batch = 14.9831s	
15719/22300 (epoch 35.244), train_loss = 0.24013942, grad/param norm = 1.7641e-01, time/batch = 17.5336s	
15720/22300 (epoch 35.247), train_loss = 0.32209424, grad/param norm = 1.9127e-01, time/batch = 15.4785s	
15721/22300 (epoch 35.249), train_loss = 0.22176300, grad/param norm = 1.4498e-01, time/batch = 15.7224s	
15722/22300 (epoch 35.251), train_loss = 0.30108048, grad/param norm = 1.8902e-01, time/batch = 16.4903s	
15723/22300 (epoch 35.253), train_loss = 0.22332935, grad/param norm = 2.3011e-01, time/batch = 16.3898s	
15724/22300 (epoch 35.256), train_loss = 0.30786767, grad/param norm = 2.2952e-01, time/batch = 15.2172s	
15725/22300 (epoch 35.258), train_loss = 0.48154357, grad/param norm = 3.3414e-01, time/batch = 16.0246s	
15726/22300 (epoch 35.260), train_loss = 0.44478271, grad/param norm = 2.4339e-01, time/batch = 16.2139s	
15727/22300 (epoch 35.262), train_loss = 0.33152640, grad/param norm = 2.0740e-01, time/batch = 17.2080s	
15728/22300 (epoch 35.265), train_loss = 0.31708365, grad/param norm = 2.3688e-01, time/batch = 15.5616s	
15729/22300 (epoch 35.267), train_loss = 0.34334931, grad/param norm = 2.4323e-01, time/batch = 16.8191s	
15730/22300 (epoch 35.269), train_loss = 0.42825086, grad/param norm = 3.0602e-01, time/batch = 16.7259s	
15731/22300 (epoch 35.271), train_loss = 0.47762798, grad/param norm = 3.1548e-01, time/batch = 14.9693s	
15732/22300 (epoch 35.274), train_loss = 0.33890392, grad/param norm = 2.5474e-01, time/batch = 15.9876s	
15733/22300 (epoch 35.276), train_loss = 0.29330233, grad/param norm = 2.2079e-01, time/batch = 16.8979s	
15734/22300 (epoch 35.278), train_loss = 0.30521261, grad/param norm = 2.0960e-01, time/batch = 15.5439s	
15735/22300 (epoch 35.280), train_loss = 0.33812843, grad/param norm = 2.1858e-01, time/batch = 16.0559s	
15736/22300 (epoch 35.283), train_loss = 0.26972208, grad/param norm = 1.8617e-01, time/batch = 15.2687s	
15737/22300 (epoch 35.285), train_loss = 0.29231074, grad/param norm = 2.0678e-01, time/batch = 16.2380s	
15738/22300 (epoch 35.287), train_loss = 0.42085210, grad/param norm = 2.6874e-01, time/batch = 16.4755s	
15739/22300 (epoch 35.289), train_loss = 0.38268939, grad/param norm = 2.3722e-01, time/batch = 17.4765s	
15740/22300 (epoch 35.291), train_loss = 0.37950148, grad/param norm = 2.5048e-01, time/batch = 16.4092s	
15741/22300 (epoch 35.294), train_loss = 0.31074402, grad/param norm = 2.1828e-01, time/batch = 16.4824s	
15742/22300 (epoch 35.296), train_loss = 0.38441967, grad/param norm = 2.8871e-01, time/batch = 15.7368s	
15743/22300 (epoch 35.298), train_loss = 0.48063716, grad/param norm = 2.4593e-01, time/batch = 19.3099s	
15744/22300 (epoch 35.300), train_loss = 0.52806725, grad/param norm = 3.0135e-01, time/batch = 15.9956s	
15745/22300 (epoch 35.303), train_loss = 0.40594363, grad/param norm = 2.7149e-01, time/batch = 16.8806s	
15746/22300 (epoch 35.305), train_loss = 0.37702352, grad/param norm = 2.3902e-01, time/batch = 15.4926s	
15747/22300 (epoch 35.307), train_loss = 0.35566244, grad/param norm = 2.9444e-01, time/batch = 15.0501s	
15748/22300 (epoch 35.309), train_loss = 0.31822546, grad/param norm = 2.2413e-01, time/batch = 16.3052s	
15749/22300 (epoch 35.312), train_loss = 0.29636404, grad/param norm = 2.3564e-01, time/batch = 17.1413s	
15750/22300 (epoch 35.314), train_loss = 0.31203722, grad/param norm = 2.0556e-01, time/batch = 17.4626s	
15751/22300 (epoch 35.316), train_loss = 0.32031849, grad/param norm = 2.6126e-01, time/batch = 17.8003s	
15752/22300 (epoch 35.318), train_loss = 0.35211890, grad/param norm = 2.2333e-01, time/batch = 16.8061s	
15753/22300 (epoch 35.321), train_loss = 0.42400197, grad/param norm = 2.0214e-01, time/batch = 16.1150s	
15754/22300 (epoch 35.323), train_loss = 0.30557598, grad/param norm = 1.9677e-01, time/batch = 16.9657s	
15755/22300 (epoch 35.325), train_loss = 0.30727052, grad/param norm = 2.4339e-01, time/batch = 16.7226s	
15756/22300 (epoch 35.327), train_loss = 0.30862402, grad/param norm = 2.0046e-01, time/batch = 16.5518s	
15757/22300 (epoch 35.330), train_loss = 0.31927507, grad/param norm = 2.2710e-01, time/batch = 16.9752s	
15758/22300 (epoch 35.332), train_loss = 0.28541997, grad/param norm = 2.1359e-01, time/batch = 15.3133s	
15759/22300 (epoch 35.334), train_loss = 0.34718725, grad/param norm = 2.4689e-01, time/batch = 14.5061s	
15760/22300 (epoch 35.336), train_loss = 0.35527031, grad/param norm = 2.2009e-01, time/batch = 15.2216s	
15761/22300 (epoch 35.339), train_loss = 0.43361092, grad/param norm = 3.4903e-01, time/batch = 17.0595s	
15762/22300 (epoch 35.341), train_loss = 0.41565087, grad/param norm = 2.8023e-01, time/batch = 16.8035s	
15763/22300 (epoch 35.343), train_loss = 0.46587362, grad/param norm = 2.9412e-01, time/batch = 16.0209s	
15764/22300 (epoch 35.345), train_loss = 0.37372844, grad/param norm = 2.8165e-01, time/batch = 15.7950s	
15765/22300 (epoch 35.348), train_loss = 0.36586825, grad/param norm = 2.4219e-01, time/batch = 15.6824s	
15766/22300 (epoch 35.350), train_loss = 0.28562765, grad/param norm = 1.8201e-01, time/batch = 17.6345s	
15767/22300 (epoch 35.352), train_loss = 0.40135366, grad/param norm = 2.7700e-01, time/batch = 16.2762s	
15768/22300 (epoch 35.354), train_loss = 0.57710716, grad/param norm = 3.5533e-01, time/batch = 17.2352s	
15769/22300 (epoch 35.357), train_loss = 0.49416906, grad/param norm = 2.4118e-01, time/batch = 16.1297s	
15770/22300 (epoch 35.359), train_loss = 0.31778488, grad/param norm = 2.2960e-01, time/batch = 15.2001s	
15771/22300 (epoch 35.361), train_loss = 0.32847894, grad/param norm = 2.3065e-01, time/batch = 15.6624s	
15772/22300 (epoch 35.363), train_loss = 0.43570992, grad/param norm = 2.5081e-01, time/batch = 15.5503s	
15773/22300 (epoch 35.365), train_loss = 0.32351219, grad/param norm = 2.2231e-01, time/batch = 15.1089s	
15774/22300 (epoch 35.368), train_loss = 0.33966384, grad/param norm = 2.6197e-01, time/batch = 14.6521s	
15775/22300 (epoch 35.370), train_loss = 0.35081189, grad/param norm = 2.2586e-01, time/batch = 15.4160s	
15776/22300 (epoch 35.372), train_loss = 0.26798050, grad/param norm = 2.0267e-01, time/batch = 15.3913s	
15777/22300 (epoch 35.374), train_loss = 0.25925918, grad/param norm = 1.8923e-01, time/batch = 16.2109s	
15778/22300 (epoch 35.377), train_loss = 0.37911525, grad/param norm = 2.7305e-01, time/batch = 16.3972s	
15779/22300 (epoch 35.379), train_loss = 0.33784075, grad/param norm = 2.7327e-01, time/batch = 15.1214s	
15780/22300 (epoch 35.381), train_loss = 0.42894435, grad/param norm = 2.7215e-01, time/batch = 16.6401s	
15781/22300 (epoch 35.383), train_loss = 0.35261201, grad/param norm = 2.7115e-01, time/batch = 17.3167s	
15782/22300 (epoch 35.386), train_loss = 0.38362462, grad/param norm = 2.3233e-01, time/batch = 16.6208s	
15783/22300 (epoch 35.388), train_loss = 0.28862766, grad/param norm = 2.3868e-01, time/batch = 15.0547s	
15784/22300 (epoch 35.390), train_loss = 0.31962626, grad/param norm = 2.5268e-01, time/batch = 17.8725s	
15785/22300 (epoch 35.392), train_loss = 0.36154601, grad/param norm = 2.4570e-01, time/batch = 14.8252s	
15786/22300 (epoch 35.395), train_loss = 0.27456960, grad/param norm = 1.8386e-01, time/batch = 15.6167s	
15787/22300 (epoch 35.397), train_loss = 0.19725466, grad/param norm = 1.5076e-01, time/batch = 17.5565s	
15788/22300 (epoch 35.399), train_loss = 0.29982425, grad/param norm = 2.6859e-01, time/batch = 16.5307s	
15789/22300 (epoch 35.401), train_loss = 0.34510935, grad/param norm = 2.6682e-01, time/batch = 16.7151s	
15790/22300 (epoch 35.404), train_loss = 0.38117792, grad/param norm = 2.8057e-01, time/batch = 16.0546s	
15791/22300 (epoch 35.406), train_loss = 0.55018606, grad/param norm = 3.5150e-01, time/batch = 17.2319s	
15792/22300 (epoch 35.408), train_loss = 0.43318624, grad/param norm = 2.6833e-01, time/batch = 16.4848s	
15793/22300 (epoch 35.410), train_loss = 0.45054200, grad/param norm = 2.7535e-01, time/batch = 15.2930s	
15794/22300 (epoch 35.413), train_loss = 0.35063983, grad/param norm = 2.6378e-01, time/batch = 16.2183s	
15795/22300 (epoch 35.415), train_loss = 0.24775366, grad/param norm = 2.1661e-01, time/batch = 17.8941s	
15796/22300 (epoch 35.417), train_loss = 0.40230156, grad/param norm = 2.6081e-01, time/batch = 17.0771s	
15797/22300 (epoch 35.419), train_loss = 0.33901167, grad/param norm = 2.0652e-01, time/batch = 15.5901s	
15798/22300 (epoch 35.422), train_loss = 0.30006003, grad/param norm = 2.3539e-01, time/batch = 19.2947s	
15799/22300 (epoch 35.424), train_loss = 0.37263285, grad/param norm = 2.4110e-01, time/batch = 18.5525s	
15800/22300 (epoch 35.426), train_loss = 0.27666535, grad/param norm = 2.0008e-01, time/batch = 16.5004s	
15801/22300 (epoch 35.428), train_loss = 0.31961455, grad/param norm = 2.8559e-01, time/batch = 15.3747s	
15802/22300 (epoch 35.430), train_loss = 0.34121089, grad/param norm = 2.2864e-01, time/batch = 17.0218s	
15803/22300 (epoch 35.433), train_loss = 0.34603252, grad/param norm = 2.3168e-01, time/batch = 17.3963s	
15804/22300 (epoch 35.435), train_loss = 0.32926614, grad/param norm = 2.1543e-01, time/batch = 15.2990s	
15805/22300 (epoch 35.437), train_loss = 0.39208499, grad/param norm = 2.8758e-01, time/batch = 18.3899s	
15806/22300 (epoch 35.439), train_loss = 0.44060614, grad/param norm = 2.5645e-01, time/batch = 15.7173s	
15807/22300 (epoch 35.442), train_loss = 0.39338986, grad/param norm = 2.5671e-01, time/batch = 16.5363s	
15808/22300 (epoch 35.444), train_loss = 0.31086577, grad/param norm = 2.0942e-01, time/batch = 15.9360s	
15809/22300 (epoch 35.446), train_loss = 0.33400327, grad/param norm = 2.5456e-01, time/batch = 17.1507s	
15810/22300 (epoch 35.448), train_loss = 0.24222757, grad/param norm = 1.6249e-01, time/batch = 16.9805s	
15811/22300 (epoch 35.451), train_loss = 0.41683437, grad/param norm = 2.9219e-01, time/batch = 16.9566s	
15812/22300 (epoch 35.453), train_loss = 0.32154034, grad/param norm = 2.3918e-01, time/batch = 17.2266s	
15813/22300 (epoch 35.455), train_loss = 0.45287012, grad/param norm = 2.9945e-01, time/batch = 17.6383s	
15814/22300 (epoch 35.457), train_loss = 0.56823419, grad/param norm = 2.9639e-01, time/batch = 17.3725s	
15815/22300 (epoch 35.460), train_loss = 0.47597363, grad/param norm = 2.7430e-01, time/batch = 17.2309s	
15816/22300 (epoch 35.462), train_loss = 0.48562669, grad/param norm = 2.8297e-01, time/batch = 16.1542s	
15817/22300 (epoch 35.464), train_loss = 0.40652741, grad/param norm = 2.5918e-01, time/batch = 16.8300s	
15818/22300 (epoch 35.466), train_loss = 0.36031945, grad/param norm = 2.4290e-01, time/batch = 16.3061s	
15819/22300 (epoch 35.469), train_loss = 0.32763207, grad/param norm = 1.9103e-01, time/batch = 14.9839s	
15820/22300 (epoch 35.471), train_loss = 0.45896174, grad/param norm = 2.5223e-01, time/batch = 15.3594s	
15821/22300 (epoch 35.473), train_loss = 0.38403235, grad/param norm = 2.0654e-01, time/batch = 15.9791s	
15822/22300 (epoch 35.475), train_loss = 0.33630811, grad/param norm = 2.8631e-01, time/batch = 16.5415s	
15823/22300 (epoch 35.478), train_loss = 0.34558708, grad/param norm = 2.4844e-01, time/batch = 16.3166s	
15824/22300 (epoch 35.480), train_loss = 0.25267890, grad/param norm = 1.8508e-01, time/batch = 18.3021s	
15825/22300 (epoch 35.482), train_loss = 0.29502163, grad/param norm = 1.9282e-01, time/batch = 22.8789s	
15826/22300 (epoch 35.484), train_loss = 0.40712663, grad/param norm = 2.6429e-01, time/batch = 24.6312s	
15827/22300 (epoch 35.487), train_loss = 0.45679657, grad/param norm = 3.3846e-01, time/batch = 15.9768s	
15828/22300 (epoch 35.489), train_loss = 0.42598196, grad/param norm = 2.3248e-01, time/batch = 16.5434s	
15829/22300 (epoch 35.491), train_loss = 0.45456576, grad/param norm = 2.7649e-01, time/batch = 16.3183s	
15830/22300 (epoch 35.493), train_loss = 0.34917535, grad/param norm = 2.9578e-01, time/batch = 15.8993s	
15831/22300 (epoch 35.496), train_loss = 0.37934470, grad/param norm = 1.8624e-01, time/batch = 14.9683s	
15832/22300 (epoch 35.498), train_loss = 0.26296808, grad/param norm = 1.9603e-01, time/batch = 16.3667s	
15833/22300 (epoch 35.500), train_loss = 0.38387549, grad/param norm = 2.5894e-01, time/batch = 16.3936s	
15834/22300 (epoch 35.502), train_loss = 0.25124599, grad/param norm = 2.1723e-01, time/batch = 19.2035s	
15835/22300 (epoch 35.504), train_loss = 0.26986260, grad/param norm = 2.0011e-01, time/batch = 16.4727s	
15836/22300 (epoch 35.507), train_loss = 0.29672794, grad/param norm = 2.0926e-01, time/batch = 15.8858s	
15837/22300 (epoch 35.509), train_loss = 0.41564920, grad/param norm = 2.2789e-01, time/batch = 16.1490s	
15838/22300 (epoch 35.511), train_loss = 0.23220362, grad/param norm = 1.6807e-01, time/batch = 15.2745s	
15839/22300 (epoch 35.513), train_loss = 0.26831835, grad/param norm = 1.9777e-01, time/batch = 15.2049s	
15840/22300 (epoch 35.516), train_loss = 0.31753689, grad/param norm = 2.4584e-01, time/batch = 17.5461s	
15841/22300 (epoch 35.518), train_loss = 0.42056201, grad/param norm = 2.9427e-01, time/batch = 15.8119s	
15842/22300 (epoch 35.520), train_loss = 0.35436883, grad/param norm = 2.5312e-01, time/batch = 16.6548s	
15843/22300 (epoch 35.522), train_loss = 0.37429894, grad/param norm = 2.7394e-01, time/batch = 15.1387s	
15844/22300 (epoch 35.525), train_loss = 0.28065292, grad/param norm = 2.3042e-01, time/batch = 17.0634s	
15845/22300 (epoch 35.527), train_loss = 0.43608800, grad/param norm = 3.0801e-01, time/batch = 15.4922s	
15846/22300 (epoch 35.529), train_loss = 0.38943452, grad/param norm = 2.3735e-01, time/batch = 16.2285s	
15847/22300 (epoch 35.531), train_loss = 0.33468675, grad/param norm = 2.3209e-01, time/batch = 16.1358s	
15848/22300 (epoch 35.534), train_loss = 0.36015307, grad/param norm = 2.6558e-01, time/batch = 17.2288s	
15849/22300 (epoch 35.536), train_loss = 0.52421593, grad/param norm = 2.5819e-01, time/batch = 18.2088s	
15850/22300 (epoch 35.538), train_loss = 0.65233457, grad/param norm = 3.4239e-01, time/batch = 15.2854s	
15851/22300 (epoch 35.540), train_loss = 0.37184796, grad/param norm = 2.5615e-01, time/batch = 16.7977s	
15852/22300 (epoch 35.543), train_loss = 0.34820528, grad/param norm = 2.2427e-01, time/batch = 16.7740s	
15853/22300 (epoch 35.545), train_loss = 0.26807709, grad/param norm = 2.3650e-01, time/batch = 16.8038s	
15854/22300 (epoch 35.547), train_loss = 0.23291608, grad/param norm = 1.8973e-01, time/batch = 16.3972s	
15855/22300 (epoch 35.549), train_loss = 0.29732470, grad/param norm = 2.1691e-01, time/batch = 15.3732s	
15856/22300 (epoch 35.552), train_loss = 0.28744096, grad/param norm = 2.1159e-01, time/batch = 18.3820s	
15857/22300 (epoch 35.554), train_loss = 0.40665932, grad/param norm = 2.7517e-01, time/batch = 16.2963s	
15858/22300 (epoch 35.556), train_loss = 0.55493616, grad/param norm = 3.6627e-01, time/batch = 17.5349s	
15859/22300 (epoch 35.558), train_loss = 0.40364898, grad/param norm = 2.6560e-01, time/batch = 16.8031s	
15860/22300 (epoch 35.561), train_loss = 0.58272465, grad/param norm = 3.3369e-01, time/batch = 16.8946s	
15861/22300 (epoch 35.563), train_loss = 0.44807030, grad/param norm = 2.9129e-01, time/batch = 15.7503s	
15862/22300 (epoch 35.565), train_loss = 0.36891950, grad/param norm = 2.3938e-01, time/batch = 18.1257s	
15863/22300 (epoch 35.567), train_loss = 0.34851017, grad/param norm = 2.5161e-01, time/batch = 18.0389s	
15864/22300 (epoch 35.570), train_loss = 0.49685897, grad/param norm = 3.3250e-01, time/batch = 15.8102s	
15865/22300 (epoch 35.572), train_loss = 0.50091254, grad/param norm = 3.1928e-01, time/batch = 16.5556s	
15866/22300 (epoch 35.574), train_loss = 0.36632855, grad/param norm = 2.5462e-01, time/batch = 15.1364s	
15867/22300 (epoch 35.576), train_loss = 0.33011568, grad/param norm = 2.0171e-01, time/batch = 17.5631s	
15868/22300 (epoch 35.578), train_loss = 0.19380875, grad/param norm = 1.5527e-01, time/batch = 14.8927s	
15869/22300 (epoch 35.581), train_loss = 0.29167242, grad/param norm = 2.1364e-01, time/batch = 17.3048s	
15870/22300 (epoch 35.583), train_loss = 0.33381769, grad/param norm = 2.0504e-01, time/batch = 16.7281s	
15871/22300 (epoch 35.585), train_loss = 0.46263058, grad/param norm = 2.9560e-01, time/batch = 16.7186s	
15872/22300 (epoch 35.587), train_loss = 0.62108385, grad/param norm = 3.0074e-01, time/batch = 16.8879s	
15873/22300 (epoch 35.590), train_loss = 0.54037643, grad/param norm = 3.7800e-01, time/batch = 15.9281s	
15874/22300 (epoch 35.592), train_loss = 0.60903597, grad/param norm = 3.0773e-01, time/batch = 16.5499s	
15875/22300 (epoch 35.594), train_loss = 0.58105268, grad/param norm = 3.4236e-01, time/batch = 16.3492s	
15876/22300 (epoch 35.596), train_loss = 0.38403348, grad/param norm = 2.9898e-01, time/batch = 16.2998s	
15877/22300 (epoch 35.599), train_loss = 0.28350643, grad/param norm = 3.0367e-01, time/batch = 17.1518s	
15878/22300 (epoch 35.601), train_loss = 0.32374792, grad/param norm = 2.4308e-01, time/batch = 17.6304s	
15879/22300 (epoch 35.603), train_loss = 0.33900616, grad/param norm = 2.4596e-01, time/batch = 17.2886s	
15880/22300 (epoch 35.605), train_loss = 0.34914255, grad/param norm = 2.5860e-01, time/batch = 16.6381s	
15881/22300 (epoch 35.608), train_loss = 0.60179399, grad/param norm = 3.5604e-01, time/batch = 15.3021s	
15882/22300 (epoch 35.610), train_loss = 0.63049864, grad/param norm = 3.0162e-01, time/batch = 15.3899s	
15883/22300 (epoch 35.612), train_loss = 0.46760224, grad/param norm = 2.8194e-01, time/batch = 17.3805s	
15884/22300 (epoch 35.614), train_loss = 0.45460653, grad/param norm = 3.1080e-01, time/batch = 14.3414s	
15885/22300 (epoch 35.617), train_loss = 0.47181437, grad/param norm = 2.7123e-01, time/batch = 18.2755s	
15886/22300 (epoch 35.619), train_loss = 0.54484034, grad/param norm = 3.1063e-01, time/batch = 15.7217s	
15887/22300 (epoch 35.621), train_loss = 0.32770142, grad/param norm = 2.5264e-01, time/batch = 19.2213s	
15888/22300 (epoch 35.623), train_loss = 0.35669891, grad/param norm = 2.3804e-01, time/batch = 18.1249s	
15889/22300 (epoch 35.626), train_loss = 0.34885848, grad/param norm = 2.5748e-01, time/batch = 16.7960s	
15890/22300 (epoch 35.628), train_loss = 0.33495355, grad/param norm = 2.2936e-01, time/batch = 15.2356s	
15891/22300 (epoch 35.630), train_loss = 0.40251456, grad/param norm = 2.2652e-01, time/batch = 16.4682s	
15892/22300 (epoch 35.632), train_loss = 0.34886467, grad/param norm = 2.3328e-01, time/batch = 16.9708s	
15893/22300 (epoch 35.635), train_loss = 0.37335416, grad/param norm = 2.1567e-01, time/batch = 15.4070s	
15894/22300 (epoch 35.637), train_loss = 0.43790919, grad/param norm = 2.8748e-01, time/batch = 17.9655s	
15895/22300 (epoch 35.639), train_loss = 0.53741611, grad/param norm = 3.3042e-01, time/batch = 15.6404s	
15896/22300 (epoch 35.641), train_loss = 0.42549707, grad/param norm = 2.5170e-01, time/batch = 17.3752s	
15897/22300 (epoch 35.643), train_loss = 0.32463724, grad/param norm = 2.4329e-01, time/batch = 17.0433s	
15898/22300 (epoch 35.646), train_loss = 0.31443767, grad/param norm = 2.0887e-01, time/batch = 16.1399s	
15899/22300 (epoch 35.648), train_loss = 0.42089560, grad/param norm = 2.3705e-01, time/batch = 17.2239s	
15900/22300 (epoch 35.650), train_loss = 0.44229871, grad/param norm = 3.7536e-01, time/batch = 16.3952s	
15901/22300 (epoch 35.652), train_loss = 0.36158035, grad/param norm = 2.3468e-01, time/batch = 17.4649s	
15902/22300 (epoch 35.655), train_loss = 0.31447767, grad/param norm = 2.4475e-01, time/batch = 16.6427s	
15903/22300 (epoch 35.657), train_loss = 0.34301589, grad/param norm = 2.6205e-01, time/batch = 17.7190s	
15904/22300 (epoch 35.659), train_loss = 0.35301437, grad/param norm = 3.0226e-01, time/batch = 15.8963s	
15905/22300 (epoch 35.661), train_loss = 0.27951287, grad/param norm = 2.3622e-01, time/batch = 17.3808s	
15906/22300 (epoch 35.664), train_loss = 0.34698953, grad/param norm = 2.4477e-01, time/batch = 16.7285s	
15907/22300 (epoch 35.666), train_loss = 0.42782852, grad/param norm = 2.6150e-01, time/batch = 15.3951s	
15908/22300 (epoch 35.668), train_loss = 0.31948386, grad/param norm = 2.3611e-01, time/batch = 15.6528s	
15909/22300 (epoch 35.670), train_loss = 0.39547135, grad/param norm = 2.4212e-01, time/batch = 15.6029s	
15910/22300 (epoch 35.673), train_loss = 0.49576132, grad/param norm = 3.0541e-01, time/batch = 15.8308s	
15911/22300 (epoch 35.675), train_loss = 0.52236866, grad/param norm = 3.7221e-01, time/batch = 16.1394s	
15912/22300 (epoch 35.677), train_loss = 0.57134443, grad/param norm = 3.0353e-01, time/batch = 17.7923s	
15913/22300 (epoch 35.679), train_loss = 0.42708712, grad/param norm = 3.1275e-01, time/batch = 18.1359s	
15914/22300 (epoch 35.682), train_loss = 0.38877174, grad/param norm = 2.1739e-01, time/batch = 15.1411s	
15915/22300 (epoch 35.684), train_loss = 0.36999093, grad/param norm = 2.3581e-01, time/batch = 14.8860s	
15916/22300 (epoch 35.686), train_loss = 0.35931086, grad/param norm = 2.4840e-01, time/batch = 17.1949s	
15917/22300 (epoch 35.688), train_loss = 0.35215621, grad/param norm = 2.6898e-01, time/batch = 15.3784s	
15918/22300 (epoch 35.691), train_loss = 0.31335086, grad/param norm = 2.6734e-01, time/batch = 16.8113s	
15919/22300 (epoch 35.693), train_loss = 0.29703540, grad/param norm = 2.1311e-01, time/batch = 15.8030s	
15920/22300 (epoch 35.695), train_loss = 0.32004929, grad/param norm = 2.3495e-01, time/batch = 17.7304s	
15921/22300 (epoch 35.697), train_loss = 0.34526711, grad/param norm = 1.9029e-01, time/batch = 18.1444s	
15922/22300 (epoch 35.700), train_loss = 0.30744551, grad/param norm = 1.9825e-01, time/batch = 16.5385s	
15923/22300 (epoch 35.702), train_loss = 0.26646552, grad/param norm = 2.0714e-01, time/batch = 17.6521s	
15924/22300 (epoch 35.704), train_loss = 0.35033845, grad/param norm = 2.4130e-01, time/batch = 18.2055s	
15925/22300 (epoch 35.706), train_loss = 0.31684191, grad/param norm = 2.7161e-01, time/batch = 16.3915s	
15926/22300 (epoch 35.709), train_loss = 0.25230100, grad/param norm = 1.9632e-01, time/batch = 15.6968s	
15927/22300 (epoch 35.711), train_loss = 0.26339411, grad/param norm = 1.8202e-01, time/batch = 16.1439s	
15928/22300 (epoch 35.713), train_loss = 0.39809234, grad/param norm = 2.8768e-01, time/batch = 16.5631s	
15929/22300 (epoch 35.715), train_loss = 0.39831298, grad/param norm = 2.5828e-01, time/batch = 15.7290s	
15930/22300 (epoch 35.717), train_loss = 0.54402103, grad/param norm = 2.9330e-01, time/batch = 16.3261s	
15931/22300 (epoch 35.720), train_loss = 0.34829061, grad/param norm = 2.5334e-01, time/batch = 18.7943s	
15932/22300 (epoch 35.722), train_loss = 0.37673338, grad/param norm = 2.3967e-01, time/batch = 16.3135s	
15933/22300 (epoch 35.724), train_loss = 0.41800685, grad/param norm = 2.7527e-01, time/batch = 17.3837s	
15934/22300 (epoch 35.726), train_loss = 0.33219185, grad/param norm = 2.2916e-01, time/batch = 15.7046s	
15935/22300 (epoch 35.729), train_loss = 0.38798710, grad/param norm = 2.7218e-01, time/batch = 17.8013s	
15936/22300 (epoch 35.731), train_loss = 0.52465706, grad/param norm = 3.6150e-01, time/batch = 16.3859s	
15937/22300 (epoch 35.733), train_loss = 0.49947004, grad/param norm = 3.7054e-01, time/batch = 17.7248s	
15938/22300 (epoch 35.735), train_loss = 0.53839031, grad/param norm = 3.2212e-01, time/batch = 16.4867s	
15939/22300 (epoch 35.738), train_loss = 0.39274157, grad/param norm = 2.8230e-01, time/batch = 16.3836s	
15940/22300 (epoch 35.740), train_loss = 0.36204860, grad/param norm = 2.5559e-01, time/batch = 15.7275s	
15941/22300 (epoch 35.742), train_loss = 0.33593223, grad/param norm = 2.4082e-01, time/batch = 16.4629s	
15942/22300 (epoch 35.744), train_loss = 0.57435768, grad/param norm = 2.9945e-01, time/batch = 17.3931s	
15943/22300 (epoch 35.747), train_loss = 0.46100658, grad/param norm = 2.5405e-01, time/batch = 15.8010s	
15944/22300 (epoch 35.749), train_loss = 0.58098771, grad/param norm = 3.5667e-01, time/batch = 15.9725s	
15945/22300 (epoch 35.751), train_loss = 0.50994958, grad/param norm = 4.1226e-01, time/batch = 17.4703s	
15946/22300 (epoch 35.753), train_loss = 0.55654680, grad/param norm = 3.3633e-01, time/batch = 15.4999s	
15947/22300 (epoch 35.756), train_loss = 0.45752842, grad/param norm = 2.3701e-01, time/batch = 14.7248s	
15948/22300 (epoch 35.758), train_loss = 0.42420976, grad/param norm = 3.0502e-01, time/batch = 19.2045s	
15949/22300 (epoch 35.760), train_loss = 0.44770947, grad/param norm = 2.7111e-01, time/batch = 15.4782s	
15950/22300 (epoch 35.762), train_loss = 0.41232101, grad/param norm = 2.7701e-01, time/batch = 17.1230s	
15951/22300 (epoch 35.765), train_loss = 0.44427959, grad/param norm = 2.9661e-01, time/batch = 17.9642s	
15952/22300 (epoch 35.767), train_loss = 0.44165581, grad/param norm = 2.9693e-01, time/batch = 15.7355s	
15953/22300 (epoch 35.769), train_loss = 0.43169746, grad/param norm = 2.9323e-01, time/batch = 16.3986s	
15954/22300 (epoch 35.771), train_loss = 0.45419973, grad/param norm = 2.8659e-01, time/batch = 15.2248s	
15955/22300 (epoch 35.774), train_loss = 0.51057671, grad/param norm = 3.8149e-01, time/batch = 17.2891s	
15956/22300 (epoch 35.776), train_loss = 0.51822868, grad/param norm = 2.5506e-01, time/batch = 15.4679s	
15957/22300 (epoch 35.778), train_loss = 0.51565925, grad/param norm = 3.1171e-01, time/batch = 16.2865s	
15958/22300 (epoch 35.780), train_loss = 0.51066195, grad/param norm = 2.9013e-01, time/batch = 16.1406s	
15959/22300 (epoch 35.783), train_loss = 0.53142322, grad/param norm = 3.6762e-01, time/batch = 18.7981s	
15960/22300 (epoch 35.785), train_loss = 0.38356387, grad/param norm = 2.8320e-01, time/batch = 17.6447s	
15961/22300 (epoch 35.787), train_loss = 0.37462246, grad/param norm = 2.4126e-01, time/batch = 16.3954s	
15962/22300 (epoch 35.789), train_loss = 0.56881507, grad/param norm = 3.3649e-01, time/batch = 15.2232s	
15963/22300 (epoch 35.791), train_loss = 0.65182023, grad/param norm = 3.2717e-01, time/batch = 17.3872s	
15964/22300 (epoch 35.794), train_loss = 0.54450951, grad/param norm = 3.3861e-01, time/batch = 16.7627s	
15965/22300 (epoch 35.796), train_loss = 0.47989980, grad/param norm = 2.8499e-01, time/batch = 15.0596s	
15966/22300 (epoch 35.798), train_loss = 0.64237913, grad/param norm = 3.1158e-01, time/batch = 18.0532s	
15967/22300 (epoch 35.800), train_loss = 0.42705410, grad/param norm = 2.5918e-01, time/batch = 18.3064s	
15968/22300 (epoch 35.803), train_loss = 0.37436575, grad/param norm = 1.9798e-01, time/batch = 16.3429s	
15969/22300 (epoch 35.805), train_loss = 0.44944132, grad/param norm = 2.6929e-01, time/batch = 16.0681s	
15970/22300 (epoch 35.807), train_loss = 0.58827037, grad/param norm = 3.5620e-01, time/batch = 15.8346s	
15971/22300 (epoch 35.809), train_loss = 0.41466056, grad/param norm = 2.5841e-01, time/batch = 15.3924s	
15972/22300 (epoch 35.812), train_loss = 0.48190980, grad/param norm = 3.1182e-01, time/batch = 17.0349s	
15973/22300 (epoch 35.814), train_loss = 0.45109444, grad/param norm = 2.9637e-01, time/batch = 17.6384s	
15974/22300 (epoch 35.816), train_loss = 0.46194440, grad/param norm = 2.6256e-01, time/batch = 16.9769s	
15975/22300 (epoch 35.818), train_loss = 0.55171202, grad/param norm = 3.3017e-01, time/batch = 16.2257s	
15976/22300 (epoch 35.821), train_loss = 0.48253822, grad/param norm = 2.6896e-01, time/batch = 15.5002s	
15977/22300 (epoch 35.823), train_loss = 0.29326419, grad/param norm = 2.0749e-01, time/batch = 17.5554s	
15978/22300 (epoch 35.825), train_loss = 0.34575233, grad/param norm = 3.1989e-01, time/batch = 16.7875s	
15979/22300 (epoch 35.827), train_loss = 0.37790578, grad/param norm = 2.6200e-01, time/batch = 16.3684s	
15980/22300 (epoch 35.830), train_loss = 0.40093305, grad/param norm = 2.8638e-01, time/batch = 15.7152s	
15981/22300 (epoch 35.832), train_loss = 0.36664569, grad/param norm = 2.4918e-01, time/batch = 16.1137s	
15982/22300 (epoch 35.834), train_loss = 0.30172955, grad/param norm = 2.2787e-01, time/batch = 16.0685s	
15983/22300 (epoch 35.836), train_loss = 0.39565045, grad/param norm = 2.4748e-01, time/batch = 15.6259s	
15984/22300 (epoch 35.839), train_loss = 0.41446892, grad/param norm = 2.9539e-01, time/batch = 18.4810s	
15985/22300 (epoch 35.841), train_loss = 0.41238920, grad/param norm = 3.3781e-01, time/batch = 18.7074s	
15986/22300 (epoch 35.843), train_loss = 0.41883579, grad/param norm = 2.9564e-01, time/batch = 15.8770s	
15987/22300 (epoch 35.845), train_loss = 0.39924263, grad/param norm = 2.5698e-01, time/batch = 16.9874s	
15988/22300 (epoch 35.848), train_loss = 0.38399246, grad/param norm = 2.4138e-01, time/batch = 15.6291s	
15989/22300 (epoch 35.850), train_loss = 0.40003626, grad/param norm = 2.5011e-01, time/batch = 18.0561s	
15990/22300 (epoch 35.852), train_loss = 0.38994500, grad/param norm = 2.8271e-01, time/batch = 16.2847s	
15991/22300 (epoch 35.854), train_loss = 0.59588952, grad/param norm = 3.2123e-01, time/batch = 16.9812s	
15992/22300 (epoch 35.857), train_loss = 0.47095993, grad/param norm = 3.1260e-01, time/batch = 16.1504s	
15993/22300 (epoch 35.859), train_loss = 0.35025041, grad/param norm = 2.0529e-01, time/batch = 15.2198s	
15994/22300 (epoch 35.861), train_loss = 0.47955729, grad/param norm = 2.8205e-01, time/batch = 16.3174s	
15995/22300 (epoch 35.863), train_loss = 0.31342369, grad/param norm = 2.2046e-01, time/batch = 15.5344s	
15996/22300 (epoch 35.865), train_loss = 0.32395275, grad/param norm = 2.4317e-01, time/batch = 17.2320s	
15997/22300 (epoch 35.868), train_loss = 0.43696297, grad/param norm = 2.5734e-01, time/batch = 16.0687s	
15998/22300 (epoch 35.870), train_loss = 0.44963571, grad/param norm = 2.9845e-01, time/batch = 15.7190s	
15999/22300 (epoch 35.872), train_loss = 0.54205356, grad/param norm = 3.4220e-01, time/batch = 17.6257s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch35.87_1.6479.t7	
16000/22300 (epoch 35.874), train_loss = 0.42864016, grad/param norm = 2.6785e-01, time/batch = 16.4653s	
16001/22300 (epoch 35.877), train_loss = 1.32403263, grad/param norm = 4.6122e-01, time/batch = 15.9826s	
16002/22300 (epoch 35.879), train_loss = 0.42057468, grad/param norm = 2.8517e-01, time/batch = 16.0576s	
16003/22300 (epoch 35.881), train_loss = 0.33293812, grad/param norm = 2.3756e-01, time/batch = 18.0341s	
16004/22300 (epoch 35.883), train_loss = 0.35445883, grad/param norm = 2.7431e-01, time/batch = 18.2146s	
16005/22300 (epoch 35.886), train_loss = 0.32511296, grad/param norm = 3.1578e-01, time/batch = 16.5225s	
16006/22300 (epoch 35.888), train_loss = 0.37356182, grad/param norm = 2.2147e-01, time/batch = 15.4600s	
16007/22300 (epoch 35.890), train_loss = 0.36440211, grad/param norm = 2.2189e-01, time/batch = 17.4696s	
16008/22300 (epoch 35.892), train_loss = 0.55864105, grad/param norm = 2.8454e-01, time/batch = 18.9646s	
16009/22300 (epoch 35.895), train_loss = 0.50982060, grad/param norm = 3.5066e-01, time/batch = 17.5483s	
16010/22300 (epoch 35.897), train_loss = 0.40757702, grad/param norm = 3.2048e-01, time/batch = 15.7003s	
16011/22300 (epoch 35.899), train_loss = 0.39910544, grad/param norm = 2.5592e-01, time/batch = 16.5526s	
16012/22300 (epoch 35.901), train_loss = 0.46475782, grad/param norm = 2.7891e-01, time/batch = 17.2412s	
16013/22300 (epoch 35.904), train_loss = 0.47619695, grad/param norm = 3.0363e-01, time/batch = 15.0508s	
16014/22300 (epoch 35.906), train_loss = 0.45933541, grad/param norm = 3.1458e-01, time/batch = 16.8222s	
16015/22300 (epoch 35.908), train_loss = 0.39909132, grad/param norm = 2.2012e-01, time/batch = 15.9831s	
16016/22300 (epoch 35.910), train_loss = 0.37696006, grad/param norm = 2.3350e-01, time/batch = 15.8614s	
16017/22300 (epoch 35.913), train_loss = 0.47879615, grad/param norm = 3.3175e-01, time/batch = 18.2964s	
16018/22300 (epoch 35.915), train_loss = 0.55714554, grad/param norm = 2.9719e-01, time/batch = 16.1612s	
16019/22300 (epoch 35.917), train_loss = 0.45556756, grad/param norm = 2.4593e-01, time/batch = 18.1347s	
16020/22300 (epoch 35.919), train_loss = 0.46584685, grad/param norm = 2.5151e-01, time/batch = 15.3992s	
16021/22300 (epoch 35.922), train_loss = 0.43448974, grad/param norm = 2.8038e-01, time/batch = 17.4594s	
16022/22300 (epoch 35.924), train_loss = 0.28024552, grad/param norm = 2.3893e-01, time/batch = 16.3748s	
16023/22300 (epoch 35.926), train_loss = 0.33863025, grad/param norm = 2.1465e-01, time/batch = 18.1218s	
16024/22300 (epoch 35.928), train_loss = 0.37641344, grad/param norm = 2.7658e-01, time/batch = 15.6339s	
16025/22300 (epoch 35.930), train_loss = 0.35618790, grad/param norm = 2.5182e-01, time/batch = 15.4735s	
16026/22300 (epoch 35.933), train_loss = 0.45054876, grad/param norm = 2.8489e-01, time/batch = 17.4736s	
16027/22300 (epoch 35.935), train_loss = 0.42557714, grad/param norm = 3.1942e-01, time/batch = 16.3825s	
16028/22300 (epoch 35.937), train_loss = 0.54955127, grad/param norm = 3.7969e-01, time/batch = 15.4774s	
16029/22300 (epoch 35.939), train_loss = 0.47357216, grad/param norm = 3.2206e-01, time/batch = 15.7374s	
16030/22300 (epoch 35.942), train_loss = 0.58374935, grad/param norm = 3.7209e-01, time/batch = 16.3060s	
16031/22300 (epoch 35.944), train_loss = 0.64643125, grad/param norm = 4.0536e-01, time/batch = 16.8037s	
16032/22300 (epoch 35.946), train_loss = 0.44278405, grad/param norm = 2.5768e-01, time/batch = 15.4588s	
16033/22300 (epoch 35.948), train_loss = 0.37619018, grad/param norm = 2.0962e-01, time/batch = 16.7329s	
16034/22300 (epoch 35.951), train_loss = 0.30239256, grad/param norm = 1.9076e-01, time/batch = 18.2665s	
16035/22300 (epoch 35.953), train_loss = 0.35477829, grad/param norm = 2.4526e-01, time/batch = 30.2144s	
16036/22300 (epoch 35.955), train_loss = 0.53958113, grad/param norm = 2.8815e-01, time/batch = 15.5377s	
16037/22300 (epoch 35.957), train_loss = 0.61431828, grad/param norm = 3.2156e-01, time/batch = 15.3830s	
16038/22300 (epoch 35.960), train_loss = 0.56353084, grad/param norm = 3.2663e-01, time/batch = 15.6527s	
16039/22300 (epoch 35.962), train_loss = 0.34948433, grad/param norm = 3.1464e-01, time/batch = 18.0563s	
16040/22300 (epoch 35.964), train_loss = 0.38392946, grad/param norm = 2.6271e-01, time/batch = 16.3768s	
16041/22300 (epoch 35.966), train_loss = 0.36517598, grad/param norm = 2.2496e-01, time/batch = 15.5848s	
16042/22300 (epoch 35.969), train_loss = 0.40819913, grad/param norm = 2.5866e-01, time/batch = 17.1442s	
16043/22300 (epoch 35.971), train_loss = 0.42313100, grad/param norm = 2.2997e-01, time/batch = 17.3021s	
16044/22300 (epoch 35.973), train_loss = 0.41650316, grad/param norm = 2.7268e-01, time/batch = 17.3877s	
16045/22300 (epoch 35.975), train_loss = 0.54999031, grad/param norm = 3.4719e-01, time/batch = 16.4749s	
16046/22300 (epoch 35.978), train_loss = 0.51508682, grad/param norm = 2.7813e-01, time/batch = 15.7901s	
16047/22300 (epoch 35.980), train_loss = 0.61220488, grad/param norm = 4.6170e-01, time/batch = 19.2150s	
16048/22300 (epoch 35.982), train_loss = 0.32423157, grad/param norm = 2.6334e-01, time/batch = 15.2986s	
16049/22300 (epoch 35.984), train_loss = 0.42393104, grad/param norm = 2.7116e-01, time/batch = 16.8932s	
16050/22300 (epoch 35.987), train_loss = 0.41148079, grad/param norm = 3.4583e-01, time/batch = 16.6249s	
16051/22300 (epoch 35.989), train_loss = 0.35318153, grad/param norm = 2.2912e-01, time/batch = 15.2136s	
16052/22300 (epoch 35.991), train_loss = 0.62855025, grad/param norm = 4.5271e-01, time/batch = 16.0284s	
16053/22300 (epoch 35.993), train_loss = 0.79792670, grad/param norm = 4.4732e-01, time/batch = 15.5039s	
16054/22300 (epoch 35.996), train_loss = 0.76979611, grad/param norm = 3.8234e-01, time/batch = 16.3958s	
16055/22300 (epoch 35.998), train_loss = 0.46147316, grad/param norm = 2.7309e-01, time/batch = 15.4045s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
16056/22300 (epoch 36.000), train_loss = 0.35558384, grad/param norm = 2.3862e-01, time/batch = 17.8820s	
16057/22300 (epoch 36.002), train_loss = 0.71629352, grad/param norm = 3.4843e-01, time/batch = 16.9708s	
16058/22300 (epoch 36.004), train_loss = 0.48236070, grad/param norm = 2.6121e-01, time/batch = 15.2763s	
16059/22300 (epoch 36.007), train_loss = 0.49299244, grad/param norm = 3.1835e-01, time/batch = 16.0543s	
16060/22300 (epoch 36.009), train_loss = 0.53736274, grad/param norm = 3.3438e-01, time/batch = 15.9849s	
16061/22300 (epoch 36.011), train_loss = 0.61861491, grad/param norm = 3.0156e-01, time/batch = 15.9040s	
16062/22300 (epoch 36.013), train_loss = 0.49575487, grad/param norm = 3.1092e-01, time/batch = 15.8164s	
16063/22300 (epoch 36.016), train_loss = 0.39501380, grad/param norm = 2.9928e-01, time/batch = 16.0133s	
16064/22300 (epoch 36.018), train_loss = 0.43550583, grad/param norm = 2.8705e-01, time/batch = 15.3809s	
16065/22300 (epoch 36.020), train_loss = 0.39747703, grad/param norm = 2.4563e-01, time/batch = 16.6419s	
16066/22300 (epoch 36.022), train_loss = 0.34645574, grad/param norm = 2.7554e-01, time/batch = 15.8823s	
16067/22300 (epoch 36.025), train_loss = 0.36063884, grad/param norm = 2.7899e-01, time/batch = 17.3734s	
16068/22300 (epoch 36.027), train_loss = 0.35676433, grad/param norm = 2.3429e-01, time/batch = 17.1338s	
16069/22300 (epoch 36.029), train_loss = 0.37781115, grad/param norm = 2.3956e-01, time/batch = 18.5405s	
16070/22300 (epoch 36.031), train_loss = 0.36633553, grad/param norm = 2.6119e-01, time/batch = 15.1761s	
16071/22300 (epoch 36.034), train_loss = 0.36362201, grad/param norm = 2.4930e-01, time/batch = 16.5187s	
16072/22300 (epoch 36.036), train_loss = 0.33891470, grad/param norm = 2.4504e-01, time/batch = 16.9837s	
16073/22300 (epoch 36.038), train_loss = 0.31830834, grad/param norm = 2.1881e-01, time/batch = 15.3974s	
16074/22300 (epoch 36.040), train_loss = 0.38509065, grad/param norm = 2.8657e-01, time/batch = 16.4610s	
16075/22300 (epoch 36.043), train_loss = 0.59956263, grad/param norm = 3.5607e-01, time/batch = 16.5537s	
16076/22300 (epoch 36.045), train_loss = 0.50141152, grad/param norm = 2.6815e-01, time/batch = 19.3049s	
16077/22300 (epoch 36.047), train_loss = 0.52926878, grad/param norm = 3.2250e-01, time/batch = 16.7161s	
16078/22300 (epoch 36.049), train_loss = 0.40154081, grad/param norm = 2.5401e-01, time/batch = 16.6407s	
16079/22300 (epoch 36.052), train_loss = 0.48310555, grad/param norm = 3.2784e-01, time/batch = 16.0726s	
16080/22300 (epoch 36.054), train_loss = 0.45078006, grad/param norm = 2.4261e-01, time/batch = 16.6879s	
16081/22300 (epoch 36.056), train_loss = 0.24940519, grad/param norm = 2.0009e-01, time/batch = 16.4619s	
16082/22300 (epoch 36.058), train_loss = 0.40392403, grad/param norm = 2.7441e-01, time/batch = 16.9513s	
16083/22300 (epoch 36.061), train_loss = 0.35939622, grad/param norm = 3.2759e-01, time/batch = 17.8736s	
16084/22300 (epoch 36.063), train_loss = 0.53321565, grad/param norm = 3.9843e-01, time/batch = 16.2374s	
16085/22300 (epoch 36.065), train_loss = 0.61682110, grad/param norm = 3.5412e-01, time/batch = 18.1383s	
16086/22300 (epoch 36.067), train_loss = 0.35966309, grad/param norm = 2.5215e-01, time/batch = 17.9838s	
16087/22300 (epoch 36.070), train_loss = 0.40391720, grad/param norm = 2.3438e-01, time/batch = 16.2990s	
16088/22300 (epoch 36.072), train_loss = 0.46344341, grad/param norm = 3.4528e-01, time/batch = 16.8757s	
16089/22300 (epoch 36.074), train_loss = 0.45530691, grad/param norm = 3.5196e-01, time/batch = 15.7736s	
16090/22300 (epoch 36.076), train_loss = 0.45437459, grad/param norm = 2.9395e-01, time/batch = 14.8143s	
16091/22300 (epoch 36.078), train_loss = 0.56260577, grad/param norm = 3.2926e-01, time/batch = 17.0165s	
16092/22300 (epoch 36.081), train_loss = 0.54812489, grad/param norm = 4.4255e-01, time/batch = 16.9628s	
16093/22300 (epoch 36.083), train_loss = 0.67633632, grad/param norm = 4.5075e-01, time/batch = 16.2255s	
16094/22300 (epoch 36.085), train_loss = 0.60895604, grad/param norm = 3.4239e-01, time/batch = 17.8834s	
16095/22300 (epoch 36.087), train_loss = 0.49023951, grad/param norm = 3.0763e-01, time/batch = 15.2325s	
16096/22300 (epoch 36.090), train_loss = 0.44347438, grad/param norm = 2.7022e-01, time/batch = 16.7875s	
16097/22300 (epoch 36.092), train_loss = 0.35833935, grad/param norm = 2.5100e-01, time/batch = 15.9934s	
16098/22300 (epoch 36.094), train_loss = 0.33543775, grad/param norm = 2.8236e-01, time/batch = 17.5522s	
16099/22300 (epoch 36.096), train_loss = 0.60725726, grad/param norm = 3.4201e-01, time/batch = 17.5514s	
16100/22300 (epoch 36.099), train_loss = 0.38484993, grad/param norm = 2.5932e-01, time/batch = 17.0462s	
16101/22300 (epoch 36.101), train_loss = 0.52175439, grad/param norm = 2.8935e-01, time/batch = 15.7324s	
16102/22300 (epoch 36.103), train_loss = 0.41577145, grad/param norm = 2.4280e-01, time/batch = 15.5539s	
16103/22300 (epoch 36.105), train_loss = 0.34112352, grad/param norm = 2.9601e-01, time/batch = 18.2146s	
16104/22300 (epoch 36.108), train_loss = 0.47082081, grad/param norm = 2.4983e-01, time/batch = 14.9866s	
16105/22300 (epoch 36.110), train_loss = 0.53039952, grad/param norm = 2.7860e-01, time/batch = 18.0363s	
16106/22300 (epoch 36.112), train_loss = 0.47076579, grad/param norm = 2.8081e-01, time/batch = 16.3823s	
16107/22300 (epoch 36.114), train_loss = 0.50280665, grad/param norm = 2.9767e-01, time/batch = 16.0223s	
16108/22300 (epoch 36.117), train_loss = 0.58930531, grad/param norm = 2.7355e-01, time/batch = 15.3221s	
16109/22300 (epoch 36.119), train_loss = 0.52497969, grad/param norm = 3.3570e-01, time/batch = 17.2982s	
16110/22300 (epoch 36.121), train_loss = 0.64942036, grad/param norm = 4.4773e-01, time/batch = 15.7816s	
16111/22300 (epoch 36.123), train_loss = 0.62424216, grad/param norm = 2.7800e-01, time/batch = 18.5365s	
16112/22300 (epoch 36.126), train_loss = 0.48933934, grad/param norm = 2.7603e-01, time/batch = 15.2403s	
16113/22300 (epoch 36.128), train_loss = 0.48057211, grad/param norm = 3.2690e-01, time/batch = 15.6450s	
16114/22300 (epoch 36.130), train_loss = 0.39834517, grad/param norm = 2.7769e-01, time/batch = 17.2151s	
16115/22300 (epoch 36.132), train_loss = 0.30492218, grad/param norm = 2.0620e-01, time/batch = 17.7216s	
16116/22300 (epoch 36.135), train_loss = 0.33685391, grad/param norm = 3.0901e-01, time/batch = 15.2747s	
16117/22300 (epoch 36.137), train_loss = 0.26807767, grad/param norm = 2.3888e-01, time/batch = 17.1213s	
16118/22300 (epoch 36.139), train_loss = 0.38742124, grad/param norm = 2.5516e-01, time/batch = 16.7063s	
16119/22300 (epoch 36.141), train_loss = 0.49933629, grad/param norm = 2.4358e-01, time/batch = 18.4716s	
16120/22300 (epoch 36.143), train_loss = 0.41896951, grad/param norm = 2.9170e-01, time/batch = 15.8007s	
16121/22300 (epoch 36.146), train_loss = 0.53279381, grad/param norm = 3.0614e-01, time/batch = 18.3726s	
16122/22300 (epoch 36.148), train_loss = 0.36999992, grad/param norm = 3.1289e-01, time/batch = 14.9938s	
16123/22300 (epoch 36.150), train_loss = 0.39366496, grad/param norm = 2.6017e-01, time/batch = 18.2118s	
16124/22300 (epoch 36.152), train_loss = 0.32259608, grad/param norm = 2.1929e-01, time/batch = 15.9532s	
16125/22300 (epoch 36.155), train_loss = 0.35398121, grad/param norm = 2.5675e-01, time/batch = 17.9685s	
16126/22300 (epoch 36.157), train_loss = 0.48441567, grad/param norm = 4.1071e-01, time/batch = 14.8752s	
16127/22300 (epoch 36.159), train_loss = 0.47358596, grad/param norm = 3.1196e-01, time/batch = 15.8729s	
16128/22300 (epoch 36.161), train_loss = 0.49090720, grad/param norm = 2.8333e-01, time/batch = 16.9766s	
16129/22300 (epoch 36.164), train_loss = 0.34618321, grad/param norm = 2.0793e-01, time/batch = 18.2145s	
16130/22300 (epoch 36.166), train_loss = 0.30679456, grad/param norm = 1.7764e-01, time/batch = 18.6286s	
16131/22300 (epoch 36.168), train_loss = 0.32230499, grad/param norm = 2.7389e-01, time/batch = 15.2196s	
16132/22300 (epoch 36.170), train_loss = 0.43978387, grad/param norm = 3.2257e-01, time/batch = 18.9682s	
16133/22300 (epoch 36.173), train_loss = 0.52327703, grad/param norm = 3.9438e-01, time/batch = 18.7955s	
16134/22300 (epoch 36.175), train_loss = 0.44486105, grad/param norm = 3.0597e-01, time/batch = 16.0400s	
16135/22300 (epoch 36.177), train_loss = 0.29293093, grad/param norm = 1.9880e-01, time/batch = 16.5908s	
16136/22300 (epoch 36.179), train_loss = 0.42935471, grad/param norm = 2.6863e-01, time/batch = 16.2745s	
16137/22300 (epoch 36.182), train_loss = 0.62177308, grad/param norm = 3.6077e-01, time/batch = 15.3995s	
16138/22300 (epoch 36.184), train_loss = 0.62100503, grad/param norm = 3.7711e-01, time/batch = 15.5498s	
16139/22300 (epoch 36.186), train_loss = 0.45098230, grad/param norm = 2.9131e-01, time/batch = 16.5222s	
16140/22300 (epoch 36.188), train_loss = 0.63702314, grad/param norm = 3.7485e-01, time/batch = 16.4840s	
16141/22300 (epoch 36.191), train_loss = 0.54477452, grad/param norm = 3.2911e-01, time/batch = 17.2064s	
16142/22300 (epoch 36.193), train_loss = 0.48108350, grad/param norm = 2.9817e-01, time/batch = 16.7092s	
16143/22300 (epoch 36.195), train_loss = 0.42592731, grad/param norm = 2.9337e-01, time/batch = 16.6492s	
16144/22300 (epoch 36.197), train_loss = 0.38229844, grad/param norm = 2.6936e-01, time/batch = 18.1313s	
16145/22300 (epoch 36.200), train_loss = 0.35266236, grad/param norm = 2.4637e-01, time/batch = 15.7159s	
16146/22300 (epoch 36.202), train_loss = 0.35838532, grad/param norm = 2.3037e-01, time/batch = 16.8603s	
16147/22300 (epoch 36.204), train_loss = 0.44506234, grad/param norm = 2.7386e-01, time/batch = 17.5421s	
16148/22300 (epoch 36.206), train_loss = 0.37459935, grad/param norm = 2.6202e-01, time/batch = 17.3142s	
16149/22300 (epoch 36.209), train_loss = 0.38747437, grad/param norm = 2.6627e-01, time/batch = 16.5499s	
16150/22300 (epoch 36.211), train_loss = 0.31941530, grad/param norm = 2.4684e-01, time/batch = 17.6386s	
16151/22300 (epoch 36.213), train_loss = 0.43657015, grad/param norm = 2.4208e-01, time/batch = 17.0432s	
16152/22300 (epoch 36.215), train_loss = 0.55839502, grad/param norm = 2.8625e-01, time/batch = 14.7892s	
16153/22300 (epoch 36.217), train_loss = 0.59090427, grad/param norm = 2.9648e-01, time/batch = 16.0616s	
16154/22300 (epoch 36.220), train_loss = 0.40001216, grad/param norm = 2.5348e-01, time/batch = 16.5674s	
16155/22300 (epoch 36.222), train_loss = 0.39548675, grad/param norm = 3.5159e-01, time/batch = 17.2695s	
16156/22300 (epoch 36.224), train_loss = 0.37333443, grad/param norm = 2.5362e-01, time/batch = 15.8528s	
16157/22300 (epoch 36.226), train_loss = 0.40628535, grad/param norm = 2.4068e-01, time/batch = 17.6286s	
16158/22300 (epoch 36.229), train_loss = 0.36216203, grad/param norm = 3.0203e-01, time/batch = 17.3968s	
16159/22300 (epoch 36.231), train_loss = 0.53773143, grad/param norm = 3.5512e-01, time/batch = 15.9712s	
16160/22300 (epoch 36.233), train_loss = 0.44350544, grad/param norm = 3.0247e-01, time/batch = 16.7161s	
16161/22300 (epoch 36.235), train_loss = 0.33121308, grad/param norm = 2.1541e-01, time/batch = 16.8137s	
16162/22300 (epoch 36.238), train_loss = 0.36766765, grad/param norm = 2.3094e-01, time/batch = 17.6383s	
16163/22300 (epoch 36.240), train_loss = 0.35583986, grad/param norm = 1.9683e-01, time/batch = 16.0568s	
16164/22300 (epoch 36.242), train_loss = 0.32282261, grad/param norm = 2.6531e-01, time/batch = 17.7142s	
16165/22300 (epoch 36.244), train_loss = 0.22410072, grad/param norm = 1.6104e-01, time/batch = 16.5270s	
16166/22300 (epoch 36.247), train_loss = 0.32590295, grad/param norm = 1.8741e-01, time/batch = 16.1423s	
16167/22300 (epoch 36.249), train_loss = 0.22407459, grad/param norm = 1.6790e-01, time/batch = 15.4067s	
16168/22300 (epoch 36.251), train_loss = 0.30547955, grad/param norm = 1.9032e-01, time/batch = 15.6266s	
16169/22300 (epoch 36.253), train_loss = 0.20055661, grad/param norm = 1.8963e-01, time/batch = 18.5541s	
16170/22300 (epoch 36.256), train_loss = 0.29658448, grad/param norm = 1.9452e-01, time/batch = 15.3185s	
16171/22300 (epoch 36.258), train_loss = 0.45384391, grad/param norm = 2.8186e-01, time/batch = 15.6353s	
16172/22300 (epoch 36.260), train_loss = 0.43164981, grad/param norm = 2.7516e-01, time/batch = 16.6347s	
16173/22300 (epoch 36.262), train_loss = 0.34341287, grad/param norm = 2.2782e-01, time/batch = 17.7091s	
16174/22300 (epoch 36.265), train_loss = 0.30332304, grad/param norm = 2.2161e-01, time/batch = 15.4414s	
16175/22300 (epoch 36.267), train_loss = 0.33956843, grad/param norm = 2.2459e-01, time/batch = 18.3751s	
16176/22300 (epoch 36.269), train_loss = 0.39898580, grad/param norm = 2.9994e-01, time/batch = 17.7964s	
16177/22300 (epoch 36.271), train_loss = 0.45098821, grad/param norm = 2.4119e-01, time/batch = 15.2694s	
16178/22300 (epoch 36.274), train_loss = 0.33404806, grad/param norm = 2.8297e-01, time/batch = 16.0694s	
16179/22300 (epoch 36.276), train_loss = 0.26455850, grad/param norm = 1.7156e-01, time/batch = 14.7410s	
16180/22300 (epoch 36.278), train_loss = 0.28331369, grad/param norm = 1.8657e-01, time/batch = 16.3157s	
16181/22300 (epoch 36.280), train_loss = 0.32762950, grad/param norm = 2.1620e-01, time/batch = 16.1225s	
16182/22300 (epoch 36.283), train_loss = 0.26068281, grad/param norm = 1.4937e-01, time/batch = 17.6979s	
16183/22300 (epoch 36.285), train_loss = 0.30107519, grad/param norm = 2.8221e-01, time/batch = 15.7876s	
16184/22300 (epoch 36.287), train_loss = 0.39825409, grad/param norm = 2.4044e-01, time/batch = 17.1300s	
16185/22300 (epoch 36.289), train_loss = 0.37631653, grad/param norm = 2.8630e-01, time/batch = 18.3578s	
16186/22300 (epoch 36.291), train_loss = 0.39466297, grad/param norm = 2.7716e-01, time/batch = 17.1486s	
16187/22300 (epoch 36.294), train_loss = 0.30274483, grad/param norm = 2.1067e-01, time/batch = 17.0548s	
16188/22300 (epoch 36.296), train_loss = 0.36357210, grad/param norm = 2.7980e-01, time/batch = 15.7311s	
16189/22300 (epoch 36.298), train_loss = 0.46192351, grad/param norm = 2.5325e-01, time/batch = 16.1990s	
16190/22300 (epoch 36.300), train_loss = 0.52581426, grad/param norm = 2.8065e-01, time/batch = 17.1413s	
16191/22300 (epoch 36.303), train_loss = 0.39929175, grad/param norm = 2.4107e-01, time/batch = 16.5543s	
16192/22300 (epoch 36.305), train_loss = 0.37544009, grad/param norm = 2.9375e-01, time/batch = 16.4702s	
16193/22300 (epoch 36.307), train_loss = 0.32543425, grad/param norm = 2.2972e-01, time/batch = 16.7876s	
16194/22300 (epoch 36.309), train_loss = 0.31034474, grad/param norm = 2.2840e-01, time/batch = 15.5627s	
16195/22300 (epoch 36.312), train_loss = 0.26871891, grad/param norm = 1.8135e-01, time/batch = 15.1189s	
16196/22300 (epoch 36.314), train_loss = 0.31734822, grad/param norm = 2.3212e-01, time/batch = 17.0487s	
16197/22300 (epoch 36.316), train_loss = 0.30694850, grad/param norm = 2.4359e-01, time/batch = 16.9842s	
16198/22300 (epoch 36.318), train_loss = 0.35145516, grad/param norm = 2.0971e-01, time/batch = 15.3994s	
16199/22300 (epoch 36.321), train_loss = 0.43430142, grad/param norm = 2.4908e-01, time/batch = 15.8785s	
16200/22300 (epoch 36.323), train_loss = 0.31899706, grad/param norm = 2.5021e-01, time/batch = 17.8743s	
16201/22300 (epoch 36.325), train_loss = 0.28987315, grad/param norm = 2.1190e-01, time/batch = 17.6435s	
16202/22300 (epoch 36.327), train_loss = 0.31307578, grad/param norm = 2.1191e-01, time/batch = 15.8964s	
16203/22300 (epoch 36.330), train_loss = 0.30017078, grad/param norm = 2.0845e-01, time/batch = 15.4686s	
16204/22300 (epoch 36.332), train_loss = 0.26984452, grad/param norm = 1.8377e-01, time/batch = 17.8863s	
16205/22300 (epoch 36.334), train_loss = 0.33698719, grad/param norm = 2.1942e-01, time/batch = 17.3755s	
16206/22300 (epoch 36.336), train_loss = 0.34018057, grad/param norm = 2.2088e-01, time/batch = 15.7051s	
16207/22300 (epoch 36.339), train_loss = 0.39795654, grad/param norm = 3.3185e-01, time/batch = 15.2080s	
16208/22300 (epoch 36.341), train_loss = 0.41396840, grad/param norm = 2.5213e-01, time/batch = 17.9651s	
16209/22300 (epoch 36.343), train_loss = 0.45844739, grad/param norm = 3.1121e-01, time/batch = 17.2317s	
16210/22300 (epoch 36.345), train_loss = 0.38218392, grad/param norm = 2.4507e-01, time/batch = 15.8960s	
16211/22300 (epoch 36.348), train_loss = 0.38504697, grad/param norm = 2.3245e-01, time/batch = 16.5553s	
16212/22300 (epoch 36.350), train_loss = 0.26915318, grad/param norm = 1.9288e-01, time/batch = 15.7076s	
16213/22300 (epoch 36.352), train_loss = 0.40811559, grad/param norm = 3.1402e-01, time/batch = 15.6300s	
16214/22300 (epoch 36.354), train_loss = 0.56785703, grad/param norm = 3.4320e-01, time/batch = 17.4793s	
16215/22300 (epoch 36.357), train_loss = 0.51046002, grad/param norm = 2.7091e-01, time/batch = 16.7273s	
16216/22300 (epoch 36.359), train_loss = 0.30537359, grad/param norm = 2.0975e-01, time/batch = 16.7242s	
16217/22300 (epoch 36.361), train_loss = 0.32825212, grad/param norm = 2.3319e-01, time/batch = 14.7506s	
16218/22300 (epoch 36.363), train_loss = 0.43755461, grad/param norm = 2.9785e-01, time/batch = 15.1310s	
16219/22300 (epoch 36.365), train_loss = 0.32862116, grad/param norm = 2.8492e-01, time/batch = 16.5694s	
16220/22300 (epoch 36.368), train_loss = 0.35810917, grad/param norm = 2.4424e-01, time/batch = 17.6291s	
16221/22300 (epoch 36.370), train_loss = 0.36455101, grad/param norm = 2.6285e-01, time/batch = 17.0601s	
16222/22300 (epoch 36.372), train_loss = 0.26173624, grad/param norm = 2.0275e-01, time/batch = 16.2312s	
16223/22300 (epoch 36.374), train_loss = 0.27094487, grad/param norm = 2.1558e-01, time/batch = 18.1408s	
16224/22300 (epoch 36.377), train_loss = 0.37266723, grad/param norm = 2.4916e-01, time/batch = 15.8067s	
16225/22300 (epoch 36.379), train_loss = 0.32449589, grad/param norm = 2.5805e-01, time/batch = 16.4588s	
16226/22300 (epoch 36.381), train_loss = 0.42968554, grad/param norm = 2.7047e-01, time/batch = 16.9683s	
16227/22300 (epoch 36.383), train_loss = 0.34315311, grad/param norm = 2.3177e-01, time/batch = 18.3726s	
16228/22300 (epoch 36.386), train_loss = 0.38453512, grad/param norm = 2.3828e-01, time/batch = 15.8104s	
16229/22300 (epoch 36.388), train_loss = 0.28954132, grad/param norm = 2.7302e-01, time/batch = 17.6260s	
16230/22300 (epoch 36.390), train_loss = 0.31405116, grad/param norm = 2.6343e-01, time/batch = 15.9766s	
16231/22300 (epoch 36.392), train_loss = 0.36039775, grad/param norm = 2.6551e-01, time/batch = 15.4539s	
16232/22300 (epoch 36.395), train_loss = 0.26669669, grad/param norm = 1.7949e-01, time/batch = 16.3854s	
16233/22300 (epoch 36.397), train_loss = 0.20909414, grad/param norm = 1.9616e-01, time/batch = 15.6335s	
16234/22300 (epoch 36.399), train_loss = 0.29236283, grad/param norm = 3.1710e-01, time/batch = 17.5585s	
16235/22300 (epoch 36.401), train_loss = 0.31854622, grad/param norm = 2.4486e-01, time/batch = 14.8180s	
16236/22300 (epoch 36.404), train_loss = 0.33301019, grad/param norm = 2.1049e-01, time/batch = 15.5707s	
16237/22300 (epoch 36.406), train_loss = 0.52910730, grad/param norm = 2.9340e-01, time/batch = 17.3103s	
16238/22300 (epoch 36.408), train_loss = 0.44451737, grad/param norm = 3.6183e-01, time/batch = 16.7821s	
16239/22300 (epoch 36.410), train_loss = 0.43658838, grad/param norm = 2.6479e-01, time/batch = 15.8124s	
16240/22300 (epoch 36.413), train_loss = 0.34473068, grad/param norm = 2.7551e-01, time/batch = 18.0617s	
16241/22300 (epoch 36.415), train_loss = 0.25507416, grad/param norm = 2.2697e-01, time/batch = 17.9747s	
16242/22300 (epoch 36.417), train_loss = 0.39976658, grad/param norm = 2.7804e-01, time/batch = 15.5146s	
16243/22300 (epoch 36.419), train_loss = 0.34162909, grad/param norm = 2.0229e-01, time/batch = 16.0420s	
16244/22300 (epoch 36.422), train_loss = 0.29877230, grad/param norm = 2.5692e-01, time/batch = 17.3833s	
16245/22300 (epoch 36.424), train_loss = 0.35645274, grad/param norm = 2.0814e-01, time/batch = 15.5668s	
16246/22300 (epoch 36.426), train_loss = 0.26753335, grad/param norm = 2.0880e-01, time/batch = 14.8144s	
16247/22300 (epoch 36.428), train_loss = 0.28097963, grad/param norm = 2.2722e-01, time/batch = 19.6854s	
16248/22300 (epoch 36.430), train_loss = 0.32068606, grad/param norm = 2.1228e-01, time/batch = 15.8150s	
16249/22300 (epoch 36.433), train_loss = 0.33590184, grad/param norm = 1.9185e-01, time/batch = 19.2615s	
16250/22300 (epoch 36.435), train_loss = 0.31300202, grad/param norm = 2.2081e-01, time/batch = 28.1173s	
16251/22300 (epoch 36.437), train_loss = 0.39422470, grad/param norm = 3.4426e-01, time/batch = 17.2246s	
16252/22300 (epoch 36.439), train_loss = 0.44472103, grad/param norm = 2.9454e-01, time/batch = 16.2192s	
16253/22300 (epoch 36.442), train_loss = 0.37667667, grad/param norm = 2.4309e-01, time/batch = 17.5414s	
16254/22300 (epoch 36.444), train_loss = 0.30484684, grad/param norm = 2.8837e-01, time/batch = 15.2961s	
16255/22300 (epoch 36.446), train_loss = 0.31694076, grad/param norm = 2.3127e-01, time/batch = 18.0382s	
16256/22300 (epoch 36.448), train_loss = 0.24301470, grad/param norm = 1.7602e-01, time/batch = 15.9607s	
16257/22300 (epoch 36.451), train_loss = 0.40720635, grad/param norm = 2.8890e-01, time/batch = 17.1326s	
16258/22300 (epoch 36.453), train_loss = 0.30986120, grad/param norm = 2.1705e-01, time/batch = 16.7298s	
16259/22300 (epoch 36.455), train_loss = 0.43756843, grad/param norm = 2.9587e-01, time/batch = 16.5476s	
16260/22300 (epoch 36.457), train_loss = 0.56532158, grad/param norm = 3.5664e-01, time/batch = 15.3837s	
16261/22300 (epoch 36.460), train_loss = 0.47237512, grad/param norm = 2.7624e-01, time/batch = 16.8804s	
16262/22300 (epoch 36.462), train_loss = 0.49016992, grad/param norm = 2.8882e-01, time/batch = 17.7173s	
16263/22300 (epoch 36.464), train_loss = 0.40341335, grad/param norm = 2.9379e-01, time/batch = 15.9660s	
16264/22300 (epoch 36.466), train_loss = 0.34049658, grad/param norm = 2.1030e-01, time/batch = 16.5519s	
16265/22300 (epoch 36.469), train_loss = 0.32735981, grad/param norm = 1.9199e-01, time/batch = 18.5522s	
16266/22300 (epoch 36.471), train_loss = 0.43803302, grad/param norm = 2.3223e-01, time/batch = 16.5405s	
16267/22300 (epoch 36.473), train_loss = 0.38178943, grad/param norm = 2.4638e-01, time/batch = 16.4834s	
16268/22300 (epoch 36.475), train_loss = 0.33221146, grad/param norm = 2.4274e-01, time/batch = 15.9044s	
16269/22300 (epoch 36.478), train_loss = 0.32352566, grad/param norm = 2.1046e-01, time/batch = 17.3763s	
16270/22300 (epoch 36.480), train_loss = 0.25460157, grad/param norm = 1.8701e-01, time/batch = 16.1247s	
16271/22300 (epoch 36.482), train_loss = 0.29199571, grad/param norm = 2.1074e-01, time/batch = 16.4827s	
16272/22300 (epoch 36.484), train_loss = 0.36761276, grad/param norm = 2.9333e-01, time/batch = 16.6370s	
16273/22300 (epoch 36.487), train_loss = 0.44096753, grad/param norm = 2.5130e-01, time/batch = 16.6502s	
16274/22300 (epoch 36.489), train_loss = 0.41620318, grad/param norm = 2.6578e-01, time/batch = 17.1337s	
16275/22300 (epoch 36.491), train_loss = 0.46176280, grad/param norm = 3.5036e-01, time/batch = 16.8769s	
16276/22300 (epoch 36.493), train_loss = 0.35335635, grad/param norm = 3.2449e-01, time/batch = 17.3080s	
16277/22300 (epoch 36.496), train_loss = 0.38682173, grad/param norm = 2.1322e-01, time/batch = 15.2996s	
16278/22300 (epoch 36.498), train_loss = 0.26827968, grad/param norm = 1.9223e-01, time/batch = 15.6049s	
16279/22300 (epoch 36.500), train_loss = 0.37045754, grad/param norm = 2.5322e-01, time/batch = 18.3507s	
16280/22300 (epoch 36.502), train_loss = 0.23851473, grad/param norm = 1.9081e-01, time/batch = 16.7118s	
16281/22300 (epoch 36.504), train_loss = 0.25746044, grad/param norm = 2.1343e-01, time/batch = 16.1322s	
16282/22300 (epoch 36.507), train_loss = 0.31590170, grad/param norm = 2.3887e-01, time/batch = 16.4782s	
16283/22300 (epoch 36.509), train_loss = 0.41082954, grad/param norm = 2.9205e-01, time/batch = 17.7288s	
16284/22300 (epoch 36.511), train_loss = 0.22823579, grad/param norm = 1.7435e-01, time/batch = 15.1109s	
16285/22300 (epoch 36.513), train_loss = 0.26617511, grad/param norm = 2.8641e-01, time/batch = 16.9566s	
16286/22300 (epoch 36.516), train_loss = 0.33171452, grad/param norm = 2.7665e-01, time/batch = 16.7341s	
16287/22300 (epoch 36.518), train_loss = 0.39799685, grad/param norm = 2.8025e-01, time/batch = 17.8094s	
16288/22300 (epoch 36.520), train_loss = 0.34300935, grad/param norm = 2.4906e-01, time/batch = 16.4560s	
16289/22300 (epoch 36.522), train_loss = 0.34047665, grad/param norm = 1.7563e-01, time/batch = 17.2270s	
16290/22300 (epoch 36.525), train_loss = 0.27363499, grad/param norm = 1.9806e-01, time/batch = 17.3885s	
16291/22300 (epoch 36.527), train_loss = 0.42709914, grad/param norm = 3.1567e-01, time/batch = 16.4716s	
16292/22300 (epoch 36.529), train_loss = 0.36031976, grad/param norm = 2.3193e-01, time/batch = 16.1409s	
16293/22300 (epoch 36.531), train_loss = 0.31261526, grad/param norm = 2.1212e-01, time/batch = 15.7294s	
16294/22300 (epoch 36.534), train_loss = 0.35736716, grad/param norm = 4.0934e-01, time/batch = 15.5194s	
16295/22300 (epoch 36.536), train_loss = 0.51961332, grad/param norm = 2.7043e-01, time/batch = 15.4624s	
16296/22300 (epoch 36.538), train_loss = 0.65224772, grad/param norm = 4.2522e-01, time/batch = 16.5357s	
16297/22300 (epoch 36.540), train_loss = 0.37145498, grad/param norm = 2.4659e-01, time/batch = 16.3857s	
16298/22300 (epoch 36.543), train_loss = 0.35308033, grad/param norm = 2.3346e-01, time/batch = 16.8830s	
16299/22300 (epoch 36.545), train_loss = 0.24708328, grad/param norm = 1.9526e-01, time/batch = 15.7206s	
16300/22300 (epoch 36.547), train_loss = 0.23365464, grad/param norm = 2.0503e-01, time/batch = 17.4638s	
16301/22300 (epoch 36.549), train_loss = 0.27723414, grad/param norm = 1.9277e-01, time/batch = 16.9714s	
16302/22300 (epoch 36.552), train_loss = 0.30508223, grad/param norm = 2.5930e-01, time/batch = 16.4605s	
16303/22300 (epoch 36.554), train_loss = 0.38596774, grad/param norm = 2.3457e-01, time/batch = 16.4754s	
16304/22300 (epoch 36.556), train_loss = 0.54915690, grad/param norm = 5.3007e-01, time/batch = 15.3919s	
16305/22300 (epoch 36.558), train_loss = 0.38922118, grad/param norm = 2.5358e-01, time/batch = 15.5488s	
16306/22300 (epoch 36.561), train_loss = 0.56693470, grad/param norm = 3.2922e-01, time/batch = 15.7360s	
16307/22300 (epoch 36.563), train_loss = 0.46496159, grad/param norm = 3.1161e-01, time/batch = 15.9002s	
16308/22300 (epoch 36.565), train_loss = 0.35606921, grad/param norm = 2.4989e-01, time/batch = 16.2159s	
16309/22300 (epoch 36.567), train_loss = 0.36206521, grad/param norm = 2.5635e-01, time/batch = 17.7801s	
16310/22300 (epoch 36.570), train_loss = 0.50354278, grad/param norm = 3.4215e-01, time/batch = 16.0553s	
16311/22300 (epoch 36.572), train_loss = 0.50150872, grad/param norm = 2.8305e-01, time/batch = 17.4563s	
16312/22300 (epoch 36.574), train_loss = 0.36675998, grad/param norm = 2.5242e-01, time/batch = 15.3749s	
16313/22300 (epoch 36.576), train_loss = 0.31798985, grad/param norm = 2.1666e-01, time/batch = 15.3990s	
16314/22300 (epoch 36.578), train_loss = 0.19413442, grad/param norm = 1.6805e-01, time/batch = 16.9663s	
16315/22300 (epoch 36.581), train_loss = 0.27914362, grad/param norm = 2.3255e-01, time/batch = 16.6290s	
16316/22300 (epoch 36.583), train_loss = 0.32516389, grad/param norm = 1.9138e-01, time/batch = 15.2408s	
16317/22300 (epoch 36.585), train_loss = 0.44565375, grad/param norm = 3.1915e-01, time/batch = 16.2109s	
16318/22300 (epoch 36.587), train_loss = 0.64835856, grad/param norm = 3.5741e-01, time/batch = 19.0628s	
16319/22300 (epoch 36.590), train_loss = 0.52037059, grad/param norm = 4.3285e-01, time/batch = 15.4820s	
16320/22300 (epoch 36.592), train_loss = 0.61330861, grad/param norm = 3.2214e-01, time/batch = 16.3885s	
16321/22300 (epoch 36.594), train_loss = 0.58050592, grad/param norm = 3.6963e-01, time/batch = 15.6290s	
16322/22300 (epoch 36.596), train_loss = 0.35311735, grad/param norm = 2.6252e-01, time/batch = 17.3134s	
16323/22300 (epoch 36.599), train_loss = 0.25915445, grad/param norm = 2.1957e-01, time/batch = 15.8785s	
16324/22300 (epoch 36.601), train_loss = 0.31517254, grad/param norm = 2.3997e-01, time/batch = 15.5502s	
16325/22300 (epoch 36.603), train_loss = 0.34478650, grad/param norm = 2.7881e-01, time/batch = 15.9897s	
16326/22300 (epoch 36.605), train_loss = 0.34356076, grad/param norm = 2.4226e-01, time/batch = 18.3032s	
16327/22300 (epoch 36.608), train_loss = 0.57152741, grad/param norm = 3.3042e-01, time/batch = 15.4395s	
16328/22300 (epoch 36.610), train_loss = 0.63520289, grad/param norm = 3.5012e-01, time/batch = 15.1402s	
16329/22300 (epoch 36.612), train_loss = 0.45722951, grad/param norm = 3.2812e-01, time/batch = 17.9695s	
16330/22300 (epoch 36.614), train_loss = 0.44655363, grad/param norm = 3.0961e-01, time/batch = 15.6337s	
16331/22300 (epoch 36.617), train_loss = 0.45581565, grad/param norm = 2.3429e-01, time/batch = 16.3107s	
16332/22300 (epoch 36.619), train_loss = 0.52451997, grad/param norm = 3.3691e-01, time/batch = 15.5281s	
16333/22300 (epoch 36.621), train_loss = 0.33455085, grad/param norm = 2.5047e-01, time/batch = 16.2990s	
16334/22300 (epoch 36.623), train_loss = 0.34574296, grad/param norm = 3.0917e-01, time/batch = 17.9725s	
16335/22300 (epoch 36.626), train_loss = 0.32937691, grad/param norm = 2.0769e-01, time/batch = 15.8948s	
16336/22300 (epoch 36.628), train_loss = 0.32346010, grad/param norm = 2.0320e-01, time/batch = 17.7974s	
16337/22300 (epoch 36.630), train_loss = 0.39644860, grad/param norm = 2.4232e-01, time/batch = 16.3971s	
16338/22300 (epoch 36.632), train_loss = 0.30475032, grad/param norm = 2.3184e-01, time/batch = 17.4644s	
16339/22300 (epoch 36.635), train_loss = 0.37852416, grad/param norm = 2.7836e-01, time/batch = 15.4245s	
16340/22300 (epoch 36.637), train_loss = 0.43646079, grad/param norm = 2.7815e-01, time/batch = 17.1200s	
16341/22300 (epoch 36.639), train_loss = 0.50843416, grad/param norm = 2.9828e-01, time/batch = 16.6512s	
16342/22300 (epoch 36.641), train_loss = 0.41866598, grad/param norm = 2.3936e-01, time/batch = 15.4748s	
16343/22300 (epoch 36.643), train_loss = 0.30971968, grad/param norm = 2.2132e-01, time/batch = 16.6843s	
16344/22300 (epoch 36.646), train_loss = 0.31939617, grad/param norm = 2.2780e-01, time/batch = 17.1262s	
16345/22300 (epoch 36.648), train_loss = 0.43045923, grad/param norm = 2.4544e-01, time/batch = 19.0463s	
16346/22300 (epoch 36.650), train_loss = 0.43434684, grad/param norm = 2.5710e-01, time/batch = 15.7341s	
16347/22300 (epoch 36.652), train_loss = 0.35323254, grad/param norm = 2.2710e-01, time/batch = 17.4625s	
16348/22300 (epoch 36.655), train_loss = 0.30089901, grad/param norm = 2.7349e-01, time/batch = 16.7988s	
16349/22300 (epoch 36.657), train_loss = 0.33365994, grad/param norm = 2.4737e-01, time/batch = 16.4558s	
16350/22300 (epoch 36.659), train_loss = 0.32406460, grad/param norm = 2.2937e-01, time/batch = 16.1360s	
16351/22300 (epoch 36.661), train_loss = 0.26069717, grad/param norm = 2.2846e-01, time/batch = 15.6284s	
16352/22300 (epoch 36.664), train_loss = 0.32782411, grad/param norm = 2.2727e-01, time/batch = 16.7374s	
16353/22300 (epoch 36.666), train_loss = 0.42350231, grad/param norm = 2.9555e-01, time/batch = 15.6225s	
16354/22300 (epoch 36.668), train_loss = 0.30926894, grad/param norm = 2.0469e-01, time/batch = 14.4843s	
16355/22300 (epoch 36.670), train_loss = 0.39506684, grad/param norm = 2.6196e-01, time/batch = 16.4802s	
16356/22300 (epoch 36.673), train_loss = 0.45952224, grad/param norm = 2.6099e-01, time/batch = 18.2182s	
16357/22300 (epoch 36.675), train_loss = 0.51072574, grad/param norm = 3.2156e-01, time/batch = 16.1962s	
16358/22300 (epoch 36.677), train_loss = 0.56227078, grad/param norm = 3.8406e-01, time/batch = 17.3037s	
16359/22300 (epoch 36.679), train_loss = 0.40646951, grad/param norm = 3.1150e-01, time/batch = 15.6535s	
16360/22300 (epoch 36.682), train_loss = 0.37521484, grad/param norm = 2.3536e-01, time/batch = 16.3030s	
16361/22300 (epoch 36.684), train_loss = 0.35605678, grad/param norm = 2.1079e-01, time/batch = 15.6350s	
16362/22300 (epoch 36.686), train_loss = 0.34713651, grad/param norm = 2.1811e-01, time/batch = 18.2053s	
16363/22300 (epoch 36.688), train_loss = 0.33069320, grad/param norm = 2.3522e-01, time/batch = 15.9482s	
16364/22300 (epoch 36.691), train_loss = 0.29208331, grad/param norm = 2.5076e-01, time/batch = 15.7159s	
16365/22300 (epoch 36.693), train_loss = 0.28486253, grad/param norm = 2.2510e-01, time/batch = 18.1225s	
16366/22300 (epoch 36.695), train_loss = 0.31013927, grad/param norm = 2.0208e-01, time/batch = 16.2385s	
16367/22300 (epoch 36.697), train_loss = 0.35157945, grad/param norm = 2.5899e-01, time/batch = 16.1418s	
16368/22300 (epoch 36.700), train_loss = 0.30588055, grad/param norm = 2.1749e-01, time/batch = 15.7817s	
16369/22300 (epoch 36.702), train_loss = 0.24697357, grad/param norm = 1.6381e-01, time/batch = 15.8894s	
16370/22300 (epoch 36.704), train_loss = 0.34826048, grad/param norm = 2.9426e-01, time/batch = 15.2057s	
16371/22300 (epoch 36.706), train_loss = 0.30787034, grad/param norm = 2.1683e-01, time/batch = 17.2860s	
16372/22300 (epoch 36.709), train_loss = 0.25700450, grad/param norm = 2.1344e-01, time/batch = 16.4031s	
16373/22300 (epoch 36.711), train_loss = 0.25783596, grad/param norm = 1.8090e-01, time/batch = 15.1513s	
16374/22300 (epoch 36.713), train_loss = 0.37792000, grad/param norm = 2.5323e-01, time/batch = 17.7139s	
16375/22300 (epoch 36.715), train_loss = 0.38126761, grad/param norm = 2.3350e-01, time/batch = 16.0389s	
16376/22300 (epoch 36.717), train_loss = 0.51083624, grad/param norm = 2.5961e-01, time/batch = 17.8900s	
16377/22300 (epoch 36.720), train_loss = 0.33062465, grad/param norm = 2.3668e-01, time/batch = 17.3121s	
16378/22300 (epoch 36.722), train_loss = 0.37002957, grad/param norm = 2.2837e-01, time/batch = 17.3750s	
16379/22300 (epoch 36.724), train_loss = 0.40181893, grad/param norm = 2.9618e-01, time/batch = 16.5618s	
16380/22300 (epoch 36.726), train_loss = 0.32777399, grad/param norm = 2.6811e-01, time/batch = 17.3893s	
16381/22300 (epoch 36.729), train_loss = 0.39022078, grad/param norm = 2.9673e-01, time/batch = 16.0359s	
16382/22300 (epoch 36.731), train_loss = 0.49232865, grad/param norm = 3.1891e-01, time/batch = 15.7186s	
16383/22300 (epoch 36.733), train_loss = 0.48232140, grad/param norm = 2.8430e-01, time/batch = 16.4785s	
16384/22300 (epoch 36.735), train_loss = 0.51339398, grad/param norm = 3.5835e-01, time/batch = 15.8114s	
16385/22300 (epoch 36.738), train_loss = 0.37891530, grad/param norm = 2.6452e-01, time/batch = 18.1937s	
16386/22300 (epoch 36.740), train_loss = 0.34665617, grad/param norm = 2.2017e-01, time/batch = 15.6332s	
16387/22300 (epoch 36.742), train_loss = 0.30833526, grad/param norm = 2.2412e-01, time/batch = 15.2251s	
16388/22300 (epoch 36.744), train_loss = 0.57182285, grad/param norm = 3.4109e-01, time/batch = 15.8869s	
16389/22300 (epoch 36.747), train_loss = 0.44843627, grad/param norm = 2.7814e-01, time/batch = 16.2922s	
16390/22300 (epoch 36.749), train_loss = 0.55030453, grad/param norm = 3.2264e-01, time/batch = 16.3865s	
16391/22300 (epoch 36.751), train_loss = 0.49050898, grad/param norm = 3.2921e-01, time/batch = 16.5535s	
16392/22300 (epoch 36.753), train_loss = 0.50391253, grad/param norm = 3.0627e-01, time/batch = 17.3025s	
16393/22300 (epoch 36.756), train_loss = 0.49571374, grad/param norm = 3.5515e-01, time/batch = 15.1032s	
16394/22300 (epoch 36.758), train_loss = 0.39744373, grad/param norm = 2.4192e-01, time/batch = 18.4737s	
16395/22300 (epoch 36.760), train_loss = 0.45694179, grad/param norm = 2.7141e-01, time/batch = 15.4066s	
16396/22300 (epoch 36.762), train_loss = 0.40141648, grad/param norm = 2.8014e-01, time/batch = 15.7371s	
16397/22300 (epoch 36.765), train_loss = 0.44106494, grad/param norm = 3.3879e-01, time/batch = 15.9469s	
16398/22300 (epoch 36.767), train_loss = 0.41547169, grad/param norm = 2.6570e-01, time/batch = 16.9669s	
16399/22300 (epoch 36.769), train_loss = 0.40538068, grad/param norm = 2.5011e-01, time/batch = 16.4149s	
16400/22300 (epoch 36.771), train_loss = 0.46624292, grad/param norm = 3.5223e-01, time/batch = 15.5412s	
16401/22300 (epoch 36.774), train_loss = 0.49304554, grad/param norm = 3.4092e-01, time/batch = 15.9313s	
16402/22300 (epoch 36.776), train_loss = 0.55150072, grad/param norm = 3.4934e-01, time/batch = 17.3129s	
16403/22300 (epoch 36.778), train_loss = 0.51049266, grad/param norm = 3.4276e-01, time/batch = 15.2216s	
16404/22300 (epoch 36.780), train_loss = 0.50621602, grad/param norm = 3.0584e-01, time/batch = 15.7277s	
16405/22300 (epoch 36.783), train_loss = 0.53765387, grad/param norm = 3.2444e-01, time/batch = 16.7197s	
16406/22300 (epoch 36.785), train_loss = 0.37046465, grad/param norm = 2.7512e-01, time/batch = 15.0466s	
16407/22300 (epoch 36.787), train_loss = 0.37718657, grad/param norm = 3.2115e-01, time/batch = 14.4017s	
16408/22300 (epoch 36.789), train_loss = 0.55086431, grad/param norm = 3.0271e-01, time/batch = 15.1523s	
16409/22300 (epoch 36.791), train_loss = 0.65085673, grad/param norm = 3.5016e-01, time/batch = 17.8053s	
16410/22300 (epoch 36.794), train_loss = 0.54755464, grad/param norm = 3.9692e-01, time/batch = 16.5545s	
16411/22300 (epoch 36.796), train_loss = 0.47770952, grad/param norm = 3.1637e-01, time/batch = 17.5296s	
16412/22300 (epoch 36.798), train_loss = 0.63592753, grad/param norm = 3.2862e-01, time/batch = 16.6314s	
16413/22300 (epoch 36.800), train_loss = 0.42310420, grad/param norm = 2.6053e-01, time/batch = 17.8065s	
16414/22300 (epoch 36.803), train_loss = 0.36417827, grad/param norm = 2.0929e-01, time/batch = 17.3098s	
16415/22300 (epoch 36.805), train_loss = 0.44012204, grad/param norm = 3.1029e-01, time/batch = 15.1391s	
16416/22300 (epoch 36.807), train_loss = 0.59229287, grad/param norm = 3.6737e-01, time/batch = 17.3065s	
16417/22300 (epoch 36.809), train_loss = 0.41903692, grad/param norm = 2.9834e-01, time/batch = 16.1489s	
16418/22300 (epoch 36.812), train_loss = 0.46402283, grad/param norm = 3.0689e-01, time/batch = 17.9651s	
16419/22300 (epoch 36.814), train_loss = 0.44552889, grad/param norm = 2.9800e-01, time/batch = 17.3865s	
16420/22300 (epoch 36.816), train_loss = 0.46082024, grad/param norm = 2.7875e-01, time/batch = 16.3140s	
16421/22300 (epoch 36.818), train_loss = 0.56202058, grad/param norm = 3.8059e-01, time/batch = 14.9585s	
16422/22300 (epoch 36.821), train_loss = 0.45674841, grad/param norm = 2.9140e-01, time/batch = 17.4764s	
16423/22300 (epoch 36.823), train_loss = 0.31246881, grad/param norm = 2.8166e-01, time/batch = 14.7278s	
16424/22300 (epoch 36.825), train_loss = 0.33802714, grad/param norm = 2.7516e-01, time/batch = 17.4539s	
16425/22300 (epoch 36.827), train_loss = 0.37544395, grad/param norm = 2.6538e-01, time/batch = 17.6420s	
16426/22300 (epoch 36.830), train_loss = 0.38255982, grad/param norm = 2.7538e-01, time/batch = 15.5381s	
16427/22300 (epoch 36.832), train_loss = 0.33989627, grad/param norm = 2.1531e-01, time/batch = 17.3179s	
16428/22300 (epoch 36.834), train_loss = 0.28775281, grad/param norm = 1.8452e-01, time/batch = 18.1452s	
16429/22300 (epoch 36.836), train_loss = 0.36493678, grad/param norm = 2.4132e-01, time/batch = 16.5462s	
16430/22300 (epoch 36.839), train_loss = 0.40178540, grad/param norm = 2.3523e-01, time/batch = 17.1353s	
16431/22300 (epoch 36.841), train_loss = 0.37134234, grad/param norm = 2.8202e-01, time/batch = 15.3277s	
16432/22300 (epoch 36.843), train_loss = 0.39851310, grad/param norm = 2.6819e-01, time/batch = 15.2006s	
16433/22300 (epoch 36.845), train_loss = 0.39766059, grad/param norm = 2.7250e-01, time/batch = 15.2228s	
16434/22300 (epoch 36.848), train_loss = 0.37330793, grad/param norm = 2.6223e-01, time/batch = 16.6969s	
16435/22300 (epoch 36.850), train_loss = 0.39769669, grad/param norm = 2.4401e-01, time/batch = 16.4905s	
16436/22300 (epoch 36.852), train_loss = 0.36870166, grad/param norm = 3.2079e-01, time/batch = 18.3764s	
16437/22300 (epoch 36.854), train_loss = 0.61921730, grad/param norm = 3.8197e-01, time/batch = 15.7155s	
16438/22300 (epoch 36.857), train_loss = 0.43953934, grad/param norm = 2.7928e-01, time/batch = 15.6953s	
16439/22300 (epoch 36.859), train_loss = 0.35001735, grad/param norm = 2.0715e-01, time/batch = 17.7233s	
16440/22300 (epoch 36.861), train_loss = 0.47011772, grad/param norm = 2.7518e-01, time/batch = 16.6323s	
16441/22300 (epoch 36.863), train_loss = 0.30908259, grad/param norm = 2.2197e-01, time/batch = 17.1362s	
16442/22300 (epoch 36.865), train_loss = 0.30183236, grad/param norm = 2.1035e-01, time/batch = 17.0408s	
16443/22300 (epoch 36.868), train_loss = 0.42120810, grad/param norm = 2.9178e-01, time/batch = 17.9665s	
16444/22300 (epoch 36.870), train_loss = 0.42544803, grad/param norm = 3.2867e-01, time/batch = 16.5540s	
16445/22300 (epoch 36.872), train_loss = 0.52761379, grad/param norm = 2.9273e-01, time/batch = 16.7305s	
16446/22300 (epoch 36.874), train_loss = 0.42784315, grad/param norm = 2.8733e-01, time/batch = 17.9659s	
16447/22300 (epoch 36.877), train_loss = 0.41077041, grad/param norm = 2.4237e-01, time/batch = 16.7046s	
16448/22300 (epoch 36.879), train_loss = 0.38153375, grad/param norm = 2.2546e-01, time/batch = 18.2208s	
16449/22300 (epoch 36.881), train_loss = 0.31271103, grad/param norm = 2.5131e-01, time/batch = 15.0738s	
16450/22300 (epoch 36.883), train_loss = 0.31871098, grad/param norm = 2.0345e-01, time/batch = 17.3082s	
16451/22300 (epoch 36.886), train_loss = 0.30914260, grad/param norm = 2.2844e-01, time/batch = 17.2173s	
16452/22300 (epoch 36.888), train_loss = 0.35450452, grad/param norm = 2.5196e-01, time/batch = 18.2961s	
16453/22300 (epoch 36.890), train_loss = 0.36086679, grad/param norm = 2.1739e-01, time/batch = 16.6411s	
16454/22300 (epoch 36.892), train_loss = 0.55137641, grad/param norm = 2.8651e-01, time/batch = 15.5991s	
16455/22300 (epoch 36.895), train_loss = 0.49253487, grad/param norm = 3.5323e-01, time/batch = 17.7277s	
16456/22300 (epoch 36.897), train_loss = 0.39002754, grad/param norm = 2.8116e-01, time/batch = 15.8176s	
16457/22300 (epoch 36.899), train_loss = 0.37780478, grad/param norm = 2.4205e-01, time/batch = 15.6375s	
16458/22300 (epoch 36.901), train_loss = 0.45813961, grad/param norm = 2.5739e-01, time/batch = 14.8980s	
16459/22300 (epoch 36.904), train_loss = 0.48114820, grad/param norm = 3.4956e-01, time/batch = 16.2172s	
16460/22300 (epoch 36.906), train_loss = 0.43492735, grad/param norm = 2.4122e-01, time/batch = 16.3123s	
16461/22300 (epoch 36.908), train_loss = 0.38152133, grad/param norm = 2.5296e-01, time/batch = 16.4710s	
16462/22300 (epoch 36.910), train_loss = 0.34479407, grad/param norm = 2.1546e-01, time/batch = 16.0428s	
16463/22300 (epoch 36.913), train_loss = 0.44496200, grad/param norm = 2.9942e-01, time/batch = 19.2193s	
16464/22300 (epoch 36.915), train_loss = 0.56012388, grad/param norm = 3.0303e-01, time/batch = 18.2739s	
16465/22300 (epoch 36.917), train_loss = 0.46111867, grad/param norm = 2.8832e-01, time/batch = 36.6195s	
16466/22300 (epoch 36.919), train_loss = 0.43868680, grad/param norm = 2.2062e-01, time/batch = 23.6417s	
16467/22300 (epoch 36.922), train_loss = 0.43133645, grad/param norm = 2.7595e-01, time/batch = 15.4735s	
16468/22300 (epoch 36.924), train_loss = 0.26262622, grad/param norm = 2.2700e-01, time/batch = 16.0344s	
16469/22300 (epoch 36.926), train_loss = 0.32691070, grad/param norm = 1.8014e-01, time/batch = 16.0598s	
16470/22300 (epoch 36.928), train_loss = 0.36093448, grad/param norm = 2.8688e-01, time/batch = 16.6058s	
16471/22300 (epoch 36.930), train_loss = 0.36808329, grad/param norm = 2.5211e-01, time/batch = 16.3048s	
16472/22300 (epoch 36.933), train_loss = 0.44311228, grad/param norm = 3.3007e-01, time/batch = 16.2272s	
16473/22300 (epoch 36.935), train_loss = 0.42695863, grad/param norm = 3.1518e-01, time/batch = 14.9857s	
16474/22300 (epoch 36.937), train_loss = 0.52752094, grad/param norm = 3.5901e-01, time/batch = 16.2193s	
16475/22300 (epoch 36.939), train_loss = 0.45611418, grad/param norm = 2.7947e-01, time/batch = 17.2192s	
16476/22300 (epoch 36.942), train_loss = 0.57937733, grad/param norm = 3.1664e-01, time/batch = 15.7941s	
16477/22300 (epoch 36.944), train_loss = 0.61431297, grad/param norm = 3.7906e-01, time/batch = 17.4709s	
16478/22300 (epoch 36.946), train_loss = 0.46302815, grad/param norm = 2.8346e-01, time/batch = 16.0316s	
16479/22300 (epoch 36.948), train_loss = 0.36988528, grad/param norm = 2.2588e-01, time/batch = 17.5524s	
16480/22300 (epoch 36.951), train_loss = 0.29567038, grad/param norm = 1.9955e-01, time/batch = 15.6479s	
16481/22300 (epoch 36.953), train_loss = 0.35630801, grad/param norm = 3.3514e-01, time/batch = 18.3406s	
16482/22300 (epoch 36.955), train_loss = 0.51567014, grad/param norm = 2.8281e-01, time/batch = 15.7986s	
16483/22300 (epoch 36.957), train_loss = 0.61637856, grad/param norm = 3.0112e-01, time/batch = 15.1338s	
16484/22300 (epoch 36.960), train_loss = 0.52278838, grad/param norm = 2.7263e-01, time/batch = 15.0003s	
16485/22300 (epoch 36.962), train_loss = 0.34197565, grad/param norm = 2.5116e-01, time/batch = 16.8726s	
16486/22300 (epoch 36.964), train_loss = 0.34493585, grad/param norm = 2.2766e-01, time/batch = 15.3727s	
16487/22300 (epoch 36.966), train_loss = 0.35141873, grad/param norm = 2.9068e-01, time/batch = 15.4863s	
16488/22300 (epoch 36.969), train_loss = 0.37601072, grad/param norm = 2.2137e-01, time/batch = 15.8153s	
16489/22300 (epoch 36.971), train_loss = 0.40121849, grad/param norm = 2.0788e-01, time/batch = 16.3081s	
16490/22300 (epoch 36.973), train_loss = 0.41824127, grad/param norm = 2.9003e-01, time/batch = 17.5418s	
16491/22300 (epoch 36.975), train_loss = 0.54568096, grad/param norm = 3.1019e-01, time/batch = 16.0732s	
16492/22300 (epoch 36.978), train_loss = 0.51702786, grad/param norm = 2.8321e-01, time/batch = 17.1335s	
16493/22300 (epoch 36.980), train_loss = 0.59194272, grad/param norm = 3.0967e-01, time/batch = 16.5447s	
16494/22300 (epoch 36.982), train_loss = 0.31276989, grad/param norm = 2.5184e-01, time/batch = 15.1444s	
16495/22300 (epoch 36.984), train_loss = 0.38848153, grad/param norm = 2.4093e-01, time/batch = 15.3753s	
16496/22300 (epoch 36.987), train_loss = 0.39020814, grad/param norm = 2.2864e-01, time/batch = 16.7868s	
16497/22300 (epoch 36.989), train_loss = 0.32511598, grad/param norm = 2.3495e-01, time/batch = 15.9828s	
16498/22300 (epoch 36.991), train_loss = 0.60613599, grad/param norm = 3.8764e-01, time/batch = 16.6401s	
16499/22300 (epoch 36.993), train_loss = 0.77035287, grad/param norm = 3.7057e-01, time/batch = 15.8935s	
16500/22300 (epoch 36.996), train_loss = 0.71496233, grad/param norm = 3.3793e-01, time/batch = 15.3267s	
16501/22300 (epoch 36.998), train_loss = 0.46311476, grad/param norm = 3.0821e-01, time/batch = 15.3066s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
16502/22300 (epoch 37.000), train_loss = 0.35624183, grad/param norm = 2.5585e-01, time/batch = 15.8953s	
16503/22300 (epoch 37.002), train_loss = 0.71540999, grad/param norm = 3.6065e-01, time/batch = 17.5429s	
16504/22300 (epoch 37.004), train_loss = 0.49057151, grad/param norm = 2.9343e-01, time/batch = 16.6300s	
16505/22300 (epoch 37.007), train_loss = 0.48515849, grad/param norm = 3.1526e-01, time/batch = 16.7352s	
16506/22300 (epoch 37.009), train_loss = 0.49756108, grad/param norm = 3.2221e-01, time/batch = 16.9865s	
16507/22300 (epoch 37.011), train_loss = 0.60264653, grad/param norm = 3.0279e-01, time/batch = 16.6392s	
16508/22300 (epoch 37.013), train_loss = 0.47564668, grad/param norm = 2.5025e-01, time/batch = 18.0508s	
16509/22300 (epoch 37.016), train_loss = 0.37860509, grad/param norm = 2.8360e-01, time/batch = 17.7104s	
16510/22300 (epoch 37.018), train_loss = 0.41170028, grad/param norm = 2.9707e-01, time/batch = 17.1214s	
16511/22300 (epoch 37.020), train_loss = 0.38396995, grad/param norm = 2.3257e-01, time/batch = 16.0946s	
16512/22300 (epoch 37.022), train_loss = 0.31071038, grad/param norm = 2.5846e-01, time/batch = 16.2956s	
16513/22300 (epoch 37.025), train_loss = 0.35261725, grad/param norm = 2.3620e-01, time/batch = 17.9646s	
16514/22300 (epoch 37.027), train_loss = 0.33679791, grad/param norm = 1.9971e-01, time/batch = 16.5545s	
16515/22300 (epoch 37.029), train_loss = 0.37758197, grad/param norm = 2.2888e-01, time/batch = 17.3800s	
16516/22300 (epoch 37.031), train_loss = 0.35329886, grad/param norm = 2.0431e-01, time/batch = 16.9042s	
16517/22300 (epoch 37.034), train_loss = 0.35365023, grad/param norm = 2.4612e-01, time/batch = 15.8179s	
16518/22300 (epoch 37.036), train_loss = 0.30838120, grad/param norm = 1.7171e-01, time/batch = 16.3001s	
16519/22300 (epoch 37.038), train_loss = 0.29855760, grad/param norm = 2.2678e-01, time/batch = 16.9852s	
16520/22300 (epoch 37.040), train_loss = 0.35777682, grad/param norm = 2.8775e-01, time/batch = 15.7313s	
16521/22300 (epoch 37.043), train_loss = 0.58331973, grad/param norm = 3.1463e-01, time/batch = 16.1900s	
16522/22300 (epoch 37.045), train_loss = 0.50588788, grad/param norm = 3.0231e-01, time/batch = 16.1062s	
16523/22300 (epoch 37.047), train_loss = 0.53041945, grad/param norm = 3.3242e-01, time/batch = 15.9036s	
16524/22300 (epoch 37.049), train_loss = 0.41982440, grad/param norm = 2.8339e-01, time/batch = 17.7311s	
16525/22300 (epoch 37.052), train_loss = 0.47536596, grad/param norm = 3.2454e-01, time/batch = 15.8031s	
16526/22300 (epoch 37.054), train_loss = 0.44811236, grad/param norm = 2.5978e-01, time/batch = 16.6547s	
16527/22300 (epoch 37.056), train_loss = 0.23723835, grad/param norm = 2.0117e-01, time/batch = 17.3972s	
16528/22300 (epoch 37.058), train_loss = 0.38348790, grad/param norm = 2.6982e-01, time/batch = 16.7230s	
16529/22300 (epoch 37.061), train_loss = 0.36251929, grad/param norm = 3.1239e-01, time/batch = 14.9741s	
16530/22300 (epoch 37.063), train_loss = 0.53578247, grad/param norm = 4.9321e-01, time/batch = 16.5442s	
16531/22300 (epoch 37.065), train_loss = 0.60803688, grad/param norm = 3.4581e-01, time/batch = 17.3745s	
16532/22300 (epoch 37.067), train_loss = 0.34951142, grad/param norm = 2.2422e-01, time/batch = 14.7318s	
16533/22300 (epoch 37.070), train_loss = 0.39276281, grad/param norm = 2.6811e-01, time/batch = 18.2906s	
16534/22300 (epoch 37.072), train_loss = 0.46523426, grad/param norm = 3.2629e-01, time/batch = 17.5512s	
16535/22300 (epoch 37.074), train_loss = 0.45511582, grad/param norm = 2.5737e-01, time/batch = 18.9594s	
16536/22300 (epoch 37.076), train_loss = 0.43276239, grad/param norm = 2.5399e-01, time/batch = 17.1200s	
16537/22300 (epoch 37.078), train_loss = 0.56504851, grad/param norm = 4.2050e-01, time/batch = 17.1225s	
16538/22300 (epoch 37.081), train_loss = 0.56205322, grad/param norm = 4.2559e-01, time/batch = 15.3833s	
16539/22300 (epoch 37.083), train_loss = 0.64094757, grad/param norm = 4.0242e-01, time/batch = 17.1317s	
16540/22300 (epoch 37.085), train_loss = 0.57943261, grad/param norm = 3.1245e-01, time/batch = 15.3622s	
16541/22300 (epoch 37.087), train_loss = 0.48925277, grad/param norm = 3.2717e-01, time/batch = 17.5475s	
16542/22300 (epoch 37.090), train_loss = 0.45738429, grad/param norm = 3.4316e-01, time/batch = 18.2960s	
16543/22300 (epoch 37.092), train_loss = 0.33179693, grad/param norm = 2.1237e-01, time/batch = 15.6357s	
16544/22300 (epoch 37.094), train_loss = 0.34432340, grad/param norm = 2.4782e-01, time/batch = 18.6317s	
16545/22300 (epoch 37.096), train_loss = 0.61459030, grad/param norm = 5.2136e-01, time/batch = 17.0646s	
16546/22300 (epoch 37.099), train_loss = 0.39391429, grad/param norm = 2.5518e-01, time/batch = 16.4733s	
16547/22300 (epoch 37.101), train_loss = 0.51618401, grad/param norm = 3.3974e-01, time/batch = 15.3773s	
16548/22300 (epoch 37.103), train_loss = 0.41378663, grad/param norm = 2.3112e-01, time/batch = 15.7981s	
16549/22300 (epoch 37.105), train_loss = 0.32901131, grad/param norm = 3.1812e-01, time/batch = 18.7078s	
16550/22300 (epoch 37.108), train_loss = 0.48693732, grad/param norm = 2.8194e-01, time/batch = 16.3533s	
16551/22300 (epoch 37.110), train_loss = 0.52854005, grad/param norm = 3.1390e-01, time/batch = 15.6349s	
16552/22300 (epoch 37.112), train_loss = 0.45126157, grad/param norm = 2.3212e-01, time/batch = 17.9715s	
16553/22300 (epoch 37.114), train_loss = 0.52229862, grad/param norm = 3.4938e-01, time/batch = 17.5519s	
16554/22300 (epoch 37.117), train_loss = 0.57547454, grad/param norm = 2.9743e-01, time/batch = 17.8781s	
16555/22300 (epoch 37.119), train_loss = 0.53832390, grad/param norm = 3.6406e-01, time/batch = 16.3932s	
16556/22300 (epoch 37.121), train_loss = 0.61669792, grad/param norm = 3.6026e-01, time/batch = 17.8842s	
16557/22300 (epoch 37.123), train_loss = 0.61563404, grad/param norm = 3.3885e-01, time/batch = 15.3018s	
16558/22300 (epoch 37.126), train_loss = 0.47552499, grad/param norm = 2.6030e-01, time/batch = 18.8799s	
16559/22300 (epoch 37.128), train_loss = 0.45519939, grad/param norm = 2.7722e-01, time/batch = 15.5585s	
16560/22300 (epoch 37.130), train_loss = 0.41231170, grad/param norm = 3.4177e-01, time/batch = 16.5069s	
16561/22300 (epoch 37.132), train_loss = 0.28756934, grad/param norm = 2.1838e-01, time/batch = 14.8682s	
16562/22300 (epoch 37.135), train_loss = 0.29371159, grad/param norm = 2.0588e-01, time/batch = 17.4718s	
16563/22300 (epoch 37.137), train_loss = 0.25102406, grad/param norm = 2.4524e-01, time/batch = 16.4724s	
16564/22300 (epoch 37.139), train_loss = 0.37693359, grad/param norm = 2.7525e-01, time/batch = 16.4048s	
16565/22300 (epoch 37.141), train_loss = 0.49776471, grad/param norm = 2.6115e-01, time/batch = 15.2291s	
16566/22300 (epoch 37.143), train_loss = 0.42726979, grad/param norm = 2.9846e-01, time/batch = 16.9615s	
16567/22300 (epoch 37.146), train_loss = 0.53372893, grad/param norm = 3.3649e-01, time/batch = 15.7333s	
16568/22300 (epoch 37.148), train_loss = 0.34670353, grad/param norm = 2.5672e-01, time/batch = 16.4582s	
16569/22300 (epoch 37.150), train_loss = 0.37007502, grad/param norm = 2.1121e-01, time/batch = 16.9708s	
16570/22300 (epoch 37.152), train_loss = 0.31390857, grad/param norm = 2.2181e-01, time/batch = 17.8841s	
16571/22300 (epoch 37.155), train_loss = 0.34361932, grad/param norm = 2.5940e-01, time/batch = 15.2800s	
16572/22300 (epoch 37.157), train_loss = 0.44994107, grad/param norm = 2.7269e-01, time/batch = 15.6381s	
16573/22300 (epoch 37.159), train_loss = 0.47303534, grad/param norm = 3.3204e-01, time/batch = 17.1137s	
16574/22300 (epoch 37.161), train_loss = 0.49134698, grad/param norm = 3.5294e-01, time/batch = 17.0448s	
16575/22300 (epoch 37.164), train_loss = 0.34643543, grad/param norm = 2.1921e-01, time/batch = 15.7110s	
16576/22300 (epoch 37.166), train_loss = 0.30909939, grad/param norm = 2.0878e-01, time/batch = 18.0534s	
16577/22300 (epoch 37.168), train_loss = 0.32024011, grad/param norm = 2.4926e-01, time/batch = 16.1424s	
16578/22300 (epoch 37.170), train_loss = 0.40540706, grad/param norm = 2.3561e-01, time/batch = 18.0549s	
16579/22300 (epoch 37.173), train_loss = 0.50528570, grad/param norm = 3.4464e-01, time/batch = 16.6240s	
16580/22300 (epoch 37.175), train_loss = 0.42176665, grad/param norm = 2.8374e-01, time/batch = 16.3950s	
16581/22300 (epoch 37.177), train_loss = 0.27464666, grad/param norm = 1.8491e-01, time/batch = 17.4655s	
16582/22300 (epoch 37.179), train_loss = 0.40964175, grad/param norm = 2.4693e-01, time/batch = 15.6240s	
16583/22300 (epoch 37.182), train_loss = 0.60122293, grad/param norm = 3.7278e-01, time/batch = 17.3825s	
16584/22300 (epoch 37.184), train_loss = 0.60211365, grad/param norm = 3.3348e-01, time/batch = 16.7098s	
16585/22300 (epoch 37.186), train_loss = 0.43283213, grad/param norm = 2.9806e-01, time/batch = 17.5554s	
16586/22300 (epoch 37.188), train_loss = 0.61690566, grad/param norm = 3.1751e-01, time/batch = 15.2928s	
16587/22300 (epoch 37.191), train_loss = 0.51985321, grad/param norm = 3.2037e-01, time/batch = 16.8820s	
16588/22300 (epoch 37.193), train_loss = 0.47177944, grad/param norm = 3.1186e-01, time/batch = 15.5246s	
16589/22300 (epoch 37.195), train_loss = 0.41088654, grad/param norm = 2.7095e-01, time/batch = 17.1247s	
16590/22300 (epoch 37.197), train_loss = 0.36755762, grad/param norm = 2.2329e-01, time/batch = 17.1364s	
16591/22300 (epoch 37.200), train_loss = 0.33819308, grad/param norm = 2.4338e-01, time/batch = 17.2088s	
16592/22300 (epoch 37.202), train_loss = 0.34451606, grad/param norm = 2.1989e-01, time/batch = 16.7289s	
16593/22300 (epoch 37.204), train_loss = 0.42533883, grad/param norm = 2.3281e-01, time/batch = 15.0562s	
16594/22300 (epoch 37.206), train_loss = 0.34352114, grad/param norm = 2.4566e-01, time/batch = 17.1446s	
16595/22300 (epoch 37.209), train_loss = 0.37633896, grad/param norm = 2.8061e-01, time/batch = 17.7244s	
16596/22300 (epoch 37.211), train_loss = 0.31753094, grad/param norm = 2.4248e-01, time/batch = 17.1412s	
16597/22300 (epoch 37.213), train_loss = 0.42722478, grad/param norm = 2.5377e-01, time/batch = 18.1989s	
16598/22300 (epoch 37.215), train_loss = 0.55751841, grad/param norm = 3.7248e-01, time/batch = 15.0104s	
16599/22300 (epoch 37.217), train_loss = 0.54918958, grad/param norm = 2.7976e-01, time/batch = 17.8857s	
16600/22300 (epoch 37.220), train_loss = 0.38450202, grad/param norm = 2.2434e-01, time/batch = 15.8815s	
16601/22300 (epoch 37.222), train_loss = 0.37971004, grad/param norm = 2.7257e-01, time/batch = 16.3029s	
16602/22300 (epoch 37.224), train_loss = 0.36621529, grad/param norm = 2.5388e-01, time/batch = 15.8088s	
16603/22300 (epoch 37.226), train_loss = 0.39978623, grad/param norm = 2.3797e-01, time/batch = 18.1246s	
16604/22300 (epoch 37.229), train_loss = 0.33898659, grad/param norm = 2.8867e-01, time/batch = 15.3008s	
16605/22300 (epoch 37.231), train_loss = 0.51433536, grad/param norm = 3.2046e-01, time/batch = 18.5588s	
16606/22300 (epoch 37.233), train_loss = 0.43610246, grad/param norm = 2.8700e-01, time/batch = 15.8984s	
16607/22300 (epoch 37.235), train_loss = 0.32827577, grad/param norm = 2.3833e-01, time/batch = 14.8480s	
16608/22300 (epoch 37.238), train_loss = 0.33888127, grad/param norm = 2.1370e-01, time/batch = 3.1297s	
16609/22300 (epoch 37.240), train_loss = 0.35277813, grad/param norm = 2.1762e-01, time/batch = 0.6480s	
16610/22300 (epoch 37.242), train_loss = 0.32224457, grad/param norm = 3.2630e-01, time/batch = 0.6478s	
16611/22300 (epoch 37.244), train_loss = 0.22921496, grad/param norm = 1.8246e-01, time/batch = 0.6451s	
16612/22300 (epoch 37.247), train_loss = 0.31270904, grad/param norm = 2.2406e-01, time/batch = 0.6420s	
16613/22300 (epoch 37.249), train_loss = 0.21563617, grad/param norm = 1.5948e-01, time/batch = 0.6503s	
16614/22300 (epoch 37.251), train_loss = 0.28156366, grad/param norm = 1.6575e-01, time/batch = 0.6417s	
16615/22300 (epoch 37.253), train_loss = 0.20090147, grad/param norm = 2.1313e-01, time/batch = 0.6856s	
16616/22300 (epoch 37.256), train_loss = 0.29141259, grad/param norm = 2.1679e-01, time/batch = 0.9458s	
16617/22300 (epoch 37.258), train_loss = 0.41638947, grad/param norm = 2.8457e-01, time/batch = 0.9406s	
16618/22300 (epoch 37.260), train_loss = 0.42899453, grad/param norm = 2.5076e-01, time/batch = 0.9517s	
16619/22300 (epoch 37.262), train_loss = 0.30144317, grad/param norm = 1.7891e-01, time/batch = 0.9579s	
16620/22300 (epoch 37.265), train_loss = 0.28259749, grad/param norm = 1.9572e-01, time/batch = 0.9489s	
16621/22300 (epoch 37.267), train_loss = 0.33305964, grad/param norm = 2.4412e-01, time/batch = 1.7077s	
16622/22300 (epoch 37.269), train_loss = 0.39707022, grad/param norm = 2.6802e-01, time/batch = 1.8133s	
16623/22300 (epoch 37.271), train_loss = 0.45440764, grad/param norm = 2.6663e-01, time/batch = 4.2105s	
16624/22300 (epoch 37.274), train_loss = 0.29519129, grad/param norm = 2.1244e-01, time/batch = 15.8301s	
16625/22300 (epoch 37.276), train_loss = 0.26636242, grad/param norm = 1.8208e-01, time/batch = 17.8908s	
16626/22300 (epoch 37.278), train_loss = 0.27982138, grad/param norm = 1.9088e-01, time/batch = 17.1231s	
16627/22300 (epoch 37.280), train_loss = 0.32022758, grad/param norm = 2.1025e-01, time/batch = 16.0192s	
16628/22300 (epoch 37.283), train_loss = 0.25487885, grad/param norm = 1.6162e-01, time/batch = 16.0455s	
16629/22300 (epoch 37.285), train_loss = 0.27741261, grad/param norm = 2.3283e-01, time/batch = 16.6381s	
16630/22300 (epoch 37.287), train_loss = 0.38778696, grad/param norm = 2.3695e-01, time/batch = 16.3961s	
16631/22300 (epoch 37.289), train_loss = 0.37559066, grad/param norm = 2.3937e-01, time/batch = 17.6549s	
16632/22300 (epoch 37.291), train_loss = 0.35146911, grad/param norm = 2.6328e-01, time/batch = 16.8252s	
16633/22300 (epoch 37.294), train_loss = 0.31042947, grad/param norm = 2.0218e-01, time/batch = 16.0503s	
16634/22300 (epoch 37.296), train_loss = 0.35446965, grad/param norm = 2.7205e-01, time/batch = 15.8804s	
16635/22300 (epoch 37.298), train_loss = 0.45171519, grad/param norm = 2.5713e-01, time/batch = 16.6419s	
16636/22300 (epoch 37.300), train_loss = 0.51815338, grad/param norm = 2.9976e-01, time/batch = 15.9642s	
16637/22300 (epoch 37.303), train_loss = 0.39262289, grad/param norm = 2.3711e-01, time/batch = 15.3520s	
16638/22300 (epoch 37.305), train_loss = 0.38068859, grad/param norm = 3.0814e-01, time/batch = 17.1423s	
16639/22300 (epoch 37.307), train_loss = 0.33323366, grad/param norm = 2.8025e-01, time/batch = 16.9012s	
16640/22300 (epoch 37.309), train_loss = 0.28795141, grad/param norm = 1.8380e-01, time/batch = 16.6187s	
16641/22300 (epoch 37.312), train_loss = 0.26511625, grad/param norm = 1.8109e-01, time/batch = 17.8882s	
16642/22300 (epoch 37.314), train_loss = 0.30881732, grad/param norm = 2.5495e-01, time/batch = 16.2370s	
16643/22300 (epoch 37.316), train_loss = 0.30753137, grad/param norm = 2.5086e-01, time/batch = 18.2893s	
16644/22300 (epoch 37.318), train_loss = 0.33771992, grad/param norm = 2.2484e-01, time/batch = 17.0482s	
16645/22300 (epoch 37.321), train_loss = 0.42496283, grad/param norm = 2.5974e-01, time/batch = 16.4064s	
16646/22300 (epoch 37.323), train_loss = 0.29690059, grad/param norm = 2.1572e-01, time/batch = 16.2069s	
16647/22300 (epoch 37.325), train_loss = 0.28017624, grad/param norm = 1.9586e-01, time/batch = 17.1319s	
16648/22300 (epoch 37.327), train_loss = 0.28094328, grad/param norm = 1.5385e-01, time/batch = 15.8946s	
16649/22300 (epoch 37.330), train_loss = 0.29241497, grad/param norm = 2.0595e-01, time/batch = 18.3775s	
16650/22300 (epoch 37.332), train_loss = 0.26766670, grad/param norm = 1.8167e-01, time/batch = 17.5422s	
16651/22300 (epoch 37.334), train_loss = 0.31902038, grad/param norm = 2.4117e-01, time/batch = 15.6879s	
16652/22300 (epoch 37.336), train_loss = 0.32603249, grad/param norm = 2.3505e-01, time/batch = 16.1389s	
16653/22300 (epoch 37.339), train_loss = 0.39655906, grad/param norm = 2.6337e-01, time/batch = 16.7266s	
16654/22300 (epoch 37.341), train_loss = 0.39049260, grad/param norm = 2.3598e-01, time/batch = 16.7987s	
16655/22300 (epoch 37.343), train_loss = 0.42700541, grad/param norm = 2.9564e-01, time/batch = 15.2262s	
16656/22300 (epoch 37.345), train_loss = 0.37575521, grad/param norm = 2.5355e-01, time/batch = 16.6469s	
16657/22300 (epoch 37.348), train_loss = 0.35007360, grad/param norm = 1.9339e-01, time/batch = 16.9809s	
16658/22300 (epoch 37.350), train_loss = 0.27091628, grad/param norm = 1.8921e-01, time/batch = 15.8016s	
16659/22300 (epoch 37.352), train_loss = 0.37567168, grad/param norm = 2.0588e-01, time/batch = 17.1514s	
16660/22300 (epoch 37.354), train_loss = 0.53477421, grad/param norm = 3.0447e-01, time/batch = 16.0597s	
16661/22300 (epoch 37.357), train_loss = 0.47956229, grad/param norm = 2.9203e-01, time/batch = 17.5438s	
16662/22300 (epoch 37.359), train_loss = 0.30830856, grad/param norm = 2.1884e-01, time/batch = 15.2894s	
16663/22300 (epoch 37.361), train_loss = 0.32395844, grad/param norm = 2.4959e-01, time/batch = 16.9745s	
16664/22300 (epoch 37.363), train_loss = 0.41902712, grad/param norm = 2.3525e-01, time/batch = 16.0455s	
16665/22300 (epoch 37.365), train_loss = 0.30548696, grad/param norm = 2.4583e-01, time/batch = 14.9744s	
16666/22300 (epoch 37.368), train_loss = 0.32212710, grad/param norm = 2.6726e-01, time/batch = 17.7223s	
16667/22300 (epoch 37.370), train_loss = 0.33938419, grad/param norm = 2.3543e-01, time/batch = 16.1443s	
16668/22300 (epoch 37.372), train_loss = 0.24313016, grad/param norm = 1.8896e-01, time/batch = 16.4767s	
16669/22300 (epoch 37.374), train_loss = 0.24933962, grad/param norm = 1.7824e-01, time/batch = 15.0684s	
16670/22300 (epoch 37.377), train_loss = 0.34413517, grad/param norm = 2.1004e-01, time/batch = 16.1322s	
16671/22300 (epoch 37.379), train_loss = 0.31015573, grad/param norm = 2.3034e-01, time/batch = 16.2524s	
16672/22300 (epoch 37.381), train_loss = 0.39474163, grad/param norm = 2.2652e-01, time/batch = 17.6303s	
16673/22300 (epoch 37.383), train_loss = 0.31154940, grad/param norm = 2.0259e-01, time/batch = 17.5587s	
16674/22300 (epoch 37.386), train_loss = 0.36481775, grad/param norm = 2.4464e-01, time/batch = 16.0671s	
16675/22300 (epoch 37.388), train_loss = 0.27728784, grad/param norm = 2.2219e-01, time/batch = 17.0626s	
16676/22300 (epoch 37.390), train_loss = 0.32404744, grad/param norm = 3.7020e-01, time/batch = 16.2987s	
16677/22300 (epoch 37.392), train_loss = 0.34093951, grad/param norm = 2.7055e-01, time/batch = 16.9640s	
16678/22300 (epoch 37.395), train_loss = 0.27621058, grad/param norm = 2.0342e-01, time/batch = 16.0763s	
16679/22300 (epoch 37.397), train_loss = 0.19405591, grad/param norm = 1.7073e-01, time/batch = 15.9083s	
16680/22300 (epoch 37.399), train_loss = 0.29227696, grad/param norm = 2.3401e-01, time/batch = 16.3923s	
16681/22300 (epoch 37.401), train_loss = 0.33338850, grad/param norm = 3.0825e-01, time/batch = 15.4074s	
16682/22300 (epoch 37.404), train_loss = 0.35251152, grad/param norm = 2.3286e-01, time/batch = 15.5376s	
16683/22300 (epoch 37.406), train_loss = 0.52454451, grad/param norm = 2.9203e-01, time/batch = 15.1251s	
16684/22300 (epoch 37.408), train_loss = 0.40845307, grad/param norm = 2.9328e-01, time/batch = 15.3859s	
16685/22300 (epoch 37.410), train_loss = 0.44059274, grad/param norm = 2.8056e-01, time/batch = 17.3405s	
16686/22300 (epoch 37.413), train_loss = 0.30736772, grad/param norm = 2.0205e-01, time/batch = 18.5420s	
16687/22300 (epoch 37.415), train_loss = 0.25859891, grad/param norm = 2.5561e-01, time/batch = 15.3884s	
16688/22300 (epoch 37.417), train_loss = 0.36296186, grad/param norm = 2.1646e-01, time/batch = 16.5596s	
16689/22300 (epoch 37.419), train_loss = 0.34064851, grad/param norm = 2.0764e-01, time/batch = 16.9684s	
16690/22300 (epoch 37.422), train_loss = 0.29691411, grad/param norm = 2.1378e-01, time/batch = 16.5545s	
16691/22300 (epoch 37.424), train_loss = 0.34914096, grad/param norm = 2.4724e-01, time/batch = 16.0391s	
16692/22300 (epoch 37.426), train_loss = 0.25101041, grad/param norm = 2.0159e-01, time/batch = 15.9000s	
16693/22300 (epoch 37.428), train_loss = 0.26384946, grad/param norm = 1.8201e-01, time/batch = 17.9671s	
16694/22300 (epoch 37.430), train_loss = 0.32100758, grad/param norm = 2.2799e-01, time/batch = 22.8871s	
16695/22300 (epoch 37.433), train_loss = 0.32115410, grad/param norm = 1.9067e-01, time/batch = 24.9750s	
16696/22300 (epoch 37.435), train_loss = 0.31440635, grad/param norm = 2.3573e-01, time/batch = 16.6504s	
16697/22300 (epoch 37.437), train_loss = 0.36914911, grad/param norm = 2.8124e-01, time/batch = 15.8857s	
16698/22300 (epoch 37.439), train_loss = 0.40166564, grad/param norm = 2.8074e-01, time/batch = 16.8082s	
16699/22300 (epoch 37.442), train_loss = 0.35979543, grad/param norm = 2.1376e-01, time/batch = 16.8072s	
16700/22300 (epoch 37.444), train_loss = 0.28760986, grad/param norm = 1.9763e-01, time/batch = 17.7919s	
16701/22300 (epoch 37.446), train_loss = 0.32454945, grad/param norm = 2.1114e-01, time/batch = 15.6638s	
16702/22300 (epoch 37.448), train_loss = 0.23796755, grad/param norm = 1.7062e-01, time/batch = 18.1247s	
16703/22300 (epoch 37.451), train_loss = 0.39037084, grad/param norm = 2.9662e-01, time/batch = 17.1392s	
16704/22300 (epoch 37.453), train_loss = 0.30117491, grad/param norm = 2.4086e-01, time/batch = 15.7758s	
16705/22300 (epoch 37.455), train_loss = 0.42772004, grad/param norm = 2.9647e-01, time/batch = 16.9671s	
16706/22300 (epoch 37.457), train_loss = 0.53856352, grad/param norm = 3.2033e-01, time/batch = 16.8054s	
16707/22300 (epoch 37.460), train_loss = 0.45440263, grad/param norm = 2.8293e-01, time/batch = 16.4679s	
16708/22300 (epoch 37.462), train_loss = 0.45954786, grad/param norm = 2.7896e-01, time/batch = 15.3701s	
16709/22300 (epoch 37.464), train_loss = 0.39680571, grad/param norm = 2.7173e-01, time/batch = 17.2152s	
16710/22300 (epoch 37.466), train_loss = 0.34861039, grad/param norm = 2.5385e-01, time/batch = 17.6265s	
16711/22300 (epoch 37.469), train_loss = 0.31010131, grad/param norm = 2.0793e-01, time/batch = 16.4466s	
16712/22300 (epoch 37.471), train_loss = 0.43327591, grad/param norm = 2.5053e-01, time/batch = 15.4566s	
16713/22300 (epoch 37.473), train_loss = 0.37297245, grad/param norm = 2.2553e-01, time/batch = 16.1506s	
16714/22300 (epoch 37.475), train_loss = 0.32328277, grad/param norm = 2.4149e-01, time/batch = 18.0649s	
16715/22300 (epoch 37.478), train_loss = 0.32002162, grad/param norm = 2.2411e-01, time/batch = 15.2299s	
16716/22300 (epoch 37.480), train_loss = 0.24817688, grad/param norm = 2.1333e-01, time/batch = 16.1178s	
16717/22300 (epoch 37.482), train_loss = 0.28006239, grad/param norm = 1.9101e-01, time/batch = 16.0580s	
16718/22300 (epoch 37.484), train_loss = 0.36188276, grad/param norm = 2.3567e-01, time/batch = 17.7139s	
16719/22300 (epoch 37.487), train_loss = 0.41760862, grad/param norm = 2.2335e-01, time/batch = 14.4744s	
16720/22300 (epoch 37.489), train_loss = 0.44131925, grad/param norm = 3.0979e-01, time/batch = 18.8751s	
16721/22300 (epoch 37.491), train_loss = 0.44073117, grad/param norm = 2.8238e-01, time/batch = 17.2178s	
16722/22300 (epoch 37.493), train_loss = 0.33793981, grad/param norm = 3.5678e-01, time/batch = 16.3756s	
16723/22300 (epoch 37.496), train_loss = 0.36635798, grad/param norm = 2.3815e-01, time/batch = 16.1749s	
16724/22300 (epoch 37.498), train_loss = 0.24832081, grad/param norm = 1.6184e-01, time/batch = 15.9571s	
16725/22300 (epoch 37.500), train_loss = 0.34954995, grad/param norm = 2.1489e-01, time/batch = 17.4745s	
16726/22300 (epoch 37.502), train_loss = 0.22938842, grad/param norm = 2.0199e-01, time/batch = 14.8118s	
16727/22300 (epoch 37.504), train_loss = 0.24110395, grad/param norm = 1.6755e-01, time/batch = 19.2102s	
16728/22300 (epoch 37.507), train_loss = 0.28136732, grad/param norm = 2.0059e-01, time/batch = 16.5687s	
16729/22300 (epoch 37.509), train_loss = 0.41656953, grad/param norm = 2.5872e-01, time/batch = 15.9459s	
16730/22300 (epoch 37.511), train_loss = 0.23277120, grad/param norm = 2.0455e-01, time/batch = 16.5286s	
16731/22300 (epoch 37.513), train_loss = 0.26832784, grad/param norm = 2.2694e-01, time/batch = 16.8564s	
16732/22300 (epoch 37.516), train_loss = 0.30017515, grad/param norm = 2.2374e-01, time/batch = 17.4557s	
16733/22300 (epoch 37.518), train_loss = 0.37810356, grad/param norm = 2.8611e-01, time/batch = 15.4435s	
16734/22300 (epoch 37.520), train_loss = 0.31928342, grad/param norm = 2.5364e-01, time/batch = 16.4790s	
16735/22300 (epoch 37.522), train_loss = 0.34449801, grad/param norm = 2.6659e-01, time/batch = 15.5502s	
16736/22300 (epoch 37.525), train_loss = 0.25946369, grad/param norm = 2.0070e-01, time/batch = 18.6184s	
16737/22300 (epoch 37.527), train_loss = 0.40675273, grad/param norm = 3.0115e-01, time/batch = 16.3954s	
16738/22300 (epoch 37.529), train_loss = 0.36386075, grad/param norm = 2.3763e-01, time/batch = 16.3751s	
16739/22300 (epoch 37.531), train_loss = 0.31487891, grad/param norm = 2.3995e-01, time/batch = 17.7146s	
16740/22300 (epoch 37.534), train_loss = 0.34652780, grad/param norm = 2.6123e-01, time/batch = 15.3092s	
16741/22300 (epoch 37.536), train_loss = 0.49661074, grad/param norm = 2.8382e-01, time/batch = 16.9696s	
16742/22300 (epoch 37.538), train_loss = 0.62923590, grad/param norm = 3.2654e-01, time/batch = 16.5484s	
16743/22300 (epoch 37.540), train_loss = 0.37617336, grad/param norm = 2.3743e-01, time/batch = 16.8085s	
16744/22300 (epoch 37.543), train_loss = 0.34498147, grad/param norm = 3.0572e-01, time/batch = 15.4742s	
16745/22300 (epoch 37.545), train_loss = 0.25194942, grad/param norm = 2.0083e-01, time/batch = 15.7910s	
16746/22300 (epoch 37.547), train_loss = 0.21832409, grad/param norm = 1.9321e-01, time/batch = 15.5364s	
16747/22300 (epoch 37.549), train_loss = 0.26243735, grad/param norm = 2.0376e-01, time/batch = 17.9388s	
16748/22300 (epoch 37.552), train_loss = 0.27840801, grad/param norm = 2.4179e-01, time/batch = 4.2552s	
16749/22300 (epoch 37.554), train_loss = 0.39171728, grad/param norm = 2.4594e-01, time/batch = 0.6663s	
16750/22300 (epoch 37.556), train_loss = 0.54107811, grad/param norm = 3.6490e-01, time/batch = 0.6582s	
16751/22300 (epoch 37.558), train_loss = 0.38813903, grad/param norm = 2.9552e-01, time/batch = 0.6590s	
16752/22300 (epoch 37.561), train_loss = 0.53659498, grad/param norm = 2.7791e-01, time/batch = 0.6588s	
16753/22300 (epoch 37.563), train_loss = 0.44517112, grad/param norm = 2.9933e-01, time/batch = 0.6663s	
16754/22300 (epoch 37.565), train_loss = 0.34508768, grad/param norm = 2.6884e-01, time/batch = 0.6585s	
16755/22300 (epoch 37.567), train_loss = 0.33409306, grad/param norm = 2.0700e-01, time/batch = 0.7447s	
16756/22300 (epoch 37.570), train_loss = 0.48203860, grad/param norm = 3.4212e-01, time/batch = 0.9659s	
16757/22300 (epoch 37.572), train_loss = 0.48468085, grad/param norm = 3.3207e-01, time/batch = 0.9567s	
16758/22300 (epoch 37.574), train_loss = 0.35830430, grad/param norm = 2.6715e-01, time/batch = 0.9616s	
16759/22300 (epoch 37.576), train_loss = 0.33280080, grad/param norm = 2.3656e-01, time/batch = 0.9648s	
16760/22300 (epoch 37.578), train_loss = 0.19900842, grad/param norm = 1.8243e-01, time/batch = 1.0274s	
16761/22300 (epoch 37.581), train_loss = 0.26934852, grad/param norm = 2.1089e-01, time/batch = 1.8528s	
16762/22300 (epoch 37.583), train_loss = 0.32582188, grad/param norm = 2.1445e-01, time/batch = 1.8531s	
16763/22300 (epoch 37.585), train_loss = 0.43817972, grad/param norm = 3.1437e-01, time/batch = 8.2274s	
16764/22300 (epoch 37.587), train_loss = 0.63802491, grad/param norm = 3.4995e-01, time/batch = 15.4948s	
16765/22300 (epoch 37.590), train_loss = 0.52288029, grad/param norm = 3.8586e-01, time/batch = 16.0649s	
16766/22300 (epoch 37.592), train_loss = 0.57616966, grad/param norm = 2.9816e-01, time/batch = 17.6257s	
16767/22300 (epoch 37.594), train_loss = 0.55319844, grad/param norm = 3.1487e-01, time/batch = 17.7211s	
16768/22300 (epoch 37.596), train_loss = 0.35197292, grad/param norm = 2.4035e-01, time/batch = 17.3055s	
16769/22300 (epoch 37.599), train_loss = 0.26275969, grad/param norm = 2.7913e-01, time/batch = 15.4722s	
16770/22300 (epoch 37.601), train_loss = 0.31848921, grad/param norm = 2.7639e-01, time/batch = 14.9731s	
16771/22300 (epoch 37.603), train_loss = 0.33858931, grad/param norm = 2.2329e-01, time/batch = 17.0544s	
16772/22300 (epoch 37.605), train_loss = 0.34189322, grad/param norm = 2.3097e-01, time/batch = 17.5526s	
16773/22300 (epoch 37.608), train_loss = 0.56187819, grad/param norm = 3.2044e-01, time/batch = 15.2428s	
16774/22300 (epoch 37.610), train_loss = 0.61113320, grad/param norm = 2.9195e-01, time/batch = 15.0458s	
16775/22300 (epoch 37.612), train_loss = 0.42158771, grad/param norm = 2.5724e-01, time/batch = 17.8160s	
16776/22300 (epoch 37.614), train_loss = 0.44999686, grad/param norm = 4.9390e-01, time/batch = 15.5909s	
16777/22300 (epoch 37.617), train_loss = 0.46366554, grad/param norm = 2.9336e-01, time/batch = 16.7838s	
16778/22300 (epoch 37.619), train_loss = 0.48675877, grad/param norm = 3.2768e-01, time/batch = 17.4744s	
16779/22300 (epoch 37.621), train_loss = 0.34187843, grad/param norm = 2.8518e-01, time/batch = 19.0406s	
16780/22300 (epoch 37.623), train_loss = 0.34441581, grad/param norm = 2.3650e-01, time/batch = 16.0368s	
16781/22300 (epoch 37.626), train_loss = 0.32892241, grad/param norm = 2.3569e-01, time/batch = 17.7967s	
16782/22300 (epoch 37.628), train_loss = 0.33051562, grad/param norm = 2.0830e-01, time/batch = 15.3256s	
16783/22300 (epoch 37.630), train_loss = 0.37904789, grad/param norm = 2.2343e-01, time/batch = 17.2099s	
16784/22300 (epoch 37.632), train_loss = 0.31502571, grad/param norm = 2.4701e-01, time/batch = 16.7112s	
16785/22300 (epoch 37.635), train_loss = 0.36890421, grad/param norm = 2.2784e-01, time/batch = 18.7192s	
16786/22300 (epoch 37.637), train_loss = 0.41477686, grad/param norm = 2.7550e-01, time/batch = 19.3734s	
16787/22300 (epoch 37.639), train_loss = 0.49266926, grad/param norm = 3.0267e-01, time/batch = 17.3633s	
16788/22300 (epoch 37.641), train_loss = 0.39263695, grad/param norm = 2.5163e-01, time/batch = 17.4868s	
16789/22300 (epoch 37.643), train_loss = 0.32444603, grad/param norm = 3.3794e-01, time/batch = 15.6212s	
16790/22300 (epoch 37.646), train_loss = 0.29867291, grad/param norm = 1.9869e-01, time/batch = 15.3457s	
16791/22300 (epoch 37.648), train_loss = 0.40618807, grad/param norm = 2.0342e-01, time/batch = 16.2161s	
16792/22300 (epoch 37.650), train_loss = 0.42276597, grad/param norm = 2.8334e-01, time/batch = 16.3610s	
16793/22300 (epoch 37.652), train_loss = 0.35479167, grad/param norm = 2.5922e-01, time/batch = 14.5679s	
16794/22300 (epoch 37.655), train_loss = 0.27874830, grad/param norm = 2.0386e-01, time/batch = 15.3728s	
16795/22300 (epoch 37.657), train_loss = 0.31375190, grad/param norm = 2.2495e-01, time/batch = 16.6966s	
16796/22300 (epoch 37.659), train_loss = 0.31651222, grad/param norm = 2.4402e-01, time/batch = 17.4618s	
16797/22300 (epoch 37.661), train_loss = 0.24820857, grad/param norm = 1.9223e-01, time/batch = 18.9373s	
16798/22300 (epoch 37.664), train_loss = 0.33569242, grad/param norm = 3.5002e-01, time/batch = 17.0522s	
16799/22300 (epoch 37.666), train_loss = 0.42580013, grad/param norm = 2.7514e-01, time/batch = 16.0763s	
16800/22300 (epoch 37.668), train_loss = 0.31353292, grad/param norm = 2.6543e-01, time/batch = 16.3259s	
16801/22300 (epoch 37.670), train_loss = 0.39452391, grad/param norm = 2.8525e-01, time/batch = 16.0496s	
16802/22300 (epoch 37.673), train_loss = 0.45398064, grad/param norm = 2.8301e-01, time/batch = 18.0424s	
16803/22300 (epoch 37.675), train_loss = 0.48446181, grad/param norm = 2.9928e-01, time/batch = 15.5464s	
16804/22300 (epoch 37.677), train_loss = 0.56167712, grad/param norm = 3.1045e-01, time/batch = 18.0232s	
16805/22300 (epoch 37.679), train_loss = 0.39649843, grad/param norm = 3.0421e-01, time/batch = 16.1408s	
16806/22300 (epoch 37.682), train_loss = 0.35476361, grad/param norm = 2.3326e-01, time/batch = 16.6443s	
16807/22300 (epoch 37.684), train_loss = 0.35165842, grad/param norm = 2.4047e-01, time/batch = 17.0483s	
16808/22300 (epoch 37.686), train_loss = 0.33264200, grad/param norm = 2.3345e-01, time/batch = 16.9656s	
16809/22300 (epoch 37.688), train_loss = 0.33926374, grad/param norm = 3.4843e-01, time/batch = 16.5616s	
16810/22300 (epoch 37.691), train_loss = 0.29418073, grad/param norm = 2.5632e-01, time/batch = 16.9549s	
16811/22300 (epoch 37.693), train_loss = 0.28171139, grad/param norm = 2.0114e-01, time/batch = 14.9816s	
16812/22300 (epoch 37.695), train_loss = 0.30849239, grad/param norm = 2.2579e-01, time/batch = 15.4652s	
16813/22300 (epoch 37.697), train_loss = 0.32931716, grad/param norm = 2.0955e-01, time/batch = 17.1268s	
16814/22300 (epoch 37.700), train_loss = 0.29347570, grad/param norm = 2.1767e-01, time/batch = 17.4510s	
16815/22300 (epoch 37.702), train_loss = 0.25223029, grad/param norm = 1.9018e-01, time/batch = 16.6148s	
16816/22300 (epoch 37.704), train_loss = 0.34363115, grad/param norm = 3.1116e-01, time/batch = 15.0571s	
16817/22300 (epoch 37.706), train_loss = 0.32212840, grad/param norm = 2.2745e-01, time/batch = 17.4630s	
16818/22300 (epoch 37.709), train_loss = 0.24346340, grad/param norm = 1.9741e-01, time/batch = 18.8849s	
16819/22300 (epoch 37.711), train_loss = 0.24965143, grad/param norm = 1.7082e-01, time/batch = 14.7345s	
16820/22300 (epoch 37.713), train_loss = 0.36272480, grad/param norm = 2.4425e-01, time/batch = 16.0677s	
16821/22300 (epoch 37.715), train_loss = 0.36858003, grad/param norm = 2.2511e-01, time/batch = 19.2045s	
16822/22300 (epoch 37.717), train_loss = 0.50818242, grad/param norm = 2.8866e-01, time/batch = 16.9376s	
16823/22300 (epoch 37.720), train_loss = 0.31418762, grad/param norm = 2.3212e-01, time/batch = 16.2601s	
16824/22300 (epoch 37.722), train_loss = 0.36306176, grad/param norm = 2.4059e-01, time/batch = 17.3042s	
16825/22300 (epoch 37.724), train_loss = 0.41719804, grad/param norm = 3.9486e-01, time/batch = 18.4699s	
16826/22300 (epoch 37.726), train_loss = 0.32206013, grad/param norm = 2.6379e-01, time/batch = 15.8921s	
16827/22300 (epoch 37.729), train_loss = 0.37685283, grad/param norm = 2.4344e-01, time/batch = 15.1379s	
16828/22300 (epoch 37.731), train_loss = 0.45765051, grad/param norm = 3.0403e-01, time/batch = 16.7791s	
16829/22300 (epoch 37.733), train_loss = 0.45852142, grad/param norm = 2.9009e-01, time/batch = 18.1316s	
16830/22300 (epoch 37.735), train_loss = 0.49332707, grad/param norm = 2.9516e-01, time/batch = 17.3871s	
16831/22300 (epoch 37.738), train_loss = 0.35658018, grad/param norm = 3.0966e-01, time/batch = 17.7135s	
16832/22300 (epoch 37.740), train_loss = 0.32493973, grad/param norm = 2.1533e-01, time/batch = 16.7273s	
16833/22300 (epoch 37.742), train_loss = 0.30218631, grad/param norm = 2.1464e-01, time/batch = 15.6261s	
16834/22300 (epoch 37.744), train_loss = 0.53425549, grad/param norm = 2.8185e-01, time/batch = 15.6515s	
16835/22300 (epoch 37.747), train_loss = 0.42696560, grad/param norm = 2.3527e-01, time/batch = 16.3172s	
16836/22300 (epoch 37.749), train_loss = 0.53329804, grad/param norm = 3.1715e-01, time/batch = 17.0751s	
16837/22300 (epoch 37.751), train_loss = 0.45862940, grad/param norm = 3.2405e-01, time/batch = 15.1152s	
16838/22300 (epoch 37.753), train_loss = 0.49489226, grad/param norm = 3.3694e-01, time/batch = 17.2917s	
16839/22300 (epoch 37.756), train_loss = 0.46078866, grad/param norm = 2.5384e-01, time/batch = 17.7147s	
16840/22300 (epoch 37.758), train_loss = 0.40134132, grad/param norm = 2.7369e-01, time/batch = 16.4842s	
16841/22300 (epoch 37.760), train_loss = 0.42763958, grad/param norm = 2.6265e-01, time/batch = 16.2318s	
16842/22300 (epoch 37.762), train_loss = 0.38835958, grad/param norm = 2.5153e-01, time/batch = 18.0438s	
16843/22300 (epoch 37.765), train_loss = 0.41049727, grad/param norm = 2.5811e-01, time/batch = 16.2977s	
16844/22300 (epoch 37.767), train_loss = 0.38641063, grad/param norm = 2.2571e-01, time/batch = 15.5207s	
16845/22300 (epoch 37.769), train_loss = 0.39460537, grad/param norm = 3.2200e-01, time/batch = 15.4759s	
16846/22300 (epoch 37.771), train_loss = 0.45051684, grad/param norm = 3.4625e-01, time/batch = 17.1351s	
16847/22300 (epoch 37.774), train_loss = 0.48174367, grad/param norm = 3.3971e-01, time/batch = 17.2200s	
16848/22300 (epoch 37.776), train_loss = 0.52175728, grad/param norm = 2.9258e-01, time/batch = 15.6387s	
16849/22300 (epoch 37.778), train_loss = 0.48604358, grad/param norm = 2.8592e-01, time/batch = 17.6277s	
16850/22300 (epoch 37.780), train_loss = 0.47542356, grad/param norm = 2.9735e-01, time/batch = 18.2095s	
16851/22300 (epoch 37.783), train_loss = 0.52741922, grad/param norm = 2.7802e-01, time/batch = 15.5103s	
16852/22300 (epoch 37.785), train_loss = 0.36300770, grad/param norm = 2.6750e-01, time/batch = 16.3089s	
16853/22300 (epoch 37.787), train_loss = 0.37899020, grad/param norm = 2.5605e-01, time/batch = 15.8118s	
16854/22300 (epoch 37.789), train_loss = 0.53457051, grad/param norm = 3.4767e-01, time/batch = 15.5782s	
16855/22300 (epoch 37.791), train_loss = 0.61534661, grad/param norm = 2.8248e-01, time/batch = 15.1329s	
16856/22300 (epoch 37.794), train_loss = 0.51709043, grad/param norm = 3.5658e-01, time/batch = 16.8666s	
16857/22300 (epoch 37.796), train_loss = 0.46277786, grad/param norm = 3.4825e-01, time/batch = 17.6319s	
16858/22300 (epoch 37.798), train_loss = 0.61223974, grad/param norm = 3.2768e-01, time/batch = 17.1486s	
16859/22300 (epoch 37.800), train_loss = 0.41927953, grad/param norm = 2.8178e-01, time/batch = 18.1319s	
16860/22300 (epoch 37.803), train_loss = 0.37433709, grad/param norm = 2.4016e-01, time/batch = 18.1233s	
16861/22300 (epoch 37.805), train_loss = 0.44052371, grad/param norm = 2.8979e-01, time/batch = 17.2088s	
16862/22300 (epoch 37.807), train_loss = 0.55763555, grad/param norm = 3.4128e-01, time/batch = 15.6001s	
16863/22300 (epoch 37.809), train_loss = 0.41721313, grad/param norm = 3.2391e-01, time/batch = 16.2948s	
16864/22300 (epoch 37.812), train_loss = 0.45208743, grad/param norm = 3.0451e-01, time/batch = 19.2070s	
16865/22300 (epoch 37.814), train_loss = 0.44845111, grad/param norm = 3.3750e-01, time/batch = 16.0412s	
16866/22300 (epoch 37.816), train_loss = 0.46848771, grad/param norm = 3.0335e-01, time/batch = 17.7140s	
16867/22300 (epoch 37.818), train_loss = 0.51885825, grad/param norm = 3.3836e-01, time/batch = 17.7203s	
16868/22300 (epoch 37.821), train_loss = 0.45738313, grad/param norm = 2.7325e-01, time/batch = 18.3059s	
16869/22300 (epoch 37.823), train_loss = 0.30432687, grad/param norm = 2.4833e-01, time/batch = 16.5522s	
16870/22300 (epoch 37.825), train_loss = 0.30893918, grad/param norm = 2.1573e-01, time/batch = 17.2066s	
16871/22300 (epoch 37.827), train_loss = 0.37665344, grad/param norm = 2.9291e-01, time/batch = 16.4511s	
16872/22300 (epoch 37.830), train_loss = 0.36115863, grad/param norm = 2.4513e-01, time/batch = 15.6134s	
16873/22300 (epoch 37.832), train_loss = 0.35964593, grad/param norm = 2.5850e-01, time/batch = 15.8535s	
16874/22300 (epoch 37.834), train_loss = 0.29664597, grad/param norm = 2.2604e-01, time/batch = 17.1423s	
16875/22300 (epoch 37.836), train_loss = 0.35140411, grad/param norm = 2.3019e-01, time/batch = 17.4619s	
16876/22300 (epoch 37.839), train_loss = 0.38748111, grad/param norm = 2.5607e-01, time/batch = 15.3952s	
16877/22300 (epoch 37.841), train_loss = 0.37511272, grad/param norm = 3.8249e-01, time/batch = 16.7996s	
16878/22300 (epoch 37.843), train_loss = 0.38367201, grad/param norm = 2.5690e-01, time/batch = 16.3153s	
16879/22300 (epoch 37.845), train_loss = 0.38639612, grad/param norm = 2.6273e-01, time/batch = 17.9588s	
16880/22300 (epoch 37.848), train_loss = 0.38752010, grad/param norm = 3.3259e-01, time/batch = 15.8839s	
16881/22300 (epoch 37.850), train_loss = 0.39026069, grad/param norm = 2.2395e-01, time/batch = 16.2500s	
16882/22300 (epoch 37.852), train_loss = 0.34921948, grad/param norm = 2.7095e-01, time/batch = 18.7919s	
16883/22300 (epoch 37.854), train_loss = 0.58166754, grad/param norm = 3.7023e-01, time/batch = 15.4787s	
16884/22300 (epoch 37.857), train_loss = 0.43471919, grad/param norm = 3.0766e-01, time/batch = 16.8919s	
16885/22300 (epoch 37.859), train_loss = 0.33683376, grad/param norm = 2.0616e-01, time/batch = 16.4000s	
16886/22300 (epoch 37.861), train_loss = 0.45799603, grad/param norm = 2.9158e-01, time/batch = 17.7195s	
16887/22300 (epoch 37.863), train_loss = 0.30699000, grad/param norm = 2.2236e-01, time/batch = 15.6317s	
16888/22300 (epoch 37.865), train_loss = 0.30033281, grad/param norm = 2.0694e-01, time/batch = 15.7445s	
16889/22300 (epoch 37.868), train_loss = 0.41297913, grad/param norm = 2.3691e-01, time/batch = 15.7336s	
16890/22300 (epoch 37.870), train_loss = 0.40372306, grad/param norm = 2.4540e-01, time/batch = 16.5578s	
16891/22300 (epoch 37.872), train_loss = 0.50685194, grad/param norm = 2.7147e-01, time/batch = 15.8910s	
16892/22300 (epoch 37.874), train_loss = 0.41944280, grad/param norm = 2.5927e-01, time/batch = 17.4935s	
16893/22300 (epoch 37.877), train_loss = 0.38284856, grad/param norm = 2.4615e-01, time/batch = 16.5663s	
16894/22300 (epoch 37.879), train_loss = 0.35731986, grad/param norm = 2.0369e-01, time/batch = 15.0944s	
16895/22300 (epoch 37.881), train_loss = 0.30672186, grad/param norm = 2.4590e-01, time/batch = 16.4769s	
16896/22300 (epoch 37.883), train_loss = 0.31776141, grad/param norm = 2.0056e-01, time/batch = 17.5539s	
16897/22300 (epoch 37.886), train_loss = 0.29448003, grad/param norm = 2.6211e-01, time/batch = 18.0357s	
16898/22300 (epoch 37.888), train_loss = 0.34293648, grad/param norm = 2.4420e-01, time/batch = 16.3634s	
16899/22300 (epoch 37.890), train_loss = 0.33880459, grad/param norm = 1.8687e-01, time/batch = 16.2246s	
16900/22300 (epoch 37.892), train_loss = 0.51567112, grad/param norm = 2.5909e-01, time/batch = 18.2120s	
16901/22300 (epoch 37.895), train_loss = 0.48125712, grad/param norm = 3.1740e-01, time/batch = 15.7048s	
16902/22300 (epoch 37.897), train_loss = 0.35781473, grad/param norm = 2.3818e-01, time/batch = 18.6204s	
16903/22300 (epoch 37.899), train_loss = 0.37560069, grad/param norm = 2.5157e-01, time/batch = 17.1981s	
16904/22300 (epoch 37.901), train_loss = 0.42281298, grad/param norm = 2.1934e-01, time/batch = 17.2965s	
16905/22300 (epoch 37.904), train_loss = 0.45282812, grad/param norm = 3.0143e-01, time/batch = 15.3001s	
16906/22300 (epoch 37.906), train_loss = 0.41743217, grad/param norm = 2.7273e-01, time/batch = 15.7943s	
16907/22300 (epoch 37.908), train_loss = 0.37601992, grad/param norm = 2.0246e-01, time/batch = 16.4728s	
16908/22300 (epoch 37.910), train_loss = 0.34197253, grad/param norm = 2.1095e-01, time/batch = 16.3844s	
16909/22300 (epoch 37.913), train_loss = 0.42248063, grad/param norm = 2.5144e-01, time/batch = 14.0074s	
16910/22300 (epoch 37.915), train_loss = 0.53048511, grad/param norm = 2.9248e-01, time/batch = 16.8824s	
16911/22300 (epoch 37.917), train_loss = 0.44899884, grad/param norm = 2.6661e-01, time/batch = 18.8780s	
16912/22300 (epoch 37.919), train_loss = 0.41450915, grad/param norm = 2.2513e-01, time/batch = 16.2929s	
16913/22300 (epoch 37.922), train_loss = 0.39160390, grad/param norm = 2.2291e-01, time/batch = 17.1397s	
16914/22300 (epoch 37.924), train_loss = 0.26627899, grad/param norm = 2.1004e-01, time/batch = 15.6368s	
16915/22300 (epoch 37.926), train_loss = 0.33190396, grad/param norm = 2.3300e-01, time/batch = 15.3620s	
16916/22300 (epoch 37.928), train_loss = 0.34880177, grad/param norm = 2.4186e-01, time/batch = 17.1855s	
16917/22300 (epoch 37.930), train_loss = 0.34489280, grad/param norm = 2.6920e-01, time/batch = 15.0585s	
16918/22300 (epoch 37.933), train_loss = 0.43200050, grad/param norm = 2.9836e-01, time/batch = 16.8047s	
16919/22300 (epoch 37.935), train_loss = 0.40970563, grad/param norm = 3.3454e-01, time/batch = 15.8772s	
16920/22300 (epoch 37.937), train_loss = 0.48824582, grad/param norm = 3.1627e-01, time/batch = 17.6240s	
16921/22300 (epoch 37.939), train_loss = 0.43667369, grad/param norm = 2.8713e-01, time/batch = 18.3044s	
16922/22300 (epoch 37.942), train_loss = 0.55826246, grad/param norm = 3.4045e-01, time/batch = 17.4549s	
16923/22300 (epoch 37.944), train_loss = 0.59484351, grad/param norm = 3.4395e-01, time/batch = 30.7211s	
16924/22300 (epoch 37.946), train_loss = 0.42259758, grad/param norm = 2.5487e-01, time/batch = 16.8894s	
16925/22300 (epoch 37.948), train_loss = 0.36159624, grad/param norm = 2.0220e-01, time/batch = 15.2126s	
16926/22300 (epoch 37.951), train_loss = 0.30143826, grad/param norm = 2.4064e-01, time/batch = 15.9732s	
16927/22300 (epoch 37.953), train_loss = 0.34080897, grad/param norm = 2.9383e-01, time/batch = 16.5496s	
16928/22300 (epoch 37.955), train_loss = 0.50500344, grad/param norm = 2.8799e-01, time/batch = 16.3907s	
16929/22300 (epoch 37.957), train_loss = 0.60867128, grad/param norm = 3.6836e-01, time/batch = 16.4829s	
16930/22300 (epoch 37.960), train_loss = 0.53386703, grad/param norm = 3.0690e-01, time/batch = 17.4612s	
16931/22300 (epoch 37.962), train_loss = 0.30814402, grad/param norm = 2.6494e-01, time/batch = 16.7622s	
16932/22300 (epoch 37.964), train_loss = 0.34049820, grad/param norm = 2.4218e-01, time/batch = 16.8847s	
16933/22300 (epoch 37.966), train_loss = 0.34463582, grad/param norm = 2.5923e-01, time/batch = 16.5545s	
16934/22300 (epoch 37.969), train_loss = 0.36117271, grad/param norm = 2.0796e-01, time/batch = 15.1356s	
16935/22300 (epoch 37.971), train_loss = 0.39141902, grad/param norm = 2.2055e-01, time/batch = 16.1478s	
16936/22300 (epoch 37.973), train_loss = 0.39647213, grad/param norm = 3.5375e-01, time/batch = 16.8111s	
16937/22300 (epoch 37.975), train_loss = 0.55437834, grad/param norm = 4.0824e-01, time/batch = 17.7044s	
16938/22300 (epoch 37.978), train_loss = 0.50116147, grad/param norm = 2.8149e-01, time/batch = 17.7361s	
16939/22300 (epoch 37.980), train_loss = 0.59236313, grad/param norm = 3.4820e-01, time/batch = 18.1301s	
16940/22300 (epoch 37.982), train_loss = 0.31541043, grad/param norm = 2.4866e-01, time/batch = 18.1999s	
16941/22300 (epoch 37.984), train_loss = 0.38934356, grad/param norm = 2.5154e-01, time/batch = 16.8886s	
16942/22300 (epoch 37.987), train_loss = 0.39699420, grad/param norm = 2.8832e-01, time/batch = 17.3921s	
16943/22300 (epoch 37.989), train_loss = 0.30223879, grad/param norm = 2.3445e-01, time/batch = 15.9715s	
16944/22300 (epoch 37.991), train_loss = 0.59394735, grad/param norm = 3.4949e-01, time/batch = 17.1929s	
16945/22300 (epoch 37.993), train_loss = 0.78688589, grad/param norm = 3.9454e-01, time/batch = 17.6214s	
16946/22300 (epoch 37.996), train_loss = 0.70502924, grad/param norm = 3.4586e-01, time/batch = 17.1414s	
16947/22300 (epoch 37.998), train_loss = 0.43671016, grad/param norm = 2.6587e-01, time/batch = 15.7315s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
16948/22300 (epoch 38.000), train_loss = 0.35561615, grad/param norm = 2.7187e-01, time/batch = 17.1315s	
16949/22300 (epoch 38.002), train_loss = 0.70640714, grad/param norm = 3.1548e-01, time/batch = 16.6334s	
16950/22300 (epoch 38.004), train_loss = 0.46587451, grad/param norm = 2.6219e-01, time/batch = 16.9618s	
16951/22300 (epoch 38.007), train_loss = 0.50599096, grad/param norm = 3.0632e-01, time/batch = 15.4056s	
16952/22300 (epoch 38.009), train_loss = 0.49797699, grad/param norm = 3.3003e-01, time/batch = 16.1382s	
16953/22300 (epoch 38.011), train_loss = 0.59835924, grad/param norm = 4.0785e-01, time/batch = 17.3421s	
16954/22300 (epoch 38.013), train_loss = 0.49040262, grad/param norm = 2.8875e-01, time/batch = 15.0576s	
16955/22300 (epoch 38.016), train_loss = 0.36468164, grad/param norm = 2.8278e-01, time/batch = 15.4889s	
16956/22300 (epoch 38.018), train_loss = 0.40297593, grad/param norm = 2.8476e-01, time/batch = 17.0428s	
16957/22300 (epoch 38.020), train_loss = 0.39312193, grad/param norm = 2.7336e-01, time/batch = 16.0507s	
16958/22300 (epoch 38.022), train_loss = 0.31343694, grad/param norm = 2.6260e-01, time/batch = 15.8331s	
16959/22300 (epoch 38.025), train_loss = 0.34427372, grad/param norm = 2.2406e-01, time/batch = 16.0244s	
16960/22300 (epoch 38.027), train_loss = 0.32957654, grad/param norm = 2.0454e-01, time/batch = 15.0070s	
16961/22300 (epoch 38.029), train_loss = 0.36814371, grad/param norm = 2.6837e-01, time/batch = 14.7511s	
16962/22300 (epoch 38.031), train_loss = 0.34274852, grad/param norm = 2.0362e-01, time/batch = 15.7180s	
16963/22300 (epoch 38.034), train_loss = 0.33679064, grad/param norm = 2.3310e-01, time/batch = 17.7172s	
16964/22300 (epoch 38.036), train_loss = 0.31374100, grad/param norm = 1.8434e-01, time/batch = 15.4604s	
16965/22300 (epoch 38.038), train_loss = 0.30243571, grad/param norm = 3.0388e-01, time/batch = 16.6483s	
16966/22300 (epoch 38.040), train_loss = 0.36979343, grad/param norm = 3.4397e-01, time/batch = 14.6617s	
16967/22300 (epoch 38.043), train_loss = 0.56567094, grad/param norm = 3.0690e-01, time/batch = 17.2222s	
16968/22300 (epoch 38.045), train_loss = 0.48513931, grad/param norm = 2.9478e-01, time/batch = 17.7125s	
16969/22300 (epoch 38.047), train_loss = 0.52054629, grad/param norm = 3.3638e-01, time/batch = 16.0225s	
16970/22300 (epoch 38.049), train_loss = 0.40243368, grad/param norm = 2.5991e-01, time/batch = 16.5413s	
16971/22300 (epoch 38.052), train_loss = 0.45663213, grad/param norm = 3.5467e-01, time/batch = 16.8183s	
16972/22300 (epoch 38.054), train_loss = 0.46846875, grad/param norm = 2.9421e-01, time/batch = 15.7094s	
16973/22300 (epoch 38.056), train_loss = 0.23911721, grad/param norm = 2.2270e-01, time/batch = 16.7340s	
16974/22300 (epoch 38.058), train_loss = 0.38195916, grad/param norm = 2.6272e-01, time/batch = 16.7213s	
16975/22300 (epoch 38.061), train_loss = 0.32948733, grad/param norm = 2.2995e-01, time/batch = 16.5645s	
16976/22300 (epoch 38.063), train_loss = 0.53549515, grad/param norm = 3.8966e-01, time/batch = 15.6273s	
16977/22300 (epoch 38.065), train_loss = 0.60599756, grad/param norm = 3.8570e-01, time/batch = 18.2116s	
16978/22300 (epoch 38.067), train_loss = 0.33243493, grad/param norm = 2.4004e-01, time/batch = 17.1426s	
16979/22300 (epoch 38.070), train_loss = 0.38004743, grad/param norm = 2.6176e-01, time/batch = 16.2211s	
16980/22300 (epoch 38.072), train_loss = 0.44079434, grad/param norm = 3.3221e-01, time/batch = 16.4428s	
16981/22300 (epoch 38.074), train_loss = 0.46113525, grad/param norm = 2.9146e-01, time/batch = 18.7950s	
16982/22300 (epoch 38.076), train_loss = 0.42735173, grad/param norm = 2.7877e-01, time/batch = 17.1392s	
16983/22300 (epoch 38.078), train_loss = 0.55183551, grad/param norm = 3.7178e-01, time/batch = 15.8036s	
16984/22300 (epoch 38.081), train_loss = 0.51830788, grad/param norm = 3.2473e-01, time/batch = 17.8974s	
16985/22300 (epoch 38.083), train_loss = 0.59970657, grad/param norm = 3.4237e-01, time/batch = 16.9711s	
16986/22300 (epoch 38.085), train_loss = 0.55076818, grad/param norm = 3.2374e-01, time/batch = 16.4659s	
16987/22300 (epoch 38.087), train_loss = 0.46625421, grad/param norm = 3.0964e-01, time/batch = 15.4770s	
16988/22300 (epoch 38.090), train_loss = 0.42672918, grad/param norm = 2.9484e-01, time/batch = 15.2582s	
16989/22300 (epoch 38.092), train_loss = 0.32381942, grad/param norm = 2.2083e-01, time/batch = 17.9590s	
16990/22300 (epoch 38.094), train_loss = 0.32013939, grad/param norm = 2.4595e-01, time/batch = 15.0561s	
16991/22300 (epoch 38.096), train_loss = 0.58198273, grad/param norm = 3.4014e-01, time/batch = 17.2199s	
16992/22300 (epoch 38.099), train_loss = 0.36305227, grad/param norm = 2.4386e-01, time/batch = 17.6228s	
16993/22300 (epoch 38.101), train_loss = 0.49184465, grad/param norm = 2.9025e-01, time/batch = 18.3010s	
16994/22300 (epoch 38.103), train_loss = 0.41166896, grad/param norm = 2.6120e-01, time/batch = 16.1958s	
16995/22300 (epoch 38.105), train_loss = 0.31596955, grad/param norm = 2.6817e-01, time/batch = 15.2892s	
16996/22300 (epoch 38.108), train_loss = 0.47063870, grad/param norm = 3.0009e-01, time/batch = 16.3941s	
16997/22300 (epoch 38.110), train_loss = 0.53364623, grad/param norm = 2.8482e-01, time/batch = 16.4780s	
16998/22300 (epoch 38.112), train_loss = 0.43992132, grad/param norm = 2.4262e-01, time/batch = 16.1503s	
16999/22300 (epoch 38.114), train_loss = 0.48510127, grad/param norm = 2.7563e-01, time/batch = 17.4598s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch38.12_1.6399.t7	
17000/22300 (epoch 38.117), train_loss = 0.55224893, grad/param norm = 2.7214e-01, time/batch = 18.0577s	
17001/22300 (epoch 38.119), train_loss = 1.46373448, grad/param norm = 5.2944e-01, time/batch = 17.3904s	
17002/22300 (epoch 38.121), train_loss = 0.62037065, grad/param norm = 3.4893e-01, time/batch = 16.7078s	
17003/22300 (epoch 38.123), train_loss = 0.58818927, grad/param norm = 3.1777e-01, time/batch = 15.9794s	
17004/22300 (epoch 38.126), train_loss = 0.47179709, grad/param norm = 2.5806e-01, time/batch = 17.9681s	
17005/22300 (epoch 38.128), train_loss = 0.44748838, grad/param norm = 2.8902e-01, time/batch = 17.3973s	
17006/22300 (epoch 38.130), train_loss = 0.40100441, grad/param norm = 2.4412e-01, time/batch = 14.9733s	
17007/22300 (epoch 38.132), train_loss = 0.28043613, grad/param norm = 2.0539e-01, time/batch = 17.2118s	
17008/22300 (epoch 38.135), train_loss = 0.29261525, grad/param norm = 2.0702e-01, time/batch = 16.3299s	
17009/22300 (epoch 38.137), train_loss = 0.24312351, grad/param norm = 1.7540e-01, time/batch = 17.0463s	
17010/22300 (epoch 38.139), train_loss = 0.36051016, grad/param norm = 2.3809e-01, time/batch = 16.5424s	
17011/22300 (epoch 38.141), train_loss = 0.49666983, grad/param norm = 2.6287e-01, time/batch = 17.4783s	
17012/22300 (epoch 38.143), train_loss = 0.39291219, grad/param norm = 2.2272e-01, time/batch = 16.9512s	
17013/22300 (epoch 38.146), train_loss = 0.51454053, grad/param norm = 3.7266e-01, time/batch = 15.5530s	
17014/22300 (epoch 38.148), train_loss = 0.32595165, grad/param norm = 2.4089e-01, time/batch = 19.1217s	
17015/22300 (epoch 38.150), train_loss = 0.36275543, grad/param norm = 2.4063e-01, time/batch = 16.5629s	
17016/22300 (epoch 38.152), train_loss = 0.32559666, grad/param norm = 2.7002e-01, time/batch = 17.3691s	
17017/22300 (epoch 38.155), train_loss = 0.33053486, grad/param norm = 2.1296e-01, time/batch = 15.3752s	
17018/22300 (epoch 38.157), train_loss = 0.44318281, grad/param norm = 3.2111e-01, time/batch = 15.8792s	
17019/22300 (epoch 38.159), train_loss = 0.44646688, grad/param norm = 3.2651e-01, time/batch = 16.1519s	
17020/22300 (epoch 38.161), train_loss = 0.48242350, grad/param norm = 2.8412e-01, time/batch = 16.0864s	
17021/22300 (epoch 38.164), train_loss = 0.34774158, grad/param norm = 2.9110e-01, time/batch = 16.8990s	
17022/22300 (epoch 38.166), train_loss = 0.29457153, grad/param norm = 2.0775e-01, time/batch = 16.6441s	
17023/22300 (epoch 38.168), train_loss = 0.30431687, grad/param norm = 2.6599e-01, time/batch = 18.2979s	
17024/22300 (epoch 38.170), train_loss = 0.41976573, grad/param norm = 2.4172e-01, time/batch = 15.1447s	
17025/22300 (epoch 38.173), train_loss = 0.47445161, grad/param norm = 3.6748e-01, time/batch = 17.9744s	
17026/22300 (epoch 38.175), train_loss = 0.41328607, grad/param norm = 2.9452e-01, time/batch = 15.7334s	
17027/22300 (epoch 38.177), train_loss = 0.27638779, grad/param norm = 2.2077e-01, time/batch = 15.5593s	
17028/22300 (epoch 38.179), train_loss = 0.42599877, grad/param norm = 2.9037e-01, time/batch = 16.3793s	
17029/22300 (epoch 38.182), train_loss = 0.56853336, grad/param norm = 3.2395e-01, time/batch = 16.8941s	
17030/22300 (epoch 38.184), train_loss = 0.56511397, grad/param norm = 3.2248e-01, time/batch = 18.1322s	
17031/22300 (epoch 38.186), train_loss = 0.43514742, grad/param norm = 2.7117e-01, time/batch = 15.2339s	
17032/22300 (epoch 38.188), train_loss = 0.60024722, grad/param norm = 3.0614e-01, time/batch = 16.0280s	
17033/22300 (epoch 38.191), train_loss = 0.51779597, grad/param norm = 3.2240e-01, time/batch = 16.9030s	
17034/22300 (epoch 38.193), train_loss = 0.44271823, grad/param norm = 2.8068e-01, time/batch = 18.1171s	
17035/22300 (epoch 38.195), train_loss = 0.40084132, grad/param norm = 2.7902e-01, time/batch = 15.7247s	
17036/22300 (epoch 38.197), train_loss = 0.36375939, grad/param norm = 2.1548e-01, time/batch = 16.1341s	
17037/22300 (epoch 38.200), train_loss = 0.34266973, grad/param norm = 2.5874e-01, time/batch = 18.0390s	
17038/22300 (epoch 38.202), train_loss = 0.34998817, grad/param norm = 2.3412e-01, time/batch = 15.7148s	
17039/22300 (epoch 38.204), train_loss = 0.43990580, grad/param norm = 2.5749e-01, time/batch = 18.1277s	
17040/22300 (epoch 38.206), train_loss = 0.33583353, grad/param norm = 2.3982e-01, time/batch = 16.1401s	
17041/22300 (epoch 38.209), train_loss = 0.37173998, grad/param norm = 2.4238e-01, time/batch = 15.2023s	
17042/22300 (epoch 38.211), train_loss = 0.29527862, grad/param norm = 2.0996e-01, time/batch = 16.2919s	
17043/22300 (epoch 38.213), train_loss = 0.41943259, grad/param norm = 2.5289e-01, time/batch = 17.5567s	
17044/22300 (epoch 38.215), train_loss = 0.53268073, grad/param norm = 2.9138e-01, time/batch = 15.6622s	
17045/22300 (epoch 38.217), train_loss = 0.53211082, grad/param norm = 2.7077e-01, time/batch = 17.4540s	
17046/22300 (epoch 38.220), train_loss = 0.37974105, grad/param norm = 2.1924e-01, time/batch = 16.0405s	
17047/22300 (epoch 38.222), train_loss = 0.36950274, grad/param norm = 2.6330e-01, time/batch = 17.6434s	
17048/22300 (epoch 38.224), train_loss = 0.37178227, grad/param norm = 2.6637e-01, time/batch = 17.4016s	
17049/22300 (epoch 38.226), train_loss = 0.39165659, grad/param norm = 2.0462e-01, time/batch = 15.5514s	
17050/22300 (epoch 38.229), train_loss = 0.31988347, grad/param norm = 1.9159e-01, time/batch = 18.7981s	
17051/22300 (epoch 38.231), train_loss = 0.52154737, grad/param norm = 4.8109e-01, time/batch = 17.0448s	
17052/22300 (epoch 38.233), train_loss = 0.43806864, grad/param norm = 2.9240e-01, time/batch = 16.2851s	
17053/22300 (epoch 38.235), train_loss = 0.31937821, grad/param norm = 1.9702e-01, time/batch = 15.5691s	
17054/22300 (epoch 38.238), train_loss = 0.32872805, grad/param norm = 2.3267e-01, time/batch = 15.4577s	
17055/22300 (epoch 38.240), train_loss = 0.34170310, grad/param norm = 2.0480e-01, time/batch = 17.8472s	
17056/22300 (epoch 38.242), train_loss = 0.30396720, grad/param norm = 2.4718e-01, time/batch = 15.5546s	
17057/22300 (epoch 38.244), train_loss = 0.22658230, grad/param norm = 1.7574e-01, time/batch = 17.7220s	
17058/22300 (epoch 38.247), train_loss = 0.30872861, grad/param norm = 2.1494e-01, time/batch = 16.5649s	
17059/22300 (epoch 38.249), train_loss = 0.21349164, grad/param norm = 1.5626e-01, time/batch = 16.8885s	
17060/22300 (epoch 38.251), train_loss = 0.27660622, grad/param norm = 1.7268e-01, time/batch = 16.4264s	
17061/22300 (epoch 38.253), train_loss = 0.19531898, grad/param norm = 1.7135e-01, time/batch = 15.3944s	
17062/22300 (epoch 38.256), train_loss = 0.27258088, grad/param norm = 1.7888e-01, time/batch = 15.4742s	
17063/22300 (epoch 38.258), train_loss = 0.42886829, grad/param norm = 3.4585e-01, time/batch = 16.7177s	
17064/22300 (epoch 38.260), train_loss = 0.40938416, grad/param norm = 2.2317e-01, time/batch = 17.1028s	
17065/22300 (epoch 38.262), train_loss = 0.30645489, grad/param norm = 1.9163e-01, time/batch = 16.9727s	
17066/22300 (epoch 38.265), train_loss = 0.28927592, grad/param norm = 2.1951e-01, time/batch = 18.0452s	
17067/22300 (epoch 38.267), train_loss = 0.32002217, grad/param norm = 2.4006e-01, time/batch = 15.2140s	
17068/22300 (epoch 38.269), train_loss = 0.38045986, grad/param norm = 2.8588e-01, time/batch = 17.8929s	
17069/22300 (epoch 38.271), train_loss = 0.43780708, grad/param norm = 2.7388e-01, time/batch = 16.2258s	
17070/22300 (epoch 38.274), train_loss = 0.31344039, grad/param norm = 2.7645e-01, time/batch = 16.0619s	
17071/22300 (epoch 38.276), train_loss = 0.26021410, grad/param norm = 1.8794e-01, time/batch = 15.8901s	
17072/22300 (epoch 38.278), train_loss = 0.28266187, grad/param norm = 1.8778e-01, time/batch = 14.9865s	
17073/22300 (epoch 38.280), train_loss = 0.30578758, grad/param norm = 1.8569e-01, time/batch = 14.9660s	
17074/22300 (epoch 38.283), train_loss = 0.25104387, grad/param norm = 1.5850e-01, time/batch = 15.7911s	
17075/22300 (epoch 38.285), train_loss = 0.27775874, grad/param norm = 3.1673e-01, time/batch = 17.2164s	
17076/22300 (epoch 38.287), train_loss = 0.39490113, grad/param norm = 3.5098e-01, time/batch = 16.8032s	
17077/22300 (epoch 38.289), train_loss = 0.35554998, grad/param norm = 2.3227e-01, time/batch = 18.6239s	
17078/22300 (epoch 38.291), train_loss = 0.38383251, grad/param norm = 3.1568e-01, time/batch = 15.1268s	
17079/22300 (epoch 38.294), train_loss = 0.29230420, grad/param norm = 1.8981e-01, time/batch = 17.2225s	
17080/22300 (epoch 38.296), train_loss = 0.35429035, grad/param norm = 3.0436e-01, time/batch = 16.0594s	
17081/22300 (epoch 38.298), train_loss = 0.44537149, grad/param norm = 2.5712e-01, time/batch = 17.1387s	
17082/22300 (epoch 38.300), train_loss = 0.48240206, grad/param norm = 2.3232e-01, time/batch = 16.5520s	
17083/22300 (epoch 38.303), train_loss = 0.37295795, grad/param norm = 2.5291e-01, time/batch = 15.8055s	
17084/22300 (epoch 38.305), train_loss = 0.37076305, grad/param norm = 2.9737e-01, time/batch = 18.1285s	
17085/22300 (epoch 38.307), train_loss = 0.32757192, grad/param norm = 3.0177e-01, time/batch = 16.2234s	
17086/22300 (epoch 38.309), train_loss = 0.29170479, grad/param norm = 2.2643e-01, time/batch = 19.4699s	
17087/22300 (epoch 38.312), train_loss = 0.26130148, grad/param norm = 2.1693e-01, time/batch = 15.0718s	
17088/22300 (epoch 38.314), train_loss = 0.29374943, grad/param norm = 2.2236e-01, time/batch = 15.2036s	
17089/22300 (epoch 38.316), train_loss = 0.28623380, grad/param norm = 2.2603e-01, time/batch = 15.6402s	
17090/22300 (epoch 38.318), train_loss = 0.33450254, grad/param norm = 2.4341e-01, time/batch = 15.8000s	
17091/22300 (epoch 38.321), train_loss = 0.41171369, grad/param norm = 2.5868e-01, time/batch = 15.8869s	
17092/22300 (epoch 38.323), train_loss = 0.29007194, grad/param norm = 1.9063e-01, time/batch = 15.5962s	
17093/22300 (epoch 38.325), train_loss = 0.26283499, grad/param norm = 1.9144e-01, time/batch = 15.8672s	
17094/22300 (epoch 38.327), train_loss = 0.28581845, grad/param norm = 1.8993e-01, time/batch = 16.8928s	
17095/22300 (epoch 38.330), train_loss = 0.29082693, grad/param norm = 2.2536e-01, time/batch = 17.2203s	
17096/22300 (epoch 38.332), train_loss = 0.27600958, grad/param norm = 1.9457e-01, time/batch = 15.3878s	
17097/22300 (epoch 38.334), train_loss = 0.30989602, grad/param norm = 2.4986e-01, time/batch = 17.4712s	
17098/22300 (epoch 38.336), train_loss = 0.33407789, grad/param norm = 2.3263e-01, time/batch = 17.0520s	
17099/22300 (epoch 38.339), train_loss = 0.36818477, grad/param norm = 2.3973e-01, time/batch = 17.1190s	
17100/22300 (epoch 38.341), train_loss = 0.38217061, grad/param norm = 2.5137e-01, time/batch = 17.9800s	
17101/22300 (epoch 38.343), train_loss = 0.41569450, grad/param norm = 3.1017e-01, time/batch = 17.5669s	
17102/22300 (epoch 38.345), train_loss = 0.34964412, grad/param norm = 2.6354e-01, time/batch = 18.0528s	
17103/22300 (epoch 38.348), train_loss = 0.34277257, grad/param norm = 2.0602e-01, time/batch = 15.6451s	
17104/22300 (epoch 38.350), train_loss = 0.24996893, grad/param norm = 1.7662e-01, time/batch = 17.8900s	
17105/22300 (epoch 38.352), train_loss = 0.36335982, grad/param norm = 2.3758e-01, time/batch = 17.5621s	
17106/22300 (epoch 38.354), train_loss = 0.51945292, grad/param norm = 2.9124e-01, time/batch = 16.8621s	
17107/22300 (epoch 38.357), train_loss = 0.46625091, grad/param norm = 2.6988e-01, time/batch = 17.3739s	
17108/22300 (epoch 38.359), train_loss = 0.29263607, grad/param norm = 2.0980e-01, time/batch = 15.7174s	
17109/22300 (epoch 38.361), train_loss = 0.30051095, grad/param norm = 2.1487e-01, time/batch = 17.1411s	
17110/22300 (epoch 38.363), train_loss = 0.39636361, grad/param norm = 2.5584e-01, time/batch = 15.3082s	
17111/22300 (epoch 38.365), train_loss = 0.29836053, grad/param norm = 1.9616e-01, time/batch = 15.2972s	
17112/22300 (epoch 38.368), train_loss = 0.31954900, grad/param norm = 2.6025e-01, time/batch = 17.2105s	
17113/22300 (epoch 38.370), train_loss = 0.33027802, grad/param norm = 2.6119e-01, time/batch = 18.2630s	
17114/22300 (epoch 38.372), train_loss = 0.24587257, grad/param norm = 2.0580e-01, time/batch = 15.2346s	
17115/22300 (epoch 38.374), train_loss = 0.25594839, grad/param norm = 1.7583e-01, time/batch = 17.0455s	
17116/22300 (epoch 38.377), train_loss = 0.34233768, grad/param norm = 2.6369e-01, time/batch = 15.8329s	
17117/22300 (epoch 38.379), train_loss = 0.29817574, grad/param norm = 2.0950e-01, time/batch = 16.1441s	
17118/22300 (epoch 38.381), train_loss = 0.40776433, grad/param norm = 3.2649e-01, time/batch = 17.4747s	
17119/22300 (epoch 38.383), train_loss = 0.31893278, grad/param norm = 2.3865e-01, time/batch = 17.6534s	
17120/22300 (epoch 38.386), train_loss = 0.34934120, grad/param norm = 2.2224e-01, time/batch = 17.6330s	
17121/22300 (epoch 38.388), train_loss = 0.26346546, grad/param norm = 2.5008e-01, time/batch = 15.3576s	
17122/22300 (epoch 38.390), train_loss = 0.27590649, grad/param norm = 2.2271e-01, time/batch = 17.5967s	
17123/22300 (epoch 38.392), train_loss = 0.32365691, grad/param norm = 2.1178e-01, time/batch = 16.5573s	
17124/22300 (epoch 38.395), train_loss = 0.26422499, grad/param norm = 1.9461e-01, time/batch = 17.0608s	
17125/22300 (epoch 38.397), train_loss = 0.19089497, grad/param norm = 1.8125e-01, time/batch = 15.8109s	
17126/22300 (epoch 38.399), train_loss = 0.26819271, grad/param norm = 1.7967e-01, time/batch = 14.9377s	
17127/22300 (epoch 38.401), train_loss = 0.31232005, grad/param norm = 2.3575e-01, time/batch = 15.8866s	
17128/22300 (epoch 38.404), train_loss = 0.32608923, grad/param norm = 2.5123e-01, time/batch = 15.9663s	
17129/22300 (epoch 38.406), train_loss = 0.48583021, grad/param norm = 2.7620e-01, time/batch = 16.3069s	
17130/22300 (epoch 38.408), train_loss = 0.38310540, grad/param norm = 2.7267e-01, time/batch = 16.3763s	
17131/22300 (epoch 38.410), train_loss = 0.42580068, grad/param norm = 2.4114e-01, time/batch = 18.3589s	
17132/22300 (epoch 38.413), train_loss = 0.32773275, grad/param norm = 2.9636e-01, time/batch = 30.2452s	
17133/22300 (epoch 38.415), train_loss = 0.23135317, grad/param norm = 2.3247e-01, time/batch = 15.0758s	
17134/22300 (epoch 38.417), train_loss = 0.36678112, grad/param norm = 2.5618e-01, time/batch = 16.0530s	
17135/22300 (epoch 38.419), train_loss = 0.31821604, grad/param norm = 2.0816e-01, time/batch = 16.1570s	
17136/22300 (epoch 38.422), train_loss = 0.28569143, grad/param norm = 2.1143e-01, time/batch = 17.0598s	
17137/22300 (epoch 38.424), train_loss = 0.34364618, grad/param norm = 2.3516e-01, time/batch = 17.9741s	
17138/22300 (epoch 38.426), train_loss = 0.25189559, grad/param norm = 2.1886e-01, time/batch = 15.0621s	
17139/22300 (epoch 38.428), train_loss = 0.26333834, grad/param norm = 2.0706e-01, time/batch = 14.4897s	
17140/22300 (epoch 38.430), train_loss = 0.31114599, grad/param norm = 2.4972e-01, time/batch = 15.7746s	
17141/22300 (epoch 38.433), train_loss = 0.33707919, grad/param norm = 2.1143e-01, time/batch = 17.5548s	
17142/22300 (epoch 38.435), train_loss = 0.28804177, grad/param norm = 2.1157e-01, time/batch = 15.3081s	
17143/22300 (epoch 38.437), train_loss = 0.36871599, grad/param norm = 3.1888e-01, time/batch = 16.8785s	
17144/22300 (epoch 38.439), train_loss = 0.39372997, grad/param norm = 2.3935e-01, time/batch = 16.2325s	
17145/22300 (epoch 38.442), train_loss = 0.34188919, grad/param norm = 2.4952e-01, time/batch = 16.3694s	
17146/22300 (epoch 38.444), train_loss = 0.27687786, grad/param norm = 2.2030e-01, time/batch = 16.1537s	
17147/22300 (epoch 38.446), train_loss = 0.31851501, grad/param norm = 2.9433e-01, time/batch = 15.7517s	
17148/22300 (epoch 38.448), train_loss = 0.22421590, grad/param norm = 1.2771e-01, time/batch = 15.8144s	
17149/22300 (epoch 38.451), train_loss = 0.38418389, grad/param norm = 2.8589e-01, time/batch = 15.6236s	
17150/22300 (epoch 38.453), train_loss = 0.29206947, grad/param norm = 2.0126e-01, time/batch = 15.3975s	
17151/22300 (epoch 38.455), train_loss = 0.39578533, grad/param norm = 2.6182e-01, time/batch = 16.3885s	
17152/22300 (epoch 38.457), train_loss = 0.55749805, grad/param norm = 3.6559e-01, time/batch = 17.0577s	
17153/22300 (epoch 38.460), train_loss = 0.44874896, grad/param norm = 2.7536e-01, time/batch = 15.0589s	
17154/22300 (epoch 38.462), train_loss = 0.44751274, grad/param norm = 2.8746e-01, time/batch = 16.0370s	
17155/22300 (epoch 38.464), train_loss = 0.39455304, grad/param norm = 2.8136e-01, time/batch = 15.8684s	
17156/22300 (epoch 38.466), train_loss = 0.31821291, grad/param norm = 1.9874e-01, time/batch = 16.8024s	
17157/22300 (epoch 38.469), train_loss = 0.30559012, grad/param norm = 1.8851e-01, time/batch = 15.9643s	
17158/22300 (epoch 38.471), train_loss = 0.41017887, grad/param norm = 2.2112e-01, time/batch = 15.6656s	
17159/22300 (epoch 38.473), train_loss = 0.36113205, grad/param norm = 2.2383e-01, time/batch = 16.7240s	
17160/22300 (epoch 38.475), train_loss = 0.31153602, grad/param norm = 2.2807e-01, time/batch = 16.7084s	
17161/22300 (epoch 38.478), train_loss = 0.33217118, grad/param norm = 2.6459e-01, time/batch = 18.3007s	
17162/22300 (epoch 38.480), train_loss = 0.24020191, grad/param norm = 1.7259e-01, time/batch = 15.3825s	
17163/22300 (epoch 38.482), train_loss = 0.26886144, grad/param norm = 2.0946e-01, time/batch = 18.3073s	
17164/22300 (epoch 38.484), train_loss = 0.35360003, grad/param norm = 2.4553e-01, time/batch = 15.8098s	
17165/22300 (epoch 38.487), train_loss = 0.41497880, grad/param norm = 2.4051e-01, time/batch = 17.8559s	
17166/22300 (epoch 38.489), train_loss = 0.40314382, grad/param norm = 2.1639e-01, time/batch = 16.0561s	
17167/22300 (epoch 38.491), train_loss = 0.42886055, grad/param norm = 2.9337e-01, time/batch = 16.5269s	
17168/22300 (epoch 38.493), train_loss = 0.32581252, grad/param norm = 3.2155e-01, time/batch = 16.6786s	
17169/22300 (epoch 38.496), train_loss = 0.35060208, grad/param norm = 2.0102e-01, time/batch = 16.3031s	
17170/22300 (epoch 38.498), train_loss = 0.24905898, grad/param norm = 1.9188e-01, time/batch = 15.9906s	
17171/22300 (epoch 38.500), train_loss = 0.35728976, grad/param norm = 2.5226e-01, time/batch = 16.5452s	
17172/22300 (epoch 38.502), train_loss = 0.21720074, grad/param norm = 1.8358e-01, time/batch = 18.1137s	
17173/22300 (epoch 38.504), train_loss = 0.24826182, grad/param norm = 1.9245e-01, time/batch = 17.8805s	
17174/22300 (epoch 38.507), train_loss = 0.29789231, grad/param norm = 2.4786e-01, time/batch = 16.0276s	
17175/22300 (epoch 38.509), train_loss = 0.38585332, grad/param norm = 2.7156e-01, time/batch = 16.6019s	
17176/22300 (epoch 38.511), train_loss = 0.21966146, grad/param norm = 2.0291e-01, time/batch = 15.5391s	
17177/22300 (epoch 38.513), train_loss = 0.24441366, grad/param norm = 2.2393e-01, time/batch = 17.7966s	
17178/22300 (epoch 38.516), train_loss = 0.29896206, grad/param norm = 2.1361e-01, time/batch = 16.7169s	
17179/22300 (epoch 38.518), train_loss = 0.38340795, grad/param norm = 3.3839e-01, time/batch = 17.5535s	
17180/22300 (epoch 38.520), train_loss = 0.31368124, grad/param norm = 2.5460e-01, time/batch = 16.7022s	
17181/22300 (epoch 38.522), train_loss = 0.33415035, grad/param norm = 2.3957e-01, time/batch = 16.2363s	
17182/22300 (epoch 38.525), train_loss = 0.26246315, grad/param norm = 1.9618e-01, time/batch = 16.2100s	
17183/22300 (epoch 38.527), train_loss = 0.40248444, grad/param norm = 2.5584e-01, time/batch = 19.2893s	
17184/22300 (epoch 38.529), train_loss = 0.36104759, grad/param norm = 2.9101e-01, time/batch = 14.3309s	
17185/22300 (epoch 38.531), train_loss = 0.32743272, grad/param norm = 3.1669e-01, time/batch = 17.1157s	
17186/22300 (epoch 38.534), train_loss = 0.33671001, grad/param norm = 2.0388e-01, time/batch = 17.9630s	
17187/22300 (epoch 38.536), train_loss = 0.50984773, grad/param norm = 2.7210e-01, time/batch = 15.3988s	
17188/22300 (epoch 38.538), train_loss = 0.60962981, grad/param norm = 3.7583e-01, time/batch = 15.5470s	
17189/22300 (epoch 38.540), train_loss = 0.35171812, grad/param norm = 2.7793e-01, time/batch = 16.0438s	
17190/22300 (epoch 38.543), train_loss = 0.35015954, grad/param norm = 2.5847e-01, time/batch = 17.5341s	
17191/22300 (epoch 38.545), train_loss = 0.25252752, grad/param norm = 2.1426e-01, time/batch = 16.5512s	
17192/22300 (epoch 38.547), train_loss = 0.20917925, grad/param norm = 1.7795e-01, time/batch = 17.5364s	
17193/22300 (epoch 38.549), train_loss = 0.25736489, grad/param norm = 1.9201e-01, time/batch = 15.6586s	
17194/22300 (epoch 38.552), train_loss = 0.27566325, grad/param norm = 2.1555e-01, time/batch = 16.9847s	
17195/22300 (epoch 38.554), train_loss = 0.35749854, grad/param norm = 2.4741e-01, time/batch = 16.8889s	
17196/22300 (epoch 38.556), train_loss = 0.53526572, grad/param norm = 4.2010e-01, time/batch = 16.2000s	
17197/22300 (epoch 38.558), train_loss = 0.37974745, grad/param norm = 3.0551e-01, time/batch = 15.1757s	
17198/22300 (epoch 38.561), train_loss = 0.51963575, grad/param norm = 3.2744e-01, time/batch = 16.2930s	
17199/22300 (epoch 38.563), train_loss = 0.43250013, grad/param norm = 3.2954e-01, time/batch = 14.9120s	
17200/22300 (epoch 38.565), train_loss = 0.32969346, grad/param norm = 2.1839e-01, time/batch = 15.3781s	
17201/22300 (epoch 38.567), train_loss = 0.35485908, grad/param norm = 2.8232e-01, time/batch = 15.5325s	
17202/22300 (epoch 38.570), train_loss = 0.47622491, grad/param norm = 3.0250e-01, time/batch = 18.2001s	
17203/22300 (epoch 38.572), train_loss = 0.46594053, grad/param norm = 2.8669e-01, time/batch = 17.5386s	
17204/22300 (epoch 38.574), train_loss = 0.34297896, grad/param norm = 2.4651e-01, time/batch = 16.4772s	
17205/22300 (epoch 38.576), train_loss = 0.30521711, grad/param norm = 2.0205e-01, time/batch = 16.4734s	
17206/22300 (epoch 38.578), train_loss = 0.17987134, grad/param norm = 1.7035e-01, time/batch = 17.9593s	
17207/22300 (epoch 38.581), train_loss = 0.26099395, grad/param norm = 1.9099e-01, time/batch = 15.2350s	
17208/22300 (epoch 38.583), train_loss = 0.30229041, grad/param norm = 1.8730e-01, time/batch = 17.3919s	
17209/22300 (epoch 38.585), train_loss = 0.41420679, grad/param norm = 3.0719e-01, time/batch = 17.6416s	
17210/22300 (epoch 38.587), train_loss = 0.61226618, grad/param norm = 3.2706e-01, time/batch = 17.3649s	
17211/22300 (epoch 38.590), train_loss = 0.50286193, grad/param norm = 3.5204e-01, time/batch = 16.4627s	
17212/22300 (epoch 38.592), train_loss = 0.55633914, grad/param norm = 3.0789e-01, time/batch = 17.9687s	
17213/22300 (epoch 38.594), train_loss = 0.54802242, grad/param norm = 3.7676e-01, time/batch = 16.4840s	
17214/22300 (epoch 38.596), train_loss = 0.34721563, grad/param norm = 2.3667e-01, time/batch = 15.3082s	
17215/22300 (epoch 38.599), train_loss = 0.23877998, grad/param norm = 2.0965e-01, time/batch = 14.9514s	
17216/22300 (epoch 38.601), train_loss = 0.29721802, grad/param norm = 2.4623e-01, time/batch = 17.8695s	
17217/22300 (epoch 38.603), train_loss = 0.30602947, grad/param norm = 2.0413e-01, time/batch = 16.5524s	
17218/22300 (epoch 38.605), train_loss = 0.33027634, grad/param norm = 2.8696e-01, time/batch = 16.4672s	
17219/22300 (epoch 38.608), train_loss = 0.55688382, grad/param norm = 3.1917e-01, time/batch = 17.8033s	
17220/22300 (epoch 38.610), train_loss = 0.60355667, grad/param norm = 3.0744e-01, time/batch = 18.8755s	
17221/22300 (epoch 38.612), train_loss = 0.43585524, grad/param norm = 2.8591e-01, time/batch = 15.7879s	
17222/22300 (epoch 38.614), train_loss = 0.42006478, grad/param norm = 3.2534e-01, time/batch = 16.8808s	
17223/22300 (epoch 38.617), train_loss = 0.44838605, grad/param norm = 2.5158e-01, time/batch = 16.7316s	
17224/22300 (epoch 38.619), train_loss = 0.48157006, grad/param norm = 3.0510e-01, time/batch = 15.4602s	
17225/22300 (epoch 38.621), train_loss = 0.30848760, grad/param norm = 2.3667e-01, time/batch = 16.4648s	
17226/22300 (epoch 38.623), train_loss = 0.32221589, grad/param norm = 2.2541e-01, time/batch = 16.8162s	
17227/22300 (epoch 38.626), train_loss = 0.30808343, grad/param norm = 2.1948e-01, time/batch = 14.7176s	
17228/22300 (epoch 38.628), train_loss = 0.31939549, grad/param norm = 2.3152e-01, time/batch = 17.1204s	
17229/22300 (epoch 38.630), train_loss = 0.37181774, grad/param norm = 2.6268e-01, time/batch = 16.9710s	
17230/22300 (epoch 38.632), train_loss = 0.30126363, grad/param norm = 2.3580e-01, time/batch = 17.4763s	
17231/22300 (epoch 38.635), train_loss = 0.35473958, grad/param norm = 2.2563e-01, time/batch = 17.1919s	
17232/22300 (epoch 38.637), train_loss = 0.41444503, grad/param norm = 2.7274e-01, time/batch = 15.7906s	
17233/22300 (epoch 38.639), train_loss = 0.48459407, grad/param norm = 2.9237e-01, time/batch = 17.3693s	
17234/22300 (epoch 38.641), train_loss = 0.40247588, grad/param norm = 2.6059e-01, time/batch = 17.2099s	
17235/22300 (epoch 38.643), train_loss = 0.30631400, grad/param norm = 2.6433e-01, time/batch = 15.6284s	
17236/22300 (epoch 38.646), train_loss = 0.33392828, grad/param norm = 3.1369e-01, time/batch = 15.8046s	
17237/22300 (epoch 38.648), train_loss = 0.41653819, grad/param norm = 2.3509e-01, time/batch = 18.7165s	
17238/22300 (epoch 38.650), train_loss = 0.41885429, grad/param norm = 3.1291e-01, time/batch = 17.8001s	
17239/22300 (epoch 38.652), train_loss = 0.32760219, grad/param norm = 2.0282e-01, time/batch = 15.1379s	
17240/22300 (epoch 38.655), train_loss = 0.28779918, grad/param norm = 2.4174e-01, time/batch = 16.0585s	
17241/22300 (epoch 38.657), train_loss = 0.33183436, grad/param norm = 2.7990e-01, time/batch = 15.8174s	
17242/22300 (epoch 38.659), train_loss = 0.33400514, grad/param norm = 2.8896e-01, time/batch = 17.5531s	
17243/22300 (epoch 38.661), train_loss = 0.26534828, grad/param norm = 1.9973e-01, time/batch = 15.2160s	
17244/22300 (epoch 38.664), train_loss = 0.31483506, grad/param norm = 2.1574e-01, time/batch = 16.9078s	
17245/22300 (epoch 38.666), train_loss = 0.40029138, grad/param norm = 2.5549e-01, time/batch = 17.3844s	
17246/22300 (epoch 38.668), train_loss = 0.29548664, grad/param norm = 2.2080e-01, time/batch = 16.5478s	
17247/22300 (epoch 38.670), train_loss = 0.38264703, grad/param norm = 2.5352e-01, time/batch = 18.1160s	
17248/22300 (epoch 38.673), train_loss = 0.44037064, grad/param norm = 3.2091e-01, time/batch = 15.4855s	
17249/22300 (epoch 38.675), train_loss = 0.52323009, grad/param norm = 4.4612e-01, time/batch = 18.6337s	
17250/22300 (epoch 38.677), train_loss = 0.55397075, grad/param norm = 3.9519e-01, time/batch = 16.0537s	
17251/22300 (epoch 38.679), train_loss = 0.37491158, grad/param norm = 2.8911e-01, time/batch = 16.7910s	
17252/22300 (epoch 38.682), train_loss = 0.35678729, grad/param norm = 2.0315e-01, time/batch = 15.9037s	
17253/22300 (epoch 38.684), train_loss = 0.33937137, grad/param norm = 2.2243e-01, time/batch = 16.0388s	
17254/22300 (epoch 38.686), train_loss = 0.31945353, grad/param norm = 2.1142e-01, time/batch = 16.8863s	
17255/22300 (epoch 38.688), train_loss = 0.31743178, grad/param norm = 2.6284e-01, time/batch = 17.1544s	
17256/22300 (epoch 38.691), train_loss = 0.28833446, grad/param norm = 2.6665e-01, time/batch = 18.1317s	
17257/22300 (epoch 38.693), train_loss = 0.28028642, grad/param norm = 2.2401e-01, time/batch = 16.1176s	
17258/22300 (epoch 38.695), train_loss = 0.31638130, grad/param norm = 2.3598e-01, time/batch = 15.4599s	
17259/22300 (epoch 38.697), train_loss = 0.34191349, grad/param norm = 2.4968e-01, time/batch = 15.9672s	
17260/22300 (epoch 38.700), train_loss = 0.27967089, grad/param norm = 2.1033e-01, time/batch = 17.1100s	
17261/22300 (epoch 38.702), train_loss = 0.23128086, grad/param norm = 1.5792e-01, time/batch = 16.9708s	
17262/22300 (epoch 38.704), train_loss = 0.32231793, grad/param norm = 2.7368e-01, time/batch = 17.8802s	
17263/22300 (epoch 38.706), train_loss = 0.30314254, grad/param norm = 2.3632e-01, time/batch = 15.9958s	
17264/22300 (epoch 38.709), train_loss = 0.23711321, grad/param norm = 1.8392e-01, time/batch = 16.1273s	
17265/22300 (epoch 38.711), train_loss = 0.23939108, grad/param norm = 1.6533e-01, time/batch = 15.4035s	
17266/22300 (epoch 38.713), train_loss = 0.35207432, grad/param norm = 2.2710e-01, time/batch = 15.8272s	
17267/22300 (epoch 38.715), train_loss = 0.36257331, grad/param norm = 2.1862e-01, time/batch = 17.9648s	
17268/22300 (epoch 38.717), train_loss = 0.47313712, grad/param norm = 2.4515e-01, time/batch = 15.3811s	
17269/22300 (epoch 38.720), train_loss = 0.31330553, grad/param norm = 2.4358e-01, time/batch = 16.7915s	
17270/22300 (epoch 38.722), train_loss = 0.33862498, grad/param norm = 2.3949e-01, time/batch = 15.4344s	
17271/22300 (epoch 38.724), train_loss = 0.41066217, grad/param norm = 3.8541e-01, time/batch = 16.8036s	
17272/22300 (epoch 38.726), train_loss = 0.31813408, grad/param norm = 2.3667e-01, time/batch = 15.6408s	
17273/22300 (epoch 38.729), train_loss = 0.37197795, grad/param norm = 2.3997e-01, time/batch = 17.8026s	
17274/22300 (epoch 38.731), train_loss = 0.48775773, grad/param norm = 3.7669e-01, time/batch = 17.3100s	
17275/22300 (epoch 38.733), train_loss = 0.45062893, grad/param norm = 2.8101e-01, time/batch = 15.4947s	
17276/22300 (epoch 38.735), train_loss = 0.49801621, grad/param norm = 3.2063e-01, time/batch = 17.3784s	
17277/22300 (epoch 38.738), train_loss = 0.37392935, grad/param norm = 3.4745e-01, time/batch = 15.3788s	
17278/22300 (epoch 38.740), train_loss = 0.33084901, grad/param norm = 2.1123e-01, time/batch = 17.0471s	
17279/22300 (epoch 38.742), train_loss = 0.29160368, grad/param norm = 1.8798e-01, time/batch = 16.3698s	
17280/22300 (epoch 38.744), train_loss = 0.53022164, grad/param norm = 3.1938e-01, time/batch = 17.8869s	
17281/22300 (epoch 38.747), train_loss = 0.41405217, grad/param norm = 2.3156e-01, time/batch = 15.2132s	
17282/22300 (epoch 38.749), train_loss = 0.56347926, grad/param norm = 4.0987e-01, time/batch = 17.1325s	
17283/22300 (epoch 38.751), train_loss = 0.45952251, grad/param norm = 4.4783e-01, time/batch = 16.8081s	
17284/22300 (epoch 38.753), train_loss = 0.48385879, grad/param norm = 3.6847e-01, time/batch = 17.7096s	
17285/22300 (epoch 38.756), train_loss = 0.44971728, grad/param norm = 2.7532e-01, time/batch = 16.9782s	
17286/22300 (epoch 38.758), train_loss = 0.39005261, grad/param norm = 2.3449e-01, time/batch = 16.2178s	
17287/22300 (epoch 38.760), train_loss = 0.42571563, grad/param norm = 2.6734e-01, time/batch = 15.8929s	
17288/22300 (epoch 38.762), train_loss = 0.38549874, grad/param norm = 2.8440e-01, time/batch = 17.6433s	
17289/22300 (epoch 38.765), train_loss = 0.41797844, grad/param norm = 2.8960e-01, time/batch = 16.8856s	
17290/22300 (epoch 38.767), train_loss = 0.40709998, grad/param norm = 2.8860e-01, time/batch = 15.0698s	
17291/22300 (epoch 38.769), train_loss = 0.38269756, grad/param norm = 2.4825e-01, time/batch = 17.2202s	
17292/22300 (epoch 38.771), train_loss = 0.43800441, grad/param norm = 3.1513e-01, time/batch = 17.9633s	
17293/22300 (epoch 38.774), train_loss = 0.50279263, grad/param norm = 3.8815e-01, time/batch = 15.9567s	
17294/22300 (epoch 38.776), train_loss = 0.51363299, grad/param norm = 3.1638e-01, time/batch = 17.6198s	
17295/22300 (epoch 38.778), train_loss = 0.50373994, grad/param norm = 3.4194e-01, time/batch = 15.5702s	
17296/22300 (epoch 38.780), train_loss = 0.49066904, grad/param norm = 3.2286e-01, time/batch = 15.2838s	
17297/22300 (epoch 38.783), train_loss = 0.50965056, grad/param norm = 3.0386e-01, time/batch = 17.2960s	
17298/22300 (epoch 38.785), train_loss = 0.34006550, grad/param norm = 2.5642e-01, time/batch = 18.1402s	
17299/22300 (epoch 38.787), train_loss = 0.37785684, grad/param norm = 2.9746e-01, time/batch = 16.8863s	
17300/22300 (epoch 38.789), train_loss = 0.55006021, grad/param norm = 3.5010e-01, time/batch = 16.2268s	
17301/22300 (epoch 38.791), train_loss = 0.64787071, grad/param norm = 3.2221e-01, time/batch = 17.9702s	
17302/22300 (epoch 38.794), train_loss = 0.52195153, grad/param norm = 3.7077e-01, time/batch = 16.9678s	
17303/22300 (epoch 38.796), train_loss = 0.48657467, grad/param norm = 3.5187e-01, time/batch = 16.7945s	
17304/22300 (epoch 38.798), train_loss = 0.61572352, grad/param norm = 3.4438e-01, time/batch = 17.4858s	
17305/22300 (epoch 38.800), train_loss = 0.41226425, grad/param norm = 2.6817e-01, time/batch = 15.8666s	
17306/22300 (epoch 38.803), train_loss = 0.36739288, grad/param norm = 2.3099e-01, time/batch = 15.3670s	
17307/22300 (epoch 38.805), train_loss = 0.42039438, grad/param norm = 2.8851e-01, time/batch = 15.4632s	
17308/22300 (epoch 38.807), train_loss = 0.54623461, grad/param norm = 3.1486e-01, time/batch = 17.7845s	
17309/22300 (epoch 38.809), train_loss = 0.39712711, grad/param norm = 2.6825e-01, time/batch = 15.6232s	
17310/22300 (epoch 38.812), train_loss = 0.44380215, grad/param norm = 2.9133e-01, time/batch = 17.9631s	
17311/22300 (epoch 38.814), train_loss = 0.43077336, grad/param norm = 2.6275e-01, time/batch = 15.3699s	
17312/22300 (epoch 38.816), train_loss = 0.44017746, grad/param norm = 2.8917e-01, time/batch = 17.8098s	
17313/22300 (epoch 38.818), train_loss = 0.51027481, grad/param norm = 3.3246e-01, time/batch = 16.9712s	
17314/22300 (epoch 38.821), train_loss = 0.45371907, grad/param norm = 2.9111e-01, time/batch = 16.9626s	
17315/22300 (epoch 38.823), train_loss = 0.28987830, grad/param norm = 2.2449e-01, time/batch = 17.8185s	
17316/22300 (epoch 38.825), train_loss = 0.29195107, grad/param norm = 2.0057e-01, time/batch = 16.7249s	
17317/22300 (epoch 38.827), train_loss = 0.35618801, grad/param norm = 2.5606e-01, time/batch = 16.1248s	
17318/22300 (epoch 38.830), train_loss = 0.36825287, grad/param norm = 2.6248e-01, time/batch = 16.6271s	
17319/22300 (epoch 38.832), train_loss = 0.33676979, grad/param norm = 2.2927e-01, time/batch = 16.8609s	
17320/22300 (epoch 38.834), train_loss = 0.28130624, grad/param norm = 1.9041e-01, time/batch = 17.2155s	
17321/22300 (epoch 38.836), train_loss = 0.34738438, grad/param norm = 2.2470e-01, time/batch = 17.2925s	
17322/22300 (epoch 38.839), train_loss = 0.38924973, grad/param norm = 2.8808e-01, time/batch = 17.1331s	
17323/22300 (epoch 38.841), train_loss = 0.33991248, grad/param norm = 2.5645e-01, time/batch = 16.2926s	
17324/22300 (epoch 38.843), train_loss = 0.37131152, grad/param norm = 2.6322e-01, time/batch = 18.8583s	
17325/22300 (epoch 38.845), train_loss = 0.37420010, grad/param norm = 2.7919e-01, time/batch = 15.7181s	
17326/22300 (epoch 38.848), train_loss = 0.35134775, grad/param norm = 2.5711e-01, time/batch = 15.4590s	
17327/22300 (epoch 38.850), train_loss = 0.37962033, grad/param norm = 2.1377e-01, time/batch = 16.6147s	
17328/22300 (epoch 38.852), train_loss = 0.33998189, grad/param norm = 2.8794e-01, time/batch = 17.5282s	
17329/22300 (epoch 38.854), train_loss = 0.57561659, grad/param norm = 3.3380e-01, time/batch = 17.0597s	
17330/22300 (epoch 38.857), train_loss = 0.41915348, grad/param norm = 3.1495e-01, time/batch = 17.6375s	
17331/22300 (epoch 38.859), train_loss = 0.33185174, grad/param norm = 2.1594e-01, time/batch = 17.6255s	
17332/22300 (epoch 38.861), train_loss = 0.46936308, grad/param norm = 3.2617e-01, time/batch = 15.1352s	
17333/22300 (epoch 38.863), train_loss = 0.29521563, grad/param norm = 2.0948e-01, time/batch = 16.8031s	
17334/22300 (epoch 38.865), train_loss = 0.29170205, grad/param norm = 2.0951e-01, time/batch = 17.7984s	
17335/22300 (epoch 38.868), train_loss = 0.40332303, grad/param norm = 2.2277e-01, time/batch = 17.2955s	
17336/22300 (epoch 38.870), train_loss = 0.40843462, grad/param norm = 2.7365e-01, time/batch = 15.1552s	
17337/22300 (epoch 38.872), train_loss = 0.49872422, grad/param norm = 2.9233e-01, time/batch = 16.4600s	
17338/22300 (epoch 38.874), train_loss = 0.42821356, grad/param norm = 3.2146e-01, time/batch = 16.9151s	
17339/22300 (epoch 38.877), train_loss = 0.38919848, grad/param norm = 2.1453e-01, time/batch = 16.7860s	
17340/22300 (epoch 38.879), train_loss = 0.35753204, grad/param norm = 2.1979e-01, time/batch = 16.7175s	
17341/22300 (epoch 38.881), train_loss = 0.29086760, grad/param norm = 2.0094e-01, time/batch = 16.3759s	
17342/22300 (epoch 38.883), train_loss = 0.30606532, grad/param norm = 2.0314e-01, time/batch = 14.8810s	
17343/22300 (epoch 38.886), train_loss = 0.29376351, grad/param norm = 3.1581e-01, time/batch = 15.0399s	
17344/22300 (epoch 38.888), train_loss = 0.34187671, grad/param norm = 2.6664e-01, time/batch = 16.2945s	
17345/22300 (epoch 38.890), train_loss = 0.33952799, grad/param norm = 2.2812e-01, time/batch = 18.1406s	
17346/22300 (epoch 38.892), train_loss = 0.50564737, grad/param norm = 3.0662e-01, time/batch = 20.9019s	
17347/22300 (epoch 38.895), train_loss = 0.47916727, grad/param norm = 3.6426e-01, time/batch = 27.0318s	
17348/22300 (epoch 38.897), train_loss = 0.38081601, grad/param norm = 2.7648e-01, time/batch = 15.1930s	
17349/22300 (epoch 38.899), train_loss = 0.36391456, grad/param norm = 2.3399e-01, time/batch = 15.4558s	
17350/22300 (epoch 38.901), train_loss = 0.43605073, grad/param norm = 2.4343e-01, time/batch = 16.7250s	
17351/22300 (epoch 38.904), train_loss = 0.43212282, grad/param norm = 2.8081e-01, time/batch = 16.3092s	
17352/22300 (epoch 38.906), train_loss = 0.41520455, grad/param norm = 2.5165e-01, time/batch = 18.3853s	
17353/22300 (epoch 38.908), train_loss = 0.35814326, grad/param norm = 1.9211e-01, time/batch = 15.3118s	
17354/22300 (epoch 38.910), train_loss = 0.32593984, grad/param norm = 2.0347e-01, time/batch = 16.9729s	
17355/22300 (epoch 38.913), train_loss = 0.42834738, grad/param norm = 2.7589e-01, time/batch = 16.5647s	
17356/22300 (epoch 38.915), train_loss = 0.51910342, grad/param norm = 2.9962e-01, time/batch = 17.0517s	
17357/22300 (epoch 38.917), train_loss = 0.41809197, grad/param norm = 2.5878e-01, time/batch = 15.9885s	
17358/22300 (epoch 38.919), train_loss = 0.41434464, grad/param norm = 2.2810e-01, time/batch = 15.7231s	
17359/22300 (epoch 38.922), train_loss = 0.39977915, grad/param norm = 2.8065e-01, time/batch = 18.2229s	
17360/22300 (epoch 38.924), train_loss = 0.24659293, grad/param norm = 1.7877e-01, time/batch = 15.6091s	
17361/22300 (epoch 38.926), train_loss = 0.33056926, grad/param norm = 2.4536e-01, time/batch = 17.3771s	
17362/22300 (epoch 38.928), train_loss = 0.34583636, grad/param norm = 2.4779e-01, time/batch = 18.6384s	
17363/22300 (epoch 38.930), train_loss = 0.32472445, grad/param norm = 2.1747e-01, time/batch = 17.1084s	
17364/22300 (epoch 38.933), train_loss = 0.41859452, grad/param norm = 2.9467e-01, time/batch = 16.1974s	
17365/22300 (epoch 38.935), train_loss = 0.40511179, grad/param norm = 3.9049e-01, time/batch = 15.1170s	
17366/22300 (epoch 38.937), train_loss = 0.49095584, grad/param norm = 3.2725e-01, time/batch = 15.1112s	
17367/22300 (epoch 38.939), train_loss = 0.43354355, grad/param norm = 3.3026e-01, time/batch = 14.9510s	
17368/22300 (epoch 38.942), train_loss = 0.54456979, grad/param norm = 3.3596e-01, time/batch = 15.0163s	
17369/22300 (epoch 38.944), train_loss = 0.57627626, grad/param norm = 3.7603e-01, time/batch = 14.6326s	
17370/22300 (epoch 38.946), train_loss = 0.42800749, grad/param norm = 3.0303e-01, time/batch = 14.7020s	
17371/22300 (epoch 38.948), train_loss = 0.37852597, grad/param norm = 2.6070e-01, time/batch = 16.0479s	
17372/22300 (epoch 38.951), train_loss = 0.28737201, grad/param norm = 2.1950e-01, time/batch = 18.5413s	
17373/22300 (epoch 38.953), train_loss = 0.32197033, grad/param norm = 2.5764e-01, time/batch = 15.7317s	
17374/22300 (epoch 38.955), train_loss = 0.48523870, grad/param norm = 2.9753e-01, time/batch = 17.1380s	
17375/22300 (epoch 38.957), train_loss = 0.55343279, grad/param norm = 2.5125e-01, time/batch = 16.7934s	
17376/22300 (epoch 38.960), train_loss = 0.49594774, grad/param norm = 2.3896e-01, time/batch = 14.2476s	
17377/22300 (epoch 38.962), train_loss = 0.31483853, grad/param norm = 2.3950e-01, time/batch = 15.5948s	
17378/22300 (epoch 38.964), train_loss = 0.32645079, grad/param norm = 2.2597e-01, time/batch = 16.8849s	
17379/22300 (epoch 38.966), train_loss = 0.33374496, grad/param norm = 2.3046e-01, time/batch = 17.6098s	
17380/22300 (epoch 38.969), train_loss = 0.36900918, grad/param norm = 2.2978e-01, time/batch = 16.2952s	
17381/22300 (epoch 38.971), train_loss = 0.38304782, grad/param norm = 2.1920e-01, time/batch = 16.8060s	
17382/22300 (epoch 38.973), train_loss = 0.36939695, grad/param norm = 2.7071e-01, time/batch = 15.4309s	
17383/22300 (epoch 38.975), train_loss = 0.50025350, grad/param norm = 3.1872e-01, time/batch = 16.1437s	
17384/22300 (epoch 38.978), train_loss = 0.48703245, grad/param norm = 2.6860e-01, time/batch = 15.6352s	
17385/22300 (epoch 38.980), train_loss = 0.58173433, grad/param norm = 4.1292e-01, time/batch = 16.8816s	
17386/22300 (epoch 38.982), train_loss = 0.31475946, grad/param norm = 2.8010e-01, time/batch = 15.8145s	
17387/22300 (epoch 38.984), train_loss = 0.39236251, grad/param norm = 2.8944e-01, time/batch = 17.3761s	
17388/22300 (epoch 38.987), train_loss = 0.39061284, grad/param norm = 2.8777e-01, time/batch = 16.1933s	
17389/22300 (epoch 38.989), train_loss = 0.32190156, grad/param norm = 3.1585e-01, time/batch = 16.9439s	
17390/22300 (epoch 38.991), train_loss = 0.57542251, grad/param norm = 2.9544e-01, time/batch = 15.5399s	
17391/22300 (epoch 38.993), train_loss = 0.72528711, grad/param norm = 3.7457e-01, time/batch = 17.8018s	
17392/22300 (epoch 38.996), train_loss = 0.72230564, grad/param norm = 4.2270e-01, time/batch = 19.0420s	
17393/22300 (epoch 38.998), train_loss = 0.44818304, grad/param norm = 2.7610e-01, time/batch = 15.0740s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
17394/22300 (epoch 39.000), train_loss = 0.34062775, grad/param norm = 2.7438e-01, time/batch = 16.4651s	
17395/22300 (epoch 39.002), train_loss = 0.70207532, grad/param norm = 3.5132e-01, time/batch = 15.4713s	
17396/22300 (epoch 39.004), train_loss = 0.45799419, grad/param norm = 2.3960e-01, time/batch = 16.6271s	
17397/22300 (epoch 39.007), train_loss = 0.46651958, grad/param norm = 2.7190e-01, time/batch = 16.2216s	
17398/22300 (epoch 39.009), train_loss = 0.48451446, grad/param norm = 3.5075e-01, time/batch = 17.5415s	
17399/22300 (epoch 39.011), train_loss = 0.60151267, grad/param norm = 3.4710e-01, time/batch = 18.2911s	
17400/22300 (epoch 39.013), train_loss = 0.46353154, grad/param norm = 3.5352e-01, time/batch = 15.8713s	
17401/22300 (epoch 39.016), train_loss = 0.35864343, grad/param norm = 2.5758e-01, time/batch = 18.7889s	
17402/22300 (epoch 39.018), train_loss = 0.39354387, grad/param norm = 2.3841e-01, time/batch = 15.7302s	
17403/22300 (epoch 39.020), train_loss = 0.37968407, grad/param norm = 2.5433e-01, time/batch = 17.7697s	
17404/22300 (epoch 39.022), train_loss = 0.30972582, grad/param norm = 2.7147e-01, time/batch = 15.8214s	
17405/22300 (epoch 39.025), train_loss = 0.32999511, grad/param norm = 2.0792e-01, time/batch = 16.8690s	
17406/22300 (epoch 39.027), train_loss = 0.31449510, grad/param norm = 1.9885e-01, time/batch = 16.7059s	
17407/22300 (epoch 39.029), train_loss = 0.35306867, grad/param norm = 2.3447e-01, time/batch = 16.3044s	
17408/22300 (epoch 39.031), train_loss = 0.31542233, grad/param norm = 1.8655e-01, time/batch = 15.9816s	
17409/22300 (epoch 39.034), train_loss = 0.33155226, grad/param norm = 2.3233e-01, time/batch = 16.3167s	
17410/22300 (epoch 39.036), train_loss = 0.30722981, grad/param norm = 2.0092e-01, time/batch = 16.8850s	
17411/22300 (epoch 39.038), train_loss = 0.27856470, grad/param norm = 2.1349e-01, time/batch = 15.1920s	
17412/22300 (epoch 39.040), train_loss = 0.36110499, grad/param norm = 3.1393e-01, time/batch = 16.9682s	
17413/22300 (epoch 39.043), train_loss = 0.57120858, grad/param norm = 3.2119e-01, time/batch = 16.8670s	
17414/22300 (epoch 39.045), train_loss = 0.46829949, grad/param norm = 3.0687e-01, time/batch = 15.6292s	
17415/22300 (epoch 39.047), train_loss = 0.49490964, grad/param norm = 2.9323e-01, time/batch = 15.3969s	
17416/22300 (epoch 39.049), train_loss = 0.39440781, grad/param norm = 2.8293e-01, time/batch = 17.7981s	
17417/22300 (epoch 39.052), train_loss = 0.44362021, grad/param norm = 3.2379e-01, time/batch = 17.4755s	
17418/22300 (epoch 39.054), train_loss = 0.46656819, grad/param norm = 3.1524e-01, time/batch = 15.6236s	
17419/22300 (epoch 39.056), train_loss = 0.21667117, grad/param norm = 1.5142e-01, time/batch = 17.5454s	
17420/22300 (epoch 39.058), train_loss = 0.36461841, grad/param norm = 2.8795e-01, time/batch = 15.4813s	
17421/22300 (epoch 39.061), train_loss = 0.33324049, grad/param norm = 2.6313e-01, time/batch = 16.2314s	
17422/22300 (epoch 39.063), train_loss = 0.49425136, grad/param norm = 3.3195e-01, time/batch = 15.8792s	
17423/22300 (epoch 39.065), train_loss = 0.57752979, grad/param norm = 3.6864e-01, time/batch = 17.7201s	
17424/22300 (epoch 39.067), train_loss = 0.32908530, grad/param norm = 3.2142e-01, time/batch = 15.8004s	
17425/22300 (epoch 39.070), train_loss = 0.37270843, grad/param norm = 2.4040e-01, time/batch = 16.4467s	
17426/22300 (epoch 39.072), train_loss = 0.43542372, grad/param norm = 3.0268e-01, time/batch = 17.0249s	
17427/22300 (epoch 39.074), train_loss = 0.42747262, grad/param norm = 2.9834e-01, time/batch = 17.5389s	
17428/22300 (epoch 39.076), train_loss = 0.42098444, grad/param norm = 3.1331e-01, time/batch = 18.3693s	
17429/22300 (epoch 39.078), train_loss = 0.56885165, grad/param norm = 4.3866e-01, time/batch = 15.5910s	
17430/22300 (epoch 39.081), train_loss = 0.50856799, grad/param norm = 3.2587e-01, time/batch = 16.2860s	
17431/22300 (epoch 39.083), train_loss = 0.58666546, grad/param norm = 3.3688e-01, time/batch = 17.0443s	
17432/22300 (epoch 39.085), train_loss = 0.56319887, grad/param norm = 3.5699e-01, time/batch = 16.2255s	
17433/22300 (epoch 39.087), train_loss = 0.45829386, grad/param norm = 3.0579e-01, time/batch = 15.6432s	
17434/22300 (epoch 39.090), train_loss = 0.43496678, grad/param norm = 3.0907e-01, time/batch = 16.8032s	
17435/22300 (epoch 39.092), train_loss = 0.32468424, grad/param norm = 2.2168e-01, time/batch = 18.0546s	
17436/22300 (epoch 39.094), train_loss = 0.32201038, grad/param norm = 2.5701e-01, time/batch = 15.4765s	
17437/22300 (epoch 39.096), train_loss = 0.54884938, grad/param norm = 2.9686e-01, time/batch = 17.3896s	
17438/22300 (epoch 39.099), train_loss = 0.35324644, grad/param norm = 2.1626e-01, time/batch = 14.8835s	
17439/22300 (epoch 39.101), train_loss = 0.49650743, grad/param norm = 3.0305e-01, time/batch = 17.3792s	
17440/22300 (epoch 39.103), train_loss = 0.38526327, grad/param norm = 2.3440e-01, time/batch = 15.7952s	
17441/22300 (epoch 39.105), train_loss = 0.32515749, grad/param norm = 3.0053e-01, time/batch = 18.0466s	
17442/22300 (epoch 39.108), train_loss = 0.45234673, grad/param norm = 2.6867e-01, time/batch = 17.5636s	
17443/22300 (epoch 39.110), train_loss = 0.50152267, grad/param norm = 2.7238e-01, time/batch = 16.3792s	
17444/22300 (epoch 39.112), train_loss = 0.43441825, grad/param norm = 2.5154e-01, time/batch = 16.4806s	
17445/22300 (epoch 39.114), train_loss = 0.47063872, grad/param norm = 2.7834e-01, time/batch = 17.1494s	
17446/22300 (epoch 39.117), train_loss = 0.56077601, grad/param norm = 3.5514e-01, time/batch = 16.6775s	
17447/22300 (epoch 39.119), train_loss = 0.50941401, grad/param norm = 3.1815e-01, time/batch = 15.9664s	
17448/22300 (epoch 39.121), train_loss = 0.56851147, grad/param norm = 3.4621e-01, time/batch = 16.3777s	
17449/22300 (epoch 39.123), train_loss = 0.58914856, grad/param norm = 3.0602e-01, time/batch = 15.2118s	
17450/22300 (epoch 39.126), train_loss = 0.43969030, grad/param norm = 2.4626e-01, time/batch = 15.7210s	
17451/22300 (epoch 39.128), train_loss = 0.45150974, grad/param norm = 3.2937e-01, time/batch = 17.7904s	
17452/22300 (epoch 39.130), train_loss = 0.38859713, grad/param norm = 2.6772e-01, time/batch = 16.9742s	
17453/22300 (epoch 39.132), train_loss = 0.29043041, grad/param norm = 2.8419e-01, time/batch = 17.5560s	
17454/22300 (epoch 39.135), train_loss = 0.29699073, grad/param norm = 2.2601e-01, time/batch = 16.7703s	
17455/22300 (epoch 39.137), train_loss = 0.24037730, grad/param norm = 1.8477e-01, time/batch = 16.1334s	
17456/22300 (epoch 39.139), train_loss = 0.36047606, grad/param norm = 3.6269e-01, time/batch = 15.6462s	
17457/22300 (epoch 39.141), train_loss = 0.46598579, grad/param norm = 2.5232e-01, time/batch = 15.3197s	
17458/22300 (epoch 39.143), train_loss = 0.39526169, grad/param norm = 2.6817e-01, time/batch = 15.6472s	
17459/22300 (epoch 39.146), train_loss = 0.50275874, grad/param norm = 3.2151e-01, time/batch = 16.8900s	
17460/22300 (epoch 39.148), train_loss = 0.32430849, grad/param norm = 2.4094e-01, time/batch = 17.2948s	
17461/22300 (epoch 39.150), train_loss = 0.34667261, grad/param norm = 2.3670e-01, time/batch = 15.4760s	
17462/22300 (epoch 39.152), train_loss = 0.32608611, grad/param norm = 2.8771e-01, time/batch = 15.8702s	
17463/22300 (epoch 39.155), train_loss = 0.33302998, grad/param norm = 2.2317e-01, time/batch = 17.2319s	
17464/22300 (epoch 39.157), train_loss = 0.42462288, grad/param norm = 2.7574e-01, time/batch = 15.8893s	
17465/22300 (epoch 39.159), train_loss = 0.44949896, grad/param norm = 2.7821e-01, time/batch = 15.6294s	
17466/22300 (epoch 39.161), train_loss = 0.44150048, grad/param norm = 2.8524e-01, time/batch = 17.7208s	
17467/22300 (epoch 39.164), train_loss = 0.32425566, grad/param norm = 2.1264e-01, time/batch = 15.7054s	
17468/22300 (epoch 39.166), train_loss = 0.29424826, grad/param norm = 2.1391e-01, time/batch = 17.2816s	
17469/22300 (epoch 39.168), train_loss = 0.29901496, grad/param norm = 2.5499e-01, time/batch = 16.2108s	
17470/22300 (epoch 39.170), train_loss = 0.41112093, grad/param norm = 2.6717e-01, time/batch = 15.5558s	
17471/22300 (epoch 39.173), train_loss = 0.47916350, grad/param norm = 3.4227e-01, time/batch = 17.2968s	
17472/22300 (epoch 39.175), train_loss = 0.39567030, grad/param norm = 2.5829e-01, time/batch = 16.0499s	
17473/22300 (epoch 39.177), train_loss = 0.28846734, grad/param norm = 2.2219e-01, time/batch = 16.2978s	
17474/22300 (epoch 39.179), train_loss = 0.40352404, grad/param norm = 2.6254e-01, time/batch = 15.9035s	
17475/22300 (epoch 39.182), train_loss = 0.56647782, grad/param norm = 3.5892e-01, time/batch = 16.5538s	
17476/22300 (epoch 39.184), train_loss = 0.58807814, grad/param norm = 3.3869e-01, time/batch = 16.1368s	
17477/22300 (epoch 39.186), train_loss = 0.43582007, grad/param norm = 3.1401e-01, time/batch = 18.4551s	
17478/22300 (epoch 39.188), train_loss = 0.60543695, grad/param norm = 3.2717e-01, time/batch = 18.7810s	
17479/22300 (epoch 39.191), train_loss = 0.49427567, grad/param norm = 3.1853e-01, time/batch = 17.6250s	
17480/22300 (epoch 39.193), train_loss = 0.43386671, grad/param norm = 2.8239e-01, time/batch = 16.4404s	
17481/22300 (epoch 39.195), train_loss = 0.39451472, grad/param norm = 2.4575e-01, time/batch = 16.7273s	
17482/22300 (epoch 39.197), train_loss = 0.34153016, grad/param norm = 2.4849e-01, time/batch = 18.0557s	
17483/22300 (epoch 39.200), train_loss = 0.32778695, grad/param norm = 2.6456e-01, time/batch = 16.4030s	
17484/22300 (epoch 39.202), train_loss = 0.32399220, grad/param norm = 2.5196e-01, time/batch = 16.2930s	
17485/22300 (epoch 39.204), train_loss = 0.41524297, grad/param norm = 2.4615e-01, time/batch = 16.7231s	
17486/22300 (epoch 39.206), train_loss = 0.33110282, grad/param norm = 2.5355e-01, time/batch = 17.2947s	
17487/22300 (epoch 39.209), train_loss = 0.34841899, grad/param norm = 2.2563e-01, time/batch = 15.9781s	
17488/22300 (epoch 39.211), train_loss = 0.30020219, grad/param norm = 2.7497e-01, time/batch = 17.0597s	
17489/22300 (epoch 39.213), train_loss = 0.42081547, grad/param norm = 2.6097e-01, time/batch = 14.9627s	
17490/22300 (epoch 39.215), train_loss = 0.50778535, grad/param norm = 2.8924e-01, time/batch = 15.1704s	
17491/22300 (epoch 39.217), train_loss = 0.52987438, grad/param norm = 2.8766e-01, time/batch = 17.1437s	
17492/22300 (epoch 39.220), train_loss = 0.39037693, grad/param norm = 2.2979e-01, time/batch = 15.9860s	
17493/22300 (epoch 39.222), train_loss = 0.34360528, grad/param norm = 2.4327e-01, time/batch = 17.4723s	
17494/22300 (epoch 39.224), train_loss = 0.35282188, grad/param norm = 2.4536e-01, time/batch = 16.5479s	
17495/22300 (epoch 39.226), train_loss = 0.37791298, grad/param norm = 2.3419e-01, time/batch = 17.6232s	
17496/22300 (epoch 39.229), train_loss = 0.31365200, grad/param norm = 2.2783e-01, time/batch = 17.1259s	
17497/22300 (epoch 39.231), train_loss = 0.50495611, grad/param norm = 3.3808e-01, time/batch = 15.8043s	
17498/22300 (epoch 39.233), train_loss = 0.41616164, grad/param norm = 3.3935e-01, time/batch = 16.2967s	
17499/22300 (epoch 39.235), train_loss = 0.31034528, grad/param norm = 2.1470e-01, time/batch = 15.4848s	
17500/22300 (epoch 39.238), train_loss = 0.32792977, grad/param norm = 2.4434e-01, time/batch = 18.7929s	
17501/22300 (epoch 39.240), train_loss = 0.33630949, grad/param norm = 2.0628e-01, time/batch = 16.6250s	
17502/22300 (epoch 39.242), train_loss = 0.29900845, grad/param norm = 2.7255e-01, time/batch = 15.5417s	
17503/22300 (epoch 39.244), train_loss = 0.21256363, grad/param norm = 1.8706e-01, time/batch = 17.0514s	
17504/22300 (epoch 39.247), train_loss = 0.29354438, grad/param norm = 1.8840e-01, time/batch = 15.2374s	
17505/22300 (epoch 39.249), train_loss = 0.20143156, grad/param norm = 1.5226e-01, time/batch = 16.2077s	
17506/22300 (epoch 39.251), train_loss = 0.28016564, grad/param norm = 1.9641e-01, time/batch = 15.7750s	
17507/22300 (epoch 39.253), train_loss = 0.18624290, grad/param norm = 2.0472e-01, time/batch = 17.7333s	
17508/22300 (epoch 39.256), train_loss = 0.27624587, grad/param norm = 2.0943e-01, time/batch = 16.6949s	
17509/22300 (epoch 39.258), train_loss = 0.40632681, grad/param norm = 2.9587e-01, time/batch = 17.5191s	
17510/22300 (epoch 39.260), train_loss = 0.41917646, grad/param norm = 2.8685e-01, time/batch = 17.2186s	
17511/22300 (epoch 39.262), train_loss = 0.31199176, grad/param norm = 2.1621e-01, time/batch = 16.6364s	
17512/22300 (epoch 39.265), train_loss = 0.26510064, grad/param norm = 1.8060e-01, time/batch = 15.7226s	
17513/22300 (epoch 39.267), train_loss = 0.31375285, grad/param norm = 2.0255e-01, time/batch = 17.0774s	
17514/22300 (epoch 39.269), train_loss = 0.39600121, grad/param norm = 3.4750e-01, time/batch = 18.7945s	
17515/22300 (epoch 39.271), train_loss = 0.43293136, grad/param norm = 2.9801e-01, time/batch = 17.0464s	
17516/22300 (epoch 39.274), train_loss = 0.28599457, grad/param norm = 2.1604e-01, time/batch = 15.2111s	
17517/22300 (epoch 39.276), train_loss = 0.24646964, grad/param norm = 1.7295e-01, time/batch = 16.8800s	
17518/22300 (epoch 39.278), train_loss = 0.26959281, grad/param norm = 2.0337e-01, time/batch = 17.7723s	
17519/22300 (epoch 39.280), train_loss = 0.30819036, grad/param norm = 2.3918e-01, time/batch = 15.5351s	
17520/22300 (epoch 39.283), train_loss = 0.24967467, grad/param norm = 2.1827e-01, time/batch = 16.1229s	
17521/22300 (epoch 39.285), train_loss = 0.26218044, grad/param norm = 2.3280e-01, time/batch = 18.8607s	
17522/22300 (epoch 39.287), train_loss = 0.39301752, grad/param norm = 3.4572e-01, time/batch = 16.7819s	
17523/22300 (epoch 39.289), train_loss = 0.36630451, grad/param norm = 2.5342e-01, time/batch = 17.8827s	
17524/22300 (epoch 39.291), train_loss = 0.32997462, grad/param norm = 2.2029e-01, time/batch = 15.8945s	
17525/22300 (epoch 39.294), train_loss = 0.28240044, grad/param norm = 2.1116e-01, time/batch = 16.8718s	
17526/22300 (epoch 39.296), train_loss = 0.32935952, grad/param norm = 2.6908e-01, time/batch = 16.3092s	
17527/22300 (epoch 39.298), train_loss = 0.42288265, grad/param norm = 2.6577e-01, time/batch = 17.4701s	
17528/22300 (epoch 39.300), train_loss = 0.48544132, grad/param norm = 2.8450e-01, time/batch = 16.8069s	
17529/22300 (epoch 39.303), train_loss = 0.39330201, grad/param norm = 3.1174e-01, time/batch = 17.2062s	
17530/22300 (epoch 39.305), train_loss = 0.35794634, grad/param norm = 2.6571e-01, time/batch = 16.7961s	
17531/22300 (epoch 39.307), train_loss = 0.31936644, grad/param norm = 2.5904e-01, time/batch = 17.3049s	
17532/22300 (epoch 39.309), train_loss = 0.26766249, grad/param norm = 1.9715e-01, time/batch = 16.8938s	
17533/22300 (epoch 39.312), train_loss = 0.25545650, grad/param norm = 1.9062e-01, time/batch = 16.4662s	
17534/22300 (epoch 39.314), train_loss = 0.29696976, grad/param norm = 2.0418e-01, time/batch = 17.5537s	
17535/22300 (epoch 39.316), train_loss = 0.28314358, grad/param norm = 2.3188e-01, time/batch = 17.7267s	
17536/22300 (epoch 39.318), train_loss = 0.31337760, grad/param norm = 2.1110e-01, time/batch = 15.3510s	
17537/22300 (epoch 39.321), train_loss = 0.40509156, grad/param norm = 2.5120e-01, time/batch = 17.1405s	
17538/22300 (epoch 39.323), train_loss = 0.28208845, grad/param norm = 2.0697e-01, time/batch = 16.3722s	
17539/22300 (epoch 39.325), train_loss = 0.27502161, grad/param norm = 2.5202e-01, time/batch = 18.7048s	
17540/22300 (epoch 39.327), train_loss = 0.27718426, grad/param norm = 1.8876e-01, time/batch = 15.8586s	
17541/22300 (epoch 39.330), train_loss = 0.28738403, grad/param norm = 2.4037e-01, time/batch = 17.7144s	
17542/22300 (epoch 39.332), train_loss = 0.26812891, grad/param norm = 1.9989e-01, time/batch = 15.0839s	
17543/22300 (epoch 39.334), train_loss = 0.31546973, grad/param norm = 2.9324e-01, time/batch = 16.2751s	
17544/22300 (epoch 39.336), train_loss = 0.32165066, grad/param norm = 2.2171e-01, time/batch = 15.3000s	
17545/22300 (epoch 39.339), train_loss = 0.37389638, grad/param norm = 2.8107e-01, time/batch = 17.6430s	
17546/22300 (epoch 39.341), train_loss = 0.36200525, grad/param norm = 2.3204e-01, time/batch = 15.9004s	
17547/22300 (epoch 39.343), train_loss = 0.40722563, grad/param norm = 2.6336e-01, time/batch = 16.7147s	
17548/22300 (epoch 39.345), train_loss = 0.33950511, grad/param norm = 2.4703e-01, time/batch = 16.3021s	
17549/22300 (epoch 39.348), train_loss = 0.33509756, grad/param norm = 1.8830e-01, time/batch = 18.0693s	
17550/22300 (epoch 39.350), train_loss = 0.25034798, grad/param norm = 1.9727e-01, time/batch = 16.2001s	
17551/22300 (epoch 39.352), train_loss = 0.35709250, grad/param norm = 2.1791e-01, time/batch = 17.3726s	
17552/22300 (epoch 39.354), train_loss = 0.49750135, grad/param norm = 3.0479e-01, time/batch = 18.9615s	
17553/22300 (epoch 39.357), train_loss = 0.46124962, grad/param norm = 2.4428e-01, time/batch = 16.1196s	
17554/22300 (epoch 39.359), train_loss = 0.27249933, grad/param norm = 1.8000e-01, time/batch = 16.6133s	
17555/22300 (epoch 39.361), train_loss = 0.30657436, grad/param norm = 2.9867e-01, time/batch = 17.4635s	
17556/22300 (epoch 39.363), train_loss = 0.39803089, grad/param norm = 2.6575e-01, time/batch = 16.4551s	
17557/22300 (epoch 39.365), train_loss = 0.27946349, grad/param norm = 2.0998e-01, time/batch = 15.6417s	
17558/22300 (epoch 39.368), train_loss = 0.31961300, grad/param norm = 3.4671e-01, time/batch = 16.3023s	
17559/22300 (epoch 39.370), train_loss = 0.32785089, grad/param norm = 2.1211e-01, time/batch = 17.9587s	
17560/22300 (epoch 39.372), train_loss = 0.23729154, grad/param norm = 2.0781e-01, time/batch = 17.3931s	
17561/22300 (epoch 39.374), train_loss = 0.24413596, grad/param norm = 2.0438e-01, time/batch = 27.9895s	
17562/22300 (epoch 39.377), train_loss = 0.32218141, grad/param norm = 2.2161e-01, time/batch = 17.8575s	
17563/22300 (epoch 39.379), train_loss = 0.28660988, grad/param norm = 2.6259e-01, time/batch = 17.1399s	
17564/22300 (epoch 39.381), train_loss = 0.38580316, grad/param norm = 2.4837e-01, time/batch = 16.1242s	
17565/22300 (epoch 39.383), train_loss = 0.30932861, grad/param norm = 2.5052e-01, time/batch = 17.3886s	
17566/22300 (epoch 39.386), train_loss = 0.35892541, grad/param norm = 2.5068e-01, time/batch = 17.0500s	
17567/22300 (epoch 39.388), train_loss = 0.25272963, grad/param norm = 2.0751e-01, time/batch = 16.9721s	
17568/22300 (epoch 39.390), train_loss = 0.27540353, grad/param norm = 2.2848e-01, time/batch = 16.3754s	
17569/22300 (epoch 39.392), train_loss = 0.32488104, grad/param norm = 2.8291e-01, time/batch = 16.9772s	
17570/22300 (epoch 39.395), train_loss = 0.25681222, grad/param norm = 1.8262e-01, time/batch = 17.1399s	
17571/22300 (epoch 39.397), train_loss = 0.18349100, grad/param norm = 1.3771e-01, time/batch = 16.0127s	
17572/22300 (epoch 39.399), train_loss = 0.25649659, grad/param norm = 1.5327e-01, time/batch = 17.2879s	
17573/22300 (epoch 39.401), train_loss = 0.28830946, grad/param norm = 2.1769e-01, time/batch = 15.0416s	
17574/22300 (epoch 39.404), train_loss = 0.31891536, grad/param norm = 2.4011e-01, time/batch = 16.2691s	
17575/22300 (epoch 39.406), train_loss = 0.48939449, grad/param norm = 2.7851e-01, time/batch = 16.0451s	
17576/22300 (epoch 39.408), train_loss = 0.36552032, grad/param norm = 2.3938e-01, time/batch = 16.9681s	
17577/22300 (epoch 39.410), train_loss = 0.40840387, grad/param norm = 3.4876e-01, time/batch = 18.3743s	
17578/22300 (epoch 39.413), train_loss = 0.30179201, grad/param norm = 2.4898e-01, time/batch = 17.1934s	
17579/22300 (epoch 39.415), train_loss = 0.23747407, grad/param norm = 2.8470e-01, time/batch = 16.8156s	
17580/22300 (epoch 39.417), train_loss = 0.36310986, grad/param norm = 2.7522e-01, time/batch = 16.8841s	
17581/22300 (epoch 39.419), train_loss = 0.31758385, grad/param norm = 2.3058e-01, time/batch = 17.3803s	
17582/22300 (epoch 39.422), train_loss = 0.27461313, grad/param norm = 2.0818e-01, time/batch = 16.2219s	
17583/22300 (epoch 39.424), train_loss = 0.33685515, grad/param norm = 2.7138e-01, time/batch = 17.2208s	
17584/22300 (epoch 39.426), train_loss = 0.23131149, grad/param norm = 1.8778e-01, time/batch = 16.3022s	
17585/22300 (epoch 39.428), train_loss = 0.24977510, grad/param norm = 1.8769e-01, time/batch = 17.2053s	
17586/22300 (epoch 39.430), train_loss = 0.29050448, grad/param norm = 2.1250e-01, time/batch = 17.4777s	
17587/22300 (epoch 39.433), train_loss = 0.30898344, grad/param norm = 1.8214e-01, time/batch = 16.1521s	
17588/22300 (epoch 39.435), train_loss = 0.29324584, grad/param norm = 2.1434e-01, time/batch = 16.8157s	
17589/22300 (epoch 39.437), train_loss = 0.33553913, grad/param norm = 2.0027e-01, time/batch = 15.6845s	
17590/22300 (epoch 39.439), train_loss = 0.39526399, grad/param norm = 2.8893e-01, time/batch = 17.6233s	
17591/22300 (epoch 39.442), train_loss = 0.31715462, grad/param norm = 2.1110e-01, time/batch = 15.6863s	
17592/22300 (epoch 39.444), train_loss = 0.28758773, grad/param norm = 2.6611e-01, time/batch = 16.2934s	
17593/22300 (epoch 39.446), train_loss = 0.30665383, grad/param norm = 2.2956e-01, time/batch = 16.2788s	
17594/22300 (epoch 39.448), train_loss = 0.23451015, grad/param norm = 1.8133e-01, time/batch = 17.7995s	
17595/22300 (epoch 39.451), train_loss = 0.37030584, grad/param norm = 2.3420e-01, time/batch = 18.7088s	
17596/22300 (epoch 39.453), train_loss = 0.29006633, grad/param norm = 2.2230e-01, time/batch = 16.0098s	
17597/22300 (epoch 39.455), train_loss = 0.40159944, grad/param norm = 2.9669e-01, time/batch = 15.4556s	
17598/22300 (epoch 39.457), train_loss = 0.53282162, grad/param norm = 3.2680e-01, time/batch = 16.7224s	
17599/22300 (epoch 39.460), train_loss = 0.44034676, grad/param norm = 2.4492e-01, time/batch = 17.7052s	
17600/22300 (epoch 39.462), train_loss = 0.42609728, grad/param norm = 2.4543e-01, time/batch = 16.1408s	
17601/22300 (epoch 39.464), train_loss = 0.37374552, grad/param norm = 3.0875e-01, time/batch = 17.3818s	
17602/22300 (epoch 39.466), train_loss = 0.32887396, grad/param norm = 2.7896e-01, time/batch = 17.3840s	
17603/22300 (epoch 39.469), train_loss = 0.28648269, grad/param norm = 1.7419e-01, time/batch = 15.6382s	
17604/22300 (epoch 39.471), train_loss = 0.41619118, grad/param norm = 2.7202e-01, time/batch = 17.8102s	
17605/22300 (epoch 39.473), train_loss = 0.35796508, grad/param norm = 3.1166e-01, time/batch = 18.2225s	
17606/22300 (epoch 39.475), train_loss = 0.30993848, grad/param norm = 2.4586e-01, time/batch = 17.1358s	
17607/22300 (epoch 39.478), train_loss = 0.32525859, grad/param norm = 2.6345e-01, time/batch = 17.0381s	
17608/22300 (epoch 39.480), train_loss = 0.23278385, grad/param norm = 2.0920e-01, time/batch = 16.0053s	
17609/22300 (epoch 39.482), train_loss = 0.27549350, grad/param norm = 2.0494e-01, time/batch = 17.9724s	
17610/22300 (epoch 39.484), train_loss = 0.35256051, grad/param norm = 2.8529e-01, time/batch = 16.2927s	
17611/22300 (epoch 39.487), train_loss = 0.41840314, grad/param norm = 2.6664e-01, time/batch = 16.7123s	
17612/22300 (epoch 39.489), train_loss = 0.41317549, grad/param norm = 2.8661e-01, time/batch = 17.2173s	
17613/22300 (epoch 39.491), train_loss = 0.43962372, grad/param norm = 3.6242e-01, time/batch = 15.4680s	
17614/22300 (epoch 39.493), train_loss = 0.31411503, grad/param norm = 3.0388e-01, time/batch = 16.3881s	
17615/22300 (epoch 39.496), train_loss = 0.35164008, grad/param norm = 1.9575e-01, time/batch = 16.4848s	
17616/22300 (epoch 39.498), train_loss = 0.23942287, grad/param norm = 2.1386e-01, time/batch = 16.1950s	
17617/22300 (epoch 39.500), train_loss = 0.33290427, grad/param norm = 2.1688e-01, time/batch = 15.5608s	
17618/22300 (epoch 39.502), train_loss = 0.20687024, grad/param norm = 1.6666e-01, time/batch = 17.3050s	
17619/22300 (epoch 39.504), train_loss = 0.23159610, grad/param norm = 1.6561e-01, time/batch = 16.3090s	
17620/22300 (epoch 39.507), train_loss = 0.27215929, grad/param norm = 2.4519e-01, time/batch = 18.3867s	
17621/22300 (epoch 39.509), train_loss = 0.39952999, grad/param norm = 2.2544e-01, time/batch = 17.0417s	
17622/22300 (epoch 39.511), train_loss = 0.22101402, grad/param norm = 2.0257e-01, time/batch = 18.7894s	
17623/22300 (epoch 39.513), train_loss = 0.25645931, grad/param norm = 1.9644e-01, time/batch = 14.9621s	
17624/22300 (epoch 39.516), train_loss = 0.29106107, grad/param norm = 1.8695e-01, time/batch = 16.6388s	
17625/22300 (epoch 39.518), train_loss = 0.37665707, grad/param norm = 2.9772e-01, time/batch = 16.3014s	
17626/22300 (epoch 39.520), train_loss = 0.32218958, grad/param norm = 2.9598e-01, time/batch = 15.3756s	
17627/22300 (epoch 39.522), train_loss = 0.33373522, grad/param norm = 2.2210e-01, time/batch = 16.2953s	
17628/22300 (epoch 39.525), train_loss = 0.24835724, grad/param norm = 1.8348e-01, time/batch = 15.9615s	
17629/22300 (epoch 39.527), train_loss = 0.39935078, grad/param norm = 2.9940e-01, time/batch = 17.3105s	
17630/22300 (epoch 39.529), train_loss = 0.33337108, grad/param norm = 2.2546e-01, time/batch = 16.3846s	
17631/22300 (epoch 39.531), train_loss = 0.30213070, grad/param norm = 2.4354e-01, time/batch = 16.9512s	
17632/22300 (epoch 39.534), train_loss = 0.33554486, grad/param norm = 2.6383e-01, time/batch = 18.1235s	
17633/22300 (epoch 39.536), train_loss = 0.49960146, grad/param norm = 2.8055e-01, time/batch = 14.8307s	
17634/22300 (epoch 39.538), train_loss = 0.60062130, grad/param norm = 3.4098e-01, time/batch = 16.7741s	
17635/22300 (epoch 39.540), train_loss = 0.34490855, grad/param norm = 2.3498e-01, time/batch = 17.3692s	
17636/22300 (epoch 39.543), train_loss = 0.33165106, grad/param norm = 2.1411e-01, time/batch = 18.2997s	
17637/22300 (epoch 39.545), train_loss = 0.23089847, grad/param norm = 1.9422e-01, time/batch = 17.3034s	
17638/22300 (epoch 39.547), train_loss = 0.21180966, grad/param norm = 1.8979e-01, time/batch = 18.0321s	
17639/22300 (epoch 39.549), train_loss = 0.25737867, grad/param norm = 2.3741e-01, time/batch = 17.6145s	
17640/22300 (epoch 39.552), train_loss = 0.26830625, grad/param norm = 2.4710e-01, time/batch = 18.7939s	
17641/22300 (epoch 39.554), train_loss = 0.37796208, grad/param norm = 2.7925e-01, time/batch = 18.6970s	
17642/22300 (epoch 39.556), train_loss = 0.51270194, grad/param norm = 3.9103e-01, time/batch = 15.4697s	
17643/22300 (epoch 39.558), train_loss = 0.37733643, grad/param norm = 3.1398e-01, time/batch = 15.4693s	
17644/22300 (epoch 39.561), train_loss = 0.54190798, grad/param norm = 3.9042e-01, time/batch = 15.7070s	
17645/22300 (epoch 39.563), train_loss = 0.42347958, grad/param norm = 3.0470e-01, time/batch = 17.4662s	
17646/22300 (epoch 39.565), train_loss = 0.31896028, grad/param norm = 2.2391e-01, time/batch = 15.5418s	
17647/22300 (epoch 39.567), train_loss = 0.31702812, grad/param norm = 2.3711e-01, time/batch = 16.2938s	
17648/22300 (epoch 39.570), train_loss = 0.45190711, grad/param norm = 3.6293e-01, time/batch = 17.0534s	
17649/22300 (epoch 39.572), train_loss = 0.44188668, grad/param norm = 2.4772e-01, time/batch = 16.9620s	
17650/22300 (epoch 39.574), train_loss = 0.34327721, grad/param norm = 2.3368e-01, time/batch = 17.0532s	
17651/22300 (epoch 39.576), train_loss = 0.30090053, grad/param norm = 1.9494e-01, time/batch = 16.4787s	
17652/22300 (epoch 39.578), train_loss = 0.18388324, grad/param norm = 1.5607e-01, time/batch = 17.3719s	
17653/22300 (epoch 39.581), train_loss = 0.26579431, grad/param norm = 2.5968e-01, time/batch = 15.6469s	
17654/22300 (epoch 39.583), train_loss = 0.31500670, grad/param norm = 1.9083e-01, time/batch = 17.3826s	
17655/22300 (epoch 39.585), train_loss = 0.42332464, grad/param norm = 3.0248e-01, time/batch = 17.3948s	
17656/22300 (epoch 39.587), train_loss = 0.59300631, grad/param norm = 3.0736e-01, time/batch = 16.8087s	
17657/22300 (epoch 39.590), train_loss = 0.48159226, grad/param norm = 3.7622e-01, time/batch = 16.8001s	
17658/22300 (epoch 39.592), train_loss = 0.56235673, grad/param norm = 3.4601e-01, time/batch = 17.1431s	
17659/22300 (epoch 39.594), train_loss = 0.53031552, grad/param norm = 3.2449e-01, time/batch = 15.8849s	
17660/22300 (epoch 39.596), train_loss = 0.34890084, grad/param norm = 3.2731e-01, time/batch = 15.4175s	
17661/22300 (epoch 39.599), train_loss = 0.23387380, grad/param norm = 1.9724e-01, time/batch = 17.9598s	
17662/22300 (epoch 39.601), train_loss = 0.28760019, grad/param norm = 2.5131e-01, time/batch = 16.2029s	
17663/22300 (epoch 39.603), train_loss = 0.30236138, grad/param norm = 2.0683e-01, time/batch = 15.7132s	
17664/22300 (epoch 39.605), train_loss = 0.34412329, grad/param norm = 2.3884e-01, time/batch = 15.7385s	
17665/22300 (epoch 39.608), train_loss = 0.53997012, grad/param norm = 3.5380e-01, time/batch = 18.6314s	
17666/22300 (epoch 39.610), train_loss = 0.57358543, grad/param norm = 2.7524e-01, time/batch = 16.4837s	
17667/22300 (epoch 39.612), train_loss = 0.44003011, grad/param norm = 2.9647e-01, time/batch = 15.0453s	
17668/22300 (epoch 39.614), train_loss = 0.40681548, grad/param norm = 3.1705e-01, time/batch = 16.3043s	
17669/22300 (epoch 39.617), train_loss = 0.42357469, grad/param norm = 2.2839e-01, time/batch = 17.4751s	
17670/22300 (epoch 39.619), train_loss = 0.44429751, grad/param norm = 2.5387e-01, time/batch = 15.8146s	
17671/22300 (epoch 39.621), train_loss = 0.30361681, grad/param norm = 2.5109e-01, time/batch = 15.3359s	
17672/22300 (epoch 39.623), train_loss = 0.31751486, grad/param norm = 2.8002e-01, time/batch = 18.6913s	
17673/22300 (epoch 39.626), train_loss = 0.32089676, grad/param norm = 2.6186e-01, time/batch = 18.6356s	
17674/22300 (epoch 39.628), train_loss = 0.31295523, grad/param norm = 1.9475e-01, time/batch = 16.6356s	
17675/22300 (epoch 39.630), train_loss = 0.37089845, grad/param norm = 3.1531e-01, time/batch = 17.6386s	
17676/22300 (epoch 39.632), train_loss = 0.31337511, grad/param norm = 3.3901e-01, time/batch = 17.3052s	
17677/22300 (epoch 39.635), train_loss = 0.35883457, grad/param norm = 2.3465e-01, time/batch = 16.9716s	
17678/22300 (epoch 39.637), train_loss = 0.39553596, grad/param norm = 2.6840e-01, time/batch = 16.6543s	
17679/22300 (epoch 39.639), train_loss = 0.48686717, grad/param norm = 2.9705e-01, time/batch = 15.3848s	
17680/22300 (epoch 39.641), train_loss = 0.38400433, grad/param norm = 2.6250e-01, time/batch = 17.7254s	
17681/22300 (epoch 39.643), train_loss = 0.30652743, grad/param norm = 2.4294e-01, time/batch = 15.7706s	
17682/22300 (epoch 39.646), train_loss = 0.30195449, grad/param norm = 2.2885e-01, time/batch = 16.7889s	
17683/22300 (epoch 39.648), train_loss = 0.41169647, grad/param norm = 2.2431e-01, time/batch = 17.2277s	
17684/22300 (epoch 39.650), train_loss = 0.41650003, grad/param norm = 2.8104e-01, time/batch = 17.7103s	
17685/22300 (epoch 39.652), train_loss = 0.32706224, grad/param norm = 2.2053e-01, time/batch = 16.3710s	
17686/22300 (epoch 39.655), train_loss = 0.27910662, grad/param norm = 2.3623e-01, time/batch = 16.4723s	
17687/22300 (epoch 39.657), train_loss = 0.32402248, grad/param norm = 2.6110e-01, time/batch = 15.0512s	
17688/22300 (epoch 39.659), train_loss = 0.30318410, grad/param norm = 2.6173e-01, time/batch = 16.1432s	
17689/22300 (epoch 39.661), train_loss = 0.25434531, grad/param norm = 1.9972e-01, time/batch = 16.9761s	
17690/22300 (epoch 39.664), train_loss = 0.31365472, grad/param norm = 2.2008e-01, time/batch = 15.4417s	
17691/22300 (epoch 39.666), train_loss = 0.38504478, grad/param norm = 2.4510e-01, time/batch = 18.6356s	
17692/22300 (epoch 39.668), train_loss = 0.28120733, grad/param norm = 2.1139e-01, time/batch = 15.6058s	
17693/22300 (epoch 39.670), train_loss = 0.35445275, grad/param norm = 2.1250e-01, time/batch = 16.5724s	
17694/22300 (epoch 39.673), train_loss = 0.45121409, grad/param norm = 3.0092e-01, time/batch = 15.5990s	
17695/22300 (epoch 39.675), train_loss = 0.47067181, grad/param norm = 3.4804e-01, time/batch = 17.7947s	
17696/22300 (epoch 39.677), train_loss = 0.53343494, grad/param norm = 2.8003e-01, time/batch = 16.2214s	
17697/22300 (epoch 39.679), train_loss = 0.36086003, grad/param norm = 2.8273e-01, time/batch = 16.5304s	
17698/22300 (epoch 39.682), train_loss = 0.35340304, grad/param norm = 2.5821e-01, time/batch = 17.8824s	
17699/22300 (epoch 39.684), train_loss = 0.33590456, grad/param norm = 2.0499e-01, time/batch = 15.5430s	
17700/22300 (epoch 39.686), train_loss = 0.31815951, grad/param norm = 2.4560e-01, time/batch = 17.3693s	
17701/22300 (epoch 39.688), train_loss = 0.31407362, grad/param norm = 3.0153e-01, time/batch = 15.4697s	
17702/22300 (epoch 39.691), train_loss = 0.29566255, grad/param norm = 3.1375e-01, time/batch = 16.8863s	
17703/22300 (epoch 39.693), train_loss = 0.27198159, grad/param norm = 2.2201e-01, time/batch = 15.1650s	
17704/22300 (epoch 39.695), train_loss = 0.31008817, grad/param norm = 2.5197e-01, time/batch = 14.8966s	
17705/22300 (epoch 39.697), train_loss = 0.32362181, grad/param norm = 2.1770e-01, time/batch = 16.0613s	
17706/22300 (epoch 39.700), train_loss = 0.29776569, grad/param norm = 2.3458e-01, time/batch = 17.3811s	
17707/22300 (epoch 39.702), train_loss = 0.22865535, grad/param norm = 2.0180e-01, time/batch = 16.0533s	
17708/22300 (epoch 39.704), train_loss = 0.32357344, grad/param norm = 2.9454e-01, time/batch = 16.4818s	
17709/22300 (epoch 39.706), train_loss = 0.28658500, grad/param norm = 2.2705e-01, time/batch = 18.6166s	
17710/22300 (epoch 39.709), train_loss = 0.22668151, grad/param norm = 1.8381e-01, time/batch = 16.1466s	
17711/22300 (epoch 39.711), train_loss = 0.22878433, grad/param norm = 1.5914e-01, time/batch = 16.1185s	
17712/22300 (epoch 39.713), train_loss = 0.35059833, grad/param norm = 2.8113e-01, time/batch = 17.3083s	
17713/22300 (epoch 39.715), train_loss = 0.36288801, grad/param norm = 2.6291e-01, time/batch = 17.1215s	
17714/22300 (epoch 39.717), train_loss = 0.48806988, grad/param norm = 3.0215e-01, time/batch = 16.6307s	
17715/22300 (epoch 39.720), train_loss = 0.29156479, grad/param norm = 2.0708e-01, time/batch = 16.3829s	
17716/22300 (epoch 39.722), train_loss = 0.33447478, grad/param norm = 2.2051e-01, time/batch = 16.1476s	
17717/22300 (epoch 39.724), train_loss = 0.38472160, grad/param norm = 3.0013e-01, time/batch = 15.2179s	
17718/22300 (epoch 39.726), train_loss = 0.30607867, grad/param norm = 2.8834e-01, time/batch = 16.1151s	
17719/22300 (epoch 39.729), train_loss = 0.34981716, grad/param norm = 2.2517e-01, time/batch = 18.3801s	
17720/22300 (epoch 39.731), train_loss = 0.43401237, grad/param norm = 3.1497e-01, time/batch = 17.5469s	
17721/22300 (epoch 39.733), train_loss = 0.43942356, grad/param norm = 3.0816e-01, time/batch = 15.0551s	
17722/22300 (epoch 39.735), train_loss = 0.46971602, grad/param norm = 3.1364e-01, time/batch = 15.8339s	
17723/22300 (epoch 39.738), train_loss = 0.34864566, grad/param norm = 3.0609e-01, time/batch = 16.3971s	
17724/22300 (epoch 39.740), train_loss = 0.31664381, grad/param norm = 2.0701e-01, time/batch = 16.7146s	
17725/22300 (epoch 39.742), train_loss = 0.28846855, grad/param norm = 2.5905e-01, time/batch = 16.3923s	
17726/22300 (epoch 39.744), train_loss = 0.50240040, grad/param norm = 2.6370e-01, time/batch = 16.7162s	
17727/22300 (epoch 39.747), train_loss = 0.41343588, grad/param norm = 2.4562e-01, time/batch = 17.4752s	
17728/22300 (epoch 39.749), train_loss = 0.51679139, grad/param norm = 3.0458e-01, time/batch = 15.8806s	
17729/22300 (epoch 39.751), train_loss = 0.46076069, grad/param norm = 3.9132e-01, time/batch = 16.9410s	
17730/22300 (epoch 39.753), train_loss = 0.48023083, grad/param norm = 3.7765e-01, time/batch = 15.3998s	
17731/22300 (epoch 39.756), train_loss = 0.44461208, grad/param norm = 2.3097e-01, time/batch = 18.0563s	
17732/22300 (epoch 39.758), train_loss = 0.35855714, grad/param norm = 1.9432e-01, time/batch = 16.1272s	
17733/22300 (epoch 39.760), train_loss = 0.40098109, grad/param norm = 2.3456e-01, time/batch = 16.6792s	
17734/22300 (epoch 39.762), train_loss = 0.36803614, grad/param norm = 2.6058e-01, time/batch = 16.8137s	
17735/22300 (epoch 39.765), train_loss = 0.42241739, grad/param norm = 2.7756e-01, time/batch = 15.9459s	
17736/22300 (epoch 39.767), train_loss = 0.36808680, grad/param norm = 2.6175e-01, time/batch = 16.6350s	
17737/22300 (epoch 39.769), train_loss = 0.37052096, grad/param norm = 2.6701e-01, time/batch = 14.5720s	
17738/22300 (epoch 39.771), train_loss = 0.40993734, grad/param norm = 2.7939e-01, time/batch = 16.1460s	
17739/22300 (epoch 39.774), train_loss = 0.47285932, grad/param norm = 4.6781e-01, time/batch = 15.8818s	
17740/22300 (epoch 39.776), train_loss = 0.48997485, grad/param norm = 2.6799e-01, time/batch = 16.2999s	
17741/22300 (epoch 39.778), train_loss = 0.46388489, grad/param norm = 2.5919e-01, time/batch = 15.4478s	
17742/22300 (epoch 39.780), train_loss = 0.46454323, grad/param norm = 3.6421e-01, time/batch = 17.3068s	
17743/22300 (epoch 39.783), train_loss = 0.51072954, grad/param norm = 3.5804e-01, time/batch = 15.0463s	
17744/22300 (epoch 39.785), train_loss = 0.35853386, grad/param norm = 5.3794e-01, time/batch = 17.6381s	
17745/22300 (epoch 39.787), train_loss = 0.35960137, grad/param norm = 2.7368e-01, time/batch = 17.3795s	
17746/22300 (epoch 39.789), train_loss = 0.51386410, grad/param norm = 3.3053e-01, time/batch = 17.1421s	
17747/22300 (epoch 39.791), train_loss = 0.64477017, grad/param norm = 3.5912e-01, time/batch = 16.9767s	
17748/22300 (epoch 39.794), train_loss = 0.51390522, grad/param norm = 3.6955e-01, time/batch = 17.3070s	
17749/22300 (epoch 39.796), train_loss = 0.45654990, grad/param norm = 3.1641e-01, time/batch = 15.4550s	
17750/22300 (epoch 39.798), train_loss = 0.60223314, grad/param norm = 3.4696e-01, time/batch = 15.4767s	
17751/22300 (epoch 39.800), train_loss = 0.39783524, grad/param norm = 2.4775e-01, time/batch = 16.8126s	
17752/22300 (epoch 39.803), train_loss = 0.35470799, grad/param norm = 2.4420e-01, time/batch = 16.2932s	
17753/22300 (epoch 39.805), train_loss = 0.41591624, grad/param norm = 3.1845e-01, time/batch = 16.5554s	
17754/22300 (epoch 39.807), train_loss = 0.53042234, grad/param norm = 3.3228e-01, time/batch = 16.1488s	
17755/22300 (epoch 39.809), train_loss = 0.38536591, grad/param norm = 2.6584e-01, time/batch = 16.8131s	
17756/22300 (epoch 39.812), train_loss = 0.42638365, grad/param norm = 3.1608e-01, time/batch = 17.7285s	
17757/22300 (epoch 39.814), train_loss = 0.43557721, grad/param norm = 3.1511e-01, time/batch = 15.4753s	
17758/22300 (epoch 39.816), train_loss = 0.44680100, grad/param norm = 3.0483e-01, time/batch = 16.4405s	
17759/22300 (epoch 39.818), train_loss = 0.49869091, grad/param norm = 3.5508e-01, time/batch = 16.5564s	
17760/22300 (epoch 39.821), train_loss = 0.42734662, grad/param norm = 2.8926e-01, time/batch = 16.8738s	
17761/22300 (epoch 39.823), train_loss = 0.27968923, grad/param norm = 2.1301e-01, time/batch = 15.6255s	
17762/22300 (epoch 39.825), train_loss = 0.30566668, grad/param norm = 2.2775e-01, time/batch = 16.9547s	
17763/22300 (epoch 39.827), train_loss = 0.36570705, grad/param norm = 3.0325e-01, time/batch = 15.2108s	
17764/22300 (epoch 39.830), train_loss = 0.36040491, grad/param norm = 3.2058e-01, time/batch = 17.3030s	
17765/22300 (epoch 39.832), train_loss = 0.33586779, grad/param norm = 2.3552e-01, time/batch = 16.9656s	
17766/22300 (epoch 39.834), train_loss = 0.28314500, grad/param norm = 2.4517e-01, time/batch = 17.1251s	
17767/22300 (epoch 39.836), train_loss = 0.34670301, grad/param norm = 2.3769e-01, time/batch = 16.6411s	
17768/22300 (epoch 39.839), train_loss = 0.40287192, grad/param norm = 2.4630e-01, time/batch = 16.3740s	
17769/22300 (epoch 39.841), train_loss = 0.34733388, grad/param norm = 3.3213e-01, time/batch = 15.9683s	
17770/22300 (epoch 39.843), train_loss = 0.37107381, grad/param norm = 2.5293e-01, time/batch = 16.3615s	
17771/22300 (epoch 39.845), train_loss = 0.36140215, grad/param norm = 2.2551e-01, time/batch = 15.7287s	
17772/22300 (epoch 39.848), train_loss = 0.34327798, grad/param norm = 2.9546e-01, time/batch = 15.5553s	
17773/22300 (epoch 39.850), train_loss = 0.38217471, grad/param norm = 2.5192e-01, time/batch = 17.1304s	
17774/22300 (epoch 39.852), train_loss = 0.34010516, grad/param norm = 2.6817e-01, time/batch = 17.5567s	
17775/22300 (epoch 39.854), train_loss = 0.55338739, grad/param norm = 3.6814e-01, time/batch = 23.3746s	
17776/22300 (epoch 39.857), train_loss = 0.42029796, grad/param norm = 3.1671e-01, time/batch = 21.9514s	
17777/22300 (epoch 39.859), train_loss = 0.32303114, grad/param norm = 1.9377e-01, time/batch = 14.5034s	
17778/22300 (epoch 39.861), train_loss = 0.44025897, grad/param norm = 2.7058e-01, time/batch = 16.3556s	
17779/22300 (epoch 39.863), train_loss = 0.27817062, grad/param norm = 2.0374e-01, time/batch = 15.8030s	
17780/22300 (epoch 39.865), train_loss = 0.29063448, grad/param norm = 2.6805e-01, time/batch = 16.6321s	
17781/22300 (epoch 39.868), train_loss = 0.39280069, grad/param norm = 2.2848e-01, time/batch = 17.8751s	
17782/22300 (epoch 39.870), train_loss = 0.40730541, grad/param norm = 2.9319e-01, time/batch = 16.2702s	
17783/22300 (epoch 39.872), train_loss = 0.47355242, grad/param norm = 2.6025e-01, time/batch = 17.6492s	
17784/22300 (epoch 39.874), train_loss = 0.41011943, grad/param norm = 3.0877e-01, time/batch = 17.5383s	
17785/22300 (epoch 39.877), train_loss = 0.37455802, grad/param norm = 2.4494e-01, time/batch = 16.1223s	
17786/22300 (epoch 39.879), train_loss = 0.34644515, grad/param norm = 2.0999e-01, time/batch = 16.3870s	
17787/22300 (epoch 39.881), train_loss = 0.27908197, grad/param norm = 2.3676e-01, time/batch = 16.0589s	
17788/22300 (epoch 39.883), train_loss = 0.28908377, grad/param norm = 1.8117e-01, time/batch = 16.7328s	
17789/22300 (epoch 39.886), train_loss = 0.28455075, grad/param norm = 3.2798e-01, time/batch = 15.3816s	
17790/22300 (epoch 39.888), train_loss = 0.33242247, grad/param norm = 2.5567e-01, time/batch = 15.9791s	
17791/22300 (epoch 39.890), train_loss = 0.33491982, grad/param norm = 2.2433e-01, time/batch = 17.8880s	
17792/22300 (epoch 39.892), train_loss = 0.50717084, grad/param norm = 2.7455e-01, time/batch = 16.4703s	
17793/22300 (epoch 39.895), train_loss = 0.43572026, grad/param norm = 2.8434e-01, time/batch = 15.7672s	
17794/22300 (epoch 39.897), train_loss = 0.35007898, grad/param norm = 2.5441e-01, time/batch = 17.2146s	
17795/22300 (epoch 39.899), train_loss = 0.34760335, grad/param norm = 2.6195e-01, time/batch = 16.5516s	
17796/22300 (epoch 39.901), train_loss = 0.42619266, grad/param norm = 2.4243e-01, time/batch = 15.2275s	
17797/22300 (epoch 39.904), train_loss = 0.41372114, grad/param norm = 2.5229e-01, time/batch = 17.3176s	
17798/22300 (epoch 39.906), train_loss = 0.39384367, grad/param norm = 2.4865e-01, time/batch = 16.9696s	
17799/22300 (epoch 39.908), train_loss = 0.35454348, grad/param norm = 1.9738e-01, time/batch = 16.4759s	
17800/22300 (epoch 39.910), train_loss = 0.33015038, grad/param norm = 2.2885e-01, time/batch = 15.4433s	
17801/22300 (epoch 39.913), train_loss = 0.39635148, grad/param norm = 2.8652e-01, time/batch = 16.3968s	
17802/22300 (epoch 39.915), train_loss = 0.52862893, grad/param norm = 2.9594e-01, time/batch = 16.8984s	
17803/22300 (epoch 39.917), train_loss = 0.42027232, grad/param norm = 2.6785e-01, time/batch = 17.5353s	
17804/22300 (epoch 39.919), train_loss = 0.38470681, grad/param norm = 2.1089e-01, time/batch = 17.2246s	
17805/22300 (epoch 39.922), train_loss = 0.39067332, grad/param norm = 2.6570e-01, time/batch = 16.9410s	
17806/22300 (epoch 39.924), train_loss = 0.23821024, grad/param norm = 1.8052e-01, time/batch = 14.8815s	
17807/22300 (epoch 39.926), train_loss = 0.32263753, grad/param norm = 2.1525e-01, time/batch = 16.4620s	
17808/22300 (epoch 39.928), train_loss = 0.32871089, grad/param norm = 2.3553e-01, time/batch = 18.0415s	
17809/22300 (epoch 39.930), train_loss = 0.32465329, grad/param norm = 2.5034e-01, time/batch = 17.2247s	
17810/22300 (epoch 39.933), train_loss = 0.39263427, grad/param norm = 2.8089e-01, time/batch = 17.7199s	
17811/22300 (epoch 39.935), train_loss = 0.37914612, grad/param norm = 3.1507e-01, time/batch = 16.1099s	
17812/22300 (epoch 39.937), train_loss = 0.46831735, grad/param norm = 2.9873e-01, time/batch = 15.1556s	
17813/22300 (epoch 39.939), train_loss = 0.43753974, grad/param norm = 3.1429e-01, time/batch = 16.4014s	
17814/22300 (epoch 39.942), train_loss = 0.52946919, grad/param norm = 3.7333e-01, time/batch = 15.3140s	
17815/22300 (epoch 39.944), train_loss = 0.56088080, grad/param norm = 3.4829e-01, time/batch = 16.8073s	
17816/22300 (epoch 39.946), train_loss = 0.39830060, grad/param norm = 2.4319e-01, time/batch = 16.2981s	
17817/22300 (epoch 39.948), train_loss = 0.35135659, grad/param norm = 2.2590e-01, time/batch = 18.5385s	
17818/22300 (epoch 39.951), train_loss = 0.28238738, grad/param norm = 2.2199e-01, time/batch = 15.7277s	
17819/22300 (epoch 39.953), train_loss = 0.31360190, grad/param norm = 2.6998e-01, time/batch = 15.8207s	
17820/22300 (epoch 39.955), train_loss = 0.48668639, grad/param norm = 3.2528e-01, time/batch = 17.0697s	
17821/22300 (epoch 39.957), train_loss = 0.56836081, grad/param norm = 3.1818e-01, time/batch = 16.3735s	
17822/22300 (epoch 39.960), train_loss = 0.50684994, grad/param norm = 3.1331e-01, time/batch = 16.8133s	
17823/22300 (epoch 39.962), train_loss = 0.31350093, grad/param norm = 2.5887e-01, time/batch = 15.7926s	
17824/22300 (epoch 39.964), train_loss = 0.32681590, grad/param norm = 2.6299e-01, time/batch = 17.0963s	
17825/22300 (epoch 39.966), train_loss = 0.33843462, grad/param norm = 2.1903e-01, time/batch = 15.7690s	
17826/22300 (epoch 39.969), train_loss = 0.34225132, grad/param norm = 2.1357e-01, time/batch = 16.4332s	
17827/22300 (epoch 39.971), train_loss = 0.37865659, grad/param norm = 2.2610e-01, time/batch = 16.9771s	
17828/22300 (epoch 39.973), train_loss = 0.35061850, grad/param norm = 2.3788e-01, time/batch = 18.9132s	
17829/22300 (epoch 39.975), train_loss = 0.49650762, grad/param norm = 3.3526e-01, time/batch = 17.2110s	
17830/22300 (epoch 39.978), train_loss = 0.49469345, grad/param norm = 2.9593e-01, time/batch = 17.1365s	
17831/22300 (epoch 39.980), train_loss = 0.56076861, grad/param norm = 3.3308e-01, time/batch = 17.6397s	
17832/22300 (epoch 39.982), train_loss = 0.28456546, grad/param norm = 2.1947e-01, time/batch = 15.8041s	
17833/22300 (epoch 39.984), train_loss = 0.36336354, grad/param norm = 2.2713e-01, time/batch = 17.6393s	
17834/22300 (epoch 39.987), train_loss = 0.38054180, grad/param norm = 2.8670e-01, time/batch = 16.2339s	
17835/22300 (epoch 39.989), train_loss = 0.30826585, grad/param norm = 3.0179e-01, time/batch = 16.6367s	
17836/22300 (epoch 39.991), train_loss = 0.54739582, grad/param norm = 3.8944e-01, time/batch = 16.8921s	
17837/22300 (epoch 39.993), train_loss = 0.75334823, grad/param norm = 5.0574e-01, time/batch = 16.8931s	
17838/22300 (epoch 39.996), train_loss = 0.67656180, grad/param norm = 3.7993e-01, time/batch = 16.7020s	
17839/22300 (epoch 39.998), train_loss = 0.42534703, grad/param norm = 2.8286e-01, time/batch = 16.1154s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
17840/22300 (epoch 40.000), train_loss = 0.33535739, grad/param norm = 2.5402e-01, time/batch = 15.3853s	
17841/22300 (epoch 40.002), train_loss = 0.70005099, grad/param norm = 3.5471e-01, time/batch = 16.3027s	
17842/22300 (epoch 40.004), train_loss = 0.46270445, grad/param norm = 2.7984e-01, time/batch = 16.1385s	
17843/22300 (epoch 40.007), train_loss = 0.44726669, grad/param norm = 2.5723e-01, time/batch = 16.4566s	
17844/22300 (epoch 40.009), train_loss = 0.48215806, grad/param norm = 3.5955e-01, time/batch = 18.2113s	
17845/22300 (epoch 40.011), train_loss = 0.58176463, grad/param norm = 3.1606e-01, time/batch = 15.4839s	
17846/22300 (epoch 40.013), train_loss = 0.45775976, grad/param norm = 2.7014e-01, time/batch = 15.9514s	
17847/22300 (epoch 40.016), train_loss = 0.36742690, grad/param norm = 2.8542e-01, time/batch = 17.2279s	
17848/22300 (epoch 40.018), train_loss = 0.38842877, grad/param norm = 2.8983e-01, time/batch = 14.7284s	
17849/22300 (epoch 40.020), train_loss = 0.36621659, grad/param norm = 2.5750e-01, time/batch = 16.0483s	
17850/22300 (epoch 40.022), train_loss = 0.29254635, grad/param norm = 2.6283e-01, time/batch = 16.1375s	
17851/22300 (epoch 40.025), train_loss = 0.33975265, grad/param norm = 2.3466e-01, time/batch = 16.4692s	
17852/22300 (epoch 40.027), train_loss = 0.31321965, grad/param norm = 1.8710e-01, time/batch = 16.8912s	
17853/22300 (epoch 40.029), train_loss = 0.34626355, grad/param norm = 2.4390e-01, time/batch = 18.8805s	
17854/22300 (epoch 40.031), train_loss = 0.33610785, grad/param norm = 2.4371e-01, time/batch = 16.0458s	
17855/22300 (epoch 40.034), train_loss = 0.32194700, grad/param norm = 2.2350e-01, time/batch = 15.9551s	
17856/22300 (epoch 40.036), train_loss = 0.29141235, grad/param norm = 2.0158e-01, time/batch = 16.3794s	
17857/22300 (epoch 40.038), train_loss = 0.28280290, grad/param norm = 2.2763e-01, time/batch = 15.2648s	
17858/22300 (epoch 40.040), train_loss = 0.33550420, grad/param norm = 2.5464e-01, time/batch = 15.9799s	
17859/22300 (epoch 40.043), train_loss = 0.53691790, grad/param norm = 3.5379e-01, time/batch = 16.0595s	
17860/22300 (epoch 40.045), train_loss = 0.47106154, grad/param norm = 2.8115e-01, time/batch = 18.2169s	
17861/22300 (epoch 40.047), train_loss = 0.48536937, grad/param norm = 2.8019e-01, time/batch = 16.8780s	
17862/22300 (epoch 40.049), train_loss = 0.37788473, grad/param norm = 2.5893e-01, time/batch = 14.9832s	
17863/22300 (epoch 40.052), train_loss = 0.43464672, grad/param norm = 2.7594e-01, time/batch = 16.9651s	
17864/22300 (epoch 40.054), train_loss = 0.43789181, grad/param norm = 2.7807e-01, time/batch = 18.2844s	
17865/22300 (epoch 40.056), train_loss = 0.22591927, grad/param norm = 2.4593e-01, time/batch = 16.3091s	
17866/22300 (epoch 40.058), train_loss = 0.36234087, grad/param norm = 2.6396e-01, time/batch = 17.3088s	
17867/22300 (epoch 40.061), train_loss = 0.31046492, grad/param norm = 2.5153e-01, time/batch = 16.8009s	
17868/22300 (epoch 40.063), train_loss = 0.50968775, grad/param norm = 4.1949e-01, time/batch = 15.7955s	
17869/22300 (epoch 40.065), train_loss = 0.56153829, grad/param norm = 3.7061e-01, time/batch = 16.5449s	
17870/22300 (epoch 40.067), train_loss = 0.30108258, grad/param norm = 2.0578e-01, time/batch = 16.6843s	
17871/22300 (epoch 40.070), train_loss = 0.37230947, grad/param norm = 2.6453e-01, time/batch = 18.3020s	
17872/22300 (epoch 40.072), train_loss = 0.42748125, grad/param norm = 3.0881e-01, time/batch = 16.3030s	
17873/22300 (epoch 40.074), train_loss = 0.43092161, grad/param norm = 3.3542e-01, time/batch = 17.4754s	
17874/22300 (epoch 40.076), train_loss = 0.41555527, grad/param norm = 2.9304e-01, time/batch = 17.8683s	
17875/22300 (epoch 40.078), train_loss = 0.52529457, grad/param norm = 3.4606e-01, time/batch = 16.6335s	
17876/22300 (epoch 40.081), train_loss = 0.51411832, grad/param norm = 3.5770e-01, time/batch = 15.5381s	
17877/22300 (epoch 40.083), train_loss = 0.58631335, grad/param norm = 4.7722e-01, time/batch = 15.9640s	
17878/22300 (epoch 40.085), train_loss = 0.55386572, grad/param norm = 3.4804e-01, time/batch = 16.3932s	
17879/22300 (epoch 40.087), train_loss = 0.44047533, grad/param norm = 2.9397e-01, time/batch = 15.9421s	
17880/22300 (epoch 40.090), train_loss = 0.41528390, grad/param norm = 3.2884e-01, time/batch = 17.8074s	
17881/22300 (epoch 40.092), train_loss = 0.32016205, grad/param norm = 2.3976e-01, time/batch = 16.8101s	
17882/22300 (epoch 40.094), train_loss = 0.31377765, grad/param norm = 2.2532e-01, time/batch = 16.6263s	
17883/22300 (epoch 40.096), train_loss = 0.52576208, grad/param norm = 3.0737e-01, time/batch = 18.2888s	
17884/22300 (epoch 40.099), train_loss = 0.35703771, grad/param norm = 2.4779e-01, time/batch = 17.6470s	
17885/22300 (epoch 40.101), train_loss = 0.48490757, grad/param norm = 3.0987e-01, time/batch = 16.3730s	
17886/22300 (epoch 40.103), train_loss = 0.37065153, grad/param norm = 2.2927e-01, time/batch = 15.2088s	
17887/22300 (epoch 40.105), train_loss = 0.30112195, grad/param norm = 2.8327e-01, time/batch = 16.3760s	
17888/22300 (epoch 40.108), train_loss = 0.43518086, grad/param norm = 2.7918e-01, time/batch = 18.0631s	
17889/22300 (epoch 40.110), train_loss = 0.48767956, grad/param norm = 2.6248e-01, time/batch = 17.2143s	
17890/22300 (epoch 40.112), train_loss = 0.41005102, grad/param norm = 2.2193e-01, time/batch = 16.3107s	
17891/22300 (epoch 40.114), train_loss = 0.46543080, grad/param norm = 3.0066e-01, time/batch = 19.4530s	
17892/22300 (epoch 40.117), train_loss = 0.54880655, grad/param norm = 2.9924e-01, time/batch = 16.5156s	
17893/22300 (epoch 40.119), train_loss = 0.48960155, grad/param norm = 3.1034e-01, time/batch = 17.7761s	
17894/22300 (epoch 40.121), train_loss = 0.56448192, grad/param norm = 3.7192e-01, time/batch = 17.5537s	
17895/22300 (epoch 40.123), train_loss = 0.58310527, grad/param norm = 3.0928e-01, time/batch = 15.4785s	
17896/22300 (epoch 40.126), train_loss = 0.46990940, grad/param norm = 2.5595e-01, time/batch = 14.3197s	
17897/22300 (epoch 40.128), train_loss = 0.42378853, grad/param norm = 2.7254e-01, time/batch = 15.3031s	
17898/22300 (epoch 40.130), train_loss = 0.38409638, grad/param norm = 2.8354e-01, time/batch = 17.2333s	
17899/22300 (epoch 40.132), train_loss = 0.27012682, grad/param norm = 1.8755e-01, time/batch = 16.3214s	
17900/22300 (epoch 40.135), train_loss = 0.30768310, grad/param norm = 2.5825e-01, time/batch = 16.1952s	
17901/22300 (epoch 40.137), train_loss = 0.23885356, grad/param norm = 1.9737e-01, time/batch = 16.6896s	
17902/22300 (epoch 40.139), train_loss = 0.35404924, grad/param norm = 2.7891e-01, time/batch = 16.5481s	
17903/22300 (epoch 40.141), train_loss = 0.47561998, grad/param norm = 2.4135e-01, time/batch = 18.5453s	
17904/22300 (epoch 40.143), train_loss = 0.39222697, grad/param norm = 2.9914e-01, time/batch = 15.8820s	
17905/22300 (epoch 40.146), train_loss = 0.49747332, grad/param norm = 3.3045e-01, time/batch = 14.9849s	
17906/22300 (epoch 40.148), train_loss = 0.31913594, grad/param norm = 2.2064e-01, time/batch = 18.4608s	
17907/22300 (epoch 40.150), train_loss = 0.35006048, grad/param norm = 2.6749e-01, time/batch = 17.3077s	
17908/22300 (epoch 40.152), train_loss = 0.30180750, grad/param norm = 2.5445e-01, time/batch = 16.3956s	
17909/22300 (epoch 40.155), train_loss = 0.31326005, grad/param norm = 2.0563e-01, time/batch = 16.7253s	
17910/22300 (epoch 40.157), train_loss = 0.43804464, grad/param norm = 3.3056e-01, time/batch = 17.2196s	
17911/22300 (epoch 40.159), train_loss = 0.43060978, grad/param norm = 2.7705e-01, time/batch = 16.0528s	
17912/22300 (epoch 40.161), train_loss = 0.44243709, grad/param norm = 2.9041e-01, time/batch = 16.4810s	
17913/22300 (epoch 40.164), train_loss = 0.31811493, grad/param norm = 2.3031e-01, time/batch = 14.8149s	
17914/22300 (epoch 40.166), train_loss = 0.27933755, grad/param norm = 2.0010e-01, time/batch = 16.3945s	
17915/22300 (epoch 40.168), train_loss = 0.27456197, grad/param norm = 2.1725e-01, time/batch = 16.2834s	
17916/22300 (epoch 40.170), train_loss = 0.39068906, grad/param norm = 2.4643e-01, time/batch = 17.7179s	
17917/22300 (epoch 40.173), train_loss = 0.43647791, grad/param norm = 3.1687e-01, time/batch = 16.9694s	
17918/22300 (epoch 40.175), train_loss = 0.37310930, grad/param norm = 2.6334e-01, time/batch = 15.4200s	
17919/22300 (epoch 40.177), train_loss = 0.27535371, grad/param norm = 2.1528e-01, time/batch = 16.0411s	
17920/22300 (epoch 40.179), train_loss = 0.36609713, grad/param norm = 2.2428e-01, time/batch = 15.2137s	
17921/22300 (epoch 40.182), train_loss = 0.51483818, grad/param norm = 2.9541e-01, time/batch = 15.8921s	
17922/22300 (epoch 40.184), train_loss = 0.55567726, grad/param norm = 3.3763e-01, time/batch = 16.7034s	
17923/22300 (epoch 40.186), train_loss = 0.42184616, grad/param norm = 3.0127e-01, time/batch = 17.3884s	
17924/22300 (epoch 40.188), train_loss = 0.58610367, grad/param norm = 4.3337e-01, time/batch = 16.1392s	
17925/22300 (epoch 40.191), train_loss = 0.48581313, grad/param norm = 3.2779e-01, time/batch = 16.5542s	
17926/22300 (epoch 40.193), train_loss = 0.46361346, grad/param norm = 3.4782e-01, time/batch = 17.2088s	
17927/22300 (epoch 40.195), train_loss = 0.37333188, grad/param norm = 2.6191e-01, time/batch = 17.7330s	
17928/22300 (epoch 40.197), train_loss = 0.34144219, grad/param norm = 2.3455e-01, time/batch = 18.3804s	
17929/22300 (epoch 40.200), train_loss = 0.32865195, grad/param norm = 2.7987e-01, time/batch = 15.9294s	
17930/22300 (epoch 40.202), train_loss = 0.32329894, grad/param norm = 2.3905e-01, time/batch = 15.6372s	
17931/22300 (epoch 40.204), train_loss = 0.39570793, grad/param norm = 2.2450e-01, time/batch = 15.2259s	
17932/22300 (epoch 40.206), train_loss = 0.31347995, grad/param norm = 2.3139e-01, time/batch = 17.2928s	
17933/22300 (epoch 40.209), train_loss = 0.33901319, grad/param norm = 2.2599e-01, time/batch = 16.3823s	
17934/22300 (epoch 40.211), train_loss = 0.28850057, grad/param norm = 2.4259e-01, time/batch = 18.4656s	
17935/22300 (epoch 40.213), train_loss = 0.42024077, grad/param norm = 2.7029e-01, time/batch = 17.8880s	
17936/22300 (epoch 40.215), train_loss = 0.51665011, grad/param norm = 3.5076e-01, time/batch = 15.3697s	
17937/22300 (epoch 40.217), train_loss = 0.52525260, grad/param norm = 3.1991e-01, time/batch = 16.2224s	
17938/22300 (epoch 40.220), train_loss = 0.36072214, grad/param norm = 2.4475e-01, time/batch = 16.5577s	
17939/22300 (epoch 40.222), train_loss = 0.34114109, grad/param norm = 2.6840e-01, time/batch = 17.0566s	
17940/22300 (epoch 40.224), train_loss = 0.34099286, grad/param norm = 2.3466e-01, time/batch = 16.9348s	
17941/22300 (epoch 40.226), train_loss = 0.37514077, grad/param norm = 2.6677e-01, time/batch = 16.6302s	
17942/22300 (epoch 40.229), train_loss = 0.30838852, grad/param norm = 2.1341e-01, time/batch = 16.9757s	
17943/22300 (epoch 40.231), train_loss = 0.52022738, grad/param norm = 6.4981e-01, time/batch = 15.7854s	
17944/22300 (epoch 40.233), train_loss = 0.42695178, grad/param norm = 3.3030e-01, time/batch = 17.0685s	
17945/22300 (epoch 40.235), train_loss = 0.31114809, grad/param norm = 2.2725e-01, time/batch = 15.6473s	
17946/22300 (epoch 40.238), train_loss = 0.32988454, grad/param norm = 2.4710e-01, time/batch = 19.2842s	
17947/22300 (epoch 40.240), train_loss = 0.32399993, grad/param norm = 1.9767e-01, time/batch = 15.8734s	
17948/22300 (epoch 40.242), train_loss = 0.29398624, grad/param norm = 2.4801e-01, time/batch = 17.2249s	
17949/22300 (epoch 40.244), train_loss = 0.21913890, grad/param norm = 1.7176e-01, time/batch = 16.0402s	
17950/22300 (epoch 40.247), train_loss = 0.28723632, grad/param norm = 1.8785e-01, time/batch = 17.2789s	
17951/22300 (epoch 40.249), train_loss = 0.20676694, grad/param norm = 1.9751e-01, time/batch = 17.4637s	
17952/22300 (epoch 40.251), train_loss = 0.27259759, grad/param norm = 1.9635e-01, time/batch = 16.5635s	
17953/22300 (epoch 40.253), train_loss = 0.18495184, grad/param norm = 1.8178e-01, time/batch = 18.7040s	
17954/22300 (epoch 40.256), train_loss = 0.27080411, grad/param norm = 2.3784e-01, time/batch = 15.6027s	
17955/22300 (epoch 40.258), train_loss = 0.39563846, grad/param norm = 2.8824e-01, time/batch = 17.4011s	
17956/22300 (epoch 40.260), train_loss = 0.40632051, grad/param norm = 2.3285e-01, time/batch = 15.7428s	
17957/22300 (epoch 40.262), train_loss = 0.28958301, grad/param norm = 1.8802e-01, time/batch = 17.0288s	
17958/22300 (epoch 40.265), train_loss = 0.27211848, grad/param norm = 2.8462e-01, time/batch = 16.4350s	
17959/22300 (epoch 40.267), train_loss = 0.31747915, grad/param norm = 2.8826e-01, time/batch = 17.4842s	
17960/22300 (epoch 40.269), train_loss = 0.37440272, grad/param norm = 2.8803e-01, time/batch = 17.2986s	
17961/22300 (epoch 40.271), train_loss = 0.43116110, grad/param norm = 2.5301e-01, time/batch = 15.2081s	
17962/22300 (epoch 40.274), train_loss = 0.28207100, grad/param norm = 2.4048e-01, time/batch = 16.4990s	
17963/22300 (epoch 40.276), train_loss = 0.25144423, grad/param norm = 1.6931e-01, time/batch = 17.3103s	
17964/22300 (epoch 40.278), train_loss = 0.26905206, grad/param norm = 2.0482e-01, time/batch = 16.8854s	
17965/22300 (epoch 40.280), train_loss = 0.29612135, grad/param norm = 2.2813e-01, time/batch = 15.6876s	
17966/22300 (epoch 40.283), train_loss = 0.23827433, grad/param norm = 1.5274e-01, time/batch = 15.7241s	
17967/22300 (epoch 40.285), train_loss = 0.25385892, grad/param norm = 2.3164e-01, time/batch = 14.8751s	
17968/22300 (epoch 40.287), train_loss = 0.37257857, grad/param norm = 2.4420e-01, time/batch = 16.2118s	
17969/22300 (epoch 40.289), train_loss = 0.35019593, grad/param norm = 2.3898e-01, time/batch = 17.3042s	
17970/22300 (epoch 40.291), train_loss = 0.32217716, grad/param norm = 2.4324e-01, time/batch = 17.3055s	
17971/22300 (epoch 40.294), train_loss = 0.27555996, grad/param norm = 1.9008e-01, time/batch = 19.1171s	
17972/22300 (epoch 40.296), train_loss = 0.32480386, grad/param norm = 2.7778e-01, time/batch = 17.1924s	
17973/22300 (epoch 40.298), train_loss = 0.44193722, grad/param norm = 3.0935e-01, time/batch = 16.8888s	
17974/22300 (epoch 40.300), train_loss = 0.46583530, grad/param norm = 2.8857e-01, time/batch = 16.0609s	
17975/22300 (epoch 40.303), train_loss = 0.35888341, grad/param norm = 2.3018e-01, time/batch = 17.0608s	
17976/22300 (epoch 40.305), train_loss = 0.36865676, grad/param norm = 2.8565e-01, time/batch = 17.4690s	
17977/22300 (epoch 40.307), train_loss = 0.30307443, grad/param norm = 2.3630e-01, time/batch = 17.5447s	
17978/22300 (epoch 40.309), train_loss = 0.28106414, grad/param norm = 2.2324e-01, time/batch = 18.7079s	
17979/22300 (epoch 40.312), train_loss = 0.24894028, grad/param norm = 1.9824e-01, time/batch = 14.9071s	
17980/22300 (epoch 40.314), train_loss = 0.28823052, grad/param norm = 1.8580e-01, time/batch = 17.1088s	
17981/22300 (epoch 40.316), train_loss = 0.27337823, grad/param norm = 2.1824e-01, time/batch = 17.1372s	
17982/22300 (epoch 40.318), train_loss = 0.31188975, grad/param norm = 2.1915e-01, time/batch = 15.8041s	
17983/22300 (epoch 40.321), train_loss = 0.39902987, grad/param norm = 2.3011e-01, time/batch = 16.0685s	
17984/22300 (epoch 40.323), train_loss = 0.27049115, grad/param norm = 2.1544e-01, time/batch = 15.1067s	
17985/22300 (epoch 40.325), train_loss = 0.24811171, grad/param norm = 1.9627e-01, time/batch = 15.6323s	
17986/22300 (epoch 40.327), train_loss = 0.27331135, grad/param norm = 1.8141e-01, time/batch = 17.1252s	
17987/22300 (epoch 40.330), train_loss = 0.28620762, grad/param norm = 3.1930e-01, time/batch = 16.3972s	
17988/22300 (epoch 40.332), train_loss = 0.26923163, grad/param norm = 1.9160e-01, time/batch = 17.3807s	
17989/22300 (epoch 40.334), train_loss = 0.30888492, grad/param norm = 2.5991e-01, time/batch = 18.6876s	
17990/22300 (epoch 40.336), train_loss = 0.30424135, grad/param norm = 1.9849e-01, time/batch = 28.9248s	
17991/22300 (epoch 40.339), train_loss = 0.37298292, grad/param norm = 2.9039e-01, time/batch = 15.5430s	
17992/22300 (epoch 40.341), train_loss = 0.36246914, grad/param norm = 2.3725e-01, time/batch = 15.2818s	
17993/22300 (epoch 40.343), train_loss = 0.41097944, grad/param norm = 2.8143e-01, time/batch = 17.3861s	
17994/22300 (epoch 40.345), train_loss = 0.32784284, grad/param norm = 2.3491e-01, time/batch = 16.0691s	
17995/22300 (epoch 40.348), train_loss = 0.34528741, grad/param norm = 2.1840e-01, time/batch = 18.4696s	
17996/22300 (epoch 40.350), train_loss = 0.24891109, grad/param norm = 2.3240e-01, time/batch = 15.7153s	
17997/22300 (epoch 40.352), train_loss = 0.35063362, grad/param norm = 2.3803e-01, time/batch = 15.9380s	
17998/22300 (epoch 40.354), train_loss = 0.49590407, grad/param norm = 3.3450e-01, time/batch = 17.3042s	
17999/22300 (epoch 40.357), train_loss = 0.44445010, grad/param norm = 2.3192e-01, time/batch = 16.8897s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch40.36_1.7144.t7	
18000/22300 (epoch 40.359), train_loss = 0.28466736, grad/param norm = 2.4041e-01, time/batch = 15.7985s	
18001/22300 (epoch 40.361), train_loss = 1.51246438, grad/param norm = 5.7975e-01, time/batch = 17.3728s	
18002/22300 (epoch 40.363), train_loss = 0.41558932, grad/param norm = 2.9888e-01, time/batch = 16.2994s	
18003/22300 (epoch 40.365), train_loss = 0.30994470, grad/param norm = 2.5822e-01, time/batch = 15.5324s	
18004/22300 (epoch 40.368), train_loss = 0.31066637, grad/param norm = 2.7772e-01, time/batch = 17.3855s	
18005/22300 (epoch 40.370), train_loss = 0.32110604, grad/param norm = 2.3070e-01, time/batch = 14.3990s	
18006/22300 (epoch 40.372), train_loss = 0.22630322, grad/param norm = 1.9835e-01, time/batch = 16.8935s	
18007/22300 (epoch 40.374), train_loss = 0.24050156, grad/param norm = 1.6736e-01, time/batch = 18.4626s	
18008/22300 (epoch 40.377), train_loss = 0.33846457, grad/param norm = 2.8562e-01, time/batch = 16.1221s	
18009/22300 (epoch 40.379), train_loss = 0.28521933, grad/param norm = 2.2532e-01, time/batch = 18.1346s	
18010/22300 (epoch 40.381), train_loss = 0.37795917, grad/param norm = 2.6484e-01, time/batch = 16.2904s	
18011/22300 (epoch 40.383), train_loss = 0.30439078, grad/param norm = 2.4348e-01, time/batch = 16.2784s	
18012/22300 (epoch 40.386), train_loss = 0.34630619, grad/param norm = 2.2862e-01, time/batch = 15.9532s	
18013/22300 (epoch 40.388), train_loss = 0.25392282, grad/param norm = 2.1723e-01, time/batch = 18.4721s	
18014/22300 (epoch 40.390), train_loss = 0.27414842, grad/param norm = 2.3801e-01, time/batch = 15.6296s	
18015/22300 (epoch 40.392), train_loss = 0.31201518, grad/param norm = 2.4032e-01, time/batch = 17.5411s	
18016/22300 (epoch 40.395), train_loss = 0.24761375, grad/param norm = 1.8576e-01, time/batch = 16.2388s	
18017/22300 (epoch 40.397), train_loss = 0.17625545, grad/param norm = 1.5872e-01, time/batch = 16.0563s	
18018/22300 (epoch 40.399), train_loss = 0.26610419, grad/param norm = 2.0879e-01, time/batch = 17.3039s	
18019/22300 (epoch 40.401), train_loss = 0.30171359, grad/param norm = 2.9082e-01, time/batch = 15.2652s	
18020/22300 (epoch 40.404), train_loss = 0.31293207, grad/param norm = 2.0496e-01, time/batch = 16.3477s	
18021/22300 (epoch 40.406), train_loss = 0.49422184, grad/param norm = 3.1085e-01, time/batch = 15.5537s	
18022/22300 (epoch 40.408), train_loss = 0.35943542, grad/param norm = 2.3160e-01, time/batch = 16.9704s	
18023/22300 (epoch 40.410), train_loss = 0.39198294, grad/param norm = 2.4594e-01, time/batch = 15.8542s	
18024/22300 (epoch 40.413), train_loss = 0.30452323, grad/param norm = 2.4228e-01, time/batch = 16.3004s	
18025/22300 (epoch 40.415), train_loss = 0.21788638, grad/param norm = 2.1397e-01, time/batch = 18.1394s	
18026/22300 (epoch 40.417), train_loss = 0.34947157, grad/param norm = 2.5372e-01, time/batch = 16.4590s	
18027/22300 (epoch 40.419), train_loss = 0.31200604, grad/param norm = 1.8390e-01, time/batch = 15.8005s	
18028/22300 (epoch 40.422), train_loss = 0.26743368, grad/param norm = 2.8262e-01, time/batch = 16.2341s	
18029/22300 (epoch 40.424), train_loss = 0.32944755, grad/param norm = 2.5850e-01, time/batch = 16.6166s	
18030/22300 (epoch 40.426), train_loss = 0.23348212, grad/param norm = 1.8169e-01, time/batch = 15.5550s	
18031/22300 (epoch 40.428), train_loss = 0.23774002, grad/param norm = 1.6539e-01, time/batch = 15.4732s	
18032/22300 (epoch 40.430), train_loss = 0.28628361, grad/param norm = 1.9393e-01, time/batch = 15.2290s	
18033/22300 (epoch 40.433), train_loss = 0.30568284, grad/param norm = 1.9739e-01, time/batch = 17.1342s	
18034/22300 (epoch 40.435), train_loss = 0.27733806, grad/param norm = 2.0145e-01, time/batch = 16.2168s	
18035/22300 (epoch 40.437), train_loss = 0.34305627, grad/param norm = 2.8193e-01, time/batch = 17.2336s	
18036/22300 (epoch 40.439), train_loss = 0.38641664, grad/param norm = 2.6274e-01, time/batch = 15.7404s	
18037/22300 (epoch 40.442), train_loss = 0.32616568, grad/param norm = 2.5193e-01, time/batch = 15.6092s	
18038/22300 (epoch 40.444), train_loss = 0.26638412, grad/param norm = 2.4815e-01, time/batch = 15.2202s	
18039/22300 (epoch 40.446), train_loss = 0.30445671, grad/param norm = 2.2822e-01, time/batch = 18.2014s	
18040/22300 (epoch 40.448), train_loss = 0.23248516, grad/param norm = 1.6220e-01, time/batch = 16.1933s	
18041/22300 (epoch 40.451), train_loss = 0.35567406, grad/param norm = 2.7232e-01, time/batch = 15.3878s	
18042/22300 (epoch 40.453), train_loss = 0.29907210, grad/param norm = 2.5990e-01, time/batch = 16.5687s	
18043/22300 (epoch 40.455), train_loss = 0.40776853, grad/param norm = 3.3289e-01, time/batch = 16.9565s	
18044/22300 (epoch 40.457), train_loss = 0.51414431, grad/param norm = 3.2761e-01, time/batch = 17.5453s	
18045/22300 (epoch 40.460), train_loss = 0.42575673, grad/param norm = 3.2439e-01, time/batch = 17.9469s	
18046/22300 (epoch 40.462), train_loss = 0.43739075, grad/param norm = 2.4769e-01, time/batch = 15.9868s	
18047/22300 (epoch 40.464), train_loss = 0.38566572, grad/param norm = 2.8366e-01, time/batch = 16.8227s	
18048/22300 (epoch 40.466), train_loss = 0.30835289, grad/param norm = 2.0468e-01, time/batch = 16.3744s	
18049/22300 (epoch 40.469), train_loss = 0.28230983, grad/param norm = 1.7851e-01, time/batch = 15.8702s	
18050/22300 (epoch 40.471), train_loss = 0.40712525, grad/param norm = 2.4935e-01, time/batch = 15.9561s	
18051/22300 (epoch 40.473), train_loss = 0.34718142, grad/param norm = 2.1436e-01, time/batch = 15.8879s	
18052/22300 (epoch 40.475), train_loss = 0.29623444, grad/param norm = 2.4163e-01, time/batch = 15.6951s	
18053/22300 (epoch 40.478), train_loss = 0.31268362, grad/param norm = 2.3199e-01, time/batch = 17.8866s	
18054/22300 (epoch 40.480), train_loss = 0.23085429, grad/param norm = 1.8323e-01, time/batch = 18.6311s	
18055/22300 (epoch 40.482), train_loss = 0.25801373, grad/param norm = 1.6609e-01, time/batch = 16.7144s	
18056/22300 (epoch 40.484), train_loss = 0.35190282, grad/param norm = 2.3989e-01, time/batch = 16.2228s	
18057/22300 (epoch 40.487), train_loss = 0.40815045, grad/param norm = 2.3267e-01, time/batch = 17.0468s	
18058/22300 (epoch 40.489), train_loss = 0.38036802, grad/param norm = 2.5227e-01, time/batch = 17.6325s	
18059/22300 (epoch 40.491), train_loss = 0.41682151, grad/param norm = 2.6023e-01, time/batch = 14.7198s	
18060/22300 (epoch 40.493), train_loss = 0.29264181, grad/param norm = 3.0844e-01, time/batch = 15.9534s	
18061/22300 (epoch 40.496), train_loss = 0.35608273, grad/param norm = 2.2311e-01, time/batch = 16.0257s	
18062/22300 (epoch 40.498), train_loss = 0.21509257, grad/param norm = 1.3796e-01, time/batch = 17.8781s	
18063/22300 (epoch 40.500), train_loss = 0.32572902, grad/param norm = 2.2227e-01, time/batch = 17.2087s	
18064/22300 (epoch 40.502), train_loss = 0.22994289, grad/param norm = 2.3977e-01, time/batch = 16.1531s	
18065/22300 (epoch 40.504), train_loss = 0.22617786, grad/param norm = 1.7655e-01, time/batch = 18.0521s	
18066/22300 (epoch 40.507), train_loss = 0.26017785, grad/param norm = 1.9936e-01, time/batch = 16.3870s	
18067/22300 (epoch 40.509), train_loss = 0.36418948, grad/param norm = 2.0303e-01, time/batch = 17.8841s	
18068/22300 (epoch 40.511), train_loss = 0.20662821, grad/param norm = 1.4901e-01, time/batch = 15.2069s	
18069/22300 (epoch 40.513), train_loss = 0.23256391, grad/param norm = 1.5896e-01, time/batch = 18.1247s	
18070/22300 (epoch 40.516), train_loss = 0.29556657, grad/param norm = 2.8018e-01, time/batch = 15.7984s	
18071/22300 (epoch 40.518), train_loss = 0.33614628, grad/param norm = 2.2519e-01, time/batch = 15.4703s	
18072/22300 (epoch 40.520), train_loss = 0.29308519, grad/param norm = 2.4289e-01, time/batch = 15.8736s	
18073/22300 (epoch 40.522), train_loss = 0.32308545, grad/param norm = 2.2716e-01, time/batch = 17.4672s	
18074/22300 (epoch 40.525), train_loss = 0.24552438, grad/param norm = 1.9925e-01, time/batch = 16.0604s	
18075/22300 (epoch 40.527), train_loss = 0.39105826, grad/param norm = 3.7558e-01, time/batch = 14.5947s	
18076/22300 (epoch 40.529), train_loss = 0.35908567, grad/param norm = 2.5092e-01, time/batch = 16.0678s	
18077/22300 (epoch 40.531), train_loss = 0.28243886, grad/param norm = 2.1157e-01, time/batch = 16.7197s	
18078/22300 (epoch 40.534), train_loss = 0.33006447, grad/param norm = 2.2125e-01, time/batch = 18.1312s	
18079/22300 (epoch 40.536), train_loss = 0.46412872, grad/param norm = 2.6918e-01, time/batch = 16.8050s	
18080/22300 (epoch 40.538), train_loss = 0.57181304, grad/param norm = 3.7163e-01, time/batch = 16.9639s	
18081/22300 (epoch 40.540), train_loss = 0.32272320, grad/param norm = 2.2248e-01, time/batch = 17.5433s	
18082/22300 (epoch 40.543), train_loss = 0.33872477, grad/param norm = 2.5319e-01, time/batch = 17.1413s	
18083/22300 (epoch 40.545), train_loss = 0.22681800, grad/param norm = 1.9891e-01, time/batch = 17.6212s	
18084/22300 (epoch 40.547), train_loss = 0.20990096, grad/param norm = 1.9747e-01, time/batch = 15.3445s	
18085/22300 (epoch 40.549), train_loss = 0.23660941, grad/param norm = 2.0055e-01, time/batch = 17.2124s	
18086/22300 (epoch 40.552), train_loss = 0.26045350, grad/param norm = 2.3518e-01, time/batch = 15.2217s	
18087/22300 (epoch 40.554), train_loss = 0.36576908, grad/param norm = 2.5603e-01, time/batch = 16.1495s	
18088/22300 (epoch 40.556), train_loss = 0.48421176, grad/param norm = 2.8726e-01, time/batch = 16.6189s	
18089/22300 (epoch 40.558), train_loss = 0.33919627, grad/param norm = 2.2000e-01, time/batch = 16.2784s	
18090/22300 (epoch 40.561), train_loss = 0.49558548, grad/param norm = 2.8822e-01, time/batch = 15.9682s	
18091/22300 (epoch 40.563), train_loss = 0.39983637, grad/param norm = 2.6652e-01, time/batch = 17.1952s	
18092/22300 (epoch 40.565), train_loss = 0.31980931, grad/param norm = 2.3415e-01, time/batch = 17.3020s	
18093/22300 (epoch 40.567), train_loss = 0.33226757, grad/param norm = 2.4575e-01, time/batch = 17.2231s	
18094/22300 (epoch 40.570), train_loss = 0.44236291, grad/param norm = 3.1945e-01, time/batch = 17.3073s	
18095/22300 (epoch 40.572), train_loss = 0.45115723, grad/param norm = 3.0475e-01, time/batch = 15.5617s	
18096/22300 (epoch 40.574), train_loss = 0.31402876, grad/param norm = 2.2842e-01, time/batch = 17.2312s	
18097/22300 (epoch 40.576), train_loss = 0.30077677, grad/param norm = 2.4155e-01, time/batch = 15.9044s	
18098/22300 (epoch 40.578), train_loss = 0.16920843, grad/param norm = 1.4445e-01, time/batch = 16.9670s	
18099/22300 (epoch 40.581), train_loss = 0.25304717, grad/param norm = 2.0573e-01, time/batch = 15.8558s	
18100/22300 (epoch 40.583), train_loss = 0.31107997, grad/param norm = 2.2681e-01, time/batch = 16.4220s	
18101/22300 (epoch 40.585), train_loss = 0.40093656, grad/param norm = 4.5207e-01, time/batch = 17.2152s	
18102/22300 (epoch 40.587), train_loss = 0.60748070, grad/param norm = 4.0341e-01, time/batch = 15.7099s	
18103/22300 (epoch 40.590), train_loss = 0.48222596, grad/param norm = 3.8373e-01, time/batch = 18.3840s	
18104/22300 (epoch 40.592), train_loss = 0.60650538, grad/param norm = 4.9416e-01, time/batch = 15.3508s	
18105/22300 (epoch 40.594), train_loss = 0.51260022, grad/param norm = 3.3613e-01, time/batch = 17.7992s	
18106/22300 (epoch 40.596), train_loss = 0.36770290, grad/param norm = 3.2425e-01, time/batch = 16.2720s	
18107/22300 (epoch 40.599), train_loss = 0.22097236, grad/param norm = 1.9828e-01, time/batch = 16.3193s	
18108/22300 (epoch 40.601), train_loss = 0.28144742, grad/param norm = 2.1896e-01, time/batch = 17.0620s	
18109/22300 (epoch 40.603), train_loss = 0.28598717, grad/param norm = 2.1923e-01, time/batch = 16.2555s	
18110/22300 (epoch 40.605), train_loss = 0.32498108, grad/param norm = 2.3841e-01, time/batch = 15.6537s	
18111/22300 (epoch 40.608), train_loss = 0.54999405, grad/param norm = 3.9873e-01, time/batch = 15.6415s	
18112/22300 (epoch 40.610), train_loss = 0.59313636, grad/param norm = 3.5347e-01, time/batch = 15.2201s	
18113/22300 (epoch 40.612), train_loss = 0.42432029, grad/param norm = 2.9923e-01, time/batch = 16.0628s	
18114/22300 (epoch 40.614), train_loss = 0.38564722, grad/param norm = 2.8549e-01, time/batch = 18.7155s	
18115/22300 (epoch 40.617), train_loss = 0.41610321, grad/param norm = 2.3040e-01, time/batch = 16.5545s	
18116/22300 (epoch 40.619), train_loss = 0.43575555, grad/param norm = 2.6619e-01, time/batch = 17.3885s	
18117/22300 (epoch 40.621), train_loss = 0.30994493, grad/param norm = 2.6126e-01, time/batch = 18.1322s	
18118/22300 (epoch 40.623), train_loss = 0.30629407, grad/param norm = 2.0485e-01, time/batch = 17.5597s	
18119/22300 (epoch 40.626), train_loss = 0.28145824, grad/param norm = 1.9511e-01, time/batch = 18.5428s	
18120/22300 (epoch 40.628), train_loss = 0.29657779, grad/param norm = 2.0104e-01, time/batch = 15.0543s	
18121/22300 (epoch 40.630), train_loss = 0.36512998, grad/param norm = 2.4774e-01, time/batch = 18.5501s	
18122/22300 (epoch 40.632), train_loss = 0.29329398, grad/param norm = 2.4809e-01, time/batch = 15.5419s	
18123/22300 (epoch 40.635), train_loss = 0.35193896, grad/param norm = 2.6183e-01, time/batch = 15.2186s	
18124/22300 (epoch 40.637), train_loss = 0.39545822, grad/param norm = 2.5253e-01, time/batch = 16.3706s	
18125/22300 (epoch 40.639), train_loss = 0.49705354, grad/param norm = 3.3539e-01, time/batch = 14.2618s	
18126/22300 (epoch 40.641), train_loss = 0.39208535, grad/param norm = 2.2704e-01, time/batch = 18.3820s	
18127/22300 (epoch 40.643), train_loss = 0.29149079, grad/param norm = 2.1868e-01, time/batch = 15.4333s	
18128/22300 (epoch 40.646), train_loss = 0.29588365, grad/param norm = 2.3477e-01, time/batch = 15.8062s	
18129/22300 (epoch 40.648), train_loss = 0.39914781, grad/param norm = 2.1681e-01, time/batch = 16.5607s	
18130/22300 (epoch 40.650), train_loss = 0.40277615, grad/param norm = 2.5083e-01, time/batch = 17.3180s	
18131/22300 (epoch 40.652), train_loss = 0.30052037, grad/param norm = 1.9111e-01, time/batch = 16.0452s	
18132/22300 (epoch 40.655), train_loss = 0.26092300, grad/param norm = 2.0320e-01, time/batch = 17.5656s	
18133/22300 (epoch 40.657), train_loss = 0.30827783, grad/param norm = 2.5124e-01, time/batch = 16.2421s	
18134/22300 (epoch 40.659), train_loss = 0.29186055, grad/param norm = 2.0526e-01, time/batch = 17.6136s	
18135/22300 (epoch 40.661), train_loss = 0.24978783, grad/param norm = 2.0207e-01, time/batch = 15.6025s	
18136/22300 (epoch 40.664), train_loss = 0.29690970, grad/param norm = 1.8791e-01, time/batch = 16.2959s	
18137/22300 (epoch 40.666), train_loss = 0.37044027, grad/param norm = 2.5048e-01, time/batch = 16.7216s	
18138/22300 (epoch 40.668), train_loss = 0.28215856, grad/param norm = 2.0033e-01, time/batch = 16.1328s	
18139/22300 (epoch 40.670), train_loss = 0.37051373, grad/param norm = 2.7952e-01, time/batch = 16.9552s	
18140/22300 (epoch 40.673), train_loss = 0.43402568, grad/param norm = 3.0414e-01, time/batch = 15.8609s	
18141/22300 (epoch 40.675), train_loss = 0.46229650, grad/param norm = 3.2690e-01, time/batch = 17.2946s	
18142/22300 (epoch 40.677), train_loss = 0.51581003, grad/param norm = 3.0906e-01, time/batch = 16.4730s	
18143/22300 (epoch 40.679), train_loss = 0.36306998, grad/param norm = 3.2587e-01, time/batch = 17.1369s	
18144/22300 (epoch 40.682), train_loss = 0.32363552, grad/param norm = 2.2360e-01, time/batch = 18.2141s	
18145/22300 (epoch 40.684), train_loss = 0.32040316, grad/param norm = 2.0806e-01, time/batch = 11.5560s	
18146/22300 (epoch 40.686), train_loss = 0.30399129, grad/param norm = 2.1356e-01, time/batch = 0.6623s	
18147/22300 (epoch 40.688), train_loss = 0.29856450, grad/param norm = 2.9221e-01, time/batch = 0.6548s	
18148/22300 (epoch 40.691), train_loss = 0.27645616, grad/param norm = 2.5612e-01, time/batch = 0.6600s	
18149/22300 (epoch 40.693), train_loss = 0.27384309, grad/param norm = 2.3881e-01, time/batch = 0.6745s	
18150/22300 (epoch 40.695), train_loss = 0.30679789, grad/param norm = 2.3156e-01, time/batch = 0.6616s	
18151/22300 (epoch 40.697), train_loss = 0.30662497, grad/param norm = 1.7403e-01, time/batch = 0.6694s	
18152/22300 (epoch 40.700), train_loss = 0.27777708, grad/param norm = 2.2702e-01, time/batch = 0.6510s	
18153/22300 (epoch 40.702), train_loss = 0.21999774, grad/param norm = 1.6113e-01, time/batch = 0.8913s	
18154/22300 (epoch 40.704), train_loss = 0.30220201, grad/param norm = 3.0661e-01, time/batch = 0.9507s	
18155/22300 (epoch 40.706), train_loss = 0.27957759, grad/param norm = 2.1522e-01, time/batch = 0.9667s	
18156/22300 (epoch 40.709), train_loss = 0.23190117, grad/param norm = 2.0786e-01, time/batch = 0.9456s	
18157/22300 (epoch 40.711), train_loss = 0.23461598, grad/param norm = 1.7318e-01, time/batch = 0.9443s	
18158/22300 (epoch 40.713), train_loss = 0.33101661, grad/param norm = 2.4012e-01, time/batch = 1.3966s	
18159/22300 (epoch 40.715), train_loss = 0.35230631, grad/param norm = 2.3736e-01, time/batch = 1.7604s	
18160/22300 (epoch 40.717), train_loss = 0.45321678, grad/param norm = 2.5066e-01, time/batch = 1.7589s	
18161/22300 (epoch 40.720), train_loss = 0.28956395, grad/param norm = 2.1968e-01, time/batch = 11.8900s	
18162/22300 (epoch 40.722), train_loss = 0.32203451, grad/param norm = 2.0518e-01, time/batch = 16.2365s	
18163/22300 (epoch 40.724), train_loss = 0.36050036, grad/param norm = 2.7576e-01, time/batch = 16.6188s	
18164/22300 (epoch 40.726), train_loss = 0.29464669, grad/param norm = 2.3013e-01, time/batch = 18.0546s	
18165/22300 (epoch 40.729), train_loss = 0.34428173, grad/param norm = 2.2608e-01, time/batch = 14.9993s	
18166/22300 (epoch 40.731), train_loss = 0.42015571, grad/param norm = 2.9648e-01, time/batch = 17.6269s	
18167/22300 (epoch 40.733), train_loss = 0.44110176, grad/param norm = 2.9035e-01, time/batch = 15.5000s	
18168/22300 (epoch 40.735), train_loss = 0.46267815, grad/param norm = 2.8349e-01, time/batch = 17.6179s	
18169/22300 (epoch 40.738), train_loss = 0.32035397, grad/param norm = 2.4165e-01, time/batch = 15.9110s	
18170/22300 (epoch 40.740), train_loss = 0.29545845, grad/param norm = 2.0680e-01, time/batch = 16.4813s	
18171/22300 (epoch 40.742), train_loss = 0.27039532, grad/param norm = 1.8999e-01, time/batch = 17.6292s	
18172/22300 (epoch 40.744), train_loss = 0.49653743, grad/param norm = 2.7080e-01, time/batch = 15.4782s	
18173/22300 (epoch 40.747), train_loss = 0.39227811, grad/param norm = 2.4680e-01, time/batch = 15.5502s	
18174/22300 (epoch 40.749), train_loss = 0.50926999, grad/param norm = 3.3581e-01, time/batch = 16.6330s	
18175/22300 (epoch 40.751), train_loss = 0.43276992, grad/param norm = 3.2328e-01, time/batch = 17.0426s	
18176/22300 (epoch 40.753), train_loss = 0.46450316, grad/param norm = 2.9929e-01, time/batch = 17.6287s	
18177/22300 (epoch 40.756), train_loss = 0.42071068, grad/param norm = 2.5558e-01, time/batch = 17.6531s	
18178/22300 (epoch 40.758), train_loss = 0.36247853, grad/param norm = 2.4947e-01, time/batch = 16.2620s	
18179/22300 (epoch 40.760), train_loss = 0.41546430, grad/param norm = 2.7110e-01, time/batch = 15.7244s	
18180/22300 (epoch 40.762), train_loss = 0.37421211, grad/param norm = 2.8448e-01, time/batch = 15.9617s	
18181/22300 (epoch 40.765), train_loss = 0.39411686, grad/param norm = 2.9457e-01, time/batch = 16.2205s	
18182/22300 (epoch 40.767), train_loss = 0.34655472, grad/param norm = 2.2078e-01, time/batch = 16.9691s	
18183/22300 (epoch 40.769), train_loss = 0.35580794, grad/param norm = 2.8080e-01, time/batch = 15.7298s	
18184/22300 (epoch 40.771), train_loss = 0.42141346, grad/param norm = 3.8055e-01, time/batch = 17.9658s	
18185/22300 (epoch 40.774), train_loss = 0.43913616, grad/param norm = 3.1363e-01, time/batch = 16.2188s	
18186/22300 (epoch 40.776), train_loss = 0.49098473, grad/param norm = 2.9179e-01, time/batch = 16.0562s	
18187/22300 (epoch 40.778), train_loss = 0.47987144, grad/param norm = 2.6580e-01, time/batch = 17.8836s	
18188/22300 (epoch 40.780), train_loss = 0.44536315, grad/param norm = 3.0260e-01, time/batch = 17.2958s	
18189/22300 (epoch 40.783), train_loss = 0.48701411, grad/param norm = 3.5380e-01, time/batch = 17.2155s	
18190/22300 (epoch 40.785), train_loss = 0.33360884, grad/param norm = 2.4254e-01, time/batch = 16.4664s	
18191/22300 (epoch 40.787), train_loss = 0.32838060, grad/param norm = 2.3187e-01, time/batch = 17.0143s	
18192/22300 (epoch 40.789), train_loss = 0.50582717, grad/param norm = 3.0331e-01, time/batch = 15.5517s	
18193/22300 (epoch 40.791), train_loss = 0.60693468, grad/param norm = 3.4714e-01, time/batch = 17.7028s	
18194/22300 (epoch 40.794), train_loss = 0.50209190, grad/param norm = 3.5239e-01, time/batch = 17.6140s	
18195/22300 (epoch 40.796), train_loss = 0.43840336, grad/param norm = 3.2780e-01, time/batch = 17.6870s	
18196/22300 (epoch 40.798), train_loss = 0.58644052, grad/param norm = 2.9661e-01, time/batch = 15.3794s	
18197/22300 (epoch 40.800), train_loss = 0.38861500, grad/param norm = 2.6695e-01, time/batch = 15.8901s	
18198/22300 (epoch 40.803), train_loss = 0.33360162, grad/param norm = 2.2892e-01, time/batch = 17.0730s	
18199/22300 (epoch 40.805), train_loss = 0.38977309, grad/param norm = 2.9245e-01, time/batch = 16.6345s	
18200/22300 (epoch 40.807), train_loss = 0.53576742, grad/param norm = 3.8608e-01, time/batch = 16.4408s	
18201/22300 (epoch 40.809), train_loss = 0.37165755, grad/param norm = 2.6306e-01, time/batch = 16.9537s	
18202/22300 (epoch 40.812), train_loss = 0.41823869, grad/param norm = 2.7514e-01, time/batch = 16.3827s	
18203/22300 (epoch 40.814), train_loss = 0.39771026, grad/param norm = 2.7352e-01, time/batch = 14.7373s	
18204/22300 (epoch 40.816), train_loss = 0.42237136, grad/param norm = 2.7564e-01, time/batch = 17.3916s	
18205/22300 (epoch 40.818), train_loss = 0.48725743, grad/param norm = 3.2010e-01, time/batch = 17.0551s	
18206/22300 (epoch 40.821), train_loss = 0.41706143, grad/param norm = 2.7830e-01, time/batch = 17.6218s	
18207/22300 (epoch 40.823), train_loss = 0.27813714, grad/param norm = 2.2499e-01, time/batch = 17.0521s	
18208/22300 (epoch 40.825), train_loss = 0.28040873, grad/param norm = 2.6142e-01, time/batch = 16.7017s	
18209/22300 (epoch 40.827), train_loss = 0.32611568, grad/param norm = 2.4496e-01, time/batch = 16.3083s	
18210/22300 (epoch 40.830), train_loss = 0.35256976, grad/param norm = 2.6306e-01, time/batch = 16.1296s	
18211/22300 (epoch 40.832), train_loss = 0.31933691, grad/param norm = 2.6145e-01, time/batch = 16.4628s	
18212/22300 (epoch 40.834), train_loss = 0.26688179, grad/param norm = 2.2616e-01, time/batch = 17.1294s	
18213/22300 (epoch 40.836), train_loss = 0.33140149, grad/param norm = 2.5085e-01, time/batch = 16.7686s	
18214/22300 (epoch 40.839), train_loss = 0.36518945, grad/param norm = 3.0046e-01, time/batch = 31.8532s	
18215/22300 (epoch 40.841), train_loss = 0.33046804, grad/param norm = 3.4146e-01, time/batch = 15.8155s	
18216/22300 (epoch 40.843), train_loss = 0.35471736, grad/param norm = 2.4198e-01, time/batch = 16.1334s	
18217/22300 (epoch 40.845), train_loss = 0.33210680, grad/param norm = 2.1305e-01, time/batch = 16.0053s	
18218/22300 (epoch 40.848), train_loss = 0.35101104, grad/param norm = 2.9954e-01, time/batch = 17.5457s	
18219/22300 (epoch 40.850), train_loss = 0.36577947, grad/param norm = 2.2858e-01, time/batch = 17.6375s	
18220/22300 (epoch 40.852), train_loss = 0.32548541, grad/param norm = 2.9184e-01, time/batch = 15.2961s	
18221/22300 (epoch 40.854), train_loss = 0.54233233, grad/param norm = 3.6550e-01, time/batch = 20.0336s	
18222/22300 (epoch 40.857), train_loss = 0.39948246, grad/param norm = 2.6181e-01, time/batch = 17.4662s	
18223/22300 (epoch 40.859), train_loss = 0.31545832, grad/param norm = 2.2255e-01, time/batch = 16.5561s	
18224/22300 (epoch 40.861), train_loss = 0.44125050, grad/param norm = 2.7272e-01, time/batch = 16.6382s	
18225/22300 (epoch 40.863), train_loss = 0.27290466, grad/param norm = 1.9809e-01, time/batch = 15.9796s	
18226/22300 (epoch 40.865), train_loss = 0.29359210, grad/param norm = 2.8141e-01, time/batch = 19.5245s	
18227/22300 (epoch 40.868), train_loss = 0.38070423, grad/param norm = 2.4347e-01, time/batch = 15.5409s	
18228/22300 (epoch 40.870), train_loss = 0.37883030, grad/param norm = 2.7518e-01, time/batch = 17.8838s	
18229/22300 (epoch 40.872), train_loss = 0.44863901, grad/param norm = 2.3590e-01, time/batch = 16.8054s	
18230/22300 (epoch 40.874), train_loss = 0.39911449, grad/param norm = 2.9804e-01, time/batch = 17.4509s	
18231/22300 (epoch 40.877), train_loss = 0.38439467, grad/param norm = 2.5020e-01, time/batch = 15.9787s	
18232/22300 (epoch 40.879), train_loss = 0.34455747, grad/param norm = 2.2321e-01, time/batch = 16.4575s	
18233/22300 (epoch 40.881), train_loss = 0.26428102, grad/param norm = 1.9256e-01, time/batch = 17.0390s	
18234/22300 (epoch 40.883), train_loss = 0.28840998, grad/param norm = 2.1388e-01, time/batch = 15.1092s	
18235/22300 (epoch 40.886), train_loss = 0.27916023, grad/param norm = 2.6343e-01, time/batch = 17.8857s	
18236/22300 (epoch 40.888), train_loss = 0.30579748, grad/param norm = 2.1807e-01, time/batch = 18.2987s	
18237/22300 (epoch 40.890), train_loss = 0.31771778, grad/param norm = 2.3209e-01, time/batch = 16.3726s	
18238/22300 (epoch 40.892), train_loss = 0.47956484, grad/param norm = 2.5072e-01, time/batch = 16.6307s	
18239/22300 (epoch 40.895), train_loss = 0.45307123, grad/param norm = 3.1970e-01, time/batch = 16.2165s	
18240/22300 (epoch 40.897), train_loss = 0.34844679, grad/param norm = 3.0288e-01, time/batch = 18.9714s	
18241/22300 (epoch 40.899), train_loss = 0.33443291, grad/param norm = 2.1242e-01, time/batch = 15.9544s	
18242/22300 (epoch 40.901), train_loss = 0.40146960, grad/param norm = 2.8144e-01, time/batch = 17.3095s	
18243/22300 (epoch 40.904), train_loss = 0.39093982, grad/param norm = 2.4417e-01, time/batch = 15.1106s	
18244/22300 (epoch 40.906), train_loss = 0.38116814, grad/param norm = 2.5726e-01, time/batch = 17.5293s	
18245/22300 (epoch 40.908), train_loss = 0.34563629, grad/param norm = 2.1454e-01, time/batch = 17.4648s	
18246/22300 (epoch 40.910), train_loss = 0.33248406, grad/param norm = 2.2995e-01, time/batch = 15.8918s	
18247/22300 (epoch 40.913), train_loss = 0.38944498, grad/param norm = 2.7692e-01, time/batch = 14.8016s	
18248/22300 (epoch 40.915), train_loss = 0.50664158, grad/param norm = 3.1715e-01, time/batch = 16.0151s	
18249/22300 (epoch 40.917), train_loss = 0.43361596, grad/param norm = 3.3840e-01, time/batch = 13.9940s	
18250/22300 (epoch 40.919), train_loss = 0.39807413, grad/param norm = 2.4234e-01, time/batch = 16.6466s	
18251/22300 (epoch 40.922), train_loss = 0.38719015, grad/param norm = 3.2240e-01, time/batch = 15.5725s	
18252/22300 (epoch 40.924), train_loss = 0.25305173, grad/param norm = 2.3124e-01, time/batch = 15.0284s	
18253/22300 (epoch 40.926), train_loss = 0.31421608, grad/param norm = 1.8948e-01, time/batch = 16.6175s	
18254/22300 (epoch 40.928), train_loss = 0.32821543, grad/param norm = 2.4009e-01, time/batch = 17.2160s	
18255/22300 (epoch 40.930), train_loss = 0.30374987, grad/param norm = 2.2872e-01, time/batch = 18.2032s	
18256/22300 (epoch 40.933), train_loss = 0.38828862, grad/param norm = 2.5128e-01, time/batch = 16.3081s	
18257/22300 (epoch 40.935), train_loss = 0.38414502, grad/param norm = 2.9719e-01, time/batch = 17.2041s	
18258/22300 (epoch 40.937), train_loss = 0.46951542, grad/param norm = 3.8173e-01, time/batch = 15.2319s	
18259/22300 (epoch 40.939), train_loss = 0.40708383, grad/param norm = 2.7676e-01, time/batch = 16.3879s	
18260/22300 (epoch 40.942), train_loss = 0.51629154, grad/param norm = 3.5106e-01, time/batch = 17.8783s	
18261/22300 (epoch 40.944), train_loss = 0.52840823, grad/param norm = 3.1933e-01, time/batch = 15.8011s	
18262/22300 (epoch 40.946), train_loss = 0.40529945, grad/param norm = 2.5948e-01, time/batch = 16.6415s	
18263/22300 (epoch 40.948), train_loss = 0.34343877, grad/param norm = 1.8213e-01, time/batch = 16.5321s	
18264/22300 (epoch 40.951), train_loss = 0.27340645, grad/param norm = 2.2783e-01, time/batch = 17.3818s	
18265/22300 (epoch 40.953), train_loss = 0.29955312, grad/param norm = 2.4637e-01, time/batch = 17.2202s	
18266/22300 (epoch 40.955), train_loss = 0.46749973, grad/param norm = 2.8751e-01, time/batch = 15.4733s	
18267/22300 (epoch 40.957), train_loss = 0.55884087, grad/param norm = 2.9945e-01, time/batch = 17.4624s	
18268/22300 (epoch 40.960), train_loss = 0.48023816, grad/param norm = 2.7332e-01, time/batch = 16.6187s	
18269/22300 (epoch 40.962), train_loss = 0.28075699, grad/param norm = 2.1551e-01, time/batch = 17.9609s	
18270/22300 (epoch 40.964), train_loss = 0.30870962, grad/param norm = 2.1478e-01, time/batch = 15.4782s	
18271/22300 (epoch 40.966), train_loss = 0.32039193, grad/param norm = 2.3693e-01, time/batch = 17.4903s	
18272/22300 (epoch 40.969), train_loss = 0.33285739, grad/param norm = 1.9009e-01, time/batch = 17.4608s	
18273/22300 (epoch 40.971), train_loss = 0.36990000, grad/param norm = 2.6268e-01, time/batch = 16.6124s	
18274/22300 (epoch 40.973), train_loss = 0.33915733, grad/param norm = 3.2547e-01, time/batch = 15.4567s	
18275/22300 (epoch 40.975), train_loss = 0.50279594, grad/param norm = 4.8435e-01, time/batch = 16.3107s	
18276/22300 (epoch 40.978), train_loss = 0.47609339, grad/param norm = 2.7249e-01, time/batch = 19.7057s	
18277/22300 (epoch 40.980), train_loss = 0.55726418, grad/param norm = 3.9871e-01, time/batch = 15.2378s	
18278/22300 (epoch 40.982), train_loss = 0.28443360, grad/param norm = 2.3878e-01, time/batch = 18.4484s	
18279/22300 (epoch 40.984), train_loss = 0.36608237, grad/param norm = 2.4191e-01, time/batch = 16.3429s	
18280/22300 (epoch 40.987), train_loss = 0.37189942, grad/param norm = 2.6345e-01, time/batch = 15.4870s	
18281/22300 (epoch 40.989), train_loss = 0.29545794, grad/param norm = 2.6426e-01, time/batch = 16.1597s	
18282/22300 (epoch 40.991), train_loss = 0.54737935, grad/param norm = 3.3298e-01, time/batch = 18.4680s	
18283/22300 (epoch 40.993), train_loss = 0.75381509, grad/param norm = 4.4807e-01, time/batch = 16.3834s	
18284/22300 (epoch 40.996), train_loss = 0.67357654, grad/param norm = 4.0594e-01, time/batch = 15.6306s	
18285/22300 (epoch 40.998), train_loss = 0.41071612, grad/param norm = 2.6575e-01, time/batch = 17.2131s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
18286/22300 (epoch 41.000), train_loss = 0.32088830, grad/param norm = 2.6590e-01, time/batch = 16.1434s	
18287/22300 (epoch 41.002), train_loss = 0.66487219, grad/param norm = 3.1889e-01, time/batch = 15.1094s	
18288/22300 (epoch 41.004), train_loss = 0.44710428, grad/param norm = 2.6900e-01, time/batch = 15.2251s	
18289/22300 (epoch 41.007), train_loss = 0.45858608, grad/param norm = 2.8750e-01, time/batch = 17.1214s	
18290/22300 (epoch 41.009), train_loss = 0.46511518, grad/param norm = 3.5909e-01, time/batch = 17.4711s	
18291/22300 (epoch 41.011), train_loss = 0.56357012, grad/param norm = 3.5237e-01, time/batch = 17.3810s	
18292/22300 (epoch 41.013), train_loss = 0.44565408, grad/param norm = 2.7452e-01, time/batch = 16.2316s	
18293/22300 (epoch 41.016), train_loss = 0.32597411, grad/param norm = 2.6764e-01, time/batch = 16.2205s	
18294/22300 (epoch 41.018), train_loss = 0.38010576, grad/param norm = 2.7103e-01, time/batch = 16.6124s	
18295/22300 (epoch 41.020), train_loss = 0.33839627, grad/param norm = 2.3067e-01, time/batch = 15.2979s	
18296/22300 (epoch 41.022), train_loss = 0.27585597, grad/param norm = 2.7134e-01, time/batch = 17.3948s	
18297/22300 (epoch 41.025), train_loss = 0.31778938, grad/param norm = 2.1342e-01, time/batch = 14.9637s	
18298/22300 (epoch 41.027), train_loss = 0.30259087, grad/param norm = 1.9237e-01, time/batch = 18.3614s	
18299/22300 (epoch 41.029), train_loss = 0.34423935, grad/param norm = 2.8240e-01, time/batch = 17.7980s	
18300/22300 (epoch 41.031), train_loss = 0.30415774, grad/param norm = 1.9092e-01, time/batch = 15.8094s	
18301/22300 (epoch 41.034), train_loss = 0.30986246, grad/param norm = 2.2582e-01, time/batch = 17.9785s	
18302/22300 (epoch 41.036), train_loss = 0.30460030, grad/param norm = 2.0400e-01, time/batch = 16.7056s	
18303/22300 (epoch 41.038), train_loss = 0.26510900, grad/param norm = 2.1776e-01, time/batch = 16.5384s	
18304/22300 (epoch 41.040), train_loss = 0.33425030, grad/param norm = 2.6178e-01, time/batch = 16.3903s	
18305/22300 (epoch 41.043), train_loss = 0.54802482, grad/param norm = 3.2073e-01, time/batch = 17.5421s	
18306/22300 (epoch 41.045), train_loss = 0.46463836, grad/param norm = 2.6483e-01, time/batch = 16.0582s	
18307/22300 (epoch 41.047), train_loss = 0.46942915, grad/param norm = 3.3464e-01, time/batch = 17.4630s	
18308/22300 (epoch 41.049), train_loss = 0.36990645, grad/param norm = 2.3139e-01, time/batch = 16.8113s	
18309/22300 (epoch 41.052), train_loss = 0.40814326, grad/param norm = 2.6516e-01, time/batch = 16.8094s	
18310/22300 (epoch 41.054), train_loss = 0.42141202, grad/param norm = 2.8546e-01, time/batch = 17.2222s	
18311/22300 (epoch 41.056), train_loss = 0.21400320, grad/param norm = 1.6829e-01, time/batch = 16.0390s	
18312/22300 (epoch 41.058), train_loss = 0.36001806, grad/param norm = 2.6246e-01, time/batch = 18.3069s	
18313/22300 (epoch 41.061), train_loss = 0.30082482, grad/param norm = 2.4150e-01, time/batch = 16.5524s	
18314/22300 (epoch 41.063), train_loss = 0.47108763, grad/param norm = 3.3041e-01, time/batch = 15.7107s	
18315/22300 (epoch 41.065), train_loss = 0.54311903, grad/param norm = 4.0787e-01, time/batch = 16.7142s	
18316/22300 (epoch 41.067), train_loss = 0.30308486, grad/param norm = 2.4682e-01, time/batch = 15.4684s	
18317/22300 (epoch 41.070), train_loss = 0.36869977, grad/param norm = 2.5691e-01, time/batch = 14.7438s	
18318/22300 (epoch 41.072), train_loss = 0.40610948, grad/param norm = 3.1090e-01, time/batch = 14.9694s	
18319/22300 (epoch 41.074), train_loss = 0.41179864, grad/param norm = 2.6643e-01, time/batch = 14.8999s	
18320/22300 (epoch 41.076), train_loss = 0.40589706, grad/param norm = 3.2433e-01, time/batch = 15.7135s	
18321/22300 (epoch 41.078), train_loss = 0.53236288, grad/param norm = 3.4836e-01, time/batch = 15.0596s	
18322/22300 (epoch 41.081), train_loss = 0.51076388, grad/param norm = 3.5366e-01, time/batch = 16.0581s	
18323/22300 (epoch 41.083), train_loss = 0.56433659, grad/param norm = 3.2476e-01, time/batch = 18.0607s	
18324/22300 (epoch 41.085), train_loss = 0.55683381, grad/param norm = 3.9343e-01, time/batch = 16.1392s	
18325/22300 (epoch 41.087), train_loss = 0.44936179, grad/param norm = 3.3213e-01, time/batch = 15.4729s	
18326/22300 (epoch 41.090), train_loss = 0.43061422, grad/param norm = 3.4713e-01, time/batch = 16.6961s	
18327/22300 (epoch 41.092), train_loss = 0.31137288, grad/param norm = 2.3844e-01, time/batch = 15.2310s	
18328/22300 (epoch 41.094), train_loss = 0.29262090, grad/param norm = 2.2349e-01, time/batch = 16.1288s	
18329/22300 (epoch 41.096), train_loss = 0.53133165, grad/param norm = 3.5883e-01, time/batch = 17.3024s	
18330/22300 (epoch 41.099), train_loss = 0.34787225, grad/param norm = 2.4286e-01, time/batch = 18.2195s	
18331/22300 (epoch 41.101), train_loss = 0.45937889, grad/param norm = 2.7518e-01, time/batch = 15.6886s	
18332/22300 (epoch 41.103), train_loss = 0.38630733, grad/param norm = 2.6699e-01, time/batch = 18.0388s	
18333/22300 (epoch 41.105), train_loss = 0.29636811, grad/param norm = 2.4546e-01, time/batch = 16.6170s	
18334/22300 (epoch 41.108), train_loss = 0.42008808, grad/param norm = 2.4742e-01, time/batch = 18.3710s	
18335/22300 (epoch 41.110), train_loss = 0.49081488, grad/param norm = 2.8726e-01, time/batch = 15.3136s	
18336/22300 (epoch 41.112), train_loss = 0.41696532, grad/param norm = 2.3743e-01, time/batch = 16.9819s	
18337/22300 (epoch 41.114), train_loss = 0.46030178, grad/param norm = 2.7800e-01, time/batch = 18.4634s	
18338/22300 (epoch 41.117), train_loss = 0.53468792, grad/param norm = 3.3097e-01, time/batch = 16.0182s	
18339/22300 (epoch 41.119), train_loss = 0.46223107, grad/param norm = 3.2374e-01, time/batch = 16.4798s	
18340/22300 (epoch 41.121), train_loss = 0.52957539, grad/param norm = 2.9995e-01, time/batch = 17.4625s	
18341/22300 (epoch 41.123), train_loss = 0.58563023, grad/param norm = 3.3884e-01, time/batch = 16.6370s	
18342/22300 (epoch 41.126), train_loss = 0.42085940, grad/param norm = 2.8965e-01, time/batch = 16.1927s	
18343/22300 (epoch 41.128), train_loss = 0.41813537, grad/param norm = 2.7443e-01, time/batch = 18.3047s	
18344/22300 (epoch 41.130), train_loss = 0.37132782, grad/param norm = 2.4781e-01, time/batch = 15.8732s	
18345/22300 (epoch 41.132), train_loss = 0.27188568, grad/param norm = 1.8475e-01, time/batch = 16.7106s	
18346/22300 (epoch 41.135), train_loss = 0.27126743, grad/param norm = 2.0455e-01, time/batch = 16.2937s	
18347/22300 (epoch 41.137), train_loss = 0.22736229, grad/param norm = 1.7247e-01, time/batch = 16.7351s	
18348/22300 (epoch 41.139), train_loss = 0.34014647, grad/param norm = 2.5089e-01, time/batch = 17.8829s	
18349/22300 (epoch 41.141), train_loss = 0.45442051, grad/param norm = 3.4729e-01, time/batch = 16.2046s	
18350/22300 (epoch 41.143), train_loss = 0.37975138, grad/param norm = 2.4723e-01, time/batch = 18.8089s	
18351/22300 (epoch 41.146), train_loss = 0.48014258, grad/param norm = 3.3654e-01, time/batch = 16.2063s	
18352/22300 (epoch 41.148), train_loss = 0.30468423, grad/param norm = 2.1311e-01, time/batch = 16.2098s	
18353/22300 (epoch 41.150), train_loss = 0.33893357, grad/param norm = 2.3981e-01, time/batch = 16.1439s	
18354/22300 (epoch 41.152), train_loss = 0.29832257, grad/param norm = 2.3346e-01, time/batch = 17.3143s	
18355/22300 (epoch 41.155), train_loss = 0.31214034, grad/param norm = 2.1414e-01, time/batch = 18.4780s	
18356/22300 (epoch 41.157), train_loss = 0.41323259, grad/param norm = 3.9138e-01, time/batch = 15.0000s	
18357/22300 (epoch 41.159), train_loss = 0.42753999, grad/param norm = 3.4686e-01, time/batch = 16.2983s	
18358/22300 (epoch 41.161), train_loss = 0.42462639, grad/param norm = 3.4547e-01, time/batch = 15.7856s	
18359/22300 (epoch 41.164), train_loss = 0.31459298, grad/param norm = 2.3841e-01, time/batch = 14.4141s	
18360/22300 (epoch 41.166), train_loss = 0.27528365, grad/param norm = 1.9473e-01, time/batch = 15.4444s	
18361/22300 (epoch 41.168), train_loss = 0.28518494, grad/param norm = 2.7356e-01, time/batch = 17.3898s	
18362/22300 (epoch 41.170), train_loss = 0.37411375, grad/param norm = 2.6470e-01, time/batch = 18.2193s	
18363/22300 (epoch 41.173), train_loss = 0.43263999, grad/param norm = 2.9293e-01, time/batch = 16.2253s	
18364/22300 (epoch 41.175), train_loss = 0.37984900, grad/param norm = 2.4803e-01, time/batch = 16.9011s	
18365/22300 (epoch 41.177), train_loss = 0.26086734, grad/param norm = 2.4130e-01, time/batch = 17.2969s	
18366/22300 (epoch 41.179), train_loss = 0.38026191, grad/param norm = 2.5410e-01, time/batch = 17.9585s	
18367/22300 (epoch 41.182), train_loss = 0.52552355, grad/param norm = 3.7164e-01, time/batch = 15.7175s	
18368/22300 (epoch 41.184), train_loss = 0.54083600, grad/param norm = 3.1961e-01, time/batch = 17.4620s	
18369/22300 (epoch 41.186), train_loss = 0.41414225, grad/param norm = 3.0725e-01, time/batch = 16.6177s	
18370/22300 (epoch 41.188), train_loss = 0.59617158, grad/param norm = 3.8934e-01, time/batch = 15.6454s	
18371/22300 (epoch 41.191), train_loss = 0.49224305, grad/param norm = 3.4215e-01, time/batch = 15.4887s	
18372/22300 (epoch 41.193), train_loss = 0.41652305, grad/param norm = 2.9285e-01, time/batch = 16.7181s	
18373/22300 (epoch 41.195), train_loss = 0.38888662, grad/param norm = 3.0084e-01, time/batch = 18.7045s	
18374/22300 (epoch 41.197), train_loss = 0.32251989, grad/param norm = 2.2717e-01, time/batch = 16.2033s	
18375/22300 (epoch 41.200), train_loss = 0.30693531, grad/param norm = 2.3258e-01, time/batch = 16.3955s	
18376/22300 (epoch 41.202), train_loss = 0.31500835, grad/param norm = 2.3492e-01, time/batch = 15.7309s	
18377/22300 (epoch 41.204), train_loss = 0.39776702, grad/param norm = 2.4960e-01, time/batch = 15.5383s	
18378/22300 (epoch 41.206), train_loss = 0.31038181, grad/param norm = 2.6321e-01, time/batch = 15.6378s	
18379/22300 (epoch 41.209), train_loss = 0.34403565, grad/param norm = 2.6646e-01, time/batch = 18.3752s	
18380/22300 (epoch 41.211), train_loss = 0.28340157, grad/param norm = 2.4266e-01, time/batch = 16.7281s	
18381/22300 (epoch 41.213), train_loss = 0.39994687, grad/param norm = 2.4580e-01, time/batch = 16.0530s	
18382/22300 (epoch 41.215), train_loss = 0.48240877, grad/param norm = 3.0836e-01, time/batch = 18.0643s	
18383/22300 (epoch 41.217), train_loss = 0.50371996, grad/param norm = 2.7140e-01, time/batch = 17.1237s	
18384/22300 (epoch 41.220), train_loss = 0.37681593, grad/param norm = 2.5031e-01, time/batch = 17.6207s	
18385/22300 (epoch 41.222), train_loss = 0.35590471, grad/param norm = 2.8486e-01, time/batch = 15.6449s	
18386/22300 (epoch 41.224), train_loss = 0.32228363, grad/param norm = 2.4232e-01, time/batch = 16.0143s	
18387/22300 (epoch 41.226), train_loss = 0.36744729, grad/param norm = 2.2064e-01, time/batch = 16.8718s	
18388/22300 (epoch 41.229), train_loss = 0.29720844, grad/param norm = 1.9611e-01, time/batch = 16.6335s	
18389/22300 (epoch 41.231), train_loss = 0.49275801, grad/param norm = 3.4185e-01, time/batch = 16.1527s	
18390/22300 (epoch 41.233), train_loss = 0.37813792, grad/param norm = 2.3847e-01, time/batch = 17.7890s	
18391/22300 (epoch 41.235), train_loss = 0.30734392, grad/param norm = 2.1798e-01, time/batch = 18.1396s	
18392/22300 (epoch 41.238), train_loss = 0.30533542, grad/param norm = 2.0136e-01, time/batch = 15.8493s	
18393/22300 (epoch 41.240), train_loss = 0.30862456, grad/param norm = 1.8706e-01, time/batch = 18.5325s	
18394/22300 (epoch 41.242), train_loss = 0.27815657, grad/param norm = 2.3785e-01, time/batch = 14.9668s	
18395/22300 (epoch 41.244), train_loss = 0.20182397, grad/param norm = 1.8095e-01, time/batch = 15.4747s	
18396/22300 (epoch 41.247), train_loss = 0.28682635, grad/param norm = 2.3744e-01, time/batch = 14.8785s	
18397/22300 (epoch 41.249), train_loss = 0.19894308, grad/param norm = 1.6636e-01, time/batch = 16.4848s	
18398/22300 (epoch 41.251), train_loss = 0.26315733, grad/param norm = 1.7416e-01, time/batch = 15.2784s	
18399/22300 (epoch 41.253), train_loss = 0.18157434, grad/param norm = 1.9397e-01, time/batch = 15.9766s	
18400/22300 (epoch 41.256), train_loss = 0.26323139, grad/param norm = 2.4801e-01, time/batch = 15.6395s	
18401/22300 (epoch 41.258), train_loss = 0.37660448, grad/param norm = 2.3711e-01, time/batch = 18.1326s	
18402/22300 (epoch 41.260), train_loss = 0.39139526, grad/param norm = 2.3183e-01, time/batch = 17.7057s	
18403/22300 (epoch 41.262), train_loss = 0.28679282, grad/param norm = 1.7871e-01, time/batch = 15.4588s	
18404/22300 (epoch 41.265), train_loss = 0.26964650, grad/param norm = 2.1232e-01, time/batch = 16.9780s	
18405/22300 (epoch 41.267), train_loss = 0.29179146, grad/param norm = 2.0372e-01, time/batch = 16.4644s	
18406/22300 (epoch 41.269), train_loss = 0.37951307, grad/param norm = 3.0879e-01, time/batch = 17.4567s	
18407/22300 (epoch 41.271), train_loss = 0.40569786, grad/param norm = 2.1731e-01, time/batch = 15.9653s	
18408/22300 (epoch 41.274), train_loss = 0.27218620, grad/param norm = 2.3204e-01, time/batch = 16.1531s	
18409/22300 (epoch 41.276), train_loss = 0.24323768, grad/param norm = 1.8357e-01, time/batch = 18.3139s	
18410/22300 (epoch 41.278), train_loss = 0.26186595, grad/param norm = 2.3581e-01, time/batch = 15.9684s	
18411/22300 (epoch 41.280), train_loss = 0.28902823, grad/param norm = 2.3719e-01, time/batch = 17.4703s	
18412/22300 (epoch 41.283), train_loss = 0.23571391, grad/param norm = 2.0288e-01, time/batch = 15.9025s	
18413/22300 (epoch 41.285), train_loss = 0.24616045, grad/param norm = 1.8931e-01, time/batch = 17.3704s	
18414/22300 (epoch 41.287), train_loss = 0.35215378, grad/param norm = 2.2274e-01, time/batch = 16.8858s	
18415/22300 (epoch 41.289), train_loss = 0.33046458, grad/param norm = 2.5063e-01, time/batch = 14.7273s	
18416/22300 (epoch 41.291), train_loss = 0.33040034, grad/param norm = 2.3453e-01, time/batch = 14.7228s	
18417/22300 (epoch 41.294), train_loss = 0.27278992, grad/param norm = 1.7519e-01, time/batch = 16.4441s	
18418/22300 (epoch 41.296), train_loss = 0.30901232, grad/param norm = 2.6564e-01, time/batch = 16.1297s	
18419/22300 (epoch 41.298), train_loss = 0.42420080, grad/param norm = 2.6097e-01, time/batch = 16.1304s	
18420/22300 (epoch 41.300), train_loss = 0.46456615, grad/param norm = 2.7804e-01, time/batch = 18.1372s	
18421/22300 (epoch 41.303), train_loss = 0.34919530, grad/param norm = 2.3438e-01, time/batch = 16.2992s	
18422/22300 (epoch 41.305), train_loss = 0.34499875, grad/param norm = 2.3444e-01, time/batch = 15.4001s	
18423/22300 (epoch 41.307), train_loss = 0.28626308, grad/param norm = 1.6050e-01, time/batch = 15.0666s	
18424/22300 (epoch 41.309), train_loss = 0.28337116, grad/param norm = 2.8369e-01, time/batch = 15.6390s	
18425/22300 (epoch 41.312), train_loss = 0.23333752, grad/param norm = 1.7177e-01, time/batch = 16.8033s	
18426/22300 (epoch 41.314), train_loss = 0.28314232, grad/param norm = 2.1178e-01, time/batch = 16.6579s	
18427/22300 (epoch 41.316), train_loss = 0.26765314, grad/param norm = 2.2298e-01, time/batch = 16.1315s	
18428/22300 (epoch 41.318), train_loss = 0.29438976, grad/param norm = 2.1527e-01, time/batch = 22.3090s	
18429/22300 (epoch 41.321), train_loss = 0.38048903, grad/param norm = 2.4667e-01, time/batch = 22.8939s	
18430/22300 (epoch 41.323), train_loss = 0.28333529, grad/param norm = 2.2998e-01, time/batch = 15.3779s	
18431/22300 (epoch 41.325), train_loss = 0.24906032, grad/param norm = 2.1118e-01, time/batch = 15.3019s	
18432/22300 (epoch 41.327), train_loss = 0.26096708, grad/param norm = 1.8647e-01, time/batch = 16.8857s	
18433/22300 (epoch 41.330), train_loss = 0.27210891, grad/param norm = 2.4285e-01, time/batch = 16.5463s	
18434/22300 (epoch 41.332), train_loss = 0.24127670, grad/param norm = 2.0282e-01, time/batch = 15.6366s	
18435/22300 (epoch 41.334), train_loss = 0.29568858, grad/param norm = 2.2255e-01, time/batch = 15.1366s	
18436/22300 (epoch 41.336), train_loss = 0.29610031, grad/param norm = 2.0032e-01, time/batch = 17.4553s	
18437/22300 (epoch 41.339), train_loss = 0.35732485, grad/param norm = 2.6663e-01, time/batch = 16.5664s	
18438/22300 (epoch 41.341), train_loss = 0.36104743, grad/param norm = 2.5738e-01, time/batch = 17.3057s	
18439/22300 (epoch 41.343), train_loss = 0.38427549, grad/param norm = 2.5115e-01, time/batch = 14.8760s	
18440/22300 (epoch 41.345), train_loss = 0.31690673, grad/param norm = 2.1379e-01, time/batch = 15.7330s	
18441/22300 (epoch 41.348), train_loss = 0.33121137, grad/param norm = 2.2366e-01, time/batch = 15.4392s	
18442/22300 (epoch 41.350), train_loss = 0.23183119, grad/param norm = 1.7330e-01, time/batch = 14.6310s	
18443/22300 (epoch 41.352), train_loss = 0.33024071, grad/param norm = 2.3016e-01, time/batch = 15.8827s	
18444/22300 (epoch 41.354), train_loss = 0.46804418, grad/param norm = 3.3816e-01, time/batch = 15.8192s	
18445/22300 (epoch 41.357), train_loss = 0.44376915, grad/param norm = 2.5608e-01, time/batch = 17.8839s	
18446/22300 (epoch 41.359), train_loss = 0.28457687, grad/param norm = 2.3429e-01, time/batch = 15.8790s	
18447/22300 (epoch 41.361), train_loss = 0.30648768, grad/param norm = 2.6084e-01, time/batch = 15.9574s	
18448/22300 (epoch 41.363), train_loss = 0.37959937, grad/param norm = 2.4194e-01, time/batch = 16.8913s	
18449/22300 (epoch 41.365), train_loss = 0.28596427, grad/param norm = 2.4816e-01, time/batch = 17.7933s	
18450/22300 (epoch 41.368), train_loss = 0.28393043, grad/param norm = 2.2597e-01, time/batch = 16.6470s	
18451/22300 (epoch 41.370), train_loss = 0.29828513, grad/param norm = 2.0545e-01, time/batch = 17.9624s	
18452/22300 (epoch 41.372), train_loss = 0.21649506, grad/param norm = 1.9947e-01, time/batch = 15.6230s	
18453/22300 (epoch 41.374), train_loss = 0.22925447, grad/param norm = 1.4829e-01, time/batch = 16.0529s	
18454/22300 (epoch 41.377), train_loss = 0.31697971, grad/param norm = 2.6997e-01, time/batch = 15.7352s	
18455/22300 (epoch 41.379), train_loss = 0.29112109, grad/param norm = 2.5031e-01, time/batch = 15.9797s	
18456/22300 (epoch 41.381), train_loss = 0.37950736, grad/param norm = 2.4580e-01, time/batch = 18.4535s	
18457/22300 (epoch 41.383), train_loss = 0.28390769, grad/param norm = 2.0382e-01, time/batch = 16.7823s	
18458/22300 (epoch 41.386), train_loss = 0.34149166, grad/param norm = 2.4631e-01, time/batch = 15.9703s	
18459/22300 (epoch 41.388), train_loss = 0.25934123, grad/param norm = 2.7356e-01, time/batch = 15.2025s	
18460/22300 (epoch 41.390), train_loss = 0.26934820, grad/param norm = 2.3965e-01, time/batch = 16.4502s	
18461/22300 (epoch 41.392), train_loss = 0.29393069, grad/param norm = 2.3701e-01, time/batch = 16.4512s	
18462/22300 (epoch 41.395), train_loss = 0.23343822, grad/param norm = 1.6061e-01, time/batch = 17.3920s	
18463/22300 (epoch 41.397), train_loss = 0.19017039, grad/param norm = 1.5809e-01, time/batch = 19.1219s	
18464/22300 (epoch 41.399), train_loss = 0.25690067, grad/param norm = 2.9170e-01, time/batch = 15.0988s	
18465/22300 (epoch 41.401), train_loss = 0.28494060, grad/param norm = 2.3259e-01, time/batch = 17.8808s	
18466/22300 (epoch 41.404), train_loss = 0.31926143, grad/param norm = 2.5398e-01, time/batch = 14.8332s	
18467/22300 (epoch 41.406), train_loss = 0.45742790, grad/param norm = 2.6840e-01, time/batch = 17.3041s	
18468/22300 (epoch 41.408), train_loss = 0.34931113, grad/param norm = 2.8602e-01, time/batch = 16.6337s	
18469/22300 (epoch 41.410), train_loss = 0.39852386, grad/param norm = 2.7599e-01, time/batch = 16.2982s	
18470/22300 (epoch 41.413), train_loss = 0.29243100, grad/param norm = 2.2740e-01, time/batch = 17.5520s	
18471/22300 (epoch 41.415), train_loss = 0.22074104, grad/param norm = 2.1242e-01, time/batch = 15.8199s	
18472/22300 (epoch 41.417), train_loss = 0.33535454, grad/param norm = 2.4145e-01, time/batch = 16.3770s	
18473/22300 (epoch 41.419), train_loss = 0.29651605, grad/param norm = 1.8237e-01, time/batch = 15.6556s	
18474/22300 (epoch 41.422), train_loss = 0.26606363, grad/param norm = 2.4331e-01, time/batch = 17.9566s	
18475/22300 (epoch 41.424), train_loss = 0.31882644, grad/param norm = 2.3905e-01, time/batch = 16.1157s	
18476/22300 (epoch 41.426), train_loss = 0.21942223, grad/param norm = 1.8528e-01, time/batch = 16.8954s	
18477/22300 (epoch 41.428), train_loss = 0.24497221, grad/param norm = 2.0382e-01, time/batch = 16.0248s	
18478/22300 (epoch 41.430), train_loss = 0.29392446, grad/param norm = 2.4662e-01, time/batch = 15.2939s	
18479/22300 (epoch 41.433), train_loss = 0.29398325, grad/param norm = 1.9067e-01, time/batch = 14.6594s	
18480/22300 (epoch 41.435), train_loss = 0.28817313, grad/param norm = 2.2899e-01, time/batch = 18.6902s	
18481/22300 (epoch 41.437), train_loss = 0.34351026, grad/param norm = 2.5910e-01, time/batch = 17.3233s	
18482/22300 (epoch 41.439), train_loss = 0.38414385, grad/param norm = 2.5309e-01, time/batch = 15.6839s	
18483/22300 (epoch 41.442), train_loss = 0.31537497, grad/param norm = 2.1550e-01, time/batch = 16.1507s	
18484/22300 (epoch 41.444), train_loss = 0.26831639, grad/param norm = 2.4304e-01, time/batch = 15.1652s	
18485/22300 (epoch 41.446), train_loss = 0.29842264, grad/param norm = 2.2836e-01, time/batch = 18.0493s	
18486/22300 (epoch 41.448), train_loss = 0.22474874, grad/param norm = 1.3927e-01, time/batch = 15.3833s	
18487/22300 (epoch 41.451), train_loss = 0.35117307, grad/param norm = 2.3036e-01, time/batch = 16.1410s	
18488/22300 (epoch 41.453), train_loss = 0.28031791, grad/param norm = 1.9694e-01, time/batch = 17.4627s	
18489/22300 (epoch 41.455), train_loss = 0.37789407, grad/param norm = 2.7842e-01, time/batch = 17.0496s	
18490/22300 (epoch 41.457), train_loss = 0.49167996, grad/param norm = 2.7984e-01, time/batch = 15.8900s	
18491/22300 (epoch 41.460), train_loss = 0.42751458, grad/param norm = 3.6035e-01, time/batch = 15.1438s	
18492/22300 (epoch 41.462), train_loss = 0.43311666, grad/param norm = 3.0234e-01, time/batch = 16.9873s	
18493/22300 (epoch 41.464), train_loss = 0.37708122, grad/param norm = 3.1587e-01, time/batch = 16.7193s	
18494/22300 (epoch 41.466), train_loss = 0.29853579, grad/param norm = 2.6156e-01, time/batch = 17.8056s	
18495/22300 (epoch 41.469), train_loss = 0.27434629, grad/param norm = 1.5779e-01, time/batch = 15.6952s	
18496/22300 (epoch 41.471), train_loss = 0.39684908, grad/param norm = 2.3876e-01, time/batch = 16.7184s	
18497/22300 (epoch 41.473), train_loss = 0.33981196, grad/param norm = 2.1256e-01, time/batch = 15.9650s	
18498/22300 (epoch 41.475), train_loss = 0.27861609, grad/param norm = 2.2248e-01, time/batch = 16.0717s	
18499/22300 (epoch 41.478), train_loss = 0.29934006, grad/param norm = 2.5127e-01, time/batch = 17.2232s	
18500/22300 (epoch 41.480), train_loss = 0.24038942, grad/param norm = 2.5281e-01, time/batch = 16.9518s	
18501/22300 (epoch 41.482), train_loss = 0.25700362, grad/param norm = 1.9028e-01, time/batch = 16.0664s	
18502/22300 (epoch 41.484), train_loss = 0.33060196, grad/param norm = 2.1586e-01, time/batch = 15.6551s	
18503/22300 (epoch 41.487), train_loss = 0.39387496, grad/param norm = 2.4392e-01, time/batch = 16.4102s	
18504/22300 (epoch 41.489), train_loss = 0.36447793, grad/param norm = 2.0573e-01, time/batch = 15.5406s	
18505/22300 (epoch 41.491), train_loss = 0.41481680, grad/param norm = 2.8507e-01, time/batch = 17.8781s	
18506/22300 (epoch 41.493), train_loss = 0.31305805, grad/param norm = 4.3662e-01, time/batch = 17.0562s	
18507/22300 (epoch 41.496), train_loss = 0.34590773, grad/param norm = 2.1438e-01, time/batch = 16.3763s	
18508/22300 (epoch 41.498), train_loss = 0.22836452, grad/param norm = 1.8738e-01, time/batch = 16.1552s	
18509/22300 (epoch 41.500), train_loss = 0.31059105, grad/param norm = 2.1551e-01, time/batch = 15.9681s	
18510/22300 (epoch 41.502), train_loss = 0.20055149, grad/param norm = 1.6347e-01, time/batch = 16.3441s	
18511/22300 (epoch 41.504), train_loss = 0.22550089, grad/param norm = 1.9119e-01, time/batch = 17.1263s	
18512/22300 (epoch 41.507), train_loss = 0.25950849, grad/param norm = 2.2894e-01, time/batch = 17.8066s	
18513/22300 (epoch 41.509), train_loss = 0.37002747, grad/param norm = 2.4157e-01, time/batch = 16.2044s	
18514/22300 (epoch 41.511), train_loss = 0.21857052, grad/param norm = 1.7813e-01, time/batch = 16.7097s	
18515/22300 (epoch 41.513), train_loss = 0.22948354, grad/param norm = 1.6844e-01, time/batch = 16.2829s	
18516/22300 (epoch 41.516), train_loss = 0.27327417, grad/param norm = 2.1802e-01, time/batch = 16.3783s	
18517/22300 (epoch 41.518), train_loss = 0.33653181, grad/param norm = 2.5781e-01, time/batch = 16.4635s	
18518/22300 (epoch 41.520), train_loss = 0.28470149, grad/param norm = 2.1304e-01, time/batch = 16.5337s	
18519/22300 (epoch 41.522), train_loss = 0.32064351, grad/param norm = 2.2654e-01, time/batch = 17.9707s	
18520/22300 (epoch 41.525), train_loss = 0.24034948, grad/param norm = 2.2922e-01, time/batch = 16.9667s	
18521/22300 (epoch 41.527), train_loss = 0.39190996, grad/param norm = 3.9561e-01, time/batch = 17.4593s	
18522/22300 (epoch 41.529), train_loss = 0.32169991, grad/param norm = 2.1659e-01, time/batch = 15.3866s	
18523/22300 (epoch 41.531), train_loss = 0.29310884, grad/param norm = 2.3648e-01, time/batch = 17.6421s	
18524/22300 (epoch 41.534), train_loss = 0.32223799, grad/param norm = 2.1548e-01, time/batch = 16.0647s	
18525/22300 (epoch 41.536), train_loss = 0.46724379, grad/param norm = 2.9054e-01, time/batch = 16.5352s	
18526/22300 (epoch 41.538), train_loss = 0.58160549, grad/param norm = 4.0400e-01, time/batch = 17.1146s	
18527/22300 (epoch 41.540), train_loss = 0.31959371, grad/param norm = 2.3382e-01, time/batch = 18.9601s	
18528/22300 (epoch 41.543), train_loss = 0.33325830, grad/param norm = 2.5054e-01, time/batch = 16.2144s	
18529/22300 (epoch 41.545), train_loss = 0.21961678, grad/param norm = 1.8780e-01, time/batch = 15.5397s	
18530/22300 (epoch 41.547), train_loss = 0.20408473, grad/param norm = 2.1184e-01, time/batch = 16.9043s	
18531/22300 (epoch 41.549), train_loss = 0.23911288, grad/param norm = 2.0518e-01, time/batch = 16.0281s	
18532/22300 (epoch 41.552), train_loss = 0.25153099, grad/param norm = 2.0840e-01, time/batch = 15.5574s	
18533/22300 (epoch 41.554), train_loss = 0.34354273, grad/param norm = 2.6291e-01, time/batch = 16.7256s	
18534/22300 (epoch 41.556), train_loss = 0.48852360, grad/param norm = 3.5105e-01, time/batch = 17.0658s	
18535/22300 (epoch 41.558), train_loss = 0.35268789, grad/param norm = 2.6593e-01, time/batch = 18.2077s	
18536/22300 (epoch 41.561), train_loss = 0.49875754, grad/param norm = 4.0679e-01, time/batch = 15.6985s	
18537/22300 (epoch 41.563), train_loss = 0.38275277, grad/param norm = 2.3321e-01, time/batch = 17.2218s	
18538/22300 (epoch 41.565), train_loss = 0.30007889, grad/param norm = 2.0775e-01, time/batch = 16.0688s	
18539/22300 (epoch 41.567), train_loss = 0.31215305, grad/param norm = 2.3837e-01, time/batch = 16.4675s	
18540/22300 (epoch 41.570), train_loss = 0.43467057, grad/param norm = 3.4915e-01, time/batch = 15.3742s	
18541/22300 (epoch 41.572), train_loss = 0.43056699, grad/param norm = 2.5644e-01, time/batch = 17.4621s	
18542/22300 (epoch 41.574), train_loss = 0.32089400, grad/param norm = 2.3269e-01, time/batch = 16.1468s	
18543/22300 (epoch 41.576), train_loss = 0.28538345, grad/param norm = 1.9956e-01, time/batch = 16.6235s	
18544/22300 (epoch 41.578), train_loss = 0.17513827, grad/param norm = 1.8105e-01, time/batch = 17.0402s	
18545/22300 (epoch 41.581), train_loss = 0.24796995, grad/param norm = 2.2490e-01, time/batch = 16.0266s	
18546/22300 (epoch 41.583), train_loss = 0.30019843, grad/param norm = 2.4592e-01, time/batch = 15.4499s	
18547/22300 (epoch 41.585), train_loss = 0.39353345, grad/param norm = 2.9081e-01, time/batch = 16.2998s	
18548/22300 (epoch 41.587), train_loss = 0.57907383, grad/param norm = 4.1301e-01, time/batch = 18.3031s	
18549/22300 (epoch 41.590), train_loss = 0.49894840, grad/param norm = 4.5376e-01, time/batch = 15.2137s	
18550/22300 (epoch 41.592), train_loss = 0.54793183, grad/param norm = 3.5373e-01, time/batch = 16.6418s	
18551/22300 (epoch 41.594), train_loss = 0.53073255, grad/param norm = 4.1326e-01, time/batch = 14.6658s	
18552/22300 (epoch 41.596), train_loss = 0.32549508, grad/param norm = 2.6748e-01, time/batch = 16.2319s	
18553/22300 (epoch 41.599), train_loss = 0.24967741, grad/param norm = 3.5886e-01, time/batch = 18.1342s	
18554/22300 (epoch 41.601), train_loss = 0.30203664, grad/param norm = 3.0017e-01, time/batch = 16.2854s	
18555/22300 (epoch 41.603), train_loss = 0.27753301, grad/param norm = 1.9122e-01, time/batch = 16.2299s	
18556/22300 (epoch 41.605), train_loss = 0.32640848, grad/param norm = 2.7616e-01, time/batch = 15.7387s	
18557/22300 (epoch 41.608), train_loss = 0.51213362, grad/param norm = 3.3336e-01, time/batch = 18.0492s	
18558/22300 (epoch 41.610), train_loss = 0.58167794, grad/param norm = 2.9435e-01, time/batch = 14.7243s	
18559/22300 (epoch 41.612), train_loss = 0.39561751, grad/param norm = 2.4671e-01, time/batch = 17.3006s	
18560/22300 (epoch 41.614), train_loss = 0.38621145, grad/param norm = 3.6758e-01, time/batch = 15.7860s	
18561/22300 (epoch 41.617), train_loss = 0.43838762, grad/param norm = 2.6594e-01, time/batch = 14.9546s	
18562/22300 (epoch 41.619), train_loss = 0.43194127, grad/param norm = 3.0217e-01, time/batch = 16.5591s	
18563/22300 (epoch 41.621), train_loss = 0.29055797, grad/param norm = 2.3532e-01, time/batch = 17.8799s	
18564/22300 (epoch 41.623), train_loss = 0.31225416, grad/param norm = 2.2161e-01, time/batch = 17.0298s	
18565/22300 (epoch 41.626), train_loss = 0.27650526, grad/param norm = 2.0544e-01, time/batch = 15.3031s	
18566/22300 (epoch 41.628), train_loss = 0.29632211, grad/param norm = 1.9827e-01, time/batch = 18.2932s	
18567/22300 (epoch 41.630), train_loss = 0.33411504, grad/param norm = 2.0958e-01, time/batch = 14.9616s	
18568/22300 (epoch 41.632), train_loss = 0.29628061, grad/param norm = 2.4050e-01, time/batch = 16.2969s	
18569/22300 (epoch 41.635), train_loss = 0.34602699, grad/param norm = 2.3875e-01, time/batch = 15.6388s	
18570/22300 (epoch 41.637), train_loss = 0.37490451, grad/param norm = 2.7754e-01, time/batch = 16.8783s	
18571/22300 (epoch 41.639), train_loss = 0.45812047, grad/param norm = 2.8590e-01, time/batch = 16.5490s	
18572/22300 (epoch 41.641), train_loss = 0.35983079, grad/param norm = 2.0716e-01, time/batch = 16.9379s	
18573/22300 (epoch 41.643), train_loss = 0.30546163, grad/param norm = 3.0355e-01, time/batch = 16.7794s	
18574/22300 (epoch 41.646), train_loss = 0.29705486, grad/param norm = 2.5489e-01, time/batch = 17.0655s	
18575/22300 (epoch 41.648), train_loss = 0.39566302, grad/param norm = 2.3757e-01, time/batch = 16.2268s	
18576/22300 (epoch 41.650), train_loss = 0.36361001, grad/param norm = 2.1173e-01, time/batch = 15.8924s	
18577/22300 (epoch 41.652), train_loss = 0.32066927, grad/param norm = 2.5708e-01, time/batch = 17.2949s	
18578/22300 (epoch 41.655), train_loss = 0.26966227, grad/param norm = 2.2040e-01, time/batch = 17.9701s	
18579/22300 (epoch 41.657), train_loss = 0.31789999, grad/param norm = 2.9089e-01, time/batch = 17.6252s	
18580/22300 (epoch 41.659), train_loss = 0.29651595, grad/param norm = 2.6643e-01, time/batch = 16.7971s	
18581/22300 (epoch 41.661), train_loss = 0.24280230, grad/param norm = 1.9444e-01, time/batch = 16.3126s	
18582/22300 (epoch 41.664), train_loss = 0.30302847, grad/param norm = 2.2573e-01, time/batch = 16.4360s	
18583/22300 (epoch 41.666), train_loss = 0.36141869, grad/param norm = 2.5033e-01, time/batch = 16.0702s	
18584/22300 (epoch 41.668), train_loss = 0.26707416, grad/param norm = 1.7654e-01, time/batch = 17.7971s	
18585/22300 (epoch 41.670), train_loss = 0.33374354, grad/param norm = 2.5726e-01, time/batch = 15.9364s	
18586/22300 (epoch 41.673), train_loss = 0.41837783, grad/param norm = 2.3472e-01, time/batch = 16.6300s	
18587/22300 (epoch 41.675), train_loss = 0.43066183, grad/param norm = 3.1373e-01, time/batch = 14.8239s	
18588/22300 (epoch 41.677), train_loss = 0.51140527, grad/param norm = 3.4662e-01, time/batch = 18.1328s	
18589/22300 (epoch 41.679), train_loss = 0.33783093, grad/param norm = 2.4891e-01, time/batch = 17.2144s	
18590/22300 (epoch 41.682), train_loss = 0.32135936, grad/param norm = 2.0421e-01, time/batch = 16.7019s	
18591/22300 (epoch 41.684), train_loss = 0.30936325, grad/param norm = 2.0250e-01, time/batch = 15.3013s	
18592/22300 (epoch 41.686), train_loss = 0.30235066, grad/param norm = 2.3556e-01, time/batch = 16.0695s	
18593/22300 (epoch 41.688), train_loss = 0.29281119, grad/param norm = 2.7091e-01, time/batch = 16.8201s	
18594/22300 (epoch 41.691), train_loss = 0.28177028, grad/param norm = 3.3691e-01, time/batch = 15.4651s	
18595/22300 (epoch 41.693), train_loss = 0.25652356, grad/param norm = 2.1371e-01, time/batch = 18.2236s	
18596/22300 (epoch 41.695), train_loss = 0.28149932, grad/param norm = 1.9223e-01, time/batch = 17.0510s	
18597/22300 (epoch 41.697), train_loss = 0.30853711, grad/param norm = 1.7781e-01, time/batch = 16.5569s	
18598/22300 (epoch 41.700), train_loss = 0.27301868, grad/param norm = 2.1999e-01, time/batch = 14.3377s	
18599/22300 (epoch 41.702), train_loss = 0.21960837, grad/param norm = 1.6535e-01, time/batch = 17.1943s	
18600/22300 (epoch 41.704), train_loss = 0.30335387, grad/param norm = 2.9011e-01, time/batch = 15.7060s	
18601/22300 (epoch 41.706), train_loss = 0.27445122, grad/param norm = 2.0841e-01, time/batch = 15.5440s	
18602/22300 (epoch 41.709), train_loss = 0.22448457, grad/param norm = 1.7588e-01, time/batch = 17.7113s	
18603/22300 (epoch 41.711), train_loss = 0.21889497, grad/param norm = 1.5201e-01, time/batch = 16.1994s	
18604/22300 (epoch 41.713), train_loss = 0.32966589, grad/param norm = 2.6054e-01, time/batch = 16.8082s	
18605/22300 (epoch 41.715), train_loss = 0.33823437, grad/param norm = 2.1227e-01, time/batch = 16.2012s	
18606/22300 (epoch 41.717), train_loss = 0.44690653, grad/param norm = 2.5647e-01, time/batch = 17.4633s	
18607/22300 (epoch 41.720), train_loss = 0.28863048, grad/param norm = 2.5076e-01, time/batch = 16.2039s	
18608/22300 (epoch 41.722), train_loss = 0.33207650, grad/param norm = 2.6420e-01, time/batch = 15.2780s	
18609/22300 (epoch 41.724), train_loss = 0.36460516, grad/param norm = 3.0405e-01, time/batch = 15.7470s	
18610/22300 (epoch 41.726), train_loss = 0.28780077, grad/param norm = 2.3692e-01, time/batch = 17.0654s	
18611/22300 (epoch 41.729), train_loss = 0.34099088, grad/param norm = 2.5655e-01, time/batch = 16.2483s	
18612/22300 (epoch 41.731), train_loss = 0.41714654, grad/param norm = 3.7389e-01, time/batch = 15.1295s	
18613/22300 (epoch 41.733), train_loss = 0.41817344, grad/param norm = 3.2295e-01, time/batch = 15.9705s	
18614/22300 (epoch 41.735), train_loss = 0.44916462, grad/param norm = 2.9028e-01, time/batch = 15.8986s	
18615/22300 (epoch 41.738), train_loss = 0.31356651, grad/param norm = 2.8563e-01, time/batch = 17.7982s	
18616/22300 (epoch 41.740), train_loss = 0.29784797, grad/param norm = 2.1251e-01, time/batch = 16.2933s	
18617/22300 (epoch 41.742), train_loss = 0.27495614, grad/param norm = 2.2660e-01, time/batch = 17.6500s	
18618/22300 (epoch 41.744), train_loss = 0.47484782, grad/param norm = 2.7110e-01, time/batch = 17.4708s	
18619/22300 (epoch 41.747), train_loss = 0.38974486, grad/param norm = 2.2958e-01, time/batch = 16.8961s	
18620/22300 (epoch 41.749), train_loss = 0.48630182, grad/param norm = 3.1422e-01, time/batch = 16.0530s	
18621/22300 (epoch 41.751), train_loss = 0.43555941, grad/param norm = 3.7874e-01, time/batch = 16.5306s	
18622/22300 (epoch 41.753), train_loss = 0.47071017, grad/param norm = 4.0285e-01, time/batch = 17.4717s	
18623/22300 (epoch 41.756), train_loss = 0.44325275, grad/param norm = 2.5906e-01, time/batch = 15.5419s	
18624/22300 (epoch 41.758), train_loss = 0.35853855, grad/param norm = 2.5564e-01, time/batch = 17.0594s	
18625/22300 (epoch 41.760), train_loss = 0.41250865, grad/param norm = 3.2497e-01, time/batch = 17.0558s	
18626/22300 (epoch 41.762), train_loss = 0.35057104, grad/param norm = 2.3981e-01, time/batch = 16.4639s	
18627/22300 (epoch 41.765), train_loss = 0.39365387, grad/param norm = 2.9234e-01, time/batch = 15.2174s	
18628/22300 (epoch 41.767), train_loss = 0.36454143, grad/param norm = 3.0355e-01, time/batch = 15.6376s	
18629/22300 (epoch 41.769), train_loss = 0.36559863, grad/param norm = 3.3277e-01, time/batch = 17.3082s	
18630/22300 (epoch 41.771), train_loss = 0.41994790, grad/param norm = 3.4594e-01, time/batch = 15.6852s	
18631/22300 (epoch 41.774), train_loss = 0.45259601, grad/param norm = 2.8767e-01, time/batch = 17.9612s	
18632/22300 (epoch 41.776), train_loss = 0.46494297, grad/param norm = 2.6784e-01, time/batch = 16.5665s	
18633/22300 (epoch 41.778), train_loss = 0.46657406, grad/param norm = 3.4022e-01, time/batch = 16.6271s	
18634/22300 (epoch 41.780), train_loss = 0.44626543, grad/param norm = 3.0753e-01, time/batch = 16.6363s	
18635/22300 (epoch 41.783), train_loss = 0.49481874, grad/param norm = 3.2158e-01, time/batch = 16.2053s	
18636/22300 (epoch 41.785), train_loss = 0.34021834, grad/param norm = 3.0147e-01, time/batch = 17.2279s	
18637/22300 (epoch 41.787), train_loss = 0.33094586, grad/param norm = 2.5242e-01, time/batch = 16.7969s	
18638/22300 (epoch 41.789), train_loss = 0.51659024, grad/param norm = 3.3375e-01, time/batch = 16.3862s	
18639/22300 (epoch 41.791), train_loss = 0.56536667, grad/param norm = 2.8357e-01, time/batch = 15.8091s	
18640/22300 (epoch 41.794), train_loss = 0.48728025, grad/param norm = 3.1391e-01, time/batch = 16.8094s	
18641/22300 (epoch 41.796), train_loss = 0.41911568, grad/param norm = 2.6042e-01, time/batch = 16.7282s	
18642/22300 (epoch 41.798), train_loss = 0.57936849, grad/param norm = 2.8998e-01, time/batch = 18.3013s	
18643/22300 (epoch 41.800), train_loss = 0.39580342, grad/param norm = 2.7057e-01, time/batch = 16.1355s	
18644/22300 (epoch 41.803), train_loss = 0.33461561, grad/param norm = 2.5667e-01, time/batch = 17.7390s	
18645/22300 (epoch 41.805), train_loss = 0.38149023, grad/param norm = 2.7994e-01, time/batch = 29.1022s	
18646/22300 (epoch 41.807), train_loss = 0.52236106, grad/param norm = 4.0216e-01, time/batch = 16.6456s	
18647/22300 (epoch 41.809), train_loss = 0.38191435, grad/param norm = 3.0937e-01, time/batch = 15.8089s	
18648/22300 (epoch 41.812), train_loss = 0.40476048, grad/param norm = 2.7933e-01, time/batch = 16.2205s	
18649/22300 (epoch 41.814), train_loss = 0.38249476, grad/param norm = 3.1234e-01, time/batch = 17.2278s	
18650/22300 (epoch 41.816), train_loss = 0.42682306, grad/param norm = 2.9392e-01, time/batch = 17.9727s	
18651/22300 (epoch 41.818), train_loss = 0.48924613, grad/param norm = 3.8766e-01, time/batch = 15.3201s	
18652/22300 (epoch 41.821), train_loss = 0.41349470, grad/param norm = 2.5477e-01, time/batch = 17.4682s	
18653/22300 (epoch 41.823), train_loss = 0.26511895, grad/param norm = 2.2434e-01, time/batch = 16.2286s	
18654/22300 (epoch 41.825), train_loss = 0.30156971, grad/param norm = 2.6181e-01, time/batch = 17.4121s	
18655/22300 (epoch 41.827), train_loss = 0.34200088, grad/param norm = 2.8632e-01, time/batch = 16.2209s	
18656/22300 (epoch 41.830), train_loss = 0.33814948, grad/param norm = 2.0949e-01, time/batch = 15.4851s	
18657/22300 (epoch 41.832), train_loss = 0.31892208, grad/param norm = 2.2327e-01, time/batch = 17.3056s	
18658/22300 (epoch 41.834), train_loss = 0.26500653, grad/param norm = 2.2507e-01, time/batch = 15.7960s	
18659/22300 (epoch 41.836), train_loss = 0.33469434, grad/param norm = 2.4562e-01, time/batch = 17.1301s	
18660/22300 (epoch 41.839), train_loss = 0.37035093, grad/param norm = 2.8345e-01, time/batch = 16.7195s	
18661/22300 (epoch 41.841), train_loss = 0.30844332, grad/param norm = 2.7459e-01, time/batch = 17.9548s	
18662/22300 (epoch 41.843), train_loss = 0.35531990, grad/param norm = 2.7382e-01, time/batch = 17.1402s	
18663/22300 (epoch 41.845), train_loss = 0.34441022, grad/param norm = 2.8025e-01, time/batch = 16.3060s	
18664/22300 (epoch 41.848), train_loss = 0.33578988, grad/param norm = 2.6180e-01, time/batch = 18.1246s	
18665/22300 (epoch 41.850), train_loss = 0.36084819, grad/param norm = 2.5992e-01, time/batch = 16.1404s	
18666/22300 (epoch 41.852), train_loss = 0.32270528, grad/param norm = 3.1318e-01, time/batch = 16.5321s	
18667/22300 (epoch 41.854), train_loss = 0.54436301, grad/param norm = 3.1323e-01, time/batch = 14.7413s	
18668/22300 (epoch 41.857), train_loss = 0.38420472, grad/param norm = 2.7030e-01, time/batch = 14.9737s	
18669/22300 (epoch 41.859), train_loss = 0.31580611, grad/param norm = 1.8800e-01, time/batch = 16.0551s	
18670/22300 (epoch 41.861), train_loss = 0.42692866, grad/param norm = 2.9426e-01, time/batch = 16.3903s	
18671/22300 (epoch 41.863), train_loss = 0.26532035, grad/param norm = 1.9630e-01, time/batch = 17.3880s	
18672/22300 (epoch 41.865), train_loss = 0.28766697, grad/param norm = 2.1993e-01, time/batch = 16.6449s	
18673/22300 (epoch 41.868), train_loss = 0.36923585, grad/param norm = 2.2410e-01, time/batch = 15.8956s	
18674/22300 (epoch 41.870), train_loss = 0.37592545, grad/param norm = 2.8174e-01, time/batch = 17.2930s	
18675/22300 (epoch 41.872), train_loss = 0.46046158, grad/param norm = 2.6468e-01, time/batch = 15.4658s	
18676/22300 (epoch 41.874), train_loss = 0.39328557, grad/param norm = 2.7821e-01, time/batch = 15.2950s	
18677/22300 (epoch 41.877), train_loss = 0.36192596, grad/param norm = 2.4397e-01, time/batch = 17.8014s	
18678/22300 (epoch 41.879), train_loss = 0.32636128, grad/param norm = 2.0545e-01, time/batch = 16.2185s	
18679/22300 (epoch 41.881), train_loss = 0.26601576, grad/param norm = 1.8175e-01, time/batch = 17.2181s	
18680/22300 (epoch 41.883), train_loss = 0.28821489, grad/param norm = 2.5562e-01, time/batch = 15.5025s	
18681/22300 (epoch 41.886), train_loss = 0.26005795, grad/param norm = 2.2814e-01, time/batch = 16.7225s	
18682/22300 (epoch 41.888), train_loss = 0.31280444, grad/param norm = 2.1057e-01, time/batch = 15.4048s	
18683/22300 (epoch 41.890), train_loss = 0.32327157, grad/param norm = 2.1106e-01, time/batch = 16.5519s	
18684/22300 (epoch 41.892), train_loss = 0.47975506, grad/param norm = 3.0560e-01, time/batch = 17.2274s	
18685/22300 (epoch 41.895), train_loss = 0.42928747, grad/param norm = 2.6981e-01, time/batch = 16.8141s	
18686/22300 (epoch 41.897), train_loss = 0.33481317, grad/param norm = 2.7352e-01, time/batch = 17.3048s	
18687/22300 (epoch 41.899), train_loss = 0.32857509, grad/param norm = 2.0302e-01, time/batch = 15.2710s	
18688/22300 (epoch 41.901), train_loss = 0.42664603, grad/param norm = 3.1025e-01, time/batch = 19.2044s	
18689/22300 (epoch 41.904), train_loss = 0.39332774, grad/param norm = 3.2769e-01, time/batch = 16.1552s	
18690/22300 (epoch 41.906), train_loss = 0.38515466, grad/param norm = 2.6358e-01, time/batch = 17.6306s	
18691/22300 (epoch 41.908), train_loss = 0.34238061, grad/param norm = 2.4547e-01, time/batch = 16.4352s	
18692/22300 (epoch 41.910), train_loss = 0.30652520, grad/param norm = 2.1510e-01, time/batch = 15.4010s	
18693/22300 (epoch 41.913), train_loss = 0.40406090, grad/param norm = 3.5755e-01, time/batch = 16.3904s	
18694/22300 (epoch 41.915), train_loss = 0.50684731, grad/param norm = 3.0985e-01, time/batch = 14.9657s	
18695/22300 (epoch 41.917), train_loss = 0.40272086, grad/param norm = 2.6613e-01, time/batch = 15.7192s	
18696/22300 (epoch 41.919), train_loss = 0.37594106, grad/param norm = 2.2951e-01, time/batch = 16.9718s	
18697/22300 (epoch 41.922), train_loss = 0.36369678, grad/param norm = 2.8293e-01, time/batch = 18.2973s	
18698/22300 (epoch 41.924), train_loss = 0.23730063, grad/param norm = 1.9398e-01, time/batch = 16.8652s	
18699/22300 (epoch 41.926), train_loss = 0.30143271, grad/param norm = 1.8061e-01, time/batch = 16.2385s	
18700/22300 (epoch 41.928), train_loss = 0.31780637, grad/param norm = 2.3872e-01, time/batch = 15.7416s	
18701/22300 (epoch 41.930), train_loss = 0.29029691, grad/param norm = 2.0163e-01, time/batch = 16.5452s	
18702/22300 (epoch 41.933), train_loss = 0.37341617, grad/param norm = 2.5924e-01, time/batch = 16.7249s	
18703/22300 (epoch 41.935), train_loss = 0.36305060, grad/param norm = 2.8000e-01, time/batch = 16.7712s	
18704/22300 (epoch 41.937), train_loss = 0.45113037, grad/param norm = 3.2978e-01, time/batch = 17.2049s	
18705/22300 (epoch 41.939), train_loss = 0.40823234, grad/param norm = 3.2018e-01, time/batch = 15.8797s	
18706/22300 (epoch 41.942), train_loss = 0.52738026, grad/param norm = 3.6972e-01, time/batch = 17.9613s	
18707/22300 (epoch 41.944), train_loss = 0.52180775, grad/param norm = 3.8292e-01, time/batch = 18.6238s	
18708/22300 (epoch 41.946), train_loss = 0.40233088, grad/param norm = 2.7779e-01, time/batch = 17.2159s	
18709/22300 (epoch 41.948), train_loss = 0.33042866, grad/param norm = 1.7405e-01, time/batch = 16.6429s	
18710/22300 (epoch 41.951), train_loss = 0.25237677, grad/param norm = 1.8715e-01, time/batch = 16.0365s	
18711/22300 (epoch 41.953), train_loss = 0.29349776, grad/param norm = 2.4811e-01, time/batch = 17.0356s	
18712/22300 (epoch 41.955), train_loss = 0.45112981, grad/param norm = 2.7283e-01, time/batch = 15.9347s	
18713/22300 (epoch 41.957), train_loss = 0.53923610, grad/param norm = 2.6826e-01, time/batch = 18.1276s	
18714/22300 (epoch 41.960), train_loss = 0.46680669, grad/param norm = 2.5069e-01, time/batch = 15.5919s	
18715/22300 (epoch 41.962), train_loss = 0.27746177, grad/param norm = 2.0135e-01, time/batch = 16.9703s	
18716/22300 (epoch 41.964), train_loss = 0.29769441, grad/param norm = 2.2885e-01, time/batch = 15.1417s	
18717/22300 (epoch 41.966), train_loss = 0.32914343, grad/param norm = 2.2585e-01, time/batch = 17.7076s	
18718/22300 (epoch 41.969), train_loss = 0.34495015, grad/param norm = 2.4410e-01, time/batch = 15.9689s	
18719/22300 (epoch 41.971), train_loss = 0.38011871, grad/param norm = 2.8183e-01, time/batch = 15.1358s	
18720/22300 (epoch 41.973), train_loss = 0.34128515, grad/param norm = 3.8349e-01, time/batch = 18.4546s	
18721/22300 (epoch 41.975), train_loss = 0.49215544, grad/param norm = 3.1144e-01, time/batch = 15.9425s	
18722/22300 (epoch 41.978), train_loss = 0.46123875, grad/param norm = 3.0389e-01, time/batch = 14.6605s	
18723/22300 (epoch 41.980), train_loss = 0.55151331, grad/param norm = 3.3238e-01, time/batch = 15.6384s	
18724/22300 (epoch 41.982), train_loss = 0.27639783, grad/param norm = 2.3283e-01, time/batch = 16.4670s	
18725/22300 (epoch 41.984), train_loss = 0.36920409, grad/param norm = 2.6595e-01, time/batch = 19.1229s	
18726/22300 (epoch 41.987), train_loss = 0.35382795, grad/param norm = 2.5451e-01, time/batch = 16.6257s	
18727/22300 (epoch 41.989), train_loss = 0.28214782, grad/param norm = 2.5460e-01, time/batch = 15.3047s	
18728/22300 (epoch 41.991), train_loss = 0.52869327, grad/param norm = 3.6343e-01, time/batch = 16.1427s	
18729/22300 (epoch 41.993), train_loss = 0.70028938, grad/param norm = 3.4674e-01, time/batch = 17.5494s	
18730/22300 (epoch 41.996), train_loss = 0.65620608, grad/param norm = 3.7657e-01, time/batch = 15.8868s	
18731/22300 (epoch 41.998), train_loss = 0.41304615, grad/param norm = 2.7782e-01, time/batch = 18.7023s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
18732/22300 (epoch 42.000), train_loss = 0.31171184, grad/param norm = 2.6049e-01, time/batch = 17.8679s	
18733/22300 (epoch 42.002), train_loss = 0.64082586, grad/param norm = 3.0372e-01, time/batch = 15.6952s	
18734/22300 (epoch 42.004), train_loss = 0.41967207, grad/param norm = 2.5079e-01, time/batch = 17.4568s	
18735/22300 (epoch 42.007), train_loss = 0.44530875, grad/param norm = 2.9646e-01, time/batch = 16.5499s	
18736/22300 (epoch 42.009), train_loss = 0.43721164, grad/param norm = 3.1544e-01, time/batch = 17.8899s	
18737/22300 (epoch 42.011), train_loss = 0.55683451, grad/param norm = 3.8751e-01, time/batch = 14.8104s	
18738/22300 (epoch 42.013), train_loss = 0.42561750, grad/param norm = 2.6279e-01, time/batch = 18.2993s	
18739/22300 (epoch 42.016), train_loss = 0.34231237, grad/param norm = 2.5672e-01, time/batch = 17.1339s	
18740/22300 (epoch 42.018), train_loss = 0.38143905, grad/param norm = 2.9503e-01, time/batch = 15.4322s	
18741/22300 (epoch 42.020), train_loss = 0.36081379, grad/param norm = 2.5494e-01, time/batch = 15.5777s	
18742/22300 (epoch 42.022), train_loss = 0.26644808, grad/param norm = 2.6017e-01, time/batch = 15.5403s	
18743/22300 (epoch 42.025), train_loss = 0.32371600, grad/param norm = 2.4812e-01, time/batch = 15.2064s	
18744/22300 (epoch 42.027), train_loss = 0.30103973, grad/param norm = 2.0836e-01, time/batch = 15.1189s	
18745/22300 (epoch 42.029), train_loss = 0.32336742, grad/param norm = 1.9999e-01, time/batch = 15.1252s	
18746/22300 (epoch 42.031), train_loss = 0.31098563, grad/param norm = 2.0573e-01, time/batch = 16.2087s	
18747/22300 (epoch 42.034), train_loss = 0.29906345, grad/param norm = 2.0841e-01, time/batch = 16.9269s	
18748/22300 (epoch 42.036), train_loss = 0.30289970, grad/param norm = 2.1661e-01, time/batch = 15.2076s	
18749/22300 (epoch 42.038), train_loss = 0.27061308, grad/param norm = 2.3849e-01, time/batch = 17.9754s	
18750/22300 (epoch 42.040), train_loss = 0.33314910, grad/param norm = 3.1566e-01, time/batch = 16.2173s	
18751/22300 (epoch 42.043), train_loss = 0.50703954, grad/param norm = 2.9434e-01, time/batch = 18.1272s	
18752/22300 (epoch 42.045), train_loss = 0.43699530, grad/param norm = 2.1389e-01, time/batch = 15.2841s	
18753/22300 (epoch 42.047), train_loss = 0.49124780, grad/param norm = 3.3305e-01, time/batch = 16.9505s	
18754/22300 (epoch 42.049), train_loss = 0.37029822, grad/param norm = 2.5306e-01, time/batch = 15.9640s	
18755/22300 (epoch 42.052), train_loss = 0.42634392, grad/param norm = 3.1754e-01, time/batch = 16.9615s	
18756/22300 (epoch 42.054), train_loss = 0.41276907, grad/param norm = 2.4203e-01, time/batch = 15.9136s	
18757/22300 (epoch 42.056), train_loss = 0.21530736, grad/param norm = 1.8316e-01, time/batch = 17.2308s	
18758/22300 (epoch 42.058), train_loss = 0.33259440, grad/param norm = 2.4531e-01, time/batch = 17.6543s	
18759/22300 (epoch 42.061), train_loss = 0.31804000, grad/param norm = 2.4404e-01, time/batch = 16.2165s	
18760/22300 (epoch 42.063), train_loss = 0.47861656, grad/param norm = 3.5549e-01, time/batch = 17.7154s	
18761/22300 (epoch 42.065), train_loss = 0.54316479, grad/param norm = 4.5459e-01, time/batch = 16.2274s	
18762/22300 (epoch 42.067), train_loss = 0.32238481, grad/param norm = 2.9691e-01, time/batch = 17.1354s	
18763/22300 (epoch 42.070), train_loss = 0.35655423, grad/param norm = 2.7038e-01, time/batch = 15.7206s	
18764/22300 (epoch 42.072), train_loss = 0.38272287, grad/param norm = 2.7417e-01, time/batch = 17.4839s	
18765/22300 (epoch 42.074), train_loss = 0.40637068, grad/param norm = 2.8576e-01, time/batch = 16.4902s	
18766/22300 (epoch 42.076), train_loss = 0.39749572, grad/param norm = 3.0772e-01, time/batch = 16.1207s	
18767/22300 (epoch 42.078), train_loss = 0.51625684, grad/param norm = 3.7835e-01, time/batch = 17.7928s	
18768/22300 (epoch 42.081), train_loss = 0.48859232, grad/param norm = 3.0602e-01, time/batch = 17.7918s	
18769/22300 (epoch 42.083), train_loss = 0.54822850, grad/param norm = 3.2636e-01, time/batch = 17.3741s	
18770/22300 (epoch 42.085), train_loss = 0.53045540, grad/param norm = 3.5056e-01, time/batch = 17.7952s	
18771/22300 (epoch 42.087), train_loss = 0.43765264, grad/param norm = 3.2635e-01, time/batch = 17.7042s	
18772/22300 (epoch 42.090), train_loss = 0.41726162, grad/param norm = 3.0909e-01, time/batch = 15.5413s	
18773/22300 (epoch 42.092), train_loss = 0.31019572, grad/param norm = 2.1735e-01, time/batch = 15.6026s	
18774/22300 (epoch 42.094), train_loss = 0.29592699, grad/param norm = 2.3681e-01, time/batch = 17.5551s	
18775/22300 (epoch 42.096), train_loss = 0.51743198, grad/param norm = 3.1830e-01, time/batch = 16.9809s	
18776/22300 (epoch 42.099), train_loss = 0.33223706, grad/param norm = 1.9518e-01, time/batch = 16.0541s	
18777/22300 (epoch 42.101), train_loss = 0.45458396, grad/param norm = 2.7708e-01, time/batch = 16.8143s	
18778/22300 (epoch 42.103), train_loss = 0.38508142, grad/param norm = 2.8386e-01, time/batch = 15.5690s	
18779/22300 (epoch 42.105), train_loss = 0.27609218, grad/param norm = 2.9511e-01, time/batch = 19.1331s	
18780/22300 (epoch 42.108), train_loss = 0.43374619, grad/param norm = 2.8546e-01, time/batch = 16.2130s	
18781/22300 (epoch 42.110), train_loss = 0.49435734, grad/param norm = 2.7262e-01, time/batch = 16.2137s	
18782/22300 (epoch 42.112), train_loss = 0.40007392, grad/param norm = 2.7541e-01, time/batch = 15.8511s	
18783/22300 (epoch 42.114), train_loss = 0.45540949, grad/param norm = 3.1652e-01, time/batch = 17.3036s	
18784/22300 (epoch 42.117), train_loss = 0.51460478, grad/param norm = 3.0417e-01, time/batch = 16.4668s	
18785/22300 (epoch 42.119), train_loss = 0.46267418, grad/param norm = 3.3199e-01, time/batch = 16.4922s	
18786/22300 (epoch 42.121), train_loss = 0.53111918, grad/param norm = 3.3061e-01, time/batch = 16.8088s	
18787/22300 (epoch 42.123), train_loss = 0.54673540, grad/param norm = 2.6514e-01, time/batch = 16.4190s	
18788/22300 (epoch 42.126), train_loss = 0.41967811, grad/param norm = 2.8655e-01, time/batch = 14.6249s	
18789/22300 (epoch 42.128), train_loss = 0.39332069, grad/param norm = 2.7367e-01, time/batch = 16.3258s	
18790/22300 (epoch 42.130), train_loss = 0.36755302, grad/param norm = 2.8023e-01, time/batch = 16.3988s	
18791/22300 (epoch 42.132), train_loss = 0.25572949, grad/param norm = 1.9099e-01, time/batch = 16.0590s	
18792/22300 (epoch 42.135), train_loss = 0.27243724, grad/param norm = 2.2539e-01, time/batch = 16.6454s	
18793/22300 (epoch 42.137), train_loss = 0.23309244, grad/param norm = 1.9046e-01, time/batch = 17.2192s	
18794/22300 (epoch 42.139), train_loss = 0.31814054, grad/param norm = 2.5217e-01, time/batch = 17.2167s	
18795/22300 (epoch 42.141), train_loss = 0.43477455, grad/param norm = 2.3840e-01, time/batch = 15.1289s	
18796/22300 (epoch 42.143), train_loss = 0.35644942, grad/param norm = 2.7445e-01, time/batch = 17.9598s	
18797/22300 (epoch 42.146), train_loss = 0.45957710, grad/param norm = 3.3402e-01, time/batch = 17.2724s	
18798/22300 (epoch 42.148), train_loss = 0.32601726, grad/param norm = 2.3380e-01, time/batch = 16.4552s	
18799/22300 (epoch 42.150), train_loss = 0.33712965, grad/param norm = 2.5057e-01, time/batch = 15.9086s	
18800/22300 (epoch 42.152), train_loss = 0.28531280, grad/param norm = 3.3903e-01, time/batch = 15.4690s	
18801/22300 (epoch 42.155), train_loss = 0.30399272, grad/param norm = 2.1411e-01, time/batch = 17.7202s	
18802/22300 (epoch 42.157), train_loss = 0.41090718, grad/param norm = 2.8067e-01, time/batch = 15.7325s	
18803/22300 (epoch 42.159), train_loss = 0.41544338, grad/param norm = 3.5133e-01, time/batch = 17.3785s	
18804/22300 (epoch 42.161), train_loss = 0.43817394, grad/param norm = 3.6553e-01, time/batch = 16.9576s	
18805/22300 (epoch 42.164), train_loss = 0.31910726, grad/param norm = 2.5954e-01, time/batch = 16.6330s	
18806/22300 (epoch 42.166), train_loss = 0.27379433, grad/param norm = 2.1972e-01, time/batch = 15.8961s	
18807/22300 (epoch 42.168), train_loss = 0.26295153, grad/param norm = 2.0279e-01, time/batch = 15.3944s	
18808/22300 (epoch 42.170), train_loss = 0.38963191, grad/param norm = 2.5749e-01, time/batch = 16.3894s	
18809/22300 (epoch 42.173), train_loss = 0.41083318, grad/param norm = 2.9209e-01, time/batch = 15.9693s	
18810/22300 (epoch 42.175), train_loss = 0.38270333, grad/param norm = 2.7565e-01, time/batch = 15.8823s	
18811/22300 (epoch 42.177), train_loss = 0.25007821, grad/param norm = 2.0511e-01, time/batch = 17.3074s	
18812/22300 (epoch 42.179), train_loss = 0.36816300, grad/param norm = 2.5981e-01, time/batch = 18.6235s	
18813/22300 (epoch 42.182), train_loss = 0.52048894, grad/param norm = 3.3804e-01, time/batch = 15.7024s	
18814/22300 (epoch 42.184), train_loss = 0.53692657, grad/param norm = 3.5590e-01, time/batch = 17.4692s	
18815/22300 (epoch 42.186), train_loss = 0.39997609, grad/param norm = 3.3847e-01, time/batch = 15.7977s	
18816/22300 (epoch 42.188), train_loss = 0.58514495, grad/param norm = 3.5864e-01, time/batch = 16.5498s	
18817/22300 (epoch 42.191), train_loss = 0.45751170, grad/param norm = 3.1326e-01, time/batch = 15.4830s	
18818/22300 (epoch 42.193), train_loss = 0.41786422, grad/param norm = 2.8366e-01, time/batch = 15.8195s	
18819/22300 (epoch 42.195), train_loss = 0.37144218, grad/param norm = 2.6598e-01, time/batch = 17.5469s	
18820/22300 (epoch 42.197), train_loss = 0.33015815, grad/param norm = 2.4043e-01, time/batch = 15.4580s	
18821/22300 (epoch 42.200), train_loss = 0.29734243, grad/param norm = 2.3031e-01, time/batch = 18.0541s	
18822/22300 (epoch 42.202), train_loss = 0.29193364, grad/param norm = 1.8487e-01, time/batch = 17.6405s	
18823/22300 (epoch 42.204), train_loss = 0.38223678, grad/param norm = 2.2556e-01, time/batch = 15.6231s	
18824/22300 (epoch 42.206), train_loss = 0.31550171, grad/param norm = 2.2267e-01, time/batch = 15.8827s	
18825/22300 (epoch 42.209), train_loss = 0.32333296, grad/param norm = 2.3799e-01, time/batch = 17.8947s	
18826/22300 (epoch 42.211), train_loss = 0.29290163, grad/param norm = 2.8415e-01, time/batch = 15.9676s	
18827/22300 (epoch 42.213), train_loss = 0.38189775, grad/param norm = 2.2611e-01, time/batch = 16.3840s	
18828/22300 (epoch 42.215), train_loss = 0.47574192, grad/param norm = 3.0943e-01, time/batch = 15.7240s	
18829/22300 (epoch 42.217), train_loss = 0.51416266, grad/param norm = 2.9384e-01, time/batch = 14.7326s	
18830/22300 (epoch 42.220), train_loss = 0.35507214, grad/param norm = 2.1851e-01, time/batch = 17.9703s	
18831/22300 (epoch 42.222), train_loss = 0.32716293, grad/param norm = 2.3412e-01, time/batch = 15.9448s	
18832/22300 (epoch 42.224), train_loss = 0.33126920, grad/param norm = 2.7447e-01, time/batch = 15.7146s	
18833/22300 (epoch 42.226), train_loss = 0.36191914, grad/param norm = 2.5908e-01, time/batch = 17.3818s	
18834/22300 (epoch 42.229), train_loss = 0.29543481, grad/param norm = 2.3035e-01, time/batch = 16.5608s	
18835/22300 (epoch 42.231), train_loss = 0.46273696, grad/param norm = 3.1418e-01, time/batch = 17.6238s	
18836/22300 (epoch 42.233), train_loss = 0.39769002, grad/param norm = 3.2032e-01, time/batch = 16.3921s	
18837/22300 (epoch 42.235), train_loss = 0.30366105, grad/param norm = 2.5355e-01, time/batch = 16.3977s	
18838/22300 (epoch 42.238), train_loss = 0.29218264, grad/param norm = 2.1979e-01, time/batch = 15.3046s	
18839/22300 (epoch 42.240), train_loss = 0.30070617, grad/param norm = 1.9080e-01, time/batch = 17.3921s	
18840/22300 (epoch 42.242), train_loss = 0.26937329, grad/param norm = 2.5304e-01, time/batch = 15.8973s	
18841/22300 (epoch 42.244), train_loss = 0.20051405, grad/param norm = 1.8162e-01, time/batch = 16.2732s	
18842/22300 (epoch 42.247), train_loss = 0.27409582, grad/param norm = 1.8811e-01, time/batch = 4.5245s	
18843/22300 (epoch 42.249), train_loss = 0.19212330, grad/param norm = 1.6149e-01, time/batch = 0.6542s	
18844/22300 (epoch 42.251), train_loss = 0.25201549, grad/param norm = 1.6666e-01, time/batch = 0.6535s	
18845/22300 (epoch 42.253), train_loss = 0.16619426, grad/param norm = 1.8701e-01, time/batch = 0.6499s	
18846/22300 (epoch 42.256), train_loss = 0.25164219, grad/param norm = 1.9163e-01, time/batch = 0.6485s	
18847/22300 (epoch 42.258), train_loss = 0.38721427, grad/param norm = 2.8433e-01, time/batch = 0.6538s	
18848/22300 (epoch 42.260), train_loss = 0.37383326, grad/param norm = 2.3245e-01, time/batch = 0.6488s	
18849/22300 (epoch 42.262), train_loss = 0.28493813, grad/param norm = 1.7298e-01, time/batch = 0.6663s	
18850/22300 (epoch 42.265), train_loss = 0.26074944, grad/param norm = 2.0965e-01, time/batch = 0.9505s	
18851/22300 (epoch 42.267), train_loss = 0.29132717, grad/param norm = 2.4188e-01, time/batch = 0.9721s	
18852/22300 (epoch 42.269), train_loss = 0.35635479, grad/param norm = 2.8096e-01, time/batch = 0.9416s	
18853/22300 (epoch 42.271), train_loss = 0.39834636, grad/param norm = 2.3904e-01, time/batch = 0.9415s	
18854/22300 (epoch 42.274), train_loss = 0.25428403, grad/param norm = 2.2888e-01, time/batch = 0.9288s	
18855/22300 (epoch 42.276), train_loss = 0.23382831, grad/param norm = 1.6819e-01, time/batch = 1.6215s	
18856/22300 (epoch 42.278), train_loss = 0.27048231, grad/param norm = 1.9771e-01, time/batch = 1.7599s	
18857/22300 (epoch 42.280), train_loss = 0.27723524, grad/param norm = 1.9641e-01, time/batch = 1.7698s	
18858/22300 (epoch 42.283), train_loss = 0.23154073, grad/param norm = 1.8259e-01, time/batch = 15.6475s	
18859/22300 (epoch 42.285), train_loss = 0.23818340, grad/param norm = 2.0947e-01, time/batch = 16.3247s	
18860/22300 (epoch 42.287), train_loss = 0.33230246, grad/param norm = 1.8483e-01, time/batch = 15.3183s	
18861/22300 (epoch 42.289), train_loss = 0.32314445, grad/param norm = 2.1275e-01, time/batch = 18.8913s	
18862/22300 (epoch 42.291), train_loss = 0.31443593, grad/param norm = 2.1495e-01, time/batch = 16.1508s	
18863/22300 (epoch 42.294), train_loss = 0.26179401, grad/param norm = 1.9334e-01, time/batch = 16.7274s	
18864/22300 (epoch 42.296), train_loss = 0.31378021, grad/param norm = 3.2042e-01, time/batch = 15.7755s	
18865/22300 (epoch 42.298), train_loss = 0.41837682, grad/param norm = 2.9462e-01, time/batch = 17.7971s	
18866/22300 (epoch 42.300), train_loss = 0.43612694, grad/param norm = 2.5082e-01, time/batch = 16.2125s	
18867/22300 (epoch 42.303), train_loss = 0.34330290, grad/param norm = 2.3239e-01, time/batch = 15.8961s	
18868/22300 (epoch 42.305), train_loss = 0.34494192, grad/param norm = 3.4193e-01, time/batch = 14.9789s	
18869/22300 (epoch 42.307), train_loss = 0.29489562, grad/param norm = 2.2653e-01, time/batch = 16.5508s	
18870/22300 (epoch 42.309), train_loss = 0.26132405, grad/param norm = 2.1736e-01, time/batch = 15.6521s	
18871/22300 (epoch 42.312), train_loss = 0.22680658, grad/param norm = 1.8396e-01, time/batch = 14.8192s	
18872/22300 (epoch 42.314), train_loss = 0.28328463, grad/param norm = 2.2473e-01, time/batch = 15.9710s	
18873/22300 (epoch 42.316), train_loss = 0.27155795, grad/param norm = 2.5282e-01, time/batch = 17.8033s	
18874/22300 (epoch 42.318), train_loss = 0.30210205, grad/param norm = 2.0045e-01, time/batch = 17.3873s	
18875/22300 (epoch 42.321), train_loss = 0.37580902, grad/param norm = 2.4363e-01, time/batch = 30.6122s	
18876/22300 (epoch 42.323), train_loss = 0.26632053, grad/param norm = 1.9692e-01, time/batch = 16.3904s	
18877/22300 (epoch 42.325), train_loss = 0.22681385, grad/param norm = 1.9115e-01, time/batch = 17.4676s	
18878/22300 (epoch 42.327), train_loss = 0.26048587, grad/param norm = 2.0620e-01, time/batch = 15.8923s	
18879/22300 (epoch 42.330), train_loss = 0.26666691, grad/param norm = 2.4978e-01, time/batch = 15.7105s	
18880/22300 (epoch 42.332), train_loss = 0.25477299, grad/param norm = 2.3009e-01, time/batch = 17.5558s	
18881/22300 (epoch 42.334), train_loss = 0.27982566, grad/param norm = 1.8437e-01, time/batch = 16.7239s	
18882/22300 (epoch 42.336), train_loss = 0.29576576, grad/param norm = 2.4292e-01, time/batch = 16.3858s	
18883/22300 (epoch 42.339), train_loss = 0.34535655, grad/param norm = 2.4117e-01, time/batch = 15.6571s	
18884/22300 (epoch 42.341), train_loss = 0.34171197, grad/param norm = 1.9379e-01, time/batch = 17.4619s	
18885/22300 (epoch 42.343), train_loss = 0.37225205, grad/param norm = 2.2610e-01, time/batch = 15.7443s	
18886/22300 (epoch 42.345), train_loss = 0.31914061, grad/param norm = 2.3601e-01, time/batch = 16.4496s	
18887/22300 (epoch 42.348), train_loss = 0.31987195, grad/param norm = 1.9366e-01, time/batch = 15.5556s	
18888/22300 (epoch 42.350), train_loss = 0.22332205, grad/param norm = 1.7861e-01, time/batch = 16.5500s	
18889/22300 (epoch 42.352), train_loss = 0.33239212, grad/param norm = 2.3200e-01, time/batch = 15.9652s	
18890/22300 (epoch 42.354), train_loss = 0.47512224, grad/param norm = 3.3611e-01, time/batch = 17.3900s	
18891/22300 (epoch 42.357), train_loss = 0.41617496, grad/param norm = 2.1605e-01, time/batch = 17.6930s	
18892/22300 (epoch 42.359), train_loss = 0.26428546, grad/param norm = 2.3264e-01, time/batch = 15.5074s	
18893/22300 (epoch 42.361), train_loss = 0.29554953, grad/param norm = 2.7458e-01, time/batch = 17.2270s	
18894/22300 (epoch 42.363), train_loss = 0.40301232, grad/param norm = 3.0209e-01, time/batch = 15.7331s	
18895/22300 (epoch 42.365), train_loss = 0.26489635, grad/param norm = 2.1649e-01, time/batch = 17.0349s	
18896/22300 (epoch 42.368), train_loss = 0.27484882, grad/param norm = 2.4334e-01, time/batch = 14.9781s	
18897/22300 (epoch 42.370), train_loss = 0.28771423, grad/param norm = 1.9295e-01, time/batch = 17.6342s	
18898/22300 (epoch 42.372), train_loss = 0.20475917, grad/param norm = 1.8723e-01, time/batch = 15.6359s	
18899/22300 (epoch 42.374), train_loss = 0.23324859, grad/param norm = 1.8684e-01, time/batch = 16.4690s	
18900/22300 (epoch 42.377), train_loss = 0.31118723, grad/param norm = 2.5205e-01, time/batch = 16.5453s	
18901/22300 (epoch 42.379), train_loss = 0.26699648, grad/param norm = 2.2145e-01, time/batch = 16.7419s	
18902/22300 (epoch 42.381), train_loss = 0.37029565, grad/param norm = 2.7401e-01, time/batch = 16.4840s	
18903/22300 (epoch 42.383), train_loss = 0.27176820, grad/param norm = 1.9886e-01, time/batch = 15.2221s	
18904/22300 (epoch 42.386), train_loss = 0.33275786, grad/param norm = 2.1253e-01, time/batch = 16.9806s	
18905/22300 (epoch 42.388), train_loss = 0.23017504, grad/param norm = 1.9948e-01, time/batch = 15.8861s	
18906/22300 (epoch 42.390), train_loss = 0.25587457, grad/param norm = 2.4526e-01, time/batch = 15.7946s	
18907/22300 (epoch 42.392), train_loss = 0.29454954, grad/param norm = 2.1517e-01, time/batch = 15.7408s	
18908/22300 (epoch 42.395), train_loss = 0.25229532, grad/param norm = 1.8512e-01, time/batch = 16.2981s	
18909/22300 (epoch 42.397), train_loss = 0.17498277, grad/param norm = 1.3769e-01, time/batch = 18.2904s	
18910/22300 (epoch 42.399), train_loss = 0.26257883, grad/param norm = 2.8693e-01, time/batch = 15.6857s	
18911/22300 (epoch 42.401), train_loss = 0.27777937, grad/param norm = 2.6531e-01, time/batch = 15.4987s	
18912/22300 (epoch 42.404), train_loss = 0.30589558, grad/param norm = 2.4334e-01, time/batch = 15.4139s	
18913/22300 (epoch 42.406), train_loss = 0.45421449, grad/param norm = 2.6557e-01, time/batch = 14.8864s	
18914/22300 (epoch 42.408), train_loss = 0.34991135, grad/param norm = 2.5353e-01, time/batch = 15.5448s	
18915/22300 (epoch 42.410), train_loss = 0.38424305, grad/param norm = 3.4406e-01, time/batch = 17.1322s	
18916/22300 (epoch 42.413), train_loss = 0.30120375, grad/param norm = 2.8126e-01, time/batch = 14.5765s	
18917/22300 (epoch 42.415), train_loss = 0.21807877, grad/param norm = 2.0622e-01, time/batch = 18.2157s	
18918/22300 (epoch 42.417), train_loss = 0.31898727, grad/param norm = 2.0264e-01, time/batch = 15.8920s	
18919/22300 (epoch 42.419), train_loss = 0.30344058, grad/param norm = 1.9257e-01, time/batch = 16.6943s	
18920/22300 (epoch 42.422), train_loss = 0.25702814, grad/param norm = 2.3820e-01, time/batch = 17.6501s	
18921/22300 (epoch 42.424), train_loss = 0.30917836, grad/param norm = 2.2746e-01, time/batch = 17.3013s	
18922/22300 (epoch 42.426), train_loss = 0.23278475, grad/param norm = 2.2638e-01, time/batch = 15.8994s	
18923/22300 (epoch 42.428), train_loss = 0.24053316, grad/param norm = 2.0072e-01, time/batch = 16.1266s	
18924/22300 (epoch 42.430), train_loss = 0.27692087, grad/param norm = 2.4076e-01, time/batch = 16.0330s	
18925/22300 (epoch 42.433), train_loss = 0.29750093, grad/param norm = 1.9990e-01, time/batch = 14.6219s	
18926/22300 (epoch 42.435), train_loss = 0.26003532, grad/param norm = 2.4559e-01, time/batch = 14.9992s	
18927/22300 (epoch 42.437), train_loss = 0.33388952, grad/param norm = 2.6333e-01, time/batch = 16.4826s	
18928/22300 (epoch 42.439), train_loss = 0.37030474, grad/param norm = 2.5827e-01, time/batch = 17.8064s	
18929/22300 (epoch 42.442), train_loss = 0.31194205, grad/param norm = 2.3202e-01, time/batch = 15.5466s	
18930/22300 (epoch 42.444), train_loss = 0.26004742, grad/param norm = 2.2231e-01, time/batch = 17.4000s	
18931/22300 (epoch 42.446), train_loss = 0.27780557, grad/param norm = 1.7423e-01, time/batch = 16.5611s	
18932/22300 (epoch 42.448), train_loss = 0.21555215, grad/param norm = 1.4255e-01, time/batch = 16.3047s	
18933/22300 (epoch 42.451), train_loss = 0.34265072, grad/param norm = 2.1830e-01, time/batch = 15.9852s	
18934/22300 (epoch 42.453), train_loss = 0.26855848, grad/param norm = 1.9632e-01, time/batch = 16.9084s	
18935/22300 (epoch 42.455), train_loss = 0.36475953, grad/param norm = 2.6833e-01, time/batch = 19.6277s	
18936/22300 (epoch 42.457), train_loss = 0.51848986, grad/param norm = 3.8731e-01, time/batch = 16.2864s	
18937/22300 (epoch 42.460), train_loss = 0.42587486, grad/param norm = 2.9300e-01, time/batch = 18.5266s	
18938/22300 (epoch 42.462), train_loss = 0.40656255, grad/param norm = 2.3347e-01, time/batch = 15.7768s	
18939/22300 (epoch 42.464), train_loss = 0.36502505, grad/param norm = 2.5146e-01, time/batch = 15.3373s	
18940/22300 (epoch 42.466), train_loss = 0.29472007, grad/param norm = 1.9966e-01, time/batch = 16.5653s	
18941/22300 (epoch 42.469), train_loss = 0.27401952, grad/param norm = 1.7115e-01, time/batch = 16.7951s	
18942/22300 (epoch 42.471), train_loss = 0.39740396, grad/param norm = 2.5066e-01, time/batch = 17.3826s	
18943/22300 (epoch 42.473), train_loss = 0.32991760, grad/param norm = 2.1981e-01, time/batch = 15.5428s	
18944/22300 (epoch 42.475), train_loss = 0.28036853, grad/param norm = 2.2550e-01, time/batch = 18.3045s	
18945/22300 (epoch 42.478), train_loss = 0.30088036, grad/param norm = 2.3578e-01, time/batch = 16.5594s	
18946/22300 (epoch 42.480), train_loss = 0.21289652, grad/param norm = 1.7015e-01, time/batch = 15.8045s	
18947/22300 (epoch 42.482), train_loss = 0.25088096, grad/param norm = 1.6442e-01, time/batch = 17.3819s	
18948/22300 (epoch 42.484), train_loss = 0.32652102, grad/param norm = 2.4533e-01, time/batch = 16.4065s	
18949/22300 (epoch 42.487), train_loss = 0.38674698, grad/param norm = 2.2393e-01, time/batch = 18.5476s	
18950/22300 (epoch 42.489), train_loss = 0.37996550, grad/param norm = 2.7320e-01, time/batch = 15.5988s	
18951/22300 (epoch 42.491), train_loss = 0.38833224, grad/param norm = 2.2551e-01, time/batch = 16.2082s	
18952/22300 (epoch 42.493), train_loss = 0.30695290, grad/param norm = 4.2030e-01, time/batch = 16.8791s	
18953/22300 (epoch 42.496), train_loss = 0.33278385, grad/param norm = 1.9016e-01, time/batch = 16.5379s	
18954/22300 (epoch 42.498), train_loss = 0.23075070, grad/param norm = 1.8354e-01, time/batch = 15.5385s	
18955/22300 (epoch 42.500), train_loss = 0.31521320, grad/param norm = 2.3154e-01, time/batch = 17.7875s	
18956/22300 (epoch 42.502), train_loss = 0.19025185, grad/param norm = 1.5123e-01, time/batch = 19.3087s	
18957/22300 (epoch 42.504), train_loss = 0.22407039, grad/param norm = 1.6698e-01, time/batch = 15.6373s	
18958/22300 (epoch 42.507), train_loss = 0.25713834, grad/param norm = 2.1201e-01, time/batch = 17.8718s	
18959/22300 (epoch 42.509), train_loss = 0.35267367, grad/param norm = 2.3431e-01, time/batch = 15.2964s	
18960/22300 (epoch 42.511), train_loss = 0.21145023, grad/param norm = 1.8306e-01, time/batch = 17.5534s	
18961/22300 (epoch 42.513), train_loss = 0.22164433, grad/param norm = 2.2546e-01, time/batch = 16.0672s	
18962/22300 (epoch 42.516), train_loss = 0.27676986, grad/param norm = 1.9917e-01, time/batch = 15.9735s	
18963/22300 (epoch 42.518), train_loss = 0.32914049, grad/param norm = 2.5390e-01, time/batch = 18.3006s	
18964/22300 (epoch 42.520), train_loss = 0.27562342, grad/param norm = 2.2479e-01, time/batch = 16.2072s	
18965/22300 (epoch 42.522), train_loss = 0.30893167, grad/param norm = 2.2345e-01, time/batch = 15.3720s	
18966/22300 (epoch 42.525), train_loss = 0.23272984, grad/param norm = 1.9000e-01, time/batch = 15.8312s	
18967/22300 (epoch 42.527), train_loss = 0.37682649, grad/param norm = 2.9244e-01, time/batch = 16.8203s	
18968/22300 (epoch 42.529), train_loss = 0.31506596, grad/param norm = 2.7361e-01, time/batch = 15.1984s	
18969/22300 (epoch 42.531), train_loss = 0.26363051, grad/param norm = 2.0948e-01, time/batch = 17.8877s	
18970/22300 (epoch 42.534), train_loss = 0.32090753, grad/param norm = 2.4552e-01, time/batch = 16.7265s	
18971/22300 (epoch 42.536), train_loss = 0.44197275, grad/param norm = 2.5834e-01, time/batch = 17.2108s	
18972/22300 (epoch 42.538), train_loss = 0.54326849, grad/param norm = 3.1383e-01, time/batch = 15.4727s	
18973/22300 (epoch 42.540), train_loss = 0.31507482, grad/param norm = 2.4596e-01, time/batch = 16.6983s	
18974/22300 (epoch 42.543), train_loss = 0.31065321, grad/param norm = 1.9910e-01, time/batch = 15.2479s	
18975/22300 (epoch 42.545), train_loss = 0.21807065, grad/param norm = 2.0261e-01, time/batch = 15.8836s	
18976/22300 (epoch 42.547), train_loss = 0.19195612, grad/param norm = 1.8116e-01, time/batch = 15.8057s	
18977/22300 (epoch 42.549), train_loss = 0.23191113, grad/param norm = 2.0256e-01, time/batch = 14.9731s	
18978/22300 (epoch 42.552), train_loss = 0.24175448, grad/param norm = 2.3195e-01, time/batch = 15.7985s	
18979/22300 (epoch 42.554), train_loss = 0.34424852, grad/param norm = 2.6036e-01, time/batch = 15.6117s	
18980/22300 (epoch 42.556), train_loss = 0.45495068, grad/param norm = 3.5159e-01, time/batch = 17.9715s	
18981/22300 (epoch 42.558), train_loss = 0.32450396, grad/param norm = 2.3521e-01, time/batch = 16.1447s	
18982/22300 (epoch 42.561), train_loss = 0.51683584, grad/param norm = 4.3029e-01, time/batch = 14.7403s	
18983/22300 (epoch 42.563), train_loss = 0.39750900, grad/param norm = 2.8575e-01, time/batch = 15.5426s	
18984/22300 (epoch 42.565), train_loss = 0.29696691, grad/param norm = 2.6259e-01, time/batch = 17.5458s	
18985/22300 (epoch 42.567), train_loss = 0.31357760, grad/param norm = 2.5746e-01, time/batch = 15.8797s	
18986/22300 (epoch 42.570), train_loss = 0.42627655, grad/param norm = 3.3346e-01, time/batch = 16.8759s	
18987/22300 (epoch 42.572), train_loss = 0.43284932, grad/param norm = 2.8961e-01, time/batch = 15.3834s	
18988/22300 (epoch 42.574), train_loss = 0.31898981, grad/param norm = 2.2948e-01, time/batch = 18.6225s	
18989/22300 (epoch 42.576), train_loss = 0.26930170, grad/param norm = 1.6690e-01, time/batch = 15.3686s	
18990/22300 (epoch 42.578), train_loss = 0.15582482, grad/param norm = 1.4106e-01, time/batch = 15.5991s	
18991/22300 (epoch 42.581), train_loss = 0.24019782, grad/param norm = 2.1009e-01, time/batch = 16.1839s	
18992/22300 (epoch 42.583), train_loss = 0.29877239, grad/param norm = 2.1543e-01, time/batch = 16.3796s	
18993/22300 (epoch 42.585), train_loss = 0.39828605, grad/param norm = 3.7415e-01, time/batch = 18.4564s	
18994/22300 (epoch 42.587), train_loss = 0.55319673, grad/param norm = 3.1242e-01, time/batch = 15.5509s	
18995/22300 (epoch 42.590), train_loss = 0.46660294, grad/param norm = 3.7206e-01, time/batch = 18.5300s	
18996/22300 (epoch 42.592), train_loss = 0.53042888, grad/param norm = 3.5095e-01, time/batch = 17.7721s	
18997/22300 (epoch 42.594), train_loss = 0.49673895, grad/param norm = 3.9877e-01, time/batch = 16.8778s	
18998/22300 (epoch 42.596), train_loss = 0.33973156, grad/param norm = 2.9901e-01, time/batch = 17.3000s	
18999/22300 (epoch 42.599), train_loss = 0.21260341, grad/param norm = 2.0344e-01, time/batch = 17.0575s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch42.60_1.7503.t7	
19000/22300 (epoch 42.601), train_loss = 0.26378679, grad/param norm = 1.9957e-01, time/batch = 16.6836s	
19001/22300 (epoch 42.603), train_loss = 1.34773724, grad/param norm = 4.7082e-01, time/batch = 15.4682s	
19002/22300 (epoch 42.605), train_loss = 0.34106722, grad/param norm = 2.9005e-01, time/batch = 16.9481s	
19003/22300 (epoch 42.608), train_loss = 0.53236221, grad/param norm = 4.0061e-01, time/batch = 16.3991s	
19004/22300 (epoch 42.610), train_loss = 0.56994141, grad/param norm = 3.0944e-01, time/batch = 15.7841s	
19005/22300 (epoch 42.612), train_loss = 0.39804053, grad/param norm = 2.8499e-01, time/batch = 15.9614s	
19006/22300 (epoch 42.614), train_loss = 0.39170562, grad/param norm = 3.1886e-01, time/batch = 15.7951s	
19007/22300 (epoch 42.617), train_loss = 0.41710079, grad/param norm = 2.4392e-01, time/batch = 14.9040s	
19008/22300 (epoch 42.619), train_loss = 0.42357511, grad/param norm = 2.8317e-01, time/batch = 15.6773s	
19009/22300 (epoch 42.621), train_loss = 0.29500122, grad/param norm = 2.6524e-01, time/batch = 16.5085s	
19010/22300 (epoch 42.623), train_loss = 0.29191945, grad/param norm = 2.0666e-01, time/batch = 16.1333s	
19011/22300 (epoch 42.626), train_loss = 0.29021060, grad/param norm = 2.3473e-01, time/batch = 15.8084s	
19012/22300 (epoch 42.628), train_loss = 0.28948378, grad/param norm = 1.7265e-01, time/batch = 16.6333s	
19013/22300 (epoch 42.630), train_loss = 0.33246424, grad/param norm = 2.2118e-01, time/batch = 16.0381s	
19014/22300 (epoch 42.632), train_loss = 0.28395471, grad/param norm = 2.3833e-01, time/batch = 15.5736s	
19015/22300 (epoch 42.635), train_loss = 0.32561040, grad/param norm = 2.1531e-01, time/batch = 15.7899s	
19016/22300 (epoch 42.637), train_loss = 0.36287704, grad/param norm = 2.2564e-01, time/batch = 16.5545s	
19017/22300 (epoch 42.639), train_loss = 0.44851820, grad/param norm = 2.7946e-01, time/batch = 15.0513s	
19018/22300 (epoch 42.641), train_loss = 0.35967819, grad/param norm = 2.3106e-01, time/batch = 17.3941s	
19019/22300 (epoch 42.643), train_loss = 0.28484693, grad/param norm = 2.7956e-01, time/batch = 17.8013s	
19020/22300 (epoch 42.646), train_loss = 0.28001740, grad/param norm = 1.9808e-01, time/batch = 16.5303s	
19021/22300 (epoch 42.648), train_loss = 0.37908509, grad/param norm = 1.8743e-01, time/batch = 15.6269s	
19022/22300 (epoch 42.650), train_loss = 0.37436749, grad/param norm = 3.1086e-01, time/batch = 15.3976s	
19023/22300 (epoch 42.652), train_loss = 0.31030750, grad/param norm = 2.2319e-01, time/batch = 14.2556s	
19024/22300 (epoch 42.655), train_loss = 0.25705863, grad/param norm = 2.1250e-01, time/batch = 15.5466s	
19025/22300 (epoch 42.657), train_loss = 0.30056612, grad/param norm = 2.3324e-01, time/batch = 14.8887s	
19026/22300 (epoch 42.659), train_loss = 0.30492139, grad/param norm = 2.5263e-01, time/batch = 15.3661s	
19027/22300 (epoch 42.661), train_loss = 0.23306772, grad/param norm = 2.3584e-01, time/batch = 15.6423s	
19028/22300 (epoch 42.664), train_loss = 0.29924844, grad/param norm = 2.1957e-01, time/batch = 15.0330s	
19029/22300 (epoch 42.666), train_loss = 0.37724829, grad/param norm = 3.0396e-01, time/batch = 15.2890s	
19030/22300 (epoch 42.668), train_loss = 0.29353476, grad/param norm = 2.7164e-01, time/batch = 14.9073s	
19031/22300 (epoch 42.670), train_loss = 0.33750325, grad/param norm = 2.2444e-01, time/batch = 15.1545s	
19032/22300 (epoch 42.673), train_loss = 0.42590841, grad/param norm = 3.0203e-01, time/batch = 15.6088s	
19033/22300 (epoch 42.675), train_loss = 0.44458184, grad/param norm = 3.2961e-01, time/batch = 15.7993s	
19034/22300 (epoch 42.677), train_loss = 0.50616692, grad/param norm = 2.9867e-01, time/batch = 15.4552s	
19035/22300 (epoch 42.679), train_loss = 0.37692074, grad/param norm = 4.0674e-01, time/batch = 15.2843s	
19036/22300 (epoch 42.682), train_loss = 0.32180796, grad/param norm = 2.6176e-01, time/batch = 15.1390s	
19037/22300 (epoch 42.684), train_loss = 0.32887034, grad/param norm = 2.2897e-01, time/batch = 16.4469s	
19038/22300 (epoch 42.686), train_loss = 0.28260910, grad/param norm = 1.9042e-01, time/batch = 16.5716s	
19039/22300 (epoch 42.688), train_loss = 0.28052270, grad/param norm = 2.0435e-01, time/batch = 17.2233s	
19040/22300 (epoch 42.691), train_loss = 0.24506144, grad/param norm = 2.0098e-01, time/batch = 15.8841s	
19041/22300 (epoch 42.693), train_loss = 0.24804979, grad/param norm = 1.9491e-01, time/batch = 17.7978s	
19042/22300 (epoch 42.695), train_loss = 0.27986772, grad/param norm = 2.0313e-01, time/batch = 15.0715s	
19043/22300 (epoch 42.697), train_loss = 0.29426382, grad/param norm = 2.1941e-01, time/batch = 16.5487s	
19044/22300 (epoch 42.700), train_loss = 0.26401539, grad/param norm = 1.9804e-01, time/batch = 15.9786s	
19045/22300 (epoch 42.702), train_loss = 0.21574732, grad/param norm = 2.2354e-01, time/batch = 16.6348s	
19046/22300 (epoch 42.704), train_loss = 0.26441349, grad/param norm = 1.9806e-01, time/batch = 17.6315s	
19047/22300 (epoch 42.706), train_loss = 0.26157487, grad/param norm = 1.8405e-01, time/batch = 15.2097s	
19048/22300 (epoch 42.709), train_loss = 0.20790641, grad/param norm = 1.6907e-01, time/batch = 17.6395s	
19049/22300 (epoch 42.711), train_loss = 0.21086792, grad/param norm = 1.7255e-01, time/batch = 15.8881s	
19050/22300 (epoch 42.713), train_loss = 0.31450941, grad/param norm = 2.2196e-01, time/batch = 17.4571s	
19051/22300 (epoch 42.715), train_loss = 0.32615034, grad/param norm = 2.1973e-01, time/batch = 15.5566s	
19052/22300 (epoch 42.717), train_loss = 0.43481902, grad/param norm = 2.3187e-01, time/batch = 17.1396s	
19053/22300 (epoch 42.720), train_loss = 0.26700995, grad/param norm = 1.9819e-01, time/batch = 14.9372s	
19054/22300 (epoch 42.722), train_loss = 0.30687343, grad/param norm = 2.3570e-01, time/batch = 15.0655s	
19055/22300 (epoch 42.724), train_loss = 0.35886198, grad/param norm = 3.3240e-01, time/batch = 15.4438s	
19056/22300 (epoch 42.726), train_loss = 0.26383872, grad/param norm = 2.1130e-01, time/batch = 15.2318s	
19057/22300 (epoch 42.729), train_loss = 0.33214229, grad/param norm = 2.2554e-01, time/batch = 15.7901s	
19058/22300 (epoch 42.731), train_loss = 0.40750049, grad/param norm = 3.5503e-01, time/batch = 16.0431s	
19059/22300 (epoch 42.733), train_loss = 0.42125087, grad/param norm = 3.4578e-01, time/batch = 15.4446s	
19060/22300 (epoch 42.735), train_loss = 0.43639013, grad/param norm = 2.8302e-01, time/batch = 17.1421s	
19061/22300 (epoch 42.738), train_loss = 0.30798802, grad/param norm = 3.0445e-01, time/batch = 14.9111s	
19062/22300 (epoch 42.740), train_loss = 0.28576654, grad/param norm = 2.0672e-01, time/batch = 15.2895s	
19063/22300 (epoch 42.742), train_loss = 0.26499768, grad/param norm = 2.0451e-01, time/batch = 15.5536s	
19064/22300 (epoch 42.744), train_loss = 0.46057998, grad/param norm = 2.9647e-01, time/batch = 15.3136s	
19065/22300 (epoch 42.747), train_loss = 0.37220906, grad/param norm = 2.3530e-01, time/batch = 15.3609s	
19066/22300 (epoch 42.749), train_loss = 0.49482034, grad/param norm = 3.1903e-01, time/batch = 15.0444s	
19067/22300 (epoch 42.751), train_loss = 0.41452572, grad/param norm = 3.4352e-01, time/batch = 16.0378s	
19068/22300 (epoch 42.753), train_loss = 0.44644063, grad/param norm = 3.3427e-01, time/batch = 15.6494s	
19069/22300 (epoch 42.756), train_loss = 0.41627231, grad/param norm = 2.3152e-01, time/batch = 15.4660s	
19070/22300 (epoch 42.758), train_loss = 0.35035509, grad/param norm = 2.0890e-01, time/batch = 15.5392s	
19071/22300 (epoch 42.760), train_loss = 0.37469402, grad/param norm = 2.4904e-01, time/batch = 16.2362s	
19072/22300 (epoch 42.762), train_loss = 0.34122807, grad/param norm = 2.5957e-01, time/batch = 15.5650s	
19073/22300 (epoch 42.765), train_loss = 0.37679176, grad/param norm = 2.5940e-01, time/batch = 15.7370s	
19074/22300 (epoch 42.767), train_loss = 0.34457726, grad/param norm = 2.7346e-01, time/batch = 15.5853s	
19075/22300 (epoch 42.769), train_loss = 0.33497447, grad/param norm = 2.9106e-01, time/batch = 15.5144s	
19076/22300 (epoch 42.771), train_loss = 0.40056856, grad/param norm = 3.2418e-01, time/batch = 15.4411s	
19077/22300 (epoch 42.774), train_loss = 0.43170307, grad/param norm = 3.2687e-01, time/batch = 15.2796s	
19078/22300 (epoch 42.776), train_loss = 0.45548529, grad/param norm = 2.8828e-01, time/batch = 15.3042s	
19079/22300 (epoch 42.778), train_loss = 0.44681927, grad/param norm = 3.0098e-01, time/batch = 16.1249s	
19080/22300 (epoch 42.780), train_loss = 0.43102708, grad/param norm = 3.3492e-01, time/batch = 15.6748s	
19081/22300 (epoch 42.783), train_loss = 0.49590939, grad/param norm = 3.1803e-01, time/batch = 15.4217s	
19082/22300 (epoch 42.785), train_loss = 0.33283481, grad/param norm = 3.5087e-01, time/batch = 15.5440s	
19083/22300 (epoch 42.787), train_loss = 0.31601515, grad/param norm = 2.3179e-01, time/batch = 14.8913s	
19084/22300 (epoch 42.789), train_loss = 0.49756865, grad/param norm = 3.2728e-01, time/batch = 16.3903s	
19085/22300 (epoch 42.791), train_loss = 0.58032708, grad/param norm = 3.3832e-01, time/batch = 15.2972s	
19086/22300 (epoch 42.794), train_loss = 0.49371770, grad/param norm = 3.7756e-01, time/batch = 14.8939s	
19087/22300 (epoch 42.796), train_loss = 0.39903422, grad/param norm = 2.8281e-01, time/batch = 16.0358s	
19088/22300 (epoch 42.798), train_loss = 0.54332504, grad/param norm = 2.8121e-01, time/batch = 16.0699s	
19089/22300 (epoch 42.800), train_loss = 0.37231261, grad/param norm = 2.4869e-01, time/batch = 29.7060s	
19090/22300 (epoch 42.803), train_loss = 0.31682303, grad/param norm = 2.0908e-01, time/batch = 14.9090s	
19091/22300 (epoch 42.805), train_loss = 0.36624488, grad/param norm = 2.7027e-01, time/batch = 15.7002s	
19092/22300 (epoch 42.807), train_loss = 0.50154320, grad/param norm = 3.5858e-01, time/batch = 15.5911s	
19093/22300 (epoch 42.809), train_loss = 0.36188392, grad/param norm = 2.5543e-01, time/batch = 15.7306s	
19094/22300 (epoch 42.812), train_loss = 0.40895603, grad/param norm = 3.0026e-01, time/batch = 15.8243s	
19095/22300 (epoch 42.814), train_loss = 0.37403192, grad/param norm = 2.8688e-01, time/batch = 16.1845s	
19096/22300 (epoch 42.816), train_loss = 0.40155035, grad/param norm = 2.5486e-01, time/batch = 16.1269s	
19097/22300 (epoch 42.818), train_loss = 0.45712039, grad/param norm = 2.9350e-01, time/batch = 17.7186s	
19098/22300 (epoch 42.821), train_loss = 0.37625160, grad/param norm = 2.2496e-01, time/batch = 15.3395s	
19099/22300 (epoch 42.823), train_loss = 0.26070247, grad/param norm = 2.3734e-01, time/batch = 15.1330s	
19100/22300 (epoch 42.825), train_loss = 0.27401283, grad/param norm = 2.1084e-01, time/batch = 17.0619s	
19101/22300 (epoch 42.827), train_loss = 0.30592867, grad/param norm = 2.5124e-01, time/batch = 16.5377s	
19102/22300 (epoch 42.830), train_loss = 0.32985394, grad/param norm = 2.4925e-01, time/batch = 18.7873s	
19103/22300 (epoch 42.832), train_loss = 0.30248680, grad/param norm = 1.8125e-01, time/batch = 16.4573s	
19104/22300 (epoch 42.834), train_loss = 0.24840650, grad/param norm = 1.8327e-01, time/batch = 18.3889s	
19105/22300 (epoch 42.836), train_loss = 0.32480127, grad/param norm = 2.8694e-01, time/batch = 16.7379s	
19106/22300 (epoch 42.839), train_loss = 0.36035254, grad/param norm = 3.1555e-01, time/batch = 17.2760s	
19107/22300 (epoch 42.841), train_loss = 0.31597777, grad/param norm = 2.9423e-01, time/batch = 17.2181s	
19108/22300 (epoch 42.843), train_loss = 0.32900352, grad/param norm = 2.3617e-01, time/batch = 15.3877s	
19109/22300 (epoch 42.845), train_loss = 0.33963307, grad/param norm = 2.3458e-01, time/batch = 15.7917s	
19110/22300 (epoch 42.848), train_loss = 0.30188556, grad/param norm = 2.4226e-01, time/batch = 15.4973s	
19111/22300 (epoch 42.850), train_loss = 0.33346492, grad/param norm = 1.9691e-01, time/batch = 15.3849s	
19112/22300 (epoch 42.852), train_loss = 0.32000298, grad/param norm = 4.1695e-01, time/batch = 15.8570s	
19113/22300 (epoch 42.854), train_loss = 0.54554846, grad/param norm = 4.2309e-01, time/batch = 15.7220s	
19114/22300 (epoch 42.857), train_loss = 0.40710581, grad/param norm = 3.3730e-01, time/batch = 15.5509s	
19115/22300 (epoch 42.859), train_loss = 0.30936187, grad/param norm = 2.0242e-01, time/batch = 17.2851s	
19116/22300 (epoch 42.861), train_loss = 0.42523410, grad/param norm = 3.1398e-01, time/batch = 15.2406s	
19117/22300 (epoch 42.863), train_loss = 0.26435921, grad/param norm = 2.2831e-01, time/batch = 16.5518s	
19118/22300 (epoch 42.865), train_loss = 0.27390565, grad/param norm = 2.3116e-01, time/batch = 16.1515s	
19119/22300 (epoch 42.868), train_loss = 0.36168746, grad/param norm = 1.9839e-01, time/batch = 15.8106s	
19120/22300 (epoch 42.870), train_loss = 0.36993357, grad/param norm = 2.7150e-01, time/batch = 18.1183s	
19121/22300 (epoch 42.872), train_loss = 0.44372743, grad/param norm = 2.5458e-01, time/batch = 15.3762s	
19122/22300 (epoch 42.874), train_loss = 0.37363410, grad/param norm = 2.6669e-01, time/batch = 16.0641s	
19123/22300 (epoch 42.877), train_loss = 0.37292586, grad/param norm = 2.9352e-01, time/batch = 18.2040s	
19124/22300 (epoch 42.879), train_loss = 0.34256873, grad/param norm = 2.1720e-01, time/batch = 16.9583s	
19125/22300 (epoch 42.881), train_loss = 0.26752821, grad/param norm = 2.7139e-01, time/batch = 17.1325s	
19126/22300 (epoch 42.883), train_loss = 0.27186954, grad/param norm = 2.4931e-01, time/batch = 17.0548s	
19127/22300 (epoch 42.886), train_loss = 0.25941996, grad/param norm = 2.5046e-01, time/batch = 15.7271s	
19128/22300 (epoch 42.888), train_loss = 0.30031925, grad/param norm = 1.8540e-01, time/batch = 16.2977s	
19129/22300 (epoch 42.890), train_loss = 0.31339521, grad/param norm = 2.3713e-01, time/batch = 15.5393s	
19130/22300 (epoch 42.892), train_loss = 0.48136475, grad/param norm = 2.8933e-01, time/batch = 16.7252s	
19131/22300 (epoch 42.895), train_loss = 0.41575041, grad/param norm = 3.0676e-01, time/batch = 15.2776s	
19132/22300 (epoch 42.897), train_loss = 0.31976454, grad/param norm = 2.2178e-01, time/batch = 15.4417s	
19133/22300 (epoch 42.899), train_loss = 0.33732804, grad/param norm = 2.3298e-01, time/batch = 14.9945s	
19134/22300 (epoch 42.901), train_loss = 0.41078591, grad/param norm = 2.8075e-01, time/batch = 15.1510s	
19135/22300 (epoch 42.904), train_loss = 0.37968066, grad/param norm = 2.5300e-01, time/batch = 15.5878s	
19136/22300 (epoch 42.906), train_loss = 0.38492037, grad/param norm = 2.9377e-01, time/batch = 15.3815s	
19137/22300 (epoch 42.908), train_loss = 0.33369383, grad/param norm = 2.2739e-01, time/batch = 15.4521s	
19138/22300 (epoch 42.910), train_loss = 0.31895999, grad/param norm = 2.4415e-01, time/batch = 15.8339s	
19139/22300 (epoch 42.913), train_loss = 0.37543395, grad/param norm = 3.2089e-01, time/batch = 15.3578s	
19140/22300 (epoch 42.915), train_loss = 0.49860868, grad/param norm = 2.9876e-01, time/batch = 15.1526s	
19141/22300 (epoch 42.917), train_loss = 0.41429129, grad/param norm = 3.5042e-01, time/batch = 15.6378s	
19142/22300 (epoch 42.919), train_loss = 0.37440965, grad/param norm = 2.6176e-01, time/batch = 16.9777s	
19143/22300 (epoch 42.922), train_loss = 0.36786236, grad/param norm = 3.2795e-01, time/batch = 15.9638s	
19144/22300 (epoch 42.924), train_loss = 0.23158473, grad/param norm = 2.3033e-01, time/batch = 17.2158s	
19145/22300 (epoch 42.926), train_loss = 0.30090475, grad/param norm = 1.9586e-01, time/batch = 15.3196s	
19146/22300 (epoch 42.928), train_loss = 0.30332606, grad/param norm = 2.1382e-01, time/batch = 14.9956s	
19147/22300 (epoch 42.930), train_loss = 0.29076140, grad/param norm = 2.2044e-01, time/batch = 15.5778s	
19148/22300 (epoch 42.933), train_loss = 0.37422873, grad/param norm = 2.5325e-01, time/batch = 16.9576s	
19149/22300 (epoch 42.935), train_loss = 0.34918827, grad/param norm = 2.9676e-01, time/batch = 15.8073s	
19150/22300 (epoch 42.937), train_loss = 0.44967641, grad/param norm = 2.8286e-01, time/batch = 15.0440s	
19151/22300 (epoch 42.939), train_loss = 0.39690515, grad/param norm = 2.8179e-01, time/batch = 15.3011s	
19152/22300 (epoch 42.942), train_loss = 0.47271113, grad/param norm = 2.8646e-01, time/batch = 16.8936s	
19153/22300 (epoch 42.944), train_loss = 0.52770264, grad/param norm = 4.5052e-01, time/batch = 15.4636s	
19154/22300 (epoch 42.946), train_loss = 0.38203895, grad/param norm = 2.7058e-01, time/batch = 17.4509s	
19155/22300 (epoch 42.948), train_loss = 0.32015491, grad/param norm = 1.6417e-01, time/batch = 14.9855s	
19156/22300 (epoch 42.951), train_loss = 0.26478292, grad/param norm = 2.1812e-01, time/batch = 16.7320s	
19157/22300 (epoch 42.953), train_loss = 0.26688396, grad/param norm = 2.2038e-01, time/batch = 16.0416s	
19158/22300 (epoch 42.955), train_loss = 0.43738490, grad/param norm = 2.8536e-01, time/batch = 14.7197s	
19159/22300 (epoch 42.957), train_loss = 0.52591133, grad/param norm = 2.7389e-01, time/batch = 15.0073s	
19160/22300 (epoch 42.960), train_loss = 0.46310414, grad/param norm = 3.1380e-01, time/batch = 16.2036s	
19161/22300 (epoch 42.962), train_loss = 0.28564580, grad/param norm = 2.6667e-01, time/batch = 17.0537s	
19162/22300 (epoch 42.964), train_loss = 0.30134365, grad/param norm = 2.8848e-01, time/batch = 15.3866s	
19163/22300 (epoch 42.966), train_loss = 0.30456237, grad/param norm = 2.1103e-01, time/batch = 17.1411s	
19164/22300 (epoch 42.969), train_loss = 0.32088960, grad/param norm = 2.0661e-01, time/batch = 15.6568s	
19165/22300 (epoch 42.971), train_loss = 0.35243755, grad/param norm = 2.1840e-01, time/batch = 15.7620s	
19166/22300 (epoch 42.973), train_loss = 0.32965382, grad/param norm = 2.7713e-01, time/batch = 15.1136s	
19167/22300 (epoch 42.975), train_loss = 0.46095969, grad/param norm = 3.4191e-01, time/batch = 16.2129s	
19168/22300 (epoch 42.978), train_loss = 0.45383841, grad/param norm = 2.8013e-01, time/batch = 16.0461s	
19169/22300 (epoch 42.980), train_loss = 0.51655752, grad/param norm = 2.8330e-01, time/batch = 16.7184s	
19170/22300 (epoch 42.982), train_loss = 0.25898693, grad/param norm = 2.0826e-01, time/batch = 15.7233s	
19171/22300 (epoch 42.984), train_loss = 0.34662528, grad/param norm = 2.4303e-01, time/batch = 15.2353s	
19172/22300 (epoch 42.987), train_loss = 0.35560536, grad/param norm = 2.7648e-01, time/batch = 15.9568s	
19173/22300 (epoch 42.989), train_loss = 0.27141863, grad/param norm = 2.5192e-01, time/batch = 15.2706s	
19174/22300 (epoch 42.991), train_loss = 0.53990356, grad/param norm = 3.8797e-01, time/batch = 15.5935s	
19175/22300 (epoch 42.993), train_loss = 0.70952213, grad/param norm = 4.3809e-01, time/batch = 15.0378s	
19176/22300 (epoch 42.996), train_loss = 0.67601583, grad/param norm = 3.7959e-01, time/batch = 15.4559s	
19177/22300 (epoch 42.998), train_loss = 0.39152284, grad/param norm = 2.4671e-01, time/batch = 15.7068s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
19178/22300 (epoch 43.000), train_loss = 0.31859430, grad/param norm = 2.5908e-01, time/batch = 15.3673s	
19179/22300 (epoch 43.002), train_loss = 0.65953891, grad/param norm = 3.4452e-01, time/batch = 15.3491s	
19180/22300 (epoch 43.004), train_loss = 0.41779898, grad/param norm = 2.6080e-01, time/batch = 15.4624s	
19181/22300 (epoch 43.007), train_loss = 0.43596437, grad/param norm = 3.1731e-01, time/batch = 15.6062s	
19182/22300 (epoch 43.009), train_loss = 0.43793120, grad/param norm = 3.2847e-01, time/batch = 16.2090s	
19183/22300 (epoch 43.011), train_loss = 0.54116750, grad/param norm = 3.9145e-01, time/batch = 15.7500s	
19184/22300 (epoch 43.013), train_loss = 0.43752495, grad/param norm = 2.8671e-01, time/batch = 15.2807s	
19185/22300 (epoch 43.016), train_loss = 0.32618120, grad/param norm = 2.4829e-01, time/batch = 15.3635s	
19186/22300 (epoch 43.018), train_loss = 0.35087077, grad/param norm = 2.3679e-01, time/batch = 14.9074s	
19187/22300 (epoch 43.020), train_loss = 0.34056693, grad/param norm = 2.4990e-01, time/batch = 14.7439s	
19188/22300 (epoch 43.022), train_loss = 0.27873043, grad/param norm = 3.0166e-01, time/batch = 15.9785s	
19189/22300 (epoch 43.025), train_loss = 0.31017772, grad/param norm = 2.5080e-01, time/batch = 15.7024s	
19190/22300 (epoch 43.027), train_loss = 0.30780062, grad/param norm = 1.9569e-01, time/batch = 15.4839s	
19191/22300 (epoch 43.029), train_loss = 0.32469846, grad/param norm = 2.2367e-01, time/batch = 15.0759s	
19192/22300 (epoch 43.031), train_loss = 0.31321331, grad/param norm = 2.1471e-01, time/batch = 15.8572s	
19193/22300 (epoch 43.034), train_loss = 0.31264802, grad/param norm = 2.4711e-01, time/batch = 15.6599s	
19194/22300 (epoch 43.036), train_loss = 0.28838605, grad/param norm = 1.8361e-01, time/batch = 15.6014s	
19195/22300 (epoch 43.038), train_loss = 0.26229806, grad/param norm = 2.3790e-01, time/batch = 15.6795s	
19196/22300 (epoch 43.040), train_loss = 0.31808386, grad/param norm = 2.4286e-01, time/batch = 15.5978s	
19197/22300 (epoch 43.043), train_loss = 0.49062123, grad/param norm = 2.7587e-01, time/batch = 15.3164s	
19198/22300 (epoch 43.045), train_loss = 0.44025092, grad/param norm = 2.8289e-01, time/batch = 15.3017s	
19199/22300 (epoch 43.047), train_loss = 0.46527103, grad/param norm = 2.8631e-01, time/batch = 14.9786s	
19200/22300 (epoch 43.049), train_loss = 0.35807184, grad/param norm = 2.4700e-01, time/batch = 15.5001s	
19201/22300 (epoch 43.052), train_loss = 0.40342636, grad/param norm = 2.7456e-01, time/batch = 15.7340s	
19202/22300 (epoch 43.054), train_loss = 0.41445899, grad/param norm = 2.5890e-01, time/batch = 15.0761s	
19203/22300 (epoch 43.056), train_loss = 0.20472204, grad/param norm = 1.6761e-01, time/batch = 14.7994s	
19204/22300 (epoch 43.058), train_loss = 0.33386145, grad/param norm = 2.6259e-01, time/batch = 14.8735s	
19205/22300 (epoch 43.061), train_loss = 0.29830424, grad/param norm = 3.6173e-01, time/batch = 15.2203s	
19206/22300 (epoch 43.063), train_loss = 0.46413541, grad/param norm = 3.5392e-01, time/batch = 15.5232s	
19207/22300 (epoch 43.065), train_loss = 0.53168113, grad/param norm = 3.7722e-01, time/batch = 17.2831s	
19208/22300 (epoch 43.067), train_loss = 0.30910507, grad/param norm = 2.2778e-01, time/batch = 15.4594s	
19209/22300 (epoch 43.070), train_loss = 0.35665466, grad/param norm = 2.5762e-01, time/batch = 15.9010s	
19210/22300 (epoch 43.072), train_loss = 0.38803681, grad/param norm = 2.8198e-01, time/batch = 15.1515s	
19211/22300 (epoch 43.074), train_loss = 0.39523552, grad/param norm = 3.1022e-01, time/batch = 18.3585s	
19212/22300 (epoch 43.076), train_loss = 0.38683135, grad/param norm = 3.1701e-01, time/batch = 15.1506s	
19213/22300 (epoch 43.078), train_loss = 0.49559485, grad/param norm = 3.5931e-01, time/batch = 16.8166s	
19214/22300 (epoch 43.081), train_loss = 0.47880523, grad/param norm = 3.2549e-01, time/batch = 15.5258s	
19215/22300 (epoch 43.083), train_loss = 0.54759629, grad/param norm = 3.1711e-01, time/batch = 15.5044s	
19216/22300 (epoch 43.085), train_loss = 0.49822287, grad/param norm = 3.1550e-01, time/batch = 15.8294s	
19217/22300 (epoch 43.087), train_loss = 0.41446450, grad/param norm = 3.0863e-01, time/batch = 15.8231s	
19218/22300 (epoch 43.090), train_loss = 0.39362568, grad/param norm = 3.1739e-01, time/batch = 15.1440s	
19219/22300 (epoch 43.092), train_loss = 0.28769503, grad/param norm = 2.2139e-01, time/batch = 15.2209s	
19220/22300 (epoch 43.094), train_loss = 0.29692505, grad/param norm = 2.9433e-01, time/batch = 15.4386s	
19221/22300 (epoch 43.096), train_loss = 0.53419990, grad/param norm = 3.9530e-01, time/batch = 15.3813s	
19222/22300 (epoch 43.099), train_loss = 0.34195648, grad/param norm = 2.4579e-01, time/batch = 15.4388s	
19223/22300 (epoch 43.101), train_loss = 0.44977495, grad/param norm = 2.7136e-01, time/batch = 14.9630s	
19224/22300 (epoch 43.103), train_loss = 0.35336681, grad/param norm = 2.2062e-01, time/batch = 16.2397s	
19225/22300 (epoch 43.105), train_loss = 0.26049710, grad/param norm = 2.2695e-01, time/batch = 15.2440s	
19226/22300 (epoch 43.108), train_loss = 0.40751643, grad/param norm = 2.6307e-01, time/batch = 16.4696s	
19227/22300 (epoch 43.110), train_loss = 0.46018616, grad/param norm = 2.6595e-01, time/batch = 14.8017s	
19228/22300 (epoch 43.112), train_loss = 0.40386280, grad/param norm = 2.9158e-01, time/batch = 15.4093s	
19229/22300 (epoch 43.114), train_loss = 0.45231261, grad/param norm = 3.5491e-01, time/batch = 15.2333s	
19230/22300 (epoch 43.117), train_loss = 0.50283424, grad/param norm = 2.9083e-01, time/batch = 15.9086s	
19231/22300 (epoch 43.119), train_loss = 0.44733387, grad/param norm = 2.9173e-01, time/batch = 15.2271s	
19232/22300 (epoch 43.121), train_loss = 0.54410416, grad/param norm = 3.1763e-01, time/batch = 17.1477s	
19233/22300 (epoch 43.123), train_loss = 0.53573999, grad/param norm = 2.7007e-01, time/batch = 15.5043s	
19234/22300 (epoch 43.126), train_loss = 0.42150342, grad/param norm = 2.4680e-01, time/batch = 15.5025s	
19235/22300 (epoch 43.128), train_loss = 0.38721963, grad/param norm = 2.5949e-01, time/batch = 15.5910s	
19236/22300 (epoch 43.130), train_loss = 0.34162499, grad/param norm = 2.1903e-01, time/batch = 15.2986s	
19237/22300 (epoch 43.132), train_loss = 0.26131053, grad/param norm = 1.9124e-01, time/batch = 15.2207s	
19238/22300 (epoch 43.135), train_loss = 0.27753277, grad/param norm = 2.3891e-01, time/batch = 15.7821s	
19239/22300 (epoch 43.137), train_loss = 0.22200742, grad/param norm = 2.0750e-01, time/batch = 15.3252s	
19240/22300 (epoch 43.139), train_loss = 0.30996811, grad/param norm = 2.2835e-01, time/batch = 15.4961s	
19241/22300 (epoch 43.141), train_loss = 0.44541999, grad/param norm = 2.4462e-01, time/batch = 15.3485s	
19242/22300 (epoch 43.143), train_loss = 0.35290193, grad/param norm = 2.1697e-01, time/batch = 15.2682s	
19243/22300 (epoch 43.146), train_loss = 0.46798844, grad/param norm = 3.5140e-01, time/batch = 15.4711s	
19244/22300 (epoch 43.148), train_loss = 0.29857683, grad/param norm = 2.2232e-01, time/batch = 14.9979s	
19245/22300 (epoch 43.150), train_loss = 0.32023431, grad/param norm = 2.2623e-01, time/batch = 15.1450s	
19246/22300 (epoch 43.152), train_loss = 0.27053162, grad/param norm = 2.3649e-01, time/batch = 14.7373s	
19247/22300 (epoch 43.155), train_loss = 0.30055016, grad/param norm = 2.0056e-01, time/batch = 14.8226s	
19248/22300 (epoch 43.157), train_loss = 0.40049390, grad/param norm = 3.4324e-01, time/batch = 15.3100s	
19249/22300 (epoch 43.159), train_loss = 0.38446020, grad/param norm = 2.5230e-01, time/batch = 14.7962s	
19250/22300 (epoch 43.161), train_loss = 0.40154657, grad/param norm = 2.7655e-01, time/batch = 15.5511s	
19251/22300 (epoch 43.164), train_loss = 0.29645340, grad/param norm = 1.9018e-01, time/batch = 15.6422s	
19252/22300 (epoch 43.166), train_loss = 0.26361340, grad/param norm = 1.9018e-01, time/batch = 16.2219s	
19253/22300 (epoch 43.168), train_loss = 0.26982718, grad/param norm = 2.4076e-01, time/batch = 15.7133s	
19254/22300 (epoch 43.170), train_loss = 0.34895537, grad/param norm = 2.2697e-01, time/batch = 15.7649s	
19255/22300 (epoch 43.173), train_loss = 0.40905461, grad/param norm = 2.8207e-01, time/batch = 17.0166s	
19256/22300 (epoch 43.175), train_loss = 0.36180414, grad/param norm = 2.4326e-01, time/batch = 16.3894s	
19257/22300 (epoch 43.177), train_loss = 0.24379054, grad/param norm = 1.9735e-01, time/batch = 16.3436s	
19258/22300 (epoch 43.179), train_loss = 0.35959168, grad/param norm = 2.3699e-01, time/batch = 15.7073s	
19259/22300 (epoch 43.182), train_loss = 0.48696056, grad/param norm = 3.0278e-01, time/batch = 16.0597s	
19260/22300 (epoch 43.184), train_loss = 0.50444688, grad/param norm = 3.1312e-01, time/batch = 15.2286s	
19261/22300 (epoch 43.186), train_loss = 0.39661471, grad/param norm = 3.0332e-01, time/batch = 16.3750s	
19262/22300 (epoch 43.188), train_loss = 0.57155916, grad/param norm = 3.4107e-01, time/batch = 15.7285s	
19263/22300 (epoch 43.191), train_loss = 0.44568070, grad/param norm = 2.8932e-01, time/batch = 16.6477s	
19264/22300 (epoch 43.193), train_loss = 0.39417542, grad/param norm = 2.8350e-01, time/batch = 17.2384s	
19265/22300 (epoch 43.195), train_loss = 0.36068401, grad/param norm = 2.7437e-01, time/batch = 15.7549s	
19266/22300 (epoch 43.197), train_loss = 0.32850640, grad/param norm = 2.4123e-01, time/batch = 15.3039s	
19267/22300 (epoch 43.200), train_loss = 0.28356219, grad/param norm = 2.2662e-01, time/batch = 15.2358s	
19268/22300 (epoch 43.202), train_loss = 0.29112765, grad/param norm = 2.2957e-01, time/batch = 15.0697s	
19269/22300 (epoch 43.204), train_loss = 0.36934797, grad/param norm = 2.3894e-01, time/batch = 15.3432s	
19270/22300 (epoch 43.206), train_loss = 0.30014268, grad/param norm = 2.3835e-01, time/batch = 15.5400s	
19271/22300 (epoch 43.209), train_loss = 0.33103440, grad/param norm = 2.4816e-01, time/batch = 15.5436s	
19272/22300 (epoch 43.211), train_loss = 0.24646628, grad/param norm = 2.2370e-01, time/batch = 15.6808s	
19273/22300 (epoch 43.213), train_loss = 0.38112780, grad/param norm = 2.1925e-01, time/batch = 15.3706s	
19274/22300 (epoch 43.215), train_loss = 0.48535525, grad/param norm = 3.9723e-01, time/batch = 15.4547s	
19275/22300 (epoch 43.217), train_loss = 0.50521474, grad/param norm = 3.0220e-01, time/batch = 15.4788s	
19276/22300 (epoch 43.220), train_loss = 0.34451142, grad/param norm = 2.2696e-01, time/batch = 15.3174s	
19277/22300 (epoch 43.222), train_loss = 0.32454264, grad/param norm = 2.5332e-01, time/batch = 15.3747s	
19278/22300 (epoch 43.224), train_loss = 0.30846594, grad/param norm = 2.4344e-01, time/batch = 15.3698s	
19279/22300 (epoch 43.226), train_loss = 0.35756230, grad/param norm = 2.4130e-01, time/batch = 15.6804s	
19280/22300 (epoch 43.229), train_loss = 0.29027879, grad/param norm = 2.3469e-01, time/batch = 15.6194s	
19281/22300 (epoch 43.231), train_loss = 0.45327278, grad/param norm = 3.0483e-01, time/batch = 15.6253s	
19282/22300 (epoch 43.233), train_loss = 0.37741062, grad/param norm = 2.5672e-01, time/batch = 15.0693s	
19283/22300 (epoch 43.235), train_loss = 0.29138995, grad/param norm = 2.1245e-01, time/batch = 15.2348s	
19284/22300 (epoch 43.238), train_loss = 0.28745377, grad/param norm = 2.0437e-01, time/batch = 15.6925s	
19285/22300 (epoch 43.240), train_loss = 0.30098871, grad/param norm = 1.9676e-01, time/batch = 15.4509s	
19286/22300 (epoch 43.242), train_loss = 0.26499971, grad/param norm = 3.1163e-01, time/batch = 15.1118s	
19287/22300 (epoch 43.244), train_loss = 0.19536550, grad/param norm = 2.0620e-01, time/batch = 15.5321s	
19288/22300 (epoch 43.247), train_loss = 0.26762019, grad/param norm = 1.9679e-01, time/batch = 15.7046s	
19289/22300 (epoch 43.249), train_loss = 0.18295603, grad/param norm = 1.5774e-01, time/batch = 15.5752s	
19290/22300 (epoch 43.251), train_loss = 0.24085236, grad/param norm = 1.5660e-01, time/batch = 15.9638s	
19291/22300 (epoch 43.253), train_loss = 0.15772152, grad/param norm = 1.7153e-01, time/batch = 16.3822s	
19292/22300 (epoch 43.256), train_loss = 0.24342555, grad/param norm = 1.8192e-01, time/batch = 16.0386s	
19293/22300 (epoch 43.258), train_loss = 0.35799249, grad/param norm = 2.6349e-01, time/batch = 16.8126s	
19294/22300 (epoch 43.260), train_loss = 0.37681829, grad/param norm = 2.3152e-01, time/batch = 14.7284s	
19295/22300 (epoch 43.262), train_loss = 0.28656268, grad/param norm = 1.9931e-01, time/batch = 14.8274s	
19296/22300 (epoch 43.265), train_loss = 0.24830613, grad/param norm = 2.0083e-01, time/batch = 14.9711s	
19297/22300 (epoch 43.267), train_loss = 0.27732520, grad/param norm = 2.4231e-01, time/batch = 15.5009s	
19298/22300 (epoch 43.269), train_loss = 0.34286273, grad/param norm = 2.7737e-01, time/batch = 15.3479s	
19299/22300 (epoch 43.271), train_loss = 0.39142770, grad/param norm = 2.7860e-01, time/batch = 14.6401s	
19300/22300 (epoch 43.274), train_loss = 0.25847489, grad/param norm = 2.6388e-01, time/batch = 15.6786s	
19301/22300 (epoch 43.276), train_loss = 0.22539124, grad/param norm = 1.5724e-01, time/batch = 16.2362s	
19302/22300 (epoch 43.278), train_loss = 0.25748882, grad/param norm = 2.0848e-01, time/batch = 16.0692s	
19303/22300 (epoch 43.280), train_loss = 0.29215660, grad/param norm = 2.8567e-01, time/batch = 16.2941s	
19304/22300 (epoch 43.283), train_loss = 0.23058497, grad/param norm = 1.6148e-01, time/batch = 15.3939s	
19305/22300 (epoch 43.285), train_loss = 0.24004441, grad/param norm = 2.0981e-01, time/batch = 15.2325s	
19306/22300 (epoch 43.287), train_loss = 0.33147641, grad/param norm = 2.1347e-01, time/batch = 15.5692s	
19307/22300 (epoch 43.289), train_loss = 0.30868050, grad/param norm = 2.0047e-01, time/batch = 16.2160s	
19308/22300 (epoch 43.291), train_loss = 0.32065397, grad/param norm = 2.7962e-01, time/batch = 15.3813s	
19309/22300 (epoch 43.294), train_loss = 0.24854724, grad/param norm = 1.7958e-01, time/batch = 15.8050s	
19310/22300 (epoch 43.296), train_loss = 0.29071360, grad/param norm = 2.3618e-01, time/batch = 15.7955s	
19311/22300 (epoch 43.298), train_loss = 0.39347121, grad/param norm = 2.4237e-01, time/batch = 16.1241s	
19312/22300 (epoch 43.300), train_loss = 0.44818822, grad/param norm = 2.6781e-01, time/batch = 15.3664s	
19313/22300 (epoch 43.303), train_loss = 0.33404908, grad/param norm = 2.5301e-01, time/batch = 15.9809s	
19314/22300 (epoch 43.305), train_loss = 0.33773328, grad/param norm = 2.5583e-01, time/batch = 15.7993s	
19315/22300 (epoch 43.307), train_loss = 0.28904496, grad/param norm = 2.2722e-01, time/batch = 29.6786s	
19316/22300 (epoch 43.309), train_loss = 0.24692516, grad/param norm = 1.8846e-01, time/batch = 15.0472s	
19317/22300 (epoch 43.312), train_loss = 0.22221064, grad/param norm = 1.9622e-01, time/batch = 15.7197s	
19318/22300 (epoch 43.314), train_loss = 0.26673633, grad/param norm = 2.0350e-01, time/batch = 15.7625s	
19319/22300 (epoch 43.316), train_loss = 0.25294948, grad/param norm = 2.1006e-01, time/batch = 15.3604s	
19320/22300 (epoch 43.318), train_loss = 0.27995634, grad/param norm = 2.0116e-01, time/batch = 15.5904s	
19321/22300 (epoch 43.321), train_loss = 0.37998722, grad/param norm = 2.1706e-01, time/batch = 15.5550s	
19322/22300 (epoch 43.323), train_loss = 0.26009903, grad/param norm = 2.0142e-01, time/batch = 15.6654s	
19323/22300 (epoch 43.325), train_loss = 0.23966052, grad/param norm = 2.1114e-01, time/batch = 15.2050s	
19324/22300 (epoch 43.327), train_loss = 0.24800732, grad/param norm = 1.6556e-01, time/batch = 15.1261s	
19325/22300 (epoch 43.330), train_loss = 0.26268863, grad/param norm = 2.8436e-01, time/batch = 14.8963s	
19326/22300 (epoch 43.332), train_loss = 0.24886339, grad/param norm = 2.1659e-01, time/batch = 15.0379s	
19327/22300 (epoch 43.334), train_loss = 0.27416540, grad/param norm = 1.9545e-01, time/batch = 14.9053s	
19328/22300 (epoch 43.336), train_loss = 0.26669281, grad/param norm = 1.7425e-01, time/batch = 15.2925s	
19329/22300 (epoch 43.339), train_loss = 0.33473979, grad/param norm = 2.6060e-01, time/batch = 14.9714s	
19330/22300 (epoch 43.341), train_loss = 0.33055332, grad/param norm = 2.2965e-01, time/batch = 15.0570s	
19331/22300 (epoch 43.343), train_loss = 0.36812432, grad/param norm = 2.5512e-01, time/batch = 14.9653s	
19332/22300 (epoch 43.345), train_loss = 0.30291190, grad/param norm = 2.0845e-01, time/batch = 15.0543s	
19333/22300 (epoch 43.348), train_loss = 0.31068693, grad/param norm = 2.2070e-01, time/batch = 15.0462s	
19334/22300 (epoch 43.350), train_loss = 0.22922247, grad/param norm = 2.1761e-01, time/batch = 15.1271s	
19335/22300 (epoch 43.352), train_loss = 0.31432342, grad/param norm = 2.2546e-01, time/batch = 15.4429s	
19336/22300 (epoch 43.354), train_loss = 0.44260650, grad/param norm = 2.9879e-01, time/batch = 15.1403s	
19337/22300 (epoch 43.357), train_loss = 0.42055836, grad/param norm = 2.2802e-01, time/batch = 15.2917s	
19338/22300 (epoch 43.359), train_loss = 0.26972293, grad/param norm = 2.3836e-01, time/batch = 15.8158s	
19339/22300 (epoch 43.361), train_loss = 0.28961460, grad/param norm = 2.7826e-01, time/batch = 15.5138s	
19340/22300 (epoch 43.363), train_loss = 0.36760355, grad/param norm = 2.5038e-01, time/batch = 15.5283s	
19341/22300 (epoch 43.365), train_loss = 0.25561852, grad/param norm = 2.4139e-01, time/batch = 15.6406s	
19342/22300 (epoch 43.368), train_loss = 0.28852516, grad/param norm = 3.1888e-01, time/batch = 14.9918s	
19343/22300 (epoch 43.370), train_loss = 0.28727496, grad/param norm = 2.1762e-01, time/batch = 14.9924s	
19344/22300 (epoch 43.372), train_loss = 0.20613593, grad/param norm = 1.9035e-01, time/batch = 14.9863s	
19345/22300 (epoch 43.374), train_loss = 0.21090840, grad/param norm = 1.3061e-01, time/batch = 14.7440s	
19346/22300 (epoch 43.377), train_loss = 0.30869555, grad/param norm = 3.9406e-01, time/batch = 15.3080s	
19347/22300 (epoch 43.379), train_loss = 0.26282455, grad/param norm = 2.1312e-01, time/batch = 15.0746s	
19348/22300 (epoch 43.381), train_loss = 0.36519283, grad/param norm = 2.3931e-01, time/batch = 15.2391s	
19349/22300 (epoch 43.383), train_loss = 0.29107943, grad/param norm = 2.8437e-01, time/batch = 15.3130s	
19350/22300 (epoch 43.386), train_loss = 0.32287546, grad/param norm = 2.1757e-01, time/batch = 15.4048s	
19351/22300 (epoch 43.388), train_loss = 0.22441950, grad/param norm = 2.3735e-01, time/batch = 15.1544s	
19352/22300 (epoch 43.390), train_loss = 0.27218158, grad/param norm = 2.8838e-01, time/batch = 15.0790s	
19353/22300 (epoch 43.392), train_loss = 0.28688467, grad/param norm = 2.0234e-01, time/batch = 15.4179s	
19354/22300 (epoch 43.395), train_loss = 0.23803687, grad/param norm = 2.1412e-01, time/batch = 14.9811s	
19355/22300 (epoch 43.397), train_loss = 0.17136712, grad/param norm = 1.2894e-01, time/batch = 15.1421s	
19356/22300 (epoch 43.399), train_loss = 0.26080789, grad/param norm = 2.3185e-01, time/batch = 15.3810s	
19357/22300 (epoch 43.401), train_loss = 0.27090899, grad/param norm = 2.3141e-01, time/batch = 15.3703s	
19358/22300 (epoch 43.404), train_loss = 0.28988825, grad/param norm = 1.9482e-01, time/batch = 15.0630s	
19359/22300 (epoch 43.406), train_loss = 0.44174878, grad/param norm = 2.5872e-01, time/batch = 15.4339s	
19360/22300 (epoch 43.408), train_loss = 0.32839989, grad/param norm = 2.3701e-01, time/batch = 14.5576s	
19361/22300 (epoch 43.410), train_loss = 0.40267965, grad/param norm = 3.0709e-01, time/batch = 15.6537s	
19362/22300 (epoch 43.413), train_loss = 0.27290025, grad/param norm = 2.1566e-01, time/batch = 14.6591s	
19363/22300 (epoch 43.415), train_loss = 0.19941666, grad/param norm = 2.0089e-01, time/batch = 14.6645s	
19364/22300 (epoch 43.417), train_loss = 0.32526415, grad/param norm = 2.6848e-01, time/batch = 14.7482s	
19365/22300 (epoch 43.419), train_loss = 0.27913497, grad/param norm = 1.6022e-01, time/batch = 14.8863s	
19366/22300 (epoch 43.422), train_loss = 0.24329907, grad/param norm = 1.9253e-01, time/batch = 14.8216s	
19367/22300 (epoch 43.424), train_loss = 0.29498096, grad/param norm = 2.1385e-01, time/batch = 15.0505s	
19368/22300 (epoch 43.426), train_loss = 0.21311152, grad/param norm = 1.9830e-01, time/batch = 15.6569s	
19369/22300 (epoch 43.428), train_loss = 0.22600629, grad/param norm = 1.9088e-01, time/batch = 15.8221s	
19370/22300 (epoch 43.430), train_loss = 0.27187671, grad/param norm = 2.7734e-01, time/batch = 15.4399s	
19371/22300 (epoch 43.433), train_loss = 0.28896275, grad/param norm = 2.2011e-01, time/batch = 14.8143s	
19372/22300 (epoch 43.435), train_loss = 0.27158112, grad/param norm = 2.2928e-01, time/batch = 14.5723s	
19373/22300 (epoch 43.437), train_loss = 0.31360358, grad/param norm = 2.2506e-01, time/batch = 15.1139s	
19374/22300 (epoch 43.439), train_loss = 0.35985025, grad/param norm = 2.7218e-01, time/batch = 14.7770s	
19375/22300 (epoch 43.442), train_loss = 0.30830084, grad/param norm = 2.8207e-01, time/batch = 14.9017s	
19376/22300 (epoch 43.444), train_loss = 0.24887707, grad/param norm = 2.4958e-01, time/batch = 15.2822s	
19377/22300 (epoch 43.446), train_loss = 0.29273967, grad/param norm = 2.0781e-01, time/batch = 15.6579s	
19378/22300 (epoch 43.448), train_loss = 0.20954113, grad/param norm = 1.4820e-01, time/batch = 15.6952s	
19379/22300 (epoch 43.451), train_loss = 0.34432158, grad/param norm = 3.0444e-01, time/batch = 15.1914s	
19380/22300 (epoch 43.453), train_loss = 0.27362932, grad/param norm = 2.4521e-01, time/batch = 15.5672s	
19381/22300 (epoch 43.455), train_loss = 0.37356533, grad/param norm = 2.9628e-01, time/batch = 14.7215s	
19382/22300 (epoch 43.457), train_loss = 0.47215742, grad/param norm = 3.1599e-01, time/batch = 14.4015s	
19383/22300 (epoch 43.460), train_loss = 0.41872547, grad/param norm = 2.8417e-01, time/batch = 14.4966s	
19384/22300 (epoch 43.462), train_loss = 0.39437913, grad/param norm = 2.4988e-01, time/batch = 14.4145s	
19385/22300 (epoch 43.464), train_loss = 0.35824826, grad/param norm = 3.2072e-01, time/batch = 14.7161s	
19386/22300 (epoch 43.466), train_loss = 0.28333903, grad/param norm = 2.1988e-01, time/batch = 14.1698s	
19387/22300 (epoch 43.469), train_loss = 0.27275632, grad/param norm = 1.8675e-01, time/batch = 14.8002s	
19388/22300 (epoch 43.471), train_loss = 0.38622581, grad/param norm = 2.3729e-01, time/batch = 15.1918s	
19389/22300 (epoch 43.473), train_loss = 0.32290503, grad/param norm = 1.9524e-01, time/batch = 15.8997s	
19390/22300 (epoch 43.475), train_loss = 0.27199484, grad/param norm = 2.2796e-01, time/batch = 14.9825s	
19391/22300 (epoch 43.478), train_loss = 0.29196459, grad/param norm = 2.3818e-01, time/batch = 14.6778s	
19392/22300 (epoch 43.480), train_loss = 0.20804994, grad/param norm = 1.4946e-01, time/batch = 14.7420s	
19393/22300 (epoch 43.482), train_loss = 0.24720648, grad/param norm = 1.6803e-01, time/batch = 15.1251s	
19394/22300 (epoch 43.484), train_loss = 0.31263013, grad/param norm = 2.2121e-01, time/batch = 14.8200s	
19395/22300 (epoch 43.487), train_loss = 0.37129707, grad/param norm = 2.0134e-01, time/batch = 14.9047s	
19396/22300 (epoch 43.489), train_loss = 0.35041165, grad/param norm = 2.1301e-01, time/batch = 14.9080s	
19397/22300 (epoch 43.491), train_loss = 0.39721264, grad/param norm = 3.5003e-01, time/batch = 15.3053s	
19398/22300 (epoch 43.493), train_loss = 0.29206878, grad/param norm = 3.7643e-01, time/batch = 14.6557s	
19399/22300 (epoch 43.496), train_loss = 0.32534941, grad/param norm = 2.0358e-01, time/batch = 15.5732s	
19400/22300 (epoch 43.498), train_loss = 0.21669949, grad/param norm = 1.6360e-01, time/batch = 15.8006s	
19401/22300 (epoch 43.500), train_loss = 0.30876002, grad/param norm = 2.2938e-01, time/batch = 16.2730s	
19402/22300 (epoch 43.502), train_loss = 0.19486250, grad/param norm = 1.7951e-01, time/batch = 16.0570s	
19403/22300 (epoch 43.504), train_loss = 0.21292076, grad/param norm = 1.7653e-01, time/batch = 16.1223s	
19404/22300 (epoch 43.507), train_loss = 0.23729865, grad/param norm = 1.8277e-01, time/batch = 15.9524s	
19405/22300 (epoch 43.509), train_loss = 0.35639415, grad/param norm = 2.0639e-01, time/batch = 16.0277s	
19406/22300 (epoch 43.511), train_loss = 0.20304318, grad/param norm = 2.2045e-01, time/batch = 15.7981s	
19407/22300 (epoch 43.513), train_loss = 0.22430754, grad/param norm = 2.5331e-01, time/batch = 15.9725s	
19408/22300 (epoch 43.516), train_loss = 0.25313474, grad/param norm = 1.9756e-01, time/batch = 15.9582s	
19409/22300 (epoch 43.518), train_loss = 0.31156157, grad/param norm = 3.3182e-01, time/batch = 15.8910s	
19410/22300 (epoch 43.520), train_loss = 0.27651048, grad/param norm = 2.6782e-01, time/batch = 15.8779s	
19411/22300 (epoch 43.522), train_loss = 0.30239700, grad/param norm = 2.3837e-01, time/batch = 16.2024s	
19412/22300 (epoch 43.525), train_loss = 0.23604273, grad/param norm = 1.8618e-01, time/batch = 16.0831s	
19413/22300 (epoch 43.527), train_loss = 0.36262259, grad/param norm = 3.2595e-01, time/batch = 15.8811s	
19414/22300 (epoch 43.529), train_loss = 0.30298541, grad/param norm = 2.2809e-01, time/batch = 16.0356s	
19415/22300 (epoch 43.531), train_loss = 0.26852593, grad/param norm = 2.2063e-01, time/batch = 16.0358s	
19416/22300 (epoch 43.534), train_loss = 0.29153568, grad/param norm = 2.2179e-01, time/batch = 16.0464s	
19417/22300 (epoch 43.536), train_loss = 0.43792312, grad/param norm = 2.7974e-01, time/batch = 16.0132s	
19418/22300 (epoch 43.538), train_loss = 0.54230454, grad/param norm = 3.3044e-01, time/batch = 15.9365s	
19419/22300 (epoch 43.540), train_loss = 0.30636389, grad/param norm = 2.3464e-01, time/batch = 15.7814s	
19420/22300 (epoch 43.543), train_loss = 0.30881698, grad/param norm = 1.9538e-01, time/batch = 15.8974s	
19421/22300 (epoch 43.545), train_loss = 0.19700027, grad/param norm = 1.4957e-01, time/batch = 15.8850s	
19422/22300 (epoch 43.547), train_loss = 0.18925636, grad/param norm = 2.0408e-01, time/batch = 15.7216s	
19423/22300 (epoch 43.549), train_loss = 0.22555465, grad/param norm = 1.9669e-01, time/batch = 16.1256s	
19424/22300 (epoch 43.552), train_loss = 0.24737636, grad/param norm = 2.3635e-01, time/batch = 15.9663s	
19425/22300 (epoch 43.554), train_loss = 0.33381645, grad/param norm = 2.4947e-01, time/batch = 15.9687s	
19426/22300 (epoch 43.556), train_loss = 0.44536215, grad/param norm = 3.4128e-01, time/batch = 16.0932s	
19427/22300 (epoch 43.558), train_loss = 0.33590799, grad/param norm = 2.5042e-01, time/batch = 15.8595s	
19428/22300 (epoch 43.561), train_loss = 0.48568507, grad/param norm = 3.4439e-01, time/batch = 15.6197s	
19429/22300 (epoch 43.563), train_loss = 0.38995493, grad/param norm = 3.3300e-01, time/batch = 15.6126s	
19430/22300 (epoch 43.565), train_loss = 0.28767313, grad/param norm = 2.0628e-01, time/batch = 15.7932s	
19431/22300 (epoch 43.567), train_loss = 0.28628196, grad/param norm = 2.2079e-01, time/batch = 15.8799s	
19432/22300 (epoch 43.570), train_loss = 0.40858733, grad/param norm = 3.1610e-01, time/batch = 15.7410s	
19433/22300 (epoch 43.572), train_loss = 0.41280843, grad/param norm = 2.5072e-01, time/batch = 15.8136s	
19434/22300 (epoch 43.574), train_loss = 0.30747664, grad/param norm = 2.3919e-01, time/batch = 15.8619s	
19435/22300 (epoch 43.576), train_loss = 0.27838024, grad/param norm = 1.9927e-01, time/batch = 15.4871s	
19436/22300 (epoch 43.578), train_loss = 0.15277814, grad/param norm = 1.2599e-01, time/batch = 15.7369s	
19437/22300 (epoch 43.581), train_loss = 0.22642930, grad/param norm = 1.8322e-01, time/batch = 15.5556s	
19438/22300 (epoch 43.583), train_loss = 0.26946368, grad/param norm = 1.6048e-01, time/batch = 15.5494s	
19439/22300 (epoch 43.585), train_loss = 0.37756578, grad/param norm = 3.0241e-01, time/batch = 15.5636s	
19440/22300 (epoch 43.587), train_loss = 0.55537144, grad/param norm = 3.2478e-01, time/batch = 15.4913s	
19441/22300 (epoch 43.590), train_loss = 0.45281240, grad/param norm = 3.3382e-01, time/batch = 15.8859s	
19442/22300 (epoch 43.592), train_loss = 0.51445693, grad/param norm = 3.3100e-01, time/batch = 15.8777s	
19443/22300 (epoch 43.594), train_loss = 0.49647245, grad/param norm = 4.1241e-01, time/batch = 15.8307s	
19444/22300 (epoch 43.596), train_loss = 0.32121040, grad/param norm = 2.3434e-01, time/batch = 15.6701s	
19445/22300 (epoch 43.599), train_loss = 0.22850964, grad/param norm = 2.3334e-01, time/batch = 15.6787s	
19446/22300 (epoch 43.601), train_loss = 0.25436872, grad/param norm = 2.2214e-01, time/batch = 15.8167s	
19447/22300 (epoch 43.603), train_loss = 0.26687692, grad/param norm = 2.0623e-01, time/batch = 15.6278s	
19448/22300 (epoch 43.605), train_loss = 0.30858368, grad/param norm = 2.6493e-01, time/batch = 15.6044s	
19449/22300 (epoch 43.608), train_loss = 0.49446306, grad/param norm = 3.2031e-01, time/batch = 15.9689s	
19450/22300 (epoch 43.610), train_loss = 0.55900519, grad/param norm = 3.0091e-01, time/batch = 15.8925s	
19451/22300 (epoch 43.612), train_loss = 0.39822590, grad/param norm = 2.7395e-01, time/batch = 16.1242s	
19452/22300 (epoch 43.614), train_loss = 0.36495063, grad/param norm = 2.9322e-01, time/batch = 15.8090s	
19453/22300 (epoch 43.617), train_loss = 0.39955611, grad/param norm = 2.3378e-01, time/batch = 15.9860s	
19454/22300 (epoch 43.619), train_loss = 0.39408529, grad/param norm = 2.5774e-01, time/batch = 15.9514s	
19455/22300 (epoch 43.621), train_loss = 0.29028070, grad/param norm = 2.5271e-01, time/batch = 15.9457s	
19456/22300 (epoch 43.623), train_loss = 0.28761953, grad/param norm = 2.4379e-01, time/batch = 15.7426s	
19457/22300 (epoch 43.626), train_loss = 0.27781993, grad/param norm = 2.2234e-01, time/batch = 15.9538s	
19458/22300 (epoch 43.628), train_loss = 0.27467520, grad/param norm = 1.7827e-01, time/batch = 15.8931s	
19459/22300 (epoch 43.630), train_loss = 0.32667275, grad/param norm = 2.0533e-01, time/batch = 15.9170s	
19460/22300 (epoch 43.632), train_loss = 0.27399241, grad/param norm = 2.0655e-01, time/batch = 15.7656s	
19461/22300 (epoch 43.635), train_loss = 0.32458331, grad/param norm = 2.1453e-01, time/batch = 16.0379s	
19462/22300 (epoch 43.637), train_loss = 0.36733052, grad/param norm = 2.5128e-01, time/batch = 15.5593s	
19463/22300 (epoch 43.639), train_loss = 0.43268324, grad/param norm = 2.6651e-01, time/batch = 15.7724s	
19464/22300 (epoch 43.641), train_loss = 0.34811539, grad/param norm = 2.7610e-01, time/batch = 15.8740s	
19465/22300 (epoch 43.643), train_loss = 0.25995939, grad/param norm = 1.9247e-01, time/batch = 15.7220s	
19466/22300 (epoch 43.646), train_loss = 0.28071296, grad/param norm = 2.1201e-01, time/batch = 15.5361s	
19467/22300 (epoch 43.648), train_loss = 0.36868735, grad/param norm = 1.9001e-01, time/batch = 15.6494s	
19468/22300 (epoch 43.650), train_loss = 0.38252405, grad/param norm = 2.8799e-01, time/batch = 15.8855s	
19469/22300 (epoch 43.652), train_loss = 0.29103245, grad/param norm = 2.0256e-01, time/batch = 15.8350s	
19470/22300 (epoch 43.655), train_loss = 0.24747304, grad/param norm = 2.1818e-01, time/batch = 15.6291s	
19471/22300 (epoch 43.657), train_loss = 0.30234340, grad/param norm = 3.0593e-01, time/batch = 16.0715s	
19472/22300 (epoch 43.659), train_loss = 0.28263306, grad/param norm = 2.4709e-01, time/batch = 16.0442s	
19473/22300 (epoch 43.661), train_loss = 0.24843883, grad/param norm = 2.4490e-01, time/batch = 15.9560s	
19474/22300 (epoch 43.664), train_loss = 0.29285970, grad/param norm = 2.3142e-01, time/batch = 15.8963s	
19475/22300 (epoch 43.666), train_loss = 0.35130486, grad/param norm = 2.4320e-01, time/batch = 15.9575s	
19476/22300 (epoch 43.668), train_loss = 0.26278217, grad/param norm = 1.7493e-01, time/batch = 15.9597s	
19477/22300 (epoch 43.670), train_loss = 0.33465878, grad/param norm = 2.5543e-01, time/batch = 15.7155s	
19478/22300 (epoch 43.673), train_loss = 0.40150583, grad/param norm = 2.2276e-01, time/batch = 15.7395s	
19479/22300 (epoch 43.675), train_loss = 0.43377594, grad/param norm = 3.5159e-01, time/batch = 15.5565s	
19480/22300 (epoch 43.677), train_loss = 0.47335784, grad/param norm = 2.8972e-01, time/batch = 15.6434s	
19481/22300 (epoch 43.679), train_loss = 0.31720267, grad/param norm = 2.9243e-01, time/batch = 15.4926s	
19482/22300 (epoch 43.682), train_loss = 0.30557511, grad/param norm = 2.1930e-01, time/batch = 15.4623s	
19483/22300 (epoch 43.684), train_loss = 0.30846380, grad/param norm = 2.2290e-01, time/batch = 15.4478s	
19484/22300 (epoch 43.686), train_loss = 0.27781315, grad/param norm = 2.0519e-01, time/batch = 15.8089s	
19485/22300 (epoch 43.688), train_loss = 0.25459462, grad/param norm = 1.8125e-01, time/batch = 15.3339s	
19486/22300 (epoch 43.691), train_loss = 0.25457674, grad/param norm = 2.3155e-01, time/batch = 15.8118s	
19487/22300 (epoch 43.693), train_loss = 0.25014199, grad/param norm = 2.1528e-01, time/batch = 15.3581s	
19488/22300 (epoch 43.695), train_loss = 0.27414179, grad/param norm = 1.8493e-01, time/batch = 14.8410s	
19489/22300 (epoch 43.697), train_loss = 0.28691322, grad/param norm = 1.5810e-01, time/batch = 15.2208s	
19490/22300 (epoch 43.700), train_loss = 0.25278841, grad/param norm = 2.0304e-01, time/batch = 15.4488s	
19491/22300 (epoch 43.702), train_loss = 0.20893739, grad/param norm = 1.7073e-01, time/batch = 15.5450s	
19492/22300 (epoch 43.704), train_loss = 0.28237278, grad/param norm = 2.3877e-01, time/batch = 15.0751s	
19493/22300 (epoch 43.706), train_loss = 0.26159968, grad/param norm = 1.8714e-01, time/batch = 15.0536s	
19494/22300 (epoch 43.709), train_loss = 0.19275564, grad/param norm = 1.6049e-01, time/batch = 15.6140s	
19495/22300 (epoch 43.711), train_loss = 0.20038924, grad/param norm = 1.3845e-01, time/batch = 15.4577s	
19496/22300 (epoch 43.713), train_loss = 0.30735729, grad/param norm = 2.6709e-01, time/batch = 15.0708s	
19497/22300 (epoch 43.715), train_loss = 0.32693117, grad/param norm = 2.4593e-01, time/batch = 15.1647s	
19498/22300 (epoch 43.717), train_loss = 0.42979529, grad/param norm = 2.3426e-01, time/batch = 14.7253s	
19499/22300 (epoch 43.720), train_loss = 0.25225517, grad/param norm = 2.0242e-01, time/batch = 15.9827s	
19500/22300 (epoch 43.722), train_loss = 0.31047871, grad/param norm = 2.2264e-01, time/batch = 15.3631s	
19501/22300 (epoch 43.724), train_loss = 0.35233234, grad/param norm = 3.0078e-01, time/batch = 15.5293s	
19502/22300 (epoch 43.726), train_loss = 0.27125667, grad/param norm = 2.4768e-01, time/batch = 14.7503s	
19503/22300 (epoch 43.729), train_loss = 0.34109621, grad/param norm = 2.0810e-01, time/batch = 15.3628s	
19504/22300 (epoch 43.731), train_loss = 0.37787020, grad/param norm = 2.5394e-01, time/batch = 14.5804s	
19505/22300 (epoch 43.733), train_loss = 0.39576800, grad/param norm = 3.1784e-01, time/batch = 15.2068s	
19506/22300 (epoch 43.735), train_loss = 0.41912115, grad/param norm = 2.9244e-01, time/batch = 15.7472s	
19507/22300 (epoch 43.738), train_loss = 0.31232193, grad/param norm = 3.1731e-01, time/batch = 15.6339s	
19508/22300 (epoch 43.740), train_loss = 0.28929337, grad/param norm = 2.0174e-01, time/batch = 14.8060s	
19509/22300 (epoch 43.742), train_loss = 0.25013944, grad/param norm = 1.7188e-01, time/batch = 15.2850s	
19510/22300 (epoch 43.744), train_loss = 0.44624968, grad/param norm = 2.7449e-01, time/batch = 14.6363s	
19511/22300 (epoch 43.747), train_loss = 0.37476435, grad/param norm = 2.6743e-01, time/batch = 14.8044s	
19512/22300 (epoch 43.749), train_loss = 0.48212333, grad/param norm = 3.0791e-01, time/batch = 14.3270s	
19513/22300 (epoch 43.751), train_loss = 0.38084093, grad/param norm = 2.8730e-01, time/batch = 14.3368s	
19514/22300 (epoch 43.753), train_loss = 0.41138263, grad/param norm = 2.8073e-01, time/batch = 14.8530s	
19515/22300 (epoch 43.756), train_loss = 0.40550416, grad/param norm = 2.3350e-01, time/batch = 14.6384s	
19516/22300 (epoch 43.758), train_loss = 0.33755733, grad/param norm = 2.2876e-01, time/batch = 14.3434s	
19517/22300 (epoch 43.760), train_loss = 0.37944592, grad/param norm = 2.8663e-01, time/batch = 14.5715s	
19518/22300 (epoch 43.762), train_loss = 0.32917461, grad/param norm = 2.3905e-01, time/batch = 14.5673s	
19519/22300 (epoch 43.765), train_loss = 0.37747322, grad/param norm = 2.5878e-01, time/batch = 15.5186s	
19520/22300 (epoch 43.767), train_loss = 0.32806946, grad/param norm = 2.4195e-01, time/batch = 17.8664s	
19521/22300 (epoch 43.769), train_loss = 0.33589491, grad/param norm = 2.7790e-01, time/batch = 16.4434s	
19522/22300 (epoch 43.771), train_loss = 0.39215575, grad/param norm = 3.0855e-01, time/batch = 17.1762s	
19523/22300 (epoch 43.774), train_loss = 0.42455883, grad/param norm = 3.5458e-01, time/batch = 16.0340s	
19524/22300 (epoch 43.776), train_loss = 0.44927600, grad/param norm = 2.8537e-01, time/batch = 16.4821s	
19525/22300 (epoch 43.778), train_loss = 0.47333315, grad/param norm = 4.0433e-01, time/batch = 15.7447s	
19526/22300 (epoch 43.780), train_loss = 0.43413740, grad/param norm = 2.8908e-01, time/batch = 15.8368s	
19527/22300 (epoch 43.783), train_loss = 0.46800670, grad/param norm = 2.9930e-01, time/batch = 15.5483s	
19528/22300 (epoch 43.785), train_loss = 0.31767649, grad/param norm = 3.0519e-01, time/batch = 14.9610s	
19529/22300 (epoch 43.787), train_loss = 0.32132305, grad/param norm = 2.2793e-01, time/batch = 15.7890s	
19530/22300 (epoch 43.789), train_loss = 0.46388010, grad/param norm = 2.6822e-01, time/batch = 15.3940s	
19531/22300 (epoch 43.791), train_loss = 0.58511919, grad/param norm = 3.7852e-01, time/batch = 15.3567s	
19532/22300 (epoch 43.794), train_loss = 0.49709262, grad/param norm = 3.6477e-01, time/batch = 15.8907s	
19533/22300 (epoch 43.796), train_loss = 0.42022042, grad/param norm = 3.2703e-01, time/batch = 15.3273s	
19534/22300 (epoch 43.798), train_loss = 0.53265677, grad/param norm = 3.2725e-01, time/batch = 15.3450s	
19535/22300 (epoch 43.800), train_loss = 0.38012320, grad/param norm = 2.7444e-01, time/batch = 15.8814s	
19536/22300 (epoch 43.803), train_loss = 0.31946774, grad/param norm = 2.2868e-01, time/batch = 17.8834s	
19537/22300 (epoch 43.805), train_loss = 0.35662653, grad/param norm = 2.7989e-01, time/batch = 16.8829s	
19538/22300 (epoch 43.807), train_loss = 0.48818106, grad/param norm = 3.1048e-01, time/batch = 15.6389s	
19539/22300 (epoch 43.809), train_loss = 0.34515584, grad/param norm = 2.4056e-01, time/batch = 15.3206s	
19540/22300 (epoch 43.812), train_loss = 0.38563016, grad/param norm = 2.7413e-01, time/batch = 15.2096s	
19541/22300 (epoch 43.814), train_loss = 0.34878286, grad/param norm = 2.4380e-01, time/batch = 15.7787s	
19542/22300 (epoch 43.816), train_loss = 0.40455332, grad/param norm = 3.0545e-01, time/batch = 15.1359s	
19543/22300 (epoch 43.818), train_loss = 0.47241910, grad/param norm = 3.7136e-01, time/batch = 15.0617s	
19544/22300 (epoch 43.821), train_loss = 0.37995230, grad/param norm = 2.7050e-01, time/batch = 15.0650s	
19545/22300 (epoch 43.823), train_loss = 0.25653063, grad/param norm = 2.1826e-01, time/batch = 23.6912s	
19546/22300 (epoch 43.825), train_loss = 0.27151765, grad/param norm = 2.2500e-01, time/batch = 20.4241s	
19547/22300 (epoch 43.827), train_loss = 0.30996940, grad/param norm = 2.7358e-01, time/batch = 15.4201s	
19548/22300 (epoch 43.830), train_loss = 0.32715989, grad/param norm = 2.6759e-01, time/batch = 15.6085s	
19549/22300 (epoch 43.832), train_loss = 0.32735295, grad/param norm = 2.7234e-01, time/batch = 15.3795s	
19550/22300 (epoch 43.834), train_loss = 0.26506175, grad/param norm = 2.0439e-01, time/batch = 14.9848s	
19551/22300 (epoch 43.836), train_loss = 0.31042930, grad/param norm = 2.2990e-01, time/batch = 15.1385s	
19552/22300 (epoch 43.839), train_loss = 0.35720301, grad/param norm = 2.4751e-01, time/batch = 15.4371s	
19553/22300 (epoch 43.841), train_loss = 0.30622114, grad/param norm = 2.6372e-01, time/batch = 15.3901s	
19554/22300 (epoch 43.843), train_loss = 0.33294903, grad/param norm = 2.6970e-01, time/batch = 14.9795s	
19555/22300 (epoch 43.845), train_loss = 0.33245863, grad/param norm = 2.3286e-01, time/batch = 14.7491s	
19556/22300 (epoch 43.848), train_loss = 0.29552518, grad/param norm = 2.2802e-01, time/batch = 15.0515s	
19557/22300 (epoch 43.850), train_loss = 0.33827971, grad/param norm = 2.3656e-01, time/batch = 14.8128s	
19558/22300 (epoch 43.852), train_loss = 0.31006022, grad/param norm = 2.7576e-01, time/batch = 15.1971s	
19559/22300 (epoch 43.854), train_loss = 0.51788748, grad/param norm = 3.4835e-01, time/batch = 14.7308s	
19560/22300 (epoch 43.857), train_loss = 0.35770620, grad/param norm = 2.3934e-01, time/batch = 15.2945s	
19561/22300 (epoch 43.859), train_loss = 0.31939005, grad/param norm = 2.8778e-01, time/batch = 15.3918s	
19562/22300 (epoch 43.861), train_loss = 0.42122232, grad/param norm = 2.7114e-01, time/batch = 15.5156s	
19563/22300 (epoch 43.863), train_loss = 0.24530873, grad/param norm = 1.8059e-01, time/batch = 14.8970s	
19564/22300 (epoch 43.865), train_loss = 0.26119896, grad/param norm = 1.8752e-01, time/batch = 8.4476s	
19565/22300 (epoch 43.868), train_loss = 0.37318836, grad/param norm = 2.8794e-01, time/batch = 0.6589s	
19566/22300 (epoch 43.870), train_loss = 0.35214019, grad/param norm = 2.8005e-01, time/batch = 0.6598s	
19567/22300 (epoch 43.872), train_loss = 0.44179616, grad/param norm = 2.5568e-01, time/batch = 0.6604s	
19568/22300 (epoch 43.874), train_loss = 0.38120344, grad/param norm = 2.8868e-01, time/batch = 0.6601s	
19569/22300 (epoch 43.877), train_loss = 0.32233247, grad/param norm = 1.9965e-01, time/batch = 0.6636s	
19570/22300 (epoch 43.879), train_loss = 0.32638054, grad/param norm = 2.2607e-01, time/batch = 0.6630s	
19571/22300 (epoch 43.881), train_loss = 0.25588895, grad/param norm = 2.1718e-01, time/batch = 0.6640s	
19572/22300 (epoch 43.883), train_loss = 0.26159756, grad/param norm = 2.5847e-01, time/batch = 0.9460s	
19573/22300 (epoch 43.886), train_loss = 0.24197105, grad/param norm = 2.4565e-01, time/batch = 0.9654s	
19574/22300 (epoch 43.888), train_loss = 0.31155267, grad/param norm = 2.2550e-01, time/batch = 0.9705s	
19575/22300 (epoch 43.890), train_loss = 0.31123120, grad/param norm = 2.4886e-01, time/batch = 0.9761s	
19576/22300 (epoch 43.892), train_loss = 0.45729931, grad/param norm = 2.6717e-01, time/batch = 0.9685s	
19577/22300 (epoch 43.895), train_loss = 0.41111050, grad/param norm = 2.8208e-01, time/batch = 1.6312s	
19578/22300 (epoch 43.897), train_loss = 0.31074272, grad/param norm = 2.3835e-01, time/batch = 1.8369s	
19579/22300 (epoch 43.899), train_loss = 0.31735467, grad/param norm = 2.3314e-01, time/batch = 2.1815s	
19580/22300 (epoch 43.901), train_loss = 0.40402987, grad/param norm = 3.0550e-01, time/batch = 14.9785s	
19581/22300 (epoch 43.904), train_loss = 0.38282707, grad/param norm = 2.5783e-01, time/batch = 14.9630s	
19582/22300 (epoch 43.906), train_loss = 0.38290288, grad/param norm = 2.8152e-01, time/batch = 15.4678s	
19583/22300 (epoch 43.908), train_loss = 0.32924981, grad/param norm = 2.2305e-01, time/batch = 14.8925s	
19584/22300 (epoch 43.910), train_loss = 0.29944794, grad/param norm = 2.2821e-01, time/batch = 15.1400s	
19585/22300 (epoch 43.913), train_loss = 0.38960703, grad/param norm = 3.0383e-01, time/batch = 14.9708s	
19586/22300 (epoch 43.915), train_loss = 0.48072320, grad/param norm = 3.2421e-01, time/batch = 15.2023s	
19587/22300 (epoch 43.917), train_loss = 0.38921075, grad/param norm = 2.8509e-01, time/batch = 14.8878s	
19588/22300 (epoch 43.919), train_loss = 0.36566017, grad/param norm = 2.6732e-01, time/batch = 14.9676s	
19589/22300 (epoch 43.922), train_loss = 0.33398918, grad/param norm = 2.3533e-01, time/batch = 15.0673s	
19590/22300 (epoch 43.924), train_loss = 0.22694980, grad/param norm = 1.6314e-01, time/batch = 15.3085s	
19591/22300 (epoch 43.926), train_loss = 0.27929067, grad/param norm = 1.8820e-01, time/batch = 15.4837s	
19592/22300 (epoch 43.928), train_loss = 0.30797548, grad/param norm = 2.4171e-01, time/batch = 15.2905s	
19593/22300 (epoch 43.930), train_loss = 0.28789071, grad/param norm = 2.3619e-01, time/batch = 15.3375s	
19594/22300 (epoch 43.933), train_loss = 0.36856420, grad/param norm = 2.9484e-01, time/batch = 15.1814s	
19595/22300 (epoch 43.935), train_loss = 0.35244476, grad/param norm = 3.0025e-01, time/batch = 14.8115s	
19596/22300 (epoch 43.937), train_loss = 0.43476332, grad/param norm = 3.2501e-01, time/batch = 15.1375s	
19597/22300 (epoch 43.939), train_loss = 0.38074327, grad/param norm = 2.5980e-01, time/batch = 14.8120s	
19598/22300 (epoch 43.942), train_loss = 0.47956867, grad/param norm = 3.3573e-01, time/batch = 15.6661s	
19599/22300 (epoch 43.944), train_loss = 0.54004101, grad/param norm = 4.6950e-01, time/batch = 15.0443s	
19600/22300 (epoch 43.946), train_loss = 0.38606908, grad/param norm = 2.4374e-01, time/batch = 14.8769s	
19601/22300 (epoch 43.948), train_loss = 0.31142250, grad/param norm = 1.9439e-01, time/batch = 15.5209s	
19602/22300 (epoch 43.951), train_loss = 0.25080781, grad/param norm = 2.1055e-01, time/batch = 15.5056s	
19603/22300 (epoch 43.953), train_loss = 0.28244575, grad/param norm = 2.6580e-01, time/batch = 15.7012s	
19604/22300 (epoch 43.955), train_loss = 0.41573323, grad/param norm = 2.3706e-01, time/batch = 15.1473s	
19605/22300 (epoch 43.957), train_loss = 0.52141664, grad/param norm = 3.0121e-01, time/batch = 16.0643s	
19606/22300 (epoch 43.960), train_loss = 0.46763592, grad/param norm = 3.5487e-01, time/batch = 15.4575s	
19607/22300 (epoch 43.962), train_loss = 0.28512180, grad/param norm = 2.4176e-01, time/batch = 15.5733s	
19608/22300 (epoch 43.964), train_loss = 0.28032598, grad/param norm = 2.1210e-01, time/batch = 14.5753s	
19609/22300 (epoch 43.966), train_loss = 0.31313564, grad/param norm = 2.4088e-01, time/batch = 15.8728s	
19610/22300 (epoch 43.969), train_loss = 0.30466093, grad/param norm = 1.8819e-01, time/batch = 14.8017s	
19611/22300 (epoch 43.971), train_loss = 0.34394024, grad/param norm = 2.2074e-01, time/batch = 15.4704s	
19612/22300 (epoch 43.973), train_loss = 0.31546073, grad/param norm = 2.7652e-01, time/batch = 15.2757s	
19613/22300 (epoch 43.975), train_loss = 0.47201945, grad/param norm = 3.3896e-01, time/batch = 14.9749s	
19614/22300 (epoch 43.978), train_loss = 0.44991964, grad/param norm = 3.3380e-01, time/batch = 15.9515s	
19615/22300 (epoch 43.980), train_loss = 0.50972905, grad/param norm = 2.5225e-01, time/batch = 14.9857s	
19616/22300 (epoch 43.982), train_loss = 0.25261657, grad/param norm = 2.2308e-01, time/batch = 15.2268s	
19617/22300 (epoch 43.984), train_loss = 0.32404153, grad/param norm = 2.0085e-01, time/batch = 16.2711s	
19618/22300 (epoch 43.987), train_loss = 0.35016727, grad/param norm = 2.6752e-01, time/batch = 15.2875s	
19619/22300 (epoch 43.989), train_loss = 0.27551268, grad/param norm = 2.4900e-01, time/batch = 14.9022s	
19620/22300 (epoch 43.991), train_loss = 0.50014664, grad/param norm = 3.1038e-01, time/batch = 15.1410s	
19621/22300 (epoch 43.993), train_loss = 0.67380736, grad/param norm = 3.5521e-01, time/batch = 14.8835s	
19622/22300 (epoch 43.996), train_loss = 0.61536296, grad/param norm = 3.2713e-01, time/batch = 15.2809s	
19623/22300 (epoch 43.998), train_loss = 0.39570985, grad/param norm = 3.5074e-01, time/batch = 15.0674s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
19624/22300 (epoch 44.000), train_loss = 0.31276417, grad/param norm = 2.5971e-01, time/batch = 15.5996s	
19625/22300 (epoch 44.002), train_loss = 0.64110686, grad/param norm = 3.0284e-01, time/batch = 15.4380s	
19626/22300 (epoch 44.004), train_loss = 0.40692596, grad/param norm = 2.4793e-01, time/batch = 14.8244s	
19627/22300 (epoch 44.007), train_loss = 0.42767717, grad/param norm = 2.8877e-01, time/batch = 14.8807s	
19628/22300 (epoch 44.009), train_loss = 0.42127674, grad/param norm = 2.8308e-01, time/batch = 14.6387s	
19629/22300 (epoch 44.011), train_loss = 0.54309829, grad/param norm = 3.5302e-01, time/batch = 15.0630s	
19630/22300 (epoch 44.013), train_loss = 0.42693063, grad/param norm = 2.6304e-01, time/batch = 15.1417s	
19631/22300 (epoch 44.016), train_loss = 0.31725365, grad/param norm = 2.7007e-01, time/batch = 14.9047s	
19632/22300 (epoch 44.018), train_loss = 0.34448394, grad/param norm = 2.2240e-01, time/batch = 15.1949s	
19633/22300 (epoch 44.020), train_loss = 0.34016918, grad/param norm = 2.5876e-01, time/batch = 15.2903s	
19634/22300 (epoch 44.022), train_loss = 0.25829041, grad/param norm = 2.5073e-01, time/batch = 14.9592s	
19635/22300 (epoch 44.025), train_loss = 0.30786159, grad/param norm = 2.4166e-01, time/batch = 15.9622s	
19636/22300 (epoch 44.027), train_loss = 0.28619527, grad/param norm = 1.9446e-01, time/batch = 14.7974s	
19637/22300 (epoch 44.029), train_loss = 0.32297245, grad/param norm = 2.6463e-01, time/batch = 15.9263s	
19638/22300 (epoch 44.031), train_loss = 0.29220055, grad/param norm = 2.1420e-01, time/batch = 15.2024s	
19639/22300 (epoch 44.034), train_loss = 0.30084961, grad/param norm = 2.2672e-01, time/batch = 14.8080s	
19640/22300 (epoch 44.036), train_loss = 0.29481545, grad/param norm = 2.1082e-01, time/batch = 15.2145s	
19641/22300 (epoch 44.038), train_loss = 0.23905481, grad/param norm = 2.1228e-01, time/batch = 14.8908s	
19642/22300 (epoch 44.040), train_loss = 0.29283915, grad/param norm = 2.1994e-01, time/batch = 14.8809s	
19643/22300 (epoch 44.043), train_loss = 0.50474289, grad/param norm = 3.2820e-01, time/batch = 15.3319s	
19644/22300 (epoch 44.045), train_loss = 0.43156926, grad/param norm = 2.5522e-01, time/batch = 14.5579s	
19645/22300 (epoch 44.047), train_loss = 0.46987480, grad/param norm = 2.7304e-01, time/batch = 15.6077s	
19646/22300 (epoch 44.049), train_loss = 0.34784559, grad/param norm = 2.5177e-01, time/batch = 14.8904s	
19647/22300 (epoch 44.052), train_loss = 0.40298521, grad/param norm = 2.7149e-01, time/batch = 14.7367s	
19648/22300 (epoch 44.054), train_loss = 0.40237714, grad/param norm = 2.5276e-01, time/batch = 15.3098s	
19649/22300 (epoch 44.056), train_loss = 0.20206191, grad/param norm = 1.7665e-01, time/batch = 15.1992s	
19650/22300 (epoch 44.058), train_loss = 0.32822764, grad/param norm = 2.6248e-01, time/batch = 15.0607s	
19651/22300 (epoch 44.061), train_loss = 0.29042423, grad/param norm = 2.4946e-01, time/batch = 15.6824s	
19652/22300 (epoch 44.063), train_loss = 0.44630204, grad/param norm = 3.5849e-01, time/batch = 15.0293s	
19653/22300 (epoch 44.065), train_loss = 0.49407226, grad/param norm = 3.2805e-01, time/batch = 15.6755s	
19654/22300 (epoch 44.067), train_loss = 0.28772463, grad/param norm = 2.6137e-01, time/batch = 14.9676s	
19655/22300 (epoch 44.070), train_loss = 0.34676959, grad/param norm = 2.8483e-01, time/batch = 15.2089s	
19656/22300 (epoch 44.072), train_loss = 0.39361556, grad/param norm = 4.0183e-01, time/batch = 14.9921s	
19657/22300 (epoch 44.074), train_loss = 0.39276009, grad/param norm = 2.9386e-01, time/batch = 15.0957s	
19658/22300 (epoch 44.076), train_loss = 0.37353872, grad/param norm = 3.3165e-01, time/batch = 14.9694s	
19659/22300 (epoch 44.078), train_loss = 0.50696930, grad/param norm = 3.8164e-01, time/batch = 15.0536s	
19660/22300 (epoch 44.081), train_loss = 0.47246336, grad/param norm = 3.1478e-01, time/batch = 15.3035s	
19661/22300 (epoch 44.083), train_loss = 0.55428336, grad/param norm = 3.9961e-01, time/batch = 15.6035s	
19662/22300 (epoch 44.085), train_loss = 0.49998069, grad/param norm = 3.1305e-01, time/batch = 15.2183s	
19663/22300 (epoch 44.087), train_loss = 0.40075394, grad/param norm = 2.6431e-01, time/batch = 14.9650s	
19664/22300 (epoch 44.090), train_loss = 0.37832012, grad/param norm = 2.7918e-01, time/batch = 15.3782s	
19665/22300 (epoch 44.092), train_loss = 0.27598593, grad/param norm = 2.0759e-01, time/batch = 15.4684s	
19666/22300 (epoch 44.094), train_loss = 0.27648588, grad/param norm = 2.2023e-01, time/batch = 15.2089s	
19667/22300 (epoch 44.096), train_loss = 0.48460929, grad/param norm = 3.0374e-01, time/batch = 14.9660s	
19668/22300 (epoch 44.099), train_loss = 0.35086352, grad/param norm = 2.8853e-01, time/batch = 14.9712s	
19669/22300 (epoch 44.101), train_loss = 0.44669291, grad/param norm = 3.0084e-01, time/batch = 14.9478s	
19670/22300 (epoch 44.103), train_loss = 0.35384612, grad/param norm = 2.0692e-01, time/batch = 15.1329s	
19671/22300 (epoch 44.105), train_loss = 0.28817317, grad/param norm = 3.0385e-01, time/batch = 15.4565s	
19672/22300 (epoch 44.108), train_loss = 0.40098820, grad/param norm = 2.6080e-01, time/batch = 15.0446s	
19673/22300 (epoch 44.110), train_loss = 0.46067927, grad/param norm = 2.9231e-01, time/batch = 15.1881s	
19674/22300 (epoch 44.112), train_loss = 0.39156501, grad/param norm = 2.6680e-01, time/batch = 14.8110s	
19675/22300 (epoch 44.114), train_loss = 0.43146450, grad/param norm = 2.8756e-01, time/batch = 15.4626s	
19676/22300 (epoch 44.117), train_loss = 0.49378400, grad/param norm = 2.8568e-01, time/batch = 15.7659s	
19677/22300 (epoch 44.119), train_loss = 0.43866121, grad/param norm = 3.3434e-01, time/batch = 15.2110s	
19678/22300 (epoch 44.121), train_loss = 0.50514857, grad/param norm = 3.1802e-01, time/batch = 15.3592s	
19679/22300 (epoch 44.123), train_loss = 0.52805951, grad/param norm = 3.0309e-01, time/batch = 15.1211s	
19680/22300 (epoch 44.126), train_loss = 0.39439927, grad/param norm = 2.3658e-01, time/batch = 15.3514s	
19681/22300 (epoch 44.128), train_loss = 0.37890278, grad/param norm = 2.6863e-01, time/batch = 15.9743s	
19682/22300 (epoch 44.130), train_loss = 0.36033422, grad/param norm = 2.6559e-01, time/batch = 15.7393s	
19683/22300 (epoch 44.132), train_loss = 0.23513413, grad/param norm = 1.7969e-01, time/batch = 15.6747s	
19684/22300 (epoch 44.135), train_loss = 0.27836276, grad/param norm = 2.1540e-01, time/batch = 14.8811s	
19685/22300 (epoch 44.137), train_loss = 0.22343866, grad/param norm = 1.8783e-01, time/batch = 14.9342s	
19686/22300 (epoch 44.139), train_loss = 0.32314186, grad/param norm = 2.6760e-01, time/batch = 14.3900s	
19687/22300 (epoch 44.141), train_loss = 0.42255890, grad/param norm = 2.4825e-01, time/batch = 14.4806s	
19688/22300 (epoch 44.143), train_loss = 0.33873923, grad/param norm = 2.4052e-01, time/batch = 14.7066s	
19689/22300 (epoch 44.146), train_loss = 0.43153879, grad/param norm = 2.7049e-01, time/batch = 14.4781s	
19690/22300 (epoch 44.148), train_loss = 0.29980373, grad/param norm = 2.2178e-01, time/batch = 14.3224s	
19691/22300 (epoch 44.150), train_loss = 0.31089937, grad/param norm = 2.0618e-01, time/batch = 15.1676s	
19692/22300 (epoch 44.152), train_loss = 0.27754098, grad/param norm = 2.2957e-01, time/batch = 15.0357s	
19693/22300 (epoch 44.155), train_loss = 0.28492740, grad/param norm = 2.0194e-01, time/batch = 14.5588s	
19694/22300 (epoch 44.157), train_loss = 0.38823738, grad/param norm = 2.8042e-01, time/batch = 14.6456s	
19695/22300 (epoch 44.159), train_loss = 0.38693343, grad/param norm = 2.8173e-01, time/batch = 14.5658s	
19696/22300 (epoch 44.161), train_loss = 0.40195013, grad/param norm = 3.4463e-01, time/batch = 14.8804s	
19697/22300 (epoch 44.164), train_loss = 0.28446458, grad/param norm = 1.9551e-01, time/batch = 14.4092s	
19698/22300 (epoch 44.166), train_loss = 0.25708571, grad/param norm = 1.8958e-01, time/batch = 14.5606s	
19699/22300 (epoch 44.168), train_loss = 0.23794886, grad/param norm = 2.1854e-01, time/batch = 14.4769s	
19700/22300 (epoch 44.170), train_loss = 0.34268922, grad/param norm = 2.5073e-01, time/batch = 14.7853s	
19701/22300 (epoch 44.173), train_loss = 0.39441227, grad/param norm = 2.7901e-01, time/batch = 14.4777s	
19702/22300 (epoch 44.175), train_loss = 0.33985890, grad/param norm = 2.2429e-01, time/batch = 14.1595s	
19703/22300 (epoch 44.177), train_loss = 0.24943469, grad/param norm = 2.3516e-01, time/batch = 14.4732s	
19704/22300 (epoch 44.179), train_loss = 0.36087087, grad/param norm = 2.6238e-01, time/batch = 14.7274s	
19705/22300 (epoch 44.182), train_loss = 0.47483781, grad/param norm = 3.0253e-01, time/batch = 14.6394s	
19706/22300 (epoch 44.184), train_loss = 0.50174403, grad/param norm = 3.2032e-01, time/batch = 14.0718s	
19707/22300 (epoch 44.186), train_loss = 0.38340797, grad/param norm = 3.1334e-01, time/batch = 14.4814s	
19708/22300 (epoch 44.188), train_loss = 0.57351425, grad/param norm = 3.5458e-01, time/batch = 14.0704s	
19709/22300 (epoch 44.191), train_loss = 0.43792462, grad/param norm = 3.0710e-01, time/batch = 14.7859s	
19710/22300 (epoch 44.193), train_loss = 0.41879237, grad/param norm = 2.7655e-01, time/batch = 14.8089s	
19711/22300 (epoch 44.195), train_loss = 0.33676916, grad/param norm = 2.5223e-01, time/batch = 14.9451s	
19712/22300 (epoch 44.197), train_loss = 0.31013643, grad/param norm = 2.2368e-01, time/batch = 14.3985s	
19713/22300 (epoch 44.200), train_loss = 0.28479096, grad/param norm = 2.4839e-01, time/batch = 15.1040s	
19714/22300 (epoch 44.202), train_loss = 0.28542324, grad/param norm = 1.9927e-01, time/batch = 14.3171s	
19715/22300 (epoch 44.204), train_loss = 0.37413297, grad/param norm = 2.2876e-01, time/batch = 14.5623s	
19716/22300 (epoch 44.206), train_loss = 0.29957105, grad/param norm = 2.8616e-01, time/batch = 14.1582s	
19717/22300 (epoch 44.209), train_loss = 0.32103052, grad/param norm = 2.6668e-01, time/batch = 14.9985s	
19718/22300 (epoch 44.211), train_loss = 0.24627327, grad/param norm = 2.0907e-01, time/batch = 14.3952s	
19719/22300 (epoch 44.213), train_loss = 0.41311613, grad/param norm = 3.2388e-01, time/batch = 14.3202s	
19720/22300 (epoch 44.215), train_loss = 0.46247742, grad/param norm = 3.1158e-01, time/batch = 14.0124s	
19721/22300 (epoch 44.217), train_loss = 0.49089849, grad/param norm = 2.8833e-01, time/batch = 15.0423s	
19722/22300 (epoch 44.220), train_loss = 0.33158310, grad/param norm = 2.3145e-01, time/batch = 15.1765s	
19723/22300 (epoch 44.222), train_loss = 0.32392148, grad/param norm = 2.9301e-01, time/batch = 14.7230s	
19724/22300 (epoch 44.224), train_loss = 0.31674488, grad/param norm = 2.6277e-01, time/batch = 14.0154s	
19725/22300 (epoch 44.226), train_loss = 0.36813863, grad/param norm = 3.0078e-01, time/batch = 14.7241s	
19726/22300 (epoch 44.229), train_loss = 0.28788718, grad/param norm = 2.8344e-01, time/batch = 14.9674s	
19727/22300 (epoch 44.231), train_loss = 0.47474906, grad/param norm = 5.5197e-01, time/batch = 14.9597s	
19728/22300 (epoch 44.233), train_loss = 0.38056400, grad/param norm = 3.1380e-01, time/batch = 13.9913s	
19729/22300 (epoch 44.235), train_loss = 0.28602647, grad/param norm = 2.0430e-01, time/batch = 14.7846s	
19730/22300 (epoch 44.238), train_loss = 0.29084599, grad/param norm = 2.2948e-01, time/batch = 15.4663s	
19731/22300 (epoch 44.240), train_loss = 0.30107901, grad/param norm = 2.0613e-01, time/batch = 15.0515s	
19732/22300 (epoch 44.242), train_loss = 0.32040232, grad/param norm = 3.7860e-01, time/batch = 14.4757s	
19733/22300 (epoch 44.244), train_loss = 0.20465554, grad/param norm = 1.8092e-01, time/batch = 14.8573s	
19734/22300 (epoch 44.247), train_loss = 0.28001284, grad/param norm = 2.4526e-01, time/batch = 14.5024s	
19735/22300 (epoch 44.249), train_loss = 0.18677015, grad/param norm = 1.7240e-01, time/batch = 14.4970s	
19736/22300 (epoch 44.251), train_loss = 0.24011474, grad/param norm = 1.5888e-01, time/batch = 14.4097s	
19737/22300 (epoch 44.253), train_loss = 0.16708333, grad/param norm = 1.9649e-01, time/batch = 15.1955s	
19738/22300 (epoch 44.256), train_loss = 0.24125262, grad/param norm = 2.1791e-01, time/batch = 14.6583s	
19739/22300 (epoch 44.258), train_loss = 0.36239760, grad/param norm = 3.0037e-01, time/batch = 14.6608s	
19740/22300 (epoch 44.260), train_loss = 0.37976863, grad/param norm = 2.6409e-01, time/batch = 14.5589s	
19741/22300 (epoch 44.262), train_loss = 0.27946957, grad/param norm = 1.9105e-01, time/batch = 15.1457s	
19742/22300 (epoch 44.265), train_loss = 0.26534186, grad/param norm = 2.4774e-01, time/batch = 14.5045s	
19743/22300 (epoch 44.267), train_loss = 0.27342794, grad/param norm = 1.8492e-01, time/batch = 14.8081s	
19744/22300 (epoch 44.269), train_loss = 0.36186087, grad/param norm = 3.1920e-01, time/batch = 14.6325s	
19745/22300 (epoch 44.271), train_loss = 0.39029552, grad/param norm = 2.2625e-01, time/batch = 15.0469s	
19746/22300 (epoch 44.274), train_loss = 0.24417108, grad/param norm = 2.0295e-01, time/batch = 14.4108s	
19747/22300 (epoch 44.276), train_loss = 0.23155747, grad/param norm = 1.6466e-01, time/batch = 14.3272s	
19748/22300 (epoch 44.278), train_loss = 0.25057402, grad/param norm = 2.2088e-01, time/batch = 14.7385s	
19749/22300 (epoch 44.280), train_loss = 0.27080461, grad/param norm = 2.3251e-01, time/batch = 14.7445s	
19750/22300 (epoch 44.283), train_loss = 0.21602614, grad/param norm = 1.5626e-01, time/batch = 14.5710s	
19751/22300 (epoch 44.285), train_loss = 0.23915633, grad/param norm = 2.4485e-01, time/batch = 14.3430s	
19752/22300 (epoch 44.287), train_loss = 0.32905019, grad/param norm = 2.3221e-01, time/batch = 15.2666s	
19753/22300 (epoch 44.289), train_loss = 0.32102765, grad/param norm = 2.6078e-01, time/batch = 14.4748s	
19754/22300 (epoch 44.291), train_loss = 0.29101084, grad/param norm = 2.2171e-01, time/batch = 14.2428s	
19755/22300 (epoch 44.294), train_loss = 0.25198045, grad/param norm = 1.7349e-01, time/batch = 14.4135s	
19756/22300 (epoch 44.296), train_loss = 0.29330144, grad/param norm = 2.9299e-01, time/batch = 14.6636s	
19757/22300 (epoch 44.298), train_loss = 0.38129970, grad/param norm = 2.4149e-01, time/batch = 14.8705s	
19758/22300 (epoch 44.300), train_loss = 0.42452499, grad/param norm = 2.4916e-01, time/batch = 14.8047s	
19759/22300 (epoch 44.303), train_loss = 0.34232616, grad/param norm = 2.6330e-01, time/batch = 14.0017s	
19760/22300 (epoch 44.305), train_loss = 0.33382128, grad/param norm = 2.2333e-01, time/batch = 13.9950s	
19761/22300 (epoch 44.307), train_loss = 0.29807132, grad/param norm = 2.9993e-01, time/batch = 14.4864s	
19762/22300 (epoch 44.309), train_loss = 0.24970109, grad/param norm = 2.0188e-01, time/batch = 14.8013s	
19763/22300 (epoch 44.312), train_loss = 0.21671187, grad/param norm = 1.8147e-01, time/batch = 14.2441s	
19764/22300 (epoch 44.314), train_loss = 0.27312109, grad/param norm = 2.2472e-01, time/batch = 14.3354s	
19765/22300 (epoch 44.316), train_loss = 0.25554650, grad/param norm = 2.5610e-01, time/batch = 14.6653s	
19766/22300 (epoch 44.318), train_loss = 0.28170336, grad/param norm = 2.2470e-01, time/batch = 16.4554s	
19767/22300 (epoch 44.321), train_loss = 0.35126408, grad/param norm = 2.1899e-01, time/batch = 14.6656s	
19768/22300 (epoch 44.323), train_loss = 0.25784411, grad/param norm = 2.1426e-01, time/batch = 15.2144s	
19769/22300 (epoch 44.325), train_loss = 0.21259862, grad/param norm = 1.5481e-01, time/batch = 16.0844s	
19770/22300 (epoch 44.327), train_loss = 0.24379006, grad/param norm = 1.6861e-01, time/batch = 15.4805s	
19771/22300 (epoch 44.330), train_loss = 0.24690675, grad/param norm = 2.0352e-01, time/batch = 14.7568s	
19772/22300 (epoch 44.332), train_loss = 0.23599172, grad/param norm = 1.7820e-01, time/batch = 15.2858s	
19773/22300 (epoch 44.334), train_loss = 0.27738353, grad/param norm = 2.4557e-01, time/batch = 15.8175s	
19774/22300 (epoch 44.336), train_loss = 0.27454590, grad/param norm = 2.2750e-01, time/batch = 16.2047s	
19775/22300 (epoch 44.339), train_loss = 0.35157925, grad/param norm = 3.2103e-01, time/batch = 15.2279s	
19776/22300 (epoch 44.341), train_loss = 0.33539531, grad/param norm = 2.5457e-01, time/batch = 17.2156s	
19777/22300 (epoch 44.343), train_loss = 0.38055132, grad/param norm = 2.7207e-01, time/batch = 15.4620s	
19778/22300 (epoch 44.345), train_loss = 0.32549859, grad/param norm = 2.7947e-01, time/batch = 16.4767s	
19779/22300 (epoch 44.348), train_loss = 0.31656755, grad/param norm = 1.9834e-01, time/batch = 15.1616s	
19780/22300 (epoch 44.350), train_loss = 0.21601920, grad/param norm = 2.1432e-01, time/batch = 17.0669s	
19781/22300 (epoch 44.352), train_loss = 0.32073265, grad/param norm = 2.3982e-01, time/batch = 15.2082s	
19782/22300 (epoch 44.354), train_loss = 0.45462403, grad/param norm = 3.7040e-01, time/batch = 17.9672s	
19783/22300 (epoch 44.357), train_loss = 0.41375984, grad/param norm = 2.2079e-01, time/batch = 15.7914s	
19784/22300 (epoch 44.359), train_loss = 0.25374480, grad/param norm = 2.0934e-01, time/batch = 17.4617s	
19785/22300 (epoch 44.361), train_loss = 0.28334248, grad/param norm = 2.4369e-01, time/batch = 15.8025s	
19786/22300 (epoch 44.363), train_loss = 0.36876578, grad/param norm = 2.5925e-01, time/batch = 16.4695s	
19787/22300 (epoch 44.365), train_loss = 0.24939548, grad/param norm = 2.1893e-01, time/batch = 15.7403s	
19788/22300 (epoch 44.368), train_loss = 0.27025625, grad/param norm = 2.6102e-01, time/batch = 15.4641s	
19789/22300 (epoch 44.370), train_loss = 0.28605560, grad/param norm = 2.3754e-01, time/batch = 16.9035s	
19790/22300 (epoch 44.372), train_loss = 0.18858998, grad/param norm = 1.8332e-01, time/batch = 15.6456s	
19791/22300 (epoch 44.374), train_loss = 0.21179519, grad/param norm = 1.5738e-01, time/batch = 16.7981s	
19792/22300 (epoch 44.377), train_loss = 0.30834094, grad/param norm = 3.0669e-01, time/batch = 15.5258s	
19793/22300 (epoch 44.379), train_loss = 0.26212969, grad/param norm = 2.2195e-01, time/batch = 17.1441s	
19794/22300 (epoch 44.381), train_loss = 0.35871363, grad/param norm = 2.6581e-01, time/batch = 15.1295s	
19795/22300 (epoch 44.383), train_loss = 0.26186717, grad/param norm = 2.3076e-01, time/batch = 18.8372s	
19796/22300 (epoch 44.386), train_loss = 0.33103437, grad/param norm = 2.2875e-01, time/batch = 26.7052s	
19797/22300 (epoch 44.388), train_loss = 0.21309257, grad/param norm = 1.9434e-01, time/batch = 15.1787s	
19798/22300 (epoch 44.390), train_loss = 0.24387410, grad/param norm = 2.2260e-01, time/batch = 15.5095s	
19799/22300 (epoch 44.392), train_loss = 0.28018211, grad/param norm = 2.6198e-01, time/batch = 15.0436s	
19800/22300 (epoch 44.395), train_loss = 0.23605805, grad/param norm = 1.7765e-01, time/batch = 15.4599s	
19801/22300 (epoch 44.397), train_loss = 0.17039923, grad/param norm = 1.7387e-01, time/batch = 15.8130s	
19802/22300 (epoch 44.399), train_loss = 0.22670036, grad/param norm = 1.7342e-01, time/batch = 15.7094s	
19803/22300 (epoch 44.401), train_loss = 0.25526215, grad/param norm = 1.9896e-01, time/batch = 15.4017s	
19804/22300 (epoch 44.404), train_loss = 0.27666976, grad/param norm = 2.0154e-01, time/batch = 15.2556s	
19805/22300 (epoch 44.406), train_loss = 0.41268653, grad/param norm = 2.4688e-01, time/batch = 15.7124s	
19806/22300 (epoch 44.408), train_loss = 0.30838587, grad/param norm = 1.9485e-01, time/batch = 15.6313s	
19807/22300 (epoch 44.410), train_loss = 0.35700451, grad/param norm = 1.9384e-01, time/batch = 15.8108s	
19808/22300 (epoch 44.413), train_loss = 0.27389435, grad/param norm = 2.0984e-01, time/batch = 15.3992s	
19809/22300 (epoch 44.415), train_loss = 0.18914458, grad/param norm = 1.8951e-01, time/batch = 15.4741s	
19810/22300 (epoch 44.417), train_loss = 0.31564630, grad/param norm = 2.4887e-01, time/batch = 15.7061s	
19811/22300 (epoch 44.419), train_loss = 0.28144379, grad/param norm = 1.7897e-01, time/batch = 15.9627s	
19812/22300 (epoch 44.422), train_loss = 0.23329858, grad/param norm = 1.8764e-01, time/batch = 15.4786s	
19813/22300 (epoch 44.424), train_loss = 0.28843377, grad/param norm = 2.0075e-01, time/batch = 15.6202s	
19814/22300 (epoch 44.426), train_loss = 0.21334080, grad/param norm = 1.9300e-01, time/batch = 15.8796s	
19815/22300 (epoch 44.428), train_loss = 0.23153070, grad/param norm = 1.8827e-01, time/batch = 15.6309s	
19816/22300 (epoch 44.430), train_loss = 0.24763242, grad/param norm = 1.5922e-01, time/batch = 15.6195s	
19817/22300 (epoch 44.433), train_loss = 0.27499596, grad/param norm = 1.7363e-01, time/batch = 15.7811s	
19818/22300 (epoch 44.435), train_loss = 0.24939917, grad/param norm = 1.9943e-01, time/batch = 15.4752s	
19819/22300 (epoch 44.437), train_loss = 0.30996482, grad/param norm = 2.5271e-01, time/batch = 15.5607s	
19820/22300 (epoch 44.439), train_loss = 0.34152821, grad/param norm = 2.2129e-01, time/batch = 15.6569s	
19821/22300 (epoch 44.442), train_loss = 0.27087347, grad/param norm = 1.9490e-01, time/batch = 15.5697s	
19822/22300 (epoch 44.444), train_loss = 0.24620691, grad/param norm = 2.1987e-01, time/batch = 15.7310s	
19823/22300 (epoch 44.446), train_loss = 0.27409213, grad/param norm = 1.8771e-01, time/batch = 15.5392s	
19824/22300 (epoch 44.448), train_loss = 0.20856751, grad/param norm = 1.4481e-01, time/batch = 15.4912s	
19825/22300 (epoch 44.451), train_loss = 0.32438986, grad/param norm = 2.1342e-01, time/batch = 15.1938s	
19826/22300 (epoch 44.453), train_loss = 0.24863612, grad/param norm = 1.6646e-01, time/batch = 15.5596s	
19827/22300 (epoch 44.455), train_loss = 0.35588962, grad/param norm = 2.5861e-01, time/batch = 15.6681s	
19828/22300 (epoch 44.457), train_loss = 0.46138873, grad/param norm = 2.8734e-01, time/batch = 15.9724s	
19829/22300 (epoch 44.460), train_loss = 0.38906232, grad/param norm = 2.5113e-01, time/batch = 16.0710s	
19830/22300 (epoch 44.462), train_loss = 0.37657230, grad/param norm = 2.1994e-01, time/batch = 15.8280s	
19831/22300 (epoch 44.464), train_loss = 0.33945908, grad/param norm = 2.7419e-01, time/batch = 15.8597s	
19832/22300 (epoch 44.466), train_loss = 0.26975931, grad/param norm = 1.6594e-01, time/batch = 15.9103s	
19833/22300 (epoch 44.469), train_loss = 0.27114862, grad/param norm = 1.6925e-01, time/batch = 15.8637s	
19834/22300 (epoch 44.471), train_loss = 0.38288638, grad/param norm = 2.1063e-01, time/batch = 15.7996s	
19835/22300 (epoch 44.473), train_loss = 0.31387563, grad/param norm = 2.1425e-01, time/batch = 15.7706s	
19836/22300 (epoch 44.475), train_loss = 0.26747135, grad/param norm = 2.2850e-01, time/batch = 15.8256s	
19837/22300 (epoch 44.478), train_loss = 0.28808817, grad/param norm = 2.8287e-01, time/batch = 15.3887s	
19838/22300 (epoch 44.480), train_loss = 0.20282571, grad/param norm = 1.6546e-01, time/batch = 15.3942s	
19839/22300 (epoch 44.482), train_loss = 0.23650583, grad/param norm = 1.5307e-01, time/batch = 15.3019s	
19840/22300 (epoch 44.484), train_loss = 0.30460262, grad/param norm = 2.0948e-01, time/batch = 14.9794s	
19841/22300 (epoch 44.487), train_loss = 0.38007080, grad/param norm = 2.2572e-01, time/batch = 15.3879s	
19842/22300 (epoch 44.489), train_loss = 0.33898234, grad/param norm = 2.1220e-01, time/batch = 14.9745s	
19843/22300 (epoch 44.491), train_loss = 0.38488752, grad/param norm = 2.5719e-01, time/batch = 15.1497s	
19844/22300 (epoch 44.493), train_loss = 0.27922179, grad/param norm = 3.2859e-01, time/batch = 15.4579s	
19845/22300 (epoch 44.496), train_loss = 0.32461372, grad/param norm = 2.1736e-01, time/batch = 15.3658s	
19846/22300 (epoch 44.498), train_loss = 0.20310145, grad/param norm = 1.5186e-01, time/batch = 15.5634s	
19847/22300 (epoch 44.500), train_loss = 0.29207090, grad/param norm = 1.9673e-01, time/batch = 15.3836s	
19848/22300 (epoch 44.502), train_loss = 0.18470667, grad/param norm = 1.7928e-01, time/batch = 14.9688s	
19849/22300 (epoch 44.504), train_loss = 0.21371542, grad/param norm = 1.9172e-01, time/batch = 14.9759s	
19850/22300 (epoch 44.507), train_loss = 0.24004002, grad/param norm = 2.0876e-01, time/batch = 15.1451s	
19851/22300 (epoch 44.509), train_loss = 0.34469854, grad/param norm = 2.3712e-01, time/batch = 15.6351s	
19852/22300 (epoch 44.511), train_loss = 0.19738805, grad/param norm = 1.5893e-01, time/batch = 15.7002s	
19853/22300 (epoch 44.513), train_loss = 0.21762188, grad/param norm = 1.6060e-01, time/batch = 15.6965s	
19854/22300 (epoch 44.516), train_loss = 0.25686777, grad/param norm = 1.7878e-01, time/batch = 15.4574s	
19855/22300 (epoch 44.518), train_loss = 0.32281292, grad/param norm = 3.0830e-01, time/batch = 15.4903s	
19856/22300 (epoch 44.520), train_loss = 0.25306497, grad/param norm = 2.3416e-01, time/batch = 15.3717s	
19857/22300 (epoch 44.522), train_loss = 0.29784735, grad/param norm = 2.1570e-01, time/batch = 15.3871s	
19858/22300 (epoch 44.525), train_loss = 0.22501796, grad/param norm = 1.9887e-01, time/batch = 15.4703s	
19859/22300 (epoch 44.527), train_loss = 0.36983284, grad/param norm = 3.0310e-01, time/batch = 15.6076s	
19860/22300 (epoch 44.529), train_loss = 0.29829365, grad/param norm = 2.1672e-01, time/batch = 15.6337s	
19861/22300 (epoch 44.531), train_loss = 0.26044855, grad/param norm = 2.0500e-01, time/batch = 15.4464s	
19862/22300 (epoch 44.534), train_loss = 0.31611215, grad/param norm = 2.8271e-01, time/batch = 15.5595s	
19863/22300 (epoch 44.536), train_loss = 0.41565751, grad/param norm = 2.2333e-01, time/batch = 15.3306s	
19864/22300 (epoch 44.538), train_loss = 0.52712262, grad/param norm = 3.4058e-01, time/batch = 15.7618s	
19865/22300 (epoch 44.540), train_loss = 0.29574635, grad/param norm = 2.3524e-01, time/batch = 15.7622s	
19866/22300 (epoch 44.543), train_loss = 0.32250403, grad/param norm = 2.4281e-01, time/batch = 15.6955s	
19867/22300 (epoch 44.545), train_loss = 0.20766769, grad/param norm = 2.1284e-01, time/batch = 15.2890s	
19868/22300 (epoch 44.547), train_loss = 0.17975178, grad/param norm = 1.4988e-01, time/batch = 15.7685s	
19869/22300 (epoch 44.549), train_loss = 0.20416679, grad/param norm = 1.9074e-01, time/batch = 15.6909s	
19870/22300 (epoch 44.552), train_loss = 0.22498994, grad/param norm = 1.9760e-01, time/batch = 15.5731s	
19871/22300 (epoch 44.554), train_loss = 0.32801810, grad/param norm = 2.6417e-01, time/batch = 15.8369s	
19872/22300 (epoch 44.556), train_loss = 0.42249467, grad/param norm = 3.3571e-01, time/batch = 15.6039s	
19873/22300 (epoch 44.558), train_loss = 0.32050745, grad/param norm = 2.7826e-01, time/batch = 15.6514s	
19874/22300 (epoch 44.561), train_loss = 0.45848831, grad/param norm = 2.9917e-01, time/batch = 15.7706s	
19875/22300 (epoch 44.563), train_loss = 0.36706870, grad/param norm = 3.0362e-01, time/batch = 15.6106s	
19876/22300 (epoch 44.565), train_loss = 0.28959134, grad/param norm = 2.9735e-01, time/batch = 15.6245s	
19877/22300 (epoch 44.567), train_loss = 0.27353050, grad/param norm = 2.2366e-01, time/batch = 15.3966s	
19878/22300 (epoch 44.570), train_loss = 0.39883680, grad/param norm = 3.0779e-01, time/batch = 17.9468s	
19879/22300 (epoch 44.572), train_loss = 0.40746687, grad/param norm = 2.7438e-01, time/batch = 16.0142s	
19880/22300 (epoch 44.574), train_loss = 0.29956325, grad/param norm = 2.3167e-01, time/batch = 16.1414s	
19881/22300 (epoch 44.576), train_loss = 0.26897606, grad/param norm = 2.0457e-01, time/batch = 15.5998s	
19882/22300 (epoch 44.578), train_loss = 0.16114999, grad/param norm = 1.5352e-01, time/batch = 15.9958s	
19883/22300 (epoch 44.581), train_loss = 0.23632637, grad/param norm = 2.5491e-01, time/batch = 16.1763s	
19884/22300 (epoch 44.583), train_loss = 0.27692105, grad/param norm = 2.0339e-01, time/batch = 16.2274s	
19885/22300 (epoch 44.585), train_loss = 0.35875862, grad/param norm = 2.8351e-01, time/batch = 15.8505s	
19886/22300 (epoch 44.587), train_loss = 0.54005285, grad/param norm = 3.2084e-01, time/batch = 16.4518s	
19887/22300 (epoch 44.590), train_loss = 0.42543329, grad/param norm = 3.0737e-01, time/batch = 16.3776s	
19888/22300 (epoch 44.592), train_loss = 0.50783209, grad/param norm = 3.3002e-01, time/batch = 16.2976s	
19889/22300 (epoch 44.594), train_loss = 0.49476548, grad/param norm = 4.1193e-01, time/batch = 16.2084s	
19890/22300 (epoch 44.596), train_loss = 0.31094295, grad/param norm = 2.1840e-01, time/batch = 16.1134s	
19891/22300 (epoch 44.599), train_loss = 0.21459399, grad/param norm = 2.4939e-01, time/batch = 16.3870s	
19892/22300 (epoch 44.601), train_loss = 0.25567928, grad/param norm = 2.1441e-01, time/batch = 16.1059s	
19893/22300 (epoch 44.603), train_loss = 0.26689423, grad/param norm = 2.2585e-01, time/batch = 16.1787s	
19894/22300 (epoch 44.605), train_loss = 0.28570363, grad/param norm = 2.1122e-01, time/batch = 16.2842s	
19895/22300 (epoch 44.608), train_loss = 0.46174115, grad/param norm = 2.6681e-01, time/batch = 16.3016s	
19896/22300 (epoch 44.610), train_loss = 0.55257001, grad/param norm = 3.2060e-01, time/batch = 16.2011s	
19897/22300 (epoch 44.612), train_loss = 0.39199852, grad/param norm = 2.8703e-01, time/batch = 16.3043s	
19898/22300 (epoch 44.614), train_loss = 0.39117350, grad/param norm = 6.0005e-01, time/batch = 15.9948s	
19899/22300 (epoch 44.617), train_loss = 0.40217187, grad/param norm = 2.8053e-01, time/batch = 15.9548s	
19900/22300 (epoch 44.619), train_loss = 0.40533404, grad/param norm = 2.8250e-01, time/batch = 16.2253s	
19901/22300 (epoch 44.621), train_loss = 0.27354438, grad/param norm = 2.2860e-01, time/batch = 16.2610s	
19902/22300 (epoch 44.623), train_loss = 0.28602778, grad/param norm = 2.1547e-01, time/batch = 16.2907s	
19903/22300 (epoch 44.626), train_loss = 0.29019538, grad/param norm = 2.7337e-01, time/batch = 16.2651s	
19904/22300 (epoch 44.628), train_loss = 0.28556488, grad/param norm = 1.8499e-01, time/batch = 16.2548s	
19905/22300 (epoch 44.630), train_loss = 0.32812595, grad/param norm = 2.9753e-01, time/batch = 16.1743s	
19906/22300 (epoch 44.632), train_loss = 0.27262699, grad/param norm = 2.4151e-01, time/batch = 16.0293s	
19907/22300 (epoch 44.635), train_loss = 0.33019509, grad/param norm = 2.4586e-01, time/batch = 16.2806s	
19908/22300 (epoch 44.637), train_loss = 0.35399133, grad/param norm = 2.3547e-01, time/batch = 16.1960s	
19909/22300 (epoch 44.639), train_loss = 0.44586950, grad/param norm = 3.2522e-01, time/batch = 16.3988s	
19910/22300 (epoch 44.641), train_loss = 0.36893945, grad/param norm = 3.3516e-01, time/batch = 16.2818s	
19911/22300 (epoch 44.643), train_loss = 0.28352901, grad/param norm = 2.7175e-01, time/batch = 16.0605s	
19912/22300 (epoch 44.646), train_loss = 0.29098784, grad/param norm = 2.6813e-01, time/batch = 16.0077s	
19913/22300 (epoch 44.648), train_loss = 0.36998190, grad/param norm = 1.9207e-01, time/batch = 15.9565s	
19914/22300 (epoch 44.650), train_loss = 0.36255616, grad/param norm = 2.9018e-01, time/batch = 15.8002s	
19915/22300 (epoch 44.652), train_loss = 0.29550023, grad/param norm = 2.2783e-01, time/batch = 15.7753s	
19916/22300 (epoch 44.655), train_loss = 0.24271083, grad/param norm = 2.1353e-01, time/batch = 16.0227s	
19917/22300 (epoch 44.657), train_loss = 0.27922105, grad/param norm = 2.2884e-01, time/batch = 16.1164s	
19918/22300 (epoch 44.659), train_loss = 0.27811292, grad/param norm = 2.4243e-01, time/batch = 15.7887s	
19919/22300 (epoch 44.661), train_loss = 0.22759583, grad/param norm = 1.9169e-01, time/batch = 15.6171s	
19920/22300 (epoch 44.664), train_loss = 0.27750059, grad/param norm = 2.5146e-01, time/batch = 15.8833s	
19921/22300 (epoch 44.666), train_loss = 0.36702412, grad/param norm = 2.6692e-01, time/batch = 15.7194s	
19922/22300 (epoch 44.668), train_loss = 0.27986549, grad/param norm = 2.3280e-01, time/batch = 15.7079s	
19923/22300 (epoch 44.670), train_loss = 0.33528987, grad/param norm = 2.7024e-01, time/batch = 15.4650s	
19924/22300 (epoch 44.673), train_loss = 0.40246400, grad/param norm = 2.8636e-01, time/batch = 15.2452s	
19925/22300 (epoch 44.675), train_loss = 0.42296974, grad/param norm = 3.1367e-01, time/batch = 15.7038s	
19926/22300 (epoch 44.677), train_loss = 0.47163771, grad/param norm = 2.9581e-01, time/batch = 15.9059s	
19927/22300 (epoch 44.679), train_loss = 0.32465987, grad/param norm = 2.9198e-01, time/batch = 16.0972s	
19928/22300 (epoch 44.682), train_loss = 0.30679331, grad/param norm = 2.0407e-01, time/batch = 16.0009s	
19929/22300 (epoch 44.684), train_loss = 0.31869265, grad/param norm = 2.5416e-01, time/batch = 15.8650s	
19930/22300 (epoch 44.686), train_loss = 0.27860571, grad/param norm = 2.3397e-01, time/batch = 16.0047s	
19931/22300 (epoch 44.688), train_loss = 0.25364616, grad/param norm = 2.1798e-01, time/batch = 15.8607s	
19932/22300 (epoch 44.691), train_loss = 0.24367178, grad/param norm = 2.3106e-01, time/batch = 15.8069s	
19933/22300 (epoch 44.693), train_loss = 0.25787172, grad/param norm = 2.5831e-01, time/batch = 15.7175s	
19934/22300 (epoch 44.695), train_loss = 0.27473925, grad/param norm = 2.5344e-01, time/batch = 15.8945s	
19935/22300 (epoch 44.697), train_loss = 0.29006420, grad/param norm = 2.0048e-01, time/batch = 15.6947s	
19936/22300 (epoch 44.700), train_loss = 0.25198763, grad/param norm = 2.1139e-01, time/batch = 15.8246s	
19937/22300 (epoch 44.702), train_loss = 0.20372272, grad/param norm = 1.9551e-01, time/batch = 15.9662s	
19938/22300 (epoch 44.704), train_loss = 0.27220164, grad/param norm = 2.3942e-01, time/batch = 15.8759s	
19939/22300 (epoch 44.706), train_loss = 0.25511984, grad/param norm = 2.0126e-01, time/batch = 15.9268s	
19940/22300 (epoch 44.709), train_loss = 0.19377931, grad/param norm = 1.5967e-01, time/batch = 15.9694s	
19941/22300 (epoch 44.711), train_loss = 0.19824344, grad/param norm = 1.2457e-01, time/batch = 16.0289s	
19942/22300 (epoch 44.713), train_loss = 0.31637549, grad/param norm = 2.6473e-01, time/batch = 15.7142s	
19943/22300 (epoch 44.715), train_loss = 0.32290062, grad/param norm = 2.2015e-01, time/batch = 15.7081s	
19944/22300 (epoch 44.717), train_loss = 0.42088322, grad/param norm = 2.4445e-01, time/batch = 15.6736s	
19945/22300 (epoch 44.720), train_loss = 0.25425442, grad/param norm = 2.5501e-01, time/batch = 15.7862s	
19946/22300 (epoch 44.722), train_loss = 0.30829108, grad/param norm = 2.3008e-01, time/batch = 15.9123s	
19947/22300 (epoch 44.724), train_loss = 0.34201133, grad/param norm = 3.2673e-01, time/batch = 15.7699s	
19948/22300 (epoch 44.726), train_loss = 0.25946954, grad/param norm = 1.9738e-01, time/batch = 15.8598s	
19949/22300 (epoch 44.729), train_loss = 0.31452977, grad/param norm = 1.9737e-01, time/batch = 15.8892s	
19950/22300 (epoch 44.731), train_loss = 0.37253406, grad/param norm = 2.9678e-01, time/batch = 15.8616s	
19951/22300 (epoch 44.733), train_loss = 0.39692094, grad/param norm = 3.3352e-01, time/batch = 15.8886s	
19952/22300 (epoch 44.735), train_loss = 0.39552639, grad/param norm = 2.5657e-01, time/batch = 15.7285s	
19953/22300 (epoch 44.738), train_loss = 0.29213966, grad/param norm = 2.7459e-01, time/batch = 15.9585s	
19954/22300 (epoch 44.740), train_loss = 0.27315682, grad/param norm = 1.7691e-01, time/batch = 16.0507s	
19955/22300 (epoch 44.742), train_loss = 0.24445120, grad/param norm = 1.8423e-01, time/batch = 15.9521s	
19956/22300 (epoch 44.744), train_loss = 0.44928315, grad/param norm = 3.0891e-01, time/batch = 15.5631s	
19957/22300 (epoch 44.747), train_loss = 0.37218416, grad/param norm = 2.7449e-01, time/batch = 15.7759s	
19958/22300 (epoch 44.749), train_loss = 0.47449364, grad/param norm = 3.8152e-01, time/batch = 15.8733s	
19959/22300 (epoch 44.751), train_loss = 0.36334598, grad/param norm = 3.0560e-01, time/batch = 15.6370s	
19960/22300 (epoch 44.753), train_loss = 0.41570199, grad/param norm = 3.2747e-01, time/batch = 15.7111s	
19961/22300 (epoch 44.756), train_loss = 0.40914366, grad/param norm = 2.2825e-01, time/batch = 16.0504s	
19962/22300 (epoch 44.758), train_loss = 0.32495129, grad/param norm = 2.1620e-01, time/batch = 15.7246s	
19963/22300 (epoch 44.760), train_loss = 0.37910544, grad/param norm = 2.9664e-01, time/batch = 15.7198s	
19964/22300 (epoch 44.762), train_loss = 0.33297051, grad/param norm = 2.6380e-01, time/batch = 15.1562s	
19965/22300 (epoch 44.765), train_loss = 0.34858280, grad/param norm = 2.8215e-01, time/batch = 15.5020s	
19966/22300 (epoch 44.767), train_loss = 0.33549133, grad/param norm = 2.6545e-01, time/batch = 15.4303s	
19967/22300 (epoch 44.769), train_loss = 0.31335614, grad/param norm = 2.7498e-01, time/batch = 15.1282s	
19968/22300 (epoch 44.771), train_loss = 0.37515488, grad/param norm = 3.5261e-01, time/batch = 14.3164s	
19969/22300 (epoch 44.774), train_loss = 0.42964613, grad/param norm = 3.7420e-01, time/batch = 14.6488s	
19970/22300 (epoch 44.776), train_loss = 0.44407544, grad/param norm = 2.5980e-01, time/batch = 14.4965s	
19971/22300 (epoch 44.778), train_loss = 0.45839311, grad/param norm = 3.5451e-01, time/batch = 14.3315s	
19972/22300 (epoch 44.780), train_loss = 0.45483084, grad/param norm = 3.7527e-01, time/batch = 14.1745s	
19973/22300 (epoch 44.783), train_loss = 0.48041196, grad/param norm = 4.1233e-01, time/batch = 14.8910s	
19974/22300 (epoch 44.785), train_loss = 0.31629796, grad/param norm = 2.7922e-01, time/batch = 14.8150s	
19975/22300 (epoch 44.787), train_loss = 0.33148943, grad/param norm = 3.1418e-01, time/batch = 14.5669s	
19976/22300 (epoch 44.789), train_loss = 0.46566920, grad/param norm = 3.5373e-01, time/batch = 15.1955s	
19977/22300 (epoch 44.791), train_loss = 0.54867166, grad/param norm = 3.3620e-01, time/batch = 15.7621s	
19978/22300 (epoch 44.794), train_loss = 0.45969584, grad/param norm = 3.1991e-01, time/batch = 15.6400s	
19979/22300 (epoch 44.796), train_loss = 0.40883374, grad/param norm = 3.6022e-01, time/batch = 15.5772s	
19980/22300 (epoch 44.798), train_loss = 0.54887939, grad/param norm = 3.0818e-01, time/batch = 15.9511s	
19981/22300 (epoch 44.800), train_loss = 0.36740815, grad/param norm = 2.7010e-01, time/batch = 15.7890s	
19982/22300 (epoch 44.803), train_loss = 0.32168106, grad/param norm = 2.5916e-01, time/batch = 15.4841s	
19983/22300 (epoch 44.805), train_loss = 0.36191412, grad/param norm = 2.7066e-01, time/batch = 15.6493s	
19984/22300 (epoch 44.807), train_loss = 0.48704918, grad/param norm = 3.7609e-01, time/batch = 15.8697s	
19985/22300 (epoch 44.809), train_loss = 0.35075735, grad/param norm = 2.8543e-01, time/batch = 15.8583s	
19986/22300 (epoch 44.812), train_loss = 0.37702277, grad/param norm = 2.7132e-01, time/batch = 15.6319s	
19987/22300 (epoch 44.814), train_loss = 0.37037272, grad/param norm = 3.9620e-01, time/batch = 15.6176s	
19988/22300 (epoch 44.816), train_loss = 0.39935131, grad/param norm = 2.9267e-01, time/batch = 15.8575s	
19989/22300 (epoch 44.818), train_loss = 0.44765527, grad/param norm = 3.1021e-01, time/batch = 15.5592s	
19990/22300 (epoch 44.821), train_loss = 0.37850816, grad/param norm = 2.8808e-01, time/batch = 15.5787s	
19991/22300 (epoch 44.823), train_loss = 0.24178628, grad/param norm = 1.9162e-01, time/batch = 15.8303s	
19992/22300 (epoch 44.825), train_loss = 0.25966645, grad/param norm = 2.3290e-01, time/batch = 15.7177s	
19993/22300 (epoch 44.827), train_loss = 0.29610354, grad/param norm = 2.3531e-01, time/batch = 15.6446s	
19994/22300 (epoch 44.830), train_loss = 0.30763327, grad/param norm = 3.6229e-01, time/batch = 15.7409s	
19995/22300 (epoch 44.832), train_loss = 0.30986110, grad/param norm = 2.6032e-01, time/batch = 15.5703s	
19996/22300 (epoch 44.834), train_loss = 0.23841657, grad/param norm = 1.7455e-01, time/batch = 15.8766s	
19997/22300 (epoch 44.836), train_loss = 0.31482352, grad/param norm = 2.3772e-01, time/batch = 15.8119s	
19998/22300 (epoch 44.839), train_loss = 0.33269619, grad/param norm = 2.3612e-01, time/batch = 15.6931s	
19999/22300 (epoch 44.841), train_loss = 0.28030585, grad/param norm = 2.4857e-01, time/batch = 15.6221s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch44.84_1.7212.t7	
20000/22300 (epoch 44.843), train_loss = 0.31479013, grad/param norm = 2.4682e-01, time/batch = 15.6400s	
20001/22300 (epoch 44.845), train_loss = 1.37521264, grad/param norm = 5.3158e-01, time/batch = 15.9434s	
20002/22300 (epoch 44.848), train_loss = 0.30179923, grad/param norm = 2.3167e-01, time/batch = 15.8421s	
20003/22300 (epoch 44.850), train_loss = 0.34786083, grad/param norm = 2.7098e-01, time/batch = 15.8616s	
20004/22300 (epoch 44.852), train_loss = 0.32069584, grad/param norm = 3.3472e-01, time/batch = 15.9771s	
20005/22300 (epoch 44.854), train_loss = 0.51069827, grad/param norm = 3.7104e-01, time/batch = 15.9559s	
20006/22300 (epoch 44.857), train_loss = 0.37910364, grad/param norm = 3.0616e-01, time/batch = 15.7053s	
20007/22300 (epoch 44.859), train_loss = 0.29470691, grad/param norm = 2.1669e-01, time/batch = 15.6196s	
20008/22300 (epoch 44.861), train_loss = 0.40240530, grad/param norm = 3.0004e-01, time/batch = 15.6431s	
20009/22300 (epoch 44.863), train_loss = 0.24721771, grad/param norm = 2.7349e-01, time/batch = 16.1020s	
20010/22300 (epoch 44.865), train_loss = 0.28677525, grad/param norm = 2.8241e-01, time/batch = 15.6747s	
20011/22300 (epoch 44.868), train_loss = 0.36285243, grad/param norm = 2.2400e-01, time/batch = 15.9403s	
20012/22300 (epoch 44.870), train_loss = 0.35449464, grad/param norm = 2.6441e-01, time/batch = 15.8772s	
20013/22300 (epoch 44.872), train_loss = 0.46266828, grad/param norm = 3.0334e-01, time/batch = 16.0503s	
20014/22300 (epoch 44.874), train_loss = 0.36803787, grad/param norm = 2.6585e-01, time/batch = 15.8802s	
20015/22300 (epoch 44.877), train_loss = 0.33437662, grad/param norm = 2.1185e-01, time/batch = 15.7170s	
20016/22300 (epoch 44.879), train_loss = 0.32701957, grad/param norm = 2.1123e-01, time/batch = 26.0513s	
20017/22300 (epoch 44.881), train_loss = 0.25991439, grad/param norm = 2.2417e-01, time/batch = 19.4895s	
20018/22300 (epoch 44.883), train_loss = 0.25083783, grad/param norm = 1.6400e-01, time/batch = 15.5591s	
20019/22300 (epoch 44.886), train_loss = 0.23094313, grad/param norm = 2.1743e-01, time/batch = 15.9160s	
20020/22300 (epoch 44.888), train_loss = 0.28454568, grad/param norm = 2.0035e-01, time/batch = 15.7331s	
20021/22300 (epoch 44.890), train_loss = 0.28917658, grad/param norm = 1.8596e-01, time/batch = 15.8070s	
20022/22300 (epoch 44.892), train_loss = 0.44680658, grad/param norm = 2.6972e-01, time/batch = 15.8125s	
20023/22300 (epoch 44.895), train_loss = 0.39353370, grad/param norm = 3.5564e-01, time/batch = 15.9752s	
20024/22300 (epoch 44.897), train_loss = 0.32352256, grad/param norm = 2.8228e-01, time/batch = 15.8895s	
20025/22300 (epoch 44.899), train_loss = 0.32670425, grad/param norm = 2.2676e-01, time/batch = 15.8727s	
20026/22300 (epoch 44.901), train_loss = 0.39525516, grad/param norm = 2.5525e-01, time/batch = 15.8302s	
20027/22300 (epoch 44.904), train_loss = 0.36494089, grad/param norm = 2.5532e-01, time/batch = 16.0841s	
20028/22300 (epoch 44.906), train_loss = 0.36315278, grad/param norm = 2.4064e-01, time/batch = 15.9533s	
20029/22300 (epoch 44.908), train_loss = 0.32110368, grad/param norm = 1.9826e-01, time/batch = 15.8351s	
20030/22300 (epoch 44.910), train_loss = 0.30201674, grad/param norm = 2.3363e-01, time/batch = 15.6077s	
20031/22300 (epoch 44.913), train_loss = 0.35504147, grad/param norm = 2.7564e-01, time/batch = 16.0503s	
20032/22300 (epoch 44.915), train_loss = 0.47798380, grad/param norm = 3.3680e-01, time/batch = 15.5370s	
20033/22300 (epoch 44.917), train_loss = 0.37916974, grad/param norm = 2.4885e-01, time/batch = 15.6299s	
20034/22300 (epoch 44.919), train_loss = 0.35581097, grad/param norm = 2.2685e-01, time/batch = 16.0469s	
20035/22300 (epoch 44.922), train_loss = 0.31791929, grad/param norm = 2.6676e-01, time/batch = 15.8729s	
20036/22300 (epoch 44.924), train_loss = 0.21742658, grad/param norm = 1.7455e-01, time/batch = 15.8821s	
20037/22300 (epoch 44.926), train_loss = 0.28509245, grad/param norm = 1.8467e-01, time/batch = 15.7137s	
20038/22300 (epoch 44.928), train_loss = 0.29821160, grad/param norm = 2.4977e-01, time/batch = 15.8063s	
20039/22300 (epoch 44.930), train_loss = 0.29338069, grad/param norm = 2.4227e-01, time/batch = 15.8904s	
20040/22300 (epoch 44.933), train_loss = 0.35942482, grad/param norm = 2.5227e-01, time/batch = 15.8819s	
20041/22300 (epoch 44.935), train_loss = 0.34373692, grad/param norm = 3.0180e-01, time/batch = 16.1684s	
20042/22300 (epoch 44.937), train_loss = 0.42677352, grad/param norm = 3.3016e-01, time/batch = 16.0323s	
20043/22300 (epoch 44.939), train_loss = 0.38313169, grad/param norm = 2.8538e-01, time/batch = 15.9681s	
20044/22300 (epoch 44.942), train_loss = 0.47094999, grad/param norm = 3.3780e-01, time/batch = 15.6483s	
20045/22300 (epoch 44.944), train_loss = 0.54432238, grad/param norm = 4.5564e-01, time/batch = 15.6873s	
20046/22300 (epoch 44.946), train_loss = 0.38210377, grad/param norm = 2.8828e-01, time/batch = 15.7872s	
20047/22300 (epoch 44.948), train_loss = 0.31567454, grad/param norm = 1.7967e-01, time/batch = 15.8734s	
20048/22300 (epoch 44.951), train_loss = 0.24326580, grad/param norm = 1.7522e-01, time/batch = 15.6631s	
20049/22300 (epoch 44.953), train_loss = 0.26677730, grad/param norm = 2.6658e-01, time/batch = 15.6977s	
20050/22300 (epoch 44.955), train_loss = 0.43855737, grad/param norm = 2.9136e-01, time/batch = 16.0329s	
20051/22300 (epoch 44.957), train_loss = 0.50678568, grad/param norm = 2.9886e-01, time/batch = 16.1400s	
20052/22300 (epoch 44.960), train_loss = 0.45548878, grad/param norm = 2.9511e-01, time/batch = 16.0622s	
20053/22300 (epoch 44.962), train_loss = 0.28260042, grad/param norm = 2.8055e-01, time/batch = 16.0058s	
20054/22300 (epoch 44.964), train_loss = 0.27787551, grad/param norm = 2.1461e-01, time/batch = 15.9828s	
20055/22300 (epoch 44.966), train_loss = 0.30552058, grad/param norm = 2.4130e-01, time/batch = 15.7997s	
20056/22300 (epoch 44.969), train_loss = 0.32749773, grad/param norm = 2.5721e-01, time/batch = 15.9606s	
20057/22300 (epoch 44.971), train_loss = 0.33787730, grad/param norm = 2.3334e-01, time/batch = 15.7480s	
20058/22300 (epoch 44.973), train_loss = 0.29029385, grad/param norm = 2.4010e-01, time/batch = 15.8092s	
20059/22300 (epoch 44.975), train_loss = 0.42012545, grad/param norm = 2.8819e-01, time/batch = 14.8199s	
20060/22300 (epoch 44.978), train_loss = 0.43136289, grad/param norm = 2.7947e-01, time/batch = 16.5340s	
20061/22300 (epoch 44.980), train_loss = 0.50308845, grad/param norm = 2.8303e-01, time/batch = 16.3838s	
20062/22300 (epoch 44.982), train_loss = 0.24534431, grad/param norm = 2.0398e-01, time/batch = 16.4665s	
20063/22300 (epoch 44.984), train_loss = 0.32719273, grad/param norm = 2.1477e-01, time/batch = 16.0578s	
20064/22300 (epoch 44.987), train_loss = 0.34105258, grad/param norm = 2.6619e-01, time/batch = 15.6212s	
20065/22300 (epoch 44.989), train_loss = 0.26495389, grad/param norm = 2.4252e-01, time/batch = 15.5711s	
20066/22300 (epoch 44.991), train_loss = 0.49625434, grad/param norm = 3.1023e-01, time/batch = 15.1169s	
20067/22300 (epoch 44.993), train_loss = 0.66261565, grad/param norm = 3.3712e-01, time/batch = 15.4360s	
20068/22300 (epoch 44.996), train_loss = 0.61103973, grad/param norm = 3.0770e-01, time/batch = 15.6091s	
20069/22300 (epoch 44.998), train_loss = 0.37934426, grad/param norm = 2.5965e-01, time/batch = 16.7978s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
20070/22300 (epoch 45.000), train_loss = 0.29794527, grad/param norm = 2.4102e-01, time/batch = 15.6396s	
20071/22300 (epoch 45.002), train_loss = 0.61157137, grad/param norm = 2.5772e-01, time/batch = 16.4748s	
20072/22300 (epoch 45.004), train_loss = 0.38676882, grad/param norm = 2.2457e-01, time/batch = 15.2954s	
20073/22300 (epoch 45.007), train_loss = 0.42068892, grad/param norm = 2.8190e-01, time/batch = 15.9011s	
20074/22300 (epoch 45.009), train_loss = 0.42002385, grad/param norm = 3.1692e-01, time/batch = 15.4803s	
20075/22300 (epoch 45.011), train_loss = 0.51657959, grad/param norm = 2.9455e-01, time/batch = 15.2328s	
20076/22300 (epoch 45.013), train_loss = 0.40357907, grad/param norm = 2.8043e-01, time/batch = 15.1463s	
20077/22300 (epoch 45.016), train_loss = 0.31099559, grad/param norm = 2.5016e-01, time/batch = 15.6263s	
20078/22300 (epoch 45.018), train_loss = 0.33950494, grad/param norm = 2.5904e-01, time/batch = 14.7832s	
20079/22300 (epoch 45.020), train_loss = 0.31657477, grad/param norm = 2.2319e-01, time/batch = 15.6985s	
20080/22300 (epoch 45.022), train_loss = 0.24499806, grad/param norm = 2.7892e-01, time/batch = 15.0241s	
20081/22300 (epoch 45.025), train_loss = 0.31113138, grad/param norm = 2.3339e-01, time/batch = 14.9925s	
20082/22300 (epoch 45.027), train_loss = 0.28012721, grad/param norm = 1.7656e-01, time/batch = 14.8164s	
20083/22300 (epoch 45.029), train_loss = 0.32528837, grad/param norm = 2.5388e-01, time/batch = 14.8243s	
20084/22300 (epoch 45.031), train_loss = 0.27641874, grad/param norm = 1.9724e-01, time/batch = 15.4901s	
20085/22300 (epoch 45.034), train_loss = 0.29738831, grad/param norm = 2.3807e-01, time/batch = 16.2891s	
20086/22300 (epoch 45.036), train_loss = 0.27973444, grad/param norm = 1.9087e-01, time/batch = 15.5042s	
20087/22300 (epoch 45.038), train_loss = 0.23632162, grad/param norm = 2.0463e-01, time/batch = 15.1222s	
20088/22300 (epoch 45.040), train_loss = 0.29979344, grad/param norm = 2.3815e-01, time/batch = 15.8718s	
20089/22300 (epoch 45.043), train_loss = 0.49940210, grad/param norm = 3.3715e-01, time/batch = 15.4873s	
20090/22300 (epoch 45.045), train_loss = 0.41781152, grad/param norm = 2.5101e-01, time/batch = 17.2277s	
20091/22300 (epoch 45.047), train_loss = 0.44065022, grad/param norm = 2.7842e-01, time/batch = 16.9479s	
20092/22300 (epoch 45.049), train_loss = 0.34007778, grad/param norm = 2.4389e-01, time/batch = 15.2230s	
20093/22300 (epoch 45.052), train_loss = 0.39011575, grad/param norm = 2.7701e-01, time/batch = 15.2997s	
20094/22300 (epoch 45.054), train_loss = 0.38478249, grad/param norm = 2.5589e-01, time/batch = 15.7994s	
20095/22300 (epoch 45.056), train_loss = 0.20169480, grad/param norm = 1.7588e-01, time/batch = 16.8788s	
20096/22300 (epoch 45.058), train_loss = 0.31904624, grad/param norm = 2.3393e-01, time/batch = 17.0298s	
20097/22300 (epoch 45.061), train_loss = 0.27348146, grad/param norm = 2.1003e-01, time/batch = 15.7427s	
20098/22300 (epoch 45.063), train_loss = 0.43185874, grad/param norm = 3.2202e-01, time/batch = 15.3069s	
20099/22300 (epoch 45.065), train_loss = 0.50999448, grad/param norm = 3.5616e-01, time/batch = 15.3657s	
20100/22300 (epoch 45.067), train_loss = 0.27811415, grad/param norm = 2.5152e-01, time/batch = 17.6371s	
20101/22300 (epoch 45.070), train_loss = 0.32895115, grad/param norm = 2.6000e-01, time/batch = 17.2217s	
20102/22300 (epoch 45.072), train_loss = 0.37108873, grad/param norm = 3.4067e-01, time/batch = 15.9558s	
20103/22300 (epoch 45.074), train_loss = 0.36579521, grad/param norm = 2.7627e-01, time/batch = 17.7103s	
20104/22300 (epoch 45.076), train_loss = 0.37411636, grad/param norm = 3.2402e-01, time/batch = 16.1334s	
20105/22300 (epoch 45.078), train_loss = 0.50953521, grad/param norm = 3.8018e-01, time/batch = 16.7887s	
20106/22300 (epoch 45.081), train_loss = 0.46108091, grad/param norm = 3.1413e-01, time/batch = 16.3004s	
20107/22300 (epoch 45.083), train_loss = 0.53327837, grad/param norm = 3.3473e-01, time/batch = 16.8922s	
20108/22300 (epoch 45.085), train_loss = 0.48074841, grad/param norm = 3.4396e-01, time/batch = 17.5594s	
20109/22300 (epoch 45.087), train_loss = 0.38617177, grad/param norm = 2.6595e-01, time/batch = 15.4217s	
20110/22300 (epoch 45.090), train_loss = 0.38668835, grad/param norm = 3.3298e-01, time/batch = 15.5790s	
20111/22300 (epoch 45.092), train_loss = 0.25832219, grad/param norm = 1.8307e-01, time/batch = 16.2913s	
20112/22300 (epoch 45.094), train_loss = 0.26977467, grad/param norm = 2.1360e-01, time/batch = 16.8754s	
20113/22300 (epoch 45.096), train_loss = 0.48729987, grad/param norm = 3.3093e-01, time/batch = 19.0482s	
20114/22300 (epoch 45.099), train_loss = 0.32012005, grad/param norm = 2.5667e-01, time/batch = 17.3701s	
20115/22300 (epoch 45.101), train_loss = 0.42533107, grad/param norm = 2.8193e-01, time/batch = 17.3827s	
20116/22300 (epoch 45.103), train_loss = 0.34312433, grad/param norm = 2.3929e-01, time/batch = 15.4649s	
20117/22300 (epoch 45.105), train_loss = 0.25871474, grad/param norm = 2.8167e-01, time/batch = 15.1581s	
20118/22300 (epoch 45.108), train_loss = 0.39670622, grad/param norm = 2.8417e-01, time/batch = 16.2153s	
20119/22300 (epoch 45.110), train_loss = 0.45349385, grad/param norm = 2.7980e-01, time/batch = 16.9441s	
20120/22300 (epoch 45.112), train_loss = 0.37108386, grad/param norm = 2.4801e-01, time/batch = 16.4564s	
20121/22300 (epoch 45.114), train_loss = 0.41364284, grad/param norm = 2.6373e-01, time/batch = 16.5213s	
20122/22300 (epoch 45.117), train_loss = 0.45129410, grad/param norm = 2.4780e-01, time/batch = 15.2848s	
20123/22300 (epoch 45.119), train_loss = 0.42093736, grad/param norm = 2.9955e-01, time/batch = 17.0529s	
20124/22300 (epoch 45.121), train_loss = 0.49147431, grad/param norm = 3.4561e-01, time/batch = 14.9511s	
20125/22300 (epoch 45.123), train_loss = 0.53177749, grad/param norm = 2.8301e-01, time/batch = 15.6336s	
20126/22300 (epoch 45.126), train_loss = 0.39500106, grad/param norm = 2.4764e-01, time/batch = 15.6474s	
20127/22300 (epoch 45.128), train_loss = 0.37913517, grad/param norm = 3.0499e-01, time/batch = 16.9327s	
20128/22300 (epoch 45.130), train_loss = 0.32799928, grad/param norm = 2.2308e-01, time/batch = 16.6499s	
20129/22300 (epoch 45.132), train_loss = 0.25014470, grad/param norm = 1.7972e-01, time/batch = 16.4022s	
20130/22300 (epoch 45.135), train_loss = 0.25621339, grad/param norm = 2.2028e-01, time/batch = 16.1094s	
20131/22300 (epoch 45.137), train_loss = 0.22077918, grad/param norm = 2.2033e-01, time/batch = 15.8702s	
20132/22300 (epoch 45.139), train_loss = 0.29860488, grad/param norm = 3.1749e-01, time/batch = 17.3082s	
20133/22300 (epoch 45.141), train_loss = 0.42888392, grad/param norm = 2.4550e-01, time/batch = 17.7094s	
20134/22300 (epoch 45.143), train_loss = 0.33327307, grad/param norm = 2.5101e-01, time/batch = 16.3688s	
20135/22300 (epoch 45.146), train_loss = 0.43383025, grad/param norm = 3.2398e-01, time/batch = 17.5247s	
20136/22300 (epoch 45.148), train_loss = 0.30476058, grad/param norm = 2.7851e-01, time/batch = 16.9676s	
20137/22300 (epoch 45.150), train_loss = 0.32125352, grad/param norm = 2.9058e-01, time/batch = 15.5586s	
20138/22300 (epoch 45.152), train_loss = 0.25511045, grad/param norm = 1.9774e-01, time/batch = 15.2269s	
20139/22300 (epoch 45.155), train_loss = 0.29013191, grad/param norm = 2.1059e-01, time/batch = 17.8816s	
20140/22300 (epoch 45.157), train_loss = 0.36966472, grad/param norm = 2.4474e-01, time/batch = 16.2202s	
20141/22300 (epoch 45.159), train_loss = 0.41154879, grad/param norm = 3.9537e-01, time/batch = 17.1291s	
20142/22300 (epoch 45.161), train_loss = 0.38568401, grad/param norm = 2.7079e-01, time/batch = 16.5604s	
20143/22300 (epoch 45.164), train_loss = 0.29436337, grad/param norm = 2.4920e-01, time/batch = 16.7382s	
20144/22300 (epoch 45.166), train_loss = 0.26123481, grad/param norm = 2.4961e-01, time/batch = 16.1429s	
20145/22300 (epoch 45.168), train_loss = 0.24089027, grad/param norm = 2.0333e-01, time/batch = 16.2047s	
20146/22300 (epoch 45.170), train_loss = 0.35351863, grad/param norm = 2.9429e-01, time/batch = 16.7229s	
20147/22300 (epoch 45.173), train_loss = 0.37060161, grad/param norm = 2.6001e-01, time/batch = 16.6360s	
20148/22300 (epoch 45.175), train_loss = 0.34927245, grad/param norm = 2.7394e-01, time/batch = 17.6231s	
20149/22300 (epoch 45.177), train_loss = 0.24471369, grad/param norm = 1.9464e-01, time/batch = 15.6068s	
20150/22300 (epoch 45.179), train_loss = 0.34856733, grad/param norm = 2.5223e-01, time/batch = 15.1190s	
20151/22300 (epoch 45.182), train_loss = 0.47067404, grad/param norm = 3.2021e-01, time/batch = 17.3969s	
20152/22300 (epoch 45.184), train_loss = 0.49259104, grad/param norm = 3.3942e-01, time/batch = 16.8869s	
20153/22300 (epoch 45.186), train_loss = 0.37569743, grad/param norm = 3.0229e-01, time/batch = 15.0468s	
20154/22300 (epoch 45.188), train_loss = 0.54389088, grad/param norm = 3.2397e-01, time/batch = 17.8848s	
20155/22300 (epoch 45.191), train_loss = 0.44452847, grad/param norm = 3.3386e-01, time/batch = 16.4924s	
20156/22300 (epoch 45.193), train_loss = 0.38099152, grad/param norm = 2.5446e-01, time/batch = 15.3916s	
20157/22300 (epoch 45.195), train_loss = 0.32543865, grad/param norm = 2.8279e-01, time/batch = 17.0572s	
20158/22300 (epoch 45.197), train_loss = 0.29808840, grad/param norm = 1.8998e-01, time/batch = 16.1395s	
20159/22300 (epoch 45.200), train_loss = 0.27181926, grad/param norm = 2.2267e-01, time/batch = 17.4605s	
20160/22300 (epoch 45.202), train_loss = 0.28379063, grad/param norm = 2.1307e-01, time/batch = 16.0738s	
20161/22300 (epoch 45.204), train_loss = 0.36392238, grad/param norm = 2.4183e-01, time/batch = 15.5341s	
20162/22300 (epoch 45.206), train_loss = 0.30297021, grad/param norm = 2.4656e-01, time/batch = 16.0773s	
20163/22300 (epoch 45.209), train_loss = 0.31181506, grad/param norm = 2.0800e-01, time/batch = 16.6927s	
20164/22300 (epoch 45.211), train_loss = 0.26969974, grad/param norm = 3.0480e-01, time/batch = 18.1058s	
20165/22300 (epoch 45.213), train_loss = 0.37069525, grad/param norm = 2.3785e-01, time/batch = 15.4845s	
20166/22300 (epoch 45.215), train_loss = 0.46666441, grad/param norm = 4.1314e-01, time/batch = 17.7973s	
20167/22300 (epoch 45.217), train_loss = 0.47311834, grad/param norm = 2.9622e-01, time/batch = 15.1332s	
20168/22300 (epoch 45.220), train_loss = 0.34028227, grad/param norm = 2.4590e-01, time/batch = 18.5444s	
20169/22300 (epoch 45.222), train_loss = 0.30752870, grad/param norm = 2.9780e-01, time/batch = 16.8911s	
20170/22300 (epoch 45.224), train_loss = 0.29978849, grad/param norm = 2.6269e-01, time/batch = 15.3562s	
20171/22300 (epoch 45.226), train_loss = 0.35106901, grad/param norm = 2.8211e-01, time/batch = 16.7153s	
20172/22300 (epoch 45.229), train_loss = 0.28535620, grad/param norm = 2.2845e-01, time/batch = 18.1416s	
20173/22300 (epoch 45.231), train_loss = 0.44983927, grad/param norm = 2.6555e-01, time/batch = 17.1390s	
20174/22300 (epoch 45.233), train_loss = 0.36230380, grad/param norm = 2.5559e-01, time/batch = 16.6938s	
20175/22300 (epoch 45.235), train_loss = 0.27405497, grad/param norm = 1.9003e-01, time/batch = 16.8209s	
20176/22300 (epoch 45.238), train_loss = 0.26863545, grad/param norm = 1.8383e-01, time/batch = 16.2788s	
20177/22300 (epoch 45.240), train_loss = 0.28590968, grad/param norm = 1.9825e-01, time/batch = 16.7153s	
20178/22300 (epoch 45.242), train_loss = 0.25335570, grad/param norm = 2.8759e-01, time/batch = 16.1325s	
20179/22300 (epoch 45.244), train_loss = 0.19236924, grad/param norm = 1.7850e-01, time/batch = 16.9765s	
20180/22300 (epoch 45.247), train_loss = 0.26848885, grad/param norm = 2.2072e-01, time/batch = 17.6349s	
20181/22300 (epoch 45.249), train_loss = 0.17763497, grad/param norm = 1.3534e-01, time/batch = 16.0531s	
20182/22300 (epoch 45.251), train_loss = 0.23732049, grad/param norm = 1.7716e-01, time/batch = 16.7075s	
20183/22300 (epoch 45.253), train_loss = 0.15591517, grad/param norm = 1.8225e-01, time/batch = 16.1496s	
20184/22300 (epoch 45.256), train_loss = 0.23980884, grad/param norm = 2.0161e-01, time/batch = 17.0454s	
20185/22300 (epoch 45.258), train_loss = 0.35659927, grad/param norm = 2.5330e-01, time/batch = 16.0200s	
20186/22300 (epoch 45.260), train_loss = 0.39112670, grad/param norm = 4.2806e-01, time/batch = 15.9894s	
20187/22300 (epoch 45.262), train_loss = 0.27935224, grad/param norm = 2.3028e-01, time/batch = 15.6929s	
20188/22300 (epoch 45.265), train_loss = 0.25398713, grad/param norm = 2.3479e-01, time/batch = 16.7147s	
20189/22300 (epoch 45.267), train_loss = 0.25708065, grad/param norm = 1.8385e-01, time/batch = 16.7942s	
20190/22300 (epoch 45.269), train_loss = 0.34608380, grad/param norm = 2.9311e-01, time/batch = 16.3191s	
20191/22300 (epoch 45.271), train_loss = 0.37344613, grad/param norm = 2.5123e-01, time/batch = 16.9011s	
20192/22300 (epoch 45.274), train_loss = 0.25355910, grad/param norm = 2.7518e-01, time/batch = 16.2116s	
20193/22300 (epoch 45.276), train_loss = 0.22596115, grad/param norm = 1.6265e-01, time/batch = 16.1508s	
20194/22300 (epoch 45.278), train_loss = 0.25717692, grad/param norm = 2.0493e-01, time/batch = 16.2179s	
20195/22300 (epoch 45.280), train_loss = 0.26732165, grad/param norm = 1.8186e-01, time/batch = 15.6948s	
20196/22300 (epoch 45.283), train_loss = 0.22152251, grad/param norm = 1.7075e-01, time/batch = 16.2042s	
20197/22300 (epoch 45.285), train_loss = 0.24199643, grad/param norm = 2.5696e-01, time/batch = 16.3992s	
20198/22300 (epoch 45.287), train_loss = 0.33971627, grad/param norm = 2.2459e-01, time/batch = 16.2028s	
20199/22300 (epoch 45.289), train_loss = 0.31247002, grad/param norm = 2.0649e-01, time/batch = 15.8925s	
20200/22300 (epoch 45.291), train_loss = 0.28693619, grad/param norm = 2.0876e-01, time/batch = 16.8053s	
20201/22300 (epoch 45.294), train_loss = 0.24733119, grad/param norm = 2.6325e-01, time/batch = 16.6469s	
20202/22300 (epoch 45.296), train_loss = 0.27758338, grad/param norm = 2.3661e-01, time/batch = 17.0590s	
20203/22300 (epoch 45.298), train_loss = 0.38279187, grad/param norm = 2.8137e-01, time/batch = 15.3905s	
20204/22300 (epoch 45.300), train_loss = 0.44284842, grad/param norm = 3.1482e-01, time/batch = 16.6411s	
20205/22300 (epoch 45.303), train_loss = 0.31540210, grad/param norm = 2.6357e-01, time/batch = 15.2097s	
20206/22300 (epoch 45.305), train_loss = 0.33555254, grad/param norm = 3.7172e-01, time/batch = 16.2292s	
20207/22300 (epoch 45.307), train_loss = 0.27928531, grad/param norm = 2.2527e-01, time/batch = 15.3989s	
20208/22300 (epoch 45.309), train_loss = 0.25064861, grad/param norm = 2.1741e-01, time/batch = 15.5648s	
20209/22300 (epoch 45.312), train_loss = 0.22487341, grad/param norm = 2.0640e-01, time/batch = 16.0772s	
20210/22300 (epoch 45.314), train_loss = 0.27590089, grad/param norm = 2.5177e-01, time/batch = 16.0594s	
20211/22300 (epoch 45.316), train_loss = 0.25890499, grad/param norm = 2.6359e-01, time/batch = 16.8869s	
20212/22300 (epoch 45.318), train_loss = 0.27521532, grad/param norm = 1.9094e-01, time/batch = 15.9008s	
20213/22300 (epoch 45.321), train_loss = 0.35143219, grad/param norm = 2.1816e-01, time/batch = 15.3944s	
20214/22300 (epoch 45.323), train_loss = 0.25743320, grad/param norm = 1.8114e-01, time/batch = 15.8099s	
20215/22300 (epoch 45.325), train_loss = 0.23114510, grad/param norm = 2.1787e-01, time/batch = 16.4738s	
20216/22300 (epoch 45.327), train_loss = 0.24751501, grad/param norm = 1.6908e-01, time/batch = 15.7861s	
20217/22300 (epoch 45.330), train_loss = 0.24943105, grad/param norm = 2.5490e-01, time/batch = 16.9680s	
20218/22300 (epoch 45.332), train_loss = 0.23816260, grad/param norm = 2.1268e-01, time/batch = 15.6286s	
20219/22300 (epoch 45.334), train_loss = 0.26188404, grad/param norm = 1.8662e-01, time/batch = 17.3991s	
20220/22300 (epoch 45.336), train_loss = 0.26117747, grad/param norm = 2.1247e-01, time/batch = 15.4898s	
20221/22300 (epoch 45.339), train_loss = 0.32860794, grad/param norm = 2.5018e-01, time/batch = 15.7187s	
20222/22300 (epoch 45.341), train_loss = 0.31916693, grad/param norm = 2.0142e-01, time/batch = 16.5356s	
20223/22300 (epoch 45.343), train_loss = 0.34843557, grad/param norm = 2.4769e-01, time/batch = 17.2865s	
20224/22300 (epoch 45.345), train_loss = 0.29310460, grad/param norm = 2.0915e-01, time/batch = 16.0494s	
20225/22300 (epoch 45.348), train_loss = 0.31036411, grad/param norm = 2.1238e-01, time/batch = 15.9615s	
20226/22300 (epoch 45.350), train_loss = 0.20408044, grad/param norm = 1.6228e-01, time/batch = 15.9757s	
20227/22300 (epoch 45.352), train_loss = 0.30629098, grad/param norm = 2.2743e-01, time/batch = 15.5690s	
20228/22300 (epoch 45.354), train_loss = 0.43490080, grad/param norm = 3.1759e-01, time/batch = 16.6571s	
20229/22300 (epoch 45.357), train_loss = 0.41429372, grad/param norm = 2.3688e-01, time/batch = 15.2172s	
20230/22300 (epoch 45.359), train_loss = 0.23581070, grad/param norm = 2.0102e-01, time/batch = 16.6597s	
20231/22300 (epoch 45.361), train_loss = 0.27527628, grad/param norm = 2.6570e-01, time/batch = 15.4611s	
20232/22300 (epoch 45.363), train_loss = 0.33151584, grad/param norm = 2.0370e-01, time/batch = 16.2269s	
20233/22300 (epoch 45.365), train_loss = 0.24717184, grad/param norm = 1.9888e-01, time/batch = 15.3560s	
20234/22300 (epoch 45.368), train_loss = 0.23917612, grad/param norm = 2.1655e-01, time/batch = 17.6399s	
20235/22300 (epoch 45.370), train_loss = 0.27274180, grad/param norm = 1.9065e-01, time/batch = 16.8028s	
20236/22300 (epoch 45.372), train_loss = 0.18678714, grad/param norm = 1.9487e-01, time/batch = 23.1981s	
20237/22300 (epoch 45.374), train_loss = 0.20696707, grad/param norm = 1.5051e-01, time/batch = 22.5784s	
20238/22300 (epoch 45.377), train_loss = 0.29277627, grad/param norm = 2.2654e-01, time/batch = 15.7434s	
20239/22300 (epoch 45.379), train_loss = 0.25186970, grad/param norm = 2.9441e-01, time/batch = 14.8013s	
20240/22300 (epoch 45.381), train_loss = 0.35453680, grad/param norm = 3.3132e-01, time/batch = 16.3965s	
20241/22300 (epoch 45.383), train_loss = 0.25751752, grad/param norm = 2.0591e-01, time/batch = 16.0291s	
20242/22300 (epoch 45.386), train_loss = 0.31440571, grad/param norm = 2.1791e-01, time/batch = 17.5451s	
20243/22300 (epoch 45.388), train_loss = 0.20988755, grad/param norm = 2.1668e-01, time/batch = 15.7188s	
20244/22300 (epoch 45.390), train_loss = 0.23793607, grad/param norm = 2.8753e-01, time/batch = 16.3983s	
20245/22300 (epoch 45.392), train_loss = 0.27395431, grad/param norm = 2.1557e-01, time/batch = 14.5574s	
20246/22300 (epoch 45.395), train_loss = 0.23061004, grad/param norm = 1.7775e-01, time/batch = 16.6314s	
20247/22300 (epoch 45.397), train_loss = 0.16418053, grad/param norm = 1.3661e-01, time/batch = 15.9776s	
20248/22300 (epoch 45.399), train_loss = 0.23824377, grad/param norm = 1.8013e-01, time/batch = 15.6585s	
20249/22300 (epoch 45.401), train_loss = 0.24649247, grad/param norm = 2.1660e-01, time/batch = 15.5554s	
20250/22300 (epoch 45.404), train_loss = 0.28556154, grad/param norm = 2.2182e-01, time/batch = 16.1915s	
20251/22300 (epoch 45.406), train_loss = 0.42924385, grad/param norm = 2.7481e-01, time/batch = 15.4139s	
20252/22300 (epoch 45.408), train_loss = 0.31152310, grad/param norm = 2.1615e-01, time/batch = 15.4010s	
20253/22300 (epoch 45.410), train_loss = 0.34589195, grad/param norm = 2.0154e-01, time/batch = 16.1375s	
20254/22300 (epoch 45.413), train_loss = 0.25852792, grad/param norm = 1.9310e-01, time/batch = 15.7247s	
20255/22300 (epoch 45.415), train_loss = 0.18526360, grad/param norm = 1.8020e-01, time/batch = 15.9695s	
20256/22300 (epoch 45.417), train_loss = 0.30944435, grad/param norm = 2.3578e-01, time/batch = 15.6249s	
20257/22300 (epoch 45.419), train_loss = 0.27682471, grad/param norm = 2.0577e-01, time/batch = 16.1663s	
20258/22300 (epoch 45.422), train_loss = 0.23212374, grad/param norm = 2.3878e-01, time/batch = 15.7970s	
20259/22300 (epoch 45.424), train_loss = 0.29074186, grad/param norm = 2.7046e-01, time/batch = 16.6473s	
20260/22300 (epoch 45.426), train_loss = 0.21484766, grad/param norm = 2.0213e-01, time/batch = 16.3155s	
20261/22300 (epoch 45.428), train_loss = 0.23786492, grad/param norm = 2.3628e-01, time/batch = 16.1328s	
20262/22300 (epoch 45.430), train_loss = 0.25453749, grad/param norm = 2.0506e-01, time/batch = 15.4016s	
20263/22300 (epoch 45.433), train_loss = 0.26948941, grad/param norm = 1.7746e-01, time/batch = 16.0659s	
20264/22300 (epoch 45.435), train_loss = 0.24527559, grad/param norm = 1.9867e-01, time/batch = 15.9677s	
20265/22300 (epoch 45.437), train_loss = 0.29964151, grad/param norm = 2.4152e-01, time/batch = 14.3884s	
20266/22300 (epoch 45.439), train_loss = 0.33678242, grad/param norm = 2.5055e-01, time/batch = 16.9248s	
20267/22300 (epoch 45.442), train_loss = 0.28073695, grad/param norm = 2.0531e-01, time/batch = 15.0403s	
20268/22300 (epoch 45.444), train_loss = 0.23849940, grad/param norm = 1.9341e-01, time/batch = 16.4689s	
20269/22300 (epoch 45.446), train_loss = 0.29252021, grad/param norm = 2.6768e-01, time/batch = 15.9785s	
20270/22300 (epoch 45.448), train_loss = 0.20795467, grad/param norm = 1.5934e-01, time/batch = 16.5666s	
20271/22300 (epoch 45.451), train_loss = 0.33262022, grad/param norm = 2.6901e-01, time/batch = 15.3206s	
20272/22300 (epoch 45.453), train_loss = 0.26203215, grad/param norm = 2.1243e-01, time/batch = 17.9024s	
20273/22300 (epoch 45.455), train_loss = 0.34342625, grad/param norm = 2.5180e-01, time/batch = 15.5659s	
20274/22300 (epoch 45.457), train_loss = 0.45906624, grad/param norm = 3.0405e-01, time/batch = 15.5605s	
20275/22300 (epoch 45.460), train_loss = 0.39678399, grad/param norm = 2.6979e-01, time/batch = 15.8169s	
20276/22300 (epoch 45.462), train_loss = 0.38744777, grad/param norm = 2.6231e-01, time/batch = 16.4571s	
20277/22300 (epoch 45.464), train_loss = 0.33271291, grad/param norm = 2.4386e-01, time/batch = 14.9070s	
20278/22300 (epoch 45.466), train_loss = 0.27268884, grad/param norm = 2.0428e-01, time/batch = 15.9984s	
20279/22300 (epoch 45.469), train_loss = 0.25965169, grad/param norm = 1.7466e-01, time/batch = 16.1563s	
20280/22300 (epoch 45.471), train_loss = 0.37109108, grad/param norm = 2.3702e-01, time/batch = 16.1330s	
20281/22300 (epoch 45.473), train_loss = 0.31441367, grad/param norm = 2.0201e-01, time/batch = 15.6415s	
20282/22300 (epoch 45.475), train_loss = 0.26429572, grad/param norm = 2.2353e-01, time/batch = 15.1355s	
20283/22300 (epoch 45.478), train_loss = 0.28184094, grad/param norm = 2.2238e-01, time/batch = 15.5276s	
20284/22300 (epoch 45.480), train_loss = 0.21895820, grad/param norm = 2.3968e-01, time/batch = 15.5649s	
20285/22300 (epoch 45.482), train_loss = 0.23527291, grad/param norm = 1.6083e-01, time/batch = 16.4719s	
20286/22300 (epoch 45.484), train_loss = 0.29739905, grad/param norm = 2.3927e-01, time/batch = 15.7996s	
20287/22300 (epoch 45.487), train_loss = 0.36268076, grad/param norm = 2.1918e-01, time/batch = 16.7630s	
20288/22300 (epoch 45.489), train_loss = 0.33583991, grad/param norm = 2.2189e-01, time/batch = 15.1332s	
20289/22300 (epoch 45.491), train_loss = 0.37436539, grad/param norm = 2.5958e-01, time/batch = 17.3111s	
20290/22300 (epoch 45.493), train_loss = 0.25745609, grad/param norm = 2.7407e-01, time/batch = 16.2222s	
20291/22300 (epoch 45.496), train_loss = 0.31376239, grad/param norm = 2.1250e-01, time/batch = 16.9625s	
20292/22300 (epoch 45.498), train_loss = 0.19409804, grad/param norm = 1.4687e-01, time/batch = 16.2025s	
20293/22300 (epoch 45.500), train_loss = 0.28333875, grad/param norm = 1.8061e-01, time/batch = 16.2217s	
20294/22300 (epoch 45.502), train_loss = 0.17850072, grad/param norm = 1.4667e-01, time/batch = 15.1587s	
20295/22300 (epoch 45.504), train_loss = 0.20407814, grad/param norm = 1.5302e-01, time/batch = 16.2987s	
20296/22300 (epoch 45.507), train_loss = 0.22680558, grad/param norm = 2.1481e-01, time/batch = 15.1868s	
20297/22300 (epoch 45.509), train_loss = 0.32988411, grad/param norm = 2.0529e-01, time/batch = 15.2800s	
20298/22300 (epoch 45.511), train_loss = 0.18240162, grad/param norm = 1.5635e-01, time/batch = 15.5684s	
20299/22300 (epoch 45.513), train_loss = 0.20688267, grad/param norm = 1.5703e-01, time/batch = 15.6920s	
20300/22300 (epoch 45.516), train_loss = 0.25326404, grad/param norm = 2.2548e-01, time/batch = 15.7165s	
20301/22300 (epoch 45.518), train_loss = 0.30148016, grad/param norm = 3.3925e-01, time/batch = 15.4919s	
20302/22300 (epoch 45.520), train_loss = 0.25193054, grad/param norm = 2.4304e-01, time/batch = 15.0851s	
20303/22300 (epoch 45.522), train_loss = 0.28833709, grad/param norm = 2.2497e-01, time/batch = 15.5365s	
20304/22300 (epoch 45.525), train_loss = 0.23051907, grad/param norm = 2.4013e-01, time/batch = 15.5624s	
20305/22300 (epoch 45.527), train_loss = 0.34119662, grad/param norm = 3.2156e-01, time/batch = 15.6932s	
20306/22300 (epoch 45.529), train_loss = 0.28320298, grad/param norm = 2.3061e-01, time/batch = 16.5348s	
20307/22300 (epoch 45.531), train_loss = 0.25623316, grad/param norm = 2.0224e-01, time/batch = 14.7278s	
20308/22300 (epoch 45.534), train_loss = 0.28641883, grad/param norm = 1.8260e-01, time/batch = 15.7793s	
20309/22300 (epoch 45.536), train_loss = 0.43108315, grad/param norm = 3.1780e-01, time/batch = 16.4715s	
20310/22300 (epoch 45.538), train_loss = 0.51218490, grad/param norm = 3.3431e-01, time/batch = 15.4666s	
20311/22300 (epoch 45.540), train_loss = 0.28166089, grad/param norm = 2.1827e-01, time/batch = 15.6798s	
20312/22300 (epoch 45.543), train_loss = 0.30483077, grad/param norm = 2.2573e-01, time/batch = 15.0483s	
20313/22300 (epoch 45.545), train_loss = 0.20218058, grad/param norm = 1.9332e-01, time/batch = 14.2514s	
20314/22300 (epoch 45.547), train_loss = 0.19211570, grad/param norm = 2.0826e-01, time/batch = 15.3896s	
20315/22300 (epoch 45.549), train_loss = 0.20235537, grad/param norm = 1.8191e-01, time/batch = 15.0385s	
20316/22300 (epoch 45.552), train_loss = 0.23755775, grad/param norm = 2.3155e-01, time/batch = 16.3124s	
20317/22300 (epoch 45.554), train_loss = 0.31673836, grad/param norm = 2.4495e-01, time/batch = 15.5302s	
20318/22300 (epoch 45.556), train_loss = 0.44544933, grad/param norm = 4.1105e-01, time/batch = 16.2901s	
20319/22300 (epoch 45.558), train_loss = 0.30215080, grad/param norm = 2.6661e-01, time/batch = 16.9782s	
20320/22300 (epoch 45.561), train_loss = 0.44644203, grad/param norm = 2.8815e-01, time/batch = 14.5839s	
20321/22300 (epoch 45.563), train_loss = 0.36011290, grad/param norm = 2.9588e-01, time/batch = 16.1528s	
20322/22300 (epoch 45.565), train_loss = 0.27992081, grad/param norm = 1.9801e-01, time/batch = 15.1504s	
20323/22300 (epoch 45.567), train_loss = 0.26575948, grad/param norm = 1.9729e-01, time/batch = 15.5494s	
20324/22300 (epoch 45.570), train_loss = 0.38484675, grad/param norm = 2.7392e-01, time/batch = 16.2024s	
20325/22300 (epoch 45.572), train_loss = 0.39625845, grad/param norm = 2.5349e-01, time/batch = 16.1995s	
20326/22300 (epoch 45.574), train_loss = 0.27949622, grad/param norm = 1.9894e-01, time/batch = 15.4654s	
20327/22300 (epoch 45.576), train_loss = 0.25417451, grad/param norm = 1.5407e-01, time/batch = 15.5657s	
20328/22300 (epoch 45.578), train_loss = 0.14338696, grad/param norm = 1.2713e-01, time/batch = 17.3889s	
20329/22300 (epoch 45.581), train_loss = 0.22411967, grad/param norm = 1.9015e-01, time/batch = 17.0498s	
20330/22300 (epoch 45.583), train_loss = 0.28081238, grad/param norm = 2.2777e-01, time/batch = 15.1418s	
20331/22300 (epoch 45.585), train_loss = 0.35944720, grad/param norm = 3.5084e-01, time/batch = 16.8097s	
20332/22300 (epoch 45.587), train_loss = 0.54599008, grad/param norm = 3.5310e-01, time/batch = 17.7208s	
20333/22300 (epoch 45.590), train_loss = 0.43037539, grad/param norm = 3.1374e-01, time/batch = 15.5537s	
20334/22300 (epoch 45.592), train_loss = 0.49982604, grad/param norm = 2.9370e-01, time/batch = 15.6769s	
20335/22300 (epoch 45.594), train_loss = 0.44637441, grad/param norm = 3.0793e-01, time/batch = 15.6125s	
20336/22300 (epoch 45.596), train_loss = 0.31484402, grad/param norm = 2.4033e-01, time/batch = 15.6111s	
20337/22300 (epoch 45.599), train_loss = 0.20671236, grad/param norm = 2.4224e-01, time/batch = 16.1342s	
20338/22300 (epoch 45.601), train_loss = 0.24183725, grad/param norm = 1.9635e-01, time/batch = 15.9742s	
20339/22300 (epoch 45.603), train_loss = 0.25652024, grad/param norm = 2.1399e-01, time/batch = 15.6491s	
20340/22300 (epoch 45.605), train_loss = 0.28446005, grad/param norm = 2.3170e-01, time/batch = 15.9481s	
20341/22300 (epoch 45.608), train_loss = 0.47016947, grad/param norm = 2.9871e-01, time/batch = 16.1272s	
20342/22300 (epoch 45.610), train_loss = 0.52608128, grad/param norm = 2.5610e-01, time/batch = 15.9674s	
20343/22300 (epoch 45.612), train_loss = 0.36528416, grad/param norm = 3.2105e-01, time/batch = 15.9384s	
20344/22300 (epoch 45.614), train_loss = 0.36122848, grad/param norm = 3.3020e-01, time/batch = 15.9812s	
20345/22300 (epoch 45.617), train_loss = 0.42315842, grad/param norm = 2.6308e-01, time/batch = 15.9171s	
20346/22300 (epoch 45.619), train_loss = 0.39334515, grad/param norm = 2.5241e-01, time/batch = 15.6949s	
20347/22300 (epoch 45.621), train_loss = 0.26728409, grad/param norm = 2.6067e-01, time/batch = 15.7225s	
20348/22300 (epoch 45.623), train_loss = 0.27285178, grad/param norm = 1.9134e-01, time/batch = 15.5510s	
20349/22300 (epoch 45.626), train_loss = 0.26315076, grad/param norm = 2.1965e-01, time/batch = 15.6777s	
20350/22300 (epoch 45.628), train_loss = 0.27464887, grad/param norm = 1.9363e-01, time/batch = 15.7837s	
20351/22300 (epoch 45.630), train_loss = 0.30449872, grad/param norm = 2.4835e-01, time/batch = 15.7350s	
20352/22300 (epoch 45.632), train_loss = 0.28124707, grad/param norm = 2.9862e-01, time/batch = 15.8914s	
20353/22300 (epoch 45.635), train_loss = 0.31484953, grad/param norm = 2.5137e-01, time/batch = 15.8180s	
20354/22300 (epoch 45.637), train_loss = 0.37720862, grad/param norm = 3.1096e-01, time/batch = 15.8100s	
20355/22300 (epoch 45.639), train_loss = 0.43010096, grad/param norm = 3.1028e-01, time/batch = 15.7317s	
20356/22300 (epoch 45.641), train_loss = 0.35934256, grad/param norm = 3.1533e-01, time/batch = 15.5637s	
20357/22300 (epoch 45.643), train_loss = 0.27066566, grad/param norm = 2.3331e-01, time/batch = 15.7764s	
20358/22300 (epoch 45.646), train_loss = 0.27908636, grad/param norm = 2.2650e-01, time/batch = 15.6422s	
20359/22300 (epoch 45.648), train_loss = 0.38014824, grad/param norm = 2.0630e-01, time/batch = 15.7291s	
20360/22300 (epoch 45.650), train_loss = 0.36083167, grad/param norm = 3.5121e-01, time/batch = 15.8702s	
20361/22300 (epoch 45.652), train_loss = 0.29046196, grad/param norm = 2.1844e-01, time/batch = 15.9576s	
20362/22300 (epoch 45.655), train_loss = 0.22728393, grad/param norm = 1.9861e-01, time/batch = 15.9042s	
20363/22300 (epoch 45.657), train_loss = 0.28088495, grad/param norm = 2.1948e-01, time/batch = 15.5383s	
20364/22300 (epoch 45.659), train_loss = 0.29426057, grad/param norm = 3.2067e-01, time/batch = 15.5652s	
20365/22300 (epoch 45.661), train_loss = 0.22345647, grad/param norm = 1.9185e-01, time/batch = 15.7026s	
20366/22300 (epoch 45.664), train_loss = 0.27655509, grad/param norm = 2.3257e-01, time/batch = 15.6526s	
20367/22300 (epoch 45.666), train_loss = 0.34861124, grad/param norm = 3.2403e-01, time/batch = 15.8651s	
20368/22300 (epoch 45.668), train_loss = 0.26158911, grad/param norm = 2.0743e-01, time/batch = 16.0506s	
20369/22300 (epoch 45.670), train_loss = 0.32802892, grad/param norm = 3.0847e-01, time/batch = 15.8772s	
20370/22300 (epoch 45.673), train_loss = 0.41132544, grad/param norm = 2.9806e-01, time/batch = 15.9851s	
20371/22300 (epoch 45.675), train_loss = 0.41650478, grad/param norm = 3.1012e-01, time/batch = 15.9674s	
20372/22300 (epoch 45.677), train_loss = 0.44981405, grad/param norm = 2.8700e-01, time/batch = 15.6407s	
20373/22300 (epoch 45.679), train_loss = 0.32653931, grad/param norm = 2.9866e-01, time/batch = 15.5552s	
20374/22300 (epoch 45.682), train_loss = 0.29484366, grad/param norm = 2.3163e-01, time/batch = 15.7274s	
20375/22300 (epoch 45.684), train_loss = 0.29166461, grad/param norm = 1.8630e-01, time/batch = 15.9494s	
20376/22300 (epoch 45.686), train_loss = 0.26762718, grad/param norm = 2.4604e-01, time/batch = 15.8095s	
20377/22300 (epoch 45.688), train_loss = 0.26915209, grad/param norm = 2.4108e-01, time/batch = 16.0552s	
20378/22300 (epoch 45.691), train_loss = 0.24021628, grad/param norm = 2.0394e-01, time/batch = 15.7732s	
20379/22300 (epoch 45.693), train_loss = 0.22970776, grad/param norm = 1.7448e-01, time/batch = 15.9577s	
20380/22300 (epoch 45.695), train_loss = 0.27738806, grad/param norm = 2.0892e-01, time/batch = 15.8867s	
20381/22300 (epoch 45.697), train_loss = 0.28336204, grad/param norm = 1.9205e-01, time/batch = 16.2022s	
20382/22300 (epoch 45.700), train_loss = 0.23978938, grad/param norm = 1.8890e-01, time/batch = 16.0409s	
20383/22300 (epoch 45.702), train_loss = 0.19735071, grad/param norm = 1.6708e-01, time/batch = 15.7156s	
20384/22300 (epoch 45.704), train_loss = 0.26199369, grad/param norm = 2.1993e-01, time/batch = 15.8851s	
20385/22300 (epoch 45.706), train_loss = 0.24784349, grad/param norm = 2.1227e-01, time/batch = 15.8088s	
20386/22300 (epoch 45.709), train_loss = 0.18262413, grad/param norm = 1.4318e-01, time/batch = 15.9655s	
20387/22300 (epoch 45.711), train_loss = 0.20499761, grad/param norm = 2.0774e-01, time/batch = 15.7311s	
20388/22300 (epoch 45.713), train_loss = 0.30314189, grad/param norm = 2.8098e-01, time/batch = 15.5452s	
20389/22300 (epoch 45.715), train_loss = 0.32294869, grad/param norm = 2.3667e-01, time/batch = 15.9504s	
20390/22300 (epoch 45.717), train_loss = 0.40432724, grad/param norm = 2.2881e-01, time/batch = 15.9597s	
20391/22300 (epoch 45.720), train_loss = 0.25384374, grad/param norm = 2.5125e-01, time/batch = 15.9405s	
20392/22300 (epoch 45.722), train_loss = 0.30434852, grad/param norm = 2.7720e-01, time/batch = 15.8779s	
20393/22300 (epoch 45.724), train_loss = 0.32490326, grad/param norm = 3.1613e-01, time/batch = 15.8660s	
20394/22300 (epoch 45.726), train_loss = 0.25792391, grad/param norm = 2.1995e-01, time/batch = 15.8116s	
20395/22300 (epoch 45.729), train_loss = 0.31472776, grad/param norm = 1.8056e-01, time/batch = 15.4836s	
20396/22300 (epoch 45.731), train_loss = 0.36333082, grad/param norm = 2.8880e-01, time/batch = 15.4755s	
20397/22300 (epoch 45.733), train_loss = 0.38048761, grad/param norm = 3.4883e-01, time/batch = 15.8912s	
20398/22300 (epoch 45.735), train_loss = 0.41056343, grad/param norm = 3.3891e-01, time/batch = 15.8784s	
20399/22300 (epoch 45.738), train_loss = 0.28563018, grad/param norm = 2.4935e-01, time/batch = 16.0564s	
20400/22300 (epoch 45.740), train_loss = 0.27502958, grad/param norm = 1.9733e-01, time/batch = 15.8893s	
20401/22300 (epoch 45.742), train_loss = 0.23723121, grad/param norm = 1.6946e-01, time/batch = 16.0230s	
20402/22300 (epoch 45.744), train_loss = 0.42379948, grad/param norm = 2.9212e-01, time/batch = 15.8596s	
20403/22300 (epoch 45.747), train_loss = 0.34460255, grad/param norm = 2.2276e-01, time/batch = 15.7740s	
20404/22300 (epoch 45.749), train_loss = 0.45639641, grad/param norm = 2.8339e-01, time/batch = 15.7622s	
20405/22300 (epoch 45.751), train_loss = 0.38118139, grad/param norm = 3.0382e-01, time/batch = 15.9413s	
20406/22300 (epoch 45.753), train_loss = 0.40241459, grad/param norm = 3.7379e-01, time/batch = 15.8720s	
20407/22300 (epoch 45.756), train_loss = 0.38984376, grad/param norm = 2.1961e-01, time/batch = 16.0011s	
20408/22300 (epoch 45.758), train_loss = 0.30834526, grad/param norm = 1.9535e-01, time/batch = 15.5981s	
20409/22300 (epoch 45.760), train_loss = 0.36514215, grad/param norm = 2.3611e-01, time/batch = 15.8668s	
20410/22300 (epoch 45.762), train_loss = 0.31980364, grad/param norm = 2.3257e-01, time/batch = 15.9519s	
20411/22300 (epoch 45.765), train_loss = 0.36256800, grad/param norm = 2.7669e-01, time/batch = 16.3018s	
20412/22300 (epoch 45.767), train_loss = 0.32465705, grad/param norm = 2.9066e-01, time/batch = 15.7746s	
20413/22300 (epoch 45.769), train_loss = 0.30972563, grad/param norm = 2.7149e-01, time/batch = 15.6460s	
20414/22300 (epoch 45.771), train_loss = 0.37357690, grad/param norm = 3.0365e-01, time/batch = 15.6487s	
20415/22300 (epoch 45.774), train_loss = 0.41804501, grad/param norm = 3.2537e-01, time/batch = 15.6301s	
20416/22300 (epoch 45.776), train_loss = 0.43242317, grad/param norm = 2.9934e-01, time/batch = 15.8923s	
20417/22300 (epoch 45.778), train_loss = 0.43395015, grad/param norm = 2.6757e-01, time/batch = 15.0652s	
20418/22300 (epoch 45.780), train_loss = 0.40674310, grad/param norm = 2.6150e-01, time/batch = 15.6065s	
20419/22300 (epoch 45.783), train_loss = 0.45724750, grad/param norm = 2.6934e-01, time/batch = 15.0512s	
20420/22300 (epoch 45.785), train_loss = 0.27941130, grad/param norm = 1.9684e-01, time/batch = 15.2122s	
20421/22300 (epoch 45.787), train_loss = 0.30354956, grad/param norm = 2.5682e-01, time/batch = 15.0621s	
20422/22300 (epoch 45.789), train_loss = 0.46008069, grad/param norm = 3.3274e-01, time/batch = 14.8316s	
20423/22300 (epoch 45.791), train_loss = 0.57021745, grad/param norm = 3.5498e-01, time/batch = 14.8910s	
20424/22300 (epoch 45.794), train_loss = 0.45646513, grad/param norm = 2.8187e-01, time/batch = 15.4614s	
20425/22300 (epoch 45.796), train_loss = 0.38045622, grad/param norm = 2.7121e-01, time/batch = 15.2296s	
20426/22300 (epoch 45.798), train_loss = 0.51924050, grad/param norm = 2.9686e-01, time/batch = 14.7136s	
20427/22300 (epoch 45.800), train_loss = 0.35541100, grad/param norm = 2.9158e-01, time/batch = 15.1191s	
20428/22300 (epoch 45.803), train_loss = 0.32545784, grad/param norm = 2.4441e-01, time/batch = 15.2605s	
20429/22300 (epoch 45.805), train_loss = 0.35501932, grad/param norm = 2.7897e-01, time/batch = 15.2753s	
20430/22300 (epoch 45.807), train_loss = 0.47829759, grad/param norm = 4.3569e-01, time/batch = 15.4080s	
20431/22300 (epoch 45.809), train_loss = 0.34666772, grad/param norm = 2.7883e-01, time/batch = 15.2208s	
20432/22300 (epoch 45.812), train_loss = 0.37385289, grad/param norm = 2.8227e-01, time/batch = 15.2091s	
20433/22300 (epoch 45.814), train_loss = 0.35936480, grad/param norm = 3.3299e-01, time/batch = 15.2544s	
20434/22300 (epoch 45.816), train_loss = 0.39043538, grad/param norm = 2.9942e-01, time/batch = 15.6682s	
20435/22300 (epoch 45.818), train_loss = 0.44203557, grad/param norm = 3.5689e-01, time/batch = 14.6520s	
20436/22300 (epoch 45.821), train_loss = 0.36317725, grad/param norm = 2.6521e-01, time/batch = 15.1305s	
20437/22300 (epoch 45.823), train_loss = 0.25786770, grad/param norm = 2.2962e-01, time/batch = 15.3203s	
20438/22300 (epoch 45.825), train_loss = 0.25880134, grad/param norm = 2.1401e-01, time/batch = 15.0876s	
20439/22300 (epoch 45.827), train_loss = 0.29480803, grad/param norm = 2.5094e-01, time/batch = 15.4807s	
20440/22300 (epoch 45.830), train_loss = 0.31200733, grad/param norm = 2.4004e-01, time/batch = 14.8587s	
20441/22300 (epoch 45.832), train_loss = 0.29658478, grad/param norm = 2.2067e-01, time/batch = 15.6833s	
20442/22300 (epoch 45.834), train_loss = 0.25096737, grad/param norm = 2.6238e-01, time/batch = 15.5016s	
20443/22300 (epoch 45.836), train_loss = 0.29484495, grad/param norm = 2.3937e-01, time/batch = 15.1408s	
20444/22300 (epoch 45.839), train_loss = 0.33263644, grad/param norm = 2.7888e-01, time/batch = 15.4618s	
20445/22300 (epoch 45.841), train_loss = 0.29797384, grad/param norm = 3.4124e-01, time/batch = 14.2420s	
20446/22300 (epoch 45.843), train_loss = 0.30954431, grad/param norm = 2.2178e-01, time/batch = 14.5636s	
20447/22300 (epoch 45.845), train_loss = 0.32218590, grad/param norm = 2.2842e-01, time/batch = 14.5728s	
20448/22300 (epoch 45.848), train_loss = 0.29871186, grad/param norm = 2.8895e-01, time/batch = 14.8970s	
20449/22300 (epoch 45.850), train_loss = 0.32827112, grad/param norm = 1.8821e-01, time/batch = 14.8657s	
20450/22300 (epoch 45.852), train_loss = 0.30698713, grad/param norm = 3.9141e-01, time/batch = 15.0460s	
20451/22300 (epoch 45.854), train_loss = 0.50577514, grad/param norm = 3.7585e-01, time/batch = 14.7252s	
20452/22300 (epoch 45.857), train_loss = 0.35123390, grad/param norm = 2.3832e-01, time/batch = 15.1439s	
20453/22300 (epoch 45.859), train_loss = 0.30472744, grad/param norm = 2.3674e-01, time/batch = 14.4981s	
20454/22300 (epoch 45.861), train_loss = 0.40178700, grad/param norm = 2.8081e-01, time/batch = 14.5827s	
20455/22300 (epoch 45.863), train_loss = 0.24562612, grad/param norm = 2.8150e-01, time/batch = 14.9808s	
20456/22300 (epoch 45.865), train_loss = 0.25983149, grad/param norm = 2.1473e-01, time/batch = 14.7355s	
20457/22300 (epoch 45.868), train_loss = 0.33302081, grad/param norm = 1.9778e-01, time/batch = 14.3298s	
20458/22300 (epoch 45.870), train_loss = 0.34734987, grad/param norm = 2.8724e-01, time/batch = 14.9816s	
20459/22300 (epoch 45.872), train_loss = 0.43801794, grad/param norm = 2.8429e-01, time/batch = 14.8584s	
20460/22300 (epoch 45.874), train_loss = 0.35688050, grad/param norm = 2.4489e-01, time/batch = 15.2209s	
20461/22300 (epoch 45.877), train_loss = 0.32505672, grad/param norm = 2.0571e-01, time/batch = 14.7459s	
20462/22300 (epoch 45.879), train_loss = 0.33757175, grad/param norm = 2.7788e-01, time/batch = 14.1707s	
20463/22300 (epoch 45.881), train_loss = 0.25781270, grad/param norm = 2.2069e-01, time/batch = 17.0317s	
20464/22300 (epoch 45.883), train_loss = 0.25767934, grad/param norm = 2.0649e-01, time/batch = 27.0437s	
20465/22300 (epoch 45.886), train_loss = 0.24040242, grad/param norm = 2.3314e-01, time/batch = 15.5142s	
20466/22300 (epoch 45.888), train_loss = 0.28375332, grad/param norm = 1.8797e-01, time/batch = 14.7337s	
20467/22300 (epoch 45.890), train_loss = 0.28494945, grad/param norm = 1.7502e-01, time/batch = 17.1331s	
20468/22300 (epoch 45.892), train_loss = 0.44117865, grad/param norm = 2.3895e-01, time/batch = 14.9808s	
20469/22300 (epoch 45.895), train_loss = 0.38905512, grad/param norm = 3.3424e-01, time/batch = 15.2839s	
20470/22300 (epoch 45.897), train_loss = 0.31594414, grad/param norm = 2.4403e-01, time/batch = 15.5068s	
20471/22300 (epoch 45.899), train_loss = 0.31226530, grad/param norm = 2.2191e-01, time/batch = 16.6183s	
20472/22300 (epoch 45.901), train_loss = 0.39015824, grad/param norm = 2.5388e-01, time/batch = 15.2734s	
20473/22300 (epoch 45.904), train_loss = 0.36339249, grad/param norm = 2.4770e-01, time/batch = 17.1499s	
20474/22300 (epoch 45.906), train_loss = 0.36267105, grad/param norm = 2.7327e-01, time/batch = 15.4803s	
20475/22300 (epoch 45.908), train_loss = 0.32775154, grad/param norm = 2.5681e-01, time/batch = 15.2637s	
20476/22300 (epoch 45.910), train_loss = 0.27898048, grad/param norm = 2.2115e-01, time/batch = 15.0128s	
20477/22300 (epoch 45.913), train_loss = 0.34591286, grad/param norm = 2.6311e-01, time/batch = 15.2819s	
20478/22300 (epoch 45.915), train_loss = 0.44794001, grad/param norm = 2.8580e-01, time/batch = 15.2862s	
20479/22300 (epoch 45.917), train_loss = 0.35190959, grad/param norm = 2.2341e-01, time/batch = 15.5258s	
20480/22300 (epoch 45.919), train_loss = 0.33617766, grad/param norm = 1.9714e-01, time/batch = 15.3113s	
20481/22300 (epoch 45.922), train_loss = 0.32267306, grad/param norm = 3.0265e-01, time/batch = 17.6147s	
20482/22300 (epoch 45.924), train_loss = 0.22168322, grad/param norm = 2.1065e-01, time/batch = 15.7011s	
20483/22300 (epoch 45.926), train_loss = 0.28567525, grad/param norm = 2.6488e-01, time/batch = 15.1471s	
20484/22300 (epoch 45.928), train_loss = 0.30039083, grad/param norm = 3.2331e-01, time/batch = 15.4336s	
20485/22300 (epoch 45.930), train_loss = 0.28622046, grad/param norm = 2.2379e-01, time/batch = 15.8831s	
20486/22300 (epoch 45.933), train_loss = 0.34181208, grad/param norm = 2.2581e-01, time/batch = 15.4565s	
20487/22300 (epoch 45.935), train_loss = 0.33950167, grad/param norm = 3.4625e-01, time/batch = 16.7108s	
20488/22300 (epoch 45.937), train_loss = 0.43706860, grad/param norm = 3.0496e-01, time/batch = 17.2226s	
20489/22300 (epoch 45.939), train_loss = 0.36515142, grad/param norm = 2.3718e-01, time/batch = 15.3969s	
20490/22300 (epoch 45.942), train_loss = 0.46213474, grad/param norm = 3.3264e-01, time/batch = 19.1090s	
20491/22300 (epoch 45.944), train_loss = 0.50345005, grad/param norm = 3.9769e-01, time/batch = 16.4774s	
20492/22300 (epoch 45.946), train_loss = 0.37007937, grad/param norm = 2.6125e-01, time/batch = 17.7694s	
20493/22300 (epoch 45.948), train_loss = 0.30802559, grad/param norm = 1.7519e-01, time/batch = 15.6604s	
20494/22300 (epoch 45.951), train_loss = 0.24226631, grad/param norm = 2.1655e-01, time/batch = 15.3633s	
20495/22300 (epoch 45.953), train_loss = 0.27866501, grad/param norm = 3.7798e-01, time/batch = 15.6036s	
20496/22300 (epoch 45.955), train_loss = 0.41479889, grad/param norm = 2.6812e-01, time/batch = 15.1371s	
20497/22300 (epoch 45.957), train_loss = 0.51676284, grad/param norm = 3.3659e-01, time/batch = 15.4009s	
20498/22300 (epoch 45.960), train_loss = 0.43847570, grad/param norm = 2.8832e-01, time/batch = 15.5548s	
20499/22300 (epoch 45.962), train_loss = 0.26493437, grad/param norm = 2.2755e-01, time/batch = 15.6553s	
20500/22300 (epoch 45.964), train_loss = 0.25071902, grad/param norm = 1.7230e-01, time/batch = 16.4402s	
20501/22300 (epoch 45.966), train_loss = 0.29749352, grad/param norm = 2.3221e-01, time/batch = 15.0347s	
20502/22300 (epoch 45.969), train_loss = 0.31047189, grad/param norm = 2.1908e-01, time/batch = 14.8236s	
20503/22300 (epoch 45.971), train_loss = 0.31778982, grad/param norm = 2.2912e-01, time/batch = 16.3139s	
20504/22300 (epoch 45.973), train_loss = 0.29781996, grad/param norm = 2.7959e-01, time/batch = 15.4643s	
20505/22300 (epoch 45.975), train_loss = 0.42817918, grad/param norm = 3.3874e-01, time/batch = 16.8019s	
20506/22300 (epoch 45.978), train_loss = 0.42665049, grad/param norm = 2.7139e-01, time/batch = 15.8226s	
20507/22300 (epoch 45.980), train_loss = 0.51902614, grad/param norm = 3.2217e-01, time/batch = 16.8103s	
20508/22300 (epoch 45.982), train_loss = 0.24774990, grad/param norm = 2.2258e-01, time/batch = 16.0610s	
20509/22300 (epoch 45.984), train_loss = 0.33142199, grad/param norm = 2.5397e-01, time/batch = 15.9039s	
20510/22300 (epoch 45.987), train_loss = 0.34247603, grad/param norm = 2.7167e-01, time/batch = 15.6463s	
20511/22300 (epoch 45.989), train_loss = 0.26026329, grad/param norm = 2.6178e-01, time/batch = 15.4865s	
20512/22300 (epoch 45.991), train_loss = 0.48683376, grad/param norm = 3.3852e-01, time/batch = 15.4410s	
20513/22300 (epoch 45.993), train_loss = 0.66933192, grad/param norm = 3.8781e-01, time/batch = 15.7567s	
20514/22300 (epoch 45.996), train_loss = 0.60760192, grad/param norm = 3.8675e-01, time/batch = 15.6541s	
20515/22300 (epoch 45.998), train_loss = 0.36563246, grad/param norm = 2.7810e-01, time/batch = 15.3730s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
20516/22300 (epoch 46.000), train_loss = 0.28864258, grad/param norm = 2.5829e-01, time/batch = 15.4776s	
20517/22300 (epoch 46.002), train_loss = 0.62184205, grad/param norm = 2.8634e-01, time/batch = 14.8196s	
20518/22300 (epoch 46.004), train_loss = 0.39921164, grad/param norm = 2.8039e-01, time/batch = 16.1224s	
20519/22300 (epoch 46.007), train_loss = 0.40695458, grad/param norm = 2.8273e-01, time/batch = 15.2906s	
20520/22300 (epoch 46.009), train_loss = 0.42246997, grad/param norm = 3.5374e-01, time/batch = 15.2201s	
20521/22300 (epoch 46.011), train_loss = 0.53902072, grad/param norm = 4.5574e-01, time/batch = 16.6418s	
20522/22300 (epoch 46.013), train_loss = 0.40906960, grad/param norm = 2.5097e-01, time/batch = 15.6563s	
20523/22300 (epoch 46.016), train_loss = 0.29254134, grad/param norm = 2.5120e-01, time/batch = 15.0660s	
20524/22300 (epoch 46.018), train_loss = 0.33654988, grad/param norm = 2.6456e-01, time/batch = 16.8737s	
20525/22300 (epoch 46.020), train_loss = 0.31813564, grad/param norm = 2.3032e-01, time/batch = 14.9792s	
20526/22300 (epoch 46.022), train_loss = 0.24293735, grad/param norm = 2.2352e-01, time/batch = 16.8119s	
20527/22300 (epoch 46.025), train_loss = 0.28688361, grad/param norm = 1.8794e-01, time/batch = 15.9433s	
20528/22300 (epoch 46.027), train_loss = 0.26433586, grad/param norm = 1.6035e-01, time/batch = 14.8175s	
20529/22300 (epoch 46.029), train_loss = 0.31089966, grad/param norm = 3.0981e-01, time/batch = 15.0459s	
20530/22300 (epoch 46.031), train_loss = 0.28649380, grad/param norm = 2.3271e-01, time/batch = 15.1346s	
20531/22300 (epoch 46.034), train_loss = 0.28319374, grad/param norm = 2.0999e-01, time/batch = 16.2968s	
20532/22300 (epoch 46.036), train_loss = 0.26973234, grad/param norm = 1.8581e-01, time/batch = 14.9973s	
20533/22300 (epoch 46.038), train_loss = 0.22915129, grad/param norm = 2.6848e-01, time/batch = 16.3470s	
20534/22300 (epoch 46.040), train_loss = 0.28210644, grad/param norm = 2.2511e-01, time/batch = 15.8001s	
20535/22300 (epoch 46.043), train_loss = 0.46319717, grad/param norm = 2.7856e-01, time/batch = 15.5086s	
20536/22300 (epoch 46.045), train_loss = 0.41373627, grad/param norm = 2.5811e-01, time/batch = 15.1785s	
20537/22300 (epoch 46.047), train_loss = 0.45189995, grad/param norm = 3.2813e-01, time/batch = 15.7999s	
20538/22300 (epoch 46.049), train_loss = 0.33626565, grad/param norm = 2.4499e-01, time/batch = 16.2791s	
20539/22300 (epoch 46.052), train_loss = 0.38208107, grad/param norm = 2.8164e-01, time/batch = 15.0355s	
20540/22300 (epoch 46.054), train_loss = 0.39735392, grad/param norm = 3.0624e-01, time/batch = 15.7887s	
20541/22300 (epoch 46.056), train_loss = 0.19783149, grad/param norm = 1.8202e-01, time/batch = 16.0547s	
20542/22300 (epoch 46.058), train_loss = 0.31091552, grad/param norm = 2.3057e-01, time/batch = 15.1317s	
20543/22300 (epoch 46.061), train_loss = 0.28098334, grad/param norm = 2.3006e-01, time/batch = 18.5263s	
20544/22300 (epoch 46.063), train_loss = 0.41102433, grad/param norm = 3.0933e-01, time/batch = 17.2960s	
20545/22300 (epoch 46.065), train_loss = 0.49301188, grad/param norm = 3.6011e-01, time/batch = 16.1137s	
20546/22300 (epoch 46.067), train_loss = 0.27156584, grad/param norm = 2.0944e-01, time/batch = 16.2041s	
20547/22300 (epoch 46.070), train_loss = 0.31552132, grad/param norm = 1.9616e-01, time/batch = 16.0405s	
20548/22300 (epoch 46.072), train_loss = 0.34017165, grad/param norm = 2.3970e-01, time/batch = 16.8981s	
20549/22300 (epoch 46.074), train_loss = 0.36497390, grad/param norm = 2.5908e-01, time/batch = 16.7938s	
20550/22300 (epoch 46.076), train_loss = 0.35141286, grad/param norm = 2.6718e-01, time/batch = 17.3885s	
20551/22300 (epoch 46.078), train_loss = 0.47588973, grad/param norm = 3.2874e-01, time/batch = 16.1470s	
20552/22300 (epoch 46.081), train_loss = 0.45257879, grad/param norm = 3.6756e-01, time/batch = 16.6179s	
20553/22300 (epoch 46.083), train_loss = 0.51078935, grad/param norm = 3.3031e-01, time/batch = 16.0938s	
20554/22300 (epoch 46.085), train_loss = 0.46341511, grad/param norm = 3.3190e-01, time/batch = 15.5500s	
20555/22300 (epoch 46.087), train_loss = 0.38807703, grad/param norm = 2.6873e-01, time/batch = 14.8987s	
20556/22300 (epoch 46.090), train_loss = 0.35566946, grad/param norm = 2.8091e-01, time/batch = 17.9231s	
20557/22300 (epoch 46.092), train_loss = 0.26030799, grad/param norm = 1.7259e-01, time/batch = 19.0934s	
20558/22300 (epoch 46.094), train_loss = 0.27903710, grad/param norm = 2.3225e-01, time/batch = 19.0353s	
20559/22300 (epoch 46.096), train_loss = 0.46152463, grad/param norm = 3.3257e-01, time/batch = 19.2951s	
20560/22300 (epoch 46.099), train_loss = 0.31762345, grad/param norm = 2.7805e-01, time/batch = 21.6426s	
20561/22300 (epoch 46.101), train_loss = 0.40339759, grad/param norm = 2.4550e-01, time/batch = 20.0070s	
20562/22300 (epoch 46.103), train_loss = 0.34133133, grad/param norm = 2.0972e-01, time/batch = 21.4812s	
20563/22300 (epoch 46.105), train_loss = 0.26102621, grad/param norm = 3.2769e-01, time/batch = 19.9163s	
20564/22300 (epoch 46.108), train_loss = 0.39905245, grad/param norm = 3.3083e-01, time/batch = 18.9607s	
20565/22300 (epoch 46.110), train_loss = 0.44039135, grad/param norm = 2.7305e-01, time/batch = 19.9213s	
20566/22300 (epoch 46.112), train_loss = 0.36906384, grad/param norm = 2.6803e-01, time/batch = 18.4422s	
20567/22300 (epoch 46.114), train_loss = 0.41182816, grad/param norm = 2.9224e-01, time/batch = 19.7617s	
20568/22300 (epoch 46.117), train_loss = 0.46693907, grad/param norm = 2.5804e-01, time/batch = 18.4679s	
20569/22300 (epoch 46.119), train_loss = 0.42953341, grad/param norm = 3.1358e-01, time/batch = 18.5338s	
20570/22300 (epoch 46.121), train_loss = 0.48536611, grad/param norm = 2.9977e-01, time/batch = 18.9638s	
20571/22300 (epoch 46.123), train_loss = 0.50385112, grad/param norm = 3.2888e-01, time/batch = 19.3494s	
20572/22300 (epoch 46.126), train_loss = 0.37902640, grad/param norm = 2.5704e-01, time/batch = 18.4796s	
20573/22300 (epoch 46.128), train_loss = 0.36491244, grad/param norm = 2.7833e-01, time/batch = 18.1579s	
20574/22300 (epoch 46.130), train_loss = 0.33405792, grad/param norm = 2.5477e-01, time/batch = 18.0746s	
20575/22300 (epoch 46.132), train_loss = 0.23049140, grad/param norm = 1.7658e-01, time/batch = 18.7345s	
20576/22300 (epoch 46.135), train_loss = 0.26668129, grad/param norm = 2.5920e-01, time/batch = 18.4879s	
20577/22300 (epoch 46.137), train_loss = 0.21513994, grad/param norm = 2.5628e-01, time/batch = 23.3520s	
20578/22300 (epoch 46.139), train_loss = 0.29518014, grad/param norm = 2.7356e-01, time/batch = 14.9667s	
20579/22300 (epoch 46.141), train_loss = 0.41110017, grad/param norm = 2.3435e-01, time/batch = 14.8089s	
20580/22300 (epoch 46.143), train_loss = 0.33692471, grad/param norm = 2.7882e-01, time/batch = 14.3341s	
20581/22300 (epoch 46.146), train_loss = 0.41949764, grad/param norm = 3.3693e-01, time/batch = 14.3253s	
20582/22300 (epoch 46.148), train_loss = 0.29214052, grad/param norm = 2.2423e-01, time/batch = 14.4704s	
20583/22300 (epoch 46.150), train_loss = 0.30646143, grad/param norm = 2.6040e-01, time/batch = 14.0865s	
20584/22300 (epoch 46.152), train_loss = 0.25440916, grad/param norm = 2.8407e-01, time/batch = 14.4585s	
20585/22300 (epoch 46.155), train_loss = 0.29332042, grad/param norm = 2.2197e-01, time/batch = 14.5572s	
20586/22300 (epoch 46.157), train_loss = 0.38218261, grad/param norm = 2.9684e-01, time/batch = 15.2135s	
20587/22300 (epoch 46.159), train_loss = 0.40792107, grad/param norm = 3.2721e-01, time/batch = 14.5724s	
20588/22300 (epoch 46.161), train_loss = 0.37680411, grad/param norm = 2.9130e-01, time/batch = 15.1399s	
20589/22300 (epoch 46.164), train_loss = 0.27806498, grad/param norm = 2.0049e-01, time/batch = 14.2585s	
20590/22300 (epoch 46.166), train_loss = 0.24275002, grad/param norm = 1.8457e-01, time/batch = 15.3442s	
20591/22300 (epoch 46.168), train_loss = 0.22914007, grad/param norm = 2.1062e-01, time/batch = 15.1643s	
20592/22300 (epoch 46.170), train_loss = 0.33467556, grad/param norm = 2.2858e-01, time/batch = 14.7197s	
20593/22300 (epoch 46.173), train_loss = 0.38889509, grad/param norm = 3.2383e-01, time/batch = 14.3273s	
20594/22300 (epoch 46.175), train_loss = 0.32463175, grad/param norm = 2.3129e-01, time/batch = 14.4859s	
20595/22300 (epoch 46.177), train_loss = 0.21246519, grad/param norm = 1.8823e-01, time/batch = 14.2368s	
20596/22300 (epoch 46.179), train_loss = 0.33170433, grad/param norm = 2.5352e-01, time/batch = 14.9654s	
20597/22300 (epoch 46.182), train_loss = 0.44700726, grad/param norm = 2.8226e-01, time/batch = 14.0039s	
20598/22300 (epoch 46.184), train_loss = 0.48031785, grad/param norm = 3.1307e-01, time/batch = 14.6547s	
20599/22300 (epoch 46.186), train_loss = 0.36727289, grad/param norm = 3.4293e-01, time/batch = 14.8174s	
20600/22300 (epoch 46.188), train_loss = 0.55199087, grad/param norm = 3.5870e-01, time/batch = 14.6071s	
20601/22300 (epoch 46.191), train_loss = 0.43617052, grad/param norm = 3.1261e-01, time/batch = 14.4175s	
20602/22300 (epoch 46.193), train_loss = 0.37883460, grad/param norm = 2.6901e-01, time/batch = 14.6547s	
20603/22300 (epoch 46.195), train_loss = 0.33371227, grad/param norm = 2.5620e-01, time/batch = 14.5032s	
20604/22300 (epoch 46.197), train_loss = 0.30422734, grad/param norm = 2.4273e-01, time/batch = 14.4971s	
20605/22300 (epoch 46.200), train_loss = 0.26180058, grad/param norm = 2.7584e-01, time/batch = 14.8077s	
20606/22300 (epoch 46.202), train_loss = 0.28139063, grad/param norm = 2.1542e-01, time/batch = 14.7917s	
20607/22300 (epoch 46.204), train_loss = 0.37000925, grad/param norm = 2.8804e-01, time/batch = 14.7275s	
20608/22300 (epoch 46.206), train_loss = 0.31581014, grad/param norm = 2.6704e-01, time/batch = 14.4189s	
20609/22300 (epoch 46.209), train_loss = 0.31779448, grad/param norm = 2.6159e-01, time/batch = 14.2558s	
20610/22300 (epoch 46.211), train_loss = 0.24493472, grad/param norm = 2.3281e-01, time/batch = 14.3392s	
20611/22300 (epoch 46.213), train_loss = 0.36059152, grad/param norm = 2.3659e-01, time/batch = 14.8613s	
20612/22300 (epoch 46.215), train_loss = 0.46341808, grad/param norm = 3.4108e-01, time/batch = 14.4150s	
20613/22300 (epoch 46.217), train_loss = 0.50506008, grad/param norm = 3.3116e-01, time/batch = 15.7293s	
20614/22300 (epoch 46.220), train_loss = 0.31654269, grad/param norm = 2.1262e-01, time/batch = 15.1874s	
20615/22300 (epoch 46.222), train_loss = 0.32908520, grad/param norm = 2.3666e-01, time/batch = 14.8013s	
20616/22300 (epoch 46.224), train_loss = 0.30968537, grad/param norm = 2.4113e-01, time/batch = 14.3374s	
20617/22300 (epoch 46.226), train_loss = 0.33572373, grad/param norm = 2.8740e-01, time/batch = 14.3294s	
20618/22300 (epoch 46.229), train_loss = 0.27906194, grad/param norm = 2.9304e-01, time/batch = 14.2542s	
20619/22300 (epoch 46.231), train_loss = 0.43662387, grad/param norm = 3.5589e-01, time/batch = 14.7243s	
20620/22300 (epoch 46.233), train_loss = 0.35328495, grad/param norm = 2.5729e-01, time/batch = 14.7979s	
20621/22300 (epoch 46.235), train_loss = 0.27682425, grad/param norm = 2.1536e-01, time/batch = 14.2415s	
20622/22300 (epoch 46.238), train_loss = 0.26810325, grad/param norm = 1.9773e-01, time/batch = 13.9324s	
20623/22300 (epoch 46.240), train_loss = 0.29774691, grad/param norm = 2.0483e-01, time/batch = 14.7953s	
20624/22300 (epoch 46.242), train_loss = 0.24183601, grad/param norm = 2.5979e-01, time/batch = 13.8441s	
20625/22300 (epoch 46.244), train_loss = 0.19217430, grad/param norm = 1.7077e-01, time/batch = 14.3926s	
20626/22300 (epoch 46.247), train_loss = 0.25934242, grad/param norm = 2.0350e-01, time/batch = 14.5627s	
20627/22300 (epoch 46.249), train_loss = 0.17800477, grad/param norm = 1.3938e-01, time/batch = 14.8894s	
20628/22300 (epoch 46.251), train_loss = 0.22407311, grad/param norm = 1.4728e-01, time/batch = 14.5514s	
20629/22300 (epoch 46.253), train_loss = 0.15676983, grad/param norm = 1.7464e-01, time/batch = 14.4034s	
20630/22300 (epoch 46.256), train_loss = 0.23176207, grad/param norm = 1.6752e-01, time/batch = 14.2549s	
20631/22300 (epoch 46.258), train_loss = 0.33683114, grad/param norm = 2.6379e-01, time/batch = 15.2129s	
20632/22300 (epoch 46.260), train_loss = 0.37545720, grad/param norm = 2.6654e-01, time/batch = 14.4071s	
20633/22300 (epoch 46.262), train_loss = 0.25975423, grad/param norm = 1.6319e-01, time/batch = 14.0811s	
20634/22300 (epoch 46.265), train_loss = 0.25229980, grad/param norm = 2.2521e-01, time/batch = 14.7988s	
20635/22300 (epoch 46.267), train_loss = 0.27899649, grad/param norm = 2.4837e-01, time/batch = 15.9595s	
20636/22300 (epoch 46.269), train_loss = 0.32613867, grad/param norm = 2.7081e-01, time/batch = 14.5607s	
20637/22300 (epoch 46.271), train_loss = 0.37771097, grad/param norm = 2.2990e-01, time/batch = 14.3972s	
20638/22300 (epoch 46.274), train_loss = 0.23520761, grad/param norm = 1.9646e-01, time/batch = 14.7821s	
20639/22300 (epoch 46.276), train_loss = 0.21506351, grad/param norm = 1.5420e-01, time/batch = 15.1092s	
20640/22300 (epoch 46.278), train_loss = 0.24334303, grad/param norm = 2.0279e-01, time/batch = 15.0732s	
20641/22300 (epoch 46.280), train_loss = 0.25080491, grad/param norm = 1.8781e-01, time/batch = 15.2868s	
20642/22300 (epoch 46.283), train_loss = 0.22059929, grad/param norm = 1.8512e-01, time/batch = 14.2458s	
20643/22300 (epoch 46.285), train_loss = 0.22095481, grad/param norm = 1.9800e-01, time/batch = 14.8103s	
20644/22300 (epoch 46.287), train_loss = 0.32505090, grad/param norm = 2.1752e-01, time/batch = 14.7214s	
20645/22300 (epoch 46.289), train_loss = 0.29666002, grad/param norm = 1.9805e-01, time/batch = 14.9592s	
20646/22300 (epoch 46.291), train_loss = 0.28462963, grad/param norm = 2.1817e-01, time/batch = 15.1131s	
20647/22300 (epoch 46.294), train_loss = 0.23413248, grad/param norm = 1.6824e-01, time/batch = 14.9602s	
20648/22300 (epoch 46.296), train_loss = 0.26519276, grad/param norm = 2.6551e-01, time/batch = 14.7975s	
20649/22300 (epoch 46.298), train_loss = 0.37266742, grad/param norm = 2.2534e-01, time/batch = 15.1249s	
20650/22300 (epoch 46.300), train_loss = 0.40431203, grad/param norm = 2.5066e-01, time/batch = 14.7372s	
20651/22300 (epoch 46.303), train_loss = 0.31248064, grad/param norm = 2.3216e-01, time/batch = 13.3134s	
20652/22300 (epoch 46.305), train_loss = 0.33689839, grad/param norm = 3.2150e-01, time/batch = 0.6714s	
20653/22300 (epoch 46.307), train_loss = 0.27289242, grad/param norm = 2.0800e-01, time/batch = 0.6793s	
20654/22300 (epoch 46.309), train_loss = 0.23292871, grad/param norm = 1.8227e-01, time/batch = 0.6612s	
20655/22300 (epoch 46.312), train_loss = 0.21535840, grad/param norm = 1.8152e-01, time/batch = 0.6544s	
20656/22300 (epoch 46.314), train_loss = 0.25848301, grad/param norm = 2.1575e-01, time/batch = 0.6470s	
20657/22300 (epoch 46.316), train_loss = 0.24726084, grad/param norm = 2.2153e-01, time/batch = 0.6476s	
20658/22300 (epoch 46.318), train_loss = 0.28218742, grad/param norm = 2.1653e-01, time/batch = 0.6450s	
20659/22300 (epoch 46.321), train_loss = 0.33848473, grad/param norm = 2.0855e-01, time/batch = 0.8068s	
20660/22300 (epoch 46.323), train_loss = 0.24463882, grad/param norm = 2.0815e-01, time/batch = 0.9476s	
20661/22300 (epoch 46.325), train_loss = 0.21369778, grad/param norm = 1.9231e-01, time/batch = 0.9552s	
20662/22300 (epoch 46.327), train_loss = 0.23192310, grad/param norm = 1.5533e-01, time/batch = 0.9669s	
20663/22300 (epoch 46.330), train_loss = 0.23483701, grad/param norm = 1.9458e-01, time/batch = 0.9452s	
20664/22300 (epoch 46.332), train_loss = 0.23691069, grad/param norm = 1.9480e-01, time/batch = 1.2181s	
20665/22300 (epoch 46.334), train_loss = 0.25732886, grad/param norm = 1.9481e-01, time/batch = 1.7725s	
20666/22300 (epoch 46.336), train_loss = 0.24602602, grad/param norm = 1.8044e-01, time/batch = 1.7894s	
20667/22300 (epoch 46.339), train_loss = 0.32428828, grad/param norm = 2.9437e-01, time/batch = 8.6847s	
20668/22300 (epoch 46.341), train_loss = 0.30315912, grad/param norm = 2.2462e-01, time/batch = 14.4704s	
20669/22300 (epoch 46.343), train_loss = 0.35644743, grad/param norm = 2.3702e-01, time/batch = 14.3125s	
20670/22300 (epoch 46.345), train_loss = 0.29459192, grad/param norm = 2.1785e-01, time/batch = 14.6263s	
20671/22300 (epoch 46.348), train_loss = 0.29657273, grad/param norm = 1.8547e-01, time/batch = 14.2494s	
20672/22300 (epoch 46.350), train_loss = 0.19938999, grad/param norm = 1.8726e-01, time/batch = 14.2430s	
20673/22300 (epoch 46.352), train_loss = 0.29875046, grad/param norm = 2.2187e-01, time/batch = 14.4817s	
20674/22300 (epoch 46.354), train_loss = 0.41492234, grad/param norm = 2.7882e-01, time/batch = 15.1309s	
20675/22300 (epoch 46.357), train_loss = 0.40583101, grad/param norm = 2.5698e-01, time/batch = 15.0397s	
20676/22300 (epoch 46.359), train_loss = 0.24476350, grad/param norm = 2.1100e-01, time/batch = 14.3939s	
20677/22300 (epoch 46.361), train_loss = 0.25377123, grad/param norm = 1.8649e-01, time/batch = 14.4705s	
20678/22300 (epoch 46.363), train_loss = 0.33270792, grad/param norm = 2.3777e-01, time/batch = 14.7894s	
20679/22300 (epoch 46.365), train_loss = 0.22778870, grad/param norm = 2.0434e-01, time/batch = 15.6457s	
20680/22300 (epoch 46.368), train_loss = 0.23802635, grad/param norm = 2.2919e-01, time/batch = 15.8528s	
20681/22300 (epoch 46.370), train_loss = 0.25937138, grad/param norm = 1.9454e-01, time/batch = 15.7933s	
20682/22300 (epoch 46.372), train_loss = 0.17847835, grad/param norm = 1.8932e-01, time/batch = 15.4379s	
20683/22300 (epoch 46.374), train_loss = 0.19807064, grad/param norm = 1.7382e-01, time/batch = 16.3088s	
20684/22300 (epoch 46.377), train_loss = 0.26767346, grad/param norm = 1.7285e-01, time/batch = 15.5960s	
20685/22300 (epoch 46.379), train_loss = 0.24421912, grad/param norm = 1.9893e-01, time/batch = 14.6168s	
20686/22300 (epoch 46.381), train_loss = 0.33250003, grad/param norm = 2.3177e-01, time/batch = 15.1193s	
20687/22300 (epoch 46.383), train_loss = 0.25167262, grad/param norm = 2.3661e-01, time/batch = 15.4580s	
20688/22300 (epoch 46.386), train_loss = 0.30228998, grad/param norm = 1.8575e-01, time/batch = 14.9057s	
20689/22300 (epoch 46.388), train_loss = 0.20001220, grad/param norm = 2.0158e-01, time/batch = 15.5572s	
20690/22300 (epoch 46.390), train_loss = 0.24970018, grad/param norm = 3.1931e-01, time/batch = 15.4882s	
20691/22300 (epoch 46.392), train_loss = 0.27720513, grad/param norm = 2.4511e-01, time/batch = 15.5688s	
20692/22300 (epoch 46.395), train_loss = 0.22229260, grad/param norm = 2.0229e-01, time/batch = 16.1580s	
20693/22300 (epoch 46.397), train_loss = 0.15674209, grad/param norm = 1.5299e-01, time/batch = 15.6272s	
20694/22300 (epoch 46.399), train_loss = 0.23137930, grad/param norm = 2.6183e-01, time/batch = 15.2330s	
20695/22300 (epoch 46.401), train_loss = 0.24908079, grad/param norm = 2.2953e-01, time/batch = 16.5536s	
20696/22300 (epoch 46.404), train_loss = 0.28361230, grad/param norm = 2.0591e-01, time/batch = 16.4523s	
20697/22300 (epoch 46.406), train_loss = 0.41982903, grad/param norm = 2.7110e-01, time/batch = 16.5261s	
20698/22300 (epoch 46.408), train_loss = 0.30182028, grad/param norm = 2.3007e-01, time/batch = 15.9549s	
20699/22300 (epoch 46.410), train_loss = 0.34610705, grad/param norm = 2.3493e-01, time/batch = 16.1449s	
20700/22300 (epoch 46.413), train_loss = 0.26469498, grad/param norm = 2.0570e-01, time/batch = 16.3336s	
20701/22300 (epoch 46.415), train_loss = 0.20354131, grad/param norm = 2.1852e-01, time/batch = 15.3043s	
20702/22300 (epoch 46.417), train_loss = 0.30435254, grad/param norm = 2.3720e-01, time/batch = 15.4317s	
20703/22300 (epoch 46.419), train_loss = 0.26714417, grad/param norm = 1.6818e-01, time/batch = 15.9211s	
20704/22300 (epoch 46.422), train_loss = 0.23289771, grad/param norm = 2.2842e-01, time/batch = 15.4741s	
20705/22300 (epoch 46.424), train_loss = 0.27340517, grad/param norm = 2.1215e-01, time/batch = 24.8544s	
20706/22300 (epoch 46.426), train_loss = 0.20223508, grad/param norm = 1.7975e-01, time/batch = 23.0095s	
20707/22300 (epoch 46.428), train_loss = 0.21296064, grad/param norm = 1.6511e-01, time/batch = 15.7389s	
20708/22300 (epoch 46.430), train_loss = 0.24728839, grad/param norm = 2.3773e-01, time/batch = 16.8285s	
20709/22300 (epoch 46.433), train_loss = 0.26239136, grad/param norm = 1.9291e-01, time/batch = 15.1115s	
20710/22300 (epoch 46.435), train_loss = 0.24403170, grad/param norm = 1.9455e-01, time/batch = 14.7326s	
20711/22300 (epoch 46.437), train_loss = 0.28625704, grad/param norm = 1.8382e-01, time/batch = 15.2119s	
20712/22300 (epoch 46.439), train_loss = 0.32356235, grad/param norm = 2.5654e-01, time/batch = 14.3242s	
20713/22300 (epoch 46.442), train_loss = 0.27101610, grad/param norm = 2.4574e-01, time/batch = 14.4756s	
20714/22300 (epoch 46.444), train_loss = 0.24572144, grad/param norm = 2.1889e-01, time/batch = 14.4115s	
20715/22300 (epoch 46.446), train_loss = 0.26804274, grad/param norm = 1.8165e-01, time/batch = 14.4035s	
20716/22300 (epoch 46.448), train_loss = 0.20662228, grad/param norm = 1.4222e-01, time/batch = 14.4161s	
20717/22300 (epoch 46.451), train_loss = 0.32035085, grad/param norm = 2.4761e-01, time/batch = 14.4097s	
20718/22300 (epoch 46.453), train_loss = 0.24735149, grad/param norm = 2.0726e-01, time/batch = 15.4368s	
20719/22300 (epoch 46.455), train_loss = 0.34941675, grad/param norm = 2.8858e-01, time/batch = 14.7966s	
20720/22300 (epoch 46.457), train_loss = 0.46768687, grad/param norm = 3.3914e-01, time/batch = 14.4084s	
20721/22300 (epoch 46.460), train_loss = 0.37950609, grad/param norm = 2.3382e-01, time/batch = 14.6541s	
20722/22300 (epoch 46.462), train_loss = 0.36658743, grad/param norm = 2.0585e-01, time/batch = 15.4346s	
20723/22300 (epoch 46.464), train_loss = 0.31611167, grad/param norm = 2.5679e-01, time/batch = 15.2009s	
20724/22300 (epoch 46.466), train_loss = 0.25059809, grad/param norm = 1.7377e-01, time/batch = 14.7066s	
20725/22300 (epoch 46.469), train_loss = 0.25220534, grad/param norm = 1.6017e-01, time/batch = 14.8209s	
20726/22300 (epoch 46.471), train_loss = 0.35241627, grad/param norm = 1.9642e-01, time/batch = 14.6533s	
20727/22300 (epoch 46.473), train_loss = 0.30446179, grad/param norm = 2.0519e-01, time/batch = 15.1891s	
20728/22300 (epoch 46.475), train_loss = 0.25976149, grad/param norm = 2.3398e-01, time/batch = 14.8732s	
20729/22300 (epoch 46.478), train_loss = 0.25924324, grad/param norm = 2.0598e-01, time/batch = 14.7569s	
20730/22300 (epoch 46.480), train_loss = 0.19054173, grad/param norm = 1.5763e-01, time/batch = 14.8966s	
20731/22300 (epoch 46.482), train_loss = 0.23020398, grad/param norm = 1.6364e-01, time/batch = 15.1950s	
20732/22300 (epoch 46.484), train_loss = 0.29871452, grad/param norm = 2.2464e-01, time/batch = 15.0664s	
20733/22300 (epoch 46.487), train_loss = 0.34505842, grad/param norm = 1.9739e-01, time/batch = 14.5805s	
20734/22300 (epoch 46.489), train_loss = 0.33475138, grad/param norm = 2.3699e-01, time/batch = 14.4078s	
20735/22300 (epoch 46.491), train_loss = 0.38736477, grad/param norm = 3.3664e-01, time/batch = 14.4901s	
20736/22300 (epoch 46.493), train_loss = 0.25733133, grad/param norm = 3.4293e-01, time/batch = 14.6430s	
20737/22300 (epoch 46.496), train_loss = 0.32632469, grad/param norm = 1.9222e-01, time/batch = 14.1699s	
20738/22300 (epoch 46.498), train_loss = 0.19419610, grad/param norm = 1.5467e-01, time/batch = 14.6465s	
20739/22300 (epoch 46.500), train_loss = 0.29633977, grad/param norm = 2.1659e-01, time/batch = 14.7116s	
20740/22300 (epoch 46.502), train_loss = 0.18237488, grad/param norm = 1.8117e-01, time/batch = 14.7444s	
20741/22300 (epoch 46.504), train_loss = 0.19447966, grad/param norm = 1.5006e-01, time/batch = 14.6553s	
20742/22300 (epoch 46.507), train_loss = 0.23291794, grad/param norm = 2.3697e-01, time/batch = 14.9655s	
20743/22300 (epoch 46.509), train_loss = 0.32726584, grad/param norm = 2.1692e-01, time/batch = 14.5586s	
20744/22300 (epoch 46.511), train_loss = 0.18891881, grad/param norm = 1.8738e-01, time/batch = 15.2612s	
20745/22300 (epoch 46.513), train_loss = 0.20591784, grad/param norm = 1.5777e-01, time/batch = 14.5698s	
20746/22300 (epoch 46.516), train_loss = 0.23960273, grad/param norm = 1.8663e-01, time/batch = 14.7979s	
20747/22300 (epoch 46.518), train_loss = 0.29236574, grad/param norm = 2.4547e-01, time/batch = 14.3238s	
20748/22300 (epoch 46.520), train_loss = 0.24186648, grad/param norm = 2.4552e-01, time/batch = 14.9605s	
20749/22300 (epoch 46.522), train_loss = 0.28487476, grad/param norm = 1.8380e-01, time/batch = 14.9408s	
20750/22300 (epoch 46.525), train_loss = 0.21817252, grad/param norm = 1.8506e-01, time/batch = 14.4697s	
20751/22300 (epoch 46.527), train_loss = 0.34506704, grad/param norm = 3.0170e-01, time/batch = 14.6505s	
20752/22300 (epoch 46.529), train_loss = 0.29953909, grad/param norm = 2.8541e-01, time/batch = 14.7186s	
20753/22300 (epoch 46.531), train_loss = 0.24564136, grad/param norm = 1.9019e-01, time/batch = 14.5692s	
20754/22300 (epoch 46.534), train_loss = 0.29649557, grad/param norm = 2.0856e-01, time/batch = 14.4060s	
20755/22300 (epoch 46.536), train_loss = 0.41949078, grad/param norm = 2.8621e-01, time/batch = 14.4311s	
20756/22300 (epoch 46.538), train_loss = 0.50351696, grad/param norm = 3.1216e-01, time/batch = 14.9658s	
20757/22300 (epoch 46.540), train_loss = 0.27336173, grad/param norm = 1.9692e-01, time/batch = 14.2591s	
20758/22300 (epoch 46.543), train_loss = 0.29872323, grad/param norm = 1.8178e-01, time/batch = 14.5524s	
20759/22300 (epoch 46.545), train_loss = 0.18855706, grad/param norm = 1.6040e-01, time/batch = 14.4836s	
20760/22300 (epoch 46.547), train_loss = 0.17967475, grad/param norm = 1.8186e-01, time/batch = 14.8715s	
20761/22300 (epoch 46.549), train_loss = 0.20077417, grad/param norm = 1.7562e-01, time/batch = 14.0882s	
20762/22300 (epoch 46.552), train_loss = 0.22342723, grad/param norm = 2.5518e-01, time/batch = 14.7399s	
20763/22300 (epoch 46.554), train_loss = 0.32154315, grad/param norm = 2.8035e-01, time/batch = 14.4921s	
20764/22300 (epoch 46.556), train_loss = 0.43553711, grad/param norm = 3.2773e-01, time/batch = 15.2048s	
20765/22300 (epoch 46.558), train_loss = 0.30433330, grad/param norm = 2.4175e-01, time/batch = 14.3440s	
20766/22300 (epoch 46.561), train_loss = 0.45763808, grad/param norm = 3.4845e-01, time/batch = 15.2055s	
20767/22300 (epoch 46.563), train_loss = 0.35632751, grad/param norm = 3.3636e-01, time/batch = 14.5759s	
20768/22300 (epoch 46.565), train_loss = 0.27683229, grad/param norm = 2.1926e-01, time/batch = 14.8679s	
20769/22300 (epoch 46.567), train_loss = 0.26461599, grad/param norm = 2.5122e-01, time/batch = 14.4938s	
20770/22300 (epoch 46.570), train_loss = 0.38296627, grad/param norm = 2.9240e-01, time/batch = 15.2804s	
20771/22300 (epoch 46.572), train_loss = 0.38194776, grad/param norm = 2.8465e-01, time/batch = 15.8346s	
20772/22300 (epoch 46.574), train_loss = 0.28102237, grad/param norm = 2.0513e-01, time/batch = 16.1311s	
20773/22300 (epoch 46.576), train_loss = 0.24738841, grad/param norm = 1.6914e-01, time/batch = 15.4787s	
20774/22300 (epoch 46.578), train_loss = 0.14313994, grad/param norm = 1.5102e-01, time/batch = 15.6497s	
20775/22300 (epoch 46.581), train_loss = 0.22654378, grad/param norm = 2.2852e-01, time/batch = 15.9213s	
20776/22300 (epoch 46.583), train_loss = 0.26721580, grad/param norm = 1.8679e-01, time/batch = 15.7996s	
20777/22300 (epoch 46.585), train_loss = 0.34783593, grad/param norm = 3.0758e-01, time/batch = 15.8725s	
20778/22300 (epoch 46.587), train_loss = 0.51583453, grad/param norm = 3.0774e-01, time/batch = 15.8859s	
20779/22300 (epoch 46.590), train_loss = 0.38784508, grad/param norm = 3.0255e-01, time/batch = 15.6879s	
20780/22300 (epoch 46.592), train_loss = 0.47189916, grad/param norm = 2.8677e-01, time/batch = 15.7961s	
20781/22300 (epoch 46.594), train_loss = 0.45033081, grad/param norm = 3.2635e-01, time/batch = 15.8083s	
20782/22300 (epoch 46.596), train_loss = 0.30355711, grad/param norm = 2.0083e-01, time/batch = 15.5614s	
20783/22300 (epoch 46.599), train_loss = 0.20756595, grad/param norm = 2.6401e-01, time/batch = 15.7080s	
20784/22300 (epoch 46.601), train_loss = 0.24375005, grad/param norm = 2.4630e-01, time/batch = 15.8801s	
20785/22300 (epoch 46.603), train_loss = 0.23823522, grad/param norm = 1.9238e-01, time/batch = 15.7938s	
20786/22300 (epoch 46.605), train_loss = 0.27977680, grad/param norm = 2.4724e-01, time/batch = 15.7975s	
20787/22300 (epoch 46.608), train_loss = 0.45440885, grad/param norm = 2.8391e-01, time/batch = 15.7836s	
20788/22300 (epoch 46.610), train_loss = 0.52608965, grad/param norm = 3.0898e-01, time/batch = 15.7003s	
20789/22300 (epoch 46.612), train_loss = 0.37334860, grad/param norm = 2.7672e-01, time/batch = 15.6827s	
20790/22300 (epoch 46.614), train_loss = 0.34461122, grad/param norm = 3.1995e-01, time/batch = 15.8742s	
20791/22300 (epoch 46.617), train_loss = 0.39261921, grad/param norm = 3.3543e-01, time/batch = 15.9076s	
20792/22300 (epoch 46.619), train_loss = 0.36902463, grad/param norm = 2.8752e-01, time/batch = 15.9290s	
20793/22300 (epoch 46.621), train_loss = 0.25867386, grad/param norm = 2.2809e-01, time/batch = 15.8587s	
20794/22300 (epoch 46.623), train_loss = 0.25999046, grad/param norm = 1.9171e-01, time/batch = 15.6395s	
20795/22300 (epoch 46.626), train_loss = 0.25021165, grad/param norm = 1.9300e-01, time/batch = 15.7368s	
20796/22300 (epoch 46.628), train_loss = 0.26550553, grad/param norm = 1.8945e-01, time/batch = 15.6509s	
20797/22300 (epoch 46.630), train_loss = 0.31820848, grad/param norm = 2.3508e-01, time/batch = 15.4748s	
20798/22300 (epoch 46.632), train_loss = 0.28207042, grad/param norm = 2.7792e-01, time/batch = 15.5416s	
20799/22300 (epoch 46.635), train_loss = 0.31854077, grad/param norm = 2.4436e-01, time/batch = 15.8930s	
20800/22300 (epoch 46.637), train_loss = 0.33343865, grad/param norm = 2.3068e-01, time/batch = 15.6276s	
20801/22300 (epoch 46.639), train_loss = 0.42118499, grad/param norm = 3.0055e-01, time/batch = 16.0629s	
20802/22300 (epoch 46.641), train_loss = 0.32166048, grad/param norm = 2.3425e-01, time/batch = 15.7772s	
20803/22300 (epoch 46.643), train_loss = 0.25561152, grad/param norm = 2.0639e-01, time/batch = 15.7153s	
20804/22300 (epoch 46.646), train_loss = 0.26675677, grad/param norm = 2.4605e-01, time/batch = 15.9334s	
20805/22300 (epoch 46.648), train_loss = 0.36671544, grad/param norm = 2.7241e-01, time/batch = 15.8242s	
20806/22300 (epoch 46.650), train_loss = 0.36432796, grad/param norm = 2.7639e-01, time/batch = 15.8816s	
20807/22300 (epoch 46.652), train_loss = 0.25976640, grad/param norm = 1.9074e-01, time/batch = 15.6580s	
20808/22300 (epoch 46.655), train_loss = 0.22817069, grad/param norm = 1.8730e-01, time/batch = 15.6502s	
20809/22300 (epoch 46.657), train_loss = 0.28199105, grad/param norm = 2.5201e-01, time/batch = 15.6938s	
20810/22300 (epoch 46.659), train_loss = 0.26773430, grad/param norm = 2.6163e-01, time/batch = 15.8438s	
20811/22300 (epoch 46.661), train_loss = 0.21615774, grad/param norm = 1.9110e-01, time/batch = 16.2062s	
20812/22300 (epoch 46.664), train_loss = 0.26808748, grad/param norm = 1.8254e-01, time/batch = 15.7189s	
20813/22300 (epoch 46.666), train_loss = 0.33416965, grad/param norm = 2.5147e-01, time/batch = 15.9670s	
20814/22300 (epoch 46.668), train_loss = 0.26370533, grad/param norm = 2.2796e-01, time/batch = 16.0670s	
20815/22300 (epoch 46.670), train_loss = 0.31262167, grad/param norm = 4.0005e-01, time/batch = 16.0067s	
20816/22300 (epoch 46.673), train_loss = 0.40355281, grad/param norm = 2.8709e-01, time/batch = 15.9561s	
20817/22300 (epoch 46.675), train_loss = 0.41596649, grad/param norm = 3.8829e-01, time/batch = 15.7006s	
20818/22300 (epoch 46.677), train_loss = 0.47601116, grad/param norm = 3.0939e-01, time/batch = 16.2515s	
20819/22300 (epoch 46.679), train_loss = 0.30530344, grad/param norm = 2.7645e-01, time/batch = 16.1407s	
20820/22300 (epoch 46.682), train_loss = 0.29941005, grad/param norm = 2.3726e-01, time/batch = 16.0369s	
20821/22300 (epoch 46.684), train_loss = 0.29985866, grad/param norm = 2.1606e-01, time/batch = 16.2494s	
20822/22300 (epoch 46.686), train_loss = 0.27587184, grad/param norm = 2.2519e-01, time/batch = 16.3159s	
20823/22300 (epoch 46.688), train_loss = 0.25479354, grad/param norm = 2.4410e-01, time/batch = 15.8684s	
20824/22300 (epoch 46.691), train_loss = 0.26168533, grad/param norm = 2.9708e-01, time/batch = 15.8832s	
20825/22300 (epoch 46.693), train_loss = 0.24329947, grad/param norm = 2.6288e-01, time/batch = 15.9800s	
20826/22300 (epoch 46.695), train_loss = 0.27491565, grad/param norm = 2.2618e-01, time/batch = 15.8788s	
20827/22300 (epoch 46.697), train_loss = 0.27722037, grad/param norm = 1.6892e-01, time/batch = 15.7325s	
20828/22300 (epoch 46.700), train_loss = 0.23940537, grad/param norm = 2.0248e-01, time/batch = 15.5993s	
20829/22300 (epoch 46.702), train_loss = 0.19933691, grad/param norm = 1.8520e-01, time/batch = 16.0828s	
20830/22300 (epoch 46.704), train_loss = 0.24996566, grad/param norm = 2.1026e-01, time/batch = 15.8864s	
20831/22300 (epoch 46.706), train_loss = 0.24539405, grad/param norm = 2.5832e-01, time/batch = 15.8541s	
20832/22300 (epoch 46.709), train_loss = 0.19006791, grad/param norm = 1.5337e-01, time/batch = 15.8753s	
20833/22300 (epoch 46.711), train_loss = 0.19007637, grad/param norm = 1.3772e-01, time/batch = 15.8844s	
20834/22300 (epoch 46.713), train_loss = 0.29496490, grad/param norm = 2.1243e-01, time/batch = 15.8652s	
20835/22300 (epoch 46.715), train_loss = 0.31724421, grad/param norm = 2.1366e-01, time/batch = 15.8883s	
20836/22300 (epoch 46.717), train_loss = 0.41099073, grad/param norm = 2.4844e-01, time/batch = 16.0944s	
20837/22300 (epoch 46.720), train_loss = 0.23786444, grad/param norm = 2.0018e-01, time/batch = 15.7236s	
20838/22300 (epoch 46.722), train_loss = 0.28367939, grad/param norm = 2.1480e-01, time/batch = 15.4681s	
20839/22300 (epoch 46.724), train_loss = 0.30959045, grad/param norm = 2.6834e-01, time/batch = 15.5480s	
20840/22300 (epoch 46.726), train_loss = 0.24836388, grad/param norm = 2.2521e-01, time/batch = 16.1997s	
20841/22300 (epoch 46.729), train_loss = 0.30454243, grad/param norm = 2.2150e-01, time/batch = 15.9660s	
20842/22300 (epoch 46.731), train_loss = 0.36111384, grad/param norm = 3.1019e-01, time/batch = 15.5656s	
20843/22300 (epoch 46.733), train_loss = 0.37403753, grad/param norm = 3.2040e-01, time/batch = 15.5602s	
20844/22300 (epoch 46.735), train_loss = 0.39641481, grad/param norm = 2.8293e-01, time/batch = 15.6467s	
20845/22300 (epoch 46.738), train_loss = 0.27596808, grad/param norm = 2.5135e-01, time/batch = 15.8873s	
20846/22300 (epoch 46.740), train_loss = 0.25351621, grad/param norm = 1.5910e-01, time/batch = 15.8981s	
20847/22300 (epoch 46.742), train_loss = 0.23571375, grad/param norm = 2.2562e-01, time/batch = 16.0411s	
20848/22300 (epoch 46.744), train_loss = 0.42297962, grad/param norm = 2.7553e-01, time/batch = 16.0497s	
20849/22300 (epoch 46.747), train_loss = 0.35131937, grad/param norm = 2.7039e-01, time/batch = 15.7164s	
20850/22300 (epoch 46.749), train_loss = 0.42845745, grad/param norm = 2.5755e-01, time/batch = 15.9802s	
20851/22300 (epoch 46.751), train_loss = 0.35307816, grad/param norm = 3.3528e-01, time/batch = 15.7510s	
20852/22300 (epoch 46.753), train_loss = 0.41967790, grad/param norm = 3.4911e-01, time/batch = 15.1781s	
20853/22300 (epoch 46.756), train_loss = 0.41158822, grad/param norm = 3.1956e-01, time/batch = 15.1244s	
20854/22300 (epoch 46.758), train_loss = 0.31592654, grad/param norm = 2.2973e-01, time/batch = 15.2688s	
20855/22300 (epoch 46.760), train_loss = 0.32196863, grad/param norm = 1.9991e-01, time/batch = 14.7169s	
20856/22300 (epoch 46.762), train_loss = 0.31261057, grad/param norm = 2.4838e-01, time/batch = 14.5009s	
20857/22300 (epoch 46.765), train_loss = 0.36266436, grad/param norm = 2.8765e-01, time/batch = 14.6576s	
20858/22300 (epoch 46.767), train_loss = 0.31367873, grad/param norm = 2.8618e-01, time/batch = 14.4115s	
20859/22300 (epoch 46.769), train_loss = 0.31104809, grad/param norm = 3.0618e-01, time/batch = 15.0939s	
20860/22300 (epoch 46.771), train_loss = 0.37712359, grad/param norm = 3.4795e-01, time/batch = 15.1896s	
20861/22300 (epoch 46.774), train_loss = 0.41125650, grad/param norm = 2.9574e-01, time/batch = 15.2079s	
20862/22300 (epoch 46.776), train_loss = 0.40454953, grad/param norm = 2.3731e-01, time/batch = 14.4868s	
20863/22300 (epoch 46.778), train_loss = 0.40806947, grad/param norm = 2.7700e-01, time/batch = 15.1271s	
20864/22300 (epoch 46.780), train_loss = 0.41254239, grad/param norm = 3.1087e-01, time/batch = 14.4955s	
20865/22300 (epoch 46.783), train_loss = 0.43568242, grad/param norm = 3.1255e-01, time/batch = 14.4827s	
20866/22300 (epoch 46.785), train_loss = 0.26834875, grad/param norm = 1.9724e-01, time/batch = 14.4108s	
20867/22300 (epoch 46.787), train_loss = 0.29612918, grad/param norm = 2.0780e-01, time/batch = 14.9007s	
20868/22300 (epoch 46.789), train_loss = 0.44247402, grad/param norm = 2.9382e-01, time/batch = 14.9045s	
20869/22300 (epoch 46.791), train_loss = 0.52579407, grad/param norm = 3.0483e-01, time/batch = 14.8940s	
20870/22300 (epoch 46.794), train_loss = 0.43306835, grad/param norm = 2.8744e-01, time/batch = 14.7388s	
20871/22300 (epoch 46.796), train_loss = 0.36737457, grad/param norm = 2.9656e-01, time/batch = 14.9814s	
20872/22300 (epoch 46.798), train_loss = 0.51269676, grad/param norm = 3.1629e-01, time/batch = 14.4891s	
20873/22300 (epoch 46.800), train_loss = 0.34554323, grad/param norm = 2.2013e-01, time/batch = 14.7267s	
20874/22300 (epoch 46.803), train_loss = 0.30964730, grad/param norm = 2.1910e-01, time/batch = 15.1102s	
20875/22300 (epoch 46.805), train_loss = 0.34493475, grad/param norm = 2.4618e-01, time/batch = 14.4127s	
20876/22300 (epoch 46.807), train_loss = 0.46530591, grad/param norm = 3.8289e-01, time/batch = 14.2444s	
20877/22300 (epoch 46.809), train_loss = 0.33254803, grad/param norm = 2.8843e-01, time/batch = 14.4039s	
20878/22300 (epoch 46.812), train_loss = 0.35285566, grad/param norm = 2.5870e-01, time/batch = 14.0971s	
20879/22300 (epoch 46.814), train_loss = 0.34975354, grad/param norm = 2.6557e-01, time/batch = 14.4090s	
20880/22300 (epoch 46.816), train_loss = 0.36855823, grad/param norm = 2.5831e-01, time/batch = 14.3193s	
20881/22300 (epoch 46.818), train_loss = 0.43203382, grad/param norm = 2.8702e-01, time/batch = 14.6552s	
20882/22300 (epoch 46.821), train_loss = 0.34269581, grad/param norm = 2.2346e-01, time/batch = 14.1635s	
20883/22300 (epoch 46.823), train_loss = 0.23922199, grad/param norm = 2.0035e-01, time/batch = 14.8837s	
20884/22300 (epoch 46.825), train_loss = 0.25064912, grad/param norm = 2.1280e-01, time/batch = 14.7858s	
20885/22300 (epoch 46.827), train_loss = 0.27975314, grad/param norm = 2.2231e-01, time/batch = 14.4184s	
20886/22300 (epoch 46.830), train_loss = 0.29713942, grad/param norm = 2.6105e-01, time/batch = 14.0822s	
20887/22300 (epoch 46.832), train_loss = 0.29134867, grad/param norm = 2.2657e-01, time/batch = 14.1644s	
20888/22300 (epoch 46.834), train_loss = 0.23621769, grad/param norm = 2.0256e-01, time/batch = 14.2490s	
20889/22300 (epoch 46.836), train_loss = 0.29615270, grad/param norm = 2.3632e-01, time/batch = 14.5106s	
20890/22300 (epoch 46.839), train_loss = 0.33606708, grad/param norm = 2.5512e-01, time/batch = 14.8242s	
20891/22300 (epoch 46.841), train_loss = 0.27181087, grad/param norm = 2.7243e-01, time/batch = 14.7428s	
20892/22300 (epoch 46.843), train_loss = 0.30215352, grad/param norm = 2.0549e-01, time/batch = 15.0529s	
20893/22300 (epoch 46.845), train_loss = 0.32649986, grad/param norm = 2.3059e-01, time/batch = 15.3436s	
20894/22300 (epoch 46.848), train_loss = 0.27714294, grad/param norm = 2.1365e-01, time/batch = 14.7093s	
20895/22300 (epoch 46.850), train_loss = 0.32032848, grad/param norm = 2.0576e-01, time/batch = 15.5756s	
20896/22300 (epoch 46.852), train_loss = 0.29528943, grad/param norm = 3.1220e-01, time/batch = 15.0927s	
20897/22300 (epoch 46.854), train_loss = 0.48661480, grad/param norm = 3.0478e-01, time/batch = 15.1952s	
20898/22300 (epoch 46.857), train_loss = 0.34091240, grad/param norm = 2.7586e-01, time/batch = 14.4074s	
20899/22300 (epoch 46.859), train_loss = 0.27072799, grad/param norm = 1.7331e-01, time/batch = 14.3243s	
20900/22300 (epoch 46.861), train_loss = 0.38447879, grad/param norm = 2.2419e-01, time/batch = 14.6521s	
20901/22300 (epoch 46.863), train_loss = 0.22823172, grad/param norm = 2.0960e-01, time/batch = 14.4926s	
20902/22300 (epoch 46.865), train_loss = 0.24708241, grad/param norm = 2.2108e-01, time/batch = 14.7316s	
20903/22300 (epoch 46.868), train_loss = 0.32818853, grad/param norm = 2.0762e-01, time/batch = 14.6395s	
20904/22300 (epoch 46.870), train_loss = 0.33111815, grad/param norm = 2.4252e-01, time/batch = 15.0477s	
20905/22300 (epoch 46.872), train_loss = 0.41788288, grad/param norm = 2.3108e-01, time/batch = 14.4944s	
20906/22300 (epoch 46.874), train_loss = 0.37475882, grad/param norm = 3.2184e-01, time/batch = 14.5030s	
20907/22300 (epoch 46.877), train_loss = 0.31077795, grad/param norm = 1.9213e-01, time/batch = 15.1284s	
20908/22300 (epoch 46.879), train_loss = 0.31170551, grad/param norm = 2.2181e-01, time/batch = 15.0554s	
20909/22300 (epoch 46.881), train_loss = 0.23615066, grad/param norm = 2.1665e-01, time/batch = 14.7883s	
20910/22300 (epoch 46.883), train_loss = 0.25130874, grad/param norm = 2.7705e-01, time/batch = 14.7977s	
20911/22300 (epoch 46.886), train_loss = 0.22490473, grad/param norm = 2.2286e-01, time/batch = 14.0916s	
20912/22300 (epoch 46.888), train_loss = 0.28668860, grad/param norm = 2.1585e-01, time/batch = 14.8843s	
20913/22300 (epoch 46.890), train_loss = 0.28306133, grad/param norm = 2.5584e-01, time/batch = 14.6689s	
20914/22300 (epoch 46.892), train_loss = 0.44612208, grad/param norm = 2.9209e-01, time/batch = 15.2691s	
20915/22300 (epoch 46.895), train_loss = 0.38926455, grad/param norm = 2.7517e-01, time/batch = 14.4800s	
20916/22300 (epoch 46.897), train_loss = 0.29332472, grad/param norm = 2.3719e-01, time/batch = 15.1247s	
20917/22300 (epoch 46.899), train_loss = 0.31281056, grad/param norm = 2.4276e-01, time/batch = 17.8937s	
20918/22300 (epoch 46.901), train_loss = 0.36820518, grad/param norm = 2.4135e-01, time/batch = 15.3010s	
20919/22300 (epoch 46.904), train_loss = 0.34482176, grad/param norm = 2.5344e-01, time/batch = 15.5375s	
20920/22300 (epoch 46.906), train_loss = 0.33462884, grad/param norm = 2.4622e-01, time/batch = 16.3513s	
20921/22300 (epoch 46.908), train_loss = 0.30148110, grad/param norm = 1.9775e-01, time/batch = 14.6558s	
20922/22300 (epoch 46.910), train_loss = 0.27707008, grad/param norm = 2.2779e-01, time/batch = 15.2886s	
20923/22300 (epoch 46.913), train_loss = 0.35053144, grad/param norm = 2.8917e-01, time/batch = 15.7240s	
20924/22300 (epoch 46.915), train_loss = 0.43246427, grad/param norm = 2.9271e-01, time/batch = 15.4731s	
20925/22300 (epoch 46.917), train_loss = 0.36911171, grad/param norm = 3.1175e-01, time/batch = 15.4545s	
20926/22300 (epoch 46.919), train_loss = 0.32815341, grad/param norm = 2.0145e-01, time/batch = 14.8932s	
20927/22300 (epoch 46.922), train_loss = 0.31260744, grad/param norm = 2.4488e-01, time/batch = 17.0417s	
20928/22300 (epoch 46.924), train_loss = 0.21128923, grad/param norm = 1.7242e-01, time/batch = 15.1777s	
20929/22300 (epoch 46.926), train_loss = 0.26454599, grad/param norm = 1.6655e-01, time/batch = 15.2091s	
20930/22300 (epoch 46.928), train_loss = 0.29003914, grad/param norm = 2.2876e-01, time/batch = 16.6305s	
20931/22300 (epoch 46.930), train_loss = 0.26673063, grad/param norm = 2.3779e-01, time/batch = 15.6309s	
20932/22300 (epoch 46.933), train_loss = 0.35654144, grad/param norm = 2.9916e-01, time/batch = 15.9868s	
20933/22300 (epoch 46.935), train_loss = 0.32721029, grad/param norm = 2.6847e-01, time/batch = 14.8860s	
20934/22300 (epoch 46.937), train_loss = 0.40120208, grad/param norm = 3.0738e-01, time/batch = 15.1390s	
20935/22300 (epoch 46.939), train_loss = 0.36116887, grad/param norm = 2.2846e-01, time/batch = 16.0393s	
20936/22300 (epoch 46.942), train_loss = 0.44494012, grad/param norm = 3.1684e-01, time/batch = 16.4553s	
20937/22300 (epoch 46.944), train_loss = 0.49671822, grad/param norm = 4.0431e-01, time/batch = 15.3270s	
20938/22300 (epoch 46.946), train_loss = 0.36403886, grad/param norm = 2.7796e-01, time/batch = 18.5878s	
20939/22300 (epoch 46.948), train_loss = 0.31153126, grad/param norm = 1.8231e-01, time/batch = 31.1880s	
20940/22300 (epoch 46.951), train_loss = 0.23442307, grad/param norm = 1.9648e-01, time/batch = 15.3323s	
20941/22300 (epoch 46.953), train_loss = 0.25013209, grad/param norm = 2.4584e-01, time/batch = 15.5930s	
20942/22300 (epoch 46.955), train_loss = 0.41846488, grad/param norm = 2.8758e-01, time/batch = 15.6297s	
20943/22300 (epoch 46.957), train_loss = 0.48236899, grad/param norm = 2.7571e-01, time/batch = 15.3182s	
20944/22300 (epoch 46.960), train_loss = 0.42179972, grad/param norm = 2.5722e-01, time/batch = 15.2349s	
20945/22300 (epoch 46.962), train_loss = 0.26255157, grad/param norm = 2.3364e-01, time/batch = 15.4703s	
20946/22300 (epoch 46.964), train_loss = 0.26013891, grad/param norm = 2.2151e-01, time/batch = 15.6137s	
20947/22300 (epoch 46.966), train_loss = 0.28669019, grad/param norm = 2.0599e-01, time/batch = 15.0662s	
20948/22300 (epoch 46.969), train_loss = 0.29514247, grad/param norm = 1.7976e-01, time/batch = 15.2853s	
20949/22300 (epoch 46.971), train_loss = 0.31597770, grad/param norm = 1.8188e-01, time/batch = 15.3781s	
20950/22300 (epoch 46.973), train_loss = 0.29587017, grad/param norm = 2.7476e-01, time/batch = 15.4463s	
20951/22300 (epoch 46.975), train_loss = 0.42396498, grad/param norm = 3.2961e-01, time/batch = 15.4086s	
20952/22300 (epoch 46.978), train_loss = 0.42768404, grad/param norm = 2.5557e-01, time/batch = 15.6107s	
20953/22300 (epoch 46.980), train_loss = 0.48392463, grad/param norm = 2.8669e-01, time/batch = 15.6039s	
20954/22300 (epoch 46.982), train_loss = 0.23848735, grad/param norm = 2.4098e-01, time/batch = 15.0870s	
20955/22300 (epoch 46.984), train_loss = 0.32260782, grad/param norm = 2.4457e-01, time/batch = 14.9927s	
20956/22300 (epoch 46.987), train_loss = 0.32103047, grad/param norm = 2.2132e-01, time/batch = 14.9005s	
20957/22300 (epoch 46.989), train_loss = 0.26828332, grad/param norm = 3.0836e-01, time/batch = 15.7699s	
20958/22300 (epoch 46.991), train_loss = 0.46990571, grad/param norm = 3.5652e-01, time/batch = 15.4536s	
20959/22300 (epoch 46.993), train_loss = 0.63697312, grad/param norm = 3.5000e-01, time/batch = 15.0609s	
20960/22300 (epoch 46.996), train_loss = 0.60671442, grad/param norm = 3.6590e-01, time/batch = 14.8161s	
20961/22300 (epoch 46.998), train_loss = 0.36848030, grad/param norm = 2.7070e-01, time/batch = 15.2926s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
20962/22300 (epoch 47.000), train_loss = 0.27574579, grad/param norm = 2.1210e-01, time/batch = 15.0668s	
20963/22300 (epoch 47.002), train_loss = 0.63125747, grad/param norm = 3.2018e-01, time/batch = 15.3624s	
20964/22300 (epoch 47.004), train_loss = 0.36841274, grad/param norm = 2.2204e-01, time/batch = 15.3107s	
20965/22300 (epoch 47.007), train_loss = 0.41535137, grad/param norm = 3.3945e-01, time/batch = 15.2182s	
20966/22300 (epoch 47.009), train_loss = 0.38538497, grad/param norm = 2.8372e-01, time/batch = 15.0596s	
20967/22300 (epoch 47.011), train_loss = 0.49848925, grad/param norm = 3.1039e-01, time/batch = 15.3160s	
20968/22300 (epoch 47.013), train_loss = 0.39724514, grad/param norm = 2.2927e-01, time/batch = 15.5919s	
20969/22300 (epoch 47.016), train_loss = 0.27886667, grad/param norm = 2.1746e-01, time/batch = 15.5410s	
20970/22300 (epoch 47.018), train_loss = 0.31029506, grad/param norm = 2.3633e-01, time/batch = 15.4418s	
20971/22300 (epoch 47.020), train_loss = 0.32383657, grad/param norm = 2.6323e-01, time/batch = 15.7216s	
20972/22300 (epoch 47.022), train_loss = 0.24461756, grad/param norm = 2.5735e-01, time/batch = 15.2974s	
20973/22300 (epoch 47.025), train_loss = 0.29314398, grad/param norm = 2.4846e-01, time/batch = 15.3899s	
20974/22300 (epoch 47.027), train_loss = 0.25568975, grad/param norm = 1.6025e-01, time/batch = 15.2165s	
20975/22300 (epoch 47.029), train_loss = 0.29776334, grad/param norm = 2.0199e-01, time/batch = 15.3967s	
20976/22300 (epoch 47.031), train_loss = 0.26613935, grad/param norm = 1.8390e-01, time/batch = 15.6168s	
20977/22300 (epoch 47.034), train_loss = 0.27202389, grad/param norm = 2.1042e-01, time/batch = 15.3869s	
20978/22300 (epoch 47.036), train_loss = 0.27661638, grad/param norm = 2.2051e-01, time/batch = 15.3956s	
20979/22300 (epoch 47.038), train_loss = 0.23926936, grad/param norm = 2.4687e-01, time/batch = 15.1416s	
20980/22300 (epoch 47.040), train_loss = 0.29156942, grad/param norm = 2.6755e-01, time/batch = 15.0372s	
20981/22300 (epoch 47.043), train_loss = 0.46995909, grad/param norm = 3.1780e-01, time/batch = 15.3162s	
20982/22300 (epoch 47.045), train_loss = 0.39389426, grad/param norm = 2.5499e-01, time/batch = 15.6345s	
20983/22300 (epoch 47.047), train_loss = 0.42371726, grad/param norm = 2.9610e-01, time/batch = 15.1563s	
20984/22300 (epoch 47.049), train_loss = 0.33621430, grad/param norm = 2.3132e-01, time/batch = 15.5112s	
20985/22300 (epoch 47.052), train_loss = 0.38170974, grad/param norm = 2.7104e-01, time/batch = 15.3003s	
20986/22300 (epoch 47.054), train_loss = 0.36879328, grad/param norm = 2.2753e-01, time/batch = 15.3694s	
20987/22300 (epoch 47.056), train_loss = 0.18894000, grad/param norm = 1.6572e-01, time/batch = 15.4531s	
20988/22300 (epoch 47.058), train_loss = 0.29955269, grad/param norm = 2.3023e-01, time/batch = 15.3564s	
20989/22300 (epoch 47.061), train_loss = 0.26154844, grad/param norm = 2.0198e-01, time/batch = 15.1550s	
20990/22300 (epoch 47.063), train_loss = 0.41152460, grad/param norm = 3.0508e-01, time/batch = 15.4746s	
20991/22300 (epoch 47.065), train_loss = 0.48275788, grad/param norm = 3.1600e-01, time/batch = 15.4790s	
20992/22300 (epoch 47.067), train_loss = 0.28128327, grad/param norm = 2.5783e-01, time/batch = 15.7308s	
20993/22300 (epoch 47.070), train_loss = 0.32134505, grad/param norm = 2.2201e-01, time/batch = 15.8066s	
20994/22300 (epoch 47.072), train_loss = 0.35956001, grad/param norm = 3.2284e-01, time/batch = 15.3953s	
20995/22300 (epoch 47.074), train_loss = 0.34756087, grad/param norm = 2.6436e-01, time/batch = 15.7228s	
20996/22300 (epoch 47.076), train_loss = 0.33655829, grad/param norm = 2.7931e-01, time/batch = 15.8303s	
20997/22300 (epoch 47.078), train_loss = 0.47244334, grad/param norm = 4.2935e-01, time/batch = 15.5704s	
20998/22300 (epoch 47.081), train_loss = 0.45721450, grad/param norm = 3.5312e-01, time/batch = 15.7316s	
20999/22300 (epoch 47.083), train_loss = 0.51523157, grad/param norm = 3.7775e-01, time/batch = 15.7143s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch47.09_1.7177.t7	
21000/22300 (epoch 47.085), train_loss = 0.46611785, grad/param norm = 3.4010e-01, time/batch = 15.7192s	
21001/22300 (epoch 47.087), train_loss = 1.48622546, grad/param norm = 5.9750e-01, time/batch = 16.0376s	
21002/22300 (epoch 47.090), train_loss = 0.36990190, grad/param norm = 2.7464e-01, time/batch = 15.6436s	
21003/22300 (epoch 47.092), train_loss = 0.24996990, grad/param norm = 2.0589e-01, time/batch = 15.5359s	
21004/22300 (epoch 47.094), train_loss = 0.25652780, grad/param norm = 2.0158e-01, time/batch = 15.4665s	
21005/22300 (epoch 47.096), train_loss = 0.47960102, grad/param norm = 4.3357e-01, time/batch = 15.7101s	
21006/22300 (epoch 47.099), train_loss = 0.32106972, grad/param norm = 2.4632e-01, time/batch = 15.6277s	
21007/22300 (epoch 47.101), train_loss = 0.43054739, grad/param norm = 3.3562e-01, time/batch = 15.7121s	
21008/22300 (epoch 47.103), train_loss = 0.32952752, grad/param norm = 2.3885e-01, time/batch = 15.3976s	
21009/22300 (epoch 47.105), train_loss = 0.26168794, grad/param norm = 2.4503e-01, time/batch = 15.7094s	
21010/22300 (epoch 47.108), train_loss = 0.38402361, grad/param norm = 2.4172e-01, time/batch = 15.2256s	
21011/22300 (epoch 47.110), train_loss = 0.42658523, grad/param norm = 3.0334e-01, time/batch = 15.6455s	
21012/22300 (epoch 47.112), train_loss = 0.37214221, grad/param norm = 2.5564e-01, time/batch = 15.4595s	
21013/22300 (epoch 47.114), train_loss = 0.42002244, grad/param norm = 3.0470e-01, time/batch = 15.5236s	
21014/22300 (epoch 47.117), train_loss = 0.47637896, grad/param norm = 3.2978e-01, time/batch = 16.4786s	
21015/22300 (epoch 47.119), train_loss = 0.41298403, grad/param norm = 3.1841e-01, time/batch = 15.9879s	
21016/22300 (epoch 47.121), train_loss = 0.47432515, grad/param norm = 3.4034e-01, time/batch = 16.1330s	
21017/22300 (epoch 47.123), train_loss = 0.50939725, grad/param norm = 3.0433e-01, time/batch = 16.9670s	
21018/22300 (epoch 47.126), train_loss = 0.39429156, grad/param norm = 2.9795e-01, time/batch = 16.6514s	
21019/22300 (epoch 47.128), train_loss = 0.36824548, grad/param norm = 2.9730e-01, time/batch = 16.3874s	
21020/22300 (epoch 47.130), train_loss = 0.31125972, grad/param norm = 2.4703e-01, time/batch = 15.8961s	
21021/22300 (epoch 47.132), train_loss = 0.23626099, grad/param norm = 1.7209e-01, time/batch = 17.9429s	
21022/22300 (epoch 47.135), train_loss = 0.25144038, grad/param norm = 2.1247e-01, time/batch = 15.7835s	
21023/22300 (epoch 47.137), train_loss = 0.21372671, grad/param norm = 2.3264e-01, time/batch = 15.7188s	
21024/22300 (epoch 47.139), train_loss = 0.28845150, grad/param norm = 2.3953e-01, time/batch = 15.9252s	
21025/22300 (epoch 47.141), train_loss = 0.41062832, grad/param norm = 2.9063e-01, time/batch = 18.1266s	
21026/22300 (epoch 47.143), train_loss = 0.32970568, grad/param norm = 2.4624e-01, time/batch = 17.8825s	
21027/22300 (epoch 47.146), train_loss = 0.41133435, grad/param norm = 2.8506e-01, time/batch = 17.3509s	
21028/22300 (epoch 47.148), train_loss = 0.27612493, grad/param norm = 2.3584e-01, time/batch = 17.2180s	
21029/22300 (epoch 47.150), train_loss = 0.30108277, grad/param norm = 2.5898e-01, time/batch = 15.4460s	
21030/22300 (epoch 47.152), train_loss = 0.25461874, grad/param norm = 2.5244e-01, time/batch = 15.7725s	
21031/22300 (epoch 47.155), train_loss = 0.28678872, grad/param norm = 2.2966e-01, time/batch = 17.2969s	
21032/22300 (epoch 47.157), train_loss = 0.36121500, grad/param norm = 2.7079e-01, time/batch = 16.6450s	
21033/22300 (epoch 47.159), train_loss = 0.37779523, grad/param norm = 2.8251e-01, time/batch = 18.0443s	
21034/22300 (epoch 47.161), train_loss = 0.36317091, grad/param norm = 2.9110e-01, time/batch = 15.5865s	
21035/22300 (epoch 47.164), train_loss = 0.27807125, grad/param norm = 1.9801e-01, time/batch = 15.3919s	
21036/22300 (epoch 47.166), train_loss = 0.23941344, grad/param norm = 1.9536e-01, time/batch = 15.6394s	
21037/22300 (epoch 47.168), train_loss = 0.25292870, grad/param norm = 2.3085e-01, time/batch = 15.6485s	
21038/22300 (epoch 47.170), train_loss = 0.33905575, grad/param norm = 2.3435e-01, time/batch = 16.1253s	
21039/22300 (epoch 47.173), train_loss = 0.37306669, grad/param norm = 2.9115e-01, time/batch = 15.9735s	
21040/22300 (epoch 47.175), train_loss = 0.34236714, grad/param norm = 2.7488e-01, time/batch = 16.1917s	
21041/22300 (epoch 47.177), train_loss = 0.21322558, grad/param norm = 1.9892e-01, time/batch = 15.9656s	
21042/22300 (epoch 47.179), train_loss = 0.33789567, grad/param norm = 2.6547e-01, time/batch = 15.4804s	
21043/22300 (epoch 47.182), train_loss = 0.45597182, grad/param norm = 3.2886e-01, time/batch = 15.6437s	
21044/22300 (epoch 47.184), train_loss = 0.48003179, grad/param norm = 3.4514e-01, time/batch = 18.2290s	
21045/22300 (epoch 47.186), train_loss = 0.36301048, grad/param norm = 2.5271e-01, time/batch = 16.6149s	
21046/22300 (epoch 47.188), train_loss = 0.53274520, grad/param norm = 3.1325e-01, time/batch = 15.6442s	
21047/22300 (epoch 47.191), train_loss = 0.41108785, grad/param norm = 2.9093e-01, time/batch = 15.9896s	
21048/22300 (epoch 47.193), train_loss = 0.37147997, grad/param norm = 2.7405e-01, time/batch = 15.8206s	
21049/22300 (epoch 47.195), train_loss = 0.30962374, grad/param norm = 2.4654e-01, time/batch = 16.3792s	
21050/22300 (epoch 47.197), train_loss = 0.29900145, grad/param norm = 2.3504e-01, time/batch = 15.4489s	
21051/22300 (epoch 47.200), train_loss = 0.25448086, grad/param norm = 2.3194e-01, time/batch = 15.5641s	
21052/22300 (epoch 47.202), train_loss = 0.26967232, grad/param norm = 2.1169e-01, time/batch = 15.5595s	
21053/22300 (epoch 47.204), train_loss = 0.34183696, grad/param norm = 2.2408e-01, time/batch = 15.4552s	
21054/22300 (epoch 47.206), train_loss = 0.27865572, grad/param norm = 2.4116e-01, time/batch = 15.6966s	
21055/22300 (epoch 47.209), train_loss = 0.30648905, grad/param norm = 2.4729e-01, time/batch = 17.1452s	
21056/22300 (epoch 47.211), train_loss = 0.22739098, grad/param norm = 2.0905e-01, time/batch = 16.6129s	
21057/22300 (epoch 47.213), train_loss = 0.35521994, grad/param norm = 2.3453e-01, time/batch = 16.3806s	
21058/22300 (epoch 47.215), train_loss = 0.42335038, grad/param norm = 2.9056e-01, time/batch = 15.7212s	
21059/22300 (epoch 47.217), train_loss = 0.46418660, grad/param norm = 2.6395e-01, time/batch = 15.5735s	
21060/22300 (epoch 47.220), train_loss = 0.31128078, grad/param norm = 2.0291e-01, time/batch = 15.6354s	
21061/22300 (epoch 47.222), train_loss = 0.29483217, grad/param norm = 2.3791e-01, time/batch = 15.9606s	
21062/22300 (epoch 47.224), train_loss = 0.27691583, grad/param norm = 2.2431e-01, time/batch = 15.8598s	
21063/22300 (epoch 47.226), train_loss = 0.34482095, grad/param norm = 3.4969e-01, time/batch = 17.6172s	
21064/22300 (epoch 47.229), train_loss = 0.27850997, grad/param norm = 2.3643e-01, time/batch = 15.7897s	
21065/22300 (epoch 47.231), train_loss = 0.43281243, grad/param norm = 2.8020e-01, time/batch = 15.2221s	
21066/22300 (epoch 47.233), train_loss = 0.34359961, grad/param norm = 3.3828e-01, time/batch = 15.2157s	
21067/22300 (epoch 47.235), train_loss = 0.26341973, grad/param norm = 1.8707e-01, time/batch = 15.6663s	
21068/22300 (epoch 47.238), train_loss = 0.26592500, grad/param norm = 2.2010e-01, time/batch = 16.5585s	
21069/22300 (epoch 47.240), train_loss = 0.27040399, grad/param norm = 1.8237e-01, time/batch = 15.2779s	
21070/22300 (epoch 47.242), train_loss = 0.25311542, grad/param norm = 2.4735e-01, time/batch = 16.8892s	
21071/22300 (epoch 47.244), train_loss = 0.18832089, grad/param norm = 2.1318e-01, time/batch = 15.5518s	
21072/22300 (epoch 47.247), train_loss = 0.24734892, grad/param norm = 2.0190e-01, time/batch = 14.6739s	
21073/22300 (epoch 47.249), train_loss = 0.17033822, grad/param norm = 1.4613e-01, time/batch = 16.0417s	
21074/22300 (epoch 47.251), train_loss = 0.22252403, grad/param norm = 1.5299e-01, time/batch = 15.5848s	
21075/22300 (epoch 47.253), train_loss = 0.14952519, grad/param norm = 1.6763e-01, time/batch = 15.2415s	
21076/22300 (epoch 47.256), train_loss = 0.21627465, grad/param norm = 2.1403e-01, time/batch = 15.3585s	
21077/22300 (epoch 47.258), train_loss = 0.32270825, grad/param norm = 2.2557e-01, time/batch = 14.8677s	
21078/22300 (epoch 47.260), train_loss = 0.37003002, grad/param norm = 2.4416e-01, time/batch = 15.1473s	
21079/22300 (epoch 47.262), train_loss = 0.24915983, grad/param norm = 1.6135e-01, time/batch = 14.9584s	
21080/22300 (epoch 47.265), train_loss = 0.23728770, grad/param norm = 1.9293e-01, time/batch = 15.4755s	
21081/22300 (epoch 47.267), train_loss = 0.25214842, grad/param norm = 1.9064e-01, time/batch = 15.4669s	
21082/22300 (epoch 47.269), train_loss = 0.32693958, grad/param norm = 2.5829e-01, time/batch = 17.0434s	
21083/22300 (epoch 47.271), train_loss = 0.35771333, grad/param norm = 2.2541e-01, time/batch = 15.7195s	
21084/22300 (epoch 47.274), train_loss = 0.23007013, grad/param norm = 1.9547e-01, time/batch = 16.3763s	
21085/22300 (epoch 47.276), train_loss = 0.21187833, grad/param norm = 1.6673e-01, time/batch = 15.4818s	
21086/22300 (epoch 47.278), train_loss = 0.23427648, grad/param norm = 1.8755e-01, time/batch = 15.6477s	
21087/22300 (epoch 47.280), train_loss = 0.24011089, grad/param norm = 1.8002e-01, time/batch = 15.7207s	
21088/22300 (epoch 47.283), train_loss = 0.20193537, grad/param norm = 1.2063e-01, time/batch = 16.3898s	
21089/22300 (epoch 47.285), train_loss = 0.21358098, grad/param norm = 1.9209e-01, time/batch = 16.7242s	
21090/22300 (epoch 47.287), train_loss = 0.32105031, grad/param norm = 2.0868e-01, time/batch = 15.7337s	
21091/22300 (epoch 47.289), train_loss = 0.28745624, grad/param norm = 1.7559e-01, time/batch = 15.4918s	
21092/22300 (epoch 47.291), train_loss = 0.28073115, grad/param norm = 2.2297e-01, time/batch = 17.7075s	
21093/22300 (epoch 47.294), train_loss = 0.24066755, grad/param norm = 1.8241e-01, time/batch = 16.6134s	
21094/22300 (epoch 47.296), train_loss = 0.26187023, grad/param norm = 2.8468e-01, time/batch = 16.3539s	
21095/22300 (epoch 47.298), train_loss = 0.35799314, grad/param norm = 2.2427e-01, time/batch = 16.3169s	
21096/22300 (epoch 47.300), train_loss = 0.40091823, grad/param norm = 2.6642e-01, time/batch = 15.6285s	
21097/22300 (epoch 47.303), train_loss = 0.29308308, grad/param norm = 2.0433e-01, time/batch = 16.1240s	
21098/22300 (epoch 47.305), train_loss = 0.31259716, grad/param norm = 2.5577e-01, time/batch = 14.8057s	
21099/22300 (epoch 47.307), train_loss = 0.26248455, grad/param norm = 1.8948e-01, time/batch = 16.9687s	
21100/22300 (epoch 47.309), train_loss = 0.22461728, grad/param norm = 1.6373e-01, time/batch = 17.6372s	
21101/22300 (epoch 47.312), train_loss = 0.19938785, grad/param norm = 1.6822e-01, time/batch = 15.4633s	
21102/22300 (epoch 47.314), train_loss = 0.25470064, grad/param norm = 2.0911e-01, time/batch = 19.2126s	
21103/22300 (epoch 47.316), train_loss = 0.22973073, grad/param norm = 2.0713e-01, time/batch = 15.4794s	
21104/22300 (epoch 47.318), train_loss = 0.25372256, grad/param norm = 1.5829e-01, time/batch = 16.3214s	
21105/22300 (epoch 47.321), train_loss = 0.33689303, grad/param norm = 2.0339e-01, time/batch = 15.5502s	
21106/22300 (epoch 47.323), train_loss = 0.22970131, grad/param norm = 1.4749e-01, time/batch = 17.7223s	
21107/22300 (epoch 47.325), train_loss = 0.19499532, grad/param norm = 1.5375e-01, time/batch = 15.9770s	
21108/22300 (epoch 47.327), train_loss = 0.23465648, grad/param norm = 1.9033e-01, time/batch = 17.0201s	
21109/22300 (epoch 47.330), train_loss = 0.23764491, grad/param norm = 2.6164e-01, time/batch = 16.9523s	
21110/22300 (epoch 47.332), train_loss = 0.21697023, grad/param norm = 1.8095e-01, time/batch = 16.9670s	
21111/22300 (epoch 47.334), train_loss = 0.24369637, grad/param norm = 1.8572e-01, time/batch = 16.7882s	
21112/22300 (epoch 47.336), train_loss = 0.24439360, grad/param norm = 1.7798e-01, time/batch = 15.7233s	
21113/22300 (epoch 47.339), train_loss = 0.32329898, grad/param norm = 2.2514e-01, time/batch = 16.7750s	
21114/22300 (epoch 47.341), train_loss = 0.29813579, grad/param norm = 2.0153e-01, time/batch = 14.8041s	
21115/22300 (epoch 47.343), train_loss = 0.37269002, grad/param norm = 4.2966e-01, time/batch = 15.1732s	
21116/22300 (epoch 47.345), train_loss = 0.30873554, grad/param norm = 2.5037e-01, time/batch = 15.6360s	
21117/22300 (epoch 47.348), train_loss = 0.29363328, grad/param norm = 1.9845e-01, time/batch = 16.2170s	
21118/22300 (epoch 47.350), train_loss = 0.19126948, grad/param norm = 2.0795e-01, time/batch = 17.2296s	
21119/22300 (epoch 47.352), train_loss = 0.29032370, grad/param norm = 1.9861e-01, time/batch = 16.4519s	
21120/22300 (epoch 47.354), train_loss = 0.41739221, grad/param norm = 3.1427e-01, time/batch = 15.3307s	
21121/22300 (epoch 47.357), train_loss = 0.40169891, grad/param norm = 2.1982e-01, time/batch = 15.2606s	
21122/22300 (epoch 47.359), train_loss = 0.24419393, grad/param norm = 2.1878e-01, time/batch = 15.0663s	
21123/22300 (epoch 47.361), train_loss = 0.25859273, grad/param norm = 2.3074e-01, time/batch = 14.9722s	
21124/22300 (epoch 47.363), train_loss = 0.32559364, grad/param norm = 2.2695e-01, time/batch = 14.9899s	
21125/22300 (epoch 47.365), train_loss = 0.25378524, grad/param norm = 2.7689e-01, time/batch = 16.4512s	
21126/22300 (epoch 47.368), train_loss = 0.24295824, grad/param norm = 2.3685e-01, time/batch = 16.3896s	
21127/22300 (epoch 47.370), train_loss = 0.25208590, grad/param norm = 1.8605e-01, time/batch = 15.3022s	
21128/22300 (epoch 47.372), train_loss = 0.16692504, grad/param norm = 1.6196e-01, time/batch = 18.0340s	
21129/22300 (epoch 47.374), train_loss = 0.19985687, grad/param norm = 1.4305e-01, time/batch = 14.7349s	
21130/22300 (epoch 47.377), train_loss = 0.28795887, grad/param norm = 2.4455e-01, time/batch = 15.4791s	
21131/22300 (epoch 47.379), train_loss = 0.22892011, grad/param norm = 1.7433e-01, time/batch = 15.5885s	
21132/22300 (epoch 47.381), train_loss = 0.32338699, grad/param norm = 2.2035e-01, time/batch = 16.3140s	
21133/22300 (epoch 47.383), train_loss = 0.26101487, grad/param norm = 2.9589e-01, time/batch = 15.0472s	
21134/22300 (epoch 47.386), train_loss = 0.32167247, grad/param norm = 2.3415e-01, time/batch = 15.3768s	
21135/22300 (epoch 47.388), train_loss = 0.19835968, grad/param norm = 1.9415e-01, time/batch = 15.4323s	
21136/22300 (epoch 47.390), train_loss = 0.23794120, grad/param norm = 2.9564e-01, time/batch = 15.4878s	
21137/22300 (epoch 47.392), train_loss = 0.26020139, grad/param norm = 2.4761e-01, time/batch = 15.0563s	
21138/22300 (epoch 47.395), train_loss = 0.22080767, grad/param norm = 1.7453e-01, time/batch = 16.1157s	
21139/22300 (epoch 47.397), train_loss = 0.16580528, grad/param norm = 1.5726e-01, time/batch = 15.9743s	
21140/22300 (epoch 47.399), train_loss = 0.23219977, grad/param norm = 2.1745e-01, time/batch = 15.2305s	
21141/22300 (epoch 47.401), train_loss = 0.24868465, grad/param norm = 2.2627e-01, time/batch = 16.7229s	
21142/22300 (epoch 47.404), train_loss = 0.28036096, grad/param norm = 2.0379e-01, time/batch = 15.3894s	
21143/22300 (epoch 47.406), train_loss = 0.40862957, grad/param norm = 2.9642e-01, time/batch = 15.3159s	
21144/22300 (epoch 47.408), train_loss = 0.30860520, grad/param norm = 2.2965e-01, time/batch = 16.6484s	
21145/22300 (epoch 47.410), train_loss = 0.33976531, grad/param norm = 2.4371e-01, time/batch = 16.0272s	
21146/22300 (epoch 47.413), train_loss = 0.24512173, grad/param norm = 1.9405e-01, time/batch = 15.8654s	
21147/22300 (epoch 47.415), train_loss = 0.17567005, grad/param norm = 2.0058e-01, time/batch = 16.1188s	
21148/22300 (epoch 47.417), train_loss = 0.28294261, grad/param norm = 1.9455e-01, time/batch = 17.0610s	
21149/22300 (epoch 47.419), train_loss = 0.26270312, grad/param norm = 1.5968e-01, time/batch = 17.0358s	
21150/22300 (epoch 47.422), train_loss = 0.21972575, grad/param norm = 1.7822e-01, time/batch = 16.3943s	
21151/22300 (epoch 47.424), train_loss = 0.26548828, grad/param norm = 2.1409e-01, time/batch = 16.5630s	
21152/22300 (epoch 47.426), train_loss = 0.20112510, grad/param norm = 1.8338e-01, time/batch = 16.4500s	
21153/22300 (epoch 47.428), train_loss = 0.21036167, grad/param norm = 1.5893e-01, time/batch = 15.5283s	
21154/22300 (epoch 47.430), train_loss = 0.24238695, grad/param norm = 2.2799e-01, time/batch = 15.6535s	
21155/22300 (epoch 47.433), train_loss = 0.25430632, grad/param norm = 1.7488e-01, time/batch = 16.1461s	
21156/22300 (epoch 47.435), train_loss = 0.24553736, grad/param norm = 2.0042e-01, time/batch = 17.4675s	
21157/22300 (epoch 47.437), train_loss = 0.29175395, grad/param norm = 2.5051e-01, time/batch = 30.6212s	
21158/22300 (epoch 47.439), train_loss = 0.30218147, grad/param norm = 2.0953e-01, time/batch = 16.4711s	
21159/22300 (epoch 47.442), train_loss = 0.26377047, grad/param norm = 1.8274e-01, time/batch = 16.1200s	
21160/22300 (epoch 47.444), train_loss = 0.23421443, grad/param norm = 2.1503e-01, time/batch = 15.1042s	
21161/22300 (epoch 47.446), train_loss = 0.26716509, grad/param norm = 1.9689e-01, time/batch = 15.5741s	
21162/22300 (epoch 47.448), train_loss = 0.19888145, grad/param norm = 1.3666e-01, time/batch = 15.2147s	
21163/22300 (epoch 47.451), train_loss = 0.29701767, grad/param norm = 1.8014e-01, time/batch = 14.9658s	
21164/22300 (epoch 47.453), train_loss = 0.24322278, grad/param norm = 2.0663e-01, time/batch = 15.1546s	
21165/22300 (epoch 47.455), train_loss = 0.32827064, grad/param norm = 2.4696e-01, time/batch = 15.1484s	
21166/22300 (epoch 47.457), train_loss = 0.41174243, grad/param norm = 2.6565e-01, time/batch = 14.9001s	
21167/22300 (epoch 47.460), train_loss = 0.37328804, grad/param norm = 2.3524e-01, time/batch = 15.6004s	
21168/22300 (epoch 47.462), train_loss = 0.34719094, grad/param norm = 1.9712e-01, time/batch = 15.2995s	
21169/22300 (epoch 47.464), train_loss = 0.32489289, grad/param norm = 3.1838e-01, time/batch = 15.3142s	
21170/22300 (epoch 47.466), train_loss = 0.25328626, grad/param norm = 1.7639e-01, time/batch = 15.3095s	
21171/22300 (epoch 47.469), train_loss = 0.25172082, grad/param norm = 1.7229e-01, time/batch = 15.4637s	
21172/22300 (epoch 47.471), train_loss = 0.35403410, grad/param norm = 2.2593e-01, time/batch = 15.5467s	
21173/22300 (epoch 47.473), train_loss = 0.28634844, grad/param norm = 1.6818e-01, time/batch = 15.5978s	
21174/22300 (epoch 47.475), train_loss = 0.23381838, grad/param norm = 1.9512e-01, time/batch = 15.0717s	
21175/22300 (epoch 47.478), train_loss = 0.26638726, grad/param norm = 2.2340e-01, time/batch = 15.5549s	
21176/22300 (epoch 47.480), train_loss = 0.18731131, grad/param norm = 1.7528e-01, time/batch = 15.2420s	
21177/22300 (epoch 47.482), train_loss = 0.22412322, grad/param norm = 1.6377e-01, time/batch = 15.2411s	
21178/22300 (epoch 47.484), train_loss = 0.27323720, grad/param norm = 2.3593e-01, time/batch = 15.2338s	
21179/22300 (epoch 47.487), train_loss = 0.34657452, grad/param norm = 2.1778e-01, time/batch = 15.4702s	
21180/22300 (epoch 47.489), train_loss = 0.31755268, grad/param norm = 2.1692e-01, time/batch = 15.3901s	
21181/22300 (epoch 47.491), train_loss = 0.37118724, grad/param norm = 2.7065e-01, time/batch = 15.3140s	
21182/22300 (epoch 47.493), train_loss = 0.24843293, grad/param norm = 3.4391e-01, time/batch = 14.9713s	
21183/22300 (epoch 47.496), train_loss = 0.30728141, grad/param norm = 1.8337e-01, time/batch = 15.5431s	
21184/22300 (epoch 47.498), train_loss = 0.19040317, grad/param norm = 1.8715e-01, time/batch = 15.2297s	
21185/22300 (epoch 47.500), train_loss = 0.27387619, grad/param norm = 1.8739e-01, time/batch = 15.3149s	
21186/22300 (epoch 47.502), train_loss = 0.18681496, grad/param norm = 2.2637e-01, time/batch = 15.7249s	
21187/22300 (epoch 47.504), train_loss = 0.19268097, grad/param norm = 1.5039e-01, time/batch = 15.3818s	
21188/22300 (epoch 47.507), train_loss = 0.22911981, grad/param norm = 2.5552e-01, time/batch = 15.3860s	
21189/22300 (epoch 47.509), train_loss = 0.33329189, grad/param norm = 2.5817e-01, time/batch = 15.3865s	
21190/22300 (epoch 47.511), train_loss = 0.18895463, grad/param norm = 1.6553e-01, time/batch = 15.4545s	
21191/22300 (epoch 47.513), train_loss = 0.20674795, grad/param norm = 1.8503e-01, time/batch = 15.8035s	
21192/22300 (epoch 47.516), train_loss = 0.25043563, grad/param norm = 2.2378e-01, time/batch = 15.4838s	
21193/22300 (epoch 47.518), train_loss = 0.28029135, grad/param norm = 2.5236e-01, time/batch = 15.0732s	
21194/22300 (epoch 47.520), train_loss = 0.22828912, grad/param norm = 2.0599e-01, time/batch = 15.2127s	
21195/22300 (epoch 47.522), train_loss = 0.28863912, grad/param norm = 2.5824e-01, time/batch = 15.0911s	
21196/22300 (epoch 47.525), train_loss = 0.20790643, grad/param norm = 1.8380e-01, time/batch = 14.7381s	
21197/22300 (epoch 47.527), train_loss = 0.31168069, grad/param norm = 2.4129e-01, time/batch = 15.0760s	
21198/22300 (epoch 47.529), train_loss = 0.28275351, grad/param norm = 2.2421e-01, time/batch = 15.2079s	
21199/22300 (epoch 47.531), train_loss = 0.24991096, grad/param norm = 2.0326e-01, time/batch = 15.1417s	
21200/22300 (epoch 47.534), train_loss = 0.28072475, grad/param norm = 2.0553e-01, time/batch = 15.4493s	
21201/22300 (epoch 47.536), train_loss = 0.39045836, grad/param norm = 2.0931e-01, time/batch = 15.4502s	
21202/22300 (epoch 47.538), train_loss = 0.47625836, grad/param norm = 3.3524e-01, time/batch = 15.3106s	
21203/22300 (epoch 47.540), train_loss = 0.27610271, grad/param norm = 2.4868e-01, time/batch = 15.0657s	
21204/22300 (epoch 47.543), train_loss = 0.28211245, grad/param norm = 2.0402e-01, time/batch = 15.0779s	
21205/22300 (epoch 47.545), train_loss = 0.19127996, grad/param norm = 1.7870e-01, time/batch = 15.1496s	
21206/22300 (epoch 47.547), train_loss = 0.17171608, grad/param norm = 1.7603e-01, time/batch = 15.2358s	
21207/22300 (epoch 47.549), train_loss = 0.19525241, grad/param norm = 2.0325e-01, time/batch = 15.4608s	
21208/22300 (epoch 47.552), train_loss = 0.21626212, grad/param norm = 2.0508e-01, time/batch = 14.8310s	
21209/22300 (epoch 47.554), train_loss = 0.32208829, grad/param norm = 2.9224e-01, time/batch = 15.0516s	
21210/22300 (epoch 47.556), train_loss = 0.39034545, grad/param norm = 2.7157e-01, time/batch = 15.5569s	
21211/22300 (epoch 47.558), train_loss = 0.30172032, grad/param norm = 2.7285e-01, time/batch = 15.7776s	
21212/22300 (epoch 47.561), train_loss = 0.42768513, grad/param norm = 2.7188e-01, time/batch = 15.7589s	
21213/22300 (epoch 47.563), train_loss = 0.35356854, grad/param norm = 2.5724e-01, time/batch = 15.5551s	
21214/22300 (epoch 47.565), train_loss = 0.27064392, grad/param norm = 2.2138e-01, time/batch = 15.3721s	
21215/22300 (epoch 47.567), train_loss = 0.25179526, grad/param norm = 2.5381e-01, time/batch = 15.3727s	
21216/22300 (epoch 47.570), train_loss = 0.38572785, grad/param norm = 3.5077e-01, time/batch = 15.4840s	
21217/22300 (epoch 47.572), train_loss = 0.37180517, grad/param norm = 2.4731e-01, time/batch = 15.7816s	
21218/22300 (epoch 47.574), train_loss = 0.27802689, grad/param norm = 2.3781e-01, time/batch = 15.6243s	
21219/22300 (epoch 47.576), train_loss = 0.25196287, grad/param norm = 1.8329e-01, time/batch = 15.4692s	
21220/22300 (epoch 47.578), train_loss = 0.15008380, grad/param norm = 1.5966e-01, time/batch = 15.5625s	
21221/22300 (epoch 47.581), train_loss = 0.21300673, grad/param norm = 1.7371e-01, time/batch = 15.5570s	
21222/22300 (epoch 47.583), train_loss = 0.27443302, grad/param norm = 2.0356e-01, time/batch = 15.8635s	
21223/22300 (epoch 47.585), train_loss = 0.33354034, grad/param norm = 2.4448e-01, time/batch = 15.8646s	
21224/22300 (epoch 47.587), train_loss = 0.50773977, grad/param norm = 3.1147e-01, time/batch = 15.5620s	
21225/22300 (epoch 47.590), train_loss = 0.39752898, grad/param norm = 3.1954e-01, time/batch = 15.1480s	
21226/22300 (epoch 47.592), train_loss = 0.46875518, grad/param norm = 3.4758e-01, time/batch = 15.8036s	
21227/22300 (epoch 47.594), train_loss = 0.43456980, grad/param norm = 3.1611e-01, time/batch = 15.4848s	
21228/22300 (epoch 47.596), train_loss = 0.28609305, grad/param norm = 1.8340e-01, time/batch = 15.5243s	
21229/22300 (epoch 47.599), train_loss = 0.19089745, grad/param norm = 2.0249e-01, time/batch = 15.6110s	
21230/22300 (epoch 47.601), train_loss = 0.23402241, grad/param norm = 2.0375e-01, time/batch = 15.8102s	
21231/22300 (epoch 47.603), train_loss = 0.23861056, grad/param norm = 1.7365e-01, time/batch = 15.4053s	
21232/22300 (epoch 47.605), train_loss = 0.26298893, grad/param norm = 2.2261e-01, time/batch = 15.3151s	
21233/22300 (epoch 47.608), train_loss = 0.45838465, grad/param norm = 3.2510e-01, time/batch = 15.5350s	
21234/22300 (epoch 47.610), train_loss = 0.51770173, grad/param norm = 2.9053e-01, time/batch = 15.4643s	
21235/22300 (epoch 47.612), train_loss = 0.36319668, grad/param norm = 2.6727e-01, time/batch = 15.1510s	
21236/22300 (epoch 47.614), train_loss = 0.34796379, grad/param norm = 4.2259e-01, time/batch = 15.3206s	
21237/22300 (epoch 47.617), train_loss = 0.37882084, grad/param norm = 2.6243e-01, time/batch = 15.4598s	
21238/22300 (epoch 47.619), train_loss = 0.35339336, grad/param norm = 2.5429e-01, time/batch = 15.4005s	
21239/22300 (epoch 47.621), train_loss = 0.24460090, grad/param norm = 2.1634e-01, time/batch = 15.3852s	
21240/22300 (epoch 47.623), train_loss = 0.28050483, grad/param norm = 2.6933e-01, time/batch = 16.8083s	
21241/22300 (epoch 47.626), train_loss = 0.25877343, grad/param norm = 2.6436e-01, time/batch = 16.0466s	
21242/22300 (epoch 47.628), train_loss = 0.25852701, grad/param norm = 1.8698e-01, time/batch = 18.1461s	
21243/22300 (epoch 47.630), train_loss = 0.29282476, grad/param norm = 2.1381e-01, time/batch = 15.7322s	
21244/22300 (epoch 47.632), train_loss = 0.23581884, grad/param norm = 1.6926e-01, time/batch = 15.7903s	
21245/22300 (epoch 47.635), train_loss = 0.29789760, grad/param norm = 2.0062e-01, time/batch = 15.5368s	
21246/22300 (epoch 47.637), train_loss = 0.33416325, grad/param norm = 2.3477e-01, time/batch = 16.9645s	
21247/22300 (epoch 47.639), train_loss = 0.40151106, grad/param norm = 2.3369e-01, time/batch = 16.4406s	
21248/22300 (epoch 47.641), train_loss = 0.33066230, grad/param norm = 2.4417e-01, time/batch = 15.8632s	
21249/22300 (epoch 47.643), train_loss = 0.25483140, grad/param norm = 1.9508e-01, time/batch = 15.5860s	
21250/22300 (epoch 47.646), train_loss = 0.26931986, grad/param norm = 2.3553e-01, time/batch = 17.1358s	
21251/22300 (epoch 47.648), train_loss = 0.36513890, grad/param norm = 2.4561e-01, time/batch = 18.5472s	
21252/22300 (epoch 47.650), train_loss = 0.33728952, grad/param norm = 3.0435e-01, time/batch = 15.6148s	
21253/22300 (epoch 47.652), train_loss = 0.27093011, grad/param norm = 1.8310e-01, time/batch = 17.1395s	
21254/22300 (epoch 47.655), train_loss = 0.23841852, grad/param norm = 2.2892e-01, time/batch = 16.2318s	
21255/22300 (epoch 47.657), train_loss = 0.26567451, grad/param norm = 2.4190e-01, time/batch = 15.7586s	
21256/22300 (epoch 47.659), train_loss = 0.25642010, grad/param norm = 1.9199e-01, time/batch = 15.7012s	
21257/22300 (epoch 47.661), train_loss = 0.22786035, grad/param norm = 2.0220e-01, time/batch = 15.8712s	
21258/22300 (epoch 47.664), train_loss = 0.25554680, grad/param norm = 1.6904e-01, time/batch = 16.1492s	
21259/22300 (epoch 47.666), train_loss = 0.32276374, grad/param norm = 2.5696e-01, time/batch = 16.3063s	
21260/22300 (epoch 47.668), train_loss = 0.24660978, grad/param norm = 2.0289e-01, time/batch = 16.3691s	
21261/22300 (epoch 47.670), train_loss = 0.31058091, grad/param norm = 2.5897e-01, time/batch = 16.5565s	
21262/22300 (epoch 47.673), train_loss = 0.38652317, grad/param norm = 2.5969e-01, time/batch = 16.0988s	
21263/22300 (epoch 47.675), train_loss = 0.41638805, grad/param norm = 3.3659e-01, time/batch = 16.1298s	
21264/22300 (epoch 47.677), train_loss = 0.45068205, grad/param norm = 2.8699e-01, time/batch = 16.0471s	
21265/22300 (epoch 47.679), train_loss = 0.31394307, grad/param norm = 3.5069e-01, time/batch = 16.1192s	
21266/22300 (epoch 47.682), train_loss = 0.27517593, grad/param norm = 1.8670e-01, time/batch = 16.1151s	
21267/22300 (epoch 47.684), train_loss = 0.28625044, grad/param norm = 2.1580e-01, time/batch = 16.1191s	
21268/22300 (epoch 47.686), train_loss = 0.25382807, grad/param norm = 1.9933e-01, time/batch = 15.9830s	
21269/22300 (epoch 47.688), train_loss = 0.24577676, grad/param norm = 1.7312e-01, time/batch = 16.3155s	
21270/22300 (epoch 47.691), train_loss = 0.23047821, grad/param norm = 2.0475e-01, time/batch = 16.1292s	
21271/22300 (epoch 47.693), train_loss = 0.23287516, grad/param norm = 1.9478e-01, time/batch = 16.3064s	
21272/22300 (epoch 47.695), train_loss = 0.25512042, grad/param norm = 1.8914e-01, time/batch = 16.3073s	
21273/22300 (epoch 47.697), train_loss = 0.27819150, grad/param norm = 1.8491e-01, time/batch = 16.2947s	
21274/22300 (epoch 47.700), train_loss = 0.22707102, grad/param norm = 1.7777e-01, time/batch = 16.2906s	
21275/22300 (epoch 47.702), train_loss = 0.18165076, grad/param norm = 1.4251e-01, time/batch = 16.0486s	
21276/22300 (epoch 47.704), train_loss = 0.25163350, grad/param norm = 2.5907e-01, time/batch = 16.0666s	
21277/22300 (epoch 47.706), train_loss = 0.24145231, grad/param norm = 1.7952e-01, time/batch = 16.0549s	
21278/22300 (epoch 47.709), train_loss = 0.18302603, grad/param norm = 1.5775e-01, time/batch = 16.4004s	
21279/22300 (epoch 47.711), train_loss = 0.18424139, grad/param norm = 1.4529e-01, time/batch = 16.1987s	
21280/22300 (epoch 47.713), train_loss = 0.29525013, grad/param norm = 2.2474e-01, time/batch = 15.7229s	
21281/22300 (epoch 47.715), train_loss = 0.32219052, grad/param norm = 2.3655e-01, time/batch = 15.7674s	
21282/22300 (epoch 47.717), train_loss = 0.39183173, grad/param norm = 2.2604e-01, time/batch = 15.9252s	
21283/22300 (epoch 47.720), train_loss = 0.23077770, grad/param norm = 2.2844e-01, time/batch = 15.8727s	
21284/22300 (epoch 47.722), train_loss = 0.27514291, grad/param norm = 2.3904e-01, time/batch = 15.7627s	
21285/22300 (epoch 47.724), train_loss = 0.34157341, grad/param norm = 5.0024e-01, time/batch = 15.6637s	
21286/22300 (epoch 47.726), train_loss = 0.24615490, grad/param norm = 2.0087e-01, time/batch = 15.7072s	
21287/22300 (epoch 47.729), train_loss = 0.32095169, grad/param norm = 2.1187e-01, time/batch = 15.8814s	
21288/22300 (epoch 47.731), train_loss = 0.35266604, grad/param norm = 3.2234e-01, time/batch = 15.9563s	
21289/22300 (epoch 47.733), train_loss = 0.36425090, grad/param norm = 3.0514e-01, time/batch = 16.1828s	
21290/22300 (epoch 47.735), train_loss = 0.37815488, grad/param norm = 3.3266e-01, time/batch = 15.8162s	
21291/22300 (epoch 47.738), train_loss = 0.28769175, grad/param norm = 3.1496e-01, time/batch = 15.9591s	
21292/22300 (epoch 47.740), train_loss = 0.27699782, grad/param norm = 2.4089e-01, time/batch = 15.4668s	
21293/22300 (epoch 47.742), train_loss = 0.23238108, grad/param norm = 1.9310e-01, time/batch = 15.8081s	
21294/22300 (epoch 47.744), train_loss = 0.42738720, grad/param norm = 3.0806e-01, time/batch = 15.6528s	
21295/22300 (epoch 47.747), train_loss = 0.34974950, grad/param norm = 2.3322e-01, time/batch = 15.5702s	
21296/22300 (epoch 47.749), train_loss = 0.43743437, grad/param norm = 2.9556e-01, time/batch = 15.6380s	
21297/22300 (epoch 47.751), train_loss = 0.34908726, grad/param norm = 3.3582e-01, time/batch = 15.6471s	
21298/22300 (epoch 47.753), train_loss = 0.39407649, grad/param norm = 3.7072e-01, time/batch = 15.5672s	
21299/22300 (epoch 47.756), train_loss = 0.38671111, grad/param norm = 2.1265e-01, time/batch = 15.6258s	
21300/22300 (epoch 47.758), train_loss = 0.29587034, grad/param norm = 2.1819e-01, time/batch = 15.7122s	
21301/22300 (epoch 47.760), train_loss = 0.35528391, grad/param norm = 2.5038e-01, time/batch = 16.0574s	
21302/22300 (epoch 47.762), train_loss = 0.30915595, grad/param norm = 2.6087e-01, time/batch = 15.8924s	
21303/22300 (epoch 47.765), train_loss = 0.34294127, grad/param norm = 2.6850e-01, time/batch = 15.8686s	
21304/22300 (epoch 47.767), train_loss = 0.29899856, grad/param norm = 2.5617e-01, time/batch = 15.9605s	
21305/22300 (epoch 47.769), train_loss = 0.28681197, grad/param norm = 2.3714e-01, time/batch = 15.8111s	
21306/22300 (epoch 47.771), train_loss = 0.36315902, grad/param norm = 3.2291e-01, time/batch = 15.8892s	
21307/22300 (epoch 47.774), train_loss = 0.38480656, grad/param norm = 2.9834e-01, time/batch = 15.8985s	
21308/22300 (epoch 47.776), train_loss = 0.42064482, grad/param norm = 2.6496e-01, time/batch = 15.9575s	
21309/22300 (epoch 47.778), train_loss = 0.41478297, grad/param norm = 2.6770e-01, time/batch = 15.8166s	
21310/22300 (epoch 47.780), train_loss = 0.40048767, grad/param norm = 2.9178e-01, time/batch = 15.7963s	
21311/22300 (epoch 47.783), train_loss = 0.44329504, grad/param norm = 3.6274e-01, time/batch = 15.7103s	
21312/22300 (epoch 47.785), train_loss = 0.27997504, grad/param norm = 2.2829e-01, time/batch = 15.6458s	
21313/22300 (epoch 47.787), train_loss = 0.29075235, grad/param norm = 2.1556e-01, time/batch = 15.8572s	
21314/22300 (epoch 47.789), train_loss = 0.42910641, grad/param norm = 3.1830e-01, time/batch = 15.9550s	
21315/22300 (epoch 47.791), train_loss = 0.52898798, grad/param norm = 3.3566e-01, time/batch = 15.6212s	
21316/22300 (epoch 47.794), train_loss = 0.44626236, grad/param norm = 3.6989e-01, time/batch = 15.8947s	
21317/22300 (epoch 47.796), train_loss = 0.36230329, grad/param norm = 3.0921e-01, time/batch = 15.7136s	
21318/22300 (epoch 47.798), train_loss = 0.50531315, grad/param norm = 2.5815e-01, time/batch = 15.7317s	
21319/22300 (epoch 47.800), train_loss = 0.34695949, grad/param norm = 2.6349e-01, time/batch = 15.6897s	
21320/22300 (epoch 47.803), train_loss = 0.29215080, grad/param norm = 2.0925e-01, time/batch = 15.7293s	
21321/22300 (epoch 47.805), train_loss = 0.33307884, grad/param norm = 2.9234e-01, time/batch = 16.1059s	
21322/22300 (epoch 47.807), train_loss = 0.46279626, grad/param norm = 3.3736e-01, time/batch = 15.9640s	
21323/22300 (epoch 47.809), train_loss = 0.32959059, grad/param norm = 2.4652e-01, time/batch = 16.0425s	
21324/22300 (epoch 47.812), train_loss = 0.34611915, grad/param norm = 2.7637e-01, time/batch = 15.9657s	
21325/22300 (epoch 47.814), train_loss = 0.31606191, grad/param norm = 2.2794e-01, time/batch = 15.8805s	
21326/22300 (epoch 47.816), train_loss = 0.36587173, grad/param norm = 2.5629e-01, time/batch = 16.0480s	
21327/22300 (epoch 47.818), train_loss = 0.42292313, grad/param norm = 3.4458e-01, time/batch = 15.9574s	
21328/22300 (epoch 47.821), train_loss = 0.34290858, grad/param norm = 2.6039e-01, time/batch = 15.8153s	
21329/22300 (epoch 47.823), train_loss = 0.21873097, grad/param norm = 1.7288e-01, time/batch = 15.7445s	
21330/22300 (epoch 47.825), train_loss = 0.24548255, grad/param norm = 1.9200e-01, time/batch = 15.8828s	
21331/22300 (epoch 47.827), train_loss = 0.28204159, grad/param norm = 2.4355e-01, time/batch = 15.9449s	
21332/22300 (epoch 47.830), train_loss = 0.29268959, grad/param norm = 2.7940e-01, time/batch = 16.0788s	
21333/22300 (epoch 47.832), train_loss = 0.28015858, grad/param norm = 2.1225e-01, time/batch = 15.4699s	
21334/22300 (epoch 47.834), train_loss = 0.23062037, grad/param norm = 1.9438e-01, time/batch = 15.4330s	
21335/22300 (epoch 47.836), train_loss = 0.29099321, grad/param norm = 2.6312e-01, time/batch = 14.8956s	
21336/22300 (epoch 47.839), train_loss = 0.31308884, grad/param norm = 2.0203e-01, time/batch = 16.1604s	
21337/22300 (epoch 47.841), train_loss = 0.27199362, grad/param norm = 3.2337e-01, time/batch = 17.3799s	
21338/22300 (epoch 47.843), train_loss = 0.31386726, grad/param norm = 2.6299e-01, time/batch = 15.2927s	
21339/22300 (epoch 47.845), train_loss = 0.31206088, grad/param norm = 2.3159e-01, time/batch = 17.4636s	
21340/22300 (epoch 47.848), train_loss = 0.26935501, grad/param norm = 2.3654e-01, time/batch = 16.7150s	
21341/22300 (epoch 47.850), train_loss = 0.31697733, grad/param norm = 2.0457e-01, time/batch = 15.3859s	
21342/22300 (epoch 47.852), train_loss = 0.28729475, grad/param norm = 2.9383e-01, time/batch = 16.3054s	
21343/22300 (epoch 47.854), train_loss = 0.47111743, grad/param norm = 3.2710e-01, time/batch = 17.0619s	
21344/22300 (epoch 47.857), train_loss = 0.33331993, grad/param norm = 2.5735e-01, time/batch = 17.1355s	
21345/22300 (epoch 47.859), train_loss = 0.29630793, grad/param norm = 2.2790e-01, time/batch = 15.8211s	
21346/22300 (epoch 47.861), train_loss = 0.39065493, grad/param norm = 2.9316e-01, time/batch = 14.9361s	
21347/22300 (epoch 47.863), train_loss = 0.24299132, grad/param norm = 2.2974e-01, time/batch = 15.4058s	
21348/22300 (epoch 47.865), train_loss = 0.25456107, grad/param norm = 2.0956e-01, time/batch = 14.9937s	
21349/22300 (epoch 47.868), train_loss = 0.31701279, grad/param norm = 1.7183e-01, time/batch = 15.1014s	
21350/22300 (epoch 47.870), train_loss = 0.31254490, grad/param norm = 2.6710e-01, time/batch = 15.0790s	
21351/22300 (epoch 47.872), train_loss = 0.40887369, grad/param norm = 2.3596e-01, time/batch = 16.8157s	
21352/22300 (epoch 47.874), train_loss = 0.34055595, grad/param norm = 2.5284e-01, time/batch = 16.7879s	
21353/22300 (epoch 47.877), train_loss = 0.32128620, grad/param norm = 2.4247e-01, time/batch = 16.6368s	
21354/22300 (epoch 47.879), train_loss = 0.30009408, grad/param norm = 2.0552e-01, time/batch = 15.2896s	
21355/22300 (epoch 47.881), train_loss = 0.22588645, grad/param norm = 2.2264e-01, time/batch = 16.6354s	
21356/22300 (epoch 47.883), train_loss = 0.25496057, grad/param norm = 2.6905e-01, time/batch = 15.3169s	
21357/22300 (epoch 47.886), train_loss = 0.21821008, grad/param norm = 2.0569e-01, time/batch = 14.9790s	
21358/22300 (epoch 47.888), train_loss = 0.27454714, grad/param norm = 1.8473e-01, time/batch = 17.7171s	
21359/22300 (epoch 47.890), train_loss = 0.27362128, grad/param norm = 1.6421e-01, time/batch = 16.7949s	
21360/22300 (epoch 47.892), train_loss = 0.42029075, grad/param norm = 2.5410e-01, time/batch = 15.3120s	
21361/22300 (epoch 47.895), train_loss = 0.38524567, grad/param norm = 3.2553e-01, time/batch = 16.0574s	
21362/22300 (epoch 47.897), train_loss = 0.29457447, grad/param norm = 2.2438e-01, time/batch = 15.3696s	
21363/22300 (epoch 47.899), train_loss = 0.29538782, grad/param norm = 2.0406e-01, time/batch = 17.1485s	
21364/22300 (epoch 47.901), train_loss = 0.37196648, grad/param norm = 2.6313e-01, time/batch = 17.2584s	
21365/22300 (epoch 47.904), train_loss = 0.33895123, grad/param norm = 2.4707e-01, time/batch = 16.2186s	
21366/22300 (epoch 47.906), train_loss = 0.33819911, grad/param norm = 2.4994e-01, time/batch = 15.7886s	
21367/22300 (epoch 47.908), train_loss = 0.30039541, grad/param norm = 1.9519e-01, time/batch = 15.9686s	
21368/22300 (epoch 47.910), train_loss = 0.26696687, grad/param norm = 2.1064e-01, time/batch = 15.4634s	
21369/22300 (epoch 47.913), train_loss = 0.32975416, grad/param norm = 2.6761e-01, time/batch = 16.8929s	
21370/22300 (epoch 47.915), train_loss = 0.43933511, grad/param norm = 2.6792e-01, time/batch = 17.3881s	
21371/22300 (epoch 47.917), train_loss = 0.34423122, grad/param norm = 2.6542e-01, time/batch = 16.7107s	
21372/22300 (epoch 47.919), train_loss = 0.32635383, grad/param norm = 2.1926e-01, time/batch = 15.4048s	
21373/22300 (epoch 47.922), train_loss = 0.30599941, grad/param norm = 2.0825e-01, time/batch = 15.9034s	
21374/22300 (epoch 47.924), train_loss = 0.19885510, grad/param norm = 1.7435e-01, time/batch = 17.6165s	
21375/22300 (epoch 47.926), train_loss = 0.26452936, grad/param norm = 1.7689e-01, time/batch = 16.7026s	
21376/22300 (epoch 47.928), train_loss = 0.27590623, grad/param norm = 2.1434e-01, time/batch = 16.0322s	
21377/22300 (epoch 47.930), train_loss = 0.24896058, grad/param norm = 2.1284e-01, time/batch = 15.5508s	
21378/22300 (epoch 47.933), train_loss = 0.32655938, grad/param norm = 2.4737e-01, time/batch = 15.7069s	
21379/22300 (epoch 47.935), train_loss = 0.31738238, grad/param norm = 3.1636e-01, time/batch = 15.6555s	
21380/22300 (epoch 47.937), train_loss = 0.41821260, grad/param norm = 3.4881e-01, time/batch = 16.0454s	
21381/22300 (epoch 47.939), train_loss = 0.34721201, grad/param norm = 2.3650e-01, time/batch = 16.0490s	
21382/22300 (epoch 47.942), train_loss = 0.43445317, grad/param norm = 2.7964e-01, time/batch = 13.4473s	
21383/22300 (epoch 47.944), train_loss = 0.49290363, grad/param norm = 3.9125e-01, time/batch = 0.9461s	
21384/22300 (epoch 47.946), train_loss = 0.33831442, grad/param norm = 2.4265e-01, time/batch = 0.6689s	
21385/22300 (epoch 47.948), train_loss = 0.29768117, grad/param norm = 1.9118e-01, time/batch = 0.6655s	
21386/22300 (epoch 47.951), train_loss = 0.23324322, grad/param norm = 2.1776e-01, time/batch = 0.6655s	
21387/22300 (epoch 47.953), train_loss = 0.23444802, grad/param norm = 2.0945e-01, time/batch = 0.6647s	
21388/22300 (epoch 47.955), train_loss = 0.38692895, grad/param norm = 2.6360e-01, time/batch = 0.6530s	
21389/22300 (epoch 47.957), train_loss = 0.47391913, grad/param norm = 2.8666e-01, time/batch = 0.6502s	
21390/22300 (epoch 47.960), train_loss = 0.41667442, grad/param norm = 2.9084e-01, time/batch = 0.6608s	
21391/22300 (epoch 47.962), train_loss = 0.26533633, grad/param norm = 2.4212e-01, time/batch = 0.6599s	
21392/22300 (epoch 47.964), train_loss = 0.24591028, grad/param norm = 2.4609e-01, time/batch = 0.6599s	
21393/22300 (epoch 47.966), train_loss = 0.27238458, grad/param norm = 1.9133e-01, time/batch = 0.6654s	
21394/22300 (epoch 47.969), train_loss = 0.29032942, grad/param norm = 2.1540e-01, time/batch = 0.6573s	
21395/22300 (epoch 47.971), train_loss = 0.31578168, grad/param norm = 2.1910e-01, time/batch = 0.6617s	
21396/22300 (epoch 47.973), train_loss = 0.27643058, grad/param norm = 2.2719e-01, time/batch = 0.6617s	
21397/22300 (epoch 47.975), train_loss = 0.40745206, grad/param norm = 3.0142e-01, time/batch = 0.9674s	
21398/22300 (epoch 47.978), train_loss = 0.40539050, grad/param norm = 2.6902e-01, time/batch = 0.9554s	
21399/22300 (epoch 47.980), train_loss = 0.50103695, grad/param norm = 2.9908e-01, time/batch = 0.9493s	
21400/22300 (epoch 47.982), train_loss = 0.22096567, grad/param norm = 2.1730e-01, time/batch = 0.9651s	
21401/22300 (epoch 47.984), train_loss = 0.30202187, grad/param norm = 2.2206e-01, time/batch = 0.9626s	
21402/22300 (epoch 47.987), train_loss = 0.33429291, grad/param norm = 3.7445e-01, time/batch = 1.7113s	
21403/22300 (epoch 47.989), train_loss = 0.26969477, grad/param norm = 3.2978e-01, time/batch = 1.8429s	
21404/22300 (epoch 47.991), train_loss = 0.47249986, grad/param norm = 3.5087e-01, time/batch = 3.5565s	
21405/22300 (epoch 47.993), train_loss = 0.64830192, grad/param norm = 3.8511e-01, time/batch = 15.2847s	
21406/22300 (epoch 47.996), train_loss = 0.62016920, grad/param norm = 3.4981e-01, time/batch = 15.4107s	
21407/22300 (epoch 47.998), train_loss = 0.36005548, grad/param norm = 2.3856e-01, time/batch = 15.1932s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
21408/22300 (epoch 48.000), train_loss = 0.26859046, grad/param norm = 2.5173e-01, time/batch = 14.9458s	
21409/22300 (epoch 48.002), train_loss = 0.61563924, grad/param norm = 3.2184e-01, time/batch = 14.8602s	
21410/22300 (epoch 48.004), train_loss = 0.36742470, grad/param norm = 2.5072e-01, time/batch = 14.2371s	
21411/22300 (epoch 48.007), train_loss = 0.37974329, grad/param norm = 2.5632e-01, time/batch = 14.7912s	
21412/22300 (epoch 48.009), train_loss = 0.39101089, grad/param norm = 2.8347e-01, time/batch = 14.3265s	
21413/22300 (epoch 48.011), train_loss = 0.48172299, grad/param norm = 2.9770e-01, time/batch = 14.1660s	
21414/22300 (epoch 48.013), train_loss = 0.38682069, grad/param norm = 2.5311e-01, time/batch = 13.9303s	
21415/22300 (epoch 48.016), train_loss = 0.29119455, grad/param norm = 2.5709e-01, time/batch = 14.3915s	
21416/22300 (epoch 48.018), train_loss = 0.30496912, grad/param norm = 2.2782e-01, time/batch = 14.0052s	
21417/22300 (epoch 48.020), train_loss = 0.29652716, grad/param norm = 2.2451e-01, time/batch = 14.3214s	
21418/22300 (epoch 48.022), train_loss = 0.23139489, grad/param norm = 2.7493e-01, time/batch = 14.5676s	
21419/22300 (epoch 48.025), train_loss = 0.30424882, grad/param norm = 2.1615e-01, time/batch = 14.8807s	
21420/22300 (epoch 48.027), train_loss = 0.26313540, grad/param norm = 1.8007e-01, time/batch = 14.4102s	
21421/22300 (epoch 48.029), train_loss = 0.29498797, grad/param norm = 2.0027e-01, time/batch = 14.1739s	
21422/22300 (epoch 48.031), train_loss = 0.27444112, grad/param norm = 2.1645e-01, time/batch = 14.0848s	
21423/22300 (epoch 48.034), train_loss = 0.27158460, grad/param norm = 2.1882e-01, time/batch = 14.6447s	
21424/22300 (epoch 48.036), train_loss = 0.27600403, grad/param norm = 1.9932e-01, time/batch = 14.3334s	
21425/22300 (epoch 48.038), train_loss = 0.23027800, grad/param norm = 2.1533e-01, time/batch = 14.4054s	
21426/22300 (epoch 48.040), train_loss = 0.28090558, grad/param norm = 2.4093e-01, time/batch = 14.5648s	
21427/22300 (epoch 48.043), train_loss = 0.47071193, grad/param norm = 3.5590e-01, time/batch = 14.5785s	
21428/22300 (epoch 48.045), train_loss = 0.39801158, grad/param norm = 2.6022e-01, time/batch = 14.3981s	
21429/22300 (epoch 48.047), train_loss = 0.41818397, grad/param norm = 2.7839e-01, time/batch = 14.6354s	
21430/22300 (epoch 48.049), train_loss = 0.33046866, grad/param norm = 2.4675e-01, time/batch = 14.8774s	
21431/22300 (epoch 48.052), train_loss = 0.37450150, grad/param norm = 2.9559e-01, time/batch = 14.7255s	
21432/22300 (epoch 48.054), train_loss = 0.37665105, grad/param norm = 2.4399e-01, time/batch = 14.4882s	
21433/22300 (epoch 48.056), train_loss = 0.18885071, grad/param norm = 1.5893e-01, time/batch = 14.1708s	
21434/22300 (epoch 48.058), train_loss = 0.30130589, grad/param norm = 2.4895e-01, time/batch = 14.5623s	
21435/22300 (epoch 48.061), train_loss = 0.25857675, grad/param norm = 2.1209e-01, time/batch = 14.3305s	
21436/22300 (epoch 48.063), train_loss = 0.41977681, grad/param norm = 3.3248e-01, time/batch = 14.5568s	
21437/22300 (epoch 48.065), train_loss = 0.47923645, grad/param norm = 3.1950e-01, time/batch = 14.3027s	
21438/22300 (epoch 48.067), train_loss = 0.26918177, grad/param norm = 2.5513e-01, time/batch = 15.1163s	
21439/22300 (epoch 48.070), train_loss = 0.31146943, grad/param norm = 2.9133e-01, time/batch = 15.2557s	
21440/22300 (epoch 48.072), train_loss = 0.33264072, grad/param norm = 2.6978e-01, time/batch = 14.7138s	
21441/22300 (epoch 48.074), train_loss = 0.37233926, grad/param norm = 3.0207e-01, time/batch = 14.8030s	
21442/22300 (epoch 48.076), train_loss = 0.32572215, grad/param norm = 3.0034e-01, time/batch = 15.0217s	
21443/22300 (epoch 48.078), train_loss = 0.46794932, grad/param norm = 3.5627e-01, time/batch = 14.5771s	
21444/22300 (epoch 48.081), train_loss = 0.43531280, grad/param norm = 3.2823e-01, time/batch = 15.0500s	
21445/22300 (epoch 48.083), train_loss = 0.50955323, grad/param norm = 3.7824e-01, time/batch = 14.4976s	
21446/22300 (epoch 48.085), train_loss = 0.47493999, grad/param norm = 3.6487e-01, time/batch = 14.5781s	
21447/22300 (epoch 48.087), train_loss = 0.36219410, grad/param norm = 2.7446e-01, time/batch = 14.6608s	
21448/22300 (epoch 48.090), train_loss = 0.36032371, grad/param norm = 2.9874e-01, time/batch = 15.2521s	
21449/22300 (epoch 48.092), train_loss = 0.26714605, grad/param norm = 2.3855e-01, time/batch = 14.4961s	
21450/22300 (epoch 48.094), train_loss = 0.26165027, grad/param norm = 2.2392e-01, time/batch = 14.7365s	
21451/22300 (epoch 48.096), train_loss = 0.46654561, grad/param norm = 3.2129e-01, time/batch = 14.5792s	
21452/22300 (epoch 48.099), train_loss = 0.31214664, grad/param norm = 2.9154e-01, time/batch = 15.0486s	
21453/22300 (epoch 48.101), train_loss = 0.40945835, grad/param norm = 2.9750e-01, time/batch = 14.7177s	
21454/22300 (epoch 48.103), train_loss = 0.32778717, grad/param norm = 2.4021e-01, time/batch = 14.5628s	
21455/22300 (epoch 48.105), train_loss = 0.25938197, grad/param norm = 2.4914e-01, time/batch = 14.7329s	
21456/22300 (epoch 48.108), train_loss = 0.37285505, grad/param norm = 2.4764e-01, time/batch = 15.4937s	
21457/22300 (epoch 48.110), train_loss = 0.42079793, grad/param norm = 2.9289e-01, time/batch = 15.5111s	
21458/22300 (epoch 48.112), train_loss = 0.34278027, grad/param norm = 2.1300e-01, time/batch = 15.1086s	
21459/22300 (epoch 48.114), train_loss = 0.39537309, grad/param norm = 2.7582e-01, time/batch = 15.5038s	
21460/22300 (epoch 48.117), train_loss = 0.47055875, grad/param norm = 3.1046e-01, time/batch = 15.5897s	
21461/22300 (epoch 48.119), train_loss = 0.39898016, grad/param norm = 3.3887e-01, time/batch = 14.5807s	
21462/22300 (epoch 48.121), train_loss = 0.45379532, grad/param norm = 3.4633e-01, time/batch = 14.5661s	
21463/22300 (epoch 48.123), train_loss = 0.48973994, grad/param norm = 2.7271e-01, time/batch = 15.0500s	
21464/22300 (epoch 48.126), train_loss = 0.37113483, grad/param norm = 2.1673e-01, time/batch = 14.8011s	
21465/22300 (epoch 48.128), train_loss = 0.34629773, grad/param norm = 2.7375e-01, time/batch = 14.4840s	
21466/22300 (epoch 48.130), train_loss = 0.32654742, grad/param norm = 2.9400e-01, time/batch = 14.3918s	
21467/22300 (epoch 48.132), train_loss = 0.22156693, grad/param norm = 1.7738e-01, time/batch = 14.3353s	
21468/22300 (epoch 48.135), train_loss = 0.25633468, grad/param norm = 2.5748e-01, time/batch = 14.6394s	
21469/22300 (epoch 48.137), train_loss = 0.20497152, grad/param norm = 2.0946e-01, time/batch = 14.0888s	
21470/22300 (epoch 48.139), train_loss = 0.27488250, grad/param norm = 2.4635e-01, time/batch = 14.9265s	
21471/22300 (epoch 48.141), train_loss = 0.39884074, grad/param norm = 2.5634e-01, time/batch = 14.2507s	
21472/22300 (epoch 48.143), train_loss = 0.31477117, grad/param norm = 2.4733e-01, time/batch = 14.7332s	
21473/22300 (epoch 48.146), train_loss = 0.38683099, grad/param norm = 2.6721e-01, time/batch = 14.6537s	
21474/22300 (epoch 48.148), train_loss = 0.26160465, grad/param norm = 2.1651e-01, time/batch = 14.1651s	
21475/22300 (epoch 48.150), train_loss = 0.29834313, grad/param norm = 2.5644e-01, time/batch = 14.0944s	
21476/22300 (epoch 48.152), train_loss = 0.23284030, grad/param norm = 2.0285e-01, time/batch = 14.3983s	
21477/22300 (epoch 48.155), train_loss = 0.26918012, grad/param norm = 1.9329e-01, time/batch = 14.0875s	
21478/22300 (epoch 48.157), train_loss = 0.34570235, grad/param norm = 2.6418e-01, time/batch = 14.0048s	
21479/22300 (epoch 48.159), train_loss = 0.36975964, grad/param norm = 2.7512e-01, time/batch = 15.0445s	
21480/22300 (epoch 48.161), train_loss = 0.35845942, grad/param norm = 2.6858e-01, time/batch = 14.5624s	
21481/22300 (epoch 48.164), train_loss = 0.26261217, grad/param norm = 1.8161e-01, time/batch = 14.1648s	
21482/22300 (epoch 48.166), train_loss = 0.23229251, grad/param norm = 1.8070e-01, time/batch = 14.6335s	
21483/22300 (epoch 48.168), train_loss = 0.21610854, grad/param norm = 2.1278e-01, time/batch = 14.0020s	
21484/22300 (epoch 48.170), train_loss = 0.32614937, grad/param norm = 2.3774e-01, time/batch = 15.1870s	
21485/22300 (epoch 48.173), train_loss = 0.35563991, grad/param norm = 3.2452e-01, time/batch = 14.4127s	
21486/22300 (epoch 48.175), train_loss = 0.32585393, grad/param norm = 2.3544e-01, time/batch = 14.4657s	
21487/22300 (epoch 48.177), train_loss = 0.21529808, grad/param norm = 1.9906e-01, time/batch = 13.9961s	
21488/22300 (epoch 48.179), train_loss = 0.33503391, grad/param norm = 2.7227e-01, time/batch = 14.3335s	
21489/22300 (epoch 48.182), train_loss = 0.45996335, grad/param norm = 3.3903e-01, time/batch = 15.5191s	
21490/22300 (epoch 48.184), train_loss = 0.47380271, grad/param norm = 3.1425e-01, time/batch = 14.6335s	
21491/22300 (epoch 48.186), train_loss = 0.36660103, grad/param norm = 3.9699e-01, time/batch = 15.2976s	
21492/22300 (epoch 48.188), train_loss = 0.52403082, grad/param norm = 3.7224e-01, time/batch = 15.2932s	
21493/22300 (epoch 48.191), train_loss = 0.41471510, grad/param norm = 2.6968e-01, time/batch = 15.5461s	
21494/22300 (epoch 48.193), train_loss = 0.35417814, grad/param norm = 2.5971e-01, time/batch = 18.5521s	
21495/22300 (epoch 48.195), train_loss = 0.30971045, grad/param norm = 3.0101e-01, time/batch = 16.6397s	
21496/22300 (epoch 48.197), train_loss = 0.28971591, grad/param norm = 2.1829e-01, time/batch = 15.5429s	
21497/22300 (epoch 48.200), train_loss = 0.24095627, grad/param norm = 2.0307e-01, time/batch = 14.6995s	
21498/22300 (epoch 48.202), train_loss = 0.26510205, grad/param norm = 2.1287e-01, time/batch = 15.6811s	
21499/22300 (epoch 48.204), train_loss = 0.32343482, grad/param norm = 2.2005e-01, time/batch = 15.2199s	
21500/22300 (epoch 48.206), train_loss = 0.27278290, grad/param norm = 2.2455e-01, time/batch = 15.8681s	
21501/22300 (epoch 48.209), train_loss = 0.29510083, grad/param norm = 1.9906e-01, time/batch = 16.3795s	
21502/22300 (epoch 48.211), train_loss = 0.22987355, grad/param norm = 2.7592e-01, time/batch = 15.8203s	
21503/22300 (epoch 48.213), train_loss = 0.35467620, grad/param norm = 2.4632e-01, time/batch = 15.4522s	
21504/22300 (epoch 48.215), train_loss = 0.42169036, grad/param norm = 3.3502e-01, time/batch = 15.3732s	
21505/22300 (epoch 48.217), train_loss = 0.47451436, grad/param norm = 3.1238e-01, time/batch = 14.9832s	
21506/22300 (epoch 48.220), train_loss = 0.33269994, grad/param norm = 2.4425e-01, time/batch = 15.7304s	
21507/22300 (epoch 48.222), train_loss = 0.28369248, grad/param norm = 2.7183e-01, time/batch = 16.1232s	
21508/22300 (epoch 48.224), train_loss = 0.26802691, grad/param norm = 1.9838e-01, time/batch = 17.7005s	
21509/22300 (epoch 48.226), train_loss = 0.33497903, grad/param norm = 2.2314e-01, time/batch = 17.8656s	
21510/22300 (epoch 48.229), train_loss = 0.26400578, grad/param norm = 2.2164e-01, time/batch = 18.4521s	
21511/22300 (epoch 48.231), train_loss = 0.43615409, grad/param norm = 3.2716e-01, time/batch = 15.4360s	
21512/22300 (epoch 48.233), train_loss = 0.34313569, grad/param norm = 2.7833e-01, time/batch = 14.9583s	
21513/22300 (epoch 48.235), train_loss = 0.26292228, grad/param norm = 1.9455e-01, time/batch = 17.0485s	
21514/22300 (epoch 48.238), train_loss = 0.25912584, grad/param norm = 2.1905e-01, time/batch = 17.7140s	
21515/22300 (epoch 48.240), train_loss = 0.27445706, grad/param norm = 2.0973e-01, time/batch = 16.4331s	
21516/22300 (epoch 48.242), train_loss = 0.24190305, grad/param norm = 2.2435e-01, time/batch = 17.4583s	
21517/22300 (epoch 48.244), train_loss = 0.18359190, grad/param norm = 1.7829e-01, time/batch = 15.9001s	
21518/22300 (epoch 48.247), train_loss = 0.24234412, grad/param norm = 1.9933e-01, time/batch = 17.1988s	
21519/22300 (epoch 48.249), train_loss = 0.16653397, grad/param norm = 1.3690e-01, time/batch = 17.2114s	
21520/22300 (epoch 48.251), train_loss = 0.22045269, grad/param norm = 1.5570e-01, time/batch = 16.0614s	
21521/22300 (epoch 48.253), train_loss = 0.13974703, grad/param norm = 1.6245e-01, time/batch = 16.2177s	
21522/22300 (epoch 48.256), train_loss = 0.21402315, grad/param norm = 1.7321e-01, time/batch = 17.1326s	
21523/22300 (epoch 48.258), train_loss = 0.30851884, grad/param norm = 2.8616e-01, time/batch = 17.9523s	
21524/22300 (epoch 48.260), train_loss = 0.36427282, grad/param norm = 2.9132e-01, time/batch = 15.3847s	
21525/22300 (epoch 48.262), train_loss = 0.25244129, grad/param norm = 1.8205e-01, time/batch = 15.4727s	
21526/22300 (epoch 48.265), train_loss = 0.22730356, grad/param norm = 2.0107e-01, time/batch = 15.9766s	
21527/22300 (epoch 48.267), train_loss = 0.24578533, grad/param norm = 1.9502e-01, time/batch = 14.7366s	
21528/22300 (epoch 48.269), train_loss = 0.32098383, grad/param norm = 2.7934e-01, time/batch = 15.7308s	
21529/22300 (epoch 48.271), train_loss = 0.34708912, grad/param norm = 2.4311e-01, time/batch = 15.8970s	
21530/22300 (epoch 48.274), train_loss = 0.23202064, grad/param norm = 2.4773e-01, time/batch = 18.6132s	
21531/22300 (epoch 48.276), train_loss = 0.20142603, grad/param norm = 1.4258e-01, time/batch = 16.0674s	
21532/22300 (epoch 48.278), train_loss = 0.23244063, grad/param norm = 1.7809e-01, time/batch = 14.4938s	
21533/22300 (epoch 48.280), train_loss = 0.23605826, grad/param norm = 1.7239e-01, time/batch = 15.8930s	
21534/22300 (epoch 48.283), train_loss = 0.20486334, grad/param norm = 1.4915e-01, time/batch = 15.0485s	
21535/22300 (epoch 48.285), train_loss = 0.21657064, grad/param norm = 2.1964e-01, time/batch = 15.0754s	
21536/22300 (epoch 48.287), train_loss = 0.31066902, grad/param norm = 2.1443e-01, time/batch = 14.6327s	
21537/22300 (epoch 48.289), train_loss = 0.28707329, grad/param norm = 2.1479e-01, time/batch = 15.5510s	
21538/22300 (epoch 48.291), train_loss = 0.27226914, grad/param norm = 1.9866e-01, time/batch = 16.7230s	
21539/22300 (epoch 48.294), train_loss = 0.22242618, grad/param norm = 1.8421e-01, time/batch = 17.4635s	
21540/22300 (epoch 48.296), train_loss = 0.26302285, grad/param norm = 2.5106e-01, time/batch = 16.5518s	
21541/22300 (epoch 48.298), train_loss = 0.35214666, grad/param norm = 2.1115e-01, time/batch = 15.3936s	
21542/22300 (epoch 48.300), train_loss = 0.40183028, grad/param norm = 2.6850e-01, time/batch = 15.0698s	
21543/22300 (epoch 48.303), train_loss = 0.28590558, grad/param norm = 2.1049e-01, time/batch = 16.7971s	
21544/22300 (epoch 48.305), train_loss = 0.30757199, grad/param norm = 2.4095e-01, time/batch = 16.0357s	
21545/22300 (epoch 48.307), train_loss = 0.24877209, grad/param norm = 1.9866e-01, time/batch = 17.2228s	
21546/22300 (epoch 48.309), train_loss = 0.21989720, grad/param norm = 1.7056e-01, time/batch = 16.8936s	
21547/22300 (epoch 48.312), train_loss = 0.19337810, grad/param norm = 1.6635e-01, time/batch = 16.3826s	
21548/22300 (epoch 48.314), train_loss = 0.24521129, grad/param norm = 2.0172e-01, time/batch = 16.3581s	
21549/22300 (epoch 48.316), train_loss = 0.23019632, grad/param norm = 2.1180e-01, time/batch = 16.6331s	
21550/22300 (epoch 48.318), train_loss = 0.25769258, grad/param norm = 1.8576e-01, time/batch = 17.1515s	
21551/22300 (epoch 48.321), train_loss = 0.33438836, grad/param norm = 2.2779e-01, time/batch = 15.5388s	
21552/22300 (epoch 48.323), train_loss = 0.23010140, grad/param norm = 1.7474e-01, time/batch = 16.1910s	
21553/22300 (epoch 48.325), train_loss = 0.19604755, grad/param norm = 1.6543e-01, time/batch = 16.4740s	
21554/22300 (epoch 48.327), train_loss = 0.22476362, grad/param norm = 1.3825e-01, time/batch = 16.3095s	
21555/22300 (epoch 48.330), train_loss = 0.23328279, grad/param norm = 2.7319e-01, time/batch = 15.2931s	
21556/22300 (epoch 48.332), train_loss = 0.22017209, grad/param norm = 2.2391e-01, time/batch = 15.6460s	
21557/22300 (epoch 48.334), train_loss = 0.24476351, grad/param norm = 1.8203e-01, time/batch = 15.6359s	
21558/22300 (epoch 48.336), train_loss = 0.24160782, grad/param norm = 1.9912e-01, time/batch = 17.0378s	
21559/22300 (epoch 48.339), train_loss = 0.30906783, grad/param norm = 2.0851e-01, time/batch = 15.1720s	
21560/22300 (epoch 48.341), train_loss = 0.28904246, grad/param norm = 2.0078e-01, time/batch = 15.6777s	
21561/22300 (epoch 48.343), train_loss = 0.33385617, grad/param norm = 2.4940e-01, time/batch = 15.1864s	
21562/22300 (epoch 48.345), train_loss = 0.28466125, grad/param norm = 2.1174e-01, time/batch = 14.7200s	
21563/22300 (epoch 48.348), train_loss = 0.28994732, grad/param norm = 1.6611e-01, time/batch = 16.0558s	
21564/22300 (epoch 48.350), train_loss = 0.18251851, grad/param norm = 1.5329e-01, time/batch = 15.0699s	
21565/22300 (epoch 48.352), train_loss = 0.29158408, grad/param norm = 2.5085e-01, time/batch = 16.5485s	
21566/22300 (epoch 48.354), train_loss = 0.39735423, grad/param norm = 2.8373e-01, time/batch = 15.5392s	
21567/22300 (epoch 48.357), train_loss = 0.38823581, grad/param norm = 2.3781e-01, time/batch = 14.5742s	
21568/22300 (epoch 48.359), train_loss = 0.22423794, grad/param norm = 2.0369e-01, time/batch = 14.8944s	
21569/22300 (epoch 48.361), train_loss = 0.24456379, grad/param norm = 2.3569e-01, time/batch = 15.5730s	
21570/22300 (epoch 48.363), train_loss = 0.32790366, grad/param norm = 2.1887e-01, time/batch = 15.9518s	
21571/22300 (epoch 48.365), train_loss = 0.22802499, grad/param norm = 2.2733e-01, time/batch = 15.5227s	
21572/22300 (epoch 48.368), train_loss = 0.24329004, grad/param norm = 3.4183e-01, time/batch = 15.2662s	
21573/22300 (epoch 48.370), train_loss = 0.26782871, grad/param norm = 2.6375e-01, time/batch = 15.5499s	
21574/22300 (epoch 48.372), train_loss = 0.17612866, grad/param norm = 1.7848e-01, time/batch = 15.6918s	
21575/22300 (epoch 48.374), train_loss = 0.19834535, grad/param norm = 1.5880e-01, time/batch = 16.2376s	
21576/22300 (epoch 48.377), train_loss = 0.26807246, grad/param norm = 1.9725e-01, time/batch = 16.8981s	
21577/22300 (epoch 48.379), train_loss = 0.22716112, grad/param norm = 2.3529e-01, time/batch = 16.7199s	
21578/22300 (epoch 48.381), train_loss = 0.32174309, grad/param norm = 2.3872e-01, time/batch = 16.2960s	
21579/22300 (epoch 48.383), train_loss = 0.23853568, grad/param norm = 2.2044e-01, time/batch = 17.1403s	
21580/22300 (epoch 48.386), train_loss = 0.29809303, grad/param norm = 1.8337e-01, time/batch = 15.3955s	
21581/22300 (epoch 48.388), train_loss = 0.18640099, grad/param norm = 1.6303e-01, time/batch = 16.8806s	
21582/22300 (epoch 48.390), train_loss = 0.21447271, grad/param norm = 1.9131e-01, time/batch = 15.7902s	
21583/22300 (epoch 48.392), train_loss = 0.26290828, grad/param norm = 3.0893e-01, time/batch = 16.5589s	
21584/22300 (epoch 48.395), train_loss = 0.21621167, grad/param norm = 2.1047e-01, time/batch = 17.2225s	
21585/22300 (epoch 48.397), train_loss = 0.15836646, grad/param norm = 1.3605e-01, time/batch = 15.8059s	
21586/22300 (epoch 48.399), train_loss = 0.21983763, grad/param norm = 2.4302e-01, time/batch = 15.2088s	
21587/22300 (epoch 48.401), train_loss = 0.24534596, grad/param norm = 2.5927e-01, time/batch = 15.8558s	
21588/22300 (epoch 48.404), train_loss = 0.26607535, grad/param norm = 1.9955e-01, time/batch = 17.9510s	
21589/22300 (epoch 48.406), train_loss = 0.37412712, grad/param norm = 2.1529e-01, time/batch = 15.8761s	
21590/22300 (epoch 48.408), train_loss = 0.28893192, grad/param norm = 2.4180e-01, time/batch = 17.6400s	
21591/22300 (epoch 48.410), train_loss = 0.33026636, grad/param norm = 2.6986e-01, time/batch = 15.6319s	
21592/22300 (epoch 48.413), train_loss = 0.25758137, grad/param norm = 2.4004e-01, time/batch = 15.5479s	
21593/22300 (epoch 48.415), train_loss = 0.18799705, grad/param norm = 2.7378e-01, time/batch = 16.7235s	
21594/22300 (epoch 48.417), train_loss = 0.29404192, grad/param norm = 2.7073e-01, time/batch = 17.7127s	
21595/22300 (epoch 48.419), train_loss = 0.26507108, grad/param norm = 1.8105e-01, time/batch = 15.6372s	
21596/22300 (epoch 48.422), train_loss = 0.22729214, grad/param norm = 2.2466e-01, time/batch = 15.3031s	
21597/22300 (epoch 48.424), train_loss = 0.26380551, grad/param norm = 1.9185e-01, time/batch = 16.3552s	
21598/22300 (epoch 48.426), train_loss = 0.19088051, grad/param norm = 1.7849e-01, time/batch = 15.1535s	
21599/22300 (epoch 48.428), train_loss = 0.21232673, grad/param norm = 2.0737e-01, time/batch = 15.7798s	
21600/22300 (epoch 48.430), train_loss = 0.23979042, grad/param norm = 2.1152e-01, time/batch = 15.0192s	
21601/22300 (epoch 48.433), train_loss = 0.26222460, grad/param norm = 2.1217e-01, time/batch = 15.7325s	
21602/22300 (epoch 48.435), train_loss = 0.23473864, grad/param norm = 1.7106e-01, time/batch = 16.1352s	
21603/22300 (epoch 48.437), train_loss = 0.28009586, grad/param norm = 2.9421e-01, time/batch = 15.1213s	
21604/22300 (epoch 48.439), train_loss = 0.30270714, grad/param norm = 2.3793e-01, time/batch = 15.1481s	
21605/22300 (epoch 48.442), train_loss = 0.26647728, grad/param norm = 2.4032e-01, time/batch = 15.8208s	
21606/22300 (epoch 48.444), train_loss = 0.23542166, grad/param norm = 2.0194e-01, time/batch = 15.2264s	
21607/22300 (epoch 48.446), train_loss = 0.27200102, grad/param norm = 1.9688e-01, time/batch = 16.3962s	
21608/22300 (epoch 48.448), train_loss = 0.20165320, grad/param norm = 1.4580e-01, time/batch = 16.4782s	
21609/22300 (epoch 48.451), train_loss = 0.30306973, grad/param norm = 2.4163e-01, time/batch = 15.4022s	
21610/22300 (epoch 48.453), train_loss = 0.23711722, grad/param norm = 2.0451e-01, time/batch = 14.8866s	
21611/22300 (epoch 48.455), train_loss = 0.33996549, grad/param norm = 3.2121e-01, time/batch = 14.8096s	
21612/22300 (epoch 48.457), train_loss = 0.43628648, grad/param norm = 2.9726e-01, time/batch = 15.2038s	
21613/22300 (epoch 48.460), train_loss = 0.36306102, grad/param norm = 2.4822e-01, time/batch = 16.7265s	
21614/22300 (epoch 48.462), train_loss = 0.36084393, grad/param norm = 2.2619e-01, time/batch = 15.6291s	
21615/22300 (epoch 48.464), train_loss = 0.31819865, grad/param norm = 2.5975e-01, time/batch = 15.5984s	
21616/22300 (epoch 48.466), train_loss = 0.24671825, grad/param norm = 1.7267e-01, time/batch = 15.5230s	
21617/22300 (epoch 48.469), train_loss = 0.24100652, grad/param norm = 1.6869e-01, time/batch = 15.4091s	
21618/22300 (epoch 48.471), train_loss = 0.34879879, grad/param norm = 1.9163e-01, time/batch = 17.2140s	
21619/22300 (epoch 48.473), train_loss = 0.28152760, grad/param norm = 1.7179e-01, time/batch = 15.2334s	
21620/22300 (epoch 48.475), train_loss = 0.23095877, grad/param norm = 2.0638e-01, time/batch = 18.0451s	
21621/22300 (epoch 48.478), train_loss = 0.24478267, grad/param norm = 2.0875e-01, time/batch = 16.8793s	
21622/22300 (epoch 48.480), train_loss = 0.18011427, grad/param norm = 1.6320e-01, time/batch = 17.2949s	
21623/22300 (epoch 48.482), train_loss = 0.21512018, grad/param norm = 1.4150e-01, time/batch = 17.2937s	
21624/22300 (epoch 48.484), train_loss = 0.28506777, grad/param norm = 2.1841e-01, time/batch = 16.2355s	
21625/22300 (epoch 48.487), train_loss = 0.33267301, grad/param norm = 2.1207e-01, time/batch = 16.6362s	
21626/22300 (epoch 48.489), train_loss = 0.32589397, grad/param norm = 3.0448e-01, time/batch = 15.7973s	
21627/22300 (epoch 48.491), train_loss = 0.36319343, grad/param norm = 2.6260e-01, time/batch = 16.6240s	
21628/22300 (epoch 48.493), train_loss = 0.23869647, grad/param norm = 2.9647e-01, time/batch = 15.4499s	
21629/22300 (epoch 48.496), train_loss = 0.30055954, grad/param norm = 1.9407e-01, time/batch = 16.0410s	
21630/22300 (epoch 48.498), train_loss = 0.18436175, grad/param norm = 1.5006e-01, time/batch = 15.8693s	
21631/22300 (epoch 48.500), train_loss = 0.27335704, grad/param norm = 1.9783e-01, time/batch = 16.6504s	
21632/22300 (epoch 48.502), train_loss = 0.16016223, grad/param norm = 1.5150e-01, time/batch = 17.9628s	
21633/22300 (epoch 48.504), train_loss = 0.18431558, grad/param norm = 1.6682e-01, time/batch = 26.2304s	
21634/22300 (epoch 48.507), train_loss = 0.23130517, grad/param norm = 2.5490e-01, time/batch = 20.3393s	
21635/22300 (epoch 48.509), train_loss = 0.30522093, grad/param norm = 1.9690e-01, time/batch = 14.7425s	
21636/22300 (epoch 48.511), train_loss = 0.17946931, grad/param norm = 1.5170e-01, time/batch = 15.1719s	
21637/22300 (epoch 48.513), train_loss = 0.19826495, grad/param norm = 1.5049e-01, time/batch = 15.0571s	
21638/22300 (epoch 48.516), train_loss = 0.24477892, grad/param norm = 1.7412e-01, time/batch = 15.6175s	
21639/22300 (epoch 48.518), train_loss = 0.27597854, grad/param norm = 2.0088e-01, time/batch = 15.3571s	
21640/22300 (epoch 48.520), train_loss = 0.21628347, grad/param norm = 1.8873e-01, time/batch = 15.6044s	
21641/22300 (epoch 48.522), train_loss = 0.27116248, grad/param norm = 1.7818e-01, time/batch = 15.4641s	
21642/22300 (epoch 48.525), train_loss = 0.20378487, grad/param norm = 2.2120e-01, time/batch = 15.3600s	
21643/22300 (epoch 48.527), train_loss = 0.31042958, grad/param norm = 2.5654e-01, time/batch = 15.0466s	
21644/22300 (epoch 48.529), train_loss = 0.27536856, grad/param norm = 3.4443e-01, time/batch = 15.1422s	
21645/22300 (epoch 48.531), train_loss = 0.23926260, grad/param norm = 1.9115e-01, time/batch = 14.9769s	
21646/22300 (epoch 48.534), train_loss = 0.26932222, grad/param norm = 1.7321e-01, time/batch = 15.1512s	
21647/22300 (epoch 48.536), train_loss = 0.39061035, grad/param norm = 2.4831e-01, time/batch = 15.2181s	
21648/22300 (epoch 48.538), train_loss = 0.47772404, grad/param norm = 3.4467e-01, time/batch = 15.3762s	
21649/22300 (epoch 48.540), train_loss = 0.26503077, grad/param norm = 2.1565e-01, time/batch = 15.0593s	
21650/22300 (epoch 48.543), train_loss = 0.29088753, grad/param norm = 2.1034e-01, time/batch = 14.9704s	
21651/22300 (epoch 48.545), train_loss = 0.19163770, grad/param norm = 2.2437e-01, time/batch = 15.9182s	
21652/22300 (epoch 48.547), train_loss = 0.17281356, grad/param norm = 2.6374e-01, time/batch = 15.2141s	
21653/22300 (epoch 48.549), train_loss = 0.20113389, grad/param norm = 2.5731e-01, time/batch = 15.0615s	
21654/22300 (epoch 48.552), train_loss = 0.21790383, grad/param norm = 1.9922e-01, time/batch = 14.7953s	
21655/22300 (epoch 48.554), train_loss = 0.29725432, grad/param norm = 2.6620e-01, time/batch = 14.8848s	
21656/22300 (epoch 48.556), train_loss = 0.40587462, grad/param norm = 3.2095e-01, time/batch = 15.4345s	
21657/22300 (epoch 48.558), train_loss = 0.28259789, grad/param norm = 2.3521e-01, time/batch = 15.3139s	
21658/22300 (epoch 48.561), train_loss = 0.42863361, grad/param norm = 3.0559e-01, time/batch = 15.1638s	
21659/22300 (epoch 48.563), train_loss = 0.34434713, grad/param norm = 2.3523e-01, time/batch = 15.1271s	
21660/22300 (epoch 48.565), train_loss = 0.26352007, grad/param norm = 2.1408e-01, time/batch = 14.9876s	
21661/22300 (epoch 48.567), train_loss = 0.24987059, grad/param norm = 2.3808e-01, time/batch = 15.4320s	
21662/22300 (epoch 48.570), train_loss = 0.35836122, grad/param norm = 2.7036e-01, time/batch = 15.5206s	
21663/22300 (epoch 48.572), train_loss = 0.37017317, grad/param norm = 3.3222e-01, time/batch = 15.6334s	
21664/22300 (epoch 48.574), train_loss = 0.26999585, grad/param norm = 2.2996e-01, time/batch = 15.6222s	
21665/22300 (epoch 48.576), train_loss = 0.25251432, grad/param norm = 1.6286e-01, time/batch = 15.1620s	
21666/22300 (epoch 48.578), train_loss = 0.14042311, grad/param norm = 1.3196e-01, time/batch = 15.3870s	
21667/22300 (epoch 48.581), train_loss = 0.22533224, grad/param norm = 2.3640e-01, time/batch = 15.3055s	
21668/22300 (epoch 48.583), train_loss = 0.25235883, grad/param norm = 1.9445e-01, time/batch = 15.5650s	
21669/22300 (epoch 48.585), train_loss = 0.33017870, grad/param norm = 2.5436e-01, time/batch = 15.7116s	
21670/22300 (epoch 48.587), train_loss = 0.50852343, grad/param norm = 3.8488e-01, time/batch = 15.7056s	
21671/22300 (epoch 48.590), train_loss = 0.40050137, grad/param norm = 3.8170e-01, time/batch = 15.7722s	
21672/22300 (epoch 48.592), train_loss = 0.46118866, grad/param norm = 3.1911e-01, time/batch = 15.5680s	
21673/22300 (epoch 48.594), train_loss = 0.45105405, grad/param norm = 4.1343e-01, time/batch = 15.4878s	
21674/22300 (epoch 48.596), train_loss = 0.29279321, grad/param norm = 2.2091e-01, time/batch = 15.6576s	
21675/22300 (epoch 48.599), train_loss = 0.19636011, grad/param norm = 2.3725e-01, time/batch = 15.4594s	
21676/22300 (epoch 48.601), train_loss = 0.21968518, grad/param norm = 1.7922e-01, time/batch = 15.3250s	
21677/22300 (epoch 48.603), train_loss = 0.23683942, grad/param norm = 2.0176e-01, time/batch = 15.4494s	
21678/22300 (epoch 48.605), train_loss = 0.26919237, grad/param norm = 2.1982e-01, time/batch = 15.4899s	
21679/22300 (epoch 48.608), train_loss = 0.45748693, grad/param norm = 3.2748e-01, time/batch = 15.7418s	
21680/22300 (epoch 48.610), train_loss = 0.51744735, grad/param norm = 3.3045e-01, time/batch = 15.2446s	
21681/22300 (epoch 48.612), train_loss = 0.36069126, grad/param norm = 3.0297e-01, time/batch = 15.6509s	
21682/22300 (epoch 48.614), train_loss = 0.33512147, grad/param norm = 2.9726e-01, time/batch = 15.2433s	
21683/22300 (epoch 48.617), train_loss = 0.38283187, grad/param norm = 2.5442e-01, time/batch = 15.4744s	
21684/22300 (epoch 48.619), train_loss = 0.35197861, grad/param norm = 2.3837e-01, time/batch = 15.0782s	
21685/22300 (epoch 48.621), train_loss = 0.24416619, grad/param norm = 2.1851e-01, time/batch = 15.3957s	
21686/22300 (epoch 48.623), train_loss = 0.25085323, grad/param norm = 2.0097e-01, time/batch = 15.7005s	
21687/22300 (epoch 48.626), train_loss = 0.25050757, grad/param norm = 2.4386e-01, time/batch = 15.7444s	
21688/22300 (epoch 48.628), train_loss = 0.24624568, grad/param norm = 1.6114e-01, time/batch = 15.2857s	
21689/22300 (epoch 48.630), train_loss = 0.29036850, grad/param norm = 1.9901e-01, time/batch = 15.4723s	
21690/22300 (epoch 48.632), train_loss = 0.26433681, grad/param norm = 2.7714e-01, time/batch = 15.5387s	
21691/22300 (epoch 48.635), train_loss = 0.30164596, grad/param norm = 2.3655e-01, time/batch = 15.1499s	
21692/22300 (epoch 48.637), train_loss = 0.32528522, grad/param norm = 2.3469e-01, time/batch = 14.9948s	
21693/22300 (epoch 48.639), train_loss = 0.41861798, grad/param norm = 3.7994e-01, time/batch = 15.3834s	
21694/22300 (epoch 48.641), train_loss = 0.32674436, grad/param norm = 2.8454e-01, time/batch = 15.7160s	
21695/22300 (epoch 48.643), train_loss = 0.24603881, grad/param norm = 1.9965e-01, time/batch = 15.6193s	
21696/22300 (epoch 48.646), train_loss = 0.24405194, grad/param norm = 2.0316e-01, time/batch = 15.2218s	
21697/22300 (epoch 48.648), train_loss = 0.35444351, grad/param norm = 2.6758e-01, time/batch = 15.3933s	
21698/22300 (epoch 48.650), train_loss = 0.32854026, grad/param norm = 2.8780e-01, time/batch = 15.6896s	
21699/22300 (epoch 48.652), train_loss = 0.26674509, grad/param norm = 2.1431e-01, time/batch = 15.4534s	
21700/22300 (epoch 48.655), train_loss = 0.21568279, grad/param norm = 1.7848e-01, time/batch = 15.2257s	
21701/22300 (epoch 48.657), train_loss = 0.25530245, grad/param norm = 2.3548e-01, time/batch = 15.3168s	
21702/22300 (epoch 48.659), train_loss = 0.25685833, grad/param norm = 2.2052e-01, time/batch = 15.5576s	
21703/22300 (epoch 48.661), train_loss = 0.21250410, grad/param norm = 1.6243e-01, time/batch = 15.1568s	
21704/22300 (epoch 48.664), train_loss = 0.26145479, grad/param norm = 1.9163e-01, time/batch = 15.2302s	
21705/22300 (epoch 48.666), train_loss = 0.33158313, grad/param norm = 2.5549e-01, time/batch = 15.5948s	
21706/22300 (epoch 48.668), train_loss = 0.24829095, grad/param norm = 1.9188e-01, time/batch = 15.5289s	
21707/22300 (epoch 48.670), train_loss = 0.30068871, grad/param norm = 2.4107e-01, time/batch = 15.3704s	
21708/22300 (epoch 48.673), train_loss = 0.37824381, grad/param norm = 2.5244e-01, time/batch = 15.7769s	
21709/22300 (epoch 48.675), train_loss = 0.38513991, grad/param norm = 3.1899e-01, time/batch = 15.9854s	
21710/22300 (epoch 48.677), train_loss = 0.43433296, grad/param norm = 3.0634e-01, time/batch = 16.2851s	
21711/22300 (epoch 48.679), train_loss = 0.32973135, grad/param norm = 3.4778e-01, time/batch = 16.3785s	
21712/22300 (epoch 48.682), train_loss = 0.29301075, grad/param norm = 2.6687e-01, time/batch = 16.3199s	
21713/22300 (epoch 48.684), train_loss = 0.29651626, grad/param norm = 2.2526e-01, time/batch = 16.3045s	
21714/22300 (epoch 48.686), train_loss = 0.25757606, grad/param norm = 3.1467e-01, time/batch = 15.9824s	
21715/22300 (epoch 48.688), train_loss = 0.24725344, grad/param norm = 2.1801e-01, time/batch = 15.9046s	
21716/22300 (epoch 48.691), train_loss = 0.23366787, grad/param norm = 2.5102e-01, time/batch = 16.1284s	
21717/22300 (epoch 48.693), train_loss = 0.23875408, grad/param norm = 1.8717e-01, time/batch = 16.1701s	
21718/22300 (epoch 48.695), train_loss = 0.24370248, grad/param norm = 1.6669e-01, time/batch = 16.3943s	
21719/22300 (epoch 48.697), train_loss = 0.26935206, grad/param norm = 2.0864e-01, time/batch = 16.4724s	
21720/22300 (epoch 48.700), train_loss = 0.23495697, grad/param norm = 1.9116e-01, time/batch = 16.1118s	
21721/22300 (epoch 48.702), train_loss = 0.19047859, grad/param norm = 1.9435e-01, time/batch = 16.1256s	
21722/22300 (epoch 48.704), train_loss = 0.24663236, grad/param norm = 2.6765e-01, time/batch = 15.9959s	
21723/22300 (epoch 48.706), train_loss = 0.23857774, grad/param norm = 2.1018e-01, time/batch = 15.9809s	
21724/22300 (epoch 48.709), train_loss = 0.17918357, grad/param norm = 1.7095e-01, time/batch = 16.2920s	
21725/22300 (epoch 48.711), train_loss = 0.18446135, grad/param norm = 1.4969e-01, time/batch = 16.0334s	
21726/22300 (epoch 48.713), train_loss = 0.28460663, grad/param norm = 2.5018e-01, time/batch = 16.2059s	
21727/22300 (epoch 48.715), train_loss = 0.31033102, grad/param norm = 1.9960e-01, time/batch = 16.0865s	
21728/22300 (epoch 48.717), train_loss = 0.38772415, grad/param norm = 2.3175e-01, time/batch = 16.1722s	
21729/22300 (epoch 48.720), train_loss = 0.22224953, grad/param norm = 2.2129e-01, time/batch = 15.8567s	
21730/22300 (epoch 48.722), train_loss = 0.27486593, grad/param norm = 2.5763e-01, time/batch = 15.8925s	
21731/22300 (epoch 48.724), train_loss = 0.31377639, grad/param norm = 2.7017e-01, time/batch = 16.3074s	
21732/22300 (epoch 48.726), train_loss = 0.23889894, grad/param norm = 2.3250e-01, time/batch = 16.2842s	
21733/22300 (epoch 48.729), train_loss = 0.29395702, grad/param norm = 1.9998e-01, time/batch = 16.1447s	
21734/22300 (epoch 48.731), train_loss = 0.34341209, grad/param norm = 3.1791e-01, time/batch = 16.0645s	
21735/22300 (epoch 48.733), train_loss = 0.36390796, grad/param norm = 3.5110e-01, time/batch = 15.8980s	
21736/22300 (epoch 48.735), train_loss = 0.37554249, grad/param norm = 2.9112e-01, time/batch = 16.0590s	
21737/22300 (epoch 48.738), train_loss = 0.27155176, grad/param norm = 3.2550e-01, time/batch = 16.1451s	
21738/22300 (epoch 48.740), train_loss = 0.25244506, grad/param norm = 1.9338e-01, time/batch = 16.2085s	
21739/22300 (epoch 48.742), train_loss = 0.22565209, grad/param norm = 1.8313e-01, time/batch = 16.1531s	
21740/22300 (epoch 48.744), train_loss = 0.40663393, grad/param norm = 2.8921e-01, time/batch = 15.8815s	
21741/22300 (epoch 48.747), train_loss = 0.33447194, grad/param norm = 2.3397e-01, time/batch = 16.2967s	
21742/22300 (epoch 48.749), train_loss = 0.42439415, grad/param norm = 2.9977e-01, time/batch = 15.8533s	
21743/22300 (epoch 48.751), train_loss = 0.35154069, grad/param norm = 3.2190e-01, time/batch = 16.1788s	
21744/22300 (epoch 48.753), train_loss = 0.39622237, grad/param norm = 3.4981e-01, time/batch = 16.0587s	
21745/22300 (epoch 48.756), train_loss = 0.38309107, grad/param norm = 2.5488e-01, time/batch = 16.1301s	
21746/22300 (epoch 48.758), train_loss = 0.31555365, grad/param norm = 2.4765e-01, time/batch = 16.0549s	
21747/22300 (epoch 48.760), train_loss = 0.32751514, grad/param norm = 2.3328e-01, time/batch = 15.9663s	
21748/22300 (epoch 48.762), train_loss = 0.30755430, grad/param norm = 2.2766e-01, time/batch = 16.0777s	
21749/22300 (epoch 48.765), train_loss = 0.34174411, grad/param norm = 3.5378e-01, time/batch = 16.1366s	
21750/22300 (epoch 48.767), train_loss = 0.29766586, grad/param norm = 2.4760e-01, time/batch = 15.7893s	
21751/22300 (epoch 48.769), train_loss = 0.27967258, grad/param norm = 2.5201e-01, time/batch = 16.2250s	
21752/22300 (epoch 48.771), train_loss = 0.35478343, grad/param norm = 3.5618e-01, time/batch = 16.0333s	
21753/22300 (epoch 48.774), train_loss = 0.38528505, grad/param norm = 3.3666e-01, time/batch = 15.8125s	
21754/22300 (epoch 48.776), train_loss = 0.41595505, grad/param norm = 2.6154e-01, time/batch = 15.6728s	
21755/22300 (epoch 48.778), train_loss = 0.40884468, grad/param norm = 3.1271e-01, time/batch = 15.6373s	
21756/22300 (epoch 48.780), train_loss = 0.39954112, grad/param norm = 3.2196e-01, time/batch = 15.6523s	
21757/22300 (epoch 48.783), train_loss = 0.40877574, grad/param norm = 2.3735e-01, time/batch = 15.6346s	
21758/22300 (epoch 48.785), train_loss = 0.28609583, grad/param norm = 3.0349e-01, time/batch = 15.7992s	
21759/22300 (epoch 48.787), train_loss = 0.30983079, grad/param norm = 2.5828e-01, time/batch = 15.5696s	
21760/22300 (epoch 48.789), train_loss = 0.42818742, grad/param norm = 3.1594e-01, time/batch = 15.6326s	
21761/22300 (epoch 48.791), train_loss = 0.52130447, grad/param norm = 3.5827e-01, time/batch = 16.0254s	
21762/22300 (epoch 48.794), train_loss = 0.43134983, grad/param norm = 3.0115e-01, time/batch = 16.0989s	
21763/22300 (epoch 48.796), train_loss = 0.36279546, grad/param norm = 4.0296e-01, time/batch = 15.7417s	
21764/22300 (epoch 48.798), train_loss = 0.50931696, grad/param norm = 3.0005e-01, time/batch = 15.7910s	
21765/22300 (epoch 48.800), train_loss = 0.34909977, grad/param norm = 2.6231e-01, time/batch = 16.1749s	
21766/22300 (epoch 48.803), train_loss = 0.28809459, grad/param norm = 2.0322e-01, time/batch = 15.7572s	
21767/22300 (epoch 48.805), train_loss = 0.33524716, grad/param norm = 3.0332e-01, time/batch = 15.6381s	
21768/22300 (epoch 48.807), train_loss = 0.43430932, grad/param norm = 3.4657e-01, time/batch = 15.6159s	
21769/22300 (epoch 48.809), train_loss = 0.32160888, grad/param norm = 2.4531e-01, time/batch = 15.7075s	
21770/22300 (epoch 48.812), train_loss = 0.33887789, grad/param norm = 2.5386e-01, time/batch = 15.9926s	
21771/22300 (epoch 48.814), train_loss = 0.31713385, grad/param norm = 2.9352e-01, time/batch = 15.9789s	
21772/22300 (epoch 48.816), train_loss = 0.35339346, grad/param norm = 2.7694e-01, time/batch = 16.2317s	
21773/22300 (epoch 48.818), train_loss = 0.41356945, grad/param norm = 3.5874e-01, time/batch = 15.9520s	
21774/22300 (epoch 48.821), train_loss = 0.35362324, grad/param norm = 2.6143e-01, time/batch = 15.8222s	
21775/22300 (epoch 48.823), train_loss = 0.23442369, grad/param norm = 2.2660e-01, time/batch = 15.7804s	
21776/22300 (epoch 48.825), train_loss = 0.23974553, grad/param norm = 1.9891e-01, time/batch = 15.9746s	
21777/22300 (epoch 48.827), train_loss = 0.28070519, grad/param norm = 2.2371e-01, time/batch = 16.2040s	
21778/22300 (epoch 48.830), train_loss = 0.28413858, grad/param norm = 2.2989e-01, time/batch = 15.8884s	
21779/22300 (epoch 48.832), train_loss = 0.27937714, grad/param norm = 2.1213e-01, time/batch = 15.7159s	
21780/22300 (epoch 48.834), train_loss = 0.22165184, grad/param norm = 1.8115e-01, time/batch = 15.9379s	
21781/22300 (epoch 48.836), train_loss = 0.27718188, grad/param norm = 1.8964e-01, time/batch = 16.1229s	
21782/22300 (epoch 48.839), train_loss = 0.30831830, grad/param norm = 2.1498e-01, time/batch = 15.7379s	
21783/22300 (epoch 48.841), train_loss = 0.26365656, grad/param norm = 2.6353e-01, time/batch = 15.8929s	
21784/22300 (epoch 48.843), train_loss = 0.28856426, grad/param norm = 2.1609e-01, time/batch = 16.0999s	
21785/22300 (epoch 48.845), train_loss = 0.30729460, grad/param norm = 2.2546e-01, time/batch = 15.9027s	
21786/22300 (epoch 48.848), train_loss = 0.27166724, grad/param norm = 2.2809e-01, time/batch = 15.7077s	
21787/22300 (epoch 48.850), train_loss = 0.30419477, grad/param norm = 1.8823e-01, time/batch = 15.8778s	
21788/22300 (epoch 48.852), train_loss = 0.26606439, grad/param norm = 2.4039e-01, time/batch = 15.7582s	
21789/22300 (epoch 48.854), train_loss = 0.47522090, grad/param norm = 3.5813e-01, time/batch = 15.6898s	
21790/22300 (epoch 48.857), train_loss = 0.32471687, grad/param norm = 2.7538e-01, time/batch = 15.7796s	
21791/22300 (epoch 48.859), train_loss = 0.27207730, grad/param norm = 2.2945e-01, time/batch = 15.9479s	
21792/22300 (epoch 48.861), train_loss = 0.39624589, grad/param norm = 2.4570e-01, time/batch = 16.0459s	
21793/22300 (epoch 48.863), train_loss = 0.22598806, grad/param norm = 2.4627e-01, time/batch = 16.1350s	
21794/22300 (epoch 48.865), train_loss = 0.24280024, grad/param norm = 2.0162e-01, time/batch = 15.8177s	
21795/22300 (epoch 48.868), train_loss = 0.32473587, grad/param norm = 2.2105e-01, time/batch = 15.8811s	
21796/22300 (epoch 48.870), train_loss = 0.31369632, grad/param norm = 2.3728e-01, time/batch = 15.8061s	
21797/22300 (epoch 48.872), train_loss = 0.40169976, grad/param norm = 2.3838e-01, time/batch = 15.9873s	
21798/22300 (epoch 48.874), train_loss = 0.34369907, grad/param norm = 2.7375e-01, time/batch = 15.8827s	
21799/22300 (epoch 48.877), train_loss = 0.30789698, grad/param norm = 2.0830e-01, time/batch = 16.6316s	
21800/22300 (epoch 48.879), train_loss = 0.29187984, grad/param norm = 2.0700e-01, time/batch = 15.5588s	
21801/22300 (epoch 48.881), train_loss = 0.22635394, grad/param norm = 2.2438e-01, time/batch = 15.8600s	
21802/22300 (epoch 48.883), train_loss = 0.23631072, grad/param norm = 2.2459e-01, time/batch = 16.9656s	
21803/22300 (epoch 48.886), train_loss = 0.22661369, grad/param norm = 2.6320e-01, time/batch = 15.3646s	
21804/22300 (epoch 48.888), train_loss = 0.27328894, grad/param norm = 2.0068e-01, time/batch = 16.8192s	
21805/22300 (epoch 48.890), train_loss = 0.26522274, grad/param norm = 1.7109e-01, time/batch = 14.9068s	
21806/22300 (epoch 48.892), train_loss = 0.40959252, grad/param norm = 2.8663e-01, time/batch = 16.1049s	
21807/22300 (epoch 48.895), train_loss = 0.36437776, grad/param norm = 3.4058e-01, time/batch = 15.7183s	
21808/22300 (epoch 48.897), train_loss = 0.29991679, grad/param norm = 2.7318e-01, time/batch = 16.8666s	
21809/22300 (epoch 48.899), train_loss = 0.29033243, grad/param norm = 2.1641e-01, time/batch = 18.3733s	
21810/22300 (epoch 48.901), train_loss = 0.36806786, grad/param norm = 2.7656e-01, time/batch = 16.1325s	
21811/22300 (epoch 48.904), train_loss = 0.34538384, grad/param norm = 2.5854e-01, time/batch = 17.4587s	
21812/22300 (epoch 48.906), train_loss = 0.33823270, grad/param norm = 2.6397e-01, time/batch = 17.1136s	
21813/22300 (epoch 48.908), train_loss = 0.28558777, grad/param norm = 1.7807e-01, time/batch = 17.3819s	
21814/22300 (epoch 48.910), train_loss = 0.27794041, grad/param norm = 2.0252e-01, time/batch = 14.9506s	
21815/22300 (epoch 48.913), train_loss = 0.32209602, grad/param norm = 2.7489e-01, time/batch = 14.9438s	
21816/22300 (epoch 48.915), train_loss = 0.41640129, grad/param norm = 2.7109e-01, time/batch = 15.2892s	
21817/22300 (epoch 48.917), train_loss = 0.33904953, grad/param norm = 2.2793e-01, time/batch = 15.2794s	
21818/22300 (epoch 48.919), train_loss = 0.31486551, grad/param norm = 2.2510e-01, time/batch = 15.6672s	
21819/22300 (epoch 48.922), train_loss = 0.29221018, grad/param norm = 2.1809e-01, time/batch = 15.9656s	
21820/22300 (epoch 48.924), train_loss = 0.20861777, grad/param norm = 2.1315e-01, time/batch = 16.1448s	
21821/22300 (epoch 48.926), train_loss = 0.27461258, grad/param norm = 2.4838e-01, time/batch = 15.4427s	
21822/22300 (epoch 48.928), train_loss = 0.27524896, grad/param norm = 2.2219e-01, time/batch = 15.8372s	
21823/22300 (epoch 48.930), train_loss = 0.24756327, grad/param norm = 1.9068e-01, time/batch = 14.9581s	
21824/22300 (epoch 48.933), train_loss = 0.32390981, grad/param norm = 2.5082e-01, time/batch = 15.3402s	
21825/22300 (epoch 48.935), train_loss = 0.31940833, grad/param norm = 2.7401e-01, time/batch = 15.5476s	
21826/22300 (epoch 48.937), train_loss = 0.39568246, grad/param norm = 2.8132e-01, time/batch = 15.8040s	
21827/22300 (epoch 48.939), train_loss = 0.35842491, grad/param norm = 2.6105e-01, time/batch = 16.9745s	
21828/22300 (epoch 48.942), train_loss = 0.42354129, grad/param norm = 3.0161e-01, time/batch = 17.9530s	
21829/22300 (epoch 48.944), train_loss = 0.46969996, grad/param norm = 3.3848e-01, time/batch = 15.6119s	
21830/22300 (epoch 48.946), train_loss = 0.34315411, grad/param norm = 2.6706e-01, time/batch = 18.2123s	
21831/22300 (epoch 48.948), train_loss = 0.29152920, grad/param norm = 1.7721e-01, time/batch = 16.3082s	
21832/22300 (epoch 48.951), train_loss = 0.22209907, grad/param norm = 2.0787e-01, time/batch = 15.2960s	
21833/22300 (epoch 48.953), train_loss = 0.22507202, grad/param norm = 2.1352e-01, time/batch = 16.4608s	
21834/22300 (epoch 48.955), train_loss = 0.39139929, grad/param norm = 2.5127e-01, time/batch = 15.8139s	
21835/22300 (epoch 48.957), train_loss = 0.45636275, grad/param norm = 2.4659e-01, time/batch = 15.3115s	
21836/22300 (epoch 48.960), train_loss = 0.40427415, grad/param norm = 2.5874e-01, time/batch = 15.5194s	
21837/22300 (epoch 48.962), train_loss = 0.24112577, grad/param norm = 2.1893e-01, time/batch = 16.0586s	
21838/22300 (epoch 48.964), train_loss = 0.25019776, grad/param norm = 2.7866e-01, time/batch = 16.4725s	
21839/22300 (epoch 48.966), train_loss = 0.26422762, grad/param norm = 1.8158e-01, time/batch = 18.9565s	
21840/22300 (epoch 48.969), train_loss = 0.28542480, grad/param norm = 1.8916e-01, time/batch = 15.2102s	
21841/22300 (epoch 48.971), train_loss = 0.31115617, grad/param norm = 2.3817e-01, time/batch = 16.4575s	
21842/22300 (epoch 48.973), train_loss = 0.28755620, grad/param norm = 2.8536e-01, time/batch = 15.5525s	
21843/22300 (epoch 48.975), train_loss = 0.40491210, grad/param norm = 3.6244e-01, time/batch = 17.3803s	
21844/22300 (epoch 48.978), train_loss = 0.40926506, grad/param norm = 2.7612e-01, time/batch = 17.0438s	
21845/22300 (epoch 48.980), train_loss = 0.49620333, grad/param norm = 3.4290e-01, time/batch = 16.4521s	
21846/22300 (epoch 48.982), train_loss = 0.23127818, grad/param norm = 2.0821e-01, time/batch = 18.5473s	
21847/22300 (epoch 48.984), train_loss = 0.31429749, grad/param norm = 2.3078e-01, time/batch = 16.1155s	
21848/22300 (epoch 48.987), train_loss = 0.30880425, grad/param norm = 2.2837e-01, time/batch = 16.2092s	
21849/22300 (epoch 48.989), train_loss = 0.24071563, grad/param norm = 2.2403e-01, time/batch = 16.5921s	
21850/22300 (epoch 48.991), train_loss = 0.45684923, grad/param norm = 3.0963e-01, time/batch = 18.6183s	
21851/22300 (epoch 48.993), train_loss = 0.62264850, grad/param norm = 3.8256e-01, time/batch = 16.8803s	
21852/22300 (epoch 48.996), train_loss = 0.56801613, grad/param norm = 3.0835e-01, time/batch = 16.6246s	
21853/22300 (epoch 48.998), train_loss = 0.34174573, grad/param norm = 2.4833e-01, time/batch = 15.3770s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
21854/22300 (epoch 49.000), train_loss = 0.25528783, grad/param norm = 2.1411e-01, time/batch = 15.5856s	
21855/22300 (epoch 49.002), train_loss = 0.61033622, grad/param norm = 2.8716e-01, time/batch = 16.2835s	
21856/22300 (epoch 49.004), train_loss = 0.36591933, grad/param norm = 2.5965e-01, time/batch = 15.0843s	
21857/22300 (epoch 49.007), train_loss = 0.38281354, grad/param norm = 2.7328e-01, time/batch = 15.7214s	
21858/22300 (epoch 49.009), train_loss = 0.37337032, grad/param norm = 3.0568e-01, time/batch = 29.3623s	
21859/22300 (epoch 49.011), train_loss = 0.47937085, grad/param norm = 3.5427e-01, time/batch = 15.1179s	
21860/22300 (epoch 49.013), train_loss = 0.37940710, grad/param norm = 2.8959e-01, time/batch = 16.1319s	
21861/22300 (epoch 49.016), train_loss = 0.30003470, grad/param norm = 2.7398e-01, time/batch = 15.3814s	
21862/22300 (epoch 49.018), train_loss = 0.29447468, grad/param norm = 2.3940e-01, time/batch = 16.4029s	
21863/22300 (epoch 49.020), train_loss = 0.29911882, grad/param norm = 2.4774e-01, time/batch = 15.1992s	
21864/22300 (epoch 49.022), train_loss = 0.23223531, grad/param norm = 2.3804e-01, time/batch = 15.0495s	
21865/22300 (epoch 49.025), train_loss = 0.27674339, grad/param norm = 2.3485e-01, time/batch = 16.2163s	
21866/22300 (epoch 49.027), train_loss = 0.25591667, grad/param norm = 1.8246e-01, time/batch = 15.4517s	
21867/22300 (epoch 49.029), train_loss = 0.29392249, grad/param norm = 2.3706e-01, time/batch = 16.3860s	
21868/22300 (epoch 49.031), train_loss = 0.27577827, grad/param norm = 2.1684e-01, time/batch = 15.8906s	
21869/22300 (epoch 49.034), train_loss = 0.26886361, grad/param norm = 1.9636e-01, time/batch = 16.2357s	
21870/22300 (epoch 49.036), train_loss = 0.25396552, grad/param norm = 1.7634e-01, time/batch = 16.3961s	
21871/22300 (epoch 49.038), train_loss = 0.21296744, grad/param norm = 1.8259e-01, time/batch = 15.4661s	
21872/22300 (epoch 49.040), train_loss = 0.26306599, grad/param norm = 2.1532e-01, time/batch = 15.4780s	
21873/22300 (epoch 49.043), train_loss = 0.44643033, grad/param norm = 2.9521e-01, time/batch = 15.4625s	
21874/22300 (epoch 49.045), train_loss = 0.38761664, grad/param norm = 2.7744e-01, time/batch = 15.8051s	
21875/22300 (epoch 49.047), train_loss = 0.43344783, grad/param norm = 4.0365e-01, time/batch = 15.5023s	
21876/22300 (epoch 49.049), train_loss = 0.33572373, grad/param norm = 2.6834e-01, time/batch = 15.2917s	
21877/22300 (epoch 49.052), train_loss = 0.37811573, grad/param norm = 2.9206e-01, time/batch = 15.6023s	
21878/22300 (epoch 49.054), train_loss = 0.35971818, grad/param norm = 2.3610e-01, time/batch = 14.5544s	
21879/22300 (epoch 49.056), train_loss = 0.18033609, grad/param norm = 1.6449e-01, time/batch = 14.4261s	
21880/22300 (epoch 49.058), train_loss = 0.29576319, grad/param norm = 2.3109e-01, time/batch = 14.7351s	
21881/22300 (epoch 49.061), train_loss = 0.26511850, grad/param norm = 2.3072e-01, time/batch = 15.1529s	
21882/22300 (epoch 49.063), train_loss = 0.40786391, grad/param norm = 3.3504e-01, time/batch = 15.7100s	
21883/22300 (epoch 49.065), train_loss = 0.46306039, grad/param norm = 3.2974e-01, time/batch = 15.4940s	
21884/22300 (epoch 49.067), train_loss = 0.26121498, grad/param norm = 2.2372e-01, time/batch = 15.2716s	
21885/22300 (epoch 49.070), train_loss = 0.31526843, grad/param norm = 2.6105e-01, time/batch = 15.2143s	
21886/22300 (epoch 49.072), train_loss = 0.32850654, grad/param norm = 3.2805e-01, time/batch = 15.1471s	
21887/22300 (epoch 49.074), train_loss = 0.34298516, grad/param norm = 2.6623e-01, time/batch = 15.1246s	
21888/22300 (epoch 49.076), train_loss = 0.32983819, grad/param norm = 3.7223e-01, time/batch = 15.3069s	
21889/22300 (epoch 49.078), train_loss = 0.44462796, grad/param norm = 3.7835e-01, time/batch = 15.6559s	
21890/22300 (epoch 49.081), train_loss = 0.42350613, grad/param norm = 2.9177e-01, time/batch = 16.8853s	
21891/22300 (epoch 49.083), train_loss = 0.49804335, grad/param norm = 3.9000e-01, time/batch = 17.0304s	
21892/22300 (epoch 49.085), train_loss = 0.46390109, grad/param norm = 3.4526e-01, time/batch = 16.1439s	
21893/22300 (epoch 49.087), train_loss = 0.35496939, grad/param norm = 2.6469e-01, time/batch = 15.4044s	
21894/22300 (epoch 49.090), train_loss = 0.33715812, grad/param norm = 2.6642e-01, time/batch = 15.8230s	
21895/22300 (epoch 49.092), train_loss = 0.24870231, grad/param norm = 2.4868e-01, time/batch = 15.4467s	
21896/22300 (epoch 49.094), train_loss = 0.25674415, grad/param norm = 2.3285e-01, time/batch = 15.0831s	
21897/22300 (epoch 49.096), train_loss = 0.43255526, grad/param norm = 2.8168e-01, time/batch = 15.4127s	
21898/22300 (epoch 49.099), train_loss = 0.29121364, grad/param norm = 2.1287e-01, time/batch = 15.3875s	
21899/22300 (epoch 49.101), train_loss = 0.39229699, grad/param norm = 2.6572e-01, time/batch = 15.6151s	
21900/22300 (epoch 49.103), train_loss = 0.31716952, grad/param norm = 2.2652e-01, time/batch = 15.2191s	
21901/22300 (epoch 49.105), train_loss = 0.25040604, grad/param norm = 3.2188e-01, time/batch = 15.4023s	
21902/22300 (epoch 49.108), train_loss = 0.36534146, grad/param norm = 2.4049e-01, time/batch = 15.5685s	
21903/22300 (epoch 49.110), train_loss = 0.40909156, grad/param norm = 2.5965e-01, time/batch = 15.2248s	
21904/22300 (epoch 49.112), train_loss = 0.33709115, grad/param norm = 2.2277e-01, time/batch = 16.8191s	
21905/22300 (epoch 49.114), train_loss = 0.37960882, grad/param norm = 2.6064e-01, time/batch = 15.3043s	
21906/22300 (epoch 49.117), train_loss = 0.44331631, grad/param norm = 2.5797e-01, time/batch = 15.1966s	
21907/22300 (epoch 49.119), train_loss = 0.39584636, grad/param norm = 3.2754e-01, time/batch = 15.6265s	
21908/22300 (epoch 49.121), train_loss = 0.46067679, grad/param norm = 3.1501e-01, time/batch = 15.1847s	
21909/22300 (epoch 49.123), train_loss = 0.47388872, grad/param norm = 2.6899e-01, time/batch = 16.4018s	
21910/22300 (epoch 49.126), train_loss = 0.37643711, grad/param norm = 2.6179e-01, time/batch = 16.6066s	
21911/22300 (epoch 49.128), train_loss = 0.33573344, grad/param norm = 2.3573e-01, time/batch = 15.7328s	
21912/22300 (epoch 49.130), train_loss = 0.30648696, grad/param norm = 1.9899e-01, time/batch = 17.1977s	
21913/22300 (epoch 49.132), train_loss = 0.21366359, grad/param norm = 1.6964e-01, time/batch = 15.7020s	
21914/22300 (epoch 49.135), train_loss = 0.23944062, grad/param norm = 2.3745e-01, time/batch = 15.8170s	
21915/22300 (epoch 49.137), train_loss = 0.20164797, grad/param norm = 2.0349e-01, time/batch = 17.7130s	
21916/22300 (epoch 49.139), train_loss = 0.26811577, grad/param norm = 2.2821e-01, time/batch = 15.2534s	
21917/22300 (epoch 49.141), train_loss = 0.39106999, grad/param norm = 2.6553e-01, time/batch = 16.9595s	
21918/22300 (epoch 49.143), train_loss = 0.32258102, grad/param norm = 2.5830e-01, time/batch = 16.2234s	
21919/22300 (epoch 49.146), train_loss = 0.38711620, grad/param norm = 2.5177e-01, time/batch = 16.4657s	
21920/22300 (epoch 49.148), train_loss = 0.25813162, grad/param norm = 2.1405e-01, time/batch = 18.8074s	
21921/22300 (epoch 49.150), train_loss = 0.28179538, grad/param norm = 2.1847e-01, time/batch = 15.7064s	
21922/22300 (epoch 49.152), train_loss = 0.23293769, grad/param norm = 2.0196e-01, time/batch = 17.5414s	
21923/22300 (epoch 49.155), train_loss = 0.26321524, grad/param norm = 1.9590e-01, time/batch = 17.0286s	
21924/22300 (epoch 49.157), train_loss = 0.34390533, grad/param norm = 3.3419e-01, time/batch = 18.5375s	
21925/22300 (epoch 49.159), train_loss = 0.35089201, grad/param norm = 2.7744e-01, time/batch = 14.9689s	
21926/22300 (epoch 49.161), train_loss = 0.36338441, grad/param norm = 2.8062e-01, time/batch = 16.2302s	
21927/22300 (epoch 49.164), train_loss = 0.26944682, grad/param norm = 2.0717e-01, time/batch = 16.5571s	
21928/22300 (epoch 49.166), train_loss = 0.22459890, grad/param norm = 1.6408e-01, time/batch = 16.6237s	
21929/22300 (epoch 49.168), train_loss = 0.22907670, grad/param norm = 2.4536e-01, time/batch = 16.9747s	
21930/22300 (epoch 49.170), train_loss = 0.31042269, grad/param norm = 2.4535e-01, time/batch = 16.1289s	
21931/22300 (epoch 49.173), train_loss = 0.35858530, grad/param norm = 3.1096e-01, time/batch = 17.4482s	
21932/22300 (epoch 49.175), train_loss = 0.33341452, grad/param norm = 2.4975e-01, time/batch = 15.8632s	
21933/22300 (epoch 49.177), train_loss = 0.22294592, grad/param norm = 1.9603e-01, time/batch = 15.7469s	
21934/22300 (epoch 49.179), train_loss = 0.32518920, grad/param norm = 2.5980e-01, time/batch = 15.4373s	
21935/22300 (epoch 49.182), train_loss = 0.45017517, grad/param norm = 3.3391e-01, time/batch = 16.4569s	
21936/22300 (epoch 49.184), train_loss = 0.45339492, grad/param norm = 3.2063e-01, time/batch = 15.3821s	
21937/22300 (epoch 49.186), train_loss = 0.33866322, grad/param norm = 2.4865e-01, time/batch = 15.9094s	
21938/22300 (epoch 49.188), train_loss = 0.52466140, grad/param norm = 3.9760e-01, time/batch = 15.2901s	
21939/22300 (epoch 49.191), train_loss = 0.40222471, grad/param norm = 2.5797e-01, time/batch = 17.6246s	
21940/22300 (epoch 49.193), train_loss = 0.36000872, grad/param norm = 2.9449e-01, time/batch = 16.0612s	
21941/22300 (epoch 49.195), train_loss = 0.30238661, grad/param norm = 3.1368e-01, time/batch = 17.3872s	
21942/22300 (epoch 49.197), train_loss = 0.29612135, grad/param norm = 3.4425e-01, time/batch = 16.1575s	
21943/22300 (epoch 49.200), train_loss = 0.24255351, grad/param norm = 2.1269e-01, time/batch = 16.2192s	
21944/22300 (epoch 49.202), train_loss = 0.27909849, grad/param norm = 2.7167e-01, time/batch = 16.0419s	
21945/22300 (epoch 49.204), train_loss = 0.34636479, grad/param norm = 2.6642e-01, time/batch = 14.6396s	
21946/22300 (epoch 49.206), train_loss = 0.28746958, grad/param norm = 2.3870e-01, time/batch = 16.0416s	
21947/22300 (epoch 49.209), train_loss = 0.28500637, grad/param norm = 1.9771e-01, time/batch = 15.2147s	
21948/22300 (epoch 49.211), train_loss = 0.22542526, grad/param norm = 2.3681e-01, time/batch = 17.8004s	
21949/22300 (epoch 49.213), train_loss = 0.35425510, grad/param norm = 2.5609e-01, time/batch = 16.3842s	
21950/22300 (epoch 49.215), train_loss = 0.44569206, grad/param norm = 3.7990e-01, time/batch = 16.8731s	
21951/22300 (epoch 49.217), train_loss = 0.46809291, grad/param norm = 2.9285e-01, time/batch = 17.4766s	
21952/22300 (epoch 49.220), train_loss = 0.29290021, grad/param norm = 2.2470e-01, time/batch = 15.3870s	
21953/22300 (epoch 49.222), train_loss = 0.29653409, grad/param norm = 2.3825e-01, time/batch = 15.4829s	
21954/22300 (epoch 49.224), train_loss = 0.27277850, grad/param norm = 2.2526e-01, time/batch = 15.3576s	
21955/22300 (epoch 49.226), train_loss = 0.32437998, grad/param norm = 2.1943e-01, time/batch = 15.7159s	
21956/22300 (epoch 49.229), train_loss = 0.26074035, grad/param norm = 2.3054e-01, time/batch = 15.2296s	
21957/22300 (epoch 49.231), train_loss = 0.42894190, grad/param norm = 3.0169e-01, time/batch = 14.9248s	
21958/22300 (epoch 49.233), train_loss = 0.33722152, grad/param norm = 2.6450e-01, time/batch = 15.4772s	
21959/22300 (epoch 49.235), train_loss = 0.24493387, grad/param norm = 2.1147e-01, time/batch = 14.9892s	
21960/22300 (epoch 49.238), train_loss = 0.25972602, grad/param norm = 2.2649e-01, time/batch = 14.8306s	
21961/22300 (epoch 49.240), train_loss = 0.27539466, grad/param norm = 2.0456e-01, time/batch = 15.1680s	
21962/22300 (epoch 49.242), train_loss = 0.23580138, grad/param norm = 3.4363e-01, time/batch = 15.7368s	
21963/22300 (epoch 49.244), train_loss = 0.17632728, grad/param norm = 1.8745e-01, time/batch = 15.2186s	
21964/22300 (epoch 49.247), train_loss = 0.24279912, grad/param norm = 1.9239e-01, time/batch = 15.1465s	
21965/22300 (epoch 49.249), train_loss = 0.16208512, grad/param norm = 1.4949e-01, time/batch = 15.1329s	
21966/22300 (epoch 49.251), train_loss = 0.21962303, grad/param norm = 2.0979e-01, time/batch = 15.5516s	
21967/22300 (epoch 49.253), train_loss = 0.13899961, grad/param norm = 1.3803e-01, time/batch = 15.3791s	
21968/22300 (epoch 49.256), train_loss = 0.20887860, grad/param norm = 1.5729e-01, time/batch = 15.8201s	
21969/22300 (epoch 49.258), train_loss = 0.32309172, grad/param norm = 3.1767e-01, time/batch = 16.6609s	
21970/22300 (epoch 49.260), train_loss = 0.36195114, grad/param norm = 2.7798e-01, time/batch = 15.2787s	
21971/22300 (epoch 49.262), train_loss = 0.24925530, grad/param norm = 2.4004e-01, time/batch = 15.1593s	
21972/22300 (epoch 49.265), train_loss = 0.24171500, grad/param norm = 1.9794e-01, time/batch = 15.6025s	
21973/22300 (epoch 49.267), train_loss = 0.25276053, grad/param norm = 2.1147e-01, time/batch = 15.4658s	
21974/22300 (epoch 49.269), train_loss = 0.29535206, grad/param norm = 2.5271e-01, time/batch = 15.2878s	
21975/22300 (epoch 49.271), train_loss = 0.33783336, grad/param norm = 2.1132e-01, time/batch = 15.5750s	
21976/22300 (epoch 49.274), train_loss = 0.23056458, grad/param norm = 2.3403e-01, time/batch = 17.4636s	
21977/22300 (epoch 49.276), train_loss = 0.20524318, grad/param norm = 1.5174e-01, time/batch = 16.9608s	
21978/22300 (epoch 49.278), train_loss = 0.24243156, grad/param norm = 2.2118e-01, time/batch = 15.2072s	
21979/22300 (epoch 49.280), train_loss = 0.24591209, grad/param norm = 1.8988e-01, time/batch = 15.1525s	
21980/22300 (epoch 49.283), train_loss = 0.20494998, grad/param norm = 1.7667e-01, time/batch = 18.8816s	
21981/22300 (epoch 49.285), train_loss = 0.21517282, grad/param norm = 2.0793e-01, time/batch = 15.4611s	
21982/22300 (epoch 49.287), train_loss = 0.31013656, grad/param norm = 2.0018e-01, time/batch = 18.5381s	
21983/22300 (epoch 49.289), train_loss = 0.28192126, grad/param norm = 2.0050e-01, time/batch = 17.4565s	
21984/22300 (epoch 49.291), train_loss = 0.27016331, grad/param norm = 2.6333e-01, time/batch = 16.5237s	
21985/22300 (epoch 49.294), train_loss = 0.22048882, grad/param norm = 1.7086e-01, time/batch = 16.8427s	
21986/22300 (epoch 49.296), train_loss = 0.24899816, grad/param norm = 2.2798e-01, time/batch = 17.3799s	
21987/22300 (epoch 49.298), train_loss = 0.36026247, grad/param norm = 2.7852e-01, time/batch = 18.7095s	
21988/22300 (epoch 49.300), train_loss = 0.38598309, grad/param norm = 2.8933e-01, time/batch = 16.4346s	
21989/22300 (epoch 49.303), train_loss = 0.29675475, grad/param norm = 3.1421e-01, time/batch = 17.0595s	
21990/22300 (epoch 49.305), train_loss = 0.30176032, grad/param norm = 2.4556e-01, time/batch = 15.2130s	
21991/22300 (epoch 49.307), train_loss = 0.24879004, grad/param norm = 2.0570e-01, time/batch = 17.2910s	
21992/22300 (epoch 49.309), train_loss = 0.21579123, grad/param norm = 2.0156e-01, time/batch = 15.8079s	
21993/22300 (epoch 49.312), train_loss = 0.19232803, grad/param norm = 1.7392e-01, time/batch = 17.0520s	
21994/22300 (epoch 49.314), train_loss = 0.23451130, grad/param norm = 1.7129e-01, time/batch = 17.3768s	
21995/22300 (epoch 49.316), train_loss = 0.22163347, grad/param norm = 2.0925e-01, time/batch = 15.4356s	
21996/22300 (epoch 49.318), train_loss = 0.24477315, grad/param norm = 1.8531e-01, time/batch = 18.1103s	
21997/22300 (epoch 49.321), train_loss = 0.32256239, grad/param norm = 1.8792e-01, time/batch = 15.1182s	
21998/22300 (epoch 49.323), train_loss = 0.22350354, grad/param norm = 1.6674e-01, time/batch = 15.8044s	
21999/22300 (epoch 49.325), train_loss = 0.18774603, grad/param norm = 1.6638e-01, time/batch = 15.6676s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch49.33_1.7620.t7	
22000/22300 (epoch 49.327), train_loss = 0.21712053, grad/param norm = 1.5315e-01, time/batch = 17.8773s	
22001/22300 (epoch 49.330), train_loss = 1.38014367, grad/param norm = 6.6896e-01, time/batch = 15.9756s	
22002/22300 (epoch 49.332), train_loss = 0.23058922, grad/param norm = 2.2068e-01, time/batch = 14.9026s	
22003/22300 (epoch 49.334), train_loss = 0.27141298, grad/param norm = 3.0210e-01, time/batch = 15.5673s	
22004/22300 (epoch 49.336), train_loss = 0.26489805, grad/param norm = 2.8437e-01, time/batch = 15.0547s	
22005/22300 (epoch 49.339), train_loss = 0.34829018, grad/param norm = 3.7473e-01, time/batch = 14.6610s	
22006/22300 (epoch 49.341), train_loss = 0.28691681, grad/param norm = 2.3408e-01, time/batch = 14.7444s	
22007/22300 (epoch 49.343), train_loss = 0.34161089, grad/param norm = 2.3372e-01, time/batch = 15.2371s	
22008/22300 (epoch 49.345), train_loss = 0.27488875, grad/param norm = 2.1781e-01, time/batch = 15.9620s	
22009/22300 (epoch 49.348), train_loss = 0.28825186, grad/param norm = 1.9504e-01, time/batch = 16.0699s	
22010/22300 (epoch 49.350), train_loss = 0.18909772, grad/param norm = 1.7659e-01, time/batch = 17.2994s	
22011/22300 (epoch 49.352), train_loss = 0.28531747, grad/param norm = 1.9792e-01, time/batch = 16.8022s	
22012/22300 (epoch 49.354), train_loss = 0.40271326, grad/param norm = 3.2773e-01, time/batch = 15.6361s	
22013/22300 (epoch 49.357), train_loss = 0.37215547, grad/param norm = 2.1877e-01, time/batch = 18.4582s	
22014/22300 (epoch 49.359), train_loss = 0.22152539, grad/param norm = 1.9652e-01, time/batch = 15.3522s	
22015/22300 (epoch 49.361), train_loss = 0.25039057, grad/param norm = 2.5272e-01, time/batch = 14.8759s	
22016/22300 (epoch 49.363), train_loss = 0.30138094, grad/param norm = 1.8437e-01, time/batch = 14.9653s	
22017/22300 (epoch 49.365), train_loss = 0.21893132, grad/param norm = 2.1769e-01, time/batch = 15.3269s	
22018/22300 (epoch 49.368), train_loss = 0.22532849, grad/param norm = 2.4879e-01, time/batch = 15.0844s	
22019/22300 (epoch 49.370), train_loss = 0.24906926, grad/param norm = 1.9296e-01, time/batch = 15.7062s	
22020/22300 (epoch 49.372), train_loss = 0.16694388, grad/param norm = 1.5532e-01, time/batch = 15.1253s	
22021/22300 (epoch 49.374), train_loss = 0.19591099, grad/param norm = 1.3427e-01, time/batch = 15.1412s	
22022/22300 (epoch 49.377), train_loss = 0.27293101, grad/param norm = 3.3508e-01, time/batch = 14.7536s	
22023/22300 (epoch 49.379), train_loss = 0.22499913, grad/param norm = 2.0109e-01, time/batch = 14.7285s	
22024/22300 (epoch 49.381), train_loss = 0.32357173, grad/param norm = 2.7863e-01, time/batch = 17.7945s	
22025/22300 (epoch 49.383), train_loss = 0.23908417, grad/param norm = 2.3372e-01, time/batch = 17.4589s	
22026/22300 (epoch 49.386), train_loss = 0.31466002, grad/param norm = 2.3581e-01, time/batch = 17.2228s	
22027/22300 (epoch 49.388), train_loss = 0.18986992, grad/param norm = 2.0657e-01, time/batch = 16.4234s	
22028/22300 (epoch 49.390), train_loss = 0.21606276, grad/param norm = 2.1912e-01, time/batch = 17.1373s	
22029/22300 (epoch 49.392), train_loss = 0.24457921, grad/param norm = 2.0193e-01, time/batch = 16.3881s	
22030/22300 (epoch 49.395), train_loss = 0.20100965, grad/param norm = 1.6130e-01, time/batch = 15.7332s	
22031/22300 (epoch 49.397), train_loss = 0.14853515, grad/param norm = 1.2451e-01, time/batch = 16.0673s	
22032/22300 (epoch 49.399), train_loss = 0.23258753, grad/param norm = 3.0093e-01, time/batch = 16.7189s	
22033/22300 (epoch 49.401), train_loss = 0.21947483, grad/param norm = 2.0897e-01, time/batch = 15.7501s	
22034/22300 (epoch 49.404), train_loss = 0.27433256, grad/param norm = 2.6635e-01, time/batch = 15.2005s	
22035/22300 (epoch 49.406), train_loss = 0.38999983, grad/param norm = 2.6716e-01, time/batch = 15.0597s	
22036/22300 (epoch 49.408), train_loss = 0.27492001, grad/param norm = 1.7204e-01, time/batch = 15.1180s	
22037/22300 (epoch 49.410), train_loss = 0.32963788, grad/param norm = 3.0196e-01, time/batch = 15.2076s	
22038/22300 (epoch 49.413), train_loss = 0.23684233, grad/param norm = 1.8854e-01, time/batch = 8.0012s	
22039/22300 (epoch 49.415), train_loss = 0.18572638, grad/param norm = 1.8330e-01, time/batch = 0.6583s	
22040/22300 (epoch 49.417), train_loss = 0.28039368, grad/param norm = 2.3591e-01, time/batch = 0.6568s	
22041/22300 (epoch 49.419), train_loss = 0.24857651, grad/param norm = 1.5870e-01, time/batch = 0.6606s	
22042/22300 (epoch 49.422), train_loss = 0.21585218, grad/param norm = 1.8311e-01, time/batch = 0.6629s	
22043/22300 (epoch 49.424), train_loss = 0.25718822, grad/param norm = 1.9769e-01, time/batch = 0.6693s	
22044/22300 (epoch 49.426), train_loss = 0.19956868, grad/param norm = 1.8608e-01, time/batch = 0.6707s	
22045/22300 (epoch 49.428), train_loss = 0.21118820, grad/param norm = 1.8534e-01, time/batch = 0.6716s	
22046/22300 (epoch 49.430), train_loss = 0.23492186, grad/param norm = 2.4467e-01, time/batch = 0.6713s	
22047/22300 (epoch 49.433), train_loss = 0.24890245, grad/param norm = 1.7679e-01, time/batch = 0.6676s	
22048/22300 (epoch 49.435), train_loss = 0.22868204, grad/param norm = 1.6528e-01, time/batch = 0.6701s	
22049/22300 (epoch 49.437), train_loss = 0.28341522, grad/param norm = 2.6151e-01, time/batch = 0.6748s	
22050/22300 (epoch 49.439), train_loss = 0.30473821, grad/param norm = 2.6656e-01, time/batch = 0.6804s	
22051/22300 (epoch 49.442), train_loss = 0.24766576, grad/param norm = 2.1711e-01, time/batch = 0.6828s	
22052/22300 (epoch 49.444), train_loss = 0.22714354, grad/param norm = 1.9655e-01, time/batch = 0.6795s	
22053/22300 (epoch 49.446), train_loss = 0.26098529, grad/param norm = 1.8709e-01, time/batch = 0.8987s	
22054/22300 (epoch 49.448), train_loss = 0.19752029, grad/param norm = 1.3439e-01, time/batch = 0.9947s	
22055/22300 (epoch 49.451), train_loss = 0.30663532, grad/param norm = 3.4445e-01, time/batch = 0.9926s	
22056/22300 (epoch 49.453), train_loss = 0.24037141, grad/param norm = 1.9140e-01, time/batch = 0.9917s	
22057/22300 (epoch 49.455), train_loss = 0.31349575, grad/param norm = 2.3389e-01, time/batch = 0.9743s	
22058/22300 (epoch 49.457), train_loss = 0.40681930, grad/param norm = 3.2347e-01, time/batch = 1.5116s	
22059/22300 (epoch 49.460), train_loss = 0.34828631, grad/param norm = 2.2883e-01, time/batch = 1.8214s	
22060/22300 (epoch 49.462), train_loss = 0.35749682, grad/param norm = 2.4668e-01, time/batch = 1.8204s	
22061/22300 (epoch 49.464), train_loss = 0.30951688, grad/param norm = 2.4956e-01, time/batch = 14.0525s	
22062/22300 (epoch 49.466), train_loss = 0.25004739, grad/param norm = 2.4391e-01, time/batch = 15.2132s	
22063/22300 (epoch 49.469), train_loss = 0.24893066, grad/param norm = 1.6989e-01, time/batch = 15.4642s	
22064/22300 (epoch 49.471), train_loss = 0.34069301, grad/param norm = 1.9588e-01, time/batch = 14.9064s	
22065/22300 (epoch 49.473), train_loss = 0.28324652, grad/param norm = 1.8135e-01, time/batch = 15.5516s	
22066/22300 (epoch 49.475), train_loss = 0.23176346, grad/param norm = 2.5650e-01, time/batch = 15.3086s	
22067/22300 (epoch 49.478), train_loss = 0.27590447, grad/param norm = 2.6787e-01, time/batch = 15.4630s	
22068/22300 (epoch 49.480), train_loss = 0.18451613, grad/param norm = 1.7092e-01, time/batch = 14.9914s	
22069/22300 (epoch 49.482), train_loss = 0.22753386, grad/param norm = 1.6846e-01, time/batch = 14.8345s	
22070/22300 (epoch 49.484), train_loss = 0.27232657, grad/param norm = 2.2012e-01, time/batch = 15.3889s	
22071/22300 (epoch 49.487), train_loss = 0.32447444, grad/param norm = 1.8551e-01, time/batch = 15.6778s	
22072/22300 (epoch 49.489), train_loss = 0.32718536, grad/param norm = 2.6349e-01, time/batch = 15.6850s	
22073/22300 (epoch 49.491), train_loss = 0.36492940, grad/param norm = 3.4141e-01, time/batch = 15.3758s	
22074/22300 (epoch 49.493), train_loss = 0.24384780, grad/param norm = 3.0046e-01, time/batch = 15.7433s	
22075/22300 (epoch 49.496), train_loss = 0.30557563, grad/param norm = 2.1426e-01, time/batch = 15.4546s	
22076/22300 (epoch 49.498), train_loss = 0.18232702, grad/param norm = 1.5967e-01, time/batch = 15.2190s	
22077/22300 (epoch 49.500), train_loss = 0.27523288, grad/param norm = 2.2114e-01, time/batch = 15.3072s	
22078/22300 (epoch 49.502), train_loss = 0.16120038, grad/param norm = 1.5200e-01, time/batch = 15.6859s	
22079/22300 (epoch 49.504), train_loss = 0.19105745, grad/param norm = 1.5606e-01, time/batch = 15.7679s	
22080/22300 (epoch 49.507), train_loss = 0.21324991, grad/param norm = 1.7418e-01, time/batch = 14.9916s	
22081/22300 (epoch 49.509), train_loss = 0.30644676, grad/param norm = 2.3927e-01, time/batch = 15.3813s	
22082/22300 (epoch 49.511), train_loss = 0.18117664, grad/param norm = 1.8914e-01, time/batch = 15.0359s	
22083/22300 (epoch 49.513), train_loss = 0.18997997, grad/param norm = 1.8071e-01, time/batch = 14.9767s	
22084/22300 (epoch 49.516), train_loss = 0.24006950, grad/param norm = 1.8401e-01, time/batch = 15.0674s	
22085/22300 (epoch 49.518), train_loss = 0.26828457, grad/param norm = 2.7472e-01, time/batch = 15.1436s	
22086/22300 (epoch 49.520), train_loss = 0.22840034, grad/param norm = 1.9191e-01, time/batch = 15.0513s	
22087/22300 (epoch 49.522), train_loss = 0.26163442, grad/param norm = 1.8875e-01, time/batch = 15.5108s	
22088/22300 (epoch 49.525), train_loss = 0.20669971, grad/param norm = 1.6315e-01, time/batch = 14.9928s	
22089/22300 (epoch 49.527), train_loss = 0.31011867, grad/param norm = 2.8557e-01, time/batch = 15.3817s	
22090/22300 (epoch 49.529), train_loss = 0.27130998, grad/param norm = 2.4254e-01, time/batch = 15.5503s	
22091/22300 (epoch 49.531), train_loss = 0.24413180, grad/param norm = 2.1862e-01, time/batch = 15.5509s	
22092/22300 (epoch 49.534), train_loss = 0.27950507, grad/param norm = 2.0469e-01, time/batch = 15.0673s	
22093/22300 (epoch 49.536), train_loss = 0.39680087, grad/param norm = 2.6646e-01, time/batch = 14.8792s	
22094/22300 (epoch 49.538), train_loss = 0.47256949, grad/param norm = 3.4969e-01, time/batch = 15.0978s	
22095/22300 (epoch 49.540), train_loss = 0.26035630, grad/param norm = 2.1326e-01, time/batch = 15.8159s	
22096/22300 (epoch 49.543), train_loss = 0.27755099, grad/param norm = 1.8143e-01, time/batch = 14.9450s	
22097/22300 (epoch 49.545), train_loss = 0.17637226, grad/param norm = 1.5653e-01, time/batch = 14.9482s	
22098/22300 (epoch 49.547), train_loss = 0.16921271, grad/param norm = 1.6231e-01, time/batch = 25.7429s	
22099/22300 (epoch 49.549), train_loss = 0.18740986, grad/param norm = 2.2424e-01, time/batch = 18.5098s	
22100/22300 (epoch 49.552), train_loss = 0.20583231, grad/param norm = 2.0851e-01, time/batch = 14.9020s	
22101/22300 (epoch 49.554), train_loss = 0.29480440, grad/param norm = 2.3869e-01, time/batch = 15.3680s	
22102/22300 (epoch 49.556), train_loss = 0.39079962, grad/param norm = 3.2789e-01, time/batch = 14.7364s	
22103/22300 (epoch 49.558), train_loss = 0.27704772, grad/param norm = 2.6578e-01, time/batch = 14.8210s	
22104/22300 (epoch 49.561), train_loss = 0.43118017, grad/param norm = 3.1574e-01, time/batch = 15.2274s	
22105/22300 (epoch 49.563), train_loss = 0.32729593, grad/param norm = 2.6552e-01, time/batch = 15.0487s	
22106/22300 (epoch 49.565), train_loss = 0.26620997, grad/param norm = 1.9252e-01, time/batch = 15.4572s	
22107/22300 (epoch 49.567), train_loss = 0.23355517, grad/param norm = 1.8876e-01, time/batch = 14.9986s	
22108/22300 (epoch 49.570), train_loss = 0.35718188, grad/param norm = 2.9157e-01, time/batch = 14.8238s	
22109/22300 (epoch 49.572), train_loss = 0.37721131, grad/param norm = 3.1425e-01, time/batch = 15.3146s	
22110/22300 (epoch 49.574), train_loss = 0.26879723, grad/param norm = 2.2222e-01, time/batch = 15.0554s	
22111/22300 (epoch 49.576), train_loss = 0.22664862, grad/param norm = 1.5249e-01, time/batch = 15.2743s	
22112/22300 (epoch 49.578), train_loss = 0.14303993, grad/param norm = 1.4488e-01, time/batch = 15.4363s	
22113/22300 (epoch 49.581), train_loss = 0.20066005, grad/param norm = 1.8498e-01, time/batch = 15.7567s	
22114/22300 (epoch 49.583), train_loss = 0.25003132, grad/param norm = 1.8662e-01, time/batch = 14.8094s	
22115/22300 (epoch 49.585), train_loss = 0.32193620, grad/param norm = 5.4165e-01, time/batch = 14.8066s	
22116/22300 (epoch 49.587), train_loss = 0.51435293, grad/param norm = 3.3519e-01, time/batch = 14.5793s	
22117/22300 (epoch 49.590), train_loss = 0.42289105, grad/param norm = 3.3032e-01, time/batch = 15.5277s	
22118/22300 (epoch 49.592), train_loss = 0.47160769, grad/param norm = 3.8081e-01, time/batch = 14.5590s	
22119/22300 (epoch 49.594), train_loss = 0.41573818, grad/param norm = 3.2723e-01, time/batch = 15.4247s	
22120/22300 (epoch 49.596), train_loss = 0.30127215, grad/param norm = 2.6250e-01, time/batch = 14.6349s	
22121/22300 (epoch 49.599), train_loss = 0.18110309, grad/param norm = 1.8320e-01, time/batch = 15.5125s	
22122/22300 (epoch 49.601), train_loss = 0.21676232, grad/param norm = 1.7874e-01, time/batch = 15.1389s	
22123/22300 (epoch 49.603), train_loss = 0.21856214, grad/param norm = 1.6648e-01, time/batch = 15.1426s	
22124/22300 (epoch 49.605), train_loss = 0.26467047, grad/param norm = 2.7108e-01, time/batch = 15.0503s	
22125/22300 (epoch 49.608), train_loss = 0.46286338, grad/param norm = 3.6906e-01, time/batch = 15.6005s	
22126/22300 (epoch 49.610), train_loss = 0.50683530, grad/param norm = 3.4463e-01, time/batch = 15.1331s	
22127/22300 (epoch 49.612), train_loss = 0.34721443, grad/param norm = 2.9328e-01, time/batch = 14.9028s	
22128/22300 (epoch 49.614), train_loss = 0.33393052, grad/param norm = 3.2160e-01, time/batch = 14.9481s	
22129/22300 (epoch 49.617), train_loss = 0.36286296, grad/param norm = 2.3000e-01, time/batch = 15.2166s	
22130/22300 (epoch 49.619), train_loss = 0.33530528, grad/param norm = 2.4677e-01, time/batch = 15.8680s	
22131/22300 (epoch 49.621), train_loss = 0.23549113, grad/param norm = 2.1918e-01, time/batch = 17.2185s	
22132/22300 (epoch 49.623), train_loss = 0.25565631, grad/param norm = 1.8287e-01, time/batch = 16.5892s	
22133/22300 (epoch 49.626), train_loss = 0.24250592, grad/param norm = 2.5303e-01, time/batch = 15.2810s	
22134/22300 (epoch 49.628), train_loss = 0.25701313, grad/param norm = 1.7626e-01, time/batch = 15.5617s	
22135/22300 (epoch 49.630), train_loss = 0.27107218, grad/param norm = 1.8993e-01, time/batch = 14.9908s	
22136/22300 (epoch 49.632), train_loss = 0.24998942, grad/param norm = 2.5058e-01, time/batch = 15.0576s	
22137/22300 (epoch 49.635), train_loss = 0.29266326, grad/param norm = 2.3715e-01, time/batch = 15.8523s	
22138/22300 (epoch 49.637), train_loss = 0.31247859, grad/param norm = 2.3151e-01, time/batch = 15.0654s	
22139/22300 (epoch 49.639), train_loss = 0.40821106, grad/param norm = 3.5919e-01, time/batch = 15.2326s	
22140/22300 (epoch 49.641), train_loss = 0.31305969, grad/param norm = 2.3177e-01, time/batch = 15.1408s	
22141/22300 (epoch 49.643), train_loss = 0.25225112, grad/param norm = 2.1937e-01, time/batch = 17.2940s	
22142/22300 (epoch 49.646), train_loss = 0.25642096, grad/param norm = 2.2320e-01, time/batch = 15.5654s	
22143/22300 (epoch 49.648), train_loss = 0.35212834, grad/param norm = 1.9731e-01, time/batch = 16.6860s	
22144/22300 (epoch 49.650), train_loss = 0.34369709, grad/param norm = 4.2156e-01, time/batch = 16.1229s	
22145/22300 (epoch 49.652), train_loss = 0.26687076, grad/param norm = 1.9653e-01, time/batch = 16.3022s	
22146/22300 (epoch 49.655), train_loss = 0.22051717, grad/param norm = 2.0376e-01, time/batch = 17.3966s	
22147/22300 (epoch 49.657), train_loss = 0.27012037, grad/param norm = 2.6648e-01, time/batch = 16.2948s	
22148/22300 (epoch 49.659), train_loss = 0.26868912, grad/param norm = 2.9528e-01, time/batch = 14.9025s	
22149/22300 (epoch 49.661), train_loss = 0.21535799, grad/param norm = 1.9615e-01, time/batch = 16.8141s	
22150/22300 (epoch 49.664), train_loss = 0.25770438, grad/param norm = 2.0663e-01, time/batch = 16.7180s	
22151/22300 (epoch 49.666), train_loss = 0.30806995, grad/param norm = 2.1588e-01, time/batch = 16.6892s	
22152/22300 (epoch 49.668), train_loss = 0.25158684, grad/param norm = 2.4238e-01, time/batch = 15.7227s	
22153/22300 (epoch 49.670), train_loss = 0.29116365, grad/param norm = 2.6943e-01, time/batch = 15.7119s	
22154/22300 (epoch 49.673), train_loss = 0.37528355, grad/param norm = 2.8299e-01, time/batch = 15.5248s	
22155/22300 (epoch 49.675), train_loss = 0.38517542, grad/param norm = 3.1981e-01, time/batch = 15.7006s	
22156/22300 (epoch 49.677), train_loss = 0.41956467, grad/param norm = 2.5916e-01, time/batch = 16.6156s	
22157/22300 (epoch 49.679), train_loss = 0.28357272, grad/param norm = 2.6757e-01, time/batch = 15.9721s	
22158/22300 (epoch 49.682), train_loss = 0.27245475, grad/param norm = 2.0751e-01, time/batch = 15.8916s	
22159/22300 (epoch 49.684), train_loss = 0.27959651, grad/param norm = 2.0374e-01, time/batch = 15.5431s	
22160/22300 (epoch 49.686), train_loss = 0.23770359, grad/param norm = 1.7635e-01, time/batch = 14.8085s	
22161/22300 (epoch 49.688), train_loss = 0.24605288, grad/param norm = 2.6338e-01, time/batch = 15.6110s	
22162/22300 (epoch 49.691), train_loss = 0.23107732, grad/param norm = 1.9604e-01, time/batch = 16.9640s	
22163/22300 (epoch 49.693), train_loss = 0.23518432, grad/param norm = 2.0623e-01, time/batch = 16.4612s	
22164/22300 (epoch 49.695), train_loss = 0.25494223, grad/param norm = 1.8774e-01, time/batch = 15.8100s	
22165/22300 (epoch 49.697), train_loss = 0.25655103, grad/param norm = 1.4734e-01, time/batch = 16.4370s	
22166/22300 (epoch 49.700), train_loss = 0.22449807, grad/param norm = 1.8090e-01, time/batch = 15.1899s	
22167/22300 (epoch 49.702), train_loss = 0.18037731, grad/param norm = 1.6048e-01, time/batch = 17.4785s	
22168/22300 (epoch 49.704), train_loss = 0.24529102, grad/param norm = 2.2339e-01, time/batch = 16.0605s	
22169/22300 (epoch 49.706), train_loss = 0.23521645, grad/param norm = 1.8008e-01, time/batch = 16.2176s	
22170/22300 (epoch 49.709), train_loss = 0.17179526, grad/param norm = 1.5912e-01, time/batch = 15.1100s	
22171/22300 (epoch 49.711), train_loss = 0.18227790, grad/param norm = 1.5305e-01, time/batch = 15.8712s	
22172/22300 (epoch 49.713), train_loss = 0.28258630, grad/param norm = 2.6441e-01, time/batch = 16.6417s	
22173/22300 (epoch 49.715), train_loss = 0.31197545, grad/param norm = 2.2160e-01, time/batch = 16.0432s	
22174/22300 (epoch 49.717), train_loss = 0.35829008, grad/param norm = 1.8209e-01, time/batch = 15.6098s	
22175/22300 (epoch 49.720), train_loss = 0.21639477, grad/param norm = 2.1859e-01, time/batch = 14.8941s	
22176/22300 (epoch 49.722), train_loss = 0.25858728, grad/param norm = 1.9639e-01, time/batch = 15.2364s	
22177/22300 (epoch 49.724), train_loss = 0.28492794, grad/param norm = 2.3754e-01, time/batch = 15.9288s	
22178/22300 (epoch 49.726), train_loss = 0.23859649, grad/param norm = 3.1132e-01, time/batch = 14.8893s	
22179/22300 (epoch 49.729), train_loss = 0.28427600, grad/param norm = 1.8238e-01, time/batch = 15.2066s	
22180/22300 (epoch 49.731), train_loss = 0.34039260, grad/param norm = 3.1646e-01, time/batch = 15.0461s	
22181/22300 (epoch 49.733), train_loss = 0.33494120, grad/param norm = 2.7539e-01, time/batch = 16.7100s	
22182/22300 (epoch 49.735), train_loss = 0.37975782, grad/param norm = 3.1006e-01, time/batch = 16.2228s	
22183/22300 (epoch 49.738), train_loss = 0.27763731, grad/param norm = 3.5646e-01, time/batch = 15.9040s	
22184/22300 (epoch 49.740), train_loss = 0.25668168, grad/param norm = 2.0537e-01, time/batch = 14.9732s	
22185/22300 (epoch 49.742), train_loss = 0.22039836, grad/param norm = 1.9155e-01, time/batch = 14.8767s	
22186/22300 (epoch 49.744), train_loss = 0.39801636, grad/param norm = 3.0653e-01, time/batch = 15.3185s	
22187/22300 (epoch 49.747), train_loss = 0.32756786, grad/param norm = 2.6361e-01, time/batch = 15.1435s	
22188/22300 (epoch 49.749), train_loss = 0.43040657, grad/param norm = 3.2966e-01, time/batch = 15.7814s	
22189/22300 (epoch 49.751), train_loss = 0.33185210, grad/param norm = 2.7403e-01, time/batch = 15.4473s	
22190/22300 (epoch 49.753), train_loss = 0.39102658, grad/param norm = 3.1857e-01, time/batch = 16.7983s	
22191/22300 (epoch 49.756), train_loss = 0.37195269, grad/param norm = 2.2486e-01, time/batch = 16.6350s	
22192/22300 (epoch 49.758), train_loss = 0.28696138, grad/param norm = 2.1134e-01, time/batch = 15.1539s	
22193/22300 (epoch 49.760), train_loss = 0.32748323, grad/param norm = 2.6067e-01, time/batch = 15.7847s	
22194/22300 (epoch 49.762), train_loss = 0.29936034, grad/param norm = 2.3048e-01, time/batch = 15.8938s	
22195/22300 (epoch 49.765), train_loss = 0.33013198, grad/param norm = 2.5604e-01, time/batch = 15.6042s	
22196/22300 (epoch 49.767), train_loss = 0.30239675, grad/param norm = 2.9545e-01, time/batch = 14.8647s	
22197/22300 (epoch 49.769), train_loss = 0.28469436, grad/param norm = 2.7477e-01, time/batch = 15.3105s	
22198/22300 (epoch 49.771), train_loss = 0.34473658, grad/param norm = 3.6784e-01, time/batch = 15.0738s	
22199/22300 (epoch 49.774), train_loss = 0.39902728, grad/param norm = 3.4732e-01, time/batch = 15.3438s	
22200/22300 (epoch 49.776), train_loss = 0.39544301, grad/param norm = 2.4378e-01, time/batch = 15.3720s	
22201/22300 (epoch 49.778), train_loss = 0.40091411, grad/param norm = 2.6456e-01, time/batch = 16.8892s	
22202/22300 (epoch 49.780), train_loss = 0.37953317, grad/param norm = 2.5553e-01, time/batch = 15.3948s	
22203/22300 (epoch 49.783), train_loss = 0.45268053, grad/param norm = 4.0650e-01, time/batch = 15.8275s	
22204/22300 (epoch 49.785), train_loss = 0.26155599, grad/param norm = 2.1162e-01, time/batch = 15.6155s	
22205/22300 (epoch 49.787), train_loss = 0.28082877, grad/param norm = 2.2045e-01, time/batch = 15.8094s	
22206/22300 (epoch 49.789), train_loss = 0.42403016, grad/param norm = 3.0858e-01, time/batch = 16.3914s	
22207/22300 (epoch 49.791), train_loss = 0.51178443, grad/param norm = 3.3157e-01, time/batch = 15.9639s	
22208/22300 (epoch 49.794), train_loss = 0.41140185, grad/param norm = 2.7273e-01, time/batch = 15.3639s	
22209/22300 (epoch 49.796), train_loss = 0.36101922, grad/param norm = 3.1352e-01, time/batch = 14.9852s	
22210/22300 (epoch 49.798), train_loss = 0.48671784, grad/param norm = 2.9585e-01, time/batch = 15.3930s	
22211/22300 (epoch 49.800), train_loss = 0.34937172, grad/param norm = 2.7872e-01, time/batch = 15.7305s	
22212/22300 (epoch 49.803), train_loss = 0.30227925, grad/param norm = 2.2189e-01, time/batch = 15.6734s	
22213/22300 (epoch 49.805), train_loss = 0.32616286, grad/param norm = 2.8460e-01, time/batch = 15.7247s	
22214/22300 (epoch 49.807), train_loss = 0.44100556, grad/param norm = 3.8291e-01, time/batch = 15.3989s	
22215/22300 (epoch 49.809), train_loss = 0.32805984, grad/param norm = 2.8910e-01, time/batch = 15.5547s	
22216/22300 (epoch 49.812), train_loss = 0.33996299, grad/param norm = 2.6861e-01, time/batch = 15.2033s	
22217/22300 (epoch 49.814), train_loss = 0.30824520, grad/param norm = 2.3843e-01, time/batch = 15.7432s	
22218/22300 (epoch 49.816), train_loss = 0.35627134, grad/param norm = 2.6675e-01, time/batch = 17.7999s	
22219/22300 (epoch 49.818), train_loss = 0.39876516, grad/param norm = 3.3244e-01, time/batch = 16.1317s	
22220/22300 (epoch 49.821), train_loss = 0.32949941, grad/param norm = 3.1868e-01, time/batch = 15.5865s	
22221/22300 (epoch 49.823), train_loss = 0.23059812, grad/param norm = 2.0212e-01, time/batch = 15.2988s	
22222/22300 (epoch 49.825), train_loss = 0.22165738, grad/param norm = 1.6381e-01, time/batch = 15.5552s	
22223/22300 (epoch 49.827), train_loss = 0.26863201, grad/param norm = 2.5291e-01, time/batch = 15.4437s	
22224/22300 (epoch 49.830), train_loss = 0.27906677, grad/param norm = 2.0410e-01, time/batch = 15.2615s	
22225/22300 (epoch 49.832), train_loss = 0.27824787, grad/param norm = 2.1199e-01, time/batch = 16.6879s	
22226/22300 (epoch 49.834), train_loss = 0.23015979, grad/param norm = 2.3633e-01, time/batch = 16.5445s	
22227/22300 (epoch 49.836), train_loss = 0.28013498, grad/param norm = 2.5135e-01, time/batch = 15.1331s	
22228/22300 (epoch 49.839), train_loss = 0.30985561, grad/param norm = 2.3312e-01, time/batch = 16.0731s	
22229/22300 (epoch 49.841), train_loss = 0.26920663, grad/param norm = 2.8548e-01, time/batch = 15.2870s	
22230/22300 (epoch 49.843), train_loss = 0.27818365, grad/param norm = 2.0991e-01, time/batch = 15.2207s	
22231/22300 (epoch 49.845), train_loss = 0.29338148, grad/param norm = 2.0998e-01, time/batch = 15.9569s	
22232/22300 (epoch 49.848), train_loss = 0.28172284, grad/param norm = 2.7350e-01, time/batch = 15.4844s	
22233/22300 (epoch 49.850), train_loss = 0.30069157, grad/param norm = 1.9594e-01, time/batch = 15.0664s	
22234/22300 (epoch 49.852), train_loss = 0.28422886, grad/param norm = 3.1254e-01, time/batch = 15.5642s	
22235/22300 (epoch 49.854), train_loss = 0.45908383, grad/param norm = 3.3410e-01, time/batch = 15.9661s	
22236/22300 (epoch 49.857), train_loss = 0.34727596, grad/param norm = 2.8700e-01, time/batch = 15.3818s	
22237/22300 (epoch 49.859), train_loss = 0.26874663, grad/param norm = 1.9161e-01, time/batch = 14.7575s	
22238/22300 (epoch 49.861), train_loss = 0.38045296, grad/param norm = 2.5535e-01, time/batch = 15.8872s	
22239/22300 (epoch 49.863), train_loss = 0.23397895, grad/param norm = 2.9570e-01, time/batch = 16.0458s	
22240/22300 (epoch 49.865), train_loss = 0.23402026, grad/param norm = 2.4826e-01, time/batch = 16.1890s	
22241/22300 (epoch 49.868), train_loss = 0.31256239, grad/param norm = 1.7745e-01, time/batch = 16.7298s	
22242/22300 (epoch 49.870), train_loss = 0.30488597, grad/param norm = 2.7189e-01, time/batch = 14.8073s	
22243/22300 (epoch 49.872), train_loss = 0.40817567, grad/param norm = 2.5509e-01, time/batch = 16.2295s	
22244/22300 (epoch 49.874), train_loss = 0.33640628, grad/param norm = 3.5111e-01, time/batch = 16.5636s	
22245/22300 (epoch 49.877), train_loss = 0.31264078, grad/param norm = 2.1906e-01, time/batch = 16.2886s	
22246/22300 (epoch 49.879), train_loss = 0.28472111, grad/param norm = 1.9824e-01, time/batch = 14.9598s	
22247/22300 (epoch 49.881), train_loss = 0.21553878, grad/param norm = 2.0327e-01, time/batch = 15.3496s	
22248/22300 (epoch 49.883), train_loss = 0.23711640, grad/param norm = 2.8419e-01, time/batch = 14.9496s	
22249/22300 (epoch 49.886), train_loss = 0.21618879, grad/param norm = 2.5520e-01, time/batch = 14.7440s	
22250/22300 (epoch 49.888), train_loss = 0.27277663, grad/param norm = 2.0072e-01, time/batch = 15.6608s	
22251/22300 (epoch 49.890), train_loss = 0.26986262, grad/param norm = 2.0261e-01, time/batch = 15.2924s	
22252/22300 (epoch 49.892), train_loss = 0.41131164, grad/param norm = 2.6745e-01, time/batch = 15.1243s	
22253/22300 (epoch 49.895), train_loss = 0.36739090, grad/param norm = 4.0079e-01, time/batch = 15.1507s	
22254/22300 (epoch 49.897), train_loss = 0.28394458, grad/param norm = 2.3737e-01, time/batch = 15.1460s	
22255/22300 (epoch 49.899), train_loss = 0.29336026, grad/param norm = 2.1340e-01, time/batch = 15.8848s	
22256/22300 (epoch 49.901), train_loss = 0.35845105, grad/param norm = 2.9607e-01, time/batch = 14.7991s	
22257/22300 (epoch 49.904), train_loss = 0.33029871, grad/param norm = 2.6216e-01, time/batch = 15.3857s	
22258/22300 (epoch 49.906), train_loss = 0.34335835, grad/param norm = 2.5924e-01, time/batch = 15.3057s	
22259/22300 (epoch 49.908), train_loss = 0.29028492, grad/param norm = 2.0332e-01, time/batch = 16.2191s	
22260/22300 (epoch 49.910), train_loss = 0.25914650, grad/param norm = 2.0256e-01, time/batch = 16.1368s	
22261/22300 (epoch 49.913), train_loss = 0.30945810, grad/param norm = 2.3541e-01, time/batch = 15.2335s	
22262/22300 (epoch 49.915), train_loss = 0.41159679, grad/param norm = 2.8922e-01, time/batch = 15.5654s	
22263/22300 (epoch 49.917), train_loss = 0.35619723, grad/param norm = 3.0926e-01, time/batch = 15.2203s	
22264/22300 (epoch 49.919), train_loss = 0.31300543, grad/param norm = 2.1999e-01, time/batch = 16.5323s	
22265/22300 (epoch 49.922), train_loss = 0.30411184, grad/param norm = 2.7544e-01, time/batch = 15.6225s	
22266/22300 (epoch 49.924), train_loss = 0.19629140, grad/param norm = 1.6142e-01, time/batch = 15.4599s	
22267/22300 (epoch 49.926), train_loss = 0.25943142, grad/param norm = 2.1862e-01, time/batch = 15.3284s	
22268/22300 (epoch 49.928), train_loss = 0.26690831, grad/param norm = 2.1157e-01, time/batch = 15.5662s	
22269/22300 (epoch 49.930), train_loss = 0.23757227, grad/param norm = 2.2305e-01, time/batch = 15.6054s	
22270/22300 (epoch 49.933), train_loss = 0.31694495, grad/param norm = 2.6322e-01, time/batch = 14.9064s	
22271/22300 (epoch 49.935), train_loss = 0.29559509, grad/param norm = 3.1214e-01, time/batch = 15.0621s	
22272/22300 (epoch 49.937), train_loss = 0.40113293, grad/param norm = 3.8787e-01, time/batch = 14.3445s	
22273/22300 (epoch 49.939), train_loss = 0.35129295, grad/param norm = 2.7371e-01, time/batch = 14.4677s	
22274/22300 (epoch 49.942), train_loss = 0.42196532, grad/param norm = 3.4995e-01, time/batch = 14.7422s	
22275/22300 (epoch 49.944), train_loss = 0.45978525, grad/param norm = 3.7818e-01, time/batch = 14.0907s	
22276/22300 (epoch 49.946), train_loss = 0.32049681, grad/param norm = 2.4356e-01, time/batch = 14.0892s	
22277/22300 (epoch 49.948), train_loss = 0.29507790, grad/param norm = 1.8033e-01, time/batch = 14.1583s	
22278/22300 (epoch 49.951), train_loss = 0.22205993, grad/param norm = 1.8073e-01, time/batch = 14.5732s	
22279/22300 (epoch 49.953), train_loss = 0.23036396, grad/param norm = 1.9388e-01, time/batch = 14.9679s	
22280/22300 (epoch 49.955), train_loss = 0.38097674, grad/param norm = 2.5509e-01, time/batch = 14.6453s	
22281/22300 (epoch 49.957), train_loss = 0.45765064, grad/param norm = 2.5922e-01, time/batch = 14.8591s	
22282/22300 (epoch 49.960), train_loss = 0.42326201, grad/param norm = 3.3417e-01, time/batch = 14.5605s	
22283/22300 (epoch 49.962), train_loss = 0.24665977, grad/param norm = 2.6490e-01, time/batch = 14.5870s	
22284/22300 (epoch 49.964), train_loss = 0.24257830, grad/param norm = 2.3277e-01, time/batch = 14.4864s	
22285/22300 (epoch 49.966), train_loss = 0.26489668, grad/param norm = 1.9322e-01, time/batch = 14.8717s	
22286/22300 (epoch 49.969), train_loss = 0.28652329, grad/param norm = 2.4749e-01, time/batch = 15.2161s	
22287/22300 (epoch 49.971), train_loss = 0.30374678, grad/param norm = 2.3165e-01, time/batch = 15.1091s	
22288/22300 (epoch 49.973), train_loss = 0.25977420, grad/param norm = 1.9616e-01, time/batch = 15.5636s	
22289/22300 (epoch 49.975), train_loss = 0.38744477, grad/param norm = 2.7795e-01, time/batch = 15.4212s	
22290/22300 (epoch 49.978), train_loss = 0.39994592, grad/param norm = 2.8487e-01, time/batch = 15.4694s	
22291/22300 (epoch 49.980), train_loss = 0.48211179, grad/param norm = 3.6773e-01, time/batch = 14.9140s	
22292/22300 (epoch 49.982), train_loss = 0.22577114, grad/param norm = 1.8984e-01, time/batch = 14.9092s	
22293/22300 (epoch 49.984), train_loss = 0.28647411, grad/param norm = 1.9374e-01, time/batch = 14.7838s	
22294/22300 (epoch 49.987), train_loss = 0.30256613, grad/param norm = 2.5782e-01, time/batch = 14.2595s	
22295/22300 (epoch 49.989), train_loss = 0.23249470, grad/param norm = 1.9286e-01, time/batch = 14.3436s	
22296/22300 (epoch 49.991), train_loss = 0.45334358, grad/param norm = 3.1800e-01, time/batch = 15.4438s	
22297/22300 (epoch 49.993), train_loss = 0.59597312, grad/param norm = 3.2685e-01, time/batch = 14.5685s	
22298/22300 (epoch 49.996), train_loss = 0.58224048, grad/param norm = 3.5653e-01, time/batch = 15.1905s	
22299/22300 (epoch 49.998), train_loss = 0.33903073, grad/param norm = 2.7844e-01, time/batch = 14.8216s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_newscientist_epoch50.00_1.7554.t7	
22300/22300 (epoch 50.000), train_loss = 0.26941146, grad/param norm = 2.4891e-01, time/batch = 14.6501s	

real	4464m18.335s
user	4435m27.912s
sys	4m36.380s
