tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 606, val: 32, test: 0	
vocab size: 169	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 306985	
cloning rnn	
cloning criterion	
1/30300 (epoch 0.002), train_loss = 5.13631993, grad/param norm = 5.7536e-01, time/batch = 0.7339s	
2/30300 (epoch 0.003), train_loss = 4.84621572, grad/param norm = 1.5568e+00, time/batch = 0.6924s	
3/30300 (epoch 0.005), train_loss = 4.01442518, grad/param norm = 1.4764e+00, time/batch = 0.6948s	
4/30300 (epoch 0.007), train_loss = 3.88513857, grad/param norm = 1.0133e+00, time/batch = 0.7054s	
5/30300 (epoch 0.008), train_loss = 3.74222392, grad/param norm = 8.4594e-01, time/batch = 0.6899s	
6/30300 (epoch 0.010), train_loss = 3.49501040, grad/param norm = 6.2738e-01, time/batch = 0.6950s	
7/30300 (epoch 0.012), train_loss = 3.51998183, grad/param norm = 6.4039e-01, time/batch = 0.6924s	
8/30300 (epoch 0.013), train_loss = 3.54089310, grad/param norm = 5.6220e-01, time/batch = 0.6978s	
9/30300 (epoch 0.015), train_loss = 3.55367157, grad/param norm = 5.8775e-01, time/batch = 0.7200s	
10/30300 (epoch 0.017), train_loss = 3.43792190, grad/param norm = 8.0885e-01, time/batch = 0.7024s	
11/30300 (epoch 0.018), train_loss = 3.44542226, grad/param norm = 7.6484e-01, time/batch = 0.6930s	
12/30300 (epoch 0.020), train_loss = 3.56656158, grad/param norm = 7.3837e-01, time/batch = 0.6907s	
13/30300 (epoch 0.021), train_loss = 3.40076297, grad/param norm = 8.4501e-01, time/batch = 0.6906s	
14/30300 (epoch 0.023), train_loss = 3.53374795, grad/param norm = 8.0634e-01, time/batch = 0.6898s	
15/30300 (epoch 0.025), train_loss = 3.52714375, grad/param norm = 7.4821e-01, time/batch = 0.6926s	
16/30300 (epoch 0.026), train_loss = 3.55280429, grad/param norm = 6.8797e-01, time/batch = 0.6877s	
17/30300 (epoch 0.028), train_loss = 3.52166780, grad/param norm = 6.0334e-01, time/batch = 0.6884s	
18/30300 (epoch 0.030), train_loss = 3.54890677, grad/param norm = 6.2562e-01, time/batch = 0.6920s	
19/30300 (epoch 0.031), train_loss = 3.54964691, grad/param norm = 8.1566e-01, time/batch = 0.6905s	
20/30300 (epoch 0.033), train_loss = 3.60946509, grad/param norm = 7.0713e-01, time/batch = 0.6947s	
21/30300 (epoch 0.035), train_loss = 3.48425018, grad/param norm = 6.0668e-01, time/batch = 0.6892s	
22/30300 (epoch 0.036), train_loss = 3.68329353, grad/param norm = 7.4324e-01, time/batch = 0.6890s	
23/30300 (epoch 0.038), train_loss = 3.46122948, grad/param norm = 6.3775e-01, time/batch = 0.7121s	
24/30300 (epoch 0.040), train_loss = 3.43640867, grad/param norm = 5.5798e-01, time/batch = 0.7082s	
25/30300 (epoch 0.041), train_loss = 3.56575688, grad/param norm = 6.4631e-01, time/batch = 0.6914s	
26/30300 (epoch 0.043), train_loss = 3.47737007, grad/param norm = 6.0657e-01, time/batch = 0.6923s	
27/30300 (epoch 0.045), train_loss = 3.56335950, grad/param norm = 6.7250e-01, time/batch = 0.6896s	
28/30300 (epoch 0.046), train_loss = 3.39522477, grad/param norm = 6.4989e-01, time/batch = 0.6883s	
29/30300 (epoch 0.048), train_loss = 3.45410817, grad/param norm = 5.4553e-01, time/batch = 0.6898s	
30/30300 (epoch 0.050), train_loss = 3.86625072, grad/param norm = 8.7660e-01, time/batch = 0.6905s	
31/30300 (epoch 0.051), train_loss = 3.86048260, grad/param norm = 9.1270e-01, time/batch = 0.6889s	
32/30300 (epoch 0.053), train_loss = 3.66069431, grad/param norm = 6.7261e-01, time/batch = 0.6894s	
33/30300 (epoch 0.054), train_loss = 3.49714137, grad/param norm = 7.1951e-01, time/batch = 0.6893s	
34/30300 (epoch 0.056), train_loss = 3.47494699, grad/param norm = 6.1702e-01, time/batch = 0.6898s	
35/30300 (epoch 0.058), train_loss = 3.55586412, grad/param norm = 5.4803e-01, time/batch = 0.6994s	
36/30300 (epoch 0.059), train_loss = 3.61738345, grad/param norm = 7.8526e-01, time/batch = 0.6938s	
37/30300 (epoch 0.061), train_loss = 3.43180688, grad/param norm = 7.1375e-01, time/batch = 0.7018s	
38/30300 (epoch 0.063), train_loss = 3.48235889, grad/param norm = 6.2154e-01, time/batch = 0.7190s	
39/30300 (epoch 0.064), train_loss = 3.56526613, grad/param norm = 5.6734e-01, time/batch = 0.6867s	
40/30300 (epoch 0.066), train_loss = 3.48719317, grad/param norm = 5.9271e-01, time/batch = 0.6896s	
41/30300 (epoch 0.068), train_loss = 3.33412486, grad/param norm = 4.2863e-01, time/batch = 0.6872s	
42/30300 (epoch 0.069), train_loss = 3.58336772, grad/param norm = 6.5384e-01, time/batch = 0.6900s	
43/30300 (epoch 0.071), train_loss = 3.55858334, grad/param norm = 7.5235e-01, time/batch = 0.7007s	
44/30300 (epoch 0.073), train_loss = 3.47130808, grad/param norm = 5.7224e-01, time/batch = 0.6912s	
45/30300 (epoch 0.074), train_loss = 3.48236172, grad/param norm = 5.0732e-01, time/batch = 0.6912s	
46/30300 (epoch 0.076), train_loss = 3.46581851, grad/param norm = 7.0818e-01, time/batch = 0.6864s	
47/30300 (epoch 0.078), train_loss = 3.52225762, grad/param norm = 7.7170e-01, time/batch = 0.6903s	
48/30300 (epoch 0.079), train_loss = 3.42636028, grad/param norm = 7.0247e-01, time/batch = 0.6930s	
49/30300 (epoch 0.081), train_loss = 3.55097970, grad/param norm = 7.3051e-01, time/batch = 0.6924s	
50/30300 (epoch 0.083), train_loss = 3.71919277, grad/param norm = 6.6252e-01, time/batch = 0.6859s	
51/30300 (epoch 0.084), train_loss = 3.41185160, grad/param norm = 6.5802e-01, time/batch = 0.6924s	
52/30300 (epoch 0.086), train_loss = 3.50877092, grad/param norm = 5.7652e-01, time/batch = 0.6896s	
53/30300 (epoch 0.087), train_loss = 3.37587213, grad/param norm = 4.6923e-01, time/batch = 0.6842s	
54/30300 (epoch 0.089), train_loss = 3.59922700, grad/param norm = 5.9468e-01, time/batch = 0.6933s	
55/30300 (epoch 0.091), train_loss = 3.34157190, grad/param norm = 5.9890e-01, time/batch = 0.6891s	
56/30300 (epoch 0.092), train_loss = 3.40530510, grad/param norm = 5.1215e-01, time/batch = 0.6962s	
57/30300 (epoch 0.094), train_loss = 3.56842383, grad/param norm = 6.4107e-01, time/batch = 0.6875s	
58/30300 (epoch 0.096), train_loss = 3.43062740, grad/param norm = 8.5331e-01, time/batch = 0.6933s	
59/30300 (epoch 0.097), train_loss = 3.48852540, grad/param norm = 7.3616e-01, time/batch = 0.6988s	
60/30300 (epoch 0.099), train_loss = 3.65190954, grad/param norm = 9.1680e-01, time/batch = 0.6960s	
61/30300 (epoch 0.101), train_loss = 3.95801232, grad/param norm = 8.2450e-01, time/batch = 0.6959s	
62/30300 (epoch 0.102), train_loss = 4.03596705, grad/param norm = 8.8592e-01, time/batch = 0.6947s	
63/30300 (epoch 0.104), train_loss = 4.02637774, grad/param norm = 9.4513e-01, time/batch = 0.6921s	
64/30300 (epoch 0.106), train_loss = 3.90734710, grad/param norm = 8.1909e-01, time/batch = 0.6891s	
65/30300 (epoch 0.107), train_loss = 3.69830631, grad/param norm = 4.5236e-01, time/batch = 0.6943s	
66/30300 (epoch 0.109), train_loss = 3.56646706, grad/param norm = 5.8150e-01, time/batch = 0.6882s	
67/30300 (epoch 0.111), train_loss = 3.42862411, grad/param norm = 5.7281e-01, time/batch = 0.7026s	
68/30300 (epoch 0.112), train_loss = 3.51948805, grad/param norm = 4.8494e-01, time/batch = 0.6865s	
69/30300 (epoch 0.114), train_loss = 3.41908294, grad/param norm = 5.3986e-01, time/batch = 0.6914s	
70/30300 (epoch 0.116), train_loss = 3.49972585, grad/param norm = 4.2507e-01, time/batch = 0.6891s	
71/30300 (epoch 0.117), train_loss = 3.54194151, grad/param norm = 5.7484e-01, time/batch = 0.6911s	
72/30300 (epoch 0.119), train_loss = 3.38915235, grad/param norm = 5.5716e-01, time/batch = 0.7056s	
73/30300 (epoch 0.120), train_loss = 3.42704709, grad/param norm = 6.2140e-01, time/batch = 0.7028s	
74/30300 (epoch 0.122), train_loss = 3.45279203, grad/param norm = 5.8195e-01, time/batch = 0.7042s	
75/30300 (epoch 0.124), train_loss = 3.50377645, grad/param norm = 6.6664e-01, time/batch = 0.6853s	
76/30300 (epoch 0.125), train_loss = 3.50772348, grad/param norm = 5.1124e-01, time/batch = 0.6877s	
77/30300 (epoch 0.127), train_loss = 3.47479423, grad/param norm = 4.8660e-01, time/batch = 0.6872s	
78/30300 (epoch 0.129), train_loss = 3.41125989, grad/param norm = 6.9872e-01, time/batch = 0.6891s	
79/30300 (epoch 0.130), train_loss = 3.53978852, grad/param norm = 5.8951e-01, time/batch = 0.6847s	
80/30300 (epoch 0.132), train_loss = 3.43904533, grad/param norm = 8.7145e-01, time/batch = 0.7121s	
81/30300 (epoch 0.134), train_loss = 3.41134212, grad/param norm = 6.7109e-01, time/batch = 0.7045s	
82/30300 (epoch 0.135), train_loss = 3.55132301, grad/param norm = 6.4003e-01, time/batch = 0.6914s	
83/30300 (epoch 0.137), train_loss = 3.44906754, grad/param norm = 5.9675e-01, time/batch = 0.6915s	
84/30300 (epoch 0.139), train_loss = 3.62465188, grad/param norm = 6.9126e-01, time/batch = 0.6958s	
85/30300 (epoch 0.140), train_loss = 4.00128817, grad/param norm = 6.3573e-01, time/batch = 0.6941s	
86/30300 (epoch 0.142), train_loss = 3.93685329, grad/param norm = 7.0406e-01, time/batch = 0.6878s	
87/30300 (epoch 0.144), train_loss = 3.82480493, grad/param norm = 6.4085e-01, time/batch = 0.6983s	
88/30300 (epoch 0.145), train_loss = 3.92524328, grad/param norm = 5.9499e-01, time/batch = 0.6998s	
89/30300 (epoch 0.147), train_loss = 3.88151540, grad/param norm = 8.4066e-01, time/batch = 0.6827s	
90/30300 (epoch 0.149), train_loss = 3.83994716, grad/param norm = 5.4527e-01, time/batch = 0.6974s	
91/30300 (epoch 0.150), train_loss = 3.84752494, grad/param norm = 3.4743e-01, time/batch = 0.7208s	
92/30300 (epoch 0.152), train_loss = 3.66245681, grad/param norm = 4.3358e-01, time/batch = 0.6898s	
93/30300 (epoch 0.153), train_loss = 3.76412761, grad/param norm = 9.4981e-01, time/batch = 0.6946s	
94/30300 (epoch 0.155), train_loss = 3.95799714, grad/param norm = 2.4907e+00, time/batch = 0.6836s	
95/30300 (epoch 0.157), train_loss = 3.71040428, grad/param norm = 3.8449e-01, time/batch = 0.6827s	
96/30300 (epoch 0.158), train_loss = 3.77410121, grad/param norm = 5.5380e-01, time/batch = 0.6830s	
97/30300 (epoch 0.160), train_loss = 3.44852095, grad/param norm = 4.7594e-01, time/batch = 0.6849s	
98/30300 (epoch 0.162), train_loss = 3.52046640, grad/param norm = 5.6022e-01, time/batch = 0.6862s	
99/30300 (epoch 0.163), train_loss = 3.46278350, grad/param norm = 4.9169e-01, time/batch = 0.6874s	
100/30300 (epoch 0.165), train_loss = 3.57770138, grad/param norm = 5.1586e-01, time/batch = 0.6875s	
101/30300 (epoch 0.167), train_loss = 3.56319410, grad/param norm = 3.8565e-01, time/batch = 0.6829s	
102/30300 (epoch 0.168), train_loss = 3.41428918, grad/param norm = 4.5157e-01, time/batch = 0.6932s	
103/30300 (epoch 0.170), train_loss = 3.75168279, grad/param norm = 7.2010e-01, time/batch = 0.6899s	
104/30300 (epoch 0.172), train_loss = 3.63238247, grad/param norm = 5.6674e-01, time/batch = 0.6857s	
105/30300 (epoch 0.173), train_loss = 3.56497286, grad/param norm = 4.1801e-01, time/batch = 0.6905s	
106/30300 (epoch 0.175), train_loss = 3.53580012, grad/param norm = 4.2619e-01, time/batch = 0.6874s	
107/30300 (epoch 0.177), train_loss = 3.54990809, grad/param norm = 4.4108e-01, time/batch = 0.6898s	
108/30300 (epoch 0.178), train_loss = 3.46490859, grad/param norm = 3.5661e-01, time/batch = 0.6942s	
109/30300 (epoch 0.180), train_loss = 3.45740166, grad/param norm = 3.9061e-01, time/batch = 0.6902s	
110/30300 (epoch 0.182), train_loss = 3.30243301, grad/param norm = 5.5428e-01, time/batch = 0.7040s	
111/30300 (epoch 0.183), train_loss = 3.41471031, grad/param norm = 4.1746e-01, time/batch = 0.6916s	
112/30300 (epoch 0.185), train_loss = 3.51905170, grad/param norm = 5.6962e-01, time/batch = 0.6968s	
113/30300 (epoch 0.186), train_loss = 3.47781628, grad/param norm = 5.3595e-01, time/batch = 0.7130s	
114/30300 (epoch 0.188), train_loss = 3.32705619, grad/param norm = 4.0481e-01, time/batch = 0.7193s	
115/30300 (epoch 0.190), train_loss = 3.38975853, grad/param norm = 6.4936e-01, time/batch = 0.6920s	
116/30300 (epoch 0.191), train_loss = 3.46335141, grad/param norm = 4.9778e-01, time/batch = 0.6959s	
117/30300 (epoch 0.193), train_loss = 3.41276246, grad/param norm = 4.2748e-01, time/batch = 0.6917s	
118/30300 (epoch 0.195), train_loss = 3.51743114, grad/param norm = 5.2153e-01, time/batch = 0.6885s	
119/30300 (epoch 0.196), train_loss = 3.31704825, grad/param norm = 5.8954e-01, time/batch = 0.6903s	
120/30300 (epoch 0.198), train_loss = 3.34758122, grad/param norm = 9.9903e-01, time/batch = 0.6896s	
121/30300 (epoch 0.200), train_loss = 3.51857488, grad/param norm = 7.1921e-01, time/batch = 0.7001s	
122/30300 (epoch 0.201), train_loss = 3.59906551, grad/param norm = 4.9473e-01, time/batch = 0.6966s	
123/30300 (epoch 0.203), train_loss = 3.46498949, grad/param norm = 5.0510e-01, time/batch = 0.7114s	
124/30300 (epoch 0.205), train_loss = 3.56597466, grad/param norm = 3.9983e-01, time/batch = 0.7208s	
125/30300 (epoch 0.206), train_loss = 3.53548415, grad/param norm = 3.7673e-01, time/batch = 0.6948s	
126/30300 (epoch 0.208), train_loss = 3.44290623, grad/param norm = 3.1542e-01, time/batch = 0.7004s	
127/30300 (epoch 0.210), train_loss = 3.40080787, grad/param norm = 3.9368e-01, time/batch = 0.6936s	
128/30300 (epoch 0.211), train_loss = 3.39346917, grad/param norm = 4.5959e-01, time/batch = 0.6949s	
129/30300 (epoch 0.213), train_loss = 3.36829483, grad/param norm = 4.4734e-01, time/batch = 0.7022s	
130/30300 (epoch 0.215), train_loss = 3.40217121, grad/param norm = 7.5092e-01, time/batch = 0.6962s	
131/30300 (epoch 0.216), train_loss = 3.50891336, grad/param norm = 5.8181e-01, time/batch = 0.6937s	
132/30300 (epoch 0.218), train_loss = 3.42500649, grad/param norm = 5.1704e-01, time/batch = 0.6966s	
133/30300 (epoch 0.219), train_loss = 3.37221771, grad/param norm = 7.1679e-01, time/batch = 0.7072s	
134/30300 (epoch 0.221), train_loss = 3.47880399, grad/param norm = 4.0227e-01, time/batch = 0.6892s	
135/30300 (epoch 0.223), train_loss = 3.61323517, grad/param norm = 6.7173e-01, time/batch = 0.6907s	
136/30300 (epoch 0.224), train_loss = 3.53900214, grad/param norm = 4.6547e-01, time/batch = 0.6878s	
137/30300 (epoch 0.226), train_loss = 3.38078204, grad/param norm = 4.9520e-01, time/batch = 0.6878s	
138/30300 (epoch 0.228), train_loss = 3.32476362, grad/param norm = 4.9353e-01, time/batch = 0.7192s	
139/30300 (epoch 0.229), train_loss = 3.31855875, grad/param norm = 7.9656e-01, time/batch = 0.7180s	
140/30300 (epoch 0.231), train_loss = 3.38135705, grad/param norm = 7.0445e-01, time/batch = 0.7188s	
141/30300 (epoch 0.233), train_loss = 3.31028933, grad/param norm = 4.0079e-01, time/batch = 0.7072s	
142/30300 (epoch 0.234), train_loss = 3.43346131, grad/param norm = 4.9650e-01, time/batch = 0.7060s	
143/30300 (epoch 0.236), train_loss = 3.43821933, grad/param norm = 5.3602e-01, time/batch = 0.7102s	
144/30300 (epoch 0.238), train_loss = 3.37278202, grad/param norm = 5.2892e-01, time/batch = 0.7128s	
145/30300 (epoch 0.239), train_loss = 3.62960833, grad/param norm = 1.1939e+00, time/batch = 0.7180s	
146/30300 (epoch 0.241), train_loss = 3.66224235, grad/param norm = 1.0465e+00, time/batch = 0.7167s	
147/30300 (epoch 0.243), train_loss = 3.53233717, grad/param norm = 4.4749e-01, time/batch = 0.7149s	
148/30300 (epoch 0.244), train_loss = 3.55595325, grad/param norm = 4.3148e-01, time/batch = 0.7166s	
149/30300 (epoch 0.246), train_loss = 3.57115804, grad/param norm = 3.6554e-01, time/batch = 0.7170s	
150/30300 (epoch 0.248), train_loss = 3.36700886, grad/param norm = 3.9051e-01, time/batch = 0.7276s	
151/30300 (epoch 0.249), train_loss = 3.36998674, grad/param norm = 3.2212e-01, time/batch = 0.7284s	
152/30300 (epoch 0.251), train_loss = 3.38919815, grad/param norm = 4.3061e-01, time/batch = 0.7287s	
153/30300 (epoch 0.252), train_loss = 3.46506263, grad/param norm = 5.2113e-01, time/batch = 0.7273s	
154/30300 (epoch 0.254), train_loss = 3.44661575, grad/param norm = 3.6692e-01, time/batch = 0.7268s	
155/30300 (epoch 0.256), train_loss = 3.30510394, grad/param norm = 6.6984e-01, time/batch = 0.7274s	
156/30300 (epoch 0.257), train_loss = 3.52240437, grad/param norm = 1.3629e+00, time/batch = 0.7492s	
157/30300 (epoch 0.259), train_loss = 3.37912863, grad/param norm = 9.3637e-01, time/batch = 0.7508s	
158/30300 (epoch 0.261), train_loss = 3.46047487, grad/param norm = 5.1024e-01, time/batch = 0.7444s	
159/30300 (epoch 0.262), train_loss = 3.38162653, grad/param norm = 3.5893e-01, time/batch = 0.7403s	
160/30300 (epoch 0.264), train_loss = 3.23156300, grad/param norm = 3.7902e-01, time/batch = 0.7501s	
161/30300 (epoch 0.266), train_loss = 3.28198149, grad/param norm = 4.1677e-01, time/batch = 0.7434s	
162/30300 (epoch 0.267), train_loss = 3.31420419, grad/param norm = 3.8733e-01, time/batch = 0.7276s	
163/30300 (epoch 0.269), train_loss = 3.34517853, grad/param norm = 3.0127e-01, time/batch = 0.7484s	
164/30300 (epoch 0.271), train_loss = 3.45505683, grad/param norm = 4.5845e-01, time/batch = 0.7406s	
165/30300 (epoch 0.272), train_loss = 3.35997062, grad/param norm = 5.8305e-01, time/batch = 0.7333s	
166/30300 (epoch 0.274), train_loss = 3.47103991, grad/param norm = 6.7806e-01, time/batch = 0.7140s	
167/30300 (epoch 0.276), train_loss = 3.49584309, grad/param norm = 6.2166e-01, time/batch = 0.6869s	
168/30300 (epoch 0.277), train_loss = 3.41101659, grad/param norm = 1.0193e+00, time/batch = 0.6917s	
169/30300 (epoch 0.279), train_loss = 3.30804526, grad/param norm = 3.8822e-01, time/batch = 0.6884s	
170/30300 (epoch 0.281), train_loss = 3.21758389, grad/param norm = 3.8464e-01, time/batch = 0.6875s	
171/30300 (epoch 0.282), train_loss = 3.36256103, grad/param norm = 5.2370e-01, time/batch = 0.7084s	
172/30300 (epoch 0.284), train_loss = 3.34989655, grad/param norm = 5.9832e-01, time/batch = 0.6891s	
173/30300 (epoch 0.285), train_loss = 3.32375740, grad/param norm = 6.1654e-01, time/batch = 0.6860s	
174/30300 (epoch 0.287), train_loss = 3.35604817, grad/param norm = 7.3713e-01, time/batch = 0.6856s	
175/30300 (epoch 0.289), train_loss = 3.22030058, grad/param norm = 6.8079e-01, time/batch = 0.6861s	
176/30300 (epoch 0.290), train_loss = 3.30743245, grad/param norm = 5.3652e-01, time/batch = 0.6874s	
177/30300 (epoch 0.292), train_loss = 3.30080000, grad/param norm = 5.4634e-01, time/batch = 0.6891s	
178/30300 (epoch 0.294), train_loss = 3.53595961, grad/param norm = 4.5945e-01, time/batch = 0.6932s	
179/30300 (epoch 0.295), train_loss = 3.37665085, grad/param norm = 4.0812e-01, time/batch = 0.6952s	
180/30300 (epoch 0.297), train_loss = 3.30795327, grad/param norm = 5.0307e-01, time/batch = 0.7206s	
181/30300 (epoch 0.299), train_loss = 3.29134188, grad/param norm = 6.3023e-01, time/batch = 0.6925s	
182/30300 (epoch 0.300), train_loss = 3.32812370, grad/param norm = 9.2434e-01, time/batch = 0.6904s	
183/30300 (epoch 0.302), train_loss = 3.27341560, grad/param norm = 1.0346e+00, time/batch = 0.6876s	
184/30300 (epoch 0.304), train_loss = 3.33261313, grad/param norm = 8.5450e-01, time/batch = 0.6880s	
185/30300 (epoch 0.305), train_loss = 3.21645516, grad/param norm = 6.1695e-01, time/batch = 0.6875s	
186/30300 (epoch 0.307), train_loss = 3.21445079, grad/param norm = 4.8993e-01, time/batch = 0.6949s	
187/30300 (epoch 0.309), train_loss = 3.36209906, grad/param norm = 5.0868e-01, time/batch = 0.6976s	
188/30300 (epoch 0.310), train_loss = 3.21322315, grad/param norm = 4.2035e-01, time/batch = 0.6919s	
189/30300 (epoch 0.312), train_loss = 3.12981491, grad/param norm = 5.2878e-01, time/batch = 0.6957s	
190/30300 (epoch 0.314), train_loss = 3.29028668, grad/param norm = 6.7869e-01, time/batch = 0.6906s	
191/30300 (epoch 0.315), train_loss = 3.23171375, grad/param norm = 7.7604e-01, time/batch = 0.6940s	
192/30300 (epoch 0.317), train_loss = 3.33732800, grad/param norm = 1.0163e+00, time/batch = 0.6904s	
193/30300 (epoch 0.318), train_loss = 3.31424428, grad/param norm = 8.4465e-01, time/batch = 0.6970s	
194/30300 (epoch 0.320), train_loss = 3.28006442, grad/param norm = 5.3332e-01, time/batch = 0.7198s	
195/30300 (epoch 0.322), train_loss = 3.27398714, grad/param norm = 5.2265e-01, time/batch = 0.7046s	
196/30300 (epoch 0.323), train_loss = 3.14593430, grad/param norm = 5.4199e-01, time/batch = 0.6896s	
197/30300 (epoch 0.325), train_loss = 3.31257989, grad/param norm = 5.0944e-01, time/batch = 0.6895s	
198/30300 (epoch 0.327), train_loss = 3.23571690, grad/param norm = 4.8152e-01, time/batch = 0.6988s	
199/30300 (epoch 0.328), train_loss = 3.12616882, grad/param norm = 4.5821e-01, time/batch = 0.6868s	
200/30300 (epoch 0.330), train_loss = 3.33154511, grad/param norm = 6.1174e-01, time/batch = 0.6918s	
201/30300 (epoch 0.332), train_loss = 3.22709216, grad/param norm = 6.9651e-01, time/batch = 0.6942s	
202/30300 (epoch 0.333), train_loss = 3.39940077, grad/param norm = 8.0624e-01, time/batch = 0.7041s	
203/30300 (epoch 0.335), train_loss = 3.25585308, grad/param norm = 6.8959e-01, time/batch = 0.6948s	
204/30300 (epoch 0.337), train_loss = 3.19447708, grad/param norm = 3.4831e-01, time/batch = 0.6892s	
205/30300 (epoch 0.338), train_loss = 3.23318820, grad/param norm = 3.6917e-01, time/batch = 0.6908s	
206/30300 (epoch 0.340), train_loss = 3.15417588, grad/param norm = 3.5158e-01, time/batch = 0.6924s	
207/30300 (epoch 0.342), train_loss = 3.18462078, grad/param norm = 3.5992e-01, time/batch = 0.7031s	
208/30300 (epoch 0.343), train_loss = 3.24364933, grad/param norm = 5.0010e-01, time/batch = 0.7254s	
209/30300 (epoch 0.345), train_loss = 3.23408687, grad/param norm = 5.5937e-01, time/batch = 0.7211s	
210/30300 (epoch 0.347), train_loss = 3.07109075, grad/param norm = 4.9936e-01, time/batch = 0.7198s	
211/30300 (epoch 0.348), train_loss = 3.15715904, grad/param norm = 6.3258e-01, time/batch = 0.7276s	
212/30300 (epoch 0.350), train_loss = 3.14731276, grad/param norm = 4.7827e-01, time/batch = 0.7213s	
213/30300 (epoch 0.351), train_loss = 3.21741398, grad/param norm = 3.6149e-01, time/batch = 0.7034s	
214/30300 (epoch 0.353), train_loss = 3.14720384, grad/param norm = 2.9498e-01, time/batch = 0.6948s	
215/30300 (epoch 0.355), train_loss = 3.30099098, grad/param norm = 3.9593e-01, time/batch = 0.6890s	
216/30300 (epoch 0.356), train_loss = 3.30668952, grad/param norm = 5.3555e-01, time/batch = 0.6858s	
217/30300 (epoch 0.358), train_loss = 3.17204038, grad/param norm = 5.6146e-01, time/batch = 0.6865s	
218/30300 (epoch 0.360), train_loss = 3.17122284, grad/param norm = 6.4873e-01, time/batch = 0.6889s	
219/30300 (epoch 0.361), train_loss = 3.11837423, grad/param norm = 1.0366e+00, time/batch = 0.6917s	
220/30300 (epoch 0.363), train_loss = 3.39918754, grad/param norm = 1.0865e+00, time/batch = 0.6866s	
221/30300 (epoch 0.365), train_loss = 3.33726270, grad/param norm = 1.0889e+00, time/batch = 0.6912s	
222/30300 (epoch 0.366), train_loss = 3.26106400, grad/param norm = 1.0902e+00, time/batch = 0.6895s	
223/30300 (epoch 0.368), train_loss = 3.20214359, grad/param norm = 6.8486e-01, time/batch = 0.6889s	
224/30300 (epoch 0.370), train_loss = 3.22899096, grad/param norm = 4.4562e-01, time/batch = 0.6871s	
225/30300 (epoch 0.371), train_loss = 3.16446491, grad/param norm = 3.3026e-01, time/batch = 0.6856s	
226/30300 (epoch 0.373), train_loss = 3.22617106, grad/param norm = 3.6238e-01, time/batch = 0.6890s	
227/30300 (epoch 0.375), train_loss = 3.18324541, grad/param norm = 3.3599e-01, time/batch = 0.7206s	
228/30300 (epoch 0.376), train_loss = 3.13034392, grad/param norm = 3.8127e-01, time/batch = 0.6979s	
229/30300 (epoch 0.378), train_loss = 3.19281617, grad/param norm = 5.5406e-01, time/batch = 0.6884s	
230/30300 (epoch 0.380), train_loss = 3.18044729, grad/param norm = 8.0707e-01, time/batch = 0.6926s	
231/30300 (epoch 0.381), train_loss = 3.27527725, grad/param norm = 9.1224e-01, time/batch = 0.6892s	
232/30300 (epoch 0.383), train_loss = 3.19923228, grad/param norm = 6.1975e-01, time/batch = 0.6908s	
233/30300 (epoch 0.384), train_loss = 3.28513321, grad/param norm = 5.4480e-01, time/batch = 0.6862s	
234/30300 (epoch 0.386), train_loss = 3.13040338, grad/param norm = 5.6913e-01, time/batch = 0.6886s	
235/30300 (epoch 0.388), train_loss = 3.14351172, grad/param norm = 5.4585e-01, time/batch = 0.6851s	
236/30300 (epoch 0.389), train_loss = 3.19399809, grad/param norm = 5.3406e-01, time/batch = 0.6906s	
237/30300 (epoch 0.391), train_loss = 3.14591580, grad/param norm = 2.9527e-01, time/batch = 0.6917s	
238/30300 (epoch 0.393), train_loss = 3.15040691, grad/param norm = 4.4437e-01, time/batch = 0.6893s	
239/30300 (epoch 0.394), train_loss = 3.17228872, grad/param norm = 4.7156e-01, time/batch = 0.6876s	
240/30300 (epoch 0.396), train_loss = 3.12296002, grad/param norm = 3.8354e-01, time/batch = 0.6933s	
241/30300 (epoch 0.398), train_loss = 3.14400397, grad/param norm = 3.4761e-01, time/batch = 0.7114s	
242/30300 (epoch 0.399), train_loss = 3.16883093, grad/param norm = 4.5408e-01, time/batch = 0.7148s	
243/30300 (epoch 0.401), train_loss = 3.12503666, grad/param norm = 5.8803e-01, time/batch = 0.7130s	
244/30300 (epoch 0.403), train_loss = 3.11906127, grad/param norm = 9.0702e-01, time/batch = 0.6968s	
245/30300 (epoch 0.404), train_loss = 3.17645623, grad/param norm = 1.0564e+00, time/batch = 0.6894s	
246/30300 (epoch 0.406), train_loss = 3.07770978, grad/param norm = 9.6619e-01, time/batch = 0.6892s	
247/30300 (epoch 0.408), train_loss = 3.11409635, grad/param norm = 6.4612e-01, time/batch = 0.6909s	
248/30300 (epoch 0.409), train_loss = 2.97292663, grad/param norm = 3.7361e-01, time/batch = 0.6942s	
249/30300 (epoch 0.411), train_loss = 3.04588499, grad/param norm = 5.2590e-01, time/batch = 0.6941s	
250/30300 (epoch 0.413), train_loss = 3.07107148, grad/param norm = 4.6172e-01, time/batch = 0.6910s	
251/30300 (epoch 0.414), train_loss = 3.21249945, grad/param norm = 4.2663e-01, time/batch = 0.6889s	
252/30300 (epoch 0.416), train_loss = 3.17935904, grad/param norm = 5.1565e-01, time/batch = 0.6915s	
253/30300 (epoch 0.417), train_loss = 3.13349406, grad/param norm = 4.8814e-01, time/batch = 0.6931s	
254/30300 (epoch 0.419), train_loss = 3.12135775, grad/param norm = 6.9363e-01, time/batch = 0.6956s	
255/30300 (epoch 0.421), train_loss = 3.04964361, grad/param norm = 6.4219e-01, time/batch = 0.7043s	
256/30300 (epoch 0.422), train_loss = 3.11793090, grad/param norm = 6.9059e-01, time/batch = 0.7206s	
257/30300 (epoch 0.424), train_loss = 3.12726560, grad/param norm = 8.0672e-01, time/batch = 0.6886s	
258/30300 (epoch 0.426), train_loss = 3.07421500, grad/param norm = 9.7161e-01, time/batch = 0.6928s	
259/30300 (epoch 0.427), train_loss = 3.10369729, grad/param norm = 8.9960e-01, time/batch = 0.7034s	
260/30300 (epoch 0.429), train_loss = 3.16386746, grad/param norm = 7.6958e-01, time/batch = 0.6935s	
261/30300 (epoch 0.431), train_loss = 3.05423615, grad/param norm = 7.0188e-01, time/batch = 0.6908s	
262/30300 (epoch 0.432), train_loss = 3.00920799, grad/param norm = 3.9919e-01, time/batch = 0.7003s	
263/30300 (epoch 0.434), train_loss = 3.01571109, grad/param norm = 4.8873e-01, time/batch = 0.6994s	
264/30300 (epoch 0.436), train_loss = 3.04478547, grad/param norm = 6.5136e-01, time/batch = 0.6975s	
265/30300 (epoch 0.437), train_loss = 3.16459320, grad/param norm = 6.5388e-01, time/batch = 0.6912s	
266/30300 (epoch 0.439), train_loss = 3.17397845, grad/param norm = 4.4559e-01, time/batch = 0.6888s	
267/30300 (epoch 0.441), train_loss = 2.99167679, grad/param norm = 2.8531e-01, time/batch = 0.6874s	
268/30300 (epoch 0.442), train_loss = 3.04467517, grad/param norm = 3.8989e-01, time/batch = 0.6903s	
269/30300 (epoch 0.444), train_loss = 3.01369301, grad/param norm = 3.9765e-01, time/batch = 0.6910s	
270/30300 (epoch 0.446), train_loss = 2.95010382, grad/param norm = 3.7022e-01, time/batch = 0.7206s	
271/30300 (epoch 0.447), train_loss = 3.08182162, grad/param norm = 4.6393e-01, time/batch = 0.6966s	
272/30300 (epoch 0.449), train_loss = 3.10834662, grad/param norm = 6.8723e-01, time/batch = 0.6882s	
273/30300 (epoch 0.450), train_loss = 3.04144088, grad/param norm = 4.0482e-01, time/batch = 0.6856s	
274/30300 (epoch 0.452), train_loss = 3.02445331, grad/param norm = 5.9577e-01, time/batch = 0.6853s	
275/30300 (epoch 0.454), train_loss = 2.98465342, grad/param norm = 7.7643e-01, time/batch = 0.6880s	
276/30300 (epoch 0.455), train_loss = 3.19544185, grad/param norm = 1.1085e+00, time/batch = 0.6883s	
277/30300 (epoch 0.457), train_loss = 3.14106784, grad/param norm = 7.7808e-01, time/batch = 0.6859s	
278/30300 (epoch 0.459), train_loss = 3.02330452, grad/param norm = 7.3864e-01, time/batch = 0.6851s	
279/30300 (epoch 0.460), train_loss = 3.05252011, grad/param norm = 7.7344e-01, time/batch = 0.6840s	
280/30300 (epoch 0.462), train_loss = 3.07545068, grad/param norm = 4.5511e-01, time/batch = 0.6845s	
281/30300 (epoch 0.464), train_loss = 3.12088927, grad/param norm = 4.3010e-01, time/batch = 0.6879s	
282/30300 (epoch 0.465), train_loss = 2.97981680, grad/param norm = 3.2850e-01, time/batch = 0.6863s	
283/30300 (epoch 0.467), train_loss = 3.06436863, grad/param norm = 3.4686e-01, time/batch = 0.6869s	
284/30300 (epoch 0.469), train_loss = 2.93149327, grad/param norm = 2.9096e-01, time/batch = 0.6895s	
285/30300 (epoch 0.470), train_loss = 3.11944868, grad/param norm = 4.4131e-01, time/batch = 0.6874s	
286/30300 (epoch 0.472), train_loss = 2.97073801, grad/param norm = 5.6037e-01, time/batch = 0.6923s	
287/30300 (epoch 0.474), train_loss = 3.06186688, grad/param norm = 5.9126e-01, time/batch = 0.6877s	
288/30300 (epoch 0.475), train_loss = 3.05774672, grad/param norm = 6.8092e-01, time/batch = 0.6843s	
289/30300 (epoch 0.477), train_loss = 3.03187623, grad/param norm = 5.6702e-01, time/batch = 0.6835s	
290/30300 (epoch 0.479), train_loss = 3.08876124, grad/param norm = 4.3901e-01, time/batch = 0.6854s	
291/30300 (epoch 0.480), train_loss = 3.00022198, grad/param norm = 5.3130e-01, time/batch = 0.6969s	
292/30300 (epoch 0.482), train_loss = 3.07435620, grad/param norm = 5.0704e-01, time/batch = 0.6934s	
293/30300 (epoch 0.483), train_loss = 2.89747674, grad/param norm = 8.0742e-01, time/batch = 0.6918s	
294/30300 (epoch 0.485), train_loss = 3.11259661, grad/param norm = 9.7276e-01, time/batch = 0.6855s	
295/30300 (epoch 0.487), train_loss = 3.05157293, grad/param norm = 9.4682e-01, time/batch = 0.7013s	
296/30300 (epoch 0.488), train_loss = 2.91477042, grad/param norm = 6.2750e-01, time/batch = 0.6904s	
297/30300 (epoch 0.490), train_loss = 3.09680137, grad/param norm = 4.3722e-01, time/batch = 0.6876s	
298/30300 (epoch 0.492), train_loss = 3.02146083, grad/param norm = 4.1589e-01, time/batch = 0.6886s	
299/30300 (epoch 0.493), train_loss = 2.97256633, grad/param norm = 3.9679e-01, time/batch = 0.6860s	
300/30300 (epoch 0.495), train_loss = 2.90379884, grad/param norm = 4.2702e-01, time/batch = 0.6870s	
301/30300 (epoch 0.497), train_loss = 2.81332481, grad/param norm = 4.5213e-01, time/batch = 0.6894s	
302/30300 (epoch 0.498), train_loss = 3.06652892, grad/param norm = 4.6791e-01, time/batch = 0.6853s	
303/30300 (epoch 0.500), train_loss = 3.21381115, grad/param norm = 7.1751e-01, time/batch = 0.7156s	
304/30300 (epoch 0.502), train_loss = 3.02358454, grad/param norm = 1.1764e+00, time/batch = 0.7062s	
305/30300 (epoch 0.503), train_loss = 3.01040838, grad/param norm = 6.9661e-01, time/batch = 0.6895s	
306/30300 (epoch 0.505), train_loss = 2.99348112, grad/param norm = 4.6146e-01, time/batch = 0.6884s	
307/30300 (epoch 0.507), train_loss = 2.91445406, grad/param norm = 3.8039e-01, time/batch = 0.6846s	
308/30300 (epoch 0.508), train_loss = 3.01076872, grad/param norm = 3.0945e-01, time/batch = 0.6854s	
309/30300 (epoch 0.510), train_loss = 2.96107822, grad/param norm = 4.1154e-01, time/batch = 0.6848s	
310/30300 (epoch 0.512), train_loss = 2.88982672, grad/param norm = 4.4480e-01, time/batch = 0.6883s	
311/30300 (epoch 0.513), train_loss = 3.01791787, grad/param norm = 3.9489e-01, time/batch = 0.6865s	
312/30300 (epoch 0.515), train_loss = 2.92365187, grad/param norm = 4.7992e-01, time/batch = 0.6881s	
313/30300 (epoch 0.517), train_loss = 2.87939142, grad/param norm = 6.7530e-01, time/batch = 0.6915s	
314/30300 (epoch 0.518), train_loss = 3.05830838, grad/param norm = 1.3200e+00, time/batch = 0.6884s	
315/30300 (epoch 0.520), train_loss = 3.07860270, grad/param norm = 9.1669e-01, time/batch = 0.6891s	
316/30300 (epoch 0.521), train_loss = 2.96923805, grad/param norm = 7.3333e-01, time/batch = 0.6891s	
317/30300 (epoch 0.523), train_loss = 3.03669481, grad/param norm = 8.9342e-01, time/batch = 0.7029s	
318/30300 (epoch 0.525), train_loss = 3.05381363, grad/param norm = 6.9967e-01, time/batch = 0.7187s	
319/30300 (epoch 0.526), train_loss = 2.91300992, grad/param norm = 4.7653e-01, time/batch = 0.6824s	
320/30300 (epoch 0.528), train_loss = 2.91594655, grad/param norm = 3.4499e-01, time/batch = 0.6840s	
321/30300 (epoch 0.530), train_loss = 3.07426286, grad/param norm = 3.7032e-01, time/batch = 0.6870s	
322/30300 (epoch 0.531), train_loss = 2.94739936, grad/param norm = 4.4377e-01, time/batch = 0.6853s	
323/30300 (epoch 0.533), train_loss = 2.99841736, grad/param norm = 3.1480e-01, time/batch = 0.6846s	
324/30300 (epoch 0.535), train_loss = 2.85517621, grad/param norm = 3.5722e-01, time/batch = 0.6842s	
325/30300 (epoch 0.536), train_loss = 2.92742124, grad/param norm = 4.1248e-01, time/batch = 0.6833s	
326/30300 (epoch 0.538), train_loss = 2.83931635, grad/param norm = 5.1578e-01, time/batch = 0.6861s	
327/30300 (epoch 0.540), train_loss = 3.00561704, grad/param norm = 6.0022e-01, time/batch = 0.6848s	
328/30300 (epoch 0.541), train_loss = 2.88099231, grad/param norm = 5.7982e-01, time/batch = 0.6851s	
329/30300 (epoch 0.543), train_loss = 2.97648229, grad/param norm = 5.8321e-01, time/batch = 0.7058s	
330/30300 (epoch 0.545), train_loss = 2.95290158, grad/param norm = 6.0794e-01, time/batch = 0.6967s	
331/30300 (epoch 0.546), train_loss = 2.91147718, grad/param norm = 5.6004e-01, time/batch = 0.7023s	
332/30300 (epoch 0.548), train_loss = 2.79749940, grad/param norm = 5.5149e-01, time/batch = 0.7191s	
333/30300 (epoch 0.550), train_loss = 3.16881908, grad/param norm = 7.0016e-01, time/batch = 0.7161s	
334/30300 (epoch 0.551), train_loss = 3.00700098, grad/param norm = 8.0246e-01, time/batch = 0.6954s	
335/30300 (epoch 0.553), train_loss = 2.95438124, grad/param norm = 7.4129e-01, time/batch = 0.6987s	
336/30300 (epoch 0.554), train_loss = 2.96604969, grad/param norm = 4.9768e-01, time/batch = 0.6936s	
337/30300 (epoch 0.556), train_loss = 2.90437139, grad/param norm = 3.8396e-01, time/batch = 0.6922s	
338/30300 (epoch 0.558), train_loss = 2.89670406, grad/param norm = 4.1185e-01, time/batch = 0.6982s	
339/30300 (epoch 0.559), train_loss = 2.90808926, grad/param norm = 4.7293e-01, time/batch = 0.7168s	
340/30300 (epoch 0.561), train_loss = 2.92447779, grad/param norm = 6.5725e-01, time/batch = 0.6966s	
341/30300 (epoch 0.563), train_loss = 2.98261385, grad/param norm = 6.7869e-01, time/batch = 0.6990s	
342/30300 (epoch 0.564), train_loss = 2.89772300, grad/param norm = 3.7393e-01, time/batch = 0.7044s	
343/30300 (epoch 0.566), train_loss = 2.93809124, grad/param norm = 3.3993e-01, time/batch = 0.7024s	
344/30300 (epoch 0.568), train_loss = 2.81610217, grad/param norm = 4.7805e-01, time/batch = 0.7045s	
345/30300 (epoch 0.569), train_loss = 2.87022808, grad/param norm = 6.2870e-01, time/batch = 0.6888s	
346/30300 (epoch 0.571), train_loss = 2.94943866, grad/param norm = 7.8759e-01, time/batch = 0.7163s	
347/30300 (epoch 0.573), train_loss = 2.86220125, grad/param norm = 6.0624e-01, time/batch = 0.7125s	
348/30300 (epoch 0.574), train_loss = 2.94658382, grad/param norm = 4.0863e-01, time/batch = 0.6920s	
349/30300 (epoch 0.576), train_loss = 2.97285467, grad/param norm = 4.1601e-01, time/batch = 0.6880s	
350/30300 (epoch 0.578), train_loss = 2.87317114, grad/param norm = 3.8085e-01, time/batch = 0.6981s	
351/30300 (epoch 0.579), train_loss = 2.79011510, grad/param norm = 4.4463e-01, time/batch = 0.6904s	
352/30300 (epoch 0.581), train_loss = 3.08210276, grad/param norm = 7.3547e-01, time/batch = 0.6884s	
353/30300 (epoch 0.583), train_loss = 2.96309479, grad/param norm = 7.2666e-01, time/batch = 0.6899s	
354/30300 (epoch 0.584), train_loss = 2.85409396, grad/param norm = 3.6987e-01, time/batch = 0.6896s	
355/30300 (epoch 0.586), train_loss = 2.87704847, grad/param norm = 4.6288e-01, time/batch = 0.6910s	
356/30300 (epoch 0.587), train_loss = 2.79077950, grad/param norm = 6.2687e-01, time/batch = 0.6929s	
357/30300 (epoch 0.589), train_loss = 2.74316675, grad/param norm = 5.3253e-01, time/batch = 0.6899s	
358/30300 (epoch 0.591), train_loss = 2.80219747, grad/param norm = 3.3196e-01, time/batch = 0.7005s	
359/30300 (epoch 0.592), train_loss = 2.83409165, grad/param norm = 5.0717e-01, time/batch = 0.7000s	
360/30300 (epoch 0.594), train_loss = 2.81222725, grad/param norm = 6.5364e-01, time/batch = 0.7141s	
361/30300 (epoch 0.596), train_loss = 2.76816219, grad/param norm = 6.8695e-01, time/batch = 0.7223s	
362/30300 (epoch 0.597), train_loss = 2.82287636, grad/param norm = 5.8119e-01, time/batch = 0.7100s	
363/30300 (epoch 0.599), train_loss = 2.81957370, grad/param norm = 7.2813e-01, time/batch = 0.7066s	
364/30300 (epoch 0.601), train_loss = 2.81451038, grad/param norm = 8.1130e-01, time/batch = 0.6979s	
365/30300 (epoch 0.602), train_loss = 2.77020039, grad/param norm = 6.5892e-01, time/batch = 0.6995s	
366/30300 (epoch 0.604), train_loss = 2.91217133, grad/param norm = 6.8082e-01, time/batch = 0.7047s	
367/30300 (epoch 0.606), train_loss = 3.28212252, grad/param norm = 7.3318e-01, time/batch = 0.7007s	
368/30300 (epoch 0.607), train_loss = 2.96824427, grad/param norm = 6.9746e-01, time/batch = 0.6899s	
369/30300 (epoch 0.609), train_loss = 2.90270313, grad/param norm = 3.7265e-01, time/batch = 0.6932s	
370/30300 (epoch 0.611), train_loss = 2.70595889, grad/param norm = 4.2178e-01, time/batch = 0.6927s	
371/30300 (epoch 0.612), train_loss = 2.84167041, grad/param norm = 2.7613e-01, time/batch = 0.6903s	
372/30300 (epoch 0.614), train_loss = 2.71901108, grad/param norm = 3.3591e-01, time/batch = 0.6942s	
373/30300 (epoch 0.616), train_loss = 2.88784538, grad/param norm = 3.2068e-01, time/batch = 0.7007s	
374/30300 (epoch 0.617), train_loss = 2.81603036, grad/param norm = 4.1376e-01, time/batch = 0.7053s	
375/30300 (epoch 0.619), train_loss = 2.66809720, grad/param norm = 5.7423e-01, time/batch = 0.7206s	
376/30300 (epoch 0.620), train_loss = 2.93178016, grad/param norm = 9.7505e-01, time/batch = 0.6905s	
377/30300 (epoch 0.622), train_loss = 2.84449666, grad/param norm = 8.8585e-01, time/batch = 0.6936s	
378/30300 (epoch 0.624), train_loss = 2.82914527, grad/param norm = 4.4894e-01, time/batch = 0.6981s	
379/30300 (epoch 0.625), train_loss = 2.79401065, grad/param norm = 4.0864e-01, time/batch = 0.6924s	
380/30300 (epoch 0.627), train_loss = 2.82909936, grad/param norm = 2.9388e-01, time/batch = 0.6932s	
381/30300 (epoch 0.629), train_loss = 2.84124688, grad/param norm = 3.4059e-01, time/batch = 0.6938s	
382/30300 (epoch 0.630), train_loss = 2.80616866, grad/param norm = 4.8152e-01, time/batch = 0.6876s	
383/30300 (epoch 0.632), train_loss = 2.86704735, grad/param norm = 7.6436e-01, time/batch = 0.6929s	
384/30300 (epoch 0.634), train_loss = 2.72141382, grad/param norm = 6.6701e-01, time/batch = 0.6902s	
385/30300 (epoch 0.635), train_loss = 2.82624494, grad/param norm = 7.5581e-01, time/batch = 0.6925s	
386/30300 (epoch 0.637), train_loss = 2.87690759, grad/param norm = 7.3656e-01, time/batch = 0.6907s	
387/30300 (epoch 0.639), train_loss = 2.68048655, grad/param norm = 6.7179e-01, time/batch = 0.6903s	
388/30300 (epoch 0.640), train_loss = 2.84299429, grad/param norm = 6.4876e-01, time/batch = 0.6882s	
389/30300 (epoch 0.642), train_loss = 2.79720036, grad/param norm = 4.5605e-01, time/batch = 0.7203s	
390/30300 (epoch 0.644), train_loss = 2.78644135, grad/param norm = 3.9141e-01, time/batch = 0.7028s	
391/30300 (epoch 0.645), train_loss = 2.68108225, grad/param norm = 4.3511e-01, time/batch = 0.6907s	
392/30300 (epoch 0.647), train_loss = 2.76904103, grad/param norm = 4.8594e-01, time/batch = 0.6950s	
393/30300 (epoch 0.649), train_loss = 2.80632556, grad/param norm = 5.1373e-01, time/batch = 0.6882s	
394/30300 (epoch 0.650), train_loss = 2.72692239, grad/param norm = 3.9049e-01, time/batch = 0.6902s	
395/30300 (epoch 0.652), train_loss = 2.67285815, grad/param norm = 3.9655e-01, time/batch = 0.6937s	
396/30300 (epoch 0.653), train_loss = 2.87647045, grad/param norm = 5.3404e-01, time/batch = 0.6941s	
397/30300 (epoch 0.655), train_loss = 2.81556309, grad/param norm = 3.8558e-01, time/batch = 0.6876s	
398/30300 (epoch 0.657), train_loss = 2.85489811, grad/param norm = 2.9600e-01, time/batch = 0.6933s	
399/30300 (epoch 0.658), train_loss = 2.74799661, grad/param norm = 2.9103e-01, time/batch = 0.6926s	
400/30300 (epoch 0.660), train_loss = 2.74053329, grad/param norm = 4.1061e-01, time/batch = 0.6878s	
401/30300 (epoch 0.662), train_loss = 2.79395336, grad/param norm = 6.0641e-01, time/batch = 0.6932s	
402/30300 (epoch 0.663), train_loss = 2.79589771, grad/param norm = 6.7708e-01, time/batch = 0.6944s	
403/30300 (epoch 0.665), train_loss = 2.76234046, grad/param norm = 7.8626e-01, time/batch = 0.6959s	
404/30300 (epoch 0.667), train_loss = 2.82914256, grad/param norm = 7.6176e-01, time/batch = 0.6865s	
405/30300 (epoch 0.668), train_loss = 2.83750591, grad/param norm = 5.6454e-01, time/batch = 0.6902s	
406/30300 (epoch 0.670), train_loss = 2.75383263, grad/param norm = 3.4500e-01, time/batch = 0.6923s	
407/30300 (epoch 0.672), train_loss = 2.84650367, grad/param norm = 3.0110e-01, time/batch = 0.6917s	
408/30300 (epoch 0.673), train_loss = 2.74398622, grad/param norm = 3.0673e-01, time/batch = 0.6892s	
409/30300 (epoch 0.675), train_loss = 2.70384597, grad/param norm = 3.4149e-01, time/batch = 0.6947s	
410/30300 (epoch 0.677), train_loss = 2.70851345, grad/param norm = 3.9998e-01, time/batch = 0.6931s	
411/30300 (epoch 0.678), train_loss = 2.73143768, grad/param norm = 3.6427e-01, time/batch = 0.6905s	
412/30300 (epoch 0.680), train_loss = 2.62009672, grad/param norm = 3.9855e-01, time/batch = 0.6908s	
413/30300 (epoch 0.682), train_loss = 2.66135760, grad/param norm = 3.7249e-01, time/batch = 0.6933s	
414/30300 (epoch 0.683), train_loss = 2.74980344, grad/param norm = 4.5960e-01, time/batch = 0.6910s	
415/30300 (epoch 0.685), train_loss = 2.87432319, grad/param norm = 4.9442e-01, time/batch = 0.7110s	
416/30300 (epoch 0.686), train_loss = 2.73356380, grad/param norm = 4.3693e-01, time/batch = 0.7115s	
417/30300 (epoch 0.688), train_loss = 2.77048789, grad/param norm = 4.6582e-01, time/batch = 0.6989s	
418/30300 (epoch 0.690), train_loss = 2.66051256, grad/param norm = 5.3029e-01, time/batch = 0.7049s	
419/30300 (epoch 0.691), train_loss = 2.74405131, grad/param norm = 8.3494e-01, time/batch = 0.7049s	
420/30300 (epoch 0.693), train_loss = 2.81847037, grad/param norm = 7.9449e-01, time/batch = 0.6959s	
421/30300 (epoch 0.695), train_loss = 2.85936609, grad/param norm = 6.3468e-01, time/batch = 0.7082s	
422/30300 (epoch 0.696), train_loss = 2.81582737, grad/param norm = 4.7165e-01, time/batch = 0.7350s	
423/30300 (epoch 0.698), train_loss = 2.76116278, grad/param norm = 3.0747e-01, time/batch = 0.6978s	
424/30300 (epoch 0.700), train_loss = 2.61042637, grad/param norm = 3.8089e-01, time/batch = 0.7037s	
425/30300 (epoch 0.701), train_loss = 2.55879553, grad/param norm = 3.6995e-01, time/batch = 0.6925s	
426/30300 (epoch 0.703), train_loss = 2.58395258, grad/param norm = 2.9923e-01, time/batch = 0.6967s	
427/30300 (epoch 0.705), train_loss = 2.74788333, grad/param norm = 4.0449e-01, time/batch = 0.6978s	
428/30300 (epoch 0.706), train_loss = 2.62979255, grad/param norm = 5.0310e-01, time/batch = 0.7098s	
429/30300 (epoch 0.708), train_loss = 2.67677327, grad/param norm = 5.2562e-01, time/batch = 0.7094s	
430/30300 (epoch 0.710), train_loss = 2.65613517, grad/param norm = 3.7874e-01, time/batch = 0.6938s	
431/30300 (epoch 0.711), train_loss = 2.57609979, grad/param norm = 3.5284e-01, time/batch = 0.6978s	
432/30300 (epoch 0.713), train_loss = 2.61364720, grad/param norm = 3.5302e-01, time/batch = 0.7267s	
433/30300 (epoch 0.715), train_loss = 2.66093284, grad/param norm = 4.1612e-01, time/batch = 0.7103s	
434/30300 (epoch 0.716), train_loss = 2.81195874, grad/param norm = 5.2545e-01, time/batch = 0.6930s	
435/30300 (epoch 0.718), train_loss = 2.75777091, grad/param norm = 5.1527e-01, time/batch = 0.6911s	
436/30300 (epoch 0.719), train_loss = 2.67399877, grad/param norm = 5.5270e-01, time/batch = 0.7035s	
437/30300 (epoch 0.721), train_loss = 2.76896017, grad/param norm = 3.9811e-01, time/batch = 0.6871s	
438/30300 (epoch 0.723), train_loss = 2.60336092, grad/param norm = 3.0089e-01, time/batch = 0.6845s	
439/30300 (epoch 0.724), train_loss = 2.75887620, grad/param norm = 5.3182e-01, time/batch = 0.6885s	
440/30300 (epoch 0.726), train_loss = 3.00731301, grad/param norm = 7.8779e-01, time/batch = 0.6862s	
441/30300 (epoch 0.728), train_loss = 2.57602775, grad/param norm = 4.2070e-01, time/batch = 0.6923s	
442/30300 (epoch 0.729), train_loss = 2.83892731, grad/param norm = 6.2014e-01, time/batch = 0.6953s	
443/30300 (epoch 0.731), train_loss = 2.72116213, grad/param norm = 5.6064e-01, time/batch = 0.6896s	
444/30300 (epoch 0.733), train_loss = 2.63133214, grad/param norm = 3.6860e-01, time/batch = 0.6899s	
445/30300 (epoch 0.734), train_loss = 2.67984944, grad/param norm = 3.5029e-01, time/batch = 0.7104s	
446/30300 (epoch 0.736), train_loss = 2.62590303, grad/param norm = 5.0593e-01, time/batch = 0.7053s	
447/30300 (epoch 0.738), train_loss = 2.49687105, grad/param norm = 4.9395e-01, time/batch = 0.6909s	
448/30300 (epoch 0.739), train_loss = 2.67773080, grad/param norm = 4.4121e-01, time/batch = 0.6922s	
449/30300 (epoch 0.741), train_loss = 2.70493159, grad/param norm = 4.7990e-01, time/batch = 0.6889s	
450/30300 (epoch 0.743), train_loss = 2.55671786, grad/param norm = 4.5892e-01, time/batch = 0.7035s	
451/30300 (epoch 0.744), train_loss = 2.71890572, grad/param norm = 5.1096e-01, time/batch = 0.7168s	
452/30300 (epoch 0.746), train_loss = 2.52790399, grad/param norm = 3.1538e-01, time/batch = 0.6871s	
453/30300 (epoch 0.748), train_loss = 2.65920944, grad/param norm = 3.7196e-01, time/batch = 0.6920s	
454/30300 (epoch 0.749), train_loss = 2.59837957, grad/param norm = 3.6714e-01, time/batch = 0.6876s	
455/30300 (epoch 0.751), train_loss = 2.63684462, grad/param norm = 3.8926e-01, time/batch = 0.6871s	
456/30300 (epoch 0.752), train_loss = 2.60978423, grad/param norm = 3.6399e-01, time/batch = 0.6895s	
457/30300 (epoch 0.754), train_loss = 2.61973071, grad/param norm = 3.5176e-01, time/batch = 0.6879s	
458/30300 (epoch 0.756), train_loss = 2.53820439, grad/param norm = 2.7951e-01, time/batch = 0.6844s	
459/30300 (epoch 0.757), train_loss = 2.76974440, grad/param norm = 4.4642e-01, time/batch = 0.6887s	
460/30300 (epoch 0.759), train_loss = 2.53447920, grad/param norm = 5.8645e-01, time/batch = 0.6972s	
461/30300 (epoch 0.761), train_loss = 2.57145252, grad/param norm = 5.4170e-01, time/batch = 0.6855s	
462/30300 (epoch 0.762), train_loss = 2.57811577, grad/param norm = 5.0072e-01, time/batch = 0.6877s	
463/30300 (epoch 0.764), train_loss = 2.65824714, grad/param norm = 5.0509e-01, time/batch = 0.6987s	
464/30300 (epoch 0.766), train_loss = 2.68938387, grad/param norm = 4.1078e-01, time/batch = 0.6898s	
465/30300 (epoch 0.767), train_loss = 2.74504934, grad/param norm = 3.3311e-01, time/batch = 0.7207s	
466/30300 (epoch 0.769), train_loss = 2.74617267, grad/param norm = 3.6347e-01, time/batch = 0.6957s	
467/30300 (epoch 0.771), train_loss = 2.66241596, grad/param norm = 3.3661e-01, time/batch = 0.6896s	
468/30300 (epoch 0.772), train_loss = 2.59493495, grad/param norm = 3.5985e-01, time/batch = 0.6877s	
469/30300 (epoch 0.774), train_loss = 2.64334303, grad/param norm = 3.2156e-01, time/batch = 0.6941s	
470/30300 (epoch 0.776), train_loss = 2.52226790, grad/param norm = 3.5924e-01, time/batch = 0.6921s	
471/30300 (epoch 0.777), train_loss = 2.62862722, grad/param norm = 4.2010e-01, time/batch = 0.6865s	
472/30300 (epoch 0.779), train_loss = 2.70579482, grad/param norm = 5.4948e-01, time/batch = 0.6922s	
473/30300 (epoch 0.781), train_loss = 2.64512026, grad/param norm = 7.2231e-01, time/batch = 0.6891s	
474/30300 (epoch 0.782), train_loss = 2.64873427, grad/param norm = 8.6756e-01, time/batch = 0.6869s	
475/30300 (epoch 0.784), train_loss = 2.81733379, grad/param norm = 5.7529e-01, time/batch = 0.6902s	
476/30300 (epoch 0.785), train_loss = 2.82146536, grad/param norm = 3.8933e-01, time/batch = 0.6906s	
477/30300 (epoch 0.787), train_loss = 2.65185596, grad/param norm = 3.4628e-01, time/batch = 0.6925s	
478/30300 (epoch 0.789), train_loss = 2.92314448, grad/param norm = 4.9571e-01, time/batch = 0.6928s	
479/30300 (epoch 0.790), train_loss = 2.76463444, grad/param norm = 4.3509e-01, time/batch = 0.7148s	
480/30300 (epoch 0.792), train_loss = 2.63444051, grad/param norm = 3.7148e-01, time/batch = 0.7119s	
481/30300 (epoch 0.794), train_loss = 2.63541202, grad/param norm = 3.7988e-01, time/batch = 0.6908s	
482/30300 (epoch 0.795), train_loss = 2.68346445, grad/param norm = 3.4166e-01, time/batch = 0.6910s	
483/30300 (epoch 0.797), train_loss = 2.64176467, grad/param norm = 2.7638e-01, time/batch = 0.6882s	
484/30300 (epoch 0.799), train_loss = 2.74195903, grad/param norm = 4.0588e-01, time/batch = 0.6920s	
485/30300 (epoch 0.800), train_loss = 2.54998103, grad/param norm = 3.7089e-01, time/batch = 0.6917s	
486/30300 (epoch 0.802), train_loss = 2.64169254, grad/param norm = 4.0282e-01, time/batch = 0.6894s	
487/30300 (epoch 0.804), train_loss = 2.72054625, grad/param norm = 3.9887e-01, time/batch = 0.6883s	
488/30300 (epoch 0.805), train_loss = 2.65219711, grad/param norm = 5.2523e-01, time/batch = 0.6868s	
489/30300 (epoch 0.807), train_loss = 2.68570191, grad/param norm = 5.4781e-01, time/batch = 0.7038s	
490/30300 (epoch 0.809), train_loss = 2.71931882, grad/param norm = 4.4910e-01, time/batch = 0.6963s	
491/30300 (epoch 0.810), train_loss = 2.67481603, grad/param norm = 3.6832e-01, time/batch = 0.6962s	
492/30300 (epoch 0.812), train_loss = 2.66120058, grad/param norm = 3.3002e-01, time/batch = 0.6950s	
493/30300 (epoch 0.814), train_loss = 2.70165571, grad/param norm = 3.4039e-01, time/batch = 0.7043s	
494/30300 (epoch 0.815), train_loss = 2.68010720, grad/param norm = 5.0642e-01, time/batch = 0.7193s	
495/30300 (epoch 0.817), train_loss = 2.64846076, grad/param norm = 5.9853e-01, time/batch = 0.7017s	
496/30300 (epoch 0.818), train_loss = 2.60075867, grad/param norm = 3.9554e-01, time/batch = 0.6962s	
497/30300 (epoch 0.820), train_loss = 2.77073235, grad/param norm = 3.8983e-01, time/batch = 0.6939s	
498/30300 (epoch 0.822), train_loss = 2.76288615, grad/param norm = 3.5322e-01, time/batch = 0.6963s	
499/30300 (epoch 0.823), train_loss = 2.81670276, grad/param norm = 4.7999e-01, time/batch = 0.6938s	
500/30300 (epoch 0.825), train_loss = 2.64843967, grad/param norm = 4.2960e-01, time/batch = 0.6962s	
501/30300 (epoch 0.827), train_loss = 2.61382261, grad/param norm = 3.1358e-01, time/batch = 0.7091s	
502/30300 (epoch 0.828), train_loss = 2.60847418, grad/param norm = 2.3539e-01, time/batch = 0.6980s	
503/30300 (epoch 0.830), train_loss = 2.56652990, grad/param norm = 2.7482e-01, time/batch = 0.6984s	
504/30300 (epoch 0.832), train_loss = 2.45779310, grad/param norm = 3.5339e-01, time/batch = 0.6976s	
505/30300 (epoch 0.833), train_loss = 2.65085911, grad/param norm = 3.4622e-01, time/batch = 0.6934s	
506/30300 (epoch 0.835), train_loss = 2.62229035, grad/param norm = 2.9061e-01, time/batch = 0.6953s	
507/30300 (epoch 0.837), train_loss = 2.45085977, grad/param norm = 3.2394e-01, time/batch = 0.7064s	
508/30300 (epoch 0.838), train_loss = 2.57775722, grad/param norm = 3.3734e-01, time/batch = 0.7217s	
509/30300 (epoch 0.840), train_loss = 2.59663534, grad/param norm = 5.3655e-01, time/batch = 0.6988s	
510/30300 (epoch 0.842), train_loss = 2.54695739, grad/param norm = 5.2756e-01, time/batch = 0.6939s	
511/30300 (epoch 0.843), train_loss = 2.56802930, grad/param norm = 3.8749e-01, time/batch = 0.6902s	
512/30300 (epoch 0.845), train_loss = 2.51574921, grad/param norm = 4.2322e-01, time/batch = 0.6870s	
513/30300 (epoch 0.847), train_loss = 2.58657883, grad/param norm = 4.3409e-01, time/batch = 0.7002s	
514/30300 (epoch 0.848), train_loss = 2.68311863, grad/param norm = 5.9081e-01, time/batch = 0.6951s	
515/30300 (epoch 0.850), train_loss = 2.61258203, grad/param norm = 7.3091e-01, time/batch = 0.7025s	
516/30300 (epoch 0.851), train_loss = 2.74484297, grad/param norm = 5.8729e-01, time/batch = 0.7035s	
517/30300 (epoch 0.853), train_loss = 2.58814476, grad/param norm = 3.8595e-01, time/batch = 0.6933s	
518/30300 (epoch 0.855), train_loss = 2.56740892, grad/param norm = 3.8878e-01, time/batch = 0.6912s	
519/30300 (epoch 0.856), train_loss = 2.54740960, grad/param norm = 3.8380e-01, time/batch = 0.6906s	
520/30300 (epoch 0.858), train_loss = 2.48498171, grad/param norm = 3.1480e-01, time/batch = 0.6901s	
521/30300 (epoch 0.860), train_loss = 2.58263841, grad/param norm = 3.4717e-01, time/batch = 0.6985s	
522/30300 (epoch 0.861), train_loss = 2.60751009, grad/param norm = 5.6659e-01, time/batch = 0.7213s	
523/30300 (epoch 0.863), train_loss = 2.67556939, grad/param norm = 5.2144e-01, time/batch = 0.7040s	
524/30300 (epoch 0.865), train_loss = 2.83182444, grad/param norm = 3.8273e-01, time/batch = 0.6911s	
525/30300 (epoch 0.866), train_loss = 2.54800741, grad/param norm = 3.2690e-01, time/batch = 0.6899s	
526/30300 (epoch 0.868), train_loss = 2.64571574, grad/param norm = 3.8574e-01, time/batch = 0.6902s	
527/30300 (epoch 0.870), train_loss = 2.55369921, grad/param norm = 4.1160e-01, time/batch = 0.6896s	
528/30300 (epoch 0.871), train_loss = 2.47356125, grad/param norm = 2.7186e-01, time/batch = 0.6920s	
529/30300 (epoch 0.873), train_loss = 2.68914198, grad/param norm = 3.4659e-01, time/batch = 0.6901s	
530/30300 (epoch 0.875), train_loss = 2.57361933, grad/param norm = 3.4697e-01, time/batch = 0.6902s	
531/30300 (epoch 0.876), train_loss = 2.47646285, grad/param norm = 3.3454e-01, time/batch = 0.6911s	
532/30300 (epoch 0.878), train_loss = 2.54391526, grad/param norm = 3.3700e-01, time/batch = 0.6893s	
533/30300 (epoch 0.880), train_loss = 2.44991112, grad/param norm = 3.3155e-01, time/batch = 0.6931s	
534/30300 (epoch 0.881), train_loss = 2.62892539, grad/param norm = 3.0918e-01, time/batch = 0.6896s	
535/30300 (epoch 0.883), train_loss = 2.54314509, grad/param norm = 3.6931e-01, time/batch = 0.6898s	
536/30300 (epoch 0.884), train_loss = 2.50738140, grad/param norm = 4.4543e-01, time/batch = 0.7080s	
537/30300 (epoch 0.886), train_loss = 2.53898312, grad/param norm = 4.1038e-01, time/batch = 0.7152s	
538/30300 (epoch 0.888), train_loss = 2.68382396, grad/param norm = 3.7888e-01, time/batch = 0.7112s	
539/30300 (epoch 0.889), train_loss = 2.55859321, grad/param norm = 4.4729e-01, time/batch = 0.7166s	
540/30300 (epoch 0.891), train_loss = 2.57411129, grad/param norm = 4.9996e-01, time/batch = 0.7194s	
541/30300 (epoch 0.893), train_loss = 2.59178023, grad/param norm = 4.9030e-01, time/batch = 0.6972s	
542/30300 (epoch 0.894), train_loss = 2.59663075, grad/param norm = 5.0856e-01, time/batch = 0.7176s	
543/30300 (epoch 0.896), train_loss = 2.50460346, grad/param norm = 4.1271e-01, time/batch = 0.7152s	
544/30300 (epoch 0.898), train_loss = 2.44005313, grad/param norm = 3.1503e-01, time/batch = 0.7137s	
545/30300 (epoch 0.899), train_loss = 2.57190807, grad/param norm = 3.7707e-01, time/batch = 0.6968s	
546/30300 (epoch 0.901), train_loss = 2.67917988, grad/param norm = 4.5165e-01, time/batch = 0.7152s	
547/30300 (epoch 0.903), train_loss = 2.63331093, grad/param norm = 4.4079e-01, time/batch = 0.7073s	
548/30300 (epoch 0.904), train_loss = 2.53138114, grad/param norm = 2.9892e-01, time/batch = 0.6929s	
549/30300 (epoch 0.906), train_loss = 2.66677714, grad/param norm = 3.2942e-01, time/batch = 0.7000s	
550/30300 (epoch 0.908), train_loss = 2.61508448, grad/param norm = 3.3944e-01, time/batch = 0.6925s	
551/30300 (epoch 0.909), train_loss = 2.75758440, grad/param norm = 3.5749e-01, time/batch = 0.6875s	
552/30300 (epoch 0.911), train_loss = 2.50826004, grad/param norm = 3.5481e-01, time/batch = 0.6967s	
553/30300 (epoch 0.913), train_loss = 2.55717725, grad/param norm = 3.7258e-01, time/batch = 0.6928s	
554/30300 (epoch 0.914), train_loss = 2.65315695, grad/param norm = 3.9944e-01, time/batch = 0.6896s	
555/30300 (epoch 0.916), train_loss = 2.53158208, grad/param norm = 4.7004e-01, time/batch = 0.6919s	
556/30300 (epoch 0.917), train_loss = 2.47072235, grad/param norm = 4.8020e-01, time/batch = 0.6932s	
557/30300 (epoch 0.919), train_loss = 2.61089242, grad/param norm = 4.4536e-01, time/batch = 0.6941s	
558/30300 (epoch 0.921), train_loss = 2.64481201, grad/param norm = 3.4974e-01, time/batch = 0.6936s	
559/30300 (epoch 0.922), train_loss = 2.59913089, grad/param norm = 2.7000e-01, time/batch = 0.6925s	
560/30300 (epoch 0.924), train_loss = 2.49397716, grad/param norm = 3.4855e-01, time/batch = 0.6929s	
561/30300 (epoch 0.926), train_loss = 2.51116525, grad/param norm = 4.5777e-01, time/batch = 0.6896s	
562/30300 (epoch 0.927), train_loss = 2.45143821, grad/param norm = 4.5444e-01, time/batch = 0.6979s	
563/30300 (epoch 0.929), train_loss = 2.61206059, grad/param norm = 5.8065e-01, time/batch = 0.6901s	
564/30300 (epoch 0.931), train_loss = 2.66586727, grad/param norm = 5.0312e-01, time/batch = 0.6903s	
565/30300 (epoch 0.932), train_loss = 2.52299452, grad/param norm = 2.8448e-01, time/batch = 0.6910s	
566/30300 (epoch 0.934), train_loss = 2.52804647, grad/param norm = 3.0936e-01, time/batch = 0.6936s	
567/30300 (epoch 0.936), train_loss = 2.50556869, grad/param norm = 3.2301e-01, time/batch = 0.6930s	
568/30300 (epoch 0.937), train_loss = 2.55744949, grad/param norm = 3.9688e-01, time/batch = 0.6893s	
569/30300 (epoch 0.939), train_loss = 2.58096317, grad/param norm = 3.9568e-01, time/batch = 0.6871s	
570/30300 (epoch 0.941), train_loss = 2.57974146, grad/param norm = 4.2084e-01, time/batch = 0.6905s	
571/30300 (epoch 0.942), train_loss = 2.46885870, grad/param norm = 3.6652e-01, time/batch = 0.6887s	
572/30300 (epoch 0.944), train_loss = 2.50339527, grad/param norm = 3.7433e-01, time/batch = 0.6883s	
573/30300 (epoch 0.946), train_loss = 2.72668031, grad/param norm = 3.6133e-01, time/batch = 0.6892s	
574/30300 (epoch 0.947), train_loss = 2.66851802, grad/param norm = 4.6121e-01, time/batch = 0.6921s	
575/30300 (epoch 0.949), train_loss = 2.71481406, grad/param norm = 4.0731e-01, time/batch = 0.6935s	
576/30300 (epoch 0.950), train_loss = 2.66617994, grad/param norm = 3.3776e-01, time/batch = 0.6877s	
577/30300 (epoch 0.952), train_loss = 2.64232859, grad/param norm = 3.1201e-01, time/batch = 0.6880s	
578/30300 (epoch 0.954), train_loss = 2.58131485, grad/param norm = 3.6144e-01, time/batch = 0.6911s	
579/30300 (epoch 0.955), train_loss = 2.54462723, grad/param norm = 2.9066e-01, time/batch = 0.6902s	
580/30300 (epoch 0.957), train_loss = 2.62546319, grad/param norm = 3.6383e-01, time/batch = 0.6864s	
581/30300 (epoch 0.959), train_loss = 2.67547196, grad/param norm = 3.4367e-01, time/batch = 0.6901s	
582/30300 (epoch 0.960), train_loss = 2.52143205, grad/param norm = 2.9009e-01, time/batch = 0.6933s	
583/30300 (epoch 0.962), train_loss = 2.53272194, grad/param norm = 2.8100e-01, time/batch = 0.6908s	
584/30300 (epoch 0.964), train_loss = 2.61623432, grad/param norm = 3.3066e-01, time/batch = 0.6870s	
585/30300 (epoch 0.965), train_loss = 2.52486065, grad/param norm = 3.5612e-01, time/batch = 0.6934s	
586/30300 (epoch 0.967), train_loss = 2.53471954, grad/param norm = 3.4399e-01, time/batch = 0.6937s	
587/30300 (epoch 0.969), train_loss = 2.47398771, grad/param norm = 4.2837e-01, time/batch = 0.7109s	
588/30300 (epoch 0.970), train_loss = 2.51675474, grad/param norm = 4.8354e-01, time/batch = 0.7020s	
589/30300 (epoch 0.972), train_loss = 2.49098766, grad/param norm = 4.3558e-01, time/batch = 0.7111s	
590/30300 (epoch 0.974), train_loss = 2.63594071, grad/param norm = 3.7873e-01, time/batch = 0.7129s	
591/30300 (epoch 0.975), train_loss = 2.53914311, grad/param norm = 2.8916e-01, time/batch = 0.6971s	
592/30300 (epoch 0.977), train_loss = 2.45638911, grad/param norm = 2.8324e-01, time/batch = 0.6938s	
593/30300 (epoch 0.979), train_loss = 2.62692868, grad/param norm = 2.8088e-01, time/batch = 0.7062s	
594/30300 (epoch 0.980), train_loss = 2.60308173, grad/param norm = 3.0853e-01, time/batch = 0.6956s	
595/30300 (epoch 0.982), train_loss = 2.60946509, grad/param norm = 3.2688e-01, time/batch = 0.6973s	
596/30300 (epoch 0.983), train_loss = 2.63484213, grad/param norm = 5.1067e-01, time/batch = 0.6961s	
597/30300 (epoch 0.985), train_loss = 2.66471870, grad/param norm = 5.5819e-01, time/batch = 0.6914s	
598/30300 (epoch 0.987), train_loss = 2.47468012, grad/param norm = 3.9226e-01, time/batch = 0.6942s	
599/30300 (epoch 0.988), train_loss = 2.66744690, grad/param norm = 3.3695e-01, time/batch = 0.7037s	
600/30300 (epoch 0.990), train_loss = 2.35793341, grad/param norm = 2.5290e-01, time/batch = 0.6917s	
601/30300 (epoch 0.992), train_loss = 2.44166913, grad/param norm = 2.6232e-01, time/batch = 0.6886s	
602/30300 (epoch 0.993), train_loss = 2.68523800, grad/param norm = 3.8205e-01, time/batch = 0.6937s	
603/30300 (epoch 0.995), train_loss = 2.64787047, grad/param norm = 3.0610e-01, time/batch = 0.7049s	
604/30300 (epoch 0.997), train_loss = 2.47850012, grad/param norm = 2.4620e-01, time/batch = 0.7197s	
605/30300 (epoch 0.998), train_loss = 2.46485494, grad/param norm = 3.0153e-01, time/batch = 0.6908s	
606/30300 (epoch 1.000), train_loss = 2.40497656, grad/param norm = 3.6170e-01, time/batch = 0.6958s	
607/30300 (epoch 1.002), train_loss = 2.42951990, grad/param norm = 3.5028e-01, time/batch = 0.6944s	
608/30300 (epoch 1.003), train_loss = 2.57160835, grad/param norm = 2.7387e-01, time/batch = 0.6930s	
609/30300 (epoch 1.005), train_loss = 2.59894682, grad/param norm = 3.4173e-01, time/batch = 0.6936s	
610/30300 (epoch 1.007), train_loss = 2.57307908, grad/param norm = 4.3720e-01, time/batch = 0.6943s	
611/30300 (epoch 1.008), train_loss = 2.53210156, grad/param norm = 4.6204e-01, time/batch = 0.6885s	
612/30300 (epoch 1.010), train_loss = 2.51508095, grad/param norm = 3.9547e-01, time/batch = 0.6885s	
613/30300 (epoch 1.012), train_loss = 2.45911701, grad/param norm = 3.0746e-01, time/batch = 0.6926s	
614/30300 (epoch 1.013), train_loss = 2.56034986, grad/param norm = 3.1543e-01, time/batch = 0.6896s	
615/30300 (epoch 1.015), train_loss = 2.60969637, grad/param norm = 3.0520e-01, time/batch = 0.6971s	
616/30300 (epoch 1.017), train_loss = 2.42568329, grad/param norm = 3.3247e-01, time/batch = 0.7013s	
617/30300 (epoch 1.018), train_loss = 2.54493187, grad/param norm = 2.7644e-01, time/batch = 0.7057s	
618/30300 (epoch 1.020), train_loss = 2.61530098, grad/param norm = 3.5663e-01, time/batch = 0.7208s	
619/30300 (epoch 1.021), train_loss = 2.59434272, grad/param norm = 4.3189e-01, time/batch = 0.7049s	
620/30300 (epoch 1.023), train_loss = 2.49820175, grad/param norm = 3.4158e-01, time/batch = 0.6951s	
621/30300 (epoch 1.025), train_loss = 2.48721475, grad/param norm = 2.6380e-01, time/batch = 0.6898s	
622/30300 (epoch 1.026), train_loss = 2.54152448, grad/param norm = 2.8908e-01, time/batch = 0.6878s	
623/30300 (epoch 1.028), train_loss = 2.50179551, grad/param norm = 2.8186e-01, time/batch = 0.6860s	
624/30300 (epoch 1.030), train_loss = 2.40738655, grad/param norm = 2.9049e-01, time/batch = 0.6867s	
625/30300 (epoch 1.031), train_loss = 2.49175805, grad/param norm = 3.5607e-01, time/batch = 0.6888s	
626/30300 (epoch 1.033), train_loss = 2.54754915, grad/param norm = 3.2208e-01, time/batch = 0.6890s	
627/30300 (epoch 1.035), train_loss = 2.55496012, grad/param norm = 3.1048e-01, time/batch = 0.6872s	
628/30300 (epoch 1.036), train_loss = 2.68398221, grad/param norm = 4.1130e-01, time/batch = 0.6886s	
629/30300 (epoch 1.038), train_loss = 2.57361004, grad/param norm = 3.3373e-01, time/batch = 0.6911s	
630/30300 (epoch 1.040), train_loss = 2.27058107, grad/param norm = 2.9466e-01, time/batch = 0.6851s	
631/30300 (epoch 1.041), train_loss = 2.51480645, grad/param norm = 3.9021e-01, time/batch = 0.6996s	
632/30300 (epoch 1.043), train_loss = 2.52630528, grad/param norm = 3.6870e-01, time/batch = 0.7158s	
633/30300 (epoch 1.045), train_loss = 2.42275987, grad/param norm = 3.6819e-01, time/batch = 0.7103s	
634/30300 (epoch 1.046), train_loss = 2.44546571, grad/param norm = 3.7557e-01, time/batch = 0.6889s	
635/30300 (epoch 1.048), train_loss = 2.44534115, grad/param norm = 4.3572e-01, time/batch = 0.6931s	
636/30300 (epoch 1.050), train_loss = 2.63629940, grad/param norm = 3.8011e-01, time/batch = 0.6900s	
637/30300 (epoch 1.051), train_loss = 2.49722116, grad/param norm = 3.6852e-01, time/batch = 0.6923s	
638/30300 (epoch 1.053), train_loss = 2.44039467, grad/param norm = 4.8424e-01, time/batch = 0.7077s	
639/30300 (epoch 1.054), train_loss = 2.42384685, grad/param norm = 4.4445e-01, time/batch = 0.6919s	
640/30300 (epoch 1.056), train_loss = 2.45720867, grad/param norm = 2.8664e-01, time/batch = 0.6877s	
641/30300 (epoch 1.058), train_loss = 2.53182052, grad/param norm = 3.1264e-01, time/batch = 0.6907s	
642/30300 (epoch 1.059), train_loss = 2.61189608, grad/param norm = 3.6416e-01, time/batch = 0.6898s	
643/30300 (epoch 1.061), train_loss = 2.49413055, grad/param norm = 4.1609e-01, time/batch = 0.6936s	
644/30300 (epoch 1.063), train_loss = 2.46921664, grad/param norm = 3.4873e-01, time/batch = 0.6862s	
645/30300 (epoch 1.064), train_loss = 2.53358961, grad/param norm = 3.9484e-01, time/batch = 0.6912s	
646/30300 (epoch 1.066), train_loss = 2.54735775, grad/param norm = 3.3824e-01, time/batch = 0.7034s	
647/30300 (epoch 1.068), train_loss = 2.35005205, grad/param norm = 3.0622e-01, time/batch = 0.6957s	
648/30300 (epoch 1.069), train_loss = 2.53622780, grad/param norm = 3.2278e-01, time/batch = 0.7013s	
649/30300 (epoch 1.071), train_loss = 2.51408114, grad/param norm = 3.5846e-01, time/batch = 0.7083s	
650/30300 (epoch 1.073), train_loss = 2.57594628, grad/param norm = 2.9360e-01, time/batch = 0.7017s	
651/30300 (epoch 1.074), train_loss = 2.56095829, grad/param norm = 3.1878e-01, time/batch = 0.7023s	
652/30300 (epoch 1.076), train_loss = 2.37005073, grad/param norm = 3.6264e-01, time/batch = 0.7008s	
653/30300 (epoch 1.078), train_loss = 2.31795858, grad/param norm = 3.3042e-01, time/batch = 0.6974s	
654/30300 (epoch 1.079), train_loss = 2.26357265, grad/param norm = 2.5146e-01, time/batch = 0.7016s	
655/30300 (epoch 1.081), train_loss = 2.62532461, grad/param norm = 2.9686e-01, time/batch = 0.7011s	
656/30300 (epoch 1.083), train_loss = 2.75371318, grad/param norm = 3.6415e-01, time/batch = 0.6915s	
657/30300 (epoch 1.084), train_loss = 2.42777683, grad/param norm = 4.0517e-01, time/batch = 0.6893s	
658/30300 (epoch 1.086), train_loss = 2.51172319, grad/param norm = 3.4837e-01, time/batch = 0.6902s	
659/30300 (epoch 1.087), train_loss = 2.39449194, grad/param norm = 2.8456e-01, time/batch = 0.6923s	
660/30300 (epoch 1.089), train_loss = 2.51625164, grad/param norm = 3.2473e-01, time/batch = 0.6961s	
661/30300 (epoch 1.091), train_loss = 2.51738765, grad/param norm = 3.2280e-01, time/batch = 0.7222s	
662/30300 (epoch 1.092), train_loss = 2.41574826, grad/param norm = 3.1555e-01, time/batch = 0.7037s	
663/30300 (epoch 1.094), train_loss = 2.68088386, grad/param norm = 3.2378e-01, time/batch = 0.6938s	
664/30300 (epoch 1.096), train_loss = 2.45286816, grad/param norm = 3.7169e-01, time/batch = 0.6935s	
665/30300 (epoch 1.097), train_loss = 2.49447063, grad/param norm = 4.1202e-01, time/batch = 0.6912s	
666/30300 (epoch 1.099), train_loss = 2.67893506, grad/param norm = 3.1293e-01, time/batch = 0.6884s	
667/30300 (epoch 1.101), train_loss = 2.58060671, grad/param norm = 2.5323e-01, time/batch = 0.6892s	
668/30300 (epoch 1.102), train_loss = 2.59328902, grad/param norm = 3.2496e-01, time/batch = 0.6911s	
669/30300 (epoch 1.104), train_loss = 2.32488856, grad/param norm = 3.5794e-01, time/batch = 0.6857s	
670/30300 (epoch 1.106), train_loss = 2.63736401, grad/param norm = 3.2903e-01, time/batch = 0.6871s	
671/30300 (epoch 1.107), train_loss = 2.46813891, grad/param norm = 2.9965e-01, time/batch = 0.6882s	
672/30300 (epoch 1.109), train_loss = 2.57069769, grad/param norm = 3.4591e-01, time/batch = 0.7067s	
673/30300 (epoch 1.111), train_loss = 2.48068848, grad/param norm = 3.4618e-01, time/batch = 0.6960s	
674/30300 (epoch 1.112), train_loss = 2.50376163, grad/param norm = 2.9654e-01, time/batch = 0.6955s	
675/30300 (epoch 1.114), train_loss = 2.41521805, grad/param norm = 2.6560e-01, time/batch = 0.7201s	
676/30300 (epoch 1.116), train_loss = 2.51861716, grad/param norm = 2.5611e-01, time/batch = 0.7077s	
677/30300 (epoch 1.117), train_loss = 2.41079853, grad/param norm = 2.6202e-01, time/batch = 0.6912s	
678/30300 (epoch 1.119), train_loss = 2.28479430, grad/param norm = 2.8275e-01, time/batch = 0.7038s	
679/30300 (epoch 1.120), train_loss = 2.34144411, grad/param norm = 3.6782e-01, time/batch = 0.6981s	
680/30300 (epoch 1.122), train_loss = 2.53887993, grad/param norm = 2.8577e-01, time/batch = 0.6946s	
681/30300 (epoch 1.124), train_loss = 2.48727790, grad/param norm = 2.5638e-01, time/batch = 0.7024s	
682/30300 (epoch 1.125), train_loss = 2.34198348, grad/param norm = 2.8947e-01, time/batch = 0.7058s	
683/30300 (epoch 1.127), train_loss = 2.52964859, grad/param norm = 4.4143e-01, time/batch = 0.6926s	
684/30300 (epoch 1.129), train_loss = 2.50899261, grad/param norm = 3.4775e-01, time/batch = 0.6885s	
685/30300 (epoch 1.130), train_loss = 2.54156810, grad/param norm = 2.9937e-01, time/batch = 0.6903s	
686/30300 (epoch 1.132), train_loss = 2.42749351, grad/param norm = 3.2238e-01, time/batch = 0.7010s	
687/30300 (epoch 1.134), train_loss = 2.33938014, grad/param norm = 3.8402e-01, time/batch = 0.6943s	
688/30300 (epoch 1.135), train_loss = 2.54429365, grad/param norm = 3.5629e-01, time/batch = 0.7017s	
689/30300 (epoch 1.137), train_loss = 2.53989749, grad/param norm = 3.4745e-01, time/batch = 0.7205s	
690/30300 (epoch 1.139), train_loss = 2.40566750, grad/param norm = 4.1276e-01, time/batch = 0.7138s	
691/30300 (epoch 1.140), train_loss = 3.01368402, grad/param norm = 7.7301e-01, time/batch = 0.6897s	
692/30300 (epoch 1.142), train_loss = 2.77093980, grad/param norm = 7.2022e-01, time/batch = 0.6883s	
693/30300 (epoch 1.144), train_loss = 2.56234902, grad/param norm = 3.3548e-01, time/batch = 0.6979s	
694/30300 (epoch 1.145), train_loss = 2.60767142, grad/param norm = 2.8729e-01, time/batch = 0.6958s	
695/30300 (epoch 1.147), train_loss = 2.58041772, grad/param norm = 3.7913e-01, time/batch = 0.6907s	
696/30300 (epoch 1.149), train_loss = 2.63044573, grad/param norm = 3.6646e-01, time/batch = 0.6914s	
697/30300 (epoch 1.150), train_loss = 2.64021479, grad/param norm = 3.3509e-01, time/batch = 0.6884s	
698/30300 (epoch 1.152), train_loss = 2.60848340, grad/param norm = 4.5241e-01, time/batch = 0.6870s	
699/30300 (epoch 1.153), train_loss = 2.58793490, grad/param norm = 3.4531e-01, time/batch = 0.6904s	
700/30300 (epoch 1.155), train_loss = 2.29079793, grad/param norm = 2.6110e-01, time/batch = 0.6922s	
701/30300 (epoch 1.157), train_loss = 2.48564595, grad/param norm = 2.5674e-01, time/batch = 0.6975s	
702/30300 (epoch 1.158), train_loss = 2.56763650, grad/param norm = 2.6781e-01, time/batch = 0.6904s	
703/30300 (epoch 1.160), train_loss = 2.39947412, grad/param norm = 3.5954e-01, time/batch = 0.6972s	
704/30300 (epoch 1.162), train_loss = 2.38416539, grad/param norm = 4.6984e-01, time/batch = 0.7206s	
705/30300 (epoch 1.163), train_loss = 2.41343353, grad/param norm = 4.2788e-01, time/batch = 0.6902s	
706/30300 (epoch 1.165), train_loss = 2.56285664, grad/param norm = 4.5937e-01, time/batch = 0.6897s	
707/30300 (epoch 1.167), train_loss = 2.50538557, grad/param norm = 3.4575e-01, time/batch = 0.6906s	
708/30300 (epoch 1.168), train_loss = 2.36162862, grad/param norm = 3.2182e-01, time/batch = 0.6901s	
709/30300 (epoch 1.170), train_loss = 2.52283676, grad/param norm = 2.8149e-01, time/batch = 0.6921s	
710/30300 (epoch 1.172), train_loss = 2.33467387, grad/param norm = 2.3240e-01, time/batch = 0.6892s	
711/30300 (epoch 1.173), train_loss = 2.55071229, grad/param norm = 2.7130e-01, time/batch = 0.6931s	
712/30300 (epoch 1.175), train_loss = 2.42860900, grad/param norm = 2.8112e-01, time/batch = 0.6916s	
713/30300 (epoch 1.177), train_loss = 2.57276150, grad/param norm = 2.7500e-01, time/batch = 0.6898s	
714/30300 (epoch 1.178), train_loss = 2.30235475, grad/param norm = 2.3668e-01, time/batch = 0.6946s	
715/30300 (epoch 1.180), train_loss = 2.35544549, grad/param norm = 2.3173e-01, time/batch = 0.6922s	
716/30300 (epoch 1.182), train_loss = 2.41088726, grad/param norm = 3.2249e-01, time/batch = 0.6901s	
717/30300 (epoch 1.183), train_loss = 2.39438842, grad/param norm = 3.5411e-01, time/batch = 0.6946s	
718/30300 (epoch 1.185), train_loss = 2.68348446, grad/param norm = 2.8686e-01, time/batch = 0.7183s	
719/30300 (epoch 1.186), train_loss = 2.48386409, grad/param norm = 3.0570e-01, time/batch = 0.7035s	
720/30300 (epoch 1.188), train_loss = 2.42933505, grad/param norm = 4.1504e-01, time/batch = 0.6873s	
721/30300 (epoch 1.190), train_loss = 2.33031896, grad/param norm = 3.7981e-01, time/batch = 0.6943s	
722/30300 (epoch 1.191), train_loss = 2.51663320, grad/param norm = 2.6072e-01, time/batch = 0.6935s	
723/30300 (epoch 1.193), train_loss = 2.34808430, grad/param norm = 2.4358e-01, time/batch = 0.6851s	
724/30300 (epoch 1.195), train_loss = 2.44675920, grad/param norm = 2.9838e-01, time/batch = 0.6879s	
725/30300 (epoch 1.196), train_loss = 2.50554043, grad/param norm = 3.2503e-01, time/batch = 0.6842s	
726/30300 (epoch 1.198), train_loss = 2.19678295, grad/param norm = 2.7946e-01, time/batch = 0.6870s	
727/30300 (epoch 1.200), train_loss = 2.47688499, grad/param norm = 3.5811e-01, time/batch = 0.6875s	
728/30300 (epoch 1.201), train_loss = 2.56232127, grad/param norm = 2.7769e-01, time/batch = 0.6888s	
729/30300 (epoch 1.203), train_loss = 2.44971310, grad/param norm = 3.0547e-01, time/batch = 0.6889s	
730/30300 (epoch 1.205), train_loss = 2.61204426, grad/param norm = 2.9824e-01, time/batch = 0.6928s	
731/30300 (epoch 1.206), train_loss = 2.60578910, grad/param norm = 2.7836e-01, time/batch = 0.6899s	
732/30300 (epoch 1.208), train_loss = 2.59498223, grad/param norm = 2.6744e-01, time/batch = 0.7137s	
733/30300 (epoch 1.210), train_loss = 2.46415465, grad/param norm = 3.3087e-01, time/batch = 0.7137s	
734/30300 (epoch 1.211), train_loss = 2.43406358, grad/param norm = 3.5278e-01, time/batch = 0.6930s	
735/30300 (epoch 1.213), train_loss = 2.46272907, grad/param norm = 3.7815e-01, time/batch = 0.6929s	
736/30300 (epoch 1.215), train_loss = 2.31352130, grad/param norm = 3.3266e-01, time/batch = 0.7062s	
737/30300 (epoch 1.216), train_loss = 2.49011308, grad/param norm = 3.2027e-01, time/batch = 0.7204s	
738/30300 (epoch 1.218), train_loss = 2.39679041, grad/param norm = 2.7872e-01, time/batch = 0.6942s	
739/30300 (epoch 1.219), train_loss = 2.33522560, grad/param norm = 3.2210e-01, time/batch = 0.6897s	
740/30300 (epoch 1.221), train_loss = 2.34522670, grad/param norm = 3.2986e-01, time/batch = 0.6903s	
741/30300 (epoch 1.223), train_loss = 2.33227347, grad/param norm = 2.4582e-01, time/batch = 0.6854s	
742/30300 (epoch 1.224), train_loss = 2.23092500, grad/param norm = 2.6535e-01, time/batch = 0.6968s	
743/30300 (epoch 1.226), train_loss = 2.45483476, grad/param norm = 2.7269e-01, time/batch = 0.6892s	
744/30300 (epoch 1.228), train_loss = 2.37040914, grad/param norm = 2.7160e-01, time/batch = 0.6928s	
745/30300 (epoch 1.229), train_loss = 2.25855360, grad/param norm = 2.7391e-01, time/batch = 0.6885s	
746/30300 (epoch 1.231), train_loss = 2.37545140, grad/param norm = 3.3349e-01, time/batch = 0.6899s	
747/30300 (epoch 1.233), train_loss = 2.29618755, grad/param norm = 2.5452e-01, time/batch = 0.6972s	
748/30300 (epoch 1.234), train_loss = 2.45357017, grad/param norm = 3.0944e-01, time/batch = 0.6877s	
749/30300 (epoch 1.236), train_loss = 2.41982286, grad/param norm = 4.2299e-01, time/batch = 0.6927s	
750/30300 (epoch 1.238), train_loss = 2.51675212, grad/param norm = 4.6353e-01, time/batch = 0.6913s	
751/30300 (epoch 1.239), train_loss = 2.39992869, grad/param norm = 3.7902e-01, time/batch = 0.7214s	
752/30300 (epoch 1.241), train_loss = 2.37544529, grad/param norm = 3.5862e-01, time/batch = 0.7044s	
753/30300 (epoch 1.243), train_loss = 2.40257330, grad/param norm = 3.8731e-01, time/batch = 0.6934s	
754/30300 (epoch 1.244), train_loss = 2.61675575, grad/param norm = 3.9528e-01, time/batch = 0.6955s	
755/30300 (epoch 1.246), train_loss = 2.40659040, grad/param norm = 3.8225e-01, time/batch = 0.6912s	
756/30300 (epoch 1.248), train_loss = 2.52283367, grad/param norm = 3.2426e-01, time/batch = 0.6905s	
757/30300 (epoch 1.249), train_loss = 2.27464708, grad/param norm = 3.5878e-01, time/batch = 0.6919s	
758/30300 (epoch 1.251), train_loss = 2.37757533, grad/param norm = 3.2051e-01, time/batch = 0.7026s	
759/30300 (epoch 1.252), train_loss = 2.53296695, grad/param norm = 3.3131e-01, time/batch = 0.7139s	
760/30300 (epoch 1.254), train_loss = 2.43722633, grad/param norm = 2.6216e-01, time/batch = 0.6884s	
761/30300 (epoch 1.256), train_loss = 2.41562898, grad/param norm = 2.9365e-01, time/batch = 0.6949s	
762/30300 (epoch 1.257), train_loss = 2.56659582, grad/param norm = 2.7588e-01, time/batch = 0.6927s	
763/30300 (epoch 1.259), train_loss = 2.40666932, grad/param norm = 2.6699e-01, time/batch = 0.6905s	
764/30300 (epoch 1.261), train_loss = 2.53409813, grad/param norm = 2.8223e-01, time/batch = 0.7028s	
765/30300 (epoch 1.262), train_loss = 2.34838446, grad/param norm = 2.5566e-01, time/batch = 0.7172s	
766/30300 (epoch 1.264), train_loss = 2.38787134, grad/param norm = 2.9813e-01, time/batch = 0.7064s	
767/30300 (epoch 1.266), train_loss = 2.32883650, grad/param norm = 2.7502e-01, time/batch = 0.6973s	
768/30300 (epoch 1.267), train_loss = 2.44341015, grad/param norm = 2.8143e-01, time/batch = 0.6918s	
769/30300 (epoch 1.269), train_loss = 2.45340182, grad/param norm = 2.6302e-01, time/batch = 0.6938s	
770/30300 (epoch 1.271), train_loss = 2.44329868, grad/param norm = 3.5032e-01, time/batch = 0.6914s	
771/30300 (epoch 1.272), train_loss = 2.46789267, grad/param norm = 3.2099e-01, time/batch = 0.6915s	
772/30300 (epoch 1.274), train_loss = 2.56560447, grad/param norm = 2.8876e-01, time/batch = 0.7021s	
773/30300 (epoch 1.276), train_loss = 2.57297712, grad/param norm = 3.0499e-01, time/batch = 0.7009s	
774/30300 (epoch 1.277), train_loss = 2.35293324, grad/param norm = 3.1438e-01, time/batch = 0.7151s	
775/30300 (epoch 1.279), train_loss = 2.44681633, grad/param norm = 2.7773e-01, time/batch = 0.7093s	
776/30300 (epoch 1.281), train_loss = 2.41411565, grad/param norm = 2.5725e-01, time/batch = 0.7125s	
777/30300 (epoch 1.282), train_loss = 2.37570715, grad/param norm = 2.7824e-01, time/batch = 0.7109s	
778/30300 (epoch 1.284), train_loss = 2.55582286, grad/param norm = 3.0520e-01, time/batch = 0.6954s	
779/30300 (epoch 1.285), train_loss = 2.49044722, grad/param norm = 3.2526e-01, time/batch = 0.7071s	
780/30300 (epoch 1.287), train_loss = 2.48320931, grad/param norm = 3.3349e-01, time/batch = 0.7030s	
781/30300 (epoch 1.289), train_loss = 2.36204747, grad/param norm = 3.6600e-01, time/batch = 0.6908s	
782/30300 (epoch 1.290), train_loss = 2.22950801, grad/param norm = 3.1417e-01, time/batch = 0.6870s	
783/30300 (epoch 1.292), train_loss = 2.31667692, grad/param norm = 2.5746e-01, time/batch = 0.6875s	
784/30300 (epoch 1.294), train_loss = 2.59751032, grad/param norm = 3.0665e-01, time/batch = 0.6865s	
785/30300 (epoch 1.295), train_loss = 2.42235172, grad/param norm = 3.0824e-01, time/batch = 0.6993s	
786/30300 (epoch 1.297), train_loss = 2.37984227, grad/param norm = 3.2058e-01, time/batch = 0.6989s	
787/30300 (epoch 1.299), train_loss = 2.50619922, grad/param norm = 3.1277e-01, time/batch = 0.6927s	
788/30300 (epoch 1.300), train_loss = 2.37898551, grad/param norm = 2.8418e-01, time/batch = 0.6909s	
789/30300 (epoch 1.302), train_loss = 2.30384433, grad/param norm = 2.9084e-01, time/batch = 0.6927s	
790/30300 (epoch 1.304), train_loss = 2.35434514, grad/param norm = 2.6436e-01, time/batch = 0.6928s	
791/30300 (epoch 1.305), train_loss = 2.40997969, grad/param norm = 3.0612e-01, time/batch = 0.6889s	
792/30300 (epoch 1.307), train_loss = 2.31763948, grad/param norm = 3.8993e-01, time/batch = 0.6961s	
793/30300 (epoch 1.309), train_loss = 2.62455820, grad/param norm = 4.2292e-01, time/batch = 0.7013s	
794/30300 (epoch 1.310), train_loss = 2.29431979, grad/param norm = 4.0730e-01, time/batch = 0.7207s	
795/30300 (epoch 1.312), train_loss = 2.39296624, grad/param norm = 3.9648e-01, time/batch = 0.7001s	
796/30300 (epoch 1.314), train_loss = 2.35715035, grad/param norm = 3.0941e-01, time/batch = 0.6947s	
797/30300 (epoch 1.315), train_loss = 2.37882153, grad/param norm = 2.6465e-01, time/batch = 0.6893s	
798/30300 (epoch 1.317), train_loss = 2.39697277, grad/param norm = 2.5189e-01, time/batch = 0.6875s	
799/30300 (epoch 1.318), train_loss = 2.57361365, grad/param norm = 2.5804e-01, time/batch = 0.6921s	
800/30300 (epoch 1.320), train_loss = 2.42014933, grad/param norm = 3.2131e-01, time/batch = 0.7008s	
801/30300 (epoch 1.322), train_loss = 2.29637870, grad/param norm = 3.5228e-01, time/batch = 0.7024s	
802/30300 (epoch 1.323), train_loss = 2.35545313, grad/param norm = 2.5678e-01, time/batch = 0.6969s	
803/30300 (epoch 1.325), train_loss = 2.26713432, grad/param norm = 2.9938e-01, time/batch = 0.6901s	
804/30300 (epoch 1.327), train_loss = 2.31209793, grad/param norm = 2.7221e-01, time/batch = 0.6925s	
805/30300 (epoch 1.328), train_loss = 2.30184285, grad/param norm = 2.5789e-01, time/batch = 0.6887s	
806/30300 (epoch 1.330), train_loss = 2.43276331, grad/param norm = 2.6990e-01, time/batch = 0.6899s	
807/30300 (epoch 1.332), train_loss = 2.53505660, grad/param norm = 2.9188e-01, time/batch = 0.6949s	
808/30300 (epoch 1.333), train_loss = 2.44009167, grad/param norm = 3.5530e-01, time/batch = 0.6893s	
809/30300 (epoch 1.335), train_loss = 2.23702727, grad/param norm = 3.4146e-01, time/batch = 0.6915s	
810/30300 (epoch 1.337), train_loss = 2.54242018, grad/param norm = 3.0904e-01, time/batch = 0.6961s	
811/30300 (epoch 1.338), train_loss = 2.36377139, grad/param norm = 3.2559e-01, time/batch = 0.6911s	
812/30300 (epoch 1.340), train_loss = 2.40141921, grad/param norm = 3.3128e-01, time/batch = 0.6938s	
813/30300 (epoch 1.342), train_loss = 2.32575338, grad/param norm = 2.6226e-01, time/batch = 0.6910s	
814/30300 (epoch 1.343), train_loss = 2.31055304, grad/param norm = 2.8778e-01, time/batch = 0.6919s	
815/30300 (epoch 1.345), train_loss = 2.35682625, grad/param norm = 2.7354e-01, time/batch = 0.6935s	
816/30300 (epoch 1.347), train_loss = 2.21023855, grad/param norm = 2.1297e-01, time/batch = 0.6927s	
817/30300 (epoch 1.348), train_loss = 2.23683842, grad/param norm = 2.4248e-01, time/batch = 0.6932s	
818/30300 (epoch 1.350), train_loss = 2.37044927, grad/param norm = 2.5845e-01, time/batch = 0.6934s	
819/30300 (epoch 1.351), train_loss = 2.32368725, grad/param norm = 3.1750e-01, time/batch = 0.6940s	
820/30300 (epoch 1.353), train_loss = 2.20452731, grad/param norm = 3.6989e-01, time/batch = 0.6893s	
821/30300 (epoch 1.355), train_loss = 2.38095356, grad/param norm = 3.3032e-01, time/batch = 0.6925s	
822/30300 (epoch 1.356), train_loss = 2.44105913, grad/param norm = 2.6212e-01, time/batch = 0.6927s	
823/30300 (epoch 1.358), train_loss = 2.45414513, grad/param norm = 2.9646e-01, time/batch = 0.6904s	
824/30300 (epoch 1.360), train_loss = 2.26558059, grad/param norm = 3.0302e-01, time/batch = 0.6891s	
825/30300 (epoch 1.361), train_loss = 2.37728892, grad/param norm = 2.9924e-01, time/batch = 0.6861s	
826/30300 (epoch 1.363), train_loss = 2.50550367, grad/param norm = 2.5972e-01, time/batch = 0.6901s	
827/30300 (epoch 1.365), train_loss = 2.32380691, grad/param norm = 3.6225e-01, time/batch = 0.7205s	
828/30300 (epoch 1.366), train_loss = 2.34699616, grad/param norm = 3.6126e-01, time/batch = 0.6974s	
829/30300 (epoch 1.368), train_loss = 2.21676949, grad/param norm = 2.9283e-01, time/batch = 0.6885s	
830/30300 (epoch 1.370), train_loss = 2.40256052, grad/param norm = 2.7645e-01, time/batch = 0.6871s	
831/30300 (epoch 1.371), train_loss = 2.38596030, grad/param norm = 3.0459e-01, time/batch = 0.6895s	
832/30300 (epoch 1.373), train_loss = 2.33479380, grad/param norm = 2.8030e-01, time/batch = 0.6923s	
833/30300 (epoch 1.375), train_loss = 2.25449976, grad/param norm = 2.4123e-01, time/batch = 0.6928s	
834/30300 (epoch 1.376), train_loss = 2.32013819, grad/param norm = 2.5082e-01, time/batch = 0.6890s	
835/30300 (epoch 1.378), train_loss = 2.28226066, grad/param norm = 2.5754e-01, time/batch = 0.6886s	
836/30300 (epoch 1.380), train_loss = 2.49399939, grad/param norm = 2.6171e-01, time/batch = 0.6939s	
837/30300 (epoch 1.381), train_loss = 2.35225292, grad/param norm = 2.3818e-01, time/batch = 0.6895s	
838/30300 (epoch 1.383), train_loss = 2.44212742, grad/param norm = 3.0457e-01, time/batch = 0.6958s	
839/30300 (epoch 1.384), train_loss = 2.53515052, grad/param norm = 3.0364e-01, time/batch = 0.6951s	
840/30300 (epoch 1.386), train_loss = 2.29520147, grad/param norm = 3.2132e-01, time/batch = 0.6876s	
841/30300 (epoch 1.388), train_loss = 2.39168266, grad/param norm = 3.8204e-01, time/batch = 0.7142s	
842/30300 (epoch 1.389), train_loss = 2.36368400, grad/param norm = 3.9188e-01, time/batch = 0.7087s	
843/30300 (epoch 1.391), train_loss = 2.41141363, grad/param norm = 2.7398e-01, time/batch = 0.6927s	
844/30300 (epoch 1.393), train_loss = 2.25604044, grad/param norm = 2.4612e-01, time/batch = 0.7097s	
845/30300 (epoch 1.394), train_loss = 2.33646413, grad/param norm = 2.6627e-01, time/batch = 0.7023s	
846/30300 (epoch 1.396), train_loss = 2.34947843, grad/param norm = 2.8736e-01, time/batch = 0.7285s	
847/30300 (epoch 1.398), train_loss = 2.34291667, grad/param norm = 3.1121e-01, time/batch = 0.7005s	
848/30300 (epoch 1.399), train_loss = 2.24901493, grad/param norm = 2.4928e-01, time/batch = 0.6861s	
849/30300 (epoch 1.401), train_loss = 2.40613434, grad/param norm = 3.0840e-01, time/batch = 0.6922s	
850/30300 (epoch 1.403), train_loss = 2.34807304, grad/param norm = 2.9167e-01, time/batch = 0.7140s	
851/30300 (epoch 1.404), train_loss = 2.36706736, grad/param norm = 3.3735e-01, time/batch = 0.7279s	
852/30300 (epoch 1.406), train_loss = 2.33545072, grad/param norm = 3.2954e-01, time/batch = 0.7042s	
853/30300 (epoch 1.408), train_loss = 2.35147059, grad/param norm = 2.9398e-01, time/batch = 0.6962s	
854/30300 (epoch 1.409), train_loss = 2.11115530, grad/param norm = 2.7952e-01, time/batch = 0.6955s	
855/30300 (epoch 1.411), train_loss = 2.24744322, grad/param norm = 3.4193e-01, time/batch = 0.6879s	
856/30300 (epoch 1.413), train_loss = 2.21512768, grad/param norm = 2.9758e-01, time/batch = 0.6881s	
857/30300 (epoch 1.414), train_loss = 2.44830304, grad/param norm = 3.1618e-01, time/batch = 0.6885s	
858/30300 (epoch 1.416), train_loss = 2.38961336, grad/param norm = 3.2413e-01, time/batch = 0.6910s	
859/30300 (epoch 1.417), train_loss = 2.20851798, grad/param norm = 2.3875e-01, time/batch = 0.6945s	
860/30300 (epoch 1.419), train_loss = 2.16216802, grad/param norm = 2.5499e-01, time/batch = 0.6923s	
861/30300 (epoch 1.421), train_loss = 2.18766320, grad/param norm = 2.9365e-01, time/batch = 0.6920s	
862/30300 (epoch 1.422), train_loss = 2.25923396, grad/param norm = 2.6903e-01, time/batch = 0.6932s	
863/30300 (epoch 1.424), train_loss = 2.40807635, grad/param norm = 2.5855e-01, time/batch = 0.6947s	
864/30300 (epoch 1.426), train_loss = 2.11565837, grad/param norm = 3.0842e-01, time/batch = 0.6972s	
865/30300 (epoch 1.427), train_loss = 2.27223762, grad/param norm = 3.6107e-01, time/batch = 0.6895s	
866/30300 (epoch 1.429), train_loss = 2.42288039, grad/param norm = 3.8385e-01, time/batch = 0.6903s	
867/30300 (epoch 1.431), train_loss = 2.39357619, grad/param norm = 4.3032e-01, time/batch = 0.6892s	
868/30300 (epoch 1.432), train_loss = 2.28806609, grad/param norm = 2.9135e-01, time/batch = 0.6937s	
869/30300 (epoch 1.434), train_loss = 2.27702949, grad/param norm = 2.4165e-01, time/batch = 0.6906s	
870/30300 (epoch 1.436), train_loss = 2.32076871, grad/param norm = 3.2073e-01, time/batch = 0.6927s	
871/30300 (epoch 1.437), train_loss = 2.35145365, grad/param norm = 2.6897e-01, time/batch = 0.6918s	
872/30300 (epoch 1.439), train_loss = 2.35850946, grad/param norm = 2.5733e-01, time/batch = 0.6941s	
873/30300 (epoch 1.441), train_loss = 2.20494899, grad/param norm = 2.3558e-01, time/batch = 0.6958s	
874/30300 (epoch 1.442), train_loss = 2.16536141, grad/param norm = 2.6803e-01, time/batch = 0.6912s	
875/30300 (epoch 1.444), train_loss = 2.27818916, grad/param norm = 3.1574e-01, time/batch = 0.6900s	
876/30300 (epoch 1.446), train_loss = 2.22628587, grad/param norm = 3.3095e-01, time/batch = 0.6907s	
877/30300 (epoch 1.447), train_loss = 2.35629216, grad/param norm = 3.2683e-01, time/batch = 0.6882s	
878/30300 (epoch 1.449), train_loss = 2.29468821, grad/param norm = 3.2822e-01, time/batch = 0.6912s	
879/30300 (epoch 1.450), train_loss = 2.44900674, grad/param norm = 3.2909e-01, time/batch = 0.6903s	
880/30300 (epoch 1.452), train_loss = 2.21535746, grad/param norm = 2.3701e-01, time/batch = 0.6892s	
881/30300 (epoch 1.454), train_loss = 2.23384450, grad/param norm = 2.2892e-01, time/batch = 0.6909s	
882/30300 (epoch 1.455), train_loss = 2.50552828, grad/param norm = 2.9609e-01, time/batch = 0.6893s	
883/30300 (epoch 1.457), train_loss = 2.37689986, grad/param norm = 2.5506e-01, time/batch = 0.6915s	
884/30300 (epoch 1.459), train_loss = 2.27049529, grad/param norm = 2.9655e-01, time/batch = 0.7168s	
885/30300 (epoch 1.460), train_loss = 2.33161781, grad/param norm = 3.2126e-01, time/batch = 0.7066s	
886/30300 (epoch 1.462), train_loss = 2.37294909, grad/param norm = 2.9968e-01, time/batch = 0.7077s	
887/30300 (epoch 1.464), train_loss = 2.41048076, grad/param norm = 2.9721e-01, time/batch = 0.7141s	
888/30300 (epoch 1.465), train_loss = 2.18299005, grad/param norm = 2.5443e-01, time/batch = 0.7060s	
889/30300 (epoch 1.467), train_loss = 2.09124375, grad/param norm = 3.0272e-01, time/batch = 0.6943s	
890/30300 (epoch 1.469), train_loss = 2.23392942, grad/param norm = 2.8158e-01, time/batch = 0.6873s	
891/30300 (epoch 1.470), train_loss = 2.29282921, grad/param norm = 2.9962e-01, time/batch = 0.6913s	
892/30300 (epoch 1.472), train_loss = 2.12745271, grad/param norm = 2.6849e-01, time/batch = 0.6908s	
893/30300 (epoch 1.474), train_loss = 2.34590865, grad/param norm = 3.4279e-01, time/batch = 0.6950s	
894/30300 (epoch 1.475), train_loss = 2.27881322, grad/param norm = 2.7936e-01, time/batch = 0.6930s	
895/30300 (epoch 1.477), train_loss = 2.32782833, grad/param norm = 2.9749e-01, time/batch = 0.6907s	
896/30300 (epoch 1.479), train_loss = 2.39126865, grad/param norm = 3.3429e-01, time/batch = 0.6903s	
897/30300 (epoch 1.480), train_loss = 2.20011145, grad/param norm = 3.1439e-01, time/batch = 0.6931s	
898/30300 (epoch 1.482), train_loss = 2.41915390, grad/param norm = 4.4998e-01, time/batch = 0.7103s	
899/30300 (epoch 1.483), train_loss = 2.32218447, grad/param norm = 4.0289e-01, time/batch = 0.7152s	
900/30300 (epoch 1.485), train_loss = 2.30199019, grad/param norm = 3.3469e-01, time/batch = 0.6916s	
901/30300 (epoch 1.487), train_loss = 2.38715309, grad/param norm = 2.4228e-01, time/batch = 0.6933s	
902/30300 (epoch 1.488), train_loss = 2.19409529, grad/param norm = 2.7529e-01, time/batch = 0.6890s	
903/30300 (epoch 1.490), train_loss = 2.14900086, grad/param norm = 3.1620e-01, time/batch = 0.6902s	
904/30300 (epoch 1.492), train_loss = 2.31683775, grad/param norm = 2.7432e-01, time/batch = 0.6912s	
905/30300 (epoch 1.493), train_loss = 2.17853031, grad/param norm = 2.7647e-01, time/batch = 0.6999s	
906/30300 (epoch 1.495), train_loss = 2.28940739, grad/param norm = 2.7583e-01, time/batch = 0.6931s	
907/30300 (epoch 1.497), train_loss = 2.26384856, grad/param norm = 3.2649e-01, time/batch = 0.6966s	
908/30300 (epoch 1.498), train_loss = 2.36430111, grad/param norm = 2.9820e-01, time/batch = 0.7140s	
909/30300 (epoch 1.500), train_loss = 2.48675542, grad/param norm = 2.9341e-01, time/batch = 0.7165s	
910/30300 (epoch 1.502), train_loss = 2.17022272, grad/param norm = 3.0117e-01, time/batch = 0.6883s	
911/30300 (epoch 1.503), train_loss = 2.29050670, grad/param norm = 2.5594e-01, time/batch = 0.6931s	
912/30300 (epoch 1.505), train_loss = 2.36484074, grad/param norm = 2.5964e-01, time/batch = 0.6930s	
913/30300 (epoch 1.507), train_loss = 2.25515363, grad/param norm = 2.7475e-01, time/batch = 0.6904s	
914/30300 (epoch 1.508), train_loss = 2.39177780, grad/param norm = 2.7307e-01, time/batch = 0.6914s	
915/30300 (epoch 1.510), train_loss = 2.32472295, grad/param norm = 2.9260e-01, time/batch = 0.6988s	
916/30300 (epoch 1.512), train_loss = 2.17411004, grad/param norm = 2.4589e-01, time/batch = 0.7008s	
917/30300 (epoch 1.513), train_loss = 2.31542205, grad/param norm = 2.7228e-01, time/batch = 0.6934s	
918/30300 (epoch 1.515), train_loss = 2.25445425, grad/param norm = 3.3715e-01, time/batch = 0.6926s	
919/30300 (epoch 1.517), train_loss = 2.16007802, grad/param norm = 3.3479e-01, time/batch = 0.6916s	
920/30300 (epoch 1.518), train_loss = 2.38276920, grad/param norm = 2.5378e-01, time/batch = 0.6855s	
921/30300 (epoch 1.520), train_loss = 2.48556238, grad/param norm = 2.9117e-01, time/batch = 0.6888s	
922/30300 (epoch 1.521), train_loss = 2.25190498, grad/param norm = 2.8626e-01, time/batch = 0.7039s	
923/30300 (epoch 1.523), train_loss = 2.39128341, grad/param norm = 2.3953e-01, time/batch = 0.7211s	
924/30300 (epoch 1.525), train_loss = 2.33389870, grad/param norm = 2.4084e-01, time/batch = 0.6896s	
925/30300 (epoch 1.526), train_loss = 2.25686434, grad/param norm = 2.5117e-01, time/batch = 0.6867s	
926/30300 (epoch 1.528), train_loss = 2.21523537, grad/param norm = 2.6568e-01, time/batch = 0.6908s	
927/30300 (epoch 1.530), train_loss = 2.27893473, grad/param norm = 2.7381e-01, time/batch = 0.6870s	
928/30300 (epoch 1.531), train_loss = 2.34092163, grad/param norm = 3.1471e-01, time/batch = 0.6900s	
929/30300 (epoch 1.533), train_loss = 2.35023571, grad/param norm = 2.5026e-01, time/batch = 0.6951s	
930/30300 (epoch 1.535), train_loss = 2.18601921, grad/param norm = 2.3105e-01, time/batch = 0.7055s	
931/30300 (epoch 1.536), train_loss = 2.27974420, grad/param norm = 2.4477e-01, time/batch = 0.7027s	
932/30300 (epoch 1.538), train_loss = 2.06486080, grad/param norm = 2.8139e-01, time/batch = 0.7021s	
933/30300 (epoch 1.540), train_loss = 2.32024654, grad/param norm = 2.7611e-01, time/batch = 0.6942s	
934/30300 (epoch 1.541), train_loss = 2.20651268, grad/param norm = 2.5350e-01, time/batch = 0.7056s	
935/30300 (epoch 1.543), train_loss = 2.28534005, grad/param norm = 2.5193e-01, time/batch = 0.6904s	
936/30300 (epoch 1.545), train_loss = 2.40826919, grad/param norm = 3.6803e-01, time/batch = 0.6988s	
937/30300 (epoch 1.546), train_loss = 2.42981136, grad/param norm = 5.2388e-01, time/batch = 0.7207s	
938/30300 (epoch 1.548), train_loss = 2.21182683, grad/param norm = 4.2479e-01, time/batch = 0.7009s	
939/30300 (epoch 1.550), train_loss = 2.46991178, grad/param norm = 2.8989e-01, time/batch = 0.6912s	
940/30300 (epoch 1.551), train_loss = 2.29754811, grad/param norm = 2.5178e-01, time/batch = 0.6960s	
941/30300 (epoch 1.553), train_loss = 2.24544257, grad/param norm = 2.3363e-01, time/batch = 0.6902s	
942/30300 (epoch 1.554), train_loss = 2.40028714, grad/param norm = 2.4848e-01, time/batch = 0.6964s	
943/30300 (epoch 1.556), train_loss = 2.33298949, grad/param norm = 2.4586e-01, time/batch = 0.6886s	
944/30300 (epoch 1.558), train_loss = 2.36494981, grad/param norm = 2.3884e-01, time/batch = 0.6879s	
945/30300 (epoch 1.559), train_loss = 2.24104568, grad/param norm = 2.5912e-01, time/batch = 0.6839s	
946/30300 (epoch 1.561), train_loss = 2.21958022, grad/param norm = 3.0501e-01, time/batch = 0.6873s	
947/30300 (epoch 1.563), train_loss = 2.37978212, grad/param norm = 3.1323e-01, time/batch = 0.6883s	
948/30300 (epoch 1.564), train_loss = 2.29767757, grad/param norm = 2.4045e-01, time/batch = 0.6951s	
949/30300 (epoch 1.566), train_loss = 2.42597745, grad/param norm = 2.9052e-01, time/batch = 0.6882s	
950/30300 (epoch 1.568), train_loss = 2.15354816, grad/param norm = 3.9033e-01, time/batch = 0.6922s	
951/30300 (epoch 1.569), train_loss = 2.24792559, grad/param norm = 3.3500e-01, time/batch = 0.7147s	
952/30300 (epoch 1.571), train_loss = 2.33597765, grad/param norm = 3.0506e-01, time/batch = 0.7113s	
953/30300 (epoch 1.573), train_loss = 2.29662196, grad/param norm = 2.6456e-01, time/batch = 0.6897s	
954/30300 (epoch 1.574), train_loss = 2.34132395, grad/param norm = 2.9675e-01, time/batch = 0.7181s	
955/30300 (epoch 1.576), train_loss = 2.38567900, grad/param norm = 2.8681e-01, time/batch = 0.6919s	
956/30300 (epoch 1.578), train_loss = 2.17471441, grad/param norm = 2.2884e-01, time/batch = 0.6862s	
957/30300 (epoch 1.579), train_loss = 2.17988434, grad/param norm = 2.8181e-01, time/batch = 0.6892s	
958/30300 (epoch 1.581), train_loss = 2.44211901, grad/param norm = 3.5121e-01, time/batch = 0.6913s	
959/30300 (epoch 1.583), train_loss = 2.43462736, grad/param norm = 2.6132e-01, time/batch = 0.6917s	
960/30300 (epoch 1.584), train_loss = 2.37881290, grad/param norm = 2.3871e-01, time/batch = 0.6915s	
961/30300 (epoch 1.586), train_loss = 2.29112700, grad/param norm = 2.7979e-01, time/batch = 0.6908s	
962/30300 (epoch 1.587), train_loss = 2.23572440, grad/param norm = 2.7480e-01, time/batch = 0.6940s	
963/30300 (epoch 1.589), train_loss = 1.98491256, grad/param norm = 2.3780e-01, time/batch = 0.7016s	
964/30300 (epoch 1.591), train_loss = 2.25537527, grad/param norm = 2.8480e-01, time/batch = 0.7017s	
965/30300 (epoch 1.592), train_loss = 2.25001481, grad/param norm = 2.8291e-01, time/batch = 0.7046s	
966/30300 (epoch 1.594), train_loss = 2.30351149, grad/param norm = 2.8518e-01, time/batch = 0.7206s	
967/30300 (epoch 1.596), train_loss = 2.14467585, grad/param norm = 3.8881e-01, time/batch = 0.6912s	
968/30300 (epoch 1.597), train_loss = 2.27065553, grad/param norm = 2.8060e-01, time/batch = 0.6917s	
969/30300 (epoch 1.599), train_loss = 2.08358308, grad/param norm = 2.9136e-01, time/batch = 0.6915s	
970/30300 (epoch 1.601), train_loss = 2.25673884, grad/param norm = 2.7116e-01, time/batch = 0.6944s	
971/30300 (epoch 1.602), train_loss = 2.24280876, grad/param norm = 2.5517e-01, time/batch = 0.6926s	
972/30300 (epoch 1.604), train_loss = 2.24257813, grad/param norm = 3.2960e-01, time/batch = 0.6914s	
973/30300 (epoch 1.606), train_loss = 2.65489540, grad/param norm = 4.6744e-01, time/batch = 0.6911s	
974/30300 (epoch 1.607), train_loss = 2.42603633, grad/param norm = 3.4438e-01, time/batch = 0.6905s	
975/30300 (epoch 1.609), train_loss = 2.49046590, grad/param norm = 3.2400e-01, time/batch = 0.6915s	
976/30300 (epoch 1.611), train_loss = 2.10504778, grad/param norm = 2.6941e-01, time/batch = 0.6863s	
977/30300 (epoch 1.612), train_loss = 2.28802359, grad/param norm = 2.9404e-01, time/batch = 0.6921s	
978/30300 (epoch 1.614), train_loss = 2.15362533, grad/param norm = 3.7619e-01, time/batch = 0.6890s	
979/30300 (epoch 1.616), train_loss = 2.34761862, grad/param norm = 3.5182e-01, time/batch = 0.6994s	
980/30300 (epoch 1.617), train_loss = 2.33534609, grad/param norm = 3.1079e-01, time/batch = 0.7226s	
981/30300 (epoch 1.619), train_loss = 2.09159293, grad/param norm = 2.2017e-01, time/batch = 0.7077s	
982/30300 (epoch 1.620), train_loss = 2.37810174, grad/param norm = 2.6057e-01, time/batch = 0.6937s	
983/30300 (epoch 1.622), train_loss = 2.20286394, grad/param norm = 2.8971e-01, time/batch = 0.6881s	
984/30300 (epoch 1.624), train_loss = 2.19222358, grad/param norm = 2.8690e-01, time/batch = 0.6891s	
985/30300 (epoch 1.625), train_loss = 2.18901658, grad/param norm = 2.9073e-01, time/batch = 0.6916s	
986/30300 (epoch 1.627), train_loss = 2.41036289, grad/param norm = 2.5705e-01, time/batch = 0.6911s	
987/30300 (epoch 1.629), train_loss = 2.32550713, grad/param norm = 2.7549e-01, time/batch = 0.6917s	
988/30300 (epoch 1.630), train_loss = 2.30035560, grad/param norm = 2.6322e-01, time/batch = 0.6886s	
989/30300 (epoch 1.632), train_loss = 2.27147849, grad/param norm = 2.8251e-01, time/batch = 0.6980s	
990/30300 (epoch 1.634), train_loss = 2.02675395, grad/param norm = 2.1250e-01, time/batch = 0.6870s	
991/30300 (epoch 1.635), train_loss = 2.29388676, grad/param norm = 2.8955e-01, time/batch = 0.6896s	
992/30300 (epoch 1.637), train_loss = 2.22412933, grad/param norm = 3.2091e-01, time/batch = 0.6898s	
993/30300 (epoch 1.639), train_loss = 2.09318993, grad/param norm = 2.8098e-01, time/batch = 0.6916s	
994/30300 (epoch 1.640), train_loss = 2.30401378, grad/param norm = 3.1631e-01, time/batch = 0.7118s	
995/30300 (epoch 1.642), train_loss = 2.28710937, grad/param norm = 2.8323e-01, time/batch = 0.7117s	
996/30300 (epoch 1.644), train_loss = 2.28517830, grad/param norm = 2.4112e-01, time/batch = 0.6910s	
997/30300 (epoch 1.645), train_loss = 2.22674228, grad/param norm = 2.5957e-01, time/batch = 0.6877s	
998/30300 (epoch 1.647), train_loss = 2.25649893, grad/param norm = 3.6184e-01, time/batch = 0.6899s	
999/30300 (epoch 1.649), train_loss = 2.28004825, grad/param norm = 2.7810e-01, time/batch = 0.6885s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch1.65_2.2623.t7	
1000/30300 (epoch 1.650), train_loss = 2.23622516, grad/param norm = 2.8175e-01, time/batch = 0.6914s	
1001/30300 (epoch 1.652), train_loss = 2.17488348, grad/param norm = 2.6657e-01, time/batch = 0.6906s	
1002/30300 (epoch 1.653), train_loss = 2.37693830, grad/param norm = 3.1397e-01, time/batch = 0.6950s	
1003/30300 (epoch 1.655), train_loss = 2.25067970, grad/param norm = 2.5697e-01, time/batch = 0.6907s	
1004/30300 (epoch 1.657), train_loss = 2.35558167, grad/param norm = 2.3696e-01, time/batch = 0.6950s	
1005/30300 (epoch 1.658), train_loss = 2.20046745, grad/param norm = 2.6943e-01, time/batch = 0.6933s	
1006/30300 (epoch 1.660), train_loss = 2.26581659, grad/param norm = 2.6362e-01, time/batch = 0.6931s	
1007/30300 (epoch 1.662), train_loss = 2.22603708, grad/param norm = 2.5242e-01, time/batch = 0.7124s	
1008/30300 (epoch 1.663), train_loss = 2.24964640, grad/param norm = 2.7795e-01, time/batch = 0.6894s	
1009/30300 (epoch 1.665), train_loss = 2.10449250, grad/param norm = 2.3260e-01, time/batch = 0.6880s	
1010/30300 (epoch 1.667), train_loss = 2.34355965, grad/param norm = 2.6828e-01, time/batch = 0.6968s	
1011/30300 (epoch 1.668), train_loss = 2.37003870, grad/param norm = 2.7154e-01, time/batch = 0.6887s	
1012/30300 (epoch 1.670), train_loss = 2.25007693, grad/param norm = 2.6726e-01, time/batch = 0.6894s	
1013/30300 (epoch 1.672), train_loss = 2.35517908, grad/param norm = 2.4457e-01, time/batch = 0.7072s	
1014/30300 (epoch 1.673), train_loss = 2.23977000, grad/param norm = 2.4128e-01, time/batch = 0.7218s	
1015/30300 (epoch 1.675), train_loss = 2.16534054, grad/param norm = 3.0147e-01, time/batch = 0.7137s	
1016/30300 (epoch 1.677), train_loss = 2.20811563, grad/param norm = 3.4806e-01, time/batch = 0.6948s	
1017/30300 (epoch 1.678), train_loss = 2.23889665, grad/param norm = 2.8748e-01, time/batch = 0.6905s	
1018/30300 (epoch 1.680), train_loss = 2.00056291, grad/param norm = 2.9820e-01, time/batch = 0.6872s	
1019/30300 (epoch 1.682), train_loss = 2.18975258, grad/param norm = 2.5925e-01, time/batch = 0.6882s	
1020/30300 (epoch 1.683), train_loss = 2.28431125, grad/param norm = 2.3511e-01, time/batch = 0.6865s	
1021/30300 (epoch 1.685), train_loss = 2.37895229, grad/param norm = 3.0269e-01, time/batch = 0.6859s	
1022/30300 (epoch 1.686), train_loss = 2.23191828, grad/param norm = 2.3339e-01, time/batch = 0.6876s	
1023/30300 (epoch 1.688), train_loss = 2.32497406, grad/param norm = 2.7674e-01, time/batch = 0.7098s	
1024/30300 (epoch 1.690), train_loss = 2.23438527, grad/param norm = 3.3117e-01, time/batch = 0.6882s	
1025/30300 (epoch 1.691), train_loss = 2.28709287, grad/param norm = 4.7480e-01, time/batch = 0.6878s	
1026/30300 (epoch 1.693), train_loss = 2.53496570, grad/param norm = 3.6098e-01, time/batch = 0.6897s	
1027/30300 (epoch 1.695), train_loss = 2.35539523, grad/param norm = 2.9739e-01, time/batch = 0.6896s	
1028/30300 (epoch 1.696), train_loss = 2.39455045, grad/param norm = 3.1929e-01, time/batch = 0.6984s	
1029/30300 (epoch 1.698), train_loss = 2.21112586, grad/param norm = 2.4782e-01, time/batch = 0.7207s	
1030/30300 (epoch 1.700), train_loss = 2.17853700, grad/param norm = 2.3066e-01, time/batch = 0.6850s	
1031/30300 (epoch 1.701), train_loss = 2.01074359, grad/param norm = 2.2825e-01, time/batch = 0.6855s	
1032/30300 (epoch 1.703), train_loss = 2.12576509, grad/param norm = 2.2825e-01, time/batch = 0.6862s	
1033/30300 (epoch 1.705), train_loss = 2.28431812, grad/param norm = 3.0763e-01, time/batch = 0.6862s	
1034/30300 (epoch 1.706), train_loss = 2.11762725, grad/param norm = 3.0389e-01, time/batch = 0.6866s	
1035/30300 (epoch 1.708), train_loss = 2.22390001, grad/param norm = 2.7001e-01, time/batch = 0.6879s	
1036/30300 (epoch 1.710), train_loss = 2.12624228, grad/param norm = 2.6781e-01, time/batch = 0.6904s	
1037/30300 (epoch 1.711), train_loss = 2.13903530, grad/param norm = 2.2553e-01, time/batch = 0.6857s	
1038/30300 (epoch 1.713), train_loss = 2.03353620, grad/param norm = 2.6030e-01, time/batch = 0.6895s	
1039/30300 (epoch 1.715), train_loss = 2.23041164, grad/param norm = 2.7789e-01, time/batch = 0.6863s	
1040/30300 (epoch 1.716), train_loss = 2.37517168, grad/param norm = 2.6795e-01, time/batch = 0.6873s	
1041/30300 (epoch 1.718), train_loss = 2.37324472, grad/param norm = 2.8258e-01, time/batch = 0.6924s	
1042/30300 (epoch 1.719), train_loss = 2.17366019, grad/param norm = 2.5365e-01, time/batch = 0.6906s	
1043/30300 (epoch 1.721), train_loss = 2.20408730, grad/param norm = 2.3814e-01, time/batch = 0.7185s	
1044/30300 (epoch 1.723), train_loss = 2.14500789, grad/param norm = 2.3615e-01, time/batch = 0.7027s	
1045/30300 (epoch 1.724), train_loss = 2.23937139, grad/param norm = 2.6362e-01, time/batch = 0.6881s	
1046/30300 (epoch 1.726), train_loss = 2.56754028, grad/param norm = 2.9600e-01, time/batch = 0.6869s	
1047/30300 (epoch 1.728), train_loss = 2.11651654, grad/param norm = 2.9819e-01, time/batch = 0.6880s	
1048/30300 (epoch 1.729), train_loss = 2.26953563, grad/param norm = 3.6105e-01, time/batch = 0.6857s	
1049/30300 (epoch 1.731), train_loss = 2.26207652, grad/param norm = 2.6639e-01, time/batch = 0.6893s	
1050/30300 (epoch 1.733), train_loss = 2.18290214, grad/param norm = 2.2235e-01, time/batch = 0.6898s	
1051/30300 (epoch 1.734), train_loss = 2.20765972, grad/param norm = 2.2632e-01, time/batch = 0.6903s	
1052/30300 (epoch 1.736), train_loss = 2.19776161, grad/param norm = 2.9042e-01, time/batch = 0.7021s	
1053/30300 (epoch 1.738), train_loss = 2.07336240, grad/param norm = 2.3453e-01, time/batch = 0.6922s	
1054/30300 (epoch 1.739), train_loss = 2.32392222, grad/param norm = 2.4577e-01, time/batch = 0.6938s	
1055/30300 (epoch 1.741), train_loss = 2.30413364, grad/param norm = 2.7200e-01, time/batch = 0.6896s	
1056/30300 (epoch 1.743), train_loss = 2.09835196, grad/param norm = 2.5654e-01, time/batch = 0.7094s	
1057/30300 (epoch 1.744), train_loss = 2.32304200, grad/param norm = 2.8971e-01, time/batch = 0.7094s	
1058/30300 (epoch 1.746), train_loss = 2.06537267, grad/param norm = 2.5569e-01, time/batch = 0.7069s	
1059/30300 (epoch 1.748), train_loss = 2.25705460, grad/param norm = 3.3576e-01, time/batch = 0.6967s	
1060/30300 (epoch 1.749), train_loss = 2.24020896, grad/param norm = 3.6472e-01, time/batch = 0.6919s	
1061/30300 (epoch 1.751), train_loss = 2.17587766, grad/param norm = 2.8989e-01, time/batch = 0.6916s	
1062/30300 (epoch 1.752), train_loss = 2.10714958, grad/param norm = 2.8364e-01, time/batch = 0.6879s	
1063/30300 (epoch 1.754), train_loss = 2.04794142, grad/param norm = 2.3010e-01, time/batch = 0.6883s	
1064/30300 (epoch 1.756), train_loss = 2.10845570, grad/param norm = 2.5309e-01, time/batch = 0.6887s	
1065/30300 (epoch 1.757), train_loss = 2.30951823, grad/param norm = 2.6222e-01, time/batch = 0.6910s	
1066/30300 (epoch 1.759), train_loss = 2.09887631, grad/param norm = 3.3963e-01, time/batch = 0.6894s	
1067/30300 (epoch 1.761), train_loss = 2.16710575, grad/param norm = 3.3954e-01, time/batch = 0.6866s	
1068/30300 (epoch 1.762), train_loss = 1.98842399, grad/param norm = 2.6636e-01, time/batch = 0.6902s	
1069/30300 (epoch 1.764), train_loss = 2.12454306, grad/param norm = 2.5365e-01, time/batch = 0.6866s	
1070/30300 (epoch 1.766), train_loss = 2.21941946, grad/param norm = 2.3292e-01, time/batch = 0.6894s	
1071/30300 (epoch 1.767), train_loss = 2.31706193, grad/param norm = 2.6302e-01, time/batch = 0.6907s	
1072/30300 (epoch 1.769), train_loss = 2.32758216, grad/param norm = 2.6362e-01, time/batch = 0.6902s	
1073/30300 (epoch 1.771), train_loss = 2.22433765, grad/param norm = 2.3375e-01, time/batch = 0.6893s	
1074/30300 (epoch 1.772), train_loss = 2.14344085, grad/param norm = 2.3460e-01, time/batch = 0.6884s	
1075/30300 (epoch 1.774), train_loss = 2.26090940, grad/param norm = 2.5200e-01, time/batch = 0.6876s	
1076/30300 (epoch 1.776), train_loss = 2.15425629, grad/param norm = 2.2710e-01, time/batch = 0.7163s	
1077/30300 (epoch 1.777), train_loss = 2.19249699, grad/param norm = 2.5056e-01, time/batch = 0.7072s	
1078/30300 (epoch 1.779), train_loss = 2.26766312, grad/param norm = 2.5953e-01, time/batch = 0.6942s	
1079/30300 (epoch 1.781), train_loss = 2.17665065, grad/param norm = 2.7551e-01, time/batch = 0.6909s	
1080/30300 (epoch 1.782), train_loss = 2.05642816, grad/param norm = 2.7234e-01, time/batch = 0.6894s	
1081/30300 (epoch 1.784), train_loss = 2.34232786, grad/param norm = 2.6966e-01, time/batch = 0.6921s	
1082/30300 (epoch 1.785), train_loss = 2.36209050, grad/param norm = 2.5542e-01, time/batch = 0.6874s	
1083/30300 (epoch 1.787), train_loss = 2.23737905, grad/param norm = 2.3654e-01, time/batch = 0.6924s	
1084/30300 (epoch 1.789), train_loss = 2.56761709, grad/param norm = 2.4616e-01, time/batch = 0.6923s	
1085/30300 (epoch 1.790), train_loss = 2.32263766, grad/param norm = 2.4986e-01, time/batch = 0.6927s	
1086/30300 (epoch 1.792), train_loss = 2.18163897, grad/param norm = 2.8450e-01, time/batch = 0.6944s	
1087/30300 (epoch 1.794), train_loss = 2.13061567, grad/param norm = 2.7630e-01, time/batch = 0.6892s	
1088/30300 (epoch 1.795), train_loss = 2.21767881, grad/param norm = 2.4092e-01, time/batch = 0.6932s	
1089/30300 (epoch 1.797), train_loss = 2.27572634, grad/param norm = 2.9022e-01, time/batch = 0.6885s	
1090/30300 (epoch 1.799), train_loss = 2.37418486, grad/param norm = 4.1892e-01, time/batch = 0.7061s	
1091/30300 (epoch 1.800), train_loss = 2.15797739, grad/param norm = 3.0248e-01, time/batch = 0.7162s	
1092/30300 (epoch 1.802), train_loss = 2.32698288, grad/param norm = 2.7997e-01, time/batch = 0.6913s	
1093/30300 (epoch 1.804), train_loss = 2.29801864, grad/param norm = 2.7827e-01, time/batch = 0.7067s	
1094/30300 (epoch 1.805), train_loss = 2.31553018, grad/param norm = 2.6081e-01, time/batch = 0.7081s	
1095/30300 (epoch 1.807), train_loss = 2.31955620, grad/param norm = 2.8602e-01, time/batch = 0.7148s	
1096/30300 (epoch 1.809), train_loss = 2.38147169, grad/param norm = 2.4665e-01, time/batch = 0.7106s	
1097/30300 (epoch 1.810), train_loss = 2.26552548, grad/param norm = 2.1710e-01, time/batch = 0.7102s	
1098/30300 (epoch 1.812), train_loss = 2.19142567, grad/param norm = 2.4592e-01, time/batch = 0.7055s	
1099/30300 (epoch 1.814), train_loss = 2.31659482, grad/param norm = 2.5962e-01, time/batch = 0.6980s	
1100/30300 (epoch 1.815), train_loss = 2.24629728, grad/param norm = 3.1257e-01, time/batch = 0.6896s	
1101/30300 (epoch 1.817), train_loss = 2.23439900, grad/param norm = 2.5945e-01, time/batch = 0.6896s	
1102/30300 (epoch 1.818), train_loss = 2.19069375, grad/param norm = 2.4291e-01, time/batch = 0.6898s	
1103/30300 (epoch 1.820), train_loss = 2.42478863, grad/param norm = 3.0617e-01, time/batch = 0.6892s	
1104/30300 (epoch 1.822), train_loss = 2.36069910, grad/param norm = 3.0210e-01, time/batch = 0.6986s	
1105/30300 (epoch 1.823), train_loss = 2.45247526, grad/param norm = 3.0524e-01, time/batch = 0.7282s	
1106/30300 (epoch 1.825), train_loss = 2.28344948, grad/param norm = 2.8768e-01, time/batch = 0.6958s	
1107/30300 (epoch 1.827), train_loss = 2.19889675, grad/param norm = 2.4929e-01, time/batch = 0.6979s	
1108/30300 (epoch 1.828), train_loss = 2.23366318, grad/param norm = 2.0928e-01, time/batch = 0.7069s	
1109/30300 (epoch 1.830), train_loss = 2.22143080, grad/param norm = 2.6022e-01, time/batch = 0.6934s	
1110/30300 (epoch 1.832), train_loss = 2.08666672, grad/param norm = 2.5254e-01, time/batch = 0.6940s	
1111/30300 (epoch 1.833), train_loss = 2.26033974, grad/param norm = 2.4384e-01, time/batch = 0.7000s	
1112/30300 (epoch 1.835), train_loss = 2.27080969, grad/param norm = 2.4519e-01, time/batch = 0.6999s	
1113/30300 (epoch 1.837), train_loss = 2.02633931, grad/param norm = 2.3660e-01, time/batch = 0.6973s	
1114/30300 (epoch 1.838), train_loss = 2.13217544, grad/param norm = 2.3101e-01, time/batch = 0.6893s	
1115/30300 (epoch 1.840), train_loss = 2.16724510, grad/param norm = 2.5463e-01, time/batch = 0.6889s	
1116/30300 (epoch 1.842), train_loss = 2.08915513, grad/param norm = 2.8231e-01, time/batch = 0.6875s	
1117/30300 (epoch 1.843), train_loss = 2.20839229, grad/param norm = 2.9216e-01, time/batch = 0.6890s	
1118/30300 (epoch 1.845), train_loss = 2.02611442, grad/param norm = 2.4088e-01, time/batch = 0.6907s	
1119/30300 (epoch 1.847), train_loss = 2.15064887, grad/param norm = 2.6499e-01, time/batch = 0.6880s	
1120/30300 (epoch 1.848), train_loss = 2.32099036, grad/param norm = 3.0382e-01, time/batch = 0.6879s	
1121/30300 (epoch 1.850), train_loss = 2.12514348, grad/param norm = 3.2077e-01, time/batch = 0.6881s	
1122/30300 (epoch 1.851), train_loss = 2.43158275, grad/param norm = 2.6524e-01, time/batch = 0.6898s	
1123/30300 (epoch 1.853), train_loss = 2.21780122, grad/param norm = 2.5844e-01, time/batch = 0.7107s	
1124/30300 (epoch 1.855), train_loss = 2.16438076, grad/param norm = 2.7482e-01, time/batch = 0.7116s	
1125/30300 (epoch 1.856), train_loss = 2.14089278, grad/param norm = 2.7133e-01, time/batch = 0.6878s	
1126/30300 (epoch 1.858), train_loss = 2.03843244, grad/param norm = 2.4161e-01, time/batch = 0.6896s	
1127/30300 (epoch 1.860), train_loss = 2.26245479, grad/param norm = 2.5293e-01, time/batch = 0.6886s	
1128/30300 (epoch 1.861), train_loss = 2.29553576, grad/param norm = 3.4735e-01, time/batch = 0.6893s	
1129/30300 (epoch 1.863), train_loss = 2.29710258, grad/param norm = 3.4836e-01, time/batch = 0.6877s	
1130/30300 (epoch 1.865), train_loss = 2.49446389, grad/param norm = 2.8153e-01, time/batch = 0.6867s	
1131/30300 (epoch 1.866), train_loss = 2.18933801, grad/param norm = 2.6172e-01, time/batch = 0.6894s	
1132/30300 (epoch 1.868), train_loss = 2.26602839, grad/param norm = 2.7162e-01, time/batch = 0.6884s	
1133/30300 (epoch 1.870), train_loss = 2.18351160, grad/param norm = 2.9514e-01, time/batch = 0.6930s	
1134/30300 (epoch 1.871), train_loss = 2.10703059, grad/param norm = 2.1843e-01, time/batch = 0.6882s	
1135/30300 (epoch 1.873), train_loss = 2.28302300, grad/param norm = 2.3297e-01, time/batch = 0.6899s	
1136/30300 (epoch 1.875), train_loss = 2.09537781, grad/param norm = 2.3575e-01, time/batch = 0.6919s	
1137/30300 (epoch 1.876), train_loss = 2.03232174, grad/param norm = 2.1182e-01, time/batch = 0.6976s	
1138/30300 (epoch 1.878), train_loss = 2.05093610, grad/param norm = 2.5895e-01, time/batch = 0.7061s	
1139/30300 (epoch 1.880), train_loss = 2.04010364, grad/param norm = 2.3963e-01, time/batch = 0.6895s	
1140/30300 (epoch 1.881), train_loss = 2.30755663, grad/param norm = 2.4492e-01, time/batch = 0.6917s	
1141/30300 (epoch 1.883), train_loss = 2.15826519, grad/param norm = 2.3933e-01, time/batch = 0.6895s	
1142/30300 (epoch 1.884), train_loss = 2.10367890, grad/param norm = 2.2929e-01, time/batch = 0.7021s	
1143/30300 (epoch 1.886), train_loss = 2.07942569, grad/param norm = 2.1844e-01, time/batch = 0.7108s	
1144/30300 (epoch 1.888), train_loss = 2.30278869, grad/param norm = 2.4385e-01, time/batch = 0.6934s	
1145/30300 (epoch 1.889), train_loss = 2.18359816, grad/param norm = 2.8466e-01, time/batch = 0.6857s	
1146/30300 (epoch 1.891), train_loss = 2.17983129, grad/param norm = 3.2616e-01, time/batch = 0.6852s	
1147/30300 (epoch 1.893), train_loss = 2.27927503, grad/param norm = 2.5415e-01, time/batch = 0.6860s	
1148/30300 (epoch 1.894), train_loss = 2.23453906, grad/param norm = 2.8359e-01, time/batch = 0.6846s	
1149/30300 (epoch 1.896), train_loss = 2.07757031, grad/param norm = 2.7723e-01, time/batch = 0.6963s	
1150/30300 (epoch 1.898), train_loss = 2.01042300, grad/param norm = 2.4383e-01, time/batch = 0.7085s	
1151/30300 (epoch 1.899), train_loss = 2.17074915, grad/param norm = 2.5581e-01, time/batch = 0.7222s	
1152/30300 (epoch 1.901), train_loss = 2.25227491, grad/param norm = 2.4676e-01, time/batch = 0.7242s	
1153/30300 (epoch 1.903), train_loss = 2.26260024, grad/param norm = 2.4344e-01, time/batch = 0.7232s	
1154/30300 (epoch 1.904), train_loss = 2.17868964, grad/param norm = 2.6691e-01, time/batch = 0.7172s	
1155/30300 (epoch 1.906), train_loss = 2.23223444, grad/param norm = 2.4512e-01, time/batch = 0.7044s	
1156/30300 (epoch 1.908), train_loss = 2.20072167, grad/param norm = 2.5910e-01, time/batch = 0.7004s	
1157/30300 (epoch 1.909), train_loss = 2.31267187, grad/param norm = 2.5934e-01, time/batch = 0.6902s	
1158/30300 (epoch 1.911), train_loss = 2.11261546, grad/param norm = 2.5647e-01, time/batch = 0.6864s	
1159/30300 (epoch 1.913), train_loss = 2.17413665, grad/param norm = 2.2928e-01, time/batch = 0.6863s	
1160/30300 (epoch 1.914), train_loss = 2.27327424, grad/param norm = 2.8376e-01, time/batch = 0.6879s	
1161/30300 (epoch 1.916), train_loss = 2.20779584, grad/param norm = 2.9115e-01, time/batch = 0.6889s	
1162/30300 (epoch 1.917), train_loss = 2.14350449, grad/param norm = 2.7687e-01, time/batch = 0.6964s	
1163/30300 (epoch 1.919), train_loss = 2.24204163, grad/param norm = 2.6080e-01, time/batch = 0.6865s	
1164/30300 (epoch 1.921), train_loss = 2.29923339, grad/param norm = 2.4914e-01, time/batch = 0.6882s	
1165/30300 (epoch 1.922), train_loss = 2.28458324, grad/param norm = 2.4457e-01, time/batch = 0.6946s	
1166/30300 (epoch 1.924), train_loss = 2.17776278, grad/param norm = 2.8814e-01, time/batch = 0.7126s	
1167/30300 (epoch 1.926), train_loss = 2.18901862, grad/param norm = 3.4942e-01, time/batch = 0.7098s	
1168/30300 (epoch 1.927), train_loss = 2.11771896, grad/param norm = 3.3739e-01, time/batch = 0.6869s	
1169/30300 (epoch 1.929), train_loss = 2.25863923, grad/param norm = 3.7597e-01, time/batch = 0.6857s	
1170/30300 (epoch 1.931), train_loss = 2.29064396, grad/param norm = 3.2777e-01, time/batch = 0.6849s	
1171/30300 (epoch 1.932), train_loss = 2.12932887, grad/param norm = 2.5401e-01, time/batch = 0.6901s	
1172/30300 (epoch 1.934), train_loss = 2.16087989, grad/param norm = 2.6499e-01, time/batch = 0.6865s	
1173/30300 (epoch 1.936), train_loss = 2.14724996, grad/param norm = 2.2926e-01, time/batch = 0.6852s	
1174/30300 (epoch 1.937), train_loss = 2.21285252, grad/param norm = 2.6120e-01, time/batch = 0.6875s	
1175/30300 (epoch 1.939), train_loss = 2.24521975, grad/param norm = 2.5629e-01, time/batch = 0.6834s	
1176/30300 (epoch 1.941), train_loss = 2.23290030, grad/param norm = 2.4649e-01, time/batch = 0.6922s	
1177/30300 (epoch 1.942), train_loss = 2.09118528, grad/param norm = 2.6476e-01, time/batch = 0.6846s	
1178/30300 (epoch 1.944), train_loss = 2.05191334, grad/param norm = 2.5628e-01, time/batch = 0.6881s	
1179/30300 (epoch 1.946), train_loss = 2.36874401, grad/param norm = 2.4669e-01, time/batch = 0.7098s	
1180/30300 (epoch 1.947), train_loss = 2.32697779, grad/param norm = 2.4826e-01, time/batch = 0.7072s	
1181/30300 (epoch 1.949), train_loss = 2.38358287, grad/param norm = 2.2050e-01, time/batch = 0.7224s	
1182/30300 (epoch 1.950), train_loss = 2.30719172, grad/param norm = 2.3208e-01, time/batch = 0.6917s	
1183/30300 (epoch 1.952), train_loss = 2.31464088, grad/param norm = 2.8402e-01, time/batch = 0.7057s	
1184/30300 (epoch 1.954), train_loss = 2.32124463, grad/param norm = 2.4351e-01, time/batch = 0.6890s	
1185/30300 (epoch 1.955), train_loss = 2.16996441, grad/param norm = 2.6751e-01, time/batch = 0.6910s	
1186/30300 (epoch 1.957), train_loss = 2.28403355, grad/param norm = 2.8665e-01, time/batch = 0.7143s	
1187/30300 (epoch 1.959), train_loss = 2.27087416, grad/param norm = 2.4239e-01, time/batch = 0.6892s	
1188/30300 (epoch 1.960), train_loss = 2.13780989, grad/param norm = 2.1730e-01, time/batch = 0.6935s	
1189/30300 (epoch 1.962), train_loss = 2.14456487, grad/param norm = 2.5782e-01, time/batch = 0.6939s	
1190/30300 (epoch 1.964), train_loss = 2.29272834, grad/param norm = 3.3583e-01, time/batch = 0.6891s	
1191/30300 (epoch 1.965), train_loss = 2.15068767, grad/param norm = 2.7213e-01, time/batch = 0.6901s	
1192/30300 (epoch 1.967), train_loss = 2.23983918, grad/param norm = 2.8692e-01, time/batch = 0.6901s	
1193/30300 (epoch 1.969), train_loss = 2.12795655, grad/param norm = 2.5005e-01, time/batch = 0.6894s	
1194/30300 (epoch 1.970), train_loss = 2.17998854, grad/param norm = 3.1129e-01, time/batch = 0.6905s	
1195/30300 (epoch 1.972), train_loss = 2.08124297, grad/param norm = 2.6212e-01, time/batch = 0.6897s	
1196/30300 (epoch 1.974), train_loss = 2.32644160, grad/param norm = 2.9618e-01, time/batch = 0.6896s	
1197/30300 (epoch 1.975), train_loss = 2.31780594, grad/param norm = 2.5702e-01, time/batch = 0.6909s	
1198/30300 (epoch 1.977), train_loss = 2.15966652, grad/param norm = 2.3810e-01, time/batch = 0.6944s	
1199/30300 (epoch 1.979), train_loss = 2.29288423, grad/param norm = 2.5509e-01, time/batch = 0.7195s	
1200/30300 (epoch 1.980), train_loss = 2.25877253, grad/param norm = 2.4712e-01, time/batch = 0.7133s	
1201/30300 (epoch 1.982), train_loss = 2.24507990, grad/param norm = 2.1675e-01, time/batch = 0.7033s	
1202/30300 (epoch 1.983), train_loss = 2.29055080, grad/param norm = 2.9902e-01, time/batch = 0.6906s	
1203/30300 (epoch 1.985), train_loss = 2.26511307, grad/param norm = 3.7497e-01, time/batch = 0.6890s	
1204/30300 (epoch 1.987), train_loss = 2.09417866, grad/param norm = 2.6666e-01, time/batch = 0.6891s	
1205/30300 (epoch 1.988), train_loss = 2.34484318, grad/param norm = 2.5609e-01, time/batch = 0.6889s	
1206/30300 (epoch 1.990), train_loss = 2.00183026, grad/param norm = 1.9740e-01, time/batch = 0.6877s	
1207/30300 (epoch 1.992), train_loss = 2.17576541, grad/param norm = 2.1843e-01, time/batch = 0.6869s	
1208/30300 (epoch 1.993), train_loss = 2.36470970, grad/param norm = 2.6594e-01, time/batch = 0.6903s	
1209/30300 (epoch 1.995), train_loss = 2.29748357, grad/param norm = 2.5127e-01, time/batch = 0.6897s	
1210/30300 (epoch 1.997), train_loss = 2.20547187, grad/param norm = 2.3073e-01, time/batch = 0.6876s	
1211/30300 (epoch 1.998), train_loss = 2.22770926, grad/param norm = 2.4650e-01, time/batch = 0.7013s	
1212/30300 (epoch 2.000), train_loss = 2.08752385, grad/param norm = 2.5045e-01, time/batch = 0.6898s	
1213/30300 (epoch 2.002), train_loss = 2.10801996, grad/param norm = 2.2376e-01, time/batch = 0.7023s	
1214/30300 (epoch 2.003), train_loss = 2.21861891, grad/param norm = 2.2823e-01, time/batch = 0.7184s	
1215/30300 (epoch 2.005), train_loss = 2.24274430, grad/param norm = 2.7140e-01, time/batch = 0.6887s	
1216/30300 (epoch 2.007), train_loss = 2.26199627, grad/param norm = 2.1921e-01, time/batch = 0.6864s	
1217/30300 (epoch 2.008), train_loss = 2.12056337, grad/param norm = 2.3015e-01, time/batch = 0.6846s	
1218/30300 (epoch 2.010), train_loss = 2.19955105, grad/param norm = 2.5159e-01, time/batch = 0.6868s	
1219/30300 (epoch 2.012), train_loss = 2.10798076, grad/param norm = 2.2676e-01, time/batch = 0.6885s	
1220/30300 (epoch 2.013), train_loss = 2.27071861, grad/param norm = 2.3086e-01, time/batch = 0.7050s	
1221/30300 (epoch 2.015), train_loss = 2.20224321, grad/param norm = 2.8004e-01, time/batch = 0.7046s	
1222/30300 (epoch 2.017), train_loss = 2.04501643, grad/param norm = 3.5359e-01, time/batch = 0.7109s	
1223/30300 (epoch 2.018), train_loss = 2.25754069, grad/param norm = 2.6688e-01, time/batch = 0.7177s	
1224/30300 (epoch 2.020), train_loss = 2.34866946, grad/param norm = 2.9436e-01, time/batch = 0.7068s	
1225/30300 (epoch 2.021), train_loss = 2.26854683, grad/param norm = 3.2208e-01, time/batch = 0.7009s	
1226/30300 (epoch 2.023), train_loss = 2.11208309, grad/param norm = 3.1119e-01, time/batch = 0.7130s	
1227/30300 (epoch 2.025), train_loss = 2.12257333, grad/param norm = 2.5911e-01, time/batch = 0.7087s	
1228/30300 (epoch 2.026), train_loss = 2.16201108, grad/param norm = 2.3270e-01, time/batch = 0.7218s	
1229/30300 (epoch 2.028), train_loss = 2.17432887, grad/param norm = 2.5287e-01, time/batch = 0.7045s	
1230/30300 (epoch 2.030), train_loss = 2.02238467, grad/param norm = 2.4073e-01, time/batch = 0.6933s	
1231/30300 (epoch 2.031), train_loss = 2.13473752, grad/param norm = 2.6837e-01, time/batch = 0.6873s	
1232/30300 (epoch 2.033), train_loss = 2.17568357, grad/param norm = 2.8994e-01, time/batch = 0.6920s	
1233/30300 (epoch 2.035), train_loss = 2.21404532, grad/param norm = 2.5455e-01, time/batch = 0.6905s	
1234/30300 (epoch 2.036), train_loss = 2.37488426, grad/param norm = 2.7173e-01, time/batch = 0.7016s	
1235/30300 (epoch 2.038), train_loss = 2.22166215, grad/param norm = 2.3984e-01, time/batch = 0.6972s	
1236/30300 (epoch 2.040), train_loss = 1.83752677, grad/param norm = 2.0364e-01, time/batch = 0.6897s	
1237/30300 (epoch 2.041), train_loss = 2.03056096, grad/param norm = 2.4152e-01, time/batch = 0.6867s	
1238/30300 (epoch 2.043), train_loss = 2.20217395, grad/param norm = 2.3265e-01, time/batch = 0.6898s	
1239/30300 (epoch 2.045), train_loss = 2.07948925, grad/param norm = 2.4422e-01, time/batch = 0.6905s	
1240/30300 (epoch 2.046), train_loss = 2.12858590, grad/param norm = 2.3367e-01, time/batch = 0.6879s	
1241/30300 (epoch 2.048), train_loss = 2.16414727, grad/param norm = 2.7352e-01, time/batch = 0.6882s	
1242/30300 (epoch 2.050), train_loss = 2.32420125, grad/param norm = 2.5918e-01, time/batch = 0.7189s	
1243/30300 (epoch 2.051), train_loss = 2.16029829, grad/param norm = 2.3466e-01, time/batch = 0.7042s	
1244/30300 (epoch 2.053), train_loss = 2.05664857, grad/param norm = 2.7990e-01, time/batch = 0.6898s	
1245/30300 (epoch 2.054), train_loss = 2.05542350, grad/param norm = 3.0484e-01, time/batch = 0.6874s	
1246/30300 (epoch 2.056), train_loss = 2.07829572, grad/param norm = 2.5034e-01, time/batch = 0.6866s	
1247/30300 (epoch 2.058), train_loss = 2.24511477, grad/param norm = 2.7678e-01, time/batch = 0.6860s	
1248/30300 (epoch 2.059), train_loss = 2.22955725, grad/param norm = 2.6517e-01, time/batch = 0.6881s	
1249/30300 (epoch 2.061), train_loss = 2.25554434, grad/param norm = 3.0968e-01, time/batch = 0.6875s	
1250/30300 (epoch 2.063), train_loss = 2.12444363, grad/param norm = 2.5591e-01, time/batch = 0.6851s	
1251/30300 (epoch 2.064), train_loss = 2.26261657, grad/param norm = 2.6010e-01, time/batch = 0.6864s	
1252/30300 (epoch 2.066), train_loss = 2.17876125, grad/param norm = 2.4890e-01, time/batch = 0.6841s	
1253/30300 (epoch 2.068), train_loss = 2.01507933, grad/param norm = 2.1936e-01, time/batch = 0.6883s	
1254/30300 (epoch 2.069), train_loss = 2.26399549, grad/param norm = 2.4112e-01, time/batch = 0.6871s	
1255/30300 (epoch 2.071), train_loss = 2.21801206, grad/param norm = 2.6021e-01, time/batch = 0.6877s	
1256/30300 (epoch 2.073), train_loss = 2.31814367, grad/param norm = 2.9043e-01, time/batch = 0.7017s	
1257/30300 (epoch 2.074), train_loss = 2.25507601, grad/param norm = 2.5649e-01, time/batch = 0.7169s	
1258/30300 (epoch 2.076), train_loss = 2.09688165, grad/param norm = 2.8356e-01, time/batch = 0.6844s	
1259/30300 (epoch 2.078), train_loss = 1.98763546, grad/param norm = 2.7165e-01, time/batch = 0.6857s	
1260/30300 (epoch 2.079), train_loss = 1.95797637, grad/param norm = 2.1070e-01, time/batch = 0.6854s	
1261/30300 (epoch 2.081), train_loss = 2.33302530, grad/param norm = 2.4119e-01, time/batch = 0.6891s	
1262/30300 (epoch 2.083), train_loss = 2.40701830, grad/param norm = 2.4738e-01, time/batch = 0.6885s	
1263/30300 (epoch 2.084), train_loss = 2.10860894, grad/param norm = 2.6128e-01, time/batch = 0.6897s	
1264/30300 (epoch 2.086), train_loss = 2.17390672, grad/param norm = 2.5071e-01, time/batch = 0.6909s	
1265/30300 (epoch 2.087), train_loss = 2.05244713, grad/param norm = 2.2329e-01, time/batch = 0.7096s	
1266/30300 (epoch 2.089), train_loss = 2.17354585, grad/param norm = 2.6472e-01, time/batch = 0.7179s	
1267/30300 (epoch 2.091), train_loss = 2.24134254, grad/param norm = 2.5970e-01, time/batch = 0.7128s	
1268/30300 (epoch 2.092), train_loss = 2.04965576, grad/param norm = 2.5684e-01, time/batch = 0.6984s	
1269/30300 (epoch 2.094), train_loss = 2.36616510, grad/param norm = 2.4134e-01, time/batch = 0.6862s	
1270/30300 (epoch 2.096), train_loss = 2.14842598, grad/param norm = 3.6224e-01, time/batch = 0.6911s	
1271/30300 (epoch 2.097), train_loss = 2.10794920, grad/param norm = 2.9486e-01, time/batch = 0.7220s	
1272/30300 (epoch 2.099), train_loss = 2.37510159, grad/param norm = 3.5467e-01, time/batch = 0.7210s	
1273/30300 (epoch 2.101), train_loss = 2.33869517, grad/param norm = 2.3945e-01, time/batch = 0.6981s	
1274/30300 (epoch 2.102), train_loss = 2.27226559, grad/param norm = 2.5141e-01, time/batch = 0.6912s	
1275/30300 (epoch 2.104), train_loss = 2.04236218, grad/param norm = 2.2289e-01, time/batch = 0.6908s	
1276/30300 (epoch 2.106), train_loss = 2.30045124, grad/param norm = 3.5958e-01, time/batch = 0.6933s	
1277/30300 (epoch 2.107), train_loss = 2.13638388, grad/param norm = 2.3200e-01, time/batch = 0.6915s	
1278/30300 (epoch 2.109), train_loss = 2.24485914, grad/param norm = 2.7059e-01, time/batch = 0.6878s	
1279/30300 (epoch 2.111), train_loss = 2.18904814, grad/param norm = 2.6737e-01, time/batch = 0.6901s	
1280/30300 (epoch 2.112), train_loss = 2.19047071, grad/param norm = 2.9063e-01, time/batch = 0.6881s	
1281/30300 (epoch 2.114), train_loss = 2.08560318, grad/param norm = 2.4286e-01, time/batch = 0.7021s	
1282/30300 (epoch 2.116), train_loss = 2.17631169, grad/param norm = 2.4788e-01, time/batch = 0.6968s	
1283/30300 (epoch 2.117), train_loss = 2.08696397, grad/param norm = 2.2103e-01, time/batch = 0.6909s	
1284/30300 (epoch 2.119), train_loss = 1.99270848, grad/param norm = 2.6327e-01, time/batch = 0.6941s	
1285/30300 (epoch 2.120), train_loss = 2.05146461, grad/param norm = 2.7532e-01, time/batch = 0.7204s	
1286/30300 (epoch 2.122), train_loss = 2.22790459, grad/param norm = 2.3867e-01, time/batch = 0.7000s	
1287/30300 (epoch 2.124), train_loss = 2.27798031, grad/param norm = 2.4230e-01, time/batch = 0.6886s	
1288/30300 (epoch 2.125), train_loss = 1.99558043, grad/param norm = 2.4851e-01, time/batch = 0.6871s	
1289/30300 (epoch 2.127), train_loss = 2.18236233, grad/param norm = 2.5134e-01, time/batch = 0.6896s	
1290/30300 (epoch 2.129), train_loss = 2.25370701, grad/param norm = 2.2333e-01, time/batch = 0.6905s	
1291/30300 (epoch 2.130), train_loss = 2.25161650, grad/param norm = 2.3805e-01, time/batch = 0.6926s	
1292/30300 (epoch 2.132), train_loss = 2.13094237, grad/param norm = 2.9132e-01, time/batch = 0.6983s	
1293/30300 (epoch 2.134), train_loss = 2.02860034, grad/param norm = 2.9587e-01, time/batch = 0.6904s	
1294/30300 (epoch 2.135), train_loss = 2.17731982, grad/param norm = 2.3661e-01, time/batch = 0.7011s	
1295/30300 (epoch 2.137), train_loss = 2.26677053, grad/param norm = 2.4727e-01, time/batch = 0.6891s	
1296/30300 (epoch 2.139), train_loss = 2.14095583, grad/param norm = 2.8346e-01, time/batch = 0.6922s	
1297/30300 (epoch 2.140), train_loss = 2.61390206, grad/param norm = 5.0728e-01, time/batch = 0.6922s	
1298/30300 (epoch 2.142), train_loss = 2.34394147, grad/param norm = 2.7726e-01, time/batch = 0.6883s	
1299/30300 (epoch 2.144), train_loss = 2.22413510, grad/param norm = 2.6732e-01, time/batch = 0.7046s	
1300/30300 (epoch 2.145), train_loss = 2.30497508, grad/param norm = 2.3743e-01, time/batch = 0.7144s	
1301/30300 (epoch 2.147), train_loss = 2.24766745, grad/param norm = 2.5913e-01, time/batch = 0.7024s	
1302/30300 (epoch 2.149), train_loss = 2.33138345, grad/param norm = 2.6100e-01, time/batch = 0.6899s	
1303/30300 (epoch 2.150), train_loss = 2.33281079, grad/param norm = 2.0745e-01, time/batch = 0.6884s	
1304/30300 (epoch 2.152), train_loss = 2.16895636, grad/param norm = 2.9935e-01, time/batch = 0.6901s	
1305/30300 (epoch 2.153), train_loss = 2.22781037, grad/param norm = 2.5915e-01, time/batch = 0.6908s	
1306/30300 (epoch 2.155), train_loss = 1.98308738, grad/param norm = 2.1824e-01, time/batch = 0.6871s	
1307/30300 (epoch 2.157), train_loss = 2.18097173, grad/param norm = 2.2026e-01, time/batch = 0.6910s	
1308/30300 (epoch 2.158), train_loss = 2.24673753, grad/param norm = 2.2247e-01, time/batch = 0.6879s	
1309/30300 (epoch 2.160), train_loss = 2.07312169, grad/param norm = 2.7734e-01, time/batch = 0.6857s	
1310/30300 (epoch 2.162), train_loss = 2.05873539, grad/param norm = 3.1064e-01, time/batch = 0.6881s	
1311/30300 (epoch 2.163), train_loss = 2.05358236, grad/param norm = 2.7875e-01, time/batch = 0.7004s	
1312/30300 (epoch 2.165), train_loss = 2.19995117, grad/param norm = 2.9143e-01, time/batch = 0.6883s	
1313/30300 (epoch 2.167), train_loss = 2.21757167, grad/param norm = 2.5870e-01, time/batch = 0.6942s	
1314/30300 (epoch 2.168), train_loss = 2.05653867, grad/param norm = 2.7146e-01, time/batch = 0.7205s	
1315/30300 (epoch 2.170), train_loss = 2.21438948, grad/param norm = 2.5779e-01, time/batch = 0.6997s	
1316/30300 (epoch 2.172), train_loss = 2.08417349, grad/param norm = 2.0875e-01, time/batch = 0.6852s	
1317/30300 (epoch 2.173), train_loss = 2.24092221, grad/param norm = 2.6342e-01, time/batch = 0.6863s	
1318/30300 (epoch 2.175), train_loss = 2.15202799, grad/param norm = 2.7417e-01, time/batch = 0.6974s	
1319/30300 (epoch 2.177), train_loss = 2.23190688, grad/param norm = 2.3242e-01, time/batch = 0.7093s	
1320/30300 (epoch 2.178), train_loss = 1.97115813, grad/param norm = 2.2214e-01, time/batch = 0.6964s	
1321/30300 (epoch 2.180), train_loss = 2.09203645, grad/param norm = 2.3059e-01, time/batch = 0.6946s	
1322/30300 (epoch 2.182), train_loss = 2.09123969, grad/param norm = 2.2546e-01, time/batch = 0.6870s	
1323/30300 (epoch 2.183), train_loss = 2.03983539, grad/param norm = 2.3296e-01, time/batch = 0.6884s	
1324/30300 (epoch 2.185), train_loss = 2.47895015, grad/param norm = 2.4897e-01, time/batch = 0.6861s	
1325/30300 (epoch 2.186), train_loss = 2.30044482, grad/param norm = 2.4997e-01, time/batch = 0.6868s	
1326/30300 (epoch 2.188), train_loss = 2.16197864, grad/param norm = 2.4140e-01, time/batch = 0.6850s	
1327/30300 (epoch 2.190), train_loss = 2.03266358, grad/param norm = 2.2381e-01, time/batch = 0.6855s	
1328/30300 (epoch 2.191), train_loss = 2.23585516, grad/param norm = 2.3223e-01, time/batch = 0.7148s	
1329/30300 (epoch 2.193), train_loss = 2.04934942, grad/param norm = 2.4932e-01, time/batch = 0.7042s	
1330/30300 (epoch 2.195), train_loss = 2.19513286, grad/param norm = 2.8696e-01, time/batch = 0.6884s	
1331/30300 (epoch 2.196), train_loss = 2.29088945, grad/param norm = 3.0915e-01, time/batch = 0.6885s	
1332/30300 (epoch 2.198), train_loss = 1.90350859, grad/param norm = 2.4450e-01, time/batch = 0.6887s	
1333/30300 (epoch 2.200), train_loss = 2.13779935, grad/param norm = 3.0043e-01, time/batch = 0.6901s	
1334/30300 (epoch 2.201), train_loss = 2.30654508, grad/param norm = 2.4479e-01, time/batch = 0.6866s	
1335/30300 (epoch 2.203), train_loss = 2.14897041, grad/param norm = 2.2325e-01, time/batch = 0.6902s	
1336/30300 (epoch 2.205), train_loss = 2.33902778, grad/param norm = 2.2174e-01, time/batch = 0.6873s	
1337/30300 (epoch 2.206), train_loss = 2.34409685, grad/param norm = 2.5087e-01, time/batch = 0.6903s	
1338/30300 (epoch 2.208), train_loss = 2.34170951, grad/param norm = 2.6163e-01, time/batch = 0.6946s	
1339/30300 (epoch 2.210), train_loss = 2.17305786, grad/param norm = 2.4084e-01, time/batch = 0.6882s	
1340/30300 (epoch 2.211), train_loss = 2.15963287, grad/param norm = 2.1921e-01, time/batch = 0.6883s	
1341/30300 (epoch 2.213), train_loss = 2.15016496, grad/param norm = 2.5233e-01, time/batch = 0.6863s	
1342/30300 (epoch 2.215), train_loss = 1.94692946, grad/param norm = 2.1530e-01, time/batch = 0.6871s	
1343/30300 (epoch 2.216), train_loss = 2.19075886, grad/param norm = 2.6494e-01, time/batch = 0.6872s	
1344/30300 (epoch 2.218), train_loss = 2.11880620, grad/param norm = 2.6237e-01, time/batch = 0.6849s	
1345/30300 (epoch 2.219), train_loss = 2.01676772, grad/param norm = 2.6151e-01, time/batch = 0.6849s	
1346/30300 (epoch 2.221), train_loss = 1.99511988, grad/param norm = 2.3776e-01, time/batch = 0.6886s	
1347/30300 (epoch 2.223), train_loss = 2.05231287, grad/param norm = 2.1592e-01, time/batch = 0.6859s	
1348/30300 (epoch 2.224), train_loss = 1.88752525, grad/param norm = 2.0685e-01, time/batch = 0.6868s	
1349/30300 (epoch 2.226), train_loss = 2.20342955, grad/param norm = 2.4267e-01, time/batch = 0.6891s	
1350/30300 (epoch 2.228), train_loss = 2.13458691, grad/param norm = 2.6387e-01, time/batch = 0.6849s	
1351/30300 (epoch 2.229), train_loss = 1.99519995, grad/param norm = 2.6505e-01, time/batch = 0.7139s	
1352/30300 (epoch 2.231), train_loss = 2.12754137, grad/param norm = 2.8753e-01, time/batch = 0.7021s	
1353/30300 (epoch 2.233), train_loss = 2.02709969, grad/param norm = 2.0400e-01, time/batch = 0.7012s	
1354/30300 (epoch 2.234), train_loss = 2.19242140, grad/param norm = 2.3464e-01, time/batch = 0.6929s	
1355/30300 (epoch 2.236), train_loss = 2.10305639, grad/param norm = 2.9077e-01, time/batch = 0.6910s	
1356/30300 (epoch 2.238), train_loss = 2.25524007, grad/param norm = 3.3847e-01, time/batch = 0.6961s	
1357/30300 (epoch 2.239), train_loss = 2.09620289, grad/param norm = 2.7684e-01, time/batch = 0.7205s	
1358/30300 (epoch 2.241), train_loss = 2.09508787, grad/param norm = 2.3104e-01, time/batch = 0.6979s	
1359/30300 (epoch 2.243), train_loss = 2.09874479, grad/param norm = 2.5153e-01, time/batch = 0.6914s	
1360/30300 (epoch 2.244), train_loss = 2.40767844, grad/param norm = 2.7310e-01, time/batch = 0.7032s	
1361/30300 (epoch 2.246), train_loss = 2.07796991, grad/param norm = 2.3393e-01, time/batch = 0.6973s	
1362/30300 (epoch 2.248), train_loss = 2.22395930, grad/param norm = 2.0839e-01, time/batch = 0.6923s	
1363/30300 (epoch 2.249), train_loss = 1.95062740, grad/param norm = 2.4573e-01, time/batch = 0.6927s	
1364/30300 (epoch 2.251), train_loss = 2.02922179, grad/param norm = 2.3557e-01, time/batch = 0.6891s	
1365/30300 (epoch 2.252), train_loss = 2.29474391, grad/param norm = 2.5246e-01, time/batch = 0.6901s	
1366/30300 (epoch 2.254), train_loss = 2.15257526, grad/param norm = 2.1007e-01, time/batch = 0.6937s	
1367/30300 (epoch 2.256), train_loss = 2.15660933, grad/param norm = 2.3379e-01, time/batch = 0.6908s	
1368/30300 (epoch 2.257), train_loss = 2.28229360, grad/param norm = 2.1275e-01, time/batch = 0.6884s	
1369/30300 (epoch 2.259), train_loss = 2.18272398, grad/param norm = 2.4817e-01, time/batch = 0.6881s	
1370/30300 (epoch 2.261), train_loss = 2.29825785, grad/param norm = 2.3682e-01, time/batch = 0.6931s	
1371/30300 (epoch 2.262), train_loss = 2.08881969, grad/param norm = 2.1436e-01, time/batch = 0.6945s	
1372/30300 (epoch 2.264), train_loss = 2.14575335, grad/param norm = 2.4975e-01, time/batch = 0.7044s	
1373/30300 (epoch 2.266), train_loss = 2.05295215, grad/param norm = 2.1816e-01, time/batch = 0.6903s	
1374/30300 (epoch 2.267), train_loss = 2.24612169, grad/param norm = 2.5071e-01, time/batch = 0.6946s	
1375/30300 (epoch 2.269), train_loss = 2.18628280, grad/param norm = 2.3402e-01, time/batch = 0.6876s	
1376/30300 (epoch 2.271), train_loss = 2.15006741, grad/param norm = 2.6560e-01, time/batch = 0.6867s	
1377/30300 (epoch 2.272), train_loss = 2.16703830, grad/param norm = 2.2028e-01, time/batch = 0.6910s	
1378/30300 (epoch 2.274), train_loss = 2.26853877, grad/param norm = 2.3361e-01, time/batch = 0.6923s	
1379/30300 (epoch 2.276), train_loss = 2.28754483, grad/param norm = 2.7733e-01, time/batch = 0.6988s	
1380/30300 (epoch 2.277), train_loss = 2.07003636, grad/param norm = 2.6073e-01, time/batch = 0.6911s	
1381/30300 (epoch 2.279), train_loss = 2.15110933, grad/param norm = 2.2055e-01, time/batch = 0.6922s	
1382/30300 (epoch 2.281), train_loss = 2.15342606, grad/param norm = 2.5092e-01, time/batch = 0.6851s	
1383/30300 (epoch 2.282), train_loss = 2.05934410, grad/param norm = 2.8327e-01, time/batch = 0.6905s	
1384/30300 (epoch 2.284), train_loss = 2.33505273, grad/param norm = 2.6203e-01, time/batch = 0.6958s	
1385/30300 (epoch 2.285), train_loss = 2.20517065, grad/param norm = 2.1907e-01, time/batch = 0.7046s	
1386/30300 (epoch 2.287), train_loss = 2.22194616, grad/param norm = 2.4952e-01, time/batch = 0.7204s	
1387/30300 (epoch 2.289), train_loss = 2.11843225, grad/param norm = 2.6495e-01, time/batch = 0.6871s	
1388/30300 (epoch 2.290), train_loss = 1.85641271, grad/param norm = 2.1638e-01, time/batch = 0.6900s	
1389/30300 (epoch 2.292), train_loss = 2.00843876, grad/param norm = 2.3018e-01, time/batch = 0.6874s	
1390/30300 (epoch 2.294), train_loss = 2.29535046, grad/param norm = 2.4451e-01, time/batch = 0.6892s	
1391/30300 (epoch 2.295), train_loss = 2.09033568, grad/param norm = 2.7436e-01, time/batch = 0.6916s	
1392/30300 (epoch 2.297), train_loss = 2.06229483, grad/param norm = 2.4033e-01, time/batch = 0.6894s	
1393/30300 (epoch 2.299), train_loss = 2.20198169, grad/param norm = 2.5987e-01, time/batch = 0.6961s	
1394/30300 (epoch 2.300), train_loss = 2.08723824, grad/param norm = 2.1113e-01, time/batch = 0.6944s	
1395/30300 (epoch 2.302), train_loss = 2.00308316, grad/param norm = 2.3360e-01, time/batch = 0.6922s	
1396/30300 (epoch 2.304), train_loss = 2.02460222, grad/param norm = 2.3535e-01, time/batch = 0.6902s	
1397/30300 (epoch 2.305), train_loss = 2.10431435, grad/param norm = 2.2100e-01, time/batch = 0.6962s	
1398/30300 (epoch 2.307), train_loss = 2.06906300, grad/param norm = 2.5555e-01, time/batch = 0.6928s	
1399/30300 (epoch 2.309), train_loss = 2.26586778, grad/param norm = 2.4445e-01, time/batch = 0.6913s	
1400/30300 (epoch 2.310), train_loss = 2.01613126, grad/param norm = 2.3806e-01, time/batch = 0.6933s	
1401/30300 (epoch 2.312), train_loss = 2.11339515, grad/param norm = 2.9968e-01, time/batch = 0.6875s	
1402/30300 (epoch 2.314), train_loss = 2.13644265, grad/param norm = 2.5632e-01, time/batch = 0.6939s	
1403/30300 (epoch 2.315), train_loss = 2.16140439, grad/param norm = 2.3469e-01, time/batch = 0.6964s	
1404/30300 (epoch 2.317), train_loss = 2.15043008, grad/param norm = 2.1627e-01, time/batch = 0.6939s	
1405/30300 (epoch 2.318), train_loss = 2.35716481, grad/param norm = 2.4577e-01, time/batch = 0.6934s	
1406/30300 (epoch 2.320), train_loss = 2.18085010, grad/param norm = 2.7024e-01, time/batch = 0.6915s	
1407/30300 (epoch 2.322), train_loss = 1.98604120, grad/param norm = 2.4004e-01, time/batch = 0.6916s	
1408/30300 (epoch 2.323), train_loss = 2.16254765, grad/param norm = 2.2717e-01, time/batch = 0.7006s	
1409/30300 (epoch 2.325), train_loss = 2.01768083, grad/param norm = 2.3713e-01, time/batch = 0.6986s	
1410/30300 (epoch 2.327), train_loss = 1.98441047, grad/param norm = 2.4804e-01, time/batch = 0.6917s	
1411/30300 (epoch 2.328), train_loss = 2.00960626, grad/param norm = 2.3445e-01, time/batch = 0.6905s	
1412/30300 (epoch 2.330), train_loss = 2.18135262, grad/param norm = 2.2682e-01, time/batch = 0.6871s	
1413/30300 (epoch 2.332), train_loss = 2.27525218, grad/param norm = 2.6028e-01, time/batch = 0.6901s	
1414/30300 (epoch 2.333), train_loss = 2.15478307, grad/param norm = 2.8914e-01, time/batch = 0.6843s	
1415/30300 (epoch 2.335), train_loss = 1.92466141, grad/param norm = 2.9447e-01, time/batch = 0.6866s	
1416/30300 (epoch 2.337), train_loss = 2.32494165, grad/param norm = 2.4984e-01, time/batch = 0.6862s	
1417/30300 (epoch 2.338), train_loss = 2.05974530, grad/param norm = 2.8928e-01, time/batch = 0.6865s	
1418/30300 (epoch 2.340), train_loss = 2.13763505, grad/param norm = 2.5985e-01, time/batch = 0.6855s	
1419/30300 (epoch 2.342), train_loss = 2.08513248, grad/param norm = 2.4169e-01, time/batch = 0.7040s	
1420/30300 (epoch 2.343), train_loss = 2.10506651, grad/param norm = 2.5499e-01, time/batch = 0.6933s	
1421/30300 (epoch 2.345), train_loss = 2.11502442, grad/param norm = 2.3949e-01, time/batch = 0.6934s	
1422/30300 (epoch 2.347), train_loss = 1.90378321, grad/param norm = 2.0896e-01, time/batch = 0.6942s	
1423/30300 (epoch 2.348), train_loss = 1.98302777, grad/param norm = 2.3677e-01, time/batch = 0.6908s	
1424/30300 (epoch 2.350), train_loss = 2.08999680, grad/param norm = 2.4851e-01, time/batch = 0.6899s	
1425/30300 (epoch 2.351), train_loss = 2.07297249, grad/param norm = 2.4782e-01, time/batch = 0.6869s	
1426/30300 (epoch 2.353), train_loss = 1.87954982, grad/param norm = 2.9364e-01, time/batch = 0.6905s	
1427/30300 (epoch 2.355), train_loss = 2.14802296, grad/param norm = 2.2496e-01, time/batch = 0.6986s	
1428/30300 (epoch 2.356), train_loss = 2.19177366, grad/param norm = 2.0843e-01, time/batch = 0.6913s	
1429/30300 (epoch 2.358), train_loss = 2.25248320, grad/param norm = 2.5105e-01, time/batch = 0.6932s	
1430/30300 (epoch 2.360), train_loss = 2.01743343, grad/param norm = 2.1253e-01, time/batch = 0.6945s	
1431/30300 (epoch 2.361), train_loss = 2.13963784, grad/param norm = 2.1643e-01, time/batch = 0.6936s	
1432/30300 (epoch 2.363), train_loss = 2.20464236, grad/param norm = 2.3588e-01, time/batch = 0.6922s	
1433/30300 (epoch 2.365), train_loss = 2.06388882, grad/param norm = 2.8140e-01, time/batch = 0.7195s	
1434/30300 (epoch 2.366), train_loss = 2.04707317, grad/param norm = 2.4383e-01, time/batch = 0.7078s	
1435/30300 (epoch 2.368), train_loss = 1.90070859, grad/param norm = 2.3775e-01, time/batch = 0.6968s	
1436/30300 (epoch 2.370), train_loss = 2.10267518, grad/param norm = 2.2118e-01, time/batch = 0.6934s	
1437/30300 (epoch 2.371), train_loss = 2.09110603, grad/param norm = 2.1756e-01, time/batch = 0.7084s	
1438/30300 (epoch 2.373), train_loss = 2.08215066, grad/param norm = 2.3635e-01, time/batch = 0.6971s	
1439/30300 (epoch 2.375), train_loss = 1.99496455, grad/param norm = 2.1922e-01, time/batch = 0.7072s	
1440/30300 (epoch 2.376), train_loss = 2.04884347, grad/param norm = 2.2567e-01, time/batch = 0.7167s	
1441/30300 (epoch 2.378), train_loss = 2.02657358, grad/param norm = 2.1716e-01, time/batch = 0.6965s	
1442/30300 (epoch 2.380), train_loss = 2.26510799, grad/param norm = 2.2277e-01, time/batch = 0.7007s	
1443/30300 (epoch 2.381), train_loss = 2.11271698, grad/param norm = 2.0736e-01, time/batch = 0.7116s	
1444/30300 (epoch 2.383), train_loss = 2.21062179, grad/param norm = 2.6645e-01, time/batch = 0.7060s	
1445/30300 (epoch 2.384), train_loss = 2.27171230, grad/param norm = 2.3439e-01, time/batch = 0.6929s	
1446/30300 (epoch 2.386), train_loss = 2.01209660, grad/param norm = 2.4585e-01, time/batch = 0.6921s	
1447/30300 (epoch 2.388), train_loss = 2.11306605, grad/param norm = 2.3384e-01, time/batch = 0.6904s	
1448/30300 (epoch 2.389), train_loss = 2.09245554, grad/param norm = 2.5669e-01, time/batch = 0.6888s	
1449/30300 (epoch 2.391), train_loss = 2.14786192, grad/param norm = 2.1814e-01, time/batch = 0.7115s	
1450/30300 (epoch 2.393), train_loss = 1.97621672, grad/param norm = 2.2156e-01, time/batch = 0.6929s	
1451/30300 (epoch 2.394), train_loss = 2.06294488, grad/param norm = 2.1326e-01, time/batch = 0.6879s	
1452/30300 (epoch 2.396), train_loss = 2.15875589, grad/param norm = 2.2752e-01, time/batch = 0.6921s	
1453/30300 (epoch 2.398), train_loss = 2.04379414, grad/param norm = 2.3089e-01, time/batch = 0.6945s	
1454/30300 (epoch 2.399), train_loss = 1.98276672, grad/param norm = 2.0668e-01, time/batch = 0.7042s	
1455/30300 (epoch 2.401), train_loss = 2.19005795, grad/param norm = 2.6328e-01, time/batch = 0.6937s	
1456/30300 (epoch 2.403), train_loss = 2.12671663, grad/param norm = 3.3697e-01, time/batch = 0.6944s	
1457/30300 (epoch 2.404), train_loss = 2.09413644, grad/param norm = 2.7495e-01, time/batch = 0.6999s	
1458/30300 (epoch 2.406), train_loss = 2.12115378, grad/param norm = 2.9348e-01, time/batch = 0.6862s	
1459/30300 (epoch 2.408), train_loss = 2.02559625, grad/param norm = 2.1955e-01, time/batch = 0.6852s	
1460/30300 (epoch 2.409), train_loss = 1.84885760, grad/param norm = 2.5549e-01, time/batch = 0.6893s	
1461/30300 (epoch 2.411), train_loss = 1.98434908, grad/param norm = 2.6537e-01, time/batch = 0.6991s	
1462/30300 (epoch 2.413), train_loss = 1.91860003, grad/param norm = 2.1430e-01, time/batch = 0.7200s	
1463/30300 (epoch 2.414), train_loss = 2.21263278, grad/param norm = 2.1126e-01, time/batch = 0.6893s	
1464/30300 (epoch 2.416), train_loss = 2.10495276, grad/param norm = 2.4486e-01, time/batch = 0.6839s	
1465/30300 (epoch 2.417), train_loss = 1.95231414, grad/param norm = 1.9172e-01, time/batch = 0.6822s	
1466/30300 (epoch 2.419), train_loss = 1.88495864, grad/param norm = 2.6088e-01, time/batch = 0.6854s	
1467/30300 (epoch 2.421), train_loss = 1.95762962, grad/param norm = 2.4561e-01, time/batch = 0.6845s	
1468/30300 (epoch 2.422), train_loss = 1.99292142, grad/param norm = 2.3618e-01, time/batch = 0.6868s	
1469/30300 (epoch 2.424), train_loss = 2.16871448, grad/param norm = 2.3884e-01, time/batch = 0.6842s	
1470/30300 (epoch 2.426), train_loss = 1.84887171, grad/param norm = 2.4237e-01, time/batch = 0.6882s	
1471/30300 (epoch 2.427), train_loss = 2.00564031, grad/param norm = 2.3445e-01, time/batch = 0.6859s	
1472/30300 (epoch 2.429), train_loss = 2.11189183, grad/param norm = 2.9426e-01, time/batch = 0.6871s	
1473/30300 (epoch 2.431), train_loss = 2.16846539, grad/param norm = 3.1687e-01, time/batch = 0.6850s	
1474/30300 (epoch 2.432), train_loss = 2.07164295, grad/param norm = 2.4337e-01, time/batch = 0.6838s	
1475/30300 (epoch 2.434), train_loss = 1.99419744, grad/param norm = 2.1905e-01, time/batch = 0.6859s	
1476/30300 (epoch 2.436), train_loss = 2.07481553, grad/param norm = 2.3225e-01, time/batch = 0.6875s	
1477/30300 (epoch 2.437), train_loss = 2.09711579, grad/param norm = 2.3587e-01, time/batch = 0.6893s	
1478/30300 (epoch 2.439), train_loss = 2.00231981, grad/param norm = 2.5018e-01, time/batch = 0.6865s	
1479/30300 (epoch 2.441), train_loss = 1.95789239, grad/param norm = 2.4767e-01, time/batch = 0.6853s	
1480/30300 (epoch 2.442), train_loss = 1.90701087, grad/param norm = 2.5297e-01, time/batch = 0.6859s	
1481/30300 (epoch 2.444), train_loss = 1.97450164, grad/param norm = 2.4810e-01, time/batch = 0.6865s	
1482/30300 (epoch 2.446), train_loss = 1.94976250, grad/param norm = 2.3801e-01, time/batch = 0.6961s	
1483/30300 (epoch 2.447), train_loss = 2.08997701, grad/param norm = 2.6536e-01, time/batch = 0.6857s	
1484/30300 (epoch 2.449), train_loss = 2.01102121, grad/param norm = 2.4454e-01, time/batch = 0.6838s	
1485/30300 (epoch 2.450), train_loss = 2.21752408, grad/param norm = 3.2197e-01, time/batch = 0.6844s	
1486/30300 (epoch 2.452), train_loss = 1.98737140, grad/param norm = 1.9395e-01, time/batch = 0.6847s	
1487/30300 (epoch 2.454), train_loss = 1.99670869, grad/param norm = 2.3080e-01, time/batch = 0.6849s	
1488/30300 (epoch 2.455), train_loss = 2.25408835, grad/param norm = 2.5106e-01, time/batch = 0.6877s	
1489/30300 (epoch 2.457), train_loss = 2.12224554, grad/param norm = 2.2554e-01, time/batch = 0.6986s	
1490/30300 (epoch 2.459), train_loss = 2.09065558, grad/param norm = 2.4187e-01, time/batch = 0.6858s	
1491/30300 (epoch 2.460), train_loss = 2.08030198, grad/param norm = 2.3227e-01, time/batch = 0.6894s	
1492/30300 (epoch 2.462), train_loss = 2.13671229, grad/param norm = 2.4758e-01, time/batch = 0.6884s	
1493/30300 (epoch 2.464), train_loss = 2.09880014, grad/param norm = 2.3195e-01, time/batch = 0.6871s	
1494/30300 (epoch 2.465), train_loss = 1.92766066, grad/param norm = 2.3788e-01, time/batch = 0.6868s	
1495/30300 (epoch 2.467), train_loss = 1.79222078, grad/param norm = 2.0799e-01, time/batch = 0.6881s	
1496/30300 (epoch 2.469), train_loss = 1.99059773, grad/param norm = 2.3979e-01, time/batch = 0.6857s	
1497/30300 (epoch 2.470), train_loss = 1.98912569, grad/param norm = 2.2019e-01, time/batch = 0.6885s	
1498/30300 (epoch 2.472), train_loss = 1.91960012, grad/param norm = 2.7035e-01, time/batch = 0.6845s	
1499/30300 (epoch 2.474), train_loss = 2.07665460, grad/param norm = 3.0749e-01, time/batch = 0.6844s	
1500/30300 (epoch 2.475), train_loss = 2.04311083, grad/param norm = 2.2838e-01, time/batch = 0.6843s	
1501/30300 (epoch 2.477), train_loss = 2.06225451, grad/param norm = 2.3406e-01, time/batch = 0.6890s	
1502/30300 (epoch 2.479), train_loss = 2.17673684, grad/param norm = 2.6497e-01, time/batch = 0.6877s	
1503/30300 (epoch 2.480), train_loss = 1.97839503, grad/param norm = 2.1520e-01, time/batch = 0.6876s	
1504/30300 (epoch 2.482), train_loss = 2.13106752, grad/param norm = 2.8993e-01, time/batch = 0.6883s	
1505/30300 (epoch 2.483), train_loss = 2.11862523, grad/param norm = 2.8300e-01, time/batch = 0.7128s	
1506/30300 (epoch 2.485), train_loss = 2.02270670, grad/param norm = 2.5147e-01, time/batch = 0.6902s	
1507/30300 (epoch 2.487), train_loss = 2.16251716, grad/param norm = 2.4126e-01, time/batch = 0.6893s	
1508/30300 (epoch 2.488), train_loss = 1.96705859, grad/param norm = 2.0888e-01, time/batch = 0.6898s	
1509/30300 (epoch 2.490), train_loss = 1.89697725, grad/param norm = 2.5524e-01, time/batch = 0.6871s	
1510/30300 (epoch 2.492), train_loss = 2.08166513, grad/param norm = 2.1438e-01, time/batch = 0.6865s	
1511/30300 (epoch 2.493), train_loss = 1.94518676, grad/param norm = 2.4119e-01, time/batch = 0.6863s	
1512/30300 (epoch 2.495), train_loss = 2.03978745, grad/param norm = 2.1735e-01, time/batch = 0.6890s	
1513/30300 (epoch 2.497), train_loss = 2.03655183, grad/param norm = 2.4008e-01, time/batch = 0.6873s	
1514/30300 (epoch 2.498), train_loss = 2.07696553, grad/param norm = 2.5502e-01, time/batch = 0.6865s	
1515/30300 (epoch 2.500), train_loss = 2.23327267, grad/param norm = 2.4400e-01, time/batch = 0.6870s	
1516/30300 (epoch 2.502), train_loss = 1.94697158, grad/param norm = 2.4629e-01, time/batch = 0.6856s	
1517/30300 (epoch 2.503), train_loss = 2.07534039, grad/param norm = 2.3920e-01, time/batch = 0.6855s	
1518/30300 (epoch 2.505), train_loss = 2.10286801, grad/param norm = 2.5694e-01, time/batch = 0.6866s	
1519/30300 (epoch 2.507), train_loss = 2.05562997, grad/param norm = 2.3428e-01, time/batch = 0.7039s	
1520/30300 (epoch 2.508), train_loss = 2.21257502, grad/param norm = 2.4024e-01, time/batch = 0.7160s	
1521/30300 (epoch 2.510), train_loss = 2.12336283, grad/param norm = 2.4079e-01, time/batch = 0.6875s	
1522/30300 (epoch 2.512), train_loss = 1.93161697, grad/param norm = 2.0629e-01, time/batch = 0.6861s	
1523/30300 (epoch 2.513), train_loss = 2.05976597, grad/param norm = 2.4370e-01, time/batch = 0.6974s	
1524/30300 (epoch 2.515), train_loss = 2.00387183, grad/param norm = 2.5902e-01, time/batch = 0.7107s	
1525/30300 (epoch 2.517), train_loss = 1.89571069, grad/param norm = 2.2899e-01, time/batch = 0.6937s	
1526/30300 (epoch 2.518), train_loss = 2.15783861, grad/param norm = 2.4293e-01, time/batch = 0.6894s	
1527/30300 (epoch 2.520), train_loss = 2.32391346, grad/param norm = 2.5998e-01, time/batch = 0.6904s	
1528/30300 (epoch 2.521), train_loss = 2.02077075, grad/param norm = 2.4879e-01, time/batch = 0.6901s	
1529/30300 (epoch 2.523), train_loss = 2.17522296, grad/param norm = 2.3182e-01, time/batch = 0.6908s	
1530/30300 (epoch 2.525), train_loss = 2.09426726, grad/param norm = 2.2926e-01, time/batch = 0.6856s	
1531/30300 (epoch 2.526), train_loss = 2.01036103, grad/param norm = 2.1644e-01, time/batch = 0.6881s	
1532/30300 (epoch 2.528), train_loss = 1.89306634, grad/param norm = 2.2118e-01, time/batch = 0.6894s	
1533/30300 (epoch 2.530), train_loss = 1.96982646, grad/param norm = 2.4533e-01, time/batch = 0.6957s	
1534/30300 (epoch 2.531), train_loss = 2.10300647, grad/param norm = 2.3904e-01, time/batch = 0.7282s	
1535/30300 (epoch 2.533), train_loss = 2.10263464, grad/param norm = 1.9877e-01, time/batch = 0.7089s	
1536/30300 (epoch 2.535), train_loss = 1.89225733, grad/param norm = 2.1044e-01, time/batch = 0.6889s	
1537/30300 (epoch 2.536), train_loss = 2.06632958, grad/param norm = 2.3132e-01, time/batch = 0.6880s	
1538/30300 (epoch 2.538), train_loss = 1.84211415, grad/param norm = 2.1496e-01, time/batch = 0.6927s	
1539/30300 (epoch 2.540), train_loss = 2.09092706, grad/param norm = 2.2783e-01, time/batch = 0.6878s	
1540/30300 (epoch 2.541), train_loss = 1.98364059, grad/param norm = 2.1492e-01, time/batch = 0.6920s	
1541/30300 (epoch 2.543), train_loss = 2.03613077, grad/param norm = 2.1532e-01, time/batch = 0.6977s	
1542/30300 (epoch 2.545), train_loss = 2.19469487, grad/param norm = 2.9526e-01, time/batch = 0.6922s	
1543/30300 (epoch 2.546), train_loss = 2.24644294, grad/param norm = 3.0964e-01, time/batch = 0.6894s	
1544/30300 (epoch 2.548), train_loss = 1.98458024, grad/param norm = 3.5533e-01, time/batch = 0.6909s	
1545/30300 (epoch 2.550), train_loss = 2.24910310, grad/param norm = 2.2556e-01, time/batch = 0.6869s	
1546/30300 (epoch 2.551), train_loss = 2.02712076, grad/param norm = 2.3081e-01, time/batch = 0.6898s	
1547/30300 (epoch 2.553), train_loss = 1.99156158, grad/param norm = 2.1323e-01, time/batch = 0.6892s	
1548/30300 (epoch 2.554), train_loss = 2.21275357, grad/param norm = 2.2759e-01, time/batch = 0.7166s	
1549/30300 (epoch 2.556), train_loss = 2.07476282, grad/param norm = 2.0970e-01, time/batch = 0.7072s	
1550/30300 (epoch 2.558), train_loss = 2.17134519, grad/param norm = 2.1846e-01, time/batch = 0.6912s	
1551/30300 (epoch 2.559), train_loss = 2.01637595, grad/param norm = 2.2974e-01, time/batch = 0.6896s	
1552/30300 (epoch 2.561), train_loss = 1.95328291, grad/param norm = 2.1712e-01, time/batch = 0.6975s	
1553/30300 (epoch 2.563), train_loss = 2.13372416, grad/param norm = 2.3363e-01, time/batch = 0.7098s	
1554/30300 (epoch 2.564), train_loss = 2.06737008, grad/param norm = 2.2062e-01, time/batch = 0.7186s	
1555/30300 (epoch 2.566), train_loss = 2.16650608, grad/param norm = 3.0901e-01, time/batch = 0.7118s	
1556/30300 (epoch 2.568), train_loss = 1.92355276, grad/param norm = 2.8038e-01, time/batch = 0.7111s	
1557/30300 (epoch 2.569), train_loss = 2.03588616, grad/param norm = 2.7988e-01, time/batch = 0.6935s	
1558/30300 (epoch 2.571), train_loss = 2.13520744, grad/param norm = 2.5506e-01, time/batch = 0.6879s	
1559/30300 (epoch 2.573), train_loss = 2.09174842, grad/param norm = 2.2314e-01, time/batch = 0.6863s	
1560/30300 (epoch 2.574), train_loss = 2.06144409, grad/param norm = 2.2903e-01, time/batch = 0.6905s	
1561/30300 (epoch 2.576), train_loss = 2.09480661, grad/param norm = 2.3515e-01, time/batch = 0.6934s	
1562/30300 (epoch 2.578), train_loss = 1.94284967, grad/param norm = 1.9600e-01, time/batch = 0.7091s	
1563/30300 (epoch 2.579), train_loss = 1.97775629, grad/param norm = 2.4120e-01, time/batch = 0.7135s	
1564/30300 (epoch 2.581), train_loss = 2.14990969, grad/param norm = 2.6805e-01, time/batch = 0.6894s	
1565/30300 (epoch 2.583), train_loss = 2.21863732, grad/param norm = 2.5288e-01, time/batch = 0.6897s	
1566/30300 (epoch 2.584), train_loss = 2.19966451, grad/param norm = 2.1084e-01, time/batch = 0.6895s	
1567/30300 (epoch 2.586), train_loss = 2.08111442, grad/param norm = 2.3378e-01, time/batch = 0.6921s	
1568/30300 (epoch 2.587), train_loss = 2.04355806, grad/param norm = 2.2493e-01, time/batch = 0.6935s	
1569/30300 (epoch 2.589), train_loss = 1.73940003, grad/param norm = 2.0448e-01, time/batch = 0.6922s	
1570/30300 (epoch 2.591), train_loss = 2.06023482, grad/param norm = 2.4358e-01, time/batch = 0.6883s	
1571/30300 (epoch 2.592), train_loss = 2.02055617, grad/param norm = 2.1885e-01, time/batch = 0.6940s	
1572/30300 (epoch 2.594), train_loss = 2.09285706, grad/param norm = 2.5952e-01, time/batch = 0.6901s	
1573/30300 (epoch 2.596), train_loss = 1.93783371, grad/param norm = 2.6416e-01, time/batch = 0.6913s	
1574/30300 (epoch 2.597), train_loss = 2.03052377, grad/param norm = 2.5263e-01, time/batch = 0.6885s	
1575/30300 (epoch 2.599), train_loss = 1.81638420, grad/param norm = 2.3202e-01, time/batch = 0.6927s	
1576/30300 (epoch 2.601), train_loss = 2.04741689, grad/param norm = 2.2563e-01, time/batch = 0.6992s	
1577/30300 (epoch 2.602), train_loss = 1.99672328, grad/param norm = 2.0367e-01, time/batch = 0.7231s	
1578/30300 (epoch 2.604), train_loss = 1.97970545, grad/param norm = 2.5114e-01, time/batch = 0.6947s	
1579/30300 (epoch 2.606), train_loss = 2.33980467, grad/param norm = 3.0812e-01, time/batch = 0.6900s	
1580/30300 (epoch 2.607), train_loss = 2.18476525, grad/param norm = 2.4292e-01, time/batch = 0.6906s	
1581/30300 (epoch 2.609), train_loss = 2.32779320, grad/param norm = 2.5390e-01, time/batch = 0.6866s	
1582/30300 (epoch 2.611), train_loss = 1.85281118, grad/param norm = 2.0688e-01, time/batch = 0.6882s	
1583/30300 (epoch 2.612), train_loss = 2.02132942, grad/param norm = 2.3746e-01, time/batch = 0.6992s	
1584/30300 (epoch 2.614), train_loss = 1.87445743, grad/param norm = 2.2325e-01, time/batch = 0.7013s	
1585/30300 (epoch 2.616), train_loss = 2.09698509, grad/param norm = 2.4374e-01, time/batch = 0.6926s	
1586/30300 (epoch 2.617), train_loss = 2.05387560, grad/param norm = 2.3652e-01, time/batch = 0.6931s	
1587/30300 (epoch 2.619), train_loss = 1.85193601, grad/param norm = 2.1206e-01, time/batch = 0.6916s	
1588/30300 (epoch 2.620), train_loss = 2.12438045, grad/param norm = 2.2849e-01, time/batch = 0.6907s	
1589/30300 (epoch 2.622), train_loss = 1.95846177, grad/param norm = 2.3612e-01, time/batch = 0.6882s	
1590/30300 (epoch 2.624), train_loss = 1.94156993, grad/param norm = 2.3158e-01, time/batch = 0.6883s	
1591/30300 (epoch 2.625), train_loss = 1.96940313, grad/param norm = 2.4559e-01, time/batch = 0.6886s	
1592/30300 (epoch 2.627), train_loss = 2.19706244, grad/param norm = 2.3321e-01, time/batch = 0.6881s	
1593/30300 (epoch 2.629), train_loss = 2.10311431, grad/param norm = 2.3186e-01, time/batch = 0.6892s	
1594/30300 (epoch 2.630), train_loss = 2.07915697, grad/param norm = 2.0850e-01, time/batch = 0.6883s	
1595/30300 (epoch 2.632), train_loss = 2.06770651, grad/param norm = 3.2103e-01, time/batch = 0.6853s	
1596/30300 (epoch 2.634), train_loss = 1.81954945, grad/param norm = 2.6374e-01, time/batch = 0.6855s	
1597/30300 (epoch 2.635), train_loss = 2.09798996, grad/param norm = 2.2249e-01, time/batch = 0.6875s	
1598/30300 (epoch 2.637), train_loss = 2.01525685, grad/param norm = 2.6627e-01, time/batch = 0.6917s	
1599/30300 (epoch 2.639), train_loss = 1.91501804, grad/param norm = 2.6109e-01, time/batch = 0.6879s	
1600/30300 (epoch 2.640), train_loss = 2.09298673, grad/param norm = 2.4753e-01, time/batch = 0.6877s	
1601/30300 (epoch 2.642), train_loss = 2.04263483, grad/param norm = 2.1756e-01, time/batch = 0.6875s	
1602/30300 (epoch 2.644), train_loss = 2.06351432, grad/param norm = 2.2663e-01, time/batch = 0.6874s	
1603/30300 (epoch 2.645), train_loss = 1.99361912, grad/param norm = 2.2920e-01, time/batch = 0.6885s	
1604/30300 (epoch 2.647), train_loss = 2.03468044, grad/param norm = 2.5858e-01, time/batch = 0.6874s	
1605/30300 (epoch 2.649), train_loss = 2.02400436, grad/param norm = 2.0743e-01, time/batch = 0.7038s	
1606/30300 (epoch 2.650), train_loss = 2.03201368, grad/param norm = 2.1739e-01, time/batch = 0.7194s	
1607/30300 (epoch 2.652), train_loss = 1.88790585, grad/param norm = 2.2614e-01, time/batch = 0.6981s	
1608/30300 (epoch 2.653), train_loss = 2.20399487, grad/param norm = 2.5636e-01, time/batch = 0.6985s	
1609/30300 (epoch 2.655), train_loss = 2.02746999, grad/param norm = 2.1958e-01, time/batch = 0.6979s	
1610/30300 (epoch 2.657), train_loss = 2.12990652, grad/param norm = 2.2822e-01, time/batch = 0.7102s	
1611/30300 (epoch 2.658), train_loss = 1.96403664, grad/param norm = 2.3195e-01, time/batch = 0.6934s	
1612/30300 (epoch 2.660), train_loss = 2.06210259, grad/param norm = 2.1354e-01, time/batch = 0.7082s	
1613/30300 (epoch 2.662), train_loss = 2.04867229, grad/param norm = 2.1388e-01, time/batch = 0.7001s	
1614/30300 (epoch 2.663), train_loss = 2.03581575, grad/param norm = 2.2228e-01, time/batch = 0.6905s	
1615/30300 (epoch 2.665), train_loss = 1.83712464, grad/param norm = 1.9480e-01, time/batch = 0.6928s	
1616/30300 (epoch 2.667), train_loss = 2.14816492, grad/param norm = 2.3642e-01, time/batch = 0.6901s	
1617/30300 (epoch 2.668), train_loss = 2.20757318, grad/param norm = 2.4570e-01, time/batch = 0.6903s	
1618/30300 (epoch 2.670), train_loss = 2.05983755, grad/param norm = 2.3848e-01, time/batch = 0.6896s	
1619/30300 (epoch 2.672), train_loss = 2.11338654, grad/param norm = 2.2086e-01, time/batch = 0.6918s	
1620/30300 (epoch 2.673), train_loss = 2.04013318, grad/param norm = 2.2686e-01, time/batch = 0.6870s	
1621/30300 (epoch 2.675), train_loss = 1.93582609, grad/param norm = 2.3100e-01, time/batch = 0.6929s	
1622/30300 (epoch 2.677), train_loss = 1.96916316, grad/param norm = 2.4027e-01, time/batch = 0.6921s	
1623/30300 (epoch 2.678), train_loss = 1.99267735, grad/param norm = 2.2011e-01, time/batch = 0.6874s	
1624/30300 (epoch 2.680), train_loss = 1.75739890, grad/param norm = 2.1889e-01, time/batch = 0.6962s	
1625/30300 (epoch 2.682), train_loss = 1.98885167, grad/param norm = 2.2593e-01, time/batch = 0.7045s	
1626/30300 (epoch 2.683), train_loss = 2.10145085, grad/param norm = 2.2989e-01, time/batch = 0.6974s	
1627/30300 (epoch 2.685), train_loss = 2.16630191, grad/param norm = 2.3689e-01, time/batch = 0.6921s	
1628/30300 (epoch 2.686), train_loss = 2.04382145, grad/param norm = 2.1292e-01, time/batch = 0.6931s	
1629/30300 (epoch 2.688), train_loss = 2.06804283, grad/param norm = 2.3521e-01, time/batch = 0.6900s	
1630/30300 (epoch 2.690), train_loss = 2.00734904, grad/param norm = 2.8617e-01, time/batch = 0.6919s	
1631/30300 (epoch 2.691), train_loss = 2.06672231, grad/param norm = 3.5013e-01, time/batch = 0.6935s	
1632/30300 (epoch 2.693), train_loss = 2.40034897, grad/param norm = 3.0742e-01, time/batch = 0.6980s	
1633/30300 (epoch 2.695), train_loss = 2.18216628, grad/param norm = 2.5018e-01, time/batch = 0.7134s	
1634/30300 (epoch 2.696), train_loss = 2.26523417, grad/param norm = 2.9185e-01, time/batch = 0.7138s	
1635/30300 (epoch 2.698), train_loss = 1.97567135, grad/param norm = 2.3756e-01, time/batch = 0.7145s	
1636/30300 (epoch 2.700), train_loss = 2.00162565, grad/param norm = 2.2772e-01, time/batch = 0.7037s	
1637/30300 (epoch 2.701), train_loss = 1.78901655, grad/param norm = 2.1537e-01, time/batch = 0.7101s	
1638/30300 (epoch 2.703), train_loss = 1.91881251, grad/param norm = 1.9076e-01, time/batch = 0.7003s	
1639/30300 (epoch 2.705), train_loss = 2.06398927, grad/param norm = 2.5011e-01, time/batch = 0.7035s	
1640/30300 (epoch 2.706), train_loss = 1.93022197, grad/param norm = 2.0924e-01, time/batch = 0.7070s	
1641/30300 (epoch 2.708), train_loss = 2.02191407, grad/param norm = 2.3681e-01, time/batch = 0.7064s	
1642/30300 (epoch 2.710), train_loss = 1.94203740, grad/param norm = 2.3609e-01, time/batch = 0.7075s	
1643/30300 (epoch 2.711), train_loss = 1.90150958, grad/param norm = 2.0133e-01, time/batch = 0.7037s	
1644/30300 (epoch 2.713), train_loss = 1.80012974, grad/param norm = 2.0742e-01, time/batch = 0.7204s	
1645/30300 (epoch 2.715), train_loss = 2.01292483, grad/param norm = 2.3092e-01, time/batch = 0.7007s	
1646/30300 (epoch 2.716), train_loss = 2.18243720, grad/param norm = 2.3007e-01, time/batch = 0.6893s	
1647/30300 (epoch 2.718), train_loss = 2.14673393, grad/param norm = 2.2783e-01, time/batch = 0.6954s	
1648/30300 (epoch 2.719), train_loss = 1.97871604, grad/param norm = 2.2233e-01, time/batch = 0.6931s	
1649/30300 (epoch 2.721), train_loss = 2.01392429, grad/param norm = 2.1156e-01, time/batch = 0.6893s	
1650/30300 (epoch 2.723), train_loss = 1.94237247, grad/param norm = 2.2020e-01, time/batch = 0.6928s	
1651/30300 (epoch 2.724), train_loss = 2.04687415, grad/param norm = 2.4635e-01, time/batch = 0.7129s	
1652/30300 (epoch 2.726), train_loss = 2.42453527, grad/param norm = 2.6580e-01, time/batch = 0.7014s	
1653/30300 (epoch 2.728), train_loss = 1.93678588, grad/param norm = 2.3151e-01, time/batch = 0.6956s	
1654/30300 (epoch 2.729), train_loss = 2.05099596, grad/param norm = 2.7853e-01, time/batch = 0.6917s	
1655/30300 (epoch 2.731), train_loss = 2.08786591, grad/param norm = 2.1982e-01, time/batch = 0.6867s	
1656/30300 (epoch 2.733), train_loss = 1.97863968, grad/param norm = 1.9919e-01, time/batch = 0.6888s	
1657/30300 (epoch 2.734), train_loss = 2.01235150, grad/param norm = 1.9522e-01, time/batch = 0.6880s	
1658/30300 (epoch 2.736), train_loss = 2.00700555, grad/param norm = 2.3799e-01, time/batch = 0.7101s	
1659/30300 (epoch 2.738), train_loss = 1.85019584, grad/param norm = 1.8997e-01, time/batch = 0.7090s	
1660/30300 (epoch 2.739), train_loss = 2.13943253, grad/param norm = 2.3751e-01, time/batch = 0.6959s	
1661/30300 (epoch 2.741), train_loss = 2.10373991, grad/param norm = 2.2461e-01, time/batch = 0.7158s	
1662/30300 (epoch 2.743), train_loss = 1.86931532, grad/param norm = 2.1565e-01, time/batch = 0.7147s	
1663/30300 (epoch 2.744), train_loss = 2.14344404, grad/param norm = 2.4172e-01, time/batch = 0.7070s	
1664/30300 (epoch 2.746), train_loss = 1.86180150, grad/param norm = 2.4532e-01, time/batch = 0.7135s	
1665/30300 (epoch 2.748), train_loss = 2.09081361, grad/param norm = 2.9954e-01, time/batch = 0.7119s	
1666/30300 (epoch 2.749), train_loss = 2.02653994, grad/param norm = 2.7365e-01, time/batch = 0.7094s	
1667/30300 (epoch 2.751), train_loss = 1.93872119, grad/param norm = 2.2973e-01, time/batch = 0.6936s	
1668/30300 (epoch 2.752), train_loss = 1.91294011, grad/param norm = 2.2485e-01, time/batch = 0.6909s	
1669/30300 (epoch 2.754), train_loss = 1.79107090, grad/param norm = 1.9839e-01, time/batch = 0.6880s	
1670/30300 (epoch 2.756), train_loss = 1.92745114, grad/param norm = 2.7138e-01, time/batch = 0.6905s	
1671/30300 (epoch 2.757), train_loss = 2.10015471, grad/param norm = 2.3254e-01, time/batch = 0.6880s	
1672/30300 (epoch 2.759), train_loss = 1.87167560, grad/param norm = 2.3525e-01, time/batch = 0.7077s	
1673/30300 (epoch 2.761), train_loss = 1.92534358, grad/param norm = 2.0466e-01, time/batch = 0.7143s	
1674/30300 (epoch 2.762), train_loss = 1.75180828, grad/param norm = 2.0625e-01, time/batch = 0.6862s	
1675/30300 (epoch 2.764), train_loss = 1.91932464, grad/param norm = 2.1758e-01, time/batch = 0.6872s	
1676/30300 (epoch 2.766), train_loss = 2.00951548, grad/param norm = 2.1769e-01, time/batch = 0.6864s	
1677/30300 (epoch 2.767), train_loss = 2.12492576, grad/param norm = 2.4610e-01, time/batch = 0.6847s	
1678/30300 (epoch 2.769), train_loss = 2.19256090, grad/param norm = 2.6023e-01, time/batch = 0.6886s	
1679/30300 (epoch 2.771), train_loss = 2.01198051, grad/param norm = 2.0603e-01, time/batch = 0.6888s	
1680/30300 (epoch 2.772), train_loss = 1.95854845, grad/param norm = 2.2117e-01, time/batch = 0.6894s	
1681/30300 (epoch 2.774), train_loss = 2.06505972, grad/param norm = 2.2254e-01, time/batch = 0.6880s	
1682/30300 (epoch 2.776), train_loss = 1.98047596, grad/param norm = 2.0753e-01, time/batch = 0.6886s	
1683/30300 (epoch 2.777), train_loss = 2.00219478, grad/param norm = 2.2117e-01, time/batch = 0.6895s	
1684/30300 (epoch 2.779), train_loss = 2.07454218, grad/param norm = 2.1280e-01, time/batch = 0.6914s	
1685/30300 (epoch 2.781), train_loss = 1.98085325, grad/param norm = 2.1954e-01, time/batch = 0.6904s	
1686/30300 (epoch 2.782), train_loss = 1.86241338, grad/param norm = 2.0247e-01, time/batch = 0.6945s	
1687/30300 (epoch 2.784), train_loss = 2.08325177, grad/param norm = 2.1231e-01, time/batch = 0.7202s	
1688/30300 (epoch 2.785), train_loss = 2.14742899, grad/param norm = 2.0093e-01, time/batch = 0.6951s	
1689/30300 (epoch 2.787), train_loss = 2.00484733, grad/param norm = 2.1652e-01, time/batch = 0.6860s	
1690/30300 (epoch 2.789), train_loss = 2.36787438, grad/param norm = 2.2670e-01, time/batch = 0.6908s	
1691/30300 (epoch 2.790), train_loss = 2.11795232, grad/param norm = 2.0757e-01, time/batch = 0.6896s	
1692/30300 (epoch 2.792), train_loss = 1.96264267, grad/param norm = 2.3215e-01, time/batch = 0.6917s	
1693/30300 (epoch 2.794), train_loss = 1.89864172, grad/param norm = 2.0993e-01, time/batch = 0.6900s	
1694/30300 (epoch 2.795), train_loss = 1.97217703, grad/param norm = 2.0546e-01, time/batch = 0.6951s	
1695/30300 (epoch 2.797), train_loss = 2.08365083, grad/param norm = 2.3030e-01, time/batch = 0.6982s	
1696/30300 (epoch 2.799), train_loss = 2.15300555, grad/param norm = 3.1236e-01, time/batch = 0.7042s	
1697/30300 (epoch 2.800), train_loss = 2.00360684, grad/param norm = 2.5493e-01, time/batch = 0.7147s	
1698/30300 (epoch 2.802), train_loss = 2.16692768, grad/param norm = 2.5158e-01, time/batch = 0.6979s	
1699/30300 (epoch 2.804), train_loss = 2.07916425, grad/param norm = 2.7316e-01, time/batch = 0.6919s	
1700/30300 (epoch 2.805), train_loss = 2.14838985, grad/param norm = 2.4483e-01, time/batch = 0.6932s	
1701/30300 (epoch 2.807), train_loss = 2.13229943, grad/param norm = 2.6147e-01, time/batch = 0.7168s	
1702/30300 (epoch 2.809), train_loss = 2.19716735, grad/param norm = 2.4385e-01, time/batch = 0.7211s	
1703/30300 (epoch 2.810), train_loss = 2.09005248, grad/param norm = 2.2589e-01, time/batch = 0.7141s	
1704/30300 (epoch 2.812), train_loss = 1.96624626, grad/param norm = 2.2805e-01, time/batch = 0.6962s	
1705/30300 (epoch 2.814), train_loss = 2.09628629, grad/param norm = 2.2265e-01, time/batch = 0.6903s	
1706/30300 (epoch 2.815), train_loss = 2.02777627, grad/param norm = 2.4051e-01, time/batch = 0.6935s	
1707/30300 (epoch 2.817), train_loss = 2.06687159, grad/param norm = 2.4901e-01, time/batch = 0.6964s	
1708/30300 (epoch 2.818), train_loss = 2.00522530, grad/param norm = 2.1999e-01, time/batch = 0.6959s	
1709/30300 (epoch 2.820), train_loss = 2.24579235, grad/param norm = 2.5120e-01, time/batch = 0.6901s	
1710/30300 (epoch 2.822), train_loss = 2.19077462, grad/param norm = 2.4556e-01, time/batch = 0.6900s	
1711/30300 (epoch 2.823), train_loss = 2.27989572, grad/param norm = 2.5360e-01, time/batch = 0.6902s	
1712/30300 (epoch 2.825), train_loss = 2.08464574, grad/param norm = 2.3637e-01, time/batch = 0.6922s	
1713/30300 (epoch 2.827), train_loss = 2.00091607, grad/param norm = 2.1980e-01, time/batch = 0.6925s	
1714/30300 (epoch 2.828), train_loss = 2.03363688, grad/param norm = 1.8890e-01, time/batch = 0.7043s	
1715/30300 (epoch 2.830), train_loss = 2.03245836, grad/param norm = 2.2815e-01, time/batch = 0.7089s	
1716/30300 (epoch 2.832), train_loss = 1.93592433, grad/param norm = 2.1133e-01, time/batch = 0.7044s	
1717/30300 (epoch 2.833), train_loss = 2.09007479, grad/param norm = 2.2034e-01, time/batch = 0.7004s	
1718/30300 (epoch 2.835), train_loss = 2.06468362, grad/param norm = 2.2561e-01, time/batch = 0.6899s	
1719/30300 (epoch 2.837), train_loss = 1.84079307, grad/param norm = 2.0274e-01, time/batch = 0.6921s	
1720/30300 (epoch 2.838), train_loss = 1.91965374, grad/param norm = 1.9406e-01, time/batch = 0.6891s	
1721/30300 (epoch 2.840), train_loss = 1.94774726, grad/param norm = 2.0957e-01, time/batch = 0.6897s	
1722/30300 (epoch 2.842), train_loss = 1.88202126, grad/param norm = 2.4457e-01, time/batch = 0.6912s	
1723/30300 (epoch 2.843), train_loss = 2.02381121, grad/param norm = 2.5767e-01, time/batch = 0.6938s	
1724/30300 (epoch 2.845), train_loss = 1.83834119, grad/param norm = 2.0164e-01, time/batch = 0.6884s	
1725/30300 (epoch 2.847), train_loss = 1.97169159, grad/param norm = 2.3491e-01, time/batch = 0.7078s	
1726/30300 (epoch 2.848), train_loss = 2.15554581, grad/param norm = 2.5588e-01, time/batch = 0.7145s	
1727/30300 (epoch 2.850), train_loss = 1.89450167, grad/param norm = 2.4715e-01, time/batch = 0.6904s	
1728/30300 (epoch 2.851), train_loss = 2.27223936, grad/param norm = 2.4185e-01, time/batch = 0.6902s	
1729/30300 (epoch 2.853), train_loss = 2.01921444, grad/param norm = 2.2645e-01, time/batch = 0.6930s	
1730/30300 (epoch 2.855), train_loss = 1.94365403, grad/param norm = 2.3656e-01, time/batch = 0.6874s	
1731/30300 (epoch 2.856), train_loss = 1.92687118, grad/param norm = 2.2788e-01, time/batch = 0.6889s	
1732/30300 (epoch 2.858), train_loss = 1.86166413, grad/param norm = 2.0464e-01, time/batch = 0.6895s	
1733/30300 (epoch 2.860), train_loss = 2.04344840, grad/param norm = 2.1477e-01, time/batch = 0.6885s	
1734/30300 (epoch 2.861), train_loss = 2.13819963, grad/param norm = 3.0964e-01, time/batch = 0.6912s	
1735/30300 (epoch 2.863), train_loss = 2.07943007, grad/param norm = 2.4720e-01, time/batch = 0.6944s	
1736/30300 (epoch 2.865), train_loss = 2.32393603, grad/param norm = 2.4065e-01, time/batch = 0.6942s	
1737/30300 (epoch 2.866), train_loss = 2.04617933, grad/param norm = 2.4863e-01, time/batch = 0.6929s	
1738/30300 (epoch 2.868), train_loss = 2.07429006, grad/param norm = 2.4923e-01, time/batch = 0.6908s	
1739/30300 (epoch 2.870), train_loss = 1.97546729, grad/param norm = 2.4728e-01, time/batch = 0.6951s	
1740/30300 (epoch 2.871), train_loss = 1.90756598, grad/param norm = 2.0394e-01, time/batch = 0.7206s	
1741/30300 (epoch 2.873), train_loss = 2.09201945, grad/param norm = 2.2834e-01, time/batch = 0.6990s	
1742/30300 (epoch 2.875), train_loss = 1.86928858, grad/param norm = 2.0527e-01, time/batch = 0.6929s	
1743/30300 (epoch 2.876), train_loss = 1.80966831, grad/param norm = 1.9790e-01, time/batch = 0.6930s	
1744/30300 (epoch 2.878), train_loss = 1.80365086, grad/param norm = 2.3181e-01, time/batch = 0.6950s	
1745/30300 (epoch 2.880), train_loss = 1.85234781, grad/param norm = 2.1053e-01, time/batch = 0.6895s	
1746/30300 (epoch 2.881), train_loss = 2.14796798, grad/param norm = 2.2024e-01, time/batch = 0.6920s	
1747/30300 (epoch 2.883), train_loss = 2.02062866, grad/param norm = 2.2167e-01, time/batch = 0.6942s	
1748/30300 (epoch 2.884), train_loss = 1.88767643, grad/param norm = 2.0364e-01, time/batch = 0.6941s	
1749/30300 (epoch 2.886), train_loss = 1.89634068, grad/param norm = 2.3025e-01, time/batch = 0.6898s	
1750/30300 (epoch 2.888), train_loss = 2.07654402, grad/param norm = 2.5250e-01, time/batch = 0.6903s	
1751/30300 (epoch 2.889), train_loss = 2.00706219, grad/param norm = 3.0012e-01, time/batch = 0.6941s	
1752/30300 (epoch 2.891), train_loss = 1.93835814, grad/param norm = 2.5381e-01, time/batch = 0.6919s	
1753/30300 (epoch 2.893), train_loss = 2.13982402, grad/param norm = 2.4977e-01, time/batch = 0.6922s	
1754/30300 (epoch 2.894), train_loss = 2.06158137, grad/param norm = 2.2852e-01, time/batch = 0.6890s	
1755/30300 (epoch 2.896), train_loss = 1.85649747, grad/param norm = 2.5963e-01, time/batch = 0.6897s	
1756/30300 (epoch 2.898), train_loss = 1.81098629, grad/param norm = 2.2333e-01, time/batch = 0.6909s	
1757/30300 (epoch 2.899), train_loss = 1.95324355, grad/param norm = 2.2675e-01, time/batch = 0.6878s	
1758/30300 (epoch 2.901), train_loss = 2.05183112, grad/param norm = 2.2514e-01, time/batch = 0.6905s	
1759/30300 (epoch 2.903), train_loss = 2.07408335, grad/param norm = 2.2733e-01, time/batch = 0.6892s	
1760/30300 (epoch 2.904), train_loss = 1.99378949, grad/param norm = 2.2477e-01, time/batch = 0.6864s	
1761/30300 (epoch 2.906), train_loss = 2.06168742, grad/param norm = 2.2874e-01, time/batch = 0.6903s	
1762/30300 (epoch 2.908), train_loss = 1.95211429, grad/param norm = 2.1049e-01, time/batch = 0.6883s	
1763/30300 (epoch 2.909), train_loss = 2.07181114, grad/param norm = 2.3115e-01, time/batch = 0.6866s	
1764/30300 (epoch 2.911), train_loss = 1.93272264, grad/param norm = 2.6661e-01, time/batch = 0.6873s	
1765/30300 (epoch 2.913), train_loss = 1.99906485, grad/param norm = 1.9783e-01, time/batch = 0.6889s	
1766/30300 (epoch 2.914), train_loss = 2.06021412, grad/param norm = 2.4534e-01, time/batch = 0.6880s	
1767/30300 (epoch 2.916), train_loss = 2.01030431, grad/param norm = 2.2935e-01, time/batch = 0.6879s	
1768/30300 (epoch 2.917), train_loss = 1.93611955, grad/param norm = 2.1749e-01, time/batch = 0.6880s	
1769/30300 (epoch 2.919), train_loss = 2.02623508, grad/param norm = 2.1547e-01, time/batch = 0.6891s	
1770/30300 (epoch 2.921), train_loss = 2.10454129, grad/param norm = 2.3771e-01, time/batch = 0.6872s	
1771/30300 (epoch 2.922), train_loss = 2.10172408, grad/param norm = 2.2195e-01, time/batch = 0.6951s	
1772/30300 (epoch 2.924), train_loss = 1.99346096, grad/param norm = 2.6631e-01, time/batch = 0.6935s	
1773/30300 (epoch 2.926), train_loss = 2.00325598, grad/param norm = 2.8105e-01, time/batch = 0.7208s	
1774/30300 (epoch 2.927), train_loss = 1.94624487, grad/param norm = 2.7976e-01, time/batch = 0.6968s	
1775/30300 (epoch 2.929), train_loss = 2.04598243, grad/param norm = 2.4964e-01, time/batch = 0.6881s	
1776/30300 (epoch 2.931), train_loss = 2.09364316, grad/param norm = 2.4497e-01, time/batch = 0.6923s	
1777/30300 (epoch 2.932), train_loss = 1.92860996, grad/param norm = 2.2898e-01, time/batch = 0.6918s	
1778/30300 (epoch 2.934), train_loss = 1.97010299, grad/param norm = 2.2485e-01, time/batch = 0.6865s	
1779/30300 (epoch 2.936), train_loss = 1.95118524, grad/param norm = 2.1160e-01, time/batch = 0.6881s	
1780/30300 (epoch 2.937), train_loss = 2.01243590, grad/param norm = 2.1142e-01, time/batch = 0.6904s	
1781/30300 (epoch 2.939), train_loss = 2.08333048, grad/param norm = 2.1108e-01, time/batch = 0.7017s	
1782/30300 (epoch 2.941), train_loss = 2.03184758, grad/param norm = 2.1692e-01, time/batch = 0.7025s	
1783/30300 (epoch 2.942), train_loss = 1.91333995, grad/param norm = 2.1352e-01, time/batch = 0.6936s	
1784/30300 (epoch 2.944), train_loss = 1.85022229, grad/param norm = 2.0346e-01, time/batch = 0.6924s	
1785/30300 (epoch 2.946), train_loss = 2.18360590, grad/param norm = 2.2073e-01, time/batch = 0.6896s	
1786/30300 (epoch 2.947), train_loss = 2.16166996, grad/param norm = 2.2732e-01, time/batch = 0.6909s	
1787/30300 (epoch 2.949), train_loss = 2.21348474, grad/param norm = 2.0775e-01, time/batch = 0.7190s	
1788/30300 (epoch 2.950), train_loss = 2.13304794, grad/param norm = 2.2680e-01, time/batch = 0.7087s	
1789/30300 (epoch 2.952), train_loss = 2.13897638, grad/param norm = 2.6179e-01, time/batch = 0.6972s	
1790/30300 (epoch 2.954), train_loss = 2.20347873, grad/param norm = 2.3196e-01, time/batch = 0.7004s	
1791/30300 (epoch 2.955), train_loss = 1.96227413, grad/param norm = 2.3841e-01, time/batch = 0.6896s	
1792/30300 (epoch 2.957), train_loss = 2.05346026, grad/param norm = 2.2900e-01, time/batch = 0.6846s	
1793/30300 (epoch 2.959), train_loss = 2.03269095, grad/param norm = 2.1326e-01, time/batch = 0.6909s	
1794/30300 (epoch 2.960), train_loss = 1.95382936, grad/param norm = 1.9729e-01, time/batch = 0.6928s	
1795/30300 (epoch 2.962), train_loss = 1.93132521, grad/param norm = 2.2038e-01, time/batch = 0.6870s	
1796/30300 (epoch 2.964), train_loss = 2.08236765, grad/param norm = 2.3272e-01, time/batch = 0.6856s	
1797/30300 (epoch 2.965), train_loss = 1.92886007, grad/param norm = 2.0899e-01, time/batch = 0.6859s	
1798/30300 (epoch 2.967), train_loss = 2.05384785, grad/param norm = 2.2649e-01, time/batch = 0.7025s	
1799/30300 (epoch 2.969), train_loss = 1.97346384, grad/param norm = 2.6768e-01, time/batch = 0.6879s	
1800/30300 (epoch 2.970), train_loss = 1.97674303, grad/param norm = 3.1746e-01, time/batch = 0.6931s	
1801/30300 (epoch 2.972), train_loss = 1.87843682, grad/param norm = 1.9922e-01, time/batch = 0.7025s	
1802/30300 (epoch 2.974), train_loss = 2.12465010, grad/param norm = 2.1762e-01, time/batch = 0.7187s	
1803/30300 (epoch 2.975), train_loss = 2.19831413, grad/param norm = 2.3416e-01, time/batch = 0.6958s	
1804/30300 (epoch 2.977), train_loss = 2.02046738, grad/param norm = 2.1725e-01, time/batch = 0.6979s	
1805/30300 (epoch 2.979), train_loss = 2.10374880, grad/param norm = 2.2205e-01, time/batch = 0.6842s	
1806/30300 (epoch 2.980), train_loss = 2.06705422, grad/param norm = 2.2926e-01, time/batch = 0.6830s	
1807/30300 (epoch 2.982), train_loss = 2.06862055, grad/param norm = 2.0599e-01, time/batch = 0.6853s	
1808/30300 (epoch 2.983), train_loss = 2.10579695, grad/param norm = 2.1871e-01, time/batch = 0.6868s	
1809/30300 (epoch 2.985), train_loss = 2.03497939, grad/param norm = 2.5159e-01, time/batch = 0.6893s	
1810/30300 (epoch 2.987), train_loss = 1.90332246, grad/param norm = 1.9788e-01, time/batch = 0.6960s	
1811/30300 (epoch 2.988), train_loss = 2.15767995, grad/param norm = 2.2330e-01, time/batch = 0.6891s	
1812/30300 (epoch 2.990), train_loss = 1.83297376, grad/param norm = 1.8179e-01, time/batch = 0.6902s	
1813/30300 (epoch 2.992), train_loss = 2.01833512, grad/param norm = 2.0638e-01, time/batch = 0.6897s	
1814/30300 (epoch 2.993), train_loss = 2.18563740, grad/param norm = 2.4454e-01, time/batch = 0.6921s	
1815/30300 (epoch 2.995), train_loss = 2.10871800, grad/param norm = 2.2284e-01, time/batch = 0.6920s	
1816/30300 (epoch 2.997), train_loss = 2.04409251, grad/param norm = 2.1446e-01, time/batch = 0.7205s	
1817/30300 (epoch 2.998), train_loss = 2.07542706, grad/param norm = 2.3877e-01, time/batch = 0.7011s	
1818/30300 (epoch 3.000), train_loss = 1.92810820, grad/param norm = 2.2858e-01, time/batch = 0.6969s	
1819/30300 (epoch 3.002), train_loss = 1.93740511, grad/param norm = 1.9908e-01, time/batch = 0.6911s	
1820/30300 (epoch 3.003), train_loss = 2.04498117, grad/param norm = 2.2005e-01, time/batch = 0.6907s	
1821/30300 (epoch 3.005), train_loss = 2.04128937, grad/param norm = 2.3483e-01, time/batch = 0.6906s	
1822/30300 (epoch 3.007), train_loss = 2.10354067, grad/param norm = 2.1178e-01, time/batch = 0.6920s	
1823/30300 (epoch 3.008), train_loss = 1.92366414, grad/param norm = 2.1299e-01, time/batch = 0.6942s	
1824/30300 (epoch 3.010), train_loss = 1.99932888, grad/param norm = 2.3342e-01, time/batch = 0.6885s	
1825/30300 (epoch 3.012), train_loss = 1.92219026, grad/param norm = 1.9906e-01, time/batch = 0.6941s	
1826/30300 (epoch 3.013), train_loss = 2.08659570, grad/param norm = 2.1440e-01, time/batch = 0.6896s	
1827/30300 (epoch 3.015), train_loss = 1.96138266, grad/param norm = 2.2581e-01, time/batch = 0.6888s	
1828/30300 (epoch 3.017), train_loss = 1.83722272, grad/param norm = 2.1448e-01, time/batch = 0.6841s	
1829/30300 (epoch 3.018), train_loss = 2.08783437, grad/param norm = 2.1116e-01, time/batch = 0.7009s	
1830/30300 (epoch 3.020), train_loss = 2.16837131, grad/param norm = 2.2249e-01, time/batch = 0.7161s	
1831/30300 (epoch 3.021), train_loss = 2.10454447, grad/param norm = 2.5551e-01, time/batch = 0.7231s	
1832/30300 (epoch 3.023), train_loss = 1.89847601, grad/param norm = 2.5902e-01, time/batch = 0.7204s	
1833/30300 (epoch 3.025), train_loss = 1.91267965, grad/param norm = 2.2654e-01, time/batch = 0.7202s	
1834/30300 (epoch 3.026), train_loss = 1.96017223, grad/param norm = 2.0226e-01, time/batch = 0.7170s	
1835/30300 (epoch 3.028), train_loss = 1.98595084, grad/param norm = 2.0956e-01, time/batch = 0.7026s	
1836/30300 (epoch 3.030), train_loss = 1.84285222, grad/param norm = 2.2396e-01, time/batch = 0.6944s	
1837/30300 (epoch 3.031), train_loss = 1.97888380, grad/param norm = 2.4005e-01, time/batch = 0.6909s	
1838/30300 (epoch 3.033), train_loss = 1.95568722, grad/param norm = 2.5232e-01, time/batch = 0.6874s	
1839/30300 (epoch 3.035), train_loss = 2.03560890, grad/param norm = 1.9905e-01, time/batch = 0.6888s	
1840/30300 (epoch 3.036), train_loss = 2.16128677, grad/param norm = 2.3754e-01, time/batch = 0.6904s	
1841/30300 (epoch 3.038), train_loss = 2.01761768, grad/param norm = 2.1461e-01, time/batch = 0.6892s	
1842/30300 (epoch 3.040), train_loss = 1.65034329, grad/param norm = 1.9744e-01, time/batch = 0.6876s	
1843/30300 (epoch 3.041), train_loss = 1.77125277, grad/param norm = 2.2060e-01, time/batch = 0.6904s	
1844/30300 (epoch 3.043), train_loss = 2.06339472, grad/param norm = 2.2102e-01, time/batch = 0.6856s	
1845/30300 (epoch 3.045), train_loss = 1.92166456, grad/param norm = 2.4367e-01, time/batch = 0.6899s	
1846/30300 (epoch 3.046), train_loss = 1.99276473, grad/param norm = 2.3575e-01, time/batch = 0.6919s	
1847/30300 (epoch 3.048), train_loss = 2.00169689, grad/param norm = 2.4413e-01, time/batch = 0.6871s	
1848/30300 (epoch 3.050), train_loss = 2.09430786, grad/param norm = 2.1966e-01, time/batch = 0.6890s	
1849/30300 (epoch 3.051), train_loss = 1.98600861, grad/param norm = 2.1663e-01, time/batch = 0.6980s	
1850/30300 (epoch 3.053), train_loss = 1.87360877, grad/param norm = 2.2419e-01, time/batch = 0.7035s	
1851/30300 (epoch 3.054), train_loss = 1.88364668, grad/param norm = 2.5105e-01, time/batch = 0.7002s	
1852/30300 (epoch 3.056), train_loss = 1.87850946, grad/param norm = 2.3189e-01, time/batch = 0.6925s	
1853/30300 (epoch 3.058), train_loss = 2.05315903, grad/param norm = 2.3220e-01, time/batch = 0.6903s	
1854/30300 (epoch 3.059), train_loss = 1.99956921, grad/param norm = 1.9721e-01, time/batch = 0.6891s	
1855/30300 (epoch 3.061), train_loss = 2.13175912, grad/param norm = 2.5544e-01, time/batch = 0.6926s	
1856/30300 (epoch 3.063), train_loss = 1.94012681, grad/param norm = 2.1857e-01, time/batch = 0.6924s	
1857/30300 (epoch 3.064), train_loss = 2.09375180, grad/param norm = 2.0161e-01, time/batch = 0.6907s	
1858/30300 (epoch 3.066), train_loss = 1.96527331, grad/param norm = 1.9863e-01, time/batch = 0.6951s	
1859/30300 (epoch 3.068), train_loss = 1.84269371, grad/param norm = 1.8598e-01, time/batch = 0.7159s	
1860/30300 (epoch 3.069), train_loss = 2.10201134, grad/param norm = 2.0237e-01, time/batch = 0.7218s	
1861/30300 (epoch 3.071), train_loss = 2.05960359, grad/param norm = 2.3118e-01, time/batch = 0.7183s	
1862/30300 (epoch 3.073), train_loss = 2.14892202, grad/param norm = 2.7134e-01, time/batch = 0.7176s	
1863/30300 (epoch 3.074), train_loss = 2.07897041, grad/param norm = 2.2553e-01, time/batch = 0.7159s	
1864/30300 (epoch 3.076), train_loss = 1.91517281, grad/param norm = 2.1752e-01, time/batch = 0.7152s	
1865/30300 (epoch 3.078), train_loss = 1.80848633, grad/param norm = 2.2589e-01, time/batch = 0.7286s	
1866/30300 (epoch 3.079), train_loss = 1.80021757, grad/param norm = 1.8283e-01, time/batch = 0.7282s	
1867/30300 (epoch 3.081), train_loss = 2.13078519, grad/param norm = 2.3516e-01, time/batch = 0.7447s	
1868/30300 (epoch 3.083), train_loss = 2.23010342, grad/param norm = 2.1887e-01, time/batch = 0.7507s	
1869/30300 (epoch 3.084), train_loss = 1.94220267, grad/param norm = 2.2552e-01, time/batch = 0.7402s	
1870/30300 (epoch 3.086), train_loss = 1.99434265, grad/param norm = 2.1197e-01, time/batch = 0.7247s	
1871/30300 (epoch 3.087), train_loss = 1.87707412, grad/param norm = 1.9519e-01, time/batch = 0.7256s	
1872/30300 (epoch 3.089), train_loss = 1.97104794, grad/param norm = 2.1616e-01, time/batch = 0.7242s	
1873/30300 (epoch 3.091), train_loss = 2.06960162, grad/param norm = 2.2307e-01, time/batch = 0.7418s	
1874/30300 (epoch 3.092), train_loss = 1.89566595, grad/param norm = 2.4349e-01, time/batch = 0.7262s	
1875/30300 (epoch 3.094), train_loss = 2.20813789, grad/param norm = 2.1546e-01, time/batch = 0.6867s	
1876/30300 (epoch 3.096), train_loss = 1.96113315, grad/param norm = 2.1622e-01, time/batch = 0.6854s	
1877/30300 (epoch 3.097), train_loss = 1.87615567, grad/param norm = 2.4755e-01, time/batch = 0.6883s	
1878/30300 (epoch 3.099), train_loss = 2.14161228, grad/param norm = 2.1948e-01, time/batch = 0.7035s	
1879/30300 (epoch 3.101), train_loss = 2.16930296, grad/param norm = 1.9642e-01, time/batch = 0.6978s	
1880/30300 (epoch 3.102), train_loss = 2.05516360, grad/param norm = 2.1962e-01, time/batch = 0.6938s	
1881/30300 (epoch 3.104), train_loss = 1.85652351, grad/param norm = 1.8886e-01, time/batch = 0.6885s	
1882/30300 (epoch 3.106), train_loss = 2.07683495, grad/param norm = 2.6054e-01, time/batch = 0.6930s	
1883/30300 (epoch 3.107), train_loss = 1.96984649, grad/param norm = 2.5725e-01, time/batch = 0.6889s	
1884/30300 (epoch 3.109), train_loss = 2.09408376, grad/param norm = 2.3851e-01, time/batch = 0.6885s	
1885/30300 (epoch 3.111), train_loss = 2.05716778, grad/param norm = 2.3541e-01, time/batch = 0.6945s	
1886/30300 (epoch 3.112), train_loss = 2.01061618, grad/param norm = 2.2844e-01, time/batch = 0.6894s	
1887/30300 (epoch 3.114), train_loss = 1.90267511, grad/param norm = 2.0994e-01, time/batch = 0.6923s	
1888/30300 (epoch 3.116), train_loss = 2.02653601, grad/param norm = 2.1507e-01, time/batch = 0.6990s	
1889/30300 (epoch 3.117), train_loss = 1.91599211, grad/param norm = 1.9212e-01, time/batch = 0.7066s	
1890/30300 (epoch 3.119), train_loss = 1.82846576, grad/param norm = 2.2043e-01, time/batch = 0.6943s	
1891/30300 (epoch 3.120), train_loss = 1.91061468, grad/param norm = 2.4801e-01, time/batch = 0.7117s	
1892/30300 (epoch 3.122), train_loss = 2.03359889, grad/param norm = 2.1218e-01, time/batch = 0.6964s	
1893/30300 (epoch 3.124), train_loss = 2.15715063, grad/param norm = 2.6229e-01, time/batch = 0.6942s	
1894/30300 (epoch 3.125), train_loss = 1.81358932, grad/param norm = 2.3913e-01, time/batch = 0.6907s	
1895/30300 (epoch 3.127), train_loss = 1.99183734, grad/param norm = 2.0793e-01, time/batch = 0.6927s	
1896/30300 (epoch 3.129), train_loss = 2.08566968, grad/param norm = 2.0645e-01, time/batch = 0.6931s	
1897/30300 (epoch 3.130), train_loss = 2.11366241, grad/param norm = 2.0910e-01, time/batch = 0.6898s	
1898/30300 (epoch 3.132), train_loss = 1.96784321, grad/param norm = 2.2150e-01, time/batch = 0.6924s	
1899/30300 (epoch 3.134), train_loss = 1.83519872, grad/param norm = 2.3077e-01, time/batch = 0.6937s	
1900/30300 (epoch 3.135), train_loss = 1.97088162, grad/param norm = 2.1196e-01, time/batch = 0.6935s	
1901/30300 (epoch 3.137), train_loss = 2.10647174, grad/param norm = 2.1565e-01, time/batch = 0.7193s	
1902/30300 (epoch 3.139), train_loss = 1.97096163, grad/param norm = 2.2788e-01, time/batch = 0.7055s	
1903/30300 (epoch 3.140), train_loss = 2.27917049, grad/param norm = 5.5694e-01, time/batch = 0.6882s	
1904/30300 (epoch 3.142), train_loss = 2.18229599, grad/param norm = 2.4310e-01, time/batch = 0.6891s	
1905/30300 (epoch 3.144), train_loss = 2.05331878, grad/param norm = 2.2763e-01, time/batch = 0.6945s	
1906/30300 (epoch 3.145), train_loss = 2.12661160, grad/param norm = 1.9828e-01, time/batch = 0.6920s	
1907/30300 (epoch 3.147), train_loss = 2.04675469, grad/param norm = 2.3263e-01, time/batch = 0.6918s	
1908/30300 (epoch 3.149), train_loss = 2.18553347, grad/param norm = 2.2149e-01, time/batch = 0.6941s	
1909/30300 (epoch 3.150), train_loss = 2.16377702, grad/param norm = 1.9127e-01, time/batch = 0.6905s	
1910/30300 (epoch 3.152), train_loss = 1.99002594, grad/param norm = 2.3014e-01, time/batch = 0.6921s	
1911/30300 (epoch 3.153), train_loss = 2.04963421, grad/param norm = 2.3202e-01, time/batch = 0.7056s	
1912/30300 (epoch 3.155), train_loss = 1.78859239, grad/param norm = 2.0190e-01, time/batch = 0.6986s	
1913/30300 (epoch 3.157), train_loss = 1.99300122, grad/param norm = 2.0285e-01, time/batch = 0.6887s	
1914/30300 (epoch 3.158), train_loss = 2.05859649, grad/param norm = 2.1634e-01, time/batch = 0.6911s	
1915/30300 (epoch 3.160), train_loss = 1.88273833, grad/param norm = 2.2560e-01, time/batch = 0.7067s	
1916/30300 (epoch 3.162), train_loss = 1.89278201, grad/param norm = 2.5626e-01, time/batch = 0.7172s	
1917/30300 (epoch 3.163), train_loss = 1.87997797, grad/param norm = 2.4867e-01, time/batch = 0.6939s	
1918/30300 (epoch 3.165), train_loss = 2.01224628, grad/param norm = 2.3715e-01, time/batch = 0.7102s	
1919/30300 (epoch 3.167), train_loss = 2.03266703, grad/param norm = 2.2649e-01, time/batch = 0.6927s	
1920/30300 (epoch 3.168), train_loss = 1.88516288, grad/param norm = 2.3935e-01, time/batch = 0.6920s	
1921/30300 (epoch 3.170), train_loss = 2.01552640, grad/param norm = 2.1831e-01, time/batch = 0.6903s	
1922/30300 (epoch 3.172), train_loss = 1.91562125, grad/param norm = 1.9524e-01, time/batch = 0.6916s	
1923/30300 (epoch 3.173), train_loss = 2.06291108, grad/param norm = 2.0615e-01, time/batch = 0.6929s	
1924/30300 (epoch 3.175), train_loss = 1.95244853, grad/param norm = 2.2765e-01, time/batch = 0.6934s	
1925/30300 (epoch 3.177), train_loss = 2.02998233, grad/param norm = 1.9541e-01, time/batch = 0.6952s	
1926/30300 (epoch 3.178), train_loss = 1.80856921, grad/param norm = 2.5937e-01, time/batch = 0.6894s	
1927/30300 (epoch 3.180), train_loss = 1.92963634, grad/param norm = 2.1015e-01, time/batch = 0.6910s	
1928/30300 (epoch 3.182), train_loss = 1.92121771, grad/param norm = 2.3948e-01, time/batch = 0.6928s	
1929/30300 (epoch 3.183), train_loss = 1.84086038, grad/param norm = 1.8537e-01, time/batch = 0.6955s	
1930/30300 (epoch 3.185), train_loss = 2.32819416, grad/param norm = 2.3110e-01, time/batch = 0.7206s	
1931/30300 (epoch 3.186), train_loss = 2.18072930, grad/param norm = 2.3295e-01, time/batch = 0.6983s	
1932/30300 (epoch 3.188), train_loss = 1.98523536, grad/param norm = 2.1263e-01, time/batch = 0.6903s	
1933/30300 (epoch 3.190), train_loss = 1.87212600, grad/param norm = 2.0173e-01, time/batch = 0.6918s	
1934/30300 (epoch 3.191), train_loss = 2.06481350, grad/param norm = 2.1725e-01, time/batch = 0.6957s	
1935/30300 (epoch 3.193), train_loss = 1.84754116, grad/param norm = 2.1188e-01, time/batch = 0.6894s	
1936/30300 (epoch 3.195), train_loss = 2.03071518, grad/param norm = 2.6503e-01, time/batch = 0.6906s	
1937/30300 (epoch 3.196), train_loss = 2.11498092, grad/param norm = 2.5099e-01, time/batch = 0.6962s	
1938/30300 (epoch 3.198), train_loss = 1.75369070, grad/param norm = 2.0184e-01, time/batch = 0.6985s	
1939/30300 (epoch 3.200), train_loss = 1.91788003, grad/param norm = 2.3419e-01, time/batch = 0.6905s	
1940/30300 (epoch 3.201), train_loss = 2.13701875, grad/param norm = 2.1640e-01, time/batch = 0.6904s	
1941/30300 (epoch 3.203), train_loss = 1.96134101, grad/param norm = 2.0326e-01, time/batch = 0.6909s	
1942/30300 (epoch 3.205), train_loss = 2.20843416, grad/param norm = 2.0890e-01, time/batch = 0.6973s	
1943/30300 (epoch 3.206), train_loss = 2.20822590, grad/param norm = 2.2447e-01, time/batch = 0.7034s	
1944/30300 (epoch 3.208), train_loss = 2.18004214, grad/param norm = 2.3579e-01, time/batch = 0.7193s	
1945/30300 (epoch 3.210), train_loss = 2.01681360, grad/param norm = 2.1212e-01, time/batch = 0.7031s	
1946/30300 (epoch 3.211), train_loss = 1.99188341, grad/param norm = 1.9701e-01, time/batch = 0.6892s	
1947/30300 (epoch 3.213), train_loss = 1.96674902, grad/param norm = 2.3443e-01, time/batch = 0.6877s	
1948/30300 (epoch 3.215), train_loss = 1.76435002, grad/param norm = 1.9587e-01, time/batch = 0.6929s	
1949/30300 (epoch 3.216), train_loss = 1.99373718, grad/param norm = 2.3169e-01, time/batch = 0.6898s	
1950/30300 (epoch 3.218), train_loss = 1.92901808, grad/param norm = 2.2095e-01, time/batch = 0.6915s	
1951/30300 (epoch 3.219), train_loss = 1.82996780, grad/param norm = 2.2432e-01, time/batch = 0.6921s	
1952/30300 (epoch 3.221), train_loss = 1.81526381, grad/param norm = 2.0164e-01, time/batch = 0.7020s	
1953/30300 (epoch 3.223), train_loss = 1.89824172, grad/param norm = 1.9035e-01, time/batch = 0.7055s	
1954/30300 (epoch 3.224), train_loss = 1.72170557, grad/param norm = 1.8564e-01, time/batch = 0.7003s	
1955/30300 (epoch 3.226), train_loss = 2.02880321, grad/param norm = 2.2067e-01, time/batch = 0.6894s	
1956/30300 (epoch 3.228), train_loss = 1.99475432, grad/param norm = 2.1243e-01, time/batch = 0.6903s	
1957/30300 (epoch 3.229), train_loss = 1.86231535, grad/param norm = 2.4937e-01, time/batch = 0.6894s	
1958/30300 (epoch 3.231), train_loss = 1.95617670, grad/param norm = 2.3333e-01, time/batch = 0.7116s	
1959/30300 (epoch 3.233), train_loss = 1.86995531, grad/param norm = 2.1506e-01, time/batch = 0.7213s	
1960/30300 (epoch 3.234), train_loss = 2.03521294, grad/param norm = 2.1109e-01, time/batch = 0.6949s	
1961/30300 (epoch 3.236), train_loss = 1.91142257, grad/param norm = 2.5615e-01, time/batch = 0.6928s	
1962/30300 (epoch 3.238), train_loss = 2.08054379, grad/param norm = 2.8216e-01, time/batch = 0.6895s	
1963/30300 (epoch 3.239), train_loss = 1.94567728, grad/param norm = 2.5652e-01, time/batch = 0.6885s	
1964/30300 (epoch 3.241), train_loss = 1.93569096, grad/param norm = 1.9428e-01, time/batch = 0.6992s	
1965/30300 (epoch 3.243), train_loss = 1.93240923, grad/param norm = 2.1678e-01, time/batch = 0.6929s	
1966/30300 (epoch 3.244), train_loss = 2.29054175, grad/param norm = 2.3459e-01, time/batch = 0.6903s	
1967/30300 (epoch 3.246), train_loss = 1.90534653, grad/param norm = 1.9870e-01, time/batch = 0.6914s	
1968/30300 (epoch 3.248), train_loss = 2.04844217, grad/param norm = 1.8941e-01, time/batch = 0.6921s	
1969/30300 (epoch 3.249), train_loss = 1.77422982, grad/param norm = 2.1619e-01, time/batch = 0.6892s	
1970/30300 (epoch 3.251), train_loss = 1.85342365, grad/param norm = 1.9929e-01, time/batch = 0.6887s	
1971/30300 (epoch 3.252), train_loss = 2.13307784, grad/param norm = 2.1564e-01, time/batch = 0.6976s	
1972/30300 (epoch 3.254), train_loss = 1.99911701, grad/param norm = 1.9809e-01, time/batch = 0.7124s	
1973/30300 (epoch 3.256), train_loss = 1.99811820, grad/param norm = 2.0238e-01, time/batch = 0.7210s	
1974/30300 (epoch 3.257), train_loss = 2.14342466, grad/param norm = 2.2052e-01, time/batch = 0.6894s	
1975/30300 (epoch 3.259), train_loss = 2.02839510, grad/param norm = 2.2352e-01, time/batch = 0.6888s	
1976/30300 (epoch 3.261), train_loss = 2.14877305, grad/param norm = 2.2832e-01, time/batch = 0.6873s	
1977/30300 (epoch 3.262), train_loss = 1.94005837, grad/param norm = 1.9359e-01, time/batch = 0.6860s	
1978/30300 (epoch 3.264), train_loss = 1.97767655, grad/param norm = 2.1705e-01, time/batch = 0.6873s	
1979/30300 (epoch 3.266), train_loss = 1.88904977, grad/param norm = 1.8386e-01, time/batch = 0.6868s	
1980/30300 (epoch 3.267), train_loss = 2.12157226, grad/param norm = 2.2261e-01, time/batch = 0.6873s	
1981/30300 (epoch 3.269), train_loss = 2.02431313, grad/param norm = 2.2182e-01, time/batch = 0.6872s	
1982/30300 (epoch 3.271), train_loss = 1.98292301, grad/param norm = 2.3551e-01, time/batch = 0.6890s	
1983/30300 (epoch 3.272), train_loss = 1.99111817, grad/param norm = 1.9253e-01, time/batch = 0.6932s	
1984/30300 (epoch 3.274), train_loss = 2.09307776, grad/param norm = 2.0991e-01, time/batch = 0.6906s	
1985/30300 (epoch 3.276), train_loss = 2.11562290, grad/param norm = 2.2943e-01, time/batch = 0.6874s	
1986/30300 (epoch 3.277), train_loss = 1.90104713, grad/param norm = 2.2105e-01, time/batch = 0.6862s	
1987/30300 (epoch 3.279), train_loss = 1.98041166, grad/param norm = 2.0019e-01, time/batch = 0.7190s	
1988/30300 (epoch 3.281), train_loss = 1.99929057, grad/param norm = 2.0629e-01, time/batch = 0.7019s	
1989/30300 (epoch 3.282), train_loss = 1.85535705, grad/param norm = 2.0771e-01, time/batch = 0.6835s	
1990/30300 (epoch 3.284), train_loss = 2.18471203, grad/param norm = 2.5576e-01, time/batch = 0.6843s	
1991/30300 (epoch 3.285), train_loss = 2.03853358, grad/param norm = 2.2464e-01, time/batch = 0.6876s	
1992/30300 (epoch 3.287), train_loss = 2.05015952, grad/param norm = 2.3022e-01, time/batch = 0.6824s	
1993/30300 (epoch 3.289), train_loss = 1.98746446, grad/param norm = 2.2887e-01, time/batch = 0.6913s	
1994/30300 (epoch 3.290), train_loss = 1.68066547, grad/param norm = 1.8895e-01, time/batch = 0.6939s	
1995/30300 (epoch 3.292), train_loss = 1.85633602, grad/param norm = 1.9585e-01, time/batch = 0.6904s	
1996/30300 (epoch 3.294), train_loss = 2.11073984, grad/param norm = 1.9385e-01, time/batch = 0.6934s	
1997/30300 (epoch 3.295), train_loss = 1.90056589, grad/param norm = 1.8745e-01, time/batch = 0.6899s	
1998/30300 (epoch 3.297), train_loss = 1.88537985, grad/param norm = 2.1343e-01, time/batch = 0.6871s	
1999/30300 (epoch 3.299), train_loss = 2.01978868, grad/param norm = 2.3152e-01, time/batch = 0.6869s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch3.30_1.9930.t7	
2000/30300 (epoch 3.300), train_loss = 1.94606052, grad/param norm = 1.8887e-01, time/batch = 0.6870s	
2001/30300 (epoch 3.302), train_loss = 1.98194903, grad/param norm = 2.2210e-01, time/batch = 0.7016s	
2002/30300 (epoch 3.304), train_loss = 1.82656962, grad/param norm = 2.1093e-01, time/batch = 0.7001s	
2003/30300 (epoch 3.305), train_loss = 1.93483132, grad/param norm = 2.0313e-01, time/batch = 0.6960s	
2004/30300 (epoch 3.307), train_loss = 1.92821520, grad/param norm = 2.1727e-01, time/batch = 0.6988s	
2005/30300 (epoch 3.309), train_loss = 2.08444349, grad/param norm = 2.1047e-01, time/batch = 0.6996s	
2006/30300 (epoch 3.310), train_loss = 1.86237855, grad/param norm = 2.1105e-01, time/batch = 0.6889s	
2007/30300 (epoch 3.312), train_loss = 1.95616720, grad/param norm = 2.1119e-01, time/batch = 0.6977s	
2008/30300 (epoch 3.314), train_loss = 1.98994307, grad/param norm = 2.0521e-01, time/batch = 0.6893s	
2009/30300 (epoch 3.315), train_loss = 2.02715813, grad/param norm = 2.0512e-01, time/batch = 0.6880s	
2010/30300 (epoch 3.317), train_loss = 2.01862683, grad/param norm = 2.0327e-01, time/batch = 0.6951s	
2011/30300 (epoch 3.318), train_loss = 2.19638816, grad/param norm = 2.2293e-01, time/batch = 0.7100s	
2012/30300 (epoch 3.320), train_loss = 2.05032013, grad/param norm = 2.3757e-01, time/batch = 0.7162s	
2013/30300 (epoch 3.322), train_loss = 1.80927755, grad/param norm = 2.0177e-01, time/batch = 0.6837s	
2014/30300 (epoch 3.323), train_loss = 2.02849917, grad/param norm = 1.9364e-01, time/batch = 0.6947s	
2015/30300 (epoch 3.325), train_loss = 1.87369550, grad/param norm = 2.0096e-01, time/batch = 0.6896s	
2016/30300 (epoch 3.327), train_loss = 1.81667480, grad/param norm = 2.1380e-01, time/batch = 0.6897s	
2017/30300 (epoch 3.328), train_loss = 1.85925814, grad/param norm = 1.9852e-01, time/batch = 0.6931s	
2018/30300 (epoch 3.330), train_loss = 2.02948926, grad/param norm = 2.1632e-01, time/batch = 0.6903s	
2019/30300 (epoch 3.332), train_loss = 2.08183880, grad/param norm = 2.0643e-01, time/batch = 0.6933s	
2020/30300 (epoch 3.333), train_loss = 1.98656263, grad/param norm = 2.1500e-01, time/batch = 0.6898s	
2021/30300 (epoch 3.335), train_loss = 1.73612345, grad/param norm = 2.3350e-01, time/batch = 0.6922s	
2022/30300 (epoch 3.337), train_loss = 2.16872340, grad/param norm = 2.2882e-01, time/batch = 0.6905s	
2023/30300 (epoch 3.338), train_loss = 1.88092820, grad/param norm = 2.3958e-01, time/batch = 0.6906s	
2024/30300 (epoch 3.340), train_loss = 1.93959205, grad/param norm = 2.5568e-01, time/batch = 0.6890s	
2025/30300 (epoch 3.342), train_loss = 1.98846453, grad/param norm = 1.9896e-01, time/batch = 0.6942s	
2026/30300 (epoch 3.343), train_loss = 1.95530476, grad/param norm = 2.2111e-01, time/batch = 0.7208s	
2027/30300 (epoch 3.345), train_loss = 1.96343732, grad/param norm = 2.4163e-01, time/batch = 0.6985s	
2028/30300 (epoch 3.347), train_loss = 1.73656213, grad/param norm = 1.9531e-01, time/batch = 0.6996s	
2029/30300 (epoch 3.348), train_loss = 1.82358608, grad/param norm = 2.0526e-01, time/batch = 0.6955s	
2030/30300 (epoch 3.350), train_loss = 1.93792609, grad/param norm = 2.3070e-01, time/batch = 0.7047s	
2031/30300 (epoch 3.351), train_loss = 1.92396984, grad/param norm = 2.1785e-01, time/batch = 0.7043s	
2032/30300 (epoch 3.353), train_loss = 1.71773013, grad/param norm = 2.3413e-01, time/batch = 0.7133s	
2033/30300 (epoch 3.355), train_loss = 1.97876778, grad/param norm = 1.9316e-01, time/batch = 0.6992s	
2034/30300 (epoch 3.356), train_loss = 2.05819475, grad/param norm = 2.0305e-01, time/batch = 0.6902s	
2035/30300 (epoch 3.358), train_loss = 2.12381242, grad/param norm = 2.3594e-01, time/batch = 0.6908s	
2036/30300 (epoch 3.360), train_loss = 1.87103990, grad/param norm = 1.8430e-01, time/batch = 0.6897s	
2037/30300 (epoch 3.361), train_loss = 2.00118026, grad/param norm = 2.3464e-01, time/batch = 0.6893s	
2038/30300 (epoch 3.363), train_loss = 2.05255573, grad/param norm = 2.4349e-01, time/batch = 0.6895s	
2039/30300 (epoch 3.365), train_loss = 1.89607066, grad/param norm = 2.3510e-01, time/batch = 0.6883s	
2040/30300 (epoch 3.366), train_loss = 1.88955986, grad/param norm = 2.1482e-01, time/batch = 0.6930s	
2041/30300 (epoch 3.368), train_loss = 1.72379153, grad/param norm = 2.0345e-01, time/batch = 0.6902s	
2042/30300 (epoch 3.370), train_loss = 1.94420401, grad/param norm = 2.0835e-01, time/batch = 0.6978s	
2043/30300 (epoch 3.371), train_loss = 1.94350265, grad/param norm = 2.0583e-01, time/batch = 0.6972s	
2044/30300 (epoch 3.373), train_loss = 1.91506190, grad/param norm = 2.0880e-01, time/batch = 0.6931s	
2045/30300 (epoch 3.375), train_loss = 1.83863941, grad/param norm = 2.0257e-01, time/batch = 0.6934s	
2046/30300 (epoch 3.376), train_loss = 1.88029800, grad/param norm = 1.9513e-01, time/batch = 0.6926s	
2047/30300 (epoch 3.378), train_loss = 1.88265477, grad/param norm = 1.9874e-01, time/batch = 0.6917s	
2048/30300 (epoch 3.380), train_loss = 2.14440815, grad/param norm = 2.1352e-01, time/batch = 0.6907s	
2049/30300 (epoch 3.381), train_loss = 1.95319660, grad/param norm = 1.9240e-01, time/batch = 0.6888s	
2050/30300 (epoch 3.383), train_loss = 2.05019200, grad/param norm = 2.1922e-01, time/batch = 0.7173s	
2051/30300 (epoch 3.384), train_loss = 2.07861740, grad/param norm = 2.0002e-01, time/batch = 0.7046s	
2052/30300 (epoch 3.386), train_loss = 1.82844608, grad/param norm = 2.2148e-01, time/batch = 0.6911s	
2053/30300 (epoch 3.388), train_loss = 1.91942640, grad/param norm = 2.0010e-01, time/batch = 0.6890s	
2054/30300 (epoch 3.389), train_loss = 1.94239004, grad/param norm = 2.2138e-01, time/batch = 0.6907s	
2055/30300 (epoch 3.391), train_loss = 2.00731734, grad/param norm = 2.0151e-01, time/batch = 0.6897s	
2056/30300 (epoch 3.393), train_loss = 1.78186434, grad/param norm = 2.0534e-01, time/batch = 0.6957s	
2057/30300 (epoch 3.394), train_loss = 1.91574897, grad/param norm = 1.8529e-01, time/batch = 0.7056s	
2058/30300 (epoch 3.396), train_loss = 2.04007742, grad/param norm = 2.1011e-01, time/batch = 0.7025s	
2059/30300 (epoch 3.398), train_loss = 1.86623329, grad/param norm = 1.9850e-01, time/batch = 0.6947s	
2060/30300 (epoch 3.399), train_loss = 1.82988264, grad/param norm = 1.8734e-01, time/batch = 0.6880s	
2061/30300 (epoch 3.401), train_loss = 2.06069133, grad/param norm = 2.1253e-01, time/batch = 0.6867s	
2062/30300 (epoch 3.403), train_loss = 1.95673822, grad/param norm = 2.1800e-01, time/batch = 0.6897s	
2063/30300 (epoch 3.404), train_loss = 1.92289819, grad/param norm = 2.4561e-01, time/batch = 0.6920s	
2064/30300 (epoch 3.406), train_loss = 1.96640850, grad/param norm = 2.2570e-01, time/batch = 0.7090s	
2065/30300 (epoch 3.408), train_loss = 1.84099307, grad/param norm = 2.0353e-01, time/batch = 0.7126s	
2066/30300 (epoch 3.409), train_loss = 1.70687183, grad/param norm = 2.3505e-01, time/batch = 0.6963s	
2067/30300 (epoch 3.411), train_loss = 1.80009481, grad/param norm = 2.3352e-01, time/batch = 0.6932s	
2068/30300 (epoch 3.413), train_loss = 1.76597750, grad/param norm = 2.0464e-01, time/batch = 0.6904s	
2069/30300 (epoch 3.414), train_loss = 2.06972951, grad/param norm = 1.9826e-01, time/batch = 0.6922s	
2070/30300 (epoch 3.416), train_loss = 1.92721366, grad/param norm = 2.0797e-01, time/batch = 0.6939s	
2071/30300 (epoch 3.417), train_loss = 1.82488387, grad/param norm = 1.7722e-01, time/batch = 0.6906s	
2072/30300 (epoch 3.419), train_loss = 1.72653473, grad/param norm = 2.2733e-01, time/batch = 0.6916s	
2073/30300 (epoch 3.421), train_loss = 1.81255346, grad/param norm = 2.1873e-01, time/batch = 0.7005s	
2074/30300 (epoch 3.422), train_loss = 1.84697223, grad/param norm = 2.0580e-01, time/batch = 0.6954s	
2075/30300 (epoch 3.424), train_loss = 1.96733418, grad/param norm = 2.2131e-01, time/batch = 0.6912s	
2076/30300 (epoch 3.426), train_loss = 1.70668793, grad/param norm = 1.9311e-01, time/batch = 0.6891s	
2077/30300 (epoch 3.427), train_loss = 1.86209809, grad/param norm = 2.0585e-01, time/batch = 0.6940s	
2078/30300 (epoch 3.429), train_loss = 1.94686958, grad/param norm = 2.6348e-01, time/batch = 0.6981s	
2079/30300 (epoch 3.431), train_loss = 1.99257408, grad/param norm = 2.6291e-01, time/batch = 0.7205s	
2080/30300 (epoch 3.432), train_loss = 1.92225854, grad/param norm = 2.2331e-01, time/batch = 0.7074s	
2081/30300 (epoch 3.434), train_loss = 1.82724279, grad/param norm = 1.9685e-01, time/batch = 0.6947s	
2082/30300 (epoch 3.436), train_loss = 1.94712657, grad/param norm = 2.1101e-01, time/batch = 0.6958s	
2083/30300 (epoch 3.437), train_loss = 1.91716251, grad/param norm = 2.1596e-01, time/batch = 0.6914s	
2084/30300 (epoch 3.439), train_loss = 1.82252461, grad/param norm = 2.1499e-01, time/batch = 0.6915s	
2085/30300 (epoch 3.441), train_loss = 1.82493558, grad/param norm = 2.1481e-01, time/batch = 0.6919s	
2086/30300 (epoch 3.442), train_loss = 1.74681578, grad/param norm = 2.2045e-01, time/batch = 0.6920s	
2087/30300 (epoch 3.444), train_loss = 1.79955027, grad/param norm = 2.3339e-01, time/batch = 0.6916s	
2088/30300 (epoch 3.446), train_loss = 1.80703539, grad/param norm = 2.1986e-01, time/batch = 0.6945s	
2089/30300 (epoch 3.447), train_loss = 1.95537835, grad/param norm = 2.8144e-01, time/batch = 0.6911s	
2090/30300 (epoch 3.449), train_loss = 1.84314435, grad/param norm = 2.1785e-01, time/batch = 0.6878s	
2091/30300 (epoch 3.450), train_loss = 2.04659513, grad/param norm = 2.8303e-01, time/batch = 0.6919s	
2092/30300 (epoch 3.452), train_loss = 1.85288534, grad/param norm = 1.7621e-01, time/batch = 0.6885s	
2093/30300 (epoch 3.454), train_loss = 1.86506126, grad/param norm = 2.1955e-01, time/batch = 0.7205s	
2094/30300 (epoch 3.455), train_loss = 2.06933756, grad/param norm = 2.1957e-01, time/batch = 0.7042s	
2095/30300 (epoch 3.457), train_loss = 1.97524908, grad/param norm = 2.1108e-01, time/batch = 0.6919s	
2096/30300 (epoch 3.459), train_loss = 1.95829216, grad/param norm = 2.2630e-01, time/batch = 0.6896s	
2097/30300 (epoch 3.460), train_loss = 1.94272597, grad/param norm = 2.0493e-01, time/batch = 0.6900s	
2098/30300 (epoch 3.462), train_loss = 1.99962611, grad/param norm = 2.1266e-01, time/batch = 0.6907s	
2099/30300 (epoch 3.464), train_loss = 1.91089983, grad/param norm = 2.1882e-01, time/batch = 0.6885s	
2100/30300 (epoch 3.465), train_loss = 1.76680328, grad/param norm = 1.9755e-01, time/batch = 0.6910s	
2101/30300 (epoch 3.467), train_loss = 1.62722094, grad/param norm = 1.9509e-01, time/batch = 0.6927s	
2102/30300 (epoch 3.469), train_loss = 1.85536198, grad/param norm = 2.1560e-01, time/batch = 0.6911s	
2103/30300 (epoch 3.470), train_loss = 1.80916008, grad/param norm = 1.9030e-01, time/batch = 0.6873s	
2104/30300 (epoch 3.472), train_loss = 1.79606567, grad/param norm = 2.2729e-01, time/batch = 0.6922s	
2105/30300 (epoch 3.474), train_loss = 1.91567961, grad/param norm = 2.5075e-01, time/batch = 0.6926s	
2106/30300 (epoch 3.475), train_loss = 1.86268975, grad/param norm = 2.0068e-01, time/batch = 0.6905s	
2107/30300 (epoch 3.477), train_loss = 1.91535172, grad/param norm = 2.1258e-01, time/batch = 0.6885s	
2108/30300 (epoch 3.479), train_loss = 2.00956708, grad/param norm = 2.2039e-01, time/batch = 0.6894s	
2109/30300 (epoch 3.480), train_loss = 1.86288079, grad/param norm = 1.8760e-01, time/batch = 0.6935s	
2110/30300 (epoch 3.482), train_loss = 1.96247207, grad/param norm = 2.5682e-01, time/batch = 0.6938s	
2111/30300 (epoch 3.483), train_loss = 1.96049917, grad/param norm = 2.2755e-01, time/batch = 0.6935s	
2112/30300 (epoch 3.485), train_loss = 1.85946220, grad/param norm = 1.9675e-01, time/batch = 0.6919s	
2113/30300 (epoch 3.487), train_loss = 2.01919426, grad/param norm = 2.3050e-01, time/batch = 0.7000s	
2114/30300 (epoch 3.488), train_loss = 1.83573638, grad/param norm = 1.8837e-01, time/batch = 0.6909s	
2115/30300 (epoch 3.490), train_loss = 1.75861015, grad/param norm = 2.0664e-01, time/batch = 0.7017s	
2116/30300 (epoch 3.492), train_loss = 1.93695497, grad/param norm = 2.2308e-01, time/batch = 0.7088s	
2117/30300 (epoch 3.493), train_loss = 1.83862036, grad/param norm = 2.3841e-01, time/batch = 0.7019s	
2118/30300 (epoch 3.495), train_loss = 1.87832749, grad/param norm = 2.0482e-01, time/batch = 0.7209s	
2119/30300 (epoch 3.497), train_loss = 1.90198002, grad/param norm = 2.2067e-01, time/batch = 0.6992s	
2120/30300 (epoch 3.498), train_loss = 1.92690741, grad/param norm = 2.0414e-01, time/batch = 0.7088s	
2121/30300 (epoch 3.500), train_loss = 2.08132522, grad/param norm = 2.1912e-01, time/batch = 0.7039s	
2122/30300 (epoch 3.502), train_loss = 1.80139638, grad/param norm = 2.4451e-01, time/batch = 0.7221s	
2123/30300 (epoch 3.503), train_loss = 1.94212395, grad/param norm = 2.0121e-01, time/batch = 0.7146s	
2124/30300 (epoch 3.505), train_loss = 1.93830120, grad/param norm = 2.1459e-01, time/batch = 0.6855s	
2125/30300 (epoch 3.507), train_loss = 1.92729692, grad/param norm = 2.0818e-01, time/batch = 0.6838s	
2126/30300 (epoch 3.508), train_loss = 2.07277991, grad/param norm = 2.2462e-01, time/batch = 0.6874s	
2127/30300 (epoch 3.510), train_loss = 1.97691646, grad/param norm = 2.2420e-01, time/batch = 0.6913s	
2128/30300 (epoch 3.512), train_loss = 1.81546569, grad/param norm = 2.0828e-01, time/batch = 0.7019s	
2129/30300 (epoch 3.513), train_loss = 1.93125622, grad/param norm = 2.2650e-01, time/batch = 0.7061s	
2130/30300 (epoch 3.515), train_loss = 1.88690323, grad/param norm = 2.2240e-01, time/batch = 0.6922s	
2131/30300 (epoch 3.517), train_loss = 1.72482643, grad/param norm = 1.9241e-01, time/batch = 0.6980s	
2132/30300 (epoch 3.518), train_loss = 2.00914458, grad/param norm = 2.1575e-01, time/batch = 0.6840s	
2133/30300 (epoch 3.520), train_loss = 2.19997138, grad/param norm = 2.3327e-01, time/batch = 0.6845s	
2134/30300 (epoch 3.521), train_loss = 1.85052813, grad/param norm = 2.2084e-01, time/batch = 0.6869s	
2135/30300 (epoch 3.523), train_loss = 2.03913754, grad/param norm = 2.2225e-01, time/batch = 0.6931s	
2136/30300 (epoch 3.525), train_loss = 1.94765686, grad/param norm = 2.0201e-01, time/batch = 0.6907s	
2137/30300 (epoch 3.526), train_loss = 1.86333983, grad/param norm = 1.9407e-01, time/batch = 0.7096s	
2138/30300 (epoch 3.528), train_loss = 1.73193682, grad/param norm = 2.0243e-01, time/batch = 0.7075s	
2139/30300 (epoch 3.530), train_loss = 1.78557273, grad/param norm = 2.2013e-01, time/batch = 0.6979s	
2140/30300 (epoch 3.531), train_loss = 1.94823833, grad/param norm = 2.0074e-01, time/batch = 0.7068s	
2141/30300 (epoch 3.533), train_loss = 1.96567797, grad/param norm = 1.9120e-01, time/batch = 0.6988s	
2142/30300 (epoch 3.535), train_loss = 1.73222697, grad/param norm = 1.9579e-01, time/batch = 0.7083s	
2143/30300 (epoch 3.536), train_loss = 1.94303250, grad/param norm = 1.9835e-01, time/batch = 0.7126s	
2144/30300 (epoch 3.538), train_loss = 1.72464106, grad/param norm = 2.0030e-01, time/batch = 0.7206s	
2145/30300 (epoch 3.540), train_loss = 1.93540713, grad/param norm = 2.0295e-01, time/batch = 0.7220s	
2146/30300 (epoch 3.541), train_loss = 1.84410604, grad/param norm = 2.0192e-01, time/batch = 0.7180s	
2147/30300 (epoch 3.543), train_loss = 1.89127400, grad/param norm = 2.0193e-01, time/batch = 0.7149s	
2148/30300 (epoch 3.545), train_loss = 2.02344480, grad/param norm = 2.2841e-01, time/batch = 0.7022s	
2149/30300 (epoch 3.546), train_loss = 2.10262650, grad/param norm = 2.2703e-01, time/batch = 0.6911s	
2150/30300 (epoch 3.548), train_loss = 1.82981591, grad/param norm = 2.5065e-01, time/batch = 0.7191s	
2151/30300 (epoch 3.550), train_loss = 2.09740279, grad/param norm = 1.9780e-01, time/batch = 0.7066s	
2152/30300 (epoch 3.551), train_loss = 1.87254310, grad/param norm = 2.0519e-01, time/batch = 0.6930s	
2153/30300 (epoch 3.553), train_loss = 1.82515200, grad/param norm = 1.9156e-01, time/batch = 0.6888s	
2154/30300 (epoch 3.554), train_loss = 2.06802812, grad/param norm = 2.1667e-01, time/batch = 0.6904s	
2155/30300 (epoch 3.556), train_loss = 1.91027578, grad/param norm = 1.8675e-01, time/batch = 0.6884s	
2156/30300 (epoch 3.558), train_loss = 2.04100585, grad/param norm = 1.9756e-01, time/batch = 0.6931s	
2157/30300 (epoch 3.559), train_loss = 1.87594639, grad/param norm = 2.1713e-01, time/batch = 0.6922s	
2158/30300 (epoch 3.561), train_loss = 1.79264196, grad/param norm = 1.9370e-01, time/batch = 0.6947s	
2159/30300 (epoch 3.563), train_loss = 1.94930414, grad/param norm = 2.0389e-01, time/batch = 0.7069s	
2160/30300 (epoch 3.564), train_loss = 1.88490348, grad/param norm = 1.8738e-01, time/batch = 0.6906s	
2161/30300 (epoch 3.566), train_loss = 1.97720818, grad/param norm = 2.4180e-01, time/batch = 0.6917s	
2162/30300 (epoch 3.568), train_loss = 1.76329442, grad/param norm = 2.1595e-01, time/batch = 0.6924s	
2163/30300 (epoch 3.569), train_loss = 1.85775247, grad/param norm = 1.9844e-01, time/batch = 0.6880s	
2164/30300 (epoch 3.571), train_loss = 1.99300262, grad/param norm = 2.3119e-01, time/batch = 0.6868s	
2165/30300 (epoch 3.573), train_loss = 1.95315436, grad/param norm = 2.0513e-01, time/batch = 0.6952s	
2166/30300 (epoch 3.574), train_loss = 1.90364641, grad/param norm = 2.1339e-01, time/batch = 0.6933s	
2167/30300 (epoch 3.576), train_loss = 1.92877295, grad/param norm = 2.0995e-01, time/batch = 0.6920s	
2168/30300 (epoch 3.578), train_loss = 1.78796273, grad/param norm = 1.8160e-01, time/batch = 0.6990s	
2169/30300 (epoch 3.579), train_loss = 1.84517180, grad/param norm = 2.1154e-01, time/batch = 0.7204s	
2170/30300 (epoch 3.581), train_loss = 1.97480096, grad/param norm = 2.3850e-01, time/batch = 0.6954s	
2171/30300 (epoch 3.583), train_loss = 2.06827250, grad/param norm = 2.4068e-01, time/batch = 0.6903s	
2172/30300 (epoch 3.584), train_loss = 2.04463085, grad/param norm = 2.0177e-01, time/batch = 0.6888s	
2173/30300 (epoch 3.586), train_loss = 1.94478515, grad/param norm = 2.0606e-01, time/batch = 0.6894s	
2174/30300 (epoch 3.587), train_loss = 1.92481968, grad/param norm = 2.0401e-01, time/batch = 0.6869s	
2175/30300 (epoch 3.589), train_loss = 1.60626038, grad/param norm = 1.8526e-01, time/batch = 0.6832s	
2176/30300 (epoch 3.591), train_loss = 1.92628286, grad/param norm = 2.1941e-01, time/batch = 0.6856s	
2177/30300 (epoch 3.592), train_loss = 1.88596165, grad/param norm = 1.9595e-01, time/batch = 0.6861s	
2178/30300 (epoch 3.594), train_loss = 1.94702563, grad/param norm = 2.6877e-01, time/batch = 0.6873s	
2179/30300 (epoch 3.596), train_loss = 1.82353542, grad/param norm = 2.5021e-01, time/batch = 0.6905s	
2180/30300 (epoch 3.597), train_loss = 1.88278863, grad/param norm = 2.3802e-01, time/batch = 0.6914s	
2181/30300 (epoch 3.599), train_loss = 1.67439319, grad/param norm = 2.1466e-01, time/batch = 0.6897s	
2182/30300 (epoch 3.601), train_loss = 1.90705693, grad/param norm = 2.1241e-01, time/batch = 0.6893s	
2183/30300 (epoch 3.602), train_loss = 1.86344605, grad/param norm = 1.8573e-01, time/batch = 0.7101s	
2184/30300 (epoch 3.604), train_loss = 1.80851618, grad/param norm = 2.1087e-01, time/batch = 0.6908s	
2185/30300 (epoch 3.606), train_loss = 2.15983104, grad/param norm = 2.5154e-01, time/batch = 0.6863s	
2186/30300 (epoch 3.607), train_loss = 1.99888443, grad/param norm = 2.0849e-01, time/batch = 0.6966s	
2187/30300 (epoch 3.609), train_loss = 2.20199274, grad/param norm = 2.3511e-01, time/batch = 0.6958s	
2188/30300 (epoch 3.611), train_loss = 1.70339851, grad/param norm = 1.8394e-01, time/batch = 0.6934s	
2189/30300 (epoch 3.612), train_loss = 1.85484918, grad/param norm = 2.1056e-01, time/batch = 0.6883s	
2190/30300 (epoch 3.614), train_loss = 1.69701073, grad/param norm = 1.8641e-01, time/batch = 0.6896s	
2191/30300 (epoch 3.616), train_loss = 1.96048501, grad/param norm = 2.0915e-01, time/batch = 0.6894s	
2192/30300 (epoch 3.617), train_loss = 1.88362592, grad/param norm = 2.0333e-01, time/batch = 0.6853s	
2193/30300 (epoch 3.619), train_loss = 1.70252042, grad/param norm = 1.9873e-01, time/batch = 0.6893s	
2194/30300 (epoch 3.620), train_loss = 1.97324424, grad/param norm = 2.0603e-01, time/batch = 0.6885s	
2195/30300 (epoch 3.622), train_loss = 1.82065905, grad/param norm = 2.0614e-01, time/batch = 0.6873s	
2196/30300 (epoch 3.624), train_loss = 1.79234160, grad/param norm = 1.9604e-01, time/batch = 0.6854s	
2197/30300 (epoch 3.625), train_loss = 1.82275210, grad/param norm = 2.1270e-01, time/batch = 0.7055s	
2198/30300 (epoch 3.627), train_loss = 2.05225151, grad/param norm = 2.0553e-01, time/batch = 0.7171s	
2199/30300 (epoch 3.629), train_loss = 1.95239879, grad/param norm = 2.0502e-01, time/batch = 0.6890s	
2200/30300 (epoch 3.630), train_loss = 1.94300462, grad/param norm = 2.0456e-01, time/batch = 0.6883s	
2201/30300 (epoch 3.632), train_loss = 1.97771940, grad/param norm = 2.4700e-01, time/batch = 0.6994s	
2202/30300 (epoch 3.634), train_loss = 1.67931806, grad/param norm = 1.7935e-01, time/batch = 0.7039s	
2203/30300 (epoch 3.635), train_loss = 1.98403456, grad/param norm = 1.9045e-01, time/batch = 0.6950s	
2204/30300 (epoch 3.637), train_loss = 1.89933035, grad/param norm = 2.1762e-01, time/batch = 0.7066s	
2205/30300 (epoch 3.639), train_loss = 1.80246306, grad/param norm = 2.4536e-01, time/batch = 0.7077s	
2206/30300 (epoch 3.640), train_loss = 1.96440716, grad/param norm = 2.2105e-01, time/batch = 0.6938s	
2207/30300 (epoch 3.642), train_loss = 1.89565566, grad/param norm = 2.6517e-01, time/batch = 0.6906s	
2208/30300 (epoch 3.644), train_loss = 1.96185899, grad/param norm = 3.1104e-01, time/batch = 0.6928s	
2209/30300 (epoch 3.645), train_loss = 1.85212724, grad/param norm = 2.1074e-01, time/batch = 0.6906s	
2210/30300 (epoch 3.647), train_loss = 1.88478468, grad/param norm = 2.1200e-01, time/batch = 0.6867s	
2211/30300 (epoch 3.649), train_loss = 1.85512821, grad/param norm = 1.9654e-01, time/batch = 0.7019s	
2212/30300 (epoch 3.650), train_loss = 1.89260273, grad/param norm = 1.9918e-01, time/batch = 0.7225s	
2213/30300 (epoch 3.652), train_loss = 1.74769732, grad/param norm = 2.2201e-01, time/batch = 0.6941s	
2214/30300 (epoch 3.653), train_loss = 2.04961059, grad/param norm = 2.2632e-01, time/batch = 0.6881s	
2215/30300 (epoch 3.655), train_loss = 1.86324749, grad/param norm = 2.0352e-01, time/batch = 0.7044s	
2216/30300 (epoch 3.657), train_loss = 1.98581970, grad/param norm = 2.1882e-01, time/batch = 0.6931s	
2217/30300 (epoch 3.658), train_loss = 1.81516129, grad/param norm = 2.0947e-01, time/batch = 0.6906s	
2218/30300 (epoch 3.660), train_loss = 1.92841021, grad/param norm = 1.9830e-01, time/batch = 0.6899s	
2219/30300 (epoch 3.662), train_loss = 1.93518718, grad/param norm = 2.0909e-01, time/batch = 0.6946s	
2220/30300 (epoch 3.663), train_loss = 1.88709979, grad/param norm = 1.9486e-01, time/batch = 0.6950s	
2221/30300 (epoch 3.665), train_loss = 1.72499062, grad/param norm = 1.8088e-01, time/batch = 0.6882s	
2222/30300 (epoch 3.667), train_loss = 2.03981397, grad/param norm = 2.2851e-01, time/batch = 0.6959s	
2223/30300 (epoch 3.668), train_loss = 2.08766107, grad/param norm = 2.1417e-01, time/batch = 0.6907s	
2224/30300 (epoch 3.670), train_loss = 1.93995971, grad/param norm = 2.1575e-01, time/batch = 0.6874s	
2225/30300 (epoch 3.672), train_loss = 1.96625470, grad/param norm = 2.0675e-01, time/batch = 0.6863s	
2226/30300 (epoch 3.673), train_loss = 1.92955162, grad/param norm = 2.1007e-01, time/batch = 0.7179s	
2227/30300 (epoch 3.675), train_loss = 1.79397893, grad/param norm = 2.0574e-01, time/batch = 0.7086s	
2228/30300 (epoch 3.677), train_loss = 1.81493579, grad/param norm = 2.0794e-01, time/batch = 0.6854s	
2229/30300 (epoch 3.678), train_loss = 1.83421017, grad/param norm = 1.9721e-01, time/batch = 0.6878s	
2230/30300 (epoch 3.680), train_loss = 1.62283675, grad/param norm = 2.0626e-01, time/batch = 0.6867s	
2231/30300 (epoch 3.682), train_loss = 1.87066431, grad/param norm = 2.7930e-01, time/batch = 0.6882s	
2232/30300 (epoch 3.683), train_loss = 1.95271474, grad/param norm = 2.0887e-01, time/batch = 0.6852s	
2233/30300 (epoch 3.685), train_loss = 2.04678638, grad/param norm = 2.2219e-01, time/batch = 0.6842s	
2234/30300 (epoch 3.686), train_loss = 1.90317364, grad/param norm = 2.0780e-01, time/batch = 0.6887s	
2235/30300 (epoch 3.688), train_loss = 1.89817734, grad/param norm = 2.0511e-01, time/batch = 0.6866s	
2236/30300 (epoch 3.690), train_loss = 1.87238636, grad/param norm = 2.3509e-01, time/batch = 0.6876s	
2237/30300 (epoch 3.691), train_loss = 1.92027342, grad/param norm = 2.7751e-01, time/batch = 0.6900s	
2238/30300 (epoch 3.693), train_loss = 2.25605352, grad/param norm = 2.4364e-01, time/batch = 0.6927s	
2239/30300 (epoch 3.695), train_loss = 2.05039867, grad/param norm = 2.0971e-01, time/batch = 0.6854s	
2240/30300 (epoch 3.696), train_loss = 2.14244496, grad/param norm = 2.5576e-01, time/batch = 0.6870s	
2241/30300 (epoch 3.698), train_loss = 1.80364645, grad/param norm = 2.1145e-01, time/batch = 0.6914s	
2242/30300 (epoch 3.700), train_loss = 1.87682635, grad/param norm = 2.0731e-01, time/batch = 0.6919s	
2243/30300 (epoch 3.701), train_loss = 1.63430165, grad/param norm = 1.8366e-01, time/batch = 0.6885s	
2244/30300 (epoch 3.703), train_loss = 1.80591569, grad/param norm = 1.7391e-01, time/batch = 0.6918s	
2245/30300 (epoch 3.705), train_loss = 1.92874558, grad/param norm = 2.2843e-01, time/batch = 0.6904s	
2246/30300 (epoch 3.706), train_loss = 1.83299921, grad/param norm = 1.9728e-01, time/batch = 0.7086s	
2247/30300 (epoch 3.708), train_loss = 1.86373107, grad/param norm = 2.0206e-01, time/batch = 0.7058s	
2248/30300 (epoch 3.710), train_loss = 1.83112219, grad/param norm = 2.1885e-01, time/batch = 0.6916s	
2249/30300 (epoch 3.711), train_loss = 1.75909057, grad/param norm = 1.9624e-01, time/batch = 0.6859s	
2250/30300 (epoch 3.713), train_loss = 1.67720046, grad/param norm = 1.7826e-01, time/batch = 0.6834s	
2251/30300 (epoch 3.715), train_loss = 1.86120016, grad/param norm = 1.9519e-01, time/batch = 0.6894s	
2252/30300 (epoch 3.716), train_loss = 2.04432168, grad/param norm = 2.1224e-01, time/batch = 0.6913s	
2253/30300 (epoch 3.718), train_loss = 1.98592018, grad/param norm = 2.0851e-01, time/batch = 0.6880s	
2254/30300 (epoch 3.719), train_loss = 1.86544814, grad/param norm = 2.1337e-01, time/batch = 0.6907s	
2255/30300 (epoch 3.721), train_loss = 1.87869996, grad/param norm = 1.9063e-01, time/batch = 0.6879s	
2256/30300 (epoch 3.723), train_loss = 1.80980606, grad/param norm = 2.0052e-01, time/batch = 0.6906s	
2257/30300 (epoch 3.724), train_loss = 1.90549938, grad/param norm = 2.0768e-01, time/batch = 0.6878s	
2258/30300 (epoch 3.726), train_loss = 2.30740080, grad/param norm = 2.3387e-01, time/batch = 0.6899s	
2259/30300 (epoch 3.728), train_loss = 1.82704763, grad/param norm = 2.0662e-01, time/batch = 0.7142s	
2260/30300 (epoch 3.729), train_loss = 1.90131682, grad/param norm = 2.1985e-01, time/batch = 0.7082s	
2261/30300 (epoch 3.731), train_loss = 1.96363648, grad/param norm = 1.9262e-01, time/batch = 0.6913s	
2262/30300 (epoch 3.733), train_loss = 1.85421021, grad/param norm = 1.9076e-01, time/batch = 0.6863s	
2263/30300 (epoch 3.734), train_loss = 1.89649971, grad/param norm = 1.8511e-01, time/batch = 0.6885s	
2264/30300 (epoch 3.736), train_loss = 1.85501206, grad/param norm = 1.9695e-01, time/batch = 0.6873s	
2265/30300 (epoch 3.738), train_loss = 1.69588537, grad/param norm = 1.7835e-01, time/batch = 0.6991s	
2266/30300 (epoch 3.739), train_loss = 1.98645338, grad/param norm = 2.0633e-01, time/batch = 0.6929s	
2267/30300 (epoch 3.741), train_loss = 1.94557425, grad/param norm = 1.9679e-01, time/batch = 0.6896s	
2268/30300 (epoch 3.743), train_loss = 1.74230959, grad/param norm = 2.0332e-01, time/batch = 0.6863s	
2269/30300 (epoch 3.744), train_loss = 2.02052969, grad/param norm = 2.2298e-01, time/batch = 0.6920s	
2270/30300 (epoch 3.746), train_loss = 1.71222398, grad/param norm = 2.1551e-01, time/batch = 0.6893s	
2271/30300 (epoch 3.748), train_loss = 1.95159350, grad/param norm = 2.5934e-01, time/batch = 0.6936s	
2272/30300 (epoch 3.749), train_loss = 1.88371963, grad/param norm = 2.3950e-01, time/batch = 0.6959s	
2273/30300 (epoch 3.751), train_loss = 1.79059471, grad/param norm = 2.0040e-01, time/batch = 0.6932s	
2274/30300 (epoch 3.752), train_loss = 1.79797836, grad/param norm = 1.9188e-01, time/batch = 0.6942s	
2275/30300 (epoch 3.754), train_loss = 1.63929256, grad/param norm = 1.8549e-01, time/batch = 0.6875s	
2276/30300 (epoch 3.756), train_loss = 1.79002437, grad/param norm = 2.0638e-01, time/batch = 0.6949s	
2277/30300 (epoch 3.757), train_loss = 1.94328506, grad/param norm = 2.0794e-01, time/batch = 0.6929s	
2278/30300 (epoch 3.759), train_loss = 1.73299519, grad/param norm = 2.0688e-01, time/batch = 0.6864s	
2279/30300 (epoch 3.761), train_loss = 1.77481418, grad/param norm = 1.9699e-01, time/batch = 0.6898s	
2280/30300 (epoch 3.762), train_loss = 1.62285496, grad/param norm = 1.8897e-01, time/batch = 0.6908s	
2281/30300 (epoch 3.764), train_loss = 1.79479341, grad/param norm = 2.1366e-01, time/batch = 0.6908s	
2282/30300 (epoch 3.766), train_loss = 1.87769199, grad/param norm = 2.0655e-01, time/batch = 0.6886s	
2283/30300 (epoch 3.767), train_loss = 1.99371816, grad/param norm = 2.2440e-01, time/batch = 0.6977s	
2284/30300 (epoch 3.769), train_loss = 2.05995392, grad/param norm = 2.4547e-01, time/batch = 0.6953s	
2285/30300 (epoch 3.771), train_loss = 1.89065385, grad/param norm = 2.0481e-01, time/batch = 0.6906s	
2286/30300 (epoch 3.772), train_loss = 1.84961548, grad/param norm = 2.1590e-01, time/batch = 0.6914s	
2287/30300 (epoch 3.774), train_loss = 1.92621459, grad/param norm = 2.0852e-01, time/batch = 0.6945s	
2288/30300 (epoch 3.776), train_loss = 1.85102221, grad/param norm = 2.0192e-01, time/batch = 0.7113s	
2289/30300 (epoch 3.777), train_loss = 1.88034471, grad/param norm = 2.1555e-01, time/batch = 0.6977s	
2290/30300 (epoch 3.779), train_loss = 1.94854209, grad/param norm = 1.9043e-01, time/batch = 0.6916s	
2291/30300 (epoch 3.781), train_loss = 1.83704672, grad/param norm = 2.0628e-01, time/batch = 0.6909s	
2292/30300 (epoch 3.782), train_loss = 1.74798555, grad/param norm = 1.9090e-01, time/batch = 0.6894s	
2293/30300 (epoch 3.784), train_loss = 1.90831184, grad/param norm = 1.9769e-01, time/batch = 0.6939s	
2294/30300 (epoch 3.785), train_loss = 2.02470092, grad/param norm = 1.9365e-01, time/batch = 0.6977s	
2295/30300 (epoch 3.787), train_loss = 1.82208067, grad/param norm = 2.0215e-01, time/batch = 0.7087s	
2296/30300 (epoch 3.789), train_loss = 2.21172379, grad/param norm = 2.0587e-01, time/batch = 0.6921s	
2297/30300 (epoch 3.790), train_loss = 1.98280107, grad/param norm = 1.9124e-01, time/batch = 0.6880s	
2298/30300 (epoch 3.792), train_loss = 1.82625791, grad/param norm = 2.1787e-01, time/batch = 0.6920s	
2299/30300 (epoch 3.794), train_loss = 1.76569057, grad/param norm = 1.9329e-01, time/batch = 0.6868s	
2300/30300 (epoch 3.795), train_loss = 1.84205577, grad/param norm = 1.8989e-01, time/batch = 0.7062s	
2301/30300 (epoch 3.797), train_loss = 1.97162923, grad/param norm = 2.2149e-01, time/batch = 0.6900s	
2302/30300 (epoch 3.799), train_loss = 2.00942521, grad/param norm = 2.5728e-01, time/batch = 0.7099s	
2303/30300 (epoch 3.800), train_loss = 1.89251926, grad/param norm = 2.3881e-01, time/batch = 0.7090s	
2304/30300 (epoch 3.802), train_loss = 2.06339754, grad/param norm = 2.2658e-01, time/batch = 0.6835s	
2305/30300 (epoch 3.804), train_loss = 1.93399707, grad/param norm = 2.3033e-01, time/batch = 0.6831s	
2306/30300 (epoch 3.805), train_loss = 2.01711717, grad/param norm = 2.1223e-01, time/batch = 0.6887s	
2307/30300 (epoch 3.807), train_loss = 1.97117997, grad/param norm = 2.2679e-01, time/batch = 0.6838s	
2308/30300 (epoch 3.809), train_loss = 2.03505352, grad/param norm = 2.1372e-01, time/batch = 0.6988s	
2309/30300 (epoch 3.810), train_loss = 1.96558370, grad/param norm = 2.3424e-01, time/batch = 0.6850s	
2310/30300 (epoch 3.812), train_loss = 1.81299030, grad/param norm = 2.0147e-01, time/batch = 0.6890s	
2311/30300 (epoch 3.814), train_loss = 1.93047628, grad/param norm = 1.9701e-01, time/batch = 0.6827s	
2312/30300 (epoch 3.815), train_loss = 1.89053754, grad/param norm = 2.1543e-01, time/batch = 0.6874s	
2313/30300 (epoch 3.817), train_loss = 1.96151533, grad/param norm = 2.1117e-01, time/batch = 0.6844s	
2314/30300 (epoch 3.818), train_loss = 1.88879613, grad/param norm = 2.0704e-01, time/batch = 0.6851s	
2315/30300 (epoch 3.820), train_loss = 2.13311663, grad/param norm = 2.0996e-01, time/batch = 0.6859s	
2316/30300 (epoch 3.822), train_loss = 2.07949392, grad/param norm = 2.1482e-01, time/batch = 0.6947s	
2317/30300 (epoch 3.823), train_loss = 2.16273413, grad/param norm = 2.3895e-01, time/batch = 0.7209s	
2318/30300 (epoch 3.825), train_loss = 1.96638993, grad/param norm = 2.1063e-01, time/batch = 0.6898s	
2319/30300 (epoch 3.827), train_loss = 1.86027913, grad/param norm = 2.0215e-01, time/batch = 0.6849s	
2320/30300 (epoch 3.828), train_loss = 1.90402457, grad/param norm = 1.7095e-01, time/batch = 0.6836s	
2321/30300 (epoch 3.830), train_loss = 1.90387903, grad/param norm = 2.0455e-01, time/batch = 0.6866s	
2322/30300 (epoch 3.832), train_loss = 1.82842764, grad/param norm = 1.9160e-01, time/batch = 0.6841s	
2323/30300 (epoch 3.833), train_loss = 1.96574990, grad/param norm = 1.9793e-01, time/batch = 0.6849s	
2324/30300 (epoch 3.835), train_loss = 1.89754272, grad/param norm = 2.0288e-01, time/batch = 0.6869s	
2325/30300 (epoch 3.837), train_loss = 1.71249566, grad/param norm = 1.7917e-01, time/batch = 0.6846s	
2326/30300 (epoch 3.838), train_loss = 1.77694399, grad/param norm = 1.8359e-01, time/batch = 0.6877s	
2327/30300 (epoch 3.840), train_loss = 1.82376808, grad/param norm = 1.8477e-01, time/batch = 0.6869s	
2328/30300 (epoch 3.842), train_loss = 1.73058659, grad/param norm = 1.9799e-01, time/batch = 0.6867s	
2329/30300 (epoch 3.843), train_loss = 1.87812218, grad/param norm = 2.3832e-01, time/batch = 0.6863s	
2330/30300 (epoch 3.845), train_loss = 1.71854524, grad/param norm = 1.7616e-01, time/batch = 0.6897s	
2331/30300 (epoch 3.847), train_loss = 1.86603060, grad/param norm = 2.2491e-01, time/batch = 0.6889s	
2332/30300 (epoch 3.848), train_loss = 2.03360075, grad/param norm = 2.1791e-01, time/batch = 0.6914s	
2333/30300 (epoch 3.850), train_loss = 1.76461671, grad/param norm = 1.9990e-01, time/batch = 0.7045s	
2334/30300 (epoch 3.851), train_loss = 2.15110417, grad/param norm = 2.3221e-01, time/batch = 0.6921s	
2335/30300 (epoch 3.853), train_loss = 1.86470648, grad/param norm = 2.1070e-01, time/batch = 0.6898s	
2336/30300 (epoch 3.855), train_loss = 1.79953152, grad/param norm = 2.1693e-01, time/batch = 0.6931s	
2337/30300 (epoch 3.856), train_loss = 1.78863935, grad/param norm = 2.0680e-01, time/batch = 0.6921s	
2338/30300 (epoch 3.858), train_loss = 1.76095501, grad/param norm = 1.8945e-01, time/batch = 0.6971s	
2339/30300 (epoch 3.860), train_loss = 1.90342223, grad/param norm = 2.0534e-01, time/batch = 0.7109s	
2340/30300 (epoch 3.861), train_loss = 2.04075207, grad/param norm = 2.6427e-01, time/batch = 0.6930s	
2341/30300 (epoch 3.863), train_loss = 1.95552663, grad/param norm = 2.2804e-01, time/batch = 0.6878s	
2342/30300 (epoch 3.865), train_loss = 2.19606801, grad/param norm = 2.6209e-01, time/batch = 0.6862s	
2343/30300 (epoch 3.866), train_loss = 1.95449171, grad/param norm = 2.2436e-01, time/batch = 0.6882s	
2344/30300 (epoch 3.868), train_loss = 1.90308264, grad/param norm = 1.8105e-01, time/batch = 0.6977s	
2345/30300 (epoch 3.870), train_loss = 1.82341709, grad/param norm = 1.9624e-01, time/batch = 0.7040s	
2346/30300 (epoch 3.871), train_loss = 1.76459687, grad/param norm = 1.8946e-01, time/batch = 0.6940s	
2347/30300 (epoch 3.873), train_loss = 1.93000917, grad/param norm = 1.9058e-01, time/batch = 0.6853s	
2348/30300 (epoch 3.875), train_loss = 1.71539659, grad/param norm = 1.8258e-01, time/batch = 0.6855s	
2349/30300 (epoch 3.876), train_loss = 1.65990965, grad/param norm = 1.7682e-01, time/batch = 0.6936s	
2350/30300 (epoch 3.878), train_loss = 1.64560958, grad/param norm = 1.9707e-01, time/batch = 0.7221s	
2351/30300 (epoch 3.880), train_loss = 1.73227959, grad/param norm = 1.7653e-01, time/batch = 0.6959s	
2352/30300 (epoch 3.881), train_loss = 2.03134699, grad/param norm = 2.0089e-01, time/batch = 0.6881s	
2353/30300 (epoch 3.883), train_loss = 1.91549305, grad/param norm = 2.0915e-01, time/batch = 0.6903s	
2354/30300 (epoch 3.884), train_loss = 1.74812947, grad/param norm = 1.9968e-01, time/batch = 0.6850s	
2355/30300 (epoch 3.886), train_loss = 1.77432614, grad/param norm = 1.9120e-01, time/batch = 0.6868s	
2356/30300 (epoch 3.888), train_loss = 1.92031470, grad/param norm = 2.2777e-01, time/batch = 0.6866s	
2357/30300 (epoch 3.889), train_loss = 1.84958789, grad/param norm = 2.5533e-01, time/batch = 0.6857s	
2358/30300 (epoch 3.891), train_loss = 1.78574872, grad/param norm = 2.1449e-01, time/batch = 0.6908s	
2359/30300 (epoch 3.893), train_loss = 2.05880481, grad/param norm = 2.2277e-01, time/batch = 0.6875s	
2360/30300 (epoch 3.894), train_loss = 1.92706372, grad/param norm = 2.0224e-01, time/batch = 0.6867s	
2361/30300 (epoch 3.896), train_loss = 1.68633806, grad/param norm = 2.2920e-01, time/batch = 0.6881s	
2362/30300 (epoch 3.898), train_loss = 1.68764201, grad/param norm = 2.0217e-01, time/batch = 0.6883s	
2363/30300 (epoch 3.899), train_loss = 1.80598864, grad/param norm = 2.0017e-01, time/batch = 0.6894s	
2364/30300 (epoch 3.901), train_loss = 1.90274321, grad/param norm = 1.9573e-01, time/batch = 0.7128s	
2365/30300 (epoch 3.903), train_loss = 1.93545538, grad/param norm = 2.1169e-01, time/batch = 0.7085s	
2366/30300 (epoch 3.904), train_loss = 1.83903166, grad/param norm = 1.9730e-01, time/batch = 0.6873s	
2367/30300 (epoch 3.906), train_loss = 1.96773413, grad/param norm = 2.1920e-01, time/batch = 0.6952s	
2368/30300 (epoch 3.908), train_loss = 1.79078493, grad/param norm = 2.0159e-01, time/batch = 0.6935s	
2369/30300 (epoch 3.909), train_loss = 1.90143056, grad/param norm = 1.9883e-01, time/batch = 0.6890s	
2370/30300 (epoch 3.911), train_loss = 1.82399206, grad/param norm = 2.0581e-01, time/batch = 0.6826s	
2371/30300 (epoch 3.913), train_loss = 1.88544137, grad/param norm = 2.0301e-01, time/batch = 0.6897s	
2372/30300 (epoch 3.914), train_loss = 1.91021006, grad/param norm = 2.3766e-01, time/batch = 0.6877s	
2373/30300 (epoch 3.916), train_loss = 1.88573983, grad/param norm = 2.0369e-01, time/batch = 0.6853s	
2374/30300 (epoch 3.917), train_loss = 1.79717330, grad/param norm = 1.9038e-01, time/batch = 0.7142s	
2375/30300 (epoch 3.919), train_loss = 1.89402486, grad/param norm = 1.8657e-01, time/batch = 0.6914s	
2376/30300 (epoch 3.921), train_loss = 1.96191868, grad/param norm = 2.2175e-01, time/batch = 0.6919s	
2377/30300 (epoch 3.922), train_loss = 1.97351217, grad/param norm = 2.1194e-01, time/batch = 0.7037s	
2378/30300 (epoch 3.924), train_loss = 1.86617188, grad/param norm = 2.1760e-01, time/batch = 0.6887s	
2379/30300 (epoch 3.926), train_loss = 1.86007718, grad/param norm = 2.2374e-01, time/batch = 0.6854s	
2380/30300 (epoch 3.927), train_loss = 1.81629091, grad/param norm = 2.2342e-01, time/batch = 0.6849s	
2381/30300 (epoch 3.929), train_loss = 1.89271835, grad/param norm = 2.1032e-01, time/batch = 0.6909s	
2382/30300 (epoch 3.931), train_loss = 1.96362435, grad/param norm = 2.1302e-01, time/batch = 0.6969s	
2383/30300 (epoch 3.932), train_loss = 1.79380590, grad/param norm = 2.0546e-01, time/batch = 0.7011s	
2384/30300 (epoch 3.934), train_loss = 1.84470163, grad/param norm = 1.9746e-01, time/batch = 0.7180s	
2385/30300 (epoch 3.936), train_loss = 1.81739703, grad/param norm = 1.8914e-01, time/batch = 0.7052s	
2386/30300 (epoch 3.937), train_loss = 1.88103247, grad/param norm = 1.9464e-01, time/batch = 0.6957s	
2387/30300 (epoch 3.939), train_loss = 1.98012450, grad/param norm = 1.8743e-01, time/batch = 0.6959s	
2388/30300 (epoch 3.941), train_loss = 1.89196723, grad/param norm = 1.9883e-01, time/batch = 0.6932s	
2389/30300 (epoch 3.942), train_loss = 1.78204283, grad/param norm = 1.8980e-01, time/batch = 0.6902s	
2390/30300 (epoch 3.944), train_loss = 1.71112446, grad/param norm = 1.8336e-01, time/batch = 0.7033s	
2391/30300 (epoch 3.946), train_loss = 2.03600226, grad/param norm = 2.1021e-01, time/batch = 0.6994s	
2392/30300 (epoch 3.947), train_loss = 2.05556270, grad/param norm = 2.0917e-01, time/batch = 0.6990s	
2393/30300 (epoch 3.949), train_loss = 2.11196466, grad/param norm = 2.1136e-01, time/batch = 0.7217s	
2394/30300 (epoch 3.950), train_loss = 2.01395387, grad/param norm = 2.0877e-01, time/batch = 0.6985s	
2395/30300 (epoch 3.952), train_loss = 2.01914097, grad/param norm = 2.2542e-01, time/batch = 0.6942s	
2396/30300 (epoch 3.954), train_loss = 2.09575047, grad/param norm = 1.9418e-01, time/batch = 0.6888s	
2397/30300 (epoch 3.955), train_loss = 1.80915793, grad/param norm = 2.1648e-01, time/batch = 0.6894s	
2398/30300 (epoch 3.957), train_loss = 1.91075359, grad/param norm = 1.9229e-01, time/batch = 0.6889s	
2399/30300 (epoch 3.959), train_loss = 1.89568390, grad/param norm = 2.0165e-01, time/batch = 0.6909s	
2400/30300 (epoch 3.960), train_loss = 1.83552718, grad/param norm = 1.7811e-01, time/batch = 0.6890s	
2401/30300 (epoch 3.962), train_loss = 1.81087010, grad/param norm = 2.1594e-01, time/batch = 0.6909s	
2402/30300 (epoch 3.964), train_loss = 1.92918931, grad/param norm = 2.1164e-01, time/batch = 0.6914s	
2403/30300 (epoch 3.965), train_loss = 1.79754174, grad/param norm = 1.9588e-01, time/batch = 0.6969s	
2404/30300 (epoch 3.967), train_loss = 1.92243991, grad/param norm = 2.1071e-01, time/batch = 0.7008s	
2405/30300 (epoch 3.969), train_loss = 1.86642399, grad/param norm = 2.5556e-01, time/batch = 0.6872s	
2406/30300 (epoch 3.970), train_loss = 1.80697120, grad/param norm = 2.4545e-01, time/batch = 0.6873s	
2407/30300 (epoch 3.972), train_loss = 1.74652000, grad/param norm = 1.8630e-01, time/batch = 0.7143s	
2408/30300 (epoch 3.974), train_loss = 2.03309327, grad/param norm = 1.9972e-01, time/batch = 0.7078s	
2409/30300 (epoch 3.975), train_loss = 2.09072039, grad/param norm = 2.3760e-01, time/batch = 0.6944s	
2410/30300 (epoch 3.977), train_loss = 1.91752945, grad/param norm = 1.9537e-01, time/batch = 0.6909s	
2411/30300 (epoch 3.979), train_loss = 1.95642196, grad/param norm = 2.0459e-01, time/batch = 0.6924s	
2412/30300 (epoch 3.980), train_loss = 1.95068265, grad/param norm = 2.4338e-01, time/batch = 0.6892s	
2413/30300 (epoch 3.982), train_loss = 1.94140676, grad/param norm = 1.9822e-01, time/batch = 0.6884s	
2414/30300 (epoch 3.983), train_loss = 2.00124338, grad/param norm = 1.9969e-01, time/batch = 0.6871s	
2415/30300 (epoch 3.985), train_loss = 1.89380564, grad/param norm = 2.1753e-01, time/batch = 0.6879s	
2416/30300 (epoch 3.987), train_loss = 1.79565900, grad/param norm = 1.7965e-01, time/batch = 0.6888s	
2417/30300 (epoch 3.988), train_loss = 2.02514386, grad/param norm = 2.0746e-01, time/batch = 0.6909s	
2418/30300 (epoch 3.990), train_loss = 1.71320893, grad/param norm = 1.8078e-01, time/batch = 0.6920s	
2419/30300 (epoch 3.992), train_loss = 1.90463654, grad/param norm = 2.0609e-01, time/batch = 0.6903s	
2420/30300 (epoch 3.993), train_loss = 2.05162075, grad/param norm = 2.2802e-01, time/batch = 0.6936s	
2421/30300 (epoch 3.995), train_loss = 1.98160205, grad/param norm = 2.0142e-01, time/batch = 0.6902s	
2422/30300 (epoch 3.997), train_loss = 1.92157448, grad/param norm = 1.9625e-01, time/batch = 0.6894s	
2423/30300 (epoch 3.998), train_loss = 1.95392253, grad/param norm = 2.0666e-01, time/batch = 0.6901s	
2424/30300 (epoch 4.000), train_loss = 1.80623590, grad/param norm = 2.0684e-01, time/batch = 0.6909s	
2425/30300 (epoch 4.002), train_loss = 1.81709227, grad/param norm = 1.8255e-01, time/batch = 0.6896s	
2426/30300 (epoch 4.003), train_loss = 1.91045837, grad/param norm = 2.0724e-01, time/batch = 0.6872s	
2427/30300 (epoch 4.005), train_loss = 1.90779439, grad/param norm = 2.1501e-01, time/batch = 0.6887s	
2428/30300 (epoch 4.007), train_loss = 1.98443922, grad/param norm = 1.9268e-01, time/batch = 0.6910s	
2429/30300 (epoch 4.008), train_loss = 1.80053531, grad/param norm = 1.9572e-01, time/batch = 0.6870s	
2430/30300 (epoch 4.010), train_loss = 1.85478301, grad/param norm = 2.1634e-01, time/batch = 0.6876s	
2431/30300 (epoch 4.012), train_loss = 1.79904734, grad/param norm = 1.9365e-01, time/batch = 0.6864s	
2432/30300 (epoch 4.013), train_loss = 1.94584011, grad/param norm = 1.9936e-01, time/batch = 0.6891s	
2433/30300 (epoch 4.015), train_loss = 1.80985071, grad/param norm = 1.9444e-01, time/batch = 0.6876s	
2434/30300 (epoch 4.017), train_loss = 1.71453721, grad/param norm = 1.9475e-01, time/batch = 0.6877s	
2435/30300 (epoch 4.018), train_loss = 1.95184172, grad/param norm = 1.9185e-01, time/batch = 0.6891s	
2436/30300 (epoch 4.020), train_loss = 2.04965693, grad/param norm = 1.9749e-01, time/batch = 0.6938s	
2437/30300 (epoch 4.021), train_loss = 1.98656733, grad/param norm = 2.1127e-01, time/batch = 0.6920s	
2438/30300 (epoch 4.023), train_loss = 1.75208192, grad/param norm = 1.9916e-01, time/batch = 0.6865s	
2439/30300 (epoch 4.025), train_loss = 1.77060879, grad/param norm = 1.9907e-01, time/batch = 0.6858s	
2440/30300 (epoch 4.026), train_loss = 1.85962125, grad/param norm = 1.9246e-01, time/batch = 0.7070s	
2441/30300 (epoch 4.028), train_loss = 1.85796455, grad/param norm = 1.9466e-01, time/batch = 0.7156s	
2442/30300 (epoch 4.030), train_loss = 1.71966270, grad/param norm = 2.2955e-01, time/batch = 0.6922s	
2443/30300 (epoch 4.031), train_loss = 1.87184778, grad/param norm = 2.2161e-01, time/batch = 0.6945s	
2444/30300 (epoch 4.033), train_loss = 1.83182746, grad/param norm = 2.2330e-01, time/batch = 0.6932s	
2445/30300 (epoch 4.035), train_loss = 1.91062903, grad/param norm = 1.8555e-01, time/batch = 0.7323s	
2446/30300 (epoch 4.036), train_loss = 1.99839222, grad/param norm = 2.0779e-01, time/batch = 0.7249s	
2447/30300 (epoch 4.038), train_loss = 1.87224247, grad/param norm = 2.0113e-01, time/batch = 0.7326s	
2448/30300 (epoch 4.040), train_loss = 1.54121255, grad/param norm = 1.8265e-01, time/batch = 0.7277s	
2449/30300 (epoch 4.041), train_loss = 1.61230306, grad/param norm = 1.8294e-01, time/batch = 0.7249s	
2450/30300 (epoch 4.043), train_loss = 1.94933811, grad/param norm = 2.0102e-01, time/batch = 0.7249s	
2451/30300 (epoch 4.045), train_loss = 1.79954657, grad/param norm = 2.1201e-01, time/batch = 0.7269s	
2452/30300 (epoch 4.046), train_loss = 1.88503283, grad/param norm = 2.2016e-01, time/batch = 0.7300s	
2453/30300 (epoch 4.048), train_loss = 1.88301716, grad/param norm = 2.1575e-01, time/batch = 0.7276s	
2454/30300 (epoch 4.050), train_loss = 1.94276581, grad/param norm = 2.0552e-01, time/batch = 0.7226s	
2455/30300 (epoch 4.051), train_loss = 1.85892299, grad/param norm = 1.9194e-01, time/batch = 0.7191s	
2456/30300 (epoch 4.053), train_loss = 1.76503782, grad/param norm = 2.0515e-01, time/batch = 0.7123s	
2457/30300 (epoch 4.054), train_loss = 1.76060843, grad/param norm = 2.3096e-01, time/batch = 0.7115s	
2458/30300 (epoch 4.056), train_loss = 1.74472846, grad/param norm = 2.0811e-01, time/batch = 0.7152s	
2459/30300 (epoch 4.058), train_loss = 1.91305551, grad/param norm = 2.1645e-01, time/batch = 0.7259s	
2460/30300 (epoch 4.059), train_loss = 1.84018956, grad/param norm = 1.8281e-01, time/batch = 0.7265s	
2461/30300 (epoch 4.061), train_loss = 2.03424121, grad/param norm = 2.2904e-01, time/batch = 0.7288s	
2462/30300 (epoch 4.063), train_loss = 1.82913182, grad/param norm = 2.0639e-01, time/batch = 0.7122s	
2463/30300 (epoch 4.064), train_loss = 1.96564520, grad/param norm = 1.9431e-01, time/batch = 0.7076s	
2464/30300 (epoch 4.066), train_loss = 1.84271585, grad/param norm = 1.7705e-01, time/batch = 0.7036s	
2465/30300 (epoch 4.068), train_loss = 1.72910718, grad/param norm = 1.7089e-01, time/batch = 0.6961s	
2466/30300 (epoch 4.069), train_loss = 1.97559628, grad/param norm = 1.9026e-01, time/batch = 0.6922s	
2467/30300 (epoch 4.071), train_loss = 1.93376824, grad/param norm = 2.3037e-01, time/batch = 0.6867s	
2468/30300 (epoch 4.073), train_loss = 2.00702756, grad/param norm = 2.3129e-01, time/batch = 0.7133s	
2469/30300 (epoch 4.074), train_loss = 1.93858427, grad/param norm = 1.9870e-01, time/batch = 0.7071s	
2470/30300 (epoch 4.076), train_loss = 1.79806314, grad/param norm = 1.8919e-01, time/batch = 0.6890s	
2471/30300 (epoch 4.078), train_loss = 1.70007775, grad/param norm = 2.0829e-01, time/batch = 0.6957s	
2472/30300 (epoch 4.079), train_loss = 1.68999743, grad/param norm = 1.6905e-01, time/batch = 0.7109s	
2473/30300 (epoch 4.081), train_loss = 1.99718964, grad/param norm = 2.1937e-01, time/batch = 0.6941s	
2474/30300 (epoch 4.083), train_loss = 2.09711751, grad/param norm = 2.1696e-01, time/batch = 0.6956s	
2475/30300 (epoch 4.084), train_loss = 1.80971473, grad/param norm = 2.0796e-01, time/batch = 0.6955s	
2476/30300 (epoch 4.086), train_loss = 1.86531493, grad/param norm = 1.9496e-01, time/batch = 0.6911s	
2477/30300 (epoch 4.087), train_loss = 1.74619836, grad/param norm = 1.8067e-01, time/batch = 0.6936s	
2478/30300 (epoch 4.089), train_loss = 1.82862838, grad/param norm = 1.9767e-01, time/batch = 0.6951s	
2479/30300 (epoch 4.091), train_loss = 1.94871418, grad/param norm = 2.0573e-01, time/batch = 0.6879s	
2480/30300 (epoch 4.092), train_loss = 1.77692526, grad/param norm = 2.1860e-01, time/batch = 0.6962s	
2481/30300 (epoch 4.094), train_loss = 2.08308708, grad/param norm = 1.9605e-01, time/batch = 0.6903s	
2482/30300 (epoch 4.096), train_loss = 1.83697044, grad/param norm = 2.0403e-01, time/batch = 0.7061s	
2483/30300 (epoch 4.097), train_loss = 1.71458556, grad/param norm = 2.0346e-01, time/batch = 0.7175s	
2484/30300 (epoch 4.099), train_loss = 2.00610910, grad/param norm = 1.9324e-01, time/batch = 0.6864s	
2485/30300 (epoch 4.101), train_loss = 2.07930234, grad/param norm = 1.9006e-01, time/batch = 0.6875s	
2486/30300 (epoch 4.102), train_loss = 1.91499767, grad/param norm = 1.9760e-01, time/batch = 0.6911s	
2487/30300 (epoch 4.104), train_loss = 1.74519869, grad/param norm = 1.7207e-01, time/batch = 0.6880s	
2488/30300 (epoch 4.106), train_loss = 1.93237084, grad/param norm = 2.1168e-01, time/batch = 0.6906s	
2489/30300 (epoch 4.107), train_loss = 1.83658513, grad/param norm = 2.0769e-01, time/batch = 0.7070s	
2490/30300 (epoch 4.109), train_loss = 1.98382081, grad/param norm = 1.9738e-01, time/batch = 0.7089s	
2491/30300 (epoch 4.111), train_loss = 1.95882440, grad/param norm = 2.1074e-01, time/batch = 0.7103s	
2492/30300 (epoch 4.112), train_loss = 1.89329448, grad/param norm = 1.9803e-01, time/batch = 0.7127s	
2493/30300 (epoch 4.114), train_loss = 1.79658688, grad/param norm = 1.9095e-01, time/batch = 0.7171s	
2494/30300 (epoch 4.116), train_loss = 1.89220618, grad/param norm = 1.8306e-01, time/batch = 0.6952s	
2495/30300 (epoch 4.117), train_loss = 1.80583705, grad/param norm = 1.7460e-01, time/batch = 0.6894s	
2496/30300 (epoch 4.119), train_loss = 1.72702615, grad/param norm = 2.0590e-01, time/batch = 0.6969s	
2497/30300 (epoch 4.120), train_loss = 1.79538951, grad/param norm = 1.8547e-01, time/batch = 0.6991s	
2498/30300 (epoch 4.122), train_loss = 1.90146273, grad/param norm = 1.7343e-01, time/batch = 0.6873s	
2499/30300 (epoch 4.124), train_loss = 2.05370947, grad/param norm = 2.3139e-01, time/batch = 0.6859s	
2500/30300 (epoch 4.125), train_loss = 1.70017460, grad/param norm = 2.0049e-01, time/batch = 0.6881s	
2501/30300 (epoch 4.127), train_loss = 1.85967165, grad/param norm = 1.8825e-01, time/batch = 0.6933s	
2502/30300 (epoch 4.129), train_loss = 1.96736738, grad/param norm = 1.9071e-01, time/batch = 0.6968s	
2503/30300 (epoch 4.130), train_loss = 1.99622633, grad/param norm = 2.0438e-01, time/batch = 0.6928s	
2504/30300 (epoch 4.132), train_loss = 1.85561088, grad/param norm = 2.0525e-01, time/batch = 0.6880s	
2505/30300 (epoch 4.134), train_loss = 1.72100832, grad/param norm = 2.0924e-01, time/batch = 0.6897s	
2506/30300 (epoch 4.135), train_loss = 1.83865636, grad/param norm = 1.9841e-01, time/batch = 0.6886s	
2507/30300 (epoch 4.137), train_loss = 1.99057726, grad/param norm = 2.0899e-01, time/batch = 0.6905s	
2508/30300 (epoch 4.139), train_loss = 1.85710120, grad/param norm = 2.2983e-01, time/batch = 0.6940s	
2509/30300 (epoch 4.140), train_loss = 2.13253170, grad/param norm = 3.0251e-01, time/batch = 0.6905s	
2510/30300 (epoch 4.142), train_loss = 2.09907631, grad/param norm = 2.5215e-01, time/batch = 0.6924s	
2511/30300 (epoch 4.144), train_loss = 1.93290424, grad/param norm = 2.0535e-01, time/batch = 0.6918s	
2512/30300 (epoch 4.145), train_loss = 2.02290674, grad/param norm = 1.8245e-01, time/batch = 0.6889s	
2513/30300 (epoch 4.147), train_loss = 1.89973421, grad/param norm = 1.9282e-01, time/batch = 0.6918s	
2514/30300 (epoch 4.149), train_loss = 2.08509156, grad/param norm = 2.0651e-01, time/batch = 0.7012s	
2515/30300 (epoch 4.150), train_loss = 2.05478150, grad/param norm = 1.9279e-01, time/batch = 0.6984s	
2516/30300 (epoch 4.152), train_loss = 1.86948242, grad/param norm = 2.2826e-01, time/batch = 0.6943s	
2517/30300 (epoch 4.153), train_loss = 1.93533746, grad/param norm = 2.1991e-01, time/batch = 0.6921s	
2518/30300 (epoch 4.155), train_loss = 1.65279085, grad/param norm = 1.8593e-01, time/batch = 0.6913s	
2519/30300 (epoch 4.157), train_loss = 1.86771921, grad/param norm = 1.8098e-01, time/batch = 0.6897s	
2520/30300 (epoch 4.158), train_loss = 1.93358154, grad/param norm = 2.0084e-01, time/batch = 0.6893s	
2521/30300 (epoch 4.160), train_loss = 1.76969622, grad/param norm = 2.0089e-01, time/batch = 0.6890s	
2522/30300 (epoch 4.162), train_loss = 1.76554464, grad/param norm = 2.1207e-01, time/batch = 0.6854s	
2523/30300 (epoch 4.163), train_loss = 1.77049076, grad/param norm = 2.2860e-01, time/batch = 0.6924s	
2524/30300 (epoch 4.165), train_loss = 1.89035066, grad/param norm = 2.0477e-01, time/batch = 0.6886s	
2525/30300 (epoch 4.167), train_loss = 1.90871199, grad/param norm = 2.1134e-01, time/batch = 0.7050s	
2526/30300 (epoch 4.168), train_loss = 1.77967853, grad/param norm = 2.0279e-01, time/batch = 0.7178s	
2527/30300 (epoch 4.170), train_loss = 1.89460744, grad/param norm = 2.1625e-01, time/batch = 0.6889s	
2528/30300 (epoch 4.172), train_loss = 1.80223480, grad/param norm = 1.9089e-01, time/batch = 0.6907s	
2529/30300 (epoch 4.173), train_loss = 1.94547676, grad/param norm = 1.9444e-01, time/batch = 0.6886s	
2530/30300 (epoch 4.175), train_loss = 1.83443615, grad/param norm = 1.8414e-01, time/batch = 0.6887s	
2531/30300 (epoch 4.177), train_loss = 1.90125223, grad/param norm = 1.8783e-01, time/batch = 0.6861s	
2532/30300 (epoch 4.178), train_loss = 1.66234726, grad/param norm = 1.8229e-01, time/batch = 0.6877s	
2533/30300 (epoch 4.180), train_loss = 1.79204752, grad/param norm = 1.8209e-01, time/batch = 0.6867s	
2534/30300 (epoch 4.182), train_loss = 1.78255610, grad/param norm = 1.9743e-01, time/batch = 0.6888s	
2535/30300 (epoch 4.183), train_loss = 1.72563547, grad/param norm = 1.8053e-01, time/batch = 0.6866s	
2536/30300 (epoch 4.185), train_loss = 2.19947337, grad/param norm = 2.3002e-01, time/batch = 0.6873s	
2537/30300 (epoch 4.186), train_loss = 2.08708637, grad/param norm = 2.1619e-01, time/batch = 0.6911s	
2538/30300 (epoch 4.188), train_loss = 1.88052243, grad/param norm = 1.9368e-01, time/batch = 0.6860s	
2539/30300 (epoch 4.190), train_loss = 1.74312218, grad/param norm = 1.8529e-01, time/batch = 0.6923s	
2540/30300 (epoch 4.191), train_loss = 1.96860084, grad/param norm = 2.0696e-01, time/batch = 0.7206s	
2541/30300 (epoch 4.193), train_loss = 1.71721744, grad/param norm = 1.9595e-01, time/batch = 0.6995s	
2542/30300 (epoch 4.195), train_loss = 1.92359144, grad/param norm = 2.2797e-01, time/batch = 0.6929s	
2543/30300 (epoch 4.196), train_loss = 1.97402782, grad/param norm = 2.4563e-01, time/batch = 0.7013s	
2544/30300 (epoch 4.198), train_loss = 1.64282998, grad/param norm = 1.9408e-01, time/batch = 0.6912s	
2545/30300 (epoch 4.200), train_loss = 1.79853452, grad/param norm = 2.1730e-01, time/batch = 0.7076s	
2546/30300 (epoch 4.201), train_loss = 2.00217045, grad/param norm = 2.1089e-01, time/batch = 0.7036s	
2547/30300 (epoch 4.203), train_loss = 1.81470255, grad/param norm = 1.8128e-01, time/batch = 1.5193s	
2548/30300 (epoch 4.205), train_loss = 2.09828545, grad/param norm = 1.9523e-01, time/batch = 0.7139s	
2549/30300 (epoch 4.206), train_loss = 2.11926178, grad/param norm = 2.1079e-01, time/batch = 0.6909s	
2550/30300 (epoch 4.208), train_loss = 2.04999599, grad/param norm = 2.2137e-01, time/batch = 0.7082s	
2551/30300 (epoch 4.210), train_loss = 1.89133936, grad/param norm = 1.9587e-01, time/batch = 0.7309s	
2552/30300 (epoch 4.211), train_loss = 1.88475556, grad/param norm = 2.0250e-01, time/batch = 0.7242s	
2553/30300 (epoch 4.213), train_loss = 1.82704582, grad/param norm = 2.0914e-01, time/batch = 0.7712s	
2554/30300 (epoch 4.215), train_loss = 1.64543237, grad/param norm = 1.8866e-01, time/batch = 0.7011s	
2555/30300 (epoch 4.216), train_loss = 1.84609672, grad/param norm = 2.1160e-01, time/batch = 0.6866s	
2556/30300 (epoch 4.218), train_loss = 1.77238419, grad/param norm = 1.8532e-01, time/batch = 0.6891s	
2557/30300 (epoch 4.219), train_loss = 1.69541745, grad/param norm = 1.9767e-01, time/batch = 0.6880s	
2558/30300 (epoch 4.221), train_loss = 1.68585040, grad/param norm = 1.8978e-01, time/batch = 0.6867s	
2559/30300 (epoch 4.223), train_loss = 1.80095285, grad/param norm = 1.8556e-01, time/batch = 0.7309s	
2560/30300 (epoch 4.224), train_loss = 1.61617931, grad/param norm = 1.7708e-01, time/batch = 0.6864s	
2561/30300 (epoch 4.226), train_loss = 1.91841485, grad/param norm = 2.0658e-01, time/batch = 0.6874s	
2562/30300 (epoch 4.228), train_loss = 1.90918643, grad/param norm = 1.9059e-01, time/batch = 0.6964s	
2563/30300 (epoch 4.229), train_loss = 1.75647031, grad/param norm = 2.0422e-01, time/batch = 0.7074s	
2564/30300 (epoch 4.231), train_loss = 1.84402447, grad/param norm = 2.0369e-01, time/batch = 0.6919s	
2565/30300 (epoch 4.233), train_loss = 1.75855315, grad/param norm = 1.8935e-01, time/batch = 0.6966s	
2566/30300 (epoch 4.234), train_loss = 1.92506831, grad/param norm = 1.9354e-01, time/batch = 0.6883s	
2567/30300 (epoch 4.236), train_loss = 1.78138653, grad/param norm = 2.3411e-01, time/batch = 0.7174s	
2568/30300 (epoch 4.238), train_loss = 1.94172021, grad/param norm = 2.3749e-01, time/batch = 0.7038s	
2569/30300 (epoch 4.239), train_loss = 1.82962943, grad/param norm = 2.0788e-01, time/batch = 0.6883s	
2570/30300 (epoch 4.241), train_loss = 1.84021588, grad/param norm = 1.8252e-01, time/batch = 0.6883s	
2571/30300 (epoch 4.243), train_loss = 1.80959095, grad/param norm = 1.9752e-01, time/batch = 0.6905s	
2572/30300 (epoch 4.244), train_loss = 2.19131391, grad/param norm = 2.0874e-01, time/batch = 0.6895s	
2573/30300 (epoch 4.246), train_loss = 1.80377393, grad/param norm = 1.9323e-01, time/batch = 0.6963s	
2574/30300 (epoch 4.248), train_loss = 1.92457257, grad/param norm = 1.7589e-01, time/batch = 0.6877s	
2575/30300 (epoch 4.249), train_loss = 1.65813362, grad/param norm = 1.8879e-01, time/batch = 0.6870s	
2576/30300 (epoch 4.251), train_loss = 1.74959939, grad/param norm = 1.8793e-01, time/batch = 0.6881s	
2577/30300 (epoch 4.252), train_loss = 2.01138889, grad/param norm = 1.8953e-01, time/batch = 0.6866s	
2578/30300 (epoch 4.254), train_loss = 1.89466758, grad/param norm = 1.8510e-01, time/batch = 0.6901s	
2579/30300 (epoch 4.256), train_loss = 1.88224083, grad/param norm = 1.8255e-01, time/batch = 0.6858s	
2580/30300 (epoch 4.257), train_loss = 2.02004789, grad/param norm = 2.0768e-01, time/batch = 0.6856s	
2581/30300 (epoch 4.259), train_loss = 1.91170648, grad/param norm = 2.0196e-01, time/batch = 0.6936s	
2582/30300 (epoch 4.261), train_loss = 2.01133088, grad/param norm = 1.8808e-01, time/batch = 0.6902s	
2583/30300 (epoch 4.262), train_loss = 1.82138404, grad/param norm = 1.7550e-01, time/batch = 0.6900s	
2584/30300 (epoch 4.264), train_loss = 1.84037603, grad/param norm = 1.9075e-01, time/batch = 0.6905s	
2585/30300 (epoch 4.266), train_loss = 1.76925701, grad/param norm = 1.6951e-01, time/batch = 0.6904s	
2586/30300 (epoch 4.267), train_loss = 2.02710374, grad/param norm = 2.0731e-01, time/batch = 0.6900s	
2587/30300 (epoch 4.269), train_loss = 1.89576737, grad/param norm = 1.9946e-01, time/batch = 0.6923s	
2588/30300 (epoch 4.271), train_loss = 1.86220436, grad/param norm = 2.0583e-01, time/batch = 0.6955s	
2589/30300 (epoch 4.272), train_loss = 1.87511655, grad/param norm = 1.8275e-01, time/batch = 0.7008s	
2590/30300 (epoch 4.274), train_loss = 1.98488492, grad/param norm = 1.9862e-01, time/batch = 0.6980s	
2591/30300 (epoch 4.276), train_loss = 1.99876321, grad/param norm = 2.0845e-01, time/batch = 0.6879s	
2592/30300 (epoch 4.277), train_loss = 1.78376431, grad/param norm = 1.9351e-01, time/batch = 0.6888s	
2593/30300 (epoch 4.279), train_loss = 1.86324324, grad/param norm = 1.8821e-01, time/batch = 0.6870s	
2594/30300 (epoch 4.281), train_loss = 1.89765896, grad/param norm = 1.8947e-01, time/batch = 0.6870s	
2595/30300 (epoch 4.282), train_loss = 1.72966378, grad/param norm = 1.8887e-01, time/batch = 0.6893s	
2596/30300 (epoch 4.284), train_loss = 2.07258783, grad/param norm = 2.1899e-01, time/batch = 0.6877s	
2597/30300 (epoch 4.285), train_loss = 1.89175391, grad/param norm = 2.0164e-01, time/batch = 0.6852s	
2598/30300 (epoch 4.287), train_loss = 1.90910369, grad/param norm = 2.0050e-01, time/batch = 0.6912s	
2599/30300 (epoch 4.289), train_loss = 1.89910493, grad/param norm = 2.0723e-01, time/batch = 0.6874s	
2600/30300 (epoch 4.290), train_loss = 1.57228098, grad/param norm = 1.7449e-01, time/batch = 0.7120s	
2601/30300 (epoch 4.292), train_loss = 1.74103443, grad/param norm = 1.7434e-01, time/batch = 0.7087s	
2602/30300 (epoch 4.294), train_loss = 1.99772443, grad/param norm = 1.8121e-01, time/batch = 0.6935s	
2603/30300 (epoch 4.295), train_loss = 1.79990281, grad/param norm = 1.7447e-01, time/batch = 0.7126s	
2604/30300 (epoch 4.297), train_loss = 1.77497882, grad/param norm = 2.0199e-01, time/batch = 0.7012s	
2605/30300 (epoch 4.299), train_loss = 1.87856569, grad/param norm = 2.0986e-01, time/batch = 0.7009s	
2606/30300 (epoch 4.300), train_loss = 1.84061946, grad/param norm = 1.8216e-01, time/batch = 0.6958s	
2607/30300 (epoch 4.302), train_loss = 1.74668467, grad/param norm = 1.9881e-01, time/batch = 0.6936s	
2608/30300 (epoch 4.304), train_loss = 1.69289356, grad/param norm = 1.9992e-01, time/batch = 0.6876s	
2609/30300 (epoch 4.305), train_loss = 1.80811835, grad/param norm = 1.8002e-01, time/batch = 0.6907s	
2610/30300 (epoch 4.307), train_loss = 1.79843163, grad/param norm = 1.8877e-01, time/batch = 0.6971s	
2611/30300 (epoch 4.309), train_loss = 1.94124038, grad/param norm = 1.8881e-01, time/batch = 0.7038s	
2612/30300 (epoch 4.310), train_loss = 1.76034025, grad/param norm = 1.7833e-01, time/batch = 0.6939s	
2613/30300 (epoch 4.312), train_loss = 1.85445985, grad/param norm = 1.7964e-01, time/batch = 0.7033s	
2614/30300 (epoch 4.314), train_loss = 1.87130729, grad/param norm = 1.7945e-01, time/batch = 0.7113s	
2615/30300 (epoch 4.315), train_loss = 1.92247247, grad/param norm = 1.8865e-01, time/batch = 0.7154s	
2616/30300 (epoch 4.317), train_loss = 1.92592238, grad/param norm = 1.9969e-01, time/batch = 0.6948s	
2617/30300 (epoch 4.318), train_loss = 2.07076472, grad/param norm = 2.0242e-01, time/batch = 0.7064s	
2618/30300 (epoch 4.320), train_loss = 1.94118665, grad/param norm = 2.0624e-01, time/batch = 0.7090s	
2619/30300 (epoch 4.322), train_loss = 1.69122791, grad/param norm = 1.8932e-01, time/batch = 0.7001s	
2620/30300 (epoch 4.323), train_loss = 1.93643982, grad/param norm = 1.8279e-01, time/batch = 0.7095s	
2621/30300 (epoch 4.325), train_loss = 1.76208663, grad/param norm = 1.8103e-01, time/batch = 0.6980s	
2622/30300 (epoch 4.327), train_loss = 1.70896553, grad/param norm = 1.7985e-01, time/batch = 0.7007s	
2623/30300 (epoch 4.328), train_loss = 1.74785096, grad/param norm = 1.9292e-01, time/batch = 0.6996s	
2624/30300 (epoch 4.330), train_loss = 1.91389140, grad/param norm = 2.0872e-01, time/batch = 0.7023s	
2625/30300 (epoch 4.332), train_loss = 1.95309585, grad/param norm = 2.0273e-01, time/batch = 0.6969s	
2626/30300 (epoch 4.333), train_loss = 1.87259866, grad/param norm = 2.0184e-01, time/batch = 0.7110s	
2627/30300 (epoch 4.335), train_loss = 1.62656045, grad/param norm = 2.1315e-01, time/batch = 0.7105s	
2628/30300 (epoch 4.337), train_loss = 2.03369224, grad/param norm = 2.0236e-01, time/batch = 0.6969s	
2629/30300 (epoch 4.338), train_loss = 1.75180076, grad/param norm = 2.1818e-01, time/batch = 0.7012s	
2630/30300 (epoch 4.340), train_loss = 1.78648590, grad/param norm = 2.1845e-01, time/batch = 0.7163s	
2631/30300 (epoch 4.342), train_loss = 1.88916307, grad/param norm = 1.8367e-01, time/batch = 0.7044s	
2632/30300 (epoch 4.343), train_loss = 1.85904926, grad/param norm = 1.9950e-01, time/batch = 0.7106s	
2633/30300 (epoch 4.345), train_loss = 1.84112834, grad/param norm = 1.7876e-01, time/batch = 0.7031s	
2634/30300 (epoch 4.347), train_loss = 1.61075394, grad/param norm = 1.5972e-01, time/batch = 0.6899s	
2635/30300 (epoch 4.348), train_loss = 1.68208389, grad/param norm = 1.8209e-01, time/batch = 0.6995s	
2636/30300 (epoch 4.350), train_loss = 1.82636258, grad/param norm = 2.0735e-01, time/batch = 0.7046s	
2637/30300 (epoch 4.351), train_loss = 1.81478309, grad/param norm = 2.0691e-01, time/batch = 0.6951s	
2638/30300 (epoch 4.353), train_loss = 1.60126417, grad/param norm = 2.1434e-01, time/batch = 0.7061s	
2639/30300 (epoch 4.355), train_loss = 1.84303357, grad/param norm = 1.8165e-01, time/batch = 0.6996s	
2640/30300 (epoch 4.356), train_loss = 1.97520978, grad/param norm = 1.9931e-01, time/batch = 0.6908s	
2641/30300 (epoch 4.358), train_loss = 2.00320240, grad/param norm = 2.1378e-01, time/batch = 0.7004s	
2642/30300 (epoch 4.360), train_loss = 1.75108873, grad/param norm = 1.7288e-01, time/batch = 0.7021s	
2643/30300 (epoch 4.361), train_loss = 1.90562878, grad/param norm = 2.3697e-01, time/batch = 0.6987s	
2644/30300 (epoch 4.363), train_loss = 1.93934093, grad/param norm = 2.1287e-01, time/batch = 0.6919s	
2645/30300 (epoch 4.365), train_loss = 1.77809895, grad/param norm = 1.8940e-01, time/batch = 0.7125s	
2646/30300 (epoch 4.366), train_loss = 1.77930567, grad/param norm = 1.9930e-01, time/batch = 0.6938s	
2647/30300 (epoch 4.368), train_loss = 1.59408242, grad/param norm = 1.8755e-01, time/batch = 0.6934s	
2648/30300 (epoch 4.370), train_loss = 1.82321257, grad/param norm = 2.1417e-01, time/batch = 0.6982s	
2649/30300 (epoch 4.371), train_loss = 1.82174918, grad/param norm = 1.9308e-01, time/batch = 0.6958s	
2650/30300 (epoch 4.373), train_loss = 1.79914088, grad/param norm = 1.9659e-01, time/batch = 0.6992s	
2651/30300 (epoch 4.375), train_loss = 1.72086348, grad/param norm = 1.9401e-01, time/batch = 0.6917s	
2652/30300 (epoch 4.376), train_loss = 1.75447329, grad/param norm = 1.7926e-01, time/batch = 0.6983s	
2653/30300 (epoch 4.378), train_loss = 1.77462009, grad/param norm = 1.8560e-01, time/batch = 0.7217s	
2654/30300 (epoch 4.380), train_loss = 2.05251036, grad/param norm = 2.0180e-01, time/batch = 0.6959s	
2655/30300 (epoch 4.381), train_loss = 1.81556412, grad/param norm = 1.8935e-01, time/batch = 0.6989s	
2656/30300 (epoch 4.383), train_loss = 1.94199988, grad/param norm = 2.0491e-01, time/batch = 0.6958s	
2657/30300 (epoch 4.384), train_loss = 1.93973049, grad/param norm = 1.8197e-01, time/batch = 0.6986s	
2658/30300 (epoch 4.386), train_loss = 1.70435875, grad/param norm = 2.1000e-01, time/batch = 0.7040s	
2659/30300 (epoch 4.388), train_loss = 1.78251489, grad/param norm = 1.8866e-01, time/batch = 0.6950s	
2660/30300 (epoch 4.389), train_loss = 1.83106339, grad/param norm = 1.9890e-01, time/batch = 0.6948s	
2661/30300 (epoch 4.391), train_loss = 1.90132313, grad/param norm = 1.7932e-01, time/batch = 0.6980s	
2662/30300 (epoch 4.393), train_loss = 1.65640841, grad/param norm = 2.0842e-01, time/batch = 0.6929s	
2663/30300 (epoch 4.394), train_loss = 1.81680311, grad/param norm = 1.7739e-01, time/batch = 0.6977s	
2664/30300 (epoch 4.396), train_loss = 1.95797297, grad/param norm = 1.9376e-01, time/batch = 0.6965s	
2665/30300 (epoch 4.398), train_loss = 1.74669941, grad/param norm = 1.7153e-01, time/batch = 0.7057s	
2666/30300 (epoch 4.399), train_loss = 1.74189612, grad/param norm = 1.8193e-01, time/batch = 0.6950s	
2667/30300 (epoch 4.401), train_loss = 1.95942289, grad/param norm = 1.9796e-01, time/batch = 0.7227s	
2668/30300 (epoch 4.403), train_loss = 1.83487738, grad/param norm = 1.9581e-01, time/batch = 0.7105s	
2669/30300 (epoch 4.404), train_loss = 1.79600964, grad/param norm = 2.1898e-01, time/batch = 0.7086s	
2670/30300 (epoch 4.406), train_loss = 1.85996534, grad/param norm = 2.0646e-01, time/batch = 0.7141s	
2671/30300 (epoch 4.408), train_loss = 1.72790126, grad/param norm = 1.9286e-01, time/batch = 0.7227s	
2672/30300 (epoch 4.409), train_loss = 1.59605731, grad/param norm = 2.0542e-01, time/batch = 0.7003s	
2673/30300 (epoch 4.411), train_loss = 1.66043957, grad/param norm = 1.8945e-01, time/batch = 0.7033s	
2674/30300 (epoch 4.413), train_loss = 1.66060041, grad/param norm = 1.7992e-01, time/batch = 0.6972s	
2675/30300 (epoch 4.414), train_loss = 1.96920703, grad/param norm = 1.8563e-01, time/batch = 0.7043s	
2676/30300 (epoch 4.416), train_loss = 1.79571711, grad/param norm = 1.9099e-01, time/batch = 0.7036s	
2677/30300 (epoch 4.417), train_loss = 1.73234365, grad/param norm = 1.7193e-01, time/batch = 0.7020s	
2678/30300 (epoch 4.419), train_loss = 1.62143632, grad/param norm = 2.0586e-01, time/batch = 0.7040s	
2679/30300 (epoch 4.421), train_loss = 1.70433914, grad/param norm = 1.8016e-01, time/batch = 0.7013s	
2680/30300 (epoch 4.422), train_loss = 1.74684695, grad/param norm = 1.8543e-01, time/batch = 0.7031s	
2681/30300 (epoch 4.424), train_loss = 1.82130553, grad/param norm = 1.9322e-01, time/batch = 0.7203s	
2682/30300 (epoch 4.426), train_loss = 1.61683677, grad/param norm = 1.8006e-01, time/batch = 0.7146s	
2683/30300 (epoch 4.427), train_loss = 1.76722585, grad/param norm = 1.9526e-01, time/batch = 0.7043s	
2684/30300 (epoch 4.429), train_loss = 1.83517797, grad/param norm = 2.2431e-01, time/batch = 0.7118s	
2685/30300 (epoch 4.431), train_loss = 1.88401177, grad/param norm = 2.2939e-01, time/batch = 0.7124s	
2686/30300 (epoch 4.432), train_loss = 1.80974437, grad/param norm = 1.9886e-01, time/batch = 0.7224s	
2687/30300 (epoch 4.434), train_loss = 1.70621600, grad/param norm = 1.8810e-01, time/batch = 0.7150s	
2688/30300 (epoch 4.436), train_loss = 1.86559210, grad/param norm = 1.9219e-01, time/batch = 0.7112s	
2689/30300 (epoch 4.437), train_loss = 1.77469271, grad/param norm = 1.9514e-01, time/batch = 0.7095s	
2690/30300 (epoch 4.439), train_loss = 1.71113702, grad/param norm = 1.8847e-01, time/batch = 0.7181s	
2691/30300 (epoch 4.441), train_loss = 1.72422734, grad/param norm = 1.9047e-01, time/batch = 0.7239s	
2692/30300 (epoch 4.442), train_loss = 1.63608905, grad/param norm = 1.9265e-01, time/batch = 0.7114s	
2693/30300 (epoch 4.444), train_loss = 1.66830168, grad/param norm = 2.2300e-01, time/batch = 0.7039s	
2694/30300 (epoch 4.446), train_loss = 1.70613798, grad/param norm = 2.0085e-01, time/batch = 0.7061s	
2695/30300 (epoch 4.447), train_loss = 1.84316468, grad/param norm = 2.7862e-01, time/batch = 0.7073s	
2696/30300 (epoch 4.449), train_loss = 1.71896998, grad/param norm = 1.9056e-01, time/batch = 0.7005s	
2697/30300 (epoch 4.450), train_loss = 1.90388844, grad/param norm = 2.1098e-01, time/batch = 0.6922s	
2698/30300 (epoch 4.452), train_loss = 1.76634847, grad/param norm = 1.6791e-01, time/batch = 0.7007s	
2699/30300 (epoch 4.454), train_loss = 1.74798075, grad/param norm = 1.8865e-01, time/batch = 0.7002s	
2700/30300 (epoch 4.455), train_loss = 1.92693608, grad/param norm = 1.9914e-01, time/batch = 0.6955s	
2701/30300 (epoch 4.457), train_loss = 1.87003293, grad/param norm = 1.9732e-01, time/batch = 0.6918s	
2702/30300 (epoch 4.459), train_loss = 1.85833665, grad/param norm = 2.0402e-01, time/batch = 0.7007s	
2703/30300 (epoch 4.460), train_loss = 1.84848383, grad/param norm = 1.9644e-01, time/batch = 0.6974s	
2704/30300 (epoch 4.462), train_loss = 1.89758928, grad/param norm = 1.9092e-01, time/batch = 0.7042s	
2705/30300 (epoch 4.464), train_loss = 1.77166588, grad/param norm = 1.9853e-01, time/batch = 0.7212s	
2706/30300 (epoch 4.465), train_loss = 1.64698123, grad/param norm = 1.7389e-01, time/batch = 0.7072s	
2707/30300 (epoch 4.467), train_loss = 1.51527564, grad/param norm = 1.8156e-01, time/batch = 0.6992s	
2708/30300 (epoch 4.469), train_loss = 1.75186893, grad/param norm = 1.9144e-01, time/batch = 0.6973s	
2709/30300 (epoch 4.470), train_loss = 1.69273960, grad/param norm = 1.6491e-01, time/batch = 0.7068s	
2710/30300 (epoch 4.472), train_loss = 1.69459793, grad/param norm = 1.9118e-01, time/batch = 0.7038s	
2711/30300 (epoch 4.474), train_loss = 1.79976369, grad/param norm = 2.1583e-01, time/batch = 0.7049s	
2712/30300 (epoch 4.475), train_loss = 1.71482395, grad/param norm = 1.8447e-01, time/batch = 0.7057s	
2713/30300 (epoch 4.477), train_loss = 1.82257246, grad/param norm = 2.0655e-01, time/batch = 0.6965s	
2714/30300 (epoch 4.479), train_loss = 1.88120943, grad/param norm = 1.9743e-01, time/batch = 0.7110s	
2715/30300 (epoch 4.480), train_loss = 1.80172626, grad/param norm = 1.7721e-01, time/batch = 0.7091s	
2716/30300 (epoch 4.482), train_loss = 1.83644989, grad/param norm = 2.2663e-01, time/batch = 0.7072s	
2717/30300 (epoch 4.483), train_loss = 1.83665305, grad/param norm = 2.0209e-01, time/batch = 0.7253s	
2718/30300 (epoch 4.485), train_loss = 1.74733880, grad/param norm = 1.8175e-01, time/batch = 0.7002s	
2719/30300 (epoch 4.487), train_loss = 1.89592173, grad/param norm = 2.1392e-01, time/batch = 0.6931s	
2720/30300 (epoch 4.488), train_loss = 1.73689157, grad/param norm = 1.7404e-01, time/batch = 0.7093s	
2721/30300 (epoch 4.490), train_loss = 1.66740318, grad/param norm = 1.8942e-01, time/batch = 0.6997s	
2722/30300 (epoch 4.492), train_loss = 1.84933020, grad/param norm = 2.2376e-01, time/batch = 0.6949s	
2723/30300 (epoch 4.493), train_loss = 1.73492408, grad/param norm = 2.1430e-01, time/batch = 0.7110s	
2724/30300 (epoch 4.495), train_loss = 1.75559812, grad/param norm = 2.0176e-01, time/batch = 0.7143s	
2725/30300 (epoch 4.497), train_loss = 1.80057419, grad/param norm = 2.1022e-01, time/batch = 0.7032s	
2726/30300 (epoch 4.498), train_loss = 1.82939103, grad/param norm = 1.9683e-01, time/batch = 0.7036s	
2727/30300 (epoch 4.500), train_loss = 1.97985565, grad/param norm = 2.0580e-01, time/batch = 0.7034s	
2728/30300 (epoch 4.502), train_loss = 1.69213725, grad/param norm = 2.1333e-01, time/batch = 0.7101s	
2729/30300 (epoch 4.503), train_loss = 1.85557054, grad/param norm = 1.8581e-01, time/batch = 0.6948s	
2730/30300 (epoch 4.505), train_loss = 1.81796830, grad/param norm = 1.8864e-01, time/batch = 0.7143s	
2731/30300 (epoch 4.507), train_loss = 1.82785985, grad/param norm = 1.9834e-01, time/batch = 0.7102s	
2732/30300 (epoch 4.508), train_loss = 1.92743301, grad/param norm = 2.0065e-01, time/batch = 0.6910s	
2733/30300 (epoch 4.510), train_loss = 1.86695336, grad/param norm = 2.0819e-01, time/batch = 0.7182s	
2734/30300 (epoch 4.512), train_loss = 1.72226899, grad/param norm = 1.9285e-01, time/batch = 0.7169s	
2735/30300 (epoch 4.513), train_loss = 1.83757157, grad/param norm = 2.0168e-01, time/batch = 0.6960s	
2736/30300 (epoch 4.515), train_loss = 1.78124486, grad/param norm = 1.9050e-01, time/batch = 0.7204s	
2737/30300 (epoch 4.517), train_loss = 1.61059262, grad/param norm = 1.7046e-01, time/batch = 0.7175s	
2738/30300 (epoch 4.518), train_loss = 1.89431125, grad/param norm = 1.9679e-01, time/batch = 0.7057s	
2739/30300 (epoch 4.520), train_loss = 2.09363734, grad/param norm = 2.2204e-01, time/batch = 0.6930s	
2740/30300 (epoch 4.521), train_loss = 1.71871921, grad/param norm = 2.0843e-01, time/batch = 0.6907s	
2741/30300 (epoch 4.523), train_loss = 1.94212428, grad/param norm = 2.0137e-01, time/batch = 0.7009s	
2742/30300 (epoch 4.525), train_loss = 1.81245818, grad/param norm = 1.8120e-01, time/batch = 0.6953s	
2743/30300 (epoch 4.526), train_loss = 1.75428311, grad/param norm = 1.7291e-01, time/batch = 0.6945s	
2744/30300 (epoch 4.528), train_loss = 1.60324760, grad/param norm = 1.8124e-01, time/batch = 0.6923s	
2745/30300 (epoch 4.530), train_loss = 1.65356697, grad/param norm = 1.9946e-01, time/batch = 0.6961s	
2746/30300 (epoch 4.531), train_loss = 1.84274298, grad/param norm = 1.9135e-01, time/batch = 0.6907s	
2747/30300 (epoch 4.533), train_loss = 1.86177388, grad/param norm = 1.7774e-01, time/batch = 0.7160s	
2748/30300 (epoch 4.535), train_loss = 1.60020852, grad/param norm = 1.7788e-01, time/batch = 0.7167s	
2749/30300 (epoch 4.536), train_loss = 1.84881715, grad/param norm = 1.8809e-01, time/batch = 0.6903s	
2750/30300 (epoch 4.538), train_loss = 1.61292127, grad/param norm = 1.8017e-01, time/batch = 0.6938s	
2751/30300 (epoch 4.540), train_loss = 1.81327239, grad/param norm = 2.2669e-01, time/batch = 0.7044s	
2752/30300 (epoch 4.541), train_loss = 1.76397048, grad/param norm = 2.2334e-01, time/batch = 0.7044s	
2753/30300 (epoch 4.543), train_loss = 1.78968621, grad/param norm = 1.8704e-01, time/batch = 0.6867s	
2754/30300 (epoch 4.545), train_loss = 1.89866341, grad/param norm = 1.9735e-01, time/batch = 0.6907s	
2755/30300 (epoch 4.546), train_loss = 1.99457021, grad/param norm = 1.9970e-01, time/batch = 0.6986s	
2756/30300 (epoch 4.548), train_loss = 1.72675594, grad/param norm = 2.1298e-01, time/batch = 0.6995s	
2757/30300 (epoch 4.550), train_loss = 1.98769607, grad/param norm = 2.0296e-01, time/batch = 0.6946s	
2758/30300 (epoch 4.551), train_loss = 1.76006485, grad/param norm = 1.9641e-01, time/batch = 0.6971s	
2759/30300 (epoch 4.553), train_loss = 1.71693633, grad/param norm = 2.0882e-01, time/batch = 0.7116s	
2760/30300 (epoch 4.554), train_loss = 1.97105548, grad/param norm = 2.0639e-01, time/batch = 0.6958s	
2761/30300 (epoch 4.556), train_loss = 1.81007760, grad/param norm = 1.8245e-01, time/batch = 0.7045s	
2762/30300 (epoch 4.558), train_loss = 1.92444066, grad/param norm = 1.8481e-01, time/batch = 0.7212s	
2763/30300 (epoch 4.559), train_loss = 1.76797364, grad/param norm = 1.9398e-01, time/batch = 0.6964s	
2764/30300 (epoch 4.561), train_loss = 1.68197718, grad/param norm = 1.8494e-01, time/batch = 0.6966s	
2765/30300 (epoch 4.563), train_loss = 1.80403928, grad/param norm = 1.8740e-01, time/batch = 0.7101s	
2766/30300 (epoch 4.564), train_loss = 1.74709482, grad/param norm = 1.7601e-01, time/batch = 0.7003s	
2767/30300 (epoch 4.566), train_loss = 1.82835912, grad/param norm = 2.1036e-01, time/batch = 0.6909s	
2768/30300 (epoch 4.568), train_loss = 1.64781982, grad/param norm = 1.9952e-01, time/batch = 0.6948s	
2769/30300 (epoch 4.569), train_loss = 1.75555752, grad/param norm = 1.7687e-01, time/batch = 0.6924s	
2770/30300 (epoch 4.571), train_loss = 1.88770279, grad/param norm = 2.0314e-01, time/batch = 0.6987s	
2771/30300 (epoch 4.573), train_loss = 1.85086830, grad/param norm = 1.9093e-01, time/batch = 0.7004s	
2772/30300 (epoch 4.574), train_loss = 1.79396419, grad/param norm = 1.9613e-01, time/batch = 0.7046s	
2773/30300 (epoch 4.576), train_loss = 1.80247384, grad/param norm = 1.8831e-01, time/batch = 0.7003s	
2774/30300 (epoch 4.578), train_loss = 1.66939144, grad/param norm = 1.7439e-01, time/batch = 0.6910s	
2775/30300 (epoch 4.579), train_loss = 1.76204413, grad/param norm = 1.9802e-01, time/batch = 0.6992s	
2776/30300 (epoch 4.581), train_loss = 1.86681770, grad/param norm = 2.2039e-01, time/batch = 0.7142s	
2777/30300 (epoch 4.583), train_loss = 1.94663251, grad/param norm = 2.0766e-01, time/batch = 0.6982s	
2778/30300 (epoch 4.584), train_loss = 1.91311065, grad/param norm = 1.8387e-01, time/batch = 0.7020s	
2779/30300 (epoch 4.586), train_loss = 1.84163201, grad/param norm = 1.8823e-01, time/batch = 0.6896s	
2780/30300 (epoch 4.587), train_loss = 1.83993962, grad/param norm = 1.9227e-01, time/batch = 0.6918s	
2781/30300 (epoch 4.589), train_loss = 1.51936703, grad/param norm = 1.6841e-01, time/batch = 0.6904s	
2782/30300 (epoch 4.591), train_loss = 1.82068604, grad/param norm = 1.9909e-01, time/batch = 0.6874s	
2783/30300 (epoch 4.592), train_loss = 1.77721362, grad/param norm = 1.8118e-01, time/batch = 0.6996s	
2784/30300 (epoch 4.594), train_loss = 1.82493033, grad/param norm = 2.0691e-01, time/batch = 0.6965s	
2785/30300 (epoch 4.596), train_loss = 1.69381742, grad/param norm = 2.1907e-01, time/batch = 0.6939s	
2786/30300 (epoch 4.597), train_loss = 1.74789778, grad/param norm = 1.9850e-01, time/batch = 0.6953s	
2787/30300 (epoch 4.599), train_loss = 1.55985034, grad/param norm = 1.8587e-01, time/batch = 0.6965s	
2788/30300 (epoch 4.601), train_loss = 1.80375293, grad/param norm = 1.9567e-01, time/batch = 0.6980s	
2789/30300 (epoch 4.602), train_loss = 1.75912471, grad/param norm = 1.6984e-01, time/batch = 0.7033s	
2790/30300 (epoch 4.604), train_loss = 1.69344443, grad/param norm = 1.8621e-01, time/batch = 0.7130s	
2791/30300 (epoch 4.606), train_loss = 2.02398910, grad/param norm = 2.2048e-01, time/batch = 0.7115s	
2792/30300 (epoch 4.607), train_loss = 1.86229985, grad/param norm = 1.8898e-01, time/batch = 0.6949s	
2793/30300 (epoch 4.609), train_loss = 2.08933351, grad/param norm = 2.1674e-01, time/batch = 0.6925s	
2794/30300 (epoch 4.611), train_loss = 1.61491647, grad/param norm = 1.7089e-01, time/batch = 0.6934s	
2795/30300 (epoch 4.612), train_loss = 1.73207728, grad/param norm = 1.8259e-01, time/batch = 0.6941s	
2796/30300 (epoch 4.614), train_loss = 1.59097292, grad/param norm = 1.7307e-01, time/batch = 0.6983s	
2797/30300 (epoch 4.616), train_loss = 1.86629338, grad/param norm = 1.9218e-01, time/batch = 0.6881s	
2798/30300 (epoch 4.617), train_loss = 1.78508496, grad/param norm = 1.9737e-01, time/batch = 0.6929s	
2799/30300 (epoch 4.619), train_loss = 1.58562844, grad/param norm = 1.7743e-01, time/batch = 0.6965s	
2800/30300 (epoch 4.620), train_loss = 1.87392496, grad/param norm = 1.8792e-01, time/batch = 0.7121s	
2801/30300 (epoch 4.622), train_loss = 1.73124723, grad/param norm = 1.9277e-01, time/batch = 0.7200s	
2802/30300 (epoch 4.624), train_loss = 1.68723259, grad/param norm = 1.7907e-01, time/batch = 0.7081s	
2803/30300 (epoch 4.625), train_loss = 1.72094963, grad/param norm = 1.9182e-01, time/batch = 0.7071s	
2804/30300 (epoch 4.627), train_loss = 1.95292133, grad/param norm = 1.9688e-01, time/batch = 0.7163s	
2805/30300 (epoch 4.629), train_loss = 1.84903146, grad/param norm = 1.8881e-01, time/batch = 0.7159s	
2806/30300 (epoch 4.630), train_loss = 1.84300375, grad/param norm = 1.9434e-01, time/batch = 0.7016s	
2807/30300 (epoch 4.632), train_loss = 1.88531156, grad/param norm = 2.3756e-01, time/batch = 0.6960s	
2808/30300 (epoch 4.634), train_loss = 1.57972894, grad/param norm = 1.6578e-01, time/batch = 0.7091s	
2809/30300 (epoch 4.635), train_loss = 1.88506455, grad/param norm = 1.7645e-01, time/batch = 0.7046s	
2810/30300 (epoch 4.637), train_loss = 1.80747396, grad/param norm = 1.9741e-01, time/batch = 0.7031s	
2811/30300 (epoch 4.639), train_loss = 1.71768575, grad/param norm = 2.6438e-01, time/batch = 0.7093s	
2812/30300 (epoch 4.640), train_loss = 1.87714177, grad/param norm = 2.0151e-01, time/batch = 0.7060s	
2813/30300 (epoch 4.642), train_loss = 1.79274621, grad/param norm = 2.5377e-01, time/batch = 0.6988s	
2814/30300 (epoch 4.644), train_loss = 1.84842127, grad/param norm = 2.2227e-01, time/batch = 0.7054s	
2815/30300 (epoch 4.645), train_loss = 1.74582648, grad/param norm = 2.0532e-01, time/batch = 0.7193s	
2816/30300 (epoch 4.647), train_loss = 1.76533945, grad/param norm = 1.8532e-01, time/batch = 0.6918s	
2817/30300 (epoch 4.649), train_loss = 1.73815381, grad/param norm = 1.7985e-01, time/batch = 0.6946s	
2818/30300 (epoch 4.650), train_loss = 1.78793953, grad/param norm = 1.8214e-01, time/batch = 0.7080s	
2819/30300 (epoch 4.652), train_loss = 1.65284557, grad/param norm = 1.9475e-01, time/batch = 0.6909s	
2820/30300 (epoch 4.653), train_loss = 1.94975311, grad/param norm = 1.9613e-01, time/batch = 0.7031s	
2821/30300 (epoch 4.655), train_loss = 1.74531960, grad/param norm = 1.9290e-01, time/batch = 0.6998s	
2822/30300 (epoch 4.657), train_loss = 1.87781073, grad/param norm = 1.9310e-01, time/batch = 0.6954s	
2823/30300 (epoch 4.658), train_loss = 1.72012688, grad/param norm = 1.9240e-01, time/batch = 0.6999s	
2824/30300 (epoch 4.660), train_loss = 1.83862109, grad/param norm = 1.8882e-01, time/batch = 0.7031s	
2825/30300 (epoch 4.662), train_loss = 1.85828291, grad/param norm = 1.9205e-01, time/batch = 0.7005s	
2826/30300 (epoch 4.663), train_loss = 1.77765760, grad/param norm = 1.8315e-01, time/batch = 0.6954s	
2827/30300 (epoch 4.665), train_loss = 1.63335195, grad/param norm = 1.7025e-01, time/batch = 0.6908s	
2828/30300 (epoch 4.667), train_loss = 1.93271853, grad/param norm = 2.0924e-01, time/batch = 0.6905s	
2829/30300 (epoch 4.668), train_loss = 1.99708973, grad/param norm = 2.0437e-01, time/batch = 0.6885s	
2830/30300 (epoch 4.670), train_loss = 1.86839295, grad/param norm = 1.8962e-01, time/batch = 0.6912s	
2831/30300 (epoch 4.672), train_loss = 1.86794982, grad/param norm = 1.9430e-01, time/batch = 0.6935s	
2832/30300 (epoch 4.673), train_loss = 1.84252576, grad/param norm = 1.9842e-01, time/batch = 0.6998s	
2833/30300 (epoch 4.675), train_loss = 1.69768183, grad/param norm = 1.9132e-01, time/batch = 0.7211s	
2834/30300 (epoch 4.677), train_loss = 1.70133942, grad/param norm = 1.8823e-01, time/batch = 0.6992s	
2835/30300 (epoch 4.678), train_loss = 1.71985310, grad/param norm = 1.7298e-01, time/batch = 0.6905s	
2836/30300 (epoch 4.680), train_loss = 1.51654965, grad/param norm = 1.9652e-01, time/batch = 0.6909s	
2837/30300 (epoch 4.682), train_loss = 1.77744535, grad/param norm = 2.2411e-01, time/batch = 0.6916s	
2838/30300 (epoch 4.683), train_loss = 1.84937375, grad/param norm = 2.0826e-01, time/batch = 0.6898s	
2839/30300 (epoch 4.685), train_loss = 1.96879957, grad/param norm = 2.1660e-01, time/batch = 0.6903s	
2840/30300 (epoch 4.686), train_loss = 1.83316957, grad/param norm = 2.4209e-01, time/batch = 0.6948s	
2841/30300 (epoch 4.688), train_loss = 1.78598506, grad/param norm = 1.9325e-01, time/batch = 0.6966s	
2842/30300 (epoch 4.690), train_loss = 1.78156723, grad/param norm = 2.1100e-01, time/batch = 0.7028s	
2843/30300 (epoch 4.691), train_loss = 1.80824636, grad/param norm = 2.2846e-01, time/batch = 0.6982s	
2844/30300 (epoch 4.693), train_loss = 2.17104077, grad/param norm = 2.2197e-01, time/batch = 0.6875s	
2845/30300 (epoch 4.695), train_loss = 1.95538270, grad/param norm = 2.0796e-01, time/batch = 0.6901s	
2846/30300 (epoch 4.696), train_loss = 2.03231981, grad/param norm = 2.1729e-01, time/batch = 0.6879s	
2847/30300 (epoch 4.698), train_loss = 1.67920520, grad/param norm = 1.9104e-01, time/batch = 0.7166s	
2848/30300 (epoch 4.700), train_loss = 1.76889962, grad/param norm = 1.9305e-01, time/batch = 0.7048s	
2849/30300 (epoch 4.701), train_loss = 1.54243272, grad/param norm = 1.5943e-01, time/batch = 0.6894s	
2850/30300 (epoch 4.703), train_loss = 1.72263839, grad/param norm = 1.6770e-01, time/batch = 0.6980s	
2851/30300 (epoch 4.705), train_loss = 1.81556791, grad/param norm = 2.1761e-01, time/batch = 0.7207s	
2852/30300 (epoch 4.706), train_loss = 1.76232023, grad/param norm = 1.8405e-01, time/batch = 0.7039s	
2853/30300 (epoch 4.708), train_loss = 1.73897974, grad/param norm = 1.9067e-01, time/batch = 0.6899s	
2854/30300 (epoch 4.710), train_loss = 1.74159947, grad/param norm = 2.0034e-01, time/batch = 0.6924s	
2855/30300 (epoch 4.711), train_loss = 1.66550911, grad/param norm = 1.9326e-01, time/batch = 0.6928s	
2856/30300 (epoch 4.713), train_loss = 1.59414417, grad/param norm = 1.6690e-01, time/batch = 0.6919s	
2857/30300 (epoch 4.715), train_loss = 1.75700939, grad/param norm = 1.8547e-01, time/batch = 0.6906s	
2858/30300 (epoch 4.716), train_loss = 1.94274538, grad/param norm = 1.9208e-01, time/batch = 0.6911s	
2859/30300 (epoch 4.718), train_loss = 1.87893815, grad/param norm = 1.9980e-01, time/batch = 0.6885s	
2860/30300 (epoch 4.719), train_loss = 1.76699493, grad/param norm = 1.9631e-01, time/batch = 0.6935s	
2861/30300 (epoch 4.721), train_loss = 1.78128422, grad/param norm = 1.8458e-01, time/batch = 0.7146s	
2862/30300 (epoch 4.723), train_loss = 1.71877840, grad/param norm = 1.8900e-01, time/batch = 0.7135s	
2863/30300 (epoch 4.724), train_loss = 1.81715853, grad/param norm = 1.8596e-01, time/batch = 0.6952s	
2864/30300 (epoch 4.726), train_loss = 2.20999981, grad/param norm = 2.1784e-01, time/batch = 0.6917s	
2865/30300 (epoch 4.728), train_loss = 1.75158332, grad/param norm = 1.9590e-01, time/batch = 0.6906s	
2866/30300 (epoch 4.729), train_loss = 1.79162402, grad/param norm = 1.9214e-01, time/batch = 0.6901s	
2867/30300 (epoch 4.731), train_loss = 1.87715318, grad/param norm = 1.8945e-01, time/batch = 0.6993s	
2868/30300 (epoch 4.733), train_loss = 1.76450621, grad/param norm = 1.7696e-01, time/batch = 0.7052s	
2869/30300 (epoch 4.734), train_loss = 1.79673739, grad/param norm = 1.7717e-01, time/batch = 0.7036s	
2870/30300 (epoch 4.736), train_loss = 1.73431294, grad/param norm = 1.7432e-01, time/batch = 0.6961s	
2871/30300 (epoch 4.738), train_loss = 1.58351756, grad/param norm = 1.6573e-01, time/batch = 0.6942s	
2872/30300 (epoch 4.739), train_loss = 1.87197037, grad/param norm = 1.8916e-01, time/batch = 0.6891s	
2873/30300 (epoch 4.741), train_loss = 1.84121982, grad/param norm = 1.8137e-01, time/batch = 0.6903s	
2874/30300 (epoch 4.743), train_loss = 1.65187531, grad/param norm = 1.8395e-01, time/batch = 0.6899s	
2875/30300 (epoch 4.744), train_loss = 1.90582597, grad/param norm = 1.9882e-01, time/batch = 0.7041s	
2876/30300 (epoch 4.746), train_loss = 1.59739284, grad/param norm = 1.8627e-01, time/batch = 0.7202s	
2877/30300 (epoch 4.748), train_loss = 1.81751047, grad/param norm = 2.0835e-01, time/batch = 0.6915s	
2878/30300 (epoch 4.749), train_loss = 1.77707855, grad/param norm = 1.8581e-01, time/batch = 0.6885s	
2879/30300 (epoch 4.751), train_loss = 1.67067523, grad/param norm = 1.8827e-01, time/batch = 0.6933s	
2880/30300 (epoch 4.752), train_loss = 1.71859248, grad/param norm = 1.8102e-01, time/batch = 0.6883s	
2881/30300 (epoch 4.754), train_loss = 1.54502481, grad/param norm = 1.7222e-01, time/batch = 0.6926s	
2882/30300 (epoch 4.756), train_loss = 1.70259206, grad/param norm = 1.9632e-01, time/batch = 0.6941s	
2883/30300 (epoch 4.757), train_loss = 1.81817320, grad/param norm = 1.9448e-01, time/batch = 0.6899s	
2884/30300 (epoch 4.759), train_loss = 1.64526793, grad/param norm = 1.8945e-01, time/batch = 0.6939s	
2885/30300 (epoch 4.761), train_loss = 1.65255078, grad/param norm = 1.9194e-01, time/batch = 0.7026s	
2886/30300 (epoch 4.762), train_loss = 1.52942225, grad/param norm = 1.6926e-01, time/batch = 0.7038s	
2887/30300 (epoch 4.764), train_loss = 1.71687308, grad/param norm = 2.0093e-01, time/batch = 0.7007s	
2888/30300 (epoch 4.766), train_loss = 1.78410484, grad/param norm = 1.8321e-01, time/batch = 0.7215s	
2889/30300 (epoch 4.767), train_loss = 1.89701785, grad/param norm = 2.0169e-01, time/batch = 0.7044s	
2890/30300 (epoch 4.769), train_loss = 1.94317579, grad/param norm = 2.2386e-01, time/batch = 0.6909s	
2891/30300 (epoch 4.771), train_loss = 1.78832250, grad/param norm = 1.8718e-01, time/batch = 0.6914s	
2892/30300 (epoch 4.772), train_loss = 1.74126644, grad/param norm = 1.9230e-01, time/batch = 0.6910s	
2893/30300 (epoch 4.774), train_loss = 1.83957421, grad/param norm = 1.9375e-01, time/batch = 0.6964s	
2894/30300 (epoch 4.776), train_loss = 1.77273169, grad/param norm = 1.9623e-01, time/batch = 0.6980s	
2895/30300 (epoch 4.777), train_loss = 1.78358178, grad/param norm = 1.8589e-01, time/batch = 0.6918s	
2896/30300 (epoch 4.779), train_loss = 1.85391789, grad/param norm = 1.8100e-01, time/batch = 0.6934s	
2897/30300 (epoch 4.781), train_loss = 1.74749739, grad/param norm = 1.9450e-01, time/batch = 0.6910s	
2898/30300 (epoch 4.782), train_loss = 1.66509277, grad/param norm = 1.7797e-01, time/batch = 0.7164s	
2899/30300 (epoch 4.784), train_loss = 1.77174947, grad/param norm = 1.7929e-01, time/batch = 0.6916s	
2900/30300 (epoch 4.785), train_loss = 1.94367649, grad/param norm = 1.9602e-01, time/batch = 0.6875s	
2901/30300 (epoch 4.787), train_loss = 1.69495840, grad/param norm = 1.9304e-01, time/batch = 0.6889s	
2902/30300 (epoch 4.789), train_loss = 2.11014141, grad/param norm = 1.8990e-01, time/batch = 0.6901s	
2903/30300 (epoch 4.790), train_loss = 1.88518799, grad/param norm = 1.8414e-01, time/batch = 0.6966s	
2904/30300 (epoch 4.792), train_loss = 1.70475664, grad/param norm = 1.9796e-01, time/batch = 0.7155s	
2905/30300 (epoch 4.794), train_loss = 1.67902136, grad/param norm = 1.7825e-01, time/batch = 0.7086s	
2906/30300 (epoch 4.795), train_loss = 1.75078693, grad/param norm = 1.7936e-01, time/batch = 0.6980s	
2907/30300 (epoch 4.797), train_loss = 1.88754088, grad/param norm = 2.1240e-01, time/batch = 0.6948s	
2908/30300 (epoch 4.799), train_loss = 1.90417145, grad/param norm = 2.2656e-01, time/batch = 0.6969s	
2909/30300 (epoch 4.800), train_loss = 1.79267916, grad/param norm = 2.3354e-01, time/batch = 0.6892s	
2910/30300 (epoch 4.802), train_loss = 1.99037857, grad/param norm = 2.1644e-01, time/batch = 0.6902s	
2911/30300 (epoch 4.804), train_loss = 1.84191259, grad/param norm = 2.2135e-01, time/batch = 0.6910s	
2912/30300 (epoch 4.805), train_loss = 1.94014480, grad/param norm = 1.9456e-01, time/batch = 0.6927s	
2913/30300 (epoch 4.807), train_loss = 1.85267395, grad/param norm = 2.1135e-01, time/batch = 0.6929s	
2914/30300 (epoch 4.809), train_loss = 1.92048166, grad/param norm = 1.9141e-01, time/batch = 0.6959s	
2915/30300 (epoch 4.810), train_loss = 1.86716152, grad/param norm = 1.9892e-01, time/batch = 0.6937s	
2916/30300 (epoch 4.812), train_loss = 1.70165998, grad/param norm = 1.7873e-01, time/batch = 0.6992s	
2917/30300 (epoch 4.814), train_loss = 1.81432807, grad/param norm = 1.8797e-01, time/batch = 0.6976s	
2918/30300 (epoch 4.815), train_loss = 1.78859511, grad/param norm = 1.9867e-01, time/batch = 0.6991s	
2919/30300 (epoch 4.817), train_loss = 1.89468296, grad/param norm = 1.9519e-01, time/batch = 0.7088s	
2920/30300 (epoch 4.818), train_loss = 1.79580526, grad/param norm = 1.9823e-01, time/batch = 0.7047s	
2921/30300 (epoch 4.820), train_loss = 2.03689256, grad/param norm = 1.9306e-01, time/batch = 0.7078s	
2922/30300 (epoch 4.822), train_loss = 1.99680087, grad/param norm = 2.0135e-01, time/batch = 0.6879s	
2923/30300 (epoch 4.823), train_loss = 2.06616160, grad/param norm = 2.1995e-01, time/batch = 0.6925s	
2924/30300 (epoch 4.825), train_loss = 1.88257671, grad/param norm = 2.0062e-01, time/batch = 0.6907s	
2925/30300 (epoch 4.827), train_loss = 1.75225279, grad/param norm = 1.9669e-01, time/batch = 0.6926s	
2926/30300 (epoch 4.828), train_loss = 1.81553385, grad/param norm = 1.6441e-01, time/batch = 0.6881s	
2927/30300 (epoch 4.830), train_loss = 1.80592703, grad/param norm = 1.9116e-01, time/batch = 0.6915s	
2928/30300 (epoch 4.832), train_loss = 1.74878651, grad/param norm = 1.7274e-01, time/batch = 0.6965s	
2929/30300 (epoch 4.833), train_loss = 1.88408090, grad/param norm = 1.8539e-01, time/batch = 0.6915s	
2930/30300 (epoch 4.835), train_loss = 1.79203321, grad/param norm = 1.8814e-01, time/batch = 0.6902s	
2931/30300 (epoch 4.837), train_loss = 1.60541833, grad/param norm = 1.6517e-01, time/batch = 0.6911s	
2932/30300 (epoch 4.838), train_loss = 1.67074130, grad/param norm = 1.7779e-01, time/batch = 0.6909s	
2933/30300 (epoch 4.840), train_loss = 1.73591103, grad/param norm = 1.7411e-01, time/batch = 0.7205s	
2934/30300 (epoch 4.842), train_loss = 1.61801342, grad/param norm = 1.6782e-01, time/batch = 0.6979s	
2935/30300 (epoch 4.843), train_loss = 1.76300747, grad/param norm = 2.0043e-01, time/batch = 0.6941s	
2936/30300 (epoch 4.845), train_loss = 1.63748051, grad/param norm = 1.6039e-01, time/batch = 0.6911s	
2937/30300 (epoch 4.847), train_loss = 1.78932108, grad/param norm = 2.1315e-01, time/batch = 0.6977s	
2938/30300 (epoch 4.848), train_loss = 1.93239365, grad/param norm = 1.9564e-01, time/batch = 0.6904s	
2939/30300 (epoch 4.850), train_loss = 1.68168695, grad/param norm = 1.7675e-01, time/batch = 0.6917s	
2940/30300 (epoch 4.851), train_loss = 2.05054362, grad/param norm = 2.1523e-01, time/batch = 0.6955s	
2941/30300 (epoch 4.853), train_loss = 1.74011285, grad/param norm = 1.8827e-01, time/batch = 0.6913s	
2942/30300 (epoch 4.855), train_loss = 1.70187393, grad/param norm = 2.0247e-01, time/batch = 0.6927s	
2943/30300 (epoch 4.856), train_loss = 1.68953552, grad/param norm = 1.8682e-01, time/batch = 0.6907s	
2944/30300 (epoch 4.858), train_loss = 1.68230924, grad/param norm = 1.7443e-01, time/batch = 0.7057s	
2945/30300 (epoch 4.860), train_loss = 1.79678305, grad/param norm = 1.9004e-01, time/batch = 0.7031s	
2946/30300 (epoch 4.861), train_loss = 1.94155523, grad/param norm = 2.0193e-01, time/batch = 0.7088s	
2947/30300 (epoch 4.863), train_loss = 1.84738655, grad/param norm = 2.0018e-01, time/batch = 0.6887s	
2948/30300 (epoch 4.865), train_loss = 2.07697635, grad/param norm = 2.0266e-01, time/batch = 0.6884s	
2949/30300 (epoch 4.866), train_loss = 1.85156724, grad/param norm = 1.9237e-01, time/batch = 0.6890s	
2950/30300 (epoch 4.868), train_loss = 1.80504411, grad/param norm = 1.9210e-01, time/batch = 0.6867s	
2951/30300 (epoch 4.870), train_loss = 1.73994046, grad/param norm = 1.9639e-01, time/batch = 0.7085s	
2952/30300 (epoch 4.871), train_loss = 1.66809499, grad/param norm = 1.8116e-01, time/batch = 0.7166s	
2953/30300 (epoch 4.873), train_loss = 1.82062610, grad/param norm = 1.7539e-01, time/batch = 0.6905s	
2954/30300 (epoch 4.875), train_loss = 1.61003693, grad/param norm = 1.7514e-01, time/batch = 0.7083s	
2955/30300 (epoch 4.876), train_loss = 1.56755580, grad/param norm = 1.6195e-01, time/batch = 0.7005s	
2956/30300 (epoch 4.878), train_loss = 1.53728053, grad/param norm = 1.7667e-01, time/batch = 0.7111s	
2957/30300 (epoch 4.880), train_loss = 1.63849357, grad/param norm = 1.6772e-01, time/batch = 0.7117s	
2958/30300 (epoch 4.881), train_loss = 1.95135075, grad/param norm = 1.8527e-01, time/batch = 0.6972s	
2959/30300 (epoch 4.883), train_loss = 1.82252316, grad/param norm = 1.9137e-01, time/batch = 0.7000s	
2960/30300 (epoch 4.884), train_loss = 1.64546542, grad/param norm = 1.8670e-01, time/batch = 0.7086s	
2961/30300 (epoch 4.886), train_loss = 1.69414087, grad/param norm = 1.7308e-01, time/batch = 0.7104s	
2962/30300 (epoch 4.888), train_loss = 1.82007042, grad/param norm = 1.9494e-01, time/batch = 0.7128s	
2963/30300 (epoch 4.889), train_loss = 1.73326600, grad/param norm = 2.1258e-01, time/batch = 0.7062s	
2964/30300 (epoch 4.891), train_loss = 1.66817188, grad/param norm = 1.8897e-01, time/batch = 0.6952s	
2965/30300 (epoch 4.893), train_loss = 1.99579741, grad/param norm = 2.0918e-01, time/batch = 0.7090s	
2966/30300 (epoch 4.894), train_loss = 1.83758427, grad/param norm = 1.8360e-01, time/batch = 0.7199s	
2967/30300 (epoch 4.896), train_loss = 1.57678457, grad/param norm = 2.0645e-01, time/batch = 0.6909s	
2968/30300 (epoch 4.898), train_loss = 1.58468619, grad/param norm = 1.8636e-01, time/batch = 0.6909s	
2969/30300 (epoch 4.899), train_loss = 1.70242956, grad/param norm = 1.8171e-01, time/batch = 0.6922s	
2970/30300 (epoch 4.901), train_loss = 1.78940353, grad/param norm = 1.8045e-01, time/batch = 0.6929s	
2971/30300 (epoch 4.903), train_loss = 1.82944619, grad/param norm = 1.9717e-01, time/batch = 0.7134s	
2972/30300 (epoch 4.904), train_loss = 1.72261543, grad/param norm = 1.6525e-01, time/batch = 0.7168s	
2973/30300 (epoch 4.906), train_loss = 1.87302849, grad/param norm = 1.7814e-01, time/batch = 0.7262s	
2974/30300 (epoch 4.908), train_loss = 1.68120593, grad/param norm = 1.8726e-01, time/batch = 0.7069s	
2975/30300 (epoch 4.909), train_loss = 1.77354617, grad/param norm = 1.8377e-01, time/batch = 0.6913s	
2976/30300 (epoch 4.911), train_loss = 1.74538136, grad/param norm = 1.9140e-01, time/batch = 0.6882s	
2977/30300 (epoch 4.913), train_loss = 1.78820843, grad/param norm = 2.0081e-01, time/batch = 0.7108s	
2978/30300 (epoch 4.914), train_loss = 1.78889363, grad/param norm = 2.1632e-01, time/batch = 0.7089s	
2979/30300 (epoch 4.916), train_loss = 1.78514149, grad/param norm = 1.7980e-01, time/batch = 0.6966s	
2980/30300 (epoch 4.917), train_loss = 1.68809901, grad/param norm = 1.7462e-01, time/batch = 0.7230s	
2981/30300 (epoch 4.919), train_loss = 1.79586644, grad/param norm = 1.7132e-01, time/batch = 0.6991s	
2982/30300 (epoch 4.921), train_loss = 1.84760606, grad/param norm = 1.9499e-01, time/batch = 0.6969s	
2983/30300 (epoch 4.922), train_loss = 1.86387598, grad/param norm = 1.9318e-01, time/batch = 0.6959s	
2984/30300 (epoch 4.924), train_loss = 1.76510667, grad/param norm = 1.9779e-01, time/batch = 0.6909s	
2985/30300 (epoch 4.926), train_loss = 1.75230566, grad/param norm = 1.9568e-01, time/batch = 0.6998s	
2986/30300 (epoch 4.927), train_loss = 1.73128119, grad/param norm = 1.9801e-01, time/batch = 0.6907s	
2987/30300 (epoch 4.929), train_loss = 1.77098964, grad/param norm = 1.8919e-01, time/batch = 0.6892s	
2988/30300 (epoch 4.931), train_loss = 1.86462948, grad/param norm = 2.0304e-01, time/batch = 0.6953s	
2989/30300 (epoch 4.932), train_loss = 1.68691276, grad/param norm = 1.9366e-01, time/batch = 0.6926s	
2990/30300 (epoch 4.934), train_loss = 1.74665105, grad/param norm = 1.7872e-01, time/batch = 0.7085s	
2991/30300 (epoch 4.936), train_loss = 1.70873599, grad/param norm = 1.8028e-01, time/batch = 0.7046s	
2992/30300 (epoch 4.937), train_loss = 1.77188795, grad/param norm = 1.7746e-01, time/batch = 0.6959s	
2993/30300 (epoch 4.939), train_loss = 1.90489802, grad/param norm = 1.7729e-01, time/batch = 0.6909s	
2994/30300 (epoch 4.941), train_loss = 1.77893414, grad/param norm = 1.8102e-01, time/batch = 0.6962s	
2995/30300 (epoch 4.942), train_loss = 1.70629388, grad/param norm = 1.8334e-01, time/batch = 0.6955s	
2996/30300 (epoch 4.944), train_loss = 1.60093292, grad/param norm = 1.6189e-01, time/batch = 0.6883s	
2997/30300 (epoch 4.946), train_loss = 1.94271059, grad/param norm = 2.0355e-01, time/batch = 0.6917s	
2998/30300 (epoch 4.947), train_loss = 1.97178111, grad/param norm = 1.9754e-01, time/batch = 0.7017s	
2999/30300 (epoch 4.949), train_loss = 2.02444992, grad/param norm = 2.0511e-01, time/batch = 0.7036s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch4.95_1.8699.t7	
3000/30300 (epoch 4.950), train_loss = 1.90486792, grad/param norm = 1.9507e-01, time/batch = 0.6999s	
3001/30300 (epoch 4.952), train_loss = 2.10980686, grad/param norm = 2.2958e-01, time/batch = 0.6936s	
3002/30300 (epoch 4.954), train_loss = 2.02332033, grad/param norm = 1.8675e-01, time/batch = 0.6945s	
3003/30300 (epoch 4.955), train_loss = 1.70118008, grad/param norm = 1.9257e-01, time/batch = 0.6924s	
3004/30300 (epoch 4.957), train_loss = 1.82700364, grad/param norm = 1.8843e-01, time/batch = 0.6941s	
3005/30300 (epoch 4.959), train_loss = 1.80897306, grad/param norm = 1.9138e-01, time/batch = 0.6962s	
3006/30300 (epoch 4.960), train_loss = 1.74256740, grad/param norm = 1.6920e-01, time/batch = 0.6896s	
3007/30300 (epoch 4.962), train_loss = 1.72748395, grad/param norm = 2.0250e-01, time/batch = 0.6851s	
3008/30300 (epoch 4.964), train_loss = 1.80502009, grad/param norm = 2.0585e-01, time/batch = 0.6931s	
3009/30300 (epoch 4.965), train_loss = 1.70050861, grad/param norm = 1.8475e-01, time/batch = 0.6871s	
3010/30300 (epoch 4.967), train_loss = 1.81506155, grad/param norm = 1.8882e-01, time/batch = 0.6886s	
3011/30300 (epoch 4.969), train_loss = 1.76736714, grad/param norm = 2.2835e-01, time/batch = 0.6893s	
3012/30300 (epoch 4.970), train_loss = 1.68323067, grad/param norm = 1.8244e-01, time/batch = 0.6909s	
3013/30300 (epoch 4.972), train_loss = 1.65281375, grad/param norm = 1.7144e-01, time/batch = 0.6894s	
3014/30300 (epoch 4.974), train_loss = 1.96293458, grad/param norm = 1.9365e-01, time/batch = 0.7165s	
3015/30300 (epoch 4.975), train_loss = 1.98688031, grad/param norm = 2.1766e-01, time/batch = 0.7047s	
3016/30300 (epoch 4.977), train_loss = 1.82236119, grad/param norm = 1.8368e-01, time/batch = 0.6984s	
3017/30300 (epoch 4.979), train_loss = 1.84156029, grad/param norm = 1.8638e-01, time/batch = 0.6959s	
3018/30300 (epoch 4.980), train_loss = 1.83292181, grad/param norm = 2.0376e-01, time/batch = 0.6938s	
3019/30300 (epoch 4.982), train_loss = 1.83593062, grad/param norm = 1.6824e-01, time/batch = 0.6904s	
3020/30300 (epoch 4.983), train_loss = 1.91282772, grad/param norm = 2.0074e-01, time/batch = 0.6904s	
3021/30300 (epoch 4.985), train_loss = 1.78760374, grad/param norm = 1.9132e-01, time/batch = 0.6888s	
3022/30300 (epoch 4.987), train_loss = 1.70061707, grad/param norm = 1.6258e-01, time/batch = 0.6917s	
3023/30300 (epoch 4.988), train_loss = 1.93736849, grad/param norm = 2.0760e-01, time/batch = 0.6915s	
3024/30300 (epoch 4.990), train_loss = 1.60421063, grad/param norm = 1.7086e-01, time/batch = 0.6870s	
3025/30300 (epoch 4.992), train_loss = 1.80729439, grad/param norm = 1.9976e-01, time/batch = 0.6917s	
3026/30300 (epoch 4.993), train_loss = 1.95804891, grad/param norm = 2.0598e-01, time/batch = 0.6890s	
3027/30300 (epoch 4.995), train_loss = 1.88686162, grad/param norm = 1.8487e-01, time/batch = 0.6891s	
3028/30300 (epoch 4.997), train_loss = 1.82249247, grad/param norm = 1.8266e-01, time/batch = 0.7051s	
3029/30300 (epoch 4.998), train_loss = 1.88353510, grad/param norm = 2.0533e-01, time/batch = 0.7162s	
3030/30300 (epoch 5.000), train_loss = 1.71060993, grad/param norm = 1.9127e-01, time/batch = 0.6868s	
3031/30300 (epoch 5.002), train_loss = 1.73992114, grad/param norm = 1.8050e-01, time/batch = 0.6894s	
3032/30300 (epoch 5.003), train_loss = 1.80469714, grad/param norm = 1.9246e-01, time/batch = 0.6935s	
3033/30300 (epoch 5.005), train_loss = 1.79805252, grad/param norm = 1.9837e-01, time/batch = 0.6904s	
3034/30300 (epoch 5.007), train_loss = 1.89239608, grad/param norm = 1.7365e-01, time/batch = 0.6898s	
3035/30300 (epoch 5.008), train_loss = 1.70638859, grad/param norm = 1.8485e-01, time/batch = 0.6888s	
3036/30300 (epoch 5.010), train_loss = 1.73332756, grad/param norm = 1.9434e-01, time/batch = 0.6877s	
3037/30300 (epoch 5.012), train_loss = 1.69619585, grad/param norm = 1.7728e-01, time/batch = 0.6895s	
3038/30300 (epoch 5.013), train_loss = 1.82980894, grad/param norm = 1.8655e-01, time/batch = 0.6923s	
3039/30300 (epoch 5.015), train_loss = 1.71499071, grad/param norm = 1.8429e-01, time/batch = 0.6855s	
3040/30300 (epoch 5.017), train_loss = 1.62773761, grad/param norm = 1.8906e-01, time/batch = 0.6853s	
3041/30300 (epoch 5.018), train_loss = 1.82516761, grad/param norm = 1.7937e-01, time/batch = 0.6902s	
3042/30300 (epoch 5.020), train_loss = 1.95535407, grad/param norm = 1.8939e-01, time/batch = 0.6893s	
3043/30300 (epoch 5.021), train_loss = 1.91650144, grad/param norm = 1.8915e-01, time/batch = 0.6882s	
3044/30300 (epoch 5.023), train_loss = 1.65889915, grad/param norm = 1.8380e-01, time/batch = 0.6923s	
3045/30300 (epoch 5.025), train_loss = 1.68953453, grad/param norm = 1.8969e-01, time/batch = 0.6880s	
3046/30300 (epoch 5.026), train_loss = 1.77707617, grad/param norm = 1.7634e-01, time/batch = 0.6883s	
3047/30300 (epoch 5.028), train_loss = 1.75395868, grad/param norm = 1.8119e-01, time/batch = 0.6946s	
3048/30300 (epoch 5.030), train_loss = 1.62031233, grad/param norm = 2.0221e-01, time/batch = 0.7044s	
3049/30300 (epoch 5.031), train_loss = 1.76873055, grad/param norm = 2.0148e-01, time/batch = 0.7027s	
3050/30300 (epoch 5.033), train_loss = 1.74538169, grad/param norm = 1.9901e-01, time/batch = 0.7056s	
3051/30300 (epoch 5.035), train_loss = 1.81585417, grad/param norm = 1.7508e-01, time/batch = 0.7029s	
3052/30300 (epoch 5.036), train_loss = 1.87620821, grad/param norm = 1.9222e-01, time/batch = 0.7095s	
3053/30300 (epoch 5.038), train_loss = 1.75893056, grad/param norm = 1.8525e-01, time/batch = 0.6969s	
3054/30300 (epoch 5.040), train_loss = 1.45393754, grad/param norm = 1.6883e-01, time/batch = 0.6896s	
3055/30300 (epoch 5.041), train_loss = 1.51615821, grad/param norm = 1.7826e-01, time/batch = 0.6944s	
3056/30300 (epoch 5.043), train_loss = 1.84768666, grad/param norm = 1.8107e-01, time/batch = 0.6903s	
3057/30300 (epoch 5.045), train_loss = 1.70725284, grad/param norm = 1.8737e-01, time/batch = 0.6932s	
3058/30300 (epoch 5.046), train_loss = 1.80699516, grad/param norm = 1.9526e-01, time/batch = 0.6948s	
3059/30300 (epoch 5.048), train_loss = 1.78920174, grad/param norm = 1.9389e-01, time/batch = 0.6917s	
3060/30300 (epoch 5.050), train_loss = 1.83765578, grad/param norm = 1.9377e-01, time/batch = 0.6918s	
3061/30300 (epoch 5.051), train_loss = 1.76076735, grad/param norm = 1.7612e-01, time/batch = 0.6925s	
3062/30300 (epoch 5.053), train_loss = 1.67497843, grad/param norm = 1.9189e-01, time/batch = 0.6955s	
3063/30300 (epoch 5.054), train_loss = 1.66695809, grad/param norm = 2.0161e-01, time/batch = 0.6935s	
3064/30300 (epoch 5.056), train_loss = 1.64220184, grad/param norm = 1.8670e-01, time/batch = 0.7059s	
3065/30300 (epoch 5.058), train_loss = 1.79722200, grad/param norm = 1.8915e-01, time/batch = 0.7103s	
3066/30300 (epoch 5.059), train_loss = 1.74041014, grad/param norm = 1.7486e-01, time/batch = 0.7075s	
3067/30300 (epoch 5.061), train_loss = 1.95366703, grad/param norm = 2.1515e-01, time/batch = 0.7221s	
3068/30300 (epoch 5.063), train_loss = 1.74194436, grad/param norm = 1.9308e-01, time/batch = 0.7188s	
3069/30300 (epoch 5.064), train_loss = 1.87647166, grad/param norm = 1.8797e-01, time/batch = 0.7196s	
3070/30300 (epoch 5.066), train_loss = 1.74096904, grad/param norm = 1.6918e-01, time/batch = 0.7097s	
3071/30300 (epoch 5.068), train_loss = 1.64135367, grad/param norm = 1.6481e-01, time/batch = 0.6889s	
3072/30300 (epoch 5.069), train_loss = 1.87696310, grad/param norm = 1.8242e-01, time/batch = 0.6931s	
3073/30300 (epoch 5.071), train_loss = 1.83725356, grad/param norm = 2.1322e-01, time/batch = 0.6927s	
3074/30300 (epoch 5.073), train_loss = 1.89026090, grad/param norm = 2.2085e-01, time/batch = 0.6923s	
3075/30300 (epoch 5.074), train_loss = 1.82532331, grad/param norm = 1.8584e-01, time/batch = 0.7110s	
3076/30300 (epoch 5.076), train_loss = 1.72021327, grad/param norm = 1.7022e-01, time/batch = 0.7071s	
3077/30300 (epoch 5.078), train_loss = 1.62318462, grad/param norm = 1.9731e-01, time/batch = 0.7030s	
3078/30300 (epoch 5.079), train_loss = 1.61158137, grad/param norm = 1.5727e-01, time/batch = 0.6857s	
3079/30300 (epoch 5.081), train_loss = 1.89129782, grad/param norm = 2.0017e-01, time/batch = 0.6890s	
3080/30300 (epoch 5.083), train_loss = 1.98889108, grad/param norm = 2.2516e-01, time/batch = 0.6893s	
3081/30300 (epoch 5.084), train_loss = 1.71320077, grad/param norm = 2.0312e-01, time/batch = 0.6912s	
3082/30300 (epoch 5.086), train_loss = 1.76723205, grad/param norm = 1.8652e-01, time/batch = 0.6884s	
3083/30300 (epoch 5.087), train_loss = 1.63360760, grad/param norm = 1.6134e-01, time/batch = 0.6909s	
3084/30300 (epoch 5.089), train_loss = 1.73194149, grad/param norm = 1.9023e-01, time/batch = 0.6879s	
3085/30300 (epoch 5.091), train_loss = 1.86417665, grad/param norm = 1.9847e-01, time/batch = 0.6870s	
3086/30300 (epoch 5.092), train_loss = 1.68252735, grad/param norm = 1.8273e-01, time/batch = 0.6871s	
3087/30300 (epoch 5.094), train_loss = 1.99232770, grad/param norm = 1.8940e-01, time/batch = 0.6936s	
3088/30300 (epoch 5.096), train_loss = 1.75225539, grad/param norm = 1.8613e-01, time/batch = 0.6848s	
3089/30300 (epoch 5.097), train_loss = 1.61101784, grad/param norm = 1.8632e-01, time/batch = 0.6906s	
3090/30300 (epoch 5.099), train_loss = 1.92024357, grad/param norm = 1.8071e-01, time/batch = 0.7189s	
3091/30300 (epoch 5.101), train_loss = 2.01385864, grad/param norm = 1.8699e-01, time/batch = 0.7050s	
3092/30300 (epoch 5.102), train_loss = 1.81104986, grad/param norm = 1.9763e-01, time/batch = 0.6900s	
3093/30300 (epoch 5.104), train_loss = 1.67411932, grad/param norm = 1.7450e-01, time/batch = 0.6877s	
3094/30300 (epoch 5.106), train_loss = 1.82050625, grad/param norm = 1.9392e-01, time/batch = 0.6891s	
3095/30300 (epoch 5.107), train_loss = 1.74263622, grad/param norm = 1.8883e-01, time/batch = 0.6871s	
3096/30300 (epoch 5.109), train_loss = 1.91105723, grad/param norm = 1.8969e-01, time/batch = 0.7079s	
3097/30300 (epoch 5.111), train_loss = 1.88589083, grad/param norm = 2.0167e-01, time/batch = 0.7030s	
3098/30300 (epoch 5.112), train_loss = 1.78964564, grad/param norm = 1.7480e-01, time/batch = 0.6868s	
3099/30300 (epoch 5.114), train_loss = 1.72435567, grad/param norm = 1.8376e-01, time/batch = 0.6875s	
3100/30300 (epoch 5.116), train_loss = 1.80027613, grad/param norm = 1.7088e-01, time/batch = 0.6893s	
3101/30300 (epoch 5.117), train_loss = 1.72805173, grad/param norm = 1.6809e-01, time/batch = 0.6875s	
3102/30300 (epoch 5.119), train_loss = 1.64145509, grad/param norm = 1.8385e-01, time/batch = 0.6877s	
3103/30300 (epoch 5.120), train_loss = 1.73350876, grad/param norm = 1.8250e-01, time/batch = 0.6868s	
3104/30300 (epoch 5.122), train_loss = 1.82970680, grad/param norm = 1.6905e-01, time/batch = 0.7075s	
3105/30300 (epoch 5.124), train_loss = 1.98794663, grad/param norm = 2.2014e-01, time/batch = 0.7137s	
3106/30300 (epoch 5.125), train_loss = 1.61259750, grad/param norm = 1.7702e-01, time/batch = 0.6932s	
3107/30300 (epoch 5.127), train_loss = 1.77780626, grad/param norm = 1.8061e-01, time/batch = 0.6923s	
3108/30300 (epoch 5.129), train_loss = 1.89198083, grad/param norm = 1.8164e-01, time/batch = 0.6899s	
3109/30300 (epoch 5.130), train_loss = 1.89331026, grad/param norm = 1.8309e-01, time/batch = 0.6909s	
3110/30300 (epoch 5.132), train_loss = 1.77005804, grad/param norm = 2.0606e-01, time/batch = 0.6875s	
3111/30300 (epoch 5.134), train_loss = 1.63122746, grad/param norm = 1.9174e-01, time/batch = 0.6899s	
3112/30300 (epoch 5.135), train_loss = 1.75341140, grad/param norm = 1.9836e-01, time/batch = 0.6915s	
3113/30300 (epoch 5.137), train_loss = 1.91115082, grad/param norm = 1.9639e-01, time/batch = 0.6895s	
3114/30300 (epoch 5.139), train_loss = 1.76181116, grad/param norm = 2.1322e-01, time/batch = 0.6958s	
3115/30300 (epoch 5.140), train_loss = 2.02482681, grad/param norm = 2.0158e-01, time/batch = 0.6968s	
3116/30300 (epoch 5.142), train_loss = 2.03082855, grad/param norm = 2.6826e-01, time/batch = 0.6919s	
3117/30300 (epoch 5.144), train_loss = 1.84930283, grad/param norm = 1.9695e-01, time/batch = 0.6907s	
3118/30300 (epoch 5.145), train_loss = 1.92159326, grad/param norm = 1.7089e-01, time/batch = 0.6905s	
3119/30300 (epoch 5.147), train_loss = 1.80535654, grad/param norm = 1.9176e-01, time/batch = 0.6939s	
3120/30300 (epoch 5.149), train_loss = 1.99348192, grad/param norm = 1.9010e-01, time/batch = 0.6912s	
3121/30300 (epoch 5.150), train_loss = 1.96562183, grad/param norm = 1.8217e-01, time/batch = 0.6930s	
3122/30300 (epoch 5.152), train_loss = 1.75305747, grad/param norm = 1.9837e-01, time/batch = 0.6915s	
3123/30300 (epoch 5.153), train_loss = 1.83707407, grad/param norm = 2.0106e-01, time/batch = 0.7205s	
3124/30300 (epoch 5.155), train_loss = 1.54985974, grad/param norm = 1.6655e-01, time/batch = 0.7015s	
3125/30300 (epoch 5.157), train_loss = 1.76338950, grad/param norm = 1.7312e-01, time/batch = 0.6877s	
3126/30300 (epoch 5.158), train_loss = 1.84192453, grad/param norm = 1.8485e-01, time/batch = 0.6901s	
3127/30300 (epoch 5.160), train_loss = 1.68426261, grad/param norm = 1.8344e-01, time/batch = 0.6912s	
3128/30300 (epoch 5.162), train_loss = 1.66443453, grad/param norm = 1.7921e-01, time/batch = 0.6863s	
3129/30300 (epoch 5.163), train_loss = 1.69201521, grad/param norm = 2.2120e-01, time/batch = 0.6899s	
3130/30300 (epoch 5.165), train_loss = 1.80233438, grad/param norm = 1.8511e-01, time/batch = 0.6952s	
3131/30300 (epoch 5.167), train_loss = 1.81472548, grad/param norm = 2.0564e-01, time/batch = 0.6896s	
3132/30300 (epoch 5.168), train_loss = 1.71432561, grad/param norm = 1.8911e-01, time/batch = 0.6910s	
3133/30300 (epoch 5.170), train_loss = 1.80439205, grad/param norm = 1.8987e-01, time/batch = 0.6957s	
3134/30300 (epoch 5.172), train_loss = 1.71770979, grad/param norm = 1.7991e-01, time/batch = 0.7156s	
3135/30300 (epoch 5.173), train_loss = 1.84653923, grad/param norm = 1.8530e-01, time/batch = 0.7032s	
3136/30300 (epoch 5.175), train_loss = 1.73519545, grad/param norm = 1.7237e-01, time/batch = 0.6881s	
3137/30300 (epoch 5.177), train_loss = 1.79965584, grad/param norm = 1.7779e-01, time/batch = 0.7119s	
3138/30300 (epoch 5.178), train_loss = 1.55353562, grad/param norm = 1.7334e-01, time/batch = 0.7126s	
3139/30300 (epoch 5.180), train_loss = 1.69165978, grad/param norm = 1.7166e-01, time/batch = 0.6872s	
3140/30300 (epoch 5.182), train_loss = 1.67382320, grad/param norm = 1.8333e-01, time/batch = 0.7055s	
3141/30300 (epoch 5.183), train_loss = 1.63941624, grad/param norm = 1.7864e-01, time/batch = 0.6960s	
3142/30300 (epoch 5.185), train_loss = 2.08862718, grad/param norm = 2.1130e-01, time/batch = 0.6937s	
3143/30300 (epoch 5.186), train_loss = 2.01243971, grad/param norm = 2.0920e-01, time/batch = 0.6961s	
3144/30300 (epoch 5.188), train_loss = 1.80546251, grad/param norm = 1.8613e-01, time/batch = 0.6960s	
3145/30300 (epoch 5.190), train_loss = 1.65564488, grad/param norm = 1.7338e-01, time/batch = 0.7013s	
3146/30300 (epoch 5.191), train_loss = 1.89105222, grad/param norm = 1.9611e-01, time/batch = 0.7240s	
3147/30300 (epoch 5.193), train_loss = 1.62534276, grad/param norm = 1.8427e-01, time/batch = 0.6971s	
3148/30300 (epoch 5.195), train_loss = 1.82638395, grad/param norm = 2.0090e-01, time/batch = 0.6979s	
3149/30300 (epoch 5.196), train_loss = 1.85340683, grad/param norm = 2.2897e-01, time/batch = 0.6986s	
3150/30300 (epoch 5.198), train_loss = 1.54099871, grad/param norm = 1.7521e-01, time/batch = 0.6897s	
3151/30300 (epoch 5.200), train_loss = 1.71117854, grad/param norm = 1.9556e-01, time/batch = 0.7075s	
3152/30300 (epoch 5.201), train_loss = 1.88578161, grad/param norm = 1.9036e-01, time/batch = 0.7195s	
3153/30300 (epoch 5.203), train_loss = 1.72522287, grad/param norm = 1.6830e-01, time/batch = 0.6936s	
3154/30300 (epoch 5.205), train_loss = 2.00045597, grad/param norm = 1.9099e-01, time/batch = 0.7012s	
3155/30300 (epoch 5.206), train_loss = 2.02183751, grad/param norm = 1.9904e-01, time/batch = 0.6904s	
3156/30300 (epoch 5.208), train_loss = 1.94741582, grad/param norm = 2.1167e-01, time/batch = 0.7090s	
3157/30300 (epoch 5.210), train_loss = 1.78643488, grad/param norm = 1.7615e-01, time/batch = 0.6983s	
3158/30300 (epoch 5.211), train_loss = 1.81008496, grad/param norm = 2.0552e-01, time/batch = 0.6895s	
3159/30300 (epoch 5.213), train_loss = 1.71593980, grad/param norm = 1.8624e-01, time/batch = 0.6897s	
3160/30300 (epoch 5.215), train_loss = 1.55383973, grad/param norm = 1.7943e-01, time/batch = 0.6956s	
3161/30300 (epoch 5.216), train_loss = 1.74160879, grad/param norm = 1.8972e-01, time/batch = 0.7002s	
3162/30300 (epoch 5.218), train_loss = 1.66892937, grad/param norm = 1.6992e-01, time/batch = 0.7045s	
3163/30300 (epoch 5.219), train_loss = 1.58211598, grad/param norm = 1.8115e-01, time/batch = 0.6924s	
3164/30300 (epoch 5.221), train_loss = 1.59412620, grad/param norm = 1.7783e-01, time/batch = 0.6860s	
3165/30300 (epoch 5.223), train_loss = 1.72254785, grad/param norm = 1.7296e-01, time/batch = 0.6933s	
3166/30300 (epoch 5.224), train_loss = 1.54679109, grad/param norm = 1.7223e-01, time/batch = 0.7207s	
3167/30300 (epoch 5.226), train_loss = 1.82804423, grad/param norm = 1.9553e-01, time/batch = 0.7005s	
3168/30300 (epoch 5.228), train_loss = 1.84805987, grad/param norm = 1.8106e-01, time/batch = 0.6904s	
3169/30300 (epoch 5.229), train_loss = 1.67433509, grad/param norm = 1.8250e-01, time/batch = 0.6910s	
3170/30300 (epoch 5.231), train_loss = 1.75326956, grad/param norm = 1.8662e-01, time/batch = 0.6952s	
3171/30300 (epoch 5.233), train_loss = 1.67715243, grad/param norm = 1.7266e-01, time/batch = 0.6896s	
3172/30300 (epoch 5.234), train_loss = 1.84064206, grad/param norm = 1.8769e-01, time/batch = 0.6903s	
3173/30300 (epoch 5.236), train_loss = 1.68609768, grad/param norm = 2.1713e-01, time/batch = 0.6907s	
3174/30300 (epoch 5.238), train_loss = 1.84528992, grad/param norm = 2.1350e-01, time/batch = 0.6894s	
3175/30300 (epoch 5.239), train_loss = 1.76418986, grad/param norm = 1.9082e-01, time/batch = 0.6989s	
3176/30300 (epoch 5.241), train_loss = 1.77748596, grad/param norm = 1.8024e-01, time/batch = 0.7092s	
3177/30300 (epoch 5.243), train_loss = 1.72477762, grad/param norm = 1.8712e-01, time/batch = 0.6950s	
3178/30300 (epoch 5.244), train_loss = 2.09562467, grad/param norm = 1.9813e-01, time/batch = 0.7029s	
3179/30300 (epoch 5.246), train_loss = 1.73187739, grad/param norm = 1.8867e-01, time/batch = 0.7157s	
3180/30300 (epoch 5.248), train_loss = 1.81974961, grad/param norm = 1.7100e-01, time/batch = 0.7134s	
3181/30300 (epoch 5.249), train_loss = 1.57542373, grad/param norm = 1.6738e-01, time/batch = 0.7148s	
3182/30300 (epoch 5.251), train_loss = 1.65904456, grad/param norm = 1.7944e-01, time/batch = 0.7072s	
3183/30300 (epoch 5.252), train_loss = 1.92336247, grad/param norm = 1.7494e-01, time/batch = 0.7041s	
3184/30300 (epoch 5.254), train_loss = 1.82917217, grad/param norm = 1.7868e-01, time/batch = 0.7055s	
3185/30300 (epoch 5.256), train_loss = 1.79661749, grad/param norm = 1.7403e-01, time/batch = 0.7191s	
3186/30300 (epoch 5.257), train_loss = 1.91775762, grad/param norm = 1.9755e-01, time/batch = 0.7072s	
3187/30300 (epoch 5.259), train_loss = 1.82804391, grad/param norm = 1.9255e-01, time/batch = 0.6996s	
3188/30300 (epoch 5.261), train_loss = 1.90293876, grad/param norm = 1.7783e-01, time/batch = 0.6925s	
3189/30300 (epoch 5.262), train_loss = 1.73359931, grad/param norm = 1.6804e-01, time/batch = 0.6884s	
3190/30300 (epoch 5.264), train_loss = 1.75478025, grad/param norm = 1.7524e-01, time/batch = 0.6902s	
3191/30300 (epoch 5.266), train_loss = 1.68087223, grad/param norm = 1.6507e-01, time/batch = 0.6914s	
3192/30300 (epoch 5.267), train_loss = 1.95400131, grad/param norm = 2.0053e-01, time/batch = 0.6915s	
3193/30300 (epoch 5.269), train_loss = 1.78954149, grad/param norm = 1.8786e-01, time/batch = 0.6835s	
3194/30300 (epoch 5.271), train_loss = 1.76930306, grad/param norm = 1.9531e-01, time/batch = 0.6898s	
3195/30300 (epoch 5.272), train_loss = 1.78870111, grad/param norm = 1.8302e-01, time/batch = 0.6944s	
3196/30300 (epoch 5.274), train_loss = 1.90980584, grad/param norm = 1.8571e-01, time/batch = 0.6921s	
3197/30300 (epoch 5.276), train_loss = 1.90924664, grad/param norm = 1.9815e-01, time/batch = 0.6943s	
3198/30300 (epoch 5.277), train_loss = 1.69490856, grad/param norm = 1.8016e-01, time/batch = 0.6936s	
3199/30300 (epoch 5.279), train_loss = 1.78477124, grad/param norm = 1.7777e-01, time/batch = 0.6934s	
3200/30300 (epoch 5.281), train_loss = 1.82057471, grad/param norm = 1.7614e-01, time/batch = 0.6868s	
3201/30300 (epoch 5.282), train_loss = 1.64907013, grad/param norm = 1.7779e-01, time/batch = 0.6929s	
3202/30300 (epoch 5.284), train_loss = 1.98540336, grad/param norm = 2.0606e-01, time/batch = 0.6941s	
3203/30300 (epoch 5.285), train_loss = 1.78786169, grad/param norm = 1.9122e-01, time/batch = 0.6876s	
3204/30300 (epoch 5.287), train_loss = 1.79051300, grad/param norm = 1.8209e-01, time/batch = 0.6919s	
3205/30300 (epoch 5.289), train_loss = 1.82225826, grad/param norm = 1.8771e-01, time/batch = 0.6919s	
3206/30300 (epoch 5.290), train_loss = 1.48054733, grad/param norm = 1.5819e-01, time/batch = 0.6958s	
3207/30300 (epoch 5.292), train_loss = 1.66508811, grad/param norm = 1.6476e-01, time/batch = 0.6964s	
3208/30300 (epoch 5.294), train_loss = 1.91861526, grad/param norm = 1.7090e-01, time/batch = 0.7057s	
3209/30300 (epoch 5.295), train_loss = 1.71650203, grad/param norm = 1.6123e-01, time/batch = 0.7203s	
3210/30300 (epoch 5.297), train_loss = 1.68717182, grad/param norm = 1.8361e-01, time/batch = 0.6879s	
3211/30300 (epoch 5.299), train_loss = 1.75921185, grad/param norm = 1.9228e-01, time/batch = 0.6875s	
3212/30300 (epoch 5.300), train_loss = 1.76038866, grad/param norm = 1.7557e-01, time/batch = 0.6908s	
3213/30300 (epoch 5.302), train_loss = 1.66726307, grad/param norm = 1.8303e-01, time/batch = 0.6884s	
3214/30300 (epoch 5.304), train_loss = 1.59317751, grad/param norm = 1.7294e-01, time/batch = 0.6873s	
3215/30300 (epoch 5.305), train_loss = 1.70962328, grad/param norm = 1.6869e-01, time/batch = 0.6899s	
3216/30300 (epoch 5.307), train_loss = 1.70475527, grad/param norm = 1.6900e-01, time/batch = 0.6925s	
3217/30300 (epoch 5.309), train_loss = 1.84148531, grad/param norm = 1.8584e-01, time/batch = 0.6898s	
3218/30300 (epoch 5.310), train_loss = 1.67224145, grad/param norm = 1.6435e-01, time/batch = 0.6878s	
3219/30300 (epoch 5.312), train_loss = 1.77014422, grad/param norm = 1.6864e-01, time/batch = 0.6928s	
3220/30300 (epoch 5.314), train_loss = 1.78351264, grad/param norm = 1.6620e-01, time/batch = 0.7132s	
3221/30300 (epoch 5.315), train_loss = 1.83315666, grad/param norm = 1.7556e-01, time/batch = 0.6989s	
3222/30300 (epoch 5.317), train_loss = 1.84549685, grad/param norm = 1.9360e-01, time/batch = 0.6874s	
3223/30300 (epoch 5.318), train_loss = 1.97478005, grad/param norm = 1.9788e-01, time/batch = 0.7264s	
3224/30300 (epoch 5.320), train_loss = 1.86882508, grad/param norm = 1.9035e-01, time/batch = 0.7037s	
3225/30300 (epoch 5.322), train_loss = 1.61482577, grad/param norm = 1.8109e-01, time/batch = 0.6969s	
3226/30300 (epoch 5.323), train_loss = 1.86674880, grad/param norm = 1.7317e-01, time/batch = 0.6940s	
3227/30300 (epoch 5.325), train_loss = 1.67100671, grad/param norm = 1.6741e-01, time/batch = 0.6907s	
3228/30300 (epoch 5.327), train_loss = 1.64332246, grad/param norm = 1.7163e-01, time/batch = 0.6872s	
3229/30300 (epoch 5.328), train_loss = 1.66127639, grad/param norm = 1.7889e-01, time/batch = 0.6874s	
3230/30300 (epoch 5.330), train_loss = 1.82330116, grad/param norm = 1.7030e-01, time/batch = 0.6896s	
3231/30300 (epoch 5.332), train_loss = 1.86583587, grad/param norm = 1.8861e-01, time/batch = 0.6934s	
3232/30300 (epoch 5.333), train_loss = 1.78346927, grad/param norm = 1.8526e-01, time/batch = 0.6885s	
3233/30300 (epoch 5.335), train_loss = 1.54676630, grad/param norm = 1.8423e-01, time/batch = 0.6922s	
3234/30300 (epoch 5.337), train_loss = 1.93141278, grad/param norm = 1.8613e-01, time/batch = 0.6963s	
3235/30300 (epoch 5.338), train_loss = 1.65005729, grad/param norm = 1.9579e-01, time/batch = 0.7081s	
3236/30300 (epoch 5.340), train_loss = 1.68025296, grad/param norm = 1.9259e-01, time/batch = 0.7008s	
3237/30300 (epoch 5.342), train_loss = 1.80999655, grad/param norm = 1.6850e-01, time/batch = 0.7145s	
3238/30300 (epoch 5.343), train_loss = 1.78414019, grad/param norm = 1.8233e-01, time/batch = 0.7124s	
3239/30300 (epoch 5.345), train_loss = 1.75399681, grad/param norm = 1.7305e-01, time/batch = 0.6867s	
3240/30300 (epoch 5.347), train_loss = 1.53087166, grad/param norm = 1.4957e-01, time/batch = 0.6952s	
3241/30300 (epoch 5.348), train_loss = 1.59740140, grad/param norm = 1.6973e-01, time/batch = 0.6916s	
3242/30300 (epoch 5.350), train_loss = 1.73871323, grad/param norm = 1.8204e-01, time/batch = 0.6896s	
3243/30300 (epoch 5.351), train_loss = 1.74131789, grad/param norm = 1.9770e-01, time/batch = 0.7035s	
3244/30300 (epoch 5.353), train_loss = 1.52006246, grad/param norm = 1.9680e-01, time/batch = 0.6964s	
3245/30300 (epoch 5.355), train_loss = 1.73441213, grad/param norm = 1.6911e-01, time/batch = 0.6882s	
3246/30300 (epoch 5.356), train_loss = 1.90525332, grad/param norm = 1.9171e-01, time/batch = 0.6880s	
3247/30300 (epoch 5.358), train_loss = 1.91708431, grad/param norm = 1.9342e-01, time/batch = 0.6882s	
3248/30300 (epoch 5.360), train_loss = 1.67260598, grad/param norm = 1.6572e-01, time/batch = 0.6918s	
3249/30300 (epoch 5.361), train_loss = 1.81891910, grad/param norm = 2.0147e-01, time/batch = 0.6935s	
3250/30300 (epoch 5.363), train_loss = 1.84770353, grad/param norm = 1.9623e-01, time/batch = 0.6948s	
3251/30300 (epoch 5.365), train_loss = 1.69733123, grad/param norm = 1.7563e-01, time/batch = 0.7096s	
3252/30300 (epoch 5.366), train_loss = 1.69155737, grad/param norm = 1.8589e-01, time/batch = 0.7236s	
3253/30300 (epoch 5.368), train_loss = 1.52440445, grad/param norm = 1.8265e-01, time/batch = 0.7036s	
3254/30300 (epoch 5.370), train_loss = 1.71276327, grad/param norm = 1.9271e-01, time/batch = 0.6907s	
3255/30300 (epoch 5.371), train_loss = 1.73908171, grad/param norm = 1.7240e-01, time/batch = 0.7046s	
3256/30300 (epoch 5.373), train_loss = 1.69721598, grad/param norm = 1.7342e-01, time/batch = 0.6915s	
3257/30300 (epoch 5.375), train_loss = 1.62931983, grad/param norm = 1.7348e-01, time/batch = 0.6916s	
3258/30300 (epoch 5.376), train_loss = 1.66263744, grad/param norm = 1.6567e-01, time/batch = 0.6918s	
3259/30300 (epoch 5.378), train_loss = 1.70037045, grad/param norm = 1.7261e-01, time/batch = 0.6865s	
3260/30300 (epoch 5.380), train_loss = 1.97338296, grad/param norm = 1.9277e-01, time/batch = 0.6894s	
3261/30300 (epoch 5.381), train_loss = 1.70887238, grad/param norm = 1.8072e-01, time/batch = 0.6930s	
3262/30300 (epoch 5.383), train_loss = 1.85003097, grad/param norm = 2.1319e-01, time/batch = 0.7004s	
3263/30300 (epoch 5.384), train_loss = 1.86406686, grad/param norm = 1.8306e-01, time/batch = 0.6990s	
3264/30300 (epoch 5.386), train_loss = 1.61854736, grad/param norm = 2.0014e-01, time/batch = 0.6926s	
3265/30300 (epoch 5.388), train_loss = 1.67335238, grad/param norm = 1.7341e-01, time/batch = 0.6931s	
3266/30300 (epoch 5.389), train_loss = 1.74513305, grad/param norm = 1.8407e-01, time/batch = 0.7248s	
3267/30300 (epoch 5.391), train_loss = 1.81022163, grad/param norm = 1.6711e-01, time/batch = 0.6992s	
3268/30300 (epoch 5.393), train_loss = 1.55840289, grad/param norm = 1.7849e-01, time/batch = 0.6900s	
3269/30300 (epoch 5.394), train_loss = 1.73179335, grad/param norm = 1.6901e-01, time/batch = 0.6914s	
3270/30300 (epoch 5.396), train_loss = 1.88834287, grad/param norm = 1.8822e-01, time/batch = 0.6908s	
3271/30300 (epoch 5.398), train_loss = 1.65321734, grad/param norm = 1.5381e-01, time/batch = 0.6901s	
3272/30300 (epoch 5.399), train_loss = 1.68844923, grad/param norm = 1.8156e-01, time/batch = 0.6960s	
3273/30300 (epoch 5.401), train_loss = 1.86284170, grad/param norm = 1.7940e-01, time/batch = 0.6918s	
3274/30300 (epoch 5.403), train_loss = 1.74381359, grad/param norm = 1.8436e-01, time/batch = 0.6950s	
3275/30300 (epoch 5.404), train_loss = 1.69796512, grad/param norm = 2.0323e-01, time/batch = 0.6898s	
3276/30300 (epoch 5.406), train_loss = 1.77473181, grad/param norm = 1.9070e-01, time/batch = 0.6916s	
3277/30300 (epoch 5.408), train_loss = 1.64458416, grad/param norm = 1.8259e-01, time/batch = 0.6890s	
3278/30300 (epoch 5.409), train_loss = 1.51612000, grad/param norm = 1.8629e-01, time/batch = 0.6920s	
3279/30300 (epoch 5.411), train_loss = 1.56726777, grad/param norm = 1.6987e-01, time/batch = 0.6918s	
3280/30300 (epoch 5.413), train_loss = 1.58102944, grad/param norm = 1.7315e-01, time/batch = 0.6900s	
3281/30300 (epoch 5.414), train_loss = 1.87337152, grad/param norm = 1.7514e-01, time/batch = 0.6991s	
3282/30300 (epoch 5.416), train_loss = 1.70823010, grad/param norm = 1.8139e-01, time/batch = 0.6933s	
3283/30300 (epoch 5.417), train_loss = 1.65851383, grad/param norm = 1.6137e-01, time/batch = 0.6916s	
3284/30300 (epoch 5.419), train_loss = 1.53949462, grad/param norm = 1.7759e-01, time/batch = 0.6943s	
3285/30300 (epoch 5.421), train_loss = 1.62545501, grad/param norm = 1.6798e-01, time/batch = 0.6906s	
3286/30300 (epoch 5.422), train_loss = 1.68585382, grad/param norm = 1.8486e-01, time/batch = 0.6873s	
3287/30300 (epoch 5.424), train_loss = 1.72524504, grad/param norm = 1.7740e-01, time/batch = 0.6925s	
3288/30300 (epoch 5.426), train_loss = 1.54974889, grad/param norm = 1.6820e-01, time/batch = 0.6915s	
3289/30300 (epoch 5.427), train_loss = 1.69223781, grad/param norm = 1.8190e-01, time/batch = 0.6918s	
3290/30300 (epoch 5.429), train_loss = 1.74473027, grad/param norm = 1.9374e-01, time/batch = 0.7116s	
3291/30300 (epoch 5.431), train_loss = 1.80007570, grad/param norm = 2.0783e-01, time/batch = 0.7133s	
3292/30300 (epoch 5.432), train_loss = 1.72017948, grad/param norm = 1.8294e-01, time/batch = 0.6859s	
3293/30300 (epoch 5.434), train_loss = 1.62039909, grad/param norm = 1.7851e-01, time/batch = 0.6852s	
3294/30300 (epoch 5.436), train_loss = 1.81219297, grad/param norm = 1.8086e-01, time/batch = 0.6949s	
3295/30300 (epoch 5.437), train_loss = 1.67913289, grad/param norm = 1.9114e-01, time/batch = 0.6907s	
3296/30300 (epoch 5.439), train_loss = 1.62283949, grad/param norm = 1.7335e-01, time/batch = 0.6855s	
3297/30300 (epoch 5.441), train_loss = 1.63835714, grad/param norm = 1.7621e-01, time/batch = 0.6852s	
3298/30300 (epoch 5.442), train_loss = 1.55573377, grad/param norm = 1.7216e-01, time/batch = 0.6893s	
3299/30300 (epoch 5.444), train_loss = 1.55300278, grad/param norm = 2.1143e-01, time/batch = 0.6934s	
3300/30300 (epoch 5.446), train_loss = 1.63176863, grad/param norm = 1.8415e-01, time/batch = 0.6870s	
3301/30300 (epoch 5.447), train_loss = 1.75043358, grad/param norm = 2.5613e-01, time/batch = 0.6870s	
3302/30300 (epoch 5.449), train_loss = 1.63366335, grad/param norm = 1.7237e-01, time/batch = 0.6852s	
3303/30300 (epoch 5.450), train_loss = 1.80698149, grad/param norm = 1.7969e-01, time/batch = 0.6949s	
3304/30300 (epoch 5.452), train_loss = 1.70035790, grad/param norm = 1.6398e-01, time/batch = 0.7010s	
3305/30300 (epoch 5.454), train_loss = 1.66674982, grad/param norm = 1.6901e-01, time/batch = 0.6980s	
3306/30300 (epoch 5.455), train_loss = 1.83478239, grad/param norm = 1.8894e-01, time/batch = 0.7070s	
3307/30300 (epoch 5.457), train_loss = 1.78410143, grad/param norm = 1.8481e-01, time/batch = 0.7023s	
3308/30300 (epoch 5.459), train_loss = 1.78251236, grad/param norm = 1.9535e-01, time/batch = 0.7035s	
3309/30300 (epoch 5.460), train_loss = 1.79291699, grad/param norm = 1.8817e-01, time/batch = 0.7268s	
3310/30300 (epoch 5.462), train_loss = 1.82018058, grad/param norm = 1.7991e-01, time/batch = 0.6932s	
3311/30300 (epoch 5.464), train_loss = 1.66519036, grad/param norm = 1.8210e-01, time/batch = 0.6938s	
3312/30300 (epoch 5.465), train_loss = 1.55860953, grad/param norm = 1.6412e-01, time/batch = 0.6895s	
3313/30300 (epoch 5.467), train_loss = 1.43833769, grad/param norm = 1.7293e-01, time/batch = 0.6967s	
3314/30300 (epoch 5.469), train_loss = 1.65989654, grad/param norm = 1.8438e-01, time/batch = 0.7086s	
3315/30300 (epoch 5.470), train_loss = 1.62055426, grad/param norm = 1.5781e-01, time/batch = 0.7079s	
3316/30300 (epoch 5.472), train_loss = 1.61352194, grad/param norm = 1.7310e-01, time/batch = 0.7149s	
3317/30300 (epoch 5.474), train_loss = 1.71296440, grad/param norm = 1.9456e-01, time/batch = 0.7164s	
3318/30300 (epoch 5.475), train_loss = 1.60045386, grad/param norm = 1.7226e-01, time/batch = 0.7096s	
3319/30300 (epoch 5.477), train_loss = 1.74393349, grad/param norm = 1.9460e-01, time/batch = 0.7209s	
3320/30300 (epoch 5.479), train_loss = 1.77738527, grad/param norm = 1.7990e-01, time/batch = 0.6959s	
3321/30300 (epoch 5.480), train_loss = 1.75202185, grad/param norm = 1.6927e-01, time/batch = 0.6997s	
3322/30300 (epoch 5.482), train_loss = 1.74379700, grad/param norm = 1.9810e-01, time/batch = 0.6915s	
3323/30300 (epoch 5.483), train_loss = 1.72582113, grad/param norm = 1.8660e-01, time/batch = 0.6950s	
3324/30300 (epoch 5.485), train_loss = 1.66634465, grad/param norm = 1.7144e-01, time/batch = 0.6914s	
3325/30300 (epoch 5.487), train_loss = 1.80201906, grad/param norm = 2.0458e-01, time/batch = 0.6905s	
3326/30300 (epoch 5.488), train_loss = 1.67279037, grad/param norm = 1.6445e-01, time/batch = 0.6942s	
3327/30300 (epoch 5.490), train_loss = 1.59516126, grad/param norm = 1.7994e-01, time/batch = 0.6933s	
3328/30300 (epoch 5.492), train_loss = 1.78018941, grad/param norm = 2.0553e-01, time/batch = 0.6900s	
3329/30300 (epoch 5.493), train_loss = 1.64778723, grad/param norm = 1.8138e-01, time/batch = 0.6863s	
3330/30300 (epoch 5.495), train_loss = 1.65356038, grad/param norm = 1.8848e-01, time/batch = 0.6867s	
3331/30300 (epoch 5.497), train_loss = 1.71292552, grad/param norm = 1.9576e-01, time/batch = 0.6951s	
3332/30300 (epoch 5.498), train_loss = 1.74662253, grad/param norm = 1.8065e-01, time/batch = 0.6886s	
3333/30300 (epoch 5.500), train_loss = 1.89258375, grad/param norm = 1.8921e-01, time/batch = 0.7183s	
3334/30300 (epoch 5.502), train_loss = 1.60866739, grad/param norm = 1.8321e-01, time/batch = 0.7064s	
3335/30300 (epoch 5.503), train_loss = 1.77220387, grad/param norm = 1.7386e-01, time/batch = 0.6914s	
3336/30300 (epoch 5.505), train_loss = 1.72570239, grad/param norm = 1.7813e-01, time/batch = 0.6939s	
3337/30300 (epoch 5.507), train_loss = 1.72627089, grad/param norm = 1.9044e-01, time/batch = 0.6940s	
3338/30300 (epoch 5.508), train_loss = 1.80581835, grad/param norm = 1.8638e-01, time/batch = 0.6903s	
3339/30300 (epoch 5.510), train_loss = 1.78263099, grad/param norm = 1.9717e-01, time/batch = 0.6896s	
3340/30300 (epoch 5.512), train_loss = 1.64860866, grad/param norm = 1.8024e-01, time/batch = 0.6899s	
3341/30300 (epoch 5.513), train_loss = 1.77100533, grad/param norm = 1.8181e-01, time/batch = 0.6895s	
3342/30300 (epoch 5.515), train_loss = 1.69309856, grad/param norm = 1.7655e-01, time/batch = 0.6950s	
3343/30300 (epoch 5.517), train_loss = 1.53759969, grad/param norm = 1.6318e-01, time/batch = 0.7062s	
3344/30300 (epoch 5.518), train_loss = 1.80554729, grad/param norm = 1.8254e-01, time/batch = 0.7115s	
3345/30300 (epoch 5.520), train_loss = 1.98989375, grad/param norm = 2.0231e-01, time/batch = 0.7045s	
3346/30300 (epoch 5.521), train_loss = 1.61993647, grad/param norm = 1.9434e-01, time/batch = 0.6942s	
3347/30300 (epoch 5.523), train_loss = 1.86063572, grad/param norm = 1.8714e-01, time/batch = 0.7063s	
3348/30300 (epoch 5.525), train_loss = 1.70512815, grad/param norm = 1.7465e-01, time/batch = 0.7195s	
3349/30300 (epoch 5.526), train_loss = 1.68998858, grad/param norm = 1.7000e-01, time/batch = 0.7220s	
3350/30300 (epoch 5.528), train_loss = 1.50805258, grad/param norm = 1.6838e-01, time/batch = 0.7159s	
3351/30300 (epoch 5.530), train_loss = 1.56329840, grad/param norm = 1.8758e-01, time/batch = 0.6962s	
3352/30300 (epoch 5.531), train_loss = 1.75632103, grad/param norm = 1.8820e-01, time/batch = 0.6893s	
3353/30300 (epoch 5.533), train_loss = 1.79289382, grad/param norm = 1.7586e-01, time/batch = 0.6891s	
3354/30300 (epoch 5.535), train_loss = 1.50165275, grad/param norm = 1.6478e-01, time/batch = 0.6916s	
3355/30300 (epoch 5.536), train_loss = 1.76608474, grad/param norm = 1.8287e-01, time/batch = 0.7045s	
3356/30300 (epoch 5.538), train_loss = 1.52665134, grad/param norm = 1.6394e-01, time/batch = 0.6961s	
3357/30300 (epoch 5.540), train_loss = 1.70012391, grad/param norm = 2.3009e-01, time/batch = 0.6955s	
3358/30300 (epoch 5.541), train_loss = 1.68584539, grad/param norm = 1.9407e-01, time/batch = 0.6918s	
3359/30300 (epoch 5.543), train_loss = 1.70688264, grad/param norm = 1.7555e-01, time/batch = 0.6975s	
3360/30300 (epoch 5.545), train_loss = 1.79863563, grad/param norm = 1.8507e-01, time/batch = 0.6909s	
3361/30300 (epoch 5.546), train_loss = 1.90825446, grad/param norm = 1.8571e-01, time/batch = 0.7029s	
3362/30300 (epoch 5.548), train_loss = 1.64937510, grad/param norm = 1.9915e-01, time/batch = 0.6936s	
3363/30300 (epoch 5.550), train_loss = 1.88812897, grad/param norm = 1.9208e-01, time/batch = 0.6891s	
3364/30300 (epoch 5.551), train_loss = 1.66376096, grad/param norm = 1.8091e-01, time/batch = 0.6900s	
3365/30300 (epoch 5.553), train_loss = 1.62618911, grad/param norm = 1.8175e-01, time/batch = 0.6882s	
3366/30300 (epoch 5.554), train_loss = 1.88251725, grad/param norm = 1.9624e-01, time/batch = 0.6888s	
3367/30300 (epoch 5.556), train_loss = 1.72641790, grad/param norm = 1.6601e-01, time/batch = 0.6888s	
3368/30300 (epoch 5.558), train_loss = 1.83992173, grad/param norm = 1.8761e-01, time/batch = 0.6895s	
3369/30300 (epoch 5.559), train_loss = 1.68257812, grad/param norm = 1.8068e-01, time/batch = 0.6900s	
3370/30300 (epoch 5.561), train_loss = 1.59586418, grad/param norm = 1.8014e-01, time/batch = 0.6912s	
3371/30300 (epoch 5.563), train_loss = 1.68868788, grad/param norm = 1.6952e-01, time/batch = 0.6957s	
3372/30300 (epoch 5.564), train_loss = 1.65072321, grad/param norm = 1.7067e-01, time/batch = 0.6901s	
3373/30300 (epoch 5.566), train_loss = 1.71758790, grad/param norm = 1.9135e-01, time/batch = 0.6904s	
3374/30300 (epoch 5.568), train_loss = 1.55446108, grad/param norm = 1.8645e-01, time/batch = 0.6882s	
3375/30300 (epoch 5.569), train_loss = 1.68592900, grad/param norm = 1.6947e-01, time/batch = 0.6928s	
3376/30300 (epoch 5.571), train_loss = 1.80501952, grad/param norm = 1.9385e-01, time/batch = 0.7240s	
3377/30300 (epoch 5.573), train_loss = 1.77155257, grad/param norm = 1.8482e-01, time/batch = 0.7046s	
3378/30300 (epoch 5.574), train_loss = 1.71421863, grad/param norm = 1.8374e-01, time/batch = 0.6954s	
3379/30300 (epoch 5.576), train_loss = 1.70711618, grad/param norm = 1.7388e-01, time/batch = 0.6892s	
3380/30300 (epoch 5.578), train_loss = 1.58381600, grad/param norm = 1.6290e-01, time/batch = 0.6880s	
3381/30300 (epoch 5.579), train_loss = 1.69438841, grad/param norm = 1.8403e-01, time/batch = 0.6937s	
3382/30300 (epoch 5.581), train_loss = 1.78247368, grad/param norm = 1.8455e-01, time/batch = 0.6933s	
3383/30300 (epoch 5.583), train_loss = 1.85317602, grad/param norm = 1.8775e-01, time/batch = 0.6909s	
3384/30300 (epoch 5.584), train_loss = 1.81750968, grad/param norm = 1.7214e-01, time/batch = 0.6915s	
3385/30300 (epoch 5.586), train_loss = 1.74851186, grad/param norm = 1.7579e-01, time/batch = 0.6905s	
3386/30300 (epoch 5.587), train_loss = 1.75679539, grad/param norm = 1.8036e-01, time/batch = 0.6877s	
3387/30300 (epoch 5.589), train_loss = 1.45744753, grad/param norm = 1.5952e-01, time/batch = 0.6919s	
3388/30300 (epoch 5.591), train_loss = 1.73723307, grad/param norm = 1.8418e-01, time/batch = 0.6891s	
3389/30300 (epoch 5.592), train_loss = 1.69515749, grad/param norm = 1.7410e-01, time/batch = 0.6928s	
3390/30300 (epoch 5.594), train_loss = 1.73555229, grad/param norm = 1.9178e-01, time/batch = 0.7071s	
3391/30300 (epoch 5.596), train_loss = 1.59293569, grad/param norm = 1.7401e-01, time/batch = 0.7213s	
3392/30300 (epoch 5.597), train_loss = 1.65439991, grad/param norm = 1.8317e-01, time/batch = 0.7100s	
3393/30300 (epoch 5.599), train_loss = 1.47438283, grad/param norm = 1.7108e-01, time/batch = 0.7097s	
3394/30300 (epoch 5.601), train_loss = 1.72478453, grad/param norm = 1.7481e-01, time/batch = 0.7122s	
3395/30300 (epoch 5.602), train_loss = 1.68001963, grad/param norm = 1.6316e-01, time/batch = 0.7045s	
3396/30300 (epoch 5.604), train_loss = 1.60802549, grad/param norm = 1.7609e-01, time/batch = 0.7013s	
3397/30300 (epoch 5.606), train_loss = 1.90683720, grad/param norm = 2.0326e-01, time/batch = 0.7022s	
3398/30300 (epoch 5.607), train_loss = 1.76249980, grad/param norm = 1.7463e-01, time/batch = 0.7185s	
3399/30300 (epoch 5.609), train_loss = 1.98714072, grad/param norm = 1.9751e-01, time/batch = 0.6897s	
3400/30300 (epoch 5.611), train_loss = 1.55842251, grad/param norm = 1.7113e-01, time/batch = 0.7140s	
3401/30300 (epoch 5.612), train_loss = 1.64208758, grad/param norm = 1.7502e-01, time/batch = 0.7089s	
3402/30300 (epoch 5.614), train_loss = 1.52438103, grad/param norm = 1.6420e-01, time/batch = 0.6901s	
3403/30300 (epoch 5.616), train_loss = 1.78496624, grad/param norm = 1.9060e-01, time/batch = 0.6930s	
3404/30300 (epoch 5.617), train_loss = 1.70789373, grad/param norm = 1.8990e-01, time/batch = 0.7021s	
3405/30300 (epoch 5.619), train_loss = 1.50513184, grad/param norm = 1.6639e-01, time/batch = 0.6992s	
3406/30300 (epoch 5.620), train_loss = 1.78416884, grad/param norm = 1.7555e-01, time/batch = 0.6951s	
3407/30300 (epoch 5.622), train_loss = 1.67414072, grad/param norm = 1.9309e-01, time/batch = 0.6880s	
3408/30300 (epoch 5.624), train_loss = 1.60893437, grad/param norm = 1.7100e-01, time/batch = 0.6893s	
3409/30300 (epoch 5.625), train_loss = 1.64190592, grad/param norm = 1.7676e-01, time/batch = 0.6883s	
3410/30300 (epoch 5.627), train_loss = 1.86977218, grad/param norm = 1.9258e-01, time/batch = 0.6927s	
3411/30300 (epoch 5.629), train_loss = 1.77986582, grad/param norm = 1.7486e-01, time/batch = 0.6917s	
3412/30300 (epoch 5.630), train_loss = 1.76339218, grad/param norm = 1.8240e-01, time/batch = 0.6930s	
3413/30300 (epoch 5.632), train_loss = 1.81269108, grad/param norm = 1.8410e-01, time/batch = 0.6909s	
3414/30300 (epoch 5.634), train_loss = 1.49617917, grad/param norm = 1.5622e-01, time/batch = 0.7081s	
3415/30300 (epoch 5.635), train_loss = 1.80427032, grad/param norm = 1.7231e-01, time/batch = 0.7169s	
3416/30300 (epoch 5.637), train_loss = 1.74232186, grad/param norm = 1.9181e-01, time/batch = 0.6871s	
3417/30300 (epoch 5.639), train_loss = 1.62737650, grad/param norm = 2.0272e-01, time/batch = 0.6897s	
3418/30300 (epoch 5.640), train_loss = 1.78460732, grad/param norm = 1.8397e-01, time/batch = 0.7030s	
3419/30300 (epoch 5.642), train_loss = 1.67230044, grad/param norm = 1.8032e-01, time/batch = 0.6888s	
3420/30300 (epoch 5.644), train_loss = 1.76366988, grad/param norm = 1.8658e-01, time/batch = 0.6901s	
3421/30300 (epoch 5.645), train_loss = 1.65416625, grad/param norm = 2.0111e-01, time/batch = 0.6929s	
3422/30300 (epoch 5.647), train_loss = 1.68942739, grad/param norm = 1.7196e-01, time/batch = 0.6899s	
3423/30300 (epoch 5.649), train_loss = 1.65318288, grad/param norm = 1.7038e-01, time/batch = 0.6893s	
3424/30300 (epoch 5.650), train_loss = 1.72232121, grad/param norm = 1.6915e-01, time/batch = 0.6891s	
3425/30300 (epoch 5.652), train_loss = 1.58593841, grad/param norm = 1.7759e-01, time/batch = 0.6911s	
3426/30300 (epoch 5.653), train_loss = 1.87256908, grad/param norm = 1.7813e-01, time/batch = 0.6885s	
3427/30300 (epoch 5.655), train_loss = 1.65735483, grad/param norm = 1.8009e-01, time/batch = 0.6891s	
3428/30300 (epoch 5.657), train_loss = 1.79221696, grad/param norm = 1.8343e-01, time/batch = 0.6916s	
3429/30300 (epoch 5.658), train_loss = 1.64811031, grad/param norm = 1.7904e-01, time/batch = 0.7209s	
3430/30300 (epoch 5.660), train_loss = 1.77251737, grad/param norm = 1.7619e-01, time/batch = 0.6960s	
3431/30300 (epoch 5.662), train_loss = 1.79533707, grad/param norm = 1.9104e-01, time/batch = 0.6912s	
3432/30300 (epoch 5.663), train_loss = 1.69376865, grad/param norm = 1.7208e-01, time/batch = 0.6935s	
3433/30300 (epoch 5.665), train_loss = 1.56308530, grad/param norm = 1.6738e-01, time/batch = 0.6914s	
3434/30300 (epoch 5.667), train_loss = 1.85405806, grad/param norm = 2.0137e-01, time/batch = 0.6962s	
3435/30300 (epoch 5.668), train_loss = 1.91928787, grad/param norm = 1.9661e-01, time/batch = 0.7006s	
3436/30300 (epoch 5.670), train_loss = 1.81190350, grad/param norm = 1.7903e-01, time/batch = 0.6916s	
3437/30300 (epoch 5.672), train_loss = 1.79578924, grad/param norm = 1.8298e-01, time/batch = 0.6968s	
3438/30300 (epoch 5.673), train_loss = 1.78840732, grad/param norm = 1.8225e-01, time/batch = 0.6909s	
3439/30300 (epoch 5.675), train_loss = 1.61943093, grad/param norm = 1.7381e-01, time/batch = 0.6910s	
3440/30300 (epoch 5.677), train_loss = 1.60365106, grad/param norm = 1.6998e-01, time/batch = 0.6901s	
3441/30300 (epoch 5.678), train_loss = 1.62206801, grad/param norm = 1.5983e-01, time/batch = 0.6928s	
3442/30300 (epoch 5.680), train_loss = 1.44007279, grad/param norm = 1.9620e-01, time/batch = 0.6906s	
3443/30300 (epoch 5.682), train_loss = 1.70149743, grad/param norm = 2.2241e-01, time/batch = 0.7161s	
3444/30300 (epoch 5.683), train_loss = 1.76875149, grad/param norm = 1.7756e-01, time/batch = 0.7086s	
3445/30300 (epoch 5.685), train_loss = 1.88998898, grad/param norm = 1.9741e-01, time/batch = 0.6898s	
3446/30300 (epoch 5.686), train_loss = 1.74817474, grad/param norm = 1.8417e-01, time/batch = 0.6939s	
3447/30300 (epoch 5.688), train_loss = 1.70280230, grad/param norm = 1.8172e-01, time/batch = 0.6898s	
3448/30300 (epoch 5.690), train_loss = 1.68787137, grad/param norm = 1.8646e-01, time/batch = 0.6901s	
3449/30300 (epoch 5.691), train_loss = 1.71190899, grad/param norm = 1.8832e-01, time/batch = 0.6926s	
3450/30300 (epoch 5.693), train_loss = 2.10200621, grad/param norm = 2.1172e-01, time/batch = 0.6934s	
3451/30300 (epoch 5.695), train_loss = 1.88388261, grad/param norm = 2.0228e-01, time/batch = 0.6912s	
3452/30300 (epoch 5.696), train_loss = 1.94638519, grad/param norm = 2.1712e-01, time/batch = 0.6899s	
3453/30300 (epoch 5.698), train_loss = 1.60924857, grad/param norm = 1.7712e-01, time/batch = 0.6936s	
3454/30300 (epoch 5.700), train_loss = 1.68576878, grad/param norm = 1.8326e-01, time/batch = 0.6986s	
3455/30300 (epoch 5.701), train_loss = 1.47623010, grad/param norm = 1.5304e-01, time/batch = 0.7014s	
3456/30300 (epoch 5.703), train_loss = 1.65543687, grad/param norm = 1.6235e-01, time/batch = 0.6988s	
3457/30300 (epoch 5.705), train_loss = 1.71937698, grad/param norm = 1.9613e-01, time/batch = 0.7153s	
3458/30300 (epoch 5.706), train_loss = 1.69806277, grad/param norm = 1.7376e-01, time/batch = 0.7168s	
3459/30300 (epoch 5.708), train_loss = 1.64081711, grad/param norm = 1.8263e-01, time/batch = 0.6892s	
3460/30300 (epoch 5.710), train_loss = 1.66835219, grad/param norm = 1.8576e-01, time/batch = 0.6927s	
3461/30300 (epoch 5.711), train_loss = 1.58192088, grad/param norm = 1.7802e-01, time/batch = 0.6998s	
3462/30300 (epoch 5.713), train_loss = 1.52102814, grad/param norm = 1.5863e-01, time/batch = 0.6885s	
3463/30300 (epoch 5.715), train_loss = 1.67404101, grad/param norm = 1.7663e-01, time/batch = 0.6882s	
3464/30300 (epoch 5.716), train_loss = 1.86637204, grad/param norm = 1.8127e-01, time/batch = 0.6906s	
3465/30300 (epoch 5.718), train_loss = 1.79411913, grad/param norm = 1.9319e-01, time/batch = 0.6886s	
3466/30300 (epoch 5.719), train_loss = 1.68249781, grad/param norm = 1.8110e-01, time/batch = 0.6870s	
3467/30300 (epoch 5.721), train_loss = 1.68426698, grad/param norm = 1.7350e-01, time/batch = 0.6896s	
3468/30300 (epoch 5.723), train_loss = 1.64393712, grad/param norm = 1.7699e-01, time/batch = 0.6912s	
3469/30300 (epoch 5.724), train_loss = 1.77022985, grad/param norm = 1.7785e-01, time/batch = 0.6904s	
3470/30300 (epoch 5.726), train_loss = 2.12442755, grad/param norm = 2.0437e-01, time/batch = 0.6946s	
3471/30300 (epoch 5.728), train_loss = 1.68537460, grad/param norm = 1.7772e-01, time/batch = 0.7026s	
3472/30300 (epoch 5.729), train_loss = 1.70601425, grad/param norm = 1.7430e-01, time/batch = 0.7214s	
3473/30300 (epoch 5.731), train_loss = 1.80653791, grad/param norm = 1.8958e-01, time/batch = 0.6971s	
3474/30300 (epoch 5.733), train_loss = 1.69689307, grad/param norm = 1.7204e-01, time/batch = 0.6884s	
3475/30300 (epoch 5.734), train_loss = 1.71841164, grad/param norm = 1.6910e-01, time/batch = 0.6910s	
3476/30300 (epoch 5.736), train_loss = 1.64999197, grad/param norm = 1.6218e-01, time/batch = 0.6910s	
3477/30300 (epoch 5.738), train_loss = 1.50465562, grad/param norm = 1.5814e-01, time/batch = 0.7101s	
3478/30300 (epoch 5.739), train_loss = 1.78323892, grad/param norm = 1.7387e-01, time/batch = 0.7042s	
3479/30300 (epoch 5.741), train_loss = 1.77446931, grad/param norm = 1.7157e-01, time/batch = 0.7111s	
3480/30300 (epoch 5.743), train_loss = 1.58951131, grad/param norm = 1.7057e-01, time/batch = 0.6955s	
3481/30300 (epoch 5.744), train_loss = 1.81420095, grad/param norm = 1.8682e-01, time/batch = 0.6889s	
3482/30300 (epoch 5.746), train_loss = 1.51044106, grad/param norm = 1.7195e-01, time/batch = 0.6908s	
3483/30300 (epoch 5.748), train_loss = 1.72467446, grad/param norm = 1.8537e-01, time/batch = 0.6885s	
3484/30300 (epoch 5.749), train_loss = 1.70358242, grad/param norm = 1.7088e-01, time/batch = 0.6951s	
3485/30300 (epoch 5.751), train_loss = 1.58147360, grad/param norm = 1.8013e-01, time/batch = 0.6888s	
3486/30300 (epoch 5.752), train_loss = 1.64770385, grad/param norm = 1.7530e-01, time/batch = 0.7137s	
3487/30300 (epoch 5.754), train_loss = 1.47996656, grad/param norm = 1.5945e-01, time/batch = 0.6990s	
3488/30300 (epoch 5.756), train_loss = 1.61985969, grad/param norm = 1.8721e-01, time/batch = 0.6921s	
3489/30300 (epoch 5.757), train_loss = 1.72264397, grad/param norm = 1.8044e-01, time/batch = 0.6906s	
3490/30300 (epoch 5.759), train_loss = 1.59076821, grad/param norm = 1.8228e-01, time/batch = 0.6892s	
3491/30300 (epoch 5.761), train_loss = 1.55293688, grad/param norm = 1.7534e-01, time/batch = 0.7106s	
3492/30300 (epoch 5.762), train_loss = 1.45789673, grad/param norm = 1.5878e-01, time/batch = 0.6999s	
3493/30300 (epoch 5.764), train_loss = 1.64813644, grad/param norm = 1.8738e-01, time/batch = 0.6959s	
3494/30300 (epoch 5.766), train_loss = 1.71118835, grad/param norm = 1.7008e-01, time/batch = 0.6907s	
3495/30300 (epoch 5.767), train_loss = 1.81592603, grad/param norm = 1.9114e-01, time/batch = 0.6878s	
3496/30300 (epoch 5.769), train_loss = 1.84664355, grad/param norm = 2.0125e-01, time/batch = 0.6913s	
3497/30300 (epoch 5.771), train_loss = 1.70277709, grad/param norm = 1.7378e-01, time/batch = 0.7001s	
3498/30300 (epoch 5.772), train_loss = 1.67241170, grad/param norm = 1.8460e-01, time/batch = 0.6897s	
3499/30300 (epoch 5.774), train_loss = 1.76854334, grad/param norm = 1.8034e-01, time/batch = 0.6912s	
3500/30300 (epoch 5.776), train_loss = 1.70188842, grad/param norm = 1.8531e-01, time/batch = 0.7124s	
3501/30300 (epoch 5.777), train_loss = 1.70429238, grad/param norm = 1.7281e-01, time/batch = 0.7244s	
3502/30300 (epoch 5.779), train_loss = 1.78279989, grad/param norm = 1.7168e-01, time/batch = 0.7069s	
3503/30300 (epoch 5.781), train_loss = 1.68481978, grad/param norm = 1.8551e-01, time/batch = 0.7099s	
3504/30300 (epoch 5.782), train_loss = 1.60581448, grad/param norm = 1.6792e-01, time/batch = 0.7071s	
3505/30300 (epoch 5.784), train_loss = 1.67037528, grad/param norm = 1.6824e-01, time/batch = 0.7020s	
3506/30300 (epoch 5.785), train_loss = 1.87268679, grad/param norm = 1.8704e-01, time/batch = 0.7167s	
3507/30300 (epoch 5.787), train_loss = 1.59966854, grad/param norm = 1.8540e-01, time/batch = 0.7097s	
3508/30300 (epoch 5.789), train_loss = 2.03252020, grad/param norm = 1.8300e-01, time/batch = 0.7083s	
3509/30300 (epoch 5.790), train_loss = 1.80118981, grad/param norm = 1.7595e-01, time/batch = 0.6992s	
3510/30300 (epoch 5.792), train_loss = 1.61052759, grad/param norm = 1.8703e-01, time/batch = 0.6920s	
3511/30300 (epoch 5.794), train_loss = 1.60248362, grad/param norm = 1.6757e-01, time/batch = 0.6904s	
3512/30300 (epoch 5.795), train_loss = 1.67271097, grad/param norm = 1.6901e-01, time/batch = 0.6875s	
3513/30300 (epoch 5.797), train_loss = 1.81485392, grad/param norm = 2.0278e-01, time/batch = 0.6901s	
3514/30300 (epoch 5.799), train_loss = 1.81302607, grad/param norm = 2.0724e-01, time/batch = 0.7071s	
3515/30300 (epoch 5.800), train_loss = 1.71229188, grad/param norm = 2.0113e-01, time/batch = 0.7217s	
3516/30300 (epoch 5.802), train_loss = 1.91673410, grad/param norm = 1.9700e-01, time/batch = 0.6843s	
3517/30300 (epoch 5.804), train_loss = 1.77707838, grad/param norm = 2.2721e-01, time/batch = 0.6867s	
3518/30300 (epoch 5.805), train_loss = 1.88712551, grad/param norm = 1.9540e-01, time/batch = 0.6891s	
3519/30300 (epoch 5.807), train_loss = 1.77164729, grad/param norm = 1.9421e-01, time/batch = 0.6847s	
3520/30300 (epoch 5.809), train_loss = 1.84008809, grad/param norm = 1.8382e-01, time/batch = 0.6914s	
3521/30300 (epoch 5.810), train_loss = 1.78993035, grad/param norm = 1.8093e-01, time/batch = 0.6930s	
3522/30300 (epoch 5.812), train_loss = 1.62389317, grad/param norm = 1.7076e-01, time/batch = 0.6883s	
3523/30300 (epoch 5.814), train_loss = 1.72643224, grad/param norm = 1.7660e-01, time/batch = 0.6948s	
3524/30300 (epoch 5.815), train_loss = 1.71358988, grad/param norm = 1.8557e-01, time/batch = 0.6987s	
3525/30300 (epoch 5.817), train_loss = 1.83566033, grad/param norm = 1.8475e-01, time/batch = 0.6957s	
3526/30300 (epoch 5.818), train_loss = 1.72773191, grad/param norm = 1.8433e-01, time/batch = 0.6930s	
3527/30300 (epoch 5.820), train_loss = 1.96228414, grad/param norm = 1.8545e-01, time/batch = 0.6900s	
3528/30300 (epoch 5.822), train_loss = 1.92971362, grad/param norm = 1.9177e-01, time/batch = 0.6925s	
3529/30300 (epoch 5.823), train_loss = 1.98269466, grad/param norm = 1.9805e-01, time/batch = 0.7207s	
3530/30300 (epoch 5.825), train_loss = 1.81778787, grad/param norm = 1.9972e-01, time/batch = 0.7001s	
3531/30300 (epoch 5.827), train_loss = 1.66704357, grad/param norm = 1.9001e-01, time/batch = 0.6898s	
3532/30300 (epoch 5.828), train_loss = 1.74397005, grad/param norm = 1.6040e-01, time/batch = 0.6974s	
3533/30300 (epoch 5.830), train_loss = 1.72861070, grad/param norm = 1.8139e-01, time/batch = 0.7068s	
3534/30300 (epoch 5.832), train_loss = 1.67533838, grad/param norm = 1.6508e-01, time/batch = 0.7193s	
3535/30300 (epoch 5.833), train_loss = 1.82144153, grad/param norm = 1.8101e-01, time/batch = 0.7199s	
3536/30300 (epoch 5.835), train_loss = 1.71989411, grad/param norm = 1.7894e-01, time/batch = 0.7204s	
3537/30300 (epoch 5.837), train_loss = 1.51422344, grad/param norm = 1.5371e-01, time/batch = 0.7177s	
3538/30300 (epoch 5.838), train_loss = 1.58789764, grad/param norm = 1.7706e-01, time/batch = 0.7172s	
3539/30300 (epoch 5.840), train_loss = 1.67492763, grad/param norm = 1.6698e-01, time/batch = 0.7145s	
3540/30300 (epoch 5.842), train_loss = 1.53220220, grad/param norm = 1.5408e-01, time/batch = 0.6963s	
3541/30300 (epoch 5.843), train_loss = 1.68670470, grad/param norm = 1.7640e-01, time/batch = 0.6931s	
3542/30300 (epoch 5.845), train_loss = 1.58441188, grad/param norm = 1.5061e-01, time/batch = 0.6944s	
3543/30300 (epoch 5.847), train_loss = 1.73841597, grad/param norm = 1.9873e-01, time/batch = 0.6925s	
3544/30300 (epoch 5.848), train_loss = 1.85303899, grad/param norm = 1.7911e-01, time/batch = 0.6937s	
3545/30300 (epoch 5.850), train_loss = 1.61865310, grad/param norm = 1.6447e-01, time/batch = 0.6901s	
3546/30300 (epoch 5.851), train_loss = 1.96175605, grad/param norm = 2.0531e-01, time/batch = 0.6938s	
3547/30300 (epoch 5.853), train_loss = 1.65653277, grad/param norm = 1.7936e-01, time/batch = 0.6944s	
3548/30300 (epoch 5.855), train_loss = 1.62743015, grad/param norm = 1.8413e-01, time/batch = 0.6914s	
3549/30300 (epoch 5.856), train_loss = 1.61618282, grad/param norm = 1.7439e-01, time/batch = 0.6928s	
3550/30300 (epoch 5.858), train_loss = 1.61335334, grad/param norm = 1.6939e-01, time/batch = 0.6940s	
3551/30300 (epoch 5.860), train_loss = 1.70107185, grad/param norm = 1.7315e-01, time/batch = 0.6920s	
3552/30300 (epoch 5.861), train_loss = 1.86560590, grad/param norm = 1.8121e-01, time/batch = 0.6936s	
3553/30300 (epoch 5.863), train_loss = 1.75577441, grad/param norm = 1.8163e-01, time/batch = 0.6919s	
3554/30300 (epoch 5.865), train_loss = 1.97901592, grad/param norm = 1.8998e-01, time/batch = 0.6947s	
3555/30300 (epoch 5.866), train_loss = 1.77331242, grad/param norm = 1.7796e-01, time/batch = 0.7213s	
3556/30300 (epoch 5.868), train_loss = 1.72246688, grad/param norm = 1.7136e-01, time/batch = 0.7158s	
3557/30300 (epoch 5.870), train_loss = 1.66157211, grad/param norm = 1.7266e-01, time/batch = 0.7214s	
3558/30300 (epoch 5.871), train_loss = 1.58951302, grad/param norm = 1.6317e-01, time/batch = 0.7202s	
3559/30300 (epoch 5.873), train_loss = 1.73542945, grad/param norm = 1.6783e-01, time/batch = 0.7170s	
3560/30300 (epoch 5.875), train_loss = 1.52695213, grad/param norm = 1.6242e-01, time/batch = 0.7241s	
3561/30300 (epoch 5.876), train_loss = 1.50609394, grad/param norm = 1.5573e-01, time/batch = 0.7345s	
3562/30300 (epoch 5.878), train_loss = 1.46409956, grad/param norm = 1.6962e-01, time/batch = 0.7404s	
3563/30300 (epoch 5.880), train_loss = 1.56199653, grad/param norm = 1.6532e-01, time/batch = 0.7415s	
3564/30300 (epoch 5.881), train_loss = 1.89009334, grad/param norm = 1.7279e-01, time/batch = 0.7423s	
3565/30300 (epoch 5.883), train_loss = 1.76854972, grad/param norm = 1.8794e-01, time/batch = 0.7347s	
3566/30300 (epoch 5.884), train_loss = 1.56205600, grad/param norm = 1.7862e-01, time/batch = 0.7252s	
3567/30300 (epoch 5.886), train_loss = 1.63970914, grad/param norm = 1.6750e-01, time/batch = 0.7259s	
3568/30300 (epoch 5.888), train_loss = 1.74354195, grad/param norm = 1.7865e-01, time/batch = 0.7288s	
3569/30300 (epoch 5.889), train_loss = 1.64647778, grad/param norm = 1.8593e-01, time/batch = 0.7425s	
3570/30300 (epoch 5.891), train_loss = 1.59376755, grad/param norm = 1.7576e-01, time/batch = 0.6991s	
3571/30300 (epoch 5.893), train_loss = 1.93506757, grad/param norm = 2.0263e-01, time/batch = 0.6977s	
3572/30300 (epoch 5.894), train_loss = 1.77466200, grad/param norm = 1.7454e-01, time/batch = 0.6878s	
3573/30300 (epoch 5.896), train_loss = 1.48899842, grad/param norm = 1.8689e-01, time/batch = 0.6869s	
3574/30300 (epoch 5.898), train_loss = 1.49585482, grad/param norm = 1.7930e-01, time/batch = 0.6898s	
3575/30300 (epoch 5.899), train_loss = 1.62793231, grad/param norm = 1.7199e-01, time/batch = 0.6957s	
3576/30300 (epoch 5.901), train_loss = 1.70164229, grad/param norm = 1.7381e-01, time/batch = 0.6945s	
3577/30300 (epoch 5.903), train_loss = 1.74960284, grad/param norm = 1.9103e-01, time/batch = 0.6958s	
3578/30300 (epoch 5.904), train_loss = 1.64858117, grad/param norm = 1.6068e-01, time/batch = 0.6896s	
3579/30300 (epoch 5.906), train_loss = 1.81407758, grad/param norm = 1.7231e-01, time/batch = 0.6910s	
3580/30300 (epoch 5.908), train_loss = 1.58877591, grad/param norm = 1.6934e-01, time/batch = 0.6895s	
3581/30300 (epoch 5.909), train_loss = 1.67746078, grad/param norm = 1.8331e-01, time/batch = 0.7054s	
3582/30300 (epoch 5.911), train_loss = 1.67443042, grad/param norm = 1.7889e-01, time/batch = 0.6969s	
3583/30300 (epoch 5.913), train_loss = 1.70601263, grad/param norm = 1.8947e-01, time/batch = 0.6880s	
3584/30300 (epoch 5.914), train_loss = 1.68662551, grad/param norm = 1.9539e-01, time/batch = 0.6901s	
3585/30300 (epoch 5.916), train_loss = 1.71261643, grad/param norm = 1.6604e-01, time/batch = 0.6896s	
3586/30300 (epoch 5.917), train_loss = 1.60389591, grad/param norm = 1.6330e-01, time/batch = 0.6896s	
3587/30300 (epoch 5.919), train_loss = 1.72152280, grad/param norm = 1.7010e-01, time/batch = 0.6896s	
3588/30300 (epoch 5.921), train_loss = 1.75064596, grad/param norm = 1.7802e-01, time/batch = 0.6900s	
3589/30300 (epoch 5.922), train_loss = 1.79336925, grad/param norm = 1.8162e-01, time/batch = 0.6945s	
3590/30300 (epoch 5.924), train_loss = 1.68155503, grad/param norm = 1.8334e-01, time/batch = 0.6876s	
3591/30300 (epoch 5.926), train_loss = 1.66616843, grad/param norm = 1.7938e-01, time/batch = 0.6929s	
3592/30300 (epoch 5.927), train_loss = 1.66878262, grad/param norm = 1.8625e-01, time/batch = 0.6946s	
3593/30300 (epoch 5.929), train_loss = 1.68513446, grad/param norm = 1.8023e-01, time/batch = 0.6889s	
3594/30300 (epoch 5.931), train_loss = 1.79887814, grad/param norm = 1.9483e-01, time/batch = 0.6883s	
3595/30300 (epoch 5.932), train_loss = 1.60714171, grad/param norm = 1.8702e-01, time/batch = 0.6927s	
3596/30300 (epoch 5.934), train_loss = 1.67757662, grad/param norm = 1.6897e-01, time/batch = 0.6928s	
3597/30300 (epoch 5.936), train_loss = 1.63938655, grad/param norm = 1.7032e-01, time/batch = 0.6924s	
3598/30300 (epoch 5.937), train_loss = 1.68645658, grad/param norm = 1.6784e-01, time/batch = 0.6896s	
3599/30300 (epoch 5.939), train_loss = 1.83058047, grad/param norm = 1.7010e-01, time/batch = 0.6883s	
3600/30300 (epoch 5.941), train_loss = 1.70537962, grad/param norm = 1.7555e-01, time/batch = 0.7132s	
3601/30300 (epoch 5.942), train_loss = 1.64180245, grad/param norm = 1.7428e-01, time/batch = 0.7031s	
3602/30300 (epoch 5.944), train_loss = 1.53709533, grad/param norm = 1.5524e-01, time/batch = 0.6975s	
3603/30300 (epoch 5.946), train_loss = 1.86831204, grad/param norm = 2.0188e-01, time/batch = 0.6939s	
3604/30300 (epoch 5.947), train_loss = 1.90948813, grad/param norm = 1.9984e-01, time/batch = 0.6926s	
3605/30300 (epoch 5.949), train_loss = 1.95550470, grad/param norm = 1.9912e-01, time/batch = 0.6922s	
3606/30300 (epoch 5.950), train_loss = 1.82726077, grad/param norm = 1.8168e-01, time/batch = 0.6914s	
3607/30300 (epoch 5.952), train_loss = 1.83740145, grad/param norm = 1.8181e-01, time/batch = 0.7051s	
3608/30300 (epoch 5.954), train_loss = 1.96025202, grad/param norm = 1.8380e-01, time/batch = 0.6879s	
3609/30300 (epoch 5.955), train_loss = 1.62281814, grad/param norm = 1.7213e-01, time/batch = 0.6923s	
3610/30300 (epoch 5.957), train_loss = 1.75774254, grad/param norm = 1.7390e-01, time/batch = 0.7209s	
3611/30300 (epoch 5.959), train_loss = 1.73675848, grad/param norm = 1.7711e-01, time/batch = 0.6947s	
3612/30300 (epoch 5.960), train_loss = 1.66949055, grad/param norm = 1.6437e-01, time/batch = 0.6941s	
3613/30300 (epoch 5.962), train_loss = 1.64642542, grad/param norm = 1.9052e-01, time/batch = 0.7172s	
3614/30300 (epoch 5.964), train_loss = 1.73221038, grad/param norm = 1.8813e-01, time/batch = 0.6906s	
3615/30300 (epoch 5.965), train_loss = 1.62130464, grad/param norm = 1.7157e-01, time/batch = 0.6891s	
3616/30300 (epoch 5.967), train_loss = 1.71893988, grad/param norm = 1.7232e-01, time/batch = 0.6862s	
3617/30300 (epoch 5.969), train_loss = 1.69201284, grad/param norm = 2.4280e-01, time/batch = 0.6933s	
3618/30300 (epoch 5.970), train_loss = 1.61528489, grad/param norm = 1.7219e-01, time/batch = 0.6908s	
3619/30300 (epoch 5.972), train_loss = 1.59112205, grad/param norm = 1.7072e-01, time/batch = 0.6891s	
3620/30300 (epoch 5.974), train_loss = 1.88432580, grad/param norm = 1.8466e-01, time/batch = 0.6893s	
3621/30300 (epoch 5.975), train_loss = 1.90637009, grad/param norm = 2.0056e-01, time/batch = 0.7003s	
3622/30300 (epoch 5.977), train_loss = 1.74412672, grad/param norm = 1.7403e-01, time/batch = 0.6888s	
3623/30300 (epoch 5.979), train_loss = 1.76005470, grad/param norm = 1.7248e-01, time/batch = 0.6885s	
3624/30300 (epoch 5.980), train_loss = 1.75734100, grad/param norm = 1.9242e-01, time/batch = 0.6894s	
3625/30300 (epoch 5.982), train_loss = 1.76779747, grad/param norm = 1.6624e-01, time/batch = 0.6943s	
3626/30300 (epoch 5.983), train_loss = 1.84702120, grad/param norm = 1.9211e-01, time/batch = 0.6850s	
3627/30300 (epoch 5.985), train_loss = 1.71200835, grad/param norm = 1.7858e-01, time/batch = 0.6902s	
3628/30300 (epoch 5.987), train_loss = 1.63092966, grad/param norm = 1.5496e-01, time/batch = 0.7000s	
3629/30300 (epoch 5.988), train_loss = 1.85367223, grad/param norm = 1.9641e-01, time/batch = 0.6948s	
3630/30300 (epoch 5.990), train_loss = 1.51736189, grad/param norm = 1.6102e-01, time/batch = 0.6892s	
3631/30300 (epoch 5.992), train_loss = 1.72575010, grad/param norm = 1.5322e-01, time/batch = 0.6903s	
3632/30300 (epoch 5.993), train_loss = 1.88568235, grad/param norm = 1.9369e-01, time/batch = 0.6942s	
3633/30300 (epoch 5.995), train_loss = 1.79878293, grad/param norm = 1.7908e-01, time/batch = 0.6891s	
3634/30300 (epoch 5.997), train_loss = 1.73520143, grad/param norm = 1.7099e-01, time/batch = 0.6862s	
3635/30300 (epoch 5.998), train_loss = 1.82129943, grad/param norm = 1.9606e-01, time/batch = 0.6875s	
3636/30300 (epoch 6.000), train_loss = 1.63397958, grad/param norm = 1.8713e-01, time/batch = 0.6881s	
3637/30300 (epoch 6.002), train_loss = 1.67926620, grad/param norm = 1.7132e-01, time/batch = 0.6838s	
3638/30300 (epoch 6.003), train_loss = 1.72999308, grad/param norm = 1.7988e-01, time/batch = 0.6877s	
3639/30300 (epoch 6.005), train_loss = 1.70927867, grad/param norm = 1.8483e-01, time/batch = 0.6854s	
3640/30300 (epoch 6.007), train_loss = 1.82187177, grad/param norm = 1.6559e-01, time/batch = 0.6936s	
3641/30300 (epoch 6.008), train_loss = 1.63548272, grad/param norm = 1.7281e-01, time/batch = 0.6839s	
3642/30300 (epoch 6.010), train_loss = 1.65698165, grad/param norm = 1.9073e-01, time/batch = 0.6950s	
3643/30300 (epoch 6.012), train_loss = 1.60933033, grad/param norm = 1.6872e-01, time/batch = 0.7212s	
3644/30300 (epoch 6.013), train_loss = 1.73916122, grad/param norm = 1.8420e-01, time/batch = 0.6926s	
3645/30300 (epoch 6.015), train_loss = 1.64417789, grad/param norm = 1.7555e-01, time/batch = 0.6855s	
3646/30300 (epoch 6.017), train_loss = 1.55135986, grad/param norm = 1.7650e-01, time/batch = 0.6915s	
3647/30300 (epoch 6.018), train_loss = 1.72106061, grad/param norm = 1.6689e-01, time/batch = 0.6927s	
3648/30300 (epoch 6.020), train_loss = 1.86437380, grad/param norm = 1.7613e-01, time/batch = 0.7100s	
3649/30300 (epoch 6.021), train_loss = 1.85914400, grad/param norm = 1.8342e-01, time/batch = 0.6936s	
3650/30300 (epoch 6.023), train_loss = 1.59189382, grad/param norm = 1.8085e-01, time/batch = 0.6997s	
3651/30300 (epoch 6.025), train_loss = 1.62808008, grad/param norm = 1.8889e-01, time/batch = 0.6945s	
3652/30300 (epoch 6.026), train_loss = 1.71324844, grad/param norm = 1.7237e-01, time/batch = 0.6896s	
3653/30300 (epoch 6.028), train_loss = 1.69302625, grad/param norm = 1.7416e-01, time/batch = 0.6956s	
3654/30300 (epoch 6.030), train_loss = 1.54977711, grad/param norm = 1.7831e-01, time/batch = 0.6923s	
3655/30300 (epoch 6.031), train_loss = 1.67995133, grad/param norm = 1.9094e-01, time/batch = 0.6966s	
3656/30300 (epoch 6.033), train_loss = 1.67210806, grad/param norm = 1.8187e-01, time/batch = 0.7033s	
3657/30300 (epoch 6.035), train_loss = 1.74805757, grad/param norm = 1.7017e-01, time/batch = 0.6908s	
3658/30300 (epoch 6.036), train_loss = 1.78666499, grad/param norm = 1.7940e-01, time/batch = 0.6894s	
3659/30300 (epoch 6.038), train_loss = 1.68570875, grad/param norm = 1.7233e-01, time/batch = 0.6885s	
3660/30300 (epoch 6.040), train_loss = 1.38543299, grad/param norm = 1.6197e-01, time/batch = 0.7016s	
3661/30300 (epoch 6.041), train_loss = 1.44254433, grad/param norm = 1.6929e-01, time/batch = 0.7087s	
3662/30300 (epoch 6.043), train_loss = 1.77299956, grad/param norm = 1.6637e-01, time/batch = 0.6961s	
3663/30300 (epoch 6.045), train_loss = 1.63177837, grad/param norm = 1.7680e-01, time/batch = 0.6948s	
3664/30300 (epoch 6.046), train_loss = 1.74854466, grad/param norm = 1.8601e-01, time/batch = 0.6995s	
3665/30300 (epoch 6.048), train_loss = 1.71923925, grad/param norm = 1.8692e-01, time/batch = 0.6990s	
3666/30300 (epoch 6.050), train_loss = 1.76365410, grad/param norm = 1.8142e-01, time/batch = 0.6891s	
3667/30300 (epoch 6.051), train_loss = 1.68836869, grad/param norm = 1.6256e-01, time/batch = 0.7002s	
3668/30300 (epoch 6.053), train_loss = 1.58916921, grad/param norm = 1.7899e-01, time/batch = 0.7057s	
3669/30300 (epoch 6.054), train_loss = 1.60824924, grad/param norm = 1.8592e-01, time/batch = 0.6983s	
3670/30300 (epoch 6.056), train_loss = 1.56680550, grad/param norm = 1.7870e-01, time/batch = 0.6915s	
3671/30300 (epoch 6.058), train_loss = 1.71053868, grad/param norm = 1.8253e-01, time/batch = 0.6928s	
3672/30300 (epoch 6.059), train_loss = 1.67468008, grad/param norm = 1.7540e-01, time/batch = 0.6897s	
3673/30300 (epoch 6.061), train_loss = 1.86810848, grad/param norm = 1.8677e-01, time/batch = 0.6881s	
3674/30300 (epoch 6.063), train_loss = 1.65545431, grad/param norm = 1.7143e-01, time/batch = 0.6894s	
3675/30300 (epoch 6.064), train_loss = 1.79431459, grad/param norm = 1.8111e-01, time/batch = 0.6911s	
3676/30300 (epoch 6.066), train_loss = 1.67005017, grad/param norm = 1.6777e-01, time/batch = 0.6911s	
3677/30300 (epoch 6.068), train_loss = 1.55393973, grad/param norm = 1.5942e-01, time/batch = 0.6895s	
3678/30300 (epoch 6.069), train_loss = 1.80354184, grad/param norm = 1.7717e-01, time/batch = 0.6927s	
3679/30300 (epoch 6.071), train_loss = 1.75416954, grad/param norm = 1.9969e-01, time/batch = 0.6874s	
3680/30300 (epoch 6.073), train_loss = 1.79918261, grad/param norm = 2.0115e-01, time/batch = 0.6879s	
3681/30300 (epoch 6.074), train_loss = 1.73157415, grad/param norm = 1.7175e-01, time/batch = 0.6904s	
3682/30300 (epoch 6.076), train_loss = 1.66062788, grad/param norm = 1.6255e-01, time/batch = 0.6889s	
3683/30300 (epoch 6.078), train_loss = 1.56061426, grad/param norm = 1.8601e-01, time/batch = 0.6938s	
3684/30300 (epoch 6.079), train_loss = 1.54769696, grad/param norm = 1.5133e-01, time/batch = 0.6882s	
3685/30300 (epoch 6.081), train_loss = 1.79308344, grad/param norm = 1.9092e-01, time/batch = 0.6995s	
3686/30300 (epoch 6.083), train_loss = 1.90180998, grad/param norm = 1.9847e-01, time/batch = 0.6972s	
3687/30300 (epoch 6.084), train_loss = 1.62280064, grad/param norm = 1.8982e-01, time/batch = 0.7076s	
3688/30300 (epoch 6.086), train_loss = 1.66995862, grad/param norm = 1.7517e-01, time/batch = 0.6973s	
3689/30300 (epoch 6.087), train_loss = 1.55272887, grad/param norm = 1.5522e-01, time/batch = 0.6971s	
3690/30300 (epoch 6.089), train_loss = 1.65561198, grad/param norm = 1.8294e-01, time/batch = 0.6917s	
3691/30300 (epoch 6.091), train_loss = 1.80407469, grad/param norm = 1.9501e-01, time/batch = 0.6906s	
3692/30300 (epoch 6.092), train_loss = 1.61568317, grad/param norm = 1.7380e-01, time/batch = 0.6940s	
3693/30300 (epoch 6.094), train_loss = 1.91602247, grad/param norm = 1.8298e-01, time/batch = 0.6924s	
3694/30300 (epoch 6.096), train_loss = 1.69718727, grad/param norm = 1.7848e-01, time/batch = 0.6903s	
3695/30300 (epoch 6.097), train_loss = 1.53264723, grad/param norm = 1.8288e-01, time/batch = 0.6890s	
3696/30300 (epoch 6.099), train_loss = 1.84805069, grad/param norm = 1.7105e-01, time/batch = 0.6928s	
3697/30300 (epoch 6.101), train_loss = 1.96154056, grad/param norm = 1.8229e-01, time/batch = 0.6917s	
3698/30300 (epoch 6.102), train_loss = 1.74250628, grad/param norm = 1.9794e-01, time/batch = 0.6907s	
3699/30300 (epoch 6.104), train_loss = 1.61147474, grad/param norm = 1.7721e-01, time/batch = 0.6953s	
3700/30300 (epoch 6.106), train_loss = 1.73740404, grad/param norm = 1.9285e-01, time/batch = 0.7050s	
3701/30300 (epoch 6.107), train_loss = 1.67721643, grad/param norm = 1.7272e-01, time/batch = 0.6943s	
3702/30300 (epoch 6.109), train_loss = 1.83029556, grad/param norm = 1.8960e-01, time/batch = 0.6885s	
3703/30300 (epoch 6.111), train_loss = 1.81761460, grad/param norm = 1.9401e-01, time/batch = 0.6892s	
3704/30300 (epoch 6.112), train_loss = 1.70869569, grad/param norm = 1.6508e-01, time/batch = 0.7112s	
3705/30300 (epoch 6.114), train_loss = 1.65463352, grad/param norm = 1.6918e-01, time/batch = 0.6875s	
3706/30300 (epoch 6.116), train_loss = 1.73674383, grad/param norm = 1.6614e-01, time/batch = 0.6893s	
3707/30300 (epoch 6.117), train_loss = 1.66746250, grad/param norm = 1.6334e-01, time/batch = 0.6901s	
3708/30300 (epoch 6.119), train_loss = 1.57077958, grad/param norm = 1.7602e-01, time/batch = 0.6869s	
3709/30300 (epoch 6.120), train_loss = 1.67643761, grad/param norm = 1.7351e-01, time/batch = 0.6878s	
3710/30300 (epoch 6.122), train_loss = 1.76968638, grad/param norm = 1.6885e-01, time/batch = 0.6882s	
3711/30300 (epoch 6.124), train_loss = 1.92345570, grad/param norm = 2.0964e-01, time/batch = 0.6926s	
3712/30300 (epoch 6.125), train_loss = 1.53393903, grad/param norm = 1.6578e-01, time/batch = 0.6943s	
3713/30300 (epoch 6.127), train_loss = 1.72653531, grad/param norm = 1.7881e-01, time/batch = 0.6908s	
3714/30300 (epoch 6.129), train_loss = 1.83458372, grad/param norm = 1.7742e-01, time/batch = 0.6957s	
3715/30300 (epoch 6.130), train_loss = 1.81384988, grad/param norm = 1.7945e-01, time/batch = 0.6872s	
3716/30300 (epoch 6.132), train_loss = 1.70962715, grad/param norm = 1.9111e-01, time/batch = 0.6888s	
3717/30300 (epoch 6.134), train_loss = 1.56640071, grad/param norm = 1.8538e-01, time/batch = 0.6840s	
3718/30300 (epoch 6.135), train_loss = 1.68481527, grad/param norm = 1.9223e-01, time/batch = 0.6928s	
3719/30300 (epoch 6.137), train_loss = 1.84027089, grad/param norm = 1.8407e-01, time/batch = 0.7209s	
3720/30300 (epoch 6.139), train_loss = 1.68059019, grad/param norm = 1.8766e-01, time/batch = 0.6996s	
3721/30300 (epoch 6.140), train_loss = 1.92205872, grad/param norm = 1.8539e-01, time/batch = 0.7000s	
3722/30300 (epoch 6.142), train_loss = 1.94316498, grad/param norm = 2.0832e-01, time/batch = 0.6944s	
3723/30300 (epoch 6.144), train_loss = 1.79911818, grad/param norm = 2.7966e-01, time/batch = 0.6903s	
3724/30300 (epoch 6.145), train_loss = 1.89300484, grad/param norm = 1.7705e-01, time/batch = 0.6989s	
3725/30300 (epoch 6.147), train_loss = 1.74887638, grad/param norm = 1.7917e-01, time/batch = 0.6974s	
3726/30300 (epoch 6.149), train_loss = 1.92021658, grad/param norm = 1.8536e-01, time/batch = 0.6925s	
3727/30300 (epoch 6.150), train_loss = 1.88536683, grad/param norm = 1.7098e-01, time/batch = 0.6854s	
3728/30300 (epoch 6.152), train_loss = 1.68357853, grad/param norm = 1.9084e-01, time/batch = 0.6920s	
3729/30300 (epoch 6.153), train_loss = 1.75859582, grad/param norm = 1.8883e-01, time/batch = 0.6883s	
3730/30300 (epoch 6.155), train_loss = 1.48032788, grad/param norm = 1.5781e-01, time/batch = 0.6861s	
3731/30300 (epoch 6.157), train_loss = 1.68030022, grad/param norm = 1.8600e-01, time/batch = 0.6836s	
3732/30300 (epoch 6.158), train_loss = 1.77048959, grad/param norm = 1.7228e-01, time/batch = 0.6892s	
3733/30300 (epoch 6.160), train_loss = 1.61878464, grad/param norm = 1.7165e-01, time/batch = 0.7118s	
3734/30300 (epoch 6.162), train_loss = 1.59343818, grad/param norm = 1.6578e-01, time/batch = 0.7166s	
3735/30300 (epoch 6.163), train_loss = 1.62711203, grad/param norm = 2.1697e-01, time/batch = 0.7036s	
3736/30300 (epoch 6.165), train_loss = 1.73647123, grad/param norm = 1.7353e-01, time/batch = 0.6950s	
3737/30300 (epoch 6.167), train_loss = 1.74347461, grad/param norm = 1.9261e-01, time/batch = 0.6934s	
3738/30300 (epoch 6.168), train_loss = 1.66360569, grad/param norm = 1.9137e-01, time/batch = 0.7034s	
3739/30300 (epoch 6.170), train_loss = 1.74370122, grad/param norm = 1.8487e-01, time/batch = 0.6972s	
3740/30300 (epoch 6.172), train_loss = 1.66414264, grad/param norm = 1.7035e-01, time/batch = 0.6924s	
3741/30300 (epoch 6.173), train_loss = 1.77081271, grad/param norm = 1.8207e-01, time/batch = 0.6915s	
3742/30300 (epoch 6.175), train_loss = 1.66196539, grad/param norm = 1.6297e-01, time/batch = 0.6930s	
3743/30300 (epoch 6.177), train_loss = 1.72179273, grad/param norm = 1.7258e-01, time/batch = 0.6966s	
3744/30300 (epoch 6.178), train_loss = 1.46486540, grad/param norm = 1.6953e-01, time/batch = 0.6904s	
3745/30300 (epoch 6.180), train_loss = 1.61071815, grad/param norm = 1.6005e-01, time/batch = 0.6893s	
3746/30300 (epoch 6.182), train_loss = 1.60120320, grad/param norm = 1.7677e-01, time/batch = 0.7021s	
3747/30300 (epoch 6.183), train_loss = 1.56329847, grad/param norm = 1.6846e-01, time/batch = 0.7092s	
3748/30300 (epoch 6.185), train_loss = 2.00156974, grad/param norm = 1.9013e-01, time/batch = 0.7165s	
3749/30300 (epoch 6.186), train_loss = 1.94366389, grad/param norm = 2.0073e-01, time/batch = 0.6966s	
3750/30300 (epoch 6.188), train_loss = 1.75162322, grad/param norm = 1.8716e-01, time/batch = 0.6971s	
3751/30300 (epoch 6.190), train_loss = 1.58607697, grad/param norm = 1.6790e-01, time/batch = 0.7022s	
3752/30300 (epoch 6.191), train_loss = 1.81622388, grad/param norm = 1.8275e-01, time/batch = 0.6953s	
3753/30300 (epoch 6.193), train_loss = 1.54686544, grad/param norm = 1.7138e-01, time/batch = 0.6918s	
3754/30300 (epoch 6.195), train_loss = 1.73401481, grad/param norm = 1.7647e-01, time/batch = 0.6964s	
3755/30300 (epoch 6.196), train_loss = 1.75573329, grad/param norm = 1.8725e-01, time/batch = 0.6927s	
3756/30300 (epoch 6.198), train_loss = 1.46945395, grad/param norm = 1.6022e-01, time/batch = 0.6878s	
3757/30300 (epoch 6.200), train_loss = 1.64064098, grad/param norm = 1.7853e-01, time/batch = 0.6942s	
3758/30300 (epoch 6.201), train_loss = 1.81104060, grad/param norm = 1.7465e-01, time/batch = 0.6915s	
3759/30300 (epoch 6.203), train_loss = 1.66683131, grad/param norm = 1.6251e-01, time/batch = 0.6879s	
3760/30300 (epoch 6.205), train_loss = 1.92263818, grad/param norm = 1.8395e-01, time/batch = 0.6936s	
3761/30300 (epoch 6.206), train_loss = 1.93613651, grad/param norm = 1.8732e-01, time/batch = 0.6941s	
3762/30300 (epoch 6.208), train_loss = 1.86510163, grad/param norm = 1.9652e-01, time/batch = 0.6946s	
3763/30300 (epoch 6.210), train_loss = 1.70575667, grad/param norm = 1.6029e-01, time/batch = 0.6882s	
3764/30300 (epoch 6.211), train_loss = 1.73726858, grad/param norm = 2.2187e-01, time/batch = 0.6916s	
3765/30300 (epoch 6.213), train_loss = 1.62995244, grad/param norm = 1.7321e-01, time/batch = 0.6981s	
3766/30300 (epoch 6.215), train_loss = 1.48634696, grad/param norm = 1.7027e-01, time/batch = 0.6987s	
3767/30300 (epoch 6.216), train_loss = 1.65853277, grad/param norm = 1.8207e-01, time/batch = 0.6954s	
3768/30300 (epoch 6.218), train_loss = 1.58844073, grad/param norm = 1.5916e-01, time/batch = 0.6895s	
3769/30300 (epoch 6.219), train_loss = 1.50402746, grad/param norm = 1.7030e-01, time/batch = 0.6921s	
3770/30300 (epoch 6.221), train_loss = 1.51955927, grad/param norm = 1.6244e-01, time/batch = 0.6852s	
3771/30300 (epoch 6.223), train_loss = 1.65390711, grad/param norm = 1.6726e-01, time/batch = 0.6902s	
3772/30300 (epoch 6.224), train_loss = 1.48654788, grad/param norm = 1.6682e-01, time/batch = 0.6912s	
3773/30300 (epoch 6.226), train_loss = 1.76549525, grad/param norm = 1.8585e-01, time/batch = 0.6859s	
3774/30300 (epoch 6.228), train_loss = 1.78513298, grad/param norm = 1.7116e-01, time/batch = 0.6923s	
3775/30300 (epoch 6.229), train_loss = 1.59931718, grad/param norm = 1.7255e-01, time/batch = 0.7108s	
3776/30300 (epoch 6.231), train_loss = 1.68783865, grad/param norm = 1.7531e-01, time/batch = 0.7200s	
3777/30300 (epoch 6.233), train_loss = 1.60510047, grad/param norm = 1.6538e-01, time/batch = 0.7106s	
3778/30300 (epoch 6.234), train_loss = 1.77043925, grad/param norm = 1.8276e-01, time/batch = 0.6875s	
3779/30300 (epoch 6.236), train_loss = 1.61509783, grad/param norm = 1.9898e-01, time/batch = 0.6945s	
3780/30300 (epoch 6.238), train_loss = 1.75995439, grad/param norm = 1.9712e-01, time/batch = 0.6915s	
3781/30300 (epoch 6.239), train_loss = 1.70941062, grad/param norm = 1.7767e-01, time/batch = 0.6920s	
3782/30300 (epoch 6.241), train_loss = 1.72688269, grad/param norm = 1.7609e-01, time/batch = 0.6880s	
3783/30300 (epoch 6.243), train_loss = 1.67300237, grad/param norm = 1.8240e-01, time/batch = 0.6937s	
3784/30300 (epoch 6.244), train_loss = 2.01015801, grad/param norm = 1.8699e-01, time/batch = 0.6917s	
3785/30300 (epoch 6.246), train_loss = 1.67315347, grad/param norm = 1.8334e-01, time/batch = 0.6890s	
3786/30300 (epoch 6.248), train_loss = 1.73618040, grad/param norm = 1.6771e-01, time/batch = 0.6932s	
3787/30300 (epoch 6.249), train_loss = 1.51291946, grad/param norm = 1.5886e-01, time/batch = 0.6927s	
3788/30300 (epoch 6.251), train_loss = 1.58024173, grad/param norm = 1.6865e-01, time/batch = 0.6910s	
3789/30300 (epoch 6.252), train_loss = 1.84607797, grad/param norm = 1.6876e-01, time/batch = 0.6914s	
3790/30300 (epoch 6.254), train_loss = 1.77482283, grad/param norm = 1.8133e-01, time/batch = 0.7081s	
3791/30300 (epoch 6.256), train_loss = 1.71773545, grad/param norm = 1.6633e-01, time/batch = 0.7164s	
3792/30300 (epoch 6.257), train_loss = 1.82661716, grad/param norm = 1.8797e-01, time/batch = 0.6896s	
3793/30300 (epoch 6.259), train_loss = 1.75410284, grad/param norm = 1.7988e-01, time/batch = 0.6933s	
3794/30300 (epoch 6.261), train_loss = 1.82471442, grad/param norm = 1.7144e-01, time/batch = 0.6920s	
3795/30300 (epoch 6.262), train_loss = 1.66832722, grad/param norm = 1.6402e-01, time/batch = 0.6895s	
3796/30300 (epoch 6.264), train_loss = 1.68967050, grad/param norm = 1.6846e-01, time/batch = 0.6878s	
3797/30300 (epoch 6.266), train_loss = 1.60778138, grad/param norm = 1.6212e-01, time/batch = 0.6875s	
3798/30300 (epoch 6.267), train_loss = 1.88787156, grad/param norm = 1.9829e-01, time/batch = 0.6893s	
3799/30300 (epoch 6.269), train_loss = 1.70350359, grad/param norm = 1.7787e-01, time/batch = 0.6879s	
3800/30300 (epoch 6.271), train_loss = 1.69696937, grad/param norm = 1.8414e-01, time/batch = 0.6878s	
3801/30300 (epoch 6.272), train_loss = 1.71382934, grad/param norm = 1.7190e-01, time/batch = 0.6911s	
3802/30300 (epoch 6.274), train_loss = 1.85108670, grad/param norm = 1.7599e-01, time/batch = 0.6875s	
3803/30300 (epoch 6.276), train_loss = 1.83175437, grad/param norm = 1.8845e-01, time/batch = 0.6879s	
3804/30300 (epoch 6.277), train_loss = 1.61720244, grad/param norm = 1.6888e-01, time/batch = 0.6906s	
3805/30300 (epoch 6.279), train_loss = 1.71773215, grad/param norm = 1.7131e-01, time/batch = 0.6875s	
3806/30300 (epoch 6.281), train_loss = 1.75008821, grad/param norm = 1.6646e-01, time/batch = 0.6973s	
3807/30300 (epoch 6.282), train_loss = 1.59268811, grad/param norm = 1.6986e-01, time/batch = 0.6891s	
3808/30300 (epoch 6.284), train_loss = 1.91694372, grad/param norm = 2.0156e-01, time/batch = 0.6916s	
3809/30300 (epoch 6.285), train_loss = 1.71706224, grad/param norm = 1.8275e-01, time/batch = 0.6886s	
3810/30300 (epoch 6.287), train_loss = 1.70462427, grad/param norm = 1.7261e-01, time/batch = 0.6854s	
3811/30300 (epoch 6.289), train_loss = 1.76388265, grad/param norm = 1.7712e-01, time/batch = 0.6930s	
3812/30300 (epoch 6.290), train_loss = 1.40855154, grad/param norm = 1.5196e-01, time/batch = 0.6897s	
3813/30300 (epoch 6.292), train_loss = 1.59724982, grad/param norm = 1.5829e-01, time/batch = 0.6902s	
3814/30300 (epoch 6.294), train_loss = 1.85320008, grad/param norm = 1.6312e-01, time/batch = 0.6868s	
3815/30300 (epoch 6.295), train_loss = 1.64994702, grad/param norm = 1.4878e-01, time/batch = 0.6929s	
3816/30300 (epoch 6.297), train_loss = 1.61019381, grad/param norm = 1.6690e-01, time/batch = 0.7017s	
3817/30300 (epoch 6.299), train_loss = 1.67855478, grad/param norm = 1.8164e-01, time/batch = 0.7052s	
3818/30300 (epoch 6.300), train_loss = 1.69767258, grad/param norm = 1.5978e-01, time/batch = 0.7151s	
3819/30300 (epoch 6.302), train_loss = 1.59915086, grad/param norm = 1.7188e-01, time/batch = 0.7135s	
3820/30300 (epoch 6.304), train_loss = 1.52818454, grad/param norm = 1.5990e-01, time/batch = 0.7174s	
3821/30300 (epoch 6.305), train_loss = 1.63080943, grad/param norm = 1.6126e-01, time/batch = 0.7152s	
3822/30300 (epoch 6.307), train_loss = 1.64527424, grad/param norm = 1.6236e-01, time/batch = 0.7165s	
3823/30300 (epoch 6.309), train_loss = 1.76712527, grad/param norm = 1.7292e-01, time/batch = 0.7149s	
3824/30300 (epoch 6.310), train_loss = 1.61223088, grad/param norm = 1.6286e-01, time/batch = 0.7051s	
3825/30300 (epoch 6.312), train_loss = 1.70541070, grad/param norm = 1.6004e-01, time/batch = 0.7137s	
3826/30300 (epoch 6.314), train_loss = 1.71751873, grad/param norm = 1.6243e-01, time/batch = 0.7058s	
3827/30300 (epoch 6.315), train_loss = 1.76302837, grad/param norm = 1.7265e-01, time/batch = 0.7081s	
3828/30300 (epoch 6.317), train_loss = 1.77838793, grad/param norm = 1.8485e-01, time/batch = 0.6862s	
3829/30300 (epoch 6.318), train_loss = 1.88795146, grad/param norm = 1.9141e-01, time/batch = 0.6875s	
3830/30300 (epoch 6.320), train_loss = 1.81602296, grad/param norm = 1.8433e-01, time/batch = 0.6921s	
3831/30300 (epoch 6.322), train_loss = 1.55216475, grad/param norm = 1.6944e-01, time/batch = 0.6862s	
3832/30300 (epoch 6.323), train_loss = 1.80886450, grad/param norm = 1.6555e-01, time/batch = 0.6953s	
3833/30300 (epoch 6.325), train_loss = 1.59897788, grad/param norm = 1.5328e-01, time/batch = 0.7101s	
3834/30300 (epoch 6.327), train_loss = 1.59349452, grad/param norm = 1.6765e-01, time/batch = 0.7177s	
3835/30300 (epoch 6.328), train_loss = 1.60059246, grad/param norm = 1.6565e-01, time/batch = 0.6917s	
3836/30300 (epoch 6.330), train_loss = 1.76237259, grad/param norm = 1.6462e-01, time/batch = 0.6940s	
3837/30300 (epoch 6.332), train_loss = 1.78970647, grad/param norm = 1.7373e-01, time/batch = 0.6892s	
3838/30300 (epoch 6.333), train_loss = 1.70948258, grad/param norm = 1.7647e-01, time/batch = 0.6931s	
3839/30300 (epoch 6.335), train_loss = 1.49486933, grad/param norm = 1.7040e-01, time/batch = 0.6914s	
3840/30300 (epoch 6.337), train_loss = 1.85373246, grad/param norm = 1.7731e-01, time/batch = 0.6967s	
3841/30300 (epoch 6.338), train_loss = 1.57014733, grad/param norm = 1.7782e-01, time/batch = 0.6908s	
3842/30300 (epoch 6.340), train_loss = 1.60724062, grad/param norm = 1.7973e-01, time/batch = 0.6963s	
3843/30300 (epoch 6.342), train_loss = 1.74757796, grad/param norm = 1.6124e-01, time/batch = 0.6905s	
3844/30300 (epoch 6.343), train_loss = 1.72519655, grad/param norm = 1.7370e-01, time/batch = 0.6891s	
3845/30300 (epoch 6.345), train_loss = 1.68989858, grad/param norm = 1.6077e-01, time/batch = 0.6925s	
3846/30300 (epoch 6.347), train_loss = 1.46841507, grad/param norm = 1.4290e-01, time/batch = 0.6900s	
3847/30300 (epoch 6.348), train_loss = 1.53445301, grad/param norm = 1.6332e-01, time/batch = 0.7016s	
3848/30300 (epoch 6.350), train_loss = 1.65773583, grad/param norm = 1.6804e-01, time/batch = 0.7209s	
3849/30300 (epoch 6.351), train_loss = 1.67523085, grad/param norm = 1.8176e-01, time/batch = 0.6945s	
3850/30300 (epoch 6.353), train_loss = 1.44412802, grad/param norm = 1.7551e-01, time/batch = 0.6902s	
3851/30300 (epoch 6.355), train_loss = 1.64731380, grad/param norm = 1.6263e-01, time/batch = 0.6932s	
3852/30300 (epoch 6.356), train_loss = 1.83778393, grad/param norm = 1.9258e-01, time/batch = 0.6984s	
3853/30300 (epoch 6.358), train_loss = 1.85225990, grad/param norm = 1.8061e-01, time/batch = 0.6884s	
3854/30300 (epoch 6.360), train_loss = 1.60328278, grad/param norm = 1.6225e-01, time/batch = 0.6904s	
3855/30300 (epoch 6.361), train_loss = 1.73145318, grad/param norm = 1.8638e-01, time/batch = 0.6918s	
3856/30300 (epoch 6.363), train_loss = 1.77615543, grad/param norm = 1.8214e-01, time/batch = 0.6917s	
3857/30300 (epoch 6.365), train_loss = 1.62746756, grad/param norm = 1.7051e-01, time/batch = 0.6890s	
3858/30300 (epoch 6.366), train_loss = 1.61235127, grad/param norm = 1.7248e-01, time/batch = 0.6939s	
3859/30300 (epoch 6.368), train_loss = 1.45987533, grad/param norm = 1.7190e-01, time/batch = 0.6942s	
3860/30300 (epoch 6.370), train_loss = 1.61868243, grad/param norm = 1.7804e-01, time/batch = 0.6940s	
3861/30300 (epoch 6.371), train_loss = 1.68406189, grad/param norm = 1.6373e-01, time/batch = 0.6951s	
3862/30300 (epoch 6.373), train_loss = 1.61930575, grad/param norm = 1.6302e-01, time/batch = 0.7241s	
3863/30300 (epoch 6.375), train_loss = 1.55821523, grad/param norm = 1.5886e-01, time/batch = 0.7142s	
3864/30300 (epoch 6.376), train_loss = 1.60018041, grad/param norm = 1.5973e-01, time/batch = 0.7011s	
3865/30300 (epoch 6.378), train_loss = 1.63144932, grad/param norm = 1.6135e-01, time/batch = 0.6932s	
3866/30300 (epoch 6.380), train_loss = 1.90277714, grad/param norm = 1.8826e-01, time/batch = 0.6929s	
3867/30300 (epoch 6.381), train_loss = 1.61356581, grad/param norm = 1.7604e-01, time/batch = 0.6918s	
3868/30300 (epoch 6.383), train_loss = 1.75357964, grad/param norm = 1.8923e-01, time/batch = 0.6945s	
3869/30300 (epoch 6.384), train_loss = 1.78383651, grad/param norm = 1.6851e-01, time/batch = 0.6892s	
3870/30300 (epoch 6.386), train_loss = 1.53116205, grad/param norm = 1.7257e-01, time/batch = 0.6889s	
3871/30300 (epoch 6.388), train_loss = 1.58372875, grad/param norm = 1.6122e-01, time/batch = 0.6917s	
3872/30300 (epoch 6.389), train_loss = 1.68222922, grad/param norm = 1.7095e-01, time/batch = 0.6929s	
3873/30300 (epoch 6.391), train_loss = 1.73697474, grad/param norm = 1.6003e-01, time/batch = 0.6909s	
3874/30300 (epoch 6.393), train_loss = 1.47929498, grad/param norm = 1.6492e-01, time/batch = 0.6900s	
3875/30300 (epoch 6.394), train_loss = 1.66085896, grad/param norm = 1.6209e-01, time/batch = 0.6911s	
3876/30300 (epoch 6.396), train_loss = 1.83358053, grad/param norm = 1.6845e-01, time/batch = 0.6898s	
3877/30300 (epoch 6.398), train_loss = 1.58263185, grad/param norm = 1.4951e-01, time/batch = 0.6891s	
3878/30300 (epoch 6.399), train_loss = 1.63261057, grad/param norm = 1.7183e-01, time/batch = 0.6901s	
3879/30300 (epoch 6.401), train_loss = 1.77831472, grad/param norm = 1.6781e-01, time/batch = 0.6928s	
3880/30300 (epoch 6.403), train_loss = 1.66180085, grad/param norm = 1.7543e-01, time/batch = 0.6895s	
3881/30300 (epoch 6.404), train_loss = 1.61065549, grad/param norm = 1.9302e-01, time/batch = 0.6908s	
3882/30300 (epoch 6.406), train_loss = 1.70570726, grad/param norm = 1.8217e-01, time/batch = 0.6911s	
3883/30300 (epoch 6.408), train_loss = 1.57424442, grad/param norm = 1.7532e-01, time/batch = 0.6917s	
3884/30300 (epoch 6.409), train_loss = 1.46287131, grad/param norm = 1.7825e-01, time/batch = 0.6900s	
3885/30300 (epoch 6.411), train_loss = 1.49901004, grad/param norm = 1.5969e-01, time/batch = 0.6901s	
3886/30300 (epoch 6.413), train_loss = 1.51545775, grad/param norm = 1.6765e-01, time/batch = 0.6903s	
3887/30300 (epoch 6.414), train_loss = 1.78395641, grad/param norm = 1.7050e-01, time/batch = 0.6890s	
3888/30300 (epoch 6.416), train_loss = 1.63985513, grad/param norm = 1.7398e-01, time/batch = 0.6899s	
3889/30300 (epoch 6.417), train_loss = 1.59362268, grad/param norm = 1.5279e-01, time/batch = 0.6860s	
3890/30300 (epoch 6.419), train_loss = 1.46661193, grad/param norm = 1.6035e-01, time/batch = 0.6969s	
3891/30300 (epoch 6.421), train_loss = 1.56594110, grad/param norm = 1.5720e-01, time/batch = 0.7219s	
3892/30300 (epoch 6.422), train_loss = 1.61842900, grad/param norm = 1.6490e-01, time/batch = 0.6926s	
3893/30300 (epoch 6.424), train_loss = 1.65635754, grad/param norm = 1.6638e-01, time/batch = 0.6875s	
3894/30300 (epoch 6.426), train_loss = 1.49408729, grad/param norm = 1.6224e-01, time/batch = 0.6913s	
3895/30300 (epoch 6.427), train_loss = 1.63470916, grad/param norm = 1.7616e-01, time/batch = 0.6897s	
3896/30300 (epoch 6.429), train_loss = 1.67746534, grad/param norm = 1.7759e-01, time/batch = 0.6884s	
3897/30300 (epoch 6.431), train_loss = 1.72461468, grad/param norm = 1.9378e-01, time/batch = 0.6902s	
3898/30300 (epoch 6.432), train_loss = 1.64657738, grad/param norm = 1.7565e-01, time/batch = 0.6923s	
3899/30300 (epoch 6.434), train_loss = 1.54540545, grad/param norm = 1.7276e-01, time/batch = 0.6932s	
3900/30300 (epoch 6.436), train_loss = 1.76841112, grad/param norm = 1.7769e-01, time/batch = 0.6889s	
3901/30300 (epoch 6.437), train_loss = 1.59477927, grad/param norm = 1.8791e-01, time/batch = 0.6929s	
3902/30300 (epoch 6.439), train_loss = 1.55856925, grad/param norm = 1.6672e-01, time/batch = 0.6904s	
3903/30300 (epoch 6.441), train_loss = 1.56196808, grad/param norm = 1.6728e-01, time/batch = 0.6973s	
3904/30300 (epoch 6.442), train_loss = 1.49611897, grad/param norm = 1.6349e-01, time/batch = 0.6945s	
3905/30300 (epoch 6.444), train_loss = 1.45464185, grad/param norm = 2.0015e-01, time/batch = 0.7181s	
3906/30300 (epoch 6.446), train_loss = 1.57378000, grad/param norm = 1.6904e-01, time/batch = 0.7158s	
3907/30300 (epoch 6.447), train_loss = 1.66305375, grad/param norm = 2.0589e-01, time/batch = 0.6967s	
3908/30300 (epoch 6.449), train_loss = 1.56209625, grad/param norm = 1.7421e-01, time/batch = 0.7049s	
3909/30300 (epoch 6.450), train_loss = 1.73785736, grad/param norm = 1.6515e-01, time/batch = 0.6867s	
3910/30300 (epoch 6.452), train_loss = 1.63954914, grad/param norm = 1.6022e-01, time/batch = 0.6882s	
3911/30300 (epoch 6.454), train_loss = 1.61300995, grad/param norm = 1.5696e-01, time/batch = 0.6925s	
3912/30300 (epoch 6.455), train_loss = 1.77550057, grad/param norm = 1.7726e-01, time/batch = 0.6944s	
3913/30300 (epoch 6.457), train_loss = 1.71044695, grad/param norm = 1.7580e-01, time/batch = 0.7068s	
3914/30300 (epoch 6.459), train_loss = 1.72269614, grad/param norm = 1.8996e-01, time/batch = 0.6903s	
3915/30300 (epoch 6.460), train_loss = 1.74731881, grad/param norm = 1.8152e-01, time/batch = 0.6911s	
3916/30300 (epoch 6.462), train_loss = 1.75375782, grad/param norm = 1.7359e-01, time/batch = 0.6888s	
3917/30300 (epoch 6.464), train_loss = 1.57499808, grad/param norm = 1.7924e-01, time/batch = 0.6888s	
3918/30300 (epoch 6.465), train_loss = 1.48646187, grad/param norm = 1.5556e-01, time/batch = 0.6869s	
3919/30300 (epoch 6.467), train_loss = 1.37761195, grad/param norm = 1.6450e-01, time/batch = 0.7073s	
3920/30300 (epoch 6.469), train_loss = 1.58699067, grad/param norm = 1.7226e-01, time/batch = 0.7188s	
3921/30300 (epoch 6.470), train_loss = 1.57263045, grad/param norm = 1.5368e-01, time/batch = 0.6940s	
3922/30300 (epoch 6.472), train_loss = 1.56089748, grad/param norm = 1.6012e-01, time/batch = 0.6922s	
3923/30300 (epoch 6.474), train_loss = 1.64675263, grad/param norm = 1.7973e-01, time/batch = 0.6892s	
3924/30300 (epoch 6.475), train_loss = 1.51895135, grad/param norm = 1.6642e-01, time/batch = 0.6865s	
3925/30300 (epoch 6.477), train_loss = 1.67677416, grad/param norm = 1.9229e-01, time/batch = 0.6889s	
3926/30300 (epoch 6.479), train_loss = 1.69499730, grad/param norm = 1.7120e-01, time/batch = 0.6902s	
3927/30300 (epoch 6.480), train_loss = 1.69622365, grad/param norm = 1.6686e-01, time/batch = 0.6941s	
3928/30300 (epoch 6.482), train_loss = 1.67324706, grad/param norm = 1.7689e-01, time/batch = 0.6924s	
3929/30300 (epoch 6.483), train_loss = 1.63594912, grad/param norm = 1.6988e-01, time/batch = 0.7066s	
3930/30300 (epoch 6.485), train_loss = 1.61575775, grad/param norm = 1.6695e-01, time/batch = 0.6965s	
3931/30300 (epoch 6.487), train_loss = 1.72491577, grad/param norm = 1.8752e-01, time/batch = 0.6959s	
3932/30300 (epoch 6.488), train_loss = 1.63148936, grad/param norm = 1.6120e-01, time/batch = 0.6882s	
3933/30300 (epoch 6.490), train_loss = 1.53574458, grad/param norm = 1.6928e-01, time/batch = 0.6996s	
3934/30300 (epoch 6.492), train_loss = 1.71304739, grad/param norm = 2.0192e-01, time/batch = 0.6944s	
3935/30300 (epoch 6.493), train_loss = 1.58658500, grad/param norm = 1.7918e-01, time/batch = 0.6946s	
3936/30300 (epoch 6.495), train_loss = 1.57738573, grad/param norm = 1.7700e-01, time/batch = 0.6907s	
3937/30300 (epoch 6.497), train_loss = 1.65269151, grad/param norm = 1.7891e-01, time/batch = 0.6899s	
3938/30300 (epoch 6.498), train_loss = 1.67263909, grad/param norm = 1.7086e-01, time/batch = 0.6902s	
3939/30300 (epoch 6.500), train_loss = 1.82249872, grad/param norm = 1.7957e-01, time/batch = 0.6877s	
3940/30300 (epoch 6.502), train_loss = 1.54363983, grad/param norm = 1.6661e-01, time/batch = 0.6910s	
3941/30300 (epoch 6.503), train_loss = 1.70510348, grad/param norm = 1.6198e-01, time/batch = 0.6939s	
3942/30300 (epoch 6.505), train_loss = 1.64379477, grad/param norm = 1.6998e-01, time/batch = 0.6917s	
3943/30300 (epoch 6.507), train_loss = 1.64151803, grad/param norm = 1.7960e-01, time/batch = 0.6879s	
3944/30300 (epoch 6.508), train_loss = 1.72049435, grad/param norm = 1.8461e-01, time/batch = 0.6987s	
3945/30300 (epoch 6.510), train_loss = 1.71226042, grad/param norm = 1.9086e-01, time/batch = 0.6908s	
3946/30300 (epoch 6.512), train_loss = 1.58064026, grad/param norm = 1.7309e-01, time/batch = 0.6880s	
3947/30300 (epoch 6.513), train_loss = 1.71643120, grad/param norm = 1.7656e-01, time/batch = 0.6908s	
3948/30300 (epoch 6.515), train_loss = 1.62974328, grad/param norm = 1.7074e-01, time/batch = 0.7191s	
3949/30300 (epoch 6.517), train_loss = 1.47958564, grad/param norm = 1.5862e-01, time/batch = 0.7065s	
3950/30300 (epoch 6.518), train_loss = 1.73565057, grad/param norm = 1.7137e-01, time/batch = 0.6929s	
3951/30300 (epoch 6.520), train_loss = 1.90971062, grad/param norm = 1.8699e-01, time/batch = 0.6963s	
3952/30300 (epoch 6.521), train_loss = 1.54161379, grad/param norm = 1.7889e-01, time/batch = 0.6948s	
3953/30300 (epoch 6.523), train_loss = 1.78861434, grad/param norm = 1.8552e-01, time/batch = 0.6924s	
3954/30300 (epoch 6.525), train_loss = 1.61947576, grad/param norm = 1.6424e-01, time/batch = 0.6951s	
3955/30300 (epoch 6.526), train_loss = 1.63508460, grad/param norm = 1.6777e-01, time/batch = 0.6937s	
3956/30300 (epoch 6.528), train_loss = 1.44109654, grad/param norm = 1.5814e-01, time/batch = 0.6940s	
3957/30300 (epoch 6.530), train_loss = 1.49327663, grad/param norm = 1.7468e-01, time/batch = 0.6946s	
3958/30300 (epoch 6.531), train_loss = 1.69131385, grad/param norm = 1.8368e-01, time/batch = 0.7004s	
3959/30300 (epoch 6.533), train_loss = 1.73024254, grad/param norm = 1.6848e-01, time/batch = 0.6947s	
3960/30300 (epoch 6.535), train_loss = 1.43785591, grad/param norm = 1.5791e-01, time/batch = 0.6914s	
3961/30300 (epoch 6.536), train_loss = 1.69817810, grad/param norm = 1.7769e-01, time/batch = 0.6960s	
3962/30300 (epoch 6.538), train_loss = 1.46303923, grad/param norm = 1.6323e-01, time/batch = 0.7105s	
3963/30300 (epoch 6.540), train_loss = 1.58611773, grad/param norm = 1.6807e-01, time/batch = 0.7138s	
3964/30300 (epoch 6.541), train_loss = 1.62841934, grad/param norm = 1.8035e-01, time/batch = 0.6926s	
3965/30300 (epoch 6.543), train_loss = 1.64858547, grad/param norm = 1.6782e-01, time/batch = 0.6900s	
3966/30300 (epoch 6.545), train_loss = 1.72007084, grad/param norm = 1.8179e-01, time/batch = 0.6952s	
3967/30300 (epoch 6.546), train_loss = 1.83048001, grad/param norm = 1.7569e-01, time/batch = 0.7005s	
3968/30300 (epoch 6.548), train_loss = 1.58381467, grad/param norm = 1.9114e-01, time/batch = 0.6899s	
3969/30300 (epoch 6.550), train_loss = 1.80124520, grad/param norm = 1.7960e-01, time/batch = 0.6902s	
3970/30300 (epoch 6.551), train_loss = 1.58656787, grad/param norm = 1.7027e-01, time/batch = 0.6911s	
3971/30300 (epoch 6.553), train_loss = 1.55772644, grad/param norm = 1.7118e-01, time/batch = 0.6945s	
3972/30300 (epoch 6.554), train_loss = 1.81152821, grad/param norm = 1.9788e-01, time/batch = 0.6934s	
3973/30300 (epoch 6.556), train_loss = 1.66671303, grad/param norm = 1.6365e-01, time/batch = 0.7031s	
3974/30300 (epoch 6.558), train_loss = 1.77491056, grad/param norm = 1.7978e-01, time/batch = 0.6992s	
3975/30300 (epoch 6.559), train_loss = 1.61683132, grad/param norm = 1.7130e-01, time/batch = 0.6909s	
3976/30300 (epoch 6.561), train_loss = 1.51822486, grad/param norm = 1.6952e-01, time/batch = 0.7024s	
3977/30300 (epoch 6.563), train_loss = 1.59746179, grad/param norm = 1.6509e-01, time/batch = 0.7208s	
3978/30300 (epoch 6.564), train_loss = 1.57563330, grad/param norm = 1.6096e-01, time/batch = 0.6941s	
3979/30300 (epoch 6.566), train_loss = 1.63101315, grad/param norm = 1.7349e-01, time/batch = 0.6855s	
3980/30300 (epoch 6.568), train_loss = 1.47622625, grad/param norm = 1.7031e-01, time/batch = 0.6896s	
3981/30300 (epoch 6.569), train_loss = 1.63595642, grad/param norm = 1.6967e-01, time/batch = 0.6932s	
3982/30300 (epoch 6.571), train_loss = 1.72822227, grad/param norm = 1.9968e-01, time/batch = 0.6959s	
3983/30300 (epoch 6.573), train_loss = 1.69798508, grad/param norm = 1.7494e-01, time/batch = 0.6901s	
3984/30300 (epoch 6.574), train_loss = 1.65490329, grad/param norm = 1.7263e-01, time/batch = 0.6897s	
3985/30300 (epoch 6.576), train_loss = 1.62240125, grad/param norm = 1.6615e-01, time/batch = 0.6907s	
3986/30300 (epoch 6.578), train_loss = 1.51893432, grad/param norm = 1.5543e-01, time/batch = 0.6917s	
3987/30300 (epoch 6.579), train_loss = 1.63508960, grad/param norm = 1.7402e-01, time/batch = 0.6918s	
3988/30300 (epoch 6.581), train_loss = 1.71110412, grad/param norm = 1.6789e-01, time/batch = 0.6888s	
3989/30300 (epoch 6.583), train_loss = 1.78291861, grad/param norm = 1.9620e-01, time/batch = 0.6892s	
3990/30300 (epoch 6.584), train_loss = 1.74826139, grad/param norm = 1.7120e-01, time/batch = 0.6970s	
3991/30300 (epoch 6.586), train_loss = 1.67999576, grad/param norm = 1.6932e-01, time/batch = 0.7221s	
3992/30300 (epoch 6.587), train_loss = 1.68310391, grad/param norm = 1.7618e-01, time/batch = 0.7222s	
3993/30300 (epoch 6.589), train_loss = 1.41577106, grad/param norm = 1.5611e-01, time/batch = 0.7182s	
3994/30300 (epoch 6.591), train_loss = 1.67288033, grad/param norm = 1.7640e-01, time/batch = 0.7291s	
3995/30300 (epoch 6.592), train_loss = 1.63226830, grad/param norm = 1.6453e-01, time/batch = 0.7147s	
3996/30300 (epoch 6.594), train_loss = 1.67472147, grad/param norm = 1.8554e-01, time/batch = 0.7234s	
3997/30300 (epoch 6.596), train_loss = 1.51310023, grad/param norm = 1.5431e-01, time/batch = 0.7196s	
3998/30300 (epoch 6.597), train_loss = 1.57898654, grad/param norm = 1.7227e-01, time/batch = 0.7165s	
3999/30300 (epoch 6.599), train_loss = 1.41205371, grad/param norm = 1.6591e-01, time/batch = 0.7112s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch6.60_1.7832.t7	
4000/30300 (epoch 6.601), train_loss = 1.66434741, grad/param norm = 1.6554e-01, time/batch = 0.6969s	
4001/30300 (epoch 6.602), train_loss = 1.70783592, grad/param norm = 1.6597e-01, time/batch = 0.7045s	
4002/30300 (epoch 6.604), train_loss = 1.54560432, grad/param norm = 1.6446e-01, time/batch = 0.7005s	
4003/30300 (epoch 6.606), train_loss = 1.80536977, grad/param norm = 1.9462e-01, time/batch = 0.6929s	
4004/30300 (epoch 6.607), train_loss = 1.68902254, grad/param norm = 1.6987e-01, time/batch = 0.7034s	
4005/30300 (epoch 6.609), train_loss = 1.89851787, grad/param norm = 1.9265e-01, time/batch = 0.6976s	
4006/30300 (epoch 6.611), train_loss = 1.50411376, grad/param norm = 1.6486e-01, time/batch = 0.6920s	
4007/30300 (epoch 6.612), train_loss = 1.57302613, grad/param norm = 1.6890e-01, time/batch = 0.6941s	
4008/30300 (epoch 6.614), train_loss = 1.47939531, grad/param norm = 1.5713e-01, time/batch = 0.6918s	
4009/30300 (epoch 6.616), train_loss = 1.71849508, grad/param norm = 1.8793e-01, time/batch = 0.6908s	
4010/30300 (epoch 6.617), train_loss = 1.62460793, grad/param norm = 1.7411e-01, time/batch = 0.6870s	
4011/30300 (epoch 6.619), train_loss = 1.44395596, grad/param norm = 1.5851e-01, time/batch = 0.6903s	
4012/30300 (epoch 6.620), train_loss = 1.71475064, grad/param norm = 1.7261e-01, time/batch = 0.6942s	
4013/30300 (epoch 6.622), train_loss = 1.62202456, grad/param norm = 1.8401e-01, time/batch = 0.6920s	
4014/30300 (epoch 6.624), train_loss = 1.55741558, grad/param norm = 1.6542e-01, time/batch = 0.6906s	
4015/30300 (epoch 6.625), train_loss = 1.58233332, grad/param norm = 1.7163e-01, time/batch = 0.6920s	
4016/30300 (epoch 6.627), train_loss = 1.79840949, grad/param norm = 1.8397e-01, time/batch = 0.6906s	
4017/30300 (epoch 6.629), train_loss = 1.71197553, grad/param norm = 1.6535e-01, time/batch = 0.6900s	
4018/30300 (epoch 6.630), train_loss = 1.69732951, grad/param norm = 1.8093e-01, time/batch = 0.6918s	
4019/30300 (epoch 6.632), train_loss = 1.76310018, grad/param norm = 1.7410e-01, time/batch = 0.6926s	
4020/30300 (epoch 6.634), train_loss = 1.43553160, grad/param norm = 1.4909e-01, time/batch = 0.6955s	
4021/30300 (epoch 6.635), train_loss = 1.73509584, grad/param norm = 1.7014e-01, time/batch = 0.7179s	
4022/30300 (epoch 6.637), train_loss = 1.68846628, grad/param norm = 1.8802e-01, time/batch = 0.6936s	
4023/30300 (epoch 6.639), train_loss = 1.56184268, grad/param norm = 1.8324e-01, time/batch = 0.6900s	
4024/30300 (epoch 6.640), train_loss = 1.71640414, grad/param norm = 1.7632e-01, time/batch = 0.7014s	
4025/30300 (epoch 6.642), train_loss = 1.58809045, grad/param norm = 1.6161e-01, time/batch = 0.7080s	
4026/30300 (epoch 6.644), train_loss = 1.70594387, grad/param norm = 1.7457e-01, time/batch = 0.6982s	
4027/30300 (epoch 6.645), train_loss = 1.56509454, grad/param norm = 1.7925e-01, time/batch = 0.7031s	
4028/30300 (epoch 6.647), train_loss = 1.61719509, grad/param norm = 1.6014e-01, time/batch = 0.7028s	
4029/30300 (epoch 6.649), train_loss = 1.58350470, grad/param norm = 1.6135e-01, time/batch = 0.6898s	
4030/30300 (epoch 6.650), train_loss = 1.65276693, grad/param norm = 1.6215e-01, time/batch = 0.6908s	
4031/30300 (epoch 6.652), train_loss = 1.53231009, grad/param norm = 1.6936e-01, time/batch = 0.6968s	
4032/30300 (epoch 6.653), train_loss = 1.80224395, grad/param norm = 1.6741e-01, time/batch = 0.6938s	
4033/30300 (epoch 6.655), train_loss = 1.58968800, grad/param norm = 1.7374e-01, time/batch = 0.6950s	
4034/30300 (epoch 6.657), train_loss = 1.70802394, grad/param norm = 1.7534e-01, time/batch = 0.7152s	
4035/30300 (epoch 6.658), train_loss = 1.58667337, grad/param norm = 1.7061e-01, time/batch = 0.7209s	
4036/30300 (epoch 6.660), train_loss = 1.71232645, grad/param norm = 1.7122e-01, time/batch = 0.7021s	
4037/30300 (epoch 6.662), train_loss = 1.74432895, grad/param norm = 1.8914e-01, time/batch = 0.6870s	
4038/30300 (epoch 6.663), train_loss = 1.63218248, grad/param norm = 1.6215e-01, time/batch = 0.6885s	
4039/30300 (epoch 6.665), train_loss = 1.50417136, grad/param norm = 1.5975e-01, time/batch = 0.6888s	
4040/30300 (epoch 6.667), train_loss = 1.79136009, grad/param norm = 1.9501e-01, time/batch = 0.6889s	
4041/30300 (epoch 6.668), train_loss = 1.85366975, grad/param norm = 1.8861e-01, time/batch = 0.6983s	
4042/30300 (epoch 6.670), train_loss = 1.75498579, grad/param norm = 1.7539e-01, time/batch = 0.6939s	
4043/30300 (epoch 6.672), train_loss = 1.72755578, grad/param norm = 1.7154e-01, time/batch = 0.6896s	
4044/30300 (epoch 6.673), train_loss = 1.73095109, grad/param norm = 1.7201e-01, time/batch = 0.6874s	
4045/30300 (epoch 6.675), train_loss = 1.55622629, grad/param norm = 1.6731e-01, time/batch = 0.6912s	
4046/30300 (epoch 6.677), train_loss = 1.53336542, grad/param norm = 1.5793e-01, time/batch = 0.6868s	
4047/30300 (epoch 6.678), train_loss = 1.54997847, grad/param norm = 1.5196e-01, time/batch = 0.6926s	
4048/30300 (epoch 6.680), train_loss = 1.37245544, grad/param norm = 1.9516e-01, time/batch = 0.6866s	
4049/30300 (epoch 6.682), train_loss = 1.63338929, grad/param norm = 2.7681e-01, time/batch = 0.7091s	
4050/30300 (epoch 6.683), train_loss = 1.70024189, grad/param norm = 1.6839e-01, time/batch = 0.7102s	
4051/30300 (epoch 6.685), train_loss = 1.82204273, grad/param norm = 1.8807e-01, time/batch = 0.6885s	
4052/30300 (epoch 6.686), train_loss = 1.68423181, grad/param norm = 1.8982e-01, time/batch = 0.6866s	
4053/30300 (epoch 6.688), train_loss = 1.63693007, grad/param norm = 1.6807e-01, time/batch = 0.6887s	
4054/30300 (epoch 6.690), train_loss = 1.61655153, grad/param norm = 1.8065e-01, time/batch = 0.6889s	
4055/30300 (epoch 6.691), train_loss = 1.64210043, grad/param norm = 1.6729e-01, time/batch = 0.6904s	
4056/30300 (epoch 6.693), train_loss = 2.04762387, grad/param norm = 1.9481e-01, time/batch = 0.6878s	
4057/30300 (epoch 6.695), train_loss = 1.83765060, grad/param norm = 2.1333e-01, time/batch = 0.6871s	
4058/30300 (epoch 6.696), train_loss = 1.87716134, grad/param norm = 2.1465e-01, time/batch = 0.6901s	
4059/30300 (epoch 6.698), train_loss = 1.56036838, grad/param norm = 1.6677e-01, time/batch = 0.6891s	
4060/30300 (epoch 6.700), train_loss = 1.61824737, grad/param norm = 1.7683e-01, time/batch = 0.6877s	
4061/30300 (epoch 6.701), train_loss = 1.42364653, grad/param norm = 1.4712e-01, time/batch = 0.6919s	
4062/30300 (epoch 6.703), train_loss = 1.60507574, grad/param norm = 1.5660e-01, time/batch = 0.6879s	
4063/30300 (epoch 6.705), train_loss = 1.64364839, grad/param norm = 1.8021e-01, time/batch = 0.6985s	
4064/30300 (epoch 6.706), train_loss = 1.64064367, grad/param norm = 1.6681e-01, time/batch = 0.7210s	
4065/30300 (epoch 6.708), train_loss = 1.56815673, grad/param norm = 1.7485e-01, time/batch = 0.6935s	
4066/30300 (epoch 6.710), train_loss = 1.60763298, grad/param norm = 1.7188e-01, time/batch = 0.6854s	
4067/30300 (epoch 6.711), train_loss = 1.51590007, grad/param norm = 1.6356e-01, time/batch = 0.6867s	
4068/30300 (epoch 6.713), train_loss = 1.46240686, grad/param norm = 1.5385e-01, time/batch = 0.6908s	
4069/30300 (epoch 6.715), train_loss = 1.60219154, grad/param norm = 1.6643e-01, time/batch = 0.7044s	
4070/30300 (epoch 6.716), train_loss = 1.80245999, grad/param norm = 1.7159e-01, time/batch = 0.6962s	
4071/30300 (epoch 6.718), train_loss = 1.72544383, grad/param norm = 1.8138e-01, time/batch = 0.7027s	
4072/30300 (epoch 6.719), train_loss = 1.62079542, grad/param norm = 1.7365e-01, time/batch = 0.6906s	
4073/30300 (epoch 6.721), train_loss = 1.60669044, grad/param norm = 1.6679e-01, time/batch = 0.6969s	
4074/30300 (epoch 6.723), train_loss = 1.59387014, grad/param norm = 1.7983e-01, time/batch = 0.7051s	
4075/30300 (epoch 6.724), train_loss = 1.72559339, grad/param norm = 1.7266e-01, time/batch = 0.6882s	
4076/30300 (epoch 6.726), train_loss = 2.06071976, grad/param norm = 1.9324e-01, time/batch = 0.6893s	
4077/30300 (epoch 6.728), train_loss = 1.64044408, grad/param norm = 1.6760e-01, time/batch = 0.6883s	
4078/30300 (epoch 6.729), train_loss = 1.63837803, grad/param norm = 1.6460e-01, time/batch = 0.7208s	
4079/30300 (epoch 6.731), train_loss = 1.74198639, grad/param norm = 1.8295e-01, time/batch = 0.7049s	
4080/30300 (epoch 6.733), train_loss = 1.63318462, grad/param norm = 1.6501e-01, time/batch = 0.7062s	
4081/30300 (epoch 6.734), train_loss = 1.66020003, grad/param norm = 1.6201e-01, time/batch = 0.7055s	
4082/30300 (epoch 6.736), train_loss = 1.58500203, grad/param norm = 1.5442e-01, time/batch = 0.6871s	
4083/30300 (epoch 6.738), train_loss = 1.44618855, grad/param norm = 1.5119e-01, time/batch = 0.6920s	
4084/30300 (epoch 6.739), train_loss = 1.71331346, grad/param norm = 1.6428e-01, time/batch = 0.6910s	
4085/30300 (epoch 6.741), train_loss = 1.72969289, grad/param norm = 1.6162e-01, time/batch = 0.6882s	
4086/30300 (epoch 6.743), train_loss = 1.53586196, grad/param norm = 1.6444e-01, time/batch = 0.6891s	
4087/30300 (epoch 6.744), train_loss = 1.74701317, grad/param norm = 1.8341e-01, time/batch = 0.6890s	
4088/30300 (epoch 6.746), train_loss = 1.44964829, grad/param norm = 1.6664e-01, time/batch = 0.6896s	
4089/30300 (epoch 6.748), train_loss = 1.65247427, grad/param norm = 1.7421e-01, time/batch = 0.6896s	
4090/30300 (epoch 6.749), train_loss = 1.64472891, grad/param norm = 1.6888e-01, time/batch = 0.7079s	
4091/30300 (epoch 6.751), train_loss = 1.51139564, grad/param norm = 1.6824e-01, time/batch = 0.6936s	
4092/30300 (epoch 6.752), train_loss = 1.58670879, grad/param norm = 1.6827e-01, time/batch = 0.7110s	
4093/30300 (epoch 6.754), train_loss = 1.43987032, grad/param norm = 1.5204e-01, time/batch = 0.7130s	
4094/30300 (epoch 6.756), train_loss = 1.55753913, grad/param norm = 1.7917e-01, time/batch = 0.6923s	
4095/30300 (epoch 6.757), train_loss = 1.65337345, grad/param norm = 1.6980e-01, time/batch = 0.6910s	
4096/30300 (epoch 6.759), train_loss = 1.54352552, grad/param norm = 1.6908e-01, time/batch = 0.6899s	
4097/30300 (epoch 6.761), train_loss = 1.47453267, grad/param norm = 1.6282e-01, time/batch = 0.6914s	
4098/30300 (epoch 6.762), train_loss = 1.40057187, grad/param norm = 1.4984e-01, time/batch = 0.7001s	
4099/30300 (epoch 6.764), train_loss = 1.59112334, grad/param norm = 1.9067e-01, time/batch = 0.6925s	
4100/30300 (epoch 6.766), train_loss = 1.65434337, grad/param norm = 1.6468e-01, time/batch = 0.6954s	
4101/30300 (epoch 6.767), train_loss = 1.75927459, grad/param norm = 1.8591e-01, time/batch = 0.6973s	
4102/30300 (epoch 6.769), train_loss = 1.78082251, grad/param norm = 1.8887e-01, time/batch = 0.6944s	
4103/30300 (epoch 6.771), train_loss = 1.62692753, grad/param norm = 1.5729e-01, time/batch = 0.6907s	
4104/30300 (epoch 6.772), train_loss = 1.62201920, grad/param norm = 1.8609e-01, time/batch = 0.6886s	
4105/30300 (epoch 6.774), train_loss = 1.71319812, grad/param norm = 1.7690e-01, time/batch = 0.6974s	
4106/30300 (epoch 6.776), train_loss = 1.64463872, grad/param norm = 1.7890e-01, time/batch = 0.7045s	
4107/30300 (epoch 6.777), train_loss = 1.63250407, grad/param norm = 1.5760e-01, time/batch = 0.7207s	
4108/30300 (epoch 6.779), train_loss = 1.74335504, grad/param norm = 1.6919e-01, time/batch = 0.6929s	
4109/30300 (epoch 6.781), train_loss = 1.63796458, grad/param norm = 1.7766e-01, time/batch = 0.7005s	
4110/30300 (epoch 6.782), train_loss = 1.55030328, grad/param norm = 1.6072e-01, time/batch = 0.7015s	
4111/30300 (epoch 6.784), train_loss = 1.59919011, grad/param norm = 1.6182e-01, time/batch = 0.7133s	
4112/30300 (epoch 6.785), train_loss = 1.80440668, grad/param norm = 1.7945e-01, time/batch = 0.6963s	
4113/30300 (epoch 6.787), train_loss = 1.52226411, grad/param norm = 1.8419e-01, time/batch = 0.6942s	
4114/30300 (epoch 6.789), train_loss = 1.97742390, grad/param norm = 1.8184e-01, time/batch = 0.6897s	
4115/30300 (epoch 6.790), train_loss = 1.73316979, grad/param norm = 1.7127e-01, time/batch = 0.6908s	
4116/30300 (epoch 6.792), train_loss = 1.53003275, grad/param norm = 1.7675e-01, time/batch = 0.6870s	
4117/30300 (epoch 6.794), train_loss = 1.54300684, grad/param norm = 1.5920e-01, time/batch = 0.6963s	
4118/30300 (epoch 6.795), train_loss = 1.60858171, grad/param norm = 1.6026e-01, time/batch = 0.6892s	
4119/30300 (epoch 6.797), train_loss = 1.76600103, grad/param norm = 1.9514e-01, time/batch = 0.6924s	
4120/30300 (epoch 6.799), train_loss = 1.74019505, grad/param norm = 1.9586e-01, time/batch = 0.6992s	
4121/30300 (epoch 6.800), train_loss = 1.65088830, grad/param norm = 1.8065e-01, time/batch = 0.7215s	
4122/30300 (epoch 6.802), train_loss = 1.86000476, grad/param norm = 1.9181e-01, time/batch = 0.7010s	
4123/30300 (epoch 6.804), train_loss = 1.71395451, grad/param norm = 1.8596e-01, time/batch = 0.6894s	
4124/30300 (epoch 6.805), train_loss = 1.81282111, grad/param norm = 1.9079e-01, time/batch = 0.6937s	
4125/30300 (epoch 6.807), train_loss = 1.70292234, grad/param norm = 1.8735e-01, time/batch = 0.6925s	
4126/30300 (epoch 6.809), train_loss = 1.77402704, grad/param norm = 1.8324e-01, time/batch = 0.6965s	
4127/30300 (epoch 6.810), train_loss = 1.72616613, grad/param norm = 1.7044e-01, time/batch = 0.6980s	
4128/30300 (epoch 6.812), train_loss = 1.56460989, grad/param norm = 1.6890e-01, time/batch = 0.6931s	
4129/30300 (epoch 6.814), train_loss = 1.65953521, grad/param norm = 1.6418e-01, time/batch = 0.6945s	
4130/30300 (epoch 6.815), train_loss = 1.65965787, grad/param norm = 1.7493e-01, time/batch = 0.6904s	
4131/30300 (epoch 6.817), train_loss = 1.77811845, grad/param norm = 1.7908e-01, time/batch = 0.6906s	
4132/30300 (epoch 6.818), train_loss = 1.66826693, grad/param norm = 1.6697e-01, time/batch = 0.6867s	
4133/30300 (epoch 6.820), train_loss = 1.90564900, grad/param norm = 1.8274e-01, time/batch = 0.6912s	
4134/30300 (epoch 6.822), train_loss = 1.87606364, grad/param norm = 1.8992e-01, time/batch = 0.6916s	
4135/30300 (epoch 6.823), train_loss = 1.92176105, grad/param norm = 1.8913e-01, time/batch = 0.7140s	
4136/30300 (epoch 6.825), train_loss = 1.74974477, grad/param norm = 1.8078e-01, time/batch = 0.7081s	
4137/30300 (epoch 6.827), train_loss = 1.59768140, grad/param norm = 1.8281e-01, time/batch = 0.6879s	
4138/30300 (epoch 6.828), train_loss = 1.69778551, grad/param norm = 1.5944e-01, time/batch = 0.6909s	
4139/30300 (epoch 6.830), train_loss = 1.66715086, grad/param norm = 1.7303e-01, time/batch = 0.6913s	
4140/30300 (epoch 6.832), train_loss = 1.60669466, grad/param norm = 1.5949e-01, time/batch = 0.6922s	
4141/30300 (epoch 6.833), train_loss = 1.75073882, grad/param norm = 1.7270e-01, time/batch = 0.6900s	
4142/30300 (epoch 6.835), train_loss = 1.64786456, grad/param norm = 1.6887e-01, time/batch = 0.6876s	
4143/30300 (epoch 6.837), train_loss = 1.44697786, grad/param norm = 1.4706e-01, time/batch = 0.6918s	
4144/30300 (epoch 6.838), train_loss = 1.51655059, grad/param norm = 1.6927e-01, time/batch = 0.6918s	
4145/30300 (epoch 6.840), train_loss = 1.63122965, grad/param norm = 1.5916e-01, time/batch = 0.6937s	
4146/30300 (epoch 6.842), train_loss = 1.46500010, grad/param norm = 1.4967e-01, time/batch = 0.7085s	
4147/30300 (epoch 6.843), train_loss = 1.62676006, grad/param norm = 1.6592e-01, time/batch = 0.6970s	
4148/30300 (epoch 6.845), train_loss = 1.53933667, grad/param norm = 1.4234e-01, time/batch = 0.6873s	
4149/30300 (epoch 6.847), train_loss = 1.69099534, grad/param norm = 1.9012e-01, time/batch = 0.6869s	
4150/30300 (epoch 6.848), train_loss = 1.79138729, grad/param norm = 1.7480e-01, time/batch = 0.6883s	
4151/30300 (epoch 6.850), train_loss = 1.56301448, grad/param norm = 1.5587e-01, time/batch = 0.6889s	
4152/30300 (epoch 6.851), train_loss = 1.87381409, grad/param norm = 1.9283e-01, time/batch = 0.6873s	
4153/30300 (epoch 6.853), train_loss = 1.59049446, grad/param norm = 1.7201e-01, time/batch = 0.6871s	
4154/30300 (epoch 6.855), train_loss = 1.57329655, grad/param norm = 1.6950e-01, time/batch = 0.6935s	
4155/30300 (epoch 6.856), train_loss = 1.55768345, grad/param norm = 1.7041e-01, time/batch = 0.7113s	
4156/30300 (epoch 6.858), train_loss = 1.55918186, grad/param norm = 1.6252e-01, time/batch = 0.7031s	
4157/30300 (epoch 6.860), train_loss = 1.62136051, grad/param norm = 1.6287e-01, time/batch = 0.7105s	
4158/30300 (epoch 6.861), train_loss = 1.81473473, grad/param norm = 1.7122e-01, time/batch = 0.7023s	
4159/30300 (epoch 6.863), train_loss = 1.67793558, grad/param norm = 1.7264e-01, time/batch = 0.6897s	
4160/30300 (epoch 6.865), train_loss = 1.89433862, grad/param norm = 1.7806e-01, time/batch = 0.6927s	
4161/30300 (epoch 6.866), train_loss = 1.69908995, grad/param norm = 1.6922e-01, time/batch = 0.7004s	
4162/30300 (epoch 6.868), train_loss = 1.65838876, grad/param norm = 1.6367e-01, time/batch = 0.7052s	
4163/30300 (epoch 6.870), train_loss = 1.59831241, grad/param norm = 1.5673e-01, time/batch = 0.7093s	
4164/30300 (epoch 6.871), train_loss = 1.53234466, grad/param norm = 1.5287e-01, time/batch = 0.7211s	
4165/30300 (epoch 6.873), train_loss = 1.66930419, grad/param norm = 1.6140e-01, time/batch = 0.7183s	
4166/30300 (epoch 6.875), train_loss = 1.46322716, grad/param norm = 1.5268e-01, time/batch = 0.7078s	
4167/30300 (epoch 6.876), train_loss = 1.46982713, grad/param norm = 1.5221e-01, time/batch = 0.6875s	
4168/30300 (epoch 6.878), train_loss = 1.39846402, grad/param norm = 1.6408e-01, time/batch = 0.6891s	
4169/30300 (epoch 6.880), train_loss = 1.50480486, grad/param norm = 1.6477e-01, time/batch = 0.6907s	
4170/30300 (epoch 6.881), train_loss = 1.84695663, grad/param norm = 1.6932e-01, time/batch = 0.6899s	
4171/30300 (epoch 6.883), train_loss = 1.71657473, grad/param norm = 1.8010e-01, time/batch = 0.6925s	
4172/30300 (epoch 6.884), train_loss = 1.48964778, grad/param norm = 1.6315e-01, time/batch = 0.6943s	
4173/30300 (epoch 6.886), train_loss = 1.59841923, grad/param norm = 1.6622e-01, time/batch = 0.6929s	
4174/30300 (epoch 6.888), train_loss = 1.68083631, grad/param norm = 1.7138e-01, time/batch = 0.6865s	
4175/30300 (epoch 6.889), train_loss = 1.58362012, grad/param norm = 1.6991e-01, time/batch = 0.6933s	
4176/30300 (epoch 6.891), train_loss = 1.54735835, grad/param norm = 1.6836e-01, time/batch = 0.6883s	
4177/30300 (epoch 6.893), train_loss = 1.87746160, grad/param norm = 1.8715e-01, time/batch = 0.6884s	
4178/30300 (epoch 6.894), train_loss = 1.71766978, grad/param norm = 1.6352e-01, time/batch = 0.6872s	
4179/30300 (epoch 6.896), train_loss = 1.41618356, grad/param norm = 1.5613e-01, time/batch = 0.6896s	
4180/30300 (epoch 6.898), train_loss = 1.41858758, grad/param norm = 1.7075e-01, time/batch = 0.6915s	
4181/30300 (epoch 6.899), train_loss = 1.56633599, grad/param norm = 1.6378e-01, time/batch = 0.6921s	
4182/30300 (epoch 6.901), train_loss = 1.63903887, grad/param norm = 1.6964e-01, time/batch = 0.6889s	
4183/30300 (epoch 6.903), train_loss = 1.68352858, grad/param norm = 1.7572e-01, time/batch = 0.6929s	
4184/30300 (epoch 6.904), train_loss = 1.58427003, grad/param norm = 1.5884e-01, time/batch = 0.7050s	
4185/30300 (epoch 6.906), train_loss = 1.75858302, grad/param norm = 1.5973e-01, time/batch = 0.6906s	
4186/30300 (epoch 6.908), train_loss = 1.51409912, grad/param norm = 1.5560e-01, time/batch = 0.6911s	
4187/30300 (epoch 6.909), train_loss = 1.60510960, grad/param norm = 1.7894e-01, time/batch = 0.6878s	
4188/30300 (epoch 6.911), train_loss = 1.61203087, grad/param norm = 1.7076e-01, time/batch = 0.6920s	
4189/30300 (epoch 6.913), train_loss = 1.63905187, grad/param norm = 1.7711e-01, time/batch = 0.6911s	
4190/30300 (epoch 6.914), train_loss = 1.61857981, grad/param norm = 1.8276e-01, time/batch = 0.6915s	
4191/30300 (epoch 6.916), train_loss = 1.65224091, grad/param norm = 1.5860e-01, time/batch = 0.6963s	
4192/30300 (epoch 6.917), train_loss = 1.54328936, grad/param norm = 1.5812e-01, time/batch = 0.6937s	
4193/30300 (epoch 6.919), train_loss = 1.65645513, grad/param norm = 1.5938e-01, time/batch = 0.6879s	
4194/30300 (epoch 6.921), train_loss = 1.66735337, grad/param norm = 1.6880e-01, time/batch = 0.7115s	
4195/30300 (epoch 6.922), train_loss = 1.72819460, grad/param norm = 1.7263e-01, time/batch = 0.7036s	
4196/30300 (epoch 6.924), train_loss = 1.62125802, grad/param norm = 1.7231e-01, time/batch = 0.6979s	
4197/30300 (epoch 6.926), train_loss = 1.59727316, grad/param norm = 1.6617e-01, time/batch = 0.7215s	
4198/30300 (epoch 6.927), train_loss = 1.61318533, grad/param norm = 1.7615e-01, time/batch = 0.6983s	
4199/30300 (epoch 6.929), train_loss = 1.61046696, grad/param norm = 1.7869e-01, time/batch = 0.7073s	
4200/30300 (epoch 6.931), train_loss = 1.75153643, grad/param norm = 1.9521e-01, time/batch = 0.7042s	
4201/30300 (epoch 6.932), train_loss = 1.54894477, grad/param norm = 1.8013e-01, time/batch = 0.7012s	
4202/30300 (epoch 6.934), train_loss = 1.62303116, grad/param norm = 1.5980e-01, time/batch = 0.6862s	
4203/30300 (epoch 6.936), train_loss = 1.57939896, grad/param norm = 1.5987e-01, time/batch = 0.6859s	
4204/30300 (epoch 6.937), train_loss = 1.61115173, grad/param norm = 1.6543e-01, time/batch = 0.6857s	
4205/30300 (epoch 6.939), train_loss = 1.76752196, grad/param norm = 1.5959e-01, time/batch = 0.6846s	
4206/30300 (epoch 6.941), train_loss = 1.64674246, grad/param norm = 1.7813e-01, time/batch = 0.6843s	
4207/30300 (epoch 6.942), train_loss = 1.59775797, grad/param norm = 1.7263e-01, time/batch = 0.6865s	
4208/30300 (epoch 6.944), train_loss = 1.48391787, grad/param norm = 1.5142e-01, time/batch = 0.6903s	
4209/30300 (epoch 6.946), train_loss = 1.81133629, grad/param norm = 1.9932e-01, time/batch = 0.6851s	
4210/30300 (epoch 6.947), train_loss = 1.84235793, grad/param norm = 1.9066e-01, time/batch = 0.6896s	
4211/30300 (epoch 6.949), train_loss = 1.89433400, grad/param norm = 1.9121e-01, time/batch = 0.7185s	
4212/30300 (epoch 6.950), train_loss = 1.76606882, grad/param norm = 1.7438e-01, time/batch = 0.7069s	
4213/30300 (epoch 6.952), train_loss = 1.77593589, grad/param norm = 1.7426e-01, time/batch = 0.6861s	
4214/30300 (epoch 6.954), train_loss = 1.91149958, grad/param norm = 1.7986e-01, time/batch = 0.6842s	
4215/30300 (epoch 6.955), train_loss = 1.56232620, grad/param norm = 1.6847e-01, time/batch = 0.6868s	
4216/30300 (epoch 6.957), train_loss = 1.69929709, grad/param norm = 1.6510e-01, time/batch = 0.6838s	
4217/30300 (epoch 6.959), train_loss = 1.66846995, grad/param norm = 1.6922e-01, time/batch = 0.6850s	
4218/30300 (epoch 6.960), train_loss = 1.61246211, grad/param norm = 1.6113e-01, time/batch = 0.6841s	
4219/30300 (epoch 6.962), train_loss = 1.58000437, grad/param norm = 1.8849e-01, time/batch = 0.6852s	
4220/30300 (epoch 6.964), train_loss = 1.67118936, grad/param norm = 1.8192e-01, time/batch = 0.6871s	
4221/30300 (epoch 6.965), train_loss = 1.55285455, grad/param norm = 1.5957e-01, time/batch = 0.6863s	
4222/30300 (epoch 6.967), train_loss = 1.64342692, grad/param norm = 1.6811e-01, time/batch = 0.6860s	
4223/30300 (epoch 6.969), train_loss = 1.62599796, grad/param norm = 1.8592e-01, time/batch = 0.6891s	
4224/30300 (epoch 6.970), train_loss = 1.55163417, grad/param norm = 1.5235e-01, time/batch = 0.6854s	
4225/30300 (epoch 6.972), train_loss = 1.52783542, grad/param norm = 1.5951e-01, time/batch = 0.7005s	
4226/30300 (epoch 6.974), train_loss = 1.82010621, grad/param norm = 1.7926e-01, time/batch = 0.7189s	
4227/30300 (epoch 6.975), train_loss = 1.83620628, grad/param norm = 1.9580e-01, time/batch = 0.6919s	
4228/30300 (epoch 6.977), train_loss = 1.68444725, grad/param norm = 1.7022e-01, time/batch = 0.6852s	
4229/30300 (epoch 6.979), train_loss = 1.69713017, grad/param norm = 1.6529e-01, time/batch = 0.6877s	
4230/30300 (epoch 6.980), train_loss = 1.69690323, grad/param norm = 1.8254e-01, time/batch = 0.6850s	
4231/30300 (epoch 6.982), train_loss = 1.71198040, grad/param norm = 1.6463e-01, time/batch = 0.6891s	
4232/30300 (epoch 6.983), train_loss = 1.77522209, grad/param norm = 1.7627e-01, time/batch = 0.6835s	
4233/30300 (epoch 6.985), train_loss = 1.66170644, grad/param norm = 1.7565e-01, time/batch = 0.6850s	
4234/30300 (epoch 6.987), train_loss = 1.57928998, grad/param norm = 1.4847e-01, time/batch = 0.6847s	
4235/30300 (epoch 6.988), train_loss = 1.78665699, grad/param norm = 1.8368e-01, time/batch = 0.6848s	
4236/30300 (epoch 6.990), train_loss = 1.44260850, grad/param norm = 1.5200e-01, time/batch = 0.6882s	
4237/30300 (epoch 6.992), train_loss = 1.66953507, grad/param norm = 1.4879e-01, time/batch = 0.6918s	
4238/30300 (epoch 6.993), train_loss = 1.81966532, grad/param norm = 1.8652e-01, time/batch = 0.6858s	
4239/30300 (epoch 6.995), train_loss = 1.71715363, grad/param norm = 1.6944e-01, time/batch = 0.6902s	
4240/30300 (epoch 6.997), train_loss = 1.67249703, grad/param norm = 1.6307e-01, time/batch = 0.7208s	
4241/30300 (epoch 6.998), train_loss = 1.76639392, grad/param norm = 1.8535e-01, time/batch = 0.7110s	
4242/30300 (epoch 7.000), train_loss = 1.56798194, grad/param norm = 1.7664e-01, time/batch = 0.6975s	
4243/30300 (epoch 7.002), train_loss = 1.63593991, grad/param norm = 1.7355e-01, time/batch = 0.7186s	
4244/30300 (epoch 7.003), train_loss = 1.67591366, grad/param norm = 1.7744e-01, time/batch = 0.7097s	
4245/30300 (epoch 7.005), train_loss = 1.63378934, grad/param norm = 1.7592e-01, time/batch = 0.6911s	
4246/30300 (epoch 7.007), train_loss = 1.76627623, grad/param norm = 1.6549e-01, time/batch = 0.6895s	
4247/30300 (epoch 7.008), train_loss = 1.57372472, grad/param norm = 1.6932e-01, time/batch = 0.7175s	
4248/30300 (epoch 7.010), train_loss = 1.58789230, grad/param norm = 1.8698e-01, time/batch = 0.7009s	
4249/30300 (epoch 7.012), train_loss = 1.53988352, grad/param norm = 1.6158e-01, time/batch = 0.6912s	
4250/30300 (epoch 7.013), train_loss = 1.66287081, grad/param norm = 1.7442e-01, time/batch = 0.6957s	
4251/30300 (epoch 7.015), train_loss = 1.58558232, grad/param norm = 1.6303e-01, time/batch = 0.6946s	
4252/30300 (epoch 7.017), train_loss = 1.49563192, grad/param norm = 1.7132e-01, time/batch = 0.6975s	
4253/30300 (epoch 7.018), train_loss = 1.64365576, grad/param norm = 1.6055e-01, time/batch = 0.6900s	
4254/30300 (epoch 7.020), train_loss = 1.79814975, grad/param norm = 1.7290e-01, time/batch = 0.7167s	
4255/30300 (epoch 7.021), train_loss = 1.79343407, grad/param norm = 1.7556e-01, time/batch = 0.7184s	
4256/30300 (epoch 7.023), train_loss = 1.53650468, grad/param norm = 1.7621e-01, time/batch = 0.7036s	
4257/30300 (epoch 7.025), train_loss = 1.56927477, grad/param norm = 1.8595e-01, time/batch = 0.6966s	
4258/30300 (epoch 7.026), train_loss = 1.67003484, grad/param norm = 1.7643e-01, time/batch = 0.6977s	
4259/30300 (epoch 7.028), train_loss = 1.65754852, grad/param norm = 1.6914e-01, time/batch = 0.6924s	
4260/30300 (epoch 7.030), train_loss = 1.50796302, grad/param norm = 1.7181e-01, time/batch = 0.6937s	
4261/30300 (epoch 7.031), train_loss = 1.61751288, grad/param norm = 1.8545e-01, time/batch = 0.6925s	
4262/30300 (epoch 7.033), train_loss = 1.61893560, grad/param norm = 1.6895e-01, time/batch = 0.6958s	
4263/30300 (epoch 7.035), train_loss = 1.69453818, grad/param norm = 1.6579e-01, time/batch = 0.6901s	
4264/30300 (epoch 7.036), train_loss = 1.71064530, grad/param norm = 1.7373e-01, time/batch = 0.6885s	
4265/30300 (epoch 7.038), train_loss = 1.63837570, grad/param norm = 1.6519e-01, time/batch = 0.6920s	
4266/30300 (epoch 7.040), train_loss = 1.32603872, grad/param norm = 1.5897e-01, time/batch = 0.6893s	
4267/30300 (epoch 7.041), train_loss = 1.38495973, grad/param norm = 1.5894e-01, time/batch = 0.6896s	
4268/30300 (epoch 7.043), train_loss = 1.70908962, grad/param norm = 1.6216e-01, time/batch = 0.6935s	
4269/30300 (epoch 7.045), train_loss = 1.56872841, grad/param norm = 1.6703e-01, time/batch = 0.6951s	
4270/30300 (epoch 7.046), train_loss = 1.69745297, grad/param norm = 1.8168e-01, time/batch = 0.6944s	
4271/30300 (epoch 7.048), train_loss = 1.65951111, grad/param norm = 1.8158e-01, time/batch = 0.6905s	
4272/30300 (epoch 7.050), train_loss = 1.70506547, grad/param norm = 1.7159e-01, time/batch = 0.6894s	
4273/30300 (epoch 7.051), train_loss = 1.62799497, grad/param norm = 1.5392e-01, time/batch = 0.6872s	
4274/30300 (epoch 7.053), train_loss = 1.51520215, grad/param norm = 1.7271e-01, time/batch = 0.6942s	
4275/30300 (epoch 7.054), train_loss = 1.56171512, grad/param norm = 1.7455e-01, time/batch = 0.6981s	
4276/30300 (epoch 7.056), train_loss = 1.50839809, grad/param norm = 1.7277e-01, time/batch = 0.6922s	
4277/30300 (epoch 7.058), train_loss = 1.63189806, grad/param norm = 1.7723e-01, time/batch = 0.6907s	
4278/30300 (epoch 7.059), train_loss = 1.61522125, grad/param norm = 1.6814e-01, time/batch = 0.6965s	
4279/30300 (epoch 7.061), train_loss = 1.80908174, grad/param norm = 1.8411e-01, time/batch = 0.7032s	
4280/30300 (epoch 7.063), train_loss = 1.58939101, grad/param norm = 1.6702e-01, time/batch = 0.7159s	
4281/30300 (epoch 7.064), train_loss = 1.72734176, grad/param norm = 1.7426e-01, time/batch = 0.7164s	
4282/30300 (epoch 7.066), train_loss = 1.61609925, grad/param norm = 1.6687e-01, time/batch = 0.7099s	
4283/30300 (epoch 7.068), train_loss = 1.48163118, grad/param norm = 1.5581e-01, time/batch = 0.7223s	
4284/30300 (epoch 7.069), train_loss = 1.75059894, grad/param norm = 1.7126e-01, time/batch = 0.7086s	
4285/30300 (epoch 7.071), train_loss = 1.68699050, grad/param norm = 1.8325e-01, time/batch = 0.7075s	
4286/30300 (epoch 7.073), train_loss = 1.71782453, grad/param norm = 1.8333e-01, time/batch = 0.7029s	
4287/30300 (epoch 7.074), train_loss = 1.65884934, grad/param norm = 1.6670e-01, time/batch = 0.7025s	
4288/30300 (epoch 7.076), train_loss = 1.60684048, grad/param norm = 1.6446e-01, time/batch = 0.6911s	
4289/30300 (epoch 7.078), train_loss = 1.49911647, grad/param norm = 1.7309e-01, time/batch = 0.6936s	
4290/30300 (epoch 7.079), train_loss = 1.49073820, grad/param norm = 1.4732e-01, time/batch = 0.6991s	
4291/30300 (epoch 7.081), train_loss = 1.70853356, grad/param norm = 1.8225e-01, time/batch = 0.6928s	
4292/30300 (epoch 7.083), train_loss = 1.83153730, grad/param norm = 1.8982e-01, time/batch = 0.6889s	
4293/30300 (epoch 7.084), train_loss = 1.54680398, grad/param norm = 1.7795e-01, time/batch = 0.6927s	
4294/30300 (epoch 7.086), train_loss = 1.59165200, grad/param norm = 1.6676e-01, time/batch = 0.6937s	
4295/30300 (epoch 7.087), train_loss = 1.49280762, grad/param norm = 1.4919e-01, time/batch = 0.6890s	
4296/30300 (epoch 7.089), train_loss = 1.59164496, grad/param norm = 1.7267e-01, time/batch = 0.6906s	
4297/30300 (epoch 7.091), train_loss = 1.73890472, grad/param norm = 1.8283e-01, time/batch = 0.7208s	
4298/30300 (epoch 7.092), train_loss = 1.56335815, grad/param norm = 1.6629e-01, time/batch = 0.7047s	
4299/30300 (epoch 7.094), train_loss = 1.84256540, grad/param norm = 1.7955e-01, time/batch = 0.6914s	
4300/30300 (epoch 7.096), train_loss = 1.65906456, grad/param norm = 1.6767e-01, time/batch = 0.6912s	
4301/30300 (epoch 7.097), train_loss = 1.48037877, grad/param norm = 1.8588e-01, time/batch = 0.6940s	
4302/30300 (epoch 7.099), train_loss = 1.79600814, grad/param norm = 1.6790e-01, time/batch = 0.6913s	
4303/30300 (epoch 7.101), train_loss = 1.91177829, grad/param norm = 1.8334e-01, time/batch = 0.6888s	
4304/30300 (epoch 7.102), train_loss = 1.67678256, grad/param norm = 1.8391e-01, time/batch = 0.6939s	
4305/30300 (epoch 7.104), train_loss = 1.55957188, grad/param norm = 1.7649e-01, time/batch = 0.6906s	
4306/30300 (epoch 7.106), train_loss = 1.65934733, grad/param norm = 1.7357e-01, time/batch = 0.6905s	
4307/30300 (epoch 7.107), train_loss = 1.62644559, grad/param norm = 1.6674e-01, time/batch = 0.6901s	
4308/30300 (epoch 7.109), train_loss = 1.74743617, grad/param norm = 1.8179e-01, time/batch = 0.6896s	
4309/30300 (epoch 7.111), train_loss = 1.75810176, grad/param norm = 1.8510e-01, time/batch = 0.6864s	
4310/30300 (epoch 7.112), train_loss = 1.65334479, grad/param norm = 1.5892e-01, time/batch = 0.6909s	
4311/30300 (epoch 7.114), train_loss = 1.59980807, grad/param norm = 1.6019e-01, time/batch = 0.7145s	
4312/30300 (epoch 7.116), train_loss = 1.67619550, grad/param norm = 1.6063e-01, time/batch = 0.7140s	
4313/30300 (epoch 7.117), train_loss = 1.61141089, grad/param norm = 1.6074e-01, time/batch = 0.6945s	
4314/30300 (epoch 7.119), train_loss = 1.51816821, grad/param norm = 1.7649e-01, time/batch = 0.6915s	
4315/30300 (epoch 7.120), train_loss = 1.62394464, grad/param norm = 1.7390e-01, time/batch = 0.6890s	
4316/30300 (epoch 7.122), train_loss = 1.72351039, grad/param norm = 1.6764e-01, time/batch = 0.6872s	
4317/30300 (epoch 7.124), train_loss = 1.86015849, grad/param norm = 2.0169e-01, time/batch = 0.6916s	
4318/30300 (epoch 7.125), train_loss = 1.47452332, grad/param norm = 1.6096e-01, time/batch = 0.6893s	
4319/30300 (epoch 7.127), train_loss = 1.67055223, grad/param norm = 1.7852e-01, time/batch = 0.6911s	
4320/30300 (epoch 7.129), train_loss = 1.77634997, grad/param norm = 1.7649e-01, time/batch = 0.6909s	
4321/30300 (epoch 7.130), train_loss = 1.75318009, grad/param norm = 1.6381e-01, time/batch = 0.6884s	
4322/30300 (epoch 7.132), train_loss = 1.68033267, grad/param norm = 2.2991e-01, time/batch = 0.6884s	
4323/30300 (epoch 7.134), train_loss = 1.49797733, grad/param norm = 1.7496e-01, time/batch = 0.6873s	
4324/30300 (epoch 7.135), train_loss = 1.62845105, grad/param norm = 2.0400e-01, time/batch = 0.6889s	
4325/30300 (epoch 7.137), train_loss = 1.77471617, grad/param norm = 1.7663e-01, time/batch = 0.6892s	
4326/30300 (epoch 7.139), train_loss = 1.61184790, grad/param norm = 1.7411e-01, time/batch = 0.6975s	
4327/30300 (epoch 7.140), train_loss = 1.85554910, grad/param norm = 1.8395e-01, time/batch = 0.7078s	
4328/30300 (epoch 7.142), train_loss = 1.87945324, grad/param norm = 1.9636e-01, time/batch = 0.6883s	
4329/30300 (epoch 7.144), train_loss = 1.72330661, grad/param norm = 2.0780e-01, time/batch = 0.7042s	
4330/30300 (epoch 7.145), train_loss = 1.79978499, grad/param norm = 1.9415e-01, time/batch = 0.6944s	
4331/30300 (epoch 7.147), train_loss = 1.69051843, grad/param norm = 1.6750e-01, time/batch = 0.7008s	
4332/30300 (epoch 7.149), train_loss = 1.85363423, grad/param norm = 1.6843e-01, time/batch = 0.6956s	
4333/30300 (epoch 7.150), train_loss = 1.80581570, grad/param norm = 1.6407e-01, time/batch = 0.6917s	
4334/30300 (epoch 7.152), train_loss = 1.60055221, grad/param norm = 1.7934e-01, time/batch = 0.6902s	
4335/30300 (epoch 7.153), train_loss = 1.69045543, grad/param norm = 1.7816e-01, time/batch = 0.6888s	
4336/30300 (epoch 7.155), train_loss = 1.43080611, grad/param norm = 1.5218e-01, time/batch = 0.6924s	
4337/30300 (epoch 7.157), train_loss = 1.62761412, grad/param norm = 1.7877e-01, time/batch = 0.7012s	
4338/30300 (epoch 7.158), train_loss = 1.71937266, grad/param norm = 1.7045e-01, time/batch = 0.6925s	
4339/30300 (epoch 7.160), train_loss = 1.56249214, grad/param norm = 1.6329e-01, time/batch = 0.7077s	
4340/30300 (epoch 7.162), train_loss = 1.52975645, grad/param norm = 1.5468e-01, time/batch = 0.7094s	
4341/30300 (epoch 7.163), train_loss = 1.56938179, grad/param norm = 2.1286e-01, time/batch = 0.6989s	
4342/30300 (epoch 7.165), train_loss = 1.67936931, grad/param norm = 1.6392e-01, time/batch = 0.6974s	
4343/30300 (epoch 7.167), train_loss = 1.68753550, grad/param norm = 1.8994e-01, time/batch = 0.6989s	
4344/30300 (epoch 7.168), train_loss = 1.61450601, grad/param norm = 1.9399e-01, time/batch = 0.6947s	
4345/30300 (epoch 7.170), train_loss = 1.68639951, grad/param norm = 1.7324e-01, time/batch = 0.7007s	
4346/30300 (epoch 7.172), train_loss = 1.59239750, grad/param norm = 1.6500e-01, time/batch = 0.6953s	
4347/30300 (epoch 7.173), train_loss = 1.71121374, grad/param norm = 1.7963e-01, time/batch = 0.6909s	
4348/30300 (epoch 7.175), train_loss = 1.60554340, grad/param norm = 1.5496e-01, time/batch = 0.6985s	
4349/30300 (epoch 7.177), train_loss = 1.66364262, grad/param norm = 1.7065e-01, time/batch = 0.6934s	
4350/30300 (epoch 7.178), train_loss = 1.39972696, grad/param norm = 1.6719e-01, time/batch = 0.6954s	
4351/30300 (epoch 7.180), train_loss = 1.53995010, grad/param norm = 1.5492e-01, time/batch = 0.6918s	
4352/30300 (epoch 7.182), train_loss = 1.54265156, grad/param norm = 1.7257e-01, time/batch = 0.6866s	
4353/30300 (epoch 7.183), train_loss = 1.51333467, grad/param norm = 1.6224e-01, time/batch = 0.6893s	
4354/30300 (epoch 7.185), train_loss = 1.93972971, grad/param norm = 1.7751e-01, time/batch = 0.6887s	
4355/30300 (epoch 7.186), train_loss = 1.88914090, grad/param norm = 1.9003e-01, time/batch = 0.6878s	
4356/30300 (epoch 7.188), train_loss = 1.70261949, grad/param norm = 1.8128e-01, time/batch = 0.7009s	
4357/30300 (epoch 7.190), train_loss = 1.53401226, grad/param norm = 1.6018e-01, time/batch = 0.6898s	
4358/30300 (epoch 7.191), train_loss = 1.74001345, grad/param norm = 1.7243e-01, time/batch = 0.6990s	
4359/30300 (epoch 7.193), train_loss = 1.48320872, grad/param norm = 1.6171e-01, time/batch = 0.7208s	
4360/30300 (epoch 7.195), train_loss = 1.66539034, grad/param norm = 1.6593e-01, time/batch = 0.6897s	
4361/30300 (epoch 7.196), train_loss = 1.67476552, grad/param norm = 1.7401e-01, time/batch = 0.6907s	
4362/30300 (epoch 7.198), train_loss = 1.41757876, grad/param norm = 1.5657e-01, time/batch = 0.6864s	
4363/30300 (epoch 7.200), train_loss = 1.59537955, grad/param norm = 1.6870e-01, time/batch = 0.6869s	
4364/30300 (epoch 7.201), train_loss = 1.75817207, grad/param norm = 1.7918e-01, time/batch = 0.7108s	
4365/30300 (epoch 7.203), train_loss = 1.61457598, grad/param norm = 1.5906e-01, time/batch = 0.6977s	
4366/30300 (epoch 7.205), train_loss = 1.85593905, grad/param norm = 1.7523e-01, time/batch = 0.6912s	
4367/30300 (epoch 7.206), train_loss = 1.86931706, grad/param norm = 1.8451e-01, time/batch = 0.6866s	
4368/30300 (epoch 7.208), train_loss = 1.79778054, grad/param norm = 1.8408e-01, time/batch = 0.6865s	
4369/30300 (epoch 7.210), train_loss = 1.63982294, grad/param norm = 1.4967e-01, time/batch = 0.6874s	
4370/30300 (epoch 7.211), train_loss = 1.67358770, grad/param norm = 1.6626e-01, time/batch = 0.6883s	
4371/30300 (epoch 7.213), train_loss = 1.56493835, grad/param norm = 1.5874e-01, time/batch = 0.6851s	
4372/30300 (epoch 7.215), train_loss = 1.43441360, grad/param norm = 1.6783e-01, time/batch = 0.6852s	
4373/30300 (epoch 7.216), train_loss = 1.59350668, grad/param norm = 1.6504e-01, time/batch = 0.7211s	
4374/30300 (epoch 7.218), train_loss = 1.52645137, grad/param norm = 1.5695e-01, time/batch = 0.6994s	
4375/30300 (epoch 7.219), train_loss = 1.44901338, grad/param norm = 1.7608e-01, time/batch = 0.6856s	
4376/30300 (epoch 7.221), train_loss = 1.45858849, grad/param norm = 1.5908e-01, time/batch = 0.6851s	
4377/30300 (epoch 7.223), train_loss = 1.59933146, grad/param norm = 1.5986e-01, time/batch = 0.6847s	
4378/30300 (epoch 7.224), train_loss = 1.43908004, grad/param norm = 1.5947e-01, time/batch = 0.6868s	
4379/30300 (epoch 7.226), train_loss = 1.70928457, grad/param norm = 1.7856e-01, time/batch = 0.6836s	
4380/30300 (epoch 7.228), train_loss = 1.73037783, grad/param norm = 1.6331e-01, time/batch = 0.6852s	
4381/30300 (epoch 7.229), train_loss = 1.53613498, grad/param norm = 1.6510e-01, time/batch = 0.6846s	
4382/30300 (epoch 7.231), train_loss = 1.63121876, grad/param norm = 1.6708e-01, time/batch = 0.6867s	
4383/30300 (epoch 7.233), train_loss = 1.54499200, grad/param norm = 1.6017e-01, time/batch = 0.6866s	
4384/30300 (epoch 7.234), train_loss = 1.70829389, grad/param norm = 1.7280e-01, time/batch = 0.6871s	
4385/30300 (epoch 7.236), train_loss = 1.55085539, grad/param norm = 1.8316e-01, time/batch = 0.6901s	
4386/30300 (epoch 7.238), train_loss = 1.70065122, grad/param norm = 1.8945e-01, time/batch = 0.6889s	
4387/30300 (epoch 7.239), train_loss = 1.66382022, grad/param norm = 1.7065e-01, time/batch = 0.7056s	
4388/30300 (epoch 7.241), train_loss = 1.67634262, grad/param norm = 1.7138e-01, time/batch = 0.7153s	
4389/30300 (epoch 7.243), train_loss = 1.63816521, grad/param norm = 1.7652e-01, time/batch = 0.6856s	
4390/30300 (epoch 7.244), train_loss = 1.93025650, grad/param norm = 1.7777e-01, time/batch = 0.6862s	
4391/30300 (epoch 7.246), train_loss = 1.61809979, grad/param norm = 1.7569e-01, time/batch = 0.6870s	
4392/30300 (epoch 7.248), train_loss = 1.66009494, grad/param norm = 1.6139e-01, time/batch = 0.6957s	
4393/30300 (epoch 7.249), train_loss = 1.46694837, grad/param norm = 1.5875e-01, time/batch = 0.6940s	
4394/30300 (epoch 7.251), train_loss = 1.52620097, grad/param norm = 1.6590e-01, time/batch = 0.6849s	
4395/30300 (epoch 7.252), train_loss = 1.77848558, grad/param norm = 1.6888e-01, time/batch = 0.6820s	
4396/30300 (epoch 7.254), train_loss = 1.72955082, grad/param norm = 1.8421e-01, time/batch = 0.6849s	
4397/30300 (epoch 7.256), train_loss = 1.64989891, grad/param norm = 1.5826e-01, time/batch = 0.6913s	
4398/30300 (epoch 7.257), train_loss = 1.75633383, grad/param norm = 1.7482e-01, time/batch = 0.6849s	
4399/30300 (epoch 7.259), train_loss = 1.68496631, grad/param norm = 1.6775e-01, time/batch = 0.6889s	
4400/30300 (epoch 7.261), train_loss = 1.75872658, grad/param norm = 1.6509e-01, time/batch = 0.6981s	
4401/30300 (epoch 7.262), train_loss = 1.61265463, grad/param norm = 1.5919e-01, time/batch = 0.6960s	
4402/30300 (epoch 7.264), train_loss = 1.63325933, grad/param norm = 1.6181e-01, time/batch = 0.7216s	
4403/30300 (epoch 7.266), train_loss = 1.54318671, grad/param norm = 1.5714e-01, time/batch = 0.6988s	
4404/30300 (epoch 7.267), train_loss = 1.82060226, grad/param norm = 1.8982e-01, time/batch = 0.6844s	
4405/30300 (epoch 7.269), train_loss = 1.62987137, grad/param norm = 1.6785e-01, time/batch = 0.6838s	
4406/30300 (epoch 7.271), train_loss = 1.63501228, grad/param norm = 1.7048e-01, time/batch = 0.6871s	
4407/30300 (epoch 7.272), train_loss = 1.65410122, grad/param norm = 1.6362e-01, time/batch = 0.6876s	
4408/30300 (epoch 7.274), train_loss = 1.80285001, grad/param norm = 1.7012e-01, time/batch = 0.6858s	
4409/30300 (epoch 7.276), train_loss = 1.76190992, grad/param norm = 1.7535e-01, time/batch = 0.6869s	
4410/30300 (epoch 7.277), train_loss = 1.56094643, grad/param norm = 1.6030e-01, time/batch = 0.6857s	
4411/30300 (epoch 7.279), train_loss = 1.66314545, grad/param norm = 1.6265e-01, time/batch = 0.6877s	
4412/30300 (epoch 7.281), train_loss = 1.69566419, grad/param norm = 1.6167e-01, time/batch = 0.6965s	
4413/30300 (epoch 7.282), train_loss = 1.55138630, grad/param norm = 1.5835e-01, time/batch = 0.7073s	
4414/30300 (epoch 7.284), train_loss = 1.85599627, grad/param norm = 1.9664e-01, time/batch = 0.6889s	
4415/30300 (epoch 7.285), train_loss = 1.65774999, grad/param norm = 1.7471e-01, time/batch = 0.6984s	
4416/30300 (epoch 7.287), train_loss = 1.64119958, grad/param norm = 1.6539e-01, time/batch = 0.7194s	
4417/30300 (epoch 7.289), train_loss = 1.71038016, grad/param norm = 1.7422e-01, time/batch = 0.7180s	
4418/30300 (epoch 7.290), train_loss = 1.35246566, grad/param norm = 1.4227e-01, time/batch = 0.7047s	
4419/30300 (epoch 7.292), train_loss = 1.53499042, grad/param norm = 1.4976e-01, time/batch = 0.7058s	
4420/30300 (epoch 7.294), train_loss = 1.79232310, grad/param norm = 1.5797e-01, time/batch = 0.7176s	
4421/30300 (epoch 7.295), train_loss = 1.59491643, grad/param norm = 1.4443e-01, time/batch = 0.6905s	
4422/30300 (epoch 7.297), train_loss = 1.55046907, grad/param norm = 1.6069e-01, time/batch = 0.6918s	
4423/30300 (epoch 7.299), train_loss = 1.61292242, grad/param norm = 1.7677e-01, time/batch = 0.7104s	
4424/30300 (epoch 7.300), train_loss = 1.65231994, grad/param norm = 1.5446e-01, time/batch = 0.6922s	
4425/30300 (epoch 7.302), train_loss = 1.54061338, grad/param norm = 1.6654e-01, time/batch = 0.6864s	
4426/30300 (epoch 7.304), train_loss = 1.47382660, grad/param norm = 1.4996e-01, time/batch = 0.6890s	
4427/30300 (epoch 7.305), train_loss = 1.57120130, grad/param norm = 1.5604e-01, time/batch = 0.6864s	
4428/30300 (epoch 7.307), train_loss = 1.59940870, grad/param norm = 1.6074e-01, time/batch = 0.6910s	
4429/30300 (epoch 7.309), train_loss = 1.70544571, grad/param norm = 1.6195e-01, time/batch = 0.6927s	
4430/30300 (epoch 7.310), train_loss = 1.56020290, grad/param norm = 1.5936e-01, time/batch = 0.7058s	
4431/30300 (epoch 7.312), train_loss = 1.66229729, grad/param norm = 1.5506e-01, time/batch = 0.7163s	
4432/30300 (epoch 7.314), train_loss = 1.65654692, grad/param norm = 1.5983e-01, time/batch = 0.6886s	
4433/30300 (epoch 7.315), train_loss = 1.70307397, grad/param norm = 1.7124e-01, time/batch = 0.6898s	
4434/30300 (epoch 7.317), train_loss = 1.72920169, grad/param norm = 1.8095e-01, time/batch = 0.6942s	
4435/30300 (epoch 7.318), train_loss = 1.82013576, grad/param norm = 1.8261e-01, time/batch = 0.6925s	
4436/30300 (epoch 7.320), train_loss = 1.77572731, grad/param norm = 1.8075e-01, time/batch = 0.6874s	
4437/30300 (epoch 7.322), train_loss = 1.50344607, grad/param norm = 1.5929e-01, time/batch = 0.6910s	
4438/30300 (epoch 7.323), train_loss = 1.75021936, grad/param norm = 1.6030e-01, time/batch = 0.6873s	
4439/30300 (epoch 7.325), train_loss = 1.54873665, grad/param norm = 1.4475e-01, time/batch = 0.6879s	
4440/30300 (epoch 7.327), train_loss = 1.54656301, grad/param norm = 1.6123e-01, time/batch = 0.6900s	
4441/30300 (epoch 7.328), train_loss = 1.54965629, grad/param norm = 1.5401e-01, time/batch = 0.6866s	
4442/30300 (epoch 7.330), train_loss = 1.71154627, grad/param norm = 1.6364e-01, time/batch = 0.6980s	
4443/30300 (epoch 7.332), train_loss = 1.72429408, grad/param norm = 1.6760e-01, time/batch = 0.7115s	
4444/30300 (epoch 7.333), train_loss = 1.65322358, grad/param norm = 1.6725e-01, time/batch = 0.7208s	
4445/30300 (epoch 7.335), train_loss = 1.45171105, grad/param norm = 1.6149e-01, time/batch = 0.7209s	
4446/30300 (epoch 7.337), train_loss = 1.80215919, grad/param norm = 1.7071e-01, time/batch = 0.7203s	
4447/30300 (epoch 7.338), train_loss = 1.51229037, grad/param norm = 1.6624e-01, time/batch = 0.7196s	
4448/30300 (epoch 7.340), train_loss = 1.53424133, grad/param norm = 1.7036e-01, time/batch = 0.7195s	
4449/30300 (epoch 7.342), train_loss = 1.69414619, grad/param norm = 1.5546e-01, time/batch = 0.6940s	
4450/30300 (epoch 7.343), train_loss = 1.67947221, grad/param norm = 1.6725e-01, time/batch = 0.7034s	
4451/30300 (epoch 7.345), train_loss = 1.63736587, grad/param norm = 1.5824e-01, time/batch = 0.6922s	
4452/30300 (epoch 7.347), train_loss = 1.42297945, grad/param norm = 1.3866e-01, time/batch = 0.6893s	
4453/30300 (epoch 7.348), train_loss = 1.48400982, grad/param norm = 1.5378e-01, time/batch = 0.6880s	
4454/30300 (epoch 7.350), train_loss = 1.59710544, grad/param norm = 1.5787e-01, time/batch = 0.6881s	
4455/30300 (epoch 7.351), train_loss = 1.62264286, grad/param norm = 1.7184e-01, time/batch = 0.6864s	
4456/30300 (epoch 7.353), train_loss = 1.38747735, grad/param norm = 1.6304e-01, time/batch = 0.6906s	
4457/30300 (epoch 7.355), train_loss = 1.58551412, grad/param norm = 1.5791e-01, time/batch = 0.7041s	
4458/30300 (epoch 7.356), train_loss = 1.76804229, grad/param norm = 1.8503e-01, time/batch = 0.6945s	
4459/30300 (epoch 7.358), train_loss = 1.79000056, grad/param norm = 1.6973e-01, time/batch = 0.7204s	
4460/30300 (epoch 7.360), train_loss = 1.54547443, grad/param norm = 1.6417e-01, time/batch = 0.7011s	
4461/30300 (epoch 7.361), train_loss = 1.66466634, grad/param norm = 1.9408e-01, time/batch = 0.6959s	
4462/30300 (epoch 7.363), train_loss = 1.71718028, grad/param norm = 1.6836e-01, time/batch = 0.6858s	
4463/30300 (epoch 7.365), train_loss = 1.56679212, grad/param norm = 1.6948e-01, time/batch = 0.6947s	
4464/30300 (epoch 7.366), train_loss = 1.54122399, grad/param norm = 1.6188e-01, time/batch = 0.7054s	
4465/30300 (epoch 7.368), train_loss = 1.40277112, grad/param norm = 1.6327e-01, time/batch = 0.6937s	
4466/30300 (epoch 7.370), train_loss = 1.53806261, grad/param norm = 1.6400e-01, time/batch = 0.6906s	
4467/30300 (epoch 7.371), train_loss = 1.63593128, grad/param norm = 1.5507e-01, time/batch = 0.6898s	
4468/30300 (epoch 7.373), train_loss = 1.54968476, grad/param norm = 1.5120e-01, time/batch = 0.6882s	
4469/30300 (epoch 7.375), train_loss = 1.50202662, grad/param norm = 1.5459e-01, time/batch = 0.6890s	
4470/30300 (epoch 7.376), train_loss = 1.55226957, grad/param norm = 1.5559e-01, time/batch = 0.6872s	
4471/30300 (epoch 7.378), train_loss = 1.57578094, grad/param norm = 1.5780e-01, time/batch = 0.6895s	
4472/30300 (epoch 7.380), train_loss = 1.84946420, grad/param norm = 1.8115e-01, time/batch = 0.6899s	
4473/30300 (epoch 7.381), train_loss = 1.54253784, grad/param norm = 1.5902e-01, time/batch = 0.7103s	
4474/30300 (epoch 7.383), train_loss = 1.68276054, grad/param norm = 2.6490e-01, time/batch = 0.7125s	
4475/30300 (epoch 7.384), train_loss = 1.74362906, grad/param norm = 1.8248e-01, time/batch = 0.6895s	
4476/30300 (epoch 7.386), train_loss = 1.51404429, grad/param norm = 2.3250e-01, time/batch = 0.6918s	
4477/30300 (epoch 7.388), train_loss = 1.51478938, grad/param norm = 1.5230e-01, time/batch = 0.6870s	
4478/30300 (epoch 7.389), train_loss = 1.64316463, grad/param norm = 1.6734e-01, time/batch = 0.6918s	
4479/30300 (epoch 7.391), train_loss = 1.68152958, grad/param norm = 1.5958e-01, time/batch = 0.6902s	
4480/30300 (epoch 7.393), train_loss = 1.42169702, grad/param norm = 1.4876e-01, time/batch = 0.6905s	
4481/30300 (epoch 7.394), train_loss = 1.60517702, grad/param norm = 1.5235e-01, time/batch = 0.6868s	
4482/30300 (epoch 7.396), train_loss = 1.78423111, grad/param norm = 1.6045e-01, time/batch = 0.6892s	
4483/30300 (epoch 7.398), train_loss = 1.52783766, grad/param norm = 1.4068e-01, time/batch = 0.6898s	
4484/30300 (epoch 7.399), train_loss = 1.58261607, grad/param norm = 1.5808e-01, time/batch = 0.6858s	
4485/30300 (epoch 7.401), train_loss = 1.71615818, grad/param norm = 1.7337e-01, time/batch = 0.6931s	
4486/30300 (epoch 7.403), train_loss = 1.59238539, grad/param norm = 1.6413e-01, time/batch = 0.7090s	
4487/30300 (epoch 7.404), train_loss = 1.53988238, grad/param norm = 1.9018e-01, time/batch = 0.7007s	
4488/30300 (epoch 7.406), train_loss = 1.64508232, grad/param norm = 1.7088e-01, time/batch = 0.7206s	
4489/30300 (epoch 7.408), train_loss = 1.50542700, grad/param norm = 1.6691e-01, time/batch = 0.6932s	
4490/30300 (epoch 7.409), train_loss = 1.41056681, grad/param norm = 1.6996e-01, time/batch = 0.6849s	
4491/30300 (epoch 7.411), train_loss = 1.44565383, grad/param norm = 1.5355e-01, time/batch = 0.6868s	
4492/30300 (epoch 7.413), train_loss = 1.44817796, grad/param norm = 1.5462e-01, time/batch = 0.6916s	
4493/30300 (epoch 7.414), train_loss = 1.70914733, grad/param norm = 1.6159e-01, time/batch = 0.6923s	
4494/30300 (epoch 7.416), train_loss = 1.57120231, grad/param norm = 1.7002e-01, time/batch = 0.6899s	
4495/30300 (epoch 7.417), train_loss = 1.53692483, grad/param norm = 1.4997e-01, time/batch = 0.6944s	
4496/30300 (epoch 7.419), train_loss = 1.41659808, grad/param norm = 1.4971e-01, time/batch = 0.6901s	
4497/30300 (epoch 7.421), train_loss = 1.51209159, grad/param norm = 1.4704e-01, time/batch = 0.6912s	
4498/30300 (epoch 7.422), train_loss = 1.56433294, grad/param norm = 1.5738e-01, time/batch = 0.6975s	
4499/30300 (epoch 7.424), train_loss = 1.60498573, grad/param norm = 1.6261e-01, time/batch = 0.7077s	
4500/30300 (epoch 7.426), train_loss = 1.45117028, grad/param norm = 1.6012e-01, time/batch = 0.6980s	
4501/30300 (epoch 7.427), train_loss = 1.58915784, grad/param norm = 1.7122e-01, time/batch = 0.6965s	
4502/30300 (epoch 7.429), train_loss = 1.62873119, grad/param norm = 1.7307e-01, time/batch = 0.6892s	
4503/30300 (epoch 7.431), train_loss = 1.65935272, grad/param norm = 1.7729e-01, time/batch = 0.6902s	
4504/30300 (epoch 7.432), train_loss = 1.57593100, grad/param norm = 1.6288e-01, time/batch = 0.6934s	
4505/30300 (epoch 7.434), train_loss = 1.48023174, grad/param norm = 1.7119e-01, time/batch = 0.7262s	
4506/30300 (epoch 7.436), train_loss = 1.73215044, grad/param norm = 1.7487e-01, time/batch = 0.6938s	
4507/30300 (epoch 7.437), train_loss = 1.52080423, grad/param norm = 1.8638e-01, time/batch = 0.6895s	
4508/30300 (epoch 7.439), train_loss = 1.50865150, grad/param norm = 1.5966e-01, time/batch = 0.6905s	
4509/30300 (epoch 7.441), train_loss = 1.50547940, grad/param norm = 1.5815e-01, time/batch = 0.6890s	
4510/30300 (epoch 7.442), train_loss = 1.46097064, grad/param norm = 1.5786e-01, time/batch = 0.6879s	
4511/30300 (epoch 7.444), train_loss = 1.38159945, grad/param norm = 1.7494e-01, time/batch = 0.6922s	
4512/30300 (epoch 7.446), train_loss = 1.53031454, grad/param norm = 1.6143e-01, time/batch = 0.6943s	
4513/30300 (epoch 7.447), train_loss = 1.59778529, grad/param norm = 1.8673e-01, time/batch = 0.6883s	
4514/30300 (epoch 7.449), train_loss = 1.50082894, grad/param norm = 1.6066e-01, time/batch = 0.6946s	
4515/30300 (epoch 7.450), train_loss = 1.68422267, grad/param norm = 1.5382e-01, time/batch = 0.6914s	
4516/30300 (epoch 7.452), train_loss = 1.58606157, grad/param norm = 1.5148e-01, time/batch = 0.7095s	
4517/30300 (epoch 7.454), train_loss = 1.57130594, grad/param norm = 1.5259e-01, time/batch = 0.7139s	
4518/30300 (epoch 7.455), train_loss = 1.71713080, grad/param norm = 1.6720e-01, time/batch = 0.6961s	
4519/30300 (epoch 7.457), train_loss = 1.64842040, grad/param norm = 1.6794e-01, time/batch = 0.7136s	
4520/30300 (epoch 7.459), train_loss = 1.67817260, grad/param norm = 1.8549e-01, time/batch = 0.6977s	
4521/30300 (epoch 7.460), train_loss = 1.70216096, grad/param norm = 1.7784e-01, time/batch = 0.6990s	
4522/30300 (epoch 7.462), train_loss = 1.70051571, grad/param norm = 1.6747e-01, time/batch = 0.6908s	
4523/30300 (epoch 7.464), train_loss = 1.49306202, grad/param norm = 1.6959e-01, time/batch = 0.6936s	
4524/30300 (epoch 7.465), train_loss = 1.42332677, grad/param norm = 1.4957e-01, time/batch = 0.6909s	
4525/30300 (epoch 7.467), train_loss = 1.33305662, grad/param norm = 1.5700e-01, time/batch = 0.6916s	
4526/30300 (epoch 7.469), train_loss = 1.53078988, grad/param norm = 1.6474e-01, time/batch = 0.6910s	
4527/30300 (epoch 7.470), train_loss = 1.53730605, grad/param norm = 1.5092e-01, time/batch = 0.6902s	
4528/30300 (epoch 7.472), train_loss = 1.52071156, grad/param norm = 1.5481e-01, time/batch = 0.6956s	
4529/30300 (epoch 7.474), train_loss = 1.59992859, grad/param norm = 1.7087e-01, time/batch = 0.6921s	
4530/30300 (epoch 7.475), train_loss = 1.46169779, grad/param norm = 1.5779e-01, time/batch = 0.7043s	
4531/30300 (epoch 7.477), train_loss = 1.61956571, grad/param norm = 1.8904e-01, time/batch = 0.7192s	
4532/30300 (epoch 7.479), train_loss = 1.62735031, grad/param norm = 1.6677e-01, time/batch = 0.6930s	
4533/30300 (epoch 7.480), train_loss = 1.64539411, grad/param norm = 1.6371e-01, time/batch = 0.6911s	
4534/30300 (epoch 7.482), train_loss = 1.62383604, grad/param norm = 1.6542e-01, time/batch = 0.6891s	
4535/30300 (epoch 7.483), train_loss = 1.56736418, grad/param norm = 1.6302e-01, time/batch = 0.6929s	
4536/30300 (epoch 7.485), train_loss = 1.57559422, grad/param norm = 1.6581e-01, time/batch = 0.6963s	
4537/30300 (epoch 7.487), train_loss = 1.65895337, grad/param norm = 1.7131e-01, time/batch = 0.6974s	
4538/30300 (epoch 7.488), train_loss = 1.59922397, grad/param norm = 1.5821e-01, time/batch = 0.6927s	
4539/30300 (epoch 7.490), train_loss = 1.47883894, grad/param norm = 1.5988e-01, time/batch = 0.6927s	
4540/30300 (epoch 7.492), train_loss = 1.64876795, grad/param norm = 1.8291e-01, time/batch = 0.6946s	
4541/30300 (epoch 7.493), train_loss = 1.53468294, grad/param norm = 1.5993e-01, time/batch = 0.6894s	
4542/30300 (epoch 7.495), train_loss = 1.52660845, grad/param norm = 1.7118e-01, time/batch = 0.6933s	
4543/30300 (epoch 7.497), train_loss = 1.61903847, grad/param norm = 1.7710e-01, time/batch = 0.6932s	
4544/30300 (epoch 7.498), train_loss = 1.61454171, grad/param norm = 1.6277e-01, time/batch = 0.6979s	
4545/30300 (epoch 7.500), train_loss = 1.75940401, grad/param norm = 1.8855e-01, time/batch = 0.7206s	
4546/30300 (epoch 7.502), train_loss = 1.50680098, grad/param norm = 1.6919e-01, time/batch = 0.7022s	
4547/30300 (epoch 7.503), train_loss = 1.65078824, grad/param norm = 1.5363e-01, time/batch = 0.6903s	
4548/30300 (epoch 7.505), train_loss = 1.58434256, grad/param norm = 1.6552e-01, time/batch = 0.6866s	
4549/30300 (epoch 7.507), train_loss = 1.56589103, grad/param norm = 1.7145e-01, time/batch = 0.6918s	
4550/30300 (epoch 7.508), train_loss = 1.65630549, grad/param norm = 1.9359e-01, time/batch = 0.6949s	
4551/30300 (epoch 7.510), train_loss = 1.66042457, grad/param norm = 1.7379e-01, time/batch = 0.6992s	
4552/30300 (epoch 7.512), train_loss = 1.52495664, grad/param norm = 1.6945e-01, time/batch = 0.7012s	
4553/30300 (epoch 7.513), train_loss = 1.67288093, grad/param norm = 1.6826e-01, time/batch = 0.6899s	
4554/30300 (epoch 7.515), train_loss = 1.58215538, grad/param norm = 1.6812e-01, time/batch = 0.6874s	
4555/30300 (epoch 7.517), train_loss = 1.42438945, grad/param norm = 1.5206e-01, time/batch = 0.6873s	
4556/30300 (epoch 7.518), train_loss = 1.67647816, grad/param norm = 1.6821e-01, time/batch = 0.6887s	
4557/30300 (epoch 7.520), train_loss = 1.84000375, grad/param norm = 1.7713e-01, time/batch = 0.6922s	
4558/30300 (epoch 7.521), train_loss = 1.47394366, grad/param norm = 1.7255e-01, time/batch = 0.6892s	
4559/30300 (epoch 7.523), train_loss = 1.74052502, grad/param norm = 1.8358e-01, time/batch = 0.7111s	
4560/30300 (epoch 7.525), train_loss = 1.55822926, grad/param norm = 1.6074e-01, time/batch = 0.7083s	
4561/30300 (epoch 7.526), train_loss = 1.58743077, grad/param norm = 1.6589e-01, time/batch = 0.6859s	
4562/30300 (epoch 7.528), train_loss = 1.39741954, grad/param norm = 1.5237e-01, time/batch = 0.6920s	
4563/30300 (epoch 7.530), train_loss = 1.44889158, grad/param norm = 1.6635e-01, time/batch = 0.6847s	
4564/30300 (epoch 7.531), train_loss = 1.64362304, grad/param norm = 1.7600e-01, time/batch = 0.6879s	
4565/30300 (epoch 7.533), train_loss = 1.66954387, grad/param norm = 1.6139e-01, time/batch = 0.6870s	
4566/30300 (epoch 7.535), train_loss = 1.39198120, grad/param norm = 1.5420e-01, time/batch = 0.6893s	
4567/30300 (epoch 7.536), train_loss = 1.63413561, grad/param norm = 1.7172e-01, time/batch = 0.6833s	
4568/30300 (epoch 7.538), train_loss = 1.40989960, grad/param norm = 1.5945e-01, time/batch = 0.6910s	
4569/30300 (epoch 7.540), train_loss = 1.51502021, grad/param norm = 1.6430e-01, time/batch = 0.6917s	
4570/30300 (epoch 7.541), train_loss = 1.56926023, grad/param norm = 1.7638e-01, time/batch = 0.6866s	
4571/30300 (epoch 7.543), train_loss = 1.59938523, grad/param norm = 1.6335e-01, time/batch = 0.6917s	
4572/30300 (epoch 7.545), train_loss = 1.64379009, grad/param norm = 1.7226e-01, time/batch = 0.6940s	
4573/30300 (epoch 7.546), train_loss = 1.78695985, grad/param norm = 1.6983e-01, time/batch = 0.7025s	
4574/30300 (epoch 7.548), train_loss = 1.53007531, grad/param norm = 1.7569e-01, time/batch = 0.7203s	
4575/30300 (epoch 7.550), train_loss = 1.74439308, grad/param norm = 1.7723e-01, time/batch = 0.6905s	
4576/30300 (epoch 7.551), train_loss = 1.52154232, grad/param norm = 1.6005e-01, time/batch = 0.6863s	
4577/30300 (epoch 7.553), train_loss = 1.49340606, grad/param norm = 1.6449e-01, time/batch = 0.6837s	
4578/30300 (epoch 7.554), train_loss = 1.73898917, grad/param norm = 1.8029e-01, time/batch = 0.6872s	
4579/30300 (epoch 7.556), train_loss = 1.61669262, grad/param norm = 1.5960e-01, time/batch = 0.6977s	
4580/30300 (epoch 7.558), train_loss = 1.72025269, grad/param norm = 1.6681e-01, time/batch = 0.6973s	
4581/30300 (epoch 7.559), train_loss = 1.56598997, grad/param norm = 1.6432e-01, time/batch = 0.6948s	
4582/30300 (epoch 7.561), train_loss = 1.45480970, grad/param norm = 1.6158e-01, time/batch = 0.6872s	
4583/30300 (epoch 7.563), train_loss = 1.52841752, grad/param norm = 1.6715e-01, time/batch = 0.6861s	
4584/30300 (epoch 7.564), train_loss = 1.52189892, grad/param norm = 1.5849e-01, time/batch = 0.7012s	
4585/30300 (epoch 7.566), train_loss = 1.56619099, grad/param norm = 1.6529e-01, time/batch = 0.7000s	
4586/30300 (epoch 7.568), train_loss = 1.40584821, grad/param norm = 1.6241e-01, time/batch = 0.7004s	
4587/30300 (epoch 7.569), train_loss = 1.58977273, grad/param norm = 1.6562e-01, time/batch = 0.6916s	
4588/30300 (epoch 7.571), train_loss = 1.65180502, grad/param norm = 1.8699e-01, time/batch = 0.6883s	
4589/30300 (epoch 7.573), train_loss = 1.63969877, grad/param norm = 1.6940e-01, time/batch = 0.6870s	
4590/30300 (epoch 7.574), train_loss = 1.61426789, grad/param norm = 1.6464e-01, time/batch = 0.6882s	
4591/30300 (epoch 7.576), train_loss = 1.56067291, grad/param norm = 1.5864e-01, time/batch = 0.6883s	
4592/30300 (epoch 7.578), train_loss = 1.46119124, grad/param norm = 1.5260e-01, time/batch = 0.6883s	
4593/30300 (epoch 7.579), train_loss = 1.58784024, grad/param norm = 1.6813e-01, time/batch = 0.6972s	
4594/30300 (epoch 7.581), train_loss = 1.65123071, grad/param norm = 1.5420e-01, time/batch = 0.6882s	
4595/30300 (epoch 7.583), train_loss = 1.72226072, grad/param norm = 1.7713e-01, time/batch = 0.6879s	
4596/30300 (epoch 7.584), train_loss = 1.68756468, grad/param norm = 1.6291e-01, time/batch = 0.6861s	
4597/30300 (epoch 7.586), train_loss = 1.62703613, grad/param norm = 1.6345e-01, time/batch = 0.6928s	
4598/30300 (epoch 7.587), train_loss = 1.62178942, grad/param norm = 1.6925e-01, time/batch = 0.7072s	
4599/30300 (epoch 7.589), train_loss = 1.37792038, grad/param norm = 1.5018e-01, time/batch = 0.6927s	
4600/30300 (epoch 7.591), train_loss = 1.62648047, grad/param norm = 1.7450e-01, time/batch = 0.6975s	
4601/30300 (epoch 7.592), train_loss = 1.58589874, grad/param norm = 1.5633e-01, time/batch = 0.6983s	
4602/30300 (epoch 7.594), train_loss = 1.61908690, grad/param norm = 1.7437e-01, time/batch = 0.7111s	
4603/30300 (epoch 7.596), train_loss = 1.45312910, grad/param norm = 1.4331e-01, time/batch = 0.7109s	
4604/30300 (epoch 7.597), train_loss = 1.52313205, grad/param norm = 1.6519e-01, time/batch = 0.6933s	
4605/30300 (epoch 7.599), train_loss = 1.35447514, grad/param norm = 1.6024e-01, time/batch = 0.7095s	
4606/30300 (epoch 7.601), train_loss = 1.61804583, grad/param norm = 1.6176e-01, time/batch = 0.6902s	
4607/30300 (epoch 7.602), train_loss = 1.58284768, grad/param norm = 1.5919e-01, time/batch = 0.6919s	
4608/30300 (epoch 7.604), train_loss = 1.49388968, grad/param norm = 1.5921e-01, time/batch = 0.6917s	
4609/30300 (epoch 7.606), train_loss = 1.71839711, grad/param norm = 1.8212e-01, time/batch = 0.6913s	
4610/30300 (epoch 7.607), train_loss = 1.63002592, grad/param norm = 1.6414e-01, time/batch = 0.6888s	
4611/30300 (epoch 7.609), train_loss = 1.82546010, grad/param norm = 1.8090e-01, time/batch = 0.6908s	
4612/30300 (epoch 7.611), train_loss = 1.46730826, grad/param norm = 1.5860e-01, time/batch = 0.6912s	
4613/30300 (epoch 7.612), train_loss = 1.51326577, grad/param norm = 1.6276e-01, time/batch = 0.6916s	
4614/30300 (epoch 7.614), train_loss = 1.44426241, grad/param norm = 1.5256e-01, time/batch = 0.6945s	
4615/30300 (epoch 7.616), train_loss = 1.65801434, grad/param norm = 1.7390e-01, time/batch = 0.6894s	
4616/30300 (epoch 7.617), train_loss = 1.54265019, grad/param norm = 1.6238e-01, time/batch = 0.6989s	
4617/30300 (epoch 7.619), train_loss = 1.39417457, grad/param norm = 1.5127e-01, time/batch = 0.7205s	
4618/30300 (epoch 7.620), train_loss = 1.65526752, grad/param norm = 1.6714e-01, time/batch = 0.6897s	
4619/30300 (epoch 7.622), train_loss = 1.57461002, grad/param norm = 1.7770e-01, time/batch = 0.7015s	
4620/30300 (epoch 7.624), train_loss = 1.50613836, grad/param norm = 1.6091e-01, time/batch = 0.6975s	
4621/30300 (epoch 7.625), train_loss = 1.52194921, grad/param norm = 1.6437e-01, time/batch = 0.6971s	
4622/30300 (epoch 7.627), train_loss = 1.74123272, grad/param norm = 1.7401e-01, time/batch = 0.6964s	
4623/30300 (epoch 7.629), train_loss = 1.66085669, grad/param norm = 1.6122e-01, time/batch = 0.6933s	
4624/30300 (epoch 7.630), train_loss = 1.63220646, grad/param norm = 1.7451e-01, time/batch = 0.6931s	
4625/30300 (epoch 7.632), train_loss = 1.71209667, grad/param norm = 1.6624e-01, time/batch = 0.6901s	
4626/30300 (epoch 7.634), train_loss = 1.39525495, grad/param norm = 1.4336e-01, time/batch = 0.6907s	
4627/30300 (epoch 7.635), train_loss = 1.67625330, grad/param norm = 1.6207e-01, time/batch = 0.6933s	
4628/30300 (epoch 7.637), train_loss = 1.63224087, grad/param norm = 1.7708e-01, time/batch = 0.7002s	
4629/30300 (epoch 7.639), train_loss = 1.49924813, grad/param norm = 1.7271e-01, time/batch = 0.6978s	
4630/30300 (epoch 7.640), train_loss = 1.66313408, grad/param norm = 1.6666e-01, time/batch = 0.6948s	
4631/30300 (epoch 7.642), train_loss = 1.51882635, grad/param norm = 1.5168e-01, time/batch = 0.7224s	
4632/30300 (epoch 7.644), train_loss = 1.65666643, grad/param norm = 1.6539e-01, time/batch = 0.7136s	
4633/30300 (epoch 7.645), train_loss = 1.49101379, grad/param norm = 1.6368e-01, time/batch = 0.7085s	
4634/30300 (epoch 7.647), train_loss = 1.55722590, grad/param norm = 1.5302e-01, time/batch = 0.7078s	
4635/30300 (epoch 7.649), train_loss = 1.52801141, grad/param norm = 1.5803e-01, time/batch = 0.6884s	
4636/30300 (epoch 7.650), train_loss = 1.58463189, grad/param norm = 1.5659e-01, time/batch = 0.6955s	
4637/30300 (epoch 7.652), train_loss = 1.48272706, grad/param norm = 1.5942e-01, time/batch = 0.6912s	
4638/30300 (epoch 7.653), train_loss = 1.74294289, grad/param norm = 1.6015e-01, time/batch = 0.6917s	
4639/30300 (epoch 7.655), train_loss = 1.52993232, grad/param norm = 1.6844e-01, time/batch = 0.6953s	
4640/30300 (epoch 7.657), train_loss = 1.63748846, grad/param norm = 1.6634e-01, time/batch = 0.6903s	
4641/30300 (epoch 7.658), train_loss = 1.53886802, grad/param norm = 1.6539e-01, time/batch = 0.6918s	
4642/30300 (epoch 7.660), train_loss = 1.66132561, grad/param norm = 1.6717e-01, time/batch = 0.6988s	
4643/30300 (epoch 7.662), train_loss = 1.69142774, grad/param norm = 1.8591e-01, time/batch = 0.6952s	
4644/30300 (epoch 7.663), train_loss = 1.58305865, grad/param norm = 1.5871e-01, time/batch = 0.6915s	
4645/30300 (epoch 7.665), train_loss = 1.45655462, grad/param norm = 1.5787e-01, time/batch = 0.6907s	
4646/30300 (epoch 7.667), train_loss = 1.72296475, grad/param norm = 1.8438e-01, time/batch = 0.6892s	
4647/30300 (epoch 7.668), train_loss = 1.78947902, grad/param norm = 1.8315e-01, time/batch = 0.6905s	
4648/30300 (epoch 7.670), train_loss = 1.70281970, grad/param norm = 1.6531e-01, time/batch = 0.6867s	
4649/30300 (epoch 7.672), train_loss = 1.66994835, grad/param norm = 1.6351e-01, time/batch = 0.6874s	
4650/30300 (epoch 7.673), train_loss = 1.68145035, grad/param norm = 1.6506e-01, time/batch = 0.6932s	
4651/30300 (epoch 7.675), train_loss = 1.50159844, grad/param norm = 1.6138e-01, time/batch = 0.6928s	
4652/30300 (epoch 7.677), train_loss = 1.48103326, grad/param norm = 1.4971e-01, time/batch = 0.6960s	
4653/30300 (epoch 7.678), train_loss = 1.49910258, grad/param norm = 1.4799e-01, time/batch = 0.6910s	
4654/30300 (epoch 7.680), train_loss = 1.31223524, grad/param norm = 1.6566e-01, time/batch = 0.6898s	
4655/30300 (epoch 7.682), train_loss = 1.57512795, grad/param norm = 1.7711e-01, time/batch = 0.6901s	
4656/30300 (epoch 7.683), train_loss = 1.65871665, grad/param norm = 2.3155e-01, time/batch = 0.6878s	
4657/30300 (epoch 7.685), train_loss = 1.76921697, grad/param norm = 1.8757e-01, time/batch = 0.6902s	
4658/30300 (epoch 7.686), train_loss = 1.62984741, grad/param norm = 1.9691e-01, time/batch = 0.6936s	
4659/30300 (epoch 7.688), train_loss = 1.58654548, grad/param norm = 1.6053e-01, time/batch = 0.6894s	
4660/30300 (epoch 7.690), train_loss = 1.56119126, grad/param norm = 1.7339e-01, time/batch = 0.6868s	
4661/30300 (epoch 7.691), train_loss = 1.58571173, grad/param norm = 1.5562e-01, time/batch = 0.6951s	
4662/30300 (epoch 7.693), train_loss = 2.00673098, grad/param norm = 1.9753e-01, time/batch = 0.6904s	
4663/30300 (epoch 7.695), train_loss = 1.77897219, grad/param norm = 1.9188e-01, time/batch = 0.6878s	
4664/30300 (epoch 7.696), train_loss = 1.80794751, grad/param norm = 1.9583e-01, time/batch = 0.6940s	
4665/30300 (epoch 7.698), train_loss = 1.51997516, grad/param norm = 1.6030e-01, time/batch = 0.6938s	
4666/30300 (epoch 7.700), train_loss = 1.55638677, grad/param norm = 1.6898e-01, time/batch = 0.6910s	
4667/30300 (epoch 7.701), train_loss = 1.37407178, grad/param norm = 1.4237e-01, time/batch = 0.6915s	
4668/30300 (epoch 7.703), train_loss = 1.56659640, grad/param norm = 1.5378e-01, time/batch = 0.6895s	
4669/30300 (epoch 7.705), train_loss = 1.59385356, grad/param norm = 1.7641e-01, time/batch = 0.6898s	
4670/30300 (epoch 7.706), train_loss = 1.59577397, grad/param norm = 1.6176e-01, time/batch = 0.6984s	
4671/30300 (epoch 7.708), train_loss = 1.52516735, grad/param norm = 1.6224e-01, time/batch = 0.7060s	
4672/30300 (epoch 7.710), train_loss = 1.55214333, grad/param norm = 1.6463e-01, time/batch = 0.7128s	
4673/30300 (epoch 7.711), train_loss = 1.45719080, grad/param norm = 1.6243e-01, time/batch = 0.7256s	
4674/30300 (epoch 7.713), train_loss = 1.41441232, grad/param norm = 1.4669e-01, time/batch = 0.7075s	
4675/30300 (epoch 7.715), train_loss = 1.55099370, grad/param norm = 1.6212e-01, time/batch = 0.6966s	
4676/30300 (epoch 7.716), train_loss = 1.74491404, grad/param norm = 1.6312e-01, time/batch = 0.7137s	
4677/30300 (epoch 7.718), train_loss = 1.66782768, grad/param norm = 1.6881e-01, time/batch = 0.7335s	
4678/30300 (epoch 7.719), train_loss = 1.57807501, grad/param norm = 1.7043e-01, time/batch = 0.7070s	
4679/30300 (epoch 7.721), train_loss = 1.55495145, grad/param norm = 1.6481e-01, time/batch = 0.6998s	
4680/30300 (epoch 7.723), train_loss = 1.55096733, grad/param norm = 1.7807e-01, time/batch = 0.6932s	
4681/30300 (epoch 7.724), train_loss = 1.68347883, grad/param norm = 1.7467e-01, time/batch = 0.6921s	
4682/30300 (epoch 7.726), train_loss = 2.02055733, grad/param norm = 1.9395e-01, time/batch = 0.6974s	
4683/30300 (epoch 7.728), train_loss = 1.59667857, grad/param norm = 1.5773e-01, time/batch = 0.6858s	
4684/30300 (epoch 7.729), train_loss = 1.58644923, grad/param norm = 1.6032e-01, time/batch = 0.6873s	
4685/30300 (epoch 7.731), train_loss = 1.68289615, grad/param norm = 1.6868e-01, time/batch = 0.6883s	
4686/30300 (epoch 7.733), train_loss = 1.57379437, grad/param norm = 1.5566e-01, time/batch = 0.6912s	
4687/30300 (epoch 7.734), train_loss = 1.60825989, grad/param norm = 1.5588e-01, time/batch = 0.6912s	
4688/30300 (epoch 7.736), train_loss = 1.53279251, grad/param norm = 1.5012e-01, time/batch = 0.7174s	
4689/30300 (epoch 7.738), train_loss = 1.40171754, grad/param norm = 1.4661e-01, time/batch = 0.7065s	
4690/30300 (epoch 7.739), train_loss = 1.66001906, grad/param norm = 1.5924e-01, time/batch = 0.7043s	
4691/30300 (epoch 7.741), train_loss = 1.69169749, grad/param norm = 1.5642e-01, time/batch = 0.6997s	
4692/30300 (epoch 7.743), train_loss = 1.48638469, grad/param norm = 1.6229e-01, time/batch = 0.6856s	
4693/30300 (epoch 7.744), train_loss = 1.69003443, grad/param norm = 1.8421e-01, time/batch = 0.6920s	
4694/30300 (epoch 7.746), train_loss = 1.40014130, grad/param norm = 1.5644e-01, time/batch = 0.6902s	
4695/30300 (epoch 7.748), train_loss = 1.59355472, grad/param norm = 1.7172e-01, time/batch = 0.6919s	
4696/30300 (epoch 7.749), train_loss = 1.59398185, grad/param norm = 1.6439e-01, time/batch = 0.6926s	
4697/30300 (epoch 7.751), train_loss = 1.46499953, grad/param norm = 1.6511e-01, time/batch = 0.6919s	
4698/30300 (epoch 7.752), train_loss = 1.53423719, grad/param norm = 1.6047e-01, time/batch = 0.6923s	
4699/30300 (epoch 7.754), train_loss = 1.40529823, grad/param norm = 1.4576e-01, time/batch = 0.6882s	
4700/30300 (epoch 7.756), train_loss = 1.51473622, grad/param norm = 1.6708e-01, time/batch = 0.6920s	
4701/30300 (epoch 7.757), train_loss = 1.60288717, grad/param norm = 1.6295e-01, time/batch = 0.6959s	
4702/30300 (epoch 7.759), train_loss = 1.49293450, grad/param norm = 1.5104e-01, time/batch = 0.7063s	
4703/30300 (epoch 7.761), train_loss = 1.42200531, grad/param norm = 1.5813e-01, time/batch = 0.7148s	
4704/30300 (epoch 7.762), train_loss = 1.35104733, grad/param norm = 1.4519e-01, time/batch = 0.6879s	
4705/30300 (epoch 7.764), train_loss = 1.53635626, grad/param norm = 1.7003e-01, time/batch = 0.6901s	
4706/30300 (epoch 7.766), train_loss = 1.60569596, grad/param norm = 1.5883e-01, time/batch = 0.6884s	
4707/30300 (epoch 7.767), train_loss = 1.71270842, grad/param norm = 1.7874e-01, time/batch = 0.6908s	
4708/30300 (epoch 7.769), train_loss = 1.71474982, grad/param norm = 1.7925e-01, time/batch = 0.6916s	
4709/30300 (epoch 7.771), train_loss = 1.57399233, grad/param norm = 1.5307e-01, time/batch = 0.6919s	
4710/30300 (epoch 7.772), train_loss = 1.57704657, grad/param norm = 1.7316e-01, time/batch = 0.6933s	
4711/30300 (epoch 7.774), train_loss = 1.67325286, grad/param norm = 1.6132e-01, time/batch = 0.6905s	
4712/30300 (epoch 7.776), train_loss = 1.59061892, grad/param norm = 1.6724e-01, time/batch = 0.6914s	
4713/30300 (epoch 7.777), train_loss = 1.58152605, grad/param norm = 1.4998e-01, time/batch = 0.6935s	
4714/30300 (epoch 7.779), train_loss = 1.70571580, grad/param norm = 1.6720e-01, time/batch = 0.7055s	
4715/30300 (epoch 7.781), train_loss = 1.60180846, grad/param norm = 1.7268e-01, time/batch = 0.6929s	
4716/30300 (epoch 7.782), train_loss = 1.49895038, grad/param norm = 1.5832e-01, time/batch = 0.6919s	
4717/30300 (epoch 7.784), train_loss = 1.53254010, grad/param norm = 1.4741e-01, time/batch = 0.6907s	
4718/30300 (epoch 7.785), train_loss = 1.75664009, grad/param norm = 1.7798e-01, time/batch = 0.6900s	
4719/30300 (epoch 7.787), train_loss = 1.45293741, grad/param norm = 1.7577e-01, time/batch = 0.6922s	
4720/30300 (epoch 7.789), train_loss = 1.90819742, grad/param norm = 1.7459e-01, time/batch = 0.6936s	
4721/30300 (epoch 7.790), train_loss = 1.68685935, grad/param norm = 1.6767e-01, time/batch = 0.6926s	
4722/30300 (epoch 7.792), train_loss = 1.47216396, grad/param norm = 1.7547e-01, time/batch = 0.6927s	
4723/30300 (epoch 7.794), train_loss = 1.49498140, grad/param norm = 1.5794e-01, time/batch = 0.6889s	
4724/30300 (epoch 7.795), train_loss = 1.55517418, grad/param norm = 1.5500e-01, time/batch = 0.6908s	
4725/30300 (epoch 7.797), train_loss = 1.74007045, grad/param norm = 1.9352e-01, time/batch = 0.6966s	
4726/30300 (epoch 7.799), train_loss = 1.67143532, grad/param norm = 1.8724e-01, time/batch = 0.6966s	
4727/30300 (epoch 7.800), train_loss = 1.60562822, grad/param norm = 1.7331e-01, time/batch = 0.7005s	
4728/30300 (epoch 7.802), train_loss = 1.81651932, grad/param norm = 1.8617e-01, time/batch = 0.7041s	
4729/30300 (epoch 7.804), train_loss = 1.67226605, grad/param norm = 1.7457e-01, time/batch = 0.6912s	
4730/30300 (epoch 7.805), train_loss = 1.75051009, grad/param norm = 1.8789e-01, time/batch = 0.6858s	
4731/30300 (epoch 7.807), train_loss = 1.65234533, grad/param norm = 2.0187e-01, time/batch = 0.6952s	
4732/30300 (epoch 7.809), train_loss = 1.70846541, grad/param norm = 1.7972e-01, time/batch = 0.6948s	
4733/30300 (epoch 7.810), train_loss = 1.67278306, grad/param norm = 1.7824e-01, time/batch = 0.6879s	
4734/30300 (epoch 7.812), train_loss = 1.50158502, grad/param norm = 1.6245e-01, time/batch = 0.6873s	
4735/30300 (epoch 7.814), train_loss = 1.60520719, grad/param norm = 1.5384e-01, time/batch = 0.6856s	
4736/30300 (epoch 7.815), train_loss = 1.61261598, grad/param norm = 1.6350e-01, time/batch = 0.6887s	
4737/30300 (epoch 7.817), train_loss = 1.72339745, grad/param norm = 1.7701e-01, time/batch = 0.6862s	
4738/30300 (epoch 7.818), train_loss = 1.62180906, grad/param norm = 1.6059e-01, time/batch = 0.6893s	
4739/30300 (epoch 7.820), train_loss = 1.85428193, grad/param norm = 1.8026e-01, time/batch = 0.6860s	
4740/30300 (epoch 7.822), train_loss = 1.82746621, grad/param norm = 1.8584e-01, time/batch = 0.6863s	
4741/30300 (epoch 7.823), train_loss = 1.87184577, grad/param norm = 1.9113e-01, time/batch = 0.6890s	
4742/30300 (epoch 7.825), train_loss = 1.69952957, grad/param norm = 1.7564e-01, time/batch = 0.6852s	
4743/30300 (epoch 7.827), train_loss = 1.53487822, grad/param norm = 1.7618e-01, time/batch = 0.6872s	
4744/30300 (epoch 7.828), train_loss = 1.65682875, grad/param norm = 1.5743e-01, time/batch = 0.6898s	
4745/30300 (epoch 7.830), train_loss = 1.61717486, grad/param norm = 1.6656e-01, time/batch = 0.6898s	
4746/30300 (epoch 7.832), train_loss = 1.55334389, grad/param norm = 1.5596e-01, time/batch = 0.6844s	
4747/30300 (epoch 7.833), train_loss = 1.69069025, grad/param norm = 1.6698e-01, time/batch = 0.6865s	
4748/30300 (epoch 7.835), train_loss = 1.59092522, grad/param norm = 1.6453e-01, time/batch = 0.6879s	
4749/30300 (epoch 7.837), train_loss = 1.38902356, grad/param norm = 1.4217e-01, time/batch = 0.6882s	
4750/30300 (epoch 7.838), train_loss = 1.47165390, grad/param norm = 1.7260e-01, time/batch = 0.6984s	
4751/30300 (epoch 7.840), train_loss = 1.59127890, grad/param norm = 1.5298e-01, time/batch = 0.6923s	
4752/30300 (epoch 7.842), train_loss = 1.40994428, grad/param norm = 1.4151e-01, time/batch = 0.6891s	
4753/30300 (epoch 7.843), train_loss = 1.58175028, grad/param norm = 1.5813e-01, time/batch = 0.6898s	
4754/30300 (epoch 7.845), train_loss = 1.50162272, grad/param norm = 1.3562e-01, time/batch = 0.6906s	
4755/30300 (epoch 7.847), train_loss = 1.64268358, grad/param norm = 1.8238e-01, time/batch = 0.6879s	
4756/30300 (epoch 7.848), train_loss = 1.74689021, grad/param norm = 1.7761e-01, time/batch = 0.7007s	
4757/30300 (epoch 7.850), train_loss = 1.51361165, grad/param norm = 1.5139e-01, time/batch = 0.7069s	
4758/30300 (epoch 7.851), train_loss = 1.80714017, grad/param norm = 1.8598e-01, time/batch = 0.7140s	
4759/30300 (epoch 7.853), train_loss = 1.52835553, grad/param norm = 1.6607e-01, time/batch = 0.6961s	
4760/30300 (epoch 7.855), train_loss = 1.52679512, grad/param norm = 1.5636e-01, time/batch = 0.6933s	
4761/30300 (epoch 7.856), train_loss = 1.50961106, grad/param norm = 1.7008e-01, time/batch = 0.6908s	
4762/30300 (epoch 7.858), train_loss = 1.50470489, grad/param norm = 1.5173e-01, time/batch = 0.6862s	
4763/30300 (epoch 7.860), train_loss = 1.55628467, grad/param norm = 1.5749e-01, time/batch = 0.6901s	
4764/30300 (epoch 7.861), train_loss = 1.76672242, grad/param norm = 1.6613e-01, time/batch = 0.7103s	
4765/30300 (epoch 7.863), train_loss = 1.61005004, grad/param norm = 1.6395e-01, time/batch = 0.7109s	
4766/30300 (epoch 7.865), train_loss = 1.82395903, grad/param norm = 1.7203e-01, time/batch = 0.7045s	
4767/30300 (epoch 7.866), train_loss = 1.64450800, grad/param norm = 1.6228e-01, time/batch = 0.7047s	
4768/30300 (epoch 7.868), train_loss = 1.60076603, grad/param norm = 1.5849e-01, time/batch = 0.6972s	
4769/30300 (epoch 7.870), train_loss = 1.54823364, grad/param norm = 1.4924e-01, time/batch = 0.6921s	
4770/30300 (epoch 7.871), train_loss = 1.49092729, grad/param norm = 1.4607e-01, time/batch = 0.6862s	
4771/30300 (epoch 7.873), train_loss = 1.61517921, grad/param norm = 1.5393e-01, time/batch = 0.6887s	
4772/30300 (epoch 7.875), train_loss = 1.40984405, grad/param norm = 1.4566e-01, time/batch = 0.6938s	
4773/30300 (epoch 7.876), train_loss = 1.44009615, grad/param norm = 1.4769e-01, time/batch = 0.6961s	
4774/30300 (epoch 7.878), train_loss = 1.34265077, grad/param norm = 1.5913e-01, time/batch = 0.6992s	
4775/30300 (epoch 7.880), train_loss = 1.45526718, grad/param norm = 1.6161e-01, time/batch = 0.6954s	
4776/30300 (epoch 7.881), train_loss = 1.80571693, grad/param norm = 1.6671e-01, time/batch = 0.6943s	
4777/30300 (epoch 7.883), train_loss = 1.66623897, grad/param norm = 1.7193e-01, time/batch = 0.6890s	
4778/30300 (epoch 7.884), train_loss = 1.43253395, grad/param norm = 1.5264e-01, time/batch = 0.7069s	
4779/30300 (epoch 7.886), train_loss = 1.56588189, grad/param norm = 1.6487e-01, time/batch = 0.7197s	
4780/30300 (epoch 7.888), train_loss = 1.62856827, grad/param norm = 1.6656e-01, time/batch = 0.6896s	
4781/30300 (epoch 7.889), train_loss = 1.53433894, grad/param norm = 1.5846e-01, time/batch = 0.6892s	
4782/30300 (epoch 7.891), train_loss = 1.51068233, grad/param norm = 1.6035e-01, time/batch = 0.6933s	
4783/30300 (epoch 7.893), train_loss = 1.83310472, grad/param norm = 1.7664e-01, time/batch = 0.6980s	
4784/30300 (epoch 7.894), train_loss = 1.67351427, grad/param norm = 1.5706e-01, time/batch = 0.6943s	
4785/30300 (epoch 7.896), train_loss = 1.36507160, grad/param norm = 1.4715e-01, time/batch = 0.6923s	
4786/30300 (epoch 7.898), train_loss = 1.35733387, grad/param norm = 1.6114e-01, time/batch = 0.6921s	
4787/30300 (epoch 7.899), train_loss = 1.51147140, grad/param norm = 1.5525e-01, time/batch = 0.7073s	
4788/30300 (epoch 7.901), train_loss = 1.58811004, grad/param norm = 1.6473e-01, time/batch = 0.7035s	
4789/30300 (epoch 7.903), train_loss = 1.62480140, grad/param norm = 1.6780e-01, time/batch = 0.6989s	
4790/30300 (epoch 7.904), train_loss = 1.52510764, grad/param norm = 1.5565e-01, time/batch = 0.6946s	
4791/30300 (epoch 7.906), train_loss = 1.71928042, grad/param norm = 1.5662e-01, time/batch = 0.6970s	
4792/30300 (epoch 7.908), train_loss = 1.45624585, grad/param norm = 1.4995e-01, time/batch = 0.6918s	
4793/30300 (epoch 7.909), train_loss = 1.55221655, grad/param norm = 1.7523e-01, time/batch = 0.6938s	
4794/30300 (epoch 7.911), train_loss = 1.56320839, grad/param norm = 1.6208e-01, time/batch = 0.6932s	
4795/30300 (epoch 7.913), train_loss = 1.57910040, grad/param norm = 1.6829e-01, time/batch = 0.6892s	
4796/30300 (epoch 7.914), train_loss = 1.56515781, grad/param norm = 1.6721e-01, time/batch = 0.6928s	
4797/30300 (epoch 7.916), train_loss = 1.60049985, grad/param norm = 1.5444e-01, time/batch = 0.6932s	
4798/30300 (epoch 7.917), train_loss = 1.49216938, grad/param norm = 1.5934e-01, time/batch = 0.6942s	
4799/30300 (epoch 7.919), train_loss = 1.58979053, grad/param norm = 1.4816e-01, time/batch = 0.6907s	
4800/30300 (epoch 7.921), train_loss = 1.60892764, grad/param norm = 1.6523e-01, time/batch = 0.6930s	
4801/30300 (epoch 7.922), train_loss = 1.67394838, grad/param norm = 1.7033e-01, time/batch = 0.6901s	
4802/30300 (epoch 7.924), train_loss = 1.57280406, grad/param norm = 1.6325e-01, time/batch = 0.6946s	
4803/30300 (epoch 7.926), train_loss = 1.54517404, grad/param norm = 1.6138e-01, time/batch = 0.7217s	
4804/30300 (epoch 7.927), train_loss = 1.57422081, grad/param norm = 1.7068e-01, time/batch = 0.7214s	
4805/30300 (epoch 7.929), train_loss = 1.55169953, grad/param norm = 1.7882e-01, time/batch = 0.7203s	
4806/30300 (epoch 7.931), train_loss = 1.71104731, grad/param norm = 1.8953e-01, time/batch = 0.7207s	
4807/30300 (epoch 7.932), train_loss = 1.50895847, grad/param norm = 1.8099e-01, time/batch = 0.7199s	
4808/30300 (epoch 7.934), train_loss = 1.58195815, grad/param norm = 1.5651e-01, time/batch = 0.7115s	
4809/30300 (epoch 7.936), train_loss = 1.52562717, grad/param norm = 1.5139e-01, time/batch = 0.7073s	
4810/30300 (epoch 7.937), train_loss = 1.55035627, grad/param norm = 1.6160e-01, time/batch = 0.7040s	
4811/30300 (epoch 7.939), train_loss = 1.71223069, grad/param norm = 1.5807e-01, time/batch = 0.6962s	
4812/30300 (epoch 7.941), train_loss = 1.58464394, grad/param norm = 1.6315e-01, time/batch = 0.6912s	
4813/30300 (epoch 7.942), train_loss = 1.56076830, grad/param norm = 1.6860e-01, time/batch = 0.6941s	
4814/30300 (epoch 7.944), train_loss = 1.43783076, grad/param norm = 1.4816e-01, time/batch = 0.6939s	
4815/30300 (epoch 7.946), train_loss = 1.74594955, grad/param norm = 1.8976e-01, time/batch = 0.6909s	
4816/30300 (epoch 7.947), train_loss = 1.78064942, grad/param norm = 1.8790e-01, time/batch = 0.6909s	
4817/30300 (epoch 7.949), train_loss = 1.83167339, grad/param norm = 1.8125e-01, time/batch = 0.7206s	
4818/30300 (epoch 7.950), train_loss = 1.71028613, grad/param norm = 1.6476e-01, time/batch = 0.7015s	
4819/30300 (epoch 7.952), train_loss = 1.71620002, grad/param norm = 1.7070e-01, time/batch = 0.6926s	
4820/30300 (epoch 7.954), train_loss = 1.86656353, grad/param norm = 1.7540e-01, time/batch = 0.6855s	
4821/30300 (epoch 7.955), train_loss = 1.51030212, grad/param norm = 1.6473e-01, time/batch = 0.6865s	
4822/30300 (epoch 7.957), train_loss = 1.65903669, grad/param norm = 1.6343e-01, time/batch = 0.6866s	
4823/30300 (epoch 7.959), train_loss = 1.61755715, grad/param norm = 1.6328e-01, time/batch = 0.6866s	
4824/30300 (epoch 7.960), train_loss = 1.55437600, grad/param norm = 1.5749e-01, time/batch = 0.6880s	
4825/30300 (epoch 7.962), train_loss = 1.51983493, grad/param norm = 1.7565e-01, time/batch = 0.6973s	
4826/30300 (epoch 7.964), train_loss = 1.61413310, grad/param norm = 1.7640e-01, time/batch = 0.7009s	
4827/30300 (epoch 7.965), train_loss = 1.50127426, grad/param norm = 1.5223e-01, time/batch = 0.6990s	
4828/30300 (epoch 7.967), train_loss = 1.57777971, grad/param norm = 1.6273e-01, time/batch = 0.7013s	
4829/30300 (epoch 7.969), train_loss = 1.57370004, grad/param norm = 1.8654e-01, time/batch = 0.7117s	
4830/30300 (epoch 7.970), train_loss = 1.50310152, grad/param norm = 1.4958e-01, time/batch = 0.6985s	
4831/30300 (epoch 7.972), train_loss = 1.46812722, grad/param norm = 1.5513e-01, time/batch = 0.7080s	
4832/30300 (epoch 7.974), train_loss = 1.76828304, grad/param norm = 1.7064e-01, time/batch = 0.7001s	
4833/30300 (epoch 7.975), train_loss = 1.78135700, grad/param norm = 1.9111e-01, time/batch = 0.7039s	
4834/30300 (epoch 7.977), train_loss = 1.63739034, grad/param norm = 1.6638e-01, time/batch = 0.6981s	
4835/30300 (epoch 7.979), train_loss = 1.64746530, grad/param norm = 1.6029e-01, time/batch = 0.6971s	
4836/30300 (epoch 7.980), train_loss = 1.64919745, grad/param norm = 1.7506e-01, time/batch = 0.6963s	
4837/30300 (epoch 7.982), train_loss = 1.67696220, grad/param norm = 1.6588e-01, time/batch = 0.6927s	
4838/30300 (epoch 7.983), train_loss = 1.71704416, grad/param norm = 1.6915e-01, time/batch = 0.6912s	
4839/30300 (epoch 7.985), train_loss = 1.60267425, grad/param norm = 1.6777e-01, time/batch = 0.6921s	
4840/30300 (epoch 7.987), train_loss = 1.53359696, grad/param norm = 1.4385e-01, time/batch = 0.6896s	
4841/30300 (epoch 7.988), train_loss = 1.73434644, grad/param norm = 1.6866e-01, time/batch = 0.6904s	
4842/30300 (epoch 7.990), train_loss = 1.38780203, grad/param norm = 1.5223e-01, time/batch = 0.7066s	
4843/30300 (epoch 7.992), train_loss = 1.62317979, grad/param norm = 1.4696e-01, time/batch = 0.7014s	
4844/30300 (epoch 7.993), train_loss = 1.76088998, grad/param norm = 1.8210e-01, time/batch = 0.7011s	
4845/30300 (epoch 7.995), train_loss = 1.64982009, grad/param norm = 1.6573e-01, time/batch = 0.7040s	
4846/30300 (epoch 7.997), train_loss = 1.62785646, grad/param norm = 1.5908e-01, time/batch = 0.7196s	
4847/30300 (epoch 7.998), train_loss = 1.71549850, grad/param norm = 1.8353e-01, time/batch = 0.7096s	
4848/30300 (epoch 8.000), train_loss = 1.50871285, grad/param norm = 1.7791e-01, time/batch = 0.7106s	
4849/30300 (epoch 8.002), train_loss = 1.61754009, grad/param norm = 1.9694e-01, time/batch = 0.7188s	
4850/30300 (epoch 8.003), train_loss = 1.61942993, grad/param norm = 1.6977e-01, time/batch = 0.6916s	
4851/30300 (epoch 8.005), train_loss = 1.57822886, grad/param norm = 1.6771e-01, time/batch = 0.6879s	
4852/30300 (epoch 8.007), train_loss = 1.71562389, grad/param norm = 1.6368e-01, time/batch = 0.6882s	
4853/30300 (epoch 8.008), train_loss = 1.51859513, grad/param norm = 1.6045e-01, time/batch = 0.6891s	
4854/30300 (epoch 8.010), train_loss = 1.52730784, grad/param norm = 1.7927e-01, time/batch = 0.6910s	
4855/30300 (epoch 8.012), train_loss = 1.48838456, grad/param norm = 1.5295e-01, time/batch = 0.6906s	
4856/30300 (epoch 8.013), train_loss = 1.59842346, grad/param norm = 1.6721e-01, time/batch = 0.6952s	
4857/30300 (epoch 8.015), train_loss = 1.54144029, grad/param norm = 1.5222e-01, time/batch = 0.7138s	
4858/30300 (epoch 8.017), train_loss = 1.45102865, grad/param norm = 1.6182e-01, time/batch = 0.7002s	
4859/30300 (epoch 8.018), train_loss = 1.58986729, grad/param norm = 1.6024e-01, time/batch = 0.6989s	
4860/30300 (epoch 8.020), train_loss = 1.74190059, grad/param norm = 1.7737e-01, time/batch = 0.6966s	
4861/30300 (epoch 8.021), train_loss = 1.72947509, grad/param norm = 1.7164e-01, time/batch = 0.7118s	
4862/30300 (epoch 8.023), train_loss = 1.48891623, grad/param norm = 1.5920e-01, time/batch = 0.6927s	
4863/30300 (epoch 8.025), train_loss = 1.51381858, grad/param norm = 1.7677e-01, time/batch = 0.6858s	
4864/30300 (epoch 8.026), train_loss = 1.63370597, grad/param norm = 1.7627e-01, time/batch = 0.6855s	
4865/30300 (epoch 8.028), train_loss = 1.62993464, grad/param norm = 1.6165e-01, time/batch = 0.6868s	
4866/30300 (epoch 8.030), train_loss = 1.46420000, grad/param norm = 1.6186e-01, time/batch = 0.6868s	
4867/30300 (epoch 8.031), train_loss = 1.56976088, grad/param norm = 1.7955e-01, time/batch = 0.6875s	
4868/30300 (epoch 8.033), train_loss = 1.57337426, grad/param norm = 1.6364e-01, time/batch = 0.6889s	
4869/30300 (epoch 8.035), train_loss = 1.65747273, grad/param norm = 1.6388e-01, time/batch = 0.6901s	
4870/30300 (epoch 8.036), train_loss = 1.64033995, grad/param norm = 1.6987e-01, time/batch = 0.6894s	
4871/30300 (epoch 8.038), train_loss = 1.58747863, grad/param norm = 1.6023e-01, time/batch = 0.6861s	
4872/30300 (epoch 8.040), train_loss = 1.27371426, grad/param norm = 1.5393e-01, time/batch = 0.6885s	
4873/30300 (epoch 8.041), train_loss = 1.33845882, grad/param norm = 1.4881e-01, time/batch = 0.6909s	
4874/30300 (epoch 8.043), train_loss = 1.64611666, grad/param norm = 1.5188e-01, time/batch = 0.7140s	
4875/30300 (epoch 8.045), train_loss = 1.51893197, grad/param norm = 1.6186e-01, time/batch = 0.7092s	
4876/30300 (epoch 8.046), train_loss = 1.64826837, grad/param norm = 1.7798e-01, time/batch = 0.6904s	
4877/30300 (epoch 8.048), train_loss = 1.61608659, grad/param norm = 1.7815e-01, time/batch = 0.6879s	
4878/30300 (epoch 8.050), train_loss = 1.64794396, grad/param norm = 1.6494e-01, time/batch = 0.6876s	
4879/30300 (epoch 8.051), train_loss = 1.59303181, grad/param norm = 1.5805e-01, time/batch = 0.6928s	
4880/30300 (epoch 8.053), train_loss = 1.45544708, grad/param norm = 1.6736e-01, time/batch = 0.6937s	
4881/30300 (epoch 8.054), train_loss = 1.51132961, grad/param norm = 1.6495e-01, time/batch = 0.6943s	
4882/30300 (epoch 8.056), train_loss = 1.45975607, grad/param norm = 1.6582e-01, time/batch = 0.6943s	
4883/30300 (epoch 8.058), train_loss = 1.57249286, grad/param norm = 1.7466e-01, time/batch = 0.6913s	
4884/30300 (epoch 8.059), train_loss = 1.56089442, grad/param norm = 1.6371e-01, time/batch = 0.6879s	
4885/30300 (epoch 8.061), train_loss = 1.75006227, grad/param norm = 1.7839e-01, time/batch = 0.6897s	
4886/30300 (epoch 8.063), train_loss = 1.53868705, grad/param norm = 1.6030e-01, time/batch = 0.6910s	
4887/30300 (epoch 8.064), train_loss = 1.66794870, grad/param norm = 1.6665e-01, time/batch = 0.7079s	
4888/30300 (epoch 8.066), train_loss = 1.56481925, grad/param norm = 1.5921e-01, time/batch = 0.7067s	
4889/30300 (epoch 8.068), train_loss = 1.42410941, grad/param norm = 1.5026e-01, time/batch = 0.7178s	
4890/30300 (epoch 8.069), train_loss = 1.70750571, grad/param norm = 1.6352e-01, time/batch = 0.6874s	
4891/30300 (epoch 8.071), train_loss = 1.63373517, grad/param norm = 1.7017e-01, time/batch = 0.6884s	
4892/30300 (epoch 8.073), train_loss = 1.65109293, grad/param norm = 1.8140e-01, time/batch = 0.6894s	
4893/30300 (epoch 8.074), train_loss = 1.60620697, grad/param norm = 1.6087e-01, time/batch = 0.7047s	
4894/30300 (epoch 8.076), train_loss = 1.54997355, grad/param norm = 1.5820e-01, time/batch = 0.6943s	
4895/30300 (epoch 8.078), train_loss = 1.44821155, grad/param norm = 1.6518e-01, time/batch = 0.6943s	
4896/30300 (epoch 8.079), train_loss = 1.44410961, grad/param norm = 1.4446e-01, time/batch = 0.6889s	
4897/30300 (epoch 8.081), train_loss = 1.63629574, grad/param norm = 1.6800e-01, time/batch = 0.6876s	
4898/30300 (epoch 8.083), train_loss = 1.76189574, grad/param norm = 1.8244e-01, time/batch = 0.6879s	
4899/30300 (epoch 8.084), train_loss = 1.48200650, grad/param norm = 1.7001e-01, time/batch = 0.6885s	
4900/30300 (epoch 8.086), train_loss = 1.52813439, grad/param norm = 1.5966e-01, time/batch = 0.6879s	
4901/30300 (epoch 8.087), train_loss = 1.44379729, grad/param norm = 1.4559e-01, time/batch = 0.6928s	
4902/30300 (epoch 8.089), train_loss = 1.53378071, grad/param norm = 1.6394e-01, time/batch = 0.6944s	
4903/30300 (epoch 8.091), train_loss = 1.67073468, grad/param norm = 1.7097e-01, time/batch = 0.6944s	
4904/30300 (epoch 8.092), train_loss = 1.51896467, grad/param norm = 1.5925e-01, time/batch = 0.6953s	
4905/30300 (epoch 8.094), train_loss = 1.78707748, grad/param norm = 1.7625e-01, time/batch = 0.6921s	
4906/30300 (epoch 8.096), train_loss = 1.62907203, grad/param norm = 1.6269e-01, time/batch = 0.6905s	
4907/30300 (epoch 8.097), train_loss = 1.43654184, grad/param norm = 1.6481e-01, time/batch = 0.7162s	
4908/30300 (epoch 8.099), train_loss = 1.74908481, grad/param norm = 1.6629e-01, time/batch = 0.7079s	
4909/30300 (epoch 8.101), train_loss = 1.86175161, grad/param norm = 1.8392e-01, time/batch = 0.6945s	
4910/30300 (epoch 8.102), train_loss = 1.62080999, grad/param norm = 1.7621e-01, time/batch = 0.6902s	
4911/30300 (epoch 8.104), train_loss = 1.51567877, grad/param norm = 1.6970e-01, time/batch = 0.6953s	
4912/30300 (epoch 8.106), train_loss = 1.59692816, grad/param norm = 1.7057e-01, time/batch = 0.6928s	
4913/30300 (epoch 8.107), train_loss = 1.58046444, grad/param norm = 1.6067e-01, time/batch = 0.6920s	
4914/30300 (epoch 8.109), train_loss = 1.67013236, grad/param norm = 1.6806e-01, time/batch = 0.6897s	
4915/30300 (epoch 8.111), train_loss = 1.71130597, grad/param norm = 1.7573e-01, time/batch = 0.6895s	
4916/30300 (epoch 8.112), train_loss = 1.60555220, grad/param norm = 1.5242e-01, time/batch = 0.6887s	
4917/30300 (epoch 8.114), train_loss = 1.56162981, grad/param norm = 1.5850e-01, time/batch = 0.6905s	
4918/30300 (epoch 8.116), train_loss = 1.61561396, grad/param norm = 1.5711e-01, time/batch = 0.6945s	
4919/30300 (epoch 8.117), train_loss = 1.56533540, grad/param norm = 1.5628e-01, time/batch = 0.6886s	
4920/30300 (epoch 8.119), train_loss = 1.47500880, grad/param norm = 1.6895e-01, time/batch = 0.6892s	
4921/30300 (epoch 8.120), train_loss = 1.59139390, grad/param norm = 1.7527e-01, time/batch = 0.7052s	
4922/30300 (epoch 8.122), train_loss = 1.68222904, grad/param norm = 1.6661e-01, time/batch = 0.7186s	
4923/30300 (epoch 8.124), train_loss = 1.79719095, grad/param norm = 1.9271e-01, time/batch = 0.6889s	
4924/30300 (epoch 8.125), train_loss = 1.41651032, grad/param norm = 1.5185e-01, time/batch = 0.6901s	
4925/30300 (epoch 8.127), train_loss = 1.61327402, grad/param norm = 1.7516e-01, time/batch = 0.6897s	
4926/30300 (epoch 8.129), train_loss = 1.72750153, grad/param norm = 1.6500e-01, time/batch = 0.6878s	
4927/30300 (epoch 8.130), train_loss = 1.71179014, grad/param norm = 1.5766e-01, time/batch = 0.6894s	
4928/30300 (epoch 8.132), train_loss = 1.62809060, grad/param norm = 2.4117e-01, time/batch = 0.7139s	
4929/30300 (epoch 8.134), train_loss = 1.45463570, grad/param norm = 1.6355e-01, time/batch = 0.6989s	
4930/30300 (epoch 8.135), train_loss = 1.56501440, grad/param norm = 1.8781e-01, time/batch = 0.6927s	
4931/30300 (epoch 8.137), train_loss = 1.71988705, grad/param norm = 1.7030e-01, time/batch = 0.6942s	
4932/30300 (epoch 8.139), train_loss = 1.55924937, grad/param norm = 1.6702e-01, time/batch = 0.6891s	
4933/30300 (epoch 8.140), train_loss = 1.79189498, grad/param norm = 1.6542e-01, time/batch = 0.6870s	
4934/30300 (epoch 8.142), train_loss = 1.81323183, grad/param norm = 2.0202e-01, time/batch = 0.6877s	
4935/30300 (epoch 8.144), train_loss = 1.69485211, grad/param norm = 2.3476e-01, time/batch = 0.6906s	
4936/30300 (epoch 8.145), train_loss = 1.75451400, grad/param norm = 1.7667e-01, time/batch = 0.7207s	
4937/30300 (epoch 8.147), train_loss = 1.63635537, grad/param norm = 1.6713e-01, time/batch = 0.7030s	
4938/30300 (epoch 8.149), train_loss = 1.80465957, grad/param norm = 1.6887e-01, time/batch = 0.7094s	
4939/30300 (epoch 8.150), train_loss = 1.73059430, grad/param norm = 1.6445e-01, time/batch = 0.7042s	
4940/30300 (epoch 8.152), train_loss = 1.54383939, grad/param norm = 1.7410e-01, time/batch = 0.7028s	
4941/30300 (epoch 8.153), train_loss = 1.63197288, grad/param norm = 1.8144e-01, time/batch = 0.6937s	
4942/30300 (epoch 8.155), train_loss = 1.38882751, grad/param norm = 1.4590e-01, time/batch = 0.6863s	
4943/30300 (epoch 8.157), train_loss = 1.57860312, grad/param norm = 1.7207e-01, time/batch = 0.6932s	
4944/30300 (epoch 8.158), train_loss = 1.66985111, grad/param norm = 1.6493e-01, time/batch = 0.6917s	
4945/30300 (epoch 8.160), train_loss = 1.50768319, grad/param norm = 1.5618e-01, time/batch = 0.6891s	
4946/30300 (epoch 8.162), train_loss = 1.47888301, grad/param norm = 1.4864e-01, time/batch = 0.6896s	
4947/30300 (epoch 8.163), train_loss = 1.51594354, grad/param norm = 1.9361e-01, time/batch = 0.6934s	
4948/30300 (epoch 8.165), train_loss = 1.63334886, grad/param norm = 1.5538e-01, time/batch = 0.6972s	
4949/30300 (epoch 8.167), train_loss = 1.64450427, grad/param norm = 1.7976e-01, time/batch = 0.6951s	
4950/30300 (epoch 8.168), train_loss = 1.56989595, grad/param norm = 1.7370e-01, time/batch = 0.7224s	
4951/30300 (epoch 8.170), train_loss = 1.63516551, grad/param norm = 1.6374e-01, time/batch = 0.7080s	
4952/30300 (epoch 8.172), train_loss = 1.53156301, grad/param norm = 1.5753e-01, time/batch = 0.6937s	
4953/30300 (epoch 8.173), train_loss = 1.65926618, grad/param norm = 1.8058e-01, time/batch = 0.6886s	
4954/30300 (epoch 8.175), train_loss = 1.56267687, grad/param norm = 1.5089e-01, time/batch = 0.6941s	
4955/30300 (epoch 8.177), train_loss = 1.61667546, grad/param norm = 1.6956e-01, time/batch = 0.7082s	
4956/30300 (epoch 8.178), train_loss = 1.34423232, grad/param norm = 1.5701e-01, time/batch = 0.6897s	
4957/30300 (epoch 8.180), train_loss = 1.48470170, grad/param norm = 1.5072e-01, time/batch = 0.6946s	
4958/30300 (epoch 8.182), train_loss = 1.49989771, grad/param norm = 1.7228e-01, time/batch = 0.6927s	
4959/30300 (epoch 8.183), train_loss = 1.46751825, grad/param norm = 1.5422e-01, time/batch = 0.6907s	
4960/30300 (epoch 8.185), train_loss = 1.87766367, grad/param norm = 1.6396e-01, time/batch = 0.6903s	
4961/30300 (epoch 8.186), train_loss = 1.83869597, grad/param norm = 1.8137e-01, time/batch = 0.6928s	
4962/30300 (epoch 8.188), train_loss = 1.65679697, grad/param norm = 1.7098e-01, time/batch = 0.6907s	
4963/30300 (epoch 8.190), train_loss = 1.49512949, grad/param norm = 1.5576e-01, time/batch = 0.6929s	
4964/30300 (epoch 8.191), train_loss = 1.68694361, grad/param norm = 1.7043e-01, time/batch = 0.6887s	
4965/30300 (epoch 8.193), train_loss = 1.43557961, grad/param norm = 1.5541e-01, time/batch = 0.6989s	
4966/30300 (epoch 8.195), train_loss = 1.60526673, grad/param norm = 1.5997e-01, time/batch = 0.6937s	
4967/30300 (epoch 8.196), train_loss = 1.60291032, grad/param norm = 1.5992e-01, time/batch = 0.6922s	
4968/30300 (epoch 8.198), train_loss = 1.35786881, grad/param norm = 1.5495e-01, time/batch = 0.6953s	
4969/30300 (epoch 8.200), train_loss = 1.55699856, grad/param norm = 1.6191e-01, time/batch = 0.6917s	
4970/30300 (epoch 8.201), train_loss = 1.70595148, grad/param norm = 1.7829e-01, time/batch = 0.6916s	
4971/30300 (epoch 8.203), train_loss = 1.56439644, grad/param norm = 1.5773e-01, time/batch = 0.6966s	
4972/30300 (epoch 8.205), train_loss = 1.80331780, grad/param norm = 1.6943e-01, time/batch = 0.6949s	
4973/30300 (epoch 8.206), train_loss = 1.81349889, grad/param norm = 1.7609e-01, time/batch = 0.6960s	
4974/30300 (epoch 8.208), train_loss = 1.74642516, grad/param norm = 1.8457e-01, time/batch = 0.6919s	
4975/30300 (epoch 8.210), train_loss = 1.59496819, grad/param norm = 1.4734e-01, time/batch = 0.6911s	
4976/30300 (epoch 8.211), train_loss = 1.62484138, grad/param norm = 1.5867e-01, time/batch = 0.6930s	
4977/30300 (epoch 8.213), train_loss = 1.51519608, grad/param norm = 1.5330e-01, time/batch = 0.6899s	
4978/30300 (epoch 8.215), train_loss = 1.38548532, grad/param norm = 1.6086e-01, time/batch = 0.6916s	
4979/30300 (epoch 8.216), train_loss = 1.56152270, grad/param norm = 1.8619e-01, time/batch = 0.6910s	
4980/30300 (epoch 8.218), train_loss = 1.47344996, grad/param norm = 1.4832e-01, time/batch = 0.6966s	
4981/30300 (epoch 8.219), train_loss = 1.39708689, grad/param norm = 1.5351e-01, time/batch = 0.6951s	
4982/30300 (epoch 8.221), train_loss = 1.41061234, grad/param norm = 1.4996e-01, time/batch = 0.6903s	
4983/30300 (epoch 8.223), train_loss = 1.56298786, grad/param norm = 1.5390e-01, time/batch = 0.7187s	
4984/30300 (epoch 8.224), train_loss = 1.40155137, grad/param norm = 1.5349e-01, time/batch = 0.7060s	
4985/30300 (epoch 8.226), train_loss = 1.66593535, grad/param norm = 1.7985e-01, time/batch = 0.6853s	
4986/30300 (epoch 8.228), train_loss = 1.68757737, grad/param norm = 1.5883e-01, time/batch = 0.6911s	
4987/30300 (epoch 8.229), train_loss = 1.47656045, grad/param norm = 1.6307e-01, time/batch = 0.6968s	
4988/30300 (epoch 8.231), train_loss = 1.58396896, grad/param norm = 1.6299e-01, time/batch = 0.6935s	
4989/30300 (epoch 8.233), train_loss = 1.50146758, grad/param norm = 1.5694e-01, time/batch = 0.6936s	
4990/30300 (epoch 8.234), train_loss = 1.64810977, grad/param norm = 1.7136e-01, time/batch = 0.6892s	
4991/30300 (epoch 8.236), train_loss = 1.49240596, grad/param norm = 1.6183e-01, time/batch = 0.6905s	
4992/30300 (epoch 8.238), train_loss = 1.64648969, grad/param norm = 1.8402e-01, time/batch = 0.6888s	
4993/30300 (epoch 8.239), train_loss = 1.61219482, grad/param norm = 1.5900e-01, time/batch = 0.6860s	
4994/30300 (epoch 8.241), train_loss = 1.64212283, grad/param norm = 1.7266e-01, time/batch = 0.6945s	
4995/30300 (epoch 8.243), train_loss = 1.59730228, grad/param norm = 1.7066e-01, time/batch = 0.6935s	
4996/30300 (epoch 8.244), train_loss = 1.86947293, grad/param norm = 1.7711e-01, time/batch = 0.6942s	
4997/30300 (epoch 8.246), train_loss = 1.56831402, grad/param norm = 1.7115e-01, time/batch = 0.7062s	
4998/30300 (epoch 8.248), train_loss = 1.59894004, grad/param norm = 1.5885e-01, time/batch = 0.7163s	
4999/30300 (epoch 8.249), train_loss = 1.42736744, grad/param norm = 1.5546e-01, time/batch = 0.6935s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch8.25_1.7382.t7	
5000/30300 (epoch 8.251), train_loss = 1.47250823, grad/param norm = 1.6205e-01, time/batch = 0.6906s	
5001/30300 (epoch 8.252), train_loss = 1.89997397, grad/param norm = 1.8324e-01, time/batch = 0.7021s	
5002/30300 (epoch 8.254), train_loss = 1.68944678, grad/param norm = 1.8215e-01, time/batch = 0.6958s	
5003/30300 (epoch 8.256), train_loss = 1.58625326, grad/param norm = 1.5307e-01, time/batch = 0.7237s	
5004/30300 (epoch 8.257), train_loss = 1.70464444, grad/param norm = 1.6840e-01, time/batch = 0.7069s	
5005/30300 (epoch 8.259), train_loss = 1.62852009, grad/param norm = 1.6085e-01, time/batch = 0.7118s	
5006/30300 (epoch 8.261), train_loss = 1.70510148, grad/param norm = 1.5837e-01, time/batch = 0.6990s	
5007/30300 (epoch 8.262), train_loss = 1.56558541, grad/param norm = 1.5638e-01, time/batch = 0.6999s	
5008/30300 (epoch 8.264), train_loss = 1.58523711, grad/param norm = 1.5839e-01, time/batch = 0.6898s	
5009/30300 (epoch 8.266), train_loss = 1.48583156, grad/param norm = 1.5523e-01, time/batch = 0.6881s	
5010/30300 (epoch 8.267), train_loss = 1.75774337, grad/param norm = 1.7898e-01, time/batch = 0.6922s	
5011/30300 (epoch 8.269), train_loss = 1.56936581, grad/param norm = 1.6095e-01, time/batch = 0.6938s	
5012/30300 (epoch 8.271), train_loss = 1.57794377, grad/param norm = 1.6512e-01, time/batch = 0.6855s	
5013/30300 (epoch 8.272), train_loss = 1.61377418, grad/param norm = 1.5929e-01, time/batch = 0.6945s	
5014/30300 (epoch 8.274), train_loss = 1.76006500, grad/param norm = 1.6548e-01, time/batch = 0.6978s	
5015/30300 (epoch 8.276), train_loss = 1.71070910, grad/param norm = 1.7229e-01, time/batch = 0.6964s	
5016/30300 (epoch 8.277), train_loss = 1.51716268, grad/param norm = 1.6044e-01, time/batch = 0.6941s	
5017/30300 (epoch 8.279), train_loss = 1.61537026, grad/param norm = 1.5747e-01, time/batch = 0.7138s	
5018/30300 (epoch 8.281), train_loss = 1.65160977, grad/param norm = 1.6609e-01, time/batch = 0.7099s	
5019/30300 (epoch 8.282), train_loss = 1.51814295, grad/param norm = 1.4931e-01, time/batch = 0.6951s	
5020/30300 (epoch 8.284), train_loss = 1.80083530, grad/param norm = 1.8821e-01, time/batch = 0.6896s	
5021/30300 (epoch 8.285), train_loss = 1.60563959, grad/param norm = 1.6365e-01, time/batch = 0.6951s	
5022/30300 (epoch 8.287), train_loss = 1.58459408, grad/param norm = 1.6255e-01, time/batch = 0.7049s	
5023/30300 (epoch 8.289), train_loss = 1.65065868, grad/param norm = 1.8062e-01, time/batch = 0.6967s	
5024/30300 (epoch 8.290), train_loss = 1.31715898, grad/param norm = 1.4322e-01, time/batch = 0.6930s	
5025/30300 (epoch 8.292), train_loss = 1.48755378, grad/param norm = 1.4713e-01, time/batch = 0.6922s	
5026/30300 (epoch 8.294), train_loss = 1.74211503, grad/param norm = 1.5615e-01, time/batch = 0.6972s	
5027/30300 (epoch 8.295), train_loss = 1.54991119, grad/param norm = 1.4314e-01, time/batch = 0.6875s	
5028/30300 (epoch 8.297), train_loss = 1.49950664, grad/param norm = 1.4849e-01, time/batch = 0.6880s	
5029/30300 (epoch 8.299), train_loss = 1.56033560, grad/param norm = 1.7222e-01, time/batch = 0.6910s	
5030/30300 (epoch 8.300), train_loss = 1.61066379, grad/param norm = 1.5263e-01, time/batch = 0.6919s	
5031/30300 (epoch 8.302), train_loss = 1.49891500, grad/param norm = 1.6297e-01, time/batch = 0.7017s	
5032/30300 (epoch 8.304), train_loss = 1.42971297, grad/param norm = 1.4713e-01, time/batch = 0.7211s	
5033/30300 (epoch 8.305), train_loss = 1.51254585, grad/param norm = 1.5061e-01, time/batch = 0.6958s	
5034/30300 (epoch 8.307), train_loss = 1.55818118, grad/param norm = 1.5606e-01, time/batch = 0.6910s	
5035/30300 (epoch 8.309), train_loss = 1.66050225, grad/param norm = 1.6018e-01, time/batch = 0.6928s	
5036/30300 (epoch 8.310), train_loss = 1.50993169, grad/param norm = 1.5571e-01, time/batch = 0.6910s	
5037/30300 (epoch 8.312), train_loss = 1.62876462, grad/param norm = 1.5134e-01, time/batch = 0.6862s	
5038/30300 (epoch 8.314), train_loss = 1.60490303, grad/param norm = 1.6092e-01, time/batch = 0.6944s	
5039/30300 (epoch 8.315), train_loss = 1.64927862, grad/param norm = 1.6986e-01, time/batch = 0.6915s	
5040/30300 (epoch 8.317), train_loss = 1.68430824, grad/param norm = 1.7837e-01, time/batch = 0.6888s	
5041/30300 (epoch 8.318), train_loss = 1.76814649, grad/param norm = 1.7915e-01, time/batch = 0.6910s	
5042/30300 (epoch 8.320), train_loss = 1.73943888, grad/param norm = 1.8017e-01, time/batch = 0.6863s	
5043/30300 (epoch 8.322), train_loss = 1.46322222, grad/param norm = 1.5478e-01, time/batch = 0.6905s	
5044/30300 (epoch 8.323), train_loss = 1.70525301, grad/param norm = 1.5850e-01, time/batch = 0.6904s	
5045/30300 (epoch 8.325), train_loss = 1.51303298, grad/param norm = 1.4243e-01, time/batch = 0.6932s	
5046/30300 (epoch 8.327), train_loss = 1.50889775, grad/param norm = 1.5633e-01, time/batch = 0.7208s	
5047/30300 (epoch 8.328), train_loss = 1.50963954, grad/param norm = 1.4765e-01, time/batch = 0.7008s	
5048/30300 (epoch 8.330), train_loss = 1.66787417, grad/param norm = 1.5894e-01, time/batch = 0.6854s	
5049/30300 (epoch 8.332), train_loss = 1.67205328, grad/param norm = 1.6214e-01, time/batch = 0.6842s	
5050/30300 (epoch 8.333), train_loss = 1.60484594, grad/param norm = 1.6242e-01, time/batch = 0.6878s	
5051/30300 (epoch 8.335), train_loss = 1.40856598, grad/param norm = 1.5494e-01, time/batch = 0.6884s	
5052/30300 (epoch 8.337), train_loss = 1.75982939, grad/param norm = 1.6606e-01, time/batch = 0.6891s	
5053/30300 (epoch 8.338), train_loss = 1.47104379, grad/param norm = 1.5827e-01, time/batch = 0.6910s	
5054/30300 (epoch 8.340), train_loss = 1.46302680, grad/param norm = 1.6337e-01, time/batch = 0.6884s	
5055/30300 (epoch 8.342), train_loss = 1.65002783, grad/param norm = 1.5293e-01, time/batch = 0.7036s	
5056/30300 (epoch 8.343), train_loss = 1.64781128, grad/param norm = 1.6226e-01, time/batch = 0.7218s	
5057/30300 (epoch 8.345), train_loss = 1.59551283, grad/param norm = 1.5203e-01, time/batch = 0.7077s	
5058/30300 (epoch 8.347), train_loss = 1.38017162, grad/param norm = 1.3357e-01, time/batch = 0.7049s	
5059/30300 (epoch 8.348), train_loss = 1.44848101, grad/param norm = 1.5323e-01, time/batch = 0.6929s	
5060/30300 (epoch 8.350), train_loss = 1.55716412, grad/param norm = 1.5675e-01, time/batch = 0.6886s	
5061/30300 (epoch 8.351), train_loss = 1.57510010, grad/param norm = 1.6344e-01, time/batch = 0.6942s	
5062/30300 (epoch 8.353), train_loss = 1.34264923, grad/param norm = 1.5633e-01, time/batch = 0.6930s	
5063/30300 (epoch 8.355), train_loss = 1.53348716, grad/param norm = 1.5605e-01, time/batch = 0.6889s	
5064/30300 (epoch 8.356), train_loss = 1.70194078, grad/param norm = 1.7230e-01, time/batch = 0.6971s	
5065/30300 (epoch 8.358), train_loss = 1.73373826, grad/param norm = 1.5859e-01, time/batch = 0.6921s	
5066/30300 (epoch 8.360), train_loss = 1.49320484, grad/param norm = 1.6588e-01, time/batch = 0.6929s	
5067/30300 (epoch 8.361), train_loss = 1.60843403, grad/param norm = 1.9041e-01, time/batch = 0.6884s	
5068/30300 (epoch 8.363), train_loss = 1.66518705, grad/param norm = 1.5838e-01, time/batch = 0.6887s	
5069/30300 (epoch 8.365), train_loss = 1.52158367, grad/param norm = 1.6644e-01, time/batch = 0.6886s	
5070/30300 (epoch 8.366), train_loss = 1.48888700, grad/param norm = 1.5058e-01, time/batch = 0.6862s	
5071/30300 (epoch 8.368), train_loss = 1.35355764, grad/param norm = 1.5702e-01, time/batch = 0.6896s	
5072/30300 (epoch 8.370), train_loss = 1.47062115, grad/param norm = 1.5429e-01, time/batch = 0.6913s	
5073/30300 (epoch 8.371), train_loss = 1.59596595, grad/param norm = 1.4728e-01, time/batch = 0.6874s	
5074/30300 (epoch 8.373), train_loss = 1.48712690, grad/param norm = 1.4278e-01, time/batch = 0.6998s	
5075/30300 (epoch 8.375), train_loss = 1.45679676, grad/param norm = 1.5684e-01, time/batch = 0.7207s	
5076/30300 (epoch 8.376), train_loss = 1.50968465, grad/param norm = 1.4879e-01, time/batch = 0.6922s	
5077/30300 (epoch 8.378), train_loss = 1.53404552, grad/param norm = 1.5847e-01, time/batch = 0.6904s	
5078/30300 (epoch 8.380), train_loss = 1.80216302, grad/param norm = 1.7545e-01, time/batch = 0.6878s	
5079/30300 (epoch 8.381), train_loss = 1.48243854, grad/param norm = 1.4954e-01, time/batch = 0.6891s	
5080/30300 (epoch 8.383), train_loss = 1.61001895, grad/param norm = 2.3007e-01, time/batch = 0.6939s	
5081/30300 (epoch 8.384), train_loss = 1.68158934, grad/param norm = 1.5921e-01, time/batch = 0.6844s	
5082/30300 (epoch 8.386), train_loss = 1.45037490, grad/param norm = 2.2108e-01, time/batch = 0.6909s	
5083/30300 (epoch 8.388), train_loss = 1.45584666, grad/param norm = 1.4565e-01, time/batch = 0.6874s	
5084/30300 (epoch 8.389), train_loss = 1.60402609, grad/param norm = 1.6637e-01, time/batch = 0.6883s	
5085/30300 (epoch 8.391), train_loss = 1.63122421, grad/param norm = 1.5387e-01, time/batch = 0.6868s	
5086/30300 (epoch 8.393), train_loss = 1.37467018, grad/param norm = 1.4265e-01, time/batch = 0.6890s	
5087/30300 (epoch 8.394), train_loss = 1.55809980, grad/param norm = 1.4548e-01, time/batch = 0.6918s	
5088/30300 (epoch 8.396), train_loss = 1.73476374, grad/param norm = 1.5307e-01, time/batch = 0.6866s	
5089/30300 (epoch 8.398), train_loss = 1.49036196, grad/param norm = 1.3925e-01, time/batch = 0.7191s	
5090/30300 (epoch 8.399), train_loss = 1.53481371, grad/param norm = 1.5335e-01, time/batch = 0.7019s	
5091/30300 (epoch 8.401), train_loss = 1.66559711, grad/param norm = 1.6164e-01, time/batch = 0.7084s	
5092/30300 (epoch 8.403), train_loss = 1.52194688, grad/param norm = 1.5027e-01, time/batch = 0.7092s	
5093/30300 (epoch 8.404), train_loss = 1.47543402, grad/param norm = 1.8382e-01, time/batch = 0.7220s	
5094/30300 (epoch 8.406), train_loss = 1.58782282, grad/param norm = 1.6272e-01, time/batch = 0.7227s	
5095/30300 (epoch 8.408), train_loss = 1.44533441, grad/param norm = 1.5981e-01, time/batch = 0.7114s	
5096/30300 (epoch 8.409), train_loss = 1.36735191, grad/param norm = 1.5738e-01, time/batch = 0.7073s	
5097/30300 (epoch 8.411), train_loss = 1.40057303, grad/param norm = 1.4627e-01, time/batch = 0.7194s	
5098/30300 (epoch 8.413), train_loss = 1.38958117, grad/param norm = 1.4890e-01, time/batch = 0.7169s	
5099/30300 (epoch 8.414), train_loss = 1.66119030, grad/param norm = 1.6028e-01, time/batch = 0.7023s	
5100/30300 (epoch 8.416), train_loss = 1.51785109, grad/param norm = 1.6973e-01, time/batch = 0.7080s	
5101/30300 (epoch 8.417), train_loss = 1.49793301, grad/param norm = 1.4951e-01, time/batch = 0.7224s	
5102/30300 (epoch 8.419), train_loss = 1.37787728, grad/param norm = 1.4140e-01, time/batch = 0.7115s	
5103/30300 (epoch 8.421), train_loss = 1.47732318, grad/param norm = 1.4394e-01, time/batch = 0.7104s	
5104/30300 (epoch 8.422), train_loss = 1.51727462, grad/param norm = 1.5049e-01, time/batch = 0.7069s	
5105/30300 (epoch 8.424), train_loss = 1.55430744, grad/param norm = 1.5609e-01, time/batch = 0.7115s	
5106/30300 (epoch 8.426), train_loss = 1.40865173, grad/param norm = 1.5668e-01, time/batch = 0.7135s	
5107/30300 (epoch 8.427), train_loss = 1.53833726, grad/param norm = 1.6201e-01, time/batch = 0.7118s	
5108/30300 (epoch 8.429), train_loss = 1.58789929, grad/param norm = 1.7268e-01, time/batch = 0.7089s	
5109/30300 (epoch 8.431), train_loss = 1.61295932, grad/param norm = 1.7115e-01, time/batch = 0.7078s	
5110/30300 (epoch 8.432), train_loss = 1.52232495, grad/param norm = 1.5374e-01, time/batch = 0.7086s	
5111/30300 (epoch 8.434), train_loss = 1.41668175, grad/param norm = 1.6075e-01, time/batch = 0.7087s	
5112/30300 (epoch 8.436), train_loss = 1.69277213, grad/param norm = 1.6951e-01, time/batch = 0.7094s	
5113/30300 (epoch 8.437), train_loss = 1.46269422, grad/param norm = 1.8183e-01, time/batch = 0.7210s	
5114/30300 (epoch 8.439), train_loss = 1.46429288, grad/param norm = 1.5590e-01, time/batch = 0.7110s	
5115/30300 (epoch 8.441), train_loss = 1.46485100, grad/param norm = 1.5099e-01, time/batch = 0.7086s	
5116/30300 (epoch 8.442), train_loss = 1.42469590, grad/param norm = 1.5289e-01, time/batch = 0.7066s	
5117/30300 (epoch 8.444), train_loss = 1.32733691, grad/param norm = 1.5966e-01, time/batch = 0.7106s	
5118/30300 (epoch 8.446), train_loss = 1.48946795, grad/param norm = 1.5657e-01, time/batch = 0.7075s	
5119/30300 (epoch 8.447), train_loss = 1.55052768, grad/param norm = 2.0272e-01, time/batch = 0.7059s	
5120/30300 (epoch 8.449), train_loss = 1.45121604, grad/param norm = 1.5568e-01, time/batch = 0.7055s	
5121/30300 (epoch 8.450), train_loss = 1.64499289, grad/param norm = 1.5275e-01, time/batch = 0.7124s	
5122/30300 (epoch 8.452), train_loss = 1.54446263, grad/param norm = 1.4397e-01, time/batch = 0.7144s	
5123/30300 (epoch 8.454), train_loss = 1.53454209, grad/param norm = 1.4773e-01, time/batch = 0.7217s	
5124/30300 (epoch 8.455), train_loss = 1.66167664, grad/param norm = 1.6501e-01, time/batch = 0.7094s	
5125/30300 (epoch 8.457), train_loss = 1.58963627, grad/param norm = 1.5930e-01, time/batch = 0.7125s	
5126/30300 (epoch 8.459), train_loss = 1.64112187, grad/param norm = 1.8142e-01, time/batch = 0.7065s	
5127/30300 (epoch 8.460), train_loss = 1.65063200, grad/param norm = 1.7311e-01, time/batch = 0.7104s	
5128/30300 (epoch 8.462), train_loss = 1.65681408, grad/param norm = 1.6216e-01, time/batch = 0.7073s	
5129/30300 (epoch 8.464), train_loss = 1.42649964, grad/param norm = 1.5922e-01, time/batch = 0.7081s	
5130/30300 (epoch 8.465), train_loss = 1.36586847, grad/param norm = 1.4230e-01, time/batch = 0.7099s	
5131/30300 (epoch 8.467), train_loss = 1.29062695, grad/param norm = 1.4848e-01, time/batch = 0.7125s	
5132/30300 (epoch 8.469), train_loss = 1.47634947, grad/param norm = 1.5670e-01, time/batch = 0.7094s	
5133/30300 (epoch 8.470), train_loss = 1.49742574, grad/param norm = 1.5079e-01, time/batch = 0.7108s	
5134/30300 (epoch 8.472), train_loss = 1.47568062, grad/param norm = 1.4916e-01, time/batch = 0.7066s	
5135/30300 (epoch 8.474), train_loss = 1.56197770, grad/param norm = 1.6722e-01, time/batch = 0.7111s	
5136/30300 (epoch 8.475), train_loss = 1.42105406, grad/param norm = 1.5382e-01, time/batch = 0.7054s	
5137/30300 (epoch 8.477), train_loss = 1.56892718, grad/param norm = 1.7626e-01, time/batch = 0.7069s	
5138/30300 (epoch 8.479), train_loss = 1.56904182, grad/param norm = 1.6214e-01, time/batch = 0.7106s	
5139/30300 (epoch 8.480), train_loss = 1.59114856, grad/param norm = 1.6954e-01, time/batch = 0.7095s	
5140/30300 (epoch 8.482), train_loss = 1.58113123, grad/param norm = 1.5537e-01, time/batch = 0.7032s	
5141/30300 (epoch 8.483), train_loss = 1.51101427, grad/param norm = 1.6345e-01, time/batch = 0.7025s	
5142/30300 (epoch 8.485), train_loss = 1.53430201, grad/param norm = 1.5807e-01, time/batch = 0.7088s	
5143/30300 (epoch 8.487), train_loss = 1.59708723, grad/param norm = 1.6234e-01, time/batch = 0.7125s	
5144/30300 (epoch 8.488), train_loss = 1.56539763, grad/param norm = 1.5346e-01, time/batch = 0.7071s	
5145/30300 (epoch 8.490), train_loss = 1.42944131, grad/param norm = 1.5514e-01, time/batch = 0.7090s	
5146/30300 (epoch 8.492), train_loss = 1.59021914, grad/param norm = 1.6475e-01, time/batch = 0.7074s	
5147/30300 (epoch 8.493), train_loss = 1.48298661, grad/param norm = 1.5837e-01, time/batch = 0.7046s	
5148/30300 (epoch 8.495), train_loss = 1.48848034, grad/param norm = 1.6007e-01, time/batch = 0.7038s	
5149/30300 (epoch 8.497), train_loss = 1.57774400, grad/param norm = 1.6562e-01, time/batch = 0.7075s	
5150/30300 (epoch 8.498), train_loss = 1.56043678, grad/param norm = 1.5713e-01, time/batch = 0.7193s	
5151/30300 (epoch 8.500), train_loss = 1.69176100, grad/param norm = 1.7408e-01, time/batch = 0.7156s	
5152/30300 (epoch 8.502), train_loss = 1.46429126, grad/param norm = 1.5298e-01, time/batch = 0.7130s	
5153/30300 (epoch 8.503), train_loss = 1.60946546, grad/param norm = 1.5014e-01, time/batch = 0.7118s	
5154/30300 (epoch 8.505), train_loss = 1.53117485, grad/param norm = 1.5601e-01, time/batch = 0.7089s	
5155/30300 (epoch 8.507), train_loss = 1.51042456, grad/param norm = 1.6565e-01, time/batch = 0.7063s	
5156/30300 (epoch 8.508), train_loss = 1.59713016, grad/param norm = 1.8348e-01, time/batch = 0.7045s	
5157/30300 (epoch 8.510), train_loss = 1.61644536, grad/param norm = 1.6944e-01, time/batch = 0.7073s	
5158/30300 (epoch 8.512), train_loss = 1.47024211, grad/param norm = 1.6427e-01, time/batch = 0.7099s	
5159/30300 (epoch 8.513), train_loss = 1.64005199, grad/param norm = 1.6359e-01, time/batch = 0.7094s	
5160/30300 (epoch 8.515), train_loss = 1.52678420, grad/param norm = 1.5757e-01, time/batch = 0.7082s	
5161/30300 (epoch 8.517), train_loss = 1.37488471, grad/param norm = 1.4699e-01, time/batch = 0.7106s	
5162/30300 (epoch 8.518), train_loss = 1.63030922, grad/param norm = 1.6775e-01, time/batch = 0.7062s	
5163/30300 (epoch 8.520), train_loss = 1.78296402, grad/param norm = 1.7371e-01, time/batch = 0.7055s	
5164/30300 (epoch 8.521), train_loss = 1.42383642, grad/param norm = 1.6854e-01, time/batch = 0.7093s	
5165/30300 (epoch 8.523), train_loss = 1.68652524, grad/param norm = 1.7608e-01, time/batch = 0.7098s	
5166/30300 (epoch 8.525), train_loss = 1.49722670, grad/param norm = 1.5703e-01, time/batch = 0.7193s	
5167/30300 (epoch 8.526), train_loss = 1.54162241, grad/param norm = 1.6495e-01, time/batch = 0.7171s	
5168/30300 (epoch 8.528), train_loss = 1.36275498, grad/param norm = 1.5450e-01, time/batch = 0.7151s	
5169/30300 (epoch 8.530), train_loss = 1.40826698, grad/param norm = 1.6004e-01, time/batch = 0.7146s	
5170/30300 (epoch 8.531), train_loss = 1.61032398, grad/param norm = 1.7128e-01, time/batch = 0.7162s	
5171/30300 (epoch 8.533), train_loss = 1.62139517, grad/param norm = 1.5915e-01, time/batch = 0.7181s	
5172/30300 (epoch 8.535), train_loss = 1.35049777, grad/param norm = 1.4550e-01, time/batch = 0.7186s	
5173/30300 (epoch 8.536), train_loss = 1.57829387, grad/param norm = 1.6580e-01, time/batch = 0.7204s	
5174/30300 (epoch 8.538), train_loss = 1.35887235, grad/param norm = 1.6048e-01, time/batch = 0.7203s	
5175/30300 (epoch 8.540), train_loss = 1.44486241, grad/param norm = 1.5768e-01, time/batch = 0.7214s	
5176/30300 (epoch 8.541), train_loss = 1.51342819, grad/param norm = 1.6946e-01, time/batch = 0.7235s	
5177/30300 (epoch 8.543), train_loss = 1.55372083, grad/param norm = 1.5859e-01, time/batch = 0.7221s	
5178/30300 (epoch 8.545), train_loss = 1.58972743, grad/param norm = 1.7064e-01, time/batch = 0.7166s	
5179/30300 (epoch 8.546), train_loss = 1.75518625, grad/param norm = 1.6626e-01, time/batch = 0.7079s	
5180/30300 (epoch 8.548), train_loss = 1.48799436, grad/param norm = 1.6563e-01, time/batch = 0.7205s	
5181/30300 (epoch 8.550), train_loss = 1.70281397, grad/param norm = 1.6933e-01, time/batch = 0.7150s	
5182/30300 (epoch 8.551), train_loss = 1.47887340, grad/param norm = 1.5707e-01, time/batch = 0.7076s	
5183/30300 (epoch 8.553), train_loss = 1.44617654, grad/param norm = 1.5778e-01, time/batch = 0.7053s	
5184/30300 (epoch 8.554), train_loss = 1.66738494, grad/param norm = 1.7018e-01, time/batch = 0.7085s	
5185/30300 (epoch 8.556), train_loss = 1.58431782, grad/param norm = 1.5744e-01, time/batch = 0.7087s	
5186/30300 (epoch 8.558), train_loss = 1.67294030, grad/param norm = 1.6450e-01, time/batch = 0.7111s	
5187/30300 (epoch 8.559), train_loss = 1.53400458, grad/param norm = 1.6052e-01, time/batch = 0.7084s	
5188/30300 (epoch 8.561), train_loss = 1.40317014, grad/param norm = 1.5616e-01, time/batch = 0.7063s	
5189/30300 (epoch 8.563), train_loss = 1.47158525, grad/param norm = 1.6312e-01, time/batch = 0.7081s	
5190/30300 (epoch 8.564), train_loss = 1.48300155, grad/param norm = 1.5906e-01, time/batch = 0.7276s	
5191/30300 (epoch 8.566), train_loss = 1.51770275, grad/param norm = 1.5620e-01, time/batch = 0.7138s	
5192/30300 (epoch 8.568), train_loss = 1.34393183, grad/param norm = 1.6048e-01, time/batch = 0.7105s	
5193/30300 (epoch 8.569), train_loss = 1.54502090, grad/param norm = 1.5842e-01, time/batch = 0.7099s	
5194/30300 (epoch 8.571), train_loss = 1.58988263, grad/param norm = 2.1883e-01, time/batch = 0.7094s	
5195/30300 (epoch 8.573), train_loss = 1.59518479, grad/param norm = 1.7329e-01, time/batch = 0.7104s	
5196/30300 (epoch 8.574), train_loss = 1.58572630, grad/param norm = 1.6377e-01, time/batch = 0.7093s	
5197/30300 (epoch 8.576), train_loss = 1.51383018, grad/param norm = 1.5170e-01, time/batch = 0.7043s	
5198/30300 (epoch 8.578), train_loss = 1.41084732, grad/param norm = 1.4842e-01, time/batch = 0.7066s	
5199/30300 (epoch 8.579), train_loss = 1.56013834, grad/param norm = 1.6523e-01, time/batch = 0.7050s	
5200/30300 (epoch 8.581), train_loss = 1.60922701, grad/param norm = 1.6091e-01, time/batch = 0.7052s	
5201/30300 (epoch 8.583), train_loss = 1.67840542, grad/param norm = 1.7221e-01, time/batch = 0.7078s	
5202/30300 (epoch 8.584), train_loss = 1.62957985, grad/param norm = 1.5727e-01, time/batch = 0.7056s	
5203/30300 (epoch 8.586), train_loss = 1.58714150, grad/param norm = 1.6229e-01, time/batch = 0.7040s	
5204/30300 (epoch 8.587), train_loss = 1.57804010, grad/param norm = 1.6537e-01, time/batch = 0.7027s	
5205/30300 (epoch 8.589), train_loss = 1.34968885, grad/param norm = 1.4170e-01, time/batch = 0.7081s	
5206/30300 (epoch 8.591), train_loss = 1.57521332, grad/param norm = 1.6528e-01, time/batch = 0.7071s	
5207/30300 (epoch 8.592), train_loss = 1.53680162, grad/param norm = 1.4994e-01, time/batch = 0.7100s	
5208/30300 (epoch 8.594), train_loss = 1.57168766, grad/param norm = 1.6684e-01, time/batch = 0.7066s	
5209/30300 (epoch 8.596), train_loss = 1.39861507, grad/param norm = 1.3639e-01, time/batch = 0.7124s	
5210/30300 (epoch 8.597), train_loss = 1.48566679, grad/param norm = 1.6375e-01, time/batch = 0.7210s	
5211/30300 (epoch 8.599), train_loss = 1.30607182, grad/param norm = 1.5090e-01, time/batch = 0.7029s	
5212/30300 (epoch 8.601), train_loss = 1.57680574, grad/param norm = 1.6172e-01, time/batch = 0.7164s	
5213/30300 (epoch 8.602), train_loss = 1.53939383, grad/param norm = 1.5470e-01, time/batch = 0.7093s	
5214/30300 (epoch 8.604), train_loss = 1.44109687, grad/param norm = 1.6293e-01, time/batch = 0.7070s	
5215/30300 (epoch 8.606), train_loss = 1.64100342, grad/param norm = 1.8647e-01, time/batch = 0.7115s	
5216/30300 (epoch 8.607), train_loss = 1.57763505, grad/param norm = 1.5599e-01, time/batch = 0.7259s	
5217/30300 (epoch 8.609), train_loss = 1.76723798, grad/param norm = 1.7552e-01, time/batch = 0.7206s	
5218/30300 (epoch 8.611), train_loss = 1.43050847, grad/param norm = 1.5302e-01, time/batch = 0.7069s	
5219/30300 (epoch 8.612), train_loss = 1.46836575, grad/param norm = 1.5863e-01, time/batch = 0.7164s	
5220/30300 (epoch 8.614), train_loss = 1.41292955, grad/param norm = 1.5065e-01, time/batch = 0.7072s	
5221/30300 (epoch 8.616), train_loss = 1.61282778, grad/param norm = 1.6394e-01, time/batch = 0.7078s	
5222/30300 (epoch 8.617), train_loss = 1.47725967, grad/param norm = 1.5381e-01, time/batch = 0.7107s	
5223/30300 (epoch 8.619), train_loss = 1.34693570, grad/param norm = 1.4827e-01, time/batch = 0.7106s	
5224/30300 (epoch 8.620), train_loss = 1.59681251, grad/param norm = 1.6233e-01, time/batch = 0.7066s	
5225/30300 (epoch 8.622), train_loss = 1.53595076, grad/param norm = 1.7264e-01, time/batch = 0.7113s	
5226/30300 (epoch 8.624), train_loss = 1.45173626, grad/param norm = 1.5882e-01, time/batch = 0.7129s	
5227/30300 (epoch 8.625), train_loss = 1.47001418, grad/param norm = 1.6053e-01, time/batch = 0.7106s	
5228/30300 (epoch 8.627), train_loss = 1.69841847, grad/param norm = 1.7749e-01, time/batch = 0.7085s	
5229/30300 (epoch 8.629), train_loss = 1.61183779, grad/param norm = 1.5655e-01, time/batch = 0.7228s	
5230/30300 (epoch 8.630), train_loss = 1.56515094, grad/param norm = 1.6636e-01, time/batch = 0.7192s	
5231/30300 (epoch 8.632), train_loss = 1.66548267, grad/param norm = 1.6504e-01, time/batch = 0.7153s	
5232/30300 (epoch 8.634), train_loss = 1.36481606, grad/param norm = 1.4111e-01, time/batch = 0.7184s	
5233/30300 (epoch 8.635), train_loss = 1.61770938, grad/param norm = 1.5443e-01, time/batch = 0.7081s	
5234/30300 (epoch 8.637), train_loss = 1.58792528, grad/param norm = 1.7202e-01, time/batch = 0.7061s	
5235/30300 (epoch 8.639), train_loss = 1.44577024, grad/param norm = 1.6564e-01, time/batch = 0.7163s	
5236/30300 (epoch 8.640), train_loss = 1.62931640, grad/param norm = 1.6129e-01, time/batch = 0.7082s	
5237/30300 (epoch 8.642), train_loss = 1.46519183, grad/param norm = 1.4598e-01, time/batch = 0.7079s	
5238/30300 (epoch 8.644), train_loss = 1.61185444, grad/param norm = 1.6179e-01, time/batch = 0.7071s	
5239/30300 (epoch 8.645), train_loss = 1.43023586, grad/param norm = 1.5468e-01, time/batch = 0.7018s	
5240/30300 (epoch 8.647), train_loss = 1.50311354, grad/param norm = 1.4809e-01, time/batch = 0.7072s	
5241/30300 (epoch 8.649), train_loss = 1.48527859, grad/param norm = 1.5977e-01, time/batch = 0.7074s	
5242/30300 (epoch 8.650), train_loss = 1.52960922, grad/param norm = 1.5485e-01, time/batch = 0.7063s	
5243/30300 (epoch 8.652), train_loss = 1.44414098, grad/param norm = 1.5394e-01, time/batch = 0.7076s	
5244/30300 (epoch 8.653), train_loss = 1.69100679, grad/param norm = 1.5566e-01, time/batch = 0.7073s	
5245/30300 (epoch 8.655), train_loss = 1.47270148, grad/param norm = 1.5854e-01, time/batch = 0.7069s	
5246/30300 (epoch 8.657), train_loss = 1.57333251, grad/param norm = 1.6269e-01, time/batch = 0.7060s	
5247/30300 (epoch 8.658), train_loss = 1.49582608, grad/param norm = 1.5930e-01, time/batch = 0.7070s	
5248/30300 (epoch 8.660), train_loss = 1.61435625, grad/param norm = 1.6349e-01, time/batch = 0.7070s	
5249/30300 (epoch 8.662), train_loss = 1.63082988, grad/param norm = 1.7635e-01, time/batch = 0.7097s	
5250/30300 (epoch 8.663), train_loss = 1.53755954, grad/param norm = 1.5620e-01, time/batch = 0.7077s	
5251/30300 (epoch 8.665), train_loss = 1.41469570, grad/param norm = 1.5681e-01, time/batch = 0.7131s	
5252/30300 (epoch 8.667), train_loss = 1.66531289, grad/param norm = 1.7835e-01, time/batch = 0.7232s	
5253/30300 (epoch 8.668), train_loss = 1.73337330, grad/param norm = 1.7890e-01, time/batch = 0.7256s	
5254/30300 (epoch 8.670), train_loss = 1.66328684, grad/param norm = 1.6107e-01, time/batch = 0.7270s	
5255/30300 (epoch 8.672), train_loss = 1.62521188, grad/param norm = 1.6001e-01, time/batch = 0.7249s	
5256/30300 (epoch 8.673), train_loss = 1.63494305, grad/param norm = 1.6148e-01, time/batch = 0.7249s	
5257/30300 (epoch 8.675), train_loss = 1.45562134, grad/param norm = 1.5747e-01, time/batch = 0.7346s	
5258/30300 (epoch 8.677), train_loss = 1.43126168, grad/param norm = 1.4375e-01, time/batch = 0.7353s	
5259/30300 (epoch 8.678), train_loss = 1.46091306, grad/param norm = 1.4425e-01, time/batch = 0.7445s	
5260/30300 (epoch 8.680), train_loss = 1.27367381, grad/param norm = 1.4887e-01, time/batch = 0.7515s	
5261/30300 (epoch 8.682), train_loss = 1.52644486, grad/param norm = 1.7118e-01, time/batch = 0.7576s	
5262/30300 (epoch 8.683), train_loss = 1.57807768, grad/param norm = 1.5651e-01, time/batch = 0.7394s	
5263/30300 (epoch 8.685), train_loss = 1.71141819, grad/param norm = 1.8609e-01, time/batch = 0.7368s	
5264/30300 (epoch 8.686), train_loss = 1.54636961, grad/param norm = 1.5448e-01, time/batch = 0.7362s	
5265/30300 (epoch 8.688), train_loss = 1.54003661, grad/param norm = 1.5519e-01, time/batch = 0.7413s	
5266/30300 (epoch 8.690), train_loss = 1.50162784, grad/param norm = 1.6594e-01, time/batch = 0.7477s	
5267/30300 (epoch 8.691), train_loss = 1.53515209, grad/param norm = 1.4950e-01, time/batch = 0.7205s	
5268/30300 (epoch 8.693), train_loss = 1.94979870, grad/param norm = 1.9031e-01, time/batch = 0.7103s	
5269/30300 (epoch 8.695), train_loss = 1.73469385, grad/param norm = 1.9229e-01, time/batch = 0.7120s	
5270/30300 (epoch 8.696), train_loss = 1.74876735, grad/param norm = 1.9068e-01, time/batch = 0.7078s	
5271/30300 (epoch 8.698), train_loss = 1.49081919, grad/param norm = 1.5716e-01, time/batch = 0.7110s	
5272/30300 (epoch 8.700), train_loss = 1.49857465, grad/param norm = 1.6202e-01, time/batch = 0.7096s	
5273/30300 (epoch 8.701), train_loss = 1.33309106, grad/param norm = 1.3911e-01, time/batch = 0.7085s	
5274/30300 (epoch 8.703), train_loss = 1.53446520, grad/param norm = 1.5248e-01, time/batch = 0.7098s	
5275/30300 (epoch 8.705), train_loss = 1.55022345, grad/param norm = 1.7618e-01, time/batch = 0.7087s	
5276/30300 (epoch 8.706), train_loss = 1.55523647, grad/param norm = 1.5625e-01, time/batch = 0.7101s	
5277/30300 (epoch 8.708), train_loss = 1.49064456, grad/param norm = 1.5730e-01, time/batch = 0.7083s	
5278/30300 (epoch 8.710), train_loss = 1.49793825, grad/param norm = 1.5695e-01, time/batch = 0.7101s	
5279/30300 (epoch 8.711), train_loss = 1.40801781, grad/param norm = 1.5669e-01, time/batch = 0.7091s	
5280/30300 (epoch 8.713), train_loss = 1.38038785, grad/param norm = 1.4206e-01, time/batch = 0.7074s	
5281/30300 (epoch 8.715), train_loss = 1.49922801, grad/param norm = 1.5770e-01, time/batch = 0.7091s	
5282/30300 (epoch 8.716), train_loss = 1.69437182, grad/param norm = 1.5558e-01, time/batch = 0.7216s	
5283/30300 (epoch 8.718), train_loss = 1.62242205, grad/param norm = 1.6481e-01, time/batch = 0.7127s	
5284/30300 (epoch 8.719), train_loss = 1.53175244, grad/param norm = 1.6677e-01, time/batch = 0.7092s	
5285/30300 (epoch 8.721), train_loss = 1.50772360, grad/param norm = 1.6598e-01, time/batch = 0.7113s	
5286/30300 (epoch 8.723), train_loss = 1.50439649, grad/param norm = 1.7096e-01, time/batch = 0.7074s	
5287/30300 (epoch 8.724), train_loss = 1.63255084, grad/param norm = 1.6361e-01, time/batch = 0.7054s	
5288/30300 (epoch 8.726), train_loss = 1.97581129, grad/param norm = 1.8844e-01, time/batch = 0.7043s	
5289/30300 (epoch 8.728), train_loss = 1.56349242, grad/param norm = 1.5896e-01, time/batch = 0.7053s	
5290/30300 (epoch 8.729), train_loss = 1.54735900, grad/param norm = 1.5899e-01, time/batch = 0.7123s	
5291/30300 (epoch 8.731), train_loss = 1.62972452, grad/param norm = 1.6014e-01, time/batch = 0.7102s	
5292/30300 (epoch 8.733), train_loss = 1.52695852, grad/param norm = 1.5327e-01, time/batch = 0.7222s	
5293/30300 (epoch 8.734), train_loss = 1.57253964, grad/param norm = 1.5051e-01, time/batch = 0.7126s	
5294/30300 (epoch 8.736), train_loss = 1.49050210, grad/param norm = 1.4845e-01, time/batch = 0.7086s	
5295/30300 (epoch 8.738), train_loss = 1.36748506, grad/param norm = 1.4527e-01, time/batch = 0.7067s	
5296/30300 (epoch 8.739), train_loss = 1.61910958, grad/param norm = 1.5664e-01, time/batch = 0.7068s	
5297/30300 (epoch 8.741), train_loss = 1.65064910, grad/param norm = 1.5477e-01, time/batch = 0.7112s	
5298/30300 (epoch 8.743), train_loss = 1.44222205, grad/param norm = 1.5888e-01, time/batch = 0.7046s	
5299/30300 (epoch 8.744), train_loss = 1.62972753, grad/param norm = 1.8339e-01, time/batch = 0.7038s	
5300/30300 (epoch 8.746), train_loss = 1.36341510, grad/param norm = 1.5060e-01, time/batch = 0.7057s	
5301/30300 (epoch 8.748), train_loss = 1.53978848, grad/param norm = 1.7613e-01, time/batch = 0.7148s	
5302/30300 (epoch 8.749), train_loss = 1.56203586, grad/param norm = 1.5932e-01, time/batch = 0.7221s	
5303/30300 (epoch 8.751), train_loss = 1.43330445, grad/param norm = 1.6054e-01, time/batch = 0.7139s	
5304/30300 (epoch 8.752), train_loss = 1.48555871, grad/param norm = 1.5413e-01, time/batch = 0.7091s	
5305/30300 (epoch 8.754), train_loss = 1.37631498, grad/param norm = 1.3994e-01, time/batch = 0.7054s	
5306/30300 (epoch 8.756), train_loss = 1.47306969, grad/param norm = 1.5923e-01, time/batch = 0.7057s	
5307/30300 (epoch 8.757), train_loss = 1.56068991, grad/param norm = 1.6026e-01, time/batch = 0.7060s	
5308/30300 (epoch 8.759), train_loss = 1.45152667, grad/param norm = 1.4463e-01, time/batch = 0.7050s	
5309/30300 (epoch 8.761), train_loss = 1.38173026, grad/param norm = 1.5180e-01, time/batch = 0.7177s	
5310/30300 (epoch 8.762), train_loss = 1.31154853, grad/param norm = 1.5071e-01, time/batch = 0.7159s	
5311/30300 (epoch 8.764), train_loss = 1.48819875, grad/param norm = 1.5354e-01, time/batch = 0.7118s	
5312/30300 (epoch 8.766), train_loss = 1.56658143, grad/param norm = 1.5392e-01, time/batch = 0.7046s	
5313/30300 (epoch 8.767), train_loss = 1.66596235, grad/param norm = 1.7500e-01, time/batch = 0.7077s	
5314/30300 (epoch 8.769), train_loss = 1.64493790, grad/param norm = 1.6974e-01, time/batch = 0.7105s	
5315/30300 (epoch 8.771), train_loss = 1.53099474, grad/param norm = 1.4757e-01, time/batch = 0.7019s	
5316/30300 (epoch 8.772), train_loss = 1.54062506, grad/param norm = 1.6445e-01, time/batch = 0.7056s	
5317/30300 (epoch 8.774), train_loss = 1.64197229, grad/param norm = 1.5453e-01, time/batch = 0.7081s	
5318/30300 (epoch 8.776), train_loss = 1.54599495, grad/param norm = 1.6503e-01, time/batch = 0.7057s	
5319/30300 (epoch 8.777), train_loss = 1.54444404, grad/param norm = 1.5002e-01, time/batch = 0.7064s	
5320/30300 (epoch 8.779), train_loss = 1.67611623, grad/param norm = 1.6835e-01, time/batch = 0.7125s	
5321/30300 (epoch 8.781), train_loss = 1.56205237, grad/param norm = 1.6806e-01, time/batch = 0.7060s	
5322/30300 (epoch 8.782), train_loss = 1.46109812, grad/param norm = 1.5794e-01, time/batch = 0.6989s	
5323/30300 (epoch 8.784), train_loss = 1.48354985, grad/param norm = 1.4646e-01, time/batch = 0.7089s	
5324/30300 (epoch 8.785), train_loss = 1.71190160, grad/param norm = 1.7691e-01, time/batch = 0.7055s	
5325/30300 (epoch 8.787), train_loss = 1.39966210, grad/param norm = 1.6777e-01, time/batch = 0.7086s	
5326/30300 (epoch 8.789), train_loss = 1.84962862, grad/param norm = 1.6498e-01, time/batch = 0.7089s	
5327/30300 (epoch 8.790), train_loss = 1.64030975, grad/param norm = 1.6867e-01, time/batch = 0.7074s	
5328/30300 (epoch 8.792), train_loss = 1.42057890, grad/param norm = 1.6823e-01, time/batch = 0.7026s	
5329/30300 (epoch 8.794), train_loss = 1.46535773, grad/param norm = 1.6170e-01, time/batch = 0.7006s	
5330/30300 (epoch 8.795), train_loss = 1.51068987, grad/param norm = 1.5118e-01, time/batch = 0.7040s	
5331/30300 (epoch 8.797), train_loss = 1.71049269, grad/param norm = 1.7835e-01, time/batch = 0.7062s	
5332/30300 (epoch 8.799), train_loss = 1.61835770, grad/param norm = 1.7955e-01, time/batch = 0.7078s	
5333/30300 (epoch 8.800), train_loss = 1.57060799, grad/param norm = 1.6388e-01, time/batch = 0.7088s	
5334/30300 (epoch 8.802), train_loss = 1.77987687, grad/param norm = 1.8152e-01, time/batch = 0.7086s	
5335/30300 (epoch 8.804), train_loss = 1.63336062, grad/param norm = 1.6861e-01, time/batch = 0.7163s	
5336/30300 (epoch 8.805), train_loss = 1.70422539, grad/param norm = 1.8372e-01, time/batch = 0.7171s	
5337/30300 (epoch 8.807), train_loss = 1.60079383, grad/param norm = 1.7931e-01, time/batch = 0.7143s	
5338/30300 (epoch 8.809), train_loss = 1.65682334, grad/param norm = 1.7142e-01, time/batch = 0.7168s	
5339/30300 (epoch 8.810), train_loss = 1.62305398, grad/param norm = 1.5696e-01, time/batch = 0.7106s	
5340/30300 (epoch 8.812), train_loss = 1.44864505, grad/param norm = 1.6000e-01, time/batch = 0.7116s	
5341/30300 (epoch 8.814), train_loss = 1.55940561, grad/param norm = 1.4680e-01, time/batch = 0.7133s	
5342/30300 (epoch 8.815), train_loss = 1.57697775, grad/param norm = 1.6039e-01, time/batch = 0.7140s	
5343/30300 (epoch 8.817), train_loss = 1.66985233, grad/param norm = 1.7440e-01, time/batch = 0.7183s	
5344/30300 (epoch 8.818), train_loss = 1.57755385, grad/param norm = 1.5802e-01, time/batch = 0.7177s	
5345/30300 (epoch 8.820), train_loss = 1.80962959, grad/param norm = 2.0006e-01, time/batch = 0.7215s	
5346/30300 (epoch 8.822), train_loss = 1.80394556, grad/param norm = 1.9675e-01, time/batch = 0.7171s	
5347/30300 (epoch 8.823), train_loss = 1.83154452, grad/param norm = 1.8872e-01, time/batch = 0.7194s	
5348/30300 (epoch 8.825), train_loss = 1.66295850, grad/param norm = 1.7294e-01, time/batch = 0.7132s	
5349/30300 (epoch 8.827), train_loss = 1.47838144, grad/param norm = 1.7441e-01, time/batch = 0.7148s	
5350/30300 (epoch 8.828), train_loss = 1.61919798, grad/param norm = 1.6062e-01, time/batch = 0.7127s	
5351/30300 (epoch 8.830), train_loss = 1.58063518, grad/param norm = 1.6239e-01, time/batch = 0.7112s	
5352/30300 (epoch 8.832), train_loss = 1.50422219, grad/param norm = 1.5445e-01, time/batch = 0.7119s	
5353/30300 (epoch 8.833), train_loss = 1.63654603, grad/param norm = 1.6500e-01, time/batch = 0.7118s	
5354/30300 (epoch 8.835), train_loss = 1.54151350, grad/param norm = 1.6080e-01, time/batch = 0.7131s	
5355/30300 (epoch 8.837), train_loss = 1.34337718, grad/param norm = 1.3745e-01, time/batch = 0.7211s	
5356/30300 (epoch 8.838), train_loss = 1.41498868, grad/param norm = 1.5324e-01, time/batch = 0.7116s	
5357/30300 (epoch 8.840), train_loss = 1.55660843, grad/param norm = 1.4860e-01, time/batch = 0.7077s	
5358/30300 (epoch 8.842), train_loss = 1.36297329, grad/param norm = 1.3391e-01, time/batch = 0.7102s	
5359/30300 (epoch 8.843), train_loss = 1.53986528, grad/param norm = 1.5325e-01, time/batch = 0.7083s	
5360/30300 (epoch 8.845), train_loss = 1.46592737, grad/param norm = 1.3332e-01, time/batch = 0.7101s	
5361/30300 (epoch 8.847), train_loss = 1.60054385, grad/param norm = 1.7568e-01, time/batch = 0.7164s	
5362/30300 (epoch 8.848), train_loss = 1.69001957, grad/param norm = 1.7277e-01, time/batch = 0.7169s	
5363/30300 (epoch 8.850), train_loss = 1.46979067, grad/param norm = 1.4565e-01, time/batch = 0.7208s	
5364/30300 (epoch 8.851), train_loss = 1.74576149, grad/param norm = 1.7995e-01, time/batch = 0.7201s	
5365/30300 (epoch 8.853), train_loss = 1.46998257, grad/param norm = 1.5581e-01, time/batch = 0.7091s	
5366/30300 (epoch 8.855), train_loss = 1.48422181, grad/param norm = 1.5128e-01, time/batch = 0.7082s	
5367/30300 (epoch 8.856), train_loss = 1.46597570, grad/param norm = 1.6663e-01, time/batch = 0.7079s	
5368/30300 (epoch 8.858), train_loss = 1.45518330, grad/param norm = 1.4455e-01, time/batch = 0.7077s	
5369/30300 (epoch 8.860), train_loss = 1.50870546, grad/param norm = 1.5328e-01, time/batch = 0.7072s	
5370/30300 (epoch 8.861), train_loss = 1.72055989, grad/param norm = 1.5900e-01, time/batch = 0.7060s	
5371/30300 (epoch 8.863), train_loss = 1.55304755, grad/param norm = 1.5608e-01, time/batch = 0.7061s	
5372/30300 (epoch 8.865), train_loss = 1.75796453, grad/param norm = 1.6599e-01, time/batch = 0.7108s	
5373/30300 (epoch 8.866), train_loss = 1.59379524, grad/param norm = 1.6254e-01, time/batch = 0.7104s	
5374/30300 (epoch 8.868), train_loss = 1.54603622, grad/param norm = 1.5065e-01, time/batch = 0.7127s	
5375/30300 (epoch 8.870), train_loss = 1.51474721, grad/param norm = 1.5080e-01, time/batch = 0.7122s	
5376/30300 (epoch 8.871), train_loss = 1.46456388, grad/param norm = 1.4535e-01, time/batch = 0.7124s	
5377/30300 (epoch 8.873), train_loss = 1.56548180, grad/param norm = 1.5375e-01, time/batch = 0.7146s	
5378/30300 (epoch 8.875), train_loss = 1.37410163, grad/param norm = 1.4335e-01, time/batch = 0.7155s	
5379/30300 (epoch 8.876), train_loss = 1.40036341, grad/param norm = 1.4256e-01, time/batch = 0.7190s	
5380/30300 (epoch 8.878), train_loss = 1.29508746, grad/param norm = 1.5893e-01, time/batch = 0.7170s	
5381/30300 (epoch 8.880), train_loss = 1.41647028, grad/param norm = 1.5350e-01, time/batch = 0.7190s	
5382/30300 (epoch 8.881), train_loss = 1.77994740, grad/param norm = 1.6779e-01, time/batch = 0.7168s	
5383/30300 (epoch 8.883), train_loss = 1.61592013, grad/param norm = 1.6708e-01, time/batch = 0.7171s	
5384/30300 (epoch 8.884), train_loss = 1.37714576, grad/param norm = 1.4511e-01, time/batch = 0.7125s	
5385/30300 (epoch 8.886), train_loss = 1.54023011, grad/param norm = 1.6322e-01, time/batch = 0.7131s	
5386/30300 (epoch 8.888), train_loss = 1.58512479, grad/param norm = 1.6436e-01, time/batch = 0.7137s	
5387/30300 (epoch 8.889), train_loss = 1.49117580, grad/param norm = 1.5210e-01, time/batch = 0.7105s	
5388/30300 (epoch 8.891), train_loss = 1.47272764, grad/param norm = 1.4974e-01, time/batch = 0.7219s	
5389/30300 (epoch 8.893), train_loss = 1.79245994, grad/param norm = 1.7425e-01, time/batch = 0.7181s	
5390/30300 (epoch 8.894), train_loss = 1.63834166, grad/param norm = 1.5348e-01, time/batch = 0.7085s	
5391/30300 (epoch 8.896), train_loss = 1.32911731, grad/param norm = 1.4429e-01, time/batch = 0.7093s	
5392/30300 (epoch 8.898), train_loss = 1.31396301, grad/param norm = 1.5654e-01, time/batch = 0.7039s	
5393/30300 (epoch 8.899), train_loss = 1.46793909, grad/param norm = 1.5009e-01, time/batch = 0.7094s	
5394/30300 (epoch 8.901), train_loss = 1.53854456, grad/param norm = 1.6116e-01, time/batch = 0.7106s	
5395/30300 (epoch 8.903), train_loss = 1.57176319, grad/param norm = 1.6408e-01, time/batch = 0.7214s	
5396/30300 (epoch 8.904), train_loss = 1.46819927, grad/param norm = 1.5228e-01, time/batch = 0.7149s	
5397/30300 (epoch 8.906), train_loss = 1.68497894, grad/param norm = 1.5342e-01, time/batch = 0.7202s	
5398/30300 (epoch 8.908), train_loss = 1.40784769, grad/param norm = 1.4626e-01, time/batch = 0.7084s	
5399/30300 (epoch 8.909), train_loss = 1.50368030, grad/param norm = 1.7471e-01, time/batch = 0.7020s	
5400/30300 (epoch 8.911), train_loss = 1.52274194, grad/param norm = 1.6027e-01, time/batch = 0.7060s	
5401/30300 (epoch 8.913), train_loss = 1.52966572, grad/param norm = 1.5913e-01, time/batch = 0.7090s	
5402/30300 (epoch 8.914), train_loss = 1.52037408, grad/param norm = 1.6295e-01, time/batch = 0.7084s	
5403/30300 (epoch 8.916), train_loss = 1.55269591, grad/param norm = 1.5004e-01, time/batch = 0.7062s	
5404/30300 (epoch 8.917), train_loss = 1.44482135, grad/param norm = 1.5558e-01, time/batch = 0.7065s	
5405/30300 (epoch 8.919), train_loss = 1.52561881, grad/param norm = 1.4508e-01, time/batch = 0.7095s	
5406/30300 (epoch 8.921), train_loss = 1.56279907, grad/param norm = 1.6186e-01, time/batch = 0.7053s	
5407/30300 (epoch 8.922), train_loss = 1.62766117, grad/param norm = 1.6786e-01, time/batch = 0.7088s	
5408/30300 (epoch 8.924), train_loss = 1.53040494, grad/param norm = 1.5891e-01, time/batch = 0.7213s	
5409/30300 (epoch 8.926), train_loss = 1.50424018, grad/param norm = 1.6053e-01, time/batch = 0.7126s	
5410/30300 (epoch 8.927), train_loss = 1.53478566, grad/param norm = 1.6465e-01, time/batch = 0.7074s	
5411/30300 (epoch 8.929), train_loss = 1.49670110, grad/param norm = 1.7259e-01, time/batch = 0.7105s	
5412/30300 (epoch 8.931), train_loss = 1.67654428, grad/param norm = 1.8403e-01, time/batch = 0.7077s	
5413/30300 (epoch 8.932), train_loss = 1.46554017, grad/param norm = 1.6849e-01, time/batch = 0.7035s	
5414/30300 (epoch 8.934), train_loss = 1.53630395, grad/param norm = 1.4937e-01, time/batch = 0.7063s	
5415/30300 (epoch 8.936), train_loss = 1.48621151, grad/param norm = 1.4901e-01, time/batch = 0.7075s	
5416/30300 (epoch 8.937), train_loss = 1.49943116, grad/param norm = 1.5761e-01, time/batch = 0.7056s	
5417/30300 (epoch 8.939), train_loss = 1.66352669, grad/param norm = 1.6000e-01, time/batch = 0.7106s	
5418/30300 (epoch 8.941), train_loss = 1.53624723, grad/param norm = 1.6419e-01, time/batch = 0.7212s	
5419/30300 (epoch 8.942), train_loss = 1.51884142, grad/param norm = 1.5712e-01, time/batch = 0.7091s	
5420/30300 (epoch 8.944), train_loss = 1.40285951, grad/param norm = 1.4698e-01, time/batch = 0.7095s	
5421/30300 (epoch 8.946), train_loss = 1.70283376, grad/param norm = 1.8691e-01, time/batch = 0.7206s	
5422/30300 (epoch 8.947), train_loss = 1.72362863, grad/param norm = 1.8523e-01, time/batch = 0.7092s	
5423/30300 (epoch 8.949), train_loss = 1.77866500, grad/param norm = 1.7402e-01, time/batch = 0.7103s	
5424/30300 (epoch 8.950), train_loss = 1.67171202, grad/param norm = 1.6202e-01, time/batch = 0.7086s	
5425/30300 (epoch 8.952), train_loss = 1.66599310, grad/param norm = 1.7011e-01, time/batch = 0.7097s	
5426/30300 (epoch 8.954), train_loss = 1.82109621, grad/param norm = 1.7056e-01, time/batch = 0.7115s	
5427/30300 (epoch 8.955), train_loss = 1.47450555, grad/param norm = 1.5886e-01, time/batch = 0.7156s	
5428/30300 (epoch 8.957), train_loss = 1.62314381, grad/param norm = 1.6135e-01, time/batch = 0.7156s	
5429/30300 (epoch 8.959), train_loss = 1.57422008, grad/param norm = 1.5733e-01, time/batch = 0.7151s	
5430/30300 (epoch 8.960), train_loss = 1.50526630, grad/param norm = 1.5628e-01, time/batch = 0.7268s	
5431/30300 (epoch 8.962), train_loss = 1.47675707, grad/param norm = 1.6795e-01, time/batch = 0.7063s	
5432/30300 (epoch 8.964), train_loss = 1.56072628, grad/param norm = 1.7107e-01, time/batch = 0.7076s	
5433/30300 (epoch 8.965), train_loss = 1.45919974, grad/param norm = 1.5099e-01, time/batch = 0.7231s	
5434/30300 (epoch 8.967), train_loss = 1.52146441, grad/param norm = 1.6198e-01, time/batch = 0.7047s	
5435/30300 (epoch 8.969), train_loss = 1.52548254, grad/param norm = 1.7622e-01, time/batch = 0.7087s	
5436/30300 (epoch 8.970), train_loss = 1.46342053, grad/param norm = 1.4893e-01, time/batch = 0.7072s	
5437/30300 (epoch 8.972), train_loss = 1.41610362, grad/param norm = 1.5329e-01, time/batch = 0.7081s	
5438/30300 (epoch 8.974), train_loss = 1.72561727, grad/param norm = 1.6938e-01, time/batch = 0.7060s	
5439/30300 (epoch 8.975), train_loss = 1.72864295, grad/param norm = 1.8510e-01, time/batch = 0.7079s	
5440/30300 (epoch 8.977), train_loss = 1.60078734, grad/param norm = 1.6506e-01, time/batch = 0.7074s	
5441/30300 (epoch 8.979), train_loss = 1.60148942, grad/param norm = 1.5672e-01, time/batch = 0.7091s	
5442/30300 (epoch 8.980), train_loss = 1.62071381, grad/param norm = 1.7571e-01, time/batch = 0.7112s	
5443/30300 (epoch 8.982), train_loss = 1.64327547, grad/param norm = 1.6465e-01, time/batch = 0.7052s	
5444/30300 (epoch 8.983), train_loss = 1.67260473, grad/param norm = 1.6222e-01, time/batch = 0.7092s	
5445/30300 (epoch 8.985), train_loss = 1.55436285, grad/param norm = 1.6082e-01, time/batch = 0.7077s	
5446/30300 (epoch 8.987), train_loss = 1.49970370, grad/param norm = 1.3965e-01, time/batch = 0.7067s	
5447/30300 (epoch 8.988), train_loss = 1.70009516, grad/param norm = 1.6405e-01, time/batch = 0.7119s	
5448/30300 (epoch 8.990), train_loss = 1.34693659, grad/param norm = 1.3980e-01, time/batch = 0.7047s	
5449/30300 (epoch 8.992), train_loss = 1.58276159, grad/param norm = 1.4317e-01, time/batch = 0.7053s	
5450/30300 (epoch 8.993), train_loss = 1.70400035, grad/param norm = 1.7694e-01, time/batch = 0.7063s	
5451/30300 (epoch 8.995), train_loss = 1.59287623, grad/param norm = 1.6495e-01, time/batch = 0.7182s	
5452/30300 (epoch 8.997), train_loss = 1.58900423, grad/param norm = 1.5826e-01, time/batch = 0.7186s	
5453/30300 (epoch 8.998), train_loss = 1.66855182, grad/param norm = 1.8311e-01, time/batch = 0.7087s	
5454/30300 (epoch 9.000), train_loss = 1.45893230, grad/param norm = 1.6055e-01, time/batch = 0.7120s	
5455/30300 (epoch 9.002), train_loss = 1.58101694, grad/param norm = 1.6451e-01, time/batch = 0.7149s	
5456/30300 (epoch 9.003), train_loss = 1.56456057, grad/param norm = 1.5988e-01, time/batch = 0.7096s	
5457/30300 (epoch 9.005), train_loss = 1.53396252, grad/param norm = 1.7064e-01, time/batch = 0.7106s	
5458/30300 (epoch 9.007), train_loss = 1.68391893, grad/param norm = 1.7254e-01, time/batch = 0.7084s	
5459/30300 (epoch 9.008), train_loss = 1.47042118, grad/param norm = 1.5465e-01, time/batch = 0.7083s	
5460/30300 (epoch 9.010), train_loss = 1.47224101, grad/param norm = 1.7289e-01, time/batch = 0.7124s	
5461/30300 (epoch 9.012), train_loss = 1.44421305, grad/param norm = 1.4731e-01, time/batch = 0.7220s	
5462/30300 (epoch 9.013), train_loss = 1.54907664, grad/param norm = 1.6019e-01, time/batch = 0.7155s	
5463/30300 (epoch 9.015), train_loss = 1.50153587, grad/param norm = 1.4883e-01, time/batch = 0.7071s	
5464/30300 (epoch 9.017), train_loss = 1.41953430, grad/param norm = 1.5662e-01, time/batch = 0.7080s	
5465/30300 (epoch 9.018), train_loss = 1.52741237, grad/param norm = 1.5717e-01, time/batch = 0.7100s	
5466/30300 (epoch 9.020), train_loss = 1.69156514, grad/param norm = 1.7613e-01, time/batch = 0.7084s	
5467/30300 (epoch 9.021), train_loss = 1.66654726, grad/param norm = 1.6916e-01, time/batch = 0.7109s	
5468/30300 (epoch 9.023), train_loss = 1.44782425, grad/param norm = 1.5636e-01, time/batch = 0.7117s	
5469/30300 (epoch 9.025), train_loss = 1.46486034, grad/param norm = 1.7584e-01, time/batch = 0.7108s	
5470/30300 (epoch 9.026), train_loss = 1.60371294, grad/param norm = 1.7308e-01, time/batch = 0.7079s	
5471/30300 (epoch 9.028), train_loss = 1.60110669, grad/param norm = 1.5824e-01, time/batch = 0.7090s	
5472/30300 (epoch 9.030), train_loss = 1.42930777, grad/param norm = 1.5562e-01, time/batch = 0.7102s	
5473/30300 (epoch 9.031), train_loss = 1.52654958, grad/param norm = 1.7306e-01, time/batch = 0.7090s	
5474/30300 (epoch 9.033), train_loss = 1.53646213, grad/param norm = 1.6094e-01, time/batch = 0.7079s	
5475/30300 (epoch 9.035), train_loss = 1.62640725, grad/param norm = 1.6173e-01, time/batch = 0.7115s	
5476/30300 (epoch 9.036), train_loss = 1.58607861, grad/param norm = 1.6594e-01, time/batch = 0.7074s	
5477/30300 (epoch 9.038), train_loss = 1.53906497, grad/param norm = 1.5588e-01, time/batch = 0.7096s	
5478/30300 (epoch 9.040), train_loss = 1.22534423, grad/param norm = 1.4265e-01, time/batch = 0.7095s	
5479/30300 (epoch 9.041), train_loss = 1.29641732, grad/param norm = 1.4146e-01, time/batch = 0.7127s	
5480/30300 (epoch 9.043), train_loss = 1.59915627, grad/param norm = 1.5204e-01, time/batch = 0.7134s	
5481/30300 (epoch 9.045), train_loss = 1.48360983, grad/param norm = 1.6141e-01, time/batch = 0.7181s	
5482/30300 (epoch 9.046), train_loss = 1.60892938, grad/param norm = 1.6904e-01, time/batch = 0.7171s	
5483/30300 (epoch 9.048), train_loss = 1.58373569, grad/param norm = 1.7572e-01, time/batch = 0.7136s	
5484/30300 (epoch 9.050), train_loss = 1.59743949, grad/param norm = 1.6200e-01, time/batch = 0.7064s	
5485/30300 (epoch 9.051), train_loss = 1.56119276, grad/param norm = 1.6535e-01, time/batch = 0.7092s	
5486/30300 (epoch 9.053), train_loss = 1.40004151, grad/param norm = 1.6310e-01, time/batch = 0.7104s	
5487/30300 (epoch 9.054), train_loss = 1.47146184, grad/param norm = 1.5897e-01, time/batch = 0.7083s	
5488/30300 (epoch 9.056), train_loss = 1.42480110, grad/param norm = 1.5977e-01, time/batch = 0.7082s	
5489/30300 (epoch 9.058), train_loss = 1.52388689, grad/param norm = 1.7220e-01, time/batch = 0.7061s	
5490/30300 (epoch 9.059), train_loss = 1.49760289, grad/param norm = 1.6265e-01, time/batch = 0.7035s	
5491/30300 (epoch 9.061), train_loss = 1.70372560, grad/param norm = 1.7658e-01, time/batch = 0.7040s	
5492/30300 (epoch 9.063), train_loss = 1.49323833, grad/param norm = 1.5406e-01, time/batch = 0.7064s	
5493/30300 (epoch 9.064), train_loss = 1.61541671, grad/param norm = 1.6264e-01, time/batch = 0.7091s	
5494/30300 (epoch 9.066), train_loss = 1.51267015, grad/param norm = 1.4736e-01, time/batch = 0.7088s	
5495/30300 (epoch 9.068), train_loss = 1.37411114, grad/param norm = 1.4463e-01, time/batch = 0.7214s	
5496/30300 (epoch 9.069), train_loss = 1.66288649, grad/param norm = 1.5975e-01, time/batch = 0.7080s	
5497/30300 (epoch 9.071), train_loss = 1.58855587, grad/param norm = 1.6513e-01, time/batch = 0.7030s	
5498/30300 (epoch 9.073), train_loss = 1.59316989, grad/param norm = 1.7824e-01, time/batch = 0.7083s	
5499/30300 (epoch 9.074), train_loss = 1.56673249, grad/param norm = 1.5401e-01, time/batch = 0.7138s	
5500/30300 (epoch 9.076), train_loss = 1.49924831, grad/param norm = 1.5571e-01, time/batch = 0.7122s	
5501/30300 (epoch 9.078), train_loss = 1.41393067, grad/param norm = 1.6295e-01, time/batch = 0.7054s	
5502/30300 (epoch 9.079), train_loss = 1.40699248, grad/param norm = 1.3924e-01, time/batch = 0.7064s	
5503/30300 (epoch 9.081), train_loss = 1.57457884, grad/param norm = 1.5879e-01, time/batch = 0.7047s	
5504/30300 (epoch 9.083), train_loss = 1.69455282, grad/param norm = 1.7533e-01, time/batch = 0.7095s	
5505/30300 (epoch 9.084), train_loss = 1.42488132, grad/param norm = 1.6447e-01, time/batch = 0.7211s	
5506/30300 (epoch 9.086), train_loss = 1.47552921, grad/param norm = 1.6073e-01, time/batch = 0.7066s	
5507/30300 (epoch 9.087), train_loss = 1.39608491, grad/param norm = 1.4173e-01, time/batch = 0.7070s	
5508/30300 (epoch 9.089), train_loss = 1.48333607, grad/param norm = 1.5642e-01, time/batch = 0.7134s	
5509/30300 (epoch 9.091), train_loss = 1.61106719, grad/param norm = 1.6323e-01, time/batch = 0.7130s	
5510/30300 (epoch 9.092), train_loss = 1.48772842, grad/param norm = 1.5733e-01, time/batch = 0.7121s	
5511/30300 (epoch 9.094), train_loss = 1.74279955, grad/param norm = 1.7189e-01, time/batch = 0.7175s	
5512/30300 (epoch 9.096), train_loss = 1.59977750, grad/param norm = 1.6069e-01, time/batch = 0.7099s	
5513/30300 (epoch 9.097), train_loss = 1.40396704, grad/param norm = 1.5436e-01, time/batch = 0.7309s	
5514/30300 (epoch 9.099), train_loss = 1.70690552, grad/param norm = 1.6584e-01, time/batch = 0.7219s	
5515/30300 (epoch 9.101), train_loss = 1.80266947, grad/param norm = 1.8072e-01, time/batch = 0.7293s	
5516/30300 (epoch 9.102), train_loss = 1.56882913, grad/param norm = 1.7375e-01, time/batch = 0.7125s	
5517/30300 (epoch 9.104), train_loss = 1.47005455, grad/param norm = 1.6413e-01, time/batch = 0.7233s	
5518/30300 (epoch 9.106), train_loss = 1.55209493, grad/param norm = 1.5583e-01, time/batch = 0.7167s	
5519/30300 (epoch 9.107), train_loss = 1.54117449, grad/param norm = 1.5041e-01, time/batch = 0.7034s	
5520/30300 (epoch 9.109), train_loss = 1.61793743, grad/param norm = 1.6535e-01, time/batch = 0.7108s	
5521/30300 (epoch 9.111), train_loss = 1.66815793, grad/param norm = 1.7170e-01, time/batch = 0.7060s	
5522/30300 (epoch 9.112), train_loss = 1.56389773, grad/param norm = 1.5092e-01, time/batch = 0.7056s	
5523/30300 (epoch 9.114), train_loss = 1.52738468, grad/param norm = 1.5819e-01, time/batch = 0.7056s	
5524/30300 (epoch 9.116), train_loss = 1.56894902, grad/param norm = 1.5527e-01, time/batch = 0.7193s	
5525/30300 (epoch 9.117), train_loss = 1.52612570, grad/param norm = 1.5351e-01, time/batch = 0.7152s	
5526/30300 (epoch 9.119), train_loss = 1.43813499, grad/param norm = 1.6465e-01, time/batch = 0.7069s	
5527/30300 (epoch 9.120), train_loss = 1.55154668, grad/param norm = 1.7171e-01, time/batch = 0.7110s	
5528/30300 (epoch 9.122), train_loss = 1.64227854, grad/param norm = 1.6563e-01, time/batch = 0.7078s	
5529/30300 (epoch 9.124), train_loss = 1.74674668, grad/param norm = 1.8640e-01, time/batch = 0.7119s	
5530/30300 (epoch 9.125), train_loss = 1.36397033, grad/param norm = 1.4651e-01, time/batch = 0.7081s	
5531/30300 (epoch 9.127), train_loss = 1.55968162, grad/param norm = 1.7107e-01, time/batch = 0.7132s	
5532/30300 (epoch 9.129), train_loss = 1.67697661, grad/param norm = 1.5760e-01, time/batch = 0.7123s	
5533/30300 (epoch 9.130), train_loss = 1.67573834, grad/param norm = 1.5376e-01, time/batch = 0.7126s	
5534/30300 (epoch 9.132), train_loss = 1.57475696, grad/param norm = 1.8238e-01, time/batch = 0.7246s	
5535/30300 (epoch 9.134), train_loss = 1.42001145, grad/param norm = 1.5987e-01, time/batch = 0.7132s	
5536/30300 (epoch 9.135), train_loss = 1.49584539, grad/param norm = 1.6834e-01, time/batch = 0.7083s	
5537/30300 (epoch 9.137), train_loss = 1.65703237, grad/param norm = 1.6522e-01, time/batch = 0.7078s	
5538/30300 (epoch 9.139), train_loss = 1.51447707, grad/param norm = 1.6088e-01, time/batch = 0.7050s	
5539/30300 (epoch 9.140), train_loss = 1.73286884, grad/param norm = 1.7994e-01, time/batch = 0.7045s	
5540/30300 (epoch 9.142), train_loss = 1.94833789, grad/param norm = 1.1936e+00, time/batch = 0.7044s	
5541/30300 (epoch 9.144), train_loss = 1.73465010, grad/param norm = 2.6007e-01, time/batch = 0.7065s	
5542/30300 (epoch 9.145), train_loss = 1.72353106, grad/param norm = 1.7134e-01, time/batch = 0.7051s	
5543/30300 (epoch 9.147), train_loss = 1.59340862, grad/param norm = 1.6296e-01, time/batch = 0.7053s	
5544/30300 (epoch 9.149), train_loss = 1.76606686, grad/param norm = 1.6620e-01, time/batch = 0.7056s	
5545/30300 (epoch 9.150), train_loss = 1.68422508, grad/param norm = 1.5603e-01, time/batch = 0.7086s	
5546/30300 (epoch 9.152), train_loss = 1.49088914, grad/param norm = 1.8010e-01, time/batch = 0.7089s	
5547/30300 (epoch 9.153), train_loss = 1.57739600, grad/param norm = 1.7094e-01, time/batch = 0.7059s	
5548/30300 (epoch 9.155), train_loss = 1.33940060, grad/param norm = 1.4163e-01, time/batch = 0.7072s	
5549/30300 (epoch 9.157), train_loss = 1.54068568, grad/param norm = 1.7233e-01, time/batch = 0.7085s	
5550/30300 (epoch 9.158), train_loss = 1.61251348, grad/param norm = 1.6273e-01, time/batch = 0.7087s	
5551/30300 (epoch 9.160), train_loss = 1.47450296, grad/param norm = 1.5225e-01, time/batch = 0.7108s	
5552/30300 (epoch 9.162), train_loss = 1.44299300, grad/param norm = 1.4676e-01, time/batch = 0.7075s	
5553/30300 (epoch 9.163), train_loss = 1.47706825, grad/param norm = 1.7964e-01, time/batch = 0.7088s	
5554/30300 (epoch 9.165), train_loss = 1.59770766, grad/param norm = 1.5168e-01, time/batch = 0.7100s	
5555/30300 (epoch 9.167), train_loss = 1.59423628, grad/param norm = 1.7066e-01, time/batch = 0.7076s	
5556/30300 (epoch 9.168), train_loss = 1.53025372, grad/param norm = 1.5693e-01, time/batch = 0.7068s	
5557/30300 (epoch 9.170), train_loss = 1.59220070, grad/param norm = 1.5658e-01, time/batch = 0.7079s	
5558/30300 (epoch 9.172), train_loss = 1.49546449, grad/param norm = 1.5788e-01, time/batch = 0.7075s	
5559/30300 (epoch 9.173), train_loss = 1.61250520, grad/param norm = 1.7616e-01, time/batch = 0.7093s	
5560/30300 (epoch 9.175), train_loss = 1.52347661, grad/param norm = 1.4826e-01, time/batch = 0.7088s	
5561/30300 (epoch 9.177), train_loss = 1.56357298, grad/param norm = 1.5964e-01, time/batch = 0.7079s	
5562/30300 (epoch 9.178), train_loss = 1.29494649, grad/param norm = 1.4819e-01, time/batch = 0.7093s	
5563/30300 (epoch 9.180), train_loss = 1.44567827, grad/param norm = 1.4169e-01, time/batch = 0.7091s	
5564/30300 (epoch 9.182), train_loss = 1.46005412, grad/param norm = 1.7476e-01, time/batch = 0.7057s	
5565/30300 (epoch 9.183), train_loss = 1.41896360, grad/param norm = 1.5046e-01, time/batch = 0.7070s	
5566/30300 (epoch 9.185), train_loss = 1.81975271, grad/param norm = 1.5803e-01, time/batch = 0.7099s	
5567/30300 (epoch 9.186), train_loss = 1.79785727, grad/param norm = 1.7485e-01, time/batch = 0.7105s	
5568/30300 (epoch 9.188), train_loss = 1.61827784, grad/param norm = 1.6326e-01, time/batch = 0.7206s	
5569/30300 (epoch 9.190), train_loss = 1.45892621, grad/param norm = 1.5027e-01, time/batch = 0.7084s	
5570/30300 (epoch 9.191), train_loss = 1.63578268, grad/param norm = 1.6802e-01, time/batch = 0.7086s	
5571/30300 (epoch 9.193), train_loss = 1.39654422, grad/param norm = 1.4879e-01, time/batch = 0.7090s	
5572/30300 (epoch 9.195), train_loss = 1.55962757, grad/param norm = 1.5625e-01, time/batch = 0.7076s	
5573/30300 (epoch 9.196), train_loss = 1.53536401, grad/param norm = 1.4710e-01, time/batch = 0.7090s	
5574/30300 (epoch 9.198), train_loss = 1.30498472, grad/param norm = 1.5119e-01, time/batch = 0.7064s	
5575/30300 (epoch 9.200), train_loss = 1.51685638, grad/param norm = 1.5326e-01, time/batch = 0.7087s	
5576/30300 (epoch 9.201), train_loss = 1.65064055, grad/param norm = 1.7302e-01, time/batch = 0.7085s	
5577/30300 (epoch 9.203), train_loss = 1.51990794, grad/param norm = 1.5810e-01, time/batch = 0.7074s	
5578/30300 (epoch 9.205), train_loss = 1.75200440, grad/param norm = 1.6036e-01, time/batch = 0.7072s	
5579/30300 (epoch 9.206), train_loss = 1.76052608, grad/param norm = 1.6843e-01, time/batch = 0.7092s	
5580/30300 (epoch 9.208), train_loss = 1.69418719, grad/param norm = 1.7760e-01, time/batch = 0.7084s	
5581/30300 (epoch 9.210), train_loss = 1.55097488, grad/param norm = 1.4323e-01, time/batch = 0.7111s	
5582/30300 (epoch 9.211), train_loss = 1.58856943, grad/param norm = 1.5721e-01, time/batch = 0.7093s	
5583/30300 (epoch 9.213), train_loss = 1.46599208, grad/param norm = 1.5179e-01, time/batch = 0.7088s	
5584/30300 (epoch 9.215), train_loss = 1.35237612, grad/param norm = 1.5924e-01, time/batch = 0.7084s	
5585/30300 (epoch 9.216), train_loss = 1.51169835, grad/param norm = 1.7547e-01, time/batch = 0.7141s	
5586/30300 (epoch 9.218), train_loss = 1.43496561, grad/param norm = 1.4584e-01, time/batch = 0.7183s	
5587/30300 (epoch 9.219), train_loss = 1.35012927, grad/param norm = 1.4051e-01, time/batch = 0.7192s	
5588/30300 (epoch 9.221), train_loss = 1.37239043, grad/param norm = 1.4515e-01, time/batch = 0.7182s	
5589/30300 (epoch 9.223), train_loss = 1.52526690, grad/param norm = 1.5347e-01, time/batch = 0.7111s	
5590/30300 (epoch 9.224), train_loss = 1.36367051, grad/param norm = 1.5000e-01, time/batch = 0.7101s	
5591/30300 (epoch 9.226), train_loss = 1.64100730, grad/param norm = 1.8482e-01, time/batch = 0.7157s	
5592/30300 (epoch 9.228), train_loss = 1.65208193, grad/param norm = 1.5591e-01, time/batch = 0.7106s	
5593/30300 (epoch 9.229), train_loss = 1.42953462, grad/param norm = 1.6719e-01, time/batch = 0.7091s	
5594/30300 (epoch 9.231), train_loss = 1.54696113, grad/param norm = 1.5760e-01, time/batch = 0.7105s	
5595/30300 (epoch 9.233), train_loss = 1.46641480, grad/param norm = 1.5626e-01, time/batch = 0.7115s	
5596/30300 (epoch 9.234), train_loss = 1.60108664, grad/param norm = 1.6838e-01, time/batch = 0.7216s	
5597/30300 (epoch 9.236), train_loss = 1.44958452, grad/param norm = 1.5574e-01, time/batch = 0.7213s	
5598/30300 (epoch 9.238), train_loss = 1.59153309, grad/param norm = 1.7632e-01, time/batch = 0.7186s	
5599/30300 (epoch 9.239), train_loss = 1.56788892, grad/param norm = 1.4895e-01, time/batch = 0.7135s	
5600/30300 (epoch 9.241), train_loss = 1.60866913, grad/param norm = 1.7569e-01, time/batch = 0.7106s	
5601/30300 (epoch 9.243), train_loss = 1.56455202, grad/param norm = 1.6584e-01, time/batch = 0.7228s	
5602/30300 (epoch 9.244), train_loss = 1.81872916, grad/param norm = 1.7732e-01, time/batch = 0.7182s	
5603/30300 (epoch 9.246), train_loss = 1.50761116, grad/param norm = 1.5938e-01, time/batch = 0.7103s	
5604/30300 (epoch 9.248), train_loss = 1.55647420, grad/param norm = 1.5479e-01, time/batch = 0.7086s	
5605/30300 (epoch 9.249), train_loss = 1.39260348, grad/param norm = 1.4941e-01, time/batch = 0.7113s	
5606/30300 (epoch 9.251), train_loss = 1.42015076, grad/param norm = 1.5379e-01, time/batch = 0.7191s	
5607/30300 (epoch 9.252), train_loss = 1.68294511, grad/param norm = 1.6837e-01, time/batch = 0.7270s	
5608/30300 (epoch 9.254), train_loss = 1.64702204, grad/param norm = 1.7343e-01, time/batch = 0.7146s	
5609/30300 (epoch 9.256), train_loss = 1.53123146, grad/param norm = 1.4734e-01, time/batch = 0.7141s	
5610/30300 (epoch 9.257), train_loss = 1.65291311, grad/param norm = 1.6723e-01, time/batch = 0.7209s	
5611/30300 (epoch 9.259), train_loss = 1.57790764, grad/param norm = 1.5556e-01, time/batch = 0.7213s	
5612/30300 (epoch 9.261), train_loss = 1.65896450, grad/param norm = 1.5421e-01, time/batch = 0.7220s	
5613/30300 (epoch 9.262), train_loss = 1.52094838, grad/param norm = 1.5257e-01, time/batch = 0.7212s	
5614/30300 (epoch 9.264), train_loss = 1.53745839, grad/param norm = 1.6035e-01, time/batch = 0.7205s	
5615/30300 (epoch 9.266), train_loss = 1.44921643, grad/param norm = 1.5193e-01, time/batch = 0.7176s	
5616/30300 (epoch 9.267), train_loss = 1.71651320, grad/param norm = 1.7576e-01, time/batch = 0.7159s	
5617/30300 (epoch 9.269), train_loss = 1.53036003, grad/param norm = 1.5824e-01, time/batch = 0.7121s	
5618/30300 (epoch 9.271), train_loss = 1.51905492, grad/param norm = 1.5920e-01, time/batch = 0.7071s	
5619/30300 (epoch 9.272), train_loss = 1.58607070, grad/param norm = 1.6388e-01, time/batch = 0.7069s	
5620/30300 (epoch 9.274), train_loss = 1.72451451, grad/param norm = 1.6842e-01, time/batch = 0.7090s	
5621/30300 (epoch 9.276), train_loss = 1.65674614, grad/param norm = 1.6822e-01, time/batch = 0.7119s	
5622/30300 (epoch 9.277), train_loss = 1.47377176, grad/param norm = 1.5885e-01, time/batch = 0.7126s	
5623/30300 (epoch 9.279), train_loss = 1.57625990, grad/param norm = 1.5303e-01, time/batch = 0.7094s	
5624/30300 (epoch 9.281), train_loss = 1.60689049, grad/param norm = 1.6986e-01, time/batch = 0.7139s	
5625/30300 (epoch 9.282), train_loss = 1.48130903, grad/param norm = 1.4390e-01, time/batch = 0.7150s	
5626/30300 (epoch 9.284), train_loss = 1.74653496, grad/param norm = 1.8169e-01, time/batch = 0.7156s	
5627/30300 (epoch 9.285), train_loss = 1.56742638, grad/param norm = 1.5797e-01, time/batch = 0.7095s	
5628/30300 (epoch 9.287), train_loss = 1.54644383, grad/param norm = 1.5932e-01, time/batch = 0.7110s	
5629/30300 (epoch 9.289), train_loss = 1.59236771, grad/param norm = 1.6687e-01, time/batch = 0.7113s	
5630/30300 (epoch 9.290), train_loss = 1.27810877, grad/param norm = 1.4269e-01, time/batch = 0.7129s	
5631/30300 (epoch 9.292), train_loss = 1.44195777, grad/param norm = 1.4592e-01, time/batch = 0.7205s	
5632/30300 (epoch 9.294), train_loss = 1.70440953, grad/param norm = 1.5592e-01, time/batch = 0.7117s	
5633/30300 (epoch 9.295), train_loss = 1.50840771, grad/param norm = 1.4227e-01, time/batch = 0.7098s	
5634/30300 (epoch 9.297), train_loss = 1.44717476, grad/param norm = 1.4268e-01, time/batch = 0.7072s	
5635/30300 (epoch 9.299), train_loss = 1.51228169, grad/param norm = 1.6546e-01, time/batch = 0.7098s	
5636/30300 (epoch 9.300), train_loss = 1.57135118, grad/param norm = 1.5239e-01, time/batch = 0.7109s	
5637/30300 (epoch 9.302), train_loss = 1.45670133, grad/param norm = 1.5443e-01, time/batch = 0.7077s	
5638/30300 (epoch 9.304), train_loss = 1.39716053, grad/param norm = 1.4893e-01, time/batch = 0.7075s	
5639/30300 (epoch 9.305), train_loss = 1.46097800, grad/param norm = 1.4437e-01, time/batch = 0.7098s	
5640/30300 (epoch 9.307), train_loss = 1.52063054, grad/param norm = 1.4965e-01, time/batch = 0.7162s	
5641/30300 (epoch 9.309), train_loss = 1.61653557, grad/param norm = 1.5293e-01, time/batch = 0.7191s	
5642/30300 (epoch 9.310), train_loss = 1.47798012, grad/param norm = 1.5275e-01, time/batch = 0.7105s	
5643/30300 (epoch 9.312), train_loss = 1.60358892, grad/param norm = 1.4774e-01, time/batch = 0.7141s	
5644/30300 (epoch 9.314), train_loss = 1.56978507, grad/param norm = 1.6050e-01, time/batch = 0.7134s	
5645/30300 (epoch 9.315), train_loss = 1.59272426, grad/param norm = 1.6385e-01, time/batch = 0.7121s	
5646/30300 (epoch 9.317), train_loss = 1.65034421, grad/param norm = 1.7552e-01, time/batch = 0.7128s	
5647/30300 (epoch 9.318), train_loss = 1.71914064, grad/param norm = 1.8001e-01, time/batch = 0.7133s	
5648/30300 (epoch 9.320), train_loss = 1.69620125, grad/param norm = 1.7546e-01, time/batch = 0.7103s	
5649/30300 (epoch 9.322), train_loss = 1.42431201, grad/param norm = 1.5277e-01, time/batch = 0.7088s	
5650/30300 (epoch 9.323), train_loss = 1.66558870, grad/param norm = 1.6167e-01, time/batch = 0.7196s	
5651/30300 (epoch 9.325), train_loss = 1.48763827, grad/param norm = 1.4212e-01, time/batch = 0.7168s	
5652/30300 (epoch 9.327), train_loss = 1.48004264, grad/param norm = 1.5393e-01, time/batch = 0.7068s	
5653/30300 (epoch 9.328), train_loss = 1.47252237, grad/param norm = 1.4218e-01, time/batch = 0.7089s	
5654/30300 (epoch 9.330), train_loss = 1.62228320, grad/param norm = 1.5235e-01, time/batch = 0.7073s	
5655/30300 (epoch 9.332), train_loss = 1.63105447, grad/param norm = 1.6134e-01, time/batch = 0.7075s	
5656/30300 (epoch 9.333), train_loss = 1.55898573, grad/param norm = 1.5802e-01, time/batch = 0.7078s	
5657/30300 (epoch 9.335), train_loss = 1.36421767, grad/param norm = 1.4872e-01, time/batch = 0.7069s	
5658/30300 (epoch 9.337), train_loss = 1.71771659, grad/param norm = 1.6336e-01, time/batch = 0.7085s	
5659/30300 (epoch 9.338), train_loss = 1.43722905, grad/param norm = 1.5327e-01, time/batch = 0.7112s	
5660/30300 (epoch 9.340), train_loss = 1.40954018, grad/param norm = 1.5645e-01, time/batch = 0.7089s	
5661/30300 (epoch 9.342), train_loss = 1.61167437, grad/param norm = 1.5250e-01, time/batch = 0.7081s	
5662/30300 (epoch 9.343), train_loss = 1.61702113, grad/param norm = 1.5706e-01, time/batch = 0.7095s	
5663/30300 (epoch 9.345), train_loss = 1.54939724, grad/param norm = 1.4903e-01, time/batch = 0.7112s	
5664/30300 (epoch 9.347), train_loss = 1.34240467, grad/param norm = 1.3158e-01, time/batch = 0.7067s	
5665/30300 (epoch 9.348), train_loss = 1.41440978, grad/param norm = 1.6281e-01, time/batch = 0.7036s	
5666/30300 (epoch 9.350), train_loss = 1.51615025, grad/param norm = 1.5434e-01, time/batch = 0.7094s	
5667/30300 (epoch 9.351), train_loss = 1.53590003, grad/param norm = 1.5875e-01, time/batch = 0.7118s	
5668/30300 (epoch 9.353), train_loss = 1.31122422, grad/param norm = 1.5377e-01, time/batch = 0.7104s	
5669/30300 (epoch 9.355), train_loss = 1.48587336, grad/param norm = 1.5332e-01, time/batch = 0.7084s	
5670/30300 (epoch 9.356), train_loss = 1.65068745, grad/param norm = 1.6743e-01, time/batch = 0.7090s	
5671/30300 (epoch 9.358), train_loss = 1.69909662, grad/param norm = 1.5326e-01, time/batch = 0.7085s	
5672/30300 (epoch 9.360), train_loss = 1.45117236, grad/param norm = 1.5984e-01, time/batch = 0.7096s	
5673/30300 (epoch 9.361), train_loss = 1.56567774, grad/param norm = 1.7477e-01, time/batch = 0.7063s	
5674/30300 (epoch 9.363), train_loss = 1.61696015, grad/param norm = 1.5820e-01, time/batch = 0.7085s	
5675/30300 (epoch 9.365), train_loss = 1.47624328, grad/param norm = 1.6463e-01, time/batch = 0.7045s	
5676/30300 (epoch 9.366), train_loss = 1.45087479, grad/param norm = 1.4813e-01, time/batch = 0.7129s	
5677/30300 (epoch 9.368), train_loss = 1.31662291, grad/param norm = 1.5038e-01, time/batch = 0.7034s	
5678/30300 (epoch 9.370), train_loss = 1.42049674, grad/param norm = 1.4843e-01, time/batch = 0.7074s	
5679/30300 (epoch 9.371), train_loss = 1.55959030, grad/param norm = 1.4486e-01, time/batch = 0.7157s	
5680/30300 (epoch 9.373), train_loss = 1.43513106, grad/param norm = 1.3941e-01, time/batch = 0.7099s	
5681/30300 (epoch 9.375), train_loss = 1.42287735, grad/param norm = 1.4152e-01, time/batch = 0.7129s	
5682/30300 (epoch 9.376), train_loss = 1.46242279, grad/param norm = 1.4200e-01, time/batch = 0.7034s	
5683/30300 (epoch 9.378), train_loss = 1.48437819, grad/param norm = 1.5162e-01, time/batch = 0.7208s	
5684/30300 (epoch 9.380), train_loss = 1.75739966, grad/param norm = 1.7075e-01, time/batch = 0.7218s	
5685/30300 (epoch 9.381), train_loss = 1.43289622, grad/param norm = 1.4469e-01, time/batch = 0.7106s	
5686/30300 (epoch 9.383), train_loss = 1.53762893, grad/param norm = 1.6444e-01, time/batch = 0.7092s	
5687/30300 (epoch 9.384), train_loss = 1.62384717, grad/param norm = 1.4385e-01, time/batch = 0.7068s	
5688/30300 (epoch 9.386), train_loss = 1.38385352, grad/param norm = 1.5372e-01, time/batch = 0.7093s	
5689/30300 (epoch 9.388), train_loss = 1.39650414, grad/param norm = 1.3966e-01, time/batch = 0.7041s	
5690/30300 (epoch 9.389), train_loss = 1.55025863, grad/param norm = 1.5654e-01, time/batch = 0.7084s	
5691/30300 (epoch 9.391), train_loss = 1.58108146, grad/param norm = 1.4557e-01, time/batch = 0.7151s	
5692/30300 (epoch 9.393), train_loss = 1.32962127, grad/param norm = 1.3469e-01, time/batch = 0.7086s	
5693/30300 (epoch 9.394), train_loss = 1.52487484, grad/param norm = 1.4845e-01, time/batch = 0.7120s	
5694/30300 (epoch 9.396), train_loss = 1.69224778, grad/param norm = 1.4966e-01, time/batch = 0.7230s	
5695/30300 (epoch 9.398), train_loss = 1.45477570, grad/param norm = 1.3949e-01, time/batch = 0.7092s	
5696/30300 (epoch 9.399), train_loss = 1.49200406, grad/param norm = 1.5186e-01, time/batch = 0.7093s	
5697/30300 (epoch 9.401), train_loss = 1.62409569, grad/param norm = 1.6268e-01, time/batch = 0.7090s	
5698/30300 (epoch 9.403), train_loss = 1.47043891, grad/param norm = 1.4498e-01, time/batch = 0.7043s	
5699/30300 (epoch 9.404), train_loss = 1.42005807, grad/param norm = 1.7944e-01, time/batch = 0.7081s	
5700/30300 (epoch 9.406), train_loss = 1.53440775, grad/param norm = 1.5520e-01, time/batch = 0.7070s	
5701/30300 (epoch 9.408), train_loss = 1.39600706, grad/param norm = 1.5610e-01, time/batch = 0.7039s	
5702/30300 (epoch 9.409), train_loss = 1.33659759, grad/param norm = 1.5226e-01, time/batch = 0.7075s	
5703/30300 (epoch 9.411), train_loss = 1.36343693, grad/param norm = 1.4323e-01, time/batch = 0.7065s	
5704/30300 (epoch 9.413), train_loss = 1.33384325, grad/param norm = 1.4477e-01, time/batch = 0.7057s	
5705/30300 (epoch 9.414), train_loss = 1.62578365, grad/param norm = 1.5798e-01, time/batch = 0.7063s	
5706/30300 (epoch 9.416), train_loss = 1.48387284, grad/param norm = 1.6365e-01, time/batch = 0.7104s	
5707/30300 (epoch 9.417), train_loss = 1.45640042, grad/param norm = 1.4825e-01, time/batch = 0.7063s	
5708/30300 (epoch 9.419), train_loss = 1.34133860, grad/param norm = 1.3677e-01, time/batch = 0.7054s	
5709/30300 (epoch 9.421), train_loss = 1.44246670, grad/param norm = 1.3935e-01, time/batch = 0.7079s	
5710/30300 (epoch 9.422), train_loss = 1.47062180, grad/param norm = 1.4253e-01, time/batch = 0.7096s	
5711/30300 (epoch 9.424), train_loss = 1.51367687, grad/param norm = 1.5232e-01, time/batch = 0.7098s	
5712/30300 (epoch 9.426), train_loss = 1.36993376, grad/param norm = 1.5096e-01, time/batch = 0.7062s	
5713/30300 (epoch 9.427), train_loss = 1.49331317, grad/param norm = 1.5778e-01, time/batch = 0.7098s	
5714/30300 (epoch 9.429), train_loss = 1.54830133, grad/param norm = 1.7108e-01, time/batch = 0.7077s	
5715/30300 (epoch 9.431), train_loss = 1.58218333, grad/param norm = 1.6689e-01, time/batch = 0.7069s	
5716/30300 (epoch 9.432), train_loss = 1.47445767, grad/param norm = 1.4838e-01, time/batch = 0.6915s	
5717/30300 (epoch 9.434), train_loss = 1.36031016, grad/param norm = 1.5984e-01, time/batch = 0.6877s	
5718/30300 (epoch 9.436), train_loss = 1.65047575, grad/param norm = 1.6503e-01, time/batch = 0.6905s	
5719/30300 (epoch 9.437), train_loss = 1.42590622, grad/param norm = 1.8193e-01, time/batch = 0.6918s	
5720/30300 (epoch 9.439), train_loss = 1.43422204, grad/param norm = 1.5258e-01, time/batch = 0.6896s	
5721/30300 (epoch 9.441), train_loss = 1.42815813, grad/param norm = 1.4434e-01, time/batch = 0.6934s	
5722/30300 (epoch 9.442), train_loss = 1.38528783, grad/param norm = 1.4795e-01, time/batch = 0.6925s	
5723/30300 (epoch 9.444), train_loss = 1.27243970, grad/param norm = 1.4651e-01, time/batch = 0.7043s	
5724/30300 (epoch 9.446), train_loss = 1.45025709, grad/param norm = 1.5225e-01, time/batch = 0.6906s	
5725/30300 (epoch 9.447), train_loss = 1.48267514, grad/param norm = 1.5423e-01, time/batch = 0.7006s	
5726/30300 (epoch 9.449), train_loss = 1.41663134, grad/param norm = 1.5035e-01, time/batch = 0.6907s	
5727/30300 (epoch 9.450), train_loss = 1.60593435, grad/param norm = 1.4751e-01, time/batch = 0.6904s	
5728/30300 (epoch 9.452), train_loss = 1.50719542, grad/param norm = 1.3906e-01, time/batch = 0.6956s	
5729/30300 (epoch 9.454), train_loss = 1.49915679, grad/param norm = 1.4296e-01, time/batch = 0.7032s	
5730/30300 (epoch 9.455), train_loss = 1.60667052, grad/param norm = 1.6199e-01, time/batch = 0.6919s	
5731/30300 (epoch 9.457), train_loss = 1.54824593, grad/param norm = 1.5411e-01, time/batch = 0.6946s	
5732/30300 (epoch 9.459), train_loss = 1.59857342, grad/param norm = 1.7349e-01, time/batch = 0.7210s	
5733/30300 (epoch 9.460), train_loss = 1.60670715, grad/param norm = 1.7300e-01, time/batch = 0.7011s	
5734/30300 (epoch 9.462), train_loss = 1.60960718, grad/param norm = 1.5394e-01, time/batch = 0.6945s	
5735/30300 (epoch 9.464), train_loss = 1.37869789, grad/param norm = 1.5589e-01, time/batch = 0.7209s	
5736/30300 (epoch 9.465), train_loss = 1.31986452, grad/param norm = 1.4166e-01, time/batch = 0.6909s	
5737/30300 (epoch 9.467), train_loss = 1.25479309, grad/param norm = 1.3624e-01, time/batch = 0.6872s	
5738/30300 (epoch 9.469), train_loss = 1.42416096, grad/param norm = 1.5603e-01, time/batch = 0.6907s	
5739/30300 (epoch 9.470), train_loss = 1.45105233, grad/param norm = 1.4788e-01, time/batch = 0.6927s	
5740/30300 (epoch 9.472), train_loss = 1.43082940, grad/param norm = 1.4145e-01, time/batch = 0.6948s	
5741/30300 (epoch 9.474), train_loss = 1.52642481, grad/param norm = 1.6470e-01, time/batch = 0.6925s	
5742/30300 (epoch 9.475), train_loss = 1.39047612, grad/param norm = 1.5670e-01, time/batch = 0.6922s	
5743/30300 (epoch 9.477), train_loss = 1.52891299, grad/param norm = 1.7330e-01, time/batch = 0.6906s	
5744/30300 (epoch 9.479), train_loss = 1.52115222, grad/param norm = 1.5806e-01, time/batch = 0.7033s	
5745/30300 (epoch 9.480), train_loss = 1.54075174, grad/param norm = 1.5401e-01, time/batch = 0.7042s	
5746/30300 (epoch 9.482), train_loss = 1.54135182, grad/param norm = 1.4748e-01, time/batch = 0.7190s	
5747/30300 (epoch 9.483), train_loss = 1.46207314, grad/param norm = 1.5482e-01, time/batch = 0.7058s	
5748/30300 (epoch 9.485), train_loss = 1.49621229, grad/param norm = 1.5192e-01, time/batch = 0.6884s	
5749/30300 (epoch 9.487), train_loss = 1.54807908, grad/param norm = 1.6222e-01, time/batch = 0.6902s	
5750/30300 (epoch 9.488), train_loss = 1.53514498, grad/param norm = 1.4999e-01, time/batch = 0.6965s	
5751/30300 (epoch 9.490), train_loss = 1.39255234, grad/param norm = 1.5265e-01, time/batch = 0.6927s	
5752/30300 (epoch 9.492), train_loss = 1.53541069, grad/param norm = 1.5947e-01, time/batch = 0.6891s	
5753/30300 (epoch 9.493), train_loss = 1.43984415, grad/param norm = 1.5423e-01, time/batch = 0.6881s	
5754/30300 (epoch 9.495), train_loss = 1.44452009, grad/param norm = 1.5458e-01, time/batch = 0.6882s	
5755/30300 (epoch 9.497), train_loss = 1.53660407, grad/param norm = 1.5877e-01, time/batch = 0.6978s	
5756/30300 (epoch 9.498), train_loss = 1.51007761, grad/param norm = 1.5356e-01, time/batch = 0.6943s	
5757/30300 (epoch 9.500), train_loss = 1.62940981, grad/param norm = 1.7031e-01, time/batch = 0.6934s	
5758/30300 (epoch 9.502), train_loss = 1.43753922, grad/param norm = 1.5487e-01, time/batch = 0.6874s	
5759/30300 (epoch 9.503), train_loss = 1.57520169, grad/param norm = 1.4970e-01, time/batch = 0.6888s	
5760/30300 (epoch 9.505), train_loss = 1.49475643, grad/param norm = 1.5003e-01, time/batch = 0.7054s	
5761/30300 (epoch 9.507), train_loss = 1.45682718, grad/param norm = 1.8610e-01, time/batch = 0.7180s	
5762/30300 (epoch 9.508), train_loss = 1.56181835, grad/param norm = 1.8172e-01, time/batch = 0.6921s	
5763/30300 (epoch 9.510), train_loss = 1.58004787, grad/param norm = 1.8337e-01, time/batch = 0.6974s	
5764/30300 (epoch 9.512), train_loss = 1.42252470, grad/param norm = 1.5712e-01, time/batch = 0.7103s	
5765/30300 (epoch 9.513), train_loss = 1.59652340, grad/param norm = 1.5687e-01, time/batch = 0.7086s	
5766/30300 (epoch 9.515), train_loss = 1.48492277, grad/param norm = 1.5982e-01, time/batch = 0.7076s	
5767/30300 (epoch 9.517), train_loss = 1.33959366, grad/param norm = 1.4663e-01, time/batch = 0.6881s	
5768/30300 (epoch 9.518), train_loss = 1.57621594, grad/param norm = 1.6240e-01, time/batch = 0.7007s	
5769/30300 (epoch 9.520), train_loss = 1.73698941, grad/param norm = 1.7727e-01, time/batch = 0.6949s	
5770/30300 (epoch 9.521), train_loss = 1.37470461, grad/param norm = 1.6343e-01, time/batch = 0.6922s	
5771/30300 (epoch 9.523), train_loss = 1.64513574, grad/param norm = 1.7027e-01, time/batch = 0.6899s	
5772/30300 (epoch 9.525), train_loss = 1.44677290, grad/param norm = 1.5555e-01, time/batch = 0.6878s	
5773/30300 (epoch 9.526), train_loss = 1.49597921, grad/param norm = 1.5900e-01, time/batch = 0.6903s	
5774/30300 (epoch 9.528), train_loss = 1.32423068, grad/param norm = 1.4493e-01, time/batch = 0.6981s	
5775/30300 (epoch 9.530), train_loss = 1.37724791, grad/param norm = 1.5654e-01, time/batch = 0.7207s	
5776/30300 (epoch 9.531), train_loss = 1.57377767, grad/param norm = 1.6957e-01, time/batch = 0.6976s	
5777/30300 (epoch 9.533), train_loss = 1.57179849, grad/param norm = 1.5698e-01, time/batch = 0.6976s	
5778/30300 (epoch 9.535), train_loss = 1.31716300, grad/param norm = 1.3582e-01, time/batch = 0.6972s	
5779/30300 (epoch 9.536), train_loss = 1.53593481, grad/param norm = 1.5893e-01, time/batch = 0.6933s	
5780/30300 (epoch 9.538), train_loss = 1.31370009, grad/param norm = 1.6754e-01, time/batch = 0.6910s	
5781/30300 (epoch 9.540), train_loss = 1.39608158, grad/param norm = 1.5443e-01, time/batch = 0.6916s	
5782/30300 (epoch 9.541), train_loss = 1.47414365, grad/param norm = 1.6283e-01, time/batch = 0.7012s	
5783/30300 (epoch 9.543), train_loss = 1.51213073, grad/param norm = 1.5186e-01, time/batch = 0.6922s	
5784/30300 (epoch 9.545), train_loss = 1.54638291, grad/param norm = 1.6747e-01, time/batch = 0.6904s	
5785/30300 (epoch 9.546), train_loss = 1.72180243, grad/param norm = 1.6536e-01, time/batch = 0.6967s	
5786/30300 (epoch 9.548), train_loss = 1.44333037, grad/param norm = 1.5880e-01, time/batch = 0.6905s	
5787/30300 (epoch 9.550), train_loss = 1.65962780, grad/param norm = 1.6980e-01, time/batch = 0.6890s	
5788/30300 (epoch 9.551), train_loss = 1.43396690, grad/param norm = 1.5639e-01, time/batch = 0.6909s	
5789/30300 (epoch 9.553), train_loss = 1.40389654, grad/param norm = 1.5283e-01, time/batch = 0.6903s	
5790/30300 (epoch 9.554), train_loss = 1.60808103, grad/param norm = 1.6352e-01, time/batch = 0.6895s	
5791/30300 (epoch 9.556), train_loss = 1.54682241, grad/param norm = 1.5580e-01, time/batch = 0.6899s	
5792/30300 (epoch 9.558), train_loss = 1.64007779, grad/param norm = 1.6012e-01, time/batch = 0.6913s	
5793/30300 (epoch 9.559), train_loss = 1.50644606, grad/param norm = 1.5933e-01, time/batch = 0.6898s	
5794/30300 (epoch 9.561), train_loss = 1.36165514, grad/param norm = 1.5566e-01, time/batch = 0.6861s	
5795/30300 (epoch 9.563), train_loss = 1.41062981, grad/param norm = 1.5261e-01, time/batch = 0.6873s	
5796/30300 (epoch 9.564), train_loss = 1.45286665, grad/param norm = 1.5849e-01, time/batch = 0.6889s	
5797/30300 (epoch 9.566), train_loss = 1.47710837, grad/param norm = 1.4609e-01, time/batch = 0.6904s	
5798/30300 (epoch 9.568), train_loss = 1.28774329, grad/param norm = 1.4690e-01, time/batch = 0.6874s	
5799/30300 (epoch 9.569), train_loss = 1.50074878, grad/param norm = 1.5184e-01, time/batch = 0.9664s	
5800/30300 (epoch 9.571), train_loss = 1.53102806, grad/param norm = 1.6690e-01, time/batch = 1.0049s	
5801/30300 (epoch 9.573), train_loss = 1.53914157, grad/param norm = 1.5527e-01, time/batch = 1.0050s	
5802/30300 (epoch 9.574), train_loss = 1.54837258, grad/param norm = 1.5600e-01, time/batch = 1.0174s	
5803/30300 (epoch 9.576), train_loss = 1.46445167, grad/param norm = 1.4754e-01, time/batch = 1.0150s	
5804/30300 (epoch 9.578), train_loss = 1.39114974, grad/param norm = 1.5551e-01, time/batch = 1.8446s	
5805/30300 (epoch 9.579), train_loss = 1.53473864, grad/param norm = 1.6809e-01, time/batch = 1.8986s	
5806/30300 (epoch 9.581), train_loss = 1.57281184, grad/param norm = 1.4804e-01, time/batch = 7.7129s	
5807/30300 (epoch 9.583), train_loss = 1.66526052, grad/param norm = 1.6805e-01, time/batch = 18.6965s	
5808/30300 (epoch 9.584), train_loss = 1.58605071, grad/param norm = 1.5525e-01, time/batch = 18.4409s	
5809/30300 (epoch 9.586), train_loss = 1.54721017, grad/param norm = 1.6116e-01, time/batch = 18.4703s	
5810/30300 (epoch 9.587), train_loss = 1.53218367, grad/param norm = 1.5943e-01, time/batch = 19.2017s	
5811/30300 (epoch 9.589), train_loss = 1.32981966, grad/param norm = 1.3982e-01, time/batch = 13.1052s	
5812/30300 (epoch 9.591), train_loss = 1.52681582, grad/param norm = 1.5529e-01, time/batch = 0.6918s	
5813/30300 (epoch 9.592), train_loss = 1.49633154, grad/param norm = 1.4512e-01, time/batch = 0.6949s	
5814/30300 (epoch 9.594), train_loss = 1.52467663, grad/param norm = 1.6401e-01, time/batch = 0.6999s	
5815/30300 (epoch 9.596), train_loss = 1.36308315, grad/param norm = 1.3742e-01, time/batch = 0.6897s	
5816/30300 (epoch 9.597), train_loss = 1.45777149, grad/param norm = 1.6722e-01, time/batch = 0.6951s	
5817/30300 (epoch 9.599), train_loss = 1.27265976, grad/param norm = 1.5410e-01, time/batch = 0.6912s	
5818/30300 (epoch 9.601), train_loss = 1.54477161, grad/param norm = 1.6345e-01, time/batch = 0.7359s	
5819/30300 (epoch 9.602), train_loss = 1.49177638, grad/param norm = 1.4603e-01, time/batch = 1.0467s	
5820/30300 (epoch 9.604), train_loss = 1.40288743, grad/param norm = 1.7982e-01, time/batch = 1.0290s	
5821/30300 (epoch 9.606), train_loss = 1.58254363, grad/param norm = 1.6911e-01, time/batch = 1.0275s	
5822/30300 (epoch 9.607), train_loss = 1.55170124, grad/param norm = 1.5970e-01, time/batch = 1.0059s	
5823/30300 (epoch 9.609), train_loss = 1.72629040, grad/param norm = 1.7102e-01, time/batch = 1.2944s	
5824/30300 (epoch 9.611), train_loss = 1.40486319, grad/param norm = 1.4975e-01, time/batch = 1.9010s	
5825/30300 (epoch 9.612), train_loss = 1.42609237, grad/param norm = 1.5207e-01, time/batch = 1.8795s	
5826/30300 (epoch 9.614), train_loss = 1.37044920, grad/param norm = 1.4956e-01, time/batch = 12.9165s	
5827/30300 (epoch 9.616), train_loss = 1.56839651, grad/param norm = 1.5606e-01, time/batch = 17.9561s	
5828/30300 (epoch 9.617), train_loss = 1.43614562, grad/param norm = 1.4701e-01, time/batch = 17.1377s	
5829/30300 (epoch 9.619), train_loss = 1.30116860, grad/param norm = 1.4374e-01, time/batch = 19.5226s	
5830/30300 (epoch 9.620), train_loss = 1.54577423, grad/param norm = 1.6001e-01, time/batch = 19.4658s	
5831/30300 (epoch 9.622), train_loss = 1.50504677, grad/param norm = 1.6873e-01, time/batch = 18.5409s	
5832/30300 (epoch 9.624), train_loss = 1.41168742, grad/param norm = 1.6035e-01, time/batch = 20.1932s	
5833/30300 (epoch 9.625), train_loss = 1.43420948, grad/param norm = 1.5881e-01, time/batch = 18.9528s	
5834/30300 (epoch 9.627), train_loss = 1.66307817, grad/param norm = 1.7835e-01, time/batch = 18.4587s	
5835/30300 (epoch 9.629), train_loss = 1.56722723, grad/param norm = 1.5476e-01, time/batch = 19.0412s	
5836/30300 (epoch 9.630), train_loss = 1.50655079, grad/param norm = 1.5194e-01, time/batch = 19.5418s	
5837/30300 (epoch 9.632), train_loss = 1.61867006, grad/param norm = 1.6752e-01, time/batch = 18.6334s	
5838/30300 (epoch 9.634), train_loss = 1.33602895, grad/param norm = 1.3889e-01, time/batch = 19.1295s	
5839/30300 (epoch 9.635), train_loss = 1.56411711, grad/param norm = 1.5209e-01, time/batch = 19.6292s	
5840/30300 (epoch 9.637), train_loss = 1.54650214, grad/param norm = 1.6507e-01, time/batch = 18.5459s	
5841/30300 (epoch 9.639), train_loss = 1.39999416, grad/param norm = 1.6051e-01, time/batch = 18.8645s	
5842/30300 (epoch 9.640), train_loss = 1.60089736, grad/param norm = 1.6153e-01, time/batch = 18.8716s	
5843/30300 (epoch 9.642), train_loss = 1.43405449, grad/param norm = 1.4631e-01, time/batch = 17.4626s	
5844/30300 (epoch 9.644), train_loss = 1.57843407, grad/param norm = 1.5866e-01, time/batch = 18.4099s	
5845/30300 (epoch 9.645), train_loss = 1.37786001, grad/param norm = 1.4595e-01, time/batch = 17.5183s	
5846/30300 (epoch 9.647), train_loss = 1.46591548, grad/param norm = 1.4490e-01, time/batch = 18.7850s	
5847/30300 (epoch 9.649), train_loss = 1.43986321, grad/param norm = 1.5446e-01, time/batch = 18.1201s	
5848/30300 (epoch 9.650), train_loss = 1.48800907, grad/param norm = 1.5613e-01, time/batch = 17.4409s	
5849/30300 (epoch 9.652), train_loss = 1.41093037, grad/param norm = 1.4591e-01, time/batch = 19.4541s	
5850/30300 (epoch 9.653), train_loss = 1.64558202, grad/param norm = 1.5109e-01, time/batch = 17.9484s	
5851/30300 (epoch 9.655), train_loss = 1.42713162, grad/param norm = 1.5486e-01, time/batch = 29.7383s	
5852/30300 (epoch 9.657), train_loss = 1.50682363, grad/param norm = 1.5888e-01, time/batch = 34.9574s	
5853/30300 (epoch 9.658), train_loss = 1.45415484, grad/param norm = 1.5638e-01, time/batch = 40.4180s	
5854/30300 (epoch 9.660), train_loss = 1.56675292, grad/param norm = 1.5805e-01, time/batch = 37.5572s	
5855/30300 (epoch 9.662), train_loss = 1.58589626, grad/param norm = 1.7153e-01, time/batch = 40.1778s	
5856/30300 (epoch 9.663), train_loss = 1.49734915, grad/param norm = 1.5383e-01, time/batch = 40.5577s	
5857/30300 (epoch 9.665), train_loss = 1.37895518, grad/param norm = 1.5597e-01, time/batch = 39.0267s	
5858/30300 (epoch 9.667), train_loss = 1.60598704, grad/param norm = 1.6081e-01, time/batch = 39.2631s	
5859/30300 (epoch 9.668), train_loss = 1.68606969, grad/param norm = 1.7552e-01, time/batch = 38.3805s	
5860/30300 (epoch 9.670), train_loss = 1.63303625, grad/param norm = 1.5996e-01, time/batch = 18.8551s	
5861/30300 (epoch 9.672), train_loss = 1.58639843, grad/param norm = 1.5865e-01, time/batch = 19.7809s	
5862/30300 (epoch 9.673), train_loss = 1.59794783, grad/param norm = 1.5987e-01, time/batch = 17.3867s	
5863/30300 (epoch 9.675), train_loss = 1.41757365, grad/param norm = 1.5363e-01, time/batch = 18.4291s	
5864/30300 (epoch 9.677), train_loss = 1.38761484, grad/param norm = 1.3801e-01, time/batch = 18.4516s	
5865/30300 (epoch 9.678), train_loss = 1.43048191, grad/param norm = 1.4213e-01, time/batch = 19.4575s	
5866/30300 (epoch 9.680), train_loss = 1.23784228, grad/param norm = 1.4127e-01, time/batch = 19.8732s	
5867/30300 (epoch 9.682), train_loss = 1.47772931, grad/param norm = 1.5443e-01, time/batch = 18.4530s	
5868/30300 (epoch 9.683), train_loss = 1.52868304, grad/param norm = 1.5041e-01, time/batch = 20.0513s	
5869/30300 (epoch 9.685), train_loss = 1.66268378, grad/param norm = 1.7957e-01, time/batch = 20.1284s	
5870/30300 (epoch 9.686), train_loss = 1.50053560, grad/param norm = 1.5494e-01, time/batch = 18.1950s	
5871/30300 (epoch 9.688), train_loss = 1.50476476, grad/param norm = 1.5367e-01, time/batch = 18.4359s	
5872/30300 (epoch 9.690), train_loss = 1.45520367, grad/param norm = 1.6437e-01, time/batch = 19.4498s	
5873/30300 (epoch 9.691), train_loss = 1.48703179, grad/param norm = 1.4574e-01, time/batch = 18.6239s	
5874/30300 (epoch 9.693), train_loss = 1.90902519, grad/param norm = 1.7675e-01, time/batch = 18.4524s	
5875/30300 (epoch 9.695), train_loss = 1.68585877, grad/param norm = 1.8324e-01, time/batch = 17.8404s	
5876/30300 (epoch 9.696), train_loss = 1.68595667, grad/param norm = 1.8187e-01, time/batch = 18.2899s	
5877/30300 (epoch 9.698), train_loss = 1.45377540, grad/param norm = 1.5478e-01, time/batch = 19.5596s	
5878/30300 (epoch 9.700), train_loss = 1.46150242, grad/param norm = 1.5851e-01, time/batch = 19.4570s	
5879/30300 (epoch 9.701), train_loss = 1.30222475, grad/param norm = 1.3702e-01, time/batch = 20.1560s	
5880/30300 (epoch 9.703), train_loss = 1.50050076, grad/param norm = 1.4812e-01, time/batch = 30.3140s	
5881/30300 (epoch 9.705), train_loss = 1.49541025, grad/param norm = 1.6248e-01, time/batch = 21.4398s	
5882/30300 (epoch 9.706), train_loss = 1.52202078, grad/param norm = 1.5346e-01, time/batch = 19.4441s	
5883/30300 (epoch 9.708), train_loss = 1.44765109, grad/param norm = 1.5155e-01, time/batch = 17.9533s	
5884/30300 (epoch 9.710), train_loss = 1.45502744, grad/param norm = 1.5260e-01, time/batch = 19.1142s	
5885/30300 (epoch 9.711), train_loss = 1.37141542, grad/param norm = 1.5134e-01, time/batch = 17.9132s	
5886/30300 (epoch 9.713), train_loss = 1.34961076, grad/param norm = 1.3950e-01, time/batch = 19.7660s	
5887/30300 (epoch 9.715), train_loss = 1.46388299, grad/param norm = 1.5638e-01, time/batch = 19.6199s	
5888/30300 (epoch 9.716), train_loss = 1.65195020, grad/param norm = 1.5468e-01, time/batch = 17.6174s	
5889/30300 (epoch 9.718), train_loss = 1.58153406, grad/param norm = 1.6266e-01, time/batch = 19.7091s	
5890/30300 (epoch 9.719), train_loss = 1.48259104, grad/param norm = 1.5888e-01, time/batch = 18.4638s	
5891/30300 (epoch 9.721), train_loss = 1.46603249, grad/param norm = 1.5967e-01, time/batch = 18.5340s	
5892/30300 (epoch 9.723), train_loss = 1.46490213, grad/param norm = 1.5922e-01, time/batch = 17.9599s	
5893/30300 (epoch 9.724), train_loss = 1.59258936, grad/param norm = 1.6158e-01, time/batch = 19.6257s	
5894/30300 (epoch 9.726), train_loss = 1.92736687, grad/param norm = 1.8518e-01, time/batch = 17.6870s	
5895/30300 (epoch 9.728), train_loss = 1.51776763, grad/param norm = 1.5144e-01, time/batch = 19.3693s	
5896/30300 (epoch 9.729), train_loss = 1.51031681, grad/param norm = 1.5623e-01, time/batch = 19.3757s	
5897/30300 (epoch 9.731), train_loss = 1.58467449, grad/param norm = 1.5421e-01, time/batch = 18.7033s	
5898/30300 (epoch 9.733), train_loss = 1.49001501, grad/param norm = 1.5477e-01, time/batch = 18.7028s	
5899/30300 (epoch 9.734), train_loss = 1.55056194, grad/param norm = 1.4988e-01, time/batch = 18.8770s	
5900/30300 (epoch 9.736), train_loss = 1.45705770, grad/param norm = 1.4626e-01, time/batch = 19.5319s	
5901/30300 (epoch 9.738), train_loss = 1.33194132, grad/param norm = 1.4178e-01, time/batch = 19.6128s	
5902/30300 (epoch 9.739), train_loss = 1.57194924, grad/param norm = 1.5295e-01, time/batch = 19.0492s	
5903/30300 (epoch 9.741), train_loss = 1.60853164, grad/param norm = 1.5273e-01, time/batch = 17.7871s	
5904/30300 (epoch 9.743), train_loss = 1.41579578, grad/param norm = 1.5425e-01, time/batch = 17.6135s	
5905/30300 (epoch 9.744), train_loss = 1.58014091, grad/param norm = 1.6877e-01, time/batch = 18.0976s	
5906/30300 (epoch 9.746), train_loss = 1.33458503, grad/param norm = 1.4708e-01, time/batch = 20.1256s	
5907/30300 (epoch 9.748), train_loss = 1.49792720, grad/param norm = 1.7285e-01, time/batch = 18.2217s	
5908/30300 (epoch 9.749), train_loss = 1.52287653, grad/param norm = 1.5676e-01, time/batch = 19.1279s	
5909/30300 (epoch 9.751), train_loss = 1.39758308, grad/param norm = 1.5471e-01, time/batch = 19.1958s	
5910/30300 (epoch 9.752), train_loss = 1.43969018, grad/param norm = 1.5053e-01, time/batch = 16.9522s	
5911/30300 (epoch 9.754), train_loss = 1.35141887, grad/param norm = 1.3691e-01, time/batch = 18.8535s	
5912/30300 (epoch 9.756), train_loss = 1.42573495, grad/param norm = 1.5568e-01, time/batch = 18.7701s	
5913/30300 (epoch 9.757), train_loss = 1.52834062, grad/param norm = 1.5948e-01, time/batch = 18.5393s	
5914/30300 (epoch 9.759), train_loss = 1.41673055, grad/param norm = 1.4175e-01, time/batch = 17.6950s	
5915/30300 (epoch 9.761), train_loss = 1.34948140, grad/param norm = 1.4584e-01, time/batch = 19.1982s	
5916/30300 (epoch 9.762), train_loss = 1.27316919, grad/param norm = 1.4205e-01, time/batch = 18.3017s	
5917/30300 (epoch 9.764), train_loss = 1.44486275, grad/param norm = 1.4394e-01, time/batch = 18.5178s	
5918/30300 (epoch 9.766), train_loss = 1.52171020, grad/param norm = 1.5206e-01, time/batch = 19.7823s	
5919/30300 (epoch 9.767), train_loss = 1.62453638, grad/param norm = 1.8392e-01, time/batch = 19.1392s	
5920/30300 (epoch 9.769), train_loss = 1.58649679, grad/param norm = 1.6380e-01, time/batch = 18.0362s	
5921/30300 (epoch 9.771), train_loss = 1.48438852, grad/param norm = 1.5031e-01, time/batch = 18.8777s	
5922/30300 (epoch 9.772), train_loss = 1.50539589, grad/param norm = 1.5702e-01, time/batch = 17.1936s	
5923/30300 (epoch 9.774), train_loss = 1.61996428, grad/param norm = 1.5113e-01, time/batch = 17.1121s	
5924/30300 (epoch 9.776), train_loss = 1.51530766, grad/param norm = 1.6535e-01, time/batch = 19.4475s	
5925/30300 (epoch 9.777), train_loss = 1.50991359, grad/param norm = 1.4595e-01, time/batch = 18.9356s	
5926/30300 (epoch 9.779), train_loss = 1.64460442, grad/param norm = 1.6442e-01, time/batch = 17.1906s	
5927/30300 (epoch 9.781), train_loss = 1.52221375, grad/param norm = 1.6830e-01, time/batch = 17.8741s	
5928/30300 (epoch 9.782), train_loss = 1.42966823, grad/param norm = 1.5563e-01, time/batch = 17.9582s	
5929/30300 (epoch 9.784), train_loss = 1.45106733, grad/param norm = 1.5427e-01, time/batch = 18.2990s	
5930/30300 (epoch 9.785), train_loss = 1.66899599, grad/param norm = 1.7294e-01, time/batch = 18.0931s	
5931/30300 (epoch 9.787), train_loss = 1.35418107, grad/param norm = 1.6335e-01, time/batch = 19.9577s	
5932/30300 (epoch 9.789), train_loss = 1.79907512, grad/param norm = 1.5897e-01, time/batch = 19.4394s	
5933/30300 (epoch 9.790), train_loss = 1.59563656, grad/param norm = 1.6258e-01, time/batch = 17.7007s	
5934/30300 (epoch 9.792), train_loss = 1.37835662, grad/param norm = 1.6391e-01, time/batch = 19.9482s	
5935/30300 (epoch 9.794), train_loss = 1.41801862, grad/param norm = 1.5041e-01, time/batch = 19.4605s	
5936/30300 (epoch 9.795), train_loss = 1.47756555, grad/param norm = 1.4898e-01, time/batch = 18.6142s	
5937/30300 (epoch 9.797), train_loss = 1.67958828, grad/param norm = 1.7334e-01, time/batch = 18.5406s	
5938/30300 (epoch 9.799), train_loss = 1.56522153, grad/param norm = 1.6979e-01, time/batch = 19.7810s	
5939/30300 (epoch 9.800), train_loss = 1.53578930, grad/param norm = 1.6088e-01, time/batch = 18.0381s	
5940/30300 (epoch 9.802), train_loss = 1.73702885, grad/param norm = 1.7823e-01, time/batch = 19.5339s	
5941/30300 (epoch 9.804), train_loss = 1.59025052, grad/param norm = 1.6120e-01, time/batch = 19.1876s	
5942/30300 (epoch 9.805), train_loss = 1.67024596, grad/param norm = 1.7641e-01, time/batch = 17.2710s	
5943/30300 (epoch 9.807), train_loss = 1.55575448, grad/param norm = 1.9078e-01, time/batch = 17.3851s	
5944/30300 (epoch 9.809), train_loss = 1.61220342, grad/param norm = 1.7038e-01, time/batch = 19.3737s	
5945/30300 (epoch 9.810), train_loss = 1.58272929, grad/param norm = 1.5855e-01, time/batch = 15.7008s	
5946/30300 (epoch 9.812), train_loss = 1.39713939, grad/param norm = 1.5996e-01, time/batch = 17.4431s	
5947/30300 (epoch 9.814), train_loss = 1.52071408, grad/param norm = 1.4719e-01, time/batch = 17.1983s	
5948/30300 (epoch 9.815), train_loss = 1.54823152, grad/param norm = 1.6333e-01, time/batch = 19.4599s	
5949/30300 (epoch 9.817), train_loss = 1.62864582, grad/param norm = 1.6947e-01, time/batch = 18.2876s	
5950/30300 (epoch 9.818), train_loss = 1.53586671, grad/param norm = 1.5092e-01, time/batch = 19.6155s	
5951/30300 (epoch 9.820), train_loss = 1.75523618, grad/param norm = 1.7245e-01, time/batch = 19.2164s	
5952/30300 (epoch 9.822), train_loss = 1.74604466, grad/param norm = 1.8846e-01, time/batch = 18.4598s	
5953/30300 (epoch 9.823), train_loss = 1.78570414, grad/param norm = 1.9143e-01, time/batch = 19.0517s	
5954/30300 (epoch 9.825), train_loss = 1.61640653, grad/param norm = 1.6684e-01, time/batch = 17.8973s	
5955/30300 (epoch 9.827), train_loss = 1.41750677, grad/param norm = 1.6886e-01, time/batch = 17.7006s	
5956/30300 (epoch 9.828), train_loss = 1.57776070, grad/param norm = 1.6026e-01, time/batch = 19.5288s	
5957/30300 (epoch 9.830), train_loss = 1.54737819, grad/param norm = 1.6056e-01, time/batch = 19.8706s	
5958/30300 (epoch 9.832), train_loss = 1.45739828, grad/param norm = 1.5176e-01, time/batch = 18.2249s	
5959/30300 (epoch 9.833), train_loss = 1.58884002, grad/param norm = 1.6071e-01, time/batch = 18.0356s	
5960/30300 (epoch 9.835), train_loss = 1.49267532, grad/param norm = 1.5365e-01, time/batch = 19.6169s	
5961/30300 (epoch 9.837), train_loss = 1.31616206, grad/param norm = 1.3520e-01, time/batch = 18.0162s	
5962/30300 (epoch 9.838), train_loss = 1.38127796, grad/param norm = 1.5004e-01, time/batch = 18.7827s	
5963/30300 (epoch 9.840), train_loss = 1.53278752, grad/param norm = 1.4644e-01, time/batch = 19.6090s	
5964/30300 (epoch 9.842), train_loss = 1.33233879, grad/param norm = 1.3724e-01, time/batch = 19.1305s	
5965/30300 (epoch 9.843), train_loss = 1.50299840, grad/param norm = 1.4689e-01, time/batch = 17.3689s	
5966/30300 (epoch 9.845), train_loss = 1.44102775, grad/param norm = 1.3270e-01, time/batch = 19.4736s	
5967/30300 (epoch 9.847), train_loss = 1.55435331, grad/param norm = 1.7322e-01, time/batch = 19.6272s	
5968/30300 (epoch 9.848), train_loss = 1.64015156, grad/param norm = 1.6625e-01, time/batch = 18.0524s	
5969/30300 (epoch 9.850), train_loss = 1.43062434, grad/param norm = 1.4192e-01, time/batch = 17.5466s	
5970/30300 (epoch 9.851), train_loss = 1.68296775, grad/param norm = 1.7527e-01, time/batch = 18.7005s	
5971/30300 (epoch 9.853), train_loss = 1.42476966, grad/param norm = 1.4948e-01, time/batch = 19.2796s	
5972/30300 (epoch 9.855), train_loss = 1.44804358, grad/param norm = 1.4913e-01, time/batch = 18.7876s	
5973/30300 (epoch 9.856), train_loss = 1.42681533, grad/param norm = 1.5438e-01, time/batch = 19.2878s	
5974/30300 (epoch 9.858), train_loss = 1.41055512, grad/param norm = 1.3976e-01, time/batch = 17.2055s	
5975/30300 (epoch 9.860), train_loss = 1.46858578, grad/param norm = 1.5114e-01, time/batch = 17.7686s	
5976/30300 (epoch 9.861), train_loss = 1.67667052, grad/param norm = 1.5474e-01, time/batch = 19.0384s	
5977/30300 (epoch 9.863), train_loss = 1.50570584, grad/param norm = 1.4670e-01, time/batch = 19.7066s	
5978/30300 (epoch 9.865), train_loss = 1.69789434, grad/param norm = 1.5876e-01, time/batch = 17.1210s	
5979/30300 (epoch 9.866), train_loss = 1.55535555, grad/param norm = 1.5703e-01, time/batch = 17.7956s	
5980/30300 (epoch 9.868), train_loss = 1.50365456, grad/param norm = 1.4516e-01, time/batch = 16.8887s	
5981/30300 (epoch 9.870), train_loss = 1.47341907, grad/param norm = 1.4595e-01, time/batch = 16.8615s	
5982/30300 (epoch 9.871), train_loss = 1.43283547, grad/param norm = 1.4305e-01, time/batch = 18.3670s	
5983/30300 (epoch 9.873), train_loss = 1.52651444, grad/param norm = 1.5016e-01, time/batch = 18.2265s	
5984/30300 (epoch 9.875), train_loss = 1.33695044, grad/param norm = 1.3969e-01, time/batch = 18.4500s	
5985/30300 (epoch 9.876), train_loss = 1.37380728, grad/param norm = 1.4191e-01, time/batch = 18.2064s	
5986/30300 (epoch 9.878), train_loss = 1.25404927, grad/param norm = 1.5730e-01, time/batch = 18.1212s	
5987/30300 (epoch 9.880), train_loss = 1.37524023, grad/param norm = 1.4750e-01, time/batch = 18.1929s	
5988/30300 (epoch 9.881), train_loss = 1.75124351, grad/param norm = 1.6927e-01, time/batch = 18.7765s	
5989/30300 (epoch 9.883), train_loss = 1.56636071, grad/param norm = 1.5883e-01, time/batch = 19.9275s	
5990/30300 (epoch 9.884), train_loss = 1.32870717, grad/param norm = 1.3726e-01, time/batch = 17.7021s	
5991/30300 (epoch 9.886), train_loss = 1.51325207, grad/param norm = 1.6048e-01, time/batch = 17.0291s	
5992/30300 (epoch 9.888), train_loss = 1.54650126, grad/param norm = 1.6200e-01, time/batch = 18.0412s	
5993/30300 (epoch 9.889), train_loss = 1.45265341, grad/param norm = 1.4734e-01, time/batch = 17.2858s	
5994/30300 (epoch 9.891), train_loss = 1.44617801, grad/param norm = 1.4669e-01, time/batch = 17.7050s	
5995/30300 (epoch 9.893), train_loss = 1.75690624, grad/param norm = 1.6557e-01, time/batch = 17.9509s	
5996/30300 (epoch 9.894), train_loss = 1.60414086, grad/param norm = 1.5467e-01, time/batch = 16.5005s	
5997/30300 (epoch 9.896), train_loss = 1.30129565, grad/param norm = 1.4648e-01, time/batch = 15.9207s	
5998/30300 (epoch 9.898), train_loss = 1.26698875, grad/param norm = 1.4982e-01, time/batch = 16.5082s	
5999/30300 (epoch 9.899), train_loss = 1.43250856, grad/param norm = 1.4571e-01, time/batch = 16.5060s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch9.90_1.7350.t7	
6000/30300 (epoch 9.901), train_loss = 1.49257317, grad/param norm = 1.8273e-01, time/batch = 17.1075s	
6001/30300 (epoch 9.903), train_loss = 1.68821236, grad/param norm = 1.6365e-01, time/batch = 17.5005s	
6002/30300 (epoch 9.904), train_loss = 1.42482016, grad/param norm = 1.4535e-01, time/batch = 18.2414s	
6003/30300 (epoch 9.906), train_loss = 1.65401545, grad/param norm = 1.5709e-01, time/batch = 18.1917s	
6004/30300 (epoch 9.908), train_loss = 1.36198955, grad/param norm = 1.4214e-01, time/batch = 15.9694s	
6005/30300 (epoch 9.909), train_loss = 1.46151810, grad/param norm = 1.6961e-01, time/batch = 17.8158s	
6006/30300 (epoch 9.911), train_loss = 1.48241776, grad/param norm = 1.5874e-01, time/batch = 15.7820s	
6007/30300 (epoch 9.913), train_loss = 1.48989221, grad/param norm = 1.5349e-01, time/batch = 16.2783s	
6008/30300 (epoch 9.914), train_loss = 1.48780047, grad/param norm = 1.6635e-01, time/batch = 18.3647s	
6009/30300 (epoch 9.916), train_loss = 1.51003712, grad/param norm = 1.4929e-01, time/batch = 18.4857s	
6010/30300 (epoch 9.917), train_loss = 1.40294175, grad/param norm = 1.5100e-01, time/batch = 20.1292s	
6011/30300 (epoch 9.919), train_loss = 1.47291931, grad/param norm = 1.4972e-01, time/batch = 18.4536s	
6012/30300 (epoch 9.921), train_loss = 1.52454237, grad/param norm = 1.5883e-01, time/batch = 19.7031s	
6013/30300 (epoch 9.922), train_loss = 1.59031174, grad/param norm = 1.6991e-01, time/batch = 18.2897s	
6014/30300 (epoch 9.924), train_loss = 1.48666259, grad/param norm = 1.5512e-01, time/batch = 18.7008s	
6015/30300 (epoch 9.926), train_loss = 1.46677344, grad/param norm = 1.6192e-01, time/batch = 19.7700s	
6016/30300 (epoch 9.927), train_loss = 1.50118101, grad/param norm = 1.6367e-01, time/batch = 18.9454s	
6017/30300 (epoch 9.929), train_loss = 1.46234604, grad/param norm = 1.6783e-01, time/batch = 17.1980s	
6018/30300 (epoch 9.931), train_loss = 1.64498558, grad/param norm = 1.7871e-01, time/batch = 18.4390s	
6019/30300 (epoch 9.932), train_loss = 1.42765421, grad/param norm = 1.7077e-01, time/batch = 19.3630s	
6020/30300 (epoch 9.934), train_loss = 1.50056417, grad/param norm = 1.4650e-01, time/batch = 18.6206s	
6021/30300 (epoch 9.936), train_loss = 1.45250462, grad/param norm = 1.4717e-01, time/batch = 19.8603s	
6022/30300 (epoch 9.937), train_loss = 1.45582533, grad/param norm = 1.5450e-01, time/batch = 18.3849s	
6023/30300 (epoch 9.939), train_loss = 1.62031471, grad/param norm = 1.7008e-01, time/batch = 17.6764s	
6024/30300 (epoch 9.941), train_loss = 1.49844678, grad/param norm = 1.6441e-01, time/batch = 19.1813s	
6025/30300 (epoch 9.942), train_loss = 1.49192815, grad/param norm = 1.6938e-01, time/batch = 18.8026s	
6026/30300 (epoch 9.944), train_loss = 1.36785222, grad/param norm = 1.4223e-01, time/batch = 19.9280s	
6027/30300 (epoch 9.946), train_loss = 1.67090815, grad/param norm = 1.8115e-01, time/batch = 18.1262s	
6028/30300 (epoch 9.947), train_loss = 1.68848100, grad/param norm = 1.8739e-01, time/batch = 19.9727s	
6029/30300 (epoch 9.949), train_loss = 1.72531395, grad/param norm = 1.6951e-01, time/batch = 20.0506s	
6030/30300 (epoch 9.950), train_loss = 1.62973584, grad/param norm = 1.6110e-01, time/batch = 18.7844s	
6031/30300 (epoch 9.952), train_loss = 1.61427353, grad/param norm = 1.6604e-01, time/batch = 18.1231s	
6032/30300 (epoch 9.954), train_loss = 1.77933593, grad/param norm = 1.6490e-01, time/batch = 20.1964s	
6033/30300 (epoch 9.955), train_loss = 1.43481648, grad/param norm = 1.5354e-01, time/batch = 17.0267s	
6034/30300 (epoch 9.957), train_loss = 1.57372465, grad/param norm = 1.5446e-01, time/batch = 18.6270s	
6035/30300 (epoch 9.959), train_loss = 1.53801635, grad/param norm = 1.5665e-01, time/batch = 18.6273s	
6036/30300 (epoch 9.960), train_loss = 1.46969783, grad/param norm = 1.5586e-01, time/batch = 18.6424s	
6037/30300 (epoch 9.962), train_loss = 1.44297445, grad/param norm = 1.6230e-01, time/batch = 18.7113s	
6038/30300 (epoch 9.964), train_loss = 1.51444668, grad/param norm = 1.6756e-01, time/batch = 19.2832s	
6039/30300 (epoch 9.965), train_loss = 1.42749210, grad/param norm = 1.5371e-01, time/batch = 17.8832s	
6040/30300 (epoch 9.967), train_loss = 1.48280757, grad/param norm = 1.5801e-01, time/batch = 19.2769s	
6041/30300 (epoch 9.969), train_loss = 1.48121798, grad/param norm = 1.6669e-01, time/batch = 19.2956s	
6042/30300 (epoch 9.970), train_loss = 1.42561928, grad/param norm = 1.4891e-01, time/batch = 17.5528s	
6043/30300 (epoch 9.972), train_loss = 1.37652995, grad/param norm = 1.5276e-01, time/batch = 18.7922s	
6044/30300 (epoch 9.974), train_loss = 1.68632888, grad/param norm = 1.6574e-01, time/batch = 19.3076s	
6045/30300 (epoch 9.975), train_loss = 1.69024310, grad/param norm = 1.8065e-01, time/batch = 20.0238s	
6046/30300 (epoch 9.977), train_loss = 1.57600759, grad/param norm = 1.6664e-01, time/batch = 18.2887s	
6047/30300 (epoch 9.979), train_loss = 1.55572522, grad/param norm = 1.5725e-01, time/batch = 20.0373s	
6048/30300 (epoch 9.980), train_loss = 1.58383996, grad/param norm = 1.6888e-01, time/batch = 19.5591s	
6049/30300 (epoch 9.982), train_loss = 1.60776515, grad/param norm = 1.6326e-01, time/batch = 17.3552s	
6050/30300 (epoch 9.983), train_loss = 1.63564616, grad/param norm = 1.5680e-01, time/batch = 19.2747s	
6051/30300 (epoch 9.985), train_loss = 1.52218199, grad/param norm = 1.6262e-01, time/batch = 18.9559s	
6052/30300 (epoch 9.987), train_loss = 1.46256100, grad/param norm = 1.3641e-01, time/batch = 17.5953s	
6053/30300 (epoch 9.988), train_loss = 1.66505543, grad/param norm = 1.6586e-01, time/batch = 19.4490s	
6054/30300 (epoch 9.990), train_loss = 1.31924998, grad/param norm = 1.3881e-01, time/batch = 19.9488s	
6055/30300 (epoch 9.992), train_loss = 1.54648339, grad/param norm = 1.4098e-01, time/batch = 17.7198s	
6056/30300 (epoch 9.993), train_loss = 1.65678612, grad/param norm = 1.7339e-01, time/batch = 18.1228s	
6057/30300 (epoch 9.995), train_loss = 1.54625915, grad/param norm = 1.5896e-01, time/batch = 16.3808s	
6058/30300 (epoch 9.997), train_loss = 1.54458323, grad/param norm = 1.5372e-01, time/batch = 17.8503s	
6059/30300 (epoch 9.998), train_loss = 1.62473623, grad/param norm = 1.7141e-01, time/batch = 18.8521s	
decayed learning rate by a factor 0.97 to 0.00194	
6060/30300 (epoch 10.000), train_loss = 1.41961261, grad/param norm = 1.6070e-01, time/batch = 19.6174s	
6061/30300 (epoch 10.002), train_loss = 1.55234405, grad/param norm = 1.5976e-01, time/batch = 19.5982s	
6062/30300 (epoch 10.003), train_loss = 1.52368166, grad/param norm = 1.6038e-01, time/batch = 17.6999s	
6063/30300 (epoch 10.005), train_loss = 1.48966349, grad/param norm = 1.6749e-01, time/batch = 19.6347s	
6064/30300 (epoch 10.007), train_loss = 1.63601157, grad/param norm = 1.7494e-01, time/batch = 20.1253s	
6065/30300 (epoch 10.008), train_loss = 1.43450608, grad/param norm = 1.4991e-01, time/batch = 31.5248s	
6066/30300 (epoch 10.010), train_loss = 1.41244418, grad/param norm = 1.5739e-01, time/batch = 19.9540s	
6067/30300 (epoch 10.012), train_loss = 1.40848346, grad/param norm = 1.4664e-01, time/batch = 18.2851s	
6068/30300 (epoch 10.013), train_loss = 1.53244945, grad/param norm = 1.6985e-01, time/batch = 19.9500s	
6069/30300 (epoch 10.015), train_loss = 1.47320252, grad/param norm = 1.5018e-01, time/batch = 17.8010s	
6070/30300 (epoch 10.017), train_loss = 1.38833217, grad/param norm = 1.5106e-01, time/batch = 18.6100s	
6071/30300 (epoch 10.018), train_loss = 1.46423939, grad/param norm = 1.5165e-01, time/batch = 18.5352s	
6072/30300 (epoch 10.020), train_loss = 1.64131762, grad/param norm = 1.6709e-01, time/batch = 19.8654s	
6073/30300 (epoch 10.021), train_loss = 1.61475915, grad/param norm = 1.6224e-01, time/batch = 19.7855s	
6074/30300 (epoch 10.023), train_loss = 1.41768157, grad/param norm = 1.5177e-01, time/batch = 18.1815s	
6075/30300 (epoch 10.025), train_loss = 1.42067160, grad/param norm = 1.6580e-01, time/batch = 19.4631s	
6076/30300 (epoch 10.026), train_loss = 1.55970794, grad/param norm = 1.6465e-01, time/batch = 19.7099s	
6077/30300 (epoch 10.028), train_loss = 1.57040397, grad/param norm = 1.5609e-01, time/batch = 19.1980s	
6078/30300 (epoch 10.030), train_loss = 1.39982921, grad/param norm = 1.5063e-01, time/batch = 20.2165s	
6079/30300 (epoch 10.031), train_loss = 1.48407074, grad/param norm = 1.6804e-01, time/batch = 16.9652s	
6080/30300 (epoch 10.033), train_loss = 1.50726633, grad/param norm = 1.6235e-01, time/batch = 18.2852s	
6081/30300 (epoch 10.035), train_loss = 1.59387142, grad/param norm = 1.6125e-01, time/batch = 19.3591s	
6082/30300 (epoch 10.036), train_loss = 1.53938491, grad/param norm = 1.5980e-01, time/batch = 19.6145s	
6083/30300 (epoch 10.038), train_loss = 1.49401501, grad/param norm = 1.5144e-01, time/batch = 17.9678s	
6084/30300 (epoch 10.040), train_loss = 1.19188360, grad/param norm = 1.4048e-01, time/batch = 19.4688s	
6085/30300 (epoch 10.041), train_loss = 1.25853374, grad/param norm = 1.3864e-01, time/batch = 17.6106s	
6086/30300 (epoch 10.043), train_loss = 1.55462319, grad/param norm = 1.5156e-01, time/batch = 18.3116s	
6087/30300 (epoch 10.045), train_loss = 1.45089668, grad/param norm = 1.6051e-01, time/batch = 19.6304s	
6088/30300 (epoch 10.046), train_loss = 1.57436225, grad/param norm = 1.6908e-01, time/batch = 19.6977s	
6089/30300 (epoch 10.048), train_loss = 1.54631185, grad/param norm = 1.7294e-01, time/batch = 18.9549s	
6090/30300 (epoch 10.050), train_loss = 1.54613725, grad/param norm = 1.5839e-01, time/batch = 17.6890s	
6091/30300 (epoch 10.051), train_loss = 1.52112071, grad/param norm = 1.6581e-01, time/batch = 20.0228s	
6092/30300 (epoch 10.053), train_loss = 1.35625784, grad/param norm = 1.5963e-01, time/batch = 19.2013s	
6093/30300 (epoch 10.054), train_loss = 1.44741110, grad/param norm = 1.7263e-01, time/batch = 18.1131s	
6094/30300 (epoch 10.056), train_loss = 1.38971209, grad/param norm = 1.5161e-01, time/batch = 20.1122s	
6095/30300 (epoch 10.058), train_loss = 1.47189087, grad/param norm = 1.5838e-01, time/batch = 19.6206s	
6096/30300 (epoch 10.059), train_loss = 1.44375664, grad/param norm = 1.5813e-01, time/batch = 18.1178s	
6097/30300 (epoch 10.061), train_loss = 1.65993652, grad/param norm = 1.7592e-01, time/batch = 18.6986s	
6098/30300 (epoch 10.063), train_loss = 1.45279996, grad/param norm = 1.5357e-01, time/batch = 19.2907s	
6099/30300 (epoch 10.064), train_loss = 1.57429088, grad/param norm = 1.6268e-01, time/batch = 18.1190s	
6100/30300 (epoch 10.066), train_loss = 1.47016924, grad/param norm = 1.4555e-01, time/batch = 18.7770s	
6101/30300 (epoch 10.068), train_loss = 1.33760565, grad/param norm = 1.4249e-01, time/batch = 19.8741s	
6102/30300 (epoch 10.069), train_loss = 1.61975904, grad/param norm = 1.5871e-01, time/batch = 17.4445s	
6103/30300 (epoch 10.071), train_loss = 1.54671057, grad/param norm = 1.5986e-01, time/batch = 18.9508s	
6104/30300 (epoch 10.073), train_loss = 1.53691855, grad/param norm = 1.6961e-01, time/batch = 19.8769s	
6105/30300 (epoch 10.074), train_loss = 1.53323018, grad/param norm = 1.4940e-01, time/batch = 18.2862s	
6106/30300 (epoch 10.076), train_loss = 1.44936574, grad/param norm = 1.4797e-01, time/batch = 19.4724s	
6107/30300 (epoch 10.078), train_loss = 1.38116110, grad/param norm = 1.5802e-01, time/batch = 18.4474s	
6108/30300 (epoch 10.079), train_loss = 1.37199128, grad/param norm = 1.3385e-01, time/batch = 18.2867s	
6109/30300 (epoch 10.081), train_loss = 1.52570913, grad/param norm = 1.5495e-01, time/batch = 18.8771s	
6110/30300 (epoch 10.083), train_loss = 1.63651165, grad/param norm = 1.7407e-01, time/batch = 19.0394s	
6111/30300 (epoch 10.084), train_loss = 1.37258462, grad/param norm = 1.5755e-01, time/batch = 18.8653s	
6112/30300 (epoch 10.086), train_loss = 1.42734826, grad/param norm = 1.5557e-01, time/batch = 18.2663s	
6113/30300 (epoch 10.087), train_loss = 1.35022257, grad/param norm = 1.3707e-01, time/batch = 17.2143s	
6114/30300 (epoch 10.089), train_loss = 1.43478712, grad/param norm = 1.5237e-01, time/batch = 18.8734s	
6115/30300 (epoch 10.091), train_loss = 1.56594564, grad/param norm = 1.6348e-01, time/batch = 18.0281s	
6116/30300 (epoch 10.092), train_loss = 1.45803344, grad/param norm = 1.5685e-01, time/batch = 17.0176s	
6117/30300 (epoch 10.094), train_loss = 1.69390414, grad/param norm = 1.6992e-01, time/batch = 17.1201s	
6118/30300 (epoch 10.096), train_loss = 1.56852742, grad/param norm = 1.6887e-01, time/batch = 18.8511s	
6119/30300 (epoch 10.097), train_loss = 1.36366021, grad/param norm = 1.5379e-01, time/batch = 19.2863s	
6120/30300 (epoch 10.099), train_loss = 1.66679069, grad/param norm = 1.6326e-01, time/batch = 19.1180s	
6121/30300 (epoch 10.101), train_loss = 1.73762811, grad/param norm = 1.7515e-01, time/batch = 18.6965s	
6122/30300 (epoch 10.102), train_loss = 1.51017190, grad/param norm = 1.6905e-01, time/batch = 18.6190s	
6123/30300 (epoch 10.104), train_loss = 1.43348885, grad/param norm = 1.6089e-01, time/batch = 19.7132s	
6124/30300 (epoch 10.106), train_loss = 1.51500854, grad/param norm = 1.5468e-01, time/batch = 17.7417s	
6125/30300 (epoch 10.107), train_loss = 1.51308620, grad/param norm = 1.5226e-01, time/batch = 18.7091s	
6126/30300 (epoch 10.109), train_loss = 1.58963276, grad/param norm = 1.6614e-01, time/batch = 18.6988s	
6127/30300 (epoch 10.111), train_loss = 1.62741803, grad/param norm = 1.6725e-01, time/batch = 19.1263s	
6128/30300 (epoch 10.112), train_loss = 1.52801139, grad/param norm = 1.4942e-01, time/batch = 18.4519s	
6129/30300 (epoch 10.114), train_loss = 1.48899142, grad/param norm = 1.5431e-01, time/batch = 18.2891s	
6130/30300 (epoch 10.116), train_loss = 1.52916018, grad/param norm = 1.5920e-01, time/batch = 18.3771s	
6131/30300 (epoch 10.117), train_loss = 1.49854509, grad/param norm = 1.5621e-01, time/batch = 18.1295s	
6132/30300 (epoch 10.119), train_loss = 1.40831046, grad/param norm = 1.6028e-01, time/batch = 18.4688s	
6133/30300 (epoch 10.120), train_loss = 1.50197583, grad/param norm = 1.6532e-01, time/batch = 19.5295s	
6134/30300 (epoch 10.122), train_loss = 1.59974408, grad/param norm = 1.6329e-01, time/batch = 16.4381s	
6135/30300 (epoch 10.124), train_loss = 1.70360560, grad/param norm = 1.7940e-01, time/batch = 18.6959s	
6136/30300 (epoch 10.125), train_loss = 1.32961297, grad/param norm = 1.4179e-01, time/batch = 18.8062s	
6137/30300 (epoch 10.127), train_loss = 1.50254945, grad/param norm = 1.6495e-01, time/batch = 17.9601s	
6138/30300 (epoch 10.129), train_loss = 1.63798951, grad/param norm = 1.5265e-01, time/batch = 16.8633s	
6139/30300 (epoch 10.130), train_loss = 1.64296076, grad/param norm = 1.5005e-01, time/batch = 19.2012s	
6140/30300 (epoch 10.132), train_loss = 1.54511902, grad/param norm = 2.4708e-01, time/batch = 18.6152s	
6141/30300 (epoch 10.134), train_loss = 1.39352617, grad/param norm = 1.5711e-01, time/batch = 18.7006s	
6142/30300 (epoch 10.135), train_loss = 1.44910976, grad/param norm = 1.7257e-01, time/batch = 18.7954s	
6143/30300 (epoch 10.137), train_loss = 1.60213568, grad/param norm = 1.6019e-01, time/batch = 19.0635s	
6144/30300 (epoch 10.139), train_loss = 1.47753671, grad/param norm = 1.6316e-01, time/batch = 17.6963s	
6145/30300 (epoch 10.140), train_loss = 1.69034742, grad/param norm = 3.5447e-01, time/batch = 18.1003s	
6146/30300 (epoch 10.142), train_loss = 1.78625820, grad/param norm = 2.0038e-01, time/batch = 19.1863s	
6147/30300 (epoch 10.144), train_loss = 1.62427871, grad/param norm = 2.0584e-01, time/batch = 19.1981s	
6148/30300 (epoch 10.145), train_loss = 1.67614360, grad/param norm = 1.6013e-01, time/batch = 19.5220s	
6149/30300 (epoch 10.147), train_loss = 1.53308236, grad/param norm = 1.5742e-01, time/batch = 19.2725s	
6150/30300 (epoch 10.149), train_loss = 1.72215759, grad/param norm = 1.6415e-01, time/batch = 18.3654s	
6151/30300 (epoch 10.150), train_loss = 1.63061732, grad/param norm = 1.6789e-01, time/batch = 19.6170s	
6152/30300 (epoch 10.152), train_loss = 1.41702067, grad/param norm = 1.6322e-01, time/batch = 19.1971s	
6153/30300 (epoch 10.153), train_loss = 1.54181751, grad/param norm = 1.7835e-01, time/batch = 18.7941s	
6154/30300 (epoch 10.155), train_loss = 1.30905522, grad/param norm = 1.4067e-01, time/batch = 19.2927s	
6155/30300 (epoch 10.157), train_loss = 1.49864696, grad/param norm = 1.6830e-01, time/batch = 19.6211s	
6156/30300 (epoch 10.158), train_loss = 1.57571985, grad/param norm = 1.6250e-01, time/batch = 16.7816s	
6157/30300 (epoch 10.160), train_loss = 1.43604453, grad/param norm = 1.5214e-01, time/batch = 17.9666s	
6158/30300 (epoch 10.162), train_loss = 1.41896593, grad/param norm = 1.4832e-01, time/batch = 19.9537s	
6159/30300 (epoch 10.163), train_loss = 1.44145830, grad/param norm = 1.7663e-01, time/batch = 20.1238s	
6160/30300 (epoch 10.165), train_loss = 1.56403263, grad/param norm = 1.4795e-01, time/batch = 17.3603s	
6161/30300 (epoch 10.167), train_loss = 1.56878977, grad/param norm = 1.7313e-01, time/batch = 17.6407s	
6162/30300 (epoch 10.168), train_loss = 1.50471992, grad/param norm = 1.5225e-01, time/batch = 19.3812s	
6163/30300 (epoch 10.170), train_loss = 1.54991813, grad/param norm = 1.5224e-01, time/batch = 16.1306s	
6164/30300 (epoch 10.172), train_loss = 1.45173261, grad/param norm = 1.5912e-01, time/batch = 18.8516s	
6165/30300 (epoch 10.173), train_loss = 1.57636783, grad/param norm = 1.6903e-01, time/batch = 18.6841s	
6166/30300 (epoch 10.175), train_loss = 1.49194846, grad/param norm = 1.4534e-01, time/batch = 17.2884s	
6167/30300 (epoch 10.177), train_loss = 1.52047463, grad/param norm = 1.6178e-01, time/batch = 18.6397s	
6168/30300 (epoch 10.178), train_loss = 1.25038054, grad/param norm = 1.3957e-01, time/batch = 19.1289s	
6169/30300 (epoch 10.180), train_loss = 1.41033058, grad/param norm = 1.3928e-01, time/batch = 18.7953s	
6170/30300 (epoch 10.182), train_loss = 1.42696756, grad/param norm = 1.6341e-01, time/batch = 16.6988s	
6171/30300 (epoch 10.183), train_loss = 1.39069496, grad/param norm = 1.4229e-01, time/batch = 19.0202s	
6172/30300 (epoch 10.185), train_loss = 1.77517935, grad/param norm = 1.5567e-01, time/batch = 19.1195s	
6173/30300 (epoch 10.186), train_loss = 1.76816722, grad/param norm = 1.7639e-01, time/batch = 18.5160s	
6174/30300 (epoch 10.188), train_loss = 1.59040001, grad/param norm = 1.6284e-01, time/batch = 19.7848s	
6175/30300 (epoch 10.190), train_loss = 1.43819625, grad/param norm = 1.4795e-01, time/batch = 18.2050s	
6176/30300 (epoch 10.191), train_loss = 1.59120190, grad/param norm = 1.6054e-01, time/batch = 15.8866s	
6177/30300 (epoch 10.193), train_loss = 1.36234371, grad/param norm = 1.4594e-01, time/batch = 19.2892s	
6178/30300 (epoch 10.195), train_loss = 1.52345247, grad/param norm = 1.5507e-01, time/batch = 18.9625s	
6179/30300 (epoch 10.196), train_loss = 1.49021009, grad/param norm = 1.4242e-01, time/batch = 18.8758s	
6180/30300 (epoch 10.198), train_loss = 1.26420190, grad/param norm = 1.4843e-01, time/batch = 18.6238s	
6181/30300 (epoch 10.200), train_loss = 1.49068494, grad/param norm = 1.4863e-01, time/batch = 20.0497s	
6182/30300 (epoch 10.201), train_loss = 1.61167810, grad/param norm = 1.7240e-01, time/batch = 18.5296s	
6183/30300 (epoch 10.203), train_loss = 1.47826751, grad/param norm = 1.5568e-01, time/batch = 18.7772s	
6184/30300 (epoch 10.205), train_loss = 1.71444690, grad/param norm = 1.5799e-01, time/batch = 19.3848s	
6185/30300 (epoch 10.206), train_loss = 1.70951255, grad/param norm = 1.6587e-01, time/batch = 18.8647s	
6186/30300 (epoch 10.208), train_loss = 1.64654359, grad/param norm = 1.7014e-01, time/batch = 19.6181s	
6187/30300 (epoch 10.210), train_loss = 1.52141885, grad/param norm = 1.4027e-01, time/batch = 19.4700s	
6188/30300 (epoch 10.211), train_loss = 1.55360790, grad/param norm = 1.5171e-01, time/batch = 19.6238s	
6189/30300 (epoch 10.213), train_loss = 1.41900364, grad/param norm = 1.4480e-01, time/batch = 17.4674s	
6190/30300 (epoch 10.215), train_loss = 1.31212815, grad/param norm = 1.5253e-01, time/batch = 19.8742s	
6191/30300 (epoch 10.216), train_loss = 1.49022579, grad/param norm = 1.7656e-01, time/batch = 17.6974s	
6192/30300 (epoch 10.218), train_loss = 1.40021061, grad/param norm = 1.5890e-01, time/batch = 18.1884s	
6193/30300 (epoch 10.219), train_loss = 1.31030843, grad/param norm = 1.3748e-01, time/batch = 19.0436s	
6194/30300 (epoch 10.221), train_loss = 1.33712711, grad/param norm = 1.4704e-01, time/batch = 18.2307s	
6195/30300 (epoch 10.223), train_loss = 1.49237002, grad/param norm = 1.4913e-01, time/batch = 18.0306s	
6196/30300 (epoch 10.224), train_loss = 1.32170157, grad/param norm = 1.4363e-01, time/batch = 19.2704s	
6197/30300 (epoch 10.226), train_loss = 1.60812016, grad/param norm = 1.8536e-01, time/batch = 19.8626s	
6198/30300 (epoch 10.228), train_loss = 1.62160618, grad/param norm = 1.5162e-01, time/batch = 18.1079s	
6199/30300 (epoch 10.229), train_loss = 1.38799041, grad/param norm = 1.5439e-01, time/batch = 19.8722s	
6200/30300 (epoch 10.231), train_loss = 1.51217216, grad/param norm = 1.5233e-01, time/batch = 19.8785s	
6201/30300 (epoch 10.233), train_loss = 1.42645986, grad/param norm = 1.5272e-01, time/batch = 19.0247s	
6202/30300 (epoch 10.234), train_loss = 1.55343640, grad/param norm = 1.6208e-01, time/batch = 20.0416s	
6203/30300 (epoch 10.236), train_loss = 1.39435985, grad/param norm = 1.4708e-01, time/batch = 18.5437s	
6204/30300 (epoch 10.238), train_loss = 1.55015755, grad/param norm = 1.8138e-01, time/batch = 17.9688s	
6205/30300 (epoch 10.239), train_loss = 1.52632077, grad/param norm = 1.5103e-01, time/batch = 19.3792s	
6206/30300 (epoch 10.241), train_loss = 1.56607058, grad/param norm = 1.7706e-01, time/batch = 19.0459s	
6207/30300 (epoch 10.243), train_loss = 1.52778480, grad/param norm = 1.5639e-01, time/batch = 19.5197s	
6208/30300 (epoch 10.244), train_loss = 1.76661781, grad/param norm = 1.7085e-01, time/batch = 19.2960s	
6209/30300 (epoch 10.246), train_loss = 1.46011196, grad/param norm = 1.5370e-01, time/batch = 18.4638s	
6210/30300 (epoch 10.248), train_loss = 1.49954006, grad/param norm = 1.5017e-01, time/batch = 20.2741s	
6211/30300 (epoch 10.249), train_loss = 1.35780436, grad/param norm = 1.4938e-01, time/batch = 19.0323s	
6212/30300 (epoch 10.251), train_loss = 1.37263945, grad/param norm = 1.5311e-01, time/batch = 17.0028s	
6213/30300 (epoch 10.252), train_loss = 1.63183383, grad/param norm = 1.6208e-01, time/batch = 19.5385s	
6214/30300 (epoch 10.254), train_loss = 1.61677975, grad/param norm = 1.6628e-01, time/batch = 18.7700s	
6215/30300 (epoch 10.256), train_loss = 1.48832299, grad/param norm = 1.4409e-01, time/batch = 20.0376s	
6216/30300 (epoch 10.257), train_loss = 1.60971873, grad/param norm = 1.6607e-01, time/batch = 18.7066s	
6217/30300 (epoch 10.259), train_loss = 1.53300229, grad/param norm = 1.5365e-01, time/batch = 17.7115s	
6218/30300 (epoch 10.261), train_loss = 1.61875783, grad/param norm = 1.4702e-01, time/batch = 19.6133s	
6219/30300 (epoch 10.262), train_loss = 1.47691758, grad/param norm = 1.5003e-01, time/batch = 19.4601s	
6220/30300 (epoch 10.264), train_loss = 1.48989441, grad/param norm = 1.6248e-01, time/batch = 18.0271s	
6221/30300 (epoch 10.266), train_loss = 1.40864220, grad/param norm = 1.4904e-01, time/batch = 19.6941s	
6222/30300 (epoch 10.267), train_loss = 1.67080758, grad/param norm = 1.6686e-01, time/batch = 19.9624s	
6223/30300 (epoch 10.269), train_loss = 1.49574864, grad/param norm = 1.5398e-01, time/batch = 18.2006s	
6224/30300 (epoch 10.271), train_loss = 1.47172720, grad/param norm = 1.5573e-01, time/batch = 19.7886s	
6225/30300 (epoch 10.272), train_loss = 1.55261748, grad/param norm = 1.5805e-01, time/batch = 18.5388s	
6226/30300 (epoch 10.274), train_loss = 1.68025332, grad/param norm = 1.6217e-01, time/batch = 18.8819s	
6227/30300 (epoch 10.276), train_loss = 1.60464209, grad/param norm = 1.6591e-01, time/batch = 19.2145s	
6228/30300 (epoch 10.277), train_loss = 1.42652151, grad/param norm = 1.5833e-01, time/batch = 18.2946s	
6229/30300 (epoch 10.279), train_loss = 1.55065176, grad/param norm = 1.5717e-01, time/batch = 18.6973s	
6230/30300 (epoch 10.281), train_loss = 1.57470056, grad/param norm = 1.7955e-01, time/batch = 19.4462s	
6231/30300 (epoch 10.282), train_loss = 1.45558022, grad/param norm = 1.4006e-01, time/batch = 17.2835s	
6232/30300 (epoch 10.284), train_loss = 1.68677355, grad/param norm = 1.7586e-01, time/batch = 19.8096s	
6233/30300 (epoch 10.285), train_loss = 1.52426835, grad/param norm = 1.5511e-01, time/batch = 18.0874s	
6234/30300 (epoch 10.287), train_loss = 1.49824211, grad/param norm = 1.5576e-01, time/batch = 19.2348s	
6235/30300 (epoch 10.289), train_loss = 1.54812683, grad/param norm = 1.6236e-01, time/batch = 19.4427s	
6236/30300 (epoch 10.290), train_loss = 1.24170863, grad/param norm = 1.3704e-01, time/batch = 18.7084s	
6237/30300 (epoch 10.292), train_loss = 1.39193724, grad/param norm = 1.4127e-01, time/batch = 19.8831s	
6238/30300 (epoch 10.294), train_loss = 1.65477259, grad/param norm = 1.5325e-01, time/batch = 17.8767s	
6239/30300 (epoch 10.295), train_loss = 1.47752124, grad/param norm = 1.4817e-01, time/batch = 18.2095s	
6240/30300 (epoch 10.297), train_loss = 1.40311613, grad/param norm = 1.3965e-01, time/batch = 19.5417s	
6241/30300 (epoch 10.299), train_loss = 1.47785116, grad/param norm = 1.6245e-01, time/batch = 18.6273s	
6242/30300 (epoch 10.300), train_loss = 1.52819181, grad/param norm = 1.5203e-01, time/batch = 17.2833s	
6243/30300 (epoch 10.302), train_loss = 1.42078395, grad/param norm = 1.5076e-01, time/batch = 19.8757s	
6244/30300 (epoch 10.304), train_loss = 1.36898842, grad/param norm = 1.4891e-01, time/batch = 19.3762s	
6245/30300 (epoch 10.305), train_loss = 1.42184902, grad/param norm = 1.4539e-01, time/batch = 18.7280s	
6246/30300 (epoch 10.307), train_loss = 1.49087655, grad/param norm = 1.4569e-01, time/batch = 19.5341s	
6247/30300 (epoch 10.309), train_loss = 1.57823742, grad/param norm = 1.4736e-01, time/batch = 19.1385s	
6248/30300 (epoch 10.310), train_loss = 1.45147885, grad/param norm = 1.5178e-01, time/batch = 18.2861s	
6249/30300 (epoch 10.312), train_loss = 1.57617090, grad/param norm = 1.4497e-01, time/batch = 19.0191s	
6250/30300 (epoch 10.314), train_loss = 1.52774394, grad/param norm = 1.5825e-01, time/batch = 19.8856s	
6251/30300 (epoch 10.315), train_loss = 1.55310728, grad/param norm = 1.5878e-01, time/batch = 19.2897s	
6252/30300 (epoch 10.317), train_loss = 1.60782940, grad/param norm = 1.7055e-01, time/batch = 18.7828s	
6253/30300 (epoch 10.318), train_loss = 1.66436482, grad/param norm = 1.7261e-01, time/batch = 19.2960s	
6254/30300 (epoch 10.320), train_loss = 1.65312651, grad/param norm = 1.7242e-01, time/batch = 19.4737s	
6255/30300 (epoch 10.322), train_loss = 1.38490557, grad/param norm = 1.4877e-01, time/batch = 31.9688s	
6256/30300 (epoch 10.323), train_loss = 1.62627448, grad/param norm = 1.6106e-01, time/batch = 19.0297s	
6257/30300 (epoch 10.325), train_loss = 1.45962224, grad/param norm = 1.3939e-01, time/batch = 16.3347s	
6258/30300 (epoch 10.327), train_loss = 1.45164443, grad/param norm = 1.4810e-01, time/batch = 17.4279s	
6259/30300 (epoch 10.328), train_loss = 1.43658315, grad/param norm = 1.3967e-01, time/batch = 17.2925s	
6260/30300 (epoch 10.330), train_loss = 1.57925977, grad/param norm = 1.4621e-01, time/batch = 19.1995s	
6261/30300 (epoch 10.332), train_loss = 1.59623986, grad/param norm = 1.5888e-01, time/batch = 17.2680s	
6262/30300 (epoch 10.333), train_loss = 1.51428077, grad/param norm = 1.5683e-01, time/batch = 19.0586s	
6263/30300 (epoch 10.335), train_loss = 1.32927353, grad/param norm = 1.4619e-01, time/batch = 19.8758s	
6264/30300 (epoch 10.337), train_loss = 1.67887154, grad/param norm = 1.6313e-01, time/batch = 17.0455s	
6265/30300 (epoch 10.338), train_loss = 1.41046951, grad/param norm = 1.5159e-01, time/batch = 18.5460s	
6266/30300 (epoch 10.340), train_loss = 1.36789250, grad/param norm = 1.4885e-01, time/batch = 18.0410s	
6267/30300 (epoch 10.342), train_loss = 1.58070995, grad/param norm = 1.5370e-01, time/batch = 17.5325s	
6268/30300 (epoch 10.343), train_loss = 1.58378335, grad/param norm = 1.5352e-01, time/batch = 18.3682s	
6269/30300 (epoch 10.345), train_loss = 1.51155573, grad/param norm = 1.4573e-01, time/batch = 19.4551s	
6270/30300 (epoch 10.347), train_loss = 1.30960826, grad/param norm = 1.2810e-01, time/batch = 17.9563s	
6271/30300 (epoch 10.348), train_loss = 1.37790649, grad/param norm = 1.5085e-01, time/batch = 19.1258s	
6272/30300 (epoch 10.350), train_loss = 1.47661990, grad/param norm = 1.5189e-01, time/batch = 18.8683s	
6273/30300 (epoch 10.351), train_loss = 1.50461683, grad/param norm = 1.5744e-01, time/batch = 18.1726s	
6274/30300 (epoch 10.353), train_loss = 1.28160878, grad/param norm = 1.4989e-01, time/batch = 18.7858s	
6275/30300 (epoch 10.355), train_loss = 1.43973879, grad/param norm = 1.5109e-01, time/batch = 19.0511s	
6276/30300 (epoch 10.356), train_loss = 1.61375981, grad/param norm = 1.7582e-01, time/batch = 19.4580s	
6277/30300 (epoch 10.358), train_loss = 1.66546351, grad/param norm = 1.4894e-01, time/batch = 18.0221s	
6278/30300 (epoch 10.360), train_loss = 1.42107512, grad/param norm = 1.4926e-01, time/batch = 19.6288s	
6279/30300 (epoch 10.361), train_loss = 1.51733471, grad/param norm = 1.5991e-01, time/batch = 19.3804s	
6280/30300 (epoch 10.363), train_loss = 1.56776475, grad/param norm = 1.4649e-01, time/batch = 16.7288s	
6281/30300 (epoch 10.365), train_loss = 1.41648778, grad/param norm = 1.5950e-01, time/batch = 20.1163s	
6282/30300 (epoch 10.366), train_loss = 1.41700859, grad/param norm = 1.4647e-01, time/batch = 19.5506s	
6283/30300 (epoch 10.368), train_loss = 1.28007658, grad/param norm = 1.4814e-01, time/batch = 17.7960s	
6284/30300 (epoch 10.370), train_loss = 1.37794054, grad/param norm = 1.4755e-01, time/batch = 19.4464s	
6285/30300 (epoch 10.371), train_loss = 1.52997761, grad/param norm = 1.4539e-01, time/batch = 17.2241s	
6286/30300 (epoch 10.373), train_loss = 1.39256190, grad/param norm = 1.3681e-01, time/batch = 18.1203s	
6287/30300 (epoch 10.375), train_loss = 1.38743610, grad/param norm = 1.3298e-01, time/batch = 18.7753s	
6288/30300 (epoch 10.376), train_loss = 1.42363253, grad/param norm = 1.4162e-01, time/batch = 19.1441s	
6289/30300 (epoch 10.378), train_loss = 1.44397316, grad/param norm = 1.5153e-01, time/batch = 18.6259s	
6290/30300 (epoch 10.380), train_loss = 1.69896212, grad/param norm = 1.6657e-01, time/batch = 18.9477s	
6291/30300 (epoch 10.381), train_loss = 1.38876646, grad/param norm = 1.4518e-01, time/batch = 19.9584s	
6292/30300 (epoch 10.383), train_loss = 1.48339825, grad/param norm = 1.6079e-01, time/batch = 18.6295s	
6293/30300 (epoch 10.384), train_loss = 1.58080883, grad/param norm = 1.4386e-01, time/batch = 17.9087s	
6294/30300 (epoch 10.386), train_loss = 1.34526913, grad/param norm = 1.5484e-01, time/batch = 18.9610s	
6295/30300 (epoch 10.388), train_loss = 1.34506470, grad/param norm = 1.3460e-01, time/batch = 19.8750s	
6296/30300 (epoch 10.389), train_loss = 1.50928057, grad/param norm = 1.5350e-01, time/batch = 17.7053s	
6297/30300 (epoch 10.391), train_loss = 1.54362171, grad/param norm = 1.4584e-01, time/batch = 19.3585s	
6298/30300 (epoch 10.393), train_loss = 1.29337280, grad/param norm = 1.3177e-01, time/batch = 19.4672s	
6299/30300 (epoch 10.394), train_loss = 1.48787124, grad/param norm = 1.4513e-01, time/batch = 17.6240s	
6300/30300 (epoch 10.396), train_loss = 1.65263877, grad/param norm = 1.4664e-01, time/batch = 19.4545s	
6301/30300 (epoch 10.398), train_loss = 1.42014134, grad/param norm = 1.3476e-01, time/batch = 19.2910s	
6302/30300 (epoch 10.399), train_loss = 1.45734394, grad/param norm = 1.5131e-01, time/batch = 16.7725s	
6303/30300 (epoch 10.401), train_loss = 1.58339432, grad/param norm = 1.5451e-01, time/batch = 19.8621s	
6304/30300 (epoch 10.403), train_loss = 1.42651551, grad/param norm = 1.4590e-01, time/batch = 18.9530s	
6305/30300 (epoch 10.404), train_loss = 1.37890233, grad/param norm = 1.7551e-01, time/batch = 18.2963s	
6306/30300 (epoch 10.406), train_loss = 1.48484089, grad/param norm = 1.5060e-01, time/batch = 19.3046s	
6307/30300 (epoch 10.408), train_loss = 1.34632748, grad/param norm = 1.5135e-01, time/batch = 18.5541s	
6308/30300 (epoch 10.409), train_loss = 1.29469653, grad/param norm = 1.4528e-01, time/batch = 18.1808s	
6309/30300 (epoch 10.411), train_loss = 1.33052815, grad/param norm = 1.4162e-01, time/batch = 18.7771s	
6310/30300 (epoch 10.413), train_loss = 1.28918361, grad/param norm = 1.4363e-01, time/batch = 19.4751s	
6311/30300 (epoch 10.414), train_loss = 1.59296994, grad/param norm = 1.5330e-01, time/batch = 18.6286s	
6312/30300 (epoch 10.416), train_loss = 1.44415177, grad/param norm = 1.5639e-01, time/batch = 18.1988s	
6313/30300 (epoch 10.417), train_loss = 1.41166973, grad/param norm = 1.4859e-01, time/batch = 19.4590s	
6314/30300 (epoch 10.419), train_loss = 1.31406678, grad/param norm = 1.3799e-01, time/batch = 19.5542s	
6315/30300 (epoch 10.421), train_loss = 1.40875854, grad/param norm = 1.3938e-01, time/batch = 18.5417s	
6316/30300 (epoch 10.422), train_loss = 1.42903946, grad/param norm = 1.3779e-01, time/batch = 19.5352s	
6317/30300 (epoch 10.424), train_loss = 1.48013473, grad/param norm = 1.4908e-01, time/batch = 19.6250s	
6318/30300 (epoch 10.426), train_loss = 1.33382646, grad/param norm = 1.4668e-01, time/batch = 12.5524s	
6319/30300 (epoch 10.427), train_loss = 1.44494034, grad/param norm = 1.5045e-01, time/batch = 0.7112s	
6320/30300 (epoch 10.429), train_loss = 1.49647748, grad/param norm = 1.6244e-01, time/batch = 0.7035s	
6321/30300 (epoch 10.431), train_loss = 1.54870264, grad/param norm = 1.6351e-01, time/batch = 0.7208s	
6322/30300 (epoch 10.432), train_loss = 1.43637994, grad/param norm = 1.4811e-01, time/batch = 0.6985s	
6323/30300 (epoch 10.434), train_loss = 1.30989634, grad/param norm = 1.5499e-01, time/batch = 0.6897s	
6324/30300 (epoch 10.436), train_loss = 1.61408568, grad/param norm = 1.6408e-01, time/batch = 0.6935s	
6325/30300 (epoch 10.437), train_loss = 1.39109632, grad/param norm = 1.8069e-01, time/batch = 0.7813s	
6326/30300 (epoch 10.439), train_loss = 1.39485638, grad/param norm = 1.4957e-01, time/batch = 1.0155s	
6327/30300 (epoch 10.441), train_loss = 1.39716656, grad/param norm = 1.4358e-01, time/batch = 1.0209s	
6328/30300 (epoch 10.442), train_loss = 1.34903997, grad/param norm = 1.4596e-01, time/batch = 1.0208s	
6329/30300 (epoch 10.444), train_loss = 1.22704987, grad/param norm = 1.3537e-01, time/batch = 1.0049s	
6330/30300 (epoch 10.446), train_loss = 1.41608967, grad/param norm = 1.4752e-01, time/batch = 1.3235s	
6331/30300 (epoch 10.447), train_loss = 1.44267839, grad/param norm = 1.4534e-01, time/batch = 1.8841s	
6332/30300 (epoch 10.449), train_loss = 1.38962590, grad/param norm = 1.5010e-01, time/batch = 1.9282s	
6333/30300 (epoch 10.450), train_loss = 1.57582796, grad/param norm = 1.4834e-01, time/batch = 15.6969s	
6334/30300 (epoch 10.452), train_loss = 1.47442205, grad/param norm = 1.3634e-01, time/batch = 20.5402s	
6335/30300 (epoch 10.454), train_loss = 1.46602592, grad/param norm = 1.3813e-01, time/batch = 17.1198s	
6336/30300 (epoch 10.455), train_loss = 1.55588232, grad/param norm = 1.6051e-01, time/batch = 20.3630s	
6337/30300 (epoch 10.457), train_loss = 1.50825978, grad/param norm = 1.5078e-01, time/batch = 19.8015s	
6338/30300 (epoch 10.459), train_loss = 1.55452649, grad/param norm = 1.6349e-01, time/batch = 18.2848s	
6339/30300 (epoch 10.460), train_loss = 1.55782113, grad/param norm = 1.7087e-01, time/batch = 17.6200s	
6340/30300 (epoch 10.462), train_loss = 1.57022888, grad/param norm = 1.5063e-01, time/batch = 18.7721s	
6341/30300 (epoch 10.464), train_loss = 1.33160630, grad/param norm = 1.5654e-01, time/batch = 19.2943s	
6342/30300 (epoch 10.465), train_loss = 1.27427999, grad/param norm = 1.4043e-01, time/batch = 18.9556s	
6343/30300 (epoch 10.467), train_loss = 1.22538553, grad/param norm = 1.3265e-01, time/batch = 19.2148s	
6344/30300 (epoch 10.469), train_loss = 1.38585279, grad/param norm = 1.6015e-01, time/batch = 18.9630s	
6345/30300 (epoch 10.470), train_loss = 1.41695572, grad/param norm = 1.4651e-01, time/batch = 19.0570s	
6346/30300 (epoch 10.472), train_loss = 1.39622484, grad/param norm = 1.4062e-01, time/batch = 19.9595s	
6347/30300 (epoch 10.474), train_loss = 1.47946354, grad/param norm = 1.6130e-01, time/batch = 19.2875s	
6348/30300 (epoch 10.475), train_loss = 1.36082948, grad/param norm = 1.5085e-01, time/batch = 18.5319s	
6349/30300 (epoch 10.477), train_loss = 1.49358665, grad/param norm = 1.6690e-01, time/batch = 19.0477s	
6350/30300 (epoch 10.479), train_loss = 1.48014957, grad/param norm = 1.5524e-01, time/batch = 19.3722s	
6351/30300 (epoch 10.480), train_loss = 1.49982524, grad/param norm = 1.4365e-01, time/batch = 18.6250s	
6352/30300 (epoch 10.482), train_loss = 1.50709540, grad/param norm = 1.4456e-01, time/batch = 19.3683s	
6353/30300 (epoch 10.483), train_loss = 1.41673044, grad/param norm = 1.4930e-01, time/batch = 17.2761s	
6354/30300 (epoch 10.485), train_loss = 1.45918714, grad/param norm = 1.4614e-01, time/batch = 18.3735s	
6355/30300 (epoch 10.487), train_loss = 1.50797547, grad/param norm = 1.5808e-01, time/batch = 18.7146s	
6356/30300 (epoch 10.488), train_loss = 1.51021987, grad/param norm = 1.4728e-01, time/batch = 19.1217s	
6357/30300 (epoch 10.490), train_loss = 1.35668017, grad/param norm = 1.5124e-01, time/batch = 17.9687s	
6358/30300 (epoch 10.492), train_loss = 1.48816351, grad/param norm = 1.6117e-01, time/batch = 18.9702s	
6359/30300 (epoch 10.493), train_loss = 1.40736354, grad/param norm = 1.5245e-01, time/batch = 20.3751s	
6360/30300 (epoch 10.495), train_loss = 1.39561389, grad/param norm = 1.4692e-01, time/batch = 17.8705s	
6361/30300 (epoch 10.497), train_loss = 1.49672542, grad/param norm = 1.5377e-01, time/batch = 18.4465s	
6362/30300 (epoch 10.498), train_loss = 1.47115905, grad/param norm = 1.5006e-01, time/batch = 19.9509s	
6363/30300 (epoch 10.500), train_loss = 1.57439259, grad/param norm = 1.6893e-01, time/batch = 18.8666s	
6364/30300 (epoch 10.502), train_loss = 1.40539344, grad/param norm = 1.4944e-01, time/batch = 19.2842s	
6365/30300 (epoch 10.503), train_loss = 1.53793381, grad/param norm = 1.4881e-01, time/batch = 19.8024s	
6366/30300 (epoch 10.505), train_loss = 1.45121581, grad/param norm = 1.4767e-01, time/batch = 18.4332s	
6367/30300 (epoch 10.507), train_loss = 1.40419709, grad/param norm = 1.5420e-01, time/batch = 19.2896s	
6368/30300 (epoch 10.508), train_loss = 1.49346993, grad/param norm = 1.7611e-01, time/batch = 18.9610s	
6369/30300 (epoch 10.510), train_loss = 1.55326680, grad/param norm = 1.7396e-01, time/batch = 18.6261s	
6370/30300 (epoch 10.512), train_loss = 1.37254989, grad/param norm = 1.4997e-01, time/batch = 18.5257s	
6371/30300 (epoch 10.513), train_loss = 1.55634514, grad/param norm = 1.5369e-01, time/batch = 19.2185s	
6372/30300 (epoch 10.515), train_loss = 1.43799999, grad/param norm = 1.4675e-01, time/batch = 19.6314s	
6373/30300 (epoch 10.517), train_loss = 1.29706142, grad/param norm = 1.5208e-01, time/batch = 18.9525s	
6374/30300 (epoch 10.518), train_loss = 1.53642325, grad/param norm = 1.6067e-01, time/batch = 19.4715s	
6375/30300 (epoch 10.520), train_loss = 1.68224014, grad/param norm = 1.6596e-01, time/batch = 18.5510s	
6376/30300 (epoch 10.521), train_loss = 1.33264161, grad/param norm = 1.5833e-01, time/batch = 17.7955s	
6377/30300 (epoch 10.523), train_loss = 1.60108787, grad/param norm = 1.7171e-01, time/batch = 19.6278s	
6378/30300 (epoch 10.525), train_loss = 1.39744328, grad/param norm = 1.5895e-01, time/batch = 20.4419s	
6379/30300 (epoch 10.526), train_loss = 1.45768878, grad/param norm = 1.5930e-01, time/batch = 18.0347s	
6380/30300 (epoch 10.528), train_loss = 1.30248959, grad/param norm = 1.4768e-01, time/batch = 18.3792s	
6381/30300 (epoch 10.530), train_loss = 1.34238266, grad/param norm = 1.5390e-01, time/batch = 19.7954s	
6382/30300 (epoch 10.531), train_loss = 1.53041594, grad/param norm = 1.6483e-01, time/batch = 17.1928s	
6383/30300 (epoch 10.533), train_loss = 1.52114872, grad/param norm = 1.5470e-01, time/batch = 19.6252s	
6384/30300 (epoch 10.535), train_loss = 1.28466446, grad/param norm = 1.3348e-01, time/batch = 19.1226s	
6385/30300 (epoch 10.536), train_loss = 1.50303930, grad/param norm = 1.5814e-01, time/batch = 18.7033s	
6386/30300 (epoch 10.538), train_loss = 1.27651741, grad/param norm = 1.5959e-01, time/batch = 19.3677s	
6387/30300 (epoch 10.540), train_loss = 1.36007861, grad/param norm = 1.5640e-01, time/batch = 19.0248s	
6388/30300 (epoch 10.541), train_loss = 1.44140320, grad/param norm = 1.5985e-01, time/batch = 16.9713s	
6389/30300 (epoch 10.543), train_loss = 1.47118478, grad/param norm = 1.4624e-01, time/batch = 17.4598s	
6390/30300 (epoch 10.545), train_loss = 1.50533097, grad/param norm = 1.6195e-01, time/batch = 19.4646s	
6391/30300 (epoch 10.546), train_loss = 1.68250708, grad/param norm = 1.5507e-01, time/batch = 19.7026s	
6392/30300 (epoch 10.548), train_loss = 1.39714222, grad/param norm = 1.5297e-01, time/batch = 18.7139s	
6393/30300 (epoch 10.550), train_loss = 1.61151030, grad/param norm = 1.6736e-01, time/batch = 19.2963s	
6394/30300 (epoch 10.551), train_loss = 1.39186233, grad/param norm = 1.5094e-01, time/batch = 19.4559s	
6395/30300 (epoch 10.553), train_loss = 1.37787932, grad/param norm = 1.5870e-01, time/batch = 18.2149s	
6396/30300 (epoch 10.554), train_loss = 1.55694947, grad/param norm = 1.6203e-01, time/batch = 18.9700s	
6397/30300 (epoch 10.556), train_loss = 1.50810845, grad/param norm = 1.5461e-01, time/batch = 19.9603s	
6398/30300 (epoch 10.558), train_loss = 1.61007022, grad/param norm = 1.6279e-01, time/batch = 16.6923s	
6399/30300 (epoch 10.559), train_loss = 1.47943805, grad/param norm = 1.5722e-01, time/batch = 18.9513s	
6400/30300 (epoch 10.561), train_loss = 1.32360558, grad/param norm = 1.5352e-01, time/batch = 19.3080s	
6401/30300 (epoch 10.563), train_loss = 1.36660760, grad/param norm = 1.4565e-01, time/batch = 18.3423s	
6402/30300 (epoch 10.564), train_loss = 1.40942609, grad/param norm = 1.5171e-01, time/batch = 19.7811s	
6403/30300 (epoch 10.566), train_loss = 1.44068935, grad/param norm = 1.4018e-01, time/batch = 19.4635s	
6404/30300 (epoch 10.568), train_loss = 1.24515141, grad/param norm = 1.4556e-01, time/batch = 19.0372s	
6405/30300 (epoch 10.569), train_loss = 1.45538278, grad/param norm = 1.4744e-01, time/batch = 18.8814s	
6406/30300 (epoch 10.571), train_loss = 1.48768718, grad/param norm = 1.5741e-01, time/batch = 19.0537s	
6407/30300 (epoch 10.573), train_loss = 1.49819187, grad/param norm = 1.5285e-01, time/batch = 19.2011s	
6408/30300 (epoch 10.574), train_loss = 1.51887046, grad/param norm = 1.5143e-01, time/batch = 18.6898s	
6409/30300 (epoch 10.576), train_loss = 1.43110010, grad/param norm = 1.4561e-01, time/batch = 19.3656s	
6410/30300 (epoch 10.578), train_loss = 1.35022525, grad/param norm = 1.4517e-01, time/batch = 18.8778s	
6411/30300 (epoch 10.579), train_loss = 1.50676584, grad/param norm = 1.6743e-01, time/batch = 18.3455s	
6412/30300 (epoch 10.581), train_loss = 1.54238024, grad/param norm = 1.4316e-01, time/batch = 19.4582s	
6413/30300 (epoch 10.583), train_loss = 1.63820820, grad/param norm = 1.6732e-01, time/batch = 19.5417s	
6414/30300 (epoch 10.584), train_loss = 1.54197920, grad/param norm = 1.4799e-01, time/batch = 16.1077s	
6415/30300 (epoch 10.586), train_loss = 1.50456832, grad/param norm = 1.5545e-01, time/batch = 16.7812s	
6416/30300 (epoch 10.587), train_loss = 1.49657727, grad/param norm = 1.6008e-01, time/batch = 16.0154s	
6417/30300 (epoch 10.589), train_loss = 1.30694507, grad/param norm = 1.3956e-01, time/batch = 18.5285s	
6418/30300 (epoch 10.591), train_loss = 1.48352391, grad/param norm = 1.4913e-01, time/batch = 17.3067s	
6419/30300 (epoch 10.592), train_loss = 1.45110925, grad/param norm = 1.4129e-01, time/batch = 18.2089s	
6420/30300 (epoch 10.594), train_loss = 1.48715314, grad/param norm = 1.5976e-01, time/batch = 18.1476s	
6421/30300 (epoch 10.596), train_loss = 1.33090832, grad/param norm = 1.3494e-01, time/batch = 18.3471s	
6422/30300 (epoch 10.597), train_loss = 1.41225135, grad/param norm = 1.5448e-01, time/batch = 19.5335s	
6423/30300 (epoch 10.599), train_loss = 1.24256518, grad/param norm = 1.4694e-01, time/batch = 18.5389s	
6424/30300 (epoch 10.601), train_loss = 1.50594467, grad/param norm = 1.5367e-01, time/batch = 17.7044s	
6425/30300 (epoch 10.602), train_loss = 1.45266997, grad/param norm = 1.3978e-01, time/batch = 19.7904s	
6426/30300 (epoch 10.604), train_loss = 1.35633425, grad/param norm = 1.3675e-01, time/batch = 19.6351s	
6427/30300 (epoch 10.606), train_loss = 1.51689033, grad/param norm = 1.6026e-01, time/batch = 17.0611s	
6428/30300 (epoch 10.607), train_loss = 1.51194225, grad/param norm = 1.6059e-01, time/batch = 18.7109s	
6429/30300 (epoch 10.609), train_loss = 1.67729566, grad/param norm = 1.6835e-01, time/batch = 18.0355s	
6430/30300 (epoch 10.611), train_loss = 1.37295839, grad/param norm = 1.4890e-01, time/batch = 17.8695s	
6431/30300 (epoch 10.612), train_loss = 1.38808573, grad/param norm = 1.5508e-01, time/batch = 17.8554s	
6432/30300 (epoch 10.614), train_loss = 1.33845543, grad/param norm = 1.4684e-01, time/batch = 20.1280s	
6433/30300 (epoch 10.616), train_loss = 1.52913301, grad/param norm = 1.5709e-01, time/batch = 17.6286s	
6434/30300 (epoch 10.617), train_loss = 1.40350317, grad/param norm = 1.4610e-01, time/batch = 17.9382s	
6435/30300 (epoch 10.619), train_loss = 1.25237062, grad/param norm = 1.3604e-01, time/batch = 18.7896s	
6436/30300 (epoch 10.620), train_loss = 1.49473850, grad/param norm = 1.5565e-01, time/batch = 19.7132s	
6437/30300 (epoch 10.622), train_loss = 1.47440802, grad/param norm = 1.6767e-01, time/batch = 17.5400s	
6438/30300 (epoch 10.624), train_loss = 1.38699281, grad/param norm = 1.6778e-01, time/batch = 19.4672s	
6439/30300 (epoch 10.625), train_loss = 1.41502017, grad/param norm = 1.6093e-01, time/batch = 18.4768s	
6440/30300 (epoch 10.627), train_loss = 1.62816499, grad/param norm = 1.7293e-01, time/batch = 17.8669s	
6441/30300 (epoch 10.629), train_loss = 1.52811563, grad/param norm = 1.5107e-01, time/batch = 18.6339s	
6442/30300 (epoch 10.630), train_loss = 1.46443099, grad/param norm = 1.4436e-01, time/batch = 19.8772s	
6443/30300 (epoch 10.632), train_loss = 1.56681981, grad/param norm = 1.6297e-01, time/batch = 17.9619s	
6444/30300 (epoch 10.634), train_loss = 1.29914009, grad/param norm = 1.3504e-01, time/batch = 18.7729s	
6445/30300 (epoch 10.635), train_loss = 1.51836123, grad/param norm = 1.4761e-01, time/batch = 18.8779s	
6446/30300 (epoch 10.637), train_loss = 1.51116901, grad/param norm = 1.5676e-01, time/batch = 18.5442s	
6447/30300 (epoch 10.639), train_loss = 1.36607570, grad/param norm = 1.5496e-01, time/batch = 17.5918s	
6448/30300 (epoch 10.640), train_loss = 1.57505378, grad/param norm = 1.6160e-01, time/batch = 17.3702s	
6449/30300 (epoch 10.642), train_loss = 1.39945072, grad/param norm = 1.4401e-01, time/batch = 20.1298s	
6450/30300 (epoch 10.644), train_loss = 1.53726711, grad/param norm = 1.5388e-01, time/batch = 19.0240s	
6451/30300 (epoch 10.645), train_loss = 1.33009323, grad/param norm = 1.3788e-01, time/batch = 19.2044s	
6452/30300 (epoch 10.647), train_loss = 1.42539754, grad/param norm = 1.4382e-01, time/batch = 19.6386s	
6453/30300 (epoch 10.649), train_loss = 1.40519555, grad/param norm = 1.4905e-01, time/batch = 18.4615s	
6454/30300 (epoch 10.650), train_loss = 1.44141334, grad/param norm = 1.5165e-01, time/batch = 19.0565s	
6455/30300 (epoch 10.652), train_loss = 1.37555480, grad/param norm = 1.4721e-01, time/batch = 18.9746s	
6456/30300 (epoch 10.653), train_loss = 1.61918592, grad/param norm = 1.5035e-01, time/batch = 18.3704s	
6457/30300 (epoch 10.655), train_loss = 1.38868071, grad/param norm = 1.5392e-01, time/batch = 19.2891s	
6458/30300 (epoch 10.657), train_loss = 1.45390613, grad/param norm = 1.5079e-01, time/batch = 18.6304s	
6459/30300 (epoch 10.658), train_loss = 1.40701046, grad/param norm = 1.5217e-01, time/batch = 26.9834s	
6460/30300 (epoch 10.660), train_loss = 1.52561926, grad/param norm = 1.5497e-01, time/batch = 24.0813s	
6461/30300 (epoch 10.662), train_loss = 1.53356902, grad/param norm = 1.6563e-01, time/batch = 19.2915s	
6462/30300 (epoch 10.663), train_loss = 1.46671999, grad/param norm = 1.5123e-01, time/batch = 18.2775s	
6463/30300 (epoch 10.665), train_loss = 1.35186724, grad/param norm = 1.5537e-01, time/batch = 19.1287s	
6464/30300 (epoch 10.667), train_loss = 1.55936685, grad/param norm = 1.5087e-01, time/batch = 19.7887s	
6465/30300 (epoch 10.668), train_loss = 1.64126905, grad/param norm = 1.7638e-01, time/batch = 17.2549s	
6466/30300 (epoch 10.670), train_loss = 1.60156757, grad/param norm = 1.5950e-01, time/batch = 16.8737s	
6467/30300 (epoch 10.672), train_loss = 1.54233028, grad/param norm = 1.5739e-01, time/batch = 19.7868s	
6468/30300 (epoch 10.673), train_loss = 1.55874744, grad/param norm = 1.5771e-01, time/batch = 17.8651s	
6469/30300 (epoch 10.675), train_loss = 1.38823551, grad/param norm = 1.5360e-01, time/batch = 18.9436s	
6470/30300 (epoch 10.677), train_loss = 1.34710839, grad/param norm = 1.3501e-01, time/batch = 19.2129s	
6471/30300 (epoch 10.678), train_loss = 1.39728037, grad/param norm = 1.4060e-01, time/batch = 18.5354s	
6472/30300 (epoch 10.680), train_loss = 1.21192124, grad/param norm = 1.3739e-01, time/batch = 19.5465s	
6473/30300 (epoch 10.682), train_loss = 1.43871278, grad/param norm = 1.5135e-01, time/batch = 19.7016s	
6474/30300 (epoch 10.683), train_loss = 1.48996353, grad/param norm = 1.4841e-01, time/batch = 17.9586s	
6475/30300 (epoch 10.685), train_loss = 1.61449229, grad/param norm = 1.7570e-01, time/batch = 19.0294s	
6476/30300 (epoch 10.686), train_loss = 1.45067025, grad/param norm = 1.5126e-01, time/batch = 19.7050s	
6477/30300 (epoch 10.688), train_loss = 1.46648877, grad/param norm = 1.4699e-01, time/batch = 19.3786s	
6478/30300 (epoch 10.690), train_loss = 1.40475989, grad/param norm = 1.5735e-01, time/batch = 18.6931s	
6479/30300 (epoch 10.691), train_loss = 1.45131667, grad/param norm = 1.4365e-01, time/batch = 19.7754s	
6480/30300 (epoch 10.693), train_loss = 1.86134014, grad/param norm = 1.7099e-01, time/batch = 18.5379s	
6481/30300 (epoch 10.695), train_loss = 1.63681404, grad/param norm = 1.7541e-01, time/batch = 19.2819s	
6482/30300 (epoch 10.696), train_loss = 1.63248561, grad/param norm = 1.7584e-01, time/batch = 18.8771s	
6483/30300 (epoch 10.698), train_loss = 1.41196274, grad/param norm = 1.4855e-01, time/batch = 18.1395s	
6484/30300 (epoch 10.700), train_loss = 1.42237908, grad/param norm = 1.5593e-01, time/batch = 17.0164s	
6485/30300 (epoch 10.701), train_loss = 1.26942944, grad/param norm = 1.3588e-01, time/batch = 19.7966s	
6486/30300 (epoch 10.703), train_loss = 1.46135580, grad/param norm = 1.4416e-01, time/batch = 17.3815s	
6487/30300 (epoch 10.705), train_loss = 1.44275337, grad/param norm = 1.5575e-01, time/batch = 17.8787s	
6488/30300 (epoch 10.706), train_loss = 1.48973996, grad/param norm = 1.5237e-01, time/batch = 19.6251s	
6489/30300 (epoch 10.708), train_loss = 1.40741722, grad/param norm = 1.4840e-01, time/batch = 20.4456s	
6490/30300 (epoch 10.710), train_loss = 1.42007571, grad/param norm = 1.5202e-01, time/batch = 18.3709s	
6491/30300 (epoch 10.711), train_loss = 1.33456485, grad/param norm = 1.4651e-01, time/batch = 19.1186s	
6492/30300 (epoch 10.713), train_loss = 1.31978115, grad/param norm = 1.3833e-01, time/batch = 20.2810s	
6493/30300 (epoch 10.715), train_loss = 1.42743723, grad/param norm = 1.5673e-01, time/batch = 17.9591s	
6494/30300 (epoch 10.716), train_loss = 1.61025678, grad/param norm = 1.5783e-01, time/batch = 18.1976s	
6495/30300 (epoch 10.718), train_loss = 1.55422637, grad/param norm = 1.6355e-01, time/batch = 18.0164s	
6496/30300 (epoch 10.719), train_loss = 1.43602889, grad/param norm = 1.5957e-01, time/batch = 18.0409s	
6497/30300 (epoch 10.721), train_loss = 1.43566292, grad/param norm = 1.5757e-01, time/batch = 19.1109s	
6498/30300 (epoch 10.723), train_loss = 1.42054515, grad/param norm = 1.5562e-01, time/batch = 19.1200s	
6499/30300 (epoch 10.724), train_loss = 1.54697232, grad/param norm = 1.5577e-01, time/batch = 19.6250s	
6500/30300 (epoch 10.726), train_loss = 1.88578036, grad/param norm = 1.8259e-01, time/batch = 17.4274s	
6501/30300 (epoch 10.728), train_loss = 1.47605722, grad/param norm = 1.4874e-01, time/batch = 20.0416s	
6502/30300 (epoch 10.729), train_loss = 1.46842429, grad/param norm = 1.5385e-01, time/batch = 19.2916s	
6503/30300 (epoch 10.731), train_loss = 1.54796618, grad/param norm = 1.5588e-01, time/batch = 18.4329s	
6504/30300 (epoch 10.733), train_loss = 1.45133987, grad/param norm = 1.5019e-01, time/batch = 17.9441s	
6505/30300 (epoch 10.734), train_loss = 1.51917197, grad/param norm = 1.4708e-01, time/batch = 18.8479s	
6506/30300 (epoch 10.736), train_loss = 1.42090848, grad/param norm = 1.4040e-01, time/batch = 17.7080s	
6507/30300 (epoch 10.738), train_loss = 1.29513262, grad/param norm = 1.3981e-01, time/batch = 19.2915s	
6508/30300 (epoch 10.739), train_loss = 1.52478669, grad/param norm = 1.4911e-01, time/batch = 18.7049s	
6509/30300 (epoch 10.741), train_loss = 1.56167453, grad/param norm = 1.4679e-01, time/batch = 18.1243s	
6510/30300 (epoch 10.743), train_loss = 1.38442101, grad/param norm = 1.4747e-01, time/batch = 18.7914s	
6511/30300 (epoch 10.744), train_loss = 1.53862836, grad/param norm = 1.5786e-01, time/batch = 19.6265s	
6512/30300 (epoch 10.746), train_loss = 1.30559402, grad/param norm = 1.4110e-01, time/batch = 18.1221s	
6513/30300 (epoch 10.748), train_loss = 1.46011812, grad/param norm = 1.7080e-01, time/batch = 19.3795s	
6514/30300 (epoch 10.749), train_loss = 1.49778632, grad/param norm = 1.6227e-01, time/batch = 18.7940s	
6515/30300 (epoch 10.751), train_loss = 1.36248980, grad/param norm = 1.4766e-01, time/batch = 18.4562s	
6516/30300 (epoch 10.752), train_loss = 1.39607402, grad/param norm = 1.4696e-01, time/batch = 19.4480s	
6517/30300 (epoch 10.754), train_loss = 1.32262308, grad/param norm = 1.3385e-01, time/batch = 17.6008s	
6518/30300 (epoch 10.756), train_loss = 1.39722461, grad/param norm = 1.5570e-01, time/batch = 18.9443s	
6519/30300 (epoch 10.757), train_loss = 1.49537367, grad/param norm = 1.5864e-01, time/batch = 18.1146s	
6520/30300 (epoch 10.759), train_loss = 1.39035178, grad/param norm = 1.3617e-01, time/batch = 18.9579s	
6521/30300 (epoch 10.761), train_loss = 1.31843111, grad/param norm = 1.4017e-01, time/batch = 20.2954s	
6522/30300 (epoch 10.762), train_loss = 1.23748020, grad/param norm = 1.3674e-01, time/batch = 17.8732s	
6523/30300 (epoch 10.764), train_loss = 1.40772555, grad/param norm = 1.3929e-01, time/batch = 18.5464s	
6524/30300 (epoch 10.766), train_loss = 1.48068079, grad/param norm = 1.4858e-01, time/batch = 19.7815s	
6525/30300 (epoch 10.767), train_loss = 1.57148652, grad/param norm = 1.7238e-01, time/batch = 16.8608s	
6526/30300 (epoch 10.769), train_loss = 1.53074033, grad/param norm = 1.5797e-01, time/batch = 18.4434s	
6527/30300 (epoch 10.771), train_loss = 1.44054525, grad/param norm = 1.5117e-01, time/batch = 20.1756s	
6528/30300 (epoch 10.772), train_loss = 1.46562836, grad/param norm = 1.5466e-01, time/batch = 15.1307s	
6529/30300 (epoch 10.774), train_loss = 1.59849099, grad/param norm = 1.5017e-01, time/batch = 19.0296s	
6530/30300 (epoch 10.776), train_loss = 1.48865363, grad/param norm = 1.6251e-01, time/batch = 18.9385s	
6531/30300 (epoch 10.777), train_loss = 1.47133959, grad/param norm = 1.4051e-01, time/batch = 19.0392s	
6532/30300 (epoch 10.779), train_loss = 1.61691148, grad/param norm = 1.6811e-01, time/batch = 17.7694s	
6533/30300 (epoch 10.781), train_loss = 1.48683384, grad/param norm = 1.6650e-01, time/batch = 19.7129s	
6534/30300 (epoch 10.782), train_loss = 1.39738675, grad/param norm = 1.5266e-01, time/batch = 18.3576s	
6535/30300 (epoch 10.784), train_loss = 1.41258949, grad/param norm = 1.5115e-01, time/batch = 17.8009s	
6536/30300 (epoch 10.785), train_loss = 1.61939380, grad/param norm = 1.6576e-01, time/batch = 19.4697s	
6537/30300 (epoch 10.787), train_loss = 1.30655806, grad/param norm = 1.5823e-01, time/batch = 19.0539s	
6538/30300 (epoch 10.789), train_loss = 1.75731118, grad/param norm = 1.5805e-01, time/batch = 17.8593s	
6539/30300 (epoch 10.790), train_loss = 1.56055229, grad/param norm = 1.7347e-01, time/batch = 19.4527s	
6540/30300 (epoch 10.792), train_loss = 1.33771940, grad/param norm = 1.6147e-01, time/batch = 19.7053s	
6541/30300 (epoch 10.794), train_loss = 1.39067411, grad/param norm = 1.5809e-01, time/batch = 18.3697s	
6542/30300 (epoch 10.795), train_loss = 1.43192050, grad/param norm = 1.4572e-01, time/batch = 18.3397s	
6543/30300 (epoch 10.797), train_loss = 1.64843085, grad/param norm = 1.7158e-01, time/batch = 20.1217s	
6544/30300 (epoch 10.799), train_loss = 1.52179963, grad/param norm = 1.6448e-01, time/batch = 18.2135s	
6545/30300 (epoch 10.800), train_loss = 1.50636719, grad/param norm = 1.5931e-01, time/batch = 20.1092s	
6546/30300 (epoch 10.802), train_loss = 1.69716763, grad/param norm = 1.7761e-01, time/batch = 18.6148s	
6547/30300 (epoch 10.804), train_loss = 1.54539514, grad/param norm = 1.5629e-01, time/batch = 19.1203s	
6548/30300 (epoch 10.805), train_loss = 1.64205346, grad/param norm = 1.7472e-01, time/batch = 19.0407s	
6549/30300 (epoch 10.807), train_loss = 1.49960498, grad/param norm = 1.6764e-01, time/batch = 19.9609s	
6550/30300 (epoch 10.809), train_loss = 1.57516592, grad/param norm = 1.7287e-01, time/batch = 18.7052s	
6551/30300 (epoch 10.810), train_loss = 1.55007066, grad/param norm = 1.5185e-01, time/batch = 18.2831s	
6552/30300 (epoch 10.812), train_loss = 1.35214285, grad/param norm = 1.5158e-01, time/batch = 19.9524s	
6553/30300 (epoch 10.814), train_loss = 1.48134470, grad/param norm = 1.4822e-01, time/batch = 19.6264s	
6554/30300 (epoch 10.815), train_loss = 1.51446317, grad/param norm = 1.6784e-01, time/batch = 17.4382s	
6555/30300 (epoch 10.817), train_loss = 1.58949215, grad/param norm = 1.7026e-01, time/batch = 16.5137s	
6556/30300 (epoch 10.818), train_loss = 1.50621117, grad/param norm = 1.4882e-01, time/batch = 18.7052s	
6557/30300 (epoch 10.820), train_loss = 1.70908482, grad/param norm = 1.7076e-01, time/batch = 16.5215s	
6558/30300 (epoch 10.822), train_loss = 1.70894651, grad/param norm = 1.8575e-01, time/batch = 17.9541s	
6559/30300 (epoch 10.823), train_loss = 1.73626787, grad/param norm = 1.8118e-01, time/batch = 18.3621s	
6560/30300 (epoch 10.825), train_loss = 1.57901809, grad/param norm = 1.6230e-01, time/batch = 17.6255s	
6561/30300 (epoch 10.827), train_loss = 1.36700045, grad/param norm = 1.6664e-01, time/batch = 19.1199s	
6562/30300 (epoch 10.828), train_loss = 1.53205042, grad/param norm = 1.5591e-01, time/batch = 18.4672s	
6563/30300 (epoch 10.830), train_loss = 1.51086920, grad/param norm = 1.5796e-01, time/batch = 18.6239s	
6564/30300 (epoch 10.832), train_loss = 1.42021284, grad/param norm = 1.5345e-01, time/batch = 18.2037s	
6565/30300 (epoch 10.833), train_loss = 1.54228490, grad/param norm = 1.5883e-01, time/batch = 19.2200s	
6566/30300 (epoch 10.835), train_loss = 1.44786549, grad/param norm = 1.5409e-01, time/batch = 19.0365s	
6567/30300 (epoch 10.837), train_loss = 1.28688841, grad/param norm = 1.3555e-01, time/batch = 17.5439s	
6568/30300 (epoch 10.838), train_loss = 1.34523612, grad/param norm = 1.5180e-01, time/batch = 19.4609s	
6569/30300 (epoch 10.840), train_loss = 1.50104210, grad/param norm = 1.4219e-01, time/batch = 18.6219s	
6570/30300 (epoch 10.842), train_loss = 1.30226588, grad/param norm = 1.3184e-01, time/batch = 17.2950s	
6571/30300 (epoch 10.843), train_loss = 1.46175775, grad/param norm = 1.4068e-01, time/batch = 18.4380s	
6572/30300 (epoch 10.845), train_loss = 1.42009439, grad/param norm = 1.3231e-01, time/batch = 18.9639s	
6573/30300 (epoch 10.847), train_loss = 1.51431269, grad/param norm = 1.7381e-01, time/batch = 18.7809s	
6574/30300 (epoch 10.848), train_loss = 1.59081084, grad/param norm = 1.5840e-01, time/batch = 18.5447s	
6575/30300 (epoch 10.850), train_loss = 1.40433430, grad/param norm = 1.4091e-01, time/batch = 17.8845s	
6576/30300 (epoch 10.851), train_loss = 1.61660825, grad/param norm = 1.6998e-01, time/batch = 18.3787s	
6577/30300 (epoch 10.853), train_loss = 1.38351786, grad/param norm = 1.4540e-01, time/batch = 18.7829s	
6578/30300 (epoch 10.855), train_loss = 1.40379961, grad/param norm = 1.4132e-01, time/batch = 19.1229s	
6579/30300 (epoch 10.856), train_loss = 1.39537443, grad/param norm = 1.4955e-01, time/batch = 17.7217s	
6580/30300 (epoch 10.858), train_loss = 1.37118288, grad/param norm = 1.3650e-01, time/batch = 18.5975s	
6581/30300 (epoch 10.860), train_loss = 1.42299183, grad/param norm = 1.4764e-01, time/batch = 20.0234s	
6582/30300 (epoch 10.861), train_loss = 1.63404826, grad/param norm = 1.5339e-01, time/batch = 18.3791s	
6583/30300 (epoch 10.863), train_loss = 1.46702273, grad/param norm = 1.4046e-01, time/batch = 18.4500s	
6584/30300 (epoch 10.865), train_loss = 1.64318548, grad/param norm = 1.5784e-01, time/batch = 16.7750s	
6585/30300 (epoch 10.866), train_loss = 1.52482195, grad/param norm = 2.0905e-01, time/batch = 15.4381s	
6586/30300 (epoch 10.868), train_loss = 1.47164562, grad/param norm = 1.4600e-01, time/batch = 16.5293s	
6587/30300 (epoch 10.870), train_loss = 1.43358336, grad/param norm = 1.4488e-01, time/batch = 18.4482s	
6588/30300 (epoch 10.871), train_loss = 1.39890274, grad/param norm = 1.3813e-01, time/batch = 18.7913s	
6589/30300 (epoch 10.873), train_loss = 1.48082625, grad/param norm = 1.4622e-01, time/batch = 19.4323s	
6590/30300 (epoch 10.875), train_loss = 1.31175666, grad/param norm = 1.3788e-01, time/batch = 18.0180s	
6591/30300 (epoch 10.876), train_loss = 1.34820614, grad/param norm = 1.4246e-01, time/batch = 18.9945s	
6592/30300 (epoch 10.878), train_loss = 1.22293957, grad/param norm = 1.5600e-01, time/batch = 19.8682s	
6593/30300 (epoch 10.880), train_loss = 1.34271173, grad/param norm = 1.4323e-01, time/batch = 17.8664s	
6594/30300 (epoch 10.881), train_loss = 1.71575879, grad/param norm = 1.6983e-01, time/batch = 19.3528s	
6595/30300 (epoch 10.883), train_loss = 1.52320965, grad/param norm = 1.5337e-01, time/batch = 19.5422s	
6596/30300 (epoch 10.884), train_loss = 1.29181458, grad/param norm = 1.3301e-01, time/batch = 18.2083s	
6597/30300 (epoch 10.886), train_loss = 1.47033814, grad/param norm = 1.5469e-01, time/batch = 19.6186s	
6598/30300 (epoch 10.888), train_loss = 1.50254206, grad/param norm = 1.5887e-01, time/batch = 18.7884s	
6599/30300 (epoch 10.889), train_loss = 1.41909219, grad/param norm = 1.4847e-01, time/batch = 18.7016s	
6600/30300 (epoch 10.891), train_loss = 1.42579716, grad/param norm = 1.4645e-01, time/batch = 18.1207s	
6601/30300 (epoch 10.893), train_loss = 1.72749037, grad/param norm = 1.6448e-01, time/batch = 18.7245s	
6602/30300 (epoch 10.894), train_loss = 1.57632899, grad/param norm = 1.5226e-01, time/batch = 17.2717s	
6603/30300 (epoch 10.896), train_loss = 1.27089013, grad/param norm = 1.4277e-01, time/batch = 15.6023s	
6604/30300 (epoch 10.898), train_loss = 1.23440203, grad/param norm = 1.4768e-01, time/batch = 16.3683s	
6605/30300 (epoch 10.899), train_loss = 1.39532948, grad/param norm = 1.4357e-01, time/batch = 19.3809s	
6606/30300 (epoch 10.901), train_loss = 1.46185853, grad/param norm = 1.6622e-01, time/batch = 17.8794s	
6607/30300 (epoch 10.903), train_loss = 1.51106238, grad/param norm = 1.5927e-01, time/batch = 17.6221s	
6608/30300 (epoch 10.904), train_loss = 1.38605364, grad/param norm = 1.4214e-01, time/batch = 19.2870s	
6609/30300 (epoch 10.906), train_loss = 1.62671953, grad/param norm = 1.5883e-01, time/batch = 18.0317s	
6610/30300 (epoch 10.908), train_loss = 1.32906289, grad/param norm = 1.4152e-01, time/batch = 19.5312s	
6611/30300 (epoch 10.909), train_loss = 1.41517521, grad/param norm = 1.6863e-01, time/batch = 18.6187s	
6612/30300 (epoch 10.911), train_loss = 1.44634472, grad/param norm = 1.5568e-01, time/batch = 19.0522s	
6613/30300 (epoch 10.913), train_loss = 1.45189835, grad/param norm = 1.4616e-01, time/batch = 19.0557s	
6614/30300 (epoch 10.914), train_loss = 1.44795482, grad/param norm = 1.6034e-01, time/batch = 19.3022s	
6615/30300 (epoch 10.916), train_loss = 1.47384181, grad/param norm = 1.4878e-01, time/batch = 18.5899s	
6616/30300 (epoch 10.917), train_loss = 1.36337576, grad/param norm = 1.4419e-01, time/batch = 18.7980s	
6617/30300 (epoch 10.919), train_loss = 1.43884855, grad/param norm = 1.5314e-01, time/batch = 19.8017s	
6618/30300 (epoch 10.921), train_loss = 1.47712194, grad/param norm = 1.5215e-01, time/batch = 18.8087s	
6619/30300 (epoch 10.922), train_loss = 1.54899522, grad/param norm = 1.6480e-01, time/batch = 17.8682s	
6620/30300 (epoch 10.924), train_loss = 1.45784438, grad/param norm = 1.5456e-01, time/batch = 20.0414s	
6621/30300 (epoch 10.926), train_loss = 1.42909881, grad/param norm = 1.5275e-01, time/batch = 19.5544s	
6622/30300 (epoch 10.927), train_loss = 1.45878428, grad/param norm = 1.6027e-01, time/batch = 18.7131s	
6623/30300 (epoch 10.929), train_loss = 1.43000444, grad/param norm = 1.6849e-01, time/batch = 19.8031s	
6624/30300 (epoch 10.931), train_loss = 1.61716708, grad/param norm = 1.8102e-01, time/batch = 17.4367s	
6625/30300 (epoch 10.932), train_loss = 1.39394422, grad/param norm = 1.6903e-01, time/batch = 17.6150s	
6626/30300 (epoch 10.934), train_loss = 1.46791433, grad/param norm = 1.4621e-01, time/batch = 19.3804s	
6627/30300 (epoch 10.936), train_loss = 1.41571962, grad/param norm = 1.4324e-01, time/batch = 19.7113s	
6628/30300 (epoch 10.937), train_loss = 1.41987309, grad/param norm = 1.5287e-01, time/batch = 17.7177s	
6629/30300 (epoch 10.939), train_loss = 1.56951337, grad/param norm = 1.5600e-01, time/batch = 19.0278s	
6630/30300 (epoch 10.941), train_loss = 1.45028509, grad/param norm = 1.5509e-01, time/batch = 18.7907s	
6631/30300 (epoch 10.942), train_loss = 1.45906521, grad/param norm = 1.6414e-01, time/batch = 18.6281s	
6632/30300 (epoch 10.944), train_loss = 1.34749058, grad/param norm = 1.4536e-01, time/batch = 18.3029s	
6633/30300 (epoch 10.946), train_loss = 1.62609066, grad/param norm = 1.7318e-01, time/batch = 19.3149s	
6634/30300 (epoch 10.947), train_loss = 1.62547677, grad/param norm = 1.7834e-01, time/batch = 19.5362s	
6635/30300 (epoch 10.949), train_loss = 1.67956226, grad/param norm = 1.6826e-01, time/batch = 19.4333s	
6636/30300 (epoch 10.950), train_loss = 1.59434982, grad/param norm = 1.5970e-01, time/batch = 19.1959s	
6637/30300 (epoch 10.952), train_loss = 1.56039297, grad/param norm = 1.5879e-01, time/batch = 19.6243s	
6638/30300 (epoch 10.954), train_loss = 1.74022875, grad/param norm = 1.6222e-01, time/batch = 18.2161s	
6639/30300 (epoch 10.955), train_loss = 1.39958097, grad/param norm = 1.4465e-01, time/batch = 19.0316s	
6640/30300 (epoch 10.957), train_loss = 1.53142441, grad/param norm = 1.5445e-01, time/batch = 19.7623s	
6641/30300 (epoch 10.959), train_loss = 1.49471783, grad/param norm = 1.5984e-01, time/batch = 18.7723s	
6642/30300 (epoch 10.960), train_loss = 1.42901279, grad/param norm = 1.5444e-01, time/batch = 19.0475s	
6643/30300 (epoch 10.962), train_loss = 1.40489854, grad/param norm = 1.5820e-01, time/batch = 19.5371s	
6644/30300 (epoch 10.964), train_loss = 1.47153508, grad/param norm = 1.6780e-01, time/batch = 18.0424s	
6645/30300 (epoch 10.965), train_loss = 1.38784904, grad/param norm = 1.5588e-01, time/batch = 20.0293s	
6646/30300 (epoch 10.967), train_loss = 1.43933185, grad/param norm = 1.5554e-01, time/batch = 19.2195s	
6647/30300 (epoch 10.969), train_loss = 1.42536328, grad/param norm = 1.6206e-01, time/batch = 18.5276s	
6648/30300 (epoch 10.970), train_loss = 1.38932496, grad/param norm = 1.5022e-01, time/batch = 18.6381s	
6649/30300 (epoch 10.972), train_loss = 1.33409888, grad/param norm = 1.4778e-01, time/batch = 18.6149s	
6650/30300 (epoch 10.974), train_loss = 1.65628914, grad/param norm = 1.6801e-01, time/batch = 26.0928s	
6651/30300 (epoch 10.975), train_loss = 1.66154693, grad/param norm = 1.9469e-01, time/batch = 23.4855s	
6652/30300 (epoch 10.977), train_loss = 1.54384516, grad/param norm = 1.6501e-01, time/batch = 18.7165s	
6653/30300 (epoch 10.979), train_loss = 1.50285100, grad/param norm = 1.5185e-01, time/batch = 17.4321s	
6654/30300 (epoch 10.980), train_loss = 1.55398730, grad/param norm = 1.6810e-01, time/batch = 18.6329s	
6655/30300 (epoch 10.982), train_loss = 1.57531570, grad/param norm = 1.6165e-01, time/batch = 18.5463s	
6656/30300 (epoch 10.983), train_loss = 1.59945570, grad/param norm = 1.5389e-01, time/batch = 18.1117s	
6657/30300 (epoch 10.985), train_loss = 1.48493530, grad/param norm = 1.6075e-01, time/batch = 19.5325s	
6658/30300 (epoch 10.987), train_loss = 1.42977414, grad/param norm = 1.3787e-01, time/batch = 19.4673s	
6659/30300 (epoch 10.988), train_loss = 1.63514502, grad/param norm = 1.5889e-01, time/batch = 18.4533s	
6660/30300 (epoch 10.990), train_loss = 1.28333101, grad/param norm = 1.4250e-01, time/batch = 18.9578s	
6661/30300 (epoch 10.992), train_loss = 1.51515064, grad/param norm = 1.4014e-01, time/batch = 18.7763s	
6662/30300 (epoch 10.993), train_loss = 1.61243824, grad/param norm = 1.7679e-01, time/batch = 17.9586s	
6663/30300 (epoch 10.995), train_loss = 1.49958581, grad/param norm = 1.5800e-01, time/batch = 18.6967s	
6664/30300 (epoch 10.997), train_loss = 1.50382186, grad/param norm = 1.5248e-01, time/batch = 18.9778s	
6665/30300 (epoch 10.998), train_loss = 1.57997172, grad/param norm = 1.6578e-01, time/batch = 19.0308s	
decayed learning rate by a factor 0.97 to 0.0018818	
6666/30300 (epoch 11.000), train_loss = 1.38826518, grad/param norm = 1.5654e-01, time/batch = 19.2974s	
6667/30300 (epoch 11.002), train_loss = 1.51629877, grad/param norm = 1.5659e-01, time/batch = 19.1199s	
6668/30300 (epoch 11.003), train_loss = 1.48016026, grad/param norm = 1.4710e-01, time/batch = 19.2845s	
6669/30300 (epoch 11.005), train_loss = 1.45608535, grad/param norm = 1.6951e-01, time/batch = 19.0331s	
6670/30300 (epoch 11.007), train_loss = 1.58261373, grad/param norm = 1.6762e-01, time/batch = 19.4775s	
6671/30300 (epoch 11.008), train_loss = 1.40613047, grad/param norm = 1.5186e-01, time/batch = 18.2904s	
6672/30300 (epoch 11.010), train_loss = 1.36472047, grad/param norm = 1.4737e-01, time/batch = 18.6238s	
6673/30300 (epoch 11.012), train_loss = 1.36906310, grad/param norm = 1.4294e-01, time/batch = 18.8016s	
6674/30300 (epoch 11.013), train_loss = 1.51264087, grad/param norm = 1.6623e-01, time/batch = 18.4455s	
6675/30300 (epoch 11.015), train_loss = 1.43917982, grad/param norm = 1.4551e-01, time/batch = 17.6243s	
6676/30300 (epoch 11.017), train_loss = 1.35140998, grad/param norm = 1.4125e-01, time/batch = 19.4617s	
6677/30300 (epoch 11.018), train_loss = 1.41545402, grad/param norm = 1.4755e-01, time/batch = 18.5402s	
6678/30300 (epoch 11.020), train_loss = 1.59504311, grad/param norm = 1.6420e-01, time/batch = 18.1093s	
6679/30300 (epoch 11.021), train_loss = 1.57024638, grad/param norm = 1.5714e-01, time/batch = 19.4520s	
6680/30300 (epoch 11.023), train_loss = 1.39187940, grad/param norm = 1.4219e-01, time/batch = 19.8738s	
6681/30300 (epoch 11.025), train_loss = 1.38691535, grad/param norm = 1.6176e-01, time/batch = 18.3699s	
6682/30300 (epoch 11.026), train_loss = 1.51898832, grad/param norm = 1.5827e-01, time/batch = 19.4489s	
6683/30300 (epoch 11.028), train_loss = 1.53159775, grad/param norm = 1.4991e-01, time/batch = 18.3918s	
6684/30300 (epoch 11.030), train_loss = 1.36946645, grad/param norm = 1.4526e-01, time/batch = 18.3720s	
6685/30300 (epoch 11.031), train_loss = 1.45662105, grad/param norm = 1.6343e-01, time/batch = 18.6912s	
6686/30300 (epoch 11.033), train_loss = 1.46903754, grad/param norm = 1.5964e-01, time/batch = 19.5481s	
6687/30300 (epoch 11.035), train_loss = 1.56174606, grad/param norm = 1.5599e-01, time/batch = 17.7205s	
6688/30300 (epoch 11.036), train_loss = 1.50152986, grad/param norm = 1.5804e-01, time/batch = 17.9449s	
6689/30300 (epoch 11.038), train_loss = 1.45634701, grad/param norm = 1.5006e-01, time/batch = 19.3768s	
6690/30300 (epoch 11.040), train_loss = 1.16720159, grad/param norm = 1.3446e-01, time/batch = 19.0652s	
6691/30300 (epoch 11.041), train_loss = 1.22543681, grad/param norm = 1.3727e-01, time/batch = 17.9508s	
6692/30300 (epoch 11.043), train_loss = 1.50962435, grad/param norm = 1.5353e-01, time/batch = 19.8551s	
6693/30300 (epoch 11.045), train_loss = 1.41947055, grad/param norm = 1.5597e-01, time/batch = 17.0130s	
6694/30300 (epoch 11.046), train_loss = 1.54922578, grad/param norm = 1.7079e-01, time/batch = 18.8629s	
6695/30300 (epoch 11.048), train_loss = 1.51201286, grad/param norm = 1.6968e-01, time/batch = 19.0338s	
6696/30300 (epoch 11.050), train_loss = 1.49194061, grad/param norm = 1.5315e-01, time/batch = 20.0359s	
6697/30300 (epoch 11.051), train_loss = 1.48008273, grad/param norm = 1.6662e-01, time/batch = 17.8791s	
6698/30300 (epoch 11.053), train_loss = 1.31112575, grad/param norm = 1.6073e-01, time/batch = 18.7173s	
6699/30300 (epoch 11.054), train_loss = 1.41135822, grad/param norm = 1.5544e-01, time/batch = 17.5283s	
6700/30300 (epoch 11.056), train_loss = 1.35828416, grad/param norm = 1.4900e-01, time/batch = 17.8482s	
6701/30300 (epoch 11.058), train_loss = 1.43124542, grad/param norm = 1.6247e-01, time/batch = 16.3026s	
6702/30300 (epoch 11.059), train_loss = 1.39387988, grad/param norm = 1.5762e-01, time/batch = 17.3566s	
6703/30300 (epoch 11.061), train_loss = 1.61589993, grad/param norm = 1.7686e-01, time/batch = 17.6849s	
6704/30300 (epoch 11.063), train_loss = 1.41540838, grad/param norm = 1.5438e-01, time/batch = 16.5289s	
6705/30300 (epoch 11.064), train_loss = 1.53548739, grad/param norm = 1.5999e-01, time/batch = 16.6984s	
6706/30300 (epoch 11.066), train_loss = 1.42706367, grad/param norm = 1.3935e-01, time/batch = 15.8456s	
6707/30300 (epoch 11.068), train_loss = 1.30055657, grad/param norm = 1.4033e-01, time/batch = 17.1928s	
6708/30300 (epoch 11.069), train_loss = 1.57625505, grad/param norm = 1.5659e-01, time/batch = 17.7657s	
6709/30300 (epoch 11.071), train_loss = 1.49942234, grad/param norm = 1.5548e-01, time/batch = 17.9733s	
6710/30300 (epoch 11.073), train_loss = 1.48518434, grad/param norm = 1.6423e-01, time/batch = 19.6161s	
6711/30300 (epoch 11.074), train_loss = 1.50132670, grad/param norm = 1.4247e-01, time/batch = 18.1893s	
6712/30300 (epoch 11.076), train_loss = 1.42049311, grad/param norm = 1.4946e-01, time/batch = 20.1158s	
6713/30300 (epoch 11.078), train_loss = 1.33685035, grad/param norm = 1.5387e-01, time/batch = 18.7941s	
6714/30300 (epoch 11.079), train_loss = 1.34571998, grad/param norm = 1.3047e-01, time/batch = 17.3544s	
6715/30300 (epoch 11.081), train_loss = 1.48801838, grad/param norm = 1.5596e-01, time/batch = 19.1818s	
6716/30300 (epoch 11.083), train_loss = 1.58713474, grad/param norm = 1.6818e-01, time/batch = 19.5275s	
6717/30300 (epoch 11.084), train_loss = 1.33937853, grad/param norm = 1.5774e-01, time/batch = 18.1101s	
6718/30300 (epoch 11.086), train_loss = 1.38299329, grad/param norm = 1.4857e-01, time/batch = 18.9449s	
6719/30300 (epoch 11.087), train_loss = 1.31283014, grad/param norm = 1.3437e-01, time/batch = 17.9220s	
6720/30300 (epoch 11.089), train_loss = 1.39748140, grad/param norm = 1.5466e-01, time/batch = 18.0445s	
6721/30300 (epoch 11.091), train_loss = 1.53653655, grad/param norm = 1.6569e-01, time/batch = 18.7725s	
6722/30300 (epoch 11.092), train_loss = 1.43591354, grad/param norm = 1.5721e-01, time/batch = 18.5368s	
6723/30300 (epoch 11.094), train_loss = 1.65244070, grad/param norm = 1.6973e-01, time/batch = 19.8632s	
6724/30300 (epoch 11.096), train_loss = 1.54318284, grad/param norm = 1.5584e-01, time/batch = 18.9553s	
6725/30300 (epoch 11.097), train_loss = 1.33659843, grad/param norm = 1.4695e-01, time/batch = 19.2716s	
6726/30300 (epoch 11.099), train_loss = 1.61915559, grad/param norm = 1.5862e-01, time/batch = 17.9602s	
6727/30300 (epoch 11.101), train_loss = 1.68387335, grad/param norm = 1.7883e-01, time/batch = 16.8434s	
6728/30300 (epoch 11.102), train_loss = 1.45033485, grad/param norm = 1.7213e-01, time/batch = 19.9705s	
6729/30300 (epoch 11.104), train_loss = 1.40811520, grad/param norm = 1.6606e-01, time/batch = 19.1326s	
6730/30300 (epoch 11.106), train_loss = 1.48243014, grad/param norm = 1.6109e-01, time/batch = 18.4448s	
6731/30300 (epoch 11.107), train_loss = 1.46818809, grad/param norm = 1.4743e-01, time/batch = 18.9520s	
6732/30300 (epoch 11.109), train_loss = 1.55321084, grad/param norm = 1.6111e-01, time/batch = 20.2031s	
6733/30300 (epoch 11.111), train_loss = 1.59603275, grad/param norm = 1.6374e-01, time/batch = 18.6990s	
6734/30300 (epoch 11.112), train_loss = 1.48997091, grad/param norm = 1.4400e-01, time/batch = 18.6853s	
6735/30300 (epoch 11.114), train_loss = 1.45774526, grad/param norm = 1.5171e-01, time/batch = 20.1363s	
6736/30300 (epoch 11.116), train_loss = 1.49307281, grad/param norm = 1.5640e-01, time/batch = 17.0249s	
6737/30300 (epoch 11.117), train_loss = 1.46972759, grad/param norm = 1.5028e-01, time/batch = 18.5092s	
6738/30300 (epoch 11.119), train_loss = 1.36786198, grad/param norm = 1.5266e-01, time/batch = 18.7017s	
6739/30300 (epoch 11.120), train_loss = 1.45706286, grad/param norm = 1.6437e-01, time/batch = 19.1269s	
6740/30300 (epoch 11.122), train_loss = 1.55101107, grad/param norm = 1.5861e-01, time/batch = 19.4595s	
6741/30300 (epoch 11.124), train_loss = 1.66554682, grad/param norm = 1.7610e-01, time/batch = 19.0277s	
6742/30300 (epoch 11.125), train_loss = 1.29993444, grad/param norm = 1.3694e-01, time/batch = 19.3751s	
6743/30300 (epoch 11.127), train_loss = 1.46076961, grad/param norm = 1.6132e-01, time/batch = 19.3637s	
6744/30300 (epoch 11.129), train_loss = 1.60674309, grad/param norm = 1.5045e-01, time/batch = 17.6984s	
6745/30300 (epoch 11.130), train_loss = 1.61169549, grad/param norm = 1.5179e-01, time/batch = 19.7263s	
6746/30300 (epoch 11.132), train_loss = 1.52022412, grad/param norm = 1.6986e-01, time/batch = 18.1987s	
6747/30300 (epoch 11.134), train_loss = 1.35737224, grad/param norm = 1.5262e-01, time/batch = 19.4680s	
6748/30300 (epoch 11.135), train_loss = 1.40445665, grad/param norm = 1.5823e-01, time/batch = 18.5444s	
6749/30300 (epoch 11.137), train_loss = 1.55556843, grad/param norm = 1.6092e-01, time/batch = 18.7980s	
6750/30300 (epoch 11.139), train_loss = 1.44061996, grad/param norm = 1.5298e-01, time/batch = 18.4610s	
6751/30300 (epoch 11.140), train_loss = 1.62923731, grad/param norm = 1.8141e-01, time/batch = 18.9325s	
6752/30300 (epoch 11.142), train_loss = 1.70115956, grad/param norm = 1.7264e-01, time/batch = 17.0295s	
6753/30300 (epoch 11.144), train_loss = 1.56264792, grad/param norm = 1.9977e-01, time/batch = 19.8735s	
6754/30300 (epoch 11.145), train_loss = 1.65116751, grad/param norm = 2.0871e-01, time/batch = 19.0560s	
6755/30300 (epoch 11.147), train_loss = 1.48375543, grad/param norm = 1.5902e-01, time/batch = 19.2065s	
6756/30300 (epoch 11.149), train_loss = 1.69753772, grad/param norm = 2.2627e-01, time/batch = 19.1188s	
6757/30300 (epoch 11.150), train_loss = 1.58781623, grad/param norm = 1.9668e-01, time/batch = 19.8104s	
6758/30300 (epoch 11.152), train_loss = 1.40558925, grad/param norm = 2.2124e-01, time/batch = 17.9597s	
6759/30300 (epoch 11.153), train_loss = 1.48513581, grad/param norm = 1.6054e-01, time/batch = 18.8531s	
6760/30300 (epoch 11.155), train_loss = 1.26821672, grad/param norm = 1.3655e-01, time/batch = 19.9608s	
6761/30300 (epoch 11.157), train_loss = 1.45753627, grad/param norm = 1.5884e-01, time/batch = 19.2946s	
6762/30300 (epoch 11.158), train_loss = 1.52541781, grad/param norm = 1.5996e-01, time/batch = 18.9559s	
6763/30300 (epoch 11.160), train_loss = 1.39612318, grad/param norm = 1.4923e-01, time/batch = 17.7964s	
6764/30300 (epoch 11.162), train_loss = 1.39959782, grad/param norm = 1.5335e-01, time/batch = 19.5338s	
6765/30300 (epoch 11.163), train_loss = 1.41305082, grad/param norm = 1.6747e-01, time/batch = 18.1338s	
6766/30300 (epoch 11.165), train_loss = 1.53035951, grad/param norm = 1.4834e-01, time/batch = 18.7184s	
6767/30300 (epoch 11.167), train_loss = 1.52276942, grad/param norm = 1.6629e-01, time/batch = 19.4692s	
6768/30300 (epoch 11.168), train_loss = 1.47695896, grad/param norm = 1.4961e-01, time/batch = 16.9697s	
6769/30300 (epoch 11.170), train_loss = 1.50676576, grad/param norm = 1.4911e-01, time/batch = 20.1354s	
6770/30300 (epoch 11.172), train_loss = 1.41705629, grad/param norm = 1.6215e-01, time/batch = 18.8771s	
6771/30300 (epoch 11.173), train_loss = 1.54092878, grad/param norm = 1.7322e-01, time/batch = 18.4589s	
6772/30300 (epoch 11.175), train_loss = 1.46060235, grad/param norm = 1.4432e-01, time/batch = 18.8080s	
6773/30300 (epoch 11.177), train_loss = 1.46996849, grad/param norm = 1.5364e-01, time/batch = 17.0267s	
6774/30300 (epoch 11.178), train_loss = 1.21505927, grad/param norm = 1.3702e-01, time/batch = 18.6158s	
6775/30300 (epoch 11.180), train_loss = 1.37544003, grad/param norm = 1.4126e-01, time/batch = 15.6203s	
6776/30300 (epoch 11.182), train_loss = 1.38290214, grad/param norm = 1.7353e-01, time/batch = 19.3808s	
6777/30300 (epoch 11.183), train_loss = 1.36501011, grad/param norm = 1.4617e-01, time/batch = 19.8771s	
6778/30300 (epoch 11.185), train_loss = 1.72985062, grad/param norm = 1.5327e-01, time/batch = 17.9532s	
6779/30300 (epoch 11.186), train_loss = 1.73874753, grad/param norm = 1.7204e-01, time/batch = 19.2940s	
6780/30300 (epoch 11.188), train_loss = 1.54413672, grad/param norm = 1.6228e-01, time/batch = 19.4560s	
6781/30300 (epoch 11.190), train_loss = 1.41457898, grad/param norm = 1.4582e-01, time/batch = 17.5451s	
6782/30300 (epoch 11.191), train_loss = 1.54447819, grad/param norm = 1.5821e-01, time/batch = 18.8741s	
6783/30300 (epoch 11.193), train_loss = 1.32785600, grad/param norm = 1.4259e-01, time/batch = 19.0401s	
6784/30300 (epoch 11.195), train_loss = 1.48780229, grad/param norm = 1.5277e-01, time/batch = 17.3498s	
6785/30300 (epoch 11.196), train_loss = 1.44911710, grad/param norm = 1.3856e-01, time/batch = 19.8732s	
6786/30300 (epoch 11.198), train_loss = 1.23236916, grad/param norm = 1.4517e-01, time/batch = 19.4501s	
6787/30300 (epoch 11.200), train_loss = 1.45618734, grad/param norm = 1.4244e-01, time/batch = 18.1126s	
6788/30300 (epoch 11.201), train_loss = 1.55109175, grad/param norm = 1.6144e-01, time/batch = 19.4633s	
6789/30300 (epoch 11.203), train_loss = 1.43421770, grad/param norm = 1.4970e-01, time/batch = 19.3919s	
6790/30300 (epoch 11.205), train_loss = 1.68013706, grad/param norm = 1.5584e-01, time/batch = 18.0346s	
6791/30300 (epoch 11.206), train_loss = 1.65734588, grad/param norm = 1.6404e-01, time/batch = 19.3548s	
6792/30300 (epoch 11.208), train_loss = 1.60670247, grad/param norm = 1.7158e-01, time/batch = 18.5356s	
6793/30300 (epoch 11.210), train_loss = 1.49291320, grad/param norm = 1.4094e-01, time/batch = 19.0372s	
6794/30300 (epoch 11.211), train_loss = 1.52005367, grad/param norm = 1.4782e-01, time/batch = 18.0310s	
6795/30300 (epoch 11.213), train_loss = 1.37308197, grad/param norm = 1.3977e-01, time/batch = 18.2981s	
6796/30300 (epoch 11.215), train_loss = 1.28446001, grad/param norm = 1.5111e-01, time/batch = 20.3787s	
6797/30300 (epoch 11.216), train_loss = 1.45216084, grad/param norm = 1.7096e-01, time/batch = 18.7018s	
6798/30300 (epoch 11.218), train_loss = 1.35343984, grad/param norm = 1.3070e-01, time/batch = 19.0452s	
6799/30300 (epoch 11.219), train_loss = 1.27256958, grad/param norm = 1.2816e-01, time/batch = 18.7871s	
6800/30300 (epoch 11.221), train_loss = 1.30583965, grad/param norm = 1.4585e-01, time/batch = 15.4029s	
6801/30300 (epoch 11.223), train_loss = 1.46448305, grad/param norm = 1.4675e-01, time/batch = 18.6866s	
6802/30300 (epoch 11.224), train_loss = 1.27980561, grad/param norm = 1.4193e-01, time/batch = 19.7967s	
6803/30300 (epoch 11.226), train_loss = 1.58019849, grad/param norm = 1.8271e-01, time/batch = 18.6388s	
6804/30300 (epoch 11.228), train_loss = 1.58861576, grad/param norm = 1.4947e-01, time/batch = 18.4801s	
6805/30300 (epoch 11.229), train_loss = 1.35179354, grad/param norm = 1.5095e-01, time/batch = 18.2782s	
6806/30300 (epoch 11.231), train_loss = 1.48754694, grad/param norm = 1.4775e-01, time/batch = 18.7102s	
6807/30300 (epoch 11.233), train_loss = 1.39564824, grad/param norm = 1.5074e-01, time/batch = 17.7793s	
6808/30300 (epoch 11.234), train_loss = 1.52263917, grad/param norm = 1.6335e-01, time/batch = 19.2895s	
6809/30300 (epoch 11.236), train_loss = 1.36021487, grad/param norm = 1.4505e-01, time/batch = 19.8647s	
6810/30300 (epoch 11.238), train_loss = 1.50897236, grad/param norm = 1.7775e-01, time/batch = 18.8495s	
6811/30300 (epoch 11.239), train_loss = 1.47922675, grad/param norm = 1.4925e-01, time/batch = 19.8880s	
6812/30300 (epoch 11.241), train_loss = 1.53299022, grad/param norm = 1.7505e-01, time/batch = 20.0483s	
6813/30300 (epoch 11.243), train_loss = 1.49005095, grad/param norm = 1.4972e-01, time/batch = 18.5353s	
6814/30300 (epoch 11.244), train_loss = 1.71854425, grad/param norm = 1.6927e-01, time/batch = 19.2260s	
6815/30300 (epoch 11.246), train_loss = 1.42337691, grad/param norm = 1.5116e-01, time/batch = 18.5505s	
6816/30300 (epoch 11.248), train_loss = 1.44779755, grad/param norm = 1.4867e-01, time/batch = 17.3506s	
6817/30300 (epoch 11.249), train_loss = 1.33026073, grad/param norm = 1.4696e-01, time/batch = 19.3906s	
6818/30300 (epoch 11.251), train_loss = 1.34025624, grad/param norm = 1.5033e-01, time/batch = 20.2178s	
6819/30300 (epoch 11.252), train_loss = 1.59695863, grad/param norm = 1.6125e-01, time/batch = 18.5534s	
6820/30300 (epoch 11.254), train_loss = 1.57929800, grad/param norm = 1.6297e-01, time/batch = 18.8802s	
6821/30300 (epoch 11.256), train_loss = 1.45629283, grad/param norm = 1.4453e-01, time/batch = 19.4585s	
6822/30300 (epoch 11.257), train_loss = 1.57499364, grad/param norm = 1.6664e-01, time/batch = 18.6340s	
6823/30300 (epoch 11.259), train_loss = 1.49131535, grad/param norm = 1.5226e-01, time/batch = 19.2032s	
6824/30300 (epoch 11.261), train_loss = 1.58407859, grad/param norm = 1.4851e-01, time/batch = 20.0465s	
6825/30300 (epoch 11.262), train_loss = 1.43796359, grad/param norm = 1.4655e-01, time/batch = 18.4531s	
6826/30300 (epoch 11.264), train_loss = 1.45435906, grad/param norm = 1.6560e-01, time/batch = 18.8555s	
6827/30300 (epoch 11.266), train_loss = 1.37434856, grad/param norm = 1.4500e-01, time/batch = 19.6329s	
6828/30300 (epoch 11.267), train_loss = 1.63534883, grad/param norm = 1.6682e-01, time/batch = 19.3644s	
6829/30300 (epoch 11.269), train_loss = 1.45871813, grad/param norm = 1.5227e-01, time/batch = 19.2031s	
6830/30300 (epoch 11.271), train_loss = 1.44210651, grad/param norm = 1.5283e-01, time/batch = 19.4762s	
6831/30300 (epoch 11.272), train_loss = 1.51524433, grad/param norm = 1.5300e-01, time/batch = 17.3723s	
6832/30300 (epoch 11.274), train_loss = 1.64249514, grad/param norm = 1.5876e-01, time/batch = 18.3617s	
6833/30300 (epoch 11.276), train_loss = 1.56614068, grad/param norm = 1.6735e-01, time/batch = 18.7104s	
6834/30300 (epoch 11.277), train_loss = 1.38705461, grad/param norm = 1.5528e-01, time/batch = 17.9566s	
6835/30300 (epoch 11.279), train_loss = 1.51556595, grad/param norm = 1.5487e-01, time/batch = 17.7871s	
6836/30300 (epoch 11.281), train_loss = 1.54299208, grad/param norm = 1.7453e-01, time/batch = 20.0367s	
6837/30300 (epoch 11.282), train_loss = 1.42231769, grad/param norm = 1.3806e-01, time/batch = 20.1157s	
6838/30300 (epoch 11.284), train_loss = 1.65047886, grad/param norm = 1.7609e-01, time/batch = 17.9617s	
6839/30300 (epoch 11.285), train_loss = 1.48108238, grad/param norm = 1.5126e-01, time/batch = 19.5483s	
6840/30300 (epoch 11.287), train_loss = 1.46393520, grad/param norm = 1.5482e-01, time/batch = 18.8717s	
6841/30300 (epoch 11.289), train_loss = 1.51468546, grad/param norm = 1.5973e-01, time/batch = 29.4152s	
6842/30300 (epoch 11.290), train_loss = 1.20945540, grad/param norm = 1.3490e-01, time/batch = 22.4439s	
6843/30300 (epoch 11.292), train_loss = 1.34073366, grad/param norm = 1.3580e-01, time/batch = 18.1985s	
6844/30300 (epoch 11.294), train_loss = 1.63094659, grad/param norm = 1.5833e-01, time/batch = 17.6319s	
6845/30300 (epoch 11.295), train_loss = 1.44340853, grad/param norm = 1.4555e-01, time/batch = 16.9779s	
6846/30300 (epoch 11.297), train_loss = 1.36837948, grad/param norm = 1.3823e-01, time/batch = 18.1232s	
6847/30300 (epoch 11.299), train_loss = 1.44082474, grad/param norm = 1.5736e-01, time/batch = 17.2660s	
6848/30300 (epoch 11.300), train_loss = 1.49017261, grad/param norm = 1.5136e-01, time/batch = 18.6906s	
6849/30300 (epoch 11.302), train_loss = 1.39070688, grad/param norm = 1.4816e-01, time/batch = 19.0087s	
6850/30300 (epoch 11.304), train_loss = 1.34308469, grad/param norm = 1.4695e-01, time/batch = 17.9714s	
6851/30300 (epoch 11.305), train_loss = 1.38121804, grad/param norm = 1.4328e-01, time/batch = 18.8667s	
6852/30300 (epoch 11.307), train_loss = 1.46834120, grad/param norm = 1.4310e-01, time/batch = 19.2116s	
6853/30300 (epoch 11.309), train_loss = 1.54331328, grad/param norm = 1.4604e-01, time/batch = 17.3893s	
6854/30300 (epoch 11.310), train_loss = 1.42253252, grad/param norm = 1.5117e-01, time/batch = 19.0490s	
6855/30300 (epoch 11.312), train_loss = 1.55415695, grad/param norm = 1.4566e-01, time/batch = 19.3754s	
6856/30300 (epoch 11.314), train_loss = 1.49684641, grad/param norm = 1.5355e-01, time/batch = 18.8762s	
6857/30300 (epoch 11.315), train_loss = 1.51527252, grad/param norm = 1.5278e-01, time/batch = 18.4505s	
6858/30300 (epoch 11.317), train_loss = 1.56570982, grad/param norm = 1.6328e-01, time/batch = 18.9449s	
6859/30300 (epoch 11.318), train_loss = 1.62721547, grad/param norm = 1.7493e-01, time/batch = 18.2107s	
6860/30300 (epoch 11.320), train_loss = 1.60837235, grad/param norm = 1.7284e-01, time/batch = 17.7684s	
6861/30300 (epoch 11.322), train_loss = 1.35274383, grad/param norm = 1.4919e-01, time/batch = 19.8733s	
6862/30300 (epoch 11.323), train_loss = 1.59214798, grad/param norm = 1.6152e-01, time/batch = 19.5500s	
6863/30300 (epoch 11.325), train_loss = 1.42766540, grad/param norm = 1.3716e-01, time/batch = 18.2053s	
6864/30300 (epoch 11.327), train_loss = 1.41882419, grad/param norm = 1.4228e-01, time/batch = 18.9502s	
6865/30300 (epoch 11.328), train_loss = 1.41109651, grad/param norm = 1.3938e-01, time/batch = 19.4722s	
6866/30300 (epoch 11.330), train_loss = 1.53369922, grad/param norm = 1.4210e-01, time/batch = 18.1258s	
6867/30300 (epoch 11.332), train_loss = 1.56207784, grad/param norm = 1.5799e-01, time/batch = 17.7176s	
6868/30300 (epoch 11.333), train_loss = 1.47371841, grad/param norm = 1.5763e-01, time/batch = 19.5361s	
6869/30300 (epoch 11.335), train_loss = 1.29159526, grad/param norm = 1.4065e-01, time/batch = 18.4558s	
6870/30300 (epoch 11.337), train_loss = 1.64321963, grad/param norm = 1.6204e-01, time/batch = 17.6453s	
6871/30300 (epoch 11.338), train_loss = 1.37530480, grad/param norm = 1.4127e-01, time/batch = 19.3884s	
6872/30300 (epoch 11.340), train_loss = 1.33414451, grad/param norm = 1.4203e-01, time/batch = 16.8819s	
6873/30300 (epoch 11.342), train_loss = 1.54304110, grad/param norm = 1.5095e-01, time/batch = 18.7068s	
6874/30300 (epoch 11.343), train_loss = 1.54714912, grad/param norm = 1.5144e-01, time/batch = 19.4654s	
6875/30300 (epoch 11.345), train_loss = 1.47544535, grad/param norm = 1.4248e-01, time/batch = 19.0391s	
6876/30300 (epoch 11.347), train_loss = 1.28341582, grad/param norm = 1.3025e-01, time/batch = 18.6917s	
6877/30300 (epoch 11.348), train_loss = 1.35137793, grad/param norm = 1.6499e-01, time/batch = 19.7106s	
6878/30300 (epoch 11.350), train_loss = 1.44370718, grad/param norm = 1.5096e-01, time/batch = 19.2168s	
6879/30300 (epoch 11.351), train_loss = 1.47303149, grad/param norm = 1.5292e-01, time/batch = 17.4492s	
6880/30300 (epoch 11.353), train_loss = 1.25746529, grad/param norm = 1.5174e-01, time/batch = 18.5407s	
6881/30300 (epoch 11.355), train_loss = 1.40579079, grad/param norm = 1.4913e-01, time/batch = 19.9425s	
6882/30300 (epoch 11.356), train_loss = 1.57250968, grad/param norm = 1.6549e-01, time/batch = 17.7596s	
6883/30300 (epoch 11.358), train_loss = 1.63124834, grad/param norm = 1.4348e-01, time/batch = 19.2060s	
6884/30300 (epoch 11.360), train_loss = 1.39411089, grad/param norm = 1.6042e-01, time/batch = 19.2837s	
6885/30300 (epoch 11.361), train_loss = 1.48630249, grad/param norm = 1.6909e-01, time/batch = 18.4242s	
6886/30300 (epoch 11.363), train_loss = 1.53348141, grad/param norm = 1.4808e-01, time/batch = 18.4634s	
6887/30300 (epoch 11.365), train_loss = 1.37564386, grad/param norm = 1.5782e-01, time/batch = 16.5680s	
6888/30300 (epoch 11.366), train_loss = 1.38428600, grad/param norm = 1.4162e-01, time/batch = 17.7048s	
6889/30300 (epoch 11.368), train_loss = 1.24431501, grad/param norm = 1.4895e-01, time/batch = 18.2719s	
6890/30300 (epoch 11.370), train_loss = 1.33679835, grad/param norm = 1.4754e-01, time/batch = 20.0439s	
6891/30300 (epoch 11.371), train_loss = 1.50548198, grad/param norm = 1.4803e-01, time/batch = 20.0434s	
6892/30300 (epoch 11.373), train_loss = 1.35621212, grad/param norm = 1.3508e-01, time/batch = 18.7784s	
6893/30300 (epoch 11.375), train_loss = 1.35995948, grad/param norm = 1.3017e-01, time/batch = 19.4537s	
6894/30300 (epoch 11.376), train_loss = 1.38291344, grad/param norm = 1.4023e-01, time/batch = 19.3073s	
6895/30300 (epoch 11.378), train_loss = 1.39941138, grad/param norm = 1.4733e-01, time/batch = 17.6867s	
6896/30300 (epoch 11.380), train_loss = 1.65850490, grad/param norm = 1.6099e-01, time/batch = 17.5647s	
6897/30300 (epoch 11.381), train_loss = 1.34230703, grad/param norm = 1.3891e-01, time/batch = 18.8141s	
6898/30300 (epoch 11.383), train_loss = 1.43884164, grad/param norm = 1.6241e-01, time/batch = 19.0334s	
6899/30300 (epoch 11.384), train_loss = 1.54493990, grad/param norm = 1.4678e-01, time/batch = 19.2997s	
6900/30300 (epoch 11.386), train_loss = 1.31080061, grad/param norm = 1.5268e-01, time/batch = 17.4379s	
6901/30300 (epoch 11.388), train_loss = 1.30567522, grad/param norm = 1.3082e-01, time/batch = 18.3809s	
6902/30300 (epoch 11.389), train_loss = 1.46397989, grad/param norm = 1.5557e-01, time/batch = 19.5348s	
6903/30300 (epoch 11.391), train_loss = 1.50895694, grad/param norm = 1.4538e-01, time/batch = 19.6336s	
6904/30300 (epoch 11.393), train_loss = 1.26860456, grad/param norm = 1.3397e-01, time/batch = 18.9604s	
6905/30300 (epoch 11.394), train_loss = 1.45559783, grad/param norm = 1.4564e-01, time/batch = 18.5398s	
6906/30300 (epoch 11.396), train_loss = 1.62017784, grad/param norm = 1.4535e-01, time/batch = 19.2944s	
6907/30300 (epoch 11.398), train_loss = 1.38638825, grad/param norm = 1.2810e-01, time/batch = 19.4568s	
6908/30300 (epoch 11.399), train_loss = 1.42926999, grad/param norm = 1.5396e-01, time/batch = 18.5503s	
6909/30300 (epoch 11.401), train_loss = 1.53688446, grad/param norm = 1.4868e-01, time/batch = 18.6310s	
6910/30300 (epoch 11.403), train_loss = 1.38775001, grad/param norm = 1.4594e-01, time/batch = 19.4648s	
6911/30300 (epoch 11.404), train_loss = 1.34801326, grad/param norm = 1.7170e-01, time/batch = 19.6091s	
6912/30300 (epoch 11.406), train_loss = 1.44628945, grad/param norm = 1.4766e-01, time/batch = 18.2695s	
6913/30300 (epoch 11.408), train_loss = 1.30709490, grad/param norm = 1.4829e-01, time/batch = 19.3015s	
6914/30300 (epoch 11.409), train_loss = 1.26558368, grad/param norm = 1.4310e-01, time/batch = 18.4627s	
6915/30300 (epoch 11.411), train_loss = 1.29661872, grad/param norm = 1.3689e-01, time/batch = 18.9721s	
6916/30300 (epoch 11.413), train_loss = 1.24962358, grad/param norm = 1.4435e-01, time/batch = 19.9497s	
6917/30300 (epoch 11.414), train_loss = 1.56654390, grad/param norm = 1.5420e-01, time/batch = 18.2087s	
6918/30300 (epoch 11.416), train_loss = 1.41655183, grad/param norm = 1.5753e-01, time/batch = 18.6239s	
6919/30300 (epoch 11.417), train_loss = 1.36593324, grad/param norm = 1.4405e-01, time/batch = 18.0199s	
6920/30300 (epoch 11.419), train_loss = 1.29078575, grad/param norm = 1.4288e-01, time/batch = 16.9516s	
6921/30300 (epoch 11.421), train_loss = 1.37837720, grad/param norm = 1.3740e-01, time/batch = 0.7016s	
6922/30300 (epoch 11.422), train_loss = 1.40037328, grad/param norm = 1.4049e-01, time/batch = 0.7213s	
6923/30300 (epoch 11.424), train_loss = 1.44009765, grad/param norm = 1.4649e-01, time/batch = 0.7025s	
6924/30300 (epoch 11.426), train_loss = 1.30298330, grad/param norm = 1.4732e-01, time/batch = 0.6944s	
6925/30300 (epoch 11.427), train_loss = 1.40633096, grad/param norm = 1.5091e-01, time/batch = 0.6946s	
6926/30300 (epoch 11.429), train_loss = 1.45571641, grad/param norm = 1.5787e-01, time/batch = 0.6895s	
6927/30300 (epoch 11.431), train_loss = 1.51236309, grad/param norm = 1.6100e-01, time/batch = 0.6893s	
6928/30300 (epoch 11.432), train_loss = 1.40369470, grad/param norm = 1.4819e-01, time/batch = 1.0124s	
6929/30300 (epoch 11.434), train_loss = 1.27231859, grad/param norm = 1.5256e-01, time/batch = 1.0161s	
6930/30300 (epoch 11.436), train_loss = 1.58621482, grad/param norm = 1.5958e-01, time/batch = 1.0185s	
6931/30300 (epoch 11.437), train_loss = 1.34950862, grad/param norm = 1.6641e-01, time/batch = 1.0247s	
6932/30300 (epoch 11.439), train_loss = 1.35906373, grad/param norm = 1.4559e-01, time/batch = 1.1376s	
6933/30300 (epoch 11.441), train_loss = 1.36164610, grad/param norm = 1.4121e-01, time/batch = 1.9378s	
6934/30300 (epoch 11.442), train_loss = 1.31331112, grad/param norm = 1.4347e-01, time/batch = 1.9123s	
6935/30300 (epoch 11.444), train_loss = 1.19928053, grad/param norm = 1.3605e-01, time/batch = 11.4549s	
6936/30300 (epoch 11.446), train_loss = 1.38314697, grad/param norm = 1.4579e-01, time/batch = 19.6143s	
6937/30300 (epoch 11.447), train_loss = 1.40904289, grad/param norm = 1.4244e-01, time/batch = 18.4531s	
6938/30300 (epoch 11.449), train_loss = 1.35915870, grad/param norm = 1.4880e-01, time/batch = 19.4590s	
6939/30300 (epoch 11.450), train_loss = 1.54315744, grad/param norm = 1.4910e-01, time/batch = 18.6233s	
6940/30300 (epoch 11.452), train_loss = 1.44764363, grad/param norm = 1.3690e-01, time/batch = 17.5306s	
6941/30300 (epoch 11.454), train_loss = 1.43454128, grad/param norm = 1.3586e-01, time/batch = 18.8947s	
6942/30300 (epoch 11.455), train_loss = 1.51556580, grad/param norm = 1.5980e-01, time/batch = 17.5147s	
6943/30300 (epoch 11.457), train_loss = 1.47161516, grad/param norm = 1.5140e-01, time/batch = 19.0511s	
6944/30300 (epoch 11.459), train_loss = 1.51279853, grad/param norm = 1.5492e-01, time/batch = 18.2041s	
6945/30300 (epoch 11.460), train_loss = 1.49902821, grad/param norm = 1.5970e-01, time/batch = 19.0500s	
6946/30300 (epoch 11.462), train_loss = 1.54096834, grad/param norm = 1.5465e-01, time/batch = 20.3009s	
6947/30300 (epoch 11.464), train_loss = 1.29013720, grad/param norm = 1.5353e-01, time/batch = 18.7870s	
6948/30300 (epoch 11.465), train_loss = 1.23956163, grad/param norm = 1.3694e-01, time/batch = 18.9703s	
6949/30300 (epoch 11.467), train_loss = 1.19200248, grad/param norm = 1.3087e-01, time/batch = 18.4733s	
6950/30300 (epoch 11.469), train_loss = 1.34576065, grad/param norm = 1.4800e-01, time/batch = 17.5503s	
6951/30300 (epoch 11.470), train_loss = 1.38401680, grad/param norm = 1.4648e-01, time/batch = 19.3831s	
6952/30300 (epoch 11.472), train_loss = 1.36588714, grad/param norm = 1.3980e-01, time/batch = 18.0931s	
6953/30300 (epoch 11.474), train_loss = 1.43648386, grad/param norm = 1.6395e-01, time/batch = 17.9434s	
6954/30300 (epoch 11.475), train_loss = 1.33618330, grad/param norm = 1.4968e-01, time/batch = 19.2966s	
6955/30300 (epoch 11.477), train_loss = 1.46202558, grad/param norm = 1.6383e-01, time/batch = 18.7099s	
6956/30300 (epoch 11.479), train_loss = 1.44587504, grad/param norm = 1.5907e-01, time/batch = 17.2072s	
6957/30300 (epoch 11.480), train_loss = 1.46660451, grad/param norm = 1.3778e-01, time/batch = 18.1199s	
6958/30300 (epoch 11.482), train_loss = 1.47491098, grad/param norm = 1.4101e-01, time/batch = 17.8119s	
6959/30300 (epoch 11.483), train_loss = 1.37749696, grad/param norm = 1.4703e-01, time/batch = 19.5405s	
6960/30300 (epoch 11.485), train_loss = 1.42932451, grad/param norm = 1.4595e-01, time/batch = 19.1132s	
6961/30300 (epoch 11.487), train_loss = 1.47301926, grad/param norm = 1.5504e-01, time/batch = 18.6107s	
6962/30300 (epoch 11.488), train_loss = 1.48897645, grad/param norm = 1.4738e-01, time/batch = 18.8442s	
6963/30300 (epoch 11.490), train_loss = 1.32877367, grad/param norm = 1.5000e-01, time/batch = 18.2801s	
6964/30300 (epoch 11.492), train_loss = 1.44527848, grad/param norm = 1.5368e-01, time/batch = 19.0615s	
6965/30300 (epoch 11.493), train_loss = 1.37703928, grad/param norm = 1.5016e-01, time/batch = 20.1141s	
6966/30300 (epoch 11.495), train_loss = 1.35773379, grad/param norm = 1.4174e-01, time/batch = 17.7146s	
6967/30300 (epoch 11.497), train_loss = 1.46189711, grad/param norm = 1.5053e-01, time/batch = 19.8031s	
6968/30300 (epoch 11.498), train_loss = 1.44686830, grad/param norm = 1.5075e-01, time/batch = 20.2861s	
6969/30300 (epoch 11.500), train_loss = 1.52694183, grad/param norm = 1.6731e-01, time/batch = 18.5276s	
6970/30300 (epoch 11.502), train_loss = 1.38122766, grad/param norm = 1.4841e-01, time/batch = 20.1235s	
6971/30300 (epoch 11.503), train_loss = 1.50591485, grad/param norm = 1.4663e-01, time/batch = 18.7876s	
6972/30300 (epoch 11.505), train_loss = 1.40813902, grad/param norm = 1.4637e-01, time/batch = 17.7016s	
6973/30300 (epoch 11.507), train_loss = 1.37292448, grad/param norm = 1.4867e-01, time/batch = 18.3554s	
6974/30300 (epoch 11.508), train_loss = 1.44744670, grad/param norm = 1.6275e-01, time/batch = 18.4663s	
6975/30300 (epoch 11.510), train_loss = 1.51903579, grad/param norm = 1.6403e-01, time/batch = 18.5571s	
6976/30300 (epoch 11.512), train_loss = 1.33647777, grad/param norm = 1.4460e-01, time/batch = 18.2990s	
6977/30300 (epoch 11.513), train_loss = 1.51634917, grad/param norm = 1.5606e-01, time/batch = 19.9635s	
6978/30300 (epoch 11.515), train_loss = 1.39557788, grad/param norm = 1.4244e-01, time/batch = 19.2828s	
6979/30300 (epoch 11.517), train_loss = 1.25670180, grad/param norm = 1.4062e-01, time/batch = 18.6267s	
6980/30300 (epoch 11.518), train_loss = 1.50241929, grad/param norm = 1.5904e-01, time/batch = 19.0522s	
6981/30300 (epoch 11.520), train_loss = 1.63025303, grad/param norm = 1.6455e-01, time/batch = 19.6433s	
6982/30300 (epoch 11.521), train_loss = 1.30900948, grad/param norm = 1.6072e-01, time/batch = 18.5935s	
6983/30300 (epoch 11.523), train_loss = 1.56022565, grad/param norm = 1.6556e-01, time/batch = 19.0553s	
6984/30300 (epoch 11.525), train_loss = 1.35207983, grad/param norm = 1.5535e-01, time/batch = 19.2060s	
6985/30300 (epoch 11.526), train_loss = 1.41823124, grad/param norm = 1.5254e-01, time/batch = 18.0535s	
6986/30300 (epoch 11.528), train_loss = 1.27139819, grad/param norm = 1.4197e-01, time/batch = 19.3762s	
6987/30300 (epoch 11.530), train_loss = 1.30672557, grad/param norm = 1.5027e-01, time/batch = 17.9488s	
6988/30300 (epoch 11.531), train_loss = 1.48813873, grad/param norm = 1.6268e-01, time/batch = 18.2875s	
6989/30300 (epoch 11.533), train_loss = 1.47474284, grad/param norm = 1.5635e-01, time/batch = 18.7902s	
6990/30300 (epoch 11.535), train_loss = 1.25265611, grad/param norm = 1.2865e-01, time/batch = 18.9700s	
6991/30300 (epoch 11.536), train_loss = 1.46989567, grad/param norm = 1.5371e-01, time/batch = 18.4658s	
6992/30300 (epoch 11.538), train_loss = 1.24895833, grad/param norm = 1.6224e-01, time/batch = 19.0359s	
6993/30300 (epoch 11.540), train_loss = 1.32155690, grad/param norm = 1.5302e-01, time/batch = 20.0517s	
6994/30300 (epoch 11.541), train_loss = 1.39984290, grad/param norm = 1.5583e-01, time/batch = 18.6222s	
6995/30300 (epoch 11.543), train_loss = 1.43554302, grad/param norm = 1.4708e-01, time/batch = 19.1993s	
6996/30300 (epoch 11.545), train_loss = 1.46849409, grad/param norm = 1.6385e-01, time/batch = 18.7275s	
6997/30300 (epoch 11.546), train_loss = 1.64874507, grad/param norm = 1.5162e-01, time/batch = 18.5439s	
6998/30300 (epoch 11.548), train_loss = 1.36002729, grad/param norm = 1.4828e-01, time/batch = 18.0324s	
6999/30300 (epoch 11.550), train_loss = 1.57200686, grad/param norm = 1.7417e-01, time/batch = 18.0487s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch11.55_1.7269.t7	
7000/30300 (epoch 11.551), train_loss = 1.35190999, grad/param norm = 1.4703e-01, time/batch = 17.8065s	
7001/30300 (epoch 11.553), train_loss = 1.70054601, grad/param norm = 2.0183e-01, time/batch = 20.2091s	
7002/30300 (epoch 11.554), train_loss = 1.52797341, grad/param norm = 1.8458e-01, time/batch = 18.6127s	
7003/30300 (epoch 11.556), train_loss = 1.47924892, grad/param norm = 1.5425e-01, time/batch = 18.7896s	
7004/30300 (epoch 11.558), train_loss = 1.56573143, grad/param norm = 1.6246e-01, time/batch = 18.1064s	
7005/30300 (epoch 11.559), train_loss = 1.45627095, grad/param norm = 1.6031e-01, time/batch = 19.1355s	
7006/30300 (epoch 11.561), train_loss = 1.28830564, grad/param norm = 1.4871e-01, time/batch = 19.5353s	
7007/30300 (epoch 11.563), train_loss = 1.32678180, grad/param norm = 1.4231e-01, time/batch = 19.1187s	
7008/30300 (epoch 11.564), train_loss = 1.37140660, grad/param norm = 1.4529e-01, time/batch = 17.0966s	
7009/30300 (epoch 11.566), train_loss = 1.41931814, grad/param norm = 1.4132e-01, time/batch = 18.7027s	
7010/30300 (epoch 11.568), train_loss = 1.21387141, grad/param norm = 1.5093e-01, time/batch = 18.3675s	
7011/30300 (epoch 11.569), train_loss = 1.41481550, grad/param norm = 1.4523e-01, time/batch = 19.6329s	
7012/30300 (epoch 11.571), train_loss = 1.45373537, grad/param norm = 1.5523e-01, time/batch = 18.7200s	
7013/30300 (epoch 11.573), train_loss = 1.46113641, grad/param norm = 1.5213e-01, time/batch = 17.4320s	
7014/30300 (epoch 11.574), train_loss = 1.49679976, grad/param norm = 1.5186e-01, time/batch = 19.6373s	
7015/30300 (epoch 11.576), train_loss = 1.39478566, grad/param norm = 1.4364e-01, time/batch = 18.0517s	
7016/30300 (epoch 11.578), train_loss = 1.30952761, grad/param norm = 1.4204e-01, time/batch = 18.7038s	
7017/30300 (epoch 11.579), train_loss = 1.47016467, grad/param norm = 1.6435e-01, time/batch = 18.6405s	
7018/30300 (epoch 11.581), train_loss = 1.50925911, grad/param norm = 1.3916e-01, time/batch = 17.3846s	
7019/30300 (epoch 11.583), train_loss = 1.60044367, grad/param norm = 1.6452e-01, time/batch = 17.8695s	
7020/30300 (epoch 11.584), train_loss = 1.50176755, grad/param norm = 1.4317e-01, time/batch = 18.1458s	
7021/30300 (epoch 11.586), train_loss = 1.46683653, grad/param norm = 1.5352e-01, time/batch = 20.0469s	
7022/30300 (epoch 11.587), train_loss = 1.45994914, grad/param norm = 1.6101e-01, time/batch = 19.3664s	
7023/30300 (epoch 11.589), train_loss = 1.28151905, grad/param norm = 1.3656e-01, time/batch = 18.8558s	
7024/30300 (epoch 11.591), train_loss = 1.45262463, grad/param norm = 1.4485e-01, time/batch = 18.9675s	
7025/30300 (epoch 11.592), train_loss = 1.40909333, grad/param norm = 1.3717e-01, time/batch = 19.8026s	
7026/30300 (epoch 11.594), train_loss = 1.45989725, grad/param norm = 1.5652e-01, time/batch = 17.5196s	
7027/30300 (epoch 11.596), train_loss = 1.29917602, grad/param norm = 1.3271e-01, time/batch = 19.9703s	
7028/30300 (epoch 11.597), train_loss = 1.38031750, grad/param norm = 1.5638e-01, time/batch = 17.6913s	
7029/30300 (epoch 11.599), train_loss = 1.21957972, grad/param norm = 1.4772e-01, time/batch = 16.1942s	
7030/30300 (epoch 11.601), train_loss = 1.47101859, grad/param norm = 1.4706e-01, time/batch = 15.5972s	
7031/30300 (epoch 11.602), train_loss = 1.41455602, grad/param norm = 1.3748e-01, time/batch = 17.0304s	
7032/30300 (epoch 11.604), train_loss = 1.31442915, grad/param norm = 1.3217e-01, time/batch = 15.6137s	
7033/30300 (epoch 11.606), train_loss = 1.50101234, grad/param norm = 3.8419e-01, time/batch = 15.9516s	
7034/30300 (epoch 11.607), train_loss = 1.50864881, grad/param norm = 1.7392e-01, time/batch = 19.7158s	
7035/30300 (epoch 11.609), train_loss = 1.64423738, grad/param norm = 1.6261e-01, time/batch = 19.2145s	
7036/30300 (epoch 11.611), train_loss = 1.34631349, grad/param norm = 1.4558e-01, time/batch = 18.2983s	
7037/30300 (epoch 11.612), train_loss = 1.34465764, grad/param norm = 1.5552e-01, time/batch = 19.1364s	
7038/30300 (epoch 11.614), train_loss = 1.31718042, grad/param norm = 1.4393e-01, time/batch = 19.4605s	
7039/30300 (epoch 11.616), train_loss = 1.48545281, grad/param norm = 1.5690e-01, time/batch = 25.0043s	
7040/30300 (epoch 11.617), train_loss = 1.38692069, grad/param norm = 1.4678e-01, time/batch = 24.3129s	
7041/30300 (epoch 11.619), train_loss = 1.21452092, grad/param norm = 1.3494e-01, time/batch = 19.6246s	
7042/30300 (epoch 11.620), train_loss = 1.44556277, grad/param norm = 1.5470e-01, time/batch = 18.4487s	
7043/30300 (epoch 11.622), train_loss = 1.43381260, grad/param norm = 1.6590e-01, time/batch = 18.5624s	
7044/30300 (epoch 11.624), train_loss = 1.35505950, grad/param norm = 1.6417e-01, time/batch = 18.2193s	
7045/30300 (epoch 11.625), train_loss = 1.38138156, grad/param norm = 1.4954e-01, time/batch = 16.2803s	
7046/30300 (epoch 11.627), train_loss = 1.58397379, grad/param norm = 1.6542e-01, time/batch = 19.1343s	
7047/30300 (epoch 11.629), train_loss = 1.49098297, grad/param norm = 1.4394e-01, time/batch = 18.8880s	
7048/30300 (epoch 11.630), train_loss = 1.43605161, grad/param norm = 1.4288e-01, time/batch = 18.5475s	
7049/30300 (epoch 11.632), train_loss = 1.53102781, grad/param norm = 1.5768e-01, time/batch = 18.7872s	
7050/30300 (epoch 11.634), train_loss = 1.27119066, grad/param norm = 1.3448e-01, time/batch = 20.2699s	
7051/30300 (epoch 11.635), train_loss = 1.48053825, grad/param norm = 1.4731e-01, time/batch = 17.2060s	
7052/30300 (epoch 11.637), train_loss = 1.48361093, grad/param norm = 1.5993e-01, time/batch = 18.5460s	
7053/30300 (epoch 11.639), train_loss = 1.33831564, grad/param norm = 1.5389e-01, time/batch = 18.8644s	
7054/30300 (epoch 11.640), train_loss = 1.54781390, grad/param norm = 1.5843e-01, time/batch = 18.6153s	
7055/30300 (epoch 11.642), train_loss = 1.36153422, grad/param norm = 1.3892e-01, time/batch = 18.3639s	
7056/30300 (epoch 11.644), train_loss = 1.48995781, grad/param norm = 1.4653e-01, time/batch = 19.5482s	
7057/30300 (epoch 11.645), train_loss = 1.27971473, grad/param norm = 1.3259e-01, time/batch = 19.5471s	
7058/30300 (epoch 11.647), train_loss = 1.38833964, grad/param norm = 1.4066e-01, time/batch = 18.9482s	
7059/30300 (epoch 11.649), train_loss = 1.37585361, grad/param norm = 1.6265e-01, time/batch = 20.2941s	
7060/30300 (epoch 11.650), train_loss = 1.38983023, grad/param norm = 1.4798e-01, time/batch = 17.6151s	
7061/30300 (epoch 11.652), train_loss = 1.34212771, grad/param norm = 1.4011e-01, time/batch = 18.7010s	
7062/30300 (epoch 11.653), train_loss = 1.58602598, grad/param norm = 1.4692e-01, time/batch = 16.7183s	
7063/30300 (epoch 11.655), train_loss = 1.35377278, grad/param norm = 1.5140e-01, time/batch = 18.4557s	
7064/30300 (epoch 11.657), train_loss = 1.40948854, grad/param norm = 1.4596e-01, time/batch = 17.3815s	
7065/30300 (epoch 11.658), train_loss = 1.36635302, grad/param norm = 1.5153e-01, time/batch = 18.8784s	
7066/30300 (epoch 11.660), train_loss = 1.47973415, grad/param norm = 1.4925e-01, time/batch = 20.3745s	
7067/30300 (epoch 11.662), train_loss = 1.48347128, grad/param norm = 1.6389e-01, time/batch = 17.7998s	
7068/30300 (epoch 11.663), train_loss = 1.43332864, grad/param norm = 1.4766e-01, time/batch = 18.1338s	
7069/30300 (epoch 11.665), train_loss = 1.32238757, grad/param norm = 1.5526e-01, time/batch = 19.8863s	
7070/30300 (epoch 11.667), train_loss = 1.52893235, grad/param norm = 1.4925e-01, time/batch = 18.9599s	
7071/30300 (epoch 11.668), train_loss = 1.59292231, grad/param norm = 1.7182e-01, time/batch = 19.7815s	
7072/30300 (epoch 11.670), train_loss = 1.56768425, grad/param norm = 1.5640e-01, time/batch = 18.3735s	
7073/30300 (epoch 11.672), train_loss = 1.50221806, grad/param norm = 1.5600e-01, time/batch = 19.1305s	
7074/30300 (epoch 11.673), train_loss = 1.52542350, grad/param norm = 1.6033e-01, time/batch = 17.1973s	
7075/30300 (epoch 11.675), train_loss = 1.35718776, grad/param norm = 1.5154e-01, time/batch = 19.4567s	
7076/30300 (epoch 11.677), train_loss = 1.31589984, grad/param norm = 1.3252e-01, time/batch = 19.2935s	
7077/30300 (epoch 11.678), train_loss = 1.36102589, grad/param norm = 1.4241e-01, time/batch = 17.8638s	
7078/30300 (epoch 11.680), train_loss = 1.18783881, grad/param norm = 1.3384e-01, time/batch = 18.2880s	
7079/30300 (epoch 11.682), train_loss = 1.40436729, grad/param norm = 1.4918e-01, time/batch = 18.8678s	
7080/30300 (epoch 11.683), train_loss = 1.45542110, grad/param norm = 1.4882e-01, time/batch = 18.0196s	
7081/30300 (epoch 11.685), train_loss = 1.56453380, grad/param norm = 1.6769e-01, time/batch = 19.5376s	
7082/30300 (epoch 11.686), train_loss = 1.41621662, grad/param norm = 1.5220e-01, time/batch = 19.8667s	
7083/30300 (epoch 11.688), train_loss = 1.43665835, grad/param norm = 1.4487e-01, time/batch = 17.9513s	
7084/30300 (epoch 11.690), train_loss = 1.35996374, grad/param norm = 1.5469e-01, time/batch = 19.3671s	
7085/30300 (epoch 11.691), train_loss = 1.42462451, grad/param norm = 1.4329e-01, time/batch = 20.1142s	
7086/30300 (epoch 11.693), train_loss = 1.82938496, grad/param norm = 1.7092e-01, time/batch = 18.0379s	
7087/30300 (epoch 11.695), train_loss = 1.58927105, grad/param norm = 1.6552e-01, time/batch = 19.2804s	
7088/30300 (epoch 11.696), train_loss = 1.58577763, grad/param norm = 1.7935e-01, time/batch = 17.3575s	
7089/30300 (epoch 11.698), train_loss = 1.37387466, grad/param norm = 1.4967e-01, time/batch = 19.2697s	
7090/30300 (epoch 11.700), train_loss = 1.38226364, grad/param norm = 1.5344e-01, time/batch = 19.2953s	
7091/30300 (epoch 11.701), train_loss = 1.24035085, grad/param norm = 1.3311e-01, time/batch = 19.7054s	
7092/30300 (epoch 11.703), train_loss = 1.43127945, grad/param norm = 1.4488e-01, time/batch = 19.6270s	
7093/30300 (epoch 11.705), train_loss = 1.40013057, grad/param norm = 1.5385e-01, time/batch = 16.7687s	
7094/30300 (epoch 11.706), train_loss = 1.45984659, grad/param norm = 1.5009e-01, time/batch = 17.5381s	
7095/30300 (epoch 11.708), train_loss = 1.37104532, grad/param norm = 1.4541e-01, time/batch = 18.9476s	
7096/30300 (epoch 11.710), train_loss = 1.38241255, grad/param norm = 1.5175e-01, time/batch = 18.8907s	
7097/30300 (epoch 11.711), train_loss = 1.30330512, grad/param norm = 1.4703e-01, time/batch = 19.2031s	
7098/30300 (epoch 11.713), train_loss = 1.29208631, grad/param norm = 1.3885e-01, time/batch = 20.2761s	
7099/30300 (epoch 11.715), train_loss = 1.39090890, grad/param norm = 1.5207e-01, time/batch = 18.5270s	
7100/30300 (epoch 11.716), train_loss = 1.56844063, grad/param norm = 1.6249e-01, time/batch = 19.2807s	
7101/30300 (epoch 11.718), train_loss = 1.53498207, grad/param norm = 1.6251e-01, time/batch = 20.1388s	
7102/30300 (epoch 11.719), train_loss = 1.38403810, grad/param norm = 1.5962e-01, time/batch = 16.9439s	
7103/30300 (epoch 11.721), train_loss = 1.40852258, grad/param norm = 1.5705e-01, time/batch = 19.7147s	
7104/30300 (epoch 11.723), train_loss = 1.37046838, grad/param norm = 1.5367e-01, time/batch = 19.2120s	
7105/30300 (epoch 11.724), train_loss = 1.51332703, grad/param norm = 1.5777e-01, time/batch = 18.7081s	
7106/30300 (epoch 11.726), train_loss = 1.85106037, grad/param norm = 1.8515e-01, time/batch = 19.7828s	
7107/30300 (epoch 11.728), train_loss = 1.43977090, grad/param norm = 1.4703e-01, time/batch = 19.3842s	
7108/30300 (epoch 11.729), train_loss = 1.42971279, grad/param norm = 1.5473e-01, time/batch = 19.0454s	
7109/30300 (epoch 11.731), train_loss = 1.50843362, grad/param norm = 1.5524e-01, time/batch = 19.3754s	
7110/30300 (epoch 11.733), train_loss = 1.41042168, grad/param norm = 1.4534e-01, time/batch = 18.9541s	
7111/30300 (epoch 11.734), train_loss = 1.49055926, grad/param norm = 1.4372e-01, time/batch = 17.2653s	
7112/30300 (epoch 11.736), train_loss = 1.39317034, grad/param norm = 1.3853e-01, time/batch = 18.9540s	
7113/30300 (epoch 11.738), train_loss = 1.26161904, grad/param norm = 1.3372e-01, time/batch = 19.2225s	
7114/30300 (epoch 11.739), train_loss = 1.47596625, grad/param norm = 1.4635e-01, time/batch = 18.3864s	
7115/30300 (epoch 11.741), train_loss = 1.52412135, grad/param norm = 1.4620e-01, time/batch = 18.7816s	
7116/30300 (epoch 11.743), train_loss = 1.35813926, grad/param norm = 1.4380e-01, time/batch = 18.8830s	
7117/30300 (epoch 11.744), train_loss = 1.50095011, grad/param norm = 1.5290e-01, time/batch = 19.7188s	
7118/30300 (epoch 11.746), train_loss = 1.27990635, grad/param norm = 1.3908e-01, time/batch = 18.6171s	
7119/30300 (epoch 11.748), train_loss = 1.43128341, grad/param norm = 1.6801e-01, time/batch = 19.1233s	
7120/30300 (epoch 11.749), train_loss = 1.46896971, grad/param norm = 1.6330e-01, time/batch = 17.5531s	
7121/30300 (epoch 11.751), train_loss = 1.33471403, grad/param norm = 1.4564e-01, time/batch = 18.3754s	
7122/30300 (epoch 11.752), train_loss = 1.36246638, grad/param norm = 1.4487e-01, time/batch = 19.7195s	
7123/30300 (epoch 11.754), train_loss = 1.29678253, grad/param norm = 1.3241e-01, time/batch = 19.2099s	
7124/30300 (epoch 11.756), train_loss = 1.37650426, grad/param norm = 1.5352e-01, time/batch = 18.5452s	
7125/30300 (epoch 11.757), train_loss = 1.46751728, grad/param norm = 1.5925e-01, time/batch = 18.2930s	
7126/30300 (epoch 11.759), train_loss = 1.37205196, grad/param norm = 1.3674e-01, time/batch = 18.4782s	
7127/30300 (epoch 11.761), train_loss = 1.28568544, grad/param norm = 1.3818e-01, time/batch = 18.2975s	
7128/30300 (epoch 11.762), train_loss = 1.20756881, grad/param norm = 1.2993e-01, time/batch = 18.2075s	
7129/30300 (epoch 11.764), train_loss = 1.37610039, grad/param norm = 1.4292e-01, time/batch = 17.8624s	
7130/30300 (epoch 11.766), train_loss = 1.44918024, grad/param norm = 1.4567e-01, time/batch = 20.3831s	
7131/30300 (epoch 11.767), train_loss = 1.53354410, grad/param norm = 1.9262e-01, time/batch = 18.6117s	
7132/30300 (epoch 11.769), train_loss = 1.49143009, grad/param norm = 1.5503e-01, time/batch = 19.3661s	
7133/30300 (epoch 11.771), train_loss = 1.40623021, grad/param norm = 1.5692e-01, time/batch = 20.2800s	
7134/30300 (epoch 11.772), train_loss = 1.43585653, grad/param norm = 1.5354e-01, time/batch = 16.9508s	
7135/30300 (epoch 11.774), train_loss = 1.57273784, grad/param norm = 1.5037e-01, time/batch = 18.1495s	
7136/30300 (epoch 11.776), train_loss = 1.46750608, grad/param norm = 1.6096e-01, time/batch = 19.5426s	
7137/30300 (epoch 11.777), train_loss = 1.43946254, grad/param norm = 1.4018e-01, time/batch = 17.9575s	
7138/30300 (epoch 11.779), train_loss = 1.58909392, grad/param norm = 1.6678e-01, time/batch = 17.8807s	
7139/30300 (epoch 11.781), train_loss = 1.44510734, grad/param norm = 1.6320e-01, time/batch = 18.6201s	
7140/30300 (epoch 11.782), train_loss = 1.36372424, grad/param norm = 1.4428e-01, time/batch = 17.5412s	
7141/30300 (epoch 11.784), train_loss = 1.36611917, grad/param norm = 1.4504e-01, time/batch = 19.2037s	
7142/30300 (epoch 11.785), train_loss = 1.57509513, grad/param norm = 1.6285e-01, time/batch = 18.5596s	
7143/30300 (epoch 11.787), train_loss = 1.27371484, grad/param norm = 1.5339e-01, time/batch = 18.3712s	
7144/30300 (epoch 11.789), train_loss = 1.71921137, grad/param norm = 1.5524e-01, time/batch = 17.4456s	
7145/30300 (epoch 11.790), train_loss = 1.52714991, grad/param norm = 1.6604e-01, time/batch = 18.9673s	
7146/30300 (epoch 11.792), train_loss = 1.30445381, grad/param norm = 1.7214e-01, time/batch = 17.8653s	
7147/30300 (epoch 11.794), train_loss = 1.35715002, grad/param norm = 1.4941e-01, time/batch = 18.0291s	
7148/30300 (epoch 11.795), train_loss = 1.38558375, grad/param norm = 1.3818e-01, time/batch = 18.8843s	
7149/30300 (epoch 11.797), train_loss = 1.61572898, grad/param norm = 1.6917e-01, time/batch = 20.4644s	
7150/30300 (epoch 11.799), train_loss = 1.48553503, grad/param norm = 1.6090e-01, time/batch = 17.1176s	
7151/30300 (epoch 11.800), train_loss = 1.48753914, grad/param norm = 1.5890e-01, time/batch = 19.2123s	
7152/30300 (epoch 11.802), train_loss = 1.67569370, grad/param norm = 1.8066e-01, time/batch = 20.0424s	
7153/30300 (epoch 11.804), train_loss = 1.50529238, grad/param norm = 1.5438e-01, time/batch = 17.9632s	
7154/30300 (epoch 11.805), train_loss = 1.61303750, grad/param norm = 1.7038e-01, time/batch = 19.9497s	
7155/30300 (epoch 11.807), train_loss = 1.44621558, grad/param norm = 1.6077e-01, time/batch = 17.8664s	
7156/30300 (epoch 11.809), train_loss = 1.53611915, grad/param norm = 1.6925e-01, time/batch = 18.3823s	
7157/30300 (epoch 11.810), train_loss = 1.51572269, grad/param norm = 1.4617e-01, time/batch = 18.4578s	
7158/30300 (epoch 11.812), train_loss = 1.31139211, grad/param norm = 1.4659e-01, time/batch = 18.7908s	
7159/30300 (epoch 11.814), train_loss = 1.45395044, grad/param norm = 1.5323e-01, time/batch = 19.3602s	
7160/30300 (epoch 11.815), train_loss = 1.47937704, grad/param norm = 1.6532e-01, time/batch = 18.4710s	
7161/30300 (epoch 11.817), train_loss = 1.54985673, grad/param norm = 1.6465e-01, time/batch = 17.5285s	
7162/30300 (epoch 11.818), train_loss = 1.47779673, grad/param norm = 1.4656e-01, time/batch = 20.1969s	
7163/30300 (epoch 11.820), train_loss = 1.66657003, grad/param norm = 1.6442e-01, time/batch = 19.2836s	
7164/30300 (epoch 11.822), train_loss = 1.66722045, grad/param norm = 1.8785e-01, time/batch = 18.7162s	
7165/30300 (epoch 11.823), train_loss = 1.70547094, grad/param norm = 1.8768e-01, time/batch = 19.7896s	
7166/30300 (epoch 11.825), train_loss = 1.54881198, grad/param norm = 1.6324e-01, time/batch = 17.0290s	
7167/30300 (epoch 11.827), train_loss = 1.33120534, grad/param norm = 1.6556e-01, time/batch = 18.5168s	
7168/30300 (epoch 11.828), train_loss = 1.48507763, grad/param norm = 1.5019e-01, time/batch = 19.3648s	
7169/30300 (epoch 11.830), train_loss = 1.47208607, grad/param norm = 1.5452e-01, time/batch = 18.6164s	
7170/30300 (epoch 11.832), train_loss = 1.38805639, grad/param norm = 1.5638e-01, time/batch = 19.4755s	
7171/30300 (epoch 11.833), train_loss = 1.51356068, grad/param norm = 1.6353e-01, time/batch = 18.8852s	
7172/30300 (epoch 11.835), train_loss = 1.41109751, grad/param norm = 1.5689e-01, time/batch = 17.1820s	
7173/30300 (epoch 11.837), train_loss = 1.25618013, grad/param norm = 1.3641e-01, time/batch = 19.3129s	
7174/30300 (epoch 11.838), train_loss = 1.31197795, grad/param norm = 1.5912e-01, time/batch = 18.8023s	
7175/30300 (epoch 11.840), train_loss = 1.47414909, grad/param norm = 1.3900e-01, time/batch = 18.5357s	
7176/30300 (epoch 11.842), train_loss = 1.27555183, grad/param norm = 1.2849e-01, time/batch = 19.2865s	
7177/30300 (epoch 11.843), train_loss = 1.43414631, grad/param norm = 1.4086e-01, time/batch = 19.5508s	
7178/30300 (epoch 11.845), train_loss = 1.39876290, grad/param norm = 1.3091e-01, time/batch = 18.3753s	
7179/30300 (epoch 11.847), train_loss = 1.47070904, grad/param norm = 1.6737e-01, time/batch = 18.5404s	
7180/30300 (epoch 11.848), train_loss = 1.55444586, grad/param norm = 1.5489e-01, time/batch = 18.5517s	
7181/30300 (epoch 11.850), train_loss = 1.38290462, grad/param norm = 1.4116e-01, time/batch = 19.8042s	
7182/30300 (epoch 11.851), train_loss = 1.56088183, grad/param norm = 1.6876e-01, time/batch = 17.0071s	
7183/30300 (epoch 11.853), train_loss = 1.35055198, grad/param norm = 1.4128e-01, time/batch = 19.1899s	
7184/30300 (epoch 11.855), train_loss = 1.36469065, grad/param norm = 1.3569e-01, time/batch = 19.5471s	
7185/30300 (epoch 11.856), train_loss = 1.37323058, grad/param norm = 1.4771e-01, time/batch = 17.7064s	
7186/30300 (epoch 11.858), train_loss = 1.33944172, grad/param norm = 1.3541e-01, time/batch = 19.9615s	
7187/30300 (epoch 11.860), train_loss = 1.37847595, grad/param norm = 1.4583e-01, time/batch = 19.6168s	
7188/30300 (epoch 11.861), train_loss = 1.59949116, grad/param norm = 1.5151e-01, time/batch = 17.6122s	
7189/30300 (epoch 11.863), train_loss = 1.44043996, grad/param norm = 1.4162e-01, time/batch = 19.5421s	
7190/30300 (epoch 11.865), train_loss = 1.59636678, grad/param norm = 1.5398e-01, time/batch = 19.3742s	
7191/30300 (epoch 11.866), train_loss = 1.49909948, grad/param norm = 1.5384e-01, time/batch = 18.4413s	
7192/30300 (epoch 11.868), train_loss = 1.42763119, grad/param norm = 1.4201e-01, time/batch = 18.2005s	
7193/30300 (epoch 11.870), train_loss = 1.40530699, grad/param norm = 1.4516e-01, time/batch = 19.8771s	
7194/30300 (epoch 11.871), train_loss = 1.36789330, grad/param norm = 1.3354e-01, time/batch = 18.9611s	
7195/30300 (epoch 11.873), train_loss = 1.43546608, grad/param norm = 1.3614e-01, time/batch = 18.3865s	
7196/30300 (epoch 11.875), train_loss = 1.28939015, grad/param norm = 1.3621e-01, time/batch = 19.3601s	
7197/30300 (epoch 11.876), train_loss = 1.32294401, grad/param norm = 1.4424e-01, time/batch = 18.7100s	
7198/30300 (epoch 11.878), train_loss = 1.19810919, grad/param norm = 1.4979e-01, time/batch = 17.7111s	
7199/30300 (epoch 11.880), train_loss = 1.31290353, grad/param norm = 1.3820e-01, time/batch = 19.4681s	
7200/30300 (epoch 11.881), train_loss = 1.67585035, grad/param norm = 1.7075e-01, time/batch = 19.7017s	
7201/30300 (epoch 11.883), train_loss = 1.48493464, grad/param norm = 1.5063e-01, time/batch = 18.0443s	
7202/30300 (epoch 11.884), train_loss = 1.25526065, grad/param norm = 1.2895e-01, time/batch = 17.5433s	
7203/30300 (epoch 11.886), train_loss = 1.42856227, grad/param norm = 1.4972e-01, time/batch = 19.2934s	
7204/30300 (epoch 11.888), train_loss = 1.46983274, grad/param norm = 1.5863e-01, time/batch = 16.7922s	
7205/30300 (epoch 11.889), train_loss = 1.39864446, grad/param norm = 1.5115e-01, time/batch = 19.0309s	
7206/30300 (epoch 11.891), train_loss = 1.39556217, grad/param norm = 1.4372e-01, time/batch = 18.8019s	
7207/30300 (epoch 11.893), train_loss = 1.69301111, grad/param norm = 1.6602e-01, time/batch = 18.8676s	
7208/30300 (epoch 11.894), train_loss = 1.54419164, grad/param norm = 1.5164e-01, time/batch = 19.5308s	
7209/30300 (epoch 11.896), train_loss = 1.23810088, grad/param norm = 1.3515e-01, time/batch = 19.2839s	
7210/30300 (epoch 11.898), train_loss = 1.21213541, grad/param norm = 1.4756e-01, time/batch = 17.6200s	
7211/30300 (epoch 11.899), train_loss = 1.35874551, grad/param norm = 1.4322e-01, time/batch = 18.7928s	
7212/30300 (epoch 11.901), train_loss = 1.42797601, grad/param norm = 1.5530e-01, time/batch = 19.4702s	
7213/30300 (epoch 11.903), train_loss = 1.47381398, grad/param norm = 1.5667e-01, time/batch = 18.6411s	
7214/30300 (epoch 11.904), train_loss = 1.35591950, grad/param norm = 1.4316e-01, time/batch = 18.9494s	
7215/30300 (epoch 11.906), train_loss = 1.57534961, grad/param norm = 1.5539e-01, time/batch = 16.9423s	
7216/30300 (epoch 11.908), train_loss = 1.29943186, grad/param norm = 1.3714e-01, time/batch = 19.1867s	
7217/30300 (epoch 11.909), train_loss = 1.37525172, grad/param norm = 1.6773e-01, time/batch = 17.3854s	
7218/30300 (epoch 11.911), train_loss = 1.40751989, grad/param norm = 1.5068e-01, time/batch = 19.0327s	
7219/30300 (epoch 11.913), train_loss = 1.41672202, grad/param norm = 1.4271e-01, time/batch = 19.3021s	
7220/30300 (epoch 11.914), train_loss = 1.41431467, grad/param norm = 1.5864e-01, time/batch = 18.0545s	
7221/30300 (epoch 11.916), train_loss = 1.44266065, grad/param norm = 1.4800e-01, time/batch = 19.0986s	
7222/30300 (epoch 11.917), train_loss = 1.33159950, grad/param norm = 1.4063e-01, time/batch = 17.9281s	
7223/30300 (epoch 11.919), train_loss = 1.40277965, grad/param norm = 1.5348e-01, time/batch = 18.7874s	
7224/30300 (epoch 11.921), train_loss = 1.43558114, grad/param norm = 1.4727e-01, time/batch = 16.0267s	
7225/30300 (epoch 11.922), train_loss = 1.51808807, grad/param norm = 1.6236e-01, time/batch = 19.0378s	
7226/30300 (epoch 11.924), train_loss = 1.42587725, grad/param norm = 1.5189e-01, time/batch = 19.4644s	
7227/30300 (epoch 11.926), train_loss = 1.39375541, grad/param norm = 1.4758e-01, time/batch = 19.3785s	
7228/30300 (epoch 11.927), train_loss = 1.41277992, grad/param norm = 1.5199e-01, time/batch = 19.1253s	
7229/30300 (epoch 11.929), train_loss = 1.38473589, grad/param norm = 1.6189e-01, time/batch = 19.7023s	
7230/30300 (epoch 11.931), train_loss = 1.58413635, grad/param norm = 1.7760e-01, time/batch = 31.5419s	
7231/30300 (epoch 11.932), train_loss = 1.35412283, grad/param norm = 1.5625e-01, time/batch = 20.1149s	
7232/30300 (epoch 11.934), train_loss = 1.44098220, grad/param norm = 1.4743e-01, time/batch = 18.2814s	
7233/30300 (epoch 11.936), train_loss = 1.38145975, grad/param norm = 1.4036e-01, time/batch = 19.1351s	
7234/30300 (epoch 11.937), train_loss = 1.38415259, grad/param norm = 1.5196e-01, time/batch = 16.9603s	
7235/30300 (epoch 11.939), train_loss = 1.53773437, grad/param norm = 1.5712e-01, time/batch = 18.2698s	
7236/30300 (epoch 11.941), train_loss = 1.41775733, grad/param norm = 1.5970e-01, time/batch = 18.5359s	
7237/30300 (epoch 11.942), train_loss = 1.42815098, grad/param norm = 1.5586e-01, time/batch = 19.2156s	
7238/30300 (epoch 11.944), train_loss = 1.31995784, grad/param norm = 1.3499e-01, time/batch = 19.6257s	
7239/30300 (epoch 11.946), train_loss = 1.58906128, grad/param norm = 1.8376e-01, time/batch = 18.0235s	
7240/30300 (epoch 11.947), train_loss = 1.59413809, grad/param norm = 1.8702e-01, time/batch = 19.7025s	
7241/30300 (epoch 11.949), train_loss = 1.63984670, grad/param norm = 1.7017e-01, time/batch = 19.3785s	
7242/30300 (epoch 11.950), train_loss = 1.55391872, grad/param norm = 1.6036e-01, time/batch = 18.4546s	
7243/30300 (epoch 11.952), train_loss = 1.51967899, grad/param norm = 1.5637e-01, time/batch = 20.0253s	
7244/30300 (epoch 11.954), train_loss = 1.70597507, grad/param norm = 1.6236e-01, time/batch = 19.2140s	
7245/30300 (epoch 11.955), train_loss = 1.36491005, grad/param norm = 1.4081e-01, time/batch = 17.2678s	
7246/30300 (epoch 11.957), train_loss = 1.49410977, grad/param norm = 1.5585e-01, time/batch = 20.3671s	
7247/30300 (epoch 11.959), train_loss = 1.46132258, grad/param norm = 1.5723e-01, time/batch = 18.8023s	
7248/30300 (epoch 11.960), train_loss = 1.40564130, grad/param norm = 1.5558e-01, time/batch = 18.0433s	
7249/30300 (epoch 11.962), train_loss = 1.37296368, grad/param norm = 1.6790e-01, time/batch = 20.1201s	
7250/30300 (epoch 11.964), train_loss = 1.42228461, grad/param norm = 1.7202e-01, time/batch = 19.8666s	
7251/30300 (epoch 11.965), train_loss = 1.35802767, grad/param norm = 1.4986e-01, time/batch = 18.9526s	
7252/30300 (epoch 11.967), train_loss = 1.39065362, grad/param norm = 1.4705e-01, time/batch = 19.4508s	
7253/30300 (epoch 11.969), train_loss = 1.38748197, grad/param norm = 1.7487e-01, time/batch = 19.2888s	
7254/30300 (epoch 11.970), train_loss = 1.36219844, grad/param norm = 1.3841e-01, time/batch = 16.1769s	
7255/30300 (epoch 11.972), train_loss = 1.29655908, grad/param norm = 1.4322e-01, time/batch = 17.6260s	
7256/30300 (epoch 11.974), train_loss = 1.63524371, grad/param norm = 1.6711e-01, time/batch = 20.4615s	
7257/30300 (epoch 11.975), train_loss = 1.63408619, grad/param norm = 1.8959e-01, time/batch = 18.9568s	
7258/30300 (epoch 11.977), train_loss = 1.51598600, grad/param norm = 1.6187e-01, time/batch = 18.8705s	
7259/30300 (epoch 11.979), train_loss = 1.47115939, grad/param norm = 1.5697e-01, time/batch = 19.6115s	
7260/30300 (epoch 11.980), train_loss = 1.53220298, grad/param norm = 1.6990e-01, time/batch = 19.6257s	
7261/30300 (epoch 11.982), train_loss = 1.53591212, grad/param norm = 1.5969e-01, time/batch = 19.2875s	
7262/30300 (epoch 11.983), train_loss = 1.56071382, grad/param norm = 1.5540e-01, time/batch = 19.3845s	
7263/30300 (epoch 11.985), train_loss = 1.44681192, grad/param norm = 1.5781e-01, time/batch = 18.7011s	
7264/30300 (epoch 11.987), train_loss = 1.40081412, grad/param norm = 1.3855e-01, time/batch = 17.9379s	
7265/30300 (epoch 11.988), train_loss = 1.59938964, grad/param norm = 1.5164e-01, time/batch = 20.0374s	
7266/30300 (epoch 11.990), train_loss = 1.24895943, grad/param norm = 1.3494e-01, time/batch = 18.7221s	
7267/30300 (epoch 11.992), train_loss = 1.48803979, grad/param norm = 1.3924e-01, time/batch = 17.3649s	
7268/30300 (epoch 11.993), train_loss = 1.56578727, grad/param norm = 1.6932e-01, time/batch = 18.7966s	
7269/30300 (epoch 11.995), train_loss = 1.44604771, grad/param norm = 1.5900e-01, time/batch = 18.5514s	
7270/30300 (epoch 11.997), train_loss = 1.47283687, grad/param norm = 1.5542e-01, time/batch = 18.2036s	
7271/30300 (epoch 11.998), train_loss = 1.54384405, grad/param norm = 1.6498e-01, time/batch = 26.0923s	
decayed learning rate by a factor 0.97 to 0.001825346	
7272/30300 (epoch 12.000), train_loss = 1.35536307, grad/param norm = 1.5058e-01, time/batch = 19.2797s	
7273/30300 (epoch 12.002), train_loss = 1.49019555, grad/param norm = 1.6299e-01, time/batch = 19.0142s	
7274/30300 (epoch 12.003), train_loss = 1.44466789, grad/param norm = 1.4716e-01, time/batch = 18.9605s	
7275/30300 (epoch 12.005), train_loss = 1.41452209, grad/param norm = 1.6343e-01, time/batch = 18.5457s	
7276/30300 (epoch 12.007), train_loss = 1.54386025, grad/param norm = 1.6077e-01, time/batch = 18.2916s	
7277/30300 (epoch 12.008), train_loss = 1.37013106, grad/param norm = 1.5117e-01, time/batch = 18.4713s	
7278/30300 (epoch 12.010), train_loss = 1.33249614, grad/param norm = 1.4399e-01, time/batch = 19.9525s	
7279/30300 (epoch 12.012), train_loss = 1.33441187, grad/param norm = 1.4389e-01, time/batch = 18.4716s	
7280/30300 (epoch 12.013), train_loss = 1.48436510, grad/param norm = 1.6307e-01, time/batch = 17.7953s	
7281/30300 (epoch 12.015), train_loss = 1.39628353, grad/param norm = 1.4486e-01, time/batch = 20.4503s	
7282/30300 (epoch 12.017), train_loss = 1.32070878, grad/param norm = 1.3692e-01, time/batch = 17.8729s	
7283/30300 (epoch 12.018), train_loss = 1.37821526, grad/param norm = 1.4883e-01, time/batch = 17.9370s	
7284/30300 (epoch 12.020), train_loss = 1.55285502, grad/param norm = 1.6248e-01, time/batch = 19.7024s	
7285/30300 (epoch 12.021), train_loss = 1.53948754, grad/param norm = 1.5387e-01, time/batch = 18.9464s	
7286/30300 (epoch 12.023), train_loss = 1.36648821, grad/param norm = 1.3950e-01, time/batch = 17.4662s	
7287/30300 (epoch 12.025), train_loss = 1.34960639, grad/param norm = 1.5860e-01, time/batch = 19.1196s	
7288/30300 (epoch 12.026), train_loss = 1.48299947, grad/param norm = 1.5654e-01, time/batch = 19.3496s	
7289/30300 (epoch 12.028), train_loss = 1.49684137, grad/param norm = 1.4897e-01, time/batch = 18.1091s	
7290/30300 (epoch 12.030), train_loss = 1.34482377, grad/param norm = 1.4169e-01, time/batch = 18.8850s	
7291/30300 (epoch 12.031), train_loss = 1.42773170, grad/param norm = 1.6140e-01, time/batch = 19.7131s	
7292/30300 (epoch 12.033), train_loss = 1.43829694, grad/param norm = 1.5772e-01, time/batch = 17.6171s	
7293/30300 (epoch 12.035), train_loss = 1.52855612, grad/param norm = 1.5139e-01, time/batch = 18.3133s	
7294/30300 (epoch 12.036), train_loss = 1.45973319, grad/param norm = 1.6085e-01, time/batch = 19.9701s	
7295/30300 (epoch 12.038), train_loss = 1.42687053, grad/param norm = 1.4924e-01, time/batch = 18.4592s	
7296/30300 (epoch 12.040), train_loss = 1.14161181, grad/param norm = 1.3133e-01, time/batch = 18.8642s	
7297/30300 (epoch 12.041), train_loss = 1.19817793, grad/param norm = 1.3597e-01, time/batch = 19.4669s	
7298/30300 (epoch 12.043), train_loss = 1.47472042, grad/param norm = 1.5807e-01, time/batch = 16.6790s	
7299/30300 (epoch 12.045), train_loss = 1.38345011, grad/param norm = 1.5124e-01, time/batch = 19.1339s	
7300/30300 (epoch 12.046), train_loss = 1.52588320, grad/param norm = 1.7122e-01, time/batch = 18.5422s	
7301/30300 (epoch 12.048), train_loss = 1.47451821, grad/param norm = 1.7052e-01, time/batch = 18.8723s	
7302/30300 (epoch 12.050), train_loss = 1.46224540, grad/param norm = 1.5238e-01, time/batch = 19.4503s	
7303/30300 (epoch 12.051), train_loss = 1.45214716, grad/param norm = 1.6805e-01, time/batch = 19.1210s	
7304/30300 (epoch 12.053), train_loss = 1.26970340, grad/param norm = 1.6026e-01, time/batch = 18.6364s	
7305/30300 (epoch 12.054), train_loss = 1.38725077, grad/param norm = 1.6335e-01, time/batch = 19.0397s	
7306/30300 (epoch 12.056), train_loss = 1.32678831, grad/param norm = 1.4601e-01, time/batch = 19.3790s	
7307/30300 (epoch 12.058), train_loss = 1.39089130, grad/param norm = 1.4801e-01, time/batch = 19.9632s	
7308/30300 (epoch 12.059), train_loss = 1.34809784, grad/param norm = 1.5628e-01, time/batch = 18.3732s	
7309/30300 (epoch 12.061), train_loss = 1.57051657, grad/param norm = 1.7035e-01, time/batch = 16.9666s	
7310/30300 (epoch 12.063), train_loss = 1.37851753, grad/param norm = 1.5199e-01, time/batch = 20.1237s	
7311/30300 (epoch 12.064), train_loss = 1.49898910, grad/param norm = 1.5323e-01, time/batch = 17.5461s	
7312/30300 (epoch 12.066), train_loss = 1.38892421, grad/param norm = 1.3800e-01, time/batch = 17.6201s	
7313/30300 (epoch 12.068), train_loss = 1.27591924, grad/param norm = 1.4100e-01, time/batch = 16.0904s	
7314/30300 (epoch 12.069), train_loss = 1.53460838, grad/param norm = 1.5524e-01, time/batch = 18.8740s	
7315/30300 (epoch 12.071), train_loss = 1.46849560, grad/param norm = 1.5770e-01, time/batch = 18.2882s	
7316/30300 (epoch 12.073), train_loss = 1.44912045, grad/param norm = 1.6208e-01, time/batch = 18.8880s	
7317/30300 (epoch 12.074), train_loss = 1.47301706, grad/param norm = 1.4471e-01, time/batch = 19.9599s	
7318/30300 (epoch 12.076), train_loss = 1.38891824, grad/param norm = 1.4693e-01, time/batch = 18.3811s	
7319/30300 (epoch 12.078), train_loss = 1.30062614, grad/param norm = 1.4876e-01, time/batch = 19.3841s	
7320/30300 (epoch 12.079), train_loss = 1.32424668, grad/param norm = 1.3153e-01, time/batch = 18.0211s	
7321/30300 (epoch 12.081), train_loss = 1.45554619, grad/param norm = 1.5418e-01, time/batch = 18.6176s	
7322/30300 (epoch 12.083), train_loss = 1.55252737, grad/param norm = 1.8877e-01, time/batch = 19.0494s	
7323/30300 (epoch 12.084), train_loss = 1.30519675, grad/param norm = 1.5677e-01, time/batch = 19.7190s	
7324/30300 (epoch 12.086), train_loss = 1.34126458, grad/param norm = 1.4439e-01, time/batch = 17.1929s	
7325/30300 (epoch 12.087), train_loss = 1.27978635, grad/param norm = 1.3108e-01, time/batch = 18.1808s	
7326/30300 (epoch 12.089), train_loss = 1.37196986, grad/param norm = 1.5864e-01, time/batch = 20.2008s	
7327/30300 (epoch 12.091), train_loss = 1.50121345, grad/param norm = 1.6202e-01, time/batch = 17.8676s	
7328/30300 (epoch 12.092), train_loss = 1.41055838, grad/param norm = 1.5833e-01, time/batch = 19.6062s	
7329/30300 (epoch 12.094), train_loss = 1.61551202, grad/param norm = 1.6443e-01, time/batch = 18.5322s	
7330/30300 (epoch 12.096), train_loss = 1.51909412, grad/param norm = 1.7825e-01, time/batch = 17.3782s	
7331/30300 (epoch 12.097), train_loss = 1.30594565, grad/param norm = 1.4203e-01, time/batch = 19.6040s	
7332/30300 (epoch 12.099), train_loss = 1.58999738, grad/param norm = 1.6263e-01, time/batch = 17.2733s	
7333/30300 (epoch 12.101), train_loss = 1.64486841, grad/param norm = 1.7281e-01, time/batch = 19.7961s	
7334/30300 (epoch 12.102), train_loss = 1.41793573, grad/param norm = 1.7332e-01, time/batch = 18.5309s	
7335/30300 (epoch 12.104), train_loss = 1.39557556, grad/param norm = 1.6680e-01, time/batch = 18.9454s	
7336/30300 (epoch 12.106), train_loss = 1.44180531, grad/param norm = 1.6106e-01, time/batch = 18.2716s	
7337/30300 (epoch 12.107), train_loss = 1.44018677, grad/param norm = 1.4752e-01, time/batch = 17.5382s	
7338/30300 (epoch 12.109), train_loss = 1.54095622, grad/param norm = 1.6613e-01, time/batch = 19.4515s	
7339/30300 (epoch 12.111), train_loss = 1.56623298, grad/param norm = 1.6248e-01, time/batch = 19.4585s	
7340/30300 (epoch 12.112), train_loss = 1.46280748, grad/param norm = 1.4558e-01, time/batch = 17.0502s	
7341/30300 (epoch 12.114), train_loss = 1.42981082, grad/param norm = 1.4966e-01, time/batch = 17.5478s	
7342/30300 (epoch 12.116), train_loss = 1.46115256, grad/param norm = 1.5669e-01, time/batch = 16.0505s	
7343/30300 (epoch 12.117), train_loss = 1.43518821, grad/param norm = 1.4298e-01, time/batch = 18.7008s	
7344/30300 (epoch 12.119), train_loss = 1.33717863, grad/param norm = 1.5354e-01, time/batch = 17.9514s	
7345/30300 (epoch 12.120), train_loss = 1.42740557, grad/param norm = 1.6215e-01, time/batch = 19.0569s	
7346/30300 (epoch 12.122), train_loss = 1.50991411, grad/param norm = 1.5786e-01, time/batch = 19.8745s	
7347/30300 (epoch 12.124), train_loss = 1.63496596, grad/param norm = 1.7337e-01, time/batch = 18.0470s	
7348/30300 (epoch 12.125), train_loss = 1.28159250, grad/param norm = 1.3950e-01, time/batch = 19.2087s	
7349/30300 (epoch 12.127), train_loss = 1.42514483, grad/param norm = 1.6037e-01, time/batch = 19.2909s	
7350/30300 (epoch 12.129), train_loss = 1.58243986, grad/param norm = 1.4934e-01, time/batch = 18.7886s	
7351/30300 (epoch 12.130), train_loss = 1.57252189, grad/param norm = 1.5063e-01, time/batch = 19.5292s	
7352/30300 (epoch 12.132), train_loss = 1.49351033, grad/param norm = 1.5923e-01, time/batch = 18.8051s	
7353/30300 (epoch 12.134), train_loss = 1.33108341, grad/param norm = 1.5277e-01, time/batch = 18.3693s	
7354/30300 (epoch 12.135), train_loss = 1.36709450, grad/param norm = 1.6193e-01, time/batch = 17.2862s	
7355/30300 (epoch 12.137), train_loss = 1.50070345, grad/param norm = 1.5612e-01, time/batch = 19.5240s	
7356/30300 (epoch 12.139), train_loss = 1.39849140, grad/param norm = 1.5321e-01, time/batch = 17.9655s	
7357/30300 (epoch 12.140), train_loss = 1.57798986, grad/param norm = 1.7685e-01, time/batch = 19.9519s	
7358/30300 (epoch 12.142), train_loss = 1.65482043, grad/param norm = 1.8284e-01, time/batch = 19.9541s	
7359/30300 (epoch 12.144), train_loss = 1.49835567, grad/param norm = 1.6665e-01, time/batch = 17.5500s	
7360/30300 (epoch 12.145), train_loss = 1.58077798, grad/param norm = 1.6537e-01, time/batch = 20.0350s	
7361/30300 (epoch 12.147), train_loss = 1.48609480, grad/param norm = 2.6355e-01, time/batch = 18.7983s	
7362/30300 (epoch 12.149), train_loss = 1.67021831, grad/param norm = 1.8089e-01, time/batch = 18.9522s	
7363/30300 (epoch 12.150), train_loss = 1.53116855, grad/param norm = 1.6872e-01, time/batch = 18.8581s	
7364/30300 (epoch 12.152), train_loss = 1.32028230, grad/param norm = 1.5642e-01, time/batch = 17.6014s	
7365/30300 (epoch 12.153), train_loss = 1.46001351, grad/param norm = 1.7088e-01, time/batch = 19.6196s	
7366/30300 (epoch 12.155), train_loss = 1.23466946, grad/param norm = 1.3520e-01, time/batch = 18.4549s	
7367/30300 (epoch 12.157), train_loss = 1.42598649, grad/param norm = 1.7792e-01, time/batch = 18.2184s	
7368/30300 (epoch 12.158), train_loss = 1.46888775, grad/param norm = 1.5285e-01, time/batch = 18.7890s	
7369/30300 (epoch 12.160), train_loss = 1.37334223, grad/param norm = 1.4523e-01, time/batch = 17.9610s	
7370/30300 (epoch 12.162), train_loss = 1.37841773, grad/param norm = 1.5035e-01, time/batch = 18.9686s	
7371/30300 (epoch 12.163), train_loss = 1.37858440, grad/param norm = 1.5758e-01, time/batch = 17.8700s	
7372/30300 (epoch 12.165), train_loss = 1.50561032, grad/param norm = 1.5454e-01, time/batch = 18.3773s	
7373/30300 (epoch 12.167), train_loss = 1.47259679, grad/param norm = 1.5923e-01, time/batch = 18.6287s	
7374/30300 (epoch 12.168), train_loss = 1.44014985, grad/param norm = 1.4604e-01, time/batch = 17.8081s	
7375/30300 (epoch 12.170), train_loss = 1.46842271, grad/param norm = 1.5139e-01, time/batch = 17.9628s	
7376/30300 (epoch 12.172), train_loss = 1.37631381, grad/param norm = 1.5335e-01, time/batch = 19.2093s	
7377/30300 (epoch 12.173), train_loss = 1.49769182, grad/param norm = 1.6452e-01, time/batch = 18.7190s	
7378/30300 (epoch 12.175), train_loss = 1.42823457, grad/param norm = 1.4046e-01, time/batch = 19.5395s	
7379/30300 (epoch 12.177), train_loss = 1.43822620, grad/param norm = 1.5550e-01, time/batch = 18.3412s	
7380/30300 (epoch 12.178), train_loss = 1.17439732, grad/param norm = 1.3541e-01, time/batch = 17.7817s	
7381/30300 (epoch 12.180), train_loss = 1.34127442, grad/param norm = 1.3730e-01, time/batch = 18.8764s	
7382/30300 (epoch 12.182), train_loss = 1.34951061, grad/param norm = 1.7068e-01, time/batch = 17.7912s	
7383/30300 (epoch 12.183), train_loss = 1.34104833, grad/param norm = 1.4052e-01, time/batch = 18.6390s	
7384/30300 (epoch 12.185), train_loss = 1.68296424, grad/param norm = 1.4953e-01, time/batch = 18.0546s	
7385/30300 (epoch 12.186), train_loss = 1.69405045, grad/param norm = 1.7035e-01, time/batch = 18.1244s	
7386/30300 (epoch 12.188), train_loss = 1.51033837, grad/param norm = 1.6171e-01, time/batch = 18.7256s	
7387/30300 (epoch 12.190), train_loss = 1.38796479, grad/param norm = 1.4425e-01, time/batch = 18.3014s	
7388/30300 (epoch 12.191), train_loss = 1.50142332, grad/param norm = 1.5501e-01, time/batch = 18.5306s	
7389/30300 (epoch 12.193), train_loss = 1.31040279, grad/param norm = 1.4375e-01, time/batch = 17.5552s	
7390/30300 (epoch 12.195), train_loss = 1.46024603, grad/param norm = 1.5366e-01, time/batch = 19.6119s	
7391/30300 (epoch 12.196), train_loss = 1.42103463, grad/param norm = 1.3707e-01, time/batch = 18.9617s	
7392/30300 (epoch 12.198), train_loss = 1.20421972, grad/param norm = 1.4279e-01, time/batch = 18.5365s	
7393/30300 (epoch 12.200), train_loss = 1.42374437, grad/param norm = 1.4130e-01, time/batch = 19.2849s	
7394/30300 (epoch 12.201), train_loss = 1.51253355, grad/param norm = 1.5989e-01, time/batch = 18.7933s	
7395/30300 (epoch 12.203), train_loss = 1.40106045, grad/param norm = 1.4959e-01, time/batch = 17.6241s	
7396/30300 (epoch 12.205), train_loss = 1.64791358, grad/param norm = 1.5734e-01, time/batch = 19.4587s	
7397/30300 (epoch 12.206), train_loss = 1.61252185, grad/param norm = 1.5949e-01, time/batch = 18.6305s	
7398/30300 (epoch 12.208), train_loss = 1.56717183, grad/param norm = 1.7997e-01, time/batch = 18.0229s	
7399/30300 (epoch 12.210), train_loss = 1.46499137, grad/param norm = 1.4516e-01, time/batch = 19.3721s	
7400/30300 (epoch 12.211), train_loss = 1.49978896, grad/param norm = 1.5263e-01, time/batch = 19.5379s	
7401/30300 (epoch 12.213), train_loss = 1.34304147, grad/param norm = 1.4033e-01, time/batch = 18.8727s	
7402/30300 (epoch 12.215), train_loss = 1.25571266, grad/param norm = 1.5049e-01, time/batch = 19.5588s	
7403/30300 (epoch 12.216), train_loss = 1.40882621, grad/param norm = 1.6100e-01, time/batch = 19.4602s	
7404/30300 (epoch 12.218), train_loss = 1.32365540, grad/param norm = 1.2872e-01, time/batch = 18.0367s	
7405/30300 (epoch 12.219), train_loss = 1.23523970, grad/param norm = 1.2770e-01, time/batch = 18.0160s	
7406/30300 (epoch 12.221), train_loss = 1.27008916, grad/param norm = 1.4312e-01, time/batch = 19.9571s	
7407/30300 (epoch 12.223), train_loss = 1.44019966, grad/param norm = 1.5233e-01, time/batch = 18.8787s	
7408/30300 (epoch 12.224), train_loss = 1.24313314, grad/param norm = 1.4316e-01, time/batch = 18.8749s	
7409/30300 (epoch 12.226), train_loss = 1.54472618, grad/param norm = 1.7611e-01, time/batch = 17.2981s	
7410/30300 (epoch 12.228), train_loss = 1.55307791, grad/param norm = 1.5289e-01, time/batch = 19.1359s	
7411/30300 (epoch 12.229), train_loss = 1.32970223, grad/param norm = 1.5633e-01, time/batch = 18.4583s	
7412/30300 (epoch 12.231), train_loss = 1.45685887, grad/param norm = 1.4635e-01, time/batch = 20.1901s	
7413/30300 (epoch 12.233), train_loss = 1.37148846, grad/param norm = 1.5013e-01, time/batch = 19.2029s	
7414/30300 (epoch 12.234), train_loss = 1.48832965, grad/param norm = 1.6086e-01, time/batch = 18.4527s	
7415/30300 (epoch 12.236), train_loss = 1.33751599, grad/param norm = 1.4281e-01, time/batch = 19.3575s	
7416/30300 (epoch 12.238), train_loss = 1.46738761, grad/param norm = 1.7033e-01, time/batch = 19.1239s	
7417/30300 (epoch 12.239), train_loss = 1.44034142, grad/param norm = 1.4939e-01, time/batch = 18.8653s	
7418/30300 (epoch 12.241), train_loss = 1.50453797, grad/param norm = 1.7787e-01, time/batch = 19.5409s	
7419/30300 (epoch 12.243), train_loss = 1.46380982, grad/param norm = 1.5171e-01, time/batch = 19.8851s	
7420/30300 (epoch 12.244), train_loss = 1.68196179, grad/param norm = 1.6724e-01, time/batch = 30.8670s	
7421/30300 (epoch 12.246), train_loss = 1.39029651, grad/param norm = 1.5076e-01, time/batch = 19.6214s	
7422/30300 (epoch 12.248), train_loss = 1.39849901, grad/param norm = 1.4357e-01, time/batch = 18.6204s	
7423/30300 (epoch 12.249), train_loss = 1.30661890, grad/param norm = 1.4632e-01, time/batch = 18.6177s	
7424/30300 (epoch 12.251), train_loss = 1.31138708, grad/param norm = 1.4904e-01, time/batch = 17.8737s	
7425/30300 (epoch 12.252), train_loss = 1.56698789, grad/param norm = 1.5640e-01, time/batch = 19.1967s	
7426/30300 (epoch 12.254), train_loss = 1.54440773, grad/param norm = 1.6537e-01, time/batch = 19.0180s	
7427/30300 (epoch 12.256), train_loss = 1.43574949, grad/param norm = 1.4486e-01, time/batch = 17.9514s	
7428/30300 (epoch 12.257), train_loss = 1.53970883, grad/param norm = 1.6656e-01, time/batch = 20.0425s	
7429/30300 (epoch 12.259), train_loss = 1.44883080, grad/param norm = 1.5176e-01, time/batch = 18.2792s	
7430/30300 (epoch 12.261), train_loss = 1.55348154, grad/param norm = 1.4768e-01, time/batch = 17.5348s	
7431/30300 (epoch 12.262), train_loss = 1.40248410, grad/param norm = 1.4324e-01, time/batch = 18.3795s	
7432/30300 (epoch 12.264), train_loss = 1.41852312, grad/param norm = 1.6441e-01, time/batch = 18.5299s	
7433/30300 (epoch 12.266), train_loss = 1.34783676, grad/param norm = 1.4038e-01, time/batch = 19.8797s	
7434/30300 (epoch 12.267), train_loss = 1.60273092, grad/param norm = 1.6771e-01, time/batch = 19.2095s	
7435/30300 (epoch 12.269), train_loss = 1.42729387, grad/param norm = 1.5078e-01, time/batch = 17.7824s	
7436/30300 (epoch 12.271), train_loss = 1.42213903, grad/param norm = 1.4791e-01, time/batch = 17.7498s	
7437/30300 (epoch 12.272), train_loss = 1.46914735, grad/param norm = 1.5707e-01, time/batch = 20.0250s	
7438/30300 (epoch 12.274), train_loss = 1.60002179, grad/param norm = 1.5556e-01, time/batch = 17.7959s	
7439/30300 (epoch 12.276), train_loss = 1.52800656, grad/param norm = 1.6304e-01, time/batch = 19.6114s	
7440/30300 (epoch 12.277), train_loss = 1.34247645, grad/param norm = 1.4748e-01, time/batch = 19.0445s	
7441/30300 (epoch 12.279), train_loss = 1.47874436, grad/param norm = 1.5746e-01, time/batch = 15.2079s	
7442/30300 (epoch 12.281), train_loss = 1.52808828, grad/param norm = 1.7668e-01, time/batch = 18.6227s	
7443/30300 (epoch 12.282), train_loss = 1.39498242, grad/param norm = 1.3517e-01, time/batch = 18.9684s	
7444/30300 (epoch 12.284), train_loss = 1.60661280, grad/param norm = 1.7625e-01, time/batch = 20.2823s	
7445/30300 (epoch 12.285), train_loss = 1.44571294, grad/param norm = 1.5030e-01, time/batch = 16.5222s	
7446/30300 (epoch 12.287), train_loss = 1.43863476, grad/param norm = 1.5416e-01, time/batch = 18.6159s	
7447/30300 (epoch 12.289), train_loss = 1.49466654, grad/param norm = 1.6153e-01, time/batch = 17.1813s	
7448/30300 (epoch 12.290), train_loss = 1.17416358, grad/param norm = 1.3109e-01, time/batch = 17.7121s	
7449/30300 (epoch 12.292), train_loss = 1.30009555, grad/param norm = 1.3259e-01, time/batch = 19.0272s	
7450/30300 (epoch 12.294), train_loss = 1.59658941, grad/param norm = 1.5773e-01, time/batch = 19.3727s	
7451/30300 (epoch 12.295), train_loss = 1.40851099, grad/param norm = 1.4240e-01, time/batch = 18.2119s	
7452/30300 (epoch 12.297), train_loss = 1.33740089, grad/param norm = 1.3715e-01, time/batch = 19.2749s	
7453/30300 (epoch 12.299), train_loss = 1.40563973, grad/param norm = 1.5403e-01, time/batch = 18.3908s	
7454/30300 (epoch 12.300), train_loss = 1.45204025, grad/param norm = 1.5118e-01, time/batch = 19.2030s	
7455/30300 (epoch 12.302), train_loss = 1.36881458, grad/param norm = 1.4897e-01, time/batch = 16.6947s	
7456/30300 (epoch 12.304), train_loss = 1.31385794, grad/param norm = 1.4110e-01, time/batch = 19.4401s	
7457/30300 (epoch 12.305), train_loss = 1.35243579, grad/param norm = 1.4468e-01, time/batch = 19.1259s	
7458/30300 (epoch 12.307), train_loss = 1.43996525, grad/param norm = 1.4206e-01, time/batch = 16.8598s	
7459/30300 (epoch 12.309), train_loss = 1.51150644, grad/param norm = 1.4814e-01, time/batch = 18.8980s	
7460/30300 (epoch 12.310), train_loss = 1.39121933, grad/param norm = 1.4840e-01, time/batch = 18.7846s	
7461/30300 (epoch 12.312), train_loss = 1.52847989, grad/param norm = 1.4479e-01, time/batch = 18.6352s	
7462/30300 (epoch 12.314), train_loss = 1.46719273, grad/param norm = 1.4977e-01, time/batch = 19.3774s	
7463/30300 (epoch 12.315), train_loss = 1.48447758, grad/param norm = 1.5019e-01, time/batch = 18.6189s	
7464/30300 (epoch 12.317), train_loss = 1.52943417, grad/param norm = 1.5930e-01, time/batch = 18.2227s	
7465/30300 (epoch 12.318), train_loss = 1.59489792, grad/param norm = 1.7043e-01, time/batch = 19.7908s	
7466/30300 (epoch 12.320), train_loss = 1.56457829, grad/param norm = 1.7013e-01, time/batch = 18.3790s	
7467/30300 (epoch 12.322), train_loss = 1.32176776, grad/param norm = 1.4637e-01, time/batch = 18.6153s	
7468/30300 (epoch 12.323), train_loss = 1.55675522, grad/param norm = 1.6184e-01, time/batch = 18.7941s	
7469/30300 (epoch 12.325), train_loss = 1.40342399, grad/param norm = 1.3701e-01, time/batch = 18.9698s	
7470/30300 (epoch 12.327), train_loss = 1.38312027, grad/param norm = 1.3854e-01, time/batch = 19.1269s	
7471/30300 (epoch 12.328), train_loss = 1.38531554, grad/param norm = 1.3737e-01, time/batch = 18.8790s	
7472/30300 (epoch 12.330), train_loss = 1.49847005, grad/param norm = 1.4166e-01, time/batch = 19.3813s	
7473/30300 (epoch 12.332), train_loss = 1.53166852, grad/param norm = 1.6240e-01, time/batch = 19.5495s	
7474/30300 (epoch 12.333), train_loss = 1.43121812, grad/param norm = 1.5485e-01, time/batch = 18.2691s	
7475/30300 (epoch 12.335), train_loss = 1.26707320, grad/param norm = 1.3973e-01, time/batch = 19.2858s	
7476/30300 (epoch 12.337), train_loss = 1.59830614, grad/param norm = 1.5848e-01, time/batch = 20.1961s	
7477/30300 (epoch 12.338), train_loss = 1.34831595, grad/param norm = 1.4677e-01, time/batch = 17.9453s	
7478/30300 (epoch 12.340), train_loss = 1.30433391, grad/param norm = 1.3757e-01, time/batch = 16.9490s	
7479/30300 (epoch 12.342), train_loss = 1.51448061, grad/param norm = 1.5055e-01, time/batch = 18.3818s	
7480/30300 (epoch 12.343), train_loss = 1.50627553, grad/param norm = 1.5195e-01, time/batch = 18.1302s	
7481/30300 (epoch 12.345), train_loss = 1.44060548, grad/param norm = 1.4041e-01, time/batch = 19.0270s	
7482/30300 (epoch 12.347), train_loss = 1.24778845, grad/param norm = 1.2620e-01, time/batch = 19.4569s	
7483/30300 (epoch 12.348), train_loss = 1.31620213, grad/param norm = 1.5066e-01, time/batch = 18.3671s	
7484/30300 (epoch 12.350), train_loss = 1.41617935, grad/param norm = 1.4936e-01, time/batch = 19.1959s	
7485/30300 (epoch 12.351), train_loss = 1.43561794, grad/param norm = 1.5069e-01, time/batch = 19.4635s	
7486/30300 (epoch 12.353), train_loss = 1.22852708, grad/param norm = 1.4854e-01, time/batch = 17.0902s	
7487/30300 (epoch 12.355), train_loss = 1.37707633, grad/param norm = 1.4905e-01, time/batch = 19.7855s	
7488/30300 (epoch 12.356), train_loss = 1.52772726, grad/param norm = 1.5883e-01, time/batch = 19.3790s	
7489/30300 (epoch 12.358), train_loss = 1.60055293, grad/param norm = 1.4117e-01, time/batch = 19.7827s	
7490/30300 (epoch 12.360), train_loss = 1.36208330, grad/param norm = 1.4827e-01, time/batch = 18.7034s	
7491/30300 (epoch 12.361), train_loss = 1.44918634, grad/param norm = 1.5815e-01, time/batch = 18.7233s	
7492/30300 (epoch 12.363), train_loss = 1.49827926, grad/param norm = 1.5104e-01, time/batch = 20.3752s	
7493/30300 (epoch 12.365), train_loss = 1.33836364, grad/param norm = 1.5618e-01, time/batch = 18.3721s	
7494/30300 (epoch 12.366), train_loss = 1.34949993, grad/param norm = 1.4280e-01, time/batch = 17.1328s	
7495/30300 (epoch 12.368), train_loss = 1.22115498, grad/param norm = 1.5314e-01, time/batch = 18.7209s	
7496/30300 (epoch 12.370), train_loss = 1.30884338, grad/param norm = 1.4737e-01, time/batch = 18.4536s	
7497/30300 (epoch 12.371), train_loss = 1.47853462, grad/param norm = 1.4416e-01, time/batch = 20.3598s	
7498/30300 (epoch 12.373), train_loss = 1.32544189, grad/param norm = 1.3117e-01, time/batch = 18.9778s	
7499/30300 (epoch 12.375), train_loss = 1.32187299, grad/param norm = 1.2941e-01, time/batch = 17.8821s	
7500/30300 (epoch 12.376), train_loss = 1.35083336, grad/param norm = 1.4133e-01, time/batch = 19.6307s	
7501/30300 (epoch 12.378), train_loss = 1.36196285, grad/param norm = 1.4921e-01, time/batch = 19.1390s	
7502/30300 (epoch 12.380), train_loss = 1.62036229, grad/param norm = 1.5868e-01, time/batch = 18.8871s	
7503/30300 (epoch 12.381), train_loss = 1.30605799, grad/param norm = 1.4428e-01, time/batch = 17.6060s	
7504/30300 (epoch 12.383), train_loss = 1.39346460, grad/param norm = 1.6634e-01, time/batch = 19.2225s	
7505/30300 (epoch 12.384), train_loss = 1.51725978, grad/param norm = 1.5069e-01, time/batch = 18.6344s	
7506/30300 (epoch 12.386), train_loss = 1.28721785, grad/param norm = 1.5206e-01, time/batch = 19.1293s	
7507/30300 (epoch 12.388), train_loss = 1.26687677, grad/param norm = 1.2931e-01, time/batch = 19.6427s	
7508/30300 (epoch 12.389), train_loss = 1.43440816, grad/param norm = 1.6641e-01, time/batch = 16.8865s	
7509/30300 (epoch 12.391), train_loss = 1.48223618, grad/param norm = 1.4741e-01, time/batch = 17.9606s	
7510/30300 (epoch 12.393), train_loss = 1.23602049, grad/param norm = 1.3225e-01, time/batch = 19.7120s	
7511/30300 (epoch 12.394), train_loss = 1.44046750, grad/param norm = 1.4847e-01, time/batch = 19.2831s	
7512/30300 (epoch 12.396), train_loss = 1.58773512, grad/param norm = 1.4508e-01, time/batch = 18.2801s	
7513/30300 (epoch 12.398), train_loss = 1.36065389, grad/param norm = 1.2852e-01, time/batch = 18.8824s	
7514/30300 (epoch 12.399), train_loss = 1.40784080, grad/param norm = 1.5730e-01, time/batch = 20.2080s	
7515/30300 (epoch 12.401), train_loss = 1.49411206, grad/param norm = 1.4759e-01, time/batch = 16.7199s	
7516/30300 (epoch 12.403), train_loss = 1.36145541, grad/param norm = 1.4613e-01, time/batch = 18.0204s	
7517/30300 (epoch 12.404), train_loss = 1.31944040, grad/param norm = 1.6528e-01, time/batch = 17.0303s	
7518/30300 (epoch 12.406), train_loss = 1.41241951, grad/param norm = 1.4784e-01, time/batch = 18.7775s	
7519/30300 (epoch 12.408), train_loss = 1.27553230, grad/param norm = 1.4320e-01, time/batch = 19.5290s	
7520/30300 (epoch 12.409), train_loss = 1.23927319, grad/param norm = 1.3977e-01, time/batch = 17.5464s	
7521/30300 (epoch 12.411), train_loss = 1.26504067, grad/param norm = 1.3185e-01, time/batch = 18.5379s	
7522/30300 (epoch 12.413), train_loss = 1.21729752, grad/param norm = 1.4537e-01, time/batch = 19.1027s	
7523/30300 (epoch 12.414), train_loss = 1.54114056, grad/param norm = 1.5284e-01, time/batch = 19.1289s	
7524/30300 (epoch 12.416), train_loss = 1.38653568, grad/param norm = 1.5872e-01, time/batch = 18.7788s	
7525/30300 (epoch 12.417), train_loss = 1.33676232, grad/param norm = 1.4528e-01, time/batch = 19.0218s	
7526/30300 (epoch 12.419), train_loss = 1.26898924, grad/param norm = 1.3643e-01, time/batch = 18.6282s	
7527/30300 (epoch 12.421), train_loss = 1.35019391, grad/param norm = 1.3873e-01, time/batch = 19.0447s	
7528/30300 (epoch 12.422), train_loss = 1.36893977, grad/param norm = 1.3655e-01, time/batch = 17.3842s	
7529/30300 (epoch 12.424), train_loss = 1.40765521, grad/param norm = 1.4699e-01, time/batch = 20.1211s	
7530/30300 (epoch 12.426), train_loss = 1.27610736, grad/param norm = 1.4651e-01, time/batch = 18.8675s	
7531/30300 (epoch 12.427), train_loss = 1.37116371, grad/param norm = 1.5095e-01, time/batch = 13.8345s	
7532/30300 (epoch 12.429), train_loss = 1.41610726, grad/param norm = 1.5606e-01, time/batch = 0.6971s	
7533/30300 (epoch 12.431), train_loss = 1.47508493, grad/param norm = 1.5892e-01, time/batch = 0.6899s	
7534/30300 (epoch 12.432), train_loss = 1.37730518, grad/param norm = 1.4770e-01, time/batch = 0.6926s	
7535/30300 (epoch 12.434), train_loss = 1.23183870, grad/param norm = 1.4360e-01, time/batch = 0.7120s	
7536/30300 (epoch 12.436), train_loss = 1.55690726, grad/param norm = 1.5458e-01, time/batch = 0.6879s	
7537/30300 (epoch 12.437), train_loss = 1.31155968, grad/param norm = 1.5030e-01, time/batch = 0.6892s	
7538/30300 (epoch 12.439), train_loss = 1.32281012, grad/param norm = 1.4205e-01, time/batch = 0.6895s	
7539/30300 (epoch 12.441), train_loss = 1.33210193, grad/param norm = 1.3999e-01, time/batch = 1.0173s	
7540/30300 (epoch 12.442), train_loss = 1.28406276, grad/param norm = 1.4179e-01, time/batch = 1.0238s	
7541/30300 (epoch 12.444), train_loss = 1.17363180, grad/param norm = 1.3531e-01, time/batch = 1.0090s	
7542/30300 (epoch 12.446), train_loss = 1.34865662, grad/param norm = 1.4414e-01, time/batch = 1.0164s	
7543/30300 (epoch 12.447), train_loss = 1.38435082, grad/param norm = 1.4297e-01, time/batch = 1.1832s	
7544/30300 (epoch 12.449), train_loss = 1.32411167, grad/param norm = 1.4605e-01, time/batch = 1.8840s	
7545/30300 (epoch 12.450), train_loss = 1.51379931, grad/param norm = 1.5045e-01, time/batch = 1.8885s	
7546/30300 (epoch 12.452), train_loss = 1.42579747, grad/param norm = 1.3580e-01, time/batch = 11.6626s	
7547/30300 (epoch 12.454), train_loss = 1.40904293, grad/param norm = 1.3553e-01, time/batch = 19.0502s	
7548/30300 (epoch 12.455), train_loss = 1.47974440, grad/param norm = 1.5659e-01, time/batch = 18.2131s	
7549/30300 (epoch 12.457), train_loss = 1.43572056, grad/param norm = 1.4654e-01, time/batch = 19.1154s	
7550/30300 (epoch 12.459), train_loss = 1.48795035, grad/param norm = 1.5445e-01, time/batch = 19.9655s	
7551/30300 (epoch 12.460), train_loss = 1.44809280, grad/param norm = 1.5457e-01, time/batch = 18.2153s	
7552/30300 (epoch 12.462), train_loss = 1.50908816, grad/param norm = 1.4957e-01, time/batch = 19.7840s	
7553/30300 (epoch 12.464), train_loss = 1.25423304, grad/param norm = 1.5352e-01, time/batch = 17.6021s	
7554/30300 (epoch 12.465), train_loss = 1.21123418, grad/param norm = 1.3590e-01, time/batch = 19.3703s	
7555/30300 (epoch 12.467), train_loss = 1.16719308, grad/param norm = 1.2918e-01, time/batch = 18.9388s	
7556/30300 (epoch 12.469), train_loss = 1.30278059, grad/param norm = 1.4180e-01, time/batch = 19.3888s	
7557/30300 (epoch 12.470), train_loss = 1.35528423, grad/param norm = 1.4528e-01, time/batch = 19.1230s	
7558/30300 (epoch 12.472), train_loss = 1.33880202, grad/param norm = 1.3830e-01, time/batch = 18.5472s	
7559/30300 (epoch 12.474), train_loss = 1.40190248, grad/param norm = 1.6311e-01, time/batch = 19.8772s	
7560/30300 (epoch 12.475), train_loss = 1.30355750, grad/param norm = 1.4789e-01, time/batch = 19.1214s	
7561/30300 (epoch 12.477), train_loss = 1.42430135, grad/param norm = 1.5832e-01, time/batch = 17.1966s	
7562/30300 (epoch 12.479), train_loss = 1.41542325, grad/param norm = 1.6036e-01, time/batch = 19.6298s	
7563/30300 (epoch 12.480), train_loss = 1.43530483, grad/param norm = 1.3653e-01, time/batch = 19.7949s	
7564/30300 (epoch 12.482), train_loss = 1.44237723, grad/param norm = 1.3998e-01, time/batch = 18.4478s	
7565/30300 (epoch 12.483), train_loss = 1.34779961, grad/param norm = 1.5016e-01, time/batch = 19.9417s	
7566/30300 (epoch 12.485), train_loss = 1.39178451, grad/param norm = 1.4309e-01, time/batch = 18.2711s	
7567/30300 (epoch 12.487), train_loss = 1.44697225, grad/param norm = 1.5287e-01, time/batch = 18.3737s	
7568/30300 (epoch 12.488), train_loss = 1.46749100, grad/param norm = 1.4663e-01, time/batch = 17.3694s	
7569/30300 (epoch 12.490), train_loss = 1.30023664, grad/param norm = 1.4934e-01, time/batch = 19.9526s	
7570/30300 (epoch 12.492), train_loss = 1.39662843, grad/param norm = 1.5046e-01, time/batch = 18.5461s	
7571/30300 (epoch 12.493), train_loss = 1.34404704, grad/param norm = 1.4936e-01, time/batch = 19.7835s	
7572/30300 (epoch 12.495), train_loss = 1.31772379, grad/param norm = 1.3550e-01, time/batch = 19.7876s	
7573/30300 (epoch 12.497), train_loss = 1.42681054, grad/param norm = 1.4792e-01, time/batch = 17.7035s	
7574/30300 (epoch 12.498), train_loss = 1.42273742, grad/param norm = 1.5001e-01, time/batch = 18.8757s	
7575/30300 (epoch 12.500), train_loss = 1.47811391, grad/param norm = 1.6324e-01, time/batch = 18.4655s	
7576/30300 (epoch 12.502), train_loss = 1.35770272, grad/param norm = 1.4685e-01, time/batch = 19.2856s	
7577/30300 (epoch 12.503), train_loss = 1.47163197, grad/param norm = 1.4550e-01, time/batch = 18.4571s	
7578/30300 (epoch 12.505), train_loss = 1.36948850, grad/param norm = 1.4715e-01, time/batch = 19.2642s	
7579/30300 (epoch 12.507), train_loss = 1.34894255, grad/param norm = 1.5148e-01, time/batch = 19.4484s	
7580/30300 (epoch 12.508), train_loss = 1.41888982, grad/param norm = 1.7011e-01, time/batch = 17.4636s	
7581/30300 (epoch 12.510), train_loss = 1.49472664, grad/param norm = 1.6787e-01, time/batch = 19.8574s	
7582/30300 (epoch 12.512), train_loss = 1.31058997, grad/param norm = 1.4307e-01, time/batch = 19.0408s	
7583/30300 (epoch 12.513), train_loss = 1.47076280, grad/param norm = 1.5061e-01, time/batch = 16.9513s	
7584/30300 (epoch 12.515), train_loss = 1.36622903, grad/param norm = 1.4461e-01, time/batch = 17.0471s	
7585/30300 (epoch 12.517), train_loss = 1.22196961, grad/param norm = 1.3718e-01, time/batch = 18.3735s	
7586/30300 (epoch 12.518), train_loss = 1.47578278, grad/param norm = 1.6385e-01, time/batch = 17.5456s	
7587/30300 (epoch 12.520), train_loss = 1.56730572, grad/param norm = 1.5893e-01, time/batch = 18.0468s	
7588/30300 (epoch 12.521), train_loss = 1.28308818, grad/param norm = 1.5885e-01, time/batch = 19.7619s	
7589/30300 (epoch 12.523), train_loss = 1.54631230, grad/param norm = 1.8036e-01, time/batch = 17.1053s	
7590/30300 (epoch 12.525), train_loss = 1.31376336, grad/param norm = 1.4651e-01, time/batch = 18.7776s	
7591/30300 (epoch 12.526), train_loss = 1.38543415, grad/param norm = 1.5154e-01, time/batch = 20.2724s	
7592/30300 (epoch 12.528), train_loss = 1.23790315, grad/param norm = 1.4436e-01, time/batch = 19.4487s	
7593/30300 (epoch 12.530), train_loss = 1.27164795, grad/param norm = 1.4606e-01, time/batch = 17.3588s	
7594/30300 (epoch 12.531), train_loss = 1.45352194, grad/param norm = 1.8995e-01, time/batch = 18.2841s	
7595/30300 (epoch 12.533), train_loss = 1.43738385, grad/param norm = 1.5868e-01, time/batch = 20.0286s	
7596/30300 (epoch 12.535), train_loss = 1.22366719, grad/param norm = 1.2741e-01, time/batch = 17.9655s	
7597/30300 (epoch 12.536), train_loss = 1.43835342, grad/param norm = 1.5464e-01, time/batch = 18.7340s	
7598/30300 (epoch 12.538), train_loss = 1.21063769, grad/param norm = 1.4884e-01, time/batch = 19.7158s	
7599/30300 (epoch 12.540), train_loss = 1.28792377, grad/param norm = 1.5858e-01, time/batch = 17.1040s	
7600/30300 (epoch 12.541), train_loss = 1.39361344, grad/param norm = 1.7831e-01, time/batch = 19.1313s	
7601/30300 (epoch 12.543), train_loss = 1.40521736, grad/param norm = 1.4774e-01, time/batch = 19.4727s	
7602/30300 (epoch 12.545), train_loss = 1.43223507, grad/param norm = 1.6041e-01, time/batch = 17.7088s	
7603/30300 (epoch 12.546), train_loss = 1.61881114, grad/param norm = 1.4976e-01, time/batch = 18.6191s	
7604/30300 (epoch 12.548), train_loss = 1.32672190, grad/param norm = 1.4938e-01, time/batch = 19.2968s	
7605/30300 (epoch 12.550), train_loss = 1.52383859, grad/param norm = 1.6565e-01, time/batch = 18.7113s	
7606/30300 (epoch 12.551), train_loss = 1.31501186, grad/param norm = 1.4573e-01, time/batch = 18.5294s	
7607/30300 (epoch 12.553), train_loss = 1.34710387, grad/param norm = 1.5990e-01, time/batch = 18.7085s	
7608/30300 (epoch 12.554), train_loss = 1.46400433, grad/param norm = 1.6118e-01, time/batch = 19.3730s	
7609/30300 (epoch 12.556), train_loss = 1.44970045, grad/param norm = 1.5238e-01, time/batch = 18.6991s	
7610/30300 (epoch 12.558), train_loss = 1.54126269, grad/param norm = 1.6187e-01, time/batch = 18.4779s	
7611/30300 (epoch 12.559), train_loss = 1.43751221, grad/param norm = 1.6220e-01, time/batch = 18.7161s	
7612/30300 (epoch 12.561), train_loss = 1.26366027, grad/param norm = 1.5043e-01, time/batch = 18.7985s	
7613/30300 (epoch 12.563), train_loss = 1.28218906, grad/param norm = 1.3385e-01, time/batch = 19.4687s	
7614/30300 (epoch 12.564), train_loss = 1.33264191, grad/param norm = 1.4412e-01, time/batch = 18.3939s	
7615/30300 (epoch 12.566), train_loss = 1.39086164, grad/param norm = 1.4056e-01, time/batch = 18.5480s	
7616/30300 (epoch 12.568), train_loss = 1.18867623, grad/param norm = 1.4796e-01, time/batch = 18.0478s	
7617/30300 (epoch 12.569), train_loss = 1.38977645, grad/param norm = 1.4369e-01, time/batch = 19.7940s	
7618/30300 (epoch 12.571), train_loss = 1.42524822, grad/param norm = 1.5424e-01, time/batch = 17.5988s	
7619/30300 (epoch 12.573), train_loss = 1.42218130, grad/param norm = 1.5043e-01, time/batch = 18.5276s	
7620/30300 (epoch 12.574), train_loss = 1.47030260, grad/param norm = 1.4712e-01, time/batch = 19.5420s	
7621/30300 (epoch 12.576), train_loss = 1.36002358, grad/param norm = 1.4068e-01, time/batch = 18.7828s	
7622/30300 (epoch 12.578), train_loss = 1.27097381, grad/param norm = 1.4311e-01, time/batch = 20.0383s	
7623/30300 (epoch 12.579), train_loss = 1.43334124, grad/param norm = 1.6184e-01, time/batch = 20.1168s	
7624/30300 (epoch 12.581), train_loss = 1.47173371, grad/param norm = 1.4372e-01, time/batch = 22.1396s	
7625/30300 (epoch 12.583), train_loss = 1.56895269, grad/param norm = 1.6437e-01, time/batch = 30.0162s	
7626/30300 (epoch 12.584), train_loss = 1.46877693, grad/param norm = 1.4463e-01, time/batch = 18.7923s	
7627/30300 (epoch 12.586), train_loss = 1.43002242, grad/param norm = 1.5584e-01, time/batch = 17.6365s	
7628/30300 (epoch 12.587), train_loss = 1.41984632, grad/param norm = 1.5830e-01, time/batch = 18.6928s	
7629/30300 (epoch 12.589), train_loss = 1.25667141, grad/param norm = 1.3495e-01, time/batch = 19.6195s	
7630/30300 (epoch 12.591), train_loss = 1.42104191, grad/param norm = 1.4228e-01, time/batch = 18.0302s	
7631/30300 (epoch 12.592), train_loss = 1.37965552, grad/param norm = 1.3430e-01, time/batch = 19.3518s	
7632/30300 (epoch 12.594), train_loss = 1.42726342, grad/param norm = 1.5698e-01, time/batch = 19.1770s	
7633/30300 (epoch 12.596), train_loss = 1.26994630, grad/param norm = 1.3010e-01, time/batch = 18.3691s	
7634/30300 (epoch 12.597), train_loss = 1.34443332, grad/param norm = 1.5128e-01, time/batch = 19.6420s	
7635/30300 (epoch 12.599), train_loss = 1.20200574, grad/param norm = 1.4873e-01, time/batch = 16.8031s	
7636/30300 (epoch 12.601), train_loss = 1.45078772, grad/param norm = 1.4642e-01, time/batch = 18.0491s	
7637/30300 (epoch 12.602), train_loss = 1.39222124, grad/param norm = 1.3682e-01, time/batch = 18.9502s	
7638/30300 (epoch 12.604), train_loss = 1.28826305, grad/param norm = 1.3187e-01, time/batch = 19.2033s	
7639/30300 (epoch 12.606), train_loss = 1.43542777, grad/param norm = 1.6642e-01, time/batch = 19.6154s	
7640/30300 (epoch 12.607), train_loss = 1.47824614, grad/param norm = 1.8103e-01, time/batch = 18.6904s	
7641/30300 (epoch 12.609), train_loss = 1.63283529, grad/param norm = 1.7648e-01, time/batch = 20.3674s	
7642/30300 (epoch 12.611), train_loss = 1.32584414, grad/param norm = 1.4880e-01, time/batch = 19.7124s	
7643/30300 (epoch 12.612), train_loss = 1.30071618, grad/param norm = 1.4942e-01, time/batch = 18.1193s	
7644/30300 (epoch 12.614), train_loss = 1.28934653, grad/param norm = 1.4006e-01, time/batch = 19.7966s	
7645/30300 (epoch 12.616), train_loss = 1.45345201, grad/param norm = 1.5901e-01, time/batch = 18.9758s	
7646/30300 (epoch 12.617), train_loss = 1.35916769, grad/param norm = 1.4259e-01, time/batch = 18.1985s	
7647/30300 (epoch 12.619), train_loss = 1.19057058, grad/param norm = 1.3568e-01, time/batch = 18.3422s	
7648/30300 (epoch 12.620), train_loss = 1.42030757, grad/param norm = 1.5204e-01, time/batch = 17.7115s	
7649/30300 (epoch 12.622), train_loss = 1.39677563, grad/param norm = 1.7367e-01, time/batch = 17.9468s	
7650/30300 (epoch 12.624), train_loss = 1.31788416, grad/param norm = 1.6577e-01, time/batch = 19.3809s	
7651/30300 (epoch 12.625), train_loss = 1.35290600, grad/param norm = 1.5139e-01, time/batch = 20.1912s	
7652/30300 (epoch 12.627), train_loss = 1.55984362, grad/param norm = 1.6620e-01, time/batch = 18.0477s	
7653/30300 (epoch 12.629), train_loss = 1.45547633, grad/param norm = 1.4231e-01, time/batch = 18.7885s	
7654/30300 (epoch 12.630), train_loss = 1.40338494, grad/param norm = 1.3473e-01, time/batch = 19.8083s	
7655/30300 (epoch 12.632), train_loss = 1.49891402, grad/param norm = 1.5814e-01, time/batch = 18.7212s	
7656/30300 (epoch 12.634), train_loss = 1.24687915, grad/param norm = 1.3548e-01, time/batch = 18.4406s	
7657/30300 (epoch 12.635), train_loss = 1.44795498, grad/param norm = 1.4401e-01, time/batch = 18.7734s	
7658/30300 (epoch 12.637), train_loss = 1.46227089, grad/param norm = 1.6485e-01, time/batch = 19.3849s	
7659/30300 (epoch 12.639), train_loss = 1.31072335, grad/param norm = 1.4586e-01, time/batch = 18.7730s	
7660/30300 (epoch 12.640), train_loss = 1.52091572, grad/param norm = 1.5943e-01, time/batch = 19.3805s	
7661/30300 (epoch 12.642), train_loss = 1.33321087, grad/param norm = 1.4052e-01, time/batch = 18.2856s	
7662/30300 (epoch 12.644), train_loss = 1.45946851, grad/param norm = 1.4718e-01, time/batch = 18.5171s	
7663/30300 (epoch 12.645), train_loss = 1.25218696, grad/param norm = 1.3704e-01, time/batch = 18.1149s	
7664/30300 (epoch 12.647), train_loss = 1.35576798, grad/param norm = 1.3803e-01, time/batch = 19.7864s	
7665/30300 (epoch 12.649), train_loss = 1.33845738, grad/param norm = 1.4118e-01, time/batch = 17.2941s	
7666/30300 (epoch 12.650), train_loss = 1.36574209, grad/param norm = 1.4369e-01, time/batch = 18.7924s	
7667/30300 (epoch 12.652), train_loss = 1.31556510, grad/param norm = 1.4920e-01, time/batch = 20.2849s	
7668/30300 (epoch 12.653), train_loss = 1.57246378, grad/param norm = 1.5492e-01, time/batch = 17.3801s	
7669/30300 (epoch 12.655), train_loss = 1.31707966, grad/param norm = 1.4897e-01, time/batch = 18.6237s	
7670/30300 (epoch 12.657), train_loss = 1.37073377, grad/param norm = 1.5070e-01, time/batch = 19.3787s	
7671/30300 (epoch 12.658), train_loss = 1.32699920, grad/param norm = 1.4457e-01, time/batch = 18.2714s	
7672/30300 (epoch 12.660), train_loss = 1.45396711, grad/param norm = 1.5165e-01, time/batch = 19.0587s	
7673/30300 (epoch 12.662), train_loss = 1.43671920, grad/param norm = 1.5665e-01, time/batch = 18.5593s	
7674/30300 (epoch 12.663), train_loss = 1.41817968, grad/param norm = 1.4784e-01, time/batch = 18.2148s	
7675/30300 (epoch 12.665), train_loss = 1.29584855, grad/param norm = 1.5706e-01, time/batch = 19.2914s	
7676/30300 (epoch 12.667), train_loss = 1.48983433, grad/param norm = 1.4483e-01, time/batch = 18.1110s	
7677/30300 (epoch 12.668), train_loss = 1.55158308, grad/param norm = 1.6995e-01, time/batch = 19.6273s	
7678/30300 (epoch 12.670), train_loss = 1.53505655, grad/param norm = 1.5386e-01, time/batch = 18.8540s	
7679/30300 (epoch 12.672), train_loss = 1.45583293, grad/param norm = 1.5402e-01, time/batch = 17.9691s	
7680/30300 (epoch 12.673), train_loss = 1.49031589, grad/param norm = 1.5816e-01, time/batch = 18.7907s	
7681/30300 (epoch 12.675), train_loss = 1.33077641, grad/param norm = 1.5019e-01, time/batch = 18.1278s	
7682/30300 (epoch 12.677), train_loss = 1.29982736, grad/param norm = 1.3334e-01, time/batch = 19.2929s	
7683/30300 (epoch 12.678), train_loss = 1.33715472, grad/param norm = 1.4455e-01, time/batch = 20.1169s	
7684/30300 (epoch 12.680), train_loss = 1.16570515, grad/param norm = 1.3312e-01, time/batch = 18.7857s	
7685/30300 (epoch 12.682), train_loss = 1.36896292, grad/param norm = 1.4762e-01, time/batch = 18.2927s	
7686/30300 (epoch 12.683), train_loss = 1.42409200, grad/param norm = 1.4132e-01, time/batch = 19.7012s	
7687/30300 (epoch 12.685), train_loss = 1.51992786, grad/param norm = 1.6526e-01, time/batch = 18.1288s	
7688/30300 (epoch 12.686), train_loss = 1.39017932, grad/param norm = 1.5085e-01, time/batch = 18.4604s	
7689/30300 (epoch 12.688), train_loss = 1.40869011, grad/param norm = 1.4335e-01, time/batch = 20.1991s	
7690/30300 (epoch 12.690), train_loss = 1.32929295, grad/param norm = 1.4971e-01, time/batch = 17.5504s	
7691/30300 (epoch 12.691), train_loss = 1.39718007, grad/param norm = 1.3910e-01, time/batch = 19.1312s	
7692/30300 (epoch 12.693), train_loss = 1.80169971, grad/param norm = 1.8329e-01, time/batch = 19.7977s	
7693/30300 (epoch 12.695), train_loss = 1.56211051, grad/param norm = 1.7851e-01, time/batch = 17.0359s	
7694/30300 (epoch 12.696), train_loss = 1.54369276, grad/param norm = 1.7844e-01, time/batch = 18.7848s	
7695/30300 (epoch 12.698), train_loss = 1.34200520, grad/param norm = 1.5172e-01, time/batch = 18.3012s	
7696/30300 (epoch 12.700), train_loss = 1.35256549, grad/param norm = 1.5107e-01, time/batch = 19.3912s	
7697/30300 (epoch 12.701), train_loss = 1.20539190, grad/param norm = 1.3245e-01, time/batch = 19.0431s	
7698/30300 (epoch 12.703), train_loss = 1.39636138, grad/param norm = 1.4492e-01, time/batch = 19.5482s	
7699/30300 (epoch 12.705), train_loss = 1.36301646, grad/param norm = 1.5128e-01, time/batch = 19.8891s	
7700/30300 (epoch 12.706), train_loss = 1.43523990, grad/param norm = 1.4939e-01, time/batch = 17.7014s	
7701/30300 (epoch 12.708), train_loss = 1.33906518, grad/param norm = 1.4575e-01, time/batch = 19.3441s	
7702/30300 (epoch 12.710), train_loss = 1.35746177, grad/param norm = 1.5181e-01, time/batch = 20.1952s	
7703/30300 (epoch 12.711), train_loss = 1.26995913, grad/param norm = 1.4380e-01, time/batch = 17.3693s	
7704/30300 (epoch 12.713), train_loss = 1.26601291, grad/param norm = 1.4026e-01, time/batch = 19.7904s	
7705/30300 (epoch 12.715), train_loss = 1.34899597, grad/param norm = 1.4794e-01, time/batch = 19.3760s	
7706/30300 (epoch 12.716), train_loss = 1.52583934, grad/param norm = 1.6288e-01, time/batch = 17.5399s	
7707/30300 (epoch 12.718), train_loss = 1.50417892, grad/param norm = 1.6172e-01, time/batch = 19.4583s	
7708/30300 (epoch 12.719), train_loss = 1.35733419, grad/param norm = 1.6297e-01, time/batch = 19.0591s	
7709/30300 (epoch 12.721), train_loss = 1.38603636, grad/param norm = 1.5976e-01, time/batch = 17.5758s	
7710/30300 (epoch 12.723), train_loss = 1.32504660, grad/param norm = 1.5232e-01, time/batch = 18.7887s	
7711/30300 (epoch 12.724), train_loss = 1.47487107, grad/param norm = 1.6165e-01, time/batch = 18.7811s	
7712/30300 (epoch 12.726), train_loss = 1.81580911, grad/param norm = 1.8321e-01, time/batch = 19.1222s	
7713/30300 (epoch 12.728), train_loss = 1.42339145, grad/param norm = 1.5320e-01, time/batch = 19.3005s	
7714/30300 (epoch 12.729), train_loss = 1.39501923, grad/param norm = 1.5828e-01, time/batch = 19.6193s	
7715/30300 (epoch 12.731), train_loss = 1.47116698, grad/param norm = 1.5497e-01, time/batch = 19.2104s	
7716/30300 (epoch 12.733), train_loss = 1.37719778, grad/param norm = 1.4164e-01, time/batch = 18.7881s	
7717/30300 (epoch 12.734), train_loss = 1.45712388, grad/param norm = 1.4387e-01, time/batch = 18.9518s	
7718/30300 (epoch 12.736), train_loss = 1.36660400, grad/param norm = 1.3659e-01, time/batch = 19.1840s	
7719/30300 (epoch 12.738), train_loss = 1.24192095, grad/param norm = 1.3106e-01, time/batch = 15.5999s	
7720/30300 (epoch 12.739), train_loss = 1.43151067, grad/param norm = 1.4283e-01, time/batch = 17.4562s	
7721/30300 (epoch 12.741), train_loss = 1.49497109, grad/param norm = 1.4635e-01, time/batch = 18.7944s	
7722/30300 (epoch 12.743), train_loss = 1.33269523, grad/param norm = 1.3969e-01, time/batch = 16.6438s	
7723/30300 (epoch 12.744), train_loss = 1.47016817, grad/param norm = 1.5262e-01, time/batch = 17.5512s	
7724/30300 (epoch 12.746), train_loss = 1.25047069, grad/param norm = 1.3518e-01, time/batch = 17.6067s	
7725/30300 (epoch 12.748), train_loss = 1.40196759, grad/param norm = 1.6350e-01, time/batch = 18.3056s	
7726/30300 (epoch 12.749), train_loss = 1.43502662, grad/param norm = 1.6167e-01, time/batch = 17.5156s	
7727/30300 (epoch 12.751), train_loss = 1.31650279, grad/param norm = 1.4500e-01, time/batch = 17.7208s	
7728/30300 (epoch 12.752), train_loss = 1.33210554, grad/param norm = 1.4121e-01, time/batch = 17.2228s	
7729/30300 (epoch 12.754), train_loss = 1.27182599, grad/param norm = 1.3164e-01, time/batch = 17.3821s	
7730/30300 (epoch 12.756), train_loss = 1.34661065, grad/param norm = 1.4817e-01, time/batch = 18.3000s	
7731/30300 (epoch 12.757), train_loss = 1.44241202, grad/param norm = 1.5802e-01, time/batch = 19.7014s	
7732/30300 (epoch 12.759), train_loss = 1.35278411, grad/param norm = 1.3569e-01, time/batch = 18.0255s	
7733/30300 (epoch 12.761), train_loss = 1.24984245, grad/param norm = 1.3693e-01, time/batch = 18.1871s	
7734/30300 (epoch 12.762), train_loss = 1.18226274, grad/param norm = 1.2863e-01, time/batch = 19.7878s	
7735/30300 (epoch 12.764), train_loss = 1.34584641, grad/param norm = 1.3550e-01, time/batch = 19.0289s	
7736/30300 (epoch 12.766), train_loss = 1.41911333, grad/param norm = 1.4230e-01, time/batch = 18.5345s	
7737/30300 (epoch 12.767), train_loss = 1.48761000, grad/param norm = 1.7495e-01, time/batch = 18.8014s	
7738/30300 (epoch 12.769), train_loss = 1.45429887, grad/param norm = 1.4722e-01, time/batch = 19.8699s	
7739/30300 (epoch 12.771), train_loss = 1.36355368, grad/param norm = 1.6184e-01, time/batch = 17.7565s	
7740/30300 (epoch 12.772), train_loss = 1.41560184, grad/param norm = 1.5483e-01, time/batch = 18.1413s	
7741/30300 (epoch 12.774), train_loss = 1.55576827, grad/param norm = 1.4777e-01, time/batch = 19.1336s	
7742/30300 (epoch 12.776), train_loss = 1.44173635, grad/param norm = 1.5860e-01, time/batch = 17.9576s	
7743/30300 (epoch 12.777), train_loss = 1.41078117, grad/param norm = 1.3764e-01, time/batch = 18.2118s	
7744/30300 (epoch 12.779), train_loss = 1.56740941, grad/param norm = 1.7250e-01, time/batch = 19.5444s	
7745/30300 (epoch 12.781), train_loss = 1.40414930, grad/param norm = 1.6070e-01, time/batch = 18.1285s	
7746/30300 (epoch 12.782), train_loss = 1.33628495, grad/param norm = 1.4301e-01, time/batch = 19.4470s	
7747/30300 (epoch 12.784), train_loss = 1.32383407, grad/param norm = 1.4115e-01, time/batch = 18.9607s	
7748/30300 (epoch 12.785), train_loss = 1.54260199, grad/param norm = 1.6582e-01, time/batch = 17.8798s	
7749/30300 (epoch 12.787), train_loss = 1.24431347, grad/param norm = 1.5036e-01, time/batch = 18.9474s	
7750/30300 (epoch 12.789), train_loss = 1.66576006, grad/param norm = 1.4438e-01, time/batch = 19.0391s	
7751/30300 (epoch 12.790), train_loss = 1.47782933, grad/param norm = 1.6343e-01, time/batch = 18.9483s	
7752/30300 (epoch 12.792), train_loss = 1.26328376, grad/param norm = 1.5414e-01, time/batch = 17.8666s	
7753/30300 (epoch 12.794), train_loss = 1.33683309, grad/param norm = 1.5271e-01, time/batch = 18.3856s	
7754/30300 (epoch 12.795), train_loss = 1.34962844, grad/param norm = 1.3440e-01, time/batch = 19.1173s	
7755/30300 (epoch 12.797), train_loss = 1.58959580, grad/param norm = 1.7192e-01, time/batch = 17.3592s	
7756/30300 (epoch 12.799), train_loss = 1.46352832, grad/param norm = 1.6661e-01, time/batch = 19.2848s	
7757/30300 (epoch 12.800), train_loss = 1.46949418, grad/param norm = 1.5837e-01, time/batch = 19.6295s	
7758/30300 (epoch 12.802), train_loss = 1.63506737, grad/param norm = 1.7339e-01, time/batch = 17.6303s	
7759/30300 (epoch 12.804), train_loss = 1.47314086, grad/param norm = 1.5927e-01, time/batch = 18.5139s	
7760/30300 (epoch 12.805), train_loss = 1.57682146, grad/param norm = 1.6657e-01, time/batch = 19.1837s	
7761/30300 (epoch 12.807), train_loss = 1.41541686, grad/param norm = 2.2623e-01, time/batch = 18.5460s	
7762/30300 (epoch 12.809), train_loss = 1.51152108, grad/param norm = 1.7539e-01, time/batch = 16.3657s	
7763/30300 (epoch 12.810), train_loss = 1.49856779, grad/param norm = 1.5447e-01, time/batch = 19.4556s	
7764/30300 (epoch 12.812), train_loss = 1.27919512, grad/param norm = 1.4719e-01, time/batch = 18.6264s	
7765/30300 (epoch 12.814), train_loss = 1.42700345, grad/param norm = 1.5826e-01, time/batch = 19.4561s	
7766/30300 (epoch 12.815), train_loss = 1.44803759, grad/param norm = 1.6188e-01, time/batch = 18.4632s	
7767/30300 (epoch 12.817), train_loss = 1.52214507, grad/param norm = 1.6787e-01, time/batch = 18.8767s	
7768/30300 (epoch 12.818), train_loss = 1.45233780, grad/param norm = 1.4597e-01, time/batch = 19.3667s	
7769/30300 (epoch 12.820), train_loss = 1.63538252, grad/param norm = 1.7602e-01, time/batch = 18.0349s	
7770/30300 (epoch 12.822), train_loss = 1.63342159, grad/param norm = 1.8848e-01, time/batch = 18.8618s	
7771/30300 (epoch 12.823), train_loss = 1.67361738, grad/param norm = 1.9286e-01, time/batch = 18.8526s	
7772/30300 (epoch 12.825), train_loss = 1.51443617, grad/param norm = 1.6037e-01, time/batch = 19.4456s	
7773/30300 (epoch 12.827), train_loss = 1.29893325, grad/param norm = 1.6931e-01, time/batch = 19.8591s	
7774/30300 (epoch 12.828), train_loss = 1.45050318, grad/param norm = 1.4695e-01, time/batch = 18.2697s	
7775/30300 (epoch 12.830), train_loss = 1.44072846, grad/param norm = 1.5568e-01, time/batch = 19.7948s	
7776/30300 (epoch 12.832), train_loss = 1.36424609, grad/param norm = 1.5628e-01, time/batch = 18.3677s	
7777/30300 (epoch 12.833), train_loss = 1.48130760, grad/param norm = 1.5693e-01, time/batch = 18.5337s	
7778/30300 (epoch 12.835), train_loss = 1.37703593, grad/param norm = 1.5705e-01, time/batch = 16.7226s	
7779/30300 (epoch 12.837), train_loss = 1.23615380, grad/param norm = 1.3769e-01, time/batch = 19.9655s	
7780/30300 (epoch 12.838), train_loss = 1.27629039, grad/param norm = 1.4866e-01, time/batch = 18.4594s	
7781/30300 (epoch 12.840), train_loss = 1.45115245, grad/param norm = 1.3494e-01, time/batch = 19.6263s	
7782/30300 (epoch 12.842), train_loss = 1.26457006, grad/param norm = 1.3109e-01, time/batch = 19.6923s	
7783/30300 (epoch 12.843), train_loss = 1.41323888, grad/param norm = 1.3967e-01, time/batch = 18.2186s	
7784/30300 (epoch 12.845), train_loss = 1.38193845, grad/param norm = 1.3116e-01, time/batch = 19.5323s	
7785/30300 (epoch 12.847), train_loss = 1.44063636, grad/param norm = 1.6544e-01, time/batch = 20.1867s	
7786/30300 (epoch 12.848), train_loss = 1.52782889, grad/param norm = 1.5718e-01, time/batch = 17.6985s	
7787/30300 (epoch 12.850), train_loss = 1.36183727, grad/param norm = 1.4028e-01, time/batch = 18.8693s	
7788/30300 (epoch 12.851), train_loss = 1.51437887, grad/param norm = 1.7035e-01, time/batch = 17.7009s	
7789/30300 (epoch 12.853), train_loss = 1.31786678, grad/param norm = 1.3525e-01, time/batch = 18.5215s	
7790/30300 (epoch 12.855), train_loss = 1.33321927, grad/param norm = 1.3449e-01, time/batch = 17.9425s	
7791/30300 (epoch 12.856), train_loss = 1.35071470, grad/param norm = 1.5133e-01, time/batch = 19.2237s	
7792/30300 (epoch 12.858), train_loss = 1.31776003, grad/param norm = 1.3512e-01, time/batch = 19.4646s	
7793/30300 (epoch 12.860), train_loss = 1.33469376, grad/param norm = 1.4568e-01, time/batch = 18.7133s	
7794/30300 (epoch 12.861), train_loss = 1.56143033, grad/param norm = 1.4765e-01, time/batch = 18.2889s	
7795/30300 (epoch 12.863), train_loss = 1.40529979, grad/param norm = 1.3719e-01, time/batch = 19.8721s	
7796/30300 (epoch 12.865), train_loss = 1.55071012, grad/param norm = 1.5379e-01, time/batch = 17.7161s	
7797/30300 (epoch 12.866), train_loss = 1.46790508, grad/param norm = 1.5721e-01, time/batch = 19.2899s	
7798/30300 (epoch 12.868), train_loss = 1.39787456, grad/param norm = 1.3967e-01, time/batch = 18.9626s	
7799/30300 (epoch 12.870), train_loss = 1.36784581, grad/param norm = 1.4225e-01, time/batch = 18.5429s	
7800/30300 (epoch 12.871), train_loss = 1.34609781, grad/param norm = 1.3182e-01, time/batch = 19.0447s	
7801/30300 (epoch 12.873), train_loss = 1.40708381, grad/param norm = 1.3460e-01, time/batch = 19.5625s	
7802/30300 (epoch 12.875), train_loss = 1.26239068, grad/param norm = 1.3362e-01, time/batch = 19.1266s	
7803/30300 (epoch 12.876), train_loss = 1.29059221, grad/param norm = 1.4232e-01, time/batch = 19.0383s	
7804/30300 (epoch 12.878), train_loss = 1.18165538, grad/param norm = 1.4907e-01, time/batch = 20.1218s	
7805/30300 (epoch 12.880), train_loss = 1.29169738, grad/param norm = 1.3944e-01, time/batch = 18.5464s	
7806/30300 (epoch 12.881), train_loss = 1.62857239, grad/param norm = 1.6509e-01, time/batch = 19.2852s	
7807/30300 (epoch 12.883), train_loss = 1.46123977, grad/param norm = 1.5231e-01, time/batch = 17.6087s	
7808/30300 (epoch 12.884), train_loss = 1.23571154, grad/param norm = 1.2651e-01, time/batch = 19.7037s	
7809/30300 (epoch 12.886), train_loss = 1.39448414, grad/param norm = 1.4543e-01, time/batch = 17.6232s	
7810/30300 (epoch 12.888), train_loss = 1.43280967, grad/param norm = 1.5484e-01, time/batch = 17.7323s	
7811/30300 (epoch 12.889), train_loss = 1.37643587, grad/param norm = 1.4950e-01, time/batch = 19.8124s	
7812/30300 (epoch 12.891), train_loss = 1.37073717, grad/param norm = 1.4373e-01, time/batch = 18.7046s	
7813/30300 (epoch 12.893), train_loss = 1.66271683, grad/param norm = 1.6498e-01, time/batch = 19.4728s	
7814/30300 (epoch 12.894), train_loss = 1.52264941, grad/param norm = 1.9335e-01, time/batch = 19.1236s	
7815/30300 (epoch 12.896), train_loss = 1.21491708, grad/param norm = 1.3593e-01, time/batch = 29.5918s	
7816/30300 (epoch 12.898), train_loss = 1.17987305, grad/param norm = 1.4527e-01, time/batch = 21.6987s	
7817/30300 (epoch 12.899), train_loss = 1.33311817, grad/param norm = 1.4578e-01, time/batch = 16.8719s	
7818/30300 (epoch 12.901), train_loss = 1.39308465, grad/param norm = 1.5779e-01, time/batch = 18.5447s	
7819/30300 (epoch 12.903), train_loss = 1.43505771, grad/param norm = 1.5334e-01, time/batch = 17.6159s	
7820/30300 (epoch 12.904), train_loss = 1.33873944, grad/param norm = 1.4867e-01, time/batch = 18.7095s	
7821/30300 (epoch 12.906), train_loss = 1.53327682, grad/param norm = 1.5170e-01, time/batch = 17.4366s	
7822/30300 (epoch 12.908), train_loss = 1.27809096, grad/param norm = 1.3498e-01, time/batch = 19.1320s	
7823/30300 (epoch 12.909), train_loss = 1.34229561, grad/param norm = 1.6348e-01, time/batch = 19.0491s	
7824/30300 (epoch 12.911), train_loss = 1.37136134, grad/param norm = 1.4328e-01, time/batch = 18.5540s	
7825/30300 (epoch 12.913), train_loss = 1.38877728, grad/param norm = 1.3875e-01, time/batch = 17.8648s	
7826/30300 (epoch 12.914), train_loss = 1.38788450, grad/param norm = 1.5930e-01, time/batch = 16.7856s	
7827/30300 (epoch 12.916), train_loss = 1.40299988, grad/param norm = 1.3924e-01, time/batch = 18.7123s	
7828/30300 (epoch 12.917), train_loss = 1.28916713, grad/param norm = 1.3746e-01, time/batch = 19.2772s	
7829/30300 (epoch 12.919), train_loss = 1.37045166, grad/param norm = 1.4954e-01, time/batch = 18.6981s	
7830/30300 (epoch 12.921), train_loss = 1.39379481, grad/param norm = 1.4110e-01, time/batch = 18.8815s	
7831/30300 (epoch 12.922), train_loss = 1.49100589, grad/param norm = 1.6290e-01, time/batch = 18.2059s	
7832/30300 (epoch 12.924), train_loss = 1.39503399, grad/param norm = 1.5037e-01, time/batch = 18.2123s	
7833/30300 (epoch 12.926), train_loss = 1.37219135, grad/param norm = 1.4668e-01, time/batch = 17.8653s	
7834/30300 (epoch 12.927), train_loss = 1.38588231, grad/param norm = 1.5354e-01, time/batch = 16.4378s	
7835/30300 (epoch 12.929), train_loss = 1.34604582, grad/param norm = 1.7174e-01, time/batch = 19.5396s	
7836/30300 (epoch 12.931), train_loss = 1.54459691, grad/param norm = 1.7459e-01, time/batch = 20.2794s	
7837/30300 (epoch 12.932), train_loss = 1.33746227, grad/param norm = 1.6988e-01, time/batch = 18.2972s	
7838/30300 (epoch 12.934), train_loss = 1.41909003, grad/param norm = 1.4965e-01, time/batch = 19.2910s	
7839/30300 (epoch 12.936), train_loss = 1.35516430, grad/param norm = 1.4016e-01, time/batch = 19.5267s	
7840/30300 (epoch 12.937), train_loss = 1.34506452, grad/param norm = 1.5178e-01, time/batch = 18.8596s	
7841/30300 (epoch 12.939), train_loss = 1.51244642, grad/param norm = 1.5386e-01, time/batch = 18.5401s	
7842/30300 (epoch 12.941), train_loss = 1.38813553, grad/param norm = 1.6114e-01, time/batch = 18.9562s	
7843/30300 (epoch 12.942), train_loss = 1.39822525, grad/param norm = 1.4562e-01, time/batch = 18.0202s	
7844/30300 (epoch 12.944), train_loss = 1.29285242, grad/param norm = 1.3811e-01, time/batch = 19.1181s	
7845/30300 (epoch 12.946), train_loss = 1.55174610, grad/param norm = 1.8509e-01, time/batch = 19.4460s	
7846/30300 (epoch 12.947), train_loss = 1.55899050, grad/param norm = 1.7898e-01, time/batch = 17.9730s	
7847/30300 (epoch 12.949), train_loss = 1.58662010, grad/param norm = 1.6331e-01, time/batch = 19.1117s	
7848/30300 (epoch 12.950), train_loss = 1.53127292, grad/param norm = 1.6578e-01, time/batch = 19.4462s	
7849/30300 (epoch 12.952), train_loss = 1.48243598, grad/param norm = 1.6187e-01, time/batch = 19.0332s	
7850/30300 (epoch 12.954), train_loss = 1.68034995, grad/param norm = 1.6619e-01, time/batch = 18.9472s	
7851/30300 (epoch 12.955), train_loss = 1.33655793, grad/param norm = 1.4225e-01, time/batch = 19.4643s	
7852/30300 (epoch 12.957), train_loss = 1.45938864, grad/param norm = 1.5529e-01, time/batch = 18.7583s	
7853/30300 (epoch 12.959), train_loss = 1.42875665, grad/param norm = 1.6871e-01, time/batch = 18.0989s	
7854/30300 (epoch 12.960), train_loss = 1.38055413, grad/param norm = 1.5060e-01, time/batch = 18.4702s	
7855/30300 (epoch 12.962), train_loss = 1.34826305, grad/param norm = 1.5908e-01, time/batch = 19.4570s	
7856/30300 (epoch 12.964), train_loss = 1.37552691, grad/param norm = 1.8196e-01, time/batch = 17.5450s	
7857/30300 (epoch 12.965), train_loss = 1.32852271, grad/param norm = 1.5361e-01, time/batch = 17.5205s	
7858/30300 (epoch 12.967), train_loss = 1.36274231, grad/param norm = 1.4777e-01, time/batch = 19.5407s	
7859/30300 (epoch 12.969), train_loss = 1.34611519, grad/param norm = 1.6640e-01, time/batch = 18.9541s	
7860/30300 (epoch 12.970), train_loss = 1.35667838, grad/param norm = 1.5032e-01, time/batch = 19.4605s	
7861/30300 (epoch 12.972), train_loss = 1.26859815, grad/param norm = 1.4423e-01, time/batch = 18.8690s	
7862/30300 (epoch 12.974), train_loss = 1.60354025, grad/param norm = 1.6665e-01, time/batch = 17.1154s	
7863/30300 (epoch 12.975), train_loss = 1.60991632, grad/param norm = 1.8357e-01, time/batch = 18.5227s	
7864/30300 (epoch 12.977), train_loss = 1.49734276, grad/param norm = 1.5888e-01, time/batch = 18.7100s	
7865/30300 (epoch 12.979), train_loss = 1.44178154, grad/param norm = 1.5526e-01, time/batch = 19.3746s	
7866/30300 (epoch 12.980), train_loss = 1.50152437, grad/param norm = 1.7221e-01, time/batch = 17.4308s	
7867/30300 (epoch 12.982), train_loss = 1.50489787, grad/param norm = 1.6239e-01, time/batch = 16.5013s	
7868/30300 (epoch 12.983), train_loss = 1.53371571, grad/param norm = 1.5754e-01, time/batch = 16.8544s	
7869/30300 (epoch 12.985), train_loss = 1.41591156, grad/param norm = 1.6218e-01, time/batch = 17.2927s	
7870/30300 (epoch 12.987), train_loss = 1.37458873, grad/param norm = 1.3679e-01, time/batch = 19.2806s	
7871/30300 (epoch 12.988), train_loss = 1.57411784, grad/param norm = 1.4972e-01, time/batch = 19.2804s	
7872/30300 (epoch 12.990), train_loss = 1.21870084, grad/param norm = 1.3491e-01, time/batch = 18.5163s	
7873/30300 (epoch 12.992), train_loss = 1.46174493, grad/param norm = 1.3862e-01, time/batch = 17.7925s	
7874/30300 (epoch 12.993), train_loss = 1.52696224, grad/param norm = 1.6611e-01, time/batch = 19.2830s	
7875/30300 (epoch 12.995), train_loss = 1.41201011, grad/param norm = 1.6103e-01, time/batch = 18.7027s	
7876/30300 (epoch 12.997), train_loss = 1.43852141, grad/param norm = 1.5133e-01, time/batch = 18.8676s	
7877/30300 (epoch 12.998), train_loss = 1.50501866, grad/param norm = 1.6254e-01, time/batch = 19.0375s	
decayed learning rate by a factor 0.97 to 0.00177058562	
7878/30300 (epoch 13.000), train_loss = 1.33390198, grad/param norm = 1.4641e-01, time/batch = 18.2876s	
7879/30300 (epoch 13.002), train_loss = 1.46827569, grad/param norm = 1.5168e-01, time/batch = 18.5179s	
7880/30300 (epoch 13.003), train_loss = 1.41726096, grad/param norm = 1.6063e-01, time/batch = 19.9486s	
7881/30300 (epoch 13.005), train_loss = 1.38372270, grad/param norm = 1.6385e-01, time/batch = 19.2606s	
7882/30300 (epoch 13.007), train_loss = 1.51998873, grad/param norm = 1.6890e-01, time/batch = 18.4485s	
7883/30300 (epoch 13.008), train_loss = 1.34753343, grad/param norm = 1.4362e-01, time/batch = 19.3717s	
7884/30300 (epoch 13.010), train_loss = 1.29547873, grad/param norm = 1.4035e-01, time/batch = 19.2877s	
7885/30300 (epoch 13.012), train_loss = 1.30420231, grad/param norm = 1.4141e-01, time/batch = 17.6141s	
7886/30300 (epoch 13.013), train_loss = 1.45546887, grad/param norm = 1.5761e-01, time/batch = 16.9282s	
7887/30300 (epoch 13.015), train_loss = 1.36509834, grad/param norm = 1.4282e-01, time/batch = 18.7073s	
7888/30300 (epoch 13.017), train_loss = 1.29506003, grad/param norm = 1.3555e-01, time/batch = 18.1318s	
7889/30300 (epoch 13.018), train_loss = 1.33741225, grad/param norm = 1.4557e-01, time/batch = 18.8715s	
7890/30300 (epoch 13.020), train_loss = 1.51201940, grad/param norm = 1.5788e-01, time/batch = 19.0118s	
7891/30300 (epoch 13.021), train_loss = 1.52180370, grad/param norm = 1.5709e-01, time/batch = 18.4629s	
7892/30300 (epoch 13.023), train_loss = 1.34495145, grad/param norm = 1.3964e-01, time/batch = 17.6243s	
7893/30300 (epoch 13.025), train_loss = 1.33422702, grad/param norm = 1.6895e-01, time/batch = 19.2966s	
7894/30300 (epoch 13.026), train_loss = 1.45985616, grad/param norm = 1.5819e-01, time/batch = 18.7174s	
7895/30300 (epoch 13.028), train_loss = 1.46918354, grad/param norm = 1.4696e-01, time/batch = 18.6861s	
7896/30300 (epoch 13.030), train_loss = 1.32388004, grad/param norm = 1.4199e-01, time/batch = 18.4575s	
7897/30300 (epoch 13.031), train_loss = 1.40130915, grad/param norm = 1.5813e-01, time/batch = 18.9552s	
7898/30300 (epoch 13.033), train_loss = 1.41020645, grad/param norm = 1.6189e-01, time/batch = 18.0301s	
7899/30300 (epoch 13.035), train_loss = 1.49918664, grad/param norm = 1.4974e-01, time/batch = 19.8569s	
7900/30300 (epoch 13.036), train_loss = 1.41837330, grad/param norm = 1.5852e-01, time/batch = 18.5256s	
7901/30300 (epoch 13.038), train_loss = 1.40068253, grad/param norm = 1.5015e-01, time/batch = 18.5385s	
7902/30300 (epoch 13.040), train_loss = 1.11059207, grad/param norm = 1.2884e-01, time/batch = 19.4452s	
7903/30300 (epoch 13.041), train_loss = 1.17838314, grad/param norm = 1.3387e-01, time/batch = 17.7079s	
7904/30300 (epoch 13.043), train_loss = 1.43845389, grad/param norm = 1.6099e-01, time/batch = 18.6046s	
7905/30300 (epoch 13.045), train_loss = 1.35474807, grad/param norm = 1.5187e-01, time/batch = 20.1102s	
7906/30300 (epoch 13.046), train_loss = 1.51124788, grad/param norm = 1.7260e-01, time/batch = 20.0430s	
7907/30300 (epoch 13.048), train_loss = 1.43621449, grad/param norm = 1.6484e-01, time/batch = 18.6246s	
7908/30300 (epoch 13.050), train_loss = 1.42689124, grad/param norm = 1.5185e-01, time/batch = 20.0310s	
7909/30300 (epoch 13.051), train_loss = 1.42758154, grad/param norm = 1.6467e-01, time/batch = 19.8750s	
7910/30300 (epoch 13.053), train_loss = 1.23909497, grad/param norm = 1.6150e-01, time/batch = 18.4409s	
7911/30300 (epoch 13.054), train_loss = 1.35320028, grad/param norm = 1.5965e-01, time/batch = 18.5248s	
7912/30300 (epoch 13.056), train_loss = 1.31153914, grad/param norm = 1.4875e-01, time/batch = 19.2014s	
7913/30300 (epoch 13.058), train_loss = 1.36899550, grad/param norm = 1.4358e-01, time/batch = 19.3679s	
7914/30300 (epoch 13.059), train_loss = 1.31388926, grad/param norm = 1.5539e-01, time/batch = 17.7905s	
7915/30300 (epoch 13.061), train_loss = 1.53237635, grad/param norm = 1.6855e-01, time/batch = 18.6283s	
7916/30300 (epoch 13.063), train_loss = 1.34797841, grad/param norm = 1.5434e-01, time/batch = 19.4566s	
7917/30300 (epoch 13.064), train_loss = 1.46154701, grad/param norm = 1.5503e-01, time/batch = 16.4357s	
7918/30300 (epoch 13.066), train_loss = 1.36645785, grad/param norm = 1.4362e-01, time/batch = 19.7846s	
7919/30300 (epoch 13.068), train_loss = 1.25286222, grad/param norm = 1.4154e-01, time/batch = 19.5366s	
7920/30300 (epoch 13.069), train_loss = 1.49217639, grad/param norm = 1.5824e-01, time/batch = 18.1309s	
7921/30300 (epoch 13.071), train_loss = 1.43912510, grad/param norm = 1.6409e-01, time/batch = 19.6214s	
7922/30300 (epoch 13.073), train_loss = 1.41452346, grad/param norm = 1.6019e-01, time/batch = 19.5258s	
7923/30300 (epoch 13.074), train_loss = 1.44563510, grad/param norm = 1.4411e-01, time/batch = 17.7807s	
7924/30300 (epoch 13.076), train_loss = 1.36241354, grad/param norm = 1.4647e-01, time/batch = 19.8793s	
7925/30300 (epoch 13.078), train_loss = 1.26957658, grad/param norm = 1.4448e-01, time/batch = 19.4384s	
7926/30300 (epoch 13.079), train_loss = 1.29859188, grad/param norm = 1.3082e-01, time/batch = 18.1889s	
7927/30300 (epoch 13.081), train_loss = 1.41974217, grad/param norm = 1.5159e-01, time/batch = 19.1811s	
7928/30300 (epoch 13.083), train_loss = 1.53560655, grad/param norm = 1.7856e-01, time/batch = 18.9520s	
7929/30300 (epoch 13.084), train_loss = 1.28070947, grad/param norm = 1.5656e-01, time/batch = 18.8425s	
7930/30300 (epoch 13.086), train_loss = 1.32173283, grad/param norm = 1.4855e-01, time/batch = 17.9519s	
7931/30300 (epoch 13.087), train_loss = 1.26093672, grad/param norm = 1.2935e-01, time/batch = 19.7935s	
7932/30300 (epoch 13.089), train_loss = 1.34033246, grad/param norm = 1.5702e-01, time/batch = 19.2949s	
7933/30300 (epoch 13.091), train_loss = 1.45697493, grad/param norm = 1.6112e-01, time/batch = 18.5989s	
7934/30300 (epoch 13.092), train_loss = 1.39632226, grad/param norm = 1.5899e-01, time/batch = 19.1212s	
7935/30300 (epoch 13.094), train_loss = 1.57636262, grad/param norm = 1.6060e-01, time/batch = 19.6315s	
7936/30300 (epoch 13.096), train_loss = 1.49524633, grad/param norm = 1.5527e-01, time/batch = 19.4316s	
7937/30300 (epoch 13.097), train_loss = 1.30490066, grad/param norm = 1.4461e-01, time/batch = 20.1029s	
7938/30300 (epoch 13.099), train_loss = 1.54951438, grad/param norm = 1.5930e-01, time/batch = 18.7921s	
7939/30300 (epoch 13.101), train_loss = 1.60693991, grad/param norm = 1.7049e-01, time/batch = 17.0215s	
7940/30300 (epoch 13.102), train_loss = 1.36765767, grad/param norm = 1.6799e-01, time/batch = 19.4501s	
7941/30300 (epoch 13.104), train_loss = 1.36058944, grad/param norm = 1.7710e-01, time/batch = 19.4628s	
7942/30300 (epoch 13.106), train_loss = 1.39644225, grad/param norm = 1.7063e-01, time/batch = 17.4306s	
7943/30300 (epoch 13.107), train_loss = 1.41643829, grad/param norm = 1.4923e-01, time/batch = 19.7831s	
7944/30300 (epoch 13.109), train_loss = 1.51364781, grad/param norm = 1.6905e-01, time/batch = 19.8734s	
7945/30300 (epoch 13.111), train_loss = 1.53728829, grad/param norm = 1.5807e-01, time/batch = 18.0488s	
7946/30300 (epoch 13.112), train_loss = 1.43637356, grad/param norm = 1.4506e-01, time/batch = 19.4554s	
7947/30300 (epoch 13.114), train_loss = 1.40717406, grad/param norm = 1.4856e-01, time/batch = 18.6077s	
7948/30300 (epoch 13.116), train_loss = 1.42164165, grad/param norm = 1.5281e-01, time/batch = 18.1926s	
7949/30300 (epoch 13.117), train_loss = 1.41031695, grad/param norm = 1.3918e-01, time/batch = 17.0366s	
7950/30300 (epoch 13.119), train_loss = 1.30914355, grad/param norm = 1.5479e-01, time/batch = 18.7200s	
7951/30300 (epoch 13.120), train_loss = 1.39205783, grad/param norm = 1.5599e-01, time/batch = 19.4567s	
7952/30300 (epoch 13.122), train_loss = 1.47211194, grad/param norm = 1.5480e-01, time/batch = 18.5423s	
7953/30300 (epoch 13.124), train_loss = 1.60420763, grad/param norm = 1.7492e-01, time/batch = 19.7083s	
7954/30300 (epoch 13.125), train_loss = 1.25888502, grad/param norm = 1.3834e-01, time/batch = 19.2780s	
7955/30300 (epoch 13.127), train_loss = 1.40170478, grad/param norm = 1.6852e-01, time/batch = 18.0382s	
7956/30300 (epoch 13.129), train_loss = 1.54919689, grad/param norm = 1.4410e-01, time/batch = 19.4539s	
7957/30300 (epoch 13.130), train_loss = 1.54270961, grad/param norm = 1.4903e-01, time/batch = 19.5333s	
7958/30300 (epoch 13.132), train_loss = 1.47364156, grad/param norm = 2.3289e-01, time/batch = 17.1077s	
7959/30300 (epoch 13.134), train_loss = 1.31276272, grad/param norm = 1.5393e-01, time/batch = 18.6901s	
7960/30300 (epoch 13.135), train_loss = 1.34259044, grad/param norm = 1.6428e-01, time/batch = 19.5385s	
7961/30300 (epoch 13.137), train_loss = 1.46773966, grad/param norm = 1.5458e-01, time/batch = 18.4578s	
7962/30300 (epoch 13.139), train_loss = 1.36936373, grad/param norm = 1.5007e-01, time/batch = 19.1119s	
7963/30300 (epoch 13.140), train_loss = 1.52246702, grad/param norm = 1.7109e-01, time/batch = 19.6062s	
7964/30300 (epoch 13.142), train_loss = 1.60767035, grad/param norm = 1.7569e-01, time/batch = 18.9482s	
7965/30300 (epoch 13.144), train_loss = 1.45514191, grad/param norm = 1.7578e-01, time/batch = 20.1044s	
7966/30300 (epoch 13.145), train_loss = 1.57702295, grad/param norm = 1.9405e-01, time/batch = 18.0337s	
7967/30300 (epoch 13.147), train_loss = 1.41916385, grad/param norm = 1.6756e-01, time/batch = 17.6164s	
7968/30300 (epoch 13.149), train_loss = 1.62379456, grad/param norm = 1.6324e-01, time/batch = 19.1314s	
7969/30300 (epoch 13.150), train_loss = 1.48881513, grad/param norm = 1.6512e-01, time/batch = 19.4561s	
7970/30300 (epoch 13.152), train_loss = 1.28778278, grad/param norm = 1.6100e-01, time/batch = 17.7782s	
7971/30300 (epoch 13.153), train_loss = 1.41884657, grad/param norm = 1.6562e-01, time/batch = 18.6884s	
7972/30300 (epoch 13.155), train_loss = 1.20553378, grad/param norm = 1.3714e-01, time/batch = 19.3841s	
7973/30300 (epoch 13.157), train_loss = 1.38313837, grad/param norm = 1.5323e-01, time/batch = 18.4673s	
7974/30300 (epoch 13.158), train_loss = 1.43726138, grad/param norm = 1.5723e-01, time/batch = 17.5178s	
7975/30300 (epoch 13.160), train_loss = 1.34551115, grad/param norm = 1.4719e-01, time/batch = 19.7973s	
7976/30300 (epoch 13.162), train_loss = 1.34514279, grad/param norm = 1.4492e-01, time/batch = 19.9526s	
7977/30300 (epoch 13.163), train_loss = 1.34750642, grad/param norm = 1.5657e-01, time/batch = 18.2096s	
7978/30300 (epoch 13.165), train_loss = 1.47511784, grad/param norm = 1.4649e-01, time/batch = 20.2931s	
7979/30300 (epoch 13.167), train_loss = 1.43708130, grad/param norm = 1.6060e-01, time/batch = 18.4724s	
7980/30300 (epoch 13.168), train_loss = 1.42038822, grad/param norm = 1.4633e-01, time/batch = 17.1147s	
7981/30300 (epoch 13.170), train_loss = 1.44213508, grad/param norm = 1.5359e-01, time/batch = 19.9436s	
7982/30300 (epoch 13.172), train_loss = 1.34869821, grad/param norm = 1.5609e-01, time/batch = 18.5373s	
7983/30300 (epoch 13.173), train_loss = 1.46028378, grad/param norm = 1.6660e-01, time/batch = 17.2766s	
7984/30300 (epoch 13.175), train_loss = 1.39698350, grad/param norm = 1.3927e-01, time/batch = 18.2927s	
7985/30300 (epoch 13.177), train_loss = 1.40928129, grad/param norm = 1.5834e-01, time/batch = 19.0430s	
7986/30300 (epoch 13.178), train_loss = 1.14994511, grad/param norm = 1.3349e-01, time/batch = 19.4575s	
7987/30300 (epoch 13.180), train_loss = 1.31763797, grad/param norm = 1.3651e-01, time/batch = 18.5347s	
7988/30300 (epoch 13.182), train_loss = 1.31533226, grad/param norm = 1.6441e-01, time/batch = 20.2021s	
7989/30300 (epoch 13.183), train_loss = 1.31789532, grad/param norm = 1.4273e-01, time/batch = 19.3716s	
7990/30300 (epoch 13.185), train_loss = 1.65225043, grad/param norm = 1.5262e-01, time/batch = 18.8474s	
7991/30300 (epoch 13.186), train_loss = 1.66895750, grad/param norm = 1.7471e-01, time/batch = 18.7862s	
7992/30300 (epoch 13.188), train_loss = 1.47885044, grad/param norm = 1.5969e-01, time/batch = 19.9588s	
7993/30300 (epoch 13.190), train_loss = 1.36458905, grad/param norm = 1.4203e-01, time/batch = 18.3684s	
7994/30300 (epoch 13.191), train_loss = 1.46967296, grad/param norm = 1.5614e-01, time/batch = 19.6291s	
7995/30300 (epoch 13.193), train_loss = 1.29317627, grad/param norm = 1.4155e-01, time/batch = 19.7908s	
7996/30300 (epoch 13.195), train_loss = 1.43103377, grad/param norm = 1.5571e-01, time/batch = 17.1114s	
7997/30300 (epoch 13.196), train_loss = 1.40051784, grad/param norm = 1.3794e-01, time/batch = 19.7068s	
7998/30300 (epoch 13.198), train_loss = 1.18842483, grad/param norm = 1.4409e-01, time/batch = 19.9452s	
7999/30300 (epoch 13.200), train_loss = 1.39709088, grad/param norm = 1.3593e-01, time/batch = 17.7096s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch13.20_1.7163.t7	
8000/30300 (epoch 13.201), train_loss = 1.47937221, grad/param norm = 1.5373e-01, time/batch = 18.0489s	
8001/30300 (epoch 13.203), train_loss = 1.63255617, grad/param norm = 1.8596e-01, time/batch = 18.2073s	
8002/30300 (epoch 13.205), train_loss = 1.62596447, grad/param norm = 1.5767e-01, time/batch = 18.4595s	
8003/30300 (epoch 13.206), train_loss = 1.58837269, grad/param norm = 1.6526e-01, time/batch = 17.9332s	
8004/30300 (epoch 13.208), train_loss = 1.52384956, grad/param norm = 1.7988e-01, time/batch = 18.8981s	
8005/30300 (epoch 13.210), train_loss = 1.42558496, grad/param norm = 1.3871e-01, time/batch = 20.2704s	
8006/30300 (epoch 13.211), train_loss = 1.47444649, grad/param norm = 1.4248e-01, time/batch = 19.7063s	
8007/30300 (epoch 13.213), train_loss = 1.31635910, grad/param norm = 1.3434e-01, time/batch = 18.1297s	
8008/30300 (epoch 13.215), train_loss = 1.23632154, grad/param norm = 1.5013e-01, time/batch = 18.9565s	
8009/30300 (epoch 13.216), train_loss = 1.38401087, grad/param norm = 1.7354e-01, time/batch = 19.6970s	
8010/30300 (epoch 13.218), train_loss = 1.29274457, grad/param norm = 1.3393e-01, time/batch = 18.7928s	
8011/30300 (epoch 13.219), train_loss = 1.20834741, grad/param norm = 1.3239e-01, time/batch = 18.6162s	
8012/30300 (epoch 13.221), train_loss = 1.23767882, grad/param norm = 1.3797e-01, time/batch = 19.4622s	
8013/30300 (epoch 13.223), train_loss = 1.41267242, grad/param norm = 1.4421e-01, time/batch = 19.3663s	
8014/30300 (epoch 13.224), train_loss = 1.21393560, grad/param norm = 1.4337e-01, time/batch = 17.1745s	
8015/30300 (epoch 13.226), train_loss = 1.50597408, grad/param norm = 1.7143e-01, time/batch = 19.7112s	
8016/30300 (epoch 13.228), train_loss = 1.50948618, grad/param norm = 1.4623e-01, time/batch = 18.5994s	
8017/30300 (epoch 13.229), train_loss = 1.30879331, grad/param norm = 1.5385e-01, time/batch = 18.3608s	
8018/30300 (epoch 13.231), train_loss = 1.42474047, grad/param norm = 1.4302e-01, time/batch = 19.1289s	
8019/30300 (epoch 13.233), train_loss = 1.34656969, grad/param norm = 1.4426e-01, time/batch = 16.8496s	
8020/30300 (epoch 13.234), train_loss = 1.45316243, grad/param norm = 1.6266e-01, time/batch = 16.7034s	
8021/30300 (epoch 13.236), train_loss = 1.31640152, grad/param norm = 1.4026e-01, time/batch = 18.3914s	
8022/30300 (epoch 13.238), train_loss = 1.44131190, grad/param norm = 1.6945e-01, time/batch = 19.5306s	
8023/30300 (epoch 13.239), train_loss = 1.40822366, grad/param norm = 1.4950e-01, time/batch = 18.2134s	
8024/30300 (epoch 13.241), train_loss = 1.47487304, grad/param norm = 1.7392e-01, time/batch = 17.1004s	
8025/30300 (epoch 13.243), train_loss = 1.44430099, grad/param norm = 1.5061e-01, time/batch = 19.6139s	
8026/30300 (epoch 13.244), train_loss = 1.65415273, grad/param norm = 1.7092e-01, time/batch = 19.2269s	
8027/30300 (epoch 13.246), train_loss = 1.36438646, grad/param norm = 1.5686e-01, time/batch = 18.1153s	
8028/30300 (epoch 13.248), train_loss = 1.36390011, grad/param norm = 1.4525e-01, time/batch = 19.0825s	
8029/30300 (epoch 13.249), train_loss = 1.28229326, grad/param norm = 1.4553e-01, time/batch = 19.5385s	
8030/30300 (epoch 13.251), train_loss = 1.28631807, grad/param norm = 1.4848e-01, time/batch = 17.8588s	
8031/30300 (epoch 13.252), train_loss = 1.54058146, grad/param norm = 1.5669e-01, time/batch = 19.2139s	
8032/30300 (epoch 13.254), train_loss = 1.51551902, grad/param norm = 1.6866e-01, time/batch = 18.5395s	
8033/30300 (epoch 13.256), train_loss = 1.41932257, grad/param norm = 1.4794e-01, time/batch = 18.1977s	
8034/30300 (epoch 13.257), train_loss = 1.50007407, grad/param norm = 1.6143e-01, time/batch = 17.8662s	
8035/30300 (epoch 13.259), train_loss = 1.40368287, grad/param norm = 1.4945e-01, time/batch = 19.2722s	
8036/30300 (epoch 13.261), train_loss = 1.53333889, grad/param norm = 1.5233e-01, time/batch = 16.3125s	
8037/30300 (epoch 13.262), train_loss = 1.37223605, grad/param norm = 1.4086e-01, time/batch = 19.6988s	
8038/30300 (epoch 13.264), train_loss = 1.38983686, grad/param norm = 1.6623e-01, time/batch = 19.3077s	
8039/30300 (epoch 13.266), train_loss = 1.32916374, grad/param norm = 1.3994e-01, time/batch = 19.0403s	
8040/30300 (epoch 13.267), train_loss = 1.58348165, grad/param norm = 1.7700e-01, time/batch = 18.6702s	
8041/30300 (epoch 13.269), train_loss = 1.39444921, grad/param norm = 1.4943e-01, time/batch = 19.7150s	
8042/30300 (epoch 13.271), train_loss = 1.40485749, grad/param norm = 1.4849e-01, time/batch = 17.8546s	
8043/30300 (epoch 13.272), train_loss = 1.44448869, grad/param norm = 1.6545e-01, time/batch = 17.8616s	
8044/30300 (epoch 13.274), train_loss = 1.55852929, grad/param norm = 1.5092e-01, time/batch = 20.2907s	
8045/30300 (epoch 13.276), train_loss = 1.48869433, grad/param norm = 1.6189e-01, time/batch = 20.0384s	
8046/30300 (epoch 13.277), train_loss = 1.30873480, grad/param norm = 1.4922e-01, time/batch = 18.0196s	
8047/30300 (epoch 13.279), train_loss = 1.44919123, grad/param norm = 1.5346e-01, time/batch = 19.6347s	
8048/30300 (epoch 13.281), train_loss = 1.50800642, grad/param norm = 1.7417e-01, time/batch = 19.6323s	
8049/30300 (epoch 13.282), train_loss = 1.36713084, grad/param norm = 1.3189e-01, time/batch = 18.2943s	
8050/30300 (epoch 13.284), train_loss = 1.57371958, grad/param norm = 1.7611e-01, time/batch = 18.5429s	
8051/30300 (epoch 13.285), train_loss = 1.41058334, grad/param norm = 1.4641e-01, time/batch = 19.6686s	
8052/30300 (epoch 13.287), train_loss = 1.41358541, grad/param norm = 1.5808e-01, time/batch = 17.9451s	
8053/30300 (epoch 13.289), train_loss = 1.45589326, grad/param norm = 1.5686e-01, time/batch = 19.0337s	
8054/30300 (epoch 13.290), train_loss = 1.14747672, grad/param norm = 1.3385e-01, time/batch = 17.9444s	
8055/30300 (epoch 13.292), train_loss = 1.26941617, grad/param norm = 1.3047e-01, time/batch = 18.7707s	
8056/30300 (epoch 13.294), train_loss = 1.57192510, grad/param norm = 1.6087e-01, time/batch = 20.1932s	
8057/30300 (epoch 13.295), train_loss = 1.38111411, grad/param norm = 1.4308e-01, time/batch = 18.2830s	
8058/30300 (epoch 13.297), train_loss = 1.30787921, grad/param norm = 1.3554e-01, time/batch = 18.6251s	
8059/30300 (epoch 13.299), train_loss = 1.36931355, grad/param norm = 1.4798e-01, time/batch = 18.6231s	
8060/30300 (epoch 13.300), train_loss = 1.41977747, grad/param norm = 1.5257e-01, time/batch = 18.2859s	
8061/30300 (epoch 13.302), train_loss = 1.35189737, grad/param norm = 1.4728e-01, time/batch = 18.9629s	
8062/30300 (epoch 13.304), train_loss = 1.29010773, grad/param norm = 1.3831e-01, time/batch = 18.2618s	
8063/30300 (epoch 13.305), train_loss = 1.32370117, grad/param norm = 1.4424e-01, time/batch = 19.3819s	
8064/30300 (epoch 13.307), train_loss = 1.41702260, grad/param norm = 1.4215e-01, time/batch = 19.5362s	
8065/30300 (epoch 13.309), train_loss = 1.48178569, grad/param norm = 1.4868e-01, time/batch = 18.9406s	
8066/30300 (epoch 13.310), train_loss = 1.36670846, grad/param norm = 1.4798e-01, time/batch = 18.2896s	
8067/30300 (epoch 13.312), train_loss = 1.51604409, grad/param norm = 1.4710e-01, time/batch = 19.9667s	
8068/30300 (epoch 13.314), train_loss = 1.43687195, grad/param norm = 1.4569e-01, time/batch = 18.5370s	
8069/30300 (epoch 13.315), train_loss = 1.45454302, grad/param norm = 1.5143e-01, time/batch = 19.0563s	
8070/30300 (epoch 13.317), train_loss = 1.49796609, grad/param norm = 1.5652e-01, time/batch = 18.6131s	
8071/30300 (epoch 13.318), train_loss = 1.56189356, grad/param norm = 1.8657e-01, time/batch = 18.1250s	
8072/30300 (epoch 13.320), train_loss = 1.52566670, grad/param norm = 1.6190e-01, time/batch = 19.0547s	
8073/30300 (epoch 13.322), train_loss = 1.29924845, grad/param norm = 1.5199e-01, time/batch = 19.8050s	
8074/30300 (epoch 13.323), train_loss = 1.52589956, grad/param norm = 1.6338e-01, time/batch = 17.5523s	
8075/30300 (epoch 13.325), train_loss = 1.36995500, grad/param norm = 1.3416e-01, time/batch = 17.1992s	
8076/30300 (epoch 13.327), train_loss = 1.35882442, grad/param norm = 1.3589e-01, time/batch = 20.1280s	
8077/30300 (epoch 13.328), train_loss = 1.36351822, grad/param norm = 1.3669e-01, time/batch = 18.5397s	
8078/30300 (epoch 13.330), train_loss = 1.45984760, grad/param norm = 1.4033e-01, time/batch = 17.9443s	
8079/30300 (epoch 13.332), train_loss = 1.49582267, grad/param norm = 1.6155e-01, time/batch = 18.9673s	
8080/30300 (epoch 13.333), train_loss = 1.39612876, grad/param norm = 1.5550e-01, time/batch = 19.4578s	
8081/30300 (epoch 13.335), train_loss = 1.24717454, grad/param norm = 1.3916e-01, time/batch = 18.8740s	
8082/30300 (epoch 13.337), train_loss = 1.55339241, grad/param norm = 1.5225e-01, time/batch = 18.7075s	
8083/30300 (epoch 13.338), train_loss = 1.31545798, grad/param norm = 1.3842e-01, time/batch = 19.4691s	
8084/30300 (epoch 13.340), train_loss = 1.28065180, grad/param norm = 1.3703e-01, time/batch = 18.3722s	
8085/30300 (epoch 13.342), train_loss = 1.48357698, grad/param norm = 1.4829e-01, time/batch = 19.0399s	
8086/30300 (epoch 13.343), train_loss = 1.47886605, grad/param norm = 1.6476e-01, time/batch = 19.5509s	
8087/30300 (epoch 13.345), train_loss = 1.41587417, grad/param norm = 1.4390e-01, time/batch = 18.5429s	
8088/30300 (epoch 13.347), train_loss = 1.22401704, grad/param norm = 1.2806e-01, time/batch = 18.3533s	
8089/30300 (epoch 13.348), train_loss = 1.29069478, grad/param norm = 1.4319e-01, time/batch = 18.5492s	
8090/30300 (epoch 13.350), train_loss = 1.37705857, grad/param norm = 1.4439e-01, time/batch = 19.1396s	
8091/30300 (epoch 13.351), train_loss = 1.40048706, grad/param norm = 1.4879e-01, time/batch = 19.1214s	
8092/30300 (epoch 13.353), train_loss = 1.20296520, grad/param norm = 1.4631e-01, time/batch = 19.1413s	
8093/30300 (epoch 13.355), train_loss = 1.35274506, grad/param norm = 1.5230e-01, time/batch = 17.8778s	
8094/30300 (epoch 13.356), train_loss = 1.50116138, grad/param norm = 1.5657e-01, time/batch = 18.6105s	
8095/30300 (epoch 13.358), train_loss = 1.58405830, grad/param norm = 1.4140e-01, time/batch = 17.7104s	
8096/30300 (epoch 13.360), train_loss = 1.32872039, grad/param norm = 1.4405e-01, time/batch = 18.7039s	
8097/30300 (epoch 13.361), train_loss = 1.41231960, grad/param norm = 1.5348e-01, time/batch = 19.9659s	
8098/30300 (epoch 13.363), train_loss = 1.47326670, grad/param norm = 1.4668e-01, time/batch = 17.7990s	
8099/30300 (epoch 13.365), train_loss = 1.30513738, grad/param norm = 1.5283e-01, time/batch = 18.8847s	
8100/30300 (epoch 13.366), train_loss = 1.31863938, grad/param norm = 1.4017e-01, time/batch = 17.7023s	
8101/30300 (epoch 13.368), train_loss = 1.19843806, grad/param norm = 1.5392e-01, time/batch = 18.6242s	
8102/30300 (epoch 13.370), train_loss = 1.27888056, grad/param norm = 1.4677e-01, time/batch = 19.0568s	
8103/30300 (epoch 13.371), train_loss = 1.45593229, grad/param norm = 1.4170e-01, time/batch = 17.9549s	
8104/30300 (epoch 13.373), train_loss = 1.29488001, grad/param norm = 1.2615e-01, time/batch = 18.9651s	
8105/30300 (epoch 13.375), train_loss = 1.29259881, grad/param norm = 1.2953e-01, time/batch = 20.2039s	
8106/30300 (epoch 13.376), train_loss = 1.31633140, grad/param norm = 1.4199e-01, time/batch = 17.6877s	
8107/30300 (epoch 13.378), train_loss = 1.31910091, grad/param norm = 1.4215e-01, time/batch = 16.6661s	
8108/30300 (epoch 13.380), train_loss = 1.58220046, grad/param norm = 1.5157e-01, time/batch = 20.7854s	
8109/30300 (epoch 13.381), train_loss = 1.26095243, grad/param norm = 1.3679e-01, time/batch = 18.3773s	
8110/30300 (epoch 13.383), train_loss = 1.36624917, grad/param norm = 1.9383e-01, time/batch = 18.1928s	
8111/30300 (epoch 13.384), train_loss = 1.48366746, grad/param norm = 1.5170e-01, time/batch = 19.7074s	
8112/30300 (epoch 13.386), train_loss = 1.27043623, grad/param norm = 1.6190e-01, time/batch = 19.1165s	
8113/30300 (epoch 13.388), train_loss = 1.23204940, grad/param norm = 1.2976e-01, time/batch = 19.3639s	
8114/30300 (epoch 13.389), train_loss = 1.39954646, grad/param norm = 1.5719e-01, time/batch = 19.2093s	
8115/30300 (epoch 13.391), train_loss = 1.45324785, grad/param norm = 1.4588e-01, time/batch = 19.0309s	
8116/30300 (epoch 13.393), train_loss = 1.21419511, grad/param norm = 1.3316e-01, time/batch = 17.1151s	
8117/30300 (epoch 13.394), train_loss = 1.41533657, grad/param norm = 1.4451e-01, time/batch = 18.3945s	
8118/30300 (epoch 13.396), train_loss = 1.55829315, grad/param norm = 1.4539e-01, time/batch = 19.8057s	
8119/30300 (epoch 13.398), train_loss = 1.33536563, grad/param norm = 1.2760e-01, time/batch = 18.7977s	
8120/30300 (epoch 13.399), train_loss = 1.36618773, grad/param norm = 1.4490e-01, time/batch = 19.7926s	
8121/30300 (epoch 13.401), train_loss = 1.45656891, grad/param norm = 1.4528e-01, time/batch = 19.1009s	
8122/30300 (epoch 13.403), train_loss = 1.34093947, grad/param norm = 1.4649e-01, time/batch = 17.9575s	
8123/30300 (epoch 13.404), train_loss = 1.28728872, grad/param norm = 1.5440e-01, time/batch = 19.0459s	
8124/30300 (epoch 13.406), train_loss = 1.38463247, grad/param norm = 1.4656e-01, time/batch = 18.8775s	
8125/30300 (epoch 13.408), train_loss = 1.24400977, grad/param norm = 1.3763e-01, time/batch = 15.8204s	
8126/30300 (epoch 13.409), train_loss = 1.21294123, grad/param norm = 1.3867e-01, time/batch = 0.6890s	
8127/30300 (epoch 13.411), train_loss = 1.24281456, grad/param norm = 1.3328e-01, time/batch = 0.7210s	
8128/30300 (epoch 13.413), train_loss = 1.19482149, grad/param norm = 1.4455e-01, time/batch = 0.7068s	
8129/30300 (epoch 13.414), train_loss = 1.51799569, grad/param norm = 1.5029e-01, time/batch = 0.6903s	
8130/30300 (epoch 13.416), train_loss = 1.35093960, grad/param norm = 1.5331e-01, time/batch = 0.6903s	
8131/30300 (epoch 13.417), train_loss = 1.30318411, grad/param norm = 1.4638e-01, time/batch = 0.6958s	
8132/30300 (epoch 13.419), train_loss = 1.24498018, grad/param norm = 1.3094e-01, time/batch = 0.7005s	
8133/30300 (epoch 13.421), train_loss = 1.32124495, grad/param norm = 1.3447e-01, time/batch = 1.0030s	
8134/30300 (epoch 13.422), train_loss = 1.35047803, grad/param norm = 1.4144e-01, time/batch = 1.0102s	
8135/30300 (epoch 13.424), train_loss = 1.37991849, grad/param norm = 1.4535e-01, time/batch = 1.0023s	
8136/30300 (epoch 13.426), train_loss = 1.25513273, grad/param norm = 1.4320e-01, time/batch = 1.0092s	
8137/30300 (epoch 13.427), train_loss = 1.34471049, grad/param norm = 1.5785e-01, time/batch = 1.0530s	
8138/30300 (epoch 13.429), train_loss = 1.37461893, grad/param norm = 1.5226e-01, time/batch = 1.8711s	
8139/30300 (epoch 13.431), train_loss = 1.44070467, grad/param norm = 1.4780e-01, time/batch = 1.9132s	
8140/30300 (epoch 13.432), train_loss = 1.34685615, grad/param norm = 1.4806e-01, time/batch = 9.9235s	
8141/30300 (epoch 13.434), train_loss = 1.20544281, grad/param norm = 1.4107e-01, time/batch = 19.3685s	
8142/30300 (epoch 13.436), train_loss = 1.53452321, grad/param norm = 1.5849e-01, time/batch = 19.5487s	
8143/30300 (epoch 13.437), train_loss = 1.27502222, grad/param norm = 1.4700e-01, time/batch = 20.2042s	
8144/30300 (epoch 13.439), train_loss = 1.29538428, grad/param norm = 1.4313e-01, time/batch = 18.7002s	
8145/30300 (epoch 13.441), train_loss = 1.30807086, grad/param norm = 1.3811e-01, time/batch = 17.2834s	
8146/30300 (epoch 13.442), train_loss = 1.25683763, grad/param norm = 1.3964e-01, time/batch = 19.6212s	
8147/30300 (epoch 13.444), train_loss = 1.16131757, grad/param norm = 1.3965e-01, time/batch = 19.5657s	
8148/30300 (epoch 13.446), train_loss = 1.31705715, grad/param norm = 1.4256e-01, time/batch = 18.2972s	
8149/30300 (epoch 13.447), train_loss = 1.36109433, grad/param norm = 1.5651e-01, time/batch = 19.3648s	
8150/30300 (epoch 13.449), train_loss = 1.29532263, grad/param norm = 1.4330e-01, time/batch = 19.6325s	
8151/30300 (epoch 13.450), train_loss = 1.47427554, grad/param norm = 1.4792e-01, time/batch = 19.3741s	
8152/30300 (epoch 13.452), train_loss = 1.41134828, grad/param norm = 1.3601e-01, time/batch = 18.5498s	
8153/30300 (epoch 13.454), train_loss = 1.39047163, grad/param norm = 1.3731e-01, time/batch = 19.7136s	
8154/30300 (epoch 13.455), train_loss = 1.44721667, grad/param norm = 1.5653e-01, time/batch = 19.2924s	
8155/30300 (epoch 13.457), train_loss = 1.39884396, grad/param norm = 1.4213e-01, time/batch = 17.8641s	
8156/30300 (epoch 13.459), train_loss = 1.46228772, grad/param norm = 1.5345e-01, time/batch = 19.0331s	
8157/30300 (epoch 13.460), train_loss = 1.42475439, grad/param norm = 1.5734e-01, time/batch = 19.4543s	
8158/30300 (epoch 13.462), train_loss = 1.48525957, grad/param norm = 1.5535e-01, time/batch = 17.5995s	
8159/30300 (epoch 13.464), train_loss = 1.22596652, grad/param norm = 1.5590e-01, time/batch = 16.9953s	
8160/30300 (epoch 13.465), train_loss = 1.18069672, grad/param norm = 1.3566e-01, time/batch = 17.6209s	
8161/30300 (epoch 13.467), train_loss = 1.14645399, grad/param norm = 1.3113e-01, time/batch = 17.7632s	
8162/30300 (epoch 13.469), train_loss = 1.26971486, grad/param norm = 1.4466e-01, time/batch = 17.6693s	
8163/30300 (epoch 13.470), train_loss = 1.32969362, grad/param norm = 1.4883e-01, time/batch = 17.0211s	
8164/30300 (epoch 13.472), train_loss = 1.31084360, grad/param norm = 1.3788e-01, time/batch = 17.3620s	
8165/30300 (epoch 13.474), train_loss = 1.37117518, grad/param norm = 1.7448e-01, time/batch = 16.8400s	
8166/30300 (epoch 13.475), train_loss = 1.28023580, grad/param norm = 1.4949e-01, time/batch = 18.1232s	
8167/30300 (epoch 13.477), train_loss = 1.39267129, grad/param norm = 1.5708e-01, time/batch = 19.3786s	
8168/30300 (epoch 13.479), train_loss = 1.37494661, grad/param norm = 1.5129e-01, time/batch = 18.2697s	
8169/30300 (epoch 13.480), train_loss = 1.40748690, grad/param norm = 1.3719e-01, time/batch = 19.3911s	
8170/30300 (epoch 13.482), train_loss = 1.40811798, grad/param norm = 1.3702e-01, time/batch = 19.5568s	
8171/30300 (epoch 13.483), train_loss = 1.31935386, grad/param norm = 1.4750e-01, time/batch = 17.7923s	
8172/30300 (epoch 13.485), train_loss = 1.35597749, grad/param norm = 1.4021e-01, time/batch = 17.9659s	
8173/30300 (epoch 13.487), train_loss = 1.42422326, grad/param norm = 1.5060e-01, time/batch = 19.7946s	
8174/30300 (epoch 13.488), train_loss = 1.44193174, grad/param norm = 1.4478e-01, time/batch = 18.1108s	
8175/30300 (epoch 13.490), train_loss = 1.26474158, grad/param norm = 1.4301e-01, time/batch = 19.5313s	
8176/30300 (epoch 13.492), train_loss = 1.35760842, grad/param norm = 1.4981e-01, time/batch = 17.7820s	
8177/30300 (epoch 13.493), train_loss = 1.32477287, grad/param norm = 1.5075e-01, time/batch = 18.0161s	
8178/30300 (epoch 13.495), train_loss = 1.28827302, grad/param norm = 1.3165e-01, time/batch = 18.0977s	
8179/30300 (epoch 13.497), train_loss = 1.39936351, grad/param norm = 1.4611e-01, time/batch = 19.3831s	
8180/30300 (epoch 13.498), train_loss = 1.39505849, grad/param norm = 1.4761e-01, time/batch = 20.2045s	
8181/30300 (epoch 13.500), train_loss = 1.43953840, grad/param norm = 1.6362e-01, time/batch = 17.5456s	
8182/30300 (epoch 13.502), train_loss = 1.33148123, grad/param norm = 1.4499e-01, time/batch = 19.8684s	
8183/30300 (epoch 13.503), train_loss = 1.44716394, grad/param norm = 1.4611e-01, time/batch = 19.6978s	
8184/30300 (epoch 13.505), train_loss = 1.33588946, grad/param norm = 1.5038e-01, time/batch = 16.6211s	
8185/30300 (epoch 13.507), train_loss = 1.32719564, grad/param norm = 1.8117e-01, time/batch = 20.2855s	
8186/30300 (epoch 13.508), train_loss = 1.39739466, grad/param norm = 1.7893e-01, time/batch = 20.1222s	
8187/30300 (epoch 13.510), train_loss = 1.48820714, grad/param norm = 1.7570e-01, time/batch = 18.2065s	
8188/30300 (epoch 13.512), train_loss = 1.28738323, grad/param norm = 1.4582e-01, time/batch = 18.0577s	
8189/30300 (epoch 13.513), train_loss = 1.43740645, grad/param norm = 1.4989e-01, time/batch = 17.8636s	
8190/30300 (epoch 13.515), train_loss = 1.34529169, grad/param norm = 1.4257e-01, time/batch = 16.3692s	
8191/30300 (epoch 13.517), train_loss = 1.19466099, grad/param norm = 1.3596e-01, time/batch = 18.4512s	
8192/30300 (epoch 13.518), train_loss = 1.46129856, grad/param norm = 1.6533e-01, time/batch = 18.9311s	
8193/30300 (epoch 13.520), train_loss = 1.52671986, grad/param norm = 1.6289e-01, time/batch = 19.6117s	
8194/30300 (epoch 13.521), train_loss = 1.25273784, grad/param norm = 1.5698e-01, time/batch = 18.3799s	
8195/30300 (epoch 13.523), train_loss = 1.51731958, grad/param norm = 1.6725e-01, time/batch = 17.6973s	
8196/30300 (epoch 13.525), train_loss = 1.28691764, grad/param norm = 1.4723e-01, time/batch = 19.2052s	
8197/30300 (epoch 13.526), train_loss = 1.35047738, grad/param norm = 1.4567e-01, time/batch = 19.1159s	
8198/30300 (epoch 13.528), train_loss = 1.21297179, grad/param norm = 1.4148e-01, time/batch = 18.1160s	
8199/30300 (epoch 13.530), train_loss = 1.24486455, grad/param norm = 1.4788e-01, time/batch = 19.4541s	
8200/30300 (epoch 13.531), train_loss = 1.42274865, grad/param norm = 1.4929e-01, time/batch = 18.2200s	
8201/30300 (epoch 13.533), train_loss = 1.41260719, grad/param norm = 1.6163e-01, time/batch = 19.0449s	
8202/30300 (epoch 13.535), train_loss = 1.20514941, grad/param norm = 1.2638e-01, time/batch = 18.1964s	
8203/30300 (epoch 13.536), train_loss = 1.39911027, grad/param norm = 1.5158e-01, time/batch = 25.3045s	
8204/30300 (epoch 13.538), train_loss = 1.19232126, grad/param norm = 1.5659e-01, time/batch = 23.8723s	
8205/30300 (epoch 13.540), train_loss = 1.26211131, grad/param norm = 1.5048e-01, time/batch = 19.5266s	
8206/30300 (epoch 13.541), train_loss = 1.34776117, grad/param norm = 1.5972e-01, time/batch = 17.1071s	
8207/30300 (epoch 13.543), train_loss = 1.37393610, grad/param norm = 1.4744e-01, time/batch = 17.9991s	
8208/30300 (epoch 13.545), train_loss = 1.38655647, grad/param norm = 1.5665e-01, time/batch = 18.3708s	
8209/30300 (epoch 13.546), train_loss = 1.58971668, grad/param norm = 1.4573e-01, time/batch = 17.5278s	
8210/30300 (epoch 13.548), train_loss = 1.28903198, grad/param norm = 1.4476e-01, time/batch = 19.4375s	
8211/30300 (epoch 13.550), train_loss = 1.48063105, grad/param norm = 1.7327e-01, time/batch = 20.1052s	
8212/30300 (epoch 13.551), train_loss = 1.28044260, grad/param norm = 1.3853e-01, time/batch = 18.6201s	
8213/30300 (epoch 13.553), train_loss = 1.31590651, grad/param norm = 1.5426e-01, time/batch = 19.4503s	
8214/30300 (epoch 13.554), train_loss = 1.43073488, grad/param norm = 1.5446e-01, time/batch = 20.1163s	
8215/30300 (epoch 13.556), train_loss = 1.43457804, grad/param norm = 1.5507e-01, time/batch = 18.6029s	
8216/30300 (epoch 13.558), train_loss = 1.51331601, grad/param norm = 1.5852e-01, time/batch = 17.9452s	
8217/30300 (epoch 13.559), train_loss = 1.41227282, grad/param norm = 1.5817e-01, time/batch = 19.8718s	
8218/30300 (epoch 13.561), train_loss = 1.23701741, grad/param norm = 1.4988e-01, time/batch = 18.9481s	
8219/30300 (epoch 13.563), train_loss = 1.25343854, grad/param norm = 1.3235e-01, time/batch = 18.2709s	
8220/30300 (epoch 13.564), train_loss = 1.30009621, grad/param norm = 1.4092e-01, time/batch = 16.9101s	
8221/30300 (epoch 13.566), train_loss = 1.37554020, grad/param norm = 1.4134e-01, time/batch = 19.1851s	
8222/30300 (epoch 13.568), train_loss = 1.16144827, grad/param norm = 1.4696e-01, time/batch = 18.2538s	
8223/30300 (epoch 13.569), train_loss = 1.36180298, grad/param norm = 1.4355e-01, time/batch = 17.9532s	
8224/30300 (epoch 13.571), train_loss = 1.40125052, grad/param norm = 1.5223e-01, time/batch = 18.4374s	
8225/30300 (epoch 13.573), train_loss = 1.38834233, grad/param norm = 1.4549e-01, time/batch = 17.0289s	
8226/30300 (epoch 13.574), train_loss = 1.44223917, grad/param norm = 1.4572e-01, time/batch = 19.8376s	
8227/30300 (epoch 13.576), train_loss = 1.33309978, grad/param norm = 1.3755e-01, time/batch = 19.6957s	
8228/30300 (epoch 13.578), train_loss = 1.23352476, grad/param norm = 1.4121e-01, time/batch = 18.1155s	
8229/30300 (epoch 13.579), train_loss = 1.40452966, grad/param norm = 1.6124e-01, time/batch = 19.8553s	
8230/30300 (epoch 13.581), train_loss = 1.44608252, grad/param norm = 1.4002e-01, time/batch = 18.7959s	
8231/30300 (epoch 13.583), train_loss = 1.55213708, grad/param norm = 1.6745e-01, time/batch = 17.5091s	
8232/30300 (epoch 13.584), train_loss = 1.43899980, grad/param norm = 1.4567e-01, time/batch = 19.2929s	
8233/30300 (epoch 13.586), train_loss = 1.38095668, grad/param norm = 1.5234e-01, time/batch = 18.8025s	
8234/30300 (epoch 13.587), train_loss = 1.38450102, grad/param norm = 1.5560e-01, time/batch = 18.6622s	
8235/30300 (epoch 13.589), train_loss = 1.23937997, grad/param norm = 1.3682e-01, time/batch = 17.8476s	
8236/30300 (epoch 13.591), train_loss = 1.39517224, grad/param norm = 1.3979e-01, time/batch = 18.9345s	
8237/30300 (epoch 13.592), train_loss = 1.34689535, grad/param norm = 1.3304e-01, time/batch = 19.6782s	
8238/30300 (epoch 13.594), train_loss = 1.39210043, grad/param norm = 1.5344e-01, time/batch = 18.5983s	
8239/30300 (epoch 13.596), train_loss = 1.24134481, grad/param norm = 1.2633e-01, time/batch = 20.4463s	
8240/30300 (epoch 13.597), train_loss = 1.30714939, grad/param norm = 1.4866e-01, time/batch = 18.0111s	
8241/30300 (epoch 13.599), train_loss = 1.17794721, grad/param norm = 1.4224e-01, time/batch = 16.4003s	
8242/30300 (epoch 13.601), train_loss = 1.42513864, grad/param norm = 1.4862e-01, time/batch = 17.7443s	
8243/30300 (epoch 13.602), train_loss = 1.36288245, grad/param norm = 1.3754e-01, time/batch = 16.7561s	
8244/30300 (epoch 13.604), train_loss = 1.25738768, grad/param norm = 1.2887e-01, time/batch = 19.1671s	
8245/30300 (epoch 13.606), train_loss = 1.38326668, grad/param norm = 1.6165e-01, time/batch = 17.7433s	
8246/30300 (epoch 13.607), train_loss = 1.44297847, grad/param norm = 1.5592e-01, time/batch = 17.3849s	
8247/30300 (epoch 13.609), train_loss = 1.58184418, grad/param norm = 1.6503e-01, time/batch = 16.0561s	
8248/30300 (epoch 13.611), train_loss = 1.29380302, grad/param norm = 1.4227e-01, time/batch = 17.5940s	
8249/30300 (epoch 13.612), train_loss = 1.26732540, grad/param norm = 1.4887e-01, time/batch = 19.8496s	
8250/30300 (epoch 13.614), train_loss = 1.26676733, grad/param norm = 1.3791e-01, time/batch = 18.1754s	
8251/30300 (epoch 13.616), train_loss = 1.41136655, grad/param norm = 1.5519e-01, time/batch = 16.7265s	
8252/30300 (epoch 13.617), train_loss = 1.33406456, grad/param norm = 1.4622e-01, time/batch = 19.3946s	
8253/30300 (epoch 13.619), train_loss = 1.16213716, grad/param norm = 1.3336e-01, time/batch = 19.0250s	
8254/30300 (epoch 13.620), train_loss = 1.38360056, grad/param norm = 1.4466e-01, time/batch = 17.8454s	
8255/30300 (epoch 13.622), train_loss = 1.35505398, grad/param norm = 1.6887e-01, time/batch = 16.1201s	
8256/30300 (epoch 13.624), train_loss = 1.28095936, grad/param norm = 1.5569e-01, time/batch = 15.4670s	
8257/30300 (epoch 13.625), train_loss = 1.32029005, grad/param norm = 1.5636e-01, time/batch = 17.0634s	
8258/30300 (epoch 13.627), train_loss = 1.52022410, grad/param norm = 1.6933e-01, time/batch = 17.8520s	
8259/30300 (epoch 13.629), train_loss = 1.43024995, grad/param norm = 1.4327e-01, time/batch = 19.0237s	
8260/30300 (epoch 13.630), train_loss = 1.37609964, grad/param norm = 1.3832e-01, time/batch = 19.2358s	
8261/30300 (epoch 13.632), train_loss = 1.46556277, grad/param norm = 1.5457e-01, time/batch = 19.3626s	
8262/30300 (epoch 13.634), train_loss = 1.22154815, grad/param norm = 1.3003e-01, time/batch = 19.6089s	
8263/30300 (epoch 13.635), train_loss = 1.42279453, grad/param norm = 1.4647e-01, time/batch = 17.0742s	
8264/30300 (epoch 13.637), train_loss = 1.43504538, grad/param norm = 1.6268e-01, time/batch = 17.0421s	
8265/30300 (epoch 13.639), train_loss = 1.28721271, grad/param norm = 1.4324e-01, time/batch = 15.4850s	
8266/30300 (epoch 13.640), train_loss = 1.49053171, grad/param norm = 1.5851e-01, time/batch = 18.1661s	
8267/30300 (epoch 13.642), train_loss = 1.31234904, grad/param norm = 1.3561e-01, time/batch = 16.7460s	
8268/30300 (epoch 13.644), train_loss = 1.41726525, grad/param norm = 1.4087e-01, time/batch = 15.3943s	
8269/30300 (epoch 13.645), train_loss = 1.22399671, grad/param norm = 1.3512e-01, time/batch = 17.7373s	
8270/30300 (epoch 13.647), train_loss = 1.33114174, grad/param norm = 1.3782e-01, time/batch = 15.2899s	
8271/30300 (epoch 13.649), train_loss = 1.32101689, grad/param norm = 1.4947e-01, time/batch = 17.4020s	
8272/30300 (epoch 13.650), train_loss = 1.33174366, grad/param norm = 1.4014e-01, time/batch = 16.9229s	
8273/30300 (epoch 13.652), train_loss = 1.28998283, grad/param norm = 1.3527e-01, time/batch = 17.3376s	
8274/30300 (epoch 13.653), train_loss = 1.55018876, grad/param norm = 1.5648e-01, time/batch = 16.8170s	
8275/30300 (epoch 13.655), train_loss = 1.29465646, grad/param norm = 1.5464e-01, time/batch = 17.3447s	
8276/30300 (epoch 13.657), train_loss = 1.34091894, grad/param norm = 1.5495e-01, time/batch = 18.9309s	
8277/30300 (epoch 13.658), train_loss = 1.29773377, grad/param norm = 1.4632e-01, time/batch = 19.9189s	
8278/30300 (epoch 13.660), train_loss = 1.41686392, grad/param norm = 1.5077e-01, time/batch = 17.7655s	
8279/30300 (epoch 13.662), train_loss = 1.41265548, grad/param norm = 1.6768e-01, time/batch = 19.0311s	
8280/30300 (epoch 13.663), train_loss = 1.39452598, grad/param norm = 1.4865e-01, time/batch = 19.0255s	
8281/30300 (epoch 13.665), train_loss = 1.26534865, grad/param norm = 1.5080e-01, time/batch = 17.9564s	
8282/30300 (epoch 13.667), train_loss = 1.45914711, grad/param norm = 1.4473e-01, time/batch = 16.6224s	
8283/30300 (epoch 13.668), train_loss = 1.51748020, grad/param norm = 1.6341e-01, time/batch = 18.3687s	
8284/30300 (epoch 13.670), train_loss = 1.50338513, grad/param norm = 1.5065e-01, time/batch = 17.0492s	
8285/30300 (epoch 13.672), train_loss = 1.42894830, grad/param norm = 1.5274e-01, time/batch = 17.2298s	
8286/30300 (epoch 13.673), train_loss = 1.45710425, grad/param norm = 1.5893e-01, time/batch = 15.2174s	
8287/30300 (epoch 13.675), train_loss = 1.30543107, grad/param norm = 1.5082e-01, time/batch = 17.6681s	
8288/30300 (epoch 13.677), train_loss = 1.27848672, grad/param norm = 1.3459e-01, time/batch = 17.8508s	
8289/30300 (epoch 13.678), train_loss = 1.31676909, grad/param norm = 1.4909e-01, time/batch = 17.9526s	
8290/30300 (epoch 13.680), train_loss = 1.14454105, grad/param norm = 1.3408e-01, time/batch = 16.5695s	
8291/30300 (epoch 13.682), train_loss = 1.33905373, grad/param norm = 1.4414e-01, time/batch = 19.3408s	
8292/30300 (epoch 13.683), train_loss = 1.39510942, grad/param norm = 1.3532e-01, time/batch = 16.8824s	
8293/30300 (epoch 13.685), train_loss = 1.47368402, grad/param norm = 1.5972e-01, time/batch = 17.8530s	
8294/30300 (epoch 13.686), train_loss = 1.35598630, grad/param norm = 1.4661e-01, time/batch = 16.9879s	
8295/30300 (epoch 13.688), train_loss = 1.37695272, grad/param norm = 1.4459e-01, time/batch = 19.2807s	
8296/30300 (epoch 13.690), train_loss = 1.30564329, grad/param norm = 1.5411e-01, time/batch = 18.0216s	
8297/30300 (epoch 13.691), train_loss = 1.37931727, grad/param norm = 1.4480e-01, time/batch = 16.5847s	
8298/30300 (epoch 13.693), train_loss = 1.75931789, grad/param norm = 1.7245e-01, time/batch = 19.4544s	
8299/30300 (epoch 13.695), train_loss = 1.51864859, grad/param norm = 1.6773e-01, time/batch = 19.1939s	
8300/30300 (epoch 13.696), train_loss = 1.49756684, grad/param norm = 1.6969e-01, time/batch = 18.6216s	
8301/30300 (epoch 13.698), train_loss = 1.32007648, grad/param norm = 1.4654e-01, time/batch = 18.7040s	
8302/30300 (epoch 13.700), train_loss = 1.31936430, grad/param norm = 1.5054e-01, time/batch = 16.1542s	
8303/30300 (epoch 13.701), train_loss = 1.17505076, grad/param norm = 1.3387e-01, time/batch = 17.1479s	
8304/30300 (epoch 13.703), train_loss = 1.36896786, grad/param norm = 1.3882e-01, time/batch = 17.5854s	
8305/30300 (epoch 13.705), train_loss = 1.33579176, grad/param norm = 1.5507e-01, time/batch = 18.1123s	
8306/30300 (epoch 13.706), train_loss = 1.42252537, grad/param norm = 1.5109e-01, time/batch = 18.0784s	
8307/30300 (epoch 13.708), train_loss = 1.30659054, grad/param norm = 1.4163e-01, time/batch = 16.2219s	
8308/30300 (epoch 13.710), train_loss = 1.32618404, grad/param norm = 1.4755e-01, time/batch = 17.1850s	
8309/30300 (epoch 13.711), train_loss = 1.24082543, grad/param norm = 1.3677e-01, time/batch = 15.9659s	
8310/30300 (epoch 13.713), train_loss = 1.23680645, grad/param norm = 1.3724e-01, time/batch = 16.0426s	
8311/30300 (epoch 13.715), train_loss = 1.30894997, grad/param norm = 1.4374e-01, time/batch = 16.5709s	
8312/30300 (epoch 13.716), train_loss = 1.48781088, grad/param norm = 1.5910e-01, time/batch = 16.1282s	
8313/30300 (epoch 13.718), train_loss = 1.48153236, grad/param norm = 1.6364e-01, time/batch = 17.5649s	
8314/30300 (epoch 13.719), train_loss = 1.33208465, grad/param norm = 1.6245e-01, time/batch = 17.6578s	
8315/30300 (epoch 13.721), train_loss = 1.36879222, grad/param norm = 1.5809e-01, time/batch = 17.1552s	
8316/30300 (epoch 13.723), train_loss = 1.28417693, grad/param norm = 1.4696e-01, time/batch = 18.5893s	
8317/30300 (epoch 13.724), train_loss = 1.44295954, grad/param norm = 1.6125e-01, time/batch = 19.4527s	
8318/30300 (epoch 13.726), train_loss = 1.78452767, grad/param norm = 1.8040e-01, time/batch = 19.2757s	
8319/30300 (epoch 13.728), train_loss = 1.39460991, grad/param norm = 1.5839e-01, time/batch = 17.1680s	
8320/30300 (epoch 13.729), train_loss = 1.36029424, grad/param norm = 1.6005e-01, time/batch = 18.2562s	
8321/30300 (epoch 13.731), train_loss = 1.44375510, grad/param norm = 1.5248e-01, time/batch = 19.3690s	
8322/30300 (epoch 13.733), train_loss = 1.34612430, grad/param norm = 1.4103e-01, time/batch = 18.2742s	
8323/30300 (epoch 13.734), train_loss = 1.42743649, grad/param norm = 1.4033e-01, time/batch = 19.8536s	
8324/30300 (epoch 13.736), train_loss = 1.34634771, grad/param norm = 1.3612e-01, time/batch = 17.2252s	
8325/30300 (epoch 13.738), train_loss = 1.21934499, grad/param norm = 1.2963e-01, time/batch = 16.1399s	
8326/30300 (epoch 13.739), train_loss = 1.39973921, grad/param norm = 1.4252e-01, time/batch = 19.4259s	
8327/30300 (epoch 13.741), train_loss = 1.46788487, grad/param norm = 1.4442e-01, time/batch = 19.2915s	
8328/30300 (epoch 13.743), train_loss = 1.31345327, grad/param norm = 1.4238e-01, time/batch = 19.0812s	
8329/30300 (epoch 13.744), train_loss = 1.42784655, grad/param norm = 1.5254e-01, time/batch = 16.4683s	
8330/30300 (epoch 13.746), train_loss = 1.22864128, grad/param norm = 1.3707e-01, time/batch = 17.2276s	
8331/30300 (epoch 13.748), train_loss = 1.37576786, grad/param norm = 1.6362e-01, time/batch = 18.1763s	
8332/30300 (epoch 13.749), train_loss = 1.40777675, grad/param norm = 1.5916e-01, time/batch = 17.7791s	
8333/30300 (epoch 13.751), train_loss = 1.29760041, grad/param norm = 1.4322e-01, time/batch = 19.7747s	
8334/30300 (epoch 13.752), train_loss = 1.30840761, grad/param norm = 1.4115e-01, time/batch = 19.4549s	
8335/30300 (epoch 13.754), train_loss = 1.24584752, grad/param norm = 1.3114e-01, time/batch = 18.3396s	
8336/30300 (epoch 13.756), train_loss = 1.31708021, grad/param norm = 1.4342e-01, time/batch = 19.4330s	
8337/30300 (epoch 13.757), train_loss = 1.41232908, grad/param norm = 1.5708e-01, time/batch = 17.9383s	
8338/30300 (epoch 13.759), train_loss = 1.33480467, grad/param norm = 1.3728e-01, time/batch = 18.0280s	
8339/30300 (epoch 13.761), train_loss = 1.21943446, grad/param norm = 1.3671e-01, time/batch = 19.1866s	
8340/30300 (epoch 13.762), train_loss = 1.16059124, grad/param norm = 1.2831e-01, time/batch = 19.6119s	
8341/30300 (epoch 13.764), train_loss = 1.32157161, grad/param norm = 1.3955e-01, time/batch = 17.4398s	
8342/30300 (epoch 13.766), train_loss = 1.38696956, grad/param norm = 1.3871e-01, time/batch = 19.3590s	
8343/30300 (epoch 13.767), train_loss = 1.45037353, grad/param norm = 1.7402e-01, time/batch = 17.6798s	
8344/30300 (epoch 13.769), train_loss = 1.42917328, grad/param norm = 1.4496e-01, time/batch = 16.0608s	
8345/30300 (epoch 13.771), train_loss = 1.32451616, grad/param norm = 1.5582e-01, time/batch = 19.0133s	
8346/30300 (epoch 13.772), train_loss = 1.39673656, grad/param norm = 1.5455e-01, time/batch = 19.7010s	
8347/30300 (epoch 13.774), train_loss = 1.53377203, grad/param norm = 1.4426e-01, time/batch = 20.0413s	
8348/30300 (epoch 13.776), train_loss = 1.42200561, grad/param norm = 1.6020e-01, time/batch = 18.1806s	
8349/30300 (epoch 13.777), train_loss = 1.38614296, grad/param norm = 1.3689e-01, time/batch = 19.4680s	
8350/30300 (epoch 13.779), train_loss = 1.54208905, grad/param norm = 1.7723e-01, time/batch = 20.1990s	
8351/30300 (epoch 13.781), train_loss = 1.36799601, grad/param norm = 1.6009e-01, time/batch = 17.5167s	
8352/30300 (epoch 13.782), train_loss = 1.31033075, grad/param norm = 1.4172e-01, time/batch = 17.9220s	
8353/30300 (epoch 13.784), train_loss = 1.28726827, grad/param norm = 1.3662e-01, time/batch = 19.6789s	
8354/30300 (epoch 13.785), train_loss = 1.51805054, grad/param norm = 1.6372e-01, time/batch = 18.7911s	
8355/30300 (epoch 13.787), train_loss = 1.22137250, grad/param norm = 1.4581e-01, time/batch = 19.0563s	
8356/30300 (epoch 13.789), train_loss = 1.63512691, grad/param norm = 1.5877e-01, time/batch = 18.8838s	
8357/30300 (epoch 13.790), train_loss = 1.44612189, grad/param norm = 1.6158e-01, time/batch = 19.3654s	
8358/30300 (epoch 13.792), train_loss = 1.22616443, grad/param norm = 1.6128e-01, time/batch = 19.2802s	
8359/30300 (epoch 13.794), train_loss = 1.31516804, grad/param norm = 1.4897e-01, time/batch = 17.6880s	
8360/30300 (epoch 13.795), train_loss = 1.31064647, grad/param norm = 1.3291e-01, time/batch = 19.4440s	
8361/30300 (epoch 13.797), train_loss = 1.56380187, grad/param norm = 1.6880e-01, time/batch = 19.1058s	
8362/30300 (epoch 13.799), train_loss = 1.42959866, grad/param norm = 1.5915e-01, time/batch = 18.9990s	
8363/30300 (epoch 13.800), train_loss = 1.43350441, grad/param norm = 1.5588e-01, time/batch = 19.0880s	
8364/30300 (epoch 13.802), train_loss = 1.60379668, grad/param norm = 1.6964e-01, time/batch = 17.8325s	
8365/30300 (epoch 13.804), train_loss = 1.43850894, grad/param norm = 1.5228e-01, time/batch = 19.6865s	
8366/30300 (epoch 13.805), train_loss = 1.55716232, grad/param norm = 1.7106e-01, time/batch = 20.3573s	
8367/30300 (epoch 13.807), train_loss = 1.37186420, grad/param norm = 1.5650e-01, time/batch = 17.9302s	
8368/30300 (epoch 13.809), train_loss = 1.47830556, grad/param norm = 1.6741e-01, time/batch = 19.8644s	
8369/30300 (epoch 13.810), train_loss = 1.45384622, grad/param norm = 1.4620e-01, time/batch = 19.8516s	
8370/30300 (epoch 13.812), train_loss = 1.25853400, grad/param norm = 1.4733e-01, time/batch = 17.7726s	
8371/30300 (epoch 13.814), train_loss = 1.39736417, grad/param norm = 1.6001e-01, time/batch = 18.7753s	
8372/30300 (epoch 13.815), train_loss = 1.41951898, grad/param norm = 1.5597e-01, time/batch = 17.2983s	
8373/30300 (epoch 13.817), train_loss = 1.48722453, grad/param norm = 1.6569e-01, time/batch = 16.9092s	
8374/30300 (epoch 13.818), train_loss = 1.41719528, grad/param norm = 1.4340e-01, time/batch = 18.3710s	
8375/30300 (epoch 13.820), train_loss = 1.60718612, grad/param norm = 1.7349e-01, time/batch = 18.6235s	
8376/30300 (epoch 13.822), train_loss = 1.59882419, grad/param norm = 1.7652e-01, time/batch = 19.5386s	
8377/30300 (epoch 13.823), train_loss = 1.64407990, grad/param norm = 1.7832e-01, time/batch = 18.8655s	
8378/30300 (epoch 13.825), train_loss = 1.49686577, grad/param norm = 1.6392e-01, time/batch = 19.0186s	
8379/30300 (epoch 13.827), train_loss = 1.26963028, grad/param norm = 1.7120e-01, time/batch = 19.9432s	
8380/30300 (epoch 13.828), train_loss = 1.42505030, grad/param norm = 1.4674e-01, time/batch = 16.8986s	
8381/30300 (epoch 13.830), train_loss = 1.40493988, grad/param norm = 1.5293e-01, time/batch = 17.2275s	
8382/30300 (epoch 13.832), train_loss = 1.33707435, grad/param norm = 1.5438e-01, time/batch = 19.3347s	
8383/30300 (epoch 13.833), train_loss = 1.44819492, grad/param norm = 1.5132e-01, time/batch = 18.3742s	
8384/30300 (epoch 13.835), train_loss = 1.33884169, grad/param norm = 1.5768e-01, time/batch = 18.6197s	
8385/30300 (epoch 13.837), train_loss = 1.21274623, grad/param norm = 1.4127e-01, time/batch = 17.7020s	
8386/30300 (epoch 13.838), train_loss = 1.23528145, grad/param norm = 1.4332e-01, time/batch = 18.3834s	
8387/30300 (epoch 13.840), train_loss = 1.42870148, grad/param norm = 1.3135e-01, time/batch = 19.2651s	
8388/30300 (epoch 13.842), train_loss = 1.24970058, grad/param norm = 1.3506e-01, time/batch = 20.0333s	
8389/30300 (epoch 13.843), train_loss = 1.39852642, grad/param norm = 1.4034e-01, time/batch = 17.4403s	
8390/30300 (epoch 13.845), train_loss = 1.36633805, grad/param norm = 1.3299e-01, time/batch = 19.6114s	
8391/30300 (epoch 13.847), train_loss = 1.40911777, grad/param norm = 1.6632e-01, time/batch = 19.6058s	
8392/30300 (epoch 13.848), train_loss = 1.48966160, grad/param norm = 1.5042e-01, time/batch = 19.5493s	
8393/30300 (epoch 13.850), train_loss = 1.34477769, grad/param norm = 1.4277e-01, time/batch = 19.6293s	
8394/30300 (epoch 13.851), train_loss = 1.47554543, grad/param norm = 1.7018e-01, time/batch = 19.6380s	
8395/30300 (epoch 13.853), train_loss = 1.29079397, grad/param norm = 1.3351e-01, time/batch = 18.9456s	
8396/30300 (epoch 13.855), train_loss = 1.31077725, grad/param norm = 1.3273e-01, time/batch = 20.1198s	
8397/30300 (epoch 13.856), train_loss = 1.32941682, grad/param norm = 1.4721e-01, time/batch = 18.6917s	
8398/30300 (epoch 13.858), train_loss = 1.29693615, grad/param norm = 1.3626e-01, time/batch = 19.4613s	
8399/30300 (epoch 13.860), train_loss = 1.30675074, grad/param norm = 1.4975e-01, time/batch = 33.2207s	
8400/30300 (epoch 13.861), train_loss = 1.53364116, grad/param norm = 1.4874e-01, time/batch = 19.2089s	
8401/30300 (epoch 13.863), train_loss = 1.37608628, grad/param norm = 1.3616e-01, time/batch = 17.3699s	
8402/30300 (epoch 13.865), train_loss = 1.51251884, grad/param norm = 1.5090e-01, time/batch = 18.7152s	
8403/30300 (epoch 13.866), train_loss = 1.43305719, grad/param norm = 1.4996e-01, time/batch = 17.3799s	
8404/30300 (epoch 13.868), train_loss = 1.36063093, grad/param norm = 1.4003e-01, time/batch = 18.7710s	
8405/30300 (epoch 13.870), train_loss = 1.34016242, grad/param norm = 1.4299e-01, time/batch = 19.0387s	
8406/30300 (epoch 13.871), train_loss = 1.32236758, grad/param norm = 1.3002e-01, time/batch = 19.1427s	
8407/30300 (epoch 13.873), train_loss = 1.37515312, grad/param norm = 1.3429e-01, time/batch = 17.1235s	
8408/30300 (epoch 13.875), train_loss = 1.23662309, grad/param norm = 1.3346e-01, time/batch = 17.9433s	
8409/30300 (epoch 13.876), train_loss = 1.26452839, grad/param norm = 1.3894e-01, time/batch = 19.3740s	
8410/30300 (epoch 13.878), train_loss = 1.15938032, grad/param norm = 1.4594e-01, time/batch = 19.4702s	
8411/30300 (epoch 13.880), train_loss = 1.27178561, grad/param norm = 1.3681e-01, time/batch = 17.4193s	
8412/30300 (epoch 13.881), train_loss = 1.58791707, grad/param norm = 1.5825e-01, time/batch = 16.5981s	
8413/30300 (epoch 13.883), train_loss = 1.43693193, grad/param norm = 1.5087e-01, time/batch = 19.7114s	
8414/30300 (epoch 13.884), train_loss = 1.21339588, grad/param norm = 1.2544e-01, time/batch = 18.2863s	
8415/30300 (epoch 13.886), train_loss = 1.37483788, grad/param norm = 1.4356e-01, time/batch = 20.1227s	
8416/30300 (epoch 13.888), train_loss = 1.39484062, grad/param norm = 1.5190e-01, time/batch = 19.6433s	
8417/30300 (epoch 13.889), train_loss = 1.36008592, grad/param norm = 1.4737e-01, time/batch = 18.1055s	
8418/30300 (epoch 13.891), train_loss = 1.35415630, grad/param norm = 1.4168e-01, time/batch = 19.3811s	
8419/30300 (epoch 13.893), train_loss = 1.62260136, grad/param norm = 1.5560e-01, time/batch = 19.5407s	
8420/30300 (epoch 13.894), train_loss = 1.49315865, grad/param norm = 1.4987e-01, time/batch = 19.1199s	
8421/30300 (epoch 13.896), train_loss = 1.19445390, grad/param norm = 1.4470e-01, time/batch = 17.6162s	
8422/30300 (epoch 13.898), train_loss = 1.15015544, grad/param norm = 1.4227e-01, time/batch = 19.1499s	
8423/30300 (epoch 13.899), train_loss = 1.30230880, grad/param norm = 1.4552e-01, time/batch = 18.6286s	
8424/30300 (epoch 13.901), train_loss = 1.36906997, grad/param norm = 1.8063e-01, time/batch = 18.7205s	
8425/30300 (epoch 13.903), train_loss = 1.41514703, grad/param norm = 1.5415e-01, time/batch = 20.1262s	
8426/30300 (epoch 13.904), train_loss = 1.32157748, grad/param norm = 1.5142e-01, time/batch = 18.7921s	
8427/30300 (epoch 13.906), train_loss = 1.50883103, grad/param norm = 1.5413e-01, time/batch = 19.0327s	
8428/30300 (epoch 13.908), train_loss = 1.25861158, grad/param norm = 1.3483e-01, time/batch = 18.9641s	
8429/30300 (epoch 13.909), train_loss = 1.32325161, grad/param norm = 1.6151e-01, time/batch = 19.2007s	
8430/30300 (epoch 13.911), train_loss = 1.33763864, grad/param norm = 1.4109e-01, time/batch = 18.6161s	
8431/30300 (epoch 13.913), train_loss = 1.35228268, grad/param norm = 1.3584e-01, time/batch = 19.2175s	
8432/30300 (epoch 13.914), train_loss = 1.36213836, grad/param norm = 1.5919e-01, time/batch = 19.7097s	
8433/30300 (epoch 13.916), train_loss = 1.37372253, grad/param norm = 1.4008e-01, time/batch = 18.0376s	
8434/30300 (epoch 13.917), train_loss = 1.25776676, grad/param norm = 1.3658e-01, time/batch = 19.7230s	
8435/30300 (epoch 13.919), train_loss = 1.33969529, grad/param norm = 1.5080e-01, time/batch = 19.2102s	
8436/30300 (epoch 13.921), train_loss = 1.36307522, grad/param norm = 1.4290e-01, time/batch = 16.9712s	
8437/30300 (epoch 13.922), train_loss = 1.45711068, grad/param norm = 1.6357e-01, time/batch = 20.2171s	
8438/30300 (epoch 13.924), train_loss = 1.36714604, grad/param norm = 1.5139e-01, time/batch = 19.8840s	
8439/30300 (epoch 13.926), train_loss = 1.34996559, grad/param norm = 1.4664e-01, time/batch = 17.5345s	
8440/30300 (epoch 13.927), train_loss = 1.35490033, grad/param norm = 1.5235e-01, time/batch = 18.2018s	
8441/30300 (epoch 13.929), train_loss = 1.31284767, grad/param norm = 1.5001e-01, time/batch = 19.8968s	
8442/30300 (epoch 13.931), train_loss = 1.51172681, grad/param norm = 1.7450e-01, time/batch = 19.3006s	
8443/30300 (epoch 13.932), train_loss = 1.29327032, grad/param norm = 1.4586e-01, time/batch = 19.2090s	
8444/30300 (epoch 13.934), train_loss = 1.39800481, grad/param norm = 1.5291e-01, time/batch = 20.4466s	
8445/30300 (epoch 13.936), train_loss = 1.32699257, grad/param norm = 1.4303e-01, time/batch = 18.0352s	
8446/30300 (epoch 13.937), train_loss = 1.30964531, grad/param norm = 1.4460e-01, time/batch = 16.5425s	
8447/30300 (epoch 13.939), train_loss = 1.49008627, grad/param norm = 1.5410e-01, time/batch = 16.8572s	
8448/30300 (epoch 13.941), train_loss = 1.36083840, grad/param norm = 1.5401e-01, time/batch = 19.5292s	
8449/30300 (epoch 13.942), train_loss = 1.36211314, grad/param norm = 1.4194e-01, time/batch = 17.4618s	
8450/30300 (epoch 13.944), train_loss = 1.26793601, grad/param norm = 1.3693e-01, time/batch = 18.9564s	
8451/30300 (epoch 13.946), train_loss = 1.52663960, grad/param norm = 1.8105e-01, time/batch = 18.5321s	
8452/30300 (epoch 13.947), train_loss = 1.53247747, grad/param norm = 1.8969e-01, time/batch = 18.4490s	
8453/30300 (epoch 13.949), train_loss = 1.54565954, grad/param norm = 1.6185e-01, time/batch = 19.2119s	
8454/30300 (epoch 13.950), train_loss = 1.50397820, grad/param norm = 1.6606e-01, time/batch = 16.2122s	
8455/30300 (epoch 13.952), train_loss = 1.45665764, grad/param norm = 1.6015e-01, time/batch = 18.7807s	
8456/30300 (epoch 13.954), train_loss = 1.64239468, grad/param norm = 1.5831e-01, time/batch = 18.3827s	
8457/30300 (epoch 13.955), train_loss = 1.31667949, grad/param norm = 1.4834e-01, time/batch = 19.3831s	
8458/30300 (epoch 13.957), train_loss = 1.42077446, grad/param norm = 1.5312e-01, time/batch = 19.0457s	
8459/30300 (epoch 13.959), train_loss = 1.38984095, grad/param norm = 1.6056e-01, time/batch = 18.9479s	
8460/30300 (epoch 13.960), train_loss = 1.37026839, grad/param norm = 1.5879e-01, time/batch = 19.4562s	
8461/30300 (epoch 13.962), train_loss = 1.32344681, grad/param norm = 1.6578e-01, time/batch = 18.6973s	
8462/30300 (epoch 13.964), train_loss = 1.32836756, grad/param norm = 1.6688e-01, time/batch = 19.1732s	
8463/30300 (epoch 13.965), train_loss = 1.29797325, grad/param norm = 1.4998e-01, time/batch = 18.4323s	
8464/30300 (epoch 13.967), train_loss = 1.32962145, grad/param norm = 1.4872e-01, time/batch = 18.7860s	
8465/30300 (epoch 13.969), train_loss = 1.31964252, grad/param norm = 1.6439e-01, time/batch = 17.0413s	
8466/30300 (epoch 13.970), train_loss = 1.33490193, grad/param norm = 1.4044e-01, time/batch = 19.2111s	
8467/30300 (epoch 13.972), train_loss = 1.24761913, grad/param norm = 1.4675e-01, time/batch = 18.6287s	
8468/30300 (epoch 13.974), train_loss = 1.58528554, grad/param norm = 1.7373e-01, time/batch = 17.9537s	
8469/30300 (epoch 13.975), train_loss = 1.59612875, grad/param norm = 1.8875e-01, time/batch = 18.0332s	
8470/30300 (epoch 13.977), train_loss = 1.46707287, grad/param norm = 1.5766e-01, time/batch = 19.1945s	
8471/30300 (epoch 13.979), train_loss = 1.41569936, grad/param norm = 1.5464e-01, time/batch = 18.9238s	
8472/30300 (epoch 13.980), train_loss = 1.47328728, grad/param norm = 1.6602e-01, time/batch = 20.3465s	
8473/30300 (epoch 13.982), train_loss = 1.47540296, grad/param norm = 1.5901e-01, time/batch = 18.1183s	
8474/30300 (epoch 13.983), train_loss = 1.50922210, grad/param norm = 1.5688e-01, time/batch = 17.5178s	
8475/30300 (epoch 13.985), train_loss = 1.38861185, grad/param norm = 1.6386e-01, time/batch = 17.9376s	
8476/30300 (epoch 13.987), train_loss = 1.34818353, grad/param norm = 1.3837e-01, time/batch = 15.7495s	
8477/30300 (epoch 13.988), train_loss = 1.55633098, grad/param norm = 1.6017e-01, time/batch = 17.0804s	
8478/30300 (epoch 13.990), train_loss = 1.18911648, grad/param norm = 1.3447e-01, time/batch = 18.0207s	
8479/30300 (epoch 13.992), train_loss = 1.43350067, grad/param norm = 1.3802e-01, time/batch = 18.6912s	
8480/30300 (epoch 13.993), train_loss = 1.50678142, grad/param norm = 1.6418e-01, time/batch = 18.8900s	
8481/30300 (epoch 13.995), train_loss = 1.37978358, grad/param norm = 1.6316e-01, time/batch = 18.9480s	
8482/30300 (epoch 13.997), train_loss = 1.41498063, grad/param norm = 1.5352e-01, time/batch = 18.4959s	
8483/30300 (epoch 13.998), train_loss = 1.47895656, grad/param norm = 1.6457e-01, time/batch = 20.3452s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
8484/30300 (epoch 14.000), train_loss = 1.31446274, grad/param norm = 1.4619e-01, time/batch = 18.3474s	
8485/30300 (epoch 14.002), train_loss = 1.45197248, grad/param norm = 1.5308e-01, time/batch = 18.0043s	
8486/30300 (epoch 14.003), train_loss = 1.38764583, grad/param norm = 1.4917e-01, time/batch = 19.6065s	
8487/30300 (epoch 14.005), train_loss = 1.35860211, grad/param norm = 1.6291e-01, time/batch = 19.8709s	
8488/30300 (epoch 14.007), train_loss = 1.48820052, grad/param norm = 1.7198e-01, time/batch = 18.2689s	
8489/30300 (epoch 14.008), train_loss = 1.31579694, grad/param norm = 1.5170e-01, time/batch = 20.2739s	
8490/30300 (epoch 14.010), train_loss = 1.27087731, grad/param norm = 1.4896e-01, time/batch = 19.1947s	
8491/30300 (epoch 14.012), train_loss = 1.28459760, grad/param norm = 1.3970e-01, time/batch = 19.0342s	
8492/30300 (epoch 14.013), train_loss = 1.43240505, grad/param norm = 1.6009e-01, time/batch = 19.8703s	
8493/30300 (epoch 14.015), train_loss = 1.33907904, grad/param norm = 1.4035e-01, time/batch = 19.3688s	
8494/30300 (epoch 14.017), train_loss = 1.27412592, grad/param norm = 1.3932e-01, time/batch = 17.3679s	
8495/30300 (epoch 14.018), train_loss = 1.30793118, grad/param norm = 1.4096e-01, time/batch = 20.2951s	
8496/30300 (epoch 14.020), train_loss = 1.49360750, grad/param norm = 1.6408e-01, time/batch = 20.1889s	
8497/30300 (epoch 14.021), train_loss = 1.49798897, grad/param norm = 1.6185e-01, time/batch = 19.3585s	
8498/30300 (epoch 14.023), train_loss = 1.32421819, grad/param norm = 1.4137e-01, time/batch = 18.3875s	
8499/30300 (epoch 14.025), train_loss = 1.30566941, grad/param norm = 1.6444e-01, time/batch = 19.1850s	
8500/30300 (epoch 14.026), train_loss = 1.43221398, grad/param norm = 1.5770e-01, time/batch = 17.9392s	
8501/30300 (epoch 14.028), train_loss = 1.43432267, grad/param norm = 1.5006e-01, time/batch = 19.4846s	
8502/30300 (epoch 14.030), train_loss = 1.30194400, grad/param norm = 1.4366e-01, time/batch = 19.1467s	
8503/30300 (epoch 14.031), train_loss = 1.38472271, grad/param norm = 1.6023e-01, time/batch = 18.2921s	
8504/30300 (epoch 14.033), train_loss = 1.39143939, grad/param norm = 1.6603e-01, time/batch = 19.6946s	
8505/30300 (epoch 14.035), train_loss = 1.46918927, grad/param norm = 1.5265e-01, time/batch = 18.6147s	
8506/30300 (epoch 14.036), train_loss = 1.38391899, grad/param norm = 1.6639e-01, time/batch = 18.1991s	
8507/30300 (epoch 14.038), train_loss = 1.37411053, grad/param norm = 1.4790e-01, time/batch = 18.8667s	
8508/30300 (epoch 14.040), train_loss = 1.08655650, grad/param norm = 1.2842e-01, time/batch = 19.3759s	
8509/30300 (epoch 14.041), train_loss = 1.16361244, grad/param norm = 1.3338e-01, time/batch = 18.3023s	
8510/30300 (epoch 14.043), train_loss = 1.40282226, grad/param norm = 1.5642e-01, time/batch = 19.8677s	
8511/30300 (epoch 14.045), train_loss = 1.33325754, grad/param norm = 1.5209e-01, time/batch = 19.5457s	
8512/30300 (epoch 14.046), train_loss = 1.49308605, grad/param norm = 1.7365e-01, time/batch = 18.8007s	
8513/30300 (epoch 14.048), train_loss = 1.39875697, grad/param norm = 1.6565e-01, time/batch = 18.4453s	
8514/30300 (epoch 14.050), train_loss = 1.39619452, grad/param norm = 1.5540e-01, time/batch = 19.6225s	
8515/30300 (epoch 14.051), train_loss = 1.40663812, grad/param norm = 1.6804e-01, time/batch = 19.6120s	
8516/30300 (epoch 14.053), train_loss = 1.20227630, grad/param norm = 1.6561e-01, time/batch = 18.8606s	
8517/30300 (epoch 14.054), train_loss = 1.31901014, grad/param norm = 1.4547e-01, time/batch = 18.8948s	
8518/30300 (epoch 14.056), train_loss = 1.28826432, grad/param norm = 1.4335e-01, time/batch = 20.0354s	
8519/30300 (epoch 14.058), train_loss = 1.33970248, grad/param norm = 1.4404e-01, time/batch = 19.0321s	
8520/30300 (epoch 14.059), train_loss = 1.27436994, grad/param norm = 1.5269e-01, time/batch = 18.8600s	
8521/30300 (epoch 14.061), train_loss = 1.49064958, grad/param norm = 1.8054e-01, time/batch = 20.2058s	
8522/30300 (epoch 14.063), train_loss = 1.31306735, grad/param norm = 1.5439e-01, time/batch = 19.2812s	
8523/30300 (epoch 14.064), train_loss = 1.42849512, grad/param norm = 1.5530e-01, time/batch = 18.4694s	
8524/30300 (epoch 14.066), train_loss = 1.33954759, grad/param norm = 1.4670e-01, time/batch = 20.2236s	
8525/30300 (epoch 14.068), train_loss = 1.22781637, grad/param norm = 1.4159e-01, time/batch = 17.4584s	
8526/30300 (epoch 14.069), train_loss = 1.45472785, grad/param norm = 1.5777e-01, time/batch = 19.0621s	
8527/30300 (epoch 14.071), train_loss = 1.42174575, grad/param norm = 1.6615e-01, time/batch = 17.6337s	
8528/30300 (epoch 14.073), train_loss = 1.38760050, grad/param norm = 1.6418e-01, time/batch = 18.0496s	
8529/30300 (epoch 14.074), train_loss = 1.40710984, grad/param norm = 1.3940e-01, time/batch = 18.1364s	
8530/30300 (epoch 14.076), train_loss = 1.34468973, grad/param norm = 1.4867e-01, time/batch = 19.1256s	
8531/30300 (epoch 14.078), train_loss = 1.24839167, grad/param norm = 1.4372e-01, time/batch = 19.1283s	
8532/30300 (epoch 14.079), train_loss = 1.27858359, grad/param norm = 1.3081e-01, time/batch = 17.7837s	
8533/30300 (epoch 14.081), train_loss = 1.38812777, grad/param norm = 1.5038e-01, time/batch = 18.9684s	
8534/30300 (epoch 14.083), train_loss = 1.48723416, grad/param norm = 1.6448e-01, time/batch = 19.5422s	
8535/30300 (epoch 14.084), train_loss = 1.24529015, grad/param norm = 1.4730e-01, time/batch = 19.4582s	
8536/30300 (epoch 14.086), train_loss = 1.28680549, grad/param norm = 1.4566e-01, time/batch = 17.9487s	
8537/30300 (epoch 14.087), train_loss = 1.23734665, grad/param norm = 1.2784e-01, time/batch = 15.5897s	
8538/30300 (epoch 14.089), train_loss = 1.31742313, grad/param norm = 1.5542e-01, time/batch = 16.6896s	
8539/30300 (epoch 14.091), train_loss = 1.41965757, grad/param norm = 1.6151e-01, time/batch = 15.5915s	
8540/30300 (epoch 14.092), train_loss = 1.37649878, grad/param norm = 1.5424e-01, time/batch = 16.2765s	
8541/30300 (epoch 14.094), train_loss = 1.54507062, grad/param norm = 1.6306e-01, time/batch = 18.8568s	
8542/30300 (epoch 14.096), train_loss = 1.46958996, grad/param norm = 1.6203e-01, time/batch = 19.6744s	
8543/30300 (epoch 14.097), train_loss = 1.29105319, grad/param norm = 1.4510e-01, time/batch = 19.2094s	
8544/30300 (epoch 14.099), train_loss = 1.51706516, grad/param norm = 1.6440e-01, time/batch = 19.3669s	
8545/30300 (epoch 14.101), train_loss = 1.57059529, grad/param norm = 1.6384e-01, time/batch = 18.6388s	
8546/30300 (epoch 14.102), train_loss = 1.32797716, grad/param norm = 1.6443e-01, time/batch = 19.2714s	
8547/30300 (epoch 14.104), train_loss = 1.32918504, grad/param norm = 1.7209e-01, time/batch = 19.7077s	
8548/30300 (epoch 14.106), train_loss = 1.36113299, grad/param norm = 1.5996e-01, time/batch = 16.4299s	
8549/30300 (epoch 14.107), train_loss = 1.39197348, grad/param norm = 1.5703e-01, time/batch = 18.2457s	
8550/30300 (epoch 14.109), train_loss = 1.47897676, grad/param norm = 1.7020e-01, time/batch = 17.5947s	
8551/30300 (epoch 14.111), train_loss = 1.51003966, grad/param norm = 1.5733e-01, time/batch = 18.7916s	
8552/30300 (epoch 14.112), train_loss = 1.40945443, grad/param norm = 1.4222e-01, time/batch = 19.4395s	
8553/30300 (epoch 14.114), train_loss = 1.38467455, grad/param norm = 1.5031e-01, time/batch = 20.2189s	
8554/30300 (epoch 14.116), train_loss = 1.38219184, grad/param norm = 1.5180e-01, time/batch = 17.9671s	
8555/30300 (epoch 14.117), train_loss = 1.39537104, grad/param norm = 1.4033e-01, time/batch = 19.8767s	
8556/30300 (epoch 14.119), train_loss = 1.28711933, grad/param norm = 1.7141e-01, time/batch = 20.3745s	
8557/30300 (epoch 14.120), train_loss = 1.37361693, grad/param norm = 1.6155e-01, time/batch = 18.5351s	
8558/30300 (epoch 14.122), train_loss = 1.44467048, grad/param norm = 1.5791e-01, time/batch = 19.7080s	
8559/30300 (epoch 14.124), train_loss = 1.58499805, grad/param norm = 1.7532e-01, time/batch = 18.6899s	
8560/30300 (epoch 14.125), train_loss = 1.23587945, grad/param norm = 1.3985e-01, time/batch = 19.5443s	
8561/30300 (epoch 14.127), train_loss = 1.36385705, grad/param norm = 1.6471e-01, time/batch = 18.5304s	
8562/30300 (epoch 14.129), train_loss = 1.51775102, grad/param norm = 1.4225e-01, time/batch = 19.5457s	
8563/30300 (epoch 14.130), train_loss = 1.51769487, grad/param norm = 1.5316e-01, time/batch = 18.2144s	
8564/30300 (epoch 14.132), train_loss = 1.45374144, grad/param norm = 1.6042e-01, time/batch = 18.8642s	
8565/30300 (epoch 14.134), train_loss = 1.28296480, grad/param norm = 1.5168e-01, time/batch = 19.0347s	
8566/30300 (epoch 14.135), train_loss = 1.30567694, grad/param norm = 1.5274e-01, time/batch = 19.7001s	
8567/30300 (epoch 14.137), train_loss = 1.42466759, grad/param norm = 1.5190e-01, time/batch = 19.2066s	
8568/30300 (epoch 14.139), train_loss = 1.33839970, grad/param norm = 1.4900e-01, time/batch = 18.9386s	
8569/30300 (epoch 14.140), train_loss = 1.48860640, grad/param norm = 1.7955e-01, time/batch = 19.3051s	
8570/30300 (epoch 14.142), train_loss = 1.57874045, grad/param norm = 1.8512e-01, time/batch = 18.8702s	
8571/30300 (epoch 14.144), train_loss = 1.42329713, grad/param norm = 1.8271e-01, time/batch = 20.3763s	
8572/30300 (epoch 14.145), train_loss = 1.55143586, grad/param norm = 1.8639e-01, time/batch = 19.4614s	
8573/30300 (epoch 14.147), train_loss = 1.36316435, grad/param norm = 1.5478e-01, time/batch = 18.0348s	
8574/30300 (epoch 14.149), train_loss = 1.56931800, grad/param norm = 1.5377e-01, time/batch = 19.4589s	
8575/30300 (epoch 14.150), train_loss = 1.42609962, grad/param norm = 1.6227e-01, time/batch = 20.5380s	
8576/30300 (epoch 14.152), train_loss = 1.25043537, grad/param norm = 1.5963e-01, time/batch = 17.5507s	
8577/30300 (epoch 14.153), train_loss = 1.37591638, grad/param norm = 1.6278e-01, time/batch = 18.7847s	
8578/30300 (epoch 14.155), train_loss = 1.18517605, grad/param norm = 1.3175e-01, time/batch = 18.6158s	
8579/30300 (epoch 14.157), train_loss = 1.34905345, grad/param norm = 1.7473e-01, time/batch = 18.3767s	
8580/30300 (epoch 14.158), train_loss = 1.40186926, grad/param norm = 1.6342e-01, time/batch = 19.8001s	
8581/30300 (epoch 14.160), train_loss = 1.31778294, grad/param norm = 1.4315e-01, time/batch = 19.4660s	
8582/30300 (epoch 14.162), train_loss = 1.32374398, grad/param norm = 1.4591e-01, time/batch = 18.5986s	
8583/30300 (epoch 14.163), train_loss = 1.31101958, grad/param norm = 1.5741e-01, time/batch = 19.6223s	
8584/30300 (epoch 14.165), train_loss = 1.45301472, grad/param norm = 1.5258e-01, time/batch = 19.2939s	
8585/30300 (epoch 14.167), train_loss = 1.39948733, grad/param norm = 1.5531e-01, time/batch = 19.8723s	
8586/30300 (epoch 14.168), train_loss = 1.39693288, grad/param norm = 1.4981e-01, time/batch = 19.6210s	
8587/30300 (epoch 14.170), train_loss = 1.40974267, grad/param norm = 1.5920e-01, time/batch = 19.2020s	
8588/30300 (epoch 14.172), train_loss = 1.32179222, grad/param norm = 1.5232e-01, time/batch = 23.0004s	
8589/30300 (epoch 14.173), train_loss = 1.42330075, grad/param norm = 1.6674e-01, time/batch = 28.7502s	
8590/30300 (epoch 14.175), train_loss = 1.37983189, grad/param norm = 1.4001e-01, time/batch = 18.0327s	
8591/30300 (epoch 14.177), train_loss = 1.37868401, grad/param norm = 1.5730e-01, time/batch = 17.1959s	
8592/30300 (epoch 14.178), train_loss = 1.12773020, grad/param norm = 1.3153e-01, time/batch = 16.6931s	
8593/30300 (epoch 14.180), train_loss = 1.29954518, grad/param norm = 1.3897e-01, time/batch = 18.2997s	
8594/30300 (epoch 14.182), train_loss = 1.28960586, grad/param norm = 1.5305e-01, time/batch = 18.6085s	
8595/30300 (epoch 14.183), train_loss = 1.28890389, grad/param norm = 1.3957e-01, time/batch = 19.6106s	
8596/30300 (epoch 14.185), train_loss = 1.61881285, grad/param norm = 1.5343e-01, time/batch = 17.4398s	
8597/30300 (epoch 14.186), train_loss = 1.63515460, grad/param norm = 1.7269e-01, time/batch = 19.0336s	
8598/30300 (epoch 14.188), train_loss = 1.44380822, grad/param norm = 1.5913e-01, time/batch = 17.8768s	
8599/30300 (epoch 14.190), train_loss = 1.34385994, grad/param norm = 1.4543e-01, time/batch = 18.8002s	
8600/30300 (epoch 14.191), train_loss = 1.43515536, grad/param norm = 1.5587e-01, time/batch = 19.3737s	
8601/30300 (epoch 14.193), train_loss = 1.27336177, grad/param norm = 1.4045e-01, time/batch = 17.9382s	
8602/30300 (epoch 14.195), train_loss = 1.39908829, grad/param norm = 1.5382e-01, time/batch = 19.9630s	
8603/30300 (epoch 14.196), train_loss = 1.38387832, grad/param norm = 1.3744e-01, time/batch = 19.5504s	
8604/30300 (epoch 14.198), train_loss = 1.16286912, grad/param norm = 1.4203e-01, time/batch = 18.0303s	
8605/30300 (epoch 14.200), train_loss = 1.37269043, grad/param norm = 1.3395e-01, time/batch = 19.7075s	
8606/30300 (epoch 14.201), train_loss = 1.46523715, grad/param norm = 1.6768e-01, time/batch = 20.1255s	
8607/30300 (epoch 14.203), train_loss = 1.35885797, grad/param norm = 1.4658e-01, time/batch = 16.5476s	
8608/30300 (epoch 14.205), train_loss = 1.58883744, grad/param norm = 1.5379e-01, time/batch = 19.2837s	
8609/30300 (epoch 14.206), train_loss = 1.55759890, grad/param norm = 1.6367e-01, time/batch = 19.6220s	
8610/30300 (epoch 14.208), train_loss = 1.49870155, grad/param norm = 1.7375e-01, time/batch = 18.0217s	
8611/30300 (epoch 14.210), train_loss = 1.39991262, grad/param norm = 1.4333e-01, time/batch = 19.7937s	
8612/30300 (epoch 14.211), train_loss = 1.46128919, grad/param norm = 1.4439e-01, time/batch = 19.5578s	
8613/30300 (epoch 14.213), train_loss = 1.30237875, grad/param norm = 1.3583e-01, time/batch = 18.7002s	
8614/30300 (epoch 14.215), train_loss = 1.22020960, grad/param norm = 1.4994e-01, time/batch = 18.8058s	
8615/30300 (epoch 14.216), train_loss = 1.34723031, grad/param norm = 1.6002e-01, time/batch = 19.3035s	
8616/30300 (epoch 14.218), train_loss = 1.26278623, grad/param norm = 1.4021e-01, time/batch = 19.3029s	
8617/30300 (epoch 14.219), train_loss = 1.17397669, grad/param norm = 1.3015e-01, time/batch = 18.3835s	
8618/30300 (epoch 14.221), train_loss = 1.21577713, grad/param norm = 1.4283e-01, time/batch = 18.4462s	
8619/30300 (epoch 14.223), train_loss = 1.37968825, grad/param norm = 1.5082e-01, time/batch = 19.6066s	
8620/30300 (epoch 14.224), train_loss = 1.18234776, grad/param norm = 1.3877e-01, time/batch = 15.3677s	
8621/30300 (epoch 14.226), train_loss = 1.47375656, grad/param norm = 1.6834e-01, time/batch = 18.8071s	
8622/30300 (epoch 14.228), train_loss = 1.47891203, grad/param norm = 1.5202e-01, time/batch = 20.5257s	
8623/30300 (epoch 14.229), train_loss = 1.29090563, grad/param norm = 1.5738e-01, time/batch = 18.4286s	
8624/30300 (epoch 14.231), train_loss = 1.39637891, grad/param norm = 1.4558e-01, time/batch = 19.2051s	
8625/30300 (epoch 14.233), train_loss = 1.32253418, grad/param norm = 1.4237e-01, time/batch = 20.2069s	
8626/30300 (epoch 14.234), train_loss = 1.41864275, grad/param norm = 1.6707e-01, time/batch = 16.7933s	
8627/30300 (epoch 14.236), train_loss = 1.30103177, grad/param norm = 1.3797e-01, time/batch = 20.1314s	
8628/30300 (epoch 14.238), train_loss = 1.41837789, grad/param norm = 1.7348e-01, time/batch = 18.6376s	
8629/30300 (epoch 14.239), train_loss = 1.37952907, grad/param norm = 1.5231e-01, time/batch = 17.9610s	
8630/30300 (epoch 14.241), train_loss = 1.43275739, grad/param norm = 1.6930e-01, time/batch = 20.0368s	
8631/30300 (epoch 14.243), train_loss = 1.42679262, grad/param norm = 1.4656e-01, time/batch = 19.7224s	
8632/30300 (epoch 14.244), train_loss = 1.62815178, grad/param norm = 1.6919e-01, time/batch = 18.8830s	
8633/30300 (epoch 14.246), train_loss = 1.33443822, grad/param norm = 1.4845e-01, time/batch = 18.7902s	
8634/30300 (epoch 14.248), train_loss = 1.32120234, grad/param norm = 1.4224e-01, time/batch = 20.0469s	
8635/30300 (epoch 14.249), train_loss = 1.26409719, grad/param norm = 1.4909e-01, time/batch = 19.0279s	
8636/30300 (epoch 14.251), train_loss = 1.25575741, grad/param norm = 1.4909e-01, time/batch = 19.2104s	
8637/30300 (epoch 14.252), train_loss = 1.51594974, grad/param norm = 1.5525e-01, time/batch = 17.2909s	
8638/30300 (epoch 14.254), train_loss = 1.48673383, grad/param norm = 1.7037e-01, time/batch = 18.1932s	
8639/30300 (epoch 14.256), train_loss = 1.39997576, grad/param norm = 1.4941e-01, time/batch = 18.9609s	
8640/30300 (epoch 14.257), train_loss = 1.46649053, grad/param norm = 1.5810e-01, time/batch = 18.8034s	
8641/30300 (epoch 14.259), train_loss = 1.37312166, grad/param norm = 1.5073e-01, time/batch = 20.1280s	
8642/30300 (epoch 14.261), train_loss = 1.50162109, grad/param norm = 1.5101e-01, time/batch = 17.0268s	
8643/30300 (epoch 14.262), train_loss = 1.35308029, grad/param norm = 1.4278e-01, time/batch = 20.1219s	
8644/30300 (epoch 14.264), train_loss = 1.36108065, grad/param norm = 1.5145e-01, time/batch = 20.4533s	
8645/30300 (epoch 14.266), train_loss = 1.30339654, grad/param norm = 1.4127e-01, time/batch = 17.7092s	
8646/30300 (epoch 14.267), train_loss = 1.56514178, grad/param norm = 1.6622e-01, time/batch = 19.9734s	
8647/30300 (epoch 14.269), train_loss = 1.35998730, grad/param norm = 1.4668e-01, time/batch = 19.5575s	
8648/30300 (epoch 14.271), train_loss = 1.38317610, grad/param norm = 1.4898e-01, time/batch = 18.7167s	
8649/30300 (epoch 14.272), train_loss = 1.40739731, grad/param norm = 1.6762e-01, time/batch = 19.8594s	
8650/30300 (epoch 14.274), train_loss = 1.51698879, grad/param norm = 1.5214e-01, time/batch = 20.0455s	
8651/30300 (epoch 14.276), train_loss = 1.46163686, grad/param norm = 1.6794e-01, time/batch = 18.7109s	
8652/30300 (epoch 14.277), train_loss = 1.28919639, grad/param norm = 1.5461e-01, time/batch = 18.9006s	
8653/30300 (epoch 14.279), train_loss = 1.42198115, grad/param norm = 1.6511e-01, time/batch = 19.5558s	
8654/30300 (epoch 14.281), train_loss = 1.47942403, grad/param norm = 1.6536e-01, time/batch = 19.1179s	
8655/30300 (epoch 14.282), train_loss = 1.35075105, grad/param norm = 1.3321e-01, time/batch = 19.8832s	
8656/30300 (epoch 14.284), train_loss = 1.53861778, grad/param norm = 1.7709e-01, time/batch = 19.0328s	
8657/30300 (epoch 14.285), train_loss = 1.37743164, grad/param norm = 1.4237e-01, time/batch = 18.7823s	
8658/30300 (epoch 14.287), train_loss = 1.37544576, grad/param norm = 1.5180e-01, time/batch = 17.6973s	
8659/30300 (epoch 14.289), train_loss = 1.42079290, grad/param norm = 1.4889e-01, time/batch = 19.1376s	
8660/30300 (epoch 14.290), train_loss = 1.11765032, grad/param norm = 1.3168e-01, time/batch = 17.5383s	
8661/30300 (epoch 14.292), train_loss = 1.24704502, grad/param norm = 1.3078e-01, time/batch = 19.4574s	
8662/30300 (epoch 14.294), train_loss = 1.53972723, grad/param norm = 1.6181e-01, time/batch = 19.1265s	
8663/30300 (epoch 14.295), train_loss = 1.35463487, grad/param norm = 1.4307e-01, time/batch = 19.2016s	
8664/30300 (epoch 14.297), train_loss = 1.28861351, grad/param norm = 1.3490e-01, time/batch = 18.4596s	
8665/30300 (epoch 14.299), train_loss = 1.34782884, grad/param norm = 1.5076e-01, time/batch = 20.0491s	
8666/30300 (epoch 14.300), train_loss = 1.38494051, grad/param norm = 1.5583e-01, time/batch = 20.2097s	
8667/30300 (epoch 14.302), train_loss = 1.33007528, grad/param norm = 1.4306e-01, time/batch = 18.7733s	
8668/30300 (epoch 14.304), train_loss = 1.26302338, grad/param norm = 1.3870e-01, time/batch = 20.0428s	
8669/30300 (epoch 14.305), train_loss = 1.31106069, grad/param norm = 1.4667e-01, time/batch = 20.3800s	
8670/30300 (epoch 14.307), train_loss = 1.39260213, grad/param norm = 1.4257e-01, time/batch = 18.9484s	
8671/30300 (epoch 14.309), train_loss = 1.44680405, grad/param norm = 1.4647e-01, time/batch = 19.7074s	
8672/30300 (epoch 14.310), train_loss = 1.34732587, grad/param norm = 1.5109e-01, time/batch = 20.4374s	
8673/30300 (epoch 14.312), train_loss = 1.49173413, grad/param norm = 1.4920e-01, time/batch = 18.1919s	
8674/30300 (epoch 14.314), train_loss = 1.40396184, grad/param norm = 1.4853e-01, time/batch = 19.7097s	
8675/30300 (epoch 14.315), train_loss = 1.42282072, grad/param norm = 1.5257e-01, time/batch = 20.3655s	
8676/30300 (epoch 14.317), train_loss = 1.47096543, grad/param norm = 1.5520e-01, time/batch = 17.4417s	
8677/30300 (epoch 14.318), train_loss = 1.53494622, grad/param norm = 1.7777e-01, time/batch = 18.5387s	
8678/30300 (epoch 14.320), train_loss = 1.49194003, grad/param norm = 1.6009e-01, time/batch = 19.5380s	
8679/30300 (epoch 14.322), train_loss = 1.27683886, grad/param norm = 1.4199e-01, time/batch = 19.2866s	
8680/30300 (epoch 14.323), train_loss = 1.49746235, grad/param norm = 1.6530e-01, time/batch = 19.2944s	
8681/30300 (epoch 14.325), train_loss = 1.34845673, grad/param norm = 1.3369e-01, time/batch = 19.4721s	
8682/30300 (epoch 14.327), train_loss = 1.34117470, grad/param norm = 1.3751e-01, time/batch = 17.9509s	
8683/30300 (epoch 14.328), train_loss = 1.34343843, grad/param norm = 1.3640e-01, time/batch = 18.0427s	
8684/30300 (epoch 14.330), train_loss = 1.42485666, grad/param norm = 1.3648e-01, time/batch = 19.7965s	
8685/30300 (epoch 14.332), train_loss = 1.46302706, grad/param norm = 1.5398e-01, time/batch = 18.9615s	
8686/30300 (epoch 14.333), train_loss = 1.36745424, grad/param norm = 1.5856e-01, time/batch = 19.1405s	
8687/30300 (epoch 14.335), train_loss = 1.23278129, grad/param norm = 1.4218e-01, time/batch = 18.5253s	
8688/30300 (epoch 14.337), train_loss = 1.52753632, grad/param norm = 1.5353e-01, time/batch = 18.0647s	
8689/30300 (epoch 14.338), train_loss = 1.28608103, grad/param norm = 1.3618e-01, time/batch = 18.9404s	
8690/30300 (epoch 14.340), train_loss = 1.25191486, grad/param norm = 1.3567e-01, time/batch = 18.7211s	
8691/30300 (epoch 14.342), train_loss = 1.45992044, grad/param norm = 1.4805e-01, time/batch = 19.8624s	
8692/30300 (epoch 14.343), train_loss = 1.44298275, grad/param norm = 1.5134e-01, time/batch = 18.2879s	
8693/30300 (epoch 14.345), train_loss = 1.39722779, grad/param norm = 1.4367e-01, time/batch = 18.7807s	
8694/30300 (epoch 14.347), train_loss = 1.20014175, grad/param norm = 1.3043e-01, time/batch = 19.2164s	
8695/30300 (epoch 14.348), train_loss = 1.27055995, grad/param norm = 1.4427e-01, time/batch = 18.6050s	
8696/30300 (epoch 14.350), train_loss = 1.35084517, grad/param norm = 1.4536e-01, time/batch = 19.3697s	
8697/30300 (epoch 14.351), train_loss = 1.37565597, grad/param norm = 1.5414e-01, time/batch = 19.6254s	
8698/30300 (epoch 14.353), train_loss = 1.18628194, grad/param norm = 1.4944e-01, time/batch = 17.7037s	
8699/30300 (epoch 14.355), train_loss = 1.32124141, grad/param norm = 1.4799e-01, time/batch = 18.8682s	
8700/30300 (epoch 14.356), train_loss = 1.47617712, grad/param norm = 1.8796e-01, time/batch = 20.3753s	
8701/30300 (epoch 14.358), train_loss = 1.56802842, grad/param norm = 1.4639e-01, time/batch = 18.2041s	
8702/30300 (epoch 14.360), train_loss = 1.31189006, grad/param norm = 1.4993e-01, time/batch = 19.2177s	
8703/30300 (epoch 14.361), train_loss = 1.39068517, grad/param norm = 1.5205e-01, time/batch = 18.4576s	
8704/30300 (epoch 14.363), train_loss = 1.45425327, grad/param norm = 1.4863e-01, time/batch = 16.6856s	
8705/30300 (epoch 14.365), train_loss = 1.27863729, grad/param norm = 1.6363e-01, time/batch = 18.1789s	
8706/30300 (epoch 14.366), train_loss = 1.29615401, grad/param norm = 1.4328e-01, time/batch = 19.3008s	
8707/30300 (epoch 14.368), train_loss = 1.17770914, grad/param norm = 1.5169e-01, time/batch = 18.9640s	
8708/30300 (epoch 14.370), train_loss = 1.26231416, grad/param norm = 1.5392e-01, time/batch = 19.2074s	
8709/30300 (epoch 14.371), train_loss = 1.43457543, grad/param norm = 1.4385e-01, time/batch = 19.5480s	
8710/30300 (epoch 14.373), train_loss = 1.26435149, grad/param norm = 1.2470e-01, time/batch = 17.5210s	
8711/30300 (epoch 14.375), train_loss = 1.26742086, grad/param norm = 1.3067e-01, time/batch = 19.6119s	
8712/30300 (epoch 14.376), train_loss = 1.28788450, grad/param norm = 1.3941e-01, time/batch = 19.2922s	
8713/30300 (epoch 14.378), train_loss = 1.28948663, grad/param norm = 1.3996e-01, time/batch = 20.2989s	
8714/30300 (epoch 14.380), train_loss = 1.54717774, grad/param norm = 1.5040e-01, time/batch = 17.8483s	
8715/30300 (epoch 14.381), train_loss = 1.22848202, grad/param norm = 1.3878e-01, time/batch = 18.4504s	
8716/30300 (epoch 14.383), train_loss = 1.32274994, grad/param norm = 1.5523e-01, time/batch = 19.6156s	
8717/30300 (epoch 14.384), train_loss = 1.44434989, grad/param norm = 1.4665e-01, time/batch = 18.7940s	
8718/30300 (epoch 14.386), train_loss = 1.23576239, grad/param norm = 1.4329e-01, time/batch = 19.7125s	
8719/30300 (epoch 14.388), train_loss = 1.20760881, grad/param norm = 1.3345e-01, time/batch = 17.9590s	
8720/30300 (epoch 14.389), train_loss = 1.36551619, grad/param norm = 1.6317e-01, time/batch = 18.5386s	
8721/30300 (epoch 14.391), train_loss = 1.41987919, grad/param norm = 1.4742e-01, time/batch = 19.6321s	
8722/30300 (epoch 14.393), train_loss = 1.18977038, grad/param norm = 1.3179e-01, time/batch = 19.1970s	
8723/30300 (epoch 14.394), train_loss = 1.40094567, grad/param norm = 1.4859e-01, time/batch = 18.7256s	
8724/30300 (epoch 14.396), train_loss = 1.52675808, grad/param norm = 1.4331e-01, time/batch = 20.2888s	
8725/30300 (epoch 14.398), train_loss = 1.31601168, grad/param norm = 1.2951e-01, time/batch = 18.2083s	
8726/30300 (epoch 14.399), train_loss = 1.33322248, grad/param norm = 1.5249e-01, time/batch = 19.4721s	
8727/30300 (epoch 14.401), train_loss = 1.41930085, grad/param norm = 1.4733e-01, time/batch = 18.8666s	
8728/30300 (epoch 14.403), train_loss = 1.31702036, grad/param norm = 1.4643e-01, time/batch = 19.1994s	
8729/30300 (epoch 14.404), train_loss = 1.26414100, grad/param norm = 1.5902e-01, time/batch = 18.7032s	
8730/30300 (epoch 14.406), train_loss = 1.36142714, grad/param norm = 1.4735e-01, time/batch = 17.2716s	
8731/30300 (epoch 14.408), train_loss = 1.21469050, grad/param norm = 1.3434e-01, time/batch = 17.2215s	
8732/30300 (epoch 14.409), train_loss = 1.18894134, grad/param norm = 1.3794e-01, time/batch = 17.5615s	
8733/30300 (epoch 14.411), train_loss = 1.21530036, grad/param norm = 1.3394e-01, time/batch = 17.7858s	
8734/30300 (epoch 14.413), train_loss = 1.16718224, grad/param norm = 1.4573e-01, time/batch = 18.7062s	
8735/30300 (epoch 14.414), train_loss = 1.49658452, grad/param norm = 1.5350e-01, time/batch = 18.5293s	
8736/30300 (epoch 14.416), train_loss = 1.32433797, grad/param norm = 1.5176e-01, time/batch = 16.8681s	
8737/30300 (epoch 14.417), train_loss = 1.27274882, grad/param norm = 1.4512e-01, time/batch = 18.5270s	
8738/30300 (epoch 14.419), train_loss = 1.22948497, grad/param norm = 1.4004e-01, time/batch = 17.8620s	
8739/30300 (epoch 14.421), train_loss = 1.30079963, grad/param norm = 1.4573e-01, time/batch = 18.8436s	
8740/30300 (epoch 14.422), train_loss = 1.32606058, grad/param norm = 1.3879e-01, time/batch = 18.0953s	
8741/30300 (epoch 14.424), train_loss = 1.35368945, grad/param norm = 1.4730e-01, time/batch = 19.1981s	
8742/30300 (epoch 14.426), train_loss = 1.23707592, grad/param norm = 1.4146e-01, time/batch = 19.8842s	
8743/30300 (epoch 14.427), train_loss = 1.32221160, grad/param norm = 1.6151e-01, time/batch = 18.0394s	
8744/30300 (epoch 14.429), train_loss = 1.33860147, grad/param norm = 1.4645e-01, time/batch = 19.2544s	
8745/30300 (epoch 14.431), train_loss = 1.41532166, grad/param norm = 1.4877e-01, time/batch = 20.0221s	
8746/30300 (epoch 14.432), train_loss = 1.31855655, grad/param norm = 1.4171e-01, time/batch = 18.5298s	
8747/30300 (epoch 14.434), train_loss = 1.18048921, grad/param norm = 1.3858e-01, time/batch = 19.5445s	
8748/30300 (epoch 14.436), train_loss = 1.50239102, grad/param norm = 1.6099e-01, time/batch = 20.0376s	
8749/30300 (epoch 14.437), train_loss = 1.24600496, grad/param norm = 1.5258e-01, time/batch = 17.3752s	
8750/30300 (epoch 14.439), train_loss = 1.27225354, grad/param norm = 1.4389e-01, time/batch = 19.0597s	
8751/30300 (epoch 14.441), train_loss = 1.28215147, grad/param norm = 1.3718e-01, time/batch = 19.2752s	
8752/30300 (epoch 14.442), train_loss = 1.23086905, grad/param norm = 1.3859e-01, time/batch = 17.1155s	
8753/30300 (epoch 14.444), train_loss = 1.13667661, grad/param norm = 1.5083e-01, time/batch = 20.1200s	
8754/30300 (epoch 14.446), train_loss = 1.29371480, grad/param norm = 1.4010e-01, time/batch = 18.9680s	
8755/30300 (epoch 14.447), train_loss = 1.33923041, grad/param norm = 1.5184e-01, time/batch = 18.7191s	
8756/30300 (epoch 14.449), train_loss = 1.27142910, grad/param norm = 1.4569e-01, time/batch = 18.6051s	
8757/30300 (epoch 14.450), train_loss = 1.44377289, grad/param norm = 1.4396e-01, time/batch = 19.7682s	
8758/30300 (epoch 14.452), train_loss = 1.40162293, grad/param norm = 1.3601e-01, time/batch = 19.2033s	
8759/30300 (epoch 14.454), train_loss = 1.36750222, grad/param norm = 1.3358e-01, time/batch = 19.7760s	
8760/30300 (epoch 14.455), train_loss = 1.41598517, grad/param norm = 1.5907e-01, time/batch = 20.1080s	
8761/30300 (epoch 14.457), train_loss = 1.36714895, grad/param norm = 1.4155e-01, time/batch = 18.4563s	
8762/30300 (epoch 14.459), train_loss = 1.43035986, grad/param norm = 1.5794e-01, time/batch = 18.9603s	
8763/30300 (epoch 14.460), train_loss = 1.39346314, grad/param norm = 1.5255e-01, time/batch = 19.4494s	
8764/30300 (epoch 14.462), train_loss = 1.44543330, grad/param norm = 1.4921e-01, time/batch = 19.0529s	
8765/30300 (epoch 14.464), train_loss = 1.20013088, grad/param norm = 1.5697e-01, time/batch = 18.9597s	
8766/30300 (epoch 14.465), train_loss = 1.16196281, grad/param norm = 1.3871e-01, time/batch = 19.8826s	
8767/30300 (epoch 14.467), train_loss = 1.12368051, grad/param norm = 1.2612e-01, time/batch = 18.8833s	
8768/30300 (epoch 14.469), train_loss = 1.24012799, grad/param norm = 1.2875e-01, time/batch = 18.0179s	
8769/30300 (epoch 14.470), train_loss = 1.29913838, grad/param norm = 1.4592e-01, time/batch = 18.9529s	
8770/30300 (epoch 14.472), train_loss = 1.28943543, grad/param norm = 1.3781e-01, time/batch = 19.9802s	
8771/30300 (epoch 14.474), train_loss = 1.33790248, grad/param norm = 1.5899e-01, time/batch = 18.2960s	
8772/30300 (epoch 14.475), train_loss = 1.24256017, grad/param norm = 1.4253e-01, time/batch = 20.2857s	
8773/30300 (epoch 14.477), train_loss = 1.36271114, grad/param norm = 1.6141e-01, time/batch = 18.0140s	
8774/30300 (epoch 14.479), train_loss = 1.34718930, grad/param norm = 1.4871e-01, time/batch = 18.7948s	
8775/30300 (epoch 14.480), train_loss = 1.38197774, grad/param norm = 1.3758e-01, time/batch = 19.7957s	
8776/30300 (epoch 14.482), train_loss = 1.38029582, grad/param norm = 1.3394e-01, time/batch = 18.7961s	
8777/30300 (epoch 14.483), train_loss = 1.29510251, grad/param norm = 1.4847e-01, time/batch = 28.4302s	
8778/30300 (epoch 14.485), train_loss = 1.33024059, grad/param norm = 1.4226e-01, time/batch = 23.6547s	
8779/30300 (epoch 14.487), train_loss = 1.40497228, grad/param norm = 1.5188e-01, time/batch = 19.0210s	
8780/30300 (epoch 14.488), train_loss = 1.41824248, grad/param norm = 1.4367e-01, time/batch = 18.3624s	
8781/30300 (epoch 14.490), train_loss = 1.23394973, grad/param norm = 1.4020e-01, time/batch = 19.2920s	
8782/30300 (epoch 14.492), train_loss = 1.33025740, grad/param norm = 1.7669e-01, time/batch = 17.1965s	
8783/30300 (epoch 14.493), train_loss = 1.31318797, grad/param norm = 1.6195e-01, time/batch = 19.1019s	
8784/30300 (epoch 14.495), train_loss = 1.25666796, grad/param norm = 1.3019e-01, time/batch = 18.6279s	
8785/30300 (epoch 14.497), train_loss = 1.37297169, grad/param norm = 1.4411e-01, time/batch = 20.3809s	
8786/30300 (epoch 14.498), train_loss = 1.37007427, grad/param norm = 1.4545e-01, time/batch = 18.2111s	
8787/30300 (epoch 14.500), train_loss = 1.40970910, grad/param norm = 1.6704e-01, time/batch = 20.2226s	
8788/30300 (epoch 14.502), train_loss = 1.31900590, grad/param norm = 1.5006e-01, time/batch = 20.1114s	
8789/30300 (epoch 14.503), train_loss = 1.41558607, grad/param norm = 1.4264e-01, time/batch = 18.2023s	
8790/30300 (epoch 14.505), train_loss = 1.30294614, grad/param norm = 1.5506e-01, time/batch = 19.2774s	
8791/30300 (epoch 14.507), train_loss = 1.29274331, grad/param norm = 1.4779e-01, time/batch = 18.8889s	
8792/30300 (epoch 14.508), train_loss = 1.32144728, grad/param norm = 1.6320e-01, time/batch = 18.0370s	
8793/30300 (epoch 14.510), train_loss = 1.44214656, grad/param norm = 1.7699e-01, time/batch = 18.9481s	
8794/30300 (epoch 14.512), train_loss = 1.25406822, grad/param norm = 1.4050e-01, time/batch = 18.7937s	
8795/30300 (epoch 14.513), train_loss = 1.39749466, grad/param norm = 1.4605e-01, time/batch = 18.9699s	
8796/30300 (epoch 14.515), train_loss = 1.33485008, grad/param norm = 1.4460e-01, time/batch = 18.9583s	
8797/30300 (epoch 14.517), train_loss = 1.16622428, grad/param norm = 1.3444e-01, time/batch = 20.0496s	
8798/30300 (epoch 14.518), train_loss = 1.43252271, grad/param norm = 1.6036e-01, time/batch = 18.7114s	
8799/30300 (epoch 14.520), train_loss = 1.47603313, grad/param norm = 1.5668e-01, time/batch = 18.5482s	
8800/30300 (epoch 14.521), train_loss = 1.22487967, grad/param norm = 1.5118e-01, time/batch = 19.7066s	
8801/30300 (epoch 14.523), train_loss = 1.50004829, grad/param norm = 1.8104e-01, time/batch = 18.0333s	
8802/30300 (epoch 14.525), train_loss = 1.25834266, grad/param norm = 1.4221e-01, time/batch = 19.4438s	
8803/30300 (epoch 14.526), train_loss = 1.32936609, grad/param norm = 1.4973e-01, time/batch = 18.8742s	
8804/30300 (epoch 14.528), train_loss = 1.19448556, grad/param norm = 1.3942e-01, time/batch = 20.2152s	
8805/30300 (epoch 14.530), train_loss = 1.21817956, grad/param norm = 1.4981e-01, time/batch = 18.4491s	
8806/30300 (epoch 14.531), train_loss = 1.40623448, grad/param norm = 1.5375e-01, time/batch = 20.3527s	
8807/30300 (epoch 14.533), train_loss = 1.38007205, grad/param norm = 1.5829e-01, time/batch = 20.4619s	
8808/30300 (epoch 14.535), train_loss = 1.18160244, grad/param norm = 1.2737e-01, time/batch = 18.7735s	
8809/30300 (epoch 14.536), train_loss = 1.37543951, grad/param norm = 1.5347e-01, time/batch = 19.0393s	
8810/30300 (epoch 14.538), train_loss = 1.16888376, grad/param norm = 1.5198e-01, time/batch = 19.7179s	
8811/30300 (epoch 14.540), train_loss = 1.23468081, grad/param norm = 1.5204e-01, time/batch = 17.8885s	
8812/30300 (epoch 14.541), train_loss = 1.32724690, grad/param norm = 1.6355e-01, time/batch = 19.1356s	
8813/30300 (epoch 14.543), train_loss = 1.34503685, grad/param norm = 1.4479e-01, time/batch = 20.0341s	
8814/30300 (epoch 14.545), train_loss = 1.35331997, grad/param norm = 1.5547e-01, time/batch = 17.3634s	
8815/30300 (epoch 14.546), train_loss = 1.57283627, grad/param norm = 1.4788e-01, time/batch = 18.8784s	
8816/30300 (epoch 14.548), train_loss = 1.25790046, grad/param norm = 1.4364e-01, time/batch = 19.6269s	
8817/30300 (epoch 14.550), train_loss = 1.45960611, grad/param norm = 1.8056e-01, time/batch = 18.7136s	
8818/30300 (epoch 14.551), train_loss = 1.25475882, grad/param norm = 1.4307e-01, time/batch = 20.2927s	
8819/30300 (epoch 14.553), train_loss = 1.29763612, grad/param norm = 1.4943e-01, time/batch = 19.0394s	
8820/30300 (epoch 14.554), train_loss = 1.39419920, grad/param norm = 1.9008e-01, time/batch = 18.3869s	
8821/30300 (epoch 14.556), train_loss = 1.39681753, grad/param norm = 1.5088e-01, time/batch = 19.2906s	
8822/30300 (epoch 14.558), train_loss = 1.48467587, grad/param norm = 1.6894e-01, time/batch = 19.8039s	
8823/30300 (epoch 14.559), train_loss = 1.39677854, grad/param norm = 1.6227e-01, time/batch = 18.7820s	
8824/30300 (epoch 14.561), train_loss = 1.20645192, grad/param norm = 1.4530e-01, time/batch = 17.7115s	
8825/30300 (epoch 14.563), train_loss = 1.22849200, grad/param norm = 1.3660e-01, time/batch = 20.1137s	
8826/30300 (epoch 14.564), train_loss = 1.27939173, grad/param norm = 1.4036e-01, time/batch = 18.3119s	
8827/30300 (epoch 14.566), train_loss = 1.35136797, grad/param norm = 1.4194e-01, time/batch = 19.2987s	
8828/30300 (epoch 14.568), train_loss = 1.14499985, grad/param norm = 1.4046e-01, time/batch = 19.2008s	
8829/30300 (epoch 14.569), train_loss = 1.32963455, grad/param norm = 1.4266e-01, time/batch = 19.7068s	
8830/30300 (epoch 14.571), train_loss = 1.37507554, grad/param norm = 1.5368e-01, time/batch = 18.0202s	
8831/30300 (epoch 14.573), train_loss = 1.36720380, grad/param norm = 1.4722e-01, time/batch = 17.8591s	
8832/30300 (epoch 14.574), train_loss = 1.41422984, grad/param norm = 1.4432e-01, time/batch = 19.4489s	
8833/30300 (epoch 14.576), train_loss = 1.30645626, grad/param norm = 1.3594e-01, time/batch = 19.1087s	
8834/30300 (epoch 14.578), train_loss = 1.19451964, grad/param norm = 1.4146e-01, time/batch = 17.7109s	
8835/30300 (epoch 14.579), train_loss = 1.37452330, grad/param norm = 1.5597e-01, time/batch = 20.0531s	
8836/30300 (epoch 14.581), train_loss = 1.42241955, grad/param norm = 1.4620e-01, time/batch = 17.1188s	
8837/30300 (epoch 14.583), train_loss = 1.51902121, grad/param norm = 1.6127e-01, time/batch = 20.0432s	
8838/30300 (epoch 14.584), train_loss = 1.41553115, grad/param norm = 1.4218e-01, time/batch = 20.1316s	
8839/30300 (epoch 14.586), train_loss = 1.35143480, grad/param norm = 1.5370e-01, time/batch = 16.9739s	
8840/30300 (epoch 14.587), train_loss = 1.34213455, grad/param norm = 1.4643e-01, time/batch = 18.7931s	
8841/30300 (epoch 14.589), train_loss = 1.21298449, grad/param norm = 1.3462e-01, time/batch = 19.5426s	
8842/30300 (epoch 14.591), train_loss = 1.37302220, grad/param norm = 1.4195e-01, time/batch = 18.4749s	
8843/30300 (epoch 14.592), train_loss = 1.31931266, grad/param norm = 1.2927e-01, time/batch = 18.3853s	
8844/30300 (epoch 14.594), train_loss = 1.36286647, grad/param norm = 1.5349e-01, time/batch = 19.6098s	
8845/30300 (epoch 14.596), train_loss = 1.22443572, grad/param norm = 1.2676e-01, time/batch = 18.2949s	
8846/30300 (epoch 14.597), train_loss = 1.27769486, grad/param norm = 1.5117e-01, time/batch = 18.1332s	
8847/30300 (epoch 14.599), train_loss = 1.15556182, grad/param norm = 1.4195e-01, time/batch = 18.8704s	
8848/30300 (epoch 14.601), train_loss = 1.40650563, grad/param norm = 1.5431e-01, time/batch = 20.0514s	
8849/30300 (epoch 14.602), train_loss = 1.33419199, grad/param norm = 1.3774e-01, time/batch = 18.8682s	
8850/30300 (epoch 14.604), train_loss = 1.23138997, grad/param norm = 1.2708e-01, time/batch = 19.4660s	
8851/30300 (epoch 14.606), train_loss = 1.35280739, grad/param norm = 1.7125e-01, time/batch = 20.4629s	
8852/30300 (epoch 14.607), train_loss = 1.41917545, grad/param norm = 1.6124e-01, time/batch = 19.6205s	
8853/30300 (epoch 14.609), train_loss = 1.54440877, grad/param norm = 1.5950e-01, time/batch = 19.1195s	
8854/30300 (epoch 14.611), train_loss = 1.27116046, grad/param norm = 1.4953e-01, time/batch = 19.8732s	
8855/30300 (epoch 14.612), train_loss = 1.24096223, grad/param norm = 1.4361e-01, time/batch = 18.2963s	
8856/30300 (epoch 14.614), train_loss = 1.23643739, grad/param norm = 1.3309e-01, time/batch = 19.3769s	
8857/30300 (epoch 14.616), train_loss = 1.37508543, grad/param norm = 1.5908e-01, time/batch = 18.1264s	
8858/30300 (epoch 14.617), train_loss = 1.31213673, grad/param norm = 1.4044e-01, time/batch = 18.9624s	
8859/30300 (epoch 14.619), train_loss = 1.13999829, grad/param norm = 1.3324e-01, time/batch = 19.2857s	
8860/30300 (epoch 14.620), train_loss = 1.34655349, grad/param norm = 1.4507e-01, time/batch = 19.8050s	
8861/30300 (epoch 14.622), train_loss = 1.32516411, grad/param norm = 1.6891e-01, time/batch = 17.9552s	
8862/30300 (epoch 14.624), train_loss = 1.25164719, grad/param norm = 1.5526e-01, time/batch = 19.2990s	
8863/30300 (epoch 14.625), train_loss = 1.29066315, grad/param norm = 1.5321e-01, time/batch = 20.1152s	
8864/30300 (epoch 14.627), train_loss = 1.49229699, grad/param norm = 1.6734e-01, time/batch = 17.3707s	
8865/30300 (epoch 14.629), train_loss = 1.41047847, grad/param norm = 1.4416e-01, time/batch = 19.2060s	
8866/30300 (epoch 14.630), train_loss = 1.34987580, grad/param norm = 1.3745e-01, time/batch = 19.9693s	
8867/30300 (epoch 14.632), train_loss = 1.43842763, grad/param norm = 1.5600e-01, time/batch = 19.2198s	
8868/30300 (epoch 14.634), train_loss = 1.19512294, grad/param norm = 1.2719e-01, time/batch = 18.8928s	
8869/30300 (epoch 14.635), train_loss = 1.39531845, grad/param norm = 1.4402e-01, time/batch = 20.2816s	
8870/30300 (epoch 14.637), train_loss = 1.41241419, grad/param norm = 1.6172e-01, time/batch = 18.7968s	
8871/30300 (epoch 14.639), train_loss = 1.26624739, grad/param norm = 1.4220e-01, time/batch = 19.2680s	
8872/30300 (epoch 14.640), train_loss = 1.46983718, grad/param norm = 1.6530e-01, time/batch = 18.8598s	
8873/30300 (epoch 14.642), train_loss = 1.28428425, grad/param norm = 1.3323e-01, time/batch = 17.8268s	
8874/30300 (epoch 14.644), train_loss = 1.39066043, grad/param norm = 1.4044e-01, time/batch = 18.6883s	
8875/30300 (epoch 14.645), train_loss = 1.19571134, grad/param norm = 1.4078e-01, time/batch = 18.4465s	
8876/30300 (epoch 14.647), train_loss = 1.30383223, grad/param norm = 1.3533e-01, time/batch = 18.5067s	
8877/30300 (epoch 14.649), train_loss = 1.29819459, grad/param norm = 1.5001e-01, time/batch = 17.5184s	
8878/30300 (epoch 14.650), train_loss = 1.30258416, grad/param norm = 1.3797e-01, time/batch = 18.8633s	
8879/30300 (epoch 14.652), train_loss = 1.26813632, grad/param norm = 1.4078e-01, time/batch = 18.5523s	
8880/30300 (epoch 14.653), train_loss = 1.52300437, grad/param norm = 1.5609e-01, time/batch = 18.2008s	
8881/30300 (epoch 14.655), train_loss = 1.27221312, grad/param norm = 1.4694e-01, time/batch = 19.3846s	
8882/30300 (epoch 14.657), train_loss = 1.31096847, grad/param norm = 1.4567e-01, time/batch = 19.2223s	
8883/30300 (epoch 14.658), train_loss = 1.26105809, grad/param norm = 1.4239e-01, time/batch = 18.5436s	
8884/30300 (epoch 14.660), train_loss = 1.37633553, grad/param norm = 1.5141e-01, time/batch = 18.3110s	
8885/30300 (epoch 14.662), train_loss = 1.39755634, grad/param norm = 1.7113e-01, time/batch = 19.0535s	
8886/30300 (epoch 14.663), train_loss = 1.36449870, grad/param norm = 1.4724e-01, time/batch = 19.1134s	
8887/30300 (epoch 14.665), train_loss = 1.24431895, grad/param norm = 1.5834e-01, time/batch = 17.9466s	
8888/30300 (epoch 14.667), train_loss = 1.43790010, grad/param norm = 1.4722e-01, time/batch = 17.4576s	
8889/30300 (epoch 14.668), train_loss = 1.48757240, grad/param norm = 1.5736e-01, time/batch = 19.2123s	
8890/30300 (epoch 14.670), train_loss = 1.47501096, grad/param norm = 1.5034e-01, time/batch = 18.8671s	
8891/30300 (epoch 14.672), train_loss = 1.40550440, grad/param norm = 1.5452e-01, time/batch = 19.7113s	
8892/30300 (epoch 14.673), train_loss = 1.42503049, grad/param norm = 1.5764e-01, time/batch = 19.0497s	
8893/30300 (epoch 14.675), train_loss = 1.28547388, grad/param norm = 1.4925e-01, time/batch = 17.4626s	
8894/30300 (epoch 14.677), train_loss = 1.26198057, grad/param norm = 1.3738e-01, time/batch = 19.6321s	
8895/30300 (epoch 14.678), train_loss = 1.30073028, grad/param norm = 1.4936e-01, time/batch = 20.3019s	
8896/30300 (epoch 14.680), train_loss = 1.11881049, grad/param norm = 1.3357e-01, time/batch = 17.4566s	
8897/30300 (epoch 14.682), train_loss = 1.31451380, grad/param norm = 1.4184e-01, time/batch = 19.9667s	
8898/30300 (epoch 14.683), train_loss = 1.37935579, grad/param norm = 1.3523e-01, time/batch = 20.3809s	
8899/30300 (epoch 14.685), train_loss = 1.43660897, grad/param norm = 1.5923e-01, time/batch = 17.8607s	
8900/30300 (epoch 14.686), train_loss = 1.32485387, grad/param norm = 1.4131e-01, time/batch = 19.4672s	
8901/30300 (epoch 14.688), train_loss = 1.34134896, grad/param norm = 1.3900e-01, time/batch = 20.3793s	
8902/30300 (epoch 14.690), train_loss = 1.27268040, grad/param norm = 1.5023e-01, time/batch = 17.8791s	
8903/30300 (epoch 14.691), train_loss = 1.35366697, grad/param norm = 1.4255e-01, time/batch = 18.7297s	
8904/30300 (epoch 14.693), train_loss = 1.72361524, grad/param norm = 1.7215e-01, time/batch = 18.0499s	
8905/30300 (epoch 14.695), train_loss = 1.51724023, grad/param norm = 1.8379e-01, time/batch = 18.7986s	
8906/30300 (epoch 14.696), train_loss = 1.46319510, grad/param norm = 1.8258e-01, time/batch = 18.8770s	
8907/30300 (epoch 14.698), train_loss = 1.29969748, grad/param norm = 1.4806e-01, time/batch = 19.0523s	
8908/30300 (epoch 14.700), train_loss = 1.28683016, grad/param norm = 1.5778e-01, time/batch = 19.3014s	
8909/30300 (epoch 14.701), train_loss = 1.15462156, grad/param norm = 1.3295e-01, time/batch = 18.6244s	
8910/30300 (epoch 14.703), train_loss = 1.34716516, grad/param norm = 1.3777e-01, time/batch = 17.2929s	
8911/30300 (epoch 14.705), train_loss = 1.30447320, grad/param norm = 1.5169e-01, time/batch = 20.6170s	
8912/30300 (epoch 14.706), train_loss = 1.40118122, grad/param norm = 1.5353e-01, time/batch = 18.7174s	
8913/30300 (epoch 14.708), train_loss = 1.29039886, grad/param norm = 1.4319e-01, time/batch = 20.0443s	
8914/30300 (epoch 14.710), train_loss = 1.30246776, grad/param norm = 1.4882e-01, time/batch = 20.3018s	
8915/30300 (epoch 14.711), train_loss = 1.21309898, grad/param norm = 1.3760e-01, time/batch = 18.6988s	
8916/30300 (epoch 14.713), train_loss = 1.21532029, grad/param norm = 1.3562e-01, time/batch = 19.1467s	
8917/30300 (epoch 14.715), train_loss = 1.27619016, grad/param norm = 1.4157e-01, time/batch = 20.0478s	
8918/30300 (epoch 14.716), train_loss = 1.44801534, grad/param norm = 1.5332e-01, time/batch = 18.5341s	
8919/30300 (epoch 14.718), train_loss = 1.43861382, grad/param norm = 1.5681e-01, time/batch = 18.4668s	
8920/30300 (epoch 14.719), train_loss = 1.30835459, grad/param norm = 1.6120e-01, time/batch = 18.2031s	
8921/30300 (epoch 14.721), train_loss = 1.35072629, grad/param norm = 1.6373e-01, time/batch = 17.2943s	
8922/30300 (epoch 14.723), train_loss = 1.25492616, grad/param norm = 1.4775e-01, time/batch = 20.3786s	
8923/30300 (epoch 14.724), train_loss = 1.41725792, grad/param norm = 1.6683e-01, time/batch = 20.3926s	
8924/30300 (epoch 14.726), train_loss = 1.74953339, grad/param norm = 1.7830e-01, time/batch = 18.2054s	
8925/30300 (epoch 14.728), train_loss = 1.38534478, grad/param norm = 1.6256e-01, time/batch = 19.4436s	
8926/30300 (epoch 14.729), train_loss = 1.32672386, grad/param norm = 1.5894e-01, time/batch = 18.3932s	
8927/30300 (epoch 14.731), train_loss = 1.41615218, grad/param norm = 1.5245e-01, time/batch = 19.3836s	
8928/30300 (epoch 14.733), train_loss = 1.32036849, grad/param norm = 1.3792e-01, time/batch = 19.2083s	
8929/30300 (epoch 14.734), train_loss = 1.40156892, grad/param norm = 1.4155e-01, time/batch = 19.1259s	
8930/30300 (epoch 14.736), train_loss = 1.31976367, grad/param norm = 1.3658e-01, time/batch = 19.7187s	
8931/30300 (epoch 14.738), train_loss = 1.20213614, grad/param norm = 1.3037e-01, time/batch = 19.7072s	
8932/30300 (epoch 14.739), train_loss = 1.37757945, grad/param norm = 1.4281e-01, time/batch = 19.7160s	
8933/30300 (epoch 14.741), train_loss = 1.44637664, grad/param norm = 1.4426e-01, time/batch = 19.3681s	
8934/30300 (epoch 14.743), train_loss = 1.29175086, grad/param norm = 1.3846e-01, time/batch = 19.5263s	
8935/30300 (epoch 14.744), train_loss = 1.39681509, grad/param norm = 1.5530e-01, time/batch = 19.9596s	
8936/30300 (epoch 14.746), train_loss = 1.20835606, grad/param norm = 1.3709e-01, time/batch = 19.6217s	
8937/30300 (epoch 14.748), train_loss = 1.35302584, grad/param norm = 1.6030e-01, time/batch = 19.1953s	
8938/30300 (epoch 14.749), train_loss = 1.38017332, grad/param norm = 1.6072e-01, time/batch = 19.8726s	
8939/30300 (epoch 14.751), train_loss = 1.28451743, grad/param norm = 1.4410e-01, time/batch = 17.9511s	
8940/30300 (epoch 14.752), train_loss = 1.29510860, grad/param norm = 1.4392e-01, time/batch = 18.9231s	
8941/30300 (epoch 14.754), train_loss = 1.22760185, grad/param norm = 1.3473e-01, time/batch = 19.1158s	
8942/30300 (epoch 14.756), train_loss = 1.29368098, grad/param norm = 1.4212e-01, time/batch = 20.4634s	
8943/30300 (epoch 14.757), train_loss = 1.38708685, grad/param norm = 1.5679e-01, time/batch = 19.2893s	
8944/30300 (epoch 14.759), train_loss = 1.31607213, grad/param norm = 1.3614e-01, time/batch = 19.7839s	
8945/30300 (epoch 14.761), train_loss = 1.19085822, grad/param norm = 1.3363e-01, time/batch = 20.2112s	
8946/30300 (epoch 14.762), train_loss = 1.14455695, grad/param norm = 1.2403e-01, time/batch = 19.0338s	
8947/30300 (epoch 14.764), train_loss = 1.30062028, grad/param norm = 1.4149e-01, time/batch = 19.2048s	
8948/30300 (epoch 14.766), train_loss = 1.35996153, grad/param norm = 1.4017e-01, time/batch = 19.7077s	
8949/30300 (epoch 14.767), train_loss = 1.42380961, grad/param norm = 1.8474e-01, time/batch = 17.7197s	
8950/30300 (epoch 14.769), train_loss = 1.40617996, grad/param norm = 1.4633e-01, time/batch = 20.1977s	
8951/30300 (epoch 14.771), train_loss = 1.29421948, grad/param norm = 1.5186e-01, time/batch = 19.2793s	
8952/30300 (epoch 14.772), train_loss = 1.36871779, grad/param norm = 1.5261e-01, time/batch = 18.3854s	
8953/30300 (epoch 14.774), train_loss = 1.51086963, grad/param norm = 1.4401e-01, time/batch = 20.3744s	
8954/30300 (epoch 14.776), train_loss = 1.38897603, grad/param norm = 1.5729e-01, time/batch = 19.3780s	
8955/30300 (epoch 14.777), train_loss = 1.36659627, grad/param norm = 1.3783e-01, time/batch = 18.8727s	
8956/30300 (epoch 14.779), train_loss = 1.51305559, grad/param norm = 1.7695e-01, time/batch = 18.0388s	
8957/30300 (epoch 14.781), train_loss = 1.33805558, grad/param norm = 1.6119e-01, time/batch = 18.7777s	
8958/30300 (epoch 14.782), train_loss = 1.28071519, grad/param norm = 1.4304e-01, time/batch = 15.3697s	
8959/30300 (epoch 14.784), train_loss = 1.26059296, grad/param norm = 1.3599e-01, time/batch = 18.5206s	
8960/30300 (epoch 14.785), train_loss = 1.48862527, grad/param norm = 1.6155e-01, time/batch = 19.2973s	
8961/30300 (epoch 14.787), train_loss = 1.19570367, grad/param norm = 1.4568e-01, time/batch = 19.5444s	
8962/30300 (epoch 14.789), train_loss = 1.60057302, grad/param norm = 1.4730e-01, time/batch = 17.8720s	
8963/30300 (epoch 14.790), train_loss = 1.41876555, grad/param norm = 1.5850e-01, time/batch = 20.1264s	
8964/30300 (epoch 14.792), train_loss = 1.19072610, grad/param norm = 1.5358e-01, time/batch = 20.5424s	
8965/30300 (epoch 14.794), train_loss = 1.30311101, grad/param norm = 1.6020e-01, time/batch = 32.7565s	
8966/30300 (epoch 14.795), train_loss = 1.27412109, grad/param norm = 1.3102e-01, time/batch = 17.6775s	
8967/30300 (epoch 14.797), train_loss = 1.53957624, grad/param norm = 1.7120e-01, time/batch = 18.1088s	
8968/30300 (epoch 14.799), train_loss = 1.41297160, grad/param norm = 1.6262e-01, time/batch = 19.1277s	
8969/30300 (epoch 14.800), train_loss = 1.41138458, grad/param norm = 1.5435e-01, time/batch = 19.3840s	
8970/30300 (epoch 14.802), train_loss = 1.57339390, grad/param norm = 1.6575e-01, time/batch = 19.2074s	
8971/30300 (epoch 14.804), train_loss = 1.41264449, grad/param norm = 1.5554e-01, time/batch = 19.0438s	
8972/30300 (epoch 14.805), train_loss = 1.52720700, grad/param norm = 1.6866e-01, time/batch = 18.6252s	
8973/30300 (epoch 14.807), train_loss = 1.34932892, grad/param norm = 2.1557e-01, time/batch = 19.5416s	
8974/30300 (epoch 14.809), train_loss = 1.45026649, grad/param norm = 1.7070e-01, time/batch = 18.8010s	
8975/30300 (epoch 14.810), train_loss = 1.43740820, grad/param norm = 1.5563e-01, time/batch = 19.5349s	
8976/30300 (epoch 14.812), train_loss = 1.24048168, grad/param norm = 1.5073e-01, time/batch = 18.3650s	
8977/30300 (epoch 14.814), train_loss = 1.37164058, grad/param norm = 1.5608e-01, time/batch = 19.3711s	
8978/30300 (epoch 14.815), train_loss = 1.38800473, grad/param norm = 1.5821e-01, time/batch = 18.8818s	
8979/30300 (epoch 14.817), train_loss = 1.46014724, grad/param norm = 1.6854e-01, time/batch = 19.4672s	
8980/30300 (epoch 14.818), train_loss = 1.39446592, grad/param norm = 1.4412e-01, time/batch = 18.1839s	
8981/30300 (epoch 14.820), train_loss = 1.56185230, grad/param norm = 1.5706e-01, time/batch = 20.3751s	
8982/30300 (epoch 14.822), train_loss = 1.55942915, grad/param norm = 1.8784e-01, time/batch = 19.8795s	
8983/30300 (epoch 14.823), train_loss = 1.59748698, grad/param norm = 1.7319e-01, time/batch = 18.4749s	
8984/30300 (epoch 14.825), train_loss = 1.47373440, grad/param norm = 1.6144e-01, time/batch = 19.3035s	
8985/30300 (epoch 14.827), train_loss = 1.24258702, grad/param norm = 1.6781e-01, time/batch = 19.3830s	
8986/30300 (epoch 14.828), train_loss = 1.40234435, grad/param norm = 1.5087e-01, time/batch = 17.0335s	
8987/30300 (epoch 14.830), train_loss = 1.37639469, grad/param norm = 1.5485e-01, time/batch = 19.5325s	
8988/30300 (epoch 14.832), train_loss = 1.31309251, grad/param norm = 1.5999e-01, time/batch = 19.3005s	
8989/30300 (epoch 14.833), train_loss = 1.43097636, grad/param norm = 1.5617e-01, time/batch = 17.3887s	
8990/30300 (epoch 14.835), train_loss = 1.30481085, grad/param norm = 1.5320e-01, time/batch = 20.1197s	
8991/30300 (epoch 14.837), train_loss = 1.18890644, grad/param norm = 1.4096e-01, time/batch = 19.9611s	
8992/30300 (epoch 14.838), train_loss = 1.21158852, grad/param norm = 1.4371e-01, time/batch = 18.7834s	
8993/30300 (epoch 14.840), train_loss = 1.40934812, grad/param norm = 1.3102e-01, time/batch = 19.4574s	
8994/30300 (epoch 14.842), train_loss = 1.22543947, grad/param norm = 1.2111e-01, time/batch = 19.6248s	
8995/30300 (epoch 14.843), train_loss = 1.37398843, grad/param norm = 1.3921e-01, time/batch = 18.1956s	
8996/30300 (epoch 14.845), train_loss = 1.35050869, grad/param norm = 1.3440e-01, time/batch = 17.8634s	
8997/30300 (epoch 14.847), train_loss = 1.38122819, grad/param norm = 1.6293e-01, time/batch = 19.6243s	
8998/30300 (epoch 14.848), train_loss = 1.46648781, grad/param norm = 1.5094e-01, time/batch = 18.7975s	
8999/30300 (epoch 14.850), train_loss = 1.33042668, grad/param norm = 1.4606e-01, time/batch = 17.2271s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch14.85_1.7398.t7	
9000/30300 (epoch 14.851), train_loss = 1.42981687, grad/param norm = 1.6681e-01, time/batch = 16.4749s	
9001/30300 (epoch 14.853), train_loss = 1.65769485, grad/param norm = 1.6215e-01, time/batch = 19.3935s	
9002/30300 (epoch 14.855), train_loss = 1.29373678, grad/param norm = 1.3808e-01, time/batch = 18.1853s	
9003/30300 (epoch 14.856), train_loss = 1.30944659, grad/param norm = 1.5513e-01, time/batch = 20.4569s	
9004/30300 (epoch 14.858), train_loss = 1.28501915, grad/param norm = 1.3973e-01, time/batch = 19.2162s	
9005/30300 (epoch 14.860), train_loss = 1.28587887, grad/param norm = 1.5108e-01, time/batch = 19.1065s	
9006/30300 (epoch 14.861), train_loss = 1.50649735, grad/param norm = 1.4517e-01, time/batch = 20.1328s	
9007/30300 (epoch 14.863), train_loss = 1.35464495, grad/param norm = 1.3591e-01, time/batch = 19.5371s	
9008/30300 (epoch 14.865), train_loss = 1.48771327, grad/param norm = 1.5413e-01, time/batch = 19.3771s	
9009/30300 (epoch 14.866), train_loss = 1.41596405, grad/param norm = 1.5836e-01, time/batch = 18.1322s	
9010/30300 (epoch 14.868), train_loss = 1.33354727, grad/param norm = 1.4000e-01, time/batch = 18.4751s	
9011/30300 (epoch 14.870), train_loss = 1.30305964, grad/param norm = 1.4004e-01, time/batch = 18.3594s	
9012/30300 (epoch 14.871), train_loss = 1.29206481, grad/param norm = 1.2725e-01, time/batch = 18.5496s	
9013/30300 (epoch 14.873), train_loss = 1.35018751, grad/param norm = 1.3648e-01, time/batch = 19.2982s	
9014/30300 (epoch 14.875), train_loss = 1.22004891, grad/param norm = 1.3127e-01, time/batch = 18.4646s	
9015/30300 (epoch 14.876), train_loss = 1.23970656, grad/param norm = 1.4151e-01, time/batch = 20.1360s	
9016/30300 (epoch 14.878), train_loss = 1.13913832, grad/param norm = 1.4557e-01, time/batch = 19.8842s	
9017/30300 (epoch 14.880), train_loss = 1.25708813, grad/param norm = 1.3769e-01, time/batch = 17.9642s	
9018/30300 (epoch 14.881), train_loss = 1.55177729, grad/param norm = 1.5680e-01, time/batch = 19.7904s	
9019/30300 (epoch 14.883), train_loss = 1.41928852, grad/param norm = 1.6056e-01, time/batch = 18.9773s	
9020/30300 (epoch 14.884), train_loss = 1.19496758, grad/param norm = 1.2178e-01, time/batch = 14.0335s	
9021/30300 (epoch 14.886), train_loss = 1.35525649, grad/param norm = 1.4425e-01, time/batch = 0.6917s	
9022/30300 (epoch 14.888), train_loss = 1.37104740, grad/param norm = 1.5282e-01, time/batch = 0.6877s	
9023/30300 (epoch 14.889), train_loss = 1.34803489, grad/param norm = 1.4578e-01, time/batch = 0.6868s	
9024/30300 (epoch 14.891), train_loss = 1.33402751, grad/param norm = 1.4610e-01, time/batch = 0.6973s	
9025/30300 (epoch 14.893), train_loss = 1.60050274, grad/param norm = 1.5772e-01, time/batch = 0.6896s	
9026/30300 (epoch 14.894), train_loss = 1.46103732, grad/param norm = 1.4479e-01, time/batch = 0.6872s	
9027/30300 (epoch 14.896), train_loss = 1.16550491, grad/param norm = 1.3125e-01, time/batch = 0.6925s	
9028/30300 (epoch 14.898), train_loss = 1.12956599, grad/param norm = 1.4648e-01, time/batch = 0.6869s	
9029/30300 (epoch 14.899), train_loss = 1.28102634, grad/param norm = 1.4422e-01, time/batch = 0.6985s	
9030/30300 (epoch 14.901), train_loss = 1.34685353, grad/param norm = 1.6420e-01, time/batch = 0.7057s	
9031/30300 (epoch 14.903), train_loss = 1.37426179, grad/param norm = 1.5257e-01, time/batch = 0.6911s	
9032/30300 (epoch 14.904), train_loss = 1.30488772, grad/param norm = 1.4990e-01, time/batch = 0.6875s	
9033/30300 (epoch 14.906), train_loss = 1.47971153, grad/param norm = 1.6294e-01, time/batch = 0.6966s	
9034/30300 (epoch 14.908), train_loss = 1.23355944, grad/param norm = 1.3050e-01, time/batch = 0.7214s	
9035/30300 (epoch 14.909), train_loss = 1.28648242, grad/param norm = 1.5592e-01, time/batch = 0.9969s	
9036/30300 (epoch 14.911), train_loss = 1.32714653, grad/param norm = 1.4288e-01, time/batch = 1.0143s	
9037/30300 (epoch 14.913), train_loss = 1.33183013, grad/param norm = 1.3770e-01, time/batch = 1.0037s	
9038/30300 (epoch 14.914), train_loss = 1.32866081, grad/param norm = 1.5951e-01, time/batch = 1.0303s	
9039/30300 (epoch 14.916), train_loss = 1.34547695, grad/param norm = 1.3868e-01, time/batch = 1.0197s	
9040/30300 (epoch 14.917), train_loss = 1.24339641, grad/param norm = 1.3796e-01, time/batch = 1.8724s	
9041/30300 (epoch 14.919), train_loss = 1.31245388, grad/param norm = 1.4777e-01, time/batch = 1.8837s	
9042/30300 (epoch 14.921), train_loss = 1.34245652, grad/param norm = 1.4779e-01, time/batch = 9.9099s	
9043/30300 (epoch 14.922), train_loss = 1.43369003, grad/param norm = 1.6158e-01, time/batch = 19.8755s	
9044/30300 (epoch 14.924), train_loss = 1.34734960, grad/param norm = 1.5578e-01, time/batch = 18.4731s	
9045/30300 (epoch 14.926), train_loss = 1.33528120, grad/param norm = 1.5086e-01, time/batch = 20.3064s	
9046/30300 (epoch 14.927), train_loss = 1.32986450, grad/param norm = 1.5120e-01, time/batch = 17.3719s	
9047/30300 (epoch 14.929), train_loss = 1.28840562, grad/param norm = 1.6740e-01, time/batch = 17.8601s	
9048/30300 (epoch 14.931), train_loss = 1.47815163, grad/param norm = 1.7390e-01, time/batch = 18.4649s	
9049/30300 (epoch 14.932), train_loss = 1.28161866, grad/param norm = 1.6293e-01, time/batch = 18.5386s	
9050/30300 (epoch 14.934), train_loss = 1.36742738, grad/param norm = 1.5483e-01, time/batch = 19.2764s	
9051/30300 (epoch 14.936), train_loss = 1.30600535, grad/param norm = 1.4482e-01, time/batch = 18.8746s	
9052/30300 (epoch 14.937), train_loss = 1.26936309, grad/param norm = 1.4139e-01, time/batch = 19.4664s	
9053/30300 (epoch 14.939), train_loss = 1.46689229, grad/param norm = 1.6236e-01, time/batch = 19.0334s	
9054/30300 (epoch 14.941), train_loss = 1.33224028, grad/param norm = 1.5357e-01, time/batch = 17.8064s	
9055/30300 (epoch 14.942), train_loss = 1.34093812, grad/param norm = 1.4661e-01, time/batch = 18.6347s	
9056/30300 (epoch 14.944), train_loss = 1.23725554, grad/param norm = 1.3725e-01, time/batch = 19.6204s	
9057/30300 (epoch 14.946), train_loss = 1.49314805, grad/param norm = 1.8008e-01, time/batch = 18.6924s	
9058/30300 (epoch 14.947), train_loss = 1.50473458, grad/param norm = 1.8322e-01, time/batch = 19.7867s	
9059/30300 (epoch 14.949), train_loss = 1.52356165, grad/param norm = 1.6804e-01, time/batch = 17.8544s	
9060/30300 (epoch 14.950), train_loss = 1.47880984, grad/param norm = 1.6267e-01, time/batch = 17.3476s	
9061/30300 (epoch 14.952), train_loss = 1.42410670, grad/param norm = 1.6563e-01, time/batch = 19.5433s	
9062/30300 (epoch 14.954), train_loss = 1.61048624, grad/param norm = 1.5771e-01, time/batch = 19.4665s	
9063/30300 (epoch 14.955), train_loss = 1.29214414, grad/param norm = 1.5109e-01, time/batch = 18.6316s	
9064/30300 (epoch 14.957), train_loss = 1.40403443, grad/param norm = 1.5406e-01, time/batch = 19.9680s	
9065/30300 (epoch 14.959), train_loss = 1.34521370, grad/param norm = 1.6240e-01, time/batch = 18.3757s	
9066/30300 (epoch 14.960), train_loss = 1.33474202, grad/param norm = 1.5020e-01, time/batch = 18.8781s	
9067/30300 (epoch 14.962), train_loss = 1.30710976, grad/param norm = 1.7303e-01, time/batch = 18.9621s	
9068/30300 (epoch 14.964), train_loss = 1.28009377, grad/param norm = 1.5536e-01, time/batch = 19.4653s	
9069/30300 (epoch 14.965), train_loss = 1.26822539, grad/param norm = 1.5076e-01, time/batch = 18.3111s	
9070/30300 (epoch 14.967), train_loss = 1.31207318, grad/param norm = 1.6014e-01, time/batch = 19.0374s	
9071/30300 (epoch 14.969), train_loss = 1.28419874, grad/param norm = 1.6379e-01, time/batch = 20.3739s	
9072/30300 (epoch 14.970), train_loss = 1.30408987, grad/param norm = 1.3876e-01, time/batch = 18.2182s	
9073/30300 (epoch 14.972), train_loss = 1.22522201, grad/param norm = 1.4775e-01, time/batch = 19.2837s	
9074/30300 (epoch 14.974), train_loss = 1.56393611, grad/param norm = 1.6472e-01, time/batch = 20.2117s	
9075/30300 (epoch 14.975), train_loss = 1.56537930, grad/param norm = 1.8629e-01, time/batch = 19.2861s	
9076/30300 (epoch 14.977), train_loss = 1.44167549, grad/param norm = 1.5621e-01, time/batch = 18.8775s	
9077/30300 (epoch 14.979), train_loss = 1.39716119, grad/param norm = 1.5009e-01, time/batch = 19.1354s	
9078/30300 (epoch 14.980), train_loss = 1.44405415, grad/param norm = 1.6263e-01, time/batch = 18.6291s	
9079/30300 (epoch 14.982), train_loss = 1.45020852, grad/param norm = 1.5381e-01, time/batch = 19.5954s	
9080/30300 (epoch 14.983), train_loss = 1.48248224, grad/param norm = 1.5996e-01, time/batch = 18.8075s	
9081/30300 (epoch 14.985), train_loss = 1.36814210, grad/param norm = 1.6167e-01, time/batch = 18.9606s	
9082/30300 (epoch 14.987), train_loss = 1.32402889, grad/param norm = 1.3847e-01, time/batch = 19.5274s	
9083/30300 (epoch 14.988), train_loss = 1.52820257, grad/param norm = 1.4989e-01, time/batch = 17.0249s	
9084/30300 (epoch 14.990), train_loss = 1.17628022, grad/param norm = 1.3498e-01, time/batch = 19.7852s	
9085/30300 (epoch 14.992), train_loss = 1.40806617, grad/param norm = 1.3854e-01, time/batch = 18.8634s	
9086/30300 (epoch 14.993), train_loss = 1.48222503, grad/param norm = 2.1536e-01, time/batch = 19.4578s	
9087/30300 (epoch 14.995), train_loss = 1.35765397, grad/param norm = 1.6365e-01, time/batch = 19.4707s	
9088/30300 (epoch 14.997), train_loss = 1.38692622, grad/param norm = 1.5736e-01, time/batch = 18.4516s	
9089/30300 (epoch 14.998), train_loss = 1.46549283, grad/param norm = 1.6804e-01, time/batch = 19.7839s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
9090/30300 (epoch 15.000), train_loss = 1.29434424, grad/param norm = 1.4794e-01, time/batch = 19.8768s	
9091/30300 (epoch 15.002), train_loss = 1.42758843, grad/param norm = 1.5190e-01, time/batch = 18.1376s	
9092/30300 (epoch 15.003), train_loss = 1.36430645, grad/param norm = 1.5680e-01, time/batch = 18.4692s	
9093/30300 (epoch 15.005), train_loss = 1.33993891, grad/param norm = 1.6041e-01, time/batch = 19.6309s	
9094/30300 (epoch 15.007), train_loss = 1.45676793, grad/param norm = 1.6120e-01, time/batch = 18.8870s	
9095/30300 (epoch 15.008), train_loss = 1.29413182, grad/param norm = 1.5089e-01, time/batch = 18.5499s	
9096/30300 (epoch 15.010), train_loss = 1.23378332, grad/param norm = 1.3549e-01, time/batch = 17.7003s	
9097/30300 (epoch 15.012), train_loss = 1.26820663, grad/param norm = 1.3965e-01, time/batch = 17.4328s	
9098/30300 (epoch 15.013), train_loss = 1.41287916, grad/param norm = 1.5949e-01, time/batch = 19.2845s	
9099/30300 (epoch 15.015), train_loss = 1.31604631, grad/param norm = 1.5047e-01, time/batch = 20.3731s	
9100/30300 (epoch 15.017), train_loss = 1.24938142, grad/param norm = 1.3784e-01, time/batch = 19.3576s	
9101/30300 (epoch 15.018), train_loss = 1.27766559, grad/param norm = 1.4489e-01, time/batch = 19.0513s	
9102/30300 (epoch 15.020), train_loss = 1.47525184, grad/param norm = 1.7437e-01, time/batch = 19.7979s	
9103/30300 (epoch 15.021), train_loss = 1.47905333, grad/param norm = 1.6497e-01, time/batch = 20.1352s	
9104/30300 (epoch 15.023), train_loss = 1.29892603, grad/param norm = 1.3779e-01, time/batch = 18.3569s	
9105/30300 (epoch 15.025), train_loss = 1.28287172, grad/param norm = 1.7201e-01, time/batch = 19.9477s	
9106/30300 (epoch 15.026), train_loss = 1.39176564, grad/param norm = 1.5553e-01, time/batch = 19.9622s	
9107/30300 (epoch 15.028), train_loss = 1.42442332, grad/param norm = 1.6091e-01, time/batch = 18.7876s	
9108/30300 (epoch 15.030), train_loss = 1.28511604, grad/param norm = 1.4956e-01, time/batch = 19.8021s	
9109/30300 (epoch 15.031), train_loss = 1.35664228, grad/param norm = 1.5636e-01, time/batch = 19.2248s	
9110/30300 (epoch 15.033), train_loss = 1.36264621, grad/param norm = 1.6190e-01, time/batch = 18.5363s	
9111/30300 (epoch 15.035), train_loss = 1.44487061, grad/param norm = 1.5879e-01, time/batch = 18.8606s	
9112/30300 (epoch 15.036), train_loss = 1.35011182, grad/param norm = 1.5332e-01, time/batch = 19.5401s	
9113/30300 (epoch 15.038), train_loss = 1.35247856, grad/param norm = 1.4790e-01, time/batch = 19.3791s	
9114/30300 (epoch 15.040), train_loss = 1.07684574, grad/param norm = 1.3232e-01, time/batch = 19.2075s	
9115/30300 (epoch 15.041), train_loss = 1.14199494, grad/param norm = 1.3230e-01, time/batch = 19.6293s	
9116/30300 (epoch 15.043), train_loss = 1.36805820, grad/param norm = 1.5336e-01, time/batch = 18.7252s	
9117/30300 (epoch 15.045), train_loss = 1.31324080, grad/param norm = 1.5240e-01, time/batch = 19.0443s	
9118/30300 (epoch 15.046), train_loss = 1.47015898, grad/param norm = 1.7057e-01, time/batch = 19.2193s	
9119/30300 (epoch 15.048), train_loss = 1.36328303, grad/param norm = 1.6339e-01, time/batch = 18.5363s	
9120/30300 (epoch 15.050), train_loss = 1.35647210, grad/param norm = 1.5332e-01, time/batch = 19.1752s	
9121/30300 (epoch 15.051), train_loss = 1.38840660, grad/param norm = 1.6565e-01, time/batch = 19.0342s	
9122/30300 (epoch 15.053), train_loss = 1.16473993, grad/param norm = 1.5681e-01, time/batch = 19.2140s	
9123/30300 (epoch 15.054), train_loss = 1.30599916, grad/param norm = 1.5805e-01, time/batch = 18.9630s	
9124/30300 (epoch 15.056), train_loss = 1.26041663, grad/param norm = 1.4085e-01, time/batch = 19.3808s	
9125/30300 (epoch 15.058), train_loss = 1.31070416, grad/param norm = 1.4721e-01, time/batch = 19.2043s	
9126/30300 (epoch 15.059), train_loss = 1.25030800, grad/param norm = 1.5552e-01, time/batch = 18.0226s	
9127/30300 (epoch 15.061), train_loss = 1.46151645, grad/param norm = 1.6428e-01, time/batch = 18.9697s	
9128/30300 (epoch 15.063), train_loss = 1.28692365, grad/param norm = 1.5483e-01, time/batch = 18.1944s	
9129/30300 (epoch 15.064), train_loss = 1.39521183, grad/param norm = 1.5317e-01, time/batch = 16.9639s	
9130/30300 (epoch 15.066), train_loss = 1.31410572, grad/param norm = 1.4611e-01, time/batch = 19.6203s	
9131/30300 (epoch 15.068), train_loss = 1.21016916, grad/param norm = 1.4267e-01, time/batch = 20.0456s	
9132/30300 (epoch 15.069), train_loss = 1.41692010, grad/param norm = 1.5376e-01, time/batch = 17.2910s	
9133/30300 (epoch 15.071), train_loss = 1.40050108, grad/param norm = 1.6342e-01, time/batch = 19.5507s	
9134/30300 (epoch 15.073), train_loss = 1.35768556, grad/param norm = 1.6401e-01, time/batch = 19.4414s	
9135/30300 (epoch 15.074), train_loss = 1.38245998, grad/param norm = 1.3887e-01, time/batch = 18.0391s	
9136/30300 (epoch 15.076), train_loss = 1.32875998, grad/param norm = 1.5024e-01, time/batch = 19.4579s	
9137/30300 (epoch 15.078), train_loss = 1.22066970, grad/param norm = 1.4259e-01, time/batch = 20.1962s	
9138/30300 (epoch 15.079), train_loss = 1.25445511, grad/param norm = 1.3113e-01, time/batch = 19.0273s	
9139/30300 (epoch 15.081), train_loss = 1.36704421, grad/param norm = 1.4999e-01, time/batch = 17.7723s	
9140/30300 (epoch 15.083), train_loss = 1.45789059, grad/param norm = 1.7086e-01, time/batch = 19.7702s	
9141/30300 (epoch 15.084), train_loss = 1.23269375, grad/param norm = 1.4626e-01, time/batch = 17.3744s	
9142/30300 (epoch 15.086), train_loss = 1.26670870, grad/param norm = 1.5076e-01, time/batch = 19.7861s	
9143/30300 (epoch 15.087), train_loss = 1.22744399, grad/param norm = 1.3038e-01, time/batch = 19.0285s	
9144/30300 (epoch 15.089), train_loss = 1.29931603, grad/param norm = 1.5489e-01, time/batch = 18.6276s	
9145/30300 (epoch 15.091), train_loss = 1.38159173, grad/param norm = 1.5995e-01, time/batch = 19.3688s	
9146/30300 (epoch 15.092), train_loss = 1.35741668, grad/param norm = 1.5220e-01, time/batch = 18.8734s	
9147/30300 (epoch 15.094), train_loss = 1.52085834, grad/param norm = 1.6899e-01, time/batch = 19.8800s	
9148/30300 (epoch 15.096), train_loss = 1.44082251, grad/param norm = 1.5214e-01, time/batch = 19.3633s	
9149/30300 (epoch 15.097), train_loss = 1.28513855, grad/param norm = 1.4350e-01, time/batch = 19.2916s	
9150/30300 (epoch 15.099), train_loss = 1.47862288, grad/param norm = 1.5956e-01, time/batch = 15.3780s	
9151/30300 (epoch 15.101), train_loss = 1.53566900, grad/param norm = 1.6244e-01, time/batch = 18.5303s	
9152/30300 (epoch 15.102), train_loss = 1.28969053, grad/param norm = 1.6282e-01, time/batch = 19.5386s	
9153/30300 (epoch 15.104), train_loss = 1.31185677, grad/param norm = 1.7416e-01, time/batch = 19.7087s	
9154/30300 (epoch 15.106), train_loss = 1.33331658, grad/param norm = 1.5302e-01, time/batch = 18.5396s	
9155/30300 (epoch 15.107), train_loss = 1.37037483, grad/param norm = 1.5053e-01, time/batch = 19.5532s	
9156/30300 (epoch 15.109), train_loss = 1.44484141, grad/param norm = 1.7881e-01, time/batch = 19.6166s	
9157/30300 (epoch 15.111), train_loss = 1.48288119, grad/param norm = 1.5974e-01, time/batch = 19.0355s	
9158/30300 (epoch 15.112), train_loss = 1.38554736, grad/param norm = 1.4357e-01, time/batch = 17.0309s	
9159/30300 (epoch 15.114), train_loss = 1.35857683, grad/param norm = 1.4778e-01, time/batch = 19.2928s	
9160/30300 (epoch 15.116), train_loss = 1.35576241, grad/param norm = 1.6558e-01, time/batch = 17.7880s	
9161/30300 (epoch 15.117), train_loss = 1.37584194, grad/param norm = 1.4576e-01, time/batch = 18.8002s	
9162/30300 (epoch 15.119), train_loss = 1.26871628, grad/param norm = 1.5664e-01, time/batch = 20.0515s	
9163/30300 (epoch 15.120), train_loss = 1.34895522, grad/param norm = 1.5611e-01, time/batch = 18.8828s	
9164/30300 (epoch 15.122), train_loss = 1.41386462, grad/param norm = 1.6433e-01, time/batch = 18.6214s	
9165/30300 (epoch 15.124), train_loss = 1.54540337, grad/param norm = 1.7307e-01, time/batch = 19.1291s	
9166/30300 (epoch 15.125), train_loss = 1.21375293, grad/param norm = 1.4153e-01, time/batch = 19.3787s	
9167/30300 (epoch 15.127), train_loss = 1.34482099, grad/param norm = 1.6226e-01, time/batch = 32.4289s	
9168/30300 (epoch 15.129), train_loss = 1.50313989, grad/param norm = 1.4364e-01, time/batch = 18.5392s	
9169/30300 (epoch 15.130), train_loss = 1.48670294, grad/param norm = 1.5340e-01, time/batch = 14.9046s	
9170/30300 (epoch 15.132), train_loss = 1.42247470, grad/param norm = 1.5750e-01, time/batch = 14.6292s	
9171/30300 (epoch 15.134), train_loss = 1.26107604, grad/param norm = 1.5448e-01, time/batch = 16.0152s	
9172/30300 (epoch 15.135), train_loss = 1.27784252, grad/param norm = 1.5001e-01, time/batch = 18.2772s	
9173/30300 (epoch 15.137), train_loss = 1.38665722, grad/param norm = 1.4984e-01, time/batch = 17.9459s	
9174/30300 (epoch 15.139), train_loss = 1.30852175, grad/param norm = 1.5046e-01, time/batch = 19.6113s	
9175/30300 (epoch 15.140), train_loss = 1.44049581, grad/param norm = 1.8075e-01, time/batch = 19.0480s	
9176/30300 (epoch 15.142), train_loss = 1.54983315, grad/param norm = 2.1412e-01, time/batch = 18.1134s	
9177/30300 (epoch 15.144), train_loss = 1.44987532, grad/param norm = 2.6101e-01, time/batch = 17.7256s	
9178/30300 (epoch 15.145), train_loss = 1.50987631, grad/param norm = 2.7508e-01, time/batch = 19.2769s	
9179/30300 (epoch 15.147), train_loss = 1.37216270, grad/param norm = 2.1561e-01, time/batch = 19.2024s	
9180/30300 (epoch 15.149), train_loss = 1.57638476, grad/param norm = 1.6911e-01, time/batch = 18.7829s	
9181/30300 (epoch 15.150), train_loss = 1.41773452, grad/param norm = 2.1702e-01, time/batch = 20.0459s	
9182/30300 (epoch 15.152), train_loss = 1.24998782, grad/param norm = 1.6809e-01, time/batch = 18.7069s	
9183/30300 (epoch 15.153), train_loss = 1.34520957, grad/param norm = 1.6552e-01, time/batch = 18.2692s	
9184/30300 (epoch 15.155), train_loss = 1.15925779, grad/param norm = 1.3107e-01, time/batch = 19.3746s	
9185/30300 (epoch 15.157), train_loss = 1.32137365, grad/param norm = 1.4939e-01, time/batch = 19.4611s	
9186/30300 (epoch 15.158), train_loss = 1.37614260, grad/param norm = 1.7104e-01, time/batch = 17.5401s	
9187/30300 (epoch 15.160), train_loss = 1.28336393, grad/param norm = 1.4730e-01, time/batch = 18.9714s	
9188/30300 (epoch 15.162), train_loss = 1.31177163, grad/param norm = 1.4766e-01, time/batch = 19.7279s	
9189/30300 (epoch 15.163), train_loss = 1.28870348, grad/param norm = 1.5914e-01, time/batch = 18.7003s	
9190/30300 (epoch 15.165), train_loss = 1.42686000, grad/param norm = 1.5146e-01, time/batch = 19.3003s	
9191/30300 (epoch 15.167), train_loss = 1.36494378, grad/param norm = 1.5571e-01, time/batch = 19.4497s	
9192/30300 (epoch 15.168), train_loss = 1.37747024, grad/param norm = 1.5100e-01, time/batch = 17.5446s	
9193/30300 (epoch 15.170), train_loss = 1.38076491, grad/param norm = 1.6131e-01, time/batch = 19.6308s	
9194/30300 (epoch 15.172), train_loss = 1.29456559, grad/param norm = 1.4991e-01, time/batch = 19.2974s	
9195/30300 (epoch 15.173), train_loss = 1.38502601, grad/param norm = 1.6640e-01, time/batch = 18.6192s	
9196/30300 (epoch 15.175), train_loss = 1.35989992, grad/param norm = 1.4373e-01, time/batch = 18.6381s	
9197/30300 (epoch 15.177), train_loss = 1.35443737, grad/param norm = 1.6561e-01, time/batch = 20.1254s	
9198/30300 (epoch 15.178), train_loss = 1.10902158, grad/param norm = 1.3482e-01, time/batch = 17.7972s	
9199/30300 (epoch 15.180), train_loss = 1.27935061, grad/param norm = 1.4524e-01, time/batch = 19.2862s	
9200/30300 (epoch 15.182), train_loss = 1.26573557, grad/param norm = 1.5041e-01, time/batch = 19.2118s	
9201/30300 (epoch 15.183), train_loss = 1.26288534, grad/param norm = 1.4200e-01, time/batch = 18.5355s	
9202/30300 (epoch 15.185), train_loss = 1.59313332, grad/param norm = 1.5669e-01, time/batch = 19.8666s	
9203/30300 (epoch 15.186), train_loss = 1.61522859, grad/param norm = 1.7243e-01, time/batch = 19.6425s	
9204/30300 (epoch 15.188), train_loss = 1.41986375, grad/param norm = 1.6287e-01, time/batch = 18.1218s	
9205/30300 (epoch 15.190), train_loss = 1.31543573, grad/param norm = 1.4455e-01, time/batch = 19.5418s	
9206/30300 (epoch 15.191), train_loss = 1.41953576, grad/param norm = 1.6176e-01, time/batch = 18.4462s	
9207/30300 (epoch 15.193), train_loss = 1.24964142, grad/param norm = 1.3732e-01, time/batch = 19.2934s	
9208/30300 (epoch 15.195), train_loss = 1.37997883, grad/param norm = 1.5408e-01, time/batch = 19.2944s	
9209/30300 (epoch 15.196), train_loss = 1.36490163, grad/param norm = 1.4835e-01, time/batch = 19.4583s	
9210/30300 (epoch 15.198), train_loss = 1.14509221, grad/param norm = 1.5416e-01, time/batch = 19.7926s	
9211/30300 (epoch 15.200), train_loss = 1.34591902, grad/param norm = 1.3509e-01, time/batch = 19.3725s	
9212/30300 (epoch 15.201), train_loss = 1.43642940, grad/param norm = 1.7072e-01, time/batch = 18.2167s	
9213/30300 (epoch 15.203), train_loss = 1.34071941, grad/param norm = 1.4842e-01, time/batch = 20.3055s	
9214/30300 (epoch 15.205), train_loss = 1.56157932, grad/param norm = 1.6093e-01, time/batch = 18.4508s	
9215/30300 (epoch 15.206), train_loss = 1.52163317, grad/param norm = 1.6399e-01, time/batch = 18.7909s	
9216/30300 (epoch 15.208), train_loss = 1.48109100, grad/param norm = 1.8896e-01, time/batch = 17.6195s	
9217/30300 (epoch 15.210), train_loss = 1.38067729, grad/param norm = 1.4358e-01, time/batch = 18.3121s	
9218/30300 (epoch 15.211), train_loss = 1.44339132, grad/param norm = 1.4828e-01, time/batch = 18.8632s	
9219/30300 (epoch 15.213), train_loss = 1.28399714, grad/param norm = 1.4315e-01, time/batch = 19.8727s	
9220/30300 (epoch 15.215), train_loss = 1.20320988, grad/param norm = 1.5122e-01, time/batch = 17.8756s	
9221/30300 (epoch 15.216), train_loss = 1.31996273, grad/param norm = 1.7356e-01, time/batch = 19.3730s	
9222/30300 (epoch 15.218), train_loss = 1.23380139, grad/param norm = 1.2540e-01, time/batch = 18.0354s	
9223/30300 (epoch 15.219), train_loss = 1.14806581, grad/param norm = 1.3557e-01, time/batch = 15.2784s	
9224/30300 (epoch 15.221), train_loss = 1.19965174, grad/param norm = 1.4333e-01, time/batch = 18.6268s	
9225/30300 (epoch 15.223), train_loss = 1.35197667, grad/param norm = 1.4900e-01, time/batch = 19.7837s	
9226/30300 (epoch 15.224), train_loss = 1.16806443, grad/param norm = 1.4208e-01, time/batch = 19.8022s	
9227/30300 (epoch 15.226), train_loss = 1.43501828, grad/param norm = 1.6849e-01, time/batch = 19.0302s	
9228/30300 (epoch 15.228), train_loss = 1.43753228, grad/param norm = 1.4466e-01, time/batch = 20.2039s	
9229/30300 (epoch 15.229), train_loss = 1.27104156, grad/param norm = 1.6124e-01, time/batch = 18.8870s	
9230/30300 (epoch 15.231), train_loss = 1.37896386, grad/param norm = 1.4648e-01, time/batch = 17.6314s	
9231/30300 (epoch 15.233), train_loss = 1.30322333, grad/param norm = 1.3909e-01, time/batch = 19.5336s	
9232/30300 (epoch 15.234), train_loss = 1.39419086, grad/param norm = 1.6514e-01, time/batch = 19.7817s	
9233/30300 (epoch 15.236), train_loss = 1.28527624, grad/param norm = 1.3340e-01, time/batch = 16.1949s	
9234/30300 (epoch 15.238), train_loss = 1.39473583, grad/param norm = 1.7632e-01, time/batch = 20.0429s	
9235/30300 (epoch 15.239), train_loss = 1.36564596, grad/param norm = 1.5321e-01, time/batch = 20.1388s	
9236/30300 (epoch 15.241), train_loss = 1.40037866, grad/param norm = 1.7610e-01, time/batch = 18.2231s	
9237/30300 (epoch 15.243), train_loss = 1.41444733, grad/param norm = 1.5001e-01, time/batch = 19.7125s	
9238/30300 (epoch 15.244), train_loss = 1.60625322, grad/param norm = 1.7483e-01, time/batch = 18.8831s	
9239/30300 (epoch 15.246), train_loss = 1.31821270, grad/param norm = 1.5055e-01, time/batch = 18.7161s	
9240/30300 (epoch 15.248), train_loss = 1.29971476, grad/param norm = 1.4279e-01, time/batch = 18.7830s	
9241/30300 (epoch 15.249), train_loss = 1.24036041, grad/param norm = 1.4386e-01, time/batch = 20.2107s	
9242/30300 (epoch 15.251), train_loss = 1.23977272, grad/param norm = 1.4628e-01, time/batch = 18.4663s	
9243/30300 (epoch 15.252), train_loss = 1.48186919, grad/param norm = 1.5592e-01, time/batch = 19.2966s	
9244/30300 (epoch 15.254), train_loss = 1.46059771, grad/param norm = 1.6757e-01, time/batch = 19.6251s	
9245/30300 (epoch 15.256), train_loss = 1.37817986, grad/param norm = 1.5118e-01, time/batch = 20.1842s	
9246/30300 (epoch 15.257), train_loss = 1.42916542, grad/param norm = 1.6065e-01, time/batch = 20.1501s	
9247/30300 (epoch 15.259), train_loss = 1.33833971, grad/param norm = 1.5262e-01, time/batch = 23.3547s	
9248/30300 (epoch 15.261), train_loss = 1.46941947, grad/param norm = 1.5389e-01, time/batch = 23.1950s	
9249/30300 (epoch 15.262), train_loss = 1.33386160, grad/param norm = 1.4300e-01, time/batch = 23.9351s	
9250/30300 (epoch 15.264), train_loss = 1.33117674, grad/param norm = 1.5031e-01, time/batch = 21.6906s	
9251/30300 (epoch 15.266), train_loss = 1.28296283, grad/param norm = 1.4003e-01, time/batch = 22.5923s	
9252/30300 (epoch 15.267), train_loss = 1.53188973, grad/param norm = 1.7127e-01, time/batch = 22.7451s	
9253/30300 (epoch 15.269), train_loss = 1.34495798, grad/param norm = 1.5972e-01, time/batch = 23.3504s	
9254/30300 (epoch 15.271), train_loss = 1.36684444, grad/param norm = 1.5380e-01, time/batch = 22.8701s	
9255/30300 (epoch 15.272), train_loss = 1.38428724, grad/param norm = 1.6250e-01, time/batch = 22.7968s	
9256/30300 (epoch 15.274), train_loss = 1.48168508, grad/param norm = 1.5294e-01, time/batch = 21.8756s	
9257/30300 (epoch 15.276), train_loss = 1.42771145, grad/param norm = 1.6647e-01, time/batch = 24.1898s	
9258/30300 (epoch 15.277), train_loss = 1.25454415, grad/param norm = 1.5099e-01, time/batch = 22.3846s	
9259/30300 (epoch 15.279), train_loss = 1.39272047, grad/param norm = 1.5462e-01, time/batch = 22.8696s	
9260/30300 (epoch 15.281), train_loss = 1.45222635, grad/param norm = 1.8520e-01, time/batch = 29.9631s	
9261/30300 (epoch 15.282), train_loss = 1.33138661, grad/param norm = 1.3610e-01, time/batch = 17.3799s	
9262/30300 (epoch 15.284), train_loss = 1.52339534, grad/param norm = 1.7950e-01, time/batch = 19.2105s	
9263/30300 (epoch 15.285), train_loss = 1.35592100, grad/param norm = 1.3892e-01, time/batch = 19.3048s	
9264/30300 (epoch 15.287), train_loss = 1.35465705, grad/param norm = 1.5656e-01, time/batch = 16.9697s	
9265/30300 (epoch 15.289), train_loss = 1.40265548, grad/param norm = 1.4513e-01, time/batch = 19.6152s	
9266/30300 (epoch 15.290), train_loss = 1.09109116, grad/param norm = 1.3212e-01, time/batch = 19.0504s	
9267/30300 (epoch 15.292), train_loss = 1.23294430, grad/param norm = 1.3138e-01, time/batch = 18.1410s	
9268/30300 (epoch 15.294), train_loss = 1.52024849, grad/param norm = 1.6510e-01, time/batch = 18.0353s	
9269/30300 (epoch 15.295), train_loss = 1.32480553, grad/param norm = 1.4433e-01, time/batch = 17.6425s	
9270/30300 (epoch 15.297), train_loss = 1.25893753, grad/param norm = 1.3263e-01, time/batch = 19.2212s	
9271/30300 (epoch 15.299), train_loss = 1.32485596, grad/param norm = 1.4866e-01, time/batch = 19.0359s	
9272/30300 (epoch 15.300), train_loss = 1.35024985, grad/param norm = 1.5844e-01, time/batch = 19.4375s	
9273/30300 (epoch 15.302), train_loss = 1.31083937, grad/param norm = 1.4017e-01, time/batch = 20.1315s	
9274/30300 (epoch 15.304), train_loss = 1.24238563, grad/param norm = 1.3438e-01, time/batch = 19.2731s	
9275/30300 (epoch 15.305), train_loss = 1.29687761, grad/param norm = 1.4410e-01, time/batch = 19.3052s	
9276/30300 (epoch 15.307), train_loss = 1.37244210, grad/param norm = 1.4013e-01, time/batch = 20.2155s	
9277/30300 (epoch 15.309), train_loss = 1.41674602, grad/param norm = 1.4492e-01, time/batch = 18.4545s	
9278/30300 (epoch 15.310), train_loss = 1.32264366, grad/param norm = 1.5555e-01, time/batch = 19.4523s	
9279/30300 (epoch 15.312), train_loss = 1.47417694, grad/param norm = 1.5151e-01, time/batch = 19.3849s	
9280/30300 (epoch 15.314), train_loss = 1.37742408, grad/param norm = 1.4919e-01, time/batch = 18.2908s	
9281/30300 (epoch 15.315), train_loss = 1.39018641, grad/param norm = 1.4843e-01, time/batch = 18.0450s	
9282/30300 (epoch 15.317), train_loss = 1.44308542, grad/param norm = 1.5206e-01, time/batch = 19.5478s	
9283/30300 (epoch 15.318), train_loss = 1.50939250, grad/param norm = 1.6904e-01, time/batch = 18.7875s	
9284/30300 (epoch 15.320), train_loss = 1.45304531, grad/param norm = 1.5576e-01, time/batch = 19.2897s	
9285/30300 (epoch 15.322), train_loss = 1.25676412, grad/param norm = 1.4434e-01, time/batch = 19.7896s	
9286/30300 (epoch 15.323), train_loss = 1.46785442, grad/param norm = 1.6199e-01, time/batch = 18.4731s	
9287/30300 (epoch 15.325), train_loss = 1.31848579, grad/param norm = 1.3324e-01, time/batch = 18.9853s	
9288/30300 (epoch 15.327), train_loss = 1.32760264, grad/param norm = 1.3634e-01, time/batch = 19.6334s	
9289/30300 (epoch 15.328), train_loss = 1.32895299, grad/param norm = 1.3578e-01, time/batch = 17.2791s	
9290/30300 (epoch 15.330), train_loss = 1.39944517, grad/param norm = 1.3385e-01, time/batch = 18.1847s	
9291/30300 (epoch 15.332), train_loss = 1.43826548, grad/param norm = 1.5636e-01, time/batch = 20.1946s	
9292/30300 (epoch 15.333), train_loss = 1.34124399, grad/param norm = 1.6107e-01, time/batch = 18.9446s	
9293/30300 (epoch 15.335), train_loss = 1.21894998, grad/param norm = 1.4474e-01, time/batch = 18.7041s	
9294/30300 (epoch 15.337), train_loss = 1.50380701, grad/param norm = 1.5244e-01, time/batch = 20.2113s	
9295/30300 (epoch 15.338), train_loss = 1.26351978, grad/param norm = 1.3740e-01, time/batch = 19.7911s	
9296/30300 (epoch 15.340), train_loss = 1.22599192, grad/param norm = 1.3479e-01, time/batch = 19.3630s	
9297/30300 (epoch 15.342), train_loss = 1.44063630, grad/param norm = 1.5045e-01, time/batch = 18.2925s	
9298/30300 (epoch 15.343), train_loss = 1.40817523, grad/param norm = 1.4981e-01, time/batch = 19.6891s	
9299/30300 (epoch 15.345), train_loss = 1.37079611, grad/param norm = 1.4554e-01, time/batch = 18.0349s	
9300/30300 (epoch 15.347), train_loss = 1.17848284, grad/param norm = 1.3152e-01, time/batch = 19.5536s	
9301/30300 (epoch 15.348), train_loss = 1.23287513, grad/param norm = 1.4113e-01, time/batch = 19.8040s	
9302/30300 (epoch 15.350), train_loss = 1.33046210, grad/param norm = 1.4317e-01, time/batch = 18.2047s	
9303/30300 (epoch 15.351), train_loss = 1.34041625, grad/param norm = 1.5036e-01, time/batch = 18.0599s	
9304/30300 (epoch 15.353), train_loss = 1.15996573, grad/param norm = 1.4778e-01, time/batch = 20.0478s	
9305/30300 (epoch 15.355), train_loss = 1.29680855, grad/param norm = 1.4694e-01, time/batch = 18.3588s	
9306/30300 (epoch 15.356), train_loss = 1.43886491, grad/param norm = 1.5681e-01, time/batch = 16.3799s	
9307/30300 (epoch 15.358), train_loss = 1.56234090, grad/param norm = 1.4335e-01, time/batch = 19.2884s	
9308/30300 (epoch 15.360), train_loss = 1.28502737, grad/param norm = 1.4673e-01, time/batch = 18.3868s	
9309/30300 (epoch 15.361), train_loss = 1.36578798, grad/param norm = 1.5197e-01, time/batch = 18.3425s	
9310/30300 (epoch 15.363), train_loss = 1.43490685, grad/param norm = 1.5346e-01, time/batch = 18.7047s	
9311/30300 (epoch 15.365), train_loss = 1.24984559, grad/param norm = 1.5758e-01, time/batch = 19.4396s	
9312/30300 (epoch 15.366), train_loss = 1.27775527, grad/param norm = 1.4490e-01, time/batch = 18.7810s	
9313/30300 (epoch 15.368), train_loss = 1.15469402, grad/param norm = 1.4913e-01, time/batch = 19.1281s	
9314/30300 (epoch 15.370), train_loss = 1.22566341, grad/param norm = 1.4572e-01, time/batch = 19.8803s	
9315/30300 (epoch 15.371), train_loss = 1.41173957, grad/param norm = 1.4736e-01, time/batch = 18.3637s	
9316/30300 (epoch 15.373), train_loss = 1.23800592, grad/param norm = 1.2361e-01, time/batch = 17.0525s	
9317/30300 (epoch 15.375), train_loss = 1.24307947, grad/param norm = 1.2827e-01, time/batch = 19.8739s	
9318/30300 (epoch 15.376), train_loss = 1.25983665, grad/param norm = 1.3670e-01, time/batch = 19.4418s	
9319/30300 (epoch 15.378), train_loss = 1.27390300, grad/param norm = 1.5364e-01, time/batch = 37.1397s	
9320/30300 (epoch 15.380), train_loss = 1.52226315, grad/param norm = 1.5820e-01, time/batch = 34.9106s	
9321/30300 (epoch 15.381), train_loss = 1.19952872, grad/param norm = 1.3317e-01, time/batch = 39.6990s	
9322/30300 (epoch 15.383), train_loss = 1.28860173, grad/param norm = 1.5208e-01, time/batch = 40.9755s	
9323/30300 (epoch 15.384), train_loss = 1.42624473, grad/param norm = 1.5333e-01, time/batch = 36.9592s	
9324/30300 (epoch 15.386), train_loss = 1.22039170, grad/param norm = 1.4191e-01, time/batch = 41.2151s	
9325/30300 (epoch 15.388), train_loss = 1.18022209, grad/param norm = 1.3175e-01, time/batch = 38.6014s	
9326/30300 (epoch 15.389), train_loss = 1.32418958, grad/param norm = 1.5647e-01, time/batch = 39.3318s	
9327/30300 (epoch 15.391), train_loss = 1.39193022, grad/param norm = 1.4611e-01, time/batch = 28.5913s	
9328/30300 (epoch 15.393), train_loss = 1.16510715, grad/param norm = 1.2558e-01, time/batch = 17.2887s	
9329/30300 (epoch 15.394), train_loss = 1.37593803, grad/param norm = 1.4648e-01, time/batch = 19.6203s	
9330/30300 (epoch 15.396), train_loss = 1.49733149, grad/param norm = 1.4417e-01, time/batch = 19.8635s	
9331/30300 (epoch 15.398), train_loss = 1.29628679, grad/param norm = 1.2992e-01, time/batch = 18.6120s	
9332/30300 (epoch 15.399), train_loss = 1.31156832, grad/param norm = 1.5036e-01, time/batch = 19.6293s	
9333/30300 (epoch 15.401), train_loss = 1.37920046, grad/param norm = 1.4814e-01, time/batch = 19.9652s	
9334/30300 (epoch 15.403), train_loss = 1.28208493, grad/param norm = 1.4585e-01, time/batch = 19.1217s	
9335/30300 (epoch 15.404), train_loss = 1.24580845, grad/param norm = 1.5876e-01, time/batch = 18.9613s	
9336/30300 (epoch 15.406), train_loss = 1.33473037, grad/param norm = 1.4802e-01, time/batch = 17.1332s	
9337/30300 (epoch 15.408), train_loss = 1.18829059, grad/param norm = 1.3405e-01, time/batch = 19.2152s	
9338/30300 (epoch 15.409), train_loss = 1.18402724, grad/param norm = 1.4722e-01, time/batch = 19.0304s	
9339/30300 (epoch 15.411), train_loss = 1.19375461, grad/param norm = 1.3126e-01, time/batch = 19.1352s	
9340/30300 (epoch 15.413), train_loss = 1.15311405, grad/param norm = 1.5029e-01, time/batch = 18.8046s	
9341/30300 (epoch 15.414), train_loss = 1.47169086, grad/param norm = 1.5071e-01, time/batch = 19.4608s	
9342/30300 (epoch 15.416), train_loss = 1.30116702, grad/param norm = 1.5359e-01, time/batch = 19.7955s	
9343/30300 (epoch 15.417), train_loss = 1.25301527, grad/param norm = 1.4853e-01, time/batch = 19.5388s	
9344/30300 (epoch 15.419), train_loss = 1.20932670, grad/param norm = 1.6200e-01, time/batch = 29.6590s	
9345/30300 (epoch 15.421), train_loss = 1.29396363, grad/param norm = 1.5276e-01, time/batch = 25.9923s	
9346/30300 (epoch 15.422), train_loss = 1.30284253, grad/param norm = 1.5271e-01, time/batch = 18.3673s	
9347/30300 (epoch 15.424), train_loss = 1.33081217, grad/param norm = 1.4469e-01, time/batch = 19.3100s	
9348/30300 (epoch 15.426), train_loss = 1.21700563, grad/param norm = 1.3916e-01, time/batch = 19.3003s	
9349/30300 (epoch 15.427), train_loss = 1.29846256, grad/param norm = 1.5897e-01, time/batch = 18.0297s	
9350/30300 (epoch 15.429), train_loss = 1.31038095, grad/param norm = 1.4571e-01, time/batch = 17.9464s	
9351/30300 (epoch 15.431), train_loss = 1.38242143, grad/param norm = 1.4591e-01, time/batch = 19.8677s	
9352/30300 (epoch 15.432), train_loss = 1.28957343, grad/param norm = 1.3784e-01, time/batch = 17.5160s	
9353/30300 (epoch 15.434), train_loss = 1.16626592, grad/param norm = 1.4499e-01, time/batch = 19.0460s	
9354/30300 (epoch 15.436), train_loss = 1.46822027, grad/param norm = 1.5970e-01, time/batch = 20.1311s	
9355/30300 (epoch 15.437), train_loss = 1.20854468, grad/param norm = 1.5003e-01, time/batch = 18.7126s	
9356/30300 (epoch 15.439), train_loss = 1.24514716, grad/param norm = 1.4872e-01, time/batch = 17.6332s	
9357/30300 (epoch 15.441), train_loss = 1.26861882, grad/param norm = 1.4012e-01, time/batch = 18.7852s	
9358/30300 (epoch 15.442), train_loss = 1.20498678, grad/param norm = 1.3416e-01, time/batch = 19.2234s	
9359/30300 (epoch 15.444), train_loss = 1.11080451, grad/param norm = 1.4044e-01, time/batch = 18.8693s	
9360/30300 (epoch 15.446), train_loss = 1.27173070, grad/param norm = 1.4130e-01, time/batch = 18.8016s	
9361/30300 (epoch 15.447), train_loss = 1.30299217, grad/param norm = 1.5082e-01, time/batch = 20.1177s	
9362/30300 (epoch 15.449), train_loss = 1.23954990, grad/param norm = 1.4472e-01, time/batch = 19.4749s	
9363/30300 (epoch 15.450), train_loss = 1.41261420, grad/param norm = 1.4554e-01, time/batch = 19.6303s	
9364/30300 (epoch 15.452), train_loss = 1.38461030, grad/param norm = 1.3576e-01, time/batch = 19.4581s	
9365/30300 (epoch 15.454), train_loss = 1.35532527, grad/param norm = 1.3282e-01, time/batch = 17.6023s	
9366/30300 (epoch 15.455), train_loss = 1.38281735, grad/param norm = 1.5813e-01, time/batch = 18.0075s	
9367/30300 (epoch 15.457), train_loss = 1.34330673, grad/param norm = 1.4563e-01, time/batch = 20.2925s	
9368/30300 (epoch 15.459), train_loss = 1.40355466, grad/param norm = 1.5615e-01, time/batch = 17.5362s	
9369/30300 (epoch 15.460), train_loss = 1.36399793, grad/param norm = 1.5036e-01, time/batch = 19.1954s	
9370/30300 (epoch 15.462), train_loss = 1.41847840, grad/param norm = 1.4672e-01, time/batch = 19.2059s	
9371/30300 (epoch 15.464), train_loss = 1.17353150, grad/param norm = 1.5201e-01, time/batch = 18.5985s	
9372/30300 (epoch 15.465), train_loss = 1.13738494, grad/param norm = 1.3268e-01, time/batch = 19.8066s	
9373/30300 (epoch 15.467), train_loss = 1.10008172, grad/param norm = 1.2757e-01, time/batch = 19.8110s	
9374/30300 (epoch 15.469), train_loss = 1.21321104, grad/param norm = 1.3597e-01, time/batch = 17.6985s	
9375/30300 (epoch 15.470), train_loss = 1.27942801, grad/param norm = 1.4319e-01, time/batch = 19.5239s	
9376/30300 (epoch 15.472), train_loss = 1.26275080, grad/param norm = 1.3703e-01, time/batch = 19.9480s	
9377/30300 (epoch 15.474), train_loss = 1.30932370, grad/param norm = 1.6196e-01, time/batch = 18.8569s	
9378/30300 (epoch 15.475), train_loss = 1.22181727, grad/param norm = 1.4358e-01, time/batch = 17.3545s	
9379/30300 (epoch 15.477), train_loss = 1.32555559, grad/param norm = 1.5865e-01, time/batch = 19.3814s	
9380/30300 (epoch 15.479), train_loss = 1.32189979, grad/param norm = 1.5032e-01, time/batch = 18.9468s	
9381/30300 (epoch 15.480), train_loss = 1.36139338, grad/param norm = 1.5188e-01, time/batch = 18.9347s	
9382/30300 (epoch 15.482), train_loss = 1.36192780, grad/param norm = 1.3440e-01, time/batch = 19.7075s	
9383/30300 (epoch 15.483), train_loss = 1.27212369, grad/param norm = 1.5477e-01, time/batch = 20.0378s	
9384/30300 (epoch 15.485), train_loss = 1.30759584, grad/param norm = 1.4478e-01, time/batch = 18.3815s	
9385/30300 (epoch 15.487), train_loss = 1.38739593, grad/param norm = 1.5068e-01, time/batch = 18.6913s	
9386/30300 (epoch 15.488), train_loss = 1.39693911, grad/param norm = 1.4381e-01, time/batch = 20.3618s	
9387/30300 (epoch 15.490), train_loss = 1.20614433, grad/param norm = 1.4036e-01, time/batch = 19.3700s	
9388/30300 (epoch 15.492), train_loss = 1.29516891, grad/param norm = 1.4671e-01, time/batch = 18.8680s	
9389/30300 (epoch 15.493), train_loss = 1.27229317, grad/param norm = 1.4570e-01, time/batch = 19.8730s	
9390/30300 (epoch 15.495), train_loss = 1.24292929, grad/param norm = 1.2876e-01, time/batch = 18.6107s	
9391/30300 (epoch 15.497), train_loss = 1.34698300, grad/param norm = 1.3953e-01, time/batch = 19.5357s	
9392/30300 (epoch 15.498), train_loss = 1.34753949, grad/param norm = 1.4107e-01, time/batch = 19.1330s	
9393/30300 (epoch 15.500), train_loss = 1.37543368, grad/param norm = 1.6759e-01, time/batch = 17.2782s	
9394/30300 (epoch 15.502), train_loss = 1.29052527, grad/param norm = 1.5668e-01, time/batch = 18.9737s	
9395/30300 (epoch 15.503), train_loss = 1.38707328, grad/param norm = 1.3662e-01, time/batch = 19.6932s	
9396/30300 (epoch 15.505), train_loss = 1.26684182, grad/param norm = 1.5391e-01, time/batch = 18.8640s	
9397/30300 (epoch 15.507), train_loss = 1.27328829, grad/param norm = 1.5766e-01, time/batch = 19.7729s	
9398/30300 (epoch 15.508), train_loss = 1.29625564, grad/param norm = 1.6616e-01, time/batch = 17.2114s	
9399/30300 (epoch 15.510), train_loss = 1.41992057, grad/param norm = 1.6928e-01, time/batch = 19.2066s	
9400/30300 (epoch 15.512), train_loss = 1.23136190, grad/param norm = 1.3470e-01, time/batch = 18.2798s	
9401/30300 (epoch 15.513), train_loss = 1.36463393, grad/param norm = 1.4680e-01, time/batch = 18.9481s	
9402/30300 (epoch 15.515), train_loss = 1.31549304, grad/param norm = 1.4713e-01, time/batch = 19.2112s	
9403/30300 (epoch 15.517), train_loss = 1.13839899, grad/param norm = 1.3123e-01, time/batch = 19.6278s	
9404/30300 (epoch 15.518), train_loss = 1.40330741, grad/param norm = 1.5818e-01, time/batch = 19.1293s	
9405/30300 (epoch 15.520), train_loss = 1.44079802, grad/param norm = 1.5821e-01, time/batch = 19.1178s	
9406/30300 (epoch 15.521), train_loss = 1.19937221, grad/param norm = 1.5098e-01, time/batch = 18.4509s	
9407/30300 (epoch 15.523), train_loss = 1.47938791, grad/param norm = 1.7566e-01, time/batch = 20.3853s	
9408/30300 (epoch 15.525), train_loss = 1.23326162, grad/param norm = 1.3943e-01, time/batch = 19.7921s	
9409/30300 (epoch 15.526), train_loss = 1.29637756, grad/param norm = 1.4505e-01, time/batch = 19.2872s	
9410/30300 (epoch 15.528), train_loss = 1.17064989, grad/param norm = 1.3501e-01, time/batch = 16.9690s	
9411/30300 (epoch 15.530), train_loss = 1.19426606, grad/param norm = 1.4593e-01, time/batch = 19.9664s	
9412/30300 (epoch 15.531), train_loss = 1.38350509, grad/param norm = 1.6635e-01, time/batch = 18.4668s	
9413/30300 (epoch 15.533), train_loss = 1.35121729, grad/param norm = 1.5836e-01, time/batch = 19.3701s	
9414/30300 (epoch 15.535), train_loss = 1.16149179, grad/param norm = 1.2658e-01, time/batch = 20.0433s	
9415/30300 (epoch 15.536), train_loss = 1.34874452, grad/param norm = 1.5138e-01, time/batch = 18.8721s	
9416/30300 (epoch 15.538), train_loss = 1.14237755, grad/param norm = 1.4788e-01, time/batch = 19.4365s	
9417/30300 (epoch 15.540), train_loss = 1.20343167, grad/param norm = 1.4588e-01, time/batch = 18.6836s	
9418/30300 (epoch 15.541), train_loss = 1.30262716, grad/param norm = 1.5455e-01, time/batch = 17.3166s	
9419/30300 (epoch 15.543), train_loss = 1.32164191, grad/param norm = 1.4777e-01, time/batch = 18.3896s	
9420/30300 (epoch 15.545), train_loss = 1.31800127, grad/param norm = 1.6815e-01, time/batch = 18.2089s	
9421/30300 (epoch 15.546), train_loss = 1.55317236, grad/param norm = 1.4643e-01, time/batch = 18.0500s	
9422/30300 (epoch 15.548), train_loss = 1.23463845, grad/param norm = 1.4328e-01, time/batch = 16.9836s	
9423/30300 (epoch 15.550), train_loss = 1.43396153, grad/param norm = 1.9456e-01, time/batch = 18.5578s	
9424/30300 (epoch 15.551), train_loss = 1.23384536, grad/param norm = 1.4180e-01, time/batch = 17.9819s	
9425/30300 (epoch 15.553), train_loss = 1.27191488, grad/param norm = 1.4413e-01, time/batch = 16.1177s	
9426/30300 (epoch 15.554), train_loss = 1.36175547, grad/param norm = 1.6216e-01, time/batch = 17.7790s	
9427/30300 (epoch 15.556), train_loss = 1.37800374, grad/param norm = 1.5024e-01, time/batch = 17.2828s	
9428/30300 (epoch 15.558), train_loss = 1.44859402, grad/param norm = 1.5814e-01, time/batch = 17.7076s	
9429/30300 (epoch 15.559), train_loss = 1.38040059, grad/param norm = 1.5714e-01, time/batch = 17.8085s	
9430/30300 (epoch 15.561), train_loss = 1.18053002, grad/param norm = 1.4571e-01, time/batch = 18.6309s	
9431/30300 (epoch 15.563), train_loss = 1.21251457, grad/param norm = 1.4564e-01, time/batch = 18.0491s	
9432/30300 (epoch 15.564), train_loss = 1.25619244, grad/param norm = 1.4354e-01, time/batch = 17.8982s	
9433/30300 (epoch 15.566), train_loss = 1.32935887, grad/param norm = 1.4157e-01, time/batch = 18.3741s	
9434/30300 (epoch 15.568), train_loss = 1.11526791, grad/param norm = 1.4134e-01, time/batch = 18.0532s	
9435/30300 (epoch 15.569), train_loss = 1.31727162, grad/param norm = 1.3981e-01, time/batch = 17.1473s	
9436/30300 (epoch 15.571), train_loss = 1.34125462, grad/param norm = 1.5377e-01, time/batch = 18.7274s	
9437/30300 (epoch 15.573), train_loss = 1.34639575, grad/param norm = 1.4527e-01, time/batch = 18.8974s	
9438/30300 (epoch 15.574), train_loss = 1.38973361, grad/param norm = 1.4033e-01, time/batch = 17.6273s	
9439/30300 (epoch 15.576), train_loss = 1.29051466, grad/param norm = 1.3807e-01, time/batch = 19.2989s	
9440/30300 (epoch 15.578), train_loss = 1.17451033, grad/param norm = 1.4400e-01, time/batch = 18.1861s	
9441/30300 (epoch 15.579), train_loss = 1.34333064, grad/param norm = 1.5719e-01, time/batch = 18.7712s	
9442/30300 (epoch 15.581), train_loss = 1.39987155, grad/param norm = 1.4798e-01, time/batch = 18.9423s	
9443/30300 (epoch 15.583), train_loss = 1.50640152, grad/param norm = 1.6313e-01, time/batch = 17.1712s	
9444/30300 (epoch 15.584), train_loss = 1.39625313, grad/param norm = 1.4611e-01, time/batch = 17.2313s	
9445/30300 (epoch 15.586), train_loss = 1.31484963, grad/param norm = 1.4923e-01, time/batch = 18.5011s	
9446/30300 (epoch 15.587), train_loss = 1.31379830, grad/param norm = 1.4570e-01, time/batch = 18.6821s	
9447/30300 (epoch 15.589), train_loss = 1.18997827, grad/param norm = 1.3367e-01, time/batch = 19.5961s	
9448/30300 (epoch 15.591), train_loss = 1.35815254, grad/param norm = 1.4110e-01, time/batch = 18.0343s	
9449/30300 (epoch 15.592), train_loss = 1.29974776, grad/param norm = 1.2804e-01, time/batch = 18.9448s	
9450/30300 (epoch 15.594), train_loss = 1.34163197, grad/param norm = 1.5083e-01, time/batch = 19.6941s	
9451/30300 (epoch 15.596), train_loss = 1.21391719, grad/param norm = 1.3056e-01, time/batch = 18.6999s	
9452/30300 (epoch 15.597), train_loss = 1.25101107, grad/param norm = 1.4705e-01, time/batch = 19.4528s	
9453/30300 (epoch 15.599), train_loss = 1.12964368, grad/param norm = 1.3854e-01, time/batch = 19.0253s	
9454/30300 (epoch 15.601), train_loss = 1.37992957, grad/param norm = 1.5755e-01, time/batch = 17.9510s	
9455/30300 (epoch 15.602), train_loss = 1.30726558, grad/param norm = 1.3490e-01, time/batch = 19.3555s	
9456/30300 (epoch 15.604), train_loss = 1.20626794, grad/param norm = 1.2852e-01, time/batch = 19.1079s	
9457/30300 (epoch 15.606), train_loss = 1.33183609, grad/param norm = 1.7967e-01, time/batch = 17.9502s	
9458/30300 (epoch 15.607), train_loss = 1.39287617, grad/param norm = 1.6250e-01, time/batch = 18.1379s	
9459/30300 (epoch 15.609), train_loss = 1.51154661, grad/param norm = 1.5964e-01, time/batch = 17.4545s	
9460/30300 (epoch 15.611), train_loss = 1.24795291, grad/param norm = 1.5000e-01, time/batch = 18.5021s	
9461/30300 (epoch 15.612), train_loss = 1.21671037, grad/param norm = 1.4832e-01, time/batch = 18.7895s	
9462/30300 (epoch 15.614), train_loss = 1.22632246, grad/param norm = 1.3709e-01, time/batch = 18.9674s	
9463/30300 (epoch 15.616), train_loss = 1.34538394, grad/param norm = 1.5481e-01, time/batch = 19.8747s	
9464/30300 (epoch 15.617), train_loss = 1.29608893, grad/param norm = 1.4952e-01, time/batch = 19.0300s	
9465/30300 (epoch 15.619), train_loss = 1.11983792, grad/param norm = 1.3575e-01, time/batch = 19.5593s	
9466/30300 (epoch 15.620), train_loss = 1.31531829, grad/param norm = 1.5163e-01, time/batch = 19.2027s	
9467/30300 (epoch 15.622), train_loss = 1.29988624, grad/param norm = 1.7452e-01, time/batch = 18.2960s	
9468/30300 (epoch 15.624), train_loss = 1.24341008, grad/param norm = 1.5637e-01, time/batch = 19.6565s	
9469/30300 (epoch 15.625), train_loss = 1.27479643, grad/param norm = 1.5717e-01, time/batch = 18.7179s	
9470/30300 (epoch 15.627), train_loss = 1.45625734, grad/param norm = 1.6349e-01, time/batch = 18.2900s	
9471/30300 (epoch 15.629), train_loss = 1.39642986, grad/param norm = 1.4777e-01, time/batch = 18.5434s	
9472/30300 (epoch 15.630), train_loss = 1.32071699, grad/param norm = 1.3644e-01, time/batch = 19.4491s	
9473/30300 (epoch 15.632), train_loss = 1.41363791, grad/param norm = 1.6050e-01, time/batch = 18.8751s	
9474/30300 (epoch 15.634), train_loss = 1.17112183, grad/param norm = 1.2647e-01, time/batch = 19.0328s	
9475/30300 (epoch 15.635), train_loss = 1.36845445, grad/param norm = 1.4909e-01, time/batch = 20.2765s	
9476/30300 (epoch 15.637), train_loss = 1.39167077, grad/param norm = 1.7380e-01, time/batch = 18.1843s	
9477/30300 (epoch 15.639), train_loss = 1.23955050, grad/param norm = 1.3657e-01, time/batch = 19.7081s	
9478/30300 (epoch 15.640), train_loss = 1.44194775, grad/param norm = 1.5634e-01, time/batch = 18.7998s	
9479/30300 (epoch 15.642), train_loss = 1.26145647, grad/param norm = 1.3794e-01, time/batch = 18.5502s	
9480/30300 (epoch 15.644), train_loss = 1.37068587, grad/param norm = 1.4244e-01, time/batch = 17.6180s	
9481/30300 (epoch 15.645), train_loss = 1.17586449, grad/param norm = 1.3742e-01, time/batch = 18.5290s	
9482/30300 (epoch 15.647), train_loss = 1.28001575, grad/param norm = 1.3889e-01, time/batch = 19.8643s	
9483/30300 (epoch 15.649), train_loss = 1.27275852, grad/param norm = 1.5775e-01, time/batch = 18.3680s	
9484/30300 (epoch 15.650), train_loss = 1.28024537, grad/param norm = 1.3818e-01, time/batch = 19.4615s	
9485/30300 (epoch 15.652), train_loss = 1.23991365, grad/param norm = 1.3251e-01, time/batch = 19.4509s	
9486/30300 (epoch 15.653), train_loss = 1.49879855, grad/param norm = 1.5136e-01, time/batch = 18.5219s	
9487/30300 (epoch 15.655), train_loss = 1.26162996, grad/param norm = 1.5619e-01, time/batch = 18.2835s	
9488/30300 (epoch 15.657), train_loss = 1.28139908, grad/param norm = 1.4558e-01, time/batch = 20.4593s	
9489/30300 (epoch 15.658), train_loss = 1.23167069, grad/param norm = 1.3991e-01, time/batch = 18.2990s	
9490/30300 (epoch 15.660), train_loss = 1.33692542, grad/param norm = 1.4585e-01, time/batch = 19.7008s	
9491/30300 (epoch 15.662), train_loss = 1.36742262, grad/param norm = 1.5893e-01, time/batch = 19.3701s	
9492/30300 (epoch 15.663), train_loss = 1.33827673, grad/param norm = 1.4625e-01, time/batch = 16.8610s	
9493/30300 (epoch 15.665), train_loss = 1.21436502, grad/param norm = 1.4746e-01, time/batch = 20.0360s	
9494/30300 (epoch 15.667), train_loss = 1.41396394, grad/param norm = 1.4894e-01, time/batch = 19.1209s	
9495/30300 (epoch 15.668), train_loss = 1.46322648, grad/param norm = 1.5577e-01, time/batch = 19.1090s	
9496/30300 (epoch 15.670), train_loss = 1.44050211, grad/param norm = 1.4984e-01, time/batch = 18.1242s	
9497/30300 (epoch 15.672), train_loss = 1.38126098, grad/param norm = 1.5621e-01, time/batch = 18.3790s	
9498/30300 (epoch 15.673), train_loss = 1.39941491, grad/param norm = 1.5319e-01, time/batch = 18.7063s	
9499/30300 (epoch 15.675), train_loss = 1.25710002, grad/param norm = 1.4263e-01, time/batch = 19.5542s	
9500/30300 (epoch 15.677), train_loss = 1.24541246, grad/param norm = 1.3802e-01, time/batch = 20.1935s	
9501/30300 (epoch 15.678), train_loss = 1.28045019, grad/param norm = 1.4967e-01, time/batch = 18.8542s	
9502/30300 (epoch 15.680), train_loss = 1.09266533, grad/param norm = 1.3336e-01, time/batch = 19.2894s	
9503/30300 (epoch 15.682), train_loss = 1.29665117, grad/param norm = 1.4580e-01, time/batch = 20.2844s	
9504/30300 (epoch 15.683), train_loss = 1.36059579, grad/param norm = 1.3201e-01, time/batch = 19.3724s	
9505/30300 (epoch 15.685), train_loss = 1.40174858, grad/param norm = 1.6317e-01, time/batch = 18.8709s	
9506/30300 (epoch 15.686), train_loss = 1.29993662, grad/param norm = 1.3845e-01, time/batch = 19.6352s	
9507/30300 (epoch 15.688), train_loss = 1.31100231, grad/param norm = 1.3939e-01, time/batch = 15.4452s	
9508/30300 (epoch 15.690), train_loss = 1.24516576, grad/param norm = 1.4970e-01, time/batch = 18.2699s	
9509/30300 (epoch 15.691), train_loss = 1.34347317, grad/param norm = 1.4325e-01, time/batch = 20.3786s	
9510/30300 (epoch 15.693), train_loss = 1.70145994, grad/param norm = 1.8300e-01, time/batch = 17.2730s	
9511/30300 (epoch 15.695), train_loss = 1.47441438, grad/param norm = 1.7992e-01, time/batch = 18.5468s	
9512/30300 (epoch 15.696), train_loss = 1.42070751, grad/param norm = 1.7199e-01, time/batch = 19.3702s	
9513/30300 (epoch 15.698), train_loss = 1.26309645, grad/param norm = 1.4194e-01, time/batch = 18.7255s	
9514/30300 (epoch 15.700), train_loss = 1.26374532, grad/param norm = 1.5734e-01, time/batch = 18.5511s	
9515/30300 (epoch 15.701), train_loss = 1.13140895, grad/param norm = 1.3135e-01, time/batch = 20.3599s	
9516/30300 (epoch 15.703), train_loss = 1.31901544, grad/param norm = 1.3582e-01, time/batch = 19.7136s	
9517/30300 (epoch 15.705), train_loss = 1.28146223, grad/param norm = 1.4914e-01, time/batch = 18.1181s	
9518/30300 (epoch 15.706), train_loss = 1.38041400, grad/param norm = 1.5430e-01, time/batch = 18.1893s	
9519/30300 (epoch 15.708), train_loss = 1.27113789, grad/param norm = 1.4091e-01, time/batch = 18.6239s	
9520/30300 (epoch 15.710), train_loss = 1.27373259, grad/param norm = 1.4869e-01, time/batch = 19.3034s	
9521/30300 (epoch 15.711), train_loss = 1.18615611, grad/param norm = 1.3137e-01, time/batch = 19.7008s	
9522/30300 (epoch 15.713), train_loss = 1.18544970, grad/param norm = 1.3378e-01, time/batch = 19.8828s	
9523/30300 (epoch 15.715), train_loss = 1.24821173, grad/param norm = 1.3930e-01, time/batch = 19.5247s	
9524/30300 (epoch 15.716), train_loss = 1.42368026, grad/param norm = 1.5197e-01, time/batch = 18.1336s	
9525/30300 (epoch 15.718), train_loss = 1.41792199, grad/param norm = 1.5751e-01, time/batch = 18.1987s	
9526/30300 (epoch 15.719), train_loss = 1.28310415, grad/param norm = 1.5999e-01, time/batch = 20.5417s	
9527/30300 (epoch 15.721), train_loss = 1.33178162, grad/param norm = 1.6394e-01, time/batch = 18.9511s	
9528/30300 (epoch 15.723), train_loss = 1.23028122, grad/param norm = 1.5368e-01, time/batch = 20.1276s	
9529/30300 (epoch 15.724), train_loss = 1.39589164, grad/param norm = 1.7331e-01, time/batch = 19.3004s	
9530/30300 (epoch 15.726), train_loss = 1.71707459, grad/param norm = 1.7353e-01, time/batch = 19.1301s	
9531/30300 (epoch 15.728), train_loss = 1.37023903, grad/param norm = 1.6051e-01, time/batch = 20.4665s	
9532/30300 (epoch 15.729), train_loss = 1.30487690, grad/param norm = 1.5920e-01, time/batch = 19.7061s	
9533/30300 (epoch 15.731), train_loss = 1.38838212, grad/param norm = 1.5289e-01, time/batch = 30.7508s	
9534/30300 (epoch 15.733), train_loss = 1.29208223, grad/param norm = 1.3908e-01, time/batch = 19.5461s	
9535/30300 (epoch 15.734), train_loss = 1.37606470, grad/param norm = 1.4132e-01, time/batch = 18.2914s	
9536/30300 (epoch 15.736), train_loss = 1.30088301, grad/param norm = 1.3842e-01, time/batch = 19.8876s	
9537/30300 (epoch 15.738), train_loss = 1.17818580, grad/param norm = 1.2820e-01, time/batch = 17.7781s	
9538/30300 (epoch 15.739), train_loss = 1.35629383, grad/param norm = 1.4451e-01, time/batch = 18.9388s	
9539/30300 (epoch 15.741), train_loss = 1.42791231, grad/param norm = 1.4328e-01, time/batch = 19.2769s	
9540/30300 (epoch 15.743), train_loss = 1.26475810, grad/param norm = 1.3816e-01, time/batch = 19.1421s	
9541/30300 (epoch 15.744), train_loss = 1.36457744, grad/param norm = 1.4969e-01, time/batch = 19.7096s	
9542/30300 (epoch 15.746), train_loss = 1.18762172, grad/param norm = 1.3637e-01, time/batch = 17.8858s	
9543/30300 (epoch 15.748), train_loss = 1.32955455, grad/param norm = 1.6844e-01, time/batch = 19.7041s	
9544/30300 (epoch 15.749), train_loss = 1.36418337, grad/param norm = 1.6308e-01, time/batch = 19.4584s	
9545/30300 (epoch 15.751), train_loss = 1.26659966, grad/param norm = 1.4114e-01, time/batch = 19.3586s	
9546/30300 (epoch 15.752), train_loss = 1.27358493, grad/param norm = 1.3963e-01, time/batch = 19.2036s	
9547/30300 (epoch 15.754), train_loss = 1.21280234, grad/param norm = 1.3782e-01, time/batch = 19.6380s	
9548/30300 (epoch 15.756), train_loss = 1.26997453, grad/param norm = 1.4016e-01, time/batch = 18.4474s	
9549/30300 (epoch 15.757), train_loss = 1.36299549, grad/param norm = 1.6138e-01, time/batch = 20.1286s	
9550/30300 (epoch 15.759), train_loss = 1.30353821, grad/param norm = 1.3685e-01, time/batch = 18.0295s	
9551/30300 (epoch 15.761), train_loss = 1.15905718, grad/param norm = 1.3353e-01, time/batch = 18.1243s	
9552/30300 (epoch 15.762), train_loss = 1.12506412, grad/param norm = 1.2368e-01, time/batch = 17.1949s	
9553/30300 (epoch 15.764), train_loss = 1.28133695, grad/param norm = 1.5395e-01, time/batch = 19.8682s	
9554/30300 (epoch 15.766), train_loss = 1.34381443, grad/param norm = 1.4442e-01, time/batch = 18.7901s	
9555/30300 (epoch 15.767), train_loss = 1.39241583, grad/param norm = 1.7699e-01, time/batch = 19.3859s	
9556/30300 (epoch 15.769), train_loss = 1.37579464, grad/param norm = 1.4711e-01, time/batch = 19.9664s	
9557/30300 (epoch 15.771), train_loss = 1.26794558, grad/param norm = 1.5781e-01, time/batch = 18.3850s	
9558/30300 (epoch 15.772), train_loss = 1.35146065, grad/param norm = 1.5267e-01, time/batch = 19.4697s	
9559/30300 (epoch 15.774), train_loss = 1.48237804, grad/param norm = 1.4391e-01, time/batch = 18.9690s	
9560/30300 (epoch 15.776), train_loss = 1.36827937, grad/param norm = 1.6047e-01, time/batch = 18.5425s	
9561/30300 (epoch 15.777), train_loss = 1.35086719, grad/param norm = 1.4085e-01, time/batch = 19.5631s	
9562/30300 (epoch 15.779), train_loss = 1.49057935, grad/param norm = 1.7596e-01, time/batch = 16.9481s	
9563/30300 (epoch 15.781), train_loss = 1.31502055, grad/param norm = 1.6579e-01, time/batch = 19.5505s	
9564/30300 (epoch 15.782), train_loss = 1.26081476, grad/param norm = 1.4558e-01, time/batch = 18.8643s	
9565/30300 (epoch 15.784), train_loss = 1.24177778, grad/param norm = 1.3648e-01, time/batch = 18.1995s	
9566/30300 (epoch 15.785), train_loss = 1.47046119, grad/param norm = 1.6090e-01, time/batch = 19.2178s	
9567/30300 (epoch 15.787), train_loss = 1.16928907, grad/param norm = 1.4124e-01, time/batch = 18.1959s	
9568/30300 (epoch 15.789), train_loss = 1.56848334, grad/param norm = 1.5054e-01, time/batch = 20.5322s	
9569/30300 (epoch 15.790), train_loss = 1.40511119, grad/param norm = 1.5646e-01, time/batch = 19.6346s	
9570/30300 (epoch 15.792), train_loss = 1.16013212, grad/param norm = 1.5774e-01, time/batch = 17.7877s	
9571/30300 (epoch 15.794), train_loss = 1.28076152, grad/param norm = 1.5529e-01, time/batch = 20.4617s	
9572/30300 (epoch 15.795), train_loss = 1.24694515, grad/param norm = 1.3170e-01, time/batch = 18.9741s	
9573/30300 (epoch 15.797), train_loss = 1.51034701, grad/param norm = 1.6975e-01, time/batch = 18.6210s	
9574/30300 (epoch 15.799), train_loss = 1.38249286, grad/param norm = 1.5661e-01, time/batch = 19.4414s	
9575/30300 (epoch 15.800), train_loss = 1.38657537, grad/param norm = 1.5716e-01, time/batch = 19.3828s	
9576/30300 (epoch 15.802), train_loss = 1.55681875, grad/param norm = 1.6307e-01, time/batch = 17.7866s	
9577/30300 (epoch 15.804), train_loss = 1.38513055, grad/param norm = 1.5813e-01, time/batch = 20.2077s	
9578/30300 (epoch 15.805), train_loss = 1.49348658, grad/param norm = 1.6764e-01, time/batch = 20.0303s	
9579/30300 (epoch 15.807), train_loss = 1.32567112, grad/param norm = 1.5902e-01, time/batch = 18.6993s	
9580/30300 (epoch 15.809), train_loss = 1.42809350, grad/param norm = 1.7153e-01, time/batch = 19.1193s	
9581/30300 (epoch 15.810), train_loss = 1.40079105, grad/param norm = 1.4465e-01, time/batch = 17.8850s	
9582/30300 (epoch 15.812), train_loss = 1.23111660, grad/param norm = 1.5581e-01, time/batch = 20.0937s	
9583/30300 (epoch 15.814), train_loss = 1.34640811, grad/param norm = 1.6009e-01, time/batch = 16.7099s	
9584/30300 (epoch 15.815), train_loss = 1.36983533, grad/param norm = 1.5890e-01, time/batch = 19.9511s	
9585/30300 (epoch 15.817), train_loss = 1.42759764, grad/param norm = 1.6541e-01, time/batch = 19.1216s	
9586/30300 (epoch 15.818), train_loss = 1.37011580, grad/param norm = 1.4176e-01, time/batch = 18.2784s	
9587/30300 (epoch 15.820), train_loss = 1.53403824, grad/param norm = 1.6589e-01, time/batch = 17.1108s	
9588/30300 (epoch 15.822), train_loss = 1.52715250, grad/param norm = 1.6280e-01, time/batch = 19.3840s	
9589/30300 (epoch 15.823), train_loss = 1.56872895, grad/param norm = 1.6815e-01, time/batch = 17.8701s	
9590/30300 (epoch 15.825), train_loss = 1.45029877, grad/param norm = 1.5887e-01, time/batch = 18.6107s	
9591/30300 (epoch 15.827), train_loss = 1.22160814, grad/param norm = 1.7301e-01, time/batch = 19.4651s	
9592/30300 (epoch 15.828), train_loss = 1.37953744, grad/param norm = 1.5080e-01, time/batch = 18.1219s	
9593/30300 (epoch 15.830), train_loss = 1.34863980, grad/param norm = 1.5476e-01, time/batch = 19.9407s	
9594/30300 (epoch 15.832), train_loss = 1.27945890, grad/param norm = 1.5510e-01, time/batch = 18.9644s	
9595/30300 (epoch 15.833), train_loss = 1.39857745, grad/param norm = 1.4938e-01, time/batch = 18.1895s	
9596/30300 (epoch 15.835), train_loss = 1.27362206, grad/param norm = 1.5287e-01, time/batch = 19.6141s	
9597/30300 (epoch 15.837), train_loss = 1.17227122, grad/param norm = 1.4081e-01, time/batch = 17.9481s	
9598/30300 (epoch 15.838), train_loss = 1.18160644, grad/param norm = 1.3725e-01, time/batch = 17.8729s	
9599/30300 (epoch 15.840), train_loss = 1.38739576, grad/param norm = 1.3064e-01, time/batch = 18.7860s	
9600/30300 (epoch 15.842), train_loss = 1.21054163, grad/param norm = 1.2462e-01, time/batch = 18.3420s	
9601/30300 (epoch 15.843), train_loss = 1.35678770, grad/param norm = 1.4053e-01, time/batch = 18.8692s	
9602/30300 (epoch 15.845), train_loss = 1.32478842, grad/param norm = 1.3455e-01, time/batch = 17.5438s	
9603/30300 (epoch 15.847), train_loss = 1.35614327, grad/param norm = 1.5691e-01, time/batch = 19.8807s	
9604/30300 (epoch 15.848), train_loss = 1.43359215, grad/param norm = 1.4916e-01, time/batch = 19.6213s	
9605/30300 (epoch 15.850), train_loss = 1.31480767, grad/param norm = 1.5030e-01, time/batch = 17.9475s	
9606/30300 (epoch 15.851), train_loss = 1.40589490, grad/param norm = 1.6870e-01, time/batch = 19.3793s	
9607/30300 (epoch 15.853), train_loss = 1.26162872, grad/param norm = 1.3181e-01, time/batch = 20.1180s	
9608/30300 (epoch 15.855), train_loss = 1.25101939, grad/param norm = 1.2793e-01, time/batch = 16.6094s	
9609/30300 (epoch 15.856), train_loss = 1.29167193, grad/param norm = 1.4426e-01, time/batch = 18.8841s	
9610/30300 (epoch 15.858), train_loss = 1.26313571, grad/param norm = 1.3392e-01, time/batch = 20.2062s	
9611/30300 (epoch 15.860), train_loss = 1.25714751, grad/param norm = 1.5085e-01, time/batch = 18.8686s	
9612/30300 (epoch 15.861), train_loss = 1.48746282, grad/param norm = 1.4507e-01, time/batch = 19.5428s	
9613/30300 (epoch 15.863), train_loss = 1.34378332, grad/param norm = 1.3957e-01, time/batch = 20.0519s	
9614/30300 (epoch 15.865), train_loss = 1.45626324, grad/param norm = 1.6111e-01, time/batch = 18.8790s	
9615/30300 (epoch 15.866), train_loss = 1.38208461, grad/param norm = 1.4366e-01, time/batch = 19.2093s	
9616/30300 (epoch 15.868), train_loss = 1.31228761, grad/param norm = 1.4997e-01, time/batch = 19.3772s	
9617/30300 (epoch 15.870), train_loss = 1.27863518, grad/param norm = 1.4455e-01, time/batch = 18.6325s	
9618/30300 (epoch 15.871), train_loss = 1.27156634, grad/param norm = 1.2998e-01, time/batch = 18.5292s	
9619/30300 (epoch 15.873), train_loss = 1.32940851, grad/param norm = 1.3921e-01, time/batch = 19.6239s	
9620/30300 (epoch 15.875), train_loss = 1.20477792, grad/param norm = 1.3209e-01, time/batch = 17.9470s	
9621/30300 (epoch 15.876), train_loss = 1.21403542, grad/param norm = 1.4436e-01, time/batch = 19.7012s	
9622/30300 (epoch 15.878), train_loss = 1.11849042, grad/param norm = 1.4688e-01, time/batch = 19.3729s	
9623/30300 (epoch 15.880), train_loss = 1.24612295, grad/param norm = 1.6038e-01, time/batch = 19.2960s	
9624/30300 (epoch 15.881), train_loss = 1.52122613, grad/param norm = 1.6193e-01, time/batch = 19.2872s	
9625/30300 (epoch 15.883), train_loss = 1.40046642, grad/param norm = 1.6414e-01, time/batch = 19.5490s	
9626/30300 (epoch 15.884), train_loss = 1.22131685, grad/param norm = 4.3335e-01, time/batch = 20.0382s	
9627/30300 (epoch 15.886), train_loss = 1.37061980, grad/param norm = 1.7779e-01, time/batch = 18.8577s	
9628/30300 (epoch 15.888), train_loss = 1.37416406, grad/param norm = 1.6720e-01, time/batch = 20.1344s	
9629/30300 (epoch 15.889), train_loss = 1.33492534, grad/param norm = 1.4975e-01, time/batch = 19.0615s	
9630/30300 (epoch 15.891), train_loss = 1.31577066, grad/param norm = 1.6274e-01, time/batch = 17.4344s	
9631/30300 (epoch 15.893), train_loss = 1.58401383, grad/param norm = 1.6574e-01, time/batch = 19.0515s	
9632/30300 (epoch 15.894), train_loss = 1.44069851, grad/param norm = 1.5415e-01, time/batch = 18.8842s	
9633/30300 (epoch 15.896), train_loss = 1.15432565, grad/param norm = 1.3838e-01, time/batch = 17.9443s	
9634/30300 (epoch 15.898), train_loss = 1.11455596, grad/param norm = 1.4694e-01, time/batch = 20.0452s	
9635/30300 (epoch 15.899), train_loss = 1.25512994, grad/param norm = 1.4737e-01, time/batch = 19.2919s	
9636/30300 (epoch 15.901), train_loss = 1.33285003, grad/param norm = 1.7186e-01, time/batch = 18.1193s	
9637/30300 (epoch 15.903), train_loss = 1.35784687, grad/param norm = 1.5260e-01, time/batch = 18.4689s	
9638/30300 (epoch 15.904), train_loss = 1.29156013, grad/param norm = 1.5095e-01, time/batch = 18.2098s	
9639/30300 (epoch 15.906), train_loss = 1.46173173, grad/param norm = 1.5423e-01, time/batch = 18.0394s	
9640/30300 (epoch 15.908), train_loss = 1.22690950, grad/param norm = 1.3444e-01, time/batch = 19.1332s	
9641/30300 (epoch 15.909), train_loss = 1.27308624, grad/param norm = 1.6141e-01, time/batch = 19.3848s	
9642/30300 (epoch 15.911), train_loss = 1.29939643, grad/param norm = 1.3649e-01, time/batch = 19.0441s	
9643/30300 (epoch 15.913), train_loss = 1.31515684, grad/param norm = 1.3702e-01, time/batch = 16.2049s	
9644/30300 (epoch 15.914), train_loss = 1.30251832, grad/param norm = 1.5950e-01, time/batch = 20.1358s	
9645/30300 (epoch 15.916), train_loss = 1.32032224, grad/param norm = 1.3254e-01, time/batch = 20.0445s	
9646/30300 (epoch 15.917), train_loss = 1.22080210, grad/param norm = 1.3675e-01, time/batch = 19.0321s	
9647/30300 (epoch 15.919), train_loss = 1.27909237, grad/param norm = 1.4802e-01, time/batch = 16.8918s	
9648/30300 (epoch 15.921), train_loss = 1.31351006, grad/param norm = 1.4339e-01, time/batch = 19.3761s	
9649/30300 (epoch 15.922), train_loss = 1.41558632, grad/param norm = 1.6347e-01, time/batch = 18.1292s	
9650/30300 (epoch 15.924), train_loss = 1.31904830, grad/param norm = 1.5554e-01, time/batch = 19.2323s	
9651/30300 (epoch 15.926), train_loss = 1.31754373, grad/param norm = 1.4870e-01, time/batch = 20.2041s	
9652/30300 (epoch 15.927), train_loss = 1.30971466, grad/param norm = 1.5250e-01, time/batch = 18.3802s	
9653/30300 (epoch 15.929), train_loss = 1.26434481, grad/param norm = 1.4782e-01, time/batch = 20.3728s	
9654/30300 (epoch 15.931), train_loss = 1.44697504, grad/param norm = 1.7125e-01, time/batch = 19.7039s	
9655/30300 (epoch 15.932), train_loss = 1.25266812, grad/param norm = 1.4919e-01, time/batch = 16.6893s	
9656/30300 (epoch 15.934), train_loss = 1.35021073, grad/param norm = 1.5811e-01, time/batch = 20.1300s	
9657/30300 (epoch 15.936), train_loss = 1.28654629, grad/param norm = 1.4860e-01, time/batch = 17.6077s	
9658/30300 (epoch 15.937), train_loss = 1.25558988, grad/param norm = 1.4647e-01, time/batch = 18.4541s	
9659/30300 (epoch 15.939), train_loss = 1.44412025, grad/param norm = 1.5866e-01, time/batch = 19.6969s	
9660/30300 (epoch 15.941), train_loss = 1.30584071, grad/param norm = 1.4869e-01, time/batch = 19.4626s	
9661/30300 (epoch 15.942), train_loss = 1.32627564, grad/param norm = 1.5353e-01, time/batch = 19.0579s	
9662/30300 (epoch 15.944), train_loss = 1.20960728, grad/param norm = 1.3690e-01, time/batch = 19.2848s	
9663/30300 (epoch 15.946), train_loss = 1.47288282, grad/param norm = 1.7997e-01, time/batch = 20.0423s	
9664/30300 (epoch 15.947), train_loss = 1.46614631, grad/param norm = 1.7612e-01, time/batch = 19.0501s	
9665/30300 (epoch 15.949), train_loss = 1.49765797, grad/param norm = 1.6621e-01, time/batch = 18.8029s	
9666/30300 (epoch 15.950), train_loss = 1.45260643, grad/param norm = 1.6082e-01, time/batch = 18.4624s	
9667/30300 (epoch 15.952), train_loss = 1.39797462, grad/param norm = 1.6635e-01, time/batch = 19.3813s	
9668/30300 (epoch 15.954), train_loss = 1.58048064, grad/param norm = 1.5524e-01, time/batch = 16.6139s	
9669/30300 (epoch 15.955), train_loss = 1.27917383, grad/param norm = 1.5515e-01, time/batch = 16.0939s	
9670/30300 (epoch 15.957), train_loss = 1.37072130, grad/param norm = 1.5024e-01, time/batch = 16.4424s	
9671/30300 (epoch 15.959), train_loss = 1.31141303, grad/param norm = 1.6007e-01, time/batch = 16.0742s	
9672/30300 (epoch 15.960), train_loss = 1.32303293, grad/param norm = 1.5628e-01, time/batch = 16.8572s	
9673/30300 (epoch 15.962), train_loss = 1.29512687, grad/param norm = 1.8448e-01, time/batch = 19.1323s	
9674/30300 (epoch 15.964), train_loss = 1.24635608, grad/param norm = 1.5573e-01, time/batch = 19.9581s	
9675/30300 (epoch 15.965), train_loss = 1.23881348, grad/param norm = 1.5338e-01, time/batch = 17.8501s	
9676/30300 (epoch 15.967), train_loss = 1.29861451, grad/param norm = 1.6229e-01, time/batch = 19.6254s	
9677/30300 (epoch 15.969), train_loss = 1.25172028, grad/param norm = 1.6257e-01, time/batch = 19.9701s	
9678/30300 (epoch 15.970), train_loss = 1.28147050, grad/param norm = 1.3947e-01, time/batch = 18.5321s	
9679/30300 (epoch 15.972), train_loss = 1.20118351, grad/param norm = 1.4940e-01, time/batch = 19.2910s	
9680/30300 (epoch 15.974), train_loss = 1.54184404, grad/param norm = 1.6967e-01, time/batch = 19.5512s	
9681/30300 (epoch 15.975), train_loss = 1.53706637, grad/param norm = 1.8038e-01, time/batch = 18.4459s	
9682/30300 (epoch 15.977), train_loss = 1.41317093, grad/param norm = 1.5641e-01, time/batch = 19.2995s	
9683/30300 (epoch 15.979), train_loss = 1.37721506, grad/param norm = 1.5308e-01, time/batch = 19.2890s	
9684/30300 (epoch 15.980), train_loss = 1.41571637, grad/param norm = 1.6292e-01, time/batch = 18.1933s	
9685/30300 (epoch 15.982), train_loss = 1.43356431, grad/param norm = 1.5871e-01, time/batch = 19.2228s	
9686/30300 (epoch 15.983), train_loss = 1.46416443, grad/param norm = 1.5988e-01, time/batch = 19.7918s	
9687/30300 (epoch 15.985), train_loss = 1.35002649, grad/param norm = 1.6419e-01, time/batch = 18.9551s	
9688/30300 (epoch 15.987), train_loss = 1.30481823, grad/param norm = 1.4162e-01, time/batch = 19.6986s	
9689/30300 (epoch 15.988), train_loss = 1.50157248, grad/param norm = 1.5575e-01, time/batch = 19.7889s	
9690/30300 (epoch 15.990), train_loss = 1.14325641, grad/param norm = 1.3136e-01, time/batch = 18.6216s	
9691/30300 (epoch 15.992), train_loss = 1.37444426, grad/param norm = 1.3553e-01, time/batch = 19.9706s	
9692/30300 (epoch 15.993), train_loss = 1.46296614, grad/param norm = 1.7025e-01, time/batch = 19.6165s	
9693/30300 (epoch 15.995), train_loss = 1.32949532, grad/param norm = 1.6375e-01, time/batch = 18.5247s	
9694/30300 (epoch 15.997), train_loss = 1.35883532, grad/param norm = 1.5549e-01, time/batch = 19.7138s	
9695/30300 (epoch 15.998), train_loss = 1.42463508, grad/param norm = 1.6425e-01, time/batch = 20.2982s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
9696/30300 (epoch 16.000), train_loss = 1.28157160, grad/param norm = 1.5686e-01, time/batch = 17.5486s	
9697/30300 (epoch 16.002), train_loss = 1.41327674, grad/param norm = 1.5187e-01, time/batch = 20.1971s	
9698/30300 (epoch 16.003), train_loss = 1.34758678, grad/param norm = 1.6975e-01, time/batch = 19.3067s	
9699/30300 (epoch 16.005), train_loss = 1.31951200, grad/param norm = 1.6476e-01, time/batch = 18.8016s	
9700/30300 (epoch 16.007), train_loss = 1.42509056, grad/param norm = 1.5882e-01, time/batch = 18.4544s	
9701/30300 (epoch 16.008), train_loss = 1.28223106, grad/param norm = 1.7689e-01, time/batch = 19.7041s	
9702/30300 (epoch 16.010), train_loss = 1.20845736, grad/param norm = 1.3742e-01, time/batch = 19.9625s	
9703/30300 (epoch 16.012), train_loss = 1.24459689, grad/param norm = 1.4217e-01, time/batch = 18.3526s	
9704/30300 (epoch 16.013), train_loss = 1.39671107, grad/param norm = 1.6714e-01, time/batch = 19.2076s	
9705/30300 (epoch 16.015), train_loss = 1.28663646, grad/param norm = 1.5175e-01, time/batch = 20.3825s	
9706/30300 (epoch 16.017), train_loss = 1.23923965, grad/param norm = 1.4332e-01, time/batch = 19.0948s	
9707/30300 (epoch 16.018), train_loss = 1.24585691, grad/param norm = 1.4247e-01, time/batch = 19.7089s	
9708/30300 (epoch 16.020), train_loss = 1.45208282, grad/param norm = 1.8380e-01, time/batch = 20.1948s	
9709/30300 (epoch 16.021), train_loss = 1.45270012, grad/param norm = 1.6266e-01, time/batch = 17.8518s	
9710/30300 (epoch 16.023), train_loss = 1.27977200, grad/param norm = 1.3884e-01, time/batch = 20.2054s	
9711/30300 (epoch 16.025), train_loss = 1.25114037, grad/param norm = 1.6295e-01, time/batch = 20.6280s	
9712/30300 (epoch 16.026), train_loss = 1.36515386, grad/param norm = 1.6079e-01, time/batch = 16.5068s	
9713/30300 (epoch 16.028), train_loss = 1.39492861, grad/param norm = 1.4611e-01, time/batch = 19.3085s	
9714/30300 (epoch 16.030), train_loss = 1.26252518, grad/param norm = 1.5089e-01, time/batch = 20.3790s	
9715/30300 (epoch 16.031), train_loss = 1.33467324, grad/param norm = 1.5103e-01, time/batch = 17.3758s	
9716/30300 (epoch 16.033), train_loss = 1.33921800, grad/param norm = 1.6874e-01, time/batch = 19.9543s	
9717/30300 (epoch 16.035), train_loss = 1.42555182, grad/param norm = 1.6258e-01, time/batch = 19.2077s	
9718/30300 (epoch 16.036), train_loss = 1.31521060, grad/param norm = 1.4335e-01, time/batch = 18.7110s	
9719/30300 (epoch 16.038), train_loss = 1.33783785, grad/param norm = 1.4789e-01, time/batch = 19.1309s	
9720/30300 (epoch 16.040), train_loss = 1.05613885, grad/param norm = 1.2942e-01, time/batch = 19.0541s	
9721/30300 (epoch 16.041), train_loss = 1.12035140, grad/param norm = 1.3011e-01, time/batch = 23.3935s	
9722/30300 (epoch 16.043), train_loss = 1.34115891, grad/param norm = 1.5157e-01, time/batch = 27.8097s	
9723/30300 (epoch 16.045), train_loss = 1.29354814, grad/param norm = 1.5314e-01, time/batch = 19.2913s	
9724/30300 (epoch 16.046), train_loss = 1.45184575, grad/param norm = 1.7572e-01, time/batch = 19.2766s	
9725/30300 (epoch 16.048), train_loss = 1.32564483, grad/param norm = 1.5905e-01, time/batch = 17.1161s	
9726/30300 (epoch 16.050), train_loss = 1.32252705, grad/param norm = 1.5528e-01, time/batch = 18.8627s	
9727/30300 (epoch 16.051), train_loss = 1.36388695, grad/param norm = 1.6561e-01, time/batch = 16.6831s	
9728/30300 (epoch 16.053), train_loss = 1.13862351, grad/param norm = 1.6469e-01, time/batch = 19.6088s	
9729/30300 (epoch 16.054), train_loss = 1.27955118, grad/param norm = 1.4153e-01, time/batch = 19.4654s	
9730/30300 (epoch 16.056), train_loss = 1.24257057, grad/param norm = 1.4661e-01, time/batch = 18.2704s	
9731/30300 (epoch 16.058), train_loss = 1.28623772, grad/param norm = 1.5305e-01, time/batch = 19.9321s	
9732/30300 (epoch 16.059), train_loss = 1.22132326, grad/param norm = 1.5796e-01, time/batch = 18.6029s	
9733/30300 (epoch 16.061), train_loss = 1.42336078, grad/param norm = 1.5623e-01, time/batch = 17.9578s	
9734/30300 (epoch 16.063), train_loss = 1.24967973, grad/param norm = 1.5682e-01, time/batch = 18.1295s	
9735/30300 (epoch 16.064), train_loss = 1.35757277, grad/param norm = 1.5013e-01, time/batch = 18.2956s	
9736/30300 (epoch 16.066), train_loss = 1.29910468, grad/param norm = 1.4533e-01, time/batch = 18.9534s	
9737/30300 (epoch 16.068), train_loss = 1.19132452, grad/param norm = 1.4188e-01, time/batch = 19.1080s	
9738/30300 (epoch 16.069), train_loss = 1.38205339, grad/param norm = 1.5100e-01, time/batch = 19.9525s	
9739/30300 (epoch 16.071), train_loss = 1.37002951, grad/param norm = 1.6238e-01, time/batch = 20.2869s	
9740/30300 (epoch 16.073), train_loss = 1.32317779, grad/param norm = 1.6100e-01, time/batch = 19.0404s	
9741/30300 (epoch 16.074), train_loss = 1.35968599, grad/param norm = 1.5091e-01, time/batch = 19.7983s	
9742/30300 (epoch 16.076), train_loss = 1.30683946, grad/param norm = 1.5447e-01, time/batch = 20.0469s	
9743/30300 (epoch 16.078), train_loss = 1.19447112, grad/param norm = 1.4480e-01, time/batch = 18.5984s	
9744/30300 (epoch 16.079), train_loss = 1.23983517, grad/param norm = 1.3266e-01, time/batch = 18.2811s	
9745/30300 (epoch 16.081), train_loss = 1.33709339, grad/param norm = 1.4658e-01, time/batch = 17.1412s	
9746/30300 (epoch 16.083), train_loss = 1.43220977, grad/param norm = 1.7810e-01, time/batch = 18.3776s	
9747/30300 (epoch 16.084), train_loss = 1.20700607, grad/param norm = 1.5032e-01, time/batch = 20.2975s	
9748/30300 (epoch 16.086), train_loss = 1.24566089, grad/param norm = 1.5189e-01, time/batch = 18.9667s	
9749/30300 (epoch 16.087), train_loss = 1.20889901, grad/param norm = 1.3258e-01, time/batch = 19.1201s	
9750/30300 (epoch 16.089), train_loss = 1.28449770, grad/param norm = 1.5924e-01, time/batch = 18.3642s	
9751/30300 (epoch 16.091), train_loss = 1.36460674, grad/param norm = 1.5822e-01, time/batch = 19.4580s	
9752/30300 (epoch 16.092), train_loss = 1.33548844, grad/param norm = 1.4462e-01, time/batch = 18.7081s	
9753/30300 (epoch 16.094), train_loss = 1.49279781, grad/param norm = 1.6615e-01, time/batch = 18.9653s	
9754/30300 (epoch 16.096), train_loss = 1.41960475, grad/param norm = 1.5153e-01, time/batch = 19.1293s	
9755/30300 (epoch 16.097), train_loss = 1.26698645, grad/param norm = 1.4691e-01, time/batch = 19.2193s	
9756/30300 (epoch 16.099), train_loss = 1.44813883, grad/param norm = 1.6183e-01, time/batch = 19.8741s	
9757/30300 (epoch 16.101), train_loss = 1.50094046, grad/param norm = 1.6248e-01, time/batch = 19.3426s	
9758/30300 (epoch 16.102), train_loss = 1.25324270, grad/param norm = 1.6742e-01, time/batch = 17.4423s	
9759/30300 (epoch 16.104), train_loss = 1.28891973, grad/param norm = 1.6092e-01, time/batch = 18.6053s	
9760/30300 (epoch 16.106), train_loss = 1.31137336, grad/param norm = 1.5393e-01, time/batch = 19.7997s	
9761/30300 (epoch 16.107), train_loss = 1.34790762, grad/param norm = 1.4997e-01, time/batch = 18.7956s	
9762/30300 (epoch 16.109), train_loss = 1.43222162, grad/param norm = 1.7948e-01, time/batch = 18.3670s	
9763/30300 (epoch 16.111), train_loss = 1.45837831, grad/param norm = 1.5972e-01, time/batch = 20.6917s	
9764/30300 (epoch 16.112), train_loss = 1.36264302, grad/param norm = 1.4459e-01, time/batch = 19.7199s	
9765/30300 (epoch 16.114), train_loss = 1.33478340, grad/param norm = 1.4757e-01, time/batch = 18.6273s	
9766/30300 (epoch 16.116), train_loss = 1.32716401, grad/param norm = 1.5807e-01, time/batch = 18.6983s	
9767/30300 (epoch 16.117), train_loss = 1.34549613, grad/param norm = 1.3976e-01, time/batch = 19.9638s	
9768/30300 (epoch 16.119), train_loss = 1.24572704, grad/param norm = 1.5607e-01, time/batch = 17.6232s	
9769/30300 (epoch 16.120), train_loss = 1.32710340, grad/param norm = 1.6756e-01, time/batch = 20.3648s	
9770/30300 (epoch 16.122), train_loss = 1.39546573, grad/param norm = 1.6681e-01, time/batch = 20.2810s	
9771/30300 (epoch 16.124), train_loss = 1.50891451, grad/param norm = 1.6895e-01, time/batch = 17.8659s	
9772/30300 (epoch 16.125), train_loss = 1.19159868, grad/param norm = 1.4106e-01, time/batch = 20.4512s	
9773/30300 (epoch 16.127), train_loss = 1.33069703, grad/param norm = 1.6739e-01, time/batch = 19.7106s	
9774/30300 (epoch 16.129), train_loss = 1.47813944, grad/param norm = 1.4670e-01, time/batch = 18.1214s	
9775/30300 (epoch 16.130), train_loss = 1.45967821, grad/param norm = 1.4861e-01, time/batch = 18.2803s	
9776/30300 (epoch 16.132), train_loss = 1.40441343, grad/param norm = 1.5859e-01, time/batch = 19.8690s	
9777/30300 (epoch 16.134), train_loss = 1.24489595, grad/param norm = 1.6011e-01, time/batch = 19.3710s	
9778/30300 (epoch 16.135), train_loss = 1.25176520, grad/param norm = 1.5336e-01, time/batch = 19.1998s	
9779/30300 (epoch 16.137), train_loss = 1.34943686, grad/param norm = 1.5140e-01, time/batch = 18.9635s	
9780/30300 (epoch 16.139), train_loss = 1.28490701, grad/param norm = 1.5344e-01, time/batch = 18.5397s	
9781/30300 (epoch 16.140), train_loss = 1.39161058, grad/param norm = 2.1862e-01, time/batch = 18.2791s	
9782/30300 (epoch 16.142), train_loss = 1.52508939, grad/param norm = 2.0646e-01, time/batch = 20.6150s	
9783/30300 (epoch 16.144), train_loss = 1.37152860, grad/param norm = 1.6662e-01, time/batch = 18.1344s	
9784/30300 (epoch 16.145), train_loss = 1.46619770, grad/param norm = 2.0083e-01, time/batch = 18.2903s	
9785/30300 (epoch 16.147), train_loss = 1.30787911, grad/param norm = 1.5043e-01, time/batch = 19.9556s	
9786/30300 (epoch 16.149), train_loss = 1.52160876, grad/param norm = 1.6297e-01, time/batch = 19.3749s	
9787/30300 (epoch 16.150), train_loss = 1.35535403, grad/param norm = 1.7146e-01, time/batch = 19.7104s	
9788/30300 (epoch 16.152), train_loss = 1.21095632, grad/param norm = 1.6175e-01, time/batch = 19.2084s	
9789/30300 (epoch 16.153), train_loss = 1.32648824, grad/param norm = 1.7088e-01, time/batch = 19.4476s	
9790/30300 (epoch 16.155), train_loss = 1.14472402, grad/param norm = 1.3525e-01, time/batch = 18.4238s	
9791/30300 (epoch 16.157), train_loss = 1.29796124, grad/param norm = 1.5345e-01, time/batch = 20.1955s	
9792/30300 (epoch 16.158), train_loss = 1.34364435, grad/param norm = 1.6822e-01, time/batch = 16.4633s	
9793/30300 (epoch 16.160), train_loss = 1.26382407, grad/param norm = 1.5474e-01, time/batch = 18.3790s	
9794/30300 (epoch 16.162), train_loss = 1.29113666, grad/param norm = 1.5060e-01, time/batch = 15.0424s	
9795/30300 (epoch 16.163), train_loss = 1.26288495, grad/param norm = 1.6364e-01, time/batch = 18.7939s	
9796/30300 (epoch 16.165), train_loss = 1.42181221, grad/param norm = 1.8529e-01, time/batch = 18.4433s	
9797/30300 (epoch 16.167), train_loss = 1.32874413, grad/param norm = 1.5709e-01, time/batch = 19.2712s	
9798/30300 (epoch 16.168), train_loss = 1.36216426, grad/param norm = 1.5632e-01, time/batch = 18.8583s	
9799/30300 (epoch 16.170), train_loss = 1.37373642, grad/param norm = 3.1339e-01, time/batch = 19.4510s	
9800/30300 (epoch 16.172), train_loss = 1.30656801, grad/param norm = 1.6143e-01, time/batch = 18.5510s	
9801/30300 (epoch 16.173), train_loss = 1.36795663, grad/param norm = 1.6582e-01, time/batch = 18.0508s	
9802/30300 (epoch 16.175), train_loss = 1.32615032, grad/param norm = 1.4260e-01, time/batch = 19.3629s	
9803/30300 (epoch 16.177), train_loss = 1.34342601, grad/param norm = 1.6268e-01, time/batch = 18.8735s	
9804/30300 (epoch 16.178), train_loss = 1.09165067, grad/param norm = 1.3493e-01, time/batch = 18.1175s	
9805/30300 (epoch 16.180), train_loss = 1.25941268, grad/param norm = 1.4334e-01, time/batch = 19.5539s	
9806/30300 (epoch 16.182), train_loss = 1.25710380, grad/param norm = 1.5944e-01, time/batch = 19.0467s	
9807/30300 (epoch 16.183), train_loss = 1.24016123, grad/param norm = 1.3987e-01, time/batch = 19.6318s	
9808/30300 (epoch 16.185), train_loss = 1.55711634, grad/param norm = 1.5672e-01, time/batch = 19.5554s	
9809/30300 (epoch 16.186), train_loss = 1.59297754, grad/param norm = 1.7089e-01, time/batch = 18.7825s	
9810/30300 (epoch 16.188), train_loss = 1.39086733, grad/param norm = 1.6059e-01, time/batch = 19.4589s	
9811/30300 (epoch 16.190), train_loss = 1.29647900, grad/param norm = 1.4599e-01, time/batch = 20.2204s	
9812/30300 (epoch 16.191), train_loss = 1.40166406, grad/param norm = 1.6106e-01, time/batch = 18.9535s	
9813/30300 (epoch 16.193), train_loss = 1.22558816, grad/param norm = 1.3899e-01, time/batch = 18.5458s	
9814/30300 (epoch 16.195), train_loss = 1.35886369, grad/param norm = 1.5299e-01, time/batch = 18.0540s	
9815/30300 (epoch 16.196), train_loss = 1.34738196, grad/param norm = 1.3848e-01, time/batch = 18.0520s	
9816/30300 (epoch 16.198), train_loss = 1.12302809, grad/param norm = 1.4126e-01, time/batch = 19.1385s	
9817/30300 (epoch 16.200), train_loss = 1.32352545, grad/param norm = 1.3407e-01, time/batch = 19.2036s	
9818/30300 (epoch 16.201), train_loss = 1.41942179, grad/param norm = 1.7432e-01, time/batch = 19.3680s	
9819/30300 (epoch 16.203), train_loss = 1.32586637, grad/param norm = 1.5299e-01, time/batch = 19.8032s	
9820/30300 (epoch 16.205), train_loss = 1.53182225, grad/param norm = 1.5518e-01, time/batch = 17.7712s	
9821/30300 (epoch 16.206), train_loss = 1.48247049, grad/param norm = 1.6945e-01, time/batch = 18.1220s	
9822/30300 (epoch 16.208), train_loss = 1.45198575, grad/param norm = 1.7595e-01, time/batch = 18.9398s	
9823/30300 (epoch 16.210), train_loss = 1.36051153, grad/param norm = 1.4607e-01, time/batch = 19.7251s	
9824/30300 (epoch 16.211), train_loss = 1.43227763, grad/param norm = 1.4958e-01, time/batch = 18.6462s	
9825/30300 (epoch 16.213), train_loss = 1.26417504, grad/param norm = 1.4214e-01, time/batch = 18.6967s	
9826/30300 (epoch 16.215), train_loss = 1.19360559, grad/param norm = 1.5296e-01, time/batch = 19.4528s	
9827/30300 (epoch 16.216), train_loss = 1.28470959, grad/param norm = 1.5391e-01, time/batch = 19.0511s	
9828/30300 (epoch 16.218), train_loss = 1.21467488, grad/param norm = 1.3205e-01, time/batch = 18.3604s	
9829/30300 (epoch 16.219), train_loss = 1.12408817, grad/param norm = 1.2550e-01, time/batch = 19.2086s	
9830/30300 (epoch 16.221), train_loss = 1.16958950, grad/param norm = 1.4158e-01, time/batch = 19.9682s	
9831/30300 (epoch 16.223), train_loss = 1.33213148, grad/param norm = 1.4127e-01, time/batch = 18.5370s	
9832/30300 (epoch 16.224), train_loss = 1.13797758, grad/param norm = 1.4572e-01, time/batch = 19.4650s	
9833/30300 (epoch 16.226), train_loss = 1.42580347, grad/param norm = 1.7625e-01, time/batch = 19.8060s	
9834/30300 (epoch 16.228), train_loss = 1.41577990, grad/param norm = 1.4921e-01, time/batch = 18.5419s	
9835/30300 (epoch 16.229), train_loss = 1.24982068, grad/param norm = 1.5479e-01, time/batch = 19.0286s	
9836/30300 (epoch 16.231), train_loss = 1.36420677, grad/param norm = 1.4490e-01, time/batch = 18.6107s	
9837/30300 (epoch 16.233), train_loss = 1.28367085, grad/param norm = 1.3765e-01, time/batch = 19.0412s	
9838/30300 (epoch 16.234), train_loss = 1.38190130, grad/param norm = 1.7227e-01, time/batch = 18.9740s	
9839/30300 (epoch 16.236), train_loss = 1.28131613, grad/param norm = 1.3299e-01, time/batch = 19.5400s	
9840/30300 (epoch 16.238), train_loss = 1.37786811, grad/param norm = 1.7176e-01, time/batch = 19.1301s	
9841/30300 (epoch 16.239), train_loss = 1.34763477, grad/param norm = 1.5125e-01, time/batch = 19.0473s	
9842/30300 (epoch 16.241), train_loss = 1.36129595, grad/param norm = 1.6347e-01, time/batch = 20.4725s	
9843/30300 (epoch 16.243), train_loss = 1.38318160, grad/param norm = 1.4392e-01, time/batch = 19.1320s	
9844/30300 (epoch 16.244), train_loss = 1.57881518, grad/param norm = 1.6602e-01, time/batch = 18.8875s	
9845/30300 (epoch 16.246), train_loss = 1.30215250, grad/param norm = 1.4583e-01, time/batch = 18.9560s	
9846/30300 (epoch 16.248), train_loss = 1.27988168, grad/param norm = 1.4353e-01, time/batch = 18.1113s	
9847/30300 (epoch 16.249), train_loss = 1.22893267, grad/param norm = 1.4762e-01, time/batch = 18.4611s	
9848/30300 (epoch 16.251), train_loss = 1.22134527, grad/param norm = 1.5331e-01, time/batch = 18.5606s	
9849/30300 (epoch 16.252), train_loss = 1.44515955, grad/param norm = 1.5502e-01, time/batch = 19.4618s	
9850/30300 (epoch 16.254), train_loss = 1.44353917, grad/param norm = 1.7182e-01, time/batch = 18.7024s	
9851/30300 (epoch 16.256), train_loss = 1.36333061, grad/param norm = 1.5363e-01, time/batch = 19.8799s	
9852/30300 (epoch 16.257), train_loss = 1.38772942, grad/param norm = 1.6090e-01, time/batch = 19.7115s	
9853/30300 (epoch 16.259), train_loss = 1.31754561, grad/param norm = 1.5485e-01, time/batch = 19.1916s	
9854/30300 (epoch 16.261), train_loss = 1.44194667, grad/param norm = 1.5183e-01, time/batch = 19.0540s	
9855/30300 (epoch 16.262), train_loss = 1.31499665, grad/param norm = 1.5038e-01, time/batch = 19.5460s	
9856/30300 (epoch 16.264), train_loss = 1.31403324, grad/param norm = 1.4566e-01, time/batch = 18.0176s	
9857/30300 (epoch 16.266), train_loss = 1.26089231, grad/param norm = 1.4215e-01, time/batch = 19.7186s	
9858/30300 (epoch 16.267), train_loss = 1.50289408, grad/param norm = 1.6598e-01, time/batch = 19.8088s	
9859/30300 (epoch 16.269), train_loss = 1.32672557, grad/param norm = 1.5388e-01, time/batch = 17.9494s	
9860/30300 (epoch 16.271), train_loss = 1.34413678, grad/param norm = 1.5763e-01, time/batch = 19.6146s	
9861/30300 (epoch 16.272), train_loss = 1.34989859, grad/param norm = 1.5214e-01, time/batch = 17.4491s	
9862/30300 (epoch 16.274), train_loss = 1.45426740, grad/param norm = 1.5246e-01, time/batch = 18.4542s	
9863/30300 (epoch 16.276), train_loss = 1.39628995, grad/param norm = 1.6560e-01, time/batch = 19.2982s	
9864/30300 (epoch 16.277), train_loss = 1.23132058, grad/param norm = 1.4649e-01, time/batch = 19.1240s	
9865/30300 (epoch 16.279), train_loss = 1.37099109, grad/param norm = 1.5820e-01, time/batch = 18.7099s	
9866/30300 (epoch 16.281), train_loss = 1.41518470, grad/param norm = 1.6082e-01, time/batch = 17.1902s	
9867/30300 (epoch 16.282), train_loss = 1.32718867, grad/param norm = 1.4574e-01, time/batch = 19.8646s	
9868/30300 (epoch 16.284), train_loss = 1.50171006, grad/param norm = 1.8093e-01, time/batch = 18.9768s	
9869/30300 (epoch 16.285), train_loss = 1.34047750, grad/param norm = 1.4300e-01, time/batch = 18.9541s	
9870/30300 (epoch 16.287), train_loss = 1.33310777, grad/param norm = 1.5901e-01, time/batch = 19.4568s	
9871/30300 (epoch 16.289), train_loss = 1.37731072, grad/param norm = 1.4818e-01, time/batch = 19.5484s	
9872/30300 (epoch 16.290), train_loss = 1.07305671, grad/param norm = 1.3399e-01, time/batch = 18.2038s	
9873/30300 (epoch 16.292), train_loss = 1.20082364, grad/param norm = 1.2859e-01, time/batch = 19.7153s	
9874/30300 (epoch 16.294), train_loss = 1.47887366, grad/param norm = 1.7064e-01, time/batch = 17.3628s	
9875/30300 (epoch 16.295), train_loss = 1.31154297, grad/param norm = 1.4658e-01, time/batch = 18.7031s	
9876/30300 (epoch 16.297), train_loss = 1.23971732, grad/param norm = 1.3397e-01, time/batch = 18.8775s	
9877/30300 (epoch 16.299), train_loss = 1.29933578, grad/param norm = 1.5423e-01, time/batch = 18.9520s	
9878/30300 (epoch 16.300), train_loss = 1.31127270, grad/param norm = 1.5504e-01, time/batch = 18.1143s	
9879/30300 (epoch 16.302), train_loss = 1.29996943, grad/param norm = 1.4113e-01, time/batch = 19.7910s	
9880/30300 (epoch 16.304), train_loss = 1.23136378, grad/param norm = 1.3876e-01, time/batch = 20.2158s	
9881/30300 (epoch 16.305), train_loss = 1.27821003, grad/param norm = 1.4741e-01, time/batch = 18.4572s	
9882/30300 (epoch 16.307), train_loss = 1.34615086, grad/param norm = 1.3833e-01, time/batch = 19.5385s	
9883/30300 (epoch 16.309), train_loss = 1.38893196, grad/param norm = 1.4655e-01, time/batch = 19.7940s	
9884/30300 (epoch 16.310), train_loss = 1.30354042, grad/param norm = 1.5765e-01, time/batch = 17.1338s	
9885/30300 (epoch 16.312), train_loss = 1.45994642, grad/param norm = 1.5180e-01, time/batch = 18.6937s	
9886/30300 (epoch 16.314), train_loss = 1.35110839, grad/param norm = 1.4937e-01, time/batch = 17.7046s	
9887/30300 (epoch 16.315), train_loss = 1.35922343, grad/param norm = 1.5216e-01, time/batch = 18.2024s	
9888/30300 (epoch 16.317), train_loss = 1.41004280, grad/param norm = 1.4931e-01, time/batch = 17.7087s	
9889/30300 (epoch 16.318), train_loss = 1.47964622, grad/param norm = 1.7467e-01, time/batch = 18.8762s	
9890/30300 (epoch 16.320), train_loss = 1.41933337, grad/param norm = 1.5205e-01, time/batch = 19.0458s	
9891/30300 (epoch 16.322), train_loss = 1.23956275, grad/param norm = 1.4867e-01, time/batch = 18.6296s	
9892/30300 (epoch 16.323), train_loss = 1.43746008, grad/param norm = 1.5591e-01, time/batch = 20.3004s	
9893/30300 (epoch 16.325), train_loss = 1.29797596, grad/param norm = 1.3669e-01, time/batch = 18.6249s	
9894/30300 (epoch 16.327), train_loss = 1.31188113, grad/param norm = 1.3764e-01, time/batch = 17.7162s	
9895/30300 (epoch 16.328), train_loss = 1.31268718, grad/param norm = 1.3813e-01, time/batch = 18.3636s	
9896/30300 (epoch 16.330), train_loss = 1.37857229, grad/param norm = 1.3646e-01, time/batch = 19.9731s	
9897/30300 (epoch 16.332), train_loss = 1.41372110, grad/param norm = 1.6389e-01, time/batch = 18.2176s	
9898/30300 (epoch 16.333), train_loss = 1.31774345, grad/param norm = 1.6831e-01, time/batch = 19.6442s	
9899/30300 (epoch 16.335), train_loss = 1.19582252, grad/param norm = 1.4380e-01, time/batch = 18.8931s	
9900/30300 (epoch 16.337), train_loss = 1.48760891, grad/param norm = 1.5724e-01, time/batch = 18.4626s	
9901/30300 (epoch 16.338), train_loss = 1.24102916, grad/param norm = 1.3607e-01, time/batch = 18.7100s	
9902/30300 (epoch 16.340), train_loss = 1.19697734, grad/param norm = 1.3353e-01, time/batch = 20.0498s	
9903/30300 (epoch 16.342), train_loss = 1.41723715, grad/param norm = 1.5104e-01, time/batch = 18.8007s	
9904/30300 (epoch 16.343), train_loss = 1.37091717, grad/param norm = 1.4766e-01, time/batch = 19.7856s	
9905/30300 (epoch 16.345), train_loss = 1.36255229, grad/param norm = 1.5758e-01, time/batch = 18.4340s	
9906/30300 (epoch 16.347), train_loss = 1.15001575, grad/param norm = 1.3126e-01, time/batch = 18.8814s	
9907/30300 (epoch 16.348), train_loss = 1.21228744, grad/param norm = 1.4830e-01, time/batch = 19.3734s	
9908/30300 (epoch 16.350), train_loss = 1.30291015, grad/param norm = 1.4154e-01, time/batch = 18.7176s	
9909/30300 (epoch 16.351), train_loss = 1.31056461, grad/param norm = 1.4897e-01, time/batch = 19.0343s	
9910/30300 (epoch 16.353), train_loss = 1.13985863, grad/param norm = 1.4633e-01, time/batch = 32.3712s	
9911/30300 (epoch 16.355), train_loss = 1.27017288, grad/param norm = 1.4396e-01, time/batch = 19.7936s	
9912/30300 (epoch 16.356), train_loss = 1.40499398, grad/param norm = 1.5502e-01, time/batch = 17.7063s	
9913/30300 (epoch 16.358), train_loss = 1.54397188, grad/param norm = 1.4537e-01, time/batch = 19.1173s	
9914/30300 (epoch 16.360), train_loss = 1.26209463, grad/param norm = 1.4722e-01, time/batch = 19.1123s	
9915/30300 (epoch 16.361), train_loss = 1.35030448, grad/param norm = 1.5817e-01, time/batch = 18.5365s	
9916/30300 (epoch 16.363), train_loss = 1.41126184, grad/param norm = 1.5143e-01, time/batch = 19.8561s	
9917/30300 (epoch 16.365), train_loss = 1.23408587, grad/param norm = 1.5547e-01, time/batch = 19.3780s	
9918/30300 (epoch 16.366), train_loss = 1.25729383, grad/param norm = 1.4550e-01, time/batch = 19.1990s	
9919/30300 (epoch 16.368), train_loss = 1.13894476, grad/param norm = 1.4700e-01, time/batch = 19.0480s	
9920/30300 (epoch 16.370), train_loss = 1.20406695, grad/param norm = 1.5078e-01, time/batch = 19.6394s	
9921/30300 (epoch 16.371), train_loss = 1.38993473, grad/param norm = 1.4882e-01, time/batch = 18.0359s	
9922/30300 (epoch 16.373), train_loss = 1.21736959, grad/param norm = 1.2419e-01, time/batch = 18.2187s	
9923/30300 (epoch 16.375), train_loss = 1.22345698, grad/param norm = 1.2837e-01, time/batch = 18.5514s	
9924/30300 (epoch 16.376), train_loss = 1.23290106, grad/param norm = 1.3715e-01, time/batch = 19.1369s	
9925/30300 (epoch 16.378), train_loss = 1.24526802, grad/param norm = 1.5588e-01, time/batch = 18.5307s	
9926/30300 (epoch 16.380), train_loss = 1.49673162, grad/param norm = 1.5240e-01, time/batch = 19.3892s	
9927/30300 (epoch 16.381), train_loss = 1.16801611, grad/param norm = 1.3278e-01, time/batch = 20.4567s	
9928/30300 (epoch 16.383), train_loss = 1.26330955, grad/param norm = 1.5103e-01, time/batch = 17.3910s	
9929/30300 (epoch 16.384), train_loss = 1.39966845, grad/param norm = 1.4998e-01, time/batch = 19.6174s	
9930/30300 (epoch 16.386), train_loss = 1.19935949, grad/param norm = 1.4762e-01, time/batch = 19.6486s	
9931/30300 (epoch 16.388), train_loss = 1.15855455, grad/param norm = 1.3007e-01, time/batch = 17.5562s	
9932/30300 (epoch 16.389), train_loss = 1.30718519, grad/param norm = 1.6662e-01, time/batch = 20.0406s	
9933/30300 (epoch 16.391), train_loss = 1.36408733, grad/param norm = 1.4570e-01, time/batch = 20.2051s	
9934/30300 (epoch 16.393), train_loss = 1.14867357, grad/param norm = 1.2963e-01, time/batch = 18.1289s	
9935/30300 (epoch 16.394), train_loss = 1.35829485, grad/param norm = 1.4456e-01, time/batch = 18.9385s	
9936/30300 (epoch 16.396), train_loss = 1.46869862, grad/param norm = 1.4437e-01, time/batch = 19.6206s	
9937/30300 (epoch 16.398), train_loss = 1.28146675, grad/param norm = 1.2947e-01, time/batch = 17.9477s	
9938/30300 (epoch 16.399), train_loss = 1.27983955, grad/param norm = 1.5175e-01, time/batch = 19.3850s	
9939/30300 (epoch 16.401), train_loss = 1.34730363, grad/param norm = 1.4459e-01, time/batch = 16.3638s	
9940/30300 (epoch 16.403), train_loss = 1.26861487, grad/param norm = 1.4827e-01, time/batch = 18.6161s	
9941/30300 (epoch 16.404), train_loss = 1.21626031, grad/param norm = 1.5797e-01, time/batch = 18.5306s	
9942/30300 (epoch 16.406), train_loss = 1.31972968, grad/param norm = 1.4910e-01, time/batch = 18.7997s	
9943/30300 (epoch 16.408), train_loss = 1.16489121, grad/param norm = 1.3607e-01, time/batch = 20.2854s	
9944/30300 (epoch 16.409), train_loss = 1.16210295, grad/param norm = 1.3809e-01, time/batch = 18.6149s	
9945/30300 (epoch 16.411), train_loss = 1.17814192, grad/param norm = 1.3319e-01, time/batch = 19.0349s	
9946/30300 (epoch 16.413), train_loss = 1.12454963, grad/param norm = 1.4782e-01, time/batch = 18.2032s	
9947/30300 (epoch 16.414), train_loss = 1.44983602, grad/param norm = 1.5788e-01, time/batch = 17.0387s	
9948/30300 (epoch 16.416), train_loss = 1.26532794, grad/param norm = 1.4848e-01, time/batch = 20.0447s	
9949/30300 (epoch 16.417), train_loss = 1.22771539, grad/param norm = 1.5701e-01, time/batch = 19.3787s	
9950/30300 (epoch 16.419), train_loss = 1.18891378, grad/param norm = 1.4027e-01, time/batch = 18.6303s	
9951/30300 (epoch 16.421), train_loss = 1.25415281, grad/param norm = 1.3896e-01, time/batch = 19.0534s	
9952/30300 (epoch 16.422), train_loss = 1.27554138, grad/param norm = 1.4827e-01, time/batch = 19.7087s	
9953/30300 (epoch 16.424), train_loss = 1.30250499, grad/param norm = 1.4254e-01, time/batch = 18.7964s	
9954/30300 (epoch 16.426), train_loss = 1.21089797, grad/param norm = 1.4627e-01, time/batch = 19.1307s	
9955/30300 (epoch 16.427), train_loss = 1.27044308, grad/param norm = 1.5623e-01, time/batch = 19.3058s	
9956/30300 (epoch 16.429), train_loss = 1.28658981, grad/param norm = 1.4259e-01, time/batch = 18.2927s	
9957/30300 (epoch 16.431), train_loss = 1.36073620, grad/param norm = 1.4612e-01, time/batch = 19.7825s	
9958/30300 (epoch 16.432), train_loss = 1.27027922, grad/param norm = 1.3918e-01, time/batch = 19.0396s	
9959/30300 (epoch 16.434), train_loss = 1.15510933, grad/param norm = 1.4941e-01, time/batch = 18.7576s	
9960/30300 (epoch 16.436), train_loss = 1.43923232, grad/param norm = 1.6277e-01, time/batch = 18.2624s	
9961/30300 (epoch 16.437), train_loss = 1.17311441, grad/param norm = 1.4420e-01, time/batch = 19.6199s	
9962/30300 (epoch 16.439), train_loss = 1.22597738, grad/param norm = 1.4873e-01, time/batch = 19.8805s	
9963/30300 (epoch 16.441), train_loss = 1.25142267, grad/param norm = 1.3864e-01, time/batch = 19.0412s	
9964/30300 (epoch 16.442), train_loss = 1.18335769, grad/param norm = 1.3642e-01, time/batch = 19.0432s	
9965/30300 (epoch 16.444), train_loss = 1.08122678, grad/param norm = 1.4303e-01, time/batch = 20.4530s	
9966/30300 (epoch 16.446), train_loss = 1.26043959, grad/param norm = 1.4414e-01, time/batch = 18.7091s	
9967/30300 (epoch 16.447), train_loss = 1.29313295, grad/param norm = 1.5474e-01, time/batch = 20.1194s	
9968/30300 (epoch 16.449), train_loss = 1.20907909, grad/param norm = 1.4185e-01, time/batch = 19.0572s	
9969/30300 (epoch 16.450), train_loss = 1.38124997, grad/param norm = 1.4649e-01, time/batch = 18.1182s	
9970/30300 (epoch 16.452), train_loss = 1.36862761, grad/param norm = 1.3707e-01, time/batch = 19.8882s	
9971/30300 (epoch 16.454), train_loss = 1.33469997, grad/param norm = 1.3171e-01, time/batch = 19.6239s	
9972/30300 (epoch 16.455), train_loss = 1.34738066, grad/param norm = 1.5535e-01, time/batch = 18.1199s	
9973/30300 (epoch 16.457), train_loss = 1.31111732, grad/param norm = 1.4032e-01, time/batch = 19.6046s	
9974/30300 (epoch 16.459), train_loss = 1.38009763, grad/param norm = 1.5294e-01, time/batch = 19.7026s	
9975/30300 (epoch 16.460), train_loss = 1.33158205, grad/param norm = 1.4765e-01, time/batch = 17.2680s	
9976/30300 (epoch 16.462), train_loss = 1.39794132, grad/param norm = 1.5130e-01, time/batch = 20.4569s	
9977/30300 (epoch 16.464), train_loss = 1.15328725, grad/param norm = 1.5721e-01, time/batch = 17.5393s	
9978/30300 (epoch 16.465), train_loss = 1.12174682, grad/param norm = 1.3666e-01, time/batch = 18.5225s	
9979/30300 (epoch 16.467), train_loss = 1.08162305, grad/param norm = 1.2697e-01, time/batch = 19.5355s	
9980/30300 (epoch 16.469), train_loss = 1.18883233, grad/param norm = 1.2751e-01, time/batch = 18.9670s	
9981/30300 (epoch 16.470), train_loss = 1.25954028, grad/param norm = 1.4250e-01, time/batch = 19.3741s	
9982/30300 (epoch 16.472), train_loss = 1.23839958, grad/param norm = 1.3327e-01, time/batch = 19.3015s	
9983/30300 (epoch 16.474), train_loss = 1.28666298, grad/param norm = 1.5383e-01, time/batch = 19.5314s	
9984/30300 (epoch 16.475), train_loss = 1.20015068, grad/param norm = 1.4035e-01, time/batch = 19.0359s	
9985/30300 (epoch 16.477), train_loss = 1.29052466, grad/param norm = 1.6001e-01, time/batch = 19.0545s	
9986/30300 (epoch 16.479), train_loss = 1.28525206, grad/param norm = 1.4564e-01, time/batch = 18.4634s	
9987/30300 (epoch 16.480), train_loss = 1.33104256, grad/param norm = 1.3930e-01, time/batch = 18.7118s	
9988/30300 (epoch 16.482), train_loss = 1.33346213, grad/param norm = 1.3136e-01, time/batch = 19.0332s	
9989/30300 (epoch 16.483), train_loss = 1.24902707, grad/param norm = 1.4965e-01, time/batch = 14.7246s	
9990/30300 (epoch 16.485), train_loss = 1.28819970, grad/param norm = 1.4675e-01, time/batch = 14.8055s	
9991/30300 (epoch 16.487), train_loss = 1.37428184, grad/param norm = 1.4975e-01, time/batch = 19.0373s	
9992/30300 (epoch 16.488), train_loss = 1.37537196, grad/param norm = 1.4173e-01, time/batch = 17.2060s	
9993/30300 (epoch 16.490), train_loss = 1.18470163, grad/param norm = 1.4401e-01, time/batch = 19.2103s	
9994/30300 (epoch 16.492), train_loss = 1.27207053, grad/param norm = 1.4794e-01, time/batch = 18.8694s	
9995/30300 (epoch 16.493), train_loss = 1.24921454, grad/param norm = 1.3966e-01, time/batch = 19.0279s	
9996/30300 (epoch 16.495), train_loss = 1.21246406, grad/param norm = 1.2851e-01, time/batch = 18.5237s	
9997/30300 (epoch 16.497), train_loss = 1.32344765, grad/param norm = 1.3816e-01, time/batch = 18.0383s	
9998/30300 (epoch 16.498), train_loss = 1.33091326, grad/param norm = 1.4078e-01, time/batch = 17.9414s	
9999/30300 (epoch 16.500), train_loss = 1.34776705, grad/param norm = 1.7116e-01, time/batch = 19.2114s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch16.50_1.7613.t7	
10000/30300 (epoch 16.502), train_loss = 1.26085072, grad/param norm = 1.4845e-01, time/batch = 18.7137s	
10001/30300 (epoch 16.503), train_loss = 1.70611512, grad/param norm = 1.7922e-01, time/batch = 18.2042s	
10002/30300 (epoch 16.505), train_loss = 1.24945168, grad/param norm = 1.5568e-01, time/batch = 18.4604s	
10003/30300 (epoch 16.507), train_loss = 1.24409566, grad/param norm = 1.4964e-01, time/batch = 18.1831s	
10004/30300 (epoch 16.508), train_loss = 1.25753054, grad/param norm = 1.6462e-01, time/batch = 19.5257s	
10005/30300 (epoch 16.510), train_loss = 1.39993151, grad/param norm = 1.6726e-01, time/batch = 19.7122s	
10006/30300 (epoch 16.512), train_loss = 1.22039965, grad/param norm = 1.3819e-01, time/batch = 18.2753s	
10007/30300 (epoch 16.513), train_loss = 1.33649644, grad/param norm = 1.4532e-01, time/batch = 19.4414s	
10008/30300 (epoch 16.515), train_loss = 1.29759027, grad/param norm = 1.5007e-01, time/batch = 18.5350s	
10009/30300 (epoch 16.517), train_loss = 1.12132012, grad/param norm = 1.3263e-01, time/batch = 18.4497s	
10010/30300 (epoch 16.518), train_loss = 1.37956860, grad/param norm = 1.5769e-01, time/batch = 18.6848s	
10011/30300 (epoch 16.520), train_loss = 1.39760196, grad/param norm = 1.5675e-01, time/batch = 19.6332s	
10012/30300 (epoch 16.521), train_loss = 1.18756269, grad/param norm = 1.6395e-01, time/batch = 19.3788s	
10013/30300 (epoch 16.523), train_loss = 1.46798571, grad/param norm = 1.9858e-01, time/batch = 18.1835s	
10014/30300 (epoch 16.525), train_loss = 1.22017379, grad/param norm = 1.4246e-01, time/batch = 19.2088s	
10015/30300 (epoch 16.526), train_loss = 1.26843142, grad/param norm = 1.4977e-01, time/batch = 19.9466s	
10016/30300 (epoch 16.528), train_loss = 1.15600402, grad/param norm = 1.3446e-01, time/batch = 17.3916s	
10017/30300 (epoch 16.530), train_loss = 1.16806338, grad/param norm = 1.4721e-01, time/batch = 19.0502s	
10018/30300 (epoch 16.531), train_loss = 1.35823076, grad/param norm = 1.6053e-01, time/batch = 19.9625s	
10019/30300 (epoch 16.533), train_loss = 1.33009840, grad/param norm = 1.5480e-01, time/batch = 17.2790s	
10020/30300 (epoch 16.535), train_loss = 1.14708469, grad/param norm = 1.2810e-01, time/batch = 14.8757s	
10021/30300 (epoch 16.536), train_loss = 1.31186751, grad/param norm = 1.4684e-01, time/batch = 14.8776s	
10022/30300 (epoch 16.538), train_loss = 1.12803243, grad/param norm = 1.4719e-01, time/batch = 15.9232s	
10023/30300 (epoch 16.540), train_loss = 1.18683303, grad/param norm = 1.4932e-01, time/batch = 18.5227s	
10024/30300 (epoch 16.541), train_loss = 1.29199431, grad/param norm = 1.6879e-01, time/batch = 18.7893s	
10025/30300 (epoch 16.543), train_loss = 1.29284821, grad/param norm = 1.5032e-01, time/batch = 19.9626s	
10026/30300 (epoch 16.545), train_loss = 1.27630794, grad/param norm = 1.5656e-01, time/batch = 19.1254s	
10027/30300 (epoch 16.546), train_loss = 1.53162503, grad/param norm = 1.4712e-01, time/batch = 18.7150s	
10028/30300 (epoch 16.548), train_loss = 1.22140128, grad/param norm = 1.4338e-01, time/batch = 20.5397s	
10029/30300 (epoch 16.550), train_loss = 1.40371885, grad/param norm = 1.7733e-01, time/batch = 17.3732s	
10030/30300 (epoch 16.551), train_loss = 1.21931455, grad/param norm = 1.4423e-01, time/batch = 17.4500s	
10031/30300 (epoch 16.553), train_loss = 1.25395258, grad/param norm = 1.4787e-01, time/batch = 19.8674s	
10032/30300 (epoch 16.554), train_loss = 1.32362304, grad/param norm = 1.5354e-01, time/batch = 18.7939s	
10033/30300 (epoch 16.556), train_loss = 1.35710138, grad/param norm = 1.5375e-01, time/batch = 19.6247s	
10034/30300 (epoch 16.558), train_loss = 1.42609286, grad/param norm = 1.5693e-01, time/batch = 18.7953s	
10035/30300 (epoch 16.559), train_loss = 1.36594451, grad/param norm = 1.7191e-01, time/batch = 19.6970s	
10036/30300 (epoch 16.561), train_loss = 1.15019892, grad/param norm = 1.5015e-01, time/batch = 19.6043s	
10037/30300 (epoch 16.563), train_loss = 1.19284881, grad/param norm = 1.4573e-01, time/batch = 18.8861s	
10038/30300 (epoch 16.564), train_loss = 1.23161242, grad/param norm = 1.4336e-01, time/batch = 19.4745s	
10039/30300 (epoch 16.566), train_loss = 1.31789527, grad/param norm = 1.4312e-01, time/batch = 18.2899s	
10040/30300 (epoch 16.568), train_loss = 1.09527341, grad/param norm = 1.3809e-01, time/batch = 18.9349s	
10041/30300 (epoch 16.569), train_loss = 1.29746509, grad/param norm = 1.4100e-01, time/batch = 19.7985s	
10042/30300 (epoch 16.571), train_loss = 1.31916440, grad/param norm = 1.5544e-01, time/batch = 16.8708s	
10043/30300 (epoch 16.573), train_loss = 1.33532298, grad/param norm = 1.5000e-01, time/batch = 19.2886s	
10044/30300 (epoch 16.574), train_loss = 1.36526293, grad/param norm = 1.4459e-01, time/batch = 18.1356s	
10045/30300 (epoch 16.576), train_loss = 1.27155921, grad/param norm = 1.3597e-01, time/batch = 17.2794s	
10046/30300 (epoch 16.578), train_loss = 1.14822553, grad/param norm = 1.4127e-01, time/batch = 20.2838s	
10047/30300 (epoch 16.579), train_loss = 1.31752489, grad/param norm = 1.6695e-01, time/batch = 20.2862s	
10048/30300 (epoch 16.581), train_loss = 1.36955040, grad/param norm = 1.4083e-01, time/batch = 18.8806s	
10049/30300 (epoch 16.583), train_loss = 1.48338680, grad/param norm = 1.6979e-01, time/batch = 19.2073s	
10050/30300 (epoch 16.584), train_loss = 1.37536770, grad/param norm = 1.5100e-01, time/batch = 20.2117s	
10051/30300 (epoch 16.586), train_loss = 1.29199824, grad/param norm = 1.4855e-01, time/batch = 17.6098s	
10052/30300 (epoch 16.587), train_loss = 1.28867467, grad/param norm = 1.5134e-01, time/batch = 19.3625s	
10053/30300 (epoch 16.589), train_loss = 1.16723627, grad/param norm = 1.3497e-01, time/batch = 19.8021s	
10054/30300 (epoch 16.591), train_loss = 1.34047698, grad/param norm = 1.4327e-01, time/batch = 19.5342s	
10055/30300 (epoch 16.592), train_loss = 1.28175380, grad/param norm = 1.2670e-01, time/batch = 19.2076s	
10056/30300 (epoch 16.594), train_loss = 1.31624581, grad/param norm = 1.5003e-01, time/batch = 19.6329s	
10057/30300 (epoch 16.596), train_loss = 1.19440195, grad/param norm = 1.3045e-01, time/batch = 19.1828s	
10058/30300 (epoch 16.597), train_loss = 1.23703130, grad/param norm = 1.6968e-01, time/batch = 19.5162s	
10059/30300 (epoch 16.599), train_loss = 1.11605961, grad/param norm = 1.4356e-01, time/batch = 20.0335s	
10060/30300 (epoch 16.601), train_loss = 1.35956529, grad/param norm = 1.5920e-01, time/batch = 18.9540s	
10061/30300 (epoch 16.602), train_loss = 1.28543378, grad/param norm = 1.3718e-01, time/batch = 18.5270s	
10062/30300 (epoch 16.604), train_loss = 1.18901053, grad/param norm = 1.3164e-01, time/batch = 19.4598s	
10063/30300 (epoch 16.606), train_loss = 1.29331217, grad/param norm = 1.5882e-01, time/batch = 19.4380s	
10064/30300 (epoch 16.607), train_loss = 1.37155673, grad/param norm = 1.7978e-01, time/batch = 18.7790s	
10065/30300 (epoch 16.609), train_loss = 1.49921100, grad/param norm = 1.7668e-01, time/batch = 18.9602s	
10066/30300 (epoch 16.611), train_loss = 1.22181972, grad/param norm = 1.4819e-01, time/batch = 18.2732s	
10067/30300 (epoch 16.612), train_loss = 1.19057234, grad/param norm = 1.4310e-01, time/batch = 17.6983s	
10068/30300 (epoch 16.614), train_loss = 1.20606484, grad/param norm = 1.3129e-01, time/batch = 19.7175s	
10069/30300 (epoch 16.616), train_loss = 1.32874271, grad/param norm = 1.7765e-01, time/batch = 19.1281s	
10070/30300 (epoch 16.617), train_loss = 1.26706932, grad/param norm = 1.4484e-01, time/batch = 18.5320s	
10071/30300 (epoch 16.619), train_loss = 1.10492468, grad/param norm = 1.4051e-01, time/batch = 20.2179s	
10072/30300 (epoch 16.620), train_loss = 1.29117545, grad/param norm = 1.5528e-01, time/batch = 19.4641s	
10073/30300 (epoch 16.622), train_loss = 1.27622639, grad/param norm = 1.7284e-01, time/batch = 17.5308s	
10074/30300 (epoch 16.624), train_loss = 1.20394266, grad/param norm = 1.5446e-01, time/batch = 19.3867s	
10075/30300 (epoch 16.625), train_loss = 1.25935898, grad/param norm = 1.5932e-01, time/batch = 19.0449s	
10076/30300 (epoch 16.627), train_loss = 1.42165544, grad/param norm = 1.6429e-01, time/batch = 17.1379s	
10077/30300 (epoch 16.629), train_loss = 1.38264257, grad/param norm = 1.4913e-01, time/batch = 18.6245s	
10078/30300 (epoch 16.630), train_loss = 1.29516009, grad/param norm = 1.4085e-01, time/batch = 18.0471s	
10079/30300 (epoch 16.632), train_loss = 1.38062970, grad/param norm = 1.5541e-01, time/batch = 18.0461s	
10080/30300 (epoch 16.634), train_loss = 1.15013360, grad/param norm = 1.2719e-01, time/batch = 17.4633s	
10081/30300 (epoch 16.635), train_loss = 1.34028288, grad/param norm = 1.4741e-01, time/batch = 18.1389s	
10082/30300 (epoch 16.637), train_loss = 1.37461385, grad/param norm = 1.7218e-01, time/batch = 18.7226s	
10083/30300 (epoch 16.639), train_loss = 1.21569161, grad/param norm = 1.3829e-01, time/batch = 17.2062s	
10084/30300 (epoch 16.640), train_loss = 1.41495418, grad/param norm = 1.6180e-01, time/batch = 19.4514s	
10085/30300 (epoch 16.642), train_loss = 1.24582150, grad/param norm = 1.3247e-01, time/batch = 17.2729s	
10086/30300 (epoch 16.644), train_loss = 1.34799061, grad/param norm = 1.4024e-01, time/batch = 17.9670s	
10087/30300 (epoch 16.645), train_loss = 1.14672131, grad/param norm = 1.3462e-01, time/batch = 20.1135s	
10088/30300 (epoch 16.647), train_loss = 1.26482136, grad/param norm = 1.4264e-01, time/batch = 19.8765s	
10089/30300 (epoch 16.649), train_loss = 1.24637780, grad/param norm = 1.5534e-01, time/batch = 19.4614s	
10090/30300 (epoch 16.650), train_loss = 1.25159992, grad/param norm = 1.3610e-01, time/batch = 17.8844s	
10091/30300 (epoch 16.652), train_loss = 1.22624142, grad/param norm = 1.3370e-01, time/batch = 20.1394s	
10092/30300 (epoch 16.653), train_loss = 1.48568336, grad/param norm = 1.5730e-01, time/batch = 21.9980s	
10093/30300 (epoch 16.655), train_loss = 1.23805284, grad/param norm = 1.5333e-01, time/batch = 29.9179s	
10094/30300 (epoch 16.657), train_loss = 1.24216442, grad/param norm = 1.4602e-01, time/batch = 17.8886s	
10095/30300 (epoch 16.658), train_loss = 1.20262225, grad/param norm = 1.4039e-01, time/batch = 17.1032s	
10096/30300 (epoch 16.660), train_loss = 1.31531569, grad/param norm = 1.4787e-01, time/batch = 18.0391s	
10097/30300 (epoch 16.662), train_loss = 1.34609360, grad/param norm = 1.6178e-01, time/batch = 17.8711s	
10098/30300 (epoch 16.663), train_loss = 1.31717779, grad/param norm = 1.4843e-01, time/batch = 17.5437s	
10099/30300 (epoch 16.665), train_loss = 1.19628437, grad/param norm = 1.6180e-01, time/batch = 17.4322s	
10100/30300 (epoch 16.667), train_loss = 1.38943896, grad/param norm = 1.4467e-01, time/batch = 15.4347s	
10101/30300 (epoch 16.668), train_loss = 1.42929184, grad/param norm = 1.5376e-01, time/batch = 17.6882s	
10102/30300 (epoch 16.670), train_loss = 1.41504196, grad/param norm = 1.5464e-01, time/batch = 17.2122s	
10103/30300 (epoch 16.672), train_loss = 1.35922280, grad/param norm = 1.5476e-01, time/batch = 18.9537s	
10104/30300 (epoch 16.673), train_loss = 1.37514311, grad/param norm = 1.5433e-01, time/batch = 17.7989s	
10105/30300 (epoch 16.675), train_loss = 1.25055685, grad/param norm = 1.4811e-01, time/batch = 16.7031s	
10106/30300 (epoch 16.677), train_loss = 1.23067628, grad/param norm = 1.3856e-01, time/batch = 17.8705s	
10107/30300 (epoch 16.678), train_loss = 1.26268472, grad/param norm = 1.5335e-01, time/batch = 18.5573s	
10108/30300 (epoch 16.680), train_loss = 1.07092141, grad/param norm = 1.3634e-01, time/batch = 19.0253s	
10109/30300 (epoch 16.682), train_loss = 1.28320090, grad/param norm = 1.5137e-01, time/batch = 18.3634s	
10110/30300 (epoch 16.683), train_loss = 1.35317517, grad/param norm = 1.3298e-01, time/batch = 19.6421s	
10111/30300 (epoch 16.685), train_loss = 1.36775112, grad/param norm = 1.6193e-01, time/batch = 19.4559s	
10112/30300 (epoch 16.686), train_loss = 1.27440218, grad/param norm = 1.3639e-01, time/batch = 19.3681s	
10113/30300 (epoch 16.688), train_loss = 1.28488867, grad/param norm = 1.3754e-01, time/batch = 18.3484s	
10114/30300 (epoch 16.690), train_loss = 1.23757559, grad/param norm = 1.5372e-01, time/batch = 16.8803s	
10115/30300 (epoch 16.691), train_loss = 1.32600657, grad/param norm = 1.4385e-01, time/batch = 17.2139s	
10116/30300 (epoch 16.693), train_loss = 1.67415540, grad/param norm = 1.7585e-01, time/batch = 19.5453s	
10117/30300 (epoch 16.695), train_loss = 1.43560451, grad/param norm = 1.6056e-01, time/batch = 19.2990s	
10118/30300 (epoch 16.696), train_loss = 1.38776227, grad/param norm = 1.6800e-01, time/batch = 18.2878s	
10119/30300 (epoch 16.698), train_loss = 1.23806271, grad/param norm = 1.4265e-01, time/batch = 19.2146s	
10120/30300 (epoch 16.700), train_loss = 1.23723740, grad/param norm = 1.5045e-01, time/batch = 19.4713s	
10121/30300 (epoch 16.701), train_loss = 1.11420082, grad/param norm = 1.3445e-01, time/batch = 18.6218s	
10122/30300 (epoch 16.703), train_loss = 1.28871303, grad/param norm = 1.3312e-01, time/batch = 19.5483s	
10123/30300 (epoch 16.705), train_loss = 1.25509148, grad/param norm = 1.5233e-01, time/batch = 19.8759s	
10124/30300 (epoch 16.706), train_loss = 1.34929928, grad/param norm = 1.4806e-01, time/batch = 18.2116s	
10125/30300 (epoch 16.708), train_loss = 1.25072801, grad/param norm = 1.4293e-01, time/batch = 18.6221s	
10126/30300 (epoch 16.710), train_loss = 1.25081287, grad/param norm = 1.4191e-01, time/batch = 18.5316s	
10127/30300 (epoch 16.711), train_loss = 1.16762150, grad/param norm = 1.3677e-01, time/batch = 17.6883s	
10128/30300 (epoch 16.713), train_loss = 1.16836444, grad/param norm = 1.3352e-01, time/batch = 19.1119s	
10129/30300 (epoch 16.715), train_loss = 1.22720259, grad/param norm = 1.4126e-01, time/batch = 19.3824s	
10130/30300 (epoch 16.716), train_loss = 1.39815717, grad/param norm = 1.5414e-01, time/batch = 18.5151s	
10131/30300 (epoch 16.718), train_loss = 1.40589566, grad/param norm = 1.5964e-01, time/batch = 17.9477s	
10132/30300 (epoch 16.719), train_loss = 1.24921252, grad/param norm = 1.5982e-01, time/batch = 19.4516s	
10133/30300 (epoch 16.721), train_loss = 1.30511027, grad/param norm = 1.6350e-01, time/batch = 19.9603s	
10134/30300 (epoch 16.723), train_loss = 1.21083355, grad/param norm = 1.4621e-01, time/batch = 18.2975s	
10135/30300 (epoch 16.724), train_loss = 1.35998314, grad/param norm = 1.6862e-01, time/batch = 17.8744s	
10136/30300 (epoch 16.726), train_loss = 1.69502517, grad/param norm = 1.7254e-01, time/batch = 18.9678s	
10137/30300 (epoch 16.728), train_loss = 1.35048193, grad/param norm = 1.6121e-01, time/batch = 18.3715s	
10138/30300 (epoch 16.729), train_loss = 1.27240650, grad/param norm = 1.5616e-01, time/batch = 19.8876s	
10139/30300 (epoch 16.731), train_loss = 1.36446254, grad/param norm = 1.5256e-01, time/batch = 18.9604s	
10140/30300 (epoch 16.733), train_loss = 1.27212229, grad/param norm = 1.4012e-01, time/batch = 18.7708s	
10141/30300 (epoch 16.734), train_loss = 1.35259408, grad/param norm = 1.4235e-01, time/batch = 19.2739s	
10142/30300 (epoch 16.736), train_loss = 1.28083265, grad/param norm = 1.3881e-01, time/batch = 19.2692s	
10143/30300 (epoch 16.738), train_loss = 1.16934049, grad/param norm = 1.2908e-01, time/batch = 18.5003s	
10144/30300 (epoch 16.739), train_loss = 1.34074377, grad/param norm = 1.4860e-01, time/batch = 17.6166s	
10145/30300 (epoch 16.741), train_loss = 1.40327657, grad/param norm = 1.4213e-01, time/batch = 19.7064s	
10146/30300 (epoch 16.743), train_loss = 1.24979139, grad/param norm = 1.3870e-01, time/batch = 18.7827s	
10147/30300 (epoch 16.744), train_loss = 1.34179468, grad/param norm = 1.4852e-01, time/batch = 17.6001s	
10148/30300 (epoch 16.746), train_loss = 1.16810099, grad/param norm = 1.3503e-01, time/batch = 19.3819s	
10149/30300 (epoch 16.748), train_loss = 1.31742086, grad/param norm = 1.6703e-01, time/batch = 19.6379s	
10150/30300 (epoch 16.749), train_loss = 1.32846499, grad/param norm = 1.5023e-01, time/batch = 17.9603s	
10151/30300 (epoch 16.751), train_loss = 1.25023223, grad/param norm = 1.4054e-01, time/batch = 18.2712s	
10152/30300 (epoch 16.752), train_loss = 1.26652606, grad/param norm = 1.4226e-01, time/batch = 19.7008s	
10153/30300 (epoch 16.754), train_loss = 1.19212233, grad/param norm = 1.3687e-01, time/batch = 17.3750s	
10154/30300 (epoch 16.756), train_loss = 1.24843741, grad/param norm = 1.4113e-01, time/batch = 19.8726s	
10155/30300 (epoch 16.757), train_loss = 1.33388745, grad/param norm = 1.6120e-01, time/batch = 19.9633s	
10156/30300 (epoch 16.759), train_loss = 1.28901099, grad/param norm = 1.3322e-01, time/batch = 17.9471s	
10157/30300 (epoch 16.761), train_loss = 1.13423532, grad/param norm = 1.3308e-01, time/batch = 18.7779s	
10158/30300 (epoch 16.762), train_loss = 1.12095209, grad/param norm = 1.2909e-01, time/batch = 19.7059s	
10159/30300 (epoch 16.764), train_loss = 1.25216304, grad/param norm = 1.4167e-01, time/batch = 18.0465s	
10160/30300 (epoch 16.766), train_loss = 1.32531373, grad/param norm = 1.4535e-01, time/batch = 19.7172s	
10161/30300 (epoch 16.767), train_loss = 1.36477994, grad/param norm = 1.8069e-01, time/batch = 18.1330s	
10162/30300 (epoch 16.769), train_loss = 1.36259029, grad/param norm = 1.5062e-01, time/batch = 18.4584s	
10163/30300 (epoch 16.771), train_loss = 1.25432293, grad/param norm = 1.7302e-01, time/batch = 19.0420s	
10164/30300 (epoch 16.772), train_loss = 1.33034685, grad/param norm = 1.5038e-01, time/batch = 19.2917s	
10165/30300 (epoch 16.774), train_loss = 1.45673943, grad/param norm = 1.4454e-01, time/batch = 19.0484s	
10166/30300 (epoch 16.776), train_loss = 1.33624051, grad/param norm = 1.5840e-01, time/batch = 18.7054s	
10167/30300 (epoch 16.777), train_loss = 1.33738648, grad/param norm = 1.4419e-01, time/batch = 20.1285s	
10168/30300 (epoch 16.779), train_loss = 1.46994805, grad/param norm = 1.7043e-01, time/batch = 17.5520s	
10169/30300 (epoch 16.781), train_loss = 1.29172094, grad/param norm = 1.6079e-01, time/batch = 18.9458s	
10170/30300 (epoch 16.782), train_loss = 1.24281439, grad/param norm = 1.4567e-01, time/batch = 19.7014s	
10171/30300 (epoch 16.784), train_loss = 1.21705964, grad/param norm = 1.3464e-01, time/batch = 18.9661s	
10172/30300 (epoch 16.785), train_loss = 1.45879292, grad/param norm = 1.6636e-01, time/batch = 17.8056s	
10173/30300 (epoch 16.787), train_loss = 1.13568978, grad/param norm = 1.3828e-01, time/batch = 18.3787s	
10174/30300 (epoch 16.789), train_loss = 1.54074990, grad/param norm = 1.5089e-01, time/batch = 19.4648s	
10175/30300 (epoch 16.790), train_loss = 1.38495359, grad/param norm = 1.7253e-01, time/batch = 18.2125s	
10176/30300 (epoch 16.792), train_loss = 1.12898538, grad/param norm = 1.5595e-01, time/batch = 19.3884s	
10177/30300 (epoch 16.794), train_loss = 1.26977101, grad/param norm = 1.6066e-01, time/batch = 19.9633s	
10178/30300 (epoch 16.795), train_loss = 1.22029214, grad/param norm = 1.2873e-01, time/batch = 17.6991s	
10179/30300 (epoch 16.797), train_loss = 1.47618853, grad/param norm = 1.7068e-01, time/batch = 17.4426s	
10180/30300 (epoch 16.799), train_loss = 1.35907237, grad/param norm = 1.5853e-01, time/batch = 19.6987s	
10181/30300 (epoch 16.800), train_loss = 1.37698125, grad/param norm = 1.5836e-01, time/batch = 18.7056s	
10182/30300 (epoch 16.802), train_loss = 1.53685512, grad/param norm = 1.6497e-01, time/batch = 16.8655s	
10183/30300 (epoch 16.804), train_loss = 1.35991961, grad/param norm = 1.6285e-01, time/batch = 20.3786s	
10184/30300 (epoch 16.805), train_loss = 1.48086112, grad/param norm = 1.7323e-01, time/batch = 19.7901s	
10185/30300 (epoch 16.807), train_loss = 1.28477592, grad/param norm = 1.5346e-01, time/batch = 18.8769s	
10186/30300 (epoch 16.809), train_loss = 1.40069552, grad/param norm = 1.6209e-01, time/batch = 20.4682s	
10187/30300 (epoch 16.810), train_loss = 1.39318921, grad/param norm = 1.4748e-01, time/batch = 19.8795s	
10188/30300 (epoch 16.812), train_loss = 1.20776665, grad/param norm = 1.5210e-01, time/batch = 18.8678s	
10189/30300 (epoch 16.814), train_loss = 1.32090593, grad/param norm = 1.5880e-01, time/batch = 18.0674s	
10190/30300 (epoch 16.815), train_loss = 1.34134360, grad/param norm = 1.5847e-01, time/batch = 19.9741s	
10191/30300 (epoch 16.817), train_loss = 1.40400105, grad/param norm = 1.5627e-01, time/batch = 19.1956s	
10192/30300 (epoch 16.818), train_loss = 1.35842481, grad/param norm = 1.4336e-01, time/batch = 18.6308s	
10193/30300 (epoch 16.820), train_loss = 1.49596033, grad/param norm = 1.6015e-01, time/batch = 19.2902s	
10194/30300 (epoch 16.822), train_loss = 1.50170788, grad/param norm = 1.9206e-01, time/batch = 17.2026s	
10195/30300 (epoch 16.823), train_loss = 1.54311832, grad/param norm = 1.7437e-01, time/batch = 18.2860s	
10196/30300 (epoch 16.825), train_loss = 1.42105605, grad/param norm = 1.7504e-01, time/batch = 19.0430s	
10197/30300 (epoch 16.827), train_loss = 1.18844483, grad/param norm = 1.7188e-01, time/batch = 18.7126s	
10198/30300 (epoch 16.828), train_loss = 1.36016319, grad/param norm = 1.5106e-01, time/batch = 19.2887s	
10199/30300 (epoch 16.830), train_loss = 1.33262486, grad/param norm = 1.5691e-01, time/batch = 19.3792s	
10200/30300 (epoch 16.832), train_loss = 1.23984206, grad/param norm = 1.4968e-01, time/batch = 18.5512s	
10201/30300 (epoch 16.833), train_loss = 1.37061651, grad/param norm = 1.4866e-01, time/batch = 17.6038s	
10202/30300 (epoch 16.835), train_loss = 1.25322973, grad/param norm = 1.5307e-01, time/batch = 18.8144s	
10203/30300 (epoch 16.837), train_loss = 1.15635556, grad/param norm = 1.4145e-01, time/batch = 19.4759s	
10204/30300 (epoch 16.838), train_loss = 1.16694325, grad/param norm = 1.3760e-01, time/batch = 18.5335s	
10205/30300 (epoch 16.840), train_loss = 1.36619616, grad/param norm = 1.3239e-01, time/batch = 18.3841s	
10206/30300 (epoch 16.842), train_loss = 1.19616048, grad/param norm = 1.2217e-01, time/batch = 19.2977s	
10207/30300 (epoch 16.843), train_loss = 1.34070775, grad/param norm = 1.4777e-01, time/batch = 19.0370s	
10208/30300 (epoch 16.845), train_loss = 1.31335526, grad/param norm = 1.3741e-01, time/batch = 19.6202s	
10209/30300 (epoch 16.847), train_loss = 1.33551624, grad/param norm = 1.5518e-01, time/batch = 19.3759s	
10210/30300 (epoch 16.848), train_loss = 1.41195244, grad/param norm = 1.4924e-01, time/batch = 17.3922s	
10211/30300 (epoch 16.850), train_loss = 1.30006838, grad/param norm = 1.4611e-01, time/batch = 19.5635s	
10212/30300 (epoch 16.851), train_loss = 1.38005531, grad/param norm = 1.6765e-01, time/batch = 18.8578s	
10213/30300 (epoch 16.853), train_loss = 1.24864311, grad/param norm = 1.3629e-01, time/batch = 18.5463s	
10214/30300 (epoch 16.855), train_loss = 1.22984953, grad/param norm = 1.3079e-01, time/batch = 19.3796s	
10215/30300 (epoch 16.856), train_loss = 1.28091818, grad/param norm = 1.5374e-01, time/batch = 19.9653s	
10216/30300 (epoch 16.858), train_loss = 1.25516834, grad/param norm = 1.3512e-01, time/batch = 18.3032s	
10217/30300 (epoch 16.860), train_loss = 1.23144913, grad/param norm = 1.4798e-01, time/batch = 18.7112s	
10218/30300 (epoch 16.861), train_loss = 1.47018966, grad/param norm = 1.4788e-01, time/batch = 19.6454s	
10219/30300 (epoch 16.863), train_loss = 1.31466192, grad/param norm = 1.3715e-01, time/batch = 18.4568s	
10220/30300 (epoch 16.865), train_loss = 1.42118942, grad/param norm = 1.5369e-01, time/batch = 17.3450s	
10221/30300 (epoch 16.866), train_loss = 1.36909570, grad/param norm = 1.5594e-01, time/batch = 16.5986s	
10222/30300 (epoch 16.868), train_loss = 1.29371019, grad/param norm = 1.4560e-01, time/batch = 19.9603s	
10223/30300 (epoch 16.870), train_loss = 1.24899785, grad/param norm = 1.4697e-01, time/batch = 18.8833s	
10224/30300 (epoch 16.871), train_loss = 1.25813281, grad/param norm = 1.3464e-01, time/batch = 18.8106s	
10225/30300 (epoch 16.873), train_loss = 1.30182831, grad/param norm = 1.4028e-01, time/batch = 19.3662s	
10226/30300 (epoch 16.875), train_loss = 1.19138667, grad/param norm = 1.3096e-01, time/batch = 17.6225s	
10227/30300 (epoch 16.876), train_loss = 1.19998858, grad/param norm = 1.4792e-01, time/batch = 19.8956s	
10228/30300 (epoch 16.878), train_loss = 1.10511771, grad/param norm = 1.4238e-01, time/batch = 20.3693s	
10229/30300 (epoch 16.880), train_loss = 1.21198060, grad/param norm = 1.4095e-01, time/batch = 18.6138s	
10230/30300 (epoch 16.881), train_loss = 1.49833466, grad/param norm = 1.6863e-01, time/batch = 19.2895s	
10231/30300 (epoch 16.883), train_loss = 1.36507274, grad/param norm = 1.5577e-01, time/batch = 19.6963s	
10232/30300 (epoch 16.884), train_loss = 1.18339970, grad/param norm = 1.2772e-01, time/batch = 17.7608s	
10233/30300 (epoch 16.886), train_loss = 1.31831022, grad/param norm = 1.4285e-01, time/batch = 19.7029s	
10234/30300 (epoch 16.888), train_loss = 1.31109246, grad/param norm = 1.4997e-01, time/batch = 19.3765s	
10235/30300 (epoch 16.889), train_loss = 1.31665387, grad/param norm = 1.4360e-01, time/batch = 17.9618s	
10236/30300 (epoch 16.891), train_loss = 1.31039375, grad/param norm = 1.5668e-01, time/batch = 18.4743s	
10237/30300 (epoch 16.893), train_loss = 1.56284953, grad/param norm = 1.5708e-01, time/batch = 19.6871s	
10238/30300 (epoch 16.894), train_loss = 1.41494185, grad/param norm = 1.4823e-01, time/batch = 18.7702s	
10239/30300 (epoch 16.896), train_loss = 1.13148635, grad/param norm = 1.3599e-01, time/batch = 18.8008s	
10240/30300 (epoch 16.898), train_loss = 1.09685110, grad/param norm = 1.5669e-01, time/batch = 19.1050s	
10241/30300 (epoch 16.899), train_loss = 1.23466130, grad/param norm = 1.5103e-01, time/batch = 16.9555s	
10242/30300 (epoch 16.901), train_loss = 1.29626109, grad/param norm = 1.7000e-01, time/batch = 18.5442s	
10243/30300 (epoch 16.903), train_loss = 1.33580846, grad/param norm = 1.4731e-01, time/batch = 19.9606s	
10244/30300 (epoch 16.904), train_loss = 1.26477757, grad/param norm = 1.5284e-01, time/batch = 19.7004s	
10245/30300 (epoch 16.906), train_loss = 1.42911153, grad/param norm = 1.6434e-01, time/batch = 18.9458s	
10246/30300 (epoch 16.908), train_loss = 1.22384925, grad/param norm = 1.4523e-01, time/batch = 20.2074s	
10247/30300 (epoch 16.909), train_loss = 1.24211082, grad/param norm = 1.6026e-01, time/batch = 19.5354s	
10248/30300 (epoch 16.911), train_loss = 1.28338334, grad/param norm = 1.4238e-01, time/batch = 18.0387s	
10249/30300 (epoch 16.913), train_loss = 1.29093797, grad/param norm = 1.3942e-01, time/batch = 18.7778s	
10250/30300 (epoch 16.914), train_loss = 1.26516873, grad/param norm = 1.5527e-01, time/batch = 18.5293s	
10251/30300 (epoch 16.916), train_loss = 1.29564710, grad/param norm = 1.3486e-01, time/batch = 17.2961s	
10252/30300 (epoch 16.917), train_loss = 1.20559244, grad/param norm = 1.3732e-01, time/batch = 18.7034s	
10253/30300 (epoch 16.919), train_loss = 1.25927600, grad/param norm = 1.5210e-01, time/batch = 18.3494s	
10254/30300 (epoch 16.921), train_loss = 1.28831830, grad/param norm = 1.4322e-01, time/batch = 17.6392s	
10255/30300 (epoch 16.922), train_loss = 1.39901212, grad/param norm = 1.7042e-01, time/batch = 19.5459s	
10256/30300 (epoch 16.924), train_loss = 1.30069659, grad/param norm = 1.6325e-01, time/batch = 18.9565s	
10257/30300 (epoch 16.926), train_loss = 1.29144115, grad/param norm = 1.5156e-01, time/batch = 18.2916s	
10258/30300 (epoch 16.927), train_loss = 1.28211215, grad/param norm = 1.4848e-01, time/batch = 19.0297s	
10259/30300 (epoch 16.929), train_loss = 1.24358992, grad/param norm = 1.4495e-01, time/batch = 19.7917s	
10260/30300 (epoch 16.931), train_loss = 1.42409104, grad/param norm = 1.7159e-01, time/batch = 19.6335s	
10261/30300 (epoch 16.932), train_loss = 1.23637234, grad/param norm = 1.5189e-01, time/batch = 20.0416s	
10262/30300 (epoch 16.934), train_loss = 1.32200328, grad/param norm = 1.5749e-01, time/batch = 19.9717s	
10263/30300 (epoch 16.936), train_loss = 1.26545538, grad/param norm = 1.4797e-01, time/batch = 19.3775s	
10264/30300 (epoch 16.937), train_loss = 1.21797714, grad/param norm = 1.4498e-01, time/batch = 19.2964s	
10265/30300 (epoch 16.939), train_loss = 1.40425325, grad/param norm = 1.5452e-01, time/batch = 19.8039s	
10266/30300 (epoch 16.941), train_loss = 1.27265106, grad/param norm = 1.4510e-01, time/batch = 19.1977s	
10267/30300 (epoch 16.942), train_loss = 1.29802316, grad/param norm = 1.4828e-01, time/batch = 18.6944s	
10268/30300 (epoch 16.944), train_loss = 1.19758655, grad/param norm = 1.4197e-01, time/batch = 19.4658s	
10269/30300 (epoch 16.946), train_loss = 1.42532343, grad/param norm = 1.5563e-01, time/batch = 17.4423s	
10270/30300 (epoch 16.947), train_loss = 1.43694596, grad/param norm = 1.7605e-01, time/batch = 18.5301s	
10271/30300 (epoch 16.949), train_loss = 1.47538715, grad/param norm = 1.8208e-01, time/batch = 19.9562s	
10272/30300 (epoch 16.950), train_loss = 1.43453576, grad/param norm = 1.6441e-01, time/batch = 20.2976s	
10273/30300 (epoch 16.952), train_loss = 1.37118930, grad/param norm = 1.7552e-01, time/batch = 18.3040s	
10274/30300 (epoch 16.954), train_loss = 1.55323974, grad/param norm = 1.5454e-01, time/batch = 19.4650s	
10275/30300 (epoch 16.955), train_loss = 1.25088648, grad/param norm = 1.5558e-01, time/batch = 20.1117s	
10276/30300 (epoch 16.957), train_loss = 1.35413973, grad/param norm = 1.5647e-01, time/batch = 18.0406s	
10277/30300 (epoch 16.959), train_loss = 1.26691597, grad/param norm = 1.5378e-01, time/batch = 18.2766s	
10278/30300 (epoch 16.960), train_loss = 1.27528215, grad/param norm = 1.5700e-01, time/batch = 19.8814s	
10279/30300 (epoch 16.962), train_loss = 1.25507494, grad/param norm = 1.7833e-01, time/batch = 18.7045s	
10280/30300 (epoch 16.964), train_loss = 1.21988272, grad/param norm = 1.5947e-01, time/batch = 19.3847s	
10281/30300 (epoch 16.965), train_loss = 1.21324592, grad/param norm = 1.5390e-01, time/batch = 19.7219s	
10282/30300 (epoch 16.967), train_loss = 1.28790872, grad/param norm = 1.6495e-01, time/batch = 27.6683s	
10283/30300 (epoch 16.969), train_loss = 1.21571787, grad/param norm = 1.5713e-01, time/batch = 28.4230s	
10284/30300 (epoch 16.970), train_loss = 1.27009808, grad/param norm = 1.5142e-01, time/batch = 17.9883s	
10285/30300 (epoch 16.972), train_loss = 1.18110144, grad/param norm = 1.5522e-01, time/batch = 17.2621s	
10286/30300 (epoch 16.974), train_loss = 1.52152088, grad/param norm = 1.7344e-01, time/batch = 17.3656s	
10287/30300 (epoch 16.975), train_loss = 1.51674627, grad/param norm = 1.8621e-01, time/batch = 19.8682s	
10288/30300 (epoch 16.977), train_loss = 1.40665322, grad/param norm = 1.5802e-01, time/batch = 17.9385s	
10289/30300 (epoch 16.979), train_loss = 1.35572273, grad/param norm = 1.5575e-01, time/batch = 18.4665s	
10290/30300 (epoch 16.980), train_loss = 1.38100970, grad/param norm = 1.5687e-01, time/batch = 20.0245s	
10291/30300 (epoch 16.982), train_loss = 1.40443483, grad/param norm = 1.5733e-01, time/batch = 17.7856s	
10292/30300 (epoch 16.983), train_loss = 1.43784390, grad/param norm = 1.5954e-01, time/batch = 18.8701s	
10293/30300 (epoch 16.985), train_loss = 1.33563627, grad/param norm = 1.7064e-01, time/batch = 19.9413s	
10294/30300 (epoch 16.987), train_loss = 1.28049952, grad/param norm = 1.4187e-01, time/batch = 17.7775s	
10295/30300 (epoch 16.988), train_loss = 1.47266363, grad/param norm = 1.4753e-01, time/batch = 18.5244s	
10296/30300 (epoch 16.990), train_loss = 1.13992405, grad/param norm = 1.3842e-01, time/batch = 18.4525s	
10297/30300 (epoch 16.992), train_loss = 1.35183655, grad/param norm = 1.3965e-01, time/batch = 18.8636s	
10298/30300 (epoch 16.993), train_loss = 1.44008888, grad/param norm = 1.8492e-01, time/batch = 19.2813s	
10299/30300 (epoch 16.995), train_loss = 1.29619001, grad/param norm = 1.8085e-01, time/batch = 17.8607s	
10300/30300 (epoch 16.997), train_loss = 1.33612485, grad/param norm = 1.6717e-01, time/batch = 19.0969s	
10301/30300 (epoch 16.998), train_loss = 1.40344349, grad/param norm = 1.6974e-01, time/batch = 18.7141s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
10302/30300 (epoch 17.000), train_loss = 1.26235406, grad/param norm = 1.5870e-01, time/batch = 19.7061s	
10303/30300 (epoch 17.002), train_loss = 1.39102095, grad/param norm = 1.5112e-01, time/batch = 19.6213s	
10304/30300 (epoch 17.003), train_loss = 1.31601565, grad/param norm = 1.5454e-01, time/batch = 18.4518s	
10305/30300 (epoch 17.005), train_loss = 1.29731291, grad/param norm = 1.5726e-01, time/batch = 18.9787s	
10306/30300 (epoch 17.007), train_loss = 1.40384301, grad/param norm = 1.7224e-01, time/batch = 19.4404s	
10307/30300 (epoch 17.008), train_loss = 1.24120964, grad/param norm = 1.5489e-01, time/batch = 18.5262s	
10308/30300 (epoch 17.010), train_loss = 1.20231242, grad/param norm = 1.4526e-01, time/batch = 19.7112s	
10309/30300 (epoch 17.012), train_loss = 1.24167790, grad/param norm = 1.4606e-01, time/batch = 19.0491s	
10310/30300 (epoch 17.013), train_loss = 1.38176509, grad/param norm = 1.6218e-01, time/batch = 17.3832s	
10311/30300 (epoch 17.015), train_loss = 1.26262578, grad/param norm = 1.4368e-01, time/batch = 19.6377s	
10312/30300 (epoch 17.017), train_loss = 1.21929795, grad/param norm = 1.3868e-01, time/batch = 18.5496s	
10313/30300 (epoch 17.018), train_loss = 1.23793429, grad/param norm = 1.4721e-01, time/batch = 18.1313s	
10314/30300 (epoch 17.020), train_loss = 1.41833007, grad/param norm = 1.7662e-01, time/batch = 19.0465s	
10315/30300 (epoch 17.021), train_loss = 1.42794488, grad/param norm = 1.5933e-01, time/batch = 18.7216s	
10316/30300 (epoch 17.023), train_loss = 1.26372983, grad/param norm = 1.3761e-01, time/batch = 19.2128s	
10317/30300 (epoch 17.025), train_loss = 1.22849346, grad/param norm = 1.6567e-01, time/batch = 19.2855s	
10318/30300 (epoch 17.026), train_loss = 1.34374770, grad/param norm = 1.7198e-01, time/batch = 19.2012s	
10319/30300 (epoch 17.028), train_loss = 1.38089877, grad/param norm = 1.4886e-01, time/batch = 17.8529s	
10320/30300 (epoch 17.030), train_loss = 1.23922566, grad/param norm = 1.5518e-01, time/batch = 18.2192s	
10321/30300 (epoch 17.031), train_loss = 1.32015817, grad/param norm = 1.5597e-01, time/batch = 19.7878s	
10322/30300 (epoch 17.033), train_loss = 1.31622947, grad/param norm = 1.6392e-01, time/batch = 18.8673s	
10323/30300 (epoch 17.035), train_loss = 1.39421180, grad/param norm = 1.5650e-01, time/batch = 18.6255s	
10324/30300 (epoch 17.036), train_loss = 1.29387566, grad/param norm = 1.4104e-01, time/batch = 20.0409s	
10325/30300 (epoch 17.038), train_loss = 1.32961588, grad/param norm = 1.5388e-01, time/batch = 19.7785s	
10326/30300 (epoch 17.040), train_loss = 1.04074494, grad/param norm = 1.3125e-01, time/batch = 18.1136s	
10327/30300 (epoch 17.041), train_loss = 1.10267049, grad/param norm = 1.3411e-01, time/batch = 20.0452s	
10328/30300 (epoch 17.043), train_loss = 1.31672187, grad/param norm = 1.5330e-01, time/batch = 18.6185s	
10329/30300 (epoch 17.045), train_loss = 1.27743621, grad/param norm = 1.5212e-01, time/batch = 17.4324s	
10330/30300 (epoch 17.046), train_loss = 1.43623847, grad/param norm = 1.7368e-01, time/batch = 19.1297s	
10331/30300 (epoch 17.048), train_loss = 1.29124948, grad/param norm = 1.6000e-01, time/batch = 18.9480s	
10332/30300 (epoch 17.050), train_loss = 1.29652756, grad/param norm = 1.5198e-01, time/batch = 18.7117s	
10333/30300 (epoch 17.051), train_loss = 1.34308091, grad/param norm = 1.6972e-01, time/batch = 20.1353s	
10334/30300 (epoch 17.053), train_loss = 1.12275117, grad/param norm = 1.6803e-01, time/batch = 18.7949s	
10335/30300 (epoch 17.054), train_loss = 1.26878715, grad/param norm = 1.4613e-01, time/batch = 18.2050s	
10336/30300 (epoch 17.056), train_loss = 1.22311166, grad/param norm = 1.4663e-01, time/batch = 20.0330s	
10337/30300 (epoch 17.058), train_loss = 1.26393034, grad/param norm = 1.4199e-01, time/batch = 19.7097s	
10338/30300 (epoch 17.059), train_loss = 1.20662469, grad/param norm = 1.5550e-01, time/batch = 16.7975s	
10339/30300 (epoch 17.061), train_loss = 1.39432965, grad/param norm = 1.5344e-01, time/batch = 19.3661s	
10340/30300 (epoch 17.063), train_loss = 1.22353217, grad/param norm = 1.6062e-01, time/batch = 20.2049s	
10341/30300 (epoch 17.064), train_loss = 1.33640673, grad/param norm = 1.5312e-01, time/batch = 19.1218s	
10342/30300 (epoch 17.066), train_loss = 1.27211562, grad/param norm = 1.4007e-01, time/batch = 19.3570s	
10343/30300 (epoch 17.068), train_loss = 1.17078466, grad/param norm = 1.4645e-01, time/batch = 19.5441s	
10344/30300 (epoch 17.069), train_loss = 1.35390611, grad/param norm = 1.4823e-01, time/batch = 19.6917s	
10345/30300 (epoch 17.071), train_loss = 1.35243463, grad/param norm = 1.7308e-01, time/batch = 18.9463s	
10346/30300 (epoch 17.073), train_loss = 1.28836592, grad/param norm = 1.6033e-01, time/batch = 19.8727s	
10347/30300 (epoch 17.074), train_loss = 1.32964113, grad/param norm = 1.3758e-01, time/batch = 18.2137s	
10348/30300 (epoch 17.076), train_loss = 1.27451025, grad/param norm = 1.5079e-01, time/batch = 17.6272s	
10349/30300 (epoch 17.078), train_loss = 1.17775037, grad/param norm = 1.4494e-01, time/batch = 19.9403s	
10350/30300 (epoch 17.079), train_loss = 1.22044055, grad/param norm = 1.3258e-01, time/batch = 19.8748s	
10351/30300 (epoch 17.081), train_loss = 1.31618440, grad/param norm = 1.4945e-01, time/batch = 18.3629s	
10352/30300 (epoch 17.083), train_loss = 1.40338919, grad/param norm = 1.6130e-01, time/batch = 19.2827s	
10353/30300 (epoch 17.084), train_loss = 1.19965122, grad/param norm = 1.5057e-01, time/batch = 19.2257s	
10354/30300 (epoch 17.086), train_loss = 1.23938213, grad/param norm = 1.5676e-01, time/batch = 17.3764s	
10355/30300 (epoch 17.087), train_loss = 1.19713353, grad/param norm = 1.3840e-01, time/batch = 18.7230s	
10356/30300 (epoch 17.089), train_loss = 1.26219463, grad/param norm = 1.5767e-01, time/batch = 20.3064s	
10357/30300 (epoch 17.091), train_loss = 1.33392329, grad/param norm = 1.5838e-01, time/batch = 18.8732s	
10358/30300 (epoch 17.092), train_loss = 1.31719321, grad/param norm = 1.4959e-01, time/batch = 19.1264s	
10359/30300 (epoch 17.094), train_loss = 1.46463753, grad/param norm = 1.6989e-01, time/batch = 18.7720s	
10360/30300 (epoch 17.096), train_loss = 1.38696068, grad/param norm = 1.5467e-01, time/batch = 18.4650s	
10361/30300 (epoch 17.097), train_loss = 1.25971832, grad/param norm = 1.5413e-01, time/batch = 19.0518s	
10362/30300 (epoch 17.099), train_loss = 1.41312048, grad/param norm = 1.6179e-01, time/batch = 19.2106s	
10363/30300 (epoch 17.101), train_loss = 1.46877491, grad/param norm = 1.5870e-01, time/batch = 18.3782s	
10364/30300 (epoch 17.102), train_loss = 1.22514395, grad/param norm = 1.6604e-01, time/batch = 19.3747s	
10365/30300 (epoch 17.104), train_loss = 1.26381265, grad/param norm = 1.5842e-01, time/batch = 19.6222s	
10366/30300 (epoch 17.106), train_loss = 1.28130530, grad/param norm = 1.5882e-01, time/batch = 18.6980s	
10367/30300 (epoch 17.107), train_loss = 1.32260010, grad/param norm = 1.5062e-01, time/batch = 19.1179s	
10368/30300 (epoch 17.109), train_loss = 1.40899913, grad/param norm = 1.8492e-01, time/batch = 18.4584s	
10369/30300 (epoch 17.111), train_loss = 1.42648874, grad/param norm = 1.5840e-01, time/batch = 19.7113s	
10370/30300 (epoch 17.112), train_loss = 1.36094278, grad/param norm = 1.5028e-01, time/batch = 19.2005s	
10371/30300 (epoch 17.114), train_loss = 1.31879463, grad/param norm = 1.4520e-01, time/batch = 20.4459s	
10372/30300 (epoch 17.116), train_loss = 1.30866304, grad/param norm = 1.6295e-01, time/batch = 19.1207s	
10373/30300 (epoch 17.117), train_loss = 1.32407926, grad/param norm = 1.3612e-01, time/batch = 18.5396s	
10374/30300 (epoch 17.119), train_loss = 1.22697676, grad/param norm = 1.5428e-01, time/batch = 19.9680s	
10375/30300 (epoch 17.120), train_loss = 1.30682853, grad/param norm = 1.6419e-01, time/batch = 19.5356s	
10376/30300 (epoch 17.122), train_loss = 1.38124328, grad/param norm = 1.7522e-01, time/batch = 12.2540s	
10377/30300 (epoch 17.124), train_loss = 1.48489187, grad/param norm = 1.7392e-01, time/batch = 0.7098s	
10378/30300 (epoch 17.125), train_loss = 1.17061339, grad/param norm = 1.4047e-01, time/batch = 0.7049s	
10379/30300 (epoch 17.127), train_loss = 1.32531999, grad/param norm = 1.7411e-01, time/batch = 0.7055s	
10380/30300 (epoch 17.129), train_loss = 1.46461551, grad/param norm = 1.5046e-01, time/batch = 0.7115s	
10381/30300 (epoch 17.130), train_loss = 1.43353593, grad/param norm = 1.4543e-01, time/batch = 0.7163s	
10382/30300 (epoch 17.132), train_loss = 1.37968456, grad/param norm = 1.5411e-01, time/batch = 0.7214s	
10383/30300 (epoch 17.134), train_loss = 1.21176616, grad/param norm = 1.5361e-01, time/batch = 0.7908s	
10384/30300 (epoch 17.135), train_loss = 1.23812044, grad/param norm = 1.6433e-01, time/batch = 1.0318s	
10385/30300 (epoch 17.137), train_loss = 1.31934494, grad/param norm = 1.4595e-01, time/batch = 1.0340s	
10386/30300 (epoch 17.139), train_loss = 1.26737527, grad/param norm = 1.6715e-01, time/batch = 1.0359s	
10387/30300 (epoch 17.140), train_loss = 1.37835867, grad/param norm = 2.0386e-01, time/batch = 1.0309s	
10388/30300 (epoch 17.142), train_loss = 1.48109746, grad/param norm = 1.8282e-01, time/batch = 1.3989s	
10389/30300 (epoch 17.144), train_loss = 1.35138311, grad/param norm = 1.9108e-01, time/batch = 1.9290s	
10390/30300 (epoch 17.145), train_loss = 1.41354831, grad/param norm = 1.6861e-01, time/batch = 1.9587s	
10391/30300 (epoch 17.147), train_loss = 1.27948654, grad/param norm = 1.5398e-01, time/batch = 13.2916s	
10392/30300 (epoch 17.149), train_loss = 1.48287655, grad/param norm = 1.6836e-01, time/batch = 15.7019s	
10393/30300 (epoch 17.150), train_loss = 1.33071162, grad/param norm = 1.9536e-01, time/batch = 15.3752s	
10394/30300 (epoch 17.152), train_loss = 1.19337927, grad/param norm = 1.6500e-01, time/batch = 15.2840s	
10395/30300 (epoch 17.153), train_loss = 1.30987101, grad/param norm = 1.6682e-01, time/batch = 15.7744s	
10396/30300 (epoch 17.155), train_loss = 1.13477302, grad/param norm = 1.3958e-01, time/batch = 15.4487s	
10397/30300 (epoch 17.157), train_loss = 1.29412149, grad/param norm = 1.5850e-01, time/batch = 16.3514s	
10398/30300 (epoch 17.158), train_loss = 1.31309903, grad/param norm = 1.7859e-01, time/batch = 15.0398s	
10399/30300 (epoch 17.160), train_loss = 1.23373647, grad/param norm = 1.5116e-01, time/batch = 15.5393s	
10400/30300 (epoch 17.162), train_loss = 1.27074937, grad/param norm = 1.4384e-01, time/batch = 16.5144s	
10401/30300 (epoch 17.163), train_loss = 1.24332315, grad/param norm = 1.5985e-01, time/batch = 15.4497s	
10402/30300 (epoch 17.165), train_loss = 1.38133405, grad/param norm = 1.5179e-01, time/batch = 15.4571s	
10403/30300 (epoch 17.167), train_loss = 1.30764846, grad/param norm = 1.6169e-01, time/batch = 15.0497s	
10404/30300 (epoch 17.168), train_loss = 1.33831727, grad/param norm = 1.5032e-01, time/batch = 15.2086s	
10405/30300 (epoch 17.170), train_loss = 1.33113145, grad/param norm = 1.6516e-01, time/batch = 15.2754s	
10406/30300 (epoch 17.172), train_loss = 1.26632427, grad/param norm = 1.6768e-01, time/batch = 15.2969s	
10407/30300 (epoch 17.173), train_loss = 1.32402421, grad/param norm = 1.7198e-01, time/batch = 15.7005s	
10408/30300 (epoch 17.175), train_loss = 1.30604223, grad/param norm = 1.4173e-01, time/batch = 15.1310s	
10409/30300 (epoch 17.177), train_loss = 1.32142706, grad/param norm = 1.6674e-01, time/batch = 15.7787s	
10410/30300 (epoch 17.178), train_loss = 1.06607095, grad/param norm = 1.3521e-01, time/batch = 14.9647s	
10411/30300 (epoch 17.180), train_loss = 1.24237813, grad/param norm = 1.3914e-01, time/batch = 15.0485s	
10412/30300 (epoch 17.182), train_loss = 1.24182162, grad/param norm = 1.5274e-01, time/batch = 15.3724s	
10413/30300 (epoch 17.183), train_loss = 1.21485018, grad/param norm = 1.3804e-01, time/batch = 15.2129s	
10414/30300 (epoch 17.185), train_loss = 1.52872852, grad/param norm = 1.5752e-01, time/batch = 15.3722s	
10415/30300 (epoch 17.186), train_loss = 1.55818333, grad/param norm = 1.6831e-01, time/batch = 14.9513s	
10416/30300 (epoch 17.188), train_loss = 1.36604838, grad/param norm = 1.6237e-01, time/batch = 15.0455s	
10417/30300 (epoch 17.190), train_loss = 1.27347710, grad/param norm = 1.4643e-01, time/batch = 15.1936s	
10418/30300 (epoch 17.191), train_loss = 1.36855634, grad/param norm = 1.5572e-01, time/batch = 16.6598s	
10419/30300 (epoch 17.193), train_loss = 1.19805753, grad/param norm = 1.3652e-01, time/batch = 19.4579s	
10420/30300 (epoch 17.195), train_loss = 1.32992136, grad/param norm = 1.5173e-01, time/batch = 18.7044s	
10421/30300 (epoch 17.196), train_loss = 1.32298383, grad/param norm = 1.3499e-01, time/batch = 19.4487s	
10422/30300 (epoch 17.198), train_loss = 1.10502949, grad/param norm = 1.4673e-01, time/batch = 17.4598s	
10423/30300 (epoch 17.200), train_loss = 1.29747987, grad/param norm = 1.3520e-01, time/batch = 18.1173s	
10424/30300 (epoch 17.201), train_loss = 1.40492567, grad/param norm = 1.7197e-01, time/batch = 19.9603s	
10425/30300 (epoch 17.203), train_loss = 1.31210746, grad/param norm = 1.5236e-01, time/batch = 19.6357s	
10426/30300 (epoch 17.205), train_loss = 1.51507226, grad/param norm = 1.7985e-01, time/batch = 17.5415s	
10427/30300 (epoch 17.206), train_loss = 1.46289923, grad/param norm = 1.7769e-01, time/batch = 2.3377s	
10428/30300 (epoch 17.208), train_loss = 1.43083664, grad/param norm = 1.9622e-01, time/batch = 0.6906s	
10429/30300 (epoch 17.210), train_loss = 1.34426186, grad/param norm = 1.4353e-01, time/batch = 0.6920s	
10430/30300 (epoch 17.211), train_loss = 1.41294308, grad/param norm = 1.5518e-01, time/batch = 0.6903s	
10431/30300 (epoch 17.213), train_loss = 1.25000976, grad/param norm = 1.4361e-01, time/batch = 0.6893s	
10432/30300 (epoch 17.215), train_loss = 1.17488580, grad/param norm = 1.5358e-01, time/batch = 0.6888s	
10433/30300 (epoch 17.216), train_loss = 1.26251090, grad/param norm = 1.5564e-01, time/batch = 0.7065s	
10434/30300 (epoch 17.218), train_loss = 1.19105268, grad/param norm = 1.3335e-01, time/batch = 0.9232s	
10435/30300 (epoch 17.219), train_loss = 1.11383380, grad/param norm = 1.3308e-01, time/batch = 1.0167s	
10436/30300 (epoch 17.221), train_loss = 1.14951325, grad/param norm = 1.4229e-01, time/batch = 1.0092s	
10437/30300 (epoch 17.223), train_loss = 1.32175239, grad/param norm = 1.4830e-01, time/batch = 1.0408s	
10438/30300 (epoch 17.224), train_loss = 1.12207241, grad/param norm = 1.4533e-01, time/batch = 1.0119s	
10439/30300 (epoch 17.226), train_loss = 1.39444507, grad/param norm = 1.7071e-01, time/batch = 1.7384s	
10440/30300 (epoch 17.228), train_loss = 1.39552491, grad/param norm = 1.4855e-01, time/batch = 1.8806s	
10441/30300 (epoch 17.229), train_loss = 1.22635052, grad/param norm = 1.5156e-01, time/batch = 5.6033s	
10442/30300 (epoch 17.231), train_loss = 1.34545563, grad/param norm = 1.4665e-01, time/batch = 20.1275s	
10443/30300 (epoch 17.233), train_loss = 1.27196278, grad/param norm = 1.4032e-01, time/batch = 18.8711s	
10444/30300 (epoch 17.234), train_loss = 1.35963235, grad/param norm = 1.8139e-01, time/batch = 17.1924s	
10445/30300 (epoch 17.236), train_loss = 1.27308656, grad/param norm = 1.3614e-01, time/batch = 19.7854s	
10446/30300 (epoch 17.238), train_loss = 1.35082403, grad/param norm = 1.7085e-01, time/batch = 19.2635s	
10447/30300 (epoch 17.239), train_loss = 1.32813437, grad/param norm = 1.5186e-01, time/batch = 18.4636s	
10448/30300 (epoch 17.241), train_loss = 1.33881553, grad/param norm = 1.6231e-01, time/batch = 19.4669s	
10449/30300 (epoch 17.243), train_loss = 1.36856575, grad/param norm = 1.4555e-01, time/batch = 19.7951s	
10450/30300 (epoch 17.244), train_loss = 1.55556286, grad/param norm = 1.6693e-01, time/batch = 19.1231s	
10451/30300 (epoch 17.246), train_loss = 1.29831922, grad/param norm = 1.4826e-01, time/batch = 20.2919s	
10452/30300 (epoch 17.248), train_loss = 1.26717258, grad/param norm = 1.4599e-01, time/batch = 19.7089s	
10453/30300 (epoch 17.249), train_loss = 1.21339672, grad/param norm = 1.4354e-01, time/batch = 19.6972s	
10454/30300 (epoch 17.251), train_loss = 1.20251724, grad/param norm = 1.4766e-01, time/batch = 19.7922s	
10455/30300 (epoch 17.252), train_loss = 1.41976069, grad/param norm = 1.5540e-01, time/batch = 19.4543s	
10456/30300 (epoch 17.254), train_loss = 1.41682392, grad/param norm = 1.7227e-01, time/batch = 19.4307s	
10457/30300 (epoch 17.256), train_loss = 1.33621770, grad/param norm = 1.5207e-01, time/batch = 16.2748s	
10458/30300 (epoch 17.257), train_loss = 1.37499835, grad/param norm = 1.7815e-01, time/batch = 17.7326s	
10459/30300 (epoch 17.259), train_loss = 1.29100051, grad/param norm = 1.6038e-01, time/batch = 17.2875s	
10460/30300 (epoch 17.261), train_loss = 1.41737710, grad/param norm = 1.5170e-01, time/batch = 18.4672s	
10461/30300 (epoch 17.262), train_loss = 1.29493167, grad/param norm = 1.4990e-01, time/batch = 19.2070s	
10462/30300 (epoch 17.264), train_loss = 1.30572871, grad/param norm = 1.8293e-01, time/batch = 18.0422s	
10463/30300 (epoch 17.266), train_loss = 1.24130760, grad/param norm = 1.4115e-01, time/batch = 19.1098s	
10464/30300 (epoch 17.267), train_loss = 1.49671853, grad/param norm = 2.3055e-01, time/batch = 18.9720s	
10465/30300 (epoch 17.269), train_loss = 1.33993694, grad/param norm = 1.9578e-01, time/batch = 18.4566s	
10466/30300 (epoch 17.271), train_loss = 1.32947711, grad/param norm = 1.5861e-01, time/batch = 18.8788s	
10467/30300 (epoch 17.272), train_loss = 1.32482907, grad/param norm = 1.5815e-01, time/batch = 19.2878s	
10468/30300 (epoch 17.274), train_loss = 1.43375495, grad/param norm = 1.5416e-01, time/batch = 19.4544s	
10469/30300 (epoch 17.276), train_loss = 1.36921800, grad/param norm = 1.6308e-01, time/batch = 19.8658s	
10470/30300 (epoch 17.277), train_loss = 1.20090278, grad/param norm = 1.4980e-01, time/batch = 19.0282s	
10471/30300 (epoch 17.279), train_loss = 1.35966069, grad/param norm = 1.6342e-01, time/batch = 19.6244s	
10472/30300 (epoch 17.281), train_loss = 1.39326013, grad/param norm = 1.7806e-01, time/batch = 18.2706s	
10473/30300 (epoch 17.282), train_loss = 1.30302311, grad/param norm = 1.4727e-01, time/batch = 19.0290s	
10474/30300 (epoch 17.284), train_loss = 1.46879300, grad/param norm = 1.8783e-01, time/batch = 19.3893s	
10475/30300 (epoch 17.285), train_loss = 1.32907867, grad/param norm = 1.3865e-01, time/batch = 17.5421s	
10476/30300 (epoch 17.287), train_loss = 1.30820602, grad/param norm = 1.5471e-01, time/batch = 16.7085s	
10477/30300 (epoch 17.289), train_loss = 1.36353607, grad/param norm = 1.4595e-01, time/batch = 18.7082s	
10478/30300 (epoch 17.290), train_loss = 1.06168522, grad/param norm = 1.3752e-01, time/batch = 16.8006s	
10479/30300 (epoch 17.292), train_loss = 1.18439939, grad/param norm = 1.3097e-01, time/batch = 18.8734s	
10480/30300 (epoch 17.294), train_loss = 1.44521514, grad/param norm = 1.6302e-01, time/batch = 18.4931s	
10481/30300 (epoch 17.295), train_loss = 1.28939885, grad/param norm = 1.5125e-01, time/batch = 18.6305s	
10482/30300 (epoch 17.297), train_loss = 1.22170039, grad/param norm = 1.3749e-01, time/batch = 17.7966s	
10483/30300 (epoch 17.299), train_loss = 1.27984331, grad/param norm = 1.5189e-01, time/batch = 14.7269s	
10484/30300 (epoch 17.300), train_loss = 1.28543395, grad/param norm = 1.5458e-01, time/batch = 14.8028s	
10485/30300 (epoch 17.302), train_loss = 1.28641545, grad/param norm = 1.4130e-01, time/batch = 15.2903s	
10486/30300 (epoch 17.304), train_loss = 1.21478936, grad/param norm = 1.4271e-01, time/batch = 19.4553s	
10487/30300 (epoch 17.305), train_loss = 1.26101964, grad/param norm = 1.4476e-01, time/batch = 18.8827s	
10488/30300 (epoch 17.307), train_loss = 1.33382424, grad/param norm = 1.3963e-01, time/batch = 18.8729s	
10489/30300 (epoch 17.309), train_loss = 1.36455134, grad/param norm = 1.5485e-01, time/batch = 18.5336s	
10490/30300 (epoch 17.310), train_loss = 1.28999033, grad/param norm = 1.5524e-01, time/batch = 18.3039s	
10491/30300 (epoch 17.312), train_loss = 1.44233431, grad/param norm = 1.5255e-01, time/batch = 19.7032s	
10492/30300 (epoch 17.314), train_loss = 1.33181441, grad/param norm = 1.5121e-01, time/batch = 18.9431s	
10493/30300 (epoch 17.315), train_loss = 1.32922240, grad/param norm = 1.5131e-01, time/batch = 18.4597s	
10494/30300 (epoch 17.317), train_loss = 1.38480375, grad/param norm = 1.4707e-01, time/batch = 19.1271s	
10495/30300 (epoch 17.318), train_loss = 1.44994238, grad/param norm = 1.6959e-01, time/batch = 17.7023s	
10496/30300 (epoch 17.320), train_loss = 1.39180882, grad/param norm = 1.5093e-01, time/batch = 19.3794s	
10497/30300 (epoch 17.322), train_loss = 1.21462909, grad/param norm = 1.4537e-01, time/batch = 18.4635s	
10498/30300 (epoch 17.323), train_loss = 1.40702684, grad/param norm = 1.5553e-01, time/batch = 17.6942s	
10499/30300 (epoch 17.325), train_loss = 1.27010011, grad/param norm = 1.3566e-01, time/batch = 16.2984s	
10500/30300 (epoch 17.327), train_loss = 1.29628974, grad/param norm = 1.4005e-01, time/batch = 18.3625s	
10501/30300 (epoch 17.328), train_loss = 1.29425624, grad/param norm = 1.3959e-01, time/batch = 18.5447s	
10502/30300 (epoch 17.330), train_loss = 1.35382203, grad/param norm = 1.4076e-01, time/batch = 19.5201s	
10503/30300 (epoch 17.332), train_loss = 1.38563706, grad/param norm = 1.5859e-01, time/batch = 19.4502s	
10504/30300 (epoch 17.333), train_loss = 1.28937373, grad/param norm = 1.5827e-01, time/batch = 19.5296s	
10505/30300 (epoch 17.335), train_loss = 1.17529442, grad/param norm = 1.4488e-01, time/batch = 31.9065s	
10506/30300 (epoch 17.337), train_loss = 1.45347606, grad/param norm = 1.5376e-01, time/batch = 19.7149s	
10507/30300 (epoch 17.338), train_loss = 1.22807951, grad/param norm = 1.3669e-01, time/batch = 18.2009s	
10508/30300 (epoch 17.340), train_loss = 1.18219360, grad/param norm = 1.3000e-01, time/batch = 18.0135s	
10509/30300 (epoch 17.342), train_loss = 1.40176119, grad/param norm = 1.5882e-01, time/batch = 19.3772s	
10510/30300 (epoch 17.343), train_loss = 1.34268137, grad/param norm = 1.4606e-01, time/batch = 18.1962s	
10511/30300 (epoch 17.345), train_loss = 1.33817617, grad/param norm = 1.4793e-01, time/batch = 19.8651s	
10512/30300 (epoch 17.347), train_loss = 1.13632875, grad/param norm = 1.3752e-01, time/batch = 19.5330s	
10513/30300 (epoch 17.348), train_loss = 1.18458624, grad/param norm = 1.4612e-01, time/batch = 18.7102s	
10514/30300 (epoch 17.350), train_loss = 1.28384620, grad/param norm = 1.4004e-01, time/batch = 18.8666s	
10515/30300 (epoch 17.351), train_loss = 1.28985833, grad/param norm = 1.5258e-01, time/batch = 18.5402s	
10516/30300 (epoch 17.353), train_loss = 1.11474977, grad/param norm = 1.4704e-01, time/batch = 18.7060s	
10517/30300 (epoch 17.355), train_loss = 1.24977660, grad/param norm = 1.4481e-01, time/batch = 19.6298s	
10518/30300 (epoch 17.356), train_loss = 1.38844343, grad/param norm = 1.7077e-01, time/batch = 17.9601s	
10519/30300 (epoch 17.358), train_loss = 1.53636454, grad/param norm = 1.4994e-01, time/batch = 19.2960s	
10520/30300 (epoch 17.360), train_loss = 1.24789169, grad/param norm = 1.5425e-01, time/batch = 18.3698s	
10521/30300 (epoch 17.361), train_loss = 1.32868105, grad/param norm = 1.5111e-01, time/batch = 19.4715s	
10522/30300 (epoch 17.363), train_loss = 1.38458779, grad/param norm = 1.5384e-01, time/batch = 19.8741s	
10523/30300 (epoch 17.365), train_loss = 1.20612164, grad/param norm = 1.5797e-01, time/batch = 18.6858s	
10524/30300 (epoch 17.366), train_loss = 1.23759530, grad/param norm = 1.3965e-01, time/batch = 19.5435s	
10525/30300 (epoch 17.368), train_loss = 1.11896980, grad/param norm = 1.4030e-01, time/batch = 18.6849s	
10526/30300 (epoch 17.370), train_loss = 1.17937585, grad/param norm = 1.4637e-01, time/batch = 18.2821s	
10527/30300 (epoch 17.371), train_loss = 1.36911455, grad/param norm = 1.5372e-01, time/batch = 18.8044s	
10528/30300 (epoch 17.373), train_loss = 1.19944273, grad/param norm = 1.2524e-01, time/batch = 19.3804s	
10529/30300 (epoch 17.375), train_loss = 1.19680972, grad/param norm = 1.2408e-01, time/batch = 17.7945s	
10530/30300 (epoch 17.376), train_loss = 1.21590253, grad/param norm = 1.3492e-01, time/batch = 19.7031s	
10531/30300 (epoch 17.378), train_loss = 1.21381585, grad/param norm = 1.4882e-01, time/batch = 19.3783s	
10532/30300 (epoch 17.380), train_loss = 1.47722500, grad/param norm = 1.5552e-01, time/batch = 17.7184s	
10533/30300 (epoch 17.381), train_loss = 1.15616180, grad/param norm = 1.3501e-01, time/batch = 17.2914s	
10534/30300 (epoch 17.383), train_loss = 1.24390022, grad/param norm = 1.5303e-01, time/batch = 19.6290s	
10535/30300 (epoch 17.384), train_loss = 1.38381868, grad/param norm = 1.5820e-01, time/batch = 18.7795s	
10536/30300 (epoch 17.386), train_loss = 1.18401289, grad/param norm = 1.5961e-01, time/batch = 18.1304s	
10537/30300 (epoch 17.388), train_loss = 1.13444733, grad/param norm = 1.3370e-01, time/batch = 20.1136s	
10538/30300 (epoch 17.389), train_loss = 1.28073094, grad/param norm = 1.6372e-01, time/batch = 19.6301s	
10539/30300 (epoch 17.391), train_loss = 1.32204444, grad/param norm = 1.3978e-01, time/batch = 18.1113s	
10540/30300 (epoch 17.393), train_loss = 1.12886300, grad/param norm = 1.3520e-01, time/batch = 18.4404s	
10541/30300 (epoch 17.394), train_loss = 1.34409422, grad/param norm = 1.4754e-01, time/batch = 18.3696s	
10542/30300 (epoch 17.396), train_loss = 1.43993088, grad/param norm = 1.4873e-01, time/batch = 17.6142s	
10543/30300 (epoch 17.398), train_loss = 1.27148644, grad/param norm = 1.3296e-01, time/batch = 19.7197s	
10544/30300 (epoch 17.399), train_loss = 1.26295725, grad/param norm = 1.5381e-01, time/batch = 20.1315s	
10545/30300 (epoch 17.401), train_loss = 1.32864786, grad/param norm = 1.5164e-01, time/batch = 18.2942s	
10546/30300 (epoch 17.403), train_loss = 1.24797434, grad/param norm = 1.5354e-01, time/batch = 19.8729s	
10547/30300 (epoch 17.404), train_loss = 1.19189023, grad/param norm = 1.5429e-01, time/batch = 19.6237s	
10548/30300 (epoch 17.406), train_loss = 1.29918171, grad/param norm = 1.4633e-01, time/batch = 17.8847s	
10549/30300 (epoch 17.408), train_loss = 1.15060448, grad/param norm = 1.3834e-01, time/batch = 18.7080s	
10550/30300 (epoch 17.409), train_loss = 1.15328606, grad/param norm = 1.4915e-01, time/batch = 19.4590s	
10551/30300 (epoch 17.411), train_loss = 1.15855195, grad/param norm = 1.3115e-01, time/batch = 18.2003s	
10552/30300 (epoch 17.413), train_loss = 1.11221041, grad/param norm = 1.5113e-01, time/batch = 15.6468s	
10553/30300 (epoch 17.414), train_loss = 1.41573904, grad/param norm = 1.5374e-01, time/batch = 15.8750s	
10554/30300 (epoch 17.416), train_loss = 1.24138747, grad/param norm = 1.4833e-01, time/batch = 17.2153s	
10555/30300 (epoch 17.417), train_loss = 1.20455307, grad/param norm = 1.4127e-01, time/batch = 17.6933s	
10556/30300 (epoch 17.419), train_loss = 1.17001718, grad/param norm = 1.6744e-01, time/batch = 19.2063s	
10557/30300 (epoch 17.421), train_loss = 1.24661253, grad/param norm = 1.5193e-01, time/batch = 19.3847s	
10558/30300 (epoch 17.422), train_loss = 1.27380363, grad/param norm = 1.4770e-01, time/batch = 17.6924s	
10559/30300 (epoch 17.424), train_loss = 1.28367546, grad/param norm = 1.4130e-01, time/batch = 18.6036s	
10560/30300 (epoch 17.426), train_loss = 1.19011826, grad/param norm = 1.4649e-01, time/batch = 19.6257s	
10561/30300 (epoch 17.427), train_loss = 1.24841141, grad/param norm = 1.5187e-01, time/batch = 17.6146s	
10562/30300 (epoch 17.429), train_loss = 1.26238291, grad/param norm = 1.4039e-01, time/batch = 18.5325s	
10563/30300 (epoch 17.431), train_loss = 1.34680410, grad/param norm = 1.5238e-01, time/batch = 19.2462s	
10564/30300 (epoch 17.432), train_loss = 1.24361774, grad/param norm = 1.3856e-01, time/batch = 18.7902s	
10565/30300 (epoch 17.434), train_loss = 1.13517016, grad/param norm = 1.4572e-01, time/batch = 18.6364s	
10566/30300 (epoch 17.436), train_loss = 1.41658575, grad/param norm = 1.5612e-01, time/batch = 19.0342s	
10567/30300 (epoch 17.437), train_loss = 1.14737410, grad/param norm = 1.3916e-01, time/batch = 19.7072s	
10568/30300 (epoch 17.439), train_loss = 1.21577066, grad/param norm = 1.5550e-01, time/batch = 18.0215s	
10569/30300 (epoch 17.441), train_loss = 1.23332306, grad/param norm = 1.3688e-01, time/batch = 19.8552s	
10570/30300 (epoch 17.442), train_loss = 1.16343605, grad/param norm = 1.4172e-01, time/batch = 19.1894s	
10571/30300 (epoch 17.444), train_loss = 1.05632737, grad/param norm = 1.3904e-01, time/batch = 17.3737s	
10572/30300 (epoch 17.446), train_loss = 1.25117797, grad/param norm = 1.4264e-01, time/batch = 19.8756s	
10573/30300 (epoch 17.447), train_loss = 1.25770816, grad/param norm = 1.4582e-01, time/batch = 19.8829s	
10574/30300 (epoch 17.449), train_loss = 1.19717009, grad/param norm = 1.4399e-01, time/batch = 18.2029s	
10575/30300 (epoch 17.450), train_loss = 1.36243625, grad/param norm = 1.4157e-01, time/batch = 19.5487s	
10576/30300 (epoch 17.452), train_loss = 1.34281889, grad/param norm = 1.3619e-01, time/batch = 20.0558s	
10577/30300 (epoch 17.454), train_loss = 1.31422453, grad/param norm = 1.3360e-01, time/batch = 18.3035s	
10578/30300 (epoch 17.455), train_loss = 1.32677234, grad/param norm = 1.7001e-01, time/batch = 19.7817s	
10579/30300 (epoch 17.457), train_loss = 1.28905931, grad/param norm = 1.4111e-01, time/batch = 19.4555s	
10580/30300 (epoch 17.459), train_loss = 1.35684960, grad/param norm = 1.5925e-01, time/batch = 18.3701s	
10581/30300 (epoch 17.460), train_loss = 1.31807758, grad/param norm = 1.4703e-01, time/batch = 19.6278s	
10582/30300 (epoch 17.462), train_loss = 1.36747542, grad/param norm = 1.4881e-01, time/batch = 16.7747s	
10583/30300 (epoch 17.464), train_loss = 1.12650155, grad/param norm = 1.5680e-01, time/batch = 19.1146s	
10584/30300 (epoch 17.465), train_loss = 1.10634084, grad/param norm = 1.3783e-01, time/batch = 19.6243s	
10585/30300 (epoch 17.467), train_loss = 1.06430725, grad/param norm = 1.2781e-01, time/batch = 18.2082s	
10586/30300 (epoch 17.469), train_loss = 1.17477887, grad/param norm = 1.3778e-01, time/batch = 19.3791s	
10587/30300 (epoch 17.470), train_loss = 1.24582523, grad/param norm = 1.4532e-01, time/batch = 18.2982s	
10588/30300 (epoch 17.472), train_loss = 1.21831994, grad/param norm = 1.3077e-01, time/batch = 19.1243s	
10589/30300 (epoch 17.474), train_loss = 1.27022680, grad/param norm = 1.6148e-01, time/batch = 19.2994s	
10590/30300 (epoch 17.475), train_loss = 1.17912095, grad/param norm = 1.3984e-01, time/batch = 18.2739s	
10591/30300 (epoch 17.477), train_loss = 1.27260769, grad/param norm = 1.5609e-01, time/batch = 19.7932s	
10592/30300 (epoch 17.479), train_loss = 1.26626478, grad/param norm = 1.5138e-01, time/batch = 18.7907s	
10593/30300 (epoch 17.480), train_loss = 1.30207833, grad/param norm = 1.3696e-01, time/batch = 18.6971s	
10594/30300 (epoch 17.482), train_loss = 1.31949553, grad/param norm = 1.3334e-01, time/batch = 19.8680s	
10595/30300 (epoch 17.483), train_loss = 1.22177533, grad/param norm = 1.4566e-01, time/batch = 19.3652s	
10596/30300 (epoch 17.485), train_loss = 1.26587971, grad/param norm = 1.4673e-01, time/batch = 18.4628s	
10597/30300 (epoch 17.487), train_loss = 1.36033477, grad/param norm = 1.5008e-01, time/batch = 19.6231s	
10598/30300 (epoch 17.488), train_loss = 1.35238823, grad/param norm = 1.4127e-01, time/batch = 19.9501s	
10599/30300 (epoch 17.490), train_loss = 1.15826690, grad/param norm = 1.4585e-01, time/batch = 17.9478s	
10600/30300 (epoch 17.492), train_loss = 1.24806954, grad/param norm = 1.5225e-01, time/batch = 17.2004s	
10601/30300 (epoch 17.493), train_loss = 1.23878911, grad/param norm = 1.3965e-01, time/batch = 18.8311s	
10602/30300 (epoch 17.495), train_loss = 1.19284901, grad/param norm = 1.2810e-01, time/batch = 17.7070s	
10603/30300 (epoch 17.497), train_loss = 1.30458457, grad/param norm = 1.3910e-01, time/batch = 18.3588s	
10604/30300 (epoch 17.498), train_loss = 1.31198363, grad/param norm = 1.4588e-01, time/batch = 18.4594s	
10605/30300 (epoch 17.500), train_loss = 1.31558969, grad/param norm = 1.6282e-01, time/batch = 18.6081s	
10606/30300 (epoch 17.502), train_loss = 1.24592732, grad/param norm = 1.4785e-01, time/batch = 17.4498s	
10607/30300 (epoch 17.503), train_loss = 1.35767587, grad/param norm = 1.3868e-01, time/batch = 17.4487s	
10608/30300 (epoch 17.505), train_loss = 1.22557458, grad/param norm = 1.5450e-01, time/batch = 17.1169s	
10609/30300 (epoch 17.507), train_loss = 1.21846895, grad/param norm = 1.5181e-01, time/batch = 18.3578s	
10610/30300 (epoch 17.508), train_loss = 1.24436755, grad/param norm = 1.7701e-01, time/batch = 19.3653s	
10611/30300 (epoch 17.510), train_loss = 1.36235270, grad/param norm = 1.5927e-01, time/batch = 19.5511s	
10612/30300 (epoch 17.512), train_loss = 1.21117625, grad/param norm = 1.3860e-01, time/batch = 17.5124s	
10613/30300 (epoch 17.513), train_loss = 1.30223515, grad/param norm = 1.4181e-01, time/batch = 19.1176s	
10614/30300 (epoch 17.515), train_loss = 1.27015435, grad/param norm = 1.4508e-01, time/batch = 18.5300s	
10615/30300 (epoch 17.517), train_loss = 1.09215484, grad/param norm = 1.3377e-01, time/batch = 16.5288s	
10616/30300 (epoch 17.518), train_loss = 1.36442145, grad/param norm = 1.5960e-01, time/batch = 18.9442s	
10617/30300 (epoch 17.520), train_loss = 1.36817274, grad/param norm = 1.6559e-01, time/batch = 19.1165s	
10618/30300 (epoch 17.521), train_loss = 1.16123481, grad/param norm = 1.4808e-01, time/batch = 19.2087s	
10619/30300 (epoch 17.523), train_loss = 1.43865600, grad/param norm = 1.7388e-01, time/batch = 19.2830s	
10620/30300 (epoch 17.525), train_loss = 1.19098403, grad/param norm = 1.3822e-01, time/batch = 18.3703s	
10621/30300 (epoch 17.526), train_loss = 1.24061709, grad/param norm = 1.4390e-01, time/batch = 19.7108s	
10622/30300 (epoch 17.528), train_loss = 1.14006566, grad/param norm = 1.4155e-01, time/batch = 18.0313s	
10623/30300 (epoch 17.530), train_loss = 1.14870072, grad/param norm = 1.4681e-01, time/batch = 17.8683s	
10624/30300 (epoch 17.531), train_loss = 1.32485507, grad/param norm = 1.4925e-01, time/batch = 18.9767s	
10625/30300 (epoch 17.533), train_loss = 1.29713888, grad/param norm = 1.4802e-01, time/batch = 18.8624s	
10626/30300 (epoch 17.535), train_loss = 1.13566757, grad/param norm = 1.3079e-01, time/batch = 19.6116s	
10627/30300 (epoch 17.536), train_loss = 1.30560086, grad/param norm = 1.6785e-01, time/batch = 19.6304s	
10628/30300 (epoch 17.538), train_loss = 1.11946025, grad/param norm = 1.5026e-01, time/batch = 18.3911s	
10629/30300 (epoch 17.540), train_loss = 1.16292115, grad/param norm = 1.5129e-01, time/batch = 19.5516s	
10630/30300 (epoch 17.541), train_loss = 1.26280959, grad/param norm = 1.5363e-01, time/batch = 19.9661s	
10631/30300 (epoch 17.543), train_loss = 1.26091082, grad/param norm = 1.4773e-01, time/batch = 17.9390s	
10632/30300 (epoch 17.545), train_loss = 1.26205214, grad/param norm = 1.8309e-01, time/batch = 19.0927s	
10633/30300 (epoch 17.546), train_loss = 1.50823769, grad/param norm = 1.4605e-01, time/batch = 19.2973s	
10634/30300 (epoch 17.548), train_loss = 1.21053419, grad/param norm = 1.4511e-01, time/batch = 18.1360s	
10635/30300 (epoch 17.550), train_loss = 1.38548580, grad/param norm = 1.8471e-01, time/batch = 18.5314s	
10636/30300 (epoch 17.551), train_loss = 1.19958077, grad/param norm = 1.4721e-01, time/batch = 18.8688s	
10637/30300 (epoch 17.553), train_loss = 1.22982935, grad/param norm = 1.5271e-01, time/batch = 19.2780s	
10638/30300 (epoch 17.554), train_loss = 1.29583021, grad/param norm = 1.6046e-01, time/batch = 18.8708s	
10639/30300 (epoch 17.556), train_loss = 1.33638395, grad/param norm = 1.4634e-01, time/batch = 19.4505s	
10640/30300 (epoch 17.558), train_loss = 1.40557404, grad/param norm = 1.5954e-01, time/batch = 19.5385s	
10641/30300 (epoch 17.559), train_loss = 1.34804136, grad/param norm = 1.5859e-01, time/batch = 18.6983s	
10642/30300 (epoch 17.561), train_loss = 1.12467951, grad/param norm = 1.4736e-01, time/batch = 18.3046s	
10643/30300 (epoch 17.563), train_loss = 1.17518583, grad/param norm = 1.4698e-01, time/batch = 19.7934s	
10644/30300 (epoch 17.564), train_loss = 1.20353139, grad/param norm = 1.4161e-01, time/batch = 18.7810s	
10645/30300 (epoch 17.566), train_loss = 1.29740858, grad/param norm = 1.5026e-01, time/batch = 18.7156s	
10646/30300 (epoch 17.568), train_loss = 1.07287869, grad/param norm = 1.4895e-01, time/batch = 18.4514s	
10647/30300 (epoch 17.569), train_loss = 1.28041373, grad/param norm = 1.4369e-01, time/batch = 18.5306s	
10648/30300 (epoch 17.571), train_loss = 1.29532743, grad/param norm = 1.5256e-01, time/batch = 18.1136s	
10649/30300 (epoch 17.573), train_loss = 1.31301211, grad/param norm = 1.4978e-01, time/batch = 19.5419s	
10650/30300 (epoch 17.574), train_loss = 1.35033006, grad/param norm = 1.4240e-01, time/batch = 18.6981s	
10651/30300 (epoch 17.576), train_loss = 1.25428985, grad/param norm = 1.4028e-01, time/batch = 19.1215s	
10652/30300 (epoch 17.578), train_loss = 1.13237988, grad/param norm = 1.3653e-01, time/batch = 19.3763s	
10653/30300 (epoch 17.579), train_loss = 1.30031432, grad/param norm = 1.6914e-01, time/batch = 18.2858s	
10654/30300 (epoch 17.581), train_loss = 1.35074811, grad/param norm = 1.4305e-01, time/batch = 19.4510s	
10655/30300 (epoch 17.583), train_loss = 1.46198560, grad/param norm = 1.7105e-01, time/batch = 18.6337s	
10656/30300 (epoch 17.584), train_loss = 1.35651392, grad/param norm = 1.4573e-01, time/batch = 18.8035s	
10657/30300 (epoch 17.586), train_loss = 1.26842666, grad/param norm = 1.4510e-01, time/batch = 19.3715s	
10658/30300 (epoch 17.587), train_loss = 1.25838578, grad/param norm = 1.4465e-01, time/batch = 19.7077s	
10659/30300 (epoch 17.589), train_loss = 1.15725886, grad/param norm = 1.3843e-01, time/batch = 17.8789s	
10660/30300 (epoch 17.591), train_loss = 1.32132652, grad/param norm = 1.4174e-01, time/batch = 19.2899s	
10661/30300 (epoch 17.592), train_loss = 1.26792882, grad/param norm = 1.2970e-01, time/batch = 19.7106s	
10662/30300 (epoch 17.594), train_loss = 1.29264274, grad/param norm = 1.4436e-01, time/batch = 18.1351s	
10663/30300 (epoch 17.596), train_loss = 1.17911098, grad/param norm = 1.3422e-01, time/batch = 19.1125s	
10664/30300 (epoch 17.597), train_loss = 1.21466430, grad/param norm = 1.4687e-01, time/batch = 20.1050s	
10665/30300 (epoch 17.599), train_loss = 1.08856030, grad/param norm = 1.3685e-01, time/batch = 19.8798s	
10666/30300 (epoch 17.601), train_loss = 1.32147887, grad/param norm = 1.5057e-01, time/batch = 18.2108s	
10667/30300 (epoch 17.602), train_loss = 1.26113789, grad/param norm = 1.3826e-01, time/batch = 18.9713s	
10668/30300 (epoch 17.604), train_loss = 1.16449423, grad/param norm = 1.3020e-01, time/batch = 20.3736s	
10669/30300 (epoch 17.606), train_loss = 1.26428265, grad/param norm = 1.7783e-01, time/batch = 16.8695s	
10670/30300 (epoch 17.607), train_loss = 1.34541592, grad/param norm = 1.6669e-01, time/batch = 19.6989s	
10671/30300 (epoch 17.609), train_loss = 1.44902928, grad/param norm = 1.6103e-01, time/batch = 18.1042s	
10672/30300 (epoch 17.611), train_loss = 1.19307017, grad/param norm = 1.4774e-01, time/batch = 18.0472s	
10673/30300 (epoch 17.612), train_loss = 1.17221921, grad/param norm = 1.4936e-01, time/batch = 19.3615s	
10674/30300 (epoch 17.614), train_loss = 1.20592635, grad/param norm = 1.3953e-01, time/batch = 17.7834s	
10675/30300 (epoch 17.616), train_loss = 1.30816089, grad/param norm = 1.6350e-01, time/batch = 18.6318s	
10676/30300 (epoch 17.617), train_loss = 1.26257711, grad/param norm = 1.5639e-01, time/batch = 18.5369s	
10677/30300 (epoch 17.619), train_loss = 1.07898162, grad/param norm = 1.3980e-01, time/batch = 19.7067s	
10678/30300 (epoch 17.620), train_loss = 1.27565393, grad/param norm = 1.6006e-01, time/batch = 18.8831s	
10679/30300 (epoch 17.622), train_loss = 1.25160804, grad/param norm = 1.8028e-01, time/batch = 7.0675s	
10680/30300 (epoch 17.624), train_loss = 1.18968515, grad/param norm = 1.5195e-01, time/batch = 0.6979s	
10681/30300 (epoch 17.625), train_loss = 1.23736330, grad/param norm = 1.5877e-01, time/batch = 0.7027s	
10682/30300 (epoch 17.627), train_loss = 1.38987622, grad/param norm = 1.5867e-01, time/batch = 0.6973s	
10683/30300 (epoch 17.629), train_loss = 1.36817359, grad/param norm = 1.5269e-01, time/batch = 0.6925s	
10684/30300 (epoch 17.630), train_loss = 1.27241824, grad/param norm = 1.4300e-01, time/batch = 0.6882s	
10685/30300 (epoch 17.632), train_loss = 1.35802500, grad/param norm = 1.5405e-01, time/batch = 0.7160s	
10686/30300 (epoch 17.634), train_loss = 1.13089394, grad/param norm = 1.2528e-01, time/batch = 0.8937s	
10687/30300 (epoch 17.635), train_loss = 1.30681686, grad/param norm = 1.4388e-01, time/batch = 1.0208s	
10688/30300 (epoch 17.637), train_loss = 1.33922678, grad/param norm = 1.6732e-01, time/batch = 1.0112s	
10689/30300 (epoch 17.639), train_loss = 1.20452707, grad/param norm = 1.4314e-01, time/batch = 1.0094s	
10690/30300 (epoch 17.640), train_loss = 1.39255965, grad/param norm = 1.5875e-01, time/batch = 1.0018s	
10691/30300 (epoch 17.642), train_loss = 1.21752490, grad/param norm = 1.3032e-01, time/batch = 1.5797s	
10692/30300 (epoch 17.644), train_loss = 1.33113970, grad/param norm = 1.3827e-01, time/batch = 1.8838s	
10693/30300 (epoch 17.645), train_loss = 1.13440653, grad/param norm = 1.3400e-01, time/batch = 1.8594s	
10694/30300 (epoch 17.647), train_loss = 1.24667070, grad/param norm = 1.4380e-01, time/batch = 19.3814s	
10695/30300 (epoch 17.649), train_loss = 1.22254630, grad/param norm = 1.5243e-01, time/batch = 19.3703s	
10696/30300 (epoch 17.650), train_loss = 1.22652715, grad/param norm = 1.3267e-01, time/batch = 18.7969s	
10697/30300 (epoch 17.652), train_loss = 1.20038753, grad/param norm = 1.3505e-01, time/batch = 17.3496s	
10698/30300 (epoch 17.653), train_loss = 1.45802964, grad/param norm = 1.5385e-01, time/batch = 19.2343s	
10699/30300 (epoch 17.655), train_loss = 1.21263227, grad/param norm = 1.6140e-01, time/batch = 18.2939s	
10700/30300 (epoch 17.657), train_loss = 1.21837024, grad/param norm = 1.4454e-01, time/batch = 19.7072s	
10701/30300 (epoch 17.658), train_loss = 1.17982842, grad/param norm = 1.3885e-01, time/batch = 19.3997s	
10702/30300 (epoch 17.660), train_loss = 1.28657868, grad/param norm = 1.4929e-01, time/batch = 18.6281s	
10703/30300 (epoch 17.662), train_loss = 1.31634345, grad/param norm = 1.5911e-01, time/batch = 18.1088s	
10704/30300 (epoch 17.663), train_loss = 1.29816549, grad/param norm = 1.5225e-01, time/batch = 19.3857s	
10705/30300 (epoch 17.665), train_loss = 1.17738197, grad/param norm = 1.4911e-01, time/batch = 18.3897s	
10706/30300 (epoch 17.667), train_loss = 1.37258602, grad/param norm = 1.5036e-01, time/batch = 19.1387s	
10707/30300 (epoch 17.668), train_loss = 1.40432372, grad/param norm = 1.5394e-01, time/batch = 19.9526s	
10708/30300 (epoch 17.670), train_loss = 1.39116715, grad/param norm = 1.5501e-01, time/batch = 27.0134s	
10709/30300 (epoch 17.672), train_loss = 1.34157414, grad/param norm = 1.5310e-01, time/batch = 25.3222s	
10710/30300 (epoch 17.673), train_loss = 1.34765247, grad/param norm = 1.6138e-01, time/batch = 19.4548s	
10711/30300 (epoch 17.675), train_loss = 1.22990298, grad/param norm = 1.5573e-01, time/batch = 18.7906s	
10712/30300 (epoch 17.677), train_loss = 1.20874617, grad/param norm = 1.3906e-01, time/batch = 18.1248s	
10713/30300 (epoch 17.678), train_loss = 1.23067306, grad/param norm = 1.4959e-01, time/batch = 20.2166s	
10714/30300 (epoch 17.680), train_loss = 1.05010780, grad/param norm = 1.3185e-01, time/batch = 18.1991s	
10715/30300 (epoch 17.682), train_loss = 1.27039993, grad/param norm = 1.4552e-01, time/batch = 19.5326s	
10716/30300 (epoch 17.683), train_loss = 1.33567439, grad/param norm = 1.3130e-01, time/batch = 19.4524s	
10717/30300 (epoch 17.685), train_loss = 1.35563599, grad/param norm = 1.7757e-01, time/batch = 16.7052s	
10718/30300 (epoch 17.686), train_loss = 1.25068791, grad/param norm = 1.3754e-01, time/batch = 18.7807s	
10719/30300 (epoch 17.688), train_loss = 1.25992115, grad/param norm = 1.3744e-01, time/batch = 19.7763s	
10720/30300 (epoch 17.690), train_loss = 1.21145546, grad/param norm = 1.5486e-01, time/batch = 18.3901s	
10721/30300 (epoch 17.691), train_loss = 1.30972605, grad/param norm = 1.4233e-01, time/batch = 19.6313s	
10722/30300 (epoch 17.693), train_loss = 1.65520526, grad/param norm = 1.8247e-01, time/batch = 18.4571s	
10723/30300 (epoch 17.695), train_loss = 1.42585095, grad/param norm = 1.8343e-01, time/batch = 17.9649s	
10724/30300 (epoch 17.696), train_loss = 1.35710736, grad/param norm = 1.6901e-01, time/batch = 18.9548s	
10725/30300 (epoch 17.698), train_loss = 1.22048613, grad/param norm = 1.4388e-01, time/batch = 20.0535s	
10726/30300 (epoch 17.700), train_loss = 1.21225719, grad/param norm = 1.4836e-01, time/batch = 16.5427s	
10727/30300 (epoch 17.701), train_loss = 1.09136444, grad/param norm = 1.3650e-01, time/batch = 19.8747s	
10728/30300 (epoch 17.703), train_loss = 1.26670119, grad/param norm = 1.3287e-01, time/batch = 18.6205s	
10729/30300 (epoch 17.705), train_loss = 1.23991945, grad/param norm = 1.5462e-01, time/batch = 19.6093s	
10730/30300 (epoch 17.706), train_loss = 1.33744208, grad/param norm = 1.5469e-01, time/batch = 18.6898s	
10731/30300 (epoch 17.708), train_loss = 1.24695973, grad/param norm = 1.4742e-01, time/batch = 19.6423s	
10732/30300 (epoch 17.710), train_loss = 1.24364463, grad/param norm = 1.4903e-01, time/batch = 19.8005s	
10733/30300 (epoch 17.711), train_loss = 1.15495863, grad/param norm = 1.3488e-01, time/batch = 18.3596s	
10734/30300 (epoch 17.713), train_loss = 1.15604246, grad/param norm = 1.3557e-01, time/batch = 19.5529s	
10735/30300 (epoch 17.715), train_loss = 1.20655636, grad/param norm = 1.4015e-01, time/batch = 19.2227s	
10736/30300 (epoch 17.716), train_loss = 1.38178656, grad/param norm = 1.5868e-01, time/batch = 18.6429s	
10737/30300 (epoch 17.718), train_loss = 1.39577136, grad/param norm = 1.6336e-01, time/batch = 19.6525s	
10738/30300 (epoch 17.719), train_loss = 1.23307247, grad/param norm = 1.6354e-01, time/batch = 18.5478s	
10739/30300 (epoch 17.721), train_loss = 1.28971137, grad/param norm = 1.6648e-01, time/batch = 16.7998s	
10740/30300 (epoch 17.723), train_loss = 1.20609714, grad/param norm = 1.5664e-01, time/batch = 19.7100s	
10741/30300 (epoch 17.724), train_loss = 1.33641722, grad/param norm = 1.8295e-01, time/batch = 20.1312s	
10742/30300 (epoch 17.726), train_loss = 1.67649276, grad/param norm = 1.8190e-01, time/batch = 18.3649s	
10743/30300 (epoch 17.728), train_loss = 1.33391183, grad/param norm = 1.6340e-01, time/batch = 20.1222s	
10744/30300 (epoch 17.729), train_loss = 1.24017018, grad/param norm = 1.5703e-01, time/batch = 19.2158s	
10745/30300 (epoch 17.731), train_loss = 1.34115911, grad/param norm = 1.5685e-01, time/batch = 17.2112s	
10746/30300 (epoch 17.733), train_loss = 1.25245104, grad/param norm = 1.4508e-01, time/batch = 19.1238s	
10747/30300 (epoch 17.734), train_loss = 1.33155000, grad/param norm = 1.4526e-01, time/batch = 17.6350s	
10748/30300 (epoch 17.736), train_loss = 1.25708852, grad/param norm = 1.3772e-01, time/batch = 19.0340s	
10749/30300 (epoch 17.738), train_loss = 1.15446702, grad/param norm = 1.3040e-01, time/batch = 18.6237s	
10750/30300 (epoch 17.739), train_loss = 1.31680763, grad/param norm = 1.4156e-01, time/batch = 20.0504s	
10751/30300 (epoch 17.741), train_loss = 1.38453141, grad/param norm = 1.3864e-01, time/batch = 15.3713s	
10752/30300 (epoch 17.743), train_loss = 1.22659617, grad/param norm = 1.3905e-01, time/batch = 17.6833s	
10753/30300 (epoch 17.744), train_loss = 1.31318701, grad/param norm = 1.4872e-01, time/batch = 19.5496s	
10754/30300 (epoch 17.746), train_loss = 1.15350236, grad/param norm = 1.3749e-01, time/batch = 19.1348s	
10755/30300 (epoch 17.748), train_loss = 1.29765339, grad/param norm = 1.6693e-01, time/batch = 18.2804s	
10756/30300 (epoch 17.749), train_loss = 1.31287677, grad/param norm = 1.5378e-01, time/batch = 19.8754s	
10757/30300 (epoch 17.751), train_loss = 1.23995704, grad/param norm = 1.3938e-01, time/batch = 19.1196s	
10758/30300 (epoch 17.752), train_loss = 1.24685687, grad/param norm = 1.5252e-01, time/batch = 18.1246s	
10759/30300 (epoch 17.754), train_loss = 1.17604773, grad/param norm = 1.3710e-01, time/batch = 18.1970s	
10760/30300 (epoch 17.756), train_loss = 1.24135236, grad/param norm = 1.4647e-01, time/batch = 18.1859s	
10761/30300 (epoch 17.757), train_loss = 1.31358662, grad/param norm = 1.5917e-01, time/batch = 19.0393s	
10762/30300 (epoch 17.759), train_loss = 1.27905841, grad/param norm = 1.3370e-01, time/batch = 17.0964s	
10763/30300 (epoch 17.761), train_loss = 1.11229111, grad/param norm = 1.3414e-01, time/batch = 16.4656s	
10764/30300 (epoch 17.762), train_loss = 1.11408965, grad/param norm = 1.3046e-01, time/batch = 19.2782s	
10765/30300 (epoch 17.764), train_loss = 1.23139912, grad/param norm = 1.4263e-01, time/batch = 17.7933s	
10766/30300 (epoch 17.766), train_loss = 1.30693187, grad/param norm = 1.4674e-01, time/batch = 19.7131s	
10767/30300 (epoch 17.767), train_loss = 1.33495026, grad/param norm = 1.6631e-01, time/batch = 18.3942s	
10768/30300 (epoch 17.769), train_loss = 1.33674787, grad/param norm = 1.5264e-01, time/batch = 18.0277s	
10769/30300 (epoch 17.771), train_loss = 1.23271072, grad/param norm = 1.6513e-01, time/batch = 18.8802s	
10770/30300 (epoch 17.772), train_loss = 1.31796154, grad/param norm = 1.5201e-01, time/batch = 19.3497s	
10771/30300 (epoch 17.774), train_loss = 1.42861594, grad/param norm = 1.4610e-01, time/batch = 17.4359s	
10772/30300 (epoch 17.776), train_loss = 1.30443890, grad/param norm = 1.5843e-01, time/batch = 19.5436s	
10773/30300 (epoch 17.777), train_loss = 1.32842764, grad/param norm = 1.4899e-01, time/batch = 19.1437s	
10774/30300 (epoch 17.779), train_loss = 1.45614481, grad/param norm = 1.7323e-01, time/batch = 17.6929s	
10775/30300 (epoch 17.781), train_loss = 1.27813531, grad/param norm = 1.6857e-01, time/batch = 18.8053s	
10776/30300 (epoch 17.782), train_loss = 1.21728985, grad/param norm = 1.4926e-01, time/batch = 18.7205s	
10777/30300 (epoch 17.784), train_loss = 1.19384997, grad/param norm = 1.3561e-01, time/batch = 18.3700s	
10778/30300 (epoch 17.785), train_loss = 1.43903777, grad/param norm = 1.6331e-01, time/batch = 18.5237s	
10779/30300 (epoch 17.787), train_loss = 1.10984394, grad/param norm = 1.4191e-01, time/batch = 18.5488s	
10780/30300 (epoch 17.789), train_loss = 1.51814825, grad/param norm = 1.5536e-01, time/batch = 19.8752s	
10781/30300 (epoch 17.790), train_loss = 1.36707593, grad/param norm = 1.6815e-01, time/batch = 18.3727s	
10782/30300 (epoch 17.792), train_loss = 1.10884798, grad/param norm = 1.6052e-01, time/batch = 19.7155s	
10783/30300 (epoch 17.794), train_loss = 1.24894713, grad/param norm = 1.5323e-01, time/batch = 17.3793s	
10784/30300 (epoch 17.795), train_loss = 1.19256522, grad/param norm = 1.2938e-01, time/batch = 18.3610s	
10785/30300 (epoch 17.797), train_loss = 1.44634697, grad/param norm = 1.7155e-01, time/batch = 18.9667s	
10786/30300 (epoch 17.799), train_loss = 1.34232905, grad/param norm = 1.5506e-01, time/batch = 18.7148s	
10787/30300 (epoch 17.800), train_loss = 1.35229791, grad/param norm = 1.5720e-01, time/batch = 18.2766s	
10788/30300 (epoch 17.802), train_loss = 1.51561690, grad/param norm = 1.6252e-01, time/batch = 19.2854s	
10789/30300 (epoch 17.804), train_loss = 1.34591007, grad/param norm = 1.6398e-01, time/batch = 18.4248s	
10790/30300 (epoch 17.805), train_loss = 1.44032076, grad/param norm = 1.6450e-01, time/batch = 18.6197s	
10791/30300 (epoch 17.807), train_loss = 1.26512191, grad/param norm = 1.5485e-01, time/batch = 19.2111s	
10792/30300 (epoch 17.809), train_loss = 1.37845351, grad/param norm = 1.6733e-01, time/batch = 15.8598s	
10793/30300 (epoch 17.810), train_loss = 1.36470293, grad/param norm = 1.4698e-01, time/batch = 16.4159s	
10794/30300 (epoch 17.812), train_loss = 1.20235372, grad/param norm = 1.5166e-01, time/batch = 15.8461s	
10795/30300 (epoch 17.814), train_loss = 1.29743320, grad/param norm = 1.5933e-01, time/batch = 15.4577s	
10796/30300 (epoch 17.815), train_loss = 1.32241741, grad/param norm = 1.6803e-01, time/batch = 17.1373s	
10797/30300 (epoch 17.817), train_loss = 1.38216317, grad/param norm = 1.5784e-01, time/batch = 18.8023s	
10798/30300 (epoch 17.818), train_loss = 1.33849743, grad/param norm = 1.4315e-01, time/batch = 18.8652s	
10799/30300 (epoch 17.820), train_loss = 1.46681750, grad/param norm = 1.5850e-01, time/batch = 19.5448s	
10800/30300 (epoch 17.822), train_loss = 1.46529848, grad/param norm = 1.6490e-01, time/batch = 19.2801s	
10801/30300 (epoch 17.823), train_loss = 1.50408580, grad/param norm = 1.6446e-01, time/batch = 19.1019s	
10802/30300 (epoch 17.825), train_loss = 1.39871382, grad/param norm = 1.5557e-01, time/batch = 19.6277s	
10803/30300 (epoch 17.827), train_loss = 1.15670229, grad/param norm = 1.5920e-01, time/batch = 18.7097s	
10804/30300 (epoch 17.828), train_loss = 1.34811590, grad/param norm = 1.5628e-01, time/batch = 18.2842s	
10805/30300 (epoch 17.830), train_loss = 1.31529020, grad/param norm = 1.5632e-01, time/batch = 19.5384s	
10806/30300 (epoch 17.832), train_loss = 1.21470860, grad/param norm = 1.5303e-01, time/batch = 18.7992s	
10807/30300 (epoch 17.833), train_loss = 1.36305153, grad/param norm = 1.5347e-01, time/batch = 16.6010s	
10808/30300 (epoch 17.835), train_loss = 1.21878700, grad/param norm = 1.4831e-01, time/batch = 16.5441s	
10809/30300 (epoch 17.837), train_loss = 1.13066020, grad/param norm = 1.3650e-01, time/batch = 18.3934s	
10810/30300 (epoch 17.838), train_loss = 1.14837774, grad/param norm = 1.4155e-01, time/batch = 16.9465s	
10811/30300 (epoch 17.840), train_loss = 1.34510788, grad/param norm = 1.3221e-01, time/batch = 19.2806s	
10812/30300 (epoch 17.842), train_loss = 1.18734369, grad/param norm = 1.2740e-01, time/batch = 19.2929s	
10813/30300 (epoch 17.843), train_loss = 1.32482092, grad/param norm = 1.4927e-01, time/batch = 19.3609s	
10814/30300 (epoch 17.845), train_loss = 1.30006235, grad/param norm = 1.3941e-01, time/batch = 18.8829s	
10815/30300 (epoch 17.847), train_loss = 1.31443219, grad/param norm = 1.5627e-01, time/batch = 19.5412s	
10816/30300 (epoch 17.848), train_loss = 1.39385117, grad/param norm = 1.5345e-01, time/batch = 19.0354s	
10817/30300 (epoch 17.850), train_loss = 1.28304160, grad/param norm = 1.4801e-01, time/batch = 18.5347s	
10818/30300 (epoch 17.851), train_loss = 1.34204446, grad/param norm = 1.6791e-01, time/batch = 20.2930s	
10819/30300 (epoch 17.853), train_loss = 1.22315860, grad/param norm = 1.3262e-01, time/batch = 17.9695s	
10820/30300 (epoch 17.855), train_loss = 1.21057855, grad/param norm = 1.2900e-01, time/batch = 18.6963s	
10821/30300 (epoch 17.856), train_loss = 1.27004491, grad/param norm = 1.5246e-01, time/batch = 19.4637s	
10822/30300 (epoch 17.858), train_loss = 1.24179033, grad/param norm = 1.3349e-01, time/batch = 19.3018s	
10823/30300 (epoch 17.860), train_loss = 1.20117145, grad/param norm = 1.4808e-01, time/batch = 17.5367s	
10824/30300 (epoch 17.861), train_loss = 1.45035494, grad/param norm = 1.5060e-01, time/batch = 19.1107s	
10825/30300 (epoch 17.863), train_loss = 1.30087357, grad/param norm = 1.3940e-01, time/batch = 19.7947s	
10826/30300 (epoch 17.865), train_loss = 1.39096680, grad/param norm = 1.5914e-01, time/batch = 17.8627s	
10827/30300 (epoch 17.866), train_loss = 1.36290940, grad/param norm = 1.6165e-01, time/batch = 19.5401s	
10828/30300 (epoch 17.868), train_loss = 1.27201723, grad/param norm = 1.4750e-01, time/batch = 19.1317s	
10829/30300 (epoch 17.870), train_loss = 1.21387034, grad/param norm = 1.4382e-01, time/batch = 19.5500s	
10830/30300 (epoch 17.871), train_loss = 1.23247594, grad/param norm = 1.3771e-01, time/batch = 17.8503s	
10831/30300 (epoch 17.873), train_loss = 1.28067526, grad/param norm = 1.4008e-01, time/batch = 18.5462s	
10832/30300 (epoch 17.875), train_loss = 1.18176166, grad/param norm = 1.3511e-01, time/batch = 19.1097s	
10833/30300 (epoch 17.876), train_loss = 1.18429053, grad/param norm = 1.5239e-01, time/batch = 19.1245s	
10834/30300 (epoch 17.878), train_loss = 1.08781449, grad/param norm = 1.4514e-01, time/batch = 19.5432s	
10835/30300 (epoch 17.880), train_loss = 1.18374724, grad/param norm = 1.4637e-01, time/batch = 18.2023s	
10836/30300 (epoch 17.881), train_loss = 1.47155869, grad/param norm = 1.6065e-01, time/batch = 18.7936s	
10837/30300 (epoch 17.883), train_loss = 1.34735445, grad/param norm = 1.6204e-01, time/batch = 19.3805s	
10838/30300 (epoch 17.884), train_loss = 1.17005949, grad/param norm = 1.2437e-01, time/batch = 19.4684s	
10839/30300 (epoch 17.886), train_loss = 1.29512129, grad/param norm = 1.3871e-01, time/batch = 17.6078s	
10840/30300 (epoch 17.888), train_loss = 1.28878995, grad/param norm = 1.4735e-01, time/batch = 18.5371s	
10841/30300 (epoch 17.889), train_loss = 1.30307974, grad/param norm = 1.4387e-01, time/batch = 19.6213s	
10842/30300 (epoch 17.891), train_loss = 1.29688580, grad/param norm = 1.5533e-01, time/batch = 17.1220s	
10843/30300 (epoch 17.893), train_loss = 1.53082811, grad/param norm = 1.5568e-01, time/batch = 19.8789s	
10844/30300 (epoch 17.894), train_loss = 1.38469573, grad/param norm = 1.4661e-01, time/batch = 20.1292s	
10845/30300 (epoch 17.896), train_loss = 1.11232762, grad/param norm = 1.3860e-01, time/batch = 18.1336s	
10846/30300 (epoch 17.898), train_loss = 1.07119062, grad/param norm = 1.4289e-01, time/batch = 19.9594s	
10847/30300 (epoch 17.899), train_loss = 1.21223008, grad/param norm = 1.5138e-01, time/batch = 19.7046s	
10848/30300 (epoch 17.901), train_loss = 1.26042565, grad/param norm = 1.5309e-01, time/batch = 18.0471s	
10849/30300 (epoch 17.903), train_loss = 1.30991126, grad/param norm = 1.4728e-01, time/batch = 19.3739s	
10850/30300 (epoch 17.904), train_loss = 1.24378645, grad/param norm = 1.5365e-01, time/batch = 17.8151s	
10851/30300 (epoch 17.906), train_loss = 1.40367624, grad/param norm = 1.5907e-01, time/batch = 17.6133s	
10852/30300 (epoch 17.908), train_loss = 1.21144081, grad/param norm = 1.3868e-01, time/batch = 17.5366s	
10853/30300 (epoch 17.909), train_loss = 1.22075682, grad/param norm = 1.7331e-01, time/batch = 18.9483s	
10854/30300 (epoch 17.911), train_loss = 1.26328495, grad/param norm = 1.3727e-01, time/batch = 18.5252s	
10855/30300 (epoch 17.913), train_loss = 1.27247762, grad/param norm = 1.4290e-01, time/batch = 18.9401s	
10856/30300 (epoch 17.914), train_loss = 1.23686470, grad/param norm = 1.5754e-01, time/batch = 19.3780s	
10857/30300 (epoch 17.916), train_loss = 1.28489798, grad/param norm = 1.3581e-01, time/batch = 18.3072s	
10858/30300 (epoch 17.917), train_loss = 1.19628928, grad/param norm = 1.4085e-01, time/batch = 17.8683s	
10859/30300 (epoch 17.919), train_loss = 1.23356773, grad/param norm = 1.5233e-01, time/batch = 18.8007s	
10860/30300 (epoch 17.921), train_loss = 1.27549169, grad/param norm = 1.4856e-01, time/batch = 18.9824s	
10861/30300 (epoch 17.922), train_loss = 1.36794571, grad/param norm = 1.5761e-01, time/batch = 18.4579s	
10862/30300 (epoch 17.924), train_loss = 1.28046152, grad/param norm = 1.6305e-01, time/batch = 19.2127s	
10863/30300 (epoch 17.926), train_loss = 1.28452463, grad/param norm = 1.5195e-01, time/batch = 19.7092s	
10864/30300 (epoch 17.927), train_loss = 1.26795055, grad/param norm = 1.5389e-01, time/batch = 17.6316s	
10865/30300 (epoch 17.929), train_loss = 1.21711598, grad/param norm = 1.4600e-01, time/batch = 17.0393s	
10866/30300 (epoch 17.931), train_loss = 1.40524140, grad/param norm = 1.7151e-01, time/batch = 19.6231s	
10867/30300 (epoch 17.932), train_loss = 1.22185313, grad/param norm = 1.4940e-01, time/batch = 18.5345s	
10868/30300 (epoch 17.934), train_loss = 1.30226735, grad/param norm = 1.5688e-01, time/batch = 18.6120s	
10869/30300 (epoch 17.936), train_loss = 1.23169969, grad/param norm = 1.4206e-01, time/batch = 19.7936s	
10870/30300 (epoch 17.937), train_loss = 1.20011852, grad/param norm = 1.4645e-01, time/batch = 18.0473s	
10871/30300 (epoch 17.939), train_loss = 1.38937397, grad/param norm = 1.4931e-01, time/batch = 18.8550s	
10872/30300 (epoch 17.941), train_loss = 1.25532391, grad/param norm = 1.5538e-01, time/batch = 18.2881s	
10873/30300 (epoch 17.942), train_loss = 1.26560658, grad/param norm = 1.4608e-01, time/batch = 16.2284s	
10874/30300 (epoch 17.944), train_loss = 1.16811081, grad/param norm = 1.3629e-01, time/batch = 17.1027s	
10875/30300 (epoch 17.946), train_loss = 1.39959512, grad/param norm = 1.7276e-01, time/batch = 19.3726s	
10876/30300 (epoch 17.947), train_loss = 1.41475740, grad/param norm = 1.9666e-01, time/batch = 18.6177s	
10877/30300 (epoch 17.949), train_loss = 1.45228996, grad/param norm = 1.6940e-01, time/batch = 14.8173s	
10878/30300 (epoch 17.950), train_loss = 1.40074280, grad/param norm = 1.5900e-01, time/batch = 14.9693s	
10879/30300 (epoch 17.952), train_loss = 1.34739035, grad/param norm = 1.6451e-01, time/batch = 14.8879s	
10880/30300 (epoch 17.954), train_loss = 1.54004247, grad/param norm = 1.5152e-01, time/batch = 18.5986s	
10881/30300 (epoch 17.955), train_loss = 1.23132915, grad/param norm = 1.5606e-01, time/batch = 16.3623s	
10882/30300 (epoch 17.957), train_loss = 1.33543862, grad/param norm = 1.5153e-01, time/batch = 19.7081s	
10883/30300 (epoch 17.959), train_loss = 1.24653976, grad/param norm = 1.5475e-01, time/batch = 19.8843s	
10884/30300 (epoch 17.960), train_loss = 1.25232921, grad/param norm = 1.5339e-01, time/batch = 15.8554s	
10885/30300 (epoch 17.962), train_loss = 1.25728150, grad/param norm = 1.8019e-01, time/batch = 18.5476s	
10886/30300 (epoch 17.964), train_loss = 1.19829304, grad/param norm = 1.6097e-01, time/batch = 18.5485s	
10887/30300 (epoch 17.965), train_loss = 1.18672226, grad/param norm = 1.5242e-01, time/batch = 19.3673s	
10888/30300 (epoch 17.967), train_loss = 1.28013676, grad/param norm = 1.6457e-01, time/batch = 18.3712s	
10889/30300 (epoch 17.969), train_loss = 1.20359084, grad/param norm = 1.7229e-01, time/batch = 19.2262s	
10890/30300 (epoch 17.970), train_loss = 1.25260410, grad/param norm = 1.5615e-01, time/batch = 19.3789s	
10891/30300 (epoch 17.972), train_loss = 1.16582763, grad/param norm = 1.5251e-01, time/batch = 18.9402s	
10892/30300 (epoch 17.974), train_loss = 1.49489601, grad/param norm = 1.7063e-01, time/batch = 19.3833s	
10893/30300 (epoch 17.975), train_loss = 1.48963359, grad/param norm = 1.7911e-01, time/batch = 19.8003s	
10894/30300 (epoch 17.977), train_loss = 1.37852083, grad/param norm = 1.5333e-01, time/batch = 17.9546s	
10895/30300 (epoch 17.979), train_loss = 1.33503005, grad/param norm = 1.5463e-01, time/batch = 19.7121s	
10896/30300 (epoch 17.980), train_loss = 1.36460475, grad/param norm = 1.6835e-01, time/batch = 18.6090s	
10897/30300 (epoch 17.982), train_loss = 1.38199917, grad/param norm = 1.6212e-01, time/batch = 17.6418s	
10898/30300 (epoch 17.983), train_loss = 1.41771362, grad/param norm = 1.5885e-01, time/batch = 19.8595s	
10899/30300 (epoch 17.985), train_loss = 1.31570613, grad/param norm = 1.6418e-01, time/batch = 18.7825s	
10900/30300 (epoch 17.987), train_loss = 1.24688975, grad/param norm = 1.3904e-01, time/batch = 27.0756s	
10901/30300 (epoch 17.988), train_loss = 1.45124812, grad/param norm = 1.6043e-01, time/batch = 23.2498s	
10902/30300 (epoch 17.990), train_loss = 1.11665724, grad/param norm = 1.3671e-01, time/batch = 16.7794s	
10903/30300 (epoch 17.992), train_loss = 1.33186514, grad/param norm = 1.3700e-01, time/batch = 18.4302s	
10904/30300 (epoch 17.993), train_loss = 1.42850844, grad/param norm = 1.7758e-01, time/batch = 18.8719s	
10905/30300 (epoch 17.995), train_loss = 1.27796304, grad/param norm = 1.7124e-01, time/batch = 18.4565s	
10906/30300 (epoch 17.997), train_loss = 1.31966260, grad/param norm = 1.6843e-01, time/batch = 16.4578s	
10907/30300 (epoch 17.998), train_loss = 1.37976815, grad/param norm = 1.7139e-01, time/batch = 17.6888s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
10908/30300 (epoch 18.000), train_loss = 1.24517543, grad/param norm = 1.5834e-01, time/batch = 18.0957s	
10909/30300 (epoch 18.002), train_loss = 1.37952131, grad/param norm = 1.6187e-01, time/batch = 17.5561s	
10910/30300 (epoch 18.003), train_loss = 1.30433552, grad/param norm = 1.6571e-01, time/batch = 18.2817s	
10911/30300 (epoch 18.005), train_loss = 1.27309688, grad/param norm = 1.5963e-01, time/batch = 18.7058s	
10912/30300 (epoch 18.007), train_loss = 1.38195615, grad/param norm = 1.7038e-01, time/batch = 19.5247s	
10913/30300 (epoch 18.008), train_loss = 1.22663301, grad/param norm = 1.6891e-01, time/batch = 17.8014s	
10914/30300 (epoch 18.010), train_loss = 1.17410112, grad/param norm = 1.5693e-01, time/batch = 18.8755s	
10915/30300 (epoch 18.012), train_loss = 1.23352688, grad/param norm = 1.5229e-01, time/batch = 19.2879s	
10916/30300 (epoch 18.013), train_loss = 1.37145957, grad/param norm = 1.5848e-01, time/batch = 17.4221s	
10917/30300 (epoch 18.015), train_loss = 1.24605432, grad/param norm = 1.4487e-01, time/batch = 18.1049s	
10918/30300 (epoch 18.017), train_loss = 1.19780669, grad/param norm = 1.3467e-01, time/batch = 19.5313s	
10919/30300 (epoch 18.018), train_loss = 1.19294251, grad/param norm = 1.3726e-01, time/batch = 16.6952s	
10920/30300 (epoch 18.020), train_loss = 1.39473044, grad/param norm = 2.0038e-01, time/batch = 18.8678s	
10921/30300 (epoch 18.021), train_loss = 1.41214189, grad/param norm = 1.8310e-01, time/batch = 19.9639s	
10922/30300 (epoch 18.023), train_loss = 1.25326058, grad/param norm = 1.4310e-01, time/batch = 18.7868s	
10923/30300 (epoch 18.025), train_loss = 1.20106673, grad/param norm = 1.5379e-01, time/batch = 19.2600s	
10924/30300 (epoch 18.026), train_loss = 1.32340674, grad/param norm = 1.7143e-01, time/batch = 19.2885s	
10925/30300 (epoch 18.028), train_loss = 1.36377085, grad/param norm = 1.4662e-01, time/batch = 17.8660s	
10926/30300 (epoch 18.030), train_loss = 1.21742730, grad/param norm = 1.4497e-01, time/batch = 17.1340s	
10927/30300 (epoch 18.031), train_loss = 1.30182636, grad/param norm = 1.5237e-01, time/batch = 19.4643s	
10928/30300 (epoch 18.033), train_loss = 1.29046820, grad/param norm = 1.7001e-01, time/batch = 19.3697s	
10929/30300 (epoch 18.035), train_loss = 1.37414289, grad/param norm = 1.5797e-01, time/batch = 18.0398s	
10930/30300 (epoch 18.036), train_loss = 1.28307110, grad/param norm = 1.6185e-01, time/batch = 20.2122s	
10931/30300 (epoch 18.038), train_loss = 1.31206840, grad/param norm = 1.5585e-01, time/batch = 19.2962s	
10932/30300 (epoch 18.040), train_loss = 1.02094683, grad/param norm = 1.3321e-01, time/batch = 18.1977s	
10933/30300 (epoch 18.041), train_loss = 1.07503278, grad/param norm = 1.2956e-01, time/batch = 19.0569s	
10934/30300 (epoch 18.043), train_loss = 1.29135858, grad/param norm = 1.5168e-01, time/batch = 19.0591s	
10935/30300 (epoch 18.045), train_loss = 1.25089446, grad/param norm = 1.4921e-01, time/batch = 18.8610s	
10936/30300 (epoch 18.046), train_loss = 1.42115453, grad/param norm = 1.7554e-01, time/batch = 19.7909s	
10937/30300 (epoch 18.048), train_loss = 1.27681350, grad/param norm = 1.7112e-01, time/batch = 18.8664s	
10938/30300 (epoch 18.050), train_loss = 1.27306300, grad/param norm = 1.6365e-01, time/batch = 17.1922s	
10939/30300 (epoch 18.051), train_loss = 1.31343532, grad/param norm = 1.6158e-01, time/batch = 19.6869s	
10940/30300 (epoch 18.053), train_loss = 1.10088228, grad/param norm = 1.6454e-01, time/batch = 17.8628s	
10941/30300 (epoch 18.054), train_loss = 1.24917359, grad/param norm = 1.4470e-01, time/batch = 17.4498s	
10942/30300 (epoch 18.056), train_loss = 1.19798379, grad/param norm = 1.4092e-01, time/batch = 17.8889s	
10943/30300 (epoch 18.058), train_loss = 1.24359531, grad/param norm = 1.4868e-01, time/batch = 19.4549s	
10944/30300 (epoch 18.059), train_loss = 1.17656084, grad/param norm = 1.5162e-01, time/batch = 19.4412s	
10945/30300 (epoch 18.061), train_loss = 1.37474519, grad/param norm = 1.5728e-01, time/batch = 18.9567s	
10946/30300 (epoch 18.063), train_loss = 1.19627618, grad/param norm = 1.6089e-01, time/batch = 19.1119s	
10947/30300 (epoch 18.064), train_loss = 1.30733223, grad/param norm = 1.5223e-01, time/batch = 19.0600s	
10948/30300 (epoch 18.066), train_loss = 1.26144253, grad/param norm = 1.4720e-01, time/batch = 18.6841s	
10949/30300 (epoch 18.068), train_loss = 1.15470420, grad/param norm = 1.4859e-01, time/batch = 20.3676s	
10950/30300 (epoch 18.069), train_loss = 1.33294884, grad/param norm = 1.5122e-01, time/batch = 19.5407s	
10951/30300 (epoch 18.071), train_loss = 1.33274594, grad/param norm = 1.6237e-01, time/batch = 19.0345s	
10952/30300 (epoch 18.073), train_loss = 1.27076590, grad/param norm = 1.6209e-01, time/batch = 19.6250s	
10953/30300 (epoch 18.074), train_loss = 1.31398675, grad/param norm = 1.3805e-01, time/batch = 18.8875s	
10954/30300 (epoch 18.076), train_loss = 1.24819011, grad/param norm = 1.4665e-01, time/batch = 17.6990s	
10955/30300 (epoch 18.078), train_loss = 1.16409373, grad/param norm = 1.4552e-01, time/batch = 19.5180s	
10956/30300 (epoch 18.079), train_loss = 1.20524116, grad/param norm = 1.3391e-01, time/batch = 18.7755s	
10957/30300 (epoch 18.081), train_loss = 1.28493406, grad/param norm = 1.4808e-01, time/batch = 18.4517s	
10958/30300 (epoch 18.083), train_loss = 1.36896048, grad/param norm = 1.5420e-01, time/batch = 17.5336s	
10959/30300 (epoch 18.084), train_loss = 1.17886030, grad/param norm = 1.5398e-01, time/batch = 19.3739s	
10960/30300 (epoch 18.086), train_loss = 1.21713784, grad/param norm = 1.5747e-01, time/batch = 17.8645s	
10961/30300 (epoch 18.087), train_loss = 1.18526870, grad/param norm = 1.4212e-01, time/batch = 19.6331s	
10962/30300 (epoch 18.089), train_loss = 1.23796346, grad/param norm = 1.5279e-01, time/batch = 19.4732s	
10963/30300 (epoch 18.091), train_loss = 1.30403708, grad/param norm = 1.5891e-01, time/batch = 18.9533s	
10964/30300 (epoch 18.092), train_loss = 1.29965551, grad/param norm = 1.4830e-01, time/batch = 18.6983s	
10965/30300 (epoch 18.094), train_loss = 1.45381958, grad/param norm = 1.7641e-01, time/batch = 20.4600s	
10966/30300 (epoch 18.096), train_loss = 1.37620925, grad/param norm = 1.5714e-01, time/batch = 18.2004s	
10967/30300 (epoch 18.097), train_loss = 1.23573500, grad/param norm = 1.5205e-01, time/batch = 18.6271s	
10968/30300 (epoch 18.099), train_loss = 1.39272029, grad/param norm = 1.6009e-01, time/batch = 20.0505s	
10969/30300 (epoch 18.101), train_loss = 1.44649352, grad/param norm = 1.7216e-01, time/batch = 17.7756s	
10970/30300 (epoch 18.102), train_loss = 1.20111550, grad/param norm = 1.6898e-01, time/batch = 17.9511s	
10971/30300 (epoch 18.104), train_loss = 1.24291824, grad/param norm = 1.8260e-01, time/batch = 19.8005s	
10972/30300 (epoch 18.106), train_loss = 1.27624422, grad/param norm = 1.7393e-01, time/batch = 20.2870s	
10973/30300 (epoch 18.107), train_loss = 1.30089224, grad/param norm = 1.4886e-01, time/batch = 17.5336s	
10974/30300 (epoch 18.109), train_loss = 1.38653225, grad/param norm = 1.7722e-01, time/batch = 20.1242s	
10975/30300 (epoch 18.111), train_loss = 1.41190130, grad/param norm = 1.6143e-01, time/batch = 19.2998s	
10976/30300 (epoch 18.112), train_loss = 1.33256950, grad/param norm = 1.4423e-01, time/batch = 18.4497s	
10977/30300 (epoch 18.114), train_loss = 1.29247228, grad/param norm = 1.4776e-01, time/batch = 18.7796s	
10978/30300 (epoch 18.116), train_loss = 1.28902515, grad/param norm = 1.6547e-01, time/batch = 18.6934s	
10979/30300 (epoch 18.117), train_loss = 1.30557564, grad/param norm = 1.3630e-01, time/batch = 17.1970s	
10980/30300 (epoch 18.119), train_loss = 1.21037540, grad/param norm = 1.5139e-01, time/batch = 19.1361s	
10981/30300 (epoch 18.120), train_loss = 1.28312426, grad/param norm = 1.5532e-01, time/batch = 19.2853s	
10982/30300 (epoch 18.122), train_loss = 1.37562200, grad/param norm = 1.8099e-01, time/batch = 18.8757s	
10983/30300 (epoch 18.124), train_loss = 1.46025147, grad/param norm = 1.7757e-01, time/batch = 18.8037s	
10984/30300 (epoch 18.125), train_loss = 1.14554917, grad/param norm = 1.3858e-01, time/batch = 19.9489s	
10985/30300 (epoch 18.127), train_loss = 1.29769393, grad/param norm = 1.6632e-01, time/batch = 19.1291s	
10986/30300 (epoch 18.129), train_loss = 1.42955916, grad/param norm = 1.4902e-01, time/batch = 17.7081s	
10987/30300 (epoch 18.130), train_loss = 1.41464475, grad/param norm = 1.4327e-01, time/batch = 19.8723s	
10988/30300 (epoch 18.132), train_loss = 1.36533167, grad/param norm = 1.6522e-01, time/batch = 19.4570s	
10989/30300 (epoch 18.134), train_loss = 1.18514520, grad/param norm = 1.5062e-01, time/batch = 18.7074s	
10990/30300 (epoch 18.135), train_loss = 1.21624391, grad/param norm = 1.5338e-01, time/batch = 18.8030s	
10991/30300 (epoch 18.137), train_loss = 1.29262440, grad/param norm = 1.4559e-01, time/batch = 19.6204s	
10992/30300 (epoch 18.139), train_loss = 1.23728403, grad/param norm = 1.5891e-01, time/batch = 18.5571s	
10993/30300 (epoch 18.140), train_loss = 1.33164095, grad/param norm = 1.8045e-01, time/batch = 19.6293s	
10994/30300 (epoch 18.142), train_loss = 1.45072110, grad/param norm = 1.7696e-01, time/batch = 20.0506s	
10995/30300 (epoch 18.144), train_loss = 1.29028944, grad/param norm = 1.6856e-01, time/batch = 18.5270s	
10996/30300 (epoch 18.145), train_loss = 1.39939152, grad/param norm = 2.0618e-01, time/batch = 19.5419s	
10997/30300 (epoch 18.147), train_loss = 1.27258607, grad/param norm = 1.7862e-01, time/batch = 17.1391s	
10998/30300 (epoch 18.149), train_loss = 1.46398401, grad/param norm = 1.6408e-01, time/batch = 18.3655s	
10999/30300 (epoch 18.150), train_loss = 1.27903653, grad/param norm = 1.7602e-01, time/batch = 19.0337s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch18.15_1.7679.t7	
11000/30300 (epoch 18.152), train_loss = 1.16264729, grad/param norm = 1.5864e-01, time/batch = 18.8734s	
11001/30300 (epoch 18.153), train_loss = 1.74813801, grad/param norm = 2.4469e-01, time/batch = 19.7825s	
11002/30300 (epoch 18.155), train_loss = 1.11422714, grad/param norm = 1.3678e-01, time/batch = 19.5458s	
11003/30300 (epoch 18.157), train_loss = 1.28546482, grad/param norm = 2.0503e-01, time/batch = 18.9604s	
11004/30300 (epoch 18.158), train_loss = 1.28693756, grad/param norm = 1.6518e-01, time/batch = 17.1974s	
11005/30300 (epoch 18.160), train_loss = 1.22700788, grad/param norm = 1.6365e-01, time/batch = 19.9423s	
11006/30300 (epoch 18.162), train_loss = 1.26163574, grad/param norm = 1.4830e-01, time/batch = 19.6169s	
11007/30300 (epoch 18.163), train_loss = 1.21042661, grad/param norm = 1.5613e-01, time/batch = 18.7854s	
11008/30300 (epoch 18.165), train_loss = 1.38455625, grad/param norm = 1.6582e-01, time/batch = 18.2756s	
11009/30300 (epoch 18.167), train_loss = 1.29275680, grad/param norm = 1.6973e-01, time/batch = 20.3732s	
11010/30300 (epoch 18.168), train_loss = 1.32596745, grad/param norm = 1.4725e-01, time/batch = 16.7718s	
11011/30300 (epoch 18.170), train_loss = 1.33013070, grad/param norm = 1.7655e-01, time/batch = 18.2810s	
11012/30300 (epoch 18.172), train_loss = 1.24607085, grad/param norm = 1.5806e-01, time/batch = 19.7877s	
11013/30300 (epoch 18.173), train_loss = 1.30272626, grad/param norm = 1.6494e-01, time/batch = 18.5003s	
11014/30300 (epoch 18.175), train_loss = 1.28889438, grad/param norm = 1.4121e-01, time/batch = 19.1052s	
11015/30300 (epoch 18.177), train_loss = 1.32403519, grad/param norm = 1.8025e-01, time/batch = 19.8774s	
11016/30300 (epoch 18.178), train_loss = 1.05572637, grad/param norm = 1.4007e-01, time/batch = 18.9598s	
11017/30300 (epoch 18.180), train_loss = 1.23544994, grad/param norm = 1.4162e-01, time/batch = 18.5430s	
11018/30300 (epoch 18.182), train_loss = 1.22692188, grad/param norm = 1.5361e-01, time/batch = 19.7926s	
11019/30300 (epoch 18.183), train_loss = 1.19846517, grad/param norm = 1.4428e-01, time/batch = 18.3768s	
11020/30300 (epoch 18.185), train_loss = 1.49806744, grad/param norm = 1.5706e-01, time/batch = 19.1082s	
11021/30300 (epoch 18.186), train_loss = 1.54401567, grad/param norm = 1.7714e-01, time/batch = 19.1278s	
11022/30300 (epoch 18.188), train_loss = 1.34311543, grad/param norm = 1.6245e-01, time/batch = 19.0280s	
11023/30300 (epoch 18.190), train_loss = 1.24025122, grad/param norm = 1.4266e-01, time/batch = 18.4583s	
11024/30300 (epoch 18.191), train_loss = 1.35672960, grad/param norm = 1.5715e-01, time/batch = 19.6293s	
11025/30300 (epoch 18.193), train_loss = 1.18103638, grad/param norm = 1.3867e-01, time/batch = 18.6281s	
11026/30300 (epoch 18.195), train_loss = 1.31558400, grad/param norm = 1.5783e-01, time/batch = 18.3386s	
11027/30300 (epoch 18.196), train_loss = 1.30835951, grad/param norm = 1.3847e-01, time/batch = 17.6169s	
11028/30300 (epoch 18.198), train_loss = 1.09124823, grad/param norm = 1.5121e-01, time/batch = 19.5131s	
11029/30300 (epoch 18.200), train_loss = 1.26974480, grad/param norm = 1.3371e-01, time/batch = 17.2056s	
11030/30300 (epoch 18.201), train_loss = 1.38059060, grad/param norm = 1.6963e-01, time/batch = 18.8630s	
11031/30300 (epoch 18.203), train_loss = 1.31043201, grad/param norm = 1.5827e-01, time/batch = 20.3583s	
11032/30300 (epoch 18.205), train_loss = 1.48765354, grad/param norm = 1.6892e-01, time/batch = 18.4487s	
11033/30300 (epoch 18.206), train_loss = 1.42674108, grad/param norm = 1.7491e-01, time/batch = 19.7097s	
11034/30300 (epoch 18.208), train_loss = 1.40191116, grad/param norm = 1.7251e-01, time/batch = 19.2104s	
11035/30300 (epoch 18.210), train_loss = 1.33372434, grad/param norm = 1.6410e-01, time/batch = 17.8558s	
11036/30300 (epoch 18.211), train_loss = 1.40437337, grad/param norm = 1.5670e-01, time/batch = 18.7807s	
11037/30300 (epoch 18.213), train_loss = 1.23398387, grad/param norm = 1.4908e-01, time/batch = 19.6800s	
11038/30300 (epoch 18.215), train_loss = 1.16562514, grad/param norm = 1.5358e-01, time/batch = 15.6479s	
11039/30300 (epoch 18.216), train_loss = 1.24646341, grad/param norm = 1.6576e-01, time/batch = 16.2958s	
11040/30300 (epoch 18.218), train_loss = 1.16206332, grad/param norm = 1.3160e-01, time/batch = 15.5536s	
11041/30300 (epoch 18.219), train_loss = 1.09738349, grad/param norm = 1.2637e-01, time/batch = 15.1179s	
11042/30300 (epoch 18.221), train_loss = 1.12862465, grad/param norm = 1.4186e-01, time/batch = 16.6271s	
11043/30300 (epoch 18.223), train_loss = 1.29906979, grad/param norm = 1.4106e-01, time/batch = 15.4799s	
11044/30300 (epoch 18.224), train_loss = 1.09729513, grad/param norm = 1.3948e-01, time/batch = 16.4127s	
11045/30300 (epoch 18.226), train_loss = 1.38281324, grad/param norm = 1.7136e-01, time/batch = 19.1063s	
11046/30300 (epoch 18.228), train_loss = 1.37720196, grad/param norm = 1.5687e-01, time/batch = 17.5076s	
11047/30300 (epoch 18.229), train_loss = 1.21085038, grad/param norm = 1.5057e-01, time/batch = 17.8321s	
11048/30300 (epoch 18.231), train_loss = 1.32721856, grad/param norm = 1.6935e-01, time/batch = 16.0681s	
11049/30300 (epoch 18.233), train_loss = 1.25385277, grad/param norm = 1.4066e-01, time/batch = 16.3244s	
11050/30300 (epoch 18.234), train_loss = 1.33888135, grad/param norm = 1.6616e-01, time/batch = 19.1992s	
11051/30300 (epoch 18.236), train_loss = 1.27375678, grad/param norm = 1.3858e-01, time/batch = 19.4364s	
11052/30300 (epoch 18.238), train_loss = 1.34087325, grad/param norm = 1.6790e-01, time/batch = 17.6786s	
11053/30300 (epoch 18.239), train_loss = 1.32310778, grad/param norm = 1.5592e-01, time/batch = 18.0959s	
11054/30300 (epoch 18.241), train_loss = 1.30276521, grad/param norm = 1.5006e-01, time/batch = 19.3645s	
11055/30300 (epoch 18.243), train_loss = 1.35027626, grad/param norm = 1.5925e-01, time/batch = 19.1298s	
11056/30300 (epoch 18.244), train_loss = 1.52814445, grad/param norm = 1.6395e-01, time/batch = 18.2052s	
11057/30300 (epoch 18.246), train_loss = 1.27770807, grad/param norm = 1.4843e-01, time/batch = 18.6131s	
11058/30300 (epoch 18.248), train_loss = 1.26545814, grad/param norm = 1.5433e-01, time/batch = 17.2715s	
11059/30300 (epoch 18.249), train_loss = 1.20180724, grad/param norm = 1.4657e-01, time/batch = 16.8653s	
11060/30300 (epoch 18.251), train_loss = 1.19196786, grad/param norm = 1.5159e-01, time/batch = 19.2886s	
11061/30300 (epoch 18.252), train_loss = 1.39631758, grad/param norm = 1.5613e-01, time/batch = 19.9517s	
11062/30300 (epoch 18.254), train_loss = 1.38464702, grad/param norm = 1.6761e-01, time/batch = 18.2901s	
11063/30300 (epoch 18.256), train_loss = 1.32417623, grad/param norm = 1.5239e-01, time/batch = 19.2169s	
11064/30300 (epoch 18.257), train_loss = 1.34325482, grad/param norm = 1.5154e-01, time/batch = 18.6357s	
11065/30300 (epoch 18.259), train_loss = 1.27381992, grad/param norm = 1.4976e-01, time/batch = 18.3755s	
11066/30300 (epoch 18.261), train_loss = 1.38914164, grad/param norm = 1.5057e-01, time/batch = 18.7897s	
11067/30300 (epoch 18.262), train_loss = 1.28094441, grad/param norm = 1.5100e-01, time/batch = 17.3830s	
11068/30300 (epoch 18.264), train_loss = 1.28324027, grad/param norm = 1.4594e-01, time/batch = 18.6200s	
11069/30300 (epoch 18.266), train_loss = 1.22035830, grad/param norm = 1.4448e-01, time/batch = 18.0127s	
11070/30300 (epoch 18.267), train_loss = 1.46339321, grad/param norm = 1.6328e-01, time/batch = 18.5334s	
11071/30300 (epoch 18.269), train_loss = 1.31516120, grad/param norm = 1.6244e-01, time/batch = 20.0811s	
11072/30300 (epoch 18.271), train_loss = 1.30209398, grad/param norm = 1.6101e-01, time/batch = 18.3575s	
11073/30300 (epoch 18.272), train_loss = 1.30661199, grad/param norm = 1.6365e-01, time/batch = 19.2821s	
11074/30300 (epoch 18.274), train_loss = 1.41112778, grad/param norm = 1.5586e-01, time/batch = 19.7130s	
11075/30300 (epoch 18.276), train_loss = 1.34137197, grad/param norm = 1.6002e-01, time/batch = 18.2964s	
11076/30300 (epoch 18.277), train_loss = 1.18611487, grad/param norm = 1.5928e-01, time/batch = 19.3788s	
11077/30300 (epoch 18.279), train_loss = 1.33018468, grad/param norm = 1.8080e-01, time/batch = 17.6381s	
11078/30300 (epoch 18.281), train_loss = 1.37995255, grad/param norm = 1.8948e-01, time/batch = 18.3954s	
11079/30300 (epoch 18.282), train_loss = 1.28826597, grad/param norm = 1.4408e-01, time/batch = 19.7053s	
11080/30300 (epoch 18.284), train_loss = 1.47802975, grad/param norm = 1.9761e-01, time/batch = 19.5362s	
11081/30300 (epoch 18.285), train_loss = 1.31046753, grad/param norm = 1.3451e-01, time/batch = 18.7067s	
11082/30300 (epoch 18.287), train_loss = 1.29534733, grad/param norm = 1.6460e-01, time/batch = 16.9574s	
11083/30300 (epoch 18.289), train_loss = 1.34625625, grad/param norm = 1.4607e-01, time/batch = 18.6429s	
11084/30300 (epoch 18.290), train_loss = 1.04037315, grad/param norm = 1.3302e-01, time/batch = 19.3842s	
11085/30300 (epoch 18.292), train_loss = 1.16494926, grad/param norm = 1.3299e-01, time/batch = 32.4348s	
11086/30300 (epoch 18.294), train_loss = 1.41205415, grad/param norm = 1.6654e-01, time/batch = 19.7115s	
11087/30300 (epoch 18.295), train_loss = 1.26248715, grad/param norm = 1.4724e-01, time/batch = 17.5307s	
11088/30300 (epoch 18.297), train_loss = 1.20605715, grad/param norm = 1.3752e-01, time/batch = 18.4746s	
11089/30300 (epoch 18.299), train_loss = 1.26462548, grad/param norm = 1.5461e-01, time/batch = 18.4621s	
11090/30300 (epoch 18.300), train_loss = 1.24928840, grad/param norm = 1.5005e-01, time/batch = 18.4550s	
11091/30300 (epoch 18.302), train_loss = 1.27241498, grad/param norm = 1.4380e-01, time/batch = 18.5214s	
11092/30300 (epoch 18.304), train_loss = 1.20071205, grad/param norm = 1.4290e-01, time/batch = 19.1282s	
11093/30300 (epoch 18.305), train_loss = 1.24373205, grad/param norm = 1.4144e-01, time/batch = 16.9642s	
11094/30300 (epoch 18.307), train_loss = 1.31506977, grad/param norm = 1.3655e-01, time/batch = 17.9660s	
11095/30300 (epoch 18.309), train_loss = 1.35247017, grad/param norm = 1.5960e-01, time/batch = 18.3776s	
11096/30300 (epoch 18.310), train_loss = 1.27085626, grad/param norm = 1.5421e-01, time/batch = 19.7864s	
11097/30300 (epoch 18.312), train_loss = 1.42780791, grad/param norm = 1.5956e-01, time/batch = 17.1271s	
11098/30300 (epoch 18.314), train_loss = 1.31342236, grad/param norm = 1.5385e-01, time/batch = 19.7130s	
11099/30300 (epoch 18.315), train_loss = 1.30875359, grad/param norm = 1.5815e-01, time/batch = 19.6189s	
11100/30300 (epoch 18.317), train_loss = 1.35809850, grad/param norm = 1.4813e-01, time/batch = 17.6230s	
11101/30300 (epoch 18.318), train_loss = 1.42751018, grad/param norm = 1.7415e-01, time/batch = 18.7117s	
11102/30300 (epoch 18.320), train_loss = 1.37091354, grad/param norm = 1.5092e-01, time/batch = 19.3864s	
11103/30300 (epoch 18.322), train_loss = 1.21381728, grad/param norm = 1.5881e-01, time/batch = 17.2278s	
11104/30300 (epoch 18.323), train_loss = 1.38160466, grad/param norm = 1.5321e-01, time/batch = 18.4607s	
11105/30300 (epoch 18.325), train_loss = 1.24976277, grad/param norm = 1.4296e-01, time/batch = 19.3160s	
11106/30300 (epoch 18.327), train_loss = 1.28502878, grad/param norm = 1.4173e-01, time/batch = 18.8695s	
11107/30300 (epoch 18.328), train_loss = 1.27551345, grad/param norm = 1.4084e-01, time/batch = 17.8644s	
11108/30300 (epoch 18.330), train_loss = 1.33777245, grad/param norm = 1.4317e-01, time/batch = 18.1864s	
11109/30300 (epoch 18.332), train_loss = 1.36504682, grad/param norm = 1.5943e-01, time/batch = 15.5988s	
11110/30300 (epoch 18.333), train_loss = 1.27544019, grad/param norm = 1.5771e-01, time/batch = 16.8792s	
11111/30300 (epoch 18.335), train_loss = 1.15613711, grad/param norm = 1.4647e-01, time/batch = 19.1260s	
11112/30300 (epoch 18.337), train_loss = 1.44100978, grad/param norm = 1.5517e-01, time/batch = 17.2094s	
11113/30300 (epoch 18.338), train_loss = 1.19816841, grad/param norm = 1.3672e-01, time/batch = 17.8566s	
11114/30300 (epoch 18.340), train_loss = 1.17122359, grad/param norm = 1.3891e-01, time/batch = 19.2932s	
11115/30300 (epoch 18.342), train_loss = 1.37774851, grad/param norm = 1.5416e-01, time/batch = 19.7080s	
11116/30300 (epoch 18.343), train_loss = 1.31477101, grad/param norm = 1.4542e-01, time/batch = 18.9529s	
11117/30300 (epoch 18.345), train_loss = 1.32408853, grad/param norm = 1.5749e-01, time/batch = 19.0488s	
11118/30300 (epoch 18.347), train_loss = 1.13829249, grad/param norm = 1.5885e-01, time/batch = 18.7171s	
11119/30300 (epoch 18.348), train_loss = 1.17384885, grad/param norm = 1.4611e-01, time/batch = 19.9674s	
11120/30300 (epoch 18.350), train_loss = 1.27019761, grad/param norm = 1.4348e-01, time/batch = 18.3815s	
11121/30300 (epoch 18.351), train_loss = 1.27908686, grad/param norm = 1.5829e-01, time/batch = 19.9663s	
11122/30300 (epoch 18.353), train_loss = 1.09780314, grad/param norm = 1.4376e-01, time/batch = 18.0490s	
11123/30300 (epoch 18.355), train_loss = 1.22891729, grad/param norm = 1.4271e-01, time/batch = 18.4519s	
11124/30300 (epoch 18.356), train_loss = 1.35894395, grad/param norm = 1.8864e-01, time/batch = 19.3024s	
11125/30300 (epoch 18.358), train_loss = 1.51593466, grad/param norm = 1.4869e-01, time/batch = 19.6157s	
11126/30300 (epoch 18.360), train_loss = 1.23973278, grad/param norm = 1.5410e-01, time/batch = 18.0384s	
11127/30300 (epoch 18.361), train_loss = 1.32518454, grad/param norm = 1.5995e-01, time/batch = 18.0256s	
11128/30300 (epoch 18.363), train_loss = 1.36878997, grad/param norm = 1.6005e-01, time/batch = 19.2996s	
11129/30300 (epoch 18.365), train_loss = 1.19981651, grad/param norm = 1.5941e-01, time/batch = 17.9757s	
11130/30300 (epoch 18.366), train_loss = 1.22728669, grad/param norm = 1.4402e-01, time/batch = 20.1401s	
11131/30300 (epoch 18.368), train_loss = 1.11224910, grad/param norm = 1.4242e-01, time/batch = 20.1185s	
11132/30300 (epoch 18.370), train_loss = 1.16078453, grad/param norm = 1.4470e-01, time/batch = 17.6009s	
11133/30300 (epoch 18.371), train_loss = 1.35350393, grad/param norm = 1.5398e-01, time/batch = 19.4757s	
11134/30300 (epoch 18.373), train_loss = 1.18078016, grad/param norm = 1.2578e-01, time/batch = 20.1186s	
11135/30300 (epoch 18.375), train_loss = 1.17882830, grad/param norm = 1.2487e-01, time/batch = 18.5505s	
11136/30300 (epoch 18.376), train_loss = 1.20222856, grad/param norm = 1.3665e-01, time/batch = 19.6239s	
11137/30300 (epoch 18.378), train_loss = 1.20373384, grad/param norm = 1.5240e-01, time/batch = 19.0525s	
11138/30300 (epoch 18.380), train_loss = 1.44362517, grad/param norm = 1.5501e-01, time/batch = 19.0355s	
11139/30300 (epoch 18.381), train_loss = 1.13690361, grad/param norm = 1.3915e-01, time/batch = 19.4488s	
11140/30300 (epoch 18.383), train_loss = 1.22497885, grad/param norm = 1.6021e-01, time/batch = 16.6979s	
11141/30300 (epoch 18.384), train_loss = 1.35594680, grad/param norm = 1.5530e-01, time/batch = 19.6245s	
11142/30300 (epoch 18.386), train_loss = 1.17387215, grad/param norm = 1.6458e-01, time/batch = 17.8587s	
11143/30300 (epoch 18.388), train_loss = 1.11419294, grad/param norm = 1.3331e-01, time/batch = 20.1236s	
11144/30300 (epoch 18.389), train_loss = 1.25388388, grad/param norm = 1.5871e-01, time/batch = 20.0303s	
11145/30300 (epoch 18.391), train_loss = 1.31104444, grad/param norm = 1.5495e-01, time/batch = 17.8816s	
11146/30300 (epoch 18.393), train_loss = 1.11616923, grad/param norm = 1.3891e-01, time/batch = 19.1762s	
11147/30300 (epoch 18.394), train_loss = 1.31644160, grad/param norm = 1.4674e-01, time/batch = 19.8563s	
11148/30300 (epoch 18.396), train_loss = 1.41633170, grad/param norm = 1.4457e-01, time/batch = 17.2101s	
11149/30300 (epoch 18.398), train_loss = 1.24879511, grad/param norm = 1.3655e-01, time/batch = 18.6397s	
11150/30300 (epoch 18.399), train_loss = 1.23794981, grad/param norm = 1.4552e-01, time/batch = 18.3680s	
11151/30300 (epoch 18.401), train_loss = 1.30289045, grad/param norm = 1.4180e-01, time/batch = 18.6289s	
11152/30300 (epoch 18.403), train_loss = 1.23632036, grad/param norm = 1.6342e-01, time/batch = 19.3020s	
11153/30300 (epoch 18.404), train_loss = 1.17950407, grad/param norm = 1.5795e-01, time/batch = 19.5452s	
11154/30300 (epoch 18.406), train_loss = 1.28311587, grad/param norm = 1.4205e-01, time/batch = 18.3025s	
11155/30300 (epoch 18.408), train_loss = 1.13133778, grad/param norm = 1.3999e-01, time/batch = 18.9606s	
11156/30300 (epoch 18.409), train_loss = 1.14000892, grad/param norm = 1.5511e-01, time/batch = 18.2890s	
11157/30300 (epoch 18.411), train_loss = 1.14279971, grad/param norm = 1.3153e-01, time/batch = 18.5291s	
11158/30300 (epoch 18.413), train_loss = 1.09135961, grad/param norm = 1.4939e-01, time/batch = 18.6324s	
11159/30300 (epoch 18.414), train_loss = 1.39966174, grad/param norm = 1.5845e-01, time/batch = 20.3849s	
11160/30300 (epoch 18.416), train_loss = 1.21648854, grad/param norm = 1.4649e-01, time/batch = 19.2173s	
11161/30300 (epoch 18.417), train_loss = 1.18258522, grad/param norm = 1.4791e-01, time/batch = 20.1973s	
11162/30300 (epoch 18.419), train_loss = 1.14958907, grad/param norm = 1.2799e-01, time/batch = 18.4570s	
11163/30300 (epoch 18.421), train_loss = 1.21266691, grad/param norm = 1.4363e-01, time/batch = 18.6087s	
11164/30300 (epoch 18.422), train_loss = 1.24395485, grad/param norm = 1.5777e-01, time/batch = 18.7828s	
11165/30300 (epoch 18.424), train_loss = 1.25277518, grad/param norm = 1.3971e-01, time/batch = 19.6913s	
11166/30300 (epoch 18.426), train_loss = 1.18265349, grad/param norm = 1.4966e-01, time/batch = 19.3721s	
11167/30300 (epoch 18.427), train_loss = 1.23643408, grad/param norm = 1.5323e-01, time/batch = 18.0416s	
11168/30300 (epoch 18.429), train_loss = 1.24333471, grad/param norm = 1.3773e-01, time/batch = 20.2801s	
11169/30300 (epoch 18.431), train_loss = 1.32282752, grad/param norm = 1.4606e-01, time/batch = 19.9530s	
11170/30300 (epoch 18.432), train_loss = 1.22753317, grad/param norm = 1.3594e-01, time/batch = 17.7891s	
11171/30300 (epoch 18.434), train_loss = 1.12334649, grad/param norm = 1.4083e-01, time/batch = 18.4465s	
11172/30300 (epoch 18.436), train_loss = 1.40338626, grad/param norm = 1.5967e-01, time/batch = 19.0312s	
11173/30300 (epoch 18.437), train_loss = 1.14164374, grad/param norm = 1.4262e-01, time/batch = 19.1212s	
11174/30300 (epoch 18.439), train_loss = 1.20715759, grad/param norm = 1.5491e-01, time/batch = 18.4649s	
11175/30300 (epoch 18.441), train_loss = 1.21515354, grad/param norm = 1.3527e-01, time/batch = 20.1176s	
11176/30300 (epoch 18.442), train_loss = 1.15073187, grad/param norm = 1.4235e-01, time/batch = 18.3769s	
11177/30300 (epoch 18.444), train_loss = 1.03931623, grad/param norm = 1.4702e-01, time/batch = 19.3105s	
11178/30300 (epoch 18.446), train_loss = 1.22548128, grad/param norm = 1.3822e-01, time/batch = 18.8007s	
11179/30300 (epoch 18.447), train_loss = 1.24131501, grad/param norm = 1.5473e-01, time/batch = 17.6030s	
11180/30300 (epoch 18.449), train_loss = 1.17307113, grad/param norm = 1.4842e-01, time/batch = 19.2929s	
11181/30300 (epoch 18.450), train_loss = 1.34313829, grad/param norm = 1.4400e-01, time/batch = 19.6465s	
11182/30300 (epoch 18.452), train_loss = 1.33104239, grad/param norm = 1.3879e-01, time/batch = 19.2033s	
11183/30300 (epoch 18.454), train_loss = 1.31278035, grad/param norm = 1.3501e-01, time/batch = 18.3701s	
11184/30300 (epoch 18.455), train_loss = 1.30338544, grad/param norm = 1.6454e-01, time/batch = 18.9622s	
11185/30300 (epoch 18.457), train_loss = 1.26095704, grad/param norm = 1.4386e-01, time/batch = 18.9587s	
11186/30300 (epoch 18.459), train_loss = 1.33544426, grad/param norm = 1.6016e-01, time/batch = 18.9381s	
11187/30300 (epoch 18.460), train_loss = 1.29441638, grad/param norm = 1.4883e-01, time/batch = 18.6363s	
11188/30300 (epoch 18.462), train_loss = 1.33585673, grad/param norm = 1.4861e-01, time/batch = 17.6390s	
11189/30300 (epoch 18.464), train_loss = 1.10797080, grad/param norm = 1.6393e-01, time/batch = 18.6178s	
11190/30300 (epoch 18.465), train_loss = 1.09041105, grad/param norm = 1.4007e-01, time/batch = 17.8535s	
11191/30300 (epoch 18.467), train_loss = 1.04625914, grad/param norm = 1.2579e-01, time/batch = 18.8799s	
11192/30300 (epoch 18.469), train_loss = 1.15192074, grad/param norm = 1.2592e-01, time/batch = 18.6102s	
11193/30300 (epoch 18.470), train_loss = 1.22313483, grad/param norm = 1.4142e-01, time/batch = 19.2839s	
11194/30300 (epoch 18.472), train_loss = 1.20549109, grad/param norm = 1.3297e-01, time/batch = 19.7174s	
11195/30300 (epoch 18.474), train_loss = 1.25004420, grad/param norm = 1.5706e-01, time/batch = 17.4595s	
11196/30300 (epoch 18.475), train_loss = 1.15687204, grad/param norm = 1.3811e-01, time/batch = 18.5375s	
11197/30300 (epoch 18.477), train_loss = 1.24996452, grad/param norm = 1.6257e-01, time/batch = 19.7056s	
11198/30300 (epoch 18.479), train_loss = 1.24291754, grad/param norm = 1.4610e-01, time/batch = 18.9514s	
11199/30300 (epoch 18.480), train_loss = 1.28581453, grad/param norm = 1.4118e-01, time/batch = 18.7694s	
11200/30300 (epoch 18.482), train_loss = 1.30191665, grad/param norm = 1.3430e-01, time/batch = 19.3587s	
11201/30300 (epoch 18.483), train_loss = 1.20144935, grad/param norm = 1.4586e-01, time/batch = 19.2114s	
11202/30300 (epoch 18.485), train_loss = 1.25428744, grad/param norm = 1.4382e-01, time/batch = 17.2699s	
11203/30300 (epoch 18.487), train_loss = 1.34157077, grad/param norm = 1.4597e-01, time/batch = 18.2035s	
11204/30300 (epoch 18.488), train_loss = 1.33275773, grad/param norm = 1.4010e-01, time/batch = 17.1094s	
11205/30300 (epoch 18.490), train_loss = 1.14353833, grad/param norm = 1.4255e-01, time/batch = 17.8741s	
11206/30300 (epoch 18.492), train_loss = 1.22573281, grad/param norm = 1.5255e-01, time/batch = 19.0491s	
11207/30300 (epoch 18.493), train_loss = 1.21771942, grad/param norm = 1.3993e-01, time/batch = 20.0458s	
11208/30300 (epoch 18.495), train_loss = 1.17633053, grad/param norm = 1.2915e-01, time/batch = 18.6328s	
11209/30300 (epoch 18.497), train_loss = 1.29114221, grad/param norm = 1.4155e-01, time/batch = 15.6019s	
11210/30300 (epoch 18.498), train_loss = 1.29725984, grad/param norm = 1.4304e-01, time/batch = 15.4971s	
11211/30300 (epoch 18.500), train_loss = 1.29416480, grad/param norm = 1.6408e-01, time/batch = 19.2849s	
11212/30300 (epoch 18.502), train_loss = 1.23199085, grad/param norm = 1.5167e-01, time/batch = 17.9476s	
11213/30300 (epoch 18.503), train_loss = 1.33680881, grad/param norm = 1.3642e-01, time/batch = 19.4602s	
11214/30300 (epoch 18.505), train_loss = 1.20805144, grad/param norm = 1.6041e-01, time/batch = 19.6200s	
11215/30300 (epoch 18.507), train_loss = 1.18820193, grad/param norm = 1.5268e-01, time/batch = 18.0347s	
11216/30300 (epoch 18.508), train_loss = 1.22386416, grad/param norm = 1.6715e-01, time/batch = 19.5528s	
11217/30300 (epoch 18.510), train_loss = 1.33881886, grad/param norm = 1.5700e-01, time/batch = 19.8729s	
11218/30300 (epoch 18.512), train_loss = 1.18310928, grad/param norm = 1.3706e-01, time/batch = 18.0358s	
11219/30300 (epoch 18.513), train_loss = 1.28545134, grad/param norm = 1.4910e-01, time/batch = 18.1977s	
11220/30300 (epoch 18.515), train_loss = 1.25945533, grad/param norm = 1.5117e-01, time/batch = 19.3741s	
11221/30300 (epoch 18.517), train_loss = 1.07454692, grad/param norm = 1.3412e-01, time/batch = 18.0335s	
11222/30300 (epoch 18.518), train_loss = 1.33856140, grad/param norm = 1.5550e-01, time/batch = 19.8833s	
11223/30300 (epoch 18.520), train_loss = 1.33961368, grad/param norm = 1.5606e-01, time/batch = 20.1232s	
11224/30300 (epoch 18.521), train_loss = 1.14636716, grad/param norm = 1.4522e-01, time/batch = 18.1190s	
11225/30300 (epoch 18.523), train_loss = 1.40894553, grad/param norm = 1.7454e-01, time/batch = 18.6276s	
11226/30300 (epoch 18.525), train_loss = 1.17641315, grad/param norm = 1.4788e-01, time/batch = 19.9542s	
11227/30300 (epoch 18.526), train_loss = 1.22398500, grad/param norm = 1.4691e-01, time/batch = 17.9614s	
11228/30300 (epoch 18.528), train_loss = 1.12706305, grad/param norm = 1.3794e-01, time/batch = 18.7807s	
11229/30300 (epoch 18.530), train_loss = 1.13124801, grad/param norm = 1.4937e-01, time/batch = 19.6272s	
11230/30300 (epoch 18.531), train_loss = 1.31237325, grad/param norm = 1.5873e-01, time/batch = 19.3004s	
11231/30300 (epoch 18.533), train_loss = 1.26803270, grad/param norm = 1.4151e-01, time/batch = 18.3044s	
11232/30300 (epoch 18.535), train_loss = 1.12231461, grad/param norm = 1.2802e-01, time/batch = 18.2066s	
11233/30300 (epoch 18.536), train_loss = 1.27203739, grad/param norm = 1.4626e-01, time/batch = 17.5332s	
11234/30300 (epoch 18.538), train_loss = 1.10839209, grad/param norm = 1.5198e-01, time/batch = 17.5336s	
11235/30300 (epoch 18.540), train_loss = 1.14580151, grad/param norm = 1.4585e-01, time/batch = 17.6101s	
11236/30300 (epoch 18.541), train_loss = 1.24667682, grad/param norm = 1.5806e-01, time/batch = 20.1319s	
11237/30300 (epoch 18.543), train_loss = 1.23818756, grad/param norm = 1.4567e-01, time/batch = 17.3717s	
11238/30300 (epoch 18.545), train_loss = 1.23512384, grad/param norm = 1.6054e-01, time/batch = 17.5305s	
11239/30300 (epoch 18.546), train_loss = 1.49316060, grad/param norm = 1.5246e-01, time/batch = 20.1328s	
11240/30300 (epoch 18.548), train_loss = 1.18761239, grad/param norm = 1.4103e-01, time/batch = 18.8840s	
11241/30300 (epoch 18.550), train_loss = 1.35644385, grad/param norm = 1.8083e-01, time/batch = 18.5465s	
11242/30300 (epoch 18.551), train_loss = 1.18173469, grad/param norm = 1.5180e-01, time/batch = 19.9642s	
11243/30300 (epoch 18.553), train_loss = 1.20860068, grad/param norm = 1.4692e-01, time/batch = 18.7911s	
11244/30300 (epoch 18.554), train_loss = 1.26280068, grad/param norm = 1.5336e-01, time/batch = 19.7022s	
11245/30300 (epoch 18.556), train_loss = 1.30673170, grad/param norm = 1.4795e-01, time/batch = 19.1334s	
11246/30300 (epoch 18.558), train_loss = 1.38324235, grad/param norm = 1.6406e-01, time/batch = 18.9644s	
11247/30300 (epoch 18.559), train_loss = 1.33105124, grad/param norm = 1.6892e-01, time/batch = 19.0476s	
11248/30300 (epoch 18.561), train_loss = 1.09780960, grad/param norm = 1.5198e-01, time/batch = 18.9783s	
11249/30300 (epoch 18.563), train_loss = 1.14809477, grad/param norm = 1.4151e-01, time/batch = 19.4621s	
11250/30300 (epoch 18.564), train_loss = 1.18312691, grad/param norm = 1.4250e-01, time/batch = 18.4328s	
11251/30300 (epoch 18.566), train_loss = 1.26850198, grad/param norm = 1.4482e-01, time/batch = 17.9567s	
11252/30300 (epoch 18.568), train_loss = 1.06051511, grad/param norm = 1.4253e-01, time/batch = 20.0416s	
11253/30300 (epoch 18.569), train_loss = 1.26698334, grad/param norm = 1.4323e-01, time/batch = 18.2785s	
11254/30300 (epoch 18.571), train_loss = 1.27853616, grad/param norm = 1.5794e-01, time/batch = 20.0502s	
11255/30300 (epoch 18.573), train_loss = 1.28892845, grad/param norm = 1.4781e-01, time/batch = 19.7927s	
11256/30300 (epoch 18.574), train_loss = 1.33552906, grad/param norm = 1.4470e-01, time/batch = 18.6098s	
11257/30300 (epoch 18.576), train_loss = 1.23392521, grad/param norm = 1.3539e-01, time/batch = 20.1309s	
11258/30300 (epoch 18.578), train_loss = 1.11263332, grad/param norm = 1.3421e-01, time/batch = 19.7819s	
11259/30300 (epoch 18.579), train_loss = 1.27426506, grad/param norm = 1.6538e-01, time/batch = 17.2866s	
11260/30300 (epoch 18.581), train_loss = 1.32221316, grad/param norm = 1.3655e-01, time/batch = 18.9675s	
11261/30300 (epoch 18.583), train_loss = 1.43078596, grad/param norm = 1.6784e-01, time/batch = 19.9503s	
11262/30300 (epoch 18.584), train_loss = 1.34134422, grad/param norm = 1.5473e-01, time/batch = 18.4690s	
11263/30300 (epoch 18.586), train_loss = 1.25318924, grad/param norm = 1.4966e-01, time/batch = 19.9539s	
11264/30300 (epoch 18.587), train_loss = 1.23739043, grad/param norm = 1.4712e-01, time/batch = 19.4550s	
11265/30300 (epoch 18.589), train_loss = 1.13951345, grad/param norm = 1.4290e-01, time/batch = 18.2109s	
11266/30300 (epoch 18.591), train_loss = 1.30456282, grad/param norm = 1.4342e-01, time/batch = 17.2813s	
11267/30300 (epoch 18.592), train_loss = 1.25856484, grad/param norm = 1.3404e-01, time/batch = 18.9826s	
11268/30300 (epoch 18.594), train_loss = 1.27053222, grad/param norm = 1.4678e-01, time/batch = 18.7965s	
11269/30300 (epoch 18.596), train_loss = 1.16536152, grad/param norm = 1.3734e-01, time/batch = 19.0380s	
11270/30300 (epoch 18.597), train_loss = 1.19486870, grad/param norm = 1.5300e-01, time/batch = 19.7810s	
11271/30300 (epoch 18.599), train_loss = 1.08184168, grad/param norm = 1.4973e-01, time/batch = 19.8696s	
11272/30300 (epoch 18.601), train_loss = 1.29526813, grad/param norm = 1.4906e-01, time/batch = 18.8894s	
11273/30300 (epoch 18.602), train_loss = 1.24499364, grad/param norm = 1.3995e-01, time/batch = 17.0446s	
11274/30300 (epoch 18.604), train_loss = 1.14990383, grad/param norm = 1.3195e-01, time/batch = 19.5470s	
11275/30300 (epoch 18.606), train_loss = 1.23413417, grad/param norm = 1.5956e-01, time/batch = 31.7018s	
11276/30300 (epoch 18.607), train_loss = 1.34012727, grad/param norm = 2.1302e-01, time/batch = 19.0393s	
11277/30300 (epoch 18.609), train_loss = 1.47049473, grad/param norm = 1.7879e-01, time/batch = 19.0354s	
11278/30300 (epoch 18.611), train_loss = 1.18206200, grad/param norm = 1.4434e-01, time/batch = 19.2091s	
11279/30300 (epoch 18.612), train_loss = 1.14867908, grad/param norm = 1.4844e-01, time/batch = 18.7875s	
11280/30300 (epoch 18.614), train_loss = 1.19648361, grad/param norm = 1.4831e-01, time/batch = 19.1136s	
11281/30300 (epoch 18.616), train_loss = 1.28251613, grad/param norm = 1.5271e-01, time/batch = 18.5467s	
11282/30300 (epoch 18.617), train_loss = 1.23196409, grad/param norm = 1.4168e-01, time/batch = 19.5523s	
11283/30300 (epoch 18.619), train_loss = 1.06160953, grad/param norm = 1.4159e-01, time/batch = 20.0430s	
11284/30300 (epoch 18.620), train_loss = 1.25182651, grad/param norm = 1.5616e-01, time/batch = 19.2758s	
11285/30300 (epoch 18.622), train_loss = 1.23548192, grad/param norm = 1.8401e-01, time/batch = 19.5613s	
11286/30300 (epoch 18.624), train_loss = 1.18087035, grad/param norm = 1.5288e-01, time/batch = 18.7327s	
11287/30300 (epoch 18.625), train_loss = 1.21266368, grad/param norm = 1.5749e-01, time/batch = 19.1999s	
11288/30300 (epoch 18.627), train_loss = 1.36986300, grad/param norm = 1.5801e-01, time/batch = 19.8012s	
11289/30300 (epoch 18.629), train_loss = 1.34770180, grad/param norm = 1.4864e-01, time/batch = 18.7879s	
11290/30300 (epoch 18.630), train_loss = 1.25171769, grad/param norm = 1.4084e-01, time/batch = 18.7896s	
11291/30300 (epoch 18.632), train_loss = 1.32790218, grad/param norm = 1.5009e-01, time/batch = 18.0283s	
11292/30300 (epoch 18.634), train_loss = 1.13319495, grad/param norm = 1.3319e-01, time/batch = 20.2047s	
11293/30300 (epoch 18.635), train_loss = 1.28830380, grad/param norm = 1.4462e-01, time/batch = 17.8036s	
11294/30300 (epoch 18.637), train_loss = 1.31033316, grad/param norm = 1.7631e-01, time/batch = 19.2974s	
11295/30300 (epoch 18.639), train_loss = 1.18202923, grad/param norm = 1.3935e-01, time/batch = 20.3813s	
11296/30300 (epoch 18.640), train_loss = 1.37858180, grad/param norm = 1.6303e-01, time/batch = 17.7922s	
11297/30300 (epoch 18.642), train_loss = 1.20565062, grad/param norm = 1.2902e-01, time/batch = 17.1235s	
11298/30300 (epoch 18.644), train_loss = 1.31657575, grad/param norm = 1.4053e-01, time/batch = 19.7975s	
11299/30300 (epoch 18.645), train_loss = 1.12053586, grad/param norm = 1.3505e-01, time/batch = 18.4615s	
11300/30300 (epoch 18.647), train_loss = 1.22358622, grad/param norm = 1.4156e-01, time/batch = 18.9604s	
11301/30300 (epoch 18.649), train_loss = 1.20436498, grad/param norm = 1.5515e-01, time/batch = 18.9391s	
11302/30300 (epoch 18.650), train_loss = 1.22580022, grad/param norm = 1.4033e-01, time/batch = 17.6270s	
11303/30300 (epoch 18.652), train_loss = 1.18676663, grad/param norm = 1.3912e-01, time/batch = 19.0413s	
11304/30300 (epoch 18.653), train_loss = 1.44395109, grad/param norm = 1.6129e-01, time/batch = 19.2903s	
11305/30300 (epoch 18.655), train_loss = 1.19230015, grad/param norm = 1.6198e-01, time/batch = 19.7866s	
11306/30300 (epoch 18.657), train_loss = 1.19958441, grad/param norm = 1.3940e-01, time/batch = 19.2676s	
11307/30300 (epoch 18.658), train_loss = 1.15855804, grad/param norm = 1.3808e-01, time/batch = 18.2778s	
11308/30300 (epoch 18.660), train_loss = 1.26305634, grad/param norm = 1.4773e-01, time/batch = 20.3728s	
11309/30300 (epoch 18.662), train_loss = 1.28450991, grad/param norm = 1.6115e-01, time/batch = 17.3605s	
11310/30300 (epoch 18.663), train_loss = 1.27803215, grad/param norm = 1.5431e-01, time/batch = 19.1046s	
11311/30300 (epoch 18.665), train_loss = 1.17551246, grad/param norm = 1.6448e-01, time/batch = 19.5602s	
11312/30300 (epoch 18.667), train_loss = 1.35288476, grad/param norm = 1.5148e-01, time/batch = 18.1014s	
11313/30300 (epoch 18.668), train_loss = 1.37542899, grad/param norm = 1.5433e-01, time/batch = 19.7740s	
11314/30300 (epoch 18.670), train_loss = 1.36435473, grad/param norm = 1.5302e-01, time/batch = 16.6958s	
11315/30300 (epoch 18.672), train_loss = 1.31549768, grad/param norm = 1.5836e-01, time/batch = 17.9620s	
11316/30300 (epoch 18.673), train_loss = 1.32093427, grad/param norm = 1.5118e-01, time/batch = 19.6844s	
11317/30300 (epoch 18.675), train_loss = 1.21284081, grad/param norm = 1.4856e-01, time/batch = 19.2861s	
11318/30300 (epoch 18.677), train_loss = 1.18901680, grad/param norm = 1.4038e-01, time/batch = 18.3600s	
11319/30300 (epoch 18.678), train_loss = 1.21187268, grad/param norm = 1.5335e-01, time/batch = 19.2165s	
11320/30300 (epoch 18.680), train_loss = 1.03815670, grad/param norm = 1.3722e-01, time/batch = 19.7955s	
11321/30300 (epoch 18.682), train_loss = 1.25432969, grad/param norm = 1.5160e-01, time/batch = 18.5305s	
11322/30300 (epoch 18.683), train_loss = 1.32738447, grad/param norm = 1.3373e-01, time/batch = 18.1084s	
11323/30300 (epoch 18.685), train_loss = 1.33958904, grad/param norm = 1.6499e-01, time/batch = 18.9552s	
11324/30300 (epoch 18.686), train_loss = 1.22659532, grad/param norm = 1.3898e-01, time/batch = 19.2109s	
11325/30300 (epoch 18.688), train_loss = 1.23506369, grad/param norm = 1.3983e-01, time/batch = 18.0332s	
11326/30300 (epoch 18.690), train_loss = 1.20637151, grad/param norm = 1.5672e-01, time/batch = 18.7926s	
11327/30300 (epoch 18.691), train_loss = 1.28993649, grad/param norm = 1.3776e-01, time/batch = 20.1875s	
11328/30300 (epoch 18.693), train_loss = 1.61583472, grad/param norm = 1.6370e-01, time/batch = 17.7026s	
11329/30300 (epoch 18.695), train_loss = 1.38951205, grad/param norm = 1.6958e-01, time/batch = 16.8618s	
11330/30300 (epoch 18.696), train_loss = 1.33095518, grad/param norm = 1.6430e-01, time/batch = 19.1310s	
11331/30300 (epoch 18.698), train_loss = 1.19381485, grad/param norm = 1.4215e-01, time/batch = 17.9537s	
11332/30300 (epoch 18.700), train_loss = 1.19874565, grad/param norm = 1.5406e-01, time/batch = 17.7668s	
11333/30300 (epoch 18.701), train_loss = 1.07256341, grad/param norm = 1.3133e-01, time/batch = 19.3727s	
11334/30300 (epoch 18.703), train_loss = 1.24359309, grad/param norm = 1.3288e-01, time/batch = 18.3757s	
11335/30300 (epoch 18.705), train_loss = 1.21591079, grad/param norm = 1.6367e-01, time/batch = 18.4736s	
11336/30300 (epoch 18.706), train_loss = 1.31738850, grad/param norm = 1.5302e-01, time/batch = 18.4516s	
11337/30300 (epoch 18.708), train_loss = 1.23289802, grad/param norm = 1.4514e-01, time/batch = 19.1035s	
11338/30300 (epoch 18.710), train_loss = 1.23054348, grad/param norm = 1.6636e-01, time/batch = 19.1193s	
11339/30300 (epoch 18.711), train_loss = 1.14872379, grad/param norm = 1.4025e-01, time/batch = 17.8889s	
11340/30300 (epoch 18.713), train_loss = 1.13959240, grad/param norm = 1.3817e-01, time/batch = 19.0511s	
11341/30300 (epoch 18.715), train_loss = 1.19275819, grad/param norm = 1.4386e-01, time/batch = 17.8603s	
11342/30300 (epoch 18.716), train_loss = 1.35651698, grad/param norm = 1.5243e-01, time/batch = 19.1314s	
11343/30300 (epoch 18.718), train_loss = 1.37545775, grad/param norm = 1.5771e-01, time/batch = 19.6187s	
11344/30300 (epoch 18.719), train_loss = 1.22102007, grad/param norm = 1.8253e-01, time/batch = 18.1193s	
11345/30300 (epoch 18.721), train_loss = 1.25979170, grad/param norm = 1.5360e-01, time/batch = 17.8494s	
11346/30300 (epoch 18.723), train_loss = 1.18981088, grad/param norm = 1.5758e-01, time/batch = 18.7907s	
11347/30300 (epoch 18.724), train_loss = 1.30071360, grad/param norm = 1.6554e-01, time/batch = 19.2865s	
11348/30300 (epoch 18.726), train_loss = 1.65978395, grad/param norm = 1.7817e-01, time/batch = 19.1097s	
11349/30300 (epoch 18.728), train_loss = 1.31666668, grad/param norm = 1.5947e-01, time/batch = 18.3841s	
11350/30300 (epoch 18.729), train_loss = 1.20960780, grad/param norm = 1.5456e-01, time/batch = 19.0321s	
11351/30300 (epoch 18.731), train_loss = 1.32556301, grad/param norm = 1.5563e-01, time/batch = 19.1431s	
11352/30300 (epoch 18.733), train_loss = 1.23597172, grad/param norm = 1.4928e-01, time/batch = 17.2116s	
11353/30300 (epoch 18.734), train_loss = 1.30542534, grad/param norm = 1.3763e-01, time/batch = 15.8736s	
11354/30300 (epoch 18.736), train_loss = 1.23354824, grad/param norm = 1.3981e-01, time/batch = 18.1109s	
11355/30300 (epoch 18.738), train_loss = 1.13883019, grad/param norm = 1.3278e-01, time/batch = 19.3838s	
11356/30300 (epoch 18.739), train_loss = 1.30677382, grad/param norm = 1.4739e-01, time/batch = 19.3825s	
11357/30300 (epoch 18.741), train_loss = 1.37285777, grad/param norm = 1.4454e-01, time/batch = 18.2848s	
11358/30300 (epoch 18.743), train_loss = 1.21510477, grad/param norm = 1.4362e-01, time/batch = 19.1292s	
11359/30300 (epoch 18.744), train_loss = 1.29707663, grad/param norm = 1.4905e-01, time/batch = 19.7863s	
11360/30300 (epoch 18.746), train_loss = 1.14163320, grad/param norm = 1.3501e-01, time/batch = 18.2063s	
11361/30300 (epoch 18.748), train_loss = 1.28000388, grad/param norm = 1.6071e-01, time/batch = 20.1900s	
11362/30300 (epoch 18.749), train_loss = 1.30540974, grad/param norm = 1.5663e-01, time/batch = 20.1249s	
11363/30300 (epoch 18.751), train_loss = 1.23146382, grad/param norm = 1.4199e-01, time/batch = 17.1058s	
11364/30300 (epoch 18.752), train_loss = 1.23313788, grad/param norm = 1.4503e-01, time/batch = 17.5459s	
11365/30300 (epoch 18.754), train_loss = 1.15530951, grad/param norm = 1.3723e-01, time/batch = 19.1947s	
11366/30300 (epoch 18.756), train_loss = 1.22551902, grad/param norm = 1.4952e-01, time/batch = 19.2051s	
11367/30300 (epoch 18.757), train_loss = 1.29140604, grad/param norm = 1.5862e-01, time/batch = 18.7031s	
11368/30300 (epoch 18.759), train_loss = 1.26327048, grad/param norm = 1.3552e-01, time/batch = 19.9661s	
11369/30300 (epoch 18.761), train_loss = 1.08649678, grad/param norm = 1.3222e-01, time/batch = 18.6971s	
11370/30300 (epoch 18.762), train_loss = 1.11082970, grad/param norm = 1.3655e-01, time/batch = 18.6261s	
11371/30300 (epoch 18.764), train_loss = 1.21260466, grad/param norm = 1.4621e-01, time/batch = 19.7020s	
11372/30300 (epoch 18.766), train_loss = 1.29832775, grad/param norm = 1.5145e-01, time/batch = 17.5429s	
11373/30300 (epoch 18.767), train_loss = 1.30976579, grad/param norm = 1.8203e-01, time/batch = 18.7079s	
11374/30300 (epoch 18.769), train_loss = 1.31319789, grad/param norm = 1.5587e-01, time/batch = 18.7012s	
11375/30300 (epoch 18.771), train_loss = 1.21668146, grad/param norm = 1.7237e-01, time/batch = 19.8614s	
11376/30300 (epoch 18.772), train_loss = 1.30382662, grad/param norm = 1.5391e-01, time/batch = 16.6000s	
11377/30300 (epoch 18.774), train_loss = 1.41297714, grad/param norm = 1.5134e-01, time/batch = 19.9435s	
11378/30300 (epoch 18.776), train_loss = 1.28365007, grad/param norm = 1.6199e-01, time/batch = 18.8733s	
11379/30300 (epoch 18.777), train_loss = 1.32313294, grad/param norm = 1.5387e-01, time/batch = 18.6268s	
11380/30300 (epoch 18.779), train_loss = 1.44003763, grad/param norm = 1.8515e-01, time/batch = 19.0431s	
11381/30300 (epoch 18.781), train_loss = 1.26221726, grad/param norm = 1.6583e-01, time/batch = 19.2136s	
11382/30300 (epoch 18.782), train_loss = 1.19582730, grad/param norm = 1.4987e-01, time/batch = 17.4328s	
11383/30300 (epoch 18.784), train_loss = 1.18754080, grad/param norm = 1.4414e-01, time/batch = 19.8726s	
11384/30300 (epoch 18.785), train_loss = 1.42541610, grad/param norm = 1.7053e-01, time/batch = 18.8879s	
11385/30300 (epoch 18.787), train_loss = 1.08726937, grad/param norm = 1.3773e-01, time/batch = 17.5527s	
11386/30300 (epoch 18.789), train_loss = 1.49739678, grad/param norm = 1.5501e-01, time/batch = 19.5539s	
11387/30300 (epoch 18.790), train_loss = 1.33340221, grad/param norm = 1.6243e-01, time/batch = 17.9708s	
11388/30300 (epoch 18.792), train_loss = 1.09149578, grad/param norm = 1.5176e-01, time/batch = 18.5620s	
11389/30300 (epoch 18.794), train_loss = 1.23160876, grad/param norm = 1.5499e-01, time/batch = 18.4698s	
11390/30300 (epoch 18.795), train_loss = 1.16515255, grad/param norm = 1.3099e-01, time/batch = 19.1423s	
11391/30300 (epoch 18.797), train_loss = 1.41692813, grad/param norm = 1.7036e-01, time/batch = 19.1931s	
11392/30300 (epoch 18.799), train_loss = 1.31827989, grad/param norm = 1.5187e-01, time/batch = 18.4509s	
11393/30300 (epoch 18.800), train_loss = 1.33992011, grad/param norm = 1.5975e-01, time/batch = 19.1355s	
11394/30300 (epoch 18.802), train_loss = 1.50907647, grad/param norm = 2.1497e-01, time/batch = 19.4904s	
11395/30300 (epoch 18.804), train_loss = 1.35297815, grad/param norm = 2.1881e-01, time/batch = 18.0517s	
11396/30300 (epoch 18.805), train_loss = 1.44713037, grad/param norm = 1.6986e-01, time/batch = 18.6274s	
11397/30300 (epoch 18.807), train_loss = 1.24131939, grad/param norm = 1.5730e-01, time/batch = 18.4744s	
11398/30300 (epoch 18.809), train_loss = 1.35992265, grad/param norm = 1.6949e-01, time/batch = 18.3931s	
11399/30300 (epoch 18.810), train_loss = 1.35130844, grad/param norm = 1.5280e-01, time/batch = 18.6360s	
11400/30300 (epoch 18.812), train_loss = 1.17901355, grad/param norm = 1.5217e-01, time/batch = 19.6360s	
11401/30300 (epoch 18.814), train_loss = 1.27000293, grad/param norm = 1.6339e-01, time/batch = 18.5335s	
11402/30300 (epoch 18.815), train_loss = 1.29560226, grad/param norm = 1.7979e-01, time/batch = 18.2824s	
11403/30300 (epoch 18.817), train_loss = 1.36730022, grad/param norm = 1.5937e-01, time/batch = 19.3563s	
11404/30300 (epoch 18.818), train_loss = 1.32628801, grad/param norm = 1.4637e-01, time/batch = 19.2130s	
11405/30300 (epoch 18.820), train_loss = 1.44408374, grad/param norm = 1.6270e-01, time/batch = 18.8010s	
11406/30300 (epoch 18.822), train_loss = 1.43247707, grad/param norm = 1.6894e-01, time/batch = 18.7925s	
11407/30300 (epoch 18.823), train_loss = 1.48742860, grad/param norm = 1.8434e-01, time/batch = 19.6242s	
11408/30300 (epoch 18.825), train_loss = 1.38276981, grad/param norm = 1.6038e-01, time/batch = 18.3670s	
11409/30300 (epoch 18.827), train_loss = 1.12451876, grad/param norm = 1.6180e-01, time/batch = 19.2927s	
11410/30300 (epoch 18.828), train_loss = 1.32831681, grad/param norm = 1.4815e-01, time/batch = 20.0487s	
11411/30300 (epoch 18.830), train_loss = 1.30302056, grad/param norm = 1.5869e-01, time/batch = 18.9457s	
11412/30300 (epoch 18.832), train_loss = 1.19075926, grad/param norm = 1.5439e-01, time/batch = 19.2756s	
11413/30300 (epoch 18.833), train_loss = 1.33537360, grad/param norm = 1.5096e-01, time/batch = 19.7181s	
11414/30300 (epoch 18.835), train_loss = 1.19204807, grad/param norm = 1.4649e-01, time/batch = 19.2088s	
11415/30300 (epoch 18.837), train_loss = 1.11724374, grad/param norm = 1.3776e-01, time/batch = 19.1048s	
11416/30300 (epoch 18.838), train_loss = 1.15099417, grad/param norm = 1.5375e-01, time/batch = 20.1184s	
11417/30300 (epoch 18.840), train_loss = 1.31925740, grad/param norm = 1.2960e-01, time/batch = 18.6053s	
11418/30300 (epoch 18.842), train_loss = 1.16565131, grad/param norm = 1.2550e-01, time/batch = 17.4564s	
11419/30300 (epoch 18.843), train_loss = 1.29535385, grad/param norm = 1.4486e-01, time/batch = 18.1186s	
11420/30300 (epoch 18.845), train_loss = 1.29381553, grad/param norm = 1.4302e-01, time/batch = 18.7943s	
11421/30300 (epoch 18.847), train_loss = 1.29658479, grad/param norm = 1.5508e-01, time/batch = 19.1260s	
11422/30300 (epoch 18.848), train_loss = 1.37175005, grad/param norm = 1.5591e-01, time/batch = 20.2185s	
11423/30300 (epoch 18.850), train_loss = 1.26635911, grad/param norm = 1.4923e-01, time/batch = 18.4540s	
11424/30300 (epoch 18.851), train_loss = 1.32562770, grad/param norm = 1.6885e-01, time/batch = 18.6806s	
11425/30300 (epoch 18.853), train_loss = 1.21555794, grad/param norm = 1.3400e-01, time/batch = 19.5342s	
11426/30300 (epoch 18.855), train_loss = 1.18608407, grad/param norm = 1.2623e-01, time/batch = 18.5591s	
11427/30300 (epoch 18.856), train_loss = 1.26042532, grad/param norm = 1.5245e-01, time/batch = 18.7095s	
11428/30300 (epoch 18.858), train_loss = 1.21607453, grad/param norm = 1.3589e-01, time/batch = 19.4537s	
11429/30300 (epoch 18.860), train_loss = 1.17830791, grad/param norm = 1.4737e-01, time/batch = 19.3802s	
11430/30300 (epoch 18.861), train_loss = 1.42306899, grad/param norm = 1.4881e-01, time/batch = 18.7151s	
11431/30300 (epoch 18.863), train_loss = 1.27442517, grad/param norm = 1.3749e-01, time/batch = 19.3049s	
11432/30300 (epoch 18.865), train_loss = 1.35642975, grad/param norm = 1.5698e-01, time/batch = 19.3060s	
11433/30300 (epoch 18.866), train_loss = 1.34157909, grad/param norm = 1.5487e-01, time/batch = 18.6207s	
11434/30300 (epoch 18.868), train_loss = 1.26370864, grad/param norm = 1.5846e-01, time/batch = 17.1449s	
11435/30300 (epoch 18.870), train_loss = 1.19396151, grad/param norm = 1.4346e-01, time/batch = 19.2134s	
11436/30300 (epoch 18.871), train_loss = 1.21184215, grad/param norm = 1.3404e-01, time/batch = 18.2065s	
11437/30300 (epoch 18.873), train_loss = 1.26323223, grad/param norm = 1.8372e-01, time/batch = 18.8476s	
11438/30300 (epoch 18.875), train_loss = 1.17770987, grad/param norm = 1.3271e-01, time/batch = 20.2948s	
11439/30300 (epoch 18.876), train_loss = 1.15817185, grad/param norm = 1.5080e-01, time/batch = 16.9673s	
11440/30300 (epoch 18.878), train_loss = 1.07828561, grad/param norm = 1.5065e-01, time/batch = 19.3792s	
11441/30300 (epoch 18.880), train_loss = 1.16864524, grad/param norm = 1.3522e-01, time/batch = 18.7035s	
11442/30300 (epoch 18.881), train_loss = 1.45024079, grad/param norm = 2.0579e-01, time/batch = 18.5408s	
11443/30300 (epoch 18.883), train_loss = 1.31477115, grad/param norm = 1.4953e-01, time/batch = 18.6310s	
11444/30300 (epoch 18.884), train_loss = 1.16726896, grad/param norm = 1.3053e-01, time/batch = 19.1242s	
11445/30300 (epoch 18.886), train_loss = 1.28599108, grad/param norm = 1.4086e-01, time/batch = 17.7932s	
11446/30300 (epoch 18.888), train_loss = 1.27323639, grad/param norm = 1.5749e-01, time/batch = 18.7846s	
11447/30300 (epoch 18.889), train_loss = 1.29326608, grad/param norm = 1.5016e-01, time/batch = 20.0308s	
11448/30300 (epoch 18.891), train_loss = 1.28272232, grad/param norm = 1.6844e-01, time/batch = 19.0502s	
11449/30300 (epoch 18.893), train_loss = 1.51052761, grad/param norm = 1.5801e-01, time/batch = 18.5236s	
11450/30300 (epoch 18.894), train_loss = 1.36271265, grad/param norm = 1.4927e-01, time/batch = 19.7025s	
11451/30300 (epoch 18.896), train_loss = 1.09690117, grad/param norm = 1.4611e-01, time/batch = 19.2877s	
11452/30300 (epoch 18.898), train_loss = 1.06253074, grad/param norm = 1.4432e-01, time/batch = 18.2901s	
11453/30300 (epoch 18.899), train_loss = 1.19241979, grad/param norm = 1.5576e-01, time/batch = 19.7996s	
11454/30300 (epoch 18.901), train_loss = 1.24678677, grad/param norm = 1.6163e-01, time/batch = 20.0403s	
11455/30300 (epoch 18.903), train_loss = 1.28823571, grad/param norm = 1.4849e-01, time/batch = 17.4649s	
11456/30300 (epoch 18.904), train_loss = 1.23110934, grad/param norm = 1.5186e-01, time/batch = 18.6127s	
11457/30300 (epoch 18.906), train_loss = 1.37150000, grad/param norm = 1.6040e-01, time/batch = 17.3567s	
11458/30300 (epoch 18.908), train_loss = 1.19651038, grad/param norm = 1.4662e-01, time/batch = 18.2118s	
11459/30300 (epoch 18.909), train_loss = 1.18435705, grad/param norm = 1.5993e-01, time/batch = 19.8714s	
11460/30300 (epoch 18.911), train_loss = 1.25886329, grad/param norm = 1.4412e-01, time/batch = 20.2748s	
11461/30300 (epoch 18.913), train_loss = 1.25729220, grad/param norm = 1.4511e-01, time/batch = 19.3670s	
11462/30300 (epoch 18.914), train_loss = 1.21961956, grad/param norm = 1.5556e-01, time/batch = 19.1168s	
11463/30300 (epoch 18.916), train_loss = 1.26893059, grad/param norm = 1.3589e-01, time/batch = 20.1226s	
11464/30300 (epoch 18.917), train_loss = 1.18156933, grad/param norm = 1.4263e-01, time/batch = 23.2300s	
11465/30300 (epoch 18.919), train_loss = 1.20975292, grad/param norm = 1.4930e-01, time/batch = 27.1243s	
11466/30300 (epoch 18.921), train_loss = 1.25813248, grad/param norm = 1.4569e-01, time/batch = 19.5440s	
11467/30300 (epoch 18.922), train_loss = 1.34902102, grad/param norm = 1.6589e-01, time/batch = 17.6234s	
11468/30300 (epoch 18.924), train_loss = 1.26849083, grad/param norm = 1.5775e-01, time/batch = 17.5348s	
11469/30300 (epoch 18.926), train_loss = 1.27495822, grad/param norm = 1.5483e-01, time/batch = 18.4698s	
11470/30300 (epoch 18.927), train_loss = 1.25430198, grad/param norm = 1.5698e-01, time/batch = 17.2096s	
11471/30300 (epoch 18.929), train_loss = 1.20497229, grad/param norm = 1.4975e-01, time/batch = 18.6287s	
11472/30300 (epoch 18.931), train_loss = 1.38157634, grad/param norm = 1.7218e-01, time/batch = 17.9705s	
11473/30300 (epoch 18.932), train_loss = 1.20780416, grad/param norm = 1.4880e-01, time/batch = 17.9282s	
11474/30300 (epoch 18.934), train_loss = 1.28476525, grad/param norm = 1.5797e-01, time/batch = 19.1982s	
11475/30300 (epoch 18.936), train_loss = 1.21351765, grad/param norm = 1.4246e-01, time/batch = 18.7979s	
11476/30300 (epoch 18.937), train_loss = 1.17631828, grad/param norm = 1.4388e-01, time/batch = 18.4726s	
11477/30300 (epoch 18.939), train_loss = 1.37077642, grad/param norm = 1.6745e-01, time/batch = 17.2676s	
11478/30300 (epoch 18.941), train_loss = 1.22973967, grad/param norm = 3.1630e-01, time/batch = 19.7819s	
11479/30300 (epoch 18.942), train_loss = 1.25418352, grad/param norm = 1.6226e-01, time/batch = 19.2900s	
11480/30300 (epoch 18.944), train_loss = 1.16668335, grad/param norm = 1.5066e-01, time/batch = 15.6190s	
11481/30300 (epoch 18.946), train_loss = 1.36875098, grad/param norm = 1.5847e-01, time/batch = 14.8416s	
11482/30300 (epoch 18.947), train_loss = 1.38221384, grad/param norm = 1.8408e-01, time/batch = 15.4058s	
11483/30300 (epoch 18.949), train_loss = 1.42959147, grad/param norm = 1.7288e-01, time/batch = 16.4184s	
11484/30300 (epoch 18.950), train_loss = 1.38331778, grad/param norm = 1.6189e-01, time/batch = 18.2758s	
11485/30300 (epoch 18.952), train_loss = 1.32984558, grad/param norm = 1.8076e-01, time/batch = 19.8740s	
11486/30300 (epoch 18.954), train_loss = 1.52368315, grad/param norm = 1.5454e-01, time/batch = 20.3693s	
11487/30300 (epoch 18.955), train_loss = 1.22247759, grad/param norm = 1.5344e-01, time/batch = 17.6057s	
11488/30300 (epoch 18.957), train_loss = 1.32089009, grad/param norm = 1.4958e-01, time/batch = 19.7773s	
11489/30300 (epoch 18.959), train_loss = 1.21454843, grad/param norm = 1.5013e-01, time/batch = 17.7815s	
11490/30300 (epoch 18.960), train_loss = 1.23245876, grad/param norm = 1.5167e-01, time/batch = 17.8661s	
11491/30300 (epoch 18.962), train_loss = 1.22998001, grad/param norm = 1.8386e-01, time/batch = 18.5433s	
11492/30300 (epoch 18.964), train_loss = 1.17751012, grad/param norm = 1.4967e-01, time/batch = 18.5307s	
11493/30300 (epoch 18.965), train_loss = 1.17161256, grad/param norm = 1.6389e-01, time/batch = 17.9501s	
11494/30300 (epoch 18.967), train_loss = 1.25750016, grad/param norm = 1.6584e-01, time/batch = 19.6156s	
11495/30300 (epoch 18.969), train_loss = 1.18576980, grad/param norm = 1.6778e-01, time/batch = 19.3783s	
11496/30300 (epoch 18.970), train_loss = 1.22489651, grad/param norm = 1.3660e-01, time/batch = 17.9596s	
11497/30300 (epoch 18.972), train_loss = 1.15110307, grad/param norm = 1.5559e-01, time/batch = 18.3625s	
11498/30300 (epoch 18.974), train_loss = 1.47291852, grad/param norm = 1.7111e-01, time/batch = 19.2911s	
11499/30300 (epoch 18.975), train_loss = 1.46902699, grad/param norm = 1.8581e-01, time/batch = 19.3609s	
11500/30300 (epoch 18.977), train_loss = 1.36611193, grad/param norm = 1.5520e-01, time/batch = 18.8683s	
11501/30300 (epoch 18.979), train_loss = 1.33349221, grad/param norm = 1.5670e-01, time/batch = 17.9585s	
11502/30300 (epoch 18.980), train_loss = 1.32286743, grad/param norm = 1.5774e-01, time/batch = 17.0089s	
11503/30300 (epoch 18.982), train_loss = 1.36737948, grad/param norm = 1.6688e-01, time/batch = 17.4276s	
11504/30300 (epoch 18.983), train_loss = 1.39267484, grad/param norm = 1.5393e-01, time/batch = 19.3651s	
11505/30300 (epoch 18.985), train_loss = 1.29911102, grad/param norm = 1.6340e-01, time/batch = 19.1098s	
11506/30300 (epoch 18.987), train_loss = 1.23265327, grad/param norm = 1.4206e-01, time/batch = 18.2987s	
11507/30300 (epoch 18.988), train_loss = 1.43381768, grad/param norm = 1.5708e-01, time/batch = 20.1986s	
11508/30300 (epoch 18.990), train_loss = 1.09699819, grad/param norm = 1.3287e-01, time/batch = 19.0345s	
11509/30300 (epoch 18.992), train_loss = 1.31654088, grad/param norm = 1.3920e-01, time/batch = 18.4533s	
11510/30300 (epoch 18.993), train_loss = 1.40867889, grad/param norm = 1.7475e-01, time/batch = 19.3802s	
11511/30300 (epoch 18.995), train_loss = 1.23327371, grad/param norm = 1.4935e-01, time/batch = 19.7088s	
11512/30300 (epoch 18.997), train_loss = 1.29665609, grad/param norm = 1.5611e-01, time/batch = 17.7841s	
11513/30300 (epoch 18.998), train_loss = 1.35614434, grad/param norm = 1.6362e-01, time/batch = 19.6948s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
11514/30300 (epoch 19.000), train_loss = 1.21940899, grad/param norm = 1.5780e-01, time/batch = 19.7768s	
11515/30300 (epoch 19.002), train_loss = 1.36289122, grad/param norm = 1.4934e-01, time/batch = 18.7978s	
11516/30300 (epoch 19.003), train_loss = 1.27760288, grad/param norm = 1.5374e-01, time/batch = 18.2776s	
11517/30300 (epoch 19.005), train_loss = 1.24719324, grad/param norm = 1.5554e-01, time/batch = 19.2107s	
11518/30300 (epoch 19.007), train_loss = 1.35978450, grad/param norm = 1.6812e-01, time/batch = 19.1955s	
11519/30300 (epoch 19.008), train_loss = 1.20046426, grad/param norm = 1.5673e-01, time/batch = 16.4632s	
11520/30300 (epoch 19.010), train_loss = 1.15592574, grad/param norm = 1.5938e-01, time/batch = 19.8502s	
11521/30300 (epoch 19.012), train_loss = 1.20598586, grad/param norm = 1.5002e-01, time/batch = 20.1238s	
11522/30300 (epoch 19.013), train_loss = 1.35524644, grad/param norm = 1.5796e-01, time/batch = 17.0933s	
11523/30300 (epoch 19.015), train_loss = 1.22493715, grad/param norm = 1.4556e-01, time/batch = 18.7189s	
11524/30300 (epoch 19.017), train_loss = 1.18730171, grad/param norm = 1.3392e-01, time/batch = 19.5502s	
11525/30300 (epoch 19.018), train_loss = 1.17469689, grad/param norm = 1.3877e-01, time/batch = 17.7069s	
11526/30300 (epoch 19.020), train_loss = 1.37234856, grad/param norm = 1.7505e-01, time/batch = 18.7836s	
11527/30300 (epoch 19.021), train_loss = 1.37888991, grad/param norm = 1.5877e-01, time/batch = 20.6997s	
11528/30300 (epoch 19.023), train_loss = 1.23562290, grad/param norm = 1.3871e-01, time/batch = 17.4650s	
11529/30300 (epoch 19.025), train_loss = 1.18171904, grad/param norm = 1.5750e-01, time/batch = 18.5233s	
11530/30300 (epoch 19.026), train_loss = 1.31404003, grad/param norm = 1.7407e-01, time/batch = 19.0240s	
11531/30300 (epoch 19.028), train_loss = 1.34680269, grad/param norm = 1.5183e-01, time/batch = 18.8633s	
11532/30300 (epoch 19.030), train_loss = 1.19811727, grad/param norm = 1.4685e-01, time/batch = 19.8737s	
11533/30300 (epoch 19.031), train_loss = 1.28633695, grad/param norm = 1.5463e-01, time/batch = 19.3868s	
11534/30300 (epoch 19.033), train_loss = 1.26941286, grad/param norm = 1.6946e-01, time/batch = 19.4605s	
11535/30300 (epoch 19.035), train_loss = 1.34645420, grad/param norm = 1.6218e-01, time/batch = 19.2899s	
11536/30300 (epoch 19.036), train_loss = 1.26379108, grad/param norm = 1.5961e-01, time/batch = 18.2913s	
11537/30300 (epoch 19.038), train_loss = 1.29980373, grad/param norm = 1.5697e-01, time/batch = 19.6955s	
11538/30300 (epoch 19.040), train_loss = 1.00383688, grad/param norm = 1.3814e-01, time/batch = 18.4454s	
11539/30300 (epoch 19.041), train_loss = 1.05270823, grad/param norm = 1.2735e-01, time/batch = 19.7894s	
11540/30300 (epoch 19.043), train_loss = 1.26868586, grad/param norm = 1.5320e-01, time/batch = 18.2933s	
11541/30300 (epoch 19.045), train_loss = 1.23524395, grad/param norm = 1.4886e-01, time/batch = 18.6248s	
11542/30300 (epoch 19.046), train_loss = 1.40961537, grad/param norm = 1.7951e-01, time/batch = 20.8650s	
11543/30300 (epoch 19.048), train_loss = 1.24905043, grad/param norm = 1.8109e-01, time/batch = 19.4673s	
11544/30300 (epoch 19.050), train_loss = 1.24279472, grad/param norm = 1.5772e-01, time/batch = 18.8542s	
11545/30300 (epoch 19.051), train_loss = 1.29932866, grad/param norm = 1.8684e-01, time/batch = 19.1301s	
11546/30300 (epoch 19.053), train_loss = 1.07819936, grad/param norm = 1.6558e-01, time/batch = 19.7108s	
11547/30300 (epoch 19.054), train_loss = 1.23585798, grad/param norm = 1.4924e-01, time/batch = 17.8706s	
11548/30300 (epoch 19.056), train_loss = 1.18761433, grad/param norm = 1.4729e-01, time/batch = 19.4539s	
11549/30300 (epoch 19.058), train_loss = 1.21770953, grad/param norm = 1.3889e-01, time/batch = 19.6882s	
11550/30300 (epoch 19.059), train_loss = 1.14869898, grad/param norm = 1.5112e-01, time/batch = 17.5212s	
11551/30300 (epoch 19.061), train_loss = 1.35709792, grad/param norm = 1.5745e-01, time/batch = 20.1981s	
11552/30300 (epoch 19.063), train_loss = 1.17485412, grad/param norm = 1.6257e-01, time/batch = 20.4552s	
11553/30300 (epoch 19.064), train_loss = 1.28848300, grad/param norm = 1.5018e-01, time/batch = 18.6876s	
11554/30300 (epoch 19.066), train_loss = 1.24343720, grad/param norm = 1.4170e-01, time/batch = 18.9493s	
11555/30300 (epoch 19.068), train_loss = 1.13034302, grad/param norm = 1.4717e-01, time/batch = 18.7866s	
11556/30300 (epoch 19.069), train_loss = 1.31430563, grad/param norm = 1.4849e-01, time/batch = 18.7086s	
11557/30300 (epoch 19.071), train_loss = 1.32163566, grad/param norm = 1.6722e-01, time/batch = 18.9600s	
11558/30300 (epoch 19.073), train_loss = 1.24644058, grad/param norm = 1.6822e-01, time/batch = 18.0328s	
11559/30300 (epoch 19.074), train_loss = 1.29637894, grad/param norm = 1.3494e-01, time/batch = 19.4469s	
11560/30300 (epoch 19.076), train_loss = 1.22203110, grad/param norm = 1.4536e-01, time/batch = 18.7774s	
11561/30300 (epoch 19.078), train_loss = 1.15029122, grad/param norm = 1.4241e-01, time/batch = 18.2774s	
11562/30300 (epoch 19.079), train_loss = 1.18183568, grad/param norm = 1.3251e-01, time/batch = 20.1109s	
11563/30300 (epoch 19.081), train_loss = 1.27678554, grad/param norm = 1.5610e-01, time/batch = 18.2959s	
11564/30300 (epoch 19.083), train_loss = 1.35420130, grad/param norm = 1.6325e-01, time/batch = 18.0407s	
11565/30300 (epoch 19.084), train_loss = 1.15777062, grad/param norm = 1.5089e-01, time/batch = 19.4521s	
11566/30300 (epoch 19.086), train_loss = 1.20191115, grad/param norm = 1.6279e-01, time/batch = 17.5268s	
11567/30300 (epoch 19.087), train_loss = 1.17584176, grad/param norm = 1.4598e-01, time/batch = 19.2083s	
11568/30300 (epoch 19.089), train_loss = 1.21861368, grad/param norm = 1.5279e-01, time/batch = 20.0480s	
11569/30300 (epoch 19.091), train_loss = 1.28238157, grad/param norm = 1.5723e-01, time/batch = 17.6473s	
11570/30300 (epoch 19.092), train_loss = 1.28596324, grad/param norm = 1.4643e-01, time/batch = 20.6158s	
11571/30300 (epoch 19.094), train_loss = 1.42137313, grad/param norm = 1.7162e-01, time/batch = 17.3504s	
11572/30300 (epoch 19.096), train_loss = 1.34278497, grad/param norm = 1.4938e-01, time/batch = 18.0348s	
11573/30300 (epoch 19.097), train_loss = 1.21492628, grad/param norm = 1.4936e-01, time/batch = 19.7805s	
11574/30300 (epoch 19.099), train_loss = 1.36903514, grad/param norm = 1.6150e-01, time/batch = 19.9462s	
11575/30300 (epoch 19.101), train_loss = 1.41994701, grad/param norm = 1.7095e-01, time/batch = 18.3591s	
11576/30300 (epoch 19.102), train_loss = 1.17675400, grad/param norm = 1.5536e-01, time/batch = 19.2930s	
11577/30300 (epoch 19.104), train_loss = 1.23391706, grad/param norm = 1.9423e-01, time/batch = 18.6332s	
11578/30300 (epoch 19.106), train_loss = 1.26381884, grad/param norm = 1.8698e-01, time/batch = 17.2108s	
11579/30300 (epoch 19.107), train_loss = 1.27307423, grad/param norm = 1.5089e-01, time/batch = 18.4490s	
11580/30300 (epoch 19.109), train_loss = 1.36573821, grad/param norm = 1.8277e-01, time/batch = 18.8749s	
11581/30300 (epoch 19.111), train_loss = 1.38554380, grad/param norm = 1.5654e-01, time/batch = 18.4444s	
11582/30300 (epoch 19.112), train_loss = 1.32839842, grad/param norm = 1.5339e-01, time/batch = 17.7765s	
11583/30300 (epoch 19.114), train_loss = 1.26493541, grad/param norm = 1.4801e-01, time/batch = 19.7156s	
11584/30300 (epoch 19.116), train_loss = 1.25881206, grad/param norm = 1.6070e-01, time/batch = 20.0405s	
11585/30300 (epoch 19.117), train_loss = 1.28982430, grad/param norm = 1.3644e-01, time/batch = 17.0493s	
11586/30300 (epoch 19.119), train_loss = 1.18582125, grad/param norm = 1.5177e-01, time/batch = 20.6058s	
11587/30300 (epoch 19.120), train_loss = 1.26232281, grad/param norm = 1.5922e-01, time/batch = 18.5942s	
11588/30300 (epoch 19.122), train_loss = 1.36609062, grad/param norm = 1.8165e-01, time/batch = 18.9343s	
11589/30300 (epoch 19.124), train_loss = 1.43702441, grad/param norm = 1.7110e-01, time/batch = 20.0323s	
11590/30300 (epoch 19.125), train_loss = 1.12005099, grad/param norm = 1.4047e-01, time/batch = 19.1915s	
11591/30300 (epoch 19.127), train_loss = 1.29401731, grad/param norm = 1.6753e-01, time/batch = 19.0326s	
11592/30300 (epoch 19.129), train_loss = 1.41792850, grad/param norm = 1.5042e-01, time/batch = 18.5332s	
11593/30300 (epoch 19.130), train_loss = 1.39872017, grad/param norm = 1.4840e-01, time/batch = 18.3798s	
11594/30300 (epoch 19.132), train_loss = 1.35445970, grad/param norm = 1.5585e-01, time/batch = 16.6923s	
11595/30300 (epoch 19.134), train_loss = 1.17383539, grad/param norm = 1.5234e-01, time/batch = 17.8809s	
11596/30300 (epoch 19.135), train_loss = 1.20008970, grad/param norm = 1.5897e-01, time/batch = 19.4680s	
11597/30300 (epoch 19.137), train_loss = 1.26832790, grad/param norm = 1.5528e-01, time/batch = 19.7071s	
11598/30300 (epoch 19.139), train_loss = 1.22653323, grad/param norm = 1.6736e-01, time/batch = 18.6188s	
11599/30300 (epoch 19.140), train_loss = 1.31596043, grad/param norm = 2.1142e-01, time/batch = 18.2215s	
11600/30300 (epoch 19.142), train_loss = 1.43619710, grad/param norm = 2.1566e-01, time/batch = 20.6898s	
11601/30300 (epoch 19.144), train_loss = 1.30893149, grad/param norm = 2.1619e-01, time/batch = 18.1155s	
11602/30300 (epoch 19.145), train_loss = 1.35994150, grad/param norm = 1.8889e-01, time/batch = 19.2980s	
11603/30300 (epoch 19.147), train_loss = 1.23619488, grad/param norm = 1.6008e-01, time/batch = 18.8714s	
11604/30300 (epoch 19.149), train_loss = 1.45971958, grad/param norm = 1.7030e-01, time/batch = 16.9355s	
11605/30300 (epoch 19.150), train_loss = 1.27959648, grad/param norm = 2.0594e-01, time/batch = 20.2793s	
11606/30300 (epoch 19.152), train_loss = 1.15326696, grad/param norm = 1.6590e-01, time/batch = 19.0469s	
11607/30300 (epoch 19.153), train_loss = 1.27300629, grad/param norm = 1.6603e-01, time/batch = 17.0241s	
11608/30300 (epoch 19.155), train_loss = 1.10126943, grad/param norm = 1.4286e-01, time/batch = 20.3746s	
11609/30300 (epoch 19.157), train_loss = 1.25804076, grad/param norm = 1.5887e-01, time/batch = 17.4688s	
11610/30300 (epoch 19.158), train_loss = 1.27925929, grad/param norm = 1.7911e-01, time/batch = 17.3466s	
11611/30300 (epoch 19.160), train_loss = 1.19401300, grad/param norm = 1.6282e-01, time/batch = 18.1977s	
11612/30300 (epoch 19.162), train_loss = 1.24670171, grad/param norm = 1.4996e-01, time/batch = 18.1208s	
11613/30300 (epoch 19.163), train_loss = 1.20003302, grad/param norm = 1.6336e-01, time/batch = 17.3245s	
11614/30300 (epoch 19.165), train_loss = 1.36486188, grad/param norm = 1.5602e-01, time/batch = 17.0249s	
11615/30300 (epoch 19.167), train_loss = 1.26795979, grad/param norm = 1.6681e-01, time/batch = 17.2981s	
11616/30300 (epoch 19.168), train_loss = 1.30819102, grad/param norm = 1.5470e-01, time/batch = 18.7621s	
11617/30300 (epoch 19.170), train_loss = 1.28673466, grad/param norm = 1.5955e-01, time/batch = 16.0740s	
11618/30300 (epoch 19.172), train_loss = 1.23350497, grad/param norm = 1.6932e-01, time/batch = 17.7194s	
11619/30300 (epoch 19.173), train_loss = 1.27951274, grad/param norm = 1.6797e-01, time/batch = 17.1415s	
11620/30300 (epoch 19.175), train_loss = 1.27056976, grad/param norm = 1.4543e-01, time/batch = 16.6664s	
11621/30300 (epoch 19.177), train_loss = 1.28537516, grad/param norm = 1.7123e-01, time/batch = 18.5052s	
11622/30300 (epoch 19.178), train_loss = 1.03130841, grad/param norm = 1.3823e-01, time/batch = 19.7875s	
11623/30300 (epoch 19.180), train_loss = 1.21571991, grad/param norm = 1.4035e-01, time/batch = 19.0397s	
11624/30300 (epoch 19.182), train_loss = 1.22137419, grad/param norm = 1.7704e-01, time/batch = 17.0157s	
11625/30300 (epoch 19.183), train_loss = 1.18307623, grad/param norm = 1.4396e-01, time/batch = 19.1134s	
11626/30300 (epoch 19.185), train_loss = 1.47635339, grad/param norm = 1.5587e-01, time/batch = 19.4462s	
11627/30300 (epoch 19.186), train_loss = 1.52095652, grad/param norm = 1.7525e-01, time/batch = 17.7468s	
11628/30300 (epoch 19.188), train_loss = 1.32008734, grad/param norm = 1.6937e-01, time/batch = 18.4332s	
11629/30300 (epoch 19.190), train_loss = 1.22889282, grad/param norm = 1.4915e-01, time/batch = 17.2562s	
11630/30300 (epoch 19.191), train_loss = 1.34084513, grad/param norm = 1.5814e-01, time/batch = 18.0846s	
11631/30300 (epoch 19.193), train_loss = 1.16592239, grad/param norm = 1.4097e-01, time/batch = 18.7698s	
11632/30300 (epoch 19.195), train_loss = 1.29796339, grad/param norm = 1.6457e-01, time/batch = 18.9444s	
11633/30300 (epoch 19.196), train_loss = 1.29169846, grad/param norm = 1.4023e-01, time/batch = 19.4487s	
11634/30300 (epoch 19.198), train_loss = 1.07178816, grad/param norm = 1.6244e-01, time/batch = 17.7969s	
11635/30300 (epoch 19.200), train_loss = 1.25497640, grad/param norm = 1.4079e-01, time/batch = 17.9631s	
11636/30300 (epoch 19.201), train_loss = 1.35530489, grad/param norm = 1.6347e-01, time/batch = 19.0220s	
11637/30300 (epoch 19.203), train_loss = 1.28394655, grad/param norm = 1.5964e-01, time/batch = 17.4178s	
11638/30300 (epoch 19.205), train_loss = 1.47159583, grad/param norm = 1.6601e-01, time/batch = 19.1031s	
11639/30300 (epoch 19.206), train_loss = 1.39616864, grad/param norm = 1.7022e-01, time/batch = 18.1223s	
11640/30300 (epoch 19.208), train_loss = 1.38393851, grad/param norm = 1.9194e-01, time/batch = 17.7493s	
11641/30300 (epoch 19.210), train_loss = 1.31207180, grad/param norm = 1.4570e-01, time/batch = 18.1982s	
11642/30300 (epoch 19.211), train_loss = 1.37970619, grad/param norm = 1.5558e-01, time/batch = 19.2855s	
11643/30300 (epoch 19.213), train_loss = 1.20866868, grad/param norm = 1.4053e-01, time/batch = 18.6054s	
11644/30300 (epoch 19.215), train_loss = 1.14780845, grad/param norm = 1.4588e-01, time/batch = 18.4476s	
11645/30300 (epoch 19.216), train_loss = 1.22225548, grad/param norm = 1.6721e-01, time/batch = 18.9955s	
11646/30300 (epoch 19.218), train_loss = 1.14822466, grad/param norm = 1.3808e-01, time/batch = 18.6976s	
11647/30300 (epoch 19.219), train_loss = 1.08234398, grad/param norm = 1.3190e-01, time/batch = 17.0165s	
11648/30300 (epoch 19.221), train_loss = 1.10458849, grad/param norm = 1.4499e-01, time/batch = 19.3715s	
11649/30300 (epoch 19.223), train_loss = 1.27882388, grad/param norm = 1.3880e-01, time/batch = 20.2758s	
11650/30300 (epoch 19.224), train_loss = 1.09586914, grad/param norm = 1.4486e-01, time/batch = 18.0284s	
11651/30300 (epoch 19.226), train_loss = 1.35423955, grad/param norm = 1.7672e-01, time/batch = 20.1276s	
11652/30300 (epoch 19.228), train_loss = 1.35662954, grad/param norm = 1.5361e-01, time/batch = 20.5290s	
11653/30300 (epoch 19.229), train_loss = 1.18674718, grad/param norm = 1.4005e-01, time/batch = 17.7809s	
11654/30300 (epoch 19.231), train_loss = 1.29981759, grad/param norm = 1.5131e-01, time/batch = 19.9366s	
11655/30300 (epoch 19.233), train_loss = 1.23135846, grad/param norm = 1.4122e-01, time/batch = 19.7858s	
11656/30300 (epoch 19.234), train_loss = 1.31861108, grad/param norm = 1.7335e-01, time/batch = 31.2485s	
11657/30300 (epoch 19.236), train_loss = 1.25472795, grad/param norm = 1.3812e-01, time/batch = 18.9537s	
11658/30300 (epoch 19.238), train_loss = 1.30879196, grad/param norm = 1.7038e-01, time/batch = 19.0401s	
11659/30300 (epoch 19.239), train_loss = 1.30288820, grad/param norm = 1.6201e-01, time/batch = 18.2192s	
11660/30300 (epoch 19.241), train_loss = 1.28867922, grad/param norm = 1.5675e-01, time/batch = 18.4577s	
11661/30300 (epoch 19.243), train_loss = 1.33068731, grad/param norm = 1.5397e-01, time/batch = 19.6188s	
11662/30300 (epoch 19.244), train_loss = 1.49715447, grad/param norm = 1.6496e-01, time/batch = 19.0337s	
11663/30300 (epoch 19.246), train_loss = 1.26949763, grad/param norm = 1.5669e-01, time/batch = 17.0860s	
11664/30300 (epoch 19.248), train_loss = 1.24301855, grad/param norm = 1.4968e-01, time/batch = 19.7921s	
11665/30300 (epoch 19.249), train_loss = 1.19253081, grad/param norm = 1.4945e-01, time/batch = 17.5970s	
11666/30300 (epoch 19.251), train_loss = 1.16976063, grad/param norm = 1.5322e-01, time/batch = 17.3554s	
11667/30300 (epoch 19.252), train_loss = 1.37167650, grad/param norm = 1.5690e-01, time/batch = 17.6920s	
11668/30300 (epoch 19.254), train_loss = 1.37299727, grad/param norm = 1.8545e-01, time/batch = 17.1790s	
11669/30300 (epoch 19.256), train_loss = 1.31267152, grad/param norm = 1.5412e-01, time/batch = 18.2774s	
11670/30300 (epoch 19.257), train_loss = 1.32676426, grad/param norm = 1.5496e-01, time/batch = 17.9563s	
11671/30300 (epoch 19.259), train_loss = 1.24857839, grad/param norm = 1.5299e-01, time/batch = 19.2714s	
11672/30300 (epoch 19.261), train_loss = 1.36597689, grad/param norm = 1.4606e-01, time/batch = 18.1562s	
11673/30300 (epoch 19.262), train_loss = 1.25071037, grad/param norm = 1.4794e-01, time/batch = 19.5226s	
11674/30300 (epoch 19.264), train_loss = 1.27315594, grad/param norm = 1.5407e-01, time/batch = 18.9486s	
11675/30300 (epoch 19.266), train_loss = 1.19718372, grad/param norm = 1.4573e-01, time/batch = 17.7104s	
11676/30300 (epoch 19.267), train_loss = 1.45732106, grad/param norm = 1.7475e-01, time/batch = 19.3671s	
11677/30300 (epoch 19.269), train_loss = 1.30065250, grad/param norm = 1.6759e-01, time/batch = 17.6255s	
11678/30300 (epoch 19.271), train_loss = 1.28497648, grad/param norm = 1.5693e-01, time/batch = 17.1291s	
11679/30300 (epoch 19.272), train_loss = 1.28550850, grad/param norm = 1.6476e-01, time/batch = 19.3679s	
11680/30300 (epoch 19.274), train_loss = 1.38697094, grad/param norm = 1.5848e-01, time/batch = 19.9540s	
11681/30300 (epoch 19.276), train_loss = 1.32231128, grad/param norm = 1.6588e-01, time/batch = 18.5350s	
11682/30300 (epoch 19.277), train_loss = 1.14631428, grad/param norm = 1.5160e-01, time/batch = 19.6100s	
11683/30300 (epoch 19.279), train_loss = 1.30875970, grad/param norm = 1.5755e-01, time/batch = 19.7850s	
11684/30300 (epoch 19.281), train_loss = 1.34635271, grad/param norm = 1.6383e-01, time/batch = 17.8699s	
11685/30300 (epoch 19.282), train_loss = 1.26272764, grad/param norm = 1.4491e-01, time/batch = 19.0306s	
11686/30300 (epoch 19.284), train_loss = 1.44491260, grad/param norm = 2.1229e-01, time/batch = 19.7883s	
11687/30300 (epoch 19.285), train_loss = 1.30040434, grad/param norm = 1.3975e-01, time/batch = 18.5283s	
11688/30300 (epoch 19.287), train_loss = 1.27468500, grad/param norm = 1.5700e-01, time/batch = 17.2270s	
11689/30300 (epoch 19.289), train_loss = 1.33090696, grad/param norm = 1.5020e-01, time/batch = 17.8255s	
11690/30300 (epoch 19.290), train_loss = 1.02555055, grad/param norm = 1.3549e-01, time/batch = 18.6734s	
11691/30300 (epoch 19.292), train_loss = 1.14883154, grad/param norm = 1.3262e-01, time/batch = 17.2671s	
11692/30300 (epoch 19.294), train_loss = 1.39435123, grad/param norm = 1.9563e-01, time/batch = 16.0772s	
11693/30300 (epoch 19.295), train_loss = 1.23768628, grad/param norm = 1.4890e-01, time/batch = 17.6777s	
11694/30300 (epoch 19.297), train_loss = 1.19278937, grad/param norm = 1.4202e-01, time/batch = 16.5992s	
11695/30300 (epoch 19.299), train_loss = 1.25904068, grad/param norm = 1.7402e-01, time/batch = 15.7902s	
11696/30300 (epoch 19.300), train_loss = 1.23206746, grad/param norm = 1.5184e-01, time/batch = 16.6568s	
11697/30300 (epoch 19.302), train_loss = 1.26059152, grad/param norm = 1.4761e-01, time/batch = 15.8955s	
11698/30300 (epoch 19.304), train_loss = 1.17659048, grad/param norm = 1.4349e-01, time/batch = 16.3889s	
11699/30300 (epoch 19.305), train_loss = 1.22387315, grad/param norm = 1.4390e-01, time/batch = 15.8952s	
11700/30300 (epoch 19.307), train_loss = 1.30537946, grad/param norm = 1.4390e-01, time/batch = 15.7915s	
11701/30300 (epoch 19.309), train_loss = 1.33930015, grad/param norm = 1.7020e-01, time/batch = 15.7866s	
11702/30300 (epoch 19.310), train_loss = 1.25760214, grad/param norm = 1.5892e-01, time/batch = 17.0706s	
11703/30300 (epoch 19.312), train_loss = 1.40748889, grad/param norm = 1.5198e-01, time/batch = 16.4179s	
11704/30300 (epoch 19.314), train_loss = 1.29294263, grad/param norm = 1.5003e-01, time/batch = 18.3352s	
11705/30300 (epoch 19.315), train_loss = 1.28060332, grad/param norm = 1.5725e-01, time/batch = 16.8346s	
11706/30300 (epoch 19.317), train_loss = 1.32766094, grad/param norm = 1.4815e-01, time/batch = 16.9701s	
11707/30300 (epoch 19.318), train_loss = 1.39416152, grad/param norm = 1.6991e-01, time/batch = 19.1083s	
11708/30300 (epoch 19.320), train_loss = 1.34841002, grad/param norm = 1.4743e-01, time/batch = 18.2633s	
11709/30300 (epoch 19.322), train_loss = 1.19225575, grad/param norm = 1.5515e-01, time/batch = 15.7129s	
11710/30300 (epoch 19.323), train_loss = 1.36042963, grad/param norm = 1.5955e-01, time/batch = 16.9125s	
11711/30300 (epoch 19.325), train_loss = 1.24050483, grad/param norm = 1.4521e-01, time/batch = 18.9266s	
11712/30300 (epoch 19.327), train_loss = 1.26919466, grad/param norm = 1.4126e-01, time/batch = 15.7921s	
11713/30300 (epoch 19.328), train_loss = 1.26644634, grad/param norm = 1.4420e-01, time/batch = 15.5712s	
11714/30300 (epoch 19.330), train_loss = 1.32770706, grad/param norm = 1.4801e-01, time/batch = 16.3536s	
11715/30300 (epoch 19.332), train_loss = 1.34465918, grad/param norm = 1.5856e-01, time/batch = 15.2549s	
11716/30300 (epoch 19.333), train_loss = 1.25254788, grad/param norm = 1.5530e-01, time/batch = 15.7158s	
11717/30300 (epoch 19.335), train_loss = 1.14321467, grad/param norm = 1.4493e-01, time/batch = 15.9090s	
11718/30300 (epoch 19.337), train_loss = 1.41166247, grad/param norm = 1.4908e-01, time/batch = 15.6913s	
11719/30300 (epoch 19.338), train_loss = 1.18265085, grad/param norm = 1.3888e-01, time/batch = 15.9234s	
11720/30300 (epoch 19.340), train_loss = 1.15960539, grad/param norm = 1.3178e-01, time/batch = 15.6399s	
11721/30300 (epoch 19.342), train_loss = 1.34919937, grad/param norm = 1.5057e-01, time/batch = 16.1658s	
11722/30300 (epoch 19.343), train_loss = 1.30157270, grad/param norm = 1.6687e-01, time/batch = 15.8647s	
11723/30300 (epoch 19.345), train_loss = 1.30247459, grad/param norm = 1.5055e-01, time/batch = 15.9798s	
11724/30300 (epoch 19.347), train_loss = 1.12187353, grad/param norm = 1.5284e-01, time/batch = 16.5676s	
11725/30300 (epoch 19.348), train_loss = 1.14927466, grad/param norm = 1.5208e-01, time/batch = 15.9311s	
11726/30300 (epoch 19.350), train_loss = 1.25645155, grad/param norm = 1.4595e-01, time/batch = 15.6307s	
11727/30300 (epoch 19.351), train_loss = 1.25370988, grad/param norm = 1.5771e-01, time/batch = 16.1249s	
11728/30300 (epoch 19.353), train_loss = 1.08744703, grad/param norm = 1.4183e-01, time/batch = 15.5803s	
11729/30300 (epoch 19.355), train_loss = 1.21865845, grad/param norm = 1.4990e-01, time/batch = 15.4577s	
11730/30300 (epoch 19.356), train_loss = 1.34522343, grad/param norm = 1.9971e-01, time/batch = 16.0300s	
11731/30300 (epoch 19.358), train_loss = 1.51978467, grad/param norm = 1.5904e-01, time/batch = 15.5490s	
11732/30300 (epoch 19.360), train_loss = 1.23124311, grad/param norm = 1.8363e-01, time/batch = 15.8022s	
11733/30300 (epoch 19.361), train_loss = 1.30463115, grad/param norm = 1.6177e-01, time/batch = 15.7806s	
11734/30300 (epoch 19.363), train_loss = 1.34477557, grad/param norm = 1.5425e-01, time/batch = 15.7682s	
11735/30300 (epoch 19.365), train_loss = 1.16838180, grad/param norm = 1.5972e-01, time/batch = 15.7895s	
11736/30300 (epoch 19.366), train_loss = 1.21979675, grad/param norm = 1.4652e-01, time/batch = 16.7787s	
11737/30300 (epoch 19.368), train_loss = 1.08834679, grad/param norm = 1.4269e-01, time/batch = 17.3489s	
11738/30300 (epoch 19.370), train_loss = 1.14864749, grad/param norm = 1.5238e-01, time/batch = 15.7917s	
11739/30300 (epoch 19.371), train_loss = 1.35157641, grad/param norm = 1.6065e-01, time/batch = 16.0072s	
11740/30300 (epoch 19.373), train_loss = 1.17446334, grad/param norm = 1.2703e-01, time/batch = 15.4621s	
11741/30300 (epoch 19.375), train_loss = 1.16582506, grad/param norm = 1.4956e-01, time/batch = 16.0575s	
11742/30300 (epoch 19.376), train_loss = 1.18332794, grad/param norm = 1.3632e-01, time/batch = 17.9157s	
11743/30300 (epoch 19.378), train_loss = 1.19233841, grad/param norm = 1.5487e-01, time/batch = 18.5193s	
11744/30300 (epoch 19.380), train_loss = 1.42903806, grad/param norm = 1.5903e-01, time/batch = 15.5445s	
11745/30300 (epoch 19.381), train_loss = 1.12876685, grad/param norm = 1.4208e-01, time/batch = 17.0823s	
11746/30300 (epoch 19.383), train_loss = 1.19503822, grad/param norm = 1.5176e-01, time/batch = 18.0288s	
11747/30300 (epoch 19.384), train_loss = 1.33340121, grad/param norm = 1.4885e-01, time/batch = 16.1377s	
11748/30300 (epoch 19.386), train_loss = 1.14949482, grad/param norm = 1.5422e-01, time/batch = 18.1624s	
11749/30300 (epoch 19.388), train_loss = 1.09998470, grad/param norm = 1.3243e-01, time/batch = 17.8433s	
11750/30300 (epoch 19.389), train_loss = 1.23237354, grad/param norm = 1.6173e-01, time/batch = 16.4874s	
11751/30300 (epoch 19.391), train_loss = 1.27637006, grad/param norm = 1.3911e-01, time/batch = 17.8941s	
11752/30300 (epoch 19.393), train_loss = 1.09528247, grad/param norm = 1.3100e-01, time/batch = 18.1913s	
11753/30300 (epoch 19.394), train_loss = 1.31721526, grad/param norm = 1.5021e-01, time/batch = 16.0100s	
11754/30300 (epoch 19.396), train_loss = 1.39223563, grad/param norm = 1.5742e-01, time/batch = 17.4831s	
11755/30300 (epoch 19.398), train_loss = 1.22970346, grad/param norm = 1.3701e-01, time/batch = 17.3518s	
11756/30300 (epoch 19.399), train_loss = 1.22516935, grad/param norm = 1.5511e-01, time/batch = 15.9873s	
11757/30300 (epoch 19.401), train_loss = 1.29498642, grad/param norm = 1.4368e-01, time/batch = 17.1565s	
11758/30300 (epoch 19.403), train_loss = 1.22467631, grad/param norm = 1.5201e-01, time/batch = 18.1149s	
11759/30300 (epoch 19.404), train_loss = 1.16097034, grad/param norm = 1.5787e-01, time/batch = 16.8958s	
11760/30300 (epoch 19.406), train_loss = 1.26017737, grad/param norm = 1.3782e-01, time/batch = 16.4732s	
11761/30300 (epoch 19.408), train_loss = 1.11990731, grad/param norm = 1.4107e-01, time/batch = 17.3311s	
11762/30300 (epoch 19.409), train_loss = 1.12225356, grad/param norm = 1.4632e-01, time/batch = 18.8502s	
11763/30300 (epoch 19.411), train_loss = 1.12550172, grad/param norm = 1.3291e-01, time/batch = 15.6308s	
11764/30300 (epoch 19.413), train_loss = 1.05967808, grad/param norm = 1.4149e-01, time/batch = 16.9993s	
11765/30300 (epoch 19.414), train_loss = 1.37448271, grad/param norm = 1.5635e-01, time/batch = 17.6937s	
11766/30300 (epoch 19.416), train_loss = 1.20524493, grad/param norm = 1.4707e-01, time/batch = 16.5278s	
11767/30300 (epoch 19.417), train_loss = 1.17129502, grad/param norm = 1.4410e-01, time/batch = 16.8397s	
11768/30300 (epoch 19.419), train_loss = 1.12560715, grad/param norm = 1.2716e-01, time/batch = 18.4322s	
11769/30300 (epoch 19.421), train_loss = 1.20239780, grad/param norm = 1.8230e-01, time/batch = 15.3785s	
11770/30300 (epoch 19.422), train_loss = 1.23857618, grad/param norm = 1.9251e-01, time/batch = 16.2591s	
11771/30300 (epoch 19.424), train_loss = 1.25207116, grad/param norm = 1.4472e-01, time/batch = 19.3744s	
11772/30300 (epoch 19.426), train_loss = 1.16141148, grad/param norm = 1.4641e-01, time/batch = 18.7041s	
11773/30300 (epoch 19.427), train_loss = 1.21569748, grad/param norm = 1.5377e-01, time/batch = 17.2543s	
11774/30300 (epoch 19.429), train_loss = 1.22799001, grad/param norm = 1.3793e-01, time/batch = 16.5750s	
11775/30300 (epoch 19.431), train_loss = 1.30114153, grad/param norm = 1.4287e-01, time/batch = 15.6217s	
11776/30300 (epoch 19.432), train_loss = 1.20644089, grad/param norm = 1.3598e-01, time/batch = 15.7796s	
11777/30300 (epoch 19.434), train_loss = 1.10233782, grad/param norm = 1.3891e-01, time/batch = 15.6554s	
11778/30300 (epoch 19.436), train_loss = 1.37912054, grad/param norm = 1.5664e-01, time/batch = 16.0857s	
11779/30300 (epoch 19.437), train_loss = 1.12666162, grad/param norm = 1.4206e-01, time/batch = 18.8537s	
11780/30300 (epoch 19.439), train_loss = 1.19159655, grad/param norm = 1.5510e-01, time/batch = 17.7119s	
11781/30300 (epoch 19.441), train_loss = 1.20145737, grad/param norm = 1.3502e-01, time/batch = 18.8004s	
11782/30300 (epoch 19.442), train_loss = 1.13751964, grad/param norm = 1.5227e-01, time/batch = 18.9701s	
11783/30300 (epoch 19.444), train_loss = 1.03073412, grad/param norm = 1.4634e-01, time/batch = 18.5327s	
11784/30300 (epoch 19.446), train_loss = 1.21466719, grad/param norm = 1.4378e-01, time/batch = 18.2239s	
11785/30300 (epoch 19.447), train_loss = 1.22780812, grad/param norm = 1.6530e-01, time/batch = 17.8650s	
11786/30300 (epoch 19.449), train_loss = 1.14948760, grad/param norm = 1.4370e-01, time/batch = 18.7132s	
11787/30300 (epoch 19.450), train_loss = 1.31741353, grad/param norm = 1.4147e-01, time/batch = 17.8414s	
11788/30300 (epoch 19.452), train_loss = 1.31663686, grad/param norm = 1.3933e-01, time/batch = 19.7049s	
11789/30300 (epoch 19.454), train_loss = 1.28784599, grad/param norm = 1.3361e-01, time/batch = 19.2278s	
11790/30300 (epoch 19.455), train_loss = 1.29295941, grad/param norm = 1.9967e-01, time/batch = 18.3830s	
11791/30300 (epoch 19.457), train_loss = 1.25026255, grad/param norm = 1.4820e-01, time/batch = 19.2171s	
11792/30300 (epoch 19.459), train_loss = 1.31351093, grad/param norm = 1.5815e-01, time/batch = 19.8873s	
11793/30300 (epoch 19.460), train_loss = 1.27104684, grad/param norm = 1.4927e-01, time/batch = 18.1024s	
11794/30300 (epoch 19.462), train_loss = 1.31441881, grad/param norm = 1.5187e-01, time/batch = 19.1113s	
11795/30300 (epoch 19.464), train_loss = 1.07539007, grad/param norm = 1.4888e-01, time/batch = 19.2883s	
11796/30300 (epoch 19.465), train_loss = 1.06744476, grad/param norm = 1.3788e-01, time/batch = 18.2971s	
11797/30300 (epoch 19.467), train_loss = 1.02862704, grad/param norm = 1.2660e-01, time/batch = 18.3813s	
11798/30300 (epoch 19.469), train_loss = 1.13101326, grad/param norm = 1.2405e-01, time/batch = 18.8646s	
11799/30300 (epoch 19.470), train_loss = 1.20934114, grad/param norm = 1.4318e-01, time/batch = 17.5260s	
11800/30300 (epoch 19.472), train_loss = 1.19157021, grad/param norm = 1.3514e-01, time/batch = 19.1618s	
11801/30300 (epoch 19.474), train_loss = 1.23006668, grad/param norm = 1.6528e-01, time/batch = 18.7984s	
11802/30300 (epoch 19.475), train_loss = 1.14957276, grad/param norm = 1.4210e-01, time/batch = 18.7861s	
11803/30300 (epoch 19.477), train_loss = 1.23549009, grad/param norm = 1.5733e-01, time/batch = 19.2895s	
11804/30300 (epoch 19.479), train_loss = 1.23032733, grad/param norm = 1.4900e-01, time/batch = 19.7010s	
11805/30300 (epoch 19.480), train_loss = 1.25348973, grad/param norm = 1.3746e-01, time/batch = 19.6094s	
11806/30300 (epoch 19.482), train_loss = 1.28332651, grad/param norm = 1.3704e-01, time/batch = 18.7891s	
11807/30300 (epoch 19.483), train_loss = 1.17961639, grad/param norm = 1.4542e-01, time/batch = 19.4402s	
11808/30300 (epoch 19.485), train_loss = 1.24226661, grad/param norm = 1.4969e-01, time/batch = 19.1303s	
11809/30300 (epoch 19.487), train_loss = 1.32999084, grad/param norm = 1.5182e-01, time/batch = 18.1983s	
11810/30300 (epoch 19.488), train_loss = 1.31978863, grad/param norm = 1.3984e-01, time/batch = 19.7977s	
11811/30300 (epoch 19.490), train_loss = 1.12104513, grad/param norm = 1.4123e-01, time/batch = 19.0460s	
11812/30300 (epoch 19.492), train_loss = 1.21145610, grad/param norm = 1.5052e-01, time/batch = 18.8558s	
11813/30300 (epoch 19.493), train_loss = 1.20454592, grad/param norm = 1.3949e-01, time/batch = 19.6301s	
11814/30300 (epoch 19.495), train_loss = 1.17496757, grad/param norm = 1.3111e-01, time/batch = 18.1028s	
11815/30300 (epoch 19.497), train_loss = 1.26592322, grad/param norm = 1.4249e-01, time/batch = 17.2627s	
11816/30300 (epoch 19.498), train_loss = 1.28142738, grad/param norm = 1.5216e-01, time/batch = 19.6124s	
11817/30300 (epoch 19.500), train_loss = 1.26720226, grad/param norm = 1.6607e-01, time/batch = 19.3732s	
11818/30300 (epoch 19.502), train_loss = 1.22286268, grad/param norm = 1.5226e-01, time/batch = 18.0484s	
11819/30300 (epoch 19.503), train_loss = 1.31591359, grad/param norm = 1.4054e-01, time/batch = 19.1930s	
11820/30300 (epoch 19.505), train_loss = 1.18918699, grad/param norm = 1.5743e-01, time/batch = 19.6366s	
11821/30300 (epoch 19.507), train_loss = 1.16512294, grad/param norm = 1.5132e-01, time/batch = 18.0306s	
11822/30300 (epoch 19.508), train_loss = 1.19571230, grad/param norm = 1.5568e-01, time/batch = 19.2022s	
11823/30300 (epoch 19.510), train_loss = 1.32433499, grad/param norm = 1.5549e-01, time/batch = 19.4459s	
11824/30300 (epoch 19.512), train_loss = 1.16583723, grad/param norm = 1.3586e-01, time/batch = 19.0986s	
11825/30300 (epoch 19.513), train_loss = 1.26043111, grad/param norm = 1.4299e-01, time/batch = 16.8675s	
11826/30300 (epoch 19.515), train_loss = 1.22510171, grad/param norm = 1.4269e-01, time/batch = 19.4652s	
11827/30300 (epoch 19.517), train_loss = 1.06605713, grad/param norm = 1.3245e-01, time/batch = 19.9582s	
11828/30300 (epoch 19.518), train_loss = 1.31395818, grad/param norm = 1.5441e-01, time/batch = 17.4235s	
11829/30300 (epoch 19.520), train_loss = 1.31598045, grad/param norm = 1.5601e-01, time/batch = 18.4653s	
11830/30300 (epoch 19.521), train_loss = 1.13447826, grad/param norm = 1.6585e-01, time/batch = 18.7872s	
11831/30300 (epoch 19.523), train_loss = 1.39769110, grad/param norm = 1.9330e-01, time/batch = 17.3644s	
11832/30300 (epoch 19.525), train_loss = 1.15058323, grad/param norm = 1.4139e-01, time/batch = 18.8884s	
11833/30300 (epoch 19.526), train_loss = 1.21060591, grad/param norm = 1.5897e-01, time/batch = 19.8931s	
11834/30300 (epoch 19.528), train_loss = 1.11780542, grad/param norm = 1.3701e-01, time/batch = 18.7812s	
11835/30300 (epoch 19.530), train_loss = 1.10175765, grad/param norm = 1.4328e-01, time/batch = 18.8795s	
11836/30300 (epoch 19.531), train_loss = 1.29156244, grad/param norm = 1.5778e-01, time/batch = 20.2891s	
11837/30300 (epoch 19.533), train_loss = 1.25161515, grad/param norm = 1.5855e-01, time/batch = 18.4637s	
11838/30300 (epoch 19.535), train_loss = 1.11918865, grad/param norm = 1.3189e-01, time/batch = 19.2795s	
11839/30300 (epoch 19.536), train_loss = 1.25358615, grad/param norm = 1.5032e-01, time/batch = 19.3007s	
11840/30300 (epoch 19.538), train_loss = 1.10248002, grad/param norm = 1.5270e-01, time/batch = 18.4598s	
11841/30300 (epoch 19.540), train_loss = 1.12692785, grad/param norm = 1.4836e-01, time/batch = 18.4664s	
11842/30300 (epoch 19.541), train_loss = 1.23481169, grad/param norm = 1.5543e-01, time/batch = 17.2888s	
11843/30300 (epoch 19.543), train_loss = 1.21495870, grad/param norm = 1.4332e-01, time/batch = 19.7085s	
11844/30300 (epoch 19.545), train_loss = 1.20877943, grad/param norm = 1.5324e-01, time/batch = 19.7726s	
11845/30300 (epoch 19.546), train_loss = 1.46301720, grad/param norm = 1.4777e-01, time/batch = 19.2938s	
11846/30300 (epoch 19.548), train_loss = 1.15555949, grad/param norm = 1.3658e-01, time/batch = 19.3843s	
11847/30300 (epoch 19.550), train_loss = 1.32685891, grad/param norm = 1.7992e-01, time/batch = 17.6800s	
11848/30300 (epoch 19.551), train_loss = 1.16176561, grad/param norm = 1.4957e-01, time/batch = 18.9589s	
11849/30300 (epoch 19.553), train_loss = 1.18729294, grad/param norm = 1.4392e-01, time/batch = 20.0424s	
11850/30300 (epoch 19.554), train_loss = 1.23567014, grad/param norm = 1.5878e-01, time/batch = 18.2013s	
11851/30300 (epoch 19.556), train_loss = 1.28364080, grad/param norm = 1.4647e-01, time/batch = 19.1386s	
11852/30300 (epoch 19.558), train_loss = 1.35846724, grad/param norm = 1.6123e-01, time/batch = 19.0398s	
11853/30300 (epoch 19.559), train_loss = 1.30716799, grad/param norm = 1.6140e-01, time/batch = 17.8883s	
11854/30300 (epoch 19.561), train_loss = 1.06662604, grad/param norm = 1.4786e-01, time/batch = 18.3802s	
11855/30300 (epoch 19.563), train_loss = 1.13347253, grad/param norm = 1.4260e-01, time/batch = 19.9556s	
11856/30300 (epoch 19.564), train_loss = 1.15835362, grad/param norm = 1.4304e-01, time/batch = 20.4991s	
11857/30300 (epoch 19.566), train_loss = 1.25242284, grad/param norm = 1.5134e-01, time/batch = 0.9762s	
11858/30300 (epoch 19.568), train_loss = 1.03751491, grad/param norm = 1.3707e-01, time/batch = 0.6906s	
11859/30300 (epoch 19.569), train_loss = 1.23930091, grad/param norm = 1.4163e-01, time/batch = 0.6884s	
11860/30300 (epoch 19.571), train_loss = 1.27172967, grad/param norm = 1.6449e-01, time/batch = 0.7106s	
11861/30300 (epoch 19.573), train_loss = 1.27764671, grad/param norm = 1.5276e-01, time/batch = 0.6890s	
11862/30300 (epoch 19.574), train_loss = 1.31431571, grad/param norm = 1.4828e-01, time/batch = 0.6903s	
11863/30300 (epoch 19.576), train_loss = 1.22843771, grad/param norm = 1.3747e-01, time/batch = 0.6896s	
11864/30300 (epoch 19.578), train_loss = 1.08019656, grad/param norm = 1.3233e-01, time/batch = 0.6940s	
11865/30300 (epoch 19.579), train_loss = 1.25300344, grad/param norm = 1.6524e-01, time/batch = 0.6887s	
11866/30300 (epoch 19.581), train_loss = 1.31758937, grad/param norm = 1.4042e-01, time/batch = 0.6987s	
11867/30300 (epoch 19.583), train_loss = 1.39848214, grad/param norm = 1.7144e-01, time/batch = 0.6959s	
11868/30300 (epoch 19.584), train_loss = 1.32735732, grad/param norm = 1.5322e-01, time/batch = 0.7212s	
11869/30300 (epoch 19.586), train_loss = 1.23087464, grad/param norm = 1.4997e-01, time/batch = 0.7018s	
11870/30300 (epoch 19.587), train_loss = 1.21663586, grad/param norm = 1.4427e-01, time/batch = 0.7942s	
11871/30300 (epoch 19.589), train_loss = 1.12095060, grad/param norm = 1.3785e-01, time/batch = 1.0075s	
11872/30300 (epoch 19.591), train_loss = 1.28236829, grad/param norm = 1.4336e-01, time/batch = 1.0167s	
11873/30300 (epoch 19.592), train_loss = 1.23509341, grad/param norm = 1.3690e-01, time/batch = 1.0302s	
11874/30300 (epoch 19.594), train_loss = 1.24669556, grad/param norm = 1.4446e-01, time/batch = 1.0250s	
11875/30300 (epoch 19.596), train_loss = 1.14254483, grad/param norm = 1.3642e-01, time/batch = 1.4275s	
11876/30300 (epoch 19.597), train_loss = 1.17150241, grad/param norm = 1.4876e-01, time/batch = 1.8760s	
11877/30300 (epoch 19.599), train_loss = 1.05996377, grad/param norm = 1.4559e-01, time/batch = 1.9109s	
11878/30300 (epoch 19.601), train_loss = 1.28066846, grad/param norm = 1.5839e-01, time/batch = 18.3650s	
11879/30300 (epoch 19.602), train_loss = 1.22781744, grad/param norm = 1.4365e-01, time/batch = 18.4467s	
11880/30300 (epoch 19.604), train_loss = 1.12522382, grad/param norm = 1.3238e-01, time/batch = 18.0383s	
11881/30300 (epoch 19.606), train_loss = 1.21299726, grad/param norm = 4.4844e-01, time/batch = 18.4458s	
11882/30300 (epoch 19.607), train_loss = 1.32420010, grad/param norm = 1.7698e-01, time/batch = 17.6654s	
11883/30300 (epoch 19.609), train_loss = 1.44370856, grad/param norm = 1.6836e-01, time/batch = 19.0361s	
11884/30300 (epoch 19.611), train_loss = 1.16312462, grad/param norm = 1.3906e-01, time/batch = 19.0444s	
11885/30300 (epoch 19.612), train_loss = 1.12986164, grad/param norm = 1.4601e-01, time/batch = 19.4633s	
11886/30300 (epoch 19.614), train_loss = 1.18686485, grad/param norm = 1.4246e-01, time/batch = 18.6231s	
11887/30300 (epoch 19.616), train_loss = 1.26898873, grad/param norm = 1.6849e-01, time/batch = 19.0437s	
11888/30300 (epoch 19.617), train_loss = 1.23721713, grad/param norm = 1.5409e-01, time/batch = 19.7154s	
11889/30300 (epoch 19.619), train_loss = 1.04621053, grad/param norm = 1.4285e-01, time/batch = 17.4751s	
11890/30300 (epoch 19.620), train_loss = 1.23321366, grad/param norm = 1.4797e-01, time/batch = 18.2903s	
11891/30300 (epoch 19.622), train_loss = 1.21165594, grad/param norm = 1.6905e-01, time/batch = 19.2212s	
11892/30300 (epoch 19.624), train_loss = 1.16950773, grad/param norm = 1.4875e-01, time/batch = 17.9499s	
11893/30300 (epoch 19.625), train_loss = 1.19522793, grad/param norm = 1.7390e-01, time/batch = 19.2882s	
11894/30300 (epoch 19.627), train_loss = 1.34906876, grad/param norm = 1.6390e-01, time/batch = 20.0509s	
11895/30300 (epoch 19.629), train_loss = 1.32247167, grad/param norm = 1.4672e-01, time/batch = 18.2971s	
11896/30300 (epoch 19.630), train_loss = 1.23565930, grad/param norm = 1.4192e-01, time/batch = 17.6827s	
11897/30300 (epoch 19.632), train_loss = 1.30816400, grad/param norm = 1.5456e-01, time/batch = 18.8011s	
11898/30300 (epoch 19.634), train_loss = 1.12676417, grad/param norm = 1.3822e-01, time/batch = 19.3796s	
11899/30300 (epoch 19.635), train_loss = 1.27547950, grad/param norm = 1.5716e-01, time/batch = 18.9292s	
11900/30300 (epoch 19.637), train_loss = 1.28815816, grad/param norm = 1.6384e-01, time/batch = 19.0517s	
11901/30300 (epoch 19.639), train_loss = 1.17252662, grad/param norm = 1.4667e-01, time/batch = 18.7169s	
11902/30300 (epoch 19.640), train_loss = 1.36513142, grad/param norm = 1.6740e-01, time/batch = 17.2992s	
11903/30300 (epoch 19.642), train_loss = 1.19574209, grad/param norm = 1.3078e-01, time/batch = 20.1156s	
11904/30300 (epoch 19.644), train_loss = 1.28983304, grad/param norm = 1.3712e-01, time/batch = 18.6194s	
11905/30300 (epoch 19.645), train_loss = 1.10355798, grad/param norm = 1.3025e-01, time/batch = 17.9588s	
11906/30300 (epoch 19.647), train_loss = 1.20258140, grad/param norm = 1.4319e-01, time/batch = 19.1842s	
11907/30300 (epoch 19.649), train_loss = 1.18623139, grad/param norm = 1.5960e-01, time/batch = 20.1207s	
11908/30300 (epoch 19.650), train_loss = 1.20603905, grad/param norm = 1.4363e-01, time/batch = 17.3607s	
11909/30300 (epoch 19.652), train_loss = 1.17159177, grad/param norm = 1.6450e-01, time/batch = 19.8080s	
11910/30300 (epoch 19.653), train_loss = 1.41181355, grad/param norm = 1.5836e-01, time/batch = 19.2143s	
11911/30300 (epoch 19.655), train_loss = 1.16165796, grad/param norm = 1.5999e-01, time/batch = 16.6845s	
11912/30300 (epoch 19.657), train_loss = 1.17541588, grad/param norm = 1.4446e-01, time/batch = 19.2822s	
11913/30300 (epoch 19.658), train_loss = 1.14088296, grad/param norm = 1.3519e-01, time/batch = 19.8761s	
11914/30300 (epoch 19.660), train_loss = 1.24447303, grad/param norm = 1.5004e-01, time/batch = 17.5378s	
11915/30300 (epoch 19.662), train_loss = 1.26519994, grad/param norm = 1.6416e-01, time/batch = 19.3784s	
11916/30300 (epoch 19.663), train_loss = 1.25540871, grad/param norm = 1.5499e-01, time/batch = 19.9634s	
11917/30300 (epoch 19.665), train_loss = 1.14792167, grad/param norm = 1.5705e-01, time/batch = 18.8909s	
11918/30300 (epoch 19.667), train_loss = 1.33457334, grad/param norm = 1.5325e-01, time/batch = 19.5330s	
11919/30300 (epoch 19.668), train_loss = 1.35625652, grad/param norm = 1.5710e-01, time/batch = 19.4523s	
11920/30300 (epoch 19.670), train_loss = 1.33365146, grad/param norm = 1.5213e-01, time/batch = 19.2189s	
11921/30300 (epoch 19.672), train_loss = 1.29763825, grad/param norm = 1.5732e-01, time/batch = 17.8644s	
11922/30300 (epoch 19.673), train_loss = 1.30112303, grad/param norm = 1.6460e-01, time/batch = 19.1428s	
11923/30300 (epoch 19.675), train_loss = 1.19086173, grad/param norm = 1.4953e-01, time/batch = 18.8116s	
11924/30300 (epoch 19.677), train_loss = 1.17231081, grad/param norm = 1.4385e-01, time/batch = 18.4565s	
11925/30300 (epoch 19.678), train_loss = 1.18946780, grad/param norm = 1.4992e-01, time/batch = 17.8620s	
11926/30300 (epoch 19.680), train_loss = 1.01793124, grad/param norm = 1.3427e-01, time/batch = 19.1414s	
11927/30300 (epoch 19.682), train_loss = 1.23252156, grad/param norm = 1.5068e-01, time/batch = 19.2080s	
11928/30300 (epoch 19.683), train_loss = 1.32071278, grad/param norm = 1.3556e-01, time/batch = 19.0199s	
11929/30300 (epoch 19.685), train_loss = 1.31806175, grad/param norm = 1.7684e-01, time/batch = 19.5372s	
11930/30300 (epoch 19.686), train_loss = 1.20271399, grad/param norm = 1.3501e-01, time/batch = 18.0323s	
11931/30300 (epoch 19.688), train_loss = 1.22863387, grad/param norm = 1.4346e-01, time/batch = 18.7102s	
11932/30300 (epoch 19.690), train_loss = 1.17893887, grad/param norm = 1.6128e-01, time/batch = 19.1165s	
11933/30300 (epoch 19.691), train_loss = 1.27260522, grad/param norm = 1.3749e-01, time/batch = 18.3812s	
11934/30300 (epoch 19.693), train_loss = 1.61470261, grad/param norm = 2.1092e-01, time/batch = 19.1288s	
11935/30300 (epoch 19.695), train_loss = 1.35952173, grad/param norm = 1.6410e-01, time/batch = 20.0253s	
11936/30300 (epoch 19.696), train_loss = 1.33465528, grad/param norm = 1.8729e-01, time/batch = 17.7214s	
11937/30300 (epoch 19.698), train_loss = 1.18333194, grad/param norm = 1.4148e-01, time/batch = 19.4611s	
11938/30300 (epoch 19.700), train_loss = 1.17852007, grad/param norm = 1.5679e-01, time/batch = 18.2278s	
11939/30300 (epoch 19.701), train_loss = 1.05789724, grad/param norm = 1.3473e-01, time/batch = 19.3768s	
11940/30300 (epoch 19.703), train_loss = 1.22759859, grad/param norm = 1.3638e-01, time/batch = 19.1120s	
11941/30300 (epoch 19.705), train_loss = 1.19849394, grad/param norm = 1.4849e-01, time/batch = 17.2107s	
11942/30300 (epoch 19.706), train_loss = 1.30987576, grad/param norm = 1.5555e-01, time/batch = 20.2122s	
11943/30300 (epoch 19.708), train_loss = 1.21691356, grad/param norm = 1.4549e-01, time/batch = 17.7040s	
11944/30300 (epoch 19.710), train_loss = 1.22709059, grad/param norm = 1.6442e-01, time/batch = 20.1127s	
11945/30300 (epoch 19.711), train_loss = 1.12678389, grad/param norm = 1.3593e-01, time/batch = 19.5543s	
11946/30300 (epoch 19.713), train_loss = 1.12967948, grad/param norm = 1.4049e-01, time/batch = 17.7084s	
11947/30300 (epoch 19.715), train_loss = 1.17357143, grad/param norm = 1.5342e-01, time/batch = 19.7859s	
11948/30300 (epoch 19.716), train_loss = 1.33149974, grad/param norm = 1.5221e-01, time/batch = 18.2722s	
11949/30300 (epoch 19.718), train_loss = 1.37196239, grad/param norm = 1.6258e-01, time/batch = 18.4570s	
11950/30300 (epoch 19.719), train_loss = 1.19124476, grad/param norm = 1.7108e-01, time/batch = 17.4525s	
11951/30300 (epoch 19.721), train_loss = 1.25249983, grad/param norm = 1.6948e-01, time/batch = 19.5449s	
11952/30300 (epoch 19.723), train_loss = 1.18538016, grad/param norm = 1.6983e-01, time/batch = 18.9616s	
11953/30300 (epoch 19.724), train_loss = 1.28973920, grad/param norm = 1.8866e-01, time/batch = 19.7057s	
11954/30300 (epoch 19.726), train_loss = 1.63654780, grad/param norm = 1.9189e-01, time/batch = 19.1334s	
11955/30300 (epoch 19.728), train_loss = 1.29487144, grad/param norm = 1.5596e-01, time/batch = 19.2731s	
11956/30300 (epoch 19.729), train_loss = 1.19307780, grad/param norm = 1.5778e-01, time/batch = 19.4504s	
11957/30300 (epoch 19.731), train_loss = 1.29652993, grad/param norm = 1.5916e-01, time/batch = 18.4626s	
11958/30300 (epoch 19.733), train_loss = 1.21948712, grad/param norm = 1.4300e-01, time/batch = 19.7018s	
11959/30300 (epoch 19.734), train_loss = 1.28581429, grad/param norm = 1.4217e-01, time/batch = 18.1204s	
11960/30300 (epoch 19.736), train_loss = 1.20679581, grad/param norm = 1.3577e-01, time/batch = 17.4411s	
11961/30300 (epoch 19.738), train_loss = 1.12743701, grad/param norm = 1.3178e-01, time/batch = 19.5627s	
11962/30300 (epoch 19.739), train_loss = 1.28325262, grad/param norm = 1.4046e-01, time/batch = 17.8797s	
11963/30300 (epoch 19.741), train_loss = 1.36089129, grad/param norm = 1.4062e-01, time/batch = 20.1421s	
11964/30300 (epoch 19.743), train_loss = 1.20344397, grad/param norm = 1.4735e-01, time/batch = 18.1356s	
11965/30300 (epoch 19.744), train_loss = 1.26498571, grad/param norm = 1.4726e-01, time/batch = 18.0270s	
11966/30300 (epoch 19.746), train_loss = 1.13151456, grad/param norm = 1.3997e-01, time/batch = 19.5403s	
11967/30300 (epoch 19.748), train_loss = 1.25635037, grad/param norm = 1.7208e-01, time/batch = 18.4686s	
11968/30300 (epoch 19.749), train_loss = 1.29370517, grad/param norm = 1.5969e-01, time/batch = 19.5442s	
11969/30300 (epoch 19.751), train_loss = 1.21194305, grad/param norm = 1.3900e-01, time/batch = 18.5383s	
11970/30300 (epoch 19.752), train_loss = 1.21103437, grad/param norm = 1.4628e-01, time/batch = 18.8762s	
11971/30300 (epoch 19.754), train_loss = 1.13330819, grad/param norm = 1.3803e-01, time/batch = 18.3574s	
11972/30300 (epoch 19.756), train_loss = 1.20660919, grad/param norm = 1.4737e-01, time/batch = 19.3538s	
11973/30300 (epoch 19.757), train_loss = 1.27305696, grad/param norm = 1.6464e-01, time/batch = 18.7620s	
11974/30300 (epoch 19.759), train_loss = 1.25200074, grad/param norm = 1.3770e-01, time/batch = 19.1202s	
11975/30300 (epoch 19.761), train_loss = 1.07102017, grad/param norm = 1.3187e-01, time/batch = 18.1245s	
11976/30300 (epoch 19.762), train_loss = 1.10488414, grad/param norm = 1.3595e-01, time/batch = 17.6806s	
11977/30300 (epoch 19.764), train_loss = 1.19721106, grad/param norm = 1.5001e-01, time/batch = 19.0281s	
11978/30300 (epoch 19.766), train_loss = 1.28838791, grad/param norm = 1.5062e-01, time/batch = 18.1945s	
11979/30300 (epoch 19.767), train_loss = 1.29534261, grad/param norm = 1.7017e-01, time/batch = 17.2746s	
11980/30300 (epoch 19.769), train_loss = 1.29140905, grad/param norm = 1.5270e-01, time/batch = 19.3540s	
11981/30300 (epoch 19.771), train_loss = 1.19180189, grad/param norm = 1.6604e-01, time/batch = 18.9547s	
11982/30300 (epoch 19.772), train_loss = 1.29069874, grad/param norm = 1.5565e-01, time/batch = 19.3804s	
11983/30300 (epoch 19.774), train_loss = 1.39025767, grad/param norm = 1.4735e-01, time/batch = 19.3007s	
11984/30300 (epoch 19.776), train_loss = 1.26077128, grad/param norm = 1.6127e-01, time/batch = 18.1951s	
11985/30300 (epoch 19.777), train_loss = 1.29978170, grad/param norm = 1.4977e-01, time/batch = 18.5338s	
11986/30300 (epoch 19.779), train_loss = 1.41036622, grad/param norm = 1.8628e-01, time/batch = 19.2934s	
11987/30300 (epoch 19.781), train_loss = 1.23837559, grad/param norm = 1.7077e-01, time/batch = 18.7029s	
11988/30300 (epoch 19.782), train_loss = 1.18046762, grad/param norm = 1.5237e-01, time/batch = 19.5346s	
11989/30300 (epoch 19.784), train_loss = 1.16377746, grad/param norm = 1.4596e-01, time/batch = 18.7849s	
11990/30300 (epoch 19.785), train_loss = 1.41097858, grad/param norm = 1.7063e-01, time/batch = 16.9387s	
11991/30300 (epoch 19.787), train_loss = 1.07454924, grad/param norm = 1.4545e-01, time/batch = 17.6232s	
11992/30300 (epoch 19.789), train_loss = 1.48034742, grad/param norm = 1.5511e-01, time/batch = 20.0975s	
11993/30300 (epoch 19.790), train_loss = 1.32423032, grad/param norm = 1.7677e-01, time/batch = 19.7922s	
11994/30300 (epoch 19.792), train_loss = 1.06969506, grad/param norm = 1.5031e-01, time/batch = 18.0301s	
11995/30300 (epoch 19.794), train_loss = 1.21951056, grad/param norm = 1.5939e-01, time/batch = 19.7034s	
11996/30300 (epoch 19.795), train_loss = 1.15463367, grad/param norm = 1.3127e-01, time/batch = 19.2975s	
11997/30300 (epoch 19.797), train_loss = 1.38611294, grad/param norm = 1.6562e-01, time/batch = 19.0276s	
11998/30300 (epoch 19.799), train_loss = 1.29613907, grad/param norm = 1.5309e-01, time/batch = 20.4417s	
11999/30300 (epoch 19.800), train_loss = 1.33124808, grad/param norm = 1.6532e-01, time/batch = 19.1236s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch19.80_1.7895.t7	
12000/30300 (epoch 19.802), train_loss = 1.48475591, grad/param norm = 1.6297e-01, time/batch = 18.2913s	
12001/30300 (epoch 19.804), train_loss = 1.75039922, grad/param norm = 1.9952e-01, time/batch = 19.8661s	
12002/30300 (epoch 19.805), train_loss = 1.45285771, grad/param norm = 1.7311e-01, time/batch = 18.5366s	
12003/30300 (epoch 19.807), train_loss = 1.22393780, grad/param norm = 1.5551e-01, time/batch = 18.9651s	
12004/30300 (epoch 19.809), train_loss = 1.34267605, grad/param norm = 1.6909e-01, time/batch = 18.0963s	
12005/30300 (epoch 19.810), train_loss = 1.33429526, grad/param norm = 1.5048e-01, time/batch = 19.3804s	
12006/30300 (epoch 19.812), train_loss = 1.16557560, grad/param norm = 1.4806e-01, time/batch = 18.2932s	
12007/30300 (epoch 19.814), train_loss = 1.25601289, grad/param norm = 1.6234e-01, time/batch = 20.5356s	
12008/30300 (epoch 19.815), train_loss = 1.27682692, grad/param norm = 1.6853e-01, time/batch = 17.2914s	
12009/30300 (epoch 19.817), train_loss = 1.35356404, grad/param norm = 1.6355e-01, time/batch = 18.7793s	
12010/30300 (epoch 19.818), train_loss = 1.29996707, grad/param norm = 1.4197e-01, time/batch = 19.6152s	
12011/30300 (epoch 19.820), train_loss = 1.44046243, grad/param norm = 1.7969e-01, time/batch = 18.5385s	
12012/30300 (epoch 19.822), train_loss = 1.42378581, grad/param norm = 1.7223e-01, time/batch = 17.2030s	
12013/30300 (epoch 19.823), train_loss = 1.45123092, grad/param norm = 1.6220e-01, time/batch = 19.0470s	
12014/30300 (epoch 19.825), train_loss = 1.37340221, grad/param norm = 1.8805e-01, time/batch = 18.4343s	
12015/30300 (epoch 19.827), train_loss = 1.10173061, grad/param norm = 1.6444e-01, time/batch = 19.0457s	
12016/30300 (epoch 19.828), train_loss = 1.32038466, grad/param norm = 1.5229e-01, time/batch = 19.2141s	
12017/30300 (epoch 19.830), train_loss = 1.29831881, grad/param norm = 1.5900e-01, time/batch = 18.6378s	
12018/30300 (epoch 19.832), train_loss = 1.17589224, grad/param norm = 1.5518e-01, time/batch = 18.2867s	
12019/30300 (epoch 19.833), train_loss = 1.31187115, grad/param norm = 1.5870e-01, time/batch = 19.6204s	
12020/30300 (epoch 19.835), train_loss = 1.15608680, grad/param norm = 1.4034e-01, time/batch = 19.3456s	
12021/30300 (epoch 19.837), train_loss = 1.11011242, grad/param norm = 1.3643e-01, time/batch = 18.3805s	
12022/30300 (epoch 19.838), train_loss = 1.11942497, grad/param norm = 1.3416e-01, time/batch = 16.8637s	
12023/30300 (epoch 19.840), train_loss = 1.30912290, grad/param norm = 1.3454e-01, time/batch = 17.1307s	
12024/30300 (epoch 19.842), train_loss = 1.15935016, grad/param norm = 1.2545e-01, time/batch = 18.3003s	
12025/30300 (epoch 19.843), train_loss = 1.28168277, grad/param norm = 1.4697e-01, time/batch = 17.7744s	
12026/30300 (epoch 19.845), train_loss = 1.27883764, grad/param norm = 1.4467e-01, time/batch = 19.6373s	
12027/30300 (epoch 19.847), train_loss = 1.27709822, grad/param norm = 1.5537e-01, time/batch = 18.7909s	
12028/30300 (epoch 19.848), train_loss = 1.35103867, grad/param norm = 1.5885e-01, time/batch = 17.4435s	
12029/30300 (epoch 19.850), train_loss = 1.25016891, grad/param norm = 1.5180e-01, time/batch = 19.2163s	
12030/30300 (epoch 19.851), train_loss = 1.30228915, grad/param norm = 1.7904e-01, time/batch = 18.6094s	
12031/30300 (epoch 19.853), train_loss = 1.20003000, grad/param norm = 1.3803e-01, time/batch = 18.8731s	
12032/30300 (epoch 19.855), train_loss = 1.17398400, grad/param norm = 1.2832e-01, time/batch = 17.8006s	
12033/30300 (epoch 19.856), train_loss = 1.24559309, grad/param norm = 1.5997e-01, time/batch = 19.4593s	
12034/30300 (epoch 19.858), train_loss = 1.21215260, grad/param norm = 1.4251e-01, time/batch = 17.9672s	
12035/30300 (epoch 19.860), train_loss = 1.15382218, grad/param norm = 1.4167e-01, time/batch = 18.1116s	
12036/30300 (epoch 19.861), train_loss = 1.41130303, grad/param norm = 1.5057e-01, time/batch = 18.1998s	
12037/30300 (epoch 19.863), train_loss = 1.25762831, grad/param norm = 1.3823e-01, time/batch = 19.1074s	
12038/30300 (epoch 19.865), train_loss = 1.33832313, grad/param norm = 1.6228e-01, time/batch = 18.6133s	
12039/30300 (epoch 19.866), train_loss = 1.32811238, grad/param norm = 1.5164e-01, time/batch = 18.7212s	
12040/30300 (epoch 19.868), train_loss = 1.24620311, grad/param norm = 1.5367e-01, time/batch = 19.3749s	
12041/30300 (epoch 19.870), train_loss = 1.16948187, grad/param norm = 1.4344e-01, time/batch = 17.4596s	
12042/30300 (epoch 19.871), train_loss = 1.20562224, grad/param norm = 1.4257e-01, time/batch = 18.4462s	
12043/30300 (epoch 19.873), train_loss = 1.24443503, grad/param norm = 1.3460e-01, time/batch = 19.7068s	
12044/30300 (epoch 19.875), train_loss = 1.15967837, grad/param norm = 1.3908e-01, time/batch = 18.0184s	
12045/30300 (epoch 19.876), train_loss = 1.13171557, grad/param norm = 1.4966e-01, time/batch = 19.6869s	
12046/30300 (epoch 19.878), train_loss = 1.06393897, grad/param norm = 1.4471e-01, time/batch = 19.5351s	
12047/30300 (epoch 19.880), train_loss = 1.14364999, grad/param norm = 1.6049e-01, time/batch = 18.4435s	
12048/30300 (epoch 19.881), train_loss = 1.43670566, grad/param norm = 2.2234e-01, time/batch = 18.4595s	
12049/30300 (epoch 19.883), train_loss = 1.29900382, grad/param norm = 1.5913e-01, time/batch = 17.9370s	
12050/30300 (epoch 19.884), train_loss = 1.14962475, grad/param norm = 1.2656e-01, time/batch = 19.3102s	
12051/30300 (epoch 19.886), train_loss = 1.27217617, grad/param norm = 1.4425e-01, time/batch = 19.0122s	
12052/30300 (epoch 19.888), train_loss = 1.24708280, grad/param norm = 1.4889e-01, time/batch = 19.5282s	
12053/30300 (epoch 19.889), train_loss = 1.27960805, grad/param norm = 1.4472e-01, time/batch = 17.4526s	
12054/30300 (epoch 19.891), train_loss = 1.27024551, grad/param norm = 1.5861e-01, time/batch = 18.6115s	
12055/30300 (epoch 19.893), train_loss = 1.49829145, grad/param norm = 1.6120e-01, time/batch = 18.7125s	
12056/30300 (epoch 19.894), train_loss = 1.34949556, grad/param norm = 1.5684e-01, time/batch = 19.7883s	
12057/30300 (epoch 19.896), train_loss = 1.07990405, grad/param norm = 1.4046e-01, time/batch = 18.2806s	
12058/30300 (epoch 19.898), train_loss = 1.04253261, grad/param norm = 1.4385e-01, time/batch = 19.8860s	
12059/30300 (epoch 19.899), train_loss = 1.17847185, grad/param norm = 1.5878e-01, time/batch = 19.8803s	
12060/30300 (epoch 19.901), train_loss = 1.21989454, grad/param norm = 1.6205e-01, time/batch = 30.5495s	
12061/30300 (epoch 19.903), train_loss = 1.26737102, grad/param norm = 1.5056e-01, time/batch = 18.4398s	
12062/30300 (epoch 19.904), train_loss = 1.21204078, grad/param norm = 1.4945e-01, time/batch = 17.9680s	
12063/30300 (epoch 19.906), train_loss = 1.35338107, grad/param norm = 1.5394e-01, time/batch = 18.6210s	
12064/30300 (epoch 19.908), train_loss = 1.18517897, grad/param norm = 1.4197e-01, time/batch = 18.2027s	
12065/30300 (epoch 19.909), train_loss = 1.16523356, grad/param norm = 1.5748e-01, time/batch = 19.3593s	
12066/30300 (epoch 19.911), train_loss = 1.23984418, grad/param norm = 1.4496e-01, time/batch = 17.3554s	
12067/30300 (epoch 19.913), train_loss = 1.22494093, grad/param norm = 1.4454e-01, time/batch = 17.3547s	
12068/30300 (epoch 19.914), train_loss = 1.20987085, grad/param norm = 1.6871e-01, time/batch = 19.7075s	
12069/30300 (epoch 19.916), train_loss = 1.25461078, grad/param norm = 1.3919e-01, time/batch = 18.2031s	
12070/30300 (epoch 19.917), train_loss = 1.16939254, grad/param norm = 1.4584e-01, time/batch = 19.2896s	
12071/30300 (epoch 19.919), train_loss = 1.20872122, grad/param norm = 1.6482e-01, time/batch = 19.0209s	
12072/30300 (epoch 19.921), train_loss = 1.24420434, grad/param norm = 1.4653e-01, time/batch = 17.7956s	
12073/30300 (epoch 19.922), train_loss = 1.33098710, grad/param norm = 1.7589e-01, time/batch = 18.7115s	
12074/30300 (epoch 19.924), train_loss = 1.25563714, grad/param norm = 1.6218e-01, time/batch = 19.3798s	
12075/30300 (epoch 19.926), train_loss = 1.25398160, grad/param norm = 1.5207e-01, time/batch = 18.0194s	
12076/30300 (epoch 19.927), train_loss = 1.22990122, grad/param norm = 1.5319e-01, time/batch = 18.2917s	
12077/30300 (epoch 19.929), train_loss = 1.18942651, grad/param norm = 1.5244e-01, time/batch = 19.3210s	
12078/30300 (epoch 19.931), train_loss = 1.37509935, grad/param norm = 1.7285e-01, time/batch = 19.3010s	
12079/30300 (epoch 19.932), train_loss = 1.19594025, grad/param norm = 1.4838e-01, time/batch = 18.8898s	
12080/30300 (epoch 19.934), train_loss = 1.26690776, grad/param norm = 1.5946e-01, time/batch = 16.8662s	
12081/30300 (epoch 19.936), train_loss = 1.19866605, grad/param norm = 1.7438e-01, time/batch = 19.8727s	
12082/30300 (epoch 19.937), train_loss = 1.16027668, grad/param norm = 1.4389e-01, time/batch = 18.1209s	
12083/30300 (epoch 19.939), train_loss = 1.36526949, grad/param norm = 1.6939e-01, time/batch = 17.1958s	
12084/30300 (epoch 19.941), train_loss = 1.20553830, grad/param norm = 1.5386e-01, time/batch = 19.2884s	
12085/30300 (epoch 19.942), train_loss = 1.24499810, grad/param norm = 1.7408e-01, time/batch = 18.4537s	
12086/30300 (epoch 19.944), train_loss = 1.13317561, grad/param norm = 1.4368e-01, time/batch = 17.7969s	
12087/30300 (epoch 19.946), train_loss = 1.36306947, grad/param norm = 1.8226e-01, time/batch = 20.1373s	
12088/30300 (epoch 19.947), train_loss = 1.36476850, grad/param norm = 1.8316e-01, time/batch = 18.2141s	
12089/30300 (epoch 19.949), train_loss = 1.42712716, grad/param norm = 1.9128e-01, time/batch = 19.2802s	
12090/30300 (epoch 19.950), train_loss = 1.36733081, grad/param norm = 1.6361e-01, time/batch = 18.7944s	
12091/30300 (epoch 19.952), train_loss = 1.31481395, grad/param norm = 1.8281e-01, time/batch = 17.7829s	
12092/30300 (epoch 19.954), train_loss = 1.51986149, grad/param norm = 1.5130e-01, time/batch = 19.3755s	
12093/30300 (epoch 19.955), train_loss = 1.19737679, grad/param norm = 1.5928e-01, time/batch = 18.1310s	
12094/30300 (epoch 19.957), train_loss = 1.28813908, grad/param norm = 1.4638e-01, time/batch = 19.4543s	
12095/30300 (epoch 19.959), train_loss = 1.19396714, grad/param norm = 1.4832e-01, time/batch = 18.3801s	
12096/30300 (epoch 19.960), train_loss = 1.20975582, grad/param norm = 1.5242e-01, time/batch = 19.9660s	
12097/30300 (epoch 19.962), train_loss = 1.22418096, grad/param norm = 1.8687e-01, time/batch = 19.3849s	
12098/30300 (epoch 19.964), train_loss = 1.15693443, grad/param norm = 1.5838e-01, time/batch = 18.7696s	
12099/30300 (epoch 19.965), train_loss = 1.14282752, grad/param norm = 1.4538e-01, time/batch = 19.1308s	
12100/30300 (epoch 19.967), train_loss = 1.24099846, grad/param norm = 1.7500e-01, time/batch = 18.9595s	
12101/30300 (epoch 19.969), train_loss = 1.16718167, grad/param norm = 1.6727e-01, time/batch = 18.0291s	
12102/30300 (epoch 19.970), train_loss = 1.20152964, grad/param norm = 1.5002e-01, time/batch = 18.9617s	
12103/30300 (epoch 19.972), train_loss = 1.12280259, grad/param norm = 1.4683e-01, time/batch = 20.3652s	
12104/30300 (epoch 19.974), train_loss = 1.45258794, grad/param norm = 1.7597e-01, time/batch = 18.3778s	
12105/30300 (epoch 19.975), train_loss = 1.45053148, grad/param norm = 1.8872e-01, time/batch = 18.2661s	
12106/30300 (epoch 19.977), train_loss = 1.34719646, grad/param norm = 1.5624e-01, time/batch = 17.6214s	
12107/30300 (epoch 19.979), train_loss = 1.31121450, grad/param norm = 1.5852e-01, time/batch = 18.1079s	
12108/30300 (epoch 19.980), train_loss = 1.31998857, grad/param norm = 1.6253e-01, time/batch = 17.4283s	
12109/30300 (epoch 19.982), train_loss = 1.34034911, grad/param norm = 1.6442e-01, time/batch = 19.8029s	
12110/30300 (epoch 19.983), train_loss = 1.37620026, grad/param norm = 1.5952e-01, time/batch = 18.9520s	
12111/30300 (epoch 19.985), train_loss = 1.29700306, grad/param norm = 1.7446e-01, time/batch = 17.2695s	
12112/30300 (epoch 19.987), train_loss = 1.20825874, grad/param norm = 1.3702e-01, time/batch = 18.7107s	
12113/30300 (epoch 19.988), train_loss = 1.40436582, grad/param norm = 1.5957e-01, time/batch = 20.2032s	
12114/30300 (epoch 19.990), train_loss = 1.08647672, grad/param norm = 1.3931e-01, time/batch = 18.6895s	
12115/30300 (epoch 19.992), train_loss = 1.29637396, grad/param norm = 1.3991e-01, time/batch = 18.5485s	
12116/30300 (epoch 19.993), train_loss = 1.39829720, grad/param norm = 1.9140e-01, time/batch = 19.8028s	
12117/30300 (epoch 19.995), train_loss = 1.22336499, grad/param norm = 1.5709e-01, time/batch = 18.4602s	
12118/30300 (epoch 19.997), train_loss = 1.28129103, grad/param norm = 1.5871e-01, time/batch = 19.6288s	
12119/30300 (epoch 19.998), train_loss = 1.34050392, grad/param norm = 1.6997e-01, time/batch = 19.8596s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
12120/30300 (epoch 20.000), train_loss = 1.20994219, grad/param norm = 1.6265e-01, time/batch = 17.9366s	
12121/30300 (epoch 20.002), train_loss = 1.34771475, grad/param norm = 1.4979e-01, time/batch = 15.6065s	
12122/30300 (epoch 20.003), train_loss = 1.26918296, grad/param norm = 1.5635e-01, time/batch = 14.7928s	
12123/30300 (epoch 20.005), train_loss = 1.23358624, grad/param norm = 1.6697e-01, time/batch = 14.7240s	
12124/30300 (epoch 20.007), train_loss = 1.33095251, grad/param norm = 1.7081e-01, time/batch = 17.5709s	
12125/30300 (epoch 20.008), train_loss = 1.19583671, grad/param norm = 1.8590e-01, time/batch = 19.3685s	
12126/30300 (epoch 20.010), train_loss = 1.13189431, grad/param norm = 1.5904e-01, time/batch = 19.7653s	
12127/30300 (epoch 20.012), train_loss = 1.19542771, grad/param norm = 1.4963e-01, time/batch = 17.9646s	
12128/30300 (epoch 20.013), train_loss = 1.33539310, grad/param norm = 1.5565e-01, time/batch = 18.2705s	
12129/30300 (epoch 20.015), train_loss = 1.19900349, grad/param norm = 1.4410e-01, time/batch = 19.5243s	
12130/30300 (epoch 20.017), train_loss = 1.17436912, grad/param norm = 1.3559e-01, time/batch = 18.2926s	
12131/30300 (epoch 20.018), train_loss = 1.15064378, grad/param norm = 1.3809e-01, time/batch = 19.9627s	
12132/30300 (epoch 20.020), train_loss = 1.36644111, grad/param norm = 1.7350e-01, time/batch = 18.4596s	
12133/30300 (epoch 20.021), train_loss = 1.36146813, grad/param norm = 1.6187e-01, time/batch = 18.1018s	
12134/30300 (epoch 20.023), train_loss = 1.22768291, grad/param norm = 1.4293e-01, time/batch = 19.3756s	
12135/30300 (epoch 20.025), train_loss = 1.17300271, grad/param norm = 1.6709e-01, time/batch = 20.1169s	
12136/30300 (epoch 20.026), train_loss = 1.28298760, grad/param norm = 1.6789e-01, time/batch = 18.1458s	
12137/30300 (epoch 20.028), train_loss = 1.32330466, grad/param norm = 1.5113e-01, time/batch = 19.0410s	
12138/30300 (epoch 20.030), train_loss = 1.18371212, grad/param norm = 1.5085e-01, time/batch = 20.0444s	
12139/30300 (epoch 20.031), train_loss = 1.27864831, grad/param norm = 1.5314e-01, time/batch = 19.2028s	
12140/30300 (epoch 20.033), train_loss = 1.23774548, grad/param norm = 1.7477e-01, time/batch = 18.4316s	
12141/30300 (epoch 20.035), train_loss = 1.32701853, grad/param norm = 1.6078e-01, time/batch = 18.6916s	
12142/30300 (epoch 20.036), train_loss = 1.24045141, grad/param norm = 1.4547e-01, time/batch = 19.9676s	
12143/30300 (epoch 20.038), train_loss = 1.28120522, grad/param norm = 1.5632e-01, time/batch = 18.6144s	
12144/30300 (epoch 20.040), train_loss = 0.99093348, grad/param norm = 1.3456e-01, time/batch = 18.9612s	
12145/30300 (epoch 20.041), train_loss = 1.03061002, grad/param norm = 1.2785e-01, time/batch = 19.5475s	
12146/30300 (epoch 20.043), train_loss = 1.24658681, grad/param norm = 1.5048e-01, time/batch = 18.7042s	
12147/30300 (epoch 20.045), train_loss = 1.22077126, grad/param norm = 1.4879e-01, time/batch = 19.0407s	
12148/30300 (epoch 20.046), train_loss = 1.39622608, grad/param norm = 1.7982e-01, time/batch = 20.2055s	
12149/30300 (epoch 20.048), train_loss = 1.23810730, grad/param norm = 1.8933e-01, time/batch = 17.9518s	
12150/30300 (epoch 20.050), train_loss = 1.22312547, grad/param norm = 1.6847e-01, time/batch = 19.3510s	
12151/30300 (epoch 20.051), train_loss = 1.27896476, grad/param norm = 1.5853e-01, time/batch = 19.4699s	
12152/30300 (epoch 20.053), train_loss = 1.04753754, grad/param norm = 1.6169e-01, time/batch = 17.7928s	
12153/30300 (epoch 20.054), train_loss = 1.22781330, grad/param norm = 1.5287e-01, time/batch = 19.0495s	
12154/30300 (epoch 20.056), train_loss = 1.16491333, grad/param norm = 1.4843e-01, time/batch = 16.8763s	
12155/30300 (epoch 20.058), train_loss = 1.20784658, grad/param norm = 1.4337e-01, time/batch = 18.7071s	
12156/30300 (epoch 20.059), train_loss = 1.13602115, grad/param norm = 1.5464e-01, time/batch = 18.2893s	
12157/30300 (epoch 20.061), train_loss = 1.32970571, grad/param norm = 1.6063e-01, time/batch = 19.7846s	
12158/30300 (epoch 20.063), train_loss = 1.15205334, grad/param norm = 1.6057e-01, time/batch = 18.6309s	
12159/30300 (epoch 20.064), train_loss = 1.25484649, grad/param norm = 1.5261e-01, time/batch = 18.7037s	
12160/30300 (epoch 20.066), train_loss = 1.22901188, grad/param norm = 1.3863e-01, time/batch = 18.3832s	
12161/30300 (epoch 20.068), train_loss = 1.11949953, grad/param norm = 1.4967e-01, time/batch = 19.7945s	
12162/30300 (epoch 20.069), train_loss = 1.28299565, grad/param norm = 1.4713e-01, time/batch = 18.2010s	
12163/30300 (epoch 20.071), train_loss = 1.30580428, grad/param norm = 1.6835e-01, time/batch = 19.2057s	
12164/30300 (epoch 20.073), train_loss = 1.22141931, grad/param norm = 1.6287e-01, time/batch = 19.5364s	
12165/30300 (epoch 20.074), train_loss = 1.28522253, grad/param norm = 1.5135e-01, time/batch = 18.1791s	
12166/30300 (epoch 20.076), train_loss = 1.19847416, grad/param norm = 1.4088e-01, time/batch = 20.1940s	
12167/30300 (epoch 20.078), train_loss = 1.13631801, grad/param norm = 1.3800e-01, time/batch = 19.3437s	
12168/30300 (epoch 20.079), train_loss = 1.16002698, grad/param norm = 1.3370e-01, time/batch = 17.7085s	
12169/30300 (epoch 20.081), train_loss = 1.23985950, grad/param norm = 1.4991e-01, time/batch = 19.0345s	
12170/30300 (epoch 20.083), train_loss = 1.33219106, grad/param norm = 1.7269e-01, time/batch = 19.1341s	
12171/30300 (epoch 20.084), train_loss = 1.13543462, grad/param norm = 1.5121e-01, time/batch = 18.2112s	
12172/30300 (epoch 20.086), train_loss = 1.18371598, grad/param norm = 1.6535e-01, time/batch = 19.4137s	
12173/30300 (epoch 20.087), train_loss = 1.16228679, grad/param norm = 1.5036e-01, time/batch = 19.5317s	
12174/30300 (epoch 20.089), train_loss = 1.19509908, grad/param norm = 1.4935e-01, time/batch = 18.8862s	
12175/30300 (epoch 20.091), train_loss = 1.26635416, grad/param norm = 1.5933e-01, time/batch = 17.1934s	
12176/30300 (epoch 20.092), train_loss = 1.26761640, grad/param norm = 1.5108e-01, time/batch = 19.2090s	
12177/30300 (epoch 20.094), train_loss = 1.40798634, grad/param norm = 1.7998e-01, time/batch = 19.4424s	
12178/30300 (epoch 20.096), train_loss = 1.32635728, grad/param norm = 1.5682e-01, time/batch = 19.4535s	
12179/30300 (epoch 20.097), train_loss = 1.19870498, grad/param norm = 1.5380e-01, time/batch = 19.7809s	
12180/30300 (epoch 20.099), train_loss = 1.34690915, grad/param norm = 1.6479e-01, time/batch = 19.6133s	
12181/30300 (epoch 20.101), train_loss = 1.40122118, grad/param norm = 1.8168e-01, time/batch = 19.5316s	
12182/30300 (epoch 20.102), train_loss = 1.15581593, grad/param norm = 1.6140e-01, time/batch = 20.2064s	
12183/30300 (epoch 20.104), train_loss = 1.21137341, grad/param norm = 1.7827e-01, time/batch = 18.7743s	
12184/30300 (epoch 20.106), train_loss = 1.24367020, grad/param norm = 1.7499e-01, time/batch = 18.3502s	
12185/30300 (epoch 20.107), train_loss = 1.26471474, grad/param norm = 1.6210e-01, time/batch = 19.7858s	
12186/30300 (epoch 20.109), train_loss = 1.33496099, grad/param norm = 1.8567e-01, time/batch = 19.7854s	
12187/30300 (epoch 20.111), train_loss = 1.36166414, grad/param norm = 1.5663e-01, time/batch = 18.1020s	
12188/30300 (epoch 20.112), train_loss = 1.30991080, grad/param norm = 1.4936e-01, time/batch = 18.6273s	
12189/30300 (epoch 20.114), train_loss = 1.24061906, grad/param norm = 1.5187e-01, time/batch = 19.8811s	
12190/30300 (epoch 20.116), train_loss = 1.24119700, grad/param norm = 1.6993e-01, time/batch = 18.4622s	
12191/30300 (epoch 20.117), train_loss = 1.27751941, grad/param norm = 1.3796e-01, time/batch = 19.7025s	
12192/30300 (epoch 20.119), train_loss = 1.17991396, grad/param norm = 1.5317e-01, time/batch = 19.7883s	
12193/30300 (epoch 20.120), train_loss = 1.25632989, grad/param norm = 1.6797e-01, time/batch = 17.6069s	
12194/30300 (epoch 20.122), train_loss = 1.34918371, grad/param norm = 1.8010e-01, time/batch = 19.4590s	
12195/30300 (epoch 20.124), train_loss = 1.40630764, grad/param norm = 1.6901e-01, time/batch = 19.3662s	
12196/30300 (epoch 20.125), train_loss = 1.09726173, grad/param norm = 1.4040e-01, time/batch = 18.5390s	
12197/30300 (epoch 20.127), train_loss = 1.28418724, grad/param norm = 1.7612e-01, time/batch = 19.2925s	
12198/30300 (epoch 20.129), train_loss = 1.39145966, grad/param norm = 1.5128e-01, time/batch = 19.6212s	
12199/30300 (epoch 20.130), train_loss = 1.38567117, grad/param norm = 1.5500e-01, time/batch = 18.7107s	
12200/30300 (epoch 20.132), train_loss = 1.35501253, grad/param norm = 1.6214e-01, time/batch = 19.5199s	
12201/30300 (epoch 20.134), train_loss = 1.14729142, grad/param norm = 1.5413e-01, time/batch = 19.3772s	
12202/30300 (epoch 20.135), train_loss = 1.19245981, grad/param norm = 1.6100e-01, time/batch = 18.0884s	
12203/30300 (epoch 20.137), train_loss = 1.24671669, grad/param norm = 1.5272e-01, time/batch = 17.7882s	
12204/30300 (epoch 20.139), train_loss = 1.19974221, grad/param norm = 1.6240e-01, time/batch = 19.5497s	
12205/30300 (epoch 20.140), train_loss = 1.29032335, grad/param norm = 1.7848e-01, time/batch = 19.3733s	
12206/30300 (epoch 20.142), train_loss = 1.41142959, grad/param norm = 1.9447e-01, time/batch = 17.7879s	
12207/30300 (epoch 20.144), train_loss = 1.26209963, grad/param norm = 1.7421e-01, time/batch = 17.7908s	
12208/30300 (epoch 20.145), train_loss = 1.34255796, grad/param norm = 1.6809e-01, time/batch = 18.1081s	
12209/30300 (epoch 20.147), train_loss = 1.22817398, grad/param norm = 1.5667e-01, time/batch = 16.6232s	
12210/30300 (epoch 20.149), train_loss = 1.44098613, grad/param norm = 1.6799e-01, time/batch = 17.3445s	
12211/30300 (epoch 20.150), train_loss = 1.22642039, grad/param norm = 1.7162e-01, time/batch = 19.7705s	
12212/30300 (epoch 20.152), train_loss = 1.12780736, grad/param norm = 1.6193e-01, time/batch = 18.1873s	
12213/30300 (epoch 20.153), train_loss = 1.24858415, grad/param norm = 1.5811e-01, time/batch = 18.5203s	
12214/30300 (epoch 20.155), train_loss = 1.08526237, grad/param norm = 1.4332e-01, time/batch = 18.5432s	
12215/30300 (epoch 20.157), train_loss = 1.23388068, grad/param norm = 1.6816e-01, time/batch = 18.7986s	
12216/30300 (epoch 20.158), train_loss = 1.25422170, grad/param norm = 1.8965e-01, time/batch = 16.3699s	
12217/30300 (epoch 20.160), train_loss = 1.17789323, grad/param norm = 1.6543e-01, time/batch = 19.7175s	
12218/30300 (epoch 20.162), train_loss = 1.22325775, grad/param norm = 1.4832e-01, time/batch = 19.0529s	
12219/30300 (epoch 20.163), train_loss = 1.19020128, grad/param norm = 1.5993e-01, time/batch = 18.8370s	
12220/30300 (epoch 20.165), train_loss = 1.35144406, grad/param norm = 1.6043e-01, time/batch = 18.6999s	
12221/30300 (epoch 20.167), train_loss = 1.24627737, grad/param norm = 1.6632e-01, time/batch = 19.7975s	
12222/30300 (epoch 20.168), train_loss = 1.28804018, grad/param norm = 1.5142e-01, time/batch = 16.5362s	
12223/30300 (epoch 20.170), train_loss = 1.26734687, grad/param norm = 1.6112e-01, time/batch = 19.6215s	
12224/30300 (epoch 20.172), train_loss = 1.21301993, grad/param norm = 1.6033e-01, time/batch = 17.8613s	
12225/30300 (epoch 20.173), train_loss = 1.24968177, grad/param norm = 1.6946e-01, time/batch = 17.1941s	
12226/30300 (epoch 20.175), train_loss = 1.25406011, grad/param norm = 1.5848e-01, time/batch = 19.1212s	
12227/30300 (epoch 20.177), train_loss = 1.26972146, grad/param norm = 1.7516e-01, time/batch = 19.5424s	
12228/30300 (epoch 20.178), train_loss = 1.01332864, grad/param norm = 1.3792e-01, time/batch = 15.3969s	
12229/30300 (epoch 20.180), train_loss = 1.20277390, grad/param norm = 1.4435e-01, time/batch = 15.4976s	
12230/30300 (epoch 20.182), train_loss = 1.19942699, grad/param norm = 1.5540e-01, time/batch = 15.0220s	
12231/30300 (epoch 20.183), train_loss = 1.17224138, grad/param norm = 1.4852e-01, time/batch = 18.2584s	
12232/30300 (epoch 20.185), train_loss = 1.44981618, grad/param norm = 1.6018e-01, time/batch = 18.7893s	
12233/30300 (epoch 20.186), train_loss = 1.48914089, grad/param norm = 1.7634e-01, time/batch = 18.3735s	
12234/30300 (epoch 20.188), train_loss = 1.29634535, grad/param norm = 1.6510e-01, time/batch = 19.2207s	
12235/30300 (epoch 20.190), train_loss = 1.21353641, grad/param norm = 1.4549e-01, time/batch = 18.6934s	
12236/30300 (epoch 20.191), train_loss = 1.30658709, grad/param norm = 1.4932e-01, time/batch = 18.1992s	
12237/30300 (epoch 20.193), train_loss = 1.14278684, grad/param norm = 1.3955e-01, time/batch = 19.4511s	
12238/30300 (epoch 20.195), train_loss = 1.26887227, grad/param norm = 1.6664e-01, time/batch = 19.4520s	
12239/30300 (epoch 20.196), train_loss = 1.27856965, grad/param norm = 1.3739e-01, time/batch = 18.4635s	
12240/30300 (epoch 20.198), train_loss = 1.05387185, grad/param norm = 1.5143e-01, time/batch = 18.3652s	
12241/30300 (epoch 20.200), train_loss = 1.23079409, grad/param norm = 1.3697e-01, time/batch = 17.8668s	
12242/30300 (epoch 20.201), train_loss = 1.33830860, grad/param norm = 1.6739e-01, time/batch = 18.1789s	
12243/30300 (epoch 20.203), train_loss = 1.26611069, grad/param norm = 1.5748e-01, time/batch = 19.1279s	
12244/30300 (epoch 20.205), train_loss = 1.45779345, grad/param norm = 1.7112e-01, time/batch = 20.0366s	
12245/30300 (epoch 20.206), train_loss = 1.38266820, grad/param norm = 1.8416e-01, time/batch = 17.9569s	
12246/30300 (epoch 20.208), train_loss = 1.36064577, grad/param norm = 1.9488e-01, time/batch = 19.7968s	
12247/30300 (epoch 20.210), train_loss = 1.29544442, grad/param norm = 1.5549e-01, time/batch = 19.7991s	
12248/30300 (epoch 20.211), train_loss = 1.37124614, grad/param norm = 1.6734e-01, time/batch = 18.2944s	
12249/30300 (epoch 20.213), train_loss = 1.19200168, grad/param norm = 1.4201e-01, time/batch = 19.5425s	
12250/30300 (epoch 20.215), train_loss = 1.13877131, grad/param norm = 1.4458e-01, time/batch = 20.2897s	
12251/30300 (epoch 20.216), train_loss = 1.20404396, grad/param norm = 1.5136e-01, time/batch = 30.3830s	
12252/30300 (epoch 20.218), train_loss = 1.10934470, grad/param norm = 1.2870e-01, time/batch = 21.4232s	
12253/30300 (epoch 20.219), train_loss = 1.06670825, grad/param norm = 1.2472e-01, time/batch = 18.5397s	
12254/30300 (epoch 20.221), train_loss = 1.08530001, grad/param norm = 1.4636e-01, time/batch = 19.2105s	
12255/30300 (epoch 20.223), train_loss = 1.27939871, grad/param norm = 1.5381e-01, time/batch = 18.3671s	
12256/30300 (epoch 20.224), train_loss = 1.07976178, grad/param norm = 1.4650e-01, time/batch = 18.6864s	
12257/30300 (epoch 20.226), train_loss = 1.32271803, grad/param norm = 1.7049e-01, time/batch = 18.1896s	
12258/30300 (epoch 20.228), train_loss = 1.34001221, grad/param norm = 1.6019e-01, time/batch = 16.8450s	
12259/30300 (epoch 20.229), train_loss = 1.17512926, grad/param norm = 1.4524e-01, time/batch = 20.2164s	
12260/30300 (epoch 20.231), train_loss = 1.28984124, grad/param norm = 1.6403e-01, time/batch = 17.9557s	
12261/30300 (epoch 20.233), train_loss = 1.22200713, grad/param norm = 1.4435e-01, time/batch = 20.0359s	
12262/30300 (epoch 20.234), train_loss = 1.30576185, grad/param norm = 1.7433e-01, time/batch = 20.3714s	
12263/30300 (epoch 20.236), train_loss = 1.24624127, grad/param norm = 1.3797e-01, time/batch = 17.7008s	
12264/30300 (epoch 20.238), train_loss = 1.30207566, grad/param norm = 1.6752e-01, time/batch = 17.9387s	
12265/30300 (epoch 20.239), train_loss = 1.28926781, grad/param norm = 1.6156e-01, time/batch = 17.6966s	
12266/30300 (epoch 20.241), train_loss = 1.27608924, grad/param norm = 1.6249e-01, time/batch = 17.9563s	
12267/30300 (epoch 20.243), train_loss = 1.30877374, grad/param norm = 1.5738e-01, time/batch = 18.9513s	
12268/30300 (epoch 20.244), train_loss = 1.49056101, grad/param norm = 1.7050e-01, time/batch = 18.8888s	
12269/30300 (epoch 20.246), train_loss = 1.24694185, grad/param norm = 1.4656e-01, time/batch = 18.9687s	
12270/30300 (epoch 20.248), train_loss = 1.23609080, grad/param norm = 1.6189e-01, time/batch = 18.7012s	
12271/30300 (epoch 20.249), train_loss = 1.17482280, grad/param norm = 1.5472e-01, time/batch = 17.6320s	
12272/30300 (epoch 20.251), train_loss = 1.15517863, grad/param norm = 1.5051e-01, time/batch = 18.4738s	
12273/30300 (epoch 20.252), train_loss = 1.34701513, grad/param norm = 1.5852e-01, time/batch = 18.6230s	
12274/30300 (epoch 20.254), train_loss = 1.35410914, grad/param norm = 1.8339e-01, time/batch = 18.7213s	
12275/30300 (epoch 20.256), train_loss = 1.28668770, grad/param norm = 1.5440e-01, time/batch = 19.3016s	
12276/30300 (epoch 20.257), train_loss = 1.30581250, grad/param norm = 1.5810e-01, time/batch = 18.3724s	
12277/30300 (epoch 20.259), train_loss = 1.22927933, grad/param norm = 1.5173e-01, time/batch = 18.5281s	
12278/30300 (epoch 20.261), train_loss = 1.34917725, grad/param norm = 1.4831e-01, time/batch = 19.8729s	
12279/30300 (epoch 20.262), train_loss = 1.23534813, grad/param norm = 1.5094e-01, time/batch = 18.7077s	
12280/30300 (epoch 20.264), train_loss = 1.25644111, grad/param norm = 1.4656e-01, time/batch = 19.3835s	
12281/30300 (epoch 20.266), train_loss = 1.17977638, grad/param norm = 1.4430e-01, time/batch = 20.4459s	
12282/30300 (epoch 20.267), train_loss = 1.42692579, grad/param norm = 1.6877e-01, time/batch = 18.3353s	
12283/30300 (epoch 20.269), train_loss = 1.29194515, grad/param norm = 1.6836e-01, time/batch = 19.0201s	
12284/30300 (epoch 20.271), train_loss = 1.26675091, grad/param norm = 1.5580e-01, time/batch = 18.1050s	
12285/30300 (epoch 20.272), train_loss = 1.26052034, grad/param norm = 1.5557e-01, time/batch = 18.3055s	
12286/30300 (epoch 20.274), train_loss = 1.36452711, grad/param norm = 1.5558e-01, time/batch = 19.2749s	
12287/30300 (epoch 20.276), train_loss = 1.29308592, grad/param norm = 1.6002e-01, time/batch = 18.8565s	
12288/30300 (epoch 20.277), train_loss = 1.12693986, grad/param norm = 1.5928e-01, time/batch = 18.7103s	
12289/30300 (epoch 20.279), train_loss = 1.30315592, grad/param norm = 2.1426e-01, time/batch = 19.2648s	
12290/30300 (epoch 20.281), train_loss = 1.34814154, grad/param norm = 1.7312e-01, time/batch = 19.1398s	
12291/30300 (epoch 20.282), train_loss = 1.25852848, grad/param norm = 1.4692e-01, time/batch = 19.6146s	
12292/30300 (epoch 20.284), train_loss = 1.42741988, grad/param norm = 2.1477e-01, time/batch = 18.1174s	
12293/30300 (epoch 20.285), train_loss = 1.28555888, grad/param norm = 1.3512e-01, time/batch = 19.3788s	
12294/30300 (epoch 20.287), train_loss = 1.26000675, grad/param norm = 1.6284e-01, time/batch = 18.5144s	
12295/30300 (epoch 20.289), train_loss = 1.31703209, grad/param norm = 1.4893e-01, time/batch = 17.5366s	
12296/30300 (epoch 20.290), train_loss = 1.00920241, grad/param norm = 1.3464e-01, time/batch = 18.7924s	
12297/30300 (epoch 20.292), train_loss = 1.14148989, grad/param norm = 1.3328e-01, time/batch = 19.4734s	
12298/30300 (epoch 20.294), train_loss = 1.37837220, grad/param norm = 1.9314e-01, time/batch = 17.5482s	
12299/30300 (epoch 20.295), train_loss = 1.20925167, grad/param norm = 1.4907e-01, time/batch = 18.8815s	
12300/30300 (epoch 20.297), train_loss = 1.17713172, grad/param norm = 1.3428e-01, time/batch = 19.6990s	
12301/30300 (epoch 20.299), train_loss = 1.22847982, grad/param norm = 1.4685e-01, time/batch = 18.4539s	
12302/30300 (epoch 20.300), train_loss = 1.19407196, grad/param norm = 1.4487e-01, time/batch = 18.8014s	
12303/30300 (epoch 20.302), train_loss = 1.25398435, grad/param norm = 1.5148e-01, time/batch = 18.5175s	
12304/30300 (epoch 20.304), train_loss = 1.16115180, grad/param norm = 1.4497e-01, time/batch = 18.4364s	
12305/30300 (epoch 20.305), train_loss = 1.20943056, grad/param norm = 1.4165e-01, time/batch = 18.7891s	
12306/30300 (epoch 20.307), train_loss = 1.29190708, grad/param norm = 1.4087e-01, time/batch = 18.1261s	
12307/30300 (epoch 20.309), train_loss = 1.31747018, grad/param norm = 1.5764e-01, time/batch = 15.7008s	
12308/30300 (epoch 20.310), train_loss = 1.23890263, grad/param norm = 1.5033e-01, time/batch = 16.6082s	
12309/30300 (epoch 20.312), train_loss = 1.38728401, grad/param norm = 1.5548e-01, time/batch = 15.5958s	
12310/30300 (epoch 20.314), train_loss = 1.27566767, grad/param norm = 1.4774e-01, time/batch = 15.9998s	
12311/30300 (epoch 20.315), train_loss = 1.26274203, grad/param norm = 1.6233e-01, time/batch = 17.1168s	
12312/30300 (epoch 20.317), train_loss = 1.31494992, grad/param norm = 1.4843e-01, time/batch = 19.8642s	
12313/30300 (epoch 20.318), train_loss = 1.37896683, grad/param norm = 1.7573e-01, time/batch = 19.2140s	
12314/30300 (epoch 20.320), train_loss = 1.33227654, grad/param norm = 1.5074e-01, time/batch = 19.0324s	
12315/30300 (epoch 20.322), train_loss = 1.17222129, grad/param norm = 1.4620e-01, time/batch = 18.3796s	
12316/30300 (epoch 20.323), train_loss = 1.33998273, grad/param norm = 1.5829e-01, time/batch = 19.0315s	
12317/30300 (epoch 20.325), train_loss = 1.22310310, grad/param norm = 1.4872e-01, time/batch = 19.2898s	
12318/30300 (epoch 20.327), train_loss = 1.24347601, grad/param norm = 1.3881e-01, time/batch = 18.6183s	
12319/30300 (epoch 20.328), train_loss = 1.24375018, grad/param norm = 1.3798e-01, time/batch = 18.4430s	
12320/30300 (epoch 20.330), train_loss = 1.30743126, grad/param norm = 1.4923e-01, time/batch = 18.4607s	
12321/30300 (epoch 20.332), train_loss = 1.32319895, grad/param norm = 1.5903e-01, time/batch = 18.0403s	
12322/30300 (epoch 20.333), train_loss = 1.23873661, grad/param norm = 1.5740e-01, time/batch = 19.6106s	
12323/30300 (epoch 20.335), train_loss = 1.12275979, grad/param norm = 1.4548e-01, time/batch = 19.6178s	
12324/30300 (epoch 20.337), train_loss = 1.38791191, grad/param norm = 1.4763e-01, time/batch = 18.0488s	
12325/30300 (epoch 20.338), train_loss = 1.16088013, grad/param norm = 1.3109e-01, time/batch = 19.7910s	
12326/30300 (epoch 20.340), train_loss = 1.14782842, grad/param norm = 1.4791e-01, time/batch = 19.7887s	
12327/30300 (epoch 20.342), train_loss = 1.33443181, grad/param norm = 1.5273e-01, time/batch = 18.5461s	
12328/30300 (epoch 20.343), train_loss = 1.28364823, grad/param norm = 1.7257e-01, time/batch = 18.7842s	
12329/30300 (epoch 20.345), train_loss = 1.28884313, grad/param norm = 1.4832e-01, time/batch = 17.4409s	
12330/30300 (epoch 20.347), train_loss = 1.11170324, grad/param norm = 1.6093e-01, time/batch = 19.4483s	
12331/30300 (epoch 20.348), train_loss = 1.15497262, grad/param norm = 1.6479e-01, time/batch = 17.5398s	
12332/30300 (epoch 20.350), train_loss = 1.24267606, grad/param norm = 1.4807e-01, time/batch = 18.5337s	
12333/30300 (epoch 20.351), train_loss = 1.23611377, grad/param norm = 1.5367e-01, time/batch = 19.7949s	
12334/30300 (epoch 20.353), train_loss = 1.08178952, grad/param norm = 1.4753e-01, time/batch = 18.5325s	
12335/30300 (epoch 20.355), train_loss = 1.18342956, grad/param norm = 1.4231e-01, time/batch = 19.2872s	
12336/30300 (epoch 20.356), train_loss = 1.31887418, grad/param norm = 1.8839e-01, time/batch = 19.7011s	
12337/30300 (epoch 20.358), train_loss = 1.48327984, grad/param norm = 1.4699e-01, time/batch = 18.5137s	
12338/30300 (epoch 20.360), train_loss = 1.20794896, grad/param norm = 1.6517e-01, time/batch = 19.4662s	
12339/30300 (epoch 20.361), train_loss = 1.28548359, grad/param norm = 1.5574e-01, time/batch = 19.8778s	
12340/30300 (epoch 20.363), train_loss = 1.33070156, grad/param norm = 1.6097e-01, time/batch = 17.7853s	
12341/30300 (epoch 20.365), train_loss = 1.15655914, grad/param norm = 1.6130e-01, time/batch = 19.2952s	
12342/30300 (epoch 20.366), train_loss = 1.20251624, grad/param norm = 1.5048e-01, time/batch = 17.5295s	
12343/30300 (epoch 20.368), train_loss = 1.08161077, grad/param norm = 1.3844e-01, time/batch = 18.8765s	
12344/30300 (epoch 20.370), train_loss = 1.12703681, grad/param norm = 1.3925e-01, time/batch = 19.6078s	
12345/30300 (epoch 20.371), train_loss = 1.32618533, grad/param norm = 1.5537e-01, time/batch = 18.7081s	
12346/30300 (epoch 20.373), train_loss = 1.15218189, grad/param norm = 1.2821e-01, time/batch = 18.5361s	
12347/30300 (epoch 20.375), train_loss = 1.13751472, grad/param norm = 1.2717e-01, time/batch = 18.6200s	
12348/30300 (epoch 20.376), train_loss = 1.16175706, grad/param norm = 1.3444e-01, time/batch = 17.1201s	
12349/30300 (epoch 20.378), train_loss = 1.17191934, grad/param norm = 1.5666e-01, time/batch = 18.5465s	
12350/30300 (epoch 20.380), train_loss = 1.41466171, grad/param norm = 1.6051e-01, time/batch = 18.7094s	
12351/30300 (epoch 20.381), train_loss = 1.11790326, grad/param norm = 1.5094e-01, time/batch = 17.7156s	
12352/30300 (epoch 20.383), train_loss = 1.18906128, grad/param norm = 1.7535e-01, time/batch = 19.2813s	
12353/30300 (epoch 20.384), train_loss = 1.31587804, grad/param norm = 1.5494e-01, time/batch = 17.3336s	
12354/30300 (epoch 20.386), train_loss = 1.13681753, grad/param norm = 1.5199e-01, time/batch = 18.1966s	
12355/30300 (epoch 20.388), train_loss = 1.08525198, grad/param norm = 1.3386e-01, time/batch = 20.0339s	
12356/30300 (epoch 20.389), train_loss = 1.21379490, grad/param norm = 1.5744e-01, time/batch = 17.3860s	
12357/30300 (epoch 20.391), train_loss = 1.27429257, grad/param norm = 1.4924e-01, time/batch = 19.3557s	
12358/30300 (epoch 20.393), train_loss = 1.09557419, grad/param norm = 1.4014e-01, time/batch = 19.6356s	
12359/30300 (epoch 20.394), train_loss = 1.29349308, grad/param norm = 1.4951e-01, time/batch = 18.1270s	
12360/30300 (epoch 20.396), train_loss = 1.36536006, grad/param norm = 1.4896e-01, time/batch = 19.5294s	
12361/30300 (epoch 20.398), train_loss = 1.21212175, grad/param norm = 1.3969e-01, time/batch = 19.1302s	
12362/30300 (epoch 20.399), train_loss = 1.20738519, grad/param norm = 1.5355e-01, time/batch = 18.5362s	
12363/30300 (epoch 20.401), train_loss = 1.26606137, grad/param norm = 1.4464e-01, time/batch = 18.0438s	
12364/30300 (epoch 20.403), train_loss = 1.21415546, grad/param norm = 1.6189e-01, time/batch = 17.5322s	
12365/30300 (epoch 20.404), train_loss = 1.14301844, grad/param norm = 1.6305e-01, time/batch = 19.5288s	
12366/30300 (epoch 20.406), train_loss = 1.24977770, grad/param norm = 1.3851e-01, time/batch = 16.8554s	
12367/30300 (epoch 20.408), train_loss = 1.10068967, grad/param norm = 1.4240e-01, time/batch = 19.8706s	
12368/30300 (epoch 20.409), train_loss = 1.11114822, grad/param norm = 1.4594e-01, time/batch = 17.9635s	
12369/30300 (epoch 20.411), train_loss = 1.11344556, grad/param norm = 1.3096e-01, time/batch = 17.1323s	
12370/30300 (epoch 20.413), train_loss = 1.04738577, grad/param norm = 1.4491e-01, time/batch = 18.9626s	
12371/30300 (epoch 20.414), train_loss = 1.35077357, grad/param norm = 1.6209e-01, time/batch = 19.6971s	
12372/30300 (epoch 20.416), train_loss = 1.18384434, grad/param norm = 1.4902e-01, time/batch = 18.5385s	
12373/30300 (epoch 20.417), train_loss = 1.15393136, grad/param norm = 1.4213e-01, time/batch = 19.6309s	
12374/30300 (epoch 20.419), train_loss = 1.11190264, grad/param norm = 1.3680e-01, time/batch = 18.8043s	
12375/30300 (epoch 20.421), train_loss = 1.18432591, grad/param norm = 1.5755e-01, time/batch = 18.6096s	
12376/30300 (epoch 20.422), train_loss = 1.21590652, grad/param norm = 1.5273e-01, time/batch = 18.9580s	
12377/30300 (epoch 20.424), train_loss = 1.23015056, grad/param norm = 1.4847e-01, time/batch = 18.6239s	
12378/30300 (epoch 20.426), train_loss = 1.17791266, grad/param norm = 1.6816e-01, time/batch = 18.1277s	
12379/30300 (epoch 20.427), train_loss = 1.20726602, grad/param norm = 1.6626e-01, time/batch = 18.6139s	
12380/30300 (epoch 20.429), train_loss = 1.21683909, grad/param norm = 1.4011e-01, time/batch = 19.0410s	
12381/30300 (epoch 20.431), train_loss = 1.28150442, grad/param norm = 1.4168e-01, time/batch = 18.2764s	
12382/30300 (epoch 20.432), train_loss = 1.19503364, grad/param norm = 1.3864e-01, time/batch = 18.8767s	
12383/30300 (epoch 20.434), train_loss = 1.10221639, grad/param norm = 1.3915e-01, time/batch = 19.3738s	
12384/30300 (epoch 20.436), train_loss = 1.36525469, grad/param norm = 1.5538e-01, time/batch = 19.2054s	
12385/30300 (epoch 20.437), train_loss = 1.10873176, grad/param norm = 1.3812e-01, time/batch = 17.2535s	
12386/30300 (epoch 20.439), train_loss = 1.16615194, grad/param norm = 1.5038e-01, time/batch = 19.2064s	
12387/30300 (epoch 20.441), train_loss = 1.20250640, grad/param norm = 1.4490e-01, time/batch = 19.5465s	
12388/30300 (epoch 20.442), train_loss = 1.11477400, grad/param norm = 1.4812e-01, time/batch = 17.7000s	
12389/30300 (epoch 20.444), train_loss = 1.01373688, grad/param norm = 1.4480e-01, time/batch = 19.0231s	
12390/30300 (epoch 20.446), train_loss = 1.19694253, grad/param norm = 1.4198e-01, time/batch = 17.3588s	
12391/30300 (epoch 20.447), train_loss = 1.20550935, grad/param norm = 1.6157e-01, time/batch = 18.9704s	
12392/30300 (epoch 20.449), train_loss = 1.13317926, grad/param norm = 1.4512e-01, time/batch = 17.7841s	
12393/30300 (epoch 20.450), train_loss = 1.29610000, grad/param norm = 1.4232e-01, time/batch = 19.2097s	
12394/30300 (epoch 20.452), train_loss = 1.30928002, grad/param norm = 1.4363e-01, time/batch = 18.6956s	
12395/30300 (epoch 20.454), train_loss = 1.27677687, grad/param norm = 1.3583e-01, time/batch = 15.0348s	
12396/30300 (epoch 20.455), train_loss = 1.27576622, grad/param norm = 1.7931e-01, time/batch = 15.1711s	
12397/30300 (epoch 20.457), train_loss = 1.21850778, grad/param norm = 1.4317e-01, time/batch = 15.6038s	
12398/30300 (epoch 20.459), train_loss = 1.30548004, grad/param norm = 1.6623e-01, time/batch = 18.5477s	
12399/30300 (epoch 20.460), train_loss = 1.25243330, grad/param norm = 1.5239e-01, time/batch = 17.7993s	
12400/30300 (epoch 20.462), train_loss = 1.28800678, grad/param norm = 1.4562e-01, time/batch = 17.5366s	
12401/30300 (epoch 20.464), train_loss = 1.07162914, grad/param norm = 1.6967e-01, time/batch = 18.8837s	
12402/30300 (epoch 20.465), train_loss = 1.05142028, grad/param norm = 1.4243e-01, time/batch = 16.6225s	
12403/30300 (epoch 20.467), train_loss = 1.02023114, grad/param norm = 1.2888e-01, time/batch = 18.4697s	
12404/30300 (epoch 20.469), train_loss = 1.12196226, grad/param norm = 1.2623e-01, time/batch = 19.6311s	
12405/30300 (epoch 20.470), train_loss = 1.17656495, grad/param norm = 1.4191e-01, time/batch = 19.1962s	
12406/30300 (epoch 20.472), train_loss = 1.17868115, grad/param norm = 1.3275e-01, time/batch = 19.4684s	
12407/30300 (epoch 20.474), train_loss = 1.20847102, grad/param norm = 1.6355e-01, time/batch = 19.9550s	
12408/30300 (epoch 20.475), train_loss = 1.12542835, grad/param norm = 1.3629e-01, time/batch = 18.3619s	
12409/30300 (epoch 20.477), train_loss = 1.21511756, grad/param norm = 1.5426e-01, time/batch = 19.5489s	
12410/30300 (epoch 20.479), train_loss = 1.20680648, grad/param norm = 1.4365e-01, time/batch = 18.7898s	
12411/30300 (epoch 20.480), train_loss = 1.23281635, grad/param norm = 1.5010e-01, time/batch = 18.4418s	
12412/30300 (epoch 20.482), train_loss = 1.26565871, grad/param norm = 1.3697e-01, time/batch = 19.5410s	
12413/30300 (epoch 20.483), train_loss = 1.15940716, grad/param norm = 1.4844e-01, time/batch = 17.7935s	
12414/30300 (epoch 20.485), train_loss = 1.22175548, grad/param norm = 1.4471e-01, time/batch = 16.7744s	
12415/30300 (epoch 20.487), train_loss = 1.31192935, grad/param norm = 1.5022e-01, time/batch = 19.7062s	
12416/30300 (epoch 20.488), train_loss = 1.30003466, grad/param norm = 1.3885e-01, time/batch = 18.5540s	
12417/30300 (epoch 20.490), train_loss = 1.11053461, grad/param norm = 1.4528e-01, time/batch = 17.3700s	
12418/30300 (epoch 20.492), train_loss = 1.18942497, grad/param norm = 1.5169e-01, time/batch = 19.5187s	
12419/30300 (epoch 20.493), train_loss = 1.19118558, grad/param norm = 1.3841e-01, time/batch = 19.2787s	
12420/30300 (epoch 20.495), train_loss = 1.15880074, grad/param norm = 1.2986e-01, time/batch = 18.9501s	
12421/30300 (epoch 20.497), train_loss = 1.25153728, grad/param norm = 1.4528e-01, time/batch = 19.4472s	
12422/30300 (epoch 20.498), train_loss = 1.25469538, grad/param norm = 1.4844e-01, time/batch = 18.8865s	
12423/30300 (epoch 20.500), train_loss = 1.24139106, grad/param norm = 1.6186e-01, time/batch = 19.7910s	
12424/30300 (epoch 20.502), train_loss = 1.21743234, grad/param norm = 1.5261e-01, time/batch = 19.0241s	
12425/30300 (epoch 20.503), train_loss = 1.30002430, grad/param norm = 1.4274e-01, time/batch = 17.0226s	
12426/30300 (epoch 20.505), train_loss = 1.16635181, grad/param norm = 1.5745e-01, time/batch = 19.6002s	
12427/30300 (epoch 20.507), train_loss = 1.14091101, grad/param norm = 1.4894e-01, time/batch = 17.4540s	
12428/30300 (epoch 20.508), train_loss = 1.19277267, grad/param norm = 1.7739e-01, time/batch = 18.7010s	
12429/30300 (epoch 20.510), train_loss = 1.31128241, grad/param norm = 1.5923e-01, time/batch = 20.2841s	
12430/30300 (epoch 20.512), train_loss = 1.14539486, grad/param norm = 1.3475e-01, time/batch = 17.2758s	
12431/30300 (epoch 20.513), train_loss = 1.23851453, grad/param norm = 1.4128e-01, time/batch = 18.7831s	
12432/30300 (epoch 20.515), train_loss = 1.20740106, grad/param norm = 1.4075e-01, time/batch = 20.2960s	
12433/30300 (epoch 20.517), train_loss = 1.04013164, grad/param norm = 1.2925e-01, time/batch = 17.7089s	
12434/30300 (epoch 20.518), train_loss = 1.28892155, grad/param norm = 1.5013e-01, time/batch = 19.7095s	
12435/30300 (epoch 20.520), train_loss = 1.29190082, grad/param norm = 1.5976e-01, time/batch = 20.1121s	
12436/30300 (epoch 20.521), train_loss = 1.12437859, grad/param norm = 1.7063e-01, time/batch = 18.7822s	
12437/30300 (epoch 20.523), train_loss = 1.38153288, grad/param norm = 1.7288e-01, time/batch = 16.1878s	
12438/30300 (epoch 20.525), train_loss = 1.13058069, grad/param norm = 1.4465e-01, time/batch = 19.4523s	
12439/30300 (epoch 20.526), train_loss = 1.19120478, grad/param norm = 1.4722e-01, time/batch = 19.8879s	
12440/30300 (epoch 20.528), train_loss = 1.10817377, grad/param norm = 1.4593e-01, time/batch = 18.3794s	
12441/30300 (epoch 20.530), train_loss = 1.09086216, grad/param norm = 1.4462e-01, time/batch = 19.3934s	
12442/30300 (epoch 20.531), train_loss = 1.26361324, grad/param norm = 1.5955e-01, time/batch = 19.4706s	
12443/30300 (epoch 20.533), train_loss = 1.22205839, grad/param norm = 1.4244e-01, time/batch = 33.0318s	
12444/30300 (epoch 20.535), train_loss = 1.11733395, grad/param norm = 1.3489e-01, time/batch = 19.1172s	
12445/30300 (epoch 20.536), train_loss = 1.23700973, grad/param norm = 1.5703e-01, time/batch = 17.0282s	
12446/30300 (epoch 20.538), train_loss = 1.09623629, grad/param norm = 1.6085e-01, time/batch = 17.6152s	
12447/30300 (epoch 20.540), train_loss = 1.11691049, grad/param norm = 1.5985e-01, time/batch = 19.0096s	
12448/30300 (epoch 20.541), train_loss = 1.21530330, grad/param norm = 1.8408e-01, time/batch = 17.6346s	
12449/30300 (epoch 20.543), train_loss = 1.20058494, grad/param norm = 1.4553e-01, time/batch = 19.6174s	
12450/30300 (epoch 20.545), train_loss = 1.20372574, grad/param norm = 1.5757e-01, time/batch = 18.9556s	
12451/30300 (epoch 20.546), train_loss = 1.44088208, grad/param norm = 1.4692e-01, time/batch = 19.4635s	
12452/30300 (epoch 20.548), train_loss = 1.14213166, grad/param norm = 1.3509e-01, time/batch = 17.9586s	
12453/30300 (epoch 20.550), train_loss = 1.29187398, grad/param norm = 1.7605e-01, time/batch = 19.1068s	
12454/30300 (epoch 20.551), train_loss = 1.15254263, grad/param norm = 1.4943e-01, time/batch = 19.2168s	
12455/30300 (epoch 20.553), train_loss = 1.17618913, grad/param norm = 1.4514e-01, time/batch = 18.4441s	
12456/30300 (epoch 20.554), train_loss = 1.21892934, grad/param norm = 1.5245e-01, time/batch = 18.7871s	
12457/30300 (epoch 20.556), train_loss = 1.26790053, grad/param norm = 1.4833e-01, time/batch = 19.8832s	
12458/30300 (epoch 20.558), train_loss = 1.33831479, grad/param norm = 1.6493e-01, time/batch = 17.6281s	
12459/30300 (epoch 20.559), train_loss = 1.28515928, grad/param norm = 1.6253e-01, time/batch = 19.3680s	
12460/30300 (epoch 20.561), train_loss = 1.05836256, grad/param norm = 1.6234e-01, time/batch = 19.3067s	
12461/30300 (epoch 20.563), train_loss = 1.11783265, grad/param norm = 1.4776e-01, time/batch = 17.8763s	
12462/30300 (epoch 20.564), train_loss = 1.13503488, grad/param norm = 1.4010e-01, time/batch = 18.5528s	
12463/30300 (epoch 20.566), train_loss = 1.22690687, grad/param norm = 1.4822e-01, time/batch = 17.0533s	
12464/30300 (epoch 20.568), train_loss = 1.02756988, grad/param norm = 1.5248e-01, time/batch = 18.5157s	
12465/30300 (epoch 20.569), train_loss = 1.23281901, grad/param norm = 1.4496e-01, time/batch = 18.7037s	
12466/30300 (epoch 20.571), train_loss = 1.25625638, grad/param norm = 1.6195e-01, time/batch = 19.0381s	
12467/30300 (epoch 20.573), train_loss = 1.26228470, grad/param norm = 1.5437e-01, time/batch = 19.3632s	
12468/30300 (epoch 20.574), train_loss = 1.29748340, grad/param norm = 1.4250e-01, time/batch = 18.7964s	
12469/30300 (epoch 20.576), train_loss = 1.21220753, grad/param norm = 1.3395e-01, time/batch = 17.8679s	
12470/30300 (epoch 20.578), train_loss = 1.07183479, grad/param norm = 1.3898e-01, time/batch = 20.0510s	
12471/30300 (epoch 20.579), train_loss = 1.23289373, grad/param norm = 1.6538e-01, time/batch = 19.2041s	
12472/30300 (epoch 20.581), train_loss = 1.29941307, grad/param norm = 1.4174e-01, time/batch = 18.6382s	
12473/30300 (epoch 20.583), train_loss = 1.38773240, grad/param norm = 1.7279e-01, time/batch = 20.0552s	
12474/30300 (epoch 20.584), train_loss = 1.30834116, grad/param norm = 1.5475e-01, time/batch = 17.9601s	
12475/30300 (epoch 20.586), train_loss = 1.21189938, grad/param norm = 1.4689e-01, time/batch = 19.1367s	
12476/30300 (epoch 20.587), train_loss = 1.21389875, grad/param norm = 1.4891e-01, time/batch = 18.3942s	
12477/30300 (epoch 20.589), train_loss = 1.10927643, grad/param norm = 1.4230e-01, time/batch = 16.6323s	
12478/30300 (epoch 20.591), train_loss = 1.26415879, grad/param norm = 1.4224e-01, time/batch = 19.8810s	
12479/30300 (epoch 20.592), train_loss = 1.21847026, grad/param norm = 1.3584e-01, time/batch = 19.6160s	
12480/30300 (epoch 20.594), train_loss = 1.23267578, grad/param norm = 1.4899e-01, time/batch = 16.6907s	
12481/30300 (epoch 20.596), train_loss = 1.13860515, grad/param norm = 1.4032e-01, time/batch = 19.2815s	
12482/30300 (epoch 20.597), train_loss = 1.15686541, grad/param norm = 1.6191e-01, time/batch = 18.4833s	
12483/30300 (epoch 20.599), train_loss = 1.04033117, grad/param norm = 1.4667e-01, time/batch = 17.1234s	
12484/30300 (epoch 20.601), train_loss = 1.24732760, grad/param norm = 1.5125e-01, time/batch = 18.2918s	
12485/30300 (epoch 20.602), train_loss = 1.20437983, grad/param norm = 1.3821e-01, time/batch = 19.5437s	
12486/30300 (epoch 20.604), train_loss = 1.11038083, grad/param norm = 1.4224e-01, time/batch = 19.5414s	
12487/30300 (epoch 20.606), train_loss = 1.20640584, grad/param norm = 2.4461e-01, time/batch = 17.6227s	
12488/30300 (epoch 20.607), train_loss = 1.32359149, grad/param norm = 1.9466e-01, time/batch = 19.0447s	
12489/30300 (epoch 20.609), train_loss = 1.42246059, grad/param norm = 1.7612e-01, time/batch = 20.1235s	
12490/30300 (epoch 20.611), train_loss = 1.14044184, grad/param norm = 1.4161e-01, time/batch = 17.8600s	
12491/30300 (epoch 20.612), train_loss = 1.10934844, grad/param norm = 1.4314e-01, time/batch = 19.6289s	
12492/30300 (epoch 20.614), train_loss = 1.16778001, grad/param norm = 1.4494e-01, time/batch = 19.6203s	
12493/30300 (epoch 20.616), train_loss = 1.26630377, grad/param norm = 2.0988e-01, time/batch = 18.6159s	
12494/30300 (epoch 20.617), train_loss = 1.20696413, grad/param norm = 1.4454e-01, time/batch = 18.2088s	
12495/30300 (epoch 20.619), train_loss = 1.03348167, grad/param norm = 1.4830e-01, time/batch = 18.0387s	
12496/30300 (epoch 20.620), train_loss = 1.23513686, grad/param norm = 1.5701e-01, time/batch = 17.2699s	
12497/30300 (epoch 20.622), train_loss = 1.21083136, grad/param norm = 1.7163e-01, time/batch = 18.3490s	
12498/30300 (epoch 20.624), train_loss = 1.14547123, grad/param norm = 1.4895e-01, time/batch = 18.2912s	
12499/30300 (epoch 20.625), train_loss = 1.17259374, grad/param norm = 1.6526e-01, time/batch = 19.3745s	
12500/30300 (epoch 20.627), train_loss = 1.31917529, grad/param norm = 1.6293e-01, time/batch = 18.7698s	
12501/30300 (epoch 20.629), train_loss = 1.31471973, grad/param norm = 1.4655e-01, time/batch = 18.4715s	
12502/30300 (epoch 20.630), train_loss = 1.21240383, grad/param norm = 1.4432e-01, time/batch = 19.3854s	
12503/30300 (epoch 20.632), train_loss = 1.29399715, grad/param norm = 1.6385e-01, time/batch = 17.5984s	
12504/30300 (epoch 20.634), train_loss = 1.10359798, grad/param norm = 1.3251e-01, time/batch = 19.3524s	
12505/30300 (epoch 20.635), train_loss = 1.24779756, grad/param norm = 1.4732e-01, time/batch = 19.6113s	
12506/30300 (epoch 20.637), train_loss = 1.27601562, grad/param norm = 1.7083e-01, time/batch = 17.9424s	
12507/30300 (epoch 20.639), train_loss = 1.15642650, grad/param norm = 1.4299e-01, time/batch = 19.1281s	
12508/30300 (epoch 20.640), train_loss = 1.35055078, grad/param norm = 1.5791e-01, time/batch = 18.8710s	
12509/30300 (epoch 20.642), train_loss = 1.17973961, grad/param norm = 1.2967e-01, time/batch = 17.5352s	
12510/30300 (epoch 20.644), train_loss = 1.26666513, grad/param norm = 1.3941e-01, time/batch = 19.9298s	
12511/30300 (epoch 20.645), train_loss = 1.09689948, grad/param norm = 1.3325e-01, time/batch = 18.8886s	
12512/30300 (epoch 20.647), train_loss = 1.18774346, grad/param norm = 1.3588e-01, time/batch = 18.5323s	
12513/30300 (epoch 20.649), train_loss = 1.17052221, grad/param norm = 1.4502e-01, time/batch = 18.2070s	
12514/30300 (epoch 20.650), train_loss = 1.20516251, grad/param norm = 1.4631e-01, time/batch = 18.8705s	
12515/30300 (epoch 20.652), train_loss = 1.17126361, grad/param norm = 1.4409e-01, time/batch = 18.6930s	
12516/30300 (epoch 20.653), train_loss = 1.39738860, grad/param norm = 1.5664e-01, time/batch = 17.5110s	
12517/30300 (epoch 20.655), train_loss = 1.14651072, grad/param norm = 1.5850e-01, time/batch = 19.8649s	
12518/30300 (epoch 20.657), train_loss = 1.14845318, grad/param norm = 1.4080e-01, time/batch = 19.3767s	
12519/30300 (epoch 20.658), train_loss = 1.12611052, grad/param norm = 1.3816e-01, time/batch = 18.3658s	
12520/30300 (epoch 20.660), train_loss = 1.23206974, grad/param norm = 1.5383e-01, time/batch = 18.9557s	
12521/30300 (epoch 20.662), train_loss = 1.23418200, grad/param norm = 1.6436e-01, time/batch = 19.7021s	
12522/30300 (epoch 20.663), train_loss = 1.23237243, grad/param norm = 1.5103e-01, time/batch = 17.4613s	
12523/30300 (epoch 20.665), train_loss = 1.14886701, grad/param norm = 1.6585e-01, time/batch = 19.2022s	
12524/30300 (epoch 20.667), train_loss = 1.31703269, grad/param norm = 1.5580e-01, time/batch = 17.9738s	
12525/30300 (epoch 20.668), train_loss = 1.32226648, grad/param norm = 1.5372e-01, time/batch = 17.5525s	
12526/30300 (epoch 20.670), train_loss = 1.30706784, grad/param norm = 1.5261e-01, time/batch = 18.4732s	
12527/30300 (epoch 20.672), train_loss = 1.27419005, grad/param norm = 1.6323e-01, time/batch = 16.9566s	
12528/30300 (epoch 20.673), train_loss = 1.27980956, grad/param norm = 1.5579e-01, time/batch = 18.9607s	
12529/30300 (epoch 20.675), train_loss = 1.17227688, grad/param norm = 1.5130e-01, time/batch = 18.8661s	
12530/30300 (epoch 20.677), train_loss = 1.14791472, grad/param norm = 1.4073e-01, time/batch = 18.6194s	
12531/30300 (epoch 20.678), train_loss = 1.15497134, grad/param norm = 1.4487e-01, time/batch = 19.0799s	
12532/30300 (epoch 20.680), train_loss = 1.00647630, grad/param norm = 1.3298e-01, time/batch = 17.5413s	
12533/30300 (epoch 20.682), train_loss = 1.21813875, grad/param norm = 1.4948e-01, time/batch = 18.5515s	
12534/30300 (epoch 20.683), train_loss = 1.30382562, grad/param norm = 1.3388e-01, time/batch = 18.1293s	
12535/30300 (epoch 20.685), train_loss = 1.30623440, grad/param norm = 1.7560e-01, time/batch = 16.2960s	
12536/30300 (epoch 20.686), train_loss = 1.19441937, grad/param norm = 1.4095e-01, time/batch = 19.5446s	
12537/30300 (epoch 20.688), train_loss = 1.20099658, grad/param norm = 1.4269e-01, time/batch = 18.8825s	
12538/30300 (epoch 20.690), train_loss = 1.16734931, grad/param norm = 1.5626e-01, time/batch = 18.1241s	
12539/30300 (epoch 20.691), train_loss = 1.26142204, grad/param norm = 1.3865e-01, time/batch = 19.7868s	
12540/30300 (epoch 20.693), train_loss = 1.57456692, grad/param norm = 1.8323e-01, time/batch = 19.2119s	
12541/30300 (epoch 20.695), train_loss = 1.34427019, grad/param norm = 1.5986e-01, time/batch = 19.7971s	
12542/30300 (epoch 20.696), train_loss = 1.29634445, grad/param norm = 1.7649e-01, time/batch = 19.1887s	
12543/30300 (epoch 20.698), train_loss = 1.16257163, grad/param norm = 1.4048e-01, time/batch = 17.4457s	
12544/30300 (epoch 20.700), train_loss = 1.15579847, grad/param norm = 1.5243e-01, time/batch = 18.4377s	
12545/30300 (epoch 20.701), train_loss = 1.04096351, grad/param norm = 1.3577e-01, time/batch = 18.4475s	
12546/30300 (epoch 20.703), train_loss = 1.21149580, grad/param norm = 1.3556e-01, time/batch = 19.3792s	
12547/30300 (epoch 20.705), train_loss = 1.16924755, grad/param norm = 1.4749e-01, time/batch = 19.6375s	
12548/30300 (epoch 20.706), train_loss = 1.27929484, grad/param norm = 1.5514e-01, time/batch = 17.5974s	
12549/30300 (epoch 20.708), train_loss = 1.20779862, grad/param norm = 1.5328e-01, time/batch = 19.7040s	
12550/30300 (epoch 20.710), train_loss = 1.21797139, grad/param norm = 1.6396e-01, time/batch = 19.7012s	
12551/30300 (epoch 20.711), train_loss = 1.10871966, grad/param norm = 1.3427e-01, time/batch = 17.1149s	
12552/30300 (epoch 20.713), train_loss = 1.12192612, grad/param norm = 1.3807e-01, time/batch = 19.4408s	
12553/30300 (epoch 20.715), train_loss = 1.15682190, grad/param norm = 1.4355e-01, time/batch = 19.5485s	
12554/30300 (epoch 20.716), train_loss = 1.31199979, grad/param norm = 1.4582e-01, time/batch = 17.2702s	
12555/30300 (epoch 20.718), train_loss = 1.35732517, grad/param norm = 1.6144e-01, time/batch = 18.7823s	
12556/30300 (epoch 20.719), train_loss = 1.17355665, grad/param norm = 1.7295e-01, time/batch = 19.3052s	
12557/30300 (epoch 20.721), train_loss = 1.23310820, grad/param norm = 1.6790e-01, time/batch = 18.5443s	
12558/30300 (epoch 20.723), train_loss = 1.15471188, grad/param norm = 1.4748e-01, time/batch = 19.1914s	
12559/30300 (epoch 20.724), train_loss = 1.26943764, grad/param norm = 1.6769e-01, time/batch = 19.7879s	
12560/30300 (epoch 20.726), train_loss = 1.62175707, grad/param norm = 1.9640e-01, time/batch = 19.1290s	
12561/30300 (epoch 20.728), train_loss = 1.27358148, grad/param norm = 1.5942e-01, time/batch = 17.3731s	
12562/30300 (epoch 20.729), train_loss = 1.16855197, grad/param norm = 1.6022e-01, time/batch = 19.4502s	
12563/30300 (epoch 20.731), train_loss = 1.28821412, grad/param norm = 1.6437e-01, time/batch = 19.5474s	
12564/30300 (epoch 20.733), train_loss = 1.20098282, grad/param norm = 1.4514e-01, time/batch = 17.6879s	
12565/30300 (epoch 20.734), train_loss = 1.27323752, grad/param norm = 1.4082e-01, time/batch = 19.5311s	
12566/30300 (epoch 20.736), train_loss = 1.18489668, grad/param norm = 1.3869e-01, time/batch = 18.3430s	
12567/30300 (epoch 20.738), train_loss = 1.11245792, grad/param norm = 1.2960e-01, time/batch = 18.1970s	
12568/30300 (epoch 20.739), train_loss = 1.26513077, grad/param norm = 1.4532e-01, time/batch = 19.3568s	
12569/30300 (epoch 20.741), train_loss = 1.34572630, grad/param norm = 1.4617e-01, time/batch = 19.6934s	
12570/30300 (epoch 20.743), train_loss = 1.19086302, grad/param norm = 1.5040e-01, time/batch = 17.4380s	
12571/30300 (epoch 20.744), train_loss = 1.25665949, grad/param norm = 1.5011e-01, time/batch = 14.8002s	
12572/30300 (epoch 20.746), train_loss = 1.12245081, grad/param norm = 1.3938e-01, time/batch = 14.8572s	
12573/30300 (epoch 20.748), train_loss = 1.23211616, grad/param norm = 1.6892e-01, time/batch = 15.2795s	
12574/30300 (epoch 20.749), train_loss = 1.27084625, grad/param norm = 1.5280e-01, time/batch = 18.3633s	
12575/30300 (epoch 20.751), train_loss = 1.19749131, grad/param norm = 1.3880e-01, time/batch = 19.4544s	
12576/30300 (epoch 20.752), train_loss = 1.19310085, grad/param norm = 1.4957e-01, time/batch = 19.5168s	
12577/30300 (epoch 20.754), train_loss = 1.12217599, grad/param norm = 1.3953e-01, time/batch = 18.1840s	
12578/30300 (epoch 20.756), train_loss = 1.19549690, grad/param norm = 1.5160e-01, time/batch = 18.7978s	
12579/30300 (epoch 20.757), train_loss = 1.24657495, grad/param norm = 1.6198e-01, time/batch = 18.9573s	
12580/30300 (epoch 20.759), train_loss = 1.23806597, grad/param norm = 1.3863e-01, time/batch = 18.2201s	
12581/30300 (epoch 20.761), train_loss = 1.05575100, grad/param norm = 1.3149e-01, time/batch = 18.5686s	
12582/30300 (epoch 20.762), train_loss = 1.09879787, grad/param norm = 1.4617e-01, time/batch = 19.7954s	
12583/30300 (epoch 20.764), train_loss = 1.18363039, grad/param norm = 1.6091e-01, time/batch = 17.6101s	
12584/30300 (epoch 20.766), train_loss = 1.27066417, grad/param norm = 1.5185e-01, time/batch = 19.2182s	
12585/30300 (epoch 20.767), train_loss = 1.28955089, grad/param norm = 1.7273e-01, time/batch = 20.1302s	
12586/30300 (epoch 20.769), train_loss = 1.27005187, grad/param norm = 1.5476e-01, time/batch = 18.6067s	
12587/30300 (epoch 20.771), train_loss = 1.17312413, grad/param norm = 1.7771e-01, time/batch = 19.0283s	
12588/30300 (epoch 20.772), train_loss = 1.28006124, grad/param norm = 1.5798e-01, time/batch = 17.4551s	
12589/30300 (epoch 20.774), train_loss = 1.36455419, grad/param norm = 1.4670e-01, time/batch = 19.2050s	
12590/30300 (epoch 20.776), train_loss = 1.24638490, grad/param norm = 1.6250e-01, time/batch = 17.1141s	
12591/30300 (epoch 20.777), train_loss = 1.29883532, grad/param norm = 1.5462e-01, time/batch = 19.7177s	
12592/30300 (epoch 20.779), train_loss = 1.38230147, grad/param norm = 1.7661e-01, time/batch = 18.8880s	
12593/30300 (epoch 20.781), train_loss = 1.22012257, grad/param norm = 1.7633e-01, time/batch = 17.3769s	
12594/30300 (epoch 20.782), train_loss = 1.16259483, grad/param norm = 1.4894e-01, time/batch = 19.2885s	
12595/30300 (epoch 20.784), train_loss = 1.14564617, grad/param norm = 1.4883e-01, time/batch = 20.1321s	
12596/30300 (epoch 20.785), train_loss = 1.39582156, grad/param norm = 2.0395e-01, time/batch = 17.9585s	
12597/30300 (epoch 20.787), train_loss = 1.05356337, grad/param norm = 1.4019e-01, time/batch = 16.8009s	
12598/30300 (epoch 20.789), train_loss = 1.45785893, grad/param norm = 1.5652e-01, time/batch = 19.9571s	
12599/30300 (epoch 20.790), train_loss = 1.29103492, grad/param norm = 1.5920e-01, time/batch = 18.5377s	
12600/30300 (epoch 20.792), train_loss = 1.05113755, grad/param norm = 1.5353e-01, time/batch = 19.8755s	
12601/30300 (epoch 20.794), train_loss = 1.20783736, grad/param norm = 1.5461e-01, time/batch = 17.6831s	
12602/30300 (epoch 20.795), train_loss = 1.13249708, grad/param norm = 1.3190e-01, time/batch = 16.0465s	
12603/30300 (epoch 20.797), train_loss = 1.37524247, grad/param norm = 1.7806e-01, time/batch = 19.0404s	
12604/30300 (epoch 20.799), train_loss = 1.28453251, grad/param norm = 1.5848e-01, time/batch = 19.7136s	
12605/30300 (epoch 20.800), train_loss = 1.30199978, grad/param norm = 1.5559e-01, time/batch = 19.6203s	
12606/30300 (epoch 20.802), train_loss = 1.45223573, grad/param norm = 1.6647e-01, time/batch = 18.2758s	
12607/30300 (epoch 20.804), train_loss = 1.33220762, grad/param norm = 1.6856e-01, time/batch = 18.9462s	
12608/30300 (epoch 20.805), train_loss = 1.38443953, grad/param norm = 1.6315e-01, time/batch = 19.2727s	
12609/30300 (epoch 20.807), train_loss = 1.20671693, grad/param norm = 1.6042e-01, time/batch = 17.4454s	
12610/30300 (epoch 20.809), train_loss = 1.32054579, grad/param norm = 1.7036e-01, time/batch = 19.7678s	
12611/30300 (epoch 20.810), train_loss = 1.31633165, grad/param norm = 1.5096e-01, time/batch = 19.3783s	
12612/30300 (epoch 20.812), train_loss = 1.14567794, grad/param norm = 1.5348e-01, time/batch = 18.6179s	
12613/30300 (epoch 20.814), train_loss = 1.24264302, grad/param norm = 1.6641e-01, time/batch = 19.8688s	
12614/30300 (epoch 20.815), train_loss = 1.25462110, grad/param norm = 1.5683e-01, time/batch = 19.7001s	
12615/30300 (epoch 20.817), train_loss = 1.32914569, grad/param norm = 1.5671e-01, time/batch = 17.5226s	
12616/30300 (epoch 20.818), train_loss = 1.28664532, grad/param norm = 1.4893e-01, time/batch = 18.3694s	
12617/30300 (epoch 20.820), train_loss = 1.40975967, grad/param norm = 1.6559e-01, time/batch = 17.3587s	
12618/30300 (epoch 20.822), train_loss = 1.40602756, grad/param norm = 1.7435e-01, time/batch = 18.6950s	
12619/30300 (epoch 20.823), train_loss = 1.42709805, grad/param norm = 1.6560e-01, time/batch = 18.3824s	
12620/30300 (epoch 20.825), train_loss = 1.34089308, grad/param norm = 1.5383e-01, time/batch = 19.5449s	
12621/30300 (epoch 20.827), train_loss = 1.08362202, grad/param norm = 1.6867e-01, time/batch = 19.5342s	
12622/30300 (epoch 20.828), train_loss = 1.31523985, grad/param norm = 1.6015e-01, time/batch = 18.4551s	
12623/30300 (epoch 20.830), train_loss = 1.27911360, grad/param norm = 1.6069e-01, time/batch = 19.6282s	
12624/30300 (epoch 20.832), train_loss = 1.15069883, grad/param norm = 1.6254e-01, time/batch = 19.7004s	
12625/30300 (epoch 20.833), train_loss = 1.29920101, grad/param norm = 1.6208e-01, time/batch = 18.5345s	
12626/30300 (epoch 20.835), train_loss = 1.14737818, grad/param norm = 1.4262e-01, time/batch = 19.2189s	
12627/30300 (epoch 20.837), train_loss = 1.08947151, grad/param norm = 1.3979e-01, time/batch = 19.5559s	
12628/30300 (epoch 20.838), train_loss = 1.11721405, grad/param norm = 1.4372e-01, time/batch = 16.9420s	
12629/30300 (epoch 20.840), train_loss = 1.29820652, grad/param norm = 1.3341e-01, time/batch = 17.9463s	
12630/30300 (epoch 20.842), train_loss = 1.14192033, grad/param norm = 1.3654e-01, time/batch = 19.9688s	
12631/30300 (epoch 20.843), train_loss = 1.26144779, grad/param norm = 1.4445e-01, time/batch = 18.7893s	
12632/30300 (epoch 20.845), train_loss = 1.26476153, grad/param norm = 1.4799e-01, time/batch = 19.1223s	
12633/30300 (epoch 20.847), train_loss = 1.25314553, grad/param norm = 1.5043e-01, time/batch = 19.9487s	
12634/30300 (epoch 20.848), train_loss = 1.32921308, grad/param norm = 1.6343e-01, time/batch = 28.1486s	
12635/30300 (epoch 20.850), train_loss = 1.23830901, grad/param norm = 1.4423e-01, time/batch = 23.5892s	
12636/30300 (epoch 20.851), train_loss = 1.27817907, grad/param norm = 1.7330e-01, time/batch = 19.1199s	
12637/30300 (epoch 20.853), train_loss = 1.18762325, grad/param norm = 1.3485e-01, time/batch = 17.7733s	
12638/30300 (epoch 20.855), train_loss = 1.15440414, grad/param norm = 1.2775e-01, time/batch = 17.3659s	
12639/30300 (epoch 20.856), train_loss = 1.23113382, grad/param norm = 1.4761e-01, time/batch = 18.6893s	
12640/30300 (epoch 20.858), train_loss = 1.17504617, grad/param norm = 1.3813e-01, time/batch = 17.8580s	
12641/30300 (epoch 20.860), train_loss = 1.13875329, grad/param norm = 1.4331e-01, time/batch = 16.7654s	
12642/30300 (epoch 20.861), train_loss = 1.38946000, grad/param norm = 1.5146e-01, time/batch = 18.7910s	
12643/30300 (epoch 20.863), train_loss = 1.24193963, grad/param norm = 1.4042e-01, time/batch = 17.6225s	
12644/30300 (epoch 20.865), train_loss = 1.31311394, grad/param norm = 1.6226e-01, time/batch = 18.3709s	
12645/30300 (epoch 20.866), train_loss = 1.31081517, grad/param norm = 1.6458e-01, time/batch = 19.1142s	
12646/30300 (epoch 20.868), train_loss = 1.22455805, grad/param norm = 1.4982e-01, time/batch = 16.4283s	
12647/30300 (epoch 20.870), train_loss = 1.14910959, grad/param norm = 1.4342e-01, time/batch = 15.4204s	
12648/30300 (epoch 20.871), train_loss = 1.18614842, grad/param norm = 1.3812e-01, time/batch = 15.2457s	
12649/30300 (epoch 20.873), train_loss = 1.23152235, grad/param norm = 1.3863e-01, time/batch = 15.4974s	
12650/30300 (epoch 20.875), train_loss = 1.15336525, grad/param norm = 1.3699e-01, time/batch = 17.4374s	
12651/30300 (epoch 20.876), train_loss = 1.11735586, grad/param norm = 1.5399e-01, time/batch = 17.9589s	
12652/30300 (epoch 20.878), train_loss = 1.05643098, grad/param norm = 1.4329e-01, time/batch = 18.2661s	
12653/30300 (epoch 20.880), train_loss = 1.12856228, grad/param norm = 1.4110e-01, time/batch = 18.1635s	
12654/30300 (epoch 20.881), train_loss = 1.42086985, grad/param norm = 2.0731e-01, time/batch = 18.8590s	
12655/30300 (epoch 20.883), train_loss = 1.27939428, grad/param norm = 1.4842e-01, time/batch = 18.0282s	
12656/30300 (epoch 20.884), train_loss = 1.14314625, grad/param norm = 1.3330e-01, time/batch = 18.7202s	
12657/30300 (epoch 20.886), train_loss = 1.25410141, grad/param norm = 1.4118e-01, time/batch = 18.0368s	
12658/30300 (epoch 20.888), train_loss = 1.23098373, grad/param norm = 1.5253e-01, time/batch = 16.8497s	
12659/30300 (epoch 20.889), train_loss = 1.25824655, grad/param norm = 1.4665e-01, time/batch = 18.4482s	
12660/30300 (epoch 20.891), train_loss = 1.26113953, grad/param norm = 1.6348e-01, time/batch = 17.5308s	
12661/30300 (epoch 20.893), train_loss = 1.46372703, grad/param norm = 1.5915e-01, time/batch = 17.7852s	
12662/30300 (epoch 20.894), train_loss = 1.31485603, grad/param norm = 1.4931e-01, time/batch = 19.1048s	
12663/30300 (epoch 20.896), train_loss = 1.06015163, grad/param norm = 1.3849e-01, time/batch = 18.2075s	
12664/30300 (epoch 20.898), train_loss = 1.02631036, grad/param norm = 1.4027e-01, time/batch = 18.4445s	
12665/30300 (epoch 20.899), train_loss = 1.15258763, grad/param norm = 1.6354e-01, time/batch = 18.3878s	
12666/30300 (epoch 20.901), train_loss = 1.20710059, grad/param norm = 1.6142e-01, time/batch = 18.8636s	
12667/30300 (epoch 20.903), train_loss = 1.26259671, grad/param norm = 1.5527e-01, time/batch = 17.0949s	
12668/30300 (epoch 20.904), train_loss = 1.20096519, grad/param norm = 1.4962e-01, time/batch = 18.3922s	
12669/30300 (epoch 20.906), train_loss = 1.32209168, grad/param norm = 1.5294e-01, time/batch = 18.1948s	
12670/30300 (epoch 20.908), train_loss = 1.17772105, grad/param norm = 1.4788e-01, time/batch = 17.4632s	
12671/30300 (epoch 20.909), train_loss = 1.13658276, grad/param norm = 1.5390e-01, time/batch = 16.9577s	
12672/30300 (epoch 20.911), train_loss = 1.22424966, grad/param norm = 1.4309e-01, time/batch = 18.6095s	
12673/30300 (epoch 20.913), train_loss = 1.20720050, grad/param norm = 1.4390e-01, time/batch = 18.1154s	
12674/30300 (epoch 20.914), train_loss = 1.17746011, grad/param norm = 1.5094e-01, time/batch = 18.6262s	
12675/30300 (epoch 20.916), train_loss = 1.24044688, grad/param norm = 1.3921e-01, time/batch = 19.1264s	
12676/30300 (epoch 20.917), train_loss = 1.15608377, grad/param norm = 1.4757e-01, time/batch = 18.8783s	
12677/30300 (epoch 20.919), train_loss = 1.18075979, grad/param norm = 1.6001e-01, time/batch = 19.2057s	
12678/30300 (epoch 20.921), train_loss = 1.23250125, grad/param norm = 1.5002e-01, time/batch = 19.4716s	
12679/30300 (epoch 20.922), train_loss = 1.32233609, grad/param norm = 1.7033e-01, time/batch = 16.7785s	
12680/30300 (epoch 20.924), train_loss = 1.22854588, grad/param norm = 1.5692e-01, time/batch = 18.0335s	
12681/30300 (epoch 20.926), train_loss = 1.25108583, grad/param norm = 1.5571e-01, time/batch = 18.7793s	
12682/30300 (epoch 20.927), train_loss = 1.22517774, grad/param norm = 1.5180e-01, time/batch = 17.1923s	
12683/30300 (epoch 20.929), train_loss = 1.16608243, grad/param norm = 1.5194e-01, time/batch = 18.5269s	
12684/30300 (epoch 20.931), train_loss = 1.34419813, grad/param norm = 1.6536e-01, time/batch = 18.1793s	
12685/30300 (epoch 20.932), train_loss = 1.18058345, grad/param norm = 1.5057e-01, time/batch = 19.9468s	
12686/30300 (epoch 20.934), train_loss = 1.25292051, grad/param norm = 1.5662e-01, time/batch = 18.1106s	
12687/30300 (epoch 20.936), train_loss = 1.18413741, grad/param norm = 1.4098e-01, time/batch = 18.4379s	
12688/30300 (epoch 20.937), train_loss = 1.14109541, grad/param norm = 1.4555e-01, time/batch = 18.7133s	
12689/30300 (epoch 20.939), train_loss = 1.35969843, grad/param norm = 1.9447e-01, time/batch = 19.4411s	
12690/30300 (epoch 20.941), train_loss = 1.22277467, grad/param norm = 1.5629e-01, time/batch = 18.8556s	
12691/30300 (epoch 20.942), train_loss = 1.22470317, grad/param norm = 1.7308e-01, time/batch = 18.2816s	
12692/30300 (epoch 20.944), train_loss = 1.11378556, grad/param norm = 1.4424e-01, time/batch = 19.9480s	
12693/30300 (epoch 20.946), train_loss = 1.34697728, grad/param norm = 1.8984e-01, time/batch = 19.1928s	
12694/30300 (epoch 20.947), train_loss = 1.32696638, grad/param norm = 1.8069e-01, time/batch = 18.6327s	
12695/30300 (epoch 20.949), train_loss = 1.40554177, grad/param norm = 1.7339e-01, time/batch = 19.4610s	
12696/30300 (epoch 20.950), train_loss = 1.32400283, grad/param norm = 1.5911e-01, time/batch = 18.5289s	
12697/30300 (epoch 20.952), train_loss = 1.30027571, grad/param norm = 1.7503e-01, time/batch = 19.0448s	
12698/30300 (epoch 20.954), train_loss = 1.49534257, grad/param norm = 1.5189e-01, time/batch = 19.7440s	
12699/30300 (epoch 20.955), train_loss = 1.18565115, grad/param norm = 1.6458e-01, time/batch = 17.6288s	
12700/30300 (epoch 20.957), train_loss = 1.27236642, grad/param norm = 1.5164e-01, time/batch = 16.7945s	
12701/30300 (epoch 20.959), train_loss = 1.17292117, grad/param norm = 1.5321e-01, time/batch = 19.7084s	
12702/30300 (epoch 20.960), train_loss = 1.19851287, grad/param norm = 1.6202e-01, time/batch = 18.4584s	
12703/30300 (epoch 20.962), train_loss = 1.21437854, grad/param norm = 1.9287e-01, time/batch = 19.3629s	
12704/30300 (epoch 20.964), train_loss = 1.15206351, grad/param norm = 1.8091e-01, time/batch = 18.0167s	
12705/30300 (epoch 20.965), train_loss = 1.14681460, grad/param norm = 1.8869e-01, time/batch = 19.4433s	
12706/30300 (epoch 20.967), train_loss = 1.23915964, grad/param norm = 1.8909e-01, time/batch = 18.2897s	
12707/30300 (epoch 20.969), train_loss = 1.13152389, grad/param norm = 1.6565e-01, time/batch = 18.1483s	
12708/30300 (epoch 20.970), train_loss = 1.18142932, grad/param norm = 1.4629e-01, time/batch = 18.9634s	
12709/30300 (epoch 20.972), train_loss = 1.10846040, grad/param norm = 1.6027e-01, time/batch = 19.2852s	
12710/30300 (epoch 20.974), train_loss = 1.43199938, grad/param norm = 1.7863e-01, time/batch = 19.6316s	
12711/30300 (epoch 20.975), train_loss = 1.43657059, grad/param norm = 1.9521e-01, time/batch = 19.4666s	
12712/30300 (epoch 20.977), train_loss = 1.33585262, grad/param norm = 1.5881e-01, time/batch = 18.2766s	
12713/30300 (epoch 20.979), train_loss = 1.28922865, grad/param norm = 1.5068e-01, time/batch = 17.4453s	
12714/30300 (epoch 20.980), train_loss = 1.31337755, grad/param norm = 1.7092e-01, time/batch = 19.9453s	
12715/30300 (epoch 20.982), train_loss = 1.33024162, grad/param norm = 1.6338e-01, time/batch = 18.1077s	
12716/30300 (epoch 20.983), train_loss = 1.35855346, grad/param norm = 1.5922e-01, time/batch = 19.1932s	
12717/30300 (epoch 20.985), train_loss = 1.28529072, grad/param norm = 1.7795e-01, time/batch = 18.5986s	
12718/30300 (epoch 20.987), train_loss = 1.19731125, grad/param norm = 1.5027e-01, time/batch = 17.3040s	
12719/30300 (epoch 20.988), train_loss = 1.36873300, grad/param norm = 1.6468e-01, time/batch = 19.2873s	
12720/30300 (epoch 20.990), train_loss = 1.07273871, grad/param norm = 1.4084e-01, time/batch = 18.4523s	
12721/30300 (epoch 20.992), train_loss = 1.28477247, grad/param norm = 1.3785e-01, time/batch = 18.3697s	
12722/30300 (epoch 20.993), train_loss = 1.36321292, grad/param norm = 1.7828e-01, time/batch = 18.2181s	
12723/30300 (epoch 20.995), train_loss = 1.21077561, grad/param norm = 1.6124e-01, time/batch = 17.6397s	
12724/30300 (epoch 20.997), train_loss = 1.26817427, grad/param norm = 1.5955e-01, time/batch = 19.5622s	
12725/30300 (epoch 20.998), train_loss = 1.32139788, grad/param norm = 1.7775e-01, time/batch = 17.8843s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
12726/30300 (epoch 21.000), train_loss = 1.18994389, grad/param norm = 1.6446e-01, time/batch = 18.5454s	
12727/30300 (epoch 21.002), train_loss = 1.33289219, grad/param norm = 1.6196e-01, time/batch = 17.4273s	
12728/30300 (epoch 21.003), train_loss = 1.25285388, grad/param norm = 1.7517e-01, time/batch = 18.7727s	
12729/30300 (epoch 21.005), train_loss = 1.21279665, grad/param norm = 1.6245e-01, time/batch = 17.7097s	
12730/30300 (epoch 21.007), train_loss = 1.31078463, grad/param norm = 1.7489e-01, time/batch = 19.2876s	
12731/30300 (epoch 21.008), train_loss = 1.16922931, grad/param norm = 1.6102e-01, time/batch = 18.3718s	
12732/30300 (epoch 21.010), train_loss = 1.12895811, grad/param norm = 3.3234e-01, time/batch = 18.0241s	
12733/30300 (epoch 21.012), train_loss = 1.17583900, grad/param norm = 1.4870e-01, time/batch = 18.3521s	
12734/30300 (epoch 21.013), train_loss = 1.34329221, grad/param norm = 1.5789e-01, time/batch = 18.3437s	
12735/30300 (epoch 21.015), train_loss = 1.18817693, grad/param norm = 1.5016e-01, time/batch = 18.4534s	
12736/30300 (epoch 21.017), train_loss = 1.17921909, grad/param norm = 1.4147e-01, time/batch = 16.5168s	
12737/30300 (epoch 21.018), train_loss = 1.18430024, grad/param norm = 1.5943e-01, time/batch = 18.5496s	
12738/30300 (epoch 21.020), train_loss = 1.33806673, grad/param norm = 1.7404e-01, time/batch = 18.1779s	
12739/30300 (epoch 21.021), train_loss = 1.34144766, grad/param norm = 1.5901e-01, time/batch = 18.9633s	
12740/30300 (epoch 21.023), train_loss = 1.20803134, grad/param norm = 1.4375e-01, time/batch = 18.5241s	
12741/30300 (epoch 21.025), train_loss = 1.14692801, grad/param norm = 1.5942e-01, time/batch = 17.8716s	
12742/30300 (epoch 21.026), train_loss = 1.27363678, grad/param norm = 1.7151e-01, time/batch = 19.4412s	
12743/30300 (epoch 21.028), train_loss = 1.31923618, grad/param norm = 1.5785e-01, time/batch = 18.3772s	
12744/30300 (epoch 21.030), train_loss = 1.15300753, grad/param norm = 1.5149e-01, time/batch = 18.1317s	
12745/30300 (epoch 21.031), train_loss = 1.26631496, grad/param norm = 1.5999e-01, time/batch = 18.9496s	
12746/30300 (epoch 21.033), train_loss = 1.22351849, grad/param norm = 1.6824e-01, time/batch = 18.0633s	
12747/30300 (epoch 21.035), train_loss = 1.31558547, grad/param norm = 1.6562e-01, time/batch = 18.4299s	
12748/30300 (epoch 21.036), train_loss = 1.23442731, grad/param norm = 1.6545e-01, time/batch = 18.1114s	
12749/30300 (epoch 21.038), train_loss = 1.25696344, grad/param norm = 1.4833e-01, time/batch = 19.4619s	
12750/30300 (epoch 21.040), train_loss = 0.97568323, grad/param norm = 1.3883e-01, time/batch = 19.1114s	
12751/30300 (epoch 21.041), train_loss = 1.01570028, grad/param norm = 1.2843e-01, time/batch = 19.0220s	
12752/30300 (epoch 21.043), train_loss = 1.24214780, grad/param norm = 1.5154e-01, time/batch = 19.0251s	
12753/30300 (epoch 21.045), train_loss = 1.20828691, grad/param norm = 1.5117e-01, time/batch = 19.7031s	
12754/30300 (epoch 21.046), train_loss = 1.38336151, grad/param norm = 1.7458e-01, time/batch = 17.5189s	
12755/30300 (epoch 21.048), train_loss = 1.22293691, grad/param norm = 1.8716e-01, time/batch = 17.9512s	
12756/30300 (epoch 21.050), train_loss = 1.18857522, grad/param norm = 1.5710e-01, time/batch = 18.3816s	
12757/30300 (epoch 21.051), train_loss = 1.24836673, grad/param norm = 1.5646e-01, time/batch = 16.9105s	
12758/30300 (epoch 21.053), train_loss = 1.05463013, grad/param norm = 1.8129e-01, time/batch = 19.5352s	
12759/30300 (epoch 21.054), train_loss = 1.21328924, grad/param norm = 1.5402e-01, time/batch = 19.1137s	
12760/30300 (epoch 21.056), train_loss = 1.15527555, grad/param norm = 1.4762e-01, time/batch = 16.5244s	
12761/30300 (epoch 21.058), train_loss = 1.18515250, grad/param norm = 1.4717e-01, time/batch = 19.5251s	
12762/30300 (epoch 21.059), train_loss = 1.12871035, grad/param norm = 1.5666e-01, time/batch = 19.0450s	
12763/30300 (epoch 21.061), train_loss = 1.31676838, grad/param norm = 1.6426e-01, time/batch = 17.7740s	
12764/30300 (epoch 21.063), train_loss = 1.13472391, grad/param norm = 1.5954e-01, time/batch = 17.4418s	
12765/30300 (epoch 21.064), train_loss = 1.23896422, grad/param norm = 1.6037e-01, time/batch = 19.1286s	
12766/30300 (epoch 21.066), train_loss = 1.21344485, grad/param norm = 1.4022e-01, time/batch = 19.8804s	
12767/30300 (epoch 21.068), train_loss = 1.10010564, grad/param norm = 1.4877e-01, time/batch = 18.4437s	
12768/30300 (epoch 21.069), train_loss = 1.26736334, grad/param norm = 1.4741e-01, time/batch = 19.6325s	
12769/30300 (epoch 21.071), train_loss = 1.29269224, grad/param norm = 1.6731e-01, time/batch = 17.8579s	
12770/30300 (epoch 21.073), train_loss = 1.19824138, grad/param norm = 1.7036e-01, time/batch = 17.5310s	
12771/30300 (epoch 21.074), train_loss = 1.26696137, grad/param norm = 1.4768e-01, time/batch = 19.8611s	
12772/30300 (epoch 21.076), train_loss = 1.18884734, grad/param norm = 1.4726e-01, time/batch = 19.3552s	
12773/30300 (epoch 21.078), train_loss = 1.12434009, grad/param norm = 1.3834e-01, time/batch = 18.1966s	
12774/30300 (epoch 21.079), train_loss = 1.14949570, grad/param norm = 1.3813e-01, time/batch = 19.2687s	
12775/30300 (epoch 21.081), train_loss = 1.22886772, grad/param norm = 1.5810e-01, time/batch = 19.7015s	
12776/30300 (epoch 21.083), train_loss = 1.29992080, grad/param norm = 1.6114e-01, time/batch = 18.5366s	
12777/30300 (epoch 21.084), train_loss = 1.11317766, grad/param norm = 1.5131e-01, time/batch = 19.3779s	
12778/30300 (epoch 21.086), train_loss = 1.16707287, grad/param norm = 1.6803e-01, time/batch = 19.1854s	
12779/30300 (epoch 21.087), train_loss = 1.13191614, grad/param norm = 1.4434e-01, time/batch = 17.0949s	
12780/30300 (epoch 21.089), train_loss = 1.17638246, grad/param norm = 1.4736e-01, time/batch = 17.9300s	
12781/30300 (epoch 21.091), train_loss = 1.24936337, grad/param norm = 1.5933e-01, time/batch = 18.0319s	
12782/30300 (epoch 21.092), train_loss = 1.25880300, grad/param norm = 1.4970e-01, time/batch = 18.1405s	
12783/30300 (epoch 21.094), train_loss = 1.38827341, grad/param norm = 1.8200e-01, time/batch = 16.6051s	
12784/30300 (epoch 21.096), train_loss = 1.31172668, grad/param norm = 1.6187e-01, time/batch = 18.3032s	
12785/30300 (epoch 21.097), train_loss = 1.18245188, grad/param norm = 1.6496e-01, time/batch = 17.6213s	
12786/30300 (epoch 21.099), train_loss = 1.32692669, grad/param norm = 1.5887e-01, time/batch = 16.2567s	
12787/30300 (epoch 21.101), train_loss = 1.37093561, grad/param norm = 1.9692e-01, time/batch = 17.9915s	
12788/30300 (epoch 21.102), train_loss = 1.16014859, grad/param norm = 1.7915e-01, time/batch = 15.9782s	
12789/30300 (epoch 21.104), train_loss = 1.19643660, grad/param norm = 1.9271e-01, time/batch = 18.4013s	
12790/30300 (epoch 21.106), train_loss = 1.19102938, grad/param norm = 1.6095e-01, time/batch = 17.2663s	
12791/30300 (epoch 21.107), train_loss = 1.24918389, grad/param norm = 1.5531e-01, time/batch = 17.2534s	
12792/30300 (epoch 21.109), train_loss = 1.32545504, grad/param norm = 1.9137e-01, time/batch = 18.5327s	
12793/30300 (epoch 21.111), train_loss = 1.34863334, grad/param norm = 1.6731e-01, time/batch = 17.1789s	
12794/30300 (epoch 21.112), train_loss = 1.29875518, grad/param norm = 1.5363e-01, time/batch = 18.5923s	
12795/30300 (epoch 21.114), train_loss = 1.22137558, grad/param norm = 1.5555e-01, time/batch = 16.9017s	
12796/30300 (epoch 21.116), train_loss = 1.21792271, grad/param norm = 1.7205e-01, time/batch = 18.5848s	
12797/30300 (epoch 21.117), train_loss = 1.25587852, grad/param norm = 1.3766e-01, time/batch = 18.3619s	
12798/30300 (epoch 21.119), train_loss = 1.15371286, grad/param norm = 1.5152e-01, time/batch = 17.5253s	
12799/30300 (epoch 21.120), train_loss = 1.23176638, grad/param norm = 1.6182e-01, time/batch = 17.1957s	
12800/30300 (epoch 21.122), train_loss = 1.33383218, grad/param norm = 1.8414e-01, time/batch = 17.1598s	
12801/30300 (epoch 21.124), train_loss = 1.38902172, grad/param norm = 1.7517e-01, time/batch = 18.6061s	
12802/30300 (epoch 21.125), train_loss = 1.08396843, grad/param norm = 1.4527e-01, time/batch = 18.4402s	
12803/30300 (epoch 21.127), train_loss = 1.27901717, grad/param norm = 1.8377e-01, time/batch = 16.7723s	
12804/30300 (epoch 21.129), train_loss = 1.37625677, grad/param norm = 1.5397e-01, time/batch = 17.5043s	
12805/30300 (epoch 21.130), train_loss = 1.37152098, grad/param norm = 1.5930e-01, time/batch = 19.0272s	
12806/30300 (epoch 21.132), train_loss = 1.34989977, grad/param norm = 1.7450e-01, time/batch = 17.3484s	
12807/30300 (epoch 21.134), train_loss = 1.13807411, grad/param norm = 1.5274e-01, time/batch = 18.5223s	
12808/30300 (epoch 21.135), train_loss = 1.16253796, grad/param norm = 1.6217e-01, time/batch = 18.8318s	
12809/30300 (epoch 21.137), train_loss = 1.24105217, grad/param norm = 1.7489e-01, time/batch = 19.3624s	
12810/30300 (epoch 21.139), train_loss = 1.19577789, grad/param norm = 1.7839e-01, time/batch = 19.7492s	
12811/30300 (epoch 21.140), train_loss = 1.26763292, grad/param norm = 1.9857e-01, time/batch = 16.6801s	
12812/30300 (epoch 21.142), train_loss = 1.37790799, grad/param norm = 2.0127e-01, time/batch = 17.7625s	
12813/30300 (epoch 21.144), train_loss = 1.24666853, grad/param norm = 1.8295e-01, time/batch = 17.2523s	
12814/30300 (epoch 21.145), train_loss = 1.36542413, grad/param norm = 2.4373e-01, time/batch = 17.8645s	
12815/30300 (epoch 21.147), train_loss = 1.19669679, grad/param norm = 1.5906e-01, time/batch = 16.2475s	
12816/30300 (epoch 21.149), train_loss = 1.43517100, grad/param norm = 1.8416e-01, time/batch = 16.5041s	
12817/30300 (epoch 21.150), train_loss = 1.20643955, grad/param norm = 1.6479e-01, time/batch = 18.6930s	
12818/30300 (epoch 21.152), train_loss = 1.12692138, grad/param norm = 1.7119e-01, time/batch = 17.7556s	
12819/30300 (epoch 21.153), train_loss = 1.22052470, grad/param norm = 1.5162e-01, time/batch = 18.5184s	
12820/30300 (epoch 21.155), train_loss = 1.07505545, grad/param norm = 1.4508e-01, time/batch = 17.6758s	
12821/30300 (epoch 21.157), train_loss = 1.21050970, grad/param norm = 1.6869e-01, time/batch = 18.6895s	
12822/30300 (epoch 21.158), train_loss = 1.25018354, grad/param norm = 1.8350e-01, time/batch = 17.6631s	
12823/30300 (epoch 21.160), train_loss = 1.14995074, grad/param norm = 1.6014e-01, time/batch = 18.2570s	
12824/30300 (epoch 21.162), train_loss = 1.20834257, grad/param norm = 1.4672e-01, time/batch = 17.3504s	
12825/30300 (epoch 21.163), train_loss = 1.17686448, grad/param norm = 1.6822e-01, time/batch = 17.8281s	
12826/30300 (epoch 21.165), train_loss = 1.33157067, grad/param norm = 1.5725e-01, time/batch = 15.9596s	
12827/30300 (epoch 21.167), train_loss = 1.22369879, grad/param norm = 1.7686e-01, time/batch = 16.3018s	
12828/30300 (epoch 21.168), train_loss = 1.28267635, grad/param norm = 1.5457e-01, time/batch = 17.6882s	
12829/30300 (epoch 21.170), train_loss = 1.26407342, grad/param norm = 1.7140e-01, time/batch = 18.8308s	
12830/30300 (epoch 21.172), train_loss = 1.19297689, grad/param norm = 1.6334e-01, time/batch = 31.3989s	
12831/30300 (epoch 21.173), train_loss = 1.22275854, grad/param norm = 1.6276e-01, time/batch = 18.3288s	
12832/30300 (epoch 21.175), train_loss = 1.22845723, grad/param norm = 1.4485e-01, time/batch = 17.1886s	
12833/30300 (epoch 21.177), train_loss = 1.26749087, grad/param norm = 1.7342e-01, time/batch = 18.6632s	
12834/30300 (epoch 21.178), train_loss = 1.00118787, grad/param norm = 1.4085e-01, time/batch = 16.5867s	
12835/30300 (epoch 21.180), train_loss = 1.19412011, grad/param norm = 1.4114e-01, time/batch = 17.1792s	
12836/30300 (epoch 21.182), train_loss = 1.19743200, grad/param norm = 1.6919e-01, time/batch = 17.5802s	
12837/30300 (epoch 21.183), train_loss = 1.15889157, grad/param norm = 1.4933e-01, time/batch = 18.1152s	
12838/30300 (epoch 21.185), train_loss = 1.43548756, grad/param norm = 1.7091e-01, time/batch = 19.5218s	
12839/30300 (epoch 21.186), train_loss = 1.48453300, grad/param norm = 1.9113e-01, time/batch = 17.2642s	
12840/30300 (epoch 21.188), train_loss = 1.27848196, grad/param norm = 1.7200e-01, time/batch = 19.4230s	
12841/30300 (epoch 21.190), train_loss = 1.20595875, grad/param norm = 1.5218e-01, time/batch = 19.3560s	
12842/30300 (epoch 21.191), train_loss = 1.29542540, grad/param norm = 1.5381e-01, time/batch = 18.6861s	
12843/30300 (epoch 21.193), train_loss = 1.14621579, grad/param norm = 1.4506e-01, time/batch = 18.9891s	
12844/30300 (epoch 21.195), train_loss = 1.24335555, grad/param norm = 1.6401e-01, time/batch = 18.7810s	
12845/30300 (epoch 21.196), train_loss = 1.26498279, grad/param norm = 1.3577e-01, time/batch = 17.3161s	
12846/30300 (epoch 21.198), train_loss = 1.02753880, grad/param norm = 1.4430e-01, time/batch = 17.6793s	
12847/30300 (epoch 21.200), train_loss = 1.21572928, grad/param norm = 1.4190e-01, time/batch = 18.8493s	
12848/30300 (epoch 21.201), train_loss = 1.32092035, grad/param norm = 1.8601e-01, time/batch = 18.7724s	
12849/30300 (epoch 21.203), train_loss = 1.25976492, grad/param norm = 1.5984e-01, time/batch = 16.9859s	
12850/30300 (epoch 21.205), train_loss = 1.44276586, grad/param norm = 1.7721e-01, time/batch = 18.2583s	
12851/30300 (epoch 21.206), train_loss = 1.34267444, grad/param norm = 1.7340e-01, time/batch = 15.6245s	
12852/30300 (epoch 21.208), train_loss = 1.34644045, grad/param norm = 1.9508e-01, time/batch = 16.7427s	
12853/30300 (epoch 21.210), train_loss = 1.29956746, grad/param norm = 1.5528e-01, time/batch = 17.7750s	
12854/30300 (epoch 21.211), train_loss = 1.34553446, grad/param norm = 1.6064e-01, time/batch = 17.6964s	
12855/30300 (epoch 21.213), train_loss = 1.18105130, grad/param norm = 1.4103e-01, time/batch = 19.5314s	
12856/30300 (epoch 21.215), train_loss = 1.13607447, grad/param norm = 1.6065e-01, time/batch = 18.6937s	
12857/30300 (epoch 21.216), train_loss = 1.19069511, grad/param norm = 1.5173e-01, time/batch = 17.1652s	
12858/30300 (epoch 21.218), train_loss = 1.10134441, grad/param norm = 1.3579e-01, time/batch = 19.7708s	
12859/30300 (epoch 21.219), train_loss = 1.06678656, grad/param norm = 1.3697e-01, time/batch = 17.6110s	
12860/30300 (epoch 21.221), train_loss = 1.08574216, grad/param norm = 1.5110e-01, time/batch = 18.4350s	
12861/30300 (epoch 21.223), train_loss = 1.24428098, grad/param norm = 1.4474e-01, time/batch = 18.4506s	
12862/30300 (epoch 21.224), train_loss = 1.06996119, grad/param norm = 1.5249e-01, time/batch = 17.1821s	
12863/30300 (epoch 21.226), train_loss = 1.29813596, grad/param norm = 1.7586e-01, time/batch = 19.1951s	
12864/30300 (epoch 21.228), train_loss = 1.32250117, grad/param norm = 1.5516e-01, time/batch = 18.9622s	
12865/30300 (epoch 21.229), train_loss = 1.17263887, grad/param norm = 1.4629e-01, time/batch = 16.7129s	
12866/30300 (epoch 21.231), train_loss = 1.25868516, grad/param norm = 1.5291e-01, time/batch = 16.2763s	
12867/30300 (epoch 21.233), train_loss = 1.20578770, grad/param norm = 1.3607e-01, time/batch = 18.5252s	
12868/30300 (epoch 21.234), train_loss = 1.27906012, grad/param norm = 1.8177e-01, time/batch = 17.5088s	
12869/30300 (epoch 21.236), train_loss = 1.23912406, grad/param norm = 1.3921e-01, time/batch = 17.4246s	
12870/30300 (epoch 21.238), train_loss = 1.27490739, grad/param norm = 1.6469e-01, time/batch = 18.0816s	
12871/30300 (epoch 21.239), train_loss = 1.26720410, grad/param norm = 1.6735e-01, time/batch = 19.2034s	
12872/30300 (epoch 21.241), train_loss = 1.25963480, grad/param norm = 1.7049e-01, time/batch = 18.4321s	
12873/30300 (epoch 21.243), train_loss = 1.28283411, grad/param norm = 1.5578e-01, time/batch = 19.0043s	
12874/30300 (epoch 21.244), train_loss = 1.46940009, grad/param norm = 1.6515e-01, time/batch = 17.7537s	
12875/30300 (epoch 21.246), train_loss = 1.23635143, grad/param norm = 1.5711e-01, time/batch = 17.4167s	
12876/30300 (epoch 21.248), train_loss = 1.20731129, grad/param norm = 1.5437e-01, time/batch = 16.9712s	
12877/30300 (epoch 21.249), train_loss = 1.16662743, grad/param norm = 1.5649e-01, time/batch = 18.8165s	
12878/30300 (epoch 21.251), train_loss = 1.15094370, grad/param norm = 1.6747e-01, time/batch = 18.3222s	
12879/30300 (epoch 21.252), train_loss = 1.34373958, grad/param norm = 1.6892e-01, time/batch = 16.3726s	
12880/30300 (epoch 21.254), train_loss = 1.33463209, grad/param norm = 1.7630e-01, time/batch = 15.1377s	
12881/30300 (epoch 21.256), train_loss = 1.28864153, grad/param norm = 1.6063e-01, time/batch = 16.8255s	
12882/30300 (epoch 21.257), train_loss = 1.29216099, grad/param norm = 1.5435e-01, time/batch = 17.2519s	
12883/30300 (epoch 21.259), train_loss = 1.21450237, grad/param norm = 1.6039e-01, time/batch = 19.0130s	
12884/30300 (epoch 21.261), train_loss = 1.32662054, grad/param norm = 1.5212e-01, time/batch = 16.4907s	
12885/30300 (epoch 21.262), train_loss = 1.21376476, grad/param norm = 1.4854e-01, time/batch = 19.0037s	
12886/30300 (epoch 21.264), train_loss = 1.24702391, grad/param norm = 1.7283e-01, time/batch = 18.3373s	
12887/30300 (epoch 21.266), train_loss = 1.15637573, grad/param norm = 1.4876e-01, time/batch = 17.9509s	
12888/30300 (epoch 21.267), train_loss = 1.42129562, grad/param norm = 1.7471e-01, time/batch = 20.1678s	
12889/30300 (epoch 21.269), train_loss = 1.27079238, grad/param norm = 1.6493e-01, time/batch = 17.5185s	
12890/30300 (epoch 21.271), train_loss = 1.25414203, grad/param norm = 1.5806e-01, time/batch = 17.3447s	
12891/30300 (epoch 21.272), train_loss = 1.25328581, grad/param norm = 1.7395e-01, time/batch = 17.6247s	
12892/30300 (epoch 21.274), train_loss = 1.34140665, grad/param norm = 1.6450e-01, time/batch = 18.7010s	
12893/30300 (epoch 21.276), train_loss = 1.27916814, grad/param norm = 1.6641e-01, time/batch = 18.6885s	
12894/30300 (epoch 21.277), train_loss = 1.10982867, grad/param norm = 1.6603e-01, time/batch = 19.7494s	
12895/30300 (epoch 21.279), train_loss = 1.27332482, grad/param norm = 1.6053e-01, time/batch = 18.5016s	
12896/30300 (epoch 21.281), train_loss = 1.32996619, grad/param norm = 1.8090e-01, time/batch = 16.3959s	
12897/30300 (epoch 21.282), train_loss = 1.24256049, grad/param norm = 1.4770e-01, time/batch = 19.4096s	
12898/30300 (epoch 21.284), train_loss = 1.40038270, grad/param norm = 2.0023e-01, time/batch = 18.8541s	
12899/30300 (epoch 21.285), train_loss = 1.28119954, grad/param norm = 1.3824e-01, time/batch = 17.9293s	
12900/30300 (epoch 21.287), train_loss = 1.24537691, grad/param norm = 1.6364e-01, time/batch = 18.7040s	
12901/30300 (epoch 21.289), train_loss = 1.30746099, grad/param norm = 1.4944e-01, time/batch = 17.6113s	
12902/30300 (epoch 21.290), train_loss = 0.99540548, grad/param norm = 1.3990e-01, time/batch = 17.6809s	
12903/30300 (epoch 21.292), train_loss = 1.13253325, grad/param norm = 1.3870e-01, time/batch = 19.7752s	
12904/30300 (epoch 21.294), train_loss = 1.37090288, grad/param norm = 1.9161e-01, time/batch = 18.6184s	
12905/30300 (epoch 21.295), train_loss = 1.19949936, grad/param norm = 1.6314e-01, time/batch = 18.7854s	
12906/30300 (epoch 21.297), train_loss = 1.16831802, grad/param norm = 1.4099e-01, time/batch = 19.9320s	
12907/30300 (epoch 21.299), train_loss = 1.20579614, grad/param norm = 1.4662e-01, time/batch = 18.6188s	
12908/30300 (epoch 21.300), train_loss = 1.18158633, grad/param norm = 1.4594e-01, time/batch = 16.6794s	
12909/30300 (epoch 21.302), train_loss = 1.23798228, grad/param norm = 1.5105e-01, time/batch = 18.3229s	
12910/30300 (epoch 21.304), train_loss = 1.15766984, grad/param norm = 1.4331e-01, time/batch = 16.3997s	
12911/30300 (epoch 21.305), train_loss = 1.18516099, grad/param norm = 1.4000e-01, time/batch = 18.3572s	
12912/30300 (epoch 21.307), train_loss = 1.27604284, grad/param norm = 1.4318e-01, time/batch = 17.6004s	
12913/30300 (epoch 21.309), train_loss = 1.30396454, grad/param norm = 1.6126e-01, time/batch = 18.7393s	
12914/30300 (epoch 21.310), train_loss = 1.22581231, grad/param norm = 1.6197e-01, time/batch = 16.9324s	
12915/30300 (epoch 21.312), train_loss = 1.37036393, grad/param norm = 1.5827e-01, time/batch = 18.0174s	
12916/30300 (epoch 21.314), train_loss = 1.24834339, grad/param norm = 1.4913e-01, time/batch = 15.3786s	
12917/30300 (epoch 21.315), train_loss = 1.24123171, grad/param norm = 1.5690e-01, time/batch = 17.6049s	
12918/30300 (epoch 21.317), train_loss = 1.29195332, grad/param norm = 1.5220e-01, time/batch = 16.5054s	
12919/30300 (epoch 21.318), train_loss = 1.34393042, grad/param norm = 1.7430e-01, time/batch = 15.5577s	
12920/30300 (epoch 21.320), train_loss = 1.30417678, grad/param norm = 1.4655e-01, time/batch = 17.4354s	
12921/30300 (epoch 21.322), train_loss = 1.15549358, grad/param norm = 1.4470e-01, time/batch = 17.6428s	
12922/30300 (epoch 21.323), train_loss = 1.31977076, grad/param norm = 1.6467e-01, time/batch = 17.0152s	
12923/30300 (epoch 21.325), train_loss = 1.21891356, grad/param norm = 1.4775e-01, time/batch = 20.0089s	
12924/30300 (epoch 21.327), train_loss = 1.23284373, grad/param norm = 1.4573e-01, time/batch = 18.3702s	
12925/30300 (epoch 21.328), train_loss = 1.23107603, grad/param norm = 1.4002e-01, time/batch = 17.4351s	
12926/30300 (epoch 21.330), train_loss = 1.28988898, grad/param norm = 1.5400e-01, time/batch = 18.0735s	
12927/30300 (epoch 21.332), train_loss = 1.31710800, grad/param norm = 2.0434e-01, time/batch = 15.3829s	
12928/30300 (epoch 21.333), train_loss = 1.22678000, grad/param norm = 1.6640e-01, time/batch = 16.3941s	
12929/30300 (epoch 21.335), train_loss = 1.12004321, grad/param norm = 1.4850e-01, time/batch = 17.1721s	
12930/30300 (epoch 21.337), train_loss = 1.37062588, grad/param norm = 1.4945e-01, time/batch = 17.9016s	
12931/30300 (epoch 21.338), train_loss = 1.14739797, grad/param norm = 1.3529e-01, time/batch = 18.9983s	
12932/30300 (epoch 21.340), train_loss = 1.13591726, grad/param norm = 1.4399e-01, time/batch = 16.1372s	
12933/30300 (epoch 21.342), train_loss = 1.31941021, grad/param norm = 1.5589e-01, time/batch = 17.5641s	
12934/30300 (epoch 21.343), train_loss = 1.25982701, grad/param norm = 1.5654e-01, time/batch = 16.9319s	
12935/30300 (epoch 21.345), train_loss = 1.26601563, grad/param norm = 1.5130e-01, time/batch = 18.4404s	
12936/30300 (epoch 21.347), train_loss = 1.08780154, grad/param norm = 1.5380e-01, time/batch = 17.7310s	
12937/30300 (epoch 21.348), train_loss = 1.13590998, grad/param norm = 1.6284e-01, time/batch = 16.4305s	
12938/30300 (epoch 21.350), train_loss = 1.22452064, grad/param norm = 1.4963e-01, time/batch = 16.4214s	
12939/30300 (epoch 21.351), train_loss = 1.23935064, grad/param norm = 1.6608e-01, time/batch = 17.9006s	
12940/30300 (epoch 21.353), train_loss = 1.07344869, grad/param norm = 1.4158e-01, time/batch = 16.9521s	
12941/30300 (epoch 21.355), train_loss = 1.19127832, grad/param norm = 1.5321e-01, time/batch = 16.7541s	
12942/30300 (epoch 21.356), train_loss = 1.30877810, grad/param norm = 1.8237e-01, time/batch = 17.2385s	
12943/30300 (epoch 21.358), train_loss = 1.46888161, grad/param norm = 1.5017e-01, time/batch = 16.0172s	
12944/30300 (epoch 21.360), train_loss = 1.18787963, grad/param norm = 1.4992e-01, time/batch = 15.9333s	
12945/30300 (epoch 21.361), train_loss = 1.27468072, grad/param norm = 1.6846e-01, time/batch = 16.1795s	
12946/30300 (epoch 21.363), train_loss = 1.30923808, grad/param norm = 1.5294e-01, time/batch = 18.3686s	
12947/30300 (epoch 21.365), train_loss = 1.13655300, grad/param norm = 1.5745e-01, time/batch = 17.9438s	
12948/30300 (epoch 21.366), train_loss = 1.18102740, grad/param norm = 1.4468e-01, time/batch = 18.2988s	
12949/30300 (epoch 21.368), train_loss = 1.05913367, grad/param norm = 1.3715e-01, time/batch = 17.5099s	
12950/30300 (epoch 21.370), train_loss = 1.11645785, grad/param norm = 1.4306e-01, time/batch = 17.8523s	
12951/30300 (epoch 21.371), train_loss = 1.31470839, grad/param norm = 1.5920e-01, time/batch = 18.5087s	
12952/30300 (epoch 21.373), train_loss = 1.13558534, grad/param norm = 1.2924e-01, time/batch = 16.7808s	
12953/30300 (epoch 21.375), train_loss = 1.13087509, grad/param norm = 1.2761e-01, time/batch = 17.2872s	
12954/30300 (epoch 21.376), train_loss = 1.14822871, grad/param norm = 1.3095e-01, time/batch = 19.2686s	
12955/30300 (epoch 21.378), train_loss = 1.15405069, grad/param norm = 1.5569e-01, time/batch = 17.8011s	
12956/30300 (epoch 21.380), train_loss = 1.39120121, grad/param norm = 1.5634e-01, time/batch = 18.7033s	
12957/30300 (epoch 21.381), train_loss = 1.08994085, grad/param norm = 1.4702e-01, time/batch = 19.6133s	
12958/30300 (epoch 21.383), train_loss = 1.17091234, grad/param norm = 1.7055e-01, time/batch = 18.2217s	
12959/30300 (epoch 21.384), train_loss = 1.30361354, grad/param norm = 1.6137e-01, time/batch = 18.9593s	
12960/30300 (epoch 21.386), train_loss = 1.12419311, grad/param norm = 1.6478e-01, time/batch = 17.2731s	
12961/30300 (epoch 21.388), train_loss = 1.06361972, grad/param norm = 1.3780e-01, time/batch = 19.0350s	
12962/30300 (epoch 21.389), train_loss = 1.19331557, grad/param norm = 1.5173e-01, time/batch = 19.3685s	
12963/30300 (epoch 21.391), train_loss = 1.25511586, grad/param norm = 1.4495e-01, time/batch = 17.6171s	
12964/30300 (epoch 21.393), train_loss = 1.08736141, grad/param norm = 1.4482e-01, time/batch = 18.6893s	
12965/30300 (epoch 21.394), train_loss = 1.28088007, grad/param norm = 1.4726e-01, time/batch = 17.8365s	
12966/30300 (epoch 21.396), train_loss = 1.35229193, grad/param norm = 1.5509e-01, time/batch = 17.6922s	
12967/30300 (epoch 21.398), train_loss = 1.19579609, grad/param norm = 1.3549e-01, time/batch = 17.0050s	
12968/30300 (epoch 21.399), train_loss = 1.18659515, grad/param norm = 1.4944e-01, time/batch = 16.0775s	
12969/30300 (epoch 21.401), train_loss = 1.25323080, grad/param norm = 1.5477e-01, time/batch = 17.6266s	
12970/30300 (epoch 21.403), train_loss = 1.20427028, grad/param norm = 1.5678e-01, time/batch = 17.9258s	
12971/30300 (epoch 21.404), train_loss = 1.13028926, grad/param norm = 1.6584e-01, time/batch = 17.7071s	
12972/30300 (epoch 21.406), train_loss = 1.24082158, grad/param norm = 1.3867e-01, time/batch = 19.3530s	
12973/30300 (epoch 21.408), train_loss = 1.09171557, grad/param norm = 1.4240e-01, time/batch = 17.4583s	
12974/30300 (epoch 21.409), train_loss = 1.09555600, grad/param norm = 1.4575e-01, time/batch = 18.5997s	
12975/30300 (epoch 21.411), train_loss = 1.10463094, grad/param norm = 1.3589e-01, time/batch = 17.3114s	
12976/30300 (epoch 21.413), train_loss = 1.03015952, grad/param norm = 1.4462e-01, time/batch = 17.0449s	
12977/30300 (epoch 21.414), train_loss = 1.32308426, grad/param norm = 1.5384e-01, time/batch = 18.7895s	
12978/30300 (epoch 21.416), train_loss = 1.16804504, grad/param norm = 1.5203e-01, time/batch = 18.0127s	
12979/30300 (epoch 21.417), train_loss = 1.14138803, grad/param norm = 1.4306e-01, time/batch = 16.6243s	
12980/30300 (epoch 21.419), train_loss = 1.08997503, grad/param norm = 1.4032e-01, time/batch = 17.2485s	
12981/30300 (epoch 21.421), train_loss = 1.15798808, grad/param norm = 1.5820e-01, time/batch = 19.5355s	
12982/30300 (epoch 21.422), train_loss = 1.20701523, grad/param norm = 1.5103e-01, time/batch = 18.5477s	
12983/30300 (epoch 21.424), train_loss = 1.21369788, grad/param norm = 1.4625e-01, time/batch = 17.9536s	
12984/30300 (epoch 21.426), train_loss = 1.15781340, grad/param norm = 1.5518e-01, time/batch = 18.3645s	
12985/30300 (epoch 21.427), train_loss = 1.18319406, grad/param norm = 1.5627e-01, time/batch = 19.1333s	
12986/30300 (epoch 21.429), train_loss = 1.19165473, grad/param norm = 1.4066e-01, time/batch = 18.0209s	
12987/30300 (epoch 21.431), train_loss = 1.26818512, grad/param norm = 1.4113e-01, time/batch = 18.3625s	
12988/30300 (epoch 21.432), train_loss = 1.18992551, grad/param norm = 1.4141e-01, time/batch = 19.1149s	
12989/30300 (epoch 21.434), train_loss = 1.09617091, grad/param norm = 1.5326e-01, time/batch = 19.2114s	
12990/30300 (epoch 21.436), train_loss = 1.34802704, grad/param norm = 1.6011e-01, time/batch = 18.6232s	
12991/30300 (epoch 21.437), train_loss = 1.10010524, grad/param norm = 1.5400e-01, time/batch = 19.7057s	
12992/30300 (epoch 21.439), train_loss = 1.14724968, grad/param norm = 1.4111e-01, time/batch = 18.9428s	
12993/30300 (epoch 21.441), train_loss = 1.18581652, grad/param norm = 1.3813e-01, time/batch = 17.9005s	
12994/30300 (epoch 21.442), train_loss = 1.10600021, grad/param norm = 1.4805e-01, time/batch = 20.2104s	
12995/30300 (epoch 21.444), train_loss = 1.01014429, grad/param norm = 1.4768e-01, time/batch = 18.3742s	
12996/30300 (epoch 21.446), train_loss = 1.18614993, grad/param norm = 1.4400e-01, time/batch = 16.6287s	
12997/30300 (epoch 21.447), train_loss = 1.19417354, grad/param norm = 1.6531e-01, time/batch = 14.7332s	
12998/30300 (epoch 21.449), train_loss = 1.12519484, grad/param norm = 1.4551e-01, time/batch = 14.8167s	
12999/30300 (epoch 21.450), train_loss = 1.27517615, grad/param norm = 1.3960e-01, time/batch = 15.5488s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch21.45_1.8100.t7	
13000/30300 (epoch 21.452), train_loss = 1.29264809, grad/param norm = 1.4338e-01, time/batch = 18.1130s	
13001/30300 (epoch 21.454), train_loss = 1.56632396, grad/param norm = 1.6113e-01, time/batch = 19.7089s	
13002/30300 (epoch 21.455), train_loss = 1.26667550, grad/param norm = 2.0079e-01, time/batch = 17.8690s	
13003/30300 (epoch 21.457), train_loss = 1.20286060, grad/param norm = 1.4524e-01, time/batch = 18.9531s	
13004/30300 (epoch 21.459), train_loss = 1.28120515, grad/param norm = 1.7095e-01, time/batch = 19.7103s	
13005/30300 (epoch 21.460), train_loss = 1.23250573, grad/param norm = 1.4729e-01, time/batch = 17.2096s	
13006/30300 (epoch 21.462), train_loss = 1.27556294, grad/param norm = 1.4750e-01, time/batch = 18.2051s	
13007/30300 (epoch 21.464), train_loss = 1.04902272, grad/param norm = 1.6760e-01, time/batch = 19.4606s	
13008/30300 (epoch 21.465), train_loss = 1.03493103, grad/param norm = 1.3984e-01, time/batch = 17.7984s	
13009/30300 (epoch 21.467), train_loss = 1.01258743, grad/param norm = 1.3257e-01, time/batch = 19.3708s	
13010/30300 (epoch 21.469), train_loss = 1.11166771, grad/param norm = 1.3253e-01, time/batch = 18.5553s	
13011/30300 (epoch 21.470), train_loss = 1.17807973, grad/param norm = 1.4904e-01, time/batch = 18.3832s	
13012/30300 (epoch 21.472), train_loss = 1.16020786, grad/param norm = 1.3534e-01, time/batch = 18.1957s	
13013/30300 (epoch 21.474), train_loss = 1.20476672, grad/param norm = 1.7477e-01, time/batch = 16.8519s	
13014/30300 (epoch 21.475), train_loss = 1.12021772, grad/param norm = 1.3656e-01, time/batch = 19.8662s	
13015/30300 (epoch 21.477), train_loss = 1.19195159, grad/param norm = 1.5447e-01, time/batch = 18.1073s	
13016/30300 (epoch 21.479), train_loss = 1.19516076, grad/param norm = 1.4911e-01, time/batch = 19.3751s	
13017/30300 (epoch 21.480), train_loss = 1.21938357, grad/param norm = 1.3757e-01, time/batch = 19.1237s	
13018/30300 (epoch 21.482), train_loss = 1.24502833, grad/param norm = 1.3441e-01, time/batch = 17.7119s	
13019/30300 (epoch 21.483), train_loss = 1.13952219, grad/param norm = 1.4726e-01, time/batch = 19.2871s	
13020/30300 (epoch 21.485), train_loss = 1.20263199, grad/param norm = 1.4555e-01, time/batch = 20.2055s	
13021/30300 (epoch 21.487), train_loss = 1.29237799, grad/param norm = 1.5236e-01, time/batch = 27.3295s	
13022/30300 (epoch 21.488), train_loss = 1.28505926, grad/param norm = 1.3547e-01, time/batch = 22.8838s	
13023/30300 (epoch 21.490), train_loss = 1.09596326, grad/param norm = 1.4887e-01, time/batch = 19.9476s	
13024/30300 (epoch 21.492), train_loss = 1.17455853, grad/param norm = 1.5278e-01, time/batch = 18.0321s	
13025/30300 (epoch 21.493), train_loss = 1.16695109, grad/param norm = 1.4422e-01, time/batch = 17.8957s	
13026/30300 (epoch 21.495), train_loss = 1.14835753, grad/param norm = 1.3161e-01, time/batch = 19.9528s	
13027/30300 (epoch 21.497), train_loss = 1.21813225, grad/param norm = 1.4450e-01, time/batch = 16.4943s	
13028/30300 (epoch 21.498), train_loss = 1.24506004, grad/param norm = 1.5212e-01, time/batch = 16.5901s	
13029/30300 (epoch 21.500), train_loss = 1.21928574, grad/param norm = 1.6896e-01, time/batch = 18.7956s	
13030/30300 (epoch 21.502), train_loss = 1.21381913, grad/param norm = 1.5929e-01, time/batch = 18.2165s	
13031/30300 (epoch 21.503), train_loss = 1.28796231, grad/param norm = 1.4458e-01, time/batch = 19.2807s	
13032/30300 (epoch 21.505), train_loss = 1.14585918, grad/param norm = 1.4469e-01, time/batch = 19.3865s	
13033/30300 (epoch 21.507), train_loss = 1.13968343, grad/param norm = 1.6776e-01, time/batch = 15.0543s	
13034/30300 (epoch 21.508), train_loss = 1.16951180, grad/param norm = 1.6650e-01, time/batch = 15.0494s	
13035/30300 (epoch 21.510), train_loss = 1.28456711, grad/param norm = 1.6241e-01, time/batch = 14.7337s	
13036/30300 (epoch 21.512), train_loss = 1.14121571, grad/param norm = 1.3973e-01, time/batch = 19.0679s	
13037/30300 (epoch 21.513), train_loss = 1.21472263, grad/param norm = 1.3513e-01, time/batch = 17.1854s	
13038/30300 (epoch 21.515), train_loss = 1.19093506, grad/param norm = 1.3717e-01, time/batch = 18.6234s	
13039/30300 (epoch 21.517), train_loss = 1.02225816, grad/param norm = 1.3411e-01, time/batch = 19.6093s	
13040/30300 (epoch 21.518), train_loss = 1.26160408, grad/param norm = 1.5051e-01, time/batch = 17.5336s	
13041/30300 (epoch 21.520), train_loss = 1.28260058, grad/param norm = 1.6798e-01, time/batch = 17.6178s	
13042/30300 (epoch 21.521), train_loss = 1.10506853, grad/param norm = 1.5255e-01, time/batch = 19.4282s	
13043/30300 (epoch 21.523), train_loss = 1.35898111, grad/param norm = 1.8227e-01, time/batch = 19.4521s	
13044/30300 (epoch 21.525), train_loss = 1.13003550, grad/param norm = 1.5767e-01, time/batch = 18.5297s	
13045/30300 (epoch 21.526), train_loss = 1.18336172, grad/param norm = 1.7519e-01, time/batch = 17.1724s	
13046/30300 (epoch 21.528), train_loss = 1.09167151, grad/param norm = 1.4851e-01, time/batch = 18.3796s	
13047/30300 (epoch 21.530), train_loss = 1.06237937, grad/param norm = 1.4373e-01, time/batch = 18.2023s	
13048/30300 (epoch 21.531), train_loss = 1.24639464, grad/param norm = 1.6051e-01, time/batch = 18.2031s	
13049/30300 (epoch 21.533), train_loss = 1.20698765, grad/param norm = 1.4249e-01, time/batch = 20.0389s	
13050/30300 (epoch 21.535), train_loss = 1.10240504, grad/param norm = 1.2823e-01, time/batch = 18.2076s	
13051/30300 (epoch 21.536), train_loss = 1.21630416, grad/param norm = 1.5407e-01, time/batch = 19.7853s	
13052/30300 (epoch 21.538), train_loss = 1.07994388, grad/param norm = 1.6052e-01, time/batch = 19.6022s	
13053/30300 (epoch 21.540), train_loss = 1.09458780, grad/param norm = 1.5293e-01, time/batch = 17.5986s	
13054/30300 (epoch 21.541), train_loss = 1.19465391, grad/param norm = 1.5883e-01, time/batch = 19.1924s	
13055/30300 (epoch 21.543), train_loss = 1.17724377, grad/param norm = 1.4987e-01, time/batch = 19.1980s	
13056/30300 (epoch 21.545), train_loss = 1.18169186, grad/param norm = 1.7984e-01, time/batch = 20.3611s	
13057/30300 (epoch 21.546), train_loss = 1.42900780, grad/param norm = 1.6443e-01, time/batch = 19.5232s	
13058/30300 (epoch 21.548), train_loss = 1.13671476, grad/param norm = 1.3967e-01, time/batch = 17.8549s	
13059/30300 (epoch 21.550), train_loss = 1.27656138, grad/param norm = 1.8792e-01, time/batch = 18.2960s	
13060/30300 (epoch 21.551), train_loss = 1.13822446, grad/param norm = 1.4654e-01, time/batch = 19.8641s	
13061/30300 (epoch 21.553), train_loss = 1.16109040, grad/param norm = 1.4629e-01, time/batch = 18.9547s	
13062/30300 (epoch 21.554), train_loss = 1.21392048, grad/param norm = 1.6448e-01, time/batch = 19.1170s	
13063/30300 (epoch 21.556), train_loss = 1.25173405, grad/param norm = 1.5059e-01, time/batch = 19.0303s	
13064/30300 (epoch 21.558), train_loss = 1.31775598, grad/param norm = 1.6039e-01, time/batch = 19.7833s	
13065/30300 (epoch 21.559), train_loss = 1.26631630, grad/param norm = 1.6892e-01, time/batch = 19.4466s	
13066/30300 (epoch 21.561), train_loss = 1.02765871, grad/param norm = 1.4687e-01, time/batch = 17.9325s	
13067/30300 (epoch 21.563), train_loss = 1.10404713, grad/param norm = 1.4829e-01, time/batch = 18.9432s	
13068/30300 (epoch 21.564), train_loss = 1.12853045, grad/param norm = 1.4012e-01, time/batch = 19.5183s	
13069/30300 (epoch 21.566), train_loss = 1.20580931, grad/param norm = 1.4508e-01, time/batch = 9.9041s	
13070/30300 (epoch 21.568), train_loss = 1.00683980, grad/param norm = 1.4331e-01, time/batch = 0.7256s	
13071/30300 (epoch 21.569), train_loss = 1.19791865, grad/param norm = 1.4151e-01, time/batch = 0.7251s	
13072/30300 (epoch 21.571), train_loss = 1.23930237, grad/param norm = 1.6176e-01, time/batch = 0.7204s	
13073/30300 (epoch 21.573), train_loss = 1.25546287, grad/param norm = 1.5823e-01, time/batch = 0.7197s	
13074/30300 (epoch 21.574), train_loss = 1.27800358, grad/param norm = 1.4907e-01, time/batch = 0.7170s	
13075/30300 (epoch 21.576), train_loss = 1.18802660, grad/param norm = 1.3837e-01, time/batch = 0.7152s	
13076/30300 (epoch 21.578), train_loss = 1.06091634, grad/param norm = 1.4104e-01, time/batch = 0.7201s	
13077/30300 (epoch 21.579), train_loss = 1.21207065, grad/param norm = 1.5467e-01, time/batch = 0.7111s	
13078/30300 (epoch 21.581), train_loss = 1.30918756, grad/param norm = 1.7908e-01, time/batch = 0.7191s	
13079/30300 (epoch 21.583), train_loss = 1.37008742, grad/param norm = 1.6887e-01, time/batch = 0.7155s	
13080/30300 (epoch 21.584), train_loss = 1.29604589, grad/param norm = 1.5502e-01, time/batch = 0.7187s	
13081/30300 (epoch 21.586), train_loss = 1.18457477, grad/param norm = 1.4826e-01, time/batch = 0.7234s	
13082/30300 (epoch 21.587), train_loss = 1.19422375, grad/param norm = 1.5219e-01, time/batch = 0.7183s	
13083/30300 (epoch 21.589), train_loss = 1.08376999, grad/param norm = 1.3967e-01, time/batch = 0.7163s	
13084/30300 (epoch 21.591), train_loss = 1.24802604, grad/param norm = 1.4295e-01, time/batch = 0.7183s	
13085/30300 (epoch 21.592), train_loss = 1.20268259, grad/param norm = 1.3760e-01, time/batch = 0.7247s	
13086/30300 (epoch 21.594), train_loss = 1.21697496, grad/param norm = 1.4981e-01, time/batch = 0.7206s	
13087/30300 (epoch 21.596), train_loss = 1.12595979, grad/param norm = 1.4102e-01, time/batch = 0.7188s	
13088/30300 (epoch 21.597), train_loss = 1.14792010, grad/param norm = 1.6785e-01, time/batch = 0.7182s	
13089/30300 (epoch 21.599), train_loss = 1.01992321, grad/param norm = 1.4151e-01, time/batch = 0.7193s	
13090/30300 (epoch 21.601), train_loss = 1.22381056, grad/param norm = 1.5217e-01, time/batch = 0.9443s	
13091/30300 (epoch 21.602), train_loss = 1.19501820, grad/param norm = 1.5163e-01, time/batch = 1.0563s	
13092/30300 (epoch 21.604), train_loss = 1.10051957, grad/param norm = 1.3460e-01, time/batch = 1.0511s	
13093/30300 (epoch 21.606), train_loss = 1.15639929, grad/param norm = 2.0358e-01, time/batch = 1.0451s	
13094/30300 (epoch 21.607), train_loss = 1.28537723, grad/param norm = 1.7526e-01, time/batch = 1.0202s	
13095/30300 (epoch 21.609), train_loss = 1.39890870, grad/param norm = 1.7503e-01, time/batch = 1.8395s	
13096/30300 (epoch 21.611), train_loss = 1.12659887, grad/param norm = 1.3403e-01, time/batch = 1.8897s	
13097/30300 (epoch 21.612), train_loss = 1.09722788, grad/param norm = 1.5289e-01, time/batch = 7.5030s	
13098/30300 (epoch 21.614), train_loss = 1.15526589, grad/param norm = 1.4390e-01, time/batch = 19.6962s	
13099/30300 (epoch 21.616), train_loss = 1.25426540, grad/param norm = 1.6936e-01, time/batch = 17.1112s	
13100/30300 (epoch 21.617), train_loss = 1.21069530, grad/param norm = 1.5525e-01, time/batch = 17.8715s	
13101/30300 (epoch 21.619), train_loss = 1.03168516, grad/param norm = 1.5127e-01, time/batch = 16.5189s	
13102/30300 (epoch 21.620), train_loss = 1.20989005, grad/param norm = 1.5819e-01, time/batch = 18.5987s	
13103/30300 (epoch 21.622), train_loss = 1.19111204, grad/param norm = 1.6563e-01, time/batch = 18.1925s	
13104/30300 (epoch 21.624), train_loss = 1.13354830, grad/param norm = 1.4777e-01, time/batch = 18.9503s	
13105/30300 (epoch 21.625), train_loss = 1.15135239, grad/param norm = 1.6469e-01, time/batch = 18.5253s	
13106/30300 (epoch 21.627), train_loss = 1.30997708, grad/param norm = 1.7300e-01, time/batch = 18.2889s	
13107/30300 (epoch 21.629), train_loss = 1.30902825, grad/param norm = 1.4790e-01, time/batch = 19.3555s	
13108/30300 (epoch 21.630), train_loss = 1.21195708, grad/param norm = 1.4782e-01, time/batch = 16.5210s	
13109/30300 (epoch 21.632), train_loss = 1.28347951, grad/param norm = 1.6536e-01, time/batch = 17.6169s	
13110/30300 (epoch 21.634), train_loss = 1.09560976, grad/param norm = 1.4010e-01, time/batch = 19.3873s	
13111/30300 (epoch 21.635), train_loss = 1.23378901, grad/param norm = 1.5804e-01, time/batch = 19.8761s	
13112/30300 (epoch 21.637), train_loss = 1.26131635, grad/param norm = 1.6896e-01, time/batch = 17.5294s	
13113/30300 (epoch 21.639), train_loss = 1.13606959, grad/param norm = 1.4380e-01, time/batch = 18.4458s	
13114/30300 (epoch 21.640), train_loss = 1.34115144, grad/param norm = 1.6939e-01, time/batch = 19.6105s	
13115/30300 (epoch 21.642), train_loss = 1.16859737, grad/param norm = 1.3172e-01, time/batch = 18.2098s	
13116/30300 (epoch 21.644), train_loss = 1.24296431, grad/param norm = 1.4785e-01, time/batch = 17.7825s	
13117/30300 (epoch 21.645), train_loss = 1.08743536, grad/param norm = 1.3558e-01, time/batch = 19.4464s	
13118/30300 (epoch 21.647), train_loss = 1.18761674, grad/param norm = 1.3887e-01, time/batch = 18.6015s	
13119/30300 (epoch 21.649), train_loss = 1.14763336, grad/param norm = 1.4833e-01, time/batch = 18.3723s	
13120/30300 (epoch 21.650), train_loss = 1.18469332, grad/param norm = 1.4145e-01, time/batch = 18.0392s	
13121/30300 (epoch 21.652), train_loss = 1.15387561, grad/param norm = 1.3949e-01, time/batch = 18.7165s	
13122/30300 (epoch 21.653), train_loss = 1.37434403, grad/param norm = 1.5761e-01, time/batch = 18.5506s	
13123/30300 (epoch 21.655), train_loss = 1.12577908, grad/param norm = 1.5147e-01, time/batch = 18.6437s	
13124/30300 (epoch 21.657), train_loss = 1.12848138, grad/param norm = 1.4520e-01, time/batch = 20.1395s	
13125/30300 (epoch 21.658), train_loss = 1.11467988, grad/param norm = 1.4363e-01, time/batch = 18.2885s	
13126/30300 (epoch 21.660), train_loss = 1.21272746, grad/param norm = 1.5370e-01, time/batch = 20.4608s	
13127/30300 (epoch 21.662), train_loss = 1.21779368, grad/param norm = 1.6549e-01, time/batch = 19.4559s	
13128/30300 (epoch 21.663), train_loss = 1.21741686, grad/param norm = 1.5628e-01, time/batch = 17.9357s	
13129/30300 (epoch 21.665), train_loss = 1.13886935, grad/param norm = 1.6348e-01, time/batch = 18.2142s	
13130/30300 (epoch 21.667), train_loss = 1.29570814, grad/param norm = 1.5119e-01, time/batch = 17.3837s	
13131/30300 (epoch 21.668), train_loss = 1.29785857, grad/param norm = 1.4957e-01, time/batch = 18.3017s	
13132/30300 (epoch 21.670), train_loss = 1.29810719, grad/param norm = 1.5828e-01, time/batch = 19.6988s	
13133/30300 (epoch 21.672), train_loss = 1.24419786, grad/param norm = 1.5790e-01, time/batch = 19.0507s	
13134/30300 (epoch 21.673), train_loss = 1.25716845, grad/param norm = 1.5847e-01, time/batch = 17.9480s	
13135/30300 (epoch 21.675), train_loss = 1.15732952, grad/param norm = 1.4733e-01, time/batch = 19.4578s	
13136/30300 (epoch 21.677), train_loss = 1.13547980, grad/param norm = 1.4190e-01, time/batch = 17.2715s	
13137/30300 (epoch 21.678), train_loss = 1.13889321, grad/param norm = 1.4460e-01, time/batch = 19.2022s	
13138/30300 (epoch 21.680), train_loss = 0.99824639, grad/param norm = 1.3537e-01, time/batch = 19.2925s	
13139/30300 (epoch 21.682), train_loss = 1.19934407, grad/param norm = 1.5510e-01, time/batch = 19.6967s	
13140/30300 (epoch 21.683), train_loss = 1.28673904, grad/param norm = 1.3538e-01, time/batch = 20.1198s	
13141/30300 (epoch 21.685), train_loss = 1.28410093, grad/param norm = 1.7031e-01, time/batch = 18.6972s	
13142/30300 (epoch 21.686), train_loss = 1.16946684, grad/param norm = 1.3533e-01, time/batch = 20.1285s	
13143/30300 (epoch 21.688), train_loss = 1.18898662, grad/param norm = 1.4285e-01, time/batch = 19.9530s	
13144/30300 (epoch 21.690), train_loss = 1.13673350, grad/param norm = 1.5019e-01, time/batch = 17.9402s	
13145/30300 (epoch 21.691), train_loss = 1.24384427, grad/param norm = 1.4089e-01, time/batch = 20.2754s	
13146/30300 (epoch 21.693), train_loss = 1.53581530, grad/param norm = 1.7246e-01, time/batch = 20.6192s	
13147/30300 (epoch 21.695), train_loss = 1.33126625, grad/param norm = 1.8347e-01, time/batch = 18.5269s	
13148/30300 (epoch 21.696), train_loss = 1.26696985, grad/param norm = 1.8026e-01, time/batch = 18.7853s	
13149/30300 (epoch 21.698), train_loss = 1.14904004, grad/param norm = 1.4317e-01, time/batch = 19.4612s	
13150/30300 (epoch 21.700), train_loss = 1.14614082, grad/param norm = 1.5401e-01, time/batch = 17.4581s	
13151/30300 (epoch 21.701), train_loss = 1.02457163, grad/param norm = 1.3490e-01, time/batch = 18.8597s	
13152/30300 (epoch 21.703), train_loss = 1.19545811, grad/param norm = 1.3797e-01, time/batch = 18.5373s	
13153/30300 (epoch 21.705), train_loss = 1.15467159, grad/param norm = 1.4667e-01, time/batch = 19.0386s	
13154/30300 (epoch 21.706), train_loss = 1.26289318, grad/param norm = 1.5302e-01, time/batch = 19.7084s	
13155/30300 (epoch 21.708), train_loss = 1.19035552, grad/param norm = 1.4875e-01, time/batch = 19.5537s	
13156/30300 (epoch 21.710), train_loss = 1.19203539, grad/param norm = 1.6378e-01, time/batch = 17.8674s	
13157/30300 (epoch 21.711), train_loss = 1.10575570, grad/param norm = 1.4076e-01, time/batch = 18.8806s	
13158/30300 (epoch 21.713), train_loss = 1.10811073, grad/param norm = 1.3834e-01, time/batch = 20.1119s	
13159/30300 (epoch 21.715), train_loss = 1.14080405, grad/param norm = 1.4452e-01, time/batch = 19.0296s	
13160/30300 (epoch 21.716), train_loss = 1.28701321, grad/param norm = 1.4423e-01, time/batch = 18.3828s	
13161/30300 (epoch 21.718), train_loss = 1.35292909, grad/param norm = 1.6126e-01, time/batch = 19.8833s	
13162/30300 (epoch 21.719), train_loss = 1.15351212, grad/param norm = 1.6784e-01, time/batch = 18.8069s	
13163/30300 (epoch 21.721), train_loss = 1.22019141, grad/param norm = 1.6894e-01, time/batch = 18.7282s	
13164/30300 (epoch 21.723), train_loss = 1.14303767, grad/param norm = 1.5398e-01, time/batch = 19.6938s	
13165/30300 (epoch 21.724), train_loss = 1.23483553, grad/param norm = 1.6803e-01, time/batch = 19.0436s	
13166/30300 (epoch 21.726), train_loss = 1.58656131, grad/param norm = 1.9356e-01, time/batch = 17.8593s	
13167/30300 (epoch 21.728), train_loss = 1.26152175, grad/param norm = 1.5739e-01, time/batch = 18.9541s	
13168/30300 (epoch 21.729), train_loss = 1.16332611, grad/param norm = 1.6575e-01, time/batch = 19.8807s	
13169/30300 (epoch 21.731), train_loss = 1.25808338, grad/param norm = 1.6368e-01, time/batch = 17.7812s	
13170/30300 (epoch 21.733), train_loss = 1.19093553, grad/param norm = 1.4441e-01, time/batch = 19.8808s	
13171/30300 (epoch 21.734), train_loss = 1.26706077, grad/param norm = 1.4210e-01, time/batch = 20.1182s	
13172/30300 (epoch 21.736), train_loss = 1.16864670, grad/param norm = 1.4274e-01, time/batch = 16.7723s	
13173/30300 (epoch 21.738), train_loss = 1.09809184, grad/param norm = 1.2747e-01, time/batch = 19.6301s	
13174/30300 (epoch 21.739), train_loss = 1.25152149, grad/param norm = 1.4397e-01, time/batch = 17.7913s	
13175/30300 (epoch 21.741), train_loss = 1.33652041, grad/param norm = 1.5037e-01, time/batch = 18.0251s	
13176/30300 (epoch 21.743), train_loss = 1.18014206, grad/param norm = 1.5889e-01, time/batch = 19.3697s	
13177/30300 (epoch 21.744), train_loss = 1.23914695, grad/param norm = 1.5841e-01, time/batch = 19.4752s	
13178/30300 (epoch 21.746), train_loss = 1.10988971, grad/param norm = 1.3940e-01, time/batch = 18.4518s	
13179/30300 (epoch 21.748), train_loss = 1.20106548, grad/param norm = 1.7632e-01, time/batch = 19.6371s	
13180/30300 (epoch 21.749), train_loss = 1.24442326, grad/param norm = 1.5433e-01, time/batch = 19.4617s	
13181/30300 (epoch 21.751), train_loss = 1.18402678, grad/param norm = 1.3854e-01, time/batch = 18.1117s	
13182/30300 (epoch 21.752), train_loss = 1.17580050, grad/param norm = 1.5168e-01, time/batch = 17.8735s	
13183/30300 (epoch 21.754), train_loss = 1.10313993, grad/param norm = 1.4029e-01, time/batch = 19.1979s	
13184/30300 (epoch 21.756), train_loss = 1.17418779, grad/param norm = 1.4976e-01, time/batch = 19.9454s	
13185/30300 (epoch 21.757), train_loss = 1.22323286, grad/param norm = 1.6144e-01, time/batch = 18.6212s	
13186/30300 (epoch 21.759), train_loss = 1.22721594, grad/param norm = 1.4060e-01, time/batch = 19.3821s	
13187/30300 (epoch 21.761), train_loss = 1.04105390, grad/param norm = 1.3453e-01, time/batch = 19.6391s	
13188/30300 (epoch 21.762), train_loss = 1.09087201, grad/param norm = 1.4326e-01, time/batch = 18.7907s	
13189/30300 (epoch 21.764), train_loss = 1.16866776, grad/param norm = 1.4970e-01, time/batch = 18.0525s	
13190/30300 (epoch 21.766), train_loss = 1.26213846, grad/param norm = 1.5828e-01, time/batch = 19.4561s	
13191/30300 (epoch 21.767), train_loss = 1.27756233, grad/param norm = 1.8882e-01, time/batch = 18.2852s	
13192/30300 (epoch 21.769), train_loss = 1.24388937, grad/param norm = 1.4781e-01, time/batch = 18.6110s	
13193/30300 (epoch 21.771), train_loss = 1.16024996, grad/param norm = 1.7866e-01, time/batch = 19.4596s	
13194/30300 (epoch 21.772), train_loss = 1.26578266, grad/param norm = 1.5862e-01, time/batch = 18.0517s	
13195/30300 (epoch 21.774), train_loss = 1.35010235, grad/param norm = 1.4853e-01, time/batch = 19.3069s	
13196/30300 (epoch 21.776), train_loss = 1.22350398, grad/param norm = 1.6513e-01, time/batch = 18.1162s	
13197/30300 (epoch 21.777), train_loss = 1.29027011, grad/param norm = 1.5233e-01, time/batch = 18.4454s	
13198/30300 (epoch 21.779), train_loss = 1.36931668, grad/param norm = 1.8118e-01, time/batch = 17.7842s	
13199/30300 (epoch 21.781), train_loss = 1.20997163, grad/param norm = 1.7847e-01, time/batch = 18.7794s	
13200/30300 (epoch 21.782), train_loss = 1.14256393, grad/param norm = 1.4401e-01, time/batch = 18.6269s	
13201/30300 (epoch 21.784), train_loss = 1.13773078, grad/param norm = 1.5144e-01, time/batch = 19.0269s	
13202/30300 (epoch 21.785), train_loss = 1.35408080, grad/param norm = 1.7367e-01, time/batch = 19.8778s	
13203/30300 (epoch 21.787), train_loss = 1.03799506, grad/param norm = 1.4623e-01, time/batch = 18.6987s	
13204/30300 (epoch 21.789), train_loss = 1.43694738, grad/param norm = 1.6181e-01, time/batch = 18.9439s	
13205/30300 (epoch 21.790), train_loss = 1.27769577, grad/param norm = 1.6425e-01, time/batch = 19.7074s	
13206/30300 (epoch 21.792), train_loss = 1.03004712, grad/param norm = 1.4465e-01, time/batch = 19.7053s	
13207/30300 (epoch 21.794), train_loss = 1.19373306, grad/param norm = 1.5667e-01, time/batch = 17.4869s	
13208/30300 (epoch 21.795), train_loss = 1.12063641, grad/param norm = 1.3926e-01, time/batch = 18.2669s	
13209/30300 (epoch 21.797), train_loss = 1.35184723, grad/param norm = 1.6898e-01, time/batch = 20.3566s	
13210/30300 (epoch 21.799), train_loss = 1.26004428, grad/param norm = 1.6035e-01, time/batch = 17.4513s	
13211/30300 (epoch 21.800), train_loss = 1.27934128, grad/param norm = 1.5801e-01, time/batch = 15.5295s	
13212/30300 (epoch 21.802), train_loss = 1.44361201, grad/param norm = 1.7153e-01, time/batch = 19.6034s	
13213/30300 (epoch 21.804), train_loss = 1.30743299, grad/param norm = 1.6237e-01, time/batch = 17.7086s	
13214/30300 (epoch 21.805), train_loss = 1.36486300, grad/param norm = 1.6658e-01, time/batch = 19.0392s	
13215/30300 (epoch 21.807), train_loss = 1.18028128, grad/param norm = 1.5771e-01, time/batch = 19.1285s	
13216/30300 (epoch 21.809), train_loss = 1.30589924, grad/param norm = 1.7646e-01, time/batch = 19.1079s	
13217/30300 (epoch 21.810), train_loss = 1.30586465, grad/param norm = 1.7711e-01, time/batch = 19.7073s	
13218/30300 (epoch 21.812), train_loss = 1.13199642, grad/param norm = 1.5673e-01, time/batch = 19.8791s	
13219/30300 (epoch 21.814), train_loss = 1.21803327, grad/param norm = 1.7136e-01, time/batch = 17.8469s	
13220/30300 (epoch 21.815), train_loss = 1.23786262, grad/param norm = 1.6011e-01, time/batch = 18.6985s	
13221/30300 (epoch 21.817), train_loss = 1.31346568, grad/param norm = 1.6149e-01, time/batch = 17.3019s	
13222/30300 (epoch 21.818), train_loss = 1.27266023, grad/param norm = 1.5835e-01, time/batch = 19.6393s	
13223/30300 (epoch 21.820), train_loss = 1.38614432, grad/param norm = 1.6674e-01, time/batch = 17.8664s	
13224/30300 (epoch 21.822), train_loss = 1.38789770, grad/param norm = 1.9160e-01, time/batch = 18.8014s	
13225/30300 (epoch 21.823), train_loss = 1.40811855, grad/param norm = 1.6955e-01, time/batch = 20.2675s	
13226/30300 (epoch 21.825), train_loss = 1.32827308, grad/param norm = 1.6698e-01, time/batch = 18.2790s	
13227/30300 (epoch 21.827), train_loss = 1.05843621, grad/param norm = 1.5997e-01, time/batch = 19.9639s	
13228/30300 (epoch 21.828), train_loss = 1.29164205, grad/param norm = 1.5215e-01, time/batch = 19.3907s	
13229/30300 (epoch 21.830), train_loss = 1.26040529, grad/param norm = 1.5785e-01, time/batch = 17.7142s	
13230/30300 (epoch 21.832), train_loss = 1.13586434, grad/param norm = 1.5095e-01, time/batch = 19.5342s	
13231/30300 (epoch 21.833), train_loss = 1.28047072, grad/param norm = 1.6559e-01, time/batch = 17.4518s	
13232/30300 (epoch 21.835), train_loss = 1.13261469, grad/param norm = 1.4719e-01, time/batch = 18.2858s	
13233/30300 (epoch 21.837), train_loss = 1.07958678, grad/param norm = 1.3961e-01, time/batch = 20.0351s	
13234/30300 (epoch 21.838), train_loss = 1.09676375, grad/param norm = 1.3409e-01, time/batch = 20.1154s	
13235/30300 (epoch 21.840), train_loss = 1.28836687, grad/param norm = 1.3554e-01, time/batch = 18.6367s	
13236/30300 (epoch 21.842), train_loss = 1.12308165, grad/param norm = 1.3058e-01, time/batch = 19.0356s	
13237/30300 (epoch 21.843), train_loss = 1.24899138, grad/param norm = 1.4774e-01, time/batch = 19.9678s	
13238/30300 (epoch 21.845), train_loss = 1.25306430, grad/param norm = 1.4771e-01, time/batch = 20.3394s	
13239/30300 (epoch 21.847), train_loss = 1.24375291, grad/param norm = 1.4915e-01, time/batch = 31.5410s	
13240/30300 (epoch 21.848), train_loss = 1.30946583, grad/param norm = 1.6057e-01, time/batch = 18.6305s	
13241/30300 (epoch 21.850), train_loss = 1.21966162, grad/param norm = 1.4425e-01, time/batch = 17.1148s	
13242/30300 (epoch 21.851), train_loss = 1.28017282, grad/param norm = 2.2641e-01, time/batch = 17.6236s	
13243/30300 (epoch 21.853), train_loss = 1.18115536, grad/param norm = 1.4400e-01, time/batch = 17.2106s	
13244/30300 (epoch 21.855), train_loss = 1.14897215, grad/param norm = 1.3016e-01, time/batch = 17.2743s	
13245/30300 (epoch 21.856), train_loss = 1.23461565, grad/param norm = 1.5333e-01, time/batch = 18.2714s	
13246/30300 (epoch 21.858), train_loss = 1.15579215, grad/param norm = 1.3788e-01, time/batch = 17.0138s	
13247/30300 (epoch 21.860), train_loss = 1.12425120, grad/param norm = 1.4414e-01, time/batch = 17.3751s	
13248/30300 (epoch 21.861), train_loss = 1.38512310, grad/param norm = 1.5456e-01, time/batch = 17.0923s	
13249/30300 (epoch 21.863), train_loss = 1.22262745, grad/param norm = 1.3904e-01, time/batch = 17.9549s	
13250/30300 (epoch 21.865), train_loss = 1.30214989, grad/param norm = 1.7540e-01, time/batch = 19.7040s	
13251/30300 (epoch 21.866), train_loss = 1.29003905, grad/param norm = 1.5336e-01, time/batch = 17.8597s	
13252/30300 (epoch 21.868), train_loss = 1.21381319, grad/param norm = 1.5100e-01, time/batch = 19.3738s	
13253/30300 (epoch 21.870), train_loss = 1.13153259, grad/param norm = 1.4572e-01, time/batch = 19.3686s	
13254/30300 (epoch 21.871), train_loss = 1.17641364, grad/param norm = 1.4176e-01, time/batch = 17.9231s	
13255/30300 (epoch 21.873), train_loss = 1.21097140, grad/param norm = 1.3585e-01, time/batch = 18.2841s	
13256/30300 (epoch 21.875), train_loss = 1.13776340, grad/param norm = 1.3832e-01, time/batch = 18.5515s	
13257/30300 (epoch 21.876), train_loss = 1.10243550, grad/param norm = 1.6559e-01, time/batch = 19.3733s	
13258/30300 (epoch 21.878), train_loss = 1.04577974, grad/param norm = 1.4239e-01, time/batch = 18.5390s	
13259/30300 (epoch 21.880), train_loss = 1.10989337, grad/param norm = 1.3625e-01, time/batch = 18.7847s	
13260/30300 (epoch 21.881), train_loss = 1.37980333, grad/param norm = 1.6998e-01, time/batch = 19.5485s	
13261/30300 (epoch 21.883), train_loss = 1.26343562, grad/param norm = 1.4886e-01, time/batch = 18.6996s	
13262/30300 (epoch 21.884), train_loss = 1.12636480, grad/param norm = 1.2925e-01, time/batch = 19.1177s	
13263/30300 (epoch 21.886), train_loss = 1.24735398, grad/param norm = 1.4213e-01, time/batch = 17.8730s	
13264/30300 (epoch 21.888), train_loss = 1.21756090, grad/param norm = 1.5673e-01, time/batch = 16.2543s	
13265/30300 (epoch 21.889), train_loss = 1.24541246, grad/param norm = 1.4984e-01, time/batch = 18.2846s	
13266/30300 (epoch 21.891), train_loss = 1.23021829, grad/param norm = 1.5556e-01, time/batch = 18.9531s	
13267/30300 (epoch 21.893), train_loss = 1.46022468, grad/param norm = 1.7504e-01, time/batch = 17.4585s	
13268/30300 (epoch 21.894), train_loss = 1.30570480, grad/param norm = 1.5885e-01, time/batch = 19.5564s	
13269/30300 (epoch 21.896), train_loss = 1.05178169, grad/param norm = 1.3915e-01, time/batch = 18.7202s	
13270/30300 (epoch 21.898), train_loss = 1.00943887, grad/param norm = 1.3616e-01, time/batch = 18.4677s	
13271/30300 (epoch 21.899), train_loss = 1.13231636, grad/param norm = 1.5885e-01, time/batch = 18.8521s	
13272/30300 (epoch 21.901), train_loss = 1.18192942, grad/param norm = 1.5931e-01, time/batch = 19.6265s	
13273/30300 (epoch 21.903), train_loss = 1.24437166, grad/param norm = 1.5645e-01, time/batch = 19.2096s	
13274/30300 (epoch 21.904), train_loss = 1.18561037, grad/param norm = 1.4927e-01, time/batch = 15.7400s	
13275/30300 (epoch 21.906), train_loss = 1.30978560, grad/param norm = 1.5677e-01, time/batch = 18.5249s	
13276/30300 (epoch 21.908), train_loss = 1.15780078, grad/param norm = 1.4393e-01, time/batch = 20.2808s	
13277/30300 (epoch 21.909), train_loss = 1.11213625, grad/param norm = 1.5492e-01, time/batch = 17.5906s	
13278/30300 (epoch 21.911), train_loss = 1.20627018, grad/param norm = 1.4110e-01, time/batch = 18.5441s	
13279/30300 (epoch 21.913), train_loss = 1.19617133, grad/param norm = 1.5387e-01, time/batch = 20.2842s	
13280/30300 (epoch 21.914), train_loss = 1.16085279, grad/param norm = 1.4859e-01, time/batch = 18.5328s	
13281/30300 (epoch 21.916), train_loss = 1.22173723, grad/param norm = 1.4052e-01, time/batch = 18.6152s	
13282/30300 (epoch 21.917), train_loss = 1.14623595, grad/param norm = 1.4836e-01, time/batch = 20.2047s	
13283/30300 (epoch 21.919), train_loss = 1.16748173, grad/param norm = 1.6130e-01, time/batch = 18.6089s	
13284/30300 (epoch 21.921), train_loss = 1.21429217, grad/param norm = 1.4649e-01, time/batch = 18.9534s	
13285/30300 (epoch 21.922), train_loss = 1.29929832, grad/param norm = 1.6662e-01, time/batch = 19.4439s	
13286/30300 (epoch 21.924), train_loss = 1.22222319, grad/param norm = 1.6098e-01, time/batch = 18.4480s	
13287/30300 (epoch 21.926), train_loss = 1.23887390, grad/param norm = 1.5224e-01, time/batch = 18.0370s	
13288/30300 (epoch 21.927), train_loss = 1.21273651, grad/param norm = 1.5386e-01, time/batch = 18.1832s	
13289/30300 (epoch 21.929), train_loss = 1.15437823, grad/param norm = 1.5915e-01, time/batch = 15.4526s	
13290/30300 (epoch 21.931), train_loss = 1.33729182, grad/param norm = 1.7942e-01, time/batch = 16.7575s	
13291/30300 (epoch 21.932), train_loss = 1.15252587, grad/param norm = 1.5412e-01, time/batch = 15.5050s	
13292/30300 (epoch 21.934), train_loss = 1.23428794, grad/param norm = 1.5238e-01, time/batch = 15.7791s	
13293/30300 (epoch 21.936), train_loss = 1.15853719, grad/param norm = 1.4098e-01, time/batch = 18.5231s	
13294/30300 (epoch 21.937), train_loss = 1.13768991, grad/param norm = 1.4905e-01, time/batch = 19.7071s	
13295/30300 (epoch 21.939), train_loss = 1.33739806, grad/param norm = 1.6545e-01, time/batch = 18.6078s	
13296/30300 (epoch 21.941), train_loss = 1.16658405, grad/param norm = 1.4894e-01, time/batch = 17.7998s	
13297/30300 (epoch 21.942), train_loss = 1.19399340, grad/param norm = 1.6526e-01, time/batch = 19.2878s	
13298/30300 (epoch 21.944), train_loss = 1.09888678, grad/param norm = 1.4621e-01, time/batch = 19.2212s	
13299/30300 (epoch 21.946), train_loss = 1.32415837, grad/param norm = 1.8798e-01, time/batch = 19.7069s	
13300/30300 (epoch 21.947), train_loss = 1.30876050, grad/param norm = 1.9215e-01, time/batch = 18.4510s	
13301/30300 (epoch 21.949), train_loss = 1.37046104, grad/param norm = 1.7934e-01, time/batch = 18.8847s	
13302/30300 (epoch 21.950), train_loss = 1.34328349, grad/param norm = 1.8436e-01, time/batch = 19.7994s	
13303/30300 (epoch 21.952), train_loss = 1.28724171, grad/param norm = 2.0278e-01, time/batch = 17.6962s	
13304/30300 (epoch 21.954), train_loss = 1.48604581, grad/param norm = 1.5320e-01, time/batch = 19.2089s	
13305/30300 (epoch 21.955), train_loss = 1.16893881, grad/param norm = 1.6027e-01, time/batch = 18.5427s	
13306/30300 (epoch 21.957), train_loss = 1.26187796, grad/param norm = 1.4478e-01, time/batch = 17.3874s	
13307/30300 (epoch 21.959), train_loss = 1.15083535, grad/param norm = 1.6747e-01, time/batch = 19.3881s	
13308/30300 (epoch 21.960), train_loss = 1.17724979, grad/param norm = 1.6506e-01, time/batch = 19.2161s	
13309/30300 (epoch 21.962), train_loss = 1.20482208, grad/param norm = 1.8957e-01, time/batch = 18.5467s	
13310/30300 (epoch 21.964), train_loss = 1.12811389, grad/param norm = 1.7993e-01, time/batch = 19.7793s	
13311/30300 (epoch 21.965), train_loss = 1.14659583, grad/param norm = 1.7873e-01, time/batch = 19.2055s	
13312/30300 (epoch 21.967), train_loss = 1.20538429, grad/param norm = 1.7109e-01, time/batch = 18.2979s	
13313/30300 (epoch 21.969), train_loss = 1.12311097, grad/param norm = 1.8434e-01, time/batch = 18.1945s	
13314/30300 (epoch 21.970), train_loss = 1.17941810, grad/param norm = 1.9699e-01, time/batch = 19.3713s	
13315/30300 (epoch 21.972), train_loss = 1.10530694, grad/param norm = 1.5668e-01, time/batch = 18.6528s	
13316/30300 (epoch 21.974), train_loss = 1.40693747, grad/param norm = 1.7925e-01, time/batch = 19.1118s	
13317/30300 (epoch 21.975), train_loss = 1.41228857, grad/param norm = 1.8556e-01, time/batch = 19.2927s	
13318/30300 (epoch 21.977), train_loss = 1.30652455, grad/param norm = 1.5808e-01, time/batch = 19.1246s	
13319/30300 (epoch 21.979), train_loss = 1.28168876, grad/param norm = 1.5799e-01, time/batch = 19.2793s	
13320/30300 (epoch 21.980), train_loss = 1.28670980, grad/param norm = 1.6068e-01, time/batch = 18.4590s	
13321/30300 (epoch 21.982), train_loss = 1.29454918, grad/param norm = 1.5899e-01, time/batch = 18.2113s	
13322/30300 (epoch 21.983), train_loss = 1.34453209, grad/param norm = 1.6866e-01, time/batch = 18.9426s	
13323/30300 (epoch 21.985), train_loss = 1.26947706, grad/param norm = 1.8801e-01, time/batch = 19.1285s	
13324/30300 (epoch 21.987), train_loss = 1.20371815, grad/param norm = 1.5824e-01, time/batch = 19.9688s	
13325/30300 (epoch 21.988), train_loss = 1.36504873, grad/param norm = 1.7434e-01, time/batch = 17.3078s	
13326/30300 (epoch 21.990), train_loss = 1.05382156, grad/param norm = 1.3669e-01, time/batch = 19.9564s	
13327/30300 (epoch 21.992), train_loss = 1.27710943, grad/param norm = 1.3931e-01, time/batch = 18.9424s	
13328/30300 (epoch 21.993), train_loss = 1.35023318, grad/param norm = 1.8130e-01, time/batch = 18.5081s	
13329/30300 (epoch 21.995), train_loss = 1.18980816, grad/param norm = 1.5991e-01, time/batch = 19.8824s	
13330/30300 (epoch 21.997), train_loss = 1.25570212, grad/param norm = 1.7175e-01, time/batch = 18.6860s	
13331/30300 (epoch 21.998), train_loss = 1.29925626, grad/param norm = 1.7003e-01, time/batch = 17.7063s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
13332/30300 (epoch 22.000), train_loss = 1.17758465, grad/param norm = 1.6938e-01, time/batch = 19.9563s	
13333/30300 (epoch 22.002), train_loss = 1.31198569, grad/param norm = 1.6021e-01, time/batch = 19.8044s	
13334/30300 (epoch 22.003), train_loss = 1.22732130, grad/param norm = 1.6013e-01, time/batch = 18.1400s	
13335/30300 (epoch 22.005), train_loss = 1.20147954, grad/param norm = 1.6645e-01, time/batch = 18.9525s	
13336/30300 (epoch 22.007), train_loss = 1.28245208, grad/param norm = 1.7093e-01, time/batch = 18.5388s	
13337/30300 (epoch 22.008), train_loss = 1.14708878, grad/param norm = 1.5666e-01, time/batch = 18.9650s	
13338/30300 (epoch 22.010), train_loss = 1.10144402, grad/param norm = 1.6114e-01, time/batch = 17.0603s	
13339/30300 (epoch 22.012), train_loss = 1.16856789, grad/param norm = 1.5249e-01, time/batch = 17.7771s	
13340/30300 (epoch 22.013), train_loss = 1.32258884, grad/param norm = 1.6175e-01, time/batch = 19.2080s	
13341/30300 (epoch 22.015), train_loss = 1.16750732, grad/param norm = 1.4445e-01, time/batch = 17.9379s	
13342/30300 (epoch 22.017), train_loss = 1.16904419, grad/param norm = 1.4168e-01, time/batch = 18.7159s	
13343/30300 (epoch 22.018), train_loss = 1.12277890, grad/param norm = 1.4215e-01, time/batch = 19.9548s	
13344/30300 (epoch 22.020), train_loss = 1.32979398, grad/param norm = 2.3672e-01, time/batch = 17.7881s	
13345/30300 (epoch 22.021), train_loss = 1.32876638, grad/param norm = 1.6579e-01, time/batch = 17.7878s	
13346/30300 (epoch 22.023), train_loss = 1.20411798, grad/param norm = 1.5005e-01, time/batch = 18.0358s	
13347/30300 (epoch 22.025), train_loss = 1.14878931, grad/param norm = 1.7304e-01, time/batch = 18.7797s	
13348/30300 (epoch 22.026), train_loss = 1.24456723, grad/param norm = 1.6527e-01, time/batch = 20.1988s	
13349/30300 (epoch 22.028), train_loss = 1.29826910, grad/param norm = 1.5220e-01, time/batch = 18.5352s	
13350/30300 (epoch 22.030), train_loss = 1.14239358, grad/param norm = 1.6228e-01, time/batch = 19.0441s	
13351/30300 (epoch 22.031), train_loss = 1.25927909, grad/param norm = 1.5477e-01, time/batch = 19.7704s	
13352/30300 (epoch 22.033), train_loss = 1.19528981, grad/param norm = 1.5832e-01, time/batch = 16.8830s	
13353/30300 (epoch 22.035), train_loss = 1.30187063, grad/param norm = 1.6722e-01, time/batch = 19.2214s	
13354/30300 (epoch 22.036), train_loss = 1.21205648, grad/param norm = 1.6577e-01, time/batch = 18.9491s	
13355/30300 (epoch 22.038), train_loss = 1.25396882, grad/param norm = 1.5413e-01, time/batch = 18.5503s	
13356/30300 (epoch 22.040), train_loss = 0.96293585, grad/param norm = 1.3423e-01, time/batch = 19.7163s	
13357/30300 (epoch 22.041), train_loss = 1.00203796, grad/param norm = 1.3051e-01, time/batch = 17.9582s	
13358/30300 (epoch 22.043), train_loss = 1.21012655, grad/param norm = 1.4998e-01, time/batch = 19.5525s	
13359/30300 (epoch 22.045), train_loss = 1.19437606, grad/param norm = 1.4967e-01, time/batch = 19.7912s	
13360/30300 (epoch 22.046), train_loss = 1.35866138, grad/param norm = 1.7993e-01, time/batch = 17.4454s	
13361/30300 (epoch 22.048), train_loss = 1.20573526, grad/param norm = 1.8067e-01, time/batch = 17.8844s	
13362/30300 (epoch 22.050), train_loss = 1.17934963, grad/param norm = 1.7068e-01, time/batch = 18.4276s	
13363/30300 (epoch 22.051), train_loss = 1.25095957, grad/param norm = 1.9582e-01, time/batch = 17.7955s	
13364/30300 (epoch 22.053), train_loss = 1.04048219, grad/param norm = 1.6931e-01, time/batch = 19.8790s	
13365/30300 (epoch 22.054), train_loss = 1.19466966, grad/param norm = 1.5761e-01, time/batch = 19.2160s	
13366/30300 (epoch 22.056), train_loss = 1.12389571, grad/param norm = 1.4337e-01, time/batch = 18.2185s	
13367/30300 (epoch 22.058), train_loss = 1.16776211, grad/param norm = 1.4621e-01, time/batch = 17.6379s	
13368/30300 (epoch 22.059), train_loss = 1.10720356, grad/param norm = 1.5766e-01, time/batch = 19.2128s	
13369/30300 (epoch 22.061), train_loss = 1.28688776, grad/param norm = 1.6477e-01, time/batch = 19.1991s	
13370/30300 (epoch 22.063), train_loss = 1.11354243, grad/param norm = 1.6223e-01, time/batch = 17.0465s	
13371/30300 (epoch 22.064), train_loss = 1.21253495, grad/param norm = 1.5563e-01, time/batch = 18.7895s	
13372/30300 (epoch 22.066), train_loss = 1.18817875, grad/param norm = 1.4483e-01, time/batch = 19.6973s	
13373/30300 (epoch 22.068), train_loss = 1.09890235, grad/param norm = 1.5117e-01, time/batch = 17.6981s	
13374/30300 (epoch 22.069), train_loss = 1.26179730, grad/param norm = 1.5329e-01, time/batch = 18.5137s	
13375/30300 (epoch 22.071), train_loss = 1.27737243, grad/param norm = 1.6851e-01, time/batch = 19.2973s	
13376/30300 (epoch 22.073), train_loss = 1.18329491, grad/param norm = 1.7230e-01, time/batch = 18.1114s	
13377/30300 (epoch 22.074), train_loss = 1.24327585, grad/param norm = 1.4917e-01, time/batch = 19.6327s	
13378/30300 (epoch 22.076), train_loss = 1.15719929, grad/param norm = 1.4060e-01, time/batch = 18.7999s	
13379/30300 (epoch 22.078), train_loss = 1.11956239, grad/param norm = 1.4467e-01, time/batch = 18.2831s	
13380/30300 (epoch 22.079), train_loss = 1.13692100, grad/param norm = 1.3780e-01, time/batch = 19.4494s	
13381/30300 (epoch 22.081), train_loss = 1.21944425, grad/param norm = 1.5911e-01, time/batch = 19.4615s	
13382/30300 (epoch 22.083), train_loss = 1.27927821, grad/param norm = 1.7701e-01, time/batch = 18.7731s	
13383/30300 (epoch 22.084), train_loss = 1.10153863, grad/param norm = 1.5422e-01, time/batch = 19.2046s	
13384/30300 (epoch 22.086), train_loss = 1.15632908, grad/param norm = 1.5991e-01, time/batch = 18.2008s	
13385/30300 (epoch 22.087), train_loss = 1.12144117, grad/param norm = 1.4837e-01, time/batch = 18.5436s	
13386/30300 (epoch 22.089), train_loss = 1.16514296, grad/param norm = 1.4988e-01, time/batch = 17.0986s	
13387/30300 (epoch 22.091), train_loss = 1.22872945, grad/param norm = 1.4996e-01, time/batch = 18.3758s	
13388/30300 (epoch 22.092), train_loss = 1.24894442, grad/param norm = 1.5249e-01, time/batch = 17.6953s	
13389/30300 (epoch 22.094), train_loss = 1.37268459, grad/param norm = 1.7819e-01, time/batch = 16.5137s	
13390/30300 (epoch 22.096), train_loss = 1.29567103, grad/param norm = 1.6072e-01, time/batch = 18.2650s	
13391/30300 (epoch 22.097), train_loss = 1.15658032, grad/param norm = 1.5446e-01, time/batch = 18.3409s	
13392/30300 (epoch 22.099), train_loss = 1.31002324, grad/param norm = 1.5789e-01, time/batch = 16.8607s	
13393/30300 (epoch 22.101), train_loss = 1.35390181, grad/param norm = 2.0050e-01, time/batch = 18.5208s	
13394/30300 (epoch 22.102), train_loss = 1.14768156, grad/param norm = 1.8819e-01, time/batch = 19.4463s	
13395/30300 (epoch 22.104), train_loss = 1.19926446, grad/param norm = 1.8054e-01, time/batch = 18.8670s	
13396/30300 (epoch 22.106), train_loss = 1.17929784, grad/param norm = 1.7222e-01, time/batch = 18.8549s	
13397/30300 (epoch 22.107), train_loss = 1.23616448, grad/param norm = 1.5533e-01, time/batch = 19.6232s	
13398/30300 (epoch 22.109), train_loss = 1.30301570, grad/param norm = 2.0802e-01, time/batch = 19.4433s	
13399/30300 (epoch 22.111), train_loss = 1.31475241, grad/param norm = 1.5584e-01, time/batch = 18.1938s	
13400/30300 (epoch 22.112), train_loss = 1.29203990, grad/param norm = 1.4972e-01, time/batch = 19.5293s	
13401/30300 (epoch 22.114), train_loss = 1.19490260, grad/param norm = 1.4967e-01, time/batch = 20.1877s	
13402/30300 (epoch 22.116), train_loss = 1.19330585, grad/param norm = 1.7091e-01, time/batch = 18.1230s	
13403/30300 (epoch 22.117), train_loss = 1.25187738, grad/param norm = 1.4328e-01, time/batch = 20.1212s	
13404/30300 (epoch 22.119), train_loss = 1.14476393, grad/param norm = 1.6012e-01, time/batch = 19.1940s	
13405/30300 (epoch 22.120), train_loss = 1.21523297, grad/param norm = 1.6217e-01, time/batch = 17.0310s	
13406/30300 (epoch 22.122), train_loss = 1.30971252, grad/param norm = 1.8352e-01, time/batch = 17.2040s	
13407/30300 (epoch 22.124), train_loss = 1.35762655, grad/param norm = 1.6897e-01, time/batch = 18.4265s	
13408/30300 (epoch 22.125), train_loss = 1.06588767, grad/param norm = 1.4876e-01, time/batch = 18.5262s	
13409/30300 (epoch 22.127), train_loss = 1.24026449, grad/param norm = 1.7313e-01, time/batch = 17.2850s	
13410/30300 (epoch 22.129), train_loss = 1.35793990, grad/param norm = 1.6031e-01, time/batch = 18.3679s	
13411/30300 (epoch 22.130), train_loss = 1.35815561, grad/param norm = 1.7510e-01, time/batch = 19.1940s	
13412/30300 (epoch 22.132), train_loss = 1.32874724, grad/param norm = 1.7213e-01, time/batch = 19.2131s	
13413/30300 (epoch 22.134), train_loss = 1.11852016, grad/param norm = 1.5062e-01, time/batch = 19.3550s	
13414/30300 (epoch 22.135), train_loss = 1.15036939, grad/param norm = 1.5873e-01, time/batch = 19.8817s	
13415/30300 (epoch 22.137), train_loss = 1.20943050, grad/param norm = 1.4791e-01, time/batch = 18.8506s	
13416/30300 (epoch 22.139), train_loss = 1.18184800, grad/param norm = 1.6970e-01, time/batch = 18.8703s	
13417/30300 (epoch 22.140), train_loss = 1.24557572, grad/param norm = 2.2915e-01, time/batch = 19.7069s	
13418/30300 (epoch 22.142), train_loss = 1.36851285, grad/param norm = 2.3054e-01, time/batch = 18.2890s	
13419/30300 (epoch 22.144), train_loss = 1.22333367, grad/param norm = 2.0441e-01, time/batch = 19.7025s	
13420/30300 (epoch 22.145), train_loss = 1.31112532, grad/param norm = 1.9353e-01, time/batch = 19.3758s	
13421/30300 (epoch 22.147), train_loss = 1.19479090, grad/param norm = 2.1780e-01, time/batch = 17.3730s	
13422/30300 (epoch 22.149), train_loss = 1.43174572, grad/param norm = 2.1575e-01, time/batch = 19.8596s	
13423/30300 (epoch 22.150), train_loss = 1.18958452, grad/param norm = 1.7737e-01, time/batch = 16.7524s	
13424/30300 (epoch 22.152), train_loss = 1.09717712, grad/param norm = 1.7302e-01, time/batch = 18.5372s	
13425/30300 (epoch 22.153), train_loss = 1.20967068, grad/param norm = 1.6475e-01, time/batch = 18.0369s	
13426/30300 (epoch 22.155), train_loss = 1.05011429, grad/param norm = 1.4182e-01, time/batch = 19.1262s	
13427/30300 (epoch 22.157), train_loss = 1.18600992, grad/param norm = 1.6383e-01, time/batch = 19.0439s	
13428/30300 (epoch 22.158), train_loss = 1.23356696, grad/param norm = 1.7947e-01, time/batch = 18.2802s	
13429/30300 (epoch 22.160), train_loss = 1.13404441, grad/param norm = 1.6066e-01, time/batch = 20.1145s	
13430/30300 (epoch 22.162), train_loss = 1.18326855, grad/param norm = 1.4874e-01, time/batch = 20.8578s	
13431/30300 (epoch 22.163), train_loss = 1.16681038, grad/param norm = 1.6907e-01, time/batch = 31.0001s	
13432/30300 (epoch 22.165), train_loss = 1.32445530, grad/param norm = 1.5182e-01, time/batch = 20.3825s	
13433/30300 (epoch 22.167), train_loss = 1.20474025, grad/param norm = 1.7018e-01, time/batch = 16.9373s	
13434/30300 (epoch 22.168), train_loss = 1.26799216, grad/param norm = 1.6254e-01, time/batch = 18.2071s	
13435/30300 (epoch 22.170), train_loss = 1.23421521, grad/param norm = 1.7654e-01, time/batch = 18.1091s	
13436/30300 (epoch 22.172), train_loss = 1.19189969, grad/param norm = 1.6357e-01, time/batch = 17.8747s	
13437/30300 (epoch 22.173), train_loss = 1.20332636, grad/param norm = 1.7969e-01, time/batch = 20.0342s	
13438/30300 (epoch 22.175), train_loss = 1.21790286, grad/param norm = 1.4986e-01, time/batch = 19.0296s	
13439/30300 (epoch 22.177), train_loss = 1.25030625, grad/param norm = 1.7923e-01, time/batch = 18.4551s	
13440/30300 (epoch 22.178), train_loss = 0.99311649, grad/param norm = 1.5348e-01, time/batch = 18.2859s	
13441/30300 (epoch 22.180), train_loss = 1.18066097, grad/param norm = 1.4544e-01, time/batch = 18.8841s	
13442/30300 (epoch 22.182), train_loss = 1.18843660, grad/param norm = 1.8094e-01, time/batch = 19.1942s	
13443/30300 (epoch 22.183), train_loss = 1.14238164, grad/param norm = 1.5322e-01, time/batch = 18.6261s	
13444/30300 (epoch 22.185), train_loss = 1.40220472, grad/param norm = 1.6292e-01, time/batch = 19.6312s	
13445/30300 (epoch 22.186), train_loss = 1.44695361, grad/param norm = 1.9481e-01, time/batch = 18.8786s	
13446/30300 (epoch 22.188), train_loss = 1.26226170, grad/param norm = 1.6825e-01, time/batch = 18.6986s	
13447/30300 (epoch 22.190), train_loss = 1.19382750, grad/param norm = 1.4999e-01, time/batch = 18.7164s	
13448/30300 (epoch 22.191), train_loss = 1.28429354, grad/param norm = 1.5674e-01, time/batch = 17.7844s	
13449/30300 (epoch 22.193), train_loss = 1.12036840, grad/param norm = 1.4449e-01, time/batch = 17.5326s	
13450/30300 (epoch 22.195), train_loss = 1.22182154, grad/param norm = 1.6429e-01, time/batch = 20.5252s	
13451/30300 (epoch 22.196), train_loss = 1.24924271, grad/param norm = 1.5679e-01, time/batch = 19.1424s	
13452/30300 (epoch 22.198), train_loss = 1.02340059, grad/param norm = 1.4812e-01, time/batch = 18.6274s	
13453/30300 (epoch 22.200), train_loss = 1.19490673, grad/param norm = 1.4061e-01, time/batch = 19.5533s	
13454/30300 (epoch 22.201), train_loss = 1.29291216, grad/param norm = 1.7099e-01, time/batch = 19.0575s	
13455/30300 (epoch 22.203), train_loss = 1.23622155, grad/param norm = 1.6244e-01, time/batch = 18.5488s	
13456/30300 (epoch 22.205), train_loss = 1.42507296, grad/param norm = 1.7031e-01, time/batch = 17.9556s	
13457/30300 (epoch 22.206), train_loss = 1.32650348, grad/param norm = 1.7578e-01, time/batch = 19.3474s	
13458/30300 (epoch 22.208), train_loss = 1.34066931, grad/param norm = 2.0994e-01, time/batch = 17.9254s	
13459/30300 (epoch 22.210), train_loss = 1.25791778, grad/param norm = 1.7492e-01, time/batch = 18.7045s	
13460/30300 (epoch 22.211), train_loss = 1.33289247, grad/param norm = 1.6885e-01, time/batch = 19.9655s	
13461/30300 (epoch 22.213), train_loss = 1.16321510, grad/param norm = 1.3695e-01, time/batch = 18.6256s	
13462/30300 (epoch 22.215), train_loss = 1.12104765, grad/param norm = 1.4736e-01, time/batch = 19.2164s	
13463/30300 (epoch 22.216), train_loss = 1.16452655, grad/param norm = 1.5075e-01, time/batch = 18.7794s	
13464/30300 (epoch 22.218), train_loss = 1.08908286, grad/param norm = 1.3493e-01, time/batch = 19.1981s	
13465/30300 (epoch 22.219), train_loss = 1.05166705, grad/param norm = 1.3941e-01, time/batch = 17.7934s	
13466/30300 (epoch 22.221), train_loss = 1.06449017, grad/param norm = 1.3791e-01, time/batch = 19.8776s	
13467/30300 (epoch 22.223), train_loss = 1.23052139, grad/param norm = 1.5123e-01, time/batch = 19.9629s	
13468/30300 (epoch 22.224), train_loss = 1.04822652, grad/param norm = 1.4966e-01, time/batch = 17.6873s	
13469/30300 (epoch 22.226), train_loss = 1.30384344, grad/param norm = 1.9762e-01, time/batch = 19.5502s	
13470/30300 (epoch 22.228), train_loss = 1.31347484, grad/param norm = 1.6097e-01, time/batch = 19.4529s	
13471/30300 (epoch 22.229), train_loss = 1.16488771, grad/param norm = 1.4620e-01, time/batch = 17.7849s	
13472/30300 (epoch 22.231), train_loss = 1.26008189, grad/param norm = 1.5490e-01, time/batch = 18.7098s	
13473/30300 (epoch 22.233), train_loss = 1.20142389, grad/param norm = 1.4030e-01, time/batch = 18.0337s	
13474/30300 (epoch 22.234), train_loss = 1.26380021, grad/param norm = 1.7401e-01, time/batch = 19.1993s	
13475/30300 (epoch 22.236), train_loss = 1.23021613, grad/param norm = 1.4199e-01, time/batch = 19.4576s	
13476/30300 (epoch 22.238), train_loss = 1.27256460, grad/param norm = 1.7561e-01, time/batch = 19.7796s	
13477/30300 (epoch 22.239), train_loss = 1.25331150, grad/param norm = 1.6386e-01, time/batch = 18.8584s	
13478/30300 (epoch 22.241), train_loss = 1.24944044, grad/param norm = 1.7618e-01, time/batch = 19.1278s	
13479/30300 (epoch 22.243), train_loss = 1.26224621, grad/param norm = 1.5205e-01, time/batch = 19.5457s	
13480/30300 (epoch 22.244), train_loss = 1.45492183, grad/param norm = 1.6340e-01, time/batch = 18.3710s	
13481/30300 (epoch 22.246), train_loss = 1.22224863, grad/param norm = 1.6111e-01, time/batch = 19.7238s	
13482/30300 (epoch 22.248), train_loss = 1.18560843, grad/param norm = 1.4993e-01, time/batch = 19.6992s	
13483/30300 (epoch 22.249), train_loss = 1.14154353, grad/param norm = 1.4979e-01, time/batch = 19.3733s	
13484/30300 (epoch 22.251), train_loss = 1.13420628, grad/param norm = 1.5311e-01, time/batch = 19.8423s	
13485/30300 (epoch 22.252), train_loss = 1.31405420, grad/param norm = 1.6550e-01, time/batch = 19.0265s	
13486/30300 (epoch 22.254), train_loss = 1.30594083, grad/param norm = 1.6778e-01, time/batch = 19.3706s	
13487/30300 (epoch 22.256), train_loss = 1.26665420, grad/param norm = 1.6162e-01, time/batch = 19.3583s	
13488/30300 (epoch 22.257), train_loss = 1.26771249, grad/param norm = 1.5452e-01, time/batch = 18.8450s	
13489/30300 (epoch 22.259), train_loss = 1.20343845, grad/param norm = 1.8432e-01, time/batch = 19.5123s	
13490/30300 (epoch 22.261), train_loss = 1.31877983, grad/param norm = 1.5997e-01, time/batch = 19.6116s	
13491/30300 (epoch 22.262), train_loss = 1.21340956, grad/param norm = 1.5808e-01, time/batch = 19.2020s	
13492/30300 (epoch 22.264), train_loss = 1.22152201, grad/param norm = 1.5154e-01, time/batch = 19.7035s	
13493/30300 (epoch 22.266), train_loss = 1.14568963, grad/param norm = 1.4803e-01, time/batch = 18.2792s	
13494/30300 (epoch 22.267), train_loss = 1.41004317, grad/param norm = 1.9554e-01, time/batch = 19.7153s	
13495/30300 (epoch 22.269), train_loss = 1.26065715, grad/param norm = 1.6835e-01, time/batch = 19.4673s	
13496/30300 (epoch 22.271), train_loss = 1.25034308, grad/param norm = 1.6061e-01, time/batch = 18.1111s	
13497/30300 (epoch 22.272), train_loss = 1.23344083, grad/param norm = 1.6767e-01, time/batch = 19.7923s	
13498/30300 (epoch 22.274), train_loss = 1.32525624, grad/param norm = 1.5734e-01, time/batch = 20.0355s	
13499/30300 (epoch 22.276), train_loss = 1.26668371, grad/param norm = 1.6327e-01, time/batch = 18.0311s	
13500/30300 (epoch 22.277), train_loss = 1.08516806, grad/param norm = 1.5807e-01, time/batch = 19.3627s	
13501/30300 (epoch 22.279), train_loss = 1.24172462, grad/param norm = 1.5596e-01, time/batch = 19.9421s	
13502/30300 (epoch 22.281), train_loss = 1.32671391, grad/param norm = 1.9097e-01, time/batch = 17.6931s	
13503/30300 (epoch 22.282), train_loss = 1.23187568, grad/param norm = 1.4693e-01, time/batch = 18.1736s	
13504/30300 (epoch 22.284), train_loss = 1.37693125, grad/param norm = 2.0201e-01, time/batch = 18.0153s	
13505/30300 (epoch 22.285), train_loss = 1.27142263, grad/param norm = 1.4114e-01, time/batch = 15.0991s	
13506/30300 (epoch 22.287), train_loss = 1.23094032, grad/param norm = 1.6271e-01, time/batch = 18.4386s	
13507/30300 (epoch 22.289), train_loss = 1.29118309, grad/param norm = 1.4704e-01, time/batch = 19.3720s	
13508/30300 (epoch 22.290), train_loss = 0.98633685, grad/param norm = 1.3989e-01, time/batch = 19.0484s	
13509/30300 (epoch 22.292), train_loss = 1.11971106, grad/param norm = 1.4153e-01, time/batch = 18.3542s	
13510/30300 (epoch 22.294), train_loss = 1.34336897, grad/param norm = 2.0772e-01, time/batch = 17.9691s	
13511/30300 (epoch 22.295), train_loss = 1.18330935, grad/param norm = 1.5999e-01, time/batch = 20.0442s	
13512/30300 (epoch 22.297), train_loss = 1.16254389, grad/param norm = 1.4270e-01, time/batch = 18.4223s	
13513/30300 (epoch 22.299), train_loss = 1.20494169, grad/param norm = 1.5816e-01, time/batch = 19.2165s	
13514/30300 (epoch 22.300), train_loss = 1.17223513, grad/param norm = 1.5190e-01, time/batch = 19.2793s	
13515/30300 (epoch 22.302), train_loss = 1.22297665, grad/param norm = 1.5303e-01, time/batch = 17.9677s	
13516/30300 (epoch 22.304), train_loss = 1.13415250, grad/param norm = 1.4667e-01, time/batch = 19.5389s	
13517/30300 (epoch 22.305), train_loss = 1.16736251, grad/param norm = 1.3763e-01, time/batch = 19.5484s	
13518/30300 (epoch 22.307), train_loss = 1.26378709, grad/param norm = 1.4067e-01, time/batch = 19.2162s	
13519/30300 (epoch 22.309), train_loss = 1.28130293, grad/param norm = 1.5704e-01, time/batch = 18.5429s	
13520/30300 (epoch 22.310), train_loss = 1.22136161, grad/param norm = 1.5422e-01, time/batch = 19.0475s	
13521/30300 (epoch 22.312), train_loss = 1.34221497, grad/param norm = 1.4973e-01, time/batch = 19.1129s	
13522/30300 (epoch 22.314), train_loss = 1.24482471, grad/param norm = 1.5775e-01, time/batch = 19.4467s	
13523/30300 (epoch 22.315), train_loss = 1.21825446, grad/param norm = 1.5597e-01, time/batch = 18.8807s	
13524/30300 (epoch 22.317), train_loss = 1.27309158, grad/param norm = 1.4565e-01, time/batch = 18.6931s	
13525/30300 (epoch 22.318), train_loss = 1.32451927, grad/param norm = 1.7068e-01, time/batch = 19.4605s	
13526/30300 (epoch 22.320), train_loss = 1.29435547, grad/param norm = 1.5107e-01, time/batch = 19.1404s	
13527/30300 (epoch 22.322), train_loss = 1.13404143, grad/param norm = 1.4379e-01, time/batch = 19.0383s	
13528/30300 (epoch 22.323), train_loss = 1.30334591, grad/param norm = 1.6761e-01, time/batch = 17.4282s	
13529/30300 (epoch 22.325), train_loss = 1.20960861, grad/param norm = 1.5373e-01, time/batch = 17.0151s	
13530/30300 (epoch 22.327), train_loss = 1.21326343, grad/param norm = 1.4112e-01, time/batch = 18.5651s	
13531/30300 (epoch 22.328), train_loss = 1.22212615, grad/param norm = 1.4197e-01, time/batch = 17.0439s	
13532/30300 (epoch 22.330), train_loss = 1.27241306, grad/param norm = 1.5556e-01, time/batch = 19.1182s	
13533/30300 (epoch 22.332), train_loss = 1.31277536, grad/param norm = 1.9416e-01, time/batch = 19.5470s	
13534/30300 (epoch 22.333), train_loss = 1.19529510, grad/param norm = 1.6603e-01, time/batch = 18.5383s	
13535/30300 (epoch 22.335), train_loss = 1.10380208, grad/param norm = 1.5410e-01, time/batch = 16.3972s	
13536/30300 (epoch 22.337), train_loss = 1.35970570, grad/param norm = 1.4862e-01, time/batch = 17.9591s	
13537/30300 (epoch 22.338), train_loss = 1.13496639, grad/param norm = 1.3677e-01, time/batch = 18.3699s	
13538/30300 (epoch 22.340), train_loss = 1.12268771, grad/param norm = 1.5550e-01, time/batch = 19.0465s	
13539/30300 (epoch 22.342), train_loss = 1.28922527, grad/param norm = 1.4921e-01, time/batch = 19.2884s	
13540/30300 (epoch 22.343), train_loss = 1.24812295, grad/param norm = 1.8314e-01, time/batch = 18.6346s	
13541/30300 (epoch 22.345), train_loss = 1.25566182, grad/param norm = 1.5867e-01, time/batch = 18.7801s	
13542/30300 (epoch 22.347), train_loss = 1.07873622, grad/param norm = 1.4910e-01, time/batch = 18.7162s	
13543/30300 (epoch 22.348), train_loss = 1.13583523, grad/param norm = 1.4993e-01, time/batch = 19.7961s	
13544/30300 (epoch 22.350), train_loss = 1.20463260, grad/param norm = 1.5563e-01, time/batch = 18.5261s	
13545/30300 (epoch 22.351), train_loss = 1.22303851, grad/param norm = 1.5833e-01, time/batch = 18.8974s	
13546/30300 (epoch 22.353), train_loss = 1.07463978, grad/param norm = 1.4768e-01, time/batch = 17.7935s	
13547/30300 (epoch 22.355), train_loss = 1.16419728, grad/param norm = 1.4402e-01, time/batch = 17.1034s	
13548/30300 (epoch 22.356), train_loss = 1.28425446, grad/param norm = 1.6782e-01, time/batch = 18.8702s	
13549/30300 (epoch 22.358), train_loss = 1.44936733, grad/param norm = 1.5132e-01, time/batch = 18.6455s	
13550/30300 (epoch 22.360), train_loss = 1.15995037, grad/param norm = 1.4604e-01, time/batch = 19.1189s	
13551/30300 (epoch 22.361), train_loss = 1.25188262, grad/param norm = 1.5697e-01, time/batch = 17.9632s	
13552/30300 (epoch 22.363), train_loss = 1.28958075, grad/param norm = 1.5551e-01, time/batch = 19.2088s	
13553/30300 (epoch 22.365), train_loss = 1.12452215, grad/param norm = 1.6305e-01, time/batch = 18.4684s	
13554/30300 (epoch 22.366), train_loss = 1.16828094, grad/param norm = 1.4167e-01, time/batch = 19.3664s	
13555/30300 (epoch 22.368), train_loss = 1.05527065, grad/param norm = 1.3825e-01, time/batch = 19.0443s	
13556/30300 (epoch 22.370), train_loss = 1.11194492, grad/param norm = 1.5066e-01, time/batch = 18.7053s	
13557/30300 (epoch 22.371), train_loss = 1.30267154, grad/param norm = 1.5406e-01, time/batch = 19.0269s	
13558/30300 (epoch 22.373), train_loss = 1.12268513, grad/param norm = 1.2863e-01, time/batch = 19.2139s	
13559/30300 (epoch 22.375), train_loss = 1.11750187, grad/param norm = 1.3824e-01, time/batch = 18.3886s	
13560/30300 (epoch 22.376), train_loss = 1.12446509, grad/param norm = 1.3002e-01, time/batch = 18.6989s	
13561/30300 (epoch 22.378), train_loss = 1.14189437, grad/param norm = 1.6444e-01, time/batch = 19.5245s	
13562/30300 (epoch 22.380), train_loss = 1.37011423, grad/param norm = 1.5906e-01, time/batch = 17.8659s	
13563/30300 (epoch 22.381), train_loss = 1.07618008, grad/param norm = 1.4390e-01, time/batch = 18.1206s	
13564/30300 (epoch 22.383), train_loss = 1.14413888, grad/param norm = 1.6377e-01, time/batch = 16.7084s	
13565/30300 (epoch 22.384), train_loss = 1.26824809, grad/param norm = 1.5345e-01, time/batch = 19.5392s	
13566/30300 (epoch 22.386), train_loss = 1.09393519, grad/param norm = 1.4352e-01, time/batch = 18.7902s	
13567/30300 (epoch 22.388), train_loss = 1.05833117, grad/param norm = 1.3848e-01, time/batch = 19.0138s	
13568/30300 (epoch 22.389), train_loss = 1.18075628, grad/param norm = 1.7288e-01, time/batch = 18.7902s	
13569/30300 (epoch 22.391), train_loss = 1.24930209, grad/param norm = 1.4946e-01, time/batch = 19.0538s	
13570/30300 (epoch 22.393), train_loss = 1.07641844, grad/param norm = 1.4273e-01, time/batch = 17.9615s	
13571/30300 (epoch 22.394), train_loss = 1.26985382, grad/param norm = 1.5053e-01, time/batch = 19.2485s	
13572/30300 (epoch 22.396), train_loss = 1.33502116, grad/param norm = 1.4957e-01, time/batch = 18.0812s	
13573/30300 (epoch 22.398), train_loss = 1.18332492, grad/param norm = 1.4224e-01, time/batch = 16.4290s	
13574/30300 (epoch 22.399), train_loss = 1.16483997, grad/param norm = 1.4494e-01, time/batch = 17.8524s	
13575/30300 (epoch 22.401), train_loss = 1.23737318, grad/param norm = 1.5603e-01, time/batch = 19.4490s	
13576/30300 (epoch 22.403), train_loss = 1.18696459, grad/param norm = 1.5404e-01, time/batch = 16.3654s	
13577/30300 (epoch 22.404), train_loss = 1.11347777, grad/param norm = 1.6791e-01, time/batch = 18.9508s	
13578/30300 (epoch 22.406), train_loss = 1.22689314, grad/param norm = 1.4316e-01, time/batch = 19.2051s	
13579/30300 (epoch 22.408), train_loss = 1.07420314, grad/param norm = 1.4259e-01, time/batch = 18.4556s	
13580/30300 (epoch 22.409), train_loss = 1.08517454, grad/param norm = 1.5111e-01, time/batch = 19.3018s	
13581/30300 (epoch 22.411), train_loss = 1.09271234, grad/param norm = 1.3274e-01, time/batch = 17.8575s	
13582/30300 (epoch 22.413), train_loss = 1.00455903, grad/param norm = 1.5637e-01, time/batch = 18.3777s	
13583/30300 (epoch 22.414), train_loss = 1.29623116, grad/param norm = 1.5726e-01, time/batch = 18.0360s	
13584/30300 (epoch 22.416), train_loss = 1.14206768, grad/param norm = 1.5150e-01, time/batch = 19.4514s	
13585/30300 (epoch 22.417), train_loss = 1.11536318, grad/param norm = 1.4016e-01, time/batch = 18.8759s	
13586/30300 (epoch 22.419), train_loss = 1.07399362, grad/param norm = 1.4233e-01, time/batch = 18.9484s	
13587/30300 (epoch 22.421), train_loss = 1.16943396, grad/param norm = 1.8957e-01, time/batch = 15.3676s	
13588/30300 (epoch 22.422), train_loss = 1.19934760, grad/param norm = 1.5425e-01, time/batch = 17.6870s	
13589/30300 (epoch 22.424), train_loss = 1.20631149, grad/param norm = 1.4951e-01, time/batch = 17.6188s	
13590/30300 (epoch 22.426), train_loss = 1.13937772, grad/param norm = 1.5455e-01, time/batch = 19.5353s	
13591/30300 (epoch 22.427), train_loss = 1.17358474, grad/param norm = 1.6278e-01, time/batch = 19.1921s	
13592/30300 (epoch 22.429), train_loss = 1.18448148, grad/param norm = 1.4757e-01, time/batch = 18.6791s	
13593/30300 (epoch 22.431), train_loss = 1.25550412, grad/param norm = 1.4262e-01, time/batch = 18.6980s	
13594/30300 (epoch 22.432), train_loss = 1.17120636, grad/param norm = 1.4079e-01, time/batch = 19.3699s	
13595/30300 (epoch 22.434), train_loss = 1.07430675, grad/param norm = 1.4286e-01, time/batch = 17.3754s	
13596/30300 (epoch 22.436), train_loss = 1.33025057, grad/param norm = 1.5908e-01, time/batch = 19.1134s	
13597/30300 (epoch 22.437), train_loss = 1.08375007, grad/param norm = 1.4760e-01, time/batch = 17.9773s	
13598/30300 (epoch 22.439), train_loss = 1.13586680, grad/param norm = 1.5073e-01, time/batch = 19.5560s	
13599/30300 (epoch 22.441), train_loss = 1.18181811, grad/param norm = 1.5429e-01, time/batch = 17.9485s	
13600/30300 (epoch 22.442), train_loss = 1.09426912, grad/param norm = 1.4802e-01, time/batch = 18.8758s	
13601/30300 (epoch 22.444), train_loss = 0.99870782, grad/param norm = 1.4392e-01, time/batch = 18.4707s	
13602/30300 (epoch 22.446), train_loss = 1.17139959, grad/param norm = 1.4354e-01, time/batch = 18.0367s	
13603/30300 (epoch 22.447), train_loss = 1.17834341, grad/param norm = 1.5727e-01, time/batch = 19.7110s	
13604/30300 (epoch 22.449), train_loss = 1.10396722, grad/param norm = 1.3822e-01, time/batch = 20.1114s	
13605/30300 (epoch 22.450), train_loss = 1.26048838, grad/param norm = 1.4492e-01, time/batch = 18.1206s	
13606/30300 (epoch 22.452), train_loss = 1.28431776, grad/param norm = 1.4962e-01, time/batch = 16.2681s	
13607/30300 (epoch 22.454), train_loss = 1.26504455, grad/param norm = 1.4974e-01, time/batch = 18.5455s	
13608/30300 (epoch 22.455), train_loss = 1.23177546, grad/param norm = 1.6221e-01, time/batch = 18.8758s	
13609/30300 (epoch 22.457), train_loss = 1.18276200, grad/param norm = 1.4815e-01, time/batch = 18.7829s	
13610/30300 (epoch 22.459), train_loss = 1.27113834, grad/param norm = 1.6427e-01, time/batch = 18.5372s	
13611/30300 (epoch 22.460), train_loss = 1.21893874, grad/param norm = 1.5323e-01, time/batch = 18.7207s	
13612/30300 (epoch 22.462), train_loss = 1.25119084, grad/param norm = 1.4832e-01, time/batch = 18.9380s	
13613/30300 (epoch 22.464), train_loss = 1.04023406, grad/param norm = 1.6802e-01, time/batch = 19.6407s	
13614/30300 (epoch 22.465), train_loss = 1.02284447, grad/param norm = 1.4514e-01, time/batch = 19.3859s	
13615/30300 (epoch 22.467), train_loss = 1.00013583, grad/param norm = 1.3327e-01, time/batch = 19.7053s	
13616/30300 (epoch 22.469), train_loss = 1.09779860, grad/param norm = 1.2854e-01, time/batch = 17.7097s	
13617/30300 (epoch 22.470), train_loss = 1.14363892, grad/param norm = 1.4977e-01, time/batch = 18.7932s	
13618/30300 (epoch 22.472), train_loss = 1.14713155, grad/param norm = 1.3494e-01, time/batch = 18.7935s	
13619/30300 (epoch 22.474), train_loss = 1.16927862, grad/param norm = 1.7239e-01, time/batch = 19.6161s	
13620/30300 (epoch 22.475), train_loss = 1.10722059, grad/param norm = 1.4185e-01, time/batch = 19.5360s	
13621/30300 (epoch 22.477), train_loss = 1.17186372, grad/param norm = 1.5381e-01, time/batch = 32.1155s	
13622/30300 (epoch 22.479), train_loss = 1.17272558, grad/param norm = 1.5033e-01, time/batch = 18.1026s	
13623/30300 (epoch 22.480), train_loss = 1.20447739, grad/param norm = 1.4825e-01, time/batch = 17.8797s	
13624/30300 (epoch 22.482), train_loss = 1.22483150, grad/param norm = 1.3341e-01, time/batch = 19.1104s	
13625/30300 (epoch 22.483), train_loss = 1.13202726, grad/param norm = 1.5159e-01, time/batch = 19.1191s	
13626/30300 (epoch 22.485), train_loss = 1.19116427, grad/param norm = 1.4469e-01, time/batch = 17.8973s	
13627/30300 (epoch 22.487), train_loss = 1.28051833, grad/param norm = 1.6046e-01, time/batch = 18.4421s	
13628/30300 (epoch 22.488), train_loss = 1.27646784, grad/param norm = 1.3828e-01, time/batch = 18.4571s	
13629/30300 (epoch 22.490), train_loss = 1.07546123, grad/param norm = 1.5104e-01, time/batch = 19.6326s	
13630/30300 (epoch 22.492), train_loss = 1.15444668, grad/param norm = 1.5136e-01, time/batch = 17.7957s	
13631/30300 (epoch 22.493), train_loss = 1.15217450, grad/param norm = 1.4396e-01, time/batch = 20.0366s	
13632/30300 (epoch 22.495), train_loss = 1.13816226, grad/param norm = 1.3491e-01, time/batch = 18.7104s	
13633/30300 (epoch 22.497), train_loss = 1.21328723, grad/param norm = 1.4289e-01, time/batch = 16.9365s	
13634/30300 (epoch 22.498), train_loss = 1.22329313, grad/param norm = 1.4536e-01, time/batch = 18.6105s	
13635/30300 (epoch 22.500), train_loss = 1.19894248, grad/param norm = 1.7213e-01, time/batch = 19.2011s	
13636/30300 (epoch 22.502), train_loss = 1.20101689, grad/param norm = 1.5955e-01, time/batch = 18.0371s	
13637/30300 (epoch 22.503), train_loss = 1.28065998, grad/param norm = 1.4754e-01, time/batch = 18.3572s	
13638/30300 (epoch 22.505), train_loss = 1.12394980, grad/param norm = 1.4466e-01, time/batch = 19.1156s	
13639/30300 (epoch 22.507), train_loss = 1.11117598, grad/param norm = 1.4339e-01, time/batch = 18.6983s	
13640/30300 (epoch 22.508), train_loss = 1.14929460, grad/param norm = 1.7112e-01, time/batch = 19.2784s	
13641/30300 (epoch 22.510), train_loss = 1.27481452, grad/param norm = 1.6629e-01, time/batch = 19.6213s	
13642/30300 (epoch 22.512), train_loss = 1.12356662, grad/param norm = 1.3664e-01, time/batch = 19.3017s	
13643/30300 (epoch 22.513), train_loss = 1.20086680, grad/param norm = 1.3597e-01, time/batch = 19.0395s	
13644/30300 (epoch 22.515), train_loss = 1.17941025, grad/param norm = 1.3885e-01, time/batch = 18.2030s	
13645/30300 (epoch 22.517), train_loss = 1.00713027, grad/param norm = 1.3158e-01, time/batch = 19.1531s	
13646/30300 (epoch 22.518), train_loss = 1.25422646, grad/param norm = 1.4933e-01, time/batch = 18.5388s	
13647/30300 (epoch 22.520), train_loss = 1.26231338, grad/param norm = 1.7164e-01, time/batch = 18.8010s	
13648/30300 (epoch 22.521), train_loss = 1.10634731, grad/param norm = 1.5810e-01, time/batch = 18.7945s	
13649/30300 (epoch 22.523), train_loss = 1.35019627, grad/param norm = 1.9704e-01, time/batch = 17.6356s	
13650/30300 (epoch 22.525), train_loss = 1.11105821, grad/param norm = 1.5748e-01, time/batch = 20.2101s	
13651/30300 (epoch 22.526), train_loss = 1.16843462, grad/param norm = 1.4249e-01, time/batch = 19.7808s	
13652/30300 (epoch 22.528), train_loss = 1.06645982, grad/param norm = 1.4612e-01, time/batch = 18.2857s	
13653/30300 (epoch 22.530), train_loss = 1.05108457, grad/param norm = 1.4449e-01, time/batch = 19.3746s	
13654/30300 (epoch 22.531), train_loss = 1.22688229, grad/param norm = 1.5769e-01, time/batch = 18.6310s	
13655/30300 (epoch 22.533), train_loss = 1.20054727, grad/param norm = 1.5511e-01, time/batch = 18.0576s	
13656/30300 (epoch 22.535), train_loss = 1.09389951, grad/param norm = 1.2615e-01, time/batch = 19.2621s	
13657/30300 (epoch 22.536), train_loss = 1.19586443, grad/param norm = 1.5275e-01, time/batch = 19.1319s	
13658/30300 (epoch 22.538), train_loss = 1.06506031, grad/param norm = 1.5310e-01, time/batch = 18.2029s	
13659/30300 (epoch 22.540), train_loss = 1.09296000, grad/param norm = 1.7047e-01, time/batch = 20.0263s	
13660/30300 (epoch 22.541), train_loss = 1.17677953, grad/param norm = 1.5772e-01, time/batch = 17.8804s	
13661/30300 (epoch 22.543), train_loss = 1.16839018, grad/param norm = 1.5058e-01, time/batch = 18.7208s	
13662/30300 (epoch 22.545), train_loss = 1.19970825, grad/param norm = 2.1182e-01, time/batch = 18.9622s	
13663/30300 (epoch 22.546), train_loss = 1.40878557, grad/param norm = 1.5893e-01, time/batch = 19.4460s	
13664/30300 (epoch 22.548), train_loss = 1.11912005, grad/param norm = 1.3626e-01, time/batch = 19.1257s	
13665/30300 (epoch 22.550), train_loss = 1.24532071, grad/param norm = 1.7651e-01, time/batch = 18.1968s	
13666/30300 (epoch 22.551), train_loss = 1.12440525, grad/param norm = 1.5419e-01, time/batch = 19.0363s	
13667/30300 (epoch 22.553), train_loss = 1.14771822, grad/param norm = 1.5213e-01, time/batch = 19.8848s	
13668/30300 (epoch 22.554), train_loss = 1.19411391, grad/param norm = 1.5799e-01, time/batch = 18.0309s	
13669/30300 (epoch 22.556), train_loss = 1.23855789, grad/param norm = 1.5331e-01, time/batch = 18.6967s	
13670/30300 (epoch 22.558), train_loss = 1.28470515, grad/param norm = 1.6433e-01, time/batch = 16.5139s	
13671/30300 (epoch 22.559), train_loss = 1.23620621, grad/param norm = 1.7431e-01, time/batch = 17.3600s	
13672/30300 (epoch 22.561), train_loss = 1.01914670, grad/param norm = 1.4445e-01, time/batch = 17.1948s	
13673/30300 (epoch 22.563), train_loss = 1.08481066, grad/param norm = 1.4489e-01, time/batch = 18.0235s	
13674/30300 (epoch 22.564), train_loss = 1.12074704, grad/param norm = 1.4395e-01, time/batch = 18.3742s	
13675/30300 (epoch 22.566), train_loss = 1.18878168, grad/param norm = 1.4283e-01, time/batch = 17.9244s	
13676/30300 (epoch 22.568), train_loss = 1.00973124, grad/param norm = 1.5314e-01, time/batch = 18.2062s	
13677/30300 (epoch 22.569), train_loss = 1.19788976, grad/param norm = 1.4418e-01, time/batch = 20.1997s	
13678/30300 (epoch 22.571), train_loss = 1.21747964, grad/param norm = 1.5682e-01, time/batch = 17.0408s	
13679/30300 (epoch 22.573), train_loss = 1.23229797, grad/param norm = 1.5550e-01, time/batch = 19.2972s	
13680/30300 (epoch 22.574), train_loss = 1.25550534, grad/param norm = 1.4472e-01, time/batch = 19.7834s	
13681/30300 (epoch 22.576), train_loss = 1.16654567, grad/param norm = 1.3858e-01, time/batch = 17.8712s	
13682/30300 (epoch 22.578), train_loss = 1.05180459, grad/param norm = 1.4422e-01, time/batch = 18.6259s	
13683/30300 (epoch 22.579), train_loss = 1.19338894, grad/param norm = 1.5949e-01, time/batch = 18.5378s	
13684/30300 (epoch 22.581), train_loss = 1.27515572, grad/param norm = 1.4143e-01, time/batch = 17.3739s	
13685/30300 (epoch 22.583), train_loss = 1.35663150, grad/param norm = 1.9198e-01, time/batch = 18.7118s	
13686/30300 (epoch 22.584), train_loss = 1.27619321, grad/param norm = 1.4867e-01, time/batch = 19.4589s	
13687/30300 (epoch 22.586), train_loss = 1.16502747, grad/param norm = 1.5002e-01, time/batch = 17.8633s	
13688/30300 (epoch 22.587), train_loss = 1.17855168, grad/param norm = 1.5770e-01, time/batch = 18.7851s	
13689/30300 (epoch 22.589), train_loss = 1.08231901, grad/param norm = 1.5230e-01, time/batch = 18.8679s	
13690/30300 (epoch 22.591), train_loss = 1.23667462, grad/param norm = 1.4386e-01, time/batch = 19.4586s	
13691/30300 (epoch 22.592), train_loss = 1.17421100, grad/param norm = 1.3915e-01, time/batch = 18.4466s	
13692/30300 (epoch 22.594), train_loss = 1.20079037, grad/param norm = 1.5063e-01, time/batch = 19.2189s	
13693/30300 (epoch 22.596), train_loss = 1.10586832, grad/param norm = 1.4398e-01, time/batch = 19.2973s	
13694/30300 (epoch 22.597), train_loss = 1.13188154, grad/param norm = 1.5007e-01, time/batch = 17.8585s	
13695/30300 (epoch 22.599), train_loss = 1.00358718, grad/param norm = 1.4082e-01, time/batch = 19.4512s	
13696/30300 (epoch 22.601), train_loss = 1.21275717, grad/param norm = 1.5591e-01, time/batch = 18.5135s	
13697/30300 (epoch 22.602), train_loss = 1.17596330, grad/param norm = 1.4543e-01, time/batch = 17.9555s	
13698/30300 (epoch 22.604), train_loss = 1.08542607, grad/param norm = 1.4295e-01, time/batch = 19.0502s	
13699/30300 (epoch 22.606), train_loss = 1.13731334, grad/param norm = 1.9877e-01, time/batch = 19.3026s	
13700/30300 (epoch 22.607), train_loss = 1.24819303, grad/param norm = 1.7115e-01, time/batch = 18.2923s	
13701/30300 (epoch 22.609), train_loss = 1.39737257, grad/param norm = 1.8028e-01, time/batch = 19.1239s	
13702/30300 (epoch 22.611), train_loss = 1.12271447, grad/param norm = 1.4350e-01, time/batch = 19.1228s	
13703/30300 (epoch 22.612), train_loss = 1.08040802, grad/param norm = 1.5471e-01, time/batch = 18.2132s	
13704/30300 (epoch 22.614), train_loss = 1.14640424, grad/param norm = 1.4029e-01, time/batch = 18.5456s	
13705/30300 (epoch 22.616), train_loss = 1.23515961, grad/param norm = 1.7005e-01, time/batch = 19.2943s	
13706/30300 (epoch 22.617), train_loss = 1.18816255, grad/param norm = 1.4856e-01, time/batch = 19.2807s	
13707/30300 (epoch 22.619), train_loss = 1.00456509, grad/param norm = 1.4392e-01, time/batch = 18.6987s	
13708/30300 (epoch 22.620), train_loss = 1.19892282, grad/param norm = 1.6551e-01, time/batch = 17.6891s	
13709/30300 (epoch 22.622), train_loss = 1.17219277, grad/param norm = 1.6628e-01, time/batch = 20.0419s	
13710/30300 (epoch 22.624), train_loss = 1.12488284, grad/param norm = 1.5499e-01, time/batch = 17.9538s	
13711/30300 (epoch 22.625), train_loss = 1.13050013, grad/param norm = 1.6350e-01, time/batch = 17.3709s	
13712/30300 (epoch 22.627), train_loss = 1.30103035, grad/param norm = 1.6421e-01, time/batch = 19.8696s	
13713/30300 (epoch 22.629), train_loss = 1.29929918, grad/param norm = 1.5538e-01, time/batch = 17.0437s	
13714/30300 (epoch 22.630), train_loss = 1.18599010, grad/param norm = 1.4431e-01, time/batch = 19.8786s	
13715/30300 (epoch 22.632), train_loss = 1.25833646, grad/param norm = 1.5987e-01, time/batch = 19.7872s	
13716/30300 (epoch 22.634), train_loss = 1.08337254, grad/param norm = 1.3326e-01, time/batch = 17.9569s	
13717/30300 (epoch 22.635), train_loss = 1.22768773, grad/param norm = 1.5850e-01, time/batch = 17.3485s	
13718/30300 (epoch 22.637), train_loss = 1.25619567, grad/param norm = 1.7157e-01, time/batch = 19.8673s	
13719/30300 (epoch 22.639), train_loss = 1.12339909, grad/param norm = 1.4000e-01, time/batch = 18.6946s	
13720/30300 (epoch 22.640), train_loss = 1.32826921, grad/param norm = 1.7601e-01, time/batch = 19.5209s	
13721/30300 (epoch 22.642), train_loss = 1.15428320, grad/param norm = 1.3587e-01, time/batch = 18.4019s	
13722/30300 (epoch 22.644), train_loss = 1.22747679, grad/param norm = 1.3890e-01, time/batch = 18.3782s	
13723/30300 (epoch 22.645), train_loss = 1.07428140, grad/param norm = 1.3556e-01, time/batch = 19.4440s	
13724/30300 (epoch 22.647), train_loss = 1.17490989, grad/param norm = 1.4075e-01, time/batch = 19.5282s	
13725/30300 (epoch 22.649), train_loss = 1.14104766, grad/param norm = 1.5861e-01, time/batch = 18.9481s	
13726/30300 (epoch 22.650), train_loss = 1.18148714, grad/param norm = 1.4625e-01, time/batch = 17.1020s	
13727/30300 (epoch 22.652), train_loss = 1.13277138, grad/param norm = 1.4870e-01, time/batch = 20.2049s	
13728/30300 (epoch 22.653), train_loss = 1.36174549, grad/param norm = 1.6080e-01, time/batch = 17.8860s	
13729/30300 (epoch 22.655), train_loss = 1.10884076, grad/param norm = 1.5002e-01, time/batch = 15.5353s	
13730/30300 (epoch 22.657), train_loss = 1.11940869, grad/param norm = 1.5766e-01, time/batch = 14.8145s	
13731/30300 (epoch 22.658), train_loss = 1.09393393, grad/param norm = 1.4090e-01, time/batch = 16.1290s	
13732/30300 (epoch 22.660), train_loss = 1.19964778, grad/param norm = 1.5485e-01, time/batch = 19.2784s	
13733/30300 (epoch 22.662), train_loss = 1.19810809, grad/param norm = 1.7021e-01, time/batch = 18.6250s	
13734/30300 (epoch 22.663), train_loss = 1.20574488, grad/param norm = 1.5837e-01, time/batch = 18.5516s	
13735/30300 (epoch 22.665), train_loss = 1.12716103, grad/param norm = 1.7556e-01, time/batch = 19.8626s	
13736/30300 (epoch 22.667), train_loss = 1.27803478, grad/param norm = 1.6006e-01, time/batch = 17.4356s	
13737/30300 (epoch 22.668), train_loss = 1.28303915, grad/param norm = 1.5689e-01, time/batch = 18.4513s	
13738/30300 (epoch 22.670), train_loss = 1.29028955, grad/param norm = 1.6907e-01, time/batch = 20.0319s	
13739/30300 (epoch 22.672), train_loss = 1.22245616, grad/param norm = 1.5883e-01, time/batch = 18.5434s	
13740/30300 (epoch 22.673), train_loss = 1.24502676, grad/param norm = 1.6825e-01, time/batch = 19.3607s	
13741/30300 (epoch 22.675), train_loss = 1.14736410, grad/param norm = 1.5811e-01, time/batch = 18.7914s	
13742/30300 (epoch 22.677), train_loss = 1.12788980, grad/param norm = 1.4353e-01, time/batch = 17.9573s	
13743/30300 (epoch 22.678), train_loss = 1.11943384, grad/param norm = 1.4481e-01, time/batch = 20.1842s	
13744/30300 (epoch 22.680), train_loss = 0.99358021, grad/param norm = 1.3688e-01, time/batch = 17.8741s	
13745/30300 (epoch 22.682), train_loss = 1.19395305, grad/param norm = 1.5999e-01, time/batch = 16.6123s	
13746/30300 (epoch 22.683), train_loss = 1.26663520, grad/param norm = 1.3620e-01, time/batch = 19.6941s	
13747/30300 (epoch 22.685), train_loss = 1.27131313, grad/param norm = 1.7059e-01, time/batch = 19.6203s	
13748/30300 (epoch 22.686), train_loss = 1.15992686, grad/param norm = 1.4282e-01, time/batch = 18.7745s	
13749/30300 (epoch 22.688), train_loss = 1.17120833, grad/param norm = 1.4194e-01, time/batch = 18.3678s	
13750/30300 (epoch 22.690), train_loss = 1.13538443, grad/param norm = 1.6458e-01, time/batch = 18.1901s	
13751/30300 (epoch 22.691), train_loss = 1.23594387, grad/param norm = 1.4083e-01, time/batch = 19.5387s	
13752/30300 (epoch 22.693), train_loss = 1.50666522, grad/param norm = 1.6406e-01, time/batch = 19.5211s	
13753/30300 (epoch 22.695), train_loss = 1.29970881, grad/param norm = 1.6167e-01, time/batch = 19.0963s	
13754/30300 (epoch 22.696), train_loss = 1.24875499, grad/param norm = 1.7254e-01, time/batch = 19.3161s	
13755/30300 (epoch 22.698), train_loss = 1.12819089, grad/param norm = 1.4163e-01, time/batch = 18.1348s	
13756/30300 (epoch 22.700), train_loss = 1.12731282, grad/param norm = 1.5063e-01, time/batch = 19.9556s	
13757/30300 (epoch 22.701), train_loss = 1.01377786, grad/param norm = 1.3735e-01, time/batch = 19.2959s	
13758/30300 (epoch 22.703), train_loss = 1.17324154, grad/param norm = 1.3809e-01, time/batch = 18.1199s	
13759/30300 (epoch 22.705), train_loss = 1.13373838, grad/param norm = 1.5008e-01, time/batch = 19.3608s	
13760/30300 (epoch 22.706), train_loss = 1.24329279, grad/param norm = 1.5652e-01, time/batch = 20.2060s	
13761/30300 (epoch 22.708), train_loss = 1.16975043, grad/param norm = 1.4962e-01, time/batch = 16.7586s	
13762/30300 (epoch 22.710), train_loss = 1.17343421, grad/param norm = 1.6303e-01, time/batch = 20.1101s	
13763/30300 (epoch 22.711), train_loss = 1.09212165, grad/param norm = 1.4823e-01, time/batch = 20.1144s	
13764/30300 (epoch 22.713), train_loss = 1.09394680, grad/param norm = 1.5412e-01, time/batch = 17.4458s	
13765/30300 (epoch 22.715), train_loss = 1.12519763, grad/param norm = 1.5048e-01, time/batch = 18.6865s	
13766/30300 (epoch 22.716), train_loss = 1.26807292, grad/param norm = 1.4543e-01, time/batch = 18.6193s	
13767/30300 (epoch 22.718), train_loss = 1.32319859, grad/param norm = 1.6281e-01, time/batch = 19.4672s	
13768/30300 (epoch 22.719), train_loss = 1.14362148, grad/param norm = 1.7293e-01, time/batch = 18.6202s	
13769/30300 (epoch 22.721), train_loss = 1.21124786, grad/param norm = 1.7017e-01, time/batch = 19.7117s	
13770/30300 (epoch 22.723), train_loss = 1.12199767, grad/param norm = 1.4905e-01, time/batch = 19.5210s	
13771/30300 (epoch 22.724), train_loss = 1.21770444, grad/param norm = 1.7462e-01, time/batch = 19.6113s	
13772/30300 (epoch 22.726), train_loss = 1.56061756, grad/param norm = 1.9044e-01, time/batch = 19.0354s	
13773/30300 (epoch 22.728), train_loss = 1.23716189, grad/param norm = 1.5553e-01, time/batch = 19.5466s	
13774/30300 (epoch 22.729), train_loss = 1.14457051, grad/param norm = 1.6108e-01, time/batch = 19.2111s	
13775/30300 (epoch 22.731), train_loss = 1.23335099, grad/param norm = 1.6462e-01, time/batch = 19.1371s	
13776/30300 (epoch 22.733), train_loss = 1.17907205, grad/param norm = 1.4448e-01, time/batch = 18.9949s	
13777/30300 (epoch 22.734), train_loss = 1.24526763, grad/param norm = 1.3852e-01, time/batch = 17.1136s	
13778/30300 (epoch 22.736), train_loss = 1.16302159, grad/param norm = 1.4701e-01, time/batch = 20.6073s	
13779/30300 (epoch 22.738), train_loss = 1.08925316, grad/param norm = 1.3017e-01, time/batch = 19.6250s	
13780/30300 (epoch 22.739), train_loss = 1.24070251, grad/param norm = 1.4540e-01, time/batch = 16.2815s	
13781/30300 (epoch 22.741), train_loss = 1.33014016, grad/param norm = 1.5199e-01, time/batch = 20.3747s	
13782/30300 (epoch 22.743), train_loss = 1.17128255, grad/param norm = 1.5707e-01, time/batch = 19.6200s	
13783/30300 (epoch 22.744), train_loss = 1.22585276, grad/param norm = 1.5010e-01, time/batch = 18.6866s	
13784/30300 (epoch 22.746), train_loss = 1.10589906, grad/param norm = 1.4545e-01, time/batch = 19.4623s	
13785/30300 (epoch 22.748), train_loss = 1.19599220, grad/param norm = 1.9471e-01, time/batch = 18.9587s	
13786/30300 (epoch 22.749), train_loss = 1.23405293, grad/param norm = 1.6712e-01, time/batch = 17.1305s	
13787/30300 (epoch 22.751), train_loss = 1.18587994, grad/param norm = 1.4652e-01, time/batch = 19.3775s	
13788/30300 (epoch 22.752), train_loss = 1.16317769, grad/param norm = 1.6069e-01, time/batch = 17.6860s	
13789/30300 (epoch 22.754), train_loss = 1.10033761, grad/param norm = 1.4150e-01, time/batch = 18.6159s	
13790/30300 (epoch 22.756), train_loss = 1.15333535, grad/param norm = 1.4851e-01, time/batch = 19.2056s	
13791/30300 (epoch 22.757), train_loss = 1.20549430, grad/param norm = 1.6665e-01, time/batch = 17.4580s	
13792/30300 (epoch 22.759), train_loss = 1.21584023, grad/param norm = 1.4300e-01, time/batch = 19.1991s	
13793/30300 (epoch 22.761), train_loss = 1.02113847, grad/param norm = 1.3714e-01, time/batch = 17.8009s	
13794/30300 (epoch 22.762), train_loss = 1.07767738, grad/param norm = 1.4708e-01, time/batch = 20.0365s	
13795/30300 (epoch 22.764), train_loss = 1.16811996, grad/param norm = 1.6270e-01, time/batch = 19.5388s	
13796/30300 (epoch 22.766), train_loss = 1.26169347, grad/param norm = 1.6612e-01, time/batch = 17.0908s	
13797/30300 (epoch 22.767), train_loss = 1.25466395, grad/param norm = 1.7259e-01, time/batch = 18.8673s	
13798/30300 (epoch 22.769), train_loss = 1.23510280, grad/param norm = 1.5695e-01, time/batch = 19.5489s	
13799/30300 (epoch 22.771), train_loss = 1.13645898, grad/param norm = 1.8750e-01, time/batch = 18.4684s	
13800/30300 (epoch 22.772), train_loss = 1.25199395, grad/param norm = 1.6429e-01, time/batch = 18.8083s	
13801/30300 (epoch 22.774), train_loss = 1.32842553, grad/param norm = 1.4867e-01, time/batch = 19.8840s	
13802/30300 (epoch 22.776), train_loss = 1.21102158, grad/param norm = 1.6458e-01, time/batch = 18.2052s	
13803/30300 (epoch 22.777), train_loss = 1.28101041, grad/param norm = 1.5448e-01, time/batch = 37.6737s	
13804/30300 (epoch 22.779), train_loss = 1.35857387, grad/param norm = 1.7869e-01, time/batch = 32.4208s	
13805/30300 (epoch 22.781), train_loss = 1.20211089, grad/param norm = 1.7866e-01, time/batch = 37.1320s	
13806/30300 (epoch 22.782), train_loss = 1.13271686, grad/param norm = 1.4211e-01, time/batch = 39.3126s	
13807/30300 (epoch 22.784), train_loss = 1.12276957, grad/param norm = 1.4979e-01, time/batch = 45.0132s	
13808/30300 (epoch 22.785), train_loss = 1.34602435, grad/param norm = 1.8994e-01, time/batch = 61.6106s	
13809/30300 (epoch 22.787), train_loss = 1.01933196, grad/param norm = 1.5188e-01, time/batch = 38.5691s	
13810/30300 (epoch 22.789), train_loss = 1.42729971, grad/param norm = 1.6040e-01, time/batch = 38.9766s	
13811/30300 (epoch 22.790), train_loss = 1.26155414, grad/param norm = 2.0139e-01, time/batch = 22.5715s	
13812/30300 (epoch 22.792), train_loss = 1.02838792, grad/param norm = 1.6838e-01, time/batch = 17.0481s	
13813/30300 (epoch 22.794), train_loss = 1.18144629, grad/param norm = 1.6130e-01, time/batch = 18.6338s	
13814/30300 (epoch 22.795), train_loss = 1.10215358, grad/param norm = 1.3941e-01, time/batch = 17.4466s	
13815/30300 (epoch 22.797), train_loss = 1.34093046, grad/param norm = 1.8401e-01, time/batch = 17.9276s	
13816/30300 (epoch 22.799), train_loss = 1.25765189, grad/param norm = 1.6879e-01, time/batch = 18.2995s	
13817/30300 (epoch 22.800), train_loss = 1.26119755, grad/param norm = 1.5180e-01, time/batch = 19.6325s	
13818/30300 (epoch 22.802), train_loss = 1.42257260, grad/param norm = 1.9498e-01, time/batch = 17.4383s	
13819/30300 (epoch 22.804), train_loss = 1.29802578, grad/param norm = 1.6683e-01, time/batch = 17.1272s	
13820/30300 (epoch 22.805), train_loss = 1.34145225, grad/param norm = 1.6562e-01, time/batch = 18.6391s	
13821/30300 (epoch 22.807), train_loss = 1.16132433, grad/param norm = 1.5474e-01, time/batch = 18.2261s	
13822/30300 (epoch 22.809), train_loss = 1.28093798, grad/param norm = 1.7457e-01, time/batch = 18.7773s	
13823/30300 (epoch 22.810), train_loss = 1.27933356, grad/param norm = 1.6236e-01, time/batch = 18.9736s	
13824/30300 (epoch 22.812), train_loss = 1.11636957, grad/param norm = 1.5808e-01, time/batch = 18.6898s	
13825/30300 (epoch 22.814), train_loss = 1.19846033, grad/param norm = 1.6215e-01, time/batch = 17.8788s	
13826/30300 (epoch 22.815), train_loss = 1.22636607, grad/param norm = 1.6219e-01, time/batch = 19.2105s	
13827/30300 (epoch 22.817), train_loss = 1.31241310, grad/param norm = 1.7348e-01, time/batch = 20.1255s	
13828/30300 (epoch 22.818), train_loss = 1.25808805, grad/param norm = 1.5433e-01, time/batch = 18.7832s	
13829/30300 (epoch 22.820), train_loss = 1.38632206, grad/param norm = 1.7777e-01, time/batch = 18.9610s	
13830/30300 (epoch 22.822), train_loss = 1.36648975, grad/param norm = 1.7008e-01, time/batch = 17.4469s	
13831/30300 (epoch 22.823), train_loss = 1.39530878, grad/param norm = 1.8421e-01, time/batch = 18.3797s	
13832/30300 (epoch 22.825), train_loss = 1.31282920, grad/param norm = 1.6215e-01, time/batch = 19.1939s	
13833/30300 (epoch 22.827), train_loss = 1.04064654, grad/param norm = 1.6490e-01, time/batch = 19.5490s	
13834/30300 (epoch 22.828), train_loss = 1.28595228, grad/param norm = 1.6180e-01, time/batch = 18.0426s	
13835/30300 (epoch 22.830), train_loss = 1.24970229, grad/param norm = 1.5387e-01, time/batch = 19.4645s	
13836/30300 (epoch 22.832), train_loss = 1.11239824, grad/param norm = 1.6162e-01, time/batch = 18.7114s	
13837/30300 (epoch 22.833), train_loss = 1.25143595, grad/param norm = 1.6832e-01, time/batch = 17.7019s	
13838/30300 (epoch 22.835), train_loss = 1.11477765, grad/param norm = 1.4112e-01, time/batch = 18.9350s	
13839/30300 (epoch 22.837), train_loss = 1.05956093, grad/param norm = 1.4022e-01, time/batch = 20.1891s	
13840/30300 (epoch 22.838), train_loss = 1.08704853, grad/param norm = 1.4175e-01, time/batch = 17.8698s	
13841/30300 (epoch 22.840), train_loss = 1.27782609, grad/param norm = 1.3873e-01, time/batch = 19.1191s	
13842/30300 (epoch 22.842), train_loss = 1.12895898, grad/param norm = 1.5213e-01, time/batch = 19.2960s	
13843/30300 (epoch 22.843), train_loss = 1.23724751, grad/param norm = 1.4834e-01, time/batch = 19.0148s	
13844/30300 (epoch 22.845), train_loss = 1.24329164, grad/param norm = 1.4692e-01, time/batch = 18.9316s	
13845/30300 (epoch 22.847), train_loss = 1.22176625, grad/param norm = 1.5516e-01, time/batch = 19.4546s	
13846/30300 (epoch 22.848), train_loss = 1.29261140, grad/param norm = 1.5985e-01, time/batch = 19.2928s	
13847/30300 (epoch 22.850), train_loss = 1.20702697, grad/param norm = 1.5553e-01, time/batch = 18.5248s	
13848/30300 (epoch 22.851), train_loss = 1.24839753, grad/param norm = 1.9227e-01, time/batch = 19.7758s	
13849/30300 (epoch 22.853), train_loss = 1.16626038, grad/param norm = 1.4084e-01, time/batch = 19.6181s	
13850/30300 (epoch 22.855), train_loss = 1.14072058, grad/param norm = 1.3266e-01, time/batch = 18.1928s	
13851/30300 (epoch 22.856), train_loss = 1.21972862, grad/param norm = 1.5453e-01, time/batch = 19.1245s	
13852/30300 (epoch 22.858), train_loss = 1.13180417, grad/param norm = 1.4748e-01, time/batch = 19.8656s	
13853/30300 (epoch 22.860), train_loss = 1.10355330, grad/param norm = 1.3954e-01, time/batch = 16.8610s	
13854/30300 (epoch 22.861), train_loss = 1.36635614, grad/param norm = 1.5476e-01, time/batch = 19.3887s	
13855/30300 (epoch 22.863), train_loss = 1.21147546, grad/param norm = 1.3938e-01, time/batch = 19.8570s	
13856/30300 (epoch 22.865), train_loss = 1.27915925, grad/param norm = 1.7414e-01, time/batch = 17.5876s	
13857/30300 (epoch 22.866), train_loss = 1.29069932, grad/param norm = 1.7454e-01, time/batch = 19.8831s	
13858/30300 (epoch 22.868), train_loss = 1.20393478, grad/param norm = 1.5117e-01, time/batch = 19.2914s	
13859/30300 (epoch 22.870), train_loss = 1.12418483, grad/param norm = 1.5148e-01, time/batch = 18.2987s	
13860/30300 (epoch 22.871), train_loss = 1.16483494, grad/param norm = 1.4415e-01, time/batch = 19.4737s	
13861/30300 (epoch 22.873), train_loss = 1.20163580, grad/param norm = 1.4562e-01, time/batch = 19.6253s	
13862/30300 (epoch 22.875), train_loss = 1.12055476, grad/param norm = 1.3560e-01, time/batch = 18.5368s	
13863/30300 (epoch 22.876), train_loss = 1.08975520, grad/param norm = 1.6818e-01, time/batch = 18.6252s	
13864/30300 (epoch 22.878), train_loss = 1.04125443, grad/param norm = 1.4850e-01, time/batch = 19.3864s	
13865/30300 (epoch 22.880), train_loss = 1.09666657, grad/param norm = 1.4514e-01, time/batch = 19.0327s	
13866/30300 (epoch 22.881), train_loss = 1.36238455, grad/param norm = 1.9674e-01, time/batch = 19.6864s	
13867/30300 (epoch 22.883), train_loss = 1.25214352, grad/param norm = 1.5875e-01, time/batch = 18.9541s	
13868/30300 (epoch 22.884), train_loss = 1.12880551, grad/param norm = 1.3475e-01, time/batch = 19.2029s	
13869/30300 (epoch 22.886), train_loss = 1.23077727, grad/param norm = 1.3906e-01, time/batch = 18.2849s	
13870/30300 (epoch 22.888), train_loss = 1.19381982, grad/param norm = 1.6041e-01, time/batch = 18.9429s	
13871/30300 (epoch 22.889), train_loss = 1.23114527, grad/param norm = 1.4653e-01, time/batch = 19.7780s	
13872/30300 (epoch 22.891), train_loss = 1.22124115, grad/param norm = 1.6704e-01, time/batch = 19.2652s	
13873/30300 (epoch 22.893), train_loss = 1.42034519, grad/param norm = 1.5717e-01, time/batch = 18.6305s	
13874/30300 (epoch 22.894), train_loss = 1.27360326, grad/param norm = 1.5688e-01, time/batch = 19.1374s	
13875/30300 (epoch 22.896), train_loss = 1.04338331, grad/param norm = 1.7115e-01, time/batch = 18.2951s	
13876/30300 (epoch 22.898), train_loss = 1.00644655, grad/param norm = 1.4492e-01, time/batch = 19.4455s	
13877/30300 (epoch 22.899), train_loss = 1.11509926, grad/param norm = 1.6170e-01, time/batch = 18.4746s	
13878/30300 (epoch 22.901), train_loss = 1.18137931, grad/param norm = 1.6386e-01, time/batch = 17.1869s	
13879/30300 (epoch 22.903), train_loss = 1.22350760, grad/param norm = 1.5489e-01, time/batch = 16.7047s	
13880/30300 (epoch 22.904), train_loss = 1.17306967, grad/param norm = 1.5335e-01, time/batch = 19.7149s	
13881/30300 (epoch 22.906), train_loss = 1.28208158, grad/param norm = 1.5343e-01, time/batch = 20.3059s	
13882/30300 (epoch 22.908), train_loss = 1.14971061, grad/param norm = 1.4600e-01, time/batch = 20.4173s	
13883/30300 (epoch 22.909), train_loss = 1.09525804, grad/param norm = 1.4923e-01, time/batch = 22.8528s	
13884/30300 (epoch 22.911), train_loss = 1.19233599, grad/param norm = 1.4179e-01, time/batch = 21.6978s	
13885/30300 (epoch 22.913), train_loss = 1.17364246, grad/param norm = 1.4236e-01, time/batch = 23.3507s	
13886/30300 (epoch 22.914), train_loss = 1.14042441, grad/param norm = 1.4965e-01, time/batch = 22.7190s	
13887/30300 (epoch 22.916), train_loss = 1.20732070, grad/param norm = 1.4107e-01, time/batch = 21.6037s	
13888/30300 (epoch 22.917), train_loss = 1.13564713, grad/param norm = 1.5265e-01, time/batch = 23.1849s	
13889/30300 (epoch 22.919), train_loss = 1.15727309, grad/param norm = 1.6246e-01, time/batch = 23.0288s	
13890/30300 (epoch 22.921), train_loss = 1.19556353, grad/param norm = 1.5040e-01, time/batch = 22.2595s	
13891/30300 (epoch 22.922), train_loss = 1.29372550, grad/param norm = 1.7155e-01, time/batch = 22.0500s	
13892/30300 (epoch 22.924), train_loss = 1.20223066, grad/param norm = 1.6328e-01, time/batch = 22.1264s	
13893/30300 (epoch 22.926), train_loss = 1.21828484, grad/param norm = 1.5234e-01, time/batch = 21.3824s	
13894/30300 (epoch 22.927), train_loss = 1.20306628, grad/param norm = 1.5354e-01, time/batch = 20.6264s	
13895/30300 (epoch 22.929), train_loss = 1.12889700, grad/param norm = 1.6154e-01, time/batch = 21.3827s	
13896/30300 (epoch 22.931), train_loss = 1.31835108, grad/param norm = 1.8957e-01, time/batch = 28.7328s	
13897/30300 (epoch 22.932), train_loss = 1.13795063, grad/param norm = 1.5949e-01, time/batch = 22.3264s	
13898/30300 (epoch 22.934), train_loss = 1.21657656, grad/param norm = 1.5553e-01, time/batch = 18.6005s	
13899/30300 (epoch 22.936), train_loss = 1.15189963, grad/param norm = 1.4466e-01, time/batch = 18.6293s	
13900/30300 (epoch 22.937), train_loss = 1.11699152, grad/param norm = 1.4634e-01, time/batch = 17.8083s	
13901/30300 (epoch 22.939), train_loss = 1.32614169, grad/param norm = 1.9829e-01, time/batch = 19.6001s	
13902/30300 (epoch 22.941), train_loss = 1.17908812, grad/param norm = 1.6348e-01, time/batch = 19.3703s	
13903/30300 (epoch 22.942), train_loss = 1.18047633, grad/param norm = 1.6268e-01, time/batch = 19.0271s	
13904/30300 (epoch 22.944), train_loss = 1.08208254, grad/param norm = 1.4533e-01, time/batch = 18.1177s	
13905/30300 (epoch 22.946), train_loss = 1.30702767, grad/param norm = 1.8381e-01, time/batch = 20.0326s	
13906/30300 (epoch 22.947), train_loss = 1.28524986, grad/param norm = 1.6905e-01, time/batch = 19.3845s	
13907/30300 (epoch 22.949), train_loss = 1.35370830, grad/param norm = 1.8101e-01, time/batch = 18.9420s	
13908/30300 (epoch 22.950), train_loss = 1.29876612, grad/param norm = 1.5762e-01, time/batch = 18.9523s	
13909/30300 (epoch 22.952), train_loss = 1.25949386, grad/param norm = 1.7656e-01, time/batch = 18.6943s	
13910/30300 (epoch 22.954), train_loss = 1.46852700, grad/param norm = 1.5797e-01, time/batch = 17.7801s	
13911/30300 (epoch 22.955), train_loss = 1.16178080, grad/param norm = 1.7393e-01, time/batch = 19.1181s	
13912/30300 (epoch 22.957), train_loss = 1.25402415, grad/param norm = 1.5142e-01, time/batch = 19.8705s	
13913/30300 (epoch 22.959), train_loss = 1.13504694, grad/param norm = 1.5434e-01, time/batch = 18.1237s	
13914/30300 (epoch 22.960), train_loss = 1.18791482, grad/param norm = 2.2660e-01, time/batch = 20.2126s	
13915/30300 (epoch 22.962), train_loss = 1.22323802, grad/param norm = 2.3503e-01, time/batch = 17.1784s	
13916/30300 (epoch 22.964), train_loss = 1.12403811, grad/param norm = 1.9096e-01, time/batch = 17.1313s	
13917/30300 (epoch 22.965), train_loss = 1.11970442, grad/param norm = 1.7505e-01, time/batch = 18.9584s	
13918/30300 (epoch 22.967), train_loss = 1.21371408, grad/param norm = 1.8382e-01, time/batch = 17.8011s	
13919/30300 (epoch 22.969), train_loss = 1.10821027, grad/param norm = 1.6459e-01, time/batch = 18.2820s	
13920/30300 (epoch 22.970), train_loss = 1.15847862, grad/param norm = 1.5245e-01, time/batch = 18.4610s	
13921/30300 (epoch 22.972), train_loss = 1.07659910, grad/param norm = 1.5387e-01, time/batch = 19.6201s	
13922/30300 (epoch 22.974), train_loss = 1.37912004, grad/param norm = 1.9865e-01, time/batch = 18.5500s	
13923/30300 (epoch 22.975), train_loss = 1.40414814, grad/param norm = 1.9210e-01, time/batch = 18.6251s	
13924/30300 (epoch 22.977), train_loss = 1.31373445, grad/param norm = 1.6787e-01, time/batch = 18.8100s	
13925/30300 (epoch 22.979), train_loss = 1.26828269, grad/param norm = 1.6563e-01, time/batch = 19.7063s	
13926/30300 (epoch 22.980), train_loss = 1.29101496, grad/param norm = 1.9092e-01, time/batch = 18.4568s	
13927/30300 (epoch 22.982), train_loss = 1.27340935, grad/param norm = 1.5984e-01, time/batch = 18.7824s	
13928/30300 (epoch 22.983), train_loss = 1.32042786, grad/param norm = 1.6119e-01, time/batch = 19.8769s	
13929/30300 (epoch 22.985), train_loss = 1.26302425, grad/param norm = 1.8364e-01, time/batch = 17.5337s	
13930/30300 (epoch 22.987), train_loss = 1.17742277, grad/param norm = 1.4441e-01, time/batch = 19.4557s	
13931/30300 (epoch 22.988), train_loss = 1.33599165, grad/param norm = 1.6018e-01, time/batch = 17.0334s	
13932/30300 (epoch 22.990), train_loss = 1.03961377, grad/param norm = 1.3144e-01, time/batch = 19.1963s	
13933/30300 (epoch 22.992), train_loss = 1.26312229, grad/param norm = 1.4365e-01, time/batch = 19.7834s	
13934/30300 (epoch 22.993), train_loss = 1.34757980, grad/param norm = 1.9913e-01, time/batch = 18.5555s	
13935/30300 (epoch 22.995), train_loss = 1.18635902, grad/param norm = 1.7036e-01, time/batch = 19.3798s	
13936/30300 (epoch 22.997), train_loss = 1.24287047, grad/param norm = 1.6168e-01, time/batch = 19.1357s	
13937/30300 (epoch 22.998), train_loss = 1.29223542, grad/param norm = 1.9128e-01, time/batch = 19.3768s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
13938/30300 (epoch 23.000), train_loss = 1.15925911, grad/param norm = 1.7122e-01, time/batch = 18.7915s	
13939/30300 (epoch 23.002), train_loss = 1.29906227, grad/param norm = 1.7056e-01, time/batch = 16.4541s	
13940/30300 (epoch 23.003), train_loss = 1.20887436, grad/param norm = 1.7498e-01, time/batch = 19.3661s	
13941/30300 (epoch 23.005), train_loss = 1.18206146, grad/param norm = 1.6401e-01, time/batch = 20.1389s	
13942/30300 (epoch 23.007), train_loss = 1.27464573, grad/param norm = 1.7651e-01, time/batch = 17.6974s	
13943/30300 (epoch 23.008), train_loss = 1.14155621, grad/param norm = 1.5794e-01, time/batch = 17.4240s	
13944/30300 (epoch 23.010), train_loss = 1.09098166, grad/param norm = 1.5540e-01, time/batch = 17.7681s	
13945/30300 (epoch 23.012), train_loss = 1.14263968, grad/param norm = 1.5049e-01, time/batch = 18.4324s	
13946/30300 (epoch 23.013), train_loss = 1.31108137, grad/param norm = 1.7155e-01, time/batch = 18.3724s	
13947/30300 (epoch 23.015), train_loss = 1.15923136, grad/param norm = 1.4996e-01, time/batch = 19.5449s	
13948/30300 (epoch 23.017), train_loss = 1.14772377, grad/param norm = 1.4035e-01, time/batch = 17.8682s	
13949/30300 (epoch 23.018), train_loss = 1.11257787, grad/param norm = 1.4635e-01, time/batch = 16.4295s	
13950/30300 (epoch 23.020), train_loss = 1.30084454, grad/param norm = 1.7694e-01, time/batch = 18.1049s	
13951/30300 (epoch 23.021), train_loss = 1.31415075, grad/param norm = 1.6289e-01, time/batch = 18.7836s	
13952/30300 (epoch 23.023), train_loss = 1.19953492, grad/param norm = 1.4822e-01, time/batch = 18.4517s	
13953/30300 (epoch 23.025), train_loss = 1.11711403, grad/param norm = 1.6303e-01, time/batch = 19.0481s	
13954/30300 (epoch 23.026), train_loss = 1.24033653, grad/param norm = 1.7129e-01, time/batch = 19.4636s	
13955/30300 (epoch 23.028), train_loss = 1.28433538, grad/param norm = 1.5765e-01, time/batch = 18.4467s	
13956/30300 (epoch 23.030), train_loss = 1.12769035, grad/param norm = 1.5642e-01, time/batch = 19.2858s	
13957/30300 (epoch 23.031), train_loss = 1.23256004, grad/param norm = 1.5165e-01, time/batch = 19.4574s	
13958/30300 (epoch 23.033), train_loss = 1.18182796, grad/param norm = 1.6229e-01, time/batch = 17.7805s	
13959/30300 (epoch 23.035), train_loss = 1.28380180, grad/param norm = 1.7577e-01, time/batch = 18.2956s	
13960/30300 (epoch 23.036), train_loss = 1.19934074, grad/param norm = 1.6005e-01, time/batch = 18.8021s	
13961/30300 (epoch 23.038), train_loss = 1.23627615, grad/param norm = 1.4685e-01, time/batch = 17.2370s	
13962/30300 (epoch 23.040), train_loss = 0.94370258, grad/param norm = 1.3251e-01, time/batch = 18.7631s	
13963/30300 (epoch 23.041), train_loss = 1.00378659, grad/param norm = 1.4279e-01, time/batch = 18.7845s	
13964/30300 (epoch 23.043), train_loss = 1.20164715, grad/param norm = 1.5498e-01, time/batch = 18.1867s	
13965/30300 (epoch 23.045), train_loss = 1.17556319, grad/param norm = 1.4502e-01, time/batch = 18.6962s	
13966/30300 (epoch 23.046), train_loss = 1.34614426, grad/param norm = 1.7130e-01, time/batch = 18.8772s	
13967/30300 (epoch 23.048), train_loss = 1.18872725, grad/param norm = 1.6709e-01, time/batch = 19.2157s	
13968/30300 (epoch 23.050), train_loss = 1.15779071, grad/param norm = 1.5226e-01, time/batch = 18.5382s	
13969/30300 (epoch 23.051), train_loss = 1.22394551, grad/param norm = 1.7015e-01, time/batch = 18.4578s	
13970/30300 (epoch 23.053), train_loss = 1.02723857, grad/param norm = 1.7532e-01, time/batch = 19.9668s	
13971/30300 (epoch 23.054), train_loss = 1.18861968, grad/param norm = 1.5832e-01, time/batch = 18.2784s	
13972/30300 (epoch 23.056), train_loss = 1.11780797, grad/param norm = 1.4590e-01, time/batch = 19.7932s	
13973/30300 (epoch 23.058), train_loss = 1.16279035, grad/param norm = 1.4606e-01, time/batch = 19.1983s	
13974/30300 (epoch 23.059), train_loss = 1.10649777, grad/param norm = 1.6198e-01, time/batch = 17.0290s	
13975/30300 (epoch 23.061), train_loss = 1.26783522, grad/param norm = 1.7036e-01, time/batch = 19.7070s	
13976/30300 (epoch 23.063), train_loss = 1.08854487, grad/param norm = 1.5330e-01, time/batch = 19.8499s	
13977/30300 (epoch 23.064), train_loss = 1.20056996, grad/param norm = 1.5693e-01, time/batch = 16.6582s	
13978/30300 (epoch 23.066), train_loss = 1.18146961, grad/param norm = 1.4595e-01, time/batch = 19.5445s	
13979/30300 (epoch 23.068), train_loss = 1.08450333, grad/param norm = 1.5306e-01, time/batch = 19.2882s	
13980/30300 (epoch 23.069), train_loss = 1.24918643, grad/param norm = 1.5430e-01, time/batch = 18.1287s	
13981/30300 (epoch 23.071), train_loss = 1.25252243, grad/param norm = 1.6778e-01, time/batch = 18.4690s	
13982/30300 (epoch 23.073), train_loss = 1.16075862, grad/param norm = 1.7224e-01, time/batch = 19.5457s	
13983/30300 (epoch 23.074), train_loss = 1.22305980, grad/param norm = 1.4340e-01, time/batch = 19.2772s	
13984/30300 (epoch 23.076), train_loss = 1.14081069, grad/param norm = 1.4079e-01, time/batch = 18.3045s	
13985/30300 (epoch 23.078), train_loss = 1.09884807, grad/param norm = 1.4336e-01, time/batch = 18.7929s	
13986/30300 (epoch 23.079), train_loss = 1.12075505, grad/param norm = 1.4193e-01, time/batch = 19.3775s	
13987/30300 (epoch 23.081), train_loss = 1.20013650, grad/param norm = 1.5857e-01, time/batch = 18.9494s	
13988/30300 (epoch 23.083), train_loss = 1.26477758, grad/param norm = 1.8129e-01, time/batch = 18.7232s	
13989/30300 (epoch 23.084), train_loss = 1.08310857, grad/param norm = 1.5046e-01, time/batch = 19.6192s	
13990/30300 (epoch 23.086), train_loss = 1.13673244, grad/param norm = 1.6076e-01, time/batch = 25.0912s	
13991/30300 (epoch 23.087), train_loss = 1.10755917, grad/param norm = 1.4545e-01, time/batch = 28.9207s	
13992/30300 (epoch 23.089), train_loss = 1.15267293, grad/param norm = 1.4859e-01, time/batch = 18.4573s	
13993/30300 (epoch 23.091), train_loss = 1.22182067, grad/param norm = 1.5602e-01, time/batch = 18.7907s	
13994/30300 (epoch 23.092), train_loss = 1.23290342, grad/param norm = 1.5223e-01, time/batch = 19.0415s	
13995/30300 (epoch 23.094), train_loss = 1.35165214, grad/param norm = 1.9421e-01, time/batch = 18.1190s	
13996/30300 (epoch 23.096), train_loss = 1.28363671, grad/param norm = 1.5967e-01, time/batch = 19.9580s	
13997/30300 (epoch 23.097), train_loss = 1.15439240, grad/param norm = 1.7085e-01, time/batch = 18.7897s	
13998/30300 (epoch 23.099), train_loss = 1.29040420, grad/param norm = 1.5939e-01, time/batch = 18.3032s	
13999/30300 (epoch 23.101), train_loss = 1.33173811, grad/param norm = 1.6989e-01, time/batch = 17.0245s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch23.10_1.8177.t7	
14000/30300 (epoch 23.102), train_loss = 1.12663100, grad/param norm = 1.8562e-01, time/batch = 19.1292s	
14001/30300 (epoch 23.104), train_loss = 1.63561418, grad/param norm = 2.3407e-01, time/batch = 18.1989s	
14002/30300 (epoch 23.106), train_loss = 1.15313743, grad/param norm = 1.6169e-01, time/batch = 19.3629s	
14003/30300 (epoch 23.107), train_loss = 1.21855760, grad/param norm = 1.5227e-01, time/batch = 19.6993s	
14004/30300 (epoch 23.109), train_loss = 1.28817993, grad/param norm = 2.0972e-01, time/batch = 18.4592s	
14005/30300 (epoch 23.111), train_loss = 1.31029290, grad/param norm = 1.7306e-01, time/batch = 18.6192s	
14006/30300 (epoch 23.112), train_loss = 1.27548768, grad/param norm = 1.6284e-01, time/batch = 19.7828s	
14007/30300 (epoch 23.114), train_loss = 1.18376784, grad/param norm = 1.5969e-01, time/batch = 19.5417s	
14008/30300 (epoch 23.116), train_loss = 1.19044611, grad/param norm = 1.8914e-01, time/batch = 18.6220s	
14009/30300 (epoch 23.117), train_loss = 1.23283992, grad/param norm = 1.4712e-01, time/batch = 18.9658s	
14010/30300 (epoch 23.119), train_loss = 1.12586556, grad/param norm = 1.6888e-01, time/batch = 18.8712s	
14011/30300 (epoch 23.120), train_loss = 1.20655916, grad/param norm = 1.6869e-01, time/batch = 18.7927s	
14012/30300 (epoch 23.122), train_loss = 1.29004051, grad/param norm = 1.7983e-01, time/batch = 19.1255s	
14013/30300 (epoch 23.124), train_loss = 1.35579827, grad/param norm = 1.7757e-01, time/batch = 18.7856s	
14014/30300 (epoch 23.125), train_loss = 1.05152505, grad/param norm = 1.4374e-01, time/batch = 18.9472s	
14015/30300 (epoch 23.127), train_loss = 1.24731267, grad/param norm = 1.8834e-01, time/batch = 18.3854s	
14016/30300 (epoch 23.129), train_loss = 1.33614162, grad/param norm = 1.6424e-01, time/batch = 18.6161s	
14017/30300 (epoch 23.130), train_loss = 1.32958669, grad/param norm = 1.5446e-01, time/batch = 17.8851s	
14018/30300 (epoch 23.132), train_loss = 1.32017951, grad/param norm = 1.7707e-01, time/batch = 20.4477s	
14019/30300 (epoch 23.134), train_loss = 1.10664439, grad/param norm = 1.5151e-01, time/batch = 19.1279s	
14020/30300 (epoch 23.135), train_loss = 1.14206299, grad/param norm = 1.6946e-01, time/batch = 16.6218s	
14021/30300 (epoch 23.137), train_loss = 1.19748227, grad/param norm = 1.5176e-01, time/batch = 19.7865s	
14022/30300 (epoch 23.139), train_loss = 1.17777531, grad/param norm = 1.9021e-01, time/batch = 19.7098s	
14023/30300 (epoch 23.140), train_loss = 1.23760144, grad/param norm = 2.1620e-01, time/batch = 18.5328s	
14024/30300 (epoch 23.142), train_loss = 1.36160275, grad/param norm = 2.0350e-01, time/batch = 19.4487s	
14025/30300 (epoch 23.144), train_loss = 1.21644180, grad/param norm = 2.0223e-01, time/batch = 17.3274s	
14026/30300 (epoch 23.145), train_loss = 1.32856766, grad/param norm = 2.0111e-01, time/batch = 19.0374s	
14027/30300 (epoch 23.147), train_loss = 1.18862844, grad/param norm = 1.7504e-01, time/batch = 18.0407s	
14028/30300 (epoch 23.149), train_loss = 1.38987732, grad/param norm = 1.7692e-01, time/batch = 19.8639s	
14029/30300 (epoch 23.150), train_loss = 1.19835916, grad/param norm = 1.7892e-01, time/batch = 18.1242s	
14030/30300 (epoch 23.152), train_loss = 1.09169908, grad/param norm = 1.8118e-01, time/batch = 19.0257s	
14031/30300 (epoch 23.153), train_loss = 1.18762543, grad/param norm = 1.5430e-01, time/batch = 19.6878s	
14032/30300 (epoch 23.155), train_loss = 1.04940989, grad/param norm = 1.5471e-01, time/batch = 18.6262s	
14033/30300 (epoch 23.157), train_loss = 1.17640466, grad/param norm = 1.6729e-01, time/batch = 18.7101s	
14034/30300 (epoch 23.158), train_loss = 1.20810650, grad/param norm = 1.8718e-01, time/batch = 20.1214s	
14035/30300 (epoch 23.160), train_loss = 1.11597436, grad/param norm = 1.5338e-01, time/batch = 19.1346s	
14036/30300 (epoch 23.162), train_loss = 1.16629315, grad/param norm = 1.4769e-01, time/batch = 17.3331s	
14037/30300 (epoch 23.163), train_loss = 1.16556153, grad/param norm = 1.7134e-01, time/batch = 20.0987s	
14038/30300 (epoch 23.165), train_loss = 1.30181917, grad/param norm = 1.5056e-01, time/batch = 19.7036s	
14039/30300 (epoch 23.167), train_loss = 1.17497946, grad/param norm = 1.6790e-01, time/batch = 17.4642s	
14040/30300 (epoch 23.168), train_loss = 1.25650620, grad/param norm = 1.6482e-01, time/batch = 18.7914s	
14041/30300 (epoch 23.170), train_loss = 1.22245867, grad/param norm = 1.6521e-01, time/batch = 20.0341s	
14042/30300 (epoch 23.172), train_loss = 1.18729087, grad/param norm = 1.9397e-01, time/batch = 18.1172s	
14043/30300 (epoch 23.173), train_loss = 1.19259475, grad/param norm = 1.8291e-01, time/batch = 19.9620s	
14044/30300 (epoch 23.175), train_loss = 1.20696658, grad/param norm = 1.4800e-01, time/batch = 19.4461s	
14045/30300 (epoch 23.177), train_loss = 1.24232693, grad/param norm = 1.7521e-01, time/batch = 18.6103s	
14046/30300 (epoch 23.178), train_loss = 0.98135322, grad/param norm = 1.4696e-01, time/batch = 17.7108s	
14047/30300 (epoch 23.180), train_loss = 1.18619799, grad/param norm = 1.5042e-01, time/batch = 18.0497s	
14048/30300 (epoch 23.182), train_loss = 1.16859118, grad/param norm = 1.7093e-01, time/batch = 18.9543s	
14049/30300 (epoch 23.183), train_loss = 1.13035223, grad/param norm = 1.5403e-01, time/batch = 19.0380s	
14050/30300 (epoch 23.185), train_loss = 1.38938891, grad/param norm = 1.6121e-01, time/batch = 19.5846s	
14051/30300 (epoch 23.186), train_loss = 1.43029110, grad/param norm = 1.8295e-01, time/batch = 18.8788s	
14052/30300 (epoch 23.188), train_loss = 1.24799915, grad/param norm = 1.7304e-01, time/batch = 18.9488s	
14053/30300 (epoch 23.190), train_loss = 1.18693721, grad/param norm = 1.4805e-01, time/batch = 19.9773s	
14054/30300 (epoch 23.191), train_loss = 1.27051226, grad/param norm = 1.6327e-01, time/batch = 19.0531s	
14055/30300 (epoch 23.193), train_loss = 1.11912634, grad/param norm = 1.4213e-01, time/batch = 18.8706s	
14056/30300 (epoch 23.195), train_loss = 1.20135197, grad/param norm = 1.5465e-01, time/batch = 18.9559s	
14057/30300 (epoch 23.196), train_loss = 1.22473968, grad/param norm = 1.3936e-01, time/batch = 19.0379s	
14058/30300 (epoch 23.198), train_loss = 1.01151133, grad/param norm = 1.4396e-01, time/batch = 17.6130s	
14059/30300 (epoch 23.200), train_loss = 1.19335681, grad/param norm = 1.5231e-01, time/batch = 19.2899s	
14060/30300 (epoch 23.201), train_loss = 1.27334270, grad/param norm = 1.8758e-01, time/batch = 19.2976s	
14061/30300 (epoch 23.203), train_loss = 1.21278475, grad/param norm = 1.5802e-01, time/batch = 18.4479s	
14062/30300 (epoch 23.205), train_loss = 1.40537163, grad/param norm = 1.6939e-01, time/batch = 19.4684s	
14063/30300 (epoch 23.206), train_loss = 1.31590629, grad/param norm = 1.8326e-01, time/batch = 19.1172s	
14064/30300 (epoch 23.208), train_loss = 1.28875357, grad/param norm = 1.7686e-01, time/batch = 17.7145s	
14065/30300 (epoch 23.210), train_loss = 1.26134250, grad/param norm = 1.6354e-01, time/batch = 19.9741s	
14066/30300 (epoch 23.211), train_loss = 1.31514879, grad/param norm = 1.6388e-01, time/batch = 18.0353s	
14067/30300 (epoch 23.213), train_loss = 1.16302305, grad/param norm = 1.4222e-01, time/batch = 18.1004s	
14068/30300 (epoch 23.215), train_loss = 1.12258251, grad/param norm = 1.6253e-01, time/batch = 18.2965s	
14069/30300 (epoch 23.216), train_loss = 1.15443411, grad/param norm = 1.4608e-01, time/batch = 19.7130s	
14070/30300 (epoch 23.218), train_loss = 1.07039343, grad/param norm = 1.2888e-01, time/batch = 18.9526s	
14071/30300 (epoch 23.219), train_loss = 1.04721346, grad/param norm = 1.3396e-01, time/batch = 19.0207s	
14072/30300 (epoch 23.221), train_loss = 1.04553774, grad/param norm = 1.4095e-01, time/batch = 20.1109s	
14073/30300 (epoch 23.223), train_loss = 1.21963451, grad/param norm = 1.5276e-01, time/batch = 19.8584s	
14074/30300 (epoch 23.224), train_loss = 1.03569394, grad/param norm = 1.5318e-01, time/batch = 19.0437s	
14075/30300 (epoch 23.226), train_loss = 1.27461612, grad/param norm = 1.8229e-01, time/batch = 19.6968s	
14076/30300 (epoch 23.228), train_loss = 1.30258538, grad/param norm = 1.7795e-01, time/batch = 18.2126s	
14077/30300 (epoch 23.229), train_loss = 1.15935985, grad/param norm = 1.4978e-01, time/batch = 18.8481s	
14078/30300 (epoch 23.231), train_loss = 1.22309796, grad/param norm = 1.5329e-01, time/batch = 18.9627s	
14079/30300 (epoch 23.233), train_loss = 1.19269083, grad/param norm = 1.3975e-01, time/batch = 19.2793s	
14080/30300 (epoch 23.234), train_loss = 1.25040755, grad/param norm = 1.7854e-01, time/batch = 15.9221s	
14081/30300 (epoch 23.236), train_loss = 1.21146912, grad/param norm = 1.3991e-01, time/batch = 15.4585s	
14082/30300 (epoch 23.238), train_loss = 1.24341713, grad/param norm = 1.7032e-01, time/batch = 16.5459s	
14083/30300 (epoch 23.239), train_loss = 1.23725033, grad/param norm = 1.6817e-01, time/batch = 17.3481s	
14084/30300 (epoch 23.241), train_loss = 1.23232693, grad/param norm = 1.6801e-01, time/batch = 18.1064s	
14085/30300 (epoch 23.243), train_loss = 1.26325961, grad/param norm = 1.5273e-01, time/batch = 18.7120s	
14086/30300 (epoch 23.244), train_loss = 1.43791432, grad/param norm = 1.6462e-01, time/batch = 18.0467s	
14087/30300 (epoch 23.246), train_loss = 1.20947158, grad/param norm = 1.6190e-01, time/batch = 17.5486s	
14088/30300 (epoch 23.248), train_loss = 1.17405443, grad/param norm = 1.4946e-01, time/batch = 18.1961s	
14089/30300 (epoch 23.249), train_loss = 1.13257227, grad/param norm = 1.4949e-01, time/batch = 18.6210s	
14090/30300 (epoch 23.251), train_loss = 1.11975925, grad/param norm = 1.4968e-01, time/batch = 18.5205s	
14091/30300 (epoch 23.252), train_loss = 1.29569061, grad/param norm = 1.6246e-01, time/batch = 18.7958s	
14092/30300 (epoch 23.254), train_loss = 1.30367095, grad/param norm = 1.7826e-01, time/batch = 19.7105s	
14093/30300 (epoch 23.256), train_loss = 1.24521180, grad/param norm = 1.5294e-01, time/batch = 17.6133s	
14094/30300 (epoch 23.257), train_loss = 1.25923237, grad/param norm = 1.6374e-01, time/batch = 18.8591s	
14095/30300 (epoch 23.259), train_loss = 1.18002900, grad/param norm = 1.5509e-01, time/batch = 18.9589s	
14096/30300 (epoch 23.261), train_loss = 1.30058268, grad/param norm = 1.6292e-01, time/batch = 18.5433s	
14097/30300 (epoch 23.262), train_loss = 1.20220364, grad/param norm = 1.5820e-01, time/batch = 17.1199s	
14098/30300 (epoch 23.264), train_loss = 1.21520352, grad/param norm = 1.5826e-01, time/batch = 17.9323s	
14099/30300 (epoch 23.266), train_loss = 1.11953649, grad/param norm = 1.4104e-01, time/batch = 19.4596s	
14100/30300 (epoch 23.267), train_loss = 1.39282814, grad/param norm = 1.8704e-01, time/batch = 18.3736s	
14101/30300 (epoch 23.269), train_loss = 1.22641860, grad/param norm = 1.6516e-01, time/batch = 19.2132s	
14102/30300 (epoch 23.271), train_loss = 1.23746768, grad/param norm = 1.6215e-01, time/batch = 19.2061s	
14103/30300 (epoch 23.272), train_loss = 1.23297532, grad/param norm = 1.8285e-01, time/batch = 17.2035s	
14104/30300 (epoch 23.274), train_loss = 1.29828921, grad/param norm = 1.6281e-01, time/batch = 17.9545s	
14105/30300 (epoch 23.276), train_loss = 1.24380053, grad/param norm = 1.6473e-01, time/batch = 19.7845s	
14106/30300 (epoch 23.277), train_loss = 1.06812151, grad/param norm = 1.7703e-01, time/batch = 18.3751s	
14107/30300 (epoch 23.279), train_loss = 1.23022951, grad/param norm = 1.7275e-01, time/batch = 18.7906s	
14108/30300 (epoch 23.281), train_loss = 1.30653235, grad/param norm = 1.7291e-01, time/batch = 19.9500s	
14109/30300 (epoch 23.282), train_loss = 1.22387635, grad/param norm = 1.4934e-01, time/batch = 18.1087s	
14110/30300 (epoch 23.284), train_loss = 1.35597441, grad/param norm = 2.3096e-01, time/batch = 19.1203s	
14111/30300 (epoch 23.285), train_loss = 1.26308840, grad/param norm = 1.4193e-01, time/batch = 19.3708s	
14112/30300 (epoch 23.287), train_loss = 1.20554583, grad/param norm = 1.6075e-01, time/batch = 18.2273s	
14113/30300 (epoch 23.289), train_loss = 1.27920243, grad/param norm = 1.4852e-01, time/batch = 18.2818s	
14114/30300 (epoch 23.290), train_loss = 0.96640641, grad/param norm = 1.3652e-01, time/batch = 18.6269s	
14115/30300 (epoch 23.292), train_loss = 1.10678422, grad/param norm = 1.4372e-01, time/batch = 18.0277s	
14116/30300 (epoch 23.294), train_loss = 1.30481101, grad/param norm = 1.8347e-01, time/batch = 18.9516s	
14117/30300 (epoch 23.295), train_loss = 1.16506909, grad/param norm = 1.6019e-01, time/batch = 18.4609s	
14118/30300 (epoch 23.297), train_loss = 1.14747472, grad/param norm = 1.5002e-01, time/batch = 17.5246s	
14119/30300 (epoch 23.299), train_loss = 1.19065155, grad/param norm = 1.6138e-01, time/batch = 17.9468s	
14120/30300 (epoch 23.300), train_loss = 1.15177146, grad/param norm = 1.4627e-01, time/batch = 18.8877s	
14121/30300 (epoch 23.302), train_loss = 1.21207677, grad/param norm = 1.5262e-01, time/batch = 19.1328s	
14122/30300 (epoch 23.304), train_loss = 1.12065709, grad/param norm = 1.5172e-01, time/batch = 17.7138s	
14123/30300 (epoch 23.305), train_loss = 1.16153003, grad/param norm = 1.4366e-01, time/batch = 19.6326s	
14124/30300 (epoch 23.307), train_loss = 1.25792143, grad/param norm = 1.4276e-01, time/batch = 20.1296s	
14125/30300 (epoch 23.309), train_loss = 1.26268851, grad/param norm = 1.5308e-01, time/batch = 17.7771s	
14126/30300 (epoch 23.310), train_loss = 1.20689160, grad/param norm = 1.5972e-01, time/batch = 18.1950s	
14127/30300 (epoch 23.312), train_loss = 1.32785196, grad/param norm = 1.5547e-01, time/batch = 18.3601s	
14128/30300 (epoch 23.314), train_loss = 1.21664392, grad/param norm = 1.5094e-01, time/batch = 17.4553s	
14129/30300 (epoch 23.315), train_loss = 1.20923197, grad/param norm = 1.6579e-01, time/batch = 18.9525s	
14130/30300 (epoch 23.317), train_loss = 1.25124879, grad/param norm = 1.4781e-01, time/batch = 19.4584s	
14131/30300 (epoch 23.318), train_loss = 1.30867130, grad/param norm = 1.6729e-01, time/batch = 20.1153s	
14132/30300 (epoch 23.320), train_loss = 1.27437037, grad/param norm = 1.5947e-01, time/batch = 18.2134s	
14133/30300 (epoch 23.322), train_loss = 1.11988923, grad/param norm = 1.5708e-01, time/batch = 18.6049s	
14134/30300 (epoch 23.323), train_loss = 1.28743194, grad/param norm = 1.6471e-01, time/batch = 17.9335s	
14135/30300 (epoch 23.325), train_loss = 1.19790535, grad/param norm = 1.4816e-01, time/batch = 18.1191s	
14136/30300 (epoch 23.327), train_loss = 1.19925459, grad/param norm = 1.4586e-01, time/batch = 19.3786s	
14137/30300 (epoch 23.328), train_loss = 1.20891900, grad/param norm = 1.4530e-01, time/batch = 19.7871s	
14138/30300 (epoch 23.330), train_loss = 1.26360180, grad/param norm = 1.5998e-01, time/batch = 18.2896s	
14139/30300 (epoch 23.332), train_loss = 1.28573763, grad/param norm = 1.7138e-01, time/batch = 18.8795s	
14140/30300 (epoch 23.333), train_loss = 1.18643563, grad/param norm = 1.6505e-01, time/batch = 19.0466s	
14141/30300 (epoch 23.335), train_loss = 1.08488254, grad/param norm = 1.5477e-01, time/batch = 18.1216s	
14142/30300 (epoch 23.337), train_loss = 1.34442653, grad/param norm = 1.4919e-01, time/batch = 16.7926s	
14143/30300 (epoch 23.338), train_loss = 1.12593508, grad/param norm = 1.3903e-01, time/batch = 19.5289s	
14144/30300 (epoch 23.340), train_loss = 1.10464990, grad/param norm = 1.4777e-01, time/batch = 19.7000s	
14145/30300 (epoch 23.342), train_loss = 1.28684443, grad/param norm = 1.5044e-01, time/batch = 18.0396s	
14146/30300 (epoch 23.343), train_loss = 1.22306894, grad/param norm = 1.6097e-01, time/batch = 19.2905s	
14147/30300 (epoch 23.345), train_loss = 1.24431215, grad/param norm = 1.6909e-01, time/batch = 19.0451s	
14148/30300 (epoch 23.347), train_loss = 1.07460120, grad/param norm = 1.5947e-01, time/batch = 18.0403s	
14149/30300 (epoch 23.348), train_loss = 1.11969102, grad/param norm = 1.5369e-01, time/batch = 17.4374s	
14150/30300 (epoch 23.350), train_loss = 1.18631420, grad/param norm = 1.4709e-01, time/batch = 19.2036s	
14151/30300 (epoch 23.351), train_loss = 1.20407636, grad/param norm = 1.6232e-01, time/batch = 18.2923s	
14152/30300 (epoch 23.353), train_loss = 1.06191792, grad/param norm = 1.4311e-01, time/batch = 19.4590s	
14153/30300 (epoch 23.355), train_loss = 1.15794411, grad/param norm = 1.4721e-01, time/batch = 19.7783s	
14154/30300 (epoch 23.356), train_loss = 1.29237833, grad/param norm = 1.8834e-01, time/batch = 18.6229s	
14155/30300 (epoch 23.358), train_loss = 1.43715148, grad/param norm = 1.5078e-01, time/batch = 18.9472s	
14156/30300 (epoch 23.360), train_loss = 1.15543107, grad/param norm = 1.5895e-01, time/batch = 20.3810s	
14157/30300 (epoch 23.361), train_loss = 1.23935053, grad/param norm = 1.5917e-01, time/batch = 17.5504s	
14158/30300 (epoch 23.363), train_loss = 1.27723450, grad/param norm = 1.5730e-01, time/batch = 18.9452s	
14159/30300 (epoch 23.365), train_loss = 1.09832233, grad/param norm = 1.5767e-01, time/batch = 18.6886s	
14160/30300 (epoch 23.366), train_loss = 1.15753336, grad/param norm = 1.4005e-01, time/batch = 19.1171s	
14161/30300 (epoch 23.368), train_loss = 1.03058011, grad/param norm = 1.4041e-01, time/batch = 18.8631s	
14162/30300 (epoch 23.370), train_loss = 1.09480942, grad/param norm = 1.3938e-01, time/batch = 18.9565s	
14163/30300 (epoch 23.371), train_loss = 1.28089094, grad/param norm = 1.5649e-01, time/batch = 19.6910s	
14164/30300 (epoch 23.373), train_loss = 1.11028037, grad/param norm = 1.3403e-01, time/batch = 19.1813s	
14165/30300 (epoch 23.375), train_loss = 1.10614217, grad/param norm = 1.3139e-01, time/batch = 19.3683s	
14166/30300 (epoch 23.376), train_loss = 1.10851363, grad/param norm = 1.3146e-01, time/batch = 19.1135s	
14167/30300 (epoch 23.378), train_loss = 1.11064870, grad/param norm = 1.6056e-01, time/batch = 18.2818s	
14168/30300 (epoch 23.380), train_loss = 1.35750420, grad/param norm = 1.6302e-01, time/batch = 19.1175s	
14169/30300 (epoch 23.381), train_loss = 1.04411820, grad/param norm = 1.4443e-01, time/batch = 19.4579s	
14170/30300 (epoch 23.383), train_loss = 1.12971144, grad/param norm = 1.6789e-01, time/batch = 18.7698s	
14171/30300 (epoch 23.384), train_loss = 1.26051642, grad/param norm = 1.5735e-01, time/batch = 19.5462s	
14172/30300 (epoch 23.386), train_loss = 1.09028377, grad/param norm = 1.5460e-01, time/batch = 20.1044s	
14173/30300 (epoch 23.388), train_loss = 1.03375314, grad/param norm = 1.3629e-01, time/batch = 30.6752s	
14174/30300 (epoch 23.389), train_loss = 1.15123764, grad/param norm = 1.5536e-01, time/batch = 20.1060s	
14175/30300 (epoch 23.391), train_loss = 1.23654171, grad/param norm = 1.4958e-01, time/batch = 18.8703s	
14176/30300 (epoch 23.393), train_loss = 1.05907010, grad/param norm = 1.4235e-01, time/batch = 19.2037s	
14177/30300 (epoch 23.394), train_loss = 1.24691313, grad/param norm = 1.4490e-01, time/batch = 18.3789s	
14178/30300 (epoch 23.396), train_loss = 1.32517378, grad/param norm = 1.4572e-01, time/batch = 17.0327s	
14179/30300 (epoch 23.398), train_loss = 1.16216033, grad/param norm = 1.3776e-01, time/batch = 18.7871s	
14180/30300 (epoch 23.399), train_loss = 1.15966615, grad/param norm = 1.6208e-01, time/batch = 18.2685s	
14181/30300 (epoch 23.401), train_loss = 1.21975097, grad/param norm = 1.5128e-01, time/batch = 17.6163s	
14182/30300 (epoch 23.403), train_loss = 1.18100498, grad/param norm = 1.6596e-01, time/batch = 18.0310s	
14183/30300 (epoch 23.404), train_loss = 1.11004484, grad/param norm = 1.7385e-01, time/batch = 20.6925s	
14184/30300 (epoch 23.406), train_loss = 1.21165227, grad/param norm = 1.4323e-01, time/batch = 19.0472s	
14185/30300 (epoch 23.408), train_loss = 1.06743081, grad/param norm = 1.4849e-01, time/batch = 17.7920s	
14186/30300 (epoch 23.409), train_loss = 1.07443001, grad/param norm = 1.5452e-01, time/batch = 20.0261s	
14187/30300 (epoch 23.411), train_loss = 1.08704829, grad/param norm = 1.3703e-01, time/batch = 18.2923s	
14188/30300 (epoch 23.413), train_loss = 0.98588041, grad/param norm = 1.4301e-01, time/batch = 18.1084s	
14189/30300 (epoch 23.414), train_loss = 1.28701215, grad/param norm = 1.7280e-01, time/batch = 19.1282s	
14190/30300 (epoch 23.416), train_loss = 1.12560706, grad/param norm = 1.4888e-01, time/batch = 17.2169s	
14191/30300 (epoch 23.417), train_loss = 1.10514443, grad/param norm = 1.5187e-01, time/batch = 17.5131s	
14192/30300 (epoch 23.419), train_loss = 1.06327090, grad/param norm = 1.5416e-01, time/batch = 18.8830s	
14193/30300 (epoch 23.421), train_loss = 1.13483004, grad/param norm = 1.6035e-01, time/batch = 17.2814s	
14194/30300 (epoch 23.422), train_loss = 1.18678317, grad/param norm = 1.5456e-01, time/batch = 20.1161s	
14195/30300 (epoch 23.424), train_loss = 1.18312946, grad/param norm = 1.4936e-01, time/batch = 18.3574s	
14196/30300 (epoch 23.426), train_loss = 1.12342152, grad/param norm = 1.7854e-01, time/batch = 19.5418s	
14197/30300 (epoch 23.427), train_loss = 1.16091854, grad/param norm = 1.6669e-01, time/batch = 20.3611s	
14198/30300 (epoch 23.429), train_loss = 1.16648536, grad/param norm = 1.4137e-01, time/batch = 17.9512s	
14199/30300 (epoch 23.431), train_loss = 1.23521025, grad/param norm = 1.4328e-01, time/batch = 19.0464s	
14200/30300 (epoch 23.432), train_loss = 1.15772662, grad/param norm = 1.4096e-01, time/batch = 18.6225s	
14201/30300 (epoch 23.434), train_loss = 1.06728017, grad/param norm = 1.4728e-01, time/batch = 16.6979s	
14202/30300 (epoch 23.436), train_loss = 1.31936057, grad/param norm = 1.6175e-01, time/batch = 18.4458s	
14203/30300 (epoch 23.437), train_loss = 1.06962872, grad/param norm = 1.4707e-01, time/batch = 19.6201s	
14204/30300 (epoch 23.439), train_loss = 1.11344984, grad/param norm = 1.3652e-01, time/batch = 18.0407s	
14205/30300 (epoch 23.441), train_loss = 1.16176416, grad/param norm = 1.9566e-01, time/batch = 19.2671s	
14206/30300 (epoch 23.442), train_loss = 1.08676560, grad/param norm = 1.4568e-01, time/batch = 18.6199s	
14207/30300 (epoch 23.444), train_loss = 0.98797523, grad/param norm = 1.4704e-01, time/batch = 18.8546s	
14208/30300 (epoch 23.446), train_loss = 1.16507195, grad/param norm = 1.4512e-01, time/batch = 18.9569s	
14209/30300 (epoch 23.447), train_loss = 1.16598312, grad/param norm = 1.5711e-01, time/batch = 16.9480s	
14210/30300 (epoch 23.449), train_loss = 1.09480915, grad/param norm = 1.4686e-01, time/batch = 19.7018s	
14211/30300 (epoch 23.450), train_loss = 1.24268183, grad/param norm = 1.4384e-01, time/batch = 18.1021s	
14212/30300 (epoch 23.452), train_loss = 1.26901855, grad/param norm = 1.4816e-01, time/batch = 19.1342s	
14213/30300 (epoch 23.454), train_loss = 1.24236610, grad/param norm = 1.4378e-01, time/batch = 19.0399s	
14214/30300 (epoch 23.455), train_loss = 1.21591788, grad/param norm = 1.6623e-01, time/batch = 18.2084s	
14215/30300 (epoch 23.457), train_loss = 1.16387686, grad/param norm = 1.4394e-01, time/batch = 19.5464s	
14216/30300 (epoch 23.459), train_loss = 1.24638104, grad/param norm = 1.6099e-01, time/batch = 19.1965s	
14217/30300 (epoch 23.460), train_loss = 1.20289962, grad/param norm = 1.5416e-01, time/batch = 18.1242s	
14218/30300 (epoch 23.462), train_loss = 1.23082306, grad/param norm = 1.4872e-01, time/batch = 19.4579s	
14219/30300 (epoch 23.464), train_loss = 1.01241812, grad/param norm = 1.5756e-01, time/batch = 19.0401s	
14220/30300 (epoch 23.465), train_loss = 1.00507416, grad/param norm = 1.3695e-01, time/batch = 18.1860s	
14221/30300 (epoch 23.467), train_loss = 0.98393858, grad/param norm = 1.3029e-01, time/batch = 18.1189s	
14222/30300 (epoch 23.469), train_loss = 1.09476468, grad/param norm = 1.4141e-01, time/batch = 17.1925s	
14223/30300 (epoch 23.470), train_loss = 1.14460932, grad/param norm = 1.6270e-01, time/batch = 18.6130s	
14224/30300 (epoch 23.472), train_loss = 1.13168085, grad/param norm = 1.3520e-01, time/batch = 18.6799s	
14225/30300 (epoch 23.474), train_loss = 1.16381383, grad/param norm = 1.9844e-01, time/batch = 19.6215s	
14226/30300 (epoch 23.475), train_loss = 1.10135809, grad/param norm = 1.3814e-01, time/batch = 17.8239s	
14227/30300 (epoch 23.477), train_loss = 1.16096692, grad/param norm = 1.5180e-01, time/batch = 17.6841s	
14228/30300 (epoch 23.479), train_loss = 1.14844882, grad/param norm = 1.4870e-01, time/batch = 18.8681s	
14229/30300 (epoch 23.480), train_loss = 1.18537541, grad/param norm = 1.4622e-01, time/batch = 17.7773s	
14230/30300 (epoch 23.482), train_loss = 1.21477003, grad/param norm = 1.3758e-01, time/batch = 17.3596s	
14231/30300 (epoch 23.483), train_loss = 1.11841195, grad/param norm = 1.4931e-01, time/batch = 17.2859s	
14232/30300 (epoch 23.485), train_loss = 1.17892421, grad/param norm = 1.4541e-01, time/batch = 18.6108s	
14233/30300 (epoch 23.487), train_loss = 1.26397172, grad/param norm = 1.5864e-01, time/batch = 18.1126s	
14234/30300 (epoch 23.488), train_loss = 1.26401488, grad/param norm = 1.3632e-01, time/batch = 18.7019s	
14235/30300 (epoch 23.490), train_loss = 1.05792632, grad/param norm = 1.4341e-01, time/batch = 19.0387s	
14236/30300 (epoch 23.492), train_loss = 1.15355036, grad/param norm = 1.5900e-01, time/batch = 19.2785s	
14237/30300 (epoch 23.493), train_loss = 1.12959858, grad/param norm = 1.3926e-01, time/batch = 18.1000s	
14238/30300 (epoch 23.495), train_loss = 1.12468409, grad/param norm = 1.3476e-01, time/batch = 18.3657s	
14239/30300 (epoch 23.497), train_loss = 1.18613365, grad/param norm = 1.4373e-01, time/batch = 19.8603s	
14240/30300 (epoch 23.498), train_loss = 1.21684845, grad/param norm = 1.6156e-01, time/batch = 17.9513s	
14241/30300 (epoch 23.500), train_loss = 1.18083216, grad/param norm = 1.6990e-01, time/batch = 19.0447s	
14242/30300 (epoch 23.502), train_loss = 1.18211544, grad/param norm = 1.6622e-01, time/batch = 19.3711s	
14243/30300 (epoch 23.503), train_loss = 1.27011567, grad/param norm = 1.5127e-01, time/batch = 17.1362s	
14244/30300 (epoch 23.505), train_loss = 1.10444480, grad/param norm = 1.4297e-01, time/batch = 16.0992s	
14245/30300 (epoch 23.507), train_loss = 1.09954155, grad/param norm = 1.4881e-01, time/batch = 19.6106s	
14246/30300 (epoch 23.508), train_loss = 1.14170757, grad/param norm = 1.7200e-01, time/batch = 17.9452s	
14247/30300 (epoch 23.510), train_loss = 1.26719200, grad/param norm = 1.6822e-01, time/batch = 19.7051s	
14248/30300 (epoch 23.512), train_loss = 1.11720545, grad/param norm = 1.4389e-01, time/batch = 19.6292s	
14249/30300 (epoch 23.513), train_loss = 1.18564205, grad/param norm = 1.3477e-01, time/batch = 19.4491s	
14250/30300 (epoch 23.515), train_loss = 1.17183345, grad/param norm = 1.5337e-01, time/batch = 18.2074s	
14251/30300 (epoch 23.517), train_loss = 0.99197516, grad/param norm = 1.2755e-01, time/batch = 18.9666s	
14252/30300 (epoch 23.518), train_loss = 1.24506143, grad/param norm = 1.5630e-01, time/batch = 19.2993s	
14253/30300 (epoch 23.520), train_loss = 1.24652806, grad/param norm = 1.6854e-01, time/batch = 18.1074s	
14254/30300 (epoch 23.521), train_loss = 1.09471522, grad/param norm = 1.7815e-01, time/batch = 18.5446s	
14255/30300 (epoch 23.523), train_loss = 1.33970753, grad/param norm = 1.8282e-01, time/batch = 19.1956s	
14256/30300 (epoch 23.525), train_loss = 1.09752713, grad/param norm = 1.4928e-01, time/batch = 18.6094s	
14257/30300 (epoch 23.526), train_loss = 1.15147784, grad/param norm = 1.4559e-01, time/batch = 19.8736s	
14258/30300 (epoch 23.528), train_loss = 1.05615854, grad/param norm = 1.4819e-01, time/batch = 18.6378s	
14259/30300 (epoch 23.530), train_loss = 1.04481337, grad/param norm = 1.4789e-01, time/batch = 16.9588s	
14260/30300 (epoch 23.531), train_loss = 1.20663519, grad/param norm = 1.5487e-01, time/batch = 20.2042s	
14261/30300 (epoch 23.533), train_loss = 1.18560996, grad/param norm = 1.4883e-01, time/batch = 17.8674s	
14262/30300 (epoch 23.535), train_loss = 1.09014630, grad/param norm = 1.2677e-01, time/batch = 18.3753s	
14263/30300 (epoch 23.536), train_loss = 1.19231392, grad/param norm = 1.7609e-01, time/batch = 18.2886s	
14264/30300 (epoch 23.538), train_loss = 1.05841049, grad/param norm = 1.6712e-01, time/batch = 19.8694s	
14265/30300 (epoch 23.540), train_loss = 1.08441634, grad/param norm = 1.6947e-01, time/batch = 18.2863s	
14266/30300 (epoch 23.541), train_loss = 1.15940863, grad/param norm = 1.6381e-01, time/batch = 19.7170s	
14267/30300 (epoch 23.543), train_loss = 1.15356293, grad/param norm = 1.5608e-01, time/batch = 19.6325s	
14268/30300 (epoch 23.545), train_loss = 1.16852768, grad/param norm = 2.1615e-01, time/batch = 18.2117s	
14269/30300 (epoch 23.546), train_loss = 1.38582617, grad/param norm = 1.6599e-01, time/batch = 19.5986s	
14270/30300 (epoch 23.548), train_loss = 1.11688204, grad/param norm = 1.4064e-01, time/batch = 18.9452s	
14271/30300 (epoch 23.550), train_loss = 1.23997866, grad/param norm = 1.9022e-01, time/batch = 18.4577s	
14272/30300 (epoch 23.551), train_loss = 1.11166598, grad/param norm = 1.4919e-01, time/batch = 18.9482s	
14273/30300 (epoch 23.553), train_loss = 1.13433403, grad/param norm = 1.6353e-01, time/batch = 18.7043s	
14274/30300 (epoch 23.554), train_loss = 1.18510290, grad/param norm = 1.6313e-01, time/batch = 18.9609s	
14275/30300 (epoch 23.556), train_loss = 1.21133713, grad/param norm = 1.4545e-01, time/batch = 17.6802s	
14276/30300 (epoch 23.558), train_loss = 1.26947759, grad/param norm = 1.6613e-01, time/batch = 18.8757s	
14277/30300 (epoch 23.559), train_loss = 1.22697680, grad/param norm = 1.7251e-01, time/batch = 19.2771s	
14278/30300 (epoch 23.561), train_loss = 0.99913294, grad/param norm = 1.4452e-01, time/batch = 18.1210s	
14279/30300 (epoch 23.563), train_loss = 1.06793576, grad/param norm = 1.4951e-01, time/batch = 19.2721s	
14280/30300 (epoch 23.564), train_loss = 1.10594239, grad/param norm = 1.4523e-01, time/batch = 17.3549s	
14281/30300 (epoch 23.566), train_loss = 1.15846409, grad/param norm = 1.4919e-01, time/batch = 18.2739s	
14282/30300 (epoch 23.568), train_loss = 0.98745285, grad/param norm = 1.4865e-01, time/batch = 20.2034s	
14283/30300 (epoch 23.569), train_loss = 1.17520362, grad/param norm = 1.4669e-01, time/batch = 18.6319s	
14284/30300 (epoch 23.571), train_loss = 1.20478267, grad/param norm = 1.7197e-01, time/batch = 18.7862s	
14285/30300 (epoch 23.573), train_loss = 1.21212086, grad/param norm = 1.5190e-01, time/batch = 19.8763s	
14286/30300 (epoch 23.574), train_loss = 1.23041881, grad/param norm = 1.4419e-01, time/batch = 19.1158s	
14287/30300 (epoch 23.576), train_loss = 1.16032058, grad/param norm = 1.4369e-01, time/batch = 18.7111s	
14288/30300 (epoch 23.578), train_loss = 1.05649598, grad/param norm = 1.5679e-01, time/batch = 18.7020s	
14289/30300 (epoch 23.579), train_loss = 1.17448668, grad/param norm = 1.6123e-01, time/batch = 20.0228s	
14290/30300 (epoch 23.581), train_loss = 1.28106750, grad/param norm = 1.5355e-01, time/batch = 18.7146s	
14291/30300 (epoch 23.583), train_loss = 1.33579327, grad/param norm = 1.6812e-01, time/batch = 18.1210s	
14292/30300 (epoch 23.584), train_loss = 1.25629135, grad/param norm = 1.4945e-01, time/batch = 19.3772s	
14293/30300 (epoch 23.586), train_loss = 1.14794283, grad/param norm = 1.4544e-01, time/batch = 19.8035s	
14294/30300 (epoch 23.587), train_loss = 1.16018081, grad/param norm = 1.4681e-01, time/batch = 18.4438s	
14295/30300 (epoch 23.589), train_loss = 1.05881900, grad/param norm = 1.4055e-01, time/batch = 19.2828s	
14296/30300 (epoch 23.591), train_loss = 1.21646083, grad/param norm = 1.4365e-01, time/batch = 17.9361s	
14297/30300 (epoch 23.592), train_loss = 1.15428218, grad/param norm = 1.3607e-01, time/batch = 18.1866s	
14298/30300 (epoch 23.594), train_loss = 1.18639418, grad/param norm = 1.5370e-01, time/batch = 19.1212s	
14299/30300 (epoch 23.596), train_loss = 1.09397948, grad/param norm = 1.4460e-01, time/batch = 19.2219s	
14300/30300 (epoch 23.597), train_loss = 1.11584128, grad/param norm = 1.4674e-01, time/batch = 17.1354s	
14301/30300 (epoch 23.599), train_loss = 0.98782149, grad/param norm = 1.3968e-01, time/batch = 18.7771s	
14302/30300 (epoch 23.601), train_loss = 1.18827405, grad/param norm = 1.5623e-01, time/batch = 18.1897s	
14303/30300 (epoch 23.602), train_loss = 1.15536890, grad/param norm = 1.4305e-01, time/batch = 18.9482s	
14304/30300 (epoch 23.604), train_loss = 1.08168665, grad/param norm = 1.4704e-01, time/batch = 19.1207s	
14305/30300 (epoch 23.606), train_loss = 1.11864091, grad/param norm = 1.9457e-01, time/batch = 19.0437s	
14306/30300 (epoch 23.607), train_loss = 1.24406504, grad/param norm = 1.6670e-01, time/batch = 19.4426s	
14307/30300 (epoch 23.609), train_loss = 1.37681042, grad/param norm = 1.6366e-01, time/batch = 18.4388s	
14308/30300 (epoch 23.611), train_loss = 1.10187821, grad/param norm = 1.4001e-01, time/batch = 19.3782s	
14309/30300 (epoch 23.612), train_loss = 1.05947473, grad/param norm = 1.4173e-01, time/batch = 19.5424s	
14310/30300 (epoch 23.614), train_loss = 1.12806566, grad/param norm = 1.4309e-01, time/batch = 17.9602s	
14311/30300 (epoch 23.616), train_loss = 1.23200390, grad/param norm = 3.5141e-01, time/batch = 19.3842s	
14312/30300 (epoch 23.617), train_loss = 1.19939963, grad/param norm = 1.8151e-01, time/batch = 17.5392s	
14313/30300 (epoch 23.619), train_loss = 1.01600153, grad/param norm = 1.6243e-01, time/batch = 18.2848s	
14314/30300 (epoch 23.620), train_loss = 1.18840170, grad/param norm = 1.5820e-01, time/batch = 20.0405s	
14315/30300 (epoch 23.622), train_loss = 1.18205827, grad/param norm = 1.7109e-01, time/batch = 18.9767s	
14316/30300 (epoch 23.624), train_loss = 1.11317444, grad/param norm = 1.4978e-01, time/batch = 17.4698s	
14317/30300 (epoch 23.625), train_loss = 1.12697470, grad/param norm = 1.8346e-01, time/batch = 20.2831s	
14318/30300 (epoch 23.627), train_loss = 1.29975373, grad/param norm = 1.8280e-01, time/batch = 19.1009s	
14319/30300 (epoch 23.629), train_loss = 1.28343223, grad/param norm = 1.5430e-01, time/batch = 17.7950s	
14320/30300 (epoch 23.630), train_loss = 1.18355548, grad/param norm = 1.5269e-01, time/batch = 19.6265s	
14321/30300 (epoch 23.632), train_loss = 1.26535679, grad/param norm = 1.6875e-01, time/batch = 19.4436s	
14322/30300 (epoch 23.634), train_loss = 1.07756488, grad/param norm = 1.3837e-01, time/batch = 18.7144s	
14323/30300 (epoch 23.635), train_loss = 1.22410724, grad/param norm = 1.9099e-01, time/batch = 16.6965s	
14324/30300 (epoch 23.637), train_loss = 1.23627202, grad/param norm = 1.6914e-01, time/batch = 19.1853s	
14325/30300 (epoch 23.639), train_loss = 1.12274939, grad/param norm = 1.5147e-01, time/batch = 18.9593s	
14326/30300 (epoch 23.640), train_loss = 1.31047238, grad/param norm = 1.8912e-01, time/batch = 17.5901s	
14327/30300 (epoch 23.642), train_loss = 1.15660233, grad/param norm = 1.4022e-01, time/batch = 20.1141s	
14328/30300 (epoch 23.644), train_loss = 1.22348677, grad/param norm = 1.4815e-01, time/batch = 19.8616s	
14329/30300 (epoch 23.645), train_loss = 1.08846824, grad/param norm = 1.4872e-01, time/batch = 17.9361s	
14330/30300 (epoch 23.647), train_loss = 1.17234338, grad/param norm = 1.3997e-01, time/batch = 20.3705s	
14331/30300 (epoch 23.649), train_loss = 1.14860011, grad/param norm = 1.7018e-01, time/batch = 19.4718s	
14332/30300 (epoch 23.650), train_loss = 1.16868712, grad/param norm = 1.4643e-01, time/batch = 18.1986s	
14333/30300 (epoch 23.652), train_loss = 1.12737760, grad/param norm = 1.4148e-01, time/batch = 19.6902s	
14334/30300 (epoch 23.653), train_loss = 1.32976346, grad/param norm = 1.5802e-01, time/batch = 19.8595s	
14335/30300 (epoch 23.655), train_loss = 1.09089958, grad/param norm = 1.4496e-01, time/batch = 17.6275s	
14336/30300 (epoch 23.657), train_loss = 1.11689762, grad/param norm = 1.6552e-01, time/batch = 18.0515s	
14337/30300 (epoch 23.658), train_loss = 1.07562855, grad/param norm = 1.3905e-01, time/batch = 19.1342s	
14338/30300 (epoch 23.660), train_loss = 1.18105215, grad/param norm = 1.5548e-01, time/batch = 17.4546s	
14339/30300 (epoch 23.662), train_loss = 1.18285002, grad/param norm = 1.7738e-01, time/batch = 19.5322s	
14340/30300 (epoch 23.663), train_loss = 1.19464023, grad/param norm = 1.6058e-01, time/batch = 19.5482s	
14341/30300 (epoch 23.665), train_loss = 1.11244894, grad/param norm = 1.5683e-01, time/batch = 19.0467s	
14342/30300 (epoch 23.667), train_loss = 1.26677703, grad/param norm = 1.6786e-01, time/batch = 18.7109s	
14343/30300 (epoch 23.668), train_loss = 1.27173621, grad/param norm = 1.5960e-01, time/batch = 18.0227s	
14344/30300 (epoch 23.670), train_loss = 1.26912883, grad/param norm = 1.6977e-01, time/batch = 19.4584s	
14345/30300 (epoch 23.672), train_loss = 1.20402285, grad/param norm = 1.5635e-01, time/batch = 18.4648s	
14346/30300 (epoch 23.673), train_loss = 1.21143718, grad/param norm = 1.5475e-01, time/batch = 18.7042s	
14347/30300 (epoch 23.675), train_loss = 1.12957023, grad/param norm = 1.5417e-01, time/batch = 19.5239s	
14348/30300 (epoch 23.677), train_loss = 1.12811418, grad/param norm = 1.5090e-01, time/batch = 8.6842s	
14349/30300 (epoch 23.678), train_loss = 1.11334334, grad/param norm = 1.4302e-01, time/batch = 0.6917s	
14350/30300 (epoch 23.680), train_loss = 0.98001860, grad/param norm = 1.3731e-01, time/batch = 0.7078s	
14351/30300 (epoch 23.682), train_loss = 1.18146002, grad/param norm = 1.6206e-01, time/batch = 0.7130s	
14352/30300 (epoch 23.683), train_loss = 1.25614338, grad/param norm = 1.4031e-01, time/batch = 0.7120s	
14353/30300 (epoch 23.685), train_loss = 1.26022935, grad/param norm = 1.7490e-01, time/batch = 0.7080s	
14354/30300 (epoch 23.686), train_loss = 1.13728053, grad/param norm = 1.3800e-01, time/batch = 0.6912s	
14355/30300 (epoch 23.688), train_loss = 1.16118086, grad/param norm = 1.4374e-01, time/batch = 0.8206s	
14356/30300 (epoch 23.690), train_loss = 1.11580742, grad/param norm = 1.6315e-01, time/batch = 1.0132s	
14357/30300 (epoch 23.691), train_loss = 1.21512157, grad/param norm = 1.4058e-01, time/batch = 1.0279s	
14358/30300 (epoch 23.693), train_loss = 1.49964771, grad/param norm = 1.7617e-01, time/batch = 1.0433s	
14359/30300 (epoch 23.695), train_loss = 1.29593868, grad/param norm = 1.6711e-01, time/batch = 1.0144s	
14360/30300 (epoch 23.696), train_loss = 1.22988659, grad/param norm = 1.7821e-01, time/batch = 1.4584s	
14361/30300 (epoch 23.698), train_loss = 1.10547092, grad/param norm = 1.4047e-01, time/batch = 1.8807s	
14362/30300 (epoch 23.700), train_loss = 1.10422478, grad/param norm = 1.5172e-01, time/batch = 1.8693s	
14363/30300 (epoch 23.701), train_loss = 1.00573196, grad/param norm = 1.3223e-01, time/batch = 17.6487s	
14364/30300 (epoch 23.703), train_loss = 1.15810715, grad/param norm = 1.3570e-01, time/batch = 17.8544s	
14365/30300 (epoch 23.705), train_loss = 1.11289221, grad/param norm = 1.4918e-01, time/batch = 19.2125s	
14366/30300 (epoch 23.706), train_loss = 1.22594874, grad/param norm = 1.5813e-01, time/batch = 19.6198s	
14367/30300 (epoch 23.708), train_loss = 1.15690979, grad/param norm = 1.5261e-01, time/batch = 19.3854s	
14368/30300 (epoch 23.710), train_loss = 1.15467242, grad/param norm = 1.6322e-01, time/batch = 17.9620s	
14369/30300 (epoch 23.711), train_loss = 1.07763258, grad/param norm = 1.4105e-01, time/batch = 19.7138s	
14370/30300 (epoch 23.713), train_loss = 1.08683467, grad/param norm = 1.5102e-01, time/batch = 19.2002s	
14371/30300 (epoch 23.715), train_loss = 1.10507071, grad/param norm = 1.4462e-01, time/batch = 17.6095s	
14372/30300 (epoch 23.716), train_loss = 1.25985155, grad/param norm = 1.4754e-01, time/batch = 19.5330s	
14373/30300 (epoch 23.718), train_loss = 1.30708254, grad/param norm = 1.6799e-01, time/batch = 20.2852s	
14374/30300 (epoch 23.719), train_loss = 1.13389023, grad/param norm = 1.6926e-01, time/batch = 18.4529s	
14375/30300 (epoch 23.721), train_loss = 1.18442770, grad/param norm = 1.6978e-01, time/batch = 18.4497s	
14376/30300 (epoch 23.723), train_loss = 1.11036655, grad/param norm = 1.5485e-01, time/batch = 20.1083s	
14377/30300 (epoch 23.724), train_loss = 1.19915223, grad/param norm = 1.7288e-01, time/batch = 22.1511s	
14378/30300 (epoch 23.726), train_loss = 1.53775428, grad/param norm = 1.9075e-01, time/batch = 28.3382s	
14379/30300 (epoch 23.728), train_loss = 1.24072603, grad/param norm = 1.6680e-01, time/batch = 18.6805s	
14380/30300 (epoch 23.729), train_loss = 1.14588846, grad/param norm = 1.6987e-01, time/batch = 17.3604s	
14381/30300 (epoch 23.731), train_loss = 1.20951255, grad/param norm = 1.6477e-01, time/batch = 17.7642s	
14382/30300 (epoch 23.733), train_loss = 1.17512239, grad/param norm = 1.5586e-01, time/batch = 17.0119s	
14383/30300 (epoch 23.734), train_loss = 1.23732249, grad/param norm = 1.4336e-01, time/batch = 18.5286s	
14384/30300 (epoch 23.736), train_loss = 1.14530379, grad/param norm = 1.4339e-01, time/batch = 16.6819s	
14385/30300 (epoch 23.738), train_loss = 1.08068159, grad/param norm = 1.2872e-01, time/batch = 17.6097s	
14386/30300 (epoch 23.739), train_loss = 1.22268645, grad/param norm = 1.3956e-01, time/batch = 19.3511s	
14387/30300 (epoch 23.741), train_loss = 1.31704050, grad/param norm = 1.5119e-01, time/batch = 17.6162s	
14388/30300 (epoch 23.743), train_loss = 1.15305873, grad/param norm = 1.6132e-01, time/batch = 18.5182s	
14389/30300 (epoch 23.744), train_loss = 1.20798244, grad/param norm = 1.5369e-01, time/batch = 18.7143s	
14390/30300 (epoch 23.746), train_loss = 1.10236117, grad/param norm = 1.4312e-01, time/batch = 17.8557s	
14391/30300 (epoch 23.748), train_loss = 1.17057353, grad/param norm = 2.1061e-01, time/batch = 18.8731s	
14392/30300 (epoch 23.749), train_loss = 1.22092331, grad/param norm = 1.5903e-01, time/batch = 19.1919s	
14393/30300 (epoch 23.751), train_loss = 1.17002331, grad/param norm = 1.5129e-01, time/batch = 17.6721s	
14394/30300 (epoch 23.752), train_loss = 1.14887776, grad/param norm = 1.5847e-01, time/batch = 18.9509s	
14395/30300 (epoch 23.754), train_loss = 1.09062623, grad/param norm = 1.4448e-01, time/batch = 17.3527s	
14396/30300 (epoch 23.756), train_loss = 1.13865100, grad/param norm = 1.5230e-01, time/batch = 18.8801s	
14397/30300 (epoch 23.757), train_loss = 1.18341030, grad/param norm = 1.6719e-01, time/batch = 19.4555s	
14398/30300 (epoch 23.759), train_loss = 1.20098186, grad/param norm = 1.4383e-01, time/batch = 19.4363s	
14399/30300 (epoch 23.761), train_loss = 1.01012153, grad/param norm = 1.3597e-01, time/batch = 18.1215s	
14400/30300 (epoch 23.762), train_loss = 1.05724379, grad/param norm = 1.4501e-01, time/batch = 17.6976s	
14401/30300 (epoch 23.764), train_loss = 1.14679543, grad/param norm = 1.5000e-01, time/batch = 19.4516s	
14402/30300 (epoch 23.766), train_loss = 1.25254544, grad/param norm = 1.6560e-01, time/batch = 19.8642s	
14403/30300 (epoch 23.767), train_loss = 1.25316398, grad/param norm = 1.9273e-01, time/batch = 19.0186s	
14404/30300 (epoch 23.769), train_loss = 1.21483068, grad/param norm = 1.4896e-01, time/batch = 19.7080s	
14405/30300 (epoch 23.771), train_loss = 1.12037329, grad/param norm = 1.6561e-01, time/batch = 20.2006s	
14406/30300 (epoch 23.772), train_loss = 1.24033311, grad/param norm = 1.6589e-01, time/batch = 17.6196s	
14407/30300 (epoch 23.774), train_loss = 1.31216437, grad/param norm = 1.5015e-01, time/batch = 19.1258s	
14408/30300 (epoch 23.776), train_loss = 1.18785710, grad/param norm = 1.6647e-01, time/batch = 20.4569s	
14409/30300 (epoch 23.777), train_loss = 1.27442628, grad/param norm = 1.5019e-01, time/batch = 17.8714s	
14410/30300 (epoch 23.779), train_loss = 1.31967601, grad/param norm = 1.8377e-01, time/batch = 18.7918s	
14411/30300 (epoch 23.781), train_loss = 1.17977707, grad/param norm = 1.7134e-01, time/batch = 18.8734s	
14412/30300 (epoch 23.782), train_loss = 1.13270169, grad/param norm = 1.6175e-01, time/batch = 18.5332s	
14413/30300 (epoch 23.784), train_loss = 1.12582161, grad/param norm = 1.5481e-01, time/batch = 20.0370s	
14414/30300 (epoch 23.785), train_loss = 1.32147467, grad/param norm = 1.8478e-01, time/batch = 17.7615s	
14415/30300 (epoch 23.787), train_loss = 1.00349745, grad/param norm = 1.5466e-01, time/batch = 17.3815s	
14416/30300 (epoch 23.789), train_loss = 1.41184839, grad/param norm = 1.6941e-01, time/batch = 19.2246s	
14417/30300 (epoch 23.790), train_loss = 1.23644398, grad/param norm = 1.6495e-01, time/batch = 19.2850s	
14418/30300 (epoch 23.792), train_loss = 1.00737209, grad/param norm = 1.4786e-01, time/batch = 18.9616s	
14419/30300 (epoch 23.794), train_loss = 1.17340443, grad/param norm = 1.6969e-01, time/batch = 19.3011s	
14420/30300 (epoch 23.795), train_loss = 1.08925994, grad/param norm = 1.4168e-01, time/batch = 19.7121s	
14421/30300 (epoch 23.797), train_loss = 1.32723436, grad/param norm = 1.7466e-01, time/batch = 19.1195s	
14422/30300 (epoch 23.799), train_loss = 1.23367874, grad/param norm = 1.7024e-01, time/batch = 19.6157s	
14423/30300 (epoch 23.800), train_loss = 1.24687053, grad/param norm = 1.6949e-01, time/batch = 20.1924s	
14424/30300 (epoch 23.802), train_loss = 1.43304123, grad/param norm = 1.8950e-01, time/batch = 18.3653s	
14425/30300 (epoch 23.804), train_loss = 1.27900049, grad/param norm = 1.6391e-01, time/batch = 17.4366s	
14426/30300 (epoch 23.805), train_loss = 1.32232085, grad/param norm = 1.6440e-01, time/batch = 19.7894s	
14427/30300 (epoch 23.807), train_loss = 1.13747184, grad/param norm = 1.4872e-01, time/batch = 17.1049s	
14428/30300 (epoch 23.809), train_loss = 1.26600580, grad/param norm = 1.6768e-01, time/batch = 18.7933s	
14429/30300 (epoch 23.810), train_loss = 1.25895122, grad/param norm = 1.5855e-01, time/batch = 20.2752s	
14430/30300 (epoch 23.812), train_loss = 1.11459071, grad/param norm = 1.6197e-01, time/batch = 19.5339s	
14431/30300 (epoch 23.814), train_loss = 1.17858308, grad/param norm = 1.6056e-01, time/batch = 18.2881s	
14432/30300 (epoch 23.815), train_loss = 1.20364471, grad/param norm = 1.6767e-01, time/batch = 19.5347s	
14433/30300 (epoch 23.817), train_loss = 1.28452122, grad/param norm = 1.6592e-01, time/batch = 19.2770s	
14434/30300 (epoch 23.818), train_loss = 1.23358636, grad/param norm = 1.5589e-01, time/batch = 17.8656s	
14435/30300 (epoch 23.820), train_loss = 1.34170197, grad/param norm = 1.7065e-01, time/batch = 20.6135s	
14436/30300 (epoch 23.822), train_loss = 1.35872627, grad/param norm = 1.7947e-01, time/batch = 19.7894s	
14437/30300 (epoch 23.823), train_loss = 1.36336147, grad/param norm = 1.7171e-01, time/batch = 18.0243s	
14438/30300 (epoch 23.825), train_loss = 1.30054178, grad/param norm = 1.6691e-01, time/batch = 19.3552s	
14439/30300 (epoch 23.827), train_loss = 1.02320720, grad/param norm = 1.7240e-01, time/batch = 20.0425s	
14440/30300 (epoch 23.828), train_loss = 1.27111261, grad/param norm = 1.5508e-01, time/batch = 17.7913s	
14441/30300 (epoch 23.830), train_loss = 1.24102477, grad/param norm = 1.5319e-01, time/batch = 18.5334s	
14442/30300 (epoch 23.832), train_loss = 1.09510791, grad/param norm = 1.5936e-01, time/batch = 19.7077s	
14443/30300 (epoch 23.833), train_loss = 1.23700516, grad/param norm = 1.5870e-01, time/batch = 18.6995s	
14444/30300 (epoch 23.835), train_loss = 1.09597396, grad/param norm = 1.4858e-01, time/batch = 18.8716s	
14445/30300 (epoch 23.837), train_loss = 1.05067129, grad/param norm = 1.4101e-01, time/batch = 19.0236s	
14446/30300 (epoch 23.838), train_loss = 1.06946275, grad/param norm = 1.4191e-01, time/batch = 17.9429s	
14447/30300 (epoch 23.840), train_loss = 1.26339615, grad/param norm = 1.3661e-01, time/batch = 18.6021s	
14448/30300 (epoch 23.842), train_loss = 1.10874474, grad/param norm = 1.3678e-01, time/batch = 19.0394s	
14449/30300 (epoch 23.843), train_loss = 1.22211318, grad/param norm = 1.5137e-01, time/batch = 19.2118s	
14450/30300 (epoch 23.845), train_loss = 1.23435137, grad/param norm = 1.4661e-01, time/batch = 18.0206s	
14451/30300 (epoch 23.847), train_loss = 1.21663144, grad/param norm = 1.5638e-01, time/batch = 19.7018s	
14452/30300 (epoch 23.848), train_loss = 1.28195786, grad/param norm = 1.6237e-01, time/batch = 16.8749s	
14453/30300 (epoch 23.850), train_loss = 1.18853241, grad/param norm = 1.4736e-01, time/batch = 16.7044s	
14454/30300 (epoch 23.851), train_loss = 1.22347440, grad/param norm = 1.8274e-01, time/batch = 19.4568s	
14455/30300 (epoch 23.853), train_loss = 1.13283419, grad/param norm = 1.3766e-01, time/batch = 18.3762s	
14456/30300 (epoch 23.855), train_loss = 1.12527546, grad/param norm = 1.3257e-01, time/batch = 18.6332s	
14457/30300 (epoch 23.856), train_loss = 1.19791414, grad/param norm = 1.4862e-01, time/batch = 18.7200s	
14458/30300 (epoch 23.858), train_loss = 1.10437961, grad/param norm = 1.3329e-01, time/batch = 18.5615s	
14459/30300 (epoch 23.860), train_loss = 1.08389579, grad/param norm = 1.4305e-01, time/batch = 18.2901s	
14460/30300 (epoch 23.861), train_loss = 1.35060390, grad/param norm = 1.5644e-01, time/batch = 18.7946s	
14461/30300 (epoch 23.863), train_loss = 1.18485288, grad/param norm = 1.3706e-01, time/batch = 19.2147s	
14462/30300 (epoch 23.865), train_loss = 1.26146031, grad/param norm = 1.7412e-01, time/batch = 18.9752s	
14463/30300 (epoch 23.866), train_loss = 1.26979510, grad/param norm = 1.7994e-01, time/batch = 17.7671s	
14464/30300 (epoch 23.868), train_loss = 1.18411803, grad/param norm = 1.4817e-01, time/batch = 19.7162s	
14465/30300 (epoch 23.870), train_loss = 1.11685062, grad/param norm = 1.5054e-01, time/batch = 17.2818s	
14466/30300 (epoch 23.871), train_loss = 1.16316978, grad/param norm = 1.4953e-01, time/batch = 18.7000s	
14467/30300 (epoch 23.873), train_loss = 1.19995750, grad/param norm = 1.7303e-01, time/batch = 18.7895s	
14468/30300 (epoch 23.875), train_loss = 1.11513357, grad/param norm = 1.3941e-01, time/batch = 20.2722s	
14469/30300 (epoch 23.876), train_loss = 1.07199226, grad/param norm = 1.6580e-01, time/batch = 17.8874s	
14470/30300 (epoch 23.878), train_loss = 1.02441295, grad/param norm = 1.4339e-01, time/batch = 19.6119s	
14471/30300 (epoch 23.880), train_loss = 1.09548785, grad/param norm = 1.4759e-01, time/batch = 19.7266s	
14472/30300 (epoch 23.881), train_loss = 1.36017535, grad/param norm = 1.9302e-01, time/batch = 18.1987s	
14473/30300 (epoch 23.883), train_loss = 1.24309379, grad/param norm = 1.5269e-01, time/batch = 19.0427s	
14474/30300 (epoch 23.884), train_loss = 1.11185836, grad/param norm = 1.3670e-01, time/batch = 20.3592s	
14475/30300 (epoch 23.886), train_loss = 1.22306957, grad/param norm = 1.4125e-01, time/batch = 18.1930s	
14476/30300 (epoch 23.888), train_loss = 1.17492524, grad/param norm = 1.5646e-01, time/batch = 19.7706s	
14477/30300 (epoch 23.889), train_loss = 1.21193367, grad/param norm = 1.4301e-01, time/batch = 19.3575s	
14478/30300 (epoch 23.891), train_loss = 1.19770347, grad/param norm = 1.5766e-01, time/batch = 18.2023s	
14479/30300 (epoch 23.893), train_loss = 1.40688535, grad/param norm = 1.6397e-01, time/batch = 18.3589s	
14480/30300 (epoch 23.894), train_loss = 1.25263727, grad/param norm = 1.5115e-01, time/batch = 19.2714s	
14481/30300 (epoch 23.896), train_loss = 1.02275779, grad/param norm = 1.5146e-01, time/batch = 19.4462s	
14482/30300 (epoch 23.898), train_loss = 0.99994838, grad/param norm = 1.5023e-01, time/batch = 18.1331s	
14483/30300 (epoch 23.899), train_loss = 1.10144952, grad/param norm = 1.5679e-01, time/batch = 18.9653s	
14484/30300 (epoch 23.901), train_loss = 1.17728509, grad/param norm = 1.7567e-01, time/batch = 19.8774s	
14485/30300 (epoch 23.903), train_loss = 1.19901271, grad/param norm = 1.6198e-01, time/batch = 18.0382s	
14486/30300 (epoch 23.904), train_loss = 1.16031467, grad/param norm = 1.5162e-01, time/batch = 19.7172s	
14487/30300 (epoch 23.906), train_loss = 1.26227804, grad/param norm = 1.6877e-01, time/batch = 18.2866s	
14488/30300 (epoch 23.908), train_loss = 1.13514339, grad/param norm = 1.3803e-01, time/batch = 17.3645s	
14489/30300 (epoch 23.909), train_loss = 1.09186996, grad/param norm = 1.6331e-01, time/batch = 19.0489s	
14490/30300 (epoch 23.911), train_loss = 1.17321969, grad/param norm = 1.3842e-01, time/batch = 18.5419s	
14491/30300 (epoch 23.913), train_loss = 1.16652915, grad/param norm = 1.4475e-01, time/batch = 17.5422s	
14492/30300 (epoch 23.914), train_loss = 1.12489748, grad/param norm = 1.5403e-01, time/batch = 17.1012s	
14493/30300 (epoch 23.916), train_loss = 1.19315122, grad/param norm = 1.3969e-01, time/batch = 18.6140s	
14494/30300 (epoch 23.917), train_loss = 1.12396523, grad/param norm = 1.4709e-01, time/batch = 18.7891s	
14495/30300 (epoch 23.919), train_loss = 1.12894389, grad/param norm = 1.5327e-01, time/batch = 18.2928s	
14496/30300 (epoch 23.921), train_loss = 1.17422637, grad/param norm = 1.4746e-01, time/batch = 19.8762s	
14497/30300 (epoch 23.922), train_loss = 1.28269112, grad/param norm = 1.7770e-01, time/batch = 17.3587s	
14498/30300 (epoch 23.924), train_loss = 1.18451718, grad/param norm = 1.6853e-01, time/batch = 18.3648s	
14499/30300 (epoch 23.926), train_loss = 1.21618001, grad/param norm = 1.4891e-01, time/batch = 20.1100s	
14500/30300 (epoch 23.927), train_loss = 1.18550870, grad/param norm = 1.5545e-01, time/batch = 19.7829s	
14501/30300 (epoch 23.929), train_loss = 1.11411092, grad/param norm = 1.7371e-01, time/batch = 17.8635s	
14502/30300 (epoch 23.931), train_loss = 1.29646646, grad/param norm = 1.8272e-01, time/batch = 20.2911s	
14503/30300 (epoch 23.932), train_loss = 1.11904521, grad/param norm = 1.5840e-01, time/batch = 17.9683s	
14504/30300 (epoch 23.934), train_loss = 1.20743544, grad/param norm = 1.5406e-01, time/batch = 17.2984s	
14505/30300 (epoch 23.936), train_loss = 1.13997355, grad/param norm = 1.4653e-01, time/batch = 19.2938s	
14506/30300 (epoch 23.937), train_loss = 1.10804638, grad/param norm = 1.4696e-01, time/batch = 18.6322s	
14507/30300 (epoch 23.939), train_loss = 1.30583281, grad/param norm = 1.6401e-01, time/batch = 17.7947s	
14508/30300 (epoch 23.941), train_loss = 1.15641055, grad/param norm = 1.6234e-01, time/batch = 17.9355s	
14509/30300 (epoch 23.942), train_loss = 1.16467018, grad/param norm = 1.5432e-01, time/batch = 19.4583s	
14510/30300 (epoch 23.944), train_loss = 1.08314085, grad/param norm = 1.4891e-01, time/batch = 19.0221s	
14511/30300 (epoch 23.946), train_loss = 1.29801737, grad/param norm = 1.8662e-01, time/batch = 18.9481s	
14512/30300 (epoch 23.947), train_loss = 1.27268379, grad/param norm = 1.9279e-01, time/batch = 19.6239s	
14513/30300 (epoch 23.949), train_loss = 1.33877602, grad/param norm = 1.8896e-01, time/batch = 19.0548s	
14514/30300 (epoch 23.950), train_loss = 1.30333407, grad/param norm = 1.6993e-01, time/batch = 17.2714s	
14515/30300 (epoch 23.952), train_loss = 1.25594651, grad/param norm = 1.7555e-01, time/batch = 19.8764s	
14516/30300 (epoch 23.954), train_loss = 1.45853299, grad/param norm = 1.6930e-01, time/batch = 19.7137s	
14517/30300 (epoch 23.955), train_loss = 1.14350759, grad/param norm = 1.5025e-01, time/batch = 18.7139s	
14518/30300 (epoch 23.957), train_loss = 1.24615075, grad/param norm = 1.5243e-01, time/batch = 19.7996s	
14519/30300 (epoch 23.959), train_loss = 1.12221740, grad/param norm = 1.5851e-01, time/batch = 19.2919s	
14520/30300 (epoch 23.960), train_loss = 1.16029154, grad/param norm = 1.6247e-01, time/batch = 17.0259s	
14521/30300 (epoch 23.962), train_loss = 1.17404240, grad/param norm = 1.9696e-01, time/batch = 19.6941s	
14522/30300 (epoch 23.964), train_loss = 1.10089825, grad/param norm = 1.9468e-01, time/batch = 19.0540s	
14523/30300 (epoch 23.965), train_loss = 1.10811502, grad/param norm = 1.6101e-01, time/batch = 18.4503s	
14524/30300 (epoch 23.967), train_loss = 1.17565791, grad/param norm = 1.7713e-01, time/batch = 19.1309s	
14525/30300 (epoch 23.969), train_loss = 1.10843859, grad/param norm = 1.6651e-01, time/batch = 18.1322s	
14526/30300 (epoch 23.970), train_loss = 1.15139113, grad/param norm = 1.4665e-01, time/batch = 16.7031s	
14527/30300 (epoch 23.972), train_loss = 1.05725013, grad/param norm = 1.5618e-01, time/batch = 18.1265s	
14528/30300 (epoch 23.974), train_loss = 1.35625869, grad/param norm = 1.7880e-01, time/batch = 17.9662s	
14529/30300 (epoch 23.975), train_loss = 1.39855751, grad/param norm = 2.2088e-01, time/batch = 18.5331s	
14530/30300 (epoch 23.977), train_loss = 1.30519479, grad/param norm = 1.6322e-01, time/batch = 18.1348s	
14531/30300 (epoch 23.979), train_loss = 1.25577925, grad/param norm = 1.5507e-01, time/batch = 18.9685s	
14532/30300 (epoch 23.980), train_loss = 1.26111680, grad/param norm = 1.7307e-01, time/batch = 19.5430s	
14533/30300 (epoch 23.982), train_loss = 1.26590664, grad/param norm = 1.6563e-01, time/batch = 17.8774s	
14534/30300 (epoch 23.983), train_loss = 1.31038684, grad/param norm = 1.6157e-01, time/batch = 18.4706s	
14535/30300 (epoch 23.985), train_loss = 1.24612324, grad/param norm = 1.7887e-01, time/batch = 18.9707s	
14536/30300 (epoch 23.987), train_loss = 1.16874551, grad/param norm = 1.4791e-01, time/batch = 18.1970s	
14537/30300 (epoch 23.988), train_loss = 1.33365490, grad/param norm = 1.6198e-01, time/batch = 18.6101s	
14538/30300 (epoch 23.990), train_loss = 1.03206289, grad/param norm = 1.3587e-01, time/batch = 16.3455s	
14539/30300 (epoch 23.992), train_loss = 1.24896610, grad/param norm = 1.4314e-01, time/batch = 18.3565s	
14540/30300 (epoch 23.993), train_loss = 1.32276343, grad/param norm = 2.0228e-01, time/batch = 18.8672s	
14541/30300 (epoch 23.995), train_loss = 1.16808798, grad/param norm = 1.5963e-01, time/batch = 18.7878s	
14542/30300 (epoch 23.997), train_loss = 1.22322850, grad/param norm = 1.5940e-01, time/batch = 18.7149s	
14543/30300 (epoch 23.998), train_loss = 1.26348421, grad/param norm = 1.6851e-01, time/batch = 17.6039s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
14544/30300 (epoch 24.000), train_loss = 1.15031681, grad/param norm = 1.7212e-01, time/batch = 18.5471s	
14545/30300 (epoch 24.002), train_loss = 1.28483797, grad/param norm = 1.6385e-01, time/batch = 19.8781s	
14546/30300 (epoch 24.003), train_loss = 1.19549686, grad/param norm = 1.6246e-01, time/batch = 18.4423s	
14547/30300 (epoch 24.005), train_loss = 1.16637415, grad/param norm = 1.6232e-01, time/batch = 16.7105s	
14548/30300 (epoch 24.007), train_loss = 1.24903917, grad/param norm = 1.7189e-01, time/batch = 14.9310s	
14549/30300 (epoch 24.008), train_loss = 1.11896536, grad/param norm = 1.5679e-01, time/batch = 14.7983s	
14550/30300 (epoch 24.010), train_loss = 1.06897676, grad/param norm = 1.6530e-01, time/batch = 17.1262s	
14551/30300 (epoch 24.012), train_loss = 1.12694834, grad/param norm = 1.4761e-01, time/batch = 18.9730s	
14552/30300 (epoch 24.013), train_loss = 1.30029200, grad/param norm = 1.6489e-01, time/batch = 17.7151s	
14553/30300 (epoch 24.015), train_loss = 1.14264548, grad/param norm = 1.5240e-01, time/batch = 17.6079s	
14554/30300 (epoch 24.017), train_loss = 1.14206730, grad/param norm = 1.4319e-01, time/batch = 19.7108s	
14555/30300 (epoch 24.018), train_loss = 1.09032637, grad/param norm = 1.4135e-01, time/batch = 18.3818s	
14556/30300 (epoch 24.020), train_loss = 1.28781392, grad/param norm = 1.8490e-01, time/batch = 18.0296s	
14557/30300 (epoch 24.021), train_loss = 1.29503928, grad/param norm = 1.6080e-01, time/batch = 18.2954s	
14558/30300 (epoch 24.023), train_loss = 1.19458553, grad/param norm = 1.5897e-01, time/batch = 19.8917s	
14559/30300 (epoch 24.025), train_loss = 1.10697032, grad/param norm = 1.6765e-01, time/batch = 18.3024s	
14560/30300 (epoch 24.026), train_loss = 1.23497902, grad/param norm = 1.8409e-01, time/batch = 19.3758s	
14561/30300 (epoch 24.028), train_loss = 1.26770377, grad/param norm = 1.5438e-01, time/batch = 19.8725s	
14562/30300 (epoch 24.030), train_loss = 1.12645226, grad/param norm = 1.5957e-01, time/batch = 16.3404s	
14563/30300 (epoch 24.031), train_loss = 1.23045689, grad/param norm = 1.5396e-01, time/batch = 19.4511s	
14564/30300 (epoch 24.033), train_loss = 1.18076209, grad/param norm = 1.5771e-01, time/batch = 19.6321s	
14565/30300 (epoch 24.035), train_loss = 1.28595147, grad/param norm = 2.2265e-01, time/batch = 18.4779s	
14566/30300 (epoch 24.036), train_loss = 1.18587989, grad/param norm = 1.5314e-01, time/batch = 17.9493s	
14567/30300 (epoch 24.038), train_loss = 1.21935934, grad/param norm = 1.5296e-01, time/batch = 19.1435s	
14568/30300 (epoch 24.040), train_loss = 0.92886080, grad/param norm = 1.3060e-01, time/batch = 19.3889s	
14569/30300 (epoch 24.041), train_loss = 0.98678053, grad/param norm = 1.3826e-01, time/batch = 32.2057s	
14570/30300 (epoch 24.043), train_loss = 1.19320713, grad/param norm = 1.6315e-01, time/batch = 18.3755s	
14571/30300 (epoch 24.045), train_loss = 1.16870818, grad/param norm = 1.4944e-01, time/batch = 17.7947s	
14572/30300 (epoch 24.046), train_loss = 1.33618435, grad/param norm = 1.8695e-01, time/batch = 16.9462s	
14573/30300 (epoch 24.048), train_loss = 1.16044101, grad/param norm = 1.6816e-01, time/batch = 18.2917s	
14574/30300 (epoch 24.050), train_loss = 1.13991440, grad/param norm = 1.5879e-01, time/batch = 19.2117s	
14575/30300 (epoch 24.051), train_loss = 1.21057506, grad/param norm = 1.6785e-01, time/batch = 16.9540s	
14576/30300 (epoch 24.053), train_loss = 1.00573216, grad/param norm = 1.7620e-01, time/batch = 17.5206s	
14577/30300 (epoch 24.054), train_loss = 1.18448564, grad/param norm = 1.5893e-01, time/batch = 19.1295s	
14578/30300 (epoch 24.056), train_loss = 1.10216162, grad/param norm = 1.4491e-01, time/batch = 18.4560s	
14579/30300 (epoch 24.058), train_loss = 1.15576906, grad/param norm = 1.5188e-01, time/batch = 19.1299s	
14580/30300 (epoch 24.059), train_loss = 1.08322541, grad/param norm = 1.5767e-01, time/batch = 19.4598s	
14581/30300 (epoch 24.061), train_loss = 1.23502698, grad/param norm = 1.5976e-01, time/batch = 17.9666s	
14582/30300 (epoch 24.063), train_loss = 1.07344873, grad/param norm = 1.5833e-01, time/batch = 19.1994s	
14583/30300 (epoch 24.064), train_loss = 1.18817901, grad/param norm = 1.6590e-01, time/batch = 20.0412s	
14584/30300 (epoch 24.066), train_loss = 1.17194471, grad/param norm = 1.5029e-01, time/batch = 18.3773s	
14585/30300 (epoch 24.068), train_loss = 1.07458757, grad/param norm = 1.5443e-01, time/batch = 18.7987s	
14586/30300 (epoch 24.069), train_loss = 1.23738332, grad/param norm = 1.7104e-01, time/batch = 18.8649s	
14587/30300 (epoch 24.071), train_loss = 1.24110996, grad/param norm = 1.8277e-01, time/batch = 18.2177s	
14588/30300 (epoch 24.073), train_loss = 1.14244419, grad/param norm = 1.6952e-01, time/batch = 17.8743s	
14589/30300 (epoch 24.074), train_loss = 1.20097130, grad/param norm = 1.4594e-01, time/batch = 19.0890s	
14590/30300 (epoch 24.076), train_loss = 1.13090164, grad/param norm = 1.4582e-01, time/batch = 19.6156s	
14591/30300 (epoch 24.078), train_loss = 1.08862439, grad/param norm = 1.4532e-01, time/batch = 19.1070s	
14592/30300 (epoch 24.079), train_loss = 1.11172856, grad/param norm = 1.4403e-01, time/batch = 19.3015s	
14593/30300 (epoch 24.081), train_loss = 1.18632118, grad/param norm = 1.5907e-01, time/batch = 17.4562s	
14594/30300 (epoch 24.083), train_loss = 1.24863073, grad/param norm = 2.1105e-01, time/batch = 18.0474s	
14595/30300 (epoch 24.084), train_loss = 1.07977056, grad/param norm = 1.6878e-01, time/batch = 17.8596s	
14596/30300 (epoch 24.086), train_loss = 1.11692691, grad/param norm = 1.6701e-01, time/batch = 19.6175s	
14597/30300 (epoch 24.087), train_loss = 1.09252402, grad/param norm = 1.4444e-01, time/batch = 18.2884s	
14598/30300 (epoch 24.089), train_loss = 1.14274005, grad/param norm = 1.5696e-01, time/batch = 18.8131s	
14599/30300 (epoch 24.091), train_loss = 1.19805891, grad/param norm = 1.5181e-01, time/batch = 19.8630s	
14600/30300 (epoch 24.092), train_loss = 1.22057312, grad/param norm = 1.5420e-01, time/batch = 18.3551s	
14601/30300 (epoch 24.094), train_loss = 1.34622245, grad/param norm = 1.8616e-01, time/batch = 18.7036s	
14602/30300 (epoch 24.096), train_loss = 1.27336195, grad/param norm = 1.6802e-01, time/batch = 18.1718s	
14603/30300 (epoch 24.097), train_loss = 1.13142955, grad/param norm = 1.6619e-01, time/batch = 18.6259s	
14604/30300 (epoch 24.099), train_loss = 1.29206544, grad/param norm = 1.7217e-01, time/batch = 18.5335s	
14605/30300 (epoch 24.101), train_loss = 1.32851944, grad/param norm = 1.9421e-01, time/batch = 19.6251s	
14606/30300 (epoch 24.102), train_loss = 1.10724271, grad/param norm = 1.9127e-01, time/batch = 18.9611s	
14607/30300 (epoch 24.104), train_loss = 1.17596180, grad/param norm = 2.3451e-01, time/batch = 16.6926s	
14608/30300 (epoch 24.106), train_loss = 1.17919836, grad/param norm = 3.5685e-01, time/batch = 19.2868s	
14609/30300 (epoch 24.107), train_loss = 1.22987309, grad/param norm = 1.6790e-01, time/batch = 19.8741s	
14610/30300 (epoch 24.109), train_loss = 1.26637011, grad/param norm = 2.0373e-01, time/batch = 18.3616s	
14611/30300 (epoch 24.111), train_loss = 1.28491449, grad/param norm = 1.5958e-01, time/batch = 19.0357s	
14612/30300 (epoch 24.112), train_loss = 1.28592299, grad/param norm = 1.6420e-01, time/batch = 20.1155s	
14613/30300 (epoch 24.114), train_loss = 1.16278577, grad/param norm = 1.5451e-01, time/batch = 18.4689s	
14614/30300 (epoch 24.116), train_loss = 1.18367182, grad/param norm = 1.7573e-01, time/batch = 19.0419s	
14615/30300 (epoch 24.117), train_loss = 1.24514033, grad/param norm = 1.4698e-01, time/batch = 19.2913s	
14616/30300 (epoch 24.119), train_loss = 1.11794768, grad/param norm = 1.7560e-01, time/batch = 17.5264s	
14617/30300 (epoch 24.120), train_loss = 1.18420555, grad/param norm = 1.6678e-01, time/batch = 19.7041s	
14618/30300 (epoch 24.122), train_loss = 1.27071088, grad/param norm = 1.8801e-01, time/batch = 16.9552s	
14619/30300 (epoch 24.124), train_loss = 1.33165207, grad/param norm = 1.7611e-01, time/batch = 18.6963s	
14620/30300 (epoch 24.125), train_loss = 1.05491465, grad/param norm = 1.6744e-01, time/batch = 19.3544s	
14621/30300 (epoch 24.127), train_loss = 1.22699867, grad/param norm = 2.0004e-01, time/batch = 18.9424s	
14622/30300 (epoch 24.129), train_loss = 1.33667290, grad/param norm = 1.7095e-01, time/batch = 19.3701s	
14623/30300 (epoch 24.130), train_loss = 1.31341335, grad/param norm = 1.5726e-01, time/batch = 18.7929s	
14624/30300 (epoch 24.132), train_loss = 1.31771181, grad/param norm = 1.8086e-01, time/batch = 18.4459s	
14625/30300 (epoch 24.134), train_loss = 1.08451961, grad/param norm = 1.5207e-01, time/batch = 19.1169s	
14626/30300 (epoch 24.135), train_loss = 1.11045363, grad/param norm = 1.5728e-01, time/batch = 18.5345s	
14627/30300 (epoch 24.137), train_loss = 1.19407499, grad/param norm = 1.6425e-01, time/batch = 20.1226s	
14628/30300 (epoch 24.139), train_loss = 1.16436880, grad/param norm = 1.8453e-01, time/batch = 19.3725s	
14629/30300 (epoch 24.140), train_loss = 1.24672534, grad/param norm = 2.7740e-01, time/batch = 18.7879s	
14630/30300 (epoch 24.142), train_loss = 1.31991739, grad/param norm = 1.7134e-01, time/batch = 19.7170s	
14631/30300 (epoch 24.144), train_loss = 1.17792546, grad/param norm = 1.9511e-01, time/batch = 20.1949s	
14632/30300 (epoch 24.145), train_loss = 1.29938887, grad/param norm = 1.8953e-01, time/batch = 18.0140s	
14633/30300 (epoch 24.147), train_loss = 1.15588960, grad/param norm = 1.6763e-01, time/batch = 20.0278s	
14634/30300 (epoch 24.149), train_loss = 1.36063291, grad/param norm = 1.9101e-01, time/batch = 20.1277s	
14635/30300 (epoch 24.150), train_loss = 1.16263540, grad/param norm = 1.6959e-01, time/batch = 18.7828s	
14636/30300 (epoch 24.152), train_loss = 1.07743898, grad/param norm = 1.7673e-01, time/batch = 18.6125s	
14637/30300 (epoch 24.153), train_loss = 1.19101922, grad/param norm = 1.7092e-01, time/batch = 19.5364s	
14638/30300 (epoch 24.155), train_loss = 1.04312335, grad/param norm = 1.5706e-01, time/batch = 18.7036s	
14639/30300 (epoch 24.157), train_loss = 1.15526063, grad/param norm = 1.6321e-01, time/batch = 18.3424s	
14640/30300 (epoch 24.158), train_loss = 1.19739496, grad/param norm = 1.8943e-01, time/batch = 19.7890s	
14641/30300 (epoch 24.160), train_loss = 1.10851794, grad/param norm = 1.5090e-01, time/batch = 18.4734s	
14642/30300 (epoch 24.162), train_loss = 1.16481551, grad/param norm = 1.6075e-01, time/batch = 18.8706s	
14643/30300 (epoch 24.163), train_loss = 1.14819346, grad/param norm = 1.6179e-01, time/batch = 20.3802s	
14644/30300 (epoch 24.165), train_loss = 1.28619402, grad/param norm = 1.5311e-01, time/batch = 19.0490s	
14645/30300 (epoch 24.167), train_loss = 1.16136143, grad/param norm = 1.7522e-01, time/batch = 17.1106s	
14646/30300 (epoch 24.168), train_loss = 1.25837246, grad/param norm = 1.7790e-01, time/batch = 19.9569s	
14647/30300 (epoch 24.170), train_loss = 1.19436494, grad/param norm = 1.6740e-01, time/batch = 18.5204s	
14648/30300 (epoch 24.172), train_loss = 1.16924209, grad/param norm = 1.7436e-01, time/batch = 17.7614s	
14649/30300 (epoch 24.173), train_loss = 1.16975567, grad/param norm = 1.7619e-01, time/batch = 14.9985s	
14650/30300 (epoch 24.175), train_loss = 1.18809129, grad/param norm = 1.6350e-01, time/batch = 14.8210s	
14651/30300 (epoch 24.177), train_loss = 1.22270552, grad/param norm = 1.8082e-01, time/batch = 18.5379s	
14652/30300 (epoch 24.178), train_loss = 0.97124840, grad/param norm = 1.5398e-01, time/batch = 18.3006s	
14653/30300 (epoch 24.180), train_loss = 1.15814932, grad/param norm = 1.5124e-01, time/batch = 19.2737s	
14654/30300 (epoch 24.182), train_loss = 1.17225137, grad/param norm = 1.9493e-01, time/batch = 18.1351s	
14655/30300 (epoch 24.183), train_loss = 1.13026772, grad/param norm = 1.6404e-01, time/batch = 19.2087s	
14656/30300 (epoch 24.185), train_loss = 1.36538992, grad/param norm = 1.8830e-01, time/batch = 19.6319s	
14657/30300 (epoch 24.186), train_loss = 1.40524123, grad/param norm = 2.0018e-01, time/batch = 18.6301s	
14658/30300 (epoch 24.188), train_loss = 1.22660153, grad/param norm = 1.6793e-01, time/batch = 19.0302s	
14659/30300 (epoch 24.190), train_loss = 1.17216848, grad/param norm = 1.4410e-01, time/batch = 19.8804s	
14660/30300 (epoch 24.191), train_loss = 1.25103659, grad/param norm = 1.6072e-01, time/batch = 18.2204s	
14661/30300 (epoch 24.193), train_loss = 1.09612203, grad/param norm = 1.3980e-01, time/batch = 19.1893s	
14662/30300 (epoch 24.195), train_loss = 1.17873486, grad/param norm = 1.6096e-01, time/batch = 20.0381s	
14663/30300 (epoch 24.196), train_loss = 1.21668484, grad/param norm = 1.3707e-01, time/batch = 18.0365s	
14664/30300 (epoch 24.198), train_loss = 1.01758845, grad/param norm = 1.5710e-01, time/batch = 18.1115s	
14665/30300 (epoch 24.200), train_loss = 1.16755886, grad/param norm = 1.4794e-01, time/batch = 18.3647s	
14666/30300 (epoch 24.201), train_loss = 1.25317272, grad/param norm = 1.8988e-01, time/batch = 15.4482s	
14667/30300 (epoch 24.203), train_loss = 1.19958480, grad/param norm = 1.6079e-01, time/batch = 15.5116s	
14668/30300 (epoch 24.205), train_loss = 1.39681073, grad/param norm = 1.7753e-01, time/batch = 15.7576s	
14669/30300 (epoch 24.206), train_loss = 1.30225243, grad/param norm = 2.0122e-01, time/batch = 16.6736s	
14670/30300 (epoch 24.208), train_loss = 1.27266217, grad/param norm = 1.8451e-01, time/batch = 17.9663s	
14671/30300 (epoch 24.210), train_loss = 1.24611137, grad/param norm = 1.6624e-01, time/batch = 17.6114s	
14672/30300 (epoch 24.211), train_loss = 1.29879863, grad/param norm = 1.6593e-01, time/batch = 19.0377s	
14673/30300 (epoch 24.213), train_loss = 1.13921552, grad/param norm = 1.3997e-01, time/batch = 18.5328s	
14674/30300 (epoch 24.215), train_loss = 1.10126572, grad/param norm = 1.6311e-01, time/batch = 18.2871s	
14675/30300 (epoch 24.216), train_loss = 1.15114171, grad/param norm = 1.7162e-01, time/batch = 18.3741s	
14676/30300 (epoch 24.218), train_loss = 1.06521362, grad/param norm = 1.3190e-01, time/batch = 17.3558s	
14677/30300 (epoch 24.219), train_loss = 1.03392018, grad/param norm = 1.4743e-01, time/batch = 17.9395s	
14678/30300 (epoch 24.221), train_loss = 1.02811980, grad/param norm = 1.4240e-01, time/batch = 19.1105s	
14679/30300 (epoch 24.223), train_loss = 1.20401350, grad/param norm = 1.5881e-01, time/batch = 16.3680s	
14680/30300 (epoch 24.224), train_loss = 1.01215165, grad/param norm = 1.4818e-01, time/batch = 19.5369s	
14681/30300 (epoch 24.226), train_loss = 1.24846767, grad/param norm = 1.8671e-01, time/batch = 18.0971s	
14682/30300 (epoch 24.228), train_loss = 1.26919312, grad/param norm = 1.5903e-01, time/batch = 18.6408s	
14683/30300 (epoch 24.229), train_loss = 1.15229274, grad/param norm = 1.5190e-01, time/batch = 18.7968s	
14684/30300 (epoch 24.231), train_loss = 1.21015776, grad/param norm = 1.5403e-01, time/batch = 18.6949s	
14685/30300 (epoch 24.233), train_loss = 1.19570700, grad/param norm = 1.4683e-01, time/batch = 18.3741s	
14686/30300 (epoch 24.234), train_loss = 1.24745211, grad/param norm = 1.8316e-01, time/batch = 20.0351s	
14687/30300 (epoch 24.236), train_loss = 1.20058851, grad/param norm = 1.3926e-01, time/batch = 17.5142s	
14688/30300 (epoch 24.238), train_loss = 1.22586754, grad/param norm = 1.7127e-01, time/batch = 19.8784s	
14689/30300 (epoch 24.239), train_loss = 1.21901204, grad/param norm = 1.6828e-01, time/batch = 18.2162s	
14690/30300 (epoch 24.241), train_loss = 1.21994673, grad/param norm = 1.7366e-01, time/batch = 18.7018s	
14691/30300 (epoch 24.243), train_loss = 1.23397336, grad/param norm = 1.6239e-01, time/batch = 18.9621s	
14692/30300 (epoch 24.244), train_loss = 1.41231102, grad/param norm = 1.6281e-01, time/batch = 18.5245s	
14693/30300 (epoch 24.246), train_loss = 1.20842559, grad/param norm = 1.7290e-01, time/batch = 17.9585s	
14694/30300 (epoch 24.248), train_loss = 1.16069182, grad/param norm = 1.5088e-01, time/batch = 16.3417s	
14695/30300 (epoch 24.249), train_loss = 1.12002429, grad/param norm = 1.5174e-01, time/batch = 19.2929s	
14696/30300 (epoch 24.251), train_loss = 1.11623597, grad/param norm = 1.7779e-01, time/batch = 19.8797s	
14697/30300 (epoch 24.252), train_loss = 1.29652860, grad/param norm = 1.7195e-01, time/batch = 17.6175s	
14698/30300 (epoch 24.254), train_loss = 1.27967981, grad/param norm = 1.7734e-01, time/batch = 19.4423s	
14699/30300 (epoch 24.256), train_loss = 1.21801761, grad/param norm = 1.4940e-01, time/batch = 20.1106s	
14700/30300 (epoch 24.257), train_loss = 1.24968673, grad/param norm = 1.6206e-01, time/batch = 18.0397s	
14701/30300 (epoch 24.259), train_loss = 1.16388449, grad/param norm = 1.6414e-01, time/batch = 18.3660s	
14702/30300 (epoch 24.261), train_loss = 1.28684949, grad/param norm = 1.5840e-01, time/batch = 19.1138s	
14703/30300 (epoch 24.262), train_loss = 1.16423833, grad/param norm = 1.5515e-01, time/batch = 15.7748s	
14704/30300 (epoch 24.264), train_loss = 1.18430204, grad/param norm = 1.4545e-01, time/batch = 19.0471s	
14705/30300 (epoch 24.266), train_loss = 1.11668596, grad/param norm = 1.4302e-01, time/batch = 19.4364s	
14706/30300 (epoch 24.267), train_loss = 1.36009297, grad/param norm = 1.8260e-01, time/batch = 18.4721s	
14707/30300 (epoch 24.269), train_loss = 1.21945639, grad/param norm = 1.6128e-01, time/batch = 18.7882s	
14708/30300 (epoch 24.271), train_loss = 1.22790121, grad/param norm = 1.6184e-01, time/batch = 19.1291s	
14709/30300 (epoch 24.272), train_loss = 1.20644090, grad/param norm = 1.7906e-01, time/batch = 18.7991s	
14710/30300 (epoch 24.274), train_loss = 1.28061950, grad/param norm = 1.6049e-01, time/batch = 18.1331s	
14711/30300 (epoch 24.276), train_loss = 1.23432957, grad/param norm = 1.6039e-01, time/batch = 19.2901s	
14712/30300 (epoch 24.277), train_loss = 1.05446449, grad/param norm = 1.6041e-01, time/batch = 20.3691s	
14713/30300 (epoch 24.279), train_loss = 1.22472127, grad/param norm = 1.7971e-01, time/batch = 18.5330s	
14714/30300 (epoch 24.281), train_loss = 1.28897724, grad/param norm = 1.8260e-01, time/batch = 18.7995s	
14715/30300 (epoch 24.282), train_loss = 1.19648672, grad/param norm = 1.4489e-01, time/batch = 18.4736s	
14716/30300 (epoch 24.284), train_loss = 1.31930033, grad/param norm = 1.9559e-01, time/batch = 17.2915s	
14717/30300 (epoch 24.285), train_loss = 1.26348250, grad/param norm = 1.4776e-01, time/batch = 19.2797s	
14718/30300 (epoch 24.287), train_loss = 1.19618023, grad/param norm = 1.6778e-01, time/batch = 17.1028s	
14719/30300 (epoch 24.289), train_loss = 1.25764542, grad/param norm = 1.4879e-01, time/batch = 17.6087s	
14720/30300 (epoch 24.290), train_loss = 0.95399606, grad/param norm = 1.4266e-01, time/batch = 19.1378s	
14721/30300 (epoch 24.292), train_loss = 1.09314126, grad/param norm = 1.3783e-01, time/batch = 19.0522s	
14722/30300 (epoch 24.294), train_loss = 1.29229328, grad/param norm = 2.0390e-01, time/batch = 19.2070s	
14723/30300 (epoch 24.295), train_loss = 1.14787391, grad/param norm = 1.5413e-01, time/batch = 18.7856s	
14724/30300 (epoch 24.297), train_loss = 1.13609433, grad/param norm = 1.5271e-01, time/batch = 19.6330s	
14725/30300 (epoch 24.299), train_loss = 1.16727246, grad/param norm = 1.5368e-01, time/batch = 18.8070s	
14726/30300 (epoch 24.300), train_loss = 1.12708159, grad/param norm = 1.4883e-01, time/batch = 19.5241s	
14727/30300 (epoch 24.302), train_loss = 1.19602395, grad/param norm = 1.5192e-01, time/batch = 19.1327s	
14728/30300 (epoch 24.304), train_loss = 1.10374976, grad/param norm = 1.5581e-01, time/batch = 18.9615s	
14729/30300 (epoch 24.305), train_loss = 1.13525277, grad/param norm = 1.3822e-01, time/batch = 18.1977s	
14730/30300 (epoch 24.307), train_loss = 1.24279412, grad/param norm = 1.4156e-01, time/batch = 19.1119s	
14731/30300 (epoch 24.309), train_loss = 1.24253372, grad/param norm = 1.6221e-01, time/batch = 19.1193s	
14732/30300 (epoch 24.310), train_loss = 1.18956970, grad/param norm = 1.6049e-01, time/batch = 17.2720s	
14733/30300 (epoch 24.312), train_loss = 1.31867876, grad/param norm = 1.5579e-01, time/batch = 19.2666s	
14734/30300 (epoch 24.314), train_loss = 1.19224120, grad/param norm = 1.5888e-01, time/batch = 18.0419s	
14735/30300 (epoch 24.315), train_loss = 1.17353816, grad/param norm = 1.5389e-01, time/batch = 17.0369s	
14736/30300 (epoch 24.317), train_loss = 1.23833827, grad/param norm = 1.5319e-01, time/batch = 19.3026s	
14737/30300 (epoch 24.318), train_loss = 1.28623024, grad/param norm = 1.6823e-01, time/batch = 18.9611s	
14738/30300 (epoch 24.320), train_loss = 1.26930597, grad/param norm = 1.6525e-01, time/batch = 19.2786s	
14739/30300 (epoch 24.322), train_loss = 1.11256975, grad/param norm = 1.4733e-01, time/batch = 19.4694s	
14740/30300 (epoch 24.323), train_loss = 1.28598818, grad/param norm = 1.7147e-01, time/batch = 20.0468s	
14741/30300 (epoch 24.325), train_loss = 1.18299131, grad/param norm = 1.5322e-01, time/batch = 19.7812s	
14742/30300 (epoch 24.327), train_loss = 1.18479856, grad/param norm = 1.4466e-01, time/batch = 18.4610s	
14743/30300 (epoch 24.328), train_loss = 1.18429001, grad/param norm = 1.3954e-01, time/batch = 19.7980s	
14744/30300 (epoch 24.330), train_loss = 1.23693541, grad/param norm = 1.5402e-01, time/batch = 18.3595s	
14745/30300 (epoch 24.332), train_loss = 1.26795526, grad/param norm = 1.7579e-01, time/batch = 17.4353s	
14746/30300 (epoch 24.333), train_loss = 1.16338427, grad/param norm = 1.7084e-01, time/batch = 18.2813s	
14747/30300 (epoch 24.335), train_loss = 1.07829655, grad/param norm = 1.6156e-01, time/batch = 19.0419s	
14748/30300 (epoch 24.337), train_loss = 1.33084301, grad/param norm = 1.5215e-01, time/batch = 18.2030s	
14749/30300 (epoch 24.338), train_loss = 1.12186448, grad/param norm = 1.4161e-01, time/batch = 17.2063s	
14750/30300 (epoch 24.340), train_loss = 1.10016682, grad/param norm = 1.4302e-01, time/batch = 19.4596s	
14751/30300 (epoch 24.342), train_loss = 1.26915261, grad/param norm = 1.5069e-01, time/batch = 18.2112s	
14752/30300 (epoch 24.343), train_loss = 1.21340398, grad/param norm = 1.5617e-01, time/batch = 20.1258s	
14753/30300 (epoch 24.345), train_loss = 1.22848595, grad/param norm = 1.5192e-01, time/batch = 18.9636s	
14754/30300 (epoch 24.347), train_loss = 1.06028109, grad/param norm = 1.6278e-01, time/batch = 18.5571s	
14755/30300 (epoch 24.348), train_loss = 1.10975595, grad/param norm = 1.5492e-01, time/batch = 19.3751s	
14756/30300 (epoch 24.350), train_loss = 1.17431636, grad/param norm = 1.5044e-01, time/batch = 19.8787s	
14757/30300 (epoch 24.351), train_loss = 1.18700260, grad/param norm = 1.5901e-01, time/batch = 17.7188s	
14758/30300 (epoch 24.353), train_loss = 1.04549924, grad/param norm = 1.5107e-01, time/batch = 19.4735s	
14759/30300 (epoch 24.355), train_loss = 1.14118222, grad/param norm = 1.4557e-01, time/batch = 18.7988s	
14760/30300 (epoch 24.356), train_loss = 1.26521879, grad/param norm = 1.6727e-01, time/batch = 20.6639s	
14761/30300 (epoch 24.358), train_loss = 1.41484518, grad/param norm = 1.4547e-01, time/batch = 30.2485s	
14762/30300 (epoch 24.360), train_loss = 1.14354649, grad/param norm = 1.9468e-01, time/batch = 18.0266s	
14763/30300 (epoch 24.361), train_loss = 1.21007839, grad/param norm = 1.5583e-01, time/batch = 16.4613s	
14764/30300 (epoch 24.363), train_loss = 1.25353997, grad/param norm = 1.7233e-01, time/batch = 17.8745s	
14765/30300 (epoch 24.365), train_loss = 1.09002490, grad/param norm = 1.6868e-01, time/batch = 17.2075s	
14766/30300 (epoch 24.366), train_loss = 1.14134740, grad/param norm = 1.4707e-01, time/batch = 17.0430s	
14767/30300 (epoch 24.368), train_loss = 1.02331580, grad/param norm = 1.3760e-01, time/batch = 17.7660s	
14768/30300 (epoch 24.370), train_loss = 1.09092153, grad/param norm = 1.3928e-01, time/batch = 17.7920s	
14769/30300 (epoch 24.371), train_loss = 1.26747805, grad/param norm = 1.6207e-01, time/batch = 18.0534s	
14770/30300 (epoch 24.373), train_loss = 1.09722893, grad/param norm = 1.3232e-01, time/batch = 16.8387s	
14771/30300 (epoch 24.375), train_loss = 1.10538800, grad/param norm = 1.5681e-01, time/batch = 17.2007s	
14772/30300 (epoch 24.376), train_loss = 1.10012874, grad/param norm = 1.4585e-01, time/batch = 17.8051s	
14773/30300 (epoch 24.378), train_loss = 1.09374669, grad/param norm = 1.5793e-01, time/batch = 17.6240s	
14774/30300 (epoch 24.380), train_loss = 1.34893583, grad/param norm = 1.7307e-01, time/batch = 17.3576s	
14775/30300 (epoch 24.381), train_loss = 1.03952284, grad/param norm = 1.4026e-01, time/batch = 18.1299s	
14776/30300 (epoch 24.383), train_loss = 1.11068579, grad/param norm = 1.8608e-01, time/batch = 19.0338s	
14777/30300 (epoch 24.384), train_loss = 1.23661510, grad/param norm = 1.5887e-01, time/batch = 18.8777s	
14778/30300 (epoch 24.386), train_loss = 1.07276064, grad/param norm = 1.4954e-01, time/batch = 17.7122s	
14779/30300 (epoch 24.388), train_loss = 1.02452620, grad/param norm = 1.3524e-01, time/batch = 19.1046s	
14780/30300 (epoch 24.389), train_loss = 1.15189778, grad/param norm = 1.6752e-01, time/batch = 18.4470s	
14781/30300 (epoch 24.391), train_loss = 1.22572707, grad/param norm = 1.5148e-01, time/batch = 19.1182s	
14782/30300 (epoch 24.393), train_loss = 1.04408496, grad/param norm = 1.4988e-01, time/batch = 19.9607s	
14783/30300 (epoch 24.394), train_loss = 1.24095416, grad/param norm = 1.5158e-01, time/batch = 16.9290s	
14784/30300 (epoch 24.396), train_loss = 1.30580720, grad/param norm = 1.5212e-01, time/batch = 19.2979s	
14785/30300 (epoch 24.398), train_loss = 1.15261384, grad/param norm = 1.5168e-01, time/batch = 18.6344s	
14786/30300 (epoch 24.399), train_loss = 1.14673955, grad/param norm = 1.5854e-01, time/batch = 18.2908s	
14787/30300 (epoch 24.401), train_loss = 1.20262598, grad/param norm = 1.5386e-01, time/batch = 18.6238s	
14788/30300 (epoch 24.403), train_loss = 1.16155112, grad/param norm = 1.5620e-01, time/batch = 19.1930s	
14789/30300 (epoch 24.404), train_loss = 1.09941079, grad/param norm = 1.8593e-01, time/batch = 17.4565s	
14790/30300 (epoch 24.406), train_loss = 1.20875364, grad/param norm = 1.5321e-01, time/batch = 18.8001s	
14791/30300 (epoch 24.408), train_loss = 1.05076074, grad/param norm = 1.4554e-01, time/batch = 19.8942s	
14792/30300 (epoch 24.409), train_loss = 1.05689609, grad/param norm = 1.5293e-01, time/batch = 18.2948s	
14793/30300 (epoch 24.411), train_loss = 1.07614517, grad/param norm = 1.3759e-01, time/batch = 17.8733s	
14794/30300 (epoch 24.413), train_loss = 0.98226152, grad/param norm = 1.5050e-01, time/batch = 19.6242s	
14795/30300 (epoch 24.414), train_loss = 1.25625336, grad/param norm = 1.6871e-01, time/batch = 19.4611s	
14796/30300 (epoch 24.416), train_loss = 1.10310101, grad/param norm = 1.5170e-01, time/batch = 18.7806s	
14797/30300 (epoch 24.417), train_loss = 1.09153223, grad/param norm = 1.4928e-01, time/batch = 18.1880s	
14798/30300 (epoch 24.419), train_loss = 1.05524688, grad/param norm = 1.4221e-01, time/batch = 19.4436s	
14799/30300 (epoch 24.421), train_loss = 1.11933683, grad/param norm = 1.6976e-01, time/batch = 16.9455s	
14800/30300 (epoch 24.422), train_loss = 1.16850101, grad/param norm = 1.5311e-01, time/batch = 18.5400s	
14801/30300 (epoch 24.424), train_loss = 1.17981539, grad/param norm = 1.5272e-01, time/batch = 19.9501s	
14802/30300 (epoch 24.426), train_loss = 1.12405969, grad/param norm = 1.7446e-01, time/batch = 18.1267s	
14803/30300 (epoch 24.427), train_loss = 1.13725915, grad/param norm = 1.5580e-01, time/batch = 18.9589s	
14804/30300 (epoch 24.429), train_loss = 1.14356228, grad/param norm = 1.4033e-01, time/batch = 19.7791s	
14805/30300 (epoch 24.431), train_loss = 1.21805287, grad/param norm = 1.5060e-01, time/batch = 18.9592s	
14806/30300 (epoch 24.432), train_loss = 1.14226674, grad/param norm = 1.4349e-01, time/batch = 18.7222s	
14807/30300 (epoch 24.434), train_loss = 1.05691105, grad/param norm = 1.4668e-01, time/batch = 20.4589s	
14808/30300 (epoch 24.436), train_loss = 1.30881948, grad/param norm = 1.6733e-01, time/batch = 18.7058s	
14809/30300 (epoch 24.437), train_loss = 1.06909988, grad/param norm = 1.5135e-01, time/batch = 18.5369s	
14810/30300 (epoch 24.439), train_loss = 1.10509837, grad/param norm = 1.4079e-01, time/batch = 18.9635s	
14811/30300 (epoch 24.441), train_loss = 1.15364657, grad/param norm = 1.6926e-01, time/batch = 16.8690s	
14812/30300 (epoch 24.442), train_loss = 1.07838246, grad/param norm = 1.5585e-01, time/batch = 16.2128s	
14813/30300 (epoch 24.444), train_loss = 0.98086601, grad/param norm = 1.4303e-01, time/batch = 18.0292s	
14814/30300 (epoch 24.446), train_loss = 1.13522185, grad/param norm = 1.4248e-01, time/batch = 17.1147s	
14815/30300 (epoch 24.447), train_loss = 1.14994963, grad/param norm = 1.6002e-01, time/batch = 17.0402s	
14816/30300 (epoch 24.449), train_loss = 1.07991547, grad/param norm = 1.4390e-01, time/batch = 17.3681s	
14817/30300 (epoch 24.450), train_loss = 1.22470565, grad/param norm = 1.4888e-01, time/batch = 17.7951s	
14818/30300 (epoch 24.452), train_loss = 1.25685046, grad/param norm = 1.5116e-01, time/batch = 17.5500s	
14819/30300 (epoch 24.454), train_loss = 1.22829398, grad/param norm = 1.3792e-01, time/batch = 18.0429s	
14820/30300 (epoch 24.455), train_loss = 1.18624428, grad/param norm = 1.7182e-01, time/batch = 17.8661s	
14821/30300 (epoch 24.457), train_loss = 1.14763466, grad/param norm = 1.5018e-01, time/batch = 19.2101s	
14822/30300 (epoch 24.459), train_loss = 1.22509698, grad/param norm = 1.7488e-01, time/batch = 18.1258s	
14823/30300 (epoch 24.460), train_loss = 1.19459622, grad/param norm = 1.5373e-01, time/batch = 19.0495s	
14824/30300 (epoch 24.462), train_loss = 1.22098675, grad/param norm = 1.5113e-01, time/batch = 19.1222s	
14825/30300 (epoch 24.464), train_loss = 0.99445170, grad/param norm = 1.6371e-01, time/batch = 17.8691s	
14826/30300 (epoch 24.465), train_loss = 0.99712037, grad/param norm = 1.4130e-01, time/batch = 18.9497s	
14827/30300 (epoch 24.467), train_loss = 0.97159757, grad/param norm = 1.3960e-01, time/batch = 19.4567s	
14828/30300 (epoch 24.469), train_loss = 1.08258240, grad/param norm = 1.3911e-01, time/batch = 18.4646s	
14829/30300 (epoch 24.470), train_loss = 1.11921553, grad/param norm = 1.5720e-01, time/batch = 18.7189s	
14830/30300 (epoch 24.472), train_loss = 1.10894370, grad/param norm = 1.3169e-01, time/batch = 18.3705s	
14831/30300 (epoch 24.474), train_loss = 1.13363787, grad/param norm = 1.9664e-01, time/batch = 18.1286s	
14832/30300 (epoch 24.475), train_loss = 1.09638410, grad/param norm = 1.4016e-01, time/batch = 18.7874s	
14833/30300 (epoch 24.477), train_loss = 1.13711934, grad/param norm = 1.4377e-01, time/batch = 17.3115s	
14834/30300 (epoch 24.479), train_loss = 1.13603877, grad/param norm = 1.5448e-01, time/batch = 19.1228s	
14835/30300 (epoch 24.480), train_loss = 1.17082472, grad/param norm = 1.5212e-01, time/batch = 17.3842s	
14836/30300 (epoch 24.482), train_loss = 1.19882154, grad/param norm = 1.3811e-01, time/batch = 19.1395s	
14837/30300 (epoch 24.483), train_loss = 1.11896760, grad/param norm = 2.0815e-01, time/batch = 18.1946s	
14838/30300 (epoch 24.485), train_loss = 1.16657039, grad/param norm = 1.4903e-01, time/batch = 18.2076s	
14839/30300 (epoch 24.487), train_loss = 1.24931323, grad/param norm = 1.6047e-01, time/batch = 18.5411s	
14840/30300 (epoch 24.488), train_loss = 1.25710292, grad/param norm = 1.4101e-01, time/batch = 19.5562s	
14841/30300 (epoch 24.490), train_loss = 1.04799521, grad/param norm = 1.5515e-01, time/batch = 17.4484s	
14842/30300 (epoch 24.492), train_loss = 1.13238716, grad/param norm = 1.5650e-01, time/batch = 18.3489s	
14843/30300 (epoch 24.493), train_loss = 1.13446175, grad/param norm = 1.6221e-01, time/batch = 19.4576s	
14844/30300 (epoch 24.495), train_loss = 1.12027584, grad/param norm = 1.4009e-01, time/batch = 18.6149s	
14845/30300 (epoch 24.497), train_loss = 1.17052447, grad/param norm = 1.4380e-01, time/batch = 19.4563s	
14846/30300 (epoch 24.498), train_loss = 1.20320750, grad/param norm = 1.6331e-01, time/batch = 17.2144s	
14847/30300 (epoch 24.500), train_loss = 1.16213796, grad/param norm = 1.7269e-01, time/batch = 18.5444s	
14848/30300 (epoch 24.502), train_loss = 1.16779399, grad/param norm = 1.7372e-01, time/batch = 19.9482s	
14849/30300 (epoch 24.503), train_loss = 1.25549182, grad/param norm = 1.5284e-01, time/batch = 15.8776s	
14850/30300 (epoch 24.505), train_loss = 1.09490540, grad/param norm = 1.4156e-01, time/batch = 15.6839s	
14851/30300 (epoch 24.507), train_loss = 1.08175817, grad/param norm = 1.6384e-01, time/batch = 16.3519s	
14852/30300 (epoch 24.508), train_loss = 1.13544800, grad/param norm = 1.7065e-01, time/batch = 15.7752s	
14853/30300 (epoch 24.510), train_loss = 1.26167171, grad/param norm = 1.7753e-01, time/batch = 15.9551s	
14854/30300 (epoch 24.512), train_loss = 1.09002813, grad/param norm = 1.3482e-01, time/batch = 18.2034s	
14855/30300 (epoch 24.513), train_loss = 1.17717526, grad/param norm = 1.4004e-01, time/batch = 18.9536s	
14856/30300 (epoch 24.515), train_loss = 1.15498312, grad/param norm = 1.4337e-01, time/batch = 20.3776s	
14857/30300 (epoch 24.517), train_loss = 0.97940862, grad/param norm = 1.2866e-01, time/batch = 19.7220s	
14858/30300 (epoch 24.518), train_loss = 1.23389805, grad/param norm = 1.5987e-01, time/batch = 18.9346s	
14859/30300 (epoch 24.520), train_loss = 1.22786142, grad/param norm = 1.8213e-01, time/batch = 19.7837s	
14860/30300 (epoch 24.521), train_loss = 1.07620825, grad/param norm = 1.6292e-01, time/batch = 17.8731s	
14861/30300 (epoch 24.523), train_loss = 1.33016292, grad/param norm = 1.8063e-01, time/batch = 17.7786s	
14862/30300 (epoch 24.525), train_loss = 1.08189074, grad/param norm = 1.4952e-01, time/batch = 19.0442s	
14863/30300 (epoch 24.526), train_loss = 1.13855333, grad/param norm = 1.4160e-01, time/batch = 17.6180s	
14864/30300 (epoch 24.528), train_loss = 1.04078877, grad/param norm = 1.5007e-01, time/batch = 17.1315s	
14865/30300 (epoch 24.530), train_loss = 1.03002028, grad/param norm = 1.4544e-01, time/batch = 17.0458s	
14866/30300 (epoch 24.531), train_loss = 1.19003462, grad/param norm = 1.5036e-01, time/batch = 18.9569s	
14867/30300 (epoch 24.533), train_loss = 1.16647830, grad/param norm = 1.5827e-01, time/batch = 19.1252s	
14868/30300 (epoch 24.535), train_loss = 1.08702127, grad/param norm = 1.3536e-01, time/batch = 18.8027s	
14869/30300 (epoch 24.536), train_loss = 1.17575912, grad/param norm = 1.5672e-01, time/batch = 19.8710s	
14870/30300 (epoch 24.538), train_loss = 1.03186483, grad/param norm = 1.5625e-01, time/batch = 19.4500s	
14871/30300 (epoch 24.540), train_loss = 1.06370864, grad/param norm = 1.6403e-01, time/batch = 18.6313s	
14872/30300 (epoch 24.541), train_loss = 1.15449389, grad/param norm = 1.6071e-01, time/batch = 19.3814s	
14873/30300 (epoch 24.543), train_loss = 1.14387516, grad/param norm = 1.5537e-01, time/batch = 19.7861s	
14874/30300 (epoch 24.545), train_loss = 1.18837593, grad/param norm = 2.3170e-01, time/batch = 18.4482s	
14875/30300 (epoch 24.546), train_loss = 1.36560037, grad/param norm = 1.5527e-01, time/batch = 19.7863s	
14876/30300 (epoch 24.548), train_loss = 1.09504046, grad/param norm = 1.3645e-01, time/batch = 17.2766s	
14877/30300 (epoch 24.550), train_loss = 1.22027613, grad/param norm = 1.8172e-01, time/batch = 17.7147s	
14878/30300 (epoch 24.551), train_loss = 1.09286303, grad/param norm = 1.5395e-01, time/batch = 16.8742s	
14879/30300 (epoch 24.553), train_loss = 1.11929063, grad/param norm = 1.5142e-01, time/batch = 19.3774s	
14880/30300 (epoch 24.554), train_loss = 1.16402861, grad/param norm = 1.5792e-01, time/batch = 18.0256s	
14881/30300 (epoch 24.556), train_loss = 1.20127817, grad/param norm = 1.5066e-01, time/batch = 19.9627s	
14882/30300 (epoch 24.558), train_loss = 1.25044936, grad/param norm = 1.6144e-01, time/batch = 18.6265s	
14883/30300 (epoch 24.559), train_loss = 1.20368272, grad/param norm = 1.6778e-01, time/batch = 18.9563s	
14884/30300 (epoch 24.561), train_loss = 0.98111125, grad/param norm = 1.4445e-01, time/batch = 19.6019s	
14885/30300 (epoch 24.563), train_loss = 1.04546666, grad/param norm = 1.4916e-01, time/batch = 18.3814s	
14886/30300 (epoch 24.564), train_loss = 1.09755026, grad/param norm = 1.4594e-01, time/batch = 18.7904s	
14887/30300 (epoch 24.566), train_loss = 1.15601222, grad/param norm = 1.4645e-01, time/batch = 16.9574s	
14888/30300 (epoch 24.568), train_loss = 0.99158588, grad/param norm = 1.5880e-01, time/batch = 19.3757s	
14889/30300 (epoch 24.569), train_loss = 1.16769796, grad/param norm = 1.4376e-01, time/batch = 19.0422s	
14890/30300 (epoch 24.571), train_loss = 1.18655170, grad/param norm = 1.6346e-01, time/batch = 18.2790s	
14891/30300 (epoch 24.573), train_loss = 1.19217851, grad/param norm = 1.5073e-01, time/batch = 18.7870s	
14892/30300 (epoch 24.574), train_loss = 1.21315150, grad/param norm = 1.4171e-01, time/batch = 19.2124s	
14893/30300 (epoch 24.576), train_loss = 1.13319791, grad/param norm = 1.4668e-01, time/batch = 18.4500s	
14894/30300 (epoch 24.578), train_loss = 1.01342537, grad/param norm = 1.4271e-01, time/batch = 19.4486s	
14895/30300 (epoch 24.579), train_loss = 1.16024357, grad/param norm = 1.6276e-01, time/batch = 19.4490s	
14896/30300 (epoch 24.581), train_loss = 1.26210569, grad/param norm = 1.5719e-01, time/batch = 17.3437s	
14897/30300 (epoch 24.583), train_loss = 1.31937755, grad/param norm = 1.7090e-01, time/batch = 19.2204s	
14898/30300 (epoch 24.584), train_loss = 1.24651081, grad/param norm = 1.5034e-01, time/batch = 19.2122s	
14899/30300 (epoch 24.586), train_loss = 1.12831602, grad/param norm = 1.4966e-01, time/batch = 18.3036s	
14900/30300 (epoch 24.587), train_loss = 1.13625237, grad/param norm = 1.5521e-01, time/batch = 19.2734s	
14901/30300 (epoch 24.589), train_loss = 1.05156875, grad/param norm = 1.4386e-01, time/batch = 19.3815s	
14902/30300 (epoch 24.591), train_loss = 1.20587898, grad/param norm = 1.4590e-01, time/batch = 18.7912s	
14903/30300 (epoch 24.592), train_loss = 1.13625424, grad/param norm = 1.3669e-01, time/batch = 19.6078s	
14904/30300 (epoch 24.594), train_loss = 1.17448370, grad/param norm = 1.6809e-01, time/batch = 20.1134s	
14905/30300 (epoch 24.596), train_loss = 1.06774159, grad/param norm = 1.6273e-01, time/batch = 19.3517s	
14906/30300 (epoch 24.597), train_loss = 1.10073252, grad/param norm = 1.5686e-01, time/batch = 18.7013s	
14907/30300 (epoch 24.599), train_loss = 0.98464521, grad/param norm = 1.5056e-01, time/batch = 19.7123s	
14908/30300 (epoch 24.601), train_loss = 1.16939153, grad/param norm = 1.5303e-01, time/batch = 16.3033s	
14909/30300 (epoch 24.602), train_loss = 1.15144258, grad/param norm = 1.4957e-01, time/batch = 18.5476s	
14910/30300 (epoch 24.604), train_loss = 1.05651282, grad/param norm = 1.4143e-01, time/batch = 19.6913s	
14911/30300 (epoch 24.606), train_loss = 1.10413381, grad/param norm = 1.8455e-01, time/batch = 19.5297s	
14912/30300 (epoch 24.607), train_loss = 1.24559770, grad/param norm = 2.0103e-01, time/batch = 18.5369s	
14913/30300 (epoch 24.609), train_loss = 1.36081452, grad/param norm = 1.6887e-01, time/batch = 19.0576s	
14914/30300 (epoch 24.611), train_loss = 1.08368821, grad/param norm = 1.3364e-01, time/batch = 17.7725s	
14915/30300 (epoch 24.612), train_loss = 1.04416164, grad/param norm = 1.4077e-01, time/batch = 17.6366s	
14916/30300 (epoch 24.614), train_loss = 1.11675153, grad/param norm = 1.3917e-01, time/batch = 19.6290s	
14917/30300 (epoch 24.616), train_loss = 1.21316494, grad/param norm = 1.9051e-01, time/batch = 19.6976s	
14918/30300 (epoch 24.617), train_loss = 1.16919461, grad/param norm = 1.5860e-01, time/batch = 17.5277s	
14919/30300 (epoch 24.619), train_loss = 0.98904869, grad/param norm = 1.5331e-01, time/batch = 20.3694s	
14920/30300 (epoch 24.620), train_loss = 1.18124183, grad/param norm = 1.6507e-01, time/batch = 19.0499s	
14921/30300 (epoch 24.622), train_loss = 1.15854945, grad/param norm = 1.8079e-01, time/batch = 17.5356s	
14922/30300 (epoch 24.624), train_loss = 1.09896217, grad/param norm = 1.5123e-01, time/batch = 18.1292s	
14923/30300 (epoch 24.625), train_loss = 1.09556533, grad/param norm = 1.6105e-01, time/batch = 19.2147s	
14924/30300 (epoch 24.627), train_loss = 1.27323351, grad/param norm = 1.6018e-01, time/batch = 18.8839s	
14925/30300 (epoch 24.629), train_loss = 1.27081689, grad/param norm = 1.5052e-01, time/batch = 19.0389s	
14926/30300 (epoch 24.630), train_loss = 1.16085362, grad/param norm = 1.5514e-01, time/batch = 19.4548s	
14927/30300 (epoch 24.632), train_loss = 1.22816304, grad/param norm = 1.5840e-01, time/batch = 18.9446s	
14928/30300 (epoch 24.634), train_loss = 1.06932690, grad/param norm = 1.3677e-01, time/batch = 17.5181s	
14929/30300 (epoch 24.635), train_loss = 1.21005823, grad/param norm = 1.7648e-01, time/batch = 19.6268s	
14930/30300 (epoch 24.637), train_loss = 1.23035057, grad/param norm = 1.6499e-01, time/batch = 19.0323s	
14931/30300 (epoch 24.639), train_loss = 1.10298355, grad/param norm = 1.4547e-01, time/batch = 17.1965s	
14932/30300 (epoch 24.640), train_loss = 1.29389088, grad/param norm = 1.8655e-01, time/batch = 18.8612s	
14933/30300 (epoch 24.642), train_loss = 1.13687605, grad/param norm = 1.6577e-01, time/batch = 19.9513s	
14934/30300 (epoch 24.644), train_loss = 1.21459235, grad/param norm = 1.5035e-01, time/batch = 17.1835s	
14935/30300 (epoch 24.645), train_loss = 1.08468327, grad/param norm = 1.4591e-01, time/batch = 16.9526s	
14936/30300 (epoch 24.647), train_loss = 1.16369258, grad/param norm = 1.4689e-01, time/batch = 20.0426s	
14937/30300 (epoch 24.649), train_loss = 1.13242974, grad/param norm = 1.7986e-01, time/batch = 18.2904s	
14938/30300 (epoch 24.650), train_loss = 1.15064915, grad/param norm = 1.4998e-01, time/batch = 18.2853s	
14939/30300 (epoch 24.652), train_loss = 1.11617577, grad/param norm = 1.4356e-01, time/batch = 19.3809s	
14940/30300 (epoch 24.653), train_loss = 1.32967359, grad/param norm = 1.5707e-01, time/batch = 18.2130s	
14941/30300 (epoch 24.655), train_loss = 1.07989853, grad/param norm = 1.4211e-01, time/batch = 18.9424s	
14942/30300 (epoch 24.657), train_loss = 1.08842520, grad/param norm = 1.5899e-01, time/batch = 19.1380s	
14943/30300 (epoch 24.658), train_loss = 1.07504022, grad/param norm = 1.4364e-01, time/batch = 18.6187s	
14944/30300 (epoch 24.660), train_loss = 1.17023301, grad/param norm = 1.6282e-01, time/batch = 16.9542s	
14945/30300 (epoch 24.662), train_loss = 1.17678814, grad/param norm = 1.9084e-01, time/batch = 17.5177s	
14946/30300 (epoch 24.663), train_loss = 1.18077927, grad/param norm = 1.5746e-01, time/batch = 19.7965s	
14947/30300 (epoch 24.665), train_loss = 1.11209038, grad/param norm = 1.9739e-01, time/batch = 18.9527s	
14948/30300 (epoch 24.667), train_loss = 1.25081055, grad/param norm = 1.7762e-01, time/batch = 19.9515s	
14949/30300 (epoch 24.668), train_loss = 1.24536804, grad/param norm = 1.6084e-01, time/batch = 18.9444s	
14950/30300 (epoch 24.670), train_loss = 1.27444467, grad/param norm = 1.7939e-01, time/batch = 17.6174s	
14951/30300 (epoch 24.672), train_loss = 1.19655992, grad/param norm = 1.6782e-01, time/batch = 19.7120s	
14952/30300 (epoch 24.673), train_loss = 1.20936560, grad/param norm = 1.5675e-01, time/batch = 19.2808s	
14953/30300 (epoch 24.675), train_loss = 1.12354112, grad/param norm = 1.6995e-01, time/batch = 26.2567s	
14954/30300 (epoch 24.677), train_loss = 1.11255439, grad/param norm = 1.4390e-01, time/batch = 31.2825s	
14955/30300 (epoch 24.678), train_loss = 1.10050748, grad/param norm = 1.4488e-01, time/batch = 18.1295s	
14956/30300 (epoch 24.680), train_loss = 0.97091000, grad/param norm = 1.4001e-01, time/batch = 16.7536s	
14957/30300 (epoch 24.682), train_loss = 1.15438957, grad/param norm = 1.6214e-01, time/batch = 17.0486s	
14958/30300 (epoch 24.683), train_loss = 1.25132670, grad/param norm = 1.4461e-01, time/batch = 19.1807s	
14959/30300 (epoch 24.685), train_loss = 1.24154777, grad/param norm = 1.7757e-01, time/batch = 17.8342s	
14960/30300 (epoch 24.686), train_loss = 1.11993282, grad/param norm = 1.4132e-01, time/batch = 19.5286s	
14961/30300 (epoch 24.688), train_loss = 1.13967625, grad/param norm = 1.4310e-01, time/batch = 18.4394s	
14962/30300 (epoch 24.690), train_loss = 1.10329238, grad/param norm = 1.7806e-01, time/batch = 17.2981s	
14963/30300 (epoch 24.691), train_loss = 1.20100304, grad/param norm = 1.4067e-01, time/batch = 19.1173s	
14964/30300 (epoch 24.693), train_loss = 1.47714550, grad/param norm = 1.7146e-01, time/batch = 17.4571s	
14965/30300 (epoch 24.695), train_loss = 1.26978215, grad/param norm = 1.5834e-01, time/batch = 17.5290s	
14966/30300 (epoch 24.696), train_loss = 1.21946367, grad/param norm = 1.8875e-01, time/batch = 19.4550s	
14967/30300 (epoch 24.698), train_loss = 1.09657667, grad/param norm = 1.4974e-01, time/batch = 19.1312s	
14968/30300 (epoch 24.700), train_loss = 1.09448421, grad/param norm = 1.5381e-01, time/batch = 18.7062s	
14969/30300 (epoch 24.701), train_loss = 1.00297382, grad/param norm = 1.4394e-01, time/batch = 5.3861s	
14970/30300 (epoch 24.703), train_loss = 1.15233194, grad/param norm = 1.4121e-01, time/batch = 0.6944s	
14971/30300 (epoch 24.705), train_loss = 1.09121780, grad/param norm = 1.5555e-01, time/batch = 0.7009s	
14972/30300 (epoch 24.706), train_loss = 1.21210859, grad/param norm = 1.6117e-01, time/batch = 0.6935s	
14973/30300 (epoch 24.708), train_loss = 1.14216152, grad/param norm = 1.5165e-01, time/batch = 0.7009s	
14974/30300 (epoch 24.710), train_loss = 1.14126155, grad/param norm = 1.6210e-01, time/batch = 0.6954s	
14975/30300 (epoch 24.711), train_loss = 1.06073565, grad/param norm = 1.5587e-01, time/batch = 0.7185s	
14976/30300 (epoch 24.713), train_loss = 1.06316436, grad/param norm = 1.5383e-01, time/batch = 0.9223s	
14977/30300 (epoch 24.715), train_loss = 1.09666003, grad/param norm = 1.5262e-01, time/batch = 1.0253s	
14978/30300 (epoch 24.716), train_loss = 1.24574654, grad/param norm = 1.3958e-01, time/batch = 1.0192s	
14979/30300 (epoch 24.718), train_loss = 1.28897629, grad/param norm = 1.5999e-01, time/batch = 1.0239s	
14980/30300 (epoch 24.719), train_loss = 1.11919290, grad/param norm = 1.7963e-01, time/batch = 1.0173s	
14981/30300 (epoch 24.721), train_loss = 1.16734283, grad/param norm = 1.6854e-01, time/batch = 1.6980s	
14982/30300 (epoch 24.723), train_loss = 1.09897336, grad/param norm = 1.4888e-01, time/batch = 1.8984s	
14983/30300 (epoch 24.724), train_loss = 1.17070945, grad/param norm = 1.7094e-01, time/batch = 4.0102s	
14984/30300 (epoch 24.726), train_loss = 1.52118183, grad/param norm = 1.9970e-01, time/batch = 19.0414s	
14985/30300 (epoch 24.728), train_loss = 1.21707028, grad/param norm = 1.5456e-01, time/batch = 18.2211s	
14986/30300 (epoch 24.729), train_loss = 1.11720100, grad/param norm = 1.6593e-01, time/batch = 18.8694s	
14987/30300 (epoch 24.731), train_loss = 1.18130234, grad/param norm = 1.6021e-01, time/batch = 19.4523s	
14988/30300 (epoch 24.733), train_loss = 1.15951351, grad/param norm = 1.5032e-01, time/batch = 18.8678s	
14989/30300 (epoch 24.734), train_loss = 1.23929467, grad/param norm = 1.4390e-01, time/batch = 18.0424s	
14990/30300 (epoch 24.736), train_loss = 1.14048404, grad/param norm = 1.4856e-01, time/batch = 18.4598s	
14991/30300 (epoch 24.738), train_loss = 1.06936895, grad/param norm = 1.3010e-01, time/batch = 18.8849s	
14992/30300 (epoch 24.739), train_loss = 1.22329004, grad/param norm = 1.7015e-01, time/batch = 18.2859s	
14993/30300 (epoch 24.741), train_loss = 1.31204108, grad/param norm = 1.5394e-01, time/batch = 17.4351s	
14994/30300 (epoch 24.743), train_loss = 1.14156182, grad/param norm = 1.5332e-01, time/batch = 16.7229s	
14995/30300 (epoch 24.744), train_loss = 1.18630480, grad/param norm = 1.5380e-01, time/batch = 18.6961s	
14996/30300 (epoch 24.746), train_loss = 1.09719584, grad/param norm = 1.4829e-01, time/batch = 18.3635s	
14997/30300 (epoch 24.748), train_loss = 1.15276822, grad/param norm = 1.7603e-01, time/batch = 18.3580s	
14998/30300 (epoch 24.749), train_loss = 1.20250529, grad/param norm = 1.5387e-01, time/batch = 18.7893s	
14999/30300 (epoch 24.751), train_loss = 1.15455743, grad/param norm = 1.4966e-01, time/batch = 18.2048s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch24.75_1.8627.t7	
15000/30300 (epoch 24.752), train_loss = 1.13182815, grad/param norm = 1.5670e-01, time/batch = 18.2913s	
15001/30300 (epoch 24.754), train_loss = 1.53547458, grad/param norm = 2.1663e-01, time/batch = 18.5435s	
15002/30300 (epoch 24.756), train_loss = 1.14549345, grad/param norm = 1.5648e-01, time/batch = 20.1239s	
15003/30300 (epoch 24.757), train_loss = 1.16333593, grad/param norm = 1.6795e-01, time/batch = 19.4612s	
15004/30300 (epoch 24.759), train_loss = 1.19419128, grad/param norm = 1.4740e-01, time/batch = 17.8706s	
15005/30300 (epoch 24.761), train_loss = 1.01051815, grad/param norm = 1.5450e-01, time/batch = 19.9634s	
15006/30300 (epoch 24.762), train_loss = 1.04924854, grad/param norm = 1.4627e-01, time/batch = 20.0455s	
15007/30300 (epoch 24.764), train_loss = 1.14492560, grad/param norm = 1.5353e-01, time/batch = 17.5190s	
15008/30300 (epoch 24.766), train_loss = 1.25360096, grad/param norm = 1.5843e-01, time/batch = 18.8863s	
15009/30300 (epoch 24.767), train_loss = 1.25447989, grad/param norm = 2.1393e-01, time/batch = 19.5507s	
15010/30300 (epoch 24.769), train_loss = 1.20183408, grad/param norm = 1.6444e-01, time/batch = 18.6146s	
15011/30300 (epoch 24.771), train_loss = 1.11789568, grad/param norm = 1.9141e-01, time/batch = 18.7928s	
15012/30300 (epoch 24.772), train_loss = 1.22697782, grad/param norm = 1.6429e-01, time/batch = 19.5493s	
15013/30300 (epoch 24.774), train_loss = 1.30001033, grad/param norm = 1.5245e-01, time/batch = 18.9612s	
15014/30300 (epoch 24.776), train_loss = 1.16145260, grad/param norm = 1.5848e-01, time/batch = 17.6999s	
15015/30300 (epoch 24.777), train_loss = 1.27162455, grad/param norm = 1.5449e-01, time/batch = 18.5514s	
15016/30300 (epoch 24.779), train_loss = 1.30297177, grad/param norm = 1.7048e-01, time/batch = 19.5395s	
15017/30300 (epoch 24.781), train_loss = 1.17379963, grad/param norm = 1.7794e-01, time/batch = 18.8665s	
15018/30300 (epoch 24.782), train_loss = 1.11229724, grad/param norm = 1.4699e-01, time/batch = 17.6870s	
15019/30300 (epoch 24.784), train_loss = 1.10885226, grad/param norm = 1.4852e-01, time/batch = 16.9673s	
15020/30300 (epoch 24.785), train_loss = 1.30146441, grad/param norm = 1.8644e-01, time/batch = 18.4636s	
15021/30300 (epoch 24.787), train_loss = 0.97443073, grad/param norm = 1.4828e-01, time/batch = 19.4669s	
15022/30300 (epoch 24.789), train_loss = 1.37617778, grad/param norm = 1.5734e-01, time/batch = 19.0464s	
15023/30300 (epoch 24.790), train_loss = 1.21563021, grad/param norm = 1.7594e-01, time/batch = 18.7982s	
15024/30300 (epoch 24.792), train_loss = 1.00183742, grad/param norm = 1.6382e-01, time/batch = 18.7894s	
15025/30300 (epoch 24.794), train_loss = 1.16002262, grad/param norm = 1.7359e-01, time/batch = 19.2048s	
15026/30300 (epoch 24.795), train_loss = 1.06887340, grad/param norm = 1.4039e-01, time/batch = 18.6955s	
15027/30300 (epoch 24.797), train_loss = 1.31148453, grad/param norm = 1.6538e-01, time/batch = 18.7962s	
15028/30300 (epoch 24.799), train_loss = 1.22042874, grad/param norm = 1.6811e-01, time/batch = 19.7031s	
15029/30300 (epoch 24.800), train_loss = 1.22381107, grad/param norm = 1.5202e-01, time/batch = 19.3012s	
15030/30300 (epoch 24.802), train_loss = 1.41451603, grad/param norm = 1.7315e-01, time/batch = 17.9381s	
15031/30300 (epoch 24.804), train_loss = 1.25054122, grad/param norm = 1.6223e-01, time/batch = 19.7134s	
15032/30300 (epoch 24.805), train_loss = 1.31233181, grad/param norm = 1.7063e-01, time/batch = 19.4670s	
15033/30300 (epoch 24.807), train_loss = 1.14045872, grad/param norm = 1.7642e-01, time/batch = 18.1280s	
15034/30300 (epoch 24.809), train_loss = 1.25269882, grad/param norm = 1.7078e-01, time/batch = 18.2740s	
15035/30300 (epoch 24.810), train_loss = 1.23394102, grad/param norm = 1.5852e-01, time/batch = 19.4641s	
15036/30300 (epoch 24.812), train_loss = 1.08757792, grad/param norm = 1.5921e-01, time/batch = 17.8713s	
15037/30300 (epoch 24.814), train_loss = 1.16705239, grad/param norm = 1.6040e-01, time/batch = 19.1146s	
15038/30300 (epoch 24.815), train_loss = 1.19629166, grad/param norm = 1.7707e-01, time/batch = 17.2902s	
15039/30300 (epoch 24.817), train_loss = 1.27609105, grad/param norm = 1.6456e-01, time/batch = 19.0350s	
15040/30300 (epoch 24.818), train_loss = 1.21287977, grad/param norm = 1.5061e-01, time/batch = 18.7714s	
15041/30300 (epoch 24.820), train_loss = 1.34512796, grad/param norm = 1.8518e-01, time/batch = 19.2962s	
15042/30300 (epoch 24.822), train_loss = 1.33158311, grad/param norm = 1.6807e-01, time/batch = 19.1953s	
15043/30300 (epoch 24.823), train_loss = 1.33745662, grad/param norm = 1.7387e-01, time/batch = 18.3047s	
15044/30300 (epoch 24.825), train_loss = 1.28960928, grad/param norm = 1.6617e-01, time/batch = 19.1316s	
15045/30300 (epoch 24.827), train_loss = 1.01336971, grad/param norm = 1.6566e-01, time/batch = 19.1185s	
15046/30300 (epoch 24.828), train_loss = 1.25610079, grad/param norm = 1.6320e-01, time/batch = 17.8757s	
15047/30300 (epoch 24.830), train_loss = 1.22469303, grad/param norm = 1.5151e-01, time/batch = 17.3738s	
15048/30300 (epoch 24.832), train_loss = 1.08509587, grad/param norm = 1.5632e-01, time/batch = 18.5478s	
15049/30300 (epoch 24.833), train_loss = 1.21484699, grad/param norm = 1.5558e-01, time/batch = 16.9234s	
15050/30300 (epoch 24.835), train_loss = 1.10405131, grad/param norm = 1.5157e-01, time/batch = 18.5448s	
15051/30300 (epoch 24.837), train_loss = 1.04801932, grad/param norm = 1.4834e-01, time/batch = 19.3804s	
15052/30300 (epoch 24.838), train_loss = 1.06783429, grad/param norm = 1.4741e-01, time/batch = 18.6252s	
15053/30300 (epoch 24.840), train_loss = 1.24782572, grad/param norm = 1.3696e-01, time/batch = 19.4647s	
15054/30300 (epoch 24.842), train_loss = 1.10638952, grad/param norm = 1.3661e-01, time/batch = 20.0470s	
15055/30300 (epoch 24.843), train_loss = 1.20355348, grad/param norm = 1.4589e-01, time/batch = 18.1138s	
15056/30300 (epoch 24.845), train_loss = 1.22560477, grad/param norm = 1.4387e-01, time/batch = 19.5180s	
15057/30300 (epoch 24.847), train_loss = 1.20208812, grad/param norm = 1.5591e-01, time/batch = 20.0360s	
15058/30300 (epoch 24.848), train_loss = 1.26035696, grad/param norm = 1.6276e-01, time/batch = 19.3539s	
15059/30300 (epoch 24.850), train_loss = 1.18018819, grad/param norm = 1.5263e-01, time/batch = 19.1160s	
15060/30300 (epoch 24.851), train_loss = 1.21500904, grad/param norm = 1.7900e-01, time/batch = 19.1095s	
15061/30300 (epoch 24.853), train_loss = 1.13071385, grad/param norm = 1.4752e-01, time/batch = 17.7977s	
15062/30300 (epoch 24.855), train_loss = 1.11085829, grad/param norm = 1.3469e-01, time/batch = 16.8451s	
15063/30300 (epoch 24.856), train_loss = 1.20072543, grad/param norm = 1.6312e-01, time/batch = 18.6157s	
15064/30300 (epoch 24.858), train_loss = 1.10247784, grad/param norm = 1.3657e-01, time/batch = 18.6261s	
15065/30300 (epoch 24.860), train_loss = 1.07320417, grad/param norm = 1.4639e-01, time/batch = 18.6721s	
15066/30300 (epoch 24.861), train_loss = 1.33315042, grad/param norm = 1.6140e-01, time/batch = 19.8508s	
15067/30300 (epoch 24.863), train_loss = 1.16642634, grad/param norm = 1.3916e-01, time/batch = 19.6222s	
15068/30300 (epoch 24.865), train_loss = 1.23033058, grad/param norm = 1.7588e-01, time/batch = 18.4541s	
15069/30300 (epoch 24.866), train_loss = 1.23344514, grad/param norm = 1.6429e-01, time/batch = 19.6114s	
15070/30300 (epoch 24.868), train_loss = 1.18049495, grad/param norm = 1.5783e-01, time/batch = 19.2792s	
15071/30300 (epoch 24.870), train_loss = 1.09734056, grad/param norm = 1.5089e-01, time/batch = 17.6917s	
15072/30300 (epoch 24.871), train_loss = 1.14528173, grad/param norm = 1.4468e-01, time/batch = 19.2863s	
15073/30300 (epoch 24.873), train_loss = 1.17564598, grad/param norm = 1.4690e-01, time/batch = 19.0428s	
15074/30300 (epoch 24.875), train_loss = 1.10583843, grad/param norm = 1.4560e-01, time/batch = 17.1247s	
15075/30300 (epoch 24.876), train_loss = 1.04153193, grad/param norm = 1.5393e-01, time/batch = 15.7866s	
15076/30300 (epoch 24.878), train_loss = 1.01598921, grad/param norm = 1.4596e-01, time/batch = 19.2798s	
15077/30300 (epoch 24.880), train_loss = 1.07483501, grad/param norm = 1.5423e-01, time/batch = 18.1296s	
15078/30300 (epoch 24.881), train_loss = 1.32935530, grad/param norm = 2.1336e-01, time/batch = 19.3486s	
15079/30300 (epoch 24.883), train_loss = 1.22075037, grad/param norm = 1.5523e-01, time/batch = 18.2131s	
15080/30300 (epoch 24.884), train_loss = 1.11351140, grad/param norm = 1.3981e-01, time/batch = 18.8763s	
15081/30300 (epoch 24.886), train_loss = 1.19868493, grad/param norm = 1.4282e-01, time/batch = 18.8732s	
15082/30300 (epoch 24.888), train_loss = 1.16889464, grad/param norm = 1.6783e-01, time/batch = 18.8956s	
15083/30300 (epoch 24.889), train_loss = 1.19883148, grad/param norm = 1.4603e-01, time/batch = 20.0311s	
15084/30300 (epoch 24.891), train_loss = 1.18277305, grad/param norm = 1.6093e-01, time/batch = 17.7920s	
15085/30300 (epoch 24.893), train_loss = 1.39017353, grad/param norm = 1.6063e-01, time/batch = 19.6456s	
15086/30300 (epoch 24.894), train_loss = 1.23852457, grad/param norm = 1.6438e-01, time/batch = 19.3812s	
15087/30300 (epoch 24.896), train_loss = 1.00466702, grad/param norm = 1.3821e-01, time/batch = 18.2887s	
15088/30300 (epoch 24.898), train_loss = 0.98337173, grad/param norm = 1.4935e-01, time/batch = 18.4780s	
15089/30300 (epoch 24.899), train_loss = 1.08357942, grad/param norm = 1.5837e-01, time/batch = 19.3708s	
15090/30300 (epoch 24.901), train_loss = 1.15563487, grad/param norm = 1.6941e-01, time/batch = 18.6210s	
15091/30300 (epoch 24.903), train_loss = 1.18894325, grad/param norm = 1.6422e-01, time/batch = 18.8820s	
15092/30300 (epoch 24.904), train_loss = 1.16272188, grad/param norm = 1.6114e-01, time/batch = 20.1259s	
15093/30300 (epoch 24.906), train_loss = 1.24581751, grad/param norm = 1.6722e-01, time/batch = 18.0444s	
15094/30300 (epoch 24.908), train_loss = 1.12384317, grad/param norm = 1.5163e-01, time/batch = 18.0494s	
15095/30300 (epoch 24.909), train_loss = 1.07925372, grad/param norm = 1.6473e-01, time/batch = 19.3028s	
15096/30300 (epoch 24.911), train_loss = 1.16661897, grad/param norm = 1.4489e-01, time/batch = 17.5271s	
15097/30300 (epoch 24.913), train_loss = 1.15132193, grad/param norm = 1.4147e-01, time/batch = 18.5405s	
15098/30300 (epoch 24.914), train_loss = 1.13214417, grad/param norm = 1.6263e-01, time/batch = 20.0380s	
15099/30300 (epoch 24.916), train_loss = 1.18689614, grad/param norm = 1.4403e-01, time/batch = 19.7915s	
15100/30300 (epoch 24.917), train_loss = 1.11620679, grad/param norm = 1.4737e-01, time/batch = 16.4504s	
15101/30300 (epoch 24.919), train_loss = 1.12143165, grad/param norm = 1.6146e-01, time/batch = 19.9545s	
15102/30300 (epoch 24.921), train_loss = 1.15150000, grad/param norm = 1.4541e-01, time/batch = 20.0374s	
15103/30300 (epoch 24.922), train_loss = 1.27055267, grad/param norm = 1.7387e-01, time/batch = 10.7787s	
15104/30300 (epoch 24.924), train_loss = 1.16550687, grad/param norm = 1.7420e-01, time/batch = 0.6916s	
15105/30300 (epoch 24.926), train_loss = 1.20089851, grad/param norm = 1.5194e-01, time/batch = 0.6935s	
15106/30300 (epoch 24.927), train_loss = 1.16749813, grad/param norm = 1.5222e-01, time/batch = 0.6936s	
15107/30300 (epoch 24.929), train_loss = 1.10308136, grad/param norm = 1.6041e-01, time/batch = 0.6900s	
15108/30300 (epoch 24.931), train_loss = 1.27449224, grad/param norm = 1.8108e-01, time/batch = 0.6927s	
15109/30300 (epoch 24.932), train_loss = 1.09318220, grad/param norm = 1.5305e-01, time/batch = 0.6893s	
15110/30300 (epoch 24.934), train_loss = 1.19544033, grad/param norm = 1.5177e-01, time/batch = 0.6934s	
15111/30300 (epoch 24.936), train_loss = 1.12939345, grad/param norm = 1.4921e-01, time/batch = 0.6912s	
15112/30300 (epoch 24.937), train_loss = 1.09763104, grad/param norm = 1.4819e-01, time/batch = 0.6904s	
15113/30300 (epoch 24.939), train_loss = 1.29572772, grad/param norm = 1.9255e-01, time/batch = 0.6962s	
15114/30300 (epoch 24.941), train_loss = 1.14843392, grad/param norm = 1.5643e-01, time/batch = 0.6890s	
15115/30300 (epoch 24.942), train_loss = 1.16593771, grad/param norm = 1.7273e-01, time/batch = 0.6899s	
15116/30300 (epoch 24.944), train_loss = 1.06398584, grad/param norm = 1.5672e-01, time/batch = 0.6886s	
15117/30300 (epoch 24.946), train_loss = 1.26834065, grad/param norm = 1.8108e-01, time/batch = 0.6991s	
15118/30300 (epoch 24.947), train_loss = 1.25586479, grad/param norm = 1.8253e-01, time/batch = 1.0056s	
15119/30300 (epoch 24.949), train_loss = 1.30787100, grad/param norm = 1.8917e-01, time/batch = 1.0175s	
15120/30300 (epoch 24.950), train_loss = 1.27317607, grad/param norm = 1.5883e-01, time/batch = 1.0128s	
15121/30300 (epoch 24.952), train_loss = 1.23903030, grad/param norm = 1.7897e-01, time/batch = 1.0173s	
15122/30300 (epoch 24.954), train_loss = 1.43075659, grad/param norm = 1.5767e-01, time/batch = 1.1178s	
15123/30300 (epoch 24.955), train_loss = 1.12773509, grad/param norm = 1.5305e-01, time/batch = 1.8750s	
15124/30300 (epoch 24.957), train_loss = 1.23824933, grad/param norm = 1.5464e-01, time/batch = 1.8930s	
15125/30300 (epoch 24.959), train_loss = 1.11584941, grad/param norm = 1.6870e-01, time/batch = 10.3244s	
15126/30300 (epoch 24.960), train_loss = 1.14393020, grad/param norm = 1.5559e-01, time/batch = 18.5344s	
15127/30300 (epoch 24.962), train_loss = 1.16699892, grad/param norm = 2.2103e-01, time/batch = 17.5223s	
15128/30300 (epoch 24.964), train_loss = 1.09000868, grad/param norm = 1.7412e-01, time/batch = 18.2801s	
15129/30300 (epoch 24.965), train_loss = 1.09334860, grad/param norm = 1.8013e-01, time/batch = 19.0312s	
15130/30300 (epoch 24.967), train_loss = 1.18440245, grad/param norm = 2.3685e-01, time/batch = 17.9574s	
15131/30300 (epoch 24.969), train_loss = 1.07412815, grad/param norm = 1.7085e-01, time/batch = 18.2915s	
15132/30300 (epoch 24.970), train_loss = 1.12455340, grad/param norm = 1.7975e-01, time/batch = 18.2782s	
15133/30300 (epoch 24.972), train_loss = 1.04364456, grad/param norm = 1.5488e-01, time/batch = 17.3609s	
15134/30300 (epoch 24.974), train_loss = 1.34074195, grad/param norm = 1.7808e-01, time/batch = 17.0241s	
15135/30300 (epoch 24.975), train_loss = 1.36757388, grad/param norm = 1.8694e-01, time/batch = 16.6155s	
15136/30300 (epoch 24.977), train_loss = 1.29411210, grad/param norm = 1.6090e-01, time/batch = 19.1335s	
15137/30300 (epoch 24.979), train_loss = 1.23826286, grad/param norm = 1.6124e-01, time/batch = 18.2055s	
15138/30300 (epoch 24.980), train_loss = 1.25000892, grad/param norm = 1.7547e-01, time/batch = 19.2868s	
15139/30300 (epoch 24.982), train_loss = 1.24424904, grad/param norm = 1.6478e-01, time/batch = 19.2950s	
15140/30300 (epoch 24.983), train_loss = 1.30836120, grad/param norm = 1.6573e-01, time/batch = 18.1231s	
15141/30300 (epoch 24.985), train_loss = 1.23852492, grad/param norm = 1.7776e-01, time/batch = 18.8741s	
15142/30300 (epoch 24.987), train_loss = 1.14945743, grad/param norm = 1.4596e-01, time/batch = 17.7874s	
15143/30300 (epoch 24.988), train_loss = 1.31347043, grad/param norm = 1.5930e-01, time/batch = 18.4592s	
15144/30300 (epoch 24.990), train_loss = 1.02297014, grad/param norm = 1.3274e-01, time/batch = 19.3695s	
15145/30300 (epoch 24.992), train_loss = 1.23407871, grad/param norm = 1.4281e-01, time/batch = 18.8771s	
15146/30300 (epoch 24.993), train_loss = 1.30559967, grad/param norm = 1.9055e-01, time/batch = 18.2853s	
15147/30300 (epoch 24.995), train_loss = 1.15760011, grad/param norm = 1.6823e-01, time/batch = 18.3600s	
15148/30300 (epoch 24.997), train_loss = 1.21677056, grad/param norm = 1.7784e-01, time/batch = 17.7148s	
15149/30300 (epoch 24.998), train_loss = 1.25676545, grad/param norm = 1.7627e-01, time/batch = 19.0508s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
15150/30300 (epoch 25.000), train_loss = 1.12858973, grad/param norm = 1.8325e-01, time/batch = 18.2066s	
15151/30300 (epoch 25.002), train_loss = 1.27124512, grad/param norm = 1.7739e-01, time/batch = 19.2997s	
15152/30300 (epoch 25.003), train_loss = 1.19520910, grad/param norm = 2.8897e-01, time/batch = 17.6085s	
15153/30300 (epoch 25.005), train_loss = 1.14871437, grad/param norm = 1.7180e-01, time/batch = 17.7853s	
15154/30300 (epoch 25.007), train_loss = 1.25179673, grad/param norm = 1.9324e-01, time/batch = 19.4544s	
15155/30300 (epoch 25.008), train_loss = 1.10304778, grad/param norm = 1.5822e-01, time/batch = 20.1064s	
15156/30300 (epoch 25.010), train_loss = 1.07019616, grad/param norm = 1.7476e-01, time/batch = 17.1241s	
15157/30300 (epoch 25.012), train_loss = 1.10608785, grad/param norm = 1.5194e-01, time/batch = 18.8795s	
15158/30300 (epoch 25.013), train_loss = 1.29080500, grad/param norm = 1.6634e-01, time/batch = 18.4402s	
15159/30300 (epoch 25.015), train_loss = 1.13487829, grad/param norm = 1.5187e-01, time/batch = 18.1317s	
15160/30300 (epoch 25.017), train_loss = 1.12581911, grad/param norm = 1.4343e-01, time/batch = 19.0452s	
15161/30300 (epoch 25.018), train_loss = 1.07447843, grad/param norm = 1.4242e-01, time/batch = 17.9513s	
15162/30300 (epoch 25.020), train_loss = 1.27814465, grad/param norm = 2.0677e-01, time/batch = 19.2091s	
15163/30300 (epoch 25.021), train_loss = 1.29009262, grad/param norm = 1.6320e-01, time/batch = 18.4596s	
15164/30300 (epoch 25.023), train_loss = 1.18868431, grad/param norm = 1.5655e-01, time/batch = 18.0525s	
15165/30300 (epoch 25.025), train_loss = 1.08623674, grad/param norm = 1.6668e-01, time/batch = 17.7866s	
15166/30300 (epoch 25.026), train_loss = 1.22438698, grad/param norm = 1.8370e-01, time/batch = 17.4616s	
15167/30300 (epoch 25.028), train_loss = 1.25976686, grad/param norm = 1.6094e-01, time/batch = 19.5486s	
15168/30300 (epoch 25.030), train_loss = 1.10612186, grad/param norm = 1.5626e-01, time/batch = 19.0566s	
15169/30300 (epoch 25.031), train_loss = 1.22932939, grad/param norm = 1.6287e-01, time/batch = 17.8980s	
15170/30300 (epoch 25.033), train_loss = 1.15219008, grad/param norm = 1.5509e-01, time/batch = 19.0610s	
15171/30300 (epoch 25.035), train_loss = 1.25350003, grad/param norm = 1.6741e-01, time/batch = 19.2228s	
15172/30300 (epoch 25.036), train_loss = 1.18093251, grad/param norm = 1.5457e-01, time/batch = 36.4733s	
15173/30300 (epoch 25.038), train_loss = 1.21422560, grad/param norm = 1.5474e-01, time/batch = 22.8312s	
15174/30300 (epoch 25.040), train_loss = 0.92280993, grad/param norm = 1.3275e-01, time/batch = 18.1294s	
15175/30300 (epoch 25.041), train_loss = 0.97812564, grad/param norm = 1.3592e-01, time/batch = 17.8602s	
15176/30300 (epoch 25.043), train_loss = 1.17561221, grad/param norm = 1.5892e-01, time/batch = 18.2989s	
15177/30300 (epoch 25.045), train_loss = 1.15325329, grad/param norm = 1.5845e-01, time/batch = 18.3740s	
15178/30300 (epoch 25.046), train_loss = 1.32497077, grad/param norm = 1.9387e-01, time/batch = 18.4519s	
15179/30300 (epoch 25.048), train_loss = 1.14400883, grad/param norm = 1.6664e-01, time/batch = 18.5399s	
15180/30300 (epoch 25.050), train_loss = 1.12705205, grad/param norm = 1.5863e-01, time/batch = 19.6121s	
15181/30300 (epoch 25.051), train_loss = 1.19055182, grad/param norm = 1.5893e-01, time/batch = 18.4349s	
15182/30300 (epoch 25.053), train_loss = 0.99132881, grad/param norm = 1.6837e-01, time/batch = 18.7950s	
15183/30300 (epoch 25.054), train_loss = 1.16948859, grad/param norm = 1.5331e-01, time/batch = 19.2960s	
15184/30300 (epoch 25.056), train_loss = 1.08039246, grad/param norm = 1.4326e-01, time/batch = 18.1978s	
15185/30300 (epoch 25.058), train_loss = 1.13642315, grad/param norm = 1.5043e-01, time/batch = 19.8715s	
15186/30300 (epoch 25.059), train_loss = 1.07934210, grad/param norm = 1.6374e-01, time/batch = 18.9644s	
15187/30300 (epoch 25.061), train_loss = 1.21383279, grad/param norm = 1.6843e-01, time/batch = 18.0507s	
15188/30300 (epoch 25.063), train_loss = 1.05215890, grad/param norm = 1.6082e-01, time/batch = 19.4412s	
15189/30300 (epoch 25.064), train_loss = 1.17561447, grad/param norm = 1.5872e-01, time/batch = 18.7931s	
15190/30300 (epoch 25.066), train_loss = 1.15652041, grad/param norm = 1.4988e-01, time/batch = 17.9601s	
15191/30300 (epoch 25.068), train_loss = 1.05554587, grad/param norm = 1.5402e-01, time/batch = 19.1244s	
15192/30300 (epoch 25.069), train_loss = 1.22798517, grad/param norm = 1.6515e-01, time/batch = 19.4648s	
15193/30300 (epoch 25.071), train_loss = 1.22025126, grad/param norm = 1.6868e-01, time/batch = 18.5345s	
15194/30300 (epoch 25.073), train_loss = 1.12247357, grad/param norm = 1.6568e-01, time/batch = 18.9420s	
15195/30300 (epoch 25.074), train_loss = 1.18150962, grad/param norm = 1.4393e-01, time/batch = 17.4499s	
15196/30300 (epoch 25.076), train_loss = 1.12296989, grad/param norm = 1.4684e-01, time/batch = 19.5582s	
15197/30300 (epoch 25.078), train_loss = 1.08477937, grad/param norm = 1.4572e-01, time/batch = 18.3748s	
15198/30300 (epoch 25.079), train_loss = 1.09959821, grad/param norm = 1.4888e-01, time/batch = 16.4630s	
15199/30300 (epoch 25.081), train_loss = 1.17063688, grad/param norm = 1.6409e-01, time/batch = 20.1141s	
15200/30300 (epoch 25.083), train_loss = 1.23202905, grad/param norm = 1.7200e-01, time/batch = 18.8631s	
15201/30300 (epoch 25.084), train_loss = 1.06278280, grad/param norm = 1.4845e-01, time/batch = 19.1120s	
15202/30300 (epoch 25.086), train_loss = 1.11402487, grad/param norm = 1.7411e-01, time/batch = 19.8023s	
15203/30300 (epoch 25.087), train_loss = 1.08583297, grad/param norm = 1.5019e-01, time/batch = 17.3686s	
15204/30300 (epoch 25.089), train_loss = 1.13085350, grad/param norm = 1.6086e-01, time/batch = 19.8829s	
15205/30300 (epoch 25.091), train_loss = 1.19122764, grad/param norm = 1.4535e-01, time/batch = 18.4343s	
15206/30300 (epoch 25.092), train_loss = 1.21231710, grad/param norm = 1.5527e-01, time/batch = 17.7083s	
15207/30300 (epoch 25.094), train_loss = 1.32273556, grad/param norm = 1.8323e-01, time/batch = 17.6036s	
15208/30300 (epoch 25.096), train_loss = 1.26374254, grad/param norm = 1.7249e-01, time/batch = 19.2841s	
15209/30300 (epoch 25.097), train_loss = 1.11576970, grad/param norm = 1.6283e-01, time/batch = 18.4352s	
15210/30300 (epoch 25.099), train_loss = 1.25549400, grad/param norm = 1.5968e-01, time/batch = 18.5996s	
15211/30300 (epoch 25.101), train_loss = 1.30186853, grad/param norm = 2.1248e-01, time/batch = 18.6843s	
15212/30300 (epoch 25.102), train_loss = 1.10920990, grad/param norm = 1.8874e-01, time/batch = 19.7088s	
15213/30300 (epoch 25.104), train_loss = 1.14781784, grad/param norm = 1.8563e-01, time/batch = 16.4281s	
15214/30300 (epoch 25.106), train_loss = 1.14712060, grad/param norm = 1.9259e-01, time/batch = 19.2920s	
15215/30300 (epoch 25.107), train_loss = 1.19930258, grad/param norm = 1.5295e-01, time/batch = 19.7937s	
15216/30300 (epoch 25.109), train_loss = 1.22818685, grad/param norm = 1.9046e-01, time/batch = 16.6288s	
15217/30300 (epoch 25.111), train_loss = 1.28466383, grad/param norm = 1.7545e-01, time/batch = 19.7787s	
15218/30300 (epoch 25.112), train_loss = 1.25764011, grad/param norm = 1.4772e-01, time/batch = 19.7788s	
15219/30300 (epoch 25.114), train_loss = 1.14207738, grad/param norm = 1.5590e-01, time/batch = 17.3700s	
15220/30300 (epoch 25.116), train_loss = 1.17207995, grad/param norm = 1.7953e-01, time/batch = 19.6859s	
15221/30300 (epoch 25.117), train_loss = 1.22384281, grad/param norm = 1.6318e-01, time/batch = 18.7961s	
15222/30300 (epoch 25.119), train_loss = 1.10087587, grad/param norm = 1.7430e-01, time/batch = 17.5297s	
15223/30300 (epoch 25.120), train_loss = 1.17170174, grad/param norm = 1.6616e-01, time/batch = 19.5358s	
15224/30300 (epoch 25.122), train_loss = 1.25457223, grad/param norm = 1.7431e-01, time/batch = 18.8787s	
15225/30300 (epoch 25.124), train_loss = 1.31295324, grad/param norm = 1.8169e-01, time/batch = 18.5295s	
15226/30300 (epoch 25.125), train_loss = 1.03414057, grad/param norm = 1.6087e-01, time/batch = 17.8833s	
15227/30300 (epoch 25.127), train_loss = 1.20735479, grad/param norm = 1.8254e-01, time/batch = 18.1258s	
15228/30300 (epoch 25.129), train_loss = 1.30675463, grad/param norm = 1.6025e-01, time/batch = 20.3567s	
15229/30300 (epoch 25.130), train_loss = 1.29355639, grad/param norm = 1.5184e-01, time/batch = 18.6974s	
15230/30300 (epoch 25.132), train_loss = 1.30734479, grad/param norm = 1.7813e-01, time/batch = 18.3910s	
15231/30300 (epoch 25.134), train_loss = 1.07581790, grad/param norm = 1.5655e-01, time/batch = 19.4678s	
15232/30300 (epoch 25.135), train_loss = 1.10672798, grad/param norm = 1.5815e-01, time/batch = 18.4445s	
15233/30300 (epoch 25.137), train_loss = 1.16777893, grad/param norm = 1.5549e-01, time/batch = 19.7036s	
15234/30300 (epoch 25.139), train_loss = 1.14123120, grad/param norm = 1.8281e-01, time/batch = 17.9628s	
15235/30300 (epoch 25.140), train_loss = 1.24071317, grad/param norm = 2.9497e-01, time/batch = 17.9525s	
15236/30300 (epoch 25.142), train_loss = 1.34462695, grad/param norm = 2.3675e-01, time/batch = 19.3706s	
15237/30300 (epoch 25.144), train_loss = 1.15537879, grad/param norm = 1.8882e-01, time/batch = 19.6284s	
15238/30300 (epoch 25.145), train_loss = 1.26984058, grad/param norm = 2.4630e-01, time/batch = 18.4607s	
15239/30300 (epoch 25.147), train_loss = 1.14986416, grad/param norm = 1.7188e-01, time/batch = 19.2897s	
15240/30300 (epoch 25.149), train_loss = 1.35902072, grad/param norm = 1.8395e-01, time/batch = 19.5367s	
15241/30300 (epoch 25.150), train_loss = 1.16499825, grad/param norm = 2.0637e-01, time/batch = 18.2986s	
15242/30300 (epoch 25.152), train_loss = 1.07196760, grad/param norm = 1.7919e-01, time/batch = 18.2923s	
15243/30300 (epoch 25.153), train_loss = 1.18408058, grad/param norm = 1.9427e-01, time/batch = 18.8867s	
15244/30300 (epoch 25.155), train_loss = 1.02921623, grad/param norm = 1.5811e-01, time/batch = 17.2000s	
15245/30300 (epoch 25.157), train_loss = 1.15567401, grad/param norm = 2.0691e-01, time/batch = 18.1991s	
15246/30300 (epoch 25.158), train_loss = 1.19189459, grad/param norm = 1.8075e-01, time/batch = 19.9578s	
15247/30300 (epoch 25.160), train_loss = 1.10120590, grad/param norm = 1.6328e-01, time/batch = 19.3031s	
15248/30300 (epoch 25.162), train_loss = 1.15171357, grad/param norm = 1.5671e-01, time/batch = 17.6262s	
15249/30300 (epoch 25.163), train_loss = 1.14142368, grad/param norm = 1.7404e-01, time/batch = 20.3887s	
15250/30300 (epoch 25.165), train_loss = 1.26960053, grad/param norm = 1.4957e-01, time/batch = 19.8056s	
15251/30300 (epoch 25.167), train_loss = 1.16508619, grad/param norm = 1.7152e-01, time/batch = 17.8617s	
15252/30300 (epoch 25.168), train_loss = 1.22201210, grad/param norm = 1.6906e-01, time/batch = 19.1837s	
15253/30300 (epoch 25.170), train_loss = 1.17981326, grad/param norm = 1.6677e-01, time/batch = 18.2161s	
15254/30300 (epoch 25.172), train_loss = 1.16008345, grad/param norm = 1.6748e-01, time/batch = 18.4546s	
15255/30300 (epoch 25.173), train_loss = 1.17030236, grad/param norm = 1.9044e-01, time/batch = 17.8012s	
15256/30300 (epoch 25.175), train_loss = 1.17946459, grad/param norm = 1.5438e-01, time/batch = 18.8690s	
15257/30300 (epoch 25.177), train_loss = 1.20963168, grad/param norm = 1.7381e-01, time/batch = 18.7919s	
15258/30300 (epoch 25.178), train_loss = 0.95506444, grad/param norm = 1.5066e-01, time/batch = 19.5321s	
15259/30300 (epoch 25.180), train_loss = 1.16340634, grad/param norm = 1.5477e-01, time/batch = 18.7954s	
15260/30300 (epoch 25.182), train_loss = 1.16180677, grad/param norm = 1.7477e-01, time/batch = 18.7899s	
15261/30300 (epoch 25.183), train_loss = 1.10934964, grad/param norm = 1.5695e-01, time/batch = 19.4658s	
15262/30300 (epoch 25.185), train_loss = 1.35588870, grad/param norm = 1.9156e-01, time/batch = 18.8824s	
15263/30300 (epoch 25.186), train_loss = 1.37875240, grad/param norm = 1.7848e-01, time/batch = 19.2130s	
15264/30300 (epoch 25.188), train_loss = 1.20674109, grad/param norm = 1.6961e-01, time/batch = 18.5399s	
15265/30300 (epoch 25.190), train_loss = 1.17845018, grad/param norm = 1.5518e-01, time/batch = 18.6244s	
15266/30300 (epoch 25.191), train_loss = 1.25762515, grad/param norm = 1.8453e-01, time/batch = 18.3691s	
15267/30300 (epoch 25.193), train_loss = 1.08809088, grad/param norm = 1.4497e-01, time/batch = 18.0312s	
15268/30300 (epoch 25.195), train_loss = 1.16393982, grad/param norm = 1.6074e-01, time/batch = 19.0352s	
15269/30300 (epoch 25.196), train_loss = 1.20443695, grad/param norm = 1.9835e-01, time/batch = 17.8805s	
15270/30300 (epoch 25.198), train_loss = 0.99175893, grad/param norm = 1.4846e-01, time/batch = 18.2766s	
15271/30300 (epoch 25.200), train_loss = 1.16412345, grad/param norm = 1.4743e-01, time/batch = 18.3724s	
15272/30300 (epoch 25.201), train_loss = 1.24383332, grad/param norm = 1.9116e-01, time/batch = 16.4484s	
15273/30300 (epoch 25.203), train_loss = 1.18166167, grad/param norm = 1.6238e-01, time/batch = 16.4762s	
15274/30300 (epoch 25.205), train_loss = 1.37969235, grad/param norm = 1.6675e-01, time/batch = 17.7064s	
15275/30300 (epoch 25.206), train_loss = 1.28664676, grad/param norm = 1.7572e-01, time/batch = 17.0899s	
15276/30300 (epoch 25.208), train_loss = 1.27523674, grad/param norm = 2.3137e-01, time/batch = 17.5369s	
15277/30300 (epoch 25.210), train_loss = 1.23335188, grad/param norm = 1.6275e-01, time/batch = 16.8051s	
15278/30300 (epoch 25.211), train_loss = 1.28346926, grad/param norm = 1.6737e-01, time/batch = 19.4613s	
15279/30300 (epoch 25.213), train_loss = 1.13591291, grad/param norm = 1.3735e-01, time/batch = 17.8670s	
15280/30300 (epoch 25.215), train_loss = 1.08742894, grad/param norm = 1.7747e-01, time/batch = 17.4604s	
15281/30300 (epoch 25.216), train_loss = 1.12227525, grad/param norm = 1.7981e-01, time/batch = 18.1976s	
15282/30300 (epoch 25.218), train_loss = 1.06295423, grad/param norm = 1.4248e-01, time/batch = 20.2919s	
15283/30300 (epoch 25.219), train_loss = 1.00826239, grad/param norm = 1.2657e-01, time/batch = 18.2716s	
15284/30300 (epoch 25.221), train_loss = 1.02324644, grad/param norm = 1.4940e-01, time/batch = 18.0070s	
15285/30300 (epoch 25.223), train_loss = 1.18812558, grad/param norm = 1.6048e-01, time/batch = 19.4643s	
15286/30300 (epoch 25.224), train_loss = 1.01331598, grad/param norm = 1.4922e-01, time/batch = 18.7868s	
15287/30300 (epoch 25.226), train_loss = 1.24350646, grad/param norm = 1.7424e-01, time/batch = 17.6284s	
15288/30300 (epoch 25.228), train_loss = 1.27275849, grad/param norm = 1.6373e-01, time/batch = 19.1428s	
15289/30300 (epoch 25.229), train_loss = 1.14030336, grad/param norm = 1.5141e-01, time/batch = 19.2064s	
15290/30300 (epoch 25.231), train_loss = 1.18996655, grad/param norm = 1.5829e-01, time/batch = 17.1260s	
15291/30300 (epoch 25.233), train_loss = 1.18741581, grad/param norm = 1.4251e-01, time/batch = 19.0378s	
15292/30300 (epoch 25.234), train_loss = 1.22375988, grad/param norm = 1.8830e-01, time/batch = 18.2956s	
15293/30300 (epoch 25.236), train_loss = 1.18664538, grad/param norm = 1.4088e-01, time/batch = 17.4671s	
15294/30300 (epoch 25.238), train_loss = 1.21022779, grad/param norm = 1.7984e-01, time/batch = 18.8061s	
15295/30300 (epoch 25.239), train_loss = 1.19894379, grad/param norm = 1.7009e-01, time/batch = 19.4578s	
15296/30300 (epoch 25.241), train_loss = 1.21185973, grad/param norm = 1.8694e-01, time/batch = 17.8761s	
15297/30300 (epoch 25.243), train_loss = 1.23887620, grad/param norm = 1.6776e-01, time/batch = 18.7917s	
15298/30300 (epoch 25.244), train_loss = 1.40401928, grad/param norm = 1.8478e-01, time/batch = 18.0419s	
15299/30300 (epoch 25.246), train_loss = 1.20171838, grad/param norm = 1.6374e-01, time/batch = 18.7038s	
15300/30300 (epoch 25.248), train_loss = 1.14764060, grad/param norm = 1.5189e-01, time/batch = 18.1893s	
15301/30300 (epoch 25.249), train_loss = 1.10739066, grad/param norm = 1.5489e-01, time/batch = 18.0245s	
15302/30300 (epoch 25.251), train_loss = 1.10557178, grad/param norm = 1.6427e-01, time/batch = 16.9535s	
15303/30300 (epoch 25.252), train_loss = 1.28070947, grad/param norm = 1.7379e-01, time/batch = 17.5191s	
15304/30300 (epoch 25.254), train_loss = 1.26442142, grad/param norm = 1.7015e-01, time/batch = 19.3813s	
15305/30300 (epoch 25.256), train_loss = 1.20634931, grad/param norm = 1.5632e-01, time/batch = 19.0474s	
15306/30300 (epoch 25.257), train_loss = 1.22942284, grad/param norm = 1.5968e-01, time/batch = 17.7118s	
15307/30300 (epoch 25.259), train_loss = 1.16092633, grad/param norm = 1.8392e-01, time/batch = 17.4542s	
15308/30300 (epoch 25.261), train_loss = 1.28372400, grad/param norm = 1.5649e-01, time/batch = 18.4692s	
15309/30300 (epoch 25.262), train_loss = 1.15500263, grad/param norm = 1.6666e-01, time/batch = 18.0387s	
15310/30300 (epoch 25.264), train_loss = 1.18688371, grad/param norm = 1.6113e-01, time/batch = 18.8747s	
15311/30300 (epoch 25.266), train_loss = 1.10427229, grad/param norm = 1.3853e-01, time/batch = 19.4749s	
15312/30300 (epoch 25.267), train_loss = 1.36800690, grad/param norm = 1.9286e-01, time/batch = 19.1324s	
15313/30300 (epoch 25.269), train_loss = 1.20319623, grad/param norm = 1.6506e-01, time/batch = 18.9508s	
15314/30300 (epoch 25.271), train_loss = 1.21601909, grad/param norm = 1.6148e-01, time/batch = 19.8816s	
15315/30300 (epoch 25.272), train_loss = 1.19195431, grad/param norm = 1.8380e-01, time/batch = 19.3766s	
15316/30300 (epoch 25.274), train_loss = 1.26454476, grad/param norm = 1.7054e-01, time/batch = 18.3762s	
15317/30300 (epoch 25.276), train_loss = 1.24101894, grad/param norm = 1.8242e-01, time/batch = 17.7801s	
15318/30300 (epoch 25.277), train_loss = 1.05665685, grad/param norm = 1.7423e-01, time/batch = 19.0494s	
15319/30300 (epoch 25.279), train_loss = 1.20609218, grad/param norm = 1.7093e-01, time/batch = 17.9692s	
15320/30300 (epoch 25.281), train_loss = 1.28163321, grad/param norm = 1.9438e-01, time/batch = 17.4532s	
15321/30300 (epoch 25.282), train_loss = 1.18281332, grad/param norm = 1.4394e-01, time/batch = 19.7838s	
15322/30300 (epoch 25.284), train_loss = 1.30547009, grad/param norm = 1.9860e-01, time/batch = 18.1169s	
15323/30300 (epoch 25.285), train_loss = 1.23570611, grad/param norm = 1.4555e-01, time/batch = 18.7992s	
15324/30300 (epoch 25.287), train_loss = 1.17356654, grad/param norm = 1.7280e-01, time/batch = 19.7789s	
15325/30300 (epoch 25.289), train_loss = 1.25976767, grad/param norm = 1.5730e-01, time/batch = 17.6361s	
15326/30300 (epoch 25.290), train_loss = 0.95206451, grad/param norm = 1.5108e-01, time/batch = 19.4534s	
15327/30300 (epoch 25.292), train_loss = 1.09029637, grad/param norm = 1.5609e-01, time/batch = 18.7952s	
15328/30300 (epoch 25.294), train_loss = 1.28541184, grad/param norm = 2.1680e-01, time/batch = 18.6297s	
15329/30300 (epoch 25.295), train_loss = 1.15142505, grad/param norm = 1.7698e-01, time/batch = 18.2893s	
15330/30300 (epoch 25.297), train_loss = 1.11970924, grad/param norm = 1.5484e-01, time/batch = 18.8091s	
15331/30300 (epoch 25.299), train_loss = 1.16322304, grad/param norm = 1.9645e-01, time/batch = 19.4700s	
15332/30300 (epoch 25.300), train_loss = 1.11342961, grad/param norm = 1.4775e-01, time/batch = 17.8021s	
15333/30300 (epoch 25.302), train_loss = 1.18407456, grad/param norm = 1.5457e-01, time/batch = 17.3755s	
15334/30300 (epoch 25.304), train_loss = 1.07986079, grad/param norm = 1.5492e-01, time/batch = 19.7058s	
15335/30300 (epoch 25.305), train_loss = 1.13448872, grad/param norm = 1.4309e-01, time/batch = 18.2012s	
15336/30300 (epoch 25.307), train_loss = 1.24278542, grad/param norm = 1.3926e-01, time/batch = 19.5559s	
15337/30300 (epoch 25.309), train_loss = 1.22311393, grad/param norm = 1.5250e-01, time/batch = 19.1931s	
15338/30300 (epoch 25.310), train_loss = 1.17894716, grad/param norm = 1.6022e-01, time/batch = 17.3001s	
15339/30300 (epoch 25.312), train_loss = 1.30344015, grad/param norm = 1.5016e-01, time/batch = 18.5889s	
15340/30300 (epoch 25.314), train_loss = 1.18212681, grad/param norm = 1.5849e-01, time/batch = 18.9829s	
15341/30300 (epoch 25.315), train_loss = 1.16584672, grad/param norm = 1.6525e-01, time/batch = 18.7947s	
15342/30300 (epoch 25.317), train_loss = 1.22224554, grad/param norm = 1.5441e-01, time/batch = 19.1294s	
15343/30300 (epoch 25.318), train_loss = 1.28229591, grad/param norm = 1.7656e-01, time/batch = 19.1358s	
15344/30300 (epoch 25.320), train_loss = 1.24669866, grad/param norm = 1.6714e-01, time/batch = 18.6996s	
15345/30300 (epoch 25.322), train_loss = 1.11763856, grad/param norm = 1.7003e-01, time/batch = 18.9724s	
15346/30300 (epoch 25.323), train_loss = 1.28058881, grad/param norm = 1.7430e-01, time/batch = 19.7773s	
15347/30300 (epoch 25.325), train_loss = 1.16296605, grad/param norm = 1.5634e-01, time/batch = 19.4456s	
15348/30300 (epoch 25.327), train_loss = 1.18538901, grad/param norm = 1.5108e-01, time/batch = 16.8452s	
15349/30300 (epoch 25.328), train_loss = 1.18098427, grad/param norm = 1.4525e-01, time/batch = 18.6442s	
15350/30300 (epoch 25.330), train_loss = 1.23486154, grad/param norm = 1.5961e-01, time/batch = 18.4677s	
15351/30300 (epoch 25.332), train_loss = 1.26980314, grad/param norm = 1.8659e-01, time/batch = 17.7133s	
15352/30300 (epoch 25.333), train_loss = 1.15025625, grad/param norm = 1.6301e-01, time/batch = 19.0506s	
15353/30300 (epoch 25.335), train_loss = 1.06293147, grad/param norm = 1.6086e-01, time/batch = 19.7906s	
15354/30300 (epoch 25.337), train_loss = 1.31822047, grad/param norm = 1.4954e-01, time/batch = 17.5346s	
15355/30300 (epoch 25.338), train_loss = 1.11050131, grad/param norm = 1.4767e-01, time/batch = 19.0432s	
15356/30300 (epoch 25.340), train_loss = 1.09964761, grad/param norm = 1.5837e-01, time/batch = 19.5445s	
15357/30300 (epoch 25.342), train_loss = 1.25464161, grad/param norm = 1.5187e-01, time/batch = 17.9555s	
15358/30300 (epoch 25.343), train_loss = 1.18915586, grad/param norm = 1.5284e-01, time/batch = 19.6323s	
15359/30300 (epoch 25.345), train_loss = 1.22838526, grad/param norm = 1.5846e-01, time/batch = 19.3846s	
15360/30300 (epoch 25.347), train_loss = 1.04749198, grad/param norm = 1.3823e-01, time/batch = 18.3034s	
15361/30300 (epoch 25.348), train_loss = 1.09843412, grad/param norm = 1.6394e-01, time/batch = 18.4740s	
15362/30300 (epoch 25.350), train_loss = 1.15019172, grad/param norm = 1.5537e-01, time/batch = 18.9604s	
15363/30300 (epoch 25.351), train_loss = 1.17773489, grad/param norm = 1.6118e-01, time/batch = 17.2948s	
15364/30300 (epoch 25.353), train_loss = 1.03454610, grad/param norm = 1.5055e-01, time/batch = 32.7811s	
15365/30300 (epoch 25.355), train_loss = 1.13380624, grad/param norm = 1.4223e-01, time/batch = 17.3673s	
15366/30300 (epoch 25.356), train_loss = 1.24869203, grad/param norm = 1.8625e-01, time/batch = 18.1195s	
15367/30300 (epoch 25.358), train_loss = 1.41142448, grad/param norm = 1.4933e-01, time/batch = 19.5400s	
15368/30300 (epoch 25.360), train_loss = 1.13380364, grad/param norm = 1.7600e-01, time/batch = 18.5222s	
15369/30300 (epoch 25.361), train_loss = 1.19998840, grad/param norm = 1.5976e-01, time/batch = 18.5351s	
15370/30300 (epoch 25.363), train_loss = 1.24114333, grad/param norm = 1.6468e-01, time/batch = 18.1165s	
15371/30300 (epoch 25.365), train_loss = 1.07870714, grad/param norm = 1.7155e-01, time/batch = 18.5858s	
15372/30300 (epoch 25.366), train_loss = 1.13254486, grad/param norm = 1.3764e-01, time/batch = 18.4595s	
15373/30300 (epoch 25.368), train_loss = 1.00292006, grad/param norm = 1.3696e-01, time/batch = 16.3462s	
15374/30300 (epoch 25.370), train_loss = 1.07063728, grad/param norm = 1.3847e-01, time/batch = 17.3809s	
15375/30300 (epoch 25.371), train_loss = 1.24880607, grad/param norm = 1.5648e-01, time/batch = 17.1241s	
15376/30300 (epoch 25.373), train_loss = 1.09080764, grad/param norm = 1.3554e-01, time/batch = 18.1224s	
15377/30300 (epoch 25.375), train_loss = 1.09048489, grad/param norm = 1.4078e-01, time/batch = 18.8128s	
15378/30300 (epoch 25.376), train_loss = 1.09802213, grad/param norm = 1.5503e-01, time/batch = 20.3716s	
15379/30300 (epoch 25.378), train_loss = 1.08109741, grad/param norm = 1.5156e-01, time/batch = 18.2071s	
15380/30300 (epoch 25.380), train_loss = 1.32457711, grad/param norm = 1.6310e-01, time/batch = 18.7172s	
15381/30300 (epoch 25.381), train_loss = 1.01691756, grad/param norm = 1.3763e-01, time/batch = 19.9541s	
15382/30300 (epoch 25.383), train_loss = 1.09284761, grad/param norm = 1.6127e-01, time/batch = 17.7145s	
15383/30300 (epoch 25.384), train_loss = 1.22233590, grad/param norm = 1.6574e-01, time/batch = 19.2124s	
15384/30300 (epoch 25.386), train_loss = 1.05475561, grad/param norm = 1.4255e-01, time/batch = 19.3672s	
15385/30300 (epoch 25.388), train_loss = 1.01495078, grad/param norm = 1.4260e-01, time/batch = 19.3790s	
15386/30300 (epoch 25.389), train_loss = 1.12987186, grad/param norm = 1.6674e-01, time/batch = 18.3645s	
15387/30300 (epoch 25.391), train_loss = 1.21294593, grad/param norm = 1.4818e-01, time/batch = 17.2084s	
15388/30300 (epoch 25.393), train_loss = 1.02477452, grad/param norm = 1.3896e-01, time/batch = 19.2199s	
15389/30300 (epoch 25.394), train_loss = 1.21965778, grad/param norm = 1.4810e-01, time/batch = 17.0434s	
15390/30300 (epoch 25.396), train_loss = 1.29284899, grad/param norm = 1.4853e-01, time/batch = 18.6237s	
15391/30300 (epoch 25.398), train_loss = 1.13278573, grad/param norm = 1.5419e-01, time/batch = 19.0432s	
15392/30300 (epoch 25.399), train_loss = 1.12678657, grad/param norm = 1.5320e-01, time/batch = 16.4650s	
15393/30300 (epoch 25.401), train_loss = 1.20177919, grad/param norm = 1.6529e-01, time/batch = 19.2061s	
15394/30300 (epoch 25.403), train_loss = 1.15119598, grad/param norm = 1.6091e-01, time/batch = 19.3023s	
15395/30300 (epoch 25.404), train_loss = 1.08127682, grad/param norm = 1.6971e-01, time/batch = 17.8759s	
15396/30300 (epoch 25.406), train_loss = 1.19148804, grad/param norm = 1.4892e-01, time/batch = 18.8607s	
15397/30300 (epoch 25.408), train_loss = 1.04016234, grad/param norm = 1.5161e-01, time/batch = 18.3897s	
15398/30300 (epoch 25.409), train_loss = 1.03922168, grad/param norm = 1.5162e-01, time/batch = 18.3718s	
15399/30300 (epoch 25.411), train_loss = 1.07173516, grad/param norm = 1.4037e-01, time/batch = 19.5356s	
15400/30300 (epoch 25.413), train_loss = 0.97065591, grad/param norm = 1.4738e-01, time/batch = 19.8885s	
15401/30300 (epoch 25.414), train_loss = 1.23879714, grad/param norm = 1.5949e-01, time/batch = 19.3935s	
15402/30300 (epoch 25.416), train_loss = 1.10207976, grad/param norm = 1.5166e-01, time/batch = 16.8562s	
15403/30300 (epoch 25.417), train_loss = 1.07443956, grad/param norm = 1.4800e-01, time/batch = 17.2735s	
15404/30300 (epoch 25.419), train_loss = 1.03135128, grad/param norm = 1.3722e-01, time/batch = 19.6339s	
15405/30300 (epoch 25.421), train_loss = 1.10765553, grad/param norm = 1.9106e-01, time/batch = 16.8954s	
15406/30300 (epoch 25.422), train_loss = 1.15858084, grad/param norm = 1.5821e-01, time/batch = 19.4716s	
15407/30300 (epoch 25.424), train_loss = 1.16663985, grad/param norm = 1.5812e-01, time/batch = 19.9735s	
15408/30300 (epoch 25.426), train_loss = 1.10323694, grad/param norm = 1.5732e-01, time/batch = 18.5526s	
15409/30300 (epoch 25.427), train_loss = 1.12562199, grad/param norm = 1.5673e-01, time/batch = 19.3797s	
15410/30300 (epoch 25.429), train_loss = 1.13040999, grad/param norm = 1.4055e-01, time/batch = 20.2083s	
15411/30300 (epoch 25.431), train_loss = 1.21073920, grad/param norm = 1.5115e-01, time/batch = 18.1325s	
15412/30300 (epoch 25.432), train_loss = 1.13545865, grad/param norm = 1.4256e-01, time/batch = 18.5375s	
15413/30300 (epoch 25.434), train_loss = 1.04955175, grad/param norm = 1.5846e-01, time/batch = 18.8126s	
15414/30300 (epoch 25.436), train_loss = 1.30897905, grad/param norm = 1.7438e-01, time/batch = 16.5152s	
15415/30300 (epoch 25.437), train_loss = 1.05015284, grad/param norm = 1.5357e-01, time/batch = 17.6910s	
15416/30300 (epoch 25.439), train_loss = 1.08843930, grad/param norm = 1.4440e-01, time/batch = 17.6183s	
15417/30300 (epoch 25.441), train_loss = 1.12963187, grad/param norm = 1.4517e-01, time/batch = 18.7945s	
15418/30300 (epoch 25.442), train_loss = 1.06081311, grad/param norm = 1.5857e-01, time/batch = 17.4459s	
15419/30300 (epoch 25.444), train_loss = 0.97147537, grad/param norm = 1.4888e-01, time/batch = 19.2151s	
15420/30300 (epoch 25.446), train_loss = 1.12611904, grad/param norm = 1.4120e-01, time/batch = 18.0349s	
15421/30300 (epoch 25.447), train_loss = 1.15370036, grad/param norm = 1.6400e-01, time/batch = 18.2189s	
15422/30300 (epoch 25.449), train_loss = 1.07318806, grad/param norm = 1.4286e-01, time/batch = 17.6977s	
15423/30300 (epoch 25.450), train_loss = 1.20853257, grad/param norm = 1.5391e-01, time/batch = 19.0347s	
15424/30300 (epoch 25.452), train_loss = 1.24396479, grad/param norm = 1.5678e-01, time/batch = 18.7978s	
15425/30300 (epoch 25.454), train_loss = 1.21074076, grad/param norm = 1.3370e-01, time/batch = 18.1318s	
15426/30300 (epoch 25.455), train_loss = 1.16309684, grad/param norm = 1.5655e-01, time/batch = 18.4479s	
15427/30300 (epoch 25.457), train_loss = 1.13321100, grad/param norm = 1.4836e-01, time/batch = 19.4559s	
15428/30300 (epoch 25.459), train_loss = 1.21387872, grad/param norm = 1.7097e-01, time/batch = 18.2678s	
15429/30300 (epoch 25.460), train_loss = 1.18137038, grad/param norm = 1.5330e-01, time/batch = 18.8028s	
15430/30300 (epoch 25.462), train_loss = 1.20636778, grad/param norm = 1.5246e-01, time/batch = 19.0627s	
15431/30300 (epoch 25.464), train_loss = 0.98401754, grad/param norm = 1.6186e-01, time/batch = 18.1930s	
15432/30300 (epoch 25.465), train_loss = 0.97441302, grad/param norm = 1.4000e-01, time/batch = 19.4450s	
15433/30300 (epoch 25.467), train_loss = 0.94832529, grad/param norm = 1.3289e-01, time/batch = 17.0508s	
15434/30300 (epoch 25.469), train_loss = 1.06613894, grad/param norm = 1.3196e-01, time/batch = 17.7897s	
15435/30300 (epoch 25.470), train_loss = 1.11090609, grad/param norm = 1.5614e-01, time/batch = 18.9635s	
15436/30300 (epoch 25.472), train_loss = 1.09415582, grad/param norm = 1.3232e-01, time/batch = 17.8865s	
15437/30300 (epoch 25.474), train_loss = 1.11227955, grad/param norm = 1.8023e-01, time/batch = 17.5170s	
15438/30300 (epoch 25.475), train_loss = 1.08561311, grad/param norm = 1.4260e-01, time/batch = 18.1183s	
15439/30300 (epoch 25.477), train_loss = 1.13645402, grad/param norm = 1.4747e-01, time/batch = 19.2088s	
15440/30300 (epoch 25.479), train_loss = 1.11416664, grad/param norm = 1.5423e-01, time/batch = 18.8706s	
15441/30300 (epoch 25.480), train_loss = 1.15847528, grad/param norm = 1.3966e-01, time/batch = 19.3666s	
15442/30300 (epoch 25.482), train_loss = 1.19369030, grad/param norm = 1.3792e-01, time/batch = 19.2221s	
15443/30300 (epoch 25.483), train_loss = 1.09921662, grad/param norm = 1.5066e-01, time/batch = 19.2167s	
15444/30300 (epoch 25.485), train_loss = 1.14336974, grad/param norm = 1.4232e-01, time/batch = 17.7726s	
15445/30300 (epoch 25.487), train_loss = 1.23252318, grad/param norm = 1.6096e-01, time/batch = 19.3106s	
15446/30300 (epoch 25.488), train_loss = 1.23850718, grad/param norm = 1.3770e-01, time/batch = 18.8056s	
15447/30300 (epoch 25.490), train_loss = 1.03550334, grad/param norm = 1.4615e-01, time/batch = 17.2861s	
15448/30300 (epoch 25.492), train_loss = 1.12047546, grad/param norm = 1.6114e-01, time/batch = 19.2947s	
15449/30300 (epoch 25.493), train_loss = 1.10710055, grad/param norm = 1.3809e-01, time/batch = 18.8781s	
15450/30300 (epoch 25.495), train_loss = 1.09916430, grad/param norm = 1.4072e-01, time/batch = 17.6329s	
15451/30300 (epoch 25.497), train_loss = 1.14936600, grad/param norm = 1.4521e-01, time/batch = 19.3668s	
15452/30300 (epoch 25.498), train_loss = 1.19577610, grad/param norm = 1.5703e-01, time/batch = 18.6354s	
15453/30300 (epoch 25.500), train_loss = 1.14568864, grad/param norm = 1.6167e-01, time/batch = 18.4593s	
15454/30300 (epoch 25.502), train_loss = 1.15632495, grad/param norm = 1.6456e-01, time/batch = 17.7897s	
15455/30300 (epoch 25.503), train_loss = 1.24436844, grad/param norm = 1.5212e-01, time/batch = 18.5361s	
15456/30300 (epoch 25.505), train_loss = 1.08141090, grad/param norm = 1.4523e-01, time/batch = 18.5141s	
15457/30300 (epoch 25.507), train_loss = 1.06990074, grad/param norm = 1.8348e-01, time/batch = 17.0251s	
15458/30300 (epoch 25.508), train_loss = 1.11826204, grad/param norm = 1.5701e-01, time/batch = 19.2115s	
15459/30300 (epoch 25.510), train_loss = 1.23899451, grad/param norm = 1.6283e-01, time/batch = 19.7938s	
15460/30300 (epoch 25.512), train_loss = 1.09093819, grad/param norm = 1.4585e-01, time/batch = 17.9638s	
15461/30300 (epoch 25.513), train_loss = 1.16454099, grad/param norm = 1.4029e-01, time/batch = 18.2857s	
15462/30300 (epoch 25.515), train_loss = 1.14573665, grad/param norm = 1.4565e-01, time/batch = 18.0468s	
15463/30300 (epoch 25.517), train_loss = 0.96272406, grad/param norm = 1.2588e-01, time/batch = 18.4711s	
15464/30300 (epoch 25.518), train_loss = 1.22720392, grad/param norm = 1.6255e-01, time/batch = 18.2055s	
15465/30300 (epoch 25.520), train_loss = 1.20890201, grad/param norm = 1.7689e-01, time/batch = 17.8886s	
15466/30300 (epoch 25.521), train_loss = 1.07757404, grad/param norm = 1.6722e-01, time/batch = 18.1096s	
15467/30300 (epoch 25.523), train_loss = 1.31485420, grad/param norm = 2.0766e-01, time/batch = 16.9553s	
15468/30300 (epoch 25.525), train_loss = 1.07987335, grad/param norm = 1.5983e-01, time/batch = 18.8017s	
15469/30300 (epoch 25.526), train_loss = 1.13034672, grad/param norm = 1.4507e-01, time/batch = 18.9665s	
15470/30300 (epoch 25.528), train_loss = 1.03916280, grad/param norm = 1.5435e-01, time/batch = 17.5328s	
15471/30300 (epoch 25.530), train_loss = 1.01887345, grad/param norm = 1.4697e-01, time/batch = 19.1332s	
15472/30300 (epoch 25.531), train_loss = 1.18777200, grad/param norm = 1.7207e-01, time/batch = 19.4681s	
15473/30300 (epoch 25.533), train_loss = 1.15590758, grad/param norm = 1.5076e-01, time/batch = 17.7025s	
15474/30300 (epoch 25.535), train_loss = 1.07592770, grad/param norm = 1.3968e-01, time/batch = 19.2092s	
15475/30300 (epoch 25.536), train_loss = 1.18274248, grad/param norm = 1.7125e-01, time/batch = 18.7643s	
15476/30300 (epoch 25.538), train_loss = 1.03825248, grad/param norm = 1.6593e-01, time/batch = 17.7164s	
15477/30300 (epoch 25.540), train_loss = 1.04987942, grad/param norm = 1.5123e-01, time/batch = 18.9519s	
15478/30300 (epoch 25.541), train_loss = 1.14172260, grad/param norm = 1.5871e-01, time/batch = 19.1938s	
15479/30300 (epoch 25.543), train_loss = 1.12380745, grad/param norm = 1.5869e-01, time/batch = 17.5225s	
15480/30300 (epoch 25.545), train_loss = 1.15281310, grad/param norm = 1.8501e-01, time/batch = 15.9854s	
15481/30300 (epoch 25.546), train_loss = 1.33578666, grad/param norm = 1.5219e-01, time/batch = 18.8662s	
15482/30300 (epoch 25.548), train_loss = 1.09100819, grad/param norm = 1.4888e-01, time/batch = 19.2958s	
15483/30300 (epoch 25.550), train_loss = 1.20259294, grad/param norm = 1.8465e-01, time/batch = 17.2896s	
15484/30300 (epoch 25.551), train_loss = 1.07624902, grad/param norm = 1.5042e-01, time/batch = 18.3673s	
15485/30300 (epoch 25.553), train_loss = 1.10182175, grad/param norm = 1.5089e-01, time/batch = 19.6163s	
15486/30300 (epoch 25.554), train_loss = 1.16039559, grad/param norm = 1.6376e-01, time/batch = 17.8743s	
15487/30300 (epoch 25.556), train_loss = 1.19476219, grad/param norm = 1.4432e-01, time/batch = 18.8587s	
15488/30300 (epoch 25.558), train_loss = 1.23273743, grad/param norm = 1.7777e-01, time/batch = 19.3706s	
15489/30300 (epoch 25.559), train_loss = 1.18311566, grad/param norm = 1.7325e-01, time/batch = 18.8656s	
15490/30300 (epoch 25.561), train_loss = 0.96763478, grad/param norm = 1.4247e-01, time/batch = 18.8885s	
15491/30300 (epoch 25.563), train_loss = 1.03784631, grad/param norm = 1.4869e-01, time/batch = 18.7283s	
15492/30300 (epoch 25.564), train_loss = 1.06919239, grad/param norm = 1.4732e-01, time/batch = 17.7943s	
15493/30300 (epoch 25.566), train_loss = 1.12761195, grad/param norm = 1.4078e-01, time/batch = 18.1992s	
15494/30300 (epoch 25.568), train_loss = 0.98445092, grad/param norm = 1.7008e-01, time/batch = 19.1446s	
15495/30300 (epoch 25.569), train_loss = 1.15070215, grad/param norm = 1.4955e-01, time/batch = 18.1269s	
15496/30300 (epoch 25.571), train_loss = 1.17194930, grad/param norm = 1.7041e-01, time/batch = 18.8716s	
15497/30300 (epoch 25.573), train_loss = 1.17967815, grad/param norm = 1.5615e-01, time/batch = 17.8815s	
15498/30300 (epoch 25.574), train_loss = 1.19370207, grad/param norm = 1.4338e-01, time/batch = 18.8908s	
15499/30300 (epoch 25.576), train_loss = 1.11347451, grad/param norm = 1.4171e-01, time/batch = 18.1187s	
15500/30300 (epoch 25.578), train_loss = 1.00018248, grad/param norm = 1.4256e-01, time/batch = 19.7039s	
15501/30300 (epoch 25.579), train_loss = 1.15165404, grad/param norm = 1.6805e-01, time/batch = 18.5426s	
15502/30300 (epoch 25.581), train_loss = 1.25296534, grad/param norm = 1.6247e-01, time/batch = 17.9529s	
15503/30300 (epoch 25.583), train_loss = 1.30411880, grad/param norm = 1.7152e-01, time/batch = 16.6857s	
15504/30300 (epoch 25.584), train_loss = 1.22297751, grad/param norm = 1.4522e-01, time/batch = 16.9393s	
15505/30300 (epoch 25.586), train_loss = 1.11554292, grad/param norm = 1.5123e-01, time/batch = 18.5519s	
15506/30300 (epoch 25.587), train_loss = 1.13275560, grad/param norm = 1.6194e-01, time/batch = 18.4577s	
15507/30300 (epoch 25.589), train_loss = 1.04383886, grad/param norm = 1.4830e-01, time/batch = 19.2251s	
15508/30300 (epoch 25.591), train_loss = 1.17910292, grad/param norm = 1.4536e-01, time/batch = 16.8704s	
15509/30300 (epoch 25.592), train_loss = 1.12623949, grad/param norm = 1.3840e-01, time/batch = 17.9446s	
15510/30300 (epoch 25.594), train_loss = 1.15198625, grad/param norm = 1.5314e-01, time/batch = 17.5234s	
15511/30300 (epoch 25.596), train_loss = 1.05235159, grad/param norm = 1.4109e-01, time/batch = 15.1210s	
15512/30300 (epoch 25.597), train_loss = 1.08268452, grad/param norm = 1.5663e-01, time/batch = 14.7981s	
15513/30300 (epoch 25.599), train_loss = 0.96389203, grad/param norm = 1.5333e-01, time/batch = 17.2805s	
15514/30300 (epoch 25.601), train_loss = 1.14901282, grad/param norm = 1.5805e-01, time/batch = 18.9663s	
15515/30300 (epoch 25.602), train_loss = 1.13375832, grad/param norm = 1.5246e-01, time/batch = 19.4731s	
15516/30300 (epoch 25.604), train_loss = 1.05823942, grad/param norm = 1.5430e-01, time/batch = 18.2941s	
15517/30300 (epoch 25.606), train_loss = 1.08503884, grad/param norm = 1.8746e-01, time/batch = 18.7020s	
15518/30300 (epoch 25.607), train_loss = 1.23189971, grad/param norm = 1.9377e-01, time/batch = 19.3847s	
15519/30300 (epoch 25.609), train_loss = 1.34867151, grad/param norm = 1.8043e-01, time/batch = 17.9502s	
15520/30300 (epoch 25.611), train_loss = 1.07498372, grad/param norm = 1.3931e-01, time/batch = 18.6088s	
15521/30300 (epoch 25.612), train_loss = 1.03116937, grad/param norm = 1.3660e-01, time/batch = 20.0408s	
15522/30300 (epoch 25.614), train_loss = 1.11219714, grad/param norm = 1.5441e-01, time/batch = 17.2145s	
15523/30300 (epoch 25.616), train_loss = 1.19134308, grad/param norm = 1.7870e-01, time/batch = 19.2126s	
15524/30300 (epoch 25.617), train_loss = 1.15729648, grad/param norm = 1.5871e-01, time/batch = 19.2170s	
15525/30300 (epoch 25.619), train_loss = 0.98089782, grad/param norm = 1.4893e-01, time/batch = 17.8698s	
15526/30300 (epoch 25.620), train_loss = 1.16493037, grad/param norm = 1.5245e-01, time/batch = 19.4519s	
15527/30300 (epoch 25.622), train_loss = 1.14099579, grad/param norm = 1.7020e-01, time/batch = 18.8884s	
15528/30300 (epoch 25.624), train_loss = 1.09532427, grad/param norm = 1.4425e-01, time/batch = 18.5370s	
15529/30300 (epoch 25.625), train_loss = 1.09287691, grad/param norm = 1.6678e-01, time/batch = 17.3805s	
15530/30300 (epoch 25.627), train_loss = 1.26939506, grad/param norm = 1.7589e-01, time/batch = 18.5560s	
15531/30300 (epoch 25.629), train_loss = 1.27657600, grad/param norm = 1.5697e-01, time/batch = 18.9542s	
15532/30300 (epoch 25.630), train_loss = 1.16376801, grad/param norm = 1.5254e-01, time/batch = 18.2016s	
15533/30300 (epoch 25.632), train_loss = 1.22128005, grad/param norm = 1.6785e-01, time/batch = 19.1359s	
15534/30300 (epoch 25.634), train_loss = 1.05567036, grad/param norm = 1.3649e-01, time/batch = 18.6482s	
15535/30300 (epoch 25.635), train_loss = 1.19662782, grad/param norm = 1.6625e-01, time/batch = 18.2074s	
15536/30300 (epoch 25.637), train_loss = 1.21628131, grad/param norm = 1.7566e-01, time/batch = 18.7947s	
15537/30300 (epoch 25.639), train_loss = 1.10998563, grad/param norm = 1.5133e-01, time/batch = 18.4394s	
15538/30300 (epoch 25.640), train_loss = 1.28294455, grad/param norm = 1.7161e-01, time/batch = 18.6251s	
15539/30300 (epoch 25.642), train_loss = 1.11629237, grad/param norm = 1.3143e-01, time/batch = 16.5544s	
15540/30300 (epoch 25.644), train_loss = 1.20374970, grad/param norm = 1.5039e-01, time/batch = 18.8012s	
15541/30300 (epoch 25.645), train_loss = 1.08081058, grad/param norm = 1.5117e-01, time/batch = 17.8923s	
15542/30300 (epoch 25.647), train_loss = 1.14887545, grad/param norm = 1.4303e-01, time/batch = 18.3047s	
15543/30300 (epoch 25.649), train_loss = 1.12518091, grad/param norm = 1.5740e-01, time/batch = 19.0500s	
15544/30300 (epoch 25.650), train_loss = 1.14595636, grad/param norm = 1.5337e-01, time/batch = 18.6214s	
15545/30300 (epoch 25.652), train_loss = 1.10148962, grad/param norm = 1.4670e-01, time/batch = 18.8096s	
15546/30300 (epoch 25.653), train_loss = 1.31205540, grad/param norm = 1.6295e-01, time/batch = 18.3882s	
15547/30300 (epoch 25.655), train_loss = 1.06843237, grad/param norm = 1.5153e-01, time/batch = 19.2995s	
15548/30300 (epoch 25.657), train_loss = 1.08896396, grad/param norm = 1.8022e-01, time/batch = 19.2859s	
15549/30300 (epoch 25.658), train_loss = 1.05953488, grad/param norm = 1.4441e-01, time/batch = 18.1131s	
15550/30300 (epoch 25.660), train_loss = 1.15366722, grad/param norm = 1.6393e-01, time/batch = 19.5382s	
15551/30300 (epoch 25.662), train_loss = 1.15281750, grad/param norm = 1.7545e-01, time/batch = 17.4567s	
15552/30300 (epoch 25.663), train_loss = 1.18641180, grad/param norm = 1.6600e-01, time/batch = 18.7166s	
15553/30300 (epoch 25.665), train_loss = 1.08330343, grad/param norm = 1.6021e-01, time/batch = 18.8083s	
15554/30300 (epoch 25.667), train_loss = 1.22479681, grad/param norm = 1.5583e-01, time/batch = 18.0560s	
15555/30300 (epoch 25.668), train_loss = 1.22631502, grad/param norm = 1.5719e-01, time/batch = 18.8848s	
15556/30300 (epoch 25.670), train_loss = 1.26090375, grad/param norm = 1.7707e-01, time/batch = 19.3039s	
15557/30300 (epoch 25.672), train_loss = 1.17165666, grad/param norm = 1.7181e-01, time/batch = 22.9094s	
15558/30300 (epoch 25.673), train_loss = 1.19381551, grad/param norm = 1.8189e-01, time/batch = 28.4822s	
15559/30300 (epoch 25.675), train_loss = 1.10278992, grad/param norm = 1.5765e-01, time/batch = 18.9589s	
15560/30300 (epoch 25.677), train_loss = 1.09494056, grad/param norm = 1.4662e-01, time/batch = 17.2078s	
15561/30300 (epoch 25.678), train_loss = 1.07827746, grad/param norm = 1.4528e-01, time/batch = 17.2254s	
15562/30300 (epoch 25.680), train_loss = 0.95746826, grad/param norm = 1.3962e-01, time/batch = 17.4515s	
15563/30300 (epoch 25.682), train_loss = 1.13271485, grad/param norm = 1.5342e-01, time/batch = 17.3652s	
15564/30300 (epoch 25.683), train_loss = 1.24557643, grad/param norm = 1.4592e-01, time/batch = 18.0459s	
15565/30300 (epoch 25.685), train_loss = 1.23629650, grad/param norm = 1.7452e-01, time/batch = 16.8831s	
15566/30300 (epoch 25.686), train_loss = 1.11237997, grad/param norm = 1.3888e-01, time/batch = 18.3825s	
15567/30300 (epoch 25.688), train_loss = 1.14458104, grad/param norm = 1.4700e-01, time/batch = 18.6999s	
15568/30300 (epoch 25.690), train_loss = 1.08621553, grad/param norm = 1.6046e-01, time/batch = 18.0535s	
15569/30300 (epoch 25.691), train_loss = 1.18768494, grad/param norm = 1.4079e-01, time/batch = 17.0268s	
15570/30300 (epoch 25.693), train_loss = 1.45494973, grad/param norm = 1.7730e-01, time/batch = 18.4423s	
15571/30300 (epoch 25.695), train_loss = 1.25509367, grad/param norm = 1.7373e-01, time/batch = 17.7145s	
15572/30300 (epoch 25.696), train_loss = 1.20453188, grad/param norm = 1.8179e-01, time/batch = 18.4725s	
15573/30300 (epoch 25.698), train_loss = 1.09063285, grad/param norm = 1.5724e-01, time/batch = 17.8650s	
15574/30300 (epoch 25.700), train_loss = 1.07808699, grad/param norm = 1.4991e-01, time/batch = 18.6348s	
15575/30300 (epoch 25.701), train_loss = 0.98386002, grad/param norm = 1.3656e-01, time/batch = 18.7270s	
15576/30300 (epoch 25.703), train_loss = 1.14087334, grad/param norm = 1.3937e-01, time/batch = 17.7140s	
15577/30300 (epoch 25.705), train_loss = 1.08077134, grad/param norm = 1.5375e-01, time/batch = 17.6200s	
15578/30300 (epoch 25.706), train_loss = 1.20677354, grad/param norm = 1.7905e-01, time/batch = 19.1400s	
15579/30300 (epoch 25.708), train_loss = 1.12916746, grad/param norm = 1.5916e-01, time/batch = 19.3114s	
15580/30300 (epoch 25.710), train_loss = 1.11502616, grad/param norm = 1.5906e-01, time/batch = 17.8629s	
15581/30300 (epoch 25.711), train_loss = 1.05612211, grad/param norm = 1.4407e-01, time/batch = 19.9511s	
15582/30300 (epoch 25.713), train_loss = 1.05537280, grad/param norm = 1.5989e-01, time/batch = 16.9606s	
15583/30300 (epoch 25.715), train_loss = 1.08056364, grad/param norm = 1.4947e-01, time/batch = 17.6955s	
15584/30300 (epoch 25.716), train_loss = 1.22569579, grad/param norm = 1.4206e-01, time/batch = 17.7954s	
15585/30300 (epoch 25.718), train_loss = 1.26840413, grad/param norm = 1.6240e-01, time/batch = 18.7890s	
15586/30300 (epoch 25.719), train_loss = 1.10282804, grad/param norm = 1.6351e-01, time/batch = 17.8126s	
15587/30300 (epoch 25.721), train_loss = 1.13957233, grad/param norm = 1.6497e-01, time/batch = 18.2992s	
15588/30300 (epoch 25.723), train_loss = 1.08867032, grad/param norm = 1.5481e-01, time/batch = 18.6304s	
15589/30300 (epoch 25.724), train_loss = 1.16650517, grad/param norm = 1.6553e-01, time/batch = 18.3970s	
15590/30300 (epoch 25.726), train_loss = 1.49148261, grad/param norm = 1.8783e-01, time/batch = 17.1193s	
15591/30300 (epoch 25.728), train_loss = 1.19812923, grad/param norm = 1.5837e-01, time/batch = 18.5580s	
15592/30300 (epoch 25.729), train_loss = 1.11170448, grad/param norm = 1.5644e-01, time/batch = 19.0590s	
15593/30300 (epoch 25.731), train_loss = 1.17686884, grad/param norm = 1.6575e-01, time/batch = 17.5280s	
15594/30300 (epoch 25.733), train_loss = 1.16216906, grad/param norm = 1.6162e-01, time/batch = 19.6157s	
15595/30300 (epoch 25.734), train_loss = 1.23020324, grad/param norm = 1.4526e-01, time/batch = 19.7139s	
15596/30300 (epoch 25.736), train_loss = 1.11953903, grad/param norm = 1.5056e-01, time/batch = 16.9449s	
15597/30300 (epoch 25.738), train_loss = 1.06469107, grad/param norm = 1.3455e-01, time/batch = 18.7000s	
15598/30300 (epoch 25.739), train_loss = 1.20369275, grad/param norm = 1.4428e-01, time/batch = 18.9571s	
15599/30300 (epoch 25.741), train_loss = 1.28441316, grad/param norm = 1.4620e-01, time/batch = 17.6241s	
15600/30300 (epoch 25.743), train_loss = 1.13103739, grad/param norm = 1.5616e-01, time/batch = 17.1765s	
15601/30300 (epoch 25.744), train_loss = 1.17251649, grad/param norm = 1.4922e-01, time/batch = 18.7125s	
15602/30300 (epoch 25.746), train_loss = 1.08684034, grad/param norm = 1.4720e-01, time/batch = 18.2159s	
15603/30300 (epoch 25.748), train_loss = 1.13069899, grad/param norm = 1.8347e-01, time/batch = 17.8014s	
15604/30300 (epoch 25.749), train_loss = 1.18759956, grad/param norm = 1.5592e-01, time/batch = 20.2072s	
15605/30300 (epoch 25.751), train_loss = 1.14249763, grad/param norm = 1.5874e-01, time/batch = 18.7871s	
15606/30300 (epoch 25.752), train_loss = 1.11441861, grad/param norm = 1.6387e-01, time/batch = 18.4443s	
15607/30300 (epoch 25.754), train_loss = 1.08646975, grad/param norm = 1.4802e-01, time/batch = 20.3737s	
15608/30300 (epoch 25.756), train_loss = 1.11676621, grad/param norm = 1.5315e-01, time/batch = 18.3794s	
15609/30300 (epoch 25.757), train_loss = 1.13052830, grad/param norm = 1.6196e-01, time/batch = 17.9500s	
15610/30300 (epoch 25.759), train_loss = 1.17507957, grad/param norm = 1.4761e-01, time/batch = 19.0532s	
15611/30300 (epoch 25.761), train_loss = 0.99095439, grad/param norm = 1.3696e-01, time/batch = 19.0460s	
15612/30300 (epoch 25.762), train_loss = 1.03552376, grad/param norm = 1.4959e-01, time/batch = 18.7937s	
15613/30300 (epoch 25.764), train_loss = 1.12739645, grad/param norm = 1.5632e-01, time/batch = 18.3889s	
15614/30300 (epoch 25.766), train_loss = 1.25250746, grad/param norm = 1.6998e-01, time/batch = 19.5400s	
15615/30300 (epoch 25.767), train_loss = 1.22564516, grad/param norm = 1.8242e-01, time/batch = 16.8686s	
15616/30300 (epoch 25.769), train_loss = 1.18688343, grad/param norm = 1.5877e-01, time/batch = 19.6046s	
15617/30300 (epoch 25.771), train_loss = 1.10396565, grad/param norm = 1.7493e-01, time/batch = 15.6143s	
15618/30300 (epoch 25.772), train_loss = 1.20874167, grad/param norm = 1.5896e-01, time/batch = 15.4379s	
15619/30300 (epoch 25.774), train_loss = 1.27619011, grad/param norm = 1.5743e-01, time/batch = 18.0214s	
15620/30300 (epoch 25.776), train_loss = 1.15408480, grad/param norm = 1.7009e-01, time/batch = 19.0451s	
15621/30300 (epoch 25.777), train_loss = 1.25856317, grad/param norm = 1.5543e-01, time/batch = 19.5574s	
15622/30300 (epoch 25.779), train_loss = 1.28307102, grad/param norm = 1.8018e-01, time/batch = 17.3620s	
15623/30300 (epoch 25.781), train_loss = 1.15716775, grad/param norm = 1.7318e-01, time/batch = 18.9540s	
15624/30300 (epoch 25.782), train_loss = 1.10334091, grad/param norm = 1.5627e-01, time/batch = 19.9461s	
15625/30300 (epoch 25.784), train_loss = 1.09381791, grad/param norm = 1.4138e-01, time/batch = 18.2145s	
15626/30300 (epoch 25.785), train_loss = 1.28413661, grad/param norm = 1.8061e-01, time/batch = 19.0416s	
15627/30300 (epoch 25.787), train_loss = 0.96405343, grad/param norm = 1.5610e-01, time/batch = 19.1396s	
15628/30300 (epoch 25.789), train_loss = 1.36132766, grad/param norm = 1.7984e-01, time/batch = 18.7267s	
15629/30300 (epoch 25.790), train_loss = 1.21306655, grad/param norm = 1.8281e-01, time/batch = 17.2745s	
15630/30300 (epoch 25.792), train_loss = 0.99656738, grad/param norm = 1.6944e-01, time/batch = 18.8059s	
15631/30300 (epoch 25.794), train_loss = 1.14994813, grad/param norm = 1.6968e-01, time/batch = 18.9724s	
15632/30300 (epoch 25.795), train_loss = 1.06181913, grad/param norm = 1.4946e-01, time/batch = 17.1351s	
15633/30300 (epoch 25.797), train_loss = 1.29854388, grad/param norm = 1.7689e-01, time/batch = 15.3704s	
15634/30300 (epoch 25.799), train_loss = 1.21475021, grad/param norm = 1.7636e-01, time/batch = 15.6819s	
15635/30300 (epoch 25.800), train_loss = 1.21651238, grad/param norm = 1.6014e-01, time/batch = 16.0173s	
15636/30300 (epoch 25.802), train_loss = 1.40739168, grad/param norm = 1.8855e-01, time/batch = 18.9259s	
15637/30300 (epoch 25.804), train_loss = 1.23992434, grad/param norm = 1.7024e-01, time/batch = 17.9608s	
15638/30300 (epoch 25.805), train_loss = 1.29651302, grad/param norm = 1.6807e-01, time/batch = 18.5502s	
15639/30300 (epoch 25.807), train_loss = 1.13683049, grad/param norm = 1.6796e-01, time/batch = 19.6980s	
15640/30300 (epoch 25.809), train_loss = 1.22654660, grad/param norm = 1.6361e-01, time/batch = 19.0523s	
15641/30300 (epoch 25.810), train_loss = 1.22446844, grad/param norm = 1.9358e-01, time/batch = 18.8211s	
15642/30300 (epoch 25.812), train_loss = 1.08007685, grad/param norm = 1.6120e-01, time/batch = 17.4257s	
15643/30300 (epoch 25.814), train_loss = 1.15051088, grad/param norm = 1.5864e-01, time/batch = 18.7792s	
15644/30300 (epoch 25.815), train_loss = 1.16711764, grad/param norm = 1.5942e-01, time/batch = 18.4639s	
15645/30300 (epoch 25.817), train_loss = 1.26440955, grad/param norm = 1.6991e-01, time/batch = 17.7127s	
15646/30300 (epoch 25.818), train_loss = 1.19804052, grad/param norm = 1.6495e-01, time/batch = 19.0631s	
15647/30300 (epoch 25.820), train_loss = 1.33186682, grad/param norm = 2.2026e-01, time/batch = 19.0517s	
15648/30300 (epoch 25.822), train_loss = 1.33030057, grad/param norm = 1.9549e-01, time/batch = 18.8857s	
15649/30300 (epoch 25.823), train_loss = 1.32200463, grad/param norm = 1.6661e-01, time/batch = 19.5399s	
15650/30300 (epoch 25.825), train_loss = 1.27495604, grad/param norm = 1.7108e-01, time/batch = 19.2973s	
15651/30300 (epoch 25.827), train_loss = 0.99592547, grad/param norm = 1.6748e-01, time/batch = 17.9663s	
15652/30300 (epoch 25.828), train_loss = 1.24907191, grad/param norm = 1.6200e-01, time/batch = 18.9558s	
15653/30300 (epoch 25.830), train_loss = 1.20376121, grad/param norm = 1.5870e-01, time/batch = 19.2185s	
15654/30300 (epoch 25.832), train_loss = 1.06744901, grad/param norm = 1.5852e-01, time/batch = 18.4531s	
15655/30300 (epoch 25.833), train_loss = 1.20580342, grad/param norm = 1.6019e-01, time/batch = 18.1417s	
15656/30300 (epoch 25.835), train_loss = 1.07969522, grad/param norm = 1.6879e-01, time/batch = 18.4389s	
15657/30300 (epoch 25.837), train_loss = 1.03382852, grad/param norm = 1.4908e-01, time/batch = 18.9688s	
15658/30300 (epoch 25.838), train_loss = 1.05516856, grad/param norm = 1.4662e-01, time/batch = 18.8676s	
15659/30300 (epoch 25.840), train_loss = 1.23763604, grad/param norm = 1.3918e-01, time/batch = 18.1248s	
15660/30300 (epoch 25.842), train_loss = 1.08807655, grad/param norm = 1.3460e-01, time/batch = 17.3731s	
15661/30300 (epoch 25.843), train_loss = 1.19538769, grad/param norm = 1.5981e-01, time/batch = 16.8789s	
15662/30300 (epoch 25.845), train_loss = 1.21597272, grad/param norm = 1.4740e-01, time/batch = 19.1295s	
15663/30300 (epoch 25.847), train_loss = 1.17599695, grad/param norm = 1.5347e-01, time/batch = 19.6108s	
15664/30300 (epoch 25.848), train_loss = 1.23629238, grad/param norm = 1.5007e-01, time/batch = 18.2057s	
15665/30300 (epoch 25.850), train_loss = 1.16203085, grad/param norm = 1.5260e-01, time/batch = 18.8749s	
15666/30300 (epoch 25.851), train_loss = 1.18123392, grad/param norm = 1.8693e-01, time/batch = 18.2925s	
15667/30300 (epoch 25.853), train_loss = 1.10121436, grad/param norm = 1.3759e-01, time/batch = 18.6334s	
15668/30300 (epoch 25.855), train_loss = 1.10142096, grad/param norm = 1.3787e-01, time/batch = 19.7832s	
15669/30300 (epoch 25.856), train_loss = 1.17765422, grad/param norm = 1.5092e-01, time/batch = 18.6334s	
15670/30300 (epoch 25.858), train_loss = 1.08601560, grad/param norm = 1.3550e-01, time/batch = 17.5354s	
15671/30300 (epoch 25.860), train_loss = 1.05567758, grad/param norm = 1.4736e-01, time/batch = 16.9479s	
15672/30300 (epoch 25.861), train_loss = 1.32446065, grad/param norm = 1.6003e-01, time/batch = 19.0348s	
15673/30300 (epoch 25.863), train_loss = 1.15761476, grad/param norm = 1.4012e-01, time/batch = 18.9795s	
15674/30300 (epoch 25.865), train_loss = 1.22249911, grad/param norm = 1.8184e-01, time/batch = 17.8728s	
15675/30300 (epoch 25.866), train_loss = 1.22463015, grad/param norm = 1.6042e-01, time/batch = 19.3023s	
15676/30300 (epoch 25.868), train_loss = 1.15707988, grad/param norm = 1.4569e-01, time/batch = 19.7161s	
15677/30300 (epoch 25.870), train_loss = 1.09298484, grad/param norm = 1.5695e-01, time/batch = 17.2101s	
15678/30300 (epoch 25.871), train_loss = 1.14118191, grad/param norm = 1.5396e-01, time/batch = 17.5322s	
15679/30300 (epoch 25.873), train_loss = 1.15916548, grad/param norm = 1.4211e-01, time/batch = 17.2873s	
15680/30300 (epoch 25.875), train_loss = 1.09595328, grad/param norm = 1.4056e-01, time/batch = 18.5634s	
15681/30300 (epoch 25.876), train_loss = 1.03533714, grad/param norm = 1.5974e-01, time/batch = 18.9489s	
15682/30300 (epoch 25.878), train_loss = 0.99797553, grad/param norm = 1.5165e-01, time/batch = 19.0457s	
15683/30300 (epoch 25.880), train_loss = 1.06764262, grad/param norm = 1.5374e-01, time/batch = 18.7228s	
15684/30300 (epoch 25.881), train_loss = 1.32167253, grad/param norm = 1.9941e-01, time/batch = 18.0315s	
15685/30300 (epoch 25.883), train_loss = 1.21011235, grad/param norm = 1.5662e-01, time/batch = 17.2092s	
15686/30300 (epoch 25.884), train_loss = 1.08567842, grad/param norm = 1.3666e-01, time/batch = 15.6941s	
15687/30300 (epoch 25.886), train_loss = 1.20327932, grad/param norm = 1.4547e-01, time/batch = 16.6853s	
15688/30300 (epoch 25.888), train_loss = 1.15547323, grad/param norm = 1.7046e-01, time/batch = 16.0779s	
15689/30300 (epoch 25.889), train_loss = 1.18605135, grad/param norm = 1.4892e-01, time/batch = 16.1950s	
15690/30300 (epoch 25.891), train_loss = 1.15819692, grad/param norm = 1.5592e-01, time/batch = 19.8024s	
15691/30300 (epoch 25.893), train_loss = 1.36973949, grad/param norm = 1.6049e-01, time/batch = 17.5441s	
15692/30300 (epoch 25.894), train_loss = 1.21186977, grad/param norm = 1.5207e-01, time/batch = 18.6342s	
15693/30300 (epoch 25.896), train_loss = 1.00259043, grad/param norm = 1.7110e-01, time/batch = 19.7082s	
15694/30300 (epoch 25.898), train_loss = 0.97284600, grad/param norm = 1.4847e-01, time/batch = 17.7091s	
15695/30300 (epoch 25.899), train_loss = 1.06044227, grad/param norm = 1.5422e-01, time/batch = 16.2789s	
15696/30300 (epoch 25.901), train_loss = 1.14358887, grad/param norm = 1.6998e-01, time/batch = 18.8007s	
15697/30300 (epoch 25.903), train_loss = 1.15998321, grad/param norm = 1.6500e-01, time/batch = 18.2115s	
15698/30300 (epoch 25.904), train_loss = 1.14224490, grad/param norm = 1.5323e-01, time/batch = 19.3643s	
15699/30300 (epoch 25.906), train_loss = 1.22049675, grad/param norm = 1.6777e-01, time/batch = 18.8041s	
15700/30300 (epoch 25.908), train_loss = 1.11198643, grad/param norm = 1.4670e-01, time/batch = 18.0471s	
15701/30300 (epoch 25.909), train_loss = 1.07927569, grad/param norm = 1.7945e-01, time/batch = 19.7079s	
15702/30300 (epoch 25.911), train_loss = 1.15319856, grad/param norm = 1.5404e-01, time/batch = 19.0486s	
15703/30300 (epoch 25.913), train_loss = 1.14839554, grad/param norm = 1.4335e-01, time/batch = 18.7887s	
15704/30300 (epoch 25.914), train_loss = 1.11540568, grad/param norm = 1.5650e-01, time/batch = 16.7784s	
15705/30300 (epoch 25.916), train_loss = 1.16963821, grad/param norm = 1.4452e-01, time/batch = 19.1151s	
15706/30300 (epoch 25.917), train_loss = 1.11344605, grad/param norm = 1.5700e-01, time/batch = 18.2255s	
15707/30300 (epoch 25.919), train_loss = 1.08538890, grad/param norm = 1.5656e-01, time/batch = 17.2115s	
15708/30300 (epoch 25.921), train_loss = 1.13547037, grad/param norm = 1.4220e-01, time/batch = 18.4767s	
15709/30300 (epoch 25.922), train_loss = 1.25712960, grad/param norm = 2.0502e-01, time/batch = 16.6350s	
15710/30300 (epoch 25.924), train_loss = 1.14413785, grad/param norm = 1.6128e-01, time/batch = 17.1987s	
15711/30300 (epoch 25.926), train_loss = 1.19531066, grad/param norm = 1.6233e-01, time/batch = 17.3683s	
15712/30300 (epoch 25.927), train_loss = 1.14923203, grad/param norm = 1.5034e-01, time/batch = 17.8693s	
15713/30300 (epoch 25.929), train_loss = 1.07461393, grad/param norm = 1.5657e-01, time/batch = 18.3618s	
15714/30300 (epoch 25.931), train_loss = 1.26938433, grad/param norm = 1.9412e-01, time/batch = 17.0552s	
15715/30300 (epoch 25.932), train_loss = 1.07772880, grad/param norm = 1.6070e-01, time/batch = 18.5402s	
15716/30300 (epoch 25.934), train_loss = 1.19127013, grad/param norm = 1.6175e-01, time/batch = 18.4351s	
15717/30300 (epoch 25.936), train_loss = 1.11925994, grad/param norm = 1.5016e-01, time/batch = 17.0483s	
15718/30300 (epoch 25.937), train_loss = 1.08389266, grad/param norm = 1.5017e-01, time/batch = 18.2162s	
15719/30300 (epoch 25.939), train_loss = 1.27991840, grad/param norm = 1.9551e-01, time/batch = 19.7891s	
15720/30300 (epoch 25.941), train_loss = 1.13174268, grad/param norm = 1.9969e-01, time/batch = 17.7926s	
15721/30300 (epoch 25.942), train_loss = 1.14200265, grad/param norm = 1.7099e-01, time/batch = 18.4726s	
15722/30300 (epoch 25.944), train_loss = 1.05103512, grad/param norm = 1.5995e-01, time/batch = 19.1346s	
15723/30300 (epoch 25.946), train_loss = 1.26992339, grad/param norm = 2.0508e-01, time/batch = 18.0441s	
15724/30300 (epoch 25.947), train_loss = 1.23279170, grad/param norm = 1.8315e-01, time/batch = 18.0591s	
15725/30300 (epoch 25.949), train_loss = 1.28941156, grad/param norm = 1.8275e-01, time/batch = 18.1414s	
15726/30300 (epoch 25.950), train_loss = 1.25415694, grad/param norm = 1.6607e-01, time/batch = 19.5513s	
15727/30300 (epoch 25.952), train_loss = 1.21898393, grad/param norm = 1.8888e-01, time/batch = 18.5294s	
15728/30300 (epoch 25.954), train_loss = 1.42146029, grad/param norm = 1.6045e-01, time/batch = 17.8601s	
15729/30300 (epoch 25.955), train_loss = 1.12472734, grad/param norm = 1.8697e-01, time/batch = 19.0507s	
15730/30300 (epoch 25.957), train_loss = 1.22988666, grad/param norm = 1.5897e-01, time/batch = 17.2167s	
15731/30300 (epoch 25.959), train_loss = 1.11068094, grad/param norm = 1.6630e-01, time/batch = 17.2849s	
15732/30300 (epoch 25.960), train_loss = 1.12008761, grad/param norm = 1.6739e-01, time/batch = 18.3948s	
15733/30300 (epoch 25.962), train_loss = 1.15003960, grad/param norm = 1.9623e-01, time/batch = 17.4507s	
15734/30300 (epoch 25.964), train_loss = 1.07744479, grad/param norm = 1.8401e-01, time/batch = 19.0249s	
15735/30300 (epoch 25.965), train_loss = 1.09362401, grad/param norm = 2.1168e-01, time/batch = 19.1211s	
15736/30300 (epoch 25.967), train_loss = 1.17566783, grad/param norm = 2.1494e-01, time/batch = 18.1282s	
15737/30300 (epoch 25.969), train_loss = 1.08078274, grad/param norm = 1.7967e-01, time/batch = 18.2894s	
15738/30300 (epoch 25.970), train_loss = 1.12031197, grad/param norm = 1.5624e-01, time/batch = 17.7191s	
15739/30300 (epoch 25.972), train_loss = 1.04055434, grad/param norm = 1.7374e-01, time/batch = 19.2826s	
15740/30300 (epoch 25.974), train_loss = 1.31119415, grad/param norm = 1.7235e-01, time/batch = 18.2806s	
15741/30300 (epoch 25.975), train_loss = 1.34689046, grad/param norm = 1.9138e-01, time/batch = 18.8782s	
15742/30300 (epoch 25.977), train_loss = 1.28546173, grad/param norm = 1.6715e-01, time/batch = 19.6334s	
15743/30300 (epoch 25.979), train_loss = 1.22962534, grad/param norm = 1.7016e-01, time/batch = 16.6908s	
15744/30300 (epoch 25.980), train_loss = 1.23926783, grad/param norm = 1.8055e-01, time/batch = 17.1275s	
15745/30300 (epoch 25.982), train_loss = 1.24764777, grad/param norm = 1.7170e-01, time/batch = 19.2145s	
15746/30300 (epoch 25.983), train_loss = 1.29551116, grad/param norm = 1.6588e-01, time/batch = 18.8001s	
15747/30300 (epoch 25.985), train_loss = 1.21581068, grad/param norm = 1.6773e-01, time/batch = 19.1395s	
15748/30300 (epoch 25.987), train_loss = 1.14695778, grad/param norm = 1.5176e-01, time/batch = 19.3785s	
15749/30300 (epoch 25.988), train_loss = 1.29561569, grad/param norm = 1.6276e-01, time/batch = 17.4671s	
15750/30300 (epoch 25.990), train_loss = 1.01855515, grad/param norm = 1.3802e-01, time/batch = 18.1249s	
15751/30300 (epoch 25.992), train_loss = 1.23599997, grad/param norm = 1.4851e-01, time/batch = 19.6227s	
15752/30300 (epoch 25.993), train_loss = 1.27547703, grad/param norm = 2.0127e-01, time/batch = 19.3103s	
15753/30300 (epoch 25.995), train_loss = 1.15502970, grad/param norm = 1.9161e-01, time/batch = 31.5369s	
15754/30300 (epoch 25.997), train_loss = 1.20186980, grad/param norm = 1.6681e-01, time/batch = 17.6036s	
15755/30300 (epoch 25.998), train_loss = 1.24105362, grad/param norm = 1.7621e-01, time/batch = 17.7173s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
15756/30300 (epoch 26.000), train_loss = 1.11894059, grad/param norm = 1.7442e-01, time/batch = 19.0500s	
15757/30300 (epoch 26.002), train_loss = 1.26662590, grad/param norm = 1.6341e-01, time/batch = 17.9759s	
15758/30300 (epoch 26.003), train_loss = 1.16711281, grad/param norm = 1.6520e-01, time/batch = 19.2032s	
15759/30300 (epoch 26.005), train_loss = 1.13059417, grad/param norm = 1.7003e-01, time/batch = 18.7104s	
15760/30300 (epoch 26.007), train_loss = 1.21269875, grad/param norm = 1.7817e-01, time/batch = 16.6249s	
15761/30300 (epoch 26.008), train_loss = 1.08435932, grad/param norm = 1.6242e-01, time/batch = 19.7142s	
15762/30300 (epoch 26.010), train_loss = 1.04281802, grad/param norm = 1.6382e-01, time/batch = 18.1392s	
15763/30300 (epoch 26.012), train_loss = 1.08994167, grad/param norm = 1.5008e-01, time/batch = 18.2962s	
15764/30300 (epoch 26.013), train_loss = 1.26647827, grad/param norm = 1.7103e-01, time/batch = 19.6192s	
15765/30300 (epoch 26.015), train_loss = 1.11231350, grad/param norm = 1.5038e-01, time/batch = 17.6192s	
15766/30300 (epoch 26.017), train_loss = 1.11234332, grad/param norm = 1.4012e-01, time/batch = 19.7088s	
15767/30300 (epoch 26.018), train_loss = 1.07043413, grad/param norm = 1.4426e-01, time/batch = 19.3741s	
15768/30300 (epoch 26.020), train_loss = 1.26794631, grad/param norm = 1.8871e-01, time/batch = 17.1226s	
15769/30300 (epoch 26.021), train_loss = 1.27949952, grad/param norm = 1.6593e-01, time/batch = 19.6081s	
15770/30300 (epoch 26.023), train_loss = 1.18368372, grad/param norm = 1.5623e-01, time/batch = 19.2143s	
15771/30300 (epoch 26.025), train_loss = 1.07552143, grad/param norm = 1.6570e-01, time/batch = 19.0392s	
15772/30300 (epoch 26.026), train_loss = 1.20286702, grad/param norm = 1.7479e-01, time/batch = 17.4835s	
15773/30300 (epoch 26.028), train_loss = 1.25097444, grad/param norm = 1.6651e-01, time/batch = 18.9698s	
15774/30300 (epoch 26.030), train_loss = 1.10161558, grad/param norm = 1.5457e-01, time/batch = 18.6402s	
15775/30300 (epoch 26.031), train_loss = 1.21510282, grad/param norm = 1.6523e-01, time/batch = 19.2951s	
15776/30300 (epoch 26.033), train_loss = 1.16087490, grad/param norm = 1.6667e-01, time/batch = 18.6216s	
15777/30300 (epoch 26.035), train_loss = 1.24911165, grad/param norm = 1.9138e-01, time/batch = 19.0465s	
15778/30300 (epoch 26.036), train_loss = 1.16972972, grad/param norm = 1.6527e-01, time/batch = 19.0227s	
15779/30300 (epoch 26.038), train_loss = 1.19895029, grad/param norm = 1.5649e-01, time/batch = 19.2978s	
15780/30300 (epoch 26.040), train_loss = 0.91668407, grad/param norm = 1.3919e-01, time/batch = 19.0500s	
15781/30300 (epoch 26.041), train_loss = 0.96330380, grad/param norm = 1.3955e-01, time/batch = 17.5978s	
15782/30300 (epoch 26.043), train_loss = 1.16679479, grad/param norm = 1.7254e-01, time/batch = 19.4584s	
15783/30300 (epoch 26.045), train_loss = 1.14165743, grad/param norm = 1.5019e-01, time/batch = 19.3866s	
15784/30300 (epoch 26.046), train_loss = 1.31306812, grad/param norm = 1.8519e-01, time/batch = 17.8623s	
15785/30300 (epoch 26.048), train_loss = 1.13835588, grad/param norm = 1.9204e-01, time/batch = 18.9678s	
15786/30300 (epoch 26.050), train_loss = 1.11202284, grad/param norm = 1.6068e-01, time/batch = 19.0470s	
15787/30300 (epoch 26.051), train_loss = 1.18310615, grad/param norm = 1.6648e-01, time/batch = 18.6168s	
15788/30300 (epoch 26.053), train_loss = 0.98678659, grad/param norm = 1.7450e-01, time/batch = 16.6163s	
15789/30300 (epoch 26.054), train_loss = 1.16456408, grad/param norm = 1.6025e-01, time/batch = 19.8854s	
15790/30300 (epoch 26.056), train_loss = 1.08075082, grad/param norm = 1.5103e-01, time/batch = 18.0426s	
15791/30300 (epoch 26.058), train_loss = 1.13300249, grad/param norm = 1.6961e-01, time/batch = 17.9684s	
15792/30300 (epoch 26.059), train_loss = 1.07146261, grad/param norm = 1.5798e-01, time/batch = 19.0447s	
15793/30300 (epoch 26.061), train_loss = 1.20781712, grad/param norm = 1.6373e-01, time/batch = 19.4522s	
15794/30300 (epoch 26.063), train_loss = 1.04657979, grad/param norm = 1.6465e-01, time/batch = 18.3692s	
15795/30300 (epoch 26.064), train_loss = 1.15377150, grad/param norm = 1.6515e-01, time/batch = 19.1288s	
15796/30300 (epoch 26.066), train_loss = 1.14807642, grad/param norm = 1.4686e-01, time/batch = 17.8506s	
15797/30300 (epoch 26.068), train_loss = 1.04726603, grad/param norm = 1.5705e-01, time/batch = 17.7850s	
15798/30300 (epoch 26.069), train_loss = 1.21571248, grad/param norm = 1.6065e-01, time/batch = 19.1269s	
15799/30300 (epoch 26.071), train_loss = 1.19930462, grad/param norm = 1.5784e-01, time/batch = 17.8858s	
15800/30300 (epoch 26.073), train_loss = 1.11305792, grad/param norm = 1.7726e-01, time/batch = 17.9630s	
15801/30300 (epoch 26.074), train_loss = 1.16730675, grad/param norm = 1.5957e-01, time/batch = 19.1338s	
15802/30300 (epoch 26.076), train_loss = 1.11911106, grad/param norm = 1.4862e-01, time/batch = 19.3910s	
15803/30300 (epoch 26.078), train_loss = 1.07537083, grad/param norm = 1.4770e-01, time/batch = 18.6326s	
15804/30300 (epoch 26.079), train_loss = 1.08771410, grad/param norm = 1.5466e-01, time/batch = 16.7941s	
15805/30300 (epoch 26.081), train_loss = 1.14916257, grad/param norm = 1.6164e-01, time/batch = 20.2214s	
15806/30300 (epoch 26.083), train_loss = 1.21486588, grad/param norm = 1.6775e-01, time/batch = 18.5499s	
15807/30300 (epoch 26.084), train_loss = 1.04979727, grad/param norm = 1.5392e-01, time/batch = 18.2980s	
15808/30300 (epoch 26.086), train_loss = 1.09164009, grad/param norm = 1.7492e-01, time/batch = 19.2198s	
15809/30300 (epoch 26.087), train_loss = 1.06161631, grad/param norm = 1.3957e-01, time/batch = 19.1377s	
15810/30300 (epoch 26.089), train_loss = 1.11723034, grad/param norm = 1.6826e-01, time/batch = 17.7901s	
15811/30300 (epoch 26.091), train_loss = 1.18591671, grad/param norm = 1.5054e-01, time/batch = 18.5350s	
15812/30300 (epoch 26.092), train_loss = 1.19821122, grad/param norm = 1.5791e-01, time/batch = 19.7193s	
15813/30300 (epoch 26.094), train_loss = 1.31325822, grad/param norm = 1.8156e-01, time/batch = 16.2233s	
15814/30300 (epoch 26.096), train_loss = 1.23772120, grad/param norm = 1.6145e-01, time/batch = 18.2829s	
15815/30300 (epoch 26.097), train_loss = 1.09525421, grad/param norm = 1.5442e-01, time/batch = 18.9666s	
15816/30300 (epoch 26.099), train_loss = 1.25459034, grad/param norm = 1.6863e-01, time/batch = 17.8802s	
15817/30300 (epoch 26.101), train_loss = 1.29767268, grad/param norm = 2.4183e-01, time/batch = 18.2096s	
15818/30300 (epoch 26.102), train_loss = 1.09782639, grad/param norm = 2.1093e-01, time/batch = 19.6153s	
15819/30300 (epoch 26.104), train_loss = 1.14727569, grad/param norm = 1.9427e-01, time/batch = 19.2059s	
15820/30300 (epoch 26.106), train_loss = 1.14328353, grad/param norm = 1.9802e-01, time/batch = 18.3774s	
15821/30300 (epoch 26.107), train_loss = 1.17786671, grad/param norm = 1.5924e-01, time/batch = 18.8862s	
15822/30300 (epoch 26.109), train_loss = 1.22717149, grad/param norm = 1.9983e-01, time/batch = 17.3015s	
15823/30300 (epoch 26.111), train_loss = 1.26662220, grad/param norm = 1.7273e-01, time/batch = 17.8772s	
15824/30300 (epoch 26.112), train_loss = 1.27776078, grad/param norm = 1.8202e-01, time/batch = 18.5569s	
15825/30300 (epoch 26.114), train_loss = 1.11476410, grad/param norm = 1.4795e-01, time/batch = 19.6432s	
15826/30300 (epoch 26.116), train_loss = 1.16511917, grad/param norm = 1.7040e-01, time/batch = 16.8615s	
15827/30300 (epoch 26.117), train_loss = 1.21469448, grad/param norm = 1.4852e-01, time/batch = 19.5385s	
15828/30300 (epoch 26.119), train_loss = 1.10298508, grad/param norm = 1.8760e-01, time/batch = 19.0518s	
15829/30300 (epoch 26.120), train_loss = 1.15893811, grad/param norm = 1.7751e-01, time/batch = 17.6262s	
15830/30300 (epoch 26.122), train_loss = 1.23663708, grad/param norm = 1.8623e-01, time/batch = 18.8035s	
15831/30300 (epoch 26.124), train_loss = 1.30829985, grad/param norm = 1.8240e-01, time/batch = 19.1328s	
15832/30300 (epoch 26.125), train_loss = 1.03093825, grad/param norm = 1.6794e-01, time/batch = 18.6920s	
15833/30300 (epoch 26.127), train_loss = 1.20406143, grad/param norm = 1.9386e-01, time/batch = 19.2066s	
15834/30300 (epoch 26.129), train_loss = 1.29230785, grad/param norm = 1.6481e-01, time/batch = 19.0435s	
15835/30300 (epoch 26.130), train_loss = 1.27557487, grad/param norm = 1.6012e-01, time/batch = 18.6899s	
15836/30300 (epoch 26.132), train_loss = 1.29880206, grad/param norm = 1.8659e-01, time/batch = 18.7092s	
15837/30300 (epoch 26.134), train_loss = 1.06483174, grad/param norm = 1.5603e-01, time/batch = 17.2862s	
15838/30300 (epoch 26.135), train_loss = 1.09016516, grad/param norm = 1.6383e-01, time/batch = 19.4629s	
15839/30300 (epoch 26.137), train_loss = 1.15569106, grad/param norm = 1.5042e-01, time/batch = 17.7889s	
15840/30300 (epoch 26.139), train_loss = 1.13127437, grad/param norm = 1.9125e-01, time/batch = 19.3004s	
15841/30300 (epoch 26.140), train_loss = 1.18090909, grad/param norm = 1.9681e-01, time/batch = 19.5457s	
15842/30300 (epoch 26.142), train_loss = 1.30527141, grad/param norm = 2.1570e-01, time/batch = 17.7237s	
15843/30300 (epoch 26.144), train_loss = 1.14386711, grad/param norm = 1.9668e-01, time/batch = 19.8042s	
15844/30300 (epoch 26.145), train_loss = 1.26459215, grad/param norm = 1.8938e-01, time/batch = 19.2961s	
15845/30300 (epoch 26.147), train_loss = 1.11827846, grad/param norm = 1.6228e-01, time/batch = 17.1835s	
15846/30300 (epoch 26.149), train_loss = 1.31780354, grad/param norm = 2.0388e-01, time/batch = 19.3749s	
15847/30300 (epoch 26.150), train_loss = 1.14220673, grad/param norm = 1.7579e-01, time/batch = 19.6445s	
15848/30300 (epoch 26.152), train_loss = 1.04707338, grad/param norm = 1.8082e-01, time/batch = 18.4733s	
15849/30300 (epoch 26.153), train_loss = 1.15812526, grad/param norm = 1.6492e-01, time/batch = 18.8752s	
15850/30300 (epoch 26.155), train_loss = 1.01621539, grad/param norm = 1.4831e-01, time/batch = 17.0267s	
15851/30300 (epoch 26.157), train_loss = 1.13979738, grad/param norm = 1.7637e-01, time/batch = 18.0410s	
15852/30300 (epoch 26.158), train_loss = 1.18997924, grad/param norm = 2.0423e-01, time/batch = 18.5451s	
15853/30300 (epoch 26.160), train_loss = 1.08163882, grad/param norm = 1.7352e-01, time/batch = 16.7101s	
15854/30300 (epoch 26.162), train_loss = 1.14654437, grad/param norm = 1.6005e-01, time/batch = 17.3890s	
15855/30300 (epoch 26.163), train_loss = 1.12894870, grad/param norm = 1.6399e-01, time/batch = 17.2136s	
15856/30300 (epoch 26.165), train_loss = 1.26968855, grad/param norm = 1.5769e-01, time/batch = 17.1142s	
15857/30300 (epoch 26.167), train_loss = 1.14547402, grad/param norm = 1.7150e-01, time/batch = 17.9447s	
15858/30300 (epoch 26.168), train_loss = 1.21455861, grad/param norm = 1.7437e-01, time/batch = 17.4657s	
15859/30300 (epoch 26.170), train_loss = 1.17152620, grad/param norm = 1.8206e-01, time/batch = 16.7671s	
15860/30300 (epoch 26.172), train_loss = 1.14156321, grad/param norm = 1.6803e-01, time/batch = 18.1479s	
15861/30300 (epoch 26.173), train_loss = 1.13793550, grad/param norm = 1.7143e-01, time/batch = 18.8955s	
15862/30300 (epoch 26.175), train_loss = 1.16437597, grad/param norm = 1.5756e-01, time/batch = 17.7708s	
15863/30300 (epoch 26.177), train_loss = 1.19236169, grad/param norm = 1.6737e-01, time/batch = 19.3008s	
15864/30300 (epoch 26.178), train_loss = 0.93866728, grad/param norm = 1.4945e-01, time/batch = 18.3843s	
15865/30300 (epoch 26.180), train_loss = 1.14433660, grad/param norm = 1.4876e-01, time/batch = 17.6095s	
15866/30300 (epoch 26.182), train_loss = 1.16780131, grad/param norm = 1.8380e-01, time/batch = 19.2921s	
15867/30300 (epoch 26.183), train_loss = 1.10652238, grad/param norm = 1.6941e-01, time/batch = 19.2155s	
15868/30300 (epoch 26.185), train_loss = 1.33058177, grad/param norm = 1.8324e-01, time/batch = 17.2037s	
15869/30300 (epoch 26.186), train_loss = 1.36887090, grad/param norm = 2.1607e-01, time/batch = 18.2149s	
15870/30300 (epoch 26.188), train_loss = 1.19613120, grad/param norm = 1.7653e-01, time/batch = 18.9570s	
15871/30300 (epoch 26.190), train_loss = 1.16953523, grad/param norm = 1.5290e-01, time/batch = 18.2083s	
15872/30300 (epoch 26.191), train_loss = 1.22686965, grad/param norm = 1.7448e-01, time/batch = 18.5425s	
15873/30300 (epoch 26.193), train_loss = 1.07003202, grad/param norm = 1.3846e-01, time/batch = 18.2831s	
15874/30300 (epoch 26.195), train_loss = 1.14654709, grad/param norm = 1.6029e-01, time/batch = 18.8666s	
15875/30300 (epoch 26.196), train_loss = 1.19066982, grad/param norm = 1.4324e-01, time/batch = 17.9449s	
15876/30300 (epoch 26.198), train_loss = 1.00052667, grad/param norm = 1.6792e-01, time/batch = 19.6084s	
15877/30300 (epoch 26.200), train_loss = 1.15236748, grad/param norm = 1.4909e-01, time/batch = 19.2164s	
15878/30300 (epoch 26.201), train_loss = 1.21496650, grad/param norm = 1.8353e-01, time/batch = 17.6319s	
15879/30300 (epoch 26.203), train_loss = 1.16153699, grad/param norm = 1.6075e-01, time/batch = 19.4574s	
15880/30300 (epoch 26.205), train_loss = 1.36762911, grad/param norm = 1.8316e-01, time/batch = 19.3706s	
15881/30300 (epoch 26.206), train_loss = 1.27386867, grad/param norm = 1.8351e-01, time/batch = 16.6943s	
15882/30300 (epoch 26.208), train_loss = 1.26207370, grad/param norm = 2.3104e-01, time/batch = 17.8596s	
15883/30300 (epoch 26.210), train_loss = 1.21075449, grad/param norm = 1.5768e-01, time/batch = 18.0547s	
15884/30300 (epoch 26.211), train_loss = 1.27292619, grad/param norm = 1.6691e-01, time/batch = 15.6122s	
15885/30300 (epoch 26.213), train_loss = 1.12382940, grad/param norm = 1.4319e-01, time/batch = 15.7543s	
15886/30300 (epoch 26.215), train_loss = 1.07114169, grad/param norm = 1.6000e-01, time/batch = 18.1176s	
15887/30300 (epoch 26.216), train_loss = 1.11767841, grad/param norm = 1.9808e-01, time/batch = 17.3648s	
15888/30300 (epoch 26.218), train_loss = 1.05168999, grad/param norm = 1.3625e-01, time/batch = 18.2807s	
15889/30300 (epoch 26.219), train_loss = 1.00231241, grad/param norm = 1.4988e-01, time/batch = 18.9590s	
15890/30300 (epoch 26.221), train_loss = 1.01303235, grad/param norm = 1.6417e-01, time/batch = 18.7975s	
15891/30300 (epoch 26.223), train_loss = 1.17076463, grad/param norm = 1.6021e-01, time/batch = 17.7183s	
15892/30300 (epoch 26.224), train_loss = 1.00012916, grad/param norm = 1.7224e-01, time/batch = 18.8060s	
15893/30300 (epoch 26.226), train_loss = 1.24961110, grad/param norm = 2.0500e-01, time/batch = 17.7942s	
15894/30300 (epoch 26.228), train_loss = 1.25355520, grad/param norm = 1.7041e-01, time/batch = 18.7172s	
15895/30300 (epoch 26.229), train_loss = 1.13558727, grad/param norm = 1.6206e-01, time/batch = 18.1246s	
15896/30300 (epoch 26.231), train_loss = 1.18735038, grad/param norm = 1.6648e-01, time/batch = 19.3807s	
15897/30300 (epoch 26.233), train_loss = 1.17947802, grad/param norm = 1.4319e-01, time/batch = 18.1983s	
15898/30300 (epoch 26.234), train_loss = 1.23018899, grad/param norm = 1.8466e-01, time/batch = 16.2723s	
15899/30300 (epoch 26.236), train_loss = 1.17864642, grad/param norm = 1.4296e-01, time/batch = 15.3581s	
15900/30300 (epoch 26.238), train_loss = 1.19886976, grad/param norm = 1.8084e-01, time/batch = 16.9325s	
15901/30300 (epoch 26.239), train_loss = 1.18883520, grad/param norm = 1.6855e-01, time/batch = 18.1242s	
15902/30300 (epoch 26.241), train_loss = 1.21415046, grad/param norm = 1.8661e-01, time/batch = 19.3753s	
15903/30300 (epoch 26.243), train_loss = 1.22407288, grad/param norm = 1.7076e-01, time/batch = 20.0343s	
15904/30300 (epoch 26.244), train_loss = 1.37885977, grad/param norm = 1.6998e-01, time/batch = 18.2953s	
15905/30300 (epoch 26.246), train_loss = 1.19506336, grad/param norm = 1.6995e-01, time/batch = 18.7722s	
15906/30300 (epoch 26.248), train_loss = 1.13308206, grad/param norm = 1.5296e-01, time/batch = 19.2001s	
15907/30300 (epoch 26.249), train_loss = 1.09467711, grad/param norm = 1.5546e-01, time/batch = 17.3656s	
15908/30300 (epoch 26.251), train_loss = 1.09182959, grad/param norm = 1.7055e-01, time/batch = 17.9307s	
15909/30300 (epoch 26.252), train_loss = 1.26037026, grad/param norm = 1.6598e-01, time/batch = 19.5412s	
15910/30300 (epoch 26.254), train_loss = 1.25743862, grad/param norm = 1.7176e-01, time/batch = 19.3630s	
15911/30300 (epoch 26.256), train_loss = 1.18331622, grad/param norm = 1.5165e-01, time/batch = 17.9558s	
15912/30300 (epoch 26.257), train_loss = 1.21984444, grad/param norm = 1.6314e-01, time/batch = 18.8841s	
15913/30300 (epoch 26.259), train_loss = 1.14202888, grad/param norm = 1.6441e-01, time/batch = 19.7089s	
15914/30300 (epoch 26.261), train_loss = 1.26509578, grad/param norm = 1.4886e-01, time/batch = 17.4408s	
15915/30300 (epoch 26.262), train_loss = 1.11951040, grad/param norm = 1.5632e-01, time/batch = 18.2840s	
15916/30300 (epoch 26.264), train_loss = 1.16264823, grad/param norm = 1.5246e-01, time/batch = 18.7726s	
15917/30300 (epoch 26.266), train_loss = 1.09202865, grad/param norm = 1.4187e-01, time/batch = 17.8741s	
15918/30300 (epoch 26.267), train_loss = 1.33076661, grad/param norm = 1.8244e-01, time/batch = 18.6210s	
15919/30300 (epoch 26.269), train_loss = 1.18413480, grad/param norm = 1.5562e-01, time/batch = 19.3892s	
15920/30300 (epoch 26.271), train_loss = 1.21347744, grad/param norm = 1.6102e-01, time/batch = 18.1320s	
15921/30300 (epoch 26.272), train_loss = 1.17963365, grad/param norm = 1.8370e-01, time/batch = 18.6064s	
15922/30300 (epoch 26.274), train_loss = 1.23563028, grad/param norm = 1.6032e-01, time/batch = 17.3018s	
15923/30300 (epoch 26.276), train_loss = 1.20211351, grad/param norm = 1.7084e-01, time/batch = 19.0387s	
15924/30300 (epoch 26.277), train_loss = 1.03235819, grad/param norm = 1.6163e-01, time/batch = 18.1254s	
15925/30300 (epoch 26.279), train_loss = 1.18230937, grad/param norm = 1.6150e-01, time/batch = 19.4626s	
15926/30300 (epoch 26.281), train_loss = 1.25764405, grad/param norm = 1.7241e-01, time/batch = 19.3137s	
15927/30300 (epoch 26.282), train_loss = 1.17158025, grad/param norm = 1.4611e-01, time/batch = 18.8758s	
15928/30300 (epoch 26.284), train_loss = 1.29702845, grad/param norm = 2.2551e-01, time/batch = 18.6310s	
15929/30300 (epoch 26.285), train_loss = 1.23719754, grad/param norm = 1.5885e-01, time/batch = 19.0327s	
15930/30300 (epoch 26.287), train_loss = 1.15268368, grad/param norm = 1.7978e-01, time/batch = 17.9631s	
15931/30300 (epoch 26.289), train_loss = 1.24922971, grad/param norm = 1.7147e-01, time/batch = 19.0528s	
15932/30300 (epoch 26.290), train_loss = 0.92638035, grad/param norm = 1.4576e-01, time/batch = 18.1023s	
15933/30300 (epoch 26.292), train_loss = 1.07765048, grad/param norm = 1.5795e-01, time/batch = 17.0437s	
15934/30300 (epoch 26.294), train_loss = 1.25364546, grad/param norm = 1.9073e-01, time/batch = 18.9705s	
15935/30300 (epoch 26.295), train_loss = 1.13264391, grad/param norm = 1.6484e-01, time/batch = 18.1261s	
15936/30300 (epoch 26.297), train_loss = 1.11425388, grad/param norm = 1.5153e-01, time/batch = 19.2940s	
15937/30300 (epoch 26.299), train_loss = 1.15397900, grad/param norm = 1.5961e-01, time/batch = 18.9545s	
15938/30300 (epoch 26.300), train_loss = 1.10984946, grad/param norm = 1.6153e-01, time/batch = 18.7250s	
15939/30300 (epoch 26.302), train_loss = 1.18687412, grad/param norm = 1.5834e-01, time/batch = 19.2948s	
15940/30300 (epoch 26.304), train_loss = 1.07558334, grad/param norm = 1.5323e-01, time/batch = 18.8567s	
15941/30300 (epoch 26.305), train_loss = 1.11686083, grad/param norm = 1.4130e-01, time/batch = 17.6895s	
15942/30300 (epoch 26.307), train_loss = 1.22045550, grad/param norm = 1.3706e-01, time/batch = 18.7134s	
15943/30300 (epoch 26.309), train_loss = 1.21027432, grad/param norm = 1.5945e-01, time/batch = 18.7876s	
15944/30300 (epoch 26.310), train_loss = 1.15782486, grad/param norm = 1.4839e-01, time/batch = 17.8754s	
15945/30300 (epoch 26.312), train_loss = 1.29606375, grad/param norm = 1.5683e-01, time/batch = 19.4749s	
15946/30300 (epoch 26.314), train_loss = 1.16798651, grad/param norm = 1.6564e-01, time/batch = 27.8438s	
15947/30300 (epoch 26.315), train_loss = 1.15135629, grad/param norm = 1.6375e-01, time/batch = 22.8994s	
15948/30300 (epoch 26.317), train_loss = 1.21558460, grad/param norm = 1.6174e-01, time/batch = 18.2119s	
15949/30300 (epoch 26.318), train_loss = 1.25402085, grad/param norm = 1.6600e-01, time/batch = 18.3752s	
15950/30300 (epoch 26.320), train_loss = 1.23625333, grad/param norm = 1.6165e-01, time/batch = 18.7161s	
15951/30300 (epoch 26.322), train_loss = 1.09101784, grad/param norm = 1.4590e-01, time/batch = 16.6212s	
15952/30300 (epoch 26.323), train_loss = 1.27497738, grad/param norm = 1.7411e-01, time/batch = 17.4645s	
15953/30300 (epoch 26.325), train_loss = 1.16086891, grad/param norm = 1.5813e-01, time/batch = 18.9702s	
15954/30300 (epoch 26.327), train_loss = 1.16664201, grad/param norm = 1.5126e-01, time/batch = 19.7088s	
15955/30300 (epoch 26.328), train_loss = 1.16865578, grad/param norm = 1.4568e-01, time/batch = 17.8729s	
15956/30300 (epoch 26.330), train_loss = 1.21562625, grad/param norm = 1.6561e-01, time/batch = 19.2145s	
15957/30300 (epoch 26.332), train_loss = 1.25225668, grad/param norm = 2.0078e-01, time/batch = 18.3880s	
15958/30300 (epoch 26.333), train_loss = 1.13002653, grad/param norm = 1.6545e-01, time/batch = 15.2094s	
15959/30300 (epoch 26.335), train_loss = 1.04968524, grad/param norm = 1.5800e-01, time/batch = 17.8659s	
15960/30300 (epoch 26.337), train_loss = 1.30068296, grad/param norm = 1.4997e-01, time/batch = 18.1247s	
15961/30300 (epoch 26.338), train_loss = 1.09868107, grad/param norm = 1.4642e-01, time/batch = 20.2959s	
15962/30300 (epoch 26.340), train_loss = 1.08218533, grad/param norm = 1.5242e-01, time/batch = 18.2792s	
15963/30300 (epoch 26.342), train_loss = 1.24739664, grad/param norm = 1.5413e-01, time/batch = 18.9565s	
15964/30300 (epoch 26.343), train_loss = 1.18386858, grad/param norm = 1.4992e-01, time/batch = 18.9655s	
15965/30300 (epoch 26.345), train_loss = 1.21323290, grad/param norm = 1.5571e-01, time/batch = 17.7851s	
15966/30300 (epoch 26.347), train_loss = 1.03662216, grad/param norm = 1.5143e-01, time/batch = 19.3056s	
15967/30300 (epoch 26.348), train_loss = 1.07752882, grad/param norm = 1.6180e-01, time/batch = 19.0492s	
15968/30300 (epoch 26.350), train_loss = 1.14731118, grad/param norm = 1.8229e-01, time/batch = 16.7809s	
15969/30300 (epoch 26.351), train_loss = 1.16725106, grad/param norm = 1.6212e-01, time/batch = 18.8801s	
15970/30300 (epoch 26.353), train_loss = 1.02926632, grad/param norm = 1.5436e-01, time/batch = 19.3699s	
15971/30300 (epoch 26.355), train_loss = 1.12421404, grad/param norm = 1.4690e-01, time/batch = 18.2891s	
15972/30300 (epoch 26.356), train_loss = 1.23411655, grad/param norm = 2.0732e-01, time/batch = 18.9503s	
15973/30300 (epoch 26.358), train_loss = 1.38296897, grad/param norm = 1.7572e-01, time/batch = 19.8021s	
15974/30300 (epoch 26.360), train_loss = 1.12419670, grad/param norm = 1.5770e-01, time/batch = 18.2143s	
15975/30300 (epoch 26.361), train_loss = 1.18084188, grad/param norm = 1.4953e-01, time/batch = 18.6274s	
15976/30300 (epoch 26.363), train_loss = 1.22258507, grad/param norm = 1.5807e-01, time/batch = 17.9632s	
15977/30300 (epoch 26.365), train_loss = 1.06598508, grad/param norm = 1.8769e-01, time/batch = 18.7164s	
15978/30300 (epoch 26.366), train_loss = 1.12501251, grad/param norm = 1.4979e-01, time/batch = 17.8733s	
15979/30300 (epoch 26.368), train_loss = 0.99693950, grad/param norm = 1.4410e-01, time/batch = 17.7821s	
15980/30300 (epoch 26.370), train_loss = 1.08252005, grad/param norm = 1.7725e-01, time/batch = 19.6253s	
15981/30300 (epoch 26.371), train_loss = 1.23958081, grad/param norm = 1.5821e-01, time/batch = 17.6419s	
15982/30300 (epoch 26.373), train_loss = 1.06919357, grad/param norm = 1.2998e-01, time/batch = 19.3892s	
15983/30300 (epoch 26.375), train_loss = 1.07768406, grad/param norm = 1.3733e-01, time/batch = 18.7003s	
15984/30300 (epoch 26.376), train_loss = 1.06727591, grad/param norm = 1.3868e-01, time/batch = 17.2782s	
15985/30300 (epoch 26.378), train_loss = 1.06315507, grad/param norm = 1.7106e-01, time/batch = 18.4657s	
15986/30300 (epoch 26.380), train_loss = 1.31517349, grad/param norm = 1.6870e-01, time/batch = 18.5422s	
15987/30300 (epoch 26.381), train_loss = 1.00838982, grad/param norm = 1.4504e-01, time/batch = 19.1239s	
15988/30300 (epoch 26.383), train_loss = 1.08744014, grad/param norm = 1.9812e-01, time/batch = 18.9672s	
15989/30300 (epoch 26.384), train_loss = 1.22562757, grad/param norm = 1.7292e-01, time/batch = 19.2144s	
15990/30300 (epoch 26.386), train_loss = 1.04207719, grad/param norm = 1.4240e-01, time/batch = 19.2960s	
15991/30300 (epoch 26.388), train_loss = 1.00515960, grad/param norm = 1.3969e-01, time/batch = 17.9745s	
15992/30300 (epoch 26.389), train_loss = 1.12229033, grad/param norm = 1.6796e-01, time/batch = 17.2968s	
15993/30300 (epoch 26.391), train_loss = 1.19509968, grad/param norm = 1.5304e-01, time/batch = 19.4505s	
15994/30300 (epoch 26.393), train_loss = 1.01136221, grad/param norm = 1.5173e-01, time/batch = 17.3875s	
15995/30300 (epoch 26.394), train_loss = 1.21177568, grad/param norm = 1.5309e-01, time/batch = 19.5400s	
15996/30300 (epoch 26.396), train_loss = 1.27361967, grad/param norm = 1.4413e-01, time/batch = 19.0428s	
15997/30300 (epoch 26.398), train_loss = 1.12023700, grad/param norm = 1.5422e-01, time/batch = 17.7176s	
15998/30300 (epoch 26.399), train_loss = 1.11353755, grad/param norm = 1.4800e-01, time/batch = 17.2153s	
15999/30300 (epoch 26.401), train_loss = 1.16846042, grad/param norm = 1.5412e-01, time/batch = 18.7318s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch26.40_1.8687.t7	
16000/30300 (epoch 26.403), train_loss = 1.13617535, grad/param norm = 1.6025e-01, time/batch = 18.7179s	
16001/30300 (epoch 26.404), train_loss = 1.61817126, grad/param norm = 2.5321e-01, time/batch = 18.6992s	
16002/30300 (epoch 26.406), train_loss = 1.22809922, grad/param norm = 1.5482e-01, time/batch = 18.9609s	
16003/30300 (epoch 26.408), train_loss = 1.03129236, grad/param norm = 1.4876e-01, time/batch = 17.0339s	
16004/30300 (epoch 26.409), train_loss = 1.01422002, grad/param norm = 1.4804e-01, time/batch = 19.4585s	
16005/30300 (epoch 26.411), train_loss = 1.06179258, grad/param norm = 1.4253e-01, time/batch = 18.2146s	
16006/30300 (epoch 26.413), train_loss = 0.95934476, grad/param norm = 1.5835e-01, time/batch = 18.6114s	
16007/30300 (epoch 26.414), train_loss = 1.22250045, grad/param norm = 1.6104e-01, time/batch = 18.3683s	
16008/30300 (epoch 26.416), train_loss = 1.09285486, grad/param norm = 1.5376e-01, time/batch = 19.2223s	
16009/30300 (epoch 26.417), train_loss = 1.05699543, grad/param norm = 1.5122e-01, time/batch = 18.7196s	
16010/30300 (epoch 26.419), train_loss = 1.02957828, grad/param norm = 1.4247e-01, time/batch = 18.7799s	
16011/30300 (epoch 26.421), train_loss = 1.08789915, grad/param norm = 1.7213e-01, time/batch = 18.9753s	
16012/30300 (epoch 26.422), train_loss = 1.16206741, grad/param norm = 1.8228e-01, time/batch = 18.8044s	
16013/30300 (epoch 26.424), train_loss = 1.14509472, grad/param norm = 1.5390e-01, time/batch = 17.1900s	
16014/30300 (epoch 26.426), train_loss = 1.09298088, grad/param norm = 1.7310e-01, time/batch = 18.9498s	
16015/30300 (epoch 26.427), train_loss = 1.10777163, grad/param norm = 1.6020e-01, time/batch = 18.8833s	
16016/30300 (epoch 26.429), train_loss = 1.13705196, grad/param norm = 1.4754e-01, time/batch = 18.2205s	
16017/30300 (epoch 26.431), train_loss = 1.20376066, grad/param norm = 1.5481e-01, time/batch = 19.1197s	
16018/30300 (epoch 26.432), train_loss = 1.12439364, grad/param norm = 1.4826e-01, time/batch = 19.2000s	
16019/30300 (epoch 26.434), train_loss = 1.02418758, grad/param norm = 1.4951e-01, time/batch = 17.2037s	
16020/30300 (epoch 26.436), train_loss = 1.29438595, grad/param norm = 1.6371e-01, time/batch = 19.1275s	
16021/30300 (epoch 26.437), train_loss = 1.04145399, grad/param norm = 1.5588e-01, time/batch = 18.7264s	
16022/30300 (epoch 26.439), train_loss = 1.07090176, grad/param norm = 1.3367e-01, time/batch = 18.2920s	
16023/30300 (epoch 26.441), train_loss = 1.12304350, grad/param norm = 2.1406e-01, time/batch = 19.3622s	
16024/30300 (epoch 26.442), train_loss = 1.05514306, grad/param norm = 1.5252e-01, time/batch = 17.2998s	
16025/30300 (epoch 26.444), train_loss = 0.96381116, grad/param norm = 1.5395e-01, time/batch = 19.1251s	
16026/30300 (epoch 26.446), train_loss = 1.11259616, grad/param norm = 1.4640e-01, time/batch = 16.8768s	
16027/30300 (epoch 26.447), train_loss = 1.14464860, grad/param norm = 1.5961e-01, time/batch = 18.9598s	
16028/30300 (epoch 26.449), train_loss = 1.04833534, grad/param norm = 1.4372e-01, time/batch = 18.0385s	
16029/30300 (epoch 26.450), train_loss = 1.19210673, grad/param norm = 1.5795e-01, time/batch = 18.2059s	
16030/30300 (epoch 26.452), train_loss = 1.24006350, grad/param norm = 1.5715e-01, time/batch = 20.0388s	
16031/30300 (epoch 26.454), train_loss = 1.20283548, grad/param norm = 1.4552e-01, time/batch = 19.4597s	
16032/30300 (epoch 26.455), train_loss = 1.14944319, grad/param norm = 1.6245e-01, time/batch = 17.5394s	
16033/30300 (epoch 26.457), train_loss = 1.12614907, grad/param norm = 1.6617e-01, time/batch = 19.9663s	
16034/30300 (epoch 26.459), train_loss = 1.19886583, grad/param norm = 1.8014e-01, time/batch = 18.2216s	
16035/30300 (epoch 26.460), train_loss = 1.16872680, grad/param norm = 1.5083e-01, time/batch = 17.8662s	
16036/30300 (epoch 26.462), train_loss = 1.20410890, grad/param norm = 1.5771e-01, time/batch = 18.2947s	
16037/30300 (epoch 26.464), train_loss = 0.97190053, grad/param norm = 1.8390e-01, time/batch = 18.7102s	
16038/30300 (epoch 26.465), train_loss = 0.97028173, grad/param norm = 1.4518e-01, time/batch = 18.7132s	
16039/30300 (epoch 26.467), train_loss = 0.94676704, grad/param norm = 1.3617e-01, time/batch = 17.8181s	
16040/30300 (epoch 26.469), train_loss = 1.06339549, grad/param norm = 1.5555e-01, time/batch = 16.8917s	
16041/30300 (epoch 26.470), train_loss = 1.08796370, grad/param norm = 1.5369e-01, time/batch = 19.2148s	
16042/30300 (epoch 26.472), train_loss = 1.08277900, grad/param norm = 1.3361e-01, time/batch = 17.1196s	
16043/30300 (epoch 26.474), train_loss = 1.09870698, grad/param norm = 2.1856e-01, time/batch = 18.7196s	
16044/30300 (epoch 26.475), train_loss = 1.08479789, grad/param norm = 1.4552e-01, time/batch = 19.3625s	
16045/30300 (epoch 26.477), train_loss = 1.12752374, grad/param norm = 1.5990e-01, time/batch = 18.2101s	
16046/30300 (epoch 26.479), train_loss = 1.10934945, grad/param norm = 1.6365e-01, time/batch = 19.2118s	
16047/30300 (epoch 26.480), train_loss = 1.14860588, grad/param norm = 1.4869e-01, time/batch = 19.1297s	
16048/30300 (epoch 26.482), train_loss = 1.17682194, grad/param norm = 1.3886e-01, time/batch = 18.7781s	
16049/30300 (epoch 26.483), train_loss = 1.09898286, grad/param norm = 1.5139e-01, time/batch = 19.6125s	
16050/30300 (epoch 26.485), train_loss = 1.13768464, grad/param norm = 1.5437e-01, time/batch = 17.3867s	
16051/30300 (epoch 26.487), train_loss = 1.23213502, grad/param norm = 1.6286e-01, time/batch = 18.7045s	
16052/30300 (epoch 26.488), train_loss = 1.22503143, grad/param norm = 1.3839e-01, time/batch = 19.2917s	
16053/30300 (epoch 26.490), train_loss = 1.01829347, grad/param norm = 1.5046e-01, time/batch = 18.6317s	
16054/30300 (epoch 26.492), train_loss = 1.11413667, grad/param norm = 1.6033e-01, time/batch = 18.2955s	
16055/30300 (epoch 26.493), train_loss = 1.10672010, grad/param norm = 1.5087e-01, time/batch = 17.2204s	
16056/30300 (epoch 26.495), train_loss = 1.08922042, grad/param norm = 1.4067e-01, time/batch = 19.6124s	
16057/30300 (epoch 26.497), train_loss = 1.13533209, grad/param norm = 1.4480e-01, time/batch = 19.5439s	
16058/30300 (epoch 26.498), train_loss = 1.19051843, grad/param norm = 1.6304e-01, time/batch = 17.4363s	
16059/30300 (epoch 26.500), train_loss = 1.12847354, grad/param norm = 1.6675e-01, time/batch = 18.4591s	
16060/30300 (epoch 26.502), train_loss = 1.13684729, grad/param norm = 1.7023e-01, time/batch = 19.1902s	
16061/30300 (epoch 26.503), train_loss = 1.23565945, grad/param norm = 1.5666e-01, time/batch = 15.9669s	
16062/30300 (epoch 26.505), train_loss = 1.06118480, grad/param norm = 1.4157e-01, time/batch = 19.2165s	
16063/30300 (epoch 26.507), train_loss = 1.06057535, grad/param norm = 1.6551e-01, time/batch = 19.5520s	
16064/30300 (epoch 26.508), train_loss = 1.09758917, grad/param norm = 1.7404e-01, time/batch = 17.9698s	
16065/30300 (epoch 26.510), train_loss = 1.22177947, grad/param norm = 1.6468e-01, time/batch = 19.2046s	
16066/30300 (epoch 26.512), train_loss = 1.07772192, grad/param norm = 1.4884e-01, time/batch = 18.7124s	
16067/30300 (epoch 26.513), train_loss = 1.14765089, grad/param norm = 1.4577e-01, time/batch = 18.2172s	
16068/30300 (epoch 26.515), train_loss = 1.12854914, grad/param norm = 1.5362e-01, time/batch = 17.8798s	
16069/30300 (epoch 26.517), train_loss = 0.94994271, grad/param norm = 1.2883e-01, time/batch = 18.5661s	
16070/30300 (epoch 26.518), train_loss = 1.21636291, grad/param norm = 1.6456e-01, time/batch = 19.5603s	
16071/30300 (epoch 26.520), train_loss = 1.18432986, grad/param norm = 1.6497e-01, time/batch = 18.3563s	
16072/30300 (epoch 26.521), train_loss = 1.06069995, grad/param norm = 1.8297e-01, time/batch = 19.1290s	
16073/30300 (epoch 26.523), train_loss = 1.30158191, grad/param norm = 1.9498e-01, time/batch = 18.1230s	
16074/30300 (epoch 26.525), train_loss = 1.06635081, grad/param norm = 1.5526e-01, time/batch = 16.1786s	
16075/30300 (epoch 26.526), train_loss = 1.13456789, grad/param norm = 1.9276e-01, time/batch = 19.1798s	
16076/30300 (epoch 26.528), train_loss = 1.02180513, grad/param norm = 1.5532e-01, time/batch = 18.3083s	
16077/30300 (epoch 26.530), train_loss = 1.00989173, grad/param norm = 1.5528e-01, time/batch = 18.7119s	
16078/30300 (epoch 26.531), train_loss = 1.17300306, grad/param norm = 1.5511e-01, time/batch = 18.9637s	
16079/30300 (epoch 26.533), train_loss = 1.13936005, grad/param norm = 1.6510e-01, time/batch = 19.1319s	
16080/30300 (epoch 26.535), train_loss = 1.07545871, grad/param norm = 1.3522e-01, time/batch = 18.7097s	
16081/30300 (epoch 26.536), train_loss = 1.16708593, grad/param norm = 1.6642e-01, time/batch = 18.8787s	
16082/30300 (epoch 26.538), train_loss = 1.03002874, grad/param norm = 1.7633e-01, time/batch = 19.7088s	
16083/30300 (epoch 26.540), train_loss = 1.04201633, grad/param norm = 1.5413e-01, time/batch = 18.1210s	
16084/30300 (epoch 26.541), train_loss = 1.13536542, grad/param norm = 1.6692e-01, time/batch = 18.6085s	
16085/30300 (epoch 26.543), train_loss = 1.10911789, grad/param norm = 1.5337e-01, time/batch = 17.4661s	
16086/30300 (epoch 26.545), train_loss = 1.14417930, grad/param norm = 1.9179e-01, time/batch = 19.8030s	
16087/30300 (epoch 26.546), train_loss = 1.34307918, grad/param norm = 1.5905e-01, time/batch = 17.2754s	
16088/30300 (epoch 26.548), train_loss = 1.08427564, grad/param norm = 1.3817e-01, time/batch = 19.0357s	
16089/30300 (epoch 26.550), train_loss = 1.17826745, grad/param norm = 1.6580e-01, time/batch = 18.8067s	
16090/30300 (epoch 26.551), train_loss = 1.07241696, grad/param norm = 1.5511e-01, time/batch = 17.5459s	
16091/30300 (epoch 26.553), train_loss = 1.08563407, grad/param norm = 1.4851e-01, time/batch = 18.9706s	
16092/30300 (epoch 26.554), train_loss = 1.12676835, grad/param norm = 1.5321e-01, time/batch = 18.6204s	
16093/30300 (epoch 26.556), train_loss = 1.18566218, grad/param norm = 1.5213e-01, time/batch = 18.5474s	
16094/30300 (epoch 26.558), train_loss = 1.21653695, grad/param norm = 1.7238e-01, time/batch = 19.0614s	
16095/30300 (epoch 26.559), train_loss = 1.17081212, grad/param norm = 1.7533e-01, time/batch = 16.5418s	
16096/30300 (epoch 26.561), train_loss = 0.94905347, grad/param norm = 1.3659e-01, time/batch = 18.3793s	
16097/30300 (epoch 26.563), train_loss = 1.01909481, grad/param norm = 1.4065e-01, time/batch = 17.9600s	
16098/30300 (epoch 26.564), train_loss = 1.06792271, grad/param norm = 1.5118e-01, time/batch = 19.4805s	
16099/30300 (epoch 26.566), train_loss = 1.13181690, grad/param norm = 1.4629e-01, time/batch = 18.4681s	
16100/30300 (epoch 26.568), train_loss = 0.96257142, grad/param norm = 1.7521e-01, time/batch = 17.5446s	
16101/30300 (epoch 26.569), train_loss = 1.13989779, grad/param norm = 1.5213e-01, time/batch = 18.8914s	
16102/30300 (epoch 26.571), train_loss = 1.15196024, grad/param norm = 1.6011e-01, time/batch = 18.1045s	
16103/30300 (epoch 26.573), train_loss = 1.16615865, grad/param norm = 1.5979e-01, time/batch = 18.5408s	
16104/30300 (epoch 26.574), train_loss = 1.17427181, grad/param norm = 1.4297e-01, time/batch = 18.7895s	
16105/30300 (epoch 26.576), train_loss = 1.10128412, grad/param norm = 1.4291e-01, time/batch = 18.4612s	
16106/30300 (epoch 26.578), train_loss = 1.00113264, grad/param norm = 1.5666e-01, time/batch = 17.5475s	
16107/30300 (epoch 26.579), train_loss = 1.14954523, grad/param norm = 1.6330e-01, time/batch = 18.2147s	
16108/30300 (epoch 26.581), train_loss = 1.24373725, grad/param norm = 1.6313e-01, time/batch = 18.4799s	
16109/30300 (epoch 26.583), train_loss = 1.29991537, grad/param norm = 1.9265e-01, time/batch = 18.5613s	
16110/30300 (epoch 26.584), train_loss = 1.22381972, grad/param norm = 1.5331e-01, time/batch = 18.7955s	
16111/30300 (epoch 26.586), train_loss = 1.09652898, grad/param norm = 1.7554e-01, time/batch = 19.2121s	
16112/30300 (epoch 26.587), train_loss = 1.11183495, grad/param norm = 1.5667e-01, time/batch = 18.8825s	
16113/30300 (epoch 26.589), train_loss = 1.04595706, grad/param norm = 1.5375e-01, time/batch = 18.4567s	
16114/30300 (epoch 26.591), train_loss = 1.16718579, grad/param norm = 1.4863e-01, time/batch = 18.4780s	
16115/30300 (epoch 26.592), train_loss = 1.10856110, grad/param norm = 1.3537e-01, time/batch = 18.5444s	
16116/30300 (epoch 26.594), train_loss = 1.14432486, grad/param norm = 1.5590e-01, time/batch = 17.7992s	
16117/30300 (epoch 26.596), train_loss = 1.03189997, grad/param norm = 1.3890e-01, time/batch = 18.8865s	
16118/30300 (epoch 26.597), train_loss = 1.06379881, grad/param norm = 1.6114e-01, time/batch = 18.7231s	
16119/30300 (epoch 26.599), train_loss = 0.94935490, grad/param norm = 1.3969e-01, time/batch = 18.5497s	
16120/30300 (epoch 26.601), train_loss = 1.13636002, grad/param norm = 1.5684e-01, time/batch = 19.4636s	
16121/30300 (epoch 26.602), train_loss = 1.11565097, grad/param norm = 1.4959e-01, time/batch = 17.6755s	
16122/30300 (epoch 26.604), train_loss = 1.04157358, grad/param norm = 1.3785e-01, time/batch = 18.2908s	
16123/30300 (epoch 26.606), train_loss = 1.08074487, grad/param norm = 2.3179e-01, time/batch = 18.4700s	
16124/30300 (epoch 26.607), train_loss = 1.22383116, grad/param norm = 2.0826e-01, time/batch = 18.8820s	
16125/30300 (epoch 26.609), train_loss = 1.33244814, grad/param norm = 1.7456e-01, time/batch = 17.4784s	
16126/30300 (epoch 26.611), train_loss = 1.06760533, grad/param norm = 1.4915e-01, time/batch = 18.0344s	
16127/30300 (epoch 26.612), train_loss = 1.02194394, grad/param norm = 1.3679e-01, time/batch = 19.7072s	
16128/30300 (epoch 26.614), train_loss = 1.10207740, grad/param norm = 1.4511e-01, time/batch = 18.7311s	
16129/30300 (epoch 26.616), train_loss = 1.17871732, grad/param norm = 1.8195e-01, time/batch = 18.0450s	
16130/30300 (epoch 26.617), train_loss = 1.16263711, grad/param norm = 1.5971e-01, time/batch = 19.7947s	
16131/30300 (epoch 26.619), train_loss = 0.95295560, grad/param norm = 1.4434e-01, time/batch = 18.4596s	
16132/30300 (epoch 26.620), train_loss = 1.14914140, grad/param norm = 1.5541e-01, time/batch = 29.2488s	
16133/30300 (epoch 26.622), train_loss = 1.12367171, grad/param norm = 1.7642e-01, time/batch = 21.3652s	
16134/30300 (epoch 26.624), train_loss = 1.07669789, grad/param norm = 1.4970e-01, time/batch = 18.1418s	
16135/30300 (epoch 26.625), train_loss = 1.07859735, grad/param norm = 1.5264e-01, time/batch = 18.1906s	
16136/30300 (epoch 26.627), train_loss = 1.25084229, grad/param norm = 1.6530e-01, time/batch = 17.1212s	
16137/30300 (epoch 26.629), train_loss = 1.25754530, grad/param norm = 1.5470e-01, time/batch = 18.8677s	
16138/30300 (epoch 26.630), train_loss = 1.12592626, grad/param norm = 1.5307e-01, time/batch = 17.1919s	
16139/30300 (epoch 26.632), train_loss = 1.20003525, grad/param norm = 1.6214e-01, time/batch = 16.6056s	
16140/30300 (epoch 26.634), train_loss = 1.07012944, grad/param norm = 1.8791e-01, time/batch = 18.1937s	
16141/30300 (epoch 26.635), train_loss = 1.19371556, grad/param norm = 1.8262e-01, time/batch = 18.1174s	
16142/30300 (epoch 26.637), train_loss = 1.21556535, grad/param norm = 1.7066e-01, time/batch = 16.5967s	
16143/30300 (epoch 26.639), train_loss = 1.09822511, grad/param norm = 1.5973e-01, time/batch = 18.7981s	
16144/30300 (epoch 26.640), train_loss = 1.26713880, grad/param norm = 1.8656e-01, time/batch = 18.6137s	
16145/30300 (epoch 26.642), train_loss = 1.10690586, grad/param norm = 1.4031e-01, time/batch = 18.2776s	
16146/30300 (epoch 26.644), train_loss = 1.19742074, grad/param norm = 1.6880e-01, time/batch = 19.1188s	
16147/30300 (epoch 26.645), train_loss = 1.07127944, grad/param norm = 1.5125e-01, time/batch = 18.5474s	
16148/30300 (epoch 26.647), train_loss = 1.15089755, grad/param norm = 1.5374e-01, time/batch = 17.6078s	
16149/30300 (epoch 26.649), train_loss = 1.10590332, grad/param norm = 1.4860e-01, time/batch = 19.3019s	
16150/30300 (epoch 26.650), train_loss = 1.12977662, grad/param norm = 1.4902e-01, time/batch = 19.4464s	
16151/30300 (epoch 26.652), train_loss = 1.09466015, grad/param norm = 1.7132e-01, time/batch = 17.2813s	
16152/30300 (epoch 26.653), train_loss = 1.31391077, grad/param norm = 1.5971e-01, time/batch = 18.5503s	
16153/30300 (epoch 26.655), train_loss = 1.06373541, grad/param norm = 1.4754e-01, time/batch = 18.3872s	
16154/30300 (epoch 26.657), train_loss = 1.05374462, grad/param norm = 1.5992e-01, time/batch = 18.1228s	
16155/30300 (epoch 26.658), train_loss = 1.05064067, grad/param norm = 1.4416e-01, time/batch = 18.5501s	
16156/30300 (epoch 26.660), train_loss = 1.13335653, grad/param norm = 1.5450e-01, time/batch = 18.9635s	
16157/30300 (epoch 26.662), train_loss = 1.15481933, grad/param norm = 1.9528e-01, time/batch = 17.7789s	
16158/30300 (epoch 26.663), train_loss = 1.16402006, grad/param norm = 1.6061e-01, time/batch = 17.0986s	
16159/30300 (epoch 26.665), train_loss = 1.08641149, grad/param norm = 1.9104e-01, time/batch = 18.7040s	
16160/30300 (epoch 26.667), train_loss = 1.22367397, grad/param norm = 1.8441e-01, time/batch = 18.7164s	
16161/30300 (epoch 26.668), train_loss = 1.22258056, grad/param norm = 1.6276e-01, time/batch = 17.9493s	
16162/30300 (epoch 26.670), train_loss = 1.26121903, grad/param norm = 1.8665e-01, time/batch = 19.3740s	
16163/30300 (epoch 26.672), train_loss = 1.15557026, grad/param norm = 1.6992e-01, time/batch = 19.4609s	
16164/30300 (epoch 26.673), train_loss = 1.18712484, grad/param norm = 1.7109e-01, time/batch = 17.1093s	
16165/30300 (epoch 26.675), train_loss = 1.10424909, grad/param norm = 1.7135e-01, time/batch = 19.3672s	
16166/30300 (epoch 26.677), train_loss = 1.08652156, grad/param norm = 1.4615e-01, time/batch = 19.5504s	
16167/30300 (epoch 26.678), train_loss = 1.05871247, grad/param norm = 1.4334e-01, time/batch = 17.1935s	
16168/30300 (epoch 26.680), train_loss = 0.94956360, grad/param norm = 1.3570e-01, time/batch = 18.5212s	
16169/30300 (epoch 26.682), train_loss = 1.11662282, grad/param norm = 1.6495e-01, time/batch = 16.6261s	
16170/30300 (epoch 26.683), train_loss = 1.23056732, grad/param norm = 1.4813e-01, time/batch = 17.2851s	
16171/30300 (epoch 26.685), train_loss = 1.23656177, grad/param norm = 2.0320e-01, time/batch = 17.5254s	
16172/30300 (epoch 26.686), train_loss = 1.10203137, grad/param norm = 1.4823e-01, time/batch = 18.8840s	
16173/30300 (epoch 26.688), train_loss = 1.13789245, grad/param norm = 1.5181e-01, time/batch = 19.2152s	
16174/30300 (epoch 26.690), train_loss = 1.07871555, grad/param norm = 1.6340e-01, time/batch = 18.3746s	
16175/30300 (epoch 26.691), train_loss = 1.16556989, grad/param norm = 1.3833e-01, time/batch = 18.5400s	
16176/30300 (epoch 26.693), train_loss = 1.43177885, grad/param norm = 1.6357e-01, time/batch = 19.7803s	
16177/30300 (epoch 26.695), train_loss = 1.23281221, grad/param norm = 1.8599e-01, time/batch = 18.6255s	
16178/30300 (epoch 26.696), train_loss = 1.20816544, grad/param norm = 1.8383e-01, time/batch = 17.9676s	
16179/30300 (epoch 26.698), train_loss = 1.08181563, grad/param norm = 1.5867e-01, time/batch = 17.2225s	
16180/30300 (epoch 26.700), train_loss = 1.06670825, grad/param norm = 1.6011e-01, time/batch = 17.5336s	
16181/30300 (epoch 26.701), train_loss = 0.98480648, grad/param norm = 1.4729e-01, time/batch = 18.1309s	
16182/30300 (epoch 26.703), train_loss = 1.14326897, grad/param norm = 1.4693e-01, time/batch = 19.3599s	
16183/30300 (epoch 26.705), train_loss = 1.06310838, grad/param norm = 1.4863e-01, time/batch = 18.4674s	
16184/30300 (epoch 26.706), train_loss = 1.18017869, grad/param norm = 1.6062e-01, time/batch = 17.9542s	
16185/30300 (epoch 26.708), train_loss = 1.12760836, grad/param norm = 1.6357e-01, time/batch = 19.0458s	
16186/30300 (epoch 26.710), train_loss = 1.11438471, grad/param norm = 1.6541e-01, time/batch = 19.7241s	
16187/30300 (epoch 26.711), train_loss = 1.04423957, grad/param norm = 1.4887e-01, time/batch = 18.1156s	
16188/30300 (epoch 26.713), train_loss = 1.04174119, grad/param norm = 1.5353e-01, time/batch = 19.0464s	
16189/30300 (epoch 26.715), train_loss = 1.07275003, grad/param norm = 1.5211e-01, time/batch = 19.6325s	
16190/30300 (epoch 26.716), train_loss = 1.21203411, grad/param norm = 1.4830e-01, time/batch = 17.3076s	
16191/30300 (epoch 26.718), train_loss = 1.24830349, grad/param norm = 1.6401e-01, time/batch = 17.6904s	
16192/30300 (epoch 26.719), train_loss = 1.08211334, grad/param norm = 1.7126e-01, time/batch = 18.8943s	
16193/30300 (epoch 26.721), train_loss = 1.11802739, grad/param norm = 1.5882e-01, time/batch = 17.7868s	
16194/30300 (epoch 26.723), train_loss = 1.07110654, grad/param norm = 1.5088e-01, time/batch = 19.2936s	
16195/30300 (epoch 26.724), train_loss = 1.15521555, grad/param norm = 1.6585e-01, time/batch = 16.5430s	
16196/30300 (epoch 26.726), train_loss = 1.47935203, grad/param norm = 2.0041e-01, time/batch = 18.4740s	
16197/30300 (epoch 26.728), train_loss = 1.18740219, grad/param norm = 1.5917e-01, time/batch = 18.9542s	
16198/30300 (epoch 26.729), train_loss = 1.09949982, grad/param norm = 1.5653e-01, time/batch = 19.0652s	
16199/30300 (epoch 26.731), train_loss = 1.15653959, grad/param norm = 1.6440e-01, time/batch = 19.2041s	
16200/30300 (epoch 26.733), train_loss = 1.14486952, grad/param norm = 1.5336e-01, time/batch = 17.0228s	
16201/30300 (epoch 26.734), train_loss = 1.22902230, grad/param norm = 1.4588e-01, time/batch = 19.5489s	
16202/30300 (epoch 26.736), train_loss = 1.11256660, grad/param norm = 1.5528e-01, time/batch = 19.5368s	
16203/30300 (epoch 26.738), train_loss = 1.05803348, grad/param norm = 1.3471e-01, time/batch = 17.5528s	
16204/30300 (epoch 26.739), train_loss = 1.20062905, grad/param norm = 1.6436e-01, time/batch = 18.7933s	
16205/30300 (epoch 26.741), train_loss = 1.27798877, grad/param norm = 1.5041e-01, time/batch = 19.6281s	
16206/30300 (epoch 26.743), train_loss = 1.12051721, grad/param norm = 1.5746e-01, time/batch = 18.4654s	
16207/30300 (epoch 26.744), train_loss = 1.15169851, grad/param norm = 1.4702e-01, time/batch = 18.5604s	
16208/30300 (epoch 26.746), train_loss = 1.06605660, grad/param norm = 1.4645e-01, time/batch = 19.1262s	
16209/30300 (epoch 26.748), train_loss = 1.10535286, grad/param norm = 1.6259e-01, time/batch = 18.2935s	
16210/30300 (epoch 26.749), train_loss = 1.18157797, grad/param norm = 1.5781e-01, time/batch = 18.0387s	
16211/30300 (epoch 26.751), train_loss = 1.13499359, grad/param norm = 1.5486e-01, time/batch = 18.9783s	
16212/30300 (epoch 26.752), train_loss = 1.10234827, grad/param norm = 1.6566e-01, time/batch = 18.8760s	
16213/30300 (epoch 26.754), train_loss = 1.06720873, grad/param norm = 1.4333e-01, time/batch = 5.4769s	
16214/30300 (epoch 26.756), train_loss = 1.09530895, grad/param norm = 1.5207e-01, time/batch = 0.7048s	
16215/30300 (epoch 26.757), train_loss = 1.11294672, grad/param norm = 1.5646e-01, time/batch = 0.7051s	
16216/30300 (epoch 26.759), train_loss = 1.16612513, grad/param norm = 1.4998e-01, time/batch = 0.6886s	
16217/30300 (epoch 26.761), train_loss = 0.98109241, grad/param norm = 1.3701e-01, time/batch = 0.6825s	
16218/30300 (epoch 26.762), train_loss = 1.01627149, grad/param norm = 1.4982e-01, time/batch = 0.6856s	
16219/30300 (epoch 26.764), train_loss = 1.11719899, grad/param norm = 1.5354e-01, time/batch = 0.6851s	
16220/30300 (epoch 26.766), train_loss = 1.22485492, grad/param norm = 1.5859e-01, time/batch = 0.8421s	
16221/30300 (epoch 26.767), train_loss = 1.20905070, grad/param norm = 1.8468e-01, time/batch = 1.0186s	
16222/30300 (epoch 26.769), train_loss = 1.16337154, grad/param norm = 1.5189e-01, time/batch = 1.0136s	
16223/30300 (epoch 26.771), train_loss = 1.09046827, grad/param norm = 1.7469e-01, time/batch = 1.0217s	
16224/30300 (epoch 26.772), train_loss = 1.18171665, grad/param norm = 1.5812e-01, time/batch = 1.0044s	
16225/30300 (epoch 26.774), train_loss = 1.25996116, grad/param norm = 1.5676e-01, time/batch = 1.5590s	
16226/30300 (epoch 26.776), train_loss = 1.13869684, grad/param norm = 1.6204e-01, time/batch = 1.8857s	
16227/30300 (epoch 26.777), train_loss = 1.24948259, grad/param norm = 1.5299e-01, time/batch = 1.8939s	
16228/30300 (epoch 26.779), train_loss = 1.25934631, grad/param norm = 1.5790e-01, time/batch = 18.1408s	
16229/30300 (epoch 26.781), train_loss = 1.14875030, grad/param norm = 1.6509e-01, time/batch = 19.6438s	
16230/30300 (epoch 26.782), train_loss = 1.09063978, grad/param norm = 1.5619e-01, time/batch = 18.3748s	
16231/30300 (epoch 26.784), train_loss = 1.08256361, grad/param norm = 1.4584e-01, time/batch = 18.3857s	
16232/30300 (epoch 26.785), train_loss = 1.26369688, grad/param norm = 1.8515e-01, time/batch = 17.6899s	
16233/30300 (epoch 26.787), train_loss = 0.94869412, grad/param norm = 1.5154e-01, time/batch = 17.5367s	
16234/30300 (epoch 26.789), train_loss = 1.33865999, grad/param norm = 1.5592e-01, time/batch = 19.5225s	
16235/30300 (epoch 26.790), train_loss = 1.18395444, grad/param norm = 1.9309e-01, time/batch = 17.9641s	
16236/30300 (epoch 26.792), train_loss = 0.97234749, grad/param norm = 1.6834e-01, time/batch = 18.4706s	
16237/30300 (epoch 26.794), train_loss = 1.14831229, grad/param norm = 1.7338e-01, time/batch = 16.8795s	
16238/30300 (epoch 26.795), train_loss = 1.04536008, grad/param norm = 1.4787e-01, time/batch = 18.8084s	
16239/30300 (epoch 26.797), train_loss = 1.28698900, grad/param norm = 1.7082e-01, time/batch = 18.2030s	
16240/30300 (epoch 26.799), train_loss = 1.19670624, grad/param norm = 1.6746e-01, time/batch = 17.7998s	
16241/30300 (epoch 26.800), train_loss = 1.20970212, grad/param norm = 1.6615e-01, time/batch = 19.2962s	
16242/30300 (epoch 26.802), train_loss = 1.40456164, grad/param norm = 2.0711e-01, time/batch = 18.8846s	
16243/30300 (epoch 26.804), train_loss = 1.22138920, grad/param norm = 1.6575e-01, time/batch = 17.4471s	
16244/30300 (epoch 26.805), train_loss = 1.29179896, grad/param norm = 1.7361e-01, time/batch = 19.3070s	
16245/30300 (epoch 26.807), train_loss = 1.12137718, grad/param norm = 1.9482e-01, time/batch = 18.1181s	
16246/30300 (epoch 26.809), train_loss = 1.21812067, grad/param norm = 1.7216e-01, time/batch = 17.4003s	
16247/30300 (epoch 26.810), train_loss = 1.21151813, grad/param norm = 1.6321e-01, time/batch = 18.8704s	
16248/30300 (epoch 26.812), train_loss = 1.06534439, grad/param norm = 1.5556e-01, time/batch = 18.7900s	
16249/30300 (epoch 26.814), train_loss = 1.14012822, grad/param norm = 1.6249e-01, time/batch = 17.4531s	
16250/30300 (epoch 26.815), train_loss = 1.17003236, grad/param norm = 1.8702e-01, time/batch = 18.7935s	
16251/30300 (epoch 26.817), train_loss = 1.25874160, grad/param norm = 1.7487e-01, time/batch = 18.9614s	
16252/30300 (epoch 26.818), train_loss = 1.17850665, grad/param norm = 1.5653e-01, time/batch = 19.0352s	
16253/30300 (epoch 26.820), train_loss = 1.31752270, grad/param norm = 1.9935e-01, time/batch = 18.5391s	
16254/30300 (epoch 26.822), train_loss = 1.31112738, grad/param norm = 2.0973e-01, time/batch = 17.2913s	
16255/30300 (epoch 26.823), train_loss = 1.31288705, grad/param norm = 1.8878e-01, time/batch = 19.5457s	
16256/30300 (epoch 26.825), train_loss = 1.28076743, grad/param norm = 1.8266e-01, time/batch = 17.7890s	
16257/30300 (epoch 26.827), train_loss = 0.98294345, grad/param norm = 1.7576e-01, time/batch = 19.5548s	
16258/30300 (epoch 26.828), train_loss = 1.22981110, grad/param norm = 1.6247e-01, time/batch = 19.5519s	
16259/30300 (epoch 26.830), train_loss = 1.21070895, grad/param norm = 1.6582e-01, time/batch = 17.1956s	
16260/30300 (epoch 26.832), train_loss = 1.06373160, grad/param norm = 1.6429e-01, time/batch = 18.6455s	
16261/30300 (epoch 26.833), train_loss = 1.18423987, grad/param norm = 1.6362e-01, time/batch = 15.6027s	
16262/30300 (epoch 26.835), train_loss = 1.06674688, grad/param norm = 1.4218e-01, time/batch = 17.1935s	
16263/30300 (epoch 26.837), train_loss = 1.02251315, grad/param norm = 1.4611e-01, time/batch = 18.9653s	
16264/30300 (epoch 26.838), train_loss = 1.04549643, grad/param norm = 1.6327e-01, time/batch = 17.9685s	
16265/30300 (epoch 26.840), train_loss = 1.22790047, grad/param norm = 1.4158e-01, time/batch = 18.5474s	
16266/30300 (epoch 26.842), train_loss = 1.08414657, grad/param norm = 1.4604e-01, time/batch = 19.1078s	
16267/30300 (epoch 26.843), train_loss = 1.17956728, grad/param norm = 1.6138e-01, time/batch = 19.0505s	
16268/30300 (epoch 26.845), train_loss = 1.19836601, grad/param norm = 1.4435e-01, time/batch = 18.5502s	
16269/30300 (epoch 26.847), train_loss = 1.16506080, grad/param norm = 1.5749e-01, time/batch = 18.0296s	
16270/30300 (epoch 26.848), train_loss = 1.22171750, grad/param norm = 1.5918e-01, time/batch = 18.7058s	
16271/30300 (epoch 26.850), train_loss = 1.16287958, grad/param norm = 1.5844e-01, time/batch = 19.6256s	
16272/30300 (epoch 26.851), train_loss = 1.17807035, grad/param norm = 1.8602e-01, time/batch = 17.8725s	
16273/30300 (epoch 26.853), train_loss = 1.09787521, grad/param norm = 1.5423e-01, time/batch = 19.5389s	
16274/30300 (epoch 26.855), train_loss = 1.08960620, grad/param norm = 1.3169e-01, time/batch = 19.0435s	
16275/30300 (epoch 26.856), train_loss = 1.17506902, grad/param norm = 1.5273e-01, time/batch = 17.1223s	
16276/30300 (epoch 26.858), train_loss = 1.07678322, grad/param norm = 1.3584e-01, time/batch = 19.0157s	
16277/30300 (epoch 26.860), train_loss = 1.05473000, grad/param norm = 1.4931e-01, time/batch = 19.1105s	
16278/30300 (epoch 26.861), train_loss = 1.31739839, grad/param norm = 1.5990e-01, time/batch = 18.4662s	
16279/30300 (epoch 26.863), train_loss = 1.13319176, grad/param norm = 1.4196e-01, time/batch = 18.5403s	
16280/30300 (epoch 26.865), train_loss = 1.20429480, grad/param norm = 1.7000e-01, time/batch = 18.6851s	
16281/30300 (epoch 26.866), train_loss = 1.19984678, grad/param norm = 1.6744e-01, time/batch = 18.1298s	
16282/30300 (epoch 26.868), train_loss = 1.15548940, grad/param norm = 1.5855e-01, time/batch = 17.6235s	
16283/30300 (epoch 26.870), train_loss = 1.08304791, grad/param norm = 1.5472e-01, time/batch = 19.0529s	
16284/30300 (epoch 26.871), train_loss = 1.11845748, grad/param norm = 1.4643e-01, time/batch = 19.0519s	
16285/30300 (epoch 26.873), train_loss = 1.14021850, grad/param norm = 1.4413e-01, time/batch = 17.4523s	
16286/30300 (epoch 26.875), train_loss = 1.08323936, grad/param norm = 1.3964e-01, time/batch = 18.7113s	
16287/30300 (epoch 26.876), train_loss = 1.02471109, grad/param norm = 1.5703e-01, time/batch = 19.6253s	
16288/30300 (epoch 26.878), train_loss = 0.99643225, grad/param norm = 1.4925e-01, time/batch = 18.3778s	
16289/30300 (epoch 26.880), train_loss = 1.05679746, grad/param norm = 1.4514e-01, time/batch = 18.9561s	
16290/30300 (epoch 26.881), train_loss = 1.29620562, grad/param norm = 1.9692e-01, time/batch = 19.1364s	
16291/30300 (epoch 26.883), train_loss = 1.19800331, grad/param norm = 1.6349e-01, time/batch = 17.3840s	
16292/30300 (epoch 26.884), train_loss = 1.09265079, grad/param norm = 1.3853e-01, time/batch = 18.3736s	
16293/30300 (epoch 26.886), train_loss = 1.19006357, grad/param norm = 1.5175e-01, time/batch = 18.4582s	
16294/30300 (epoch 26.888), train_loss = 1.12487553, grad/param norm = 1.5860e-01, time/batch = 18.1250s	
16295/30300 (epoch 26.889), train_loss = 1.16357250, grad/param norm = 1.5096e-01, time/batch = 16.8465s	
16296/30300 (epoch 26.891), train_loss = 1.14547723, grad/param norm = 1.6000e-01, time/batch = 17.6055s	
16297/30300 (epoch 26.893), train_loss = 1.35416643, grad/param norm = 1.5356e-01, time/batch = 19.0266s	
16298/30300 (epoch 26.894), train_loss = 1.19656812, grad/param norm = 1.5778e-01, time/batch = 17.6194s	
16299/30300 (epoch 26.896), train_loss = 0.97685426, grad/param norm = 1.4551e-01, time/batch = 18.3797s	
16300/30300 (epoch 26.898), train_loss = 0.97373151, grad/param norm = 1.5466e-01, time/batch = 18.0601s	
16301/30300 (epoch 26.899), train_loss = 1.06154135, grad/param norm = 1.6713e-01, time/batch = 18.2945s	
16302/30300 (epoch 26.901), train_loss = 1.13707903, grad/param norm = 1.8516e-01, time/batch = 17.9584s	
16303/30300 (epoch 26.903), train_loss = 1.14759669, grad/param norm = 1.6823e-01, time/batch = 18.6417s	
16304/30300 (epoch 26.904), train_loss = 1.13649742, grad/param norm = 1.5973e-01, time/batch = 18.4661s	
16305/30300 (epoch 26.906), train_loss = 1.19981516, grad/param norm = 1.7098e-01, time/batch = 17.7178s	
16306/30300 (epoch 26.908), train_loss = 1.10271817, grad/param norm = 1.5532e-01, time/batch = 18.4678s	
16307/30300 (epoch 26.909), train_loss = 1.05754527, grad/param norm = 1.9452e-01, time/batch = 18.3065s	
16308/30300 (epoch 26.911), train_loss = 1.13881543, grad/param norm = 1.5285e-01, time/batch = 17.8574s	
16309/30300 (epoch 26.913), train_loss = 1.13346311, grad/param norm = 1.4187e-01, time/batch = 18.9617s	
16310/30300 (epoch 26.914), train_loss = 1.11410875, grad/param norm = 1.6283e-01, time/batch = 18.4684s	
16311/30300 (epoch 26.916), train_loss = 1.16918840, grad/param norm = 1.4656e-01, time/batch = 17.4568s	
16312/30300 (epoch 26.917), train_loss = 1.10399496, grad/param norm = 1.5474e-01, time/batch = 19.2957s	
16313/30300 (epoch 26.919), train_loss = 1.07010481, grad/param norm = 1.6060e-01, time/batch = 19.2186s	
16314/30300 (epoch 26.921), train_loss = 1.13169828, grad/param norm = 1.4668e-01, time/batch = 17.0456s	
16315/30300 (epoch 26.922), train_loss = 1.23492282, grad/param norm = 1.7172e-01, time/batch = 17.7992s	
16316/30300 (epoch 26.924), train_loss = 1.13669268, grad/param norm = 1.6429e-01, time/batch = 19.0522s	
16317/30300 (epoch 26.926), train_loss = 1.18078451, grad/param norm = 1.5768e-01, time/batch = 15.1470s	
16318/30300 (epoch 26.927), train_loss = 1.14803062, grad/param norm = 1.5610e-01, time/batch = 15.0856s	
16319/30300 (epoch 26.929), train_loss = 1.06683441, grad/param norm = 1.5879e-01, time/batch = 14.8575s	
16320/30300 (epoch 26.931), train_loss = 1.23190036, grad/param norm = 1.9417e-01, time/batch = 16.0555s	
16321/30300 (epoch 26.932), train_loss = 1.06185554, grad/param norm = 1.5859e-01, time/batch = 18.4575s	
16322/30300 (epoch 26.934), train_loss = 1.16881487, grad/param norm = 1.5848e-01, time/batch = 18.5285s	
16323/30300 (epoch 26.936), train_loss = 1.08904445, grad/param norm = 1.4356e-01, time/batch = 18.9525s	
16324/30300 (epoch 26.937), train_loss = 1.07537969, grad/param norm = 1.5606e-01, time/batch = 18.3786s	
16325/30300 (epoch 26.939), train_loss = 1.27812256, grad/param norm = 2.1597e-01, time/batch = 18.1922s	
16326/30300 (epoch 26.941), train_loss = 1.13533271, grad/param norm = 1.6977e-01, time/batch = 19.2210s	
16327/30300 (epoch 26.942), train_loss = 1.13841375, grad/param norm = 1.7357e-01, time/batch = 18.7177s	
16328/30300 (epoch 26.944), train_loss = 1.02958533, grad/param norm = 1.7580e-01, time/batch = 18.0409s	
16329/30300 (epoch 26.946), train_loss = 1.24442149, grad/param norm = 1.9313e-01, time/batch = 17.9753s	
16330/30300 (epoch 26.947), train_loss = 1.24303270, grad/param norm = 1.9455e-01, time/batch = 18.6432s	
16331/30300 (epoch 26.949), train_loss = 1.26181328, grad/param norm = 1.9138e-01, time/batch = 16.1511s	
16332/30300 (epoch 26.950), train_loss = 1.23061783, grad/param norm = 1.5950e-01, time/batch = 15.9550s	
16333/30300 (epoch 26.952), train_loss = 1.19825266, grad/param norm = 1.6678e-01, time/batch = 16.0281s	
16334/30300 (epoch 26.954), train_loss = 1.40615697, grad/param norm = 1.6373e-01, time/batch = 15.4544s	
16335/30300 (epoch 26.955), train_loss = 1.10761281, grad/param norm = 1.5281e-01, time/batch = 17.1036s	
16336/30300 (epoch 26.957), train_loss = 1.22613347, grad/param norm = 1.6001e-01, time/batch = 18.9684s	
16337/30300 (epoch 26.959), train_loss = 1.10618136, grad/param norm = 1.7408e-01, time/batch = 17.7982s	
16338/30300 (epoch 26.960), train_loss = 1.11982319, grad/param norm = 1.7300e-01, time/batch = 18.7114s	
16339/30300 (epoch 26.962), train_loss = 1.12421009, grad/param norm = 2.0212e-01, time/batch = 18.6202s	
16340/30300 (epoch 26.964), train_loss = 1.05669566, grad/param norm = 2.1451e-01, time/batch = 18.9757s	
16341/30300 (epoch 26.965), train_loss = 1.06964035, grad/param norm = 1.6604e-01, time/batch = 23.5539s	
16342/30300 (epoch 26.967), train_loss = 1.14586859, grad/param norm = 1.7745e-01, time/batch = 26.8828s	
16343/30300 (epoch 26.969), train_loss = 1.05514535, grad/param norm = 1.7831e-01, time/batch = 19.4725s	
16344/30300 (epoch 26.970), train_loss = 1.10849127, grad/param norm = 1.6683e-01, time/batch = 18.9434s	
16345/30300 (epoch 26.972), train_loss = 1.02117688, grad/param norm = 1.8175e-01, time/batch = 17.7011s	
16346/30300 (epoch 26.974), train_loss = 1.30160405, grad/param norm = 1.7991e-01, time/batch = 18.2183s	
16347/30300 (epoch 26.975), train_loss = 1.33117720, grad/param norm = 1.9841e-01, time/batch = 17.7893s	
16348/30300 (epoch 26.977), train_loss = 1.29043342, grad/param norm = 1.7222e-01, time/batch = 19.3742s	
16349/30300 (epoch 26.979), train_loss = 1.21847117, grad/param norm = 1.6737e-01, time/batch = 18.6353s	
16350/30300 (epoch 26.980), train_loss = 1.23272263, grad/param norm = 1.7629e-01, time/batch = 17.3582s	
16351/30300 (epoch 26.982), train_loss = 1.23794724, grad/param norm = 1.7260e-01, time/batch = 17.6217s	
16352/30300 (epoch 26.983), train_loss = 1.27940927, grad/param norm = 1.6399e-01, time/batch = 19.5271s	
16353/30300 (epoch 26.985), train_loss = 1.22235900, grad/param norm = 2.0353e-01, time/batch = 18.5523s	
16354/30300 (epoch 26.987), train_loss = 1.13694452, grad/param norm = 1.5185e-01, time/batch = 17.9716s	
16355/30300 (epoch 26.988), train_loss = 1.29015942, grad/param norm = 1.7374e-01, time/batch = 19.3844s	
16356/30300 (epoch 26.990), train_loss = 1.01678343, grad/param norm = 1.3896e-01, time/batch = 19.2943s	
16357/30300 (epoch 26.992), train_loss = 1.21416109, grad/param norm = 1.4306e-01, time/batch = 17.7048s	
16358/30300 (epoch 26.993), train_loss = 1.27907863, grad/param norm = 2.1801e-01, time/batch = 18.4474s	
16359/30300 (epoch 26.995), train_loss = 1.13073343, grad/param norm = 1.7405e-01, time/batch = 18.4755s	
16360/30300 (epoch 26.997), train_loss = 1.19098023, grad/param norm = 1.9521e-01, time/batch = 17.4756s	
16361/30300 (epoch 26.998), train_loss = 1.22627347, grad/param norm = 1.8091e-01, time/batch = 18.4652s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
16362/30300 (epoch 27.000), train_loss = 1.10528970, grad/param norm = 1.8064e-01, time/batch = 17.9528s	
16363/30300 (epoch 27.002), train_loss = 1.26175561, grad/param norm = 1.7727e-01, time/batch = 18.0385s	
16364/30300 (epoch 27.003), train_loss = 1.16289162, grad/param norm = 1.6885e-01, time/batch = 18.7864s	
16365/30300 (epoch 27.005), train_loss = 1.10625189, grad/param norm = 1.6278e-01, time/batch = 18.8878s	
16366/30300 (epoch 27.007), train_loss = 1.19812988, grad/param norm = 1.7985e-01, time/batch = 18.8007s	
16367/30300 (epoch 27.008), train_loss = 1.10248474, grad/param norm = 1.9137e-01, time/batch = 18.3708s	
16368/30300 (epoch 27.010), train_loss = 1.03177728, grad/param norm = 1.7196e-01, time/batch = 17.0324s	
16369/30300 (epoch 27.012), train_loss = 1.09656674, grad/param norm = 1.5982e-01, time/batch = 19.4669s	
16370/30300 (epoch 27.013), train_loss = 1.25510810, grad/param norm = 1.6550e-01, time/batch = 18.9537s	
16371/30300 (epoch 27.015), train_loss = 1.10773212, grad/param norm = 1.5100e-01, time/batch = 19.4747s	
16372/30300 (epoch 27.017), train_loss = 1.10057042, grad/param norm = 1.4238e-01, time/batch = 18.0572s	
16373/30300 (epoch 27.018), train_loss = 1.05650317, grad/param norm = 1.4298e-01, time/batch = 17.3782s	
16374/30300 (epoch 27.020), train_loss = 1.24923824, grad/param norm = 1.8757e-01, time/batch = 18.0522s	
16375/30300 (epoch 27.021), train_loss = 1.25958443, grad/param norm = 1.7117e-01, time/batch = 18.8842s	
16376/30300 (epoch 27.023), train_loss = 1.16429715, grad/param norm = 1.5350e-01, time/batch = 18.5488s	
16377/30300 (epoch 27.025), train_loss = 1.06119478, grad/param norm = 1.7579e-01, time/batch = 18.9629s	
16378/30300 (epoch 27.026), train_loss = 1.18917355, grad/param norm = 1.6313e-01, time/batch = 19.3741s	
16379/30300 (epoch 27.028), train_loss = 1.23153349, grad/param norm = 1.7358e-01, time/batch = 17.5437s	
16380/30300 (epoch 27.030), train_loss = 1.09641655, grad/param norm = 1.6634e-01, time/batch = 17.7078s	
16381/30300 (epoch 27.031), train_loss = 1.20628623, grad/param norm = 1.6379e-01, time/batch = 18.2974s	
16382/30300 (epoch 27.033), train_loss = 1.13746228, grad/param norm = 1.4842e-01, time/batch = 18.9692s	
16383/30300 (epoch 27.035), train_loss = 1.23810637, grad/param norm = 1.8166e-01, time/batch = 19.1245s	
16384/30300 (epoch 27.036), train_loss = 1.17118457, grad/param norm = 1.6744e-01, time/batch = 17.1982s	
16385/30300 (epoch 27.038), train_loss = 1.18237225, grad/param norm = 1.5020e-01, time/batch = 19.4631s	
16386/30300 (epoch 27.040), train_loss = 0.91540554, grad/param norm = 1.4318e-01, time/batch = 18.3024s	
16387/30300 (epoch 27.041), train_loss = 0.97136604, grad/param norm = 1.5398e-01, time/batch = 19.2198s	
16388/30300 (epoch 27.043), train_loss = 1.16007500, grad/param norm = 1.6195e-01, time/batch = 18.3752s	
16389/30300 (epoch 27.045), train_loss = 1.13601104, grad/param norm = 1.5474e-01, time/batch = 17.9541s	
16390/30300 (epoch 27.046), train_loss = 1.32113803, grad/param norm = 1.9695e-01, time/batch = 18.3803s	
16391/30300 (epoch 27.048), train_loss = 1.13586835, grad/param norm = 1.9514e-01, time/batch = 19.9533s	
16392/30300 (epoch 27.050), train_loss = 1.10376026, grad/param norm = 1.6614e-01, time/batch = 17.7072s	
16393/30300 (epoch 27.051), train_loss = 1.17813278, grad/param norm = 1.7283e-01, time/batch = 18.3544s	
16394/30300 (epoch 27.053), train_loss = 0.98430850, grad/param norm = 1.9654e-01, time/batch = 18.6362s	
16395/30300 (epoch 27.054), train_loss = 1.15304249, grad/param norm = 1.6086e-01, time/batch = 18.5613s	
16396/30300 (epoch 27.056), train_loss = 1.05491417, grad/param norm = 1.4905e-01, time/batch = 19.0414s	
16397/30300 (epoch 27.058), train_loss = 1.11826172, grad/param norm = 1.5840e-01, time/batch = 18.3808s	
16398/30300 (epoch 27.059), train_loss = 1.05526039, grad/param norm = 1.7378e-01, time/batch = 19.4499s	
16399/30300 (epoch 27.061), train_loss = 1.21338857, grad/param norm = 1.7341e-01, time/batch = 18.1418s	
16400/30300 (epoch 27.063), train_loss = 1.03240642, grad/param norm = 1.6241e-01, time/batch = 19.2121s	
16401/30300 (epoch 27.064), train_loss = 1.14786293, grad/param norm = 1.6650e-01, time/batch = 19.2254s	
16402/30300 (epoch 27.066), train_loss = 1.13771804, grad/param norm = 1.4636e-01, time/batch = 17.9774s	
16403/30300 (epoch 27.068), train_loss = 1.02955072, grad/param norm = 1.5949e-01, time/batch = 16.3510s	
16404/30300 (epoch 27.069), train_loss = 1.20443383, grad/param norm = 1.6636e-01, time/batch = 18.3821s	
16405/30300 (epoch 27.071), train_loss = 1.18419636, grad/param norm = 1.6315e-01, time/batch = 18.4570s	
16406/30300 (epoch 27.073), train_loss = 1.08886816, grad/param norm = 1.6009e-01, time/batch = 18.3103s	
16407/30300 (epoch 27.074), train_loss = 1.15565012, grad/param norm = 1.6199e-01, time/batch = 18.8129s	
16408/30300 (epoch 27.076), train_loss = 1.10028648, grad/param norm = 1.4393e-01, time/batch = 17.8004s	
16409/30300 (epoch 27.078), train_loss = 1.06279652, grad/param norm = 1.4346e-01, time/batch = 17.6988s	
16410/30300 (epoch 27.079), train_loss = 1.07759878, grad/param norm = 1.5473e-01, time/batch = 18.8189s	
16411/30300 (epoch 27.081), train_loss = 1.14347534, grad/param norm = 1.6314e-01, time/batch = 19.3858s	
16412/30300 (epoch 27.083), train_loss = 1.19566853, grad/param norm = 1.7045e-01, time/batch = 18.1831s	
16413/30300 (epoch 27.084), train_loss = 1.06070635, grad/param norm = 1.7260e-01, time/batch = 18.9674s	
16414/30300 (epoch 27.086), train_loss = 1.07576032, grad/param norm = 1.6774e-01, time/batch = 19.6378s	
16415/30300 (epoch 27.087), train_loss = 1.05380744, grad/param norm = 1.3951e-01, time/batch = 17.0581s	
16416/30300 (epoch 27.089), train_loss = 1.09713353, grad/param norm = 1.6136e-01, time/batch = 19.4594s	
16417/30300 (epoch 27.091), train_loss = 1.17040184, grad/param norm = 1.4871e-01, time/batch = 19.5251s	
16418/30300 (epoch 27.092), train_loss = 1.18675090, grad/param norm = 1.5639e-01, time/batch = 18.1313s	
16419/30300 (epoch 27.094), train_loss = 1.30353873, grad/param norm = 1.9169e-01, time/batch = 19.7007s	
16420/30300 (epoch 27.096), train_loss = 1.24770687, grad/param norm = 1.7253e-01, time/batch = 18.8007s	
16421/30300 (epoch 27.097), train_loss = 1.06682599, grad/param norm = 1.5190e-01, time/batch = 17.8831s	
16422/30300 (epoch 27.099), train_loss = 1.23586981, grad/param norm = 1.5893e-01, time/batch = 18.8060s	
16423/30300 (epoch 27.101), train_loss = 1.27464766, grad/param norm = 1.8886e-01, time/batch = 18.1164s	
16424/30300 (epoch 27.102), train_loss = 1.09800461, grad/param norm = 1.7976e-01, time/batch = 18.6331s	
16425/30300 (epoch 27.104), train_loss = 1.11423700, grad/param norm = 1.8362e-01, time/batch = 17.6179s	
16426/30300 (epoch 27.106), train_loss = 1.12105605, grad/param norm = 1.7786e-01, time/batch = 18.8091s	
16427/30300 (epoch 27.107), train_loss = 1.17913679, grad/param norm = 1.5904e-01, time/batch = 19.4664s	
16428/30300 (epoch 27.109), train_loss = 1.21464480, grad/param norm = 1.9287e-01, time/batch = 17.6976s	
16429/30300 (epoch 27.111), train_loss = 1.24345343, grad/param norm = 1.6980e-01, time/batch = 18.5578s	
16430/30300 (epoch 27.112), train_loss = 1.26006445, grad/param norm = 1.8840e-01, time/batch = 19.2973s	
16431/30300 (epoch 27.114), train_loss = 1.10883542, grad/param norm = 1.4945e-01, time/batch = 17.6130s	
16432/30300 (epoch 27.116), train_loss = 1.15161778, grad/param norm = 1.8599e-01, time/batch = 17.5174s	
16433/30300 (epoch 27.117), train_loss = 1.21349053, grad/param norm = 1.6507e-01, time/batch = 19.2963s	
16434/30300 (epoch 27.119), train_loss = 1.08203260, grad/param norm = 1.8485e-01, time/batch = 17.7164s	
16435/30300 (epoch 27.120), train_loss = 1.13369167, grad/param norm = 1.6713e-01, time/batch = 18.0523s	
16436/30300 (epoch 27.122), train_loss = 1.23349642, grad/param norm = 2.0202e-01, time/batch = 18.5602s	
16437/30300 (epoch 27.124), train_loss = 1.29053550, grad/param norm = 1.9125e-01, time/batch = 18.0294s	
16438/30300 (epoch 27.125), train_loss = 1.02204848, grad/param norm = 1.6593e-01, time/batch = 19.1975s	
16439/30300 (epoch 27.127), train_loss = 1.18441726, grad/param norm = 2.0651e-01, time/batch = 17.6264s	
16440/30300 (epoch 27.129), train_loss = 1.26328556, grad/param norm = 1.6724e-01, time/batch = 18.8795s	
16441/30300 (epoch 27.130), train_loss = 1.27007026, grad/param norm = 1.6294e-01, time/batch = 18.1110s	
16442/30300 (epoch 27.132), train_loss = 1.28514965, grad/param norm = 1.7735e-01, time/batch = 17.6450s	
16443/30300 (epoch 27.134), train_loss = 1.05410063, grad/param norm = 1.6130e-01, time/batch = 17.9588s	
16444/30300 (epoch 27.135), train_loss = 1.07960286, grad/param norm = 1.6505e-01, time/batch = 16.8510s	
16445/30300 (epoch 27.137), train_loss = 1.15589009, grad/param norm = 1.7161e-01, time/batch = 18.9504s	
16446/30300 (epoch 27.139), train_loss = 1.10426531, grad/param norm = 1.8607e-01, time/batch = 17.9487s	
16447/30300 (epoch 27.140), train_loss = 1.17690603, grad/param norm = 1.9885e-01, time/batch = 18.6234s	
16448/30300 (epoch 27.142), train_loss = 1.28754563, grad/param norm = 2.1095e-01, time/batch = 17.8846s	
16449/30300 (epoch 27.144), train_loss = 1.11463337, grad/param norm = 1.8844e-01, time/batch = 17.2696s	
16450/30300 (epoch 27.145), train_loss = 1.23519345, grad/param norm = 1.7751e-01, time/batch = 19.2184s	
16451/30300 (epoch 27.147), train_loss = 1.11803388, grad/param norm = 1.9461e-01, time/batch = 18.4423s	
16452/30300 (epoch 27.149), train_loss = 1.31608689, grad/param norm = 2.1214e-01, time/batch = 19.0418s	
16453/30300 (epoch 27.150), train_loss = 1.12587027, grad/param norm = 1.9897e-01, time/batch = 18.2070s	
16454/30300 (epoch 27.152), train_loss = 1.04943346, grad/param norm = 1.9770e-01, time/batch = 17.2103s	
16455/30300 (epoch 27.153), train_loss = 1.14972164, grad/param norm = 1.6968e-01, time/batch = 18.4586s	
16456/30300 (epoch 27.155), train_loss = 1.00896363, grad/param norm = 1.5343e-01, time/batch = 17.8055s	
16457/30300 (epoch 27.157), train_loss = 1.12616304, grad/param norm = 1.8560e-01, time/batch = 17.8623s	
16458/30300 (epoch 27.158), train_loss = 1.16838957, grad/param norm = 2.0228e-01, time/batch = 17.7726s	
16459/30300 (epoch 27.160), train_loss = 1.07396256, grad/param norm = 1.7276e-01, time/batch = 18.6153s	
16460/30300 (epoch 27.162), train_loss = 1.13847295, grad/param norm = 1.5668e-01, time/batch = 18.8639s	
16461/30300 (epoch 27.163), train_loss = 1.12537785, grad/param norm = 1.7914e-01, time/batch = 18.7795s	
16462/30300 (epoch 27.165), train_loss = 1.25711998, grad/param norm = 1.6781e-01, time/batch = 18.2974s	
16463/30300 (epoch 27.167), train_loss = 1.12192077, grad/param norm = 1.5884e-01, time/batch = 19.0349s	
16464/30300 (epoch 27.168), train_loss = 1.19931148, grad/param norm = 1.7341e-01, time/batch = 16.6926s	
16465/30300 (epoch 27.170), train_loss = 1.16198754, grad/param norm = 1.9723e-01, time/batch = 18.7993s	
16466/30300 (epoch 27.172), train_loss = 1.13562217, grad/param norm = 1.8235e-01, time/batch = 19.5351s	
16467/30300 (epoch 27.173), train_loss = 1.13430534, grad/param norm = 1.7493e-01, time/batch = 17.8626s	
16468/30300 (epoch 27.175), train_loss = 1.15310742, grad/param norm = 1.5422e-01, time/batch = 19.1357s	
16469/30300 (epoch 27.177), train_loss = 1.18380915, grad/param norm = 1.6586e-01, time/batch = 18.8828s	
16470/30300 (epoch 27.178), train_loss = 0.91829691, grad/param norm = 1.4072e-01, time/batch = 17.7030s	
16471/30300 (epoch 27.180), train_loss = 1.12690589, grad/param norm = 1.4938e-01, time/batch = 18.6280s	
16472/30300 (epoch 27.182), train_loss = 1.16019848, grad/param norm = 1.7823e-01, time/batch = 18.7032s	
16473/30300 (epoch 27.183), train_loss = 1.07916724, grad/param norm = 1.5881e-01, time/batch = 18.1339s	
16474/30300 (epoch 27.185), train_loss = 1.31536939, grad/param norm = 1.8034e-01, time/batch = 18.5482s	
16475/30300 (epoch 27.186), train_loss = 1.34144722, grad/param norm = 1.8664e-01, time/batch = 19.2234s	
16476/30300 (epoch 27.188), train_loss = 1.17561968, grad/param norm = 1.6558e-01, time/batch = 18.0200s	
16477/30300 (epoch 27.190), train_loss = 1.15933058, grad/param norm = 1.5217e-01, time/batch = 17.2889s	
16478/30300 (epoch 27.191), train_loss = 1.21458102, grad/param norm = 1.8356e-01, time/batch = 18.2137s	
16479/30300 (epoch 27.193), train_loss = 1.06078671, grad/param norm = 1.4494e-01, time/batch = 18.5418s	
16480/30300 (epoch 27.195), train_loss = 1.12432074, grad/param norm = 1.5429e-01, time/batch = 17.0435s	
16481/30300 (epoch 27.196), train_loss = 1.17388454, grad/param norm = 1.4332e-01, time/batch = 19.8000s	
16482/30300 (epoch 27.198), train_loss = 0.97804137, grad/param norm = 1.5055e-01, time/batch = 19.5361s	
16483/30300 (epoch 27.200), train_loss = 1.14136990, grad/param norm = 1.5518e-01, time/batch = 18.2245s	
16484/30300 (epoch 27.201), train_loss = 1.21099843, grad/param norm = 1.8434e-01, time/batch = 19.1014s	
16485/30300 (epoch 27.203), train_loss = 1.14574165, grad/param norm = 1.5790e-01, time/batch = 19.7192s	
16486/30300 (epoch 27.205), train_loss = 1.35554752, grad/param norm = 1.7802e-01, time/batch = 18.3813s	
16487/30300 (epoch 27.206), train_loss = 1.25300258, grad/param norm = 1.7492e-01, time/batch = 17.1299s	
16488/30300 (epoch 27.208), train_loss = 1.23132059, grad/param norm = 1.7998e-01, time/batch = 18.7050s	
16489/30300 (epoch 27.210), train_loss = 1.20885277, grad/param norm = 1.6570e-01, time/batch = 19.3707s	
16490/30300 (epoch 27.211), train_loss = 1.26021234, grad/param norm = 1.6754e-01, time/batch = 17.0232s	
16491/30300 (epoch 27.213), train_loss = 1.12083674, grad/param norm = 1.4169e-01, time/batch = 18.1240s	
16492/30300 (epoch 27.215), train_loss = 1.06590407, grad/param norm = 1.7028e-01, time/batch = 19.6245s	
16493/30300 (epoch 27.216), train_loss = 1.09347406, grad/param norm = 1.5840e-01, time/batch = 18.4571s	
16494/30300 (epoch 27.218), train_loss = 1.03560391, grad/param norm = 1.5452e-01, time/batch = 19.3905s	
16495/30300 (epoch 27.219), train_loss = 0.99912761, grad/param norm = 1.3880e-01, time/batch = 19.1935s	
16496/30300 (epoch 27.221), train_loss = 0.98920789, grad/param norm = 1.3810e-01, time/batch = 17.9496s	
16497/30300 (epoch 27.223), train_loss = 1.16604195, grad/param norm = 1.6820e-01, time/batch = 18.9578s	
16498/30300 (epoch 27.224), train_loss = 0.99424233, grad/param norm = 1.5165e-01, time/batch = 18.5577s	
16499/30300 (epoch 27.226), train_loss = 1.21258209, grad/param norm = 1.6863e-01, time/batch = 18.2149s	
16500/30300 (epoch 27.228), train_loss = 1.24052951, grad/param norm = 1.6004e-01, time/batch = 18.9705s	
16501/30300 (epoch 27.229), train_loss = 1.11781506, grad/param norm = 1.5898e-01, time/batch = 18.4780s	
16502/30300 (epoch 27.231), train_loss = 1.16153553, grad/param norm = 1.5859e-01, time/batch = 17.8520s	
16503/30300 (epoch 27.233), train_loss = 1.17142068, grad/param norm = 1.4657e-01, time/batch = 18.8606s	
16504/30300 (epoch 27.234), train_loss = 1.21394723, grad/param norm = 1.9404e-01, time/batch = 18.6256s	
16505/30300 (epoch 27.236), train_loss = 1.16921074, grad/param norm = 1.4696e-01, time/batch = 18.4372s	
16506/30300 (epoch 27.238), train_loss = 1.17552327, grad/param norm = 1.7446e-01, time/batch = 18.5329s	
16507/30300 (epoch 27.239), train_loss = 1.16877491, grad/param norm = 1.7766e-01, time/batch = 19.6384s	
16508/30300 (epoch 27.241), train_loss = 1.19204946, grad/param norm = 1.6947e-01, time/batch = 18.2999s	
16509/30300 (epoch 27.243), train_loss = 1.20561665, grad/param norm = 1.6061e-01, time/batch = 17.5312s	
16510/30300 (epoch 27.244), train_loss = 1.36423717, grad/param norm = 1.7089e-01, time/batch = 19.0597s	
16511/30300 (epoch 27.246), train_loss = 1.18859615, grad/param norm = 1.6449e-01, time/batch = 18.7206s	
16512/30300 (epoch 27.248), train_loss = 1.11936196, grad/param norm = 1.4339e-01, time/batch = 18.2028s	
16513/30300 (epoch 27.249), train_loss = 1.08525626, grad/param norm = 1.5540e-01, time/batch = 18.7799s	
16514/30300 (epoch 27.251), train_loss = 1.08112186, grad/param norm = 1.6124e-01, time/batch = 18.3022s	
16515/30300 (epoch 27.252), train_loss = 1.25526737, grad/param norm = 1.7507e-01, time/batch = 18.1397s	
16516/30300 (epoch 27.254), train_loss = 1.23555654, grad/param norm = 1.7415e-01, time/batch = 18.2209s	
16517/30300 (epoch 27.256), train_loss = 1.17855426, grad/param norm = 1.5640e-01, time/batch = 17.0388s	
16518/30300 (epoch 27.257), train_loss = 1.20580311, grad/param norm = 1.5864e-01, time/batch = 19.2893s	
16519/30300 (epoch 27.259), train_loss = 1.13386243, grad/param norm = 1.7001e-01, time/batch = 17.8755s	
16520/30300 (epoch 27.261), train_loss = 1.25422627, grad/param norm = 1.5705e-01, time/batch = 18.0471s	
16521/30300 (epoch 27.262), train_loss = 1.11529403, grad/param norm = 1.5921e-01, time/batch = 18.5387s	
16522/30300 (epoch 27.264), train_loss = 1.15272610, grad/param norm = 1.6375e-01, time/batch = 17.7890s	
16523/30300 (epoch 27.266), train_loss = 1.07456171, grad/param norm = 1.4218e-01, time/batch = 18.7153s	
16524/30300 (epoch 27.267), train_loss = 1.32924199, grad/param norm = 1.9638e-01, time/batch = 18.7222s	
16525/30300 (epoch 27.269), train_loss = 1.15873854, grad/param norm = 1.5956e-01, time/batch = 17.9740s	
16526/30300 (epoch 27.271), train_loss = 1.20265937, grad/param norm = 1.5874e-01, time/batch = 17.8731s	
16527/30300 (epoch 27.272), train_loss = 1.15606944, grad/param norm = 1.8534e-01, time/batch = 18.5491s	
16528/30300 (epoch 27.274), train_loss = 1.23140583, grad/param norm = 1.6947e-01, time/batch = 18.7784s	
16529/30300 (epoch 27.276), train_loss = 1.19277754, grad/param norm = 1.7580e-01, time/batch = 18.7090s	
16530/30300 (epoch 27.277), train_loss = 1.01977572, grad/param norm = 1.4928e-01, time/batch = 18.1235s	
16531/30300 (epoch 27.279), train_loss = 1.17602628, grad/param norm = 1.8722e-01, time/batch = 18.5878s	
16532/30300 (epoch 27.281), train_loss = 1.24879922, grad/param norm = 1.8957e-01, time/batch = 18.4613s	
16533/30300 (epoch 27.282), train_loss = 1.15325031, grad/param norm = 1.3900e-01, time/batch = 19.3610s	
16534/30300 (epoch 27.284), train_loss = 1.26042937, grad/param norm = 2.0968e-01, time/batch = 19.3816s	
16535/30300 (epoch 27.285), train_loss = 1.21408271, grad/param norm = 1.5606e-01, time/batch = 31.4320s	
16536/30300 (epoch 27.287), train_loss = 1.14916333, grad/param norm = 1.7008e-01, time/batch = 18.8793s	
16537/30300 (epoch 27.289), train_loss = 1.24496657, grad/param norm = 1.6912e-01, time/batch = 18.7855s	
16538/30300 (epoch 27.290), train_loss = 0.91885137, grad/param norm = 1.4284e-01, time/batch = 16.8608s	
16539/30300 (epoch 27.292), train_loss = 1.07461392, grad/param norm = 1.6493e-01, time/batch = 18.1278s	
16540/30300 (epoch 27.294), train_loss = 1.23645892, grad/param norm = 1.9033e-01, time/batch = 18.7772s	
16541/30300 (epoch 27.295), train_loss = 1.10952248, grad/param norm = 1.5621e-01, time/batch = 18.3646s	
16542/30300 (epoch 27.297), train_loss = 1.10427653, grad/param norm = 1.5729e-01, time/batch = 19.2922s	
16543/30300 (epoch 27.299), train_loss = 1.13114117, grad/param norm = 1.5293e-01, time/batch = 19.6220s	
16544/30300 (epoch 27.300), train_loss = 1.08676234, grad/param norm = 1.5181e-01, time/batch = 17.7889s	
16545/30300 (epoch 27.302), train_loss = 1.18696013, grad/param norm = 1.6944e-01, time/batch = 19.2882s	
16546/30300 (epoch 27.304), train_loss = 1.06293088, grad/param norm = 1.5541e-01, time/batch = 19.1398s	
16547/30300 (epoch 27.305), train_loss = 1.11574585, grad/param norm = 1.4406e-01, time/batch = 17.1250s	
16548/30300 (epoch 27.307), train_loss = 1.20934911, grad/param norm = 1.3626e-01, time/batch = 18.7926s	
16549/30300 (epoch 27.309), train_loss = 1.19812092, grad/param norm = 1.6315e-01, time/batch = 19.4597s	
16550/30300 (epoch 27.310), train_loss = 1.14635020, grad/param norm = 1.4958e-01, time/batch = 18.1017s	
16551/30300 (epoch 27.312), train_loss = 1.27821866, grad/param norm = 1.5325e-01, time/batch = 18.2082s	
16552/30300 (epoch 27.314), train_loss = 1.15695588, grad/param norm = 1.6533e-01, time/batch = 19.0444s	
16553/30300 (epoch 27.315), train_loss = 1.12846653, grad/param norm = 1.6646e-01, time/batch = 18.5452s	
16554/30300 (epoch 27.317), train_loss = 1.18089725, grad/param norm = 1.5793e-01, time/batch = 17.5500s	
16555/30300 (epoch 27.318), train_loss = 1.23219415, grad/param norm = 1.6239e-01, time/batch = 19.2268s	
16556/30300 (epoch 27.320), train_loss = 1.21075910, grad/param norm = 1.6276e-01, time/batch = 18.6294s	
16557/30300 (epoch 27.322), train_loss = 1.08718254, grad/param norm = 1.5295e-01, time/batch = 18.9548s	
16558/30300 (epoch 27.323), train_loss = 1.26567058, grad/param norm = 1.7129e-01, time/batch = 17.8091s	
16559/30300 (epoch 27.325), train_loss = 1.14867373, grad/param norm = 1.5764e-01, time/batch = 16.9262s	
16560/30300 (epoch 27.327), train_loss = 1.15254408, grad/param norm = 1.4880e-01, time/batch = 18.2120s	
16561/30300 (epoch 27.328), train_loss = 1.14789228, grad/param norm = 1.4243e-01, time/batch = 18.9720s	
16562/30300 (epoch 27.330), train_loss = 1.20011880, grad/param norm = 1.6441e-01, time/batch = 18.7165s	
16563/30300 (epoch 27.332), train_loss = 1.25554830, grad/param norm = 1.7961e-01, time/batch = 18.2154s	
16564/30300 (epoch 27.333), train_loss = 1.10967162, grad/param norm = 1.7193e-01, time/batch = 19.2066s	
16565/30300 (epoch 27.335), train_loss = 1.04181212, grad/param norm = 1.6199e-01, time/batch = 18.4590s	
16566/30300 (epoch 27.337), train_loss = 1.29375490, grad/param norm = 1.5298e-01, time/batch = 17.3806s	
16567/30300 (epoch 27.338), train_loss = 1.10553666, grad/param norm = 1.5184e-01, time/batch = 17.9586s	
16568/30300 (epoch 27.340), train_loss = 1.08593312, grad/param norm = 1.5684e-01, time/batch = 15.3585s	
16569/30300 (epoch 27.342), train_loss = 1.23771483, grad/param norm = 1.5863e-01, time/batch = 16.8751s	
16570/30300 (epoch 27.343), train_loss = 1.17013609, grad/param norm = 1.6249e-01, time/batch = 18.6213s	
16571/30300 (epoch 27.345), train_loss = 1.19542407, grad/param norm = 1.6347e-01, time/batch = 18.2008s	
16572/30300 (epoch 27.347), train_loss = 1.01706468, grad/param norm = 1.3703e-01, time/batch = 17.5218s	
16573/30300 (epoch 27.348), train_loss = 1.07807928, grad/param norm = 1.6135e-01, time/batch = 16.9520s	
16574/30300 (epoch 27.350), train_loss = 1.12685646, grad/param norm = 1.5385e-01, time/batch = 18.0292s	
16575/30300 (epoch 27.351), train_loss = 1.13865549, grad/param norm = 1.6216e-01, time/batch = 18.8101s	
16576/30300 (epoch 27.353), train_loss = 1.02503376, grad/param norm = 1.5276e-01, time/batch = 17.8844s	
16577/30300 (epoch 27.355), train_loss = 1.11199954, grad/param norm = 1.5057e-01, time/batch = 19.3739s	
16578/30300 (epoch 27.356), train_loss = 1.22709692, grad/param norm = 1.9197e-01, time/batch = 19.2180s	
16579/30300 (epoch 27.358), train_loss = 1.37280511, grad/param norm = 1.5331e-01, time/batch = 18.9627s	
16580/30300 (epoch 27.360), train_loss = 1.10330696, grad/param norm = 1.5045e-01, time/batch = 18.3664s	
16581/30300 (epoch 27.361), train_loss = 1.17061960, grad/param norm = 1.5696e-01, time/batch = 19.7105s	
16582/30300 (epoch 27.363), train_loss = 1.20066936, grad/param norm = 1.6046e-01, time/batch = 19.1452s	
16583/30300 (epoch 27.365), train_loss = 1.03837669, grad/param norm = 1.8908e-01, time/batch = 16.1175s	
16584/30300 (epoch 27.366), train_loss = 1.10530854, grad/param norm = 1.4567e-01, time/batch = 16.5410s	
16585/30300 (epoch 27.368), train_loss = 0.98181767, grad/param norm = 1.3827e-01, time/batch = 18.3876s	
16586/30300 (epoch 27.370), train_loss = 1.06645963, grad/param norm = 1.4945e-01, time/batch = 17.4630s	
16587/30300 (epoch 27.371), train_loss = 1.23827078, grad/param norm = 1.6417e-01, time/batch = 17.7088s	
16588/30300 (epoch 27.373), train_loss = 1.07516535, grad/param norm = 1.4009e-01, time/batch = 19.0390s	
16589/30300 (epoch 27.375), train_loss = 1.07645075, grad/param norm = 1.4666e-01, time/batch = 18.5223s	
16590/30300 (epoch 27.376), train_loss = 1.05493996, grad/param norm = 1.3828e-01, time/batch = 18.8593s	
16591/30300 (epoch 27.378), train_loss = 1.05063798, grad/param norm = 1.5217e-01, time/batch = 18.7916s	
16592/30300 (epoch 27.380), train_loss = 1.29405163, grad/param norm = 1.6605e-01, time/batch = 18.0142s	
16593/30300 (epoch 27.381), train_loss = 0.97590234, grad/param norm = 1.4487e-01, time/batch = 18.0407s	
16594/30300 (epoch 27.383), train_loss = 1.08044950, grad/param norm = 2.0867e-01, time/batch = 18.9682s	
16595/30300 (epoch 27.384), train_loss = 1.21027934, grad/param norm = 1.7648e-01, time/batch = 18.8882s	
16596/30300 (epoch 27.386), train_loss = 1.03792806, grad/param norm = 1.5675e-01, time/batch = 17.8071s	
16597/30300 (epoch 27.388), train_loss = 1.00225994, grad/param norm = 1.4235e-01, time/batch = 18.9016s	
16598/30300 (epoch 27.389), train_loss = 1.11212230, grad/param norm = 1.6576e-01, time/batch = 18.2222s	
16599/30300 (epoch 27.391), train_loss = 1.18213205, grad/param norm = 1.4337e-01, time/batch = 17.5534s	
16600/30300 (epoch 27.393), train_loss = 1.00729149, grad/param norm = 1.5056e-01, time/batch = 18.6371s	
16601/30300 (epoch 27.394), train_loss = 1.18791676, grad/param norm = 1.5682e-01, time/batch = 19.2154s	
16602/30300 (epoch 27.396), train_loss = 1.25558551, grad/param norm = 1.5927e-01, time/batch = 17.0419s	
16603/30300 (epoch 27.398), train_loss = 1.11634342, grad/param norm = 1.6153e-01, time/batch = 18.4461s	
16604/30300 (epoch 27.399), train_loss = 1.10188275, grad/param norm = 1.6311e-01, time/batch = 19.0358s	
16605/30300 (epoch 27.401), train_loss = 1.17233209, grad/param norm = 1.7336e-01, time/batch = 18.5536s	
16606/30300 (epoch 27.403), train_loss = 1.12762388, grad/param norm = 1.7121e-01, time/batch = 17.1974s	
16607/30300 (epoch 27.404), train_loss = 1.08042977, grad/param norm = 1.7904e-01, time/batch = 19.0525s	
16608/30300 (epoch 27.406), train_loss = 1.17080330, grad/param norm = 1.4992e-01, time/batch = 19.3796s	
16609/30300 (epoch 27.408), train_loss = 1.01977678, grad/param norm = 1.5005e-01, time/batch = 17.6975s	
16610/30300 (epoch 27.409), train_loss = 1.00993647, grad/param norm = 1.6148e-01, time/batch = 17.5964s	
16611/30300 (epoch 27.411), train_loss = 1.04945481, grad/param norm = 1.3881e-01, time/batch = 19.1218s	
16612/30300 (epoch 27.413), train_loss = 0.95233007, grad/param norm = 1.5449e-01, time/batch = 17.0341s	
16613/30300 (epoch 27.414), train_loss = 1.20284011, grad/param norm = 1.6389e-01, time/batch = 19.0430s	
16614/30300 (epoch 27.416), train_loss = 1.07343894, grad/param norm = 1.5325e-01, time/batch = 19.5390s	
16615/30300 (epoch 27.417), train_loss = 1.04513483, grad/param norm = 1.5323e-01, time/batch = 17.7864s	
16616/30300 (epoch 27.419), train_loss = 1.02397407, grad/param norm = 1.4050e-01, time/batch = 17.1939s	
16617/30300 (epoch 27.421), train_loss = 1.07073754, grad/param norm = 1.6635e-01, time/batch = 20.0392s	
16618/30300 (epoch 27.422), train_loss = 1.13591622, grad/param norm = 1.5107e-01, time/batch = 19.0382s	
16619/30300 (epoch 27.424), train_loss = 1.13293742, grad/param norm = 1.5484e-01, time/batch = 18.3507s	
16620/30300 (epoch 27.426), train_loss = 1.09345198, grad/param norm = 1.7477e-01, time/batch = 18.9710s	
16621/30300 (epoch 27.427), train_loss = 1.09224197, grad/param norm = 1.6134e-01, time/batch = 19.7958s	
16622/30300 (epoch 27.429), train_loss = 1.12112584, grad/param norm = 1.4881e-01, time/batch = 18.0279s	
16623/30300 (epoch 27.431), train_loss = 1.19061865, grad/param norm = 1.5109e-01, time/batch = 18.0514s	
16624/30300 (epoch 27.432), train_loss = 1.11240826, grad/param norm = 1.4865e-01, time/batch = 20.0334s	
16625/30300 (epoch 27.434), train_loss = 1.01404463, grad/param norm = 1.4792e-01, time/batch = 17.9781s	
16626/30300 (epoch 27.436), train_loss = 1.28532645, grad/param norm = 1.7121e-01, time/batch = 18.7181s	
16627/30300 (epoch 27.437), train_loss = 1.03059718, grad/param norm = 1.5057e-01, time/batch = 20.0428s	
16628/30300 (epoch 27.439), train_loss = 1.06373800, grad/param norm = 1.4893e-01, time/batch = 17.4556s	
16629/30300 (epoch 27.441), train_loss = 1.09946215, grad/param norm = 1.4673e-01, time/batch = 18.8940s	
16630/30300 (epoch 27.442), train_loss = 1.04454763, grad/param norm = 1.7733e-01, time/batch = 18.2875s	
16631/30300 (epoch 27.444), train_loss = 0.95121359, grad/param norm = 1.4805e-01, time/batch = 18.9475s	
16632/30300 (epoch 27.446), train_loss = 1.08998997, grad/param norm = 1.4311e-01, time/batch = 17.3602s	
16633/30300 (epoch 27.447), train_loss = 1.12382665, grad/param norm = 1.5382e-01, time/batch = 16.2147s	
16634/30300 (epoch 27.449), train_loss = 1.04006742, grad/param norm = 1.4303e-01, time/batch = 17.7888s	
16635/30300 (epoch 27.450), train_loss = 1.17760675, grad/param norm = 1.5222e-01, time/batch = 16.7802s	
16636/30300 (epoch 27.452), train_loss = 1.23799074, grad/param norm = 1.6995e-01, time/batch = 16.9674s	
16637/30300 (epoch 27.454), train_loss = 1.18487887, grad/param norm = 1.4372e-01, time/batch = 16.5402s	
16638/30300 (epoch 27.455), train_loss = 1.13261241, grad/param norm = 1.6567e-01, time/batch = 17.7772s	
16639/30300 (epoch 27.457), train_loss = 1.10646177, grad/param norm = 1.6159e-01, time/batch = 17.9503s	
16640/30300 (epoch 27.459), train_loss = 1.18903160, grad/param norm = 1.6232e-01, time/batch = 18.5482s	
16641/30300 (epoch 27.460), train_loss = 1.15867354, grad/param norm = 1.4836e-01, time/batch = 18.1193s	
16642/30300 (epoch 27.462), train_loss = 1.19395516, grad/param norm = 1.5400e-01, time/batch = 18.1318s	
16643/30300 (epoch 27.464), train_loss = 0.95220096, grad/param norm = 1.6165e-01, time/batch = 18.2999s	
16644/30300 (epoch 27.465), train_loss = 0.95436616, grad/param norm = 1.4235e-01, time/batch = 17.7764s	
16645/30300 (epoch 27.467), train_loss = 0.92984673, grad/param norm = 1.3479e-01, time/batch = 17.5376s	
16646/30300 (epoch 27.469), train_loss = 1.04932675, grad/param norm = 1.5267e-01, time/batch = 18.2105s	
16647/30300 (epoch 27.470), train_loss = 1.07141251, grad/param norm = 1.5501e-01, time/batch = 19.4627s	
16648/30300 (epoch 27.472), train_loss = 1.07844416, grad/param norm = 1.3877e-01, time/batch = 18.2003s	
16649/30300 (epoch 27.474), train_loss = 1.08556782, grad/param norm = 1.9723e-01, time/batch = 18.7834s	
16650/30300 (epoch 27.475), train_loss = 1.06772118, grad/param norm = 1.4665e-01, time/batch = 19.0424s	
16651/30300 (epoch 27.477), train_loss = 1.11980619, grad/param norm = 1.5683e-01, time/batch = 18.6177s	
16652/30300 (epoch 27.479), train_loss = 1.09682256, grad/param norm = 1.6261e-01, time/batch = 17.7892s	
16653/30300 (epoch 27.480), train_loss = 1.14013966, grad/param norm = 1.4215e-01, time/batch = 18.8924s	
16654/30300 (epoch 27.482), train_loss = 1.17406690, grad/param norm = 1.4591e-01, time/batch = 19.2980s	
16655/30300 (epoch 27.483), train_loss = 1.08529422, grad/param norm = 1.5606e-01, time/batch = 17.2964s	
16656/30300 (epoch 27.485), train_loss = 1.12968280, grad/param norm = 1.6349e-01, time/batch = 16.9485s	
16657/30300 (epoch 27.487), train_loss = 1.21882173, grad/param norm = 1.6664e-01, time/batch = 19.6235s	
16658/30300 (epoch 27.488), train_loss = 1.21643553, grad/param norm = 1.4020e-01, time/batch = 18.5432s	
16659/30300 (epoch 27.490), train_loss = 1.01638459, grad/param norm = 1.5655e-01, time/batch = 19.3700s	
16660/30300 (epoch 27.492), train_loss = 1.09579517, grad/param norm = 1.6758e-01, time/batch = 18.9315s	
16661/30300 (epoch 27.493), train_loss = 1.09778818, grad/param norm = 1.4411e-01, time/batch = 18.3671s	
16662/30300 (epoch 27.495), train_loss = 1.08998187, grad/param norm = 1.4391e-01, time/batch = 18.8718s	
16663/30300 (epoch 27.497), train_loss = 1.12020575, grad/param norm = 1.4212e-01, time/batch = 19.4614s	
16664/30300 (epoch 27.498), train_loss = 1.17982018, grad/param norm = 1.5722e-01, time/batch = 17.3615s	
16665/30300 (epoch 27.500), train_loss = 1.12516047, grad/param norm = 1.7270e-01, time/batch = 18.3621s	
16666/30300 (epoch 27.502), train_loss = 1.12727361, grad/param norm = 1.8126e-01, time/batch = 17.6007s	
16667/30300 (epoch 27.503), train_loss = 1.22078789, grad/param norm = 1.5497e-01, time/batch = 19.1136s	
16668/30300 (epoch 27.505), train_loss = 1.03151078, grad/param norm = 1.3578e-01, time/batch = 18.0336s	
16669/30300 (epoch 27.507), train_loss = 1.04751053, grad/param norm = 1.7057e-01, time/batch = 19.1981s	
16670/30300 (epoch 27.508), train_loss = 1.08605786, grad/param norm = 1.7634e-01, time/batch = 19.0485s	
16671/30300 (epoch 27.510), train_loss = 1.22642483, grad/param norm = 1.8378e-01, time/batch = 18.0383s	
16672/30300 (epoch 27.512), train_loss = 1.07096372, grad/param norm = 1.5073e-01, time/batch = 18.9508s	
16673/30300 (epoch 27.513), train_loss = 1.13779676, grad/param norm = 1.4517e-01, time/batch = 19.7744s	
16674/30300 (epoch 27.515), train_loss = 1.12473587, grad/param norm = 1.4732e-01, time/batch = 18.1127s	
16675/30300 (epoch 27.517), train_loss = 0.93388687, grad/param norm = 1.3465e-01, time/batch = 19.2001s	
16676/30300 (epoch 27.518), train_loss = 1.20947023, grad/param norm = 1.7773e-01, time/batch = 18.2826s	
16677/30300 (epoch 27.520), train_loss = 1.17786273, grad/param norm = 1.9227e-01, time/batch = 17.9539s	
16678/30300 (epoch 27.521), train_loss = 1.05649705, grad/param norm = 1.9386e-01, time/batch = 19.4595s	
16679/30300 (epoch 27.523), train_loss = 1.28197873, grad/param norm = 1.9919e-01, time/batch = 19.3779s	
16680/30300 (epoch 27.525), train_loss = 1.05645246, grad/param norm = 1.6704e-01, time/batch = 18.1121s	
16681/30300 (epoch 27.526), train_loss = 1.12686181, grad/param norm = 1.6732e-01, time/batch = 17.4355s	
16682/30300 (epoch 27.528), train_loss = 1.01591052, grad/param norm = 1.5478e-01, time/batch = 18.7143s	
16683/30300 (epoch 27.530), train_loss = 1.00311881, grad/param norm = 1.5161e-01, time/batch = 18.4453s	
16684/30300 (epoch 27.531), train_loss = 1.15986438, grad/param norm = 1.6426e-01, time/batch = 16.6244s	
16685/30300 (epoch 27.533), train_loss = 1.12162930, grad/param norm = 1.5332e-01, time/batch = 17.2744s	
16686/30300 (epoch 27.535), train_loss = 1.06932476, grad/param norm = 1.3833e-01, time/batch = 19.4642s	
16687/30300 (epoch 27.536), train_loss = 1.16692915, grad/param norm = 1.9242e-01, time/batch = 17.2848s	
16688/30300 (epoch 27.538), train_loss = 1.01202355, grad/param norm = 1.8613e-01, time/batch = 17.7947s	
16689/30300 (epoch 27.540), train_loss = 1.05316288, grad/param norm = 1.8927e-01, time/batch = 18.4551s	
16690/30300 (epoch 27.541), train_loss = 1.13541836, grad/param norm = 1.8711e-01, time/batch = 18.7886s	
16691/30300 (epoch 27.543), train_loss = 1.10953084, grad/param norm = 1.6685e-01, time/batch = 17.8858s	
16692/30300 (epoch 27.545), train_loss = 1.13068505, grad/param norm = 1.7087e-01, time/batch = 19.4569s	
16693/30300 (epoch 27.546), train_loss = 1.32596013, grad/param norm = 1.5620e-01, time/batch = 18.6265s	
16694/30300 (epoch 27.548), train_loss = 1.06531532, grad/param norm = 1.3933e-01, time/batch = 17.0175s	
16695/30300 (epoch 27.550), train_loss = 1.19068469, grad/param norm = 2.0475e-01, time/batch = 18.5467s	
16696/30300 (epoch 27.551), train_loss = 1.06614483, grad/param norm = 1.6313e-01, time/batch = 19.7038s	
16697/30300 (epoch 27.553), train_loss = 1.07423755, grad/param norm = 1.4612e-01, time/batch = 18.0213s	
16698/30300 (epoch 27.554), train_loss = 1.15111586, grad/param norm = 2.2312e-01, time/batch = 18.9495s	
16699/30300 (epoch 27.556), train_loss = 1.17141097, grad/param norm = 1.5179e-01, time/batch = 18.8804s	
16700/30300 (epoch 27.558), train_loss = 1.19925554, grad/param norm = 1.6873e-01, time/batch = 17.5464s	
16701/30300 (epoch 27.559), train_loss = 1.14566270, grad/param norm = 1.7131e-01, time/batch = 19.0314s	
16702/30300 (epoch 27.561), train_loss = 0.94195200, grad/param norm = 1.4583e-01, time/batch = 18.0435s	
16703/30300 (epoch 27.563), train_loss = 1.03162751, grad/param norm = 1.6138e-01, time/batch = 17.4428s	
16704/30300 (epoch 27.564), train_loss = 1.04443688, grad/param norm = 1.3967e-01, time/batch = 18.7912s	
16705/30300 (epoch 27.566), train_loss = 1.10689212, grad/param norm = 1.5119e-01, time/batch = 18.9518s	
16706/30300 (epoch 27.568), train_loss = 0.96568359, grad/param norm = 1.8485e-01, time/batch = 19.2025s	
16707/30300 (epoch 27.569), train_loss = 1.13184931, grad/param norm = 1.5650e-01, time/batch = 18.2935s	
16708/30300 (epoch 27.571), train_loss = 1.15429666, grad/param norm = 1.7314e-01, time/batch = 18.7148s	
16709/30300 (epoch 27.573), train_loss = 1.15332356, grad/param norm = 1.5280e-01, time/batch = 18.7085s	
16710/30300 (epoch 27.574), train_loss = 1.16561912, grad/param norm = 1.4528e-01, time/batch = 17.9346s	
16711/30300 (epoch 27.576), train_loss = 1.08051146, grad/param norm = 1.4249e-01, time/batch = 19.5440s	
16712/30300 (epoch 27.578), train_loss = 0.98032313, grad/param norm = 1.4269e-01, time/batch = 17.8992s	
16713/30300 (epoch 27.579), train_loss = 1.14485481, grad/param norm = 1.7374e-01, time/batch = 17.6260s	
16714/30300 (epoch 27.581), train_loss = 1.24801956, grad/param norm = 1.6051e-01, time/batch = 16.8651s	
16715/30300 (epoch 27.583), train_loss = 1.28126631, grad/param norm = 1.6795e-01, time/batch = 19.6281s	
16716/30300 (epoch 27.584), train_loss = 1.22569819, grad/param norm = 1.5506e-01, time/batch = 17.2263s	
16717/30300 (epoch 27.586), train_loss = 1.09357853, grad/param norm = 1.6720e-01, time/batch = 18.1377s	
16718/30300 (epoch 27.587), train_loss = 1.11286526, grad/param norm = 1.6537e-01, time/batch = 18.8735s	
16719/30300 (epoch 27.589), train_loss = 1.03740156, grad/param norm = 1.4956e-01, time/batch = 17.7080s	
16720/30300 (epoch 27.591), train_loss = 1.15708460, grad/param norm = 1.4923e-01, time/batch = 18.3794s	
16721/30300 (epoch 27.592), train_loss = 1.08813803, grad/param norm = 1.3897e-01, time/batch = 19.2883s	
16722/30300 (epoch 27.594), train_loss = 1.13381230, grad/param norm = 1.6148e-01, time/batch = 19.1277s	
16723/30300 (epoch 27.596), train_loss = 1.03476587, grad/param norm = 1.5011e-01, time/batch = 18.6290s	
16724/30300 (epoch 27.597), train_loss = 1.05521807, grad/param norm = 1.7074e-01, time/batch = 19.0452s	
16725/30300 (epoch 27.599), train_loss = 0.93747768, grad/param norm = 1.4196e-01, time/batch = 19.5384s	
16726/30300 (epoch 27.601), train_loss = 1.12638911, grad/param norm = 1.4651e-01, time/batch = 18.6179s	
16727/30300 (epoch 27.602), train_loss = 1.11383568, grad/param norm = 1.5507e-01, time/batch = 18.4751s	
16728/30300 (epoch 27.604), train_loss = 1.04121428, grad/param norm = 1.4922e-01, time/batch = 19.2983s	
16729/30300 (epoch 27.606), train_loss = 1.07166731, grad/param norm = 1.9011e-01, time/batch = 29.1819s	
16730/30300 (epoch 27.607), train_loss = 1.20239257, grad/param norm = 1.7583e-01, time/batch = 20.9533s	
16731/30300 (epoch 27.609), train_loss = 1.32160891, grad/param norm = 1.7245e-01, time/batch = 18.3784s	
16732/30300 (epoch 27.611), train_loss = 1.06103031, grad/param norm = 1.5101e-01, time/batch = 16.2843s	
16733/30300 (epoch 27.612), train_loss = 1.02209416, grad/param norm = 1.5855e-01, time/batch = 17.8522s	
16734/30300 (epoch 27.614), train_loss = 1.08365593, grad/param norm = 1.4959e-01, time/batch = 16.9688s	
16735/30300 (epoch 27.616), train_loss = 1.17122591, grad/param norm = 2.0345e-01, time/batch = 16.4262s	
16736/30300 (epoch 27.617), train_loss = 1.14113465, grad/param norm = 1.6108e-01, time/batch = 18.0372s	
16737/30300 (epoch 27.619), train_loss = 0.94693283, grad/param norm = 1.4865e-01, time/batch = 18.1266s	
16738/30300 (epoch 27.620), train_loss = 1.16536599, grad/param norm = 1.6537e-01, time/batch = 18.5397s	
16739/30300 (epoch 27.622), train_loss = 1.12173298, grad/param norm = 1.8173e-01, time/batch = 17.9435s	
16740/30300 (epoch 27.624), train_loss = 1.07463683, grad/param norm = 1.5428e-01, time/batch = 18.4608s	
16741/30300 (epoch 27.625), train_loss = 1.07597611, grad/param norm = 1.7864e-01, time/batch = 18.5483s	
16742/30300 (epoch 27.627), train_loss = 1.23562515, grad/param norm = 1.6692e-01, time/batch = 18.2168s	
16743/30300 (epoch 27.629), train_loss = 1.25542866, grad/param norm = 1.6000e-01, time/batch = 19.4542s	
16744/30300 (epoch 27.630), train_loss = 1.11859899, grad/param norm = 1.4934e-01, time/batch = 19.2126s	
16745/30300 (epoch 27.632), train_loss = 1.20214400, grad/param norm = 1.7266e-01, time/batch = 16.9640s	
16746/30300 (epoch 27.634), train_loss = 1.04186655, grad/param norm = 1.3841e-01, time/batch = 18.7059s	
16747/30300 (epoch 27.635), train_loss = 1.17709342, grad/param norm = 1.6838e-01, time/batch = 18.5583s	
16748/30300 (epoch 27.637), train_loss = 1.19898635, grad/param norm = 1.7671e-01, time/batch = 17.7156s	
16749/30300 (epoch 27.639), train_loss = 1.07773362, grad/param norm = 1.5113e-01, time/batch = 18.2105s	
16750/30300 (epoch 27.640), train_loss = 1.23804315, grad/param norm = 1.9485e-01, time/batch = 18.6368s	
16751/30300 (epoch 27.642), train_loss = 1.08753687, grad/param norm = 1.3925e-01, time/batch = 18.6205s	
16752/30300 (epoch 27.644), train_loss = 1.17377112, grad/param norm = 1.4756e-01, time/batch = 17.6319s	
16753/30300 (epoch 27.645), train_loss = 1.05693922, grad/param norm = 1.5379e-01, time/batch = 19.2051s	
16754/30300 (epoch 27.647), train_loss = 1.13832139, grad/param norm = 1.4540e-01, time/batch = 18.4479s	
16755/30300 (epoch 27.649), train_loss = 1.10159147, grad/param norm = 1.8707e-01, time/batch = 16.6498s	
16756/30300 (epoch 27.650), train_loss = 1.11150206, grad/param norm = 1.5183e-01, time/batch = 18.6377s	
16757/30300 (epoch 27.652), train_loss = 1.09617722, grad/param norm = 1.7361e-01, time/batch = 18.8027s	
16758/30300 (epoch 27.653), train_loss = 1.31833451, grad/param norm = 1.7534e-01, time/batch = 17.5365s	
16759/30300 (epoch 27.655), train_loss = 1.04422533, grad/param norm = 1.4964e-01, time/batch = 19.2228s	
16760/30300 (epoch 27.657), train_loss = 1.05015344, grad/param norm = 1.6491e-01, time/batch = 18.8094s	
16761/30300 (epoch 27.658), train_loss = 1.03554354, grad/param norm = 1.4364e-01, time/batch = 17.5369s	
16762/30300 (epoch 27.660), train_loss = 1.11729888, grad/param norm = 1.5833e-01, time/batch = 19.0548s	
16763/30300 (epoch 27.662), train_loss = 1.11466717, grad/param norm = 1.6948e-01, time/batch = 18.8826s	
16764/30300 (epoch 27.663), train_loss = 1.14906008, grad/param norm = 1.6327e-01, time/batch = 17.8014s	
16765/30300 (epoch 27.665), train_loss = 1.06655287, grad/param norm = 1.6999e-01, time/batch = 18.6356s	
16766/30300 (epoch 27.667), train_loss = 1.18809767, grad/param norm = 1.5105e-01, time/batch = 19.2981s	
16767/30300 (epoch 27.668), train_loss = 1.21154099, grad/param norm = 1.7185e-01, time/batch = 18.0482s	
16768/30300 (epoch 27.670), train_loss = 1.24641439, grad/param norm = 1.7734e-01, time/batch = 18.5231s	
16769/30300 (epoch 27.672), train_loss = 1.13237214, grad/param norm = 1.6542e-01, time/batch = 17.6377s	
16770/30300 (epoch 27.673), train_loss = 1.18085166, grad/param norm = 1.8073e-01, time/batch = 18.1340s	
16771/30300 (epoch 27.675), train_loss = 1.06848181, grad/param norm = 1.5143e-01, time/batch = 17.6310s	
16772/30300 (epoch 27.677), train_loss = 1.07523618, grad/param norm = 1.4344e-01, time/batch = 17.3947s	
16773/30300 (epoch 27.678), train_loss = 1.06291960, grad/param norm = 1.4736e-01, time/batch = 16.7765s	
16774/30300 (epoch 27.680), train_loss = 0.93607281, grad/param norm = 1.3780e-01, time/batch = 18.0517s	
16775/30300 (epoch 27.682), train_loss = 1.10890562, grad/param norm = 1.6193e-01, time/batch = 18.7004s	
16776/30300 (epoch 27.683), train_loss = 1.22743993, grad/param norm = 1.5093e-01, time/batch = 19.2153s	
16777/30300 (epoch 27.685), train_loss = 1.20876162, grad/param norm = 1.8207e-01, time/batch = 18.3719s	
16778/30300 (epoch 27.686), train_loss = 1.07623726, grad/param norm = 1.3904e-01, time/batch = 16.9632s	
16779/30300 (epoch 27.688), train_loss = 1.12756104, grad/param norm = 1.5405e-01, time/batch = 19.7941s	
16780/30300 (epoch 27.690), train_loss = 1.05976776, grad/param norm = 1.6374e-01, time/batch = 19.7952s	
16781/30300 (epoch 27.691), train_loss = 1.14757286, grad/param norm = 1.4606e-01, time/batch = 17.2972s	
16782/30300 (epoch 27.693), train_loss = 1.42187399, grad/param norm = 1.7017e-01, time/batch = 19.3637s	
16783/30300 (epoch 27.695), train_loss = 1.21060803, grad/param norm = 1.5818e-01, time/batch = 18.7880s	
16784/30300 (epoch 27.696), train_loss = 1.19788588, grad/param norm = 1.9685e-01, time/batch = 18.1311s	
16785/30300 (epoch 27.698), train_loss = 1.05964940, grad/param norm = 1.5209e-01, time/batch = 18.9395s	
16786/30300 (epoch 27.700), train_loss = 1.05571497, grad/param norm = 1.6874e-01, time/batch = 18.6201s	
16787/30300 (epoch 27.701), train_loss = 0.96760022, grad/param norm = 1.3795e-01, time/batch = 18.0517s	
16788/30300 (epoch 27.703), train_loss = 1.12445548, grad/param norm = 1.3891e-01, time/batch = 18.6217s	
16789/30300 (epoch 27.705), train_loss = 1.04339392, grad/param norm = 1.4373e-01, time/batch = 18.8854s	
16790/30300 (epoch 27.706), train_loss = 1.16748669, grad/param norm = 1.6492e-01, time/batch = 16.6221s	
16791/30300 (epoch 27.708), train_loss = 1.11460315, grad/param norm = 1.6353e-01, time/batch = 18.4342s	
16792/30300 (epoch 27.710), train_loss = 1.08892468, grad/param norm = 1.5665e-01, time/batch = 17.9205s	
16793/30300 (epoch 27.711), train_loss = 1.03728426, grad/param norm = 1.4499e-01, time/batch = 19.5496s	
16794/30300 (epoch 27.713), train_loss = 1.03075830, grad/param norm = 1.6242e-01, time/batch = 18.5215s	
16795/30300 (epoch 27.715), train_loss = 1.06236178, grad/param norm = 1.5260e-01, time/batch = 17.1427s	
16796/30300 (epoch 27.716), train_loss = 1.20322991, grad/param norm = 1.4757e-01, time/batch = 19.5446s	
16797/30300 (epoch 27.718), train_loss = 1.22961968, grad/param norm = 1.6043e-01, time/batch = 17.5509s	
16798/30300 (epoch 27.719), train_loss = 1.06779488, grad/param norm = 1.7728e-01, time/batch = 19.2832s	
16799/30300 (epoch 27.721), train_loss = 1.10178483, grad/param norm = 1.5922e-01, time/batch = 18.5579s	
16800/30300 (epoch 27.723), train_loss = 1.06014157, grad/param norm = 1.5565e-01, time/batch = 18.4634s	
16801/30300 (epoch 27.724), train_loss = 1.15936596, grad/param norm = 1.9740e-01, time/batch = 18.7850s	
16802/30300 (epoch 27.726), train_loss = 1.48194309, grad/param norm = 2.0049e-01, time/batch = 17.8909s	
16803/30300 (epoch 27.728), train_loss = 1.17193002, grad/param norm = 1.5749e-01, time/batch = 18.1918s	
16804/30300 (epoch 27.729), train_loss = 1.09650267, grad/param norm = 1.7055e-01, time/batch = 18.2942s	
16805/30300 (epoch 27.731), train_loss = 1.13982918, grad/param norm = 1.7414e-01, time/batch = 19.1334s	
16806/30300 (epoch 27.733), train_loss = 1.13462650, grad/param norm = 1.5703e-01, time/batch = 18.4726s	
16807/30300 (epoch 27.734), train_loss = 1.21332802, grad/param norm = 1.4668e-01, time/batch = 18.6455s	
16808/30300 (epoch 27.736), train_loss = 1.11135094, grad/param norm = 1.5551e-01, time/batch = 18.7043s	
16809/30300 (epoch 27.738), train_loss = 1.05412587, grad/param norm = 1.4064e-01, time/batch = 18.8112s	
16810/30300 (epoch 27.739), train_loss = 1.18750828, grad/param norm = 1.4926e-01, time/batch = 18.8626s	
16811/30300 (epoch 27.741), train_loss = 1.25801890, grad/param norm = 1.4481e-01, time/batch = 19.2955s	
16812/30300 (epoch 27.743), train_loss = 1.12121294, grad/param norm = 1.6207e-01, time/batch = 18.1025s	
16813/30300 (epoch 27.744), train_loss = 1.14585809, grad/param norm = 1.4715e-01, time/batch = 18.2083s	
16814/30300 (epoch 27.746), train_loss = 1.07182653, grad/param norm = 1.4819e-01, time/batch = 18.6996s	
16815/30300 (epoch 27.748), train_loss = 1.09683966, grad/param norm = 1.8287e-01, time/batch = 16.6219s	
16816/30300 (epoch 27.749), train_loss = 1.17156608, grad/param norm = 1.7387e-01, time/batch = 18.1373s	
16817/30300 (epoch 27.751), train_loss = 1.12509130, grad/param norm = 1.6775e-01, time/batch = 18.7936s	
16818/30300 (epoch 27.752), train_loss = 1.08914527, grad/param norm = 1.6060e-01, time/batch = 18.4635s	
16819/30300 (epoch 27.754), train_loss = 1.06181690, grad/param norm = 1.4425e-01, time/batch = 18.6231s	
16820/30300 (epoch 27.756), train_loss = 1.08412385, grad/param norm = 1.5263e-01, time/batch = 17.9589s	
16821/30300 (epoch 27.757), train_loss = 1.10318372, grad/param norm = 1.6471e-01, time/batch = 18.1311s	
16822/30300 (epoch 27.759), train_loss = 1.15682628, grad/param norm = 1.4678e-01, time/batch = 19.5623s	
16823/30300 (epoch 27.761), train_loss = 0.96544854, grad/param norm = 1.3715e-01, time/batch = 17.8712s	
16824/30300 (epoch 27.762), train_loss = 1.00609071, grad/param norm = 1.4864e-01, time/batch = 16.7935s	
16825/30300 (epoch 27.764), train_loss = 1.10856608, grad/param norm = 1.5685e-01, time/batch = 18.9772s	
16826/30300 (epoch 27.766), train_loss = 1.22780623, grad/param norm = 1.7061e-01, time/batch = 17.9511s	
16827/30300 (epoch 27.767), train_loss = 1.20459332, grad/param norm = 2.0792e-01, time/batch = 18.6289s	
16828/30300 (epoch 27.769), train_loss = 1.14326765, grad/param norm = 1.5985e-01, time/batch = 19.4541s	
16829/30300 (epoch 27.771), train_loss = 1.07530817, grad/param norm = 1.7749e-01, time/batch = 18.0441s	
16830/30300 (epoch 27.772), train_loss = 1.17027247, grad/param norm = 1.6281e-01, time/batch = 18.7963s	
16831/30300 (epoch 27.774), train_loss = 1.25833151, grad/param norm = 1.6231e-01, time/batch = 16.8823s	
16832/30300 (epoch 27.776), train_loss = 1.11613897, grad/param norm = 1.6759e-01, time/batch = 18.2573s	
16833/30300 (epoch 27.777), train_loss = 1.23222173, grad/param norm = 1.5383e-01, time/batch = 17.7080s	
16834/30300 (epoch 27.779), train_loss = 1.24149477, grad/param norm = 1.6940e-01, time/batch = 18.9632s	
16835/30300 (epoch 27.781), train_loss = 1.13500275, grad/param norm = 1.6378e-01, time/batch = 18.9589s	
16836/30300 (epoch 27.782), train_loss = 1.08181250, grad/param norm = 1.5970e-01, time/batch = 18.3030s	
16837/30300 (epoch 27.784), train_loss = 1.06577313, grad/param norm = 1.5001e-01, time/batch = 19.0365s	
16838/30300 (epoch 27.785), train_loss = 1.23563263, grad/param norm = 1.7765e-01, time/batch = 19.6160s	
16839/30300 (epoch 27.787), train_loss = 0.94824445, grad/param norm = 1.6431e-01, time/batch = 17.8792s	
16840/30300 (epoch 27.789), train_loss = 1.30952471, grad/param norm = 1.5521e-01, time/batch = 19.2022s	
16841/30300 (epoch 27.790), train_loss = 1.15905878, grad/param norm = 1.8068e-01, time/batch = 19.6164s	
16842/30300 (epoch 27.792), train_loss = 0.96565513, grad/param norm = 1.6288e-01, time/batch = 17.9287s	
16843/30300 (epoch 27.794), train_loss = 1.12642468, grad/param norm = 1.7523e-01, time/batch = 0.6913s	
16844/30300 (epoch 27.795), train_loss = 1.02797225, grad/param norm = 1.4302e-01, time/batch = 0.6831s	
16845/30300 (epoch 27.797), train_loss = 1.27508752, grad/param norm = 1.6854e-01, time/batch = 0.6857s	
16846/30300 (epoch 27.799), train_loss = 1.19246398, grad/param norm = 1.8433e-01, time/batch = 0.6891s	
16847/30300 (epoch 27.800), train_loss = 1.19675167, grad/param norm = 1.5922e-01, time/batch = 0.6987s	
16848/30300 (epoch 27.802), train_loss = 1.37863835, grad/param norm = 1.7484e-01, time/batch = 0.6884s	
16849/30300 (epoch 27.804), train_loss = 1.21218450, grad/param norm = 1.8126e-01, time/batch = 0.6984s	
16850/30300 (epoch 27.805), train_loss = 1.27584238, grad/param norm = 1.7245e-01, time/batch = 0.9390s	
16851/30300 (epoch 27.807), train_loss = 1.10547055, grad/param norm = 1.6886e-01, time/batch = 1.0204s	
16852/30300 (epoch 27.809), train_loss = 1.20007277, grad/param norm = 1.6770e-01, time/batch = 1.0245s	
16853/30300 (epoch 27.810), train_loss = 1.19375353, grad/param norm = 1.7640e-01, time/batch = 1.0295s	
16854/30300 (epoch 27.812), train_loss = 1.06048004, grad/param norm = 1.5666e-01, time/batch = 1.0183s	
16855/30300 (epoch 27.814), train_loss = 1.12726280, grad/param norm = 1.5572e-01, time/batch = 1.8157s	
16856/30300 (epoch 27.815), train_loss = 1.14600512, grad/param norm = 1.9000e-01, time/batch = 1.9043s	
16857/30300 (epoch 27.817), train_loss = 1.22716486, grad/param norm = 1.7526e-01, time/batch = 7.5148s	
16858/30300 (epoch 27.818), train_loss = 1.16539854, grad/param norm = 1.6231e-01, time/batch = 19.9553s	
16859/30300 (epoch 27.820), train_loss = 1.29847458, grad/param norm = 1.6738e-01, time/batch = 18.2192s	
16860/30300 (epoch 27.822), train_loss = 1.30464526, grad/param norm = 1.9937e-01, time/batch = 17.8704s	
16861/30300 (epoch 27.823), train_loss = 1.29528455, grad/param norm = 1.8223e-01, time/batch = 16.9473s	
16862/30300 (epoch 27.825), train_loss = 1.26577655, grad/param norm = 1.7379e-01, time/batch = 18.2911s	
16863/30300 (epoch 27.827), train_loss = 0.97904695, grad/param norm = 1.6307e-01, time/batch = 17.3571s	
16864/30300 (epoch 27.828), train_loss = 1.22412761, grad/param norm = 1.6808e-01, time/batch = 18.2770s	
16865/30300 (epoch 27.830), train_loss = 1.17808965, grad/param norm = 1.5883e-01, time/batch = 19.7950s	
16866/30300 (epoch 27.832), train_loss = 1.05292942, grad/param norm = 1.7057e-01, time/batch = 17.7832s	
16867/30300 (epoch 27.833), train_loss = 1.14504090, grad/param norm = 1.5551e-01, time/batch = 19.0251s	
16868/30300 (epoch 27.835), train_loss = 1.06639723, grad/param norm = 1.7966e-01, time/batch = 19.2155s	
16869/30300 (epoch 27.837), train_loss = 1.02170179, grad/param norm = 1.6407e-01, time/batch = 17.6237s	
16870/30300 (epoch 27.838), train_loss = 1.01946624, grad/param norm = 1.4313e-01, time/batch = 19.1292s	
16871/30300 (epoch 27.840), train_loss = 1.21924249, grad/param norm = 1.4586e-01, time/batch = 19.6349s	
16872/30300 (epoch 27.842), train_loss = 1.07532320, grad/param norm = 1.4166e-01, time/batch = 17.9625s	
16873/30300 (epoch 27.843), train_loss = 1.16950048, grad/param norm = 1.6028e-01, time/batch = 19.4638s	
16874/30300 (epoch 27.845), train_loss = 1.18676320, grad/param norm = 1.4512e-01, time/batch = 18.2750s	
16875/30300 (epoch 27.847), train_loss = 1.14420058, grad/param norm = 1.4942e-01, time/batch = 17.8531s	
16876/30300 (epoch 27.848), train_loss = 1.21042177, grad/param norm = 1.6000e-01, time/batch = 18.9536s	
16877/30300 (epoch 27.850), train_loss = 1.14717917, grad/param norm = 1.6284e-01, time/batch = 17.7016s	
16878/30300 (epoch 27.851), train_loss = 1.16347721, grad/param norm = 1.8965e-01, time/batch = 19.2050s	
16879/30300 (epoch 27.853), train_loss = 1.07926400, grad/param norm = 1.4739e-01, time/batch = 18.1324s	
16880/30300 (epoch 27.855), train_loss = 1.07674898, grad/param norm = 1.4278e-01, time/batch = 18.3704s	
16881/30300 (epoch 27.856), train_loss = 1.16134620, grad/param norm = 1.5414e-01, time/batch = 17.9488s	
16882/30300 (epoch 27.858), train_loss = 1.08072045, grad/param norm = 1.5452e-01, time/batch = 17.6380s	
16883/30300 (epoch 27.860), train_loss = 1.04024451, grad/param norm = 1.5257e-01, time/batch = 19.5264s	
16884/30300 (epoch 27.861), train_loss = 1.29664315, grad/param norm = 1.6061e-01, time/batch = 19.4604s	
16885/30300 (epoch 27.863), train_loss = 1.12802605, grad/param norm = 1.4504e-01, time/batch = 17.8849s	
16886/30300 (epoch 27.865), train_loss = 1.19240040, grad/param norm = 1.9019e-01, time/batch = 18.8051s	
16887/30300 (epoch 27.866), train_loss = 1.20436926, grad/param norm = 1.7695e-01, time/batch = 18.9613s	
16888/30300 (epoch 27.868), train_loss = 1.14351297, grad/param norm = 1.7378e-01, time/batch = 17.9549s	
16889/30300 (epoch 27.870), train_loss = 1.08352150, grad/param norm = 1.6316e-01, time/batch = 17.1037s	
16890/30300 (epoch 27.871), train_loss = 1.12897306, grad/param norm = 1.5280e-01, time/batch = 19.6246s	
16891/30300 (epoch 27.873), train_loss = 1.12142149, grad/param norm = 1.4244e-01, time/batch = 18.3891s	
16892/30300 (epoch 27.875), train_loss = 1.07844276, grad/param norm = 1.3854e-01, time/batch = 17.6404s	
16893/30300 (epoch 27.876), train_loss = 1.00620213, grad/param norm = 1.6621e-01, time/batch = 18.5082s	
16894/30300 (epoch 27.878), train_loss = 0.98031331, grad/param norm = 1.5272e-01, time/batch = 19.8551s	
16895/30300 (epoch 27.880), train_loss = 1.03435879, grad/param norm = 1.5017e-01, time/batch = 18.4433s	
16896/30300 (epoch 27.881), train_loss = 1.28490549, grad/param norm = 1.8196e-01, time/batch = 19.2155s	
16897/30300 (epoch 27.883), train_loss = 1.19245097, grad/param norm = 1.5752e-01, time/batch = 19.7907s	
16898/30300 (epoch 27.884), train_loss = 1.07114955, grad/param norm = 1.3745e-01, time/batch = 17.7078s	
16899/30300 (epoch 27.886), train_loss = 1.18116579, grad/param norm = 1.4908e-01, time/batch = 18.8008s	
16900/30300 (epoch 27.888), train_loss = 1.12660778, grad/param norm = 1.6278e-01, time/batch = 19.6333s	
16901/30300 (epoch 27.889), train_loss = 1.15581673, grad/param norm = 1.5284e-01, time/batch = 18.1295s	
16902/30300 (epoch 27.891), train_loss = 1.13075403, grad/param norm = 1.6051e-01, time/batch = 19.6088s	
16903/30300 (epoch 27.893), train_loss = 1.34528873, grad/param norm = 1.5888e-01, time/batch = 18.9522s	
16904/30300 (epoch 27.894), train_loss = 1.17397576, grad/param norm = 1.6433e-01, time/batch = 18.0319s	
16905/30300 (epoch 27.896), train_loss = 0.96690455, grad/param norm = 1.4364e-01, time/batch = 16.7877s	
16906/30300 (epoch 27.898), train_loss = 0.96944217, grad/param norm = 1.4829e-01, time/batch = 18.8888s	
16907/30300 (epoch 27.899), train_loss = 1.05113084, grad/param norm = 1.6699e-01, time/batch = 19.1319s	
16908/30300 (epoch 27.901), train_loss = 1.13233668, grad/param norm = 1.7256e-01, time/batch = 17.8805s	
16909/30300 (epoch 27.903), train_loss = 1.13156260, grad/param norm = 2.1595e-01, time/batch = 18.6355s	
16910/30300 (epoch 27.904), train_loss = 1.12947309, grad/param norm = 1.5808e-01, time/batch = 19.3712s	
16911/30300 (epoch 27.906), train_loss = 1.18683650, grad/param norm = 1.7851e-01, time/batch = 17.9514s	
16912/30300 (epoch 27.908), train_loss = 1.08690928, grad/param norm = 1.4533e-01, time/batch = 18.7999s	
16913/30300 (epoch 27.909), train_loss = 1.06821546, grad/param norm = 1.8487e-01, time/batch = 19.1406s	
16914/30300 (epoch 27.911), train_loss = 1.12459848, grad/param norm = 1.5874e-01, time/batch = 18.1301s	
16915/30300 (epoch 27.913), train_loss = 1.12457414, grad/param norm = 1.4421e-01, time/batch = 19.5551s	
16916/30300 (epoch 27.914), train_loss = 1.09586668, grad/param norm = 1.6222e-01, time/batch = 17.6158s	
16917/30300 (epoch 27.916), train_loss = 1.14479936, grad/param norm = 1.4564e-01, time/batch = 16.6233s	
16918/30300 (epoch 27.917), train_loss = 1.08821709, grad/param norm = 1.4945e-01, time/batch = 16.7204s	
16919/30300 (epoch 27.919), train_loss = 1.05303546, grad/param norm = 1.5873e-01, time/batch = 18.7125s	
16920/30300 (epoch 27.921), train_loss = 1.11143802, grad/param norm = 1.4864e-01, time/batch = 18.0542s	
16921/30300 (epoch 27.922), train_loss = 1.21403437, grad/param norm = 1.6369e-01, time/batch = 18.6173s	
16922/30300 (epoch 27.924), train_loss = 1.12512788, grad/param norm = 1.6776e-01, time/batch = 18.2829s	
16923/30300 (epoch 27.926), train_loss = 1.17363028, grad/param norm = 1.5259e-01, time/batch = 18.9674s	
16924/30300 (epoch 27.927), train_loss = 1.14056951, grad/param norm = 1.5893e-01, time/batch = 17.8794s	
16925/30300 (epoch 27.929), train_loss = 1.03958752, grad/param norm = 1.5446e-01, time/batch = 17.2083s	
16926/30300 (epoch 27.931), train_loss = 1.22712516, grad/param norm = 1.9294e-01, time/batch = 17.7986s	
16927/30300 (epoch 27.932), train_loss = 1.04712301, grad/param norm = 1.7169e-01, time/batch = 17.7070s	
16928/30300 (epoch 27.934), train_loss = 1.16053266, grad/param norm = 1.6021e-01, time/batch = 18.2079s	
16929/30300 (epoch 27.936), train_loss = 1.08328024, grad/param norm = 1.5000e-01, time/batch = 18.3841s	
16930/30300 (epoch 27.937), train_loss = 1.05948448, grad/param norm = 1.4959e-01, time/batch = 18.6038s	
16931/30300 (epoch 27.939), train_loss = 1.25649896, grad/param norm = 1.7129e-01, time/batch = 18.7129s	
16932/30300 (epoch 27.941), train_loss = 1.11673647, grad/param norm = 1.6613e-01, time/batch = 19.2998s	
16933/30300 (epoch 27.942), train_loss = 1.12835150, grad/param norm = 1.7496e-01, time/batch = 18.4477s	
16934/30300 (epoch 27.944), train_loss = 1.02283778, grad/param norm = 1.4613e-01, time/batch = 17.7093s	
16935/30300 (epoch 27.946), train_loss = 1.23235242, grad/param norm = 2.1868e-01, time/batch = 18.7143s	
16936/30300 (epoch 27.947), train_loss = 1.23637376, grad/param norm = 2.1519e-01, time/batch = 19.4714s	
16937/30300 (epoch 27.949), train_loss = 1.24020229, grad/param norm = 1.9070e-01, time/batch = 31.3900s	
16938/30300 (epoch 27.950), train_loss = 1.22893062, grad/param norm = 1.7114e-01, time/batch = 18.3969s	
16939/30300 (epoch 27.952), train_loss = 1.17444789, grad/param norm = 1.7255e-01, time/batch = 16.8714s	
16940/30300 (epoch 27.954), train_loss = 1.39527111, grad/param norm = 1.6012e-01, time/batch = 18.1412s	
16941/30300 (epoch 27.955), train_loss = 1.09926861, grad/param norm = 1.5423e-01, time/batch = 18.3027s	
16942/30300 (epoch 27.957), train_loss = 1.19129788, grad/param norm = 1.5455e-01, time/batch = 17.0325s	
16943/30300 (epoch 27.959), train_loss = 1.07542206, grad/param norm = 1.8102e-01, time/batch = 17.8737s	
16944/30300 (epoch 27.960), train_loss = 1.10356012, grad/param norm = 1.7769e-01, time/batch = 19.0454s	
16945/30300 (epoch 27.962), train_loss = 1.14128421, grad/param norm = 2.1534e-01, time/batch = 18.9465s	
16946/30300 (epoch 27.964), train_loss = 1.03595419, grad/param norm = 1.8568e-01, time/batch = 18.5412s	
16947/30300 (epoch 27.965), train_loss = 1.08670541, grad/param norm = 1.9925e-01, time/batch = 19.6318s	
16948/30300 (epoch 27.967), train_loss = 1.14258664, grad/param norm = 2.0473e-01, time/batch = 18.3678s	
16949/30300 (epoch 27.969), train_loss = 1.05092018, grad/param norm = 1.9030e-01, time/batch = 18.2970s	
16950/30300 (epoch 27.970), train_loss = 1.09948837, grad/param norm = 1.4408e-01, time/batch = 18.9611s	
16951/30300 (epoch 27.972), train_loss = 1.01250600, grad/param norm = 1.7324e-01, time/batch = 19.3711s	
16952/30300 (epoch 27.974), train_loss = 1.29225912, grad/param norm = 1.7264e-01, time/batch = 17.3753s	
16953/30300 (epoch 27.975), train_loss = 1.30785648, grad/param norm = 1.9103e-01, time/batch = 18.9501s	
16954/30300 (epoch 27.977), train_loss = 1.27691157, grad/param norm = 1.6804e-01, time/batch = 18.3061s	
16955/30300 (epoch 27.979), train_loss = 1.18821951, grad/param norm = 1.6044e-01, time/batch = 19.3834s	
16956/30300 (epoch 27.980), train_loss = 1.22068070, grad/param norm = 1.8452e-01, time/batch = 17.7862s	
16957/30300 (epoch 27.982), train_loss = 1.23483441, grad/param norm = 1.7382e-01, time/batch = 18.4617s	
16958/30300 (epoch 27.983), train_loss = 1.26262575, grad/param norm = 1.7034e-01, time/batch = 18.1255s	
16959/30300 (epoch 27.985), train_loss = 1.19017709, grad/param norm = 1.7528e-01, time/batch = 16.8567s	
16960/30300 (epoch 27.987), train_loss = 1.13030318, grad/param norm = 1.5718e-01, time/batch = 19.2754s	
16961/30300 (epoch 27.988), train_loss = 1.26475413, grad/param norm = 1.7224e-01, time/batch = 18.9642s	
16962/30300 (epoch 27.990), train_loss = 1.01387290, grad/param norm = 1.4346e-01, time/batch = 17.3533s	
16963/30300 (epoch 27.992), train_loss = 1.21507326, grad/param norm = 1.4504e-01, time/batch = 18.1824s	
16964/30300 (epoch 27.993), train_loss = 1.25055649, grad/param norm = 1.9353e-01, time/batch = 18.8839s	
16965/30300 (epoch 27.995), train_loss = 1.13283051, grad/param norm = 1.8168e-01, time/batch = 18.8819s	
16966/30300 (epoch 27.997), train_loss = 1.16697176, grad/param norm = 1.6704e-01, time/batch = 18.3851s	
16967/30300 (epoch 27.998), train_loss = 1.20958610, grad/param norm = 1.7802e-01, time/batch = 19.2947s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
16968/30300 (epoch 28.000), train_loss = 1.11619832, grad/param norm = 1.8502e-01, time/batch = 18.8808s	
16969/30300 (epoch 28.002), train_loss = 1.23211597, grad/param norm = 1.6919e-01, time/batch = 17.8093s	
16970/30300 (epoch 28.003), train_loss = 1.13568994, grad/param norm = 1.5709e-01, time/batch = 18.1402s	
16971/30300 (epoch 28.005), train_loss = 1.09525158, grad/param norm = 1.7149e-01, time/batch = 19.7912s	
16972/30300 (epoch 28.007), train_loss = 1.18036083, grad/param norm = 1.8201e-01, time/batch = 18.2997s	
16973/30300 (epoch 28.008), train_loss = 1.07730815, grad/param norm = 1.5165e-01, time/batch = 17.2043s	
16974/30300 (epoch 28.010), train_loss = 1.01328791, grad/param norm = 1.6909e-01, time/batch = 18.7798s	
16975/30300 (epoch 28.012), train_loss = 1.07787430, grad/param norm = 1.5622e-01, time/batch = 16.6651s	
16976/30300 (epoch 28.013), train_loss = 1.22619170, grad/param norm = 1.6745e-01, time/batch = 18.8739s	
16977/30300 (epoch 28.015), train_loss = 1.09312121, grad/param norm = 1.5345e-01, time/batch = 17.7144s	
16978/30300 (epoch 28.017), train_loss = 1.09469037, grad/param norm = 1.4647e-01, time/batch = 18.8156s	
16979/30300 (epoch 28.018), train_loss = 1.04558314, grad/param norm = 1.4758e-01, time/batch = 18.0467s	
16980/30300 (epoch 28.020), train_loss = 1.23669313, grad/param norm = 2.5617e-01, time/batch = 18.1246s	
16981/30300 (epoch 28.021), train_loss = 1.25201574, grad/param norm = 1.7172e-01, time/batch = 19.1391s	
16982/30300 (epoch 28.023), train_loss = 1.15505624, grad/param norm = 1.5498e-01, time/batch = 17.8882s	
16983/30300 (epoch 28.025), train_loss = 1.04580321, grad/param norm = 1.6388e-01, time/batch = 19.9510s	
16984/30300 (epoch 28.026), train_loss = 1.17833557, grad/param norm = 1.8346e-01, time/batch = 19.1388s	
16985/30300 (epoch 28.028), train_loss = 1.22531762, grad/param norm = 1.6688e-01, time/batch = 17.9536s	
16986/30300 (epoch 28.030), train_loss = 1.08107026, grad/param norm = 1.7275e-01, time/batch = 19.4759s	
16987/30300 (epoch 28.031), train_loss = 1.19932889, grad/param norm = 1.6055e-01, time/batch = 17.6968s	
16988/30300 (epoch 28.033), train_loss = 1.12670942, grad/param norm = 1.5038e-01, time/batch = 17.7253s	
16989/30300 (epoch 28.035), train_loss = 1.21396981, grad/param norm = 2.1881e-01, time/batch = 18.6213s	
16990/30300 (epoch 28.036), train_loss = 1.16118913, grad/param norm = 1.6330e-01, time/batch = 19.4674s	
16991/30300 (epoch 28.038), train_loss = 1.16928313, grad/param norm = 1.4746e-01, time/batch = 17.8037s	
16992/30300 (epoch 28.040), train_loss = 0.91714232, grad/param norm = 1.4491e-01, time/batch = 18.6308s	
16993/30300 (epoch 28.041), train_loss = 0.95536390, grad/param norm = 1.5016e-01, time/batch = 18.6706s	
16994/30300 (epoch 28.043), train_loss = 1.15018467, grad/param norm = 1.6415e-01, time/batch = 19.1189s	
16995/30300 (epoch 28.045), train_loss = 1.11957735, grad/param norm = 1.5086e-01, time/batch = 18.3029s	
16996/30300 (epoch 28.046), train_loss = 1.31127751, grad/param norm = 1.9310e-01, time/batch = 19.2976s	
16997/30300 (epoch 28.048), train_loss = 1.11137785, grad/param norm = 1.7721e-01, time/batch = 18.9019s	
16998/30300 (epoch 28.050), train_loss = 1.08716881, grad/param norm = 1.6306e-01, time/batch = 18.2829s	
16999/30300 (epoch 28.051), train_loss = 1.16105068, grad/param norm = 1.6286e-01, time/batch = 19.1283s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch28.05_1.8860.t7	
17000/30300 (epoch 28.053), train_loss = 0.97362622, grad/param norm = 1.7792e-01, time/batch = 19.3923s	
17001/30300 (epoch 28.054), train_loss = 1.42718485, grad/param norm = 2.4560e-01, time/batch = 17.6271s	
17002/30300 (epoch 28.056), train_loss = 1.06167232, grad/param norm = 1.6380e-01, time/batch = 18.8898s	
17003/30300 (epoch 28.058), train_loss = 1.11124423, grad/param norm = 1.5828e-01, time/batch = 18.2947s	
17004/30300 (epoch 28.059), train_loss = 1.04850056, grad/param norm = 1.6293e-01, time/batch = 19.2098s	
17005/30300 (epoch 28.061), train_loss = 1.19053954, grad/param norm = 1.7088e-01, time/batch = 20.0415s	
17006/30300 (epoch 28.063), train_loss = 1.03352120, grad/param norm = 1.7479e-01, time/batch = 17.9400s	
17007/30300 (epoch 28.064), train_loss = 1.14004264, grad/param norm = 1.7230e-01, time/batch = 17.8658s	
17008/30300 (epoch 28.066), train_loss = 1.13304583, grad/param norm = 1.4860e-01, time/batch = 17.9612s	
17009/30300 (epoch 28.068), train_loss = 1.01731677, grad/param norm = 1.5979e-01, time/batch = 18.7171s	
17010/30300 (epoch 28.069), train_loss = 1.21087955, grad/param norm = 1.8934e-01, time/batch = 17.8734s	
17011/30300 (epoch 28.071), train_loss = 1.18661345, grad/param norm = 1.7188e-01, time/batch = 18.5537s	
17012/30300 (epoch 28.073), train_loss = 1.07546231, grad/param norm = 1.7384e-01, time/batch = 18.9771s	
17013/30300 (epoch 28.074), train_loss = 1.13565989, grad/param norm = 1.5099e-01, time/batch = 17.4703s	
17014/30300 (epoch 28.076), train_loss = 1.10458300, grad/param norm = 1.5268e-01, time/batch = 19.1178s	
17015/30300 (epoch 28.078), train_loss = 1.04831252, grad/param norm = 1.4316e-01, time/batch = 17.6255s	
17016/30300 (epoch 28.079), train_loss = 1.07162967, grad/param norm = 1.5750e-01, time/batch = 17.7085s	
17017/30300 (epoch 28.081), train_loss = 1.12616514, grad/param norm = 1.6242e-01, time/batch = 19.2079s	
17018/30300 (epoch 28.083), train_loss = 1.19166168, grad/param norm = 1.7022e-01, time/batch = 19.7204s	
17019/30300 (epoch 28.084), train_loss = 1.03593096, grad/param norm = 1.5850e-01, time/batch = 18.3729s	
17020/30300 (epoch 28.086), train_loss = 1.06556607, grad/param norm = 1.8220e-01, time/batch = 18.3634s	
17021/30300 (epoch 28.087), train_loss = 1.03739080, grad/param norm = 1.4020e-01, time/batch = 19.5328s	
17022/30300 (epoch 28.089), train_loss = 1.08764404, grad/param norm = 1.6333e-01, time/batch = 19.7063s	
17023/30300 (epoch 28.091), train_loss = 1.15979414, grad/param norm = 1.5264e-01, time/batch = 18.3800s	
17024/30300 (epoch 28.092), train_loss = 1.17989165, grad/param norm = 1.6148e-01, time/batch = 19.5520s	
17025/30300 (epoch 28.094), train_loss = 1.28265500, grad/param norm = 1.8270e-01, time/batch = 19.1379s	
17026/30300 (epoch 28.096), train_loss = 1.23484111, grad/param norm = 1.8021e-01, time/batch = 17.7067s	
17027/30300 (epoch 28.097), train_loss = 1.05435292, grad/param norm = 1.5342e-01, time/batch = 17.3592s	
17028/30300 (epoch 28.099), train_loss = 1.22218869, grad/param norm = 1.6957e-01, time/batch = 17.7179s	
17029/30300 (epoch 28.101), train_loss = 1.25819047, grad/param norm = 1.7918e-01, time/batch = 18.3747s	
17030/30300 (epoch 28.102), train_loss = 1.07791468, grad/param norm = 1.9124e-01, time/batch = 17.3656s	
17031/30300 (epoch 28.104), train_loss = 1.09982949, grad/param norm = 2.0695e-01, time/batch = 18.3901s	
17032/30300 (epoch 28.106), train_loss = 1.13526688, grad/param norm = 2.2871e-01, time/batch = 18.1188s	
17033/30300 (epoch 28.107), train_loss = 1.16578720, grad/param norm = 1.5597e-01, time/batch = 19.4559s	
17034/30300 (epoch 28.109), train_loss = 1.19815695, grad/param norm = 1.9517e-01, time/batch = 18.3051s	
17035/30300 (epoch 28.111), train_loss = 1.23091650, grad/param norm = 1.6724e-01, time/batch = 18.1252s	
17036/30300 (epoch 28.112), train_loss = 1.24899365, grad/param norm = 1.5635e-01, time/batch = 18.5280s	
17037/30300 (epoch 28.114), train_loss = 1.08532737, grad/param norm = 1.5015e-01, time/batch = 18.1321s	
17038/30300 (epoch 28.116), train_loss = 1.14287901, grad/param norm = 1.7578e-01, time/batch = 17.8646s	
17039/30300 (epoch 28.117), train_loss = 1.19489314, grad/param norm = 1.4617e-01, time/batch = 17.3838s	
17040/30300 (epoch 28.119), train_loss = 1.07587499, grad/param norm = 1.8235e-01, time/batch = 18.0437s	
17041/30300 (epoch 28.120), train_loss = 1.11124494, grad/param norm = 1.6919e-01, time/batch = 19.2191s	
17042/30300 (epoch 28.122), train_loss = 1.21942802, grad/param norm = 1.8931e-01, time/batch = 17.9513s	
17043/30300 (epoch 28.124), train_loss = 1.27957674, grad/param norm = 1.8480e-01, time/batch = 18.1259s	
17044/30300 (epoch 28.125), train_loss = 1.01328503, grad/param norm = 1.8232e-01, time/batch = 19.1442s	
17045/30300 (epoch 28.127), train_loss = 1.17179433, grad/param norm = 2.0644e-01, time/batch = 17.8877s	
17046/30300 (epoch 28.129), train_loss = 1.25836514, grad/param norm = 1.7098e-01, time/batch = 17.1857s	
17047/30300 (epoch 28.130), train_loss = 1.26326090, grad/param norm = 1.6449e-01, time/batch = 17.2045s	
17048/30300 (epoch 28.132), train_loss = 1.28320665, grad/param norm = 1.7661e-01, time/batch = 18.7834s	
17049/30300 (epoch 28.134), train_loss = 1.03110997, grad/param norm = 1.5808e-01, time/batch = 16.7102s	
17050/30300 (epoch 28.135), train_loss = 1.06622310, grad/param norm = 1.6864e-01, time/batch = 18.2997s	
17051/30300 (epoch 28.137), train_loss = 1.13908309, grad/param norm = 1.7099e-01, time/batch = 18.2281s	
17052/30300 (epoch 28.139), train_loss = 1.09654185, grad/param norm = 1.9874e-01, time/batch = 18.0384s	
17053/30300 (epoch 28.140), train_loss = 1.16487949, grad/param norm = 2.1846e-01, time/batch = 17.7807s	
17054/30300 (epoch 28.142), train_loss = 1.24856716, grad/param norm = 1.9706e-01, time/batch = 19.3924s	
17055/30300 (epoch 28.144), train_loss = 1.07898138, grad/param norm = 1.7858e-01, time/batch = 18.1975s	
17056/30300 (epoch 28.145), train_loss = 1.23390175, grad/param norm = 2.0836e-01, time/batch = 17.8679s	
17057/30300 (epoch 28.147), train_loss = 1.09907455, grad/param norm = 2.0153e-01, time/batch = 19.5452s	
17058/30300 (epoch 28.149), train_loss = 1.28855805, grad/param norm = 1.9191e-01, time/batch = 18.9693s	
17059/30300 (epoch 28.150), train_loss = 1.11514622, grad/param norm = 1.8538e-01, time/batch = 18.1980s	
17060/30300 (epoch 28.152), train_loss = 1.03054750, grad/param norm = 1.7427e-01, time/batch = 17.8821s	
17061/30300 (epoch 28.153), train_loss = 1.12802481, grad/param norm = 1.6250e-01, time/batch = 19.4645s	
17062/30300 (epoch 28.155), train_loss = 1.00550307, grad/param norm = 1.5089e-01, time/batch = 18.1321s	
17063/30300 (epoch 28.157), train_loss = 1.11421705, grad/param norm = 1.8119e-01, time/batch = 18.2166s	
17064/30300 (epoch 28.158), train_loss = 1.14872409, grad/param norm = 1.8988e-01, time/batch = 19.2909s	
17065/30300 (epoch 28.160), train_loss = 1.05220907, grad/param norm = 1.8170e-01, time/batch = 17.3809s	
17066/30300 (epoch 28.162), train_loss = 1.13444203, grad/param norm = 1.4950e-01, time/batch = 17.0439s	
17067/30300 (epoch 28.163), train_loss = 1.11434829, grad/param norm = 1.7096e-01, time/batch = 18.6309s	
17068/30300 (epoch 28.165), train_loss = 1.24304137, grad/param norm = 1.6214e-01, time/batch = 17.5397s	
17069/30300 (epoch 28.167), train_loss = 1.11887554, grad/param norm = 1.7030e-01, time/batch = 18.8938s	
17070/30300 (epoch 28.168), train_loss = 1.18791681, grad/param norm = 1.5717e-01, time/batch = 19.0317s	
17071/30300 (epoch 28.170), train_loss = 1.13451257, grad/param norm = 1.6771e-01, time/batch = 17.9364s	
17072/30300 (epoch 28.172), train_loss = 1.12316591, grad/param norm = 1.8825e-01, time/batch = 18.0360s	
17073/30300 (epoch 28.173), train_loss = 1.12136777, grad/param norm = 1.9664e-01, time/batch = 18.8686s	
17074/30300 (epoch 28.175), train_loss = 1.13691445, grad/param norm = 1.5759e-01, time/batch = 18.9526s	
17075/30300 (epoch 28.177), train_loss = 1.17765514, grad/param norm = 1.7834e-01, time/batch = 18.0216s	
17076/30300 (epoch 28.178), train_loss = 0.92051020, grad/param norm = 1.5155e-01, time/batch = 18.5280s	
17077/30300 (epoch 28.180), train_loss = 1.12181273, grad/param norm = 1.4840e-01, time/batch = 19.3736s	
17078/30300 (epoch 28.182), train_loss = 1.15144014, grad/param norm = 1.7637e-01, time/batch = 17.3672s	
17079/30300 (epoch 28.183), train_loss = 1.07647020, grad/param norm = 1.6996e-01, time/batch = 18.8826s	
17080/30300 (epoch 28.185), train_loss = 1.29064015, grad/param norm = 1.6908e-01, time/batch = 16.4580s	
17081/30300 (epoch 28.186), train_loss = 1.33074050, grad/param norm = 2.1024e-01, time/batch = 15.7731s	
17082/30300 (epoch 28.188), train_loss = 1.16530094, grad/param norm = 1.6121e-01, time/batch = 16.5132s	
17083/30300 (epoch 28.190), train_loss = 1.15839622, grad/param norm = 1.5632e-01, time/batch = 15.9068s	
17084/30300 (epoch 28.191), train_loss = 1.20583046, grad/param norm = 1.8017e-01, time/batch = 16.1984s	
17085/30300 (epoch 28.193), train_loss = 1.04803604, grad/param norm = 1.4412e-01, time/batch = 18.2104s	
17086/30300 (epoch 28.195), train_loss = 1.10586329, grad/param norm = 1.5564e-01, time/batch = 18.9523s	
17087/30300 (epoch 28.196), train_loss = 1.16261736, grad/param norm = 1.4206e-01, time/batch = 19.0473s	
17088/30300 (epoch 28.198), train_loss = 0.98188699, grad/param norm = 1.5412e-01, time/batch = 18.7033s	
17089/30300 (epoch 28.200), train_loss = 1.12740529, grad/param norm = 1.5243e-01, time/batch = 16.3910s	
17090/30300 (epoch 28.201), train_loss = 1.19979292, grad/param norm = 1.8959e-01, time/batch = 18.8723s	
17091/30300 (epoch 28.203), train_loss = 1.13694984, grad/param norm = 1.7381e-01, time/batch = 19.5583s	
17092/30300 (epoch 28.205), train_loss = 1.36290712, grad/param norm = 1.9372e-01, time/batch = 18.9463s	
17093/30300 (epoch 28.206), train_loss = 1.23927225, grad/param norm = 1.9221e-01, time/batch = 18.6334s	
17094/30300 (epoch 28.208), train_loss = 1.21604046, grad/param norm = 2.1790e-01, time/batch = 19.2175s	
17095/30300 (epoch 28.210), train_loss = 1.18857697, grad/param norm = 1.6210e-01, time/batch = 18.7080s	
17096/30300 (epoch 28.211), train_loss = 1.24752985, grad/param norm = 1.6738e-01, time/batch = 18.7983s	
17097/30300 (epoch 28.213), train_loss = 1.11486510, grad/param norm = 1.4921e-01, time/batch = 19.0467s	
17098/30300 (epoch 28.215), train_loss = 1.05579913, grad/param norm = 1.7067e-01, time/batch = 16.9506s	
17099/30300 (epoch 28.216), train_loss = 1.09981105, grad/param norm = 1.8743e-01, time/batch = 19.0534s	
17100/30300 (epoch 28.218), train_loss = 1.03613596, grad/param norm = 1.4208e-01, time/batch = 19.2113s	
17101/30300 (epoch 28.219), train_loss = 0.99845332, grad/param norm = 1.5200e-01, time/batch = 17.4380s	
17102/30300 (epoch 28.221), train_loss = 0.98358174, grad/param norm = 1.4427e-01, time/batch = 18.8746s	
17103/30300 (epoch 28.223), train_loss = 1.15256876, grad/param norm = 1.6358e-01, time/batch = 19.3815s	
17104/30300 (epoch 28.224), train_loss = 0.98310876, grad/param norm = 1.6050e-01, time/batch = 18.1177s	
17105/30300 (epoch 28.226), train_loss = 1.19415735, grad/param norm = 1.7488e-01, time/batch = 19.2115s	
17106/30300 (epoch 28.228), train_loss = 1.21977210, grad/param norm = 1.6390e-01, time/batch = 19.3657s	
17107/30300 (epoch 28.229), train_loss = 1.11026479, grad/param norm = 1.6256e-01, time/batch = 18.7104s	
17108/30300 (epoch 28.231), train_loss = 1.15228956, grad/param norm = 1.5557e-01, time/batch = 16.6935s	
17109/30300 (epoch 28.233), train_loss = 1.15945955, grad/param norm = 1.4230e-01, time/batch = 18.8118s	
17110/30300 (epoch 28.234), train_loss = 1.18996309, grad/param norm = 1.8099e-01, time/batch = 19.2956s	
17111/30300 (epoch 28.236), train_loss = 1.15905338, grad/param norm = 1.4343e-01, time/batch = 17.6896s	
17112/30300 (epoch 28.238), train_loss = 1.15425490, grad/param norm = 1.7532e-01, time/batch = 19.0510s	
17113/30300 (epoch 28.239), train_loss = 1.15734114, grad/param norm = 1.9015e-01, time/batch = 19.4622s	
17114/30300 (epoch 28.241), train_loss = 1.16913815, grad/param norm = 1.7539e-01, time/batch = 17.6093s	
17115/30300 (epoch 28.243), train_loss = 1.19091432, grad/param norm = 1.6484e-01, time/batch = 18.2796s	
17116/30300 (epoch 28.244), train_loss = 1.35642910, grad/param norm = 1.6787e-01, time/batch = 19.2996s	
17117/30300 (epoch 28.246), train_loss = 1.16724392, grad/param norm = 1.6403e-01, time/batch = 17.2093s	
17118/30300 (epoch 28.248), train_loss = 1.11129355, grad/param norm = 1.5215e-01, time/batch = 19.5249s	
17119/30300 (epoch 28.249), train_loss = 1.07255417, grad/param norm = 1.6165e-01, time/batch = 19.2932s	
17120/30300 (epoch 28.251), train_loss = 1.07056555, grad/param norm = 1.6078e-01, time/batch = 17.3871s	
17121/30300 (epoch 28.252), train_loss = 1.24078783, grad/param norm = 1.7184e-01, time/batch = 18.0439s	
17122/30300 (epoch 28.254), train_loss = 1.23218755, grad/param norm = 1.7537e-01, time/batch = 18.4764s	
17123/30300 (epoch 28.256), train_loss = 1.16456617, grad/param norm = 1.6493e-01, time/batch = 18.8990s	
17124/30300 (epoch 28.257), train_loss = 1.21090342, grad/param norm = 1.6355e-01, time/batch = 31.8072s	
17125/30300 (epoch 28.259), train_loss = 1.11941268, grad/param norm = 1.6533e-01, time/batch = 18.7253s	
17126/30300 (epoch 28.261), train_loss = 1.24240425, grad/param norm = 1.6159e-01, time/batch = 18.4635s	
17127/30300 (epoch 28.262), train_loss = 1.08737527, grad/param norm = 1.5495e-01, time/batch = 18.2187s	
17128/30300 (epoch 28.264), train_loss = 1.13526564, grad/param norm = 1.5620e-01, time/batch = 18.7122s	
17129/30300 (epoch 28.266), train_loss = 1.07119017, grad/param norm = 1.4504e-01, time/batch = 18.6335s	
17130/30300 (epoch 28.267), train_loss = 1.30642742, grad/param norm = 1.8247e-01, time/batch = 17.3665s	
17131/30300 (epoch 28.269), train_loss = 1.14981124, grad/param norm = 1.5773e-01, time/batch = 18.7903s	
17132/30300 (epoch 28.271), train_loss = 1.19129444, grad/param norm = 1.7300e-01, time/batch = 19.5230s	
17133/30300 (epoch 28.272), train_loss = 1.13742174, grad/param norm = 1.6541e-01, time/batch = 17.0219s	
17134/30300 (epoch 28.274), train_loss = 1.20026175, grad/param norm = 1.6331e-01, time/batch = 18.6881s	
17135/30300 (epoch 28.276), train_loss = 1.18255554, grad/param norm = 1.8526e-01, time/batch = 19.1301s	
17136/30300 (epoch 28.277), train_loss = 1.01255733, grad/param norm = 1.5157e-01, time/batch = 17.1419s	
17137/30300 (epoch 28.279), train_loss = 1.14711336, grad/param norm = 1.6897e-01, time/batch = 18.8941s	
17138/30300 (epoch 28.281), train_loss = 1.24453014, grad/param norm = 2.1965e-01, time/batch = 18.8025s	
17139/30300 (epoch 28.282), train_loss = 1.15502138, grad/param norm = 1.4245e-01, time/batch = 18.0349s	
17140/30300 (epoch 28.284), train_loss = 1.25475955, grad/param norm = 2.3549e-01, time/batch = 19.4542s	
17141/30300 (epoch 28.285), train_loss = 1.21213250, grad/param norm = 1.7966e-01, time/batch = 19.1373s	
17142/30300 (epoch 28.287), train_loss = 1.13553083, grad/param norm = 1.7595e-01, time/batch = 18.4622s	
17143/30300 (epoch 28.289), train_loss = 1.22841929, grad/param norm = 1.6034e-01, time/batch = 17.9668s	
17144/30300 (epoch 28.290), train_loss = 0.90096360, grad/param norm = 1.3675e-01, time/batch = 18.7028s	
17145/30300 (epoch 28.292), train_loss = 1.05537652, grad/param norm = 1.6027e-01, time/batch = 19.7847s	
17146/30300 (epoch 28.294), train_loss = 1.23214636, grad/param norm = 2.1833e-01, time/batch = 18.0405s	
17147/30300 (epoch 28.295), train_loss = 1.09878759, grad/param norm = 1.6227e-01, time/batch = 19.3723s	
17148/30300 (epoch 28.297), train_loss = 1.08607958, grad/param norm = 1.5555e-01, time/batch = 18.6259s	
17149/30300 (epoch 28.299), train_loss = 1.11451957, grad/param norm = 1.5084e-01, time/batch = 17.6278s	
17150/30300 (epoch 28.300), train_loss = 1.06316464, grad/param norm = 1.5174e-01, time/batch = 18.8824s	
17151/30300 (epoch 28.302), train_loss = 1.18030022, grad/param norm = 1.6809e-01, time/batch = 20.0400s	
17152/30300 (epoch 28.304), train_loss = 1.05326258, grad/param norm = 1.5892e-01, time/batch = 17.5092s	
17153/30300 (epoch 28.305), train_loss = 1.10506465, grad/param norm = 1.4433e-01, time/batch = 17.9746s	
17154/30300 (epoch 28.307), train_loss = 1.19192256, grad/param norm = 1.3817e-01, time/batch = 18.6356s	
17155/30300 (epoch 28.309), train_loss = 1.18930603, grad/param norm = 1.6857e-01, time/batch = 18.3797s	
17156/30300 (epoch 28.310), train_loss = 1.13184270, grad/param norm = 1.6174e-01, time/batch = 18.0552s	
17157/30300 (epoch 28.312), train_loss = 1.27294514, grad/param norm = 1.5906e-01, time/batch = 18.8811s	
17158/30300 (epoch 28.314), train_loss = 1.15951137, grad/param norm = 1.8430e-01, time/batch = 16.6470s	
17159/30300 (epoch 28.315), train_loss = 1.10727969, grad/param norm = 1.5561e-01, time/batch = 17.5366s	
17160/30300 (epoch 28.317), train_loss = 1.17954317, grad/param norm = 1.6143e-01, time/batch = 19.2200s	
17161/30300 (epoch 28.318), train_loss = 1.22622584, grad/param norm = 1.7809e-01, time/batch = 19.4680s	
17162/30300 (epoch 28.320), train_loss = 1.20817758, grad/param norm = 1.6548e-01, time/batch = 16.5416s	
17163/30300 (epoch 28.322), train_loss = 1.07060061, grad/param norm = 1.5973e-01, time/batch = 17.7735s	
17164/30300 (epoch 28.323), train_loss = 1.25921101, grad/param norm = 1.8510e-01, time/batch = 19.3906s	
17165/30300 (epoch 28.325), train_loss = 1.12958340, grad/param norm = 1.5608e-01, time/batch = 16.8915s	
17166/30300 (epoch 28.327), train_loss = 1.13507312, grad/param norm = 1.5138e-01, time/batch = 18.2098s	
17167/30300 (epoch 28.328), train_loss = 1.14532624, grad/param norm = 1.5108e-01, time/batch = 18.8870s	
17168/30300 (epoch 28.330), train_loss = 1.18057454, grad/param norm = 1.6469e-01, time/batch = 18.5376s	
17169/30300 (epoch 28.332), train_loss = 1.23346916, grad/param norm = 2.0310e-01, time/batch = 19.2893s	
17170/30300 (epoch 28.333), train_loss = 1.09576745, grad/param norm = 1.6016e-01, time/batch = 18.6313s	
17171/30300 (epoch 28.335), train_loss = 1.01768530, grad/param norm = 1.6102e-01, time/batch = 19.6956s	
17172/30300 (epoch 28.337), train_loss = 1.27361588, grad/param norm = 1.5108e-01, time/batch = 18.0104s	
17173/30300 (epoch 28.338), train_loss = 1.08098935, grad/param norm = 1.4782e-01, time/batch = 18.6366s	
17174/30300 (epoch 28.340), train_loss = 1.08240215, grad/param norm = 1.6453e-01, time/batch = 17.8749s	
17175/30300 (epoch 28.342), train_loss = 1.22889271, grad/param norm = 1.5982e-01, time/batch = 17.1310s	
17176/30300 (epoch 28.343), train_loss = 1.15460475, grad/param norm = 1.5611e-01, time/batch = 17.2523s	
17177/30300 (epoch 28.345), train_loss = 1.20222769, grad/param norm = 1.5570e-01, time/batch = 17.0175s	
17178/30300 (epoch 28.347), train_loss = 1.01849349, grad/param norm = 1.5945e-01, time/batch = 15.9391s	
17179/30300 (epoch 28.348), train_loss = 1.06269155, grad/param norm = 1.5558e-01, time/batch = 16.9581s	
17180/30300 (epoch 28.350), train_loss = 1.11667034, grad/param norm = 1.7126e-01, time/batch = 17.8679s	
17181/30300 (epoch 28.351), train_loss = 1.12378041, grad/param norm = 1.6655e-01, time/batch = 19.2883s	
17182/30300 (epoch 28.353), train_loss = 1.01031005, grad/param norm = 1.5865e-01, time/batch = 17.2725s	
17183/30300 (epoch 28.355), train_loss = 1.09404731, grad/param norm = 1.4854e-01, time/batch = 18.5226s	
17184/30300 (epoch 28.356), train_loss = 1.20525087, grad/param norm = 1.8093e-01, time/batch = 18.5557s	
17185/30300 (epoch 28.358), train_loss = 1.36437438, grad/param norm = 1.4808e-01, time/batch = 17.0293s	
17186/30300 (epoch 28.360), train_loss = 1.09028024, grad/param norm = 1.6213e-01, time/batch = 18.4310s	
17187/30300 (epoch 28.361), train_loss = 1.15079555, grad/param norm = 1.5602e-01, time/batch = 18.7708s	
17188/30300 (epoch 28.363), train_loss = 1.19661034, grad/param norm = 1.7950e-01, time/batch = 18.1767s	
17189/30300 (epoch 28.365), train_loss = 1.03284297, grad/param norm = 1.9827e-01, time/batch = 18.1168s	
17190/30300 (epoch 28.366), train_loss = 1.10657085, grad/param norm = 1.5554e-01, time/batch = 19.8871s	
17191/30300 (epoch 28.368), train_loss = 0.98105404, grad/param norm = 1.4448e-01, time/batch = 18.9574s	
17192/30300 (epoch 28.370), train_loss = 1.05956814, grad/param norm = 1.5474e-01, time/batch = 17.6335s	
17193/30300 (epoch 28.371), train_loss = 1.21130887, grad/param norm = 1.5894e-01, time/batch = 18.4687s	
17194/30300 (epoch 28.373), train_loss = 1.06061125, grad/param norm = 1.3914e-01, time/batch = 18.7900s	
17195/30300 (epoch 28.375), train_loss = 1.05648443, grad/param norm = 1.3846e-01, time/batch = 17.7893s	
17196/30300 (epoch 28.376), train_loss = 1.04993124, grad/param norm = 1.4525e-01, time/batch = 18.4521s	
17197/30300 (epoch 28.378), train_loss = 1.03755432, grad/param norm = 1.6386e-01, time/batch = 19.2965s	
17198/30300 (epoch 28.380), train_loss = 1.27611305, grad/param norm = 1.7807e-01, time/batch = 17.9559s	
17199/30300 (epoch 28.381), train_loss = 0.96788345, grad/param norm = 1.4636e-01, time/batch = 18.5171s	
17200/30300 (epoch 28.383), train_loss = 1.07543110, grad/param norm = 2.2779e-01, time/batch = 18.4627s	
17201/30300 (epoch 28.384), train_loss = 1.19333180, grad/param norm = 1.8717e-01, time/batch = 18.4608s	
17202/30300 (epoch 28.386), train_loss = 1.03279511, grad/param norm = 1.5271e-01, time/batch = 18.6242s	
17203/30300 (epoch 28.388), train_loss = 0.98800224, grad/param norm = 1.3833e-01, time/batch = 19.2198s	
17204/30300 (epoch 28.389), train_loss = 1.10996541, grad/param norm = 1.6218e-01, time/batch = 18.0505s	
17205/30300 (epoch 28.391), train_loss = 1.17120070, grad/param norm = 1.5469e-01, time/batch = 17.5392s	
17206/30300 (epoch 28.393), train_loss = 0.98854737, grad/param norm = 1.4358e-01, time/batch = 18.1954s	
17207/30300 (epoch 28.394), train_loss = 1.17076695, grad/param norm = 1.5746e-01, time/batch = 18.7004s	
17208/30300 (epoch 28.396), train_loss = 1.24092087, grad/param norm = 1.5545e-01, time/batch = 18.1179s	
17209/30300 (epoch 28.398), train_loss = 1.10215821, grad/param norm = 1.6790e-01, time/batch = 18.1283s	
17210/30300 (epoch 28.399), train_loss = 1.08068662, grad/param norm = 1.4887e-01, time/batch = 18.3654s	
17211/30300 (epoch 28.401), train_loss = 1.16308896, grad/param norm = 1.9769e-01, time/batch = 17.6577s	
17212/30300 (epoch 28.403), train_loss = 1.10823159, grad/param norm = 1.5934e-01, time/batch = 18.5436s	
17213/30300 (epoch 28.404), train_loss = 1.06209348, grad/param norm = 1.7255e-01, time/batch = 19.7038s	
17214/30300 (epoch 28.406), train_loss = 1.15812813, grad/param norm = 1.4810e-01, time/batch = 18.4392s	
17215/30300 (epoch 28.408), train_loss = 1.00301097, grad/param norm = 1.5438e-01, time/batch = 19.4399s	
17216/30300 (epoch 28.409), train_loss = 0.99658228, grad/param norm = 1.5312e-01, time/batch = 19.3765s	
17217/30300 (epoch 28.411), train_loss = 1.04526661, grad/param norm = 1.4398e-01, time/batch = 18.9670s	
17218/30300 (epoch 28.413), train_loss = 0.93776897, grad/param norm = 1.5514e-01, time/batch = 18.8581s	
17219/30300 (epoch 28.414), train_loss = 1.19517061, grad/param norm = 1.6957e-01, time/batch = 18.5359s	
17220/30300 (epoch 28.416), train_loss = 1.06118439, grad/param norm = 1.4325e-01, time/batch = 18.6749s	
17221/30300 (epoch 28.417), train_loss = 1.02882791, grad/param norm = 1.5118e-01, time/batch = 17.2508s	
17222/30300 (epoch 28.419), train_loss = 1.01259051, grad/param norm = 1.4679e-01, time/batch = 18.9247s	
17223/30300 (epoch 28.421), train_loss = 1.05334186, grad/param norm = 1.5249e-01, time/batch = 17.7530s	
17224/30300 (epoch 28.422), train_loss = 1.12547331, grad/param norm = 1.5933e-01, time/batch = 17.4520s	
17225/30300 (epoch 28.424), train_loss = 1.12937121, grad/param norm = 1.6079e-01, time/batch = 18.8709s	
17226/30300 (epoch 28.426), train_loss = 1.07852925, grad/param norm = 1.5985e-01, time/batch = 17.7082s	
17227/30300 (epoch 28.427), train_loss = 1.06892429, grad/param norm = 1.5923e-01, time/batch = 16.4287s	
17228/30300 (epoch 28.429), train_loss = 1.10381914, grad/param norm = 1.4686e-01, time/batch = 16.9341s	
17229/30300 (epoch 28.431), train_loss = 1.17290135, grad/param norm = 1.5694e-01, time/batch = 18.3714s	
17230/30300 (epoch 28.432), train_loss = 1.08862253, grad/param norm = 1.4326e-01, time/batch = 18.7021s	
17231/30300 (epoch 28.434), train_loss = 1.00168849, grad/param norm = 1.6118e-01, time/batch = 17.9549s	
17232/30300 (epoch 28.436), train_loss = 1.27573256, grad/param norm = 1.7466e-01, time/batch = 19.7971s	
17233/30300 (epoch 28.437), train_loss = 1.01415396, grad/param norm = 1.4878e-01, time/batch = 19.1117s	
17234/30300 (epoch 28.439), train_loss = 1.06162539, grad/param norm = 1.5042e-01, time/batch = 17.9566s	
17235/30300 (epoch 28.441), train_loss = 1.10690966, grad/param norm = 1.8986e-01, time/batch = 19.1759s	
17236/30300 (epoch 28.442), train_loss = 1.03236330, grad/param norm = 1.5730e-01, time/batch = 18.9413s	
17237/30300 (epoch 28.444), train_loss = 0.94332863, grad/param norm = 1.5165e-01, time/batch = 17.5950s	
17238/30300 (epoch 28.446), train_loss = 1.08730586, grad/param norm = 1.4054e-01, time/batch = 18.6675s	
17239/30300 (epoch 28.447), train_loss = 1.12400630, grad/param norm = 1.7931e-01, time/batch = 18.4476s	
17240/30300 (epoch 28.449), train_loss = 1.04765847, grad/param norm = 1.5677e-01, time/batch = 18.5289s	
17241/30300 (epoch 28.450), train_loss = 1.17027658, grad/param norm = 1.5245e-01, time/batch = 18.0968s	
17242/30300 (epoch 28.452), train_loss = 1.22796590, grad/param norm = 1.6045e-01, time/batch = 19.5408s	
17243/30300 (epoch 28.454), train_loss = 1.18237004, grad/param norm = 1.5430e-01, time/batch = 18.2941s	
17244/30300 (epoch 28.455), train_loss = 1.11841064, grad/param norm = 1.6789e-01, time/batch = 17.7157s	
17245/30300 (epoch 28.457), train_loss = 1.10130125, grad/param norm = 1.7114e-01, time/batch = 17.7200s	
17246/30300 (epoch 28.459), train_loss = 1.16720037, grad/param norm = 1.5951e-01, time/batch = 18.7103s	
17247/30300 (epoch 28.460), train_loss = 1.16099905, grad/param norm = 1.5834e-01, time/batch = 17.3577s	
17248/30300 (epoch 28.462), train_loss = 1.18511554, grad/param norm = 1.6100e-01, time/batch = 19.1429s	
17249/30300 (epoch 28.464), train_loss = 0.95354807, grad/param norm = 1.9682e-01, time/batch = 18.4524s	
17250/30300 (epoch 28.465), train_loss = 0.94043368, grad/param norm = 1.4567e-01, time/batch = 17.6281s	
17251/30300 (epoch 28.467), train_loss = 0.93644828, grad/param norm = 1.3667e-01, time/batch = 19.3839s	
17252/30300 (epoch 28.469), train_loss = 1.03275687, grad/param norm = 1.6205e-01, time/batch = 17.8674s	
17253/30300 (epoch 28.470), train_loss = 1.07609678, grad/param norm = 1.8165e-01, time/batch = 15.4363s	
17254/30300 (epoch 28.472), train_loss = 1.05629196, grad/param norm = 1.3754e-01, time/batch = 18.1117s	
17255/30300 (epoch 28.474), train_loss = 1.06702668, grad/param norm = 1.8209e-01, time/batch = 19.3086s	
17256/30300 (epoch 28.475), train_loss = 1.05538998, grad/param norm = 1.4814e-01, time/batch = 19.2207s	
17257/30300 (epoch 28.477), train_loss = 1.10890366, grad/param norm = 1.5264e-01, time/batch = 18.6935s	
17258/30300 (epoch 28.479), train_loss = 1.08847902, grad/param norm = 1.6760e-01, time/batch = 16.9196s	
17259/30300 (epoch 28.480), train_loss = 1.12779162, grad/param norm = 1.4466e-01, time/batch = 19.6119s	
17260/30300 (epoch 28.482), train_loss = 1.15244548, grad/param norm = 1.3984e-01, time/batch = 18.1060s	
17261/30300 (epoch 28.483), train_loss = 1.08569231, grad/param norm = 1.8606e-01, time/batch = 19.2817s	
17262/30300 (epoch 28.485), train_loss = 1.11560517, grad/param norm = 1.4497e-01, time/batch = 19.5365s	
17263/30300 (epoch 28.487), train_loss = 1.20274217, grad/param norm = 1.6322e-01, time/batch = 16.8697s	
17264/30300 (epoch 28.488), train_loss = 1.20437016, grad/param norm = 1.3902e-01, time/batch = 18.6219s	
17265/30300 (epoch 28.490), train_loss = 0.99881608, grad/param norm = 1.6133e-01, time/batch = 18.6111s	
17266/30300 (epoch 28.492), train_loss = 1.09578530, grad/param norm = 1.7570e-01, time/batch = 18.3627s	
17267/30300 (epoch 28.493), train_loss = 1.10967317, grad/param norm = 2.0090e-01, time/batch = 18.6974s	
17268/30300 (epoch 28.495), train_loss = 1.08003668, grad/param norm = 1.4329e-01, time/batch = 18.8689s	
17269/30300 (epoch 28.497), train_loss = 1.11234091, grad/param norm = 1.5073e-01, time/batch = 17.9104s	
17270/30300 (epoch 28.498), train_loss = 1.16712975, grad/param norm = 1.5127e-01, time/batch = 18.9234s	
17271/30300 (epoch 28.500), train_loss = 1.11244505, grad/param norm = 1.7315e-01, time/batch = 18.4365s	
17272/30300 (epoch 28.502), train_loss = 1.11566616, grad/param norm = 1.7932e-01, time/batch = 18.4810s	
17273/30300 (epoch 28.503), train_loss = 1.21817540, grad/param norm = 1.6251e-01, time/batch = 18.0370s	
17274/30300 (epoch 28.505), train_loss = 1.02553317, grad/param norm = 1.4093e-01, time/batch = 18.9600s	
17275/30300 (epoch 28.507), train_loss = 1.02604085, grad/param norm = 1.4612e-01, time/batch = 18.7084s	
17276/30300 (epoch 28.508), train_loss = 1.07227616, grad/param norm = 1.9529e-01, time/batch = 17.6222s	
17277/30300 (epoch 28.510), train_loss = 1.18945603, grad/param norm = 1.6567e-01, time/batch = 18.2658s	
17278/30300 (epoch 28.512), train_loss = 1.05138752, grad/param norm = 1.4527e-01, time/batch = 18.9494s	
17279/30300 (epoch 28.513), train_loss = 1.12749806, grad/param norm = 1.7801e-01, time/batch = 18.0307s	
17280/30300 (epoch 28.515), train_loss = 1.11829474, grad/param norm = 1.7157e-01, time/batch = 18.6284s	
17281/30300 (epoch 28.517), train_loss = 0.92990387, grad/param norm = 1.4348e-01, time/batch = 19.8654s	
17282/30300 (epoch 28.518), train_loss = 1.19934165, grad/param norm = 1.7020e-01, time/batch = 18.2977s	
17283/30300 (epoch 28.520), train_loss = 1.16309684, grad/param norm = 1.7090e-01, time/batch = 17.4630s	
17284/30300 (epoch 28.521), train_loss = 1.04623612, grad/param norm = 2.1181e-01, time/batch = 19.2694s	
17285/30300 (epoch 28.523), train_loss = 1.28633770, grad/param norm = 2.1550e-01, time/batch = 17.4030s	
17286/30300 (epoch 28.525), train_loss = 1.06024428, grad/param norm = 1.7062e-01, time/batch = 18.1082s	
17287/30300 (epoch 28.526), train_loss = 1.11981987, grad/param norm = 1.5594e-01, time/batch = 18.8758s	
17288/30300 (epoch 28.528), train_loss = 1.01712577, grad/param norm = 1.5712e-01, time/batch = 17.0243s	
17289/30300 (epoch 28.530), train_loss = 0.97678765, grad/param norm = 1.4864e-01, time/batch = 17.2104s	
17290/30300 (epoch 28.531), train_loss = 1.15898037, grad/param norm = 1.5978e-01, time/batch = 17.5506s	
17291/30300 (epoch 28.533), train_loss = 1.11568009, grad/param norm = 1.5864e-01, time/batch = 20.0293s	
17292/30300 (epoch 28.535), train_loss = 1.05523341, grad/param norm = 1.4083e-01, time/batch = 17.6168s	
17293/30300 (epoch 28.536), train_loss = 1.15928536, grad/param norm = 1.9458e-01, time/batch = 18.7793s	
17294/30300 (epoch 28.538), train_loss = 1.00829100, grad/param norm = 1.7544e-01, time/batch = 18.0414s	
17295/30300 (epoch 28.540), train_loss = 1.03907986, grad/param norm = 1.9591e-01, time/batch = 18.9642s	
17296/30300 (epoch 28.541), train_loss = 1.12069364, grad/param norm = 1.7111e-01, time/batch = 18.1231s	
17297/30300 (epoch 28.543), train_loss = 1.10418711, grad/param norm = 1.6623e-01, time/batch = 18.7803s	
17298/30300 (epoch 28.545), train_loss = 1.12451914, grad/param norm = 1.8533e-01, time/batch = 17.7787s	
17299/30300 (epoch 28.546), train_loss = 1.31172886, grad/param norm = 1.6655e-01, time/batch = 18.6858s	
17300/30300 (epoch 28.548), train_loss = 1.06083818, grad/param norm = 1.4687e-01, time/batch = 18.0431s	
17301/30300 (epoch 28.550), train_loss = 1.14384556, grad/param norm = 1.7677e-01, time/batch = 19.8821s	
17302/30300 (epoch 28.551), train_loss = 1.05979972, grad/param norm = 1.5295e-01, time/batch = 18.5267s	
17303/30300 (epoch 28.553), train_loss = 1.07029472, grad/param norm = 1.6662e-01, time/batch = 19.1185s	
17304/30300 (epoch 28.554), train_loss = 1.11408777, grad/param norm = 1.6238e-01, time/batch = 19.1388s	
17305/30300 (epoch 28.556), train_loss = 1.17570546, grad/param norm = 1.5677e-01, time/batch = 17.4487s	
17306/30300 (epoch 28.558), train_loss = 1.19919962, grad/param norm = 1.8675e-01, time/batch = 18.4674s	
17307/30300 (epoch 28.559), train_loss = 1.13258966, grad/param norm = 1.6481e-01, time/batch = 19.2765s	
17308/30300 (epoch 28.561), train_loss = 0.92849135, grad/param norm = 1.5013e-01, time/batch = 17.8898s	
17309/30300 (epoch 28.563), train_loss = 1.00378406, grad/param norm = 1.4895e-01, time/batch = 19.6070s	
17310/30300 (epoch 28.564), train_loss = 1.02717031, grad/param norm = 1.3745e-01, time/batch = 18.3566s	
17311/30300 (epoch 28.566), train_loss = 1.08895282, grad/param norm = 1.4826e-01, time/batch = 19.2056s	
17312/30300 (epoch 28.568), train_loss = 0.94396460, grad/param norm = 1.5890e-01, time/batch = 17.8599s	
17313/30300 (epoch 28.569), train_loss = 1.11788953, grad/param norm = 1.5681e-01, time/batch = 18.2081s	
17314/30300 (epoch 28.571), train_loss = 1.11697149, grad/param norm = 1.6787e-01, time/batch = 18.1833s	
17315/30300 (epoch 28.573), train_loss = 1.13786924, grad/param norm = 1.5750e-01, time/batch = 18.2777s	
17316/30300 (epoch 28.574), train_loss = 1.15858092, grad/param norm = 1.4804e-01, time/batch = 18.0428s	
17317/30300 (epoch 28.576), train_loss = 1.06833128, grad/param norm = 1.4380e-01, time/batch = 19.8693s	
17318/30300 (epoch 28.578), train_loss = 0.97444113, grad/param norm = 1.5323e-01, time/batch = 25.6120s	
17319/30300 (epoch 28.579), train_loss = 1.11930994, grad/param norm = 1.6923e-01, time/batch = 22.4871s	
17320/30300 (epoch 28.581), train_loss = 1.21726985, grad/param norm = 1.6061e-01, time/batch = 18.4501s	
17321/30300 (epoch 28.583), train_loss = 1.27488385, grad/param norm = 2.0584e-01, time/batch = 18.2691s	
17322/30300 (epoch 28.584), train_loss = 1.20230259, grad/param norm = 1.5085e-01, time/batch = 17.6373s	
17323/30300 (epoch 28.586), train_loss = 1.08358849, grad/param norm = 1.6044e-01, time/batch = 19.2098s	
17324/30300 (epoch 28.587), train_loss = 1.09232520, grad/param norm = 1.5712e-01, time/batch = 17.4461s	
17325/30300 (epoch 28.589), train_loss = 1.02593225, grad/param norm = 1.5183e-01, time/batch = 18.7899s	
17326/30300 (epoch 28.591), train_loss = 1.14479712, grad/param norm = 1.5042e-01, time/batch = 18.7852s	
17327/30300 (epoch 28.592), train_loss = 1.08457007, grad/param norm = 1.4372e-01, time/batch = 18.9587s	
17328/30300 (epoch 28.594), train_loss = 1.12338374, grad/param norm = 1.6835e-01, time/batch = 18.7907s	
17329/30300 (epoch 28.596), train_loss = 1.01667499, grad/param norm = 1.4581e-01, time/batch = 16.4421s	
17330/30300 (epoch 28.597), train_loss = 1.04527401, grad/param norm = 1.6064e-01, time/batch = 17.5347s	
17331/30300 (epoch 28.599), train_loss = 0.92589438, grad/param norm = 1.4471e-01, time/batch = 19.2887s	
17332/30300 (epoch 28.601), train_loss = 1.12458969, grad/param norm = 1.4962e-01, time/batch = 18.8992s	
17333/30300 (epoch 28.602), train_loss = 1.09668910, grad/param norm = 1.4906e-01, time/batch = 19.2877s	
17334/30300 (epoch 28.604), train_loss = 1.02759220, grad/param norm = 1.4221e-01, time/batch = 18.0973s	
17335/30300 (epoch 28.606), train_loss = 1.06284081, grad/param norm = 2.6870e-01, time/batch = 19.3899s	
17336/30300 (epoch 28.607), train_loss = 1.17282198, grad/param norm = 1.8323e-01, time/batch = 19.6242s	
17337/30300 (epoch 28.609), train_loss = 1.31536559, grad/param norm = 1.7499e-01, time/batch = 18.3910s	
17338/30300 (epoch 28.611), train_loss = 1.04275930, grad/param norm = 1.4134e-01, time/batch = 19.0620s	
17339/30300 (epoch 28.612), train_loss = 1.00500327, grad/param norm = 1.3755e-01, time/batch = 19.5323s	
17340/30300 (epoch 28.614), train_loss = 1.07623272, grad/param norm = 1.4635e-01, time/batch = 18.2002s	
17341/30300 (epoch 28.616), train_loss = 1.15381999, grad/param norm = 2.2164e-01, time/batch = 19.7871s	
17342/30300 (epoch 28.617), train_loss = 1.13683099, grad/param norm = 1.5683e-01, time/batch = 18.9615s	
17343/30300 (epoch 28.619), train_loss = 0.93208289, grad/param norm = 1.4471e-01, time/batch = 17.2070s	
17344/30300 (epoch 28.620), train_loss = 1.15907516, grad/param norm = 1.7300e-01, time/batch = 19.7059s	
17345/30300 (epoch 28.622), train_loss = 1.11267112, grad/param norm = 1.7766e-01, time/batch = 17.9477s	
17346/30300 (epoch 28.624), train_loss = 1.06477531, grad/param norm = 1.5158e-01, time/batch = 18.8683s	
17347/30300 (epoch 28.625), train_loss = 1.05875745, grad/param norm = 1.6145e-01, time/batch = 18.7937s	
17348/30300 (epoch 28.627), train_loss = 1.23867511, grad/param norm = 1.9041e-01, time/batch = 19.4747s	
17349/30300 (epoch 28.629), train_loss = 1.24243183, grad/param norm = 1.5802e-01, time/batch = 19.4522s	
17350/30300 (epoch 28.630), train_loss = 1.12392253, grad/param norm = 1.6382e-01, time/batch = 19.7027s	
17351/30300 (epoch 28.632), train_loss = 1.18669298, grad/param norm = 1.7200e-01, time/batch = 19.6188s	
17352/30300 (epoch 28.634), train_loss = 1.03445853, grad/param norm = 1.4366e-01, time/batch = 19.5399s	
17353/30300 (epoch 28.635), train_loss = 1.16570678, grad/param norm = 1.7495e-01, time/batch = 19.7477s	
17354/30300 (epoch 28.637), train_loss = 1.19053482, grad/param norm = 1.8375e-01, time/batch = 20.1904s	
17355/30300 (epoch 28.639), train_loss = 1.07966679, grad/param norm = 1.6471e-01, time/batch = 18.8885s	
17356/30300 (epoch 28.640), train_loss = 1.21287199, grad/param norm = 1.7903e-01, time/batch = 16.4586s	
17357/30300 (epoch 28.642), train_loss = 1.07817482, grad/param norm = 1.3925e-01, time/batch = 18.7336s	
17358/30300 (epoch 28.644), train_loss = 1.18294179, grad/param norm = 1.6708e-01, time/batch = 19.4557s	
17359/30300 (epoch 28.645), train_loss = 1.05109668, grad/param norm = 1.5633e-01, time/batch = 17.9537s	
17360/30300 (epoch 28.647), train_loss = 1.13144200, grad/param norm = 1.4943e-01, time/batch = 19.5539s	
17361/30300 (epoch 28.649), train_loss = 1.08811105, grad/param norm = 1.7104e-01, time/batch = 19.1235s	
17362/30300 (epoch 28.650), train_loss = 1.09674376, grad/param norm = 1.5130e-01, time/batch = 18.5456s	
17363/30300 (epoch 28.652), train_loss = 1.07494584, grad/param norm = 1.6181e-01, time/batch = 19.6212s	
17364/30300 (epoch 28.653), train_loss = 1.28547609, grad/param norm = 1.5964e-01, time/batch = 19.6228s	
17365/30300 (epoch 28.655), train_loss = 1.04653641, grad/param norm = 1.5213e-01, time/batch = 17.7637s	
17366/30300 (epoch 28.657), train_loss = 1.04230487, grad/param norm = 1.6353e-01, time/batch = 19.6004s	
17367/30300 (epoch 28.658), train_loss = 1.02610645, grad/param norm = 1.4488e-01, time/batch = 18.6383s	
17368/30300 (epoch 28.660), train_loss = 1.10944938, grad/param norm = 1.5833e-01, time/batch = 19.2954s	
17369/30300 (epoch 28.662), train_loss = 1.11563873, grad/param norm = 1.7965e-01, time/batch = 18.6276s	
17370/30300 (epoch 28.663), train_loss = 1.15411797, grad/param norm = 1.6664e-01, time/batch = 19.4015s	
17371/30300 (epoch 28.665), train_loss = 1.05329694, grad/param norm = 1.6260e-01, time/batch = 18.9630s	
17372/30300 (epoch 28.667), train_loss = 1.18308758, grad/param norm = 1.6965e-01, time/batch = 19.0468s	
17373/30300 (epoch 28.668), train_loss = 1.19796128, grad/param norm = 1.6711e-01, time/batch = 19.4691s	
17374/30300 (epoch 28.670), train_loss = 1.22797421, grad/param norm = 1.7877e-01, time/batch = 17.6914s	
17375/30300 (epoch 28.672), train_loss = 1.12381116, grad/param norm = 1.7923e-01, time/batch = 18.5326s	
17376/30300 (epoch 28.673), train_loss = 1.17723007, grad/param norm = 1.9065e-01, time/batch = 19.0188s	
17377/30300 (epoch 28.675), train_loss = 1.06656754, grad/param norm = 1.5132e-01, time/batch = 20.2956s	
17378/30300 (epoch 28.677), train_loss = 1.05655208, grad/param norm = 1.4364e-01, time/batch = 19.0296s	
17379/30300 (epoch 28.678), train_loss = 1.04973764, grad/param norm = 1.4990e-01, time/batch = 19.0551s	
17380/30300 (epoch 28.680), train_loss = 0.93702015, grad/param norm = 1.4407e-01, time/batch = 20.6327s	
17381/30300 (epoch 28.682), train_loss = 1.08620868, grad/param norm = 1.5017e-01, time/batch = 18.0262s	
17382/30300 (epoch 28.683), train_loss = 1.19774445, grad/param norm = 1.4720e-01, time/batch = 18.2628s	
17383/30300 (epoch 28.685), train_loss = 1.19760607, grad/param norm = 1.9941e-01, time/batch = 19.5036s	
17384/30300 (epoch 28.686), train_loss = 1.07391877, grad/param norm = 1.4199e-01, time/batch = 18.3566s	
17385/30300 (epoch 28.688), train_loss = 1.11432269, grad/param norm = 1.5064e-01, time/batch = 19.5285s	
17386/30300 (epoch 28.690), train_loss = 1.06088180, grad/param norm = 1.7808e-01, time/batch = 19.7788s	
17387/30300 (epoch 28.691), train_loss = 1.15291261, grad/param norm = 1.6639e-01, time/batch = 18.2053s	
17388/30300 (epoch 28.693), train_loss = 1.40363718, grad/param norm = 1.7845e-01, time/batch = 17.1848s	
17389/30300 (epoch 28.695), train_loss = 1.19940588, grad/param norm = 1.7125e-01, time/batch = 19.5573s	
17390/30300 (epoch 28.696), train_loss = 1.18170906, grad/param norm = 2.0625e-01, time/batch = 18.7175s	
17391/30300 (epoch 28.698), train_loss = 1.05273884, grad/param norm = 1.5829e-01, time/batch = 17.2795s	
17392/30300 (epoch 28.700), train_loss = 1.04029719, grad/param norm = 1.5652e-01, time/batch = 19.7773s	
17393/30300 (epoch 28.701), train_loss = 0.96366475, grad/param norm = 1.4167e-01, time/batch = 19.1268s	
17394/30300 (epoch 28.703), train_loss = 1.11876072, grad/param norm = 1.5000e-01, time/batch = 18.7952s	
17395/30300 (epoch 28.705), train_loss = 1.03539111, grad/param norm = 1.4211e-01, time/batch = 19.1209s	
17396/30300 (epoch 28.706), train_loss = 1.16501356, grad/param norm = 1.6924e-01, time/batch = 20.6847s	
17397/30300 (epoch 28.708), train_loss = 1.09322364, grad/param norm = 1.5883e-01, time/batch = 18.6055s	
17398/30300 (epoch 28.710), train_loss = 1.08072635, grad/param norm = 1.6063e-01, time/batch = 18.2022s	
17399/30300 (epoch 28.711), train_loss = 1.02638907, grad/param norm = 1.4863e-01, time/batch = 19.7589s	
17400/30300 (epoch 28.713), train_loss = 1.02195912, grad/param norm = 1.7672e-01, time/batch = 18.9418s	
17401/30300 (epoch 28.715), train_loss = 1.05551548, grad/param norm = 1.5770e-01, time/batch = 19.4419s	
17402/30300 (epoch 28.716), train_loss = 1.19473412, grad/param norm = 1.5068e-01, time/batch = 20.1986s	
17403/30300 (epoch 28.718), train_loss = 1.21410833, grad/param norm = 1.6553e-01, time/batch = 18.1257s	
17404/30300 (epoch 28.719), train_loss = 1.06609481, grad/param norm = 1.7552e-01, time/batch = 19.2787s	
17405/30300 (epoch 28.721), train_loss = 1.09182946, grad/param norm = 1.7441e-01, time/batch = 19.3848s	
17406/30300 (epoch 28.723), train_loss = 1.05007566, grad/param norm = 1.5827e-01, time/batch = 17.8648s	
17407/30300 (epoch 28.724), train_loss = 1.14229480, grad/param norm = 1.8374e-01, time/batch = 18.8557s	
17408/30300 (epoch 28.726), train_loss = 1.45034262, grad/param norm = 2.0627e-01, time/batch = 20.3621s	
17409/30300 (epoch 28.728), train_loss = 1.15638788, grad/param norm = 1.5665e-01, time/batch = 17.2680s	
17410/30300 (epoch 28.729), train_loss = 1.07829873, grad/param norm = 1.6863e-01, time/batch = 19.5346s	
17411/30300 (epoch 28.731), train_loss = 1.11945903, grad/param norm = 1.7025e-01, time/batch = 19.6182s	
17412/30300 (epoch 28.733), train_loss = 1.12615645, grad/param norm = 1.7507e-01, time/batch = 18.4489s	
17413/30300 (epoch 28.734), train_loss = 1.20399970, grad/param norm = 1.4928e-01, time/batch = 19.4590s	
17414/30300 (epoch 28.736), train_loss = 1.10432056, grad/param norm = 1.5792e-01, time/batch = 17.9381s	
17415/30300 (epoch 28.738), train_loss = 1.04144307, grad/param norm = 1.3866e-01, time/batch = 18.6033s	
17416/30300 (epoch 28.739), train_loss = 1.18854651, grad/param norm = 1.5977e-01, time/batch = 18.1176s	
17417/30300 (epoch 28.741), train_loss = 1.25299366, grad/param norm = 1.5029e-01, time/batch = 18.0265s	
17418/30300 (epoch 28.743), train_loss = 1.10250290, grad/param norm = 1.6474e-01, time/batch = 19.7922s	
17419/30300 (epoch 28.744), train_loss = 1.13051015, grad/param norm = 1.4846e-01, time/batch = 17.6172s	
17420/30300 (epoch 28.746), train_loss = 1.05829472, grad/param norm = 1.5241e-01, time/batch = 19.3707s	
17421/30300 (epoch 28.748), train_loss = 1.09140020, grad/param norm = 1.7951e-01, time/batch = 19.8572s	
17422/30300 (epoch 28.749), train_loss = 1.15049065, grad/param norm = 1.6632e-01, time/batch = 16.8496s	
17423/30300 (epoch 28.751), train_loss = 1.11340888, grad/param norm = 1.6394e-01, time/batch = 19.8545s	
17424/30300 (epoch 28.752), train_loss = 1.08147500, grad/param norm = 1.6766e-01, time/batch = 20.1090s	
17425/30300 (epoch 28.754), train_loss = 1.05081574, grad/param norm = 1.4395e-01, time/batch = 16.7769s	
17426/30300 (epoch 28.756), train_loss = 1.06460117, grad/param norm = 1.5091e-01, time/batch = 19.1928s	
17427/30300 (epoch 28.757), train_loss = 1.08235631, grad/param norm = 1.5437e-01, time/batch = 20.0374s	
17428/30300 (epoch 28.759), train_loss = 1.14274809, grad/param norm = 1.5317e-01, time/batch = 18.7054s	
17429/30300 (epoch 28.761), train_loss = 0.96299175, grad/param norm = 1.4301e-01, time/batch = 20.1028s	
17430/30300 (epoch 28.762), train_loss = 1.00692232, grad/param norm = 1.4908e-01, time/batch = 18.6238s	
17431/30300 (epoch 28.764), train_loss = 1.09693119, grad/param norm = 1.6534e-01, time/batch = 18.2946s	
17432/30300 (epoch 28.766), train_loss = 1.20684620, grad/param norm = 1.6010e-01, time/batch = 19.0060s	
17433/30300 (epoch 28.767), train_loss = 1.17782950, grad/param norm = 2.0285e-01, time/batch = 18.4613s	
17434/30300 (epoch 28.769), train_loss = 1.12495948, grad/param norm = 1.5738e-01, time/batch = 19.2919s	
17435/30300 (epoch 28.771), train_loss = 1.07424391, grad/param norm = 1.9362e-01, time/batch = 19.1032s	
17436/30300 (epoch 28.772), train_loss = 1.15905195, grad/param norm = 1.6197e-01, time/batch = 19.1185s	
17437/30300 (epoch 28.774), train_loss = 1.24080093, grad/param norm = 1.5638e-01, time/batch = 19.5325s	
17438/30300 (epoch 28.776), train_loss = 1.11471827, grad/param norm = 1.6722e-01, time/batch = 17.9282s	
17439/30300 (epoch 28.777), train_loss = 1.21709142, grad/param norm = 1.5057e-01, time/batch = 19.6073s	
17440/30300 (epoch 28.779), train_loss = 1.23160310, grad/param norm = 1.7756e-01, time/batch = 19.6736s	
17441/30300 (epoch 28.781), train_loss = 1.11794409, grad/param norm = 1.6452e-01, time/batch = 18.1017s	
17442/30300 (epoch 28.782), train_loss = 1.06059474, grad/param norm = 1.6430e-01, time/batch = 20.5241s	
17443/30300 (epoch 28.784), train_loss = 1.04969212, grad/param norm = 1.5073e-01, time/batch = 20.0108s	
17444/30300 (epoch 28.785), train_loss = 1.22576454, grad/param norm = 1.8124e-01, time/batch = 17.2739s	
17445/30300 (epoch 28.787), train_loss = 0.93255467, grad/param norm = 1.5643e-01, time/batch = 19.0391s	
17446/30300 (epoch 28.789), train_loss = 1.31369002, grad/param norm = 1.8501e-01, time/batch = 19.2132s	
17447/30300 (epoch 28.790), train_loss = 1.15313490, grad/param norm = 1.8426e-01, time/batch = 18.7036s	
17448/30300 (epoch 28.792), train_loss = 0.94564097, grad/param norm = 1.6934e-01, time/batch = 17.3656s	
17449/30300 (epoch 28.794), train_loss = 1.10648366, grad/param norm = 1.7332e-01, time/batch = 19.4473s	
17450/30300 (epoch 28.795), train_loss = 1.02163773, grad/param norm = 1.4810e-01, time/batch = 18.8735s	
17451/30300 (epoch 28.797), train_loss = 1.25988644, grad/param norm = 1.8663e-01, time/batch = 18.5313s	
17452/30300 (epoch 28.799), train_loss = 1.18960274, grad/param norm = 1.7536e-01, time/batch = 18.2814s	
17453/30300 (epoch 28.800), train_loss = 1.18883718, grad/param norm = 1.5928e-01, time/batch = 19.0100s	
17454/30300 (epoch 28.802), train_loss = 1.36334548, grad/param norm = 1.7956e-01, time/batch = 18.1098s	
17455/30300 (epoch 28.804), train_loss = 1.19323213, grad/param norm = 1.8243e-01, time/batch = 19.6195s	
17456/30300 (epoch 28.805), train_loss = 1.24803230, grad/param norm = 1.7047e-01, time/batch = 19.8728s	
17457/30300 (epoch 28.807), train_loss = 1.09383057, grad/param norm = 1.7289e-01, time/batch = 19.2092s	
17458/30300 (epoch 28.809), train_loss = 1.18581509, grad/param norm = 1.6503e-01, time/batch = 18.8621s	
17459/30300 (epoch 28.810), train_loss = 1.18108698, grad/param norm = 1.6277e-01, time/batch = 19.3686s	
17460/30300 (epoch 28.812), train_loss = 1.04461881, grad/param norm = 1.5200e-01, time/batch = 17.9224s	
17461/30300 (epoch 28.814), train_loss = 1.10872907, grad/param norm = 1.5913e-01, time/batch = 19.5105s	
17462/30300 (epoch 28.815), train_loss = 1.13253998, grad/param norm = 1.8021e-01, time/batch = 18.5453s	
17463/30300 (epoch 28.817), train_loss = 1.21322295, grad/param norm = 1.7686e-01, time/batch = 18.2449s	
17464/30300 (epoch 28.818), train_loss = 1.15051458, grad/param norm = 1.6623e-01, time/batch = 17.5940s	
17465/30300 (epoch 28.820), train_loss = 1.27880570, grad/param norm = 1.7670e-01, time/batch = 19.0924s	
17466/30300 (epoch 28.822), train_loss = 1.26496315, grad/param norm = 1.7840e-01, time/batch = 16.8345s	
17467/30300 (epoch 28.823), train_loss = 1.27687969, grad/param norm = 1.8792e-01, time/batch = 16.0595s	
17468/30300 (epoch 28.825), train_loss = 1.25678511, grad/param norm = 1.7795e-01, time/batch = 17.0726s	
17469/30300 (epoch 28.827), train_loss = 0.96797250, grad/param norm = 1.6560e-01, time/batch = 18.3566s	
17470/30300 (epoch 28.828), train_loss = 1.21077042, grad/param norm = 1.6616e-01, time/batch = 17.0207s	
17471/30300 (epoch 28.830), train_loss = 1.16959511, grad/param norm = 1.6414e-01, time/batch = 19.9230s	
17472/30300 (epoch 28.832), train_loss = 1.04647685, grad/param norm = 1.6656e-01, time/batch = 17.3401s	
17473/30300 (epoch 28.833), train_loss = 1.14826373, grad/param norm = 1.6783e-01, time/batch = 17.6713s	
17474/30300 (epoch 28.835), train_loss = 1.04488688, grad/param norm = 1.5973e-01, time/batch = 19.3638s	
17475/30300 (epoch 28.837), train_loss = 1.01473264, grad/param norm = 1.5556e-01, time/batch = 20.0273s	
17476/30300 (epoch 28.838), train_loss = 1.02601302, grad/param norm = 1.6827e-01, time/batch = 17.5858s	
17477/30300 (epoch 28.840), train_loss = 1.21030212, grad/param norm = 1.4375e-01, time/batch = 18.1563s	
17478/30300 (epoch 28.842), train_loss = 1.06430658, grad/param norm = 1.4317e-01, time/batch = 18.7623s	
17479/30300 (epoch 28.843), train_loss = 1.16303199, grad/param norm = 1.5801e-01, time/batch = 19.1053s	
17480/30300 (epoch 28.845), train_loss = 1.18133694, grad/param norm = 1.5324e-01, time/batch = 18.6247s	
17481/30300 (epoch 28.847), train_loss = 1.14239303, grad/param norm = 1.6354e-01, time/batch = 18.5450s	
17482/30300 (epoch 28.848), train_loss = 1.19489093, grad/param norm = 1.6503e-01, time/batch = 19.1793s	
17483/30300 (epoch 28.850), train_loss = 1.11876694, grad/param norm = 2.0248e-01, time/batch = 17.5193s	
17484/30300 (epoch 28.851), train_loss = 1.15209174, grad/param norm = 2.0243e-01, time/batch = 19.4510s	
17485/30300 (epoch 28.853), train_loss = 1.06881673, grad/param norm = 1.4943e-01, time/batch = 19.1977s	
17486/30300 (epoch 28.855), train_loss = 1.07397573, grad/param norm = 1.3757e-01, time/batch = 16.6222s	
17487/30300 (epoch 28.856), train_loss = 1.14201796, grad/param norm = 1.7629e-01, time/batch = 18.0238s	
17488/30300 (epoch 28.858), train_loss = 1.05164509, grad/param norm = 1.3694e-01, time/batch = 19.0212s	
17489/30300 (epoch 28.860), train_loss = 1.03334207, grad/param norm = 1.5256e-01, time/batch = 18.5471s	
17490/30300 (epoch 28.861), train_loss = 1.28844213, grad/param norm = 1.6434e-01, time/batch = 18.2795s	
17491/30300 (epoch 28.863), train_loss = 1.10441540, grad/param norm = 1.4872e-01, time/batch = 19.0375s	
17492/30300 (epoch 28.865), train_loss = 1.18034491, grad/param norm = 1.7344e-01, time/batch = 18.2608s	
17493/30300 (epoch 28.866), train_loss = 1.17564099, grad/param norm = 2.0930e-01, time/batch = 17.8353s	
17494/30300 (epoch 28.868), train_loss = 1.13678295, grad/param norm = 1.6367e-01, time/batch = 18.0318s	
17495/30300 (epoch 28.870), train_loss = 1.04899197, grad/param norm = 1.4910e-01, time/batch = 19.2878s	
17496/30300 (epoch 28.871), train_loss = 1.12185165, grad/param norm = 1.5641e-01, time/batch = 18.9288s	
17497/30300 (epoch 28.873), train_loss = 1.11351689, grad/param norm = 1.4314e-01, time/batch = 17.3161s	
17498/30300 (epoch 28.875), train_loss = 1.08258110, grad/param norm = 1.5120e-01, time/batch = 19.6776s	
17499/30300 (epoch 28.876), train_loss = 1.01174509, grad/param norm = 1.8030e-01, time/batch = 18.5156s	
17500/30300 (epoch 28.878), train_loss = 0.97406826, grad/param norm = 1.5694e-01, time/batch = 18.1023s	
17501/30300 (epoch 28.880), train_loss = 1.02876766, grad/param norm = 1.6695e-01, time/batch = 17.6194s	
17502/30300 (epoch 28.881), train_loss = 1.26286595, grad/param norm = 1.9387e-01, time/batch = 18.0290s	
17503/30300 (epoch 28.883), train_loss = 1.17251405, grad/param norm = 1.6361e-01, time/batch = 18.3773s	
17504/30300 (epoch 28.884), train_loss = 1.07147915, grad/param norm = 1.3880e-01, time/batch = 19.7186s	
17505/30300 (epoch 28.886), train_loss = 1.15776169, grad/param norm = 1.5260e-01, time/batch = 18.6294s	
17506/30300 (epoch 28.888), train_loss = 1.10633196, grad/param norm = 1.7211e-01, time/batch = 19.7934s	
17507/30300 (epoch 28.889), train_loss = 1.14423926, grad/param norm = 1.5611e-01, time/batch = 20.0656s	
17508/30300 (epoch 28.891), train_loss = 1.09635686, grad/param norm = 1.5396e-01, time/batch = 23.8200s	
17509/30300 (epoch 28.893), train_loss = 1.33550026, grad/param norm = 1.6126e-01, time/batch = 28.7057s	
17510/30300 (epoch 28.894), train_loss = 1.16164433, grad/param norm = 1.5787e-01, time/batch = 20.2046s	
17511/30300 (epoch 28.896), train_loss = 0.95043363, grad/param norm = 1.4349e-01, time/batch = 19.4964s	
17512/30300 (epoch 28.898), train_loss = 0.96228783, grad/param norm = 1.5011e-01, time/batch = 17.9599s	
17513/30300 (epoch 28.899), train_loss = 1.02909126, grad/param norm = 1.4789e-01, time/batch = 19.1287s	
17514/30300 (epoch 28.901), train_loss = 1.11623056, grad/param norm = 1.6556e-01, time/batch = 17.9530s	
17515/30300 (epoch 28.903), train_loss = 1.12444381, grad/param norm = 1.8281e-01, time/batch = 17.5931s	
17516/30300 (epoch 28.904), train_loss = 1.12858148, grad/param norm = 1.6052e-01, time/batch = 20.2814s	
17517/30300 (epoch 28.906), train_loss = 1.16342793, grad/param norm = 1.8303e-01, time/batch = 18.1123s	
17518/30300 (epoch 28.908), train_loss = 1.07184685, grad/param norm = 1.4916e-01, time/batch = 18.5110s	
17519/30300 (epoch 28.909), train_loss = 1.03060007, grad/param norm = 1.7302e-01, time/batch = 20.0268s	
17520/30300 (epoch 28.911), train_loss = 1.13026796, grad/param norm = 1.6448e-01, time/batch = 18.8724s	
17521/30300 (epoch 28.913), train_loss = 1.10944066, grad/param norm = 1.4597e-01, time/batch = 19.7965s	
17522/30300 (epoch 28.914), train_loss = 1.08709657, grad/param norm = 1.6131e-01, time/batch = 19.9483s	
17523/30300 (epoch 28.916), train_loss = 1.14592254, grad/param norm = 1.5095e-01, time/batch = 18.0494s	
17524/30300 (epoch 28.917), train_loss = 1.08133725, grad/param norm = 1.5627e-01, time/batch = 19.6357s	
17525/30300 (epoch 28.919), train_loss = 1.03795027, grad/param norm = 1.5533e-01, time/batch = 19.1250s	
17526/30300 (epoch 28.921), train_loss = 1.08935538, grad/param norm = 1.3935e-01, time/batch = 19.2094s	
17527/30300 (epoch 28.922), train_loss = 1.21294698, grad/param norm = 1.8159e-01, time/batch = 19.7440s	
17528/30300 (epoch 28.924), train_loss = 1.11548011, grad/param norm = 1.6931e-01, time/batch = 18.7676s	
17529/30300 (epoch 28.926), train_loss = 1.15979304, grad/param norm = 1.6199e-01, time/batch = 19.8440s	
17530/30300 (epoch 28.927), train_loss = 1.13549176, grad/param norm = 1.6397e-01, time/batch = 18.8349s	
17531/30300 (epoch 28.929), train_loss = 1.03230136, grad/param norm = 1.6662e-01, time/batch = 19.9582s	
17532/30300 (epoch 28.931), train_loss = 1.20051997, grad/param norm = 2.1248e-01, time/batch = 19.0093s	
17533/30300 (epoch 28.932), train_loss = 1.05787612, grad/param norm = 1.6917e-01, time/batch = 18.6914s	
17534/30300 (epoch 28.934), train_loss = 1.14635241, grad/param norm = 1.6258e-01, time/batch = 19.5333s	
17535/30300 (epoch 28.936), train_loss = 1.06354508, grad/param norm = 2.4145e-01, time/batch = 19.5448s	
17536/30300 (epoch 28.937), train_loss = 1.05896175, grad/param norm = 1.5391e-01, time/batch = 19.3711s	
17537/30300 (epoch 28.939), train_loss = 1.25369168, grad/param norm = 1.9598e-01, time/batch = 17.3916s	
17538/30300 (epoch 28.941), train_loss = 1.08107710, grad/param norm = 1.7967e-01, time/batch = 19.6356s	
17539/30300 (epoch 28.942), train_loss = 1.10334137, grad/param norm = 1.7259e-01, time/batch = 17.6727s	
17540/30300 (epoch 28.944), train_loss = 1.00511542, grad/param norm = 1.5368e-01, time/batch = 18.9533s	
17541/30300 (epoch 28.946), train_loss = 1.22912593, grad/param norm = 1.9676e-01, time/batch = 20.0329s	
17542/30300 (epoch 28.947), train_loss = 1.19443725, grad/param norm = 1.8155e-01, time/batch = 18.1967s	
17543/30300 (epoch 28.949), train_loss = 1.23636084, grad/param norm = 2.1066e-01, time/batch = 19.3714s	
17544/30300 (epoch 28.950), train_loss = 1.21493831, grad/param norm = 1.7047e-01, time/batch = 18.0916s	
17545/30300 (epoch 28.952), train_loss = 1.16947720, grad/param norm = 1.7763e-01, time/batch = 17.6084s	
17546/30300 (epoch 28.954), train_loss = 1.38518703, grad/param norm = 1.7223e-01, time/batch = 18.5021s	
17547/30300 (epoch 28.955), train_loss = 1.09829886, grad/param norm = 1.4755e-01, time/batch = 20.1159s	
17548/30300 (epoch 28.957), train_loss = 1.18302114, grad/param norm = 1.5960e-01, time/batch = 16.8052s	
17549/30300 (epoch 28.959), train_loss = 1.05132052, grad/param norm = 1.7794e-01, time/batch = 17.9811s	
17550/30300 (epoch 28.960), train_loss = 1.08035287, grad/param norm = 1.5812e-01, time/batch = 18.5296s	
17551/30300 (epoch 28.962), train_loss = 1.11002577, grad/param norm = 2.1377e-01, time/batch = 19.6016s	
17552/30300 (epoch 28.964), train_loss = 1.04018333, grad/param norm = 1.8977e-01, time/batch = 18.0922s	
17553/30300 (epoch 28.965), train_loss = 1.06065589, grad/param norm = 1.7617e-01, time/batch = 19.6734s	
17554/30300 (epoch 28.967), train_loss = 1.13275522, grad/param norm = 2.0621e-01, time/batch = 19.2100s	
17555/30300 (epoch 28.969), train_loss = 1.03599484, grad/param norm = 1.8781e-01, time/batch = 17.0877s	
17556/30300 (epoch 28.970), train_loss = 1.08696321, grad/param norm = 1.5491e-01, time/batch = 19.3576s	
17557/30300 (epoch 28.972), train_loss = 1.01009565, grad/param norm = 1.7194e-01, time/batch = 18.8990s	
17558/30300 (epoch 28.974), train_loss = 1.28054511, grad/param norm = 1.8868e-01, time/batch = 17.3444s	
17559/30300 (epoch 28.975), train_loss = 1.28987507, grad/param norm = 2.0136e-01, time/batch = 15.3215s	
17560/30300 (epoch 28.977), train_loss = 1.27800805, grad/param norm = 1.6906e-01, time/batch = 16.1957s	
17561/30300 (epoch 28.979), train_loss = 1.18938601, grad/param norm = 1.7792e-01, time/batch = 15.1265s	
17562/30300 (epoch 28.980), train_loss = 1.21197061, grad/param norm = 1.7621e-01, time/batch = 16.9904s	
17563/30300 (epoch 28.982), train_loss = 1.22168231, grad/param norm = 1.7117e-01, time/batch = 19.6722s	
17564/30300 (epoch 28.983), train_loss = 1.25267493, grad/param norm = 1.6824e-01, time/batch = 17.7478s	
17565/30300 (epoch 28.985), train_loss = 1.18316351, grad/param norm = 1.9352e-01, time/batch = 18.3302s	
17566/30300 (epoch 28.987), train_loss = 1.10124750, grad/param norm = 1.5187e-01, time/batch = 17.9357s	
17567/30300 (epoch 28.988), train_loss = 1.26392267, grad/param norm = 1.8798e-01, time/batch = 19.5971s	
17568/30300 (epoch 28.990), train_loss = 1.00633609, grad/param norm = 1.4317e-01, time/batch = 16.5634s	
17569/30300 (epoch 28.992), train_loss = 1.19856538, grad/param norm = 1.5417e-01, time/batch = 18.1742s	
17570/30300 (epoch 28.993), train_loss = 1.25737735, grad/param norm = 2.1006e-01, time/batch = 16.7332s	
17571/30300 (epoch 28.995), train_loss = 1.11769936, grad/param norm = 1.7823e-01, time/batch = 17.1455s	
17572/30300 (epoch 28.997), train_loss = 1.14404457, grad/param norm = 1.6753e-01, time/batch = 16.9062s	
17573/30300 (epoch 28.998), train_loss = 1.18309755, grad/param norm = 1.7551e-01, time/batch = 18.9154s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
17574/30300 (epoch 29.000), train_loss = 1.09566277, grad/param norm = 1.9064e-01, time/batch = 20.0300s	
17575/30300 (epoch 29.002), train_loss = 1.23332425, grad/param norm = 1.8396e-01, time/batch = 17.6977s	
17576/30300 (epoch 29.003), train_loss = 1.12333096, grad/param norm = 1.6641e-01, time/batch = 18.5579s	
17577/30300 (epoch 29.005), train_loss = 1.07801187, grad/param norm = 1.6660e-01, time/batch = 19.1957s	
17578/30300 (epoch 29.007), train_loss = 1.16102411, grad/param norm = 1.7871e-01, time/batch = 16.9325s	
17579/30300 (epoch 29.008), train_loss = 1.08211752, grad/param norm = 1.7879e-01, time/batch = 16.0852s	
17580/30300 (epoch 29.010), train_loss = 1.00296974, grad/param norm = 1.6203e-01, time/batch = 18.2419s	
17581/30300 (epoch 29.012), train_loss = 1.06282079, grad/param norm = 1.4988e-01, time/batch = 19.1192s	
17582/30300 (epoch 29.013), train_loss = 1.22182543, grad/param norm = 1.7236e-01, time/batch = 18.4224s	
17583/30300 (epoch 29.015), train_loss = 1.09586992, grad/param norm = 1.5899e-01, time/batch = 17.0777s	
17584/30300 (epoch 29.017), train_loss = 1.08451090, grad/param norm = 1.5155e-01, time/batch = 17.2211s	
17585/30300 (epoch 29.018), train_loss = 1.03316659, grad/param norm = 1.5959e-01, time/batch = 16.5781s	
17586/30300 (epoch 29.020), train_loss = 1.22533808, grad/param norm = 2.0075e-01, time/batch = 17.6404s	
17587/30300 (epoch 29.021), train_loss = 1.24378070, grad/param norm = 1.6974e-01, time/batch = 19.9140s	
17588/30300 (epoch 29.023), train_loss = 1.15135966, grad/param norm = 1.6073e-01, time/batch = 18.0145s	
17589/30300 (epoch 29.025), train_loss = 1.04850548, grad/param norm = 1.7470e-01, time/batch = 19.2363s	
17590/30300 (epoch 29.026), train_loss = 1.18610316, grad/param norm = 2.0613e-01, time/batch = 16.7373s	
17591/30300 (epoch 29.028), train_loss = 1.21701238, grad/param norm = 1.7959e-01, time/batch = 18.2515s	
17592/30300 (epoch 29.030), train_loss = 1.07769218, grad/param norm = 1.7062e-01, time/batch = 18.7525s	
17593/30300 (epoch 29.031), train_loss = 1.19484335, grad/param norm = 1.6735e-01, time/batch = 18.6294s	
17594/30300 (epoch 29.033), train_loss = 1.12515424, grad/param norm = 1.5537e-01, time/batch = 19.6992s	
17595/30300 (epoch 29.035), train_loss = 1.21057328, grad/param norm = 1.8735e-01, time/batch = 18.9410s	
17596/30300 (epoch 29.036), train_loss = 1.14074134, grad/param norm = 1.5780e-01, time/batch = 19.5410s	
17597/30300 (epoch 29.038), train_loss = 1.16191255, grad/param norm = 1.5188e-01, time/batch = 19.4596s	
17598/30300 (epoch 29.040), train_loss = 0.91763761, grad/param norm = 1.4324e-01, time/batch = 17.1095s	
17599/30300 (epoch 29.041), train_loss = 0.94743200, grad/param norm = 1.5720e-01, time/batch = 18.0976s	
17600/30300 (epoch 29.043), train_loss = 1.14164537, grad/param norm = 1.7093e-01, time/batch = 19.3740s	
17601/30300 (epoch 29.045), train_loss = 1.10831145, grad/param norm = 1.5236e-01, time/batch = 18.0314s	
17602/30300 (epoch 29.046), train_loss = 1.30494749, grad/param norm = 1.9765e-01, time/batch = 19.6202s	
17603/30300 (epoch 29.048), train_loss = 1.10994742, grad/param norm = 1.7503e-01, time/batch = 19.6238s	
17604/30300 (epoch 29.050), train_loss = 1.07019855, grad/param norm = 1.6391e-01, time/batch = 18.4475s	
17605/30300 (epoch 29.051), train_loss = 1.14127181, grad/param norm = 1.7126e-01, time/batch = 19.8448s	
17606/30300 (epoch 29.053), train_loss = 0.97112565, grad/param norm = 1.9158e-01, time/batch = 16.2622s	
17607/30300 (epoch 29.054), train_loss = 1.15256107, grad/param norm = 1.6683e-01, time/batch = 17.7221s	
17608/30300 (epoch 29.056), train_loss = 1.03721103, grad/param norm = 1.6352e-01, time/batch = 18.2831s	
17609/30300 (epoch 29.058), train_loss = 1.09513330, grad/param norm = 1.5628e-01, time/batch = 17.0871s	
17610/30300 (epoch 29.059), train_loss = 1.05201386, grad/param norm = 1.8767e-01, time/batch = 19.5318s	
17611/30300 (epoch 29.061), train_loss = 1.17784697, grad/param norm = 1.6973e-01, time/batch = 16.8633s	
17612/30300 (epoch 29.063), train_loss = 1.01093295, grad/param norm = 1.6270e-01, time/batch = 19.1303s	
17613/30300 (epoch 29.064), train_loss = 1.13109603, grad/param norm = 1.6636e-01, time/batch = 19.0367s	
17614/30300 (epoch 29.066), train_loss = 1.11964020, grad/param norm = 1.5946e-01, time/batch = 18.0366s	
17615/30300 (epoch 29.068), train_loss = 1.02107453, grad/param norm = 1.6509e-01, time/batch = 18.7785s	
17616/30300 (epoch 29.069), train_loss = 1.19130455, grad/param norm = 1.7805e-01, time/batch = 15.8796s	
17617/30300 (epoch 29.071), train_loss = 1.17005425, grad/param norm = 1.7693e-01, time/batch = 18.6288s	
17618/30300 (epoch 29.073), train_loss = 1.06223201, grad/param norm = 1.7200e-01, time/batch = 18.7876s	
17619/30300 (epoch 29.074), train_loss = 1.12663917, grad/param norm = 1.5506e-01, time/batch = 18.9559s	
17620/30300 (epoch 29.076), train_loss = 1.09219991, grad/param norm = 1.6368e-01, time/batch = 19.8813s	
17621/30300 (epoch 29.078), train_loss = 1.03372469, grad/param norm = 1.4319e-01, time/batch = 17.9519s	
17622/30300 (epoch 29.079), train_loss = 1.05870423, grad/param norm = 1.6115e-01, time/batch = 19.3747s	
17623/30300 (epoch 29.081), train_loss = 1.11492824, grad/param norm = 1.5505e-01, time/batch = 20.3678s	
17624/30300 (epoch 29.083), train_loss = 1.18454825, grad/param norm = 1.8906e-01, time/batch = 18.2898s	
17625/30300 (epoch 29.084), train_loss = 1.02738177, grad/param norm = 1.6252e-01, time/batch = 18.9643s	
17626/30300 (epoch 29.086), train_loss = 1.05912956, grad/param norm = 1.6532e-01, time/batch = 19.3836s	
17627/30300 (epoch 29.087), train_loss = 1.03733625, grad/param norm = 1.4338e-01, time/batch = 17.9525s	
17628/30300 (epoch 29.089), train_loss = 1.06116472, grad/param norm = 1.5183e-01, time/batch = 19.2890s	
17629/30300 (epoch 29.091), train_loss = 1.15039671, grad/param norm = 1.5505e-01, time/batch = 18.9619s	
17630/30300 (epoch 29.092), train_loss = 1.16719213, grad/param norm = 1.6392e-01, time/batch = 17.2853s	
17631/30300 (epoch 29.094), train_loss = 1.26464709, grad/param norm = 1.8081e-01, time/batch = 19.6186s	
17632/30300 (epoch 29.096), train_loss = 1.22590216, grad/param norm = 1.7821e-01, time/batch = 19.6353s	
17633/30300 (epoch 29.097), train_loss = 1.04572888, grad/param norm = 1.7091e-01, time/batch = 17.1116s	
17634/30300 (epoch 29.099), train_loss = 1.20595074, grad/param norm = 1.6171e-01, time/batch = 19.6202s	
17635/30300 (epoch 29.101), train_loss = 1.24546778, grad/param norm = 2.0954e-01, time/batch = 19.4426s	
17636/30300 (epoch 29.102), train_loss = 1.05905037, grad/param norm = 1.8974e-01, time/batch = 18.4327s	
17637/30300 (epoch 29.104), train_loss = 1.08533959, grad/param norm = 1.8394e-01, time/batch = 19.6694s	
17638/30300 (epoch 29.106), train_loss = 1.11570291, grad/param norm = 2.8841e-01, time/batch = 19.2898s	
17639/30300 (epoch 29.107), train_loss = 1.16987032, grad/param norm = 1.5938e-01, time/batch = 19.8629s	
17640/30300 (epoch 29.109), train_loss = 1.19683748, grad/param norm = 2.0775e-01, time/batch = 18.8629s	
17641/30300 (epoch 29.111), train_loss = 1.21142897, grad/param norm = 1.7159e-01, time/batch = 19.1993s	
17642/30300 (epoch 29.112), train_loss = 1.23406267, grad/param norm = 1.5209e-01, time/batch = 18.6886s	
17643/30300 (epoch 29.114), train_loss = 1.07924693, grad/param norm = 1.4868e-01, time/batch = 18.3538s	
17644/30300 (epoch 29.116), train_loss = 1.13417513, grad/param norm = 1.7817e-01, time/batch = 19.5426s	
17645/30300 (epoch 29.117), train_loss = 1.20030961, grad/param norm = 1.6671e-01, time/batch = 20.0238s	
17646/30300 (epoch 29.119), train_loss = 1.04778536, grad/param norm = 1.8058e-01, time/batch = 18.3669s	
17647/30300 (epoch 29.120), train_loss = 1.10663415, grad/param norm = 1.7257e-01, time/batch = 17.1951s	
17648/30300 (epoch 29.122), train_loss = 1.20490227, grad/param norm = 2.0229e-01, time/batch = 18.4451s	
17649/30300 (epoch 29.124), train_loss = 1.26861413, grad/param norm = 1.7954e-01, time/batch = 18.7753s	
17650/30300 (epoch 29.125), train_loss = 0.99521806, grad/param norm = 1.6735e-01, time/batch = 19.3654s	
17651/30300 (epoch 29.127), train_loss = 1.17569281, grad/param norm = 2.0462e-01, time/batch = 17.2813s	
17652/30300 (epoch 29.129), train_loss = 1.24837332, grad/param norm = 1.8961e-01, time/batch = 19.0067s	
17653/30300 (epoch 29.130), train_loss = 1.24783113, grad/param norm = 1.6816e-01, time/batch = 16.9220s	
17654/30300 (epoch 29.132), train_loss = 1.26355156, grad/param norm = 1.7508e-01, time/batch = 19.7882s	
17655/30300 (epoch 29.134), train_loss = 1.02755346, grad/param norm = 1.6022e-01, time/batch = 19.6893s	
17656/30300 (epoch 29.135), train_loss = 1.06440163, grad/param norm = 1.6651e-01, time/batch = 19.1966s	
17657/30300 (epoch 29.137), train_loss = 1.13251864, grad/param norm = 1.7899e-01, time/batch = 18.6146s	
17658/30300 (epoch 29.139), train_loss = 1.08482768, grad/param norm = 1.9078e-01, time/batch = 19.6204s	
17659/30300 (epoch 29.140), train_loss = 1.14635282, grad/param norm = 2.5739e-01, time/batch = 17.9563s	
17660/30300 (epoch 29.142), train_loss = 1.23382720, grad/param norm = 2.2057e-01, time/batch = 19.3014s	
17661/30300 (epoch 29.144), train_loss = 1.09299202, grad/param norm = 2.6158e-01, time/batch = 20.3528s	
17662/30300 (epoch 29.145), train_loss = 1.25130836, grad/param norm = 2.3937e-01, time/batch = 19.2039s	
17663/30300 (epoch 29.147), train_loss = 1.11322177, grad/param norm = 1.8217e-01, time/batch = 17.3353s	
17664/30300 (epoch 29.149), train_loss = 1.26639677, grad/param norm = 1.9150e-01, time/batch = 19.3842s	
17665/30300 (epoch 29.150), train_loss = 1.11933340, grad/param norm = 2.1039e-01, time/batch = 17.7103s	
17666/30300 (epoch 29.152), train_loss = 1.01680220, grad/param norm = 1.9251e-01, time/batch = 17.6269s	
17667/30300 (epoch 29.153), train_loss = 1.11189022, grad/param norm = 1.7885e-01, time/batch = 18.7958s	
17668/30300 (epoch 29.155), train_loss = 0.98172670, grad/param norm = 1.4560e-01, time/batch = 18.6136s	
17669/30300 (epoch 29.157), train_loss = 1.10317109, grad/param norm = 1.8312e-01, time/batch = 19.3558s	
17670/30300 (epoch 29.158), train_loss = 1.15792712, grad/param norm = 2.1376e-01, time/batch = 19.6292s	
17671/30300 (epoch 29.160), train_loss = 1.04221594, grad/param norm = 1.6272e-01, time/batch = 18.1181s	
17672/30300 (epoch 29.162), train_loss = 1.13955009, grad/param norm = 1.8591e-01, time/batch = 18.9488s	
17673/30300 (epoch 29.163), train_loss = 1.11106047, grad/param norm = 1.9453e-01, time/batch = 18.9615s	
17674/30300 (epoch 29.165), train_loss = 1.23967019, grad/param norm = 1.7800e-01, time/batch = 19.0378s	
17675/30300 (epoch 29.167), train_loss = 1.11382589, grad/param norm = 1.7722e-01, time/batch = 17.7783s	
17676/30300 (epoch 29.168), train_loss = 1.19467040, grad/param norm = 2.0054e-01, time/batch = 18.8715s	
17677/30300 (epoch 29.170), train_loss = 1.11876460, grad/param norm = 1.6720e-01, time/batch = 20.3474s	
17678/30300 (epoch 29.172), train_loss = 1.11262113, grad/param norm = 1.6512e-01, time/batch = 17.9960s	
17679/30300 (epoch 29.173), train_loss = 1.12189701, grad/param norm = 2.0911e-01, time/batch = 18.2001s	
17680/30300 (epoch 29.175), train_loss = 1.12770157, grad/param norm = 1.6953e-01, time/batch = 20.6455s	
17681/30300 (epoch 29.177), train_loss = 1.17094537, grad/param norm = 1.8250e-01, time/batch = 18.5405s	
17682/30300 (epoch 29.178), train_loss = 0.89932572, grad/param norm = 1.3887e-01, time/batch = 18.8567s	
17683/30300 (epoch 29.180), train_loss = 1.10669302, grad/param norm = 1.5287e-01, time/batch = 20.3492s	
17684/30300 (epoch 29.182), train_loss = 1.13060261, grad/param norm = 1.7951e-01, time/batch = 16.8346s	
17685/30300 (epoch 29.183), train_loss = 1.06095525, grad/param norm = 1.5577e-01, time/batch = 20.3570s	
17686/30300 (epoch 29.185), train_loss = 1.28596314, grad/param norm = 1.7928e-01, time/batch = 20.3855s	
17687/30300 (epoch 29.186), train_loss = 1.30889949, grad/param norm = 1.8399e-01, time/batch = 18.3694s	
17688/30300 (epoch 29.188), train_loss = 1.17097731, grad/param norm = 1.9180e-01, time/batch = 18.7079s	
17689/30300 (epoch 29.190), train_loss = 1.13505388, grad/param norm = 1.5350e-01, time/batch = 18.9718s	
17690/30300 (epoch 29.191), train_loss = 1.18368836, grad/param norm = 1.8154e-01, time/batch = 19.1002s	
17691/30300 (epoch 29.193), train_loss = 1.02885073, grad/param norm = 1.4021e-01, time/batch = 20.1100s	
17692/30300 (epoch 29.195), train_loss = 1.08325817, grad/param norm = 1.5847e-01, time/batch = 17.7887s	
17693/30300 (epoch 29.196), train_loss = 1.14929635, grad/param norm = 1.4149e-01, time/batch = 18.6697s	
17694/30300 (epoch 29.198), train_loss = 0.96357945, grad/param norm = 1.6472e-01, time/batch = 18.7632s	
17695/30300 (epoch 29.200), train_loss = 1.11985865, grad/param norm = 1.5484e-01, time/batch = 18.1169s	
17696/30300 (epoch 29.201), train_loss = 1.19173397, grad/param norm = 2.1976e-01, time/batch = 19.2442s	
17697/30300 (epoch 29.203), train_loss = 1.11245858, grad/param norm = 1.6643e-01, time/batch = 19.3526s	
17698/30300 (epoch 29.205), train_loss = 1.34873952, grad/param norm = 1.9529e-01, time/batch = 20.2745s	
17699/30300 (epoch 29.206), train_loss = 1.22449446, grad/param norm = 1.9550e-01, time/batch = 19.1135s	
17700/30300 (epoch 29.208), train_loss = 1.19419497, grad/param norm = 2.0985e-01, time/batch = 28.4929s	
17701/30300 (epoch 29.210), train_loss = 1.18710505, grad/param norm = 1.6870e-01, time/batch = 16.2710s	
17702/30300 (epoch 29.211), train_loss = 1.23555219, grad/param norm = 1.7284e-01, time/batch = 18.5862s	
17703/30300 (epoch 29.213), train_loss = 1.10215864, grad/param norm = 1.4837e-01, time/batch = 17.4124s	
17704/30300 (epoch 29.215), train_loss = 1.05216621, grad/param norm = 1.8003e-01, time/batch = 18.7068s	
17705/30300 (epoch 29.216), train_loss = 1.06282855, grad/param norm = 1.6456e-01, time/batch = 20.4286s	
17706/30300 (epoch 29.218), train_loss = 1.02348180, grad/param norm = 1.4057e-01, time/batch = 18.0156s	
17707/30300 (epoch 29.219), train_loss = 0.98485901, grad/param norm = 1.4747e-01, time/batch = 18.9504s	
17708/30300 (epoch 29.221), train_loss = 0.97360757, grad/param norm = 1.5168e-01, time/batch = 20.8594s	
17709/30300 (epoch 29.223), train_loss = 1.14503024, grad/param norm = 1.8038e-01, time/batch = 18.3515s	
17710/30300 (epoch 29.224), train_loss = 0.97645664, grad/param norm = 1.5444e-01, time/batch = 20.0965s	
17711/30300 (epoch 29.226), train_loss = 1.19400533, grad/param norm = 1.8167e-01, time/batch = 19.9303s	
17712/30300 (epoch 29.228), train_loss = 1.20592478, grad/param norm = 1.7501e-01, time/batch = 17.6751s	
17713/30300 (epoch 29.229), train_loss = 1.10950125, grad/param norm = 1.5985e-01, time/batch = 17.0967s	
17714/30300 (epoch 29.231), train_loss = 1.15008916, grad/param norm = 1.6167e-01, time/batch = 19.9572s	
17715/30300 (epoch 29.233), train_loss = 1.15462018, grad/param norm = 1.4098e-01, time/batch = 18.2871s	
17716/30300 (epoch 29.234), train_loss = 1.20087262, grad/param norm = 1.8091e-01, time/batch = 18.7331s	
17717/30300 (epoch 29.236), train_loss = 1.15072390, grad/param norm = 1.5259e-01, time/batch = 18.7908s	
17718/30300 (epoch 29.238), train_loss = 1.16053817, grad/param norm = 2.2549e-01, time/batch = 18.6974s	
17719/30300 (epoch 29.239), train_loss = 1.13657094, grad/param norm = 1.8891e-01, time/batch = 18.8778s	
17720/30300 (epoch 29.241), train_loss = 1.18825875, grad/param norm = 1.9641e-01, time/batch = 19.2904s	
17721/30300 (epoch 29.243), train_loss = 1.18325723, grad/param norm = 1.6303e-01, time/batch = 19.2130s	
17722/30300 (epoch 29.244), train_loss = 1.32941237, grad/param norm = 1.7058e-01, time/batch = 19.7651s	
17723/30300 (epoch 29.246), train_loss = 1.15936101, grad/param norm = 1.6919e-01, time/batch = 19.6244s	
17724/30300 (epoch 29.248), train_loss = 1.10082687, grad/param norm = 1.4889e-01, time/batch = 19.5335s	
17725/30300 (epoch 29.249), train_loss = 1.05646315, grad/param norm = 1.6137e-01, time/batch = 19.7763s	
17726/30300 (epoch 29.251), train_loss = 1.06796053, grad/param norm = 1.7725e-01, time/batch = 19.2941s	
17727/30300 (epoch 29.252), train_loss = 1.24981880, grad/param norm = 2.0452e-01, time/batch = 19.2872s	
17728/30300 (epoch 29.254), train_loss = 1.23100672, grad/param norm = 1.7801e-01, time/batch = 18.9487s	
17729/30300 (epoch 29.256), train_loss = 1.14508715, grad/param norm = 1.6293e-01, time/batch = 19.8735s	
17730/30300 (epoch 29.257), train_loss = 1.21309832, grad/param norm = 1.7065e-01, time/batch = 19.9557s	
17731/30300 (epoch 29.259), train_loss = 1.11885642, grad/param norm = 1.7812e-01, time/batch = 8.7627s	
17732/30300 (epoch 29.261), train_loss = 1.23898867, grad/param norm = 1.6850e-01, time/batch = 0.6875s	
17733/30300 (epoch 29.262), train_loss = 1.07176413, grad/param norm = 1.6563e-01, time/batch = 0.6912s	
17734/30300 (epoch 29.264), train_loss = 1.11519107, grad/param norm = 1.5135e-01, time/batch = 0.6910s	
17735/30300 (epoch 29.266), train_loss = 1.06073755, grad/param norm = 1.4478e-01, time/batch = 0.6964s	
17736/30300 (epoch 29.267), train_loss = 1.30156872, grad/param norm = 1.9160e-01, time/batch = 0.6869s	
17737/30300 (epoch 29.269), train_loss = 1.13055554, grad/param norm = 1.5450e-01, time/batch = 0.7037s	
17738/30300 (epoch 29.271), train_loss = 1.16597098, grad/param norm = 1.6699e-01, time/batch = 0.8463s	
17739/30300 (epoch 29.272), train_loss = 1.14352496, grad/param norm = 1.9380e-01, time/batch = 1.0056s	
17740/30300 (epoch 29.274), train_loss = 1.20378645, grad/param norm = 1.7383e-01, time/batch = 1.0137s	
17741/30300 (epoch 29.276), train_loss = 1.18428247, grad/param norm = 1.8036e-01, time/batch = 1.0041s	
17742/30300 (epoch 29.277), train_loss = 1.00664684, grad/param norm = 1.7352e-01, time/batch = 1.0123s	
17743/30300 (epoch 29.279), train_loss = 1.14807178, grad/param norm = 1.7291e-01, time/batch = 1.4057s	
17744/30300 (epoch 29.281), train_loss = 1.22323333, grad/param norm = 1.7817e-01, time/batch = 1.8831s	
17745/30300 (epoch 29.282), train_loss = 1.14765256, grad/param norm = 1.5830e-01, time/batch = 1.8949s	
17746/30300 (epoch 29.284), train_loss = 1.23735794, grad/param norm = 1.9650e-01, time/batch = 16.6793s	
17747/30300 (epoch 29.285), train_loss = 1.17558882, grad/param norm = 1.5803e-01, time/batch = 20.0266s	
17748/30300 (epoch 29.287), train_loss = 1.11554139, grad/param norm = 1.6516e-01, time/batch = 18.7068s	
17749/30300 (epoch 29.289), train_loss = 1.20857125, grad/param norm = 1.6085e-01, time/batch = 17.6253s	
17750/30300 (epoch 29.290), train_loss = 0.89438089, grad/param norm = 1.3880e-01, time/batch = 19.8789s	
17751/30300 (epoch 29.292), train_loss = 1.03757802, grad/param norm = 1.6343e-01, time/batch = 17.5409s	
17752/30300 (epoch 29.294), train_loss = 1.21145228, grad/param norm = 2.4931e-01, time/batch = 19.4585s	
17753/30300 (epoch 29.295), train_loss = 1.09907216, grad/param norm = 1.7297e-01, time/batch = 19.0860s	
17754/30300 (epoch 29.297), train_loss = 1.07911007, grad/param norm = 1.5310e-01, time/batch = 18.2130s	
17755/30300 (epoch 29.299), train_loss = 1.11952656, grad/param norm = 1.7831e-01, time/batch = 19.7835s	
17756/30300 (epoch 29.300), train_loss = 1.05563551, grad/param norm = 1.7147e-01, time/batch = 18.7896s	
17757/30300 (epoch 29.302), train_loss = 1.19176334, grad/param norm = 1.6585e-01, time/batch = 18.5343s	
17758/30300 (epoch 29.304), train_loss = 1.04518957, grad/param norm = 1.5253e-01, time/batch = 17.6718s	
17759/30300 (epoch 29.305), train_loss = 1.10104828, grad/param norm = 1.4920e-01, time/batch = 16.6358s	
17760/30300 (epoch 29.307), train_loss = 1.19181512, grad/param norm = 1.4691e-01, time/batch = 17.6613s	
17761/30300 (epoch 29.309), train_loss = 1.16480141, grad/param norm = 1.6244e-01, time/batch = 16.6948s	
17762/30300 (epoch 29.310), train_loss = 1.12457936, grad/param norm = 1.5675e-01, time/batch = 16.5375s	
17763/30300 (epoch 29.312), train_loss = 1.26873468, grad/param norm = 1.6782e-01, time/batch = 19.7622s	
17764/30300 (epoch 29.314), train_loss = 1.12878454, grad/param norm = 1.5635e-01, time/batch = 17.3524s	
17765/30300 (epoch 29.315), train_loss = 1.10155920, grad/param norm = 1.6676e-01, time/batch = 18.1901s	
17766/30300 (epoch 29.317), train_loss = 1.14164952, grad/param norm = 1.5163e-01, time/batch = 17.5461s	
17767/30300 (epoch 29.318), train_loss = 1.19348770, grad/param norm = 1.5535e-01, time/batch = 17.7238s	
17768/30300 (epoch 29.320), train_loss = 1.19414326, grad/param norm = 1.6473e-01, time/batch = 18.6984s	
17769/30300 (epoch 29.322), train_loss = 1.07360492, grad/param norm = 1.5743e-01, time/batch = 17.5803s	
17770/30300 (epoch 29.323), train_loss = 1.24093187, grad/param norm = 1.7310e-01, time/batch = 16.8225s	
17771/30300 (epoch 29.325), train_loss = 1.12258718, grad/param norm = 1.5733e-01, time/batch = 18.2643s	
17772/30300 (epoch 29.327), train_loss = 1.12429107, grad/param norm = 1.5821e-01, time/batch = 16.5699s	
17773/30300 (epoch 29.328), train_loss = 1.14400858, grad/param norm = 1.5721e-01, time/batch = 16.1474s	
17774/30300 (epoch 29.330), train_loss = 1.18160135, grad/param norm = 1.7479e-01, time/batch = 18.3258s	
17775/30300 (epoch 29.332), train_loss = 1.22379135, grad/param norm = 2.0517e-01, time/batch = 17.7418s	
17776/30300 (epoch 29.333), train_loss = 1.08473876, grad/param norm = 1.6395e-01, time/batch = 15.6050s	
17777/30300 (epoch 29.335), train_loss = 1.01706870, grad/param norm = 1.6250e-01, time/batch = 18.7783s	
17778/30300 (epoch 29.337), train_loss = 1.26299697, grad/param norm = 1.5371e-01, time/batch = 16.9591s	
17779/30300 (epoch 29.338), train_loss = 1.07937535, grad/param norm = 1.5154e-01, time/batch = 18.2984s	
17780/30300 (epoch 29.340), train_loss = 1.06595784, grad/param norm = 1.4997e-01, time/batch = 17.9666s	
17781/30300 (epoch 29.342), train_loss = 1.21929363, grad/param norm = 1.6622e-01, time/batch = 16.8025s	
17782/30300 (epoch 29.343), train_loss = 1.14350672, grad/param norm = 1.5551e-01, time/batch = 19.9503s	
17783/30300 (epoch 29.345), train_loss = 1.18832546, grad/param norm = 1.8175e-01, time/batch = 18.1978s	
17784/30300 (epoch 29.347), train_loss = 0.99933028, grad/param norm = 1.5962e-01, time/batch = 17.9598s	
17785/30300 (epoch 29.348), train_loss = 1.06484024, grad/param norm = 1.6423e-01, time/batch = 19.6932s	
17786/30300 (epoch 29.350), train_loss = 1.09979969, grad/param norm = 1.6341e-01, time/batch = 19.5515s	
17787/30300 (epoch 29.351), train_loss = 1.11222030, grad/param norm = 1.6615e-01, time/batch = 18.5530s	
17788/30300 (epoch 29.353), train_loss = 0.98908399, grad/param norm = 1.5549e-01, time/batch = 19.4581s	
17789/30300 (epoch 29.355), train_loss = 1.07626543, grad/param norm = 1.4807e-01, time/batch = 19.0398s	
17790/30300 (epoch 29.356), train_loss = 1.20588662, grad/param norm = 2.0372e-01, time/batch = 17.7142s	
17791/30300 (epoch 29.358), train_loss = 1.35970016, grad/param norm = 1.5384e-01, time/batch = 18.5558s	
17792/30300 (epoch 29.360), train_loss = 1.08293369, grad/param norm = 1.8248e-01, time/batch = 18.1341s	
17793/30300 (epoch 29.361), train_loss = 1.12977838, grad/param norm = 1.5973e-01, time/batch = 19.2166s	
17794/30300 (epoch 29.363), train_loss = 1.18803727, grad/param norm = 1.6679e-01, time/batch = 17.7562s	
17795/30300 (epoch 29.365), train_loss = 1.01358072, grad/param norm = 1.9576e-01, time/batch = 18.1371s	
17796/30300 (epoch 29.366), train_loss = 1.09158750, grad/param norm = 1.8307e-01, time/batch = 18.2981s	
17797/30300 (epoch 29.368), train_loss = 0.97404848, grad/param norm = 1.4170e-01, time/batch = 18.3789s	
17798/30300 (epoch 29.370), train_loss = 1.05791247, grad/param norm = 1.6474e-01, time/batch = 18.4468s	
17799/30300 (epoch 29.371), train_loss = 1.21011477, grad/param norm = 1.6354e-01, time/batch = 15.9816s	
17800/30300 (epoch 29.373), train_loss = 1.06296369, grad/param norm = 1.4031e-01, time/batch = 18.8828s	
17801/30300 (epoch 29.375), train_loss = 1.05479203, grad/param norm = 1.4324e-01, time/batch = 18.2876s	
17802/30300 (epoch 29.376), train_loss = 1.05627873, grad/param norm = 1.4557e-01, time/batch = 18.7182s	
17803/30300 (epoch 29.378), train_loss = 1.03710272, grad/param norm = 1.5951e-01, time/batch = 19.6032s	
17804/30300 (epoch 29.380), train_loss = 1.26832759, grad/param norm = 1.7703e-01, time/batch = 18.9625s	
17805/30300 (epoch 29.381), train_loss = 0.95365286, grad/param norm = 1.5468e-01, time/batch = 19.9696s	
17806/30300 (epoch 29.383), train_loss = 1.05218704, grad/param norm = 1.8438e-01, time/batch = 17.4402s	
17807/30300 (epoch 29.384), train_loss = 1.17256211, grad/param norm = 1.7393e-01, time/batch = 18.6920s	
17808/30300 (epoch 29.386), train_loss = 1.01153100, grad/param norm = 1.5525e-01, time/batch = 19.2982s	
17809/30300 (epoch 29.388), train_loss = 0.99189966, grad/param norm = 1.6071e-01, time/batch = 17.1818s	
17810/30300 (epoch 29.389), train_loss = 1.09878582, grad/param norm = 1.6451e-01, time/batch = 18.6932s	
17811/30300 (epoch 29.391), train_loss = 1.16852146, grad/param norm = 1.6849e-01, time/batch = 4.4213s	
17812/30300 (epoch 29.393), train_loss = 0.97954059, grad/param norm = 1.4955e-01, time/batch = 0.7393s	
17813/30300 (epoch 29.394), train_loss = 1.18099414, grad/param norm = 1.6850e-01, time/batch = 0.6913s	
17814/30300 (epoch 29.396), train_loss = 1.23229197, grad/param norm = 1.5031e-01, time/batch = 0.6797s	
17815/30300 (epoch 29.398), train_loss = 1.08409951, grad/param norm = 1.5391e-01, time/batch = 0.6909s	
17816/30300 (epoch 29.399), train_loss = 1.07310166, grad/param norm = 1.5878e-01, time/batch = 0.6941s	
17817/30300 (epoch 29.401), train_loss = 1.14355145, grad/param norm = 1.7802e-01, time/batch = 0.6848s	
17818/30300 (epoch 29.403), train_loss = 1.09545859, grad/param norm = 1.7053e-01, time/batch = 0.6865s	
17819/30300 (epoch 29.404), train_loss = 1.05800548, grad/param norm = 1.8809e-01, time/batch = 0.6931s	
17820/30300 (epoch 29.406), train_loss = 1.14939917, grad/param norm = 1.5610e-01, time/batch = 0.6812s	
17821/30300 (epoch 29.408), train_loss = 0.99739980, grad/param norm = 1.5634e-01, time/batch = 0.6830s	
17822/30300 (epoch 29.409), train_loss = 0.98512510, grad/param norm = 1.4547e-01, time/batch = 0.6812s	
17823/30300 (epoch 29.411), train_loss = 1.02180805, grad/param norm = 1.3783e-01, time/batch = 0.6817s	
17824/30300 (epoch 29.413), train_loss = 0.92298170, grad/param norm = 1.5035e-01, time/batch = 0.6837s	
17825/30300 (epoch 29.414), train_loss = 1.18208524, grad/param norm = 1.6694e-01, time/batch = 0.6992s	
17826/30300 (epoch 29.416), train_loss = 1.05568889, grad/param norm = 1.4727e-01, time/batch = 0.7034s	
17827/30300 (epoch 29.417), train_loss = 1.00839738, grad/param norm = 1.5040e-01, time/batch = 0.7048s	
17828/30300 (epoch 29.419), train_loss = 1.00858539, grad/param norm = 1.3935e-01, time/batch = 0.6935s	
17829/30300 (epoch 29.421), train_loss = 1.05061269, grad/param norm = 1.6925e-01, time/batch = 0.6836s	
17830/30300 (epoch 29.422), train_loss = 1.12225137, grad/param norm = 1.6418e-01, time/batch = 0.7101s	
17831/30300 (epoch 29.424), train_loss = 1.12004528, grad/param norm = 1.6760e-01, time/batch = 0.7194s	
17832/30300 (epoch 29.426), train_loss = 1.06891772, grad/param norm = 1.7759e-01, time/batch = 0.6865s	
17833/30300 (epoch 29.427), train_loss = 1.04613510, grad/param norm = 1.6749e-01, time/batch = 0.6830s	
17834/30300 (epoch 29.429), train_loss = 1.09510304, grad/param norm = 1.5122e-01, time/batch = 0.6833s	
17835/30300 (epoch 29.431), train_loss = 1.16408374, grad/param norm = 1.5642e-01, time/batch = 0.6829s	
17836/30300 (epoch 29.432), train_loss = 1.06565895, grad/param norm = 1.4599e-01, time/batch = 0.6854s	
17837/30300 (epoch 29.434), train_loss = 0.98465913, grad/param norm = 1.5267e-01, time/batch = 0.6837s	
17838/30300 (epoch 29.436), train_loss = 1.24748120, grad/param norm = 1.6440e-01, time/batch = 0.6867s	
17839/30300 (epoch 29.437), train_loss = 1.00535036, grad/param norm = 1.5567e-01, time/batch = 0.6840s	
17840/30300 (epoch 29.439), train_loss = 1.04590157, grad/param norm = 1.4954e-01, time/batch = 0.6830s	
17841/30300 (epoch 29.441), train_loss = 1.08614851, grad/param norm = 1.4617e-01, time/batch = 0.6866s	
17842/30300 (epoch 29.442), train_loss = 1.02852201, grad/param norm = 1.8174e-01, time/batch = 0.6813s	
17843/30300 (epoch 29.444), train_loss = 0.93418736, grad/param norm = 1.5323e-01, time/batch = 0.6822s	
17844/30300 (epoch 29.446), train_loss = 1.07678517, grad/param norm = 1.4710e-01, time/batch = 0.6939s	
17845/30300 (epoch 29.447), train_loss = 1.11272031, grad/param norm = 1.6498e-01, time/batch = 0.7265s	
17846/30300 (epoch 29.449), train_loss = 1.02963828, grad/param norm = 1.5273e-01, time/batch = 0.6951s	
17847/30300 (epoch 29.450), train_loss = 1.13156541, grad/param norm = 1.4344e-01, time/batch = 0.6808s	
17848/30300 (epoch 29.452), train_loss = 1.22342010, grad/param norm = 1.6084e-01, time/batch = 0.6821s	
17849/30300 (epoch 29.454), train_loss = 1.16563719, grad/param norm = 1.4896e-01, time/batch = 0.6889s	
17850/30300 (epoch 29.455), train_loss = 1.11762832, grad/param norm = 1.7317e-01, time/batch = 0.6827s	
17851/30300 (epoch 29.457), train_loss = 1.07459980, grad/param norm = 1.5549e-01, time/batch = 0.6845s	
17852/30300 (epoch 29.459), train_loss = 1.17909830, grad/param norm = 1.8174e-01, time/batch = 0.6870s	
17853/30300 (epoch 29.460), train_loss = 1.15160488, grad/param norm = 1.5353e-01, time/batch = 0.6933s	
17854/30300 (epoch 29.462), train_loss = 1.18135607, grad/param norm = 1.6850e-01, time/batch = 0.7098s	
17855/30300 (epoch 29.464), train_loss = 0.92902760, grad/param norm = 1.7268e-01, time/batch = 0.7097s	
17856/30300 (epoch 29.465), train_loss = 0.92476662, grad/param norm = 1.3430e-01, time/batch = 0.7119s	
17857/30300 (epoch 29.467), train_loss = 0.92527012, grad/param norm = 1.4414e-01, time/batch = 0.7131s	
17858/30300 (epoch 29.469), train_loss = 1.02494541, grad/param norm = 1.5585e-01, time/batch = 0.7038s	
17859/30300 (epoch 29.470), train_loss = 1.06949789, grad/param norm = 1.6065e-01, time/batch = 0.7245s	
17860/30300 (epoch 29.472), train_loss = 1.06518928, grad/param norm = 1.4345e-01, time/batch = 0.7090s	
17861/30300 (epoch 29.474), train_loss = 1.05856884, grad/param norm = 1.9670e-01, time/batch = 0.6827s	
17862/30300 (epoch 29.475), train_loss = 1.04402415, grad/param norm = 1.4929e-01, time/batch = 0.6804s	
17863/30300 (epoch 29.477), train_loss = 1.10004626, grad/param norm = 1.5391e-01, time/batch = 0.6808s	
17864/30300 (epoch 29.479), train_loss = 1.08276354, grad/param norm = 1.8448e-01, time/batch = 0.6789s	
17865/30300 (epoch 29.480), train_loss = 1.12082072, grad/param norm = 1.4291e-01, time/batch = 0.6786s	
17866/30300 (epoch 29.482), train_loss = 1.14971261, grad/param norm = 1.4759e-01, time/batch = 0.6805s	
17867/30300 (epoch 29.483), train_loss = 1.06407116, grad/param norm = 1.4873e-01, time/batch = 0.6797s	
17868/30300 (epoch 29.485), train_loss = 1.11694588, grad/param norm = 1.4842e-01, time/batch = 0.6802s	
17869/30300 (epoch 29.487), train_loss = 1.20813406, grad/param norm = 1.7068e-01, time/batch = 0.6806s	
17870/30300 (epoch 29.488), train_loss = 1.19943352, grad/param norm = 1.4069e-01, time/batch = 0.6890s	
17871/30300 (epoch 29.490), train_loss = 0.98981890, grad/param norm = 1.6033e-01, time/batch = 0.6963s	
17872/30300 (epoch 29.492), train_loss = 1.07825851, grad/param norm = 1.6968e-01, time/batch = 0.6892s	
17873/30300 (epoch 29.493), train_loss = 1.08735188, grad/param norm = 1.4975e-01, time/batch = 0.6847s	
17874/30300 (epoch 29.495), train_loss = 1.07164583, grad/param norm = 1.4306e-01, time/batch = 0.7073s	
17875/30300 (epoch 29.497), train_loss = 1.10997231, grad/param norm = 1.4956e-01, time/batch = 0.6850s	
17876/30300 (epoch 29.498), train_loss = 1.15873134, grad/param norm = 1.9066e-01, time/batch = 0.6834s	
17877/30300 (epoch 29.500), train_loss = 1.09831701, grad/param norm = 1.7543e-01, time/batch = 0.6855s	
17878/30300 (epoch 29.502), train_loss = 1.08864537, grad/param norm = 1.8428e-01, time/batch = 0.7264s	
17879/30300 (epoch 29.503), train_loss = 1.19909199, grad/param norm = 1.5648e-01, time/batch = 0.6994s	
17880/30300 (epoch 29.505), train_loss = 1.01247746, grad/param norm = 1.3771e-01, time/batch = 0.6815s	
17881/30300 (epoch 29.507), train_loss = 1.01141884, grad/param norm = 1.5967e-01, time/batch = 0.6867s	
17882/30300 (epoch 29.508), train_loss = 1.04257615, grad/param norm = 1.7859e-01, time/batch = 0.6856s	
17883/30300 (epoch 29.510), train_loss = 1.18461897, grad/param norm = 1.6936e-01, time/batch = 0.6812s	
17884/30300 (epoch 29.512), train_loss = 1.03663464, grad/param norm = 1.4280e-01, time/batch = 0.6808s	
17885/30300 (epoch 29.513), train_loss = 1.11662119, grad/param norm = 1.4639e-01, time/batch = 0.6813s	
17886/30300 (epoch 29.515), train_loss = 1.10588058, grad/param norm = 1.5527e-01, time/batch = 0.6807s	
17887/30300 (epoch 29.517), train_loss = 0.91417596, grad/param norm = 1.3542e-01, time/batch = 0.6997s	
17888/30300 (epoch 29.518), train_loss = 1.19302253, grad/param norm = 1.8632e-01, time/batch = 0.6929s	
17889/30300 (epoch 29.520), train_loss = 1.14759552, grad/param norm = 1.7489e-01, time/batch = 0.6846s	
17890/30300 (epoch 29.521), train_loss = 1.02221297, grad/param norm = 1.8001e-01, time/batch = 0.6793s	
17891/30300 (epoch 29.523), train_loss = 1.25705938, grad/param norm = 2.0422e-01, time/batch = 0.6834s	
17892/30300 (epoch 29.525), train_loss = 1.04973012, grad/param norm = 1.6054e-01, time/batch = 0.6812s	
17893/30300 (epoch 29.526), train_loss = 1.10332292, grad/param norm = 1.5732e-01, time/batch = 0.6815s	
17894/30300 (epoch 29.528), train_loss = 1.01104783, grad/param norm = 1.5719e-01, time/batch = 0.6832s	
17895/30300 (epoch 29.530), train_loss = 0.97531669, grad/param norm = 1.5067e-01, time/batch = 0.6859s	
17896/30300 (epoch 29.531), train_loss = 1.13888580, grad/param norm = 1.8982e-01, time/batch = 0.6894s	
17897/30300 (epoch 29.533), train_loss = 1.09250498, grad/param norm = 1.5577e-01, time/batch = 0.7277s	
17898/30300 (epoch 29.535), train_loss = 1.05081271, grad/param norm = 1.4212e-01, time/batch = 0.6909s	
17899/30300 (epoch 29.536), train_loss = 1.13009253, grad/param norm = 1.8791e-01, time/batch = 0.6836s	
17900/30300 (epoch 29.538), train_loss = 0.98402244, grad/param norm = 1.6300e-01, time/batch = 0.6803s	
17901/30300 (epoch 29.540), train_loss = 1.02525201, grad/param norm = 1.6541e-01, time/batch = 0.6817s	
17902/30300 (epoch 29.541), train_loss = 1.10892813, grad/param norm = 1.7472e-01, time/batch = 0.6816s	
17903/30300 (epoch 29.543), train_loss = 1.08157574, grad/param norm = 1.5926e-01, time/batch = 0.6772s	
17904/30300 (epoch 29.545), train_loss = 1.15018824, grad/param norm = 2.8855e-01, time/batch = 0.6771s	
17905/30300 (epoch 29.546), train_loss = 1.29519516, grad/param norm = 1.5477e-01, time/batch = 0.6786s	
17906/30300 (epoch 29.548), train_loss = 1.04920108, grad/param norm = 1.5280e-01, time/batch = 0.6817s	
17907/30300 (epoch 29.550), train_loss = 1.15513288, grad/param norm = 1.9620e-01, time/batch = 0.6785s	
17908/30300 (epoch 29.551), train_loss = 1.04228257, grad/param norm = 1.6023e-01, time/batch = 0.6788s	
17909/30300 (epoch 29.553), train_loss = 1.05369914, grad/param norm = 1.5425e-01, time/batch = 0.6816s	
17910/30300 (epoch 29.554), train_loss = 1.09437795, grad/param norm = 1.6924e-01, time/batch = 0.6805s	
17911/30300 (epoch 29.556), train_loss = 1.14371877, grad/param norm = 1.5217e-01, time/batch = 0.6808s	
17912/30300 (epoch 29.558), train_loss = 1.16795854, grad/param norm = 1.6609e-01, time/batch = 0.6805s	
17913/30300 (epoch 29.559), train_loss = 1.11839519, grad/param norm = 1.6762e-01, time/batch = 0.6803s	
17914/30300 (epoch 29.561), train_loss = 0.90841359, grad/param norm = 1.4767e-01, time/batch = 0.6814s	
17915/30300 (epoch 29.563), train_loss = 0.99062554, grad/param norm = 1.4447e-01, time/batch = 0.6962s	
17916/30300 (epoch 29.564), train_loss = 1.02944434, grad/param norm = 1.4107e-01, time/batch = 0.7261s	
17917/30300 (epoch 29.566), train_loss = 1.08638364, grad/param norm = 1.4855e-01, time/batch = 0.6882s	
17918/30300 (epoch 29.568), train_loss = 0.94586223, grad/param norm = 1.6667e-01, time/batch = 0.6817s	
17919/30300 (epoch 29.569), train_loss = 1.10583859, grad/param norm = 1.5262e-01, time/batch = 0.6831s	
17920/30300 (epoch 29.571), train_loss = 1.10143240, grad/param norm = 1.6297e-01, time/batch = 0.6830s	
17921/30300 (epoch 29.573), train_loss = 1.12616149, grad/param norm = 1.5645e-01, time/batch = 0.6865s	
17922/30300 (epoch 29.574), train_loss = 1.14335157, grad/param norm = 1.4962e-01, time/batch = 0.6826s	
17923/30300 (epoch 29.576), train_loss = 1.05781056, grad/param norm = 1.5009e-01, time/batch = 0.6806s	
17924/30300 (epoch 29.578), train_loss = 0.97289940, grad/param norm = 1.4966e-01, time/batch = 0.6837s	
17925/30300 (epoch 29.579), train_loss = 1.11575922, grad/param norm = 1.6828e-01, time/batch = 0.6813s	
17926/30300 (epoch 29.581), train_loss = 1.21556260, grad/param norm = 1.6624e-01, time/batch = 0.6807s	
17927/30300 (epoch 29.583), train_loss = 1.25599241, grad/param norm = 1.8406e-01, time/batch = 0.6820s	
17928/30300 (epoch 29.584), train_loss = 1.20647466, grad/param norm = 1.6429e-01, time/batch = 0.6835s	
17929/30300 (epoch 29.586), train_loss = 1.06381009, grad/param norm = 1.6510e-01, time/batch = 0.6805s	
17930/30300 (epoch 29.587), train_loss = 1.09565621, grad/param norm = 1.8176e-01, time/batch = 0.6812s	
17931/30300 (epoch 29.589), train_loss = 1.02197772, grad/param norm = 1.5559e-01, time/batch = 0.6834s	
17932/30300 (epoch 29.591), train_loss = 1.12527973, grad/param norm = 1.4896e-01, time/batch = 0.6804s	
17933/30300 (epoch 29.592), train_loss = 1.06524499, grad/param norm = 1.4985e-01, time/batch = 0.6811s	
17934/30300 (epoch 29.594), train_loss = 1.10878402, grad/param norm = 1.5814e-01, time/batch = 0.7017s	
17935/30300 (epoch 29.596), train_loss = 1.00609102, grad/param norm = 1.4804e-01, time/batch = 0.7233s	
17936/30300 (epoch 29.597), train_loss = 1.02406963, grad/param norm = 2.0089e-01, time/batch = 0.6830s	
17937/30300 (epoch 29.599), train_loss = 0.92130280, grad/param norm = 1.4380e-01, time/batch = 0.6816s	
17938/30300 (epoch 29.601), train_loss = 1.11360094, grad/param norm = 1.6109e-01, time/batch = 0.6824s	
17939/30300 (epoch 29.602), train_loss = 1.08227920, grad/param norm = 1.5399e-01, time/batch = 0.6827s	
17940/30300 (epoch 29.604), train_loss = 1.01661470, grad/param norm = 1.3975e-01, time/batch = 0.6814s	
17941/30300 (epoch 29.606), train_loss = 1.05578726, grad/param norm = 2.1807e-01, time/batch = 0.6933s	
17942/30300 (epoch 29.607), train_loss = 1.18871410, grad/param norm = 1.8536e-01, time/batch = 0.6846s	
17943/30300 (epoch 29.609), train_loss = 1.29727076, grad/param norm = 1.7046e-01, time/batch = 0.6822s	
17944/30300 (epoch 29.611), train_loss = 1.04122599, grad/param norm = 1.5465e-01, time/batch = 0.6810s	
17945/30300 (epoch 29.612), train_loss = 0.99702588, grad/param norm = 1.4558e-01, time/batch = 0.6824s	
17946/30300 (epoch 29.614), train_loss = 1.07423677, grad/param norm = 1.5044e-01, time/batch = 0.6834s	
17947/30300 (epoch 29.616), train_loss = 1.13942506, grad/param norm = 1.8114e-01, time/batch = 0.6826s	
17948/30300 (epoch 29.617), train_loss = 1.12342332, grad/param norm = 1.9071e-01, time/batch = 0.6829s	
17949/30300 (epoch 29.619), train_loss = 0.91702228, grad/param norm = 1.4030e-01, time/batch = 0.6811s	
17950/30300 (epoch 29.620), train_loss = 1.14940582, grad/param norm = 1.6683e-01, time/batch = 0.6812s	
17951/30300 (epoch 29.622), train_loss = 1.09075761, grad/param norm = 1.7420e-01, time/batch = 0.6835s	
17952/30300 (epoch 29.624), train_loss = 1.06081300, grad/param norm = 1.6851e-01, time/batch = 0.6829s	
17953/30300 (epoch 29.625), train_loss = 1.06406937, grad/param norm = 1.9095e-01, time/batch = 0.7083s	
17954/30300 (epoch 29.627), train_loss = 1.22091122, grad/param norm = 1.7475e-01, time/batch = 0.7172s	
17955/30300 (epoch 29.629), train_loss = 1.24533561, grad/param norm = 1.6634e-01, time/batch = 0.6825s	
17956/30300 (epoch 29.630), train_loss = 1.11284939, grad/param norm = 1.6401e-01, time/batch = 0.6810s	
17957/30300 (epoch 29.632), train_loss = 1.16606115, grad/param norm = 1.6857e-01, time/batch = 0.6835s	
17958/30300 (epoch 29.634), train_loss = 1.03117265, grad/param norm = 1.5302e-01, time/batch = 0.6923s	
17959/30300 (epoch 29.635), train_loss = 1.15481494, grad/param norm = 1.7863e-01, time/batch = 0.6940s	
17960/30300 (epoch 29.637), train_loss = 1.18519276, grad/param norm = 1.8671e-01, time/batch = 0.6811s	
17961/30300 (epoch 29.639), train_loss = 1.07144475, grad/param norm = 1.5454e-01, time/batch = 0.7186s	
17962/30300 (epoch 29.640), train_loss = 1.20712120, grad/param norm = 1.8103e-01, time/batch = 0.6902s	
17963/30300 (epoch 29.642), train_loss = 1.05923081, grad/param norm = 1.3922e-01, time/batch = 0.6871s	
17964/30300 (epoch 29.644), train_loss = 1.15301589, grad/param norm = 1.5077e-01, time/batch = 0.6881s	
17965/30300 (epoch 29.645), train_loss = 1.02839461, grad/param norm = 1.4990e-01, time/batch = 0.6886s	
17966/30300 (epoch 29.647), train_loss = 1.12349977, grad/param norm = 1.5477e-01, time/batch = 0.6840s	
17967/30300 (epoch 29.649), train_loss = 1.08102553, grad/param norm = 1.6360e-01, time/batch = 0.6818s	
17968/30300 (epoch 29.650), train_loss = 1.08778174, grad/param norm = 1.5991e-01, time/batch = 0.6800s	
17969/30300 (epoch 29.652), train_loss = 1.06577424, grad/param norm = 1.8428e-01, time/batch = 0.6806s	
17970/30300 (epoch 29.653), train_loss = 1.28738256, grad/param norm = 1.6239e-01, time/batch = 0.6811s	
17971/30300 (epoch 29.655), train_loss = 1.04185132, grad/param norm = 1.5580e-01, time/batch = 0.6855s	
17972/30300 (epoch 29.657), train_loss = 1.03602057, grad/param norm = 1.8319e-01, time/batch = 0.7201s	
17973/30300 (epoch 29.658), train_loss = 1.02367109, grad/param norm = 1.4928e-01, time/batch = 0.7145s	
17974/30300 (epoch 29.660), train_loss = 1.10387443, grad/param norm = 1.6679e-01, time/batch = 0.7231s	
17975/30300 (epoch 29.662), train_loss = 1.10366899, grad/param norm = 1.8265e-01, time/batch = 0.7145s	
17976/30300 (epoch 29.663), train_loss = 1.13610175, grad/param norm = 1.6375e-01, time/batch = 0.7302s	
17977/30300 (epoch 29.665), train_loss = 1.04855983, grad/param norm = 1.6636e-01, time/batch = 0.7118s	
17978/30300 (epoch 29.667), train_loss = 1.16396931, grad/param norm = 1.6569e-01, time/batch = 0.7123s	
17979/30300 (epoch 29.668), train_loss = 1.19038403, grad/param norm = 1.7081e-01, time/batch = 0.6996s	
17980/30300 (epoch 29.670), train_loss = 1.22190085, grad/param norm = 1.7644e-01, time/batch = 0.7116s	
17981/30300 (epoch 29.672), train_loss = 1.10271590, grad/param norm = 1.6370e-01, time/batch = 0.7106s	
17982/30300 (epoch 29.673), train_loss = 1.14870623, grad/param norm = 1.8268e-01, time/batch = 0.6987s	
17983/30300 (epoch 29.675), train_loss = 1.04159967, grad/param norm = 1.5987e-01, time/batch = 0.6858s	
17984/30300 (epoch 29.677), train_loss = 1.05695305, grad/param norm = 1.4723e-01, time/batch = 0.6878s	
17985/30300 (epoch 29.678), train_loss = 1.04439270, grad/param norm = 1.5070e-01, time/batch = 0.6851s	
17986/30300 (epoch 29.680), train_loss = 0.93956555, grad/param norm = 1.4626e-01, time/batch = 0.7249s	
17987/30300 (epoch 29.682), train_loss = 1.08716902, grad/param norm = 1.6978e-01, time/batch = 0.7170s	
17988/30300 (epoch 29.683), train_loss = 1.19454304, grad/param norm = 1.5044e-01, time/batch = 0.6914s	
17989/30300 (epoch 29.685), train_loss = 1.17546400, grad/param norm = 1.8186e-01, time/batch = 0.6900s	
17990/30300 (epoch 29.686), train_loss = 1.05460115, grad/param norm = 1.4491e-01, time/batch = 0.6799s	
17991/30300 (epoch 29.688), train_loss = 1.08934189, grad/param norm = 1.4352e-01, time/batch = 0.6857s	
17992/30300 (epoch 29.690), train_loss = 1.05026965, grad/param norm = 1.6284e-01, time/batch = 0.6803s	
17993/30300 (epoch 29.691), train_loss = 1.12433383, grad/param norm = 1.4525e-01, time/batch = 0.6814s	
17994/30300 (epoch 29.693), train_loss = 1.39072327, grad/param norm = 1.8077e-01, time/batch = 0.6807s	
17995/30300 (epoch 29.695), train_loss = 1.17840425, grad/param norm = 1.6047e-01, time/batch = 0.6801s	
17996/30300 (epoch 29.696), train_loss = 1.17364303, grad/param norm = 2.0619e-01, time/batch = 0.6825s	
17997/30300 (epoch 29.698), train_loss = 1.04373509, grad/param norm = 1.5935e-01, time/batch = 0.6826s	
17998/30300 (epoch 29.700), train_loss = 1.04435380, grad/param norm = 1.6686e-01, time/batch = 0.6842s	
17999/30300 (epoch 29.701), train_loss = 0.95268953, grad/param norm = 1.4486e-01, time/batch = 0.6830s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch29.70_1.9140.t7	
18000/30300 (epoch 29.703), train_loss = 1.10249180, grad/param norm = 1.4901e-01, time/batch = 0.6872s	
18001/30300 (epoch 29.705), train_loss = 1.64260382, grad/param norm = 2.2007e-01, time/batch = 0.6984s	
18002/30300 (epoch 29.706), train_loss = 1.16221666, grad/param norm = 1.8316e-01, time/batch = 0.6854s	
18003/30300 (epoch 29.708), train_loss = 1.10550527, grad/param norm = 1.6858e-01, time/batch = 0.7084s	
18004/30300 (epoch 29.710), train_loss = 1.06082680, grad/param norm = 1.5327e-01, time/batch = 0.7011s	
18005/30300 (epoch 29.711), train_loss = 1.03238629, grad/param norm = 1.5156e-01, time/batch = 0.7134s	
18006/30300 (epoch 29.713), train_loss = 1.00998665, grad/param norm = 1.5496e-01, time/batch = 0.7024s	
18007/30300 (epoch 29.715), train_loss = 1.04130654, grad/param norm = 1.4544e-01, time/batch = 0.6878s	
18008/30300 (epoch 29.716), train_loss = 1.17515965, grad/param norm = 1.4790e-01, time/batch = 0.6875s	
18009/30300 (epoch 29.718), train_loss = 1.21259599, grad/param norm = 1.6220e-01, time/batch = 0.6836s	
18010/30300 (epoch 29.719), train_loss = 1.04302397, grad/param norm = 1.6817e-01, time/batch = 0.6819s	
18011/30300 (epoch 29.721), train_loss = 1.07940910, grad/param norm = 1.5844e-01, time/batch = 0.6829s	
18012/30300 (epoch 29.723), train_loss = 1.03084282, grad/param norm = 1.5854e-01, time/batch = 0.6812s	
18013/30300 (epoch 29.724), train_loss = 1.13945260, grad/param norm = 1.8069e-01, time/batch = 0.6866s	
18014/30300 (epoch 29.726), train_loss = 1.44632701, grad/param norm = 2.0223e-01, time/batch = 0.6850s	
18015/30300 (epoch 29.728), train_loss = 1.15342204, grad/param norm = 1.6836e-01, time/batch = 0.7029s	
18016/30300 (epoch 29.729), train_loss = 1.08098376, grad/param norm = 1.7752e-01, time/batch = 0.7010s	
18017/30300 (epoch 29.731), train_loss = 1.11473924, grad/param norm = 1.8199e-01, time/batch = 0.7016s	
18018/30300 (epoch 29.733), train_loss = 1.10731043, grad/param norm = 1.6003e-01, time/batch = 0.7059s	
18019/30300 (epoch 29.734), train_loss = 1.18085041, grad/param norm = 1.5103e-01, time/batch = 0.7113s	
18020/30300 (epoch 29.736), train_loss = 1.09131308, grad/param norm = 1.5534e-01, time/batch = 0.7104s	
18021/30300 (epoch 29.738), train_loss = 1.03154530, grad/param norm = 1.3957e-01, time/batch = 0.6877s	
18022/30300 (epoch 29.739), train_loss = 1.18710161, grad/param norm = 2.0282e-01, time/batch = 0.6839s	
18023/30300 (epoch 29.741), train_loss = 1.23991632, grad/param norm = 1.4902e-01, time/batch = 0.6830s	
18024/30300 (epoch 29.743), train_loss = 1.09807694, grad/param norm = 1.6889e-01, time/batch = 0.6854s	
18025/30300 (epoch 29.744), train_loss = 1.12953702, grad/param norm = 1.5645e-01, time/batch = 0.7126s	
18026/30300 (epoch 29.746), train_loss = 1.04997414, grad/param norm = 1.4591e-01, time/batch = 0.7040s	
18027/30300 (epoch 29.748), train_loss = 1.08303190, grad/param norm = 2.2313e-01, time/batch = 0.6894s	
18028/30300 (epoch 29.749), train_loss = 1.15569344, grad/param norm = 1.7967e-01, time/batch = 0.6875s	
18029/30300 (epoch 29.751), train_loss = 1.11770664, grad/param norm = 1.7484e-01, time/batch = 0.7163s	
18030/30300 (epoch 29.752), train_loss = 1.08206907, grad/param norm = 1.8290e-01, time/batch = 0.7092s	
18031/30300 (epoch 29.754), train_loss = 1.05354073, grad/param norm = 1.4649e-01, time/batch = 0.6836s	
18032/30300 (epoch 29.756), train_loss = 1.06379634, grad/param norm = 1.5743e-01, time/batch = 0.6847s	
18033/30300 (epoch 29.757), train_loss = 1.06068993, grad/param norm = 1.5661e-01, time/batch = 0.6840s	
18034/30300 (epoch 29.759), train_loss = 1.13604958, grad/param norm = 1.5031e-01, time/batch = 0.6830s	
18035/30300 (epoch 29.761), train_loss = 0.95491937, grad/param norm = 1.4284e-01, time/batch = 0.7025s	
18036/30300 (epoch 29.762), train_loss = 0.99405577, grad/param norm = 1.5184e-01, time/batch = 0.7007s	
18037/30300 (epoch 29.764), train_loss = 1.08498394, grad/param norm = 1.5539e-01, time/batch = 0.6977s	
18038/30300 (epoch 29.766), train_loss = 1.19332640, grad/param norm = 1.6475e-01, time/batch = 0.7119s	
18039/30300 (epoch 29.767), train_loss = 1.15802187, grad/param norm = 1.8119e-01, time/batch = 0.6876s	
18040/30300 (epoch 29.769), train_loss = 1.12602287, grad/param norm = 1.5607e-01, time/batch = 0.6812s	
18041/30300 (epoch 29.771), train_loss = 1.04746796, grad/param norm = 1.8558e-01, time/batch = 0.6851s	
18042/30300 (epoch 29.772), train_loss = 1.13023027, grad/param norm = 1.5917e-01, time/batch = 0.6897s	
18043/30300 (epoch 29.774), train_loss = 1.23327296, grad/param norm = 1.5859e-01, time/batch = 0.7008s	
18044/30300 (epoch 29.776), train_loss = 1.09125820, grad/param norm = 1.6906e-01, time/batch = 0.7177s	
18045/30300 (epoch 29.777), train_loss = 1.21760315, grad/param norm = 1.5524e-01, time/batch = 0.6798s	
18046/30300 (epoch 29.779), train_loss = 1.21392599, grad/param norm = 1.7778e-01, time/batch = 0.6775s	
18047/30300 (epoch 29.781), train_loss = 1.11324255, grad/param norm = 1.7028e-01, time/batch = 0.6865s	
18048/30300 (epoch 29.782), train_loss = 1.05083128, grad/param norm = 1.5929e-01, time/batch = 0.6919s	
18049/30300 (epoch 29.784), train_loss = 1.02875651, grad/param norm = 1.5062e-01, time/batch = 0.6834s	
18050/30300 (epoch 29.785), train_loss = 1.21023202, grad/param norm = 1.7725e-01, time/batch = 0.6817s	
18051/30300 (epoch 29.787), train_loss = 0.92469253, grad/param norm = 1.6186e-01, time/batch = 0.7410s	
18052/30300 (epoch 29.789), train_loss = 1.28795064, grad/param norm = 1.6828e-01, time/batch = 0.6988s	
18053/30300 (epoch 29.790), train_loss = 1.14410646, grad/param norm = 1.9478e-01, time/batch = 0.6834s	
18054/30300 (epoch 29.792), train_loss = 0.92188687, grad/param norm = 1.5533e-01, time/batch = 0.6792s	
18055/30300 (epoch 29.794), train_loss = 1.09731349, grad/param norm = 1.7094e-01, time/batch = 0.6800s	
18056/30300 (epoch 29.795), train_loss = 1.00118449, grad/param norm = 1.4325e-01, time/batch = 0.6800s	
18057/30300 (epoch 29.797), train_loss = 1.24574762, grad/param norm = 1.7463e-01, time/batch = 0.6792s	
18058/30300 (epoch 29.799), train_loss = 1.17773285, grad/param norm = 1.7915e-01, time/batch = 0.6804s	
18059/30300 (epoch 29.800), train_loss = 1.17318736, grad/param norm = 1.7819e-01, time/batch = 0.6817s	
18060/30300 (epoch 29.802), train_loss = 1.34996369, grad/param norm = 1.7820e-01, time/batch = 0.6825s	
18061/30300 (epoch 29.804), train_loss = 1.18240831, grad/param norm = 1.8018e-01, time/batch = 0.6826s	
18062/30300 (epoch 29.805), train_loss = 1.25125198, grad/param norm = 1.6995e-01, time/batch = 0.7106s	
18063/30300 (epoch 29.807), train_loss = 1.08559580, grad/param norm = 1.7876e-01, time/batch = 0.7128s	
18064/30300 (epoch 29.809), train_loss = 1.17396778, grad/param norm = 1.6336e-01, time/batch = 0.6826s	
18065/30300 (epoch 29.810), train_loss = 1.17249350, grad/param norm = 1.6752e-01, time/batch = 0.6833s	
18066/30300 (epoch 29.812), train_loss = 1.04003699, grad/param norm = 1.5413e-01, time/batch = 0.6863s	
18067/30300 (epoch 29.814), train_loss = 1.10068861, grad/param norm = 1.6201e-01, time/batch = 0.6843s	
18068/30300 (epoch 29.815), train_loss = 1.10879773, grad/param norm = 1.6382e-01, time/batch = 0.6791s	
18069/30300 (epoch 29.817), train_loss = 1.18888388, grad/param norm = 1.7551e-01, time/batch = 0.6797s	
18070/30300 (epoch 29.818), train_loss = 1.14169190, grad/param norm = 1.9957e-01, time/batch = 0.6809s	
18071/30300 (epoch 29.820), train_loss = 1.27864003, grad/param norm = 1.8321e-01, time/batch = 0.6843s	
18072/30300 (epoch 29.822), train_loss = 1.28465302, grad/param norm = 2.1326e-01, time/batch = 0.6822s	
18073/30300 (epoch 29.823), train_loss = 1.27036010, grad/param norm = 1.8996e-01, time/batch = 0.6854s	
18074/30300 (epoch 29.825), train_loss = 1.24446566, grad/param norm = 1.7300e-01, time/batch = 0.6828s	
18075/30300 (epoch 29.827), train_loss = 0.95513771, grad/param norm = 1.6795e-01, time/batch = 0.6812s	
18076/30300 (epoch 29.828), train_loss = 1.18272470, grad/param norm = 1.6617e-01, time/batch = 0.6799s	
18077/30300 (epoch 29.830), train_loss = 1.15471338, grad/param norm = 1.7209e-01, time/batch = 0.6814s	
18078/30300 (epoch 29.832), train_loss = 1.03378398, grad/param norm = 1.6844e-01, time/batch = 0.6800s	
18079/30300 (epoch 29.833), train_loss = 1.13746028, grad/param norm = 1.6237e-01, time/batch = 0.6817s	
18080/30300 (epoch 29.835), train_loss = 1.03499426, grad/param norm = 1.6904e-01, time/batch = 0.6872s	
18081/30300 (epoch 29.837), train_loss = 0.99790373, grad/param norm = 1.4861e-01, time/batch = 0.7200s	
18082/30300 (epoch 29.838), train_loss = 0.99995528, grad/param norm = 1.5311e-01, time/batch = 0.7075s	
18083/30300 (epoch 29.840), train_loss = 1.20235938, grad/param norm = 1.4724e-01, time/batch = 0.6823s	
18084/30300 (epoch 29.842), train_loss = 1.05112697, grad/param norm = 1.3315e-01, time/batch = 0.6829s	
18085/30300 (epoch 29.843), train_loss = 1.14461177, grad/param norm = 1.5640e-01, time/batch = 0.6824s	
18086/30300 (epoch 29.845), train_loss = 1.16460753, grad/param norm = 1.4876e-01, time/batch = 0.6852s	
18087/30300 (epoch 29.847), train_loss = 1.12523540, grad/param norm = 1.5681e-01, time/batch = 0.6817s	
18088/30300 (epoch 29.848), train_loss = 1.17974634, grad/param norm = 1.7047e-01, time/batch = 0.6846s	
18089/30300 (epoch 29.850), train_loss = 1.11747547, grad/param norm = 1.5291e-01, time/batch = 0.6846s	
18090/30300 (epoch 29.851), train_loss = 1.14505404, grad/param norm = 1.9266e-01, time/batch = 0.6869s	
18091/30300 (epoch 29.853), train_loss = 1.06228742, grad/param norm = 1.5292e-01, time/batch = 0.6859s	
18092/30300 (epoch 29.855), train_loss = 1.05578494, grad/param norm = 1.4978e-01, time/batch = 0.6871s	
18093/30300 (epoch 29.856), train_loss = 1.13901866, grad/param norm = 1.6018e-01, time/batch = 0.6871s	
18094/30300 (epoch 29.858), train_loss = 1.04244383, grad/param norm = 1.4516e-01, time/batch = 0.6834s	
18095/30300 (epoch 29.860), train_loss = 1.02244747, grad/param norm = 1.5319e-01, time/batch = 0.6840s	
18096/30300 (epoch 29.861), train_loss = 1.26823075, grad/param norm = 1.5902e-01, time/batch = 0.6885s	
18097/30300 (epoch 29.863), train_loss = 1.08978255, grad/param norm = 1.5312e-01, time/batch = 0.6838s	
18098/30300 (epoch 29.865), train_loss = 1.16293432, grad/param norm = 1.7066e-01, time/batch = 0.6805s	
18099/30300 (epoch 29.866), train_loss = 1.18578642, grad/param norm = 1.6693e-01, time/batch = 0.6794s	
18100/30300 (epoch 29.868), train_loss = 1.11647849, grad/param norm = 1.5146e-01, time/batch = 0.7231s	
18101/30300 (epoch 29.870), train_loss = 1.03979426, grad/param norm = 1.5182e-01, time/batch = 0.7024s	
18102/30300 (epoch 29.871), train_loss = 1.10353588, grad/param norm = 1.5577e-01, time/batch = 0.6822s	
18103/30300 (epoch 29.873), train_loss = 1.09574353, grad/param norm = 1.4262e-01, time/batch = 0.6905s	
18104/30300 (epoch 29.875), train_loss = 1.07042758, grad/param norm = 1.4354e-01, time/batch = 0.6914s	
18105/30300 (epoch 29.876), train_loss = 0.98684293, grad/param norm = 1.5691e-01, time/batch = 0.6837s	
18106/30300 (epoch 29.878), train_loss = 0.95687888, grad/param norm = 1.5788e-01, time/batch = 0.6943s	
18107/30300 (epoch 29.880), train_loss = 1.01711805, grad/param norm = 1.5616e-01, time/batch = 0.7084s	
18108/30300 (epoch 29.881), train_loss = 1.25737225, grad/param norm = 1.8219e-01, time/batch = 0.7195s	
18109/30300 (epoch 29.883), train_loss = 1.16238171, grad/param norm = 1.6188e-01, time/batch = 0.6945s	
18110/30300 (epoch 29.884), train_loss = 1.05539390, grad/param norm = 1.3926e-01, time/batch = 0.7001s	
18111/30300 (epoch 29.886), train_loss = 1.15448404, grad/param norm = 1.5982e-01, time/batch = 0.7006s	
18112/30300 (epoch 29.888), train_loss = 1.09123289, grad/param norm = 1.6753e-01, time/batch = 0.7073s	
18113/30300 (epoch 29.889), train_loss = 1.12838130, grad/param norm = 1.5584e-01, time/batch = 0.7053s	
18114/30300 (epoch 29.891), train_loss = 1.08700639, grad/param norm = 1.5912e-01, time/batch = 0.7158s	
18115/30300 (epoch 29.893), train_loss = 1.31499903, grad/param norm = 1.5813e-01, time/batch = 0.7084s	
18116/30300 (epoch 29.894), train_loss = 1.16025264, grad/param norm = 1.6661e-01, time/batch = 0.6866s	
18117/30300 (epoch 29.896), train_loss = 0.95236336, grad/param norm = 1.7317e-01, time/batch = 0.6926s	
18118/30300 (epoch 29.898), train_loss = 0.96248022, grad/param norm = 1.5818e-01, time/batch = 0.6835s	
18119/30300 (epoch 29.899), train_loss = 1.01907046, grad/param norm = 1.5023e-01, time/batch = 0.6810s	
18120/30300 (epoch 29.901), train_loss = 1.11692841, grad/param norm = 1.9273e-01, time/batch = 0.6806s	
18121/30300 (epoch 29.903), train_loss = 1.11460564, grad/param norm = 1.7892e-01, time/batch = 0.6918s	
18122/30300 (epoch 29.904), train_loss = 1.11013442, grad/param norm = 1.5235e-01, time/batch = 0.7009s	
18123/30300 (epoch 29.906), train_loss = 1.14397380, grad/param norm = 1.9899e-01, time/batch = 0.6868s	
18124/30300 (epoch 29.908), train_loss = 1.05676306, grad/param norm = 1.4679e-01, time/batch = 0.7020s	
18125/30300 (epoch 29.909), train_loss = 1.03323064, grad/param norm = 1.8256e-01, time/batch = 0.7319s	
18126/30300 (epoch 29.911), train_loss = 1.10826737, grad/param norm = 1.5325e-01, time/batch = 0.7325s	
18127/30300 (epoch 29.913), train_loss = 1.10422016, grad/param norm = 1.4877e-01, time/batch = 0.6883s	
18128/30300 (epoch 29.914), train_loss = 1.07311572, grad/param norm = 1.7695e-01, time/batch = 0.7051s	
18129/30300 (epoch 29.916), train_loss = 1.13005232, grad/param norm = 1.4642e-01, time/batch = 0.7215s	
18130/30300 (epoch 29.917), train_loss = 1.08011669, grad/param norm = 1.6023e-01, time/batch = 0.6836s	
18131/30300 (epoch 29.919), train_loss = 1.02868211, grad/param norm = 1.5772e-01, time/batch = 0.6855s	
18132/30300 (epoch 29.921), train_loss = 1.07671982, grad/param norm = 1.4275e-01, time/batch = 0.6829s	
18133/30300 (epoch 29.922), train_loss = 1.19124859, grad/param norm = 1.7518e-01, time/batch = 0.6802s	
18134/30300 (epoch 29.924), train_loss = 1.10789735, grad/param norm = 1.7244e-01, time/batch = 0.6808s	
18135/30300 (epoch 29.926), train_loss = 1.15254520, grad/param norm = 1.6444e-01, time/batch = 0.6825s	
18136/30300 (epoch 29.927), train_loss = 1.12100898, grad/param norm = 1.5765e-01, time/batch = 0.6793s	
18137/30300 (epoch 29.929), train_loss = 1.01984800, grad/param norm = 1.6097e-01, time/batch = 0.6824s	
18138/30300 (epoch 29.931), train_loss = 1.20556609, grad/param norm = 1.9026e-01, time/batch = 0.6841s	
18139/30300 (epoch 29.932), train_loss = 1.03313441, grad/param norm = 1.7028e-01, time/batch = 0.6822s	
18140/30300 (epoch 29.934), train_loss = 1.13355496, grad/param norm = 1.6207e-01, time/batch = 0.6860s	
18141/30300 (epoch 29.936), train_loss = 1.03967160, grad/param norm = 1.4912e-01, time/batch = 0.6833s	
18142/30300 (epoch 29.937), train_loss = 1.04729477, grad/param norm = 1.7373e-01, time/batch = 0.6870s	
18143/30300 (epoch 29.939), train_loss = 1.23280211, grad/param norm = 1.7783e-01, time/batch = 0.7270s	
18144/30300 (epoch 29.941), train_loss = 1.09972023, grad/param norm = 1.7398e-01, time/batch = 0.6994s	
18145/30300 (epoch 29.942), train_loss = 1.09572942, grad/param norm = 1.7403e-01, time/batch = 0.6852s	
18146/30300 (epoch 29.944), train_loss = 0.99324769, grad/param norm = 1.5187e-01, time/batch = 0.6832s	
18147/30300 (epoch 29.946), train_loss = 1.20275878, grad/param norm = 1.8834e-01, time/batch = 0.6830s	
18148/30300 (epoch 29.947), train_loss = 1.17992397, grad/param norm = 1.8976e-01, time/batch = 0.6817s	
18149/30300 (epoch 29.949), train_loss = 1.19510756, grad/param norm = 1.7462e-01, time/batch = 0.6823s	
18150/30300 (epoch 29.950), train_loss = 1.19330341, grad/param norm = 1.6566e-01, time/batch = 0.6805s	
18151/30300 (epoch 29.952), train_loss = 1.14525047, grad/param norm = 1.6151e-01, time/batch = 0.6854s	
18152/30300 (epoch 29.954), train_loss = 1.37797454, grad/param norm = 1.7659e-01, time/batch = 0.6842s	
18153/30300 (epoch 29.955), train_loss = 1.09475740, grad/param norm = 1.5875e-01, time/batch = 0.6848s	
18154/30300 (epoch 29.957), train_loss = 1.16401709, grad/param norm = 1.6260e-01, time/batch = 0.6831s	
18155/30300 (epoch 29.959), train_loss = 1.04852703, grad/param norm = 1.7932e-01, time/batch = 0.6837s	
18156/30300 (epoch 29.960), train_loss = 1.07493695, grad/param norm = 1.7315e-01, time/batch = 0.6872s	
18157/30300 (epoch 29.962), train_loss = 1.08846674, grad/param norm = 2.0817e-01, time/batch = 0.6864s	
18158/30300 (epoch 29.964), train_loss = 1.02088599, grad/param norm = 2.0274e-01, time/batch = 0.6856s	
18159/30300 (epoch 29.965), train_loss = 1.06226079, grad/param norm = 1.9214e-01, time/batch = 0.6828s	
18160/30300 (epoch 29.967), train_loss = 1.12212760, grad/param norm = 2.1177e-01, time/batch = 0.6799s	
18161/30300 (epoch 29.969), train_loss = 1.01977816, grad/param norm = 1.8817e-01, time/batch = 0.6906s	
18162/30300 (epoch 29.970), train_loss = 1.09468489, grad/param norm = 1.6115e-01, time/batch = 0.7268s	
18163/30300 (epoch 29.972), train_loss = 0.99857657, grad/param norm = 1.7957e-01, time/batch = 0.6908s	
18164/30300 (epoch 29.974), train_loss = 1.25966153, grad/param norm = 1.7449e-01, time/batch = 0.6801s	
18165/30300 (epoch 29.975), train_loss = 1.27305592, grad/param norm = 2.1606e-01, time/batch = 0.6783s	
18166/30300 (epoch 29.977), train_loss = 1.27419253, grad/param norm = 1.7567e-01, time/batch = 0.6794s	
18167/30300 (epoch 29.979), train_loss = 1.16847372, grad/param norm = 1.8095e-01, time/batch = 0.6833s	
18168/30300 (epoch 29.980), train_loss = 1.20749927, grad/param norm = 1.9247e-01, time/batch = 0.6841s	
18169/30300 (epoch 29.982), train_loss = 1.21442817, grad/param norm = 1.7479e-01, time/batch = 0.6795s	
18170/30300 (epoch 29.983), train_loss = 1.23833425, grad/param norm = 1.6400e-01, time/batch = 0.6782s	
18171/30300 (epoch 29.985), train_loss = 1.17842399, grad/param norm = 1.8611e-01, time/batch = 0.6846s	
18172/30300 (epoch 29.987), train_loss = 1.09230465, grad/param norm = 1.5200e-01, time/batch = 0.6800s	
18173/30300 (epoch 29.988), train_loss = 1.24415543, grad/param norm = 1.7112e-01, time/batch = 0.6787s	
18174/30300 (epoch 29.990), train_loss = 1.01120993, grad/param norm = 1.4811e-01, time/batch = 0.6783s	
18175/30300 (epoch 29.992), train_loss = 1.18845756, grad/param norm = 1.4785e-01, time/batch = 0.6786s	
18176/30300 (epoch 29.993), train_loss = 1.23116854, grad/param norm = 2.0181e-01, time/batch = 0.6769s	
18177/30300 (epoch 29.995), train_loss = 1.11163620, grad/param norm = 1.8995e-01, time/batch = 0.6791s	
18178/30300 (epoch 29.997), train_loss = 1.13933391, grad/param norm = 2.0076e-01, time/batch = 0.6807s	
18179/30300 (epoch 29.998), train_loss = 1.19509766, grad/param norm = 1.9921e-01, time/batch = 0.6792s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
18180/30300 (epoch 30.000), train_loss = 1.07470935, grad/param norm = 1.9070e-01, time/batch = 0.6896s	
18181/30300 (epoch 30.002), train_loss = 1.20099434, grad/param norm = 1.6736e-01, time/batch = 0.7099s	
18182/30300 (epoch 30.003), train_loss = 1.10682348, grad/param norm = 1.6972e-01, time/batch = 0.6803s	
18183/30300 (epoch 30.005), train_loss = 1.07375499, grad/param norm = 1.7402e-01, time/batch = 0.6792s	
18184/30300 (epoch 30.007), train_loss = 1.14938617, grad/param norm = 1.8106e-01, time/batch = 0.6834s	
18185/30300 (epoch 30.008), train_loss = 1.07495467, grad/param norm = 1.6161e-01, time/batch = 0.6971s	
18186/30300 (epoch 30.010), train_loss = 0.99559932, grad/param norm = 1.7435e-01, time/batch = 0.6926s	
18187/30300 (epoch 30.012), train_loss = 1.04863870, grad/param norm = 1.5712e-01, time/batch = 0.6885s	
18188/30300 (epoch 30.013), train_loss = 1.19521956, grad/param norm = 1.8681e-01, time/batch = 0.6872s	
18189/30300 (epoch 30.015), train_loss = 1.06778677, grad/param norm = 1.5378e-01, time/batch = 0.6810s	
18190/30300 (epoch 30.017), train_loss = 1.07344597, grad/param norm = 1.5245e-01, time/batch = 0.6813s	
18191/30300 (epoch 30.018), train_loss = 1.02629928, grad/param norm = 1.5620e-01, time/batch = 0.6824s	
18192/30300 (epoch 30.020), train_loss = 1.20421707, grad/param norm = 2.2031e-01, time/batch = 0.6821s	
18193/30300 (epoch 30.021), train_loss = 1.24033604, grad/param norm = 1.7654e-01, time/batch = 0.6819s	
18194/30300 (epoch 30.023), train_loss = 1.12863223, grad/param norm = 1.5972e-01, time/batch = 0.6822s	
18195/30300 (epoch 30.025), train_loss = 1.03821416, grad/param norm = 1.8199e-01, time/batch = 0.6798s	
18196/30300 (epoch 30.026), train_loss = 1.15531826, grad/param norm = 1.7679e-01, time/batch = 0.6792s	
18197/30300 (epoch 30.028), train_loss = 1.19564683, grad/param norm = 1.7340e-01, time/batch = 0.6815s	
18198/30300 (epoch 30.030), train_loss = 1.07172577, grad/param norm = 1.8108e-01, time/batch = 0.6855s	
18199/30300 (epoch 30.031), train_loss = 1.17521841, grad/param norm = 1.6725e-01, time/batch = 0.6801s	
18200/30300 (epoch 30.033), train_loss = 1.11161710, grad/param norm = 1.4744e-01, time/batch = 0.6813s	
18201/30300 (epoch 30.035), train_loss = 1.19310625, grad/param norm = 1.8878e-01, time/batch = 0.6834s	
18202/30300 (epoch 30.036), train_loss = 1.14288301, grad/param norm = 1.6351e-01, time/batch = 0.6823s	
18203/30300 (epoch 30.038), train_loss = 1.15625285, grad/param norm = 1.5517e-01, time/batch = 0.6797s	
18204/30300 (epoch 30.040), train_loss = 0.92056726, grad/param norm = 1.5388e-01, time/batch = 0.6828s	
18205/30300 (epoch 30.041), train_loss = 0.94656345, grad/param norm = 1.6719e-01, time/batch = 0.6795s	
18206/30300 (epoch 30.043), train_loss = 1.13350963, grad/param norm = 1.7013e-01, time/batch = 0.6813s	
18207/30300 (epoch 30.045), train_loss = 1.08367843, grad/param norm = 1.5376e-01, time/batch = 0.6813s	
18208/30300 (epoch 30.046), train_loss = 1.28850063, grad/param norm = 1.8859e-01, time/batch = 0.6899s	
18209/30300 (epoch 30.048), train_loss = 1.09794229, grad/param norm = 1.6526e-01, time/batch = 0.6979s	
18210/30300 (epoch 30.050), train_loss = 1.04848168, grad/param norm = 1.6033e-01, time/batch = 0.6894s	
18211/30300 (epoch 30.051), train_loss = 1.14154207, grad/param norm = 1.7077e-01, time/batch = 0.7038s	
18212/30300 (epoch 30.053), train_loss = 0.96815914, grad/param norm = 2.0383e-01, time/batch = 0.7216s	
18213/30300 (epoch 30.054), train_loss = 1.13601254, grad/param norm = 1.6236e-01, time/batch = 0.7141s	
18214/30300 (epoch 30.056), train_loss = 1.01999508, grad/param norm = 1.5872e-01, time/batch = 0.6994s	
18215/30300 (epoch 30.058), train_loss = 1.09263220, grad/param norm = 1.7199e-01, time/batch = 0.6962s	
18216/30300 (epoch 30.059), train_loss = 1.04936489, grad/param norm = 1.9813e-01, time/batch = 0.7048s	
18217/30300 (epoch 30.061), train_loss = 1.16506497, grad/param norm = 1.7225e-01, time/batch = 0.6943s	
18218/30300 (epoch 30.063), train_loss = 1.00225434, grad/param norm = 1.7284e-01, time/batch = 0.7162s	
18219/30300 (epoch 30.064), train_loss = 1.12027139, grad/param norm = 1.7326e-01, time/batch = 0.7053s	
18220/30300 (epoch 30.066), train_loss = 1.09882434, grad/param norm = 1.5267e-01, time/batch = 0.6906s	
18221/30300 (epoch 30.068), train_loss = 1.00870447, grad/param norm = 1.6303e-01, time/batch = 0.6950s	
18222/30300 (epoch 30.069), train_loss = 1.18271854, grad/param norm = 1.6751e-01, time/batch = 0.6950s	
18223/30300 (epoch 30.071), train_loss = 1.15170397, grad/param norm = 1.5909e-01, time/batch = 0.6846s	
18224/30300 (epoch 30.073), train_loss = 1.04112719, grad/param norm = 1.6565e-01, time/batch = 0.6864s	
18225/30300 (epoch 30.074), train_loss = 1.10855752, grad/param norm = 1.6075e-01, time/batch = 0.6883s	
18226/30300 (epoch 30.076), train_loss = 1.09814006, grad/param norm = 1.6154e-01, time/batch = 0.6819s	
18227/30300 (epoch 30.078), train_loss = 1.02885388, grad/param norm = 1.4138e-01, time/batch = 0.6859s	
18228/30300 (epoch 30.079), train_loss = 1.05823279, grad/param norm = 1.6676e-01, time/batch = 0.6863s	
18229/30300 (epoch 30.081), train_loss = 1.10255626, grad/param norm = 1.5719e-01, time/batch = 0.6823s	
18230/30300 (epoch 30.083), train_loss = 1.18306150, grad/param norm = 2.0449e-01, time/batch = 0.6878s	
18231/30300 (epoch 30.084), train_loss = 1.02431684, grad/param norm = 1.6191e-01, time/batch = 0.6845s	
18232/30300 (epoch 30.086), train_loss = 1.03592922, grad/param norm = 1.7686e-01, time/batch = 0.6975s	
18233/30300 (epoch 30.087), train_loss = 1.01950936, grad/param norm = 1.4871e-01, time/batch = 0.7270s	
18234/30300 (epoch 30.089), train_loss = 1.05912696, grad/param norm = 1.6110e-01, time/batch = 0.6885s	
18235/30300 (epoch 30.091), train_loss = 1.14125319, grad/param norm = 1.5567e-01, time/batch = 0.6853s	
18236/30300 (epoch 30.092), train_loss = 1.15589929, grad/param norm = 1.6080e-01, time/batch = 0.6823s	
18237/30300 (epoch 30.094), train_loss = 1.25979959, grad/param norm = 1.8744e-01, time/batch = 0.7050s	
18238/30300 (epoch 30.096), train_loss = 1.22016724, grad/param norm = 1.7810e-01, time/batch = 0.7089s	
18239/30300 (epoch 30.097), train_loss = 1.03995717, grad/param norm = 1.6692e-01, time/batch = 0.7034s	
18240/30300 (epoch 30.099), train_loss = 1.19609046, grad/param norm = 1.6513e-01, time/batch = 0.6837s	
18241/30300 (epoch 30.101), train_loss = 1.26279747, grad/param norm = 2.0384e-01, time/batch = 0.7047s	
18242/30300 (epoch 30.102), train_loss = 1.04420377, grad/param norm = 1.8506e-01, time/batch = 0.6978s	
18243/30300 (epoch 30.104), train_loss = 1.06594306, grad/param norm = 1.9044e-01, time/batch = 0.6845s	
18244/30300 (epoch 30.106), train_loss = 1.09868152, grad/param norm = 1.9635e-01, time/batch = 0.7061s	
18245/30300 (epoch 30.107), train_loss = 1.14698479, grad/param norm = 1.6021e-01, time/batch = 0.7253s	
18246/30300 (epoch 30.109), train_loss = 1.17135193, grad/param norm = 2.0425e-01, time/batch = 0.7223s	
18247/30300 (epoch 30.111), train_loss = 1.21282866, grad/param norm = 1.8432e-01, time/batch = 0.6867s	
18248/30300 (epoch 30.112), train_loss = 1.23772006, grad/param norm = 1.6502e-01, time/batch = 0.6828s	
18249/30300 (epoch 30.114), train_loss = 1.06226708, grad/param norm = 1.5630e-01, time/batch = 0.6893s	
18250/30300 (epoch 30.116), train_loss = 1.11824133, grad/param norm = 1.7226e-01, time/batch = 0.6832s	
18251/30300 (epoch 30.117), train_loss = 1.19009020, grad/param norm = 1.5992e-01, time/batch = 0.7175s	
18252/30300 (epoch 30.119), train_loss = 1.04448026, grad/param norm = 2.0092e-01, time/batch = 0.7120s	
18253/30300 (epoch 30.120), train_loss = 1.07934969, grad/param norm = 1.6032e-01, time/batch = 0.6840s	
18254/30300 (epoch 30.122), train_loss = 1.21102734, grad/param norm = 2.0433e-01, time/batch = 0.6837s	
18255/30300 (epoch 30.124), train_loss = 1.26355224, grad/param norm = 1.8904e-01, time/batch = 0.6814s	
18256/30300 (epoch 30.125), train_loss = 0.99024114, grad/param norm = 1.6206e-01, time/batch = 0.6815s	
18257/30300 (epoch 30.127), train_loss = 1.16245859, grad/param norm = 2.0725e-01, time/batch = 0.6882s	
18258/30300 (epoch 30.129), train_loss = 1.23439033, grad/param norm = 1.7703e-01, time/batch = 0.6988s	
18259/30300 (epoch 30.130), train_loss = 1.24498262, grad/param norm = 1.6309e-01, time/batch = 0.6845s	
18260/30300 (epoch 30.132), train_loss = 1.25591133, grad/param norm = 1.7459e-01, time/batch = 0.6818s	
18261/30300 (epoch 30.134), train_loss = 1.02550277, grad/param norm = 1.6510e-01, time/batch = 0.6836s	
18262/30300 (epoch 30.135), train_loss = 1.06274120, grad/param norm = 1.7941e-01, time/batch = 0.6827s	
18263/30300 (epoch 30.137), train_loss = 1.12117838, grad/param norm = 1.9230e-01, time/batch = 0.6835s	
18264/30300 (epoch 30.139), train_loss = 1.08403719, grad/param norm = 2.3084e-01, time/batch = 0.6818s	
18265/30300 (epoch 30.140), train_loss = 1.14403825, grad/param norm = 2.4086e-01, time/batch = 0.6946s	
18266/30300 (epoch 30.142), train_loss = 1.22949716, grad/param norm = 1.8823e-01, time/batch = 0.7260s	
18267/30300 (epoch 30.144), train_loss = 1.05603527, grad/param norm = 1.8155e-01, time/batch = 0.6852s	
18268/30300 (epoch 30.145), train_loss = 1.20062858, grad/param norm = 1.8010e-01, time/batch = 0.6825s	
18269/30300 (epoch 30.147), train_loss = 1.07108908, grad/param norm = 1.5916e-01, time/batch = 0.6814s	
18270/30300 (epoch 30.149), train_loss = 1.24725653, grad/param norm = 1.9559e-01, time/batch = 0.6799s	
18271/30300 (epoch 30.150), train_loss = 1.07463515, grad/param norm = 1.8186e-01, time/batch = 0.6822s	
18272/30300 (epoch 30.152), train_loss = 0.99920590, grad/param norm = 1.8257e-01, time/batch = 0.6887s	
18273/30300 (epoch 30.153), train_loss = 1.10871070, grad/param norm = 2.0028e-01, time/batch = 0.6874s	
18274/30300 (epoch 30.155), train_loss = 0.97795150, grad/param norm = 1.4403e-01, time/batch = 0.7076s	
18275/30300 (epoch 30.157), train_loss = 1.09014378, grad/param norm = 1.9932e-01, time/batch = 0.6872s	
18276/30300 (epoch 30.158), train_loss = 1.14064159, grad/param norm = 2.1197e-01, time/batch = 0.6820s	
18277/30300 (epoch 30.160), train_loss = 1.03807485, grad/param norm = 1.9303e-01, time/batch = 0.6807s	
18278/30300 (epoch 30.162), train_loss = 1.11824978, grad/param norm = 1.5996e-01, time/batch = 0.6813s	
18279/30300 (epoch 30.163), train_loss = 1.09712292, grad/param norm = 1.7635e-01, time/batch = 0.6858s	
18280/30300 (epoch 30.165), train_loss = 1.22769569, grad/param norm = 1.7072e-01, time/batch = 0.6796s	
18281/30300 (epoch 30.167), train_loss = 1.11591371, grad/param norm = 1.7865e-01, time/batch = 0.6831s	
18282/30300 (epoch 30.168), train_loss = 1.16283908, grad/param norm = 1.5630e-01, time/batch = 0.6804s	
18283/30300 (epoch 30.170), train_loss = 1.11051182, grad/param norm = 1.7363e-01, time/batch = 0.6795s	
18284/30300 (epoch 30.172), train_loss = 1.12099063, grad/param norm = 2.5533e-01, time/batch = 0.7010s	
18285/30300 (epoch 30.173), train_loss = 1.09566733, grad/param norm = 1.9159e-01, time/batch = 0.7240s	
18286/30300 (epoch 30.175), train_loss = 1.11644438, grad/param norm = 1.6656e-01, time/batch = 0.6894s	
18287/30300 (epoch 30.177), train_loss = 1.15108386, grad/param norm = 1.6989e-01, time/batch = 0.6953s	
18288/30300 (epoch 30.178), train_loss = 0.90590721, grad/param norm = 1.4790e-01, time/batch = 0.6951s	
18289/30300 (epoch 30.180), train_loss = 1.09905154, grad/param norm = 1.5481e-01, time/batch = 0.6910s	
18290/30300 (epoch 30.182), train_loss = 1.13043884, grad/param norm = 1.9594e-01, time/batch = 0.7003s	
18291/30300 (epoch 30.183), train_loss = 1.06672108, grad/param norm = 1.6769e-01, time/batch = 0.6957s	
18292/30300 (epoch 30.185), train_loss = 1.27700972, grad/param norm = 1.7385e-01, time/batch = 0.6938s	
18293/30300 (epoch 30.186), train_loss = 1.30859257, grad/param norm = 1.9977e-01, time/batch = 0.6871s	
18294/30300 (epoch 30.188), train_loss = 1.14684959, grad/param norm = 1.6716e-01, time/batch = 0.6897s	
18295/30300 (epoch 30.190), train_loss = 1.12800408, grad/param norm = 1.6329e-01, time/batch = 0.7095s	
18296/30300 (epoch 30.191), train_loss = 1.16072594, grad/param norm = 1.6828e-01, time/batch = 0.6936s	
18297/30300 (epoch 30.193), train_loss = 1.03094401, grad/param norm = 1.4477e-01, time/batch = 0.7148s	
18298/30300 (epoch 30.195), train_loss = 1.08747576, grad/param norm = 1.6125e-01, time/batch = 0.7025s	
18299/30300 (epoch 30.196), train_loss = 1.13362183, grad/param norm = 1.4276e-01, time/batch = 0.6978s	
18300/30300 (epoch 30.198), train_loss = 0.95950348, grad/param norm = 1.6824e-01, time/batch = 0.6942s	
18301/30300 (epoch 30.200), train_loss = 1.10360055, grad/param norm = 1.5978e-01, time/batch = 0.6933s	
18302/30300 (epoch 30.201), train_loss = 1.17716028, grad/param norm = 1.8657e-01, time/batch = 0.6918s	
18303/30300 (epoch 30.203), train_loss = 1.10663867, grad/param norm = 1.7656e-01, time/batch = 0.6945s	
18304/30300 (epoch 30.205), train_loss = 1.32891744, grad/param norm = 1.9666e-01, time/batch = 0.7091s	
18305/30300 (epoch 30.206), train_loss = 1.23126018, grad/param norm = 2.2859e-01, time/batch = 0.7178s	
18306/30300 (epoch 30.208), train_loss = 1.17501006, grad/param norm = 2.3230e-01, time/batch = 0.7205s	
18307/30300 (epoch 30.210), train_loss = 1.17460957, grad/param norm = 1.7349e-01, time/batch = 0.7170s	
18308/30300 (epoch 30.211), train_loss = 1.23985484, grad/param norm = 1.6911e-01, time/batch = 0.7070s	
18309/30300 (epoch 30.213), train_loss = 1.09222698, grad/param norm = 1.4241e-01, time/batch = 0.6957s	
18310/30300 (epoch 30.215), train_loss = 1.04360902, grad/param norm = 1.6702e-01, time/batch = 0.6837s	
18311/30300 (epoch 30.216), train_loss = 1.07299184, grad/param norm = 1.7383e-01, time/batch = 0.6900s	
18312/30300 (epoch 30.218), train_loss = 1.01542602, grad/param norm = 1.4868e-01, time/batch = 0.6903s	
18313/30300 (epoch 30.219), train_loss = 0.98100007, grad/param norm = 1.5339e-01, time/batch = 0.7000s	
18314/30300 (epoch 30.221), train_loss = 0.95627564, grad/param norm = 1.5561e-01, time/batch = 0.6902s	
18315/30300 (epoch 30.223), train_loss = 1.13691363, grad/param norm = 1.7679e-01, time/batch = 0.6809s	
18316/30300 (epoch 30.224), train_loss = 0.96260033, grad/param norm = 1.5990e-01, time/batch = 0.6810s	
18317/30300 (epoch 30.226), train_loss = 1.17496405, grad/param norm = 1.7779e-01, time/batch = 0.6836s	
18318/30300 (epoch 30.228), train_loss = 1.20774545, grad/param norm = 1.8400e-01, time/batch = 0.6838s	
18319/30300 (epoch 30.229), train_loss = 1.09770479, grad/param norm = 1.7013e-01, time/batch = 0.6812s	
18320/30300 (epoch 30.231), train_loss = 1.13373190, grad/param norm = 1.5767e-01, time/batch = 0.6825s	
18321/30300 (epoch 30.233), train_loss = 1.14726355, grad/param norm = 1.3940e-01, time/batch = 0.6864s	
18322/30300 (epoch 30.234), train_loss = 1.18116492, grad/param norm = 1.7818e-01, time/batch = 0.6798s	
18323/30300 (epoch 30.236), train_loss = 1.14791682, grad/param norm = 1.5780e-01, time/batch = 0.6828s	
18324/30300 (epoch 30.238), train_loss = 1.13143384, grad/param norm = 1.8381e-01, time/batch = 0.6861s	
18325/30300 (epoch 30.239), train_loss = 1.12346170, grad/param norm = 1.8928e-01, time/batch = 0.6869s	
18326/30300 (epoch 30.241), train_loss = 1.16121323, grad/param norm = 1.7721e-01, time/batch = 0.6807s	
18327/30300 (epoch 30.243), train_loss = 1.15874784, grad/param norm = 1.5386e-01, time/batch = 0.6815s	
18328/30300 (epoch 30.244), train_loss = 1.31897639, grad/param norm = 1.7181e-01, time/batch = 0.6845s	
18329/30300 (epoch 30.246), train_loss = 1.14375520, grad/param norm = 1.7128e-01, time/batch = 0.6853s	
18330/30300 (epoch 30.248), train_loss = 1.07850259, grad/param norm = 1.4560e-01, time/batch = 0.6878s	
18331/30300 (epoch 30.249), train_loss = 1.04392380, grad/param norm = 1.6528e-01, time/batch = 0.6972s	
18332/30300 (epoch 30.251), train_loss = 1.04918047, grad/param norm = 1.6135e-01, time/batch = 0.6844s	
18333/30300 (epoch 30.252), train_loss = 1.22521902, grad/param norm = 1.8196e-01, time/batch = 0.6902s	
18334/30300 (epoch 30.254), train_loss = 1.21737344, grad/param norm = 1.7226e-01, time/batch = 0.6837s	
18335/30300 (epoch 30.256), train_loss = 1.13133431, grad/param norm = 1.6440e-01, time/batch = 0.6856s	
18336/30300 (epoch 30.257), train_loss = 1.19315203, grad/param norm = 1.6405e-01, time/batch = 0.6823s	
18337/30300 (epoch 30.259), train_loss = 1.10557375, grad/param norm = 1.7140e-01, time/batch = 0.6822s	
18338/30300 (epoch 30.261), train_loss = 1.23481034, grad/param norm = 1.7166e-01, time/batch = 0.6896s	
18339/30300 (epoch 30.262), train_loss = 1.05257269, grad/param norm = 1.5715e-01, time/batch = 0.6865s	
18340/30300 (epoch 30.264), train_loss = 1.09858066, grad/param norm = 1.4889e-01, time/batch = 0.6853s	
18341/30300 (epoch 30.266), train_loss = 1.05829053, grad/param norm = 1.4245e-01, time/batch = 0.6863s	
18342/30300 (epoch 30.267), train_loss = 1.29325153, grad/param norm = 1.8705e-01, time/batch = 0.6842s	
18343/30300 (epoch 30.269), train_loss = 1.12165894, grad/param norm = 1.5245e-01, time/batch = 0.6893s	
18344/30300 (epoch 30.271), train_loss = 1.15540898, grad/param norm = 1.6277e-01, time/batch = 0.6875s	
18345/30300 (epoch 30.272), train_loss = 1.12447786, grad/param norm = 1.9287e-01, time/batch = 0.6860s	
18346/30300 (epoch 30.274), train_loss = 1.17536834, grad/param norm = 1.7632e-01, time/batch = 0.6858s	
18347/30300 (epoch 30.276), train_loss = 1.14650774, grad/param norm = 1.7504e-01, time/batch = 0.6919s	
18348/30300 (epoch 30.277), train_loss = 0.99335561, grad/param norm = 1.4973e-01, time/batch = 0.6851s	
18349/30300 (epoch 30.279), train_loss = 1.13690172, grad/param norm = 1.9586e-01, time/batch = 0.6874s	
18350/30300 (epoch 30.281), train_loss = 1.22476129, grad/param norm = 1.9255e-01, time/batch = 0.6940s	
18351/30300 (epoch 30.282), train_loss = 1.14737357, grad/param norm = 1.5042e-01, time/batch = 0.7277s	
18352/30300 (epoch 30.284), train_loss = 1.20765047, grad/param norm = 2.2921e-01, time/batch = 0.6864s	
18353/30300 (epoch 30.285), train_loss = 1.17176541, grad/param norm = 1.6147e-01, time/batch = 0.6827s	
18354/30300 (epoch 30.287), train_loss = 1.10095719, grad/param norm = 1.5489e-01, time/batch = 0.6854s	
18355/30300 (epoch 30.289), train_loss = 1.20584214, grad/param norm = 1.6212e-01, time/batch = 0.6855s	
18356/30300 (epoch 30.290), train_loss = 0.88314636, grad/param norm = 1.4031e-01, time/batch = 0.6849s	
18357/30300 (epoch 30.292), train_loss = 1.01523092, grad/param norm = 1.5560e-01, time/batch = 0.6812s	
18358/30300 (epoch 30.294), train_loss = 1.20541853, grad/param norm = 2.3818e-01, time/batch = 0.6844s	
18359/30300 (epoch 30.295), train_loss = 1.07659422, grad/param norm = 1.6630e-01, time/batch = 0.6855s	
18360/30300 (epoch 30.297), train_loss = 1.07112598, grad/param norm = 1.5750e-01, time/batch = 0.6804s	
18361/30300 (epoch 30.299), train_loss = 1.10121471, grad/param norm = 1.5370e-01, time/batch = 0.6886s	
18362/30300 (epoch 30.300), train_loss = 1.04886650, grad/param norm = 1.6045e-01, time/batch = 0.6864s	
18363/30300 (epoch 30.302), train_loss = 1.16657688, grad/param norm = 1.6674e-01, time/batch = 0.6856s	
18364/30300 (epoch 30.304), train_loss = 1.04248767, grad/param norm = 1.5158e-01, time/batch = 0.6851s	
18365/30300 (epoch 30.305), train_loss = 1.09537589, grad/param norm = 1.4977e-01, time/batch = 0.6856s	
18366/30300 (epoch 30.307), train_loss = 1.17648101, grad/param norm = 1.4243e-01, time/batch = 0.6865s	
18367/30300 (epoch 30.309), train_loss = 1.16551878, grad/param norm = 1.6823e-01, time/batch = 0.6874s	
18368/30300 (epoch 30.310), train_loss = 1.10882334, grad/param norm = 1.4961e-01, time/batch = 0.6907s	
18369/30300 (epoch 30.312), train_loss = 1.25438405, grad/param norm = 1.6186e-01, time/batch = 0.7065s	
18370/30300 (epoch 30.314), train_loss = 1.13678783, grad/param norm = 1.8421e-01, time/batch = 0.7220s	
18371/30300 (epoch 30.315), train_loss = 1.08254323, grad/param norm = 1.5772e-01, time/batch = 0.6870s	
18372/30300 (epoch 30.317), train_loss = 1.14243274, grad/param norm = 1.5963e-01, time/batch = 0.6864s	
18373/30300 (epoch 30.318), train_loss = 1.18960875, grad/param norm = 1.6206e-01, time/batch = 0.6801s	
18374/30300 (epoch 30.320), train_loss = 1.17566674, grad/param norm = 1.6739e-01, time/batch = 0.6807s	
18375/30300 (epoch 30.322), train_loss = 1.06088642, grad/param norm = 1.7315e-01, time/batch = 0.6816s	
18376/30300 (epoch 30.323), train_loss = 1.23753758, grad/param norm = 1.8347e-01, time/batch = 0.6854s	
18377/30300 (epoch 30.325), train_loss = 1.10822045, grad/param norm = 1.6314e-01, time/batch = 0.6828s	
18378/30300 (epoch 30.327), train_loss = 1.11557358, grad/param norm = 1.5691e-01, time/batch = 0.6845s	
18379/30300 (epoch 30.328), train_loss = 1.13324916, grad/param norm = 1.5858e-01, time/batch = 0.6809s	
18380/30300 (epoch 30.330), train_loss = 1.16292009, grad/param norm = 1.7080e-01, time/batch = 0.6899s	
18381/30300 (epoch 30.332), train_loss = 1.19949184, grad/param norm = 1.7240e-01, time/batch = 0.6962s	
18382/30300 (epoch 30.333), train_loss = 1.07717470, grad/param norm = 1.8322e-01, time/batch = 0.7088s	
18383/30300 (epoch 30.335), train_loss = 0.99563643, grad/param norm = 1.5617e-01, time/batch = 0.6964s	
18384/30300 (epoch 30.337), train_loss = 1.25175957, grad/param norm = 1.6005e-01, time/batch = 0.7076s	
18385/30300 (epoch 30.338), train_loss = 1.06393809, grad/param norm = 1.4773e-01, time/batch = 0.6862s	
18386/30300 (epoch 30.340), train_loss = 1.06256361, grad/param norm = 1.5714e-01, time/batch = 0.6897s	
18387/30300 (epoch 30.342), train_loss = 1.20530830, grad/param norm = 1.6966e-01, time/batch = 0.6830s	
18388/30300 (epoch 30.343), train_loss = 1.14687023, grad/param norm = 1.7171e-01, time/batch = 0.7155s	
18389/30300 (epoch 30.345), train_loss = 1.17921044, grad/param norm = 1.6452e-01, time/batch = 0.6869s	
18390/30300 (epoch 30.347), train_loss = 1.00085851, grad/param norm = 1.9001e-01, time/batch = 0.6852s	
18391/30300 (epoch 30.348), train_loss = 1.06019672, grad/param norm = 1.6523e-01, time/batch = 0.7008s	
18392/30300 (epoch 30.350), train_loss = 1.08622341, grad/param norm = 1.6009e-01, time/batch = 0.6897s	
18393/30300 (epoch 30.351), train_loss = 1.09716225, grad/param norm = 1.6279e-01, time/batch = 0.6866s	
18394/30300 (epoch 30.353), train_loss = 0.99078417, grad/param norm = 1.5626e-01, time/batch = 0.6837s	
18395/30300 (epoch 30.355), train_loss = 1.07477680, grad/param norm = 1.5275e-01, time/batch = 0.6803s	
18396/30300 (epoch 30.356), train_loss = 1.17616849, grad/param norm = 1.8027e-01, time/batch = 0.6839s	
18397/30300 (epoch 30.358), train_loss = 1.34179174, grad/param norm = 1.5489e-01, time/batch = 0.6898s	
18398/30300 (epoch 30.360), train_loss = 1.05711779, grad/param norm = 1.5225e-01, time/batch = 0.6901s	
18399/30300 (epoch 30.361), train_loss = 1.11900352, grad/param norm = 1.6484e-01, time/batch = 0.6832s	
18400/30300 (epoch 30.363), train_loss = 1.17243024, grad/param norm = 1.6416e-01, time/batch = 0.6824s	
18401/30300 (epoch 30.365), train_loss = 0.98752889, grad/param norm = 1.6597e-01, time/batch = 0.6871s	
18402/30300 (epoch 30.366), train_loss = 1.08773208, grad/param norm = 1.5821e-01, time/batch = 0.6961s	
18403/30300 (epoch 30.368), train_loss = 0.97238536, grad/param norm = 1.4661e-01, time/batch = 0.6943s	
18404/30300 (epoch 30.370), train_loss = 1.05329551, grad/param norm = 1.7214e-01, time/batch = 0.6842s	
18405/30300 (epoch 30.371), train_loss = 1.18095293, grad/param norm = 1.4915e-01, time/batch = 0.6846s	
18406/30300 (epoch 30.373), train_loss = 1.05300688, grad/param norm = 1.4003e-01, time/batch = 0.6821s	
18407/30300 (epoch 30.375), train_loss = 1.04074615, grad/param norm = 1.4372e-01, time/batch = 0.7246s	
18408/30300 (epoch 30.376), train_loss = 1.03691122, grad/param norm = 1.5170e-01, time/batch = 0.7021s	
18409/30300 (epoch 30.378), train_loss = 1.01944939, grad/param norm = 1.6517e-01, time/batch = 0.6805s	
18410/30300 (epoch 30.380), train_loss = 1.25800031, grad/param norm = 2.0574e-01, time/batch = 0.6829s	
18411/30300 (epoch 30.381), train_loss = 0.95341628, grad/param norm = 1.5169e-01, time/batch = 0.6842s	
18412/30300 (epoch 30.383), train_loss = 1.04262970, grad/param norm = 1.7695e-01, time/batch = 0.6836s	
18413/30300 (epoch 30.384), train_loss = 1.17010285, grad/param norm = 1.7576e-01, time/batch = 0.6825s	
18414/30300 (epoch 30.386), train_loss = 0.99562290, grad/param norm = 1.4293e-01, time/batch = 0.6858s	
18415/30300 (epoch 30.388), train_loss = 0.97268777, grad/param norm = 1.5011e-01, time/batch = 0.6856s	
18416/30300 (epoch 30.389), train_loss = 1.08797597, grad/param norm = 1.6910e-01, time/batch = 0.6849s	
18417/30300 (epoch 30.391), train_loss = 1.14694244, grad/param norm = 1.4513e-01, time/batch = 0.6874s	
18418/30300 (epoch 30.393), train_loss = 0.97404386, grad/param norm = 1.6511e-01, time/batch = 0.6880s	
18419/30300 (epoch 30.394), train_loss = 1.16202642, grad/param norm = 1.7481e-01, time/batch = 0.6843s	
18420/30300 (epoch 30.396), train_loss = 1.22159960, grad/param norm = 1.5611e-01, time/batch = 0.6850s	
18421/30300 (epoch 30.398), train_loss = 1.07700073, grad/param norm = 1.5940e-01, time/batch = 0.6854s	
18422/30300 (epoch 30.399), train_loss = 1.06300381, grad/param norm = 1.5378e-01, time/batch = 0.6853s	
18423/30300 (epoch 30.401), train_loss = 1.15058891, grad/param norm = 5.6337e-01, time/batch = 0.6935s	
18424/30300 (epoch 30.403), train_loss = 1.13940363, grad/param norm = 1.9950e-01, time/batch = 0.6878s	
18425/30300 (epoch 30.404), train_loss = 1.05329525, grad/param norm = 1.9385e-01, time/batch = 0.6957s	
18426/30300 (epoch 30.406), train_loss = 1.13832012, grad/param norm = 1.6022e-01, time/batch = 0.7258s	
18427/30300 (epoch 30.408), train_loss = 0.98689264, grad/param norm = 1.5809e-01, time/batch = 0.6925s	
18428/30300 (epoch 30.409), train_loss = 0.99716874, grad/param norm = 1.9683e-01, time/batch = 0.6859s	
18429/30300 (epoch 30.411), train_loss = 1.03744058, grad/param norm = 1.5497e-01, time/batch = 0.6842s	
18430/30300 (epoch 30.413), train_loss = 0.92869720, grad/param norm = 1.6831e-01, time/batch = 0.6837s	
18431/30300 (epoch 30.414), train_loss = 1.17036456, grad/param norm = 1.6623e-01, time/batch = 0.6936s	
18432/30300 (epoch 30.416), train_loss = 1.05785099, grad/param norm = 1.6006e-01, time/batch = 0.6863s	
18433/30300 (epoch 30.417), train_loss = 1.01929570, grad/param norm = 1.9243e-01, time/batch = 0.6811s	
18434/30300 (epoch 30.419), train_loss = 1.01160667, grad/param norm = 1.5354e-01, time/batch = 0.6875s	
18435/30300 (epoch 30.421), train_loss = 1.04816314, grad/param norm = 1.7475e-01, time/batch = 0.6818s	
18436/30300 (epoch 30.422), train_loss = 1.10562349, grad/param norm = 1.5352e-01, time/batch = 0.6819s	
18437/30300 (epoch 30.424), train_loss = 1.11390192, grad/param norm = 1.6674e-01, time/batch = 0.6851s	
18438/30300 (epoch 30.426), train_loss = 1.06747659, grad/param norm = 2.2286e-01, time/batch = 0.6833s	
18439/30300 (epoch 30.427), train_loss = 1.04772878, grad/param norm = 1.7171e-01, time/batch = 0.6855s	
18440/30300 (epoch 30.429), train_loss = 1.08271303, grad/param norm = 1.4462e-01, time/batch = 0.6820s	
18441/30300 (epoch 30.431), train_loss = 1.15811855, grad/param norm = 1.6901e-01, time/batch = 0.6859s	
18442/30300 (epoch 30.432), train_loss = 1.07583964, grad/param norm = 1.6161e-01, time/batch = 0.6836s	
18443/30300 (epoch 30.434), train_loss = 0.99804428, grad/param norm = 1.8232e-01, time/batch = 0.6827s	
18444/30300 (epoch 30.436), train_loss = 1.24511475, grad/param norm = 1.7762e-01, time/batch = 0.6982s	
18445/30300 (epoch 30.437), train_loss = 0.99077060, grad/param norm = 1.5156e-01, time/batch = 0.7258s	
18446/30300 (epoch 30.439), train_loss = 1.04749836, grad/param norm = 1.4793e-01, time/batch = 0.6866s	
18447/30300 (epoch 30.441), train_loss = 1.08076198, grad/param norm = 1.5151e-01, time/batch = 0.6828s	
18448/30300 (epoch 30.442), train_loss = 1.02376610, grad/param norm = 1.6437e-01, time/batch = 0.6860s	
18449/30300 (epoch 30.444), train_loss = 0.92394267, grad/param norm = 1.5690e-01, time/batch = 0.6856s	
18450/30300 (epoch 30.446), train_loss = 1.06748789, grad/param norm = 1.4795e-01, time/batch = 0.6806s	
18451/30300 (epoch 30.447), train_loss = 1.08690946, grad/param norm = 1.4986e-01, time/batch = 0.6827s	
18452/30300 (epoch 30.449), train_loss = 1.02744915, grad/param norm = 1.5274e-01, time/batch = 0.6860s	
18453/30300 (epoch 30.450), train_loss = 1.15120995, grad/param norm = 1.5298e-01, time/batch = 0.6881s	
18454/30300 (epoch 30.452), train_loss = 1.22300362, grad/param norm = 1.6800e-01, time/batch = 0.7025s	
18455/30300 (epoch 30.454), train_loss = 1.14882302, grad/param norm = 1.4976e-01, time/batch = 0.6965s	
18456/30300 (epoch 30.455), train_loss = 1.09809080, grad/param norm = 1.6987e-01, time/batch = 0.7026s	
18457/30300 (epoch 30.457), train_loss = 1.07965380, grad/param norm = 1.7350e-01, time/batch = 0.7108s	
18458/30300 (epoch 30.459), train_loss = 1.16308698, grad/param norm = 1.8749e-01, time/batch = 0.7134s	
18459/30300 (epoch 30.460), train_loss = 1.14065893, grad/param norm = 1.5627e-01, time/batch = 0.7274s	
18460/30300 (epoch 30.462), train_loss = 1.16610727, grad/param norm = 1.6679e-01, time/batch = 0.6963s	
18461/30300 (epoch 30.464), train_loss = 0.93718180, grad/param norm = 1.8558e-01, time/batch = 0.6839s	
18462/30300 (epoch 30.465), train_loss = 0.92370411, grad/param norm = 1.3974e-01, time/batch = 0.6806s	
18463/30300 (epoch 30.467), train_loss = 0.91769965, grad/param norm = 1.4107e-01, time/batch = 0.6874s	
18464/30300 (epoch 30.469), train_loss = 1.01598862, grad/param norm = 1.7473e-01, time/batch = 0.6841s	
18465/30300 (epoch 30.470), train_loss = 1.05661094, grad/param norm = 1.6721e-01, time/batch = 0.6852s	
18466/30300 (epoch 30.472), train_loss = 1.03704237, grad/param norm = 1.4012e-01, time/batch = 0.6833s	
18467/30300 (epoch 30.474), train_loss = 1.04957874, grad/param norm = 1.9928e-01, time/batch = 0.6858s	
18468/30300 (epoch 30.475), train_loss = 1.03277856, grad/param norm = 1.4757e-01, time/batch = 0.6950s	
18469/30300 (epoch 30.477), train_loss = 1.08858808, grad/param norm = 1.5541e-01, time/batch = 0.6913s	
18470/30300 (epoch 30.479), train_loss = 1.07461311, grad/param norm = 1.7115e-01, time/batch = 0.6963s	
18471/30300 (epoch 30.480), train_loss = 1.11241917, grad/param norm = 1.4879e-01, time/batch = 0.7000s	
18472/30300 (epoch 30.482), train_loss = 1.14220661, grad/param norm = 1.4636e-01, time/batch = 0.6888s	
18473/30300 (epoch 30.483), train_loss = 1.06166265, grad/param norm = 1.5669e-01, time/batch = 0.6852s	
18474/30300 (epoch 30.485), train_loss = 1.10013065, grad/param norm = 1.4390e-01, time/batch = 0.6850s	
18475/30300 (epoch 30.487), train_loss = 1.18774291, grad/param norm = 1.7118e-01, time/batch = 0.6888s	
18476/30300 (epoch 30.488), train_loss = 1.19768519, grad/param norm = 1.4240e-01, time/batch = 0.7000s	
18477/30300 (epoch 30.490), train_loss = 0.98376826, grad/param norm = 1.5528e-01, time/batch = 0.7028s	
18478/30300 (epoch 30.492), train_loss = 1.07462180, grad/param norm = 2.0153e-01, time/batch = 0.7285s	
18479/30300 (epoch 30.493), train_loss = 1.08812156, grad/param norm = 1.8131e-01, time/batch = 0.6968s	
18480/30300 (epoch 30.495), train_loss = 1.04476296, grad/param norm = 1.4194e-01, time/batch = 0.6935s	
18481/30300 (epoch 30.497), train_loss = 1.09588643, grad/param norm = 1.5478e-01, time/batch = 0.6968s	
18482/30300 (epoch 30.498), train_loss = 1.14481855, grad/param norm = 1.6323e-01, time/batch = 0.6991s	
18483/30300 (epoch 30.500), train_loss = 1.08588099, grad/param norm = 1.7210e-01, time/batch = 0.6931s	
18484/30300 (epoch 30.502), train_loss = 1.08201171, grad/param norm = 1.6653e-01, time/batch = 0.6919s	
18485/30300 (epoch 30.503), train_loss = 1.18870695, grad/param norm = 1.5755e-01, time/batch = 0.6992s	
18486/30300 (epoch 30.505), train_loss = 0.99328693, grad/param norm = 1.3638e-01, time/batch = 0.6926s	
18487/30300 (epoch 30.507), train_loss = 1.01959654, grad/param norm = 1.9920e-01, time/batch = 0.6905s	
18488/30300 (epoch 30.508), train_loss = 1.04060151, grad/param norm = 1.6800e-01, time/batch = 0.6954s	
18489/30300 (epoch 30.510), train_loss = 1.17325059, grad/param norm = 2.1106e-01, time/batch = 0.6823s	
18490/30300 (epoch 30.512), train_loss = 1.02384797, grad/param norm = 1.4709e-01, time/batch = 0.6840s	
18491/30300 (epoch 30.513), train_loss = 1.09273683, grad/param norm = 1.5488e-01, time/batch = 0.6927s	
18492/30300 (epoch 30.515), train_loss = 1.10060590, grad/param norm = 1.6876e-01, time/batch = 0.7277s	
18493/30300 (epoch 30.517), train_loss = 0.90432925, grad/param norm = 1.3722e-01, time/batch = 0.6960s	
18494/30300 (epoch 30.518), train_loss = 1.17445376, grad/param norm = 1.8354e-01, time/batch = 0.6876s	
18495/30300 (epoch 30.520), train_loss = 1.12552778, grad/param norm = 1.7522e-01, time/batch = 0.6818s	
18496/30300 (epoch 30.521), train_loss = 1.01133897, grad/param norm = 1.8927e-01, time/batch = 0.6825s	
18497/30300 (epoch 30.523), train_loss = 1.24333367, grad/param norm = 1.8775e-01, time/batch = 0.6832s	
18498/30300 (epoch 30.525), train_loss = 1.03554680, grad/param norm = 1.5745e-01, time/batch = 0.6821s	
18499/30300 (epoch 30.526), train_loss = 1.09046904, grad/param norm = 1.5958e-01, time/batch = 0.6825s	
18500/30300 (epoch 30.528), train_loss = 0.98705316, grad/param norm = 1.5704e-01, time/batch = 0.6816s	
18501/30300 (epoch 30.530), train_loss = 0.96704066, grad/param norm = 1.5467e-01, time/batch = 0.6853s	
18502/30300 (epoch 30.531), train_loss = 1.13193476, grad/param norm = 1.6494e-01, time/batch = 0.6817s	
18503/30300 (epoch 30.533), train_loss = 1.08604006, grad/param norm = 2.0496e-01, time/batch = 0.6876s	
18504/30300 (epoch 30.535), train_loss = 1.04106428, grad/param norm = 1.4492e-01, time/batch = 0.6834s	
18505/30300 (epoch 30.536), train_loss = 1.14212554, grad/param norm = 1.8863e-01, time/batch = 0.6839s	
18506/30300 (epoch 30.538), train_loss = 0.98567138, grad/param norm = 1.8662e-01, time/batch = 0.6863s	
18507/30300 (epoch 30.540), train_loss = 1.02016123, grad/param norm = 1.7048e-01, time/batch = 0.6824s	
18508/30300 (epoch 30.541), train_loss = 1.10275806, grad/param norm = 1.8373e-01, time/batch = 0.6829s	
18509/30300 (epoch 30.543), train_loss = 1.07319924, grad/param norm = 1.5874e-01, time/batch = 0.6830s	
18510/30300 (epoch 30.545), train_loss = 1.13869137, grad/param norm = 1.9966e-01, time/batch = 0.6896s	
18511/30300 (epoch 30.546), train_loss = 1.29311115, grad/param norm = 1.6463e-01, time/batch = 0.7410s	
18512/30300 (epoch 30.548), train_loss = 1.03417865, grad/param norm = 1.4733e-01, time/batch = 0.7016s	
18513/30300 (epoch 30.550), train_loss = 1.13759642, grad/param norm = 1.9727e-01, time/batch = 0.6857s	
18514/30300 (epoch 30.551), train_loss = 1.05062693, grad/param norm = 1.6884e-01, time/batch = 0.6844s	
18515/30300 (epoch 30.553), train_loss = 1.04069550, grad/param norm = 1.5468e-01, time/batch = 0.6808s	
18516/30300 (epoch 30.554), train_loss = 1.08919421, grad/param norm = 1.6696e-01, time/batch = 0.6824s	
18517/30300 (epoch 30.556), train_loss = 1.14798544, grad/param norm = 1.5895e-01, time/batch = 0.6815s	
18518/30300 (epoch 30.558), train_loss = 1.17168887, grad/param norm = 1.8139e-01, time/batch = 0.6823s	
18519/30300 (epoch 30.559), train_loss = 1.09806180, grad/param norm = 1.6861e-01, time/batch = 0.6817s	
18520/30300 (epoch 30.561), train_loss = 0.90723703, grad/param norm = 1.6690e-01, time/batch = 0.6819s	
18521/30300 (epoch 30.563), train_loss = 0.98618002, grad/param norm = 1.5718e-01, time/batch = 0.6888s	
18522/30300 (epoch 30.564), train_loss = 1.03023023, grad/param norm = 1.4378e-01, time/batch = 0.6841s	
18523/30300 (epoch 30.566), train_loss = 1.07044074, grad/param norm = 1.6068e-01, time/batch = 0.6820s	
18524/30300 (epoch 30.568), train_loss = 0.93108947, grad/param norm = 1.5761e-01, time/batch = 0.6827s	
18525/30300 (epoch 30.569), train_loss = 1.09684304, grad/param norm = 1.5322e-01, time/batch = 0.6842s	
18526/30300 (epoch 30.571), train_loss = 1.10020288, grad/param norm = 1.6994e-01, time/batch = 0.6830s	
18527/30300 (epoch 30.573), train_loss = 1.12821137, grad/param norm = 1.5519e-01, time/batch = 0.6868s	
18528/30300 (epoch 30.574), train_loss = 1.13522225, grad/param norm = 1.4837e-01, time/batch = 0.6920s	
18529/30300 (epoch 30.576), train_loss = 1.04767166, grad/param norm = 1.4488e-01, time/batch = 0.7072s	
18530/30300 (epoch 30.578), train_loss = 0.95316213, grad/param norm = 1.5653e-01, time/batch = 0.7247s	
18531/30300 (epoch 30.579), train_loss = 1.11710181, grad/param norm = 1.9140e-01, time/batch = 0.6848s	
18532/30300 (epoch 30.581), train_loss = 1.20164478, grad/param norm = 1.7055e-01, time/batch = 0.6846s	
18533/30300 (epoch 30.583), train_loss = 1.25161107, grad/param norm = 2.5711e-01, time/batch = 0.7077s	
18534/30300 (epoch 30.584), train_loss = 1.19618054, grad/param norm = 1.6020e-01, time/batch = 0.6920s	
18535/30300 (epoch 30.586), train_loss = 1.06620939, grad/param norm = 1.7181e-01, time/batch = 0.6992s	
18536/30300 (epoch 30.587), train_loss = 1.06454453, grad/param norm = 1.5450e-01, time/batch = 0.6871s	
18537/30300 (epoch 30.589), train_loss = 1.00920741, grad/param norm = 1.6169e-01, time/batch = 0.6959s	
18538/30300 (epoch 30.591), train_loss = 1.11706304, grad/param norm = 1.4627e-01, time/batch = 0.6874s	
18539/30300 (epoch 30.592), train_loss = 1.05764866, grad/param norm = 1.4086e-01, time/batch = 0.6922s	
18540/30300 (epoch 30.594), train_loss = 1.10890032, grad/param norm = 1.6836e-01, time/batch = 0.6961s	
18541/30300 (epoch 30.596), train_loss = 0.99183596, grad/param norm = 1.4501e-01, time/batch = 0.7158s	
18542/30300 (epoch 30.597), train_loss = 1.02415161, grad/param norm = 1.6023e-01, time/batch = 0.7216s	
18543/30300 (epoch 30.599), train_loss = 0.90679750, grad/param norm = 1.4213e-01, time/batch = 0.7230s	
18544/30300 (epoch 30.601), train_loss = 1.11328953, grad/param norm = 1.5451e-01, time/batch = 0.7301s	
18545/30300 (epoch 30.602), train_loss = 1.06536332, grad/param norm = 1.4664e-01, time/batch = 0.7047s	
18546/30300 (epoch 30.604), train_loss = 1.01890286, grad/param norm = 1.5231e-01, time/batch = 0.6887s	
18547/30300 (epoch 30.606), train_loss = 1.01832440, grad/param norm = 1.8773e-01, time/batch = 0.6854s	
18548/30300 (epoch 30.607), train_loss = 1.17231316, grad/param norm = 2.5797e-01, time/batch = 0.6807s	
18549/30300 (epoch 30.609), train_loss = 1.28966876, grad/param norm = 1.8236e-01, time/batch = 0.6813s	
18550/30300 (epoch 30.611), train_loss = 1.04064669, grad/param norm = 1.5140e-01, time/batch = 0.6840s	
18551/30300 (epoch 30.612), train_loss = 1.00131039, grad/param norm = 1.6181e-01, time/batch = 0.6825s	
18552/30300 (epoch 30.614), train_loss = 1.05782114, grad/param norm = 1.6026e-01, time/batch = 0.6812s	
18553/30300 (epoch 30.616), train_loss = 1.11660294, grad/param norm = 2.2424e-01, time/batch = 0.6952s	
18554/30300 (epoch 30.617), train_loss = 1.10448546, grad/param norm = 1.6962e-01, time/batch = 0.7083s	
18555/30300 (epoch 30.619), train_loss = 0.90549533, grad/param norm = 1.5047e-01, time/batch = 0.7026s	
18556/30300 (epoch 30.620), train_loss = 1.13195182, grad/param norm = 1.5777e-01, time/batch = 0.7092s	
18557/30300 (epoch 30.622), train_loss = 1.10339372, grad/param norm = 1.8758e-01, time/batch = 0.7088s	
18558/30300 (epoch 30.624), train_loss = 1.05699460, grad/param norm = 1.5999e-01, time/batch = 0.6869s	
18559/30300 (epoch 30.625), train_loss = 1.05199738, grad/param norm = 1.9004e-01, time/batch = 0.6845s	
18560/30300 (epoch 30.627), train_loss = 1.20290445, grad/param norm = 1.7227e-01, time/batch = 0.6912s	
18561/30300 (epoch 30.629), train_loss = 1.21831908, grad/param norm = 1.5861e-01, time/batch = 0.7006s	
18562/30300 (epoch 30.630), train_loss = 1.10407655, grad/param norm = 1.6568e-01, time/batch = 0.7117s	
18563/30300 (epoch 30.632), train_loss = 1.14235717, grad/param norm = 1.7234e-01, time/batch = 0.7153s	
18564/30300 (epoch 30.634), train_loss = 1.02411880, grad/param norm = 1.4422e-01, time/batch = 0.6816s	
18565/30300 (epoch 30.635), train_loss = 1.14964313, grad/param norm = 1.9908e-01, time/batch = 0.6796s	
18566/30300 (epoch 30.637), train_loss = 1.16819410, grad/param norm = 2.0308e-01, time/batch = 0.6816s	
18567/30300 (epoch 30.639), train_loss = 1.05579012, grad/param norm = 1.5668e-01, time/batch = 0.6801s	
18568/30300 (epoch 30.640), train_loss = 1.18682344, grad/param norm = 1.8863e-01, time/batch = 0.6814s	
18569/30300 (epoch 30.642), train_loss = 1.05735930, grad/param norm = 1.4403e-01, time/batch = 0.6832s	
18570/30300 (epoch 30.644), train_loss = 1.16018739, grad/param norm = 1.7407e-01, time/batch = 0.6913s	
18571/30300 (epoch 30.645), train_loss = 1.03680736, grad/param norm = 1.5342e-01, time/batch = 0.7032s	
18572/30300 (epoch 30.647), train_loss = 1.10192857, grad/param norm = 1.4702e-01, time/batch = 0.6848s	
18573/30300 (epoch 30.649), train_loss = 1.07173868, grad/param norm = 1.6120e-01, time/batch = 0.6871s	
18574/30300 (epoch 30.650), train_loss = 1.08231727, grad/param norm = 1.6339e-01, time/batch = 0.6862s	
18575/30300 (epoch 30.652), train_loss = 1.06549910, grad/param norm = 1.6702e-01, time/batch = 0.6837s	
18576/30300 (epoch 30.653), train_loss = 1.26103543, grad/param norm = 1.7007e-01, time/batch = 0.6837s	
18577/30300 (epoch 30.655), train_loss = 1.03483488, grad/param norm = 1.5526e-01, time/batch = 0.6840s	
18578/30300 (epoch 30.657), train_loss = 1.02740679, grad/param norm = 1.6524e-01, time/batch = 0.6835s	
18579/30300 (epoch 30.658), train_loss = 1.01969794, grad/param norm = 1.5515e-01, time/batch = 0.6867s	
18580/30300 (epoch 30.660), train_loss = 1.09542706, grad/param norm = 1.7846e-01, time/batch = 0.6853s	
18581/30300 (epoch 30.662), train_loss = 1.09743617, grad/param norm = 1.7790e-01, time/batch = 0.7217s	
18582/30300 (epoch 30.663), train_loss = 1.12817750, grad/param norm = 1.6132e-01, time/batch = 0.7103s	
18583/30300 (epoch 30.665), train_loss = 1.03410319, grad/param norm = 1.6843e-01, time/batch = 0.6919s	
18584/30300 (epoch 30.667), train_loss = 1.14225212, grad/param norm = 1.5933e-01, time/batch = 0.6861s	
18585/30300 (epoch 30.668), train_loss = 1.18966392, grad/param norm = 1.8100e-01, time/batch = 0.6813s	
18586/30300 (epoch 30.670), train_loss = 1.21612874, grad/param norm = 1.7970e-01, time/batch = 0.6810s	
18587/30300 (epoch 30.672), train_loss = 1.09724892, grad/param norm = 1.7380e-01, time/batch = 0.6815s	
18588/30300 (epoch 30.673), train_loss = 1.13679410, grad/param norm = 1.6216e-01, time/batch = 0.6836s	
18589/30300 (epoch 30.675), train_loss = 1.04766834, grad/param norm = 1.6096e-01, time/batch = 0.6804s	
18590/30300 (epoch 30.677), train_loss = 1.04437945, grad/param norm = 1.5001e-01, time/batch = 0.6884s	
18591/30300 (epoch 30.678), train_loss = 1.03438912, grad/param norm = 1.5445e-01, time/batch = 0.6835s	
18592/30300 (epoch 30.680), train_loss = 0.92584491, grad/param norm = 1.3832e-01, time/batch = 0.6820s	
18593/30300 (epoch 30.682), train_loss = 1.05894127, grad/param norm = 1.5264e-01, time/batch = 0.6867s	
18594/30300 (epoch 30.683), train_loss = 1.18902670, grad/param norm = 1.5496e-01, time/batch = 0.6830s	
18595/30300 (epoch 30.685), train_loss = 1.17083851, grad/param norm = 1.9284e-01, time/batch = 0.6845s	
18596/30300 (epoch 30.686), train_loss = 1.04717143, grad/param norm = 1.4119e-01, time/batch = 0.6851s	
18597/30300 (epoch 30.688), train_loss = 1.08637854, grad/param norm = 1.4991e-01, time/batch = 0.6838s	
18598/30300 (epoch 30.690), train_loss = 1.03755191, grad/param norm = 1.6717e-01, time/batch = 0.6860s	
18599/30300 (epoch 30.691), train_loss = 1.12518789, grad/param norm = 1.7231e-01, time/batch = 0.7027s	
18600/30300 (epoch 30.693), train_loss = 1.37603471, grad/param norm = 1.9482e-01, time/batch = 0.6917s	
18601/30300 (epoch 30.695), train_loss = 1.17007990, grad/param norm = 1.7020e-01, time/batch = 0.6867s	
18602/30300 (epoch 30.696), train_loss = 1.16375797, grad/param norm = 1.8950e-01, time/batch = 0.6815s	
18603/30300 (epoch 30.698), train_loss = 1.02799568, grad/param norm = 1.5373e-01, time/batch = 0.6832s	
18604/30300 (epoch 30.700), train_loss = 1.01438287, grad/param norm = 1.5761e-01, time/batch = 0.6874s	
18605/30300 (epoch 30.701), train_loss = 0.93933062, grad/param norm = 1.5479e-01, time/batch = 0.6834s	
18606/30300 (epoch 30.703), train_loss = 1.09257808, grad/param norm = 1.4614e-01, time/batch = 0.6815s	
18607/30300 (epoch 30.705), train_loss = 1.03381134, grad/param norm = 1.5939e-01, time/batch = 0.6817s	
18608/30300 (epoch 30.706), train_loss = 1.14523078, grad/param norm = 1.7165e-01, time/batch = 0.6945s	
18609/30300 (epoch 30.708), train_loss = 1.09225921, grad/param norm = 1.6241e-01, time/batch = 0.6865s	
18610/30300 (epoch 30.710), train_loss = 1.05606101, grad/param norm = 1.5672e-01, time/batch = 0.6814s	
18611/30300 (epoch 30.711), train_loss = 1.01617234, grad/param norm = 1.4982e-01, time/batch = 0.6811s	
18612/30300 (epoch 30.713), train_loss = 1.01102938, grad/param norm = 1.8354e-01, time/batch = 0.6829s	
18613/30300 (epoch 30.715), train_loss = 1.04337689, grad/param norm = 1.6164e-01, time/batch = 0.6864s	
18614/30300 (epoch 30.716), train_loss = 1.16498801, grad/param norm = 1.5445e-01, time/batch = 0.6894s	
18615/30300 (epoch 30.718), train_loss = 1.18741398, grad/param norm = 1.6646e-01, time/batch = 0.6862s	
18616/30300 (epoch 30.719), train_loss = 1.04077869, grad/param norm = 1.9020e-01, time/batch = 0.6860s	
18617/30300 (epoch 30.721), train_loss = 1.06168176, grad/param norm = 1.5571e-01, time/batch = 0.6825s	
18618/30300 (epoch 30.723), train_loss = 1.02526539, grad/param norm = 1.5899e-01, time/batch = 0.6887s	
18619/30300 (epoch 30.724), train_loss = 1.12114537, grad/param norm = 1.8972e-01, time/batch = 0.7125s	
18620/30300 (epoch 30.726), train_loss = 1.40168026, grad/param norm = 1.8984e-01, time/batch = 0.6802s	
18621/30300 (epoch 30.728), train_loss = 1.13684368, grad/param norm = 1.6842e-01, time/batch = 0.6841s	
18622/30300 (epoch 30.729), train_loss = 1.05035612, grad/param norm = 1.7878e-01, time/batch = 0.6852s	
18623/30300 (epoch 30.731), train_loss = 1.08717157, grad/param norm = 1.7872e-01, time/batch = 0.6826s	
18624/30300 (epoch 30.733), train_loss = 1.08971335, grad/param norm = 1.6131e-01, time/batch = 0.6841s	
18625/30300 (epoch 30.734), train_loss = 1.18011049, grad/param norm = 1.6141e-01, time/batch = 0.6831s	
18626/30300 (epoch 30.736), train_loss = 1.08875962, grad/param norm = 1.6190e-01, time/batch = 0.6842s	
18627/30300 (epoch 30.738), train_loss = 1.02460958, grad/param norm = 1.3867e-01, time/batch = 0.6899s	
18628/30300 (epoch 30.739), train_loss = 1.17718482, grad/param norm = 1.6424e-01, time/batch = 0.6874s	
18629/30300 (epoch 30.741), train_loss = 1.23749664, grad/param norm = 1.5640e-01, time/batch = 0.6889s	
18630/30300 (epoch 30.743), train_loss = 1.07505656, grad/param norm = 1.6734e-01, time/batch = 0.6906s	
18631/30300 (epoch 30.744), train_loss = 1.11136350, grad/param norm = 1.5458e-01, time/batch = 0.6849s	
18632/30300 (epoch 30.746), train_loss = 1.03419024, grad/param norm = 1.4365e-01, time/batch = 0.6861s	
18633/30300 (epoch 30.748), train_loss = 1.06721153, grad/param norm = 1.7588e-01, time/batch = 0.6865s	
18634/30300 (epoch 30.749), train_loss = 1.11896443, grad/param norm = 1.6545e-01, time/batch = 0.6846s	
18635/30300 (epoch 30.751), train_loss = 1.09881599, grad/param norm = 1.6779e-01, time/batch = 0.6804s	
18636/30300 (epoch 30.752), train_loss = 1.06524254, grad/param norm = 1.7173e-01, time/batch = 0.6917s	
18637/30300 (epoch 30.754), train_loss = 1.03863289, grad/param norm = 1.5336e-01, time/batch = 0.7041s	
18638/30300 (epoch 30.756), train_loss = 1.05216477, grad/param norm = 1.5044e-01, time/batch = 0.7265s	
18639/30300 (epoch 30.757), train_loss = 1.06811338, grad/param norm = 1.6481e-01, time/batch = 0.6899s	
18640/30300 (epoch 30.759), train_loss = 1.12968199, grad/param norm = 1.6005e-01, time/batch = 0.6924s	
18641/30300 (epoch 30.761), train_loss = 0.94831211, grad/param norm = 1.4820e-01, time/batch = 0.7170s	
18642/30300 (epoch 30.762), train_loss = 0.98262540, grad/param norm = 1.5138e-01, time/batch = 0.7007s	
18643/30300 (epoch 30.764), train_loss = 1.06832136, grad/param norm = 1.5306e-01, time/batch = 0.7388s	
18644/30300 (epoch 30.766), train_loss = 1.18009360, grad/param norm = 1.6112e-01, time/batch = 0.7305s	
18645/30300 (epoch 30.767), train_loss = 1.14623555, grad/param norm = 1.8267e-01, time/batch = 0.7154s	
18646/30300 (epoch 30.769), train_loss = 1.11051040, grad/param norm = 1.8178e-01, time/batch = 0.7084s	
18647/30300 (epoch 30.771), train_loss = 1.05537496, grad/param norm = 1.7889e-01, time/batch = 0.7102s	
18648/30300 (epoch 30.772), train_loss = 1.12643599, grad/param norm = 1.6819e-01, time/batch = 0.6854s	
18649/30300 (epoch 30.774), train_loss = 1.22062946, grad/param norm = 1.7279e-01, time/batch = 0.6820s	
18650/30300 (epoch 30.776), train_loss = 1.07738104, grad/param norm = 1.6942e-01, time/batch = 0.6855s	
18651/30300 (epoch 30.777), train_loss = 1.20313319, grad/param norm = 1.5752e-01, time/batch = 0.7049s	
18652/30300 (epoch 30.779), train_loss = 1.20990041, grad/param norm = 1.8286e-01, time/batch = 0.7294s	
18653/30300 (epoch 30.781), train_loss = 1.10442631, grad/param norm = 1.8810e-01, time/batch = 0.7063s	
18654/30300 (epoch 30.782), train_loss = 1.03861444, grad/param norm = 1.5974e-01, time/batch = 0.6934s	
18655/30300 (epoch 30.784), train_loss = 1.02725870, grad/param norm = 1.5126e-01, time/batch = 0.6908s	
18656/30300 (epoch 30.785), train_loss = 1.20020211, grad/param norm = 2.0002e-01, time/batch = 0.6869s	
18657/30300 (epoch 30.787), train_loss = 0.91119334, grad/param norm = 1.5895e-01, time/batch = 0.6835s	
18658/30300 (epoch 30.789), train_loss = 1.27918528, grad/param norm = 1.7883e-01, time/batch = 0.6812s	
18659/30300 (epoch 30.790), train_loss = 1.12117151, grad/param norm = 2.0448e-01, time/batch = 0.6849s	
18660/30300 (epoch 30.792), train_loss = 0.91865889, grad/param norm = 1.7652e-01, time/batch = 0.6832s	
18661/30300 (epoch 30.794), train_loss = 1.09829871, grad/param norm = 1.8824e-01, time/batch = 0.6904s	
18662/30300 (epoch 30.795), train_loss = 1.00911078, grad/param norm = 1.4894e-01, time/batch = 0.6896s	
18663/30300 (epoch 30.797), train_loss = 1.23530546, grad/param norm = 1.7889e-01, time/batch = 0.6860s	
18664/30300 (epoch 30.799), train_loss = 1.16848833, grad/param norm = 1.8765e-01, time/batch = 0.6899s	
18665/30300 (epoch 30.800), train_loss = 1.16653347, grad/param norm = 1.6832e-01, time/batch = 0.7008s	
18666/30300 (epoch 30.802), train_loss = 1.34371986, grad/param norm = 2.1856e-01, time/batch = 0.7245s	
18667/30300 (epoch 30.804), train_loss = 1.16960112, grad/param norm = 1.8297e-01, time/batch = 0.7108s	
18668/30300 (epoch 30.805), train_loss = 1.23586120, grad/param norm = 1.7512e-01, time/batch = 0.6835s	
18669/30300 (epoch 30.807), train_loss = 1.06683343, grad/param norm = 1.7249e-01, time/batch = 0.6834s	
18670/30300 (epoch 30.809), train_loss = 1.16349064, grad/param norm = 1.6663e-01, time/batch = 0.6849s	
18671/30300 (epoch 30.810), train_loss = 1.15397619, grad/param norm = 1.6046e-01, time/batch = 0.6877s	
18672/30300 (epoch 30.812), train_loss = 1.03419146, grad/param norm = 1.5594e-01, time/batch = 0.6888s	
18673/30300 (epoch 30.814), train_loss = 1.08597749, grad/param norm = 1.5399e-01, time/batch = 0.6866s	
18674/30300 (epoch 30.815), train_loss = 1.09651552, grad/param norm = 1.6219e-01, time/batch = 0.6820s	
18675/30300 (epoch 30.817), train_loss = 1.18515390, grad/param norm = 1.8250e-01, time/batch = 0.6809s	
18676/30300 (epoch 30.818), train_loss = 1.11748284, grad/param norm = 1.6309e-01, time/batch = 0.6812s	
18677/30300 (epoch 30.820), train_loss = 1.26194852, grad/param norm = 2.0549e-01, time/batch = 0.6812s	
18678/30300 (epoch 30.822), train_loss = 1.25190860, grad/param norm = 1.8773e-01, time/batch = 0.6804s	
18679/30300 (epoch 30.823), train_loss = 1.25642872, grad/param norm = 2.0281e-01, time/batch = 0.6844s	
18680/30300 (epoch 30.825), train_loss = 1.23794958, grad/param norm = 1.8322e-01, time/batch = 0.6807s	
18681/30300 (epoch 30.827), train_loss = 0.94196246, grad/param norm = 1.6039e-01, time/batch = 0.6988s	
18682/30300 (epoch 30.828), train_loss = 1.18173940, grad/param norm = 1.7001e-01, time/batch = 0.7188s	
18683/30300 (epoch 30.830), train_loss = 1.15146356, grad/param norm = 1.6802e-01, time/batch = 0.7209s	
18684/30300 (epoch 30.832), train_loss = 1.02349898, grad/param norm = 1.6398e-01, time/batch = 0.7045s	
18685/30300 (epoch 30.833), train_loss = 1.12413854, grad/param norm = 1.6830e-01, time/batch = 0.7079s	
18686/30300 (epoch 30.835), train_loss = 1.02107420, grad/param norm = 1.6546e-01, time/batch = 0.6975s	
18687/30300 (epoch 30.837), train_loss = 0.98317338, grad/param norm = 1.5057e-01, time/batch = 0.6881s	
18688/30300 (epoch 30.838), train_loss = 1.00211321, grad/param norm = 1.5866e-01, time/batch = 0.6797s	
18689/30300 (epoch 30.840), train_loss = 1.18014425, grad/param norm = 1.4136e-01, time/batch = 0.6866s	
18690/30300 (epoch 30.842), train_loss = 1.05081942, grad/param norm = 1.4505e-01, time/batch = 0.6866s	
18691/30300 (epoch 30.843), train_loss = 1.13936282, grad/param norm = 1.7310e-01, time/batch = 0.6832s	
18692/30300 (epoch 30.845), train_loss = 1.15540780, grad/param norm = 1.5395e-01, time/batch = 0.6824s	
18693/30300 (epoch 30.847), train_loss = 1.11032883, grad/param norm = 1.6841e-01, time/batch = 0.6818s	
18694/30300 (epoch 30.848), train_loss = 1.15618215, grad/param norm = 1.5841e-01, time/batch = 0.6814s	
18695/30300 (epoch 30.850), train_loss = 1.09490340, grad/param norm = 1.5117e-01, time/batch = 0.6852s	
18696/30300 (epoch 30.851), train_loss = 1.12760506, grad/param norm = 1.9746e-01, time/batch = 0.6856s	
18697/30300 (epoch 30.853), train_loss = 1.05269004, grad/param norm = 1.5654e-01, time/batch = 0.6826s	
18698/30300 (epoch 30.855), train_loss = 1.05988810, grad/param norm = 1.5328e-01, time/batch = 0.6828s	
18699/30300 (epoch 30.856), train_loss = 1.12217001, grad/param norm = 1.6279e-01, time/batch = 0.6815s	
18700/30300 (epoch 30.858), train_loss = 1.02410075, grad/param norm = 1.3951e-01, time/batch = 0.6815s	
18701/30300 (epoch 30.860), train_loss = 1.01394314, grad/param norm = 1.6231e-01, time/batch = 0.6831s	
18702/30300 (epoch 30.861), train_loss = 1.26407690, grad/param norm = 1.5957e-01, time/batch = 0.6821s	
18703/30300 (epoch 30.863), train_loss = 1.07166781, grad/param norm = 1.5221e-01, time/batch = 0.6811s	
18704/30300 (epoch 30.865), train_loss = 1.16683068, grad/param norm = 1.9008e-01, time/batch = 0.6802s	
18705/30300 (epoch 30.866), train_loss = 1.16451157, grad/param norm = 1.6720e-01, time/batch = 0.6857s	
18706/30300 (epoch 30.868), train_loss = 1.10920331, grad/param norm = 1.5581e-01, time/batch = 0.6997s	
18707/30300 (epoch 30.870), train_loss = 1.03267474, grad/param norm = 1.5819e-01, time/batch = 0.7035s	
18708/30300 (epoch 30.871), train_loss = 1.10102381, grad/param norm = 1.5792e-01, time/batch = 0.7121s	
18709/30300 (epoch 30.873), train_loss = 1.09875464, grad/param norm = 1.5084e-01, time/batch = 0.7287s	
18710/30300 (epoch 30.875), train_loss = 1.07615983, grad/param norm = 1.5669e-01, time/batch = 0.7254s	
18711/30300 (epoch 30.876), train_loss = 0.97652454, grad/param norm = 1.5660e-01, time/batch = 0.7052s	
18712/30300 (epoch 30.878), train_loss = 0.95034307, grad/param norm = 1.5875e-01, time/batch = 0.6889s	
18713/30300 (epoch 30.880), train_loss = 1.00882888, grad/param norm = 1.5534e-01, time/batch = 0.6913s	
18714/30300 (epoch 30.881), train_loss = 1.25367990, grad/param norm = 2.1193e-01, time/batch = 0.6882s	
18715/30300 (epoch 30.883), train_loss = 1.16707347, grad/param norm = 1.6680e-01, time/batch = 0.6921s	
18716/30300 (epoch 30.884), train_loss = 1.05775630, grad/param norm = 1.4071e-01, time/batch = 0.6882s	
18717/30300 (epoch 30.886), train_loss = 1.14369255, grad/param norm = 1.5357e-01, time/batch = 0.6975s	
18718/30300 (epoch 30.888), train_loss = 1.08119994, grad/param norm = 1.6934e-01, time/batch = 0.7298s	
18719/30300 (epoch 30.889), train_loss = 1.11526976, grad/param norm = 1.4964e-01, time/batch = 0.6943s	
18720/30300 (epoch 30.891), train_loss = 1.07826518, grad/param norm = 1.9819e-01, time/batch = 0.6801s	
18721/30300 (epoch 30.893), train_loss = 1.29568302, grad/param norm = 1.6498e-01, time/batch = 0.6825s	
18722/30300 (epoch 30.894), train_loss = 1.14117207, grad/param norm = 1.6378e-01, time/batch = 0.6817s	
18723/30300 (epoch 30.896), train_loss = 0.94238469, grad/param norm = 1.6317e-01, time/batch = 0.6809s	
18724/30300 (epoch 30.898), train_loss = 0.94895757, grad/param norm = 1.5160e-01, time/batch = 0.6807s	
18725/30300 (epoch 30.899), train_loss = 1.00662589, grad/param norm = 1.6066e-01, time/batch = 0.6807s	
18726/30300 (epoch 30.901), train_loss = 1.09583081, grad/param norm = 1.6623e-01, time/batch = 0.6912s	
18727/30300 (epoch 30.903), train_loss = 1.10208278, grad/param norm = 1.8326e-01, time/batch = 0.7028s	
18728/30300 (epoch 30.904), train_loss = 1.10322040, grad/param norm = 1.5474e-01, time/batch = 0.6892s	
18729/30300 (epoch 30.906), train_loss = 1.12674328, grad/param norm = 1.8097e-01, time/batch = 0.7180s	
18730/30300 (epoch 30.908), train_loss = 1.03941997, grad/param norm = 1.5106e-01, time/batch = 0.6892s	
18731/30300 (epoch 30.909), train_loss = 1.02953050, grad/param norm = 2.0523e-01, time/batch = 0.6901s	
18732/30300 (epoch 30.911), train_loss = 1.10412030, grad/param norm = 1.6406e-01, time/batch = 0.7160s	
18733/30300 (epoch 30.913), train_loss = 1.09042164, grad/param norm = 1.5376e-01, time/batch = 0.7136s	
18734/30300 (epoch 30.914), train_loss = 1.06168623, grad/param norm = 1.6366e-01, time/batch = 0.6850s	
18735/30300 (epoch 30.916), train_loss = 1.11681534, grad/param norm = 1.4613e-01, time/batch = 0.6862s	
18736/30300 (epoch 30.917), train_loss = 1.06904427, grad/param norm = 1.6318e-01, time/batch = 0.6835s	
18737/30300 (epoch 30.919), train_loss = 1.01900483, grad/param norm = 1.6940e-01, time/batch = 0.6853s	
18738/30300 (epoch 30.921), train_loss = 1.06182692, grad/param norm = 1.4378e-01, time/batch = 0.6810s	
18739/30300 (epoch 30.922), train_loss = 1.17980450, grad/param norm = 1.6876e-01, time/batch = 0.6819s	
18740/30300 (epoch 30.924), train_loss = 1.09270653, grad/param norm = 1.6552e-01, time/batch = 0.6825s	
18741/30300 (epoch 30.926), train_loss = 1.14307724, grad/param norm = 1.5941e-01, time/batch = 0.6890s	
18742/30300 (epoch 30.927), train_loss = 1.11004682, grad/param norm = 1.6000e-01, time/batch = 0.7050s	
18743/30300 (epoch 30.929), train_loss = 1.00923304, grad/param norm = 1.6389e-01, time/batch = 0.6993s	
18744/30300 (epoch 30.931), train_loss = 1.18378861, grad/param norm = 1.9164e-01, time/batch = 0.6822s	
18745/30300 (epoch 30.932), train_loss = 1.03172641, grad/param norm = 1.9220e-01, time/batch = 0.6816s	
18746/30300 (epoch 30.934), train_loss = 1.12981247, grad/param norm = 1.6146e-01, time/batch = 0.6881s	
18747/30300 (epoch 30.936), train_loss = 1.03056393, grad/param norm = 2.1175e-01, time/batch = 0.6835s	
18748/30300 (epoch 30.937), train_loss = 1.03678601, grad/param norm = 1.5480e-01, time/batch = 0.6816s	
18749/30300 (epoch 30.939), train_loss = 1.21255150, grad/param norm = 1.6947e-01, time/batch = 0.6828s	
18750/30300 (epoch 30.941), train_loss = 1.05892928, grad/param norm = 1.6680e-01, time/batch = 0.6823s	
18751/30300 (epoch 30.942), train_loss = 1.09656716, grad/param norm = 1.7054e-01, time/batch = 0.7249s	
18752/30300 (epoch 30.944), train_loss = 0.98071648, grad/param norm = 1.4854e-01, time/batch = 0.7044s	
18753/30300 (epoch 30.946), train_loss = 1.19393607, grad/param norm = 1.9960e-01, time/batch = 0.6830s	
18754/30300 (epoch 30.947), train_loss = 1.16830996, grad/param norm = 2.1680e-01, time/batch = 0.6840s	
18755/30300 (epoch 30.949), train_loss = 1.19719062, grad/param norm = 2.0938e-01, time/batch = 0.6820s	
18756/30300 (epoch 30.950), train_loss = 1.20438538, grad/param norm = 1.7633e-01, time/batch = 0.6825s	
18757/30300 (epoch 30.952), train_loss = 1.15299135, grad/param norm = 2.0198e-01, time/batch = 0.6836s	
18758/30300 (epoch 30.954), train_loss = 1.37216952, grad/param norm = 1.9238e-01, time/batch = 0.6817s	
18759/30300 (epoch 30.955), train_loss = 1.06747845, grad/param norm = 1.5013e-01, time/batch = 0.6814s	
18760/30300 (epoch 30.957), train_loss = 1.15445658, grad/param norm = 1.6044e-01, time/batch = 0.6782s	
18761/30300 (epoch 30.959), train_loss = 1.03276507, grad/param norm = 1.8175e-01, time/batch = 0.6839s	
18762/30300 (epoch 30.960), train_loss = 1.05209025, grad/param norm = 1.6791e-01, time/batch = 0.6848s	
18763/30300 (epoch 30.962), train_loss = 1.06652295, grad/param norm = 1.9752e-01, time/batch = 0.6822s	
18764/30300 (epoch 30.964), train_loss = 1.00976011, grad/param norm = 2.0883e-01, time/batch = 0.6797s	
18765/30300 (epoch 30.965), train_loss = 1.03828571, grad/param norm = 1.7970e-01, time/batch = 0.6799s	
18766/30300 (epoch 30.967), train_loss = 1.07732739, grad/param norm = 1.9419e-01, time/batch = 0.6824s	
18767/30300 (epoch 30.969), train_loss = 1.01754561, grad/param norm = 2.0608e-01, time/batch = 0.6828s	
18768/30300 (epoch 30.970), train_loss = 1.08623936, grad/param norm = 1.7621e-01, time/batch = 0.6806s	
18769/30300 (epoch 30.972), train_loss = 0.97848229, grad/param norm = 1.6953e-01, time/batch = 0.6825s	
18770/30300 (epoch 30.974), train_loss = 1.23780962, grad/param norm = 1.7382e-01, time/batch = 0.7251s	
18771/30300 (epoch 30.975), train_loss = 1.24084553, grad/param norm = 1.7655e-01, time/batch = 0.6997s	
18772/30300 (epoch 30.977), train_loss = 1.26304105, grad/param norm = 1.8883e-01, time/batch = 0.6823s	
18773/30300 (epoch 30.979), train_loss = 1.16569301, grad/param norm = 1.7977e-01, time/batch = 0.6811s	
18774/30300 (epoch 30.980), train_loss = 1.20410709, grad/param norm = 1.9566e-01, time/batch = 0.6797s	
18775/30300 (epoch 30.982), train_loss = 1.20186010, grad/param norm = 1.7215e-01, time/batch = 0.6817s	
18776/30300 (epoch 30.983), train_loss = 1.23434707, grad/param norm = 1.7344e-01, time/batch = 0.6806s	
18777/30300 (epoch 30.985), train_loss = 1.16548309, grad/param norm = 1.8098e-01, time/batch = 0.6842s	
18778/30300 (epoch 30.987), train_loss = 1.09374450, grad/param norm = 1.5119e-01, time/batch = 0.6878s	
18779/30300 (epoch 30.988), train_loss = 1.22787733, grad/param norm = 1.7245e-01, time/batch = 0.6802s	
18780/30300 (epoch 30.990), train_loss = 0.99624489, grad/param norm = 1.5353e-01, time/batch = 0.6805s	
18781/30300 (epoch 30.992), train_loss = 1.17711314, grad/param norm = 1.4715e-01, time/batch = 0.6833s	
18782/30300 (epoch 30.993), train_loss = 1.22841788, grad/param norm = 1.9153e-01, time/batch = 0.6911s	
18783/30300 (epoch 30.995), train_loss = 1.09450363, grad/param norm = 1.8672e-01, time/batch = 0.6917s	
18784/30300 (epoch 30.997), train_loss = 1.12318676, grad/param norm = 1.7845e-01, time/batch = 0.6923s	
18785/30300 (epoch 30.998), train_loss = 1.16050607, grad/param norm = 1.7804e-01, time/batch = 0.6895s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
18786/30300 (epoch 31.000), train_loss = 1.08197209, grad/param norm = 1.8817e-01, time/batch = 0.6944s	
18787/30300 (epoch 31.002), train_loss = 1.21157389, grad/param norm = 2.1066e-01, time/batch = 0.6955s	
18788/30300 (epoch 31.003), train_loss = 1.11281589, grad/param norm = 1.8409e-01, time/batch = 0.6888s	
18789/30300 (epoch 31.005), train_loss = 1.05510629, grad/param norm = 1.7442e-01, time/batch = 0.6843s	
18790/30300 (epoch 31.007), train_loss = 1.14138531, grad/param norm = 1.9330e-01, time/batch = 0.6857s	
18791/30300 (epoch 31.008), train_loss = 1.06479091, grad/param norm = 1.7471e-01, time/batch = 0.6843s	
18792/30300 (epoch 31.010), train_loss = 1.00441230, grad/param norm = 3.1726e-01, time/batch = 0.6839s	
18793/30300 (epoch 31.012), train_loss = 1.05642417, grad/param norm = 1.6075e-01, time/batch = 0.6849s	
18794/30300 (epoch 31.013), train_loss = 1.19692108, grad/param norm = 1.7530e-01, time/batch = 0.6831s	
18795/30300 (epoch 31.015), train_loss = 1.07095326, grad/param norm = 1.7832e-01, time/batch = 0.6838s	
18796/30300 (epoch 31.017), train_loss = 1.06053848, grad/param norm = 1.5226e-01, time/batch = 0.6827s	
18797/30300 (epoch 31.018), train_loss = 1.03093072, grad/param norm = 2.1901e-01, time/batch = 0.6879s	
18798/30300 (epoch 31.020), train_loss = 1.20114038, grad/param norm = 2.3774e-01, time/batch = 0.6889s	
18799/30300 (epoch 31.021), train_loss = 1.23244165, grad/param norm = 1.7427e-01, time/batch = 0.6848s	
18800/30300 (epoch 31.023), train_loss = 1.13599756, grad/param norm = 1.6764e-01, time/batch = 0.6840s	
18801/30300 (epoch 31.025), train_loss = 1.02843700, grad/param norm = 1.7509e-01, time/batch = 0.6836s	
18802/30300 (epoch 31.026), train_loss = 1.15923993, grad/param norm = 1.9398e-01, time/batch = 0.6805s	
18803/30300 (epoch 31.028), train_loss = 1.18467111, grad/param norm = 1.7558e-01, time/batch = 0.7140s	
18804/30300 (epoch 31.030), train_loss = 1.06869046, grad/param norm = 1.8895e-01, time/batch = 0.6829s	
18805/30300 (epoch 31.031), train_loss = 1.16359136, grad/param norm = 1.7287e-01, time/batch = 0.6808s	
18806/30300 (epoch 31.033), train_loss = 1.11940488, grad/param norm = 1.6014e-01, time/batch = 0.6825s	
18807/30300 (epoch 31.035), train_loss = 1.18171952, grad/param norm = 1.8734e-01, time/batch = 0.6816s	
18808/30300 (epoch 31.036), train_loss = 1.12309302, grad/param norm = 1.6201e-01, time/batch = 0.6831s	
18809/30300 (epoch 31.038), train_loss = 1.15269378, grad/param norm = 1.5582e-01, time/batch = 0.6826s	
18810/30300 (epoch 31.040), train_loss = 0.90384097, grad/param norm = 1.4600e-01, time/batch = 0.6817s	
18811/30300 (epoch 31.041), train_loss = 0.93090835, grad/param norm = 1.5329e-01, time/batch = 0.6850s	
18812/30300 (epoch 31.043), train_loss = 1.11801077, grad/param norm = 1.7052e-01, time/batch = 0.6932s	
18813/30300 (epoch 31.045), train_loss = 1.07891869, grad/param norm = 1.5377e-01, time/batch = 0.6939s	
18814/30300 (epoch 31.046), train_loss = 1.26904721, grad/param norm = 1.9766e-01, time/batch = 0.6971s	
18815/30300 (epoch 31.048), train_loss = 1.09471975, grad/param norm = 1.6840e-01, time/batch = 0.7028s	
18816/30300 (epoch 31.050), train_loss = 1.03842485, grad/param norm = 1.6806e-01, time/batch = 0.7003s	
18817/30300 (epoch 31.051), train_loss = 1.14971079, grad/param norm = 1.9193e-01, time/batch = 0.6841s	
18818/30300 (epoch 31.053), train_loss = 0.95975308, grad/param norm = 2.0483e-01, time/batch = 0.6858s	
18819/30300 (epoch 31.054), train_loss = 1.13069284, grad/param norm = 1.6394e-01, time/batch = 0.6830s	
18820/30300 (epoch 31.056), train_loss = 1.01179615, grad/param norm = 1.5778e-01, time/batch = 0.7084s	
18821/30300 (epoch 31.058), train_loss = 1.06544121, grad/param norm = 1.5276e-01, time/batch = 0.6864s	
18822/30300 (epoch 31.059), train_loss = 1.05177626, grad/param norm = 1.9553e-01, time/batch = 0.7261s	
18823/30300 (epoch 31.061), train_loss = 1.15553688, grad/param norm = 1.7828e-01, time/batch = 0.6992s	
18824/30300 (epoch 31.063), train_loss = 0.98492169, grad/param norm = 1.6003e-01, time/batch = 0.6823s	
18825/30300 (epoch 31.064), train_loss = 1.11551700, grad/param norm = 1.7542e-01, time/batch = 0.6799s	
18826/30300 (epoch 31.066), train_loss = 1.09192234, grad/param norm = 1.5836e-01, time/batch = 0.6798s	
18827/30300 (epoch 31.068), train_loss = 0.99863333, grad/param norm = 1.6703e-01, time/batch = 0.6804s	
18828/30300 (epoch 31.069), train_loss = 1.17105047, grad/param norm = 1.7597e-01, time/batch = 0.6875s	
18829/30300 (epoch 31.071), train_loss = 1.15308352, grad/param norm = 1.7687e-01, time/batch = 0.6803s	
18830/30300 (epoch 31.073), train_loss = 1.02989649, grad/param norm = 1.7743e-01, time/batch = 0.6824s	
18831/30300 (epoch 31.074), train_loss = 1.10410715, grad/param norm = 1.6947e-01, time/batch = 0.6827s	
18832/30300 (epoch 31.076), train_loss = 1.08598563, grad/param norm = 1.6230e-01, time/batch = 0.6818s	
18833/30300 (epoch 31.078), train_loss = 1.02315744, grad/param norm = 1.5364e-01, time/batch = 0.6815s	
18834/30300 (epoch 31.079), train_loss = 1.03383082, grad/param norm = 1.4711e-01, time/batch = 0.6827s	
18835/30300 (epoch 31.081), train_loss = 1.10007733, grad/param norm = 1.6868e-01, time/batch = 0.6830s	
18836/30300 (epoch 31.083), train_loss = 1.16617667, grad/param norm = 2.1774e-01, time/batch = 0.6872s	
18837/30300 (epoch 31.084), train_loss = 1.00651563, grad/param norm = 1.6388e-01, time/batch = 0.6847s	
18838/30300 (epoch 31.086), train_loss = 1.02841485, grad/param norm = 1.6858e-01, time/batch = 0.6833s	
18839/30300 (epoch 31.087), train_loss = 1.01960612, grad/param norm = 1.5068e-01, time/batch = 0.6848s	
18840/30300 (epoch 31.089), train_loss = 1.03954183, grad/param norm = 1.5033e-01, time/batch = 0.6861s	
18841/30300 (epoch 31.091), train_loss = 1.12944421, grad/param norm = 1.5186e-01, time/batch = 0.7274s	
18842/30300 (epoch 31.092), train_loss = 1.16228969, grad/param norm = 1.8882e-01, time/batch = 0.6939s	
18843/30300 (epoch 31.094), train_loss = 1.23746197, grad/param norm = 1.9129e-01, time/batch = 0.6844s	
18844/30300 (epoch 31.096), train_loss = 1.21597472, grad/param norm = 1.8129e-01, time/batch = 0.6817s	
18845/30300 (epoch 31.097), train_loss = 1.03170549, grad/param norm = 1.6926e-01, time/batch = 0.6812s	
18846/30300 (epoch 31.099), train_loss = 1.19891232, grad/param norm = 1.7217e-01, time/batch = 0.6946s	
18847/30300 (epoch 31.101), train_loss = 1.23227966, grad/param norm = 1.9493e-01, time/batch = 0.6882s	
18848/30300 (epoch 31.102), train_loss = 1.03932261, grad/param norm = 1.7699e-01, time/batch = 0.6805s	
18849/30300 (epoch 31.104), train_loss = 1.06876052, grad/param norm = 2.5461e-01, time/batch = 0.6802s	
18850/30300 (epoch 31.106), train_loss = 1.08401391, grad/param norm = 1.9419e-01, time/batch = 0.6797s	
18851/30300 (epoch 31.107), train_loss = 1.13110665, grad/param norm = 1.5636e-01, time/batch = 0.6816s	
18852/30300 (epoch 31.109), train_loss = 1.17715591, grad/param norm = 2.2063e-01, time/batch = 0.6815s	
18853/30300 (epoch 31.111), train_loss = 1.18708095, grad/param norm = 1.7736e-01, time/batch = 0.6815s	
18854/30300 (epoch 31.112), train_loss = 1.22338314, grad/param norm = 1.6545e-01, time/batch = 0.6864s	
18855/30300 (epoch 31.114), train_loss = 1.06772365, grad/param norm = 1.6043e-01, time/batch = 0.6860s	
18856/30300 (epoch 31.116), train_loss = 1.11073242, grad/param norm = 1.8120e-01, time/batch = 0.6829s	
18857/30300 (epoch 31.117), train_loss = 1.18854541, grad/param norm = 1.5773e-01, time/batch = 0.6855s	
18858/30300 (epoch 31.119), train_loss = 1.02054909, grad/param norm = 1.6709e-01, time/batch = 0.6864s	
18859/30300 (epoch 31.120), train_loss = 1.07467248, grad/param norm = 1.7297e-01, time/batch = 0.6853s	
18860/30300 (epoch 31.122), train_loss = 1.18936056, grad/param norm = 2.0875e-01, time/batch = 0.6816s	
18861/30300 (epoch 31.124), train_loss = 1.25339928, grad/param norm = 1.8330e-01, time/batch = 0.6852s	
18862/30300 (epoch 31.125), train_loss = 0.97637481, grad/param norm = 1.6999e-01, time/batch = 0.6831s	
18863/30300 (epoch 31.127), train_loss = 1.14271093, grad/param norm = 2.0868e-01, time/batch = 0.6822s	
18864/30300 (epoch 31.129), train_loss = 1.21562027, grad/param norm = 1.7329e-01, time/batch = 0.6841s	
18865/30300 (epoch 31.130), train_loss = 1.22986740, grad/param norm = 1.7363e-01, time/batch = 0.6875s	
18866/30300 (epoch 31.132), train_loss = 1.23075504, grad/param norm = 1.7127e-01, time/batch = 0.6838s	
18867/30300 (epoch 31.134), train_loss = 1.02776053, grad/param norm = 1.9253e-01, time/batch = 0.6833s	
18868/30300 (epoch 31.135), train_loss = 1.05360836, grad/param norm = 1.8725e-01, time/batch = 0.6867s	
18869/30300 (epoch 31.137), train_loss = 1.11903062, grad/param norm = 1.7963e-01, time/batch = 0.6820s	
18870/30300 (epoch 31.139), train_loss = 1.05611601, grad/param norm = 1.9537e-01, time/batch = 0.6849s	
18871/30300 (epoch 31.140), train_loss = 1.13392173, grad/param norm = 2.7646e-01, time/batch = 0.6848s	
18872/30300 (epoch 31.142), train_loss = 1.22964083, grad/param norm = 2.2417e-01, time/batch = 0.6826s	
18873/30300 (epoch 31.144), train_loss = 1.04028520, grad/param norm = 1.8478e-01, time/batch = 0.6840s	
18874/30300 (epoch 31.145), train_loss = 1.18910406, grad/param norm = 2.0697e-01, time/batch = 0.7145s	
18875/30300 (epoch 31.147), train_loss = 1.06594772, grad/param norm = 1.7010e-01, time/batch = 0.7103s	
18876/30300 (epoch 31.149), train_loss = 1.21211479, grad/param norm = 2.0157e-01, time/batch = 0.6829s	
18877/30300 (epoch 31.150), train_loss = 1.07500581, grad/param norm = 1.8993e-01, time/batch = 0.6827s	
18878/30300 (epoch 31.152), train_loss = 0.99729259, grad/param norm = 1.8043e-01, time/batch = 0.6841s	
18879/30300 (epoch 31.153), train_loss = 1.10128675, grad/param norm = 1.6935e-01, time/batch = 0.6807s	
18880/30300 (epoch 31.155), train_loss = 0.96660696, grad/param norm = 1.4802e-01, time/batch = 0.6832s	
18881/30300 (epoch 31.157), train_loss = 1.07917953, grad/param norm = 1.9723e-01, time/batch = 0.6939s	
18882/30300 (epoch 31.158), train_loss = 1.14624709, grad/param norm = 2.3556e-01, time/batch = 0.7112s	
18883/30300 (epoch 31.160), train_loss = 1.01660238, grad/param norm = 1.6961e-01, time/batch = 0.7196s	
18884/30300 (epoch 31.162), train_loss = 1.11393317, grad/param norm = 1.5543e-01, time/batch = 0.7095s	
18885/30300 (epoch 31.163), train_loss = 1.09281246, grad/param norm = 1.7913e-01, time/batch = 0.6989s	
18886/30300 (epoch 31.165), train_loss = 1.21164371, grad/param norm = 1.6736e-01, time/batch = 0.6835s	
18887/30300 (epoch 31.167), train_loss = 1.11277708, grad/param norm = 1.7859e-01, time/batch = 0.6801s	
18888/30300 (epoch 31.168), train_loss = 1.15700658, grad/param norm = 1.7634e-01, time/batch = 0.6986s	
18889/30300 (epoch 31.170), train_loss = 1.10082081, grad/param norm = 1.6922e-01, time/batch = 0.7249s	
18890/30300 (epoch 31.172), train_loss = 1.10968102, grad/param norm = 1.8938e-01, time/batch = 0.6790s	
18891/30300 (epoch 31.173), train_loss = 1.10421121, grad/param norm = 2.0194e-01, time/batch = 0.6847s	
18892/30300 (epoch 31.175), train_loss = 1.09297958, grad/param norm = 1.5256e-01, time/batch = 0.7004s	
18893/30300 (epoch 31.177), train_loss = 1.15699204, grad/param norm = 1.8741e-01, time/batch = 0.6939s	
18894/30300 (epoch 31.178), train_loss = 0.88771520, grad/param norm = 1.5230e-01, time/batch = 0.6959s	
18895/30300 (epoch 31.180), train_loss = 1.08011933, grad/param norm = 1.5794e-01, time/batch = 0.7070s	
18896/30300 (epoch 31.182), train_loss = 1.11593036, grad/param norm = 1.8153e-01, time/batch = 0.6871s	
18897/30300 (epoch 31.183), train_loss = 1.03929410, grad/param norm = 1.6624e-01, time/batch = 0.6791s	
18898/30300 (epoch 31.185), train_loss = 1.26064159, grad/param norm = 1.8166e-01, time/batch = 0.6793s	
18899/30300 (epoch 31.186), train_loss = 1.30285616, grad/param norm = 2.0416e-01, time/batch = 0.6859s	
18900/30300 (epoch 31.188), train_loss = 1.14194987, grad/param norm = 1.6687e-01, time/batch = 0.6906s	
18901/30300 (epoch 31.190), train_loss = 1.11939935, grad/param norm = 1.5591e-01, time/batch = 0.7015s	
18902/30300 (epoch 31.191), train_loss = 1.16594096, grad/param norm = 1.7994e-01, time/batch = 0.6914s	
18903/30300 (epoch 31.193), train_loss = 1.00966518, grad/param norm = 1.4670e-01, time/batch = 0.7022s	
18904/30300 (epoch 31.195), train_loss = 1.07473384, grad/param norm = 1.7586e-01, time/batch = 0.6848s	
18905/30300 (epoch 31.196), train_loss = 1.13413406, grad/param norm = 1.4646e-01, time/batch = 0.6855s	
18906/30300 (epoch 31.198), train_loss = 0.95207673, grad/param norm = 1.5840e-01, time/batch = 0.6864s	
18907/30300 (epoch 31.200), train_loss = 1.09231962, grad/param norm = 1.5807e-01, time/batch = 0.7152s	
18908/30300 (epoch 31.201), train_loss = 1.17215014, grad/param norm = 1.9090e-01, time/batch = 0.7120s	
18909/30300 (epoch 31.203), train_loss = 1.09722076, grad/param norm = 1.8525e-01, time/batch = 0.6872s	
18910/30300 (epoch 31.205), train_loss = 1.31314523, grad/param norm = 1.8681e-01, time/batch = 0.6998s	
18911/30300 (epoch 31.206), train_loss = 1.19044799, grad/param norm = 1.7475e-01, time/batch = 0.6893s	
18912/30300 (epoch 31.208), train_loss = 1.16820881, grad/param norm = 2.2810e-01, time/batch = 0.6823s	
18913/30300 (epoch 31.210), train_loss = 1.17110638, grad/param norm = 1.7349e-01, time/batch = 0.6823s	
18914/30300 (epoch 31.211), train_loss = 1.23771972, grad/param norm = 1.8055e-01, time/batch = 0.6818s	
18915/30300 (epoch 31.213), train_loss = 1.09219047, grad/param norm = 1.5167e-01, time/batch = 0.6827s	
18916/30300 (epoch 31.215), train_loss = 1.05224453, grad/param norm = 1.9519e-01, time/batch = 0.6923s	
18917/30300 (epoch 31.216), train_loss = 1.05301828, grad/param norm = 1.6927e-01, time/batch = 0.6819s	
18918/30300 (epoch 31.218), train_loss = 1.01710345, grad/param norm = 1.5020e-01, time/batch = 0.6819s	
18919/30300 (epoch 31.219), train_loss = 0.97818181, grad/param norm = 1.5765e-01, time/batch = 0.6817s	
18920/30300 (epoch 31.221), train_loss = 0.95862146, grad/param norm = 1.6541e-01, time/batch = 0.6846s	
18921/30300 (epoch 31.223), train_loss = 1.11356503, grad/param norm = 1.6305e-01, time/batch = 0.6843s	
18922/30300 (epoch 31.224), train_loss = 0.95073884, grad/param norm = 1.6999e-01, time/batch = 0.6818s	
18923/30300 (epoch 31.226), train_loss = 1.15736489, grad/param norm = 1.7095e-01, time/batch = 0.6863s	
18924/30300 (epoch 31.228), train_loss = 1.19088393, grad/param norm = 1.6982e-01, time/batch = 0.6874s	
18925/30300 (epoch 31.229), train_loss = 1.08473589, grad/param norm = 1.5969e-01, time/batch = 0.6835s	
18926/30300 (epoch 31.231), train_loss = 1.13075174, grad/param norm = 1.6570e-01, time/batch = 0.7229s	
18927/30300 (epoch 31.233), train_loss = 1.13729059, grad/param norm = 1.4258e-01, time/batch = 0.7021s	
18928/30300 (epoch 31.234), train_loss = 1.17000787, grad/param norm = 2.0703e-01, time/batch = 0.6927s	
18929/30300 (epoch 31.236), train_loss = 1.13265307, grad/param norm = 1.4912e-01, time/batch = 0.6926s	
18930/30300 (epoch 31.238), train_loss = 1.10687958, grad/param norm = 1.8666e-01, time/batch = 0.6847s	
18931/30300 (epoch 31.239), train_loss = 1.10105932, grad/param norm = 1.8991e-01, time/batch = 0.6861s	
18932/30300 (epoch 31.241), train_loss = 1.15074872, grad/param norm = 1.7956e-01, time/batch = 0.6832s	
18933/30300 (epoch 31.243), train_loss = 1.16063494, grad/param norm = 1.6929e-01, time/batch = 0.6841s	
18934/30300 (epoch 31.244), train_loss = 1.30279524, grad/param norm = 1.7188e-01, time/batch = 0.6831s	
18935/30300 (epoch 31.246), train_loss = 1.13534092, grad/param norm = 1.6373e-01, time/batch = 0.6838s	
18936/30300 (epoch 31.248), train_loss = 1.06999886, grad/param norm = 1.4802e-01, time/batch = 0.6830s	
18937/30300 (epoch 31.249), train_loss = 1.03359493, grad/param norm = 1.6761e-01, time/batch = 0.6849s	
18938/30300 (epoch 31.251), train_loss = 1.05239368, grad/param norm = 1.8604e-01, time/batch = 0.6874s	
18939/30300 (epoch 31.252), train_loss = 1.21280376, grad/param norm = 1.8035e-01, time/batch = 0.6822s	
18940/30300 (epoch 31.254), train_loss = 1.20992223, grad/param norm = 1.8301e-01, time/batch = 0.6818s	
18941/30300 (epoch 31.256), train_loss = 1.13070316, grad/param norm = 1.7010e-01, time/batch = 0.6845s	
18942/30300 (epoch 31.257), train_loss = 1.18935461, grad/param norm = 1.6780e-01, time/batch = 0.6818s	
18943/30300 (epoch 31.259), train_loss = 1.10357599, grad/param norm = 1.7656e-01, time/batch = 0.6813s	
18944/30300 (epoch 31.261), train_loss = 1.21963432, grad/param norm = 1.6148e-01, time/batch = 0.6871s	
18945/30300 (epoch 31.262), train_loss = 1.03611329, grad/param norm = 1.5829e-01, time/batch = 0.7257s	
18946/30300 (epoch 31.264), train_loss = 1.08874019, grad/param norm = 1.4988e-01, time/batch = 0.6936s	
18947/30300 (epoch 31.266), train_loss = 1.04698493, grad/param norm = 1.4826e-01, time/batch = 0.6847s	
18948/30300 (epoch 31.267), train_loss = 1.27376817, grad/param norm = 1.8455e-01, time/batch = 0.6848s	
18949/30300 (epoch 31.269), train_loss = 1.10578179, grad/param norm = 1.5557e-01, time/batch = 0.6811s	
18950/30300 (epoch 31.271), train_loss = 1.14620312, grad/param norm = 1.6463e-01, time/batch = 0.6935s	
18951/30300 (epoch 31.272), train_loss = 1.12188412, grad/param norm = 1.9578e-01, time/batch = 0.6877s	
18952/30300 (epoch 31.274), train_loss = 1.16680532, grad/param norm = 1.6958e-01, time/batch = 0.6819s	
18953/30300 (epoch 31.276), train_loss = 1.17521513, grad/param norm = 2.0066e-01, time/batch = 0.6829s	
18954/30300 (epoch 31.277), train_loss = 0.99933293, grad/param norm = 1.6124e-01, time/batch = 0.6813s	
18955/30300 (epoch 31.279), train_loss = 1.11843063, grad/param norm = 1.7913e-01, time/batch = 0.6831s	
18956/30300 (epoch 31.281), train_loss = 1.20934484, grad/param norm = 1.9040e-01, time/batch = 0.6913s	
18957/30300 (epoch 31.282), train_loss = 1.13325501, grad/param norm = 1.5056e-01, time/batch = 0.6808s	
18958/30300 (epoch 31.284), train_loss = 1.21242095, grad/param norm = 2.4403e-01, time/batch = 0.6796s	
18959/30300 (epoch 31.285), train_loss = 1.15286271, grad/param norm = 1.6186e-01, time/batch = 0.6814s	
18960/30300 (epoch 31.287), train_loss = 1.08841836, grad/param norm = 1.7178e-01, time/batch = 0.6805s	
18961/30300 (epoch 31.289), train_loss = 1.19455896, grad/param norm = 1.6504e-01, time/batch = 0.6831s	
18962/30300 (epoch 31.290), train_loss = 0.88212480, grad/param norm = 1.4543e-01, time/batch = 0.6810s	
18963/30300 (epoch 31.292), train_loss = 1.01276519, grad/param norm = 1.6264e-01, time/batch = 0.6820s	
18964/30300 (epoch 31.294), train_loss = 1.18829392, grad/param norm = 2.1276e-01, time/batch = 0.6842s	
18965/30300 (epoch 31.295), train_loss = 1.07644238, grad/param norm = 1.7346e-01, time/batch = 0.6864s	
18966/30300 (epoch 31.297), train_loss = 1.06422854, grad/param norm = 1.5383e-01, time/batch = 0.6823s	
18967/30300 (epoch 31.299), train_loss = 1.08624238, grad/param norm = 1.5220e-01, time/batch = 0.6834s	
18968/30300 (epoch 31.300), train_loss = 1.02800061, grad/param norm = 2.0130e-01, time/batch = 0.7220s	
18969/30300 (epoch 31.302), train_loss = 1.17437590, grad/param norm = 1.7246e-01, time/batch = 0.7166s	
18970/30300 (epoch 31.304), train_loss = 1.04676713, grad/param norm = 1.7156e-01, time/batch = 0.6845s	
18971/30300 (epoch 31.305), train_loss = 1.09229087, grad/param norm = 1.5486e-01, time/batch = 0.6855s	
18972/30300 (epoch 31.307), train_loss = 1.16895829, grad/param norm = 1.5696e-01, time/batch = 0.6837s	
18973/30300 (epoch 31.309), train_loss = 1.14422504, grad/param norm = 1.6558e-01, time/batch = 0.6819s	
18974/30300 (epoch 31.310), train_loss = 1.08841737, grad/param norm = 1.5379e-01, time/batch = 0.6863s	
18975/30300 (epoch 31.312), train_loss = 1.25129034, grad/param norm = 1.6624e-01, time/batch = 0.6942s	
18976/30300 (epoch 31.314), train_loss = 1.11894135, grad/param norm = 1.6919e-01, time/batch = 0.6932s	
18977/30300 (epoch 31.315), train_loss = 1.07734854, grad/param norm = 1.8227e-01, time/batch = 0.6861s	
18978/30300 (epoch 31.317), train_loss = 1.11908045, grad/param norm = 1.5071e-01, time/batch = 0.7068s	
18979/30300 (epoch 31.318), train_loss = 1.18604530, grad/param norm = 1.9434e-01, time/batch = 0.6862s	
18980/30300 (epoch 31.320), train_loss = 1.15465589, grad/param norm = 1.6264e-01, time/batch = 0.6846s	
18981/30300 (epoch 31.322), train_loss = 1.04782389, grad/param norm = 1.6754e-01, time/batch = 0.6863s	
18982/30300 (epoch 31.323), train_loss = 1.22057855, grad/param norm = 1.8177e-01, time/batch = 0.6876s	
18983/30300 (epoch 31.325), train_loss = 1.09362963, grad/param norm = 1.5709e-01, time/batch = 0.6851s	
18984/30300 (epoch 31.327), train_loss = 1.09866366, grad/param norm = 1.5252e-01, time/batch = 0.6930s	
18985/30300 (epoch 31.328), train_loss = 1.12327273, grad/param norm = 1.5994e-01, time/batch = 0.6831s	
18986/30300 (epoch 31.330), train_loss = 1.14556826, grad/param norm = 1.7090e-01, time/batch = 0.7219s	
18987/30300 (epoch 31.332), train_loss = 1.20358156, grad/param norm = 1.8694e-01, time/batch = 0.7184s	
18988/30300 (epoch 31.333), train_loss = 1.05997447, grad/param norm = 1.7505e-01, time/batch = 0.7363s	
18989/30300 (epoch 31.335), train_loss = 0.99289556, grad/param norm = 1.6170e-01, time/batch = 0.7419s	
18990/30300 (epoch 31.337), train_loss = 1.23181666, grad/param norm = 1.5736e-01, time/batch = 0.7354s	
18991/30300 (epoch 31.338), train_loss = 1.05471564, grad/param norm = 1.5424e-01, time/batch = 0.7074s	
18992/30300 (epoch 31.340), train_loss = 1.04991569, grad/param norm = 1.6055e-01, time/batch = 0.6916s	
18993/30300 (epoch 31.342), train_loss = 1.19617765, grad/param norm = 1.7077e-01, time/batch = 0.6839s	
18994/30300 (epoch 31.343), train_loss = 1.13142848, grad/param norm = 1.5918e-01, time/batch = 0.6910s	
18995/30300 (epoch 31.345), train_loss = 1.17596100, grad/param norm = 1.7638e-01, time/batch = 0.6955s	
18996/30300 (epoch 31.347), train_loss = 0.98815252, grad/param norm = 1.5255e-01, time/batch = 0.6920s	
18997/30300 (epoch 31.348), train_loss = 1.06211056, grad/param norm = 1.6293e-01, time/batch = 0.6829s	
18998/30300 (epoch 31.350), train_loss = 1.07496444, grad/param norm = 1.6747e-01, time/batch = 0.6798s	
18999/30300 (epoch 31.351), train_loss = 1.07461800, grad/param norm = 1.6229e-01, time/batch = 0.6799s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch31.35_1.9324.t7	
19000/30300 (epoch 31.353), train_loss = 0.98585098, grad/param norm = 1.5918e-01, time/batch = 0.6791s	
19001/30300 (epoch 31.355), train_loss = 1.50792691, grad/param norm = 2.2147e-01, time/batch = 0.6953s	
19002/30300 (epoch 31.356), train_loss = 1.19253012, grad/param norm = 2.1445e-01, time/batch = 0.6870s	
19003/30300 (epoch 31.358), train_loss = 1.34802359, grad/param norm = 1.5841e-01, time/batch = 0.6854s	
19004/30300 (epoch 31.360), train_loss = 1.06689328, grad/param norm = 1.9564e-01, time/batch = 0.6846s	
19005/30300 (epoch 31.361), train_loss = 1.10650232, grad/param norm = 1.6890e-01, time/batch = 0.6910s	
19006/30300 (epoch 31.363), train_loss = 1.16203402, grad/param norm = 1.7232e-01, time/batch = 0.6861s	
19007/30300 (epoch 31.365), train_loss = 1.00259246, grad/param norm = 1.9863e-01, time/batch = 0.6865s	
19008/30300 (epoch 31.366), train_loss = 1.07483818, grad/param norm = 1.5745e-01, time/batch = 0.6886s	
19009/30300 (epoch 31.368), train_loss = 0.95877628, grad/param norm = 1.4588e-01, time/batch = 0.6841s	
19010/30300 (epoch 31.370), train_loss = 1.04944640, grad/param norm = 1.7659e-01, time/batch = 0.6844s	
19011/30300 (epoch 31.371), train_loss = 1.17933441, grad/param norm = 1.6525e-01, time/batch = 0.6823s	
19012/30300 (epoch 31.373), train_loss = 1.03465669, grad/param norm = 1.5027e-01, time/batch = 0.6823s	
19013/30300 (epoch 31.375), train_loss = 1.03199502, grad/param norm = 1.4264e-01, time/batch = 0.6885s	
19014/30300 (epoch 31.376), train_loss = 1.03347052, grad/param norm = 1.5451e-01, time/batch = 0.6818s	
19015/30300 (epoch 31.378), train_loss = 1.01388768, grad/param norm = 1.5394e-01, time/batch = 0.7145s	
19016/30300 (epoch 31.380), train_loss = 1.23018946, grad/param norm = 1.8572e-01, time/batch = 0.7170s	
19017/30300 (epoch 31.381), train_loss = 0.94463159, grad/param norm = 1.9696e-01, time/batch = 0.6826s	
19018/30300 (epoch 31.383), train_loss = 1.02342292, grad/param norm = 1.9057e-01, time/batch = 0.6809s	
19019/30300 (epoch 31.384), train_loss = 1.15952101, grad/param norm = 1.7054e-01, time/batch = 0.6839s	
19020/30300 (epoch 31.386), train_loss = 0.98632017, grad/param norm = 1.5574e-01, time/batch = 0.6834s	
19021/30300 (epoch 31.388), train_loss = 0.95889714, grad/param norm = 1.4448e-01, time/batch = 0.6845s	
19022/30300 (epoch 31.389), train_loss = 1.08787588, grad/param norm = 1.6854e-01, time/batch = 0.6922s	
19023/30300 (epoch 31.391), train_loss = 1.13853959, grad/param norm = 1.5484e-01, time/batch = 0.6980s	
19024/30300 (epoch 31.393), train_loss = 0.96191528, grad/param norm = 1.5249e-01, time/batch = 0.6847s	
19025/30300 (epoch 31.394), train_loss = 1.15152252, grad/param norm = 1.6200e-01, time/batch = 0.6824s	
19026/30300 (epoch 31.396), train_loss = 1.21569325, grad/param norm = 1.5579e-01, time/batch = 0.7093s	
19027/30300 (epoch 31.398), train_loss = 1.06718611, grad/param norm = 2.1608e-01, time/batch = 0.6819s	
19028/30300 (epoch 31.399), train_loss = 1.03676473, grad/param norm = 1.4322e-01, time/batch = 0.6843s	
19029/30300 (epoch 31.401), train_loss = 1.17122639, grad/param norm = 2.4401e-01, time/batch = 0.6918s	
19030/30300 (epoch 31.403), train_loss = 1.09135103, grad/param norm = 1.6310e-01, time/batch = 0.7253s	
19031/30300 (epoch 31.404), train_loss = 1.04638220, grad/param norm = 1.8690e-01, time/batch = 0.6885s	
19032/30300 (epoch 31.406), train_loss = 1.11731069, grad/param norm = 1.5081e-01, time/batch = 0.6816s	
19033/30300 (epoch 31.408), train_loss = 0.98050804, grad/param norm = 1.4865e-01, time/batch = 0.6815s	
19034/30300 (epoch 31.409), train_loss = 0.96781908, grad/param norm = 1.5324e-01, time/batch = 0.6838s	
19035/30300 (epoch 31.411), train_loss = 1.02423421, grad/param norm = 1.5404e-01, time/batch = 0.6868s	
19036/30300 (epoch 31.413), train_loss = 0.92282901, grad/param norm = 1.5668e-01, time/batch = 0.6853s	
19037/30300 (epoch 31.414), train_loss = 1.15317765, grad/param norm = 1.6593e-01, time/batch = 0.6804s	
19038/30300 (epoch 31.416), train_loss = 1.03958677, grad/param norm = 1.5101e-01, time/batch = 0.6817s	
19039/30300 (epoch 31.417), train_loss = 1.00419820, grad/param norm = 1.6538e-01, time/batch = 0.6910s	
19040/30300 (epoch 31.419), train_loss = 0.99888132, grad/param norm = 1.6520e-01, time/batch = 0.6937s	
19041/30300 (epoch 31.421), train_loss = 1.05679654, grad/param norm = 1.9784e-01, time/batch = 0.7076s	
19042/30300 (epoch 31.422), train_loss = 1.10604763, grad/param norm = 1.7287e-01, time/batch = 0.7408s	
19043/30300 (epoch 31.424), train_loss = 1.11991715, grad/param norm = 1.7301e-01, time/batch = 0.7436s	
19044/30300 (epoch 31.426), train_loss = 1.04598387, grad/param norm = 1.6514e-01, time/batch = 0.7003s	
19045/30300 (epoch 31.427), train_loss = 1.02426376, grad/param norm = 1.6892e-01, time/batch = 0.6806s	
19046/30300 (epoch 31.429), train_loss = 1.06870248, grad/param norm = 1.5096e-01, time/batch = 0.6919s	
19047/30300 (epoch 31.431), train_loss = 1.14452428, grad/param norm = 1.6636e-01, time/batch = 0.6906s	
19048/30300 (epoch 31.432), train_loss = 1.06196239, grad/param norm = 1.5265e-01, time/batch = 0.6944s	
19049/30300 (epoch 31.434), train_loss = 0.97936411, grad/param norm = 1.7878e-01, time/batch = 0.6933s	
19050/30300 (epoch 31.436), train_loss = 1.22448275, grad/param norm = 1.6665e-01, time/batch = 0.6879s	
19051/30300 (epoch 31.437), train_loss = 0.99533188, grad/param norm = 1.5984e-01, time/batch = 0.6890s	
19052/30300 (epoch 31.439), train_loss = 1.02967858, grad/param norm = 1.5244e-01, time/batch = 0.6868s	
19053/30300 (epoch 31.441), train_loss = 1.06695556, grad/param norm = 1.5135e-01, time/batch = 0.6840s	
19054/30300 (epoch 31.442), train_loss = 1.01471792, grad/param norm = 1.7397e-01, time/batch = 0.6821s	
19055/30300 (epoch 31.444), train_loss = 0.92127696, grad/param norm = 1.5996e-01, time/batch = 0.6804s	
19056/30300 (epoch 31.446), train_loss = 1.05486757, grad/param norm = 1.4320e-01, time/batch = 0.6802s	
19057/30300 (epoch 31.447), train_loss = 1.08856740, grad/param norm = 1.6382e-01, time/batch = 0.6808s	
19058/30300 (epoch 31.449), train_loss = 1.02223627, grad/param norm = 1.6548e-01, time/batch = 0.6854s	
19059/30300 (epoch 31.450), train_loss = 1.12036561, grad/param norm = 1.5024e-01, time/batch = 0.6861s	
19060/30300 (epoch 31.452), train_loss = 1.21007288, grad/param norm = 1.6855e-01, time/batch = 0.6844s	
19061/30300 (epoch 31.454), train_loss = 1.14874572, grad/param norm = 1.5552e-01, time/batch = 0.6987s	
19062/30300 (epoch 31.455), train_loss = 1.08718323, grad/param norm = 1.6818e-01, time/batch = 0.7051s	
19063/30300 (epoch 31.457), train_loss = 1.06174147, grad/param norm = 1.5743e-01, time/batch = 0.7297s	
19064/30300 (epoch 31.459), train_loss = 1.14242532, grad/param norm = 1.7238e-01, time/batch = 0.7062s	
19065/30300 (epoch 31.460), train_loss = 1.14559282, grad/param norm = 1.6256e-01, time/batch = 0.7187s	
19066/30300 (epoch 31.462), train_loss = 1.16927619, grad/param norm = 1.8234e-01, time/batch = 0.7088s	
19067/30300 (epoch 31.464), train_loss = 0.91786977, grad/param norm = 1.6861e-01, time/batch = 0.7329s	
19068/30300 (epoch 31.465), train_loss = 0.91608589, grad/param norm = 1.3909e-01, time/batch = 0.7126s	
19069/30300 (epoch 31.467), train_loss = 0.91279574, grad/param norm = 1.4771e-01, time/batch = 0.6998s	
19070/30300 (epoch 31.469), train_loss = 1.01209891, grad/param norm = 1.5123e-01, time/batch = 0.7006s	
19071/30300 (epoch 31.470), train_loss = 1.04143364, grad/param norm = 1.6888e-01, time/batch = 0.7111s	
19072/30300 (epoch 31.472), train_loss = 1.04238806, grad/param norm = 1.4568e-01, time/batch = 0.7066s	
19073/30300 (epoch 31.474), train_loss = 1.05095782, grad/param norm = 2.1236e-01, time/batch = 0.7023s	
19074/30300 (epoch 31.475), train_loss = 1.02448709, grad/param norm = 1.5594e-01, time/batch = 0.6938s	
19075/30300 (epoch 31.477), train_loss = 1.07977755, grad/param norm = 1.4948e-01, time/batch = 0.6853s	
19076/30300 (epoch 31.479), train_loss = 1.04608119, grad/param norm = 1.6098e-01, time/batch = 0.6861s	
19077/30300 (epoch 31.480), train_loss = 1.09476119, grad/param norm = 1.5077e-01, time/batch = 0.7261s	
19078/30300 (epoch 31.482), train_loss = 1.13701488, grad/param norm = 1.5386e-01, time/batch = 0.6991s	
19079/30300 (epoch 31.483), train_loss = 1.05097424, grad/param norm = 1.6347e-01, time/batch = 0.6813s	
19080/30300 (epoch 31.485), train_loss = 1.09765818, grad/param norm = 1.6619e-01, time/batch = 0.6873s	
19081/30300 (epoch 31.487), train_loss = 1.18407518, grad/param norm = 1.7178e-01, time/batch = 0.6879s	
19082/30300 (epoch 31.488), train_loss = 1.19615666, grad/param norm = 1.4862e-01, time/batch = 0.6791s	
19083/30300 (epoch 31.490), train_loss = 0.96577630, grad/param norm = 1.5905e-01, time/batch = 0.6851s	
19084/30300 (epoch 31.492), train_loss = 1.06278753, grad/param norm = 1.7020e-01, time/batch = 0.6832s	
19085/30300 (epoch 31.493), train_loss = 1.06757147, grad/param norm = 1.5275e-01, time/batch = 0.6832s	
19086/30300 (epoch 31.495), train_loss = 1.06441617, grad/param norm = 1.4786e-01, time/batch = 0.6846s	
19087/30300 (epoch 31.497), train_loss = 1.09043268, grad/param norm = 1.4578e-01, time/batch = 0.6857s	
19088/30300 (epoch 31.498), train_loss = 1.13926020, grad/param norm = 1.6542e-01, time/batch = 0.6831s	
19089/30300 (epoch 31.500), train_loss = 1.06819417, grad/param norm = 1.6695e-01, time/batch = 0.6813s	
19090/30300 (epoch 31.502), train_loss = 1.06742496, grad/param norm = 1.7009e-01, time/batch = 0.6804s	
19091/30300 (epoch 31.503), train_loss = 1.17215859, grad/param norm = 1.5294e-01, time/batch = 0.7127s	
19092/30300 (epoch 31.505), train_loss = 0.97636722, grad/param norm = 1.3524e-01, time/batch = 0.7140s	
19093/30300 (epoch 31.507), train_loss = 0.98788115, grad/param norm = 1.6400e-01, time/batch = 0.6833s	
19094/30300 (epoch 31.508), train_loss = 1.02492762, grad/param norm = 1.7517e-01, time/batch = 0.6818s	
19095/30300 (epoch 31.510), train_loss = 1.15835602, grad/param norm = 1.8025e-01, time/batch = 0.6817s	
19096/30300 (epoch 31.512), train_loss = 1.01400585, grad/param norm = 1.4446e-01, time/batch = 0.6839s	
19097/30300 (epoch 31.513), train_loss = 1.09236592, grad/param norm = 1.5547e-01, time/batch = 0.6818s	
19098/30300 (epoch 31.515), train_loss = 1.08182360, grad/param norm = 1.5730e-01, time/batch = 0.6808s	
19099/30300 (epoch 31.517), train_loss = 0.90199557, grad/param norm = 1.4867e-01, time/batch = 0.6832s	
19100/30300 (epoch 31.518), train_loss = 1.16346850, grad/param norm = 1.7947e-01, time/batch = 0.6881s	
19101/30300 (epoch 31.520), train_loss = 1.11700149, grad/param norm = 1.7803e-01, time/batch = 0.6854s	
19102/30300 (epoch 31.521), train_loss = 0.99919748, grad/param norm = 1.8028e-01, time/batch = 0.6854s	
19103/30300 (epoch 31.523), train_loss = 1.23788926, grad/param norm = 2.2003e-01, time/batch = 0.6843s	
19104/30300 (epoch 31.525), train_loss = 1.01452888, grad/param norm = 1.7080e-01, time/batch = 0.6857s	
19105/30300 (epoch 31.526), train_loss = 1.09848048, grad/param norm = 1.7153e-01, time/batch = 0.6826s	
19106/30300 (epoch 31.528), train_loss = 0.97674015, grad/param norm = 1.5969e-01, time/batch = 0.6870s	
19107/30300 (epoch 31.530), train_loss = 0.95390598, grad/param norm = 1.5168e-01, time/batch = 0.6823s	
19108/30300 (epoch 31.531), train_loss = 1.11020506, grad/param norm = 1.5724e-01, time/batch = 0.6805s	
19109/30300 (epoch 31.533), train_loss = 1.06972516, grad/param norm = 1.8498e-01, time/batch = 0.6839s	
19110/30300 (epoch 31.535), train_loss = 1.03726804, grad/param norm = 1.3866e-01, time/batch = 0.6817s	
19111/30300 (epoch 31.536), train_loss = 1.10533902, grad/param norm = 1.6712e-01, time/batch = 0.6866s	
19112/30300 (epoch 31.538), train_loss = 0.96769603, grad/param norm = 1.9387e-01, time/batch = 0.6844s	
19113/30300 (epoch 31.540), train_loss = 1.02496956, grad/param norm = 1.7986e-01, time/batch = 0.6839s	
19114/30300 (epoch 31.541), train_loss = 1.08908357, grad/param norm = 1.8013e-01, time/batch = 0.7013s	
19115/30300 (epoch 31.543), train_loss = 1.06997863, grad/param norm = 1.5732e-01, time/batch = 0.7240s	
19116/30300 (epoch 31.545), train_loss = 1.11438377, grad/param norm = 2.1069e-01, time/batch = 0.6840s	
19117/30300 (epoch 31.546), train_loss = 1.27796228, grad/param norm = 1.6787e-01, time/batch = 0.6832s	
19118/30300 (epoch 31.548), train_loss = 1.01546533, grad/param norm = 1.3929e-01, time/batch = 0.6826s	
19119/30300 (epoch 31.550), train_loss = 1.11345325, grad/param norm = 1.7500e-01, time/batch = 0.6823s	
19120/30300 (epoch 31.551), train_loss = 1.03002238, grad/param norm = 1.6665e-01, time/batch = 0.6814s	
19121/30300 (epoch 31.553), train_loss = 1.02997929, grad/param norm = 1.5447e-01, time/batch = 0.6834s	
19122/30300 (epoch 31.554), train_loss = 1.08162222, grad/param norm = 1.6340e-01, time/batch = 0.6826s	
19123/30300 (epoch 31.556), train_loss = 1.12614385, grad/param norm = 1.6378e-01, time/batch = 0.6814s	
19124/30300 (epoch 31.558), train_loss = 1.14425904, grad/param norm = 1.7334e-01, time/batch = 0.6835s	
19125/30300 (epoch 31.559), train_loss = 1.08916081, grad/param norm = 1.5841e-01, time/batch = 0.6837s	
19126/30300 (epoch 31.561), train_loss = 0.88934953, grad/param norm = 1.5062e-01, time/batch = 0.6858s	
19127/30300 (epoch 31.563), train_loss = 0.97824418, grad/param norm = 1.5731e-01, time/batch = 0.6861s	
19128/30300 (epoch 31.564), train_loss = 1.01320529, grad/param norm = 1.4381e-01, time/batch = 0.6810s	
19129/30300 (epoch 31.566), train_loss = 1.05674886, grad/param norm = 1.5098e-01, time/batch = 0.7239s	
19130/30300 (epoch 31.568), train_loss = 0.92389842, grad/param norm = 1.7925e-01, time/batch = 0.7096s	
19131/30300 (epoch 31.569), train_loss = 1.11221435, grad/param norm = 1.6598e-01, time/batch = 0.6886s	
19132/30300 (epoch 31.571), train_loss = 1.06875654, grad/param norm = 1.5595e-01, time/batch = 0.6854s	
19133/30300 (epoch 31.573), train_loss = 1.11301575, grad/param norm = 1.6263e-01, time/batch = 0.6848s	
19134/30300 (epoch 31.574), train_loss = 1.11870618, grad/param norm = 1.5143e-01, time/batch = 0.6832s	
19135/30300 (epoch 31.576), train_loss = 1.02822889, grad/param norm = 1.4846e-01, time/batch = 0.6809s	
19136/30300 (epoch 31.578), train_loss = 0.95060566, grad/param norm = 1.7363e-01, time/batch = 0.6828s	
19137/30300 (epoch 31.579), train_loss = 1.10669801, grad/param norm = 1.7722e-01, time/batch = 0.6835s	
19138/30300 (epoch 31.581), train_loss = 1.19733543, grad/param norm = 1.6281e-01, time/batch = 0.6866s	
19139/30300 (epoch 31.583), train_loss = 1.23919213, grad/param norm = 1.8234e-01, time/batch = 0.6830s	
19140/30300 (epoch 31.584), train_loss = 1.19078167, grad/param norm = 1.6459e-01, time/batch = 0.6834s	
19141/30300 (epoch 31.586), train_loss = 1.04792315, grad/param norm = 1.6787e-01, time/batch = 0.6854s	
19142/30300 (epoch 31.587), train_loss = 1.06212361, grad/param norm = 1.6227e-01, time/batch = 0.6845s	
19143/30300 (epoch 31.589), train_loss = 1.00434988, grad/param norm = 1.5653e-01, time/batch = 0.6843s	
19144/30300 (epoch 31.591), train_loss = 1.10112447, grad/param norm = 1.5106e-01, time/batch = 0.6839s	
19145/30300 (epoch 31.592), train_loss = 1.04745726, grad/param norm = 1.4999e-01, time/batch = 0.6827s	
19146/30300 (epoch 31.594), train_loss = 1.09641168, grad/param norm = 1.7238e-01, time/batch = 0.6850s	
19147/30300 (epoch 31.596), train_loss = 0.97900990, grad/param norm = 1.4510e-01, time/batch = 0.6877s	
19148/30300 (epoch 31.597), train_loss = 1.02258270, grad/param norm = 1.7575e-01, time/batch = 0.7256s	
19149/30300 (epoch 31.599), train_loss = 0.90491050, grad/param norm = 1.4185e-01, time/batch = 0.6951s	
19150/30300 (epoch 31.601), train_loss = 1.09054128, grad/param norm = 1.5363e-01, time/batch = 0.6977s	
19151/30300 (epoch 31.602), train_loss = 1.05482229, grad/param norm = 1.5015e-01, time/batch = 0.7031s	
19152/30300 (epoch 31.604), train_loss = 0.99526931, grad/param norm = 1.5304e-01, time/batch = 0.6925s	
19153/30300 (epoch 31.606), train_loss = 1.02800307, grad/param norm = 2.4692e-01, time/batch = 0.7067s	
19154/30300 (epoch 31.607), train_loss = 1.16097970, grad/param norm = 2.0641e-01, time/batch = 0.6840s	
19155/30300 (epoch 31.609), train_loss = 1.28820688, grad/param norm = 1.9837e-01, time/batch = 0.7010s	
19156/30300 (epoch 31.611), train_loss = 1.02650081, grad/param norm = 1.5665e-01, time/batch = 0.6941s	
19157/30300 (epoch 31.612), train_loss = 0.97365343, grad/param norm = 1.4305e-01, time/batch = 0.6819s	
19158/30300 (epoch 31.614), train_loss = 1.04832009, grad/param norm = 1.5617e-01, time/batch = 0.6809s	
19159/30300 (epoch 31.616), train_loss = 1.11054003, grad/param norm = 1.9889e-01, time/batch = 0.6919s	
19160/30300 (epoch 31.617), train_loss = 1.10100994, grad/param norm = 1.6871e-01, time/batch = 0.6855s	
19161/30300 (epoch 31.619), train_loss = 0.89855583, grad/param norm = 1.4470e-01, time/batch = 0.6830s	
19162/30300 (epoch 31.620), train_loss = 1.13063165, grad/param norm = 1.5878e-01, time/batch = 0.6839s	
19163/30300 (epoch 31.622), train_loss = 1.07923765, grad/param norm = 1.7749e-01, time/batch = 0.6819s	
19164/30300 (epoch 31.624), train_loss = 1.05168169, grad/param norm = 1.5144e-01, time/batch = 0.6801s	
19165/30300 (epoch 31.625), train_loss = 1.04290765, grad/param norm = 1.8071e-01, time/batch = 0.6818s	
19166/30300 (epoch 31.627), train_loss = 1.18030010, grad/param norm = 1.6920e-01, time/batch = 0.6999s	
19167/30300 (epoch 31.629), train_loss = 1.22281181, grad/param norm = 1.6349e-01, time/batch = 0.7241s	
19168/30300 (epoch 31.630), train_loss = 1.09913492, grad/param norm = 1.6935e-01, time/batch = 0.6807s	
19169/30300 (epoch 31.632), train_loss = 1.14384832, grad/param norm = 1.7968e-01, time/batch = 0.6832s	
19170/30300 (epoch 31.634), train_loss = 1.00968979, grad/param norm = 1.4104e-01, time/batch = 0.6811s	
19171/30300 (epoch 31.635), train_loss = 1.12929715, grad/param norm = 1.7489e-01, time/batch = 0.6875s	
19172/30300 (epoch 31.637), train_loss = 1.15465559, grad/param norm = 1.7262e-01, time/batch = 0.6833s	
19173/30300 (epoch 31.639), train_loss = 1.04743958, grad/param norm = 1.6776e-01, time/batch = 0.6807s	
19174/30300 (epoch 31.640), train_loss = 1.17541689, grad/param norm = 1.9085e-01, time/batch = 0.6849s	
19175/30300 (epoch 31.642), train_loss = 1.03968507, grad/param norm = 1.3667e-01, time/batch = 0.6859s	
19176/30300 (epoch 31.644), train_loss = 1.14720045, grad/param norm = 1.6262e-01, time/batch = 0.6825s	
19177/30300 (epoch 31.645), train_loss = 1.00814782, grad/param norm = 1.4059e-01, time/batch = 0.6900s	
19178/30300 (epoch 31.647), train_loss = 1.10374038, grad/param norm = 1.4848e-01, time/batch = 0.6906s	
19179/30300 (epoch 31.649), train_loss = 1.05836131, grad/param norm = 2.1150e-01, time/batch = 0.6848s	
19180/30300 (epoch 31.650), train_loss = 1.07115007, grad/param norm = 1.5178e-01, time/batch = 0.6874s	
19181/30300 (epoch 31.652), train_loss = 1.02812257, grad/param norm = 2.2043e-01, time/batch = 0.7001s	
19182/30300 (epoch 31.653), train_loss = 1.24917897, grad/param norm = 1.6310e-01, time/batch = 0.6845s	
19183/30300 (epoch 31.655), train_loss = 1.03615761, grad/param norm = 1.6371e-01, time/batch = 0.6829s	
19184/30300 (epoch 31.657), train_loss = 1.02119655, grad/param norm = 1.8991e-01, time/batch = 0.6850s	
19185/30300 (epoch 31.658), train_loss = 1.00998647, grad/param norm = 1.5171e-01, time/batch = 0.6919s	
19186/30300 (epoch 31.660), train_loss = 1.08722006, grad/param norm = 1.6442e-01, time/batch = 0.6948s	
19187/30300 (epoch 31.662), train_loss = 1.09141412, grad/param norm = 1.9987e-01, time/batch = 0.6877s	
19188/30300 (epoch 31.663), train_loss = 1.12701533, grad/param norm = 1.6177e-01, time/batch = 0.6815s	
19189/30300 (epoch 31.665), train_loss = 1.03998204, grad/param norm = 2.0124e-01, time/batch = 0.6823s	
19190/30300 (epoch 31.667), train_loss = 1.14307845, grad/param norm = 1.8844e-01, time/batch = 0.6828s	
19191/30300 (epoch 31.668), train_loss = 1.18010126, grad/param norm = 1.8911e-01, time/batch = 0.6960s	
19192/30300 (epoch 31.670), train_loss = 1.21211513, grad/param norm = 1.8729e-01, time/batch = 0.6944s	
19193/30300 (epoch 31.672), train_loss = 1.09193765, grad/param norm = 1.7811e-01, time/batch = 0.6901s	
19194/30300 (epoch 31.673), train_loss = 1.12135337, grad/param norm = 1.6820e-01, time/batch = 0.6832s	
19195/30300 (epoch 31.675), train_loss = 1.03219226, grad/param norm = 1.6829e-01, time/batch = 0.6837s	
19196/30300 (epoch 31.677), train_loss = 1.03926090, grad/param norm = 1.5109e-01, time/batch = 0.6822s	
19197/30300 (epoch 31.678), train_loss = 1.01174143, grad/param norm = 1.4330e-01, time/batch = 0.6892s	
19198/30300 (epoch 31.680), train_loss = 0.91599664, grad/param norm = 1.5422e-01, time/batch = 0.7024s	
19199/30300 (epoch 31.682), train_loss = 1.06588847, grad/param norm = 1.6914e-01, time/batch = 0.7022s	
19200/30300 (epoch 31.683), train_loss = 1.17039353, grad/param norm = 1.5301e-01, time/batch = 0.7312s	
19201/30300 (epoch 31.685), train_loss = 1.15641298, grad/param norm = 1.8535e-01, time/batch = 0.7203s	
19202/30300 (epoch 31.686), train_loss = 1.02689710, grad/param norm = 1.4209e-01, time/batch = 0.7092s	
19203/30300 (epoch 31.688), train_loss = 1.06429050, grad/param norm = 1.4506e-01, time/batch = 0.7003s	
19204/30300 (epoch 31.690), train_loss = 1.03251439, grad/param norm = 1.7167e-01, time/batch = 0.6876s	
19205/30300 (epoch 31.691), train_loss = 1.11195766, grad/param norm = 1.5709e-01, time/batch = 0.6822s	
19206/30300 (epoch 31.693), train_loss = 1.36297262, grad/param norm = 1.8419e-01, time/batch = 0.6816s	
19207/30300 (epoch 31.695), train_loss = 1.16146536, grad/param norm = 2.1712e-01, time/batch = 0.6799s	
19208/30300 (epoch 31.696), train_loss = 1.16767854, grad/param norm = 2.1067e-01, time/batch = 0.6826s	
19209/30300 (epoch 31.698), train_loss = 1.03191382, grad/param norm = 1.7006e-01, time/batch = 0.6803s	
19210/30300 (epoch 31.700), train_loss = 1.01642052, grad/param norm = 1.6314e-01, time/batch = 0.6816s	
19211/30300 (epoch 31.701), train_loss = 0.93284006, grad/param norm = 1.5580e-01, time/batch = 0.6831s	
19212/30300 (epoch 31.703), train_loss = 1.08269222, grad/param norm = 1.5436e-01, time/batch = 0.6801s	
19213/30300 (epoch 31.705), train_loss = 1.01413033, grad/param norm = 1.5121e-01, time/batch = 0.6794s	
19214/30300 (epoch 31.706), train_loss = 1.12356733, grad/param norm = 1.6216e-01, time/batch = 0.6818s	
19215/30300 (epoch 31.708), train_loss = 1.08144787, grad/param norm = 1.6042e-01, time/batch = 0.6808s	
19216/30300 (epoch 31.710), train_loss = 1.05230513, grad/param norm = 1.5717e-01, time/batch = 0.6810s	
19217/30300 (epoch 31.711), train_loss = 1.00670215, grad/param norm = 1.6216e-01, time/batch = 0.6855s	
19218/30300 (epoch 31.713), train_loss = 1.00076896, grad/param norm = 1.7821e-01, time/batch = 0.6814s	
19219/30300 (epoch 31.715), train_loss = 1.01775594, grad/param norm = 1.4755e-01, time/batch = 0.6847s	
19220/30300 (epoch 31.716), train_loss = 1.15676818, grad/param norm = 1.6105e-01, time/batch = 0.6828s	
19221/30300 (epoch 31.718), train_loss = 1.18872929, grad/param norm = 1.6241e-01, time/batch = 0.6834s	
19222/30300 (epoch 31.719), train_loss = 1.01804565, grad/param norm = 1.8111e-01, time/batch = 0.6832s	
19223/30300 (epoch 31.721), train_loss = 1.06110206, grad/param norm = 1.8712e-01, time/batch = 0.6828s	
19224/30300 (epoch 31.723), train_loss = 1.02258614, grad/param norm = 1.8301e-01, time/batch = 0.6925s	
19225/30300 (epoch 31.724), train_loss = 1.11643203, grad/param norm = 1.8820e-01, time/batch = 0.6899s	
19226/30300 (epoch 31.726), train_loss = 1.38247170, grad/param norm = 2.1933e-01, time/batch = 0.6803s	
19227/30300 (epoch 31.728), train_loss = 1.12636617, grad/param norm = 1.6034e-01, time/batch = 0.6806s	
19228/30300 (epoch 31.729), train_loss = 1.04201262, grad/param norm = 1.8332e-01, time/batch = 0.6859s	
19229/30300 (epoch 31.731), train_loss = 1.08834299, grad/param norm = 1.8765e-01, time/batch = 0.6808s	
19230/30300 (epoch 31.733), train_loss = 1.08498935, grad/param norm = 1.5784e-01, time/batch = 0.6812s	
19231/30300 (epoch 31.734), train_loss = 1.16043256, grad/param norm = 1.5115e-01, time/batch = 0.6858s	
19232/30300 (epoch 31.736), train_loss = 1.07733333, grad/param norm = 1.5853e-01, time/batch = 0.6834s	
19233/30300 (epoch 31.738), train_loss = 1.01098934, grad/param norm = 1.3845e-01, time/batch = 0.6838s	
19234/30300 (epoch 31.739), train_loss = 1.16886849, grad/param norm = 1.7147e-01, time/batch = 0.6856s	
19235/30300 (epoch 31.741), train_loss = 1.23381165, grad/param norm = 1.5555e-01, time/batch = 0.6819s	
19236/30300 (epoch 31.743), train_loss = 1.06743912, grad/param norm = 1.6556e-01, time/batch = 0.6792s	
19237/30300 (epoch 31.744), train_loss = 1.10709358, grad/param norm = 1.5500e-01, time/batch = 0.7128s	
19238/30300 (epoch 31.746), train_loss = 1.02984595, grad/param norm = 1.4389e-01, time/batch = 0.7252s	
19239/30300 (epoch 31.748), train_loss = 1.07721543, grad/param norm = 2.0760e-01, time/batch = 0.6967s	
19240/30300 (epoch 31.749), train_loss = 1.11637917, grad/param norm = 1.8593e-01, time/batch = 0.7077s	
19241/30300 (epoch 31.751), train_loss = 1.10143582, grad/param norm = 1.7209e-01, time/batch = 0.6951s	
19242/30300 (epoch 31.752), train_loss = 1.05474335, grad/param norm = 1.6914e-01, time/batch = 0.6840s	
19243/30300 (epoch 31.754), train_loss = 1.03093038, grad/param norm = 1.4628e-01, time/batch = 0.6836s	
19244/30300 (epoch 31.756), train_loss = 1.04722174, grad/param norm = 1.5286e-01, time/batch = 0.6880s	
19245/30300 (epoch 31.757), train_loss = 1.03572502, grad/param norm = 1.6683e-01, time/batch = 0.6863s	
19246/30300 (epoch 31.759), train_loss = 1.12412639, grad/param norm = 1.6018e-01, time/batch = 0.6877s	
19247/30300 (epoch 31.761), train_loss = 0.94247398, grad/param norm = 1.4643e-01, time/batch = 0.6866s	
19248/30300 (epoch 31.762), train_loss = 0.96705578, grad/param norm = 1.4788e-01, time/batch = 0.6882s	
19249/30300 (epoch 31.764), train_loss = 1.06455498, grad/param norm = 1.6853e-01, time/batch = 0.7022s	
19250/30300 (epoch 31.766), train_loss = 1.19461847, grad/param norm = 1.7397e-01, time/batch = 0.6825s	
19251/30300 (epoch 31.767), train_loss = 1.13735405, grad/param norm = 2.1114e-01, time/batch = 0.6942s	
19252/30300 (epoch 31.769), train_loss = 1.11341229, grad/param norm = 1.7389e-01, time/batch = 0.7267s	
19253/30300 (epoch 31.771), train_loss = 1.04954578, grad/param norm = 2.0808e-01, time/batch = 0.6943s	
19254/30300 (epoch 31.772), train_loss = 1.10725308, grad/param norm = 1.6851e-01, time/batch = 0.6853s	
19255/30300 (epoch 31.774), train_loss = 1.20868583, grad/param norm = 1.6153e-01, time/batch = 0.6833s	
19256/30300 (epoch 31.776), train_loss = 1.05029565, grad/param norm = 1.6361e-01, time/batch = 0.6839s	
19257/30300 (epoch 31.777), train_loss = 1.18590152, grad/param norm = 1.5662e-01, time/batch = 0.6833s	
19258/30300 (epoch 31.779), train_loss = 1.20643054, grad/param norm = 1.7833e-01, time/batch = 0.6825s	
19259/30300 (epoch 31.781), train_loss = 1.09217632, grad/param norm = 1.8168e-01, time/batch = 0.6836s	
19260/30300 (epoch 31.782), train_loss = 1.02704708, grad/param norm = 1.6286e-01, time/batch = 0.6840s	
19261/30300 (epoch 31.784), train_loss = 1.02154722, grad/param norm = 1.5623e-01, time/batch = 0.6974s	
19262/30300 (epoch 31.785), train_loss = 1.18808463, grad/param norm = 1.8454e-01, time/batch = 0.6938s	
19263/30300 (epoch 31.787), train_loss = 0.90846875, grad/param norm = 1.6961e-01, time/batch = 0.6869s	
19264/30300 (epoch 31.789), train_loss = 1.25067546, grad/param norm = 1.7472e-01, time/batch = 0.6830s	
19265/30300 (epoch 31.790), train_loss = 1.11926493, grad/param norm = 1.9871e-01, time/batch = 0.6928s	
19266/30300 (epoch 31.792), train_loss = 0.88871768, grad/param norm = 1.5547e-01, time/batch = 0.6899s	
19267/30300 (epoch 31.794), train_loss = 1.07991872, grad/param norm = 1.8168e-01, time/batch = 0.6857s	
19268/30300 (epoch 31.795), train_loss = 0.99703596, grad/param norm = 1.5092e-01, time/batch = 0.6819s	
19269/30300 (epoch 31.797), train_loss = 1.23240109, grad/param norm = 1.8802e-01, time/batch = 0.6841s	
19270/30300 (epoch 31.799), train_loss = 1.16484163, grad/param norm = 2.0244e-01, time/batch = 0.6989s	
19271/30300 (epoch 31.800), train_loss = 1.15532125, grad/param norm = 1.6718e-01, time/batch = 0.7274s	
19272/30300 (epoch 31.802), train_loss = 1.33392851, grad/param norm = 1.8770e-01, time/batch = 0.6972s	
19273/30300 (epoch 31.804), train_loss = 1.14809923, grad/param norm = 1.7821e-01, time/batch = 0.7122s	
19274/30300 (epoch 31.805), train_loss = 1.22121505, grad/param norm = 1.7233e-01, time/batch = 0.6938s	
19275/30300 (epoch 31.807), train_loss = 1.05168072, grad/param norm = 1.9183e-01, time/batch = 0.6841s	
19276/30300 (epoch 31.809), train_loss = 1.16711377, grad/param norm = 1.8230e-01, time/batch = 0.6858s	
19277/30300 (epoch 31.810), train_loss = 1.13359665, grad/param norm = 1.5967e-01, time/batch = 0.6886s	
19278/30300 (epoch 31.812), train_loss = 1.01657503, grad/param norm = 1.6358e-01, time/batch = 0.6845s	
19279/30300 (epoch 31.814), train_loss = 1.07826681, grad/param norm = 1.5809e-01, time/batch = 0.6862s	
19280/30300 (epoch 31.815), train_loss = 1.08947881, grad/param norm = 1.7525e-01, time/batch = 0.6837s	
19281/30300 (epoch 31.817), train_loss = 1.17062192, grad/param norm = 1.8143e-01, time/batch = 0.6857s	
19282/30300 (epoch 31.818), train_loss = 1.10699251, grad/param norm = 1.6305e-01, time/batch = 0.6851s	
19283/30300 (epoch 31.820), train_loss = 1.25508837, grad/param norm = 1.7796e-01, time/batch = 0.6864s	
19284/30300 (epoch 31.822), train_loss = 1.24129426, grad/param norm = 2.0433e-01, time/batch = 0.6834s	
19285/30300 (epoch 31.823), train_loss = 1.25656577, grad/param norm = 1.9702e-01, time/batch = 0.6856s	
19286/30300 (epoch 31.825), train_loss = 1.21912211, grad/param norm = 1.8218e-01, time/batch = 0.6850s	
19287/30300 (epoch 31.827), train_loss = 0.93196020, grad/param norm = 1.7018e-01, time/batch = 0.6821s	
19288/30300 (epoch 31.828), train_loss = 1.17385290, grad/param norm = 1.7093e-01, time/batch = 0.6824s	
19289/30300 (epoch 31.830), train_loss = 1.12810535, grad/param norm = 1.6632e-01, time/batch = 0.6826s	
19290/30300 (epoch 31.832), train_loss = 1.01154210, grad/param norm = 1.6196e-01, time/batch = 0.6824s	
19291/30300 (epoch 31.833), train_loss = 1.10670742, grad/param norm = 1.6781e-01, time/batch = 0.6897s	
19292/30300 (epoch 31.835), train_loss = 1.00935467, grad/param norm = 1.6788e-01, time/batch = 0.6913s	
19293/30300 (epoch 31.837), train_loss = 0.97535058, grad/param norm = 1.4823e-01, time/batch = 0.6970s	
19294/30300 (epoch 31.838), train_loss = 0.98725881, grad/param norm = 1.5220e-01, time/batch = 0.7261s	
19295/30300 (epoch 31.840), train_loss = 1.17677487, grad/param norm = 1.5000e-01, time/batch = 0.6852s	
19296/30300 (epoch 31.842), train_loss = 1.04296585, grad/param norm = 1.5576e-01, time/batch = 0.6840s	
19297/30300 (epoch 31.843), train_loss = 1.12397280, grad/param norm = 1.8098e-01, time/batch = 0.6845s	
19298/30300 (epoch 31.845), train_loss = 1.15249610, grad/param norm = 1.5476e-01, time/batch = 0.6838s	
19299/30300 (epoch 31.847), train_loss = 1.10267184, grad/param norm = 1.5651e-01, time/batch = 0.6816s	
19300/30300 (epoch 31.848), train_loss = 1.15219335, grad/param norm = 1.6400e-01, time/batch = 0.6812s	
19301/30300 (epoch 31.850), train_loss = 1.08445365, grad/param norm = 1.5620e-01, time/batch = 0.6867s	
19302/30300 (epoch 31.851), train_loss = 1.11156010, grad/param norm = 1.8051e-01, time/batch = 0.6841s	
19303/30300 (epoch 31.853), train_loss = 1.03751672, grad/param norm = 1.5811e-01, time/batch = 0.7126s	
19304/30300 (epoch 31.855), train_loss = 1.04459857, grad/param norm = 1.5734e-01, time/batch = 0.6852s	
19305/30300 (epoch 31.856), train_loss = 1.09776120, grad/param norm = 1.6135e-01, time/batch = 0.6843s	
19306/30300 (epoch 31.858), train_loss = 1.01587790, grad/param norm = 1.3914e-01, time/batch = 0.6826s	
19307/30300 (epoch 31.860), train_loss = 1.00031532, grad/param norm = 1.5203e-01, time/batch = 0.6851s	
19308/30300 (epoch 31.861), train_loss = 1.24030079, grad/param norm = 1.6457e-01, time/batch = 0.6830s	
19309/30300 (epoch 31.863), train_loss = 1.07147033, grad/param norm = 1.5687e-01, time/batch = 0.6827s	
19310/30300 (epoch 31.865), train_loss = 1.14493831, grad/param norm = 1.7703e-01, time/batch = 0.6835s	
19311/30300 (epoch 31.866), train_loss = 1.16178777, grad/param norm = 1.6273e-01, time/batch = 0.6845s	
19312/30300 (epoch 31.868), train_loss = 1.09183843, grad/param norm = 1.7049e-01, time/batch = 0.7076s	
19313/30300 (epoch 31.870), train_loss = 1.02207951, grad/param norm = 1.5981e-01, time/batch = 0.7188s	
19314/30300 (epoch 31.871), train_loss = 1.08703744, grad/param norm = 1.5920e-01, time/batch = 0.6858s	
19315/30300 (epoch 31.873), train_loss = 1.07485057, grad/param norm = 1.4400e-01, time/batch = 0.6820s	
19316/30300 (epoch 31.875), train_loss = 1.05125766, grad/param norm = 1.4448e-01, time/batch = 0.6827s	
19317/30300 (epoch 31.876), train_loss = 0.97358563, grad/param norm = 1.7144e-01, time/batch = 0.6827s	
19318/30300 (epoch 31.878), train_loss = 0.92379308, grad/param norm = 1.5281e-01, time/batch = 0.6834s	
19319/30300 (epoch 31.880), train_loss = 1.00197463, grad/param norm = 1.7395e-01, time/batch = 0.6882s	
19320/30300 (epoch 31.881), train_loss = 1.23292206, grad/param norm = 1.9996e-01, time/batch = 0.7063s	
19321/30300 (epoch 31.883), train_loss = 1.15796275, grad/param norm = 1.7949e-01, time/batch = 0.7040s	
19322/30300 (epoch 31.884), train_loss = 1.05349891, grad/param norm = 1.4336e-01, time/batch = 0.6976s	
19323/30300 (epoch 31.886), train_loss = 1.13106258, grad/param norm = 1.7363e-01, time/batch = 0.7062s	
19324/30300 (epoch 31.888), train_loss = 1.07191778, grad/param norm = 1.6951e-01, time/batch = 0.7207s	
19325/30300 (epoch 31.889), train_loss = 1.11001924, grad/param norm = 1.5443e-01, time/batch = 0.7099s	
19326/30300 (epoch 31.891), train_loss = 1.06420186, grad/param norm = 1.5856e-01, time/batch = 0.6981s	
19327/30300 (epoch 31.893), train_loss = 1.28030561, grad/param norm = 1.6390e-01, time/batch = 0.7027s	
19328/30300 (epoch 31.894), train_loss = 1.12844888, grad/param norm = 1.6084e-01, time/batch = 0.6830s	
19329/30300 (epoch 31.896), train_loss = 0.92963146, grad/param norm = 1.4921e-01, time/batch = 0.6842s	
19330/30300 (epoch 31.898), train_loss = 0.93772016, grad/param norm = 1.5693e-01, time/batch = 0.6832s	
19331/30300 (epoch 31.899), train_loss = 0.99674354, grad/param norm = 1.6142e-01, time/batch = 0.7292s	
19332/30300 (epoch 31.901), train_loss = 1.10311621, grad/param norm = 1.8461e-01, time/batch = 0.6996s	
19333/30300 (epoch 31.903), train_loss = 1.09152312, grad/param norm = 1.8756e-01, time/batch = 0.6959s	
19334/30300 (epoch 31.904), train_loss = 1.09992324, grad/param norm = 1.6022e-01, time/batch = 0.7073s	
19335/30300 (epoch 31.906), train_loss = 1.12129655, grad/param norm = 1.8450e-01, time/batch = 0.6884s	
19336/30300 (epoch 31.908), train_loss = 1.02578117, grad/param norm = 1.4689e-01, time/batch = 0.6846s	
19337/30300 (epoch 31.909), train_loss = 1.00992560, grad/param norm = 1.7895e-01, time/batch = 0.6802s	
19338/30300 (epoch 31.911), train_loss = 1.09200998, grad/param norm = 1.6340e-01, time/batch = 0.6867s	
19339/30300 (epoch 31.913), train_loss = 1.08609073, grad/param norm = 1.5736e-01, time/batch = 0.6841s	
19340/30300 (epoch 31.914), train_loss = 1.05781178, grad/param norm = 1.9079e-01, time/batch = 0.7132s	
19341/30300 (epoch 31.916), train_loss = 1.11479350, grad/param norm = 1.4970e-01, time/batch = 0.6933s	
19342/30300 (epoch 31.917), train_loss = 1.05397375, grad/param norm = 1.5278e-01, time/batch = 0.6849s	
19343/30300 (epoch 31.919), train_loss = 1.01948497, grad/param norm = 1.6720e-01, time/batch = 0.6839s	
19344/30300 (epoch 31.921), train_loss = 1.05368150, grad/param norm = 1.4289e-01, time/batch = 0.6897s	
19345/30300 (epoch 31.922), train_loss = 1.17230794, grad/param norm = 1.7780e-01, time/batch = 0.7105s	
19346/30300 (epoch 31.924), train_loss = 1.09824571, grad/param norm = 1.8557e-01, time/batch = 0.7169s	
19347/30300 (epoch 31.926), train_loss = 1.12054348, grad/param norm = 1.5896e-01, time/batch = 0.6820s	
19348/30300 (epoch 31.927), train_loss = 1.10903955, grad/param norm = 1.6504e-01, time/batch = 0.6826s	
19349/30300 (epoch 31.929), train_loss = 0.99529594, grad/param norm = 1.5672e-01, time/batch = 0.6813s	
19350/30300 (epoch 31.931), train_loss = 1.16873465, grad/param norm = 2.0273e-01, time/batch = 0.6801s	
19351/30300 (epoch 31.932), train_loss = 1.01036158, grad/param norm = 1.6638e-01, time/batch = 0.6913s	
19352/30300 (epoch 31.934), train_loss = 1.12726594, grad/param norm = 1.6190e-01, time/batch = 0.6841s	
19353/30300 (epoch 31.936), train_loss = 1.01081244, grad/param norm = 1.5234e-01, time/batch = 0.6854s	
19354/30300 (epoch 31.937), train_loss = 1.02453291, grad/param norm = 1.5700e-01, time/batch = 0.6855s	
19355/30300 (epoch 31.939), train_loss = 1.22623939, grad/param norm = 2.1454e-01, time/batch = 0.6902s	
19356/30300 (epoch 31.941), train_loss = 1.09028228, grad/param norm = 1.9075e-01, time/batch = 0.6838s	
19357/30300 (epoch 31.942), train_loss = 1.07558988, grad/param norm = 1.5689e-01, time/batch = 0.6830s	
19358/30300 (epoch 31.944), train_loss = 0.97102560, grad/param norm = 1.4467e-01, time/batch = 0.6849s	
19359/30300 (epoch 31.946), train_loss = 1.17366769, grad/param norm = 1.9740e-01, time/batch = 0.6826s	
19360/30300 (epoch 31.947), train_loss = 1.14651717, grad/param norm = 1.9326e-01, time/batch = 0.6834s	
19361/30300 (epoch 31.949), train_loss = 1.16342702, grad/param norm = 1.8330e-01, time/batch = 0.6880s	
19362/30300 (epoch 31.950), train_loss = 1.18204328, grad/param norm = 1.7881e-01, time/batch = 0.6843s	
19363/30300 (epoch 31.952), train_loss = 1.15101237, grad/param norm = 1.9250e-01, time/batch = 0.6869s	
19364/30300 (epoch 31.954), train_loss = 1.34873528, grad/param norm = 1.6439e-01, time/batch = 0.6862s	
19365/30300 (epoch 31.955), train_loss = 1.07064799, grad/param norm = 1.5705e-01, time/batch = 0.6853s	
19366/30300 (epoch 31.957), train_loss = 1.13067239, grad/param norm = 1.5219e-01, time/batch = 0.6835s	
19367/30300 (epoch 31.959), train_loss = 1.00365525, grad/param norm = 1.7494e-01, time/batch = 0.6829s	
19368/30300 (epoch 31.960), train_loss = 1.05805170, grad/param norm = 1.8198e-01, time/batch = 0.7030s	
19369/30300 (epoch 31.962), train_loss = 1.04827353, grad/param norm = 2.0448e-01, time/batch = 0.7236s	
19370/30300 (epoch 31.964), train_loss = 0.98346347, grad/param norm = 1.8137e-01, time/batch = 0.6866s	
19371/30300 (epoch 31.965), train_loss = 1.02661022, grad/param norm = 1.7632e-01, time/batch = 0.6866s	
19372/30300 (epoch 31.967), train_loss = 1.07566013, grad/param norm = 1.8703e-01, time/batch = 0.6820s	
19373/30300 (epoch 31.969), train_loss = 1.00009099, grad/param norm = 1.8280e-01, time/batch = 0.6826s	
19374/30300 (epoch 31.970), train_loss = 1.05454251, grad/param norm = 1.4854e-01, time/batch = 0.6837s	
19375/30300 (epoch 31.972), train_loss = 0.98003109, grad/param norm = 1.9410e-01, time/batch = 0.6846s	
19376/30300 (epoch 31.974), train_loss = 1.22238859, grad/param norm = 1.7490e-01, time/batch = 0.6845s	
19377/30300 (epoch 31.975), train_loss = 1.23728295, grad/param norm = 2.0622e-01, time/batch = 0.7014s	
19378/30300 (epoch 31.977), train_loss = 1.27331419, grad/param norm = 1.8896e-01, time/batch = 0.7168s	
19379/30300 (epoch 31.979), train_loss = 1.15551362, grad/param norm = 1.8040e-01, time/batch = 0.7130s	
19380/30300 (epoch 31.980), train_loss = 1.18416781, grad/param norm = 1.9106e-01, time/batch = 0.7046s	
19381/30300 (epoch 31.982), train_loss = 1.18947920, grad/param norm = 1.7284e-01, time/batch = 0.7064s	
19382/30300 (epoch 31.983), train_loss = 1.21186402, grad/param norm = 1.6819e-01, time/batch = 0.7026s	
19383/30300 (epoch 31.985), train_loss = 1.15865645, grad/param norm = 1.8684e-01, time/batch = 0.7280s	
19384/30300 (epoch 31.987), train_loss = 1.07707699, grad/param norm = 1.6344e-01, time/batch = 0.6888s	
19385/30300 (epoch 31.988), train_loss = 1.21865682, grad/param norm = 1.6912e-01, time/batch = 0.6839s	
19386/30300 (epoch 31.990), train_loss = 0.99151763, grad/param norm = 1.5294e-01, time/batch = 0.6791s	
19387/30300 (epoch 31.992), train_loss = 1.16195567, grad/param norm = 1.5178e-01, time/batch = 0.6860s	
19388/30300 (epoch 31.993), train_loss = 1.22765672, grad/param norm = 2.1349e-01, time/batch = 0.6865s	
19389/30300 (epoch 31.995), train_loss = 1.08749937, grad/param norm = 1.9735e-01, time/batch = 0.6830s	
19390/30300 (epoch 31.997), train_loss = 1.10749936, grad/param norm = 1.8374e-01, time/batch = 0.6823s	
19391/30300 (epoch 31.998), train_loss = 1.15815192, grad/param norm = 1.8501e-01, time/batch = 0.6842s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
19392/30300 (epoch 32.000), train_loss = 1.05486007, grad/param norm = 1.8505e-01, time/batch = 0.6807s	
19393/30300 (epoch 32.002), train_loss = 1.18386588, grad/param norm = 1.8035e-01, time/batch = 0.6874s	
19394/30300 (epoch 32.003), train_loss = 1.10152766, grad/param norm = 1.6799e-01, time/batch = 0.6812s	
19395/30300 (epoch 32.005), train_loss = 1.04271478, grad/param norm = 1.7287e-01, time/batch = 0.6825s	
19396/30300 (epoch 32.007), train_loss = 1.13972389, grad/param norm = 1.9656e-01, time/batch = 0.6826s	
19397/30300 (epoch 32.008), train_loss = 1.06445642, grad/param norm = 1.5685e-01, time/batch = 0.6829s	
19398/30300 (epoch 32.010), train_loss = 0.97616317, grad/param norm = 1.7265e-01, time/batch = 0.6815s	
19399/30300 (epoch 32.012), train_loss = 1.04252692, grad/param norm = 1.6435e-01, time/batch = 0.6792s	
19400/30300 (epoch 32.013), train_loss = 1.20144940, grad/param norm = 2.1696e-01, time/batch = 0.6819s	
19401/30300 (epoch 32.015), train_loss = 1.06059844, grad/param norm = 1.6585e-01, time/batch = 0.6844s	
19402/30300 (epoch 32.017), train_loss = 1.03590401, grad/param norm = 1.4392e-01, time/batch = 0.6803s	
19403/30300 (epoch 32.018), train_loss = 0.99381915, grad/param norm = 1.5234e-01, time/batch = 0.6833s	
19404/30300 (epoch 32.020), train_loss = 1.17356349, grad/param norm = 1.8173e-01, time/batch = 0.6823s	
19405/30300 (epoch 32.021), train_loss = 1.21469947, grad/param norm = 1.6823e-01, time/batch = 0.6803s	
19406/30300 (epoch 32.023), train_loss = 1.09365908, grad/param norm = 1.4929e-01, time/batch = 0.6834s	
19407/30300 (epoch 32.025), train_loss = 1.01337301, grad/param norm = 1.8075e-01, time/batch = 0.6797s	
19408/30300 (epoch 32.026), train_loss = 1.13320602, grad/param norm = 1.7377e-01, time/batch = 0.6805s	
19409/30300 (epoch 32.028), train_loss = 1.17304391, grad/param norm = 1.6493e-01, time/batch = 0.6807s	
19410/30300 (epoch 32.030), train_loss = 1.04990237, grad/param norm = 1.6718e-01, time/batch = 0.6984s	
19411/30300 (epoch 32.031), train_loss = 1.14345357, grad/param norm = 1.6127e-01, time/batch = 0.7054s	
19412/30300 (epoch 32.033), train_loss = 1.09717436, grad/param norm = 1.7112e-01, time/batch = 0.7031s	
19413/30300 (epoch 32.035), train_loss = 1.16369682, grad/param norm = 1.8438e-01, time/batch = 0.7214s	
19414/30300 (epoch 32.036), train_loss = 1.12079284, grad/param norm = 1.7007e-01, time/batch = 0.7168s	
19415/30300 (epoch 32.038), train_loss = 1.14169341, grad/param norm = 1.5567e-01, time/batch = 0.7003s	
19416/30300 (epoch 32.040), train_loss = 0.89406819, grad/param norm = 1.3735e-01, time/batch = 0.7232s	
19417/30300 (epoch 32.041), train_loss = 0.90694345, grad/param norm = 1.4920e-01, time/batch = 0.7054s	
19418/30300 (epoch 32.043), train_loss = 1.10883315, grad/param norm = 1.8809e-01, time/batch = 0.7003s	
19419/30300 (epoch 32.045), train_loss = 1.05563743, grad/param norm = 1.5511e-01, time/batch = 0.6862s	
19420/30300 (epoch 32.046), train_loss = 1.26115431, grad/param norm = 1.9576e-01, time/batch = 0.6847s	
19421/30300 (epoch 32.048), train_loss = 1.08620199, grad/param norm = 2.0441e-01, time/batch = 0.6869s	
19422/30300 (epoch 32.050), train_loss = 1.02621102, grad/param norm = 1.8408e-01, time/batch = 0.7063s	
19423/30300 (epoch 32.051), train_loss = 1.11662268, grad/param norm = 1.7388e-01, time/batch = 0.7065s	
19424/30300 (epoch 32.053), train_loss = 0.94803591, grad/param norm = 1.9273e-01, time/batch = 0.6872s	
19425/30300 (epoch 32.054), train_loss = 1.11182576, grad/param norm = 1.6106e-01, time/batch = 0.6872s	
19426/30300 (epoch 32.056), train_loss = 0.99941029, grad/param norm = 1.5697e-01, time/batch = 0.6830s	
19427/30300 (epoch 32.058), train_loss = 1.05523877, grad/param norm = 1.5231e-01, time/batch = 0.6829s	
19428/30300 (epoch 32.059), train_loss = 1.04592182, grad/param norm = 1.9683e-01, time/batch = 0.6828s	
19429/30300 (epoch 32.061), train_loss = 1.14557718, grad/param norm = 1.7346e-01, time/batch = 0.6834s	
19430/30300 (epoch 32.063), train_loss = 0.97830320, grad/param norm = 1.6938e-01, time/batch = 0.6811s	
19431/30300 (epoch 32.064), train_loss = 1.10748157, grad/param norm = 1.8337e-01, time/batch = 0.6889s	
19432/30300 (epoch 32.066), train_loss = 1.08646532, grad/param norm = 1.5209e-01, time/batch = 0.6847s	
19433/30300 (epoch 32.068), train_loss = 0.99453804, grad/param norm = 1.6774e-01, time/batch = 0.6883s	
19434/30300 (epoch 32.069), train_loss = 1.15851008, grad/param norm = 1.7174e-01, time/batch = 0.6996s	
19435/30300 (epoch 32.071), train_loss = 1.14765812, grad/param norm = 1.7415e-01, time/batch = 0.7262s	
19436/30300 (epoch 32.073), train_loss = 1.00679931, grad/param norm = 1.7625e-01, time/batch = 0.6909s	
19437/30300 (epoch 32.074), train_loss = 1.08170869, grad/param norm = 1.5539e-01, time/batch = 0.6824s	
19438/30300 (epoch 32.076), train_loss = 1.07580385, grad/param norm = 1.7291e-01, time/batch = 0.6830s	
19439/30300 (epoch 32.078), train_loss = 1.01181527, grad/param norm = 1.4640e-01, time/batch = 0.6841s	
19440/30300 (epoch 32.079), train_loss = 1.03376294, grad/param norm = 1.5244e-01, time/batch = 0.6833s	
19441/30300 (epoch 32.081), train_loss = 1.08472155, grad/param norm = 1.6532e-01, time/batch = 0.6874s	
19442/30300 (epoch 32.083), train_loss = 1.16031907, grad/param norm = 2.2521e-01, time/batch = 0.6865s	
19443/30300 (epoch 32.084), train_loss = 1.00738678, grad/param norm = 1.7341e-01, time/batch = 0.6849s	
19444/30300 (epoch 32.086), train_loss = 1.03071318, grad/param norm = 2.2421e-01, time/batch = 0.6822s	
19445/30300 (epoch 32.087), train_loss = 1.01126098, grad/param norm = 1.5301e-01, time/batch = 0.6837s	
19446/30300 (epoch 32.089), train_loss = 1.02784642, grad/param norm = 1.6160e-01, time/batch = 0.6831s	
19447/30300 (epoch 32.091), train_loss = 1.12908587, grad/param norm = 1.6034e-01, time/batch = 0.6825s	
19448/30300 (epoch 32.092), train_loss = 1.14839233, grad/param norm = 1.7081e-01, time/batch = 0.6836s	
19449/30300 (epoch 32.094), train_loss = 1.20721379, grad/param norm = 1.9503e-01, time/batch = 0.6839s	
19450/30300 (epoch 32.096), train_loss = 1.18821725, grad/param norm = 1.7123e-01, time/batch = 0.6841s	
19451/30300 (epoch 32.097), train_loss = 1.02761710, grad/param norm = 2.0530e-01, time/batch = 0.6885s	
19452/30300 (epoch 32.099), train_loss = 1.17008590, grad/param norm = 1.7441e-01, time/batch = 0.6875s	
19453/30300 (epoch 32.101), train_loss = 1.24130111, grad/param norm = 1.9556e-01, time/batch = 0.6867s	
19454/30300 (epoch 32.102), train_loss = 1.03364106, grad/param norm = 1.8920e-01, time/batch = 0.6854s	
19455/30300 (epoch 32.104), train_loss = 1.06406685, grad/param norm = 1.8892e-01, time/batch = 0.6891s	
19456/30300 (epoch 32.106), train_loss = 1.06909075, grad/param norm = 2.0195e-01, time/batch = 0.6870s	
19457/30300 (epoch 32.107), train_loss = 1.13547291, grad/param norm = 1.6132e-01, time/batch = 0.6934s	
19458/30300 (epoch 32.109), train_loss = 1.16909965, grad/param norm = 2.0982e-01, time/batch = 0.6934s	
19459/30300 (epoch 32.111), train_loss = 1.17058881, grad/param norm = 1.9295e-01, time/batch = 0.6855s	
19460/30300 (epoch 32.112), train_loss = 1.23676592, grad/param norm = 1.8875e-01, time/batch = 0.6848s	
19461/30300 (epoch 32.114), train_loss = 1.05698245, grad/param norm = 1.6436e-01, time/batch = 0.6869s	
19462/30300 (epoch 32.116), train_loss = 1.10341269, grad/param norm = 1.7560e-01, time/batch = 0.6863s	
19463/30300 (epoch 32.117), train_loss = 1.18974184, grad/param norm = 1.7406e-01, time/batch = 0.6891s	
19464/30300 (epoch 32.119), train_loss = 1.03229024, grad/param norm = 2.0162e-01, time/batch = 0.6848s	
19465/30300 (epoch 32.120), train_loss = 1.06882143, grad/param norm = 1.6642e-01, time/batch = 0.6898s	
19466/30300 (epoch 32.122), train_loss = 1.18597982, grad/param norm = 2.1544e-01, time/batch = 0.6865s	
19467/30300 (epoch 32.124), train_loss = 1.24041453, grad/param norm = 1.8055e-01, time/batch = 0.6839s	
19468/30300 (epoch 32.125), train_loss = 0.98369495, grad/param norm = 1.7196e-01, time/batch = 0.6859s	
19469/30300 (epoch 32.127), train_loss = 1.13126903, grad/param norm = 1.9487e-01, time/batch = 0.6839s	
19470/30300 (epoch 32.129), train_loss = 1.19484740, grad/param norm = 1.8702e-01, time/batch = 0.6835s	
19471/30300 (epoch 32.130), train_loss = 1.23499230, grad/param norm = 1.8303e-01, time/batch = 0.6844s	
19472/30300 (epoch 32.132), train_loss = 1.22222979, grad/param norm = 1.8550e-01, time/batch = 0.6842s	
19473/30300 (epoch 32.134), train_loss = 1.00392302, grad/param norm = 1.6992e-01, time/batch = 0.6844s	
19474/30300 (epoch 32.135), train_loss = 1.04861951, grad/param norm = 1.9013e-01, time/batch = 0.6839s	
19475/30300 (epoch 32.137), train_loss = 1.09210097, grad/param norm = 1.8506e-01, time/batch = 0.6833s	
19476/30300 (epoch 32.139), train_loss = 1.05260567, grad/param norm = 2.0901e-01, time/batch = 0.6909s	
19477/30300 (epoch 32.140), train_loss = 1.11256702, grad/param norm = 2.2985e-01, time/batch = 0.7264s	
19478/30300 (epoch 32.142), train_loss = 1.21499284, grad/param norm = 2.3059e-01, time/batch = 0.6920s	
19479/30300 (epoch 32.144), train_loss = 1.05883417, grad/param norm = 2.8087e-01, time/batch = 0.6813s	
19480/30300 (epoch 32.145), train_loss = 1.17375470, grad/param norm = 1.9381e-01, time/batch = 0.6810s	
19481/30300 (epoch 32.147), train_loss = 1.04314350, grad/param norm = 1.7480e-01, time/batch = 0.6845s	
19482/30300 (epoch 32.149), train_loss = 1.21735709, grad/param norm = 2.1942e-01, time/batch = 0.6809s	
19483/30300 (epoch 32.150), train_loss = 1.07763928, grad/param norm = 2.1407e-01, time/batch = 0.6866s	
19484/30300 (epoch 32.152), train_loss = 0.99547849, grad/param norm = 1.9014e-01, time/batch = 0.6854s	
19485/30300 (epoch 32.153), train_loss = 1.08602282, grad/param norm = 1.7087e-01, time/batch = 0.6857s	
19486/30300 (epoch 32.155), train_loss = 0.96746366, grad/param norm = 1.5382e-01, time/batch = 0.6843s	
19487/30300 (epoch 32.157), train_loss = 1.07313950, grad/param norm = 2.0552e-01, time/batch = 0.6859s	
19488/30300 (epoch 32.158), train_loss = 1.11677971, grad/param norm = 2.0333e-01, time/batch = 0.6858s	
19489/30300 (epoch 32.160), train_loss = 1.02083761, grad/param norm = 1.7934e-01, time/batch = 0.6857s	
19490/30300 (epoch 32.162), train_loss = 1.08965556, grad/param norm = 1.6187e-01, time/batch = 0.6843s	
19491/30300 (epoch 32.163), train_loss = 1.09243902, grad/param norm = 1.9006e-01, time/batch = 0.6867s	
19492/30300 (epoch 32.165), train_loss = 1.19241204, grad/param norm = 1.7070e-01, time/batch = 0.6851s	
19493/30300 (epoch 32.167), train_loss = 1.10116311, grad/param norm = 1.8881e-01, time/batch = 0.6857s	
19494/30300 (epoch 32.168), train_loss = 1.15861598, grad/param norm = 1.8083e-01, time/batch = 0.6837s	
19495/30300 (epoch 32.170), train_loss = 1.09080913, grad/param norm = 1.7790e-01, time/batch = 0.6995s	
19496/30300 (epoch 32.172), train_loss = 1.08321290, grad/param norm = 1.7715e-01, time/batch = 0.7259s	
19497/30300 (epoch 32.173), train_loss = 1.07315659, grad/param norm = 1.7306e-01, time/batch = 0.6996s	
19498/30300 (epoch 32.175), train_loss = 1.09133927, grad/param norm = 1.8338e-01, time/batch = 0.7048s	
19499/30300 (epoch 32.177), train_loss = 1.17712408, grad/param norm = 2.0941e-01, time/batch = 0.7192s	
19500/30300 (epoch 32.178), train_loss = 0.88772176, grad/param norm = 1.5514e-01, time/batch = 0.7208s	
19501/30300 (epoch 32.180), train_loss = 1.07336104, grad/param norm = 1.5799e-01, time/batch = 0.7043s	
19502/30300 (epoch 32.182), train_loss = 1.10418644, grad/param norm = 1.7598e-01, time/batch = 0.7201s	
19503/30300 (epoch 32.183), train_loss = 1.03685038, grad/param norm = 1.7882e-01, time/batch = 0.6937s	
19504/30300 (epoch 32.185), train_loss = 1.24717338, grad/param norm = 1.7515e-01, time/batch = 0.6899s	
19505/30300 (epoch 32.186), train_loss = 1.29746962, grad/param norm = 2.2755e-01, time/batch = 0.6853s	
19506/30300 (epoch 32.188), train_loss = 1.13268142, grad/param norm = 1.8393e-01, time/batch = 0.6861s	
19507/30300 (epoch 32.190), train_loss = 1.10890092, grad/param norm = 1.6186e-01, time/batch = 0.6926s	
19508/30300 (epoch 32.191), train_loss = 1.16286018, grad/param norm = 1.9363e-01, time/batch = 0.6922s	
19509/30300 (epoch 32.193), train_loss = 1.00516625, grad/param norm = 1.5218e-01, time/batch = 0.6840s	
19510/30300 (epoch 32.195), train_loss = 1.05566518, grad/param norm = 1.6903e-01, time/batch = 0.6839s	
19511/30300 (epoch 32.196), train_loss = 1.12467186, grad/param norm = 1.9054e-01, time/batch = 0.6878s	
19512/30300 (epoch 32.198), train_loss = 0.93822448, grad/param norm = 1.7556e-01, time/batch = 0.6873s	
19513/30300 (epoch 32.200), train_loss = 1.07819140, grad/param norm = 1.6387e-01, time/batch = 0.6867s	
19514/30300 (epoch 32.201), train_loss = 1.17752058, grad/param norm = 2.1722e-01, time/batch = 0.7212s	
19515/30300 (epoch 32.203), train_loss = 1.09328463, grad/param norm = 1.8832e-01, time/batch = 0.7055s	
19516/30300 (epoch 32.205), train_loss = 1.29265206, grad/param norm = 1.8950e-01, time/batch = 0.6886s	
19517/30300 (epoch 32.206), train_loss = 1.18727016, grad/param norm = 1.9894e-01, time/batch = 0.6856s	
19518/30300 (epoch 32.208), train_loss = 1.14489553, grad/param norm = 2.0613e-01, time/batch = 0.6865s	
19519/30300 (epoch 32.210), train_loss = 1.16260653, grad/param norm = 1.7656e-01, time/batch = 0.6892s	
19520/30300 (epoch 32.211), train_loss = 1.21358991, grad/param norm = 1.6908e-01, time/batch = 0.6831s	
19521/30300 (epoch 32.213), train_loss = 1.07649852, grad/param norm = 1.4664e-01, time/batch = 0.6851s	
19522/30300 (epoch 32.215), train_loss = 1.02492769, grad/param norm = 1.7065e-01, time/batch = 0.6830s	
19523/30300 (epoch 32.216), train_loss = 1.04483415, grad/param norm = 1.7882e-01, time/batch = 0.6827s	
19524/30300 (epoch 32.218), train_loss = 1.01488416, grad/param norm = 1.6440e-01, time/batch = 0.6862s	
19525/30300 (epoch 32.219), train_loss = 0.96440621, grad/param norm = 1.6156e-01, time/batch = 0.6819s	
19526/30300 (epoch 32.221), train_loss = 0.94737754, grad/param norm = 1.5421e-01, time/batch = 0.6814s	
19527/30300 (epoch 32.223), train_loss = 1.11478543, grad/param norm = 1.8542e-01, time/batch = 0.6833s	
19528/30300 (epoch 32.224), train_loss = 0.94158719, grad/param norm = 1.6608e-01, time/batch = 0.6812s	
19529/30300 (epoch 32.226), train_loss = 1.14614602, grad/param norm = 1.9763e-01, time/batch = 0.6820s	
19530/30300 (epoch 32.228), train_loss = 1.18777830, grad/param norm = 1.8050e-01, time/batch = 0.6810s	
19531/30300 (epoch 32.229), train_loss = 1.07210705, grad/param norm = 1.6528e-01, time/batch = 0.6858s	
19532/30300 (epoch 32.231), train_loss = 1.12573422, grad/param norm = 1.7102e-01, time/batch = 0.6846s	
19533/30300 (epoch 32.233), train_loss = 1.14030081, grad/param norm = 1.5431e-01, time/batch = 0.7095s	
19534/30300 (epoch 32.234), train_loss = 1.16612246, grad/param norm = 1.9958e-01, time/batch = 0.6825s	
19535/30300 (epoch 32.236), train_loss = 1.13866650, grad/param norm = 1.5624e-01, time/batch = 0.6849s	
19536/30300 (epoch 32.238), train_loss = 1.10028279, grad/param norm = 1.8712e-01, time/batch = 0.6817s	
19537/30300 (epoch 32.239), train_loss = 1.09203063, grad/param norm = 1.8203e-01, time/batch = 0.6813s	
19538/30300 (epoch 32.241), train_loss = 1.15157412, grad/param norm = 1.8249e-01, time/batch = 0.6820s	
19539/30300 (epoch 32.243), train_loss = 1.14560454, grad/param norm = 1.6701e-01, time/batch = 0.6821s	
19540/30300 (epoch 32.244), train_loss = 1.29582942, grad/param norm = 1.7230e-01, time/batch = 0.6807s	
19541/30300 (epoch 32.246), train_loss = 1.12007085, grad/param norm = 1.7005e-01, time/batch = 0.6827s	
19542/30300 (epoch 32.248), train_loss = 1.06409795, grad/param norm = 1.5536e-01, time/batch = 0.6959s	
19543/30300 (epoch 32.249), train_loss = 1.01360008, grad/param norm = 1.7026e-01, time/batch = 0.6884s	
19544/30300 (epoch 32.251), train_loss = 1.03925477, grad/param norm = 1.6772e-01, time/batch = 0.7142s	
19545/30300 (epoch 32.252), train_loss = 1.20238857, grad/param norm = 1.9920e-01, time/batch = 0.7120s	
19546/30300 (epoch 32.254), train_loss = 1.19659824, grad/param norm = 1.7164e-01, time/batch = 0.7012s	
19547/30300 (epoch 32.256), train_loss = 1.11514986, grad/param norm = 1.6683e-01, time/batch = 0.7015s	
19548/30300 (epoch 32.257), train_loss = 1.18051129, grad/param norm = 1.7674e-01, time/batch = 0.6810s	
19549/30300 (epoch 32.259), train_loss = 1.08139898, grad/param norm = 1.7784e-01, time/batch = 0.6820s	
19550/30300 (epoch 32.261), train_loss = 1.20772450, grad/param norm = 1.6707e-01, time/batch = 0.6859s	
19551/30300 (epoch 32.262), train_loss = 1.03399584, grad/param norm = 1.6476e-01, time/batch = 0.6953s	
19552/30300 (epoch 32.264), train_loss = 1.08861235, grad/param norm = 1.7992e-01, time/batch = 0.7269s	
19553/30300 (epoch 32.266), train_loss = 1.05200706, grad/param norm = 1.5109e-01, time/batch = 0.6867s	
19554/30300 (epoch 32.267), train_loss = 1.26969286, grad/param norm = 1.8596e-01, time/batch = 0.6790s	
19555/30300 (epoch 32.269), train_loss = 1.10322539, grad/param norm = 1.5746e-01, time/batch = 0.6808s	
19556/30300 (epoch 32.271), train_loss = 1.12914441, grad/param norm = 1.6780e-01, time/batch = 0.6827s	
19557/30300 (epoch 32.272), train_loss = 1.09622819, grad/param norm = 1.8818e-01, time/batch = 0.6818s	
19558/30300 (epoch 32.274), train_loss = 1.16585556, grad/param norm = 1.7255e-01, time/batch = 0.6806s	
19559/30300 (epoch 32.276), train_loss = 1.13842836, grad/param norm = 1.8604e-01, time/batch = 0.6794s	
19560/30300 (epoch 32.277), train_loss = 0.98904529, grad/param norm = 1.9867e-01, time/batch = 0.6790s	
19561/30300 (epoch 32.279), train_loss = 1.09571759, grad/param norm = 1.6854e-01, time/batch = 0.6851s	
19562/30300 (epoch 32.281), train_loss = 1.19250448, grad/param norm = 2.1525e-01, time/batch = 0.7027s	
19563/30300 (epoch 32.282), train_loss = 1.12286217, grad/param norm = 1.5468e-01, time/batch = 0.6870s	
19564/30300 (epoch 32.284), train_loss = 1.21312867, grad/param norm = 2.2153e-01, time/batch = 0.6826s	
19565/30300 (epoch 32.285), train_loss = 1.13563143, grad/param norm = 1.6256e-01, time/batch = 0.6804s	
19566/30300 (epoch 32.287), train_loss = 1.08783092, grad/param norm = 1.7478e-01, time/batch = 0.6827s	
19567/30300 (epoch 32.289), train_loss = 1.18853545, grad/param norm = 1.6652e-01, time/batch = 0.6967s	
19568/30300 (epoch 32.290), train_loss = 0.87341020, grad/param norm = 1.4582e-01, time/batch = 0.6866s	
19569/30300 (epoch 32.292), train_loss = 1.01519287, grad/param norm = 1.6990e-01, time/batch = 0.6814s	
19570/30300 (epoch 32.294), train_loss = 1.17976217, grad/param norm = 2.2330e-01, time/batch = 0.7009s	
19571/30300 (epoch 32.295), train_loss = 1.05571247, grad/param norm = 1.7462e-01, time/batch = 0.7246s	
19572/30300 (epoch 32.297), train_loss = 1.04748921, grad/param norm = 1.5363e-01, time/batch = 0.6862s	
19573/30300 (epoch 32.299), train_loss = 1.07584307, grad/param norm = 1.5436e-01, time/batch = 0.6841s	
19574/30300 (epoch 32.300), train_loss = 1.02530885, grad/param norm = 1.7286e-01, time/batch = 0.6853s	
19575/30300 (epoch 32.302), train_loss = 1.16182284, grad/param norm = 1.7165e-01, time/batch = 0.6829s	
19576/30300 (epoch 32.304), train_loss = 1.02584344, grad/param norm = 1.5393e-01, time/batch = 0.6799s	
19577/30300 (epoch 32.305), train_loss = 1.07416139, grad/param norm = 1.5840e-01, time/batch = 0.6808s	
19578/30300 (epoch 32.307), train_loss = 1.16345235, grad/param norm = 1.4357e-01, time/batch = 0.6816s	
19579/30300 (epoch 32.309), train_loss = 1.13662634, grad/param norm = 1.6275e-01, time/batch = 0.6850s	
19580/30300 (epoch 32.310), train_loss = 1.08859213, grad/param norm = 1.6193e-01, time/batch = 0.7100s	
19581/30300 (epoch 32.312), train_loss = 1.22963210, grad/param norm = 1.6577e-01, time/batch = 0.6826s	
19582/30300 (epoch 32.314), train_loss = 1.10906955, grad/param norm = 1.6897e-01, time/batch = 0.6888s	
19583/30300 (epoch 32.315), train_loss = 1.06786238, grad/param norm = 1.6453e-01, time/batch = 0.6887s	
19584/30300 (epoch 32.317), train_loss = 1.11012321, grad/param norm = 1.5748e-01, time/batch = 0.7068s	
19585/30300 (epoch 32.318), train_loss = 1.18744493, grad/param norm = 2.0285e-01, time/batch = 0.7107s	
19586/30300 (epoch 32.320), train_loss = 1.13873144, grad/param norm = 1.6410e-01, time/batch = 0.7284s	
19587/30300 (epoch 32.322), train_loss = 1.03391148, grad/param norm = 1.5454e-01, time/batch = 0.6876s	
19588/30300 (epoch 32.323), train_loss = 1.21216650, grad/param norm = 1.8442e-01, time/batch = 0.6921s	
19589/30300 (epoch 32.325), train_loss = 1.08716838, grad/param norm = 1.6523e-01, time/batch = 0.7193s	
19590/30300 (epoch 32.327), train_loss = 1.08965556, grad/param norm = 1.6380e-01, time/batch = 0.7072s	
19591/30300 (epoch 32.328), train_loss = 1.11348501, grad/param norm = 1.6713e-01, time/batch = 0.6929s	
19592/30300 (epoch 32.330), train_loss = 1.14546444, grad/param norm = 1.7377e-01, time/batch = 0.7159s	
19593/30300 (epoch 32.332), train_loss = 1.18936890, grad/param norm = 1.8032e-01, time/batch = 0.6998s	
19594/30300 (epoch 32.333), train_loss = 1.04784317, grad/param norm = 1.7029e-01, time/batch = 0.6972s	
19595/30300 (epoch 32.335), train_loss = 0.98399058, grad/param norm = 1.6019e-01, time/batch = 0.7044s	
19596/30300 (epoch 32.337), train_loss = 1.22471114, grad/param norm = 1.6016e-01, time/batch = 0.7033s	
19597/30300 (epoch 32.338), train_loss = 1.04709367, grad/param norm = 1.5603e-01, time/batch = 0.6857s	
19598/30300 (epoch 32.340), train_loss = 1.03819312, grad/param norm = 1.4798e-01, time/batch = 0.6870s	
19599/30300 (epoch 32.342), train_loss = 1.17862340, grad/param norm = 1.7350e-01, time/batch = 0.6812s	
19600/30300 (epoch 32.343), train_loss = 1.11424226, grad/param norm = 1.5353e-01, time/batch = 0.6790s	
19601/30300 (epoch 32.345), train_loss = 1.14520049, grad/param norm = 1.6462e-01, time/batch = 0.6856s	
19602/30300 (epoch 32.347), train_loss = 0.98831047, grad/param norm = 1.7832e-01, time/batch = 0.6906s	
19603/30300 (epoch 32.348), train_loss = 1.05930808, grad/param norm = 1.7683e-01, time/batch = 0.7059s	
19604/30300 (epoch 32.350), train_loss = 1.06300501, grad/param norm = 1.7756e-01, time/batch = 0.7187s	
19605/30300 (epoch 32.351), train_loss = 1.07504283, grad/param norm = 1.6749e-01, time/batch = 0.6844s	
19606/30300 (epoch 32.353), train_loss = 0.97753971, grad/param norm = 1.8259e-01, time/batch = 0.6794s	
19607/30300 (epoch 32.355), train_loss = 1.06171294, grad/param norm = 1.5659e-01, time/batch = 0.6812s	
19608/30300 (epoch 32.356), train_loss = 1.17024340, grad/param norm = 1.8724e-01, time/batch = 0.6805s	
19609/30300 (epoch 32.358), train_loss = 1.33366909, grad/param norm = 1.6986e-01, time/batch = 0.6794s	
19610/30300 (epoch 32.360), train_loss = 1.07016185, grad/param norm = 1.8985e-01, time/batch = 0.6806s	
19611/30300 (epoch 32.361), train_loss = 1.08637551, grad/param norm = 1.5916e-01, time/batch = 0.6851s	
19612/30300 (epoch 32.363), train_loss = 1.14690520, grad/param norm = 1.6806e-01, time/batch = 0.6877s	
19613/30300 (epoch 32.365), train_loss = 0.97380722, grad/param norm = 1.8871e-01, time/batch = 0.6859s	
19614/30300 (epoch 32.366), train_loss = 1.06772797, grad/param norm = 1.5839e-01, time/batch = 0.6819s	
19615/30300 (epoch 32.368), train_loss = 0.97114744, grad/param norm = 1.5928e-01, time/batch = 0.6807s	
19616/30300 (epoch 32.370), train_loss = 1.04123135, grad/param norm = 1.7364e-01, time/batch = 0.6807s	
19617/30300 (epoch 32.371), train_loss = 1.16357932, grad/param norm = 1.5179e-01, time/batch = 0.6864s	
19618/30300 (epoch 32.373), train_loss = 1.03785662, grad/param norm = 1.3977e-01, time/batch = 0.6797s	
19619/30300 (epoch 32.375), train_loss = 1.02021090, grad/param norm = 1.4055e-01, time/batch = 0.6820s	
19620/30300 (epoch 32.376), train_loss = 1.02365153, grad/param norm = 1.4879e-01, time/batch = 0.6848s	
19621/30300 (epoch 32.378), train_loss = 0.99178569, grad/param norm = 1.6639e-01, time/batch = 0.6860s	
19622/30300 (epoch 32.380), train_loss = 1.23398315, grad/param norm = 1.9106e-01, time/batch = 0.7135s	
19623/30300 (epoch 32.381), train_loss = 0.92855614, grad/param norm = 1.4697e-01, time/batch = 0.7130s	
19624/30300 (epoch 32.383), train_loss = 1.01357859, grad/param norm = 2.1704e-01, time/batch = 0.6850s	
19625/30300 (epoch 32.384), train_loss = 1.15302310, grad/param norm = 1.7468e-01, time/batch = 0.6848s	
19626/30300 (epoch 32.386), train_loss = 0.98796469, grad/param norm = 1.6258e-01, time/batch = 0.6817s	
19627/30300 (epoch 32.388), train_loss = 0.95235327, grad/param norm = 1.5469e-01, time/batch = 0.6828s	
19628/30300 (epoch 32.389), train_loss = 1.08927164, grad/param norm = 1.8580e-01, time/batch = 0.6805s	
19629/30300 (epoch 32.391), train_loss = 1.11906374, grad/param norm = 1.4756e-01, time/batch = 0.6805s	
19630/30300 (epoch 32.393), train_loss = 0.94645560, grad/param norm = 1.4309e-01, time/batch = 0.6821s	
19631/30300 (epoch 32.394), train_loss = 1.13408980, grad/param norm = 1.6281e-01, time/batch = 0.6826s	
19632/30300 (epoch 32.396), train_loss = 1.19739588, grad/param norm = 1.5071e-01, time/batch = 0.6836s	
19633/30300 (epoch 32.398), train_loss = 1.06747014, grad/param norm = 1.7451e-01, time/batch = 0.6838s	
19634/30300 (epoch 32.399), train_loss = 1.04206429, grad/param norm = 1.7005e-01, time/batch = 0.6799s	
19635/30300 (epoch 32.401), train_loss = 1.11992994, grad/param norm = 2.1913e-01, time/batch = 0.6823s	
19636/30300 (epoch 32.403), train_loss = 1.07748924, grad/param norm = 1.6602e-01, time/batch = 0.6879s	
19637/30300 (epoch 32.404), train_loss = 1.03561702, grad/param norm = 1.9661e-01, time/batch = 0.6944s	
19638/30300 (epoch 32.406), train_loss = 1.11565760, grad/param norm = 1.6267e-01, time/batch = 0.6911s	
19639/30300 (epoch 32.408), train_loss = 0.96936855, grad/param norm = 1.5759e-01, time/batch = 0.6917s	
19640/30300 (epoch 32.409), train_loss = 0.96488915, grad/param norm = 1.6340e-01, time/batch = 0.6834s	
19641/30300 (epoch 32.411), train_loss = 1.00808762, grad/param norm = 1.5504e-01, time/batch = 0.7235s	
19642/30300 (epoch 32.413), train_loss = 0.92022959, grad/param norm = 1.5984e-01, time/batch = 0.7049s	
19643/30300 (epoch 32.414), train_loss = 1.14961005, grad/param norm = 1.7789e-01, time/batch = 0.6814s	
19644/30300 (epoch 32.416), train_loss = 1.03552852, grad/param norm = 1.4979e-01, time/batch = 0.6812s	
19645/30300 (epoch 32.417), train_loss = 0.99356421, grad/param norm = 1.6414e-01, time/batch = 0.6826s	
19646/30300 (epoch 32.419), train_loss = 1.00349462, grad/param norm = 1.6092e-01, time/batch = 0.6810s	
19647/30300 (epoch 32.421), train_loss = 1.03144221, grad/param norm = 2.0258e-01, time/batch = 0.6807s	
19648/30300 (epoch 32.422), train_loss = 1.09816712, grad/param norm = 1.7113e-01, time/batch = 0.6842s	
19649/30300 (epoch 32.424), train_loss = 1.09986070, grad/param norm = 1.6362e-01, time/batch = 0.6812s	
19650/30300 (epoch 32.426), train_loss = 1.03653155, grad/param norm = 1.6681e-01, time/batch = 0.6828s	
19651/30300 (epoch 32.427), train_loss = 1.02260620, grad/param norm = 1.6686e-01, time/batch = 0.6845s	
19652/30300 (epoch 32.429), train_loss = 1.07975060, grad/param norm = 1.5324e-01, time/batch = 0.6885s	
19653/30300 (epoch 32.431), train_loss = 1.12913348, grad/param norm = 1.7004e-01, time/batch = 0.6814s	
19654/30300 (epoch 32.432), train_loss = 1.05250235, grad/param norm = 1.5224e-01, time/batch = 0.6828s	
19655/30300 (epoch 32.434), train_loss = 0.96836185, grad/param norm = 1.5696e-01, time/batch = 0.6818s	
19656/30300 (epoch 32.436), train_loss = 1.19464425, grad/param norm = 1.6241e-01, time/batch = 0.6829s	
19657/30300 (epoch 32.437), train_loss = 0.97026840, grad/param norm = 1.4684e-01, time/batch = 0.6823s	
19658/30300 (epoch 32.439), train_loss = 1.01702547, grad/param norm = 1.5246e-01, time/batch = 0.6814s	
19659/30300 (epoch 32.441), train_loss = 1.04217822, grad/param norm = 1.4015e-01, time/batch = 0.6811s	
19660/30300 (epoch 32.442), train_loss = 1.00209017, grad/param norm = 1.5634e-01, time/batch = 0.7265s	
19661/30300 (epoch 32.444), train_loss = 0.89846847, grad/param norm = 1.5129e-01, time/batch = 0.7088s	
19662/30300 (epoch 32.446), train_loss = 1.04800381, grad/param norm = 1.4558e-01, time/batch = 0.6970s	
19663/30300 (epoch 32.447), train_loss = 1.06922477, grad/param norm = 1.5147e-01, time/batch = 0.7107s	
19664/30300 (epoch 32.449), train_loss = 1.00609595, grad/param norm = 1.4857e-01, time/batch = 0.7013s	
19665/30300 (epoch 32.450), train_loss = 1.11599676, grad/param norm = 1.5332e-01, time/batch = 0.6916s	
19666/30300 (epoch 32.452), train_loss = 1.20662699, grad/param norm = 1.6478e-01, time/batch = 0.6883s	
19667/30300 (epoch 32.454), train_loss = 1.12956464, grad/param norm = 1.4728e-01, time/batch = 0.6919s	
19668/30300 (epoch 32.455), train_loss = 1.07240790, grad/param norm = 1.6565e-01, time/batch = 0.6901s	
19669/30300 (epoch 32.457), train_loss = 1.06053866, grad/param norm = 1.7242e-01, time/batch = 0.6957s	
19670/30300 (epoch 32.459), train_loss = 1.13485838, grad/param norm = 1.8696e-01, time/batch = 0.6999s	
19671/30300 (epoch 32.460), train_loss = 1.13031228, grad/param norm = 1.5408e-01, time/batch = 0.7019s	
19672/30300 (epoch 32.462), train_loss = 1.16209735, grad/param norm = 1.7220e-01, time/batch = 0.7019s	
19673/30300 (epoch 32.464), train_loss = 0.89611861, grad/param norm = 1.7924e-01, time/batch = 0.6997s	
19674/30300 (epoch 32.465), train_loss = 0.91542344, grad/param norm = 1.4617e-01, time/batch = 0.7183s	
19675/30300 (epoch 32.467), train_loss = 0.90226702, grad/param norm = 1.3996e-01, time/batch = 0.7100s	
19676/30300 (epoch 32.469), train_loss = 1.00861470, grad/param norm = 1.4541e-01, time/batch = 0.6859s	
19677/30300 (epoch 32.470), train_loss = 1.02622044, grad/param norm = 1.6974e-01, time/batch = 0.6869s	
19678/30300 (epoch 32.472), train_loss = 1.03386263, grad/param norm = 1.4705e-01, time/batch = 0.6846s	
19679/30300 (epoch 32.474), train_loss = 1.02285953, grad/param norm = 1.9416e-01, time/batch = 0.6866s	
19680/30300 (epoch 32.475), train_loss = 1.00680235, grad/param norm = 1.4341e-01, time/batch = 0.6848s	
19681/30300 (epoch 32.477), train_loss = 1.08524856, grad/param norm = 1.6679e-01, time/batch = 0.6840s	
19682/30300 (epoch 32.479), train_loss = 1.04903684, grad/param norm = 1.6854e-01, time/batch = 0.6902s	
19683/30300 (epoch 32.480), train_loss = 1.09208330, grad/param norm = 1.5165e-01, time/batch = 0.6967s	
19684/30300 (epoch 32.482), train_loss = 1.13114887, grad/param norm = 1.4794e-01, time/batch = 0.6853s	
19685/30300 (epoch 32.483), train_loss = 1.04429918, grad/param norm = 1.6401e-01, time/batch = 0.6857s	
19686/30300 (epoch 32.485), train_loss = 1.08921816, grad/param norm = 1.5087e-01, time/batch = 0.6877s	
19687/30300 (epoch 32.487), train_loss = 1.16437674, grad/param norm = 1.7862e-01, time/batch = 0.6811s	
19688/30300 (epoch 32.488), train_loss = 1.18084191, grad/param norm = 1.4643e-01, time/batch = 0.6828s	
19689/30300 (epoch 32.490), train_loss = 0.95079040, grad/param norm = 1.5594e-01, time/batch = 0.6843s	
19690/30300 (epoch 32.492), train_loss = 1.04587663, grad/param norm = 1.7911e-01, time/batch = 0.6861s	
19691/30300 (epoch 32.493), train_loss = 1.06333862, grad/param norm = 1.7958e-01, time/batch = 0.6875s	
19692/30300 (epoch 32.495), train_loss = 1.04222280, grad/param norm = 1.4482e-01, time/batch = 0.6817s	
19693/30300 (epoch 32.497), train_loss = 1.08529064, grad/param norm = 1.5930e-01, time/batch = 0.6840s	
19694/30300 (epoch 32.498), train_loss = 1.12842940, grad/param norm = 1.7427e-01, time/batch = 0.6885s	
19695/30300 (epoch 32.500), train_loss = 1.04470964, grad/param norm = 1.6027e-01, time/batch = 0.6822s	
19696/30300 (epoch 32.502), train_loss = 1.05429188, grad/param norm = 1.7590e-01, time/batch = 0.6868s	
19697/30300 (epoch 32.503), train_loss = 1.16497444, grad/param norm = 1.5564e-01, time/batch = 0.7201s	
19698/30300 (epoch 32.505), train_loss = 0.96354366, grad/param norm = 1.3945e-01, time/batch = 0.7144s	
19699/30300 (epoch 32.507), train_loss = 0.97952144, grad/param norm = 1.9640e-01, time/batch = 0.6887s	
19700/30300 (epoch 32.508), train_loss = 1.04131918, grad/param norm = 1.9779e-01, time/batch = 0.6827s	
19701/30300 (epoch 32.510), train_loss = 1.14370639, grad/param norm = 1.9559e-01, time/batch = 0.6909s	
19702/30300 (epoch 32.512), train_loss = 1.00506920, grad/param norm = 1.4745e-01, time/batch = 0.6918s	
19703/30300 (epoch 32.513), train_loss = 1.07413768, grad/param norm = 1.5698e-01, time/batch = 0.7070s	
19704/30300 (epoch 32.515), train_loss = 1.06926835, grad/param norm = 1.6249e-01, time/batch = 0.6912s	
19705/30300 (epoch 32.517), train_loss = 0.88894957, grad/param norm = 1.3313e-01, time/batch = 0.6824s	
19706/30300 (epoch 32.518), train_loss = 1.14741944, grad/param norm = 1.7659e-01, time/batch = 0.6812s	
19707/30300 (epoch 32.520), train_loss = 1.10846272, grad/param norm = 1.8553e-01, time/batch = 0.6825s	
19708/30300 (epoch 32.521), train_loss = 0.98573681, grad/param norm = 1.8811e-01, time/batch = 0.6829s	
19709/30300 (epoch 32.523), train_loss = 1.21959194, grad/param norm = 1.8773e-01, time/batch = 0.6813s	
19710/30300 (epoch 32.525), train_loss = 1.00198867, grad/param norm = 1.5769e-01, time/batch = 0.6849s	
19711/30300 (epoch 32.526), train_loss = 1.07243493, grad/param norm = 1.4768e-01, time/batch = 0.6951s	
19712/30300 (epoch 32.528), train_loss = 0.96359658, grad/param norm = 1.5495e-01, time/batch = 0.7260s	
19713/30300 (epoch 32.530), train_loss = 0.94591854, grad/param norm = 1.5412e-01, time/batch = 0.6878s	
19714/30300 (epoch 32.531), train_loss = 1.10761820, grad/param norm = 1.6847e-01, time/batch = 0.6820s	
19715/30300 (epoch 32.533), train_loss = 1.05117660, grad/param norm = 1.6064e-01, time/batch = 0.6813s	
19716/30300 (epoch 32.535), train_loss = 1.02330643, grad/param norm = 1.4295e-01, time/batch = 0.6817s	
19717/30300 (epoch 32.536), train_loss = 1.11587904, grad/param norm = 1.9420e-01, time/batch = 0.6789s	
19718/30300 (epoch 32.538), train_loss = 0.95406698, grad/param norm = 1.7121e-01, time/batch = 0.6799s	
19719/30300 (epoch 32.540), train_loss = 1.01284271, grad/param norm = 1.7283e-01, time/batch = 0.6799s	
19720/30300 (epoch 32.541), train_loss = 1.07496646, grad/param norm = 1.7972e-01, time/batch = 0.6820s	
19721/30300 (epoch 32.543), train_loss = 1.05182442, grad/param norm = 1.5648e-01, time/batch = 0.6834s	
19722/30300 (epoch 32.545), train_loss = 1.12153756, grad/param norm = 2.4407e-01, time/batch = 0.6839s	
19723/30300 (epoch 32.546), train_loss = 1.25645904, grad/param norm = 1.6236e-01, time/batch = 0.6864s	
19724/30300 (epoch 32.548), train_loss = 1.00999240, grad/param norm = 1.4747e-01, time/batch = 0.6873s	
19725/30300 (epoch 32.550), train_loss = 1.12061176, grad/param norm = 2.1943e-01, time/batch = 0.6837s	
19726/30300 (epoch 32.551), train_loss = 1.01181378, grad/param norm = 1.6420e-01, time/batch = 0.6845s	
19727/30300 (epoch 32.553), train_loss = 1.02796277, grad/param norm = 1.6424e-01, time/batch = 0.6805s	
19728/30300 (epoch 32.554), train_loss = 1.06544076, grad/param norm = 1.6301e-01, time/batch = 0.6809s	
19729/30300 (epoch 32.556), train_loss = 1.10736412, grad/param norm = 1.5973e-01, time/batch = 0.6819s	
19730/30300 (epoch 32.558), train_loss = 1.14957221, grad/param norm = 1.7729e-01, time/batch = 0.6970s	
19731/30300 (epoch 32.559), train_loss = 1.07667859, grad/param norm = 1.6121e-01, time/batch = 0.7274s	
19732/30300 (epoch 32.561), train_loss = 0.87035844, grad/param norm = 1.4492e-01, time/batch = 0.6836s	
19733/30300 (epoch 32.563), train_loss = 0.96120664, grad/param norm = 1.5440e-01, time/batch = 0.6809s	
19734/30300 (epoch 32.564), train_loss = 1.00449695, grad/param norm = 1.4508e-01, time/batch = 0.6818s	
19735/30300 (epoch 32.566), train_loss = 1.05254185, grad/param norm = 1.7407e-01, time/batch = 0.6818s	
19736/30300 (epoch 32.568), train_loss = 0.91046826, grad/param norm = 1.6562e-01, time/batch = 0.6824s	
19737/30300 (epoch 32.569), train_loss = 1.09001626, grad/param norm = 1.6347e-01, time/batch = 0.6825s	
19738/30300 (epoch 32.571), train_loss = 1.07091131, grad/param norm = 1.7186e-01, time/batch = 0.6839s	
19739/30300 (epoch 32.573), train_loss = 1.10957738, grad/param norm = 1.6729e-01, time/batch = 0.6809s	
19740/30300 (epoch 32.574), train_loss = 1.10457930, grad/param norm = 1.5238e-01, time/batch = 0.6800s	
19741/30300 (epoch 32.576), train_loss = 1.01853806, grad/param norm = 1.4307e-01, time/batch = 0.6836s	
19742/30300 (epoch 32.578), train_loss = 0.93129820, grad/param norm = 1.4613e-01, time/batch = 0.6843s	
19743/30300 (epoch 32.579), train_loss = 1.09370691, grad/param norm = 1.6496e-01, time/batch = 0.6831s	
19744/30300 (epoch 32.581), train_loss = 1.18805761, grad/param norm = 1.6250e-01, time/batch = 0.7001s	
19745/30300 (epoch 32.583), train_loss = 1.21691166, grad/param norm = 1.8362e-01, time/batch = 0.6837s	
19746/30300 (epoch 32.584), train_loss = 1.16929173, grad/param norm = 1.6546e-01, time/batch = 0.6809s	
19747/30300 (epoch 32.586), train_loss = 1.02539194, grad/param norm = 1.5826e-01, time/batch = 0.6843s	
19748/30300 (epoch 32.587), train_loss = 1.05761155, grad/param norm = 1.6562e-01, time/batch = 0.6807s	
19749/30300 (epoch 32.589), train_loss = 0.99363912, grad/param norm = 1.5831e-01, time/batch = 0.7031s	
19750/30300 (epoch 32.591), train_loss = 1.08725007, grad/param norm = 1.5435e-01, time/batch = 0.7193s	
19751/30300 (epoch 32.592), train_loss = 1.03015544, grad/param norm = 1.4786e-01, time/batch = 0.6824s	
19752/30300 (epoch 32.594), train_loss = 1.09304299, grad/param norm = 1.7542e-01, time/batch = 0.6814s	
19753/30300 (epoch 32.596), train_loss = 0.96639817, grad/param norm = 1.5210e-01, time/batch = 0.6821s	
19754/30300 (epoch 32.597), train_loss = 1.01847236, grad/param norm = 1.6254e-01, time/batch = 0.6812s	
19755/30300 (epoch 32.599), train_loss = 0.89444563, grad/param norm = 1.3945e-01, time/batch = 0.6806s	
19756/30300 (epoch 32.601), train_loss = 1.09523172, grad/param norm = 1.5733e-01, time/batch = 0.6936s	
19757/30300 (epoch 32.602), train_loss = 1.03916992, grad/param norm = 1.5717e-01, time/batch = 0.7057s	
19758/30300 (epoch 32.604), train_loss = 0.99291739, grad/param norm = 1.5254e-01, time/batch = 0.6855s	
19759/30300 (epoch 32.606), train_loss = 1.00156687, grad/param norm = 2.1682e-01, time/batch = 0.7139s	
19760/30300 (epoch 32.607), train_loss = 1.13892627, grad/param norm = 1.9742e-01, time/batch = 0.7014s	
19761/30300 (epoch 32.609), train_loss = 1.25334270, grad/param norm = 1.7479e-01, time/batch = 0.7035s	
19762/30300 (epoch 32.611), train_loss = 1.01830867, grad/param norm = 1.4826e-01, time/batch = 0.7017s	
19763/30300 (epoch 32.612), train_loss = 0.96295356, grad/param norm = 1.4368e-01, time/batch = 0.6960s	
19764/30300 (epoch 32.614), train_loss = 1.03415572, grad/param norm = 1.5054e-01, time/batch = 0.6834s	
19765/30300 (epoch 32.616), train_loss = 1.09820452, grad/param norm = 2.0948e-01, time/batch = 0.6799s	
19766/30300 (epoch 32.617), train_loss = 1.07959205, grad/param norm = 1.5948e-01, time/batch = 0.6908s	
19767/30300 (epoch 32.619), train_loss = 0.88013712, grad/param norm = 1.4845e-01, time/batch = 0.6899s	
19768/30300 (epoch 32.620), train_loss = 1.11782851, grad/param norm = 1.6017e-01, time/batch = 0.7239s	
19769/30300 (epoch 32.622), train_loss = 1.06195960, grad/param norm = 1.8339e-01, time/batch = 0.7052s	
19770/30300 (epoch 32.624), train_loss = 1.04807482, grad/param norm = 1.5950e-01, time/batch = 0.6817s	
19771/30300 (epoch 32.625), train_loss = 1.04631176, grad/param norm = 1.8854e-01, time/batch = 0.6829s	
19772/30300 (epoch 32.627), train_loss = 1.17091165, grad/param norm = 1.8111e-01, time/batch = 0.6995s	
19773/30300 (epoch 32.629), train_loss = 1.20316327, grad/param norm = 1.6458e-01, time/batch = 0.6846s	
19774/30300 (epoch 32.630), train_loss = 1.09011417, grad/param norm = 1.6996e-01, time/batch = 0.6799s	
19775/30300 (epoch 32.632), train_loss = 1.12864034, grad/param norm = 1.8042e-01, time/batch = 0.6838s	
19776/30300 (epoch 32.634), train_loss = 1.00424110, grad/param norm = 1.5381e-01, time/batch = 0.6829s	
19777/30300 (epoch 32.635), train_loss = 1.12397980, grad/param norm = 1.9772e-01, time/batch = 0.6801s	
19778/30300 (epoch 32.637), train_loss = 1.15543175, grad/param norm = 1.8508e-01, time/batch = 0.6849s	
19779/30300 (epoch 32.639), train_loss = 1.03860684, grad/param norm = 1.6071e-01, time/batch = 0.6816s	
19780/30300 (epoch 32.640), train_loss = 1.15682911, grad/param norm = 1.7527e-01, time/batch = 0.6829s	
19781/30300 (epoch 32.642), train_loss = 1.04162333, grad/param norm = 1.4012e-01, time/batch = 0.6864s	
19782/30300 (epoch 32.644), train_loss = 1.15790484, grad/param norm = 1.8817e-01, time/batch = 0.6832s	
19783/30300 (epoch 32.645), train_loss = 1.01315079, grad/param norm = 1.4594e-01, time/batch = 0.6830s	
19784/30300 (epoch 32.647), train_loss = 1.08715460, grad/param norm = 1.5173e-01, time/batch = 0.6816s	
19785/30300 (epoch 32.649), train_loss = 1.06160527, grad/param norm = 2.0751e-01, time/batch = 0.6811s	
19786/30300 (epoch 32.650), train_loss = 1.05496537, grad/param norm = 1.5457e-01, time/batch = 0.6864s	
19787/30300 (epoch 32.652), train_loss = 1.04299888, grad/param norm = 1.6614e-01, time/batch = 0.7095s	
19788/30300 (epoch 32.653), train_loss = 1.24427536, grad/param norm = 1.6078e-01, time/batch = 0.6828s	
19789/30300 (epoch 32.655), train_loss = 1.02863159, grad/param norm = 1.7546e-01, time/batch = 0.6841s	
19790/30300 (epoch 32.657), train_loss = 1.01129219, grad/param norm = 1.9477e-01, time/batch = 0.6847s	
19791/30300 (epoch 32.658), train_loss = 1.01191781, grad/param norm = 1.5456e-01, time/batch = 0.6859s	
19792/30300 (epoch 32.660), train_loss = 1.07474301, grad/param norm = 1.6170e-01, time/batch = 0.6825s	
19793/30300 (epoch 32.662), train_loss = 1.08495858, grad/param norm = 2.0725e-01, time/batch = 0.6804s	
19794/30300 (epoch 32.663), train_loss = 1.12635283, grad/param norm = 1.6719e-01, time/batch = 0.6913s	
19795/30300 (epoch 32.665), train_loss = 1.01550614, grad/param norm = 1.7621e-01, time/batch = 0.6883s	
19796/30300 (epoch 32.667), train_loss = 1.12623783, grad/param norm = 1.8473e-01, time/batch = 0.6868s	
19797/30300 (epoch 32.668), train_loss = 1.16798183, grad/param norm = 1.8077e-01, time/batch = 0.6852s	
19798/30300 (epoch 32.670), train_loss = 1.20729277, grad/param norm = 1.9405e-01, time/batch = 0.6857s	
19799/30300 (epoch 32.672), train_loss = 1.07353449, grad/param norm = 1.6571e-01, time/batch = 0.6905s	
19800/30300 (epoch 32.673), train_loss = 1.11896008, grad/param norm = 1.8661e-01, time/batch = 0.6827s	
19801/30300 (epoch 32.675), train_loss = 1.01936220, grad/param norm = 1.6633e-01, time/batch = 0.6869s	
19802/30300 (epoch 32.677), train_loss = 1.02490250, grad/param norm = 1.5184e-01, time/batch = 0.6823s	
19803/30300 (epoch 32.678), train_loss = 1.01521160, grad/param norm = 1.5361e-01, time/batch = 0.6868s	
19804/30300 (epoch 32.680), train_loss = 0.92355202, grad/param norm = 1.4060e-01, time/batch = 0.6850s	
19805/30300 (epoch 32.682), train_loss = 1.04325057, grad/param norm = 1.6310e-01, time/batch = 0.6922s	
19806/30300 (epoch 32.683), train_loss = 1.17329675, grad/param norm = 1.6135e-01, time/batch = 0.7260s	
19807/30300 (epoch 32.685), train_loss = 1.13801445, grad/param norm = 1.9078e-01, time/batch = 0.6919s	
19808/30300 (epoch 32.686), train_loss = 1.02209648, grad/param norm = 1.3678e-01, time/batch = 0.6818s	
19809/30300 (epoch 32.688), train_loss = 1.05692315, grad/param norm = 1.4494e-01, time/batch = 0.6818s	
19810/30300 (epoch 32.690), train_loss = 1.00876873, grad/param norm = 1.6545e-01, time/batch = 0.6923s	
19811/30300 (epoch 32.691), train_loss = 1.09872917, grad/param norm = 1.5992e-01, time/batch = 0.6954s	
19812/30300 (epoch 32.693), train_loss = 1.34918837, grad/param norm = 2.0115e-01, time/batch = 0.6869s	
19813/30300 (epoch 32.695), train_loss = 1.13922480, grad/param norm = 1.6782e-01, time/batch = 0.6839s	
19814/30300 (epoch 32.696), train_loss = 1.13355423, grad/param norm = 1.8927e-01, time/batch = 0.6846s	
19815/30300 (epoch 32.698), train_loss = 1.01380453, grad/param norm = 1.6470e-01, time/batch = 0.6868s	
19816/30300 (epoch 32.700), train_loss = 1.00403484, grad/param norm = 1.6990e-01, time/batch = 0.6815s	
19817/30300 (epoch 32.701), train_loss = 0.92537738, grad/param norm = 1.4843e-01, time/batch = 0.6801s	
19818/30300 (epoch 32.703), train_loss = 1.07660127, grad/param norm = 1.5173e-01, time/batch = 0.6805s	
19819/30300 (epoch 32.705), train_loss = 1.01061160, grad/param norm = 1.6384e-01, time/batch = 0.6809s	
19820/30300 (epoch 32.706), train_loss = 1.12081784, grad/param norm = 1.7223e-01, time/batch = 0.6810s	
19821/30300 (epoch 32.708), train_loss = 1.06834762, grad/param norm = 1.5685e-01, time/batch = 0.6855s	
19822/30300 (epoch 32.710), train_loss = 1.03753286, grad/param norm = 1.5189e-01, time/batch = 0.6819s	
19823/30300 (epoch 32.711), train_loss = 1.00730221, grad/param norm = 1.5777e-01, time/batch = 0.6843s	
19824/30300 (epoch 32.713), train_loss = 0.99773740, grad/param norm = 1.6164e-01, time/batch = 0.7004s	
19825/30300 (epoch 32.715), train_loss = 1.01665583, grad/param norm = 1.7088e-01, time/batch = 0.7258s	
19826/30300 (epoch 32.716), train_loss = 1.13966243, grad/param norm = 1.6744e-01, time/batch = 0.6834s	
19827/30300 (epoch 32.718), train_loss = 1.17309580, grad/param norm = 1.6353e-01, time/batch = 0.6833s	
19828/30300 (epoch 32.719), train_loss = 1.00946313, grad/param norm = 1.6726e-01, time/batch = 0.6826s	
19829/30300 (epoch 32.721), train_loss = 1.04762627, grad/param norm = 1.6651e-01, time/batch = 0.6829s	
19830/30300 (epoch 32.723), train_loss = 0.99611730, grad/param norm = 1.6209e-01, time/batch = 0.6823s	
19831/30300 (epoch 32.724), train_loss = 1.11186899, grad/param norm = 1.8304e-01, time/batch = 0.6859s	
19832/30300 (epoch 32.726), train_loss = 1.37480951, grad/param norm = 2.0617e-01, time/batch = 0.6829s	
19833/30300 (epoch 32.728), train_loss = 1.12448703, grad/param norm = 1.8439e-01, time/batch = 0.6832s	
19834/30300 (epoch 32.729), train_loss = 1.03694854, grad/param norm = 1.6691e-01, time/batch = 0.6811s	
19835/30300 (epoch 32.731), train_loss = 1.07280036, grad/param norm = 1.9372e-01, time/batch = 0.6883s	
19836/30300 (epoch 32.733), train_loss = 1.07950440, grad/param norm = 1.8137e-01, time/batch = 0.6885s	
19837/30300 (epoch 32.734), train_loss = 1.15702378, grad/param norm = 1.5650e-01, time/batch = 0.6850s	
19838/30300 (epoch 32.736), train_loss = 1.07287523, grad/param norm = 1.6057e-01, time/batch = 0.6860s	
19839/30300 (epoch 32.738), train_loss = 1.00456801, grad/param norm = 1.3810e-01, time/batch = 0.7219s	
19840/30300 (epoch 32.739), train_loss = 1.15074762, grad/param norm = 1.6849e-01, time/batch = 0.7027s	
19841/30300 (epoch 32.741), train_loss = 1.21055443, grad/param norm = 1.5438e-01, time/batch = 0.6835s	
19842/30300 (epoch 32.743), train_loss = 1.04866785, grad/param norm = 1.7403e-01, time/batch = 0.6873s	
19843/30300 (epoch 32.744), train_loss = 1.11068040, grad/param norm = 1.7440e-01, time/batch = 0.6938s	
19844/30300 (epoch 32.746), train_loss = 1.02772534, grad/param norm = 1.4661e-01, time/batch = 0.7095s	
19845/30300 (epoch 32.748), train_loss = 1.04795665, grad/param norm = 1.7860e-01, time/batch = 0.7015s	
19846/30300 (epoch 32.749), train_loss = 1.10254672, grad/param norm = 1.7279e-01, time/batch = 0.7046s	
19847/30300 (epoch 32.751), train_loss = 1.08369429, grad/param norm = 1.6547e-01, time/batch = 0.7054s	
19848/30300 (epoch 32.752), train_loss = 1.03559713, grad/param norm = 1.7008e-01, time/batch = 0.6870s	
19849/30300 (epoch 32.754), train_loss = 1.02472986, grad/param norm = 1.5264e-01, time/batch = 0.6840s	
19850/30300 (epoch 32.756), train_loss = 1.04765200, grad/param norm = 1.7350e-01, time/batch = 0.6820s	
19851/30300 (epoch 32.757), train_loss = 1.02717203, grad/param norm = 1.5559e-01, time/batch = 0.6855s	
19852/30300 (epoch 32.759), train_loss = 1.10132518, grad/param norm = 1.5092e-01, time/batch = 0.6845s	
19853/30300 (epoch 32.761), train_loss = 0.93896611, grad/param norm = 1.5301e-01, time/batch = 0.6847s	
19854/30300 (epoch 32.762), train_loss = 0.96218315, grad/param norm = 1.5935e-01, time/batch = 0.6911s	
19855/30300 (epoch 32.764), train_loss = 1.04966087, grad/param norm = 1.5638e-01, time/batch = 0.7007s	
19856/30300 (epoch 32.766), train_loss = 1.16381984, grad/param norm = 1.7681e-01, time/batch = 0.6874s	
19857/30300 (epoch 32.767), train_loss = 1.12031720, grad/param norm = 1.9654e-01, time/batch = 0.7112s	
19858/30300 (epoch 32.769), train_loss = 1.09086579, grad/param norm = 1.5478e-01, time/batch = 0.7259s	
19859/30300 (epoch 32.771), train_loss = 1.04255462, grad/param norm = 2.3477e-01, time/batch = 0.6909s	
19860/30300 (epoch 32.772), train_loss = 1.09336691, grad/param norm = 1.7811e-01, time/batch = 0.6856s	
19861/30300 (epoch 32.774), train_loss = 1.20260357, grad/param norm = 1.6395e-01, time/batch = 0.6986s	
19862/30300 (epoch 32.776), train_loss = 1.04298334, grad/param norm = 1.7147e-01, time/batch = 0.6873s	
19863/30300 (epoch 32.777), train_loss = 1.18005063, grad/param norm = 1.5743e-01, time/batch = 0.6853s	
19864/30300 (epoch 32.779), train_loss = 1.19346268, grad/param norm = 1.8308e-01, time/batch = 0.6982s	
19865/30300 (epoch 32.781), train_loss = 1.07164728, grad/param norm = 1.6267e-01, time/batch = 0.6879s	
19866/30300 (epoch 32.782), train_loss = 1.01091858, grad/param norm = 1.5205e-01, time/batch = 0.6858s	
19867/30300 (epoch 32.784), train_loss = 0.99508837, grad/param norm = 1.4062e-01, time/batch = 0.6859s	
19868/30300 (epoch 32.785), train_loss = 1.17056426, grad/param norm = 1.8628e-01, time/batch = 0.6858s	
19869/30300 (epoch 32.787), train_loss = 0.90290553, grad/param norm = 1.6201e-01, time/batch = 0.6866s	
19870/30300 (epoch 32.789), train_loss = 1.25170951, grad/param norm = 1.8939e-01, time/batch = 0.6837s	
19871/30300 (epoch 32.790), train_loss = 1.11047570, grad/param norm = 2.1443e-01, time/batch = 0.6830s	
19872/30300 (epoch 32.792), train_loss = 0.88810932, grad/param norm = 1.6453e-01, time/batch = 0.6841s	
19873/30300 (epoch 32.794), train_loss = 1.06431896, grad/param norm = 1.7214e-01, time/batch = 0.6831s	
19874/30300 (epoch 32.795), train_loss = 0.98937083, grad/param norm = 1.4270e-01, time/batch = 0.6817s	
19875/30300 (epoch 32.797), train_loss = 1.21518085, grad/param norm = 1.8950e-01, time/batch = 0.6919s	
19876/30300 (epoch 32.799), train_loss = 1.14595586, grad/param norm = 1.9495e-01, time/batch = 0.7150s	
19877/30300 (epoch 32.800), train_loss = 1.15405109, grad/param norm = 1.7444e-01, time/batch = 0.7186s	
19878/30300 (epoch 32.802), train_loss = 1.31565149, grad/param norm = 1.8215e-01, time/batch = 0.6805s	
19879/30300 (epoch 32.804), train_loss = 1.14472660, grad/param norm = 1.8691e-01, time/batch = 0.6824s	
19880/30300 (epoch 32.805), train_loss = 1.21292873, grad/param norm = 1.7131e-01, time/batch = 0.6811s	
19881/30300 (epoch 32.807), train_loss = 1.03699238, grad/param norm = 1.8207e-01, time/batch = 0.6834s	
19882/30300 (epoch 32.809), train_loss = 1.14388418, grad/param norm = 1.7288e-01, time/batch = 0.6877s	
19883/30300 (epoch 32.810), train_loss = 1.10945056, grad/param norm = 1.5882e-01, time/batch = 0.6874s	
19884/30300 (epoch 32.812), train_loss = 1.02319909, grad/param norm = 1.6180e-01, time/batch = 0.6903s	
19885/30300 (epoch 32.814), train_loss = 1.06937070, grad/param norm = 1.5930e-01, time/batch = 0.6855s	
19886/30300 (epoch 32.815), train_loss = 1.07468882, grad/param norm = 1.7114e-01, time/batch = 0.6807s	
19887/30300 (epoch 32.817), train_loss = 1.16966581, grad/param norm = 1.8681e-01, time/batch = 0.6809s	
19888/30300 (epoch 32.818), train_loss = 1.09495479, grad/param norm = 1.6372e-01, time/batch = 0.6816s	
19889/30300 (epoch 32.820), train_loss = 1.23361239, grad/param norm = 1.9302e-01, time/batch = 0.6842s	
19890/30300 (epoch 32.822), train_loss = 1.21996890, grad/param norm = 1.8886e-01, time/batch = 0.6820s	
19891/30300 (epoch 32.823), train_loss = 1.23473058, grad/param norm = 1.8389e-01, time/batch = 0.6845s	
19892/30300 (epoch 32.825), train_loss = 1.20804794, grad/param norm = 1.7442e-01, time/batch = 0.6841s	
19893/30300 (epoch 32.827), train_loss = 0.92594355, grad/param norm = 1.6593e-01, time/batch = 0.6912s	
19894/30300 (epoch 32.828), train_loss = 1.14815638, grad/param norm = 1.7041e-01, time/batch = 0.6875s	
19895/30300 (epoch 32.830), train_loss = 1.12442128, grad/param norm = 1.6281e-01, time/batch = 0.7133s	
19896/30300 (epoch 32.832), train_loss = 1.00906125, grad/param norm = 1.7382e-01, time/batch = 0.7100s	
19897/30300 (epoch 32.833), train_loss = 1.10547802, grad/param norm = 1.7755e-01, time/batch = 0.6832s	
19898/30300 (epoch 32.835), train_loss = 1.00805407, grad/param norm = 1.5266e-01, time/batch = 0.6804s	
19899/30300 (epoch 32.837), train_loss = 0.96385602, grad/param norm = 1.4936e-01, time/batch = 0.6822s	
19900/30300 (epoch 32.838), train_loss = 0.97287576, grad/param norm = 1.5033e-01, time/batch = 0.6809s	
19901/30300 (epoch 32.840), train_loss = 1.17363045, grad/param norm = 1.4687e-01, time/batch = 0.6841s	
19902/30300 (epoch 32.842), train_loss = 1.02997646, grad/param norm = 1.4693e-01, time/batch = 0.6798s	
19903/30300 (epoch 32.843), train_loss = 1.11468865, grad/param norm = 1.7448e-01, time/batch = 0.6812s	
19904/30300 (epoch 32.845), train_loss = 1.13855690, grad/param norm = 1.5425e-01, time/batch = 0.6811s	
19905/30300 (epoch 32.847), train_loss = 1.08809035, grad/param norm = 1.5674e-01, time/batch = 0.6800s	
19906/30300 (epoch 32.848), train_loss = 1.13870008, grad/param norm = 1.7537e-01, time/batch = 0.6822s	
19907/30300 (epoch 32.850), train_loss = 1.07087968, grad/param norm = 1.6034e-01, time/batch = 0.6808s	
19908/30300 (epoch 32.851), train_loss = 1.11506833, grad/param norm = 2.1749e-01, time/batch = 0.6850s	
19909/30300 (epoch 32.853), train_loss = 1.04474318, grad/param norm = 1.7745e-01, time/batch = 0.6819s	
19910/30300 (epoch 32.855), train_loss = 1.03816343, grad/param norm = 1.6656e-01, time/batch = 0.6811s	
19911/30300 (epoch 32.856), train_loss = 1.09099510, grad/param norm = 1.5911e-01, time/batch = 0.6826s	
19912/30300 (epoch 32.858), train_loss = 1.01081960, grad/param norm = 1.5406e-01, time/batch = 0.6815s	
19913/30300 (epoch 32.860), train_loss = 0.99134027, grad/param norm = 1.5494e-01, time/batch = 0.6818s	
19914/30300 (epoch 32.861), train_loss = 1.22552840, grad/param norm = 1.5824e-01, time/batch = 0.7196s	
19915/30300 (epoch 32.863), train_loss = 1.06118067, grad/param norm = 1.6019e-01, time/batch = 0.7057s	
19916/30300 (epoch 32.865), train_loss = 1.13644992, grad/param norm = 1.7909e-01, time/batch = 0.6829s	
19917/30300 (epoch 32.866), train_loss = 1.14835814, grad/param norm = 2.0238e-01, time/batch = 0.6801s	
19918/30300 (epoch 32.868), train_loss = 1.08690096, grad/param norm = 1.5615e-01, time/batch = 0.6834s	
19919/30300 (epoch 32.870), train_loss = 1.01055724, grad/param norm = 1.6466e-01, time/batch = 0.6809s	
19920/30300 (epoch 32.871), train_loss = 1.07389591, grad/param norm = 1.5720e-01, time/batch = 0.6801s	
19921/30300 (epoch 32.873), train_loss = 1.07252073, grad/param norm = 1.5788e-01, time/batch = 0.6825s	
19922/30300 (epoch 32.875), train_loss = 1.05469259, grad/param norm = 1.4502e-01, time/batch = 0.6823s	
19923/30300 (epoch 32.876), train_loss = 0.95024042, grad/param norm = 1.5553e-01, time/batch = 0.6853s	
19924/30300 (epoch 32.878), train_loss = 0.92100033, grad/param norm = 1.5626e-01, time/batch = 0.6842s	
19925/30300 (epoch 32.880), train_loss = 0.99299862, grad/param norm = 1.5233e-01, time/batch = 0.6845s	
19926/30300 (epoch 32.881), train_loss = 1.21995728, grad/param norm = 1.9899e-01, time/batch = 0.6822s	
19927/30300 (epoch 32.883), train_loss = 1.15279227, grad/param norm = 1.8347e-01, time/batch = 0.6798s	
19928/30300 (epoch 32.884), train_loss = 1.04871227, grad/param norm = 1.4632e-01, time/batch = 0.6836s	
19929/30300 (epoch 32.886), train_loss = 1.11604667, grad/param norm = 1.5453e-01, time/batch = 0.6865s	
19930/30300 (epoch 32.888), train_loss = 1.06248656, grad/param norm = 1.7864e-01, time/batch = 0.6947s	
19931/30300 (epoch 32.889), train_loss = 1.09606623, grad/param norm = 1.5690e-01, time/batch = 0.7034s	
19932/30300 (epoch 32.891), train_loss = 1.05201517, grad/param norm = 1.6266e-01, time/batch = 0.7540s	
19933/30300 (epoch 32.893), train_loss = 1.27282082, grad/param norm = 1.7047e-01, time/batch = 0.7353s	
19934/30300 (epoch 32.894), train_loss = 1.11736005, grad/param norm = 1.6584e-01, time/batch = 0.6957s	
19935/30300 (epoch 32.896), train_loss = 0.92996339, grad/param norm = 1.7022e-01, time/batch = 0.6823s	
19936/30300 (epoch 32.898), train_loss = 0.94163375, grad/param norm = 1.6596e-01, time/batch = 0.6823s	
19937/30300 (epoch 32.899), train_loss = 0.97677490, grad/param norm = 1.6551e-01, time/batch = 0.6848s	
19938/30300 (epoch 32.901), train_loss = 1.08896795, grad/param norm = 1.7289e-01, time/batch = 0.6883s	
19939/30300 (epoch 32.903), train_loss = 1.08084284, grad/param norm = 1.8437e-01, time/batch = 0.6932s	
19940/30300 (epoch 32.904), train_loss = 1.09582949, grad/param norm = 1.6392e-01, time/batch = 0.6877s	
19941/30300 (epoch 32.906), train_loss = 1.10475098, grad/param norm = 1.7406e-01, time/batch = 0.6846s	
19942/30300 (epoch 32.908), train_loss = 1.00899404, grad/param norm = 1.5097e-01, time/batch = 0.6818s	
19943/30300 (epoch 32.909), train_loss = 0.99788643, grad/param norm = 1.7836e-01, time/batch = 0.6792s	
19944/30300 (epoch 32.911), train_loss = 1.08402646, grad/param norm = 1.6869e-01, time/batch = 0.6815s	
19945/30300 (epoch 32.913), train_loss = 1.07078840, grad/param norm = 1.4957e-01, time/batch = 0.6858s	
19946/30300 (epoch 32.914), train_loss = 1.04251526, grad/param norm = 1.6524e-01, time/batch = 0.6878s	
19947/30300 (epoch 32.916), train_loss = 1.11213826, grad/param norm = 1.5307e-01, time/batch = 0.7121s	
19948/30300 (epoch 32.917), train_loss = 1.04354726, grad/param norm = 1.6389e-01, time/batch = 0.7124s	
19949/30300 (epoch 32.919), train_loss = 0.98743879, grad/param norm = 1.6105e-01, time/batch = 0.6805s	
19950/30300 (epoch 32.921), train_loss = 1.04511875, grad/param norm = 1.4840e-01, time/batch = 0.6803s	
19951/30300 (epoch 32.922), train_loss = 1.14139116, grad/param norm = 1.7696e-01, time/batch = 0.6830s	
19952/30300 (epoch 32.924), train_loss = 1.07129272, grad/param norm = 1.6669e-01, time/batch = 0.6809s	
19953/30300 (epoch 32.926), train_loss = 1.11913184, grad/param norm = 1.7011e-01, time/batch = 0.6815s	
19954/30300 (epoch 32.927), train_loss = 1.10258766, grad/param norm = 1.6648e-01, time/batch = 0.6856s	
19955/30300 (epoch 32.929), train_loss = 0.99859458, grad/param norm = 1.7384e-01, time/batch = 0.6842s	
19956/30300 (epoch 32.931), train_loss = 1.15818955, grad/param norm = 1.9620e-01, time/batch = 0.6810s	
19957/30300 (epoch 32.932), train_loss = 0.99891890, grad/param norm = 1.5878e-01, time/batch = 0.6809s	
19958/30300 (epoch 32.934), train_loss = 1.11347502, grad/param norm = 1.6509e-01, time/batch = 0.6782s	
19959/30300 (epoch 32.936), train_loss = 0.99809321, grad/param norm = 1.5827e-01, time/batch = 0.6797s	
19960/30300 (epoch 32.937), train_loss = 1.01106390, grad/param norm = 1.7469e-01, time/batch = 0.6820s	
19961/30300 (epoch 32.939), train_loss = 1.19610387, grad/param norm = 1.6849e-01, time/batch = 0.6972s	
19962/30300 (epoch 32.941), train_loss = 1.04303374, grad/param norm = 1.6309e-01, time/batch = 0.7265s	
19963/30300 (epoch 32.942), train_loss = 1.06798642, grad/param norm = 1.6537e-01, time/batch = 0.6905s	
19964/30300 (epoch 32.944), train_loss = 0.96286498, grad/param norm = 1.6389e-01, time/batch = 0.6801s	
19965/30300 (epoch 32.946), train_loss = 1.14851700, grad/param norm = 1.9886e-01, time/batch = 0.6792s	
19966/30300 (epoch 32.947), train_loss = 1.13503673, grad/param norm = 2.0098e-01, time/batch = 0.6799s	
19967/30300 (epoch 32.949), train_loss = 1.14585452, grad/param norm = 1.9577e-01, time/batch = 0.6801s	
19968/30300 (epoch 32.950), train_loss = 1.16247868, grad/param norm = 1.6754e-01, time/batch = 0.6812s	
19969/30300 (epoch 32.952), train_loss = 1.11791208, grad/param norm = 1.8479e-01, time/batch = 0.6854s	
19970/30300 (epoch 32.954), train_loss = 1.34756012, grad/param norm = 1.8492e-01, time/batch = 0.6861s	
19971/30300 (epoch 32.955), train_loss = 1.06103011, grad/param norm = 1.7840e-01, time/batch = 0.6830s	
19972/30300 (epoch 32.957), train_loss = 1.13997324, grad/param norm = 1.6949e-01, time/batch = 0.6815s	
19973/30300 (epoch 32.959), train_loss = 0.98455056, grad/param norm = 1.7228e-01, time/batch = 0.6809s	
19974/30300 (epoch 32.960), train_loss = 1.03258779, grad/param norm = 1.6538e-01, time/batch = 0.6818s	
19975/30300 (epoch 32.962), train_loss = 1.04854054, grad/param norm = 2.2191e-01, time/batch = 0.7021s	
19976/30300 (epoch 32.964), train_loss = 0.97853617, grad/param norm = 1.8799e-01, time/batch = 0.7040s	
19977/30300 (epoch 32.965), train_loss = 1.01588535, grad/param norm = 2.1494e-01, time/batch = 0.7199s	
19978/30300 (epoch 32.967), train_loss = 1.07163072, grad/param norm = 2.0112e-01, time/batch = 0.7129s	
19979/30300 (epoch 32.969), train_loss = 0.98720508, grad/param norm = 1.9339e-01, time/batch = 0.7198s	
19980/30300 (epoch 32.970), train_loss = 1.05616695, grad/param norm = 1.6984e-01, time/batch = 0.7145s	
19981/30300 (epoch 32.972), train_loss = 0.96392357, grad/param norm = 1.7828e-01, time/batch = 0.7003s	
19982/30300 (epoch 32.974), train_loss = 1.21628628, grad/param norm = 1.9821e-01, time/batch = 0.6873s	
19983/30300 (epoch 32.975), train_loss = 1.22246876, grad/param norm = 1.9392e-01, time/batch = 0.6841s	
19984/30300 (epoch 32.977), train_loss = 1.25086131, grad/param norm = 1.8059e-01, time/batch = 0.6842s	
19985/30300 (epoch 32.979), train_loss = 1.14356224, grad/param norm = 1.7723e-01, time/batch = 0.6838s	
19986/30300 (epoch 32.980), train_loss = 1.16909745, grad/param norm = 1.9700e-01, time/batch = 0.6819s	
19987/30300 (epoch 32.982), train_loss = 1.17958356, grad/param norm = 1.6954e-01, time/batch = 0.6817s	
19988/30300 (epoch 32.983), train_loss = 1.20671709, grad/param norm = 1.6915e-01, time/batch = 0.6786s	
19989/30300 (epoch 32.985), train_loss = 1.12927116, grad/param norm = 1.7860e-01, time/batch = 0.6873s	
19990/30300 (epoch 32.987), train_loss = 1.07529518, grad/param norm = 1.5735e-01, time/batch = 0.6824s	
19991/30300 (epoch 32.988), train_loss = 1.19931422, grad/param norm = 1.7294e-01, time/batch = 0.6830s	
19992/30300 (epoch 32.990), train_loss = 0.98429894, grad/param norm = 1.5905e-01, time/batch = 0.6821s	
19993/30300 (epoch 32.992), train_loss = 1.14527435, grad/param norm = 1.4708e-01, time/batch = 0.7007s	
19994/30300 (epoch 32.993), train_loss = 1.20880300, grad/param norm = 2.0811e-01, time/batch = 0.6995s	
19995/30300 (epoch 32.995), train_loss = 1.07034525, grad/param norm = 1.7283e-01, time/batch = 0.7050s	
19996/30300 (epoch 32.997), train_loss = 1.10629849, grad/param norm = 1.9043e-01, time/batch = 0.6823s	
19997/30300 (epoch 32.998), train_loss = 1.13919747, grad/param norm = 1.8138e-01, time/batch = 0.6831s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
19998/30300 (epoch 33.000), train_loss = 1.03712559, grad/param norm = 1.7840e-01, time/batch = 0.6816s	
19999/30300 (epoch 33.002), train_loss = 1.16524285, grad/param norm = 1.7746e-01, time/batch = 0.6827s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch33.00_1.9440.t7	
20000/30300 (epoch 33.003), train_loss = 1.10046626, grad/param norm = 1.6560e-01, time/batch = 0.6807s	
20001/30300 (epoch 33.005), train_loss = 1.61938155, grad/param norm = 2.6047e-01, time/batch = 0.7339s	
20002/30300 (epoch 33.007), train_loss = 1.12198620, grad/param norm = 1.9932e-01, time/batch = 0.6859s	
20003/30300 (epoch 33.008), train_loss = 1.07341982, grad/param norm = 1.8971e-01, time/batch = 0.6838s	
20004/30300 (epoch 33.010), train_loss = 0.97149143, grad/param norm = 1.7849e-01, time/batch = 0.6820s	
20005/30300 (epoch 33.012), train_loss = 1.02280882, grad/param norm = 1.6725e-01, time/batch = 0.6896s	
20006/30300 (epoch 33.013), train_loss = 1.17408631, grad/param norm = 1.8087e-01, time/batch = 0.6970s	
20007/30300 (epoch 33.015), train_loss = 1.04320740, grad/param norm = 1.6028e-01, time/batch = 0.6867s	
20008/30300 (epoch 33.017), train_loss = 1.04417545, grad/param norm = 1.5290e-01, time/batch = 0.7034s	
20009/30300 (epoch 33.018), train_loss = 0.98655903, grad/param norm = 1.5818e-01, time/batch = 0.7090s	
20010/30300 (epoch 33.020), train_loss = 1.16360522, grad/param norm = 1.8562e-01, time/batch = 0.7040s	
20011/30300 (epoch 33.021), train_loss = 1.20265570, grad/param norm = 1.7604e-01, time/batch = 0.6850s	
20012/30300 (epoch 33.023), train_loss = 1.08835403, grad/param norm = 1.5803e-01, time/batch = 0.6927s	
20013/30300 (epoch 33.025), train_loss = 1.01896414, grad/param norm = 1.8069e-01, time/batch = 0.7030s	
20014/30300 (epoch 33.026), train_loss = 1.12849316, grad/param norm = 1.7240e-01, time/batch = 0.6907s	
20015/30300 (epoch 33.028), train_loss = 1.16299236, grad/param norm = 1.7643e-01, time/batch = 0.7282s	
20016/30300 (epoch 33.030), train_loss = 1.04732548, grad/param norm = 1.7537e-01, time/batch = 0.6966s	
20017/30300 (epoch 33.031), train_loss = 1.13176504, grad/param norm = 1.6680e-01, time/batch = 0.6817s	
20018/30300 (epoch 33.033), train_loss = 1.10160519, grad/param norm = 1.5752e-01, time/batch = 0.6800s	
20019/30300 (epoch 33.035), train_loss = 1.15308964, grad/param norm = 1.8273e-01, time/batch = 0.6806s	
20020/30300 (epoch 33.036), train_loss = 1.10612838, grad/param norm = 1.5233e-01, time/batch = 0.6843s	
20021/30300 (epoch 33.038), train_loss = 1.12418255, grad/param norm = 1.4871e-01, time/batch = 0.6880s	
20022/30300 (epoch 33.040), train_loss = 0.89471054, grad/param norm = 1.4857e-01, time/batch = 0.6824s	
20023/30300 (epoch 33.041), train_loss = 0.91544374, grad/param norm = 1.7656e-01, time/batch = 0.6798s	
20024/30300 (epoch 33.043), train_loss = 1.08828294, grad/param norm = 1.6647e-01, time/batch = 0.6805s	
20025/30300 (epoch 33.045), train_loss = 1.04903169, grad/param norm = 1.5341e-01, time/batch = 0.6830s	
20026/30300 (epoch 33.046), train_loss = 1.23610618, grad/param norm = 1.9017e-01, time/batch = 0.6906s	
20027/30300 (epoch 33.048), train_loss = 1.07583924, grad/param norm = 1.7480e-01, time/batch = 0.6898s	
20028/30300 (epoch 33.050), train_loss = 1.01164569, grad/param norm = 1.7559e-01, time/batch = 0.6902s	
20029/30300 (epoch 33.051), train_loss = 1.13418440, grad/param norm = 1.9456e-01, time/batch = 0.6928s	
20030/30300 (epoch 33.053), train_loss = 0.93904430, grad/param norm = 1.8934e-01, time/batch = 0.6961s	
20031/30300 (epoch 33.054), train_loss = 1.11633022, grad/param norm = 1.6818e-01, time/batch = 0.7022s	
20032/30300 (epoch 33.056), train_loss = 0.98613749, grad/param norm = 1.6050e-01, time/batch = 0.6914s	
20033/30300 (epoch 33.058), train_loss = 1.05789978, grad/param norm = 1.6434e-01, time/batch = 0.7084s	
20034/30300 (epoch 33.059), train_loss = 1.03541243, grad/param norm = 1.9667e-01, time/batch = 0.7264s	
20035/30300 (epoch 33.061), train_loss = 1.13700656, grad/param norm = 1.8980e-01, time/batch = 0.6918s	
20036/30300 (epoch 33.063), train_loss = 0.96479785, grad/param norm = 1.6435e-01, time/batch = 0.6980s	
20037/30300 (epoch 33.064), train_loss = 1.09401274, grad/param norm = 1.8353e-01, time/batch = 0.6966s	
20038/30300 (epoch 33.066), train_loss = 1.08108401, grad/param norm = 1.5191e-01, time/batch = 0.7021s	
20039/30300 (epoch 33.068), train_loss = 0.97978706, grad/param norm = 1.6425e-01, time/batch = 0.6871s	
20040/30300 (epoch 33.069), train_loss = 1.14453992, grad/param norm = 1.7058e-01, time/batch = 0.6946s	
20041/30300 (epoch 33.071), train_loss = 1.12825637, grad/param norm = 1.7387e-01, time/batch = 0.6874s	
20042/30300 (epoch 33.073), train_loss = 0.99325644, grad/param norm = 1.5773e-01, time/batch = 0.6932s	
20043/30300 (epoch 33.074), train_loss = 1.07202691, grad/param norm = 1.6162e-01, time/batch = 0.6953s	
20044/30300 (epoch 33.076), train_loss = 1.06340408, grad/param norm = 1.5877e-01, time/batch = 0.6894s	
20045/30300 (epoch 33.078), train_loss = 1.01002178, grad/param norm = 1.5327e-01, time/batch = 0.6876s	
20046/30300 (epoch 33.079), train_loss = 1.02377452, grad/param norm = 1.6373e-01, time/batch = 0.6875s	
20047/30300 (epoch 33.081), train_loss = 1.08918270, grad/param norm = 1.6996e-01, time/batch = 0.6871s	
20048/30300 (epoch 33.083), train_loss = 1.14511525, grad/param norm = 1.9348e-01, time/batch = 0.6853s	
20049/30300 (epoch 33.084), train_loss = 1.01191375, grad/param norm = 1.6665e-01, time/batch = 0.6853s	
20050/30300 (epoch 33.086), train_loss = 1.01620068, grad/param norm = 1.6453e-01, time/batch = 0.6869s	
20051/30300 (epoch 33.087), train_loss = 1.00771368, grad/param norm = 1.5930e-01, time/batch = 0.6892s	
20052/30300 (epoch 33.089), train_loss = 1.01826649, grad/param norm = 1.5756e-01, time/batch = 0.6834s	
20053/30300 (epoch 33.091), train_loss = 1.12129356, grad/param norm = 1.6033e-01, time/batch = 0.6851s	
20054/30300 (epoch 33.092), train_loss = 1.12722515, grad/param norm = 1.5792e-01, time/batch = 0.6870s	
20055/30300 (epoch 33.094), train_loss = 1.19860444, grad/param norm = 1.8340e-01, time/batch = 0.6824s	
20056/30300 (epoch 33.096), train_loss = 1.18765228, grad/param norm = 1.7753e-01, time/batch = 0.6961s	
20057/30300 (epoch 33.097), train_loss = 1.01276450, grad/param norm = 1.9016e-01, time/batch = 0.7257s	
20058/30300 (epoch 33.099), train_loss = 1.16915361, grad/param norm = 1.7309e-01, time/batch = 0.6875s	
20059/30300 (epoch 33.101), train_loss = 1.20984368, grad/param norm = 1.9566e-01, time/batch = 0.6875s	
20060/30300 (epoch 33.102), train_loss = 1.01993384, grad/param norm = 1.9127e-01, time/batch = 0.7011s	
20061/30300 (epoch 33.104), train_loss = 1.03785214, grad/param norm = 1.8731e-01, time/batch = 0.6915s	
20062/30300 (epoch 33.106), train_loss = 1.04315126, grad/param norm = 1.6873e-01, time/batch = 0.6875s	
20063/30300 (epoch 33.107), train_loss = 1.12582350, grad/param norm = 1.6085e-01, time/batch = 0.6939s	
20064/30300 (epoch 33.109), train_loss = 1.16422938, grad/param norm = 2.1558e-01, time/batch = 0.6977s	
20065/30300 (epoch 33.111), train_loss = 1.16235669, grad/param norm = 1.7741e-01, time/batch = 0.6887s	
20066/30300 (epoch 33.112), train_loss = 1.21313264, grad/param norm = 1.6863e-01, time/batch = 0.6879s	
20067/30300 (epoch 33.114), train_loss = 1.03133487, grad/param norm = 1.6030e-01, time/batch = 0.6828s	
20068/30300 (epoch 33.116), train_loss = 1.11284997, grad/param norm = 1.8690e-01, time/batch = 0.6890s	
20069/30300 (epoch 33.117), train_loss = 1.17546260, grad/param norm = 1.6376e-01, time/batch = 0.6918s	
20070/30300 (epoch 33.119), train_loss = 1.00114824, grad/param norm = 1.7499e-01, time/batch = 0.6823s	
20071/30300 (epoch 33.120), train_loss = 1.06269261, grad/param norm = 1.7500e-01, time/batch = 0.7282s	
20072/30300 (epoch 33.122), train_loss = 1.17574087, grad/param norm = 2.1054e-01, time/batch = 0.7064s	
20073/30300 (epoch 33.124), train_loss = 1.24302547, grad/param norm = 1.9466e-01, time/batch = 0.7100s	
20074/30300 (epoch 33.125), train_loss = 0.98838052, grad/param norm = 1.8538e-01, time/batch = 0.6872s	
20075/30300 (epoch 33.127), train_loss = 1.13863177, grad/param norm = 2.5271e-01, time/batch = 0.6848s	
20076/30300 (epoch 33.129), train_loss = 1.18876309, grad/param norm = 1.7937e-01, time/batch = 0.6852s	
20077/30300 (epoch 33.130), train_loss = 1.21344131, grad/param norm = 1.6952e-01, time/batch = 0.6818s	
20078/30300 (epoch 33.132), train_loss = 1.21758171, grad/param norm = 1.7953e-01, time/batch = 0.6830s	
20079/30300 (epoch 33.134), train_loss = 1.02283159, grad/param norm = 1.8050e-01, time/batch = 0.6833s	
20080/30300 (epoch 33.135), train_loss = 1.04414925, grad/param norm = 1.7703e-01, time/batch = 0.6909s	
20081/30300 (epoch 33.137), train_loss = 1.10189527, grad/param norm = 2.0794e-01, time/batch = 0.6855s	
20082/30300 (epoch 33.139), train_loss = 1.02902526, grad/param norm = 2.0613e-01, time/batch = 0.6848s	
20083/30300 (epoch 33.140), train_loss = 1.10339214, grad/param norm = 2.2285e-01, time/batch = 0.6816s	
20084/30300 (epoch 33.142), train_loss = 1.18567932, grad/param norm = 2.2171e-01, time/batch = 0.6959s	
20085/30300 (epoch 33.144), train_loss = 1.02211247, grad/param norm = 2.3849e-01, time/batch = 0.6970s	
20086/30300 (epoch 33.145), train_loss = 1.19042683, grad/param norm = 2.1619e-01, time/batch = 0.6964s	
20087/30300 (epoch 33.147), train_loss = 1.06267993, grad/param norm = 2.1136e-01, time/batch = 0.7056s	
20088/30300 (epoch 33.149), train_loss = 1.20708396, grad/param norm = 2.0654e-01, time/batch = 0.7041s	
20089/30300 (epoch 33.150), train_loss = 1.05047037, grad/param norm = 1.6334e-01, time/batch = 0.7077s	
20090/30300 (epoch 33.152), train_loss = 0.98544824, grad/param norm = 2.0563e-01, time/batch = 0.7276s	
20091/30300 (epoch 33.153), train_loss = 1.09462062, grad/param norm = 2.0964e-01, time/batch = 0.6976s	
20092/30300 (epoch 33.155), train_loss = 0.95930811, grad/param norm = 1.5085e-01, time/batch = 0.7020s	
20093/30300 (epoch 33.157), train_loss = 1.04648227, grad/param norm = 1.9135e-01, time/batch = 0.6991s	
20094/30300 (epoch 33.158), train_loss = 1.11820489, grad/param norm = 2.0447e-01, time/batch = 0.7058s	
20095/30300 (epoch 33.160), train_loss = 0.99030860, grad/param norm = 1.7861e-01, time/batch = 0.6949s	
20096/30300 (epoch 33.162), train_loss = 1.09127202, grad/param norm = 1.6534e-01, time/batch = 0.7032s	
20097/30300 (epoch 33.163), train_loss = 1.07771514, grad/param norm = 1.9459e-01, time/batch = 0.6905s	
20098/30300 (epoch 33.165), train_loss = 1.19456975, grad/param norm = 1.8208e-01, time/batch = 0.7018s	
20099/30300 (epoch 33.167), train_loss = 1.09586569, grad/param norm = 1.8220e-01, time/batch = 0.6948s	
20100/30300 (epoch 33.168), train_loss = 1.15041116, grad/param norm = 1.7369e-01, time/batch = 0.6832s	
20101/30300 (epoch 33.170), train_loss = 1.07855427, grad/param norm = 1.7297e-01, time/batch = 0.6855s	
20102/30300 (epoch 33.172), train_loss = 1.10091917, grad/param norm = 2.1037e-01, time/batch = 0.6893s	
20103/30300 (epoch 33.173), train_loss = 1.07979161, grad/param norm = 1.9116e-01, time/batch = 0.6863s	
20104/30300 (epoch 33.175), train_loss = 1.09549948, grad/param norm = 1.7389e-01, time/batch = 0.6864s	
20105/30300 (epoch 33.177), train_loss = 1.14968874, grad/param norm = 1.8211e-01, time/batch = 0.6822s	
20106/30300 (epoch 33.178), train_loss = 0.88005709, grad/param norm = 1.4133e-01, time/batch = 0.6827s	
20107/30300 (epoch 33.180), train_loss = 1.05545373, grad/param norm = 1.5314e-01, time/batch = 0.6827s	
20108/30300 (epoch 33.182), train_loss = 1.09053874, grad/param norm = 1.7886e-01, time/batch = 0.7132s	
20109/30300 (epoch 33.183), train_loss = 1.03171185, grad/param norm = 1.7733e-01, time/batch = 0.7132s	
20110/30300 (epoch 33.185), train_loss = 1.22975480, grad/param norm = 1.8717e-01, time/batch = 0.6826s	
20111/30300 (epoch 33.186), train_loss = 1.28976668, grad/param norm = 2.0888e-01, time/batch = 0.6856s	
20112/30300 (epoch 33.188), train_loss = 1.11915259, grad/param norm = 1.6966e-01, time/batch = 0.6836s	
20113/30300 (epoch 33.190), train_loss = 1.10027843, grad/param norm = 1.6081e-01, time/batch = 0.6842s	
20114/30300 (epoch 33.191), train_loss = 1.15276118, grad/param norm = 1.8030e-01, time/batch = 0.6883s	
20115/30300 (epoch 33.193), train_loss = 0.98530284, grad/param norm = 1.4766e-01, time/batch = 0.6824s	
20116/30300 (epoch 33.195), train_loss = 1.04696418, grad/param norm = 1.7104e-01, time/batch = 0.6870s	
20117/30300 (epoch 33.196), train_loss = 1.11642941, grad/param norm = 1.5309e-01, time/batch = 0.6836s	
20118/30300 (epoch 33.198), train_loss = 0.93319173, grad/param norm = 1.5465e-01, time/batch = 0.6859s	
20119/30300 (epoch 33.200), train_loss = 1.07181507, grad/param norm = 1.6191e-01, time/batch = 0.6923s	
20120/30300 (epoch 33.201), train_loss = 1.16122934, grad/param norm = 2.1139e-01, time/batch = 0.6844s	
20121/30300 (epoch 33.203), train_loss = 1.07290781, grad/param norm = 1.7355e-01, time/batch = 0.6920s	
20122/30300 (epoch 33.205), train_loss = 1.28969979, grad/param norm = 1.8616e-01, time/batch = 0.6864s	
20123/30300 (epoch 33.206), train_loss = 1.16446929, grad/param norm = 2.2276e-01, time/batch = 0.6847s	
20124/30300 (epoch 33.208), train_loss = 1.14368217, grad/param norm = 2.0667e-01, time/batch = 0.6868s	
20125/30300 (epoch 33.210), train_loss = 1.14503044, grad/param norm = 1.6511e-01, time/batch = 0.6909s	
20126/30300 (epoch 33.211), train_loss = 1.19890466, grad/param norm = 1.7472e-01, time/batch = 0.6881s	
20127/30300 (epoch 33.213), train_loss = 1.06607357, grad/param norm = 1.5452e-01, time/batch = 0.7232s	
20128/30300 (epoch 33.215), train_loss = 1.02569408, grad/param norm = 2.3249e-01, time/batch = 0.7069s	
20129/30300 (epoch 33.216), train_loss = 1.04902771, grad/param norm = 1.9882e-01, time/batch = 0.6856s	
20130/30300 (epoch 33.218), train_loss = 1.00474797, grad/param norm = 1.6175e-01, time/batch = 0.6839s	
20131/30300 (epoch 33.219), train_loss = 0.96418526, grad/param norm = 1.5441e-01, time/batch = 0.6909s	
20132/30300 (epoch 33.221), train_loss = 0.93203496, grad/param norm = 1.7249e-01, time/batch = 0.6856s	
20133/30300 (epoch 33.223), train_loss = 1.09527712, grad/param norm = 1.7532e-01, time/batch = 0.6885s	
20134/30300 (epoch 33.224), train_loss = 0.94183247, grad/param norm = 1.6475e-01, time/batch = 0.6872s	
20135/30300 (epoch 33.226), train_loss = 1.15015689, grad/param norm = 2.2057e-01, time/batch = 0.6910s	
20136/30300 (epoch 33.228), train_loss = 1.19776228, grad/param norm = 1.8823e-01, time/batch = 0.6934s	
20137/30300 (epoch 33.229), train_loss = 1.06605420, grad/param norm = 1.6957e-01, time/batch = 0.6883s	
20138/30300 (epoch 33.231), train_loss = 1.12069730, grad/param norm = 1.7790e-01, time/batch = 0.6913s	
20139/30300 (epoch 33.233), train_loss = 1.13158365, grad/param norm = 1.4960e-01, time/batch = 0.6845s	
20140/30300 (epoch 33.234), train_loss = 1.14873872, grad/param norm = 1.9910e-01, time/batch = 0.6974s	
20141/30300 (epoch 33.236), train_loss = 1.12112073, grad/param norm = 1.5251e-01, time/batch = 0.6921s	
20142/30300 (epoch 33.238), train_loss = 1.08980206, grad/param norm = 1.9212e-01, time/batch = 0.6861s	
20143/30300 (epoch 33.239), train_loss = 1.06558301, grad/param norm = 1.8242e-01, time/batch = 0.6848s	
20144/30300 (epoch 33.241), train_loss = 1.13602156, grad/param norm = 1.8675e-01, time/batch = 0.6874s	
20145/30300 (epoch 33.243), train_loss = 1.13577903, grad/param norm = 1.6982e-01, time/batch = 0.6949s	
20146/30300 (epoch 33.244), train_loss = 1.29133372, grad/param norm = 1.7755e-01, time/batch = 0.7259s	
20147/30300 (epoch 33.246), train_loss = 1.11470431, grad/param norm = 1.7129e-01, time/batch = 0.6947s	
20148/30300 (epoch 33.248), train_loss = 1.05820473, grad/param norm = 1.6120e-01, time/batch = 0.6877s	
20149/30300 (epoch 33.249), train_loss = 1.00432784, grad/param norm = 1.6982e-01, time/batch = 0.6849s	
20150/30300 (epoch 33.251), train_loss = 1.03502286, grad/param norm = 1.7295e-01, time/batch = 0.6843s	
20151/30300 (epoch 33.252), train_loss = 1.19239885, grad/param norm = 1.7805e-01, time/batch = 0.6870s	
20152/30300 (epoch 33.254), train_loss = 1.18602094, grad/param norm = 1.7888e-01, time/batch = 0.6841s	
20153/30300 (epoch 33.256), train_loss = 1.11362449, grad/param norm = 1.6551e-01, time/batch = 0.6860s	
20154/30300 (epoch 33.257), train_loss = 1.16537127, grad/param norm = 1.7373e-01, time/batch = 0.6862s	
20155/30300 (epoch 33.259), train_loss = 1.07233425, grad/param norm = 1.7360e-01, time/batch = 0.6842s	
20156/30300 (epoch 33.261), train_loss = 1.20704700, grad/param norm = 1.6557e-01, time/batch = 0.6864s	
20157/30300 (epoch 33.262), train_loss = 1.01763238, grad/param norm = 1.5865e-01, time/batch = 0.6850s	
20158/30300 (epoch 33.264), train_loss = 1.07865553, grad/param norm = 1.5534e-01, time/batch = 0.6845s	
20159/30300 (epoch 33.266), train_loss = 1.05261595, grad/param norm = 1.6260e-01, time/batch = 0.6836s	
20160/30300 (epoch 33.267), train_loss = 1.25276050, grad/param norm = 1.8960e-01, time/batch = 0.6863s	
20161/30300 (epoch 33.269), train_loss = 1.09499831, grad/param norm = 1.5533e-01, time/batch = 0.6865s	
20162/30300 (epoch 33.271), train_loss = 1.12368547, grad/param norm = 1.6931e-01, time/batch = 0.6844s	
20163/30300 (epoch 33.272), train_loss = 1.09568924, grad/param norm = 1.9135e-01, time/batch = 0.6854s	
20164/30300 (epoch 33.274), train_loss = 1.16298337, grad/param norm = 1.9366e-01, time/batch = 0.6850s	
20165/30300 (epoch 33.276), train_loss = 1.13083140, grad/param norm = 1.9537e-01, time/batch = 0.6879s	
20166/30300 (epoch 33.277), train_loss = 0.97673587, grad/param norm = 1.7498e-01, time/batch = 0.6949s	
20167/30300 (epoch 33.279), train_loss = 1.10180035, grad/param norm = 1.8079e-01, time/batch = 0.7090s	
20168/30300 (epoch 33.281), train_loss = 1.18453757, grad/param norm = 1.8806e-01, time/batch = 0.6886s	
20169/30300 (epoch 33.282), train_loss = 1.12806479, grad/param norm = 1.6136e-01, time/batch = 0.6884s	
20170/30300 (epoch 33.284), train_loss = 1.19148977, grad/param norm = 2.1801e-01, time/batch = 0.6842s	
20171/30300 (epoch 33.285), train_loss = 1.13786706, grad/param norm = 1.5994e-01, time/batch = 0.6880s	
20172/30300 (epoch 33.287), train_loss = 1.08332731, grad/param norm = 1.6598e-01, time/batch = 0.6878s	
20173/30300 (epoch 33.289), train_loss = 1.17992691, grad/param norm = 1.6582e-01, time/batch = 0.6860s	
20174/30300 (epoch 33.290), train_loss = 0.86922618, grad/param norm = 1.7295e-01, time/batch = 0.6873s	
20175/30300 (epoch 33.292), train_loss = 0.99743007, grad/param norm = 1.6723e-01, time/batch = 0.6864s	
20176/30300 (epoch 33.294), train_loss = 1.16153967, grad/param norm = 1.9141e-01, time/batch = 0.6835s	
20177/30300 (epoch 33.295), train_loss = 1.06621044, grad/param norm = 2.1211e-01, time/batch = 0.6820s	
20178/30300 (epoch 33.297), train_loss = 1.04575924, grad/param norm = 1.5484e-01, time/batch = 0.6869s	
20179/30300 (epoch 33.299), train_loss = 1.07098944, grad/param norm = 1.6543e-01, time/batch = 0.6876s	
20180/30300 (epoch 33.300), train_loss = 1.00794826, grad/param norm = 1.6939e-01, time/batch = 0.6844s	
20181/30300 (epoch 33.302), train_loss = 1.16195893, grad/param norm = 1.7638e-01, time/batch = 0.7000s	
20182/30300 (epoch 33.304), train_loss = 1.01192839, grad/param norm = 1.5373e-01, time/batch = 0.7232s	
20183/30300 (epoch 33.305), train_loss = 1.07653561, grad/param norm = 1.6796e-01, time/batch = 0.7158s	
20184/30300 (epoch 33.307), train_loss = 1.16745506, grad/param norm = 1.5071e-01, time/batch = 0.7123s	
20185/30300 (epoch 33.309), train_loss = 1.12307744, grad/param norm = 1.7380e-01, time/batch = 0.6866s	
20186/30300 (epoch 33.310), train_loss = 1.08047827, grad/param norm = 1.7594e-01, time/batch = 0.6903s	
20187/30300 (epoch 33.312), train_loss = 1.21799000, grad/param norm = 1.6617e-01, time/batch = 0.6895s	
20188/30300 (epoch 33.314), train_loss = 1.10146272, grad/param norm = 1.7962e-01, time/batch = 0.6955s	
20189/30300 (epoch 33.315), train_loss = 1.04610636, grad/param norm = 1.6453e-01, time/batch = 0.6974s	
20190/30300 (epoch 33.317), train_loss = 1.10007244, grad/param norm = 1.5011e-01, time/batch = 0.7007s	
20191/30300 (epoch 33.318), train_loss = 1.14534012, grad/param norm = 1.6726e-01, time/batch = 0.7087s	
20192/30300 (epoch 33.320), train_loss = 1.12657550, grad/param norm = 1.5743e-01, time/batch = 0.7121s	
20193/30300 (epoch 33.322), train_loss = 1.03186855, grad/param norm = 1.6601e-01, time/batch = 0.7033s	
20194/30300 (epoch 33.323), train_loss = 1.21111385, grad/param norm = 1.8954e-01, time/batch = 0.6834s	
20195/30300 (epoch 33.325), train_loss = 1.08332230, grad/param norm = 1.6424e-01, time/batch = 0.6824s	
20196/30300 (epoch 33.327), train_loss = 1.06863667, grad/param norm = 1.4666e-01, time/batch = 0.6988s	
20197/30300 (epoch 33.328), train_loss = 1.10392845, grad/param norm = 1.6174e-01, time/batch = 0.7049s	
20198/30300 (epoch 33.330), train_loss = 1.12923100, grad/param norm = 1.6686e-01, time/batch = 0.7264s	
20199/30300 (epoch 33.332), train_loss = 1.19280332, grad/param norm = 2.4414e-01, time/batch = 0.6831s	
20200/30300 (epoch 33.333), train_loss = 1.04213393, grad/param norm = 1.7888e-01, time/batch = 0.6834s	
20201/30300 (epoch 33.335), train_loss = 0.98129305, grad/param norm = 1.5646e-01, time/batch = 0.6870s	
20202/30300 (epoch 33.337), train_loss = 1.21308729, grad/param norm = 1.6522e-01, time/batch = 0.6818s	
20203/30300 (epoch 33.338), train_loss = 1.03873608, grad/param norm = 1.5662e-01, time/batch = 0.6904s	
20204/30300 (epoch 33.340), train_loss = 1.03752436, grad/param norm = 1.5570e-01, time/batch = 0.6943s	
20205/30300 (epoch 33.342), train_loss = 1.17411149, grad/param norm = 1.7772e-01, time/batch = 0.6857s	
20206/30300 (epoch 33.343), train_loss = 1.10762596, grad/param norm = 1.5565e-01, time/batch = 0.6836s	
20207/30300 (epoch 33.345), train_loss = 1.14617840, grad/param norm = 1.7083e-01, time/batch = 0.6850s	
20208/30300 (epoch 33.347), train_loss = 0.97037497, grad/param norm = 1.5804e-01, time/batch = 0.6852s	
20209/30300 (epoch 33.348), train_loss = 1.03876286, grad/param norm = 1.6132e-01, time/batch = 0.6850s	
20210/30300 (epoch 33.350), train_loss = 1.05062540, grad/param norm = 1.8884e-01, time/batch = 0.6818s	
20211/30300 (epoch 33.351), train_loss = 1.06714477, grad/param norm = 1.6680e-01, time/batch = 0.6838s	
20212/30300 (epoch 33.353), train_loss = 0.96661852, grad/param norm = 1.5626e-01, time/batch = 0.6886s	
20213/30300 (epoch 33.355), train_loss = 1.04352387, grad/param norm = 1.5587e-01, time/batch = 0.6821s	
20214/30300 (epoch 33.356), train_loss = 1.16391128, grad/param norm = 1.8236e-01, time/batch = 0.6828s	
20215/30300 (epoch 33.358), train_loss = 1.32319329, grad/param norm = 1.5681e-01, time/batch = 0.6818s	
20216/30300 (epoch 33.360), train_loss = 1.04301830, grad/param norm = 1.6080e-01, time/batch = 0.7067s	
20217/30300 (epoch 33.361), train_loss = 1.07339542, grad/param norm = 1.6056e-01, time/batch = 0.6811s	
20218/30300 (epoch 33.363), train_loss = 1.13269198, grad/param norm = 1.7238e-01, time/batch = 0.6870s	
20219/30300 (epoch 33.365), train_loss = 0.96074430, grad/param norm = 1.8583e-01, time/batch = 0.6843s	
20220/30300 (epoch 33.366), train_loss = 1.05002077, grad/param norm = 1.6447e-01, time/batch = 0.6949s	
20221/30300 (epoch 33.368), train_loss = 0.95025488, grad/param norm = 1.5148e-01, time/batch = 0.7282s	
20222/30300 (epoch 33.370), train_loss = 1.02620414, grad/param norm = 1.5739e-01, time/batch = 0.6956s	
20223/30300 (epoch 33.371), train_loss = 1.15758990, grad/param norm = 1.5325e-01, time/batch = 0.7049s	
20224/30300 (epoch 33.373), train_loss = 1.01776447, grad/param norm = 1.4774e-01, time/batch = 0.7238s	
20225/30300 (epoch 33.375), train_loss = 1.01319864, grad/param norm = 1.3741e-01, time/batch = 0.7205s	
20226/30300 (epoch 33.376), train_loss = 1.01752137, grad/param norm = 1.5026e-01, time/batch = 0.7149s	
20227/30300 (epoch 33.378), train_loss = 1.00019573, grad/param norm = 1.6659e-01, time/batch = 0.7055s	
20228/30300 (epoch 33.380), train_loss = 1.20452699, grad/param norm = 1.6757e-01, time/batch = 0.7023s	
20229/30300 (epoch 33.381), train_loss = 0.93099851, grad/param norm = 1.5847e-01, time/batch = 0.6801s	
20230/30300 (epoch 33.383), train_loss = 0.99441108, grad/param norm = 2.0827e-01, time/batch = 0.6805s	
20231/30300 (epoch 33.384), train_loss = 1.14302670, grad/param norm = 1.9544e-01, time/batch = 0.6821s	
20232/30300 (epoch 33.386), train_loss = 0.96557349, grad/param norm = 1.6463e-01, time/batch = 0.6849s	
20233/30300 (epoch 33.388), train_loss = 0.95424151, grad/param norm = 1.5790e-01, time/batch = 0.6828s	
20234/30300 (epoch 33.389), train_loss = 1.06779425, grad/param norm = 1.9061e-01, time/batch = 0.6822s	
20235/30300 (epoch 33.391), train_loss = 1.11804181, grad/param norm = 1.6174e-01, time/batch = 0.6798s	
20236/30300 (epoch 33.393), train_loss = 0.94888011, grad/param norm = 1.5906e-01, time/batch = 0.6825s	
20237/30300 (epoch 33.394), train_loss = 1.12491457, grad/param norm = 1.5898e-01, time/batch = 0.6799s	
20238/30300 (epoch 33.396), train_loss = 1.19470739, grad/param norm = 1.5896e-01, time/batch = 0.6833s	
20239/30300 (epoch 33.398), train_loss = 1.04911776, grad/param norm = 1.7394e-01, time/batch = 0.7058s	
20240/30300 (epoch 33.399), train_loss = 1.02366218, grad/param norm = 1.6095e-01, time/batch = 0.6843s	
20241/30300 (epoch 33.401), train_loss = 1.09013292, grad/param norm = 1.6878e-01, time/batch = 0.6875s	
20242/30300 (epoch 33.403), train_loss = 1.06358468, grad/param norm = 1.5656e-01, time/batch = 0.6971s	
20243/30300 (epoch 33.404), train_loss = 1.02092664, grad/param norm = 1.8324e-01, time/batch = 0.6920s	
20244/30300 (epoch 33.406), train_loss = 1.09213639, grad/param norm = 1.5668e-01, time/batch = 0.6852s	
20245/30300 (epoch 33.408), train_loss = 0.95531350, grad/param norm = 1.5019e-01, time/batch = 0.6870s	
20246/30300 (epoch 33.409), train_loss = 0.96482973, grad/param norm = 1.7255e-01, time/batch = 0.6846s	
20247/30300 (epoch 33.411), train_loss = 0.99906811, grad/param norm = 1.4372e-01, time/batch = 0.6888s	
20248/30300 (epoch 33.413), train_loss = 0.90085968, grad/param norm = 1.6344e-01, time/batch = 0.6933s	
20249/30300 (epoch 33.414), train_loss = 1.13266316, grad/param norm = 1.7632e-01, time/batch = 0.6860s	
20250/30300 (epoch 33.416), train_loss = 1.01959531, grad/param norm = 1.5567e-01, time/batch = 0.6828s	
20251/30300 (epoch 33.417), train_loss = 0.98207128, grad/param norm = 1.6203e-01, time/batch = 0.6831s	
20252/30300 (epoch 33.419), train_loss = 0.98629965, grad/param norm = 1.5477e-01, time/batch = 0.6837s	
20253/30300 (epoch 33.421), train_loss = 1.02092722, grad/param norm = 1.8904e-01, time/batch = 0.6836s	
20254/30300 (epoch 33.422), train_loss = 1.09737855, grad/param norm = 2.0388e-01, time/batch = 0.6836s	
20255/30300 (epoch 33.424), train_loss = 1.09222274, grad/param norm = 1.6149e-01, time/batch = 0.6802s	
20256/30300 (epoch 33.426), train_loss = 1.02363292, grad/param norm = 1.5354e-01, time/batch = 0.6808s	
20257/30300 (epoch 33.427), train_loss = 1.00740534, grad/param norm = 1.9752e-01, time/batch = 0.6801s	
20258/30300 (epoch 33.429), train_loss = 1.05529654, grad/param norm = 1.5862e-01, time/batch = 0.7034s	
20259/30300 (epoch 33.431), train_loss = 1.11369027, grad/param norm = 1.6995e-01, time/batch = 0.6922s	
20260/30300 (epoch 33.432), train_loss = 1.06054820, grad/param norm = 1.6261e-01, time/batch = 0.6827s	
20261/30300 (epoch 33.434), train_loss = 0.95821225, grad/param norm = 1.7508e-01, time/batch = 0.7016s	
20262/30300 (epoch 33.436), train_loss = 1.17998277, grad/param norm = 1.5890e-01, time/batch = 0.6887s	
20263/30300 (epoch 33.437), train_loss = 0.96939437, grad/param norm = 1.6412e-01, time/batch = 0.6822s	
20264/30300 (epoch 33.439), train_loss = 1.01563964, grad/param norm = 1.4721e-01, time/batch = 0.6812s	
20265/30300 (epoch 33.441), train_loss = 1.04446215, grad/param norm = 1.5720e-01, time/batch = 0.6908s	
20266/30300 (epoch 33.442), train_loss = 1.00839561, grad/param norm = 1.5909e-01, time/batch = 0.6873s	
20267/30300 (epoch 33.444), train_loss = 0.88822626, grad/param norm = 1.5081e-01, time/batch = 0.7034s	
20268/30300 (epoch 33.446), train_loss = 1.03478541, grad/param norm = 1.4112e-01, time/batch = 0.7047s	
20269/30300 (epoch 33.447), train_loss = 1.05898457, grad/param norm = 1.5793e-01, time/batch = 0.7179s	
20270/30300 (epoch 33.449), train_loss = 0.99545622, grad/param norm = 1.5968e-01, time/batch = 0.6861s	
20271/30300 (epoch 33.450), train_loss = 1.09283224, grad/param norm = 1.5208e-01, time/batch = 0.6873s	
20272/30300 (epoch 33.452), train_loss = 1.19207106, grad/param norm = 1.7871e-01, time/batch = 0.7060s	
20273/30300 (epoch 33.454), train_loss = 1.12817385, grad/param norm = 1.5800e-01, time/batch = 0.7203s	
20274/30300 (epoch 33.455), train_loss = 1.05846671, grad/param norm = 1.8994e-01, time/batch = 0.6923s	
20275/30300 (epoch 33.457), train_loss = 1.03477801, grad/param norm = 1.6724e-01, time/batch = 0.6945s	
20276/30300 (epoch 33.459), train_loss = 1.12055776, grad/param norm = 1.7992e-01, time/batch = 0.6855s	
20277/30300 (epoch 33.460), train_loss = 1.12839773, grad/param norm = 1.5812e-01, time/batch = 0.6849s	
20278/30300 (epoch 33.462), train_loss = 1.14500751, grad/param norm = 1.8204e-01, time/batch = 0.6824s	
20279/30300 (epoch 33.464), train_loss = 0.88742746, grad/param norm = 1.7375e-01, time/batch = 0.6819s	
20280/30300 (epoch 33.465), train_loss = 0.90825366, grad/param norm = 1.4542e-01, time/batch = 0.6811s	
20281/30300 (epoch 33.467), train_loss = 0.88904396, grad/param norm = 1.3882e-01, time/batch = 0.6852s	
20282/30300 (epoch 33.469), train_loss = 0.98733059, grad/param norm = 1.4584e-01, time/batch = 0.6870s	
20283/30300 (epoch 33.470), train_loss = 1.02339959, grad/param norm = 1.6859e-01, time/batch = 0.6968s	
20284/30300 (epoch 33.472), train_loss = 1.01462171, grad/param norm = 1.4696e-01, time/batch = 0.6873s	
20285/30300 (epoch 33.474), train_loss = 1.01995697, grad/param norm = 2.2080e-01, time/batch = 0.6833s	
20286/30300 (epoch 33.475), train_loss = 0.99459787, grad/param norm = 1.4675e-01, time/batch = 0.6835s	
20287/30300 (epoch 33.477), train_loss = 1.05791879, grad/param norm = 1.5124e-01, time/batch = 0.6826s	
20288/30300 (epoch 33.479), train_loss = 1.03973126, grad/param norm = 1.7096e-01, time/batch = 0.6821s	
20289/30300 (epoch 33.480), train_loss = 1.08528046, grad/param norm = 1.5390e-01, time/batch = 0.6955s	
20290/30300 (epoch 33.482), train_loss = 1.13012549, grad/param norm = 1.5596e-01, time/batch = 0.6848s	
20291/30300 (epoch 33.483), train_loss = 1.02579525, grad/param norm = 1.6285e-01, time/batch = 0.7165s	
20292/30300 (epoch 33.485), train_loss = 1.07735864, grad/param norm = 1.6504e-01, time/batch = 0.7110s	
20293/30300 (epoch 33.487), train_loss = 1.15409848, grad/param norm = 1.6546e-01, time/batch = 0.6872s	
20294/30300 (epoch 33.488), train_loss = 1.17743901, grad/param norm = 1.4914e-01, time/batch = 0.6854s	
20295/30300 (epoch 33.490), train_loss = 0.94959526, grad/param norm = 1.6470e-01, time/batch = 0.6834s	
20296/30300 (epoch 33.492), train_loss = 1.04468618, grad/param norm = 1.7886e-01, time/batch = 0.6833s	
20297/30300 (epoch 33.493), train_loss = 1.04725735, grad/param norm = 1.5447e-01, time/batch = 0.6861s	
20298/30300 (epoch 33.495), train_loss = 1.05948884, grad/param norm = 1.5766e-01, time/batch = 0.6849s	
20299/30300 (epoch 33.497), train_loss = 1.07090257, grad/param norm = 1.5737e-01, time/batch = 0.6854s	
20300/30300 (epoch 33.498), train_loss = 1.12176016, grad/param norm = 1.6352e-01, time/batch = 0.6844s	
20301/30300 (epoch 33.500), train_loss = 1.04912289, grad/param norm = 1.7676e-01, time/batch = 0.6866s	
20302/30300 (epoch 33.502), train_loss = 1.03968318, grad/param norm = 1.8409e-01, time/batch = 0.6893s	
20303/30300 (epoch 33.503), train_loss = 1.15932984, grad/param norm = 1.5744e-01, time/batch = 0.6993s	
20304/30300 (epoch 33.505), train_loss = 0.95903397, grad/param norm = 1.3893e-01, time/batch = 0.6861s	
20305/30300 (epoch 33.507), train_loss = 0.97764516, grad/param norm = 1.8233e-01, time/batch = 0.6925s	
20306/30300 (epoch 33.508), train_loss = 1.00826472, grad/param norm = 1.9408e-01, time/batch = 0.6845s	
20307/30300 (epoch 33.510), train_loss = 1.13253155, grad/param norm = 1.8499e-01, time/batch = 0.6822s	
20308/30300 (epoch 33.512), train_loss = 1.00028068, grad/param norm = 1.5075e-01, time/batch = 0.6820s	
20309/30300 (epoch 33.513), train_loss = 1.07088420, grad/param norm = 1.5493e-01, time/batch = 0.6814s	
20310/30300 (epoch 33.515), train_loss = 1.05288138, grad/param norm = 1.6435e-01, time/batch = 0.7234s	
20311/30300 (epoch 33.517), train_loss = 0.89178524, grad/param norm = 1.5041e-01, time/batch = 0.7026s	
20312/30300 (epoch 33.518), train_loss = 1.14676852, grad/param norm = 1.7274e-01, time/batch = 0.6872s	
20313/30300 (epoch 33.520), train_loss = 1.09922872, grad/param norm = 1.8456e-01, time/batch = 0.6848s	
20314/30300 (epoch 33.521), train_loss = 0.97522463, grad/param norm = 1.8224e-01, time/batch = 0.6849s	
20315/30300 (epoch 33.523), train_loss = 1.19818959, grad/param norm = 2.0657e-01, time/batch = 0.6830s	
20316/30300 (epoch 33.525), train_loss = 1.00688642, grad/param norm = 1.7183e-01, time/batch = 0.6822s	
20317/30300 (epoch 33.526), train_loss = 1.05997709, grad/param norm = 1.5663e-01, time/batch = 0.6835s	
20318/30300 (epoch 33.528), train_loss = 0.95148705, grad/param norm = 1.5068e-01, time/batch = 0.6822s	
20319/30300 (epoch 33.530), train_loss = 0.93033185, grad/param norm = 1.5189e-01, time/batch = 0.7105s	
20320/30300 (epoch 33.531), train_loss = 1.08221694, grad/param norm = 1.7433e-01, time/batch = 0.6837s	
20321/30300 (epoch 33.533), train_loss = 1.05333319, grad/param norm = 2.0812e-01, time/batch = 0.6881s	
20322/30300 (epoch 33.535), train_loss = 1.02919358, grad/param norm = 1.4139e-01, time/batch = 0.6870s	
20323/30300 (epoch 33.536), train_loss = 1.07716806, grad/param norm = 1.7208e-01, time/batch = 0.6886s	
20324/30300 (epoch 33.538), train_loss = 0.93764708, grad/param norm = 1.8046e-01, time/batch = 0.7093s	
20325/30300 (epoch 33.540), train_loss = 0.99830406, grad/param norm = 1.8613e-01, time/batch = 0.7187s	
20326/30300 (epoch 33.541), train_loss = 1.05998193, grad/param norm = 2.1641e-01, time/batch = 0.6839s	
20327/30300 (epoch 33.543), train_loss = 1.03979731, grad/param norm = 1.5426e-01, time/batch = 0.6863s	
20328/30300 (epoch 33.545), train_loss = 1.09794022, grad/param norm = 1.8362e-01, time/batch = 0.6822s	
20329/30300 (epoch 33.546), train_loss = 1.25448600, grad/param norm = 1.6250e-01, time/batch = 0.6825s	
20330/30300 (epoch 33.548), train_loss = 0.99863972, grad/param norm = 1.4770e-01, time/batch = 0.6900s	
20331/30300 (epoch 33.550), train_loss = 1.10892817, grad/param norm = 1.9864e-01, time/batch = 0.6882s	
20332/30300 (epoch 33.551), train_loss = 1.00858474, grad/param norm = 1.7427e-01, time/batch = 0.6823s	
20333/30300 (epoch 33.553), train_loss = 1.03178562, grad/param norm = 1.7169e-01, time/batch = 0.6841s	
20334/30300 (epoch 33.554), train_loss = 1.05914083, grad/param norm = 1.7225e-01, time/batch = 0.6862s	
20335/30300 (epoch 33.556), train_loss = 1.10986972, grad/param norm = 1.5913e-01, time/batch = 0.6861s	
20336/30300 (epoch 33.558), train_loss = 1.12968974, grad/param norm = 1.7497e-01, time/batch = 0.6880s	
20337/30300 (epoch 33.559), train_loss = 1.06886366, grad/param norm = 1.7473e-01, time/batch = 0.6808s	
20338/30300 (epoch 33.561), train_loss = 0.87259036, grad/param norm = 1.5598e-01, time/batch = 0.6843s	
20339/30300 (epoch 33.563), train_loss = 0.95796806, grad/param norm = 1.6048e-01, time/batch = 0.6833s	
20340/30300 (epoch 33.564), train_loss = 0.99908399, grad/param norm = 1.4661e-01, time/batch = 0.6829s	
20341/30300 (epoch 33.566), train_loss = 1.02636298, grad/param norm = 1.4826e-01, time/batch = 0.6889s	
20342/30300 (epoch 33.568), train_loss = 0.91907540, grad/param norm = 1.7472e-01, time/batch = 0.6830s	
20343/30300 (epoch 33.569), train_loss = 1.10601794, grad/param norm = 1.7314e-01, time/batch = 0.7160s	
20344/30300 (epoch 33.571), train_loss = 1.05639613, grad/param norm = 1.5762e-01, time/batch = 0.7104s	
20345/30300 (epoch 33.573), train_loss = 1.09540208, grad/param norm = 1.6671e-01, time/batch = 0.6833s	
20346/30300 (epoch 33.574), train_loss = 1.09452876, grad/param norm = 1.4525e-01, time/batch = 0.6840s	
20347/30300 (epoch 33.576), train_loss = 1.00477738, grad/param norm = 1.4306e-01, time/batch = 0.6829s	
20348/30300 (epoch 33.578), train_loss = 0.92117160, grad/param norm = 1.4288e-01, time/batch = 0.6886s	
20349/30300 (epoch 33.579), train_loss = 1.09781897, grad/param norm = 1.7647e-01, time/batch = 0.6832s	
20350/30300 (epoch 33.581), train_loss = 1.17440695, grad/param norm = 1.6225e-01, time/batch = 0.6845s	
20351/30300 (epoch 33.583), train_loss = 1.19936842, grad/param norm = 1.7458e-01, time/batch = 0.6881s	
20352/30300 (epoch 33.584), train_loss = 1.16123287, grad/param norm = 1.6386e-01, time/batch = 0.6902s	
20353/30300 (epoch 33.586), train_loss = 1.02844520, grad/param norm = 1.7061e-01, time/batch = 0.6907s	
20354/30300 (epoch 33.587), train_loss = 1.04211553, grad/param norm = 1.5914e-01, time/batch = 0.7094s	
20355/30300 (epoch 33.589), train_loss = 0.98361848, grad/param norm = 1.5836e-01, time/batch = 0.7428s	
20356/30300 (epoch 33.591), train_loss = 1.07856382, grad/param norm = 1.5336e-01, time/batch = 1.3292s	
20357/30300 (epoch 33.592), train_loss = 1.02598948, grad/param norm = 1.4822e-01, time/batch = 0.7731s	
20358/30300 (epoch 33.594), train_loss = 1.08067716, grad/param norm = 1.6128e-01, time/batch = 0.6839s	
20359/30300 (epoch 33.596), train_loss = 0.96139410, grad/param norm = 1.4352e-01, time/batch = 0.6854s	
20360/30300 (epoch 33.597), train_loss = 1.00439806, grad/param norm = 1.6462e-01, time/batch = 0.6866s	
20361/30300 (epoch 33.599), train_loss = 0.89521413, grad/param norm = 1.3758e-01, time/batch = 0.6869s	
20362/30300 (epoch 33.601), train_loss = 1.08249626, grad/param norm = 1.6287e-01, time/batch = 0.7010s	
20363/30300 (epoch 33.602), train_loss = 1.02781560, grad/param norm = 1.5294e-01, time/batch = 0.6935s	
20364/30300 (epoch 33.604), train_loss = 0.98630637, grad/param norm = 1.5452e-01, time/batch = 0.7034s	
20365/30300 (epoch 33.606), train_loss = 0.98492762, grad/param norm = 1.9836e-01, time/batch = 0.6903s	
20366/30300 (epoch 33.607), train_loss = 1.13733037, grad/param norm = 2.1396e-01, time/batch = 0.6829s	
20367/30300 (epoch 33.609), train_loss = 1.22680585, grad/param norm = 1.7732e-01, time/batch = 0.6873s	
20368/30300 (epoch 33.611), train_loss = 1.00685134, grad/param norm = 1.5823e-01, time/batch = 0.6864s	
20369/30300 (epoch 33.612), train_loss = 0.94820052, grad/param norm = 1.3664e-01, time/batch = 0.6852s	
20370/30300 (epoch 33.614), train_loss = 1.02757915, grad/param norm = 1.5284e-01, time/batch = 0.6854s	
20371/30300 (epoch 33.616), train_loss = 1.08986509, grad/param norm = 2.1256e-01, time/batch = 0.7284s	
20372/30300 (epoch 33.617), train_loss = 1.07300551, grad/param norm = 1.7523e-01, time/batch = 0.7008s	
20373/30300 (epoch 33.619), train_loss = 0.87013567, grad/param norm = 1.3639e-01, time/batch = 0.6917s	
20374/30300 (epoch 33.620), train_loss = 1.10560624, grad/param norm = 1.5185e-01, time/batch = 0.6834s	
20375/30300 (epoch 33.622), train_loss = 1.04252249, grad/param norm = 1.8186e-01, time/batch = 0.7175s	
20376/30300 (epoch 33.624), train_loss = 1.03237924, grad/param norm = 1.6658e-01, time/batch = 0.7099s	
20377/30300 (epoch 33.625), train_loss = 1.04682023, grad/param norm = 1.8735e-01, time/batch = 0.7206s	
20378/30300 (epoch 33.627), train_loss = 1.15467442, grad/param norm = 1.6910e-01, time/batch = 0.6939s	
20379/30300 (epoch 33.629), train_loss = 1.19479593, grad/param norm = 1.6106e-01, time/batch = 0.7126s	
20380/30300 (epoch 33.630), train_loss = 1.06652070, grad/param norm = 1.5108e-01, time/batch = 0.7164s	
20381/30300 (epoch 33.632), train_loss = 1.09967509, grad/param norm = 1.7491e-01, time/batch = 0.7173s	
20382/30300 (epoch 33.634), train_loss = 0.98611828, grad/param norm = 1.4714e-01, time/batch = 0.6957s	
20383/30300 (epoch 33.635), train_loss = 1.11712499, grad/param norm = 1.8711e-01, time/batch = 0.6915s	
20384/30300 (epoch 33.637), train_loss = 1.13268645, grad/param norm = 1.8066e-01, time/batch = 0.6853s	
20385/30300 (epoch 33.639), train_loss = 1.03334448, grad/param norm = 1.6175e-01, time/batch = 0.6865s	
20386/30300 (epoch 33.640), train_loss = 1.15322373, grad/param norm = 2.0155e-01, time/batch = 0.6889s	
20387/30300 (epoch 33.642), train_loss = 1.03485905, grad/param norm = 1.4823e-01, time/batch = 0.6869s	
20388/30300 (epoch 33.644), train_loss = 1.12686723, grad/param norm = 1.6219e-01, time/batch = 0.6822s	
20389/30300 (epoch 33.645), train_loss = 0.99740022, grad/param norm = 1.4122e-01, time/batch = 0.7050s	
20390/30300 (epoch 33.647), train_loss = 1.07189268, grad/param norm = 1.5144e-01, time/batch = 0.7184s	
20391/30300 (epoch 33.649), train_loss = 1.03434403, grad/param norm = 1.8138e-01, time/batch = 0.6825s	
20392/30300 (epoch 33.650), train_loss = 1.04726909, grad/param norm = 1.6667e-01, time/batch = 0.6828s	
20393/30300 (epoch 33.652), train_loss = 1.02103195, grad/param norm = 1.6748e-01, time/batch = 0.6837s	
20394/30300 (epoch 33.653), train_loss = 1.22459027, grad/param norm = 1.7078e-01, time/batch = 0.6815s	
20395/30300 (epoch 33.655), train_loss = 1.01632687, grad/param norm = 1.6399e-01, time/batch = 0.6831s	
20396/30300 (epoch 33.657), train_loss = 0.99423580, grad/param norm = 1.7595e-01, time/batch = 0.6934s	
20397/30300 (epoch 33.658), train_loss = 0.99455490, grad/param norm = 1.4823e-01, time/batch = 0.6829s	
20398/30300 (epoch 33.660), train_loss = 1.06563108, grad/param norm = 1.6513e-01, time/batch = 0.6854s	
20399/30300 (epoch 33.662), train_loss = 1.08843009, grad/param norm = 2.0787e-01, time/batch = 0.6881s	
20400/30300 (epoch 33.663), train_loss = 1.11255671, grad/param norm = 1.6541e-01, time/batch = 0.6807s	
20401/30300 (epoch 33.665), train_loss = 1.00076807, grad/param norm = 1.7520e-01, time/batch = 0.6895s	
20402/30300 (epoch 33.667), train_loss = 1.11513659, grad/param norm = 1.8316e-01, time/batch = 0.6902s	
20403/30300 (epoch 33.668), train_loss = 1.14789803, grad/param norm = 1.7406e-01, time/batch = 0.6922s	
20404/30300 (epoch 33.670), train_loss = 1.18507531, grad/param norm = 1.7944e-01, time/batch = 0.7263s	
20405/30300 (epoch 33.672), train_loss = 1.07659216, grad/param norm = 1.8613e-01, time/batch = 0.6938s	
20406/30300 (epoch 33.673), train_loss = 1.12228386, grad/param norm = 1.9145e-01, time/batch = 0.6826s	
20407/30300 (epoch 33.675), train_loss = 1.01560017, grad/param norm = 1.6164e-01, time/batch = 0.6826s	
20408/30300 (epoch 33.677), train_loss = 1.00162656, grad/param norm = 1.4353e-01, time/batch = 0.6815s	
20409/30300 (epoch 33.678), train_loss = 1.00628343, grad/param norm = 1.4999e-01, time/batch = 0.6853s	
20410/30300 (epoch 33.680), train_loss = 0.92217447, grad/param norm = 1.4232e-01, time/batch = 0.6827s	
20411/30300 (epoch 33.682), train_loss = 1.03611393, grad/param norm = 1.6941e-01, time/batch = 0.6857s	
20412/30300 (epoch 33.683), train_loss = 1.15329580, grad/param norm = 1.6218e-01, time/batch = 0.6846s	
20413/30300 (epoch 33.685), train_loss = 1.11532574, grad/param norm = 1.8165e-01, time/batch = 0.6831s	
20414/30300 (epoch 33.686), train_loss = 1.01102612, grad/param norm = 1.4744e-01, time/batch = 0.6818s	
20415/30300 (epoch 33.688), train_loss = 1.05144494, grad/param norm = 1.5057e-01, time/batch = 0.6809s	
20416/30300 (epoch 33.690), train_loss = 1.00309221, grad/param norm = 1.7000e-01, time/batch = 0.6825s	
20417/30300 (epoch 33.691), train_loss = 1.08735443, grad/param norm = 1.6034e-01, time/batch = 0.6847s	
20418/30300 (epoch 33.693), train_loss = 1.35241685, grad/param norm = 2.0759e-01, time/batch = 0.6829s	
20419/30300 (epoch 33.695), train_loss = 1.13396316, grad/param norm = 1.8421e-01, time/batch = 0.6843s	
20420/30300 (epoch 33.696), train_loss = 1.13045733, grad/param norm = 2.0890e-01, time/batch = 0.6812s	
20421/30300 (epoch 33.698), train_loss = 0.99113837, grad/param norm = 1.6417e-01, time/batch = 0.6824s	
20422/30300 (epoch 33.700), train_loss = 0.98718304, grad/param norm = 1.6676e-01, time/batch = 0.6799s	
20423/30300 (epoch 33.701), train_loss = 0.91987872, grad/param norm = 1.5910e-01, time/batch = 0.6792s	
20424/30300 (epoch 33.703), train_loss = 1.06408237, grad/param norm = 1.6406e-01, time/batch = 0.6825s	
20425/30300 (epoch 33.705), train_loss = 0.98598810, grad/param norm = 1.6123e-01, time/batch = 0.6822s	
20426/30300 (epoch 33.706), train_loss = 1.12382219, grad/param norm = 1.7737e-01, time/batch = 0.6816s	
20427/30300 (epoch 33.708), train_loss = 1.05840286, grad/param norm = 1.6510e-01, time/batch = 0.6784s	
20428/30300 (epoch 33.710), train_loss = 1.04225264, grad/param norm = 1.6008e-01, time/batch = 0.6789s	
20429/30300 (epoch 33.711), train_loss = 0.98869655, grad/param norm = 1.5660e-01, time/batch = 0.6797s	
20430/30300 (epoch 33.713), train_loss = 0.97992314, grad/param norm = 1.5243e-01, time/batch = 0.6793s	
20431/30300 (epoch 33.715), train_loss = 0.99741025, grad/param norm = 1.5108e-01, time/batch = 0.6810s	
20432/30300 (epoch 33.716), train_loss = 1.12824222, grad/param norm = 1.5609e-01, time/batch = 0.6789s	
20433/30300 (epoch 33.718), train_loss = 1.15392623, grad/param norm = 1.6055e-01, time/batch = 0.6842s	
20434/30300 (epoch 33.719), train_loss = 1.00150204, grad/param norm = 1.8897e-01, time/batch = 0.6812s	
20435/30300 (epoch 33.721), train_loss = 1.04011204, grad/param norm = 1.6982e-01, time/batch = 0.6793s	
20436/30300 (epoch 33.723), train_loss = 0.97966336, grad/param norm = 1.5468e-01, time/batch = 0.6797s	
20437/30300 (epoch 33.724), train_loss = 1.08657651, grad/param norm = 1.8851e-01, time/batch = 0.6822s	
20438/30300 (epoch 33.726), train_loss = 1.36074320, grad/param norm = 2.3963e-01, time/batch = 0.6869s	
20439/30300 (epoch 33.728), train_loss = 1.09896461, grad/param norm = 1.6957e-01, time/batch = 0.6958s	
20440/30300 (epoch 33.729), train_loss = 1.01803893, grad/param norm = 1.8176e-01, time/batch = 0.6928s	
20441/30300 (epoch 33.731), train_loss = 1.05787270, grad/param norm = 1.8387e-01, time/batch = 0.7228s	
20442/30300 (epoch 33.733), train_loss = 1.07246416, grad/param norm = 1.6835e-01, time/batch = 0.6954s	
20443/30300 (epoch 33.734), train_loss = 1.14159682, grad/param norm = 1.5397e-01, time/batch = 0.6978s	
20444/30300 (epoch 33.736), train_loss = 1.05948909, grad/param norm = 1.5609e-01, time/batch = 0.7021s	
20445/30300 (epoch 33.738), train_loss = 0.99987471, grad/param norm = 1.4052e-01, time/batch = 0.6902s	
20446/30300 (epoch 33.739), train_loss = 1.14961236, grad/param norm = 1.6213e-01, time/batch = 0.7041s	
20447/30300 (epoch 33.741), train_loss = 1.20121940, grad/param norm = 1.5428e-01, time/batch = 0.6850s	
20448/30300 (epoch 33.743), train_loss = 1.04339458, grad/param norm = 1.9237e-01, time/batch = 0.6846s	
20449/30300 (epoch 33.744), train_loss = 1.10003552, grad/param norm = 1.6781e-01, time/batch = 0.6908s	
20450/30300 (epoch 33.746), train_loss = 1.01410791, grad/param norm = 1.4877e-01, time/batch = 0.6837s	
20451/30300 (epoch 33.748), train_loss = 1.03753569, grad/param norm = 1.6949e-01, time/batch = 0.6848s	
20452/30300 (epoch 33.749), train_loss = 1.08364802, grad/param norm = 1.7015e-01, time/batch = 0.6816s	
20453/30300 (epoch 33.751), train_loss = 1.08083925, grad/param norm = 1.6540e-01, time/batch = 0.6829s	
20454/30300 (epoch 33.752), train_loss = 1.03051014, grad/param norm = 1.6894e-01, time/batch = 0.6833s	
20455/30300 (epoch 33.754), train_loss = 1.02581006, grad/param norm = 1.5174e-01, time/batch = 0.6817s	
20456/30300 (epoch 33.756), train_loss = 1.03909459, grad/param norm = 1.5960e-01, time/batch = 0.6815s	
20457/30300 (epoch 33.757), train_loss = 1.00565709, grad/param norm = 1.5860e-01, time/batch = 0.6820s	
20458/30300 (epoch 33.759), train_loss = 1.09086149, grad/param norm = 1.5313e-01, time/batch = 0.6811s	
20459/30300 (epoch 33.761), train_loss = 0.93096031, grad/param norm = 1.4649e-01, time/batch = 0.6822s	
20460/30300 (epoch 33.762), train_loss = 0.94635711, grad/param norm = 1.5117e-01, time/batch = 0.6922s	
20461/30300 (epoch 33.764), train_loss = 1.03450763, grad/param norm = 1.5917e-01, time/batch = 0.6859s	
20462/30300 (epoch 33.766), train_loss = 1.16697558, grad/param norm = 1.7885e-01, time/batch = 0.6844s	
20463/30300 (epoch 33.767), train_loss = 1.10350551, grad/param norm = 2.1440e-01, time/batch = 0.6881s	
20464/30300 (epoch 33.769), train_loss = 1.09774125, grad/param norm = 1.8036e-01, time/batch = 0.6871s	
20465/30300 (epoch 33.771), train_loss = 1.00965737, grad/param norm = 1.7640e-01, time/batch = 0.6829s	
20466/30300 (epoch 33.772), train_loss = 1.08295462, grad/param norm = 1.6233e-01, time/batch = 0.6842s	
20467/30300 (epoch 33.774), train_loss = 1.20346167, grad/param norm = 1.6671e-01, time/batch = 0.6845s	
20468/30300 (epoch 33.776), train_loss = 1.01401504, grad/param norm = 1.6400e-01, time/batch = 0.6845s	
20469/30300 (epoch 33.777), train_loss = 1.18446062, grad/param norm = 1.6426e-01, time/batch = 0.7062s	
20470/30300 (epoch 33.779), train_loss = 1.18784066, grad/param norm = 2.0487e-01, time/batch = 0.6849s	
20471/30300 (epoch 33.781), train_loss = 1.08207077, grad/param norm = 1.8636e-01, time/batch = 0.6855s	
20472/30300 (epoch 33.782), train_loss = 1.00485748, grad/param norm = 1.5944e-01, time/batch = 0.6870s	
20473/30300 (epoch 33.784), train_loss = 0.99520889, grad/param norm = 1.4932e-01, time/batch = 0.6838s	
20474/30300 (epoch 33.785), train_loss = 1.15358020, grad/param norm = 1.9184e-01, time/batch = 0.6810s	
20475/30300 (epoch 33.787), train_loss = 0.89329806, grad/param norm = 1.7311e-01, time/batch = 0.6805s	
20476/30300 (epoch 33.789), train_loss = 1.24181806, grad/param norm = 1.7181e-01, time/batch = 0.6816s	
20477/30300 (epoch 33.790), train_loss = 1.09365064, grad/param norm = 1.7677e-01, time/batch = 0.6817s	
20478/30300 (epoch 33.792), train_loss = 0.87862808, grad/param norm = 1.6201e-01, time/batch = 0.6811s	
20479/30300 (epoch 33.794), train_loss = 1.04436778, grad/param norm = 1.9021e-01, time/batch = 0.6847s	
20480/30300 (epoch 33.795), train_loss = 0.98555389, grad/param norm = 1.5630e-01, time/batch = 0.6864s	
20481/30300 (epoch 33.797), train_loss = 1.19041007, grad/param norm = 1.8084e-01, time/batch = 0.6846s	
20482/30300 (epoch 33.799), train_loss = 1.13797981, grad/param norm = 2.0360e-01, time/batch = 0.6838s	
20483/30300 (epoch 33.800), train_loss = 1.14339133, grad/param norm = 1.9555e-01, time/batch = 0.6827s	
20484/30300 (epoch 33.802), train_loss = 1.30961643, grad/param norm = 2.0412e-01, time/batch = 0.6905s	
20485/30300 (epoch 33.804), train_loss = 1.13029182, grad/param norm = 1.7655e-01, time/batch = 0.6853s	
20486/30300 (epoch 33.805), train_loss = 1.21175669, grad/param norm = 1.8159e-01, time/batch = 0.6836s	
20487/30300 (epoch 33.807), train_loss = 1.02561594, grad/param norm = 1.9056e-01, time/batch = 0.6854s	
20488/30300 (epoch 33.809), train_loss = 1.13785126, grad/param norm = 1.7373e-01, time/batch = 0.6833s	
20489/30300 (epoch 33.810), train_loss = 1.10239066, grad/param norm = 1.6031e-01, time/batch = 0.6860s	
20490/30300 (epoch 33.812), train_loss = 1.00969920, grad/param norm = 1.6827e-01, time/batch = 0.6861s	
20491/30300 (epoch 33.814), train_loss = 1.06215255, grad/param norm = 1.5355e-01, time/batch = 0.6851s	
20492/30300 (epoch 33.815), train_loss = 1.06464846, grad/param norm = 1.6690e-01, time/batch = 0.6847s	
20493/30300 (epoch 33.817), train_loss = 1.15118138, grad/param norm = 1.9151e-01, time/batch = 0.7002s	
20494/30300 (epoch 33.818), train_loss = 1.09507861, grad/param norm = 1.8037e-01, time/batch = 0.6882s	
20495/30300 (epoch 33.820), train_loss = 1.23605397, grad/param norm = 1.9222e-01, time/batch = 0.6850s	
20496/30300 (epoch 33.822), train_loss = 1.22360306, grad/param norm = 2.1427e-01, time/batch = 0.6838s	
20497/30300 (epoch 33.823), train_loss = 1.23430787, grad/param norm = 1.9998e-01, time/batch = 0.6901s	
20498/30300 (epoch 33.825), train_loss = 1.21620850, grad/param norm = 1.9828e-01, time/batch = 0.6819s	
20499/30300 (epoch 33.827), train_loss = 0.93743663, grad/param norm = 1.8923e-01, time/batch = 0.6811s	
20500/30300 (epoch 33.828), train_loss = 1.15403973, grad/param norm = 1.8087e-01, time/batch = 0.6805s	
20501/30300 (epoch 33.830), train_loss = 1.11564063, grad/param norm = 1.6587e-01, time/batch = 0.6835s	
20502/30300 (epoch 33.832), train_loss = 0.99554703, grad/param norm = 1.6256e-01, time/batch = 0.7022s	
20503/30300 (epoch 33.833), train_loss = 1.09577521, grad/param norm = 1.6890e-01, time/batch = 0.7230s	
20504/30300 (epoch 33.835), train_loss = 0.99452146, grad/param norm = 1.5758e-01, time/batch = 0.6804s	
20505/30300 (epoch 33.837), train_loss = 0.95612490, grad/param norm = 1.4271e-01, time/batch = 0.6850s	
20506/30300 (epoch 33.838), train_loss = 0.97276372, grad/param norm = 1.6893e-01, time/batch = 0.6865s	
20507/30300 (epoch 33.840), train_loss = 1.15279510, grad/param norm = 1.5085e-01, time/batch = 0.6857s	
20508/30300 (epoch 33.842), train_loss = 1.02729710, grad/param norm = 1.4546e-01, time/batch = 0.6812s	
20509/30300 (epoch 33.843), train_loss = 1.10073449, grad/param norm = 2.0485e-01, time/batch = 0.6791s	
20510/30300 (epoch 33.845), train_loss = 1.11783120, grad/param norm = 1.5875e-01, time/batch = 0.6859s	
20511/30300 (epoch 33.847), train_loss = 1.08232497, grad/param norm = 1.7186e-01, time/batch = 0.6881s	
20512/30300 (epoch 33.848), train_loss = 1.12244817, grad/param norm = 1.7156e-01, time/batch = 0.6863s	
20513/30300 (epoch 33.850), train_loss = 1.06154421, grad/param norm = 1.5972e-01, time/batch = 0.6816s	
20514/30300 (epoch 33.851), train_loss = 1.10220499, grad/param norm = 2.0580e-01, time/batch = 0.6801s	
20515/30300 (epoch 33.853), train_loss = 1.02727807, grad/param norm = 1.7596e-01, time/batch = 0.6788s	
20516/30300 (epoch 33.855), train_loss = 1.03175478, grad/param norm = 1.5713e-01, time/batch = 0.6798s	
20517/30300 (epoch 33.856), train_loss = 1.07997983, grad/param norm = 1.6179e-01, time/batch = 0.6801s	
20518/30300 (epoch 33.858), train_loss = 0.98747935, grad/param norm = 1.4546e-01, time/batch = 0.6831s	
20519/30300 (epoch 33.860), train_loss = 0.97722662, grad/param norm = 1.5409e-01, time/batch = 0.6879s	
20520/30300 (epoch 33.861), train_loss = 1.21492575, grad/param norm = 1.6305e-01, time/batch = 0.6817s	
20521/30300 (epoch 33.863), train_loss = 1.04273136, grad/param norm = 1.6213e-01, time/batch = 0.6830s	
20522/30300 (epoch 33.865), train_loss = 1.12951945, grad/param norm = 1.7745e-01, time/batch = 0.6810s	
20523/30300 (epoch 33.866), train_loss = 1.13201507, grad/param norm = 1.6425e-01, time/batch = 0.6809s	
20524/30300 (epoch 33.868), train_loss = 1.07658229, grad/param norm = 1.5073e-01, time/batch = 0.6882s	
20525/30300 (epoch 33.870), train_loss = 1.01940699, grad/param norm = 1.9757e-01, time/batch = 0.6878s	
20526/30300 (epoch 33.871), train_loss = 1.07810455, grad/param norm = 1.6780e-01, time/batch = 0.7044s	
20527/30300 (epoch 33.873), train_loss = 1.05916089, grad/param norm = 1.5732e-01, time/batch = 0.6878s	
20528/30300 (epoch 33.875), train_loss = 1.05568609, grad/param norm = 1.5720e-01, time/batch = 0.7128s	
20529/30300 (epoch 33.876), train_loss = 0.95284173, grad/param norm = 1.6165e-01, time/batch = 0.6858s	
20530/30300 (epoch 33.878), train_loss = 0.90671635, grad/param norm = 1.5700e-01, time/batch = 0.6852s	
20531/30300 (epoch 33.880), train_loss = 0.98946057, grad/param norm = 1.7797e-01, time/batch = 0.6859s	
20532/30300 (epoch 33.881), train_loss = 1.21710294, grad/param norm = 2.0297e-01, time/batch = 0.6934s	
20533/30300 (epoch 33.883), train_loss = 1.13131991, grad/param norm = 1.6756e-01, time/batch = 0.6838s	
20534/30300 (epoch 33.884), train_loss = 1.04234829, grad/param norm = 1.4473e-01, time/batch = 0.6830s	
20535/30300 (epoch 33.886), train_loss = 1.12248547, grad/param norm = 1.6672e-01, time/batch = 0.6875s	
20536/30300 (epoch 33.888), train_loss = 1.03561161, grad/param norm = 1.7248e-01, time/batch = 0.7278s	
20537/30300 (epoch 33.889), train_loss = 1.07863335, grad/param norm = 1.5270e-01, time/batch = 0.6975s	
20538/30300 (epoch 33.891), train_loss = 1.03634320, grad/param norm = 1.5798e-01, time/batch = 0.6947s	
20539/30300 (epoch 33.893), train_loss = 1.26585153, grad/param norm = 1.7045e-01, time/batch = 0.6843s	
20540/30300 (epoch 33.894), train_loss = 1.11527182, grad/param norm = 1.7167e-01, time/batch = 0.6917s	
20541/30300 (epoch 33.896), train_loss = 0.91743947, grad/param norm = 1.5738e-01, time/batch = 0.6857s	
20542/30300 (epoch 33.898), train_loss = 0.93491253, grad/param norm = 1.5221e-01, time/batch = 0.6839s	
20543/30300 (epoch 33.899), train_loss = 0.97159852, grad/param norm = 1.6126e-01, time/batch = 0.6808s	
20544/30300 (epoch 33.901), train_loss = 1.07854967, grad/param norm = 1.8800e-01, time/batch = 0.6884s	
20545/30300 (epoch 33.903), train_loss = 1.07207455, grad/param norm = 2.1130e-01, time/batch = 0.6881s	
20546/30300 (epoch 33.904), train_loss = 1.09362280, grad/param norm = 1.5860e-01, time/batch = 0.6809s	
20547/30300 (epoch 33.906), train_loss = 1.08807953, grad/param norm = 1.8753e-01, time/batch = 0.6853s	
20548/30300 (epoch 33.908), train_loss = 1.00385382, grad/param norm = 1.5031e-01, time/batch = 0.6822s	
20549/30300 (epoch 33.909), train_loss = 1.00093739, grad/param norm = 1.9098e-01, time/batch = 0.6882s	
20550/30300 (epoch 33.911), train_loss = 1.06951423, grad/param norm = 1.5655e-01, time/batch = 0.7124s	
20551/30300 (epoch 33.913), train_loss = 1.06071258, grad/param norm = 1.5734e-01, time/batch = 0.7119s	
20552/30300 (epoch 33.914), train_loss = 1.03420860, grad/param norm = 1.6886e-01, time/batch = 0.6798s	
20553/30300 (epoch 33.916), train_loss = 1.10112512, grad/param norm = 1.5298e-01, time/batch = 0.6805s	
20554/30300 (epoch 33.917), train_loss = 1.03289180, grad/param norm = 1.5915e-01, time/batch = 0.6844s	
20555/30300 (epoch 33.919), train_loss = 0.97881152, grad/param norm = 1.6100e-01, time/batch = 0.6832s	
20556/30300 (epoch 33.921), train_loss = 1.03051541, grad/param norm = 1.4430e-01, time/batch = 0.6844s	
20557/30300 (epoch 33.922), train_loss = 1.14363543, grad/param norm = 1.6990e-01, time/batch = 0.6821s	
20558/30300 (epoch 33.924), train_loss = 1.06578310, grad/param norm = 1.6984e-01, time/batch = 0.6802s	
20559/30300 (epoch 33.926), train_loss = 1.11015350, grad/param norm = 1.6694e-01, time/batch = 0.6803s	
20560/30300 (epoch 33.927), train_loss = 1.08561224, grad/param norm = 1.6317e-01, time/batch = 0.6826s	
20561/30300 (epoch 33.929), train_loss = 0.98298341, grad/param norm = 1.6757e-01, time/batch = 0.6871s	
20562/30300 (epoch 33.931), train_loss = 1.15144440, grad/param norm = 2.0014e-01, time/batch = 0.6848s	
20563/30300 (epoch 33.932), train_loss = 0.98776784, grad/param norm = 1.5828e-01, time/batch = 0.6905s	
20564/30300 (epoch 33.934), train_loss = 1.11163495, grad/param norm = 1.7347e-01, time/batch = 0.7028s	
20565/30300 (epoch 33.936), train_loss = 0.99990121, grad/param norm = 1.6509e-01, time/batch = 0.6962s	
20566/30300 (epoch 33.937), train_loss = 1.00664342, grad/param norm = 1.5264e-01, time/batch = 0.6924s	
20567/30300 (epoch 33.939), train_loss = 1.19546109, grad/param norm = 1.9492e-01, time/batch = 0.6941s	
20568/30300 (epoch 33.941), train_loss = 1.06048659, grad/param norm = 1.7365e-01, time/batch = 0.6814s	
20569/30300 (epoch 33.942), train_loss = 1.05776714, grad/param norm = 1.6885e-01, time/batch = 0.7230s	
20570/30300 (epoch 33.944), train_loss = 0.95257817, grad/param norm = 1.5374e-01, time/batch = 0.7035s	
20571/30300 (epoch 33.946), train_loss = 1.13916607, grad/param norm = 1.8452e-01, time/batch = 0.6844s	
20572/30300 (epoch 33.947), train_loss = 1.12241822, grad/param norm = 2.1897e-01, time/batch = 0.6859s	
20573/30300 (epoch 33.949), train_loss = 1.12599783, grad/param norm = 1.9857e-01, time/batch = 0.6850s	
20574/30300 (epoch 33.950), train_loss = 1.17330140, grad/param norm = 1.7807e-01, time/batch = 0.6862s	
20575/30300 (epoch 33.952), train_loss = 1.12161808, grad/param norm = 2.0418e-01, time/batch = 0.6823s	
20576/30300 (epoch 33.954), train_loss = 1.32110880, grad/param norm = 1.6817e-01, time/batch = 0.6847s	
20577/30300 (epoch 33.955), train_loss = 1.04316326, grad/param norm = 1.5420e-01, time/batch = 0.6837s	
20578/30300 (epoch 33.957), train_loss = 1.12423033, grad/param norm = 1.6036e-01, time/batch = 0.6827s	
20579/30300 (epoch 33.959), train_loss = 0.97313956, grad/param norm = 1.7361e-01, time/batch = 0.6842s	
20580/30300 (epoch 33.960), train_loss = 1.01592239, grad/param norm = 1.6633e-01, time/batch = 0.6820s	
20581/30300 (epoch 33.962), train_loss = 1.01946491, grad/param norm = 2.0950e-01, time/batch = 0.6860s	
20582/30300 (epoch 33.964), train_loss = 0.96837721, grad/param norm = 1.8380e-01, time/batch = 0.6848s	
20583/30300 (epoch 33.965), train_loss = 1.01685966, grad/param norm = 2.0079e-01, time/batch = 0.6915s	
20584/30300 (epoch 33.967), train_loss = 1.05011604, grad/param norm = 2.0170e-01, time/batch = 0.6863s	
20585/30300 (epoch 33.969), train_loss = 0.98843146, grad/param norm = 1.9232e-01, time/batch = 0.6852s	
20586/30300 (epoch 33.970), train_loss = 1.04137687, grad/param norm = 1.6356e-01, time/batch = 0.6843s	
20587/30300 (epoch 33.972), train_loss = 0.95896069, grad/param norm = 1.7404e-01, time/batch = 0.6841s	
20588/30300 (epoch 33.974), train_loss = 1.21607859, grad/param norm = 1.8066e-01, time/batch = 0.6854s	
20589/30300 (epoch 33.975), train_loss = 1.21465254, grad/param norm = 2.3236e-01, time/batch = 0.6851s	
20590/30300 (epoch 33.977), train_loss = 1.24125608, grad/param norm = 1.8081e-01, time/batch = 0.6858s	
20591/30300 (epoch 33.979), train_loss = 1.12161604, grad/param norm = 1.7827e-01, time/batch = 0.7006s	
20592/30300 (epoch 33.980), train_loss = 1.16065907, grad/param norm = 1.9724e-01, time/batch = 0.7221s	
20593/30300 (epoch 33.982), train_loss = 1.16064342, grad/param norm = 1.6665e-01, time/batch = 0.7093s	
20594/30300 (epoch 33.983), train_loss = 1.19337950, grad/param norm = 1.7164e-01, time/batch = 0.6848s	
20595/30300 (epoch 33.985), train_loss = 1.12090663, grad/param norm = 2.0171e-01, time/batch = 0.6852s	
20596/30300 (epoch 33.987), train_loss = 1.05129714, grad/param norm = 1.4760e-01, time/batch = 0.6844s	
20597/30300 (epoch 33.988), train_loss = 1.20346049, grad/param norm = 2.0054e-01, time/batch = 0.6817s	
20598/30300 (epoch 33.990), train_loss = 0.97805901, grad/param norm = 1.6926e-01, time/batch = 0.6836s	
20599/30300 (epoch 33.992), train_loss = 1.15175623, grad/param norm = 1.5280e-01, time/batch = 0.6850s	
20600/30300 (epoch 33.993), train_loss = 1.20653177, grad/param norm = 2.2034e-01, time/batch = 0.6831s	
20601/30300 (epoch 33.995), train_loss = 1.07989517, grad/param norm = 2.2275e-01, time/batch = 0.6863s	
20602/30300 (epoch 33.997), train_loss = 1.10755113, grad/param norm = 1.9320e-01, time/batch = 0.6854s	
20603/30300 (epoch 33.998), train_loss = 1.13724132, grad/param norm = 1.8341e-01, time/batch = 0.6806s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
20604/30300 (epoch 34.000), train_loss = 1.03778035, grad/param norm = 2.0213e-01, time/batch = 0.6821s	
20605/30300 (epoch 34.002), train_loss = 1.17268966, grad/param norm = 1.8454e-01, time/batch = 0.6822s	
20606/30300 (epoch 34.003), train_loss = 1.07717317, grad/param norm = 1.6336e-01, time/batch = 0.6816s	
20607/30300 (epoch 34.005), train_loss = 1.04341822, grad/param norm = 1.6872e-01, time/batch = 0.6840s	
20608/30300 (epoch 34.007), train_loss = 1.12113477, grad/param norm = 1.9508e-01, time/batch = 0.6839s	
20609/30300 (epoch 34.008), train_loss = 1.03994789, grad/param norm = 1.6175e-01, time/batch = 0.6831s	
20610/30300 (epoch 34.010), train_loss = 0.95744906, grad/param norm = 1.8142e-01, time/batch = 0.6841s	
20611/30300 (epoch 34.012), train_loss = 1.01165371, grad/param norm = 1.6202e-01, time/batch = 0.7283s	
20612/30300 (epoch 34.013), train_loss = 1.15907744, grad/param norm = 1.7821e-01, time/batch = 0.7098s	
20613/30300 (epoch 34.015), train_loss = 1.03337123, grad/param norm = 1.5211e-01, time/batch = 0.6997s	
20614/30300 (epoch 34.017), train_loss = 1.02654168, grad/param norm = 1.5542e-01, time/batch = 0.6900s	
20615/30300 (epoch 34.018), train_loss = 0.97454102, grad/param norm = 1.6172e-01, time/batch = 0.7397s	
20616/30300 (epoch 34.020), train_loss = 1.16505555, grad/param norm = 1.9509e-01, time/batch = 0.7056s	
20617/30300 (epoch 34.021), train_loss = 1.18569962, grad/param norm = 1.6270e-01, time/batch = 0.6874s	
20618/30300 (epoch 34.023), train_loss = 1.08117604, grad/param norm = 1.6107e-01, time/batch = 0.6834s	
20619/30300 (epoch 34.025), train_loss = 1.00478874, grad/param norm = 1.8615e-01, time/batch = 0.6824s	
20620/30300 (epoch 34.026), train_loss = 1.11691538, grad/param norm = 1.8170e-01, time/batch = 0.6829s	
20621/30300 (epoch 34.028), train_loss = 1.14436909, grad/param norm = 1.6756e-01, time/batch = 0.6856s	
20622/30300 (epoch 34.030), train_loss = 1.03622994, grad/param norm = 1.7197e-01, time/batch = 0.6853s	
20623/30300 (epoch 34.031), train_loss = 1.11500728, grad/param norm = 1.6485e-01, time/batch = 0.6831s	
20624/30300 (epoch 34.033), train_loss = 1.07182784, grad/param norm = 1.5314e-01, time/batch = 0.6868s	
20625/30300 (epoch 34.035), train_loss = 1.13233352, grad/param norm = 1.8184e-01, time/batch = 0.6869s	
20626/30300 (epoch 34.036), train_loss = 1.09092748, grad/param norm = 1.6448e-01, time/batch = 0.6965s	
20627/30300 (epoch 34.038), train_loss = 1.13123249, grad/param norm = 1.6057e-01, time/batch = 0.7021s	
20628/30300 (epoch 34.040), train_loss = 0.88356629, grad/param norm = 1.4913e-01, time/batch = 0.7051s	
20629/30300 (epoch 34.041), train_loss = 0.91044446, grad/param norm = 1.7145e-01, time/batch = 0.7171s	
20630/30300 (epoch 34.043), train_loss = 1.09101256, grad/param norm = 1.7690e-01, time/batch = 0.7117s	
20631/30300 (epoch 34.045), train_loss = 1.02134214, grad/param norm = 1.4986e-01, time/batch = 0.7197s	
20632/30300 (epoch 34.046), train_loss = 1.23029179, grad/param norm = 1.9880e-01, time/batch = 0.7141s	
20633/30300 (epoch 34.048), train_loss = 1.07786624, grad/param norm = 2.0700e-01, time/batch = 0.7122s	
20634/30300 (epoch 34.050), train_loss = 1.00113439, grad/param norm = 1.8779e-01, time/batch = 0.6867s	
20635/30300 (epoch 34.051), train_loss = 1.12810506, grad/param norm = 1.8833e-01, time/batch = 0.6846s	
20636/30300 (epoch 34.053), train_loss = 0.93809199, grad/param norm = 1.9131e-01, time/batch = 0.6868s	
20637/30300 (epoch 34.054), train_loss = 1.10343782, grad/param norm = 1.6553e-01, time/batch = 0.6943s	
20638/30300 (epoch 34.056), train_loss = 0.98343954, grad/param norm = 1.5856e-01, time/batch = 0.6941s	
20639/30300 (epoch 34.058), train_loss = 1.04277636, grad/param norm = 1.5501e-01, time/batch = 0.6988s	
20640/30300 (epoch 34.059), train_loss = 1.04923372, grad/param norm = 2.0659e-01, time/batch = 0.7018s	
20641/30300 (epoch 34.061), train_loss = 1.12212371, grad/param norm = 1.9632e-01, time/batch = 0.6954s	
20642/30300 (epoch 34.063), train_loss = 0.94607013, grad/param norm = 1.6722e-01, time/batch = 0.6904s	
20643/30300 (epoch 34.064), train_loss = 1.08427476, grad/param norm = 1.8067e-01, time/batch = 0.6983s	
20644/30300 (epoch 34.066), train_loss = 1.06059297, grad/param norm = 1.4763e-01, time/batch = 0.7281s	
20645/30300 (epoch 34.068), train_loss = 0.97799760, grad/param norm = 1.6345e-01, time/batch = 0.6991s	
20646/30300 (epoch 34.069), train_loss = 1.13276944, grad/param norm = 1.6578e-01, time/batch = 0.6998s	
20647/30300 (epoch 34.071), train_loss = 1.12047516, grad/param norm = 1.7544e-01, time/batch = 0.6924s	
20648/30300 (epoch 34.073), train_loss = 0.98568440, grad/param norm = 1.7752e-01, time/batch = 0.6846s	
20649/30300 (epoch 34.074), train_loss = 1.06482931, grad/param norm = 1.5912e-01, time/batch = 0.6815s	
20650/30300 (epoch 34.076), train_loss = 1.05031135, grad/param norm = 1.7048e-01, time/batch = 0.6806s	
20651/30300 (epoch 34.078), train_loss = 1.00047329, grad/param norm = 1.5179e-01, time/batch = 0.6826s	
20652/30300 (epoch 34.079), train_loss = 1.01326499, grad/param norm = 1.5601e-01, time/batch = 0.7041s	
20653/30300 (epoch 34.081), train_loss = 1.07695215, grad/param norm = 1.7012e-01, time/batch = 0.7054s	
20654/30300 (epoch 34.083), train_loss = 1.13093386, grad/param norm = 2.0301e-01, time/batch = 0.7287s	
20655/30300 (epoch 34.084), train_loss = 0.99235814, grad/param norm = 1.5712e-01, time/batch = 0.7009s	
20656/30300 (epoch 34.086), train_loss = 1.01299994, grad/param norm = 2.1179e-01, time/batch = 0.6845s	
20657/30300 (epoch 34.087), train_loss = 0.98485219, grad/param norm = 1.5372e-01, time/batch = 0.7053s	
20658/30300 (epoch 34.089), train_loss = 1.00374449, grad/param norm = 1.5149e-01, time/batch = 0.6979s	
20659/30300 (epoch 34.091), train_loss = 1.10044480, grad/param norm = 1.6411e-01, time/batch = 0.6862s	
20660/30300 (epoch 34.092), train_loss = 1.13629360, grad/param norm = 1.7746e-01, time/batch = 0.6820s	
20661/30300 (epoch 34.094), train_loss = 1.18510310, grad/param norm = 1.8758e-01, time/batch = 0.6847s	
20662/30300 (epoch 34.096), train_loss = 1.17435805, grad/param norm = 1.8551e-01, time/batch = 0.6861s	
20663/30300 (epoch 34.097), train_loss = 1.00229712, grad/param norm = 1.8344e-01, time/batch = 0.6840s	
20664/30300 (epoch 34.099), train_loss = 1.14435817, grad/param norm = 1.6693e-01, time/batch = 0.6838s	
20665/30300 (epoch 34.101), train_loss = 1.20261245, grad/param norm = 2.1085e-01, time/batch = 0.6836s	
20666/30300 (epoch 34.102), train_loss = 1.01060880, grad/param norm = 1.8950e-01, time/batch = 0.6823s	
20667/30300 (epoch 34.104), train_loss = 1.01873785, grad/param norm = 1.8670e-01, time/batch = 0.6833s	
20668/30300 (epoch 34.106), train_loss = 1.02784141, grad/param norm = 1.8828e-01, time/batch = 0.6832s	
20669/30300 (epoch 34.107), train_loss = 1.11431848, grad/param norm = 1.6148e-01, time/batch = 0.6828s	
20670/30300 (epoch 34.109), train_loss = 1.14782286, grad/param norm = 2.2382e-01, time/batch = 0.6838s	
20671/30300 (epoch 34.111), train_loss = 1.14590042, grad/param norm = 1.8311e-01, time/batch = 0.6858s	
20672/30300 (epoch 34.112), train_loss = 1.19506981, grad/param norm = 1.5644e-01, time/batch = 0.6837s	
20673/30300 (epoch 34.114), train_loss = 1.03434122, grad/param norm = 1.6904e-01, time/batch = 0.6838s	
20674/30300 (epoch 34.116), train_loss = 1.09821492, grad/param norm = 2.0376e-01, time/batch = 0.6847s	
20675/30300 (epoch 34.117), train_loss = 1.18152415, grad/param norm = 1.7429e-01, time/batch = 0.6875s	
20676/30300 (epoch 34.119), train_loss = 1.00799195, grad/param norm = 2.1090e-01, time/batch = 0.6889s	
20677/30300 (epoch 34.120), train_loss = 1.05245777, grad/param norm = 1.8253e-01, time/batch = 0.7069s	
20678/30300 (epoch 34.122), train_loss = 1.16264899, grad/param norm = 2.0270e-01, time/batch = 0.6872s	
20679/30300 (epoch 34.124), train_loss = 1.23453647, grad/param norm = 1.9704e-01, time/batch = 0.6854s	
20680/30300 (epoch 34.125), train_loss = 0.96975521, grad/param norm = 1.7342e-01, time/batch = 0.7299s	
20681/30300 (epoch 34.127), train_loss = 1.11038856, grad/param norm = 1.9129e-01, time/batch = 0.6954s	
20682/30300 (epoch 34.129), train_loss = 1.17921209, grad/param norm = 1.8147e-01, time/batch = 0.6835s	
20683/30300 (epoch 34.130), train_loss = 1.20701132, grad/param norm = 1.7629e-01, time/batch = 0.6813s	
20684/30300 (epoch 34.132), train_loss = 1.20099867, grad/param norm = 1.8312e-01, time/batch = 0.6857s	
20685/30300 (epoch 34.134), train_loss = 1.00088235, grad/param norm = 2.0320e-01, time/batch = 0.6795s	
20686/30300 (epoch 34.135), train_loss = 1.03025621, grad/param norm = 1.8651e-01, time/batch = 0.6836s	
20687/30300 (epoch 34.137), train_loss = 1.07551745, grad/param norm = 1.8368e-01, time/batch = 0.6846s	
20688/30300 (epoch 34.139), train_loss = 1.02265653, grad/param norm = 1.9891e-01, time/batch = 0.6834s	
20689/30300 (epoch 34.140), train_loss = 1.09878871, grad/param norm = 2.3577e-01, time/batch = 0.6844s	
20690/30300 (epoch 34.142), train_loss = 1.15379770, grad/param norm = 1.8537e-01, time/batch = 0.6815s	
20691/30300 (epoch 34.144), train_loss = 0.99982944, grad/param norm = 1.8271e-01, time/batch = 0.7127s	
20692/30300 (epoch 34.145), train_loss = 1.16027751, grad/param norm = 2.1626e-01, time/batch = 0.7164s	
20693/30300 (epoch 34.147), train_loss = 1.04278959, grad/param norm = 1.7360e-01, time/batch = 0.6839s	
20694/30300 (epoch 34.149), train_loss = 1.17685764, grad/param norm = 1.9255e-01, time/batch = 0.6820s	
20695/30300 (epoch 34.150), train_loss = 1.04518734, grad/param norm = 1.9438e-01, time/batch = 0.6819s	
20696/30300 (epoch 34.152), train_loss = 0.97934059, grad/param norm = 1.9143e-01, time/batch = 0.6811s	
20697/30300 (epoch 34.153), train_loss = 1.08477588, grad/param norm = 2.0368e-01, time/batch = 0.6818s	
20698/30300 (epoch 34.155), train_loss = 0.94321985, grad/param norm = 1.5966e-01, time/batch = 0.6928s	
20699/30300 (epoch 34.157), train_loss = 1.03293295, grad/param norm = 2.0729e-01, time/batch = 0.7006s	
20700/30300 (epoch 34.158), train_loss = 1.10935695, grad/param norm = 2.0899e-01, time/batch = 0.6877s	
20701/30300 (epoch 34.160), train_loss = 0.99932455, grad/param norm = 1.8544e-01, time/batch = 0.7198s	
20702/30300 (epoch 34.162), train_loss = 1.07399846, grad/param norm = 1.6035e-01, time/batch = 0.7222s	
20703/30300 (epoch 34.163), train_loss = 1.07550942, grad/param norm = 1.9270e-01, time/batch = 0.7076s	
20704/30300 (epoch 34.165), train_loss = 1.18952521, grad/param norm = 1.7612e-01, time/batch = 0.6827s	
20705/30300 (epoch 34.167), train_loss = 1.09706307, grad/param norm = 2.0380e-01, time/batch = 0.6815s	
20706/30300 (epoch 34.168), train_loss = 1.13949298, grad/param norm = 1.9502e-01, time/batch = 0.6828s	
20707/30300 (epoch 34.170), train_loss = 1.08265371, grad/param norm = 1.9725e-01, time/batch = 0.6814s	
20708/30300 (epoch 34.172), train_loss = 1.09833297, grad/param norm = 2.2191e-01, time/batch = 0.6851s	
20709/30300 (epoch 34.173), train_loss = 1.06030686, grad/param norm = 1.7820e-01, time/batch = 0.6825s	
20710/30300 (epoch 34.175), train_loss = 1.08391013, grad/param norm = 1.7492e-01, time/batch = 0.7234s	
20711/30300 (epoch 34.177), train_loss = 1.14060377, grad/param norm = 1.8084e-01, time/batch = 0.7023s	
20712/30300 (epoch 34.178), train_loss = 0.87369019, grad/param norm = 1.5012e-01, time/batch = 0.6833s	
20713/30300 (epoch 34.180), train_loss = 1.05498617, grad/param norm = 1.5849e-01, time/batch = 0.6825s	
20714/30300 (epoch 34.182), train_loss = 1.08914912, grad/param norm = 1.7908e-01, time/batch = 0.6825s	
20715/30300 (epoch 34.183), train_loss = 1.01381404, grad/param norm = 1.6992e-01, time/batch = 0.6828s	
20716/30300 (epoch 34.185), train_loss = 1.22686123, grad/param norm = 1.8290e-01, time/batch = 0.6809s	
20717/30300 (epoch 34.186), train_loss = 1.26618251, grad/param norm = 1.9010e-01, time/batch = 0.6858s	
20718/30300 (epoch 34.188), train_loss = 1.11757570, grad/param norm = 1.8410e-01, time/batch = 0.6891s	
20719/30300 (epoch 34.190), train_loss = 1.07301142, grad/param norm = 1.5872e-01, time/batch = 0.6869s	
20720/30300 (epoch 34.191), train_loss = 1.13925613, grad/param norm = 1.9121e-01, time/batch = 0.6889s	
20721/30300 (epoch 34.193), train_loss = 0.99407411, grad/param norm = 1.5640e-01, time/batch = 0.6842s	
20722/30300 (epoch 34.195), train_loss = 1.03647438, grad/param norm = 1.7145e-01, time/batch = 0.6898s	
20723/30300 (epoch 34.196), train_loss = 1.11004961, grad/param norm = 1.4844e-01, time/batch = 0.7070s	
20724/30300 (epoch 34.198), train_loss = 0.91606219, grad/param norm = 1.5419e-01, time/batch = 0.7103s	
20725/30300 (epoch 34.200), train_loss = 1.04572609, grad/param norm = 1.5776e-01, time/batch = 0.7190s	
20726/30300 (epoch 34.201), train_loss = 1.15164994, grad/param norm = 2.1262e-01, time/batch = 0.6827s	
20727/30300 (epoch 34.203), train_loss = 1.07326510, grad/param norm = 2.2014e-01, time/batch = 0.6832s	
20728/30300 (epoch 34.205), train_loss = 1.27641962, grad/param norm = 1.8641e-01, time/batch = 0.6831s	
20729/30300 (epoch 34.206), train_loss = 1.14523164, grad/param norm = 1.7580e-01, time/batch = 0.6831s	
20730/30300 (epoch 34.208), train_loss = 1.12946420, grad/param norm = 2.6225e-01, time/batch = 0.6813s	
20731/30300 (epoch 34.210), train_loss = 1.14828938, grad/param norm = 1.8124e-01, time/batch = 0.6829s	
20732/30300 (epoch 34.211), train_loss = 1.20019802, grad/param norm = 1.8796e-01, time/batch = 0.7002s	
20733/30300 (epoch 34.213), train_loss = 1.07950819, grad/param norm = 1.5908e-01, time/batch = 0.7108s	
20734/30300 (epoch 34.215), train_loss = 1.01685012, grad/param norm = 1.8391e-01, time/batch = 0.6925s	
20735/30300 (epoch 34.216), train_loss = 1.02127216, grad/param norm = 1.7114e-01, time/batch = 0.6924s	
20736/30300 (epoch 34.218), train_loss = 0.99274880, grad/param norm = 1.6884e-01, time/batch = 0.6866s	
20737/30300 (epoch 34.219), train_loss = 0.94036278, grad/param norm = 1.4779e-01, time/batch = 0.6820s	
20738/30300 (epoch 34.221), train_loss = 0.92489863, grad/param norm = 1.5485e-01, time/batch = 0.6797s	
20739/30300 (epoch 34.223), train_loss = 1.09008320, grad/param norm = 1.8058e-01, time/batch = 0.6834s	
20740/30300 (epoch 34.224), train_loss = 0.91871241, grad/param norm = 1.6148e-01, time/batch = 0.6813s	
20741/30300 (epoch 34.226), train_loss = 1.12987310, grad/param norm = 2.0648e-01, time/batch = 0.6847s	
20742/30300 (epoch 34.228), train_loss = 1.18200203, grad/param norm = 1.9067e-01, time/batch = 0.6848s	
20743/30300 (epoch 34.229), train_loss = 1.06081476, grad/param norm = 1.7140e-01, time/batch = 0.7174s	
20744/30300 (epoch 34.231), train_loss = 1.12016062, grad/param norm = 1.8260e-01, time/batch = 0.7085s	
20745/30300 (epoch 34.233), train_loss = 1.12676240, grad/param norm = 1.4976e-01, time/batch = 0.6821s	
20746/30300 (epoch 34.234), train_loss = 1.15859032, grad/param norm = 2.3464e-01, time/batch = 0.6834s	
20747/30300 (epoch 34.236), train_loss = 1.12399941, grad/param norm = 1.6075e-01, time/batch = 0.6836s	
20748/30300 (epoch 34.238), train_loss = 1.06871179, grad/param norm = 1.9444e-01, time/batch = 0.6836s	
20749/30300 (epoch 34.239), train_loss = 1.07014898, grad/param norm = 1.9450e-01, time/batch = 0.6821s	
20750/30300 (epoch 34.241), train_loss = 1.12758686, grad/param norm = 1.8564e-01, time/batch = 0.6809s	
20751/30300 (epoch 34.243), train_loss = 1.13770570, grad/param norm = 1.8038e-01, time/batch = 0.6889s	
20752/30300 (epoch 34.244), train_loss = 1.27530962, grad/param norm = 1.7293e-01, time/batch = 0.6879s	
20753/30300 (epoch 34.246), train_loss = 1.10026611, grad/param norm = 1.5928e-01, time/batch = 0.6883s	
20754/30300 (epoch 34.248), train_loss = 1.04591123, grad/param norm = 1.5845e-01, time/batch = 0.6837s	
20755/30300 (epoch 34.249), train_loss = 0.99382112, grad/param norm = 1.6805e-01, time/batch = 0.6847s	
20756/30300 (epoch 34.251), train_loss = 1.02828326, grad/param norm = 1.8282e-01, time/batch = 0.6857s	
20757/30300 (epoch 34.252), train_loss = 1.18553422, grad/param norm = 1.8793e-01, time/batch = 0.6842s	
20758/30300 (epoch 34.254), train_loss = 1.17388836, grad/param norm = 1.7284e-01, time/batch = 0.6839s	
20759/30300 (epoch 34.256), train_loss = 1.11447497, grad/param norm = 1.7110e-01, time/batch = 0.6845s	
20760/30300 (epoch 34.257), train_loss = 1.15683316, grad/param norm = 1.7993e-01, time/batch = 0.6835s	
20761/30300 (epoch 34.259), train_loss = 1.06170646, grad/param norm = 1.7391e-01, time/batch = 0.6842s	
20762/30300 (epoch 34.261), train_loss = 1.19780771, grad/param norm = 1.6264e-01, time/batch = 0.7254s	
20763/30300 (epoch 34.262), train_loss = 1.00789832, grad/param norm = 1.6353e-01, time/batch = 0.7009s	
20764/30300 (epoch 34.264), train_loss = 1.06689011, grad/param norm = 1.7675e-01, time/batch = 0.6817s	
20765/30300 (epoch 34.266), train_loss = 1.05003661, grad/param norm = 1.5483e-01, time/batch = 0.6845s	
20766/30300 (epoch 34.267), train_loss = 1.22884156, grad/param norm = 1.8975e-01, time/batch = 0.6842s	
20767/30300 (epoch 34.269), train_loss = 1.09873664, grad/param norm = 1.6244e-01, time/batch = 0.6833s	
20768/30300 (epoch 34.271), train_loss = 1.09607528, grad/param norm = 1.7149e-01, time/batch = 0.6867s	
20769/30300 (epoch 34.272), train_loss = 1.09220067, grad/param norm = 2.0537e-01, time/batch = 0.6826s	
20770/30300 (epoch 34.274), train_loss = 1.15054195, grad/param norm = 1.8041e-01, time/batch = 0.6820s	
20771/30300 (epoch 34.276), train_loss = 1.11426220, grad/param norm = 1.9665e-01, time/batch = 0.6857s	
20772/30300 (epoch 34.277), train_loss = 0.97825382, grad/param norm = 1.6963e-01, time/batch = 0.6840s	
20773/30300 (epoch 34.279), train_loss = 1.08737216, grad/param norm = 1.7562e-01, time/batch = 0.6886s	
20774/30300 (epoch 34.281), train_loss = 1.16611783, grad/param norm = 1.6903e-01, time/batch = 0.6941s	
20775/30300 (epoch 34.282), train_loss = 1.11619966, grad/param norm = 1.6751e-01, time/batch = 0.6868s	
20776/30300 (epoch 34.284), train_loss = 1.17756182, grad/param norm = 2.1965e-01, time/batch = 0.6834s	
20777/30300 (epoch 34.285), train_loss = 1.11746243, grad/param norm = 1.5540e-01, time/batch = 0.6830s	
20778/30300 (epoch 34.287), train_loss = 1.08084811, grad/param norm = 1.8295e-01, time/batch = 0.6813s	
20779/30300 (epoch 34.289), train_loss = 1.16346245, grad/param norm = 1.6300e-01, time/batch = 0.6835s	
20780/30300 (epoch 34.290), train_loss = 0.85501651, grad/param norm = 1.4376e-01, time/batch = 0.6864s	
20781/30300 (epoch 34.292), train_loss = 0.99013434, grad/param norm = 1.7851e-01, time/batch = 0.7047s	
20782/30300 (epoch 34.294), train_loss = 1.15808857, grad/param norm = 2.1938e-01, time/batch = 0.6888s	
20783/30300 (epoch 34.295), train_loss = 1.03141741, grad/param norm = 1.6553e-01, time/batch = 0.6849s	
20784/30300 (epoch 34.297), train_loss = 1.03933577, grad/param norm = 1.5897e-01, time/batch = 0.6917s	
20785/30300 (epoch 34.299), train_loss = 1.06101416, grad/param norm = 1.5697e-01, time/batch = 0.6961s	
20786/30300 (epoch 34.300), train_loss = 1.01866526, grad/param norm = 1.8315e-01, time/batch = 0.7050s	
20787/30300 (epoch 34.302), train_loss = 1.15052687, grad/param norm = 1.7300e-01, time/batch = 0.7032s	
20788/30300 (epoch 34.304), train_loss = 1.00855880, grad/param norm = 1.6120e-01, time/batch = 0.7325s	
20789/30300 (epoch 34.305), train_loss = 1.05930430, grad/param norm = 1.5862e-01, time/batch = 0.6991s	
20790/30300 (epoch 34.307), train_loss = 1.15939364, grad/param norm = 1.5279e-01, time/batch = 0.6879s	
20791/30300 (epoch 34.309), train_loss = 1.12535604, grad/param norm = 1.6941e-01, time/batch = 0.6931s	
20792/30300 (epoch 34.310), train_loss = 1.07817770, grad/param norm = 1.7248e-01, time/batch = 0.7053s	
20793/30300 (epoch 34.312), train_loss = 1.20683350, grad/param norm = 1.7057e-01, time/batch = 0.6927s	
20794/30300 (epoch 34.314), train_loss = 1.09123148, grad/param norm = 1.7212e-01, time/batch = 0.6860s	
20795/30300 (epoch 34.315), train_loss = 1.05669194, grad/param norm = 1.8520e-01, time/batch = 0.6881s	
20796/30300 (epoch 34.317), train_loss = 1.09868224, grad/param norm = 1.6078e-01, time/batch = 0.6872s	
20797/30300 (epoch 34.318), train_loss = 1.14634735, grad/param norm = 1.7568e-01, time/batch = 0.6855s	
20798/30300 (epoch 34.320), train_loss = 1.11197063, grad/param norm = 1.6482e-01, time/batch = 0.6820s	
20799/30300 (epoch 34.322), train_loss = 1.01862829, grad/param norm = 2.1226e-01, time/batch = 0.7021s	
20800/30300 (epoch 34.323), train_loss = 1.20240191, grad/param norm = 1.8141e-01, time/batch = 0.7217s	
20801/30300 (epoch 34.325), train_loss = 1.08305695, grad/param norm = 1.8246e-01, time/batch = 0.6848s	
20802/30300 (epoch 34.327), train_loss = 1.06403215, grad/param norm = 1.5924e-01, time/batch = 0.7224s	
20803/30300 (epoch 34.328), train_loss = 1.09384961, grad/param norm = 1.5973e-01, time/batch = 0.7179s	
20804/30300 (epoch 34.330), train_loss = 1.13565737, grad/param norm = 1.7869e-01, time/batch = 0.7068s	
20805/30300 (epoch 34.332), train_loss = 1.17916198, grad/param norm = 2.1409e-01, time/batch = 0.7051s	
20806/30300 (epoch 34.333), train_loss = 1.02919565, grad/param norm = 1.8442e-01, time/batch = 0.6899s	
20807/30300 (epoch 34.335), train_loss = 0.98102934, grad/param norm = 1.6120e-01, time/batch = 0.6825s	
20808/30300 (epoch 34.337), train_loss = 1.21027455, grad/param norm = 1.6406e-01, time/batch = 0.6854s	
20809/30300 (epoch 34.338), train_loss = 1.02923377, grad/param norm = 1.5434e-01, time/batch = 0.6817s	
20810/30300 (epoch 34.340), train_loss = 1.02174436, grad/param norm = 1.5726e-01, time/batch = 0.6815s	
20811/30300 (epoch 34.342), train_loss = 1.15411309, grad/param norm = 1.6037e-01, time/batch = 0.6861s	
20812/30300 (epoch 34.343), train_loss = 1.10438350, grad/param norm = 1.6591e-01, time/batch = 0.6834s	
20813/30300 (epoch 34.345), train_loss = 1.14449324, grad/param norm = 1.8056e-01, time/batch = 0.6942s	
20814/30300 (epoch 34.347), train_loss = 0.95552115, grad/param norm = 1.5049e-01, time/batch = 0.7265s	
20815/30300 (epoch 34.348), train_loss = 1.04183120, grad/param norm = 1.7331e-01, time/batch = 0.6871s	
20816/30300 (epoch 34.350), train_loss = 1.04083933, grad/param norm = 1.7415e-01, time/batch = 0.6812s	
20817/30300 (epoch 34.351), train_loss = 1.06554786, grad/param norm = 1.7441e-01, time/batch = 0.6811s	
20818/30300 (epoch 34.353), train_loss = 0.95598047, grad/param norm = 1.6894e-01, time/batch = 0.6822s	
20819/30300 (epoch 34.355), train_loss = 1.02935306, grad/param norm = 1.5139e-01, time/batch = 0.6810s	
20820/30300 (epoch 34.356), train_loss = 1.14594564, grad/param norm = 2.0576e-01, time/batch = 0.6808s	
20821/30300 (epoch 34.358), train_loss = 1.30170353, grad/param norm = 1.5982e-01, time/batch = 0.6826s	
20822/30300 (epoch 34.360), train_loss = 1.04287434, grad/param norm = 1.7751e-01, time/batch = 0.6814s	
20823/30300 (epoch 34.361), train_loss = 1.05824136, grad/param norm = 1.6353e-01, time/batch = 0.6837s	
20824/30300 (epoch 34.363), train_loss = 1.12079092, grad/param norm = 1.8148e-01, time/batch = 0.6822s	
20825/30300 (epoch 34.365), train_loss = 0.94986008, grad/param norm = 1.8343e-01, time/batch = 0.6822s	
20826/30300 (epoch 34.366), train_loss = 1.04730894, grad/param norm = 1.5941e-01, time/batch = 0.6867s	
20827/30300 (epoch 34.368), train_loss = 0.95278434, grad/param norm = 1.7132e-01, time/batch = 0.6990s	
20828/30300 (epoch 34.370), train_loss = 1.00593411, grad/param norm = 1.6986e-01, time/batch = 0.6942s	
20829/30300 (epoch 34.371), train_loss = 1.14606746, grad/param norm = 1.6168e-01, time/batch = 0.6844s	
20830/30300 (epoch 34.373), train_loss = 1.02076173, grad/param norm = 1.4202e-01, time/batch = 0.6875s	
20831/30300 (epoch 34.375), train_loss = 1.00460607, grad/param norm = 1.4166e-01, time/batch = 0.6836s	
20832/30300 (epoch 34.376), train_loss = 1.00379823, grad/param norm = 1.4873e-01, time/batch = 0.7015s	
20833/30300 (epoch 34.378), train_loss = 0.99047624, grad/param norm = 1.9270e-01, time/batch = 0.7244s	
20834/30300 (epoch 34.380), train_loss = 1.21551371, grad/param norm = 1.9898e-01, time/batch = 0.6850s	
20835/30300 (epoch 34.381), train_loss = 0.91885361, grad/param norm = 1.6267e-01, time/batch = 0.6863s	
20836/30300 (epoch 34.383), train_loss = 0.97509793, grad/param norm = 1.9156e-01, time/batch = 0.6881s	
20837/30300 (epoch 34.384), train_loss = 1.13309351, grad/param norm = 1.8824e-01, time/batch = 0.6847s	
20838/30300 (epoch 34.386), train_loss = 0.97057693, grad/param norm = 1.6976e-01, time/batch = 0.6844s	
20839/30300 (epoch 34.388), train_loss = 0.95027664, grad/param norm = 1.7356e-01, time/batch = 0.6845s	
20840/30300 (epoch 34.389), train_loss = 1.06780142, grad/param norm = 1.7522e-01, time/batch = 0.6844s	
20841/30300 (epoch 34.391), train_loss = 1.11264759, grad/param norm = 1.6009e-01, time/batch = 0.6870s	
20842/30300 (epoch 34.393), train_loss = 0.94192534, grad/param norm = 1.5630e-01, time/batch = 0.6833s	
20843/30300 (epoch 34.394), train_loss = 1.12187436, grad/param norm = 1.6884e-01, time/batch = 0.6824s	
20844/30300 (epoch 34.396), train_loss = 1.18496294, grad/param norm = 1.5084e-01, time/batch = 0.6868s	
20845/30300 (epoch 34.398), train_loss = 1.03370678, grad/param norm = 1.5844e-01, time/batch = 0.6819s	
20846/30300 (epoch 34.399), train_loss = 1.01116074, grad/param norm = 1.5826e-01, time/batch = 0.6813s	
20847/30300 (epoch 34.401), train_loss = 1.07810851, grad/param norm = 1.7103e-01, time/batch = 0.6826s	
20848/30300 (epoch 34.403), train_loss = 1.06951656, grad/param norm = 1.8579e-01, time/batch = 0.6860s	
20849/30300 (epoch 34.404), train_loss = 1.00681686, grad/param norm = 1.7761e-01, time/batch = 0.6860s	
20850/30300 (epoch 34.406), train_loss = 1.07957949, grad/param norm = 1.5652e-01, time/batch = 0.6852s	
20851/30300 (epoch 34.408), train_loss = 0.94600432, grad/param norm = 1.5038e-01, time/batch = 0.7119s	
20852/30300 (epoch 34.409), train_loss = 0.95046197, grad/param norm = 1.7054e-01, time/batch = 0.7169s	
20853/30300 (epoch 34.411), train_loss = 0.98310984, grad/param norm = 1.5325e-01, time/batch = 0.6818s	
20854/30300 (epoch 34.413), train_loss = 0.89161519, grad/param norm = 1.6075e-01, time/batch = 0.6885s	
20855/30300 (epoch 34.414), train_loss = 1.11879026, grad/param norm = 1.7488e-01, time/batch = 0.6927s	
20856/30300 (epoch 34.416), train_loss = 1.01324200, grad/param norm = 1.5434e-01, time/batch = 0.6816s	
20857/30300 (epoch 34.417), train_loss = 0.97272774, grad/param norm = 1.5938e-01, time/batch = 0.6824s	
20858/30300 (epoch 34.419), train_loss = 0.97447584, grad/param norm = 1.5584e-01, time/batch = 0.6856s	
20859/30300 (epoch 34.421), train_loss = 1.01421532, grad/param norm = 1.8234e-01, time/batch = 0.6885s	
20860/30300 (epoch 34.422), train_loss = 1.08757572, grad/param norm = 1.7411e-01, time/batch = 0.6902s	
20861/30300 (epoch 34.424), train_loss = 1.09498374, grad/param norm = 1.8536e-01, time/batch = 0.6899s	
20862/30300 (epoch 34.426), train_loss = 1.02023102, grad/param norm = 1.6517e-01, time/batch = 0.6819s	
20863/30300 (epoch 34.427), train_loss = 1.00574585, grad/param norm = 2.2262e-01, time/batch = 0.6833s	
20864/30300 (epoch 34.429), train_loss = 1.04017399, grad/param norm = 1.5174e-01, time/batch = 0.6832s	
20865/30300 (epoch 34.431), train_loss = 1.12019744, grad/param norm = 1.7821e-01, time/batch = 0.6824s	
20866/30300 (epoch 34.432), train_loss = 1.05307809, grad/param norm = 1.5752e-01, time/batch = 0.6854s	
20867/30300 (epoch 34.434), train_loss = 0.95481109, grad/param norm = 1.6514e-01, time/batch = 0.6833s	
20868/30300 (epoch 34.436), train_loss = 1.17555508, grad/param norm = 1.6758e-01, time/batch = 0.6812s	
20869/30300 (epoch 34.437), train_loss = 0.95874370, grad/param norm = 1.5419e-01, time/batch = 0.6827s	
20870/30300 (epoch 34.439), train_loss = 0.99312642, grad/param norm = 1.4497e-01, time/batch = 0.6834s	
20871/30300 (epoch 34.441), train_loss = 1.04252313, grad/param norm = 1.6371e-01, time/batch = 0.7010s	
20872/30300 (epoch 34.442), train_loss = 0.99181929, grad/param norm = 1.5497e-01, time/batch = 0.7071s	
20873/30300 (epoch 34.444), train_loss = 0.87715271, grad/param norm = 1.4992e-01, time/batch = 0.7012s	
20874/30300 (epoch 34.446), train_loss = 1.03057890, grad/param norm = 1.4521e-01, time/batch = 0.7004s	
20875/30300 (epoch 34.447), train_loss = 1.04905578, grad/param norm = 1.7120e-01, time/batch = 0.6844s	
20876/30300 (epoch 34.449), train_loss = 0.99546638, grad/param norm = 1.5556e-01, time/batch = 0.6836s	
20877/30300 (epoch 34.450), train_loss = 1.08970038, grad/param norm = 1.4842e-01, time/batch = 0.6850s	
20878/30300 (epoch 34.452), train_loss = 1.18242162, grad/param norm = 1.5848e-01, time/batch = 0.6809s	
20879/30300 (epoch 34.454), train_loss = 1.11527808, grad/param norm = 1.5528e-01, time/batch = 0.6899s	
20880/30300 (epoch 34.455), train_loss = 1.04802948, grad/param norm = 1.6987e-01, time/batch = 0.6853s	
20881/30300 (epoch 34.457), train_loss = 1.02131457, grad/param norm = 1.6340e-01, time/batch = 0.6870s	
20882/30300 (epoch 34.459), train_loss = 1.12085086, grad/param norm = 1.8148e-01, time/batch = 0.6868s	
20883/30300 (epoch 34.460), train_loss = 1.11554301, grad/param norm = 1.9135e-01, time/batch = 0.6838s	
20884/30300 (epoch 34.462), train_loss = 1.14285228, grad/param norm = 1.8768e-01, time/batch = 0.6809s	
20885/30300 (epoch 34.464), train_loss = 0.88211740, grad/param norm = 1.6543e-01, time/batch = 0.6808s	
20886/30300 (epoch 34.465), train_loss = 0.90973146, grad/param norm = 1.4511e-01, time/batch = 0.6900s	
20887/30300 (epoch 34.467), train_loss = 0.88429532, grad/param norm = 1.4807e-01, time/batch = 0.6928s	
20888/30300 (epoch 34.469), train_loss = 0.97571086, grad/param norm = 1.4210e-01, time/batch = 0.6886s	
20889/30300 (epoch 34.470), train_loss = 1.00508441, grad/param norm = 1.6103e-01, time/batch = 0.7268s	
20890/30300 (epoch 34.472), train_loss = 1.00536473, grad/param norm = 1.5286e-01, time/batch = 0.6969s	
20891/30300 (epoch 34.474), train_loss = 1.00939659, grad/param norm = 2.2282e-01, time/batch = 0.6845s	
20892/30300 (epoch 34.475), train_loss = 0.99998810, grad/param norm = 1.5764e-01, time/batch = 0.6799s	
20893/30300 (epoch 34.477), train_loss = 1.05046371, grad/param norm = 1.5867e-01, time/batch = 0.6814s	
20894/30300 (epoch 34.479), train_loss = 1.02693406, grad/param norm = 1.7006e-01, time/batch = 0.6805s	
20895/30300 (epoch 34.480), train_loss = 1.07779321, grad/param norm = 1.6568e-01, time/batch = 0.6826s	
20896/30300 (epoch 34.482), train_loss = 1.11481952, grad/param norm = 1.5515e-01, time/batch = 0.6842s	
20897/30300 (epoch 34.483), train_loss = 1.01457878, grad/param norm = 1.6472e-01, time/batch = 0.6831s	
20898/30300 (epoch 34.485), train_loss = 1.06175868, grad/param norm = 1.5358e-01, time/batch = 0.6802s	
20899/30300 (epoch 34.487), train_loss = 1.14301314, grad/param norm = 1.7011e-01, time/batch = 0.6805s	
20900/30300 (epoch 34.488), train_loss = 1.16633448, grad/param norm = 1.4534e-01, time/batch = 0.6842s	
20901/30300 (epoch 34.490), train_loss = 0.92974768, grad/param norm = 1.6097e-01, time/batch = 0.6839s	
20902/30300 (epoch 34.492), train_loss = 1.04052898, grad/param norm = 2.4399e-01, time/batch = 0.6826s	
20903/30300 (epoch 34.493), train_loss = 1.04935942, grad/param norm = 1.7567e-01, time/batch = 0.6846s	
20904/30300 (epoch 34.495), train_loss = 1.02117726, grad/param norm = 1.4247e-01, time/batch = 0.6894s	
20905/30300 (epoch 34.497), train_loss = 1.07896579, grad/param norm = 1.6218e-01, time/batch = 0.6828s	
20906/30300 (epoch 34.498), train_loss = 1.11456034, grad/param norm = 1.7209e-01, time/batch = 0.6816s	
20907/30300 (epoch 34.500), train_loss = 1.02603905, grad/param norm = 1.6462e-01, time/batch = 0.6874s	
20908/30300 (epoch 34.502), train_loss = 1.04480811, grad/param norm = 2.0030e-01, time/batch = 0.6965s	
20909/30300 (epoch 34.503), train_loss = 1.15563854, grad/param norm = 1.6821e-01, time/batch = 0.6854s	
20910/30300 (epoch 34.505), train_loss = 0.94695120, grad/param norm = 1.4284e-01, time/batch = 0.6830s	
20911/30300 (epoch 34.507), train_loss = 0.97125076, grad/param norm = 2.5174e-01, time/batch = 0.6885s	
20912/30300 (epoch 34.508), train_loss = 1.02494847, grad/param norm = 2.0101e-01, time/batch = 0.6863s	
20913/30300 (epoch 34.510), train_loss = 1.13094686, grad/param norm = 1.9549e-01, time/batch = 0.6850s	
20914/30300 (epoch 34.512), train_loss = 0.98148823, grad/param norm = 1.5030e-01, time/batch = 0.6834s	
20915/30300 (epoch 34.513), train_loss = 1.06160374, grad/param norm = 1.7340e-01, time/batch = 0.6845s	
20916/30300 (epoch 34.515), train_loss = 1.04716908, grad/param norm = 1.7081e-01, time/batch = 0.6857s	
20917/30300 (epoch 34.517), train_loss = 0.87472146, grad/param norm = 1.5763e-01, time/batch = 0.6963s	
20918/30300 (epoch 34.518), train_loss = 1.14769403, grad/param norm = 2.0072e-01, time/batch = 0.6848s	
20919/30300 (epoch 34.520), train_loss = 1.08012949, grad/param norm = 1.7336e-01, time/batch = 0.6836s	
20920/30300 (epoch 34.521), train_loss = 0.96508145, grad/param norm = 1.9667e-01, time/batch = 0.7005s	
20921/30300 (epoch 34.523), train_loss = 1.19799993, grad/param norm = 2.2409e-01, time/batch = 0.7021s	
20922/30300 (epoch 34.525), train_loss = 0.98221302, grad/param norm = 1.5082e-01, time/batch = 0.6821s	
20923/30300 (epoch 34.526), train_loss = 1.06841360, grad/param norm = 1.5358e-01, time/batch = 0.6806s	
20924/30300 (epoch 34.528), train_loss = 0.95373767, grad/param norm = 1.7354e-01, time/batch = 0.6824s	
20925/30300 (epoch 34.530), train_loss = 0.94062450, grad/param norm = 1.6737e-01, time/batch = 0.6813s	
20926/30300 (epoch 34.531), train_loss = 1.07996043, grad/param norm = 1.6657e-01, time/batch = 0.6981s	
20927/30300 (epoch 34.533), train_loss = 1.04025413, grad/param norm = 1.9073e-01, time/batch = 0.7260s	
20928/30300 (epoch 34.535), train_loss = 1.01217612, grad/param norm = 1.4801e-01, time/batch = 0.6838s	
20929/30300 (epoch 34.536), train_loss = 1.07704916, grad/param norm = 1.6656e-01, time/batch = 0.6807s	
20930/30300 (epoch 34.538), train_loss = 0.92293485, grad/param norm = 1.6509e-01, time/batch = 0.6796s	
20931/30300 (epoch 34.540), train_loss = 1.00346545, grad/param norm = 2.0951e-01, time/batch = 0.6846s	
20932/30300 (epoch 34.541), train_loss = 1.06584877, grad/param norm = 2.0622e-01, time/batch = 0.6840s	
20933/30300 (epoch 34.543), train_loss = 1.03355439, grad/param norm = 1.5984e-01, time/batch = 0.6816s	
20934/30300 (epoch 34.545), train_loss = 1.10978614, grad/param norm = 2.3562e-01, time/batch = 0.6825s	
20935/30300 (epoch 34.546), train_loss = 1.22188310, grad/param norm = 1.6231e-01, time/batch = 0.6822s	
20936/30300 (epoch 34.548), train_loss = 0.98919293, grad/param norm = 1.4655e-01, time/batch = 0.6825s	
20937/30300 (epoch 34.550), train_loss = 1.09230426, grad/param norm = 1.9303e-01, time/batch = 0.6808s	
20938/30300 (epoch 34.551), train_loss = 1.00144587, grad/param norm = 1.6083e-01, time/batch = 0.6849s	
20939/30300 (epoch 34.553), train_loss = 1.01142588, grad/param norm = 1.5207e-01, time/batch = 0.6848s	
20940/30300 (epoch 34.554), train_loss = 1.05445560, grad/param norm = 1.8053e-01, time/batch = 0.6838s	
20941/30300 (epoch 34.556), train_loss = 1.09616197, grad/param norm = 1.6839e-01, time/batch = 0.6870s	
20942/30300 (epoch 34.558), train_loss = 1.13604862, grad/param norm = 1.9116e-01, time/batch = 0.6838s	
20943/30300 (epoch 34.559), train_loss = 1.05752034, grad/param norm = 1.7207e-01, time/batch = 0.6818s	
20944/30300 (epoch 34.561), train_loss = 0.85158220, grad/param norm = 1.4351e-01, time/batch = 0.6823s	
20945/30300 (epoch 34.563), train_loss = 0.94763452, grad/param norm = 1.6802e-01, time/batch = 0.7019s	
20946/30300 (epoch 34.564), train_loss = 0.99158953, grad/param norm = 1.4685e-01, time/batch = 0.7225s	
20947/30300 (epoch 34.566), train_loss = 1.02561544, grad/param norm = 1.6044e-01, time/batch = 0.6850s	
20948/30300 (epoch 34.568), train_loss = 0.90540291, grad/param norm = 1.7358e-01, time/batch = 0.6868s	
20949/30300 (epoch 34.569), train_loss = 1.07953379, grad/param norm = 1.7333e-01, time/batch = 0.6859s	
20950/30300 (epoch 34.571), train_loss = 1.04938523, grad/param norm = 1.6358e-01, time/batch = 0.6835s	
20951/30300 (epoch 34.573), train_loss = 1.08605483, grad/param norm = 1.6399e-01, time/batch = 0.6865s	
20952/30300 (epoch 34.574), train_loss = 1.08171874, grad/param norm = 1.5297e-01, time/batch = 0.6843s	
20953/30300 (epoch 34.576), train_loss = 0.98898420, grad/param norm = 1.4149e-01, time/batch = 0.6854s	
20954/30300 (epoch 34.578), train_loss = 0.91859405, grad/param norm = 1.4681e-01, time/batch = 0.6873s	
20955/30300 (epoch 34.579), train_loss = 1.09415967, grad/param norm = 1.7389e-01, time/batch = 0.6821s	
20956/30300 (epoch 34.581), train_loss = 1.16306399, grad/param norm = 1.6030e-01, time/batch = 0.6828s	
20957/30300 (epoch 34.583), train_loss = 1.19583842, grad/param norm = 2.0703e-01, time/batch = 0.6986s	
20958/30300 (epoch 34.584), train_loss = 1.13445223, grad/param norm = 1.5817e-01, time/batch = 0.6905s	
20959/30300 (epoch 34.586), train_loss = 1.01127697, grad/param norm = 1.6852e-01, time/batch = 0.6961s	
20960/30300 (epoch 34.587), train_loss = 1.02587333, grad/param norm = 1.6168e-01, time/batch = 0.7044s	
20961/30300 (epoch 34.589), train_loss = 0.98394336, grad/param norm = 1.6114e-01, time/batch = 0.6913s	
20962/30300 (epoch 34.591), train_loss = 1.08478816, grad/param norm = 1.6884e-01, time/batch = 0.6854s	
20963/30300 (epoch 34.592), train_loss = 1.01772480, grad/param norm = 1.5426e-01, time/batch = 0.6844s	
20964/30300 (epoch 34.594), train_loss = 1.08025371, grad/param norm = 1.7083e-01, time/batch = 0.7165s	
20965/30300 (epoch 34.596), train_loss = 0.95109593, grad/param norm = 1.4534e-01, time/batch = 0.7098s	
20966/30300 (epoch 34.597), train_loss = 0.98602329, grad/param norm = 1.5594e-01, time/batch = 0.6813s	
20967/30300 (epoch 34.599), train_loss = 0.88473585, grad/param norm = 1.4098e-01, time/batch = 0.6844s	
20968/30300 (epoch 34.601), train_loss = 1.06797043, grad/param norm = 1.5874e-01, time/batch = 0.6836s	
20969/30300 (epoch 34.602), train_loss = 1.01045273, grad/param norm = 1.4191e-01, time/batch = 0.6868s	
20970/30300 (epoch 34.604), train_loss = 0.96684407, grad/param norm = 1.4837e-01, time/batch = 0.6869s	
20971/30300 (epoch 34.606), train_loss = 0.98768849, grad/param norm = 2.5282e-01, time/batch = 0.6951s	
20972/30300 (epoch 34.607), train_loss = 1.10603964, grad/param norm = 2.0102e-01, time/batch = 0.7128s	
20973/30300 (epoch 34.609), train_loss = 1.21957966, grad/param norm = 1.6372e-01, time/batch = 0.6876s	
20974/30300 (epoch 34.611), train_loss = 1.00444688, grad/param norm = 1.5380e-01, time/batch = 0.6839s	
20975/30300 (epoch 34.612), train_loss = 0.94648657, grad/param norm = 1.4763e-01, time/batch = 0.6840s	
20976/30300 (epoch 34.614), train_loss = 1.01894841, grad/param norm = 1.6699e-01, time/batch = 0.6843s	
20977/30300 (epoch 34.616), train_loss = 1.07454838, grad/param norm = 1.9099e-01, time/batch = 0.6877s	
20978/30300 (epoch 34.617), train_loss = 1.05677199, grad/param norm = 1.5775e-01, time/batch = 0.6858s	
20979/30300 (epoch 34.619), train_loss = 0.86197759, grad/param norm = 1.4427e-01, time/batch = 0.6853s	
20980/30300 (epoch 34.620), train_loss = 1.10032513, grad/param norm = 1.5860e-01, time/batch = 0.6822s	
20981/30300 (epoch 34.622), train_loss = 1.04643568, grad/param norm = 1.8425e-01, time/batch = 0.6839s	
20982/30300 (epoch 34.624), train_loss = 1.03066816, grad/param norm = 1.6571e-01, time/batch = 0.6847s	
20983/30300 (epoch 34.625), train_loss = 1.03165018, grad/param norm = 2.2256e-01, time/batch = 0.7294s	
20984/30300 (epoch 34.627), train_loss = 1.12951488, grad/param norm = 1.6568e-01, time/batch = 0.7073s	
20985/30300 (epoch 34.629), train_loss = 1.17514245, grad/param norm = 1.6358e-01, time/batch = 0.6931s	
20986/30300 (epoch 34.630), train_loss = 1.05500414, grad/param norm = 1.6392e-01, time/batch = 0.7017s	
20987/30300 (epoch 34.632), train_loss = 1.09970560, grad/param norm = 1.9483e-01, time/batch = 0.6947s	
20988/30300 (epoch 34.634), train_loss = 0.97987999, grad/param norm = 1.4604e-01, time/batch = 0.6956s	
20989/30300 (epoch 34.635), train_loss = 1.09686187, grad/param norm = 1.7500e-01, time/batch = 0.6972s	
20990/30300 (epoch 34.637), train_loss = 1.13245671, grad/param norm = 1.9899e-01, time/batch = 0.6944s	
20991/30300 (epoch 34.639), train_loss = 1.03315035, grad/param norm = 1.7569e-01, time/batch = 0.6973s	
20992/30300 (epoch 34.640), train_loss = 1.14346078, grad/param norm = 1.9544e-01, time/batch = 0.6902s	
20993/30300 (epoch 34.642), train_loss = 1.02281053, grad/param norm = 1.4496e-01, time/batch = 0.6829s	
20994/30300 (epoch 34.644), train_loss = 1.12644723, grad/param norm = 1.7077e-01, time/batch = 0.6819s	
20995/30300 (epoch 34.645), train_loss = 0.98273751, grad/param norm = 1.4520e-01, time/batch = 0.6837s	
20996/30300 (epoch 34.647), train_loss = 1.06155391, grad/param norm = 1.5776e-01, time/batch = 0.6810s	
20997/30300 (epoch 34.649), train_loss = 1.03729136, grad/param norm = 1.8660e-01, time/batch = 0.7104s	
20998/30300 (epoch 34.650), train_loss = 1.03660914, grad/param norm = 1.6155e-01, time/batch = 0.7151s	
20999/30300 (epoch 34.652), train_loss = 0.99949950, grad/param norm = 1.6590e-01, time/batch = 0.6806s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch34.65_1.9775.t7	
21000/30300 (epoch 34.653), train_loss = 1.21908798, grad/param norm = 1.6025e-01, time/batch = 0.6851s	
21001/30300 (epoch 34.655), train_loss = 1.66317236, grad/param norm = 2.7778e-01, time/batch = 0.6970s	
21002/30300 (epoch 34.657), train_loss = 1.02016241, grad/param norm = 1.9035e-01, time/batch = 0.6881s	
21003/30300 (epoch 34.658), train_loss = 1.00439442, grad/param norm = 1.6010e-01, time/batch = 0.6828s	
21004/30300 (epoch 34.660), train_loss = 1.06017091, grad/param norm = 1.7122e-01, time/batch = 0.6836s	
21005/30300 (epoch 34.662), train_loss = 1.06782390, grad/param norm = 1.8748e-01, time/batch = 0.7009s	
21006/30300 (epoch 34.663), train_loss = 1.11102683, grad/param norm = 1.6475e-01, time/batch = 0.6968s	
21007/30300 (epoch 34.665), train_loss = 1.00447363, grad/param norm = 1.8303e-01, time/batch = 0.7203s	
21008/30300 (epoch 34.667), train_loss = 1.11201446, grad/param norm = 1.7111e-01, time/batch = 0.7179s	
21009/30300 (epoch 34.668), train_loss = 1.13612419, grad/param norm = 1.7698e-01, time/batch = 0.6891s	
21010/30300 (epoch 34.670), train_loss = 1.17215584, grad/param norm = 1.8494e-01, time/batch = 0.6868s	
21011/30300 (epoch 34.672), train_loss = 1.06216378, grad/param norm = 1.7691e-01, time/batch = 0.6860s	
21012/30300 (epoch 34.673), train_loss = 1.09123918, grad/param norm = 1.7298e-01, time/batch = 0.6934s	
21013/30300 (epoch 34.675), train_loss = 1.01261066, grad/param norm = 1.6865e-01, time/batch = 0.6938s	
21014/30300 (epoch 34.677), train_loss = 1.00283523, grad/param norm = 1.4233e-01, time/batch = 0.6895s	
21015/30300 (epoch 34.678), train_loss = 1.00189879, grad/param norm = 1.5790e-01, time/batch = 0.6824s	
21016/30300 (epoch 34.680), train_loss = 0.93098883, grad/param norm = 1.4887e-01, time/batch = 0.6867s	
21017/30300 (epoch 34.682), train_loss = 1.02833451, grad/param norm = 1.7721e-01, time/batch = 0.6839s	
21018/30300 (epoch 34.683), train_loss = 1.14516827, grad/param norm = 1.5915e-01, time/batch = 0.6813s	
21019/30300 (epoch 34.685), train_loss = 1.11044977, grad/param norm = 1.8748e-01, time/batch = 0.6838s	
21020/30300 (epoch 34.686), train_loss = 1.01338011, grad/param norm = 1.4545e-01, time/batch = 0.6834s	
21021/30300 (epoch 34.688), train_loss = 1.04095620, grad/param norm = 1.5217e-01, time/batch = 0.6841s	
21022/30300 (epoch 34.690), train_loss = 0.98264944, grad/param norm = 1.6969e-01, time/batch = 0.6856s	
21023/30300 (epoch 34.691), train_loss = 1.06353663, grad/param norm = 1.5602e-01, time/batch = 0.6861s	
21024/30300 (epoch 34.693), train_loss = 1.34576732, grad/param norm = 2.7248e-01, time/batch = 0.6850s	
21025/30300 (epoch 34.695), train_loss = 1.10655971, grad/param norm = 1.7647e-01, time/batch = 0.6827s	
21026/30300 (epoch 34.696), train_loss = 1.12841698, grad/param norm = 2.2836e-01, time/batch = 0.7248s	
21027/30300 (epoch 34.698), train_loss = 0.99778785, grad/param norm = 1.5952e-01, time/batch = 0.6998s	
21028/30300 (epoch 34.700), train_loss = 0.98508613, grad/param norm = 1.7635e-01, time/batch = 0.6837s	
21029/30300 (epoch 34.701), train_loss = 0.91640423, grad/param norm = 1.5022e-01, time/batch = 0.6832s	
21030/30300 (epoch 34.703), train_loss = 1.05918385, grad/param norm = 1.6226e-01, time/batch = 0.6822s	
21031/30300 (epoch 34.705), train_loss = 0.97755682, grad/param norm = 1.6159e-01, time/batch = 0.6856s	
21032/30300 (epoch 34.706), train_loss = 1.10097661, grad/param norm = 1.6170e-01, time/batch = 0.6844s	
21033/30300 (epoch 34.708), train_loss = 1.05194044, grad/param norm = 1.6534e-01, time/batch = 0.6816s	
21034/30300 (epoch 34.710), train_loss = 1.03081720, grad/param norm = 1.6398e-01, time/batch = 0.6847s	
21035/30300 (epoch 34.711), train_loss = 0.99315284, grad/param norm = 1.6069e-01, time/batch = 0.6891s	
21036/30300 (epoch 34.713), train_loss = 0.97789251, grad/param norm = 1.7766e-01, time/batch = 0.6909s	
21037/30300 (epoch 34.715), train_loss = 0.99690485, grad/param norm = 1.6360e-01, time/batch = 0.6971s	
21038/30300 (epoch 34.716), train_loss = 1.11797918, grad/param norm = 1.5948e-01, time/batch = 0.7087s	
21039/30300 (epoch 34.718), train_loss = 1.15309175, grad/param norm = 1.6700e-01, time/batch = 0.6908s	
21040/30300 (epoch 34.719), train_loss = 0.99378570, grad/param norm = 1.8957e-01, time/batch = 0.6820s	
21041/30300 (epoch 34.721), train_loss = 1.02245793, grad/param norm = 1.6542e-01, time/batch = 0.6830s	
21042/30300 (epoch 34.723), train_loss = 0.97619228, grad/param norm = 1.5418e-01, time/batch = 0.6878s	
21043/30300 (epoch 34.724), train_loss = 1.08680453, grad/param norm = 1.9419e-01, time/batch = 0.6868s	
21044/30300 (epoch 34.726), train_loss = 1.34699526, grad/param norm = 2.0718e-01, time/batch = 0.6944s	
21045/30300 (epoch 34.728), train_loss = 1.09541585, grad/param norm = 1.7183e-01, time/batch = 0.7259s	
21046/30300 (epoch 34.729), train_loss = 1.01748513, grad/param norm = 2.3841e-01, time/batch = 0.6915s	
21047/30300 (epoch 34.731), train_loss = 1.03548395, grad/param norm = 1.7982e-01, time/batch = 0.6927s	
21048/30300 (epoch 34.733), train_loss = 1.06423640, grad/param norm = 1.6442e-01, time/batch = 0.6840s	
21049/30300 (epoch 34.734), train_loss = 1.12766946, grad/param norm = 1.5735e-01, time/batch = 0.6844s	
21050/30300 (epoch 34.736), train_loss = 1.06852264, grad/param norm = 1.6239e-01, time/batch = 0.6886s	
21051/30300 (epoch 34.738), train_loss = 0.99064512, grad/param norm = 1.4218e-01, time/batch = 0.6935s	
21052/30300 (epoch 34.739), train_loss = 1.13806829, grad/param norm = 1.7829e-01, time/batch = 0.6861s	
21053/30300 (epoch 34.741), train_loss = 1.20075822, grad/param norm = 1.5885e-01, time/batch = 0.6847s	
21054/30300 (epoch 34.743), train_loss = 1.02568362, grad/param norm = 1.6905e-01, time/batch = 0.6846s	
21055/30300 (epoch 34.744), train_loss = 1.09160535, grad/param norm = 1.6438e-01, time/batch = 0.6859s	
21056/30300 (epoch 34.746), train_loss = 1.01073477, grad/param norm = 1.4829e-01, time/batch = 0.6908s	
21057/30300 (epoch 34.748), train_loss = 1.04165535, grad/param norm = 2.0369e-01, time/batch = 0.6849s	
21058/30300 (epoch 34.749), train_loss = 1.06740681, grad/param norm = 1.7514e-01, time/batch = 0.7064s	
21059/30300 (epoch 34.751), train_loss = 1.08833725, grad/param norm = 1.6743e-01, time/batch = 0.6995s	
21060/30300 (epoch 34.752), train_loss = 1.02922336, grad/param norm = 1.7038e-01, time/batch = 0.6969s	
21061/30300 (epoch 34.754), train_loss = 1.02254513, grad/param norm = 1.5875e-01, time/batch = 0.7072s	
21062/30300 (epoch 34.756), train_loss = 1.02482976, grad/param norm = 1.5543e-01, time/batch = 0.7066s	
21063/30300 (epoch 34.757), train_loss = 1.00382380, grad/param norm = 1.7049e-01, time/batch = 0.7215s	
21064/30300 (epoch 34.759), train_loss = 1.08590487, grad/param norm = 1.6118e-01, time/batch = 0.7245s	
21065/30300 (epoch 34.761), train_loss = 0.92011634, grad/param norm = 1.5137e-01, time/batch = 0.6935s	
21066/30300 (epoch 34.762), train_loss = 0.93981658, grad/param norm = 1.5894e-01, time/batch = 0.6824s	
21067/30300 (epoch 34.764), train_loss = 1.02924577, grad/param norm = 1.5778e-01, time/batch = 0.6821s	
21068/30300 (epoch 34.766), train_loss = 1.15403202, grad/param norm = 1.8700e-01, time/batch = 0.6814s	
21069/30300 (epoch 34.767), train_loss = 1.09352343, grad/param norm = 2.1101e-01, time/batch = 0.6849s	
21070/30300 (epoch 34.769), train_loss = 1.07053418, grad/param norm = 1.6883e-01, time/batch = 0.6828s	
21071/30300 (epoch 34.771), train_loss = 1.00988919, grad/param norm = 1.9862e-01, time/batch = 0.6842s	
21072/30300 (epoch 34.772), train_loss = 1.06454663, grad/param norm = 1.6753e-01, time/batch = 0.6846s	
21073/30300 (epoch 34.774), train_loss = 1.19940357, grad/param norm = 1.7275e-01, time/batch = 0.6843s	
21074/30300 (epoch 34.776), train_loss = 1.01727451, grad/param norm = 1.7589e-01, time/batch = 0.6818s	
21075/30300 (epoch 34.777), train_loss = 1.17442203, grad/param norm = 1.7240e-01, time/batch = 0.6832s	
21076/30300 (epoch 34.779), train_loss = 1.16622574, grad/param norm = 1.9308e-01, time/batch = 0.6850s	
21077/30300 (epoch 34.781), train_loss = 1.07023802, grad/param norm = 1.8252e-01, time/batch = 0.6878s	
21078/30300 (epoch 34.782), train_loss = 0.99010374, grad/param norm = 1.5918e-01, time/batch = 0.6815s	
21079/30300 (epoch 34.784), train_loss = 0.99239378, grad/param norm = 1.5251e-01, time/batch = 0.6821s	
21080/30300 (epoch 34.785), train_loss = 1.14618279, grad/param norm = 1.8709e-01, time/batch = 0.6860s	
21081/30300 (epoch 34.787), train_loss = 0.88617249, grad/param norm = 1.8060e-01, time/batch = 0.6940s	
21082/30300 (epoch 34.789), train_loss = 1.22820449, grad/param norm = 1.7556e-01, time/batch = 0.7255s	
21083/30300 (epoch 34.790), train_loss = 1.08202876, grad/param norm = 2.0190e-01, time/batch = 0.7104s	
21084/30300 (epoch 34.792), train_loss = 0.87649193, grad/param norm = 1.7525e-01, time/batch = 0.6826s	
21085/30300 (epoch 34.794), train_loss = 1.05176632, grad/param norm = 1.7707e-01, time/batch = 0.6856s	
21086/30300 (epoch 34.795), train_loss = 0.98333241, grad/param norm = 1.5133e-01, time/batch = 0.6831s	
21087/30300 (epoch 34.797), train_loss = 1.17947546, grad/param norm = 1.8296e-01, time/batch = 0.6885s	
21088/30300 (epoch 34.799), train_loss = 1.12688531, grad/param norm = 1.9328e-01, time/batch = 0.6825s	
21089/30300 (epoch 34.800), train_loss = 1.13493821, grad/param norm = 1.8867e-01, time/batch = 0.6834s	
21090/30300 (epoch 34.802), train_loss = 1.30134200, grad/param norm = 2.2070e-01, time/batch = 0.7075s	
21091/30300 (epoch 34.804), train_loss = 1.12811870, grad/param norm = 1.8780e-01, time/batch = 0.6976s	
21092/30300 (epoch 34.805), train_loss = 1.19452618, grad/param norm = 1.7328e-01, time/batch = 0.6838s	
21093/30300 (epoch 34.807), train_loss = 1.02171395, grad/param norm = 1.7929e-01, time/batch = 0.6835s	
21094/30300 (epoch 34.809), train_loss = 1.12925533, grad/param norm = 1.7596e-01, time/batch = 0.6831s	
21095/30300 (epoch 34.810), train_loss = 1.10149620, grad/param norm = 1.7986e-01, time/batch = 0.6844s	
21096/30300 (epoch 34.812), train_loss = 1.01039239, grad/param norm = 1.7504e-01, time/batch = 0.6844s	
21097/30300 (epoch 34.814), train_loss = 1.05449681, grad/param norm = 1.6008e-01, time/batch = 0.6827s	
21098/30300 (epoch 34.815), train_loss = 1.06381330, grad/param norm = 1.7261e-01, time/batch = 0.6829s	
21099/30300 (epoch 34.817), train_loss = 1.14707117, grad/param norm = 1.9628e-01, time/batch = 0.6834s	
21100/30300 (epoch 34.818), train_loss = 1.07841266, grad/param norm = 1.6929e-01, time/batch = 0.6915s	
21101/30300 (epoch 34.820), train_loss = 1.23024360, grad/param norm = 2.0936e-01, time/batch = 0.7293s	
21102/30300 (epoch 34.822), train_loss = 1.19569599, grad/param norm = 1.7716e-01, time/batch = 0.6974s	
21103/30300 (epoch 34.823), train_loss = 1.21454383, grad/param norm = 1.9048e-01, time/batch = 0.6840s	
21104/30300 (epoch 34.825), train_loss = 1.20121216, grad/param norm = 1.7933e-01, time/batch = 0.6877s	
21105/30300 (epoch 34.827), train_loss = 0.91824071, grad/param norm = 1.8044e-01, time/batch = 0.6942s	
21106/30300 (epoch 34.828), train_loss = 1.13739092, grad/param norm = 1.6641e-01, time/batch = 0.6819s	
21107/30300 (epoch 34.830), train_loss = 1.11316743, grad/param norm = 1.7459e-01, time/batch = 0.6815s	
21108/30300 (epoch 34.832), train_loss = 0.99463619, grad/param norm = 1.6775e-01, time/batch = 0.6842s	
21109/30300 (epoch 34.833), train_loss = 1.08837060, grad/param norm = 1.7352e-01, time/batch = 0.6828s	
21110/30300 (epoch 34.835), train_loss = 0.98296989, grad/param norm = 1.6760e-01, time/batch = 0.6819s	
21111/30300 (epoch 34.837), train_loss = 0.94714076, grad/param norm = 1.5572e-01, time/batch = 0.6858s	
21112/30300 (epoch 34.838), train_loss = 0.95891642, grad/param norm = 1.4925e-01, time/batch = 0.6838s	
21113/30300 (epoch 34.840), train_loss = 1.14843549, grad/param norm = 1.4777e-01, time/batch = 0.6833s	
21114/30300 (epoch 34.842), train_loss = 1.02012474, grad/param norm = 1.4770e-01, time/batch = 0.6824s	
21115/30300 (epoch 34.843), train_loss = 1.09496695, grad/param norm = 1.8596e-01, time/batch = 0.6838s	
21116/30300 (epoch 34.845), train_loss = 1.10841667, grad/param norm = 1.5467e-01, time/batch = 0.6902s	
21117/30300 (epoch 34.847), train_loss = 1.06429518, grad/param norm = 1.6587e-01, time/batch = 0.6908s	
21118/30300 (epoch 34.848), train_loss = 1.10616447, grad/param norm = 1.6641e-01, time/batch = 0.6887s	
21119/30300 (epoch 34.850), train_loss = 1.06073985, grad/param norm = 1.5782e-01, time/batch = 0.6882s	
21120/30300 (epoch 34.851), train_loss = 1.10374146, grad/param norm = 2.0425e-01, time/batch = 0.6906s	
21121/30300 (epoch 34.853), train_loss = 1.01651761, grad/param norm = 1.6137e-01, time/batch = 0.6958s	
21122/30300 (epoch 34.855), train_loss = 1.02500694, grad/param norm = 1.5919e-01, time/batch = 0.6902s	
21123/30300 (epoch 34.856), train_loss = 1.06413193, grad/param norm = 1.5553e-01, time/batch = 0.7063s	
21124/30300 (epoch 34.858), train_loss = 0.97941873, grad/param norm = 1.4940e-01, time/batch = 0.7127s	
21125/30300 (epoch 34.860), train_loss = 0.97613880, grad/param norm = 1.5989e-01, time/batch = 0.7103s	
21126/30300 (epoch 34.861), train_loss = 1.21456838, grad/param norm = 1.6933e-01, time/batch = 0.6925s	
21127/30300 (epoch 34.863), train_loss = 1.04282013, grad/param norm = 1.6777e-01, time/batch = 0.6826s	
21128/30300 (epoch 34.865), train_loss = 1.12137026, grad/param norm = 1.9227e-01, time/batch = 0.6800s	
21129/30300 (epoch 34.866), train_loss = 1.13241986, grad/param norm = 1.9139e-01, time/batch = 0.6848s	
21130/30300 (epoch 34.868), train_loss = 1.07979464, grad/param norm = 1.5744e-01, time/batch = 0.6928s	
21131/30300 (epoch 34.870), train_loss = 0.99703490, grad/param norm = 1.7070e-01, time/batch = 0.6902s	
21132/30300 (epoch 34.871), train_loss = 1.06387410, grad/param norm = 1.6184e-01, time/batch = 0.6881s	
21133/30300 (epoch 34.873), train_loss = 1.07157861, grad/param norm = 1.7858e-01, time/batch = 0.6831s	
21134/30300 (epoch 34.875), train_loss = 1.03562923, grad/param norm = 1.4726e-01, time/batch = 0.6807s	
21135/30300 (epoch 34.876), train_loss = 0.94713730, grad/param norm = 1.8116e-01, time/batch = 0.6815s	
21136/30300 (epoch 34.878), train_loss = 0.90595623, grad/param norm = 1.6892e-01, time/batch = 0.6821s	
21137/30300 (epoch 34.880), train_loss = 0.98897401, grad/param norm = 1.6059e-01, time/batch = 0.6803s	
21138/30300 (epoch 34.881), train_loss = 1.22236763, grad/param norm = 2.4276e-01, time/batch = 0.6860s	
21139/30300 (epoch 34.883), train_loss = 1.13864515, grad/param norm = 1.7537e-01, time/batch = 0.6857s	
21140/30300 (epoch 34.884), train_loss = 1.04613867, grad/param norm = 1.5320e-01, time/batch = 0.6831s	
21141/30300 (epoch 34.886), train_loss = 1.11526113, grad/param norm = 1.7747e-01, time/batch = 0.6888s	
21142/30300 (epoch 34.888), train_loss = 1.02737548, grad/param norm = 1.7840e-01, time/batch = 0.6970s	
21143/30300 (epoch 34.889), train_loss = 1.07261747, grad/param norm = 1.6173e-01, time/batch = 0.7268s	
21144/30300 (epoch 34.891), train_loss = 1.03312304, grad/param norm = 1.6473e-01, time/batch = 0.6925s	
21145/30300 (epoch 34.893), train_loss = 1.25248265, grad/param norm = 1.7217e-01, time/batch = 0.6838s	
21146/30300 (epoch 34.894), train_loss = 1.10137380, grad/param norm = 1.6698e-01, time/batch = 0.6920s	
21147/30300 (epoch 34.896), train_loss = 0.91500905, grad/param norm = 1.5479e-01, time/batch = 0.6867s	
21148/30300 (epoch 34.898), train_loss = 0.91763453, grad/param norm = 1.5988e-01, time/batch = 0.6870s	
21149/30300 (epoch 34.899), train_loss = 0.95976035, grad/param norm = 1.7142e-01, time/batch = 0.6838s	
21150/30300 (epoch 34.901), train_loss = 1.07311403, grad/param norm = 1.9981e-01, time/batch = 0.6817s	
21151/30300 (epoch 34.903), train_loss = 1.04123300, grad/param norm = 1.7552e-01, time/batch = 0.7060s	
21152/30300 (epoch 34.904), train_loss = 1.07265123, grad/param norm = 1.5415e-01, time/batch = 0.6941s	
21153/30300 (epoch 34.906), train_loss = 1.06544184, grad/param norm = 1.6180e-01, time/batch = 0.6832s	
21154/30300 (epoch 34.908), train_loss = 0.99222190, grad/param norm = 1.4978e-01, time/batch = 0.6814s	
21155/30300 (epoch 34.909), train_loss = 0.98243116, grad/param norm = 1.7995e-01, time/batch = 0.6818s	
21156/30300 (epoch 34.911), train_loss = 1.06226037, grad/param norm = 1.6124e-01, time/batch = 0.6812s	
21157/30300 (epoch 34.913), train_loss = 1.05673771, grad/param norm = 1.5160e-01, time/batch = 0.6810s	
21158/30300 (epoch 34.914), train_loss = 1.01759228, grad/param norm = 1.6645e-01, time/batch = 0.6824s	
21159/30300 (epoch 34.916), train_loss = 1.09747507, grad/param norm = 1.5123e-01, time/batch = 0.6820s	
21160/30300 (epoch 34.917), train_loss = 1.01301430, grad/param norm = 1.5475e-01, time/batch = 0.6829s	
21161/30300 (epoch 34.919), train_loss = 0.98427161, grad/param norm = 1.7486e-01, time/batch = 0.7016s	
21162/30300 (epoch 34.921), train_loss = 1.02481042, grad/param norm = 1.5247e-01, time/batch = 0.7253s	
21163/30300 (epoch 34.922), train_loss = 1.13880863, grad/param norm = 1.7621e-01, time/batch = 0.6854s	
21164/30300 (epoch 34.924), train_loss = 1.05665021, grad/param norm = 1.7774e-01, time/batch = 0.6814s	
21165/30300 (epoch 34.926), train_loss = 1.08727262, grad/param norm = 1.5734e-01, time/batch = 0.6815s	
21166/30300 (epoch 34.927), train_loss = 1.08453507, grad/param norm = 1.7732e-01, time/batch = 0.6878s	
21167/30300 (epoch 34.929), train_loss = 0.98313022, grad/param norm = 1.7532e-01, time/batch = 0.6879s	
21168/30300 (epoch 34.931), train_loss = 1.13939711, grad/param norm = 2.0799e-01, time/batch = 0.6857s	
21169/30300 (epoch 34.932), train_loss = 0.97843552, grad/param norm = 1.8534e-01, time/batch = 0.6833s	
21170/30300 (epoch 34.934), train_loss = 1.09410546, grad/param norm = 1.6791e-01, time/batch = 0.6819s	
21171/30300 (epoch 34.936), train_loss = 0.98905986, grad/param norm = 1.7463e-01, time/batch = 0.6838s	
21172/30300 (epoch 34.937), train_loss = 0.99047932, grad/param norm = 1.5805e-01, time/batch = 0.6827s	
21173/30300 (epoch 34.939), train_loss = 1.16581662, grad/param norm = 1.8490e-01, time/batch = 0.6829s	
21174/30300 (epoch 34.941), train_loss = 1.02760743, grad/param norm = 1.8011e-01, time/batch = 0.6831s	
21175/30300 (epoch 34.942), train_loss = 1.04548884, grad/param norm = 1.9151e-01, time/batch = 0.6852s	
21176/30300 (epoch 34.944), train_loss = 0.94679554, grad/param norm = 1.8232e-01, time/batch = 0.6822s	
21177/30300 (epoch 34.946), train_loss = 1.12420814, grad/param norm = 2.1277e-01, time/batch = 0.6840s	
21178/30300 (epoch 34.947), train_loss = 1.12413691, grad/param norm = 2.2537e-01, time/batch = 0.6849s	
21179/30300 (epoch 34.949), train_loss = 1.12724805, grad/param norm = 2.1219e-01, time/batch = 0.6834s	
21180/30300 (epoch 34.950), train_loss = 1.15916583, grad/param norm = 1.7653e-01, time/batch = 0.7055s	
21181/30300 (epoch 34.952), train_loss = 1.10474549, grad/param norm = 1.8589e-01, time/batch = 0.7202s	
21182/30300 (epoch 34.954), train_loss = 1.32220554, grad/param norm = 1.8866e-01, time/batch = 0.6873s	
21183/30300 (epoch 34.955), train_loss = 1.03020207, grad/param norm = 1.5196e-01, time/batch = 0.6912s	
21184/30300 (epoch 34.957), train_loss = 1.11484268, grad/param norm = 1.6631e-01, time/batch = 0.6878s	
21185/30300 (epoch 34.959), train_loss = 0.97242118, grad/param norm = 2.0274e-01, time/batch = 0.6833s	
21186/30300 (epoch 34.960), train_loss = 1.01323089, grad/param norm = 1.6655e-01, time/batch = 0.6837s	
21187/30300 (epoch 34.962), train_loss = 1.00934660, grad/param norm = 2.3290e-01, time/batch = 0.6841s	
21188/30300 (epoch 34.964), train_loss = 0.95593509, grad/param norm = 1.8491e-01, time/batch = 0.6871s	
21189/30300 (epoch 34.965), train_loss = 1.00309447, grad/param norm = 1.9824e-01, time/batch = 0.6934s	
21190/30300 (epoch 34.967), train_loss = 1.04503511, grad/param norm = 1.9391e-01, time/batch = 0.6871s	
21191/30300 (epoch 34.969), train_loss = 0.96608342, grad/param norm = 1.9594e-01, time/batch = 0.6845s	
21192/30300 (epoch 34.970), train_loss = 1.04083551, grad/param norm = 1.7396e-01, time/batch = 0.6864s	
21193/30300 (epoch 34.972), train_loss = 0.95123896, grad/param norm = 1.7797e-01, time/batch = 0.6914s	
21194/30300 (epoch 34.974), train_loss = 1.19554744, grad/param norm = 1.7973e-01, time/batch = 0.6997s	
21195/30300 (epoch 34.975), train_loss = 1.19163238, grad/param norm = 2.0215e-01, time/batch = 0.6847s	
21196/30300 (epoch 34.977), train_loss = 1.23276172, grad/param norm = 1.7873e-01, time/batch = 0.6818s	
21197/30300 (epoch 34.979), train_loss = 1.13034299, grad/param norm = 1.8892e-01, time/batch = 0.6869s	
21198/30300 (epoch 34.980), train_loss = 1.14585387, grad/param norm = 1.9713e-01, time/batch = 0.6830s	
21199/30300 (epoch 34.982), train_loss = 1.16722496, grad/param norm = 1.8288e-01, time/batch = 0.6813s	
21200/30300 (epoch 34.983), train_loss = 1.18046343, grad/param norm = 1.6375e-01, time/batch = 0.6837s	
21201/30300 (epoch 34.985), train_loss = 1.12101011, grad/param norm = 2.0667e-01, time/batch = 0.6855s	
21202/30300 (epoch 34.987), train_loss = 1.05914471, grad/param norm = 1.5643e-01, time/batch = 0.6839s	
21203/30300 (epoch 34.988), train_loss = 1.17967308, grad/param norm = 1.7222e-01, time/batch = 0.7059s	
21204/30300 (epoch 34.990), train_loss = 0.98197934, grad/param norm = 1.6805e-01, time/batch = 0.7231s	
21205/30300 (epoch 34.992), train_loss = 1.13181398, grad/param norm = 1.4824e-01, time/batch = 0.6837s	
21206/30300 (epoch 34.993), train_loss = 1.17553843, grad/param norm = 2.0400e-01, time/batch = 0.6834s	
21207/30300 (epoch 34.995), train_loss = 1.06562740, grad/param norm = 1.9905e-01, time/batch = 0.7016s	
21208/30300 (epoch 34.997), train_loss = 1.10021412, grad/param norm = 1.8682e-01, time/batch = 0.6949s	
21209/30300 (epoch 34.998), train_loss = 1.12756526, grad/param norm = 1.9368e-01, time/batch = 0.6937s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
21210/30300 (epoch 35.000), train_loss = 1.01305095, grad/param norm = 1.8108e-01, time/batch = 0.7042s	
21211/30300 (epoch 35.002), train_loss = 1.14721158, grad/param norm = 1.8327e-01, time/batch = 0.7194s	
21212/30300 (epoch 35.003), train_loss = 1.08614799, grad/param norm = 1.7794e-01, time/batch = 0.7067s	
21213/30300 (epoch 35.005), train_loss = 1.04493874, grad/param norm = 1.8778e-01, time/batch = 0.7072s	
21214/30300 (epoch 35.007), train_loss = 1.10963473, grad/param norm = 1.9167e-01, time/batch = 0.6893s	
21215/30300 (epoch 35.008), train_loss = 1.03453222, grad/param norm = 1.5573e-01, time/batch = 0.6815s	
21216/30300 (epoch 35.010), train_loss = 0.94627762, grad/param norm = 1.8062e-01, time/batch = 0.6826s	
21217/30300 (epoch 35.012), train_loss = 1.00943782, grad/param norm = 1.6708e-01, time/batch = 0.6935s	
21218/30300 (epoch 35.013), train_loss = 1.14366557, grad/param norm = 1.9227e-01, time/batch = 0.7262s	
21219/30300 (epoch 35.015), train_loss = 1.02793996, grad/param norm = 1.6026e-01, time/batch = 0.6915s	
21220/30300 (epoch 35.017), train_loss = 1.02293821, grad/param norm = 1.5464e-01, time/batch = 0.6846s	
21221/30300 (epoch 35.018), train_loss = 0.96356423, grad/param norm = 1.5813e-01, time/batch = 0.6883s	
21222/30300 (epoch 35.020), train_loss = 1.15063487, grad/param norm = 2.1337e-01, time/batch = 0.6805s	
21223/30300 (epoch 35.021), train_loss = 1.16614508, grad/param norm = 1.6518e-01, time/batch = 0.6992s	
21224/30300 (epoch 35.023), train_loss = 1.07419377, grad/param norm = 1.5543e-01, time/batch = 0.6938s	
21225/30300 (epoch 35.025), train_loss = 0.99770835, grad/param norm = 2.0100e-01, time/batch = 0.6843s	
21226/30300 (epoch 35.026), train_loss = 1.09961007, grad/param norm = 1.7344e-01, time/batch = 0.6817s	
21227/30300 (epoch 35.028), train_loss = 1.13937632, grad/param norm = 1.6330e-01, time/batch = 0.6865s	
21228/30300 (epoch 35.030), train_loss = 1.02078943, grad/param norm = 1.6845e-01, time/batch = 0.6831s	
21229/30300 (epoch 35.031), train_loss = 1.10687467, grad/param norm = 1.7817e-01, time/batch = 0.6899s	
21230/30300 (epoch 35.033), train_loss = 1.08599835, grad/param norm = 1.7202e-01, time/batch = 0.6851s	
21231/30300 (epoch 35.035), train_loss = 1.14006865, grad/param norm = 2.0890e-01, time/batch = 0.6966s	
21232/30300 (epoch 35.036), train_loss = 1.08588755, grad/param norm = 1.6438e-01, time/batch = 0.7223s	
21233/30300 (epoch 35.038), train_loss = 1.11011408, grad/param norm = 1.4925e-01, time/batch = 0.7167s	
21234/30300 (epoch 35.040), train_loss = 0.88863290, grad/param norm = 1.4140e-01, time/batch = 0.6857s	
21235/30300 (epoch 35.041), train_loss = 0.88929670, grad/param norm = 1.6517e-01, time/batch = 0.6813s	
21236/30300 (epoch 35.043), train_loss = 1.09098232, grad/param norm = 1.8573e-01, time/batch = 0.6848s	
21237/30300 (epoch 35.045), train_loss = 1.02393849, grad/param norm = 1.5593e-01, time/batch = 0.6823s	
21238/30300 (epoch 35.046), train_loss = 1.21513448, grad/param norm = 2.0104e-01, time/batch = 0.6845s	
21239/30300 (epoch 35.048), train_loss = 1.07100079, grad/param norm = 1.7980e-01, time/batch = 0.6842s	
21240/30300 (epoch 35.050), train_loss = 0.97990263, grad/param norm = 1.6363e-01, time/batch = 0.6827s	
21241/30300 (epoch 35.051), train_loss = 1.11195001, grad/param norm = 1.7905e-01, time/batch = 0.6871s	
21242/30300 (epoch 35.053), train_loss = 0.93051260, grad/param norm = 2.0613e-01, time/batch = 0.6868s	
21243/30300 (epoch 35.054), train_loss = 1.11057875, grad/param norm = 1.7132e-01, time/batch = 0.6973s	
21244/30300 (epoch 35.056), train_loss = 0.97547872, grad/param norm = 1.5427e-01, time/batch = 0.6904s	
21245/30300 (epoch 35.058), train_loss = 1.02446331, grad/param norm = 1.9154e-01, time/batch = 0.6947s	
21246/30300 (epoch 35.059), train_loss = 1.00051018, grad/param norm = 1.8651e-01, time/batch = 0.7034s	
21247/30300 (epoch 35.061), train_loss = 1.11017825, grad/param norm = 1.8716e-01, time/batch = 0.6889s	
21248/30300 (epoch 35.063), train_loss = 0.94170615, grad/param norm = 1.6156e-01, time/batch = 0.6931s	
21249/30300 (epoch 35.064), train_loss = 1.07780518, grad/param norm = 1.9108e-01, time/batch = 0.6940s	
21250/30300 (epoch 35.066), train_loss = 1.05801578, grad/param norm = 1.5359e-01, time/batch = 0.6927s	
21251/30300 (epoch 35.068), train_loss = 0.97461917, grad/param norm = 1.7331e-01, time/batch = 0.6921s	
21252/30300 (epoch 35.069), train_loss = 1.11665160, grad/param norm = 1.7151e-01, time/batch = 0.6895s	
21253/30300 (epoch 35.071), train_loss = 1.12519589, grad/param norm = 1.8038e-01, time/batch = 0.6840s	
21254/30300 (epoch 35.073), train_loss = 0.97782725, grad/param norm = 1.7105e-01, time/batch = 0.7010s	
21255/30300 (epoch 35.074), train_loss = 1.04786529, grad/param norm = 1.5587e-01, time/batch = 0.6886s	
21256/30300 (epoch 35.076), train_loss = 1.03438152, grad/param norm = 1.6401e-01, time/batch = 0.6829s	
21257/30300 (epoch 35.078), train_loss = 0.99098656, grad/param norm = 1.5478e-01, time/batch = 0.6822s	
21258/30300 (epoch 35.079), train_loss = 1.01085563, grad/param norm = 1.7035e-01, time/batch = 0.6872s	
21259/30300 (epoch 35.081), train_loss = 1.08502877, grad/param norm = 1.8130e-01, time/batch = 0.6852s	
21260/30300 (epoch 35.083), train_loss = 1.11840791, grad/param norm = 2.5165e-01, time/batch = 0.6985s	
21261/30300 (epoch 35.084), train_loss = 0.99538584, grad/param norm = 1.6087e-01, time/batch = 0.7293s	
21262/30300 (epoch 35.086), train_loss = 0.99585809, grad/param norm = 2.0541e-01, time/batch = 0.7029s	
21263/30300 (epoch 35.087), train_loss = 0.97805215, grad/param norm = 1.4945e-01, time/batch = 0.6843s	
21264/30300 (epoch 35.089), train_loss = 0.98050248, grad/param norm = 1.5823e-01, time/batch = 0.6836s	
21265/30300 (epoch 35.091), train_loss = 1.09660251, grad/param norm = 1.6616e-01, time/batch = 0.6919s	
21266/30300 (epoch 35.092), train_loss = 1.12068344, grad/param norm = 1.6837e-01, time/batch = 0.6878s	
21267/30300 (epoch 35.094), train_loss = 1.18143210, grad/param norm = 2.0677e-01, time/batch = 0.6946s	
21268/30300 (epoch 35.096), train_loss = 1.17517871, grad/param norm = 1.8739e-01, time/batch = 0.6821s	
21269/30300 (epoch 35.097), train_loss = 1.00518845, grad/param norm = 1.7912e-01, time/batch = 0.6808s	
21270/30300 (epoch 35.099), train_loss = 1.13068038, grad/param norm = 1.6855e-01, time/batch = 0.6847s	
21271/30300 (epoch 35.101), train_loss = 1.18314428, grad/param norm = 2.0641e-01, time/batch = 0.6835s	
21272/30300 (epoch 35.102), train_loss = 1.00664082, grad/param norm = 2.0958e-01, time/batch = 0.6808s	
21273/30300 (epoch 35.104), train_loss = 1.03369629, grad/param norm = 2.5034e-01, time/batch = 0.6843s	
21274/30300 (epoch 35.106), train_loss = 1.03229071, grad/param norm = 2.1972e-01, time/batch = 0.6841s	
21275/30300 (epoch 35.107), train_loss = 1.10461317, grad/param norm = 1.5843e-01, time/batch = 0.7052s	
21276/30300 (epoch 35.109), train_loss = 1.13597243, grad/param norm = 2.2671e-01, time/batch = 0.7177s	
21277/30300 (epoch 35.111), train_loss = 1.14184978, grad/param norm = 1.9701e-01, time/batch = 0.6789s	
21278/30300 (epoch 35.112), train_loss = 1.19685299, grad/param norm = 1.7439e-01, time/batch = 0.6983s	
21279/30300 (epoch 35.114), train_loss = 1.02869898, grad/param norm = 1.6737e-01, time/batch = 0.6912s	
21280/30300 (epoch 35.116), train_loss = 1.10321687, grad/param norm = 1.9864e-01, time/batch = 0.6846s	
21281/30300 (epoch 35.117), train_loss = 1.17182851, grad/param norm = 1.7145e-01, time/batch = 0.6835s	
21282/30300 (epoch 35.119), train_loss = 0.98450854, grad/param norm = 1.7678e-01, time/batch = 0.6861s	
21283/30300 (epoch 35.120), train_loss = 1.04130073, grad/param norm = 1.6827e-01, time/batch = 0.6838s	
21284/30300 (epoch 35.122), train_loss = 1.15895056, grad/param norm = 2.2759e-01, time/batch = 0.6818s	
21285/30300 (epoch 35.124), train_loss = 1.22598060, grad/param norm = 1.9165e-01, time/batch = 0.6813s	
21286/30300 (epoch 35.125), train_loss = 0.95686891, grad/param norm = 1.6555e-01, time/batch = 0.6832s	
21287/30300 (epoch 35.127), train_loss = 1.11883615, grad/param norm = 2.4963e-01, time/batch = 0.7112s	
21288/30300 (epoch 35.129), train_loss = 1.16579953, grad/param norm = 1.7778e-01, time/batch = 0.6962s	
21289/30300 (epoch 35.130), train_loss = 1.19501645, grad/param norm = 1.6620e-01, time/batch = 0.7183s	
21290/30300 (epoch 35.132), train_loss = 1.18957479, grad/param norm = 1.7941e-01, time/batch = 0.7288s	
21291/30300 (epoch 35.134), train_loss = 0.98862000, grad/param norm = 1.8163e-01, time/batch = 0.7329s	
21292/30300 (epoch 35.135), train_loss = 1.03602706, grad/param norm = 2.2771e-01, time/batch = 0.7306s	
21293/30300 (epoch 35.137), train_loss = 1.06991664, grad/param norm = 1.7612e-01, time/batch = 0.7233s	
21294/30300 (epoch 35.139), train_loss = 1.00974922, grad/param norm = 2.2993e-01, time/batch = 0.7092s	
21295/30300 (epoch 35.140), train_loss = 1.08461057, grad/param norm = 2.1964e-01, time/batch = 0.7383s	
21296/30300 (epoch 35.142), train_loss = 1.15031592, grad/param norm = 1.9501e-01, time/batch = 0.7191s	
21297/30300 (epoch 35.144), train_loss = 1.00802348, grad/param norm = 2.0663e-01, time/batch = 0.7135s	
21298/30300 (epoch 35.145), train_loss = 1.12983243, grad/param norm = 1.9291e-01, time/batch = 0.6935s	
21299/30300 (epoch 35.147), train_loss = 1.03621265, grad/param norm = 1.9545e-01, time/batch = 0.6866s	
21300/30300 (epoch 35.149), train_loss = 1.15750890, grad/param norm = 2.0155e-01, time/batch = 0.7028s	
21301/30300 (epoch 35.150), train_loss = 1.05068508, grad/param norm = 2.2920e-01, time/batch = 0.7040s	
21302/30300 (epoch 35.152), train_loss = 0.97241658, grad/param norm = 1.9225e-01, time/batch = 0.6831s	
21303/30300 (epoch 35.153), train_loss = 1.08104697, grad/param norm = 2.0003e-01, time/batch = 0.6885s	
21304/30300 (epoch 35.155), train_loss = 0.95573720, grad/param norm = 1.7305e-01, time/batch = 0.6838s	
21305/30300 (epoch 35.157), train_loss = 1.02494100, grad/param norm = 1.8883e-01, time/batch = 0.6842s	
21306/30300 (epoch 35.158), train_loss = 1.10798781, grad/param norm = 2.0151e-01, time/batch = 0.6840s	
21307/30300 (epoch 35.160), train_loss = 0.98081155, grad/param norm = 1.7080e-01, time/batch = 0.6891s	
21308/30300 (epoch 35.162), train_loss = 1.06990454, grad/param norm = 1.6431e-01, time/batch = 0.7208s	
21309/30300 (epoch 35.163), train_loss = 1.06209342, grad/param norm = 1.9985e-01, time/batch = 0.7103s	
21310/30300 (epoch 35.165), train_loss = 1.18252586, grad/param norm = 1.8599e-01, time/batch = 0.6892s	
21311/30300 (epoch 35.167), train_loss = 1.09025194, grad/param norm = 2.0716e-01, time/batch = 0.6841s	
21312/30300 (epoch 35.168), train_loss = 1.13044320, grad/param norm = 1.7496e-01, time/batch = 0.6811s	
21313/30300 (epoch 35.170), train_loss = 1.07039831, grad/param norm = 1.7780e-01, time/batch = 0.6812s	
21314/30300 (epoch 35.172), train_loss = 1.08248591, grad/param norm = 2.0961e-01, time/batch = 0.6815s	
21315/30300 (epoch 35.173), train_loss = 1.04831243, grad/param norm = 1.9668e-01, time/batch = 0.6823s	
21316/30300 (epoch 35.175), train_loss = 1.07545205, grad/param norm = 2.0177e-01, time/batch = 0.6863s	
21317/30300 (epoch 35.177), train_loss = 1.11309287, grad/param norm = 1.8690e-01, time/batch = 0.6825s	
21318/30300 (epoch 35.178), train_loss = 0.87542951, grad/param norm = 1.5861e-01, time/batch = 0.6860s	
21319/30300 (epoch 35.180), train_loss = 1.04762845, grad/param norm = 1.6066e-01, time/batch = 0.6849s	
21320/30300 (epoch 35.182), train_loss = 1.08126950, grad/param norm = 1.9565e-01, time/batch = 0.6829s	
21321/30300 (epoch 35.183), train_loss = 1.00544611, grad/param norm = 1.6171e-01, time/batch = 0.6842s	
21322/30300 (epoch 35.185), train_loss = 1.22243633, grad/param norm = 1.8843e-01, time/batch = 0.6829s	
21323/30300 (epoch 35.186), train_loss = 1.26455270, grad/param norm = 2.1878e-01, time/batch = 0.6827s	
21324/30300 (epoch 35.188), train_loss = 1.11004298, grad/param norm = 1.8443e-01, time/batch = 0.6826s	
21325/30300 (epoch 35.190), train_loss = 1.07357333, grad/param norm = 1.6033e-01, time/batch = 0.6836s	
21326/30300 (epoch 35.191), train_loss = 1.13249265, grad/param norm = 1.8582e-01, time/batch = 0.6874s	
21327/30300 (epoch 35.193), train_loss = 0.96825612, grad/param norm = 1.4972e-01, time/batch = 0.6824s	
21328/30300 (epoch 35.195), train_loss = 1.00777312, grad/param norm = 1.5676e-01, time/batch = 0.6818s	
21329/30300 (epoch 35.196), train_loss = 1.09008932, grad/param norm = 1.5085e-01, time/batch = 0.7023s	
21330/30300 (epoch 35.198), train_loss = 0.90853021, grad/param norm = 1.7693e-01, time/batch = 0.6886s	
21331/30300 (epoch 35.200), train_loss = 1.04510201, grad/param norm = 1.7287e-01, time/batch = 0.6870s	
21332/30300 (epoch 35.201), train_loss = 1.14466414, grad/param norm = 3.2967e-01, time/batch = 0.6852s	
21333/30300 (epoch 35.203), train_loss = 1.06527289, grad/param norm = 1.9505e-01, time/batch = 0.6835s	
21334/30300 (epoch 35.205), train_loss = 1.25165238, grad/param norm = 1.8250e-01, time/batch = 0.6845s	
21335/30300 (epoch 35.206), train_loss = 1.13325485, grad/param norm = 1.7758e-01, time/batch = 0.6849s	
21336/30300 (epoch 35.208), train_loss = 1.13690280, grad/param norm = 2.0433e-01, time/batch = 0.6826s	
21337/30300 (epoch 35.210), train_loss = 1.12989291, grad/param norm = 1.7132e-01, time/batch = 0.6827s	
21338/30300 (epoch 35.211), train_loss = 1.19292136, grad/param norm = 1.8983e-01, time/batch = 0.6931s	
21339/30300 (epoch 35.213), train_loss = 1.05281862, grad/param norm = 1.4532e-01, time/batch = 0.7005s	
21340/30300 (epoch 35.215), train_loss = 1.01196074, grad/param norm = 1.9276e-01, time/batch = 0.7121s	
21341/30300 (epoch 35.216), train_loss = 1.02416054, grad/param norm = 1.8162e-01, time/batch = 0.7105s	
21342/30300 (epoch 35.218), train_loss = 0.98557078, grad/param norm = 1.6453e-01, time/batch = 0.6921s	
21343/30300 (epoch 35.219), train_loss = 0.94151298, grad/param norm = 1.5940e-01, time/batch = 0.6803s	
21344/30300 (epoch 35.221), train_loss = 0.92074351, grad/param norm = 1.6160e-01, time/batch = 0.6810s	
21345/30300 (epoch 35.223), train_loss = 1.06061113, grad/param norm = 1.6093e-01, time/batch = 0.6819s	
21346/30300 (epoch 35.224), train_loss = 0.91150540, grad/param norm = 1.7214e-01, time/batch = 0.6792s	
21347/30300 (epoch 35.226), train_loss = 1.11023506, grad/param norm = 1.8376e-01, time/batch = 0.6809s	
21348/30300 (epoch 35.228), train_loss = 1.16707788, grad/param norm = 1.8186e-01, time/batch = 0.6914s	
21349/30300 (epoch 35.229), train_loss = 1.05065401, grad/param norm = 1.6473e-01, time/batch = 0.6892s	
21350/30300 (epoch 35.231), train_loss = 1.11105493, grad/param norm = 1.7706e-01, time/batch = 0.6858s	
21351/30300 (epoch 35.233), train_loss = 1.11762794, grad/param norm = 1.4753e-01, time/batch = 0.6840s	
21352/30300 (epoch 35.234), train_loss = 1.13648253, grad/param norm = 1.8571e-01, time/batch = 0.6828s	
21353/30300 (epoch 35.236), train_loss = 1.10129176, grad/param norm = 1.5112e-01, time/batch = 0.6826s	
21354/30300 (epoch 35.238), train_loss = 1.07320190, grad/param norm = 2.2178e-01, time/batch = 0.6847s	
21355/30300 (epoch 35.239), train_loss = 1.03862557, grad/param norm = 1.8717e-01, time/batch = 0.6904s	
21356/30300 (epoch 35.241), train_loss = 1.12363114, grad/param norm = 1.9098e-01, time/batch = 0.6879s	
21357/30300 (epoch 35.243), train_loss = 1.10456401, grad/param norm = 1.7273e-01, time/batch = 0.6867s	
21358/30300 (epoch 35.244), train_loss = 1.27658984, grad/param norm = 1.7804e-01, time/batch = 0.6866s	
21359/30300 (epoch 35.246), train_loss = 1.09259259, grad/param norm = 1.7660e-01, time/batch = 0.6820s	
21360/30300 (epoch 35.248), train_loss = 1.04307069, grad/param norm = 1.6569e-01, time/batch = 0.6812s	
21361/30300 (epoch 35.249), train_loss = 0.98549804, grad/param norm = 1.8272e-01, time/batch = 0.6827s	
21362/30300 (epoch 35.251), train_loss = 1.00629545, grad/param norm = 1.8076e-01, time/batch = 0.6815s	
21363/30300 (epoch 35.252), train_loss = 1.17771981, grad/param norm = 2.0103e-01, time/batch = 0.6850s	
21364/30300 (epoch 35.254), train_loss = 1.16856077, grad/param norm = 1.8796e-01, time/batch = 0.7001s	
21365/30300 (epoch 35.256), train_loss = 1.09706239, grad/param norm = 1.6211e-01, time/batch = 0.7257s	
21366/30300 (epoch 35.257), train_loss = 1.15220204, grad/param norm = 1.8590e-01, time/batch = 0.6813s	
21367/30300 (epoch 35.259), train_loss = 1.05825981, grad/param norm = 1.8338e-01, time/batch = 0.6826s	
21368/30300 (epoch 35.261), train_loss = 1.20619494, grad/param norm = 1.6891e-01, time/batch = 0.6814s	
21369/30300 (epoch 35.262), train_loss = 1.00572154, grad/param norm = 1.6259e-01, time/batch = 0.6820s	
21370/30300 (epoch 35.264), train_loss = 1.05958044, grad/param norm = 1.6257e-01, time/batch = 0.6820s	
21371/30300 (epoch 35.266), train_loss = 1.04849992, grad/param norm = 1.6335e-01, time/batch = 0.6851s	
21372/30300 (epoch 35.267), train_loss = 1.24577655, grad/param norm = 2.0487e-01, time/batch = 0.6860s	
21373/30300 (epoch 35.269), train_loss = 1.08028856, grad/param norm = 1.6065e-01, time/batch = 0.6847s	
21374/30300 (epoch 35.271), train_loss = 1.10505258, grad/param norm = 1.9747e-01, time/batch = 0.6831s	
21375/30300 (epoch 35.272), train_loss = 1.07534309, grad/param norm = 1.9416e-01, time/batch = 0.6826s	
21376/30300 (epoch 35.274), train_loss = 1.15285273, grad/param norm = 1.8550e-01, time/batch = 0.6833s	
21377/30300 (epoch 35.276), train_loss = 1.11116038, grad/param norm = 1.7783e-01, time/batch = 0.6845s	
21378/30300 (epoch 35.277), train_loss = 0.95293694, grad/param norm = 1.8247e-01, time/batch = 0.6880s	
21379/30300 (epoch 35.279), train_loss = 1.07429217, grad/param norm = 1.6217e-01, time/batch = 0.6852s	
21380/30300 (epoch 35.281), train_loss = 1.17013491, grad/param norm = 2.6247e-01, time/batch = 0.6865s	
21381/30300 (epoch 35.282), train_loss = 1.11029283, grad/param norm = 1.5981e-01, time/batch = 0.6963s	
21382/30300 (epoch 35.284), train_loss = 1.16821797, grad/param norm = 2.3984e-01, time/batch = 0.6972s	
21383/30300 (epoch 35.285), train_loss = 1.11293636, grad/param norm = 1.5278e-01, time/batch = 0.7072s	
21384/30300 (epoch 35.287), train_loss = 1.07134265, grad/param norm = 1.8955e-01, time/batch = 0.7141s	
21385/30300 (epoch 35.289), train_loss = 1.15754471, grad/param norm = 1.7044e-01, time/batch = 0.6894s	
21386/30300 (epoch 35.290), train_loss = 0.85859813, grad/param norm = 1.7321e-01, time/batch = 0.6860s	
21387/30300 (epoch 35.292), train_loss = 0.97412335, grad/param norm = 1.8208e-01, time/batch = 0.6829s	
21388/30300 (epoch 35.294), train_loss = 1.14444275, grad/param norm = 2.0410e-01, time/batch = 0.6851s	
21389/30300 (epoch 35.295), train_loss = 1.02977939, grad/param norm = 1.6196e-01, time/batch = 0.6990s	
21390/30300 (epoch 35.297), train_loss = 1.03652897, grad/param norm = 1.6347e-01, time/batch = 0.6928s	
21391/30300 (epoch 35.299), train_loss = 1.05290292, grad/param norm = 1.6415e-01, time/batch = 0.6913s	
21392/30300 (epoch 35.300), train_loss = 1.00114914, grad/param norm = 1.7440e-01, time/batch = 0.6857s	
21393/30300 (epoch 35.302), train_loss = 1.14448966, grad/param norm = 1.7523e-01, time/batch = 0.6859s	
21394/30300 (epoch 35.304), train_loss = 0.99947241, grad/param norm = 1.7867e-01, time/batch = 0.6884s	
21395/30300 (epoch 35.305), train_loss = 1.04916463, grad/param norm = 1.7064e-01, time/batch = 0.7047s	
21396/30300 (epoch 35.307), train_loss = 1.15819705, grad/param norm = 1.5609e-01, time/batch = 0.6894s	
21397/30300 (epoch 35.309), train_loss = 1.11653040, grad/param norm = 1.8557e-01, time/batch = 0.6835s	
21398/30300 (epoch 35.310), train_loss = 1.05986920, grad/param norm = 1.6582e-01, time/batch = 0.6847s	
21399/30300 (epoch 35.312), train_loss = 1.19298366, grad/param norm = 1.6141e-01, time/batch = 0.6868s	
21400/30300 (epoch 35.314), train_loss = 1.09412771, grad/param norm = 1.8826e-01, time/batch = 0.6835s	
21401/30300 (epoch 35.315), train_loss = 1.04107213, grad/param norm = 1.8774e-01, time/batch = 0.6835s	
21402/30300 (epoch 35.317), train_loss = 1.09032614, grad/param norm = 1.6932e-01, time/batch = 0.7196s	
21403/30300 (epoch 35.318), train_loss = 1.14180322, grad/param norm = 2.2796e-01, time/batch = 0.7053s	
21404/30300 (epoch 35.320), train_loss = 1.10279387, grad/param norm = 1.6438e-01, time/batch = 0.6814s	
21405/30300 (epoch 35.322), train_loss = 1.01610078, grad/param norm = 1.9013e-01, time/batch = 0.6838s	
21406/30300 (epoch 35.323), train_loss = 1.19498164, grad/param norm = 1.9326e-01, time/batch = 0.6836s	
21407/30300 (epoch 35.325), train_loss = 1.07202106, grad/param norm = 1.6685e-01, time/batch = 0.6841s	
21408/30300 (epoch 35.327), train_loss = 1.05082773, grad/param norm = 1.5758e-01, time/batch = 0.6829s	
21409/30300 (epoch 35.328), train_loss = 1.09145382, grad/param norm = 1.6477e-01, time/batch = 0.6852s	
21410/30300 (epoch 35.330), train_loss = 1.11514555, grad/param norm = 1.7047e-01, time/batch = 0.6860s	
21411/30300 (epoch 35.332), train_loss = 1.17836592, grad/param norm = 1.8378e-01, time/batch = 0.6899s	
21412/30300 (epoch 35.333), train_loss = 1.01208787, grad/param norm = 1.6869e-01, time/batch = 0.6843s	
21413/30300 (epoch 35.335), train_loss = 0.97541761, grad/param norm = 1.6151e-01, time/batch = 0.6855s	
21414/30300 (epoch 35.337), train_loss = 1.20008147, grad/param norm = 1.6185e-01, time/batch = 0.6832s	
21415/30300 (epoch 35.338), train_loss = 1.01233045, grad/param norm = 1.5335e-01, time/batch = 0.6832s	
21416/30300 (epoch 35.340), train_loss = 1.01795246, grad/param norm = 1.8124e-01, time/batch = 0.6833s	
21417/30300 (epoch 35.342), train_loss = 1.14818924, grad/param norm = 1.7321e-01, time/batch = 0.6870s	
21418/30300 (epoch 35.343), train_loss = 1.09261276, grad/param norm = 1.8280e-01, time/batch = 0.6894s	
21419/30300 (epoch 35.345), train_loss = 1.12645443, grad/param norm = 1.7407e-01, time/batch = 0.6867s	
21420/30300 (epoch 35.347), train_loss = 0.95169145, grad/param norm = 1.6300e-01, time/batch = 0.6855s	
21421/30300 (epoch 35.348), train_loss = 1.03675918, grad/param norm = 1.6568e-01, time/batch = 0.7280s	
21422/30300 (epoch 35.350), train_loss = 1.04896937, grad/param norm = 1.8434e-01, time/batch = 0.6983s	
21423/30300 (epoch 35.351), train_loss = 1.06253650, grad/param norm = 1.8086e-01, time/batch = 0.6842s	
21424/30300 (epoch 35.353), train_loss = 0.94945662, grad/param norm = 1.6224e-01, time/batch = 0.6827s	
21425/30300 (epoch 35.355), train_loss = 1.02613977, grad/param norm = 1.5988e-01, time/batch = 0.6847s	
21426/30300 (epoch 35.356), train_loss = 1.14737667, grad/param norm = 2.1500e-01, time/batch = 0.6852s	
21427/30300 (epoch 35.358), train_loss = 1.30564104, grad/param norm = 1.6287e-01, time/batch = 0.6867s	
21428/30300 (epoch 35.360), train_loss = 1.02597559, grad/param norm = 1.9122e-01, time/batch = 0.6834s	
21429/30300 (epoch 35.361), train_loss = 1.07475418, grad/param norm = 1.8983e-01, time/batch = 0.7032s	
21430/30300 (epoch 35.363), train_loss = 1.09945867, grad/param norm = 1.7186e-01, time/batch = 0.6957s	
21431/30300 (epoch 35.365), train_loss = 0.96595513, grad/param norm = 2.0608e-01, time/batch = 0.6887s	
21432/30300 (epoch 35.366), train_loss = 1.02373944, grad/param norm = 1.5104e-01, time/batch = 0.6891s	
21433/30300 (epoch 35.368), train_loss = 0.95029655, grad/param norm = 1.5875e-01, time/batch = 0.6853s	
21434/30300 (epoch 35.370), train_loss = 1.00725054, grad/param norm = 1.6192e-01, time/batch = 0.6827s	
21435/30300 (epoch 35.371), train_loss = 1.13014000, grad/param norm = 1.6368e-01, time/batch = 0.6821s	
21436/30300 (epoch 35.373), train_loss = 1.01319342, grad/param norm = 1.4524e-01, time/batch = 0.6817s	
21437/30300 (epoch 35.375), train_loss = 0.98925180, grad/param norm = 1.4580e-01, time/batch = 0.6815s	
21438/30300 (epoch 35.376), train_loss = 0.99095830, grad/param norm = 1.4805e-01, time/batch = 0.6807s	
21439/30300 (epoch 35.378), train_loss = 0.97199138, grad/param norm = 1.6212e-01, time/batch = 0.6814s	
21440/30300 (epoch 35.380), train_loss = 1.18912221, grad/param norm = 1.7187e-01, time/batch = 0.6840s	
21441/30300 (epoch 35.381), train_loss = 0.91518332, grad/param norm = 1.9079e-01, time/batch = 0.6909s	
21442/30300 (epoch 35.383), train_loss = 0.98692029, grad/param norm = 2.2332e-01, time/batch = 0.6855s	
21443/30300 (epoch 35.384), train_loss = 1.12560344, grad/param norm = 1.7950e-01, time/batch = 0.6833s	
21444/30300 (epoch 35.386), train_loss = 0.96461706, grad/param norm = 1.7621e-01, time/batch = 0.7218s	
21445/30300 (epoch 35.388), train_loss = 0.94090095, grad/param norm = 1.6445e-01, time/batch = 0.7030s	
21446/30300 (epoch 35.389), train_loss = 1.05155696, grad/param norm = 1.8483e-01, time/batch = 0.6812s	
21447/30300 (epoch 35.391), train_loss = 1.09216575, grad/param norm = 1.5146e-01, time/batch = 0.6849s	
21448/30300 (epoch 35.393), train_loss = 0.93050150, grad/param norm = 1.7087e-01, time/batch = 0.6834s	
21449/30300 (epoch 35.394), train_loss = 1.11544254, grad/param norm = 1.6398e-01, time/batch = 0.6857s	
21450/30300 (epoch 35.396), train_loss = 1.18771153, grad/param norm = 1.6211e-01, time/batch = 0.6806s	
21451/30300 (epoch 35.398), train_loss = 1.02402636, grad/param norm = 1.6192e-01, time/batch = 0.6836s	
21452/30300 (epoch 35.399), train_loss = 0.99967558, grad/param norm = 1.7396e-01, time/batch = 0.6871s	
21453/30300 (epoch 35.401), train_loss = 1.07508023, grad/param norm = 2.2946e-01, time/batch = 0.6841s	
21454/30300 (epoch 35.403), train_loss = 1.06597992, grad/param norm = 1.7928e-01, time/batch = 0.6829s	
21455/30300 (epoch 35.404), train_loss = 1.01133365, grad/param norm = 2.0078e-01, time/batch = 0.6855s	
21456/30300 (epoch 35.406), train_loss = 1.07632018, grad/param norm = 1.6221e-01, time/batch = 0.6889s	
21457/30300 (epoch 35.408), train_loss = 0.93723896, grad/param norm = 1.4645e-01, time/batch = 0.6821s	
21458/30300 (epoch 35.409), train_loss = 0.94535858, grad/param norm = 1.8960e-01, time/batch = 0.6813s	
21459/30300 (epoch 35.411), train_loss = 0.98140775, grad/param norm = 1.4807e-01, time/batch = 0.6796s	
21460/30300 (epoch 35.413), train_loss = 0.89277979, grad/param norm = 1.6383e-01, time/batch = 0.6804s	
21461/30300 (epoch 35.414), train_loss = 1.11316567, grad/param norm = 1.7323e-01, time/batch = 0.6827s	
21462/30300 (epoch 35.416), train_loss = 1.00347662, grad/param norm = 1.5355e-01, time/batch = 0.6838s	
21463/30300 (epoch 35.417), train_loss = 0.96623393, grad/param norm = 2.0263e-01, time/batch = 0.7260s	
21464/30300 (epoch 35.419), train_loss = 0.96954078, grad/param norm = 1.6125e-01, time/batch = 0.6972s	
21465/30300 (epoch 35.421), train_loss = 1.02444947, grad/param norm = 2.0336e-01, time/batch = 0.6795s	
21466/30300 (epoch 35.422), train_loss = 1.06637871, grad/param norm = 1.6146e-01, time/batch = 0.6793s	
21467/30300 (epoch 35.424), train_loss = 1.08021966, grad/param norm = 1.7630e-01, time/batch = 0.6855s	
21468/30300 (epoch 35.426), train_loss = 1.02202447, grad/param norm = 1.6335e-01, time/batch = 0.6870s	
21469/30300 (epoch 35.427), train_loss = 0.99200843, grad/param norm = 1.6926e-01, time/batch = 0.7011s	
21470/30300 (epoch 35.429), train_loss = 1.04046141, grad/param norm = 1.5575e-01, time/batch = 0.6839s	
21471/30300 (epoch 35.431), train_loss = 1.11392927, grad/param norm = 1.7617e-01, time/batch = 0.7161s	
21472/30300 (epoch 35.432), train_loss = 1.03543159, grad/param norm = 1.5614e-01, time/batch = 0.6874s	
21473/30300 (epoch 35.434), train_loss = 0.95604933, grad/param norm = 1.9000e-01, time/batch = 0.6856s	
21474/30300 (epoch 35.436), train_loss = 1.15100001, grad/param norm = 1.6037e-01, time/batch = 0.6816s	
21475/30300 (epoch 35.437), train_loss = 0.96452821, grad/param norm = 1.7247e-01, time/batch = 0.6806s	
21476/30300 (epoch 35.439), train_loss = 1.00440708, grad/param norm = 1.6749e-01, time/batch = 0.6819s	
21477/30300 (epoch 35.441), train_loss = 1.03902732, grad/param norm = 1.5781e-01, time/batch = 0.7083s	
21478/30300 (epoch 35.442), train_loss = 0.98863050, grad/param norm = 1.5537e-01, time/batch = 0.6906s	
21479/30300 (epoch 35.444), train_loss = 0.88245357, grad/param norm = 1.7336e-01, time/batch = 0.6836s	
21480/30300 (epoch 35.446), train_loss = 1.01985199, grad/param norm = 1.4836e-01, time/batch = 0.6801s	
21481/30300 (epoch 35.447), train_loss = 1.03805070, grad/param norm = 1.5711e-01, time/batch = 0.7009s	
21482/30300 (epoch 35.449), train_loss = 0.98195037, grad/param norm = 1.6020e-01, time/batch = 0.7271s	
21483/30300 (epoch 35.450), train_loss = 1.07216950, grad/param norm = 1.5061e-01, time/batch = 0.6851s	
21484/30300 (epoch 35.452), train_loss = 1.17034364, grad/param norm = 1.7231e-01, time/batch = 0.6844s	
21485/30300 (epoch 35.454), train_loss = 1.10354950, grad/param norm = 1.5726e-01, time/batch = 0.6831s	
21486/30300 (epoch 35.455), train_loss = 1.04850417, grad/param norm = 2.0615e-01, time/batch = 0.6819s	
21487/30300 (epoch 35.457), train_loss = 1.00889933, grad/param norm = 1.6034e-01, time/batch = 0.6814s	
21488/30300 (epoch 35.459), train_loss = 1.10131724, grad/param norm = 1.8155e-01, time/batch = 0.6918s	
21489/30300 (epoch 35.460), train_loss = 1.11761522, grad/param norm = 1.6048e-01, time/batch = 0.6934s	
21490/30300 (epoch 35.462), train_loss = 1.12216250, grad/param norm = 1.7217e-01, time/batch = 0.6952s	
21491/30300 (epoch 35.464), train_loss = 0.88053408, grad/param norm = 1.7695e-01, time/batch = 0.6944s	
21492/30300 (epoch 35.465), train_loss = 0.89467476, grad/param norm = 1.4776e-01, time/batch = 0.6851s	
21493/30300 (epoch 35.467), train_loss = 0.87959439, grad/param norm = 1.4732e-01, time/batch = 0.6839s	
21494/30300 (epoch 35.469), train_loss = 0.97070304, grad/param norm = 1.4793e-01, time/batch = 0.6827s	
21495/30300 (epoch 35.470), train_loss = 1.00166789, grad/param norm = 1.7158e-01, time/batch = 0.6817s	
21496/30300 (epoch 35.472), train_loss = 0.99685434, grad/param norm = 1.4522e-01, time/batch = 0.6820s	
21497/30300 (epoch 35.474), train_loss = 0.98950628, grad/param norm = 1.9753e-01, time/batch = 0.6821s	
21498/30300 (epoch 35.475), train_loss = 0.96716698, grad/param norm = 1.4847e-01, time/batch = 0.6968s	
21499/30300 (epoch 35.477), train_loss = 1.05045493, grad/param norm = 1.7139e-01, time/batch = 0.7041s	
21500/30300 (epoch 35.479), train_loss = 1.01782290, grad/param norm = 1.6837e-01, time/batch = 0.7252s	
21501/30300 (epoch 35.480), train_loss = 1.06751908, grad/param norm = 1.6656e-01, time/batch = 0.7276s	
21502/30300 (epoch 35.482), train_loss = 1.10769021, grad/param norm = 1.5738e-01, time/batch = 0.7093s	
21503/30300 (epoch 35.483), train_loss = 1.01130274, grad/param norm = 1.6916e-01, time/batch = 0.7058s	
21504/30300 (epoch 35.485), train_loss = 1.05523017, grad/param norm = 1.5282e-01, time/batch = 0.7074s	
21505/30300 (epoch 35.487), train_loss = 1.12339460, grad/param norm = 1.7085e-01, time/batch = 0.7030s	
21506/30300 (epoch 35.488), train_loss = 1.17627377, grad/param norm = 1.5418e-01, time/batch = 0.7071s	
21507/30300 (epoch 35.490), train_loss = 0.92583424, grad/param norm = 1.5650e-01, time/batch = 0.7004s	
21508/30300 (epoch 35.492), train_loss = 1.02849782, grad/param norm = 1.6936e-01, time/batch = 0.6879s	
21509/30300 (epoch 35.493), train_loss = 1.03710721, grad/param norm = 1.6494e-01, time/batch = 0.6860s	
21510/30300 (epoch 35.495), train_loss = 1.02683114, grad/param norm = 1.4986e-01, time/batch = 0.6828s	
21511/30300 (epoch 35.497), train_loss = 1.06306734, grad/param norm = 1.5787e-01, time/batch = 0.6891s	
21512/30300 (epoch 35.498), train_loss = 1.10100202, grad/param norm = 1.8237e-01, time/batch = 0.6836s	
21513/30300 (epoch 35.500), train_loss = 1.02148269, grad/param norm = 1.8339e-01, time/batch = 0.6847s	
21514/30300 (epoch 35.502), train_loss = 1.04247299, grad/param norm = 2.1776e-01, time/batch = 0.6845s	
21515/30300 (epoch 35.503), train_loss = 1.13981179, grad/param norm = 1.6536e-01, time/batch = 0.6834s	
21516/30300 (epoch 35.505), train_loss = 0.93635606, grad/param norm = 1.4207e-01, time/batch = 0.6845s	
21517/30300 (epoch 35.507), train_loss = 0.95621013, grad/param norm = 1.7476e-01, time/batch = 0.6851s	
21518/30300 (epoch 35.508), train_loss = 0.98793315, grad/param norm = 1.9442e-01, time/batch = 0.6837s	
21519/30300 (epoch 35.510), train_loss = 1.10085371, grad/param norm = 1.7079e-01, time/batch = 0.7246s	
21520/30300 (epoch 35.512), train_loss = 0.98444244, grad/param norm = 1.5423e-01, time/batch = 0.7006s	
21521/30300 (epoch 35.513), train_loss = 1.05373616, grad/param norm = 1.7270e-01, time/batch = 0.6852s	
21522/30300 (epoch 35.515), train_loss = 1.03307279, grad/param norm = 1.6523e-01, time/batch = 0.6841s	
21523/30300 (epoch 35.517), train_loss = 0.87127906, grad/param norm = 1.4943e-01, time/batch = 0.6838s	
21524/30300 (epoch 35.518), train_loss = 1.12695480, grad/param norm = 1.8977e-01, time/batch = 0.6961s	
21525/30300 (epoch 35.520), train_loss = 1.06465354, grad/param norm = 2.0689e-01, time/batch = 0.6957s	
21526/30300 (epoch 35.521), train_loss = 0.97542295, grad/param norm = 2.0183e-01, time/batch = 0.6849s	
21527/30300 (epoch 35.523), train_loss = 1.18533598, grad/param norm = 2.0524e-01, time/batch = 0.6828s	
21528/30300 (epoch 35.525), train_loss = 0.97575167, grad/param norm = 1.7884e-01, time/batch = 0.6814s	
21529/30300 (epoch 35.526), train_loss = 1.05989411, grad/param norm = 1.5204e-01, time/batch = 0.6831s	
21530/30300 (epoch 35.528), train_loss = 0.93174131, grad/param norm = 1.6013e-01, time/batch = 0.6822s	
21531/30300 (epoch 35.530), train_loss = 0.93191365, grad/param norm = 1.6855e-01, time/batch = 0.6832s	
21532/30300 (epoch 35.531), train_loss = 1.05703932, grad/param norm = 1.6665e-01, time/batch = 0.6864s	
21533/30300 (epoch 35.533), train_loss = 1.02402413, grad/param norm = 1.7723e-01, time/batch = 0.6947s	
21534/30300 (epoch 35.535), train_loss = 1.01203355, grad/param norm = 1.4343e-01, time/batch = 0.6822s	
21535/30300 (epoch 35.536), train_loss = 1.07548157, grad/param norm = 2.1063e-01, time/batch = 0.6857s	
21536/30300 (epoch 35.538), train_loss = 0.92155011, grad/param norm = 1.7673e-01, time/batch = 0.6831s	
21537/30300 (epoch 35.540), train_loss = 0.99882917, grad/param norm = 2.2115e-01, time/batch = 0.6896s	
21538/30300 (epoch 35.541), train_loss = 1.05957343, grad/param norm = 2.1476e-01, time/batch = 0.7264s	
21539/30300 (epoch 35.543), train_loss = 1.01669004, grad/param norm = 1.5207e-01, time/batch = 0.6913s	
21540/30300 (epoch 35.545), train_loss = 1.09572136, grad/param norm = 2.5910e-01, time/batch = 0.6828s	
21541/30300 (epoch 35.546), train_loss = 1.23375334, grad/param norm = 1.6545e-01, time/batch = 0.6844s	
21542/30300 (epoch 35.548), train_loss = 0.97893476, grad/param norm = 1.4903e-01, time/batch = 0.6845s	
21543/30300 (epoch 35.550), train_loss = 1.08862091, grad/param norm = 2.0861e-01, time/batch = 0.6826s	
21544/30300 (epoch 35.551), train_loss = 0.98632663, grad/param norm = 1.7158e-01, time/batch = 0.6815s	
21545/30300 (epoch 35.553), train_loss = 1.01478295, grad/param norm = 1.6033e-01, time/batch = 0.6854s	
21546/30300 (epoch 35.554), train_loss = 1.04855281, grad/param norm = 1.7674e-01, time/batch = 0.6841s	
21547/30300 (epoch 35.556), train_loss = 1.07089940, grad/param norm = 1.6563e-01, time/batch = 0.6832s	
21548/30300 (epoch 35.558), train_loss = 1.11185268, grad/param norm = 1.7181e-01, time/batch = 0.6843s	
21549/30300 (epoch 35.559), train_loss = 1.04886063, grad/param norm = 1.7965e-01, time/batch = 0.6910s	
21550/30300 (epoch 35.561), train_loss = 0.85186329, grad/param norm = 1.5023e-01, time/batch = 0.6941s	
21551/30300 (epoch 35.563), train_loss = 0.92766302, grad/param norm = 1.4702e-01, time/batch = 0.6905s	
21552/30300 (epoch 35.564), train_loss = 0.98062917, grad/param norm = 1.4740e-01, time/batch = 0.6852s	
21553/30300 (epoch 35.566), train_loss = 1.01044394, grad/param norm = 1.6567e-01, time/batch = 0.6847s	
21554/30300 (epoch 35.568), train_loss = 0.87216614, grad/param norm = 1.7557e-01, time/batch = 0.6935s	
21555/30300 (epoch 35.569), train_loss = 1.06684977, grad/param norm = 1.7132e-01, time/batch = 0.6984s	
21556/30300 (epoch 35.571), train_loss = 1.03733640, grad/param norm = 1.6581e-01, time/batch = 0.6950s	
21557/30300 (epoch 35.573), train_loss = 1.08594498, grad/param norm = 1.7265e-01, time/batch = 0.7373s	
21558/30300 (epoch 35.574), train_loss = 1.06712065, grad/param norm = 1.5648e-01, time/batch = 0.7215s	
21559/30300 (epoch 35.576), train_loss = 0.98757948, grad/param norm = 1.4688e-01, time/batch = 0.7004s	
21560/30300 (epoch 35.578), train_loss = 0.91928368, grad/param norm = 1.5369e-01, time/batch = 0.7020s	
21561/30300 (epoch 35.579), train_loss = 1.07884530, grad/param norm = 1.6829e-01, time/batch = 0.6910s	
21562/30300 (epoch 35.581), train_loss = 1.15220462, grad/param norm = 1.6009e-01, time/batch = 0.6922s	
21563/30300 (epoch 35.583), train_loss = 1.18523614, grad/param norm = 1.8638e-01, time/batch = 0.6938s	
21564/30300 (epoch 35.584), train_loss = 1.14080828, grad/param norm = 1.6454e-01, time/batch = 0.6922s	
21565/30300 (epoch 35.586), train_loss = 1.00574891, grad/param norm = 1.7468e-01, time/batch = 0.6914s	
21566/30300 (epoch 35.587), train_loss = 1.02746930, grad/param norm = 1.6566e-01, time/batch = 0.7289s	
21567/30300 (epoch 35.589), train_loss = 0.97453457, grad/param norm = 1.6185e-01, time/batch = 0.6969s	
21568/30300 (epoch 35.591), train_loss = 1.05173444, grad/param norm = 1.4908e-01, time/batch = 0.6976s	
21569/30300 (epoch 35.592), train_loss = 1.00492767, grad/param norm = 1.5192e-01, time/batch = 0.6966s	
21570/30300 (epoch 35.594), train_loss = 1.07113124, grad/param norm = 1.5960e-01, time/batch = 0.6974s	
21571/30300 (epoch 35.596), train_loss = 0.94829582, grad/param norm = 1.4974e-01, time/batch = 0.6993s	
21572/30300 (epoch 35.597), train_loss = 0.97631514, grad/param norm = 1.6394e-01, time/batch = 0.7016s	
21573/30300 (epoch 35.599), train_loss = 0.87755240, grad/param norm = 1.4483e-01, time/batch = 0.7038s	
21574/30300 (epoch 35.601), train_loss = 1.07004661, grad/param norm = 1.7514e-01, time/batch = 0.6882s	
21575/30300 (epoch 35.602), train_loss = 1.01614273, grad/param norm = 1.5688e-01, time/batch = 0.7264s	
21576/30300 (epoch 35.604), train_loss = 0.96400112, grad/param norm = 1.5336e-01, time/batch = 0.7035s	
21577/30300 (epoch 35.606), train_loss = 0.97078255, grad/param norm = 2.3590e-01, time/batch = 0.6847s	
21578/30300 (epoch 35.607), train_loss = 1.08873943, grad/param norm = 1.9038e-01, time/batch = 0.6850s	
21579/30300 (epoch 35.609), train_loss = 1.19659673, grad/param norm = 1.7859e-01, time/batch = 0.6902s	
21580/30300 (epoch 35.611), train_loss = 0.98830221, grad/param norm = 1.7880e-01, time/batch = 0.6916s	
21581/30300 (epoch 35.612), train_loss = 0.94000935, grad/param norm = 1.5017e-01, time/batch = 0.6907s	
21582/30300 (epoch 35.614), train_loss = 1.00605218, grad/param norm = 1.5182e-01, time/batch = 0.6851s	
21583/30300 (epoch 35.616), train_loss = 1.06181488, grad/param norm = 2.0259e-01, time/batch = 0.6871s	
21584/30300 (epoch 35.617), train_loss = 1.07667607, grad/param norm = 2.0126e-01, time/batch = 0.6908s	
21585/30300 (epoch 35.619), train_loss = 0.85675742, grad/param norm = 1.4361e-01, time/batch = 0.7035s	
21586/30300 (epoch 35.620), train_loss = 1.09602762, grad/param norm = 1.6239e-01, time/batch = 0.6844s	
21587/30300 (epoch 35.622), train_loss = 1.04045378, grad/param norm = 1.9174e-01, time/batch = 0.6812s	
21588/30300 (epoch 35.624), train_loss = 1.02323756, grad/param norm = 1.6190e-01, time/batch = 0.6828s	
21589/30300 (epoch 35.625), train_loss = 1.02332402, grad/param norm = 1.9416e-01, time/batch = 0.6823s	
21590/30300 (epoch 35.627), train_loss = 1.12130361, grad/param norm = 1.7119e-01, time/batch = 0.6824s	
21591/30300 (epoch 35.629), train_loss = 1.16892545, grad/param norm = 1.5943e-01, time/batch = 0.6862s	
21592/30300 (epoch 35.630), train_loss = 1.05372424, grad/param norm = 1.7109e-01, time/batch = 0.6894s	
21593/30300 (epoch 35.632), train_loss = 1.09111745, grad/param norm = 1.7946e-01, time/batch = 0.6966s	
21594/30300 (epoch 35.634), train_loss = 0.96399098, grad/param norm = 1.4814e-01, time/batch = 0.7261s	
21595/30300 (epoch 35.635), train_loss = 1.09987665, grad/param norm = 1.9569e-01, time/batch = 0.6924s	
21596/30300 (epoch 35.637), train_loss = 1.12509612, grad/param norm = 1.9918e-01, time/batch = 0.6841s	
21597/30300 (epoch 35.639), train_loss = 1.03027270, grad/param norm = 1.7876e-01, time/batch = 0.6825s	
21598/30300 (epoch 35.640), train_loss = 1.12791192, grad/param norm = 1.9067e-01, time/batch = 0.6821s	
21599/30300 (epoch 35.642), train_loss = 1.01828611, grad/param norm = 1.4668e-01, time/batch = 0.6858s	
21600/30300 (epoch 35.644), train_loss = 1.11249104, grad/param norm = 1.7343e-01, time/batch = 0.6840s	
21601/30300 (epoch 35.645), train_loss = 0.97833521, grad/param norm = 1.4921e-01, time/batch = 0.6827s	
21602/30300 (epoch 35.647), train_loss = 1.06064348, grad/param norm = 1.5645e-01, time/batch = 0.6824s	
21603/30300 (epoch 35.649), train_loss = 1.02026018, grad/param norm = 2.7788e-01, time/batch = 0.6832s	
21604/30300 (epoch 35.650), train_loss = 1.02467698, grad/param norm = 1.6197e-01, time/batch = 0.6835s	
21605/30300 (epoch 35.652), train_loss = 1.01130317, grad/param norm = 1.7677e-01, time/batch = 0.6892s	
21606/30300 (epoch 35.653), train_loss = 1.19303889, grad/param norm = 1.5124e-01, time/batch = 0.6891s	
21607/30300 (epoch 35.655), train_loss = 1.02628048, grad/param norm = 2.0256e-01, time/batch = 0.6848s	
21608/30300 (epoch 35.657), train_loss = 0.95689466, grad/param norm = 1.7502e-01, time/batch = 0.6819s	
21609/30300 (epoch 35.658), train_loss = 0.99660657, grad/param norm = 1.6523e-01, time/batch = 0.6832s	
21610/30300 (epoch 35.660), train_loss = 1.05486927, grad/param norm = 1.6562e-01, time/batch = 0.6819s	
21611/30300 (epoch 35.662), train_loss = 1.07389680, grad/param norm = 2.0917e-01, time/batch = 0.6864s	
21612/30300 (epoch 35.663), train_loss = 1.10274542, grad/param norm = 1.6835e-01, time/batch = 0.7037s	
21613/30300 (epoch 35.665), train_loss = 1.00608506, grad/param norm = 1.7823e-01, time/batch = 0.7239s	
21614/30300 (epoch 35.667), train_loss = 1.09901337, grad/param norm = 1.7211e-01, time/batch = 0.6835s	
21615/30300 (epoch 35.668), train_loss = 1.13132118, grad/param norm = 1.7690e-01, time/batch = 0.6832s	
21616/30300 (epoch 35.670), train_loss = 1.15851943, grad/param norm = 1.8491e-01, time/batch = 0.6828s	
21617/30300 (epoch 35.672), train_loss = 1.05446749, grad/param norm = 1.8127e-01, time/batch = 0.6811s	
21618/30300 (epoch 35.673), train_loss = 1.10002683, grad/param norm = 2.0809e-01, time/batch = 0.6815s	
21619/30300 (epoch 35.675), train_loss = 0.99859534, grad/param norm = 1.7279e-01, time/batch = 0.6836s	
21620/30300 (epoch 35.677), train_loss = 0.98356596, grad/param norm = 1.3789e-01, time/batch = 0.6806s	
21621/30300 (epoch 35.678), train_loss = 0.99050692, grad/param norm = 1.4857e-01, time/batch = 0.6844s	
21622/30300 (epoch 35.680), train_loss = 0.92671323, grad/param norm = 1.7332e-01, time/batch = 0.6840s	
21623/30300 (epoch 35.682), train_loss = 1.01840461, grad/param norm = 1.7037e-01, time/batch = 0.6813s	
21624/30300 (epoch 35.683), train_loss = 1.14029668, grad/param norm = 1.6061e-01, time/batch = 0.6864s	
21625/30300 (epoch 35.685), train_loss = 1.08802625, grad/param norm = 1.8102e-01, time/batch = 0.6802s	
21626/30300 (epoch 35.686), train_loss = 1.00604503, grad/param norm = 1.5147e-01, time/batch = 0.6794s	
21627/30300 (epoch 35.688), train_loss = 1.02898267, grad/param norm = 1.5044e-01, time/batch = 0.6795s	
21628/30300 (epoch 35.690), train_loss = 0.97407672, grad/param norm = 1.6392e-01, time/batch = 0.6812s	
21629/30300 (epoch 35.691), train_loss = 1.05342520, grad/param norm = 1.6211e-01, time/batch = 0.6816s	
21630/30300 (epoch 35.693), train_loss = 1.33012646, grad/param norm = 1.9794e-01, time/batch = 0.6822s	
21631/30300 (epoch 35.695), train_loss = 1.11284551, grad/param norm = 1.8696e-01, time/batch = 0.7103s	
21632/30300 (epoch 35.696), train_loss = 1.12349282, grad/param norm = 2.2125e-01, time/batch = 0.7196s	
21633/30300 (epoch 35.698), train_loss = 0.99251259, grad/param norm = 1.7767e-01, time/batch = 0.6881s	
21634/30300 (epoch 35.700), train_loss = 0.98122617, grad/param norm = 1.6974e-01, time/batch = 0.6824s	
21635/30300 (epoch 35.701), train_loss = 0.91147601, grad/param norm = 1.5892e-01, time/batch = 0.6830s	
21636/30300 (epoch 35.703), train_loss = 1.05410644, grad/param norm = 1.6271e-01, time/batch = 0.6802s	
21637/30300 (epoch 35.705), train_loss = 0.95923566, grad/param norm = 1.5624e-01, time/batch = 0.6824s	
21638/30300 (epoch 35.706), train_loss = 1.10230481, grad/param norm = 1.9729e-01, time/batch = 0.6862s	
21639/30300 (epoch 35.708), train_loss = 1.04938038, grad/param norm = 1.6674e-01, time/batch = 0.6867s	
21640/30300 (epoch 35.710), train_loss = 1.00553056, grad/param norm = 1.5707e-01, time/batch = 0.6851s	
21641/30300 (epoch 35.711), train_loss = 0.99277058, grad/param norm = 1.9151e-01, time/batch = 0.6953s	
21642/30300 (epoch 35.713), train_loss = 0.97676299, grad/param norm = 1.6261e-01, time/batch = 0.7094s	
21643/30300 (epoch 35.715), train_loss = 0.98860026, grad/param norm = 1.6630e-01, time/batch = 0.7136s	
21644/30300 (epoch 35.716), train_loss = 1.11156876, grad/param norm = 1.6804e-01, time/batch = 0.7195s	
21645/30300 (epoch 35.718), train_loss = 1.13619751, grad/param norm = 1.7046e-01, time/batch = 0.7124s	
21646/30300 (epoch 35.719), train_loss = 0.99115652, grad/param norm = 1.7856e-01, time/batch = 0.7077s	
21647/30300 (epoch 35.721), train_loss = 1.03375929, grad/param norm = 1.8867e-01, time/batch = 0.7104s	
21648/30300 (epoch 35.723), train_loss = 0.96968659, grad/param norm = 1.6601e-01, time/batch = 0.6842s	
21649/30300 (epoch 35.724), train_loss = 1.08642278, grad/param norm = 2.0406e-01, time/batch = 0.6819s	
21650/30300 (epoch 35.726), train_loss = 1.31383561, grad/param norm = 2.2637e-01, time/batch = 0.7246s	
21651/30300 (epoch 35.728), train_loss = 1.07608401, grad/param norm = 1.7056e-01, time/batch = 0.7027s	
21652/30300 (epoch 35.729), train_loss = 1.00355373, grad/param norm = 1.7546e-01, time/batch = 0.6846s	
21653/30300 (epoch 35.731), train_loss = 1.02961176, grad/param norm = 1.8242e-01, time/batch = 0.6879s	
21654/30300 (epoch 35.733), train_loss = 1.05555171, grad/param norm = 1.8127e-01, time/batch = 0.6839s	
21655/30300 (epoch 35.734), train_loss = 1.13731157, grad/param norm = 1.5963e-01, time/batch = 0.6804s	
21656/30300 (epoch 35.736), train_loss = 1.05793739, grad/param norm = 1.7090e-01, time/batch = 0.6805s	
21657/30300 (epoch 35.738), train_loss = 0.97742843, grad/param norm = 1.4101e-01, time/batch = 0.6840s	
21658/30300 (epoch 35.739), train_loss = 1.13763352, grad/param norm = 1.7619e-01, time/batch = 0.6880s	
21659/30300 (epoch 35.741), train_loss = 1.18225172, grad/param norm = 1.5708e-01, time/batch = 0.6809s	
21660/30300 (epoch 35.743), train_loss = 1.01477119, grad/param norm = 1.6276e-01, time/batch = 0.6807s	
21661/30300 (epoch 35.744), train_loss = 1.07821454, grad/param norm = 1.7256e-01, time/batch = 0.6871s	
21662/30300 (epoch 35.746), train_loss = 1.00158713, grad/param norm = 1.5092e-01, time/batch = 0.6953s	
21663/30300 (epoch 35.748), train_loss = 1.03025604, grad/param norm = 1.7888e-01, time/batch = 0.6810s	
21664/30300 (epoch 35.749), train_loss = 1.05141332, grad/param norm = 1.5957e-01, time/batch = 0.6807s	
21665/30300 (epoch 35.751), train_loss = 1.06606583, grad/param norm = 1.5893e-01, time/batch = 0.6808s	
21666/30300 (epoch 35.752), train_loss = 1.03410856, grad/param norm = 1.8297e-01, time/batch = 0.6809s	
21667/30300 (epoch 35.754), train_loss = 1.01757445, grad/param norm = 1.6013e-01, time/batch = 0.6822s	
21668/30300 (epoch 35.756), train_loss = 1.01418974, grad/param norm = 1.6104e-01, time/batch = 0.6987s	
21669/30300 (epoch 35.757), train_loss = 0.98500083, grad/param norm = 1.6592e-01, time/batch = 0.7296s	
21670/30300 (epoch 35.759), train_loss = 1.07575706, grad/param norm = 1.5278e-01, time/batch = 0.6917s	
21671/30300 (epoch 35.761), train_loss = 0.91552595, grad/param norm = 1.5524e-01, time/batch = 0.6827s	
21672/30300 (epoch 35.762), train_loss = 0.93533382, grad/param norm = 1.5443e-01, time/batch = 0.6810s	
21673/30300 (epoch 35.764), train_loss = 1.01219800, grad/param norm = 1.6946e-01, time/batch = 0.6947s	
21674/30300 (epoch 35.766), train_loss = 1.16636381, grad/param norm = 1.8349e-01, time/batch = 0.6904s	
21675/30300 (epoch 35.767), train_loss = 1.08460071, grad/param norm = 1.9293e-01, time/batch = 0.6886s	
21676/30300 (epoch 35.769), train_loss = 1.06521049, grad/param norm = 1.9382e-01, time/batch = 0.7058s	
21677/30300 (epoch 35.771), train_loss = 0.99780769, grad/param norm = 1.9356e-01, time/batch = 0.7191s	
21678/30300 (epoch 35.772), train_loss = 1.05743133, grad/param norm = 1.6795e-01, time/batch = 0.7074s	
21679/30300 (epoch 35.774), train_loss = 1.18564739, grad/param norm = 1.6590e-01, time/batch = 0.6941s	
21680/30300 (epoch 35.776), train_loss = 1.00224922, grad/param norm = 1.7302e-01, time/batch = 0.6792s	
21681/30300 (epoch 35.777), train_loss = 1.16233305, grad/param norm = 1.6205e-01, time/batch = 0.6831s	
21682/30300 (epoch 35.779), train_loss = 1.16436995, grad/param norm = 1.8813e-01, time/batch = 0.6809s	
21683/30300 (epoch 35.781), train_loss = 1.06417905, grad/param norm = 1.7881e-01, time/batch = 0.6815s	
21684/30300 (epoch 35.782), train_loss = 0.98328245, grad/param norm = 1.8497e-01, time/batch = 0.6830s	
21685/30300 (epoch 35.784), train_loss = 0.98283812, grad/param norm = 1.5415e-01, time/batch = 0.6801s	
21686/30300 (epoch 35.785), train_loss = 1.11944180, grad/param norm = 1.8375e-01, time/batch = 0.6829s	
21687/30300 (epoch 35.787), train_loss = 0.89442769, grad/param norm = 1.9090e-01, time/batch = 0.7019s	
21688/30300 (epoch 35.789), train_loss = 1.20527298, grad/param norm = 1.8113e-01, time/batch = 0.7235s	
21689/30300 (epoch 35.790), train_loss = 1.05028094, grad/param norm = 1.6741e-01, time/batch = 0.6796s	
21690/30300 (epoch 35.792), train_loss = 0.85101557, grad/param norm = 1.6157e-01, time/batch = 0.6797s	
21691/30300 (epoch 35.794), train_loss = 1.03032364, grad/param norm = 1.8722e-01, time/batch = 0.6811s	
21692/30300 (epoch 35.795), train_loss = 0.97678335, grad/param norm = 1.6451e-01, time/batch = 0.6821s	
21693/30300 (epoch 35.797), train_loss = 1.15947351, grad/param norm = 1.7550e-01, time/batch = 0.6818s	
21694/30300 (epoch 35.799), train_loss = 1.12934846, grad/param norm = 2.1724e-01, time/batch = 0.6806s	
21695/30300 (epoch 35.800), train_loss = 1.11802087, grad/param norm = 1.7374e-01, time/batch = 0.6816s	
21696/30300 (epoch 35.802), train_loss = 1.29264308, grad/param norm = 2.0360e-01, time/batch = 0.6816s	
21697/30300 (epoch 35.804), train_loss = 1.11350008, grad/param norm = 1.7927e-01, time/batch = 0.6818s	
21698/30300 (epoch 35.805), train_loss = 1.19259491, grad/param norm = 1.8896e-01, time/batch = 0.6846s	
21699/30300 (epoch 35.807), train_loss = 1.01856155, grad/param norm = 1.8915e-01, time/batch = 0.6839s	
21700/30300 (epoch 35.809), train_loss = 1.10940149, grad/param norm = 1.7588e-01, time/batch = 0.6821s	
21701/30300 (epoch 35.810), train_loss = 1.09151394, grad/param norm = 1.8060e-01, time/batch = 0.6844s	
21702/30300 (epoch 35.812), train_loss = 0.98842845, grad/param norm = 1.5853e-01, time/batch = 0.6894s	
21703/30300 (epoch 35.814), train_loss = 1.05181724, grad/param norm = 1.6700e-01, time/batch = 0.6890s	
21704/30300 (epoch 35.815), train_loss = 1.05582492, grad/param norm = 2.1455e-01, time/batch = 0.6848s	
21705/30300 (epoch 35.817), train_loss = 1.13470438, grad/param norm = 1.9283e-01, time/batch = 0.6858s	
21706/30300 (epoch 35.818), train_loss = 1.07161622, grad/param norm = 1.5989e-01, time/batch = 0.6995s	
21707/30300 (epoch 35.820), train_loss = 1.22025821, grad/param norm = 1.9784e-01, time/batch = 0.6902s	
21708/30300 (epoch 35.822), train_loss = 1.19563705, grad/param norm = 1.9529e-01, time/batch = 0.6895s	
21709/30300 (epoch 35.823), train_loss = 1.19900784, grad/param norm = 1.9901e-01, time/batch = 0.6848s	
21710/30300 (epoch 35.825), train_loss = 1.18020577, grad/param norm = 1.6879e-01, time/batch = 0.6826s	
21711/30300 (epoch 35.827), train_loss = 0.91362420, grad/param norm = 1.9026e-01, time/batch = 0.6849s	
21712/30300 (epoch 35.828), train_loss = 1.14059839, grad/param norm = 2.4248e-01, time/batch = 0.6829s	
21713/30300 (epoch 35.830), train_loss = 1.09978362, grad/param norm = 1.7686e-01, time/batch = 0.6837s	
21714/30300 (epoch 35.832), train_loss = 0.98792696, grad/param norm = 1.6765e-01, time/batch = 0.6872s	
21715/30300 (epoch 35.833), train_loss = 1.07304836, grad/param norm = 1.8374e-01, time/batch = 0.6843s	
21716/30300 (epoch 35.835), train_loss = 0.98058143, grad/param norm = 1.6435e-01, time/batch = 0.6819s	
21717/30300 (epoch 35.837), train_loss = 0.94831009, grad/param norm = 1.5441e-01, time/batch = 0.6830s	
21718/30300 (epoch 35.838), train_loss = 0.95436661, grad/param norm = 1.6365e-01, time/batch = 0.6840s	
21719/30300 (epoch 35.840), train_loss = 1.14867319, grad/param norm = 1.5658e-01, time/batch = 0.6819s	
21720/30300 (epoch 35.842), train_loss = 1.01687816, grad/param norm = 1.5290e-01, time/batch = 0.6829s	
21721/30300 (epoch 35.843), train_loss = 1.08750201, grad/param norm = 1.7739e-01, time/batch = 0.6845s	
21722/30300 (epoch 35.845), train_loss = 1.10013611, grad/param norm = 1.5518e-01, time/batch = 0.6823s	
21723/30300 (epoch 35.847), train_loss = 1.06687199, grad/param norm = 1.7324e-01, time/batch = 0.6835s	
21724/30300 (epoch 35.848), train_loss = 1.09445083, grad/param norm = 1.8872e-01, time/batch = 0.6814s	
21725/30300 (epoch 35.850), train_loss = 1.04726795, grad/param norm = 1.8078e-01, time/batch = 0.6820s	
21726/30300 (epoch 35.851), train_loss = 1.10726629, grad/param norm = 2.3053e-01, time/batch = 0.6818s	
21727/30300 (epoch 35.853), train_loss = 1.02391390, grad/param norm = 1.7770e-01, time/batch = 0.6938s	
21728/30300 (epoch 35.855), train_loss = 1.02616625, grad/param norm = 1.6735e-01, time/batch = 0.7007s	
21729/30300 (epoch 35.856), train_loss = 1.05259896, grad/param norm = 1.6608e-01, time/batch = 0.7039s	
21730/30300 (epoch 35.858), train_loss = 0.97169686, grad/param norm = 1.5167e-01, time/batch = 0.7079s	
21731/30300 (epoch 35.860), train_loss = 0.95813551, grad/param norm = 1.5338e-01, time/batch = 0.6948s	
21732/30300 (epoch 35.861), train_loss = 1.20670116, grad/param norm = 1.6891e-01, time/batch = 0.6870s	
21733/30300 (epoch 35.863), train_loss = 1.02759289, grad/param norm = 1.6360e-01, time/batch = 0.6836s	
21734/30300 (epoch 35.865), train_loss = 1.10760717, grad/param norm = 1.8674e-01, time/batch = 0.6832s	
21735/30300 (epoch 35.866), train_loss = 1.11398892, grad/param norm = 1.8126e-01, time/batch = 0.6839s	
21736/30300 (epoch 35.868), train_loss = 1.07414598, grad/param norm = 1.6215e-01, time/batch = 0.6888s	
21737/30300 (epoch 35.870), train_loss = 0.97937099, grad/param norm = 1.6849e-01, time/batch = 0.6845s	
21738/30300 (epoch 35.871), train_loss = 1.06538921, grad/param norm = 1.7033e-01, time/batch = 0.6869s	
21739/30300 (epoch 35.873), train_loss = 1.05683674, grad/param norm = 1.7021e-01, time/batch = 0.6831s	
21740/30300 (epoch 35.875), train_loss = 1.03335653, grad/param norm = 1.5225e-01, time/batch = 0.6828s	
21741/30300 (epoch 35.876), train_loss = 0.92868842, grad/param norm = 1.6165e-01, time/batch = 0.6839s	
21742/30300 (epoch 35.878), train_loss = 0.89213326, grad/param norm = 1.5816e-01, time/batch = 0.6999s	
21743/30300 (epoch 35.880), train_loss = 0.97649447, grad/param norm = 1.5743e-01, time/batch = 0.6917s	
21744/30300 (epoch 35.881), train_loss = 1.21588813, grad/param norm = 2.5391e-01, time/batch = 0.6818s	
21745/30300 (epoch 35.883), train_loss = 1.13549176, grad/param norm = 1.8452e-01, time/batch = 0.6826s	
21746/30300 (epoch 35.884), train_loss = 1.04046581, grad/param norm = 1.6188e-01, time/batch = 0.6799s	
21747/30300 (epoch 35.886), train_loss = 1.10077547, grad/param norm = 1.6386e-01, time/batch = 0.6791s	
21748/30300 (epoch 35.888), train_loss = 1.01951373, grad/param norm = 1.8399e-01, time/batch = 0.7060s	
21749/30300 (epoch 35.889), train_loss = 1.06074963, grad/param norm = 1.6258e-01, time/batch = 0.7176s	
21750/30300 (epoch 35.891), train_loss = 1.03963711, grad/param norm = 1.7067e-01, time/batch = 0.6835s	
21751/30300 (epoch 35.893), train_loss = 1.24468571, grad/param norm = 1.6920e-01, time/batch = 0.6819s	
21752/30300 (epoch 35.894), train_loss = 1.08407873, grad/param norm = 1.7044e-01, time/batch = 0.6814s	
21753/30300 (epoch 35.896), train_loss = 0.90444622, grad/param norm = 1.5775e-01, time/batch = 0.6789s	
21754/30300 (epoch 35.898), train_loss = 0.91703484, grad/param norm = 1.5925e-01, time/batch = 0.6790s	
21755/30300 (epoch 35.899), train_loss = 0.95318051, grad/param norm = 1.6417e-01, time/batch = 0.6797s	
21756/30300 (epoch 35.901), train_loss = 1.06518847, grad/param norm = 2.0825e-01, time/batch = 0.6791s	
21757/30300 (epoch 35.903), train_loss = 1.05161851, grad/param norm = 2.2350e-01, time/batch = 0.6788s	
21758/30300 (epoch 35.904), train_loss = 1.07431275, grad/param norm = 1.5756e-01, time/batch = 0.6800s	
21759/30300 (epoch 35.906), train_loss = 1.07892231, grad/param norm = 1.9728e-01, time/batch = 0.6815s	
21760/30300 (epoch 35.908), train_loss = 0.98149180, grad/param norm = 1.6255e-01, time/batch = 0.6851s	
21761/30300 (epoch 35.909), train_loss = 0.99061708, grad/param norm = 2.1177e-01, time/batch = 0.6965s	
21762/30300 (epoch 35.911), train_loss = 1.04528511, grad/param norm = 1.5583e-01, time/batch = 0.6881s	
21763/30300 (epoch 35.913), train_loss = 1.05142281, grad/param norm = 1.5211e-01, time/batch = 0.7260s	
21764/30300 (epoch 35.914), train_loss = 1.03444838, grad/param norm = 1.8577e-01, time/batch = 0.6932s	
21765/30300 (epoch 35.916), train_loss = 1.07518657, grad/param norm = 1.5155e-01, time/batch = 0.6818s	
21766/30300 (epoch 35.917), train_loss = 1.01016411, grad/param norm = 1.5507e-01, time/batch = 0.6811s	
21767/30300 (epoch 35.919), train_loss = 0.95692887, grad/param norm = 1.6359e-01, time/batch = 0.6826s	
21768/30300 (epoch 35.921), train_loss = 1.02249089, grad/param norm = 1.4861e-01, time/batch = 0.6838s	
21769/30300 (epoch 35.922), train_loss = 1.14194305, grad/param norm = 1.9404e-01, time/batch = 0.6834s	
21770/30300 (epoch 35.924), train_loss = 1.04508465, grad/param norm = 1.8568e-01, time/batch = 0.6813s	
21771/30300 (epoch 35.926), train_loss = 1.09291020, grad/param norm = 1.7280e-01, time/batch = 0.6840s	
21772/30300 (epoch 35.927), train_loss = 1.08420282, grad/param norm = 1.7734e-01, time/batch = 0.6902s	
21773/30300 (epoch 35.929), train_loss = 0.97411319, grad/param norm = 1.7536e-01, time/batch = 0.6914s	
21774/30300 (epoch 35.931), train_loss = 1.13386644, grad/param norm = 1.9287e-01, time/batch = 0.7013s	
21775/30300 (epoch 35.932), train_loss = 0.97193898, grad/param norm = 1.6588e-01, time/batch = 0.6915s	
21776/30300 (epoch 35.934), train_loss = 1.08969112, grad/param norm = 1.6557e-01, time/batch = 0.6998s	
21777/30300 (epoch 35.936), train_loss = 0.98139262, grad/param norm = 1.6721e-01, time/batch = 0.6927s	
21778/30300 (epoch 35.937), train_loss = 0.99849773, grad/param norm = 1.8288e-01, time/batch = 0.6913s	
21779/30300 (epoch 35.939), train_loss = 1.16670002, grad/param norm = 1.7931e-01, time/batch = 0.6876s	
21780/30300 (epoch 35.941), train_loss = 1.02997277, grad/param norm = 1.6933e-01, time/batch = 0.6902s	
21781/30300 (epoch 35.942), train_loss = 1.05392169, grad/param norm = 2.6485e-01, time/batch = 0.7058s	
21782/30300 (epoch 35.944), train_loss = 0.95050571, grad/param norm = 1.6514e-01, time/batch = 0.7289s	
21783/30300 (epoch 35.946), train_loss = 1.12310897, grad/param norm = 2.2417e-01, time/batch = 0.6916s	
21784/30300 (epoch 35.947), train_loss = 1.09505207, grad/param norm = 1.9189e-01, time/batch = 0.6967s	
21785/30300 (epoch 35.949), train_loss = 1.11194799, grad/param norm = 2.2886e-01, time/batch = 0.6859s	
21786/30300 (epoch 35.950), train_loss = 1.15097294, grad/param norm = 1.7733e-01, time/batch = 0.6833s	
21787/30300 (epoch 35.952), train_loss = 1.10200308, grad/param norm = 2.4035e-01, time/batch = 0.6898s	
21788/30300 (epoch 35.954), train_loss = 1.31121140, grad/param norm = 1.9061e-01, time/batch = 0.6866s	
21789/30300 (epoch 35.955), train_loss = 1.02225552, grad/param norm = 1.5760e-01, time/batch = 0.6881s	
21790/30300 (epoch 35.957), train_loss = 1.10890573, grad/param norm = 1.6698e-01, time/batch = 0.6910s	
21791/30300 (epoch 35.959), train_loss = 0.97036406, grad/param norm = 1.9097e-01, time/batch = 0.6914s	
21792/30300 (epoch 35.960), train_loss = 1.00156069, grad/param norm = 1.7976e-01, time/batch = 0.6838s	
21793/30300 (epoch 35.962), train_loss = 0.99039624, grad/param norm = 2.1149e-01, time/batch = 0.6851s	
21794/30300 (epoch 35.964), train_loss = 0.97057014, grad/param norm = 2.3957e-01, time/batch = 0.6832s	
21795/30300 (epoch 35.965), train_loss = 0.99247102, grad/param norm = 2.0392e-01, time/batch = 0.6833s	
21796/30300 (epoch 35.967), train_loss = 1.03505951, grad/param norm = 2.0145e-01, time/batch = 0.7250s	
21797/30300 (epoch 35.969), train_loss = 0.97495218, grad/param norm = 2.1311e-01, time/batch = 0.7000s	
21798/30300 (epoch 35.970), train_loss = 1.02427816, grad/param norm = 1.7641e-01, time/batch = 0.6856s	
21799/30300 (epoch 35.972), train_loss = 0.95527951, grad/param norm = 1.8509e-01, time/batch = 0.6813s	
21800/30300 (epoch 35.974), train_loss = 1.18005181, grad/param norm = 1.6934e-01, time/batch = 0.6820s	
21801/30300 (epoch 35.975), train_loss = 1.17359018, grad/param norm = 1.9370e-01, time/batch = 0.6841s	
21802/30300 (epoch 35.977), train_loss = 1.23057253, grad/param norm = 1.8237e-01, time/batch = 0.6974s	
21803/30300 (epoch 35.979), train_loss = 1.11340238, grad/param norm = 1.7985e-01, time/batch = 0.6907s	
21804/30300 (epoch 35.980), train_loss = 1.15867378, grad/param norm = 2.0985e-01, time/batch = 0.7017s	
21805/30300 (epoch 35.982), train_loss = 1.15190819, grad/param norm = 1.8002e-01, time/batch = 0.7052s	
21806/30300 (epoch 35.983), train_loss = 1.17905745, grad/param norm = 1.7215e-01, time/batch = 0.7009s	
21807/30300 (epoch 35.985), train_loss = 1.11822880, grad/param norm = 2.2872e-01, time/batch = 0.6947s	
21808/30300 (epoch 35.987), train_loss = 1.05114396, grad/param norm = 1.5869e-01, time/batch = 0.6985s	
21809/30300 (epoch 35.988), train_loss = 1.18078125, grad/param norm = 2.1236e-01, time/batch = 0.6955s	
21810/30300 (epoch 35.990), train_loss = 0.96071854, grad/param norm = 1.6539e-01, time/batch = 0.6999s	
21811/30300 (epoch 35.992), train_loss = 1.14099824, grad/param norm = 1.5625e-01, time/batch = 0.6970s	
21812/30300 (epoch 35.993), train_loss = 1.16278724, grad/param norm = 2.0893e-01, time/batch = 0.6894s	
21813/30300 (epoch 35.995), train_loss = 1.05611330, grad/param norm = 1.9756e-01, time/batch = 0.6882s	
21814/30300 (epoch 35.997), train_loss = 1.10855956, grad/param norm = 1.8239e-01, time/batch = 0.7100s	
21815/30300 (epoch 35.998), train_loss = 1.13032993, grad/param norm = 1.9384e-01, time/batch = 0.7278s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
21816/30300 (epoch 36.000), train_loss = 1.00289711, grad/param norm = 2.0052e-01, time/batch = 0.7006s	
21817/30300 (epoch 36.002), train_loss = 1.15797166, grad/param norm = 1.9903e-01, time/batch = 0.7153s	
21818/30300 (epoch 36.003), train_loss = 1.07954234, grad/param norm = 1.8283e-01, time/batch = 0.6941s	
21819/30300 (epoch 36.005), train_loss = 1.02426393, grad/param norm = 1.7224e-01, time/batch = 0.6824s	
21820/30300 (epoch 36.007), train_loss = 1.10239457, grad/param norm = 1.8951e-01, time/batch = 0.6868s	
21821/30300 (epoch 36.008), train_loss = 1.03198301, grad/param norm = 1.8329e-01, time/batch = 0.6909s	
21822/30300 (epoch 36.010), train_loss = 0.94058538, grad/param norm = 1.7542e-01, time/batch = 0.6854s	
21823/30300 (epoch 36.012), train_loss = 1.00745050, grad/param norm = 1.6624e-01, time/batch = 0.6930s	
21824/30300 (epoch 36.013), train_loss = 1.15360346, grad/param norm = 2.0204e-01, time/batch = 0.6953s	
21825/30300 (epoch 36.015), train_loss = 1.00555927, grad/param norm = 1.5201e-01, time/batch = 0.6840s	
21826/30300 (epoch 36.017), train_loss = 1.01552406, grad/param norm = 1.6219e-01, time/batch = 0.6819s	
21827/30300 (epoch 36.018), train_loss = 0.95797930, grad/param norm = 1.6740e-01, time/batch = 0.6860s	
21828/30300 (epoch 36.020), train_loss = 1.15178210, grad/param norm = 2.1386e-01, time/batch = 0.6807s	
21829/30300 (epoch 36.021), train_loss = 1.17479386, grad/param norm = 1.6667e-01, time/batch = 0.6807s	
21830/30300 (epoch 36.023), train_loss = 1.05632299, grad/param norm = 1.5670e-01, time/batch = 0.6821s	
21831/30300 (epoch 36.025), train_loss = 0.97802468, grad/param norm = 1.8219e-01, time/batch = 0.6834s	
21832/30300 (epoch 36.026), train_loss = 1.10699104, grad/param norm = 2.1544e-01, time/batch = 0.6821s	
21833/30300 (epoch 36.028), train_loss = 1.13302004, grad/param norm = 1.8205e-01, time/batch = 0.7113s	
21834/30300 (epoch 36.030), train_loss = 1.01870832, grad/param norm = 1.8256e-01, time/batch = 0.7147s	
21835/30300 (epoch 36.031), train_loss = 1.09353515, grad/param norm = 1.7577e-01, time/batch = 0.6851s	
21836/30300 (epoch 36.033), train_loss = 1.06959891, grad/param norm = 1.6766e-01, time/batch = 0.6881s	
21837/30300 (epoch 36.035), train_loss = 1.12076100, grad/param norm = 1.9376e-01, time/batch = 0.6838s	
21838/30300 (epoch 36.036), train_loss = 1.06998015, grad/param norm = 1.8503e-01, time/batch = 0.6831s	
21839/30300 (epoch 36.038), train_loss = 1.10367162, grad/param norm = 1.6186e-01, time/batch = 0.6834s	
21840/30300 (epoch 36.040), train_loss = 0.89622473, grad/param norm = 1.4954e-01, time/batch = 0.6827s	
21841/30300 (epoch 36.041), train_loss = 0.89658806, grad/param norm = 1.6731e-01, time/batch = 0.6877s	
21842/30300 (epoch 36.043), train_loss = 1.06542584, grad/param norm = 1.7569e-01, time/batch = 0.6916s	
21843/30300 (epoch 36.045), train_loss = 1.00681929, grad/param norm = 1.5733e-01, time/batch = 0.6879s	
21844/30300 (epoch 36.046), train_loss = 1.18818780, grad/param norm = 2.0243e-01, time/batch = 0.6840s	
21845/30300 (epoch 36.048), train_loss = 1.06587130, grad/param norm = 1.8012e-01, time/batch = 0.6856s	
21846/30300 (epoch 36.050), train_loss = 0.96775622, grad/param norm = 1.6635e-01, time/batch = 0.6846s	
21847/30300 (epoch 36.051), train_loss = 1.09652966, grad/param norm = 1.8911e-01, time/batch = 0.6825s	
21848/30300 (epoch 36.053), train_loss = 0.93076749, grad/param norm = 2.3170e-01, time/batch = 0.6898s	
21849/30300 (epoch 36.054), train_loss = 1.10023913, grad/param norm = 1.6059e-01, time/batch = 0.6915s	
21850/30300 (epoch 36.056), train_loss = 0.96479278, grad/param norm = 1.6259e-01, time/batch = 0.6835s	
21851/30300 (epoch 36.058), train_loss = 1.01603679, grad/param norm = 1.8826e-01, time/batch = 0.6904s	
21852/30300 (epoch 36.059), train_loss = 1.01839768, grad/param norm = 1.8812e-01, time/batch = 0.6830s	
21853/30300 (epoch 36.061), train_loss = 1.08542985, grad/param norm = 1.7174e-01, time/batch = 0.6833s	
21854/30300 (epoch 36.063), train_loss = 0.93557420, grad/param norm = 1.6959e-01, time/batch = 0.6819s	
21855/30300 (epoch 36.064), train_loss = 1.05336511, grad/param norm = 1.9075e-01, time/batch = 0.6840s	
21856/30300 (epoch 36.066), train_loss = 1.05168054, grad/param norm = 1.5844e-01, time/batch = 0.7041s	
21857/30300 (epoch 36.068), train_loss = 0.97327970, grad/param norm = 1.7261e-01, time/batch = 0.7209s	
21858/30300 (epoch 36.069), train_loss = 1.11115346, grad/param norm = 1.7592e-01, time/batch = 0.6924s	
21859/30300 (epoch 36.071), train_loss = 1.11346072, grad/param norm = 1.8382e-01, time/batch = 0.6991s	
21860/30300 (epoch 36.073), train_loss = 0.96330489, grad/param norm = 1.6909e-01, time/batch = 0.6881s	
21861/30300 (epoch 36.074), train_loss = 1.03121797, grad/param norm = 1.5782e-01, time/batch = 0.6912s	
21862/30300 (epoch 36.076), train_loss = 1.03559875, grad/param norm = 1.6673e-01, time/batch = 0.6921s	
21863/30300 (epoch 36.078), train_loss = 0.97618093, grad/param norm = 1.4703e-01, time/batch = 0.6879s	
21864/30300 (epoch 36.079), train_loss = 1.00247304, grad/param norm = 1.9691e-01, time/batch = 0.6891s	
21865/30300 (epoch 36.081), train_loss = 1.06262501, grad/param norm = 1.7961e-01, time/batch = 0.6854s	
21866/30300 (epoch 36.083), train_loss = 1.11970483, grad/param norm = 2.3622e-01, time/batch = 0.6821s	
21867/30300 (epoch 36.084), train_loss = 0.98880530, grad/param norm = 1.7547e-01, time/batch = 0.6844s	
21868/30300 (epoch 36.086), train_loss = 1.00988220, grad/param norm = 2.2816e-01, time/batch = 0.6824s	
21869/30300 (epoch 36.087), train_loss = 0.97634141, grad/param norm = 1.6393e-01, time/batch = 0.6837s	
21870/30300 (epoch 36.089), train_loss = 0.98236748, grad/param norm = 1.6723e-01, time/batch = 0.6911s	
21871/30300 (epoch 36.091), train_loss = 1.08772125, grad/param norm = 1.6278e-01, time/batch = 0.7306s	
21872/30300 (epoch 36.092), train_loss = 1.11857585, grad/param norm = 1.8136e-01, time/batch = 0.7254s	
21873/30300 (epoch 36.094), train_loss = 1.16330296, grad/param norm = 2.1651e-01, time/batch = 0.7239s	
21874/30300 (epoch 36.096), train_loss = 1.16052997, grad/param norm = 1.7913e-01, time/batch = 0.7187s	
21875/30300 (epoch 36.097), train_loss = 0.99329031, grad/param norm = 1.8617e-01, time/batch = 0.7061s	
21876/30300 (epoch 36.099), train_loss = 1.12067207, grad/param norm = 1.6153e-01, time/batch = 0.6991s	
21877/30300 (epoch 36.101), train_loss = 1.18165881, grad/param norm = 2.2544e-01, time/batch = 0.6901s	
21878/30300 (epoch 36.102), train_loss = 1.01023399, grad/param norm = 2.1511e-01, time/batch = 0.6892s	
21879/30300 (epoch 36.104), train_loss = 1.02126097, grad/param norm = 2.0386e-01, time/batch = 0.6926s	
21880/30300 (epoch 36.106), train_loss = 1.01721991, grad/param norm = 1.8354e-01, time/batch = 0.6858s	
21881/30300 (epoch 36.107), train_loss = 1.10046459, grad/param norm = 1.6481e-01, time/batch = 0.6846s	
21882/30300 (epoch 36.109), train_loss = 1.14280785, grad/param norm = 2.1857e-01, time/batch = 0.6841s	
21883/30300 (epoch 36.111), train_loss = 1.10957751, grad/param norm = 1.7985e-01, time/batch = 0.6822s	
21884/30300 (epoch 36.112), train_loss = 1.19303250, grad/param norm = 1.7673e-01, time/batch = 0.6827s	
21885/30300 (epoch 36.114), train_loss = 1.02205009, grad/param norm = 1.7015e-01, time/batch = 0.6837s	
21886/30300 (epoch 36.116), train_loss = 1.09289869, grad/param norm = 1.9183e-01, time/batch = 0.6833s	
21887/30300 (epoch 36.117), train_loss = 1.17197660, grad/param norm = 1.9078e-01, time/batch = 0.6841s	
21888/30300 (epoch 36.119), train_loss = 0.97964909, grad/param norm = 1.7204e-01, time/batch = 0.6829s	
21889/30300 (epoch 36.120), train_loss = 1.03511795, grad/param norm = 1.6808e-01, time/batch = 0.7068s	
21890/30300 (epoch 36.122), train_loss = 1.15220420, grad/param norm = 2.2454e-01, time/batch = 0.7202s	
21891/30300 (epoch 36.124), train_loss = 1.20629415, grad/param norm = 1.9208e-01, time/batch = 0.6855s	
21892/30300 (epoch 36.125), train_loss = 0.95918405, grad/param norm = 1.8663e-01, time/batch = 0.6851s	
21893/30300 (epoch 36.127), train_loss = 1.09434672, grad/param norm = 2.3021e-01, time/batch = 0.6856s	
21894/30300 (epoch 36.129), train_loss = 1.15995858, grad/param norm = 1.9061e-01, time/batch = 0.6871s	
21895/30300 (epoch 36.130), train_loss = 1.19811752, grad/param norm = 1.7498e-01, time/batch = 0.6837s	
21896/30300 (epoch 36.132), train_loss = 1.18503543, grad/param norm = 1.9701e-01, time/batch = 0.6836s	
21897/30300 (epoch 36.134), train_loss = 0.98466185, grad/param norm = 1.7971e-01, time/batch = 0.6826s	
21898/30300 (epoch 36.135), train_loss = 1.01453538, grad/param norm = 1.7764e-01, time/batch = 0.6833s	
21899/30300 (epoch 36.137), train_loss = 1.06780179, grad/param norm = 1.9100e-01, time/batch = 0.6839s	
21900/30300 (epoch 36.139), train_loss = 1.01843597, grad/param norm = 2.6168e-01, time/batch = 0.6907s	
21901/30300 (epoch 36.140), train_loss = 1.08091088, grad/param norm = 2.4816e-01, time/batch = 0.7090s	
21902/30300 (epoch 36.142), train_loss = 1.14294405, grad/param norm = 2.0009e-01, time/batch = 0.6932s	
21903/30300 (epoch 36.144), train_loss = 0.99088866, grad/param norm = 2.0392e-01, time/batch = 0.7014s	
21904/30300 (epoch 36.145), train_loss = 1.14124749, grad/param norm = 2.1460e-01, time/batch = 0.6998s	
21905/30300 (epoch 36.147), train_loss = 1.02269626, grad/param norm = 1.8603e-01, time/batch = 0.6860s	
21906/30300 (epoch 36.149), train_loss = 1.16448417, grad/param norm = 3.2117e-01, time/batch = 0.6863s	
21907/30300 (epoch 36.150), train_loss = 1.06587513, grad/param norm = 2.4549e-01, time/batch = 0.6835s	
21908/30300 (epoch 36.152), train_loss = 0.95331028, grad/param norm = 1.7852e-01, time/batch = 0.7168s	
21909/30300 (epoch 36.153), train_loss = 1.07656120, grad/param norm = 2.0636e-01, time/batch = 0.7083s	
21910/30300 (epoch 36.155), train_loss = 0.93911745, grad/param norm = 1.5955e-01, time/batch = 0.6866s	
21911/30300 (epoch 36.157), train_loss = 1.00870084, grad/param norm = 1.9530e-01, time/batch = 0.7046s	
21912/30300 (epoch 36.158), train_loss = 1.10446103, grad/param norm = 2.4904e-01, time/batch = 0.6945s	
21913/30300 (epoch 36.160), train_loss = 0.97384817, grad/param norm = 1.8500e-01, time/batch = 0.7255s	
21914/30300 (epoch 36.162), train_loss = 1.05967518, grad/param norm = 1.6841e-01, time/batch = 0.7237s	
21915/30300 (epoch 36.163), train_loss = 1.05202012, grad/param norm = 1.9091e-01, time/batch = 0.7485s	
21916/30300 (epoch 36.165), train_loss = 1.17674696, grad/param norm = 1.9217e-01, time/batch = 0.7197s	
21917/30300 (epoch 36.167), train_loss = 1.07680083, grad/param norm = 1.8600e-01, time/batch = 0.7125s	
21918/30300 (epoch 36.168), train_loss = 1.12085996, grad/param norm = 1.7083e-01, time/batch = 0.7019s	
21919/30300 (epoch 36.170), train_loss = 1.06927131, grad/param norm = 1.8187e-01, time/batch = 0.6903s	
21920/30300 (epoch 36.172), train_loss = 1.06779350, grad/param norm = 1.8863e-01, time/batch = 0.6981s	
21921/30300 (epoch 36.173), train_loss = 1.03937980, grad/param norm = 2.0033e-01, time/batch = 0.6999s	
21922/30300 (epoch 36.175), train_loss = 1.07151783, grad/param norm = 1.8038e-01, time/batch = 0.7375s	
21923/30300 (epoch 36.177), train_loss = 1.12385379, grad/param norm = 1.8790e-01, time/batch = 0.7192s	
21924/30300 (epoch 36.178), train_loss = 0.87432549, grad/param norm = 1.4880e-01, time/batch = 0.6930s	
21925/30300 (epoch 36.180), train_loss = 1.03687367, grad/param norm = 1.6091e-01, time/batch = 0.6824s	
21926/30300 (epoch 36.182), train_loss = 1.08176330, grad/param norm = 1.9346e-01, time/batch = 0.7072s	
21927/30300 (epoch 36.183), train_loss = 0.99261959, grad/param norm = 1.7393e-01, time/batch = 0.6891s	
21928/30300 (epoch 36.185), train_loss = 1.20682844, grad/param norm = 1.8668e-01, time/batch = 0.6854s	
21929/30300 (epoch 36.186), train_loss = 1.27861060, grad/param norm = 3.2250e-01, time/batch = 0.6827s	
21930/30300 (epoch 36.188), train_loss = 1.09742700, grad/param norm = 1.7616e-01, time/batch = 0.6869s	
21931/30300 (epoch 36.190), train_loss = 1.05224373, grad/param norm = 1.7075e-01, time/batch = 0.7102s	
21932/30300 (epoch 36.191), train_loss = 1.12478896, grad/param norm = 2.0060e-01, time/batch = 0.7033s	
21933/30300 (epoch 36.193), train_loss = 0.97681844, grad/param norm = 1.6808e-01, time/batch = 0.6998s	
21934/30300 (epoch 36.195), train_loss = 1.02465952, grad/param norm = 1.8330e-01, time/batch = 0.7075s	
21935/30300 (epoch 36.196), train_loss = 1.09354395, grad/param norm = 1.5224e-01, time/batch = 0.7002s	
21936/30300 (epoch 36.198), train_loss = 0.89680397, grad/param norm = 1.6373e-01, time/batch = 0.6984s	
21937/30300 (epoch 36.200), train_loss = 1.03734694, grad/param norm = 1.8403e-01, time/batch = 0.6900s	
21938/30300 (epoch 36.201), train_loss = 1.14353503, grad/param norm = 2.2973e-01, time/batch = 0.6937s	
21939/30300 (epoch 36.203), train_loss = 1.05442959, grad/param norm = 1.8213e-01, time/batch = 0.7004s	
21940/30300 (epoch 36.205), train_loss = 1.24858444, grad/param norm = 1.8692e-01, time/batch = 0.6924s	
21941/30300 (epoch 36.206), train_loss = 1.12299676, grad/param norm = 1.8673e-01, time/batch = 0.6993s	
21942/30300 (epoch 36.208), train_loss = 1.13680799, grad/param norm = 2.2015e-01, time/batch = 0.6951s	
21943/30300 (epoch 36.210), train_loss = 1.14243111, grad/param norm = 1.7448e-01, time/batch = 0.7030s	
21944/30300 (epoch 36.211), train_loss = 1.18587188, grad/param norm = 1.7414e-01, time/batch = 0.7063s	
21945/30300 (epoch 36.213), train_loss = 1.05909066, grad/param norm = 1.6005e-01, time/batch = 0.7060s	
21946/30300 (epoch 36.215), train_loss = 0.98112982, grad/param norm = 1.6376e-01, time/batch = 0.7061s	
21947/30300 (epoch 36.216), train_loss = 1.01431738, grad/param norm = 1.9964e-01, time/batch = 0.7178s	
21948/30300 (epoch 36.218), train_loss = 0.97678569, grad/param norm = 1.7454e-01, time/batch = 0.7136s	
21949/30300 (epoch 36.219), train_loss = 0.94414440, grad/param norm = 1.7089e-01, time/batch = 0.7127s	
21950/30300 (epoch 36.221), train_loss = 0.90631990, grad/param norm = 1.6698e-01, time/batch = 0.7259s	
21951/30300 (epoch 36.223), train_loss = 1.05837523, grad/param norm = 1.7657e-01, time/batch = 0.7375s	
21952/30300 (epoch 36.224), train_loss = 0.88707140, grad/param norm = 1.6997e-01, time/batch = 0.7010s	
21953/30300 (epoch 36.226), train_loss = 1.10616397, grad/param norm = 2.0886e-01, time/batch = 0.6866s	
21954/30300 (epoch 36.228), train_loss = 1.15363697, grad/param norm = 1.6660e-01, time/batch = 0.6879s	
21955/30300 (epoch 36.229), train_loss = 1.03480798, grad/param norm = 1.6808e-01, time/batch = 0.6832s	
21956/30300 (epoch 36.231), train_loss = 1.11178348, grad/param norm = 1.8078e-01, time/batch = 0.6832s	
21957/30300 (epoch 36.233), train_loss = 1.11142259, grad/param norm = 1.5537e-01, time/batch = 0.6840s	
21958/30300 (epoch 36.234), train_loss = 1.13542726, grad/param norm = 2.1291e-01, time/batch = 0.6852s	
21959/30300 (epoch 36.236), train_loss = 1.10272770, grad/param norm = 1.5700e-01, time/batch = 0.6848s	
21960/30300 (epoch 36.238), train_loss = 1.05461074, grad/param norm = 2.0002e-01, time/batch = 0.6878s	
21961/30300 (epoch 36.239), train_loss = 1.02940747, grad/param norm = 2.0513e-01, time/batch = 0.7006s	
21962/30300 (epoch 36.241), train_loss = 1.11516148, grad/param norm = 1.8755e-01, time/batch = 0.6895s	
21963/30300 (epoch 36.243), train_loss = 1.09506401, grad/param norm = 1.6963e-01, time/batch = 0.6837s	
21964/30300 (epoch 36.244), train_loss = 1.26650792, grad/param norm = 1.8784e-01, time/batch = 0.6926s	
21965/30300 (epoch 36.246), train_loss = 1.08718593, grad/param norm = 1.7388e-01, time/batch = 0.7266s	
21966/30300 (epoch 36.248), train_loss = 1.02750307, grad/param norm = 1.5623e-01, time/batch = 0.6972s	
21967/30300 (epoch 36.249), train_loss = 0.97550487, grad/param norm = 1.8507e-01, time/batch = 0.6865s	
21968/30300 (epoch 36.251), train_loss = 1.00085692, grad/param norm = 1.7596e-01, time/batch = 0.6861s	
21969/30300 (epoch 36.252), train_loss = 1.16528862, grad/param norm = 1.9119e-01, time/batch = 0.6893s	
21970/30300 (epoch 36.254), train_loss = 1.14725553, grad/param norm = 1.7146e-01, time/batch = 0.6829s	
21971/30300 (epoch 36.256), train_loss = 1.09845894, grad/param norm = 1.7191e-01, time/batch = 0.6905s	
21972/30300 (epoch 36.257), train_loss = 1.13173735, grad/param norm = 1.7792e-01, time/batch = 0.6832s	
21973/30300 (epoch 36.259), train_loss = 1.05514739, grad/param norm = 1.8976e-01, time/batch = 0.6881s	
21974/30300 (epoch 36.261), train_loss = 1.19441344, grad/param norm = 1.7390e-01, time/batch = 0.6864s	
21975/30300 (epoch 36.262), train_loss = 0.99415113, grad/param norm = 1.6559e-01, time/batch = 0.6825s	
21976/30300 (epoch 36.264), train_loss = 1.06016206, grad/param norm = 1.7471e-01, time/batch = 0.6875s	
21977/30300 (epoch 36.266), train_loss = 1.03863667, grad/param norm = 1.6013e-01, time/batch = 0.6831s	
21978/30300 (epoch 36.267), train_loss = 1.20839451, grad/param norm = 1.9600e-01, time/batch = 0.6864s	
21979/30300 (epoch 36.269), train_loss = 1.06847060, grad/param norm = 1.6688e-01, time/batch = 0.6881s	
21980/30300 (epoch 36.271), train_loss = 1.07396629, grad/param norm = 1.7399e-01, time/batch = 0.6850s	
21981/30300 (epoch 36.272), train_loss = 1.07636965, grad/param norm = 1.9224e-01, time/batch = 0.6958s	
21982/30300 (epoch 36.274), train_loss = 1.14877581, grad/param norm = 1.8593e-01, time/batch = 0.6885s	
21983/30300 (epoch 36.276), train_loss = 1.08926304, grad/param norm = 1.7480e-01, time/batch = 0.7131s	
21984/30300 (epoch 36.277), train_loss = 0.95472970, grad/param norm = 1.7417e-01, time/batch = 0.7261s	
21985/30300 (epoch 36.279), train_loss = 1.05669519, grad/param norm = 1.6224e-01, time/batch = 0.6855s	
21986/30300 (epoch 36.281), train_loss = 1.13827051, grad/param norm = 1.9427e-01, time/batch = 0.6936s	
21987/30300 (epoch 36.282), train_loss = 1.10495389, grad/param norm = 1.6855e-01, time/batch = 0.7068s	
21988/30300 (epoch 36.284), train_loss = 1.16312500, grad/param norm = 2.3585e-01, time/batch = 0.7050s	
21989/30300 (epoch 36.285), train_loss = 1.10695769, grad/param norm = 1.6234e-01, time/batch = 0.7322s	
21990/30300 (epoch 36.287), train_loss = 1.07019477, grad/param norm = 1.9100e-01, time/batch = 0.7303s	
21991/30300 (epoch 36.289), train_loss = 1.14966343, grad/param norm = 1.6270e-01, time/batch = 0.6975s	
21992/30300 (epoch 36.290), train_loss = 0.84853760, grad/param norm = 1.5659e-01, time/batch = 0.6897s	
21993/30300 (epoch 36.292), train_loss = 0.96048689, grad/param norm = 1.7752e-01, time/batch = 0.6932s	
21994/30300 (epoch 36.294), train_loss = 1.15274484, grad/param norm = 2.8914e-01, time/batch = 0.6881s	
21995/30300 (epoch 36.295), train_loss = 1.01880900, grad/param norm = 1.6392e-01, time/batch = 0.6864s	
21996/30300 (epoch 36.297), train_loss = 1.02830601, grad/param norm = 1.6096e-01, time/batch = 0.6855s	
21997/30300 (epoch 36.299), train_loss = 1.04687894, grad/param norm = 1.6203e-01, time/batch = 0.6981s	
21998/30300 (epoch 36.300), train_loss = 0.98227381, grad/param norm = 1.7972e-01, time/batch = 0.7262s	
21999/30300 (epoch 36.302), train_loss = 1.13806004, grad/param norm = 1.7555e-01, time/batch = 0.7208s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch36.30_1.9793.t7	
22000/30300 (epoch 36.304), train_loss = 0.98313076, grad/param norm = 1.5922e-01, time/batch = 0.6907s	
22001/30300 (epoch 36.305), train_loss = 1.56828225, grad/param norm = 2.0760e-01, time/batch = 0.6917s	
22002/30300 (epoch 36.307), train_loss = 1.17173302, grad/param norm = 1.7569e-01, time/batch = 0.6815s	
22003/30300 (epoch 36.309), train_loss = 1.09882181, grad/param norm = 1.7605e-01, time/batch = 0.6940s	
22004/30300 (epoch 36.310), train_loss = 1.06366758, grad/param norm = 1.8272e-01, time/batch = 0.6838s	
22005/30300 (epoch 36.312), train_loss = 1.18613520, grad/param norm = 1.7098e-01, time/batch = 0.6878s	
22006/30300 (epoch 36.314), train_loss = 1.08795254, grad/param norm = 1.9768e-01, time/batch = 0.6948s	
22007/30300 (epoch 36.315), train_loss = 1.02327020, grad/param norm = 1.6645e-01, time/batch = 0.7051s	
22008/30300 (epoch 36.317), train_loss = 1.09579394, grad/param norm = 1.6131e-01, time/batch = 0.7313s	
22009/30300 (epoch 36.318), train_loss = 1.14438323, grad/param norm = 2.0642e-01, time/batch = 0.6912s	
22010/30300 (epoch 36.320), train_loss = 1.09629048, grad/param norm = 1.7050e-01, time/batch = 0.6900s	
22011/30300 (epoch 36.322), train_loss = 1.02386541, grad/param norm = 1.5862e-01, time/batch = 0.6922s	
22012/30300 (epoch 36.323), train_loss = 1.18176391, grad/param norm = 1.7281e-01, time/batch = 0.6883s	
22013/30300 (epoch 36.325), train_loss = 1.06465763, grad/param norm = 1.9336e-01, time/batch = 0.6914s	
22014/30300 (epoch 36.327), train_loss = 1.04178967, grad/param norm = 1.5994e-01, time/batch = 0.6860s	
22015/30300 (epoch 36.328), train_loss = 1.08065989, grad/param norm = 1.6017e-01, time/batch = 0.6866s	
22016/30300 (epoch 36.330), train_loss = 1.10974303, grad/param norm = 1.8200e-01, time/batch = 0.6959s	
22017/30300 (epoch 36.332), train_loss = 1.16860981, grad/param norm = 1.8979e-01, time/batch = 0.7031s	
22018/30300 (epoch 36.333), train_loss = 1.00217160, grad/param norm = 1.7722e-01, time/batch = 0.6866s	
22019/30300 (epoch 36.335), train_loss = 0.95984236, grad/param norm = 1.5959e-01, time/batch = 0.6891s	
22020/30300 (epoch 36.337), train_loss = 1.19607965, grad/param norm = 1.7201e-01, time/batch = 0.6917s	
22021/30300 (epoch 36.338), train_loss = 1.01858124, grad/param norm = 1.6489e-01, time/batch = 0.6891s	
22022/30300 (epoch 36.340), train_loss = 1.00765697, grad/param norm = 1.5482e-01, time/batch = 0.6835s	
22023/30300 (epoch 36.342), train_loss = 1.14580274, grad/param norm = 1.8061e-01, time/batch = 0.6871s	
22024/30300 (epoch 36.343), train_loss = 1.09245833, grad/param norm = 1.6646e-01, time/batch = 0.6829s	
22025/30300 (epoch 36.345), train_loss = 1.12526343, grad/param norm = 1.7127e-01, time/batch = 0.6824s	
22026/30300 (epoch 36.347), train_loss = 0.94346799, grad/param norm = 1.6323e-01, time/batch = 0.7109s	
22027/30300 (epoch 36.348), train_loss = 1.02015296, grad/param norm = 1.6086e-01, time/batch = 0.7159s	
22028/30300 (epoch 36.350), train_loss = 1.02762764, grad/param norm = 1.7670e-01, time/batch = 0.6866s	
22029/30300 (epoch 36.351), train_loss = 1.04074955, grad/param norm = 1.6856e-01, time/batch = 0.6885s	
22030/30300 (epoch 36.353), train_loss = 0.94334808, grad/param norm = 1.6393e-01, time/batch = 0.6810s	
22031/30300 (epoch 36.355), train_loss = 1.01233282, grad/param norm = 1.5500e-01, time/batch = 0.6862s	
22032/30300 (epoch 36.356), train_loss = 1.14907866, grad/param norm = 2.0410e-01, time/batch = 0.6844s	
22033/30300 (epoch 36.358), train_loss = 1.29059609, grad/param norm = 1.6556e-01, time/batch = 0.6836s	
22034/30300 (epoch 36.360), train_loss = 1.01834356, grad/param norm = 1.7552e-01, time/batch = 0.6826s	
22035/30300 (epoch 36.361), train_loss = 1.05303025, grad/param norm = 1.6872e-01, time/batch = 0.6852s	
22036/30300 (epoch 36.363), train_loss = 1.09568584, grad/param norm = 1.7676e-01, time/batch = 0.6844s	
22037/30300 (epoch 36.365), train_loss = 0.94074920, grad/param norm = 1.7305e-01, time/batch = 0.6830s	
22038/30300 (epoch 36.366), train_loss = 1.03855061, grad/param norm = 1.6472e-01, time/batch = 0.6837s	
22039/30300 (epoch 36.368), train_loss = 0.93673267, grad/param norm = 1.6499e-01, time/batch = 0.6954s	
22040/30300 (epoch 36.370), train_loss = 1.00110729, grad/param norm = 1.8451e-01, time/batch = 0.6970s	
22041/30300 (epoch 36.371), train_loss = 1.12778893, grad/param norm = 1.6672e-01, time/batch = 0.7283s	
22042/30300 (epoch 36.373), train_loss = 1.00975755, grad/param norm = 1.4552e-01, time/batch = 0.6902s	
22043/30300 (epoch 36.375), train_loss = 0.98312541, grad/param norm = 1.4170e-01, time/batch = 0.6879s	
22044/30300 (epoch 36.376), train_loss = 0.98104219, grad/param norm = 1.5252e-01, time/batch = 0.6903s	
22045/30300 (epoch 36.378), train_loss = 0.97250722, grad/param norm = 1.6582e-01, time/batch = 0.6860s	
22046/30300 (epoch 36.380), train_loss = 1.17421848, grad/param norm = 1.6630e-01, time/batch = 0.6848s	
22047/30300 (epoch 36.381), train_loss = 0.90895719, grad/param norm = 1.6220e-01, time/batch = 0.6885s	
22048/30300 (epoch 36.383), train_loss = 0.96357355, grad/param norm = 1.9220e-01, time/batch = 0.6830s	
22049/30300 (epoch 36.384), train_loss = 1.11512972, grad/param norm = 2.0428e-01, time/batch = 0.6975s	
22050/30300 (epoch 36.386), train_loss = 0.94293402, grad/param norm = 1.5944e-01, time/batch = 0.6885s	
22051/30300 (epoch 36.388), train_loss = 0.93524290, grad/param norm = 1.6895e-01, time/batch = 0.6929s	
22052/30300 (epoch 36.389), train_loss = 1.03837945, grad/param norm = 1.7062e-01, time/batch = 0.6956s	
22053/30300 (epoch 36.391), train_loss = 1.09023035, grad/param norm = 1.6295e-01, time/batch = 0.6874s	
22054/30300 (epoch 36.393), train_loss = 0.92038090, grad/param norm = 1.5095e-01, time/batch = 0.6920s	
22055/30300 (epoch 36.394), train_loss = 1.09916028, grad/param norm = 1.6581e-01, time/batch = 0.6864s	
22056/30300 (epoch 36.396), train_loss = 1.17250872, grad/param norm = 1.7916e-01, time/batch = 0.6951s	
22057/30300 (epoch 36.398), train_loss = 1.01969983, grad/param norm = 1.7449e-01, time/batch = 0.7055s	
22058/30300 (epoch 36.399), train_loss = 0.98680532, grad/param norm = 1.7897e-01, time/batch = 0.6866s	
22059/30300 (epoch 36.401), train_loss = 1.06530698, grad/param norm = 2.2364e-01, time/batch = 0.7082s	
22060/30300 (epoch 36.403), train_loss = 1.04834996, grad/param norm = 1.7801e-01, time/batch = 0.7197s	
22061/30300 (epoch 36.404), train_loss = 0.99512722, grad/param norm = 1.8230e-01, time/batch = 0.6848s	
22062/30300 (epoch 36.406), train_loss = 1.06479847, grad/param norm = 1.6106e-01, time/batch = 0.6850s	
22063/30300 (epoch 36.408), train_loss = 0.93667728, grad/param norm = 1.5160e-01, time/batch = 0.7160s	
22064/30300 (epoch 36.409), train_loss = 0.93136543, grad/param norm = 1.6539e-01, time/batch = 0.7228s	
22065/30300 (epoch 36.411), train_loss = 0.97611152, grad/param norm = 1.5200e-01, time/batch = 0.7170s	
22066/30300 (epoch 36.413), train_loss = 0.88398550, grad/param norm = 1.5052e-01, time/batch = 0.7233s	
22067/30300 (epoch 36.414), train_loss = 1.10298315, grad/param norm = 1.7549e-01, time/batch = 0.7221s	
22068/30300 (epoch 36.416), train_loss = 0.98849636, grad/param norm = 1.5416e-01, time/batch = 0.7139s	
22069/30300 (epoch 36.417), train_loss = 0.96693495, grad/param norm = 1.7774e-01, time/batch = 0.7177s	
22070/30300 (epoch 36.419), train_loss = 0.95736395, grad/param norm = 2.4493e-01, time/batch = 0.7177s	
22071/30300 (epoch 36.421), train_loss = 1.00838823, grad/param norm = 1.7653e-01, time/batch = 0.7165s	
22072/30300 (epoch 36.422), train_loss = 1.06985645, grad/param norm = 1.8952e-01, time/batch = 0.7137s	
22073/30300 (epoch 36.424), train_loss = 1.06018642, grad/param norm = 1.6958e-01, time/batch = 0.7192s	
22074/30300 (epoch 36.426), train_loss = 0.99938713, grad/param norm = 1.6374e-01, time/batch = 0.7116s	
22075/30300 (epoch 36.427), train_loss = 0.97934549, grad/param norm = 1.7732e-01, time/batch = 0.7123s	
22076/30300 (epoch 36.429), train_loss = 1.04280098, grad/param norm = 1.6009e-01, time/batch = 0.7130s	
22077/30300 (epoch 36.431), train_loss = 1.09713345, grad/param norm = 1.8815e-01, time/batch = 0.7408s	
22078/30300 (epoch 36.432), train_loss = 1.03272858, grad/param norm = 1.6203e-01, time/batch = 0.7203s	
22079/30300 (epoch 36.434), train_loss = 0.95614752, grad/param norm = 1.8248e-01, time/batch = 0.7156s	
22080/30300 (epoch 36.436), train_loss = 1.15488666, grad/param norm = 1.7992e-01, time/batch = 0.7106s	
22081/30300 (epoch 36.437), train_loss = 0.95287634, grad/param norm = 1.5969e-01, time/batch = 0.7160s	
22082/30300 (epoch 36.439), train_loss = 0.98679819, grad/param norm = 1.5130e-01, time/batch = 0.7147s	
22083/30300 (epoch 36.441), train_loss = 1.02442313, grad/param norm = 1.5573e-01, time/batch = 0.7282s	
22084/30300 (epoch 36.442), train_loss = 0.98058377, grad/param norm = 1.5568e-01, time/batch = 0.7191s	
22085/30300 (epoch 36.444), train_loss = 0.86314317, grad/param norm = 1.5488e-01, time/batch = 0.7026s	
22086/30300 (epoch 36.446), train_loss = 1.01797598, grad/param norm = 1.6824e-01, time/batch = 0.7047s	
22087/30300 (epoch 36.447), train_loss = 1.02994023, grad/param norm = 1.5965e-01, time/batch = 0.7059s	
22088/30300 (epoch 36.449), train_loss = 0.96689110, grad/param norm = 1.6150e-01, time/batch = 0.7042s	
22089/30300 (epoch 36.450), train_loss = 1.06814141, grad/param norm = 1.6036e-01, time/batch = 0.7138s	
22090/30300 (epoch 36.452), train_loss = 1.16448126, grad/param norm = 1.6113e-01, time/batch = 0.7099s	
22091/30300 (epoch 36.454), train_loss = 1.10057726, grad/param norm = 1.6370e-01, time/batch = 0.7081s	
22092/30300 (epoch 36.455), train_loss = 1.03517895, grad/param norm = 1.6566e-01, time/batch = 0.7030s	
22093/30300 (epoch 36.457), train_loss = 1.01347293, grad/param norm = 1.8689e-01, time/batch = 0.6861s	
22094/30300 (epoch 36.459), train_loss = 1.10712477, grad/param norm = 1.8850e-01, time/batch = 0.6889s	
22095/30300 (epoch 36.460), train_loss = 1.11223287, grad/param norm = 1.9177e-01, time/batch = 0.6876s	
22096/30300 (epoch 36.462), train_loss = 1.10986252, grad/param norm = 1.6628e-01, time/batch = 0.6896s	
22097/30300 (epoch 36.464), train_loss = 0.86093246, grad/param norm = 1.8353e-01, time/batch = 0.6826s	
22098/30300 (epoch 36.465), train_loss = 0.89431709, grad/param norm = 1.4605e-01, time/batch = 0.6847s	
22099/30300 (epoch 36.467), train_loss = 0.88989421, grad/param norm = 1.6160e-01, time/batch = 0.6937s	
22100/30300 (epoch 36.469), train_loss = 0.96109154, grad/param norm = 1.4635e-01, time/batch = 0.6835s	
22101/30300 (epoch 36.470), train_loss = 0.99146283, grad/param norm = 1.7504e-01, time/batch = 0.6875s	
22102/30300 (epoch 36.472), train_loss = 0.98713796, grad/param norm = 1.5903e-01, time/batch = 0.6881s	
22103/30300 (epoch 36.474), train_loss = 0.98232617, grad/param norm = 1.9746e-01, time/batch = 0.6885s	
22104/30300 (epoch 36.475), train_loss = 0.97041216, grad/param norm = 1.5290e-01, time/batch = 0.6892s	
22105/30300 (epoch 36.477), train_loss = 1.03634122, grad/param norm = 1.6452e-01, time/batch = 0.6846s	
22106/30300 (epoch 36.479), train_loss = 1.00614736, grad/param norm = 1.6859e-01, time/batch = 0.6860s	
22107/30300 (epoch 36.480), train_loss = 1.06740268, grad/param norm = 1.7079e-01, time/batch = 0.6877s	
22108/30300 (epoch 36.482), train_loss = 1.10627683, grad/param norm = 1.6719e-01, time/batch = 0.6868s	
22109/30300 (epoch 36.483), train_loss = 1.02188830, grad/param norm = 1.9452e-01, time/batch = 0.6883s	
22110/30300 (epoch 36.485), train_loss = 1.05132834, grad/param norm = 1.6323e-01, time/batch = 0.6907s	
22111/30300 (epoch 36.487), train_loss = 1.11444934, grad/param norm = 1.7044e-01, time/batch = 0.6952s	
22112/30300 (epoch 36.488), train_loss = 1.15657208, grad/param norm = 1.5045e-01, time/batch = 0.6822s	
22113/30300 (epoch 36.490), train_loss = 0.91533392, grad/param norm = 1.5672e-01, time/batch = 0.6860s	
22114/30300 (epoch 36.492), train_loss = 1.01381805, grad/param norm = 1.7522e-01, time/batch = 0.6939s	
22115/30300 (epoch 36.493), train_loss = 1.03519114, grad/param norm = 1.6888e-01, time/batch = 0.7055s	
22116/30300 (epoch 36.495), train_loss = 1.02263319, grad/param norm = 1.6099e-01, time/batch = 0.7261s	
22117/30300 (epoch 36.497), train_loss = 1.05425451, grad/param norm = 1.5726e-01, time/batch = 0.7222s	
22118/30300 (epoch 36.498), train_loss = 1.09342395, grad/param norm = 1.7905e-01, time/batch = 0.7161s	
22119/30300 (epoch 36.500), train_loss = 1.01652664, grad/param norm = 2.3402e-01, time/batch = 0.7047s	
22120/30300 (epoch 36.502), train_loss = 1.02544594, grad/param norm = 1.8479e-01, time/batch = 0.7002s	
22121/30300 (epoch 36.503), train_loss = 1.12750044, grad/param norm = 1.7033e-01, time/batch = 0.6849s	
22122/30300 (epoch 36.505), train_loss = 0.92942804, grad/param norm = 1.5711e-01, time/batch = 0.6843s	
22123/30300 (epoch 36.507), train_loss = 0.94437558, grad/param norm = 2.0862e-01, time/batch = 0.6850s	
22124/30300 (epoch 36.508), train_loss = 1.01706601, grad/param norm = 2.4523e-01, time/batch = 0.6860s	
22125/30300 (epoch 36.510), train_loss = 1.11794488, grad/param norm = 1.9273e-01, time/batch = 0.6869s	
22126/30300 (epoch 36.512), train_loss = 0.97667560, grad/param norm = 1.6036e-01, time/batch = 0.6884s	
22127/30300 (epoch 36.513), train_loss = 1.03615895, grad/param norm = 1.6146e-01, time/batch = 0.6895s	
22128/30300 (epoch 36.515), train_loss = 1.02429715, grad/param norm = 1.6170e-01, time/batch = 0.6812s	
22129/30300 (epoch 36.517), train_loss = 0.86647810, grad/param norm = 1.3957e-01, time/batch = 0.6815s	
22130/30300 (epoch 36.518), train_loss = 1.12918103, grad/param norm = 1.9093e-01, time/batch = 0.6824s	
22131/30300 (epoch 36.520), train_loss = 1.06737791, grad/param norm = 2.2234e-01, time/batch = 0.6842s	
22132/30300 (epoch 36.521), train_loss = 0.95616346, grad/param norm = 1.8661e-01, time/batch = 0.6876s	
22133/30300 (epoch 36.523), train_loss = 1.17030486, grad/param norm = 2.0209e-01, time/batch = 0.6887s	
22134/30300 (epoch 36.525), train_loss = 0.96984493, grad/param norm = 1.6355e-01, time/batch = 0.6955s	
22135/30300 (epoch 36.526), train_loss = 1.05360395, grad/param norm = 1.5334e-01, time/batch = 0.7260s	
22136/30300 (epoch 36.528), train_loss = 0.93226236, grad/param norm = 1.5819e-01, time/batch = 0.6900s	
22137/30300 (epoch 36.530), train_loss = 0.91647036, grad/param norm = 1.6338e-01, time/batch = 0.6882s	
22138/30300 (epoch 36.531), train_loss = 1.04256730, grad/param norm = 1.6318e-01, time/batch = 0.6897s	
22139/30300 (epoch 36.533), train_loss = 1.01301407, grad/param norm = 1.7591e-01, time/batch = 0.6902s	
22140/30300 (epoch 36.535), train_loss = 1.00395443, grad/param norm = 1.5234e-01, time/batch = 0.6940s	
22141/30300 (epoch 36.536), train_loss = 1.05751104, grad/param norm = 2.0584e-01, time/batch = 0.7006s	
22142/30300 (epoch 36.538), train_loss = 0.91610904, grad/param norm = 1.9388e-01, time/batch = 0.6900s	
22143/30300 (epoch 36.540), train_loss = 0.98523356, grad/param norm = 1.8089e-01, time/batch = 0.6884s	
22144/30300 (epoch 36.541), train_loss = 1.05880401, grad/param norm = 2.0171e-01, time/batch = 0.6850s	
22145/30300 (epoch 36.543), train_loss = 1.02004772, grad/param norm = 1.5890e-01, time/batch = 0.6837s	
22146/30300 (epoch 36.545), train_loss = 1.09946143, grad/param norm = 2.5963e-01, time/batch = 0.6838s	
22147/30300 (epoch 36.546), train_loss = 1.21152786, grad/param norm = 1.6405e-01, time/batch = 0.6861s	
22148/30300 (epoch 36.548), train_loss = 0.98293306, grad/param norm = 1.4673e-01, time/batch = 0.6908s	
22149/30300 (epoch 36.550), train_loss = 1.06745388, grad/param norm = 1.9876e-01, time/batch = 0.7032s	
22150/30300 (epoch 36.551), train_loss = 0.97948731, grad/param norm = 1.7409e-01, time/batch = 0.7001s	
22151/30300 (epoch 36.553), train_loss = 0.99580293, grad/param norm = 1.7067e-01, time/batch = 0.7063s	
22152/30300 (epoch 36.554), train_loss = 1.03410577, grad/param norm = 1.7324e-01, time/batch = 0.6929s	
22153/30300 (epoch 36.556), train_loss = 1.07611587, grad/param norm = 1.8965e-01, time/batch = 0.7135s	
22154/30300 (epoch 36.558), train_loss = 1.11536812, grad/param norm = 1.9286e-01, time/batch = 0.7157s	
22155/30300 (epoch 36.559), train_loss = 1.04251566, grad/param norm = 1.9359e-01, time/batch = 0.6877s	
22156/30300 (epoch 36.561), train_loss = 0.84509034, grad/param norm = 1.5403e-01, time/batch = 0.6870s	
22157/30300 (epoch 36.563), train_loss = 0.94614137, grad/param norm = 1.7516e-01, time/batch = 0.6931s	
22158/30300 (epoch 36.564), train_loss = 0.97370551, grad/param norm = 1.5122e-01, time/batch = 0.6816s	
22159/30300 (epoch 36.566), train_loss = 1.00755646, grad/param norm = 1.7168e-01, time/batch = 0.6810s	
22160/30300 (epoch 36.568), train_loss = 0.88832503, grad/param norm = 2.0247e-01, time/batch = 0.6809s	
22161/30300 (epoch 36.569), train_loss = 1.06880950, grad/param norm = 1.7460e-01, time/batch = 0.6835s	
22162/30300 (epoch 36.571), train_loss = 1.02371657, grad/param norm = 1.7345e-01, time/batch = 0.6854s	
22163/30300 (epoch 36.573), train_loss = 1.08779447, grad/param norm = 1.7862e-01, time/batch = 0.6945s	
22164/30300 (epoch 36.574), train_loss = 1.06325987, grad/param norm = 1.6206e-01, time/batch = 0.6889s	
22165/30300 (epoch 36.576), train_loss = 0.98947051, grad/param norm = 1.4585e-01, time/batch = 0.6834s	
22166/30300 (epoch 36.578), train_loss = 0.89180579, grad/param norm = 1.5223e-01, time/batch = 0.6849s	
22167/30300 (epoch 36.579), train_loss = 1.08079534, grad/param norm = 1.7608e-01, time/batch = 0.6907s	
22168/30300 (epoch 36.581), train_loss = 1.15003689, grad/param norm = 1.5456e-01, time/batch = 0.7253s	
22169/30300 (epoch 36.583), train_loss = 1.17611314, grad/param norm = 1.9568e-01, time/batch = 0.6890s	
22170/30300 (epoch 36.584), train_loss = 1.12321649, grad/param norm = 1.5904e-01, time/batch = 0.6824s	
22171/30300 (epoch 36.586), train_loss = 0.99462835, grad/param norm = 1.6840e-01, time/batch = 0.6881s	
22172/30300 (epoch 36.587), train_loss = 1.02274849, grad/param norm = 1.8523e-01, time/batch = 0.6841s	
22173/30300 (epoch 36.589), train_loss = 0.96651655, grad/param norm = 1.7478e-01, time/batch = 0.6842s	
22174/30300 (epoch 36.591), train_loss = 1.06139424, grad/param norm = 1.6449e-01, time/batch = 0.6824s	
22175/30300 (epoch 36.592), train_loss = 0.99370071, grad/param norm = 1.4520e-01, time/batch = 0.6825s	
22176/30300 (epoch 36.594), train_loss = 1.06524035, grad/param norm = 1.7974e-01, time/batch = 0.6829s	
22177/30300 (epoch 36.596), train_loss = 0.93329276, grad/param norm = 1.4461e-01, time/batch = 0.6828s	
22178/30300 (epoch 36.597), train_loss = 0.97412450, grad/param norm = 1.6385e-01, time/batch = 0.6926s	
22179/30300 (epoch 36.599), train_loss = 0.87045581, grad/param norm = 1.3974e-01, time/batch = 0.6880s	
22180/30300 (epoch 36.601), train_loss = 1.06201682, grad/param norm = 1.6526e-01, time/batch = 0.6862s	
22181/30300 (epoch 36.602), train_loss = 1.00240218, grad/param norm = 1.4765e-01, time/batch = 0.6845s	
22182/30300 (epoch 36.604), train_loss = 0.95342274, grad/param norm = 1.5435e-01, time/batch = 0.6833s	
22183/30300 (epoch 36.606), train_loss = 0.95057380, grad/param norm = 1.7701e-01, time/batch = 0.6837s	
22184/30300 (epoch 36.607), train_loss = 1.09058862, grad/param norm = 2.2345e-01, time/batch = 0.6833s	
22185/30300 (epoch 36.609), train_loss = 1.18843034, grad/param norm = 1.7512e-01, time/batch = 0.6846s	
22186/30300 (epoch 36.611), train_loss = 0.99799894, grad/param norm = 1.6850e-01, time/batch = 0.6852s	
22187/30300 (epoch 36.612), train_loss = 0.91627003, grad/param norm = 1.3600e-01, time/batch = 0.6891s	
22188/30300 (epoch 36.614), train_loss = 0.99650600, grad/param norm = 1.7225e-01, time/batch = 0.6817s	
22189/30300 (epoch 36.616), train_loss = 1.04692855, grad/param norm = 2.0298e-01, time/batch = 0.6818s	
22190/30300 (epoch 36.617), train_loss = 1.03985513, grad/param norm = 1.8385e-01, time/batch = 0.6811s	
22191/30300 (epoch 36.619), train_loss = 0.84199291, grad/param norm = 1.3917e-01, time/batch = 0.7279s	
22192/30300 (epoch 36.620), train_loss = 1.09012856, grad/param norm = 1.6785e-01, time/batch = 0.7009s	
22193/30300 (epoch 36.622), train_loss = 1.02797745, grad/param norm = 1.8296e-01, time/batch = 0.6873s	
22194/30300 (epoch 36.624), train_loss = 1.01762623, grad/param norm = 1.7504e-01, time/batch = 0.6876s	
22195/30300 (epoch 36.625), train_loss = 1.02600294, grad/param norm = 1.9155e-01, time/batch = 0.6848s	
22196/30300 (epoch 36.627), train_loss = 1.11496611, grad/param norm = 1.8193e-01, time/batch = 0.6857s	
22197/30300 (epoch 36.629), train_loss = 1.15447908, grad/param norm = 1.5684e-01, time/batch = 0.6833s	
22198/30300 (epoch 36.630), train_loss = 1.03665279, grad/param norm = 1.6931e-01, time/batch = 0.6826s	
22199/30300 (epoch 36.632), train_loss = 1.08358302, grad/param norm = 1.8509e-01, time/batch = 0.6851s	
22200/30300 (epoch 36.634), train_loss = 0.95695576, grad/param norm = 1.5460e-01, time/batch = 0.7013s	
22201/30300 (epoch 36.635), train_loss = 1.08528364, grad/param norm = 1.9629e-01, time/batch = 0.7143s	
22202/30300 (epoch 36.637), train_loss = 1.11775294, grad/param norm = 2.0416e-01, time/batch = 0.7222s	
22203/30300 (epoch 36.639), train_loss = 1.00847273, grad/param norm = 1.7131e-01, time/batch = 0.7135s	
22204/30300 (epoch 36.640), train_loss = 1.12119750, grad/param norm = 1.8360e-01, time/batch = 0.7006s	
22205/30300 (epoch 36.642), train_loss = 1.01268108, grad/param norm = 1.5257e-01, time/batch = 0.6843s	
22206/30300 (epoch 36.644), train_loss = 1.10324021, grad/param norm = 1.8084e-01, time/batch = 0.6801s	
22207/30300 (epoch 36.645), train_loss = 0.96887117, grad/param norm = 1.4470e-01, time/batch = 0.6840s	
22208/30300 (epoch 36.647), train_loss = 1.04775293, grad/param norm = 1.6279e-01, time/batch = 0.6873s	
22209/30300 (epoch 36.649), train_loss = 1.00311497, grad/param norm = 1.7410e-01, time/batch = 0.6944s	
22210/30300 (epoch 36.650), train_loss = 1.01735687, grad/param norm = 1.6285e-01, time/batch = 0.6789s	
22211/30300 (epoch 36.652), train_loss = 0.99173886, grad/param norm = 1.7333e-01, time/batch = 0.6845s	
22212/30300 (epoch 36.653), train_loss = 1.19635681, grad/param norm = 1.5273e-01, time/batch = 0.6825s	
22213/30300 (epoch 36.655), train_loss = 1.02153494, grad/param norm = 1.9066e-01, time/batch = 0.6839s	
22214/30300 (epoch 36.657), train_loss = 0.96236450, grad/param norm = 1.7928e-01, time/batch = 0.6845s	
22215/30300 (epoch 36.658), train_loss = 0.98807802, grad/param norm = 1.6126e-01, time/batch = 0.6854s	
22216/30300 (epoch 36.660), train_loss = 1.03139632, grad/param norm = 1.6444e-01, time/batch = 0.6844s	
22217/30300 (epoch 36.662), train_loss = 1.04715069, grad/param norm = 2.0644e-01, time/batch = 0.6822s	
22218/30300 (epoch 36.663), train_loss = 1.10695238, grad/param norm = 1.7158e-01, time/batch = 0.6824s	
22219/30300 (epoch 36.665), train_loss = 0.98033365, grad/param norm = 1.8385e-01, time/batch = 0.6830s	
22220/30300 (epoch 36.667), train_loss = 1.09250604, grad/param norm = 1.7048e-01, time/batch = 0.6814s	
22221/30300 (epoch 36.668), train_loss = 1.11744605, grad/param norm = 1.7233e-01, time/batch = 0.6861s	
22222/30300 (epoch 36.670), train_loss = 1.14858654, grad/param norm = 1.7816e-01, time/batch = 0.6847s	
22223/30300 (epoch 36.672), train_loss = 1.04798899, grad/param norm = 1.7061e-01, time/batch = 0.6887s	
22224/30300 (epoch 36.673), train_loss = 1.08934489, grad/param norm = 1.9667e-01, time/batch = 0.6833s	
22225/30300 (epoch 36.675), train_loss = 1.01516034, grad/param norm = 1.9423e-01, time/batch = 0.6805s	
22226/30300 (epoch 36.677), train_loss = 0.97711095, grad/param norm = 1.3996e-01, time/batch = 0.6805s	
22227/30300 (epoch 36.678), train_loss = 0.97978500, grad/param norm = 1.6032e-01, time/batch = 0.6815s	
22228/30300 (epoch 36.680), train_loss = 0.92238490, grad/param norm = 1.5269e-01, time/batch = 0.7007s	
22229/30300 (epoch 36.682), train_loss = 1.02138986, grad/param norm = 1.9003e-01, time/batch = 0.7217s	
22230/30300 (epoch 36.683), train_loss = 1.12715195, grad/param norm = 1.6731e-01, time/batch = 0.6852s	
22231/30300 (epoch 36.685), train_loss = 1.06952109, grad/param norm = 1.8998e-01, time/batch = 0.6865s	
22232/30300 (epoch 36.686), train_loss = 1.00080827, grad/param norm = 1.5051e-01, time/batch = 0.6826s	
22233/30300 (epoch 36.688), train_loss = 1.02886154, grad/param norm = 1.5604e-01, time/batch = 0.6833s	
22234/30300 (epoch 36.690), train_loss = 0.96941870, grad/param norm = 1.6849e-01, time/batch = 0.6947s	
22235/30300 (epoch 36.691), train_loss = 1.05651797, grad/param norm = 2.2435e-01, time/batch = 0.7039s	
22236/30300 (epoch 36.693), train_loss = 1.30371127, grad/param norm = 2.0107e-01, time/batch = 0.7066s	
22237/30300 (epoch 36.695), train_loss = 1.10125119, grad/param norm = 1.6950e-01, time/batch = 0.6850s	
22238/30300 (epoch 36.696), train_loss = 1.10382709, grad/param norm = 2.2092e-01, time/batch = 0.7150s	
22239/30300 (epoch 36.698), train_loss = 0.98921408, grad/param norm = 1.7350e-01, time/batch = 0.6915s	
22240/30300 (epoch 36.700), train_loss = 0.96131024, grad/param norm = 1.6989e-01, time/batch = 0.6895s	
22241/30300 (epoch 36.701), train_loss = 0.89491178, grad/param norm = 1.5578e-01, time/batch = 0.6895s	
22242/30300 (epoch 36.703), train_loss = 1.03594839, grad/param norm = 1.5646e-01, time/batch = 0.6869s	
22243/30300 (epoch 36.705), train_loss = 0.96272977, grad/param norm = 1.5696e-01, time/batch = 0.6848s	
22244/30300 (epoch 36.706), train_loss = 1.08946381, grad/param norm = 1.8218e-01, time/batch = 0.6956s	
22245/30300 (epoch 36.708), train_loss = 1.03454332, grad/param norm = 1.6179e-01, time/batch = 0.6896s	
22246/30300 (epoch 36.710), train_loss = 1.01498913, grad/param norm = 1.7285e-01, time/batch = 0.6836s	
22247/30300 (epoch 36.711), train_loss = 0.98060852, grad/param norm = 1.7119e-01, time/batch = 0.7176s	
22248/30300 (epoch 36.713), train_loss = 0.97011947, grad/param norm = 1.7729e-01, time/batch = 0.7063s	
22249/30300 (epoch 36.715), train_loss = 0.98452569, grad/param norm = 1.8418e-01, time/batch = 0.6802s	
22250/30300 (epoch 36.716), train_loss = 1.09629984, grad/param norm = 1.6779e-01, time/batch = 0.6809s	
22251/30300 (epoch 36.718), train_loss = 1.12992325, grad/param norm = 1.6354e-01, time/batch = 0.6848s	
22252/30300 (epoch 36.719), train_loss = 0.97307452, grad/param norm = 1.8450e-01, time/batch = 0.6855s	
22253/30300 (epoch 36.721), train_loss = 1.01599747, grad/param norm = 1.7884e-01, time/batch = 0.6863s	
22254/30300 (epoch 36.723), train_loss = 0.94864932, grad/param norm = 1.4794e-01, time/batch = 0.6813s	
22255/30300 (epoch 36.724), train_loss = 1.06502521, grad/param norm = 2.0381e-01, time/batch = 0.6809s	
22256/30300 (epoch 36.726), train_loss = 1.31649028, grad/param norm = 2.2437e-01, time/batch = 0.6815s	
22257/30300 (epoch 36.728), train_loss = 1.07351857, grad/param norm = 1.7981e-01, time/batch = 0.6813s	
22258/30300 (epoch 36.729), train_loss = 0.98526420, grad/param norm = 1.6418e-01, time/batch = 0.6812s	
22259/30300 (epoch 36.731), train_loss = 1.00282166, grad/param norm = 1.7749e-01, time/batch = 0.6818s	
22260/30300 (epoch 36.733), train_loss = 1.04699919, grad/param norm = 1.7454e-01, time/batch = 0.6900s	
22261/30300 (epoch 36.734), train_loss = 1.11864925, grad/param norm = 1.6172e-01, time/batch = 0.7014s	
22262/30300 (epoch 36.736), train_loss = 1.04605005, grad/param norm = 1.6000e-01, time/batch = 0.6814s	
22263/30300 (epoch 36.738), train_loss = 0.96566764, grad/param norm = 1.4225e-01, time/batch = 0.6824s	
22264/30300 (epoch 36.739), train_loss = 1.11804687, grad/param norm = 1.8207e-01, time/batch = 0.6807s	
22265/30300 (epoch 36.741), train_loss = 1.18776855, grad/param norm = 1.9341e-01, time/batch = 0.6823s	
22266/30300 (epoch 36.743), train_loss = 1.00044070, grad/param norm = 1.6699e-01, time/batch = 0.6827s	
22267/30300 (epoch 36.744), train_loss = 1.06956463, grad/param norm = 2.0673e-01, time/batch = 0.6835s	
22268/30300 (epoch 36.746), train_loss = 0.99834154, grad/param norm = 1.4691e-01, time/batch = 0.6854s	
22269/30300 (epoch 36.748), train_loss = 1.02338464, grad/param norm = 2.0789e-01, time/batch = 0.6826s	
22270/30300 (epoch 36.749), train_loss = 1.05457252, grad/param norm = 1.8137e-01, time/batch = 0.6805s	
22271/30300 (epoch 36.751), train_loss = 1.07531739, grad/param norm = 1.6574e-01, time/batch = 0.6837s	
22272/30300 (epoch 36.752), train_loss = 1.01395215, grad/param norm = 1.6926e-01, time/batch = 0.6828s	
22273/30300 (epoch 36.754), train_loss = 1.01535366, grad/param norm = 1.5486e-01, time/batch = 0.6824s	
22274/30300 (epoch 36.756), train_loss = 1.01714805, grad/param norm = 1.6520e-01, time/batch = 0.6838s	
22275/30300 (epoch 36.757), train_loss = 0.97690213, grad/param norm = 1.6458e-01, time/batch = 0.6911s	
22276/30300 (epoch 36.759), train_loss = 1.05522322, grad/param norm = 1.5607e-01, time/batch = 0.6998s	
22277/30300 (epoch 36.761), train_loss = 0.90209201, grad/param norm = 1.5123e-01, time/batch = 0.7019s	
22278/30300 (epoch 36.762), train_loss = 0.91732246, grad/param norm = 1.4603e-01, time/batch = 0.7143s	
22279/30300 (epoch 36.764), train_loss = 1.00395792, grad/param norm = 1.7507e-01, time/batch = 0.7080s	
22280/30300 (epoch 36.766), train_loss = 1.14945341, grad/param norm = 1.8707e-01, time/batch = 0.7368s	
22281/30300 (epoch 36.767), train_loss = 1.07117380, grad/param norm = 2.2609e-01, time/batch = 0.7307s	
22282/30300 (epoch 36.769), train_loss = 1.05222999, grad/param norm = 1.8795e-01, time/batch = 0.7089s	
22283/30300 (epoch 36.771), train_loss = 0.99701561, grad/param norm = 2.1082e-01, time/batch = 0.7276s	
22284/30300 (epoch 36.772), train_loss = 1.04990634, grad/param norm = 1.8115e-01, time/batch = 0.7062s	
22285/30300 (epoch 36.774), train_loss = 1.18579854, grad/param norm = 1.7185e-01, time/batch = 0.6894s	
22286/30300 (epoch 36.776), train_loss = 0.99548499, grad/param norm = 1.8356e-01, time/batch = 0.6875s	
22287/30300 (epoch 36.777), train_loss = 1.15195542, grad/param norm = 1.6402e-01, time/batch = 0.6845s	
22288/30300 (epoch 36.779), train_loss = 1.15026050, grad/param norm = 1.9099e-01, time/batch = 0.6821s	
22289/30300 (epoch 36.781), train_loss = 1.05349206, grad/param norm = 1.7486e-01, time/batch = 0.6819s	
22290/30300 (epoch 36.782), train_loss = 0.97404516, grad/param norm = 2.0779e-01, time/batch = 0.6817s	
22291/30300 (epoch 36.784), train_loss = 0.99024708, grad/param norm = 1.6019e-01, time/batch = 0.6858s	
22292/30300 (epoch 36.785), train_loss = 1.12278910, grad/param norm = 2.0822e-01, time/batch = 0.6808s	
22293/30300 (epoch 36.787), train_loss = 0.88149555, grad/param norm = 1.5640e-01, time/batch = 0.6817s	
22294/30300 (epoch 36.789), train_loss = 1.20313560, grad/param norm = 1.9760e-01, time/batch = 0.6830s	
22295/30300 (epoch 36.790), train_loss = 1.05840620, grad/param norm = 2.0383e-01, time/batch = 0.7282s	
22296/30300 (epoch 36.792), train_loss = 0.85810562, grad/param norm = 1.7717e-01, time/batch = 0.6917s	
22297/30300 (epoch 36.794), train_loss = 1.02062030, grad/param norm = 1.6542e-01, time/batch = 0.6842s	
22298/30300 (epoch 36.795), train_loss = 0.96224060, grad/param norm = 1.4732e-01, time/batch = 0.6856s	
22299/30300 (epoch 36.797), train_loss = 1.15935142, grad/param norm = 1.8964e-01, time/batch = 0.7252s	
22300/30300 (epoch 36.799), train_loss = 1.12771095, grad/param norm = 2.1515e-01, time/batch = 0.6996s	
22301/30300 (epoch 36.800), train_loss = 1.11713617, grad/param norm = 1.8594e-01, time/batch = 0.6837s	
22302/30300 (epoch 36.802), train_loss = 1.29431530, grad/param norm = 3.5971e-01, time/batch = 0.6894s	
22303/30300 (epoch 36.804), train_loss = 1.11525826, grad/param norm = 1.9567e-01, time/batch = 0.6855s	
22304/30300 (epoch 36.805), train_loss = 1.17987852, grad/param norm = 1.8922e-01, time/batch = 0.6838s	
22305/30300 (epoch 36.807), train_loss = 1.00627460, grad/param norm = 1.9204e-01, time/batch = 0.6836s	
22306/30300 (epoch 36.809), train_loss = 1.13550629, grad/param norm = 2.0205e-01, time/batch = 0.6925s	
22307/30300 (epoch 36.810), train_loss = 1.08176351, grad/param norm = 1.6885e-01, time/batch = 0.6851s	
22308/30300 (epoch 36.812), train_loss = 0.99631423, grad/param norm = 1.7624e-01, time/batch = 0.6831s	
22309/30300 (epoch 36.814), train_loss = 1.04641743, grad/param norm = 1.7455e-01, time/batch = 0.6852s	
22310/30300 (epoch 36.815), train_loss = 1.04549826, grad/param norm = 1.8808e-01, time/batch = 0.6847s	
22311/30300 (epoch 36.817), train_loss = 1.11710202, grad/param norm = 1.8237e-01, time/batch = 0.6877s	
22312/30300 (epoch 36.818), train_loss = 1.06097506, grad/param norm = 1.6615e-01, time/batch = 0.6851s	
22313/30300 (epoch 36.820), train_loss = 1.24344931, grad/param norm = 3.8313e-01, time/batch = 0.6865s	
22314/30300 (epoch 36.822), train_loss = 1.20893043, grad/param norm = 2.0338e-01, time/batch = 0.6859s	
22315/30300 (epoch 36.823), train_loss = 1.20221314, grad/param norm = 1.8940e-01, time/batch = 0.6833s	
22316/30300 (epoch 36.825), train_loss = 1.16676157, grad/param norm = 1.7611e-01, time/batch = 0.6822s	
22317/30300 (epoch 36.827), train_loss = 0.90674236, grad/param norm = 2.0398e-01, time/batch = 0.6911s	
22318/30300 (epoch 36.828), train_loss = 1.14234532, grad/param norm = 1.7504e-01, time/batch = 0.6841s	
22319/30300 (epoch 36.830), train_loss = 1.09686174, grad/param norm = 1.8286e-01, time/batch = 0.6810s	
22320/30300 (epoch 36.832), train_loss = 0.97298917, grad/param norm = 1.6511e-01, time/batch = 0.6826s	
22321/30300 (epoch 36.833), train_loss = 1.06851463, grad/param norm = 1.7381e-01, time/batch = 0.6964s	
22322/30300 (epoch 36.835), train_loss = 0.97531067, grad/param norm = 1.6589e-01, time/batch = 0.6971s	
22323/30300 (epoch 36.837), train_loss = 0.95790599, grad/param norm = 1.8988e-01, time/batch = 0.6942s	
22324/30300 (epoch 36.838), train_loss = 0.96819780, grad/param norm = 1.7196e-01, time/batch = 0.6969s	
22325/30300 (epoch 36.840), train_loss = 1.12923760, grad/param norm = 1.5817e-01, time/batch = 0.6980s	
22326/30300 (epoch 36.842), train_loss = 1.00756962, grad/param norm = 1.5243e-01, time/batch = 0.6889s	
22327/30300 (epoch 36.843), train_loss = 1.09055051, grad/param norm = 2.0372e-01, time/batch = 0.6892s	
22328/30300 (epoch 36.845), train_loss = 1.09326854, grad/param norm = 1.5621e-01, time/batch = 0.6886s	
22329/30300 (epoch 36.847), train_loss = 1.05231474, grad/param norm = 1.7605e-01, time/batch = 0.6950s	
22330/30300 (epoch 36.848), train_loss = 1.09205354, grad/param norm = 1.7966e-01, time/batch = 0.6944s	
22331/30300 (epoch 36.850), train_loss = 1.03354710, grad/param norm = 1.6377e-01, time/batch = 0.6883s	
22332/30300 (epoch 36.851), train_loss = 1.07500811, grad/param norm = 1.9491e-01, time/batch = 0.6872s	
22333/30300 (epoch 36.853), train_loss = 0.99825736, grad/param norm = 1.5945e-01, time/batch = 0.6837s	
22334/30300 (epoch 36.855), train_loss = 1.00235779, grad/param norm = 1.5748e-01, time/batch = 0.6835s	
22335/30300 (epoch 36.856), train_loss = 1.05641799, grad/param norm = 1.7247e-01, time/batch = 0.6857s	
22336/30300 (epoch 36.858), train_loss = 0.96209220, grad/param norm = 1.4716e-01, time/batch = 0.7096s	
22337/30300 (epoch 36.860), train_loss = 0.95793641, grad/param norm = 1.6136e-01, time/batch = 0.7294s	
22338/30300 (epoch 36.861), train_loss = 1.19004976, grad/param norm = 1.7190e-01, time/batch = 0.6859s	
22339/30300 (epoch 36.863), train_loss = 1.01094593, grad/param norm = 1.6506e-01, time/batch = 0.6850s	
22340/30300 (epoch 36.865), train_loss = 1.11147778, grad/param norm = 1.8828e-01, time/batch = 0.6841s	
22341/30300 (epoch 36.866), train_loss = 1.11642411, grad/param norm = 1.9078e-01, time/batch = 0.6849s	
22342/30300 (epoch 36.868), train_loss = 1.06570911, grad/param norm = 1.5561e-01, time/batch = 0.6846s	
22343/30300 (epoch 36.870), train_loss = 0.98745603, grad/param norm = 1.7218e-01, time/batch = 0.6885s	
22344/30300 (epoch 36.871), train_loss = 1.05506421, grad/param norm = 1.7669e-01, time/batch = 0.6975s	
22345/30300 (epoch 36.873), train_loss = 1.04615833, grad/param norm = 1.6775e-01, time/batch = 0.6895s	
22346/30300 (epoch 36.875), train_loss = 1.01828825, grad/param norm = 1.4361e-01, time/batch = 0.6856s	
22347/30300 (epoch 36.876), train_loss = 0.94885612, grad/param norm = 1.9073e-01, time/batch = 0.6820s	
22348/30300 (epoch 36.878), train_loss = 0.87962625, grad/param norm = 1.5305e-01, time/batch = 0.6864s	
22349/30300 (epoch 36.880), train_loss = 0.97067866, grad/param norm = 1.6505e-01, time/batch = 0.6857s	
22350/30300 (epoch 36.881), train_loss = 1.20329491, grad/param norm = 2.0235e-01, time/batch = 0.6831s	
22351/30300 (epoch 36.883), train_loss = 1.11695791, grad/param norm = 1.9116e-01, time/batch = 0.6872s	
22352/30300 (epoch 36.884), train_loss = 1.02981419, grad/param norm = 1.5903e-01, time/batch = 0.6856s	
22353/30300 (epoch 36.886), train_loss = 1.10104454, grad/param norm = 1.7998e-01, time/batch = 0.6831s	
22354/30300 (epoch 36.888), train_loss = 1.00480745, grad/param norm = 1.8277e-01, time/batch = 0.6835s	
22355/30300 (epoch 36.889), train_loss = 1.05809339, grad/param norm = 1.6331e-01, time/batch = 0.7122s	
22356/30300 (epoch 36.891), train_loss = 1.02655111, grad/param norm = 2.1536e-01, time/batch = 0.7126s	
22357/30300 (epoch 36.893), train_loss = 1.23699409, grad/param norm = 1.7430e-01, time/batch = 0.6836s	
22358/30300 (epoch 36.894), train_loss = 1.07197658, grad/param norm = 1.6868e-01, time/batch = 0.6848s	
22359/30300 (epoch 36.896), train_loss = 0.89501403, grad/param norm = 1.5504e-01, time/batch = 0.6827s	
22360/30300 (epoch 36.898), train_loss = 0.90448915, grad/param norm = 1.6151e-01, time/batch = 0.6813s	
22361/30300 (epoch 36.899), train_loss = 0.94078498, grad/param norm = 1.6680e-01, time/batch = 0.6877s	
22362/30300 (epoch 36.901), train_loss = 1.05095975, grad/param norm = 1.8198e-01, time/batch = 0.6868s	
22363/30300 (epoch 36.903), train_loss = 1.02731218, grad/param norm = 2.2247e-01, time/batch = 0.6836s	
22364/30300 (epoch 36.904), train_loss = 1.06434602, grad/param norm = 1.7228e-01, time/batch = 0.6835s	
22365/30300 (epoch 36.906), train_loss = 1.05877180, grad/param norm = 1.8173e-01, time/batch = 0.6838s	
22366/30300 (epoch 36.908), train_loss = 0.98434080, grad/param norm = 1.6168e-01, time/batch = 0.6849s	
22367/30300 (epoch 36.909), train_loss = 0.99227887, grad/param norm = 2.2384e-01, time/batch = 0.6831s	
22368/30300 (epoch 36.911), train_loss = 1.04016340, grad/param norm = 1.5759e-01, time/batch = 0.6836s	
22369/30300 (epoch 36.913), train_loss = 1.04567443, grad/param norm = 1.6020e-01, time/batch = 0.6921s	
22370/30300 (epoch 36.914), train_loss = 1.02495586, grad/param norm = 2.2798e-01, time/batch = 0.7265s	
22371/30300 (epoch 36.916), train_loss = 1.07254295, grad/param norm = 1.5055e-01, time/batch = 0.6909s	
22372/30300 (epoch 36.917), train_loss = 1.00108458, grad/param norm = 1.6130e-01, time/batch = 0.6864s	
22373/30300 (epoch 36.919), train_loss = 0.94999521, grad/param norm = 1.7265e-01, time/batch = 0.6894s	
22374/30300 (epoch 36.921), train_loss = 1.01388167, grad/param norm = 1.5313e-01, time/batch = 0.6920s	
22375/30300 (epoch 36.922), train_loss = 1.12055440, grad/param norm = 1.8038e-01, time/batch = 0.6998s	
22376/30300 (epoch 36.924), train_loss = 1.03470076, grad/param norm = 1.7993e-01, time/batch = 0.7009s	
22377/30300 (epoch 36.926), train_loss = 1.08521485, grad/param norm = 1.7214e-01, time/batch = 0.7040s	
22378/30300 (epoch 36.927), train_loss = 1.06330718, grad/param norm = 1.6510e-01, time/batch = 0.7159s	
22379/30300 (epoch 36.929), train_loss = 0.97334295, grad/param norm = 1.6762e-01, time/batch = 0.7149s	
22380/30300 (epoch 36.931), train_loss = 1.12459446, grad/param norm = 2.1039e-01, time/batch = 0.7143s	
22381/30300 (epoch 36.932), train_loss = 0.95778900, grad/param norm = 1.5970e-01, time/batch = 0.7156s	
22382/30300 (epoch 36.934), train_loss = 1.07128966, grad/param norm = 1.6376e-01, time/batch = 0.7125s	
22383/30300 (epoch 36.936), train_loss = 0.97601599, grad/param norm = 1.6794e-01, time/batch = 0.6887s	
22384/30300 (epoch 36.937), train_loss = 0.97673132, grad/param norm = 1.5348e-01, time/batch = 0.6862s	
22385/30300 (epoch 36.939), train_loss = 1.15031341, grad/param norm = 1.8732e-01, time/batch = 0.6945s	
22386/30300 (epoch 36.941), train_loss = 1.01971730, grad/param norm = 1.7921e-01, time/batch = 0.6956s	
22387/30300 (epoch 36.942), train_loss = 1.03684615, grad/param norm = 1.7324e-01, time/batch = 0.6888s	
22388/30300 (epoch 36.944), train_loss = 0.92423977, grad/param norm = 1.6450e-01, time/batch = 0.7145s	
22389/30300 (epoch 36.946), train_loss = 1.09149360, grad/param norm = 2.0369e-01, time/batch = 0.7168s	
22390/30300 (epoch 36.947), train_loss = 1.09009026, grad/param norm = 2.2642e-01, time/batch = 0.6939s	
22391/30300 (epoch 36.949), train_loss = 1.11935879, grad/param norm = 2.1168e-01, time/batch = 0.6864s	
22392/30300 (epoch 36.950), train_loss = 1.15085128, grad/param norm = 1.8662e-01, time/batch = 0.6821s	
22393/30300 (epoch 36.952), train_loss = 1.07822458, grad/param norm = 1.7947e-01, time/batch = 0.6825s	
22394/30300 (epoch 36.954), train_loss = 1.29179813, grad/param norm = 1.6916e-01, time/batch = 0.6844s	
22395/30300 (epoch 36.955), train_loss = 1.01745461, grad/param norm = 1.5302e-01, time/batch = 0.6925s	
22396/30300 (epoch 36.957), train_loss = 1.10747018, grad/param norm = 1.8170e-01, time/batch = 0.6943s	
22397/30300 (epoch 36.959), train_loss = 0.95952282, grad/param norm = 1.9470e-01, time/batch = 0.7327s	
22398/30300 (epoch 36.960), train_loss = 1.00012355, grad/param norm = 1.7734e-01, time/batch = 0.7155s	
22399/30300 (epoch 36.962), train_loss = 0.99558778, grad/param norm = 1.9461e-01, time/batch = 0.7337s	
22400/30300 (epoch 36.964), train_loss = 0.96389147, grad/param norm = 2.1427e-01, time/batch = 0.7118s	
22401/30300 (epoch 36.965), train_loss = 1.00464966, grad/param norm = 2.3167e-01, time/batch = 0.6878s	
22402/30300 (epoch 36.967), train_loss = 1.01826323, grad/param norm = 2.1297e-01, time/batch = 0.7097s	
22403/30300 (epoch 36.969), train_loss = 0.96158778, grad/param norm = 2.0888e-01, time/batch = 0.7172s	
22404/30300 (epoch 36.970), train_loss = 1.02038708, grad/param norm = 1.7807e-01, time/batch = 0.6806s	
22405/30300 (epoch 36.972), train_loss = 0.92851160, grad/param norm = 1.7293e-01, time/batch = 0.6808s	
22406/30300 (epoch 36.974), train_loss = 1.18009502, grad/param norm = 1.9710e-01, time/batch = 0.6838s	
22407/30300 (epoch 36.975), train_loss = 1.17049925, grad/param norm = 2.1727e-01, time/batch = 0.7016s	
22408/30300 (epoch 36.977), train_loss = 1.21151294, grad/param norm = 1.7916e-01, time/batch = 0.7000s	
22409/30300 (epoch 36.979), train_loss = 1.11428397, grad/param norm = 1.9299e-01, time/batch = 0.7010s	
22410/30300 (epoch 36.980), train_loss = 1.14338197, grad/param norm = 1.8811e-01, time/batch = 0.7148s	
22411/30300 (epoch 36.982), train_loss = 1.15338915, grad/param norm = 1.8416e-01, time/batch = 0.6894s	
22412/30300 (epoch 36.983), train_loss = 1.15554727, grad/param norm = 1.6250e-01, time/batch = 0.6857s	
22413/30300 (epoch 36.985), train_loss = 1.10550199, grad/param norm = 2.0857e-01, time/batch = 0.6915s	
22414/30300 (epoch 36.987), train_loss = 1.05467213, grad/param norm = 1.6816e-01, time/batch = 0.7042s	
22415/30300 (epoch 36.988), train_loss = 1.16866910, grad/param norm = 1.8780e-01, time/batch = 0.6909s	
22416/30300 (epoch 36.990), train_loss = 0.96667769, grad/param norm = 1.7418e-01, time/batch = 0.6947s	
22417/30300 (epoch 36.992), train_loss = 1.12461833, grad/param norm = 1.5345e-01, time/batch = 0.7257s	
22418/30300 (epoch 36.993), train_loss = 1.15581058, grad/param norm = 2.2682e-01, time/batch = 0.6889s	
22419/30300 (epoch 36.995), train_loss = 1.05870382, grad/param norm = 2.1627e-01, time/batch = 0.6866s	
22420/30300 (epoch 36.997), train_loss = 1.10016198, grad/param norm = 2.3245e-01, time/batch = 0.6885s	
22421/30300 (epoch 36.998), train_loss = 1.10236700, grad/param norm = 1.7992e-01, time/batch = 0.6910s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
22422/30300 (epoch 37.000), train_loss = 1.00196612, grad/param norm = 1.8982e-01, time/batch = 0.7087s	
22423/30300 (epoch 37.002), train_loss = 1.15379256, grad/param norm = 2.0269e-01, time/batch = 0.6931s	
22424/30300 (epoch 37.003), train_loss = 1.07266065, grad/param norm = 1.7305e-01, time/batch = 0.6909s	
22425/30300 (epoch 37.005), train_loss = 1.01865196, grad/param norm = 1.7024e-01, time/batch = 0.6922s	
22426/30300 (epoch 37.007), train_loss = 1.09806233, grad/param norm = 1.8915e-01, time/batch = 0.6857s	
22427/30300 (epoch 37.008), train_loss = 1.03309488, grad/param norm = 2.1002e-01, time/batch = 0.6870s	
22428/30300 (epoch 37.010), train_loss = 0.93388773, grad/param norm = 1.9763e-01, time/batch = 0.6938s	
22429/30300 (epoch 37.012), train_loss = 1.00579315, grad/param norm = 1.7918e-01, time/batch = 0.6855s	
22430/30300 (epoch 37.013), train_loss = 1.12473889, grad/param norm = 1.8397e-01, time/batch = 0.6851s	
22431/30300 (epoch 37.015), train_loss = 0.99798896, grad/param norm = 1.5552e-01, time/batch = 0.6851s	
22432/30300 (epoch 37.017), train_loss = 1.00658232, grad/param norm = 1.5207e-01, time/batch = 0.6852s	
22433/30300 (epoch 37.018), train_loss = 0.95343871, grad/param norm = 1.6147e-01, time/batch = 0.6827s	
22434/30300 (epoch 37.020), train_loss = 1.13851061, grad/param norm = 1.9493e-01, time/batch = 0.6818s	
22435/30300 (epoch 37.021), train_loss = 1.16596619, grad/param norm = 1.7856e-01, time/batch = 0.7179s	
22436/30300 (epoch 37.023), train_loss = 1.05144337, grad/param norm = 1.5155e-01, time/batch = 0.7212s	
22437/30300 (epoch 37.025), train_loss = 0.97117602, grad/param norm = 1.9791e-01, time/batch = 0.6811s	
22438/30300 (epoch 37.026), train_loss = 1.10651637, grad/param norm = 1.9667e-01, time/batch = 0.6806s	
22439/30300 (epoch 37.028), train_loss = 1.12929317, grad/param norm = 1.7122e-01, time/batch = 0.6845s	
22440/30300 (epoch 37.030), train_loss = 1.01300087, grad/param norm = 1.9465e-01, time/batch = 0.6880s	
22441/30300 (epoch 37.031), train_loss = 1.08271317, grad/param norm = 1.6491e-01, time/batch = 0.6867s	
22442/30300 (epoch 37.033), train_loss = 1.06247728, grad/param norm = 1.7540e-01, time/batch = 0.6898s	
22443/30300 (epoch 37.035), train_loss = 1.09866399, grad/param norm = 1.7685e-01, time/batch = 0.6915s	
22444/30300 (epoch 37.036), train_loss = 1.07766100, grad/param norm = 2.0648e-01, time/batch = 0.7001s	
22445/30300 (epoch 37.038), train_loss = 1.09152452, grad/param norm = 1.6092e-01, time/batch = 0.6816s	
22446/30300 (epoch 37.040), train_loss = 0.88638289, grad/param norm = 1.6154e-01, time/batch = 0.6809s	
22447/30300 (epoch 37.041), train_loss = 0.88977112, grad/param norm = 1.7403e-01, time/batch = 0.6814s	
22448/30300 (epoch 37.043), train_loss = 1.07372574, grad/param norm = 1.9715e-01, time/batch = 0.6829s	
22449/30300 (epoch 37.045), train_loss = 0.98868815, grad/param norm = 1.5322e-01, time/batch = 0.6810s	
22450/30300 (epoch 37.046), train_loss = 1.17938946, grad/param norm = 2.0262e-01, time/batch = 0.6809s	
22451/30300 (epoch 37.048), train_loss = 1.04786918, grad/param norm = 2.1324e-01, time/batch = 0.6823s	
22452/30300 (epoch 37.050), train_loss = 0.97375895, grad/param norm = 1.7608e-01, time/batch = 0.6812s	
22453/30300 (epoch 37.051), train_loss = 1.09523851, grad/param norm = 1.8373e-01, time/batch = 0.6811s	
22454/30300 (epoch 37.053), train_loss = 0.92269866, grad/param norm = 2.2654e-01, time/batch = 0.7155s	
22455/30300 (epoch 37.054), train_loss = 1.08871995, grad/param norm = 1.6814e-01, time/batch = 0.7100s	
22456/30300 (epoch 37.056), train_loss = 0.96546583, grad/param norm = 1.6702e-01, time/batch = 0.6835s	
22457/30300 (epoch 37.058), train_loss = 1.01358798, grad/param norm = 1.6656e-01, time/batch = 0.6802s	
22458/30300 (epoch 37.059), train_loss = 1.00119544, grad/param norm = 1.9838e-01, time/batch = 0.6813s	
22459/30300 (epoch 37.061), train_loss = 1.09005459, grad/param norm = 1.7446e-01, time/batch = 0.6857s	
22460/30300 (epoch 37.063), train_loss = 0.92892257, grad/param norm = 1.6368e-01, time/batch = 0.6912s	
22461/30300 (epoch 37.064), train_loss = 1.05127519, grad/param norm = 1.9265e-01, time/batch = 0.7085s	
22462/30300 (epoch 37.066), train_loss = 1.05082319, grad/param norm = 1.4727e-01, time/batch = 0.7121s	
22463/30300 (epoch 37.068), train_loss = 0.95750150, grad/param norm = 1.5824e-01, time/batch = 0.7308s	
22464/30300 (epoch 37.069), train_loss = 1.10073813, grad/param norm = 1.7501e-01, time/batch = 0.7313s	
22465/30300 (epoch 37.071), train_loss = 1.10196909, grad/param norm = 1.8882e-01, time/batch = 0.7192s	
22466/30300 (epoch 37.073), train_loss = 0.96474771, grad/param norm = 1.7883e-01, time/batch = 0.6883s	
22467/30300 (epoch 37.074), train_loss = 1.02057739, grad/param norm = 1.5722e-01, time/batch = 0.6939s	
22468/30300 (epoch 37.076), train_loss = 1.02614400, grad/param norm = 1.7215e-01, time/batch = 0.7135s	
22469/30300 (epoch 37.078), train_loss = 0.97383827, grad/param norm = 1.5190e-01, time/batch = 0.7013s	
22470/30300 (epoch 37.079), train_loss = 0.99331715, grad/param norm = 1.5622e-01, time/batch = 0.6865s	
22471/30300 (epoch 37.081), train_loss = 1.05527281, grad/param norm = 1.7603e-01, time/batch = 0.6857s	
22472/30300 (epoch 37.083), train_loss = 1.10043416, grad/param norm = 2.0143e-01, time/batch = 0.7045s	
22473/30300 (epoch 37.084), train_loss = 0.97881261, grad/param norm = 1.6251e-01, time/batch = 0.7261s	
22474/30300 (epoch 37.086), train_loss = 0.99111887, grad/param norm = 1.7635e-01, time/batch = 0.6833s	
22475/30300 (epoch 37.087), train_loss = 0.96444819, grad/param norm = 1.5579e-01, time/batch = 0.6812s	
22476/30300 (epoch 37.089), train_loss = 0.97586557, grad/param norm = 1.6820e-01, time/batch = 0.6824s	
22477/30300 (epoch 37.091), train_loss = 1.07029674, grad/param norm = 1.6353e-01, time/batch = 0.6814s	
22478/30300 (epoch 37.092), train_loss = 1.09412338, grad/param norm = 1.5823e-01, time/batch = 0.6837s	
22479/30300 (epoch 37.094), train_loss = 1.15824391, grad/param norm = 2.0042e-01, time/batch = 0.6794s	
22480/30300 (epoch 37.096), train_loss = 1.16224796, grad/param norm = 1.8560e-01, time/batch = 0.6811s	
22481/30300 (epoch 37.097), train_loss = 0.97878866, grad/param norm = 1.7211e-01, time/batch = 0.6816s	
22482/30300 (epoch 37.099), train_loss = 1.11578198, grad/param norm = 1.6574e-01, time/batch = 0.6830s	
22483/30300 (epoch 37.101), train_loss = 1.15399634, grad/param norm = 1.8316e-01, time/batch = 0.6861s	
22484/30300 (epoch 37.102), train_loss = 0.99568365, grad/param norm = 2.1513e-01, time/batch = 0.6880s	
22485/30300 (epoch 37.104), train_loss = 1.01541379, grad/param norm = 2.2980e-01, time/batch = 0.6856s	
22486/30300 (epoch 37.106), train_loss = 1.00673865, grad/param norm = 1.9785e-01, time/batch = 0.6814s	
22487/30300 (epoch 37.107), train_loss = 1.09316205, grad/param norm = 1.6353e-01, time/batch = 0.6820s	
22488/30300 (epoch 37.109), train_loss = 1.12348719, grad/param norm = 2.2391e-01, time/batch = 0.6864s	
22489/30300 (epoch 37.111), train_loss = 1.12414017, grad/param norm = 2.1134e-01, time/batch = 0.6860s	
22490/30300 (epoch 37.112), train_loss = 1.17476056, grad/param norm = 1.8161e-01, time/batch = 0.6844s	
22491/30300 (epoch 37.114), train_loss = 1.01511161, grad/param norm = 1.6934e-01, time/batch = 0.7058s	
22492/30300 (epoch 37.116), train_loss = 1.07948540, grad/param norm = 1.9869e-01, time/batch = 0.7232s	
22493/30300 (epoch 37.117), train_loss = 1.15749805, grad/param norm = 1.7575e-01, time/batch = 0.6927s	
22494/30300 (epoch 37.119), train_loss = 0.96220594, grad/param norm = 1.7307e-01, time/batch = 0.6947s	
22495/30300 (epoch 37.120), train_loss = 1.02704442, grad/param norm = 1.7621e-01, time/batch = 0.7016s	
22496/30300 (epoch 37.122), train_loss = 1.14053278, grad/param norm = 2.0132e-01, time/batch = 0.7269s	
22497/30300 (epoch 37.124), train_loss = 1.20002377, grad/param norm = 1.9901e-01, time/batch = 0.7159s	
22498/30300 (epoch 37.125), train_loss = 0.94981816, grad/param norm = 1.6630e-01, time/batch = 0.6850s	
22499/30300 (epoch 37.127), train_loss = 1.08509066, grad/param norm = 2.0368e-01, time/batch = 0.6877s	
22500/30300 (epoch 37.129), train_loss = 1.15439419, grad/param norm = 1.9160e-01, time/batch = 0.6870s	
22501/30300 (epoch 37.130), train_loss = 1.18247015, grad/param norm = 1.6949e-01, time/batch = 0.6936s	
22502/30300 (epoch 37.132), train_loss = 1.17480558, grad/param norm = 1.7998e-01, time/batch = 0.6843s	
22503/30300 (epoch 37.134), train_loss = 0.97463284, grad/param norm = 1.7695e-01, time/batch = 0.6867s	
22504/30300 (epoch 37.135), train_loss = 1.01610570, grad/param norm = 1.9638e-01, time/batch = 0.6825s	
22505/30300 (epoch 37.137), train_loss = 1.05601782, grad/param norm = 2.2492e-01, time/batch = 0.6886s	
22506/30300 (epoch 37.139), train_loss = 0.97213278, grad/param norm = 1.9541e-01, time/batch = 0.7265s	
22507/30300 (epoch 37.140), train_loss = 1.05472433, grad/param norm = 2.2956e-01, time/batch = 0.6907s	
22508/30300 (epoch 37.142), train_loss = 1.12275042, grad/param norm = 2.0190e-01, time/batch = 0.6899s	
22509/30300 (epoch 37.144), train_loss = 0.97793905, grad/param norm = 2.1642e-01, time/batch = 0.6829s	
22510/30300 (epoch 37.145), train_loss = 1.12234819, grad/param norm = 3.0117e-01, time/batch = 0.6841s	
22511/30300 (epoch 37.147), train_loss = 1.01340286, grad/param norm = 2.0345e-01, time/batch = 0.6877s	
22512/30300 (epoch 37.149), train_loss = 1.14743631, grad/param norm = 2.3558e-01, time/batch = 0.6823s	
22513/30300 (epoch 37.150), train_loss = 1.04643610, grad/param norm = 2.6198e-01, time/batch = 0.6871s	
22514/30300 (epoch 37.152), train_loss = 0.93259652, grad/param norm = 1.8693e-01, time/batch = 0.6899s	
22515/30300 (epoch 37.153), train_loss = 1.06120170, grad/param norm = 1.8053e-01, time/batch = 0.6867s	
22516/30300 (epoch 37.155), train_loss = 0.93178543, grad/param norm = 1.7497e-01, time/batch = 0.6879s	
22517/30300 (epoch 37.157), train_loss = 1.00355898, grad/param norm = 1.9721e-01, time/batch = 0.6959s	
22518/30300 (epoch 37.158), train_loss = 1.09487970, grad/param norm = 1.9974e-01, time/batch = 0.7043s	
22519/30300 (epoch 37.160), train_loss = 0.96300010, grad/param norm = 1.7734e-01, time/batch = 0.7003s	
22520/30300 (epoch 37.162), train_loss = 1.06491333, grad/param norm = 1.6475e-01, time/batch = 0.6956s	
22521/30300 (epoch 37.163), train_loss = 1.04834102, grad/param norm = 2.0143e-01, time/batch = 0.6811s	
22522/30300 (epoch 37.165), train_loss = 1.16519073, grad/param norm = 1.8463e-01, time/batch = 0.6794s	
22523/30300 (epoch 37.167), train_loss = 1.07144307, grad/param norm = 1.8599e-01, time/batch = 0.6805s	
22524/30300 (epoch 37.168), train_loss = 1.10422658, grad/param norm = 1.7450e-01, time/batch = 0.6825s	
22525/30300 (epoch 37.170), train_loss = 1.05620150, grad/param norm = 1.7819e-01, time/batch = 0.6832s	
22526/30300 (epoch 37.172), train_loss = 1.07203147, grad/param norm = 2.1175e-01, time/batch = 0.6806s	
22527/30300 (epoch 37.173), train_loss = 1.01725120, grad/param norm = 1.8284e-01, time/batch = 0.6812s	
22528/30300 (epoch 37.175), train_loss = 1.06849065, grad/param norm = 1.7781e-01, time/batch = 0.6829s	
22529/30300 (epoch 37.177), train_loss = 1.11460485, grad/param norm = 2.7231e-01, time/batch = 0.6895s	
22530/30300 (epoch 37.178), train_loss = 0.86900445, grad/param norm = 1.5015e-01, time/batch = 0.6876s	
22531/30300 (epoch 37.180), train_loss = 1.01893605, grad/param norm = 1.5587e-01, time/batch = 0.6874s	
22532/30300 (epoch 37.182), train_loss = 1.07239029, grad/param norm = 1.9605e-01, time/batch = 0.6849s	
22533/30300 (epoch 37.183), train_loss = 0.99767371, grad/param norm = 1.8110e-01, time/batch = 0.6822s	
22534/30300 (epoch 37.185), train_loss = 1.21326400, grad/param norm = 2.0277e-01, time/batch = 0.6817s	
22535/30300 (epoch 37.186), train_loss = 1.25666555, grad/param norm = 2.2854e-01, time/batch = 0.6830s	
22536/30300 (epoch 37.188), train_loss = 1.10160439, grad/param norm = 2.1317e-01, time/batch = 0.6801s	
22537/30300 (epoch 37.190), train_loss = 1.05330043, grad/param norm = 1.7462e-01, time/batch = 0.6820s	
22538/30300 (epoch 37.191), train_loss = 1.09312742, grad/param norm = 1.9257e-01, time/batch = 0.6831s	
22539/30300 (epoch 37.193), train_loss = 0.97338317, grad/param norm = 1.6137e-01, time/batch = 0.7263s	
22540/30300 (epoch 37.195), train_loss = 1.00809277, grad/param norm = 1.7101e-01, time/batch = 0.7039s	
22541/30300 (epoch 37.196), train_loss = 1.09103716, grad/param norm = 1.5797e-01, time/batch = 0.6846s	
22542/30300 (epoch 37.198), train_loss = 0.88944203, grad/param norm = 1.6904e-01, time/batch = 0.6841s	
22543/30300 (epoch 37.200), train_loss = 1.02773538, grad/param norm = 1.7155e-01, time/batch = 0.6817s	
22544/30300 (epoch 37.201), train_loss = 1.13914045, grad/param norm = 2.1995e-01, time/batch = 0.6859s	
22545/30300 (epoch 37.203), train_loss = 1.04510345, grad/param norm = 1.8118e-01, time/batch = 0.6834s	
22546/30300 (epoch 37.205), train_loss = 1.23065233, grad/param norm = 1.9154e-01, time/batch = 0.6854s	
22547/30300 (epoch 37.206), train_loss = 1.11308528, grad/param norm = 1.9803e-01, time/batch = 0.6809s	
22548/30300 (epoch 37.208), train_loss = 1.11141522, grad/param norm = 2.0337e-01, time/batch = 0.6795s	
22549/30300 (epoch 37.210), train_loss = 1.13239540, grad/param norm = 1.7726e-01, time/batch = 0.6806s	
22550/30300 (epoch 37.211), train_loss = 1.16905041, grad/param norm = 1.7834e-01, time/batch = 0.6791s	
22551/30300 (epoch 37.213), train_loss = 1.04835174, grad/param norm = 1.5278e-01, time/batch = 0.6814s	
22552/30300 (epoch 37.215), train_loss = 0.98745584, grad/param norm = 2.0139e-01, time/batch = 0.6808s	
22553/30300 (epoch 37.216), train_loss = 1.01546806, grad/param norm = 1.9570e-01, time/batch = 0.6993s	
22554/30300 (epoch 37.218), train_loss = 0.97549949, grad/param norm = 1.7057e-01, time/batch = 0.7258s	
22555/30300 (epoch 37.219), train_loss = 0.92133013, grad/param norm = 1.6262e-01, time/batch = 0.6791s	
22556/30300 (epoch 37.221), train_loss = 0.90010402, grad/param norm = 1.5517e-01, time/batch = 0.6789s	
22557/30300 (epoch 37.223), train_loss = 1.05690933, grad/param norm = 1.8702e-01, time/batch = 0.6795s	
22558/30300 (epoch 37.224), train_loss = 0.88826356, grad/param norm = 1.6899e-01, time/batch = 0.6919s	
22559/30300 (epoch 37.226), train_loss = 1.09406246, grad/param norm = 2.0648e-01, time/batch = 0.6938s	
22560/30300 (epoch 37.228), train_loss = 1.14926179, grad/param norm = 1.9205e-01, time/batch = 0.6835s	
22561/30300 (epoch 37.229), train_loss = 1.03246910, grad/param norm = 1.7090e-01, time/batch = 0.6853s	
22562/30300 (epoch 37.231), train_loss = 1.10489822, grad/param norm = 1.8232e-01, time/batch = 0.6835s	
22563/30300 (epoch 37.233), train_loss = 1.10373373, grad/param norm = 1.5547e-01, time/batch = 0.6797s	
22564/30300 (epoch 37.234), train_loss = 1.12438039, grad/param norm = 2.3132e-01, time/batch = 0.6818s	
22565/30300 (epoch 37.236), train_loss = 1.09562658, grad/param norm = 1.5940e-01, time/batch = 0.6839s	
22566/30300 (epoch 37.238), train_loss = 1.06316364, grad/param norm = 2.5255e-01, time/batch = 0.6937s	
22567/30300 (epoch 37.239), train_loss = 1.01863649, grad/param norm = 2.1097e-01, time/batch = 0.6816s	
22568/30300 (epoch 37.241), train_loss = 1.11140441, grad/param norm = 2.0920e-01, time/batch = 0.6823s	
22569/30300 (epoch 37.243), train_loss = 1.07795508, grad/param norm = 1.6765e-01, time/batch = 0.6833s	
22570/30300 (epoch 37.244), train_loss = 1.25002929, grad/param norm = 1.8281e-01, time/batch = 0.6811s	
22571/30300 (epoch 37.246), train_loss = 1.09013911, grad/param norm = 1.9736e-01, time/batch = 0.7171s	
22572/30300 (epoch 37.248), train_loss = 1.03517315, grad/param norm = 1.7431e-01, time/batch = 0.7264s	
22573/30300 (epoch 37.249), train_loss = 0.96878837, grad/param norm = 1.8606e-01, time/batch = 0.7149s	
22574/30300 (epoch 37.251), train_loss = 0.99552848, grad/param norm = 1.7887e-01, time/batch = 0.6798s	
22575/30300 (epoch 37.252), train_loss = 1.15652805, grad/param norm = 1.9042e-01, time/batch = 0.6808s	
22576/30300 (epoch 37.254), train_loss = 1.14518382, grad/param norm = 1.8816e-01, time/batch = 0.6828s	
22577/30300 (epoch 37.256), train_loss = 1.09654884, grad/param norm = 1.9294e-01, time/batch = 0.6838s	
22578/30300 (epoch 37.257), train_loss = 1.12151069, grad/param norm = 1.9191e-01, time/batch = 0.6795s	
22579/30300 (epoch 37.259), train_loss = 1.04280870, grad/param norm = 1.8119e-01, time/batch = 0.6871s	
22580/30300 (epoch 37.261), train_loss = 1.19314827, grad/param norm = 1.7939e-01, time/batch = 0.6873s	
22581/30300 (epoch 37.262), train_loss = 0.98855137, grad/param norm = 1.6126e-01, time/batch = 0.6966s	
22582/30300 (epoch 37.264), train_loss = 1.05096154, grad/param norm = 2.0965e-01, time/batch = 0.7337s	
22583/30300 (epoch 37.266), train_loss = 1.03292472, grad/param norm = 1.6477e-01, time/batch = 0.7436s	
22584/30300 (epoch 37.267), train_loss = 1.21495951, grad/param norm = 2.0524e-01, time/batch = 0.7316s	
22585/30300 (epoch 37.269), train_loss = 1.07100570, grad/param norm = 1.6861e-01, time/batch = 0.7295s	
22586/30300 (epoch 37.271), train_loss = 1.06682105, grad/param norm = 1.7288e-01, time/batch = 0.7219s	
22587/30300 (epoch 37.272), train_loss = 1.06510483, grad/param norm = 2.1320e-01, time/batch = 0.7198s	
22588/30300 (epoch 37.274), train_loss = 1.14383198, grad/param norm = 1.9867e-01, time/batch = 0.7122s	
22589/30300 (epoch 37.276), train_loss = 1.08278650, grad/param norm = 1.9438e-01, time/batch = 0.7236s	
22590/30300 (epoch 37.277), train_loss = 0.94303241, grad/param norm = 1.7577e-01, time/batch = 0.7593s	
22591/30300 (epoch 37.279), train_loss = 1.06857495, grad/param norm = 1.8709e-01, time/batch = 0.7137s	
22592/30300 (epoch 37.281), train_loss = 1.14349560, grad/param norm = 2.2114e-01, time/batch = 0.7062s	
22593/30300 (epoch 37.282), train_loss = 1.09425683, grad/param norm = 1.6941e-01, time/batch = 0.6877s	
22594/30300 (epoch 37.284), train_loss = 1.13044046, grad/param norm = 2.1001e-01, time/batch = 0.6805s	
22595/30300 (epoch 37.285), train_loss = 1.10737935, grad/param norm = 1.5935e-01, time/batch = 0.6861s	
22596/30300 (epoch 37.287), train_loss = 1.06526709, grad/param norm = 1.9300e-01, time/batch = 0.7108s	
22597/30300 (epoch 37.289), train_loss = 1.14971832, grad/param norm = 1.7648e-01, time/batch = 0.7123s	
22598/30300 (epoch 37.290), train_loss = 0.84202725, grad/param norm = 1.5485e-01, time/batch = 0.6869s	
22599/30300 (epoch 37.292), train_loss = 0.95288181, grad/param norm = 1.7079e-01, time/batch = 0.6990s	
22600/30300 (epoch 37.294), train_loss = 1.15041107, grad/param norm = 2.5084e-01, time/batch = 0.7011s	
22601/30300 (epoch 37.295), train_loss = 1.01917365, grad/param norm = 1.8935e-01, time/batch = 0.7078s	
22602/30300 (epoch 37.297), train_loss = 1.02465398, grad/param norm = 1.6595e-01, time/batch = 0.7423s	
22603/30300 (epoch 37.299), train_loss = 1.03404657, grad/param norm = 1.8047e-01, time/batch = 0.7250s	
22604/30300 (epoch 37.300), train_loss = 0.97358109, grad/param norm = 1.7718e-01, time/batch = 0.7058s	
22605/30300 (epoch 37.302), train_loss = 1.12660384, grad/param norm = 1.9349e-01, time/batch = 0.7012s	
22606/30300 (epoch 37.304), train_loss = 0.98030669, grad/param norm = 1.6904e-01, time/batch = 0.6942s	
22607/30300 (epoch 37.305), train_loss = 1.04974445, grad/param norm = 1.7007e-01, time/batch = 0.6861s	
22608/30300 (epoch 37.307), train_loss = 1.14173681, grad/param norm = 1.5651e-01, time/batch = 0.7045s	
22609/30300 (epoch 37.309), train_loss = 1.09426831, grad/param norm = 1.7455e-01, time/batch = 0.6865s	
22610/30300 (epoch 37.310), train_loss = 1.03960157, grad/param norm = 1.6464e-01, time/batch = 0.6778s	
22611/30300 (epoch 37.312), train_loss = 1.17852246, grad/param norm = 1.6488e-01, time/batch = 0.6808s	
22612/30300 (epoch 37.314), train_loss = 1.05673028, grad/param norm = 1.6717e-01, time/batch = 0.6809s	
22613/30300 (epoch 37.315), train_loss = 1.02627175, grad/param norm = 1.8040e-01, time/batch = 0.6801s	
22614/30300 (epoch 37.317), train_loss = 1.07711353, grad/param norm = 1.6236e-01, time/batch = 0.6825s	
22615/30300 (epoch 37.318), train_loss = 1.12908952, grad/param norm = 1.9429e-01, time/batch = 0.6880s	
22616/30300 (epoch 37.320), train_loss = 1.09253508, grad/param norm = 1.8521e-01, time/batch = 0.6821s	
22617/30300 (epoch 37.322), train_loss = 1.00096841, grad/param norm = 1.6926e-01, time/batch = 0.6819s	
22618/30300 (epoch 37.323), train_loss = 1.16472818, grad/param norm = 1.8666e-01, time/batch = 0.6839s	
22619/30300 (epoch 37.325), train_loss = 1.04629763, grad/param norm = 1.6587e-01, time/batch = 0.6835s	
22620/30300 (epoch 37.327), train_loss = 1.02974220, grad/param norm = 1.6031e-01, time/batch = 0.6915s	
22621/30300 (epoch 37.328), train_loss = 1.07395137, grad/param norm = 1.5968e-01, time/batch = 0.6886s	
22622/30300 (epoch 37.330), train_loss = 1.08674773, grad/param norm = 1.7581e-01, time/batch = 0.6881s	
22623/30300 (epoch 37.332), train_loss = 1.15576078, grad/param norm = 2.1612e-01, time/batch = 0.6885s	
22624/30300 (epoch 37.333), train_loss = 0.99713115, grad/param norm = 1.8531e-01, time/batch = 0.7095s	
22625/30300 (epoch 37.335), train_loss = 0.96245218, grad/param norm = 1.6622e-01, time/batch = 0.6994s	
22626/30300 (epoch 37.337), train_loss = 1.18203495, grad/param norm = 1.7239e-01, time/batch = 0.7044s	
22627/30300 (epoch 37.338), train_loss = 1.00016826, grad/param norm = 1.5474e-01, time/batch = 0.7055s	
22628/30300 (epoch 37.340), train_loss = 0.99292883, grad/param norm = 1.6216e-01, time/batch = 0.7051s	
22629/30300 (epoch 37.342), train_loss = 1.13075704, grad/param norm = 1.7177e-01, time/batch = 0.6826s	
22630/30300 (epoch 37.343), train_loss = 1.08875765, grad/param norm = 1.6974e-01, time/batch = 0.6879s	
22631/30300 (epoch 37.345), train_loss = 1.11336888, grad/param norm = 1.7361e-01, time/batch = 0.6860s	
22632/30300 (epoch 37.347), train_loss = 0.93392642, grad/param norm = 1.5348e-01, time/batch = 0.6870s	
22633/30300 (epoch 37.348), train_loss = 1.01391739, grad/param norm = 1.8866e-01, time/batch = 0.6836s	
22634/30300 (epoch 37.350), train_loss = 1.00561691, grad/param norm = 1.6709e-01, time/batch = 0.6877s	
22635/30300 (epoch 37.351), train_loss = 1.03116452, grad/param norm = 1.7103e-01, time/batch = 0.6821s	
22636/30300 (epoch 37.353), train_loss = 0.92863152, grad/param norm = 1.6072e-01, time/batch = 0.6875s	
22637/30300 (epoch 37.355), train_loss = 1.01373689, grad/param norm = 1.8109e-01, time/batch = 0.6882s	
22638/30300 (epoch 37.356), train_loss = 1.12657753, grad/param norm = 1.9293e-01, time/batch = 0.6904s	
22639/30300 (epoch 37.358), train_loss = 1.27487619, grad/param norm = 1.6316e-01, time/batch = 0.6874s	
22640/30300 (epoch 37.360), train_loss = 0.99631357, grad/param norm = 1.6371e-01, time/batch = 0.6853s	
22641/30300 (epoch 37.361), train_loss = 1.05366554, grad/param norm = 1.8950e-01, time/batch = 0.6827s	
22642/30300 (epoch 37.363), train_loss = 1.08424015, grad/param norm = 1.7352e-01, time/batch = 0.6812s	
22643/30300 (epoch 37.365), train_loss = 0.93260781, grad/param norm = 1.9052e-01, time/batch = 0.6836s	
22644/30300 (epoch 37.366), train_loss = 1.02465297, grad/param norm = 1.5533e-01, time/batch = 0.6855s	
22645/30300 (epoch 37.368), train_loss = 0.93417029, grad/param norm = 1.6209e-01, time/batch = 0.6850s	
22646/30300 (epoch 37.370), train_loss = 0.98666101, grad/param norm = 1.6907e-01, time/batch = 0.6886s	
22647/30300 (epoch 37.371), train_loss = 1.10767175, grad/param norm = 1.6374e-01, time/batch = 0.6939s	
22648/30300 (epoch 37.373), train_loss = 1.00447179, grad/param norm = 1.4602e-01, time/batch = 0.7228s	
22649/30300 (epoch 37.375), train_loss = 0.98810239, grad/param norm = 1.7103e-01, time/batch = 0.7012s	
22650/30300 (epoch 37.376), train_loss = 0.97062966, grad/param norm = 1.4678e-01, time/batch = 0.6851s	
22651/30300 (epoch 37.378), train_loss = 0.95590752, grad/param norm = 1.7235e-01, time/batch = 0.6841s	
22652/30300 (epoch 37.380), train_loss = 1.18302007, grad/param norm = 1.8533e-01, time/batch = 0.6828s	
22653/30300 (epoch 37.381), train_loss = 0.89125284, grad/param norm = 1.6189e-01, time/batch = 0.6874s	
22654/30300 (epoch 37.383), train_loss = 0.95021941, grad/param norm = 1.8779e-01, time/batch = 0.6867s	
22655/30300 (epoch 37.384), train_loss = 1.09751486, grad/param norm = 1.9156e-01, time/batch = 0.6822s	
22656/30300 (epoch 37.386), train_loss = 0.93020401, grad/param norm = 1.7201e-01, time/batch = 0.6815s	
22657/30300 (epoch 37.388), train_loss = 0.92903924, grad/param norm = 1.9539e-01, time/batch = 0.6798s	
22658/30300 (epoch 37.389), train_loss = 1.04638542, grad/param norm = 1.9669e-01, time/batch = 0.6815s	
22659/30300 (epoch 37.391), train_loss = 1.09428551, grad/param norm = 1.6109e-01, time/batch = 0.6837s	
22660/30300 (epoch 37.393), train_loss = 0.92394565, grad/param norm = 1.7429e-01, time/batch = 0.6851s	
22661/30300 (epoch 37.394), train_loss = 1.08546602, grad/param norm = 1.5546e-01, time/batch = 0.6917s	
22662/30300 (epoch 37.396), train_loss = 1.17252763, grad/param norm = 1.5941e-01, time/batch = 0.6919s	
22663/30300 (epoch 37.398), train_loss = 1.01651202, grad/param norm = 1.8244e-01, time/batch = 0.6824s	
22664/30300 (epoch 37.399), train_loss = 0.97139012, grad/param norm = 1.7284e-01, time/batch = 0.6834s	
22665/30300 (epoch 37.401), train_loss = 1.04890328, grad/param norm = 2.5334e-01, time/batch = 0.6879s	
22666/30300 (epoch 37.403), train_loss = 1.04924033, grad/param norm = 1.8993e-01, time/batch = 0.6928s	
22667/30300 (epoch 37.404), train_loss = 0.99476719, grad/param norm = 1.8917e-01, time/batch = 0.7065s	
22668/30300 (epoch 37.406), train_loss = 1.06013181, grad/param norm = 1.6412e-01, time/batch = 0.7038s	
22669/30300 (epoch 37.408), train_loss = 0.92447100, grad/param norm = 1.5537e-01, time/batch = 0.7037s	
22670/30300 (epoch 37.409), train_loss = 0.93189861, grad/param norm = 1.6935e-01, time/batch = 0.6876s	
22671/30300 (epoch 37.411), train_loss = 0.97307013, grad/param norm = 1.6067e-01, time/batch = 0.6939s	
22672/30300 (epoch 37.413), train_loss = 0.87291001, grad/param norm = 1.5437e-01, time/batch = 0.6817s	
22673/30300 (epoch 37.414), train_loss = 1.09287395, grad/param norm = 1.7722e-01, time/batch = 0.6946s	
22674/30300 (epoch 37.416), train_loss = 0.97469617, grad/param norm = 1.5338e-01, time/batch = 0.6870s	
22675/30300 (epoch 37.417), train_loss = 0.94666497, grad/param norm = 1.9654e-01, time/batch = 0.6868s	
22676/30300 (epoch 37.419), train_loss = 0.95151556, grad/param norm = 1.6759e-01, time/batch = 0.6877s	
22677/30300 (epoch 37.421), train_loss = 1.03415924, grad/param norm = 2.4885e-01, time/batch = 0.6875s	
22678/30300 (epoch 37.422), train_loss = 1.06095619, grad/param norm = 1.9907e-01, time/batch = 0.6803s	
22679/30300 (epoch 37.424), train_loss = 1.05295394, grad/param norm = 1.7958e-01, time/batch = 0.7100s	
22680/30300 (epoch 37.426), train_loss = 1.00392122, grad/param norm = 1.7059e-01, time/batch = 0.6836s	
22681/30300 (epoch 37.427), train_loss = 0.98806324, grad/param norm = 2.0362e-01, time/batch = 0.7170s	
22682/30300 (epoch 37.429), train_loss = 1.02333960, grad/param norm = 1.5485e-01, time/batch = 0.7102s	
22683/30300 (epoch 37.431), train_loss = 1.09628347, grad/param norm = 2.0079e-01, time/batch = 0.6849s	
22684/30300 (epoch 37.432), train_loss = 1.02856895, grad/param norm = 1.7280e-01, time/batch = 0.6822s	
22685/30300 (epoch 37.434), train_loss = 0.94151670, grad/param norm = 1.9413e-01, time/batch = 0.6855s	
22686/30300 (epoch 37.436), train_loss = 1.14145304, grad/param norm = 1.7547e-01, time/batch = 0.6812s	
22687/30300 (epoch 37.437), train_loss = 0.93284357, grad/param norm = 1.5011e-01, time/batch = 0.6818s	
22688/30300 (epoch 37.439), train_loss = 0.98471555, grad/param norm = 1.6918e-01, time/batch = 0.6807s	
22689/30300 (epoch 37.441), train_loss = 1.02757670, grad/param norm = 1.5683e-01, time/batch = 0.6882s	
22690/30300 (epoch 37.442), train_loss = 0.97329459, grad/param norm = 1.4509e-01, time/batch = 0.6816s	
22691/30300 (epoch 37.444), train_loss = 0.84880356, grad/param norm = 1.5093e-01, time/batch = 0.6939s	
22692/30300 (epoch 37.446), train_loss = 1.00983664, grad/param norm = 1.5429e-01, time/batch = 0.6848s	
22693/30300 (epoch 37.447), train_loss = 1.02775600, grad/param norm = 1.7236e-01, time/batch = 0.6823s	
22694/30300 (epoch 37.449), train_loss = 0.96213332, grad/param norm = 1.5607e-01, time/batch = 0.6823s	
22695/30300 (epoch 37.450), train_loss = 1.05632270, grad/param norm = 1.5776e-01, time/batch = 0.6817s	
22696/30300 (epoch 37.452), train_loss = 1.14162147, grad/param norm = 1.7215e-01, time/batch = 0.6811s	
22697/30300 (epoch 37.454), train_loss = 1.08817099, grad/param norm = 1.5951e-01, time/batch = 0.6860s	
22698/30300 (epoch 37.455), train_loss = 1.03319689, grad/param norm = 1.7905e-01, time/batch = 0.6841s	
22699/30300 (epoch 37.457), train_loss = 1.00301200, grad/param norm = 1.8777e-01, time/batch = 0.6852s	
22700/30300 (epoch 37.459), train_loss = 1.09923229, grad/param norm = 2.2629e-01, time/batch = 0.7224s	
22701/30300 (epoch 37.460), train_loss = 1.10620676, grad/param norm = 1.7067e-01, time/batch = 0.7029s	
22702/30300 (epoch 37.462), train_loss = 1.10610017, grad/param norm = 1.8337e-01, time/batch = 0.6823s	
22703/30300 (epoch 37.464), train_loss = 0.85541318, grad/param norm = 1.8633e-01, time/batch = 0.6818s	
22704/30300 (epoch 37.465), train_loss = 0.87673986, grad/param norm = 1.6531e-01, time/batch = 0.6824s	
22705/30300 (epoch 37.467), train_loss = 0.88363952, grad/param norm = 1.5771e-01, time/batch = 0.6835s	
22706/30300 (epoch 37.469), train_loss = 0.96485046, grad/param norm = 1.5603e-01, time/batch = 0.6836s	
22707/30300 (epoch 37.470), train_loss = 0.98537377, grad/param norm = 1.7566e-01, time/batch = 0.6839s	
22708/30300 (epoch 37.472), train_loss = 0.97172072, grad/param norm = 1.4180e-01, time/batch = 0.6821s	
22709/30300 (epoch 37.474), train_loss = 0.97636599, grad/param norm = 1.9274e-01, time/batch = 0.6807s	
22710/30300 (epoch 37.475), train_loss = 0.96074755, grad/param norm = 1.5241e-01, time/batch = 0.6835s	
22711/30300 (epoch 37.477), train_loss = 1.02470357, grad/param norm = 1.7106e-01, time/batch = 0.6856s	
22712/30300 (epoch 37.479), train_loss = 1.00669936, grad/param norm = 1.7628e-01, time/batch = 0.6838s	
22713/30300 (epoch 37.480), train_loss = 1.05279943, grad/param norm = 1.7122e-01, time/batch = 0.6846s	
22714/30300 (epoch 37.482), train_loss = 1.08746439, grad/param norm = 1.6001e-01, time/batch = 0.6909s	
22715/30300 (epoch 37.483), train_loss = 1.00514380, grad/param norm = 1.7665e-01, time/batch = 0.6875s	
22716/30300 (epoch 37.485), train_loss = 1.04367802, grad/param norm = 1.8103e-01, time/batch = 0.6841s	
22717/30300 (epoch 37.487), train_loss = 1.09982406, grad/param norm = 1.6235e-01, time/batch = 0.6876s	
22718/30300 (epoch 37.488), train_loss = 1.14537633, grad/param norm = 1.4820e-01, time/batch = 0.6864s	
22719/30300 (epoch 37.490), train_loss = 0.89346439, grad/param norm = 1.4753e-01, time/batch = 0.6847s	
22720/30300 (epoch 37.492), train_loss = 1.00259134, grad/param norm = 1.7567e-01, time/batch = 0.6862s	
22721/30300 (epoch 37.493), train_loss = 1.02492831, grad/param norm = 1.5903e-01, time/batch = 0.6853s	
22722/30300 (epoch 37.495), train_loss = 1.00553397, grad/param norm = 1.4526e-01, time/batch = 0.6873s	
22723/30300 (epoch 37.497), train_loss = 1.05091397, grad/param norm = 1.6050e-01, time/batch = 0.7154s	
22724/30300 (epoch 37.498), train_loss = 1.07970738, grad/param norm = 1.6233e-01, time/batch = 0.7126s	
22725/30300 (epoch 37.500), train_loss = 1.00771733, grad/param norm = 1.9290e-01, time/batch = 0.6836s	
22726/30300 (epoch 37.502), train_loss = 1.02480210, grad/param norm = 1.9709e-01, time/batch = 0.7070s	
22727/30300 (epoch 37.503), train_loss = 1.11772424, grad/param norm = 1.6552e-01, time/batch = 0.6903s	
22728/30300 (epoch 37.505), train_loss = 0.92861088, grad/param norm = 1.5917e-01, time/batch = 0.6882s	
22729/30300 (epoch 37.507), train_loss = 0.93350327, grad/param norm = 1.8976e-01, time/batch = 0.6902s	
22730/30300 (epoch 37.508), train_loss = 0.98095012, grad/param norm = 2.0728e-01, time/batch = 0.6880s	
22731/30300 (epoch 37.510), train_loss = 1.07960915, grad/param norm = 1.8048e-01, time/batch = 0.6881s	
22732/30300 (epoch 37.512), train_loss = 0.96800234, grad/param norm = 1.5428e-01, time/batch = 0.6809s	
22733/30300 (epoch 37.513), train_loss = 1.03728864, grad/param norm = 1.6101e-01, time/batch = 0.6879s	
22734/30300 (epoch 37.515), train_loss = 1.01554336, grad/param norm = 1.6371e-01, time/batch = 0.6833s	
22735/30300 (epoch 37.517), train_loss = 0.85576320, grad/param norm = 1.6053e-01, time/batch = 0.6853s	
22736/30300 (epoch 37.518), train_loss = 1.11987879, grad/param norm = 1.9514e-01, time/batch = 0.6875s	
22737/30300 (epoch 37.520), train_loss = 1.03356213, grad/param norm = 1.7864e-01, time/batch = 0.6910s	
22738/30300 (epoch 37.521), train_loss = 0.93797149, grad/param norm = 1.7370e-01, time/batch = 0.6879s	
22739/30300 (epoch 37.523), train_loss = 1.14859219, grad/param norm = 2.3481e-01, time/batch = 0.6898s	
22740/30300 (epoch 37.525), train_loss = 0.95523980, grad/param norm = 1.8405e-01, time/batch = 0.6989s	
22741/30300 (epoch 37.526), train_loss = 1.05149173, grad/param norm = 1.5649e-01, time/batch = 0.6995s	
22742/30300 (epoch 37.528), train_loss = 0.92229282, grad/param norm = 1.7254e-01, time/batch = 0.7276s	
22743/30300 (epoch 37.530), train_loss = 0.90364293, grad/param norm = 1.6082e-01, time/batch = 0.7184s	
22744/30300 (epoch 37.531), train_loss = 1.04274857, grad/param norm = 1.7398e-01, time/batch = 0.7215s	
22745/30300 (epoch 37.533), train_loss = 1.00188987, grad/param norm = 1.7204e-01, time/batch = 0.7217s	
22746/30300 (epoch 37.535), train_loss = 1.00031566, grad/param norm = 1.4874e-01, time/batch = 0.7193s	
22747/30300 (epoch 37.536), train_loss = 1.03712751, grad/param norm = 1.6189e-01, time/batch = 0.6994s	
22748/30300 (epoch 37.538), train_loss = 0.89220106, grad/param norm = 1.6840e-01, time/batch = 0.7090s	
22749/30300 (epoch 37.540), train_loss = 0.97240205, grad/param norm = 2.0845e-01, time/batch = 0.7060s	
22750/30300 (epoch 37.541), train_loss = 1.02360614, grad/param norm = 1.8393e-01, time/batch = 0.7013s	
22751/30300 (epoch 37.543), train_loss = 0.99510746, grad/param norm = 1.5745e-01, time/batch = 0.6898s	
22752/30300 (epoch 37.545), train_loss = 1.08958810, grad/param norm = 2.3913e-01, time/batch = 0.6921s	
22753/30300 (epoch 37.546), train_loss = 1.20633496, grad/param norm = 1.7013e-01, time/batch = 0.7031s	
22754/30300 (epoch 37.548), train_loss = 0.96826417, grad/param norm = 1.4559e-01, time/batch = 0.6865s	
22755/30300 (epoch 37.550), train_loss = 1.07246684, grad/param norm = 2.3672e-01, time/batch = 0.7172s	
22756/30300 (epoch 37.551), train_loss = 0.97591692, grad/param norm = 1.8667e-01, time/batch = 0.7267s	
22757/30300 (epoch 37.553), train_loss = 0.99298679, grad/param norm = 1.7516e-01, time/batch = 0.7024s	
22758/30300 (epoch 37.554), train_loss = 1.03886717, grad/param norm = 1.8659e-01, time/batch = 0.6915s	
22759/30300 (epoch 37.556), train_loss = 1.06271163, grad/param norm = 1.7630e-01, time/batch = 0.6883s	
22760/30300 (epoch 37.558), train_loss = 1.10799569, grad/param norm = 2.0041e-01, time/batch = 0.6896s	
22761/30300 (epoch 37.559), train_loss = 1.03279658, grad/param norm = 1.6367e-01, time/batch = 0.6884s	
22762/30300 (epoch 37.561), train_loss = 0.83906408, grad/param norm = 1.6299e-01, time/batch = 0.6871s	
22763/30300 (epoch 37.563), train_loss = 0.92133685, grad/param norm = 1.7579e-01, time/batch = 0.6860s	
22764/30300 (epoch 37.564), train_loss = 0.97281259, grad/param norm = 1.4800e-01, time/batch = 0.6847s	
22765/30300 (epoch 37.566), train_loss = 0.99732613, grad/param norm = 1.7286e-01, time/batch = 0.7168s	
22766/30300 (epoch 37.568), train_loss = 0.87305593, grad/param norm = 1.7910e-01, time/batch = 0.7033s	
22767/30300 (epoch 37.569), train_loss = 1.05708904, grad/param norm = 1.7201e-01, time/batch = 0.7048s	
22768/30300 (epoch 37.571), train_loss = 1.02251061, grad/param norm = 1.8252e-01, time/batch = 0.6939s	
22769/30300 (epoch 37.573), train_loss = 1.06543446, grad/param norm = 1.6823e-01, time/batch = 0.6881s	
22770/30300 (epoch 37.574), train_loss = 1.04717341, grad/param norm = 1.5822e-01, time/batch = 0.6835s	
22771/30300 (epoch 37.576), train_loss = 0.98437490, grad/param norm = 1.4758e-01, time/batch = 0.6841s	
22772/30300 (epoch 37.578), train_loss = 0.89277454, grad/param norm = 1.5733e-01, time/batch = 0.6841s	
22773/30300 (epoch 37.579), train_loss = 1.06815492, grad/param norm = 1.7470e-01, time/batch = 0.6838s	
22774/30300 (epoch 37.581), train_loss = 1.14329638, grad/param norm = 1.7063e-01, time/batch = 0.7000s	
22775/30300 (epoch 37.583), train_loss = 1.14915000, grad/param norm = 1.9616e-01, time/batch = 0.7272s	
22776/30300 (epoch 37.584), train_loss = 1.11580535, grad/param norm = 1.6308e-01, time/batch = 0.6903s	
22777/30300 (epoch 37.586), train_loss = 0.99833897, grad/param norm = 1.8001e-01, time/batch = 0.6845s	
22778/30300 (epoch 37.587), train_loss = 1.01183149, grad/param norm = 1.6523e-01, time/batch = 0.6822s	
22779/30300 (epoch 37.589), train_loss = 0.96258714, grad/param norm = 1.6632e-01, time/batch = 0.6843s	
22780/30300 (epoch 37.591), train_loss = 1.04524697, grad/param norm = 1.5577e-01, time/batch = 0.6839s	
22781/30300 (epoch 37.592), train_loss = 0.98736808, grad/param norm = 1.6261e-01, time/batch = 0.6867s	
22782/30300 (epoch 37.594), train_loss = 1.04854239, grad/param norm = 1.5972e-01, time/batch = 0.6872s	
22783/30300 (epoch 37.596), train_loss = 0.94174587, grad/param norm = 1.6364e-01, time/batch = 0.6855s	
22784/30300 (epoch 37.597), train_loss = 0.96204079, grad/param norm = 1.7148e-01, time/batch = 0.6840s	
22785/30300 (epoch 37.599), train_loss = 0.86307965, grad/param norm = 1.4019e-01, time/batch = 0.6833s	
22786/30300 (epoch 37.601), train_loss = 1.04234271, grad/param norm = 1.7339e-01, time/batch = 0.6828s	
22787/30300 (epoch 37.602), train_loss = 1.00213800, grad/param norm = 1.5867e-01, time/batch = 0.6819s	
22788/30300 (epoch 37.604), train_loss = 0.94374680, grad/param norm = 1.4446e-01, time/batch = 0.6828s	
22789/30300 (epoch 37.606), train_loss = 0.94586654, grad/param norm = 2.7231e-01, time/batch = 0.6891s	
22790/30300 (epoch 37.607), train_loss = 1.08187653, grad/param norm = 2.1950e-01, time/batch = 0.6894s	
22791/30300 (epoch 37.609), train_loss = 1.18072397, grad/param norm = 1.8438e-01, time/batch = 0.6835s	
22792/30300 (epoch 37.611), train_loss = 0.98768111, grad/param norm = 1.7026e-01, time/batch = 0.6813s	
22793/30300 (epoch 37.612), train_loss = 0.91430673, grad/param norm = 1.4705e-01, time/batch = 0.7058s	
22794/30300 (epoch 37.614), train_loss = 1.00106926, grad/param norm = 1.7766e-01, time/batch = 0.7181s	
22795/30300 (epoch 37.616), train_loss = 1.04696219, grad/param norm = 2.2154e-01, time/batch = 0.6812s	
22796/30300 (epoch 37.617), train_loss = 1.03705019, grad/param norm = 1.8918e-01, time/batch = 0.6821s	
22797/30300 (epoch 37.619), train_loss = 0.83670937, grad/param norm = 1.4507e-01, time/batch = 0.6857s	
22798/30300 (epoch 37.620), train_loss = 1.08119764, grad/param norm = 1.7468e-01, time/batch = 0.6865s	
22799/30300 (epoch 37.622), train_loss = 1.02346841, grad/param norm = 2.0053e-01, time/batch = 0.6928s	
22800/30300 (epoch 37.624), train_loss = 0.99660941, grad/param norm = 1.5574e-01, time/batch = 0.6815s	
22801/30300 (epoch 37.625), train_loss = 1.01585634, grad/param norm = 2.0320e-01, time/batch = 0.6827s	
22802/30300 (epoch 37.627), train_loss = 1.12521068, grad/param norm = 2.1278e-01, time/batch = 0.6815s	
22803/30300 (epoch 37.629), train_loss = 1.14682863, grad/param norm = 1.5870e-01, time/batch = 0.6833s	
22804/30300 (epoch 37.630), train_loss = 1.01639229, grad/param norm = 1.5918e-01, time/batch = 0.6889s	
22805/30300 (epoch 37.632), train_loss = 1.06503628, grad/param norm = 1.9403e-01, time/batch = 0.6900s	
22806/30300 (epoch 37.634), train_loss = 0.93953963, grad/param norm = 1.5461e-01, time/batch = 0.6904s	
22807/30300 (epoch 37.635), train_loss = 1.08067253, grad/param norm = 2.0100e-01, time/batch = 0.6884s	
22808/30300 (epoch 37.637), train_loss = 1.11321306, grad/param norm = 1.9998e-01, time/batch = 0.7179s	
22809/30300 (epoch 37.639), train_loss = 1.01645861, grad/param norm = 1.7897e-01, time/batch = 0.7168s	
22810/30300 (epoch 37.640), train_loss = 1.11055477, grad/param norm = 2.0748e-01, time/batch = 0.7127s	
22811/30300 (epoch 37.642), train_loss = 0.99702156, grad/param norm = 1.5020e-01, time/batch = 0.6973s	
22812/30300 (epoch 37.644), train_loss = 1.10329425, grad/param norm = 1.8212e-01, time/batch = 0.7235s	
22813/30300 (epoch 37.645), train_loss = 0.96155805, grad/param norm = 1.5096e-01, time/batch = 0.7053s	
22814/30300 (epoch 37.647), train_loss = 1.04614597, grad/param norm = 1.7030e-01, time/batch = 0.6875s	
22815/30300 (epoch 37.649), train_loss = 0.99965746, grad/param norm = 1.9805e-01, time/batch = 0.7000s	
22816/30300 (epoch 37.650), train_loss = 1.02450928, grad/param norm = 1.7854e-01, time/batch = 0.6939s	
22817/30300 (epoch 37.652), train_loss = 0.98918404, grad/param norm = 1.9241e-01, time/batch = 0.7107s	
22818/30300 (epoch 37.653), train_loss = 1.17803210, grad/param norm = 1.5175e-01, time/batch = 0.7093s	
22819/30300 (epoch 37.655), train_loss = 0.99869203, grad/param norm = 1.7479e-01, time/batch = 0.7200s	
22820/30300 (epoch 37.657), train_loss = 0.94270959, grad/param norm = 1.7887e-01, time/batch = 0.7270s	
22821/30300 (epoch 37.658), train_loss = 0.97270002, grad/param norm = 1.5463e-01, time/batch = 0.7106s	
22822/30300 (epoch 37.660), train_loss = 1.04341751, grad/param norm = 1.7205e-01, time/batch = 0.6853s	
22823/30300 (epoch 37.662), train_loss = 1.05919779, grad/param norm = 2.5365e-01, time/batch = 0.6884s	
22824/30300 (epoch 37.663), train_loss = 1.08534847, grad/param norm = 1.6309e-01, time/batch = 0.6809s	
22825/30300 (epoch 37.665), train_loss = 0.97745529, grad/param norm = 1.8370e-01, time/batch = 0.6817s	
22826/30300 (epoch 37.667), train_loss = 1.07724613, grad/param norm = 1.6119e-01, time/batch = 0.6814s	
22827/30300 (epoch 37.668), train_loss = 1.10505465, grad/param norm = 1.7540e-01, time/batch = 0.6856s	
22828/30300 (epoch 37.670), train_loss = 1.13761303, grad/param norm = 1.7431e-01, time/batch = 0.6830s	
22829/30300 (epoch 37.672), train_loss = 1.03783960, grad/param norm = 1.9308e-01, time/batch = 0.6821s	
22830/30300 (epoch 37.673), train_loss = 1.09228943, grad/param norm = 2.3022e-01, time/batch = 0.6963s	
22831/30300 (epoch 37.675), train_loss = 0.98915472, grad/param norm = 1.6903e-01, time/batch = 0.7286s	
22832/30300 (epoch 37.677), train_loss = 0.97745119, grad/param norm = 1.4353e-01, time/batch = 0.6845s	
22833/30300 (epoch 37.678), train_loss = 0.98117213, grad/param norm = 1.7074e-01, time/batch = 0.6853s	
22834/30300 (epoch 37.680), train_loss = 0.91547751, grad/param norm = 1.5684e-01, time/batch = 0.6879s	
22835/30300 (epoch 37.682), train_loss = 1.01204944, grad/param norm = 1.8347e-01, time/batch = 0.6858s	
22836/30300 (epoch 37.683), train_loss = 1.11261457, grad/param norm = 1.5519e-01, time/batch = 0.6837s	
22837/30300 (epoch 37.685), train_loss = 1.08964889, grad/param norm = 2.0491e-01, time/batch = 0.6824s	
22838/30300 (epoch 37.686), train_loss = 0.99591430, grad/param norm = 1.4882e-01, time/batch = 0.6922s	
22839/30300 (epoch 37.688), train_loss = 1.01338373, grad/param norm = 1.5416e-01, time/batch = 0.6937s	
22840/30300 (epoch 37.690), train_loss = 0.96744884, grad/param norm = 1.8198e-01, time/batch = 0.7011s	
22841/30300 (epoch 37.691), train_loss = 1.02943499, grad/param norm = 1.6147e-01, time/batch = 0.7298s	
22842/30300 (epoch 37.693), train_loss = 1.32027990, grad/param norm = 2.1896e-01, time/batch = 0.6952s	
22843/30300 (epoch 37.695), train_loss = 1.09150186, grad/param norm = 1.8282e-01, time/batch = 0.7057s	
22844/30300 (epoch 37.696), train_loss = 1.08831107, grad/param norm = 2.0378e-01, time/batch = 0.6849s	
22845/30300 (epoch 37.698), train_loss = 0.97939527, grad/param norm = 1.7514e-01, time/batch = 0.6826s	
22846/30300 (epoch 37.700), train_loss = 0.97270128, grad/param norm = 1.7195e-01, time/batch = 0.6810s	
22847/30300 (epoch 37.701), train_loss = 0.89819521, grad/param norm = 1.6112e-01, time/batch = 0.7089s	
22848/30300 (epoch 37.703), train_loss = 1.03136006, grad/param norm = 1.6582e-01, time/batch = 0.7026s	
22849/30300 (epoch 37.705), train_loss = 0.93837514, grad/param norm = 1.6548e-01, time/batch = 0.6858s	
22850/30300 (epoch 37.706), train_loss = 1.09135995, grad/param norm = 1.8498e-01, time/batch = 0.6852s	
22851/30300 (epoch 37.708), train_loss = 1.02479311, grad/param norm = 1.6447e-01, time/batch = 0.6845s	
22852/30300 (epoch 37.710), train_loss = 0.99596073, grad/param norm = 1.6024e-01, time/batch = 0.6832s	
22853/30300 (epoch 37.711), train_loss = 0.97629568, grad/param norm = 1.7125e-01, time/batch = 0.7030s	
22854/30300 (epoch 37.713), train_loss = 0.96965117, grad/param norm = 1.6248e-01, time/batch = 0.7251s	
22855/30300 (epoch 37.715), train_loss = 0.97534880, grad/param norm = 1.6642e-01, time/batch = 0.6849s	
22856/30300 (epoch 37.716), train_loss = 1.08601437, grad/param norm = 1.6502e-01, time/batch = 0.6866s	
22857/30300 (epoch 37.718), train_loss = 1.12483711, grad/param norm = 1.6765e-01, time/batch = 0.6897s	
22858/30300 (epoch 37.719), train_loss = 0.97910902, grad/param norm = 2.0012e-01, time/batch = 0.6912s	
22859/30300 (epoch 37.721), train_loss = 0.99772015, grad/param norm = 1.7128e-01, time/batch = 0.7093s	
22860/30300 (epoch 37.723), train_loss = 0.95538703, grad/param norm = 1.5021e-01, time/batch = 0.6937s	
22861/30300 (epoch 37.724), train_loss = 1.05722788, grad/param norm = 1.9589e-01, time/batch = 0.6849s	
22862/30300 (epoch 37.726), train_loss = 1.28774851, grad/param norm = 2.4443e-01, time/batch = 0.6840s	
22863/30300 (epoch 37.728), train_loss = 1.05893496, grad/param norm = 1.7557e-01, time/batch = 0.6836s	
22864/30300 (epoch 37.729), train_loss = 0.97803601, grad/param norm = 1.6706e-01, time/batch = 0.6838s	
22865/30300 (epoch 37.731), train_loss = 1.00191174, grad/param norm = 1.8781e-01, time/batch = 0.6862s	
22866/30300 (epoch 37.733), train_loss = 1.03980265, grad/param norm = 1.7762e-01, time/batch = 0.6835s	
22867/30300 (epoch 37.734), train_loss = 1.10809592, grad/param norm = 1.6281e-01, time/batch = 0.6818s	
22868/30300 (epoch 37.736), train_loss = 1.04758149, grad/param norm = 1.6463e-01, time/batch = 0.6818s	
22869/30300 (epoch 37.738), train_loss = 0.96429165, grad/param norm = 1.4022e-01, time/batch = 0.6812s	
22870/30300 (epoch 37.739), train_loss = 1.11906202, grad/param norm = 1.7518e-01, time/batch = 0.6821s	
22871/30300 (epoch 37.741), train_loss = 1.16886062, grad/param norm = 1.6032e-01, time/batch = 0.6948s	
22872/30300 (epoch 37.743), train_loss = 0.99785490, grad/param norm = 1.6371e-01, time/batch = 0.7121s	
22873/30300 (epoch 37.744), train_loss = 1.07101324, grad/param norm = 1.7322e-01, time/batch = 0.7148s	
22874/30300 (epoch 37.746), train_loss = 0.98728436, grad/param norm = 1.5928e-01, time/batch = 0.6806s	
22875/30300 (epoch 37.748), train_loss = 1.01539949, grad/param norm = 1.9472e-01, time/batch = 0.6808s	
22876/30300 (epoch 37.749), train_loss = 1.03235265, grad/param norm = 1.6355e-01, time/batch = 0.6826s	
22877/30300 (epoch 37.751), train_loss = 1.06585759, grad/param norm = 1.6575e-01, time/batch = 0.6833s	
22878/30300 (epoch 37.752), train_loss = 1.00881438, grad/param norm = 1.7404e-01, time/batch = 0.6838s	
22879/30300 (epoch 37.754), train_loss = 1.00412061, grad/param norm = 1.6001e-01, time/batch = 0.6814s	
22880/30300 (epoch 37.756), train_loss = 0.99618333, grad/param norm = 1.5691e-01, time/batch = 0.6844s	
22881/30300 (epoch 37.757), train_loss = 0.96949646, grad/param norm = 1.6736e-01, time/batch = 0.6849s	
22882/30300 (epoch 37.759), train_loss = 1.04764236, grad/param norm = 1.6868e-01, time/batch = 0.6890s	
22883/30300 (epoch 37.761), train_loss = 0.89382588, grad/param norm = 1.5669e-01, time/batch = 0.6826s	
22884/30300 (epoch 37.762), train_loss = 0.90911240, grad/param norm = 1.5461e-01, time/batch = 0.6870s	
22885/30300 (epoch 37.764), train_loss = 0.99999147, grad/param norm = 1.8685e-01, time/batch = 0.6857s	
22886/30300 (epoch 37.766), train_loss = 1.13788972, grad/param norm = 1.9124e-01, time/batch = 0.6840s	
22887/30300 (epoch 37.767), train_loss = 1.07640141, grad/param norm = 2.7382e-01, time/batch = 0.6864s	
22888/30300 (epoch 37.769), train_loss = 1.05349197, grad/param norm = 1.8757e-01, time/batch = 0.6920s	
22889/30300 (epoch 37.771), train_loss = 1.00039123, grad/param norm = 2.5709e-01, time/batch = 0.6902s	
22890/30300 (epoch 37.772), train_loss = 1.03942676, grad/param norm = 1.6789e-01, time/batch = 0.6844s	
22891/30300 (epoch 37.774), train_loss = 1.18097540, grad/param norm = 1.7288e-01, time/batch = 0.7217s	
22892/30300 (epoch 37.776), train_loss = 0.98584325, grad/param norm = 1.7865e-01, time/batch = 0.7068s	
22893/30300 (epoch 37.777), train_loss = 1.15333344, grad/param norm = 1.6999e-01, time/batch = 0.6833s	
22894/30300 (epoch 37.779), train_loss = 1.15600764, grad/param norm = 2.0721e-01, time/batch = 0.6850s	
22895/30300 (epoch 37.781), train_loss = 1.04990564, grad/param norm = 2.0921e-01, time/batch = 0.6887s	
22896/30300 (epoch 37.782), train_loss = 0.96124462, grad/param norm = 1.9040e-01, time/batch = 0.6852s	
22897/30300 (epoch 37.784), train_loss = 0.98278026, grad/param norm = 1.5199e-01, time/batch = 0.6840s	
22898/30300 (epoch 37.785), train_loss = 1.13926223, grad/param norm = 2.2739e-01, time/batch = 0.6854s	
22899/30300 (epoch 37.787), train_loss = 0.87800698, grad/param norm = 1.8812e-01, time/batch = 0.6839s	
22900/30300 (epoch 37.789), train_loss = 1.18558693, grad/param norm = 2.0136e-01, time/batch = 0.6857s	
22901/30300 (epoch 37.790), train_loss = 1.04756336, grad/param norm = 1.7121e-01, time/batch = 0.6917s	
22902/30300 (epoch 37.792), train_loss = 0.83602610, grad/param norm = 1.6418e-01, time/batch = 0.6906s	
22903/30300 (epoch 37.794), train_loss = 1.02574386, grad/param norm = 1.8534e-01, time/batch = 0.6888s	
22904/30300 (epoch 37.795), train_loss = 0.95815559, grad/param norm = 1.5485e-01, time/batch = 0.6833s	
22905/30300 (epoch 37.797), train_loss = 1.16370172, grad/param norm = 2.0397e-01, time/batch = 0.6824s	
22906/30300 (epoch 37.799), train_loss = 1.10551300, grad/param norm = 1.9936e-01, time/batch = 0.6824s	
22907/30300 (epoch 37.800), train_loss = 1.09324413, grad/param norm = 1.9839e-01, time/batch = 0.6817s	
22908/30300 (epoch 37.802), train_loss = 1.27875412, grad/param norm = 1.9184e-01, time/batch = 0.6813s	
22909/30300 (epoch 37.804), train_loss = 1.09417546, grad/param norm = 2.0006e-01, time/batch = 0.6843s	
22910/30300 (epoch 37.805), train_loss = 1.16362802, grad/param norm = 1.7584e-01, time/batch = 0.7257s	
22911/30300 (epoch 37.807), train_loss = 0.99820577, grad/param norm = 1.8144e-01, time/batch = 0.6995s	
22912/30300 (epoch 37.809), train_loss = 1.12286404, grad/param norm = 1.9605e-01, time/batch = 0.6832s	
22913/30300 (epoch 37.810), train_loss = 1.08150215, grad/param norm = 1.7291e-01, time/batch = 0.6855s	
22914/30300 (epoch 37.812), train_loss = 0.98294220, grad/param norm = 1.5508e-01, time/batch = 0.7149s	
22915/30300 (epoch 37.814), train_loss = 1.04477321, grad/param norm = 1.8333e-01, time/batch = 0.7093s	
22916/30300 (epoch 37.815), train_loss = 1.04201449, grad/param norm = 2.0465e-01, time/batch = 0.6812s	
22917/30300 (epoch 37.817), train_loss = 1.11487999, grad/param norm = 1.9560e-01, time/batch = 0.6816s	
22918/30300 (epoch 37.818), train_loss = 1.06919595, grad/param norm = 1.8310e-01, time/batch = 0.6849s	
22919/30300 (epoch 37.820), train_loss = 1.21209349, grad/param norm = 2.3370e-01, time/batch = 0.6825s	
22920/30300 (epoch 37.822), train_loss = 1.17971535, grad/param norm = 1.8817e-01, time/batch = 0.6884s	
22921/30300 (epoch 37.823), train_loss = 1.17962167, grad/param norm = 1.8755e-01, time/batch = 0.7024s	
22922/30300 (epoch 37.825), train_loss = 1.16154607, grad/param norm = 1.7145e-01, time/batch = 0.6922s	
22923/30300 (epoch 37.827), train_loss = 0.90614347, grad/param norm = 1.7722e-01, time/batch = 0.6989s	
22924/30300 (epoch 37.828), train_loss = 1.11704310, grad/param norm = 1.8314e-01, time/batch = 0.7096s	
22925/30300 (epoch 37.830), train_loss = 1.09098881, grad/param norm = 1.8170e-01, time/batch = 0.7039s	
22926/30300 (epoch 37.832), train_loss = 0.97808461, grad/param norm = 1.8520e-01, time/batch = 0.7187s	
22927/30300 (epoch 37.833), train_loss = 1.05508036, grad/param norm = 2.0814e-01, time/batch = 0.7047s	
22928/30300 (epoch 37.835), train_loss = 0.96814553, grad/param norm = 1.6324e-01, time/batch = 0.7497s	
22929/30300 (epoch 37.837), train_loss = 0.93865101, grad/param norm = 1.5366e-01, time/batch = 0.7415s	
22930/30300 (epoch 37.838), train_loss = 0.94424121, grad/param norm = 1.6153e-01, time/batch = 0.7017s	
22931/30300 (epoch 37.840), train_loss = 1.12445643, grad/param norm = 1.5841e-01, time/batch = 0.6958s	
22932/30300 (epoch 37.842), train_loss = 1.00085423, grad/param norm = 1.5081e-01, time/batch = 0.6897s	
22933/30300 (epoch 37.843), train_loss = 1.07455004, grad/param norm = 1.7514e-01, time/batch = 0.6899s	
22934/30300 (epoch 37.845), train_loss = 1.07938254, grad/param norm = 1.5306e-01, time/batch = 0.6864s	
22935/30300 (epoch 37.847), train_loss = 1.04545366, grad/param norm = 1.7795e-01, time/batch = 0.6871s	
22936/30300 (epoch 37.848), train_loss = 1.07674490, grad/param norm = 1.8237e-01, time/batch = 0.6818s	
22937/30300 (epoch 37.850), train_loss = 1.02291885, grad/param norm = 2.3091e-01, time/batch = 0.6811s	
22938/30300 (epoch 37.851), train_loss = 1.07711372, grad/param norm = 2.0168e-01, time/batch = 0.6842s	
22939/30300 (epoch 37.853), train_loss = 1.01491397, grad/param norm = 1.7841e-01, time/batch = 0.7030s	
22940/30300 (epoch 37.855), train_loss = 1.00553971, grad/param norm = 1.6274e-01, time/batch = 0.6975s	
22941/30300 (epoch 37.856), train_loss = 1.04846611, grad/param norm = 1.6073e-01, time/batch = 0.7136s	
22942/30300 (epoch 37.858), train_loss = 0.95346505, grad/param norm = 1.5811e-01, time/batch = 0.6934s	
22943/30300 (epoch 37.860), train_loss = 0.94827860, grad/param norm = 1.6025e-01, time/batch = 0.6818s	
22944/30300 (epoch 37.861), train_loss = 1.18877615, grad/param norm = 1.7407e-01, time/batch = 0.6812s	
22945/30300 (epoch 37.863), train_loss = 1.00375359, grad/param norm = 1.6527e-01, time/batch = 0.6850s	
22946/30300 (epoch 37.865), train_loss = 1.10720256, grad/param norm = 2.0554e-01, time/batch = 0.6839s	
22947/30300 (epoch 37.866), train_loss = 1.10771317, grad/param norm = 1.7321e-01, time/batch = 0.7219s	
22948/30300 (epoch 37.868), train_loss = 1.04683775, grad/param norm = 1.5880e-01, time/batch = 0.7068s	
22949/30300 (epoch 37.870), train_loss = 0.97862726, grad/param norm = 1.7588e-01, time/batch = 0.6841s	
22950/30300 (epoch 37.871), train_loss = 1.05158098, grad/param norm = 1.8591e-01, time/batch = 0.6819s	
22951/30300 (epoch 37.873), train_loss = 1.03277323, grad/param norm = 1.6739e-01, time/batch = 0.6844s	
22952/30300 (epoch 37.875), train_loss = 1.00575460, grad/param norm = 1.5106e-01, time/batch = 0.6805s	
22953/30300 (epoch 37.876), train_loss = 0.92484256, grad/param norm = 1.6855e-01, time/batch = 0.6797s	
22954/30300 (epoch 37.878), train_loss = 0.86949073, grad/param norm = 1.6135e-01, time/batch = 0.6794s	
22955/30300 (epoch 37.880), train_loss = 0.96646374, grad/param norm = 1.7485e-01, time/batch = 0.6846s	
22956/30300 (epoch 37.881), train_loss = 1.18228934, grad/param norm = 1.8848e-01, time/batch = 0.6852s	
22957/30300 (epoch 37.883), train_loss = 1.10673297, grad/param norm = 1.8685e-01, time/batch = 0.6916s	
22958/30300 (epoch 37.884), train_loss = 1.03740060, grad/param norm = 1.5368e-01, time/batch = 0.7209s	
22959/30300 (epoch 37.886), train_loss = 1.07820752, grad/param norm = 1.6284e-01, time/batch = 0.7207s	
22960/30300 (epoch 37.888), train_loss = 0.99748693, grad/param norm = 1.7693e-01, time/batch = 0.7406s	
22961/30300 (epoch 37.889), train_loss = 1.03865700, grad/param norm = 1.6401e-01, time/batch = 0.7335s	
22962/30300 (epoch 37.891), train_loss = 1.01957920, grad/param norm = 1.7589e-01, time/batch = 0.7348s	
22963/30300 (epoch 37.893), train_loss = 1.23016661, grad/param norm = 1.7860e-01, time/batch = 0.7231s	
22964/30300 (epoch 37.894), train_loss = 1.07464422, grad/param norm = 1.7707e-01, time/batch = 0.7105s	
22965/30300 (epoch 37.896), train_loss = 0.89427576, grad/param norm = 1.7987e-01, time/batch = 0.6949s	
22966/30300 (epoch 37.898), train_loss = 0.89255542, grad/param norm = 1.6173e-01, time/batch = 0.6826s	
22967/30300 (epoch 37.899), train_loss = 0.92895145, grad/param norm = 1.6422e-01, time/batch = 0.6857s	
22968/30300 (epoch 37.901), train_loss = 1.03171976, grad/param norm = 1.8950e-01, time/batch = 0.6831s	
22969/30300 (epoch 37.903), train_loss = 1.01497653, grad/param norm = 1.9591e-01, time/batch = 0.6891s	
22970/30300 (epoch 37.904), train_loss = 1.05520320, grad/param norm = 1.6032e-01, time/batch = 0.6976s	
22971/30300 (epoch 37.906), train_loss = 1.05164471, grad/param norm = 1.9528e-01, time/batch = 0.6851s	
22972/30300 (epoch 37.908), train_loss = 0.97265616, grad/param norm = 1.5303e-01, time/batch = 0.6806s	
22973/30300 (epoch 37.909), train_loss = 0.98819753, grad/param norm = 2.2146e-01, time/batch = 0.6799s	
22974/30300 (epoch 37.911), train_loss = 1.03855374, grad/param norm = 1.6551e-01, time/batch = 0.6833s	
22975/30300 (epoch 37.913), train_loss = 1.03521122, grad/param norm = 1.5199e-01, time/batch = 0.6888s	
22976/30300 (epoch 37.914), train_loss = 1.00125979, grad/param norm = 1.7780e-01, time/batch = 0.6812s	
22977/30300 (epoch 37.916), train_loss = 1.06926243, grad/param norm = 1.5822e-01, time/batch = 0.6831s	
22978/30300 (epoch 37.917), train_loss = 0.98459123, grad/param norm = 1.5074e-01, time/batch = 0.6897s	
22979/30300 (epoch 37.919), train_loss = 0.93613038, grad/param norm = 1.7149e-01, time/batch = 0.6839s	
22980/30300 (epoch 37.921), train_loss = 1.00615555, grad/param norm = 1.5167e-01, time/batch = 0.6817s	
22981/30300 (epoch 37.922), train_loss = 1.12315473, grad/param norm = 1.8990e-01, time/batch = 0.6827s	
22982/30300 (epoch 37.924), train_loss = 1.03368625, grad/param norm = 2.0461e-01, time/batch = 0.6813s	
22983/30300 (epoch 37.926), train_loss = 1.09102563, grad/param norm = 1.8507e-01, time/batch = 0.6811s	
22984/30300 (epoch 37.927), train_loss = 1.06969073, grad/param norm = 1.7627e-01, time/batch = 0.6829s	
22985/30300 (epoch 37.929), train_loss = 0.94977724, grad/param norm = 1.6703e-01, time/batch = 0.6863s	
22986/30300 (epoch 37.931), train_loss = 1.12266960, grad/param norm = 2.0545e-01, time/batch = 0.6867s	
22987/30300 (epoch 37.932), train_loss = 0.94004197, grad/param norm = 1.5514e-01, time/batch = 0.6845s	
22988/30300 (epoch 37.934), train_loss = 1.06182126, grad/param norm = 1.7416e-01, time/batch = 0.6819s	
22989/30300 (epoch 37.936), train_loss = 0.96830792, grad/param norm = 1.6912e-01, time/batch = 0.6826s	
22990/30300 (epoch 37.937), train_loss = 0.96962131, grad/param norm = 1.6442e-01, time/batch = 0.6820s	
22991/30300 (epoch 37.939), train_loss = 1.12682482, grad/param norm = 1.6770e-01, time/batch = 0.6851s	
22992/30300 (epoch 37.941), train_loss = 1.00510041, grad/param norm = 1.6550e-01, time/batch = 0.6863s	
22993/30300 (epoch 37.942), train_loss = 1.03943614, grad/param norm = 1.9306e-01, time/batch = 0.6836s	
22994/30300 (epoch 37.944), train_loss = 0.91532238, grad/param norm = 1.8692e-01, time/batch = 0.6853s	
22995/30300 (epoch 37.946), train_loss = 1.09694408, grad/param norm = 2.2676e-01, time/batch = 0.6807s	
22996/30300 (epoch 37.947), train_loss = 1.08979853, grad/param norm = 2.8300e-01, time/batch = 0.6840s	
22997/30300 (epoch 37.949), train_loss = 1.10643056, grad/param norm = 2.1830e-01, time/batch = 0.6828s	
22998/30300 (epoch 37.950), train_loss = 1.13577230, grad/param norm = 1.8486e-01, time/batch = 0.6845s	
22999/30300 (epoch 37.952), train_loss = 1.06967823, grad/param norm = 1.8102e-01, time/batch = 0.7260s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch37.95_1.9976.t7	
23000/30300 (epoch 37.954), train_loss = 1.28733498, grad/param norm = 1.7693e-01, time/batch = 0.6964s	
23001/30300 (epoch 37.955), train_loss = 1.68133237, grad/param norm = 2.2894e-01, time/batch = 0.6912s	
23002/30300 (epoch 37.957), train_loss = 1.10583921, grad/param norm = 1.7198e-01, time/batch = 0.6920s	
23003/30300 (epoch 37.959), train_loss = 0.95723293, grad/param norm = 1.8958e-01, time/batch = 0.7001s	
23004/30300 (epoch 37.960), train_loss = 0.99280935, grad/param norm = 1.7735e-01, time/batch = 0.7054s	
23005/30300 (epoch 37.962), train_loss = 0.98067182, grad/param norm = 3.5449e-01, time/batch = 0.7062s	
23006/30300 (epoch 37.964), train_loss = 0.95462300, grad/param norm = 2.4052e-01, time/batch = 0.7286s	
23007/30300 (epoch 37.965), train_loss = 0.97296274, grad/param norm = 2.1452e-01, time/batch = 0.6993s	
23008/30300 (epoch 37.967), train_loss = 1.02395142, grad/param norm = 2.1530e-01, time/batch = 0.6886s	
23009/30300 (epoch 37.969), train_loss = 0.96208815, grad/param norm = 2.0064e-01, time/batch = 0.6910s	
23010/30300 (epoch 37.970), train_loss = 0.99989647, grad/param norm = 1.6890e-01, time/batch = 0.6920s	
23011/30300 (epoch 37.972), train_loss = 0.92652386, grad/param norm = 1.7304e-01, time/batch = 0.6888s	
23012/30300 (epoch 37.974), train_loss = 1.16568285, grad/param norm = 1.8354e-01, time/batch = 0.6977s	
23013/30300 (epoch 37.975), train_loss = 1.15778926, grad/param norm = 2.1445e-01, time/batch = 0.7134s	
23014/30300 (epoch 37.977), train_loss = 1.21944207, grad/param norm = 1.9448e-01, time/batch = 0.7124s	
23015/30300 (epoch 37.979), train_loss = 1.10549715, grad/param norm = 1.9171e-01, time/batch = 0.7287s	
23016/30300 (epoch 37.980), train_loss = 1.16271935, grad/param norm = 2.4968e-01, time/batch = 0.7282s	
23017/30300 (epoch 37.982), train_loss = 1.13094090, grad/param norm = 1.9052e-01, time/batch = 0.7237s	
23018/30300 (epoch 37.983), train_loss = 1.15211417, grad/param norm = 1.6567e-01, time/batch = 0.7080s	
23019/30300 (epoch 37.985), train_loss = 1.10436220, grad/param norm = 2.2766e-01, time/batch = 0.7220s	
23020/30300 (epoch 37.987), train_loss = 1.03327868, grad/param norm = 1.6036e-01, time/batch = 0.6992s	
23021/30300 (epoch 37.988), train_loss = 1.16461155, grad/param norm = 1.9991e-01, time/batch = 0.6985s	
23022/30300 (epoch 37.990), train_loss = 0.95674336, grad/param norm = 1.7220e-01, time/batch = 0.7016s	
23023/30300 (epoch 37.992), train_loss = 1.11985863, grad/param norm = 1.5224e-01, time/batch = 0.6915s	
23024/30300 (epoch 37.993), train_loss = 1.15543250, grad/param norm = 2.4006e-01, time/batch = 0.6813s	
23025/30300 (epoch 37.995), train_loss = 1.04935499, grad/param norm = 2.1049e-01, time/batch = 0.6830s	
23026/30300 (epoch 37.997), train_loss = 1.09843615, grad/param norm = 1.8640e-01, time/batch = 0.6863s	
23027/30300 (epoch 37.998), train_loss = 1.10233712, grad/param norm = 1.9964e-01, time/batch = 0.7012s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
23028/30300 (epoch 38.000), train_loss = 0.98191194, grad/param norm = 1.9856e-01, time/batch = 0.7215s	
23029/30300 (epoch 38.002), train_loss = 1.14387042, grad/param norm = 1.9973e-01, time/batch = 0.7111s	
23030/30300 (epoch 38.003), train_loss = 1.06587457, grad/param norm = 1.9194e-01, time/batch = 0.7011s	
23031/30300 (epoch 38.005), train_loss = 1.03062127, grad/param norm = 1.9203e-01, time/batch = 0.6860s	
23032/30300 (epoch 38.007), train_loss = 1.10789112, grad/param norm = 2.1372e-01, time/batch = 0.6930s	
23033/30300 (epoch 38.008), train_loss = 1.02704765, grad/param norm = 1.6664e-01, time/batch = 0.7299s	
23034/30300 (epoch 38.010), train_loss = 0.92814014, grad/param norm = 1.8111e-01, time/batch = 0.6997s	
23035/30300 (epoch 38.012), train_loss = 0.99871762, grad/param norm = 1.6865e-01, time/batch = 0.6961s	
23036/30300 (epoch 38.013), train_loss = 1.12393757, grad/param norm = 1.9362e-01, time/batch = 0.7000s	
23037/30300 (epoch 38.015), train_loss = 0.99483590, grad/param norm = 1.6693e-01, time/batch = 0.6808s	
23038/30300 (epoch 38.017), train_loss = 0.99961690, grad/param norm = 1.4773e-01, time/batch = 0.6818s	
23039/30300 (epoch 38.018), train_loss = 0.93222947, grad/param norm = 1.6588e-01, time/batch = 0.6816s	
23040/30300 (epoch 38.020), train_loss = 1.13460339, grad/param norm = 2.8744e-01, time/batch = 0.6855s	
23041/30300 (epoch 38.021), train_loss = 1.15231459, grad/param norm = 1.7876e-01, time/batch = 0.6830s	
23042/30300 (epoch 38.023), train_loss = 1.05826386, grad/param norm = 1.6673e-01, time/batch = 0.6819s	
23043/30300 (epoch 38.025), train_loss = 0.98197274, grad/param norm = 1.9619e-01, time/batch = 0.6932s	
23044/30300 (epoch 38.026), train_loss = 1.11819369, grad/param norm = 2.2209e-01, time/batch = 0.6934s	
23045/30300 (epoch 38.028), train_loss = 1.10839062, grad/param norm = 1.7139e-01, time/batch = 0.6893s	
23046/30300 (epoch 38.030), train_loss = 1.02041803, grad/param norm = 2.1121e-01, time/batch = 0.6847s	
23047/30300 (epoch 38.031), train_loss = 1.07800688, grad/param norm = 1.7831e-01, time/batch = 0.7206s	
23048/30300 (epoch 38.033), train_loss = 1.07261557, grad/param norm = 1.7583e-01, time/batch = 0.7049s	
23049/30300 (epoch 38.035), train_loss = 1.10105016, grad/param norm = 2.1024e-01, time/batch = 0.6821s	
23050/30300 (epoch 38.036), train_loss = 1.06101024, grad/param norm = 1.8566e-01, time/batch = 0.6819s	
23051/30300 (epoch 38.038), train_loss = 1.07845552, grad/param norm = 1.5428e-01, time/batch = 0.6856s	
23052/30300 (epoch 38.040), train_loss = 0.89169937, grad/param norm = 1.5845e-01, time/batch = 0.6850s	
23053/30300 (epoch 38.041), train_loss = 0.88688046, grad/param norm = 1.7849e-01, time/batch = 0.6809s	
23054/30300 (epoch 38.043), train_loss = 1.06492510, grad/param norm = 1.8341e-01, time/batch = 0.6816s	
23055/30300 (epoch 38.045), train_loss = 0.98437220, grad/param norm = 1.5527e-01, time/batch = 0.6820s	
23056/30300 (epoch 38.046), train_loss = 1.17101579, grad/param norm = 2.3027e-01, time/batch = 0.6819s	
23057/30300 (epoch 38.048), train_loss = 1.05926439, grad/param norm = 2.0057e-01, time/batch = 0.6829s	
23058/30300 (epoch 38.050), train_loss = 0.96345955, grad/param norm = 1.6836e-01, time/batch = 0.6879s	
23059/30300 (epoch 38.051), train_loss = 1.08152461, grad/param norm = 2.1162e-01, time/batch = 0.6816s	
23060/30300 (epoch 38.053), train_loss = 0.92431369, grad/param norm = 2.3285e-01, time/batch = 0.6815s	
23061/30300 (epoch 38.054), train_loss = 1.10392778, grad/param norm = 1.7704e-01, time/batch = 0.6814s	
23062/30300 (epoch 38.056), train_loss = 0.95279057, grad/param norm = 1.6546e-01, time/batch = 0.6828s	
23063/30300 (epoch 38.058), train_loss = 0.99506693, grad/param norm = 1.6962e-01, time/batch = 0.6804s	
23064/30300 (epoch 38.059), train_loss = 1.03733891, grad/param norm = 2.1070e-01, time/batch = 0.6786s	
23065/30300 (epoch 38.061), train_loss = 1.07172922, grad/param norm = 1.8444e-01, time/batch = 0.6789s	
23066/30300 (epoch 38.063), train_loss = 0.92905441, grad/param norm = 1.8057e-01, time/batch = 0.7259s	
23067/30300 (epoch 38.064), train_loss = 1.03671052, grad/param norm = 2.1114e-01, time/batch = 0.6993s	
23068/30300 (epoch 38.066), train_loss = 1.03285062, grad/param norm = 1.5675e-01, time/batch = 0.6841s	
23069/30300 (epoch 38.068), train_loss = 0.95974648, grad/param norm = 1.6398e-01, time/batch = 0.6839s	
23070/30300 (epoch 38.069), train_loss = 1.10768507, grad/param norm = 1.8605e-01, time/batch = 0.6808s	
23071/30300 (epoch 38.071), train_loss = 1.09139469, grad/param norm = 1.8499e-01, time/batch = 0.6844s	
23072/30300 (epoch 38.073), train_loss = 0.96936724, grad/param norm = 1.8373e-01, time/batch = 0.6845s	
23073/30300 (epoch 38.074), train_loss = 1.00880610, grad/param norm = 1.5265e-01, time/batch = 0.6853s	
23074/30300 (epoch 38.076), train_loss = 1.02675065, grad/param norm = 1.7593e-01, time/batch = 0.6902s	
23075/30300 (epoch 38.078), train_loss = 0.97412748, grad/param norm = 1.5788e-01, time/batch = 0.6872s	
23076/30300 (epoch 38.079), train_loss = 0.98753854, grad/param norm = 1.5985e-01, time/batch = 0.6857s	
23077/30300 (epoch 38.081), train_loss = 1.05732654, grad/param norm = 1.9160e-01, time/batch = 0.6862s	
23078/30300 (epoch 38.083), train_loss = 1.09260948, grad/param norm = 2.2023e-01, time/batch = 0.6867s	
23079/30300 (epoch 38.084), train_loss = 0.97554358, grad/param norm = 1.6253e-01, time/batch = 0.6820s	
23080/30300 (epoch 38.086), train_loss = 0.98092182, grad/param norm = 1.7138e-01, time/batch = 0.6831s	
23081/30300 (epoch 38.087), train_loss = 0.96009495, grad/param norm = 1.5478e-01, time/batch = 0.6891s	
23082/30300 (epoch 38.089), train_loss = 0.97034754, grad/param norm = 1.7203e-01, time/batch = 0.7006s	
23083/30300 (epoch 38.091), train_loss = 1.07794187, grad/param norm = 1.7806e-01, time/batch = 0.6837s	
23084/30300 (epoch 38.092), train_loss = 1.09977211, grad/param norm = 1.7473e-01, time/batch = 0.6921s	
23085/30300 (epoch 38.094), train_loss = 1.14981337, grad/param norm = 2.5858e-01, time/batch = 0.7258s	
23086/30300 (epoch 38.096), train_loss = 1.14552703, grad/param norm = 1.8453e-01, time/batch = 0.6895s	
23087/30300 (epoch 38.097), train_loss = 0.97791558, grad/param norm = 1.8581e-01, time/batch = 0.6910s	
23088/30300 (epoch 38.099), train_loss = 1.09683253, grad/param norm = 1.5650e-01, time/batch = 0.7011s	
23089/30300 (epoch 38.101), train_loss = 1.15258324, grad/param norm = 1.9966e-01, time/batch = 0.7055s	
23090/30300 (epoch 38.102), train_loss = 0.97914334, grad/param norm = 1.8761e-01, time/batch = 0.6963s	
23091/30300 (epoch 38.104), train_loss = 1.00385491, grad/param norm = 2.0935e-01, time/batch = 0.7180s	
23092/30300 (epoch 38.106), train_loss = 0.97918998, grad/param norm = 1.7085e-01, time/batch = 0.6870s	
23093/30300 (epoch 38.107), train_loss = 1.08599685, grad/param norm = 1.6158e-01, time/batch = 0.6895s	
23094/30300 (epoch 38.109), train_loss = 1.11926907, grad/param norm = 2.4732e-01, time/batch = 0.6820s	
23095/30300 (epoch 38.111), train_loss = 1.08894239, grad/param norm = 1.9428e-01, time/batch = 0.6816s	
23096/30300 (epoch 38.112), train_loss = 1.18237665, grad/param norm = 1.9441e-01, time/batch = 0.6816s	
23097/30300 (epoch 38.114), train_loss = 1.01591446, grad/param norm = 1.6364e-01, time/batch = 0.6876s	
23098/30300 (epoch 38.116), train_loss = 1.07720753, grad/param norm = 1.8603e-01, time/batch = 0.6905s	
23099/30300 (epoch 38.117), train_loss = 1.14985894, grad/param norm = 1.8073e-01, time/batch = 0.6882s	
23100/30300 (epoch 38.119), train_loss = 0.94793496, grad/param norm = 1.8673e-01, time/batch = 0.6874s	
23101/30300 (epoch 38.120), train_loss = 1.01056112, grad/param norm = 1.7635e-01, time/batch = 0.6868s	
23102/30300 (epoch 38.122), train_loss = 1.13682257, grad/param norm = 2.1736e-01, time/batch = 0.6868s	
23103/30300 (epoch 38.124), train_loss = 1.19151007, grad/param norm = 1.9638e-01, time/batch = 0.7076s	
23104/30300 (epoch 38.125), train_loss = 0.93872380, grad/param norm = 1.6789e-01, time/batch = 0.7195s	
23105/30300 (epoch 38.127), train_loss = 1.08012352, grad/param norm = 2.1554e-01, time/batch = 0.6886s	
23106/30300 (epoch 38.129), train_loss = 1.13436305, grad/param norm = 1.8413e-01, time/batch = 0.6822s	
23107/30300 (epoch 38.130), train_loss = 1.17837959, grad/param norm = 1.7821e-01, time/batch = 0.6840s	
23108/30300 (epoch 38.132), train_loss = 1.16211520, grad/param norm = 1.8406e-01, time/batch = 0.6833s	
23109/30300 (epoch 38.134), train_loss = 0.97186576, grad/param norm = 1.9240e-01, time/batch = 0.6831s	
23110/30300 (epoch 38.135), train_loss = 0.99423725, grad/param norm = 2.0346e-01, time/batch = 0.6842s	
23111/30300 (epoch 38.137), train_loss = 1.04481493, grad/param norm = 1.8601e-01, time/batch = 0.6876s	
23112/30300 (epoch 38.139), train_loss = 0.98062726, grad/param norm = 2.1889e-01, time/batch = 0.6873s	
23113/30300 (epoch 38.140), train_loss = 1.05467112, grad/param norm = 2.3982e-01, time/batch = 0.6842s	
23114/30300 (epoch 38.142), train_loss = 1.11753657, grad/param norm = 2.0283e-01, time/batch = 0.6865s	
23115/30300 (epoch 38.144), train_loss = 0.98165929, grad/param norm = 2.5436e-01, time/batch = 0.6827s	
23116/30300 (epoch 38.145), train_loss = 1.12381179, grad/param norm = 2.1329e-01, time/batch = 0.6841s	
23117/30300 (epoch 38.147), train_loss = 1.00200429, grad/param norm = 1.9802e-01, time/batch = 0.6822s	
23118/30300 (epoch 38.149), train_loss = 1.13386076, grad/param norm = 2.3904e-01, time/batch = 0.6853s	
23119/30300 (epoch 38.150), train_loss = 1.03032829, grad/param norm = 1.9676e-01, time/batch = 0.6867s	
23120/30300 (epoch 38.152), train_loss = 0.92340279, grad/param norm = 1.7588e-01, time/batch = 0.6888s	
23121/30300 (epoch 38.153), train_loss = 1.06206205, grad/param norm = 2.0884e-01, time/batch = 0.6863s	
23122/30300 (epoch 38.155), train_loss = 0.93272102, grad/param norm = 1.6987e-01, time/batch = 0.6848s	
23123/30300 (epoch 38.157), train_loss = 0.97882580, grad/param norm = 2.0126e-01, time/batch = 0.6871s	
23124/30300 (epoch 38.158), train_loss = 1.07519787, grad/param norm = 2.1666e-01, time/batch = 0.6817s	
23125/30300 (epoch 38.160), train_loss = 0.96851807, grad/param norm = 1.9230e-01, time/batch = 0.6833s	
23126/30300 (epoch 38.162), train_loss = 1.04837420, grad/param norm = 1.6644e-01, time/batch = 0.6999s	
23127/30300 (epoch 38.163), train_loss = 1.04683500, grad/param norm = 2.0549e-01, time/batch = 0.7256s	
23128/30300 (epoch 38.165), train_loss = 1.16347596, grad/param norm = 2.0411e-01, time/batch = 0.6834s	
23129/30300 (epoch 38.167), train_loss = 1.05866348, grad/param norm = 1.8868e-01, time/batch = 0.6835s	
23130/30300 (epoch 38.168), train_loss = 1.09343816, grad/param norm = 1.8337e-01, time/batch = 0.6921s	
23131/30300 (epoch 38.170), train_loss = 1.05221666, grad/param norm = 1.9388e-01, time/batch = 0.6891s	
23132/30300 (epoch 38.172), train_loss = 1.04388898, grad/param norm = 1.9135e-01, time/batch = 0.6857s	
23133/30300 (epoch 38.173), train_loss = 0.99695975, grad/param norm = 1.7643e-01, time/batch = 0.6837s	
23134/30300 (epoch 38.175), train_loss = 1.06625583, grad/param norm = 1.9664e-01, time/batch = 0.6861s	
23135/30300 (epoch 38.177), train_loss = 1.09983998, grad/param norm = 1.7270e-01, time/batch = 0.6840s	
23136/30300 (epoch 38.178), train_loss = 0.86075291, grad/param norm = 1.6139e-01, time/batch = 0.6856s	
23137/30300 (epoch 38.180), train_loss = 1.01991509, grad/param norm = 1.5934e-01, time/batch = 0.7110s	
23138/30300 (epoch 38.182), train_loss = 1.05664162, grad/param norm = 1.9837e-01, time/batch = 0.6929s	
23139/30300 (epoch 38.183), train_loss = 0.97776662, grad/param norm = 1.8132e-01, time/batch = 0.7000s	
23140/30300 (epoch 38.185), train_loss = 1.17970410, grad/param norm = 1.9069e-01, time/batch = 0.7056s	
23141/30300 (epoch 38.186), train_loss = 1.26190928, grad/param norm = 2.4083e-01, time/batch = 0.6936s	
23142/30300 (epoch 38.188), train_loss = 1.08777869, grad/param norm = 1.7796e-01, time/batch = 0.6849s	
23143/30300 (epoch 38.190), train_loss = 1.03415857, grad/param norm = 1.6928e-01, time/batch = 0.6838s	
23144/30300 (epoch 38.191), train_loss = 1.10059897, grad/param norm = 1.9604e-01, time/batch = 0.6823s	
23145/30300 (epoch 38.193), train_loss = 0.94739305, grad/param norm = 1.6885e-01, time/batch = 0.6839s	
23146/30300 (epoch 38.195), train_loss = 0.98708900, grad/param norm = 1.7294e-01, time/batch = 0.6849s	
23147/30300 (epoch 38.196), train_loss = 1.07398943, grad/param norm = 1.5446e-01, time/batch = 0.6832s	
23148/30300 (epoch 38.198), train_loss = 0.88580960, grad/param norm = 1.7054e-01, time/batch = 0.6851s	
23149/30300 (epoch 38.200), train_loss = 1.01327589, grad/param norm = 1.7501e-01, time/batch = 0.6845s	
23150/30300 (epoch 38.201), train_loss = 1.11411756, grad/param norm = 2.0569e-01, time/batch = 0.6956s	
23151/30300 (epoch 38.203), train_loss = 1.03807571, grad/param norm = 1.9963e-01, time/batch = 0.7013s	
23152/30300 (epoch 38.205), train_loss = 1.22457991, grad/param norm = 1.9487e-01, time/batch = 0.6967s	
23153/30300 (epoch 38.206), train_loss = 1.12311334, grad/param norm = 2.1779e-01, time/batch = 0.6878s	
23154/30300 (epoch 38.208), train_loss = 1.10012975, grad/param norm = 1.9685e-01, time/batch = 0.6843s	
23155/30300 (epoch 38.210), train_loss = 1.12443307, grad/param norm = 1.8541e-01, time/batch = 0.6856s	
23156/30300 (epoch 38.211), train_loss = 1.16350993, grad/param norm = 1.9522e-01, time/batch = 0.6836s	
23157/30300 (epoch 38.213), train_loss = 1.06071794, grad/param norm = 1.6374e-01, time/batch = 0.6844s	
23158/30300 (epoch 38.215), train_loss = 0.96066397, grad/param norm = 1.7820e-01, time/batch = 0.6844s	
23159/30300 (epoch 38.216), train_loss = 0.98321999, grad/param norm = 1.6325e-01, time/batch = 0.6888s	
23160/30300 (epoch 38.218), train_loss = 0.96317364, grad/param norm = 1.6822e-01, time/batch = 0.6820s	
23161/30300 (epoch 38.219), train_loss = 0.91462009, grad/param norm = 1.6865e-01, time/batch = 0.6860s	
23162/30300 (epoch 38.221), train_loss = 0.88523532, grad/param norm = 1.5676e-01, time/batch = 0.6834s	
23163/30300 (epoch 38.223), train_loss = 1.03234710, grad/param norm = 1.7481e-01, time/batch = 0.6854s	
23164/30300 (epoch 38.224), train_loss = 0.86667810, grad/param norm = 1.6730e-01, time/batch = 0.6841s	
23165/30300 (epoch 38.226), train_loss = 1.07627999, grad/param norm = 1.9254e-01, time/batch = 0.6903s	
23166/30300 (epoch 38.228), train_loss = 1.14893556, grad/param norm = 1.8374e-01, time/batch = 0.6868s	
23167/30300 (epoch 38.229), train_loss = 1.03146168, grad/param norm = 1.8641e-01, time/batch = 0.6849s	
23168/30300 (epoch 38.231), train_loss = 1.11327599, grad/param norm = 1.9464e-01, time/batch = 0.6828s	
23169/30300 (epoch 38.233), train_loss = 1.08122609, grad/param norm = 1.4560e-01, time/batch = 0.6812s	
23170/30300 (epoch 38.234), train_loss = 1.12394307, grad/param norm = 2.1236e-01, time/batch = 0.6825s	
23171/30300 (epoch 38.236), train_loss = 1.08668440, grad/param norm = 1.6002e-01, time/batch = 0.6836s	
23172/30300 (epoch 38.238), train_loss = 1.04441508, grad/param norm = 2.0378e-01, time/batch = 0.6829s	
23173/30300 (epoch 38.239), train_loss = 1.01473670, grad/param norm = 2.0913e-01, time/batch = 0.6833s	
23174/30300 (epoch 38.241), train_loss = 1.08425138, grad/param norm = 1.9635e-01, time/batch = 0.6860s	
23175/30300 (epoch 38.243), train_loss = 1.08161185, grad/param norm = 1.6807e-01, time/batch = 0.6939s	
23176/30300 (epoch 38.244), train_loss = 1.23688657, grad/param norm = 1.9148e-01, time/batch = 0.7107s	
23177/30300 (epoch 38.246), train_loss = 1.07272491, grad/param norm = 1.6811e-01, time/batch = 0.6900s	
23178/30300 (epoch 38.248), train_loss = 1.02823179, grad/param norm = 1.6421e-01, time/batch = 0.7203s	
23179/30300 (epoch 38.249), train_loss = 0.95501765, grad/param norm = 2.0190e-01, time/batch = 0.7249s	
23180/30300 (epoch 38.251), train_loss = 0.97469015, grad/param norm = 1.7736e-01, time/batch = 0.6869s	
23181/30300 (epoch 38.252), train_loss = 1.14604522, grad/param norm = 1.9259e-01, time/batch = 0.6858s	
23182/30300 (epoch 38.254), train_loss = 1.13998090, grad/param norm = 1.8971e-01, time/batch = 0.6834s	
23183/30300 (epoch 38.256), train_loss = 1.08104605, grad/param norm = 1.6951e-01, time/batch = 0.7022s	
23184/30300 (epoch 38.257), train_loss = 1.11110290, grad/param norm = 1.9905e-01, time/batch = 0.6852s	
23185/30300 (epoch 38.259), train_loss = 1.02268818, grad/param norm = 1.7299e-01, time/batch = 0.6844s	
23186/30300 (epoch 38.261), train_loss = 1.17963860, grad/param norm = 1.7047e-01, time/batch = 0.6846s	
23187/30300 (epoch 38.262), train_loss = 0.96741652, grad/param norm = 1.6556e-01, time/batch = 0.6875s	
23188/30300 (epoch 38.264), train_loss = 1.04296664, grad/param norm = 1.7107e-01, time/batch = 0.6838s	
23189/30300 (epoch 38.266), train_loss = 1.03149786, grad/param norm = 1.5842e-01, time/batch = 0.6840s	
23190/30300 (epoch 38.267), train_loss = 1.19108247, grad/param norm = 1.9761e-01, time/batch = 0.6831s	
23191/30300 (epoch 38.269), train_loss = 1.07114313, grad/param norm = 1.7310e-01, time/batch = 0.6876s	
23192/30300 (epoch 38.271), train_loss = 1.06789075, grad/param norm = 1.7660e-01, time/batch = 0.6864s	
23193/30300 (epoch 38.272), train_loss = 1.07594026, grad/param norm = 2.0715e-01, time/batch = 0.6832s	
23194/30300 (epoch 38.274), train_loss = 1.11984112, grad/param norm = 1.9487e-01, time/batch = 0.6843s	
23195/30300 (epoch 38.276), train_loss = 1.07836608, grad/param norm = 1.9856e-01, time/batch = 0.6839s	
23196/30300 (epoch 38.277), train_loss = 0.93938023, grad/param norm = 1.7169e-01, time/batch = 0.6871s	
23197/30300 (epoch 38.279), train_loss = 1.05687778, grad/param norm = 1.9077e-01, time/batch = 0.7182s	
23198/30300 (epoch 38.281), train_loss = 1.13211324, grad/param norm = 2.1256e-01, time/batch = 0.7258s	
23199/30300 (epoch 38.282), train_loss = 1.09337519, grad/param norm = 1.6523e-01, time/batch = 0.6923s	
23200/30300 (epoch 38.284), train_loss = 1.12946525, grad/param norm = 2.2223e-01, time/batch = 0.6923s	
23201/30300 (epoch 38.285), train_loss = 1.09689881, grad/param norm = 1.5878e-01, time/batch = 0.6925s	
23202/30300 (epoch 38.287), train_loss = 1.04882066, grad/param norm = 1.7544e-01, time/batch = 0.6795s	
23203/30300 (epoch 38.289), train_loss = 1.12149556, grad/param norm = 1.6951e-01, time/batch = 0.6827s	
23204/30300 (epoch 38.290), train_loss = 0.84393265, grad/param norm = 1.8089e-01, time/batch = 0.6823s	
23205/30300 (epoch 38.292), train_loss = 0.95171195, grad/param norm = 1.9517e-01, time/batch = 0.6860s	
23206/30300 (epoch 38.294), train_loss = 1.11553365, grad/param norm = 2.2035e-01, time/batch = 0.6816s	
23207/30300 (epoch 38.295), train_loss = 1.00413234, grad/param norm = 1.7182e-01, time/batch = 0.6962s	
23208/30300 (epoch 38.297), train_loss = 1.02163029, grad/param norm = 1.6840e-01, time/batch = 0.7058s	
23209/30300 (epoch 38.299), train_loss = 1.03674114, grad/param norm = 1.7451e-01, time/batch = 0.6812s	
23210/30300 (epoch 38.300), train_loss = 0.96526109, grad/param norm = 1.7206e-01, time/batch = 0.6870s	
23211/30300 (epoch 38.302), train_loss = 1.11681833, grad/param norm = 1.7237e-01, time/batch = 0.7013s	
23212/30300 (epoch 38.304), train_loss = 0.96489932, grad/param norm = 1.6121e-01, time/batch = 0.7269s	
23213/30300 (epoch 38.305), train_loss = 1.03951513, grad/param norm = 1.6313e-01, time/batch = 0.6852s	
23214/30300 (epoch 38.307), train_loss = 1.14123088, grad/param norm = 1.6826e-01, time/batch = 0.6826s	
23215/30300 (epoch 38.309), train_loss = 1.08262973, grad/param norm = 1.7817e-01, time/batch = 0.6810s	
23216/30300 (epoch 38.310), train_loss = 1.03425723, grad/param norm = 1.8040e-01, time/batch = 0.7020s	
23217/30300 (epoch 38.312), train_loss = 1.16139169, grad/param norm = 1.6464e-01, time/batch = 0.6906s	
23218/30300 (epoch 38.314), train_loss = 1.06014462, grad/param norm = 1.8842e-01, time/batch = 0.7216s	
23219/30300 (epoch 38.315), train_loss = 1.00756045, grad/param norm = 1.7762e-01, time/batch = 0.7373s	
23220/30300 (epoch 38.317), train_loss = 1.07190609, grad/param norm = 1.5786e-01, time/batch = 0.7084s	
23221/30300 (epoch 38.318), train_loss = 1.11414589, grad/param norm = 1.8874e-01, time/batch = 0.7001s	
23222/30300 (epoch 38.320), train_loss = 1.09265812, grad/param norm = 2.0139e-01, time/batch = 0.6881s	
23223/30300 (epoch 38.322), train_loss = 0.99455021, grad/param norm = 1.6697e-01, time/batch = 0.6928s	
23224/30300 (epoch 38.323), train_loss = 1.16590832, grad/param norm = 1.8703e-01, time/batch = 0.6866s	
23225/30300 (epoch 38.325), train_loss = 1.03720150, grad/param norm = 1.6938e-01, time/batch = 0.6991s	
23226/30300 (epoch 38.327), train_loss = 1.02525955, grad/param norm = 1.5778e-01, time/batch = 0.7270s	
23227/30300 (epoch 38.328), train_loss = 1.06972440, grad/param norm = 1.6968e-01, time/batch = 0.6976s	
23228/30300 (epoch 38.330), train_loss = 1.09865278, grad/param norm = 1.8738e-01, time/batch = 0.6821s	
23229/30300 (epoch 38.332), train_loss = 1.15044397, grad/param norm = 2.4782e-01, time/batch = 0.6814s	
23230/30300 (epoch 38.333), train_loss = 0.97200571, grad/param norm = 1.8174e-01, time/batch = 0.6890s	
23231/30300 (epoch 38.335), train_loss = 0.94606754, grad/param norm = 1.6050e-01, time/batch = 0.6856s	
23232/30300 (epoch 38.337), train_loss = 1.17425981, grad/param norm = 1.6604e-01, time/batch = 0.6853s	
23233/30300 (epoch 38.338), train_loss = 0.99687365, grad/param norm = 1.6122e-01, time/batch = 0.6861s	
23234/30300 (epoch 38.340), train_loss = 0.99727597, grad/param norm = 2.0031e-01, time/batch = 0.6856s	
23235/30300 (epoch 38.342), train_loss = 1.12254006, grad/param norm = 1.7154e-01, time/batch = 0.6855s	
23236/30300 (epoch 38.343), train_loss = 1.08367295, grad/param norm = 2.0207e-01, time/batch = 0.6831s	
23237/30300 (epoch 38.345), train_loss = 1.09896715, grad/param norm = 1.7206e-01, time/batch = 0.6821s	
23238/30300 (epoch 38.347), train_loss = 0.93233326, grad/param norm = 1.7407e-01, time/batch = 0.6818s	
23239/30300 (epoch 38.348), train_loss = 1.00357238, grad/param norm = 1.6899e-01, time/batch = 0.6847s	
23240/30300 (epoch 38.350), train_loss = 1.00819214, grad/param norm = 1.7575e-01, time/batch = 0.6833s	
23241/30300 (epoch 38.351), train_loss = 1.02236949, grad/param norm = 1.6562e-01, time/batch = 0.6880s	
23242/30300 (epoch 38.353), train_loss = 0.92225669, grad/param norm = 1.5706e-01, time/batch = 0.6858s	
23243/30300 (epoch 38.355), train_loss = 1.00578608, grad/param norm = 1.6104e-01, time/batch = 0.6866s	
23244/30300 (epoch 38.356), train_loss = 1.11668814, grad/param norm = 2.0899e-01, time/batch = 0.7075s	
23245/30300 (epoch 38.358), train_loss = 1.28037885, grad/param norm = 1.6266e-01, time/batch = 0.7047s	
23246/30300 (epoch 38.360), train_loss = 0.99235652, grad/param norm = 1.8564e-01, time/batch = 0.6941s	
23247/30300 (epoch 38.361), train_loss = 1.03795112, grad/param norm = 1.8677e-01, time/batch = 0.7031s	
23248/30300 (epoch 38.363), train_loss = 1.06889767, grad/param norm = 1.9104e-01, time/batch = 0.7091s	
23249/30300 (epoch 38.365), train_loss = 0.91484111, grad/param norm = 1.7342e-01, time/batch = 0.7367s	
23250/30300 (epoch 38.366), train_loss = 1.02445544, grad/param norm = 1.6013e-01, time/batch = 0.7151s	
23251/30300 (epoch 38.368), train_loss = 0.91650868, grad/param norm = 1.6074e-01, time/batch = 0.6877s	
23252/30300 (epoch 38.370), train_loss = 0.97412028, grad/param norm = 1.6735e-01, time/batch = 0.6803s	
23253/30300 (epoch 38.371), train_loss = 1.10694236, grad/param norm = 1.8255e-01, time/batch = 0.6806s	
23254/30300 (epoch 38.373), train_loss = 0.99388835, grad/param norm = 1.5055e-01, time/batch = 0.6803s	
23255/30300 (epoch 38.375), train_loss = 0.96905002, grad/param norm = 1.4428e-01, time/batch = 0.6808s	
23256/30300 (epoch 38.376), train_loss = 0.95853786, grad/param norm = 1.5262e-01, time/batch = 0.6837s	
23257/30300 (epoch 38.378), train_loss = 0.96358990, grad/param norm = 1.8815e-01, time/batch = 0.6854s	
23258/30300 (epoch 38.380), train_loss = 1.16048640, grad/param norm = 1.8309e-01, time/batch = 0.6845s	
23259/30300 (epoch 38.381), train_loss = 0.88312763, grad/param norm = 1.6339e-01, time/batch = 0.6804s	
23260/30300 (epoch 38.383), train_loss = 0.94412956, grad/param norm = 2.3383e-01, time/batch = 0.6803s	
23261/30300 (epoch 38.384), train_loss = 1.09078708, grad/param norm = 1.8159e-01, time/batch = 0.6926s	
23262/30300 (epoch 38.386), train_loss = 0.94089193, grad/param norm = 1.8904e-01, time/batch = 0.7007s	
23263/30300 (epoch 38.388), train_loss = 0.92499537, grad/param norm = 1.9413e-01, time/batch = 0.7248s	
23264/30300 (epoch 38.389), train_loss = 1.02867795, grad/param norm = 1.8725e-01, time/batch = 0.7297s	
23265/30300 (epoch 38.391), train_loss = 1.06942878, grad/param norm = 1.6711e-01, time/batch = 0.7437s	
23266/30300 (epoch 38.393), train_loss = 0.91309393, grad/param norm = 1.4200e-01, time/batch = 0.6886s	
23267/30300 (epoch 38.394), train_loss = 1.06228441, grad/param norm = 1.5849e-01, time/batch = 0.6803s	
23268/30300 (epoch 38.396), train_loss = 1.15362303, grad/param norm = 1.5596e-01, time/batch = 0.6791s	
23269/30300 (epoch 38.398), train_loss = 1.00847682, grad/param norm = 1.7062e-01, time/batch = 0.6815s	
23270/30300 (epoch 38.399), train_loss = 0.96209853, grad/param norm = 1.7443e-01, time/batch = 0.6954s	
23271/30300 (epoch 38.401), train_loss = 1.04198796, grad/param norm = 1.9401e-01, time/batch = 0.6875s	
23272/30300 (epoch 38.403), train_loss = 1.02963706, grad/param norm = 1.8096e-01, time/batch = 0.6853s	
23273/30300 (epoch 38.404), train_loss = 0.97663357, grad/param norm = 1.9336e-01, time/batch = 0.6836s	
23274/30300 (epoch 38.406), train_loss = 1.05485983, grad/param norm = 1.6337e-01, time/batch = 0.6810s	
23275/30300 (epoch 38.408), train_loss = 0.91197634, grad/param norm = 1.4637e-01, time/batch = 0.6809s	
23276/30300 (epoch 38.409), train_loss = 0.91010337, grad/param norm = 1.8185e-01, time/batch = 0.6817s	
23277/30300 (epoch 38.411), train_loss = 0.96408952, grad/param norm = 1.5873e-01, time/batch = 0.6814s	
23278/30300 (epoch 38.413), train_loss = 0.87965807, grad/param norm = 1.6950e-01, time/batch = 0.6888s	
23279/30300 (epoch 38.414), train_loss = 1.08081614, grad/param norm = 1.7454e-01, time/batch = 0.6882s	
23280/30300 (epoch 38.416), train_loss = 0.97090404, grad/param norm = 1.4638e-01, time/batch = 0.6871s	
23281/30300 (epoch 38.417), train_loss = 0.92774576, grad/param norm = 1.6360e-01, time/batch = 0.6882s	
23282/30300 (epoch 38.419), train_loss = 0.93908862, grad/param norm = 1.7735e-01, time/batch = 0.7249s	
23283/30300 (epoch 38.421), train_loss = 0.99255217, grad/param norm = 2.0838e-01, time/batch = 0.7000s	
23284/30300 (epoch 38.422), train_loss = 1.04508483, grad/param norm = 1.7441e-01, time/batch = 0.6821s	
23285/30300 (epoch 38.424), train_loss = 1.05149307, grad/param norm = 1.7176e-01, time/batch = 0.6823s	
23286/30300 (epoch 38.426), train_loss = 0.99713140, grad/param norm = 1.7244e-01, time/batch = 0.6845s	
23287/30300 (epoch 38.427), train_loss = 0.96874973, grad/param norm = 1.7066e-01, time/batch = 0.6870s	
23288/30300 (epoch 38.429), train_loss = 1.01867411, grad/param norm = 1.6040e-01, time/batch = 0.6907s	
23289/30300 (epoch 38.431), train_loss = 1.06906750, grad/param norm = 1.6606e-01, time/batch = 0.6960s	
23290/30300 (epoch 38.432), train_loss = 1.03669108, grad/param norm = 1.6553e-01, time/batch = 0.6941s	
23291/30300 (epoch 38.434), train_loss = 0.92689979, grad/param norm = 1.6294e-01, time/batch = 0.6898s	
23292/30300 (epoch 38.436), train_loss = 1.11941903, grad/param norm = 1.6206e-01, time/batch = 0.6826s	
23293/30300 (epoch 38.437), train_loss = 0.94084697, grad/param norm = 1.6876e-01, time/batch = 0.6808s	
23294/30300 (epoch 38.439), train_loss = 0.97674660, grad/param norm = 1.7583e-01, time/batch = 0.6823s	
23295/30300 (epoch 38.441), train_loss = 1.03620261, grad/param norm = 2.1833e-01, time/batch = 0.6856s	
23296/30300 (epoch 38.442), train_loss = 0.96617979, grad/param norm = 1.5596e-01, time/batch = 0.6841s	
23297/30300 (epoch 38.444), train_loss = 0.83945502, grad/param norm = 1.4604e-01, time/batch = 0.6815s	
23298/30300 (epoch 38.446), train_loss = 0.99474680, grad/param norm = 1.5545e-01, time/batch = 0.6815s	
23299/30300 (epoch 38.447), train_loss = 1.01978378, grad/param norm = 1.5990e-01, time/batch = 0.6829s	
23300/30300 (epoch 38.449), train_loss = 0.95207929, grad/param norm = 1.5916e-01, time/batch = 0.6888s	
23301/30300 (epoch 38.450), train_loss = 1.03991870, grad/param norm = 1.5050e-01, time/batch = 0.7277s	
23302/30300 (epoch 38.452), train_loss = 1.13304056, grad/param norm = 1.6133e-01, time/batch = 0.6941s	
23303/30300 (epoch 38.454), train_loss = 1.07912415, grad/param norm = 1.5604e-01, time/batch = 0.6866s	
23304/30300 (epoch 38.455), train_loss = 1.02894304, grad/param norm = 1.8110e-01, time/batch = 0.6835s	
23305/30300 (epoch 38.457), train_loss = 0.98306533, grad/param norm = 1.5775e-01, time/batch = 0.6837s	
23306/30300 (epoch 38.459), train_loss = 1.08457015, grad/param norm = 1.8065e-01, time/batch = 0.6837s	
23307/30300 (epoch 38.460), train_loss = 1.09118920, grad/param norm = 1.6898e-01, time/batch = 0.6851s	
23308/30300 (epoch 38.462), train_loss = 1.10533937, grad/param norm = 1.8049e-01, time/batch = 0.6832s	
23309/30300 (epoch 38.464), train_loss = 0.85185407, grad/param norm = 1.8722e-01, time/batch = 0.6844s	
23310/30300 (epoch 38.465), train_loss = 0.87657619, grad/param norm = 1.4595e-01, time/batch = 0.6872s	
23311/30300 (epoch 38.467), train_loss = 0.87112532, grad/param norm = 1.5503e-01, time/batch = 0.6915s	
23312/30300 (epoch 38.469), train_loss = 0.95039857, grad/param norm = 1.5552e-01, time/batch = 0.6823s	
23313/30300 (epoch 38.470), train_loss = 0.97196158, grad/param norm = 1.7439e-01, time/batch = 0.6831s	
23314/30300 (epoch 38.472), train_loss = 0.97908137, grad/param norm = 1.5395e-01, time/batch = 0.6842s	
23315/30300 (epoch 38.474), train_loss = 0.97125330, grad/param norm = 1.9254e-01, time/batch = 0.6825s	
23316/30300 (epoch 38.475), train_loss = 0.96141165, grad/param norm = 1.6151e-01, time/batch = 0.6863s	
23317/30300 (epoch 38.477), train_loss = 1.02613697, grad/param norm = 1.6964e-01, time/batch = 0.6925s	
23318/30300 (epoch 38.479), train_loss = 0.99019320, grad/param norm = 1.7145e-01, time/batch = 0.7148s	
23319/30300 (epoch 38.480), train_loss = 1.04223832, grad/param norm = 1.7327e-01, time/batch = 0.7346s	
23320/30300 (epoch 38.482), train_loss = 1.08175574, grad/param norm = 1.6176e-01, time/batch = 0.7504s	
23321/30300 (epoch 38.483), train_loss = 0.99328475, grad/param norm = 1.6356e-01, time/batch = 0.6954s	
23322/30300 (epoch 38.485), train_loss = 1.03095926, grad/param norm = 1.5675e-01, time/batch = 0.6876s	
23323/30300 (epoch 38.487), train_loss = 1.08706495, grad/param norm = 1.6674e-01, time/batch = 0.7222s	
23324/30300 (epoch 38.488), train_loss = 1.14825353, grad/param norm = 1.5549e-01, time/batch = 0.7241s	
23325/30300 (epoch 38.490), train_loss = 0.89460511, grad/param norm = 1.5809e-01, time/batch = 0.7137s	
23326/30300 (epoch 38.492), train_loss = 0.99261532, grad/param norm = 1.9187e-01, time/batch = 0.6932s	
23327/30300 (epoch 38.493), train_loss = 1.02554793, grad/param norm = 1.7206e-01, time/batch = 0.7192s	
23328/30300 (epoch 38.495), train_loss = 0.99608201, grad/param norm = 1.5620e-01, time/batch = 0.7188s	
23329/30300 (epoch 38.497), train_loss = 1.05650285, grad/param norm = 1.6994e-01, time/batch = 0.7159s	
23330/30300 (epoch 38.498), train_loss = 1.06988968, grad/param norm = 1.6234e-01, time/batch = 0.7044s	
23331/30300 (epoch 38.500), train_loss = 0.98454306, grad/param norm = 1.7839e-01, time/batch = 0.7017s	
23332/30300 (epoch 38.502), train_loss = 1.00486861, grad/param norm = 1.8249e-01, time/batch = 0.6865s	
23333/30300 (epoch 38.503), train_loss = 1.11635038, grad/param norm = 1.7478e-01, time/batch = 0.6839s	
23334/30300 (epoch 38.505), train_loss = 0.92167534, grad/param norm = 1.6183e-01, time/batch = 0.6818s	
23335/30300 (epoch 38.507), train_loss = 0.92412382, grad/param norm = 1.9434e-01, time/batch = 0.6830s	
23336/30300 (epoch 38.508), train_loss = 0.97368860, grad/param norm = 2.1433e-01, time/batch = 0.6824s	
23337/30300 (epoch 38.510), train_loss = 1.10211861, grad/param norm = 1.9830e-01, time/batch = 0.6817s	
23338/30300 (epoch 38.512), train_loss = 0.96061661, grad/param norm = 1.5305e-01, time/batch = 0.6826s	
23339/30300 (epoch 38.513), train_loss = 1.02487754, grad/param norm = 1.7519e-01, time/batch = 0.6851s	
23340/30300 (epoch 38.515), train_loss = 1.00306575, grad/param norm = 1.6578e-01, time/batch = 0.6860s	
23341/30300 (epoch 38.517), train_loss = 0.84923163, grad/param norm = 1.4032e-01, time/batch = 0.6870s	
23342/30300 (epoch 38.518), train_loss = 1.10572328, grad/param norm = 1.7983e-01, time/batch = 0.6836s	
23343/30300 (epoch 38.520), train_loss = 1.02404117, grad/param norm = 1.7955e-01, time/batch = 0.6866s	
23344/30300 (epoch 38.521), train_loss = 0.91580668, grad/param norm = 1.7551e-01, time/batch = 0.6890s	
23345/30300 (epoch 38.523), train_loss = 1.15428301, grad/param norm = 2.1574e-01, time/batch = 0.6870s	
23346/30300 (epoch 38.525), train_loss = 0.94835295, grad/param norm = 1.8458e-01, time/batch = 0.6893s	
23347/30300 (epoch 38.526), train_loss = 1.04191810, grad/param norm = 1.9416e-01, time/batch = 0.6992s	
23348/30300 (epoch 38.528), train_loss = 0.91327329, grad/param norm = 1.6296e-01, time/batch = 0.7268s	
23349/30300 (epoch 38.530), train_loss = 0.89688598, grad/param norm = 1.6140e-01, time/batch = 0.7236s	
23350/30300 (epoch 38.531), train_loss = 1.02020586, grad/param norm = 1.6159e-01, time/batch = 0.7552s	
23351/30300 (epoch 38.533), train_loss = 0.99506032, grad/param norm = 1.8044e-01, time/batch = 0.7217s	
23352/30300 (epoch 38.535), train_loss = 1.00250140, grad/param norm = 1.5713e-01, time/batch = 0.7093s	
23353/30300 (epoch 38.536), train_loss = 1.02944448, grad/param norm = 1.7124e-01, time/batch = 0.7038s	
23354/30300 (epoch 38.538), train_loss = 0.89349210, grad/param norm = 1.7117e-01, time/batch = 0.7015s	
23355/30300 (epoch 38.540), train_loss = 0.96074438, grad/param norm = 1.8662e-01, time/batch = 0.7212s	
23356/30300 (epoch 38.541), train_loss = 1.01066661, grad/param norm = 1.9622e-01, time/batch = 0.7025s	
23357/30300 (epoch 38.543), train_loss = 1.00101095, grad/param norm = 1.6252e-01, time/batch = 0.6890s	
23358/30300 (epoch 38.545), train_loss = 1.07245702, grad/param norm = 2.1527e-01, time/batch = 0.6845s	
23359/30300 (epoch 38.546), train_loss = 1.18463512, grad/param norm = 1.7274e-01, time/batch = 0.6858s	
23360/30300 (epoch 38.548), train_loss = 0.96653190, grad/param norm = 1.5493e-01, time/batch = 0.7018s	
23361/30300 (epoch 38.550), train_loss = 1.06471564, grad/param norm = 2.1198e-01, time/batch = 0.7005s	
23362/30300 (epoch 38.551), train_loss = 0.95378851, grad/param norm = 1.6502e-01, time/batch = 0.7269s	
23363/30300 (epoch 38.553), train_loss = 0.98490692, grad/param norm = 1.5951e-01, time/batch = 0.7310s	
23364/30300 (epoch 38.554), train_loss = 1.02700108, grad/param norm = 1.7877e-01, time/batch = 0.7098s	
23365/30300 (epoch 38.556), train_loss = 1.04553391, grad/param norm = 1.6706e-01, time/batch = 0.6984s	
23366/30300 (epoch 38.558), train_loss = 1.08724076, grad/param norm = 1.8369e-01, time/batch = 0.6921s	
23367/30300 (epoch 38.559), train_loss = 1.02853624, grad/param norm = 1.9249e-01, time/batch = 0.6921s	
23368/30300 (epoch 38.561), train_loss = 0.83321493, grad/param norm = 1.5424e-01, time/batch = 0.6964s	
23369/30300 (epoch 38.563), train_loss = 0.91419276, grad/param norm = 1.5885e-01, time/batch = 0.6937s	
23370/30300 (epoch 38.564), train_loss = 0.95783220, grad/param norm = 1.4651e-01, time/batch = 0.6874s	
23371/30300 (epoch 38.566), train_loss = 0.98313116, grad/param norm = 1.6547e-01, time/batch = 0.6850s	
23372/30300 (epoch 38.568), train_loss = 0.86689095, grad/param norm = 1.7344e-01, time/batch = 0.6840s	
23373/30300 (epoch 38.569), train_loss = 1.04573802, grad/param norm = 1.8673e-01, time/batch = 0.6833s	
23374/30300 (epoch 38.571), train_loss = 1.00913352, grad/param norm = 1.8325e-01, time/batch = 0.6856s	
23375/30300 (epoch 38.573), train_loss = 1.06066763, grad/param norm = 1.7434e-01, time/batch = 0.6881s	
23376/30300 (epoch 38.574), train_loss = 1.04865589, grad/param norm = 1.6943e-01, time/batch = 0.7143s	
23377/30300 (epoch 38.576), train_loss = 0.97724471, grad/param norm = 1.5866e-01, time/batch = 0.7177s	
23378/30300 (epoch 38.578), train_loss = 0.87329600, grad/param norm = 1.5409e-01, time/batch = 0.6862s	
23379/30300 (epoch 38.579), train_loss = 1.06451174, grad/param norm = 1.9195e-01, time/batch = 0.6841s	
23380/30300 (epoch 38.581), train_loss = 1.13223654, grad/param norm = 1.5909e-01, time/batch = 0.6841s	
23381/30300 (epoch 38.583), train_loss = 1.16718216, grad/param norm = 3.1462e-01, time/batch = 0.6870s	
23382/30300 (epoch 38.584), train_loss = 1.11255517, grad/param norm = 1.6750e-01, time/batch = 0.6879s	
23383/30300 (epoch 38.586), train_loss = 1.00834463, grad/param norm = 1.8935e-01, time/batch = 0.6861s	
23384/30300 (epoch 38.587), train_loss = 1.01885756, grad/param norm = 1.7855e-01, time/batch = 0.6844s	
23385/30300 (epoch 38.589), train_loss = 0.95326310, grad/param norm = 1.6812e-01, time/batch = 0.6834s	
23386/30300 (epoch 38.591), train_loss = 1.03972766, grad/param norm = 1.5499e-01, time/batch = 0.6844s	
23387/30300 (epoch 38.592), train_loss = 0.97211109, grad/param norm = 1.5488e-01, time/batch = 0.6812s	
23388/30300 (epoch 38.594), train_loss = 1.04995897, grad/param norm = 1.6820e-01, time/batch = 0.6857s	
23389/30300 (epoch 38.596), train_loss = 0.92845601, grad/param norm = 1.5021e-01, time/batch = 0.6889s	
23390/30300 (epoch 38.597), train_loss = 0.96220174, grad/param norm = 2.4481e-01, time/batch = 0.6840s	
23391/30300 (epoch 38.599), train_loss = 0.86458877, grad/param norm = 1.5165e-01, time/batch = 0.6867s	
23392/30300 (epoch 38.601), train_loss = 1.04914166, grad/param norm = 1.8361e-01, time/batch = 0.6886s	
23393/30300 (epoch 38.602), train_loss = 0.99055047, grad/param norm = 1.5138e-01, time/batch = 0.6899s	
23394/30300 (epoch 38.604), train_loss = 0.95306698, grad/param norm = 1.9638e-01, time/batch = 0.6852s	
23395/30300 (epoch 38.606), train_loss = 0.95644084, grad/param norm = 2.5177e-01, time/batch = 0.7177s	
23396/30300 (epoch 38.607), train_loss = 1.10198170, grad/param norm = 2.0091e-01, time/batch = 0.7076s	
23397/30300 (epoch 38.609), train_loss = 1.16733007, grad/param norm = 1.7661e-01, time/batch = 0.6949s	
23398/30300 (epoch 38.611), train_loss = 0.97864569, grad/param norm = 1.5908e-01, time/batch = 0.6950s	
23399/30300 (epoch 38.612), train_loss = 0.91749712, grad/param norm = 1.7704e-01, time/batch = 0.6937s	
23400/30300 (epoch 38.614), train_loss = 0.99268082, grad/param norm = 1.7291e-01, time/batch = 0.6858s	
23401/30300 (epoch 38.616), train_loss = 1.04151723, grad/param norm = 2.2911e-01, time/batch = 0.6892s	
23402/30300 (epoch 38.617), train_loss = 1.03667018, grad/param norm = 1.8124e-01, time/batch = 0.6891s	
23403/30300 (epoch 38.619), train_loss = 0.82701047, grad/param norm = 1.4024e-01, time/batch = 0.6852s	
23404/30300 (epoch 38.620), train_loss = 1.08387506, grad/param norm = 1.8191e-01, time/batch = 0.6859s	
23405/30300 (epoch 38.622), train_loss = 1.01044531, grad/param norm = 1.9701e-01, time/batch = 0.6838s	
23406/30300 (epoch 38.624), train_loss = 0.99092766, grad/param norm = 1.6273e-01, time/batch = 0.6837s	
23407/30300 (epoch 38.625), train_loss = 1.00227664, grad/param norm = 2.1382e-01, time/batch = 0.6842s	
23408/30300 (epoch 38.627), train_loss = 1.09748013, grad/param norm = 1.7907e-01, time/batch = 0.6842s	
23409/30300 (epoch 38.629), train_loss = 1.13861484, grad/param norm = 1.6996e-01, time/batch = 0.6816s	
23410/30300 (epoch 38.630), train_loss = 1.00041283, grad/param norm = 1.7247e-01, time/batch = 0.6831s	
23411/30300 (epoch 38.632), train_loss = 1.06263210, grad/param norm = 1.9049e-01, time/batch = 0.6884s	
23412/30300 (epoch 38.634), train_loss = 0.93472478, grad/param norm = 1.5245e-01, time/batch = 0.6855s	
23413/30300 (epoch 38.635), train_loss = 1.05626705, grad/param norm = 2.0067e-01, time/batch = 0.6843s	
23414/30300 (epoch 38.637), train_loss = 1.09847211, grad/param norm = 2.0520e-01, time/batch = 0.6854s	
23415/30300 (epoch 38.639), train_loss = 1.00323585, grad/param norm = 1.7741e-01, time/batch = 0.6846s	
23416/30300 (epoch 38.640), train_loss = 1.11484806, grad/param norm = 1.8385e-01, time/batch = 0.6852s	
23417/30300 (epoch 38.642), train_loss = 0.99225622, grad/param norm = 1.5038e-01, time/batch = 0.6824s	
23418/30300 (epoch 38.644), train_loss = 1.08185862, grad/param norm = 1.6837e-01, time/batch = 0.7126s	
23419/30300 (epoch 38.645), train_loss = 0.95418882, grad/param norm = 1.5967e-01, time/batch = 0.7134s	
23420/30300 (epoch 38.647), train_loss = 1.01827644, grad/param norm = 1.5452e-01, time/batch = 0.6837s	
23421/30300 (epoch 38.649), train_loss = 1.00288866, grad/param norm = 2.0939e-01, time/batch = 0.6890s	
23422/30300 (epoch 38.650), train_loss = 1.01373699, grad/param norm = 1.6469e-01, time/batch = 0.6885s	
23423/30300 (epoch 38.652), train_loss = 0.99378471, grad/param norm = 1.8139e-01, time/batch = 0.6867s	
23424/30300 (epoch 38.653), train_loss = 1.17416753, grad/param norm = 1.5004e-01, time/batch = 0.6856s	
23425/30300 (epoch 38.655), train_loss = 0.99620895, grad/param norm = 1.9851e-01, time/batch = 0.6875s	
23426/30300 (epoch 38.657), train_loss = 0.92487537, grad/param norm = 1.7018e-01, time/batch = 0.6874s	
23427/30300 (epoch 38.658), train_loss = 0.98282625, grad/param norm = 1.5428e-01, time/batch = 0.6872s	
23428/30300 (epoch 38.660), train_loss = 1.02388378, grad/param norm = 1.7183e-01, time/batch = 0.6889s	
23429/30300 (epoch 38.662), train_loss = 1.04352460, grad/param norm = 1.9626e-01, time/batch = 0.6905s	
23430/30300 (epoch 38.663), train_loss = 1.08887714, grad/param norm = 1.6818e-01, time/batch = 0.6828s	
23431/30300 (epoch 38.665), train_loss = 0.96554224, grad/param norm = 2.0554e-01, time/batch = 0.6864s	
23432/30300 (epoch 38.667), train_loss = 1.08631566, grad/param norm = 1.9830e-01, time/batch = 0.6888s	
23433/30300 (epoch 38.668), train_loss = 1.10389916, grad/param norm = 1.7392e-01, time/batch = 0.6887s	
23434/30300 (epoch 38.670), train_loss = 1.12852855, grad/param norm = 1.7312e-01, time/batch = 0.7039s	
23435/30300 (epoch 38.672), train_loss = 1.02344919, grad/param norm = 1.7448e-01, time/batch = 0.6865s	
23436/30300 (epoch 38.673), train_loss = 1.07166924, grad/param norm = 1.9946e-01, time/batch = 0.7123s	
23437/30300 (epoch 38.675), train_loss = 0.99147215, grad/param norm = 1.8599e-01, time/batch = 0.7266s	
23438/30300 (epoch 38.677), train_loss = 0.97713275, grad/param norm = 1.5146e-01, time/batch = 0.7006s	
23439/30300 (epoch 38.678), train_loss = 0.95945105, grad/param norm = 1.5605e-01, time/batch = 0.6813s	
23440/30300 (epoch 38.680), train_loss = 0.90905605, grad/param norm = 1.5676e-01, time/batch = 0.6846s	
23441/30300 (epoch 38.682), train_loss = 1.00893529, grad/param norm = 1.9962e-01, time/batch = 0.6882s	
23442/30300 (epoch 38.683), train_loss = 1.09898220, grad/param norm = 1.5012e-01, time/batch = 0.6860s	
23443/30300 (epoch 38.685), train_loss = 1.06316236, grad/param norm = 1.9097e-01, time/batch = 0.6892s	
23444/30300 (epoch 38.686), train_loss = 0.99723737, grad/param norm = 1.6631e-01, time/batch = 0.6862s	
23445/30300 (epoch 38.688), train_loss = 1.00814439, grad/param norm = 1.5652e-01, time/batch = 0.6841s	
23446/30300 (epoch 38.690), train_loss = 0.97014322, grad/param norm = 1.8667e-01, time/batch = 0.6828s	
23447/30300 (epoch 38.691), train_loss = 1.01916982, grad/param norm = 1.6703e-01, time/batch = 0.6818s	
23448/30300 (epoch 38.693), train_loss = 1.29391091, grad/param norm = 2.0073e-01, time/batch = 0.6831s	
23449/30300 (epoch 38.695), train_loss = 1.07908203, grad/param norm = 2.3097e-01, time/batch = 0.6938s	
23450/30300 (epoch 38.696), train_loss = 1.09499568, grad/param norm = 2.2337e-01, time/batch = 0.6927s	
23451/30300 (epoch 38.698), train_loss = 0.96813778, grad/param norm = 1.7609e-01, time/batch = 0.6857s	
23452/30300 (epoch 38.700), train_loss = 0.96674610, grad/param norm = 1.8454e-01, time/batch = 0.6862s	
23453/30300 (epoch 38.701), train_loss = 0.88932137, grad/param norm = 1.5754e-01, time/batch = 0.6834s	
23454/30300 (epoch 38.703), train_loss = 1.01892078, grad/param norm = 1.6279e-01, time/batch = 0.6823s	
23455/30300 (epoch 38.705), train_loss = 0.93815050, grad/param norm = 1.6307e-01, time/batch = 0.6869s	
23456/30300 (epoch 38.706), train_loss = 1.07109432, grad/param norm = 1.6760e-01, time/batch = 0.6816s	
23457/30300 (epoch 38.708), train_loss = 1.02077414, grad/param norm = 1.6943e-01, time/batch = 0.6851s	
23458/30300 (epoch 38.710), train_loss = 0.99265071, grad/param norm = 1.6394e-01, time/batch = 0.6936s	
23459/30300 (epoch 38.711), train_loss = 0.96144264, grad/param norm = 1.6408e-01, time/batch = 0.6832s	
23460/30300 (epoch 38.713), train_loss = 0.96864319, grad/param norm = 1.9354e-01, time/batch = 0.6880s	
23461/30300 (epoch 38.715), train_loss = 0.98254286, grad/param norm = 1.8512e-01, time/batch = 0.6854s	
23462/30300 (epoch 38.716), train_loss = 1.08296696, grad/param norm = 1.6583e-01, time/batch = 0.6837s	
23463/30300 (epoch 38.718), train_loss = 1.13077529, grad/param norm = 1.7700e-01, time/batch = 0.6906s	
23464/30300 (epoch 38.719), train_loss = 0.96635437, grad/param norm = 1.8498e-01, time/batch = 0.6855s	
23465/30300 (epoch 38.721), train_loss = 1.00970276, grad/param norm = 1.9001e-01, time/batch = 0.6843s	
23466/30300 (epoch 38.723), train_loss = 0.94010897, grad/param norm = 1.5982e-01, time/batch = 0.6829s	
23467/30300 (epoch 38.724), train_loss = 1.05493596, grad/param norm = 1.8826e-01, time/batch = 0.6832s	
23468/30300 (epoch 38.726), train_loss = 1.29111761, grad/param norm = 2.2929e-01, time/batch = 0.6833s	
23469/30300 (epoch 38.728), train_loss = 1.06569574, grad/param norm = 1.8108e-01, time/batch = 0.6825s	
23470/30300 (epoch 38.729), train_loss = 0.98322169, grad/param norm = 1.7785e-01, time/batch = 0.6826s	
23471/30300 (epoch 38.731), train_loss = 0.98931823, grad/param norm = 1.7339e-01, time/batch = 0.6839s	
23472/30300 (epoch 38.733), train_loss = 1.02458246, grad/param norm = 1.7111e-01, time/batch = 0.6833s	
23473/30300 (epoch 38.734), train_loss = 1.10732472, grad/param norm = 1.6358e-01, time/batch = 0.6839s	
23474/30300 (epoch 38.736), train_loss = 1.03700341, grad/param norm = 1.7117e-01, time/batch = 0.6906s	
23475/30300 (epoch 38.738), train_loss = 0.96169967, grad/param norm = 1.4191e-01, time/batch = 0.7054s	
23476/30300 (epoch 38.739), train_loss = 1.11187088, grad/param norm = 1.7166e-01, time/batch = 0.6880s	
23477/30300 (epoch 38.741), train_loss = 1.14821183, grad/param norm = 1.6098e-01, time/batch = 0.6798s	
23478/30300 (epoch 38.743), train_loss = 0.99241445, grad/param norm = 1.7330e-01, time/batch = 0.6833s	
23479/30300 (epoch 38.744), train_loss = 1.05492036, grad/param norm = 1.6426e-01, time/batch = 0.6813s	
23480/30300 (epoch 38.746), train_loss = 0.97657597, grad/param norm = 1.4439e-01, time/batch = 0.6842s	
23481/30300 (epoch 38.748), train_loss = 0.99394633, grad/param norm = 1.8982e-01, time/batch = 0.6839s	
23482/30300 (epoch 38.749), train_loss = 1.01616889, grad/param norm = 1.4773e-01, time/batch = 0.6828s	
23483/30300 (epoch 38.751), train_loss = 1.06167820, grad/param norm = 1.6933e-01, time/batch = 0.6852s	
23484/30300 (epoch 38.752), train_loss = 1.00336535, grad/param norm = 1.7935e-01, time/batch = 0.6843s	
23485/30300 (epoch 38.754), train_loss = 1.00541960, grad/param norm = 1.5806e-01, time/batch = 0.6825s	
23486/30300 (epoch 38.756), train_loss = 1.00108380, grad/param norm = 1.6175e-01, time/batch = 0.6819s	
23487/30300 (epoch 38.757), train_loss = 0.94835752, grad/param norm = 1.6948e-01, time/batch = 0.6851s	
23488/30300 (epoch 38.759), train_loss = 1.04819627, grad/param norm = 1.5798e-01, time/batch = 0.6834s	
23489/30300 (epoch 38.761), train_loss = 0.88542076, grad/param norm = 1.5389e-01, time/batch = 0.7168s	
23490/30300 (epoch 38.762), train_loss = 0.90448938, grad/param norm = 1.5837e-01, time/batch = 0.7093s	
23491/30300 (epoch 38.764), train_loss = 1.00498272, grad/param norm = 1.7544e-01, time/batch = 0.6882s	
23492/30300 (epoch 38.766), train_loss = 1.15175750, grad/param norm = 2.1707e-01, time/batch = 0.6838s	
23493/30300 (epoch 38.767), train_loss = 1.03759623, grad/param norm = 1.9827e-01, time/batch = 0.6812s	
23494/30300 (epoch 38.769), train_loss = 1.03610332, grad/param norm = 1.7753e-01, time/batch = 0.6819s	
23495/30300 (epoch 38.771), train_loss = 0.96328321, grad/param norm = 2.3239e-01, time/batch = 0.6829s	
23496/30300 (epoch 38.772), train_loss = 1.02478551, grad/param norm = 1.8083e-01, time/batch = 0.6840s	
23497/30300 (epoch 38.774), train_loss = 1.16956198, grad/param norm = 1.6770e-01, time/batch = 0.6855s	
23498/30300 (epoch 38.776), train_loss = 0.99920554, grad/param norm = 1.9508e-01, time/batch = 0.6872s	
23499/30300 (epoch 38.777), train_loss = 1.14767822, grad/param norm = 1.5940e-01, time/batch = 0.6997s	
23500/30300 (epoch 38.779), train_loss = 1.13770692, grad/param norm = 1.9243e-01, time/batch = 0.6934s	
23501/30300 (epoch 38.781), train_loss = 1.02521785, grad/param norm = 1.8038e-01, time/batch = 0.6848s	
23502/30300 (epoch 38.782), train_loss = 0.95466159, grad/param norm = 2.6525e-01, time/batch = 0.6833s	
23503/30300 (epoch 38.784), train_loss = 0.97572281, grad/param norm = 1.6282e-01, time/batch = 0.6818s	
23504/30300 (epoch 38.785), train_loss = 1.10537970, grad/param norm = 2.1221e-01, time/batch = 0.6831s	
23505/30300 (epoch 38.787), train_loss = 0.86576690, grad/param norm = 1.7401e-01, time/batch = 0.6909s	
23506/30300 (epoch 38.789), train_loss = 1.16701423, grad/param norm = 1.7472e-01, time/batch = 0.6937s	
23507/30300 (epoch 38.790), train_loss = 1.03394224, grad/param norm = 1.8080e-01, time/batch = 0.6956s	
23508/30300 (epoch 38.792), train_loss = 0.82393247, grad/param norm = 1.7106e-01, time/batch = 0.6873s	
23509/30300 (epoch 38.794), train_loss = 1.00969042, grad/param norm = 1.8113e-01, time/batch = 0.6959s	
23510/30300 (epoch 38.795), train_loss = 0.94712807, grad/param norm = 1.5425e-01, time/batch = 0.7056s	
23511/30300 (epoch 38.797), train_loss = 1.14845841, grad/param norm = 1.8138e-01, time/batch = 0.7021s	
23512/30300 (epoch 38.799), train_loss = 1.11608792, grad/param norm = 2.2966e-01, time/batch = 0.7178s	
23513/30300 (epoch 38.800), train_loss = 1.07158590, grad/param norm = 1.6678e-01, time/batch = 0.7135s	
23514/30300 (epoch 38.802), train_loss = 1.26177679, grad/param norm = 1.8857e-01, time/batch = 0.7013s	
23515/30300 (epoch 38.804), train_loss = 1.09157841, grad/param norm = 1.9141e-01, time/batch = 0.7120s	
23516/30300 (epoch 38.805), train_loss = 1.15754611, grad/param norm = 1.8572e-01, time/batch = 0.7267s	
23517/30300 (epoch 38.807), train_loss = 1.00608409, grad/param norm = 6.6927e-01, time/batch = 0.7077s	
23518/30300 (epoch 38.809), train_loss = 1.12166453, grad/param norm = 1.9077e-01, time/batch = 0.7193s	
23519/30300 (epoch 38.810), train_loss = 1.10335583, grad/param norm = 2.1161e-01, time/batch = 0.7135s	
23520/30300 (epoch 38.812), train_loss = 1.00126964, grad/param norm = 2.0679e-01, time/batch = 0.7048s	
23521/30300 (epoch 38.814), train_loss = 1.04062333, grad/param norm = 1.8961e-01, time/batch = 0.7087s	
23522/30300 (epoch 38.815), train_loss = 1.04859623, grad/param norm = 2.1854e-01, time/batch = 0.7214s	
23523/30300 (epoch 38.817), train_loss = 1.11942518, grad/param norm = 1.9448e-01, time/batch = 0.6925s	
23524/30300 (epoch 38.818), train_loss = 1.07075519, grad/param norm = 2.3837e-01, time/batch = 0.6973s	
23525/30300 (epoch 38.820), train_loss = 1.20009625, grad/param norm = 2.0618e-01, time/batch = 0.7002s	
23526/30300 (epoch 38.822), train_loss = 1.18933478, grad/param norm = 2.1557e-01, time/batch = 0.7169s	
23527/30300 (epoch 38.823), train_loss = 1.16483442, grad/param norm = 2.0748e-01, time/batch = 0.7151s	
23528/30300 (epoch 38.825), train_loss = 1.16509149, grad/param norm = 1.9436e-01, time/batch = 0.6870s	
23529/30300 (epoch 38.827), train_loss = 0.91206818, grad/param norm = 2.1692e-01, time/batch = 0.6870s	
23530/30300 (epoch 38.828), train_loss = 1.12000666, grad/param norm = 1.9510e-01, time/batch = 0.6846s	
23531/30300 (epoch 38.830), train_loss = 1.09063171, grad/param norm = 1.8679e-01, time/batch = 0.6916s	
23532/30300 (epoch 38.832), train_loss = 0.97925379, grad/param norm = 1.8541e-01, time/batch = 0.6916s	
23533/30300 (epoch 38.833), train_loss = 1.05942104, grad/param norm = 2.1137e-01, time/batch = 0.6883s	
23534/30300 (epoch 38.835), train_loss = 0.96402688, grad/param norm = 1.5423e-01, time/batch = 0.6877s	
23535/30300 (epoch 38.837), train_loss = 0.94939899, grad/param norm = 1.7873e-01, time/batch = 0.6848s	
23536/30300 (epoch 38.838), train_loss = 0.95023922, grad/param norm = 1.6397e-01, time/batch = 0.6918s	
23537/30300 (epoch 38.840), train_loss = 1.12546162, grad/param norm = 1.7466e-01, time/batch = 0.6860s	
23538/30300 (epoch 38.842), train_loss = 1.00037461, grad/param norm = 1.8384e-01, time/batch = 0.6823s	
23539/30300 (epoch 38.843), train_loss = 1.07479350, grad/param norm = 2.0180e-01, time/batch = 0.6858s	
23540/30300 (epoch 38.845), train_loss = 1.07176869, grad/param norm = 1.5630e-01, time/batch = 0.6812s	
23541/30300 (epoch 38.847), train_loss = 1.05091669, grad/param norm = 1.8207e-01, time/batch = 0.6858s	
23542/30300 (epoch 38.848), train_loss = 1.08443161, grad/param norm = 2.0128e-01, time/batch = 0.6858s	
23543/30300 (epoch 38.850), train_loss = 1.01712053, grad/param norm = 1.5475e-01, time/batch = 0.6875s	
23544/30300 (epoch 38.851), train_loss = 1.06395277, grad/param norm = 1.9901e-01, time/batch = 0.6870s	
23545/30300 (epoch 38.853), train_loss = 0.99850376, grad/param norm = 1.7029e-01, time/batch = 0.7254s	
23546/30300 (epoch 38.855), train_loss = 0.99020625, grad/param norm = 1.7122e-01, time/batch = 0.7063s	
23547/30300 (epoch 38.856), train_loss = 1.04252796, grad/param norm = 1.6671e-01, time/batch = 0.6874s	
23548/30300 (epoch 38.858), train_loss = 0.95432005, grad/param norm = 1.6305e-01, time/batch = 0.6890s	
23549/30300 (epoch 38.860), train_loss = 0.94410274, grad/param norm = 1.6111e-01, time/batch = 0.6898s	
23550/30300 (epoch 38.861), train_loss = 1.17112020, grad/param norm = 1.7501e-01, time/batch = 0.6902s	
23551/30300 (epoch 38.863), train_loss = 1.01420213, grad/param norm = 1.7322e-01, time/batch = 0.6913s	
23552/30300 (epoch 38.865), train_loss = 1.10577668, grad/param norm = 2.0120e-01, time/batch = 0.6914s	
23553/30300 (epoch 38.866), train_loss = 1.12424612, grad/param norm = 2.2197e-01, time/batch = 0.7004s	
23554/30300 (epoch 38.868), train_loss = 1.05071262, grad/param norm = 1.6040e-01, time/batch = 0.6939s	
23555/30300 (epoch 38.870), train_loss = 0.97160238, grad/param norm = 1.8052e-01, time/batch = 0.6927s	
23556/30300 (epoch 38.871), train_loss = 1.05605013, grad/param norm = 1.7712e-01, time/batch = 0.7112s	
23557/30300 (epoch 38.873), train_loss = 1.02261992, grad/param norm = 1.4347e-01, time/batch = 0.7003s	
23558/30300 (epoch 38.875), train_loss = 0.99796500, grad/param norm = 1.4983e-01, time/batch = 0.6864s	
23559/30300 (epoch 38.876), train_loss = 0.92271064, grad/param norm = 1.6688e-01, time/batch = 0.6844s	
23560/30300 (epoch 38.878), train_loss = 0.88186885, grad/param norm = 1.6666e-01, time/batch = 0.6821s	
23561/30300 (epoch 38.880), train_loss = 0.95255663, grad/param norm = 1.6911e-01, time/batch = 0.6922s	
23562/30300 (epoch 38.881), train_loss = 1.17506760, grad/param norm = 2.1073e-01, time/batch = 0.6833s	
23563/30300 (epoch 38.883), train_loss = 1.09152969, grad/param norm = 1.8225e-01, time/batch = 0.6991s	
23564/30300 (epoch 38.884), train_loss = 1.02204120, grad/param norm = 1.5678e-01, time/batch = 0.7259s	
23565/30300 (epoch 38.886), train_loss = 1.08272992, grad/param norm = 1.8939e-01, time/batch = 0.6852s	
23566/30300 (epoch 38.888), train_loss = 0.98947702, grad/param norm = 1.7966e-01, time/batch = 0.6926s	
23567/30300 (epoch 38.889), train_loss = 1.04181874, grad/param norm = 1.7563e-01, time/batch = 0.6908s	
23568/30300 (epoch 38.891), train_loss = 1.00931175, grad/param norm = 1.8148e-01, time/batch = 0.6934s	
23569/30300 (epoch 38.893), train_loss = 1.22856717, grad/param norm = 1.6434e-01, time/batch = 0.6868s	
23570/30300 (epoch 38.894), train_loss = 1.07138864, grad/param norm = 1.7949e-01, time/batch = 0.6848s	
23571/30300 (epoch 38.896), train_loss = 0.89530673, grad/param norm = 1.8998e-01, time/batch = 0.6869s	
23572/30300 (epoch 38.898), train_loss = 0.89524991, grad/param norm = 1.7480e-01, time/batch = 0.6864s	
23573/30300 (epoch 38.899), train_loss = 0.93158862, grad/param norm = 1.6811e-01, time/batch = 0.6860s	
23574/30300 (epoch 38.901), train_loss = 1.03953486, grad/param norm = 2.3041e-01, time/batch = 0.6891s	
23575/30300 (epoch 38.903), train_loss = 1.02570265, grad/param norm = 2.1640e-01, time/batch = 0.6904s	
23576/30300 (epoch 38.904), train_loss = 1.04209151, grad/param norm = 1.5754e-01, time/batch = 0.6885s	
23577/30300 (epoch 38.906), train_loss = 1.04334447, grad/param norm = 1.7620e-01, time/batch = 0.6889s	
23578/30300 (epoch 38.908), train_loss = 0.97283425, grad/param norm = 1.9518e-01, time/batch = 0.6866s	
23579/30300 (epoch 38.909), train_loss = 0.97386452, grad/param norm = 1.9743e-01, time/batch = 0.6879s	
23580/30300 (epoch 38.911), train_loss = 1.02794432, grad/param norm = 1.7285e-01, time/batch = 0.6877s	
23581/30300 (epoch 38.913), train_loss = 1.02439106, grad/param norm = 1.5809e-01, time/batch = 0.6898s	
23582/30300 (epoch 38.914), train_loss = 0.99571987, grad/param norm = 1.8366e-01, time/batch = 0.7127s	
23583/30300 (epoch 38.916), train_loss = 1.05200282, grad/param norm = 1.5878e-01, time/batch = 0.7166s	
23584/30300 (epoch 38.917), train_loss = 0.97697727, grad/param norm = 1.5437e-01, time/batch = 0.6866s	
23585/30300 (epoch 38.919), train_loss = 0.91868148, grad/param norm = 1.6554e-01, time/batch = 0.6855s	
23586/30300 (epoch 38.921), train_loss = 1.00017209, grad/param norm = 1.5391e-01, time/batch = 0.6843s	
23587/30300 (epoch 38.922), train_loss = 1.11343110, grad/param norm = 1.8867e-01, time/batch = 0.6826s	
23588/30300 (epoch 38.924), train_loss = 1.02815210, grad/param norm = 1.6351e-01, time/batch = 0.6864s	
23589/30300 (epoch 38.926), train_loss = 1.06671995, grad/param norm = 1.7381e-01, time/batch = 0.6904s	
23590/30300 (epoch 38.927), train_loss = 1.04698034, grad/param norm = 1.6942e-01, time/batch = 0.6836s	
23591/30300 (epoch 38.929), train_loss = 0.96005492, grad/param norm = 1.8638e-01, time/batch = 0.6871s	
23592/30300 (epoch 38.931), train_loss = 1.09997174, grad/param norm = 2.0282e-01, time/batch = 0.6871s	
23593/30300 (epoch 38.932), train_loss = 0.95032366, grad/param norm = 1.7498e-01, time/batch = 0.6880s	
23594/30300 (epoch 38.934), train_loss = 1.05132859, grad/param norm = 1.6723e-01, time/batch = 0.6846s	
23595/30300 (epoch 38.936), train_loss = 0.96214981, grad/param norm = 1.6634e-01, time/batch = 0.6865s	
23596/30300 (epoch 38.937), train_loss = 0.97881448, grad/param norm = 1.6991e-01, time/batch = 0.6839s	
23597/30300 (epoch 38.939), train_loss = 1.12892666, grad/param norm = 1.8650e-01, time/batch = 0.6873s	
23598/30300 (epoch 38.941), train_loss = 1.00338239, grad/param norm = 1.7377e-01, time/batch = 0.6836s	
23599/30300 (epoch 38.942), train_loss = 1.01783979, grad/param norm = 1.8850e-01, time/batch = 0.6841s	
23600/30300 (epoch 38.944), train_loss = 0.91245267, grad/param norm = 1.5768e-01, time/batch = 0.6872s	
23601/30300 (epoch 38.946), train_loss = 1.10128889, grad/param norm = 2.2572e-01, time/batch = 0.6919s	
23602/30300 (epoch 38.947), train_loss = 1.07880232, grad/param norm = 2.4349e-01, time/batch = 0.6887s	
23603/30300 (epoch 38.949), train_loss = 1.09843561, grad/param norm = 2.3520e-01, time/batch = 0.6906s	
23604/30300 (epoch 38.950), train_loss = 1.12627641, grad/param norm = 1.8926e-01, time/batch = 0.6895s	
23605/30300 (epoch 38.952), train_loss = 1.07485269, grad/param norm = 1.9753e-01, time/batch = 0.7096s	
23606/30300 (epoch 38.954), train_loss = 1.26858011, grad/param norm = 1.6897e-01, time/batch = 0.7251s	
23607/30300 (epoch 38.955), train_loss = 1.02489094, grad/param norm = 1.6669e-01, time/batch = 0.7109s	
23608/30300 (epoch 38.957), train_loss = 1.08912872, grad/param norm = 1.8176e-01, time/batch = 0.7065s	
23609/30300 (epoch 38.959), train_loss = 0.95412271, grad/param norm = 2.1799e-01, time/batch = 0.6968s	
23610/30300 (epoch 38.960), train_loss = 0.97560904, grad/param norm = 1.6702e-01, time/batch = 0.6895s	
23611/30300 (epoch 38.962), train_loss = 0.97691832, grad/param norm = 2.0741e-01, time/batch = 0.6885s	
23612/30300 (epoch 38.964), train_loss = 0.94508055, grad/param norm = 1.8751e-01, time/batch = 0.6852s	
23613/30300 (epoch 38.965), train_loss = 0.97259791, grad/param norm = 2.0595e-01, time/batch = 0.6841s	
23614/30300 (epoch 38.967), train_loss = 1.01373527, grad/param norm = 2.1013e-01, time/batch = 0.6934s	
23615/30300 (epoch 38.969), train_loss = 0.96613289, grad/param norm = 1.9356e-01, time/batch = 0.6894s	
23616/30300 (epoch 38.970), train_loss = 0.99259295, grad/param norm = 1.6855e-01, time/batch = 0.6922s	
23617/30300 (epoch 38.972), train_loss = 0.91737040, grad/param norm = 1.8183e-01, time/batch = 0.6819s	
23618/30300 (epoch 38.974), train_loss = 1.15853587, grad/param norm = 1.8561e-01, time/batch = 0.6981s	
23619/30300 (epoch 38.975), train_loss = 1.15673160, grad/param norm = 2.6292e-01, time/batch = 0.6870s	
23620/30300 (epoch 38.977), train_loss = 1.21245067, grad/param norm = 1.8934e-01, time/batch = 0.6814s	
23621/30300 (epoch 38.979), train_loss = 1.09950274, grad/param norm = 1.9558e-01, time/batch = 0.6824s	
23622/30300 (epoch 38.980), train_loss = 1.15175724, grad/param norm = 2.1267e-01, time/batch = 0.6912s	
23623/30300 (epoch 38.982), train_loss = 1.13309856, grad/param norm = 2.0320e-01, time/batch = 0.6889s	
23624/30300 (epoch 38.983), train_loss = 1.14749482, grad/param norm = 1.8110e-01, time/batch = 0.7193s	
23625/30300 (epoch 38.985), train_loss = 1.09161021, grad/param norm = 2.1516e-01, time/batch = 0.7063s	
23626/30300 (epoch 38.987), train_loss = 1.04422752, grad/param norm = 1.6176e-01, time/batch = 0.6848s	
23627/30300 (epoch 38.988), train_loss = 1.15670311, grad/param norm = 1.8945e-01, time/batch = 0.6826s	
23628/30300 (epoch 38.990), train_loss = 0.95583590, grad/param norm = 2.0849e-01, time/batch = 0.6806s	
23629/30300 (epoch 38.992), train_loss = 1.12040376, grad/param norm = 1.6618e-01, time/batch = 0.6803s	
23630/30300 (epoch 38.993), train_loss = 1.12845194, grad/param norm = 2.3009e-01, time/batch = 0.6809s	
23631/30300 (epoch 38.995), train_loss = 1.04817054, grad/param norm = 2.2426e-01, time/batch = 0.6844s	
23632/30300 (epoch 38.997), train_loss = 1.09085328, grad/param norm = 2.0741e-01, time/batch = 0.6844s	
23633/30300 (epoch 38.998), train_loss = 1.10368819, grad/param norm = 2.0728e-01, time/batch = 0.6889s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
23634/30300 (epoch 39.000), train_loss = 0.98857035, grad/param norm = 2.0771e-01, time/batch = 0.6955s	
23635/30300 (epoch 39.002), train_loss = 1.14440219, grad/param norm = 2.0099e-01, time/batch = 0.7033s	
23636/30300 (epoch 39.003), train_loss = 1.07309601, grad/param norm = 1.8309e-01, time/batch = 0.7185s	
23637/30300 (epoch 39.005), train_loss = 1.01798723, grad/param norm = 1.8311e-01, time/batch = 0.7153s	
23638/30300 (epoch 39.007), train_loss = 1.10132243, grad/param norm = 1.9991e-01, time/batch = 0.7129s	
23639/30300 (epoch 39.008), train_loss = 1.03461914, grad/param norm = 1.9679e-01, time/batch = 0.7202s	
23640/30300 (epoch 39.010), train_loss = 0.91408183, grad/param norm = 1.8144e-01, time/batch = 0.6874s	
23641/30300 (epoch 39.012), train_loss = 0.99372450, grad/param norm = 1.7106e-01, time/batch = 0.7004s	
23642/30300 (epoch 39.013), train_loss = 1.12689528, grad/param norm = 2.1699e-01, time/batch = 0.6906s	
23643/30300 (epoch 39.015), train_loss = 0.99228534, grad/param norm = 1.6345e-01, time/batch = 0.6970s	
23644/30300 (epoch 39.017), train_loss = 1.00719130, grad/param norm = 1.5944e-01, time/batch = 0.6913s	
23645/30300 (epoch 39.018), train_loss = 0.93557449, grad/param norm = 1.7304e-01, time/batch = 0.6837s	
23646/30300 (epoch 39.020), train_loss = 1.13962101, grad/param norm = 2.5945e-01, time/batch = 0.6825s	
23647/30300 (epoch 39.021), train_loss = 1.15508756, grad/param norm = 1.7071e-01, time/batch = 0.7038s	
23648/30300 (epoch 39.023), train_loss = 1.04296674, grad/param norm = 1.6173e-01, time/batch = 0.6901s	
23649/30300 (epoch 39.025), train_loss = 0.95839273, grad/param norm = 1.9620e-01, time/batch = 0.6855s	
23650/30300 (epoch 39.026), train_loss = 1.09705988, grad/param norm = 2.1104e-01, time/batch = 0.6830s	
23651/30300 (epoch 39.028), train_loss = 1.10676186, grad/param norm = 1.7020e-01, time/batch = 0.6849s	
23652/30300 (epoch 39.030), train_loss = 0.99267358, grad/param norm = 1.8223e-01, time/batch = 0.6848s	
23653/30300 (epoch 39.031), train_loss = 1.05998731, grad/param norm = 1.6776e-01, time/batch = 0.6862s	
23654/30300 (epoch 39.033), train_loss = 1.05864311, grad/param norm = 1.7619e-01, time/batch = 0.6877s	
23655/30300 (epoch 39.035), train_loss = 1.10472577, grad/param norm = 2.2649e-01, time/batch = 0.6880s	
23656/30300 (epoch 39.036), train_loss = 1.07535517, grad/param norm = 1.8219e-01, time/batch = 0.6902s	
23657/30300 (epoch 39.038), train_loss = 1.07944354, grad/param norm = 1.5539e-01, time/batch = 0.7191s	
23658/30300 (epoch 39.040), train_loss = 0.89500670, grad/param norm = 1.6160e-01, time/batch = 0.7084s	
23659/30300 (epoch 39.041), train_loss = 0.88345841, grad/param norm = 1.7967e-01, time/batch = 0.6894s	
23660/30300 (epoch 39.043), train_loss = 1.06812654, grad/param norm = 1.8835e-01, time/batch = 0.6838s	
23661/30300 (epoch 39.045), train_loss = 0.98361645, grad/param norm = 1.6328e-01, time/batch = 0.6882s	
23662/30300 (epoch 39.046), train_loss = 1.16508344, grad/param norm = 2.0675e-01, time/batch = 0.6853s	
23663/30300 (epoch 39.048), train_loss = 1.05835986, grad/param norm = 2.0726e-01, time/batch = 0.6849s	
23664/30300 (epoch 39.050), train_loss = 0.95320991, grad/param norm = 1.7253e-01, time/batch = 0.6859s	
23665/30300 (epoch 39.051), train_loss = 1.08258558, grad/param norm = 2.0410e-01, time/batch = 0.6861s	
23666/30300 (epoch 39.053), train_loss = 0.89546139, grad/param norm = 1.9528e-01, time/batch = 0.6880s	
23667/30300 (epoch 39.054), train_loss = 1.07514551, grad/param norm = 1.9871e-01, time/batch = 0.6844s	
23668/30300 (epoch 39.056), train_loss = 0.95168404, grad/param norm = 1.6580e-01, time/batch = 0.6853s	
23669/30300 (epoch 39.058), train_loss = 0.99636679, grad/param norm = 1.8337e-01, time/batch = 0.6846s	
23670/30300 (epoch 39.059), train_loss = 1.02181800, grad/param norm = 2.1180e-01, time/batch = 0.6854s	
23671/30300 (epoch 39.061), train_loss = 1.06079605, grad/param norm = 1.7009e-01, time/batch = 0.6859s	
23672/30300 (epoch 39.063), train_loss = 0.93707198, grad/param norm = 2.0767e-01, time/batch = 0.6874s	
23673/30300 (epoch 39.064), train_loss = 1.03159033, grad/param norm = 1.9444e-01, time/batch = 0.6860s	
23674/30300 (epoch 39.066), train_loss = 1.02414290, grad/param norm = 1.5076e-01, time/batch = 0.6941s	
23675/30300 (epoch 39.068), train_loss = 0.95102642, grad/param norm = 1.6684e-01, time/batch = 0.7088s	
23676/30300 (epoch 39.069), train_loss = 1.08269147, grad/param norm = 1.9179e-01, time/batch = 0.7260s	
23677/30300 (epoch 39.071), train_loss = 1.08067685, grad/param norm = 1.7841e-01, time/batch = 0.6966s	
23678/30300 (epoch 39.073), train_loss = 0.96294007, grad/param norm = 1.9729e-01, time/batch = 0.6826s	
23679/30300 (epoch 39.074), train_loss = 1.00724456, grad/param norm = 1.7210e-01, time/batch = 0.6880s	
23680/30300 (epoch 39.076), train_loss = 1.01021583, grad/param norm = 1.6647e-01, time/batch = 0.6983s	
23681/30300 (epoch 39.078), train_loss = 0.96425823, grad/param norm = 1.5347e-01, time/batch = 0.6933s	
23682/30300 (epoch 39.079), train_loss = 0.99651874, grad/param norm = 1.9345e-01, time/batch = 0.7053s	
23683/30300 (epoch 39.081), train_loss = 1.04826594, grad/param norm = 1.9842e-01, time/batch = 0.7006s	
23684/30300 (epoch 39.083), train_loss = 1.09954568, grad/param norm = 2.1360e-01, time/batch = 0.7011s	
23685/30300 (epoch 39.084), train_loss = 0.97021628, grad/param norm = 1.6040e-01, time/batch = 0.6998s	
23686/30300 (epoch 39.086), train_loss = 0.98926925, grad/param norm = 2.1491e-01, time/batch = 0.7127s	
23687/30300 (epoch 39.087), train_loss = 0.95745417, grad/param norm = 1.6271e-01, time/batch = 0.7119s	
23688/30300 (epoch 39.089), train_loss = 0.95477828, grad/param norm = 1.6344e-01, time/batch = 0.7139s	
23689/30300 (epoch 39.091), train_loss = 1.06446384, grad/param norm = 1.7463e-01, time/batch = 0.6847s	
23690/30300 (epoch 39.092), train_loss = 1.08570471, grad/param norm = 1.6221e-01, time/batch = 0.7202s	
23691/30300 (epoch 39.094), train_loss = 1.14463660, grad/param norm = 1.9871e-01, time/batch = 0.7108s	
23692/30300 (epoch 39.096), train_loss = 1.15229083, grad/param norm = 2.0291e-01, time/batch = 0.6890s	
23693/30300 (epoch 39.097), train_loss = 0.96860485, grad/param norm = 1.9420e-01, time/batch = 0.7037s	
23694/30300 (epoch 39.099), train_loss = 1.09350385, grad/param norm = 1.7529e-01, time/batch = 0.6979s	
23695/30300 (epoch 39.101), train_loss = 1.14711393, grad/param norm = 1.9185e-01, time/batch = 0.7273s	
23696/30300 (epoch 39.102), train_loss = 0.96948890, grad/param norm = 1.9704e-01, time/batch = 0.6907s	
23697/30300 (epoch 39.104), train_loss = 0.99577642, grad/param norm = 2.1311e-01, time/batch = 0.6888s	
23698/30300 (epoch 39.106), train_loss = 0.97600189, grad/param norm = 1.9251e-01, time/batch = 0.7154s	
23699/30300 (epoch 39.107), train_loss = 1.09314155, grad/param norm = 1.7276e-01, time/batch = 0.6922s	
23700/30300 (epoch 39.109), train_loss = 1.10469496, grad/param norm = 2.1377e-01, time/batch = 0.6816s	
23701/30300 (epoch 39.111), train_loss = 1.08951878, grad/param norm = 1.8977e-01, time/batch = 0.6858s	
23702/30300 (epoch 39.112), train_loss = 1.15631344, grad/param norm = 1.7721e-01, time/batch = 0.6901s	
23703/30300 (epoch 39.114), train_loss = 0.98795380, grad/param norm = 1.6844e-01, time/batch = 0.6851s	
23704/30300 (epoch 39.116), train_loss = 1.06017431, grad/param norm = 1.8726e-01, time/batch = 0.6840s	
23705/30300 (epoch 39.117), train_loss = 1.13697096, grad/param norm = 1.7667e-01, time/batch = 0.6864s	
23706/30300 (epoch 39.119), train_loss = 0.93931239, grad/param norm = 1.7116e-01, time/batch = 0.6828s	
23707/30300 (epoch 39.120), train_loss = 1.01041293, grad/param norm = 1.8017e-01, time/batch = 0.6838s	
23708/30300 (epoch 39.122), train_loss = 1.12806009, grad/param norm = 2.0954e-01, time/batch = 0.6965s	
23709/30300 (epoch 39.124), train_loss = 1.18751954, grad/param norm = 1.9737e-01, time/batch = 0.7268s	
23710/30300 (epoch 39.125), train_loss = 0.94279508, grad/param norm = 1.7389e-01, time/batch = 0.6936s	
23711/30300 (epoch 39.127), train_loss = 1.05819381, grad/param norm = 2.2514e-01, time/batch = 0.6935s	
23712/30300 (epoch 39.129), train_loss = 1.12925266, grad/param norm = 1.9769e-01, time/batch = 0.6949s	
23713/30300 (epoch 39.130), train_loss = 1.16897714, grad/param norm = 1.8861e-01, time/batch = 0.6918s	
23714/30300 (epoch 39.132), train_loss = 1.15426637, grad/param norm = 1.8741e-01, time/batch = 0.6863s	
23715/30300 (epoch 39.134), train_loss = 0.96780951, grad/param norm = 1.9573e-01, time/batch = 0.6880s	
23716/30300 (epoch 39.135), train_loss = 0.99416921, grad/param norm = 1.7939e-01, time/batch = 0.6880s	
23717/30300 (epoch 39.137), train_loss = 1.03768772, grad/param norm = 2.0073e-01, time/batch = 0.6906s	
23718/30300 (epoch 39.139), train_loss = 0.97985281, grad/param norm = 2.7172e-01, time/batch = 0.6899s	
23719/30300 (epoch 39.140), train_loss = 1.04063224, grad/param norm = 2.6560e-01, time/batch = 0.6867s	
23720/30300 (epoch 39.142), train_loss = 1.12199259, grad/param norm = 2.8518e-01, time/batch = 0.6883s	
23721/30300 (epoch 39.144), train_loss = 0.98728407, grad/param norm = 2.4821e-01, time/batch = 0.6868s	
23722/30300 (epoch 39.145), train_loss = 1.12281857, grad/param norm = 2.6557e-01, time/batch = 0.6840s	
23723/30300 (epoch 39.147), train_loss = 1.01620788, grad/param norm = 2.3931e-01, time/batch = 0.6824s	
23724/30300 (epoch 39.149), train_loss = 1.11770553, grad/param norm = 1.8199e-01, time/batch = 0.6860s	
23725/30300 (epoch 39.150), train_loss = 1.01884034, grad/param norm = 2.2068e-01, time/batch = 0.6910s	
23726/30300 (epoch 39.152), train_loss = 0.93061562, grad/param norm = 1.9611e-01, time/batch = 0.6832s	
23727/30300 (epoch 39.153), train_loss = 1.05224690, grad/param norm = 2.1839e-01, time/batch = 0.6847s	
23728/30300 (epoch 39.155), train_loss = 0.91482048, grad/param norm = 1.7765e-01, time/batch = 0.6817s	
23729/30300 (epoch 39.157), train_loss = 0.97282332, grad/param norm = 1.9745e-01, time/batch = 0.6806s	
23730/30300 (epoch 39.158), train_loss = 1.08455931, grad/param norm = 2.4208e-01, time/batch = 0.6822s	
23731/30300 (epoch 39.160), train_loss = 0.95599385, grad/param norm = 1.9675e-01, time/batch = 0.6877s	
23732/30300 (epoch 39.162), train_loss = 1.03636292, grad/param norm = 1.7229e-01, time/batch = 0.6843s	
23733/30300 (epoch 39.163), train_loss = 1.03175649, grad/param norm = 2.0285e-01, time/batch = 0.6804s	
23734/30300 (epoch 39.165), train_loss = 1.15889476, grad/param norm = 1.8202e-01, time/batch = 0.6861s	
23735/30300 (epoch 39.167), train_loss = 1.04183925, grad/param norm = 1.9247e-01, time/batch = 0.6801s	
23736/30300 (epoch 39.168), train_loss = 1.08599624, grad/param norm = 1.8258e-01, time/batch = 0.6822s	
23737/30300 (epoch 39.170), train_loss = 1.05394796, grad/param norm = 1.9085e-01, time/batch = 0.6814s	
23738/30300 (epoch 39.172), train_loss = 1.04429735, grad/param norm = 1.9957e-01, time/batch = 0.6822s	
23739/30300 (epoch 39.173), train_loss = 1.01100615, grad/param norm = 2.1770e-01, time/batch = 0.6830s	
23740/30300 (epoch 39.175), train_loss = 1.05622623, grad/param norm = 1.9243e-01, time/batch = 0.6883s	
23741/30300 (epoch 39.177), train_loss = 1.11092170, grad/param norm = 1.9778e-01, time/batch = 0.6854s	
23742/30300 (epoch 39.178), train_loss = 0.85838913, grad/param norm = 1.4655e-01, time/batch = 0.7264s	
23743/30300 (epoch 39.180), train_loss = 1.01394987, grad/param norm = 1.6314e-01, time/batch = 0.7004s	
23744/30300 (epoch 39.182), train_loss = 1.05070465, grad/param norm = 1.9077e-01, time/batch = 0.6830s	
23745/30300 (epoch 39.183), train_loss = 0.97425679, grad/param norm = 1.7078e-01, time/batch = 0.6866s	
23746/30300 (epoch 39.185), train_loss = 1.17898841, grad/param norm = 1.9730e-01, time/batch = 0.6861s	
23747/30300 (epoch 39.186), train_loss = 1.24847593, grad/param norm = 2.1349e-01, time/batch = 0.6863s	
23748/30300 (epoch 39.188), train_loss = 1.08854378, grad/param norm = 2.2105e-01, time/batch = 0.6833s	
23749/30300 (epoch 39.190), train_loss = 1.03893082, grad/param norm = 1.6775e-01, time/batch = 0.6890s	
23750/30300 (epoch 39.191), train_loss = 1.09980527, grad/param norm = 2.0756e-01, time/batch = 0.6873s	
23751/30300 (epoch 39.193), train_loss = 0.93874489, grad/param norm = 1.6163e-01, time/batch = 0.6891s	
23752/30300 (epoch 39.195), train_loss = 0.98759530, grad/param norm = 1.6993e-01, time/batch = 0.6842s	
23753/30300 (epoch 39.196), train_loss = 1.05679444, grad/param norm = 1.9470e-01, time/batch = 0.6921s	
23754/30300 (epoch 39.198), train_loss = 0.88169336, grad/param norm = 1.5346e-01, time/batch = 0.6842s	
23755/30300 (epoch 39.200), train_loss = 1.00333881, grad/param norm = 1.7350e-01, time/batch = 0.6870s	
23756/30300 (epoch 39.201), train_loss = 1.14250679, grad/param norm = 3.1262e-01, time/batch = 0.6844s	
23757/30300 (epoch 39.203), train_loss = 1.01723713, grad/param norm = 1.8902e-01, time/batch = 0.6833s	
23758/30300 (epoch 39.205), train_loss = 1.21186700, grad/param norm = 1.9867e-01, time/batch = 0.6836s	
23759/30300 (epoch 39.206), train_loss = 1.10989809, grad/param norm = 1.9632e-01, time/batch = 0.6858s	
23760/30300 (epoch 39.208), train_loss = 1.09156501, grad/param norm = 2.3681e-01, time/batch = 0.6843s	
23761/30300 (epoch 39.210), train_loss = 1.12782298, grad/param norm = 1.8176e-01, time/batch = 0.6886s	
23762/30300 (epoch 39.211), train_loss = 1.16353700, grad/param norm = 2.0571e-01, time/batch = 0.6883s	
23763/30300 (epoch 39.213), train_loss = 1.04336632, grad/param norm = 1.5339e-01, time/batch = 0.6853s	
23764/30300 (epoch 39.215), train_loss = 0.95204585, grad/param norm = 1.7514e-01, time/batch = 0.6848s	
23765/30300 (epoch 39.216), train_loss = 0.97740189, grad/param norm = 1.7303e-01, time/batch = 0.7206s	
23766/30300 (epoch 39.218), train_loss = 0.95128166, grad/param norm = 1.6511e-01, time/batch = 0.7052s	
23767/30300 (epoch 39.219), train_loss = 0.90467921, grad/param norm = 1.6640e-01, time/batch = 0.6871s	
23768/30300 (epoch 39.221), train_loss = 0.87881926, grad/param norm = 1.5890e-01, time/batch = 0.6843s	
23769/30300 (epoch 39.223), train_loss = 1.03188259, grad/param norm = 1.7363e-01, time/batch = 0.6880s	
23770/30300 (epoch 39.224), train_loss = 0.86178216, grad/param norm = 1.6794e-01, time/batch = 0.6877s	
23771/30300 (epoch 39.226), train_loss = 1.08478162, grad/param norm = 1.8866e-01, time/batch = 0.6846s	
23772/30300 (epoch 39.228), train_loss = 1.15769054, grad/param norm = 2.0005e-01, time/batch = 0.6858s	
23773/30300 (epoch 39.229), train_loss = 1.01444819, grad/param norm = 1.7683e-01, time/batch = 0.6879s	
23774/30300 (epoch 39.231), train_loss = 1.09717659, grad/param norm = 1.9091e-01, time/batch = 0.6887s	
23775/30300 (epoch 39.233), train_loss = 1.08455620, grad/param norm = 1.5833e-01, time/batch = 0.6892s	
23776/30300 (epoch 39.234), train_loss = 1.13043086, grad/param norm = 2.2605e-01, time/batch = 0.6849s	
23777/30300 (epoch 39.236), train_loss = 1.07867048, grad/param norm = 1.6469e-01, time/batch = 0.6869s	
23778/30300 (epoch 39.238), train_loss = 1.04388118, grad/param norm = 2.4333e-01, time/batch = 0.6892s	
23779/30300 (epoch 39.239), train_loss = 0.99141814, grad/param norm = 2.2711e-01, time/batch = 0.6935s	
23780/30300 (epoch 39.241), train_loss = 1.06548695, grad/param norm = 1.8921e-01, time/batch = 0.6993s	
23781/30300 (epoch 39.243), train_loss = 1.06494613, grad/param norm = 1.6269e-01, time/batch = 0.7242s	
23782/30300 (epoch 39.244), train_loss = 1.24082380, grad/param norm = 1.8400e-01, time/batch = 0.7389s	
23783/30300 (epoch 39.246), train_loss = 1.08248948, grad/param norm = 1.8282e-01, time/batch = 0.7164s	
23784/30300 (epoch 39.248), train_loss = 1.02652498, grad/param norm = 1.7962e-01, time/batch = 0.7068s	
23785/30300 (epoch 39.249), train_loss = 0.93727807, grad/param norm = 1.8730e-01, time/batch = 0.7021s	
23786/30300 (epoch 39.251), train_loss = 0.97633472, grad/param norm = 1.8576e-01, time/batch = 0.7073s	
23787/30300 (epoch 39.252), train_loss = 1.15201050, grad/param norm = 2.2187e-01, time/batch = 0.6943s	
23788/30300 (epoch 39.254), train_loss = 1.10916707, grad/param norm = 1.6906e-01, time/batch = 0.7108s	
23789/30300 (epoch 39.256), train_loss = 1.07940495, grad/param norm = 1.6502e-01, time/batch = 0.7101s	
23790/30300 (epoch 39.257), train_loss = 1.09383595, grad/param norm = 2.0020e-01, time/batch = 0.7080s	
23791/30300 (epoch 39.259), train_loss = 1.03317740, grad/param norm = 1.8257e-01, time/batch = 0.6999s	
23792/30300 (epoch 39.261), train_loss = 1.17919653, grad/param norm = 1.8715e-01, time/batch = 0.6957s	
23793/30300 (epoch 39.262), train_loss = 0.96757764, grad/param norm = 1.7643e-01, time/batch = 0.6871s	
23794/30300 (epoch 39.264), train_loss = 1.02992456, grad/param norm = 1.6537e-01, time/batch = 0.6922s	
23795/30300 (epoch 39.266), train_loss = 1.02239387, grad/param norm = 1.6285e-01, time/batch = 0.6959s	
23796/30300 (epoch 39.267), train_loss = 1.17776406, grad/param norm = 2.0187e-01, time/batch = 0.6997s	
23797/30300 (epoch 39.269), train_loss = 1.05744945, grad/param norm = 1.7241e-01, time/batch = 0.6911s	
23798/30300 (epoch 39.271), train_loss = 1.05348012, grad/param norm = 1.7756e-01, time/batch = 0.7256s	
23799/30300 (epoch 39.272), train_loss = 1.06648989, grad/param norm = 2.1574e-01, time/batch = 0.7049s	
23800/30300 (epoch 39.274), train_loss = 1.10974299, grad/param norm = 1.8902e-01, time/batch = 0.6901s	
23801/30300 (epoch 39.276), train_loss = 1.07497510, grad/param norm = 2.0262e-01, time/batch = 0.6999s	
23802/30300 (epoch 39.277), train_loss = 0.94577737, grad/param norm = 1.8311e-01, time/batch = 0.6870s	
23803/30300 (epoch 39.279), train_loss = 1.03662137, grad/param norm = 1.7924e-01, time/batch = 0.6884s	
23804/30300 (epoch 39.281), train_loss = 1.13891282, grad/param norm = 2.9479e-01, time/batch = 0.6852s	
23805/30300 (epoch 39.282), train_loss = 1.08372669, grad/param norm = 1.7646e-01, time/batch = 0.6923s	
23806/30300 (epoch 39.284), train_loss = 1.13344588, grad/param norm = 2.6275e-01, time/batch = 0.6887s	
23807/30300 (epoch 39.285), train_loss = 1.09739418, grad/param norm = 1.7149e-01, time/batch = 0.6844s	
23808/30300 (epoch 39.287), train_loss = 1.05436862, grad/param norm = 2.0827e-01, time/batch = 0.6909s	
23809/30300 (epoch 39.289), train_loss = 1.12635696, grad/param norm = 1.7368e-01, time/batch = 0.6956s	
23810/30300 (epoch 39.290), train_loss = 0.84375635, grad/param norm = 1.8243e-01, time/batch = 0.6887s	
23811/30300 (epoch 39.292), train_loss = 0.93446848, grad/param norm = 1.7005e-01, time/batch = 0.6967s	
23812/30300 (epoch 39.294), train_loss = 1.11121823, grad/param norm = 2.2809e-01, time/batch = 0.6882s	
23813/30300 (epoch 39.295), train_loss = 0.99336955, grad/param norm = 1.6299e-01, time/batch = 0.6921s	
23814/30300 (epoch 39.297), train_loss = 1.01434471, grad/param norm = 1.6485e-01, time/batch = 0.6925s	
23815/30300 (epoch 39.299), train_loss = 1.02702528, grad/param norm = 1.7194e-01, time/batch = 0.6842s	
23816/30300 (epoch 39.300), train_loss = 0.96757239, grad/param norm = 1.9017e-01, time/batch = 0.7008s	
23817/30300 (epoch 39.302), train_loss = 1.12348326, grad/param norm = 1.8447e-01, time/batch = 0.7290s	
23818/30300 (epoch 39.304), train_loss = 0.96078939, grad/param norm = 1.6203e-01, time/batch = 0.6845s	
23819/30300 (epoch 39.305), train_loss = 1.03490559, grad/param norm = 1.6828e-01, time/batch = 0.6864s	
23820/30300 (epoch 39.307), train_loss = 1.13884758, grad/param norm = 1.7635e-01, time/batch = 0.6871s	
23821/30300 (epoch 39.309), train_loss = 1.07402965, grad/param norm = 1.7412e-01, time/batch = 0.6897s	
23822/30300 (epoch 39.310), train_loss = 1.02560136, grad/param norm = 1.8044e-01, time/batch = 0.6868s	
23823/30300 (epoch 39.312), train_loss = 1.16527373, grad/param norm = 1.7110e-01, time/batch = 0.7002s	
23824/30300 (epoch 39.314), train_loss = 1.04641486, grad/param norm = 1.7558e-01, time/batch = 0.6904s	
23825/30300 (epoch 39.315), train_loss = 1.00154397, grad/param norm = 1.8176e-01, time/batch = 0.6837s	
23826/30300 (epoch 39.317), train_loss = 1.07070043, grad/param norm = 1.7372e-01, time/batch = 0.6852s	
23827/30300 (epoch 39.318), train_loss = 1.11163403, grad/param norm = 2.2145e-01, time/batch = 0.6826s	
23828/30300 (epoch 39.320), train_loss = 1.08502767, grad/param norm = 1.8427e-01, time/batch = 0.6880s	
23829/30300 (epoch 39.322), train_loss = 0.99231089, grad/param norm = 1.7286e-01, time/batch = 0.6864s	
23830/30300 (epoch 39.323), train_loss = 1.15015439, grad/param norm = 2.1039e-01, time/batch = 0.6830s	
23831/30300 (epoch 39.325), train_loss = 1.03010708, grad/param norm = 1.7247e-01, time/batch = 0.7275s	
23832/30300 (epoch 39.327), train_loss = 1.02212643, grad/param norm = 1.6398e-01, time/batch = 0.7008s	
23833/30300 (epoch 39.328), train_loss = 1.05984932, grad/param norm = 1.5558e-01, time/batch = 0.6856s	
23834/30300 (epoch 39.330), train_loss = 1.08347457, grad/param norm = 1.7773e-01, time/batch = 0.6859s	
23835/30300 (epoch 39.332), train_loss = 1.14467840, grad/param norm = 1.8999e-01, time/batch = 0.6929s	
23836/30300 (epoch 39.333), train_loss = 0.96129031, grad/param norm = 1.9198e-01, time/batch = 0.6857s	
23837/30300 (epoch 39.335), train_loss = 0.93716643, grad/param norm = 1.5526e-01, time/batch = 0.6866s	
23838/30300 (epoch 39.337), train_loss = 1.16802416, grad/param norm = 1.7239e-01, time/batch = 0.6856s	
23839/30300 (epoch 39.338), train_loss = 0.98929515, grad/param norm = 1.6349e-01, time/batch = 0.6841s	
23840/30300 (epoch 39.340), train_loss = 0.99192410, grad/param norm = 1.6303e-01, time/batch = 0.6831s	
23841/30300 (epoch 39.342), train_loss = 1.11361877, grad/param norm = 1.7881e-01, time/batch = 0.6877s	
23842/30300 (epoch 39.343), train_loss = 1.06816522, grad/param norm = 1.9393e-01, time/batch = 0.6889s	
23843/30300 (epoch 39.345), train_loss = 1.09312190, grad/param norm = 1.6860e-01, time/batch = 0.7149s	
23844/30300 (epoch 39.347), train_loss = 0.94218109, grad/param norm = 1.7886e-01, time/batch = 0.6912s	
23845/30300 (epoch 39.348), train_loss = 0.99297129, grad/param norm = 1.7068e-01, time/batch = 0.6870s	
23846/30300 (epoch 39.350), train_loss = 1.00880252, grad/param norm = 1.7816e-01, time/batch = 0.6876s	
23847/30300 (epoch 39.351), train_loss = 1.03317383, grad/param norm = 1.8727e-01, time/batch = 0.6831s	
23848/30300 (epoch 39.353), train_loss = 0.91197868, grad/param norm = 1.6398e-01, time/batch = 0.6835s	
23849/30300 (epoch 39.355), train_loss = 0.99136746, grad/param norm = 1.5639e-01, time/batch = 0.6832s	
23850/30300 (epoch 39.356), train_loss = 1.11215675, grad/param norm = 1.9748e-01, time/batch = 0.6839s	
23851/30300 (epoch 39.358), train_loss = 1.26868516, grad/param norm = 1.6779e-01, time/batch = 0.6865s	
23852/30300 (epoch 39.360), train_loss = 0.99933968, grad/param norm = 1.7510e-01, time/batch = 0.6874s	
23853/30300 (epoch 39.361), train_loss = 1.03737572, grad/param norm = 1.8886e-01, time/batch = 0.6845s	
23854/30300 (epoch 39.363), train_loss = 1.06739068, grad/param norm = 1.8557e-01, time/batch = 0.6890s	
23855/30300 (epoch 39.365), train_loss = 0.90373231, grad/param norm = 1.7880e-01, time/batch = 0.6861s	
23856/30300 (epoch 39.366), train_loss = 1.01066915, grad/param norm = 1.7347e-01, time/batch = 0.6834s	
23857/30300 (epoch 39.368), train_loss = 0.91304935, grad/param norm = 1.7049e-01, time/batch = 0.6865s	
23858/30300 (epoch 39.370), train_loss = 0.96854628, grad/param norm = 1.7780e-01, time/batch = 0.6854s	
23859/30300 (epoch 39.371), train_loss = 1.10038242, grad/param norm = 1.7895e-01, time/batch = 0.6889s	
23860/30300 (epoch 39.373), train_loss = 0.99518064, grad/param norm = 1.5688e-01, time/batch = 0.6880s	
23861/30300 (epoch 39.375), train_loss = 0.96647769, grad/param norm = 1.5108e-01, time/batch = 0.6859s	
23862/30300 (epoch 39.376), train_loss = 0.95829831, grad/param norm = 1.5948e-01, time/batch = 0.6839s	
23863/30300 (epoch 39.378), train_loss = 0.94885340, grad/param norm = 1.8089e-01, time/batch = 0.6845s	
23864/30300 (epoch 39.380), train_loss = 1.14979085, grad/param norm = 1.8089e-01, time/batch = 0.6946s	
23865/30300 (epoch 39.381), train_loss = 0.85738814, grad/param norm = 1.7588e-01, time/batch = 0.6957s	
23866/30300 (epoch 39.383), train_loss = 0.93034944, grad/param norm = 1.8213e-01, time/batch = 0.7039s	
23867/30300 (epoch 39.384), train_loss = 1.09386516, grad/param norm = 1.9418e-01, time/batch = 0.7206s	
23868/30300 (epoch 39.386), train_loss = 0.92615617, grad/param norm = 1.5972e-01, time/batch = 0.7067s	
23869/30300 (epoch 39.388), train_loss = 0.92137331, grad/param norm = 1.9383e-01, time/batch = 0.7106s	
23870/30300 (epoch 39.389), train_loss = 1.02685815, grad/param norm = 1.8700e-01, time/batch = 0.7003s	
23871/30300 (epoch 39.391), train_loss = 1.06722822, grad/param norm = 1.6661e-01, time/batch = 0.6935s	
23872/30300 (epoch 39.393), train_loss = 0.92050950, grad/param norm = 1.6203e-01, time/batch = 0.6899s	
23873/30300 (epoch 39.394), train_loss = 1.05785134, grad/param norm = 1.7067e-01, time/batch = 0.6907s	
23874/30300 (epoch 39.396), train_loss = 1.15285432, grad/param norm = 1.6982e-01, time/batch = 0.6891s	
23875/30300 (epoch 39.398), train_loss = 0.99160809, grad/param norm = 1.6213e-01, time/batch = 0.6861s	
23876/30300 (epoch 39.399), train_loss = 0.95534733, grad/param norm = 1.7354e-01, time/batch = 0.6854s	
23877/30300 (epoch 39.401), train_loss = 1.05563826, grad/param norm = 2.2769e-01, time/batch = 0.6841s	
23878/30300 (epoch 39.403), train_loss = 1.02299632, grad/param norm = 1.7496e-01, time/batch = 0.6871s	
23879/30300 (epoch 39.404), train_loss = 0.97365085, grad/param norm = 1.8889e-01, time/batch = 0.6805s	
23880/30300 (epoch 39.406), train_loss = 1.04941587, grad/param norm = 1.7116e-01, time/batch = 0.6813s	
23881/30300 (epoch 39.408), train_loss = 0.90186739, grad/param norm = 1.4506e-01, time/batch = 0.6863s	
23882/30300 (epoch 39.409), train_loss = 0.89835264, grad/param norm = 1.6128e-01, time/batch = 0.6829s	
23883/30300 (epoch 39.411), train_loss = 0.95493344, grad/param norm = 1.5626e-01, time/batch = 0.6801s	
23884/30300 (epoch 39.413), train_loss = 0.86181558, grad/param norm = 1.5956e-01, time/batch = 0.6828s	
23885/30300 (epoch 39.414), train_loss = 1.06759938, grad/param norm = 1.7460e-01, time/batch = 0.6828s	
23886/30300 (epoch 39.416), train_loss = 0.96604166, grad/param norm = 1.6328e-01, time/batch = 0.6813s	
23887/30300 (epoch 39.417), train_loss = 0.93870226, grad/param norm = 1.8453e-01, time/batch = 0.6834s	
23888/30300 (epoch 39.419), train_loss = 0.92015348, grad/param norm = 1.5111e-01, time/batch = 0.6807s	
23889/30300 (epoch 39.421), train_loss = 1.00355729, grad/param norm = 2.3242e-01, time/batch = 0.6822s	
23890/30300 (epoch 39.422), train_loss = 1.03492982, grad/param norm = 1.7909e-01, time/batch = 0.6802s	
23891/30300 (epoch 39.424), train_loss = 1.03066151, grad/param norm = 1.7145e-01, time/batch = 0.7082s	
23892/30300 (epoch 39.426), train_loss = 0.98644230, grad/param norm = 1.7236e-01, time/batch = 0.6910s	
23893/30300 (epoch 39.427), train_loss = 0.96960921, grad/param norm = 1.8344e-01, time/batch = 0.6817s	
23894/30300 (epoch 39.429), train_loss = 1.01337466, grad/param norm = 1.6081e-01, time/batch = 0.6811s	
23895/30300 (epoch 39.431), train_loss = 1.06293663, grad/param norm = 1.7327e-01, time/batch = 0.6815s	
23896/30300 (epoch 39.432), train_loss = 1.02928508, grad/param norm = 1.6693e-01, time/batch = 0.6827s	
23897/30300 (epoch 39.434), train_loss = 0.91849346, grad/param norm = 1.6377e-01, time/batch = 0.6808s	
23898/30300 (epoch 39.436), train_loss = 1.11114141, grad/param norm = 1.7123e-01, time/batch = 0.6815s	
23899/30300 (epoch 39.437), train_loss = 0.92010958, grad/param norm = 1.6693e-01, time/batch = 0.6819s	
23900/30300 (epoch 39.439), train_loss = 0.96335212, grad/param norm = 1.7201e-01, time/batch = 0.6832s	
23901/30300 (epoch 39.441), train_loss = 1.00824714, grad/param norm = 1.5207e-01, time/batch = 0.6831s	
23902/30300 (epoch 39.442), train_loss = 0.95897509, grad/param norm = 1.5886e-01, time/batch = 0.6819s	
23903/30300 (epoch 39.444), train_loss = 0.83949443, grad/param norm = 1.5637e-01, time/batch = 0.6835s	
23904/30300 (epoch 39.446), train_loss = 0.98193821, grad/param norm = 1.5929e-01, time/batch = 0.6840s	
23905/30300 (epoch 39.447), train_loss = 1.01377863, grad/param norm = 1.5921e-01, time/batch = 0.6826s	
23906/30300 (epoch 39.449), train_loss = 0.95693416, grad/param norm = 1.6015e-01, time/batch = 0.6827s	
23907/30300 (epoch 39.450), train_loss = 1.04218333, grad/param norm = 1.6124e-01, time/batch = 0.6856s	
23908/30300 (epoch 39.452), train_loss = 1.12089580, grad/param norm = 1.6128e-01, time/batch = 0.6836s	
23909/30300 (epoch 39.454), train_loss = 1.06255882, grad/param norm = 1.5343e-01, time/batch = 0.6834s	
23910/30300 (epoch 39.455), train_loss = 1.02135103, grad/param norm = 1.7518e-01, time/batch = 0.6839s	
23911/30300 (epoch 39.457), train_loss = 0.97755911, grad/param norm = 1.6944e-01, time/batch = 0.6847s	
23912/30300 (epoch 39.459), train_loss = 1.08001750, grad/param norm = 2.0530e-01, time/batch = 0.6844s	
23913/30300 (epoch 39.460), train_loss = 1.09336838, grad/param norm = 1.9816e-01, time/batch = 0.6814s	
23914/30300 (epoch 39.462), train_loss = 1.09249687, grad/param norm = 1.7135e-01, time/batch = 0.6830s	
23915/30300 (epoch 39.464), train_loss = 0.84456871, grad/param norm = 1.9376e-01, time/batch = 0.6805s	
23916/30300 (epoch 39.465), train_loss = 0.86907587, grad/param norm = 1.3888e-01, time/batch = 0.6822s	
23917/30300 (epoch 39.467), train_loss = 0.86754393, grad/param norm = 1.6441e-01, time/batch = 0.6831s	
23918/30300 (epoch 39.469), train_loss = 0.95889967, grad/param norm = 1.7217e-01, time/batch = 0.6845s	
23919/30300 (epoch 39.470), train_loss = 0.96990456, grad/param norm = 1.7366e-01, time/batch = 0.6818s	
23920/30300 (epoch 39.472), train_loss = 0.96828922, grad/param norm = 1.5114e-01, time/batch = 0.6825s	
23921/30300 (epoch 39.474), train_loss = 0.97279084, grad/param norm = 2.5623e-01, time/batch = 0.6818s	
23922/30300 (epoch 39.475), train_loss = 0.95203197, grad/param norm = 1.6671e-01, time/batch = 0.6931s	
23923/30300 (epoch 39.477), train_loss = 1.00727438, grad/param norm = 1.7668e-01, time/batch = 0.6853s	
23924/30300 (epoch 39.479), train_loss = 0.98138534, grad/param norm = 1.6075e-01, time/batch = 0.6828s	
23925/30300 (epoch 39.480), train_loss = 1.04032192, grad/param norm = 1.8427e-01, time/batch = 0.6827s	
23926/30300 (epoch 39.482), train_loss = 1.06685359, grad/param norm = 1.6101e-01, time/batch = 0.6803s	
23927/30300 (epoch 39.483), train_loss = 0.99979951, grad/param norm = 1.6087e-01, time/batch = 0.6802s	
23928/30300 (epoch 39.485), train_loss = 1.01841817, grad/param norm = 1.6913e-01, time/batch = 0.6805s	
23929/30300 (epoch 39.487), train_loss = 1.08518432, grad/param norm = 1.6915e-01, time/batch = 0.7012s	
23930/30300 (epoch 39.488), train_loss = 1.13823252, grad/param norm = 1.5338e-01, time/batch = 0.7214s	
23931/30300 (epoch 39.490), train_loss = 0.89331382, grad/param norm = 1.6523e-01, time/batch = 0.6826s	
23932/30300 (epoch 39.492), train_loss = 0.97862293, grad/param norm = 1.7459e-01, time/batch = 0.6843s	
23933/30300 (epoch 39.493), train_loss = 1.01866919, grad/param norm = 1.5933e-01, time/batch = 0.6825s	
23934/30300 (epoch 39.495), train_loss = 0.99522212, grad/param norm = 1.5279e-01, time/batch = 0.6824s	
23935/30300 (epoch 39.497), train_loss = 1.04102007, grad/param norm = 1.6679e-01, time/batch = 0.6848s	
23936/30300 (epoch 39.498), train_loss = 1.06320366, grad/param norm = 1.7869e-01, time/batch = 0.6872s	
23937/30300 (epoch 39.500), train_loss = 0.98482795, grad/param norm = 2.0585e-01, time/batch = 0.6806s	
23938/30300 (epoch 39.502), train_loss = 1.02227693, grad/param norm = 2.1309e-01, time/batch = 0.6815s	
23939/30300 (epoch 39.503), train_loss = 1.11928550, grad/param norm = 1.7535e-01, time/batch = 0.6887s	
23940/30300 (epoch 39.505), train_loss = 0.90316529, grad/param norm = 1.5579e-01, time/batch = 0.6807s	
23941/30300 (epoch 39.507), train_loss = 0.90804765, grad/param norm = 1.7378e-01, time/batch = 0.6862s	
23942/30300 (epoch 39.508), train_loss = 0.95736792, grad/param norm = 1.8756e-01, time/batch = 0.6826s	
23943/30300 (epoch 39.510), train_loss = 1.07441505, grad/param norm = 1.8843e-01, time/batch = 0.6923s	
23944/30300 (epoch 39.512), train_loss = 0.95429570, grad/param norm = 1.6468e-01, time/batch = 0.6882s	
23945/30300 (epoch 39.513), train_loss = 1.01114535, grad/param norm = 1.7617e-01, time/batch = 0.6869s	
23946/30300 (epoch 39.515), train_loss = 0.99545069, grad/param norm = 1.6025e-01, time/batch = 0.6819s	
23947/30300 (epoch 39.517), train_loss = 0.84370610, grad/param norm = 1.5817e-01, time/batch = 0.6836s	
23948/30300 (epoch 39.518), train_loss = 1.10250328, grad/param norm = 1.8749e-01, time/batch = 0.6814s	
23949/30300 (epoch 39.520), train_loss = 1.00343248, grad/param norm = 1.9005e-01, time/batch = 0.6826s	
23950/30300 (epoch 39.521), train_loss = 0.92068828, grad/param norm = 1.9239e-01, time/batch = 0.6834s	
23951/30300 (epoch 39.523), train_loss = 1.13304180, grad/param norm = 2.0340e-01, time/batch = 0.6895s	
23952/30300 (epoch 39.525), train_loss = 0.93247506, grad/param norm = 1.6432e-01, time/batch = 0.6985s	
23953/30300 (epoch 39.526), train_loss = 1.03397941, grad/param norm = 1.5813e-01, time/batch = 0.7011s	
23954/30300 (epoch 39.528), train_loss = 0.89699532, grad/param norm = 1.6664e-01, time/batch = 0.7003s	
23955/30300 (epoch 39.530), train_loss = 0.88642353, grad/param norm = 1.6550e-01, time/batch = 0.7102s	
23956/30300 (epoch 39.531), train_loss = 1.01061134, grad/param norm = 1.6401e-01, time/batch = 0.6907s	
23957/30300 (epoch 39.533), train_loss = 0.98731466, grad/param norm = 1.7972e-01, time/batch = 0.6907s	
23958/30300 (epoch 39.535), train_loss = 1.00017438, grad/param norm = 1.5955e-01, time/batch = 0.6844s	
23959/30300 (epoch 39.536), train_loss = 1.02657815, grad/param norm = 1.9034e-01, time/batch = 0.6868s	
23960/30300 (epoch 39.538), train_loss = 0.87729684, grad/param norm = 1.6071e-01, time/batch = 0.6886s	
23961/30300 (epoch 39.540), train_loss = 0.94773756, grad/param norm = 1.6976e-01, time/batch = 0.6952s	
23962/30300 (epoch 39.541), train_loss = 1.01148874, grad/param norm = 1.9635e-01, time/batch = 0.6898s	
23963/30300 (epoch 39.543), train_loss = 0.98184418, grad/param norm = 1.5788e-01, time/batch = 0.6851s	
23964/30300 (epoch 39.545), train_loss = 1.05167178, grad/param norm = 2.5177e-01, time/batch = 0.6860s	
23965/30300 (epoch 39.546), train_loss = 1.18138210, grad/param norm = 1.6640e-01, time/batch = 0.6851s	
23966/30300 (epoch 39.548), train_loss = 0.95295136, grad/param norm = 1.5143e-01, time/batch = 0.6833s	
23967/30300 (epoch 39.550), train_loss = 1.05418030, grad/param norm = 2.0597e-01, time/batch = 0.6831s	
23968/30300 (epoch 39.551), train_loss = 0.94140652, grad/param norm = 1.6839e-01, time/batch = 0.6845s	
23969/30300 (epoch 39.553), train_loss = 0.97409822, grad/param norm = 1.5615e-01, time/batch = 0.6827s	
23970/30300 (epoch 39.554), train_loss = 1.01044497, grad/param norm = 1.6877e-01, time/batch = 0.6824s	
23971/30300 (epoch 39.556), train_loss = 1.03821483, grad/param norm = 1.6754e-01, time/batch = 0.6878s	
23972/30300 (epoch 39.558), train_loss = 1.08634241, grad/param norm = 1.8901e-01, time/batch = 0.6835s	
23973/30300 (epoch 39.559), train_loss = 1.02550007, grad/param norm = 1.8028e-01, time/batch = 0.6839s	
23974/30300 (epoch 39.561), train_loss = 0.81608714, grad/param norm = 1.5596e-01, time/batch = 0.6848s	
23975/30300 (epoch 39.563), train_loss = 0.89825687, grad/param norm = 1.5819e-01, time/batch = 0.6841s	
23976/30300 (epoch 39.564), train_loss = 0.94898204, grad/param norm = 1.4587e-01, time/batch = 0.6844s	
23977/30300 (epoch 39.566), train_loss = 0.97122773, grad/param norm = 1.6547e-01, time/batch = 0.6833s	
23978/30300 (epoch 39.568), train_loss = 0.85956317, grad/param norm = 2.8468e-01, time/batch = 0.6834s	
23979/30300 (epoch 39.569), train_loss = 1.03826034, grad/param norm = 1.6942e-01, time/batch = 0.6842s	
23980/30300 (epoch 39.571), train_loss = 1.01398774, grad/param norm = 1.7529e-01, time/batch = 0.6859s	
23981/30300 (epoch 39.573), train_loss = 1.05623655, grad/param norm = 1.6875e-01, time/batch = 0.6862s	
23982/30300 (epoch 39.574), train_loss = 1.03347136, grad/param norm = 1.6104e-01, time/batch = 0.7031s	
23983/30300 (epoch 39.576), train_loss = 0.96964374, grad/param norm = 1.4493e-01, time/batch = 0.6947s	
23984/30300 (epoch 39.578), train_loss = 0.87397978, grad/param norm = 1.5366e-01, time/batch = 0.6945s	
23985/30300 (epoch 39.579), train_loss = 1.05478030, grad/param norm = 1.8207e-01, time/batch = 0.6880s	
23986/30300 (epoch 39.581), train_loss = 1.12477330, grad/param norm = 1.6386e-01, time/batch = 0.6887s	
23987/30300 (epoch 39.583), train_loss = 1.12908671, grad/param norm = 2.0582e-01, time/batch = 0.6944s	
23988/30300 (epoch 39.584), train_loss = 1.11007386, grad/param norm = 1.6768e-01, time/batch = 0.6949s	
23989/30300 (epoch 39.586), train_loss = 0.98189486, grad/param norm = 1.7536e-01, time/batch = 0.7012s	
23990/30300 (epoch 39.587), train_loss = 0.99909718, grad/param norm = 1.7125e-01, time/batch = 0.7076s	
23991/30300 (epoch 39.589), train_loss = 0.94818666, grad/param norm = 1.7170e-01, time/batch = 0.7186s	
23992/30300 (epoch 39.591), train_loss = 1.01649228, grad/param norm = 1.5094e-01, time/batch = 0.7046s	
23993/30300 (epoch 39.592), train_loss = 0.96127353, grad/param norm = 1.5136e-01, time/batch = 0.6857s	
23994/30300 (epoch 39.594), train_loss = 1.03498636, grad/param norm = 1.5539e-01, time/batch = 0.6909s	
23995/30300 (epoch 39.596), train_loss = 0.91751700, grad/param norm = 1.5495e-01, time/batch = 0.6838s	
23996/30300 (epoch 39.597), train_loss = 0.95045926, grad/param norm = 1.8913e-01, time/batch = 0.6833s	
23997/30300 (epoch 39.599), train_loss = 0.85726213, grad/param norm = 1.4853e-01, time/batch = 0.6858s	
23998/30300 (epoch 39.601), train_loss = 1.03306679, grad/param norm = 1.7449e-01, time/batch = 0.6846s	
23999/30300 (epoch 39.602), train_loss = 0.98532821, grad/param norm = 1.5608e-01, time/batch = 0.6858s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch39.60_2.0290.t7	
24000/30300 (epoch 39.604), train_loss = 0.93202848, grad/param norm = 1.5986e-01, time/batch = 0.7103s	
24001/30300 (epoch 39.606), train_loss = 1.73196274, grad/param norm = 5.4209e-01, time/batch = 0.6918s	
24002/30300 (epoch 39.607), train_loss = 1.10284076, grad/param norm = 2.4215e-01, time/batch = 0.6827s	
24003/30300 (epoch 39.609), train_loss = 1.18472077, grad/param norm = 1.8931e-01, time/batch = 0.6841s	
24004/30300 (epoch 39.611), train_loss = 0.98235752, grad/param norm = 2.0214e-01, time/batch = 0.6840s	
24005/30300 (epoch 39.612), train_loss = 0.91537497, grad/param norm = 1.7078e-01, time/batch = 0.6840s	
24006/30300 (epoch 39.614), train_loss = 0.97867405, grad/param norm = 1.5716e-01, time/batch = 0.6977s	
24007/30300 (epoch 39.616), train_loss = 1.03407070, grad/param norm = 2.0531e-01, time/batch = 0.6929s	
24008/30300 (epoch 39.617), train_loss = 1.01913842, grad/param norm = 1.8029e-01, time/batch = 0.6907s	
24009/30300 (epoch 39.619), train_loss = 0.82548789, grad/param norm = 1.4273e-01, time/batch = 0.6884s	
24010/30300 (epoch 39.620), train_loss = 1.06770478, grad/param norm = 1.7207e-01, time/batch = 0.6862s	
24011/30300 (epoch 39.622), train_loss = 1.00698691, grad/param norm = 1.8773e-01, time/batch = 0.6833s	
24012/30300 (epoch 39.624), train_loss = 0.99276610, grad/param norm = 1.6896e-01, time/batch = 0.6818s	
24013/30300 (epoch 39.625), train_loss = 1.00970293, grad/param norm = 2.3115e-01, time/batch = 0.6827s	
24014/30300 (epoch 39.627), train_loss = 1.09904059, grad/param norm = 2.3840e-01, time/batch = 0.6839s	
24015/30300 (epoch 39.629), train_loss = 1.13223365, grad/param norm = 1.6817e-01, time/batch = 0.6848s	
24016/30300 (epoch 39.630), train_loss = 1.01444038, grad/param norm = 1.9062e-01, time/batch = 0.6841s	
24017/30300 (epoch 39.632), train_loss = 1.06567561, grad/param norm = 1.8861e-01, time/batch = 0.6833s	
24018/30300 (epoch 39.634), train_loss = 0.92943371, grad/param norm = 1.5932e-01, time/batch = 0.6853s	
24019/30300 (epoch 39.635), train_loss = 1.06920485, grad/param norm = 1.9951e-01, time/batch = 0.6831s	
24020/30300 (epoch 39.637), train_loss = 1.10621663, grad/param norm = 2.4905e-01, time/batch = 0.6832s	
24021/30300 (epoch 39.639), train_loss = 0.99264612, grad/param norm = 1.7803e-01, time/batch = 0.6857s	
24022/30300 (epoch 39.640), train_loss = 1.10614067, grad/param norm = 1.9687e-01, time/batch = 0.6954s	
24023/30300 (epoch 39.642), train_loss = 0.99508988, grad/param norm = 1.5733e-01, time/batch = 0.6911s	
24024/30300 (epoch 39.644), train_loss = 1.07863069, grad/param norm = 1.7249e-01, time/batch = 0.6907s	
24025/30300 (epoch 39.645), train_loss = 0.95384664, grad/param norm = 1.5515e-01, time/batch = 0.6850s	
24026/30300 (epoch 39.647), train_loss = 1.01552750, grad/param norm = 1.5529e-01, time/batch = 0.6823s	
24027/30300 (epoch 39.649), train_loss = 0.98611914, grad/param norm = 1.7820e-01, time/batch = 0.6845s	
24028/30300 (epoch 39.650), train_loss = 1.01955514, grad/param norm = 1.8506e-01, time/batch = 0.6866s	
24029/30300 (epoch 39.652), train_loss = 0.98259822, grad/param norm = 1.8673e-01, time/batch = 0.6932s	
24030/30300 (epoch 39.653), train_loss = 1.17468702, grad/param norm = 1.6404e-01, time/batch = 0.7129s	
24031/30300 (epoch 39.655), train_loss = 0.98742303, grad/param norm = 1.7043e-01, time/batch = 0.6945s	
24032/30300 (epoch 39.657), train_loss = 0.90950006, grad/param norm = 1.6523e-01, time/batch = 0.7104s	
24033/30300 (epoch 39.658), train_loss = 0.97442780, grad/param norm = 1.6121e-01, time/batch = 0.6912s	
24034/30300 (epoch 39.660), train_loss = 1.01184530, grad/param norm = 1.7415e-01, time/batch = 0.6873s	
24035/30300 (epoch 39.662), train_loss = 1.03076422, grad/param norm = 1.8574e-01, time/batch = 0.6834s	
24036/30300 (epoch 39.663), train_loss = 1.07825626, grad/param norm = 1.7954e-01, time/batch = 0.6811s	
24037/30300 (epoch 39.665), train_loss = 0.93811314, grad/param norm = 1.8000e-01, time/batch = 0.7108s	
24038/30300 (epoch 39.667), train_loss = 1.06642631, grad/param norm = 1.6578e-01, time/batch = 0.7325s	
24039/30300 (epoch 39.668), train_loss = 1.07909252, grad/param norm = 1.7050e-01, time/batch = 0.7187s	
24040/30300 (epoch 39.670), train_loss = 1.10031703, grad/param norm = 1.7057e-01, time/batch = 0.7219s	
24041/30300 (epoch 39.672), train_loss = 1.02219617, grad/param norm = 1.7646e-01, time/batch = 0.7305s	
24042/30300 (epoch 39.673), train_loss = 1.07446981, grad/param norm = 2.2137e-01, time/batch = 0.7281s	
24043/30300 (epoch 39.675), train_loss = 0.98325542, grad/param norm = 1.9761e-01, time/batch = 0.7180s	
24044/30300 (epoch 39.677), train_loss = 0.97330157, grad/param norm = 1.7184e-01, time/batch = 0.7359s	
24045/30300 (epoch 39.678), train_loss = 0.95860611, grad/param norm = 1.5574e-01, time/batch = 0.7279s	
24046/30300 (epoch 39.680), train_loss = 0.90775051, grad/param norm = 1.6064e-01, time/batch = 0.6980s	
24047/30300 (epoch 39.682), train_loss = 0.99698723, grad/param norm = 1.8619e-01, time/batch = 0.7392s	
24048/30300 (epoch 39.683), train_loss = 1.08777534, grad/param norm = 1.6034e-01, time/batch = 0.6986s	
24049/30300 (epoch 39.685), train_loss = 1.06447942, grad/param norm = 1.8582e-01, time/batch = 0.6897s	
24050/30300 (epoch 39.686), train_loss = 0.98833404, grad/param norm = 1.6378e-01, time/batch = 0.6869s	
24051/30300 (epoch 39.688), train_loss = 1.00367478, grad/param norm = 1.6090e-01, time/batch = 0.6933s	
24052/30300 (epoch 39.690), train_loss = 0.96630683, grad/param norm = 2.3137e-01, time/batch = 0.6999s	
24053/30300 (epoch 39.691), train_loss = 1.01049684, grad/param norm = 1.7667e-01, time/batch = 0.6858s	
24054/30300 (epoch 39.693), train_loss = 1.28759957, grad/param norm = 2.0164e-01, time/batch = 0.6795s	
24055/30300 (epoch 39.695), train_loss = 1.08863963, grad/param norm = 1.8159e-01, time/batch = 0.6791s	
24056/30300 (epoch 39.696), train_loss = 1.08544635, grad/param norm = 2.3271e-01, time/batch = 0.6823s	
24057/30300 (epoch 39.698), train_loss = 0.98340477, grad/param norm = 1.8050e-01, time/batch = 0.6797s	
24058/30300 (epoch 39.700), train_loss = 0.94787563, grad/param norm = 1.6533e-01, time/batch = 0.6827s	
24059/30300 (epoch 39.701), train_loss = 0.89064301, grad/param norm = 1.7329e-01, time/batch = 0.6842s	
24060/30300 (epoch 39.703), train_loss = 1.01558557, grad/param norm = 1.6782e-01, time/batch = 0.6823s	
24061/30300 (epoch 39.705), train_loss = 0.92390340, grad/param norm = 1.6090e-01, time/batch = 0.6845s	
24062/30300 (epoch 39.706), train_loss = 1.05706879, grad/param norm = 1.8530e-01, time/batch = 0.6891s	
24063/30300 (epoch 39.708), train_loss = 1.01014149, grad/param norm = 1.6303e-01, time/batch = 0.6878s	
24064/30300 (epoch 39.710), train_loss = 0.98555966, grad/param norm = 1.6589e-01, time/batch = 0.6903s	
24065/30300 (epoch 39.711), train_loss = 0.96245739, grad/param norm = 1.6759e-01, time/batch = 0.6876s	
24066/30300 (epoch 39.713), train_loss = 0.95475816, grad/param norm = 1.8129e-01, time/batch = 0.6885s	
24067/30300 (epoch 39.715), train_loss = 0.97548649, grad/param norm = 1.6992e-01, time/batch = 0.6858s	
24068/30300 (epoch 39.716), train_loss = 1.07629583, grad/param norm = 1.6884e-01, time/batch = 0.6813s	
24069/30300 (epoch 39.718), train_loss = 1.12153758, grad/param norm = 1.7911e-01, time/batch = 0.6886s	
24070/30300 (epoch 39.719), train_loss = 0.96136240, grad/param norm = 1.9156e-01, time/batch = 0.6826s	
24071/30300 (epoch 39.721), train_loss = 0.98833252, grad/param norm = 2.0091e-01, time/batch = 0.6841s	
24072/30300 (epoch 39.723), train_loss = 0.93635731, grad/param norm = 1.5629e-01, time/batch = 0.6845s	
24073/30300 (epoch 39.724), train_loss = 1.04586282, grad/param norm = 2.0208e-01, time/batch = 0.6873s	
24074/30300 (epoch 39.726), train_loss = 1.26413147, grad/param norm = 1.9606e-01, time/batch = 0.6851s	
24075/30300 (epoch 39.728), train_loss = 1.05025189, grad/param norm = 1.8116e-01, time/batch = 0.6821s	
24076/30300 (epoch 39.729), train_loss = 0.97844550, grad/param norm = 1.9000e-01, time/batch = 0.6811s	
24077/30300 (epoch 39.731), train_loss = 0.98474083, grad/param norm = 1.9460e-01, time/batch = 0.6796s	
24078/30300 (epoch 39.733), train_loss = 1.02281592, grad/param norm = 1.7164e-01, time/batch = 0.6774s	
24079/30300 (epoch 39.734), train_loss = 1.09732420, grad/param norm = 1.7300e-01, time/batch = 0.6800s	
24080/30300 (epoch 39.736), train_loss = 1.02218690, grad/param norm = 1.6135e-01, time/batch = 0.6812s	
24081/30300 (epoch 39.738), train_loss = 0.94765460, grad/param norm = 1.3986e-01, time/batch = 0.6851s	
24082/30300 (epoch 39.739), train_loss = 1.11550019, grad/param norm = 1.9162e-01, time/batch = 0.6877s	
24083/30300 (epoch 39.741), train_loss = 1.16758581, grad/param norm = 1.6916e-01, time/batch = 0.6842s	
24084/30300 (epoch 39.743), train_loss = 0.98991536, grad/param norm = 1.7942e-01, time/batch = 0.6822s	
24085/30300 (epoch 39.744), train_loss = 1.04195927, grad/param norm = 1.6517e-01, time/batch = 0.6814s	
24086/30300 (epoch 39.746), train_loss = 0.97288141, grad/param norm = 1.5748e-01, time/batch = 0.6835s	
24087/30300 (epoch 39.748), train_loss = 1.00480527, grad/param norm = 1.8094e-01, time/batch = 0.6814s	
24088/30300 (epoch 39.749), train_loss = 1.01520571, grad/param norm = 1.6087e-01, time/batch = 0.6816s	
24089/30300 (epoch 39.751), train_loss = 1.05680265, grad/param norm = 1.6853e-01, time/batch = 0.6842s	
24090/30300 (epoch 39.752), train_loss = 0.99938601, grad/param norm = 1.8378e-01, time/batch = 0.6878s	
24091/30300 (epoch 39.754), train_loss = 1.00064644, grad/param norm = 1.6662e-01, time/batch = 0.6894s	
24092/30300 (epoch 39.756), train_loss = 0.99029645, grad/param norm = 1.6950e-01, time/batch = 0.6830s	
24093/30300 (epoch 39.757), train_loss = 0.95280634, grad/param norm = 1.7305e-01, time/batch = 0.6830s	
24094/30300 (epoch 39.759), train_loss = 1.03017577, grad/param norm = 1.5612e-01, time/batch = 0.6841s	
24095/30300 (epoch 39.761), train_loss = 0.88682668, grad/param norm = 1.5751e-01, time/batch = 0.6821s	
24096/30300 (epoch 39.762), train_loss = 0.90740173, grad/param norm = 1.6496e-01, time/batch = 0.6849s	
24097/30300 (epoch 39.764), train_loss = 0.98819190, grad/param norm = 1.9545e-01, time/batch = 0.6845s	
24098/30300 (epoch 39.766), train_loss = 1.12806570, grad/param norm = 1.9842e-01, time/batch = 0.6837s	
24099/30300 (epoch 39.767), train_loss = 1.05026726, grad/param norm = 2.3129e-01, time/batch = 0.6843s	
24100/30300 (epoch 39.769), train_loss = 1.02893818, grad/param norm = 1.7957e-01, time/batch = 0.6837s	
24101/30300 (epoch 39.771), train_loss = 0.95447168, grad/param norm = 1.9886e-01, time/batch = 0.6869s	
24102/30300 (epoch 39.772), train_loss = 1.02630678, grad/param norm = 1.6790e-01, time/batch = 0.6885s	
24103/30300 (epoch 39.774), train_loss = 1.16795190, grad/param norm = 1.8176e-01, time/batch = 0.6961s	
24104/30300 (epoch 39.776), train_loss = 0.98067690, grad/param norm = 1.8777e-01, time/batch = 0.6911s	
24105/30300 (epoch 39.777), train_loss = 1.13557293, grad/param norm = 1.7500e-01, time/batch = 0.7055s	
24106/30300 (epoch 39.779), train_loss = 1.12383884, grad/param norm = 2.2943e-01, time/batch = 0.7048s	
24107/30300 (epoch 39.781), train_loss = 1.03460787, grad/param norm = 1.9836e-01, time/batch = 0.7205s	
24108/30300 (epoch 39.782), train_loss = 0.94862434, grad/param norm = 2.2602e-01, time/batch = 0.7140s	
24109/30300 (epoch 39.784), train_loss = 0.97111197, grad/param norm = 1.7067e-01, time/batch = 0.7036s	
24110/30300 (epoch 39.785), train_loss = 1.08262111, grad/param norm = 2.2152e-01, time/batch = 0.7056s	
24111/30300 (epoch 39.787), train_loss = 0.85730989, grad/param norm = 1.6732e-01, time/batch = 0.6990s	
24112/30300 (epoch 39.789), train_loss = 1.16144290, grad/param norm = 1.9223e-01, time/batch = 0.6968s	
24113/30300 (epoch 39.790), train_loss = 1.02046065, grad/param norm = 1.9883e-01, time/batch = 0.6970s	
24114/30300 (epoch 39.792), train_loss = 0.82238170, grad/param norm = 1.7886e-01, time/batch = 0.6964s	
24115/30300 (epoch 39.794), train_loss = 1.00605288, grad/param norm = 1.6832e-01, time/batch = 0.7006s	
24116/30300 (epoch 39.795), train_loss = 0.94009529, grad/param norm = 1.4791e-01, time/batch = 0.7190s	
24117/30300 (epoch 39.797), train_loss = 1.15508876, grad/param norm = 1.9245e-01, time/batch = 0.7337s	
24118/30300 (epoch 39.799), train_loss = 1.09936147, grad/param norm = 2.3594e-01, time/batch = 0.7223s	
24119/30300 (epoch 39.800), train_loss = 1.08052482, grad/param norm = 1.7150e-01, time/batch = 0.6927s	
24120/30300 (epoch 39.802), train_loss = 1.24755635, grad/param norm = 2.1789e-01, time/batch = 0.6996s	
24121/30300 (epoch 39.804), train_loss = 1.07186668, grad/param norm = 1.9335e-01, time/batch = 0.6919s	
24122/30300 (epoch 39.805), train_loss = 1.14835902, grad/param norm = 1.7475e-01, time/batch = 0.6934s	
24123/30300 (epoch 39.807), train_loss = 0.99802986, grad/param norm = 1.8567e-01, time/batch = 0.6914s	
24124/30300 (epoch 39.809), train_loss = 1.09583226, grad/param norm = 1.9553e-01, time/batch = 0.6819s	
24125/30300 (epoch 39.810), train_loss = 1.07205296, grad/param norm = 1.9342e-01, time/batch = 0.6830s	
24126/30300 (epoch 39.812), train_loss = 0.98850934, grad/param norm = 1.8352e-01, time/batch = 0.6834s	
24127/30300 (epoch 39.814), train_loss = 1.04165596, grad/param norm = 1.7350e-01, time/batch = 0.6814s	
24128/30300 (epoch 39.815), train_loss = 1.03023093, grad/param norm = 1.9299e-01, time/batch = 0.6862s	
24129/30300 (epoch 39.817), train_loss = 1.11324632, grad/param norm = 2.0136e-01, time/batch = 0.6835s	
24130/30300 (epoch 39.818), train_loss = 1.04729414, grad/param norm = 1.7097e-01, time/batch = 0.6829s	
24131/30300 (epoch 39.820), train_loss = 1.19797286, grad/param norm = 2.0142e-01, time/batch = 0.6872s	
24132/30300 (epoch 39.822), train_loss = 1.17659099, grad/param norm = 1.9932e-01, time/batch = 0.6915s	
24133/30300 (epoch 39.823), train_loss = 1.16449886, grad/param norm = 1.8964e-01, time/batch = 0.6893s	
24134/30300 (epoch 39.825), train_loss = 1.14664018, grad/param norm = 1.8070e-01, time/batch = 0.6829s	
24135/30300 (epoch 39.827), train_loss = 0.88595261, grad/param norm = 1.9147e-01, time/batch = 0.6828s	
24136/30300 (epoch 39.828), train_loss = 1.10256347, grad/param norm = 1.7820e-01, time/batch = 0.6843s	
24137/30300 (epoch 39.830), train_loss = 1.07349934, grad/param norm = 1.8197e-01, time/batch = 0.6811s	
24138/30300 (epoch 39.832), train_loss = 0.96258632, grad/param norm = 1.7608e-01, time/batch = 0.6894s	
24139/30300 (epoch 39.833), train_loss = 1.04270715, grad/param norm = 1.7546e-01, time/batch = 0.7081s	
24140/30300 (epoch 39.835), train_loss = 0.95990741, grad/param norm = 1.7414e-01, time/batch = 0.7094s	
24141/30300 (epoch 39.837), train_loss = 0.93677193, grad/param norm = 1.8586e-01, time/batch = 0.7127s	
24142/30300 (epoch 39.838), train_loss = 0.93166236, grad/param norm = 1.5329e-01, time/batch = 0.7117s	
24143/30300 (epoch 39.840), train_loss = 1.11307030, grad/param norm = 1.5836e-01, time/batch = 0.6874s	
24144/30300 (epoch 39.842), train_loss = 0.99526814, grad/param norm = 1.5029e-01, time/batch = 0.6964s	
24145/30300 (epoch 39.843), train_loss = 1.05591225, grad/param norm = 1.8688e-01, time/batch = 0.6957s	
24146/30300 (epoch 39.845), train_loss = 1.06169361, grad/param norm = 1.5764e-01, time/batch = 0.6915s	
24147/30300 (epoch 39.847), train_loss = 1.02764549, grad/param norm = 1.6973e-01, time/batch = 0.6925s	
24148/30300 (epoch 39.848), train_loss = 1.06573556, grad/param norm = 1.8512e-01, time/batch = 0.6918s	
24149/30300 (epoch 39.850), train_loss = 1.00896357, grad/param norm = 1.6009e-01, time/batch = 0.6829s	
24150/30300 (epoch 39.851), train_loss = 1.05781689, grad/param norm = 1.8380e-01, time/batch = 0.6855s	
24151/30300 (epoch 39.853), train_loss = 0.98171364, grad/param norm = 1.5835e-01, time/batch = 0.6836s	
24152/30300 (epoch 39.855), train_loss = 0.97620900, grad/param norm = 1.5398e-01, time/batch = 0.6900s	
24153/30300 (epoch 39.856), train_loss = 1.03148441, grad/param norm = 1.6545e-01, time/batch = 0.6862s	
24154/30300 (epoch 39.858), train_loss = 0.94458093, grad/param norm = 1.6322e-01, time/batch = 0.6861s	
24155/30300 (epoch 39.860), train_loss = 0.92685840, grad/param norm = 1.5925e-01, time/batch = 0.6822s	
24156/30300 (epoch 39.861), train_loss = 1.15905949, grad/param norm = 1.7108e-01, time/batch = 0.6815s	
24157/30300 (epoch 39.863), train_loss = 0.99188103, grad/param norm = 1.7080e-01, time/batch = 0.6850s	
24158/30300 (epoch 39.865), train_loss = 1.08145062, grad/param norm = 1.8178e-01, time/batch = 0.6868s	
24159/30300 (epoch 39.866), train_loss = 1.09649452, grad/param norm = 1.7780e-01, time/batch = 0.6865s	
24160/30300 (epoch 39.868), train_loss = 1.04510800, grad/param norm = 1.6529e-01, time/batch = 0.6827s	
24161/30300 (epoch 39.870), train_loss = 0.96447547, grad/param norm = 1.8187e-01, time/batch = 0.6853s	
24162/30300 (epoch 39.871), train_loss = 1.02528753, grad/param norm = 1.6797e-01, time/batch = 0.6874s	
24163/30300 (epoch 39.873), train_loss = 1.02545388, grad/param norm = 1.5471e-01, time/batch = 0.6823s	
24164/30300 (epoch 39.875), train_loss = 0.99061100, grad/param norm = 1.5397e-01, time/batch = 0.6809s	
24165/30300 (epoch 39.876), train_loss = 0.91443423, grad/param norm = 1.7240e-01, time/batch = 0.6815s	
24166/30300 (epoch 39.878), train_loss = 0.86273237, grad/param norm = 1.6249e-01, time/batch = 0.6826s	
24167/30300 (epoch 39.880), train_loss = 0.94187989, grad/param norm = 1.6771e-01, time/batch = 0.6830s	
24168/30300 (epoch 39.881), train_loss = 1.18228854, grad/param norm = 2.1055e-01, time/batch = 0.6822s	
24169/30300 (epoch 39.883), train_loss = 1.08447359, grad/param norm = 1.8215e-01, time/batch = 0.6784s	
24170/30300 (epoch 39.884), train_loss = 1.01082621, grad/param norm = 1.5722e-01, time/batch = 0.6795s	
24171/30300 (epoch 39.886), train_loss = 1.06597104, grad/param norm = 1.7232e-01, time/batch = 0.6844s	
24172/30300 (epoch 39.888), train_loss = 0.98873992, grad/param norm = 1.7849e-01, time/batch = 0.6818s	
24173/30300 (epoch 39.889), train_loss = 1.03401120, grad/param norm = 1.6555e-01, time/batch = 0.6827s	
24174/30300 (epoch 39.891), train_loss = 0.99897608, grad/param norm = 1.7364e-01, time/batch = 0.6841s	
24175/30300 (epoch 39.893), train_loss = 1.22704295, grad/param norm = 1.7566e-01, time/batch = 0.6833s	
24176/30300 (epoch 39.894), train_loss = 1.05269333, grad/param norm = 1.6281e-01, time/batch = 0.6804s	
24177/30300 (epoch 39.896), train_loss = 0.88275366, grad/param norm = 1.8709e-01, time/batch = 0.6814s	
24178/30300 (epoch 39.898), train_loss = 0.88193358, grad/param norm = 1.5613e-01, time/batch = 0.6820s	
24179/30300 (epoch 39.899), train_loss = 0.91775382, grad/param norm = 1.6874e-01, time/batch = 0.6788s	
24180/30300 (epoch 39.901), train_loss = 1.02075338, grad/param norm = 1.8434e-01, time/batch = 0.6805s	
24181/30300 (epoch 39.903), train_loss = 0.98882619, grad/param norm = 1.9011e-01, time/batch = 0.6867s	
24182/30300 (epoch 39.904), train_loss = 1.03681529, grad/param norm = 1.5939e-01, time/batch = 0.6841s	
24183/30300 (epoch 39.906), train_loss = 1.03154689, grad/param norm = 1.8054e-01, time/batch = 0.6838s	
24184/30300 (epoch 39.908), train_loss = 0.96274550, grad/param norm = 1.5405e-01, time/batch = 0.6801s	
24185/30300 (epoch 39.909), train_loss = 0.98088950, grad/param norm = 2.4438e-01, time/batch = 0.6807s	
24186/30300 (epoch 39.911), train_loss = 1.00991621, grad/param norm = 1.6128e-01, time/batch = 0.6814s	
24187/30300 (epoch 39.913), train_loss = 1.02160248, grad/param norm = 1.7355e-01, time/batch = 0.6799s	
24188/30300 (epoch 39.914), train_loss = 0.98419744, grad/param norm = 1.8869e-01, time/batch = 0.6837s	
24189/30300 (epoch 39.916), train_loss = 1.04230974, grad/param norm = 1.5483e-01, time/batch = 0.6822s	
24190/30300 (epoch 39.917), train_loss = 0.97010891, grad/param norm = 1.6156e-01, time/batch = 0.6829s	
24191/30300 (epoch 39.919), train_loss = 0.90908518, grad/param norm = 1.7332e-01, time/batch = 0.6823s	
24192/30300 (epoch 39.921), train_loss = 0.97847090, grad/param norm = 1.5059e-01, time/batch = 0.6818s	
24193/30300 (epoch 39.922), train_loss = 1.10648675, grad/param norm = 1.7117e-01, time/batch = 0.6835s	
24194/30300 (epoch 39.924), train_loss = 1.01638810, grad/param norm = 1.8474e-01, time/batch = 0.6823s	
24195/30300 (epoch 39.926), train_loss = 1.06014218, grad/param norm = 1.8921e-01, time/batch = 0.6812s	
24196/30300 (epoch 39.927), train_loss = 1.03513547, grad/param norm = 1.6254e-01, time/batch = 0.6830s	
24197/30300 (epoch 39.929), train_loss = 0.96312222, grad/param norm = 1.8225e-01, time/batch = 0.6829s	
24198/30300 (epoch 39.931), train_loss = 1.09288684, grad/param norm = 2.0432e-01, time/batch = 0.6812s	
24199/30300 (epoch 39.932), train_loss = 0.92657508, grad/param norm = 1.6473e-01, time/batch = 0.6792s	
24200/30300 (epoch 39.934), train_loss = 1.04779029, grad/param norm = 1.6822e-01, time/batch = 0.6797s	
24201/30300 (epoch 39.936), train_loss = 0.95375845, grad/param norm = 1.6345e-01, time/batch = 0.6946s	
24202/30300 (epoch 39.937), train_loss = 0.96477412, grad/param norm = 1.6965e-01, time/batch = 0.6827s	
24203/30300 (epoch 39.939), train_loss = 1.10675394, grad/param norm = 1.7915e-01, time/batch = 0.7065s	
24204/30300 (epoch 39.941), train_loss = 0.99347503, grad/param norm = 1.6737e-01, time/batch = 0.7217s	
24205/30300 (epoch 39.942), train_loss = 1.01341783, grad/param norm = 1.9723e-01, time/batch = 0.7272s	
24206/30300 (epoch 39.944), train_loss = 0.91290036, grad/param norm = 1.8712e-01, time/batch = 0.6977s	
24207/30300 (epoch 39.946), train_loss = 1.08530238, grad/param norm = 2.4256e-01, time/batch = 0.6862s	
24208/30300 (epoch 39.947), train_loss = 1.07089323, grad/param norm = 2.2947e-01, time/batch = 0.6855s	
24209/30300 (epoch 39.949), train_loss = 1.10102313, grad/param norm = 2.4791e-01, time/batch = 0.6865s	
24210/30300 (epoch 39.950), train_loss = 1.12235951, grad/param norm = 1.8663e-01, time/batch = 0.6855s	
24211/30300 (epoch 39.952), train_loss = 1.06126299, grad/param norm = 1.9984e-01, time/batch = 0.6900s	
24212/30300 (epoch 39.954), train_loss = 1.27274591, grad/param norm = 2.2304e-01, time/batch = 0.6890s	
24213/30300 (epoch 39.955), train_loss = 1.02560329, grad/param norm = 1.7961e-01, time/batch = 0.6836s	
24214/30300 (epoch 39.957), train_loss = 1.08829464, grad/param norm = 1.8860e-01, time/batch = 0.6839s	
24215/30300 (epoch 39.959), train_loss = 0.94531485, grad/param norm = 1.9340e-01, time/batch = 0.7175s	
24216/30300 (epoch 39.960), train_loss = 0.96870938, grad/param norm = 1.7164e-01, time/batch = 0.6959s	
24217/30300 (epoch 39.962), train_loss = 0.95727635, grad/param norm = 1.9398e-01, time/batch = 0.6965s	
24218/30300 (epoch 39.964), train_loss = 0.92474174, grad/param norm = 1.8465e-01, time/batch = 0.6859s	
24219/30300 (epoch 39.965), train_loss = 0.96486108, grad/param norm = 2.1426e-01, time/batch = 0.6849s	
24220/30300 (epoch 39.967), train_loss = 0.99647008, grad/param norm = 2.1891e-01, time/batch = 0.6830s	
24221/30300 (epoch 39.969), train_loss = 0.93935319, grad/param norm = 1.8751e-01, time/batch = 0.6846s	
24222/30300 (epoch 39.970), train_loss = 0.98595420, grad/param norm = 1.7149e-01, time/batch = 0.6817s	
24223/30300 (epoch 39.972), train_loss = 0.90791256, grad/param norm = 1.6282e-01, time/batch = 0.6832s	
24224/30300 (epoch 39.974), train_loss = 1.14969153, grad/param norm = 1.8373e-01, time/batch = 0.6817s	
24225/30300 (epoch 39.975), train_loss = 1.15918652, grad/param norm = 2.2948e-01, time/batch = 0.6909s	
24226/30300 (epoch 39.977), train_loss = 1.21233388, grad/param norm = 1.8860e-01, time/batch = 0.6832s	
24227/30300 (epoch 39.979), train_loss = 1.09588853, grad/param norm = 2.0019e-01, time/batch = 0.6856s	
24228/30300 (epoch 39.980), train_loss = 1.14173187, grad/param norm = 2.1092e-01, time/batch = 0.6792s	
24229/30300 (epoch 39.982), train_loss = 1.11037263, grad/param norm = 1.8236e-01, time/batch = 0.6819s	
24230/30300 (epoch 39.983), train_loss = 1.13111556, grad/param norm = 1.6799e-01, time/batch = 0.6832s	
24231/30300 (epoch 39.985), train_loss = 1.07954013, grad/param norm = 2.2449e-01, time/batch = 0.6845s	
24232/30300 (epoch 39.987), train_loss = 1.04451100, grad/param norm = 1.7469e-01, time/batch = 0.6845s	
24233/30300 (epoch 39.988), train_loss = 1.14910491, grad/param norm = 2.0546e-01, time/batch = 0.6830s	
24234/30300 (epoch 39.990), train_loss = 0.94195205, grad/param norm = 1.7804e-01, time/batch = 0.6862s	
24235/30300 (epoch 39.992), train_loss = 1.11024210, grad/param norm = 1.5734e-01, time/batch = 0.6862s	
24236/30300 (epoch 39.993), train_loss = 1.10435592, grad/param norm = 1.9865e-01, time/batch = 0.6896s	
24237/30300 (epoch 39.995), train_loss = 1.03907577, grad/param norm = 2.1468e-01, time/batch = 0.6870s	
24238/30300 (epoch 39.997), train_loss = 1.08263514, grad/param norm = 2.0881e-01, time/batch = 0.6838s	
24239/30300 (epoch 39.998), train_loss = 1.09968824, grad/param norm = 2.0821e-01, time/batch = 0.6868s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
24240/30300 (epoch 40.000), train_loss = 0.97066963, grad/param norm = 1.9690e-01, time/batch = 0.6906s	
24241/30300 (epoch 40.002), train_loss = 1.14103093, grad/param norm = 2.0614e-01, time/batch = 0.6841s	
24242/30300 (epoch 40.003), train_loss = 1.06219933, grad/param norm = 1.8691e-01, time/batch = 0.6829s	
24243/30300 (epoch 40.005), train_loss = 1.00176707, grad/param norm = 1.7581e-01, time/batch = 0.6835s	
24244/30300 (epoch 40.007), train_loss = 1.08439815, grad/param norm = 1.9976e-01, time/batch = 0.6804s	
24245/30300 (epoch 40.008), train_loss = 1.02997423, grad/param norm = 1.8956e-01, time/batch = 0.6839s	
24246/30300 (epoch 40.010), train_loss = 0.90818453, grad/param norm = 1.8090e-01, time/batch = 0.6828s	
24247/30300 (epoch 40.012), train_loss = 0.98405914, grad/param norm = 1.7091e-01, time/batch = 0.6841s	
24248/30300 (epoch 40.013), train_loss = 1.11948589, grad/param norm = 1.8912e-01, time/batch = 0.6846s	
24249/30300 (epoch 40.015), train_loss = 0.97542993, grad/param norm = 1.6112e-01, time/batch = 0.6848s	
24250/30300 (epoch 40.017), train_loss = 0.99872234, grad/param norm = 1.5018e-01, time/batch = 0.6818s	
24251/30300 (epoch 40.018), train_loss = 0.92327086, grad/param norm = 1.6531e-01, time/batch = 0.6853s	
24252/30300 (epoch 40.020), train_loss = 1.11532969, grad/param norm = 1.8542e-01, time/batch = 0.6837s	
24253/30300 (epoch 40.021), train_loss = 1.13717932, grad/param norm = 1.7755e-01, time/batch = 0.6840s	
24254/30300 (epoch 40.023), train_loss = 1.02564954, grad/param norm = 1.5295e-01, time/batch = 0.6852s	
24255/30300 (epoch 40.025), train_loss = 0.95463235, grad/param norm = 1.8446e-01, time/batch = 0.6899s	
24256/30300 (epoch 40.026), train_loss = 1.08172477, grad/param norm = 2.1011e-01, time/batch = 0.6931s	
24257/30300 (epoch 40.028), train_loss = 1.10746570, grad/param norm = 1.9658e-01, time/batch = 0.6881s	
24258/30300 (epoch 40.030), train_loss = 0.98602548, grad/param norm = 1.7921e-01, time/batch = 0.6844s	
24259/30300 (epoch 40.031), train_loss = 1.05322289, grad/param norm = 1.6429e-01, time/batch = 0.6831s	
24260/30300 (epoch 40.033), train_loss = 1.04861562, grad/param norm = 1.8465e-01, time/batch = 0.6832s	
24261/30300 (epoch 40.035), train_loss = 1.08671550, grad/param norm = 2.1290e-01, time/batch = 0.6847s	
24262/30300 (epoch 40.036), train_loss = 1.05314014, grad/param norm = 1.9265e-01, time/batch = 0.6849s	
24263/30300 (epoch 40.038), train_loss = 1.08459819, grad/param norm = 1.5963e-01, time/batch = 0.6830s	
24264/30300 (epoch 40.040), train_loss = 0.88359771, grad/param norm = 1.6165e-01, time/batch = 0.6844s	
24265/30300 (epoch 40.041), train_loss = 0.87856280, grad/param norm = 1.8835e-01, time/batch = 0.6853s	
24266/30300 (epoch 40.043), train_loss = 1.04949842, grad/param norm = 1.7760e-01, time/batch = 0.6867s	
24267/30300 (epoch 40.045), train_loss = 0.96257025, grad/param norm = 1.6028e-01, time/batch = 0.6869s	
24268/30300 (epoch 40.046), train_loss = 1.15833647, grad/param norm = 2.0688e-01, time/batch = 0.6831s	
24269/30300 (epoch 40.048), train_loss = 1.03757741, grad/param norm = 2.0825e-01, time/batch = 0.6848s	
24270/30300 (epoch 40.050), train_loss = 0.94279474, grad/param norm = 1.6607e-01, time/batch = 0.6946s	
24271/30300 (epoch 40.051), train_loss = 1.06762079, grad/param norm = 1.9940e-01, time/batch = 0.6936s	
24272/30300 (epoch 40.053), train_loss = 0.90830527, grad/param norm = 2.3092e-01, time/batch = 0.6863s	
24273/30300 (epoch 40.054), train_loss = 1.07825630, grad/param norm = 1.7556e-01, time/batch = 0.6849s	
24274/30300 (epoch 40.056), train_loss = 0.94172749, grad/param norm = 1.5661e-01, time/batch = 0.6826s	
24275/30300 (epoch 40.058), train_loss = 0.98771046, grad/param norm = 1.6947e-01, time/batch = 0.6818s	
24276/30300 (epoch 40.059), train_loss = 0.98613083, grad/param norm = 1.8998e-01, time/batch = 0.6841s	
24277/30300 (epoch 40.061), train_loss = 1.08082741, grad/param norm = 1.8752e-01, time/batch = 0.6841s	
24278/30300 (epoch 40.063), train_loss = 0.92115254, grad/param norm = 1.8217e-01, time/batch = 0.6863s	
24279/30300 (epoch 40.064), train_loss = 1.01504997, grad/param norm = 1.8266e-01, time/batch = 0.6851s	
24280/30300 (epoch 40.066), train_loss = 1.02009633, grad/param norm = 2.6269e-01, time/batch = 0.6837s	
24281/30300 (epoch 40.068), train_loss = 0.94497091, grad/param norm = 1.6004e-01, time/batch = 0.6827s	
24282/30300 (epoch 40.069), train_loss = 1.07484872, grad/param norm = 1.7606e-01, time/batch = 0.6813s	
24283/30300 (epoch 40.071), train_loss = 1.06435474, grad/param norm = 1.7103e-01, time/batch = 0.6820s	
24284/30300 (epoch 40.073), train_loss = 0.94495853, grad/param norm = 1.8474e-01, time/batch = 0.6820s	
24285/30300 (epoch 40.074), train_loss = 0.98930464, grad/param norm = 1.6875e-01, time/batch = 0.6819s	
24286/30300 (epoch 40.076), train_loss = 1.00428726, grad/param norm = 1.7391e-01, time/batch = 0.6811s	
24287/30300 (epoch 40.078), train_loss = 0.95288069, grad/param norm = 1.6280e-01, time/batch = 0.6812s	
24288/30300 (epoch 40.079), train_loss = 0.97564800, grad/param norm = 1.6276e-01, time/batch = 0.6910s	
24289/30300 (epoch 40.081), train_loss = 1.02382239, grad/param norm = 1.7697e-01, time/batch = 0.6831s	
24290/30300 (epoch 40.083), train_loss = 1.08883937, grad/param norm = 2.1204e-01, time/batch = 0.7016s	
24291/30300 (epoch 40.084), train_loss = 0.96213314, grad/param norm = 1.6430e-01, time/batch = 0.7132s	
24292/30300 (epoch 40.086), train_loss = 0.97386529, grad/param norm = 1.8463e-01, time/batch = 0.6882s	
24293/30300 (epoch 40.087), train_loss = 0.94685950, grad/param norm = 1.7615e-01, time/batch = 0.6862s	
24294/30300 (epoch 40.089), train_loss = 0.94043390, grad/param norm = 1.6261e-01, time/batch = 0.6821s	
24295/30300 (epoch 40.091), train_loss = 1.06399224, grad/param norm = 1.8024e-01, time/batch = 0.6820s	
24296/30300 (epoch 40.092), train_loss = 1.09006298, grad/param norm = 1.6475e-01, time/batch = 0.6831s	
24297/30300 (epoch 40.094), train_loss = 1.14412889, grad/param norm = 2.0505e-01, time/batch = 0.6837s	
24298/30300 (epoch 40.096), train_loss = 1.13172667, grad/param norm = 1.8452e-01, time/batch = 0.6826s	
24299/30300 (epoch 40.097), train_loss = 0.96739751, grad/param norm = 1.8188e-01, time/batch = 0.6875s	
24300/30300 (epoch 40.099), train_loss = 1.08792932, grad/param norm = 1.7886e-01, time/batch = 0.6845s	
24301/30300 (epoch 40.101), train_loss = 1.11752547, grad/param norm = 1.8999e-01, time/batch = 0.7123s	
24302/30300 (epoch 40.102), train_loss = 0.95075326, grad/param norm = 1.7896e-01, time/batch = 0.6960s	
24303/30300 (epoch 40.104), train_loss = 0.99653479, grad/param norm = 2.4030e-01, time/batch = 0.6834s	
24304/30300 (epoch 40.106), train_loss = 0.95935439, grad/param norm = 1.8190e-01, time/batch = 0.6940s	
24305/30300 (epoch 40.107), train_loss = 1.05951437, grad/param norm = 1.6992e-01, time/batch = 0.6983s	
24306/30300 (epoch 40.109), train_loss = 1.10442942, grad/param norm = 2.3482e-01, time/batch = 0.6852s	
24307/30300 (epoch 40.111), train_loss = 1.06929496, grad/param norm = 1.8927e-01, time/batch = 0.6832s	
24308/30300 (epoch 40.112), train_loss = 1.15500537, grad/param norm = 1.8828e-01, time/batch = 0.6835s	
24309/30300 (epoch 40.114), train_loss = 0.99633919, grad/param norm = 1.7018e-01, time/batch = 0.6824s	
24310/30300 (epoch 40.116), train_loss = 1.05443998, grad/param norm = 2.0590e-01, time/batch = 0.6837s	
24311/30300 (epoch 40.117), train_loss = 1.13726341, grad/param norm = 1.8641e-01, time/batch = 0.6990s	
24312/30300 (epoch 40.119), train_loss = 0.92508950, grad/param norm = 2.0687e-01, time/batch = 0.6832s	
24313/30300 (epoch 40.120), train_loss = 1.01162204, grad/param norm = 1.8343e-01, time/batch = 0.6820s	
24314/30300 (epoch 40.122), train_loss = 1.11578475, grad/param norm = 1.9497e-01, time/batch = 0.6831s	
24315/30300 (epoch 40.124), train_loss = 1.18800083, grad/param norm = 2.0749e-01, time/batch = 0.6863s	
24316/30300 (epoch 40.125), train_loss = 0.93497422, grad/param norm = 1.6355e-01, time/batch = 0.6895s	
24317/30300 (epoch 40.127), train_loss = 1.05697497, grad/param norm = 2.0795e-01, time/batch = 0.6869s	
24318/30300 (epoch 40.129), train_loss = 1.10286853, grad/param norm = 1.8314e-01, time/batch = 0.6828s	
24319/30300 (epoch 40.130), train_loss = 1.16113383, grad/param norm = 1.8377e-01, time/batch = 0.6830s	
24320/30300 (epoch 40.132), train_loss = 1.15273402, grad/param norm = 1.8788e-01, time/batch = 0.6832s	
24321/30300 (epoch 40.134), train_loss = 0.96274170, grad/param norm = 1.9881e-01, time/batch = 0.6844s	
24322/30300 (epoch 40.135), train_loss = 0.98270142, grad/param norm = 2.0123e-01, time/batch = 0.6825s	
24323/30300 (epoch 40.137), train_loss = 1.02047818, grad/param norm = 1.9105e-01, time/batch = 0.6840s	
24324/30300 (epoch 40.139), train_loss = 0.96119838, grad/param norm = 2.0441e-01, time/batch = 0.6830s	
24325/30300 (epoch 40.140), train_loss = 1.03436041, grad/param norm = 2.3680e-01, time/batch = 0.6824s	
24326/30300 (epoch 40.142), train_loss = 1.09572475, grad/param norm = 2.1219e-01, time/batch = 0.6833s	
24327/30300 (epoch 40.144), train_loss = 0.96040507, grad/param norm = 2.5884e-01, time/batch = 0.6863s	
24328/30300 (epoch 40.145), train_loss = 1.08326942, grad/param norm = 2.0336e-01, time/batch = 0.6824s	
24329/30300 (epoch 40.147), train_loss = 1.01385985, grad/param norm = 3.1171e-01, time/batch = 0.6858s	
24330/30300 (epoch 40.149), train_loss = 1.15440462, grad/param norm = 2.3175e-01, time/batch = 0.6839s	
24331/30300 (epoch 40.150), train_loss = 1.03542623, grad/param norm = 2.2590e-01, time/batch = 0.6821s	
24332/30300 (epoch 40.152), train_loss = 0.93901208, grad/param norm = 2.1491e-01, time/batch = 0.6876s	
24333/30300 (epoch 40.153), train_loss = 1.06529682, grad/param norm = 1.9416e-01, time/batch = 0.6852s	
24334/30300 (epoch 40.155), train_loss = 0.90355882, grad/param norm = 1.6873e-01, time/batch = 0.6811s	
24335/30300 (epoch 40.157), train_loss = 0.96770482, grad/param norm = 1.8108e-01, time/batch = 0.6834s	
24336/30300 (epoch 40.158), train_loss = 1.06396485, grad/param norm = 2.4750e-01, time/batch = 0.6873s	
24337/30300 (epoch 40.160), train_loss = 0.94467179, grad/param norm = 1.8542e-01, time/batch = 0.6836s	
24338/30300 (epoch 40.162), train_loss = 1.02758535, grad/param norm = 1.8282e-01, time/batch = 0.6849s	
24339/30300 (epoch 40.163), train_loss = 1.01865940, grad/param norm = 1.9197e-01, time/batch = 0.6865s	
24340/30300 (epoch 40.165), train_loss = 1.15803810, grad/param norm = 1.8996e-01, time/batch = 0.6812s	
24341/30300 (epoch 40.167), train_loss = 1.03779069, grad/param norm = 1.8037e-01, time/batch = 0.6824s	
24342/30300 (epoch 40.168), train_loss = 1.07914959, grad/param norm = 1.8990e-01, time/batch = 0.6831s	
24343/30300 (epoch 40.170), train_loss = 1.05197354, grad/param norm = 2.0629e-01, time/batch = 0.6867s	
24344/30300 (epoch 40.172), train_loss = 1.02856450, grad/param norm = 2.1666e-01, time/batch = 0.6832s	
24345/30300 (epoch 40.173), train_loss = 1.01380997, grad/param norm = 2.6406e-01, time/batch = 0.6836s	
24346/30300 (epoch 40.175), train_loss = 1.03878443, grad/param norm = 1.8072e-01, time/batch = 0.6835s	
24347/30300 (epoch 40.177), train_loss = 1.08287773, grad/param norm = 1.8874e-01, time/batch = 0.6808s	
24348/30300 (epoch 40.178), train_loss = 0.85543823, grad/param norm = 1.5713e-01, time/batch = 0.6869s	
24349/30300 (epoch 40.180), train_loss = 0.99716994, grad/param norm = 1.5804e-01, time/batch = 0.6845s	
24350/30300 (epoch 40.182), train_loss = 1.03657036, grad/param norm = 1.8384e-01, time/batch = 0.6812s	
24351/30300 (epoch 40.183), train_loss = 0.95904539, grad/param norm = 1.7014e-01, time/batch = 0.6855s	
24352/30300 (epoch 40.185), train_loss = 1.16366030, grad/param norm = 2.1708e-01, time/batch = 0.6841s	
24353/30300 (epoch 40.186), train_loss = 1.22902998, grad/param norm = 2.1146e-01, time/batch = 0.6837s	
24354/30300 (epoch 40.188), train_loss = 1.07123263, grad/param norm = 1.9088e-01, time/batch = 0.6879s	
24355/30300 (epoch 40.190), train_loss = 1.02095886, grad/param norm = 1.6154e-01, time/batch = 0.6835s	
24356/30300 (epoch 40.191), train_loss = 1.07942531, grad/param norm = 1.9167e-01, time/batch = 0.6876s	
24357/30300 (epoch 40.193), train_loss = 0.93868971, grad/param norm = 1.7111e-01, time/batch = 0.6867s	
24358/30300 (epoch 40.195), train_loss = 0.98258897, grad/param norm = 1.8263e-01, time/batch = 0.6843s	
24359/30300 (epoch 40.196), train_loss = 1.06174113, grad/param norm = 1.6022e-01, time/batch = 0.6838s	
24360/30300 (epoch 40.198), train_loss = 0.88828190, grad/param norm = 2.2400e-01, time/batch = 0.6858s	
24361/30300 (epoch 40.200), train_loss = 0.99588153, grad/param norm = 1.7369e-01, time/batch = 0.6864s	
24362/30300 (epoch 40.201), train_loss = 1.12086663, grad/param norm = 2.4754e-01, time/batch = 0.6846s	
24363/30300 (epoch 40.203), train_loss = 1.02305214, grad/param norm = 1.9122e-01, time/batch = 0.6847s	
24364/30300 (epoch 40.205), train_loss = 1.21470588, grad/param norm = 2.4923e-01, time/batch = 0.6858s	
24365/30300 (epoch 40.206), train_loss = 1.09460010, grad/param norm = 1.8839e-01, time/batch = 0.6827s	
24366/30300 (epoch 40.208), train_loss = 1.11563583, grad/param norm = 2.8244e-01, time/batch = 0.6826s	
24367/30300 (epoch 40.210), train_loss = 1.12047917, grad/param norm = 1.7886e-01, time/batch = 0.6842s	
24368/30300 (epoch 40.211), train_loss = 1.15797449, grad/param norm = 1.9141e-01, time/batch = 0.6839s	
24369/30300 (epoch 40.213), train_loss = 1.03289254, grad/param norm = 1.5502e-01, time/batch = 0.6828s	
24370/30300 (epoch 40.215), train_loss = 0.95208056, grad/param norm = 1.8122e-01, time/batch = 0.6812s	
24371/30300 (epoch 40.216), train_loss = 0.97225678, grad/param norm = 1.7285e-01, time/batch = 0.6836s	
24372/30300 (epoch 40.218), train_loss = 0.94007589, grad/param norm = 1.8646e-01, time/batch = 0.6841s	
24373/30300 (epoch 40.219), train_loss = 0.88982499, grad/param norm = 1.6524e-01, time/batch = 0.6903s	
24374/30300 (epoch 40.221), train_loss = 0.87995597, grad/param norm = 1.5160e-01, time/batch = 0.6842s	
24375/30300 (epoch 40.223), train_loss = 1.02028535, grad/param norm = 1.6719e-01, time/batch = 0.6955s	
24376/30300 (epoch 40.224), train_loss = 0.87108151, grad/param norm = 1.8538e-01, time/batch = 0.6855s	
24377/30300 (epoch 40.226), train_loss = 1.06904235, grad/param norm = 2.5574e-01, time/batch = 0.7015s	
24378/30300 (epoch 40.228), train_loss = 1.14083102, grad/param norm = 1.9828e-01, time/batch = 0.7154s	
24379/30300 (epoch 40.229), train_loss = 1.01965480, grad/param norm = 1.8782e-01, time/batch = 0.6930s	
24380/30300 (epoch 40.231), train_loss = 1.08852120, grad/param norm = 1.7615e-01, time/batch = 0.6965s	
24381/30300 (epoch 40.233), train_loss = 1.07578399, grad/param norm = 1.5333e-01, time/batch = 0.6839s	
24382/30300 (epoch 40.234), train_loss = 1.10797631, grad/param norm = 2.2705e-01, time/batch = 0.6816s	
24383/30300 (epoch 40.236), train_loss = 1.06676741, grad/param norm = 1.6389e-01, time/batch = 0.6822s	
24384/30300 (epoch 40.238), train_loss = 1.02322264, grad/param norm = 2.3962e-01, time/batch = 0.6820s	
24385/30300 (epoch 40.239), train_loss = 1.00208360, grad/param norm = 2.2495e-01, time/batch = 0.6914s	
24386/30300 (epoch 40.241), train_loss = 1.07823766, grad/param norm = 1.8640e-01, time/batch = 0.7001s	
24387/30300 (epoch 40.243), train_loss = 1.07066746, grad/param norm = 2.0520e-01, time/batch = 0.7144s	
24388/30300 (epoch 40.244), train_loss = 1.23376767, grad/param norm = 1.9795e-01, time/batch = 0.7139s	
24389/30300 (epoch 40.246), train_loss = 1.05634703, grad/param norm = 1.8250e-01, time/batch = 0.7097s	
24390/30300 (epoch 40.248), train_loss = 1.01479918, grad/param norm = 1.7710e-01, time/batch = 0.7028s	
24391/30300 (epoch 40.249), train_loss = 0.94737686, grad/param norm = 1.9804e-01, time/batch = 0.7022s	
24392/30300 (epoch 40.251), train_loss = 0.96113561, grad/param norm = 1.7550e-01, time/batch = 0.7061s	
24393/30300 (epoch 40.252), train_loss = 1.11758881, grad/param norm = 1.8590e-01, time/batch = 0.6992s	
24394/30300 (epoch 40.254), train_loss = 1.11646250, grad/param norm = 2.0470e-01, time/batch = 0.6912s	
24395/30300 (epoch 40.256), train_loss = 1.07403170, grad/param norm = 1.7762e-01, time/batch = 0.6869s	
24396/30300 (epoch 40.257), train_loss = 1.09939418, grad/param norm = 1.9354e-01, time/batch = 0.6839s	
24397/30300 (epoch 40.259), train_loss = 1.01511071, grad/param norm = 1.7688e-01, time/batch = 0.6836s	
24398/30300 (epoch 40.261), train_loss = 1.17330035, grad/param norm = 1.8368e-01, time/batch = 0.6830s	
24399/30300 (epoch 40.262), train_loss = 0.96006374, grad/param norm = 1.6555e-01, time/batch = 0.6840s	
24400/30300 (epoch 40.264), train_loss = 1.02391448, grad/param norm = 1.6624e-01, time/batch = 0.6827s	
24401/30300 (epoch 40.266), train_loss = 1.02197629, grad/param norm = 1.5827e-01, time/batch = 0.6868s	
24402/30300 (epoch 40.267), train_loss = 1.18219102, grad/param norm = 2.0089e-01, time/batch = 0.6842s	
24403/30300 (epoch 40.269), train_loss = 1.04787183, grad/param norm = 1.7535e-01, time/batch = 0.6917s	
24404/30300 (epoch 40.271), train_loss = 1.05067798, grad/param norm = 1.7619e-01, time/batch = 0.6918s	
24405/30300 (epoch 40.272), train_loss = 1.05031467, grad/param norm = 2.1075e-01, time/batch = 0.6870s	
24406/30300 (epoch 40.274), train_loss = 1.10669558, grad/param norm = 2.0705e-01, time/batch = 0.6807s	
24407/30300 (epoch 40.276), train_loss = 1.06886621, grad/param norm = 2.0715e-01, time/batch = 0.6848s	
24408/30300 (epoch 40.277), train_loss = 0.93623478, grad/param norm = 2.2735e-01, time/batch = 0.6855s	
24409/30300 (epoch 40.279), train_loss = 1.03339978, grad/param norm = 1.8715e-01, time/batch = 0.6820s	
24410/30300 (epoch 40.281), train_loss = 1.11024577, grad/param norm = 1.8989e-01, time/batch = 0.6822s	
24411/30300 (epoch 40.282), train_loss = 1.06908895, grad/param norm = 1.6603e-01, time/batch = 0.6885s	
24412/30300 (epoch 40.284), train_loss = 1.10995155, grad/param norm = 2.3520e-01, time/batch = 0.6857s	
24413/30300 (epoch 40.285), train_loss = 1.08581300, grad/param norm = 1.6838e-01, time/batch = 0.6836s	
24414/30300 (epoch 40.287), train_loss = 1.04312779, grad/param norm = 2.0739e-01, time/batch = 0.6835s	
24415/30300 (epoch 40.289), train_loss = 1.12108906, grad/param norm = 1.9019e-01, time/batch = 0.6884s	
24416/30300 (epoch 40.290), train_loss = 0.82930427, grad/param norm = 1.6120e-01, time/batch = 0.6871s	
24417/30300 (epoch 40.292), train_loss = 0.93821792, grad/param norm = 1.9226e-01, time/batch = 0.6836s	
24418/30300 (epoch 40.294), train_loss = 1.10531247, grad/param norm = 2.1420e-01, time/batch = 0.6841s	
24419/30300 (epoch 40.295), train_loss = 0.98535446, grad/param norm = 1.7473e-01, time/batch = 0.6870s	
24420/30300 (epoch 40.297), train_loss = 1.00837588, grad/param norm = 1.6051e-01, time/batch = 0.6856s	
24421/30300 (epoch 40.299), train_loss = 1.01895287, grad/param norm = 1.7940e-01, time/batch = 0.6897s	
24422/30300 (epoch 40.300), train_loss = 0.95923356, grad/param norm = 1.8790e-01, time/batch = 0.6881s	
24423/30300 (epoch 40.302), train_loss = 1.11233712, grad/param norm = 1.8733e-01, time/batch = 0.6839s	
24424/30300 (epoch 40.304), train_loss = 0.96273579, grad/param norm = 1.7454e-01, time/batch = 0.6852s	
24425/30300 (epoch 40.305), train_loss = 1.02644775, grad/param norm = 1.6969e-01, time/batch = 0.6873s	
24426/30300 (epoch 40.307), train_loss = 1.13472570, grad/param norm = 1.6793e-01, time/batch = 0.6904s	
24427/30300 (epoch 40.309), train_loss = 1.07241447, grad/param norm = 1.8518e-01, time/batch = 0.6896s	
24428/30300 (epoch 40.310), train_loss = 1.02458317, grad/param norm = 1.6835e-01, time/batch = 0.6848s	
24429/30300 (epoch 40.312), train_loss = 1.15497379, grad/param norm = 1.6595e-01, time/batch = 0.6963s	
24430/30300 (epoch 40.314), train_loss = 1.03180434, grad/param norm = 1.6827e-01, time/batch = 0.6841s	
24431/30300 (epoch 40.315), train_loss = 0.99090957, grad/param norm = 1.8577e-01, time/batch = 0.6871s	
24432/30300 (epoch 40.317), train_loss = 1.06517373, grad/param norm = 1.7831e-01, time/batch = 0.6976s	
24433/30300 (epoch 40.318), train_loss = 1.09034448, grad/param norm = 1.8523e-01, time/batch = 0.6951s	
24434/30300 (epoch 40.320), train_loss = 1.07629146, grad/param norm = 1.9771e-01, time/batch = 0.6912s	
24435/30300 (epoch 40.322), train_loss = 0.97651628, grad/param norm = 1.6527e-01, time/batch = 0.6883s	
24436/30300 (epoch 40.323), train_loss = 1.13933788, grad/param norm = 1.9356e-01, time/batch = 0.6851s	
24437/30300 (epoch 40.325), train_loss = 1.01524999, grad/param norm = 1.6828e-01, time/batch = 0.6823s	
24438/30300 (epoch 40.327), train_loss = 1.01348274, grad/param norm = 1.5580e-01, time/batch = 0.6850s	
24439/30300 (epoch 40.328), train_loss = 1.05657179, grad/param norm = 1.5636e-01, time/batch = 0.6853s	
24440/30300 (epoch 40.330), train_loss = 1.07603071, grad/param norm = 1.8924e-01, time/batch = 0.6817s	
24441/30300 (epoch 40.332), train_loss = 1.13024098, grad/param norm = 1.9940e-01, time/batch = 0.6886s	
24442/30300 (epoch 40.333), train_loss = 0.95056066, grad/param norm = 1.8116e-01, time/batch = 0.6872s	
24443/30300 (epoch 40.335), train_loss = 0.93350657, grad/param norm = 1.8721e-01, time/batch = 0.6851s	
24444/30300 (epoch 40.337), train_loss = 1.15030359, grad/param norm = 1.7336e-01, time/batch = 0.6828s	
24445/30300 (epoch 40.338), train_loss = 0.98720162, grad/param norm = 1.6584e-01, time/batch = 0.6834s	
24446/30300 (epoch 40.340), train_loss = 0.99558175, grad/param norm = 1.7244e-01, time/batch = 0.6829s	
24447/30300 (epoch 40.342), train_loss = 1.09655433, grad/param norm = 1.6591e-01, time/batch = 0.6848s	
24448/30300 (epoch 40.343), train_loss = 1.06052073, grad/param norm = 1.7375e-01, time/batch = 0.6847s	
24449/30300 (epoch 40.345), train_loss = 1.09291348, grad/param norm = 1.8211e-01, time/batch = 0.6889s	
24450/30300 (epoch 40.347), train_loss = 0.93455214, grad/param norm = 1.8541e-01, time/batch = 0.6848s	
24451/30300 (epoch 40.348), train_loss = 0.99283401, grad/param norm = 1.8718e-01, time/batch = 0.6891s	
24452/30300 (epoch 40.350), train_loss = 1.00281749, grad/param norm = 2.5019e-01, time/batch = 0.6861s	
24453/30300 (epoch 40.351), train_loss = 1.01865991, grad/param norm = 1.8103e-01, time/batch = 0.6842s	
24454/30300 (epoch 40.353), train_loss = 0.91213206, grad/param norm = 1.6278e-01, time/batch = 0.6848s	
24455/30300 (epoch 40.355), train_loss = 0.98133423, grad/param norm = 1.4674e-01, time/batch = 0.6849s	
24456/30300 (epoch 40.356), train_loss = 1.10149382, grad/param norm = 2.2043e-01, time/batch = 0.6853s	
24457/30300 (epoch 40.358), train_loss = 1.26592691, grad/param norm = 1.8007e-01, time/batch = 0.6849s	
24458/30300 (epoch 40.360), train_loss = 0.98566779, grad/param norm = 1.7217e-01, time/batch = 0.6878s	
24459/30300 (epoch 40.361), train_loss = 1.01870358, grad/param norm = 1.7131e-01, time/batch = 0.6825s	
24460/30300 (epoch 40.363), train_loss = 1.05228745, grad/param norm = 1.9869e-01, time/batch = 0.6827s	
24461/30300 (epoch 40.365), train_loss = 0.89553097, grad/param norm = 1.9397e-01, time/batch = 0.6856s	
24462/30300 (epoch 40.366), train_loss = 0.99756375, grad/param norm = 1.5697e-01, time/batch = 0.6951s	
24463/30300 (epoch 40.368), train_loss = 0.90544954, grad/param norm = 1.7898e-01, time/batch = 0.6917s	
24464/30300 (epoch 40.370), train_loss = 0.95672145, grad/param norm = 1.8321e-01, time/batch = 0.7076s	
24465/30300 (epoch 40.371), train_loss = 1.08661592, grad/param norm = 1.7365e-01, time/batch = 0.7320s	
24466/30300 (epoch 40.373), train_loss = 0.98412572, grad/param norm = 1.5309e-01, time/batch = 0.7074s	
24467/30300 (epoch 40.375), train_loss = 0.95702786, grad/param norm = 1.4634e-01, time/batch = 0.6954s	
24468/30300 (epoch 40.376), train_loss = 0.94522780, grad/param norm = 1.4265e-01, time/batch = 0.6850s	
24469/30300 (epoch 40.378), train_loss = 0.92930271, grad/param norm = 1.8890e-01, time/batch = 0.6963s	
24470/30300 (epoch 40.380), train_loss = 1.12723687, grad/param norm = 1.8263e-01, time/batch = 0.7079s	
24471/30300 (epoch 40.381), train_loss = 0.86544639, grad/param norm = 1.5845e-01, time/batch = 0.7266s	
24472/30300 (epoch 40.383), train_loss = 0.92382360, grad/param norm = 1.9399e-01, time/batch = 0.7219s	
24473/30300 (epoch 40.384), train_loss = 1.08431422, grad/param norm = 2.0166e-01, time/batch = 0.7164s	
24474/30300 (epoch 40.386), train_loss = 0.91590190, grad/param norm = 1.8044e-01, time/batch = 0.7071s	
24475/30300 (epoch 40.388), train_loss = 0.92016942, grad/param norm = 1.9376e-01, time/batch = 0.7152s	
24476/30300 (epoch 40.389), train_loss = 1.01348363, grad/param norm = 1.8791e-01, time/batch = 0.6871s	
24477/30300 (epoch 40.391), train_loss = 1.05778509, grad/param norm = 1.8116e-01, time/batch = 0.6852s	
24478/30300 (epoch 40.393), train_loss = 0.89970783, grad/param norm = 1.4514e-01, time/batch = 0.6875s	
24479/30300 (epoch 40.394), train_loss = 1.04499563, grad/param norm = 1.6171e-01, time/batch = 0.6843s	
24480/30300 (epoch 40.396), train_loss = 1.14831998, grad/param norm = 1.6662e-01, time/batch = 0.6820s	
24481/30300 (epoch 40.398), train_loss = 0.99762638, grad/param norm = 2.0708e-01, time/batch = 0.6910s	
24482/30300 (epoch 40.399), train_loss = 0.93547511, grad/param norm = 1.6443e-01, time/batch = 0.6856s	
24483/30300 (epoch 40.401), train_loss = 1.01708129, grad/param norm = 2.1247e-01, time/batch = 0.6858s	
24484/30300 (epoch 40.403), train_loss = 1.01245466, grad/param norm = 1.7780e-01, time/batch = 0.6850s	
24485/30300 (epoch 40.404), train_loss = 0.95980887, grad/param norm = 1.9291e-01, time/batch = 0.6817s	
24486/30300 (epoch 40.406), train_loss = 1.02609822, grad/param norm = 1.6287e-01, time/batch = 0.6817s	
24487/30300 (epoch 40.408), train_loss = 0.89931752, grad/param norm = 1.5582e-01, time/batch = 0.6835s	
24488/30300 (epoch 40.409), train_loss = 0.91126959, grad/param norm = 1.8479e-01, time/batch = 0.6893s	
24489/30300 (epoch 40.411), train_loss = 0.95662261, grad/param norm = 1.6279e-01, time/batch = 0.6826s	
24490/30300 (epoch 40.413), train_loss = 0.86181738, grad/param norm = 1.6513e-01, time/batch = 0.6818s	
24491/30300 (epoch 40.414), train_loss = 1.05049596, grad/param norm = 1.6563e-01, time/batch = 0.6839s	
24492/30300 (epoch 40.416), train_loss = 0.95282772, grad/param norm = 1.5399e-01, time/batch = 0.6849s	
24493/30300 (epoch 40.417), train_loss = 0.91668843, grad/param norm = 1.9738e-01, time/batch = 0.6857s	
24494/30300 (epoch 40.419), train_loss = 0.92280016, grad/param norm = 1.8253e-01, time/batch = 0.6854s	
24495/30300 (epoch 40.421), train_loss = 0.99589904, grad/param norm = 2.0772e-01, time/batch = 0.6855s	
24496/30300 (epoch 40.422), train_loss = 1.02353415, grad/param norm = 1.7916e-01, time/batch = 0.6846s	
24497/30300 (epoch 40.424), train_loss = 1.01661137, grad/param norm = 1.7070e-01, time/batch = 0.6852s	
24498/30300 (epoch 40.426), train_loss = 0.99262078, grad/param norm = 1.7388e-01, time/batch = 0.6846s	
24499/30300 (epoch 40.427), train_loss = 0.95907543, grad/param norm = 1.7896e-01, time/batch = 0.6851s	
24500/30300 (epoch 40.429), train_loss = 0.99795849, grad/param norm = 1.6106e-01, time/batch = 0.6935s	
24501/30300 (epoch 40.431), train_loss = 1.04701435, grad/param norm = 1.6826e-01, time/batch = 0.6985s	
24502/30300 (epoch 40.432), train_loss = 1.01267738, grad/param norm = 1.6192e-01, time/batch = 0.6850s	
24503/30300 (epoch 40.434), train_loss = 0.90839955, grad/param norm = 1.6916e-01, time/batch = 0.6848s	
24504/30300 (epoch 40.436), train_loss = 1.10027799, grad/param norm = 1.7548e-01, time/batch = 0.6866s	
24505/30300 (epoch 40.437), train_loss = 0.90773374, grad/param norm = 1.5521e-01, time/batch = 0.6824s	
24506/30300 (epoch 40.439), train_loss = 0.95939973, grad/param norm = 1.6078e-01, time/batch = 0.6815s	
24507/30300 (epoch 40.441), train_loss = 1.00136691, grad/param norm = 1.5680e-01, time/batch = 0.6852s	
24508/30300 (epoch 40.442), train_loss = 0.95167415, grad/param norm = 1.6835e-01, time/batch = 0.6817s	
24509/30300 (epoch 40.444), train_loss = 0.83153035, grad/param norm = 1.5044e-01, time/batch = 0.6804s	
24510/30300 (epoch 40.446), train_loss = 0.97166247, grad/param norm = 1.5496e-01, time/batch = 0.6809s	
24511/30300 (epoch 40.447), train_loss = 1.00104427, grad/param norm = 1.6545e-01, time/batch = 0.6846s	
24512/30300 (epoch 40.449), train_loss = 0.94463313, grad/param norm = 1.7142e-01, time/batch = 0.6840s	
24513/30300 (epoch 40.450), train_loss = 1.03156872, grad/param norm = 1.5208e-01, time/batch = 0.6854s	
24514/30300 (epoch 40.452), train_loss = 1.10921012, grad/param norm = 1.7771e-01, time/batch = 0.6808s	
24515/30300 (epoch 40.454), train_loss = 1.06283352, grad/param norm = 1.9612e-01, time/batch = 0.6822s	
24516/30300 (epoch 40.455), train_loss = 1.01894873, grad/param norm = 1.9755e-01, time/batch = 0.6818s	
24517/30300 (epoch 40.457), train_loss = 0.98984428, grad/param norm = 1.9449e-01, time/batch = 0.6911s	
24518/30300 (epoch 40.459), train_loss = 1.06110132, grad/param norm = 1.9171e-01, time/batch = 0.6882s	
24519/30300 (epoch 40.460), train_loss = 1.09535598, grad/param norm = 1.7720e-01, time/batch = 0.6856s	
24520/30300 (epoch 40.462), train_loss = 1.08444460, grad/param norm = 1.7958e-01, time/batch = 0.6828s	
24521/30300 (epoch 40.464), train_loss = 0.83336102, grad/param norm = 1.8539e-01, time/batch = 0.6863s	
24522/30300 (epoch 40.465), train_loss = 0.86794457, grad/param norm = 1.5778e-01, time/batch = 0.6834s	
24523/30300 (epoch 40.467), train_loss = 0.86402034, grad/param norm = 1.5734e-01, time/batch = 0.6830s	
24524/30300 (epoch 40.469), train_loss = 0.94878394, grad/param norm = 1.6802e-01, time/batch = 0.6849s	
24525/30300 (epoch 40.470), train_loss = 0.96905931, grad/param norm = 1.8442e-01, time/batch = 0.6831s	
24526/30300 (epoch 40.472), train_loss = 0.96491087, grad/param norm = 1.7086e-01, time/batch = 0.6819s	
24527/30300 (epoch 40.474), train_loss = 0.96338649, grad/param norm = 2.2522e-01, time/batch = 0.6827s	
24528/30300 (epoch 40.475), train_loss = 0.93558678, grad/param norm = 1.6580e-01, time/batch = 0.6837s	
24529/30300 (epoch 40.477), train_loss = 1.00153748, grad/param norm = 1.7425e-01, time/batch = 0.6952s	
24530/30300 (epoch 40.479), train_loss = 0.97746408, grad/param norm = 1.7229e-01, time/batch = 0.7129s	
24531/30300 (epoch 40.480), train_loss = 1.02933421, grad/param norm = 1.8729e-01, time/batch = 0.7229s	
24532/30300 (epoch 40.482), train_loss = 1.06022856, grad/param norm = 1.6243e-01, time/batch = 0.7126s	
24533/30300 (epoch 40.483), train_loss = 0.99079422, grad/param norm = 1.7167e-01, time/batch = 0.6917s	
24534/30300 (epoch 40.485), train_loss = 1.01535394, grad/param norm = 1.5883e-01, time/batch = 0.6849s	
24535/30300 (epoch 40.487), train_loss = 1.06688751, grad/param norm = 1.6180e-01, time/batch = 0.6828s	
24536/30300 (epoch 40.488), train_loss = 1.12586505, grad/param norm = 1.5197e-01, time/batch = 0.6813s	
24537/30300 (epoch 40.490), train_loss = 0.87130236, grad/param norm = 1.5982e-01, time/batch = 0.6826s	
24538/30300 (epoch 40.492), train_loss = 0.97453032, grad/param norm = 2.0866e-01, time/batch = 0.6810s	
24539/30300 (epoch 40.493), train_loss = 1.00682467, grad/param norm = 1.6504e-01, time/batch = 0.6820s	
24540/30300 (epoch 40.495), train_loss = 0.97489174, grad/param norm = 1.4850e-01, time/batch = 0.6829s	
24541/30300 (epoch 40.497), train_loss = 1.04639068, grad/param norm = 1.8803e-01, time/batch = 0.6832s	
24542/30300 (epoch 40.498), train_loss = 1.05568933, grad/param norm = 1.6456e-01, time/batch = 0.6857s	
24543/30300 (epoch 40.500), train_loss = 0.96175733, grad/param norm = 1.8527e-01, time/batch = 0.6853s	
24544/30300 (epoch 40.502), train_loss = 1.00392968, grad/param norm = 2.0952e-01, time/batch = 0.6855s	
24545/30300 (epoch 40.503), train_loss = 1.09166516, grad/param norm = 1.5954e-01, time/batch = 0.6830s	
24546/30300 (epoch 40.505), train_loss = 0.89802134, grad/param norm = 1.5889e-01, time/batch = 0.6800s	
24547/30300 (epoch 40.507), train_loss = 0.89422089, grad/param norm = 1.5726e-01, time/batch = 0.6832s	
24548/30300 (epoch 40.508), train_loss = 0.94669103, grad/param norm = 2.1756e-01, time/batch = 0.6920s	
24549/30300 (epoch 40.510), train_loss = 1.07143647, grad/param norm = 1.7525e-01, time/batch = 0.6829s	
24550/30300 (epoch 40.512), train_loss = 0.94504249, grad/param norm = 1.6277e-01, time/batch = 0.6955s	
24551/30300 (epoch 40.513), train_loss = 1.00958815, grad/param norm = 1.6809e-01, time/batch = 0.6953s	
24552/30300 (epoch 40.515), train_loss = 0.99516871, grad/param norm = 1.7300e-01, time/batch = 0.7232s	
24553/30300 (epoch 40.517), train_loss = 0.83496267, grad/param norm = 1.6048e-01, time/batch = 0.7247s	
24554/30300 (epoch 40.518), train_loss = 1.08907382, grad/param norm = 1.7827e-01, time/batch = 0.7356s	
24555/30300 (epoch 40.520), train_loss = 0.98754747, grad/param norm = 1.8074e-01, time/batch = 0.7130s	
24556/30300 (epoch 40.521), train_loss = 0.90191804, grad/param norm = 2.2335e-01, time/batch = 0.6983s	
24557/30300 (epoch 40.523), train_loss = 1.10582019, grad/param norm = 2.1380e-01, time/batch = 0.7087s	
24558/30300 (epoch 40.525), train_loss = 0.92990976, grad/param norm = 1.7931e-01, time/batch = 0.7121s	
24559/30300 (epoch 40.526), train_loss = 1.02737961, grad/param norm = 1.6266e-01, time/batch = 0.7075s	
24560/30300 (epoch 40.528), train_loss = 0.87659837, grad/param norm = 1.5827e-01, time/batch = 0.6912s	
24561/30300 (epoch 40.530), train_loss = 0.88420084, grad/param norm = 1.6003e-01, time/batch = 0.6857s	
24562/30300 (epoch 40.531), train_loss = 0.98759534, grad/param norm = 1.6139e-01, time/batch = 0.6829s	
24563/30300 (epoch 40.533), train_loss = 0.98230508, grad/param norm = 2.0483e-01, time/batch = 0.6843s	
24564/30300 (epoch 40.535), train_loss = 0.98363152, grad/param norm = 1.4564e-01, time/batch = 0.6870s	
24565/30300 (epoch 40.536), train_loss = 1.00772903, grad/param norm = 2.2230e-01, time/batch = 0.6918s	
24566/30300 (epoch 40.538), train_loss = 0.88789434, grad/param norm = 1.7932e-01, time/batch = 0.6886s	
24567/30300 (epoch 40.540), train_loss = 0.94215220, grad/param norm = 1.7434e-01, time/batch = 0.6826s	
24568/30300 (epoch 40.541), train_loss = 1.00736547, grad/param norm = 2.0070e-01, time/batch = 0.6830s	
24569/30300 (epoch 40.543), train_loss = 0.97553778, grad/param norm = 1.6195e-01, time/batch = 0.6829s	
24570/30300 (epoch 40.545), train_loss = 1.06640655, grad/param norm = 2.0464e-01, time/batch = 0.6850s	
24571/30300 (epoch 40.546), train_loss = 1.16577917, grad/param norm = 1.6752e-01, time/batch = 0.6857s	
24572/30300 (epoch 40.548), train_loss = 0.94532081, grad/param norm = 1.4635e-01, time/batch = 0.6880s	
24573/30300 (epoch 40.550), train_loss = 1.04296417, grad/param norm = 1.9785e-01, time/batch = 0.6829s	
24574/30300 (epoch 40.551), train_loss = 0.92918922, grad/param norm = 1.6942e-01, time/batch = 0.6864s	
24575/30300 (epoch 40.553), train_loss = 0.98557982, grad/param norm = 2.2545e-01, time/batch = 0.7117s	
24576/30300 (epoch 40.554), train_loss = 1.01424826, grad/param norm = 1.7781e-01, time/batch = 0.6930s	
24577/30300 (epoch 40.556), train_loss = 1.02430885, grad/param norm = 1.6066e-01, time/batch = 0.6845s	
24578/30300 (epoch 40.558), train_loss = 1.09069483, grad/param norm = 1.9684e-01, time/batch = 0.6817s	
24579/30300 (epoch 40.559), train_loss = 1.00693180, grad/param norm = 1.6540e-01, time/batch = 0.7235s	
24580/30300 (epoch 40.561), train_loss = 0.80532063, grad/param norm = 1.5925e-01, time/batch = 0.6993s	
24581/30300 (epoch 40.563), train_loss = 0.91040760, grad/param norm = 1.7863e-01, time/batch = 0.6871s	
24582/30300 (epoch 40.564), train_loss = 0.95229563, grad/param norm = 1.5811e-01, time/batch = 0.6847s	
24583/30300 (epoch 40.566), train_loss = 0.97181027, grad/param norm = 1.8060e-01, time/batch = 0.6815s	
24584/30300 (epoch 40.568), train_loss = 0.86811023, grad/param norm = 2.1698e-01, time/batch = 0.6814s	
24585/30300 (epoch 40.569), train_loss = 1.02475676, grad/param norm = 1.6573e-01, time/batch = 0.6811s	
24586/30300 (epoch 40.571), train_loss = 0.99660720, grad/param norm = 1.7781e-01, time/batch = 0.6818s	
24587/30300 (epoch 40.573), train_loss = 1.04851877, grad/param norm = 1.7788e-01, time/batch = 0.6831s	
24588/30300 (epoch 40.574), train_loss = 1.02687557, grad/param norm = 1.7065e-01, time/batch = 0.6861s	
24589/30300 (epoch 40.576), train_loss = 0.96693990, grad/param norm = 1.5476e-01, time/batch = 0.6809s	
24590/30300 (epoch 40.578), train_loss = 0.87503030, grad/param norm = 1.5838e-01, time/batch = 0.6804s	
24591/30300 (epoch 40.579), train_loss = 1.05573344, grad/param norm = 1.9427e-01, time/batch = 0.6842s	
24592/30300 (epoch 40.581), train_loss = 1.11862995, grad/param norm = 1.7064e-01, time/batch = 0.6841s	
24593/30300 (epoch 40.583), train_loss = 1.11356536, grad/param norm = 1.9277e-01, time/batch = 0.6849s	
24594/30300 (epoch 40.584), train_loss = 1.09160783, grad/param norm = 1.5748e-01, time/batch = 0.6836s	
24595/30300 (epoch 40.586), train_loss = 0.97489569, grad/param norm = 1.7133e-01, time/batch = 0.6953s	
24596/30300 (epoch 40.587), train_loss = 0.99866327, grad/param norm = 1.8124e-01, time/batch = 0.6865s	
24597/30300 (epoch 40.589), train_loss = 0.94409538, grad/param norm = 1.7967e-01, time/batch = 0.6812s	
24598/30300 (epoch 40.591), train_loss = 1.02022176, grad/param norm = 1.5221e-01, time/batch = 0.6797s	
24599/30300 (epoch 40.592), train_loss = 0.94811601, grad/param norm = 1.4768e-01, time/batch = 0.6822s	
24600/30300 (epoch 40.594), train_loss = 1.03277479, grad/param norm = 1.7331e-01, time/batch = 0.6805s	
24601/30300 (epoch 40.596), train_loss = 0.91087186, grad/param norm = 1.4894e-01, time/batch = 0.6833s	
24602/30300 (epoch 40.597), train_loss = 0.94290619, grad/param norm = 1.7757e-01, time/batch = 0.6841s	
24603/30300 (epoch 40.599), train_loss = 0.85181195, grad/param norm = 1.5779e-01, time/batch = 0.6840s	
24604/30300 (epoch 40.601), train_loss = 1.03500306, grad/param norm = 1.8286e-01, time/batch = 0.7010s	
24605/30300 (epoch 40.602), train_loss = 0.98194020, grad/param norm = 1.6158e-01, time/batch = 0.6895s	
24606/30300 (epoch 40.604), train_loss = 0.93793912, grad/param norm = 1.6952e-01, time/batch = 0.6868s	
24607/30300 (epoch 40.606), train_loss = 0.95069244, grad/param norm = 2.0373e-01, time/batch = 0.6867s	
24608/30300 (epoch 40.607), train_loss = 1.07184761, grad/param norm = 1.8679e-01, time/batch = 0.6853s	
24609/30300 (epoch 40.609), train_loss = 1.15614642, grad/param norm = 1.7025e-01, time/batch = 0.6830s	
24610/30300 (epoch 40.611), train_loss = 0.96982102, grad/param norm = 1.5784e-01, time/batch = 0.6824s	
24611/30300 (epoch 40.612), train_loss = 0.90058853, grad/param norm = 1.4930e-01, time/batch = 0.6858s	
24612/30300 (epoch 40.614), train_loss = 0.97481349, grad/param norm = 1.5279e-01, time/batch = 0.6863s	
24613/30300 (epoch 40.616), train_loss = 1.02134761, grad/param norm = 2.0039e-01, time/batch = 0.6823s	
24614/30300 (epoch 40.617), train_loss = 1.01461127, grad/param norm = 1.9890e-01, time/batch = 0.6845s	
24615/30300 (epoch 40.619), train_loss = 0.82127019, grad/param norm = 1.3731e-01, time/batch = 0.6808s	
24616/30300 (epoch 40.620), train_loss = 1.05888036, grad/param norm = 1.7358e-01, time/batch = 0.6825s	
24617/30300 (epoch 40.622), train_loss = 0.99124468, grad/param norm = 1.8813e-01, time/batch = 0.6822s	
24618/30300 (epoch 40.624), train_loss = 0.98877003, grad/param norm = 1.7487e-01, time/batch = 0.6824s	
24619/30300 (epoch 40.625), train_loss = 0.99138487, grad/param norm = 2.2401e-01, time/batch = 0.6852s	
24620/30300 (epoch 40.627), train_loss = 1.10148415, grad/param norm = 2.9879e-01, time/batch = 0.6834s	
24621/30300 (epoch 40.629), train_loss = 1.13474573, grad/param norm = 1.7463e-01, time/batch = 0.6848s	
24622/30300 (epoch 40.630), train_loss = 1.00885042, grad/param norm = 2.0055e-01, time/batch = 0.6847s	
24623/30300 (epoch 40.632), train_loss = 1.04937949, grad/param norm = 1.9696e-01, time/batch = 0.6836s	
24624/30300 (epoch 40.634), train_loss = 0.93445216, grad/param norm = 1.8827e-01, time/batch = 0.6841s	
24625/30300 (epoch 40.635), train_loss = 1.04560340, grad/param norm = 2.3401e-01, time/batch = 0.6828s	
24626/30300 (epoch 40.637), train_loss = 1.07893318, grad/param norm = 1.9813e-01, time/batch = 0.6809s	
24627/30300 (epoch 40.639), train_loss = 0.99156180, grad/param norm = 1.8161e-01, time/batch = 0.6820s	
24628/30300 (epoch 40.640), train_loss = 1.10334503, grad/param norm = 1.7803e-01, time/batch = 0.6886s	
24629/30300 (epoch 40.642), train_loss = 0.99940363, grad/param norm = 1.6757e-01, time/batch = 0.6845s	
24630/30300 (epoch 40.644), train_loss = 1.08175955, grad/param norm = 1.8563e-01, time/batch = 0.6912s	
24631/30300 (epoch 40.645), train_loss = 0.93715328, grad/param norm = 1.4963e-01, time/batch = 0.6919s	
24632/30300 (epoch 40.647), train_loss = 0.99472004, grad/param norm = 1.5760e-01, time/batch = 0.6829s	
24633/30300 (epoch 40.649), train_loss = 0.98169906, grad/param norm = 2.3271e-01, time/batch = 0.6829s	
24634/30300 (epoch 40.650), train_loss = 1.01091615, grad/param norm = 1.7712e-01, time/batch = 0.6825s	
24635/30300 (epoch 40.652), train_loss = 0.98015199, grad/param norm = 1.7740e-01, time/batch = 0.6894s	
24636/30300 (epoch 40.653), train_loss = 1.16943378, grad/param norm = 1.4970e-01, time/batch = 0.6863s	
24637/30300 (epoch 40.655), train_loss = 0.99751261, grad/param norm = 1.8674e-01, time/batch = 0.7077s	
24638/30300 (epoch 40.657), train_loss = 0.90155885, grad/param norm = 1.7251e-01, time/batch = 0.7150s	
24639/30300 (epoch 40.658), train_loss = 0.96787814, grad/param norm = 1.6451e-01, time/batch = 0.7380s	
24640/30300 (epoch 40.660), train_loss = 1.00878906, grad/param norm = 1.7188e-01, time/batch = 0.7197s	
24641/30300 (epoch 40.662), train_loss = 1.02015682, grad/param norm = 1.8699e-01, time/batch = 0.6863s	
24642/30300 (epoch 40.663), train_loss = 1.08018273, grad/param norm = 1.7307e-01, time/batch = 0.6832s	
24643/30300 (epoch 40.665), train_loss = 0.94234792, grad/param norm = 1.9905e-01, time/batch = 0.6857s	
24644/30300 (epoch 40.667), train_loss = 1.06499832, grad/param norm = 1.8700e-01, time/batch = 0.6880s	
24645/30300 (epoch 40.668), train_loss = 1.08658727, grad/param norm = 1.7530e-01, time/batch = 0.6835s	
24646/30300 (epoch 40.670), train_loss = 1.10971634, grad/param norm = 1.8698e-01, time/batch = 0.6868s	
24647/30300 (epoch 40.672), train_loss = 1.00918965, grad/param norm = 1.8120e-01, time/batch = 0.6821s	
24648/30300 (epoch 40.673), train_loss = 1.07099828, grad/param norm = 1.8472e-01, time/batch = 0.6837s	
24649/30300 (epoch 40.675), train_loss = 0.98530234, grad/param norm = 1.9751e-01, time/batch = 0.6849s	
24650/30300 (epoch 40.677), train_loss = 0.96195672, grad/param norm = 1.5059e-01, time/batch = 0.6834s	
24651/30300 (epoch 40.678), train_loss = 0.95461902, grad/param norm = 1.6571e-01, time/batch = 0.6907s	
24652/30300 (epoch 40.680), train_loss = 0.89302780, grad/param norm = 1.5829e-01, time/batch = 0.6856s	
24653/30300 (epoch 40.682), train_loss = 1.00299487, grad/param norm = 1.8078e-01, time/batch = 0.6830s	
24654/30300 (epoch 40.683), train_loss = 1.09190454, grad/param norm = 1.7605e-01, time/batch = 0.6823s	
24655/30300 (epoch 40.685), train_loss = 1.04961291, grad/param norm = 2.0035e-01, time/batch = 0.6990s	
24656/30300 (epoch 40.686), train_loss = 0.98890263, grad/param norm = 1.6894e-01, time/batch = 0.6994s	
24657/30300 (epoch 40.688), train_loss = 0.99894083, grad/param norm = 1.5585e-01, time/batch = 0.6846s	
24658/30300 (epoch 40.690), train_loss = 0.95616574, grad/param norm = 1.9084e-01, time/batch = 0.6850s	
24659/30300 (epoch 40.691), train_loss = 1.00355905, grad/param norm = 1.6544e-01, time/batch = 0.6829s	
24660/30300 (epoch 40.693), train_loss = 1.28281653, grad/param norm = 2.0350e-01, time/batch = 0.6804s	
24661/30300 (epoch 40.695), train_loss = 1.07633181, grad/param norm = 2.0767e-01, time/batch = 0.6821s	
24662/30300 (epoch 40.696), train_loss = 1.06681299, grad/param norm = 2.2312e-01, time/batch = 0.6802s	
24663/30300 (epoch 40.698), train_loss = 0.97395573, grad/param norm = 1.7772e-01, time/batch = 0.6790s	
24664/30300 (epoch 40.700), train_loss = 0.93989500, grad/param norm = 1.8040e-01, time/batch = 0.6826s	
24665/30300 (epoch 40.701), train_loss = 0.87995285, grad/param norm = 1.6464e-01, time/batch = 0.6821s	
24666/30300 (epoch 40.703), train_loss = 1.01566880, grad/param norm = 1.6664e-01, time/batch = 0.6841s	
24667/30300 (epoch 40.705), train_loss = 0.92449991, grad/param norm = 1.6471e-01, time/batch = 0.6793s	
24668/30300 (epoch 40.706), train_loss = 1.05773152, grad/param norm = 1.7163e-01, time/batch = 0.6805s	
24669/30300 (epoch 40.708), train_loss = 1.00637357, grad/param norm = 1.6651e-01, time/batch = 0.6791s	
24670/30300 (epoch 40.710), train_loss = 0.97686683, grad/param norm = 1.7263e-01, time/batch = 0.6800s	
24671/30300 (epoch 40.711), train_loss = 0.94968508, grad/param norm = 1.7094e-01, time/batch = 0.6833s	
24672/30300 (epoch 40.713), train_loss = 0.94607854, grad/param norm = 1.6977e-01, time/batch = 0.6824s	
24673/30300 (epoch 40.715), train_loss = 0.95465049, grad/param norm = 1.5277e-01, time/batch = 0.6828s	
24674/30300 (epoch 40.716), train_loss = 1.07634320, grad/param norm = 1.7615e-01, time/batch = 0.6796s	
24675/30300 (epoch 40.718), train_loss = 1.10755107, grad/param norm = 1.7522e-01, time/batch = 0.6860s	
24676/30300 (epoch 40.719), train_loss = 0.96694679, grad/param norm = 1.9744e-01, time/batch = 0.6810s	
24677/30300 (epoch 40.721), train_loss = 0.99021656, grad/param norm = 1.8895e-01, time/batch = 0.6890s	
24678/30300 (epoch 40.723), train_loss = 0.92626797, grad/param norm = 1.5607e-01, time/batch = 0.6973s	
24679/30300 (epoch 40.724), train_loss = 1.04090029, grad/param norm = 1.8442e-01, time/batch = 0.7018s	
24680/30300 (epoch 40.726), train_loss = 1.25093738, grad/param norm = 1.9003e-01, time/batch = 0.7219s	
24681/30300 (epoch 40.728), train_loss = 1.04002652, grad/param norm = 1.7294e-01, time/batch = 0.7170s	
24682/30300 (epoch 40.729), train_loss = 0.97097126, grad/param norm = 1.8139e-01, time/batch = 0.6920s	
24683/30300 (epoch 40.731), train_loss = 0.97681818, grad/param norm = 1.8062e-01, time/batch = 0.6813s	
24684/30300 (epoch 40.733), train_loss = 1.01943242, grad/param norm = 2.1674e-01, time/batch = 0.6823s	
24685/30300 (epoch 40.734), train_loss = 1.08859815, grad/param norm = 1.6725e-01, time/batch = 0.6813s	
24686/30300 (epoch 40.736), train_loss = 1.02626988, grad/param norm = 1.7548e-01, time/batch = 0.6832s	
24687/30300 (epoch 40.738), train_loss = 0.92956572, grad/param norm = 1.3829e-01, time/batch = 0.6839s	
24688/30300 (epoch 40.739), train_loss = 1.11334018, grad/param norm = 1.9915e-01, time/batch = 0.6828s	
24689/30300 (epoch 40.741), train_loss = 1.14040608, grad/param norm = 1.6797e-01, time/batch = 0.6955s	
24690/30300 (epoch 40.743), train_loss = 0.97653991, grad/param norm = 1.7568e-01, time/batch = 0.7069s	
24691/30300 (epoch 40.744), train_loss = 1.06917715, grad/param norm = 2.4490e-01, time/batch = 0.7106s	
24692/30300 (epoch 40.746), train_loss = 0.96525813, grad/param norm = 1.4911e-01, time/batch = 0.7134s	
24693/30300 (epoch 40.748), train_loss = 0.98717918, grad/param norm = 1.8413e-01, time/batch = 0.7109s	
24694/30300 (epoch 40.749), train_loss = 1.01542949, grad/param norm = 1.7089e-01, time/batch = 0.7310s	
24695/30300 (epoch 40.751), train_loss = 1.05625820, grad/param norm = 1.6841e-01, time/batch = 0.7193s	
24696/30300 (epoch 40.752), train_loss = 0.99145179, grad/param norm = 1.8810e-01, time/batch = 0.7160s	
24697/30300 (epoch 40.754), train_loss = 0.99849486, grad/param norm = 1.6365e-01, time/batch = 0.7071s	
24698/30300 (epoch 40.756), train_loss = 0.99014194, grad/param norm = 1.6772e-01, time/batch = 0.7172s	
24699/30300 (epoch 40.757), train_loss = 0.93055638, grad/param norm = 1.6407e-01, time/batch = 0.7432s	
24700/30300 (epoch 40.759), train_loss = 1.02625799, grad/param norm = 1.7250e-01, time/batch = 0.7141s	
24701/30300 (epoch 40.761), train_loss = 0.87794724, grad/param norm = 1.6409e-01, time/batch = 0.7063s	
24702/30300 (epoch 40.762), train_loss = 0.89209455, grad/param norm = 1.6202e-01, time/batch = 0.7072s	
24703/30300 (epoch 40.764), train_loss = 0.98334576, grad/param norm = 1.9569e-01, time/batch = 0.6981s	
24704/30300 (epoch 40.766), train_loss = 1.12325992, grad/param norm = 2.0212e-01, time/batch = 0.7010s	
24705/30300 (epoch 40.767), train_loss = 1.02875467, grad/param norm = 2.3732e-01, time/batch = 0.6990s	
24706/30300 (epoch 40.769), train_loss = 1.02455705, grad/param norm = 2.5557e-01, time/batch = 0.7264s	
24707/30300 (epoch 40.771), train_loss = 0.95001255, grad/param norm = 2.2977e-01, time/batch = 0.6994s	
24708/30300 (epoch 40.772), train_loss = 1.00244996, grad/param norm = 1.8544e-01, time/batch = 0.6972s	
24709/30300 (epoch 40.774), train_loss = 1.15844246, grad/param norm = 1.8257e-01, time/batch = 0.6842s	
24710/30300 (epoch 40.776), train_loss = 0.98076646, grad/param norm = 1.8664e-01, time/batch = 0.6824s	
24711/30300 (epoch 40.777), train_loss = 1.13434736, grad/param norm = 1.6740e-01, time/batch = 0.6840s	
24712/30300 (epoch 40.779), train_loss = 1.11758466, grad/param norm = 1.8149e-01, time/batch = 0.6829s	
24713/30300 (epoch 40.781), train_loss = 1.01582019, grad/param norm = 1.7894e-01, time/batch = 0.6851s	
24714/30300 (epoch 40.782), train_loss = 0.94017421, grad/param norm = 1.9781e-01, time/batch = 0.6846s	
24715/30300 (epoch 40.784), train_loss = 0.96576214, grad/param norm = 1.7737e-01, time/batch = 0.6874s	
24716/30300 (epoch 40.785), train_loss = 1.08056280, grad/param norm = 2.1572e-01, time/batch = 0.6839s	
24717/30300 (epoch 40.787), train_loss = 0.85175556, grad/param norm = 1.8208e-01, time/batch = 0.6836s	
24718/30300 (epoch 40.789), train_loss = 1.14646086, grad/param norm = 2.0234e-01, time/batch = 0.6834s	
24719/30300 (epoch 40.790), train_loss = 1.01642678, grad/param norm = 1.8998e-01, time/batch = 0.6870s	
24720/30300 (epoch 40.792), train_loss = 0.82573740, grad/param norm = 1.8466e-01, time/batch = 0.6918s	
24721/30300 (epoch 40.794), train_loss = 1.00394097, grad/param norm = 2.0030e-01, time/batch = 0.7008s	
24722/30300 (epoch 40.795), train_loss = 0.92595001, grad/param norm = 1.4542e-01, time/batch = 0.6960s	
24723/30300 (epoch 40.797), train_loss = 1.15081181, grad/param norm = 2.2174e-01, time/batch = 0.7035s	
24724/30300 (epoch 40.799), train_loss = 1.08082269, grad/param norm = 2.2049e-01, time/batch = 0.7080s	
24725/30300 (epoch 40.800), train_loss = 1.06402662, grad/param norm = 1.6799e-01, time/batch = 0.7003s	
24726/30300 (epoch 40.802), train_loss = 1.25068933, grad/param norm = 1.9986e-01, time/batch = 0.6868s	
24727/30300 (epoch 40.804), train_loss = 1.07752918, grad/param norm = 1.9984e-01, time/batch = 0.6869s	
24728/30300 (epoch 40.805), train_loss = 1.13668752, grad/param norm = 1.8868e-01, time/batch = 0.6847s	
24729/30300 (epoch 40.807), train_loss = 0.97465485, grad/param norm = 1.8083e-01, time/batch = 0.7110s	
24730/30300 (epoch 40.809), train_loss = 1.09342145, grad/param norm = 1.8411e-01, time/batch = 0.6994s	
24731/30300 (epoch 40.810), train_loss = 1.06115427, grad/param norm = 1.8074e-01, time/batch = 0.6970s	
24732/30300 (epoch 40.812), train_loss = 0.96196969, grad/param norm = 1.6220e-01, time/batch = 0.7128s	
24733/30300 (epoch 40.814), train_loss = 1.02249880, grad/param norm = 1.8182e-01, time/batch = 0.7037s	
24734/30300 (epoch 40.815), train_loss = 1.01090516, grad/param norm = 1.9409e-01, time/batch = 0.6907s	
24735/30300 (epoch 40.817), train_loss = 1.09106444, grad/param norm = 1.9958e-01, time/batch = 0.6815s	
24736/30300 (epoch 40.818), train_loss = 1.04033401, grad/param norm = 1.6798e-01, time/batch = 0.7102s	
24737/30300 (epoch 40.820), train_loss = 1.18126264, grad/param norm = 2.0037e-01, time/batch = 0.6906s	
24738/30300 (epoch 40.822), train_loss = 1.15328661, grad/param norm = 1.7459e-01, time/batch = 0.6830s	
24739/30300 (epoch 40.823), train_loss = 1.15050711, grad/param norm = 1.8569e-01, time/batch = 0.6827s	
24740/30300 (epoch 40.825), train_loss = 1.13921233, grad/param norm = 1.7206e-01, time/batch = 0.6815s	
24741/30300 (epoch 40.827), train_loss = 0.86536176, grad/param norm = 1.7596e-01, time/batch = 0.7069s	
24742/30300 (epoch 40.828), train_loss = 1.11307450, grad/param norm = 1.9430e-01, time/batch = 0.6987s	
24743/30300 (epoch 40.830), train_loss = 1.06633629, grad/param norm = 1.8057e-01, time/batch = 0.6879s	
24744/30300 (epoch 40.832), train_loss = 0.95014284, grad/param norm = 1.6906e-01, time/batch = 0.6873s	
24745/30300 (epoch 40.833), train_loss = 1.04301902, grad/param norm = 1.8325e-01, time/batch = 0.6853s	
24746/30300 (epoch 40.835), train_loss = 0.95408967, grad/param norm = 1.8095e-01, time/batch = 0.6829s	
24747/30300 (epoch 40.837), train_loss = 0.92466356, grad/param norm = 1.7124e-01, time/batch = 0.6820s	
24748/30300 (epoch 40.838), train_loss = 0.92124582, grad/param norm = 1.6865e-01, time/batch = 0.6819s	
24749/30300 (epoch 40.840), train_loss = 1.10840302, grad/param norm = 1.6445e-01, time/batch = 0.6823s	
24750/30300 (epoch 40.842), train_loss = 0.99196176, grad/param norm = 1.4996e-01, time/batch = 0.6825s	
24751/30300 (epoch 40.843), train_loss = 1.05985251, grad/param norm = 1.7497e-01, time/batch = 0.6860s	
24752/30300 (epoch 40.845), train_loss = 1.05426074, grad/param norm = 1.5120e-01, time/batch = 0.6855s	
24753/30300 (epoch 40.847), train_loss = 1.01994579, grad/param norm = 1.7724e-01, time/batch = 0.6859s	
24754/30300 (epoch 40.848), train_loss = 1.06379181, grad/param norm = 1.7836e-01, time/batch = 0.6844s	
24755/30300 (epoch 40.850), train_loss = 1.00568682, grad/param norm = 1.6326e-01, time/batch = 0.6830s	
24756/30300 (epoch 40.851), train_loss = 1.04763928, grad/param norm = 1.9430e-01, time/batch = 0.6818s	
24757/30300 (epoch 40.853), train_loss = 0.98588119, grad/param norm = 1.6676e-01, time/batch = 0.6814s	
24758/30300 (epoch 40.855), train_loss = 0.96511772, grad/param norm = 1.5998e-01, time/batch = 0.7007s	
24759/30300 (epoch 40.856), train_loss = 1.01697204, grad/param norm = 1.5917e-01, time/batch = 0.7038s	
24760/30300 (epoch 40.858), train_loss = 0.92799897, grad/param norm = 1.5173e-01, time/batch = 0.7136s	
24761/30300 (epoch 40.860), train_loss = 0.91972583, grad/param norm = 1.5382e-01, time/batch = 0.7254s	
24762/30300 (epoch 40.861), train_loss = 1.15150065, grad/param norm = 1.7768e-01, time/batch = 0.7323s	
24763/30300 (epoch 40.863), train_loss = 0.97637309, grad/param norm = 1.6828e-01, time/batch = 0.6864s	
24764/30300 (epoch 40.865), train_loss = 1.07067048, grad/param norm = 1.8755e-01, time/batch = 0.6806s	
24765/30300 (epoch 40.866), train_loss = 1.07737827, grad/param norm = 1.7299e-01, time/batch = 0.6851s	
24766/30300 (epoch 40.868), train_loss = 1.04273216, grad/param norm = 1.7106e-01, time/batch = 0.7050s	
24767/30300 (epoch 40.870), train_loss = 0.95483588, grad/param norm = 1.6813e-01, time/batch = 0.6917s	
24768/30300 (epoch 40.871), train_loss = 1.04201038, grad/param norm = 1.7564e-01, time/batch = 0.7079s	
24769/30300 (epoch 40.873), train_loss = 1.01466590, grad/param norm = 1.4459e-01, time/batch = 0.6890s	
24770/30300 (epoch 40.875), train_loss = 0.98476790, grad/param norm = 1.5121e-01, time/batch = 0.6814s	
24771/30300 (epoch 40.876), train_loss = 0.90225289, grad/param norm = 1.6263e-01, time/batch = 0.6828s	
24772/30300 (epoch 40.878), train_loss = 0.85098251, grad/param norm = 1.6215e-01, time/batch = 0.6801s	
24773/30300 (epoch 40.880), train_loss = 0.94037598, grad/param norm = 1.7230e-01, time/batch = 0.6813s	
24774/30300 (epoch 40.881), train_loss = 1.15478695, grad/param norm = 2.1260e-01, time/batch = 0.6920s	
24775/30300 (epoch 40.883), train_loss = 1.07042429, grad/param norm = 1.9551e-01, time/batch = 0.6908s	
24776/30300 (epoch 40.884), train_loss = 1.01346451, grad/param norm = 1.6366e-01, time/batch = 0.6846s	
24777/30300 (epoch 40.886), train_loss = 1.06110484, grad/param norm = 1.8438e-01, time/batch = 0.6864s	
24778/30300 (epoch 40.888), train_loss = 0.96712960, grad/param norm = 1.8163e-01, time/batch = 0.6827s	
24779/30300 (epoch 40.889), train_loss = 1.03591897, grad/param norm = 1.7015e-01, time/batch = 0.6812s	
24780/30300 (epoch 40.891), train_loss = 0.99983010, grad/param norm = 1.8529e-01, time/batch = 0.6836s	
24781/30300 (epoch 40.893), train_loss = 1.21501795, grad/param norm = 1.7522e-01, time/batch = 0.6989s	
24782/30300 (epoch 40.894), train_loss = 1.03371393, grad/param norm = 1.7132e-01, time/batch = 0.6891s	
24783/30300 (epoch 40.896), train_loss = 0.87307289, grad/param norm = 1.5562e-01, time/batch = 0.6949s	
24784/30300 (epoch 40.898), train_loss = 0.86314038, grad/param norm = 1.6190e-01, time/batch = 0.6838s	
24785/30300 (epoch 40.899), train_loss = 0.90828944, grad/param norm = 1.5874e-01, time/batch = 0.6841s	
24786/30300 (epoch 40.901), train_loss = 1.01468090, grad/param norm = 1.9048e-01, time/batch = 0.6854s	
24787/30300 (epoch 40.903), train_loss = 0.98463047, grad/param norm = 2.0629e-01, time/batch = 0.6820s	
24788/30300 (epoch 40.904), train_loss = 1.02827837, grad/param norm = 1.5836e-01, time/batch = 0.6912s	
24789/30300 (epoch 40.906), train_loss = 1.01459106, grad/param norm = 1.8203e-01, time/batch = 0.6884s	
24790/30300 (epoch 40.908), train_loss = 0.95576990, grad/param norm = 1.7230e-01, time/batch = 0.6853s	
24791/30300 (epoch 40.909), train_loss = 0.96406365, grad/param norm = 2.2809e-01, time/batch = 0.6860s	
24792/30300 (epoch 40.911), train_loss = 1.00049805, grad/param norm = 1.7162e-01, time/batch = 0.6837s	
24793/30300 (epoch 40.913), train_loss = 1.00947486, grad/param norm = 1.5474e-01, time/batch = 0.6823s	
24794/30300 (epoch 40.914), train_loss = 0.97299340, grad/param norm = 1.9272e-01, time/batch = 0.6811s	
24795/30300 (epoch 40.916), train_loss = 1.03382522, grad/param norm = 1.5837e-01, time/batch = 0.6825s	
24796/30300 (epoch 40.917), train_loss = 0.96527470, grad/param norm = 1.6885e-01, time/batch = 0.6823s	
24797/30300 (epoch 40.919), train_loss = 0.89643100, grad/param norm = 1.7288e-01, time/batch = 0.6854s	
24798/30300 (epoch 40.921), train_loss = 0.98900535, grad/param norm = 1.5940e-01, time/batch = 0.6827s	
24799/30300 (epoch 40.922), train_loss = 1.09933027, grad/param norm = 1.9340e-01, time/batch = 0.6877s	
24800/30300 (epoch 40.924), train_loss = 1.01642621, grad/param norm = 1.9550e-01, time/batch = 0.6851s	
24801/30300 (epoch 40.926), train_loss = 1.04358550, grad/param norm = 1.6927e-01, time/batch = 0.7288s	
24802/30300 (epoch 40.927), train_loss = 1.03428114, grad/param norm = 1.8858e-01, time/batch = 0.7006s	
24803/30300 (epoch 40.929), train_loss = 0.94642533, grad/param norm = 1.8660e-01, time/batch = 0.6835s	
24804/30300 (epoch 40.931), train_loss = 1.08217055, grad/param norm = 1.9644e-01, time/batch = 0.6847s	
24805/30300 (epoch 40.932), train_loss = 0.91021306, grad/param norm = 1.5059e-01, time/batch = 0.6824s	
24806/30300 (epoch 40.934), train_loss = 1.04315812, grad/param norm = 1.7543e-01, time/batch = 0.6833s	
24807/30300 (epoch 40.936), train_loss = 0.94489024, grad/param norm = 1.8241e-01, time/batch = 0.6800s	
24808/30300 (epoch 40.937), train_loss = 0.96162901, grad/param norm = 1.7154e-01, time/batch = 0.6914s	
24809/30300 (epoch 40.939), train_loss = 1.09720784, grad/param norm = 1.7607e-01, time/batch = 0.6879s	
24810/30300 (epoch 40.941), train_loss = 0.98748415, grad/param norm = 1.7402e-01, time/batch = 0.6996s	
24811/30300 (epoch 40.942), train_loss = 0.99078277, grad/param norm = 1.7145e-01, time/batch = 0.7129s	
24812/30300 (epoch 40.944), train_loss = 0.88921636, grad/param norm = 1.4825e-01, time/batch = 0.6923s	
24813/30300 (epoch 40.946), train_loss = 1.07850402, grad/param norm = 2.4982e-01, time/batch = 0.7198s	
24814/30300 (epoch 40.947), train_loss = 1.07056247, grad/param norm = 2.4333e-01, time/batch = 0.6900s	
24815/30300 (epoch 40.949), train_loss = 1.09332710, grad/param norm = 2.4204e-01, time/batch = 0.6830s	
24816/30300 (epoch 40.950), train_loss = 1.11770479, grad/param norm = 1.9542e-01, time/batch = 0.6840s	
24817/30300 (epoch 40.952), train_loss = 1.06476208, grad/param norm = 2.0642e-01, time/batch = 0.6840s	
24818/30300 (epoch 40.954), train_loss = 1.25065152, grad/param norm = 1.8396e-01, time/batch = 0.6831s	
24819/30300 (epoch 40.955), train_loss = 0.99452905, grad/param norm = 1.5990e-01, time/batch = 0.6852s	
24820/30300 (epoch 40.957), train_loss = 1.08377274, grad/param norm = 1.8813e-01, time/batch = 0.6933s	
24821/30300 (epoch 40.959), train_loss = 0.93383093, grad/param norm = 1.8761e-01, time/batch = 0.6969s	
24822/30300 (epoch 40.960), train_loss = 0.97766201, grad/param norm = 1.8093e-01, time/batch = 0.6944s	
24823/30300 (epoch 40.962), train_loss = 0.96166362, grad/param norm = 2.2404e-01, time/batch = 0.7016s	
24824/30300 (epoch 40.964), train_loss = 0.92328518, grad/param norm = 1.9088e-01, time/batch = 0.7033s	
24825/30300 (epoch 40.965), train_loss = 0.93032401, grad/param norm = 1.8640e-01, time/batch = 0.6898s	
24826/30300 (epoch 40.967), train_loss = 0.98350789, grad/param norm = 1.9772e-01, time/batch = 0.6943s	
24827/30300 (epoch 40.969), train_loss = 0.94362160, grad/param norm = 2.0710e-01, time/batch = 0.6939s	
24828/30300 (epoch 40.970), train_loss = 0.97345888, grad/param norm = 1.6525e-01, time/batch = 0.6912s	
24829/30300 (epoch 40.972), train_loss = 0.90679570, grad/param norm = 1.9452e-01, time/batch = 0.6857s	
24830/30300 (epoch 40.974), train_loss = 1.13572782, grad/param norm = 1.9015e-01, time/batch = 0.6825s	
24831/30300 (epoch 40.975), train_loss = 1.14643741, grad/param norm = 2.2547e-01, time/batch = 0.6880s	
24832/30300 (epoch 40.977), train_loss = 1.18989449, grad/param norm = 1.7779e-01, time/batch = 0.6841s	
24833/30300 (epoch 40.979), train_loss = 1.08468704, grad/param norm = 1.9229e-01, time/batch = 0.6862s	
24834/30300 (epoch 40.980), train_loss = 1.10939162, grad/param norm = 2.0351e-01, time/batch = 0.6844s	
24835/30300 (epoch 40.982), train_loss = 1.08935063, grad/param norm = 1.8920e-01, time/batch = 0.6850s	
24836/30300 (epoch 40.983), train_loss = 1.12063199, grad/param norm = 1.6676e-01, time/batch = 0.6836s	
24837/30300 (epoch 40.985), train_loss = 1.06742985, grad/param norm = 2.0748e-01, time/batch = 0.6829s	
24838/30300 (epoch 40.987), train_loss = 1.03835210, grad/param norm = 1.6724e-01, time/batch = 0.6838s	
24839/30300 (epoch 40.988), train_loss = 1.12935472, grad/param norm = 1.9059e-01, time/batch = 0.6819s	
24840/30300 (epoch 40.990), train_loss = 0.94583379, grad/param norm = 2.2998e-01, time/batch = 0.6828s	
24841/30300 (epoch 40.992), train_loss = 1.10831575, grad/param norm = 1.6951e-01, time/batch = 0.6855s	
24842/30300 (epoch 40.993), train_loss = 1.10699873, grad/param norm = 2.7256e-01, time/batch = 0.6843s	
24843/30300 (epoch 40.995), train_loss = 1.00723243, grad/param norm = 2.1302e-01, time/batch = 0.6838s	
24844/30300 (epoch 40.997), train_loss = 1.07593698, grad/param norm = 1.8498e-01, time/batch = 0.6815s	
24845/30300 (epoch 40.998), train_loss = 1.09251664, grad/param norm = 1.8690e-01, time/batch = 0.6815s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
24846/30300 (epoch 41.000), train_loss = 0.96443732, grad/param norm = 2.1138e-01, time/batch = 0.6815s	
24847/30300 (epoch 41.002), train_loss = 1.13453637, grad/param norm = 1.9626e-01, time/batch = 0.6831s	
24848/30300 (epoch 41.003), train_loss = 1.04786716, grad/param norm = 1.8147e-01, time/batch = 0.6866s	
24849/30300 (epoch 41.005), train_loss = 0.99711152, grad/param norm = 1.9751e-01, time/batch = 0.6839s	
24850/30300 (epoch 41.007), train_loss = 1.09277056, grad/param norm = 1.9796e-01, time/batch = 0.6868s	
24851/30300 (epoch 41.008), train_loss = 1.02172575, grad/param norm = 2.3469e-01, time/batch = 0.6874s	
24852/30300 (epoch 41.010), train_loss = 0.91195071, grad/param norm = 1.8456e-01, time/batch = 0.6900s	
24853/30300 (epoch 41.012), train_loss = 0.98851540, grad/param norm = 1.7743e-01, time/batch = 0.6804s	
24854/30300 (epoch 41.013), train_loss = 1.11193616, grad/param norm = 2.0456e-01, time/batch = 0.6819s	
24855/30300 (epoch 41.015), train_loss = 0.96760424, grad/param norm = 1.5895e-01, time/batch = 0.6826s	
24856/30300 (epoch 41.017), train_loss = 0.99764962, grad/param norm = 1.5558e-01, time/batch = 0.6830s	
24857/30300 (epoch 41.018), train_loss = 0.92129390, grad/param norm = 1.9064e-01, time/batch = 0.6838s	
24858/30300 (epoch 41.020), train_loss = 1.11713869, grad/param norm = 2.0681e-01, time/batch = 0.6844s	
24859/30300 (epoch 41.021), train_loss = 1.14494006, grad/param norm = 1.8216e-01, time/batch = 0.6828s	
24860/30300 (epoch 41.023), train_loss = 1.02907940, grad/param norm = 1.5689e-01, time/batch = 0.6877s	
24861/30300 (epoch 41.025), train_loss = 0.94708416, grad/param norm = 1.7527e-01, time/batch = 0.6845s	
24862/30300 (epoch 41.026), train_loss = 1.09483729, grad/param norm = 2.3189e-01, time/batch = 0.6869s	
24863/30300 (epoch 41.028), train_loss = 1.08255381, grad/param norm = 1.6983e-01, time/batch = 0.6827s	
24864/30300 (epoch 41.030), train_loss = 0.97674452, grad/param norm = 1.9178e-01, time/batch = 0.6827s	
24865/30300 (epoch 41.031), train_loss = 1.03860989, grad/param norm = 1.7574e-01, time/batch = 0.6810s	
24866/30300 (epoch 41.033), train_loss = 1.04210240, grad/param norm = 1.7269e-01, time/batch = 0.6830s	
24867/30300 (epoch 41.035), train_loss = 1.06372176, grad/param norm = 1.9643e-01, time/batch = 0.6824s	
24868/30300 (epoch 41.036), train_loss = 1.03746601, grad/param norm = 1.6619e-01, time/batch = 0.6812s	
24869/30300 (epoch 41.038), train_loss = 1.06291372, grad/param norm = 1.5963e-01, time/batch = 0.6816s	
24870/30300 (epoch 41.040), train_loss = 0.88513770, grad/param norm = 1.6706e-01, time/batch = 0.6805s	
24871/30300 (epoch 41.041), train_loss = 0.86435567, grad/param norm = 1.8532e-01, time/batch = 0.6848s	
24872/30300 (epoch 41.043), train_loss = 1.05452647, grad/param norm = 1.7786e-01, time/batch = 0.6807s	
24873/30300 (epoch 41.045), train_loss = 0.95878834, grad/param norm = 1.6404e-01, time/batch = 0.6821s	
24874/30300 (epoch 41.046), train_loss = 1.14443917, grad/param norm = 2.1079e-01, time/batch = 0.6824s	
24875/30300 (epoch 41.048), train_loss = 1.04187766, grad/param norm = 2.1082e-01, time/batch = 0.6818s	
24876/30300 (epoch 41.050), train_loss = 0.93964141, grad/param norm = 1.9266e-01, time/batch = 0.6831s	
24877/30300 (epoch 41.051), train_loss = 1.04704635, grad/param norm = 2.0717e-01, time/batch = 0.6872s	
24878/30300 (epoch 41.053), train_loss = 0.90627774, grad/param norm = 2.2307e-01, time/batch = 0.6839s	
24879/30300 (epoch 41.054), train_loss = 1.07838078, grad/param norm = 2.0002e-01, time/batch = 0.6840s	
24880/30300 (epoch 41.056), train_loss = 0.93856522, grad/param norm = 1.6266e-01, time/batch = 0.6834s	
24881/30300 (epoch 41.058), train_loss = 0.98544928, grad/param norm = 1.6235e-01, time/batch = 0.6848s	
24882/30300 (epoch 41.059), train_loss = 0.98799527, grad/param norm = 2.0616e-01, time/batch = 0.6849s	
24883/30300 (epoch 41.061), train_loss = 1.06501545, grad/param norm = 1.8090e-01, time/batch = 0.6885s	
24884/30300 (epoch 41.063), train_loss = 0.91668591, grad/param norm = 1.8301e-01, time/batch = 0.6849s	
24885/30300 (epoch 41.064), train_loss = 1.00486360, grad/param norm = 2.0525e-01, time/batch = 0.6839s	
24886/30300 (epoch 41.066), train_loss = 1.01411626, grad/param norm = 1.6636e-01, time/batch = 0.6826s	
24887/30300 (epoch 41.068), train_loss = 0.93659445, grad/param norm = 1.7001e-01, time/batch = 0.6838s	
24888/30300 (epoch 41.069), train_loss = 1.06511057, grad/param norm = 1.7669e-01, time/batch = 0.6863s	
24889/30300 (epoch 41.071), train_loss = 1.07198385, grad/param norm = 2.1279e-01, time/batch = 0.6825s	
24890/30300 (epoch 41.073), train_loss = 0.94290766, grad/param norm = 1.9279e-01, time/batch = 0.6818s	
24891/30300 (epoch 41.074), train_loss = 0.98350913, grad/param norm = 1.6009e-01, time/batch = 0.6864s	
24892/30300 (epoch 41.076), train_loss = 0.99984265, grad/param norm = 1.6935e-01, time/batch = 0.6827s	
24893/30300 (epoch 41.078), train_loss = 0.93457282, grad/param norm = 1.6166e-01, time/batch = 0.6831s	
24894/30300 (epoch 41.079), train_loss = 0.97869457, grad/param norm = 1.9288e-01, time/batch = 0.6845s	
24895/30300 (epoch 41.081), train_loss = 1.02050194, grad/param norm = 1.9530e-01, time/batch = 0.6938s	
24896/30300 (epoch 41.083), train_loss = 1.09131891, grad/param norm = 2.4906e-01, time/batch = 0.6959s	
24897/30300 (epoch 41.084), train_loss = 0.95875386, grad/param norm = 1.7058e-01, time/batch = 0.7005s	
24898/30300 (epoch 41.086), train_loss = 0.96315174, grad/param norm = 2.1731e-01, time/batch = 0.7062s	
24899/30300 (epoch 41.087), train_loss = 0.94610510, grad/param norm = 1.6034e-01, time/batch = 0.6945s	
24900/30300 (epoch 41.089), train_loss = 0.93129236, grad/param norm = 1.6238e-01, time/batch = 0.6860s	
24901/30300 (epoch 41.091), train_loss = 1.04282252, grad/param norm = 1.8285e-01, time/batch = 0.6848s	
24902/30300 (epoch 41.092), train_loss = 1.07609727, grad/param norm = 1.7094e-01, time/batch = 0.6860s	
24903/30300 (epoch 41.094), train_loss = 1.11882731, grad/param norm = 1.8873e-01, time/batch = 0.6885s	
24904/30300 (epoch 41.096), train_loss = 1.12895376, grad/param norm = 2.0605e-01, time/batch = 0.6883s	
24905/30300 (epoch 41.097), train_loss = 0.96230195, grad/param norm = 2.2073e-01, time/batch = 0.6912s	
24906/30300 (epoch 41.099), train_loss = 1.07137182, grad/param norm = 1.6337e-01, time/batch = 0.6883s	
24907/30300 (epoch 41.101), train_loss = 1.11345780, grad/param norm = 2.2258e-01, time/batch = 0.6927s	
24908/30300 (epoch 41.102), train_loss = 0.95446428, grad/param norm = 2.0639e-01, time/batch = 0.6898s	
24909/30300 (epoch 41.104), train_loss = 0.98131884, grad/param norm = 2.0136e-01, time/batch = 0.6845s	
24910/30300 (epoch 41.106), train_loss = 0.95518435, grad/param norm = 1.8818e-01, time/batch = 0.6856s	
24911/30300 (epoch 41.107), train_loss = 1.05864861, grad/param norm = 1.6211e-01, time/batch = 0.6875s	
24912/30300 (epoch 41.109), train_loss = 1.08325183, grad/param norm = 1.9945e-01, time/batch = 0.6868s	
24913/30300 (epoch 41.111), train_loss = 1.07044630, grad/param norm = 2.0072e-01, time/batch = 0.6835s	
24914/30300 (epoch 41.112), train_loss = 1.13772313, grad/param norm = 1.8540e-01, time/batch = 0.6837s	
24915/30300 (epoch 41.114), train_loss = 0.97944556, grad/param norm = 1.6054e-01, time/batch = 0.6878s	
24916/30300 (epoch 41.116), train_loss = 1.07036066, grad/param norm = 2.2622e-01, time/batch = 0.6922s	
24917/30300 (epoch 41.117), train_loss = 1.11691146, grad/param norm = 1.7698e-01, time/batch = 0.6904s	
24918/30300 (epoch 41.119), train_loss = 0.92079140, grad/param norm = 1.8544e-01, time/batch = 0.6841s	
24919/30300 (epoch 41.120), train_loss = 1.00358960, grad/param norm = 2.0303e-01, time/batch = 0.6861s	
24920/30300 (epoch 41.122), train_loss = 1.11653165, grad/param norm = 2.3101e-01, time/batch = 0.6866s	
24921/30300 (epoch 41.124), train_loss = 1.16333380, grad/param norm = 1.8859e-01, time/batch = 0.6857s	
24922/30300 (epoch 41.125), train_loss = 0.91959097, grad/param norm = 1.6419e-01, time/batch = 0.6832s	
24923/30300 (epoch 41.127), train_loss = 1.04195143, grad/param norm = 2.0731e-01, time/batch = 0.6859s	
24924/30300 (epoch 41.129), train_loss = 1.08098912, grad/param norm = 1.7633e-01, time/batch = 0.6912s	
24925/30300 (epoch 41.130), train_loss = 1.15694276, grad/param norm = 1.9282e-01, time/batch = 0.6871s	
24926/30300 (epoch 41.132), train_loss = 1.13232397, grad/param norm = 1.8649e-01, time/batch = 0.6830s	
24927/30300 (epoch 41.134), train_loss = 0.92997677, grad/param norm = 1.8647e-01, time/batch = 0.6837s	
24928/30300 (epoch 41.135), train_loss = 0.96794070, grad/param norm = 1.8792e-01, time/batch = 0.6836s	
24929/30300 (epoch 41.137), train_loss = 1.02269915, grad/param norm = 2.0786e-01, time/batch = 0.6824s	
24930/30300 (epoch 41.139), train_loss = 0.95577571, grad/param norm = 2.5154e-01, time/batch = 0.6831s	
24931/30300 (epoch 41.140), train_loss = 1.02304126, grad/param norm = 1.9795e-01, time/batch = 0.7087s	
24932/30300 (epoch 41.142), train_loss = 1.08377198, grad/param norm = 2.2885e-01, time/batch = 0.6906s	
24933/30300 (epoch 41.144), train_loss = 0.94648235, grad/param norm = 2.1950e-01, time/batch = 0.6922s	
24934/30300 (epoch 41.145), train_loss = 1.07697086, grad/param norm = 2.7960e-01, time/batch = 0.6840s	
24935/30300 (epoch 41.147), train_loss = 0.97359796, grad/param norm = 1.7182e-01, time/batch = 0.6814s	
24936/30300 (epoch 41.149), train_loss = 1.08534064, grad/param norm = 2.0646e-01, time/batch = 0.6819s	
24937/30300 (epoch 41.150), train_loss = 0.99550235, grad/param norm = 2.0433e-01, time/batch = 0.6798s	
24938/30300 (epoch 41.152), train_loss = 0.91961574, grad/param norm = 2.1570e-01, time/batch = 0.6816s	
24939/30300 (epoch 41.153), train_loss = 1.04330240, grad/param norm = 1.9928e-01, time/batch = 0.6842s	
24940/30300 (epoch 41.155), train_loss = 0.91316520, grad/param norm = 1.8305e-01, time/batch = 0.6849s	
24941/30300 (epoch 41.157), train_loss = 0.97448119, grad/param norm = 1.9833e-01, time/batch = 0.6889s	
24942/30300 (epoch 41.158), train_loss = 1.07900122, grad/param norm = 2.4609e-01, time/batch = 0.6911s	
24943/30300 (epoch 41.160), train_loss = 0.94682200, grad/param norm = 1.8208e-01, time/batch = 0.6861s	
24944/30300 (epoch 41.162), train_loss = 1.02137554, grad/param norm = 1.7495e-01, time/batch = 0.6863s	
24945/30300 (epoch 41.163), train_loss = 1.02153996, grad/param norm = 2.1075e-01, time/batch = 0.6841s	
24946/30300 (epoch 41.165), train_loss = 1.14021785, grad/param norm = 1.9703e-01, time/batch = 0.6844s	
24947/30300 (epoch 41.167), train_loss = 1.02897654, grad/param norm = 1.8588e-01, time/batch = 0.6847s	
24948/30300 (epoch 41.168), train_loss = 1.05347471, grad/param norm = 1.7612e-01, time/batch = 0.6903s	
24949/30300 (epoch 41.170), train_loss = 1.04485956, grad/param norm = 2.0878e-01, time/batch = 0.6865s	
24950/30300 (epoch 41.172), train_loss = 1.03961784, grad/param norm = 2.7805e-01, time/batch = 0.6823s	
24951/30300 (epoch 41.173), train_loss = 0.99492081, grad/param norm = 2.1086e-01, time/batch = 0.6858s	
24952/30300 (epoch 41.175), train_loss = 1.04259383, grad/param norm = 2.0088e-01, time/batch = 0.6857s	
24953/30300 (epoch 41.177), train_loss = 1.07702350, grad/param norm = 1.9240e-01, time/batch = 0.6847s	
24954/30300 (epoch 41.178), train_loss = 0.85314027, grad/param norm = 1.5913e-01, time/batch = 0.6883s	
24955/30300 (epoch 41.180), train_loss = 0.99800064, grad/param norm = 1.7184e-01, time/batch = 0.6858s	
24956/30300 (epoch 41.182), train_loss = 1.03699215, grad/param norm = 1.8852e-01, time/batch = 0.6897s	
24957/30300 (epoch 41.183), train_loss = 0.96511148, grad/param norm = 2.1147e-01, time/batch = 0.6862s	
24958/30300 (epoch 41.185), train_loss = 1.14808802, grad/param norm = 2.1832e-01, time/batch = 0.6845s	
24959/30300 (epoch 41.186), train_loss = 1.25195710, grad/param norm = 2.4337e-01, time/batch = 0.6848s	
24960/30300 (epoch 41.188), train_loss = 1.06598659, grad/param norm = 2.0753e-01, time/batch = 0.6838s	
24961/30300 (epoch 41.190), train_loss = 1.00680474, grad/param norm = 1.8066e-01, time/batch = 0.6845s	
24962/30300 (epoch 41.191), train_loss = 1.07793084, grad/param norm = 1.9565e-01, time/batch = 0.6904s	
24963/30300 (epoch 41.193), train_loss = 0.92586725, grad/param norm = 1.7247e-01, time/batch = 0.6967s	
24964/30300 (epoch 41.195), train_loss = 0.96787803, grad/param norm = 1.7535e-01, time/batch = 0.6865s	
24965/30300 (epoch 41.196), train_loss = 1.05276034, grad/param norm = 2.1502e-01, time/batch = 0.6857s	
24966/30300 (epoch 41.198), train_loss = 0.87172926, grad/param norm = 1.5847e-01, time/batch = 0.6837s	
24967/30300 (epoch 41.200), train_loss = 0.98399059, grad/param norm = 1.7381e-01, time/batch = 0.6832s	
24968/30300 (epoch 41.201), train_loss = 1.11048865, grad/param norm = 2.2872e-01, time/batch = 0.6828s	
24969/30300 (epoch 41.203), train_loss = 1.01506481, grad/param norm = 1.8816e-01, time/batch = 0.6832s	
24970/30300 (epoch 41.205), train_loss = 1.19414944, grad/param norm = 2.2449e-01, time/batch = 0.6825s	
24971/30300 (epoch 41.206), train_loss = 1.10536995, grad/param norm = 2.1009e-01, time/batch = 0.6850s	
24972/30300 (epoch 41.208), train_loss = 1.08936302, grad/param norm = 2.1891e-01, time/batch = 0.6904s	
24973/30300 (epoch 41.210), train_loss = 1.11465550, grad/param norm = 2.3114e-01, time/batch = 0.6995s	
24974/30300 (epoch 41.211), train_loss = 1.14623353, grad/param norm = 2.0292e-01, time/batch = 0.7225s	
24975/30300 (epoch 41.213), train_loss = 1.04122937, grad/param norm = 1.6235e-01, time/batch = 0.7299s	
24976/30300 (epoch 41.215), train_loss = 0.94647744, grad/param norm = 1.9140e-01, time/batch = 0.7071s	
24977/30300 (epoch 41.216), train_loss = 0.97406990, grad/param norm = 1.7698e-01, time/batch = 0.6892s	
24978/30300 (epoch 41.218), train_loss = 0.93670344, grad/param norm = 1.6027e-01, time/batch = 0.6825s	
24979/30300 (epoch 41.219), train_loss = 0.89995356, grad/param norm = 1.6370e-01, time/batch = 0.6794s	
24980/30300 (epoch 41.221), train_loss = 0.86380956, grad/param norm = 1.4983e-01, time/batch = 0.6798s	
24981/30300 (epoch 41.223), train_loss = 1.01996803, grad/param norm = 1.7182e-01, time/batch = 0.6819s	
24982/30300 (epoch 41.224), train_loss = 0.85530511, grad/param norm = 1.6835e-01, time/batch = 0.6899s	
24983/30300 (epoch 41.226), train_loss = 1.07655567, grad/param norm = 2.4158e-01, time/batch = 0.6973s	
24984/30300 (epoch 41.228), train_loss = 1.14182922, grad/param norm = 1.9471e-01, time/batch = 0.6917s	
24985/30300 (epoch 41.229), train_loss = 1.01665105, grad/param norm = 1.7159e-01, time/batch = 0.7143s	
24986/30300 (epoch 41.231), train_loss = 1.08812936, grad/param norm = 1.9103e-01, time/batch = 0.6855s	
24987/30300 (epoch 41.233), train_loss = 1.06673334, grad/param norm = 1.5344e-01, time/batch = 0.6844s	
24988/30300 (epoch 41.234), train_loss = 1.12049122, grad/param norm = 3.0914e-01, time/batch = 0.6820s	
24989/30300 (epoch 41.236), train_loss = 1.07402939, grad/param norm = 1.6829e-01, time/batch = 0.6811s	
24990/30300 (epoch 41.238), train_loss = 1.02572028, grad/param norm = 2.0605e-01, time/batch = 0.6893s	
24991/30300 (epoch 41.239), train_loss = 0.96307864, grad/param norm = 1.9834e-01, time/batch = 0.6867s	
24992/30300 (epoch 41.241), train_loss = 1.04829818, grad/param norm = 1.9406e-01, time/batch = 0.6875s	
24993/30300 (epoch 41.243), train_loss = 1.05046902, grad/param norm = 1.6692e-01, time/batch = 0.6894s	
24994/30300 (epoch 41.244), train_loss = 1.22270194, grad/param norm = 1.8052e-01, time/batch = 0.6981s	
24995/30300 (epoch 41.246), train_loss = 1.06822767, grad/param norm = 1.8360e-01, time/batch = 0.6977s	
24996/30300 (epoch 41.248), train_loss = 1.00943068, grad/param norm = 1.7090e-01, time/batch = 0.6960s	
24997/30300 (epoch 41.249), train_loss = 0.93609877, grad/param norm = 2.1571e-01, time/batch = 0.7024s	
24998/30300 (epoch 41.251), train_loss = 0.95451952, grad/param norm = 1.7222e-01, time/batch = 0.7066s	
24999/30300 (epoch 41.252), train_loss = 1.11258968, grad/param norm = 2.1920e-01, time/batch = 0.6846s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch41.25_2.0264.t7	
25000/30300 (epoch 41.254), train_loss = 1.11096994, grad/param norm = 1.8755e-01, time/batch = 0.6920s	
25001/30300 (epoch 41.256), train_loss = 1.65533823, grad/param norm = 2.4141e-01, time/batch = 0.6963s	
25002/30300 (epoch 41.257), train_loss = 1.10214534, grad/param norm = 2.0503e-01, time/batch = 0.6892s	
25003/30300 (epoch 41.259), train_loss = 1.02071093, grad/param norm = 1.8724e-01, time/batch = 0.6835s	
25004/30300 (epoch 41.261), train_loss = 1.16257890, grad/param norm = 1.8799e-01, time/batch = 0.6817s	
25005/30300 (epoch 41.262), train_loss = 0.94792068, grad/param norm = 1.5920e-01, time/batch = 0.6823s	
25006/30300 (epoch 41.264), train_loss = 1.02247235, grad/param norm = 2.0523e-01, time/batch = 0.6819s	
25007/30300 (epoch 41.266), train_loss = 1.03950840, grad/param norm = 1.8313e-01, time/batch = 0.6928s	
25008/30300 (epoch 41.267), train_loss = 1.18083230, grad/param norm = 2.3415e-01, time/batch = 0.6996s	
25009/30300 (epoch 41.269), train_loss = 1.05106387, grad/param norm = 1.7917e-01, time/batch = 0.6927s	
25010/30300 (epoch 41.271), train_loss = 1.04225353, grad/param norm = 1.7221e-01, time/batch = 0.6871s	
25011/30300 (epoch 41.272), train_loss = 1.04600515, grad/param norm = 2.0632e-01, time/batch = 0.6830s	
25012/30300 (epoch 41.274), train_loss = 1.08732978, grad/param norm = 1.8692e-01, time/batch = 0.6834s	
25013/30300 (epoch 41.276), train_loss = 1.05444691, grad/param norm = 1.9776e-01, time/batch = 0.6812s	
25014/30300 (epoch 41.277), train_loss = 0.93850210, grad/param norm = 2.1755e-01, time/batch = 0.6846s	
25015/30300 (epoch 41.279), train_loss = 1.03533305, grad/param norm = 1.8886e-01, time/batch = 0.6882s	
25016/30300 (epoch 41.281), train_loss = 1.11894019, grad/param norm = 2.2257e-01, time/batch = 0.7122s	
25017/30300 (epoch 41.282), train_loss = 1.07209164, grad/param norm = 1.8447e-01, time/batch = 0.6977s	
25018/30300 (epoch 41.284), train_loss = 1.10724075, grad/param norm = 2.2309e-01, time/batch = 0.6831s	
25019/30300 (epoch 41.285), train_loss = 1.08450037, grad/param norm = 1.6650e-01, time/batch = 0.6828s	
25020/30300 (epoch 41.287), train_loss = 1.05729891, grad/param norm = 3.0168e-01, time/batch = 0.6880s	
25021/30300 (epoch 41.289), train_loss = 1.11840990, grad/param norm = 1.9147e-01, time/batch = 0.6837s	
25022/30300 (epoch 41.290), train_loss = 0.83361849, grad/param norm = 1.8786e-01, time/batch = 0.7195s	
25023/30300 (epoch 41.292), train_loss = 0.93396798, grad/param norm = 1.7773e-01, time/batch = 0.7072s	
25024/30300 (epoch 41.294), train_loss = 1.10453341, grad/param norm = 2.8205e-01, time/batch = 0.6849s	
25025/30300 (epoch 41.295), train_loss = 0.98349371, grad/param norm = 1.8083e-01, time/batch = 0.6880s	
25026/30300 (epoch 41.297), train_loss = 0.99343257, grad/param norm = 1.6604e-01, time/batch = 0.6902s	
25027/30300 (epoch 41.299), train_loss = 1.01583746, grad/param norm = 1.8450e-01, time/batch = 0.6880s	
25028/30300 (epoch 41.300), train_loss = 0.95206075, grad/param norm = 1.8490e-01, time/batch = 0.6849s	
25029/30300 (epoch 41.302), train_loss = 1.10591644, grad/param norm = 1.7976e-01, time/batch = 0.6861s	
25030/30300 (epoch 41.304), train_loss = 0.94991362, grad/param norm = 1.6518e-01, time/batch = 0.6871s	
25031/30300 (epoch 41.305), train_loss = 1.02327205, grad/param norm = 1.6886e-01, time/batch = 0.6873s	
25032/30300 (epoch 41.307), train_loss = 1.12671479, grad/param norm = 1.8736e-01, time/batch = 0.6858s	
25033/30300 (epoch 41.309), train_loss = 1.05147838, grad/param norm = 1.8982e-01, time/batch = 0.6896s	
25034/30300 (epoch 41.310), train_loss = 1.01165474, grad/param norm = 1.6714e-01, time/batch = 0.7051s	
25035/30300 (epoch 41.312), train_loss = 1.15332924, grad/param norm = 1.9501e-01, time/batch = 0.6931s	
25036/30300 (epoch 41.314), train_loss = 1.03187599, grad/param norm = 2.0989e-01, time/batch = 0.6862s	
25037/30300 (epoch 41.315), train_loss = 0.99161914, grad/param norm = 1.8683e-01, time/batch = 0.7225s	
25038/30300 (epoch 41.317), train_loss = 1.05781484, grad/param norm = 1.7750e-01, time/batch = 0.7302s	
25039/30300 (epoch 41.318), train_loss = 1.08684601, grad/param norm = 2.0202e-01, time/batch = 0.7292s	
25040/30300 (epoch 41.320), train_loss = 1.08661918, grad/param norm = 2.0323e-01, time/batch = 0.7248s	
25041/30300 (epoch 41.322), train_loss = 0.97288963, grad/param norm = 1.6969e-01, time/batch = 0.6834s	
25042/30300 (epoch 41.323), train_loss = 1.13129595, grad/param norm = 1.9259e-01, time/batch = 0.6787s	
25043/30300 (epoch 41.325), train_loss = 1.00691528, grad/param norm = 1.7869e-01, time/batch = 0.6803s	
25044/30300 (epoch 41.327), train_loss = 1.00296848, grad/param norm = 1.5488e-01, time/batch = 0.6796s	
25045/30300 (epoch 41.328), train_loss = 1.05199213, grad/param norm = 1.6121e-01, time/batch = 0.6831s	
25046/30300 (epoch 41.330), train_loss = 1.06972162, grad/param norm = 1.7539e-01, time/batch = 0.6935s	
25047/30300 (epoch 41.332), train_loss = 1.11806404, grad/param norm = 1.9047e-01, time/batch = 0.7027s	
25048/30300 (epoch 41.333), train_loss = 0.94500021, grad/param norm = 1.8036e-01, time/batch = 0.6937s	
25049/30300 (epoch 41.335), train_loss = 0.93037917, grad/param norm = 1.7004e-01, time/batch = 0.6800s	
25050/30300 (epoch 41.337), train_loss = 1.13654425, grad/param norm = 1.6904e-01, time/batch = 0.6786s	
25051/30300 (epoch 41.338), train_loss = 0.98455165, grad/param norm = 1.6736e-01, time/batch = 0.6862s	
25052/30300 (epoch 41.340), train_loss = 0.98744057, grad/param norm = 1.8147e-01, time/batch = 0.6886s	
25053/30300 (epoch 41.342), train_loss = 1.10524697, grad/param norm = 1.9830e-01, time/batch = 0.6872s	
25054/30300 (epoch 41.343), train_loss = 1.06185243, grad/param norm = 1.6931e-01, time/batch = 0.6831s	
25055/30300 (epoch 41.345), train_loss = 1.07257789, grad/param norm = 1.7368e-01, time/batch = 0.7169s	
25056/30300 (epoch 41.347), train_loss = 0.92642373, grad/param norm = 1.6184e-01, time/batch = 0.7001s	
25057/30300 (epoch 41.348), train_loss = 0.98682512, grad/param norm = 1.6993e-01, time/batch = 0.6863s	
25058/30300 (epoch 41.350), train_loss = 1.00503790, grad/param norm = 1.9505e-01, time/batch = 0.7045s	
25059/30300 (epoch 41.351), train_loss = 1.00548506, grad/param norm = 1.8255e-01, time/batch = 0.6848s	
25060/30300 (epoch 41.353), train_loss = 0.91620478, grad/param norm = 1.6008e-01, time/batch = 0.6915s	
25061/30300 (epoch 41.355), train_loss = 0.98470582, grad/param norm = 1.6924e-01, time/batch = 0.7149s	
25062/30300 (epoch 41.356), train_loss = 1.08510414, grad/param norm = 2.2481e-01, time/batch = 0.7431s	
25063/30300 (epoch 41.358), train_loss = 1.25395246, grad/param norm = 1.7569e-01, time/batch = 0.6964s	
25064/30300 (epoch 41.360), train_loss = 0.98810211, grad/param norm = 2.0098e-01, time/batch = 0.6954s	
25065/30300 (epoch 41.361), train_loss = 1.00782237, grad/param norm = 1.6568e-01, time/batch = 0.6827s	
25066/30300 (epoch 41.363), train_loss = 1.04471163, grad/param norm = 1.7719e-01, time/batch = 0.6824s	
25067/30300 (epoch 41.365), train_loss = 0.89643545, grad/param norm = 2.0133e-01, time/batch = 0.6872s	
25068/30300 (epoch 41.366), train_loss = 0.99613699, grad/param norm = 1.6122e-01, time/batch = 0.6865s	
25069/30300 (epoch 41.368), train_loss = 0.89963232, grad/param norm = 1.8104e-01, time/batch = 0.6868s	
25070/30300 (epoch 41.370), train_loss = 0.95487028, grad/param norm = 1.9602e-01, time/batch = 0.6913s	
25071/30300 (epoch 41.371), train_loss = 1.08262813, grad/param norm = 1.8593e-01, time/batch = 0.6880s	
25072/30300 (epoch 41.373), train_loss = 0.97676785, grad/param norm = 1.5307e-01, time/batch = 0.6853s	
25073/30300 (epoch 41.375), train_loss = 0.94920347, grad/param norm = 1.5828e-01, time/batch = 0.6818s	
25074/30300 (epoch 41.376), train_loss = 0.94643045, grad/param norm = 1.4819e-01, time/batch = 0.7096s	
25075/30300 (epoch 41.378), train_loss = 0.94017691, grad/param norm = 2.0076e-01, time/batch = 0.6919s	
25076/30300 (epoch 41.380), train_loss = 1.14384909, grad/param norm = 1.8811e-01, time/batch = 0.6838s	
25077/30300 (epoch 41.381), train_loss = 0.84180361, grad/param norm = 1.4894e-01, time/batch = 0.6826s	
25078/30300 (epoch 41.383), train_loss = 0.91062568, grad/param norm = 1.7892e-01, time/batch = 0.6781s	
25079/30300 (epoch 41.384), train_loss = 1.06135865, grad/param norm = 1.9312e-01, time/batch = 0.6835s	
25080/30300 (epoch 41.386), train_loss = 0.91445012, grad/param norm = 1.7074e-01, time/batch = 0.6833s	
25081/30300 (epoch 41.388), train_loss = 0.91644655, grad/param norm = 1.6833e-01, time/batch = 0.6968s	
25082/30300 (epoch 41.389), train_loss = 1.01063082, grad/param norm = 1.8275e-01, time/batch = 0.7018s	
25083/30300 (epoch 41.391), train_loss = 1.05748144, grad/param norm = 1.7277e-01, time/batch = 0.7019s	
25084/30300 (epoch 41.393), train_loss = 0.89930797, grad/param norm = 1.4688e-01, time/batch = 0.6925s	
25085/30300 (epoch 41.394), train_loss = 1.03271856, grad/param norm = 1.5697e-01, time/batch = 0.6804s	
25086/30300 (epoch 41.396), train_loss = 1.13874528, grad/param norm = 1.6464e-01, time/batch = 0.6825s	
25087/30300 (epoch 41.398), train_loss = 0.98476078, grad/param norm = 1.7165e-01, time/batch = 0.6814s	
25088/30300 (epoch 41.399), train_loss = 0.93899379, grad/param norm = 1.9236e-01, time/batch = 0.6811s	
25089/30300 (epoch 41.401), train_loss = 1.01486832, grad/param norm = 1.9784e-01, time/batch = 0.6821s	
25090/30300 (epoch 41.403), train_loss = 1.01806893, grad/param norm = 1.8856e-01, time/batch = 0.6830s	
25091/30300 (epoch 41.404), train_loss = 0.96748612, grad/param norm = 2.0089e-01, time/batch = 0.6867s	
25092/30300 (epoch 41.406), train_loss = 1.02992341, grad/param norm = 1.7600e-01, time/batch = 0.6826s	
25093/30300 (epoch 41.408), train_loss = 0.89337868, grad/param norm = 1.6043e-01, time/batch = 0.6861s	
25094/30300 (epoch 41.409), train_loss = 0.90296594, grad/param norm = 1.8646e-01, time/batch = 0.6812s	
25095/30300 (epoch 41.411), train_loss = 0.94335230, grad/param norm = 1.4791e-01, time/batch = 0.6803s	
25096/30300 (epoch 41.413), train_loss = 0.85165527, grad/param norm = 1.7299e-01, time/batch = 0.6826s	
25097/30300 (epoch 41.414), train_loss = 1.04537031, grad/param norm = 2.0434e-01, time/batch = 0.6787s	
25098/30300 (epoch 41.416), train_loss = 0.96094290, grad/param norm = 1.8379e-01, time/batch = 0.6802s	
25099/30300 (epoch 41.417), train_loss = 0.92662989, grad/param norm = 1.8119e-01, time/batch = 0.6958s	
25100/30300 (epoch 41.419), train_loss = 0.92083213, grad/param norm = 1.6578e-01, time/batch = 0.7017s	
25101/30300 (epoch 41.421), train_loss = 0.97607778, grad/param norm = 1.9737e-01, time/batch = 0.7086s	
25102/30300 (epoch 41.422), train_loss = 1.02058932, grad/param norm = 1.8962e-01, time/batch = 0.7306s	
25103/30300 (epoch 41.424), train_loss = 1.01186225, grad/param norm = 1.7477e-01, time/batch = 0.7301s	
25104/30300 (epoch 41.426), train_loss = 0.97448296, grad/param norm = 1.6785e-01, time/batch = 0.7063s	
25105/30300 (epoch 41.427), train_loss = 0.96044390, grad/param norm = 1.7156e-01, time/batch = 0.7107s	
25106/30300 (epoch 41.429), train_loss = 0.99596395, grad/param norm = 1.5854e-01, time/batch = 0.7053s	
25107/30300 (epoch 41.431), train_loss = 1.03620469, grad/param norm = 1.7934e-01, time/batch = 0.7005s	
25108/30300 (epoch 41.432), train_loss = 1.02447008, grad/param norm = 1.8761e-01, time/batch = 0.6984s	
25109/30300 (epoch 41.434), train_loss = 0.90663167, grad/param norm = 1.6884e-01, time/batch = 0.7072s	
25110/30300 (epoch 41.436), train_loss = 1.10196675, grad/param norm = 1.6991e-01, time/batch = 0.6921s	
25111/30300 (epoch 41.437), train_loss = 0.90913226, grad/param norm = 1.7482e-01, time/batch = 0.6879s	
25112/30300 (epoch 41.439), train_loss = 0.95791147, grad/param norm = 1.8258e-01, time/batch = 0.6827s	
25113/30300 (epoch 41.441), train_loss = 0.99205313, grad/param norm = 1.5661e-01, time/batch = 0.6849s	
25114/30300 (epoch 41.442), train_loss = 0.94038596, grad/param norm = 1.5542e-01, time/batch = 0.6828s	
25115/30300 (epoch 41.444), train_loss = 0.84146514, grad/param norm = 1.6962e-01, time/batch = 0.6821s	
25116/30300 (epoch 41.446), train_loss = 0.96674627, grad/param norm = 1.6124e-01, time/batch = 0.7109s	
25117/30300 (epoch 41.447), train_loss = 0.98918121, grad/param norm = 1.6970e-01, time/batch = 0.6948s	
25118/30300 (epoch 41.449), train_loss = 0.93916228, grad/param norm = 1.5707e-01, time/batch = 0.6937s	
25119/30300 (epoch 41.450), train_loss = 1.02641204, grad/param norm = 1.5118e-01, time/batch = 0.6902s	
25120/30300 (epoch 41.452), train_loss = 1.10564088, grad/param norm = 1.6425e-01, time/batch = 0.6922s	
25121/30300 (epoch 41.454), train_loss = 1.03741921, grad/param norm = 1.6529e-01, time/batch = 0.6846s	
25122/30300 (epoch 41.455), train_loss = 1.01540192, grad/param norm = 2.2019e-01, time/batch = 0.6828s	
25123/30300 (epoch 41.457), train_loss = 0.96563440, grad/param norm = 1.6320e-01, time/batch = 0.6892s	
25124/30300 (epoch 41.459), train_loss = 1.04573621, grad/param norm = 1.8497e-01, time/batch = 0.6818s	
25125/30300 (epoch 41.460), train_loss = 1.08225483, grad/param norm = 1.5645e-01, time/batch = 0.6800s	
25126/30300 (epoch 41.462), train_loss = 1.09250959, grad/param norm = 1.8435e-01, time/batch = 0.6821s	
25127/30300 (epoch 41.464), train_loss = 0.82387147, grad/param norm = 1.7028e-01, time/batch = 0.6840s	
25128/30300 (epoch 41.465), train_loss = 0.85306867, grad/param norm = 1.4726e-01, time/batch = 0.6801s	
25129/30300 (epoch 41.467), train_loss = 0.84688642, grad/param norm = 1.5456e-01, time/batch = 0.6846s	
25130/30300 (epoch 41.469), train_loss = 0.93906418, grad/param norm = 1.7005e-01, time/batch = 0.6869s	
25131/30300 (epoch 41.470), train_loss = 0.94668487, grad/param norm = 1.6217e-01, time/batch = 0.6848s	
25132/30300 (epoch 41.472), train_loss = 0.95713292, grad/param norm = 1.5939e-01, time/batch = 0.6846s	
25133/30300 (epoch 41.474), train_loss = 0.94625552, grad/param norm = 2.1695e-01, time/batch = 0.6828s	
25134/30300 (epoch 41.475), train_loss = 0.93264017, grad/param norm = 1.6196e-01, time/batch = 0.6838s	
25135/30300 (epoch 41.477), train_loss = 0.97863019, grad/param norm = 1.6562e-01, time/batch = 0.6849s	
25136/30300 (epoch 41.479), train_loss = 0.96019573, grad/param norm = 1.6246e-01, time/batch = 0.6838s	
25137/30300 (epoch 41.480), train_loss = 1.02287433, grad/param norm = 1.7054e-01, time/batch = 0.6834s	
25138/30300 (epoch 41.482), train_loss = 1.06059721, grad/param norm = 1.6561e-01, time/batch = 0.6853s	
25139/30300 (epoch 41.483), train_loss = 0.97230647, grad/param norm = 1.6668e-01, time/batch = 0.6848s	
25140/30300 (epoch 41.485), train_loss = 1.00767545, grad/param norm = 1.5326e-01, time/batch = 0.6843s	
25141/30300 (epoch 41.487), train_loss = 1.07004579, grad/param norm = 1.7266e-01, time/batch = 0.6916s	
25142/30300 (epoch 41.488), train_loss = 1.11977882, grad/param norm = 1.4972e-01, time/batch = 0.6854s	
25143/30300 (epoch 41.490), train_loss = 0.86946646, grad/param norm = 1.6570e-01, time/batch = 0.6847s	
25144/30300 (epoch 41.492), train_loss = 0.96623993, grad/param norm = 1.7668e-01, time/batch = 0.6933s	
25145/30300 (epoch 41.493), train_loss = 1.01632631, grad/param norm = 1.7194e-01, time/batch = 0.7139s	
25146/30300 (epoch 41.495), train_loss = 0.98906612, grad/param norm = 1.6286e-01, time/batch = 0.6850s	
25147/30300 (epoch 41.497), train_loss = 1.02614801, grad/param norm = 1.6762e-01, time/batch = 0.7101s	
25148/30300 (epoch 41.498), train_loss = 1.05012213, grad/param norm = 1.6280e-01, time/batch = 0.7059s	
25149/30300 (epoch 41.500), train_loss = 0.94053975, grad/param norm = 1.8968e-01, time/batch = 0.6994s	
25150/30300 (epoch 41.502), train_loss = 1.00451452, grad/param norm = 2.0595e-01, time/batch = 0.7176s	
25151/30300 (epoch 41.503), train_loss = 1.09655510, grad/param norm = 1.7707e-01, time/batch = 0.7037s	
25152/30300 (epoch 41.505), train_loss = 0.90167301, grad/param norm = 1.6365e-01, time/batch = 0.7045s	
25153/30300 (epoch 41.507), train_loss = 0.89396661, grad/param norm = 1.6777e-01, time/batch = 0.6855s	
25154/30300 (epoch 41.508), train_loss = 0.94092791, grad/param norm = 2.0463e-01, time/batch = 0.6830s	
25155/30300 (epoch 41.510), train_loss = 1.08039177, grad/param norm = 1.9365e-01, time/batch = 0.6849s	
25156/30300 (epoch 41.512), train_loss = 0.93392710, grad/param norm = 1.6348e-01, time/batch = 0.6834s	
25157/30300 (epoch 41.513), train_loss = 1.00421138, grad/param norm = 1.7432e-01, time/batch = 0.6803s	
25158/30300 (epoch 41.515), train_loss = 0.98150227, grad/param norm = 1.6664e-01, time/batch = 0.6852s	
25159/30300 (epoch 41.517), train_loss = 0.82559033, grad/param norm = 1.5338e-01, time/batch = 0.6847s	
25160/30300 (epoch 41.518), train_loss = 1.08496720, grad/param norm = 1.9248e-01, time/batch = 0.6946s	
25161/30300 (epoch 41.520), train_loss = 0.98741590, grad/param norm = 2.2766e-01, time/batch = 0.7118s	
25162/30300 (epoch 41.521), train_loss = 0.90558525, grad/param norm = 2.1294e-01, time/batch = 0.7205s	
25163/30300 (epoch 41.523), train_loss = 1.10738005, grad/param norm = 2.0180e-01, time/batch = 0.7218s	
25164/30300 (epoch 41.525), train_loss = 0.91532439, grad/param norm = 1.6332e-01, time/batch = 0.7231s	
25165/30300 (epoch 41.526), train_loss = 1.03047847, grad/param norm = 1.7260e-01, time/batch = 0.7017s	
25166/30300 (epoch 41.528), train_loss = 0.87380101, grad/param norm = 1.5878e-01, time/batch = 0.6872s	
25167/30300 (epoch 41.530), train_loss = 0.87238199, grad/param norm = 1.6924e-01, time/batch = 0.6863s	
25168/30300 (epoch 41.531), train_loss = 0.98198079, grad/param norm = 1.7896e-01, time/batch = 0.6866s	
25169/30300 (epoch 41.533), train_loss = 0.97449832, grad/param norm = 1.8694e-01, time/batch = 0.6805s	
25170/30300 (epoch 41.535), train_loss = 0.99754547, grad/param norm = 1.6050e-01, time/batch = 0.6813s	
25171/30300 (epoch 41.536), train_loss = 1.01513348, grad/param norm = 1.7994e-01, time/batch = 0.6835s	
25172/30300 (epoch 41.538), train_loss = 0.86902716, grad/param norm = 1.6954e-01, time/batch = 0.6838s	
25173/30300 (epoch 41.540), train_loss = 0.94261161, grad/param norm = 1.9040e-01, time/batch = 0.6817s	
25174/30300 (epoch 41.541), train_loss = 0.98090824, grad/param norm = 1.7998e-01, time/batch = 0.6831s	
25175/30300 (epoch 41.543), train_loss = 0.96843995, grad/param norm = 1.6480e-01, time/batch = 0.6859s	
25176/30300 (epoch 41.545), train_loss = 1.04258904, grad/param norm = 2.0689e-01, time/batch = 0.6851s	
25177/30300 (epoch 41.546), train_loss = 1.15800056, grad/param norm = 1.6611e-01, time/batch = 0.7129s	
25178/30300 (epoch 41.548), train_loss = 0.94570299, grad/param norm = 1.5865e-01, time/batch = 0.7226s	
25179/30300 (epoch 41.550), train_loss = 1.03213200, grad/param norm = 2.0929e-01, time/batch = 0.6947s	
25180/30300 (epoch 41.551), train_loss = 0.91658034, grad/param norm = 1.6489e-01, time/batch = 0.6999s	
25181/30300 (epoch 41.553), train_loss = 0.96424212, grad/param norm = 1.6398e-01, time/batch = 0.6964s	
25182/30300 (epoch 41.554), train_loss = 0.99916241, grad/param norm = 1.7380e-01, time/batch = 0.6907s	
25183/30300 (epoch 41.556), train_loss = 1.02951433, grad/param norm = 1.6591e-01, time/batch = 0.6899s	
25184/30300 (epoch 41.558), train_loss = 1.06164838, grad/param norm = 1.7850e-01, time/batch = 0.6890s	
25185/30300 (epoch 41.559), train_loss = 1.01004502, grad/param norm = 1.9045e-01, time/batch = 0.6850s	
25186/30300 (epoch 41.561), train_loss = 0.79777106, grad/param norm = 1.6971e-01, time/batch = 0.6818s	
25187/30300 (epoch 41.563), train_loss = 0.88177777, grad/param norm = 1.5565e-01, time/batch = 0.6854s	
25188/30300 (epoch 41.564), train_loss = 0.93508316, grad/param norm = 1.5076e-01, time/batch = 0.6828s	
25189/30300 (epoch 41.566), train_loss = 0.96455875, grad/param norm = 1.7699e-01, time/batch = 0.6844s	
25190/30300 (epoch 41.568), train_loss = 0.85709287, grad/param norm = 2.8154e-01, time/batch = 0.6814s	
25191/30300 (epoch 41.569), train_loss = 1.00464076, grad/param norm = 1.6788e-01, time/batch = 0.6862s	
25192/30300 (epoch 41.571), train_loss = 1.01744052, grad/param norm = 2.1986e-01, time/batch = 0.6832s	
25193/30300 (epoch 41.573), train_loss = 1.03649235, grad/param norm = 1.7302e-01, time/batch = 0.6807s	
25194/30300 (epoch 41.574), train_loss = 1.02985735, grad/param norm = 1.6948e-01, time/batch = 0.6807s	
25195/30300 (epoch 41.576), train_loss = 0.95746464, grad/param norm = 1.4505e-01, time/batch = 0.6816s	
25196/30300 (epoch 41.578), train_loss = 0.85896944, grad/param norm = 1.5141e-01, time/batch = 0.6874s	
25197/30300 (epoch 41.579), train_loss = 1.05822658, grad/param norm = 2.2727e-01, time/batch = 0.6868s	
25198/30300 (epoch 41.581), train_loss = 1.11604495, grad/param norm = 1.8195e-01, time/batch = 0.6854s	
25199/30300 (epoch 41.583), train_loss = 1.12470870, grad/param norm = 2.1106e-01, time/batch = 0.6875s	
25200/30300 (epoch 41.584), train_loss = 1.09813788, grad/param norm = 1.7464e-01, time/batch = 0.6828s	
25201/30300 (epoch 41.586), train_loss = 0.98174249, grad/param norm = 1.7888e-01, time/batch = 0.6880s	
25202/30300 (epoch 41.587), train_loss = 0.98727949, grad/param norm = 1.8422e-01, time/batch = 0.7116s	
25203/30300 (epoch 41.589), train_loss = 0.92975334, grad/param norm = 1.7065e-01, time/batch = 0.7005s	
25204/30300 (epoch 41.591), train_loss = 1.01247465, grad/param norm = 1.5587e-01, time/batch = 0.6856s	
25205/30300 (epoch 41.592), train_loss = 0.95056245, grad/param norm = 1.4761e-01, time/batch = 0.6789s	
25206/30300 (epoch 41.594), train_loss = 1.03327038, grad/param norm = 1.6296e-01, time/batch = 0.6724s	
25207/30300 (epoch 41.596), train_loss = 0.91846731, grad/param norm = 1.5945e-01, time/batch = 0.6735s	
25208/30300 (epoch 41.597), train_loss = 0.93403575, grad/param norm = 1.7669e-01, time/batch = 0.6697s	
25209/30300 (epoch 41.599), train_loss = 0.84490376, grad/param norm = 1.4833e-01, time/batch = 0.6704s	
25210/30300 (epoch 41.601), train_loss = 1.01421421, grad/param norm = 1.7345e-01, time/batch = 0.6714s	
25211/30300 (epoch 41.602), train_loss = 0.97805945, grad/param norm = 1.6532e-01, time/batch = 0.6744s	
25212/30300 (epoch 41.604), train_loss = 0.93408482, grad/param norm = 1.8131e-01, time/batch = 0.6726s	
25213/30300 (epoch 41.606), train_loss = 0.92360451, grad/param norm = 2.0551e-01, time/batch = 0.6739s	
25214/30300 (epoch 41.607), train_loss = 1.06367389, grad/param norm = 2.0121e-01, time/batch = 0.6723s	
25215/30300 (epoch 41.609), train_loss = 1.15856886, grad/param norm = 1.9308e-01, time/batch = 0.7061s	
25216/30300 (epoch 41.611), train_loss = 0.96770080, grad/param norm = 1.6827e-01, time/batch = 0.6951s	
25217/30300 (epoch 41.612), train_loss = 0.88920090, grad/param norm = 1.4705e-01, time/batch = 0.6691s	
25218/30300 (epoch 41.614), train_loss = 0.96675821, grad/param norm = 1.5467e-01, time/batch = 0.6704s	
25219/30300 (epoch 41.616), train_loss = 0.99854704, grad/param norm = 1.8628e-01, time/batch = 0.6692s	
25220/30300 (epoch 41.617), train_loss = 0.99243756, grad/param norm = 1.8944e-01, time/batch = 0.6704s	
25221/30300 (epoch 41.619), train_loss = 0.81272377, grad/param norm = 1.4439e-01, time/batch = 0.6727s	
25222/30300 (epoch 41.620), train_loss = 1.05365230, grad/param norm = 1.9436e-01, time/batch = 0.6712s	
25223/30300 (epoch 41.622), train_loss = 0.98142221, grad/param norm = 1.8818e-01, time/batch = 0.6738s	
25224/30300 (epoch 41.624), train_loss = 0.98422718, grad/param norm = 1.7218e-01, time/batch = 0.6751s	
25225/30300 (epoch 41.625), train_loss = 0.97279373, grad/param norm = 2.1264e-01, time/batch = 0.6879s	
25226/30300 (epoch 41.627), train_loss = 1.07829177, grad/param norm = 1.8941e-01, time/batch = 0.6698s	
25227/30300 (epoch 41.629), train_loss = 1.10567500, grad/param norm = 1.6163e-01, time/batch = 0.6691s	
25228/30300 (epoch 41.630), train_loss = 0.99620453, grad/param norm = 1.8276e-01, time/batch = 0.6697s	
25229/30300 (epoch 41.632), train_loss = 1.04708029, grad/param norm = 2.0003e-01, time/batch = 0.6722s	
25230/30300 (epoch 41.634), train_loss = 0.91752259, grad/param norm = 1.6995e-01, time/batch = 0.6752s	
25231/30300 (epoch 41.635), train_loss = 1.03717606, grad/param norm = 2.1358e-01, time/batch = 0.6723s	
25232/30300 (epoch 41.637), train_loss = 1.07959289, grad/param norm = 2.2997e-01, time/batch = 0.6761s	
25233/30300 (epoch 41.639), train_loss = 0.98580388, grad/param norm = 1.8525e-01, time/batch = 0.6759s	
25234/30300 (epoch 41.640), train_loss = 1.09733030, grad/param norm = 1.9775e-01, time/batch = 0.7017s	
25235/30300 (epoch 41.642), train_loss = 0.98594104, grad/param norm = 1.6700e-01, time/batch = 0.7127s	
25236/30300 (epoch 41.644), train_loss = 1.06788776, grad/param norm = 1.7788e-01, time/batch = 0.7008s	
25237/30300 (epoch 41.645), train_loss = 0.93632338, grad/param norm = 1.5827e-01, time/batch = 0.6764s	
25238/30300 (epoch 41.647), train_loss = 0.98763145, grad/param norm = 1.7066e-01, time/batch = 0.6849s	
25239/30300 (epoch 41.649), train_loss = 0.97305929, grad/param norm = 1.9997e-01, time/batch = 0.6890s	
25240/30300 (epoch 41.650), train_loss = 1.00314760, grad/param norm = 1.7542e-01, time/batch = 0.6836s	
25241/30300 (epoch 41.652), train_loss = 0.98180829, grad/param norm = 2.3257e-01, time/batch = 0.6777s	
25242/30300 (epoch 41.653), train_loss = 1.17767540, grad/param norm = 2.0665e-01, time/batch = 0.6923s	
25243/30300 (epoch 41.655), train_loss = 0.97680577, grad/param norm = 1.7371e-01, time/batch = 0.6977s	
25244/30300 (epoch 41.657), train_loss = 0.90384891, grad/param norm = 1.8467e-01, time/batch = 0.7084s	
25245/30300 (epoch 41.658), train_loss = 0.96278760, grad/param norm = 1.6470e-01, time/batch = 0.7333s	
25246/30300 (epoch 41.660), train_loss = 0.99774113, grad/param norm = 1.7769e-01, time/batch = 0.7209s	
25247/30300 (epoch 41.662), train_loss = 1.01627005, grad/param norm = 2.0653e-01, time/batch = 0.7272s	
25248/30300 (epoch 41.663), train_loss = 1.07596667, grad/param norm = 1.7629e-01, time/batch = 0.7306s	
25249/30300 (epoch 41.665), train_loss = 0.93271944, grad/param norm = 1.9068e-01, time/batch = 0.7185s	
25250/30300 (epoch 41.667), train_loss = 1.05423541, grad/param norm = 1.8869e-01, time/batch = 0.7302s	
25251/30300 (epoch 41.668), train_loss = 1.07479825, grad/param norm = 1.8212e-01, time/batch = 0.6914s	
25252/30300 (epoch 41.670), train_loss = 1.09690273, grad/param norm = 1.6945e-01, time/batch = 0.6959s	
25253/30300 (epoch 41.672), train_loss = 1.00747692, grad/param norm = 1.7865e-01, time/batch = 0.7063s	
25254/30300 (epoch 41.673), train_loss = 1.06033110, grad/param norm = 2.2334e-01, time/batch = 0.6860s	
25255/30300 (epoch 41.675), train_loss = 0.96360933, grad/param norm = 1.8869e-01, time/batch = 0.6842s	
25256/30300 (epoch 41.677), train_loss = 0.96120549, grad/param norm = 1.7031e-01, time/batch = 0.6825s	
25257/30300 (epoch 41.678), train_loss = 0.94969543, grad/param norm = 1.5732e-01, time/batch = 0.6745s	
25258/30300 (epoch 41.680), train_loss = 0.90249969, grad/param norm = 1.5967e-01, time/batch = 0.6811s	
25259/30300 (epoch 41.682), train_loss = 0.98585532, grad/param norm = 1.7264e-01, time/batch = 0.6780s	
25260/30300 (epoch 41.683), train_loss = 1.08568129, grad/param norm = 1.7169e-01, time/batch = 0.6854s	
25261/30300 (epoch 41.685), train_loss = 1.05398828, grad/param norm = 1.7928e-01, time/batch = 0.6904s	
25262/30300 (epoch 41.686), train_loss = 0.97277300, grad/param norm = 1.5521e-01, time/batch = 0.6920s	
25263/30300 (epoch 41.688), train_loss = 0.99216050, grad/param norm = 1.5914e-01, time/batch = 0.6880s	
25264/30300 (epoch 41.690), train_loss = 0.94379208, grad/param norm = 2.0603e-01, time/batch = 0.6694s	
25265/30300 (epoch 41.691), train_loss = 0.99037958, grad/param norm = 1.8945e-01, time/batch = 0.6748s	
25266/30300 (epoch 41.693), train_loss = 1.27667902, grad/param norm = 2.0970e-01, time/batch = 0.6686s	
25267/30300 (epoch 41.695), train_loss = 1.07767749, grad/param norm = 1.8781e-01, time/batch = 0.6704s	
25268/30300 (epoch 41.696), train_loss = 1.05153926, grad/param norm = 2.1810e-01, time/batch = 0.6727s	
25269/30300 (epoch 41.698), train_loss = 0.95288301, grad/param norm = 1.7176e-01, time/batch = 0.6680s	
25270/30300 (epoch 41.700), train_loss = 0.93106199, grad/param norm = 1.7266e-01, time/batch = 0.6760s	
25271/30300 (epoch 41.701), train_loss = 0.87558351, grad/param norm = 1.6166e-01, time/batch = 0.6715s	
25272/30300 (epoch 41.703), train_loss = 0.99545287, grad/param norm = 1.6157e-01, time/batch = 0.6783s	
25273/30300 (epoch 41.705), train_loss = 0.92081090, grad/param norm = 1.7323e-01, time/batch = 0.6788s	
25274/30300 (epoch 41.706), train_loss = 1.04515575, grad/param norm = 1.6635e-01, time/batch = 0.6725s	
25275/30300 (epoch 41.708), train_loss = 0.99365504, grad/param norm = 1.6004e-01, time/batch = 0.6717s	
25276/30300 (epoch 41.710), train_loss = 0.97661201, grad/param norm = 1.6794e-01, time/batch = 0.6723s	
25277/30300 (epoch 41.711), train_loss = 0.93684002, grad/param norm = 1.7337e-01, time/batch = 0.6776s	
25278/30300 (epoch 41.713), train_loss = 0.93673855, grad/param norm = 1.6302e-01, time/batch = 0.6763s	
25279/30300 (epoch 41.715), train_loss = 0.96563404, grad/param norm = 1.7563e-01, time/batch = 0.6788s	
25280/30300 (epoch 41.716), train_loss = 1.05580418, grad/param norm = 1.6815e-01, time/batch = 0.6808s	
25281/30300 (epoch 41.718), train_loss = 1.09801330, grad/param norm = 1.8057e-01, time/batch = 0.6776s	
25282/30300 (epoch 41.719), train_loss = 0.94760291, grad/param norm = 1.8416e-01, time/batch = 0.7156s	
25283/30300 (epoch 41.721), train_loss = 0.97579593, grad/param norm = 1.8019e-01, time/batch = 0.6880s	
25284/30300 (epoch 41.723), train_loss = 0.92116143, grad/param norm = 1.5018e-01, time/batch = 0.6740s	
25285/30300 (epoch 41.724), train_loss = 1.01600797, grad/param norm = 1.8313e-01, time/batch = 0.6739s	
25286/30300 (epoch 41.726), train_loss = 1.24604222, grad/param norm = 2.1745e-01, time/batch = 0.6784s	
25287/30300 (epoch 41.728), train_loss = 1.02647916, grad/param norm = 1.8520e-01, time/batch = 0.6795s	
25288/30300 (epoch 41.729), train_loss = 0.95748476, grad/param norm = 1.7763e-01, time/batch = 0.6730s	
25289/30300 (epoch 41.731), train_loss = 0.96878531, grad/param norm = 1.9115e-01, time/batch = 0.6757s	
25290/30300 (epoch 41.733), train_loss = 1.00335459, grad/param norm = 1.8020e-01, time/batch = 0.6717s	
25291/30300 (epoch 41.734), train_loss = 1.08137239, grad/param norm = 1.7494e-01, time/batch = 0.6757s	
25292/30300 (epoch 41.736), train_loss = 1.01510648, grad/param norm = 1.6962e-01, time/batch = 0.6736s	
25293/30300 (epoch 41.738), train_loss = 0.93205770, grad/param norm = 1.3466e-01, time/batch = 0.6698s	
25294/30300 (epoch 41.739), train_loss = 1.10770404, grad/param norm = 1.9750e-01, time/batch = 0.6705s	
25295/30300 (epoch 41.741), train_loss = 1.14047240, grad/param norm = 1.8006e-01, time/batch = 0.6746s	
25296/30300 (epoch 41.743), train_loss = 0.96981858, grad/param norm = 1.7511e-01, time/batch = 0.6772s	
25297/30300 (epoch 41.744), train_loss = 1.03951990, grad/param norm = 1.6867e-01, time/batch = 0.6686s	
25298/30300 (epoch 41.746), train_loss = 0.96028647, grad/param norm = 1.5549e-01, time/batch = 0.6731s	
25299/30300 (epoch 41.748), train_loss = 0.98535317, grad/param norm = 1.9047e-01, time/batch = 0.6722s	
25300/30300 (epoch 41.749), train_loss = 0.99636484, grad/param norm = 1.5756e-01, time/batch = 0.6715s	
25301/30300 (epoch 41.751), train_loss = 1.05805757, grad/param norm = 2.1969e-01, time/batch = 0.7116s	
25302/30300 (epoch 41.752), train_loss = 0.98204970, grad/param norm = 1.7911e-01, time/batch = 0.6944s	
25303/30300 (epoch 41.754), train_loss = 0.99354741, grad/param norm = 1.5807e-01, time/batch = 0.6787s	
25304/30300 (epoch 41.756), train_loss = 0.97924620, grad/param norm = 1.7948e-01, time/batch = 0.6679s	
25305/30300 (epoch 41.757), train_loss = 0.93085220, grad/param norm = 1.7706e-01, time/batch = 0.6709s	
25306/30300 (epoch 41.759), train_loss = 1.01656723, grad/param norm = 1.6277e-01, time/batch = 0.6705s	
25307/30300 (epoch 41.761), train_loss = 0.87178235, grad/param norm = 1.6083e-01, time/batch = 0.6700s	
25308/30300 (epoch 41.762), train_loss = 0.88438234, grad/param norm = 1.7691e-01, time/batch = 0.6700s	
25309/30300 (epoch 41.764), train_loss = 0.97014729, grad/param norm = 1.7326e-01, time/batch = 0.6709s	
25310/30300 (epoch 41.766), train_loss = 1.10128632, grad/param norm = 1.9110e-01, time/batch = 0.6767s	
25311/30300 (epoch 41.767), train_loss = 0.99267620, grad/param norm = 1.9764e-01, time/batch = 0.6762s	
25312/30300 (epoch 41.769), train_loss = 1.00627211, grad/param norm = 1.7664e-01, time/batch = 0.6721s	
25313/30300 (epoch 41.771), train_loss = 0.92918547, grad/param norm = 2.1106e-01, time/batch = 0.6758s	
25314/30300 (epoch 41.772), train_loss = 0.99521526, grad/param norm = 1.6916e-01, time/batch = 0.6759s	
25315/30300 (epoch 41.774), train_loss = 1.14861078, grad/param norm = 1.7091e-01, time/batch = 0.6829s	
25316/30300 (epoch 41.776), train_loss = 0.97604064, grad/param norm = 1.9556e-01, time/batch = 0.7139s	
25317/30300 (epoch 41.777), train_loss = 1.12312536, grad/param norm = 1.6953e-01, time/batch = 0.6897s	
25318/30300 (epoch 41.779), train_loss = 1.12176899, grad/param norm = 2.0639e-01, time/batch = 0.6734s	
25319/30300 (epoch 41.781), train_loss = 1.01077799, grad/param norm = 1.9235e-01, time/batch = 0.6690s	
25320/30300 (epoch 41.782), train_loss = 0.92321422, grad/param norm = 2.0827e-01, time/batch = 0.6815s	
25321/30300 (epoch 41.784), train_loss = 0.96319002, grad/param norm = 1.6891e-01, time/batch = 0.6836s	
25322/30300 (epoch 41.785), train_loss = 1.06615729, grad/param norm = 2.1015e-01, time/batch = 0.6950s	
25323/30300 (epoch 41.787), train_loss = 0.84402362, grad/param norm = 1.7883e-01, time/batch = 0.7139s	
25324/30300 (epoch 41.789), train_loss = 1.14576987, grad/param norm = 1.9132e-01, time/batch = 0.7142s	
25325/30300 (epoch 41.790), train_loss = 0.99050496, grad/param norm = 1.7430e-01, time/batch = 0.7102s	
25326/30300 (epoch 41.792), train_loss = 0.79761431, grad/param norm = 1.6286e-01, time/batch = 0.7039s	
25327/30300 (epoch 41.794), train_loss = 1.00246516, grad/param norm = 1.8571e-01, time/batch = 0.6941s	
25328/30300 (epoch 41.795), train_loss = 0.92624035, grad/param norm = 1.5393e-01, time/batch = 0.6836s	
25329/30300 (epoch 41.797), train_loss = 1.13991596, grad/param norm = 2.0759e-01, time/batch = 0.6727s	
25330/30300 (epoch 41.799), train_loss = 1.08247633, grad/param norm = 2.2458e-01, time/batch = 0.6746s	
25331/30300 (epoch 41.800), train_loss = 1.06147640, grad/param norm = 1.6982e-01, time/batch = 0.6736s	
25332/30300 (epoch 41.802), train_loss = 1.23487626, grad/param norm = 1.8594e-01, time/batch = 0.6730s	
25333/30300 (epoch 41.804), train_loss = 1.04694382, grad/param norm = 1.8412e-01, time/batch = 0.6719s	
25334/30300 (epoch 41.805), train_loss = 1.12526370, grad/param norm = 1.8354e-01, time/batch = 0.6894s	
25335/30300 (epoch 41.807), train_loss = 0.96475927, grad/param norm = 1.7764e-01, time/batch = 0.7183s	
25336/30300 (epoch 41.809), train_loss = 1.09132314, grad/param norm = 1.8271e-01, time/batch = 0.6748s	
25337/30300 (epoch 41.810), train_loss = 1.05090692, grad/param norm = 1.8444e-01, time/batch = 0.6776s	
25338/30300 (epoch 41.812), train_loss = 0.96558157, grad/param norm = 1.7364e-01, time/batch = 0.6794s	
25339/30300 (epoch 41.814), train_loss = 1.02065622, grad/param norm = 1.8273e-01, time/batch = 0.6788s	
25340/30300 (epoch 41.815), train_loss = 1.02527397, grad/param norm = 2.0812e-01, time/batch = 0.6752s	
25341/30300 (epoch 41.817), train_loss = 1.07977175, grad/param norm = 1.9852e-01, time/batch = 0.7109s	
25342/30300 (epoch 41.818), train_loss = 1.03558384, grad/param norm = 2.0242e-01, time/batch = 0.6859s	
25343/30300 (epoch 41.820), train_loss = 1.16369724, grad/param norm = 1.8101e-01, time/batch = 0.6720s	
25344/30300 (epoch 41.822), train_loss = 1.16679962, grad/param norm = 2.1561e-01, time/batch = 0.6721s	
25345/30300 (epoch 41.823), train_loss = 1.13417624, grad/param norm = 1.8926e-01, time/batch = 0.6722s	
25346/30300 (epoch 41.825), train_loss = 1.13286327, grad/param norm = 1.7872e-01, time/batch = 0.6722s	
25347/30300 (epoch 41.827), train_loss = 0.86648712, grad/param norm = 1.7479e-01, time/batch = 0.6690s	
25348/30300 (epoch 41.828), train_loss = 1.09996256, grad/param norm = 1.7857e-01, time/batch = 0.6690s	
25349/30300 (epoch 41.830), train_loss = 1.05179595, grad/param norm = 1.8888e-01, time/batch = 0.7048s	
25350/30300 (epoch 41.832), train_loss = 0.95517386, grad/param norm = 1.8317e-01, time/batch = 0.6979s	
25351/30300 (epoch 41.833), train_loss = 1.03767351, grad/param norm = 1.7744e-01, time/batch = 0.6734s	
25352/30300 (epoch 41.835), train_loss = 0.95010486, grad/param norm = 1.6795e-01, time/batch = 0.6726s	
25353/30300 (epoch 41.837), train_loss = 0.92026426, grad/param norm = 1.8063e-01, time/batch = 0.6735s	
25354/30300 (epoch 41.838), train_loss = 0.92809257, grad/param norm = 1.7923e-01, time/batch = 0.6681s	
25355/30300 (epoch 41.840), train_loss = 1.08600848, grad/param norm = 1.6226e-01, time/batch = 0.6697s	
25356/30300 (epoch 41.842), train_loss = 0.99084124, grad/param norm = 1.5898e-01, time/batch = 0.6694s	
25357/30300 (epoch 41.843), train_loss = 1.03795796, grad/param norm = 1.7396e-01, time/batch = 0.6694s	
25358/30300 (epoch 41.845), train_loss = 1.04668449, grad/param norm = 1.5453e-01, time/batch = 0.6694s	
25359/30300 (epoch 41.847), train_loss = 1.00653657, grad/param norm = 1.7178e-01, time/batch = 0.6710s	
25360/30300 (epoch 41.848), train_loss = 1.04115605, grad/param norm = 1.8458e-01, time/batch = 0.6713s	
25361/30300 (epoch 41.850), train_loss = 0.99574639, grad/param norm = 1.5332e-01, time/batch = 0.6734s	
25362/30300 (epoch 41.851), train_loss = 1.04435253, grad/param norm = 2.0647e-01, time/batch = 0.6690s	
25363/30300 (epoch 41.853), train_loss = 0.98159781, grad/param norm = 1.8637e-01, time/batch = 0.6704s	
25364/30300 (epoch 41.855), train_loss = 0.96193349, grad/param norm = 1.6092e-01, time/batch = 0.6704s	
25365/30300 (epoch 41.856), train_loss = 1.01043626, grad/param norm = 1.6807e-01, time/batch = 0.6717s	
25366/30300 (epoch 41.858), train_loss = 0.93269402, grad/param norm = 1.6684e-01, time/batch = 0.6772s	
25367/30300 (epoch 41.860), train_loss = 0.91681810, grad/param norm = 1.5621e-01, time/batch = 0.6745s	
25368/30300 (epoch 41.861), train_loss = 1.13912696, grad/param norm = 1.7357e-01, time/batch = 0.6712s	
25369/30300 (epoch 41.863), train_loss = 0.96268028, grad/param norm = 1.6563e-01, time/batch = 0.6727s	
25370/30300 (epoch 41.865), train_loss = 1.07100817, grad/param norm = 1.9398e-01, time/batch = 0.6745s	
25371/30300 (epoch 41.866), train_loss = 1.06895625, grad/param norm = 1.7637e-01, time/batch = 0.6738s	
25372/30300 (epoch 41.868), train_loss = 1.03309906, grad/param norm = 1.6796e-01, time/batch = 0.6809s	
25373/30300 (epoch 41.870), train_loss = 0.94795919, grad/param norm = 1.7372e-01, time/batch = 0.7154s	
25374/30300 (epoch 41.871), train_loss = 1.02115337, grad/param norm = 1.7386e-01, time/batch = 0.6888s	
25375/30300 (epoch 41.873), train_loss = 1.00916093, grad/param norm = 1.8576e-01, time/batch = 0.6755s	
25376/30300 (epoch 41.875), train_loss = 0.97441650, grad/param norm = 1.4841e-01, time/batch = 0.6770s	
25377/30300 (epoch 41.876), train_loss = 0.90932296, grad/param norm = 1.9130e-01, time/batch = 0.6804s	
25378/30300 (epoch 41.878), train_loss = 0.84553019, grad/param norm = 1.5786e-01, time/batch = 0.6773s	
25379/30300 (epoch 41.880), train_loss = 0.94442855, grad/param norm = 1.9018e-01, time/batch = 0.6734s	
25380/30300 (epoch 41.881), train_loss = 1.16741364, grad/param norm = 2.2718e-01, time/batch = 0.6730s	
25381/30300 (epoch 41.883), train_loss = 1.06721682, grad/param norm = 1.7916e-01, time/batch = 0.6944s	
25382/30300 (epoch 41.884), train_loss = 0.99695418, grad/param norm = 1.5648e-01, time/batch = 0.6725s	
25383/30300 (epoch 41.886), train_loss = 1.04039154, grad/param norm = 1.6749e-01, time/batch = 0.6750s	
25384/30300 (epoch 41.888), train_loss = 0.97647719, grad/param norm = 1.9128e-01, time/batch = 0.6778s	
25385/30300 (epoch 41.889), train_loss = 1.02709310, grad/param norm = 1.6492e-01, time/batch = 0.6800s	
25386/30300 (epoch 41.891), train_loss = 0.98436356, grad/param norm = 1.8220e-01, time/batch = 0.6778s	
25387/30300 (epoch 41.893), train_loss = 1.20869553, grad/param norm = 1.7604e-01, time/batch = 0.6723s	
25388/30300 (epoch 41.894), train_loss = 1.03305347, grad/param norm = 1.7156e-01, time/batch = 0.6729s	
25389/30300 (epoch 41.896), train_loss = 0.87277683, grad/param norm = 1.9316e-01, time/batch = 0.6781s	
25390/30300 (epoch 41.898), train_loss = 0.85781252, grad/param norm = 1.5644e-01, time/batch = 0.6930s	
25391/30300 (epoch 41.899), train_loss = 0.90048356, grad/param norm = 1.6183e-01, time/batch = 0.6765s	
25392/30300 (epoch 41.901), train_loss = 1.00299359, grad/param norm = 2.0004e-01, time/batch = 0.6717s	
25393/30300 (epoch 41.903), train_loss = 0.97940470, grad/param norm = 1.9249e-01, time/batch = 0.6749s	
25394/30300 (epoch 41.904), train_loss = 1.02526700, grad/param norm = 1.6212e-01, time/batch = 0.6755s	
25395/30300 (epoch 41.906), train_loss = 1.01555917, grad/param norm = 1.8308e-01, time/batch = 0.6739s	
25396/30300 (epoch 41.908), train_loss = 0.95353299, grad/param norm = 1.6193e-01, time/batch = 0.6808s	
25397/30300 (epoch 41.909), train_loss = 0.97340518, grad/param norm = 2.2142e-01, time/batch = 0.6722s	
25398/30300 (epoch 41.911), train_loss = 0.98990997, grad/param norm = 1.6577e-01, time/batch = 0.6727s	
25399/30300 (epoch 41.913), train_loss = 0.99839726, grad/param norm = 1.7705e-01, time/batch = 0.6732s	
25400/30300 (epoch 41.914), train_loss = 0.96297099, grad/param norm = 1.8565e-01, time/batch = 0.6757s	
25401/30300 (epoch 41.916), train_loss = 1.02830155, grad/param norm = 1.5739e-01, time/batch = 0.6783s	
25402/30300 (epoch 41.917), train_loss = 0.96638611, grad/param norm = 1.7559e-01, time/batch = 0.6720s	
25403/30300 (epoch 41.919), train_loss = 0.88437833, grad/param norm = 1.8961e-01, time/batch = 0.6727s	
25404/30300 (epoch 41.921), train_loss = 0.97197404, grad/param norm = 1.5255e-01, time/batch = 0.6706s	
25405/30300 (epoch 41.922), train_loss = 1.09186149, grad/param norm = 1.9254e-01, time/batch = 0.6712s	
25406/30300 (epoch 41.924), train_loss = 1.00295021, grad/param norm = 2.0689e-01, time/batch = 0.6731s	
25407/30300 (epoch 41.926), train_loss = 1.04614751, grad/param norm = 1.7804e-01, time/batch = 0.6768s	
25408/30300 (epoch 41.927), train_loss = 1.00925410, grad/param norm = 1.6558e-01, time/batch = 0.6820s	
25409/30300 (epoch 41.929), train_loss = 0.93878507, grad/param norm = 1.7752e-01, time/batch = 0.6928s	
25410/30300 (epoch 41.931), train_loss = 1.07327140, grad/param norm = 2.1347e-01, time/batch = 0.6835s	
25411/30300 (epoch 41.932), train_loss = 0.92081791, grad/param norm = 1.6333e-01, time/batch = 0.7217s	
25412/30300 (epoch 41.934), train_loss = 1.02860992, grad/param norm = 1.6740e-01, time/batch = 0.6884s	
25413/30300 (epoch 41.936), train_loss = 0.94788879, grad/param norm = 1.7868e-01, time/batch = 0.6767s	
25414/30300 (epoch 41.937), train_loss = 0.95921243, grad/param norm = 1.6890e-01, time/batch = 0.6903s	
25415/30300 (epoch 41.939), train_loss = 1.09087184, grad/param norm = 1.8052e-01, time/batch = 0.6798s	
25416/30300 (epoch 41.941), train_loss = 0.97003900, grad/param norm = 1.7947e-01, time/batch = 0.6710s	
25417/30300 (epoch 41.942), train_loss = 0.99801523, grad/param norm = 1.9497e-01, time/batch = 0.6723s	
25418/30300 (epoch 41.944), train_loss = 0.88537189, grad/param norm = 1.5610e-01, time/batch = 0.6804s	
25419/30300 (epoch 41.946), train_loss = 1.06668972, grad/param norm = 1.9455e-01, time/batch = 0.6846s	
25420/30300 (epoch 41.947), train_loss = 1.04347714, grad/param norm = 2.1673e-01, time/batch = 0.6760s	
25421/30300 (epoch 41.949), train_loss = 1.08942144, grad/param norm = 2.3122e-01, time/batch = 0.6755s	
25422/30300 (epoch 41.950), train_loss = 1.11785697, grad/param norm = 2.1979e-01, time/batch = 0.6723s	
25423/30300 (epoch 41.952), train_loss = 1.03513209, grad/param norm = 1.9358e-01, time/batch = 0.6737s	
25424/30300 (epoch 41.954), train_loss = 1.24431536, grad/param norm = 1.8591e-01, time/batch = 0.6720s	
25425/30300 (epoch 41.955), train_loss = 0.99655056, grad/param norm = 1.5994e-01, time/batch = 0.7076s	
25426/30300 (epoch 41.957), train_loss = 1.06279554, grad/param norm = 1.8371e-01, time/batch = 0.7151s	
25427/30300 (epoch 41.959), train_loss = 0.91577102, grad/param norm = 1.7563e-01, time/batch = 0.6838s	
25428/30300 (epoch 41.960), train_loss = 0.94913622, grad/param norm = 1.6780e-01, time/batch = 0.6882s	
25429/30300 (epoch 41.962), train_loss = 0.94421246, grad/param norm = 2.0914e-01, time/batch = 0.6938s	
25430/30300 (epoch 41.964), train_loss = 0.91812335, grad/param norm = 2.1150e-01, time/batch = 0.6850s	
25431/30300 (epoch 41.965), train_loss = 0.95217937, grad/param norm = 2.3321e-01, time/batch = 0.6791s	
25432/30300 (epoch 41.967), train_loss = 0.97447650, grad/param norm = 2.1074e-01, time/batch = 0.6781s	
25433/30300 (epoch 41.969), train_loss = 0.93444648, grad/param norm = 1.8856e-01, time/batch = 0.6751s	
25434/30300 (epoch 41.970), train_loss = 0.96906984, grad/param norm = 1.5994e-01, time/batch = 0.6703s	
25435/30300 (epoch 41.972), train_loss = 0.89201840, grad/param norm = 1.8412e-01, time/batch = 0.6717s	
25436/30300 (epoch 41.974), train_loss = 1.12090016, grad/param norm = 1.7840e-01, time/batch = 0.6758s	
25437/30300 (epoch 41.975), train_loss = 1.12385563, grad/param norm = 2.0162e-01, time/batch = 0.6741s	
25438/30300 (epoch 41.977), train_loss = 1.20021400, grad/param norm = 1.7957e-01, time/batch = 0.6764s	
25439/30300 (epoch 41.979), train_loss = 1.05793786, grad/param norm = 1.8102e-01, time/batch = 0.6710s	
25440/30300 (epoch 41.980), train_loss = 1.10820382, grad/param norm = 2.0623e-01, time/batch = 0.6722s	
25441/30300 (epoch 41.982), train_loss = 1.09517314, grad/param norm = 1.8388e-01, time/batch = 0.6769s	
25442/30300 (epoch 41.983), train_loss = 1.12119569, grad/param norm = 1.7587e-01, time/batch = 0.6758s	
25443/30300 (epoch 41.985), train_loss = 1.06116391, grad/param norm = 2.1140e-01, time/batch = 0.6718s	
25444/30300 (epoch 41.987), train_loss = 1.03355264, grad/param norm = 1.7793e-01, time/batch = 0.6903s	
25445/30300 (epoch 41.988), train_loss = 1.13526673, grad/param norm = 2.1943e-01, time/batch = 0.7123s	
25446/30300 (epoch 41.990), train_loss = 0.94133107, grad/param norm = 1.6982e-01, time/batch = 0.6774s	
25447/30300 (epoch 41.992), train_loss = 1.10115425, grad/param norm = 1.6128e-01, time/batch = 0.6713s	
25448/30300 (epoch 41.993), train_loss = 1.08359254, grad/param norm = 2.1924e-01, time/batch = 0.6747s	
25449/30300 (epoch 41.995), train_loss = 1.01473273, grad/param norm = 2.2804e-01, time/batch = 0.6697s	
25450/30300 (epoch 41.997), train_loss = 1.07821746, grad/param norm = 2.0587e-01, time/batch = 0.6695s	
25451/30300 (epoch 41.998), train_loss = 1.07438094, grad/param norm = 1.8926e-01, time/batch = 0.6724s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
25452/30300 (epoch 42.000), train_loss = 0.95057735, grad/param norm = 1.9543e-01, time/batch = 0.6722s	
25453/30300 (epoch 42.002), train_loss = 1.12667821, grad/param norm = 2.1509e-01, time/batch = 0.6730s	
25454/30300 (epoch 42.003), train_loss = 1.04569466, grad/param norm = 1.8433e-01, time/batch = 0.6735s	
25455/30300 (epoch 42.005), train_loss = 0.99623056, grad/param norm = 1.8462e-01, time/batch = 0.6709s	
25456/30300 (epoch 42.007), train_loss = 1.07663844, grad/param norm = 1.8978e-01, time/batch = 0.6736s	
25457/30300 (epoch 42.008), train_loss = 1.01880518, grad/param norm = 2.1645e-01, time/batch = 0.6694s	
25458/30300 (epoch 42.010), train_loss = 0.89934022, grad/param norm = 1.9154e-01, time/batch = 0.6699s	
25459/30300 (epoch 42.012), train_loss = 0.99097716, grad/param norm = 1.8363e-01, time/batch = 0.6712s	
25460/30300 (epoch 42.013), train_loss = 1.09638573, grad/param norm = 2.1969e-01, time/batch = 0.6682s	
25461/30300 (epoch 42.015), train_loss = 0.96709588, grad/param norm = 1.7025e-01, time/batch = 0.6691s	
25462/30300 (epoch 42.017), train_loss = 0.98765180, grad/param norm = 1.5225e-01, time/batch = 0.6692s	
25463/30300 (epoch 42.018), train_loss = 0.91359786, grad/param norm = 1.9342e-01, time/batch = 0.6821s	
25464/30300 (epoch 42.020), train_loss = 1.10006090, grad/param norm = 2.1597e-01, time/batch = 0.7145s	
25465/30300 (epoch 42.021), train_loss = 1.12390072, grad/param norm = 1.7080e-01, time/batch = 0.6760s	
25466/30300 (epoch 42.023), train_loss = 1.01181603, grad/param norm = 1.6066e-01, time/batch = 0.6697s	
25467/30300 (epoch 42.025), train_loss = 0.95123249, grad/param norm = 2.0065e-01, time/batch = 0.6698s	
25468/30300 (epoch 42.026), train_loss = 1.07843351, grad/param norm = 2.0583e-01, time/batch = 0.6717s	
25469/30300 (epoch 42.028), train_loss = 1.08260439, grad/param norm = 1.8507e-01, time/batch = 0.6740s	
25470/30300 (epoch 42.030), train_loss = 0.97184972, grad/param norm = 1.8623e-01, time/batch = 0.6695s	
25471/30300 (epoch 42.031), train_loss = 1.04071901, grad/param norm = 1.7826e-01, time/batch = 0.6732s	
25472/30300 (epoch 42.033), train_loss = 1.03301848, grad/param norm = 1.7590e-01, time/batch = 0.6721s	
25473/30300 (epoch 42.035), train_loss = 1.05418733, grad/param norm = 2.0055e-01, time/batch = 0.6802s	
25474/30300 (epoch 42.036), train_loss = 1.04757306, grad/param norm = 1.7294e-01, time/batch = 0.6803s	
25475/30300 (epoch 42.038), train_loss = 1.06628392, grad/param norm = 1.5942e-01, time/batch = 0.6844s	
25476/30300 (epoch 42.040), train_loss = 0.87710898, grad/param norm = 1.6057e-01, time/batch = 0.6958s	
25477/30300 (epoch 42.041), train_loss = 0.86116800, grad/param norm = 1.7075e-01, time/batch = 0.6809s	
25478/30300 (epoch 42.043), train_loss = 1.04361525, grad/param norm = 1.7454e-01, time/batch = 0.6797s	
25479/30300 (epoch 42.045), train_loss = 0.95862897, grad/param norm = 1.6757e-01, time/batch = 0.6764s	
25480/30300 (epoch 42.046), train_loss = 1.15449622, grad/param norm = 2.2115e-01, time/batch = 0.6765s	
25481/30300 (epoch 42.048), train_loss = 1.04346272, grad/param norm = 2.3303e-01, time/batch = 0.6751s	
25482/30300 (epoch 42.050), train_loss = 0.94467867, grad/param norm = 1.9424e-01, time/batch = 0.6811s	
25483/30300 (epoch 42.051), train_loss = 1.04821566, grad/param norm = 1.8294e-01, time/batch = 0.7144s	
25484/30300 (epoch 42.053), train_loss = 0.89174590, grad/param norm = 2.3830e-01, time/batch = 0.6824s	
25485/30300 (epoch 42.054), train_loss = 1.05082187, grad/param norm = 1.7722e-01, time/batch = 0.6710s	
25486/30300 (epoch 42.056), train_loss = 0.94601118, grad/param norm = 1.7904e-01, time/batch = 0.6730s	
25487/30300 (epoch 42.058), train_loss = 0.97420315, grad/param norm = 1.7423e-01, time/batch = 0.6722s	
25488/30300 (epoch 42.059), train_loss = 0.98535632, grad/param norm = 2.2813e-01, time/batch = 0.6721s	
25489/30300 (epoch 42.061), train_loss = 1.06798510, grad/param norm = 1.8498e-01, time/batch = 0.6752s	
25490/30300 (epoch 42.063), train_loss = 0.91935177, grad/param norm = 1.9979e-01, time/batch = 0.6892s	
25491/30300 (epoch 42.064), train_loss = 0.99471633, grad/param norm = 1.8986e-01, time/batch = 0.6905s	
25492/30300 (epoch 42.066), train_loss = 1.00510135, grad/param norm = 1.5408e-01, time/batch = 0.6911s	
25493/30300 (epoch 42.068), train_loss = 0.93401666, grad/param norm = 1.6845e-01, time/batch = 0.7011s	
25494/30300 (epoch 42.069), train_loss = 1.05819253, grad/param norm = 2.0026e-01, time/batch = 0.6810s	
25495/30300 (epoch 42.071), train_loss = 1.03099953, grad/param norm = 1.7033e-01, time/batch = 0.6968s	
25496/30300 (epoch 42.073), train_loss = 0.92555410, grad/param norm = 1.8655e-01, time/batch = 0.6904s	
25497/30300 (epoch 42.074), train_loss = 0.97944213, grad/param norm = 1.6485e-01, time/batch = 0.6974s	
25498/30300 (epoch 42.076), train_loss = 0.99522011, grad/param norm = 1.8365e-01, time/batch = 0.6929s	
25499/30300 (epoch 42.078), train_loss = 0.93990066, grad/param norm = 1.6199e-01, time/batch = 1.3330s	
25500/30300 (epoch 42.079), train_loss = 0.96239697, grad/param norm = 1.5295e-01, time/batch = 0.7118s	
25501/30300 (epoch 42.081), train_loss = 1.03555793, grad/param norm = 2.0616e-01, time/batch = 0.7169s	
25502/30300 (epoch 42.083), train_loss = 1.07220453, grad/param norm = 2.3025e-01, time/batch = 0.6724s	
25503/30300 (epoch 42.084), train_loss = 0.96081876, grad/param norm = 1.7403e-01, time/batch = 0.6713s	
25504/30300 (epoch 42.086), train_loss = 0.96245679, grad/param norm = 2.3469e-01, time/batch = 0.6760s	
25505/30300 (epoch 42.087), train_loss = 0.94235268, grad/param norm = 1.5971e-01, time/batch = 0.6824s	
25506/30300 (epoch 42.089), train_loss = 0.92848842, grad/param norm = 1.6909e-01, time/batch = 0.6900s	
25507/30300 (epoch 42.091), train_loss = 1.04816781, grad/param norm = 1.8747e-01, time/batch = 0.6906s	
25508/30300 (epoch 42.092), train_loss = 1.07502818, grad/param norm = 1.6461e-01, time/batch = 0.6808s	
25509/30300 (epoch 42.094), train_loss = 1.11851133, grad/param norm = 2.1507e-01, time/batch = 0.6921s	
25510/30300 (epoch 42.096), train_loss = 1.12786385, grad/param norm = 1.9242e-01, time/batch = 0.6973s	
25511/30300 (epoch 42.097), train_loss = 0.96801535, grad/param norm = 2.0270e-01, time/batch = 0.7034s	
25512/30300 (epoch 42.099), train_loss = 1.06629282, grad/param norm = 1.6712e-01, time/batch = 0.6903s	
25513/30300 (epoch 42.101), train_loss = 1.11534654, grad/param norm = 1.9383e-01, time/batch = 0.6782s	
25514/30300 (epoch 42.102), train_loss = 0.94034418, grad/param norm = 1.8363e-01, time/batch = 0.6730s	
25515/30300 (epoch 42.104), train_loss = 0.99215049, grad/param norm = 2.3670e-01, time/batch = 0.7078s	
25516/30300 (epoch 42.106), train_loss = 0.93540380, grad/param norm = 2.0214e-01, time/batch = 0.6938s	
25517/30300 (epoch 42.107), train_loss = 1.06789423, grad/param norm = 1.7503e-01, time/batch = 0.6709s	
25518/30300 (epoch 42.109), train_loss = 1.09524510, grad/param norm = 2.6027e-01, time/batch = 0.6733s	
25519/30300 (epoch 42.111), train_loss = 1.04424024, grad/param norm = 1.8563e-01, time/batch = 0.6771s	
25520/30300 (epoch 42.112), train_loss = 1.13817639, grad/param norm = 2.1015e-01, time/batch = 0.6760s	
25521/30300 (epoch 42.114), train_loss = 0.97089713, grad/param norm = 1.7467e-01, time/batch = 0.6714s	
25522/30300 (epoch 42.116), train_loss = 1.04739973, grad/param norm = 2.1597e-01, time/batch = 0.6695s	
25523/30300 (epoch 42.117), train_loss = 1.10579636, grad/param norm = 1.7394e-01, time/batch = 0.6729s	
25524/30300 (epoch 42.119), train_loss = 0.91500893, grad/param norm = 1.9505e-01, time/batch = 0.6696s	
25525/30300 (epoch 42.120), train_loss = 0.99174445, grad/param norm = 1.9724e-01, time/batch = 0.6723s	
25526/30300 (epoch 42.122), train_loss = 1.10387562, grad/param norm = 1.9987e-01, time/batch = 0.6683s	
25527/30300 (epoch 42.124), train_loss = 1.17131613, grad/param norm = 2.0004e-01, time/batch = 0.6707s	
25528/30300 (epoch 42.125), train_loss = 0.92172485, grad/param norm = 1.7337e-01, time/batch = 0.6710s	
25529/30300 (epoch 42.127), train_loss = 1.02998369, grad/param norm = 1.9100e-01, time/batch = 0.6735s	
25530/30300 (epoch 42.129), train_loss = 1.08631387, grad/param norm = 2.1165e-01, time/batch = 0.6680s	
25531/30300 (epoch 42.130), train_loss = 1.13910261, grad/param norm = 1.8101e-01, time/batch = 0.6732s	
25532/30300 (epoch 42.132), train_loss = 1.13243478, grad/param norm = 1.9566e-01, time/batch = 0.6707s	
25533/30300 (epoch 42.134), train_loss = 0.95066389, grad/param norm = 2.0214e-01, time/batch = 0.6795s	
25534/30300 (epoch 42.135), train_loss = 0.95549921, grad/param norm = 2.0045e-01, time/batch = 0.7037s	
25535/30300 (epoch 42.137), train_loss = 1.01147417, grad/param norm = 2.0484e-01, time/batch = 0.7029s	
25536/30300 (epoch 42.139), train_loss = 0.94876104, grad/param norm = 2.3760e-01, time/batch = 0.6726s	
25537/30300 (epoch 42.140), train_loss = 1.02663489, grad/param norm = 2.4812e-01, time/batch = 0.6717s	
25538/30300 (epoch 42.142), train_loss = 1.08068174, grad/param norm = 2.0035e-01, time/batch = 0.6711s	
25539/30300 (epoch 42.144), train_loss = 0.94255547, grad/param norm = 2.3990e-01, time/batch = 0.6697s	
25540/30300 (epoch 42.145), train_loss = 1.07254926, grad/param norm = 2.3817e-01, time/batch = 0.6726s	
25541/30300 (epoch 42.147), train_loss = 1.00819302, grad/param norm = 1.9238e-01, time/batch = 0.6709s	
25542/30300 (epoch 42.149), train_loss = 1.07947180, grad/param norm = 2.1892e-01, time/batch = 0.6716s	
25543/30300 (epoch 42.150), train_loss = 0.97502656, grad/param norm = 2.0446e-01, time/batch = 0.6733s	
25544/30300 (epoch 42.152), train_loss = 0.89970811, grad/param norm = 2.0104e-01, time/batch = 0.6813s	
25545/30300 (epoch 42.153), train_loss = 1.04536268, grad/param norm = 2.0886e-01, time/batch = 0.6846s	
25546/30300 (epoch 42.155), train_loss = 0.89568949, grad/param norm = 1.7736e-01, time/batch = 0.6792s	
25547/30300 (epoch 42.157), train_loss = 0.94711501, grad/param norm = 1.8588e-01, time/batch = 0.6708s	
25548/30300 (epoch 42.158), train_loss = 1.04433483, grad/param norm = 2.4485e-01, time/batch = 0.6693s	
25549/30300 (epoch 42.160), train_loss = 0.92150814, grad/param norm = 1.9859e-01, time/batch = 0.6701s	
25550/30300 (epoch 42.162), train_loss = 1.00094757, grad/param norm = 1.7126e-01, time/batch = 0.6733s	
25551/30300 (epoch 42.163), train_loss = 0.99620041, grad/param norm = 1.9673e-01, time/batch = 0.6766s	
25552/30300 (epoch 42.165), train_loss = 1.13114904, grad/param norm = 1.9455e-01, time/batch = 0.6764s	
25553/30300 (epoch 42.167), train_loss = 1.02973869, grad/param norm = 2.0360e-01, time/batch = 0.6962s	
25554/30300 (epoch 42.168), train_loss = 1.05784699, grad/param norm = 2.0215e-01, time/batch = 0.7061s	
25555/30300 (epoch 42.170), train_loss = 1.03288864, grad/param norm = 2.0198e-01, time/batch = 0.6697s	
25556/30300 (epoch 42.172), train_loss = 1.01388668, grad/param norm = 1.8968e-01, time/batch = 0.6704s	
25557/30300 (epoch 42.173), train_loss = 0.99237479, grad/param norm = 2.2183e-01, time/batch = 0.6707s	
25558/30300 (epoch 42.175), train_loss = 1.01895411, grad/param norm = 1.6688e-01, time/batch = 0.6702s	
25559/30300 (epoch 42.177), train_loss = 1.08145338, grad/param norm = 2.1491e-01, time/batch = 0.6730s	
25560/30300 (epoch 42.178), train_loss = 0.84189587, grad/param norm = 1.5992e-01, time/batch = 0.6674s	
25561/30300 (epoch 42.180), train_loss = 0.99062197, grad/param norm = 1.6872e-01, time/batch = 0.6726s	
25562/30300 (epoch 42.182), train_loss = 1.02176353, grad/param norm = 1.9396e-01, time/batch = 0.6706s	
25563/30300 (epoch 42.183), train_loss = 0.94613171, grad/param norm = 1.8389e-01, time/batch = 0.6723s	
25564/30300 (epoch 42.185), train_loss = 1.14250050, grad/param norm = 2.0216e-01, time/batch = 0.6738s	
25565/30300 (epoch 42.186), train_loss = 1.21545508, grad/param norm = 2.1486e-01, time/batch = 0.6754s	
25566/30300 (epoch 42.188), train_loss = 1.05860512, grad/param norm = 1.9260e-01, time/batch = 0.6748s	
25567/30300 (epoch 42.190), train_loss = 1.00320562, grad/param norm = 1.7129e-01, time/batch = 0.6759s	
25568/30300 (epoch 42.191), train_loss = 1.06530714, grad/param norm = 1.9921e-01, time/batch = 0.6776s	
25569/30300 (epoch 42.193), train_loss = 0.92443702, grad/param norm = 1.7762e-01, time/batch = 0.6718s	
25570/30300 (epoch 42.195), train_loss = 0.96603698, grad/param norm = 1.7540e-01, time/batch = 0.6703s	
25571/30300 (epoch 42.196), train_loss = 1.04205067, grad/param norm = 1.6410e-01, time/batch = 0.6742s	
25572/30300 (epoch 42.198), train_loss = 0.87009853, grad/param norm = 1.7289e-01, time/batch = 0.6911s	
25573/30300 (epoch 42.200), train_loss = 0.96921546, grad/param norm = 1.6933e-01, time/batch = 0.7129s	
25574/30300 (epoch 42.201), train_loss = 1.10902672, grad/param norm = 2.3339e-01, time/batch = 0.6741s	
25575/30300 (epoch 42.203), train_loss = 1.02517736, grad/param norm = 1.8867e-01, time/batch = 0.6763s	
25576/30300 (epoch 42.205), train_loss = 1.17906983, grad/param norm = 2.2308e-01, time/batch = 0.6722s	
25577/30300 (epoch 42.206), train_loss = 1.07910789, grad/param norm = 1.8576e-01, time/batch = 0.6731s	
25578/30300 (epoch 42.208), train_loss = 1.06628593, grad/param norm = 2.3351e-01, time/batch = 0.6759s	
25579/30300 (epoch 42.210), train_loss = 1.08346119, grad/param norm = 1.6601e-01, time/batch = 0.6738s	
25580/30300 (epoch 42.211), train_loss = 1.14453125, grad/param norm = 1.9712e-01, time/batch = 0.6708s	
25581/30300 (epoch 42.213), train_loss = 1.03452249, grad/param norm = 1.6679e-01, time/batch = 0.6783s	
25582/30300 (epoch 42.215), train_loss = 0.93235351, grad/param norm = 1.6367e-01, time/batch = 0.6738s	
25583/30300 (epoch 42.216), train_loss = 0.95337482, grad/param norm = 1.8091e-01, time/batch = 0.6851s	
25584/30300 (epoch 42.218), train_loss = 0.92900996, grad/param norm = 1.6616e-01, time/batch = 0.6975s	
25585/30300 (epoch 42.219), train_loss = 0.88643849, grad/param norm = 1.6799e-01, time/batch = 0.6737s	
25586/30300 (epoch 42.221), train_loss = 0.86719782, grad/param norm = 1.7480e-01, time/batch = 0.7161s	
25587/30300 (epoch 42.223), train_loss = 1.01639205, grad/param norm = 1.9866e-01, time/batch = 0.6860s	
25588/30300 (epoch 42.224), train_loss = 0.84413031, grad/param norm = 1.9265e-01, time/batch = 0.6863s	
25589/30300 (epoch 42.226), train_loss = 1.05950996, grad/param norm = 2.0355e-01, time/batch = 0.6716s	
25590/30300 (epoch 42.228), train_loss = 1.12769782, grad/param norm = 1.9624e-01, time/batch = 0.6755s	
25591/30300 (epoch 42.229), train_loss = 1.00630125, grad/param norm = 1.7973e-01, time/batch = 0.7120s	
25592/30300 (epoch 42.231), train_loss = 1.07049257, grad/param norm = 1.9110e-01, time/batch = 0.7202s	
25593/30300 (epoch 42.233), train_loss = 1.05778153, grad/param norm = 1.5334e-01, time/batch = 0.7132s	
25594/30300 (epoch 42.234), train_loss = 1.09223038, grad/param norm = 2.5631e-01, time/batch = 0.7213s	
25595/30300 (epoch 42.236), train_loss = 1.06103178, grad/param norm = 1.5978e-01, time/batch = 0.7287s	
25596/30300 (epoch 42.238), train_loss = 1.02519713, grad/param norm = 1.9904e-01, time/batch = 0.7076s	
25597/30300 (epoch 42.239), train_loss = 0.96151822, grad/param norm = 2.2813e-01, time/batch = 0.7009s	
25598/30300 (epoch 42.241), train_loss = 1.05405701, grad/param norm = 2.0800e-01, time/batch = 0.6820s	
25599/30300 (epoch 42.243), train_loss = 1.05935515, grad/param norm = 1.9428e-01, time/batch = 0.6914s	
25600/30300 (epoch 42.244), train_loss = 1.21275880, grad/param norm = 1.8464e-01, time/batch = 0.6813s	
25601/30300 (epoch 42.246), train_loss = 1.04794927, grad/param norm = 1.7185e-01, time/batch = 0.6912s	
25602/30300 (epoch 42.248), train_loss = 1.00514079, grad/param norm = 1.7363e-01, time/batch = 0.6938s	
25603/30300 (epoch 42.249), train_loss = 0.92039018, grad/param norm = 1.9260e-01, time/batch = 0.6761s	
25604/30300 (epoch 42.251), train_loss = 0.95216661, grad/param norm = 1.9136e-01, time/batch = 0.6701s	
25605/30300 (epoch 42.252), train_loss = 1.11206319, grad/param norm = 2.0605e-01, time/batch = 0.6878s	
25606/30300 (epoch 42.254), train_loss = 1.09499423, grad/param norm = 1.8130e-01, time/batch = 0.7172s	
25607/30300 (epoch 42.256), train_loss = 1.08332722, grad/param norm = 1.9045e-01, time/batch = 0.6889s	
25608/30300 (epoch 42.257), train_loss = 1.08833791, grad/param norm = 2.2207e-01, time/batch = 0.6841s	
25609/30300 (epoch 42.259), train_loss = 1.00221540, grad/param norm = 1.7498e-01, time/batch = 0.7011s	
25610/30300 (epoch 42.261), train_loss = 1.15918715, grad/param norm = 1.8035e-01, time/batch = 0.7019s	
25611/30300 (epoch 42.262), train_loss = 0.94563458, grad/param norm = 1.5804e-01, time/batch = 0.6927s	
25612/30300 (epoch 42.264), train_loss = 1.02077244, grad/param norm = 2.0922e-01, time/batch = 0.6814s	
25613/30300 (epoch 42.266), train_loss = 1.01106608, grad/param norm = 1.6274e-01, time/batch = 0.6712s	
25614/30300 (epoch 42.267), train_loss = 1.16097947, grad/param norm = 1.9774e-01, time/batch = 0.6897s	
25615/30300 (epoch 42.269), train_loss = 1.04009189, grad/param norm = 1.7203e-01, time/batch = 0.6831s	
25616/30300 (epoch 42.271), train_loss = 1.03711449, grad/param norm = 1.6835e-01, time/batch = 0.6751s	
25617/30300 (epoch 42.272), train_loss = 1.04883156, grad/param norm = 2.2040e-01, time/batch = 0.6679s	
25618/30300 (epoch 42.274), train_loss = 1.08877925, grad/param norm = 1.9349e-01, time/batch = 0.6739s	
25619/30300 (epoch 42.276), train_loss = 1.04737118, grad/param norm = 1.9364e-01, time/batch = 0.6714s	
25620/30300 (epoch 42.277), train_loss = 0.93161907, grad/param norm = 1.7370e-01, time/batch = 0.6690s	
25621/30300 (epoch 42.279), train_loss = 1.02644953, grad/param norm = 1.8003e-01, time/batch = 0.6681s	
25622/30300 (epoch 42.281), train_loss = 1.10015183, grad/param norm = 2.2779e-01, time/batch = 0.6698s	
25623/30300 (epoch 42.282), train_loss = 1.06181623, grad/param norm = 1.8306e-01, time/batch = 0.6705s	
25624/30300 (epoch 42.284), train_loss = 1.09693484, grad/param norm = 2.3612e-01, time/batch = 0.6820s	
25625/30300 (epoch 42.285), train_loss = 1.07629757, grad/param norm = 1.6320e-01, time/batch = 0.7161s	
25626/30300 (epoch 42.287), train_loss = 1.04989614, grad/param norm = 2.1589e-01, time/batch = 0.6770s	
25627/30300 (epoch 42.289), train_loss = 1.11641554, grad/param norm = 1.8939e-01, time/batch = 0.6724s	
25628/30300 (epoch 42.290), train_loss = 0.82774533, grad/param norm = 1.8311e-01, time/batch = 0.6731s	
25629/30300 (epoch 42.292), train_loss = 0.92217935, grad/param norm = 1.6620e-01, time/batch = 0.6706s	
25630/30300 (epoch 42.294), train_loss = 1.09546962, grad/param norm = 2.3712e-01, time/batch = 0.6705s	
25631/30300 (epoch 42.295), train_loss = 0.98357213, grad/param norm = 1.8606e-01, time/batch = 0.6749s	
25632/30300 (epoch 42.297), train_loss = 0.99040153, grad/param norm = 1.7386e-01, time/batch = 0.6854s	
25633/30300 (epoch 42.299), train_loss = 1.01835945, grad/param norm = 2.0775e-01, time/batch = 0.6731s	
25634/30300 (epoch 42.300), train_loss = 0.94875274, grad/param norm = 2.4341e-01, time/batch = 0.6740s	
25635/30300 (epoch 42.302), train_loss = 1.10281045, grad/param norm = 2.0736e-01, time/batch = 0.6734s	
25636/30300 (epoch 42.304), train_loss = 0.95208317, grad/param norm = 1.8632e-01, time/batch = 0.6755s	
25637/30300 (epoch 42.305), train_loss = 1.02784667, grad/param norm = 1.7721e-01, time/batch = 0.6757s	
25638/30300 (epoch 42.307), train_loss = 1.10778053, grad/param norm = 1.7518e-01, time/batch = 0.6717s	
25639/30300 (epoch 42.309), train_loss = 1.05450648, grad/param norm = 1.8352e-01, time/batch = 0.6986s	
25640/30300 (epoch 42.310), train_loss = 1.00056635, grad/param norm = 1.7836e-01, time/batch = 0.7132s	
25641/30300 (epoch 42.312), train_loss = 1.13657916, grad/param norm = 1.6782e-01, time/batch = 0.6751s	
25642/30300 (epoch 42.314), train_loss = 1.02722035, grad/param norm = 1.8305e-01, time/batch = 0.6706s	
25643/30300 (epoch 42.315), train_loss = 0.98130029, grad/param norm = 1.7500e-01, time/batch = 0.6730s	
25644/30300 (epoch 42.317), train_loss = 1.03623701, grad/param norm = 1.6792e-01, time/batch = 0.6691s	
25645/30300 (epoch 42.318), train_loss = 1.07527225, grad/param norm = 2.3436e-01, time/batch = 0.6676s	
25646/30300 (epoch 42.320), train_loss = 1.06982041, grad/param norm = 1.9452e-01, time/batch = 0.6745s	
25647/30300 (epoch 42.322), train_loss = 0.95825602, grad/param norm = 1.6794e-01, time/batch = 0.6803s	
25648/30300 (epoch 42.323), train_loss = 1.11971539, grad/param norm = 1.8188e-01, time/batch = 0.6787s	
25649/30300 (epoch 42.325), train_loss = 0.99695599, grad/param norm = 1.7815e-01, time/batch = 0.6799s	
25650/30300 (epoch 42.327), train_loss = 1.00244061, grad/param norm = 1.6294e-01, time/batch = 0.6831s	
25651/30300 (epoch 42.328), train_loss = 1.03867352, grad/param norm = 1.5512e-01, time/batch = 0.6792s	
25652/30300 (epoch 42.330), train_loss = 1.05548659, grad/param norm = 1.7226e-01, time/batch = 0.6715s	
25653/30300 (epoch 42.332), train_loss = 1.11869332, grad/param norm = 1.9289e-01, time/batch = 0.6659s	
25654/30300 (epoch 42.333), train_loss = 0.93238247, grad/param norm = 1.6931e-01, time/batch = 0.7107s	
25655/30300 (epoch 42.335), train_loss = 0.92745602, grad/param norm = 1.7205e-01, time/batch = 0.6894s	
25656/30300 (epoch 42.337), train_loss = 1.13444371, grad/param norm = 1.6992e-01, time/batch = 0.6672s	
25657/30300 (epoch 42.338), train_loss = 0.97553631, grad/param norm = 1.5808e-01, time/batch = 0.6688s	
25658/30300 (epoch 42.340), train_loss = 0.97032518, grad/param norm = 1.6775e-01, time/batch = 0.6712s	
25659/30300 (epoch 42.342), train_loss = 1.09698713, grad/param norm = 1.9680e-01, time/batch = 0.6715s	
25660/30300 (epoch 42.343), train_loss = 1.04669208, grad/param norm = 1.7228e-01, time/batch = 0.6687s	
25661/30300 (epoch 42.345), train_loss = 1.06678755, grad/param norm = 1.8227e-01, time/batch = 0.6729s	
25662/30300 (epoch 42.347), train_loss = 0.92408324, grad/param norm = 1.7417e-01, time/batch = 0.6704s	
25663/30300 (epoch 42.348), train_loss = 0.98170837, grad/param norm = 1.8133e-01, time/batch = 0.6689s	
25664/30300 (epoch 42.350), train_loss = 0.99225268, grad/param norm = 1.9964e-01, time/batch = 0.6674s	
25665/30300 (epoch 42.351), train_loss = 1.00480505, grad/param norm = 1.8332e-01, time/batch = 0.6678s	
25666/30300 (epoch 42.353), train_loss = 0.91507405, grad/param norm = 1.7116e-01, time/batch = 0.6768s	
25667/30300 (epoch 42.355), train_loss = 0.97192831, grad/param norm = 1.6025e-01, time/batch = 0.6748s	
25668/30300 (epoch 42.356), train_loss = 1.08855451, grad/param norm = 2.1397e-01, time/batch = 0.6707s	
25669/30300 (epoch 42.358), train_loss = 1.25459302, grad/param norm = 1.7746e-01, time/batch = 0.6668s	
25670/30300 (epoch 42.360), train_loss = 0.97671669, grad/param norm = 1.9548e-01, time/batch = 0.6734s	
25671/30300 (epoch 42.361), train_loss = 1.01122185, grad/param norm = 1.9705e-01, time/batch = 0.6832s	
25672/30300 (epoch 42.363), train_loss = 1.03498324, grad/param norm = 1.7186e-01, time/batch = 0.6840s	
25673/30300 (epoch 42.365), train_loss = 0.87302833, grad/param norm = 1.9929e-01, time/batch = 0.7008s	
25674/30300 (epoch 42.366), train_loss = 0.98454201, grad/param norm = 1.5945e-01, time/batch = 0.7047s	
25675/30300 (epoch 42.368), train_loss = 0.89462947, grad/param norm = 1.7463e-01, time/batch = 0.6781s	
25676/30300 (epoch 42.370), train_loss = 0.93550088, grad/param norm = 1.7798e-01, time/batch = 0.6697s	
25677/30300 (epoch 42.371), train_loss = 1.07388681, grad/param norm = 1.7978e-01, time/batch = 0.6684s	
25678/30300 (epoch 42.373), train_loss = 0.96076966, grad/param norm = 1.5368e-01, time/batch = 0.6679s	
25679/30300 (epoch 42.375), train_loss = 0.94209910, grad/param norm = 1.7109e-01, time/batch = 0.7088s	
25680/30300 (epoch 42.376), train_loss = 0.93885455, grad/param norm = 1.6348e-01, time/batch = 0.6923s	
25681/30300 (epoch 42.378), train_loss = 0.92511219, grad/param norm = 1.7789e-01, time/batch = 0.6740s	
25682/30300 (epoch 42.380), train_loss = 1.11971700, grad/param norm = 1.7688e-01, time/batch = 0.6737s	
25683/30300 (epoch 42.381), train_loss = 0.84985378, grad/param norm = 1.6636e-01, time/batch = 0.6706s	
25684/30300 (epoch 42.383), train_loss = 0.91657751, grad/param norm = 2.1923e-01, time/batch = 0.6681s	
25685/30300 (epoch 42.384), train_loss = 1.05018966, grad/param norm = 1.9037e-01, time/batch = 0.6653s	
25686/30300 (epoch 42.386), train_loss = 0.91035377, grad/param norm = 1.7440e-01, time/batch = 0.6674s	
25687/30300 (epoch 42.388), train_loss = 0.90297420, grad/param norm = 1.7330e-01, time/batch = 0.6655s	
25688/30300 (epoch 42.389), train_loss = 0.99346787, grad/param norm = 1.8742e-01, time/batch = 0.6673s	
25689/30300 (epoch 42.391), train_loss = 1.04229431, grad/param norm = 1.6863e-01, time/batch = 0.6677s	
25690/30300 (epoch 42.393), train_loss = 0.89425992, grad/param norm = 1.5038e-01, time/batch = 0.6725s	
25691/30300 (epoch 42.394), train_loss = 1.02906205, grad/param norm = 1.7632e-01, time/batch = 0.6706s	
25692/30300 (epoch 42.396), train_loss = 1.14005771, grad/param norm = 1.7243e-01, time/batch = 0.6852s	
25693/30300 (epoch 42.398), train_loss = 0.97466133, grad/param norm = 1.6580e-01, time/batch = 0.6976s	
25694/30300 (epoch 42.399), train_loss = 0.91280125, grad/param norm = 1.6868e-01, time/batch = 0.7150s	
25695/30300 (epoch 42.401), train_loss = 1.01092704, grad/param norm = 2.1876e-01, time/batch = 0.6793s	
25696/30300 (epoch 42.403), train_loss = 0.99966040, grad/param norm = 1.9072e-01, time/batch = 0.6686s	
25697/30300 (epoch 42.404), train_loss = 0.95241608, grad/param norm = 2.0295e-01, time/batch = 0.6692s	
25698/30300 (epoch 42.406), train_loss = 1.01648499, grad/param norm = 1.6789e-01, time/batch = 0.6704s	
25699/30300 (epoch 42.408), train_loss = 0.87386364, grad/param norm = 1.5061e-01, time/batch = 0.6673s	
25700/30300 (epoch 42.409), train_loss = 0.88972984, grad/param norm = 1.8768e-01, time/batch = 0.6668s	
25701/30300 (epoch 42.411), train_loss = 0.93877194, grad/param norm = 1.5095e-01, time/batch = 0.6701s	
25702/30300 (epoch 42.413), train_loss = 0.84724851, grad/param norm = 1.6374e-01, time/batch = 0.6672s	
25703/30300 (epoch 42.414), train_loss = 1.04877940, grad/param norm = 1.8825e-01, time/batch = 0.6696s	
25704/30300 (epoch 42.416), train_loss = 0.94672416, grad/param norm = 1.7117e-01, time/batch = 0.6715s	
25705/30300 (epoch 42.417), train_loss = 0.91623007, grad/param norm = 1.7227e-01, time/batch = 0.6747s	
25706/30300 (epoch 42.419), train_loss = 0.89112872, grad/param norm = 1.5035e-01, time/batch = 0.6705s	
25707/30300 (epoch 42.421), train_loss = 0.97008165, grad/param norm = 2.4038e-01, time/batch = 0.6663s	
25708/30300 (epoch 42.422), train_loss = 1.00628675, grad/param norm = 1.7871e-01, time/batch = 0.6851s	
25709/30300 (epoch 42.424), train_loss = 1.02225139, grad/param norm = 1.8276e-01, time/batch = 0.7134s	
25710/30300 (epoch 42.426), train_loss = 0.97599640, grad/param norm = 2.0058e-01, time/batch = 0.6677s	
25711/30300 (epoch 42.427), train_loss = 0.96183900, grad/param norm = 2.0376e-01, time/batch = 0.6695s	
25712/30300 (epoch 42.429), train_loss = 0.99172676, grad/param norm = 1.6690e-01, time/batch = 0.6778s	
25713/30300 (epoch 42.431), train_loss = 1.02919104, grad/param norm = 1.7858e-01, time/batch = 0.6694s	
25714/30300 (epoch 42.432), train_loss = 1.02304648, grad/param norm = 1.7291e-01, time/batch = 0.6676s	
25715/30300 (epoch 42.434), train_loss = 0.89453064, grad/param norm = 1.8156e-01, time/batch = 0.6675s	
25716/30300 (epoch 42.436), train_loss = 1.08707043, grad/param norm = 1.7892e-01, time/batch = 0.6681s	
25717/30300 (epoch 42.437), train_loss = 0.92130385, grad/param norm = 1.8209e-01, time/batch = 0.6677s	
25718/30300 (epoch 42.439), train_loss = 0.95839091, grad/param norm = 1.8009e-01, time/batch = 0.6690s	
25719/30300 (epoch 42.441), train_loss = 0.98634833, grad/param norm = 1.6088e-01, time/batch = 0.6681s	
25720/30300 (epoch 42.442), train_loss = 0.93374448, grad/param norm = 1.6409e-01, time/batch = 0.6676s	
25721/30300 (epoch 42.444), train_loss = 0.82762576, grad/param norm = 1.5292e-01, time/batch = 0.6702s	
25722/30300 (epoch 42.446), train_loss = 0.94763045, grad/param norm = 1.5323e-01, time/batch = 0.6680s	
25723/30300 (epoch 42.447), train_loss = 0.99296673, grad/param norm = 1.7839e-01, time/batch = 0.6682s	
25724/30300 (epoch 42.449), train_loss = 0.93445256, grad/param norm = 1.7173e-01, time/batch = 0.6681s	
25725/30300 (epoch 42.450), train_loss = 1.02519523, grad/param norm = 1.6196e-01, time/batch = 0.6726s	
25726/30300 (epoch 42.452), train_loss = 1.10987800, grad/param norm = 1.7275e-01, time/batch = 0.6673s	
25727/30300 (epoch 42.454), train_loss = 1.04216363, grad/param norm = 1.6873e-01, time/batch = 0.6763s	
25728/30300 (epoch 42.455), train_loss = 1.00306641, grad/param norm = 1.7611e-01, time/batch = 0.7140s	
25729/30300 (epoch 42.457), train_loss = 0.98229425, grad/param norm = 1.8585e-01, time/batch = 0.6825s	
25730/30300 (epoch 42.459), train_loss = 1.03550207, grad/param norm = 1.8631e-01, time/batch = 0.6695s	
25731/30300 (epoch 42.460), train_loss = 1.07611569, grad/param norm = 1.7236e-01, time/batch = 0.6697s	
25732/30300 (epoch 42.462), train_loss = 1.06963696, grad/param norm = 1.8410e-01, time/batch = 0.6878s	
25733/30300 (epoch 42.464), train_loss = 0.82396372, grad/param norm = 2.3033e-01, time/batch = 0.6818s	
25734/30300 (epoch 42.465), train_loss = 0.84907097, grad/param norm = 1.5156e-01, time/batch = 0.6806s	
25735/30300 (epoch 42.467), train_loss = 0.84319673, grad/param norm = 1.5004e-01, time/batch = 0.6787s	
25736/30300 (epoch 42.469), train_loss = 0.94363607, grad/param norm = 1.8905e-01, time/batch = 0.6826s	
25737/30300 (epoch 42.470), train_loss = 0.94782071, grad/param norm = 1.7874e-01, time/batch = 0.6743s	
25738/30300 (epoch 42.472), train_loss = 0.94458480, grad/param norm = 1.5811e-01, time/batch = 0.6734s	
25739/30300 (epoch 42.474), train_loss = 0.93751494, grad/param norm = 1.9338e-01, time/batch = 0.6756s	
25740/30300 (epoch 42.475), train_loss = 0.93659965, grad/param norm = 1.8230e-01, time/batch = 0.6712s	
25741/30300 (epoch 42.477), train_loss = 0.98357959, grad/param norm = 1.7605e-01, time/batch = 0.6726s	
25742/30300 (epoch 42.479), train_loss = 0.93587626, grad/param norm = 1.5731e-01, time/batch = 0.6687s	
25743/30300 (epoch 42.480), train_loss = 1.01169733, grad/param norm = 1.7172e-01, time/batch = 0.6672s	
25744/30300 (epoch 42.482), train_loss = 1.03551648, grad/param norm = 1.6340e-01, time/batch = 0.6707s	
25745/30300 (epoch 42.483), train_loss = 0.97261111, grad/param norm = 1.6443e-01, time/batch = 0.6727s	
25746/30300 (epoch 42.485), train_loss = 1.00131499, grad/param norm = 1.6966e-01, time/batch = 0.6685s	
25747/30300 (epoch 42.487), train_loss = 1.05748218, grad/param norm = 1.6843e-01, time/batch = 0.6670s	
25748/30300 (epoch 42.488), train_loss = 1.11551371, grad/param norm = 1.5547e-01, time/batch = 0.6679s	
25749/30300 (epoch 42.490), train_loss = 0.86613468, grad/param norm = 1.7151e-01, time/batch = 0.6658s	
25750/30300 (epoch 42.492), train_loss = 0.95627492, grad/param norm = 1.7317e-01, time/batch = 0.6661s	
25751/30300 (epoch 42.493), train_loss = 0.99763047, grad/param norm = 1.6825e-01, time/batch = 0.6683s	
25752/30300 (epoch 42.495), train_loss = 0.97632719, grad/param norm = 1.6196e-01, time/batch = 0.6671s	
25753/30300 (epoch 42.497), train_loss = 1.02901921, grad/param norm = 1.7085e-01, time/batch = 0.6783s	
25754/30300 (epoch 42.498), train_loss = 1.04234355, grad/param norm = 1.7081e-01, time/batch = 0.6722s	
25755/30300 (epoch 42.500), train_loss = 0.94118831, grad/param norm = 1.9894e-01, time/batch = 0.6681s	
25756/30300 (epoch 42.502), train_loss = 1.00488113, grad/param norm = 2.2691e-01, time/batch = 0.6661s	
25757/30300 (epoch 42.503), train_loss = 1.09060997, grad/param norm = 1.7798e-01, time/batch = 0.6666s	
25758/30300 (epoch 42.505), train_loss = 0.88722401, grad/param norm = 1.6665e-01, time/batch = 0.6691s	
25759/30300 (epoch 42.507), train_loss = 0.88860280, grad/param norm = 1.7741e-01, time/batch = 0.6778s	
25760/30300 (epoch 42.508), train_loss = 0.94746291, grad/param norm = 1.9822e-01, time/batch = 0.6913s	
25761/30300 (epoch 42.510), train_loss = 1.05828747, grad/param norm = 1.8307e-01, time/batch = 0.6882s	
25762/30300 (epoch 42.512), train_loss = 0.92431485, grad/param norm = 1.6450e-01, time/batch = 0.7430s	
25763/30300 (epoch 42.513), train_loss = 0.99116836, grad/param norm = 1.6133e-01, time/batch = 0.6937s	
25764/30300 (epoch 42.515), train_loss = 0.97524887, grad/param norm = 1.6792e-01, time/batch = 0.6694s	
25765/30300 (epoch 42.517), train_loss = 0.80818048, grad/param norm = 1.5178e-01, time/batch = 0.6759s	
25766/30300 (epoch 42.518), train_loss = 1.08329605, grad/param norm = 1.8287e-01, time/batch = 0.6883s	
25767/30300 (epoch 42.520), train_loss = 0.96774055, grad/param norm = 1.7434e-01, time/batch = 0.6796s	
25768/30300 (epoch 42.521), train_loss = 0.89656640, grad/param norm = 2.1692e-01, time/batch = 0.6767s	
25769/30300 (epoch 42.523), train_loss = 1.10544177, grad/param norm = 2.4585e-01, time/batch = 0.6707s	
25770/30300 (epoch 42.525), train_loss = 0.89562627, grad/param norm = 1.6906e-01, time/batch = 0.6690s	
25771/30300 (epoch 42.526), train_loss = 1.01514038, grad/param norm = 1.6754e-01, time/batch = 0.6760s	
25772/30300 (epoch 42.528), train_loss = 0.86928860, grad/param norm = 1.6541e-01, time/batch = 0.6759s	
25773/30300 (epoch 42.530), train_loss = 0.86161212, grad/param norm = 1.6263e-01, time/batch = 0.6734s	
25774/30300 (epoch 42.531), train_loss = 0.96666874, grad/param norm = 1.6752e-01, time/batch = 0.6677s	
25775/30300 (epoch 42.533), train_loss = 0.95932541, grad/param norm = 1.7917e-01, time/batch = 0.6741s	
25776/30300 (epoch 42.535), train_loss = 0.98452404, grad/param norm = 1.5425e-01, time/batch = 0.6969s	
25777/30300 (epoch 42.536), train_loss = 0.99414257, grad/param norm = 1.6773e-01, time/batch = 0.7036s	
25778/30300 (epoch 42.538), train_loss = 0.85438998, grad/param norm = 1.6085e-01, time/batch = 0.6662s	
25779/30300 (epoch 42.540), train_loss = 0.93899247, grad/param norm = 2.5164e-01, time/batch = 0.6684s	
25780/30300 (epoch 42.541), train_loss = 0.96940301, grad/param norm = 1.9840e-01, time/batch = 0.6669s	
25781/30300 (epoch 42.543), train_loss = 0.95526897, grad/param norm = 1.5470e-01, time/batch = 0.6688s	
25782/30300 (epoch 42.545), train_loss = 1.04348039, grad/param norm = 2.1932e-01, time/batch = 0.6685s	
25783/30300 (epoch 42.546), train_loss = 1.15037126, grad/param norm = 1.6381e-01, time/batch = 0.6681s	
25784/30300 (epoch 42.548), train_loss = 0.93141988, grad/param norm = 1.5293e-01, time/batch = 0.6713s	
25785/30300 (epoch 42.550), train_loss = 1.02642877, grad/param norm = 2.0248e-01, time/batch = 0.6671s	
25786/30300 (epoch 42.551), train_loss = 0.91255881, grad/param norm = 1.6565e-01, time/batch = 0.6664s	
25787/30300 (epoch 42.553), train_loss = 0.95395380, grad/param norm = 1.6988e-01, time/batch = 0.6694s	
25788/30300 (epoch 42.554), train_loss = 0.98840885, grad/param norm = 1.7530e-01, time/batch = 0.6695s	
25789/30300 (epoch 42.556), train_loss = 1.02772502, grad/param norm = 1.7091e-01, time/batch = 0.6673s	
25790/30300 (epoch 42.558), train_loss = 1.08279319, grad/param norm = 1.8602e-01, time/batch = 0.6683s	
25791/30300 (epoch 42.559), train_loss = 0.99569943, grad/param norm = 1.7915e-01, time/batch = 0.7059s	
25792/30300 (epoch 42.561), train_loss = 0.79819699, grad/param norm = 1.7382e-01, time/batch = 0.6925s	
25793/30300 (epoch 42.563), train_loss = 0.87420305, grad/param norm = 1.5552e-01, time/batch = 0.6662s	
25794/30300 (epoch 42.564), train_loss = 0.93109320, grad/param norm = 1.4400e-01, time/batch = 0.6660s	
25795/30300 (epoch 42.566), train_loss = 0.95345795, grad/param norm = 1.8480e-01, time/batch = 0.6650s	
25796/30300 (epoch 42.568), train_loss = 0.84643421, grad/param norm = 1.7206e-01, time/batch = 0.6654s	
25797/30300 (epoch 42.569), train_loss = 1.00630880, grad/param norm = 1.6665e-01, time/batch = 0.6665s	
25798/30300 (epoch 42.571), train_loss = 0.98191530, grad/param norm = 1.8125e-01, time/batch = 0.6674s	
25799/30300 (epoch 42.573), train_loss = 1.01497833, grad/param norm = 1.6566e-01, time/batch = 0.6727s	
25800/30300 (epoch 42.574), train_loss = 1.00463800, grad/param norm = 1.6685e-01, time/batch = 0.6695s	
25801/30300 (epoch 42.576), train_loss = 0.95864837, grad/param norm = 1.6445e-01, time/batch = 0.6667s	
25802/30300 (epoch 42.578), train_loss = 0.84694066, grad/param norm = 1.5994e-01, time/batch = 0.6663s	
25803/30300 (epoch 42.579), train_loss = 1.04848245, grad/param norm = 2.4846e-01, time/batch = 0.6660s	
25804/30300 (epoch 42.581), train_loss = 1.11125889, grad/param norm = 1.9019e-01, time/batch = 0.6663s	
25805/30300 (epoch 42.583), train_loss = 1.10582861, grad/param norm = 2.2958e-01, time/batch = 0.6676s	
25806/30300 (epoch 42.584), train_loss = 1.09256758, grad/param norm = 1.7476e-01, time/batch = 0.6718s	
25807/30300 (epoch 42.586), train_loss = 0.95850334, grad/param norm = 1.6743e-01, time/batch = 0.6721s	
25808/30300 (epoch 42.587), train_loss = 0.98119788, grad/param norm = 1.7984e-01, time/batch = 0.6647s	
25809/30300 (epoch 42.589), train_loss = 0.91925062, grad/param norm = 1.7681e-01, time/batch = 0.6661s	
25810/30300 (epoch 42.591), train_loss = 1.00703267, grad/param norm = 1.5209e-01, time/batch = 0.6651s	
25811/30300 (epoch 42.592), train_loss = 0.93875810, grad/param norm = 1.5145e-01, time/batch = 0.6693s	
25812/30300 (epoch 42.594), train_loss = 1.03177655, grad/param norm = 1.9476e-01, time/batch = 0.6677s	
25813/30300 (epoch 42.596), train_loss = 0.91495353, grad/param norm = 1.5716e-01, time/batch = 0.6685s	
25814/30300 (epoch 42.597), train_loss = 0.92510215, grad/param norm = 1.7412e-01, time/batch = 0.6698s	
25815/30300 (epoch 42.599), train_loss = 0.85072203, grad/param norm = 1.7317e-01, time/batch = 0.6696s	
25816/30300 (epoch 42.601), train_loss = 1.01787948, grad/param norm = 1.8097e-01, time/batch = 0.6687s	
25817/30300 (epoch 42.602), train_loss = 0.97052034, grad/param norm = 1.5791e-01, time/batch = 0.6700s	
25818/30300 (epoch 42.604), train_loss = 0.92076886, grad/param norm = 1.6320e-01, time/batch = 0.6811s	
25819/30300 (epoch 42.606), train_loss = 0.94435581, grad/param norm = 2.8966e-01, time/batch = 0.6679s	
25820/30300 (epoch 42.607), train_loss = 1.06943384, grad/param norm = 2.3170e-01, time/batch = 0.6687s	
25821/30300 (epoch 42.609), train_loss = 1.13937568, grad/param norm = 1.8908e-01, time/batch = 0.6702s	
25822/30300 (epoch 42.611), train_loss = 0.95130208, grad/param norm = 1.5466e-01, time/batch = 0.6706s	
25823/30300 (epoch 42.612), train_loss = 0.89293235, grad/param norm = 1.9614e-01, time/batch = 0.6720s	
25824/30300 (epoch 42.614), train_loss = 0.96771699, grad/param norm = 1.6054e-01, time/batch = 0.6673s	
25825/30300 (epoch 42.616), train_loss = 0.99743308, grad/param norm = 1.8873e-01, time/batch = 0.6982s	
25826/30300 (epoch 42.617), train_loss = 0.98632790, grad/param norm = 1.8558e-01, time/batch = 0.7008s	
25827/30300 (epoch 42.619), train_loss = 0.81478720, grad/param norm = 1.4478e-01, time/batch = 0.6677s	
25828/30300 (epoch 42.620), train_loss = 1.03062308, grad/param norm = 1.7391e-01, time/batch = 0.6676s	
25829/30300 (epoch 42.622), train_loss = 0.97765927, grad/param norm = 2.0195e-01, time/batch = 0.6709s	
25830/30300 (epoch 42.624), train_loss = 0.95750085, grad/param norm = 1.5685e-01, time/batch = 0.6744s	
25831/30300 (epoch 42.625), train_loss = 0.97504198, grad/param norm = 1.9318e-01, time/batch = 0.6793s	
25832/30300 (epoch 42.627), train_loss = 1.06818356, grad/param norm = 1.9899e-01, time/batch = 0.6759s	
25833/30300 (epoch 42.629), train_loss = 1.10029535, grad/param norm = 1.7498e-01, time/batch = 0.6757s	
25834/30300 (epoch 42.630), train_loss = 0.97963468, grad/param norm = 1.7896e-01, time/batch = 0.6671s	
25835/30300 (epoch 42.632), train_loss = 1.02885573, grad/param norm = 1.8168e-01, time/batch = 0.6660s	
25836/30300 (epoch 42.634), train_loss = 0.90535484, grad/param norm = 1.6270e-01, time/batch = 0.6706s	
25837/30300 (epoch 42.635), train_loss = 1.02723080, grad/param norm = 1.8683e-01, time/batch = 0.6723s	
25838/30300 (epoch 42.637), train_loss = 1.06064099, grad/param norm = 2.1672e-01, time/batch = 0.6771s	
25839/30300 (epoch 42.639), train_loss = 0.96806206, grad/param norm = 1.8773e-01, time/batch = 0.6705s	
25840/30300 (epoch 42.640), train_loss = 1.08834045, grad/param norm = 1.7451e-01, time/batch = 0.6649s	
25841/30300 (epoch 42.642), train_loss = 0.97223177, grad/param norm = 1.6105e-01, time/batch = 0.6672s	
25842/30300 (epoch 42.644), train_loss = 1.05378969, grad/param norm = 1.8452e-01, time/batch = 0.6710s	
25843/30300 (epoch 42.645), train_loss = 0.92925222, grad/param norm = 1.5653e-01, time/batch = 0.6765s	
25844/30300 (epoch 42.647), train_loss = 0.98712423, grad/param norm = 1.6642e-01, time/batch = 0.6656s	
25845/30300 (epoch 42.649), train_loss = 0.97479825, grad/param norm = 2.1327e-01, time/batch = 0.6704s	
25846/30300 (epoch 42.650), train_loss = 0.98140658, grad/param norm = 1.6381e-01, time/batch = 0.6709s	
25847/30300 (epoch 42.652), train_loss = 0.97339870, grad/param norm = 1.8525e-01, time/batch = 0.6722s	
25848/30300 (epoch 42.653), train_loss = 1.14498466, grad/param norm = 1.5789e-01, time/batch = 0.6789s	
25849/30300 (epoch 42.655), train_loss = 0.97143762, grad/param norm = 2.0561e-01, time/batch = 0.6875s	
25850/30300 (epoch 42.657), train_loss = 0.89125275, grad/param norm = 2.3155e-01, time/batch = 0.6793s	
25851/30300 (epoch 42.658), train_loss = 0.96358712, grad/param norm = 1.6072e-01, time/batch = 0.7064s	
25852/30300 (epoch 42.660), train_loss = 0.98615340, grad/param norm = 1.6611e-01, time/batch = 0.7159s	
25853/30300 (epoch 42.662), train_loss = 1.00113600, grad/param norm = 1.8796e-01, time/batch = 0.6778s	
25854/30300 (epoch 42.663), train_loss = 1.06119243, grad/param norm = 1.7167e-01, time/batch = 0.6857s	
25855/30300 (epoch 42.665), train_loss = 0.92251862, grad/param norm = 1.8608e-01, time/batch = 0.7142s	
25856/30300 (epoch 42.667), train_loss = 1.04424330, grad/param norm = 1.7389e-01, time/batch = 0.6721s	
25857/30300 (epoch 42.668), train_loss = 1.07026300, grad/param norm = 1.7681e-01, time/batch = 0.6654s	
25858/30300 (epoch 42.670), train_loss = 1.07781759, grad/param norm = 1.7208e-01, time/batch = 0.6669s	
25859/30300 (epoch 42.672), train_loss = 0.99773710, grad/param norm = 1.8916e-01, time/batch = 0.6705s	
25860/30300 (epoch 42.673), train_loss = 1.04434354, grad/param norm = 1.9647e-01, time/batch = 0.6709s	
25861/30300 (epoch 42.675), train_loss = 0.96589409, grad/param norm = 1.7872e-01, time/batch = 0.6733s	
25862/30300 (epoch 42.677), train_loss = 0.94237637, grad/param norm = 1.5382e-01, time/batch = 0.6699s	
25863/30300 (epoch 42.678), train_loss = 0.93593080, grad/param norm = 1.5731e-01, time/batch = 0.6797s	
25864/30300 (epoch 42.680), train_loss = 0.89468532, grad/param norm = 1.5817e-01, time/batch = 0.6741s	
25865/30300 (epoch 42.682), train_loss = 0.96859229, grad/param norm = 1.7526e-01, time/batch = 0.6702s	
25866/30300 (epoch 42.683), train_loss = 1.06713828, grad/param norm = 1.6497e-01, time/batch = 0.6736s	
25867/30300 (epoch 42.685), train_loss = 1.04107716, grad/param norm = 2.0339e-01, time/batch = 0.6706s	
25868/30300 (epoch 42.686), train_loss = 0.97977147, grad/param norm = 1.6517e-01, time/batch = 0.6697s	
25869/30300 (epoch 42.688), train_loss = 0.97933825, grad/param norm = 1.5993e-01, time/batch = 0.6933s	
25870/30300 (epoch 42.690), train_loss = 0.93869507, grad/param norm = 1.7293e-01, time/batch = 0.7192s	
25871/30300 (epoch 42.691), train_loss = 0.98516837, grad/param norm = 1.6909e-01, time/batch = 0.6838s	
25872/30300 (epoch 42.693), train_loss = 1.25196429, grad/param norm = 1.8899e-01, time/batch = 0.6825s	
25873/30300 (epoch 42.695), train_loss = 1.07389620, grad/param norm = 3.1810e-01, time/batch = 0.6816s	
25874/30300 (epoch 42.696), train_loss = 1.04414857, grad/param norm = 1.9990e-01, time/batch = 0.6930s	
25875/30300 (epoch 42.698), train_loss = 0.96279607, grad/param norm = 1.9231e-01, time/batch = 0.6907s	
25876/30300 (epoch 42.700), train_loss = 0.94929762, grad/param norm = 1.7724e-01, time/batch = 0.6717s	
25877/30300 (epoch 42.701), train_loss = 0.88489239, grad/param norm = 1.6975e-01, time/batch = 0.6670s	
25878/30300 (epoch 42.703), train_loss = 0.98963480, grad/param norm = 1.6577e-01, time/batch = 0.6674s	
25879/30300 (epoch 42.705), train_loss = 0.90934265, grad/param norm = 1.8114e-01, time/batch = 0.6660s	
25880/30300 (epoch 42.706), train_loss = 1.05259761, grad/param norm = 1.7454e-01, time/batch = 0.6675s	
25881/30300 (epoch 42.708), train_loss = 0.99021130, grad/param norm = 1.6261e-01, time/batch = 0.6699s	
25882/30300 (epoch 42.710), train_loss = 0.96442973, grad/param norm = 1.7503e-01, time/batch = 0.6676s	
25883/30300 (epoch 42.711), train_loss = 0.92939141, grad/param norm = 1.7099e-01, time/batch = 0.6710s	
25884/30300 (epoch 42.713), train_loss = 0.93435044, grad/param norm = 1.7069e-01, time/batch = 0.7115s	
25885/30300 (epoch 42.715), train_loss = 0.95261160, grad/param norm = 1.6977e-01, time/batch = 0.6899s	
25886/30300 (epoch 42.716), train_loss = 1.05079823, grad/param norm = 1.7064e-01, time/batch = 0.6666s	
25887/30300 (epoch 42.718), train_loss = 1.09544185, grad/param norm = 1.8158e-01, time/batch = 0.6669s	
25888/30300 (epoch 42.719), train_loss = 0.95062734, grad/param norm = 2.0007e-01, time/batch = 0.6661s	
25889/30300 (epoch 42.721), train_loss = 0.98038214, grad/param norm = 2.0206e-01, time/batch = 0.6669s	
25890/30300 (epoch 42.723), train_loss = 0.91818759, grad/param norm = 1.6904e-01, time/batch = 0.6705s	
25891/30300 (epoch 42.724), train_loss = 1.01394748, grad/param norm = 1.9538e-01, time/batch = 0.6709s	
25892/30300 (epoch 42.726), train_loss = 1.25254809, grad/param norm = 2.1750e-01, time/batch = 0.6708s	
25893/30300 (epoch 42.728), train_loss = 1.02781080, grad/param norm = 1.8775e-01, time/batch = 0.6694s	
25894/30300 (epoch 42.729), train_loss = 0.95455120, grad/param norm = 1.9285e-01, time/batch = 0.6676s	
25895/30300 (epoch 42.731), train_loss = 0.95338601, grad/param norm = 1.8238e-01, time/batch = 0.6666s	
25896/30300 (epoch 42.733), train_loss = 0.99003656, grad/param norm = 1.6982e-01, time/batch = 0.6694s	
25897/30300 (epoch 42.734), train_loss = 1.07249207, grad/param norm = 1.6769e-01, time/batch = 0.6722s	
25898/30300 (epoch 42.736), train_loss = 1.00827276, grad/param norm = 1.7158e-01, time/batch = 0.6716s	
25899/30300 (epoch 42.738), train_loss = 0.92689582, grad/param norm = 1.4045e-01, time/batch = 0.6728s	
25900/30300 (epoch 42.739), train_loss = 1.10841632, grad/param norm = 1.9738e-01, time/batch = 0.6696s	
25901/30300 (epoch 42.741), train_loss = 1.12688392, grad/param norm = 1.6690e-01, time/batch = 0.6691s	
25902/30300 (epoch 42.743), train_loss = 0.95886256, grad/param norm = 1.6783e-01, time/batch = 0.6681s	
25903/30300 (epoch 42.744), train_loss = 1.03005755, grad/param norm = 1.7216e-01, time/batch = 0.6686s	
25904/30300 (epoch 42.746), train_loss = 0.94970830, grad/param norm = 1.5124e-01, time/batch = 0.6692s	
25905/30300 (epoch 42.748), train_loss = 0.97604328, grad/param norm = 2.0084e-01, time/batch = 0.6725s	
25906/30300 (epoch 42.749), train_loss = 1.00236753, grad/param norm = 1.7127e-01, time/batch = 0.6710s	
25907/30300 (epoch 42.751), train_loss = 1.04819315, grad/param norm = 1.7806e-01, time/batch = 0.6702s	
25908/30300 (epoch 42.752), train_loss = 0.97280594, grad/param norm = 1.7959e-01, time/batch = 0.6748s	
25909/30300 (epoch 42.754), train_loss = 0.97355448, grad/param norm = 1.5560e-01, time/batch = 0.6738s	
25910/30300 (epoch 42.756), train_loss = 0.96942278, grad/param norm = 1.5699e-01, time/batch = 0.6721s	
25911/30300 (epoch 42.757), train_loss = 0.91418413, grad/param norm = 1.6990e-01, time/batch = 0.6739s	
25912/30300 (epoch 42.759), train_loss = 1.00615576, grad/param norm = 1.6749e-01, time/batch = 0.6698s	
25913/30300 (epoch 42.761), train_loss = 0.86576802, grad/param norm = 1.6990e-01, time/batch = 0.6769s	
25914/30300 (epoch 42.762), train_loss = 0.88321824, grad/param norm = 1.6420e-01, time/batch = 0.6753s	
25915/30300 (epoch 42.764), train_loss = 0.97141883, grad/param norm = 1.9092e-01, time/batch = 0.6726s	
25916/30300 (epoch 42.766), train_loss = 1.11105798, grad/param norm = 2.0960e-01, time/batch = 0.6949s	
25917/30300 (epoch 42.767), train_loss = 1.00027243, grad/param norm = 2.1269e-01, time/batch = 0.6802s	
25918/30300 (epoch 42.769), train_loss = 0.99507330, grad/param norm = 2.0029e-01, time/batch = 0.6811s	
25919/30300 (epoch 42.771), train_loss = 0.94644843, grad/param norm = 2.4275e-01, time/batch = 0.6760s	
25920/30300 (epoch 42.772), train_loss = 0.99603509, grad/param norm = 1.7866e-01, time/batch = 0.6665s	
25921/30300 (epoch 42.774), train_loss = 1.14473023, grad/param norm = 1.7973e-01, time/batch = 0.6721s	
25922/30300 (epoch 42.776), train_loss = 0.95461928, grad/param norm = 2.0655e-01, time/batch = 0.6777s	
25923/30300 (epoch 42.777), train_loss = 1.11239836, grad/param norm = 1.7149e-01, time/batch = 0.6698s	
25924/30300 (epoch 42.779), train_loss = 1.10895618, grad/param norm = 2.0810e-01, time/batch = 0.8775s	
25925/30300 (epoch 42.781), train_loss = 1.00622260, grad/param norm = 2.0378e-01, time/batch = 0.9762s	
25926/30300 (epoch 42.782), train_loss = 0.91885944, grad/param norm = 1.7544e-01, time/batch = 0.9826s	
25927/30300 (epoch 42.784), train_loss = 0.96064183, grad/param norm = 1.7498e-01, time/batch = 0.9763s	
25928/30300 (epoch 42.785), train_loss = 1.05610311, grad/param norm = 2.1316e-01, time/batch = 0.9894s	
25929/30300 (epoch 42.787), train_loss = 0.84386908, grad/param norm = 1.7650e-01, time/batch = 1.4948s	
25930/30300 (epoch 42.789), train_loss = 1.14252181, grad/param norm = 1.9903e-01, time/batch = 1.8782s	
25931/30300 (epoch 42.790), train_loss = 0.99571493, grad/param norm = 2.3778e-01, time/batch = 1.8802s	
25932/30300 (epoch 42.792), train_loss = 0.79675284, grad/param norm = 1.6316e-01, time/batch = 5.5006s	
25933/30300 (epoch 42.794), train_loss = 1.00606674, grad/param norm = 1.9713e-01, time/batch = 0.6763s	
25934/30300 (epoch 42.795), train_loss = 0.91610441, grad/param norm = 1.5897e-01, time/batch = 0.6750s	
25935/30300 (epoch 42.797), train_loss = 1.13394630, grad/param norm = 2.0744e-01, time/batch = 0.6720s	
25936/30300 (epoch 42.799), train_loss = 1.07331803, grad/param norm = 2.3352e-01, time/batch = 0.6679s	
25937/30300 (epoch 42.800), train_loss = 1.05137035, grad/param norm = 1.9097e-01, time/batch = 0.6693s	
25938/30300 (epoch 42.802), train_loss = 1.23203019, grad/param norm = 1.9465e-01, time/batch = 0.6749s	
25939/30300 (epoch 42.804), train_loss = 1.05337443, grad/param norm = 2.0251e-01, time/batch = 0.6755s	
25940/30300 (epoch 42.805), train_loss = 1.12731711, grad/param norm = 1.9061e-01, time/batch = 0.6669s	
25941/30300 (epoch 42.807), train_loss = 0.95347190, grad/param norm = 1.7920e-01, time/batch = 0.6682s	
25942/30300 (epoch 42.809), train_loss = 1.08256981, grad/param norm = 1.8533e-01, time/batch = 0.6658s	
25943/30300 (epoch 42.810), train_loss = 1.04196728, grad/param norm = 1.8924e-01, time/batch = 0.6663s	
25944/30300 (epoch 42.812), train_loss = 0.95729576, grad/param norm = 1.5780e-01, time/batch = 0.6683s	
25945/30300 (epoch 42.814), train_loss = 1.00726223, grad/param norm = 1.7095e-01, time/batch = 0.6870s	
25946/30300 (epoch 42.815), train_loss = 1.00977903, grad/param norm = 2.2230e-01, time/batch = 0.6820s	
25947/30300 (epoch 42.817), train_loss = 1.07847745, grad/param norm = 2.0280e-01, time/batch = 0.9347s	
25948/30300 (epoch 42.818), train_loss = 1.03710208, grad/param norm = 1.7560e-01, time/batch = 1.0407s	
25949/30300 (epoch 42.820), train_loss = 1.16445336, grad/param norm = 2.0595e-01, time/batch = 0.9794s	
25950/30300 (epoch 42.822), train_loss = 1.13587785, grad/param norm = 2.0668e-01, time/batch = 0.9849s	
25951/30300 (epoch 42.823), train_loss = 1.12423931, grad/param norm = 2.2376e-01, time/batch = 0.9899s	
25952/30300 (epoch 42.825), train_loss = 1.13161594, grad/param norm = 2.0486e-01, time/batch = 1.6986s	
25953/30300 (epoch 42.827), train_loss = 0.85984020, grad/param norm = 1.9758e-01, time/batch = 1.8314s	
25954/30300 (epoch 42.828), train_loss = 1.09637520, grad/param norm = 1.8322e-01, time/batch = 3.2690s	
25955/30300 (epoch 42.830), train_loss = 1.04918948, grad/param norm = 1.7920e-01, time/batch = 15.1818s	
25956/30300 (epoch 42.832), train_loss = 0.93634430, grad/param norm = 1.6913e-01, time/batch = 14.4056s	
25957/30300 (epoch 42.833), train_loss = 1.02275961, grad/param norm = 1.9358e-01, time/batch = 14.8812s	
25958/30300 (epoch 42.835), train_loss = 0.94245774, grad/param norm = 1.8747e-01, time/batch = 14.4783s	
25959/30300 (epoch 42.837), train_loss = 0.92244290, grad/param norm = 1.8552e-01, time/batch = 14.4096s	
25960/30300 (epoch 42.838), train_loss = 0.91673734, grad/param norm = 1.6372e-01, time/batch = 14.3235s	
25961/30300 (epoch 42.840), train_loss = 1.07703112, grad/param norm = 1.6193e-01, time/batch = 14.8899s	
25962/30300 (epoch 42.842), train_loss = 0.97013298, grad/param norm = 1.6108e-01, time/batch = 14.4904s	
25963/30300 (epoch 42.843), train_loss = 1.03197210, grad/param norm = 1.8020e-01, time/batch = 14.4751s	
25964/30300 (epoch 42.845), train_loss = 1.03633581, grad/param norm = 1.5310e-01, time/batch = 14.4784s	
25965/30300 (epoch 42.847), train_loss = 1.01477217, grad/param norm = 2.0435e-01, time/batch = 14.7858s	
25966/30300 (epoch 42.848), train_loss = 1.04651451, grad/param norm = 1.7562e-01, time/batch = 14.3957s	
25967/30300 (epoch 42.850), train_loss = 0.98927545, grad/param norm = 1.6496e-01, time/batch = 14.5589s	
25968/30300 (epoch 42.851), train_loss = 1.04741240, grad/param norm = 2.1760e-01, time/batch = 14.5704s	
25969/30300 (epoch 42.853), train_loss = 0.98327885, grad/param norm = 1.8180e-01, time/batch = 15.2001s	
25970/30300 (epoch 42.855), train_loss = 0.94840402, grad/param norm = 1.5989e-01, time/batch = 15.0501s	
25971/30300 (epoch 42.856), train_loss = 0.99692060, grad/param norm = 1.6548e-01, time/batch = 14.9488s	
25972/30300 (epoch 42.858), train_loss = 0.92743957, grad/param norm = 1.6848e-01, time/batch = 14.6417s	
25973/30300 (epoch 42.860), train_loss = 0.91021122, grad/param norm = 1.5936e-01, time/batch = 12.8309s	
25974/30300 (epoch 42.861), train_loss = 1.12801678, grad/param norm = 1.8087e-01, time/batch = 0.6702s	
25975/30300 (epoch 42.863), train_loss = 0.95908857, grad/param norm = 1.6274e-01, time/batch = 0.6664s	
25976/30300 (epoch 42.865), train_loss = 1.05640761, grad/param norm = 1.9717e-01, time/batch = 0.6692s	
25977/30300 (epoch 42.866), train_loss = 1.06745476, grad/param norm = 1.7992e-01, time/batch = 0.6826s	
25978/30300 (epoch 42.868), train_loss = 1.03204927, grad/param norm = 1.8094e-01, time/batch = 0.7138s	
25979/30300 (epoch 42.870), train_loss = 0.94020395, grad/param norm = 1.8057e-01, time/batch = 0.6894s	
25980/30300 (epoch 42.871), train_loss = 1.02109350, grad/param norm = 1.7262e-01, time/batch = 0.6739s	
25981/30300 (epoch 42.873), train_loss = 1.01542635, grad/param norm = 1.6336e-01, time/batch = 0.9384s	
25982/30300 (epoch 42.875), train_loss = 0.96449311, grad/param norm = 1.5835e-01, time/batch = 0.9760s	
25983/30300 (epoch 42.876), train_loss = 0.89694184, grad/param norm = 1.7910e-01, time/batch = 0.9963s	
25984/30300 (epoch 42.878), train_loss = 0.84943791, grad/param norm = 1.7726e-01, time/batch = 0.9942s	
25985/30300 (epoch 42.880), train_loss = 0.91285789, grad/param norm = 1.6771e-01, time/batch = 0.9847s	
25986/30300 (epoch 42.881), train_loss = 1.15287622, grad/param norm = 2.3955e-01, time/batch = 1.6322s	
25987/30300 (epoch 42.883), train_loss = 1.06949372, grad/param norm = 2.3005e-01, time/batch = 1.8204s	
25988/30300 (epoch 42.884), train_loss = 0.99566786, grad/param norm = 1.5449e-01, time/batch = 2.4420s	
25989/30300 (epoch 42.886), train_loss = 1.05922943, grad/param norm = 1.9038e-01, time/batch = 14.5705s	
25990/30300 (epoch 42.888), train_loss = 0.95222426, grad/param norm = 1.7445e-01, time/batch = 14.2366s	
25991/30300 (epoch 42.889), train_loss = 1.02867737, grad/param norm = 1.7260e-01, time/batch = 14.7326s	
25992/30300 (epoch 42.891), train_loss = 0.98290684, grad/param norm = 1.7359e-01, time/batch = 14.7067s	
25993/30300 (epoch 42.893), train_loss = 1.21196090, grad/param norm = 1.8716e-01, time/batch = 14.4826s	
25994/30300 (epoch 42.894), train_loss = 1.01753969, grad/param norm = 1.7079e-01, time/batch = 14.4828s	
25995/30300 (epoch 42.896), train_loss = 0.86374898, grad/param norm = 1.6792e-01, time/batch = 14.8633s	
25996/30300 (epoch 42.898), train_loss = 0.85676229, grad/param norm = 1.6190e-01, time/batch = 15.4184s	
25997/30300 (epoch 42.899), train_loss = 0.89182894, grad/param norm = 1.6770e-01, time/batch = 14.3799s	
25998/30300 (epoch 42.901), train_loss = 1.00286133, grad/param norm = 2.8799e-01, time/batch = 14.3984s	
25999/30300 (epoch 42.903), train_loss = 0.97145445, grad/param norm = 1.9682e-01, time/batch = 14.7223s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch42.90_2.0525.t7	
26000/30300 (epoch 42.904), train_loss = 1.01322354, grad/param norm = 1.6112e-01, time/batch = 14.3949s	
26001/30300 (epoch 42.906), train_loss = 1.69493489, grad/param norm = 4.1299e-01, time/batch = 14.6452s	
26002/30300 (epoch 42.908), train_loss = 0.96380496, grad/param norm = 1.8450e-01, time/batch = 14.3801s	
26003/30300 (epoch 42.909), train_loss = 0.99106014, grad/param norm = 4.8958e-01, time/batch = 14.7261s	
26004/30300 (epoch 42.911), train_loss = 0.98920329, grad/param norm = 1.6913e-01, time/batch = 14.8868s	
26005/30300 (epoch 42.913), train_loss = 0.98799412, grad/param norm = 1.5570e-01, time/batch = 14.5683s	
26006/30300 (epoch 42.914), train_loss = 0.96318120, grad/param norm = 1.8539e-01, time/batch = 14.5648s	
26007/30300 (epoch 42.916), train_loss = 1.01666614, grad/param norm = 1.6149e-01, time/batch = 14.9628s	
26008/30300 (epoch 42.917), train_loss = 0.93773726, grad/param norm = 1.4976e-01, time/batch = 14.4033s	
26009/30300 (epoch 42.919), train_loss = 0.88634294, grad/param norm = 2.0713e-01, time/batch = 14.6448s	
26010/30300 (epoch 42.921), train_loss = 0.97523417, grad/param norm = 1.6527e-01, time/batch = 14.8091s	
26011/30300 (epoch 42.922), train_loss = 1.12291167, grad/param norm = 2.2579e-01, time/batch = 15.6940s	
26012/30300 (epoch 42.924), train_loss = 0.99754614, grad/param norm = 1.9300e-01, time/batch = 14.7160s	
26013/30300 (epoch 42.926), train_loss = 1.04070023, grad/param norm = 1.9044e-01, time/batch = 15.4983s	
26014/30300 (epoch 42.927), train_loss = 1.02045548, grad/param norm = 1.7441e-01, time/batch = 15.2740s	
26015/30300 (epoch 42.929), train_loss = 0.94807913, grad/param norm = 2.2061e-01, time/batch = 15.3816s	
26016/30300 (epoch 42.931), train_loss = 1.07391531, grad/param norm = 2.2367e-01, time/batch = 14.6883s	
26017/30300 (epoch 42.932), train_loss = 0.92610310, grad/param norm = 2.0780e-01, time/batch = 14.5703s	
26018/30300 (epoch 42.934), train_loss = 1.02759515, grad/param norm = 1.5848e-01, time/batch = 14.6416s	
26019/30300 (epoch 42.936), train_loss = 0.95804786, grad/param norm = 1.8499e-01, time/batch = 15.0433s	
26020/30300 (epoch 42.937), train_loss = 0.96361365, grad/param norm = 1.8514e-01, time/batch = 14.3942s	
26021/30300 (epoch 42.939), train_loss = 1.08791925, grad/param norm = 1.9425e-01, time/batch = 14.8731s	
26022/30300 (epoch 42.941), train_loss = 0.97209653, grad/param norm = 1.8505e-01, time/batch = 14.3132s	
26023/30300 (epoch 42.942), train_loss = 0.97057351, grad/param norm = 1.6589e-01, time/batch = 15.0501s	
26024/30300 (epoch 42.944), train_loss = 0.87858952, grad/param norm = 1.5060e-01, time/batch = 14.4724s	
26025/30300 (epoch 42.946), train_loss = 1.06600541, grad/param norm = 2.4824e-01, time/batch = 14.5582s	
26026/30300 (epoch 42.947), train_loss = 1.04355459, grad/param norm = 2.4065e-01, time/batch = 14.4011s	
26027/30300 (epoch 42.949), train_loss = 1.09523310, grad/param norm = 2.2435e-01, time/batch = 16.4673s	
26028/30300 (epoch 42.950), train_loss = 1.10408655, grad/param norm = 1.9187e-01, time/batch = 18.0614s	
26029/30300 (epoch 42.952), train_loss = 1.03455267, grad/param norm = 1.8332e-01, time/batch = 18.1435s	
26030/30300 (epoch 42.954), train_loss = 1.23138231, grad/param norm = 1.7264e-01, time/batch = 18.9547s	
26031/30300 (epoch 42.955), train_loss = 0.99669178, grad/param norm = 1.7658e-01, time/batch = 17.6291s	
26032/30300 (epoch 42.957), train_loss = 1.06605844, grad/param norm = 1.8761e-01, time/batch = 17.7783s	
26033/30300 (epoch 42.959), train_loss = 0.91575071, grad/param norm = 1.7840e-01, time/batch = 17.1123s	
26034/30300 (epoch 42.960), train_loss = 0.95892912, grad/param norm = 1.7588e-01, time/batch = 18.0348s	
26035/30300 (epoch 42.962), train_loss = 0.95002069, grad/param norm = 2.3670e-01, time/batch = 17.9540s	
26036/30300 (epoch 42.964), train_loss = 0.90848563, grad/param norm = 1.8486e-01, time/batch = 18.2108s	
26037/30300 (epoch 42.965), train_loss = 0.93582863, grad/param norm = 2.4816e-01, time/batch = 17.4548s	
26038/30300 (epoch 42.967), train_loss = 0.96350592, grad/param norm = 2.0646e-01, time/batch = 18.6357s	
26039/30300 (epoch 42.969), train_loss = 0.91615559, grad/param norm = 2.0079e-01, time/batch = 17.6324s	
26040/30300 (epoch 42.970), train_loss = 0.96505877, grad/param norm = 1.8025e-01, time/batch = 18.0493s	
26041/30300 (epoch 42.972), train_loss = 0.89073891, grad/param norm = 1.8087e-01, time/batch = 18.7043s	
26042/30300 (epoch 42.974), train_loss = 1.12243836, grad/param norm = 1.9222e-01, time/batch = 18.1854s	
26043/30300 (epoch 42.975), train_loss = 1.14114412, grad/param norm = 2.6964e-01, time/batch = 18.0641s	
26044/30300 (epoch 42.977), train_loss = 1.17804925, grad/param norm = 1.8414e-01, time/batch = 18.7883s	
26045/30300 (epoch 42.979), train_loss = 1.07075531, grad/param norm = 1.7998e-01, time/batch = 18.2981s	
26046/30300 (epoch 42.980), train_loss = 1.09910612, grad/param norm = 1.9549e-01, time/batch = 18.1402s	
26047/30300 (epoch 42.982), train_loss = 1.07551810, grad/param norm = 1.9573e-01, time/batch = 17.8884s	
26048/30300 (epoch 42.983), train_loss = 1.10208020, grad/param norm = 1.7089e-01, time/batch = 18.4591s	
26049/30300 (epoch 42.985), train_loss = 1.07535453, grad/param norm = 3.4011e-01, time/batch = 17.7884s	
26050/30300 (epoch 42.987), train_loss = 1.05113520, grad/param norm = 1.7633e-01, time/batch = 17.6216s	
26051/30300 (epoch 42.988), train_loss = 1.13784330, grad/param norm = 1.9761e-01, time/batch = 19.2129s	
26052/30300 (epoch 42.990), train_loss = 0.94132641, grad/param norm = 1.8032e-01, time/batch = 17.7109s	
26053/30300 (epoch 42.992), train_loss = 1.09489728, grad/param norm = 1.7399e-01, time/batch = 18.2060s	
26054/30300 (epoch 42.993), train_loss = 1.08168898, grad/param norm = 2.2517e-01, time/batch = 3.0412s	
26055/30300 (epoch 42.995), train_loss = 1.00700493, grad/param norm = 2.1472e-01, time/batch = 0.6748s	
26056/30300 (epoch 42.997), train_loss = 1.06737641, grad/param norm = 2.0178e-01, time/batch = 0.6842s	
26057/30300 (epoch 42.998), train_loss = 1.08045348, grad/param norm = 2.0389e-01, time/batch = 0.6797s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
26058/30300 (epoch 43.000), train_loss = 0.94179074, grad/param norm = 2.0860e-01, time/batch = 0.6997s	
26059/30300 (epoch 43.002), train_loss = 1.12047060, grad/param norm = 2.1873e-01, time/batch = 0.7135s	
26060/30300 (epoch 43.003), train_loss = 1.02779086, grad/param norm = 1.7616e-01, time/batch = 0.6836s	
26061/30300 (epoch 43.005), train_loss = 0.98147511, grad/param norm = 1.8118e-01, time/batch = 0.8819s	
26062/30300 (epoch 43.007), train_loss = 1.07793545, grad/param norm = 2.0776e-01, time/batch = 0.9793s	
26063/30300 (epoch 43.008), train_loss = 1.01323530, grad/param norm = 1.8457e-01, time/batch = 0.9888s	
26064/30300 (epoch 43.010), train_loss = 0.90148621, grad/param norm = 1.8292e-01, time/batch = 0.9802s	
26065/30300 (epoch 43.012), train_loss = 0.97661955, grad/param norm = 1.8350e-01, time/batch = 0.9873s	
26066/30300 (epoch 43.013), train_loss = 1.09675232, grad/param norm = 2.0622e-01, time/batch = 1.4837s	
26067/30300 (epoch 43.015), train_loss = 0.96662212, grad/param norm = 1.8117e-01, time/batch = 1.8436s	
26068/30300 (epoch 43.017), train_loss = 0.99357574, grad/param norm = 1.6415e-01, time/batch = 1.8910s	
26069/30300 (epoch 43.018), train_loss = 0.88891987, grad/param norm = 1.6163e-01, time/batch = 15.6411s	
26070/30300 (epoch 43.020), train_loss = 1.11087403, grad/param norm = 2.0089e-01, time/batch = 18.3898s	
26071/30300 (epoch 43.021), train_loss = 1.12328114, grad/param norm = 1.8146e-01, time/batch = 15.7102s	
26072/30300 (epoch 43.023), train_loss = 1.00902630, grad/param norm = 1.5158e-01, time/batch = 15.2503s	
26073/30300 (epoch 43.025), train_loss = 0.94210048, grad/param norm = 1.8827e-01, time/batch = 18.8657s	
26074/30300 (epoch 43.026), train_loss = 1.10026928, grad/param norm = 2.3984e-01, time/batch = 18.4665s	
26075/30300 (epoch 43.028), train_loss = 1.07987454, grad/param norm = 1.8376e-01, time/batch = 17.8108s	
26076/30300 (epoch 43.030), train_loss = 0.96128897, grad/param norm = 1.7741e-01, time/batch = 19.2162s	
26077/30300 (epoch 43.031), train_loss = 1.04500690, grad/param norm = 1.7946e-01, time/batch = 17.8929s	
26078/30300 (epoch 43.033), train_loss = 1.02905913, grad/param norm = 1.7857e-01, time/batch = 18.2000s	
26079/30300 (epoch 43.035), train_loss = 1.03136756, grad/param norm = 1.9183e-01, time/batch = 18.0596s	
26080/30300 (epoch 43.036), train_loss = 1.04287303, grad/param norm = 2.0060e-01, time/batch = 18.9629s	
26081/30300 (epoch 43.038), train_loss = 1.06801525, grad/param norm = 1.6464e-01, time/batch = 16.2991s	
26082/30300 (epoch 43.040), train_loss = 0.87245310, grad/param norm = 1.6407e-01, time/batch = 18.4698s	
26083/30300 (epoch 43.041), train_loss = 0.84996334, grad/param norm = 1.7359e-01, time/batch = 15.3629s	
26084/30300 (epoch 43.043), train_loss = 1.04732278, grad/param norm = 1.7171e-01, time/batch = 17.7757s	
26085/30300 (epoch 43.045), train_loss = 0.94166258, grad/param norm = 1.6508e-01, time/batch = 17.7787s	
26086/30300 (epoch 43.046), train_loss = 1.11737376, grad/param norm = 1.8472e-01, time/batch = 18.9720s	
26087/30300 (epoch 43.048), train_loss = 1.03419862, grad/param norm = 2.5412e-01, time/batch = 17.5347s	
26088/30300 (epoch 43.050), train_loss = 0.91236143, grad/param norm = 1.6513e-01, time/batch = 17.9572s	
26089/30300 (epoch 43.051), train_loss = 1.03179297, grad/param norm = 1.8129e-01, time/batch = 17.0466s	
26090/30300 (epoch 43.053), train_loss = 0.88942345, grad/param norm = 2.2575e-01, time/batch = 18.4700s	
26091/30300 (epoch 43.054), train_loss = 1.04320463, grad/param norm = 1.7136e-01, time/batch = 18.2119s	
26092/30300 (epoch 43.056), train_loss = 0.93287235, grad/param norm = 1.7959e-01, time/batch = 19.0467s	
26093/30300 (epoch 43.058), train_loss = 0.97204037, grad/param norm = 1.8289e-01, time/batch = 18.9556s	
26094/30300 (epoch 43.059), train_loss = 0.95928690, grad/param norm = 2.0177e-01, time/batch = 17.0243s	
26095/30300 (epoch 43.061), train_loss = 1.04842836, grad/param norm = 1.8902e-01, time/batch = 18.3773s	
26096/30300 (epoch 43.063), train_loss = 0.90600079, grad/param norm = 1.8930e-01, time/batch = 16.1011s	
26097/30300 (epoch 43.064), train_loss = 0.98720733, grad/param norm = 1.8511e-01, time/batch = 17.8705s	
26098/30300 (epoch 43.066), train_loss = 1.00584639, grad/param norm = 1.7169e-01, time/batch = 18.4403s	
26099/30300 (epoch 43.068), train_loss = 0.93838229, grad/param norm = 1.7935e-01, time/batch = 18.8776s	
26100/30300 (epoch 43.069), train_loss = 1.03654355, grad/param norm = 1.6547e-01, time/batch = 18.0426s	
26101/30300 (epoch 43.071), train_loss = 1.04581008, grad/param norm = 2.0389e-01, time/batch = 16.9564s	
26102/30300 (epoch 43.073), train_loss = 0.92149613, grad/param norm = 1.8574e-01, time/batch = 18.8832s	
26103/30300 (epoch 43.074), train_loss = 0.96116353, grad/param norm = 1.6076e-01, time/batch = 17.8686s	
26104/30300 (epoch 43.076), train_loss = 0.98557391, grad/param norm = 1.7215e-01, time/batch = 17.8830s	
26105/30300 (epoch 43.078), train_loss = 0.93135662, grad/param norm = 1.7260e-01, time/batch = 18.8736s	
26106/30300 (epoch 43.079), train_loss = 0.96788217, grad/param norm = 1.6625e-01, time/batch = 18.9532s	
26107/30300 (epoch 43.081), train_loss = 1.01076389, grad/param norm = 1.9091e-01, time/batch = 17.8913s	
26108/30300 (epoch 43.083), train_loss = 1.09266830, grad/param norm = 3.1176e-01, time/batch = 17.4309s	
26109/30300 (epoch 43.084), train_loss = 0.95426731, grad/param norm = 1.6687e-01, time/batch = 14.7071s	
26110/30300 (epoch 43.086), train_loss = 0.95234427, grad/param norm = 1.7904e-01, time/batch = 18.3070s	
26111/30300 (epoch 43.087), train_loss = 0.93085861, grad/param norm = 1.5607e-01, time/batch = 17.9722s	
26112/30300 (epoch 43.089), train_loss = 0.91161756, grad/param norm = 1.6417e-01, time/batch = 18.3879s	
26113/30300 (epoch 43.091), train_loss = 1.03815034, grad/param norm = 1.7601e-01, time/batch = 18.9712s	
26114/30300 (epoch 43.092), train_loss = 1.07390019, grad/param norm = 1.6788e-01, time/batch = 17.9657s	
26115/30300 (epoch 43.094), train_loss = 1.10765623, grad/param norm = 2.0470e-01, time/batch = 17.7845s	
26116/30300 (epoch 43.096), train_loss = 1.12492691, grad/param norm = 1.8854e-01, time/batch = 18.4613s	
26117/30300 (epoch 43.097), train_loss = 0.96154031, grad/param norm = 2.0724e-01, time/batch = 18.3810s	
26118/30300 (epoch 43.099), train_loss = 1.05465522, grad/param norm = 1.6816e-01, time/batch = 18.0523s	
26119/30300 (epoch 43.101), train_loss = 1.08849579, grad/param norm = 2.0066e-01, time/batch = 18.8770s	
26120/30300 (epoch 43.102), train_loss = 0.94832005, grad/param norm = 2.1571e-01, time/batch = 19.1441s	
26121/30300 (epoch 43.104), train_loss = 0.99085095, grad/param norm = 2.3960e-01, time/batch = 18.5337s	
26122/30300 (epoch 43.106), train_loss = 0.93464693, grad/param norm = 1.8795e-01, time/batch = 18.1153s	
26123/30300 (epoch 43.107), train_loss = 1.05123900, grad/param norm = 1.6044e-01, time/batch = 18.5390s	
26124/30300 (epoch 43.109), train_loss = 1.06258848, grad/param norm = 1.9753e-01, time/batch = 17.1348s	
26125/30300 (epoch 43.111), train_loss = 1.06174865, grad/param norm = 2.1869e-01, time/batch = 19.1359s	
26126/30300 (epoch 43.112), train_loss = 1.14203140, grad/param norm = 1.9922e-01, time/batch = 16.7180s	
26127/30300 (epoch 43.114), train_loss = 0.96319175, grad/param norm = 1.6176e-01, time/batch = 17.6234s	
26128/30300 (epoch 43.116), train_loss = 1.03677779, grad/param norm = 2.1296e-01, time/batch = 18.9622s	
26129/30300 (epoch 43.117), train_loss = 1.10594441, grad/param norm = 1.9270e-01, time/batch = 18.8861s	
26130/30300 (epoch 43.119), train_loss = 0.90431862, grad/param norm = 1.8437e-01, time/batch = 18.1323s	
26131/30300 (epoch 43.120), train_loss = 0.98153576, grad/param norm = 2.1050e-01, time/batch = 17.3627s	
26132/30300 (epoch 43.122), train_loss = 1.11711299, grad/param norm = 2.5009e-01, time/batch = 18.6375s	
26133/30300 (epoch 43.124), train_loss = 1.16497735, grad/param norm = 2.0229e-01, time/batch = 17.7281s	
26134/30300 (epoch 43.125), train_loss = 0.91648321, grad/param norm = 1.7127e-01, time/batch = 17.1995s	
26135/30300 (epoch 43.127), train_loss = 1.02941036, grad/param norm = 2.0361e-01, time/batch = 18.7206s	
26136/30300 (epoch 43.129), train_loss = 1.06284071, grad/param norm = 1.8308e-01, time/batch = 18.6273s	
26137/30300 (epoch 43.130), train_loss = 1.14468854, grad/param norm = 1.8053e-01, time/batch = 17.7067s	
26138/30300 (epoch 43.132), train_loss = 1.11851828, grad/param norm = 1.8353e-01, time/batch = 18.8897s	
26139/30300 (epoch 43.134), train_loss = 0.92883352, grad/param norm = 1.9674e-01, time/batch = 18.7220s	
26140/30300 (epoch 43.135), train_loss = 0.94451748, grad/param norm = 1.9109e-01, time/batch = 18.5496s	
26141/30300 (epoch 43.137), train_loss = 1.01766432, grad/param norm = 1.9642e-01, time/batch = 16.2019s	
26142/30300 (epoch 43.139), train_loss = 0.94648376, grad/param norm = 2.8892e-01, time/batch = 17.8639s	
26143/30300 (epoch 43.140), train_loss = 1.02239764, grad/param norm = 2.2450e-01, time/batch = 19.0456s	
26144/30300 (epoch 43.142), train_loss = 1.08134925, grad/param norm = 2.5476e-01, time/batch = 17.7876s	
26145/30300 (epoch 43.144), train_loss = 0.96090718, grad/param norm = 2.5123e-01, time/batch = 18.2789s	
26146/30300 (epoch 43.145), train_loss = 1.08812135, grad/param norm = 2.5760e-01, time/batch = 18.4767s	
26147/30300 (epoch 43.147), train_loss = 0.96939015, grad/param norm = 2.0909e-01, time/batch = 18.5418s	
26148/30300 (epoch 43.149), train_loss = 1.09257153, grad/param norm = 2.2321e-01, time/batch = 17.8844s	
26149/30300 (epoch 43.150), train_loss = 1.00722350, grad/param norm = 2.8947e-01, time/batch = 18.2237s	
26150/30300 (epoch 43.152), train_loss = 0.92349420, grad/param norm = 2.0525e-01, time/batch = 18.0317s	
26151/30300 (epoch 43.153), train_loss = 1.03309082, grad/param norm = 2.0364e-01, time/batch = 16.8753s	
26152/30300 (epoch 43.155), train_loss = 0.90220703, grad/param norm = 1.7180e-01, time/batch = 18.7237s	
26153/30300 (epoch 43.157), train_loss = 0.94401505, grad/param norm = 2.0348e-01, time/batch = 18.3980s	
26154/30300 (epoch 43.158), train_loss = 1.06166046, grad/param norm = 2.4642e-01, time/batch = 17.3652s	
26155/30300 (epoch 43.160), train_loss = 0.92678394, grad/param norm = 1.8807e-01, time/batch = 17.6987s	
26156/30300 (epoch 43.162), train_loss = 0.99554536, grad/param norm = 1.7766e-01, time/batch = 17.6844s	
26157/30300 (epoch 43.163), train_loss = 1.00357959, grad/param norm = 2.3288e-01, time/batch = 17.9683s	
26158/30300 (epoch 43.165), train_loss = 1.12311531, grad/param norm = 1.9446e-01, time/batch = 18.9625s	
26159/30300 (epoch 43.167), train_loss = 1.01457272, grad/param norm = 1.9218e-01, time/batch = 18.6331s	
26160/30300 (epoch 43.168), train_loss = 1.05303338, grad/param norm = 1.9064e-01, time/batch = 18.0418s	
26161/30300 (epoch 43.170), train_loss = 1.03470942, grad/param norm = 2.1559e-01, time/batch = 18.5426s	
26162/30300 (epoch 43.172), train_loss = 1.02046984, grad/param norm = 2.3370e-01, time/batch = 18.6317s	
26163/30300 (epoch 43.173), train_loss = 0.96376250, grad/param norm = 1.8979e-01, time/batch = 18.3070s	
26164/30300 (epoch 43.175), train_loss = 1.01358830, grad/param norm = 1.7603e-01, time/batch = 18.4610s	
26165/30300 (epoch 43.177), train_loss = 1.07148695, grad/param norm = 1.9721e-01, time/batch = 18.3821s	
26166/30300 (epoch 43.178), train_loss = 0.82390160, grad/param norm = 1.4983e-01, time/batch = 17.1193s	
26167/30300 (epoch 43.180), train_loss = 0.98397328, grad/param norm = 1.7637e-01, time/batch = 31.9458s	
26168/30300 (epoch 43.182), train_loss = 1.02275834, grad/param norm = 2.1727e-01, time/batch = 18.9651s	
26169/30300 (epoch 43.183), train_loss = 0.93894200, grad/param norm = 1.9119e-01, time/batch = 17.4338s	
26170/30300 (epoch 43.185), train_loss = 1.11697102, grad/param norm = 1.8908e-01, time/batch = 17.8683s	
26171/30300 (epoch 43.186), train_loss = 1.21242340, grad/param norm = 2.0858e-01, time/batch = 19.0559s	
26172/30300 (epoch 43.188), train_loss = 1.06672389, grad/param norm = 2.1853e-01, time/batch = 18.6315s	
26173/30300 (epoch 43.190), train_loss = 0.99129742, grad/param norm = 1.7008e-01, time/batch = 17.8486s	
26174/30300 (epoch 43.191), train_loss = 1.05509637, grad/param norm = 1.9184e-01, time/batch = 17.9611s	
26175/30300 (epoch 43.193), train_loss = 0.92584350, grad/param norm = 1.8278e-01, time/batch = 17.1272s	
26176/30300 (epoch 43.195), train_loss = 0.95022672, grad/param norm = 1.7389e-01, time/batch = 17.5344s	
26177/30300 (epoch 43.196), train_loss = 1.03336945, grad/param norm = 1.6016e-01, time/batch = 18.9573s	
26178/30300 (epoch 43.198), train_loss = 0.85878720, grad/param norm = 1.7299e-01, time/batch = 17.7799s	
26179/30300 (epoch 43.200), train_loss = 0.95749543, grad/param norm = 1.7442e-01, time/batch = 17.6914s	
26180/30300 (epoch 43.201), train_loss = 1.08944609, grad/param norm = 2.3873e-01, time/batch = 17.7933s	
26181/30300 (epoch 43.203), train_loss = 1.00328880, grad/param norm = 2.0126e-01, time/batch = 18.2977s	
26182/30300 (epoch 43.205), train_loss = 1.17974499, grad/param norm = 2.0617e-01, time/batch = 18.1201s	
26183/30300 (epoch 43.206), train_loss = 1.08226860, grad/param norm = 1.9505e-01, time/batch = 18.1230s	
26184/30300 (epoch 43.208), train_loss = 1.08151400, grad/param norm = 2.8738e-01, time/batch = 18.8105s	
26185/30300 (epoch 43.210), train_loss = 1.09150048, grad/param norm = 1.8088e-01, time/batch = 18.3920s	
26186/30300 (epoch 43.211), train_loss = 1.12381357, grad/param norm = 1.9260e-01, time/batch = 17.2256s	
26187/30300 (epoch 43.213), train_loss = 1.01886545, grad/param norm = 1.6580e-01, time/batch = 18.8037s	
26188/30300 (epoch 43.215), train_loss = 0.94509906, grad/param norm = 2.0130e-01, time/batch = 18.4516s	
26189/30300 (epoch 43.216), train_loss = 0.94302879, grad/param norm = 1.5671e-01, time/batch = 17.7168s	
26190/30300 (epoch 43.218), train_loss = 0.92940582, grad/param norm = 1.7026e-01, time/batch = 17.0077s	
26191/30300 (epoch 43.219), train_loss = 0.89568294, grad/param norm = 1.8259e-01, time/batch = 18.3833s	
26192/30300 (epoch 43.221), train_loss = 0.85294229, grad/param norm = 1.5974e-01, time/batch = 18.5428s	
26193/30300 (epoch 43.223), train_loss = 1.00628559, grad/param norm = 1.7770e-01, time/batch = 17.2797s	
26194/30300 (epoch 43.224), train_loss = 0.84423909, grad/param norm = 1.7880e-01, time/batch = 18.7276s	
26195/30300 (epoch 43.226), train_loss = 1.06828114, grad/param norm = 2.3911e-01, time/batch = 17.7243s	
26196/30300 (epoch 43.228), train_loss = 1.12338864, grad/param norm = 1.9375e-01, time/batch = 17.6185s	
26197/30300 (epoch 43.229), train_loss = 1.00896685, grad/param norm = 1.8348e-01, time/batch = 19.0354s	
26198/30300 (epoch 43.231), train_loss = 1.06603664, grad/param norm = 1.7245e-01, time/batch = 18.7118s	
26199/30300 (epoch 43.233), train_loss = 1.05237511, grad/param norm = 1.5999e-01, time/batch = 16.7739s	
26200/30300 (epoch 43.234), train_loss = 1.09200010, grad/param norm = 2.3564e-01, time/batch = 18.6175s	
26201/30300 (epoch 43.236), train_loss = 1.05675218, grad/param norm = 1.6673e-01, time/batch = 19.2971s	
26202/30300 (epoch 43.238), train_loss = 1.01126147, grad/param norm = 2.1702e-01, time/batch = 18.0418s	
26203/30300 (epoch 43.239), train_loss = 0.95784982, grad/param norm = 2.1680e-01, time/batch = 18.7192s	
26204/30300 (epoch 43.241), train_loss = 1.03414499, grad/param norm = 1.9367e-01, time/batch = 18.7145s	
26205/30300 (epoch 43.243), train_loss = 1.05148436, grad/param norm = 1.7053e-01, time/batch = 18.4587s	
26206/30300 (epoch 43.244), train_loss = 1.19934977, grad/param norm = 1.9027e-01, time/batch = 18.3750s	
26207/30300 (epoch 43.246), train_loss = 1.06053310, grad/param norm = 1.7992e-01, time/batch = 18.1372s	
26208/30300 (epoch 43.248), train_loss = 0.98687481, grad/param norm = 1.6164e-01, time/batch = 18.3143s	
26209/30300 (epoch 43.249), train_loss = 0.90759511, grad/param norm = 1.8855e-01, time/batch = 17.3530s	
26210/30300 (epoch 43.251), train_loss = 0.94200870, grad/param norm = 1.8078e-01, time/batch = 18.8868s	
26211/30300 (epoch 43.252), train_loss = 1.10428649, grad/param norm = 1.9684e-01, time/batch = 18.8022s	
26212/30300 (epoch 43.254), train_loss = 1.08555661, grad/param norm = 1.9656e-01, time/batch = 16.2886s	
26213/30300 (epoch 43.256), train_loss = 1.05566135, grad/param norm = 1.8588e-01, time/batch = 18.8807s	
26214/30300 (epoch 43.257), train_loss = 1.06765155, grad/param norm = 1.9333e-01, time/batch = 18.1394s	
26215/30300 (epoch 43.259), train_loss = 0.99802601, grad/param norm = 1.7737e-01, time/batch = 18.3667s	
26216/30300 (epoch 43.261), train_loss = 1.15838933, grad/param norm = 1.8955e-01, time/batch = 17.9610s	
26217/30300 (epoch 43.262), train_loss = 0.94939877, grad/param norm = 1.6071e-01, time/batch = 17.3847s	
26218/30300 (epoch 43.264), train_loss = 1.00720507, grad/param norm = 1.6855e-01, time/batch = 18.9610s	
26219/30300 (epoch 43.266), train_loss = 1.00682865, grad/param norm = 1.6750e-01, time/batch = 17.1773s	
26220/30300 (epoch 43.267), train_loss = 1.15755656, grad/param norm = 2.1119e-01, time/batch = 18.8019s	
26221/30300 (epoch 43.269), train_loss = 1.03639100, grad/param norm = 1.7870e-01, time/batch = 19.1269s	
26222/30300 (epoch 43.271), train_loss = 1.02888939, grad/param norm = 1.6797e-01, time/batch = 17.2113s	
26223/30300 (epoch 43.272), train_loss = 1.03096124, grad/param norm = 2.1619e-01, time/batch = 16.8631s	
26224/30300 (epoch 43.274), train_loss = 1.07083574, grad/param norm = 1.9360e-01, time/batch = 18.7802s	
26225/30300 (epoch 43.276), train_loss = 1.03782592, grad/param norm = 2.0839e-01, time/batch = 17.1158s	
26226/30300 (epoch 43.277), train_loss = 0.92262609, grad/param norm = 1.8710e-01, time/batch = 15.8915s	
26227/30300 (epoch 43.279), train_loss = 1.00601304, grad/param norm = 1.7762e-01, time/batch = 17.6364s	
26228/30300 (epoch 43.281), train_loss = 1.10714995, grad/param norm = 2.2901e-01, time/batch = 18.5489s	
26229/30300 (epoch 43.282), train_loss = 1.05376281, grad/param norm = 1.7508e-01, time/batch = 18.0347s	
26230/30300 (epoch 43.284), train_loss = 1.08688950, grad/param norm = 2.2601e-01, time/batch = 18.6333s	
26231/30300 (epoch 43.285), train_loss = 1.07020675, grad/param norm = 1.6370e-01, time/batch = 19.1370s	
26232/30300 (epoch 43.287), train_loss = 1.03499600, grad/param norm = 2.0363e-01, time/batch = 16.6893s	
26233/30300 (epoch 43.289), train_loss = 1.09775013, grad/param norm = 1.9802e-01, time/batch = 18.4718s	
26234/30300 (epoch 43.290), train_loss = 0.82106945, grad/param norm = 1.8385e-01, time/batch = 18.0614s	
26235/30300 (epoch 43.292), train_loss = 0.92200934, grad/param norm = 2.0542e-01, time/batch = 18.0576s	
26236/30300 (epoch 43.294), train_loss = 1.07501643, grad/param norm = 2.1276e-01, time/batch = 18.1398s	
26237/30300 (epoch 43.295), train_loss = 0.96359583, grad/param norm = 1.6358e-01, time/batch = 18.2845s	
26238/30300 (epoch 43.297), train_loss = 0.98413509, grad/param norm = 1.6565e-01, time/batch = 18.7126s	
26239/30300 (epoch 43.299), train_loss = 0.99692516, grad/param norm = 1.8762e-01, time/batch = 18.3658s	
26240/30300 (epoch 43.300), train_loss = 0.94317129, grad/param norm = 1.8491e-01, time/batch = 18.2227s	
26241/30300 (epoch 43.302), train_loss = 1.08589103, grad/param norm = 1.7612e-01, time/batch = 18.8960s	
26242/30300 (epoch 43.304), train_loss = 0.96154755, grad/param norm = 1.8587e-01, time/batch = 17.8796s	
26243/30300 (epoch 43.305), train_loss = 1.01480840, grad/param norm = 1.9090e-01, time/batch = 18.9651s	
26244/30300 (epoch 43.307), train_loss = 1.11142021, grad/param norm = 1.7950e-01, time/batch = 17.1986s	
26245/30300 (epoch 43.309), train_loss = 1.05129014, grad/param norm = 1.7930e-01, time/batch = 17.2153s	
26246/30300 (epoch 43.310), train_loss = 0.97973062, grad/param norm = 1.6745e-01, time/batch = 19.1306s	
26247/30300 (epoch 43.312), train_loss = 1.11313403, grad/param norm = 1.6026e-01, time/batch = 18.5606s	
26248/30300 (epoch 43.314), train_loss = 1.00709236, grad/param norm = 2.0586e-01, time/batch = 18.2938s	
26249/30300 (epoch 43.315), train_loss = 0.96698076, grad/param norm = 1.7561e-01, time/batch = 18.2871s	
26250/30300 (epoch 43.317), train_loss = 1.03265099, grad/param norm = 1.6884e-01, time/batch = 19.0498s	
26251/30300 (epoch 43.318), train_loss = 1.06666608, grad/param norm = 2.1824e-01, time/batch = 19.1195s	
26252/30300 (epoch 43.320), train_loss = 1.05275765, grad/param norm = 1.8406e-01, time/batch = 17.4909s	
26253/30300 (epoch 43.322), train_loss = 0.94383339, grad/param norm = 1.6374e-01, time/batch = 19.5253s	
26254/30300 (epoch 43.323), train_loss = 1.10091171, grad/param norm = 1.9431e-01, time/batch = 19.4659s	
26255/30300 (epoch 43.325), train_loss = 1.00062668, grad/param norm = 1.8488e-01, time/batch = 18.2939s	
26256/30300 (epoch 43.327), train_loss = 1.00077323, grad/param norm = 1.5927e-01, time/batch = 19.6330s	
26257/30300 (epoch 43.328), train_loss = 1.03893008, grad/param norm = 1.6246e-01, time/batch = 19.4650s	
26258/30300 (epoch 43.330), train_loss = 1.05163567, grad/param norm = 1.7068e-01, time/batch = 17.9629s	
26259/30300 (epoch 43.332), train_loss = 1.09810038, grad/param norm = 1.9135e-01, time/batch = 19.6189s	
26260/30300 (epoch 43.333), train_loss = 0.93363360, grad/param norm = 1.8980e-01, time/batch = 18.9688s	
26261/30300 (epoch 43.335), train_loss = 0.91187633, grad/param norm = 1.6894e-01, time/batch = 18.3820s	
26262/30300 (epoch 43.337), train_loss = 1.10953024, grad/param norm = 1.7328e-01, time/batch = 18.3803s	
26263/30300 (epoch 43.338), train_loss = 0.96424673, grad/param norm = 1.6770e-01, time/batch = 19.1976s	
26264/30300 (epoch 43.340), train_loss = 0.97221841, grad/param norm = 1.6838e-01, time/batch = 18.4576s	
26265/30300 (epoch 43.342), train_loss = 1.08473536, grad/param norm = 1.7511e-01, time/batch = 18.5380s	
26266/30300 (epoch 43.343), train_loss = 1.05619400, grad/param norm = 2.4887e-01, time/batch = 18.2877s	
26267/30300 (epoch 43.345), train_loss = 1.05108300, grad/param norm = 1.7661e-01, time/batch = 18.2010s	
26268/30300 (epoch 43.347), train_loss = 0.91542784, grad/param norm = 1.6045e-01, time/batch = 18.7895s	
26269/30300 (epoch 43.348), train_loss = 0.97743670, grad/param norm = 1.7097e-01, time/batch = 18.2848s	
26270/30300 (epoch 43.350), train_loss = 0.98298727, grad/param norm = 1.7122e-01, time/batch = 18.9528s	
26271/30300 (epoch 43.351), train_loss = 0.99721286, grad/param norm = 1.8375e-01, time/batch = 18.1961s	
26272/30300 (epoch 43.353), train_loss = 0.90912291, grad/param norm = 1.6839e-01, time/batch = 19.3092s	
26273/30300 (epoch 43.355), train_loss = 0.96828431, grad/param norm = 1.8848e-01, time/batch = 18.8040s	
26274/30300 (epoch 43.356), train_loss = 1.07907341, grad/param norm = 2.1482e-01, time/batch = 18.2933s	
26275/30300 (epoch 43.358), train_loss = 1.24582158, grad/param norm = 1.8593e-01, time/batch = 19.8871s	
26276/30300 (epoch 43.360), train_loss = 0.95979512, grad/param norm = 2.1586e-01, time/batch = 18.6394s	
26277/30300 (epoch 43.361), train_loss = 0.99442420, grad/param norm = 1.7572e-01, time/batch = 16.7776s	
26278/30300 (epoch 43.363), train_loss = 1.02892134, grad/param norm = 1.7496e-01, time/batch = 19.2998s	
26279/30300 (epoch 43.365), train_loss = 0.87332561, grad/param norm = 2.3038e-01, time/batch = 19.7135s	
26280/30300 (epoch 43.366), train_loss = 0.98810544, grad/param norm = 1.7272e-01, time/batch = 18.7843s	
26281/30300 (epoch 43.368), train_loss = 0.88784790, grad/param norm = 1.8311e-01, time/batch = 19.3702s	
26282/30300 (epoch 43.370), train_loss = 0.94066225, grad/param norm = 1.9949e-01, time/batch = 19.1882s	
26283/30300 (epoch 43.371), train_loss = 1.06761224, grad/param norm = 1.8572e-01, time/batch = 18.6325s	
26284/30300 (epoch 43.373), train_loss = 0.94442638, grad/param norm = 1.5827e-01, time/batch = 19.0479s	
26285/30300 (epoch 43.375), train_loss = 0.93951636, grad/param norm = 1.5972e-01, time/batch = 18.2795s	
26286/30300 (epoch 43.376), train_loss = 0.93924703, grad/param norm = 1.5072e-01, time/batch = 17.3212s	
26287/30300 (epoch 43.378), train_loss = 0.91866197, grad/param norm = 1.8583e-01, time/batch = 18.7758s	
26288/30300 (epoch 43.380), train_loss = 1.12138573, grad/param norm = 1.9914e-01, time/batch = 19.2950s	
26289/30300 (epoch 43.381), train_loss = 0.84346704, grad/param norm = 1.6709e-01, time/batch = 19.7191s	
26290/30300 (epoch 43.383), train_loss = 0.90540324, grad/param norm = 1.9199e-01, time/batch = 18.5486s	
26291/30300 (epoch 43.384), train_loss = 1.05099425, grad/param norm = 1.9246e-01, time/batch = 19.2827s	
26292/30300 (epoch 43.386), train_loss = 0.89805882, grad/param norm = 1.7329e-01, time/batch = 19.5394s	
26293/30300 (epoch 43.388), train_loss = 0.90287800, grad/param norm = 1.8766e-01, time/batch = 17.2046s	
26294/30300 (epoch 43.389), train_loss = 0.99472862, grad/param norm = 1.9247e-01, time/batch = 19.0426s	
26295/30300 (epoch 43.391), train_loss = 1.04969478, grad/param norm = 1.9211e-01, time/batch = 19.1344s	
26296/30300 (epoch 43.393), train_loss = 0.88395782, grad/param norm = 1.5081e-01, time/batch = 18.4443s	
26297/30300 (epoch 43.394), train_loss = 1.01772294, grad/param norm = 1.5845e-01, time/batch = 18.2945s	
26298/30300 (epoch 43.396), train_loss = 1.13408923, grad/param norm = 1.6489e-01, time/batch = 19.3442s	
26299/30300 (epoch 43.398), train_loss = 0.97609537, grad/param norm = 1.7553e-01, time/batch = 18.1320s	
26300/30300 (epoch 43.399), train_loss = 0.90785970, grad/param norm = 1.7889e-01, time/batch = 19.6259s	
26301/30300 (epoch 43.401), train_loss = 1.00573530, grad/param norm = 2.1744e-01, time/batch = 19.1284s	
26302/30300 (epoch 43.403), train_loss = 1.00552802, grad/param norm = 2.0681e-01, time/batch = 19.5405s	
26303/30300 (epoch 43.404), train_loss = 0.95075764, grad/param norm = 1.8921e-01, time/batch = 19.4591s	
26304/30300 (epoch 43.406), train_loss = 0.99922346, grad/param norm = 1.6378e-01, time/batch = 18.7651s	
26305/30300 (epoch 43.408), train_loss = 0.87410026, grad/param norm = 1.6314e-01, time/batch = 18.8048s	
26306/30300 (epoch 43.409), train_loss = 0.90033387, grad/param norm = 2.0225e-01, time/batch = 18.3823s	
26307/30300 (epoch 43.411), train_loss = 0.93258957, grad/param norm = 1.4575e-01, time/batch = 19.4717s	
26308/30300 (epoch 43.413), train_loss = 0.83197684, grad/param norm = 1.5708e-01, time/batch = 18.4682s	
26309/30300 (epoch 43.414), train_loss = 1.04835084, grad/param norm = 2.0095e-01, time/batch = 19.2087s	
26310/30300 (epoch 43.416), train_loss = 0.94320141, grad/param norm = 1.7713e-01, time/batch = 19.1398s	
26311/30300 (epoch 43.417), train_loss = 0.91161258, grad/param norm = 1.9078e-01, time/batch = 19.4678s	
26312/30300 (epoch 43.419), train_loss = 0.90764597, grad/param norm = 1.7032e-01, time/batch = 19.0295s	
26313/30300 (epoch 43.421), train_loss = 0.95365520, grad/param norm = 2.1262e-01, time/batch = 19.7917s	
26314/30300 (epoch 43.422), train_loss = 1.00270569, grad/param norm = 1.8170e-01, time/batch = 19.0400s	
26315/30300 (epoch 43.424), train_loss = 0.99414747, grad/param norm = 1.7269e-01, time/batch = 18.0419s	
26316/30300 (epoch 43.426), train_loss = 0.99212013, grad/param norm = 2.8936e-01, time/batch = 18.7178s	
26317/30300 (epoch 43.427), train_loss = 0.95719275, grad/param norm = 1.7798e-01, time/batch = 20.3776s	
26318/30300 (epoch 43.429), train_loss = 0.98239144, grad/param norm = 1.7183e-01, time/batch = 17.9685s	
26319/30300 (epoch 43.431), train_loss = 1.01308676, grad/param norm = 2.0796e-01, time/batch = 18.6919s	
26320/30300 (epoch 43.432), train_loss = 1.00235605, grad/param norm = 1.6552e-01, time/batch = 19.9633s	
26321/30300 (epoch 43.434), train_loss = 0.88942265, grad/param norm = 1.7559e-01, time/batch = 18.8724s	
26322/30300 (epoch 43.436), train_loss = 1.08275313, grad/param norm = 1.7772e-01, time/batch = 17.9695s	
26323/30300 (epoch 43.437), train_loss = 0.90315326, grad/param norm = 1.6598e-01, time/batch = 18.9589s	
26324/30300 (epoch 43.439), train_loss = 0.94440010, grad/param norm = 1.9257e-01, time/batch = 18.0324s	
26325/30300 (epoch 43.441), train_loss = 0.98209505, grad/param norm = 1.6828e-01, time/batch = 18.7038s	
26326/30300 (epoch 43.442), train_loss = 0.93536419, grad/param norm = 1.8004e-01, time/batch = 19.6398s	
26327/30300 (epoch 43.444), train_loss = 0.82774606, grad/param norm = 1.6023e-01, time/batch = 20.0270s	
26328/30300 (epoch 43.446), train_loss = 0.95303088, grad/param norm = 1.6303e-01, time/batch = 25.0381s	
26329/30300 (epoch 43.447), train_loss = 0.97402562, grad/param norm = 1.6379e-01, time/batch = 41.1245s	
26330/30300 (epoch 43.449), train_loss = 0.92462134, grad/param norm = 1.5277e-01, time/batch = 35.6749s	
26331/30300 (epoch 43.450), train_loss = 1.01970869, grad/param norm = 1.5989e-01, time/batch = 42.8542s	
26332/30300 (epoch 43.452), train_loss = 1.09979262, grad/param norm = 1.7665e-01, time/batch = 36.1334s	
26333/30300 (epoch 43.454), train_loss = 1.02794822, grad/param norm = 1.5767e-01, time/batch = 41.6770s	
26334/30300 (epoch 43.455), train_loss = 0.99307153, grad/param norm = 1.8054e-01, time/batch = 38.5576s	
26335/30300 (epoch 43.457), train_loss = 0.96399270, grad/param norm = 1.5944e-01, time/batch = 41.6215s	
26336/30300 (epoch 43.459), train_loss = 1.02807617, grad/param norm = 1.8402e-01, time/batch = 42.3022s	
26337/30300 (epoch 43.460), train_loss = 1.07469303, grad/param norm = 1.7265e-01, time/batch = 40.6669s	
26338/30300 (epoch 43.462), train_loss = 1.07063739, grad/param norm = 1.8079e-01, time/batch = 30.1839s	
26339/30300 (epoch 43.464), train_loss = 0.82336368, grad/param norm = 2.2749e-01, time/batch = 18.8656s	
26340/30300 (epoch 43.465), train_loss = 0.83817148, grad/param norm = 1.5512e-01, time/batch = 19.9686s	
26341/30300 (epoch 43.467), train_loss = 0.84276431, grad/param norm = 1.6100e-01, time/batch = 18.2906s	
26342/30300 (epoch 43.469), train_loss = 0.92722010, grad/param norm = 1.8781e-01, time/batch = 18.3526s	
26343/30300 (epoch 43.470), train_loss = 0.94459390, grad/param norm = 1.9768e-01, time/batch = 19.5427s	
26344/30300 (epoch 43.472), train_loss = 0.93186152, grad/param norm = 1.5106e-01, time/batch = 17.0997s	
26345/30300 (epoch 43.474), train_loss = 0.94408643, grad/param norm = 2.2494e-01, time/batch = 18.5179s	
26346/30300 (epoch 43.475), train_loss = 0.91883221, grad/param norm = 1.5867e-01, time/batch = 19.2091s	
26347/30300 (epoch 43.477), train_loss = 0.96619418, grad/param norm = 1.7749e-01, time/batch = 20.0418s	
26348/30300 (epoch 43.479), train_loss = 0.93913878, grad/param norm = 1.5617e-01, time/batch = 23.3960s	
26349/30300 (epoch 43.480), train_loss = 1.00570215, grad/param norm = 1.6811e-01, time/batch = 30.0827s	
26350/30300 (epoch 43.482), train_loss = 1.03679208, grad/param norm = 1.6683e-01, time/batch = 19.1154s	
26351/30300 (epoch 43.483), train_loss = 0.97607948, grad/param norm = 1.7002e-01, time/batch = 19.5465s	
26352/30300 (epoch 43.485), train_loss = 0.99439202, grad/param norm = 1.6336e-01, time/batch = 18.3709s	
26353/30300 (epoch 43.487), train_loss = 1.05049236, grad/param norm = 1.6890e-01, time/batch = 18.8907s	
26354/30300 (epoch 43.488), train_loss = 1.11368564, grad/param norm = 1.5469e-01, time/batch = 18.2897s	
26355/30300 (epoch 43.490), train_loss = 0.85911536, grad/param norm = 1.7126e-01, time/batch = 19.0343s	
26356/30300 (epoch 43.492), train_loss = 0.94355511, grad/param norm = 1.8970e-01, time/batch = 20.0531s	
26357/30300 (epoch 43.493), train_loss = 0.99733647, grad/param norm = 1.8405e-01, time/batch = 18.6217s	
26358/30300 (epoch 43.495), train_loss = 0.96031996, grad/param norm = 1.4693e-01, time/batch = 19.2905s	
26359/30300 (epoch 43.497), train_loss = 1.02042114, grad/param norm = 1.8137e-01, time/batch = 18.2130s	
26360/30300 (epoch 43.498), train_loss = 1.05150376, grad/param norm = 2.0669e-01, time/batch = 18.5372s	
26361/30300 (epoch 43.500), train_loss = 0.93433202, grad/param norm = 1.8575e-01, time/batch = 20.3819s	
26362/30300 (epoch 43.502), train_loss = 0.99113289, grad/param norm = 1.8561e-01, time/batch = 18.8975s	
26363/30300 (epoch 43.503), train_loss = 1.08397651, grad/param norm = 1.7038e-01, time/batch = 18.3762s	
26364/30300 (epoch 43.505), train_loss = 0.88411155, grad/param norm = 1.8969e-01, time/batch = 18.4654s	
26365/30300 (epoch 43.507), train_loss = 0.87489560, grad/param norm = 1.6555e-01, time/batch = 18.5538s	
26366/30300 (epoch 43.508), train_loss = 0.93785632, grad/param norm = 2.4585e-01, time/batch = 18.0450s	
26367/30300 (epoch 43.510), train_loss = 1.06186352, grad/param norm = 1.9775e-01, time/batch = 19.7080s	
26368/30300 (epoch 43.512), train_loss = 0.92991661, grad/param norm = 1.6503e-01, time/batch = 19.1227s	
26369/30300 (epoch 43.513), train_loss = 0.99359438, grad/param norm = 1.7470e-01, time/batch = 17.2776s	
26370/30300 (epoch 43.515), train_loss = 0.97537440, grad/param norm = 1.7415e-01, time/batch = 19.3764s	
26371/30300 (epoch 43.517), train_loss = 0.80394894, grad/param norm = 1.5224e-01, time/batch = 19.8011s	
26372/30300 (epoch 43.518), train_loss = 1.06748816, grad/param norm = 1.8100e-01, time/batch = 19.3618s	
26373/30300 (epoch 43.520), train_loss = 0.95441453, grad/param norm = 1.7489e-01, time/batch = 18.7227s	
26374/30300 (epoch 43.521), train_loss = 0.88654219, grad/param norm = 1.8842e-01, time/batch = 20.0580s	
26375/30300 (epoch 43.523), train_loss = 1.08833825, grad/param norm = 2.0602e-01, time/batch = 18.1194s	
26376/30300 (epoch 43.525), train_loss = 0.90085475, grad/param norm = 1.6722e-01, time/batch = 18.4493s	
26377/30300 (epoch 43.526), train_loss = 1.00675979, grad/param norm = 1.7820e-01, time/batch = 17.9456s	
26378/30300 (epoch 43.528), train_loss = 0.86397205, grad/param norm = 1.7370e-01, time/batch = 19.9677s	
26379/30300 (epoch 43.530), train_loss = 0.84630493, grad/param norm = 1.6443e-01, time/batch = 17.6201s	
26380/30300 (epoch 43.531), train_loss = 0.95153427, grad/param norm = 1.7446e-01, time/batch = 18.8007s	
26381/30300 (epoch 43.533), train_loss = 0.95527782, grad/param norm = 1.8894e-01, time/batch = 19.9688s	
26382/30300 (epoch 43.535), train_loss = 0.96976936, grad/param norm = 1.4759e-01, time/batch = 18.5508s	
26383/30300 (epoch 43.536), train_loss = 0.98769936, grad/param norm = 2.1701e-01, time/batch = 18.9613s	
26384/30300 (epoch 43.538), train_loss = 0.87346539, grad/param norm = 1.9770e-01, time/batch = 18.9633s	
26385/30300 (epoch 43.540), train_loss = 0.93010475, grad/param norm = 2.0017e-01, time/batch = 19.2916s	
26386/30300 (epoch 43.541), train_loss = 0.97951459, grad/param norm = 1.9514e-01, time/batch = 19.1324s	
26387/30300 (epoch 43.543), train_loss = 0.96826406, grad/param norm = 1.8100e-01, time/batch = 18.5404s	
26388/30300 (epoch 43.545), train_loss = 1.04433720, grad/param norm = 2.4746e-01, time/batch = 18.9675s	
26389/30300 (epoch 43.546), train_loss = 1.14763597, grad/param norm = 1.7441e-01, time/batch = 18.6138s	
26390/30300 (epoch 43.548), train_loss = 0.93165995, grad/param norm = 1.5779e-01, time/batch = 19.4555s	
26391/30300 (epoch 43.550), train_loss = 1.01865408, grad/param norm = 2.0730e-01, time/batch = 18.7725s	
26392/30300 (epoch 43.551), train_loss = 0.91033530, grad/param norm = 1.7864e-01, time/batch = 19.7902s	
26393/30300 (epoch 43.553), train_loss = 0.94921164, grad/param norm = 1.7908e-01, time/batch = 18.8886s	
26394/30300 (epoch 43.554), train_loss = 0.97991579, grad/param norm = 1.7293e-01, time/batch = 18.9670s	
26395/30300 (epoch 43.556), train_loss = 1.01260281, grad/param norm = 1.6498e-01, time/batch = 19.2059s	
26396/30300 (epoch 43.558), train_loss = 1.07424959, grad/param norm = 2.0324e-01, time/batch = 19.0449s	
26397/30300 (epoch 43.559), train_loss = 0.99523114, grad/param norm = 1.7080e-01, time/batch = 19.7243s	
26398/30300 (epoch 43.561), train_loss = 0.79866924, grad/param norm = 1.8791e-01, time/batch = 18.9529s	
26399/30300 (epoch 43.563), train_loss = 0.87031399, grad/param norm = 1.7828e-01, time/batch = 17.2972s	
26400/30300 (epoch 43.564), train_loss = 0.92403584, grad/param norm = 1.4618e-01, time/batch = 18.5228s	
26401/30300 (epoch 43.566), train_loss = 0.94871147, grad/param norm = 1.7840e-01, time/batch = 18.4555s	
26402/30300 (epoch 43.568), train_loss = 0.83650978, grad/param norm = 1.7632e-01, time/batch = 19.8141s	
26403/30300 (epoch 43.569), train_loss = 1.00550112, grad/param norm = 1.6542e-01, time/batch = 18.8576s	
26404/30300 (epoch 43.571), train_loss = 0.98726650, grad/param norm = 1.8743e-01, time/batch = 18.4542s	
26405/30300 (epoch 43.573), train_loss = 1.01070931, grad/param norm = 1.6531e-01, time/batch = 20.2894s	
26406/30300 (epoch 43.574), train_loss = 1.00294434, grad/param norm = 1.6474e-01, time/batch = 18.8802s	
26407/30300 (epoch 43.576), train_loss = 0.95212490, grad/param norm = 1.4500e-01, time/batch = 17.8638s	
26408/30300 (epoch 43.578), train_loss = 0.84766250, grad/param norm = 1.7473e-01, time/batch = 19.3743s	
26409/30300 (epoch 43.579), train_loss = 1.03106900, grad/param norm = 1.9514e-01, time/batch = 19.8740s	
26410/30300 (epoch 43.581), train_loss = 1.10138652, grad/param norm = 1.8714e-01, time/batch = 18.0413s	
26411/30300 (epoch 43.583), train_loss = 1.09609121, grad/param norm = 2.1645e-01, time/batch = 17.7666s	
26412/30300 (epoch 43.584), train_loss = 1.07758334, grad/param norm = 1.7115e-01, time/batch = 19.1254s	
26413/30300 (epoch 43.586), train_loss = 0.94900238, grad/param norm = 1.6636e-01, time/batch = 18.1115s	
26414/30300 (epoch 43.587), train_loss = 0.98122750, grad/param norm = 1.7601e-01, time/batch = 15.3033s	
26415/30300 (epoch 43.589), train_loss = 0.91614873, grad/param norm = 1.8314e-01, time/batch = 18.8766s	
26416/30300 (epoch 43.591), train_loss = 1.00700881, grad/param norm = 1.5215e-01, time/batch = 20.2115s	
26417/30300 (epoch 43.592), train_loss = 0.93439552, grad/param norm = 1.4903e-01, time/batch = 18.4662s	
26418/30300 (epoch 43.594), train_loss = 1.02807980, grad/param norm = 1.8339e-01, time/batch = 18.8055s	
26419/30300 (epoch 43.596), train_loss = 0.89945965, grad/param norm = 1.5239e-01, time/batch = 20.2001s	
26420/30300 (epoch 43.597), train_loss = 0.92915828, grad/param norm = 1.8481e-01, time/batch = 18.5499s	
26421/30300 (epoch 43.599), train_loss = 0.82485656, grad/param norm = 1.5533e-01, time/batch = 17.7819s	
26422/30300 (epoch 43.601), train_loss = 0.99284696, grad/param norm = 1.7047e-01, time/batch = 18.9623s	
26423/30300 (epoch 43.602), train_loss = 0.96910201, grad/param norm = 1.5015e-01, time/batch = 18.1155s	
26424/30300 (epoch 43.604), train_loss = 0.90197062, grad/param norm = 1.5260e-01, time/batch = 18.7056s	
26425/30300 (epoch 43.606), train_loss = 0.92051237, grad/param norm = 2.0613e-01, time/batch = 18.7212s	
26426/30300 (epoch 43.607), train_loss = 1.05135939, grad/param norm = 2.1841e-01, time/batch = 20.9200s	
26427/30300 (epoch 43.609), train_loss = 1.14822926, grad/param norm = 1.7608e-01, time/batch = 23.9916s	
26428/30300 (epoch 43.611), train_loss = 0.96868953, grad/param norm = 1.7641e-01, time/batch = 23.4455s	
26429/30300 (epoch 43.612), train_loss = 0.88319298, grad/param norm = 1.4536e-01, time/batch = 21.1427s	
26430/30300 (epoch 43.614), train_loss = 0.96006658, grad/param norm = 1.6340e-01, time/batch = 23.8698s	
26431/30300 (epoch 43.616), train_loss = 0.99844548, grad/param norm = 2.1779e-01, time/batch = 23.4484s	
26432/30300 (epoch 43.617), train_loss = 0.98430989, grad/param norm = 2.0478e-01, time/batch = 23.2888s	
26433/30300 (epoch 43.619), train_loss = 0.80049196, grad/param norm = 1.4327e-01, time/batch = 21.3731s	
26434/30300 (epoch 43.620), train_loss = 1.03754440, grad/param norm = 1.8707e-01, time/batch = 24.0380s	
26435/30300 (epoch 43.622), train_loss = 0.96263491, grad/param norm = 1.9975e-01, time/batch = 23.3030s	
26436/30300 (epoch 43.624), train_loss = 0.95546189, grad/param norm = 1.5439e-01, time/batch = 21.5445s	
26437/30300 (epoch 43.625), train_loss = 0.95507543, grad/param norm = 2.7459e-01, time/batch = 22.2937s	
26438/30300 (epoch 43.627), train_loss = 1.06255602, grad/param norm = 1.8266e-01, time/batch = 23.3844s	
26439/30300 (epoch 43.629), train_loss = 1.09449373, grad/param norm = 1.6899e-01, time/batch = 22.5422s	
26440/30300 (epoch 43.630), train_loss = 0.97025722, grad/param norm = 1.7281e-01, time/batch = 24.2111s	
26441/30300 (epoch 43.632), train_loss = 1.00568310, grad/param norm = 1.9216e-01, time/batch = 29.1030s	
26442/30300 (epoch 43.634), train_loss = 0.90172363, grad/param norm = 1.6320e-01, time/batch = 19.6803s	
26443/30300 (epoch 43.635), train_loss = 1.02147456, grad/param norm = 1.9036e-01, time/batch = 20.0414s	
26444/30300 (epoch 43.637), train_loss = 1.03684788, grad/param norm = 1.7983e-01, time/batch = 20.4642s	
26445/30300 (epoch 43.639), train_loss = 0.96347633, grad/param norm = 1.8174e-01, time/batch = 18.9496s	
26446/30300 (epoch 43.640), train_loss = 1.08539980, grad/param norm = 2.2627e-01, time/batch = 18.6871s	
26447/30300 (epoch 43.642), train_loss = 0.98033191, grad/param norm = 1.7014e-01, time/batch = 20.5497s	
26448/30300 (epoch 43.644), train_loss = 1.06292951, grad/param norm = 1.9727e-01, time/batch = 18.4543s	
26449/30300 (epoch 43.645), train_loss = 0.92386206, grad/param norm = 1.5724e-01, time/batch = 19.3059s	
26450/30300 (epoch 43.647), train_loss = 0.96783613, grad/param norm = 1.8735e-01, time/batch = 18.7126s	
26451/30300 (epoch 43.649), train_loss = 0.96263670, grad/param norm = 2.2941e-01, time/batch = 18.5256s	
26452/30300 (epoch 43.650), train_loss = 1.00015915, grad/param norm = 1.8148e-01, time/batch = 19.7951s	
26453/30300 (epoch 43.652), train_loss = 0.97353511, grad/param norm = 2.4258e-01, time/batch = 17.5440s	
26454/30300 (epoch 43.653), train_loss = 1.14569493, grad/param norm = 1.6414e-01, time/batch = 18.8589s	
26455/30300 (epoch 43.655), train_loss = 0.95914070, grad/param norm = 1.7854e-01, time/batch = 18.7185s	
26456/30300 (epoch 43.657), train_loss = 0.88446529, grad/param norm = 1.7823e-01, time/batch = 18.5176s	
26457/30300 (epoch 43.658), train_loss = 0.95230069, grad/param norm = 1.6627e-01, time/batch = 19.4520s	
26458/30300 (epoch 43.660), train_loss = 0.96536480, grad/param norm = 1.7458e-01, time/batch = 19.0483s	
26459/30300 (epoch 43.662), train_loss = 1.00339234, grad/param norm = 2.3880e-01, time/batch = 19.2220s	
26460/30300 (epoch 43.663), train_loss = 1.04882415, grad/param norm = 1.7154e-01, time/batch = 19.0440s	
26461/30300 (epoch 43.665), train_loss = 0.91970409, grad/param norm = 2.2842e-01, time/batch = 19.7146s	
26462/30300 (epoch 43.667), train_loss = 1.04019818, grad/param norm = 1.9925e-01, time/batch = 19.1248s	
26463/30300 (epoch 43.668), train_loss = 1.06225845, grad/param norm = 1.8536e-01, time/batch = 19.2898s	
26464/30300 (epoch 43.670), train_loss = 1.08388278, grad/param norm = 1.8470e-01, time/batch = 18.8754s	
26465/30300 (epoch 43.672), train_loss = 0.99032442, grad/param norm = 1.9727e-01, time/batch = 18.5197s	
26466/30300 (epoch 43.673), train_loss = 1.04541118, grad/param norm = 2.2523e-01, time/batch = 19.2077s	
26467/30300 (epoch 43.675), train_loss = 0.96011528, grad/param norm = 1.8867e-01, time/batch = 17.6829s	
26468/30300 (epoch 43.677), train_loss = 0.94816028, grad/param norm = 1.8325e-01, time/batch = 20.0394s	
26469/30300 (epoch 43.678), train_loss = 0.93687581, grad/param norm = 1.8092e-01, time/batch = 20.2836s	
26470/30300 (epoch 43.680), train_loss = 0.87831723, grad/param norm = 1.6138e-01, time/batch = 16.6894s	
26471/30300 (epoch 43.682), train_loss = 0.98079663, grad/param norm = 2.0701e-01, time/batch = 20.1247s	
26472/30300 (epoch 43.683), train_loss = 1.05983710, grad/param norm = 1.5958e-01, time/batch = 18.6034s	
26473/30300 (epoch 43.685), train_loss = 1.03042813, grad/param norm = 1.9709e-01, time/batch = 18.8646s	
26474/30300 (epoch 43.686), train_loss = 0.97298837, grad/param norm = 1.6670e-01, time/batch = 18.8863s	
26475/30300 (epoch 43.688), train_loss = 0.97208913, grad/param norm = 1.5196e-01, time/batch = 19.7097s	
26476/30300 (epoch 43.690), train_loss = 0.93527656, grad/param norm = 1.7491e-01, time/batch = 17.4569s	
26477/30300 (epoch 43.691), train_loss = 0.97442276, grad/param norm = 1.7759e-01, time/batch = 19.9595s	
26478/30300 (epoch 43.693), train_loss = 1.26480297, grad/param norm = 2.2304e-01, time/batch = 19.8016s	
26479/30300 (epoch 43.695), train_loss = 1.06476574, grad/param norm = 2.2010e-01, time/batch = 18.7930s	
26480/30300 (epoch 43.696), train_loss = 1.04165478, grad/param norm = 2.3568e-01, time/batch = 19.4753s	
26481/30300 (epoch 43.698), train_loss = 0.96911313, grad/param norm = 1.8574e-01, time/batch = 19.3165s	
26482/30300 (epoch 43.700), train_loss = 0.91963999, grad/param norm = 1.8503e-01, time/batch = 18.9481s	
26483/30300 (epoch 43.701), train_loss = 0.87163653, grad/param norm = 1.7444e-01, time/batch = 18.1239s	
26484/30300 (epoch 43.703), train_loss = 0.97806646, grad/param norm = 1.5671e-01, time/batch = 19.7201s	
26485/30300 (epoch 43.705), train_loss = 0.89984275, grad/param norm = 1.7883e-01, time/batch = 19.4658s	
26486/30300 (epoch 43.706), train_loss = 1.04123284, grad/param norm = 2.0812e-01, time/batch = 18.1136s	
26487/30300 (epoch 43.708), train_loss = 0.98570964, grad/param norm = 1.7083e-01, time/batch = 19.7116s	
26488/30300 (epoch 43.710), train_loss = 0.96199581, grad/param norm = 1.7451e-01, time/batch = 19.1213s	
26489/30300 (epoch 43.711), train_loss = 0.92218755, grad/param norm = 1.6889e-01, time/batch = 19.4552s	
26490/30300 (epoch 43.713), train_loss = 0.93111243, grad/param norm = 2.2148e-01, time/batch = 18.1086s	
26491/30300 (epoch 43.715), train_loss = 0.95556639, grad/param norm = 1.6868e-01, time/batch = 20.2071s	
26492/30300 (epoch 43.716), train_loss = 1.04363051, grad/param norm = 1.7569e-01, time/batch = 18.7878s	
26493/30300 (epoch 43.718), train_loss = 1.09012049, grad/param norm = 1.7813e-01, time/batch = 19.5624s	
26494/30300 (epoch 43.719), train_loss = 0.93693663, grad/param norm = 1.8888e-01, time/batch = 18.2832s	
26495/30300 (epoch 43.721), train_loss = 0.95563159, grad/param norm = 1.7218e-01, time/batch = 18.4529s	
26496/30300 (epoch 43.723), train_loss = 0.91323602, grad/param norm = 1.6716e-01, time/batch = 19.4412s	
26497/30300 (epoch 43.724), train_loss = 1.00755873, grad/param norm = 2.0201e-01, time/batch = 19.3718s	
26498/30300 (epoch 43.726), train_loss = 1.23635122, grad/param norm = 2.1693e-01, time/batch = 18.7866s	
26499/30300 (epoch 43.728), train_loss = 1.00434257, grad/param norm = 1.6578e-01, time/batch = 19.1372s	
26500/30300 (epoch 43.729), train_loss = 0.94982353, grad/param norm = 2.0505e-01, time/batch = 19.3920s	
26501/30300 (epoch 43.731), train_loss = 0.95097566, grad/param norm = 2.0614e-01, time/batch = 19.1248s	
26502/30300 (epoch 43.733), train_loss = 0.98189754, grad/param norm = 2.0942e-01, time/batch = 19.7843s	
26503/30300 (epoch 43.734), train_loss = 1.06114370, grad/param norm = 1.7423e-01, time/batch = 19.5339s	
26504/30300 (epoch 43.736), train_loss = 1.01797875, grad/param norm = 1.8520e-01, time/batch = 19.2747s	
26505/30300 (epoch 43.738), train_loss = 0.93061125, grad/param norm = 1.4941e-01, time/batch = 19.8706s	
26506/30300 (epoch 43.739), train_loss = 1.10378432, grad/param norm = 1.7789e-01, time/batch = 19.8868s	
26507/30300 (epoch 43.741), train_loss = 1.11102039, grad/param norm = 1.7309e-01, time/batch = 18.2176s	
26508/30300 (epoch 43.743), train_loss = 0.95060290, grad/param norm = 1.8120e-01, time/batch = 19.0485s	
26509/30300 (epoch 43.744), train_loss = 1.02774151, grad/param norm = 1.9530e-01, time/batch = 17.7043s	
26510/30300 (epoch 43.746), train_loss = 0.94941136, grad/param norm = 1.5192e-01, time/batch = 18.9638s	
26511/30300 (epoch 43.748), train_loss = 0.97002102, grad/param norm = 2.0496e-01, time/batch = 18.7291s	
26512/30300 (epoch 43.749), train_loss = 0.99090654, grad/param norm = 1.8184e-01, time/batch = 19.4751s	
26513/30300 (epoch 43.751), train_loss = 1.02635853, grad/param norm = 1.6098e-01, time/batch = 18.6911s	
26514/30300 (epoch 43.752), train_loss = 0.96127644, grad/param norm = 1.8623e-01, time/batch = 19.2058s	
26515/30300 (epoch 43.754), train_loss = 0.98020966, grad/param norm = 1.6656e-01, time/batch = 19.4664s	
26516/30300 (epoch 43.756), train_loss = 0.97001061, grad/param norm = 1.7492e-01, time/batch = 20.1292s	
26517/30300 (epoch 43.757), train_loss = 0.90346382, grad/param norm = 1.6893e-01, time/batch = 19.0229s	
26518/30300 (epoch 43.759), train_loss = 1.00189651, grad/param norm = 1.6778e-01, time/batch = 19.7054s	
26519/30300 (epoch 43.761), train_loss = 0.85103508, grad/param norm = 1.7175e-01, time/batch = 18.9703s	
26520/30300 (epoch 43.762), train_loss = 0.88001654, grad/param norm = 1.6784e-01, time/batch = 19.4561s	
26521/30300 (epoch 43.764), train_loss = 0.95466312, grad/param norm = 1.6866e-01, time/batch = 19.3889s	
26522/30300 (epoch 43.766), train_loss = 1.09841046, grad/param norm = 2.0235e-01, time/batch = 18.3663s	
26523/30300 (epoch 43.767), train_loss = 0.99449796, grad/param norm = 2.2987e-01, time/batch = 18.0437s	
26524/30300 (epoch 43.769), train_loss = 0.99494012, grad/param norm = 1.9172e-01, time/batch = 18.6356s	
26525/30300 (epoch 43.771), train_loss = 0.91836135, grad/param norm = 2.2166e-01, time/batch = 18.4547s	
26526/30300 (epoch 43.772), train_loss = 0.97587046, grad/param norm = 1.7411e-01, time/batch = 18.8728s	
26527/30300 (epoch 43.774), train_loss = 1.13972229, grad/param norm = 1.7987e-01, time/batch = 20.1295s	
26528/30300 (epoch 43.776), train_loss = 0.95540420, grad/param norm = 1.8360e-01, time/batch = 19.3059s	
26529/30300 (epoch 43.777), train_loss = 1.11710402, grad/param norm = 1.6801e-01, time/batch = 18.1291s	
26530/30300 (epoch 43.779), train_loss = 1.09690646, grad/param norm = 1.9015e-01, time/batch = 19.5344s	
26531/30300 (epoch 43.781), train_loss = 0.98558791, grad/param norm = 1.8931e-01, time/batch = 19.1956s	
26532/30300 (epoch 43.782), train_loss = 0.91802357, grad/param norm = 1.8152e-01, time/batch = 21.0754s	
26533/30300 (epoch 43.784), train_loss = 0.94152701, grad/param norm = 1.7022e-01, time/batch = 32.7687s	
26534/30300 (epoch 43.785), train_loss = 1.04704924, grad/param norm = 2.0128e-01, time/batch = 20.6876s	
26535/30300 (epoch 43.787), train_loss = 0.83673419, grad/param norm = 1.6996e-01, time/batch = 19.2712s	
26536/30300 (epoch 43.789), train_loss = 1.12194959, grad/param norm = 2.2524e-01, time/batch = 20.4543s	
26537/30300 (epoch 43.790), train_loss = 0.97499821, grad/param norm = 1.9890e-01, time/batch = 19.6273s	
26538/30300 (epoch 43.792), train_loss = 0.78700770, grad/param norm = 1.6368e-01, time/batch = 18.8691s	
26539/30300 (epoch 43.794), train_loss = 0.98374554, grad/param norm = 1.7027e-01, time/batch = 19.9703s	
26540/30300 (epoch 43.795), train_loss = 0.90175668, grad/param norm = 1.5539e-01, time/batch = 19.3823s	
26541/30300 (epoch 43.797), train_loss = 1.13477038, grad/param norm = 2.3987e-01, time/batch = 18.6999s	
26542/30300 (epoch 43.799), train_loss = 1.06083235, grad/param norm = 2.2242e-01, time/batch = 19.2092s	
26543/30300 (epoch 43.800), train_loss = 1.03529787, grad/param norm = 1.8198e-01, time/batch = 19.5536s	
26544/30300 (epoch 43.802), train_loss = 1.22726381, grad/param norm = 2.0729e-01, time/batch = 17.3459s	
26545/30300 (epoch 43.804), train_loss = 1.03991009, grad/param norm = 1.9120e-01, time/batch = 19.8744s	
26546/30300 (epoch 43.805), train_loss = 1.11124152, grad/param norm = 1.8531e-01, time/batch = 19.3855s	
26547/30300 (epoch 43.807), train_loss = 0.94626572, grad/param norm = 1.8279e-01, time/batch = 17.9564s	
26548/30300 (epoch 43.809), train_loss = 1.06660440, grad/param norm = 1.8808e-01, time/batch = 19.7226s	
26549/30300 (epoch 43.810), train_loss = 1.03956387, grad/param norm = 1.9215e-01, time/batch = 19.4607s	
26550/30300 (epoch 43.812), train_loss = 0.95221783, grad/param norm = 1.7916e-01, time/batch = 18.2081s	
26551/30300 (epoch 43.814), train_loss = 0.99496130, grad/param norm = 1.8462e-01, time/batch = 19.8754s	
26552/30300 (epoch 43.815), train_loss = 1.01270040, grad/param norm = 2.3382e-01, time/batch = 18.7190s	
26553/30300 (epoch 43.817), train_loss = 1.06444827, grad/param norm = 1.9677e-01, time/batch = 17.7796s	
26554/30300 (epoch 43.818), train_loss = 1.02646379, grad/param norm = 1.7958e-01, time/batch = 19.4628s	
26555/30300 (epoch 43.820), train_loss = 1.15460893, grad/param norm = 2.0365e-01, time/batch = 19.9682s	
26556/30300 (epoch 43.822), train_loss = 1.14265647, grad/param norm = 2.5601e-01, time/batch = 18.1876s	
26557/30300 (epoch 43.823), train_loss = 1.12476589, grad/param norm = 2.2915e-01, time/batch = 20.2061s	
26558/30300 (epoch 43.825), train_loss = 1.11385469, grad/param norm = 1.7370e-01, time/batch = 19.6269s	
26559/30300 (epoch 43.827), train_loss = 0.85421572, grad/param norm = 2.0673e-01, time/batch = 19.3822s	
26560/30300 (epoch 43.828), train_loss = 1.09660549, grad/param norm = 1.8755e-01, time/batch = 19.1282s	
26561/30300 (epoch 43.830), train_loss = 1.04668832, grad/param norm = 1.7707e-01, time/batch = 19.4628s	
26562/30300 (epoch 43.832), train_loss = 0.92397196, grad/param norm = 1.9216e-01, time/batch = 18.8758s	
26563/30300 (epoch 43.833), train_loss = 1.01580988, grad/param norm = 1.7074e-01, time/batch = 19.6270s	
26564/30300 (epoch 43.835), train_loss = 0.93977906, grad/param norm = 1.9165e-01, time/batch = 18.8622s	
26565/30300 (epoch 43.837), train_loss = 0.90251671, grad/param norm = 1.6994e-01, time/batch = 17.6299s	
26566/30300 (epoch 43.838), train_loss = 0.90709406, grad/param norm = 1.7030e-01, time/batch = 18.3664s	
26567/30300 (epoch 43.840), train_loss = 1.07233979, grad/param norm = 1.7210e-01, time/batch = 19.5607s	
26568/30300 (epoch 43.842), train_loss = 0.97361208, grad/param norm = 1.6345e-01, time/batch = 19.4712s	
26569/30300 (epoch 43.843), train_loss = 1.03388458, grad/param norm = 2.0918e-01, time/batch = 18.8714s	
26570/30300 (epoch 43.845), train_loss = 1.03185848, grad/param norm = 1.7013e-01, time/batch = 19.8793s	
26571/30300 (epoch 43.847), train_loss = 0.99239407, grad/param norm = 1.6966e-01, time/batch = 19.7668s	
26572/30300 (epoch 43.848), train_loss = 1.04856091, grad/param norm = 1.9271e-01, time/batch = 18.6312s	
26573/30300 (epoch 43.850), train_loss = 0.98318121, grad/param norm = 1.6102e-01, time/batch = 19.8828s	
26574/30300 (epoch 43.851), train_loss = 1.03888282, grad/param norm = 2.1598e-01, time/batch = 19.7146s	
26575/30300 (epoch 43.853), train_loss = 0.96031977, grad/param norm = 1.6888e-01, time/batch = 18.7966s	
26576/30300 (epoch 43.855), train_loss = 0.93801979, grad/param norm = 1.5169e-01, time/batch = 20.2082s	
26577/30300 (epoch 43.856), train_loss = 0.99499968, grad/param norm = 1.6532e-01, time/batch = 18.9674s	
26578/30300 (epoch 43.858), train_loss = 0.92378039, grad/param norm = 1.6612e-01, time/batch = 17.8656s	
26579/30300 (epoch 43.860), train_loss = 0.90706550, grad/param norm = 1.5842e-01, time/batch = 19.7257s	
26580/30300 (epoch 43.861), train_loss = 1.13046754, grad/param norm = 1.7996e-01, time/batch = 20.2086s	
26581/30300 (epoch 43.863), train_loss = 0.94845980, grad/param norm = 1.6510e-01, time/batch = 18.1772s	
26582/30300 (epoch 43.865), train_loss = 1.05533694, grad/param norm = 2.1923e-01, time/batch = 20.0491s	
26583/30300 (epoch 43.866), train_loss = 1.06269289, grad/param norm = 1.9484e-01, time/batch = 19.0560s	
26584/30300 (epoch 43.868), train_loss = 1.02337395, grad/param norm = 1.6779e-01, time/batch = 18.4617s	
26585/30300 (epoch 43.870), train_loss = 0.93698002, grad/param norm = 1.8087e-01, time/batch = 17.3856s	
26586/30300 (epoch 43.871), train_loss = 1.01813210, grad/param norm = 1.7510e-01, time/batch = 19.5402s	
26587/30300 (epoch 43.873), train_loss = 1.01043583, grad/param norm = 1.5371e-01, time/batch = 19.7095s	
26588/30300 (epoch 43.875), train_loss = 0.95805574, grad/param norm = 1.5563e-01, time/batch = 19.3748s	
26589/30300 (epoch 43.876), train_loss = 0.88426454, grad/param norm = 1.7265e-01, time/batch = 17.4478s	
26590/30300 (epoch 43.878), train_loss = 0.83407069, grad/param norm = 1.8038e-01, time/batch = 19.6359s	
26591/30300 (epoch 43.880), train_loss = 0.92471673, grad/param norm = 1.8386e-01, time/batch = 19.0244s	
26592/30300 (epoch 43.881), train_loss = 1.16894966, grad/param norm = 3.1799e-01, time/batch = 20.0401s	
26593/30300 (epoch 43.883), train_loss = 1.07209085, grad/param norm = 2.0726e-01, time/batch = 19.5414s	
26594/30300 (epoch 43.884), train_loss = 0.98929147, grad/param norm = 1.6138e-01, time/batch = 18.3570s	
26595/30300 (epoch 43.886), train_loss = 1.03585571, grad/param norm = 2.2819e-01, time/batch = 19.3762s	
26596/30300 (epoch 43.888), train_loss = 0.96441161, grad/param norm = 1.8537e-01, time/batch = 20.0418s	
26597/30300 (epoch 43.889), train_loss = 1.02928911, grad/param norm = 1.7577e-01, time/batch = 17.8392s	
26598/30300 (epoch 43.891), train_loss = 0.98093317, grad/param norm = 1.8037e-01, time/batch = 19.8845s	
26599/30300 (epoch 43.893), train_loss = 1.20450339, grad/param norm = 1.7603e-01, time/batch = 20.0440s	
26600/30300 (epoch 43.894), train_loss = 1.00555827, grad/param norm = 1.7433e-01, time/batch = 18.4501s	
26601/30300 (epoch 43.896), train_loss = 0.86468112, grad/param norm = 2.0915e-01, time/batch = 18.5340s	
26602/30300 (epoch 43.898), train_loss = 0.84969901, grad/param norm = 1.6825e-01, time/batch = 15.9957s	
26603/30300 (epoch 43.899), train_loss = 0.88764757, grad/param norm = 1.6761e-01, time/batch = 16.7793s	
26604/30300 (epoch 43.901), train_loss = 1.00539451, grad/param norm = 1.9139e-01, time/batch = 16.3203s	
26605/30300 (epoch 43.903), train_loss = 0.96321935, grad/param norm = 1.9327e-01, time/batch = 16.5126s	
26606/30300 (epoch 43.904), train_loss = 1.00025680, grad/param norm = 1.6481e-01, time/batch = 18.6205s	
26607/30300 (epoch 43.906), train_loss = 1.01355523, grad/param norm = 2.2042e-01, time/batch = 18.1987s	
26608/30300 (epoch 43.908), train_loss = 0.95700331, grad/param norm = 1.7363e-01, time/batch = 20.5383s	
26609/30300 (epoch 43.909), train_loss = 0.96293184, grad/param norm = 2.1353e-01, time/batch = 19.8006s	
26610/30300 (epoch 43.911), train_loss = 0.98062327, grad/param norm = 1.7403e-01, time/batch = 16.8736s	
26611/30300 (epoch 43.913), train_loss = 0.98057540, grad/param norm = 1.6210e-01, time/batch = 18.5148s	
26612/30300 (epoch 43.914), train_loss = 0.96303942, grad/param norm = 2.3324e-01, time/batch = 20.3009s	
26613/30300 (epoch 43.916), train_loss = 1.01817394, grad/param norm = 1.5946e-01, time/batch = 18.2984s	
26614/30300 (epoch 43.917), train_loss = 0.94852553, grad/param norm = 1.6250e-01, time/batch = 19.4644s	
26615/30300 (epoch 43.919), train_loss = 0.87299590, grad/param norm = 1.7862e-01, time/batch = 19.5391s	
26616/30300 (epoch 43.921), train_loss = 0.96839803, grad/param norm = 1.6340e-01, time/batch = 18.9546s	
26617/30300 (epoch 43.922), train_loss = 1.09051737, grad/param norm = 2.0965e-01, time/batch = 19.9528s	
26618/30300 (epoch 43.924), train_loss = 0.98649000, grad/param norm = 1.8438e-01, time/batch = 19.7887s	
26619/30300 (epoch 43.926), train_loss = 1.04594903, grad/param norm = 1.9272e-01, time/batch = 18.5283s	
26620/30300 (epoch 43.927), train_loss = 1.00368497, grad/param norm = 1.7315e-01, time/batch = 18.3659s	
26621/30300 (epoch 43.929), train_loss = 0.93445075, grad/param norm = 1.8555e-01, time/batch = 20.0272s	
26622/30300 (epoch 43.931), train_loss = 1.05428736, grad/param norm = 1.8949e-01, time/batch = 17.2066s	
26623/30300 (epoch 43.932), train_loss = 0.90469302, grad/param norm = 1.6159e-01, time/batch = 18.1415s	
26624/30300 (epoch 43.934), train_loss = 1.01142599, grad/param norm = 1.6953e-01, time/batch = 20.3001s	
26625/30300 (epoch 43.936), train_loss = 0.94640483, grad/param norm = 1.7131e-01, time/batch = 18.6418s	
26626/30300 (epoch 43.937), train_loss = 0.94862408, grad/param norm = 1.7496e-01, time/batch = 19.2800s	
26627/30300 (epoch 43.939), train_loss = 1.08021610, grad/param norm = 1.8388e-01, time/batch = 20.2003s	
26628/30300 (epoch 43.941), train_loss = 0.96536585, grad/param norm = 1.8127e-01, time/batch = 18.3497s	
26629/30300 (epoch 43.942), train_loss = 0.96234443, grad/param norm = 1.7849e-01, time/batch = 18.1133s	
26630/30300 (epoch 43.944), train_loss = 0.88082169, grad/param norm = 1.6613e-01, time/batch = 17.2867s	
26631/30300 (epoch 43.946), train_loss = 1.04122769, grad/param norm = 2.0363e-01, time/batch = 19.1384s	
26632/30300 (epoch 43.947), train_loss = 1.02035784, grad/param norm = 2.0818e-01, time/batch = 19.4478s	
26633/30300 (epoch 43.949), train_loss = 1.06273454, grad/param norm = 2.0198e-01, time/batch = 19.7171s	
26634/30300 (epoch 43.950), train_loss = 1.09490874, grad/param norm = 1.9704e-01, time/batch = 20.0429s	
26635/30300 (epoch 43.952), train_loss = 1.02469968, grad/param norm = 1.9730e-01, time/batch = 18.3823s	
26636/30300 (epoch 43.954), train_loss = 1.21741917, grad/param norm = 1.6869e-01, time/batch = 19.8057s	
26637/30300 (epoch 43.955), train_loss = 0.98728319, grad/param norm = 1.6641e-01, time/batch = 18.8003s	
26638/30300 (epoch 43.957), train_loss = 1.05423392, grad/param norm = 1.8183e-01, time/batch = 18.9512s	
26639/30300 (epoch 43.959), train_loss = 0.90349876, grad/param norm = 2.2020e-01, time/batch = 19.3659s	
26640/30300 (epoch 43.960), train_loss = 0.95644834, grad/param norm = 1.8857e-01, time/batch = 19.9699s	
26641/30300 (epoch 43.962), train_loss = 0.92944706, grad/param norm = 2.4050e-01, time/batch = 19.0373s	
26642/30300 (epoch 43.964), train_loss = 0.90678422, grad/param norm = 1.8527e-01, time/batch = 18.1845s	
26643/30300 (epoch 43.965), train_loss = 0.92214529, grad/param norm = 2.0175e-01, time/batch = 20.2089s	
26644/30300 (epoch 43.967), train_loss = 0.96397531, grad/param norm = 2.1286e-01, time/batch = 19.0434s	
26645/30300 (epoch 43.969), train_loss = 0.93095375, grad/param norm = 2.0255e-01, time/batch = 18.3787s	
26646/30300 (epoch 43.970), train_loss = 0.96154152, grad/param norm = 1.9616e-01, time/batch = 19.6326s	
26647/30300 (epoch 43.972), train_loss = 0.88206582, grad/param norm = 1.8258e-01, time/batch = 19.0427s	
26648/30300 (epoch 43.974), train_loss = 1.11475864, grad/param norm = 1.8066e-01, time/batch = 18.2799s	
26649/30300 (epoch 43.975), train_loss = 1.12430083, grad/param norm = 2.3277e-01, time/batch = 19.7135s	
26650/30300 (epoch 43.977), train_loss = 1.19002373, grad/param norm = 1.7997e-01, time/batch = 20.2188s	
26651/30300 (epoch 43.979), train_loss = 1.04500318, grad/param norm = 1.9077e-01, time/batch = 18.6163s	
26652/30300 (epoch 43.980), train_loss = 1.09543222, grad/param norm = 1.9971e-01, time/batch = 19.2096s	
26653/30300 (epoch 43.982), train_loss = 1.06885090, grad/param norm = 1.8760e-01, time/batch = 19.6838s	
26654/30300 (epoch 43.983), train_loss = 1.10142373, grad/param norm = 1.7198e-01, time/batch = 18.7709s	
26655/30300 (epoch 43.985), train_loss = 1.04058406, grad/param norm = 2.1356e-01, time/batch = 19.7889s	
26656/30300 (epoch 43.987), train_loss = 1.02257434, grad/param norm = 1.5851e-01, time/batch = 19.2966s	
26657/30300 (epoch 43.988), train_loss = 1.11664195, grad/param norm = 2.0027e-01, time/batch = 17.7927s	
26658/30300 (epoch 43.990), train_loss = 0.93062287, grad/param norm = 1.8055e-01, time/batch = 20.0528s	
26659/30300 (epoch 43.992), train_loss = 1.09699731, grad/param norm = 1.7578e-01, time/batch = 19.4545s	
26660/30300 (epoch 43.993), train_loss = 1.06676229, grad/param norm = 2.3566e-01, time/batch = 18.6278s	
26661/30300 (epoch 43.995), train_loss = 0.98810799, grad/param norm = 1.9717e-01, time/batch = 18.0376s	
26662/30300 (epoch 43.997), train_loss = 1.04888803, grad/param norm = 1.7914e-01, time/batch = 20.6143s	
26663/30300 (epoch 43.998), train_loss = 1.07841174, grad/param norm = 1.9254e-01, time/batch = 18.2002s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
26664/30300 (epoch 44.000), train_loss = 0.94062341, grad/param norm = 2.1733e-01, time/batch = 18.4548s	
26665/30300 (epoch 44.002), train_loss = 1.11420974, grad/param norm = 2.2621e-01, time/batch = 20.2116s	
26666/30300 (epoch 44.003), train_loss = 1.02573019, grad/param norm = 2.0516e-01, time/batch = 19.1240s	
26667/30300 (epoch 44.005), train_loss = 0.98131172, grad/param norm = 1.9097e-01, time/batch = 19.4600s	
26668/30300 (epoch 44.007), train_loss = 1.06843649, grad/param norm = 2.0749e-01, time/batch = 18.8778s	
26669/30300 (epoch 44.008), train_loss = 1.00193712, grad/param norm = 1.8798e-01, time/batch = 19.1155s	
26670/30300 (epoch 44.010), train_loss = 0.88195256, grad/param norm = 1.7456e-01, time/batch = 18.7241s	
26671/30300 (epoch 44.012), train_loss = 0.97664508, grad/param norm = 1.6937e-01, time/batch = 19.3855s	
26672/30300 (epoch 44.013), train_loss = 1.10249458, grad/param norm = 2.0004e-01, time/batch = 16.2067s	
26673/30300 (epoch 44.015), train_loss = 0.94648335, grad/param norm = 1.5982e-01, time/batch = 19.1895s	
26674/30300 (epoch 44.017), train_loss = 0.97984184, grad/param norm = 1.5045e-01, time/batch = 18.0124s	
26675/30300 (epoch 44.018), train_loss = 0.88849760, grad/param norm = 1.6769e-01, time/batch = 19.9562s	
26676/30300 (epoch 44.020), train_loss = 1.09703761, grad/param norm = 2.0953e-01, time/batch = 18.1192s	
26677/30300 (epoch 44.021), train_loss = 1.11199446, grad/param norm = 1.8726e-01, time/batch = 19.2132s	
26678/30300 (epoch 44.023), train_loss = 1.01196086, grad/param norm = 1.6064e-01, time/batch = 19.7921s	
26679/30300 (epoch 44.025), train_loss = 0.93304305, grad/param norm = 1.8557e-01, time/batch = 18.7972s	
26680/30300 (epoch 44.026), train_loss = 1.08182751, grad/param norm = 1.9759e-01, time/batch = 18.7234s	
26681/30300 (epoch 44.028), train_loss = 1.07034896, grad/param norm = 1.9949e-01, time/batch = 20.6324s	
26682/30300 (epoch 44.030), train_loss = 0.95316338, grad/param norm = 1.7858e-01, time/batch = 18.9594s	
26683/30300 (epoch 44.031), train_loss = 1.03245305, grad/param norm = 1.7413e-01, time/batch = 18.7016s	
26684/30300 (epoch 44.033), train_loss = 1.02516746, grad/param norm = 1.8497e-01, time/batch = 19.9620s	
26685/30300 (epoch 44.035), train_loss = 1.03212508, grad/param norm = 2.0713e-01, time/batch = 17.9597s	
26686/30300 (epoch 44.036), train_loss = 1.03582084, grad/param norm = 1.8008e-01, time/batch = 19.3649s	
26687/30300 (epoch 44.038), train_loss = 1.06070923, grad/param norm = 1.6656e-01, time/batch = 19.4727s	
26688/30300 (epoch 44.040), train_loss = 0.88366179, grad/param norm = 1.6669e-01, time/batch = 18.5284s	
26689/30300 (epoch 44.041), train_loss = 0.83952887, grad/param norm = 1.6954e-01, time/batch = 19.1428s	
26690/30300 (epoch 44.043), train_loss = 1.03598291, grad/param norm = 1.9011e-01, time/batch = 20.1328s	
26691/30300 (epoch 44.045), train_loss = 0.94383859, grad/param norm = 1.6689e-01, time/batch = 18.7095s	
26692/30300 (epoch 44.046), train_loss = 1.12779608, grad/param norm = 2.0112e-01, time/batch = 19.0455s	
26693/30300 (epoch 44.048), train_loss = 1.03491039, grad/param norm = 2.2453e-01, time/batch = 17.2165s	
26694/30300 (epoch 44.050), train_loss = 0.92966208, grad/param norm = 1.9241e-01, time/batch = 19.6197s	
26695/30300 (epoch 44.051), train_loss = 1.02807770, grad/param norm = 1.9235e-01, time/batch = 19.3745s	
26696/30300 (epoch 44.053), train_loss = 0.87341541, grad/param norm = 2.3129e-01, time/batch = 18.8601s	
26697/30300 (epoch 44.054), train_loss = 1.04480418, grad/param norm = 1.8164e-01, time/batch = 19.5408s	
26698/30300 (epoch 44.056), train_loss = 0.92623511, grad/param norm = 1.7055e-01, time/batch = 19.3665s	
26699/30300 (epoch 44.058), train_loss = 0.96941825, grad/param norm = 1.8329e-01, time/batch = 19.9614s	
26700/30300 (epoch 44.059), train_loss = 0.96946088, grad/param norm = 2.5096e-01, time/batch = 19.4626s	
26701/30300 (epoch 44.061), train_loss = 1.04665477, grad/param norm = 1.8575e-01, time/batch = 18.7111s	
26702/30300 (epoch 44.063), train_loss = 0.90851232, grad/param norm = 1.9034e-01, time/batch = 19.2052s	
26703/30300 (epoch 44.064), train_loss = 0.97421767, grad/param norm = 1.7604e-01, time/batch = 19.7166s	
26704/30300 (epoch 44.066), train_loss = 0.98505794, grad/param norm = 1.6127e-01, time/batch = 18.7844s	
26705/30300 (epoch 44.068), train_loss = 0.92159067, grad/param norm = 1.5960e-01, time/batch = 19.1285s	
26706/30300 (epoch 44.069), train_loss = 1.04278919, grad/param norm = 2.0193e-01, time/batch = 18.6939s	
26707/30300 (epoch 44.071), train_loss = 1.02160688, grad/param norm = 1.8048e-01, time/batch = 18.8811s	
26708/30300 (epoch 44.073), train_loss = 0.92299741, grad/param norm = 1.7992e-01, time/batch = 17.5968s	
26709/30300 (epoch 44.074), train_loss = 0.96130800, grad/param norm = 1.6859e-01, time/batch = 18.2835s	
26710/30300 (epoch 44.076), train_loss = 0.98032079, grad/param norm = 1.7578e-01, time/batch = 18.3000s	
26711/30300 (epoch 44.078), train_loss = 0.90713415, grad/param norm = 1.5427e-01, time/batch = 20.1289s	
26712/30300 (epoch 44.079), train_loss = 0.95254338, grad/param norm = 1.5844e-01, time/batch = 19.3846s	
26713/30300 (epoch 44.081), train_loss = 1.00584904, grad/param norm = 1.9854e-01, time/batch = 18.2159s	
26714/30300 (epoch 44.083), train_loss = 1.05984231, grad/param norm = 2.4110e-01, time/batch = 19.6316s	
26715/30300 (epoch 44.084), train_loss = 0.93762047, grad/param norm = 1.5718e-01, time/batch = 20.3778s	
26716/30300 (epoch 44.086), train_loss = 0.95174857, grad/param norm = 1.8660e-01, time/batch = 18.5299s	
26717/30300 (epoch 44.087), train_loss = 0.93950571, grad/param norm = 1.6691e-01, time/batch = 19.2020s	
26718/30300 (epoch 44.089), train_loss = 0.90684507, grad/param norm = 1.5984e-01, time/batch = 19.2979s	
26719/30300 (epoch 44.091), train_loss = 1.03126263, grad/param norm = 1.8260e-01, time/batch = 19.7785s	
26720/30300 (epoch 44.092), train_loss = 1.06741750, grad/param norm = 1.7099e-01, time/batch = 34.2269s	
26721/30300 (epoch 44.094), train_loss = 1.09430250, grad/param norm = 2.1092e-01, time/batch = 17.8537s	
26722/30300 (epoch 44.096), train_loss = 1.11225099, grad/param norm = 1.8751e-01, time/batch = 17.3741s	
26723/30300 (epoch 44.097), train_loss = 0.95719820, grad/param norm = 1.9833e-01, time/batch = 18.7945s	
26724/30300 (epoch 44.099), train_loss = 1.04574028, grad/param norm = 1.6585e-01, time/batch = 19.5564s	
26725/30300 (epoch 44.101), train_loss = 1.09161778, grad/param norm = 2.2086e-01, time/batch = 18.5391s	
26726/30300 (epoch 44.102), train_loss = 0.92752789, grad/param norm = 1.9504e-01, time/batch = 18.8810s	
26727/30300 (epoch 44.104), train_loss = 0.97481027, grad/param norm = 2.3617e-01, time/batch = 19.1957s	
26728/30300 (epoch 44.106), train_loss = 0.91408557, grad/param norm = 1.7488e-01, time/batch = 19.1227s	
26729/30300 (epoch 44.107), train_loss = 1.05055773, grad/param norm = 1.6140e-01, time/batch = 19.5966s	
26730/30300 (epoch 44.109), train_loss = 1.07006012, grad/param norm = 2.2593e-01, time/batch = 18.7111s	
26731/30300 (epoch 44.111), train_loss = 1.03041967, grad/param norm = 2.0438e-01, time/batch = 18.5271s	
26732/30300 (epoch 44.112), train_loss = 1.12765308, grad/param norm = 1.8928e-01, time/batch = 18.6279s	
26733/30300 (epoch 44.114), train_loss = 0.95480927, grad/param norm = 1.7654e-01, time/batch = 19.8693s	
26734/30300 (epoch 44.116), train_loss = 1.03619663, grad/param norm = 2.2496e-01, time/batch = 19.1225s	
26735/30300 (epoch 44.117), train_loss = 1.09499631, grad/param norm = 1.8138e-01, time/batch = 18.7048s	
26736/30300 (epoch 44.119), train_loss = 0.89911306, grad/param norm = 2.0983e-01, time/batch = 19.0298s	
26737/30300 (epoch 44.120), train_loss = 0.97443112, grad/param norm = 1.9175e-01, time/batch = 19.8791s	
26738/30300 (epoch 44.122), train_loss = 1.08626991, grad/param norm = 2.1707e-01, time/batch = 19.1169s	
26739/30300 (epoch 44.124), train_loss = 1.16247619, grad/param norm = 2.0984e-01, time/batch = 18.1471s	
26740/30300 (epoch 44.125), train_loss = 0.90576496, grad/param norm = 1.6374e-01, time/batch = 19.5412s	
26741/30300 (epoch 44.127), train_loss = 1.01725824, grad/param norm = 2.4681e-01, time/batch = 19.3543s	
26742/30300 (epoch 44.129), train_loss = 1.05559052, grad/param norm = 2.1625e-01, time/batch = 19.7115s	
26743/30300 (epoch 44.130), train_loss = 1.12689384, grad/param norm = 1.9803e-01, time/batch = 19.9674s	
26744/30300 (epoch 44.132), train_loss = 1.11392867, grad/param norm = 2.0152e-01, time/batch = 18.7018s	
26745/30300 (epoch 44.134), train_loss = 0.93353482, grad/param norm = 2.0519e-01, time/batch = 18.6210s	
26746/30300 (epoch 44.135), train_loss = 0.94303721, grad/param norm = 1.8041e-01, time/batch = 19.2923s	
26747/30300 (epoch 44.137), train_loss = 1.00788653, grad/param norm = 1.9936e-01, time/batch = 18.0440s	
26748/30300 (epoch 44.139), train_loss = 0.93750162, grad/param norm = 2.6218e-01, time/batch = 18.9595s	
26749/30300 (epoch 44.140), train_loss = 0.98461453, grad/param norm = 2.2252e-01, time/batch = 19.0498s	
26750/30300 (epoch 44.142), train_loss = 1.06071693, grad/param norm = 2.2925e-01, time/batch = 18.2794s	
26751/30300 (epoch 44.144), train_loss = 0.91577621, grad/param norm = 2.7625e-01, time/batch = 19.6177s	
26752/30300 (epoch 44.145), train_loss = 1.06036235, grad/param norm = 2.1486e-01, time/batch = 19.3734s	
26753/30300 (epoch 44.147), train_loss = 0.98600058, grad/param norm = 2.1236e-01, time/batch = 18.7725s	
26754/30300 (epoch 44.149), train_loss = 1.05982291, grad/param norm = 2.4134e-01, time/batch = 19.0516s	
26755/30300 (epoch 44.150), train_loss = 0.96191703, grad/param norm = 2.0513e-01, time/batch = 19.3749s	
26756/30300 (epoch 44.152), train_loss = 0.90219028, grad/param norm = 1.8961e-01, time/batch = 18.8025s	
26757/30300 (epoch 44.153), train_loss = 1.02280084, grad/param norm = 2.1233e-01, time/batch = 19.2071s	
26758/30300 (epoch 44.155), train_loss = 0.88235311, grad/param norm = 1.8205e-01, time/batch = 19.2084s	
26759/30300 (epoch 44.157), train_loss = 0.93272115, grad/param norm = 1.8748e-01, time/batch = 18.7276s	
26760/30300 (epoch 44.158), train_loss = 1.03216455, grad/param norm = 2.0672e-01, time/batch = 19.0427s	
26761/30300 (epoch 44.160), train_loss = 0.91713802, grad/param norm = 1.9209e-01, time/batch = 18.5298s	
26762/30300 (epoch 44.162), train_loss = 0.97990243, grad/param norm = 1.7769e-01, time/batch = 19.4531s	
26763/30300 (epoch 44.163), train_loss = 0.99148165, grad/param norm = 2.0835e-01, time/batch = 18.9587s	
26764/30300 (epoch 44.165), train_loss = 1.10351123, grad/param norm = 1.8485e-01, time/batch = 19.6272s	
26765/30300 (epoch 44.167), train_loss = 0.99358087, grad/param norm = 2.0381e-01, time/batch = 19.6337s	
26766/30300 (epoch 44.168), train_loss = 1.03495194, grad/param norm = 1.7737e-01, time/batch = 18.5379s	
26767/30300 (epoch 44.170), train_loss = 1.02769693, grad/param norm = 2.2326e-01, time/batch = 18.7154s	
26768/30300 (epoch 44.172), train_loss = 1.00963297, grad/param norm = 2.0103e-01, time/batch = 19.1210s	
26769/30300 (epoch 44.173), train_loss = 0.95927872, grad/param norm = 1.9225e-01, time/batch = 18.6018s	
26770/30300 (epoch 44.175), train_loss = 1.02796140, grad/param norm = 2.2422e-01, time/batch = 19.1165s	
26771/30300 (epoch 44.177), train_loss = 1.04474884, grad/param norm = 2.0114e-01, time/batch = 19.7203s	
26772/30300 (epoch 44.178), train_loss = 0.83439325, grad/param norm = 1.4971e-01, time/batch = 19.1187s	
26773/30300 (epoch 44.180), train_loss = 0.97579596, grad/param norm = 1.7388e-01, time/batch = 19.5397s	
26774/30300 (epoch 44.182), train_loss = 1.00443851, grad/param norm = 1.8088e-01, time/batch = 17.8104s	
26775/30300 (epoch 44.183), train_loss = 0.93740813, grad/param norm = 1.8799e-01, time/batch = 18.9554s	
26776/30300 (epoch 44.185), train_loss = 1.12374670, grad/param norm = 2.3557e-01, time/batch = 19.6205s	
26777/30300 (epoch 44.186), train_loss = 1.21171295, grad/param norm = 2.3349e-01, time/batch = 19.6396s	
26778/30300 (epoch 44.188), train_loss = 1.03576384, grad/param norm = 1.8527e-01, time/batch = 18.1269s	
26779/30300 (epoch 44.190), train_loss = 0.98849785, grad/param norm = 1.7449e-01, time/batch = 18.7924s	
26780/30300 (epoch 44.191), train_loss = 1.05768314, grad/param norm = 2.0866e-01, time/batch = 20.3810s	
26781/30300 (epoch 44.193), train_loss = 0.90432244, grad/param norm = 1.9655e-01, time/batch = 18.9570s	
26782/30300 (epoch 44.195), train_loss = 0.95223628, grad/param norm = 1.6524e-01, time/batch = 19.1222s	
26783/30300 (epoch 44.196), train_loss = 1.04166725, grad/param norm = 1.5988e-01, time/batch = 17.8539s	
26784/30300 (epoch 44.198), train_loss = 0.84394794, grad/param norm = 1.6028e-01, time/batch = 19.3720s	
26785/30300 (epoch 44.200), train_loss = 0.96269779, grad/param norm = 1.7580e-01, time/batch = 19.3728s	
26786/30300 (epoch 44.201), train_loss = 1.08319548, grad/param norm = 2.6041e-01, time/batch = 19.1092s	
26787/30300 (epoch 44.203), train_loss = 0.99721370, grad/param norm = 1.8143e-01, time/batch = 19.7115s	
26788/30300 (epoch 44.205), train_loss = 1.15766612, grad/param norm = 2.0048e-01, time/batch = 19.0357s	
26789/30300 (epoch 44.206), train_loss = 1.08614663, grad/param norm = 2.1264e-01, time/batch = 18.7982s	
26790/30300 (epoch 44.208), train_loss = 1.06670015, grad/param norm = 2.6775e-01, time/batch = 19.7968s	
26791/30300 (epoch 44.210), train_loss = 1.07429737, grad/param norm = 1.6877e-01, time/batch = 17.7582s	
26792/30300 (epoch 44.211), train_loss = 1.13304885, grad/param norm = 2.0153e-01, time/batch = 20.5448s	
26793/30300 (epoch 44.213), train_loss = 1.01800229, grad/param norm = 1.6372e-01, time/batch = 19.5466s	
26794/30300 (epoch 44.215), train_loss = 0.93238469, grad/param norm = 1.8006e-01, time/batch = 18.1061s	
26795/30300 (epoch 44.216), train_loss = 0.94196171, grad/param norm = 1.6460e-01, time/batch = 19.7147s	
26796/30300 (epoch 44.218), train_loss = 0.91255513, grad/param norm = 1.6692e-01, time/batch = 20.2202s	
26797/30300 (epoch 44.219), train_loss = 0.88560497, grad/param norm = 1.7490e-01, time/batch = 18.3720s	
26798/30300 (epoch 44.221), train_loss = 0.85557431, grad/param norm = 1.5222e-01, time/batch = 19.7174s	
26799/30300 (epoch 44.223), train_loss = 0.99917704, grad/param norm = 1.7947e-01, time/batch = 20.1377s	
26800/30300 (epoch 44.224), train_loss = 0.84058491, grad/param norm = 1.7720e-01, time/batch = 18.1308s	
26801/30300 (epoch 44.226), train_loss = 1.04250643, grad/param norm = 2.1669e-01, time/batch = 18.7819s	
26802/30300 (epoch 44.228), train_loss = 1.11921395, grad/param norm = 2.2645e-01, time/batch = 18.7920s	
26803/30300 (epoch 44.229), train_loss = 0.99984987, grad/param norm = 1.9551e-01, time/batch = 19.2103s	
26804/30300 (epoch 44.231), train_loss = 1.06070057, grad/param norm = 1.9152e-01, time/batch = 19.5555s	
26805/30300 (epoch 44.233), train_loss = 1.05017264, grad/param norm = 1.5008e-01, time/batch = 19.2173s	
26806/30300 (epoch 44.234), train_loss = 1.06871780, grad/param norm = 2.2535e-01, time/batch = 19.1984s	
26807/30300 (epoch 44.236), train_loss = 1.05358493, grad/param norm = 1.6904e-01, time/batch = 16.8688s	
26808/30300 (epoch 44.238), train_loss = 0.99986154, grad/param norm = 1.9695e-01, time/batch = 19.5279s	
26809/30300 (epoch 44.239), train_loss = 0.95204030, grad/param norm = 2.1216e-01, time/batch = 18.8738s	
26810/30300 (epoch 44.241), train_loss = 1.04861826, grad/param norm = 2.1040e-01, time/batch = 18.7050s	
26811/30300 (epoch 44.243), train_loss = 1.04159637, grad/param norm = 1.8906e-01, time/batch = 20.2068s	
26812/30300 (epoch 44.244), train_loss = 1.19063934, grad/param norm = 1.8166e-01, time/batch = 19.9543s	
26813/30300 (epoch 44.246), train_loss = 1.04651524, grad/param norm = 1.8785e-01, time/batch = 19.5322s	
26814/30300 (epoch 44.248), train_loss = 0.99655183, grad/param norm = 1.7069e-01, time/batch = 19.6860s	
26815/30300 (epoch 44.249), train_loss = 0.89912433, grad/param norm = 1.9153e-01, time/batch = 19.3861s	
26816/30300 (epoch 44.251), train_loss = 0.92880549, grad/param norm = 1.7327e-01, time/batch = 18.8607s	
26817/30300 (epoch 44.252), train_loss = 1.09164616, grad/param norm = 1.9579e-01, time/batch = 19.8069s	
26818/30300 (epoch 44.254), train_loss = 1.07693072, grad/param norm = 1.8778e-01, time/batch = 18.5497s	
26819/30300 (epoch 44.256), train_loss = 1.05552059, grad/param norm = 1.8122e-01, time/batch = 19.0389s	
26820/30300 (epoch 44.257), train_loss = 1.07278562, grad/param norm = 2.0364e-01, time/batch = 19.5488s	
26821/30300 (epoch 44.259), train_loss = 0.98617995, grad/param norm = 1.7933e-01, time/batch = 19.6317s	
26822/30300 (epoch 44.261), train_loss = 1.15068171, grad/param norm = 1.8091e-01, time/batch = 18.9554s	
26823/30300 (epoch 44.262), train_loss = 0.92655311, grad/param norm = 1.5530e-01, time/batch = 19.3884s	
26824/30300 (epoch 44.264), train_loss = 1.00685966, grad/param norm = 1.7140e-01, time/batch = 18.1758s	
26825/30300 (epoch 44.266), train_loss = 1.00633596, grad/param norm = 1.6445e-01, time/batch = 17.9578s	
26826/30300 (epoch 44.267), train_loss = 1.13876928, grad/param norm = 1.9446e-01, time/batch = 18.7060s	
26827/30300 (epoch 44.269), train_loss = 1.02580774, grad/param norm = 1.6851e-01, time/batch = 19.1292s	
26828/30300 (epoch 44.271), train_loss = 1.02283001, grad/param norm = 1.7132e-01, time/batch = 17.3674s	
26829/30300 (epoch 44.272), train_loss = 1.02810434, grad/param norm = 2.2401e-01, time/batch = 19.2978s	
26830/30300 (epoch 44.274), train_loss = 1.07579671, grad/param norm = 2.1244e-01, time/batch = 18.6027s	
26831/30300 (epoch 44.276), train_loss = 1.02339127, grad/param norm = 1.8997e-01, time/batch = 19.2834s	
26832/30300 (epoch 44.277), train_loss = 0.92161032, grad/param norm = 2.0149e-01, time/batch = 19.0530s	
26833/30300 (epoch 44.279), train_loss = 1.00113886, grad/param norm = 1.9135e-01, time/batch = 19.8749s	
26834/30300 (epoch 44.281), train_loss = 1.09457521, grad/param norm = 2.0879e-01, time/batch = 19.4594s	
26835/30300 (epoch 44.282), train_loss = 1.04277964, grad/param norm = 1.7301e-01, time/batch = 19.3595s	
26836/30300 (epoch 44.284), train_loss = 1.07827844, grad/param norm = 2.1204e-01, time/batch = 20.0347s	
26837/30300 (epoch 44.285), train_loss = 1.06538808, grad/param norm = 1.6537e-01, time/batch = 19.6327s	
26838/30300 (epoch 44.287), train_loss = 1.03124268, grad/param norm = 2.0224e-01, time/batch = 17.5987s	
26839/30300 (epoch 44.289), train_loss = 1.09544098, grad/param norm = 1.9359e-01, time/batch = 19.7152s	
26840/30300 (epoch 44.290), train_loss = 0.80506674, grad/param norm = 1.7140e-01, time/batch = 19.7880s	
26841/30300 (epoch 44.292), train_loss = 0.91054991, grad/param norm = 1.7426e-01, time/batch = 18.0160s	
26842/30300 (epoch 44.294), train_loss = 1.06089169, grad/param norm = 2.0734e-01, time/batch = 18.7935s	
26843/30300 (epoch 44.295), train_loss = 0.96120891, grad/param norm = 1.7877e-01, time/batch = 20.3754s	
26844/30300 (epoch 44.297), train_loss = 0.97138403, grad/param norm = 1.6375e-01, time/batch = 17.6351s	
26845/30300 (epoch 44.299), train_loss = 0.99905018, grad/param norm = 1.9339e-01, time/batch = 19.9545s	
26846/30300 (epoch 44.300), train_loss = 0.93596919, grad/param norm = 1.8765e-01, time/batch = 19.6019s	
26847/30300 (epoch 44.302), train_loss = 1.07981097, grad/param norm = 1.8062e-01, time/batch = 18.5312s	
26848/30300 (epoch 44.304), train_loss = 0.93568791, grad/param norm = 1.7699e-01, time/batch = 18.5614s	
26849/30300 (epoch 44.305), train_loss = 0.99932687, grad/param norm = 1.6382e-01, time/batch = 18.5800s	
26850/30300 (epoch 44.307), train_loss = 1.09171341, grad/param norm = 1.7218e-01, time/batch = 18.1221s	
26851/30300 (epoch 44.309), train_loss = 1.03826594, grad/param norm = 1.9613e-01, time/batch = 20.7012s	
26852/30300 (epoch 44.310), train_loss = 0.98217115, grad/param norm = 1.7522e-01, time/batch = 20.4561s	
26853/30300 (epoch 44.312), train_loss = 1.12756999, grad/param norm = 1.7167e-01, time/batch = 19.0452s	
26854/30300 (epoch 44.314), train_loss = 1.00096461, grad/param norm = 1.8946e-01, time/batch = 19.9603s	
26855/30300 (epoch 44.315), train_loss = 0.96006572, grad/param norm = 1.8112e-01, time/batch = 18.5414s	
26856/30300 (epoch 44.317), train_loss = 1.02334285, grad/param norm = 1.6830e-01, time/batch = 18.6124s	
26857/30300 (epoch 44.318), train_loss = 1.04798169, grad/param norm = 1.9121e-01, time/batch = 18.6203s	
26858/30300 (epoch 44.320), train_loss = 1.04761067, grad/param norm = 1.8951e-01, time/batch = 19.1338s	
26859/30300 (epoch 44.322), train_loss = 0.94814069, grad/param norm = 1.8477e-01, time/batch = 19.3595s	
26860/30300 (epoch 44.323), train_loss = 1.10118080, grad/param norm = 2.0234e-01, time/batch = 18.4677s	
26861/30300 (epoch 44.325), train_loss = 0.98268826, grad/param norm = 1.8383e-01, time/batch = 18.3837s	
26862/30300 (epoch 44.327), train_loss = 0.98278168, grad/param norm = 1.5816e-01, time/batch = 19.1997s	
26863/30300 (epoch 44.328), train_loss = 1.02896537, grad/param norm = 1.6218e-01, time/batch = 18.4266s	
26864/30300 (epoch 44.330), train_loss = 1.04683111, grad/param norm = 1.8099e-01, time/batch = 19.2111s	
26865/30300 (epoch 44.332), train_loss = 1.09108617, grad/param norm = 1.8879e-01, time/batch = 19.6966s	
26866/30300 (epoch 44.333), train_loss = 0.93259630, grad/param norm = 2.0619e-01, time/batch = 19.1201s	
26867/30300 (epoch 44.335), train_loss = 0.92386922, grad/param norm = 1.7714e-01, time/batch = 19.4487s	
26868/30300 (epoch 44.337), train_loss = 1.11070400, grad/param norm = 1.7934e-01, time/batch = 19.7015s	
26869/30300 (epoch 44.338), train_loss = 0.94558416, grad/param norm = 1.5986e-01, time/batch = 17.8616s	
26870/30300 (epoch 44.340), train_loss = 0.95633171, grad/param norm = 1.6425e-01, time/batch = 19.1258s	
26871/30300 (epoch 44.342), train_loss = 1.08378370, grad/param norm = 1.9265e-01, time/batch = 19.9472s	
26872/30300 (epoch 44.343), train_loss = 1.03231172, grad/param norm = 1.7191e-01, time/batch = 18.2539s	
26873/30300 (epoch 44.345), train_loss = 1.04470764, grad/param norm = 1.7224e-01, time/batch = 18.0462s	
26874/30300 (epoch 44.347), train_loss = 0.90902045, grad/param norm = 1.6901e-01, time/batch = 20.0343s	
26875/30300 (epoch 44.348), train_loss = 0.96717336, grad/param norm = 1.7696e-01, time/batch = 18.7868s	
26876/30300 (epoch 44.350), train_loss = 0.97151820, grad/param norm = 1.7650e-01, time/batch = 19.2956s	
26877/30300 (epoch 44.351), train_loss = 0.99343157, grad/param norm = 1.8340e-01, time/batch = 19.6291s	
26878/30300 (epoch 44.353), train_loss = 0.91662015, grad/param norm = 1.8154e-01, time/batch = 18.7856s	
26879/30300 (epoch 44.355), train_loss = 0.95061096, grad/param norm = 1.8103e-01, time/batch = 19.5429s	
26880/30300 (epoch 44.356), train_loss = 1.05567015, grad/param norm = 1.8816e-01, time/batch = 18.8114s	
26881/30300 (epoch 44.358), train_loss = 1.23830329, grad/param norm = 1.8042e-01, time/batch = 18.7859s	
26882/30300 (epoch 44.360), train_loss = 0.95795311, grad/param norm = 1.6983e-01, time/batch = 19.1251s	
26883/30300 (epoch 44.361), train_loss = 0.99198509, grad/param norm = 2.0129e-01, time/batch = 17.7706s	
26884/30300 (epoch 44.363), train_loss = 1.02613768, grad/param norm = 1.7268e-01, time/batch = 19.1441s	
26885/30300 (epoch 44.365), train_loss = 0.85128616, grad/param norm = 1.8660e-01, time/batch = 18.7886s	
26886/30300 (epoch 44.366), train_loss = 0.96964964, grad/param norm = 1.6789e-01, time/batch = 18.8789s	
26887/30300 (epoch 44.368), train_loss = 0.88089775, grad/param norm = 1.8399e-01, time/batch = 18.8004s	
26888/30300 (epoch 44.370), train_loss = 0.92112427, grad/param norm = 1.8061e-01, time/batch = 19.0211s	
26889/30300 (epoch 44.371), train_loss = 1.06903840, grad/param norm = 1.9115e-01, time/batch = 18.9497s	
26890/30300 (epoch 44.373), train_loss = 0.94490604, grad/param norm = 1.5514e-01, time/batch = 19.8020s	
26891/30300 (epoch 44.375), train_loss = 0.93461265, grad/param norm = 1.5752e-01, time/batch = 11.8711s	
26892/30300 (epoch 44.376), train_loss = 0.92991894, grad/param norm = 1.5438e-01, time/batch = 0.7047s	
26893/30300 (epoch 44.378), train_loss = 0.90355860, grad/param norm = 1.7900e-01, time/batch = 0.7313s	
26894/30300 (epoch 44.380), train_loss = 1.10237408, grad/param norm = 1.7315e-01, time/batch = 0.6958s	
26895/30300 (epoch 44.381), train_loss = 0.83311531, grad/param norm = 1.5435e-01, time/batch = 0.6902s	
26896/30300 (epoch 44.383), train_loss = 0.89159750, grad/param norm = 1.7881e-01, time/batch = 0.6919s	
26897/30300 (epoch 44.384), train_loss = 1.03220504, grad/param norm = 1.8553e-01, time/batch = 0.6925s	
26898/30300 (epoch 44.386), train_loss = 0.90418380, grad/param norm = 1.7993e-01, time/batch = 0.7622s	
26899/30300 (epoch 44.388), train_loss = 0.89522465, grad/param norm = 2.8415e-01, time/batch = 1.0061s	
26900/30300 (epoch 44.389), train_loss = 0.98351901, grad/param norm = 1.9743e-01, time/batch = 1.0373s	
26901/30300 (epoch 44.391), train_loss = 1.03101073, grad/param norm = 1.6325e-01, time/batch = 1.0341s	
26902/30300 (epoch 44.393), train_loss = 0.88953691, grad/param norm = 1.6034e-01, time/batch = 1.0183s	
26903/30300 (epoch 44.394), train_loss = 1.01451750, grad/param norm = 2.0153e-01, time/batch = 1.3400s	
26904/30300 (epoch 44.396), train_loss = 1.12338596, grad/param norm = 1.6573e-01, time/batch = 1.9849s	
26905/30300 (epoch 44.398), train_loss = 0.98121154, grad/param norm = 1.9210e-01, time/batch = 2.0191s	
26906/30300 (epoch 44.399), train_loss = 0.89885170, grad/param norm = 1.6960e-01, time/batch = 17.6208s	
26907/30300 (epoch 44.401), train_loss = 1.00414123, grad/param norm = 2.0190e-01, time/batch = 20.3764s	
26908/30300 (epoch 44.403), train_loss = 0.98240470, grad/param norm = 1.7440e-01, time/batch = 19.3547s	
26909/30300 (epoch 44.404), train_loss = 0.93779525, grad/param norm = 2.1179e-01, time/batch = 19.5506s	
26910/30300 (epoch 44.406), train_loss = 0.99682158, grad/param norm = 1.6707e-01, time/batch = 19.6238s	
26911/30300 (epoch 44.408), train_loss = 0.86798741, grad/param norm = 1.5833e-01, time/batch = 18.8788s	
26912/30300 (epoch 44.409), train_loss = 0.87834287, grad/param norm = 1.6788e-01, time/batch = 19.8797s	
26913/30300 (epoch 44.411), train_loss = 0.91946765, grad/param norm = 1.4914e-01, time/batch = 19.9321s	
26914/30300 (epoch 44.413), train_loss = 0.82403307, grad/param norm = 1.6059e-01, time/batch = 19.1242s	
26915/30300 (epoch 44.414), train_loss = 1.03930446, grad/param norm = 1.9855e-01, time/batch = 18.1896s	
26916/30300 (epoch 44.416), train_loss = 0.92565072, grad/param norm = 1.7029e-01, time/batch = 19.0271s	
26917/30300 (epoch 44.417), train_loss = 0.91391274, grad/param norm = 2.1809e-01, time/batch = 18.4643s	
26918/30300 (epoch 44.419), train_loss = 0.90296096, grad/param norm = 2.2325e-01, time/batch = 19.1253s	
26919/30300 (epoch 44.421), train_loss = 0.95430204, grad/param norm = 2.0914e-01, time/batch = 19.2205s	
26920/30300 (epoch 44.422), train_loss = 0.99880973, grad/param norm = 1.9659e-01, time/batch = 29.5903s	
26921/30300 (epoch 44.424), train_loss = 1.00425627, grad/param norm = 1.8154e-01, time/batch = 22.0242s	
26922/30300 (epoch 44.426), train_loss = 0.96671223, grad/param norm = 1.6590e-01, time/batch = 18.6909s	
26923/30300 (epoch 44.427), train_loss = 0.95099939, grad/param norm = 1.9802e-01, time/batch = 19.7054s	
26924/30300 (epoch 44.429), train_loss = 0.97661580, grad/param norm = 1.6525e-01, time/batch = 18.7889s	
26925/30300 (epoch 44.431), train_loss = 0.99874458, grad/param norm = 1.8409e-01, time/batch = 19.1990s	
26926/30300 (epoch 44.432), train_loss = 0.99806706, grad/param norm = 1.6242e-01, time/batch = 19.5228s	
26927/30300 (epoch 44.434), train_loss = 0.88223860, grad/param norm = 1.7264e-01, time/batch = 18.1952s	
26928/30300 (epoch 44.436), train_loss = 1.07489726, grad/param norm = 1.8007e-01, time/batch = 19.7807s	
26929/30300 (epoch 44.437), train_loss = 0.89663049, grad/param norm = 1.6963e-01, time/batch = 19.6071s	
26930/30300 (epoch 44.439), train_loss = 0.94318609, grad/param norm = 1.7385e-01, time/batch = 19.5499s	
26931/30300 (epoch 44.441), train_loss = 1.05015997, grad/param norm = 2.1043e-01, time/batch = 18.1024s	
26932/30300 (epoch 44.442), train_loss = 0.91997632, grad/param norm = 1.6985e-01, time/batch = 18.4464s	
26933/30300 (epoch 44.444), train_loss = 0.82478777, grad/param norm = 1.6711e-01, time/batch = 18.8107s	
26934/30300 (epoch 44.446), train_loss = 0.93271195, grad/param norm = 1.6781e-01, time/batch = 20.1355s	
26935/30300 (epoch 44.447), train_loss = 0.97091270, grad/param norm = 1.6892e-01, time/batch = 18.6179s	
26936/30300 (epoch 44.449), train_loss = 0.92621957, grad/param norm = 1.8468e-01, time/batch = 20.4654s	
26937/30300 (epoch 44.450), train_loss = 1.00174515, grad/param norm = 1.4859e-01, time/batch = 19.8661s	
26938/30300 (epoch 44.452), train_loss = 1.08712771, grad/param norm = 1.7189e-01, time/batch = 18.0491s	
26939/30300 (epoch 44.454), train_loss = 1.02765951, grad/param norm = 2.1371e-01, time/batch = 19.8687s	
26940/30300 (epoch 44.455), train_loss = 0.99544116, grad/param norm = 1.9000e-01, time/batch = 19.8781s	
26941/30300 (epoch 44.457), train_loss = 0.96637095, grad/param norm = 1.9932e-01, time/batch = 17.7089s	
26942/30300 (epoch 44.459), train_loss = 1.01431698, grad/param norm = 1.7932e-01, time/batch = 19.2774s	
26943/30300 (epoch 44.460), train_loss = 1.06799132, grad/param norm = 1.6590e-01, time/batch = 18.5113s	
26944/30300 (epoch 44.462), train_loss = 1.05909301, grad/param norm = 1.9656e-01, time/batch = 18.6982s	
26945/30300 (epoch 44.464), train_loss = 0.81340685, grad/param norm = 1.7769e-01, time/batch = 18.4556s	
26946/30300 (epoch 44.465), train_loss = 0.84789068, grad/param norm = 1.7231e-01, time/batch = 19.2140s	
26947/30300 (epoch 44.467), train_loss = 0.84052581, grad/param norm = 1.6217e-01, time/batch = 19.1205s	
26948/30300 (epoch 44.469), train_loss = 0.92010183, grad/param norm = 1.7863e-01, time/batch = 18.2902s	
26949/30300 (epoch 44.470), train_loss = 0.93696953, grad/param norm = 2.0603e-01, time/batch = 20.2815s	
26950/30300 (epoch 44.472), train_loss = 0.93367506, grad/param norm = 1.5283e-01, time/batch = 19.5301s	
26951/30300 (epoch 44.474), train_loss = 0.91718038, grad/param norm = 1.8667e-01, time/batch = 17.9461s	
26952/30300 (epoch 44.475), train_loss = 0.91100407, grad/param norm = 1.6220e-01, time/batch = 19.3801s	
26953/30300 (epoch 44.477), train_loss = 0.96981107, grad/param norm = 1.6659e-01, time/batch = 18.3792s	
26954/30300 (epoch 44.479), train_loss = 0.93837722, grad/param norm = 1.7850e-01, time/batch = 19.0421s	
26955/30300 (epoch 44.480), train_loss = 0.99463096, grad/param norm = 1.8436e-01, time/batch = 18.6367s	
26956/30300 (epoch 44.482), train_loss = 1.03091547, grad/param norm = 1.6622e-01, time/batch = 19.4613s	
26957/30300 (epoch 44.483), train_loss = 0.97296504, grad/param norm = 1.7598e-01, time/batch = 17.7901s	
26958/30300 (epoch 44.485), train_loss = 1.00674123, grad/param norm = 2.1547e-01, time/batch = 20.0280s	
26959/30300 (epoch 44.487), train_loss = 1.03464137, grad/param norm = 1.7041e-01, time/batch = 19.6297s	
26960/30300 (epoch 44.488), train_loss = 1.10344187, grad/param norm = 1.5084e-01, time/batch = 19.0480s	
26961/30300 (epoch 44.490), train_loss = 0.85266155, grad/param norm = 1.5882e-01, time/batch = 19.8729s	
26962/30300 (epoch 44.492), train_loss = 0.94368009, grad/param norm = 1.8202e-01, time/batch = 18.5294s	
26963/30300 (epoch 44.493), train_loss = 0.99588043, grad/param norm = 1.8307e-01, time/batch = 18.6251s	
26964/30300 (epoch 44.495), train_loss = 0.96939331, grad/param norm = 1.5988e-01, time/batch = 17.6893s	
26965/30300 (epoch 44.497), train_loss = 1.01641499, grad/param norm = 1.7485e-01, time/batch = 19.6190s	
26966/30300 (epoch 44.498), train_loss = 1.04302664, grad/param norm = 1.9796e-01, time/batch = 19.0240s	
26967/30300 (epoch 44.500), train_loss = 0.92639338, grad/param norm = 2.0829e-01, time/batch = 19.2101s	
26968/30300 (epoch 44.502), train_loss = 0.98742012, grad/param norm = 2.8410e-01, time/batch = 20.0564s	
26969/30300 (epoch 44.503), train_loss = 1.07775990, grad/param norm = 1.8066e-01, time/batch = 18.7177s	
26970/30300 (epoch 44.505), train_loss = 0.88259844, grad/param norm = 1.6951e-01, time/batch = 19.9561s	
26971/30300 (epoch 44.507), train_loss = 0.88476633, grad/param norm = 2.1948e-01, time/batch = 19.6719s	
26972/30300 (epoch 44.508), train_loss = 0.94630601, grad/param norm = 3.3304e-01, time/batch = 18.7135s	
26973/30300 (epoch 44.510), train_loss = 1.07178178, grad/param norm = 2.4876e-01, time/batch = 18.3526s	
26974/30300 (epoch 44.512), train_loss = 0.92653683, grad/param norm = 1.7392e-01, time/batch = 19.8596s	
26975/30300 (epoch 44.513), train_loss = 1.00001088, grad/param norm = 1.7358e-01, time/batch = 19.4540s	
26976/30300 (epoch 44.515), train_loss = 0.96184473, grad/param norm = 1.6867e-01, time/batch = 19.2026s	
26977/30300 (epoch 44.517), train_loss = 0.79778674, grad/param norm = 1.5182e-01, time/batch = 20.2922s	
26978/30300 (epoch 44.518), train_loss = 1.06314151, grad/param norm = 1.8585e-01, time/batch = 19.1997s	
26979/30300 (epoch 44.520), train_loss = 0.94743615, grad/param norm = 1.8333e-01, time/batch = 18.9439s	
26980/30300 (epoch 44.521), train_loss = 0.87929671, grad/param norm = 2.2809e-01, time/batch = 19.2172s	
26981/30300 (epoch 44.523), train_loss = 1.07988042, grad/param norm = 2.1393e-01, time/batch = 19.6181s	
26982/30300 (epoch 44.525), train_loss = 0.88396627, grad/param norm = 1.6121e-01, time/batch = 17.6895s	
26983/30300 (epoch 44.526), train_loss = 1.00421542, grad/param norm = 1.6445e-01, time/batch = 19.7790s	
26984/30300 (epoch 44.528), train_loss = 0.84172601, grad/param norm = 1.6501e-01, time/batch = 19.7930s	
26985/30300 (epoch 44.530), train_loss = 0.85266132, grad/param norm = 1.8167e-01, time/batch = 18.7803s	
26986/30300 (epoch 44.531), train_loss = 0.95059213, grad/param norm = 1.7095e-01, time/batch = 19.3901s	
26987/30300 (epoch 44.533), train_loss = 0.95279184, grad/param norm = 1.9585e-01, time/batch = 19.3759s	
26988/30300 (epoch 44.535), train_loss = 0.97935725, grad/param norm = 1.6921e-01, time/batch = 18.2142s	
26989/30300 (epoch 44.536), train_loss = 0.98841334, grad/param norm = 2.0021e-01, time/batch = 18.9454s	
26990/30300 (epoch 44.538), train_loss = 0.85166667, grad/param norm = 1.7706e-01, time/batch = 19.5114s	
26991/30300 (epoch 44.540), train_loss = 0.93723343, grad/param norm = 2.6801e-01, time/batch = 19.5395s	
26992/30300 (epoch 44.541), train_loss = 0.95570336, grad/param norm = 2.0083e-01, time/batch = 19.5299s	
26993/30300 (epoch 44.543), train_loss = 0.94963058, grad/param norm = 1.6801e-01, time/batch = 18.6307s	
26994/30300 (epoch 44.545), train_loss = 1.04053880, grad/param norm = 2.5263e-01, time/batch = 18.1735s	
26995/30300 (epoch 44.546), train_loss = 1.13092208, grad/param norm = 1.8119e-01, time/batch = 18.4575s	
26996/30300 (epoch 44.548), train_loss = 0.93270550, grad/param norm = 1.6222e-01, time/batch = 18.2085s	
26997/30300 (epoch 44.550), train_loss = 1.02277419, grad/param norm = 2.2694e-01, time/batch = 18.3518s	
26998/30300 (epoch 44.551), train_loss = 0.90590924, grad/param norm = 1.7369e-01, time/batch = 18.7945s	
26999/30300 (epoch 44.553), train_loss = 0.95386808, grad/param norm = 1.7702e-01, time/batch = 19.2191s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch44.55_2.0675.t7	
27000/30300 (epoch 44.554), train_loss = 0.96985920, grad/param norm = 1.8017e-01, time/batch = 18.7135s	
27001/30300 (epoch 44.556), train_loss = 1.51542389, grad/param norm = 2.2650e-01, time/batch = 18.9688s	
27002/30300 (epoch 44.558), train_loss = 1.07653518, grad/param norm = 2.0901e-01, time/batch = 18.7835s	
27003/30300 (epoch 44.559), train_loss = 1.00578418, grad/param norm = 1.8866e-01, time/batch = 18.3789s	
27004/30300 (epoch 44.561), train_loss = 0.79822289, grad/param norm = 1.9459e-01, time/batch = 19.0605s	
27005/30300 (epoch 44.563), train_loss = 0.86674296, grad/param norm = 1.6772e-01, time/batch = 18.9594s	
27006/30300 (epoch 44.564), train_loss = 0.93367096, grad/param norm = 1.5745e-01, time/batch = 17.7839s	
27007/30300 (epoch 44.566), train_loss = 0.94938823, grad/param norm = 1.7542e-01, time/batch = 19.2965s	
27008/30300 (epoch 44.568), train_loss = 0.83643814, grad/param norm = 1.5844e-01, time/batch = 19.6260s	
27009/30300 (epoch 44.569), train_loss = 0.99321688, grad/param norm = 1.7281e-01, time/batch = 19.2024s	
27010/30300 (epoch 44.571), train_loss = 0.96748531, grad/param norm = 1.8295e-01, time/batch = 19.2292s	
27011/30300 (epoch 44.573), train_loss = 0.99979948, grad/param norm = 1.7483e-01, time/batch = 19.3673s	
27012/30300 (epoch 44.574), train_loss = 0.99972071, grad/param norm = 1.7568e-01, time/batch = 18.7852s	
27013/30300 (epoch 44.576), train_loss = 0.94398292, grad/param norm = 1.5950e-01, time/batch = 18.6225s	
27014/30300 (epoch 44.578), train_loss = 0.83506901, grad/param norm = 1.5456e-01, time/batch = 18.9676s	
27015/30300 (epoch 44.579), train_loss = 1.02782303, grad/param norm = 1.7970e-01, time/batch = 19.1324s	
27016/30300 (epoch 44.581), train_loss = 1.07445888, grad/param norm = 1.6202e-01, time/batch = 18.2180s	
27017/30300 (epoch 44.583), train_loss = 1.09698918, grad/param norm = 2.0893e-01, time/batch = 18.9555s	
27018/30300 (epoch 44.584), train_loss = 1.07873765, grad/param norm = 2.0166e-01, time/batch = 18.8453s	
27019/30300 (epoch 44.586), train_loss = 0.94197437, grad/param norm = 1.8768e-01, time/batch = 17.9563s	
27020/30300 (epoch 44.587), train_loss = 0.95776665, grad/param norm = 1.7440e-01, time/batch = 19.3096s	
27021/30300 (epoch 44.589), train_loss = 0.91188921, grad/param norm = 1.7464e-01, time/batch = 18.2106s	
27022/30300 (epoch 44.591), train_loss = 1.00265255, grad/param norm = 1.5414e-01, time/batch = 18.4602s	
27023/30300 (epoch 44.592), train_loss = 0.93809746, grad/param norm = 1.5494e-01, time/batch = 17.2221s	
27024/30300 (epoch 44.594), train_loss = 1.02633554, grad/param norm = 1.6973e-01, time/batch = 19.1258s	
27025/30300 (epoch 44.596), train_loss = 0.88679201, grad/param norm = 1.5289e-01, time/batch = 19.2062s	
27026/30300 (epoch 44.597), train_loss = 0.91607897, grad/param norm = 1.8046e-01, time/batch = 17.9295s	
27027/30300 (epoch 44.599), train_loss = 0.82477421, grad/param norm = 1.6490e-01, time/batch = 19.1369s	
27028/30300 (epoch 44.601), train_loss = 0.99647850, grad/param norm = 1.8260e-01, time/batch = 19.0426s	
27029/30300 (epoch 44.602), train_loss = 0.96747500, grad/param norm = 1.5842e-01, time/batch = 18.0461s	
27030/30300 (epoch 44.604), train_loss = 0.89550634, grad/param norm = 1.6400e-01, time/batch = 20.2171s	
27031/30300 (epoch 44.606), train_loss = 0.90635078, grad/param norm = 2.0854e-01, time/batch = 18.9450s	
27032/30300 (epoch 44.607), train_loss = 1.03261050, grad/param norm = 1.9089e-01, time/batch = 19.2944s	
27033/30300 (epoch 44.609), train_loss = 1.13345088, grad/param norm = 1.8285e-01, time/batch = 20.0517s	
27034/30300 (epoch 44.611), train_loss = 0.95061015, grad/param norm = 1.6680e-01, time/batch = 19.3003s	
27035/30300 (epoch 44.612), train_loss = 0.89011255, grad/param norm = 1.5336e-01, time/batch = 19.1146s	
27036/30300 (epoch 44.614), train_loss = 0.95178752, grad/param norm = 1.6589e-01, time/batch = 20.0370s	
27037/30300 (epoch 44.616), train_loss = 0.98175827, grad/param norm = 1.8641e-01, time/batch = 19.7132s	
27038/30300 (epoch 44.617), train_loss = 0.97112145, grad/param norm = 2.0099e-01, time/batch = 18.7797s	
27039/30300 (epoch 44.619), train_loss = 0.79985340, grad/param norm = 1.4542e-01, time/batch = 19.7974s	
27040/30300 (epoch 44.620), train_loss = 1.02157178, grad/param norm = 1.8007e-01, time/batch = 17.7979s	
27041/30300 (epoch 44.622), train_loss = 0.96128399, grad/param norm = 1.8897e-01, time/batch = 17.8002s	
27042/30300 (epoch 44.624), train_loss = 0.95720596, grad/param norm = 1.8610e-01, time/batch = 19.6249s	
27043/30300 (epoch 44.625), train_loss = 0.96720397, grad/param norm = 2.5110e-01, time/batch = 20.2989s	
27044/30300 (epoch 44.627), train_loss = 1.06969610, grad/param norm = 1.9903e-01, time/batch = 18.5369s	
27045/30300 (epoch 44.629), train_loss = 1.07970448, grad/param norm = 1.6238e-01, time/batch = 19.5332s	
27046/30300 (epoch 44.630), train_loss = 0.95946977, grad/param norm = 1.7890e-01, time/batch = 19.7082s	
27047/30300 (epoch 44.632), train_loss = 1.01628300, grad/param norm = 1.8731e-01, time/batch = 19.1238s	
27048/30300 (epoch 44.634), train_loss = 0.89542143, grad/param norm = 1.7648e-01, time/batch = 19.6337s	
27049/30300 (epoch 44.635), train_loss = 1.00834357, grad/param norm = 1.9317e-01, time/batch = 18.6925s	
27050/30300 (epoch 44.637), train_loss = 1.05260371, grad/param norm = 2.6359e-01, time/batch = 18.4585s	
27051/30300 (epoch 44.639), train_loss = 0.95736047, grad/param norm = 1.8799e-01, time/batch = 19.2213s	
27052/30300 (epoch 44.640), train_loss = 1.09646190, grad/param norm = 2.0259e-01, time/batch = 19.7108s	
27053/30300 (epoch 44.642), train_loss = 0.96567381, grad/param norm = 1.6089e-01, time/batch = 18.9483s	
27054/30300 (epoch 44.644), train_loss = 1.05456937, grad/param norm = 1.8334e-01, time/batch = 18.6350s	
27055/30300 (epoch 44.645), train_loss = 0.90879652, grad/param norm = 1.5163e-01, time/batch = 19.7967s	
27056/30300 (epoch 44.647), train_loss = 0.96088704, grad/param norm = 1.7616e-01, time/batch = 18.4482s	
27057/30300 (epoch 44.649), train_loss = 0.94872510, grad/param norm = 1.7551e-01, time/batch = 17.1973s	
27058/30300 (epoch 44.650), train_loss = 0.97099597, grad/param norm = 1.5916e-01, time/batch = 19.4719s	
27059/30300 (epoch 44.652), train_loss = 0.96405709, grad/param norm = 1.9253e-01, time/batch = 20.0400s	
27060/30300 (epoch 44.653), train_loss = 1.13970539, grad/param norm = 1.9343e-01, time/batch = 18.8709s	
27061/30300 (epoch 44.655), train_loss = 0.95145771, grad/param norm = 1.7120e-01, time/batch = 19.0225s	
27062/30300 (epoch 44.657), train_loss = 0.86748832, grad/param norm = 1.7774e-01, time/batch = 20.2088s	
27063/30300 (epoch 44.658), train_loss = 0.94971843, grad/param norm = 2.2567e-01, time/batch = 19.2864s	
27064/30300 (epoch 44.660), train_loss = 0.97071709, grad/param norm = 1.7636e-01, time/batch = 19.3042s	
27065/30300 (epoch 44.662), train_loss = 0.98247799, grad/param norm = 1.8626e-01, time/batch = 18.2975s	
27066/30300 (epoch 44.663), train_loss = 1.04514421, grad/param norm = 1.7480e-01, time/batch = 19.0332s	
27067/30300 (epoch 44.665), train_loss = 0.91412647, grad/param norm = 2.0174e-01, time/batch = 20.1279s	
27068/30300 (epoch 44.667), train_loss = 1.03911323, grad/param norm = 2.0622e-01, time/batch = 18.0481s	
27069/30300 (epoch 44.668), train_loss = 1.06191703, grad/param norm = 1.8525e-01, time/batch = 18.0347s	
27070/30300 (epoch 44.670), train_loss = 1.07724605, grad/param norm = 1.7828e-01, time/batch = 20.2868s	
27071/30300 (epoch 44.672), train_loss = 0.97469935, grad/param norm = 1.9164e-01, time/batch = 19.7166s	
27072/30300 (epoch 44.673), train_loss = 1.03536981, grad/param norm = 1.9861e-01, time/batch = 18.2213s	
27073/30300 (epoch 44.675), train_loss = 0.96569442, grad/param norm = 2.1331e-01, time/batch = 18.4529s	
27074/30300 (epoch 44.677), train_loss = 0.93212888, grad/param norm = 1.5523e-01, time/batch = 20.1254s	
27075/30300 (epoch 44.678), train_loss = 0.93036593, grad/param norm = 1.6412e-01, time/batch = 18.4642s	
27076/30300 (epoch 44.680), train_loss = 0.88409485, grad/param norm = 1.5815e-01, time/batch = 18.2580s	
27077/30300 (epoch 44.682), train_loss = 0.95927846, grad/param norm = 1.7060e-01, time/batch = 20.2933s	
27078/30300 (epoch 44.683), train_loss = 1.04776220, grad/param norm = 1.7132e-01, time/batch = 19.2907s	
27079/30300 (epoch 44.685), train_loss = 1.03154761, grad/param norm = 2.0553e-01, time/batch = 19.2189s	
27080/30300 (epoch 44.686), train_loss = 0.96401543, grad/param norm = 1.5975e-01, time/batch = 19.8858s	
27081/30300 (epoch 44.688), train_loss = 0.97270650, grad/param norm = 1.5576e-01, time/batch = 19.2893s	
27082/30300 (epoch 44.690), train_loss = 0.93255925, grad/param norm = 1.7861e-01, time/batch = 18.8034s	
27083/30300 (epoch 44.691), train_loss = 0.97419891, grad/param norm = 1.8579e-01, time/batch = 18.7962s	
27084/30300 (epoch 44.693), train_loss = 1.25335966, grad/param norm = 2.2294e-01, time/batch = 19.3580s	
27085/30300 (epoch 44.695), train_loss = 1.04504023, grad/param norm = 1.7765e-01, time/batch = 19.4619s	
27086/30300 (epoch 44.696), train_loss = 1.01557411, grad/param norm = 2.0726e-01, time/batch = 18.6366s	
27087/30300 (epoch 44.698), train_loss = 0.93656780, grad/param norm = 1.8209e-01, time/batch = 18.5176s	
27088/30300 (epoch 44.700), train_loss = 0.92330620, grad/param norm = 1.7463e-01, time/batch = 19.1154s	
27089/30300 (epoch 44.701), train_loss = 0.87068139, grad/param norm = 1.8444e-01, time/batch = 19.1455s	
27090/30300 (epoch 44.703), train_loss = 0.97324499, grad/param norm = 1.6547e-01, time/batch = 19.0648s	
27091/30300 (epoch 44.705), train_loss = 0.89722629, grad/param norm = 1.8055e-01, time/batch = 16.9523s	
27092/30300 (epoch 44.706), train_loss = 1.04137333, grad/param norm = 1.7970e-01, time/batch = 17.2710s	
27093/30300 (epoch 44.708), train_loss = 0.98224970, grad/param norm = 1.6924e-01, time/batch = 19.1443s	
27094/30300 (epoch 44.710), train_loss = 0.95527359, grad/param norm = 1.8874e-01, time/batch = 19.0398s	
27095/30300 (epoch 44.711), train_loss = 0.92628943, grad/param norm = 1.8667e-01, time/batch = 19.2925s	
27096/30300 (epoch 44.713), train_loss = 0.92900384, grad/param norm = 1.9400e-01, time/batch = 19.0421s	
27097/30300 (epoch 44.715), train_loss = 0.94720614, grad/param norm = 1.7275e-01, time/batch = 18.1837s	
27098/30300 (epoch 44.716), train_loss = 1.02813190, grad/param norm = 1.7550e-01, time/batch = 18.5458s	
27099/30300 (epoch 44.718), train_loss = 1.08577876, grad/param norm = 1.9153e-01, time/batch = 20.3033s	
27100/30300 (epoch 44.719), train_loss = 0.93934256, grad/param norm = 2.1583e-01, time/batch = 22.2499s	
27101/30300 (epoch 44.721), train_loss = 0.95263263, grad/param norm = 1.8026e-01, time/batch = 29.5192s	
27102/30300 (epoch 44.723), train_loss = 0.90847407, grad/param norm = 1.6944e-01, time/batch = 17.6920s	
27103/30300 (epoch 44.724), train_loss = 0.99288968, grad/param norm = 1.9476e-01, time/batch = 17.3495s	
27104/30300 (epoch 44.726), train_loss = 1.24571444, grad/param norm = 2.9604e-01, time/batch = 19.7109s	
27105/30300 (epoch 44.728), train_loss = 1.01026677, grad/param norm = 1.8542e-01, time/batch = 18.9554s	
27106/30300 (epoch 44.729), train_loss = 0.94501180, grad/param norm = 1.9254e-01, time/batch = 18.2134s	
27107/30300 (epoch 44.731), train_loss = 0.93162676, grad/param norm = 1.8940e-01, time/batch = 19.3754s	
27108/30300 (epoch 44.733), train_loss = 0.98353006, grad/param norm = 1.7614e-01, time/batch = 19.2146s	
27109/30300 (epoch 44.734), train_loss = 1.05991408, grad/param norm = 1.6553e-01, time/batch = 19.0410s	
27110/30300 (epoch 44.736), train_loss = 1.00203571, grad/param norm = 1.6649e-01, time/batch = 18.6188s	
27111/30300 (epoch 44.738), train_loss = 0.91329822, grad/param norm = 1.4490e-01, time/batch = 19.3589s	
27112/30300 (epoch 44.739), train_loss = 1.09366316, grad/param norm = 1.9541e-01, time/batch = 18.2786s	
27113/30300 (epoch 44.741), train_loss = 1.10553898, grad/param norm = 1.6683e-01, time/batch = 19.2935s	
27114/30300 (epoch 44.743), train_loss = 0.94427939, grad/param norm = 1.7980e-01, time/batch = 19.8040s	
27115/30300 (epoch 44.744), train_loss = 1.02665400, grad/param norm = 1.7897e-01, time/batch = 18.8673s	
27116/30300 (epoch 44.746), train_loss = 0.94571561, grad/param norm = 1.7294e-01, time/batch = 17.6160s	
27117/30300 (epoch 44.748), train_loss = 0.96833184, grad/param norm = 1.9505e-01, time/batch = 19.6350s	
27118/30300 (epoch 44.749), train_loss = 0.98428929, grad/param norm = 1.6950e-01, time/batch = 19.0426s	
27119/30300 (epoch 44.751), train_loss = 1.02660362, grad/param norm = 1.7920e-01, time/batch = 19.3680s	
27120/30300 (epoch 44.752), train_loss = 0.95775778, grad/param norm = 1.7416e-01, time/batch = 19.6297s	
27121/30300 (epoch 44.754), train_loss = 0.97038710, grad/param norm = 1.5999e-01, time/batch = 19.8884s	
27122/30300 (epoch 44.756), train_loss = 0.96996861, grad/param norm = 1.7891e-01, time/batch = 19.0285s	
27123/30300 (epoch 44.757), train_loss = 0.90279144, grad/param norm = 1.7211e-01, time/batch = 18.7075s	
27124/30300 (epoch 44.759), train_loss = 0.99155292, grad/param norm = 1.5851e-01, time/batch = 19.2170s	
27125/30300 (epoch 44.761), train_loss = 0.84602235, grad/param norm = 1.6209e-01, time/batch = 18.1897s	
27126/30300 (epoch 44.762), train_loss = 0.87091289, grad/param norm = 1.5737e-01, time/batch = 19.2211s	
27127/30300 (epoch 44.764), train_loss = 0.95907963, grad/param norm = 1.7969e-01, time/batch = 18.9700s	
27128/30300 (epoch 44.766), train_loss = 1.08385432, grad/param norm = 1.9205e-01, time/batch = 18.3028s	
27129/30300 (epoch 44.767), train_loss = 0.96442352, grad/param norm = 1.9419e-01, time/batch = 18.9577s	
27130/30300 (epoch 44.769), train_loss = 0.97756665, grad/param norm = 1.9072e-01, time/batch = 19.0621s	
27131/30300 (epoch 44.771), train_loss = 0.90360453, grad/param norm = 1.8603e-01, time/batch = 18.4496s	
27132/30300 (epoch 44.772), train_loss = 0.96129625, grad/param norm = 1.7655e-01, time/batch = 19.8680s	
27133/30300 (epoch 44.774), train_loss = 1.14001145, grad/param norm = 1.8750e-01, time/batch = 20.2093s	
27134/30300 (epoch 44.776), train_loss = 0.95209851, grad/param norm = 1.8606e-01, time/batch = 18.0618s	
27135/30300 (epoch 44.777), train_loss = 1.09986678, grad/param norm = 1.7452e-01, time/batch = 18.7973s	
27136/30300 (epoch 44.779), train_loss = 1.11133556, grad/param norm = 2.2623e-01, time/batch = 19.3033s	
27137/30300 (epoch 44.781), train_loss = 0.97656167, grad/param norm = 1.8814e-01, time/batch = 18.7036s	
27138/30300 (epoch 44.782), train_loss = 0.92516961, grad/param norm = 2.1251e-01, time/batch = 19.7112s	
27139/30300 (epoch 44.784), train_loss = 0.93992895, grad/param norm = 1.8205e-01, time/batch = 17.5306s	
27140/30300 (epoch 44.785), train_loss = 1.03449597, grad/param norm = 2.0876e-01, time/batch = 15.9512s	
27141/30300 (epoch 44.787), train_loss = 0.83973794, grad/param norm = 1.9839e-01, time/batch = 18.4449s	
27142/30300 (epoch 44.789), train_loss = 1.13048898, grad/param norm = 2.0396e-01, time/batch = 19.3702s	
27143/30300 (epoch 44.790), train_loss = 0.96646500, grad/param norm = 1.8651e-01, time/batch = 19.3854s	
27144/30300 (epoch 44.792), train_loss = 0.79464584, grad/param norm = 1.8059e-01, time/batch = 17.9634s	
27145/30300 (epoch 44.794), train_loss = 0.98775722, grad/param norm = 1.8310e-01, time/batch = 18.6415s	
27146/30300 (epoch 44.795), train_loss = 0.90507014, grad/param norm = 1.8489e-01, time/batch = 20.2121s	
27147/30300 (epoch 44.797), train_loss = 1.11757867, grad/param norm = 2.2769e-01, time/batch = 17.3724s	
27148/30300 (epoch 44.799), train_loss = 1.03924327, grad/param norm = 2.0484e-01, time/batch = 18.4727s	
27149/30300 (epoch 44.800), train_loss = 1.03038569, grad/param norm = 1.7536e-01, time/batch = 18.7752s	
27150/30300 (epoch 44.802), train_loss = 1.23420567, grad/param norm = 3.7176e-01, time/batch = 18.2198s	
27151/30300 (epoch 44.804), train_loss = 1.03483129, grad/param norm = 1.8033e-01, time/batch = 19.4760s	
27152/30300 (epoch 44.805), train_loss = 1.10707909, grad/param norm = 1.9310e-01, time/batch = 17.8555s	
27153/30300 (epoch 44.807), train_loss = 0.94304686, grad/param norm = 1.8203e-01, time/batch = 19.2945s	
27154/30300 (epoch 44.809), train_loss = 1.07615623, grad/param norm = 1.9581e-01, time/batch = 18.9585s	
27155/30300 (epoch 44.810), train_loss = 1.03112927, grad/param norm = 1.8635e-01, time/batch = 18.7097s	
27156/30300 (epoch 44.812), train_loss = 0.94273587, grad/param norm = 1.6873e-01, time/batch = 19.6298s	
27157/30300 (epoch 44.814), train_loss = 0.98861912, grad/param norm = 1.8105e-01, time/batch = 17.4618s	
27158/30300 (epoch 44.815), train_loss = 1.00713930, grad/param norm = 2.1707e-01, time/batch = 19.0395s	
27159/30300 (epoch 44.817), train_loss = 1.05844569, grad/param norm = 2.1689e-01, time/batch = 19.1228s	
27160/30300 (epoch 44.818), train_loss = 1.02106138, grad/param norm = 1.7436e-01, time/batch = 18.4569s	
27161/30300 (epoch 44.820), train_loss = 1.15664400, grad/param norm = 3.5463e-01, time/batch = 18.8982s	
27162/30300 (epoch 44.822), train_loss = 1.13425794, grad/param norm = 2.2586e-01, time/batch = 18.5530s	
27163/30300 (epoch 44.823), train_loss = 1.11251185, grad/param norm = 2.1079e-01, time/batch = 18.2791s	
27164/30300 (epoch 44.825), train_loss = 1.12163248, grad/param norm = 1.9111e-01, time/batch = 19.0616s	
27165/30300 (epoch 44.827), train_loss = 0.84703441, grad/param norm = 1.8933e-01, time/batch = 19.3804s	
27166/30300 (epoch 44.828), train_loss = 1.09734451, grad/param norm = 1.9240e-01, time/batch = 19.0489s	
27167/30300 (epoch 44.830), train_loss = 1.03516431, grad/param norm = 1.8550e-01, time/batch = 18.0280s	
27168/30300 (epoch 44.832), train_loss = 0.92745961, grad/param norm = 1.7963e-01, time/batch = 19.1326s	
27169/30300 (epoch 44.833), train_loss = 1.02291247, grad/param norm = 2.0304e-01, time/batch = 18.3695s	
27170/30300 (epoch 44.835), train_loss = 0.93063118, grad/param norm = 1.6938e-01, time/batch = 19.8760s	
27171/30300 (epoch 44.837), train_loss = 0.90640107, grad/param norm = 1.7551e-01, time/batch = 17.8005s	
27172/30300 (epoch 44.838), train_loss = 0.90626713, grad/param norm = 1.9318e-01, time/batch = 18.8700s	
27173/30300 (epoch 44.840), train_loss = 1.05323200, grad/param norm = 1.6236e-01, time/batch = 19.7041s	
27174/30300 (epoch 44.842), train_loss = 0.96885301, grad/param norm = 1.6273e-01, time/batch = 18.8807s	
27175/30300 (epoch 44.843), train_loss = 1.02344125, grad/param norm = 1.9582e-01, time/batch = 18.5552s	
27176/30300 (epoch 44.845), train_loss = 1.02417373, grad/param norm = 1.5879e-01, time/batch = 19.0360s	
27177/30300 (epoch 44.847), train_loss = 0.99271020, grad/param norm = 2.0735e-01, time/batch = 19.3060s	
27178/30300 (epoch 44.848), train_loss = 1.03532121, grad/param norm = 1.8245e-01, time/batch = 19.5489s	
27179/30300 (epoch 44.850), train_loss = 0.98315696, grad/param norm = 1.9318e-01, time/batch = 17.0227s	
27180/30300 (epoch 44.851), train_loss = 1.03533931, grad/param norm = 2.1663e-01, time/batch = 19.4604s	
27181/30300 (epoch 44.853), train_loss = 0.96276811, grad/param norm = 1.8353e-01, time/batch = 19.7130s	
27182/30300 (epoch 44.855), train_loss = 0.93645702, grad/param norm = 1.6925e-01, time/batch = 18.1333s	
27183/30300 (epoch 44.856), train_loss = 0.99215166, grad/param norm = 1.8178e-01, time/batch = 19.7068s	
27184/30300 (epoch 44.858), train_loss = 0.91386601, grad/param norm = 1.6125e-01, time/batch = 18.8721s	
27185/30300 (epoch 44.860), train_loss = 0.90426621, grad/param norm = 1.6348e-01, time/batch = 18.8744s	
27186/30300 (epoch 44.861), train_loss = 1.12166201, grad/param norm = 1.7751e-01, time/batch = 19.2960s	
27187/30300 (epoch 44.863), train_loss = 0.94226839, grad/param norm = 1.6913e-01, time/batch = 18.6361s	
27188/30300 (epoch 44.865), train_loss = 1.04958209, grad/param norm = 2.2240e-01, time/batch = 18.6953s	
27189/30300 (epoch 44.866), train_loss = 1.06045500, grad/param norm = 2.0392e-01, time/batch = 19.8528s	
27190/30300 (epoch 44.868), train_loss = 1.00940705, grad/param norm = 1.6507e-01, time/batch = 18.7689s	
27191/30300 (epoch 44.870), train_loss = 0.93247574, grad/param norm = 1.7063e-01, time/batch = 18.0485s	
27192/30300 (epoch 44.871), train_loss = 1.01586706, grad/param norm = 1.7836e-01, time/batch = 18.3959s	
27193/30300 (epoch 44.873), train_loss = 0.99692817, grad/param norm = 1.5323e-01, time/batch = 18.6475s	
27194/30300 (epoch 44.875), train_loss = 0.94849956, grad/param norm = 1.5609e-01, time/batch = 19.4582s	
27195/30300 (epoch 44.876), train_loss = 0.87361127, grad/param norm = 1.7108e-01, time/batch = 18.3809s	
27196/30300 (epoch 44.878), train_loss = 0.83020854, grad/param norm = 1.6329e-01, time/batch = 19.2994s	
27197/30300 (epoch 44.880), train_loss = 0.90370449, grad/param norm = 1.6375e-01, time/batch = 18.3688s	
27198/30300 (epoch 44.881), train_loss = 1.15080429, grad/param norm = 2.3352e-01, time/batch = 18.4680s	
27199/30300 (epoch 44.883), train_loss = 1.03484466, grad/param norm = 1.8214e-01, time/batch = 18.3655s	
27200/30300 (epoch 44.884), train_loss = 0.98945667, grad/param norm = 1.6711e-01, time/batch = 18.7212s	
27201/30300 (epoch 44.886), train_loss = 1.03632871, grad/param norm = 1.8066e-01, time/batch = 17.5174s	
27202/30300 (epoch 44.888), train_loss = 0.93995056, grad/param norm = 1.8735e-01, time/batch = 19.8015s	
27203/30300 (epoch 44.889), train_loss = 1.01757178, grad/param norm = 1.6789e-01, time/batch = 17.9691s	
27204/30300 (epoch 44.891), train_loss = 0.96825227, grad/param norm = 1.8364e-01, time/batch = 18.7172s	
27205/30300 (epoch 44.893), train_loss = 1.19964906, grad/param norm = 1.8867e-01, time/batch = 18.1333s	
27206/30300 (epoch 44.894), train_loss = 0.99859661, grad/param norm = 1.7519e-01, time/batch = 19.8854s	
27207/30300 (epoch 44.896), train_loss = 0.86540079, grad/param norm = 2.0989e-01, time/batch = 18.1232s	
27208/30300 (epoch 44.898), train_loss = 0.83399533, grad/param norm = 1.6862e-01, time/batch = 19.5464s	
27209/30300 (epoch 44.899), train_loss = 0.89329253, grad/param norm = 1.7770e-01, time/batch = 19.0459s	
27210/30300 (epoch 44.901), train_loss = 0.99861893, grad/param norm = 1.9249e-01, time/batch = 18.3005s	
27211/30300 (epoch 44.903), train_loss = 0.96109482, grad/param norm = 1.8566e-01, time/batch = 19.6198s	
27212/30300 (epoch 44.904), train_loss = 0.99585767, grad/param norm = 1.6488e-01, time/batch = 18.9743s	
27213/30300 (epoch 44.906), train_loss = 1.00920161, grad/param norm = 2.4039e-01, time/batch = 17.7253s	
27214/30300 (epoch 44.908), train_loss = 0.94050431, grad/param norm = 1.7152e-01, time/batch = 18.6046s	
27215/30300 (epoch 44.909), train_loss = 0.94041717, grad/param norm = 2.2479e-01, time/batch = 19.8923s	
27216/30300 (epoch 44.911), train_loss = 0.97038839, grad/param norm = 1.6617e-01, time/batch = 19.9718s	
27217/30300 (epoch 44.913), train_loss = 0.96266348, grad/param norm = 1.5477e-01, time/batch = 18.4757s	
27218/30300 (epoch 44.914), train_loss = 0.95370544, grad/param norm = 1.7075e-01, time/batch = 20.0542s	
27219/30300 (epoch 44.916), train_loss = 1.01452590, grad/param norm = 1.5886e-01, time/batch = 18.1290s	
27220/30300 (epoch 44.917), train_loss = 0.94924807, grad/param norm = 1.7165e-01, time/batch = 17.8576s	
27221/30300 (epoch 44.919), train_loss = 0.87684703, grad/param norm = 1.8521e-01, time/batch = 19.4487s	
27222/30300 (epoch 44.921), train_loss = 0.97090002, grad/param norm = 1.7400e-01, time/batch = 19.2016s	
27223/30300 (epoch 44.922), train_loss = 1.07407385, grad/param norm = 1.8915e-01, time/batch = 18.5429s	
27224/30300 (epoch 44.924), train_loss = 0.98876790, grad/param norm = 2.0554e-01, time/batch = 18.6274s	
27225/30300 (epoch 44.926), train_loss = 1.03286924, grad/param norm = 1.8095e-01, time/batch = 17.8704s	
27226/30300 (epoch 44.927), train_loss = 0.99399930, grad/param norm = 1.7231e-01, time/batch = 18.6221s	
27227/30300 (epoch 44.929), train_loss = 0.93018804, grad/param norm = 1.8488e-01, time/batch = 18.8967s	
27228/30300 (epoch 44.931), train_loss = 1.04803322, grad/param norm = 2.0710e-01, time/batch = 19.8834s	
27229/30300 (epoch 44.932), train_loss = 0.90903244, grad/param norm = 1.6922e-01, time/batch = 19.2051s	
27230/30300 (epoch 44.934), train_loss = 1.01310355, grad/param norm = 1.7813e-01, time/batch = 18.7975s	
27231/30300 (epoch 44.936), train_loss = 0.95023074, grad/param norm = 1.7910e-01, time/batch = 18.8767s	
27232/30300 (epoch 44.937), train_loss = 0.94067872, grad/param norm = 1.6422e-01, time/batch = 19.5504s	
27233/30300 (epoch 44.939), train_loss = 1.08325742, grad/param norm = 1.9984e-01, time/batch = 18.4518s	
27234/30300 (epoch 44.941), train_loss = 0.96068297, grad/param norm = 1.8361e-01, time/batch = 19.7164s	
27235/30300 (epoch 44.942), train_loss = 0.96103896, grad/param norm = 1.8359e-01, time/batch = 18.0463s	
27236/30300 (epoch 44.944), train_loss = 0.86956326, grad/param norm = 1.7330e-01, time/batch = 17.5152s	
27237/30300 (epoch 44.946), train_loss = 1.02795587, grad/param norm = 2.0667e-01, time/batch = 19.6335s	
27238/30300 (epoch 44.947), train_loss = 1.00231694, grad/param norm = 2.1031e-01, time/batch = 18.5528s	
27239/30300 (epoch 44.949), train_loss = 1.06217861, grad/param norm = 2.2838e-01, time/batch = 18.2986s	
27240/30300 (epoch 44.950), train_loss = 1.08522825, grad/param norm = 1.9565e-01, time/batch = 18.7171s	
27241/30300 (epoch 44.952), train_loss = 1.02057425, grad/param norm = 2.1278e-01, time/batch = 19.9717s	
27242/30300 (epoch 44.954), train_loss = 1.21007791, grad/param norm = 1.7925e-01, time/batch = 17.3549s	
27243/30300 (epoch 44.955), train_loss = 0.97432468, grad/param norm = 1.6804e-01, time/batch = 19.6324s	
27244/30300 (epoch 44.957), train_loss = 1.04424226, grad/param norm = 1.9404e-01, time/batch = 18.7852s	
27245/30300 (epoch 44.959), train_loss = 0.88439400, grad/param norm = 1.8038e-01, time/batch = 18.5078s	
27246/30300 (epoch 44.960), train_loss = 0.94991886, grad/param norm = 1.7681e-01, time/batch = 17.2792s	
27247/30300 (epoch 44.962), train_loss = 0.93610656, grad/param norm = 2.6540e-01, time/batch = 19.9696s	
27248/30300 (epoch 44.964), train_loss = 0.90100280, grad/param norm = 2.0596e-01, time/batch = 19.2069s	
27249/30300 (epoch 44.965), train_loss = 0.92099839, grad/param norm = 2.2400e-01, time/batch = 18.2095s	
27250/30300 (epoch 44.967), train_loss = 0.95670367, grad/param norm = 2.2085e-01, time/batch = 19.4740s	
27251/30300 (epoch 44.969), train_loss = 0.91253632, grad/param norm = 1.9398e-01, time/batch = 19.0529s	
27252/30300 (epoch 44.970), train_loss = 0.95453641, grad/param norm = 1.9516e-01, time/batch = 18.6121s	
27253/30300 (epoch 44.972), train_loss = 0.89038666, grad/param norm = 2.0728e-01, time/batch = 20.0523s	
27254/30300 (epoch 44.974), train_loss = 1.11134584, grad/param norm = 2.2234e-01, time/batch = 18.5489s	
27255/30300 (epoch 44.975), train_loss = 1.10772084, grad/param norm = 2.0739e-01, time/batch = 18.3703s	
27256/30300 (epoch 44.977), train_loss = 1.17994797, grad/param norm = 1.8377e-01, time/batch = 18.5524s	
27257/30300 (epoch 44.979), train_loss = 1.03338861, grad/param norm = 1.7739e-01, time/batch = 19.5475s	
27258/30300 (epoch 44.980), train_loss = 1.08208464, grad/param norm = 2.3889e-01, time/batch = 17.1933s	
27259/30300 (epoch 44.982), train_loss = 1.05549685, grad/param norm = 1.9193e-01, time/batch = 18.9399s	
27260/30300 (epoch 44.983), train_loss = 1.08662372, grad/param norm = 1.7783e-01, time/batch = 19.6327s	
27261/30300 (epoch 44.985), train_loss = 1.03367088, grad/param norm = 2.7568e-01, time/batch = 17.9742s	
27262/30300 (epoch 44.987), train_loss = 1.01743838, grad/param norm = 1.6334e-01, time/batch = 19.1101s	
27263/30300 (epoch 44.988), train_loss = 1.10791238, grad/param norm = 2.0109e-01, time/batch = 20.1995s	
27264/30300 (epoch 44.990), train_loss = 0.92962661, grad/param norm = 1.7929e-01, time/batch = 19.1356s	
27265/30300 (epoch 44.992), train_loss = 1.08539059, grad/param norm = 1.7245e-01, time/batch = 16.9447s	
27266/30300 (epoch 44.993), train_loss = 1.06667152, grad/param norm = 2.1429e-01, time/batch = 19.5436s	
27267/30300 (epoch 44.995), train_loss = 0.97719423, grad/param norm = 2.1523e-01, time/batch = 18.2843s	
27268/30300 (epoch 44.997), train_loss = 1.05334637, grad/param norm = 1.8895e-01, time/batch = 19.2829s	
27269/30300 (epoch 44.998), train_loss = 1.07546995, grad/param norm = 2.1409e-01, time/batch = 18.7162s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
27270/30300 (epoch 45.000), train_loss = 0.93364746, grad/param norm = 2.0428e-01, time/batch = 18.7921s	
27271/30300 (epoch 45.002), train_loss = 1.09713445, grad/param norm = 1.9915e-01, time/batch = 19.0880s	
27272/30300 (epoch 45.003), train_loss = 1.03093675, grad/param norm = 1.7817e-01, time/batch = 19.8812s	
27273/30300 (epoch 45.005), train_loss = 0.96766318, grad/param norm = 1.9778e-01, time/batch = 19.3751s	
27274/30300 (epoch 45.007), train_loss = 1.06101015, grad/param norm = 2.1267e-01, time/batch = 18.7818s	
27275/30300 (epoch 45.008), train_loss = 1.00697727, grad/param norm = 2.3168e-01, time/batch = 19.4762s	
27276/30300 (epoch 45.010), train_loss = 0.88145481, grad/param norm = 1.7461e-01, time/batch = 19.1212s	
27277/30300 (epoch 45.012), train_loss = 0.97711890, grad/param norm = 1.9442e-01, time/batch = 18.4475s	
27278/30300 (epoch 45.013), train_loss = 1.08476688, grad/param norm = 2.0010e-01, time/batch = 19.6308s	
27279/30300 (epoch 45.015), train_loss = 0.94075702, grad/param norm = 1.6693e-01, time/batch = 19.5534s	
27280/30300 (epoch 45.017), train_loss = 0.97122977, grad/param norm = 1.6821e-01, time/batch = 18.7899s	
27281/30300 (epoch 45.018), train_loss = 0.88527144, grad/param norm = 2.0359e-01, time/batch = 18.6079s	
27282/30300 (epoch 45.020), train_loss = 1.09445789, grad/param norm = 1.9614e-01, time/batch = 19.9580s	
27283/30300 (epoch 45.021), train_loss = 1.10386230, grad/param norm = 1.8652e-01, time/batch = 17.6193s	
27284/30300 (epoch 45.023), train_loss = 1.00128799, grad/param norm = 1.4982e-01, time/batch = 19.7857s	
27285/30300 (epoch 45.025), train_loss = 0.92765515, grad/param norm = 1.9422e-01, time/batch = 19.3863s	
27286/30300 (epoch 45.026), train_loss = 1.07694644, grad/param norm = 2.2581e-01, time/batch = 18.4600s	
27287/30300 (epoch 45.028), train_loss = 1.05156348, grad/param norm = 1.6672e-01, time/batch = 18.2013s	
27288/30300 (epoch 45.030), train_loss = 0.94325993, grad/param norm = 1.8101e-01, time/batch = 19.2963s	
27289/30300 (epoch 45.031), train_loss = 1.03513794, grad/param norm = 1.8485e-01, time/batch = 19.6128s	
27290/30300 (epoch 45.033), train_loss = 1.01717557, grad/param norm = 1.8878e-01, time/batch = 32.7252s	
27291/30300 (epoch 45.035), train_loss = 1.01595983, grad/param norm = 1.9221e-01, time/batch = 18.3583s	
27292/30300 (epoch 45.036), train_loss = 1.02869218, grad/param norm = 1.9222e-01, time/batch = 17.5489s	
27293/30300 (epoch 45.038), train_loss = 1.04593296, grad/param norm = 1.6413e-01, time/batch = 19.5411s	
27294/30300 (epoch 45.040), train_loss = 0.87447062, grad/param norm = 1.6126e-01, time/batch = 19.3861s	
27295/30300 (epoch 45.041), train_loss = 0.83427003, grad/param norm = 2.0996e-01, time/batch = 18.3697s	
27296/30300 (epoch 45.043), train_loss = 1.03935713, grad/param norm = 1.9294e-01, time/batch = 19.3746s	
27297/30300 (epoch 45.045), train_loss = 0.93571893, grad/param norm = 1.6818e-01, time/batch = 18.4570s	
27298/30300 (epoch 45.046), train_loss = 1.10633741, grad/param norm = 1.9597e-01, time/batch = 18.4581s	
27299/30300 (epoch 45.048), train_loss = 1.02039016, grad/param norm = 1.9278e-01, time/batch = 18.6202s	
27300/30300 (epoch 45.050), train_loss = 0.90214710, grad/param norm = 1.8080e-01, time/batch = 18.8897s	
27301/30300 (epoch 45.051), train_loss = 1.01415674, grad/param norm = 1.9640e-01, time/batch = 18.4285s	
27302/30300 (epoch 45.053), train_loss = 0.88969607, grad/param norm = 2.6127e-01, time/batch = 18.6951s	
27303/30300 (epoch 45.054), train_loss = 1.04152798, grad/param norm = 1.8974e-01, time/batch = 19.2214s	
27304/30300 (epoch 45.056), train_loss = 0.92013909, grad/param norm = 1.7706e-01, time/batch = 19.0669s	
27305/30300 (epoch 45.058), train_loss = 0.95568668, grad/param norm = 1.7227e-01, time/batch = 19.4274s	
27306/30300 (epoch 45.059), train_loss = 0.97121907, grad/param norm = 2.2313e-01, time/batch = 19.0548s	
27307/30300 (epoch 45.061), train_loss = 1.03472643, grad/param norm = 1.8345e-01, time/batch = 19.1236s	
27308/30300 (epoch 45.063), train_loss = 0.89246584, grad/param norm = 2.1513e-01, time/batch = 19.1195s	
27309/30300 (epoch 45.064), train_loss = 0.97154790, grad/param norm = 1.8341e-01, time/batch = 17.9497s	
27310/30300 (epoch 45.066), train_loss = 0.98701714, grad/param norm = 1.6320e-01, time/batch = 19.3072s	
27311/30300 (epoch 45.068), train_loss = 0.93426927, grad/param norm = 1.7467e-01, time/batch = 18.3657s	
27312/30300 (epoch 45.069), train_loss = 1.03021582, grad/param norm = 1.7716e-01, time/batch = 20.0570s	
27313/30300 (epoch 45.071), train_loss = 1.01061486, grad/param norm = 1.7697e-01, time/batch = 19.9652s	
27314/30300 (epoch 45.073), train_loss = 0.92224454, grad/param norm = 1.9629e-01, time/batch = 18.1973s	
27315/30300 (epoch 45.074), train_loss = 0.95331696, grad/param norm = 1.5904e-01, time/batch = 19.9654s	
27316/30300 (epoch 45.076), train_loss = 0.97349958, grad/param norm = 1.7904e-01, time/batch = 19.6452s	
27317/30300 (epoch 45.078), train_loss = 0.91262576, grad/param norm = 1.6954e-01, time/batch = 17.8785s	
27318/30300 (epoch 45.079), train_loss = 0.95373568, grad/param norm = 1.6690e-01, time/batch = 19.0487s	
27319/30300 (epoch 45.081), train_loss = 0.99933441, grad/param norm = 1.8156e-01, time/batch = 19.2106s	
27320/30300 (epoch 45.083), train_loss = 1.04892558, grad/param norm = 2.3215e-01, time/batch = 18.7021s	
27321/30300 (epoch 45.084), train_loss = 0.94826031, grad/param norm = 1.8552e-01, time/batch = 18.6802s	
27322/30300 (epoch 45.086), train_loss = 0.92587118, grad/param norm = 1.7029e-01, time/batch = 19.3011s	
27323/30300 (epoch 45.087), train_loss = 0.92986644, grad/param norm = 1.5862e-01, time/batch = 19.8017s	
27324/30300 (epoch 45.089), train_loss = 0.90581392, grad/param norm = 1.6402e-01, time/batch = 18.4326s	
27325/30300 (epoch 45.091), train_loss = 1.02764839, grad/param norm = 1.7948e-01, time/batch = 19.2256s	
27326/30300 (epoch 45.092), train_loss = 1.05698651, grad/param norm = 1.6915e-01, time/batch = 18.2148s	
27327/30300 (epoch 45.094), train_loss = 1.06977686, grad/param norm = 1.8288e-01, time/batch = 18.7877s	
27328/30300 (epoch 45.096), train_loss = 1.10081496, grad/param norm = 2.0634e-01, time/batch = 18.7984s	
27329/30300 (epoch 45.097), train_loss = 0.95073592, grad/param norm = 1.9083e-01, time/batch = 19.3039s	
27330/30300 (epoch 45.099), train_loss = 1.03607222, grad/param norm = 1.8029e-01, time/batch = 17.7900s	
27331/30300 (epoch 45.101), train_loss = 1.08949561, grad/param norm = 1.9580e-01, time/batch = 19.7045s	
27332/30300 (epoch 45.102), train_loss = 0.91893103, grad/param norm = 1.8370e-01, time/batch = 18.7913s	
27333/30300 (epoch 45.104), train_loss = 0.96356999, grad/param norm = 2.1042e-01, time/batch = 18.0050s	
27334/30300 (epoch 45.106), train_loss = 0.89684524, grad/param norm = 1.7517e-01, time/batch = 18.8915s	
27335/30300 (epoch 45.107), train_loss = 1.03837562, grad/param norm = 1.7065e-01, time/batch = 19.1220s	
27336/30300 (epoch 45.109), train_loss = 1.06181261, grad/param norm = 2.3473e-01, time/batch = 18.8713s	
27337/30300 (epoch 45.111), train_loss = 1.04528884, grad/param norm = 2.4880e-01, time/batch = 19.3950s	
27338/30300 (epoch 45.112), train_loss = 1.11024922, grad/param norm = 2.1194e-01, time/batch = 19.3769s	
27339/30300 (epoch 45.114), train_loss = 0.93664550, grad/param norm = 1.6214e-01, time/batch = 18.9557s	
27340/30300 (epoch 45.116), train_loss = 1.02951608, grad/param norm = 2.2873e-01, time/batch = 18.8509s	
27341/30300 (epoch 45.117), train_loss = 1.08269443, grad/param norm = 1.7077e-01, time/batch = 18.4536s	
27342/30300 (epoch 45.119), train_loss = 0.88096988, grad/param norm = 1.8948e-01, time/batch = 18.7785s	
27343/30300 (epoch 45.120), train_loss = 0.95981998, grad/param norm = 1.8811e-01, time/batch = 17.6998s	
27344/30300 (epoch 45.122), train_loss = 1.08335795, grad/param norm = 2.1024e-01, time/batch = 19.7881s	
27345/30300 (epoch 45.124), train_loss = 1.14448430, grad/param norm = 1.9649e-01, time/batch = 18.6349s	
27346/30300 (epoch 45.125), train_loss = 0.91049123, grad/param norm = 2.2388e-01, time/batch = 17.6958s	
27347/30300 (epoch 45.127), train_loss = 1.00937144, grad/param norm = 2.4403e-01, time/batch = 20.1414s	
27348/30300 (epoch 45.129), train_loss = 1.04976427, grad/param norm = 1.8997e-01, time/batch = 19.0487s	
27349/30300 (epoch 45.130), train_loss = 1.12262069, grad/param norm = 1.9754e-01, time/batch = 18.2760s	
27350/30300 (epoch 45.132), train_loss = 1.10575240, grad/param norm = 1.8646e-01, time/batch = 19.0481s	
27351/30300 (epoch 45.134), train_loss = 0.91579348, grad/param norm = 2.0949e-01, time/batch = 19.7878s	
27352/30300 (epoch 45.135), train_loss = 0.93326441, grad/param norm = 2.1764e-01, time/batch = 17.3745s	
27353/30300 (epoch 45.137), train_loss = 0.99963226, grad/param norm = 2.2781e-01, time/batch = 18.5582s	
27354/30300 (epoch 45.139), train_loss = 0.92345906, grad/param norm = 2.3370e-01, time/batch = 19.7970s	
27355/30300 (epoch 45.140), train_loss = 1.01446317, grad/param norm = 4.4196e-01, time/batch = 17.2686s	
27356/30300 (epoch 45.142), train_loss = 1.06121648, grad/param norm = 2.6957e-01, time/batch = 19.7125s	
27357/30300 (epoch 45.144), train_loss = 0.93829667, grad/param norm = 2.4030e-01, time/batch = 19.6269s	
27358/30300 (epoch 45.145), train_loss = 1.03744739, grad/param norm = 2.0797e-01, time/batch = 18.9689s	
27359/30300 (epoch 45.147), train_loss = 0.95864674, grad/param norm = 1.8947e-01, time/batch = 18.8869s	
27360/30300 (epoch 45.149), train_loss = 1.04259553, grad/param norm = 1.8392e-01, time/batch = 17.4536s	
27361/30300 (epoch 45.150), train_loss = 0.96441170, grad/param norm = 2.2670e-01, time/batch = 17.7897s	
27362/30300 (epoch 45.152), train_loss = 0.90102381, grad/param norm = 2.2640e-01, time/batch = 18.5397s	
27363/30300 (epoch 45.153), train_loss = 1.01062863, grad/param norm = 2.0583e-01, time/batch = 19.7941s	
27364/30300 (epoch 45.155), train_loss = 0.86804785, grad/param norm = 1.7816e-01, time/batch = 18.5538s	
27365/30300 (epoch 45.157), train_loss = 0.91571745, grad/param norm = 1.8885e-01, time/batch = 19.0347s	
27366/30300 (epoch 45.158), train_loss = 1.01315614, grad/param norm = 2.0814e-01, time/batch = 18.0592s	
27367/30300 (epoch 45.160), train_loss = 0.91481285, grad/param norm = 1.8773e-01, time/batch = 19.7982s	
27368/30300 (epoch 45.162), train_loss = 0.97294357, grad/param norm = 1.7812e-01, time/batch = 18.5412s	
27369/30300 (epoch 45.163), train_loss = 0.99328535, grad/param norm = 2.1053e-01, time/batch = 19.6375s	
27370/30300 (epoch 45.165), train_loss = 1.08829505, grad/param norm = 1.9025e-01, time/batch = 18.4713s	
27371/30300 (epoch 45.167), train_loss = 0.99509772, grad/param norm = 1.8711e-01, time/batch = 17.7033s	
27372/30300 (epoch 45.168), train_loss = 1.03185816, grad/param norm = 1.8668e-01, time/batch = 18.6153s	
27373/30300 (epoch 45.170), train_loss = 1.02644913, grad/param norm = 2.0277e-01, time/batch = 18.8962s	
27374/30300 (epoch 45.172), train_loss = 0.99355955, grad/param norm = 1.8453e-01, time/batch = 18.6400s	
27375/30300 (epoch 45.173), train_loss = 0.95074016, grad/param norm = 3.7392e-01, time/batch = 19.2082s	
27376/30300 (epoch 45.175), train_loss = 1.01601569, grad/param norm = 1.8114e-01, time/batch = 19.7237s	
27377/30300 (epoch 45.177), train_loss = 1.08268551, grad/param norm = 2.2057e-01, time/batch = 17.8874s	
27378/30300 (epoch 45.178), train_loss = 0.82435310, grad/param norm = 1.5690e-01, time/batch = 17.9523s	
27379/30300 (epoch 45.180), train_loss = 0.97618264, grad/param norm = 1.7337e-01, time/batch = 19.2977s	
27380/30300 (epoch 45.182), train_loss = 1.00691689, grad/param norm = 1.9348e-01, time/batch = 18.7184s	
27381/30300 (epoch 45.183), train_loss = 0.93696404, grad/param norm = 2.0113e-01, time/batch = 19.0431s	
27382/30300 (epoch 45.185), train_loss = 1.10792015, grad/param norm = 2.1383e-01, time/batch = 17.1892s	
27383/30300 (epoch 45.186), train_loss = 1.19883690, grad/param norm = 2.5031e-01, time/batch = 19.2988s	
27384/30300 (epoch 45.188), train_loss = 1.05060330, grad/param norm = 2.0830e-01, time/batch = 18.5332s	
27385/30300 (epoch 45.190), train_loss = 0.98824873, grad/param norm = 1.8354e-01, time/batch = 18.2769s	
27386/30300 (epoch 45.191), train_loss = 1.04596555, grad/param norm = 1.8964e-01, time/batch = 19.2226s	
27387/30300 (epoch 45.193), train_loss = 0.89737320, grad/param norm = 1.8025e-01, time/batch = 18.6400s	
27388/30300 (epoch 45.195), train_loss = 0.95422326, grad/param norm = 1.9272e-01, time/batch = 18.1170s	
27389/30300 (epoch 45.196), train_loss = 1.02647324, grad/param norm = 1.6334e-01, time/batch = 18.8026s	
27390/30300 (epoch 45.198), train_loss = 0.85195347, grad/param norm = 2.0188e-01, time/batch = 18.5426s	
27391/30300 (epoch 45.200), train_loss = 0.96013183, grad/param norm = 1.7843e-01, time/batch = 19.1245s	
27392/30300 (epoch 45.201), train_loss = 1.08122058, grad/param norm = 2.5525e-01, time/batch = 19.4767s	
27393/30300 (epoch 45.203), train_loss = 0.99163808, grad/param norm = 1.8176e-01, time/batch = 18.2195s	
27394/30300 (epoch 45.205), train_loss = 1.16440921, grad/param norm = 2.3708e-01, time/batch = 15.6274s	
27395/30300 (epoch 45.206), train_loss = 1.07721586, grad/param norm = 2.0948e-01, time/batch = 19.9607s	
27396/30300 (epoch 45.208), train_loss = 1.05494224, grad/param norm = 2.6405e-01, time/batch = 19.2132s	
27397/30300 (epoch 45.210), train_loss = 1.07646913, grad/param norm = 1.7139e-01, time/batch = 18.9355s	
27398/30300 (epoch 45.211), train_loss = 1.11484337, grad/param norm = 1.9297e-01, time/batch = 17.0523s	
27399/30300 (epoch 45.213), train_loss = 1.00973682, grad/param norm = 1.5608e-01, time/batch = 19.4604s	
27400/30300 (epoch 45.215), train_loss = 0.92268314, grad/param norm = 2.0958e-01, time/batch = 17.3651s	
27401/30300 (epoch 45.216), train_loss = 0.94940483, grad/param norm = 1.8206e-01, time/batch = 17.8534s	
27402/30300 (epoch 45.218), train_loss = 0.91135422, grad/param norm = 1.8181e-01, time/batch = 19.7236s	
27403/30300 (epoch 45.219), train_loss = 0.86342962, grad/param norm = 1.6711e-01, time/batch = 18.7128s	
27404/30300 (epoch 45.221), train_loss = 0.83914144, grad/param norm = 1.5631e-01, time/batch = 19.1068s	
27405/30300 (epoch 45.223), train_loss = 1.00029125, grad/param norm = 2.1085e-01, time/batch = 19.1474s	
27406/30300 (epoch 45.224), train_loss = 0.82564198, grad/param norm = 1.8953e-01, time/batch = 18.7094s	
27407/30300 (epoch 45.226), train_loss = 1.05691126, grad/param norm = 2.2209e-01, time/batch = 17.1110s	
27408/30300 (epoch 45.228), train_loss = 1.11952538, grad/param norm = 2.0851e-01, time/batch = 19.2249s	
27409/30300 (epoch 45.229), train_loss = 0.98678629, grad/param norm = 1.8138e-01, time/batch = 19.0542s	
27410/30300 (epoch 45.231), train_loss = 1.06093096, grad/param norm = 1.9049e-01, time/batch = 19.0454s	
27411/30300 (epoch 45.233), train_loss = 1.04379464, grad/param norm = 1.5827e-01, time/batch = 19.3788s	
27412/30300 (epoch 45.234), train_loss = 1.06973297, grad/param norm = 2.2478e-01, time/batch = 18.1487s	
27413/30300 (epoch 45.236), train_loss = 1.04063498, grad/param norm = 1.6609e-01, time/batch = 18.7019s	
27414/30300 (epoch 45.238), train_loss = 0.99792574, grad/param norm = 2.3438e-01, time/batch = 19.1321s	
27415/30300 (epoch 45.239), train_loss = 0.93526039, grad/param norm = 1.9475e-01, time/batch = 19.7897s	
27416/30300 (epoch 45.241), train_loss = 1.01961065, grad/param norm = 1.8845e-01, time/batch = 18.2854s	
27417/30300 (epoch 45.243), train_loss = 1.04255949, grad/param norm = 1.9057e-01, time/batch = 19.6304s	
27418/30300 (epoch 45.244), train_loss = 1.18595928, grad/param norm = 1.8796e-01, time/batch = 18.0346s	
27419/30300 (epoch 45.246), train_loss = 1.04847801, grad/param norm = 1.8621e-01, time/batch = 18.1320s	
27420/30300 (epoch 45.248), train_loss = 0.99316844, grad/param norm = 1.6621e-01, time/batch = 19.1362s	
27421/30300 (epoch 45.249), train_loss = 0.89557508, grad/param norm = 1.9385e-01, time/batch = 18.5451s	
27422/30300 (epoch 45.251), train_loss = 0.92597818, grad/param norm = 1.9029e-01, time/batch = 18.4447s	
27423/30300 (epoch 45.252), train_loss = 1.08286644, grad/param norm = 1.9325e-01, time/batch = 19.5496s	
27424/30300 (epoch 45.254), train_loss = 1.06764010, grad/param norm = 1.9888e-01, time/batch = 19.7170s	
27425/30300 (epoch 45.256), train_loss = 1.03234685, grad/param norm = 1.8078e-01, time/batch = 17.7058s	
27426/30300 (epoch 45.257), train_loss = 1.07237671, grad/param norm = 2.4697e-01, time/batch = 19.1090s	
27427/30300 (epoch 45.259), train_loss = 0.97952889, grad/param norm = 1.8593e-01, time/batch = 17.2149s	
27428/30300 (epoch 45.261), train_loss = 1.13911870, grad/param norm = 2.0049e-01, time/batch = 19.3767s	
27429/30300 (epoch 45.262), train_loss = 0.92289457, grad/param norm = 1.6879e-01, time/batch = 18.7103s	
27430/30300 (epoch 45.264), train_loss = 1.00786949, grad/param norm = 1.9420e-01, time/batch = 19.4598s	
27431/30300 (epoch 45.266), train_loss = 1.00257402, grad/param norm = 1.7663e-01, time/batch = 19.7947s	
27432/30300 (epoch 45.267), train_loss = 1.13044671, grad/param norm = 2.1189e-01, time/batch = 19.2785s	
27433/30300 (epoch 45.269), train_loss = 1.02631210, grad/param norm = 1.8210e-01, time/batch = 19.0616s	
27434/30300 (epoch 45.271), train_loss = 1.02297473, grad/param norm = 1.8393e-01, time/batch = 19.8114s	
27435/30300 (epoch 45.272), train_loss = 1.00428468, grad/param norm = 1.9446e-01, time/batch = 18.6265s	
27436/30300 (epoch 45.274), train_loss = 1.05104988, grad/param norm = 1.7714e-01, time/batch = 19.3832s	
27437/30300 (epoch 45.276), train_loss = 1.01733495, grad/param norm = 2.1978e-01, time/batch = 20.0511s	
27438/30300 (epoch 45.277), train_loss = 0.91732420, grad/param norm = 1.8097e-01, time/batch = 17.3530s	
27439/30300 (epoch 45.279), train_loss = 1.00149788, grad/param norm = 1.9464e-01, time/batch = 19.0483s	
27440/30300 (epoch 45.281), train_loss = 1.10856834, grad/param norm = 2.7891e-01, time/batch = 17.9489s	
27441/30300 (epoch 45.282), train_loss = 1.04378458, grad/param norm = 1.9045e-01, time/batch = 18.4656s	
27442/30300 (epoch 45.284), train_loss = 1.08095215, grad/param norm = 2.1597e-01, time/batch = 18.8003s	
27443/30300 (epoch 45.285), train_loss = 1.05724178, grad/param norm = 1.6420e-01, time/batch = 18.7710s	
27444/30300 (epoch 45.287), train_loss = 1.01308484, grad/param norm = 2.0160e-01, time/batch = 18.5326s	
27445/30300 (epoch 45.289), train_loss = 1.10058723, grad/param norm = 2.0253e-01, time/batch = 18.8043s	
27446/30300 (epoch 45.290), train_loss = 0.80764666, grad/param norm = 1.9075e-01, time/batch = 18.8775s	
27447/30300 (epoch 45.292), train_loss = 0.90730697, grad/param norm = 1.8836e-01, time/batch = 19.0494s	
27448/30300 (epoch 45.294), train_loss = 1.03823205, grad/param norm = 2.0133e-01, time/batch = 18.6222s	
27449/30300 (epoch 45.295), train_loss = 0.95455297, grad/param norm = 1.6745e-01, time/batch = 19.2268s	
27450/30300 (epoch 45.297), train_loss = 0.96734054, grad/param norm = 1.6281e-01, time/batch = 19.0487s	
27451/30300 (epoch 45.299), train_loss = 1.00775248, grad/param norm = 2.6116e-01, time/batch = 18.5430s	
27452/30300 (epoch 45.300), train_loss = 0.93559389, grad/param norm = 1.8769e-01, time/batch = 19.7152s	
27453/30300 (epoch 45.302), train_loss = 1.07639974, grad/param norm = 1.9055e-01, time/batch = 19.9661s	
27454/30300 (epoch 45.304), train_loss = 0.93724542, grad/param norm = 1.8126e-01, time/batch = 17.5161s	
27455/30300 (epoch 45.305), train_loss = 1.00583959, grad/param norm = 1.7238e-01, time/batch = 19.9572s	
27456/30300 (epoch 45.307), train_loss = 1.07078680, grad/param norm = 1.6702e-01, time/batch = 19.8853s	
27457/30300 (epoch 45.309), train_loss = 1.02429475, grad/param norm = 1.6903e-01, time/batch = 17.7972s	
27458/30300 (epoch 45.310), train_loss = 0.97429042, grad/param norm = 1.7053e-01, time/batch = 17.7064s	
27459/30300 (epoch 45.312), train_loss = 1.12175513, grad/param norm = 1.7430e-01, time/batch = 19.3757s	
27460/30300 (epoch 45.314), train_loss = 0.99810131, grad/param norm = 1.8799e-01, time/batch = 17.9539s	
27461/30300 (epoch 45.315), train_loss = 0.95687480, grad/param norm = 1.9283e-01, time/batch = 18.9444s	
27462/30300 (epoch 45.317), train_loss = 1.02473503, grad/param norm = 1.8090e-01, time/batch = 19.7144s	
27463/30300 (epoch 45.318), train_loss = 1.03405745, grad/param norm = 2.2295e-01, time/batch = 18.1178s	
27464/30300 (epoch 45.320), train_loss = 1.04072886, grad/param norm = 1.9708e-01, time/batch = 19.2971s	
27465/30300 (epoch 45.322), train_loss = 0.93374017, grad/param norm = 1.7077e-01, time/batch = 19.8091s	
27466/30300 (epoch 45.323), train_loss = 1.09593908, grad/param norm = 1.9671e-01, time/batch = 19.2080s	
27467/30300 (epoch 45.325), train_loss = 0.98103181, grad/param norm = 1.8551e-01, time/batch = 18.9648s	
27468/30300 (epoch 45.327), train_loss = 0.98391799, grad/param norm = 1.6400e-01, time/batch = 19.7232s	
27469/30300 (epoch 45.328), train_loss = 1.02865785, grad/param norm = 1.5921e-01, time/batch = 18.1084s	
27470/30300 (epoch 45.330), train_loss = 1.04060297, grad/param norm = 1.8901e-01, time/batch = 18.6394s	
27471/30300 (epoch 45.332), train_loss = 1.08819097, grad/param norm = 2.0430e-01, time/batch = 18.1243s	
27472/30300 (epoch 45.333), train_loss = 0.91528796, grad/param norm = 1.8292e-01, time/batch = 16.9448s	
27473/30300 (epoch 45.335), train_loss = 0.90016775, grad/param norm = 1.7851e-01, time/batch = 19.0290s	
27474/30300 (epoch 45.337), train_loss = 1.10511958, grad/param norm = 1.8124e-01, time/batch = 18.5421s	
27475/30300 (epoch 45.338), train_loss = 0.94798356, grad/param norm = 1.6617e-01, time/batch = 19.8002s	
27476/30300 (epoch 45.340), train_loss = 0.96295805, grad/param norm = 1.8466e-01, time/batch = 17.2959s	
27477/30300 (epoch 45.342), train_loss = 1.07607217, grad/param norm = 1.8105e-01, time/batch = 19.1391s	
27478/30300 (epoch 45.343), train_loss = 1.05195170, grad/param norm = 2.2775e-01, time/batch = 19.4705s	
27479/30300 (epoch 45.345), train_loss = 1.02191741, grad/param norm = 1.6542e-01, time/batch = 27.1912s	
27480/30300 (epoch 45.347), train_loss = 0.91178852, grad/param norm = 1.7048e-01, time/batch = 23.1490s	
27481/30300 (epoch 45.348), train_loss = 0.95567953, grad/param norm = 1.7902e-01, time/batch = 18.2784s	
27482/30300 (epoch 45.350), train_loss = 0.97460824, grad/param norm = 1.8196e-01, time/batch = 18.3540s	
27483/30300 (epoch 45.351), train_loss = 0.98125235, grad/param norm = 1.7873e-01, time/batch = 18.2043s	
27484/30300 (epoch 45.353), train_loss = 0.90275361, grad/param norm = 1.7595e-01, time/batch = 19.6982s	
27485/30300 (epoch 45.355), train_loss = 0.95096847, grad/param norm = 1.7057e-01, time/batch = 18.3770s	
27486/30300 (epoch 45.356), train_loss = 1.04458820, grad/param norm = 1.9809e-01, time/batch = 20.0434s	
27487/30300 (epoch 45.358), train_loss = 1.22751822, grad/param norm = 1.8003e-01, time/batch = 19.1143s	
27488/30300 (epoch 45.360), train_loss = 0.95368420, grad/param norm = 1.9102e-01, time/batch = 18.2827s	
27489/30300 (epoch 45.361), train_loss = 0.98830040, grad/param norm = 1.8722e-01, time/batch = 20.1253s	
27490/30300 (epoch 45.363), train_loss = 1.02046853, grad/param norm = 1.8458e-01, time/batch = 19.2015s	
27491/30300 (epoch 45.365), train_loss = 0.84319718, grad/param norm = 1.7575e-01, time/batch = 17.2941s	
27492/30300 (epoch 45.366), train_loss = 0.96306360, grad/param norm = 1.6024e-01, time/batch = 19.5398s	
27493/30300 (epoch 45.368), train_loss = 0.87439490, grad/param norm = 1.8876e-01, time/batch = 19.2953s	
27494/30300 (epoch 45.370), train_loss = 0.90483918, grad/param norm = 1.7355e-01, time/batch = 17.6875s	
27495/30300 (epoch 45.371), train_loss = 1.05828750, grad/param norm = 1.7546e-01, time/batch = 18.7126s	
27496/30300 (epoch 45.373), train_loss = 0.92628400, grad/param norm = 1.5355e-01, time/batch = 19.2169s	
27497/30300 (epoch 45.375), train_loss = 0.92902889, grad/param norm = 1.7054e-01, time/batch = 17.8416s	
27498/30300 (epoch 45.376), train_loss = 0.93094906, grad/param norm = 1.5433e-01, time/batch = 19.0432s	
27499/30300 (epoch 45.378), train_loss = 0.90699085, grad/param norm = 2.1098e-01, time/batch = 19.3018s	
27500/30300 (epoch 45.380), train_loss = 1.10068478, grad/param norm = 1.9291e-01, time/batch = 20.1361s	
27501/30300 (epoch 45.381), train_loss = 0.83916863, grad/param norm = 1.9460e-01, time/batch = 19.0265s	
27502/30300 (epoch 45.383), train_loss = 0.89120725, grad/param norm = 1.9032e-01, time/batch = 19.6160s	
27503/30300 (epoch 45.384), train_loss = 1.02917262, grad/param norm = 2.1296e-01, time/batch = 19.3833s	
27504/30300 (epoch 45.386), train_loss = 0.89068723, grad/param norm = 1.7552e-01, time/batch = 17.5271s	
27505/30300 (epoch 45.388), train_loss = 0.89109633, grad/param norm = 1.8759e-01, time/batch = 19.6325s	
27506/30300 (epoch 45.389), train_loss = 0.96939206, grad/param norm = 1.8054e-01, time/batch = 19.3706s	
27507/30300 (epoch 45.391), train_loss = 1.02152792, grad/param norm = 1.8040e-01, time/batch = 18.7806s	
27508/30300 (epoch 45.393), train_loss = 0.87777367, grad/param norm = 1.5148e-01, time/batch = 18.2901s	
27509/30300 (epoch 45.394), train_loss = 1.00261412, grad/param norm = 1.5413e-01, time/batch = 18.8744s	
27510/30300 (epoch 45.396), train_loss = 1.11765790, grad/param norm = 1.6857e-01, time/batch = 16.8581s	
27511/30300 (epoch 45.398), train_loss = 0.96798143, grad/param norm = 1.8945e-01, time/batch = 18.3584s	
27512/30300 (epoch 45.399), train_loss = 0.88807630, grad/param norm = 1.8716e-01, time/batch = 18.2211s	
27513/30300 (epoch 45.401), train_loss = 0.99474686, grad/param norm = 2.1652e-01, time/batch = 19.3796s	
27514/30300 (epoch 45.403), train_loss = 0.99145314, grad/param norm = 2.1870e-01, time/batch = 18.6384s	
27515/30300 (epoch 45.404), train_loss = 0.93049184, grad/param norm = 1.9402e-01, time/batch = 19.7051s	
27516/30300 (epoch 45.406), train_loss = 0.98744747, grad/param norm = 1.6683e-01, time/batch = 17.6115s	
27517/30300 (epoch 45.408), train_loss = 0.85576543, grad/param norm = 1.5906e-01, time/batch = 19.2000s	
27518/30300 (epoch 45.409), train_loss = 0.88572926, grad/param norm = 1.9642e-01, time/batch = 20.0530s	
27519/30300 (epoch 45.411), train_loss = 0.92244001, grad/param norm = 1.5759e-01, time/batch = 19.0651s	
27520/30300 (epoch 45.413), train_loss = 0.82361862, grad/param norm = 1.8585e-01, time/batch = 19.2786s	
27521/30300 (epoch 45.414), train_loss = 1.01732968, grad/param norm = 1.7253e-01, time/batch = 19.4544s	
27522/30300 (epoch 45.416), train_loss = 0.92025557, grad/param norm = 1.7299e-01, time/batch = 18.7142s	
27523/30300 (epoch 45.417), train_loss = 0.90875219, grad/param norm = 2.0567e-01, time/batch = 19.0406s	
27524/30300 (epoch 45.419), train_loss = 0.87346094, grad/param norm = 1.5415e-01, time/batch = 19.7213s	
27525/30300 (epoch 45.421), train_loss = 0.94017366, grad/param norm = 2.1878e-01, time/batch = 19.2970s	
27526/30300 (epoch 45.422), train_loss = 0.98178861, grad/param norm = 1.7676e-01, time/batch = 11.9276s	
27527/30300 (epoch 45.424), train_loss = 0.98720677, grad/param norm = 1.7612e-01, time/batch = 0.6825s	
27528/30300 (epoch 45.426), train_loss = 0.97777043, grad/param norm = 2.3780e-01, time/batch = 0.6855s	
27529/30300 (epoch 45.427), train_loss = 0.94550718, grad/param norm = 2.1924e-01, time/batch = 0.7028s	
27530/30300 (epoch 45.429), train_loss = 0.96459229, grad/param norm = 1.6613e-01, time/batch = 0.7225s	
27531/30300 (epoch 45.431), train_loss = 1.00773525, grad/param norm = 2.2347e-01, time/batch = 0.6866s	
27532/30300 (epoch 45.432), train_loss = 0.99060051, grad/param norm = 1.7323e-01, time/batch = 0.6821s	
27533/30300 (epoch 45.434), train_loss = 0.86520713, grad/param norm = 1.6989e-01, time/batch = 0.7515s	
27534/30300 (epoch 45.436), train_loss = 1.06270941, grad/param norm = 1.8170e-01, time/batch = 1.0019s	
27535/30300 (epoch 45.437), train_loss = 0.89161374, grad/param norm = 1.6593e-01, time/batch = 1.0006s	
27536/30300 (epoch 45.439), train_loss = 0.93209236, grad/param norm = 1.6489e-01, time/batch = 1.0029s	
27537/30300 (epoch 45.441), train_loss = 0.97129487, grad/param norm = 1.6545e-01, time/batch = 1.0043s	
27538/30300 (epoch 45.442), train_loss = 0.91399737, grad/param norm = 1.8218e-01, time/batch = 1.2317s	
27539/30300 (epoch 45.444), train_loss = 0.81120227, grad/param norm = 1.5817e-01, time/batch = 1.8965s	
27540/30300 (epoch 45.446), train_loss = 0.93605581, grad/param norm = 1.6755e-01, time/batch = 1.9549s	
27541/30300 (epoch 45.447), train_loss = 0.96458388, grad/param norm = 1.7953e-01, time/batch = 14.8229s	
27542/30300 (epoch 45.449), train_loss = 0.91739905, grad/param norm = 1.6309e-01, time/batch = 19.8917s	
27543/30300 (epoch 45.450), train_loss = 1.00147610, grad/param norm = 1.6522e-01, time/batch = 17.7732s	
27544/30300 (epoch 45.452), train_loss = 1.09033656, grad/param norm = 1.8329e-01, time/batch = 18.8021s	
27545/30300 (epoch 45.454), train_loss = 1.01750145, grad/param norm = 1.6795e-01, time/batch = 19.7214s	
27546/30300 (epoch 45.455), train_loss = 0.98818434, grad/param norm = 2.1331e-01, time/batch = 17.0271s	
27547/30300 (epoch 45.457), train_loss = 0.95313464, grad/param norm = 1.5220e-01, time/batch = 19.0531s	
27548/30300 (epoch 45.459), train_loss = 1.00772058, grad/param norm = 1.8578e-01, time/batch = 19.5498s	
27549/30300 (epoch 45.460), train_loss = 1.06978133, grad/param norm = 1.8881e-01, time/batch = 18.0278s	
27550/30300 (epoch 45.462), train_loss = 1.05163503, grad/param norm = 1.8793e-01, time/batch = 19.4566s	
27551/30300 (epoch 45.464), train_loss = 0.80642204, grad/param norm = 1.8985e-01, time/batch = 18.7213s	
27552/30300 (epoch 45.465), train_loss = 0.83770627, grad/param norm = 1.7323e-01, time/batch = 18.6952s	
27553/30300 (epoch 45.467), train_loss = 0.82941320, grad/param norm = 1.7199e-01, time/batch = 18.9728s	
27554/30300 (epoch 45.469), train_loss = 0.92032200, grad/param norm = 2.5238e-01, time/batch = 19.7864s	
27555/30300 (epoch 45.470), train_loss = 0.92322531, grad/param norm = 1.7514e-01, time/batch = 18.8748s	
27556/30300 (epoch 45.472), train_loss = 0.93171350, grad/param norm = 1.5493e-01, time/batch = 18.2836s	
27557/30300 (epoch 45.474), train_loss = 0.90629924, grad/param norm = 1.7088e-01, time/batch = 19.1195s	
27558/30300 (epoch 45.475), train_loss = 0.90412541, grad/param norm = 1.5804e-01, time/batch = 19.4541s	
27559/30300 (epoch 45.477), train_loss = 0.94619895, grad/param norm = 1.7371e-01, time/batch = 19.1061s	
27560/30300 (epoch 45.479), train_loss = 0.92139970, grad/param norm = 1.7374e-01, time/batch = 18.7978s	
27561/30300 (epoch 45.480), train_loss = 0.98666444, grad/param norm = 1.6578e-01, time/batch = 19.8011s	
27562/30300 (epoch 45.482), train_loss = 1.02326529, grad/param norm = 1.6821e-01, time/batch = 19.0333s	
27563/30300 (epoch 45.483), train_loss = 0.96093777, grad/param norm = 1.8192e-01, time/batch = 18.1417s	
27564/30300 (epoch 45.485), train_loss = 0.98626007, grad/param norm = 1.7788e-01, time/batch = 19.8008s	
27565/30300 (epoch 45.487), train_loss = 1.02700991, grad/param norm = 1.8048e-01, time/batch = 17.7176s	
27566/30300 (epoch 45.488), train_loss = 1.10179518, grad/param norm = 1.5351e-01, time/batch = 19.3051s	
27567/30300 (epoch 45.490), train_loss = 0.85734944, grad/param norm = 1.8044e-01, time/batch = 18.3002s	
27568/30300 (epoch 45.492), train_loss = 0.93329912, grad/param norm = 1.6156e-01, time/batch = 18.1364s	
27569/30300 (epoch 45.493), train_loss = 0.98238709, grad/param norm = 1.9948e-01, time/batch = 18.2936s	
27570/30300 (epoch 45.495), train_loss = 0.96413866, grad/param norm = 1.5685e-01, time/batch = 17.9633s	
27571/30300 (epoch 45.497), train_loss = 1.00111479, grad/param norm = 1.7529e-01, time/batch = 18.2101s	
27572/30300 (epoch 45.498), train_loss = 1.04188640, grad/param norm = 2.0611e-01, time/batch = 17.2837s	
27573/30300 (epoch 45.500), train_loss = 0.91532800, grad/param norm = 2.0556e-01, time/batch = 19.2044s	
27574/30300 (epoch 45.502), train_loss = 0.98268561, grad/param norm = 2.0091e-01, time/batch = 18.9462s	
27575/30300 (epoch 45.503), train_loss = 1.06844545, grad/param norm = 1.8081e-01, time/batch = 18.8742s	
27576/30300 (epoch 45.505), train_loss = 0.85976353, grad/param norm = 1.6840e-01, time/batch = 19.5442s	
27577/30300 (epoch 45.507), train_loss = 0.88771067, grad/param norm = 2.5704e-01, time/batch = 19.9649s	
27578/30300 (epoch 45.508), train_loss = 0.93366827, grad/param norm = 2.8437e-01, time/batch = 18.0382s	
27579/30300 (epoch 45.510), train_loss = 1.05549643, grad/param norm = 2.2892e-01, time/batch = 18.9599s	
27580/30300 (epoch 45.512), train_loss = 0.91959581, grad/param norm = 1.6533e-01, time/batch = 19.7897s	
27581/30300 (epoch 45.513), train_loss = 0.98922596, grad/param norm = 1.9116e-01, time/batch = 18.3795s	
27582/30300 (epoch 45.515), train_loss = 0.97052611, grad/param norm = 1.7411e-01, time/batch = 19.4594s	
27583/30300 (epoch 45.517), train_loss = 0.78964128, grad/param norm = 1.5782e-01, time/batch = 17.8634s	
27584/30300 (epoch 45.518), train_loss = 1.05976680, grad/param norm = 2.0173e-01, time/batch = 18.4704s	
27585/30300 (epoch 45.520), train_loss = 0.94557526, grad/param norm = 1.7441e-01, time/batch = 18.8919s	
27586/30300 (epoch 45.521), train_loss = 0.89528007, grad/param norm = 3.1571e-01, time/batch = 19.2085s	
27587/30300 (epoch 45.523), train_loss = 1.07660147, grad/param norm = 2.2586e-01, time/batch = 18.4522s	
27588/30300 (epoch 45.525), train_loss = 0.90051416, grad/param norm = 1.8453e-01, time/batch = 19.2963s	
27589/30300 (epoch 45.526), train_loss = 0.99500415, grad/param norm = 1.7144e-01, time/batch = 18.3657s	
27590/30300 (epoch 45.528), train_loss = 0.86240702, grad/param norm = 1.7278e-01, time/batch = 19.2099s	
27591/30300 (epoch 45.530), train_loss = 0.84531229, grad/param norm = 1.8434e-01, time/batch = 18.7147s	
27592/30300 (epoch 45.531), train_loss = 0.95360759, grad/param norm = 1.9279e-01, time/batch = 19.3000s	
27593/30300 (epoch 45.533), train_loss = 0.96067016, grad/param norm = 1.9300e-01, time/batch = 19.2146s	
27594/30300 (epoch 45.535), train_loss = 0.97067198, grad/param norm = 1.5860e-01, time/batch = 18.7005s	
27595/30300 (epoch 45.536), train_loss = 0.97744581, grad/param norm = 1.8639e-01, time/batch = 16.5498s	
27596/30300 (epoch 45.538), train_loss = 0.85691267, grad/param norm = 1.8482e-01, time/batch = 20.0454s	
27597/30300 (epoch 45.540), train_loss = 0.92923551, grad/param norm = 2.0786e-01, time/batch = 17.8784s	
27598/30300 (epoch 45.541), train_loss = 0.95413275, grad/param norm = 1.8334e-01, time/batch = 19.5426s	
27599/30300 (epoch 45.543), train_loss = 0.94857537, grad/param norm = 1.6438e-01, time/batch = 18.0468s	
27600/30300 (epoch 45.545), train_loss = 1.02205539, grad/param norm = 2.3247e-01, time/batch = 18.2832s	
27601/30300 (epoch 45.546), train_loss = 1.11653588, grad/param norm = 2.0951e-01, time/batch = 20.0522s	
27602/30300 (epoch 45.548), train_loss = 0.92227593, grad/param norm = 1.5341e-01, time/batch = 18.5550s	
27603/30300 (epoch 45.550), train_loss = 1.01218765, grad/param norm = 2.2047e-01, time/batch = 18.2058s	
27604/30300 (epoch 45.551), train_loss = 0.89068901, grad/param norm = 1.7348e-01, time/batch = 17.7066s	
27605/30300 (epoch 45.553), train_loss = 0.94483557, grad/param norm = 1.7841e-01, time/batch = 19.6332s	
27606/30300 (epoch 45.554), train_loss = 0.96771124, grad/param norm = 1.8518e-01, time/batch = 19.1254s	
27607/30300 (epoch 45.556), train_loss = 1.01724305, grad/param norm = 1.7296e-01, time/batch = 19.6212s	
27608/30300 (epoch 45.558), train_loss = 1.08242834, grad/param norm = 2.2902e-01, time/batch = 18.0237s	
27609/30300 (epoch 45.559), train_loss = 0.99971503, grad/param norm = 2.2573e-01, time/batch = 19.2077s	
27610/30300 (epoch 45.561), train_loss = 0.78140556, grad/param norm = 1.8140e-01, time/batch = 19.1291s	
27611/30300 (epoch 45.563), train_loss = 0.85018101, grad/param norm = 1.8312e-01, time/batch = 19.7159s	
27612/30300 (epoch 45.564), train_loss = 0.92620619, grad/param norm = 1.5704e-01, time/batch = 17.5345s	
27613/30300 (epoch 45.566), train_loss = 0.94739864, grad/param norm = 1.8689e-01, time/batch = 18.7782s	
27614/30300 (epoch 45.568), train_loss = 0.83201699, grad/param norm = 2.0128e-01, time/batch = 20.1936s	
27615/30300 (epoch 45.569), train_loss = 0.98509108, grad/param norm = 1.7147e-01, time/batch = 18.1257s	
27616/30300 (epoch 45.571), train_loss = 0.95657184, grad/param norm = 1.8464e-01, time/batch = 18.2874s	
27617/30300 (epoch 45.573), train_loss = 0.99230083, grad/param norm = 1.7256e-01, time/batch = 18.6980s	
27618/30300 (epoch 45.574), train_loss = 0.99827573, grad/param norm = 1.9015e-01, time/batch = 19.9667s	
27619/30300 (epoch 45.576), train_loss = 0.94830506, grad/param norm = 1.6231e-01, time/batch = 18.8655s	
27620/30300 (epoch 45.578), train_loss = 0.83478672, grad/param norm = 1.7056e-01, time/batch = 19.3846s	
27621/30300 (epoch 45.579), train_loss = 1.02192087, grad/param norm = 1.8069e-01, time/batch = 18.8782s	
27622/30300 (epoch 45.581), train_loss = 1.08080676, grad/param norm = 1.7540e-01, time/batch = 18.4551s	
27623/30300 (epoch 45.583), train_loss = 1.09305557, grad/param norm = 3.4497e-01, time/batch = 18.9688s	
27624/30300 (epoch 45.584), train_loss = 1.08166103, grad/param norm = 1.8523e-01, time/batch = 20.1390s	
27625/30300 (epoch 45.586), train_loss = 0.93269210, grad/param norm = 1.7897e-01, time/batch = 17.7029s	
27626/30300 (epoch 45.587), train_loss = 0.97379491, grad/param norm = 1.9180e-01, time/batch = 19.8628s	
27627/30300 (epoch 45.589), train_loss = 0.90095251, grad/param norm = 1.6877e-01, time/batch = 19.5556s	
27628/30300 (epoch 45.591), train_loss = 1.00871761, grad/param norm = 1.5979e-01, time/batch = 17.4289s	
27629/30300 (epoch 45.592), train_loss = 0.92767651, grad/param norm = 1.5178e-01, time/batch = 19.0436s	
27630/30300 (epoch 45.594), train_loss = 1.02902373, grad/param norm = 1.8081e-01, time/batch = 18.2037s	
27631/30300 (epoch 45.596), train_loss = 0.89677275, grad/param norm = 1.6643e-01, time/batch = 16.2848s	
27632/30300 (epoch 45.597), train_loss = 0.91671327, grad/param norm = 1.8972e-01, time/batch = 18.9495s	
27633/30300 (epoch 45.599), train_loss = 0.81332695, grad/param norm = 1.7069e-01, time/batch = 19.7114s	
27634/30300 (epoch 45.601), train_loss = 0.98551601, grad/param norm = 1.9184e-01, time/batch = 17.9742s	
27635/30300 (epoch 45.602), train_loss = 0.95902207, grad/param norm = 1.4771e-01, time/batch = 18.7916s	
27636/30300 (epoch 45.604), train_loss = 0.88907140, grad/param norm = 1.6732e-01, time/batch = 19.0551s	
27637/30300 (epoch 45.606), train_loss = 0.91244088, grad/param norm = 2.4664e-01, time/batch = 18.7830s	
27638/30300 (epoch 45.607), train_loss = 1.03841931, grad/param norm = 2.1490e-01, time/batch = 19.6990s	
27639/30300 (epoch 45.609), train_loss = 1.12442256, grad/param norm = 1.7703e-01, time/batch = 19.2978s	
27640/30300 (epoch 45.611), train_loss = 0.94597506, grad/param norm = 1.6760e-01, time/batch = 19.4711s	
27641/30300 (epoch 45.612), train_loss = 0.87065530, grad/param norm = 1.7326e-01, time/batch = 18.1188s	
27642/30300 (epoch 45.614), train_loss = 0.96041343, grad/param norm = 1.8281e-01, time/batch = 17.4573s	
27643/30300 (epoch 45.616), train_loss = 0.99354591, grad/param norm = 2.0768e-01, time/batch = 19.4787s	
27644/30300 (epoch 45.617), train_loss = 0.95960598, grad/param norm = 1.9800e-01, time/batch = 18.1288s	
27645/30300 (epoch 45.619), train_loss = 0.79667772, grad/param norm = 1.5884e-01, time/batch = 18.9615s	
27646/30300 (epoch 45.620), train_loss = 1.01359545, grad/param norm = 1.7350e-01, time/batch = 18.2820s	
27647/30300 (epoch 45.622), train_loss = 0.95744952, grad/param norm = 2.1141e-01, time/batch = 18.7161s	
27648/30300 (epoch 45.624), train_loss = 0.94505820, grad/param norm = 1.6857e-01, time/batch = 19.2767s	
27649/30300 (epoch 45.625), train_loss = 0.94875859, grad/param norm = 2.1715e-01, time/batch = 18.7943s	
27650/30300 (epoch 45.627), train_loss = 1.04178327, grad/param norm = 1.9069e-01, time/batch = 19.8812s	
27651/30300 (epoch 45.629), train_loss = 1.07232512, grad/param norm = 1.6651e-01, time/batch = 18.8737s	
27652/30300 (epoch 45.630), train_loss = 0.95527659, grad/param norm = 1.6018e-01, time/batch = 18.7178s	
27653/30300 (epoch 45.632), train_loss = 0.99253526, grad/param norm = 1.8759e-01, time/batch = 19.4729s	
27654/30300 (epoch 45.634), train_loss = 0.88969425, grad/param norm = 1.5815e-01, time/batch = 18.3667s	
27655/30300 (epoch 45.635), train_loss = 0.98961259, grad/param norm = 1.7226e-01, time/batch = 19.6233s	
27656/30300 (epoch 45.637), train_loss = 1.04205919, grad/param norm = 2.0439e-01, time/batch = 19.3164s	
27657/30300 (epoch 45.639), train_loss = 0.95180920, grad/param norm = 1.8433e-01, time/batch = 19.1309s	
27658/30300 (epoch 45.640), train_loss = 1.08300393, grad/param norm = 2.1223e-01, time/batch = 19.0594s	
27659/30300 (epoch 45.642), train_loss = 0.96920675, grad/param norm = 1.8520e-01, time/batch = 18.6362s	
27660/30300 (epoch 45.644), train_loss = 1.05623287, grad/param norm = 1.8168e-01, time/batch = 19.6180s	
27661/30300 (epoch 45.645), train_loss = 0.90504771, grad/param norm = 1.5880e-01, time/batch = 18.5252s	
27662/30300 (epoch 45.647), train_loss = 0.95060763, grad/param norm = 1.7225e-01, time/batch = 19.4507s	
27663/30300 (epoch 45.649), train_loss = 0.96503769, grad/param norm = 2.7826e-01, time/batch = 17.0126s	
27664/30300 (epoch 45.650), train_loss = 0.98565366, grad/param norm = 1.6520e-01, time/batch = 19.4617s	
27665/30300 (epoch 45.652), train_loss = 0.96388681, grad/param norm = 2.2671e-01, time/batch = 19.5543s	
27666/30300 (epoch 45.653), train_loss = 1.11073695, grad/param norm = 1.5590e-01, time/batch = 19.2027s	
27667/30300 (epoch 45.655), train_loss = 0.95385201, grad/param norm = 2.0413e-01, time/batch = 17.9446s	
27668/30300 (epoch 45.657), train_loss = 0.87846770, grad/param norm = 2.1200e-01, time/batch = 18.8002s	
27669/30300 (epoch 45.658), train_loss = 0.94539917, grad/param norm = 1.8038e-01, time/batch = 19.8838s	
27670/30300 (epoch 45.660), train_loss = 0.96815643, grad/param norm = 1.8716e-01, time/batch = 18.2806s	
27671/30300 (epoch 45.662), train_loss = 0.97631976, grad/param norm = 1.8696e-01, time/batch = 19.7992s	
27672/30300 (epoch 45.663), train_loss = 1.03439635, grad/param norm = 1.7812e-01, time/batch = 19.5505s	
27673/30300 (epoch 45.665), train_loss = 0.90285964, grad/param norm = 1.8975e-01, time/batch = 18.1037s	
27674/30300 (epoch 45.667), train_loss = 1.02112231, grad/param norm = 1.7805e-01, time/batch = 19.5546s	
27675/30300 (epoch 45.668), train_loss = 1.05383756, grad/param norm = 1.7499e-01, time/batch = 18.9707s	
27676/30300 (epoch 45.670), train_loss = 1.07970469, grad/param norm = 1.9827e-01, time/batch = 18.2938s	
27677/30300 (epoch 45.672), train_loss = 0.96633357, grad/param norm = 1.6883e-01, time/batch = 19.3020s	
27678/30300 (epoch 45.673), train_loss = 1.03173699, grad/param norm = 1.9848e-01, time/batch = 18.8779s	
27679/30300 (epoch 45.675), train_loss = 0.95731555, grad/param norm = 1.9516e-01, time/batch = 17.0476s	
27680/30300 (epoch 45.677), train_loss = 0.93741702, grad/param norm = 1.8334e-01, time/batch = 19.4595s	
27681/30300 (epoch 45.678), train_loss = 0.92817787, grad/param norm = 1.6748e-01, time/batch = 19.2168s	
27682/30300 (epoch 45.680), train_loss = 0.87210251, grad/param norm = 1.6484e-01, time/batch = 25.2081s	
27683/30300 (epoch 45.682), train_loss = 0.96717641, grad/param norm = 1.7826e-01, time/batch = 26.9569s	
27684/30300 (epoch 45.683), train_loss = 1.04035096, grad/param norm = 1.6580e-01, time/batch = 19.4673s	
27685/30300 (epoch 45.685), train_loss = 1.02567277, grad/param norm = 2.0126e-01, time/batch = 18.7790s	
27686/30300 (epoch 45.686), train_loss = 0.95682187, grad/param norm = 1.7370e-01, time/batch = 19.6339s	
27687/30300 (epoch 45.688), train_loss = 0.96274096, grad/param norm = 1.5618e-01, time/batch = 19.3059s	
27688/30300 (epoch 45.690), train_loss = 0.93422755, grad/param norm = 2.0865e-01, time/batch = 18.4510s	
27689/30300 (epoch 45.691), train_loss = 0.96333494, grad/param norm = 1.7400e-01, time/batch = 19.2978s	
27690/30300 (epoch 45.693), train_loss = 1.24197751, grad/param norm = 2.1776e-01, time/batch = 18.3571s	
27691/30300 (epoch 45.695), train_loss = 1.05163401, grad/param norm = 2.0483e-01, time/batch = 18.5400s	
27692/30300 (epoch 45.696), train_loss = 1.00194450, grad/param norm = 1.9576e-01, time/batch = 18.5352s	
27693/30300 (epoch 45.698), train_loss = 0.93813944, grad/param norm = 1.8620e-01, time/batch = 18.9536s	
27694/30300 (epoch 45.700), train_loss = 0.91759549, grad/param norm = 1.8134e-01, time/batch = 17.6055s	
27695/30300 (epoch 45.701), train_loss = 0.86257086, grad/param norm = 1.8461e-01, time/batch = 17.8711s	
27696/30300 (epoch 45.703), train_loss = 0.96238057, grad/param norm = 1.6000e-01, time/batch = 20.1214s	
27697/30300 (epoch 45.705), train_loss = 0.88631615, grad/param norm = 1.6875e-01, time/batch = 19.0468s	
27698/30300 (epoch 45.706), train_loss = 1.03331496, grad/param norm = 1.7613e-01, time/batch = 19.9504s	
27699/30300 (epoch 45.708), train_loss = 0.97106860, grad/param norm = 1.7042e-01, time/batch = 19.2128s	
27700/30300 (epoch 45.710), train_loss = 0.94539515, grad/param norm = 1.7481e-01, time/batch = 19.0298s	
27701/30300 (epoch 45.711), train_loss = 0.91602768, grad/param norm = 1.8386e-01, time/batch = 19.2976s	
27702/30300 (epoch 45.713), train_loss = 0.91809713, grad/param norm = 1.7680e-01, time/batch = 18.1266s	
27703/30300 (epoch 45.715), train_loss = 0.94935727, grad/param norm = 1.7387e-01, time/batch = 19.4548s	
27704/30300 (epoch 45.716), train_loss = 1.02563955, grad/param norm = 1.7483e-01, time/batch = 22.4149s	
27705/30300 (epoch 45.718), train_loss = 1.06213111, grad/param norm = 1.7531e-01, time/batch = 24.8347s	
27706/30300 (epoch 45.719), train_loss = 0.93466335, grad/param norm = 1.9133e-01, time/batch = 17.1949s	
27707/30300 (epoch 45.721), train_loss = 0.95814370, grad/param norm = 1.9040e-01, time/batch = 19.3756s	
27708/30300 (epoch 45.723), train_loss = 0.90514656, grad/param norm = 1.6981e-01, time/batch = 20.1382s	
27709/30300 (epoch 45.724), train_loss = 0.99052746, grad/param norm = 2.0427e-01, time/batch = 18.7159s	
27710/30300 (epoch 45.726), train_loss = 1.21697300, grad/param norm = 2.2789e-01, time/batch = 19.2748s	
27711/30300 (epoch 45.728), train_loss = 1.00793511, grad/param norm = 1.9387e-01, time/batch = 19.3769s	
27712/30300 (epoch 45.729), train_loss = 0.95469325, grad/param norm = 2.6042e-01, time/batch = 18.2963s	
27713/30300 (epoch 45.731), train_loss = 0.92874163, grad/param norm = 1.8999e-01, time/batch = 19.1966s	
27714/30300 (epoch 45.733), train_loss = 0.97689664, grad/param norm = 2.1943e-01, time/batch = 18.6365s	
27715/30300 (epoch 45.734), train_loss = 1.05496990, grad/param norm = 1.6612e-01, time/batch = 18.7721s	
27716/30300 (epoch 45.736), train_loss = 0.99404009, grad/param norm = 1.7838e-01, time/batch = 18.3737s	
27717/30300 (epoch 45.738), train_loss = 0.91763810, grad/param norm = 1.4119e-01, time/batch = 18.2899s	
27718/30300 (epoch 45.739), train_loss = 1.07874512, grad/param norm = 1.7796e-01, time/batch = 19.4489s	
27719/30300 (epoch 45.741), train_loss = 1.09947787, grad/param norm = 1.8088e-01, time/batch = 18.5494s	
27720/30300 (epoch 45.743), train_loss = 0.93957798, grad/param norm = 1.8802e-01, time/batch = 18.4745s	
27721/30300 (epoch 45.744), train_loss = 1.01915816, grad/param norm = 2.2083e-01, time/batch = 19.0613s	
27722/30300 (epoch 45.746), train_loss = 0.93131556, grad/param norm = 1.5327e-01, time/batch = 18.2900s	
27723/30300 (epoch 45.748), train_loss = 0.97361320, grad/param norm = 2.0163e-01, time/batch = 18.5521s	
27724/30300 (epoch 45.749), train_loss = 0.98948290, grad/param norm = 1.7178e-01, time/batch = 19.2951s	
27725/30300 (epoch 45.751), train_loss = 1.02389459, grad/param norm = 1.8163e-01, time/batch = 18.7135s	
27726/30300 (epoch 45.752), train_loss = 0.95725374, grad/param norm = 1.7853e-01, time/batch = 17.2927s	
27727/30300 (epoch 45.754), train_loss = 0.96357684, grad/param norm = 1.6562e-01, time/batch = 19.3849s	
27728/30300 (epoch 45.756), train_loss = 0.96827581, grad/param norm = 1.7597e-01, time/batch = 17.7933s	
27729/30300 (epoch 45.757), train_loss = 0.89294937, grad/param norm = 1.7658e-01, time/batch = 17.2653s	
27730/30300 (epoch 45.759), train_loss = 0.98467278, grad/param norm = 1.7185e-01, time/batch = 18.8009s	
27731/30300 (epoch 45.761), train_loss = 0.84153115, grad/param norm = 1.6351e-01, time/batch = 19.9619s	
27732/30300 (epoch 45.762), train_loss = 0.86840670, grad/param norm = 1.6318e-01, time/batch = 19.4404s	
27733/30300 (epoch 45.764), train_loss = 0.94985792, grad/param norm = 1.8710e-01, time/batch = 18.8950s	
27734/30300 (epoch 45.766), train_loss = 1.08550130, grad/param norm = 2.0514e-01, time/batch = 20.2270s	
27735/30300 (epoch 45.767), train_loss = 0.95679004, grad/param norm = 2.1267e-01, time/batch = 18.9513s	
27736/30300 (epoch 45.769), train_loss = 0.97862695, grad/param norm = 2.0444e-01, time/batch = 18.9461s	
27737/30300 (epoch 45.771), train_loss = 0.91142006, grad/param norm = 2.2325e-01, time/batch = 19.4609s	
27738/30300 (epoch 45.772), train_loss = 0.96228570, grad/param norm = 1.6617e-01, time/batch = 18.7049s	
27739/30300 (epoch 45.774), train_loss = 1.14894423, grad/param norm = 1.9330e-01, time/batch = 19.3839s	
27740/30300 (epoch 45.776), train_loss = 0.93665082, grad/param norm = 2.0992e-01, time/batch = 18.8876s	
27741/30300 (epoch 45.777), train_loss = 1.10230382, grad/param norm = 1.6969e-01, time/batch = 17.7120s	
27742/30300 (epoch 45.779), train_loss = 1.08963841, grad/param norm = 2.0081e-01, time/batch = 19.2969s	
27743/30300 (epoch 45.781), train_loss = 0.96590124, grad/param norm = 1.8554e-01, time/batch = 19.9643s	
27744/30300 (epoch 45.782), train_loss = 0.89808744, grad/param norm = 1.8655e-01, time/batch = 17.5312s	
27745/30300 (epoch 45.784), train_loss = 0.92383427, grad/param norm = 1.7727e-01, time/batch = 19.7164s	
27746/30300 (epoch 45.785), train_loss = 1.02467751, grad/param norm = 2.2733e-01, time/batch = 18.1365s	
27747/30300 (epoch 45.787), train_loss = 0.82659858, grad/param norm = 1.9102e-01, time/batch = 18.6057s	
27748/30300 (epoch 45.789), train_loss = 1.11811183, grad/param norm = 2.0572e-01, time/batch = 18.3939s	
27749/30300 (epoch 45.790), train_loss = 0.95321110, grad/param norm = 1.8309e-01, time/batch = 19.7189s	
27750/30300 (epoch 45.792), train_loss = 0.78450193, grad/param norm = 1.7528e-01, time/batch = 19.2230s	
27751/30300 (epoch 45.794), train_loss = 0.99305486, grad/param norm = 1.8531e-01, time/batch = 17.2110s	
27752/30300 (epoch 45.795), train_loss = 0.89385331, grad/param norm = 1.6067e-01, time/batch = 17.8859s	
27753/30300 (epoch 45.797), train_loss = 1.11496920, grad/param norm = 2.6121e-01, time/batch = 19.8059s	
27754/30300 (epoch 45.799), train_loss = 1.03189438, grad/param norm = 2.2857e-01, time/batch = 17.8081s	
27755/30300 (epoch 45.800), train_loss = 1.03918520, grad/param norm = 1.7911e-01, time/batch = 19.0487s	
27756/30300 (epoch 45.802), train_loss = 1.22022178, grad/param norm = 2.0571e-01, time/batch = 19.3006s	
27757/30300 (epoch 45.804), train_loss = 1.02110174, grad/param norm = 2.1083e-01, time/batch = 17.9604s	
27758/30300 (epoch 45.805), train_loss = 1.11482513, grad/param norm = 1.9138e-01, time/batch = 18.6128s	
27759/30300 (epoch 45.807), train_loss = 0.94001931, grad/param norm = 2.4109e-01, time/batch = 19.0621s	
27760/30300 (epoch 45.809), train_loss = 1.05471497, grad/param norm = 1.7753e-01, time/batch = 19.2849s	
27761/30300 (epoch 45.810), train_loss = 1.02703385, grad/param norm = 1.7629e-01, time/batch = 18.6315s	
27762/30300 (epoch 45.812), train_loss = 0.92616572, grad/param norm = 1.6258e-01, time/batch = 18.2240s	
27763/30300 (epoch 45.814), train_loss = 0.98382436, grad/param norm = 1.9091e-01, time/batch = 19.0510s	
27764/30300 (epoch 45.815), train_loss = 0.99470336, grad/param norm = 2.1535e-01, time/batch = 18.8137s	
27765/30300 (epoch 45.817), train_loss = 1.06091652, grad/param norm = 1.9366e-01, time/batch = 19.2188s	
27766/30300 (epoch 45.818), train_loss = 1.02398431, grad/param norm = 1.7912e-01, time/batch = 18.7975s	
27767/30300 (epoch 45.820), train_loss = 1.15881064, grad/param norm = 2.0706e-01, time/batch = 19.3746s	
27768/30300 (epoch 45.822), train_loss = 1.13313788, grad/param norm = 2.3278e-01, time/batch = 17.5273s	
27769/30300 (epoch 45.823), train_loss = 1.10073286, grad/param norm = 2.0663e-01, time/batch = 19.9628s	
27770/30300 (epoch 45.825), train_loss = 1.11054854, grad/param norm = 1.8067e-01, time/batch = 17.0341s	
27771/30300 (epoch 45.827), train_loss = 0.83365467, grad/param norm = 1.7880e-01, time/batch = 18.6991s	
27772/30300 (epoch 45.828), train_loss = 1.09415923, grad/param norm = 1.8829e-01, time/batch = 19.6281s	
27773/30300 (epoch 45.830), train_loss = 1.02315533, grad/param norm = 1.6409e-01, time/batch = 18.1169s	
27774/30300 (epoch 45.832), train_loss = 0.91817693, grad/param norm = 1.8382e-01, time/batch = 18.0472s	
27775/30300 (epoch 45.833), train_loss = 0.99315045, grad/param norm = 1.9461e-01, time/batch = 18.8847s	
27776/30300 (epoch 45.835), train_loss = 0.91231877, grad/param norm = 1.8140e-01, time/batch = 17.9633s	
27777/30300 (epoch 45.837), train_loss = 0.89078322, grad/param norm = 1.7607e-01, time/batch = 19.2805s	
27778/30300 (epoch 45.838), train_loss = 0.89963457, grad/param norm = 1.7730e-01, time/batch = 19.2242s	
27779/30300 (epoch 45.840), train_loss = 1.03537696, grad/param norm = 1.5645e-01, time/batch = 18.7021s	
27780/30300 (epoch 45.842), train_loss = 0.95137849, grad/param norm = 1.7102e-01, time/batch = 18.5367s	
27781/30300 (epoch 45.843), train_loss = 1.02904307, grad/param norm = 1.9307e-01, time/batch = 19.6273s	
27782/30300 (epoch 45.845), train_loss = 1.02040123, grad/param norm = 1.6351e-01, time/batch = 18.8855s	
27783/30300 (epoch 45.847), train_loss = 0.98226443, grad/param norm = 2.0020e-01, time/batch = 18.8048s	
27784/30300 (epoch 45.848), train_loss = 1.02485566, grad/param norm = 1.8229e-01, time/batch = 19.9719s	
27785/30300 (epoch 45.850), train_loss = 0.97951524, grad/param norm = 1.6446e-01, time/batch = 19.6336s	
27786/30300 (epoch 45.851), train_loss = 1.01004153, grad/param norm = 1.8935e-01, time/batch = 17.2894s	
27787/30300 (epoch 45.853), train_loss = 0.95169644, grad/param norm = 1.7609e-01, time/batch = 17.1172s	
27788/30300 (epoch 45.855), train_loss = 0.92732743, grad/param norm = 1.6105e-01, time/batch = 19.3877s	
27789/30300 (epoch 45.856), train_loss = 0.98023437, grad/param norm = 1.7633e-01, time/batch = 17.4583s	
27790/30300 (epoch 45.858), train_loss = 0.91268699, grad/param norm = 1.6875e-01, time/batch = 18.8864s	
27791/30300 (epoch 45.860), train_loss = 0.89200591, grad/param norm = 1.5288e-01, time/batch = 19.4725s	
27792/30300 (epoch 45.861), train_loss = 1.11270116, grad/param norm = 1.8530e-01, time/batch = 18.4558s	
27793/30300 (epoch 45.863), train_loss = 0.94104021, grad/param norm = 1.7479e-01, time/batch = 19.1075s	
27794/30300 (epoch 45.865), train_loss = 1.03038581, grad/param norm = 2.0267e-01, time/batch = 18.5581s	
27795/30300 (epoch 45.866), train_loss = 1.04149683, grad/param norm = 1.7406e-01, time/batch = 19.6297s	
27796/30300 (epoch 45.868), train_loss = 1.00365021, grad/param norm = 1.6649e-01, time/batch = 19.1381s	
27797/30300 (epoch 45.870), train_loss = 0.92739043, grad/param norm = 1.7384e-01, time/batch = 19.3052s	
27798/30300 (epoch 45.871), train_loss = 1.00470343, grad/param norm = 1.7504e-01, time/batch = 17.8621s	
27799/30300 (epoch 45.873), train_loss = 1.00237777, grad/param norm = 1.5869e-01, time/batch = 18.9351s	
27800/30300 (epoch 45.875), train_loss = 0.94203104, grad/param norm = 1.5867e-01, time/batch = 19.7906s	
27801/30300 (epoch 45.876), train_loss = 0.87510735, grad/param norm = 1.8448e-01, time/batch = 18.3611s	
27802/30300 (epoch 45.878), train_loss = 0.82354917, grad/param norm = 1.7975e-01, time/batch = 18.7184s	
27803/30300 (epoch 45.880), train_loss = 0.90683056, grad/param norm = 1.8058e-01, time/batch = 19.3859s	
27804/30300 (epoch 45.881), train_loss = 1.12880768, grad/param norm = 2.0494e-01, time/batch = 19.4603s	
27805/30300 (epoch 45.883), train_loss = 1.05091738, grad/param norm = 1.9841e-01, time/batch = 18.1295s	
27806/30300 (epoch 45.884), train_loss = 0.96876214, grad/param norm = 1.5574e-01, time/batch = 18.3705s	
27807/30300 (epoch 45.886), train_loss = 1.02525144, grad/param norm = 1.7700e-01, time/batch = 19.5539s	
27808/30300 (epoch 45.888), train_loss = 0.94301462, grad/param norm = 1.9699e-01, time/batch = 17.7962s	
27809/30300 (epoch 45.889), train_loss = 1.02679339, grad/param norm = 1.8569e-01, time/batch = 19.7113s	
27810/30300 (epoch 45.891), train_loss = 0.96710968, grad/param norm = 1.9671e-01, time/batch = 19.0500s	
27811/30300 (epoch 45.893), train_loss = 1.20234953, grad/param norm = 1.9617e-01, time/batch = 18.5537s	
27812/30300 (epoch 45.894), train_loss = 0.98744551, grad/param norm = 1.7977e-01, time/batch = 17.8680s	
27813/30300 (epoch 45.896), train_loss = 0.85442692, grad/param norm = 2.3823e-01, time/batch = 19.7167s	
27814/30300 (epoch 45.898), train_loss = 0.84101139, grad/param norm = 1.7030e-01, time/batch = 19.0384s	
27815/30300 (epoch 45.899), train_loss = 0.88325976, grad/param norm = 1.8139e-01, time/batch = 18.4515s	
27816/30300 (epoch 45.901), train_loss = 0.99046906, grad/param norm = 2.0943e-01, time/batch = 19.6168s	
27817/30300 (epoch 45.903), train_loss = 0.95303605, grad/param norm = 2.1323e-01, time/batch = 17.6968s	
27818/30300 (epoch 45.904), train_loss = 0.99495175, grad/param norm = 1.7347e-01, time/batch = 19.2189s	
27819/30300 (epoch 45.906), train_loss = 1.00870601, grad/param norm = 2.1243e-01, time/batch = 19.8749s	
27820/30300 (epoch 45.908), train_loss = 0.92948377, grad/param norm = 1.6697e-01, time/batch = 18.1243s	
27821/30300 (epoch 45.909), train_loss = 0.96092355, grad/param norm = 2.3633e-01, time/batch = 18.2931s	
27822/30300 (epoch 45.911), train_loss = 0.97138106, grad/param norm = 1.9500e-01, time/batch = 18.2941s	
27823/30300 (epoch 45.913), train_loss = 0.98022361, grad/param norm = 1.7454e-01, time/batch = 18.6355s	
27824/30300 (epoch 45.914), train_loss = 0.95194787, grad/param norm = 1.9773e-01, time/batch = 17.8819s	
27825/30300 (epoch 45.916), train_loss = 1.00889020, grad/param norm = 1.6359e-01, time/batch = 18.4011s	
27826/30300 (epoch 45.917), train_loss = 0.92689853, grad/param norm = 1.5505e-01, time/batch = 19.1308s	
27827/30300 (epoch 45.919), train_loss = 0.86012184, grad/param norm = 1.7095e-01, time/batch = 17.9635s	
27828/30300 (epoch 45.921), train_loss = 0.95301180, grad/param norm = 1.5950e-01, time/batch = 18.9680s	
27829/30300 (epoch 45.922), train_loss = 1.07686291, grad/param norm = 2.0028e-01, time/batch = 19.0541s	
27830/30300 (epoch 45.924), train_loss = 0.96782264, grad/param norm = 1.8460e-01, time/batch = 18.2086s	
27831/30300 (epoch 45.926), train_loss = 1.01852974, grad/param norm = 1.8014e-01, time/batch = 18.8138s	
27832/30300 (epoch 45.927), train_loss = 1.00229687, grad/param norm = 1.8716e-01, time/batch = 16.9615s	
27833/30300 (epoch 45.929), train_loss = 0.90273584, grad/param norm = 1.8015e-01, time/batch = 17.2757s	
27834/30300 (epoch 45.931), train_loss = 1.03632906, grad/param norm = 2.0964e-01, time/batch = 18.7165s	
27835/30300 (epoch 45.932), train_loss = 0.90582922, grad/param norm = 1.6728e-01, time/batch = 18.2328s	
27836/30300 (epoch 45.934), train_loss = 0.99761093, grad/param norm = 1.6160e-01, time/batch = 18.5531s	
27837/30300 (epoch 45.936), train_loss = 0.95172352, grad/param norm = 1.8096e-01, time/batch = 18.2968s	
27838/30300 (epoch 45.937), train_loss = 0.93718655, grad/param norm = 1.7982e-01, time/batch = 17.9635s	
27839/30300 (epoch 45.939), train_loss = 1.07391706, grad/param norm = 1.9432e-01, time/batch = 19.2358s	
27840/30300 (epoch 45.941), train_loss = 0.94819794, grad/param norm = 1.7229e-01, time/batch = 17.7021s	
27841/30300 (epoch 45.942), train_loss = 0.96116829, grad/param norm = 1.9735e-01, time/batch = 19.0551s	
27842/30300 (epoch 45.944), train_loss = 0.86511610, grad/param norm = 1.6180e-01, time/batch = 17.4799s	
27843/30300 (epoch 45.946), train_loss = 1.04540815, grad/param norm = 2.3622e-01, time/batch = 17.7253s	
27844/30300 (epoch 45.947), train_loss = 1.00216237, grad/param norm = 2.2894e-01, time/batch = 18.5536s	
27845/30300 (epoch 45.949), train_loss = 1.05890993, grad/param norm = 2.1322e-01, time/batch = 18.6366s	
27846/30300 (epoch 45.950), train_loss = 1.08457943, grad/param norm = 2.0958e-01, time/batch = 18.1281s	
27847/30300 (epoch 45.952), train_loss = 0.99817562, grad/param norm = 1.8914e-01, time/batch = 18.8857s	
27848/30300 (epoch 45.954), train_loss = 1.19878037, grad/param norm = 1.7053e-01, time/batch = 16.6595s	
27849/30300 (epoch 45.955), train_loss = 0.96347207, grad/param norm = 1.6394e-01, time/batch = 16.6944s	
27850/30300 (epoch 45.957), train_loss = 1.02980557, grad/param norm = 1.8317e-01, time/batch = 17.2701s	
27851/30300 (epoch 45.959), train_loss = 0.89297395, grad/param norm = 2.0315e-01, time/batch = 18.7045s	
27852/30300 (epoch 45.960), train_loss = 0.93901250, grad/param norm = 1.6846e-01, time/batch = 18.6275s	
27853/30300 (epoch 45.962), train_loss = 0.89978537, grad/param norm = 2.0493e-01, time/batch = 16.7131s	
27854/30300 (epoch 45.964), train_loss = 0.90188328, grad/param norm = 2.0206e-01, time/batch = 19.2934s	
27855/30300 (epoch 45.965), train_loss = 0.90439649, grad/param norm = 2.0319e-01, time/batch = 18.1211s	
27856/30300 (epoch 45.967), train_loss = 0.93219651, grad/param norm = 1.8304e-01, time/batch = 18.7258s	
27857/30300 (epoch 45.969), train_loss = 0.92053474, grad/param norm = 1.9452e-01, time/batch = 7.1162s	
27858/30300 (epoch 45.970), train_loss = 0.94623970, grad/param norm = 1.6320e-01, time/batch = 0.6708s	
27859/30300 (epoch 45.972), train_loss = 0.86184000, grad/param norm = 1.7145e-01, time/batch = 0.6692s	
27860/30300 (epoch 45.974), train_loss = 1.08530647, grad/param norm = 1.8416e-01, time/batch = 0.6706s	
27861/30300 (epoch 45.975), train_loss = 1.11236366, grad/param norm = 2.0973e-01, time/batch = 0.6738s	
27862/30300 (epoch 45.977), train_loss = 1.16578106, grad/param norm = 1.7745e-01, time/batch = 0.6771s	
27863/30300 (epoch 45.979), train_loss = 1.04318698, grad/param norm = 2.0303e-01, time/batch = 0.6729s	
27864/30300 (epoch 45.980), train_loss = 1.07532817, grad/param norm = 1.9156e-01, time/batch = 0.7714s	
27865/30300 (epoch 45.982), train_loss = 1.04739194, grad/param norm = 1.9414e-01, time/batch = 0.9912s	
27866/30300 (epoch 45.983), train_loss = 1.08597363, grad/param norm = 1.6921e-01, time/batch = 0.9886s	
27867/30300 (epoch 45.985), train_loss = 1.03760047, grad/param norm = 2.3174e-01, time/batch = 1.0180s	
27868/30300 (epoch 45.987), train_loss = 1.00769343, grad/param norm = 1.6302e-01, time/batch = 1.0153s	
27869/30300 (epoch 45.988), train_loss = 1.10919991, grad/param norm = 2.1492e-01, time/batch = 1.2090s	
27870/30300 (epoch 45.990), train_loss = 0.92887421, grad/param norm = 1.9420e-01, time/batch = 1.8387s	
27871/30300 (epoch 45.992), train_loss = 1.07112851, grad/param norm = 1.6086e-01, time/batch = 1.8623s	
27872/30300 (epoch 45.993), train_loss = 1.06158017, grad/param norm = 2.3336e-01, time/batch = 14.1964s	
27873/30300 (epoch 45.995), train_loss = 0.97091975, grad/param norm = 2.1977e-01, time/batch = 19.2076s	
27874/30300 (epoch 45.997), train_loss = 1.06190243, grad/param norm = 2.8589e-01, time/batch = 17.1206s	
27875/30300 (epoch 45.998), train_loss = 1.06748506, grad/param norm = 1.9697e-01, time/batch = 18.7873s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
27876/30300 (epoch 46.000), train_loss = 0.91639808, grad/param norm = 1.9883e-01, time/batch = 19.0673s	
27877/30300 (epoch 46.002), train_loss = 1.10099864, grad/param norm = 1.9081e-01, time/batch = 16.4649s	
27878/30300 (epoch 46.003), train_loss = 1.01139127, grad/param norm = 1.8852e-01, time/batch = 18.8061s	
27879/30300 (epoch 46.005), train_loss = 0.96247820, grad/param norm = 1.8509e-01, time/batch = 18.1366s	
27880/30300 (epoch 46.007), train_loss = 1.05973644, grad/param norm = 2.1275e-01, time/batch = 17.2958s	
27881/30300 (epoch 46.008), train_loss = 1.00240996, grad/param norm = 2.0207e-01, time/batch = 18.7327s	
27882/30300 (epoch 46.010), train_loss = 0.87966331, grad/param norm = 1.8585e-01, time/batch = 18.6386s	
27883/30300 (epoch 46.012), train_loss = 0.96241746, grad/param norm = 1.9198e-01, time/batch = 18.9701s	
27884/30300 (epoch 46.013), train_loss = 1.08675145, grad/param norm = 2.2383e-01, time/batch = 18.3001s	
27885/30300 (epoch 46.015), train_loss = 0.93071090, grad/param norm = 1.7137e-01, time/batch = 17.8851s	
27886/30300 (epoch 46.017), train_loss = 0.97392486, grad/param norm = 1.5067e-01, time/batch = 18.7954s	
27887/30300 (epoch 46.018), train_loss = 0.87255112, grad/param norm = 1.6725e-01, time/batch = 29.4849s	
27888/30300 (epoch 46.020), train_loss = 1.09413859, grad/param norm = 2.5339e-01, time/batch = 20.4350s	
27889/30300 (epoch 46.021), train_loss = 1.10566135, grad/param norm = 1.9308e-01, time/batch = 18.6318s	
27890/30300 (epoch 46.023), train_loss = 1.01309078, grad/param norm = 1.6058e-01, time/batch = 18.3821s	
27891/30300 (epoch 46.025), train_loss = 0.91632533, grad/param norm = 1.8699e-01, time/batch = 18.5626s	
27892/30300 (epoch 46.026), train_loss = 1.08046244, grad/param norm = 2.2738e-01, time/batch = 19.5688s	
27893/30300 (epoch 46.028), train_loss = 1.04567401, grad/param norm = 1.8981e-01, time/batch = 16.1197s	
27894/30300 (epoch 46.030), train_loss = 0.95872550, grad/param norm = 2.0146e-01, time/batch = 18.0450s	
27895/30300 (epoch 46.031), train_loss = 1.02075356, grad/param norm = 1.7801e-01, time/batch = 18.9621s	
27896/30300 (epoch 46.033), train_loss = 1.00414665, grad/param norm = 1.9446e-01, time/batch = 17.3975s	
27897/30300 (epoch 46.035), train_loss = 1.02274590, grad/param norm = 2.1443e-01, time/batch = 19.3779s	
27898/30300 (epoch 46.036), train_loss = 1.02613297, grad/param norm = 1.7763e-01, time/batch = 18.5479s	
27899/30300 (epoch 46.038), train_loss = 1.04409021, grad/param norm = 1.6335e-01, time/batch = 17.7876s	
27900/30300 (epoch 46.040), train_loss = 0.89195662, grad/param norm = 1.6612e-01, time/batch = 17.7993s	
27901/30300 (epoch 46.041), train_loss = 0.82313557, grad/param norm = 1.6124e-01, time/batch = 18.2999s	
27902/30300 (epoch 46.043), train_loss = 1.02511379, grad/param norm = 1.7461e-01, time/batch = 18.2197s	
27903/30300 (epoch 46.045), train_loss = 0.93400478, grad/param norm = 1.8437e-01, time/batch = 17.6973s	
27904/30300 (epoch 46.046), train_loss = 1.11383526, grad/param norm = 2.0725e-01, time/batch = 18.4672s	
27905/30300 (epoch 46.048), train_loss = 1.01705043, grad/param norm = 1.9018e-01, time/batch = 17.8886s	
27906/30300 (epoch 46.050), train_loss = 0.90372816, grad/param norm = 1.8835e-01, time/batch = 18.2853s	
27907/30300 (epoch 46.051), train_loss = 1.01406016, grad/param norm = 1.8219e-01, time/batch = 19.2204s	
27908/30300 (epoch 46.053), train_loss = 0.87540514, grad/param norm = 2.1835e-01, time/batch = 19.0631s	
27909/30300 (epoch 46.054), train_loss = 1.02369588, grad/param norm = 1.7627e-01, time/batch = 17.1114s	
27910/30300 (epoch 46.056), train_loss = 0.91547212, grad/param norm = 1.8542e-01, time/batch = 19.3813s	
27911/30300 (epoch 46.058), train_loss = 0.95157298, grad/param norm = 1.7148e-01, time/batch = 18.2972s	
27912/30300 (epoch 46.059), train_loss = 0.93512735, grad/param norm = 1.8690e-01, time/batch = 17.8677s	
27913/30300 (epoch 46.061), train_loss = 1.04361673, grad/param norm = 1.9326e-01, time/batch = 18.2992s	
27914/30300 (epoch 46.063), train_loss = 0.89864372, grad/param norm = 1.9047e-01, time/batch = 19.0574s	
27915/30300 (epoch 46.064), train_loss = 0.96219789, grad/param norm = 1.9391e-01, time/batch = 18.0485s	
27916/30300 (epoch 46.066), train_loss = 0.99723579, grad/param norm = 2.0153e-01, time/batch = 17.5471s	
27917/30300 (epoch 46.068), train_loss = 0.92098528, grad/param norm = 1.6200e-01, time/batch = 18.7923s	
27918/30300 (epoch 46.069), train_loss = 1.06608923, grad/param norm = 2.5796e-01, time/batch = 19.2933s	
27919/30300 (epoch 46.071), train_loss = 1.00813609, grad/param norm = 2.0694e-01, time/batch = 18.1068s	
27920/30300 (epoch 46.073), train_loss = 0.92461284, grad/param norm = 2.0385e-01, time/batch = 16.6201s	
27921/30300 (epoch 46.074), train_loss = 0.95248056, grad/param norm = 1.7223e-01, time/batch = 18.7199s	
27922/30300 (epoch 46.076), train_loss = 0.97053861, grad/param norm = 1.7942e-01, time/batch = 17.7090s	
27923/30300 (epoch 46.078), train_loss = 0.90647478, grad/param norm = 1.6465e-01, time/batch = 17.8742s	
27924/30300 (epoch 46.079), train_loss = 0.94420984, grad/param norm = 1.9620e-01, time/batch = 19.1995s	
27925/30300 (epoch 46.081), train_loss = 0.99073426, grad/param norm = 1.8931e-01, time/batch = 18.7902s	
27926/30300 (epoch 46.083), train_loss = 1.04216001, grad/param norm = 2.3204e-01, time/batch = 18.6272s	
27927/30300 (epoch 46.084), train_loss = 0.93635836, grad/param norm = 1.7687e-01, time/batch = 18.4729s	
27928/30300 (epoch 46.086), train_loss = 0.93000406, grad/param norm = 2.2985e-01, time/batch = 18.3136s	
27929/30300 (epoch 46.087), train_loss = 0.92056609, grad/param norm = 1.6148e-01, time/batch = 17.0292s	
27930/30300 (epoch 46.089), train_loss = 0.89464271, grad/param norm = 1.6807e-01, time/batch = 18.6182s	
27931/30300 (epoch 46.091), train_loss = 1.01796769, grad/param norm = 1.7520e-01, time/batch = 18.8037s	
27932/30300 (epoch 46.092), train_loss = 1.04722084, grad/param norm = 1.7720e-01, time/batch = 17.3014s	
27933/30300 (epoch 46.094), train_loss = 1.07387902, grad/param norm = 2.0908e-01, time/batch = 18.6456s	
27934/30300 (epoch 46.096), train_loss = 1.09455240, grad/param norm = 1.9419e-01, time/batch = 17.8822s	
27935/30300 (epoch 46.097), train_loss = 0.94567876, grad/param norm = 2.2548e-01, time/batch = 18.2048s	
27936/30300 (epoch 46.099), train_loss = 1.03369660, grad/param norm = 1.7061e-01, time/batch = 19.1366s	
27937/30300 (epoch 46.101), train_loss = 1.06767808, grad/param norm = 2.0313e-01, time/batch = 19.2297s	
27938/30300 (epoch 46.102), train_loss = 0.90891159, grad/param norm = 1.8633e-01, time/batch = 18.1361s	
27939/30300 (epoch 46.104), train_loss = 0.95706463, grad/param norm = 2.1295e-01, time/batch = 18.0324s	
27940/30300 (epoch 46.106), train_loss = 0.89906424, grad/param norm = 1.8898e-01, time/batch = 18.8796s	
27941/30300 (epoch 46.107), train_loss = 1.04517154, grad/param norm = 1.8194e-01, time/batch = 18.6320s	
27942/30300 (epoch 46.109), train_loss = 1.04871435, grad/param norm = 2.1128e-01, time/batch = 18.2106s	
27943/30300 (epoch 46.111), train_loss = 1.01986403, grad/param norm = 2.0908e-01, time/batch = 18.7229s	
27944/30300 (epoch 46.112), train_loss = 1.11312499, grad/param norm = 2.0836e-01, time/batch = 17.8697s	
27945/30300 (epoch 46.114), train_loss = 0.93697270, grad/param norm = 1.6541e-01, time/batch = 17.4597s	
27946/30300 (epoch 46.116), train_loss = 1.02834380, grad/param norm = 2.2692e-01, time/batch = 18.8799s	
27947/30300 (epoch 46.117), train_loss = 1.07534306, grad/param norm = 1.7577e-01, time/batch = 17.5256s	
27948/30300 (epoch 46.119), train_loss = 0.87918991, grad/param norm = 1.8558e-01, time/batch = 17.8773s	
27949/30300 (epoch 46.120), train_loss = 0.95664412, grad/param norm = 1.9638e-01, time/batch = 18.4650s	
27950/30300 (epoch 46.122), train_loss = 1.07224712, grad/param norm = 2.1868e-01, time/batch = 18.4724s	
27951/30300 (epoch 46.124), train_loss = 1.14886707, grad/param norm = 2.0548e-01, time/batch = 18.2847s	
27952/30300 (epoch 46.125), train_loss = 0.90479244, grad/param norm = 1.7690e-01, time/batch = 17.6238s	
27953/30300 (epoch 46.127), train_loss = 1.00418221, grad/param norm = 2.1103e-01, time/batch = 19.3011s	
27954/30300 (epoch 46.129), train_loss = 1.02162398, grad/param norm = 1.8370e-01, time/batch = 16.7804s	
27955/30300 (epoch 46.130), train_loss = 1.12124071, grad/param norm = 1.9304e-01, time/batch = 18.2161s	
27956/30300 (epoch 46.132), train_loss = 1.09919416, grad/param norm = 2.0481e-01, time/batch = 17.0487s	
27957/30300 (epoch 46.134), train_loss = 0.93093138, grad/param norm = 2.0741e-01, time/batch = 18.9734s	
27958/30300 (epoch 46.135), train_loss = 0.93484664, grad/param norm = 2.1455e-01, time/batch = 17.4620s	
27959/30300 (epoch 46.137), train_loss = 0.99835754, grad/param norm = 2.1194e-01, time/batch = 19.2123s	
27960/30300 (epoch 46.139), train_loss = 0.90694329, grad/param norm = 2.4373e-01, time/batch = 18.3954s	
27961/30300 (epoch 46.140), train_loss = 1.00149398, grad/param norm = 2.8745e-01, time/batch = 18.8916s	
27962/30300 (epoch 46.142), train_loss = 1.08511501, grad/param norm = 2.5654e-01, time/batch = 18.7194s	
27963/30300 (epoch 46.144), train_loss = 0.91013555, grad/param norm = 2.0746e-01, time/batch = 18.7266s	
27964/30300 (epoch 46.145), train_loss = 1.06827310, grad/param norm = 2.0998e-01, time/batch = 18.0459s	
27965/30300 (epoch 46.147), train_loss = 0.96477333, grad/param norm = 2.3873e-01, time/batch = 18.8865s	
27966/30300 (epoch 46.149), train_loss = 1.06143218, grad/param norm = 2.6393e-01, time/batch = 18.4710s	
27967/30300 (epoch 46.150), train_loss = 0.95883431, grad/param norm = 2.1251e-01, time/batch = 18.2979s	
27968/30300 (epoch 46.152), train_loss = 0.90032955, grad/param norm = 2.0146e-01, time/batch = 16.1585s	
27969/30300 (epoch 46.153), train_loss = 1.01518081, grad/param norm = 2.2380e-01, time/batch = 17.8635s	
27970/30300 (epoch 46.155), train_loss = 0.89218113, grad/param norm = 2.2041e-01, time/batch = 18.7244s	
27971/30300 (epoch 46.157), train_loss = 0.92103930, grad/param norm = 2.1833e-01, time/batch = 17.9537s	
27972/30300 (epoch 46.158), train_loss = 1.01272829, grad/param norm = 3.3484e-01, time/batch = 18.7967s	
27973/30300 (epoch 46.160), train_loss = 0.90742819, grad/param norm = 1.9698e-01, time/batch = 19.2011s	
27974/30300 (epoch 46.162), train_loss = 0.96787086, grad/param norm = 1.7749e-01, time/batch = 17.8046s	
27975/30300 (epoch 46.163), train_loss = 0.98635191, grad/param norm = 2.0028e-01, time/batch = 18.3870s	
27976/30300 (epoch 46.165), train_loss = 1.09675286, grad/param norm = 1.8309e-01, time/batch = 19.3081s	
27977/30300 (epoch 46.167), train_loss = 0.99637210, grad/param norm = 2.0514e-01, time/batch = 18.3846s	
27978/30300 (epoch 46.168), train_loss = 1.02304288, grad/param norm = 1.7085e-01, time/batch = 17.1183s	
27979/30300 (epoch 46.170), train_loss = 1.03497778, grad/param norm = 2.1235e-01, time/batch = 19.0554s	
27980/30300 (epoch 46.172), train_loss = 0.98795536, grad/param norm = 1.9302e-01, time/batch = 18.5480s	
27981/30300 (epoch 46.173), train_loss = 0.96421171, grad/param norm = 2.3155e-01, time/batch = 18.0393s	
27982/30300 (epoch 46.175), train_loss = 1.01802762, grad/param norm = 2.0268e-01, time/batch = 17.8950s	
27983/30300 (epoch 46.177), train_loss = 1.04969158, grad/param norm = 2.1043e-01, time/batch = 18.8824s	
27984/30300 (epoch 46.178), train_loss = 0.81612625, grad/param norm = 1.5609e-01, time/batch = 17.4646s	
27985/30300 (epoch 46.180), train_loss = 0.96059956, grad/param norm = 1.6989e-01, time/batch = 18.8810s	
27986/30300 (epoch 46.182), train_loss = 1.00546758, grad/param norm = 2.0768e-01, time/batch = 18.8009s	
27987/30300 (epoch 46.183), train_loss = 0.93113859, grad/param norm = 2.1437e-01, time/batch = 16.5537s	
27988/30300 (epoch 46.185), train_loss = 1.10085456, grad/param norm = 1.9496e-01, time/batch = 17.4821s	
27989/30300 (epoch 46.186), train_loss = 1.19183428, grad/param norm = 2.3252e-01, time/batch = 18.2996s	
27990/30300 (epoch 46.188), train_loss = 1.04122322, grad/param norm = 2.1094e-01, time/batch = 18.5546s	
27991/30300 (epoch 46.190), train_loss = 0.97010870, grad/param norm = 1.6763e-01, time/batch = 17.9653s	
27992/30300 (epoch 46.191), train_loss = 1.02246871, grad/param norm = 2.0134e-01, time/batch = 18.6378s	
27993/30300 (epoch 46.193), train_loss = 0.90018796, grad/param norm = 2.0072e-01, time/batch = 18.3092s	
27994/30300 (epoch 46.195), train_loss = 0.93076803, grad/param norm = 1.6601e-01, time/batch = 18.2177s	
27995/30300 (epoch 46.196), train_loss = 1.03190911, grad/param norm = 1.6781e-01, time/batch = 17.6365s	
27996/30300 (epoch 46.198), train_loss = 0.83614065, grad/param norm = 1.6363e-01, time/batch = 18.6414s	
27997/30300 (epoch 46.200), train_loss = 0.95218403, grad/param norm = 1.8013e-01, time/batch = 17.9689s	
27998/30300 (epoch 46.201), train_loss = 1.07094613, grad/param norm = 2.4669e-01, time/batch = 17.9731s	
27999/30300 (epoch 46.203), train_loss = 0.98420150, grad/param norm = 1.9955e-01, time/batch = 18.5693s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch46.20_2.0848.t7	
28000/30300 (epoch 46.205), train_loss = 1.16392377, grad/param norm = 2.2420e-01, time/batch = 17.7945s	
28001/30300 (epoch 46.206), train_loss = 1.94814789, grad/param norm = 3.3787e-01, time/batch = 18.3622s	
28002/30300 (epoch 46.208), train_loss = 1.10754174, grad/param norm = 3.0779e-01, time/batch = 18.1455s	
28003/30300 (epoch 46.210), train_loss = 1.06822632, grad/param norm = 1.7200e-01, time/batch = 17.5585s	
28004/30300 (epoch 46.211), train_loss = 1.11168158, grad/param norm = 1.9486e-01, time/batch = 18.9737s	
28005/30300 (epoch 46.213), train_loss = 0.99836220, grad/param norm = 1.5725e-01, time/batch = 19.0473s	
28006/30300 (epoch 46.215), train_loss = 0.92211640, grad/param norm = 1.8487e-01, time/batch = 17.2998s	
28007/30300 (epoch 46.216), train_loss = 0.94125802, grad/param norm = 1.8770e-01, time/batch = 19.2254s	
28008/30300 (epoch 46.218), train_loss = 0.91783212, grad/param norm = 1.8272e-01, time/batch = 18.0495s	
28009/30300 (epoch 46.219), train_loss = 0.86435431, grad/param norm = 1.9191e-01, time/batch = 16.5305s	
28010/30300 (epoch 46.221), train_loss = 0.84773727, grad/param norm = 1.6572e-01, time/batch = 18.2725s	
28011/30300 (epoch 46.223), train_loss = 0.98808427, grad/param norm = 1.7100e-01, time/batch = 19.2169s	
28012/30300 (epoch 46.224), train_loss = 0.84362456, grad/param norm = 1.8737e-01, time/batch = 17.9049s	
28013/30300 (epoch 46.226), train_loss = 1.04265924, grad/param norm = 2.3315e-01, time/batch = 17.3761s	
28014/30300 (epoch 46.228), train_loss = 1.10471959, grad/param norm = 2.2926e-01, time/batch = 18.3991s	
28015/30300 (epoch 46.229), train_loss = 0.97885228, grad/param norm = 1.8180e-01, time/batch = 19.1259s	
28016/30300 (epoch 46.231), train_loss = 1.05882616, grad/param norm = 1.8395e-01, time/batch = 18.2060s	
28017/30300 (epoch 46.233), train_loss = 1.03822323, grad/param norm = 1.6446e-01, time/batch = 17.5446s	
28018/30300 (epoch 46.234), train_loss = 1.05588059, grad/param norm = 2.2302e-01, time/batch = 18.7249s	
28019/30300 (epoch 46.236), train_loss = 1.03574772, grad/param norm = 1.7228e-01, time/batch = 18.3838s	
28020/30300 (epoch 46.238), train_loss = 1.00140160, grad/param norm = 2.5302e-01, time/batch = 18.8083s	
28021/30300 (epoch 46.239), train_loss = 0.95853266, grad/param norm = 2.4631e-01, time/batch = 18.9701s	
28022/30300 (epoch 46.241), train_loss = 1.02178521, grad/param norm = 1.9112e-01, time/batch = 17.8097s	
28023/30300 (epoch 46.243), train_loss = 1.03990719, grad/param norm = 1.9658e-01, time/batch = 17.8888s	
28024/30300 (epoch 46.244), train_loss = 1.17616910, grad/param norm = 1.8512e-01, time/batch = 18.6467s	
28025/30300 (epoch 46.246), train_loss = 1.03486495, grad/param norm = 2.0244e-01, time/batch = 17.8064s	
28026/30300 (epoch 46.248), train_loss = 0.98139336, grad/param norm = 1.6993e-01, time/batch = 17.3595s	
28027/30300 (epoch 46.249), train_loss = 0.88625978, grad/param norm = 1.8021e-01, time/batch = 18.8952s	
28028/30300 (epoch 46.251), train_loss = 0.92541633, grad/param norm = 1.8755e-01, time/batch = 17.3539s	
28029/30300 (epoch 46.252), train_loss = 1.07847003, grad/param norm = 1.9589e-01, time/batch = 18.5440s	
28030/30300 (epoch 46.254), train_loss = 1.06409274, grad/param norm = 2.1702e-01, time/batch = 18.6129s	
28031/30300 (epoch 46.256), train_loss = 1.02968307, grad/param norm = 2.0113e-01, time/batch = 18.7186s	
28032/30300 (epoch 46.257), train_loss = 1.05196094, grad/param norm = 2.5298e-01, time/batch = 18.0264s	
28033/30300 (epoch 46.259), train_loss = 0.97162023, grad/param norm = 1.7889e-01, time/batch = 18.0565s	
28034/30300 (epoch 46.261), train_loss = 1.13114066, grad/param norm = 1.8951e-01, time/batch = 18.6498s	
28035/30300 (epoch 46.262), train_loss = 0.93670380, grad/param norm = 1.6887e-01, time/batch = 17.9716s	
28036/30300 (epoch 46.264), train_loss = 1.00815453, grad/param norm = 2.5623e-01, time/batch = 18.7162s	
28037/30300 (epoch 46.266), train_loss = 0.99521732, grad/param norm = 1.6675e-01, time/batch = 18.6301s	
28038/30300 (epoch 46.267), train_loss = 1.13565631, grad/param norm = 2.2017e-01, time/batch = 17.4530s	
28039/30300 (epoch 46.269), train_loss = 1.02828723, grad/param norm = 1.8429e-01, time/batch = 17.7139s	
28040/30300 (epoch 46.271), train_loss = 1.00881575, grad/param norm = 1.7769e-01, time/batch = 18.7212s	
28041/30300 (epoch 46.272), train_loss = 1.00203365, grad/param norm = 2.1659e-01, time/batch = 19.4683s	
28042/30300 (epoch 46.274), train_loss = 1.06450570, grad/param norm = 2.0254e-01, time/batch = 17.4620s	
28043/30300 (epoch 46.276), train_loss = 1.02416927, grad/param norm = 2.0479e-01, time/batch = 18.3606s	
28044/30300 (epoch 46.277), train_loss = 0.89006411, grad/param norm = 1.7413e-01, time/batch = 19.1416s	
28045/30300 (epoch 46.279), train_loss = 0.98625713, grad/param norm = 1.9025e-01, time/batch = 18.4535s	
28046/30300 (epoch 46.281), train_loss = 1.07644776, grad/param norm = 2.3581e-01, time/batch = 19.2238s	
28047/30300 (epoch 46.282), train_loss = 1.03401650, grad/param norm = 1.8845e-01, time/batch = 18.5660s	
28048/30300 (epoch 46.284), train_loss = 1.06562184, grad/param norm = 2.2864e-01, time/batch = 18.9807s	
28049/30300 (epoch 46.285), train_loss = 1.05645593, grad/param norm = 1.7642e-01, time/batch = 17.2745s	
28050/30300 (epoch 46.287), train_loss = 1.01242651, grad/param norm = 2.1098e-01, time/batch = 19.2231s	
28051/30300 (epoch 46.289), train_loss = 1.08190272, grad/param norm = 2.0618e-01, time/batch = 18.6400s	
28052/30300 (epoch 46.290), train_loss = 0.80141959, grad/param norm = 1.9194e-01, time/batch = 17.6312s	
28053/30300 (epoch 46.292), train_loss = 0.92579531, grad/param norm = 2.2814e-01, time/batch = 18.7297s	
28054/30300 (epoch 46.294), train_loss = 1.05345539, grad/param norm = 2.3788e-01, time/batch = 18.5540s	
28055/30300 (epoch 46.295), train_loss = 0.95461940, grad/param norm = 1.9635e-01, time/batch = 18.0473s	
28056/30300 (epoch 46.297), train_loss = 0.97225731, grad/param norm = 1.7698e-01, time/batch = 18.1236s	
28057/30300 (epoch 46.299), train_loss = 0.99632972, grad/param norm = 1.8920e-01, time/batch = 18.8071s	
28058/30300 (epoch 46.300), train_loss = 0.91017994, grad/param norm = 1.8626e-01, time/batch = 18.1338s	
28059/30300 (epoch 46.302), train_loss = 1.05779754, grad/param norm = 1.8934e-01, time/batch = 18.3009s	
28060/30300 (epoch 46.304), train_loss = 0.93012395, grad/param norm = 1.7826e-01, time/batch = 17.9979s	
28061/30300 (epoch 46.305), train_loss = 1.00024557, grad/param norm = 1.7306e-01, time/batch = 18.5630s	
28062/30300 (epoch 46.307), train_loss = 1.08367874, grad/param norm = 1.7478e-01, time/batch = 15.6900s	
28063/30300 (epoch 46.309), train_loss = 1.02520414, grad/param norm = 1.9818e-01, time/batch = 16.7876s	
28064/30300 (epoch 46.310), train_loss = 0.96044632, grad/param norm = 1.7166e-01, time/batch = 16.1553s	
28065/30300 (epoch 46.312), train_loss = 1.10248950, grad/param norm = 1.7292e-01, time/batch = 15.3506s	
28066/30300 (epoch 46.314), train_loss = 0.97701205, grad/param norm = 1.6638e-01, time/batch = 17.0384s	
28067/30300 (epoch 46.315), train_loss = 0.94550661, grad/param norm = 1.8901e-01, time/batch = 18.4701s	
28068/30300 (epoch 46.317), train_loss = 1.00736693, grad/param norm = 1.6615e-01, time/batch = 19.1223s	
28069/30300 (epoch 46.318), train_loss = 1.02964104, grad/param norm = 1.9564e-01, time/batch = 18.8790s	
28070/30300 (epoch 46.320), train_loss = 1.04158346, grad/param norm = 1.7853e-01, time/batch = 18.5612s	
28071/30300 (epoch 46.322), train_loss = 0.93495592, grad/param norm = 2.0729e-01, time/batch = 18.7183s	
28072/30300 (epoch 46.323), train_loss = 1.08218315, grad/param norm = 1.8225e-01, time/batch = 17.0531s	
28073/30300 (epoch 46.325), train_loss = 0.98010910, grad/param norm = 1.6757e-01, time/batch = 18.7984s	
28074/30300 (epoch 46.327), train_loss = 0.97478254, grad/param norm = 1.6617e-01, time/batch = 18.3938s	
28075/30300 (epoch 46.328), train_loss = 1.02564423, grad/param norm = 1.7761e-01, time/batch = 24.9581s	
28076/30300 (epoch 46.330), train_loss = 1.03233644, grad/param norm = 1.7128e-01, time/batch = 25.7420s	
28077/30300 (epoch 46.332), train_loss = 1.08645905, grad/param norm = 2.2720e-01, time/batch = 17.3049s	
28078/30300 (epoch 46.333), train_loss = 0.90064034, grad/param norm = 1.7768e-01, time/batch = 16.8067s	
28079/30300 (epoch 46.335), train_loss = 0.90678179, grad/param norm = 1.9555e-01, time/batch = 18.7872s	
28080/30300 (epoch 46.337), train_loss = 1.08584126, grad/param norm = 1.8566e-01, time/batch = 19.1496s	
28081/30300 (epoch 46.338), train_loss = 0.94327913, grad/param norm = 1.8097e-01, time/batch = 17.9546s	
28082/30300 (epoch 46.340), train_loss = 0.94630784, grad/param norm = 1.6405e-01, time/batch = 18.8166s	
28083/30300 (epoch 46.342), train_loss = 1.07293617, grad/param norm = 1.9221e-01, time/batch = 18.7295s	
28084/30300 (epoch 46.343), train_loss = 1.03328689, grad/param norm = 1.8178e-01, time/batch = 17.6353s	
28085/30300 (epoch 46.345), train_loss = 1.02796061, grad/param norm = 1.6776e-01, time/batch = 18.6195s	
28086/30300 (epoch 46.347), train_loss = 0.90017588, grad/param norm = 1.8157e-01, time/batch = 18.7117s	
28087/30300 (epoch 46.348), train_loss = 0.95293282, grad/param norm = 1.8422e-01, time/batch = 18.4514s	
28088/30300 (epoch 46.350), train_loss = 0.97477014, grad/param norm = 2.0767e-01, time/batch = 17.9669s	
28089/30300 (epoch 46.351), train_loss = 0.98321097, grad/param norm = 1.9388e-01, time/batch = 19.3781s	
28090/30300 (epoch 46.353), train_loss = 0.88864882, grad/param norm = 1.6933e-01, time/batch = 18.5519s	
28091/30300 (epoch 46.355), train_loss = 0.93673576, grad/param norm = 1.7720e-01, time/batch = 18.2752s	
28092/30300 (epoch 46.356), train_loss = 1.04562989, grad/param norm = 2.0517e-01, time/batch = 18.3857s	
28093/30300 (epoch 46.358), train_loss = 1.23010589, grad/param norm = 1.9902e-01, time/batch = 17.9458s	
28094/30300 (epoch 46.360), train_loss = 0.95875395, grad/param norm = 2.1935e-01, time/batch = 16.7229s	
28095/30300 (epoch 46.361), train_loss = 0.97682497, grad/param norm = 1.7786e-01, time/batch = 17.6140s	
28096/30300 (epoch 46.363), train_loss = 1.02258836, grad/param norm = 1.9398e-01, time/batch = 18.9699s	
28097/30300 (epoch 46.365), train_loss = 0.85317462, grad/param norm = 2.2292e-01, time/batch = 17.5517s	
28098/30300 (epoch 46.366), train_loss = 0.97084916, grad/param norm = 1.7881e-01, time/batch = 18.1419s	
28099/30300 (epoch 46.368), train_loss = 0.87031493, grad/param norm = 1.8119e-01, time/batch = 16.1165s	
28100/30300 (epoch 46.370), train_loss = 0.89937329, grad/param norm = 1.8378e-01, time/batch = 18.7235s	
28101/30300 (epoch 46.371), train_loss = 1.05949347, grad/param norm = 1.8750e-01, time/batch = 18.0363s	
28102/30300 (epoch 46.373), train_loss = 0.93333139, grad/param norm = 1.5776e-01, time/batch = 19.7255s	
28103/30300 (epoch 46.375), train_loss = 0.92158505, grad/param norm = 1.5748e-01, time/batch = 18.7134s	
28104/30300 (epoch 46.376), train_loss = 0.91614740, grad/param norm = 1.5920e-01, time/batch = 17.8836s	
28105/30300 (epoch 46.378), train_loss = 0.91210712, grad/param norm = 2.0464e-01, time/batch = 19.2037s	
28106/30300 (epoch 46.380), train_loss = 1.09177678, grad/param norm = 1.7287e-01, time/batch = 19.0567s	
28107/30300 (epoch 46.381), train_loss = 0.82407118, grad/param norm = 1.6701e-01, time/batch = 18.0453s	
28108/30300 (epoch 46.383), train_loss = 0.90182092, grad/param norm = 2.4435e-01, time/batch = 18.6293s	
28109/30300 (epoch 46.384), train_loss = 1.02748687, grad/param norm = 1.9514e-01, time/batch = 16.7848s	
28110/30300 (epoch 46.386), train_loss = 0.89140516, grad/param norm = 1.7103e-01, time/batch = 17.6308s	
28111/30300 (epoch 46.388), train_loss = 0.86763966, grad/param norm = 1.7075e-01, time/batch = 17.5488s	
28112/30300 (epoch 46.389), train_loss = 0.96924866, grad/param norm = 1.9778e-01, time/batch = 18.2064s	
28113/30300 (epoch 46.391), train_loss = 1.01791224, grad/param norm = 1.7780e-01, time/batch = 18.3888s	
28114/30300 (epoch 46.393), train_loss = 0.86848598, grad/param norm = 1.5239e-01, time/batch = 18.1233s	
28115/30300 (epoch 46.394), train_loss = 0.99155485, grad/param norm = 1.6085e-01, time/batch = 18.7297s	
28116/30300 (epoch 46.396), train_loss = 1.11207016, grad/param norm = 1.7427e-01, time/batch = 18.8090s	
28117/30300 (epoch 46.398), train_loss = 0.95802175, grad/param norm = 1.7880e-01, time/batch = 18.2066s	
28118/30300 (epoch 46.399), train_loss = 0.88864583, grad/param norm = 1.9462e-01, time/batch = 18.5593s	
28119/30300 (epoch 46.401), train_loss = 1.00425153, grad/param norm = 2.7763e-01, time/batch = 18.9720s	
28120/30300 (epoch 46.403), train_loss = 0.96888304, grad/param norm = 1.7453e-01, time/batch = 17.7144s	
28121/30300 (epoch 46.404), train_loss = 0.93444341, grad/param norm = 2.1453e-01, time/batch = 18.5594s	
28122/30300 (epoch 46.406), train_loss = 0.98667474, grad/param norm = 1.6702e-01, time/batch = 18.5293s	
28123/30300 (epoch 46.408), train_loss = 0.85349608, grad/param norm = 1.5971e-01, time/batch = 18.5534s	
28124/30300 (epoch 46.409), train_loss = 0.87482168, grad/param norm = 1.8153e-01, time/batch = 17.9633s	
28125/30300 (epoch 46.411), train_loss = 0.90468531, grad/param norm = 1.4870e-01, time/batch = 18.4723s	
28126/30300 (epoch 46.413), train_loss = 0.81441178, grad/param norm = 1.5855e-01, time/batch = 19.2239s	
28127/30300 (epoch 46.414), train_loss = 1.01033720, grad/param norm = 1.7723e-01, time/batch = 18.2075s	
28128/30300 (epoch 46.416), train_loss = 0.92053915, grad/param norm = 1.7219e-01, time/batch = 19.0516s	
28129/30300 (epoch 46.417), train_loss = 0.90127970, grad/param norm = 2.0648e-01, time/batch = 18.7178s	
28130/30300 (epoch 46.419), train_loss = 0.87099320, grad/param norm = 1.6425e-01, time/batch = 16.8587s	
28131/30300 (epoch 46.421), train_loss = 0.96009430, grad/param norm = 3.2533e-01, time/batch = 17.6129s	
28132/30300 (epoch 46.422), train_loss = 1.01116132, grad/param norm = 2.3726e-01, time/batch = 18.7269s	
28133/30300 (epoch 46.424), train_loss = 1.00251971, grad/param norm = 2.0040e-01, time/batch = 16.8747s	
28134/30300 (epoch 46.426), train_loss = 0.96276268, grad/param norm = 1.9063e-01, time/batch = 18.8065s	
28135/30300 (epoch 46.427), train_loss = 0.95798969, grad/param norm = 2.9823e-01, time/batch = 19.2226s	
28136/30300 (epoch 46.429), train_loss = 0.96544608, grad/param norm = 1.6488e-01, time/batch = 18.2838s	
28137/30300 (epoch 46.431), train_loss = 0.98912040, grad/param norm = 1.9180e-01, time/batch = 17.5487s	
28138/30300 (epoch 46.432), train_loss = 0.99561541, grad/param norm = 1.7931e-01, time/batch = 18.4739s	
28139/30300 (epoch 46.434), train_loss = 0.86766144, grad/param norm = 1.7564e-01, time/batch = 18.4728s	
28140/30300 (epoch 46.436), train_loss = 1.06308778, grad/param norm = 1.9643e-01, time/batch = 17.6199s	
28141/30300 (epoch 46.437), train_loss = 0.87977927, grad/param norm = 1.6966e-01, time/batch = 18.9611s	
28142/30300 (epoch 46.439), train_loss = 0.94256592, grad/param norm = 1.6837e-01, time/batch = 18.7408s	
28143/30300 (epoch 46.441), train_loss = 0.96214916, grad/param norm = 1.7330e-01, time/batch = 17.1252s	
28144/30300 (epoch 46.442), train_loss = 0.90838854, grad/param norm = 1.9626e-01, time/batch = 18.9088s	
28145/30300 (epoch 46.444), train_loss = 0.81765214, grad/param norm = 1.5692e-01, time/batch = 19.0506s	
28146/30300 (epoch 46.446), train_loss = 0.91287904, grad/param norm = 1.5847e-01, time/batch = 17.8026s	
28147/30300 (epoch 46.447), train_loss = 0.95791011, grad/param norm = 1.6716e-01, time/batch = 18.8015s	
28148/30300 (epoch 46.449), train_loss = 0.91556348, grad/param norm = 1.6945e-01, time/batch = 17.5609s	
28149/30300 (epoch 46.450), train_loss = 1.00297893, grad/param norm = 1.5883e-01, time/batch = 18.7247s	
28150/30300 (epoch 46.452), train_loss = 1.08800771, grad/param norm = 1.8775e-01, time/batch = 18.1946s	
28151/30300 (epoch 46.454), train_loss = 1.01562564, grad/param norm = 1.6376e-01, time/batch = 17.2142s	
28152/30300 (epoch 46.455), train_loss = 0.99032611, grad/param norm = 1.8129e-01, time/batch = 18.7166s	
28153/30300 (epoch 46.457), train_loss = 0.96057386, grad/param norm = 1.9470e-01, time/batch = 17.3650s	
28154/30300 (epoch 46.459), train_loss = 1.00526855, grad/param norm = 1.8823e-01, time/batch = 18.4578s	
28155/30300 (epoch 46.460), train_loss = 1.05695192, grad/param norm = 1.7274e-01, time/batch = 18.9731s	
28156/30300 (epoch 46.462), train_loss = 1.05494043, grad/param norm = 1.8365e-01, time/batch = 18.0428s	
28157/30300 (epoch 46.464), train_loss = 0.79421967, grad/param norm = 1.8977e-01, time/batch = 16.5272s	
28158/30300 (epoch 46.465), train_loss = 0.83236264, grad/param norm = 1.5764e-01, time/batch = 18.9707s	
28159/30300 (epoch 46.467), train_loss = 0.81853842, grad/param norm = 1.5586e-01, time/batch = 17.4469s	
28160/30300 (epoch 46.469), train_loss = 0.90843885, grad/param norm = 1.7627e-01, time/batch = 18.6298s	
28161/30300 (epoch 46.470), train_loss = 0.91211329, grad/param norm = 1.8788e-01, time/batch = 19.0431s	
28162/30300 (epoch 46.472), train_loss = 0.92327335, grad/param norm = 1.6284e-01, time/batch = 18.6399s	
28163/30300 (epoch 46.474), train_loss = 0.91085259, grad/param norm = 2.8424e-01, time/batch = 17.7145s	
28164/30300 (epoch 46.475), train_loss = 0.90018851, grad/param norm = 1.7934e-01, time/batch = 18.8035s	
28165/30300 (epoch 46.477), train_loss = 0.95129046, grad/param norm = 1.8429e-01, time/batch = 18.3778s	
28166/30300 (epoch 46.479), train_loss = 0.90414818, grad/param norm = 1.6686e-01, time/batch = 17.7973s	
28167/30300 (epoch 46.480), train_loss = 0.98881161, grad/param norm = 1.7248e-01, time/batch = 18.8864s	
28168/30300 (epoch 46.482), train_loss = 1.01620755, grad/param norm = 1.6330e-01, time/batch = 17.6054s	
28169/30300 (epoch 46.483), train_loss = 0.95589064, grad/param norm = 1.7649e-01, time/batch = 17.6368s	
28170/30300 (epoch 46.485), train_loss = 0.97757104, grad/param norm = 1.7024e-01, time/batch = 16.7038s	
28171/30300 (epoch 46.487), train_loss = 1.02065083, grad/param norm = 1.7001e-01, time/batch = 18.7213s	
28172/30300 (epoch 46.488), train_loss = 1.10185116, grad/param norm = 1.5879e-01, time/batch = 18.8036s	
28173/30300 (epoch 46.490), train_loss = 0.84199621, grad/param norm = 1.9300e-01, time/batch = 18.0381s	
28174/30300 (epoch 46.492), train_loss = 0.92476508, grad/param norm = 1.8099e-01, time/batch = 18.8796s	
28175/30300 (epoch 46.493), train_loss = 0.97266950, grad/param norm = 1.7249e-01, time/batch = 19.1392s	
28176/30300 (epoch 46.495), train_loss = 0.95305333, grad/param norm = 1.5327e-01, time/batch = 17.9667s	
28177/30300 (epoch 46.497), train_loss = 1.01389391, grad/param norm = 1.8310e-01, time/batch = 17.5401s	
28178/30300 (epoch 46.498), train_loss = 1.03069717, grad/param norm = 1.8814e-01, time/batch = 18.7298s	
28179/30300 (epoch 46.500), train_loss = 0.93236495, grad/param norm = 2.4498e-01, time/batch = 17.3074s	
28180/30300 (epoch 46.502), train_loss = 0.98186179, grad/param norm = 2.2997e-01, time/batch = 17.9884s	
28181/30300 (epoch 46.503), train_loss = 1.07283911, grad/param norm = 1.8444e-01, time/batch = 19.1472s	
28182/30300 (epoch 46.505), train_loss = 0.85765875, grad/param norm = 1.6160e-01, time/batch = 18.3015s	
28183/30300 (epoch 46.507), train_loss = 0.87259191, grad/param norm = 2.1058e-01, time/batch = 17.1980s	
28184/30300 (epoch 46.508), train_loss = 0.94348946, grad/param norm = 3.3114e-01, time/batch = 18.4833s	
28185/30300 (epoch 46.510), train_loss = 1.04128041, grad/param norm = 2.0648e-01, time/batch = 17.6428s	
28186/30300 (epoch 46.512), train_loss = 0.90334966, grad/param norm = 1.7780e-01, time/batch = 18.3496s	
28187/30300 (epoch 46.513), train_loss = 0.97645199, grad/param norm = 1.8545e-01, time/batch = 17.6498s	
28188/30300 (epoch 46.515), train_loss = 0.96912612, grad/param norm = 2.1185e-01, time/batch = 19.2147s	
28189/30300 (epoch 46.517), train_loss = 0.78753421, grad/param norm = 1.5230e-01, time/batch = 17.6245s	
28190/30300 (epoch 46.518), train_loss = 1.04503508, grad/param norm = 2.0471e-01, time/batch = 17.0381s	
28191/30300 (epoch 46.520), train_loss = 0.93507671, grad/param norm = 2.2529e-01, time/batch = 19.4712s	
28192/30300 (epoch 46.521), train_loss = 0.87897279, grad/param norm = 2.6579e-01, time/batch = 18.5543s	
28193/30300 (epoch 46.523), train_loss = 1.07992182, grad/param norm = 2.3872e-01, time/batch = 17.6158s	
28194/30300 (epoch 46.525), train_loss = 0.88816786, grad/param norm = 1.7193e-01, time/batch = 18.4796s	
28195/30300 (epoch 46.526), train_loss = 0.98975242, grad/param norm = 1.7106e-01, time/batch = 18.5455s	
28196/30300 (epoch 46.528), train_loss = 0.85152266, grad/param norm = 1.6727e-01, time/batch = 18.7915s	
28197/30300 (epoch 46.530), train_loss = 0.83188558, grad/param norm = 1.7347e-01, time/batch = 18.4809s	
28198/30300 (epoch 46.531), train_loss = 0.92686225, grad/param norm = 1.8103e-01, time/batch = 18.4900s	
28199/30300 (epoch 46.533), train_loss = 0.94483597, grad/param norm = 2.1097e-01, time/batch = 17.8843s	
28200/30300 (epoch 46.535), train_loss = 0.98811830, grad/param norm = 1.8012e-01, time/batch = 18.4738s	
28201/30300 (epoch 46.536), train_loss = 0.97364661, grad/param norm = 1.9736e-01, time/batch = 17.9889s	
28202/30300 (epoch 46.538), train_loss = 0.86373380, grad/param norm = 2.2479e-01, time/batch = 18.1266s	
28203/30300 (epoch 46.540), train_loss = 0.92296833, grad/param norm = 1.8196e-01, time/batch = 16.7087s	
28204/30300 (epoch 46.541), train_loss = 0.95581563, grad/param norm = 1.9224e-01, time/batch = 18.1354s	
28205/30300 (epoch 46.543), train_loss = 0.94231629, grad/param norm = 1.7736e-01, time/batch = 17.7907s	
28206/30300 (epoch 46.545), train_loss = 1.03541443, grad/param norm = 3.1257e-01, time/batch = 18.4772s	
28207/30300 (epoch 46.546), train_loss = 1.13127246, grad/param norm = 1.7890e-01, time/batch = 18.0491s	
28208/30300 (epoch 46.548), train_loss = 0.92643453, grad/param norm = 1.6658e-01, time/batch = 18.6405s	
28209/30300 (epoch 46.550), train_loss = 1.01496349, grad/param norm = 2.1289e-01, time/batch = 18.1862s	
28210/30300 (epoch 46.551), train_loss = 0.89929116, grad/param norm = 1.8429e-01, time/batch = 18.5468s	
28211/30300 (epoch 46.553), train_loss = 0.94179263, grad/param norm = 1.9175e-01, time/batch = 19.3949s	
28212/30300 (epoch 46.554), train_loss = 0.95104214, grad/param norm = 1.7194e-01, time/batch = 18.2084s	
28213/30300 (epoch 46.556), train_loss = 1.00001020, grad/param norm = 1.8579e-01, time/batch = 18.5581s	
28214/30300 (epoch 46.558), train_loss = 1.07708424, grad/param norm = 2.0442e-01, time/batch = 19.3127s	
28215/30300 (epoch 46.559), train_loss = 0.97814777, grad/param norm = 1.7361e-01, time/batch = 17.9698s	
28216/30300 (epoch 46.561), train_loss = 0.78209471, grad/param norm = 1.9028e-01, time/batch = 19.0604s	
28217/30300 (epoch 46.563), train_loss = 0.85074905, grad/param norm = 1.8630e-01, time/batch = 18.9617s	
28218/30300 (epoch 46.564), train_loss = 0.92374726, grad/param norm = 1.6042e-01, time/batch = 16.9200s	
28219/30300 (epoch 46.566), train_loss = 0.94250228, grad/param norm = 1.8255e-01, time/batch = 16.1045s	
28220/30300 (epoch 46.568), train_loss = 0.82303673, grad/param norm = 2.0937e-01, time/batch = 17.0558s	
28221/30300 (epoch 46.569), train_loss = 0.98098399, grad/param norm = 1.6772e-01, time/batch = 15.2622s	
28222/30300 (epoch 46.571), train_loss = 0.96739347, grad/param norm = 1.8565e-01, time/batch = 16.6024s	
28223/30300 (epoch 46.573), train_loss = 0.98232002, grad/param norm = 1.6878e-01, time/batch = 16.6441s	
28224/30300 (epoch 46.574), train_loss = 0.98289163, grad/param norm = 1.7234e-01, time/batch = 18.8635s	
28225/30300 (epoch 46.576), train_loss = 0.93497937, grad/param norm = 1.5748e-01, time/batch = 18.8809s	
28226/30300 (epoch 46.578), train_loss = 0.82663094, grad/param norm = 1.6195e-01, time/batch = 19.4499s	
28227/30300 (epoch 46.579), train_loss = 1.01285194, grad/param norm = 2.0217e-01, time/batch = 17.7915s	
28228/30300 (epoch 46.581), train_loss = 1.06000543, grad/param norm = 1.6628e-01, time/batch = 18.7214s	
28229/30300 (epoch 46.583), train_loss = 1.10130884, grad/param norm = 3.0658e-01, time/batch = 18.7949s	
28230/30300 (epoch 46.584), train_loss = 1.06584376, grad/param norm = 1.7314e-01, time/batch = 18.4128s	
28231/30300 (epoch 46.586), train_loss = 0.91904829, grad/param norm = 1.6466e-01, time/batch = 19.2184s	
28232/30300 (epoch 46.587), train_loss = 0.94775207, grad/param norm = 1.7884e-01, time/batch = 19.2058s	
28233/30300 (epoch 46.589), train_loss = 0.89408341, grad/param norm = 1.7971e-01, time/batch = 19.2165s	
28234/30300 (epoch 46.591), train_loss = 1.00179428, grad/param norm = 1.6635e-01, time/batch = 15.7215s	
28235/30300 (epoch 46.592), train_loss = 0.92973622, grad/param norm = 1.5375e-01, time/batch = 17.6896s	
28236/30300 (epoch 46.594), train_loss = 1.02030194, grad/param norm = 1.7406e-01, time/batch = 19.2180s	
28237/30300 (epoch 46.596), train_loss = 0.88778774, grad/param norm = 2.0572e-01, time/batch = 18.8749s	
28238/30300 (epoch 46.597), train_loss = 0.90871585, grad/param norm = 1.8819e-01, time/batch = 17.6136s	
28239/30300 (epoch 46.599), train_loss = 0.82982942, grad/param norm = 1.7465e-01, time/batch = 19.0195s	
28240/30300 (epoch 46.601), train_loss = 0.98348037, grad/param norm = 2.1193e-01, time/batch = 19.2712s	
28241/30300 (epoch 46.602), train_loss = 0.96328603, grad/param norm = 1.5065e-01, time/batch = 18.0786s	
28242/30300 (epoch 46.604), train_loss = 0.89478170, grad/param norm = 1.9402e-01, time/batch = 17.1192s	
28243/30300 (epoch 46.606), train_loss = 0.90302779, grad/param norm = 2.2708e-01, time/batch = 19.3717s	
28244/30300 (epoch 46.607), train_loss = 1.01909616, grad/param norm = 1.9922e-01, time/batch = 19.0464s	
28245/30300 (epoch 46.609), train_loss = 1.13412559, grad/param norm = 1.9195e-01, time/batch = 18.1328s	
28246/30300 (epoch 46.611), train_loss = 0.95532025, grad/param norm = 1.6724e-01, time/batch = 18.5578s	
28247/30300 (epoch 46.612), train_loss = 0.87391492, grad/param norm = 1.4958e-01, time/batch = 19.1379s	
28248/30300 (epoch 46.614), train_loss = 0.94042159, grad/param norm = 1.6710e-01, time/batch = 17.2113s	
28249/30300 (epoch 46.616), train_loss = 0.97096300, grad/param norm = 2.3123e-01, time/batch = 16.8787s	
28250/30300 (epoch 46.617), train_loss = 0.94341605, grad/param norm = 1.8843e-01, time/batch = 18.8832s	
28251/30300 (epoch 46.619), train_loss = 0.78972425, grad/param norm = 1.5765e-01, time/batch = 18.1300s	
28252/30300 (epoch 46.620), train_loss = 1.00596546, grad/param norm = 1.8702e-01, time/batch = 18.7953s	
28253/30300 (epoch 46.622), train_loss = 0.94500920, grad/param norm = 1.9416e-01, time/batch = 18.4796s	
28254/30300 (epoch 46.624), train_loss = 0.94099462, grad/param norm = 2.1272e-01, time/batch = 18.3786s	
28255/30300 (epoch 46.625), train_loss = 0.95428362, grad/param norm = 2.1085e-01, time/batch = 18.6388s	
28256/30300 (epoch 46.627), train_loss = 1.06240223, grad/param norm = 2.3512e-01, time/batch = 17.9422s	
28257/30300 (epoch 46.629), train_loss = 1.06980340, grad/param norm = 1.7496e-01, time/batch = 19.2184s	
28258/30300 (epoch 46.630), train_loss = 0.95000200, grad/param norm = 1.5945e-01, time/batch = 18.2963s	
28259/30300 (epoch 46.632), train_loss = 0.98739412, grad/param norm = 1.7366e-01, time/batch = 18.6398s	
28260/30300 (epoch 46.634), train_loss = 0.88401935, grad/param norm = 1.6334e-01, time/batch = 18.5394s	
28261/30300 (epoch 46.635), train_loss = 0.98951546, grad/param norm = 1.9129e-01, time/batch = 17.5999s	
28262/30300 (epoch 46.637), train_loss = 1.03747139, grad/param norm = 2.0315e-01, time/batch = 18.8059s	
28263/30300 (epoch 46.639), train_loss = 0.94547364, grad/param norm = 1.9544e-01, time/batch = 18.7828s	
28264/30300 (epoch 46.640), train_loss = 1.06750068, grad/param norm = 2.0415e-01, time/batch = 17.7930s	
28265/30300 (epoch 46.642), train_loss = 0.95429519, grad/param norm = 1.7214e-01, time/batch = 19.2097s	
28266/30300 (epoch 46.644), train_loss = 1.03942390, grad/param norm = 1.8417e-01, time/batch = 18.6408s	
28267/30300 (epoch 46.645), train_loss = 0.90386187, grad/param norm = 1.6221e-01, time/batch = 18.2024s	
28268/30300 (epoch 46.647), train_loss = 0.94979701, grad/param norm = 1.7118e-01, time/batch = 18.3793s	
28269/30300 (epoch 46.649), train_loss = 0.95191836, grad/param norm = 2.0784e-01, time/batch = 18.7946s	
28270/30300 (epoch 46.650), train_loss = 0.96896107, grad/param norm = 1.6806e-01, time/batch = 19.2246s	
28271/30300 (epoch 46.652), train_loss = 0.94695702, grad/param norm = 1.7179e-01, time/batch = 32.8700s	
28272/30300 (epoch 46.653), train_loss = 1.10395726, grad/param norm = 1.5829e-01, time/batch = 18.7883s	
28273/30300 (epoch 46.655), train_loss = 0.94573143, grad/param norm = 1.9357e-01, time/batch = 16.1928s	
28274/30300 (epoch 46.657), train_loss = 0.87551474, grad/param norm = 1.8755e-01, time/batch = 18.4772s	
28275/30300 (epoch 46.658), train_loss = 0.93619416, grad/param norm = 1.6534e-01, time/batch = 19.3057s	
28276/30300 (epoch 46.660), train_loss = 0.94988643, grad/param norm = 1.7304e-01, time/batch = 17.8053s	
28277/30300 (epoch 46.662), train_loss = 0.96855856, grad/param norm = 1.9290e-01, time/batch = 16.9605s	
28278/30300 (epoch 46.663), train_loss = 1.03098466, grad/param norm = 1.8544e-01, time/batch = 19.2239s	
28279/30300 (epoch 46.665), train_loss = 0.89328808, grad/param norm = 2.1795e-01, time/batch = 19.0522s	
28280/30300 (epoch 46.667), train_loss = 1.00903528, grad/param norm = 1.8360e-01, time/batch = 17.8007s	
28281/30300 (epoch 46.668), train_loss = 1.04691433, grad/param norm = 1.8441e-01, time/batch = 19.0566s	
28282/30300 (epoch 46.670), train_loss = 1.07216811, grad/param norm = 1.8733e-01, time/batch = 17.2905s	
28283/30300 (epoch 46.672), train_loss = 0.95525383, grad/param norm = 1.8872e-01, time/batch = 16.7961s	
28284/30300 (epoch 46.673), train_loss = 1.02355568, grad/param norm = 2.0428e-01, time/batch = 19.3763s	
28285/30300 (epoch 46.675), train_loss = 0.95857316, grad/param norm = 2.1704e-01, time/batch = 18.8927s	
28286/30300 (epoch 46.677), train_loss = 0.92438206, grad/param norm = 2.0670e-01, time/batch = 17.4615s	
28287/30300 (epoch 46.678), train_loss = 0.92870556, grad/param norm = 1.6850e-01, time/batch = 16.6225s	
28288/30300 (epoch 46.680), train_loss = 0.87541670, grad/param norm = 1.6430e-01, time/batch = 17.8041s	
28289/30300 (epoch 46.682), train_loss = 0.95848282, grad/param norm = 1.7653e-01, time/batch = 18.8739s	
28290/30300 (epoch 46.683), train_loss = 1.02691560, grad/param norm = 1.8696e-01, time/batch = 17.4595s	
28291/30300 (epoch 46.685), train_loss = 1.02693489, grad/param norm = 2.0799e-01, time/batch = 17.7916s	
28292/30300 (epoch 46.686), train_loss = 0.95457681, grad/param norm = 1.6314e-01, time/batch = 19.6363s	
28293/30300 (epoch 46.688), train_loss = 0.96832614, grad/param norm = 1.5712e-01, time/batch = 17.5561s	
28294/30300 (epoch 46.690), train_loss = 0.93172736, grad/param norm = 2.9242e-01, time/batch = 18.7966s	
28295/30300 (epoch 46.691), train_loss = 0.96733055, grad/param norm = 1.9032e-01, time/batch = 18.2233s	
28296/30300 (epoch 46.693), train_loss = 1.22875711, grad/param norm = 2.1262e-01, time/batch = 17.0325s	
28297/30300 (epoch 46.695), train_loss = 1.04238918, grad/param norm = 1.9774e-01, time/batch = 18.7039s	
28298/30300 (epoch 46.696), train_loss = 1.01116759, grad/param norm = 2.2132e-01, time/batch = 18.7354s	
28299/30300 (epoch 46.698), train_loss = 0.93436534, grad/param norm = 1.9161e-01, time/batch = 18.1268s	
28300/30300 (epoch 46.700), train_loss = 0.90370836, grad/param norm = 1.8098e-01, time/batch = 18.5592s	
28301/30300 (epoch 46.701), train_loss = 0.85510652, grad/param norm = 1.6513e-01, time/batch = 18.4628s	
28302/30300 (epoch 46.703), train_loss = 0.96791302, grad/param norm = 1.7581e-01, time/batch = 19.1357s	
28303/30300 (epoch 46.705), train_loss = 0.88234939, grad/param norm = 1.7024e-01, time/batch = 16.9341s	
28304/30300 (epoch 46.706), train_loss = 1.02376885, grad/param norm = 1.7064e-01, time/batch = 18.5518s	
28305/30300 (epoch 46.708), train_loss = 0.96856037, grad/param norm = 1.6475e-01, time/batch = 18.2974s	
28306/30300 (epoch 46.710), train_loss = 0.94559090, grad/param norm = 1.8998e-01, time/batch = 17.3781s	
28307/30300 (epoch 46.711), train_loss = 0.90882769, grad/param norm = 1.8270e-01, time/batch = 18.7138s	
28308/30300 (epoch 46.713), train_loss = 0.91331375, grad/param norm = 2.1360e-01, time/batch = 18.8950s	
28309/30300 (epoch 46.715), train_loss = 0.93670956, grad/param norm = 1.6985e-01, time/batch = 18.4634s	
28310/30300 (epoch 46.716), train_loss = 1.01625728, grad/param norm = 1.7131e-01, time/batch = 19.1385s	
28311/30300 (epoch 46.718), train_loss = 1.06746275, grad/param norm = 1.7577e-01, time/batch = 18.7229s	
28312/30300 (epoch 46.719), train_loss = 0.91429688, grad/param norm = 1.9681e-01, time/batch = 16.4643s	
28313/30300 (epoch 46.721), train_loss = 0.93904297, grad/param norm = 1.7777e-01, time/batch = 16.8774s	
28314/30300 (epoch 46.723), train_loss = 0.90301743, grad/param norm = 1.6367e-01, time/batch = 17.7817s	
28315/30300 (epoch 46.724), train_loss = 0.97135420, grad/param norm = 1.8482e-01, time/batch = 18.7215s	
28316/30300 (epoch 46.726), train_loss = 1.23705394, grad/param norm = 2.7528e-01, time/batch = 16.3639s	
28317/30300 (epoch 46.728), train_loss = 1.01505051, grad/param norm = 1.9874e-01, time/batch = 18.4698s	
28318/30300 (epoch 46.729), train_loss = 0.92718147, grad/param norm = 1.9318e-01, time/batch = 18.9791s	
28319/30300 (epoch 46.731), train_loss = 0.91797750, grad/param norm = 1.9226e-01, time/batch = 18.3750s	
28320/30300 (epoch 46.733), train_loss = 0.97419620, grad/param norm = 1.9243e-01, time/batch = 18.6359s	
28321/30300 (epoch 46.734), train_loss = 1.04880597, grad/param norm = 1.7609e-01, time/batch = 18.2961s	
28322/30300 (epoch 46.736), train_loss = 0.99389307, grad/param norm = 1.8244e-01, time/batch = 17.7840s	
28323/30300 (epoch 46.738), train_loss = 0.91049096, grad/param norm = 1.5400e-01, time/batch = 18.7935s	
28324/30300 (epoch 46.739), train_loss = 1.07396555, grad/param norm = 1.7911e-01, time/batch = 19.4702s	
28325/30300 (epoch 46.741), train_loss = 1.09041544, grad/param norm = 2.0863e-01, time/batch = 18.7240s	
28326/30300 (epoch 46.743), train_loss = 0.93562972, grad/param norm = 1.8419e-01, time/batch = 18.0454s	
28327/30300 (epoch 46.744), train_loss = 1.00999551, grad/param norm = 1.8358e-01, time/batch = 19.0533s	
28328/30300 (epoch 46.746), train_loss = 0.94612333, grad/param norm = 1.8203e-01, time/batch = 18.4736s	
28329/30300 (epoch 46.748), train_loss = 0.95400418, grad/param norm = 2.0120e-01, time/batch = 18.1277s	
28330/30300 (epoch 46.749), train_loss = 0.98317582, grad/param norm = 1.8315e-01, time/batch = 17.5376s	
28331/30300 (epoch 46.751), train_loss = 1.01664557, grad/param norm = 1.7229e-01, time/batch = 19.0455s	
28332/30300 (epoch 46.752), train_loss = 0.94444511, grad/param norm = 1.7522e-01, time/batch = 18.1991s	
28333/30300 (epoch 46.754), train_loss = 0.96165756, grad/param norm = 1.8101e-01, time/batch = 19.1375s	
28334/30300 (epoch 46.756), train_loss = 0.95303858, grad/param norm = 1.7142e-01, time/batch = 17.6129s	
28335/30300 (epoch 46.757), train_loss = 0.88655486, grad/param norm = 1.7355e-01, time/batch = 18.4621s	
28336/30300 (epoch 46.759), train_loss = 0.97868814, grad/param norm = 1.6896e-01, time/batch = 18.2219s	
28337/30300 (epoch 46.761), train_loss = 0.83522300, grad/param norm = 1.6548e-01, time/batch = 18.7156s	
28338/30300 (epoch 46.762), train_loss = 0.86146449, grad/param norm = 1.6786e-01, time/batch = 18.2149s	
28339/30300 (epoch 46.764), train_loss = 0.94044509, grad/param norm = 1.9255e-01, time/batch = 17.0325s	
28340/30300 (epoch 46.766), train_loss = 1.09143087, grad/param norm = 2.0366e-01, time/batch = 19.0500s	
28341/30300 (epoch 46.767), train_loss = 0.95179765, grad/param norm = 2.2113e-01, time/batch = 18.5457s	
28342/30300 (epoch 46.769), train_loss = 0.97200077, grad/param norm = 1.9667e-01, time/batch = 17.6412s	
28343/30300 (epoch 46.771), train_loss = 0.90002467, grad/param norm = 2.0218e-01, time/batch = 18.1319s	
28344/30300 (epoch 46.772), train_loss = 0.94621844, grad/param norm = 1.7381e-01, time/batch = 18.5566s	
28345/30300 (epoch 46.774), train_loss = 1.13936580, grad/param norm = 1.9444e-01, time/batch = 17.8086s	
28346/30300 (epoch 46.776), train_loss = 0.93199020, grad/param norm = 1.9689e-01, time/batch = 18.2263s	
28347/30300 (epoch 46.777), train_loss = 1.08232873, grad/param norm = 1.7821e-01, time/batch = 18.1149s	
28348/30300 (epoch 46.779), train_loss = 1.10501525, grad/param norm = 2.3614e-01, time/batch = 17.7114s	
28349/30300 (epoch 46.781), train_loss = 0.96032522, grad/param norm = 1.9742e-01, time/batch = 18.8022s	
28350/30300 (epoch 46.782), train_loss = 0.91086168, grad/param norm = 2.1206e-01, time/batch = 15.6958s	
28351/30300 (epoch 46.784), train_loss = 0.92683938, grad/param norm = 1.9732e-01, time/batch = 15.6096s	
28352/30300 (epoch 46.785), train_loss = 1.01613717, grad/param norm = 2.2504e-01, time/batch = 16.4352s	
28353/30300 (epoch 46.787), train_loss = 0.82965521, grad/param norm = 1.8046e-01, time/batch = 18.9520s	
28354/30300 (epoch 46.789), train_loss = 1.10911763, grad/param norm = 1.9744e-01, time/batch = 18.6373s	
28355/30300 (epoch 46.790), train_loss = 0.94528469, grad/param norm = 2.0133e-01, time/batch = 17.7122s	
28356/30300 (epoch 46.792), train_loss = 0.78319394, grad/param norm = 1.8370e-01, time/batch = 17.5429s	
28357/30300 (epoch 46.794), train_loss = 0.98168234, grad/param norm = 2.2089e-01, time/batch = 17.9615s	
28358/30300 (epoch 46.795), train_loss = 0.89294722, grad/param norm = 1.6578e-01, time/batch = 18.9741s	
28359/30300 (epoch 46.797), train_loss = 1.10519487, grad/param norm = 2.1291e-01, time/batch = 17.2160s	
28360/30300 (epoch 46.799), train_loss = 1.03416152, grad/param norm = 2.2445e-01, time/batch = 19.3055s	
28361/30300 (epoch 46.800), train_loss = 1.01758993, grad/param norm = 1.7312e-01, time/batch = 19.2219s	
28362/30300 (epoch 46.802), train_loss = 1.21421264, grad/param norm = 2.2088e-01, time/batch = 18.0972s	
28363/30300 (epoch 46.804), train_loss = 1.01607657, grad/param norm = 1.9955e-01, time/batch = 18.7236s	
28364/30300 (epoch 46.805), train_loss = 1.10886640, grad/param norm = 2.0095e-01, time/batch = 18.3962s	
28365/30300 (epoch 46.807), train_loss = 0.93804753, grad/param norm = 1.9961e-01, time/batch = 17.9721s	
28366/30300 (epoch 46.809), train_loss = 1.06291015, grad/param norm = 1.9885e-01, time/batch = 18.1485s	
28367/30300 (epoch 46.810), train_loss = 1.03066407, grad/param norm = 1.9840e-01, time/batch = 18.9657s	
28368/30300 (epoch 46.812), train_loss = 0.93177597, grad/param norm = 1.6336e-01, time/batch = 18.0407s	
28369/30300 (epoch 46.814), train_loss = 0.97786285, grad/param norm = 1.8037e-01, time/batch = 16.9523s	
28370/30300 (epoch 46.815), train_loss = 0.98537694, grad/param norm = 2.2620e-01, time/batch = 18.8773s	
28371/30300 (epoch 46.817), train_loss = 1.03764139, grad/param norm = 1.7741e-01, time/batch = 17.5308s	
28372/30300 (epoch 46.818), train_loss = 1.01708393, grad/param norm = 2.0885e-01, time/batch = 18.6985s	
28373/30300 (epoch 46.820), train_loss = 1.14107482, grad/param norm = 1.9895e-01, time/batch = 17.7297s	
28374/30300 (epoch 46.822), train_loss = 1.11825449, grad/param norm = 1.9427e-01, time/batch = 18.9882s	
28375/30300 (epoch 46.823), train_loss = 1.10276706, grad/param norm = 2.1575e-01, time/batch = 18.3832s	
28376/30300 (epoch 46.825), train_loss = 1.10749843, grad/param norm = 1.8898e-01, time/batch = 18.9780s	
28377/30300 (epoch 46.827), train_loss = 0.83341106, grad/param norm = 2.1969e-01, time/batch = 19.3071s	
28378/30300 (epoch 46.828), train_loss = 1.08192065, grad/param norm = 1.9333e-01, time/batch = 18.2246s	
28379/30300 (epoch 46.830), train_loss = 1.02539497, grad/param norm = 1.8576e-01, time/batch = 19.2213s	
28380/30300 (epoch 46.832), train_loss = 0.90342349, grad/param norm = 1.7957e-01, time/batch = 18.3823s	
28381/30300 (epoch 46.833), train_loss = 0.98220203, grad/param norm = 1.8967e-01, time/batch = 17.6946s	
28382/30300 (epoch 46.835), train_loss = 0.91794712, grad/param norm = 1.8529e-01, time/batch = 18.7183s	
28383/30300 (epoch 46.837), train_loss = 0.88059426, grad/param norm = 1.7746e-01, time/batch = 18.9010s	
28384/30300 (epoch 46.838), train_loss = 0.89178978, grad/param norm = 1.7141e-01, time/batch = 17.7169s	
28385/30300 (epoch 46.840), train_loss = 1.03730930, grad/param norm = 1.7549e-01, time/batch = 18.5604s	
28386/30300 (epoch 46.842), train_loss = 0.96077924, grad/param norm = 1.6021e-01, time/batch = 18.8055s	
28387/30300 (epoch 46.843), train_loss = 1.01140762, grad/param norm = 1.7967e-01, time/batch = 17.8866s	
28388/30300 (epoch 46.845), train_loss = 1.02246232, grad/param norm = 1.6068e-01, time/batch = 16.6899s	
28389/30300 (epoch 46.847), train_loss = 0.97733677, grad/param norm = 1.9898e-01, time/batch = 18.4812s	
28390/30300 (epoch 46.848), train_loss = 1.02132445, grad/param norm = 2.0018e-01, time/batch = 18.0517s	
28391/30300 (epoch 46.850), train_loss = 0.96109605, grad/param norm = 1.6452e-01, time/batch = 18.6247s	
28392/30300 (epoch 46.851), train_loss = 1.01716330, grad/param norm = 2.0809e-01, time/batch = 18.1410s	
28393/30300 (epoch 46.853), train_loss = 0.95552350, grad/param norm = 1.8593e-01, time/batch = 19.1523s	
28394/30300 (epoch 46.855), train_loss = 0.92852700, grad/param norm = 1.6566e-01, time/batch = 16.4473s	
28395/30300 (epoch 46.856), train_loss = 0.97745880, grad/param norm = 1.9145e-01, time/batch = 16.5273s	
28396/30300 (epoch 46.858), train_loss = 0.89563745, grad/param norm = 1.6078e-01, time/batch = 17.8024s	
28397/30300 (epoch 46.860), train_loss = 0.88247979, grad/param norm = 1.6219e-01, time/batch = 16.0224s	
28398/30300 (epoch 46.861), train_loss = 1.10957329, grad/param norm = 1.8292e-01, time/batch = 17.9702s	
28399/30300 (epoch 46.863), train_loss = 0.92952863, grad/param norm = 1.6772e-01, time/batch = 18.5578s	
28400/30300 (epoch 46.865), train_loss = 1.02181377, grad/param norm = 2.0034e-01, time/batch = 18.3907s	
28401/30300 (epoch 46.866), train_loss = 1.03050612, grad/param norm = 1.8935e-01, time/batch = 17.7048s	
28402/30300 (epoch 46.868), train_loss = 1.00274687, grad/param norm = 1.8301e-01, time/batch = 18.4831s	
28403/30300 (epoch 46.870), train_loss = 0.91788310, grad/param norm = 1.7061e-01, time/batch = 19.0633s	
28404/30300 (epoch 46.871), train_loss = 0.99423730, grad/param norm = 1.7122e-01, time/batch = 17.8791s	
28405/30300 (epoch 46.873), train_loss = 0.98610471, grad/param norm = 1.6151e-01, time/batch = 18.7201s	
28406/30300 (epoch 46.875), train_loss = 0.93157817, grad/param norm = 1.6727e-01, time/batch = 16.7078s	
28407/30300 (epoch 46.876), train_loss = 0.86173114, grad/param norm = 1.8502e-01, time/batch = 19.5472s	
28408/30300 (epoch 46.878), train_loss = 0.81552458, grad/param norm = 1.6629e-01, time/batch = 18.2890s	
28409/30300 (epoch 46.880), train_loss = 0.88811256, grad/param norm = 1.7070e-01, time/batch = 18.9667s	
28410/30300 (epoch 46.881), train_loss = 1.11065631, grad/param norm = 2.0302e-01, time/batch = 17.7881s	
28411/30300 (epoch 46.883), train_loss = 1.03241874, grad/param norm = 1.8333e-01, time/batch = 17.8776s	
28412/30300 (epoch 46.884), train_loss = 0.97009089, grad/param norm = 1.6117e-01, time/batch = 18.7241s	
28413/30300 (epoch 46.886), train_loss = 1.01880055, grad/param norm = 1.7916e-01, time/batch = 18.1392s	
28414/30300 (epoch 46.888), train_loss = 0.93197039, grad/param norm = 1.7576e-01, time/batch = 17.7850s	
28415/30300 (epoch 46.889), train_loss = 1.01632715, grad/param norm = 1.7124e-01, time/batch = 19.3027s	
28416/30300 (epoch 46.891), train_loss = 0.95033890, grad/param norm = 1.8113e-01, time/batch = 17.8833s	
28417/30300 (epoch 46.893), train_loss = 1.16806477, grad/param norm = 1.8238e-01, time/batch = 18.2764s	
28418/30300 (epoch 46.894), train_loss = 0.98148381, grad/param norm = 1.8359e-01, time/batch = 18.6253s	
28419/30300 (epoch 46.896), train_loss = 0.84821684, grad/param norm = 1.7668e-01, time/batch = 18.6426s	
28420/30300 (epoch 46.898), train_loss = 0.82758054, grad/param norm = 1.9918e-01, time/batch = 18.1481s	
28421/30300 (epoch 46.899), train_loss = 0.87130817, grad/param norm = 1.7007e-01, time/batch = 17.2520s	
28422/30300 (epoch 46.901), train_loss = 0.96985801, grad/param norm = 2.1210e-01, time/batch = 19.2236s	
28423/30300 (epoch 46.903), train_loss = 0.95799801, grad/param norm = 2.0323e-01, time/batch = 19.3840s	
28424/30300 (epoch 46.904), train_loss = 0.97635345, grad/param norm = 1.6847e-01, time/batch = 16.7180s	
28425/30300 (epoch 46.906), train_loss = 0.97317826, grad/param norm = 1.7348e-01, time/batch = 19.3847s	
28426/30300 (epoch 46.908), train_loss = 0.92557332, grad/param norm = 1.6397e-01, time/batch = 19.2952s	
28427/30300 (epoch 46.909), train_loss = 0.94236382, grad/param norm = 2.0938e-01, time/batch = 17.9599s	
28428/30300 (epoch 46.911), train_loss = 0.94407427, grad/param norm = 1.6338e-01, time/batch = 18.0301s	
28429/30300 (epoch 46.913), train_loss = 0.95490570, grad/param norm = 1.5956e-01, time/batch = 18.8009s	
28430/30300 (epoch 46.914), train_loss = 0.94404779, grad/param norm = 1.9190e-01, time/batch = 18.2895s	
28431/30300 (epoch 46.916), train_loss = 0.99710440, grad/param norm = 1.6147e-01, time/batch = 18.4599s	
28432/30300 (epoch 46.917), train_loss = 0.92681753, grad/param norm = 1.7651e-01, time/batch = 18.2098s	
28433/30300 (epoch 46.919), train_loss = 0.84921369, grad/param norm = 1.7587e-01, time/batch = 18.8031s	
28434/30300 (epoch 46.921), train_loss = 0.95267203, grad/param norm = 1.6671e-01, time/batch = 18.1188s	
28435/30300 (epoch 46.922), train_loss = 1.05024114, grad/param norm = 1.9418e-01, time/batch = 18.9808s	
28436/30300 (epoch 46.924), train_loss = 0.96040554, grad/param norm = 1.9726e-01, time/batch = 17.6301s	
28437/30300 (epoch 46.926), train_loss = 1.01156777, grad/param norm = 1.7464e-01, time/batch = 17.3823s	
28438/30300 (epoch 46.927), train_loss = 0.98554367, grad/param norm = 1.6938e-01, time/batch = 18.0467s	
28439/30300 (epoch 46.929), train_loss = 0.91233852, grad/param norm = 1.9292e-01, time/batch = 18.8088s	
28440/30300 (epoch 46.931), train_loss = 1.02566672, grad/param norm = 2.0718e-01, time/batch = 17.7769s	
28441/30300 (epoch 46.932), train_loss = 0.90658675, grad/param norm = 1.6866e-01, time/batch = 18.5591s	
28442/30300 (epoch 46.934), train_loss = 0.99221067, grad/param norm = 1.7459e-01, time/batch = 18.7159s	
28443/30300 (epoch 46.936), train_loss = 0.93084332, grad/param norm = 1.8213e-01, time/batch = 18.4733s	
28444/30300 (epoch 46.937), train_loss = 0.92079676, grad/param norm = 1.6993e-01, time/batch = 18.3065s	
28445/30300 (epoch 46.939), train_loss = 1.07045803, grad/param norm = 2.0395e-01, time/batch = 18.9811s	
28446/30300 (epoch 46.941), train_loss = 0.94140452, grad/param norm = 1.7941e-01, time/batch = 18.8065s	
28447/30300 (epoch 46.942), train_loss = 0.94232934, grad/param norm = 1.8989e-01, time/batch = 17.6241s	
28448/30300 (epoch 46.944), train_loss = 0.86069398, grad/param norm = 1.6116e-01, time/batch = 19.1336s	
28449/30300 (epoch 46.946), train_loss = 1.01110072, grad/param norm = 1.9174e-01, time/batch = 18.3125s	
28450/30300 (epoch 46.947), train_loss = 0.99425774, grad/param norm = 2.4048e-01, time/batch = 17.0263s	
28451/30300 (epoch 46.949), train_loss = 1.05433689, grad/param norm = 2.4016e-01, time/batch = 19.2211s	
28452/30300 (epoch 46.950), train_loss = 1.07935250, grad/param norm = 2.0283e-01, time/batch = 18.2935s	
28453/30300 (epoch 46.952), train_loss = 0.99537536, grad/param norm = 2.0198e-01, time/batch = 17.1109s	
28454/30300 (epoch 46.954), train_loss = 1.19982375, grad/param norm = 1.7622e-01, time/batch = 18.2890s	
28455/30300 (epoch 46.955), train_loss = 0.96174677, grad/param norm = 1.6890e-01, time/batch = 18.5611s	
28456/30300 (epoch 46.957), train_loss = 1.02435056, grad/param norm = 1.8939e-01, time/batch = 18.4741s	
28457/30300 (epoch 46.959), train_loss = 0.87860631, grad/param norm = 1.7898e-01, time/batch = 18.9389s	
28458/30300 (epoch 46.960), train_loss = 0.93922784, grad/param norm = 1.8711e-01, time/batch = 18.6437s	
28459/30300 (epoch 46.962), train_loss = 0.91356601, grad/param norm = 2.2493e-01, time/batch = 18.9846s	
28460/30300 (epoch 46.964), train_loss = 0.88478299, grad/param norm = 1.9482e-01, time/batch = 17.7069s	
28461/30300 (epoch 46.965), train_loss = 0.89348401, grad/param norm = 2.1252e-01, time/batch = 18.8126s	
28462/30300 (epoch 46.967), train_loss = 0.92964018, grad/param norm = 2.1493e-01, time/batch = 17.8666s	
28463/30300 (epoch 46.969), train_loss = 0.90454657, grad/param norm = 1.9441e-01, time/batch = 17.6269s	
28464/30300 (epoch 46.970), train_loss = 0.94074840, grad/param norm = 1.7778e-01, time/batch = 18.8902s	
28465/30300 (epoch 46.972), train_loss = 0.86924120, grad/param norm = 2.0067e-01, time/batch = 18.2224s	
28466/30300 (epoch 46.974), train_loss = 1.08421264, grad/param norm = 2.0091e-01, time/batch = 22.4759s	
28467/30300 (epoch 46.975), train_loss = 1.08674507, grad/param norm = 2.0927e-01, time/batch = 26.8107s	
28468/30300 (epoch 46.977), train_loss = 1.16167206, grad/param norm = 1.8309e-01, time/batch = 16.7896s	
28469/30300 (epoch 46.979), train_loss = 1.01576075, grad/param norm = 1.7656e-01, time/batch = 16.2700s	
28470/30300 (epoch 46.980), train_loss = 1.06015473, grad/param norm = 2.0478e-01, time/batch = 18.7246s	
28471/30300 (epoch 46.982), train_loss = 1.03123399, grad/param norm = 1.8918e-01, time/batch = 18.8903s	
28472/30300 (epoch 46.983), train_loss = 1.07266952, grad/param norm = 1.7084e-01, time/batch = 17.9723s	
28473/30300 (epoch 46.985), train_loss = 1.02353577, grad/param norm = 3.1857e-01, time/batch = 18.1269s	
28474/30300 (epoch 46.987), train_loss = 1.00097624, grad/param norm = 1.6308e-01, time/batch = 18.3773s	
28475/30300 (epoch 46.988), train_loss = 1.09446163, grad/param norm = 1.9370e-01, time/batch = 18.2106s	
28476/30300 (epoch 46.990), train_loss = 0.91393565, grad/param norm = 1.8925e-01, time/batch = 19.0441s	
28477/30300 (epoch 46.992), train_loss = 1.06614786, grad/param norm = 1.6696e-01, time/batch = 18.5723s	
28478/30300 (epoch 46.993), train_loss = 1.06306610, grad/param norm = 2.3323e-01, time/batch = 18.2199s	
28479/30300 (epoch 46.995), train_loss = 0.96434695, grad/param norm = 2.2560e-01, time/batch = 17.2933s	
28480/30300 (epoch 46.997), train_loss = 1.03493698, grad/param norm = 1.7933e-01, time/batch = 18.4777s	
28481/30300 (epoch 46.998), train_loss = 1.06399797, grad/param norm = 2.0175e-01, time/batch = 17.4577s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
28482/30300 (epoch 47.000), train_loss = 0.91649808, grad/param norm = 2.3273e-01, time/batch = 17.8005s	
28483/30300 (epoch 47.002), train_loss = 1.09133319, grad/param norm = 2.1600e-01, time/batch = 18.5488s	
28484/30300 (epoch 47.003), train_loss = 1.00388858, grad/param norm = 1.8784e-01, time/batch = 17.9759s	
28485/30300 (epoch 47.005), train_loss = 0.95832256, grad/param norm = 1.8684e-01, time/batch = 18.2216s	
28486/30300 (epoch 47.007), train_loss = 1.04678210, grad/param norm = 2.1558e-01, time/batch = 17.4609s	
28487/30300 (epoch 47.008), train_loss = 0.98820068, grad/param norm = 2.1236e-01, time/batch = 17.9635s	
28488/30300 (epoch 47.010), train_loss = 0.87438640, grad/param norm = 1.8382e-01, time/batch = 18.4627s	
28489/30300 (epoch 47.012), train_loss = 0.95654942, grad/param norm = 1.8572e-01, time/batch = 19.1288s	
28490/30300 (epoch 47.013), train_loss = 1.07333510, grad/param norm = 1.8776e-01, time/batch = 18.6873s	
28491/30300 (epoch 47.015), train_loss = 0.93207425, grad/param norm = 1.7291e-01, time/batch = 18.8048s	
28492/30300 (epoch 47.017), train_loss = 0.96635793, grad/param norm = 1.5522e-01, time/batch = 17.7014s	
28493/30300 (epoch 47.018), train_loss = 0.86742263, grad/param norm = 1.6334e-01, time/batch = 18.3828s	
28494/30300 (epoch 47.020), train_loss = 1.07848350, grad/param norm = 1.9386e-01, time/batch = 18.6320s	
28495/30300 (epoch 47.021), train_loss = 1.08726946, grad/param norm = 1.7964e-01, time/batch = 17.8073s	
28496/30300 (epoch 47.023), train_loss = 1.01414094, grad/param norm = 1.7173e-01, time/batch = 18.0503s	
28497/30300 (epoch 47.025), train_loss = 0.91141830, grad/param norm = 1.9058e-01, time/batch = 16.9477s	
28498/30300 (epoch 47.026), train_loss = 1.07559475, grad/param norm = 2.2740e-01, time/batch = 18.4505s	
28499/30300 (epoch 47.028), train_loss = 1.03069634, grad/param norm = 1.7238e-01, time/batch = 18.7176s	
28500/30300 (epoch 47.030), train_loss = 0.94394539, grad/param norm = 1.8536e-01, time/batch = 18.7334s	
28501/30300 (epoch 47.031), train_loss = 1.01865507, grad/param norm = 1.7976e-01, time/batch = 17.8747s	
28502/30300 (epoch 47.033), train_loss = 1.01132706, grad/param norm = 1.9969e-01, time/batch = 17.1908s	
28503/30300 (epoch 47.035), train_loss = 0.99659595, grad/param norm = 1.8514e-01, time/batch = 19.4713s	
28504/30300 (epoch 47.036), train_loss = 1.01142699, grad/param norm = 1.6028e-01, time/batch = 19.0529s	
28505/30300 (epoch 47.038), train_loss = 1.04472967, grad/param norm = 1.6865e-01, time/batch = 18.1479s	
28506/30300 (epoch 47.040), train_loss = 0.86310878, grad/param norm = 1.6346e-01, time/batch = 18.9679s	
28507/30300 (epoch 47.041), train_loss = 0.82081737, grad/param norm = 1.9572e-01, time/batch = 18.6428s	
28508/30300 (epoch 47.043), train_loss = 1.02267369, grad/param norm = 1.9399e-01, time/batch = 18.3738s	
28509/30300 (epoch 47.045), train_loss = 0.91878605, grad/param norm = 1.7179e-01, time/batch = 18.2158s	
28510/30300 (epoch 47.046), train_loss = 1.09054153, grad/param norm = 1.9392e-01, time/batch = 17.5476s	
28511/30300 (epoch 47.048), train_loss = 1.00509600, grad/param norm = 2.0915e-01, time/batch = 18.2815s	
28512/30300 (epoch 47.050), train_loss = 0.89251535, grad/param norm = 1.8254e-01, time/batch = 18.3842s	
28513/30300 (epoch 47.051), train_loss = 1.00321824, grad/param norm = 1.8635e-01, time/batch = 18.3076s	
28514/30300 (epoch 47.053), train_loss = 0.85892365, grad/param norm = 2.8422e-01, time/batch = 18.3957s	
28515/30300 (epoch 47.054), train_loss = 1.01673081, grad/param norm = 1.7143e-01, time/batch = 9.6821s	
28516/30300 (epoch 47.056), train_loss = 0.91111397, grad/param norm = 1.9263e-01, time/batch = 0.6777s	
28517/30300 (epoch 47.058), train_loss = 0.94871086, grad/param norm = 1.9094e-01, time/batch = 0.6719s	
28518/30300 (epoch 47.059), train_loss = 0.93314703, grad/param norm = 1.8545e-01, time/batch = 0.6802s	
28519/30300 (epoch 47.061), train_loss = 1.03445934, grad/param norm = 2.0007e-01, time/batch = 0.6771s	
28520/30300 (epoch 47.063), train_loss = 0.87952200, grad/param norm = 1.8258e-01, time/batch = 0.6726s	
28521/30300 (epoch 47.064), train_loss = 0.95182517, grad/param norm = 1.8125e-01, time/batch = 0.6780s	
28522/30300 (epoch 47.066), train_loss = 0.99121440, grad/param norm = 1.8234e-01, time/batch = 0.7066s	
28523/30300 (epoch 47.068), train_loss = 0.95111586, grad/param norm = 1.8204e-01, time/batch = 0.9910s	
28524/30300 (epoch 47.069), train_loss = 1.03680215, grad/param norm = 1.9740e-01, time/batch = 0.9914s	
28525/30300 (epoch 47.071), train_loss = 1.00042488, grad/param norm = 1.7509e-01, time/batch = 0.9827s	
28526/30300 (epoch 47.073), train_loss = 0.90876441, grad/param norm = 1.9901e-01, time/batch = 0.9912s	
28527/30300 (epoch 47.074), train_loss = 0.93712060, grad/param norm = 1.6379e-01, time/batch = 1.0638s	
28528/30300 (epoch 47.076), train_loss = 0.96105945, grad/param norm = 1.7233e-01, time/batch = 1.9134s	
28529/30300 (epoch 47.078), train_loss = 0.89882339, grad/param norm = 1.7650e-01, time/batch = 1.8985s	
28530/30300 (epoch 47.079), train_loss = 0.94504866, grad/param norm = 1.7094e-01, time/batch = 9.5591s	
28531/30300 (epoch 47.081), train_loss = 0.98590609, grad/param norm = 1.8759e-01, time/batch = 19.3903s	
28532/30300 (epoch 47.083), train_loss = 1.04341746, grad/param norm = 2.4061e-01, time/batch = 17.0340s	
28533/30300 (epoch 47.084), train_loss = 0.93977487, grad/param norm = 1.7721e-01, time/batch = 17.8916s	
28534/30300 (epoch 47.086), train_loss = 0.91029292, grad/param norm = 1.7254e-01, time/batch = 18.8932s	
28535/30300 (epoch 47.087), train_loss = 0.92625231, grad/param norm = 1.6776e-01, time/batch = 18.3014s	
28536/30300 (epoch 47.089), train_loss = 0.88931341, grad/param norm = 1.7250e-01, time/batch = 18.7269s	
28537/30300 (epoch 47.091), train_loss = 1.01634661, grad/param norm = 1.8040e-01, time/batch = 19.3041s	
28538/30300 (epoch 47.092), train_loss = 1.03287691, grad/param norm = 1.7525e-01, time/batch = 17.0164s	
28539/30300 (epoch 47.094), train_loss = 1.05462333, grad/param norm = 2.0730e-01, time/batch = 18.7099s	
28540/30300 (epoch 47.096), train_loss = 1.10143573, grad/param norm = 1.8787e-01, time/batch = 18.3032s	
28541/30300 (epoch 47.097), train_loss = 0.93532216, grad/param norm = 2.0398e-01, time/batch = 19.2945s	
28542/30300 (epoch 47.099), train_loss = 1.02302657, grad/param norm = 1.7863e-01, time/batch = 18.1289s	
28543/30300 (epoch 47.101), train_loss = 1.06149705, grad/param norm = 2.1975e-01, time/batch = 20.1381s	
28544/30300 (epoch 47.102), train_loss = 0.90140453, grad/param norm = 1.8417e-01, time/batch = 19.0507s	
28545/30300 (epoch 47.104), train_loss = 0.94811361, grad/param norm = 2.0250e-01, time/batch = 18.1176s	
28546/30300 (epoch 47.106), train_loss = 0.89167619, grad/param norm = 1.8616e-01, time/batch = 20.3822s	
28547/30300 (epoch 47.107), train_loss = 1.03634713, grad/param norm = 1.6448e-01, time/batch = 20.1257s	
28548/30300 (epoch 47.109), train_loss = 1.04968375, grad/param norm = 2.2272e-01, time/batch = 18.3690s	
28549/30300 (epoch 47.111), train_loss = 1.01581240, grad/param norm = 1.9810e-01, time/batch = 16.9505s	
28550/30300 (epoch 47.112), train_loss = 1.09598061, grad/param norm = 1.9523e-01, time/batch = 19.0328s	
28551/30300 (epoch 47.114), train_loss = 0.92701658, grad/param norm = 1.6790e-01, time/batch = 18.7156s	
28552/30300 (epoch 47.116), train_loss = 1.01657369, grad/param norm = 2.0528e-01, time/batch = 19.9532s	
28553/30300 (epoch 47.117), train_loss = 1.07266947, grad/param norm = 1.8241e-01, time/batch = 19.2131s	
28554/30300 (epoch 47.119), train_loss = 0.87564351, grad/param norm = 2.5629e-01, time/batch = 18.8728s	
28555/30300 (epoch 47.120), train_loss = 0.94816210, grad/param norm = 2.0013e-01, time/batch = 19.7111s	
28556/30300 (epoch 47.122), train_loss = 1.07589286, grad/param norm = 2.2307e-01, time/batch = 19.5598s	
28557/30300 (epoch 47.124), train_loss = 1.14096341, grad/param norm = 2.1391e-01, time/batch = 17.8455s	
28558/30300 (epoch 47.125), train_loss = 0.89321788, grad/param norm = 1.7717e-01, time/batch = 19.4463s	
28559/30300 (epoch 47.127), train_loss = 0.99375349, grad/param norm = 2.6035e-01, time/batch = 20.0354s	
28560/30300 (epoch 47.129), train_loss = 1.02972510, grad/param norm = 1.9826e-01, time/batch = 19.4560s	
28561/30300 (epoch 47.130), train_loss = 1.10890337, grad/param norm = 1.8743e-01, time/batch = 19.6995s	
28562/30300 (epoch 47.132), train_loss = 1.09376293, grad/param norm = 1.9224e-01, time/batch = 18.8016s	
28563/30300 (epoch 47.134), train_loss = 0.91300861, grad/param norm = 2.0758e-01, time/batch = 18.9680s	
28564/30300 (epoch 47.135), train_loss = 0.92412625, grad/param norm = 1.8187e-01, time/batch = 18.7727s	
28565/30300 (epoch 47.137), train_loss = 0.98292615, grad/param norm = 2.1177e-01, time/batch = 19.1120s	
28566/30300 (epoch 47.139), train_loss = 0.89232667, grad/param norm = 2.1061e-01, time/batch = 19.1970s	
28567/30300 (epoch 47.140), train_loss = 0.96897098, grad/param norm = 2.3887e-01, time/batch = 18.0408s	
28568/30300 (epoch 47.142), train_loss = 1.04233137, grad/param norm = 2.6196e-01, time/batch = 19.4578s	
28569/30300 (epoch 47.144), train_loss = 0.88587332, grad/param norm = 2.1730e-01, time/batch = 19.7202s	
28570/30300 (epoch 47.145), train_loss = 1.04642795, grad/param norm = 2.2910e-01, time/batch = 17.9544s	
28571/30300 (epoch 47.147), train_loss = 0.95035611, grad/param norm = 2.0591e-01, time/batch = 19.5203s	
28572/30300 (epoch 47.149), train_loss = 1.03688220, grad/param norm = 2.0361e-01, time/batch = 18.6925s	
28573/30300 (epoch 47.150), train_loss = 0.94101623, grad/param norm = 2.2289e-01, time/batch = 17.6971s	
28574/30300 (epoch 47.152), train_loss = 0.89798741, grad/param norm = 2.2045e-01, time/batch = 19.5524s	
28575/30300 (epoch 47.153), train_loss = 0.99239676, grad/param norm = 2.2860e-01, time/batch = 19.1433s	
28576/30300 (epoch 47.155), train_loss = 0.85617137, grad/param norm = 1.8551e-01, time/batch = 18.6153s	
28577/30300 (epoch 47.157), train_loss = 0.91717572, grad/param norm = 2.0293e-01, time/batch = 18.3750s	
28578/30300 (epoch 47.158), train_loss = 1.01854058, grad/param norm = 2.4199e-01, time/batch = 19.7136s	
28579/30300 (epoch 47.160), train_loss = 0.91102851, grad/param norm = 2.2335e-01, time/batch = 19.1918s	
28580/30300 (epoch 47.162), train_loss = 0.95340585, grad/param norm = 1.6384e-01, time/batch = 19.2018s	
28581/30300 (epoch 47.163), train_loss = 0.98497794, grad/param norm = 2.1594e-01, time/batch = 18.7813s	
28582/30300 (epoch 47.165), train_loss = 1.08085539, grad/param norm = 1.8849e-01, time/batch = 19.2112s	
28583/30300 (epoch 47.167), train_loss = 0.98270233, grad/param norm = 1.9736e-01, time/batch = 19.2923s	
28584/30300 (epoch 47.168), train_loss = 1.01052499, grad/param norm = 1.8301e-01, time/batch = 20.0458s	
28585/30300 (epoch 47.170), train_loss = 1.01246298, grad/param norm = 2.2183e-01, time/batch = 19.8765s	
28586/30300 (epoch 47.172), train_loss = 0.98654545, grad/param norm = 2.0572e-01, time/batch = 18.7902s	
28587/30300 (epoch 47.173), train_loss = 0.96291713, grad/param norm = 2.4795e-01, time/batch = 15.0916s	
28588/30300 (epoch 47.175), train_loss = 1.00695706, grad/param norm = 1.8860e-01, time/batch = 14.5893s	
28589/30300 (epoch 47.177), train_loss = 1.04607817, grad/param norm = 2.0838e-01, time/batch = 18.6200s	
28590/30300 (epoch 47.178), train_loss = 0.80744696, grad/param norm = 1.5985e-01, time/batch = 20.1301s	
28591/30300 (epoch 47.180), train_loss = 0.95304366, grad/param norm = 1.7147e-01, time/batch = 18.4422s	
28592/30300 (epoch 47.182), train_loss = 1.00108016, grad/param norm = 1.9957e-01, time/batch = 18.7876s	
28593/30300 (epoch 47.183), train_loss = 0.92371379, grad/param norm = 2.2802e-01, time/batch = 19.5481s	
28594/30300 (epoch 47.185), train_loss = 1.09330511, grad/param norm = 1.9597e-01, time/batch = 19.7167s	
28595/30300 (epoch 47.186), train_loss = 1.19034532, grad/param norm = 2.4440e-01, time/batch = 19.6265s	
28596/30300 (epoch 47.188), train_loss = 1.03327152, grad/param norm = 2.0053e-01, time/batch = 19.0456s	
28597/30300 (epoch 47.190), train_loss = 0.96301070, grad/param norm = 1.7079e-01, time/batch = 18.6982s	
28598/30300 (epoch 47.191), train_loss = 1.02486055, grad/param norm = 1.9749e-01, time/batch = 18.6912s	
28599/30300 (epoch 47.193), train_loss = 0.90190711, grad/param norm = 1.9731e-01, time/batch = 19.2881s	
28600/30300 (epoch 47.195), train_loss = 0.93466059, grad/param norm = 1.7790e-01, time/batch = 19.0498s	
28601/30300 (epoch 47.196), train_loss = 1.02093294, grad/param norm = 1.6901e-01, time/batch = 19.9608s	
28602/30300 (epoch 47.198), train_loss = 0.83835619, grad/param norm = 2.0618e-01, time/batch = 19.0341s	
28603/30300 (epoch 47.200), train_loss = 0.95105400, grad/param norm = 1.7088e-01, time/batch = 19.5543s	
28604/30300 (epoch 47.201), train_loss = 1.05780088, grad/param norm = 3.0060e-01, time/batch = 19.2821s	
28605/30300 (epoch 47.203), train_loss = 0.98442567, grad/param norm = 1.8911e-01, time/batch = 18.9400s	
28606/30300 (epoch 47.205), train_loss = 1.12771499, grad/param norm = 2.0588e-01, time/batch = 19.6196s	
28607/30300 (epoch 47.206), train_loss = 1.08358323, grad/param norm = 2.0698e-01, time/batch = 20.1221s	
28608/30300 (epoch 47.208), train_loss = 1.06808773, grad/param norm = 3.1201e-01, time/batch = 18.7774s	
28609/30300 (epoch 47.210), train_loss = 1.04963890, grad/param norm = 1.6450e-01, time/batch = 17.6077s	
28610/30300 (epoch 47.211), train_loss = 1.10998924, grad/param norm = 2.0099e-01, time/batch = 19.2150s	
28611/30300 (epoch 47.213), train_loss = 1.00883975, grad/param norm = 1.6668e-01, time/batch = 18.1994s	
28612/30300 (epoch 47.215), train_loss = 0.91278153, grad/param norm = 2.0172e-01, time/batch = 18.8376s	
28613/30300 (epoch 47.216), train_loss = 0.91891855, grad/param norm = 1.5708e-01, time/batch = 19.9451s	
28614/30300 (epoch 47.218), train_loss = 0.89946668, grad/param norm = 1.6604e-01, time/batch = 18.3770s	
28615/30300 (epoch 47.219), train_loss = 0.84778044, grad/param norm = 1.6793e-01, time/batch = 19.8716s	
28616/30300 (epoch 47.221), train_loss = 0.84833159, grad/param norm = 1.7622e-01, time/batch = 19.3027s	
28617/30300 (epoch 47.223), train_loss = 0.98375828, grad/param norm = 1.8788e-01, time/batch = 19.2964s	
28618/30300 (epoch 47.224), train_loss = 0.81597189, grad/param norm = 1.9001e-01, time/batch = 19.2823s	
28619/30300 (epoch 47.226), train_loss = 1.03827206, grad/param norm = 2.4701e-01, time/batch = 20.0960s	
28620/30300 (epoch 47.228), train_loss = 1.09779447, grad/param norm = 2.0849e-01, time/batch = 18.2973s	
28621/30300 (epoch 47.229), train_loss = 0.97057994, grad/param norm = 1.8282e-01, time/batch = 19.1242s	
28622/30300 (epoch 47.231), train_loss = 1.05594086, grad/param norm = 2.1254e-01, time/batch = 19.7956s	
28623/30300 (epoch 47.233), train_loss = 1.04392746, grad/param norm = 1.6594e-01, time/batch = 18.8036s	
28624/30300 (epoch 47.234), train_loss = 1.05744380, grad/param norm = 2.5250e-01, time/batch = 18.1868s	
28625/30300 (epoch 47.236), train_loss = 1.02525888, grad/param norm = 1.7016e-01, time/batch = 18.8758s	
28626/30300 (epoch 47.238), train_loss = 0.98089765, grad/param norm = 2.3841e-01, time/batch = 19.7980s	
28627/30300 (epoch 47.239), train_loss = 0.93750738, grad/param norm = 2.2305e-01, time/batch = 19.2166s	
28628/30300 (epoch 47.241), train_loss = 1.01563813, grad/param norm = 2.0490e-01, time/batch = 19.0387s	
28629/30300 (epoch 47.243), train_loss = 1.04546769, grad/param norm = 2.1704e-01, time/batch = 19.7865s	
28630/30300 (epoch 47.244), train_loss = 1.17207119, grad/param norm = 1.9446e-01, time/batch = 18.7780s	
28631/30300 (epoch 47.246), train_loss = 1.04302076, grad/param norm = 1.8807e-01, time/batch = 19.0272s	
28632/30300 (epoch 47.248), train_loss = 0.99600429, grad/param norm = 1.8419e-01, time/batch = 19.9551s	
28633/30300 (epoch 47.249), train_loss = 0.88250085, grad/param norm = 1.8448e-01, time/batch = 18.5085s	
28634/30300 (epoch 47.251), train_loss = 0.91491114, grad/param norm = 1.8828e-01, time/batch = 20.0272s	
28635/30300 (epoch 47.252), train_loss = 1.06079399, grad/param norm = 1.8816e-01, time/batch = 19.2067s	
28636/30300 (epoch 47.254), train_loss = 1.05941334, grad/param norm = 2.3524e-01, time/batch = 17.6094s	
28637/30300 (epoch 47.256), train_loss = 1.02024441, grad/param norm = 1.8565e-01, time/batch = 19.7115s	
28638/30300 (epoch 47.257), train_loss = 1.04665654, grad/param norm = 2.0765e-01, time/batch = 19.3699s	
28639/30300 (epoch 47.259), train_loss = 0.96976365, grad/param norm = 1.8247e-01, time/batch = 17.7913s	
28640/30300 (epoch 47.261), train_loss = 1.12727905, grad/param norm = 1.9050e-01, time/batch = 19.2891s	
28641/30300 (epoch 47.262), train_loss = 0.90631409, grad/param norm = 1.7326e-01, time/batch = 19.5577s	
28642/30300 (epoch 47.264), train_loss = 0.99817303, grad/param norm = 2.6787e-01, time/batch = 18.8740s	
28643/30300 (epoch 47.266), train_loss = 0.99768720, grad/param norm = 1.7295e-01, time/batch = 19.3803s	
28644/30300 (epoch 47.267), train_loss = 1.12153978, grad/param norm = 2.2008e-01, time/batch = 17.0264s	
28645/30300 (epoch 47.269), train_loss = 1.02630035, grad/param norm = 1.9112e-01, time/batch = 19.2123s	
28646/30300 (epoch 47.271), train_loss = 1.00393445, grad/param norm = 1.8680e-01, time/batch = 17.1325s	
28647/30300 (epoch 47.272), train_loss = 0.98908931, grad/param norm = 2.0849e-01, time/batch = 19.8729s	
28648/30300 (epoch 47.274), train_loss = 1.04992152, grad/param norm = 1.9088e-01, time/batch = 18.9783s	
28649/30300 (epoch 47.276), train_loss = 0.99592768, grad/param norm = 2.0051e-01, time/batch = 19.3685s	
28650/30300 (epoch 47.277), train_loss = 0.89289792, grad/param norm = 1.7631e-01, time/batch = 15.0340s	
28651/30300 (epoch 47.279), train_loss = 0.98375868, grad/param norm = 1.8118e-01, time/batch = 19.6941s	
28652/30300 (epoch 47.281), train_loss = 1.08818668, grad/param norm = 2.3778e-01, time/batch = 17.4611s	
28653/30300 (epoch 47.282), train_loss = 1.01048132, grad/param norm = 1.7404e-01, time/batch = 20.3712s	
28654/30300 (epoch 47.284), train_loss = 1.06159231, grad/param norm = 2.3357e-01, time/batch = 19.8753s	
28655/30300 (epoch 47.285), train_loss = 1.04805342, grad/param norm = 1.6858e-01, time/batch = 18.3686s	
28656/30300 (epoch 47.287), train_loss = 0.99591897, grad/param norm = 2.0477e-01, time/batch = 20.2183s	
28657/30300 (epoch 47.289), train_loss = 1.08394995, grad/param norm = 1.9972e-01, time/batch = 18.4397s	
28658/30300 (epoch 47.290), train_loss = 0.79742930, grad/param norm = 1.9105e-01, time/batch = 19.1297s	
28659/30300 (epoch 47.292), train_loss = 0.90384992, grad/param norm = 1.8887e-01, time/batch = 18.8835s	
28660/30300 (epoch 47.294), train_loss = 1.04297222, grad/param norm = 2.4957e-01, time/batch = 17.8739s	
28661/30300 (epoch 47.295), train_loss = 0.95799731, grad/param norm = 1.9454e-01, time/batch = 19.3737s	
28662/30300 (epoch 47.297), train_loss = 0.96156182, grad/param norm = 1.7269e-01, time/batch = 17.8587s	
28663/30300 (epoch 47.299), train_loss = 0.98720155, grad/param norm = 1.8661e-01, time/batch = 19.6393s	
28664/30300 (epoch 47.300), train_loss = 0.90856360, grad/param norm = 1.7731e-01, time/batch = 19.4636s	
28665/30300 (epoch 47.302), train_loss = 1.05241344, grad/param norm = 2.0672e-01, time/batch = 20.1278s	
28666/30300 (epoch 47.304), train_loss = 0.92412805, grad/param norm = 1.8874e-01, time/batch = 19.9624s	
28667/30300 (epoch 47.305), train_loss = 1.00549511, grad/param norm = 1.8782e-01, time/batch = 18.7055s	
28668/30300 (epoch 47.307), train_loss = 1.06800077, grad/param norm = 1.7035e-01, time/batch = 19.2163s	
28669/30300 (epoch 47.309), train_loss = 1.01296901, grad/param norm = 1.7850e-01, time/batch = 19.0515s	
28670/30300 (epoch 47.310), train_loss = 0.95647972, grad/param norm = 1.8164e-01, time/batch = 19.7170s	
28671/30300 (epoch 47.312), train_loss = 1.10990009, grad/param norm = 1.7314e-01, time/batch = 34.3767s	
28672/30300 (epoch 47.314), train_loss = 0.97342853, grad/param norm = 1.9050e-01, time/batch = 20.3719s	
28673/30300 (epoch 47.315), train_loss = 0.94091847, grad/param norm = 1.9554e-01, time/batch = 18.1937s	
28674/30300 (epoch 47.317), train_loss = 1.01181963, grad/param norm = 1.7925e-01, time/batch = 20.3022s	
28675/30300 (epoch 47.318), train_loss = 1.02703689, grad/param norm = 2.0202e-01, time/batch = 19.0517s	
28676/30300 (epoch 47.320), train_loss = 1.02953380, grad/param norm = 1.9386e-01, time/batch = 18.6177s	
28677/30300 (epoch 47.322), train_loss = 0.91684415, grad/param norm = 1.7207e-01, time/batch = 19.2798s	
28678/30300 (epoch 47.323), train_loss = 1.07904858, grad/param norm = 1.8647e-01, time/batch = 17.6061s	
28679/30300 (epoch 47.325), train_loss = 0.96127851, grad/param norm = 1.7457e-01, time/batch = 19.2877s	
28680/30300 (epoch 47.327), train_loss = 0.96470222, grad/param norm = 1.8418e-01, time/batch = 18.6278s	
28681/30300 (epoch 47.328), train_loss = 1.02056253, grad/param norm = 1.7108e-01, time/batch = 20.2035s	
28682/30300 (epoch 47.330), train_loss = 1.02246153, grad/param norm = 1.6992e-01, time/batch = 18.3814s	
28683/30300 (epoch 47.332), train_loss = 1.08288122, grad/param norm = 2.1781e-01, time/batch = 19.1939s	
28684/30300 (epoch 47.333), train_loss = 0.91260702, grad/param norm = 2.1596e-01, time/batch = 19.5465s	
28685/30300 (epoch 47.335), train_loss = 0.89370984, grad/param norm = 1.7321e-01, time/batch = 19.0293s	
28686/30300 (epoch 47.337), train_loss = 1.09034984, grad/param norm = 1.8614e-01, time/batch = 19.7132s	
28687/30300 (epoch 47.338), train_loss = 0.93939956, grad/param norm = 1.7387e-01, time/batch = 19.7963s	
28688/30300 (epoch 47.340), train_loss = 0.95718201, grad/param norm = 1.8310e-01, time/batch = 18.9646s	
28689/30300 (epoch 47.342), train_loss = 1.07020353, grad/param norm = 1.8177e-01, time/batch = 19.7878s	
28690/30300 (epoch 47.343), train_loss = 1.03742206, grad/param norm = 2.1644e-01, time/batch = 18.0993s	
28691/30300 (epoch 47.345), train_loss = 1.00911845, grad/param norm = 1.6963e-01, time/batch = 19.0367s	
28692/30300 (epoch 47.347), train_loss = 0.89413238, grad/param norm = 1.6710e-01, time/batch = 19.0267s	
28693/30300 (epoch 47.348), train_loss = 0.94137102, grad/param norm = 1.7731e-01, time/batch = 19.8784s	
28694/30300 (epoch 47.350), train_loss = 0.97185850, grad/param norm = 1.9124e-01, time/batch = 20.0569s	
28695/30300 (epoch 47.351), train_loss = 0.96008737, grad/param norm = 1.7974e-01, time/batch = 19.3736s	
28696/30300 (epoch 47.353), train_loss = 0.89836377, grad/param norm = 1.8122e-01, time/batch = 18.6436s	
28697/30300 (epoch 47.355), train_loss = 0.93789568, grad/param norm = 1.8057e-01, time/batch = 19.7951s	
28698/30300 (epoch 47.356), train_loss = 1.02906895, grad/param norm = 2.0239e-01, time/batch = 19.1924s	
28699/30300 (epoch 47.358), train_loss = 1.22149636, grad/param norm = 1.8497e-01, time/batch = 17.0384s	
28700/30300 (epoch 47.360), train_loss = 0.94676021, grad/param norm = 1.7113e-01, time/batch = 19.6302s	
28701/30300 (epoch 47.361), train_loss = 0.98855316, grad/param norm = 2.0887e-01, time/batch = 17.8668s	
28702/30300 (epoch 47.363), train_loss = 1.02107920, grad/param norm = 2.0420e-01, time/batch = 19.5294s	
28703/30300 (epoch 47.365), train_loss = 0.83647236, grad/param norm = 2.0440e-01, time/batch = 19.6380s	
28704/30300 (epoch 47.366), train_loss = 0.96218732, grad/param norm = 1.8514e-01, time/batch = 18.6210s	
28705/30300 (epoch 47.368), train_loss = 0.86490854, grad/param norm = 1.8076e-01, time/batch = 19.0355s	
28706/30300 (epoch 47.370), train_loss = 0.90061903, grad/param norm = 2.1258e-01, time/batch = 18.4275s	
28707/30300 (epoch 47.371), train_loss = 1.05143656, grad/param norm = 1.9568e-01, time/batch = 18.7885s	
28708/30300 (epoch 47.373), train_loss = 0.91755815, grad/param norm = 1.6273e-01, time/batch = 18.7151s	
28709/30300 (epoch 47.375), train_loss = 0.92115804, grad/param norm = 1.7145e-01, time/batch = 17.9360s	
28710/30300 (epoch 47.376), train_loss = 0.92486844, grad/param norm = 1.6914e-01, time/batch = 15.7072s	
28711/30300 (epoch 47.378), train_loss = 0.88735237, grad/param norm = 1.7398e-01, time/batch = 16.3517s	
28712/30300 (epoch 47.380), train_loss = 1.08524366, grad/param norm = 1.8371e-01, time/batch = 19.8710s	
28713/30300 (epoch 47.381), train_loss = 0.82220964, grad/param norm = 1.6491e-01, time/batch = 19.4571s	
28714/30300 (epoch 47.383), train_loss = 0.88648523, grad/param norm = 2.0559e-01, time/batch = 18.3662s	
28715/30300 (epoch 47.384), train_loss = 1.02570679, grad/param norm = 2.2554e-01, time/batch = 19.2105s	
28716/30300 (epoch 47.386), train_loss = 0.88224372, grad/param norm = 1.7786e-01, time/batch = 19.8753s	
28717/30300 (epoch 47.388), train_loss = 0.86773132, grad/param norm = 1.6790e-01, time/batch = 18.1176s	
28718/30300 (epoch 47.389), train_loss = 0.96665681, grad/param norm = 1.9295e-01, time/batch = 18.6242s	
28719/30300 (epoch 47.391), train_loss = 1.01126105, grad/param norm = 1.7285e-01, time/batch = 17.6226s	
28720/30300 (epoch 47.393), train_loss = 0.86051883, grad/param norm = 1.6454e-01, time/batch = 18.4544s	
28721/30300 (epoch 47.394), train_loss = 0.99619591, grad/param norm = 2.1171e-01, time/batch = 19.5440s	
28722/30300 (epoch 47.396), train_loss = 1.11321177, grad/param norm = 1.8206e-01, time/batch = 19.8734s	
28723/30300 (epoch 47.398), train_loss = 0.95322368, grad/param norm = 1.8492e-01, time/batch = 18.6864s	
28724/30300 (epoch 47.399), train_loss = 0.86842065, grad/param norm = 1.7631e-01, time/batch = 19.2976s	
28725/30300 (epoch 47.401), train_loss = 0.99760335, grad/param norm = 2.3626e-01, time/batch = 18.5487s	
28726/30300 (epoch 47.403), train_loss = 0.97747231, grad/param norm = 2.0511e-01, time/batch = 17.8542s	
28727/30300 (epoch 47.404), train_loss = 0.91807498, grad/param norm = 1.9793e-01, time/batch = 18.7027s	
28728/30300 (epoch 47.406), train_loss = 0.96868607, grad/param norm = 1.6706e-01, time/batch = 18.9494s	
28729/30300 (epoch 47.408), train_loss = 0.85263759, grad/param norm = 1.6092e-01, time/batch = 16.6204s	
28730/30300 (epoch 47.409), train_loss = 0.86989119, grad/param norm = 1.8781e-01, time/batch = 16.0889s	
28731/30300 (epoch 47.411), train_loss = 0.90669039, grad/param norm = 1.5105e-01, time/batch = 16.6840s	
28732/30300 (epoch 47.413), train_loss = 0.81822597, grad/param norm = 1.8019e-01, time/batch = 18.9524s	
28733/30300 (epoch 47.414), train_loss = 0.99805360, grad/param norm = 1.8449e-01, time/batch = 17.8494s	
28734/30300 (epoch 47.416), train_loss = 0.90684275, grad/param norm = 1.7277e-01, time/batch = 17.4224s	
28735/30300 (epoch 47.417), train_loss = 0.88960348, grad/param norm = 1.8688e-01, time/batch = 19.5460s	
28736/30300 (epoch 47.419), train_loss = 0.86881879, grad/param norm = 1.7629e-01, time/batch = 18.3621s	
28737/30300 (epoch 47.421), train_loss = 0.93379160, grad/param norm = 2.0153e-01, time/batch = 18.9526s	
28738/30300 (epoch 47.422), train_loss = 0.97009510, grad/param norm = 1.8939e-01, time/batch = 18.7188s	
28739/30300 (epoch 47.424), train_loss = 0.98471945, grad/param norm = 2.1333e-01, time/batch = 19.0338s	
28740/30300 (epoch 47.426), train_loss = 0.96066069, grad/param norm = 1.8243e-01, time/batch = 18.5386s	
28741/30300 (epoch 47.427), train_loss = 0.92910193, grad/param norm = 1.8085e-01, time/batch = 18.0519s	
28742/30300 (epoch 47.429), train_loss = 0.95079551, grad/param norm = 1.6233e-01, time/batch = 15.9499s	
28743/30300 (epoch 47.431), train_loss = 0.97905877, grad/param norm = 1.8168e-01, time/batch = 16.1753s	
28744/30300 (epoch 47.432), train_loss = 0.98436764, grad/param norm = 1.7866e-01, time/batch = 16.4390s	
28745/30300 (epoch 47.434), train_loss = 0.85627445, grad/param norm = 1.7872e-01, time/batch = 15.0516s	
28746/30300 (epoch 47.436), train_loss = 1.05958299, grad/param norm = 2.0719e-01, time/batch = 16.4317s	
28747/30300 (epoch 47.437), train_loss = 0.87585047, grad/param norm = 1.6690e-01, time/batch = 16.3328s	
28748/30300 (epoch 47.439), train_loss = 0.93640126, grad/param norm = 1.6985e-01, time/batch = 16.7791s	
28749/30300 (epoch 47.441), train_loss = 0.95664101, grad/param norm = 1.7088e-01, time/batch = 18.9640s	
28750/30300 (epoch 47.442), train_loss = 0.89521627, grad/param norm = 1.6754e-01, time/batch = 18.8672s	
28751/30300 (epoch 47.444), train_loss = 0.80686825, grad/param norm = 1.5858e-01, time/batch = 19.4655s	
28752/30300 (epoch 47.446), train_loss = 0.91499732, grad/param norm = 1.6174e-01, time/batch = 18.9682s	
28753/30300 (epoch 47.447), train_loss = 0.97898861, grad/param norm = 2.2313e-01, time/batch = 17.2887s	
28754/30300 (epoch 47.449), train_loss = 0.90918440, grad/param norm = 1.7659e-01, time/batch = 18.5349s	
28755/30300 (epoch 47.450), train_loss = 0.99913135, grad/param norm = 1.6834e-01, time/batch = 19.7046s	
28756/30300 (epoch 47.452), train_loss = 1.06604721, grad/param norm = 1.6868e-01, time/batch = 16.9110s	
28757/30300 (epoch 47.454), train_loss = 1.00912140, grad/param norm = 1.7593e-01, time/batch = 18.4420s	
28758/30300 (epoch 47.455), train_loss = 0.97843520, grad/param norm = 1.8988e-01, time/batch = 18.9506s	
28759/30300 (epoch 47.457), train_loss = 0.94935800, grad/param norm = 1.6003e-01, time/batch = 15.6284s	
28760/30300 (epoch 47.459), train_loss = 0.99701629, grad/param norm = 1.8967e-01, time/batch = 16.0067s	
28761/30300 (epoch 47.460), train_loss = 1.05252688, grad/param norm = 1.8110e-01, time/batch = 16.2671s	
28762/30300 (epoch 47.462), train_loss = 1.03653123, grad/param norm = 1.7831e-01, time/batch = 19.1191s	
28763/30300 (epoch 47.464), train_loss = 0.78375329, grad/param norm = 1.7501e-01, time/batch = 18.9543s	
28764/30300 (epoch 47.465), train_loss = 0.82504729, grad/param norm = 1.6196e-01, time/batch = 18.0465s	
28765/30300 (epoch 47.467), train_loss = 0.82310096, grad/param norm = 1.6180e-01, time/batch = 19.9654s	
28766/30300 (epoch 47.469), train_loss = 0.90442027, grad/param norm = 1.8268e-01, time/batch = 19.4621s	
28767/30300 (epoch 47.470), train_loss = 0.91441367, grad/param norm = 1.9240e-01, time/batch = 17.8544s	
28768/30300 (epoch 47.472), train_loss = 0.91131015, grad/param norm = 1.5584e-01, time/batch = 19.2923s	
28769/30300 (epoch 47.474), train_loss = 0.91572159, grad/param norm = 2.4969e-01, time/batch = 18.0207s	
28770/30300 (epoch 47.475), train_loss = 0.89277902, grad/param norm = 1.8998e-01, time/batch = 17.7087s	
28771/30300 (epoch 47.477), train_loss = 0.94139578, grad/param norm = 1.7477e-01, time/batch = 19.0297s	
28772/30300 (epoch 47.479), train_loss = 0.90921001, grad/param norm = 1.8205e-01, time/batch = 15.6202s	
28773/30300 (epoch 47.480), train_loss = 0.98176716, grad/param norm = 1.9792e-01, time/batch = 16.3218s	
28774/30300 (epoch 47.482), train_loss = 1.01374865, grad/param norm = 1.6758e-01, time/batch = 18.1110s	
28775/30300 (epoch 47.483), train_loss = 0.95991766, grad/param norm = 1.7225e-01, time/batch = 19.4591s	
28776/30300 (epoch 47.485), train_loss = 0.97405408, grad/param norm = 1.6877e-01, time/batch = 18.5473s	
28777/30300 (epoch 47.487), train_loss = 1.01635717, grad/param norm = 1.8156e-01, time/batch = 19.0260s	
28778/30300 (epoch 47.488), train_loss = 1.08687415, grad/param norm = 1.6156e-01, time/batch = 18.4388s	
28779/30300 (epoch 47.490), train_loss = 0.83877207, grad/param norm = 1.7321e-01, time/batch = 19.2130s	
28780/30300 (epoch 47.492), train_loss = 0.92216363, grad/param norm = 1.7506e-01, time/batch = 15.4576s	
28781/30300 (epoch 47.493), train_loss = 0.97368571, grad/param norm = 1.9673e-01, time/batch = 18.7827s	
28782/30300 (epoch 47.495), train_loss = 0.95115053, grad/param norm = 1.5148e-01, time/batch = 19.3861s	
28783/30300 (epoch 47.497), train_loss = 0.99561785, grad/param norm = 1.7691e-01, time/batch = 19.1201s	
28784/30300 (epoch 47.498), train_loss = 1.02799911, grad/param norm = 1.8106e-01, time/batch = 19.2101s	
28785/30300 (epoch 47.500), train_loss = 0.89158742, grad/param norm = 1.9842e-01, time/batch = 18.8104s	
28786/30300 (epoch 47.502), train_loss = 0.96484782, grad/param norm = 1.8528e-01, time/batch = 18.7992s	
28787/30300 (epoch 47.503), train_loss = 1.05939162, grad/param norm = 1.8557e-01, time/batch = 16.9321s	
28788/30300 (epoch 47.505), train_loss = 0.84559133, grad/param norm = 1.5345e-01, time/batch = 19.5437s	
28789/30300 (epoch 47.507), train_loss = 0.85779281, grad/param norm = 1.8146e-01, time/batch = 18.2144s	
28790/30300 (epoch 47.508), train_loss = 0.91194250, grad/param norm = 2.3408e-01, time/batch = 15.6197s	
28791/30300 (epoch 47.510), train_loss = 1.03481016, grad/param norm = 2.0082e-01, time/batch = 15.8748s	
28792/30300 (epoch 47.512), train_loss = 0.90363707, grad/param norm = 1.5763e-01, time/batch = 17.0157s	
28793/30300 (epoch 47.513), train_loss = 0.97824320, grad/param norm = 1.8934e-01, time/batch = 17.5463s	
28794/30300 (epoch 47.515), train_loss = 0.95245797, grad/param norm = 1.7038e-01, time/batch = 19.4691s	
28795/30300 (epoch 47.517), train_loss = 0.79462728, grad/param norm = 1.6947e-01, time/batch = 19.2804s	
28796/30300 (epoch 47.518), train_loss = 1.03682443, grad/param norm = 1.8178e-01, time/batch = 19.2173s	
28797/30300 (epoch 47.520), train_loss = 0.93422272, grad/param norm = 1.8804e-01, time/batch = 18.2939s	
28798/30300 (epoch 47.521), train_loss = 0.86774174, grad/param norm = 2.1841e-01, time/batch = 19.2827s	
28799/30300 (epoch 47.523), train_loss = 1.06214501, grad/param norm = 2.1182e-01, time/batch = 18.3807s	
28800/30300 (epoch 47.525), train_loss = 0.87943477, grad/param norm = 1.8065e-01, time/batch = 18.4532s	
28801/30300 (epoch 47.526), train_loss = 0.98046306, grad/param norm = 1.7095e-01, time/batch = 19.9614s	
28802/30300 (epoch 47.528), train_loss = 0.83230753, grad/param norm = 1.6591e-01, time/batch = 19.4601s	
28803/30300 (epoch 47.530), train_loss = 0.83293966, grad/param norm = 1.9261e-01, time/batch = 16.6253s	
28804/30300 (epoch 47.531), train_loss = 0.92929267, grad/param norm = 1.9180e-01, time/batch = 16.1505s	
28805/30300 (epoch 47.533), train_loss = 0.94067744, grad/param norm = 1.9540e-01, time/batch = 16.5254s	
28806/30300 (epoch 47.535), train_loss = 0.96283725, grad/param norm = 1.6831e-01, time/batch = 18.2928s	
28807/30300 (epoch 47.536), train_loss = 0.97075814, grad/param norm = 1.7961e-01, time/batch = 17.6758s	
28808/30300 (epoch 47.538), train_loss = 0.84872315, grad/param norm = 1.7930e-01, time/batch = 19.5438s	
28809/30300 (epoch 47.540), train_loss = 0.89968819, grad/param norm = 1.9952e-01, time/batch = 19.2056s	
28810/30300 (epoch 47.541), train_loss = 0.93424984, grad/param norm = 1.7854e-01, time/batch = 18.3684s	
28811/30300 (epoch 47.543), train_loss = 0.93415649, grad/param norm = 1.7304e-01, time/batch = 19.9565s	
28812/30300 (epoch 47.545), train_loss = 1.01650358, grad/param norm = 1.9686e-01, time/batch = 17.9275s	
28813/30300 (epoch 47.546), train_loss = 1.11017285, grad/param norm = 1.8323e-01, time/batch = 19.2883s	
28814/30300 (epoch 47.548), train_loss = 0.91175904, grad/param norm = 1.6045e-01, time/batch = 19.3878s	
28815/30300 (epoch 47.550), train_loss = 1.00067448, grad/param norm = 2.1399e-01, time/batch = 19.5526s	
28816/30300 (epoch 47.551), train_loss = 0.89210027, grad/param norm = 1.8108e-01, time/batch = 18.7685s	
28817/30300 (epoch 47.553), train_loss = 0.93364319, grad/param norm = 1.7584e-01, time/batch = 19.0182s	
28818/30300 (epoch 47.554), train_loss = 0.94983887, grad/param norm = 2.2021e-01, time/batch = 19.5482s	
28819/30300 (epoch 47.556), train_loss = 0.99931575, grad/param norm = 1.6863e-01, time/batch = 18.7818s	
28820/30300 (epoch 47.558), train_loss = 1.06198167, grad/param norm = 1.9313e-01, time/batch = 18.1937s	
28821/30300 (epoch 47.559), train_loss = 0.98733084, grad/param norm = 2.1844e-01, time/batch = 15.7683s	
28822/30300 (epoch 47.561), train_loss = 0.77877668, grad/param norm = 2.0563e-01, time/batch = 16.0156s	
28823/30300 (epoch 47.563), train_loss = 0.83251990, grad/param norm = 1.6592e-01, time/batch = 18.3407s	
28824/30300 (epoch 47.564), train_loss = 0.92585319, grad/param norm = 1.6943e-01, time/batch = 19.2979s	
28825/30300 (epoch 47.566), train_loss = 0.93252535, grad/param norm = 1.8211e-01, time/batch = 19.0298s	
28826/30300 (epoch 47.568), train_loss = 0.82203388, grad/param norm = 1.9805e-01, time/batch = 18.1107s	
28827/30300 (epoch 47.569), train_loss = 0.97020164, grad/param norm = 1.7397e-01, time/batch = 19.6049s	
28828/30300 (epoch 47.571), train_loss = 0.94675832, grad/param norm = 1.7477e-01, time/batch = 18.4641s	
28829/30300 (epoch 47.573), train_loss = 0.97753598, grad/param norm = 1.7468e-01, time/batch = 18.3723s	
28830/30300 (epoch 47.574), train_loss = 0.98744382, grad/param norm = 1.7965e-01, time/batch = 18.9685s	
28831/30300 (epoch 47.576), train_loss = 0.92493387, grad/param norm = 1.6146e-01, time/batch = 18.8038s	
28832/30300 (epoch 47.578), train_loss = 0.82077748, grad/param norm = 1.5861e-01, time/batch = 18.1186s	
28833/30300 (epoch 47.579), train_loss = 1.00529884, grad/param norm = 1.8949e-01, time/batch = 19.6321s	
28834/30300 (epoch 47.581), train_loss = 1.05651057, grad/param norm = 1.5819e-01, time/batch = 19.5401s	
28835/30300 (epoch 47.583), train_loss = 1.08662167, grad/param norm = 2.3681e-01, time/batch = 18.4675s	
28836/30300 (epoch 47.584), train_loss = 1.06242428, grad/param norm = 2.0165e-01, time/batch = 19.7994s	
28837/30300 (epoch 47.586), train_loss = 0.92295310, grad/param norm = 1.8880e-01, time/batch = 19.1432s	
28838/30300 (epoch 47.587), train_loss = 0.94432832, grad/param norm = 1.8373e-01, time/batch = 16.8821s	
28839/30300 (epoch 47.589), train_loss = 0.88079977, grad/param norm = 1.6383e-01, time/batch = 18.2916s	
28840/30300 (epoch 47.591), train_loss = 0.99905012, grad/param norm = 1.6933e-01, time/batch = 15.6919s	
28841/30300 (epoch 47.592), train_loss = 0.91823350, grad/param norm = 1.6238e-01, time/batch = 16.2465s	
28842/30300 (epoch 47.594), train_loss = 1.02299770, grad/param norm = 1.8413e-01, time/batch = 18.4424s	
28843/30300 (epoch 47.596), train_loss = 0.87844273, grad/param norm = 1.5746e-01, time/batch = 19.0444s	
28844/30300 (epoch 47.597), train_loss = 0.90878477, grad/param norm = 2.0231e-01, time/batch = 17.4217s	
28845/30300 (epoch 47.599), train_loss = 0.81051042, grad/param norm = 1.7407e-01, time/batch = 17.7816s	
28846/30300 (epoch 47.601), train_loss = 0.96662561, grad/param norm = 1.8213e-01, time/batch = 18.2070s	
28847/30300 (epoch 47.602), train_loss = 0.96383171, grad/param norm = 1.5482e-01, time/batch = 19.5280s	
28848/30300 (epoch 47.604), train_loss = 0.88287838, grad/param norm = 1.7623e-01, time/batch = 18.6161s	
28849/30300 (epoch 47.606), train_loss = 0.90280561, grad/param norm = 2.0482e-01, time/batch = 18.8779s	
28850/30300 (epoch 47.607), train_loss = 1.01812908, grad/param norm = 2.0955e-01, time/batch = 18.7152s	
28851/30300 (epoch 47.609), train_loss = 1.11799732, grad/param norm = 1.8806e-01, time/batch = 18.7927s	
28852/30300 (epoch 47.611), train_loss = 0.93244282, grad/param norm = 1.6502e-01, time/batch = 15.9516s	
28853/30300 (epoch 47.612), train_loss = 0.86404766, grad/param norm = 1.5114e-01, time/batch = 15.8637s	
28854/30300 (epoch 47.614), train_loss = 0.94382317, grad/param norm = 1.6330e-01, time/batch = 16.1813s	
28855/30300 (epoch 47.616), train_loss = 0.97313690, grad/param norm = 1.9666e-01, time/batch = 17.4736s	
28856/30300 (epoch 47.617), train_loss = 0.93863332, grad/param norm = 2.0209e-01, time/batch = 18.7183s	
28857/30300 (epoch 47.619), train_loss = 0.78171905, grad/param norm = 1.4956e-01, time/batch = 18.7095s	
28858/30300 (epoch 47.620), train_loss = 0.99698356, grad/param norm = 1.8667e-01, time/batch = 18.5513s	
28859/30300 (epoch 47.622), train_loss = 0.94293809, grad/param norm = 2.0214e-01, time/batch = 18.1103s	
28860/30300 (epoch 47.624), train_loss = 0.94473234, grad/param norm = 1.8801e-01, time/batch = 18.3720s	
28861/30300 (epoch 47.625), train_loss = 0.94099254, grad/param norm = 2.0450e-01, time/batch = 18.2938s	
28862/30300 (epoch 47.627), train_loss = 1.03944414, grad/param norm = 2.0140e-01, time/batch = 18.9651s	
28863/30300 (epoch 47.629), train_loss = 1.05666834, grad/param norm = 1.7340e-01, time/batch = 17.6151s	
28864/30300 (epoch 47.630), train_loss = 0.95412833, grad/param norm = 1.8925e-01, time/batch = 18.8900s	
28865/30300 (epoch 47.632), train_loss = 0.99218299, grad/param norm = 1.9935e-01, time/batch = 33.2837s	
28866/30300 (epoch 47.634), train_loss = 0.87740389, grad/param norm = 1.6079e-01, time/batch = 19.5473s	
28867/30300 (epoch 47.635), train_loss = 0.98515775, grad/param norm = 2.0331e-01, time/batch = 16.0124s	
28868/30300 (epoch 47.637), train_loss = 1.03699610, grad/param norm = 2.2075e-01, time/batch = 15.6014s	
28869/30300 (epoch 47.639), train_loss = 0.94296054, grad/param norm = 1.8482e-01, time/batch = 17.9227s	
28870/30300 (epoch 47.640), train_loss = 1.06962834, grad/param norm = 2.0963e-01, time/batch = 18.1187s	
28871/30300 (epoch 47.642), train_loss = 0.95867837, grad/param norm = 1.7801e-01, time/batch = 17.7038s	
28872/30300 (epoch 47.644), train_loss = 1.04137820, grad/param norm = 1.8354e-01, time/batch = 19.7947s	
28873/30300 (epoch 47.645), train_loss = 0.88863076, grad/param norm = 1.5605e-01, time/batch = 16.7807s	
28874/30300 (epoch 47.647), train_loss = 0.94359422, grad/param norm = 1.7999e-01, time/batch = 17.3711s	
28875/30300 (epoch 47.649), train_loss = 0.94505038, grad/param norm = 2.1012e-01, time/batch = 19.4662s	
28876/30300 (epoch 47.650), train_loss = 0.97096542, grad/param norm = 1.6289e-01, time/batch = 18.8784s	
28877/30300 (epoch 47.652), train_loss = 0.94021220, grad/param norm = 1.7846e-01, time/batch = 17.7959s	
28878/30300 (epoch 47.653), train_loss = 1.10164803, grad/param norm = 1.6870e-01, time/batch = 15.6221s	
28879/30300 (epoch 47.655), train_loss = 0.93850902, grad/param norm = 1.9282e-01, time/batch = 15.5374s	
28880/30300 (epoch 47.657), train_loss = 0.84953627, grad/param norm = 2.1281e-01, time/batch = 16.5401s	
28881/30300 (epoch 47.658), train_loss = 0.93114960, grad/param norm = 1.6668e-01, time/batch = 18.5422s	
28882/30300 (epoch 47.660), train_loss = 0.94675473, grad/param norm = 1.7725e-01, time/batch = 19.2985s	
28883/30300 (epoch 47.662), train_loss = 0.96711311, grad/param norm = 1.9084e-01, time/batch = 15.6639s	
28884/30300 (epoch 47.663), train_loss = 1.02461454, grad/param norm = 1.8360e-01, time/batch = 16.3405s	
28885/30300 (epoch 47.665), train_loss = 0.88958049, grad/param norm = 1.8321e-01, time/batch = 15.9322s	
28886/30300 (epoch 47.667), train_loss = 1.00237981, grad/param norm = 1.9998e-01, time/batch = 15.5378s	
28887/30300 (epoch 47.668), train_loss = 1.04385865, grad/param norm = 1.9267e-01, time/batch = 17.1985s	
28888/30300 (epoch 47.670), train_loss = 1.05934271, grad/param norm = 1.8395e-01, time/batch = 17.2942s	
28889/30300 (epoch 47.672), train_loss = 0.95172812, grad/param norm = 1.7999e-01, time/batch = 19.9533s	
28890/30300 (epoch 47.673), train_loss = 1.02070301, grad/param norm = 2.4915e-01, time/batch = 18.9751s	
28891/30300 (epoch 47.675), train_loss = 0.94487943, grad/param norm = 2.0956e-01, time/batch = 18.2793s	
28892/30300 (epoch 47.677), train_loss = 0.92433552, grad/param norm = 1.6219e-01, time/batch = 18.2609s	
28893/30300 (epoch 47.678), train_loss = 0.92490576, grad/param norm = 1.7614e-01, time/batch = 18.3023s	
28894/30300 (epoch 47.680), train_loss = 0.87004508, grad/param norm = 1.6619e-01, time/batch = 18.7092s	
28895/30300 (epoch 47.682), train_loss = 0.95696853, grad/param norm = 1.9478e-01, time/batch = 17.8740s	
28896/30300 (epoch 47.683), train_loss = 1.01725491, grad/param norm = 1.6676e-01, time/batch = 19.9366s	
28897/30300 (epoch 47.685), train_loss = 1.01614453, grad/param norm = 1.8869e-01, time/batch = 18.1240s	
28898/30300 (epoch 47.686), train_loss = 0.94969555, grad/param norm = 1.6928e-01, time/batch = 18.5327s	
28899/30300 (epoch 47.688), train_loss = 0.94986180, grad/param norm = 1.5170e-01, time/batch = 19.6194s	
28900/30300 (epoch 47.690), train_loss = 0.91561029, grad/param norm = 1.9830e-01, time/batch = 19.2127s	
28901/30300 (epoch 47.691), train_loss = 0.94805652, grad/param norm = 1.7308e-01, time/batch = 17.9323s	
28902/30300 (epoch 47.693), train_loss = 1.22743789, grad/param norm = 2.0904e-01, time/batch = 19.7887s	
28903/30300 (epoch 47.695), train_loss = 1.02954801, grad/param norm = 1.9237e-01, time/batch = 19.5448s	
28904/30300 (epoch 47.696), train_loss = 0.97972738, grad/param norm = 2.0458e-01, time/batch = 18.7881s	
28905/30300 (epoch 47.698), train_loss = 0.92321501, grad/param norm = 1.8487e-01, time/batch = 19.5354s	
28906/30300 (epoch 47.700), train_loss = 0.89672831, grad/param norm = 1.7109e-01, time/batch = 19.5533s	
28907/30300 (epoch 47.701), train_loss = 0.84777523, grad/param norm = 1.7963e-01, time/batch = 17.5288s	
28908/30300 (epoch 47.703), train_loss = 0.95925981, grad/param norm = 1.6017e-01, time/batch = 19.2972s	
28909/30300 (epoch 47.705), train_loss = 0.87947356, grad/param norm = 1.7859e-01, time/batch = 19.9696s	
28910/30300 (epoch 47.706), train_loss = 1.01921711, grad/param norm = 1.8989e-01, time/batch = 18.3768s	
28911/30300 (epoch 47.708), train_loss = 0.95781039, grad/param norm = 1.6141e-01, time/batch = 18.5428s	
28912/30300 (epoch 47.710), train_loss = 0.94202160, grad/param norm = 1.7750e-01, time/batch = 20.0557s	
28913/30300 (epoch 47.711), train_loss = 0.88958874, grad/param norm = 1.6943e-01, time/batch = 17.7819s	
28914/30300 (epoch 47.713), train_loss = 0.89786187, grad/param norm = 1.6729e-01, time/batch = 20.1324s	
28915/30300 (epoch 47.715), train_loss = 0.93392141, grad/param norm = 1.8896e-01, time/batch = 19.2163s	
28916/30300 (epoch 47.716), train_loss = 1.00871531, grad/param norm = 1.7498e-01, time/batch = 17.3608s	
28917/30300 (epoch 47.718), train_loss = 1.05584648, grad/param norm = 1.7304e-01, time/batch = 18.5575s	
28918/30300 (epoch 47.719), train_loss = 0.91654870, grad/param norm = 1.8964e-01, time/batch = 19.1407s	
28919/30300 (epoch 47.721), train_loss = 0.93702693, grad/param norm = 1.7937e-01, time/batch = 19.4570s	
28920/30300 (epoch 47.723), train_loss = 0.89044519, grad/param norm = 1.6901e-01, time/batch = 18.6950s	
28921/30300 (epoch 47.724), train_loss = 0.97089155, grad/param norm = 1.9239e-01, time/batch = 19.4351s	
28922/30300 (epoch 47.726), train_loss = 1.19353555, grad/param norm = 2.0758e-01, time/batch = 19.3722s	
28923/30300 (epoch 47.728), train_loss = 0.99143768, grad/param norm = 1.8176e-01, time/batch = 19.1844s	
28924/30300 (epoch 47.729), train_loss = 0.92064263, grad/param norm = 1.8773e-01, time/batch = 19.4626s	
28925/30300 (epoch 47.731), train_loss = 0.91007145, grad/param norm = 2.3351e-01, time/batch = 19.5443s	
28926/30300 (epoch 47.733), train_loss = 0.95537175, grad/param norm = 1.8032e-01, time/batch = 18.1175s	
28927/30300 (epoch 47.734), train_loss = 1.05388386, grad/param norm = 1.8174e-01, time/batch = 17.2073s	
28928/30300 (epoch 47.736), train_loss = 0.99062495, grad/param norm = 1.7648e-01, time/batch = 18.8072s	
28929/30300 (epoch 47.738), train_loss = 0.90178653, grad/param norm = 1.5023e-01, time/batch = 18.4525s	
28930/30300 (epoch 47.739), train_loss = 1.06427704, grad/param norm = 1.7331e-01, time/batch = 19.2105s	
28931/30300 (epoch 47.741), train_loss = 1.08610867, grad/param norm = 1.6738e-01, time/batch = 18.4703s	
28932/30300 (epoch 47.743), train_loss = 0.93309739, grad/param norm = 1.9881e-01, time/batch = 18.7101s	
28933/30300 (epoch 47.744), train_loss = 1.00682756, grad/param norm = 2.3450e-01, time/batch = 17.7595s	
28934/30300 (epoch 47.746), train_loss = 0.92622243, grad/param norm = 1.5268e-01, time/batch = 19.3834s	
28935/30300 (epoch 47.748), train_loss = 0.94381339, grad/param norm = 2.3465e-01, time/batch = 18.6137s	
28936/30300 (epoch 47.749), train_loss = 0.97101582, grad/param norm = 1.8265e-01, time/batch = 19.1259s	
28937/30300 (epoch 47.751), train_loss = 1.00588504, grad/param norm = 1.8087e-01, time/batch = 18.5454s	
28938/30300 (epoch 47.752), train_loss = 0.94576810, grad/param norm = 1.8850e-01, time/batch = 18.7975s	
28939/30300 (epoch 47.754), train_loss = 0.95280343, grad/param norm = 1.7918e-01, time/batch = 19.2723s	
28940/30300 (epoch 47.756), train_loss = 0.96233696, grad/param norm = 1.8124e-01, time/batch = 17.9574s	
28941/30300 (epoch 47.757), train_loss = 0.86550749, grad/param norm = 1.7860e-01, time/batch = 19.6234s	
28942/30300 (epoch 47.759), train_loss = 0.96171734, grad/param norm = 1.6643e-01, time/batch = 18.1203s	
28943/30300 (epoch 47.761), train_loss = 0.82463585, grad/param norm = 1.7090e-01, time/batch = 19.2925s	
28944/30300 (epoch 47.762), train_loss = 0.84807666, grad/param norm = 1.5730e-01, time/batch = 19.8818s	
28945/30300 (epoch 47.764), train_loss = 0.92983353, grad/param norm = 1.8415e-01, time/batch = 16.7780s	
28946/30300 (epoch 47.766), train_loss = 1.07744563, grad/param norm = 2.0987e-01, time/batch = 18.8759s	
28947/30300 (epoch 47.767), train_loss = 0.94466753, grad/param norm = 2.2329e-01, time/batch = 20.1245s	
28948/30300 (epoch 47.769), train_loss = 0.95039113, grad/param norm = 2.0367e-01, time/batch = 18.2180s	
28949/30300 (epoch 47.771), train_loss = 0.89836549, grad/param norm = 2.0616e-01, time/batch = 19.4601s	
28950/30300 (epoch 47.772), train_loss = 0.94227283, grad/param norm = 1.8777e-01, time/batch = 20.1268s	
28951/30300 (epoch 47.774), train_loss = 1.12863909, grad/param norm = 1.8978e-01, time/batch = 18.6322s	
28952/30300 (epoch 47.776), train_loss = 0.91935124, grad/param norm = 1.9307e-01, time/batch = 17.1134s	
28953/30300 (epoch 47.777), train_loss = 1.08233089, grad/param norm = 1.7841e-01, time/batch = 18.0908s	
28954/30300 (epoch 47.779), train_loss = 1.07976857, grad/param norm = 1.9041e-01, time/batch = 18.5517s	
28955/30300 (epoch 47.781), train_loss = 0.97013159, grad/param norm = 2.0264e-01, time/batch = 18.7001s	
28956/30300 (epoch 47.782), train_loss = 0.88634685, grad/param norm = 1.6742e-01, time/batch = 19.2174s	
28957/30300 (epoch 47.784), train_loss = 0.89956732, grad/param norm = 1.5768e-01, time/batch = 19.3685s	
28958/30300 (epoch 47.785), train_loss = 1.00543902, grad/param norm = 1.9077e-01, time/batch = 17.7024s	
28959/30300 (epoch 47.787), train_loss = 0.81436225, grad/param norm = 1.7260e-01, time/batch = 18.5525s	
28960/30300 (epoch 47.789), train_loss = 1.10611810, grad/param norm = 2.0156e-01, time/batch = 19.3020s	
28961/30300 (epoch 47.790), train_loss = 0.94846996, grad/param norm = 1.9538e-01, time/batch = 18.5292s	
28962/30300 (epoch 47.792), train_loss = 0.76420816, grad/param norm = 1.6761e-01, time/batch = 19.7856s	
28963/30300 (epoch 47.794), train_loss = 0.97580621, grad/param norm = 1.7835e-01, time/batch = 18.9481s	
28964/30300 (epoch 47.795), train_loss = 0.88113793, grad/param norm = 1.6731e-01, time/batch = 18.3810s	
28965/30300 (epoch 47.797), train_loss = 1.10903208, grad/param norm = 2.2352e-01, time/batch = 18.9469s	
28966/30300 (epoch 47.799), train_loss = 1.02349736, grad/param norm = 2.3294e-01, time/batch = 19.6262s	
28967/30300 (epoch 47.800), train_loss = 1.02531853, grad/param norm = 1.8847e-01, time/batch = 18.5384s	
28968/30300 (epoch 47.802), train_loss = 1.20573576, grad/param norm = 2.0441e-01, time/batch = 18.9472s	
28969/30300 (epoch 47.804), train_loss = 1.01290071, grad/param norm = 2.1751e-01, time/batch = 18.6867s	
28970/30300 (epoch 47.805), train_loss = 1.09671990, grad/param norm = 1.9378e-01, time/batch = 18.2951s	
28971/30300 (epoch 47.807), train_loss = 0.94469454, grad/param norm = 2.0614e-01, time/batch = 19.9518s	
28972/30300 (epoch 47.809), train_loss = 1.05758592, grad/param norm = 1.8925e-01, time/batch = 18.2777s	
28973/30300 (epoch 47.810), train_loss = 1.00558263, grad/param norm = 1.7680e-01, time/batch = 18.6861s	
28974/30300 (epoch 47.812), train_loss = 0.92664400, grad/param norm = 1.8030e-01, time/batch = 18.3757s	
28975/30300 (epoch 47.814), train_loss = 0.97950681, grad/param norm = 1.8894e-01, time/batch = 17.6182s	
28976/30300 (epoch 47.815), train_loss = 0.98604202, grad/param norm = 2.2563e-01, time/batch = 20.2131s	
28977/30300 (epoch 47.817), train_loss = 1.03386958, grad/param norm = 1.7957e-01, time/batch = 18.5223s	
28978/30300 (epoch 47.818), train_loss = 1.00934661, grad/param norm = 1.8164e-01, time/batch = 19.6259s	
28979/30300 (epoch 47.820), train_loss = 1.13306589, grad/param norm = 2.1760e-01, time/batch = 19.8048s	
28980/30300 (epoch 47.822), train_loss = 1.10763115, grad/param norm = 2.0352e-01, time/batch = 18.3719s	
28981/30300 (epoch 47.823), train_loss = 1.09022074, grad/param norm = 2.1557e-01, time/batch = 19.9778s	
28982/30300 (epoch 47.825), train_loss = 1.10984088, grad/param norm = 1.9291e-01, time/batch = 19.2075s	
28983/30300 (epoch 47.827), train_loss = 0.82261680, grad/param norm = 2.3438e-01, time/batch = 16.4306s	
28984/30300 (epoch 47.828), train_loss = 1.07822917, grad/param norm = 2.0696e-01, time/batch = 18.3632s	
28985/30300 (epoch 47.830), train_loss = 1.01108732, grad/param norm = 1.7733e-01, time/batch = 19.2933s	
28986/30300 (epoch 47.832), train_loss = 0.89739561, grad/param norm = 1.8266e-01, time/batch = 19.3731s	
28987/30300 (epoch 47.833), train_loss = 0.98914705, grad/param norm = 1.8511e-01, time/batch = 19.5376s	
28988/30300 (epoch 47.835), train_loss = 0.91260892, grad/param norm = 2.0015e-01, time/batch = 19.1143s	
28989/30300 (epoch 47.837), train_loss = 0.88241432, grad/param norm = 1.7664e-01, time/batch = 18.6399s	
28990/30300 (epoch 47.838), train_loss = 0.89146908, grad/param norm = 2.1119e-01, time/batch = 19.5431s	
28991/30300 (epoch 47.840), train_loss = 1.02483797, grad/param norm = 1.6909e-01, time/batch = 18.8780s	
28992/30300 (epoch 47.842), train_loss = 0.93710047, grad/param norm = 1.5203e-01, time/batch = 18.9549s	
28993/30300 (epoch 47.843), train_loss = 1.01054437, grad/param norm = 1.8324e-01, time/batch = 18.1062s	
28994/30300 (epoch 47.845), train_loss = 1.00463130, grad/param norm = 1.6171e-01, time/batch = 19.2990s	
28995/30300 (epoch 47.847), train_loss = 0.96757020, grad/param norm = 1.8519e-01, time/batch = 19.1355s	
28996/30300 (epoch 47.848), train_loss = 1.01755744, grad/param norm = 1.9147e-01, time/batch = 18.0063s	
28997/30300 (epoch 47.850), train_loss = 0.96678870, grad/param norm = 2.4489e-01, time/batch = 19.5479s	
28998/30300 (epoch 47.851), train_loss = 1.00988928, grad/param norm = 2.0705e-01, time/batch = 18.9659s	
28999/30300 (epoch 47.853), train_loss = 0.93908130, grad/param norm = 1.8023e-01, time/batch = 18.3628s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch47.85_2.0860.t7	
29000/30300 (epoch 47.855), train_loss = 0.91548209, grad/param norm = 1.6440e-01, time/batch = 18.8630s	
29001/30300 (epoch 47.856), train_loss = 1.51395805, grad/param norm = 2.6103e-01, time/batch = 18.1070s	
29002/30300 (epoch 47.858), train_loss = 0.92878614, grad/param norm = 1.7610e-01, time/batch = 19.7795s	
29003/30300 (epoch 47.860), train_loss = 0.88384912, grad/param norm = 1.6031e-01, time/batch = 19.3762s	
29004/30300 (epoch 47.861), train_loss = 1.10959435, grad/param norm = 2.0245e-01, time/batch = 19.1175s	
29005/30300 (epoch 47.863), train_loss = 0.92090044, grad/param norm = 1.6589e-01, time/batch = 19.4588s	
29006/30300 (epoch 47.865), train_loss = 1.03002640, grad/param norm = 1.9190e-01, time/batch = 19.1294s	
29007/30300 (epoch 47.866), train_loss = 1.03821937, grad/param norm = 1.8571e-01, time/batch = 18.1226s	
29008/30300 (epoch 47.868), train_loss = 0.99418271, grad/param norm = 1.7222e-01, time/batch = 18.7950s	
29009/30300 (epoch 47.870), train_loss = 0.91884612, grad/param norm = 1.7940e-01, time/batch = 17.9270s	
29010/30300 (epoch 47.871), train_loss = 1.00769764, grad/param norm = 1.8155e-01, time/batch = 19.3028s	
29011/30300 (epoch 47.873), train_loss = 0.98706393, grad/param norm = 1.6157e-01, time/batch = 17.7967s	
29012/30300 (epoch 47.875), train_loss = 0.92294304, grad/param norm = 1.5417e-01, time/batch = 19.8734s	
29013/30300 (epoch 47.876), train_loss = 0.86578978, grad/param norm = 1.7830e-01, time/batch = 18.8654s	
29014/30300 (epoch 47.878), train_loss = 0.81160358, grad/param norm = 1.8590e-01, time/batch = 19.1128s	
29015/30300 (epoch 47.880), train_loss = 0.88607366, grad/param norm = 1.6701e-01, time/batch = 19.0362s	
29016/30300 (epoch 47.881), train_loss = 1.09686356, grad/param norm = 1.9970e-01, time/batch = 18.8934s	
29017/30300 (epoch 47.883), train_loss = 1.03406354, grad/param norm = 1.9067e-01, time/batch = 16.2139s	
29018/30300 (epoch 47.884), train_loss = 0.95988795, grad/param norm = 1.5922e-01, time/batch = 19.1275s	
29019/30300 (epoch 47.886), train_loss = 1.01473726, grad/param norm = 1.8731e-01, time/batch = 17.7791s	
29020/30300 (epoch 47.888), train_loss = 0.92393223, grad/param norm = 1.8801e-01, time/batch = 17.9616s	
29021/30300 (epoch 47.889), train_loss = 1.00936411, grad/param norm = 1.7716e-01, time/batch = 18.2732s	
29022/30300 (epoch 47.891), train_loss = 0.94766640, grad/param norm = 1.7459e-01, time/batch = 19.4708s	
29023/30300 (epoch 47.893), train_loss = 1.17502070, grad/param norm = 1.8194e-01, time/batch = 18.2789s	
29024/30300 (epoch 47.894), train_loss = 0.96842412, grad/param norm = 1.7652e-01, time/batch = 18.3796s	
29025/30300 (epoch 47.896), train_loss = 0.83666367, grad/param norm = 1.7139e-01, time/batch = 18.6995s	
29026/30300 (epoch 47.898), train_loss = 0.81911911, grad/param norm = 1.7211e-01, time/batch = 19.3840s	
29027/30300 (epoch 47.899), train_loss = 0.86460347, grad/param norm = 1.9079e-01, time/batch = 18.3835s	
29028/30300 (epoch 47.901), train_loss = 0.97701717, grad/param norm = 1.9720e-01, time/batch = 20.0517s	
29029/30300 (epoch 47.903), train_loss = 0.95938568, grad/param norm = 2.0987e-01, time/batch = 18.7180s	
29030/30300 (epoch 47.904), train_loss = 0.97637316, grad/param norm = 1.7195e-01, time/batch = 18.5264s	
29031/30300 (epoch 47.906), train_loss = 0.97076163, grad/param norm = 1.8048e-01, time/batch = 19.7187s	
29032/30300 (epoch 47.908), train_loss = 0.91214027, grad/param norm = 1.5908e-01, time/batch = 19.4735s	
29033/30300 (epoch 47.909), train_loss = 0.94717879, grad/param norm = 2.3649e-01, time/batch = 18.6260s	
29034/30300 (epoch 47.911), train_loss = 0.94317645, grad/param norm = 1.7269e-01, time/batch = 16.6763s	
29035/30300 (epoch 47.913), train_loss = 0.95346849, grad/param norm = 1.7071e-01, time/batch = 15.2120s	
29036/30300 (epoch 47.914), train_loss = 0.94656156, grad/param norm = 2.0755e-01, time/batch = 15.3690s	
29037/30300 (epoch 47.916), train_loss = 0.99708661, grad/param norm = 1.6404e-01, time/batch = 15.4477s	
29038/30300 (epoch 47.917), train_loss = 0.92001735, grad/param norm = 1.7549e-01, time/batch = 15.1172s	
29039/30300 (epoch 47.919), train_loss = 0.84286396, grad/param norm = 1.7607e-01, time/batch = 17.6375s	
29040/30300 (epoch 47.921), train_loss = 0.94220625, grad/param norm = 1.7291e-01, time/batch = 17.1956s	
29041/30300 (epoch 47.922), train_loss = 1.05479049, grad/param norm = 2.5245e-01, time/batch = 19.2017s	
29042/30300 (epoch 47.924), train_loss = 0.95515948, grad/param norm = 1.7726e-01, time/batch = 18.1006s	
29043/30300 (epoch 47.926), train_loss = 1.00962058, grad/param norm = 1.9380e-01, time/batch = 19.0513s	
29044/30300 (epoch 47.927), train_loss = 0.99071082, grad/param norm = 1.9772e-01, time/batch = 18.8773s	
29045/30300 (epoch 47.929), train_loss = 0.90007558, grad/param norm = 2.1197e-01, time/batch = 19.4635s	
29046/30300 (epoch 47.931), train_loss = 1.03853233, grad/param norm = 2.3512e-01, time/batch = 18.1973s	
29047/30300 (epoch 47.932), train_loss = 0.89159036, grad/param norm = 1.6274e-01, time/batch = 18.6308s	
29048/30300 (epoch 47.934), train_loss = 0.99648976, grad/param norm = 1.7723e-01, time/batch = 20.0510s	
29049/30300 (epoch 47.936), train_loss = 0.91993984, grad/param norm = 1.7605e-01, time/batch = 17.6223s	
29050/30300 (epoch 47.937), train_loss = 0.91611519, grad/param norm = 1.8214e-01, time/batch = 32.8412s	
29051/30300 (epoch 47.939), train_loss = 1.05642229, grad/param norm = 1.8162e-01, time/batch = 19.0396s	
29052/30300 (epoch 47.941), train_loss = 0.94292338, grad/param norm = 1.7365e-01, time/batch = 18.2107s	
29053/30300 (epoch 47.942), train_loss = 0.93470334, grad/param norm = 1.7912e-01, time/batch = 19.2919s	
29054/30300 (epoch 47.944), train_loss = 0.85090924, grad/param norm = 1.4822e-01, time/batch = 19.7927s	
29055/30300 (epoch 47.946), train_loss = 1.02903005, grad/param norm = 2.5113e-01, time/batch = 18.4552s	
29056/30300 (epoch 47.947), train_loss = 0.97321475, grad/param norm = 1.9987e-01, time/batch = 19.3727s	
29057/30300 (epoch 47.949), train_loss = 1.04186043, grad/param norm = 2.2568e-01, time/batch = 17.8491s	
29058/30300 (epoch 47.950), train_loss = 1.07048908, grad/param norm = 2.1245e-01, time/batch = 18.9359s	
29059/30300 (epoch 47.952), train_loss = 1.01080480, grad/param norm = 2.1679e-01, time/batch = 19.2129s	
29060/30300 (epoch 47.954), train_loss = 1.19583310, grad/param norm = 1.7930e-01, time/batch = 19.2171s	
29061/30300 (epoch 47.955), train_loss = 0.95211143, grad/param norm = 1.7295e-01, time/batch = 18.3550s	
29062/30300 (epoch 47.957), train_loss = 1.00740675, grad/param norm = 1.7766e-01, time/batch = 18.6942s	
29063/30300 (epoch 47.959), train_loss = 0.88172344, grad/param norm = 1.9127e-01, time/batch = 17.6340s	
29064/30300 (epoch 47.960), train_loss = 0.93143534, grad/param norm = 1.8744e-01, time/batch = 19.6150s	
29065/30300 (epoch 47.962), train_loss = 0.90665669, grad/param norm = 2.8000e-01, time/batch = 18.6084s	
29066/30300 (epoch 47.964), train_loss = 0.89452716, grad/param norm = 2.0572e-01, time/batch = 19.5525s	
29067/30300 (epoch 47.965), train_loss = 0.89692216, grad/param norm = 3.4463e-01, time/batch = 19.2218s	
29068/30300 (epoch 47.967), train_loss = 0.94882804, grad/param norm = 2.6754e-01, time/batch = 17.9349s	
29069/30300 (epoch 47.969), train_loss = 0.89777531, grad/param norm = 1.9133e-01, time/batch = 19.6264s	
29070/30300 (epoch 47.970), train_loss = 0.94110966, grad/param norm = 1.9167e-01, time/batch = 20.1214s	
29071/30300 (epoch 47.972), train_loss = 0.84558468, grad/param norm = 1.7447e-01, time/batch = 18.3769s	
29072/30300 (epoch 47.974), train_loss = 1.06975503, grad/param norm = 2.3715e-01, time/batch = 18.6173s	
29073/30300 (epoch 47.975), train_loss = 1.09503161, grad/param norm = 2.2003e-01, time/batch = 19.1992s	
29074/30300 (epoch 47.977), train_loss = 1.16453591, grad/param norm = 1.8712e-01, time/batch = 18.8772s	
29075/30300 (epoch 47.979), train_loss = 1.02458147, grad/param norm = 2.0194e-01, time/batch = 18.7261s	
29076/30300 (epoch 47.980), train_loss = 1.05725296, grad/param norm = 2.0052e-01, time/batch = 18.5386s	
29077/30300 (epoch 47.982), train_loss = 1.04759731, grad/param norm = 2.1338e-01, time/batch = 18.7903s	
29078/30300 (epoch 47.983), train_loss = 1.06990162, grad/param norm = 1.8148e-01, time/batch = 19.2013s	
29079/30300 (epoch 47.985), train_loss = 1.01627401, grad/param norm = 2.1624e-01, time/batch = 19.3834s	
29080/30300 (epoch 47.987), train_loss = 0.99650217, grad/param norm = 1.6990e-01, time/batch = 19.1266s	
29081/30300 (epoch 47.988), train_loss = 1.10759816, grad/param norm = 2.4710e-01, time/batch = 18.7933s	
29082/30300 (epoch 47.990), train_loss = 0.90840799, grad/param norm = 1.6411e-01, time/batch = 19.6171s	
29083/30300 (epoch 47.992), train_loss = 1.06158673, grad/param norm = 1.6834e-01, time/batch = 19.4738s	
29084/30300 (epoch 47.993), train_loss = 1.03561005, grad/param norm = 2.2233e-01, time/batch = 18.2011s	
29085/30300 (epoch 47.995), train_loss = 0.95962733, grad/param norm = 2.1610e-01, time/batch = 19.0385s	
29086/30300 (epoch 47.997), train_loss = 1.04720981, grad/param norm = 2.1602e-01, time/batch = 19.1867s	
29087/30300 (epoch 47.998), train_loss = 1.05286655, grad/param norm = 1.9095e-01, time/batch = 19.1064s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
29088/30300 (epoch 48.000), train_loss = 0.92848768, grad/param norm = 2.2945e-01, time/batch = 18.1084s	
29089/30300 (epoch 48.002), train_loss = 1.09698012, grad/param norm = 2.2509e-01, time/batch = 19.2932s	
29090/30300 (epoch 48.003), train_loss = 1.01595655, grad/param norm = 1.8719e-01, time/batch = 18.4575s	
29091/30300 (epoch 48.005), train_loss = 0.94516622, grad/param norm = 1.8812e-01, time/batch = 19.0367s	
29092/30300 (epoch 48.007), train_loss = 1.04056710, grad/param norm = 2.1237e-01, time/batch = 19.5367s	
29093/30300 (epoch 48.008), train_loss = 0.98490216, grad/param norm = 2.0581e-01, time/batch = 18.2083s	
29094/30300 (epoch 48.010), train_loss = 0.86487379, grad/param norm = 1.9993e-01, time/batch = 17.1194s	
29095/30300 (epoch 48.012), train_loss = 0.96416077, grad/param norm = 1.9794e-01, time/batch = 18.9702s	
29096/30300 (epoch 48.013), train_loss = 1.06480352, grad/param norm = 2.1207e-01, time/batch = 18.2903s	
29097/30300 (epoch 48.015), train_loss = 0.91255275, grad/param norm = 1.7291e-01, time/batch = 19.7119s	
29098/30300 (epoch 48.017), train_loss = 0.97425855, grad/param norm = 1.6817e-01, time/batch = 19.8113s	
29099/30300 (epoch 48.018), train_loss = 0.87323253, grad/param norm = 2.2888e-01, time/batch = 16.4207s	
29100/30300 (epoch 48.020), train_loss = 1.08285601, grad/param norm = 2.0979e-01, time/batch = 19.0388s	
29101/30300 (epoch 48.021), train_loss = 1.08567386, grad/param norm = 1.9126e-01, time/batch = 20.0485s	
29102/30300 (epoch 48.023), train_loss = 1.00620969, grad/param norm = 1.6094e-01, time/batch = 19.4779s	
29103/30300 (epoch 48.025), train_loss = 0.90864438, grad/param norm = 1.9356e-01, time/batch = 18.5367s	
29104/30300 (epoch 48.026), train_loss = 1.07146167, grad/param norm = 2.5121e-01, time/batch = 18.7296s	
29105/30300 (epoch 48.028), train_loss = 1.02132943, grad/param norm = 1.8168e-01, time/batch = 18.9722s	
29106/30300 (epoch 48.030), train_loss = 0.93164134, grad/param norm = 1.8428e-01, time/batch = 18.3029s	
29107/30300 (epoch 48.031), train_loss = 1.01029170, grad/param norm = 1.8295e-01, time/batch = 20.1234s	
29108/30300 (epoch 48.033), train_loss = 1.00778118, grad/param norm = 2.1001e-01, time/batch = 18.8708s	
29109/30300 (epoch 48.035), train_loss = 1.00555721, grad/param norm = 2.0755e-01, time/batch = 16.4502s	
29110/30300 (epoch 48.036), train_loss = 1.01204176, grad/param norm = 1.7999e-01, time/batch = 19.7116s	
29111/30300 (epoch 48.038), train_loss = 1.02373387, grad/param norm = 1.6610e-01, time/batch = 19.2907s	
29112/30300 (epoch 48.040), train_loss = 0.87069499, grad/param norm = 1.7024e-01, time/batch = 18.4652s	
29113/30300 (epoch 48.041), train_loss = 0.81915190, grad/param norm = 1.7867e-01, time/batch = 17.7655s	
29114/30300 (epoch 48.043), train_loss = 1.01733251, grad/param norm = 1.9488e-01, time/batch = 18.3882s	
29115/30300 (epoch 48.045), train_loss = 0.92355429, grad/param norm = 1.8060e-01, time/batch = 19.1329s	
29116/30300 (epoch 48.046), train_loss = 1.10244866, grad/param norm = 2.2322e-01, time/batch = 18.7132s	
29117/30300 (epoch 48.048), train_loss = 1.01057959, grad/param norm = 2.1908e-01, time/batch = 19.5481s	
29118/30300 (epoch 48.050), train_loss = 0.88479452, grad/param norm = 1.7867e-01, time/batch = 19.6410s	
29119/30300 (epoch 48.051), train_loss = 0.99330514, grad/param norm = 1.9278e-01, time/batch = 18.6114s	
29120/30300 (epoch 48.053), train_loss = 0.85941022, grad/param norm = 2.1430e-01, time/batch = 18.0441s	
29121/30300 (epoch 48.054), train_loss = 1.01876564, grad/param norm = 1.8751e-01, time/batch = 18.5494s	
29122/30300 (epoch 48.056), train_loss = 0.90629353, grad/param norm = 2.0058e-01, time/batch = 17.9664s	
29123/30300 (epoch 48.058), train_loss = 0.94187296, grad/param norm = 1.8151e-01, time/batch = 18.1246s	
29124/30300 (epoch 48.059), train_loss = 0.93615206, grad/param norm = 2.0090e-01, time/batch = 19.4548s	
29125/30300 (epoch 48.061), train_loss = 1.01538590, grad/param norm = 2.0076e-01, time/batch = 18.3729s	
29126/30300 (epoch 48.063), train_loss = 0.88903905, grad/param norm = 2.0527e-01, time/batch = 18.6412s	
29127/30300 (epoch 48.064), train_loss = 0.95495884, grad/param norm = 1.8688e-01, time/batch = 19.7956s	
29128/30300 (epoch 48.066), train_loss = 0.98320709, grad/param norm = 2.9987e-01, time/batch = 18.2877s	
29129/30300 (epoch 48.068), train_loss = 0.92108175, grad/param norm = 1.7303e-01, time/batch = 19.9609s	
29130/30300 (epoch 48.069), train_loss = 1.03737663, grad/param norm = 1.8908e-01, time/batch = 19.2189s	
29131/30300 (epoch 48.071), train_loss = 0.99340547, grad/param norm = 2.2185e-01, time/batch = 16.9485s	
29132/30300 (epoch 48.073), train_loss = 0.92011275, grad/param norm = 2.1806e-01, time/batch = 19.5327s	
29133/30300 (epoch 48.074), train_loss = 0.94030813, grad/param norm = 1.8152e-01, time/batch = 18.3792s	
29134/30300 (epoch 48.076), train_loss = 0.96275872, grad/param norm = 1.7417e-01, time/batch = 18.7158s	
29135/30300 (epoch 48.078), train_loss = 0.88369628, grad/param norm = 1.7320e-01, time/batch = 18.8021s	
29136/30300 (epoch 48.079), train_loss = 0.94558471, grad/param norm = 1.9591e-01, time/batch = 19.3020s	
29137/30300 (epoch 48.081), train_loss = 0.98301199, grad/param norm = 2.0075e-01, time/batch = 18.7230s	
29138/30300 (epoch 48.083), train_loss = 1.02345079, grad/param norm = 2.1686e-01, time/batch = 18.4540s	
29139/30300 (epoch 48.084), train_loss = 0.92191237, grad/param norm = 1.8266e-01, time/batch = 18.5359s	
29140/30300 (epoch 48.086), train_loss = 0.91065808, grad/param norm = 1.9142e-01, time/batch = 19.6862s	
29141/30300 (epoch 48.087), train_loss = 0.92170580, grad/param norm = 1.6625e-01, time/batch = 18.6080s	
29142/30300 (epoch 48.089), train_loss = 0.88150001, grad/param norm = 1.6606e-01, time/batch = 19.2966s	
29143/30300 (epoch 48.091), train_loss = 1.00980198, grad/param norm = 1.8580e-01, time/batch = 19.4636s	
29144/30300 (epoch 48.092), train_loss = 1.02823903, grad/param norm = 1.5722e-01, time/batch = 17.5154s	
29145/30300 (epoch 48.094), train_loss = 1.05477299, grad/param norm = 2.6774e-01, time/batch = 19.2933s	
29146/30300 (epoch 48.096), train_loss = 1.09248715, grad/param norm = 2.0424e-01, time/batch = 18.2833s	
29147/30300 (epoch 48.097), train_loss = 0.94204865, grad/param norm = 1.8647e-01, time/batch = 18.7077s	
29148/30300 (epoch 48.099), train_loss = 1.01958048, grad/param norm = 1.7282e-01, time/batch = 18.5409s	
29149/30300 (epoch 48.101), train_loss = 1.04690117, grad/param norm = 2.0413e-01, time/batch = 19.7341s	
29150/30300 (epoch 48.102), train_loss = 0.90739560, grad/param norm = 1.9616e-01, time/batch = 18.8682s	
29151/30300 (epoch 48.104), train_loss = 0.94229895, grad/param norm = 2.2404e-01, time/batch = 18.7043s	
29152/30300 (epoch 48.106), train_loss = 0.88049783, grad/param norm = 1.7776e-01, time/batch = 19.2144s	
29153/30300 (epoch 48.107), train_loss = 1.02038052, grad/param norm = 1.7475e-01, time/batch = 19.6163s	
29154/30300 (epoch 48.109), train_loss = 1.04345439, grad/param norm = 2.6875e-01, time/batch = 18.6303s	
29155/30300 (epoch 48.111), train_loss = 0.99731753, grad/param norm = 1.9671e-01, time/batch = 17.5426s	
29156/30300 (epoch 48.112), train_loss = 1.09400932, grad/param norm = 2.1610e-01, time/batch = 19.4478s	
29157/30300 (epoch 48.114), train_loss = 0.93039610, grad/param norm = 1.6541e-01, time/batch = 18.5339s	
29158/30300 (epoch 48.116), train_loss = 1.03207771, grad/param norm = 2.3604e-01, time/batch = 18.5368s	
29159/30300 (epoch 48.117), train_loss = 1.06295162, grad/param norm = 1.7372e-01, time/batch = 19.7845s	
29160/30300 (epoch 48.119), train_loss = 0.86900470, grad/param norm = 1.9189e-01, time/batch = 12.7010s	
29161/30300 (epoch 48.120), train_loss = 0.94982531, grad/param norm = 2.0187e-01, time/batch = 0.6924s	
29162/30300 (epoch 48.122), train_loss = 1.06927940, grad/param norm = 2.2842e-01, time/batch = 0.6869s	
29163/30300 (epoch 48.124), train_loss = 1.13187670, grad/param norm = 2.0477e-01, time/batch = 0.6839s	
29164/30300 (epoch 48.125), train_loss = 0.90092441, grad/param norm = 1.8462e-01, time/batch = 0.6830s	
29165/30300 (epoch 48.127), train_loss = 0.98647287, grad/param norm = 2.0948e-01, time/batch = 0.6841s	
29166/30300 (epoch 48.129), train_loss = 1.02361324, grad/param norm = 1.9568e-01, time/batch = 0.6832s	
29167/30300 (epoch 48.130), train_loss = 1.10217480, grad/param norm = 1.8890e-01, time/batch = 0.6866s	
29168/30300 (epoch 48.132), train_loss = 1.09566792, grad/param norm = 2.0291e-01, time/batch = 1.0122s	
29169/30300 (epoch 48.134), train_loss = 0.91033981, grad/param norm = 2.0315e-01, time/batch = 1.0578s	
29170/30300 (epoch 48.135), train_loss = 0.93623995, grad/param norm = 4.3561e-01, time/batch = 1.0213s	
29171/30300 (epoch 48.137), train_loss = 0.98338965, grad/param norm = 2.2262e-01, time/batch = 1.0022s	
29172/30300 (epoch 48.139), train_loss = 0.90391688, grad/param norm = 2.6797e-01, time/batch = 1.1359s	
29173/30300 (epoch 48.140), train_loss = 0.99191547, grad/param norm = 2.6217e-01, time/batch = 1.8794s	
29174/30300 (epoch 48.142), train_loss = 1.03819164, grad/param norm = 2.3376e-01, time/batch = 1.8990s	
29175/30300 (epoch 48.144), train_loss = 0.89156949, grad/param norm = 2.5219e-01, time/batch = 11.2099s	
29176/30300 (epoch 48.145), train_loss = 1.04210003, grad/param norm = 2.3308e-01, time/batch = 19.3742s	
29177/30300 (epoch 48.147), train_loss = 0.93035764, grad/param norm = 2.4295e-01, time/batch = 18.1926s	
29178/30300 (epoch 48.149), train_loss = 1.04753262, grad/param norm = 2.6171e-01, time/batch = 19.4667s	
29179/30300 (epoch 48.150), train_loss = 0.94454245, grad/param norm = 2.0918e-01, time/batch = 19.2206s	
29180/30300 (epoch 48.152), train_loss = 0.88696447, grad/param norm = 2.2128e-01, time/batch = 18.4559s	
29181/30300 (epoch 48.153), train_loss = 1.01226080, grad/param norm = 2.2660e-01, time/batch = 18.4495s	
29182/30300 (epoch 48.155), train_loss = 0.86561048, grad/param norm = 2.0209e-01, time/batch = 19.1246s	
29183/30300 (epoch 48.157), train_loss = 0.90275333, grad/param norm = 1.9868e-01, time/batch = 17.7872s	
29184/30300 (epoch 48.158), train_loss = 1.01228104, grad/param norm = 2.4454e-01, time/batch = 19.1496s	
29185/30300 (epoch 48.160), train_loss = 0.89634272, grad/param norm = 1.8758e-01, time/batch = 18.9656s	
29186/30300 (epoch 48.162), train_loss = 0.95299607, grad/param norm = 1.9215e-01, time/batch = 17.2567s	
29187/30300 (epoch 48.163), train_loss = 0.97356521, grad/param norm = 2.0691e-01, time/batch = 18.6285s	
29188/30300 (epoch 48.165), train_loss = 1.07506864, grad/param norm = 1.8558e-01, time/batch = 19.2218s	
29189/30300 (epoch 48.167), train_loss = 0.97298553, grad/param norm = 2.0271e-01, time/batch = 17.6231s	
29190/30300 (epoch 48.168), train_loss = 1.01672629, grad/param norm = 1.8101e-01, time/batch = 17.2894s	
29191/30300 (epoch 48.170), train_loss = 1.03110340, grad/param norm = 2.4708e-01, time/batch = 19.2178s	
29192/30300 (epoch 48.172), train_loss = 0.98372992, grad/param norm = 2.0643e-01, time/batch = 19.9609s	
29193/30300 (epoch 48.173), train_loss = 0.94563597, grad/param norm = 2.0362e-01, time/batch = 17.6038s	
29194/30300 (epoch 48.175), train_loss = 0.99825221, grad/param norm = 2.0739e-01, time/batch = 19.6346s	
29195/30300 (epoch 48.177), train_loss = 1.05738833, grad/param norm = 2.3232e-01, time/batch = 19.2176s	
29196/30300 (epoch 48.178), train_loss = 0.81485769, grad/param norm = 1.6750e-01, time/batch = 18.3753s	
29197/30300 (epoch 48.180), train_loss = 0.94322615, grad/param norm = 1.7918e-01, time/batch = 19.6184s	
29198/30300 (epoch 48.182), train_loss = 0.98340719, grad/param norm = 1.9618e-01, time/batch = 19.6250s	
29199/30300 (epoch 48.183), train_loss = 0.92878379, grad/param norm = 2.2054e-01, time/batch = 18.4570s	
29200/30300 (epoch 48.185), train_loss = 1.09301637, grad/param norm = 2.0701e-01, time/batch = 19.2038s	
29201/30300 (epoch 48.186), train_loss = 1.18289577, grad/param norm = 2.7805e-01, time/batch = 17.7054s	
29202/30300 (epoch 48.188), train_loss = 1.02954121, grad/param norm = 2.1383e-01, time/batch = 19.3695s	
29203/30300 (epoch 48.190), train_loss = 0.95815926, grad/param norm = 1.7519e-01, time/batch = 16.3816s	
29204/30300 (epoch 48.191), train_loss = 1.03195872, grad/param norm = 2.0701e-01, time/batch = 19.7143s	
29205/30300 (epoch 48.193), train_loss = 0.89076182, grad/param norm = 1.9973e-01, time/batch = 19.3820s	
29206/30300 (epoch 48.195), train_loss = 0.92441394, grad/param norm = 1.8016e-01, time/batch = 18.7766s	
29207/30300 (epoch 48.196), train_loss = 1.02209032, grad/param norm = 1.6675e-01, time/batch = 19.0598s	
29208/30300 (epoch 48.198), train_loss = 0.82895880, grad/param norm = 1.8368e-01, time/batch = 19.3092s	
29209/30300 (epoch 48.200), train_loss = 0.94183420, grad/param norm = 1.6744e-01, time/batch = 18.2101s	
29210/30300 (epoch 48.201), train_loss = 1.07478712, grad/param norm = 3.1322e-01, time/batch = 19.3913s	
29211/30300 (epoch 48.203), train_loss = 0.97027894, grad/param norm = 1.8063e-01, time/batch = 19.7824s	
29212/30300 (epoch 48.205), train_loss = 1.13830879, grad/param norm = 2.1829e-01, time/batch = 17.3845s	
29213/30300 (epoch 48.206), train_loss = 1.07284253, grad/param norm = 2.0504e-01, time/batch = 20.0392s	
29214/30300 (epoch 48.208), train_loss = 1.04094970, grad/param norm = 2.5910e-01, time/batch = 19.2139s	
29215/30300 (epoch 48.210), train_loss = 1.06540406, grad/param norm = 1.7623e-01, time/batch = 17.6671s	
29216/30300 (epoch 48.211), train_loss = 1.09305225, grad/param norm = 2.0280e-01, time/batch = 18.0435s	
29217/30300 (epoch 48.213), train_loss = 1.00107412, grad/param norm = 1.6193e-01, time/batch = 19.0289s	
29218/30300 (epoch 48.215), train_loss = 0.91129109, grad/param norm = 1.8425e-01, time/batch = 17.9363s	
29219/30300 (epoch 48.216), train_loss = 0.93578600, grad/param norm = 1.9316e-01, time/batch = 18.7818s	
29220/30300 (epoch 48.218), train_loss = 0.91041842, grad/param norm = 1.8237e-01, time/batch = 19.5598s	
29221/30300 (epoch 48.219), train_loss = 0.84747038, grad/param norm = 1.8006e-01, time/batch = 18.6369s	
29222/30300 (epoch 48.221), train_loss = 0.81843653, grad/param norm = 1.5440e-01, time/batch = 18.0464s	
29223/30300 (epoch 48.223), train_loss = 0.97695974, grad/param norm = 1.8758e-01, time/batch = 19.1878s	
29224/30300 (epoch 48.224), train_loss = 0.81975686, grad/param norm = 1.8376e-01, time/batch = 18.5468s	
29225/30300 (epoch 48.226), train_loss = 1.04118730, grad/param norm = 3.3217e-01, time/batch = 19.0293s	
29226/30300 (epoch 48.228), train_loss = 1.09363853, grad/param norm = 2.0637e-01, time/batch = 18.8802s	
29227/30300 (epoch 48.229), train_loss = 0.98062474, grad/param norm = 1.9119e-01, time/batch = 19.5361s	
29228/30300 (epoch 48.231), train_loss = 1.05347059, grad/param norm = 1.9650e-01, time/batch = 17.9527s	
29229/30300 (epoch 48.233), train_loss = 1.03176330, grad/param norm = 1.5676e-01, time/batch = 17.5362s	
29230/30300 (epoch 48.234), train_loss = 1.04363345, grad/param norm = 2.1738e-01, time/batch = 19.9618s	
29231/30300 (epoch 48.236), train_loss = 1.03396338, grad/param norm = 1.8811e-01, time/batch = 18.5394s	
29232/30300 (epoch 48.238), train_loss = 0.98682672, grad/param norm = 2.8150e-01, time/batch = 19.7840s	
29233/30300 (epoch 48.239), train_loss = 0.95603814, grad/param norm = 2.6789e-01, time/batch = 17.9408s	
29234/30300 (epoch 48.241), train_loss = 1.01154833, grad/param norm = 2.0179e-01, time/batch = 18.7898s	
29235/30300 (epoch 48.243), train_loss = 1.03136767, grad/param norm = 2.1967e-01, time/batch = 18.1165s	
29236/30300 (epoch 48.244), train_loss = 1.15766176, grad/param norm = 1.9135e-01, time/batch = 20.0480s	
29237/30300 (epoch 48.246), train_loss = 1.03389994, grad/param norm = 2.0643e-01, time/batch = 18.2868s	
29238/30300 (epoch 48.248), train_loss = 0.96657389, grad/param norm = 1.6187e-01, time/batch = 18.5455s	
29239/30300 (epoch 48.249), train_loss = 0.88762886, grad/param norm = 2.0696e-01, time/batch = 18.8046s	
29240/30300 (epoch 48.251), train_loss = 0.91334437, grad/param norm = 1.9333e-01, time/batch = 19.9756s	
29241/30300 (epoch 48.252), train_loss = 1.07174930, grad/param norm = 2.1546e-01, time/batch = 18.8694s	
29242/30300 (epoch 48.254), train_loss = 1.06650710, grad/param norm = 2.4088e-01, time/batch = 19.1100s	
29243/30300 (epoch 48.256), train_loss = 1.01368231, grad/param norm = 1.8697e-01, time/batch = 19.2179s	
29244/30300 (epoch 48.257), train_loss = 1.03661835, grad/param norm = 2.1327e-01, time/batch = 19.2866s	
29245/30300 (epoch 48.259), train_loss = 0.97387698, grad/param norm = 2.0063e-01, time/batch = 18.6419s	
29246/30300 (epoch 48.261), train_loss = 1.12235006, grad/param norm = 1.9634e-01, time/batch = 19.8897s	
29247/30300 (epoch 48.262), train_loss = 0.91600473, grad/param norm = 1.8544e-01, time/batch = 18.9594s	
29248/30300 (epoch 48.264), train_loss = 1.00049123, grad/param norm = 1.9926e-01, time/batch = 19.7091s	
29249/30300 (epoch 48.266), train_loss = 0.99633250, grad/param norm = 1.8065e-01, time/batch = 18.0329s	
29250/30300 (epoch 48.267), train_loss = 1.11230431, grad/param norm = 2.1604e-01, time/batch = 17.9405s	
29251/30300 (epoch 48.269), train_loss = 1.01115302, grad/param norm = 1.9247e-01, time/batch = 19.6205s	
29252/30300 (epoch 48.271), train_loss = 1.00197458, grad/param norm = 1.8556e-01, time/batch = 18.7967s	
29253/30300 (epoch 48.272), train_loss = 0.98465939, grad/param norm = 2.0839e-01, time/batch = 26.5312s	
29254/30300 (epoch 48.274), train_loss = 1.04518581, grad/param norm = 2.0726e-01, time/batch = 25.4920s	
29255/30300 (epoch 48.276), train_loss = 1.00868957, grad/param norm = 1.9915e-01, time/batch = 19.2137s	
29256/30300 (epoch 48.277), train_loss = 0.89424971, grad/param norm = 1.9150e-01, time/batch = 19.2059s	
29257/30300 (epoch 48.279), train_loss = 0.98126001, grad/param norm = 1.8751e-01, time/batch = 19.9657s	
29258/30300 (epoch 48.281), train_loss = 1.06940729, grad/param norm = 2.3723e-01, time/batch = 18.1708s	
29259/30300 (epoch 48.282), train_loss = 1.01535551, grad/param norm = 1.8048e-01, time/batch = 18.2888s	
29260/30300 (epoch 48.284), train_loss = 1.05974362, grad/param norm = 2.4217e-01, time/batch = 18.9697s	
29261/30300 (epoch 48.285), train_loss = 1.05138931, grad/param norm = 1.7996e-01, time/batch = 19.8842s	
29262/30300 (epoch 48.287), train_loss = 0.99514510, grad/param norm = 1.9799e-01, time/batch = 18.2824s	
29263/30300 (epoch 48.289), train_loss = 1.05983079, grad/param norm = 1.8425e-01, time/batch = 19.4582s	
29264/30300 (epoch 48.290), train_loss = 0.79800125, grad/param norm = 2.1030e-01, time/batch = 18.7126s	
29265/30300 (epoch 48.292), train_loss = 0.89813207, grad/param norm = 1.8729e-01, time/batch = 18.7006s	
29266/30300 (epoch 48.294), train_loss = 1.03643721, grad/param norm = 2.4063e-01, time/batch = 19.6323s	
29267/30300 (epoch 48.295), train_loss = 0.96360786, grad/param norm = 2.7133e-01, time/batch = 18.8924s	
29268/30300 (epoch 48.297), train_loss = 0.95982173, grad/param norm = 1.7838e-01, time/batch = 18.2042s	
29269/30300 (epoch 48.299), train_loss = 0.98840699, grad/param norm = 1.9738e-01, time/batch = 17.7663s	
29270/30300 (epoch 48.300), train_loss = 0.90147269, grad/param norm = 2.3375e-01, time/batch = 19.2148s	
29271/30300 (epoch 48.302), train_loss = 1.04310772, grad/param norm = 1.9340e-01, time/batch = 18.8741s	
29272/30300 (epoch 48.304), train_loss = 0.92463260, grad/param norm = 2.0729e-01, time/batch = 16.5348s	
29273/30300 (epoch 48.305), train_loss = 0.99579722, grad/param norm = 1.7710e-01, time/batch = 19.2153s	
29274/30300 (epoch 48.307), train_loss = 1.05837903, grad/param norm = 1.6825e-01, time/batch = 19.0430s	
29275/30300 (epoch 48.309), train_loss = 1.01099430, grad/param norm = 1.9412e-01, time/batch = 18.0085s	
29276/30300 (epoch 48.310), train_loss = 0.93890844, grad/param norm = 1.8064e-01, time/batch = 18.1381s	
29277/30300 (epoch 48.312), train_loss = 1.10821660, grad/param norm = 1.7659e-01, time/batch = 20.0461s	
29278/30300 (epoch 48.314), train_loss = 0.96432755, grad/param norm = 1.7222e-01, time/batch = 18.8626s	
29279/30300 (epoch 48.315), train_loss = 0.93483360, grad/param norm = 1.8204e-01, time/batch = 18.1348s	
29280/30300 (epoch 48.317), train_loss = 0.99792922, grad/param norm = 1.6997e-01, time/batch = 15.0583s	
29281/30300 (epoch 48.318), train_loss = 1.03156894, grad/param norm = 2.9420e-01, time/batch = 18.3637s	
29282/30300 (epoch 48.320), train_loss = 1.03958142, grad/param norm = 2.2244e-01, time/batch = 19.2060s	
29283/30300 (epoch 48.322), train_loss = 0.92646946, grad/param norm = 1.8310e-01, time/batch = 18.6315s	
29284/30300 (epoch 48.323), train_loss = 1.07843233, grad/param norm = 2.1007e-01, time/batch = 18.3768s	
29285/30300 (epoch 48.325), train_loss = 0.95993800, grad/param norm = 1.7654e-01, time/batch = 18.7545s	
29286/30300 (epoch 48.327), train_loss = 0.96273375, grad/param norm = 1.7053e-01, time/batch = 17.2749s	
29287/30300 (epoch 48.328), train_loss = 1.01951598, grad/param norm = 1.6768e-01, time/batch = 18.8024s	
29288/30300 (epoch 48.330), train_loss = 1.01957786, grad/param norm = 1.7758e-01, time/batch = 18.6044s	
29289/30300 (epoch 48.332), train_loss = 1.08410304, grad/param norm = 2.0984e-01, time/batch = 19.0533s	
29290/30300 (epoch 48.333), train_loss = 0.89228193, grad/param norm = 1.8289e-01, time/batch = 18.5606s	
29291/30300 (epoch 48.335), train_loss = 0.89332399, grad/param norm = 1.8239e-01, time/batch = 18.6142s	
29292/30300 (epoch 48.337), train_loss = 1.07008160, grad/param norm = 1.7493e-01, time/batch = 19.2949s	
29293/30300 (epoch 48.338), train_loss = 0.92863225, grad/param norm = 1.7767e-01, time/batch = 19.7868s	
29294/30300 (epoch 48.340), train_loss = 0.94863671, grad/param norm = 1.8993e-01, time/batch = 17.2830s	
29295/30300 (epoch 48.342), train_loss = 1.07200188, grad/param norm = 1.9403e-01, time/batch = 17.6994s	
29296/30300 (epoch 48.343), train_loss = 1.02165998, grad/param norm = 1.6981e-01, time/batch = 18.9978s	
29297/30300 (epoch 48.345), train_loss = 1.00491686, grad/param norm = 1.6489e-01, time/batch = 18.6184s	
29298/30300 (epoch 48.347), train_loss = 0.88939887, grad/param norm = 1.6531e-01, time/batch = 19.7068s	
29299/30300 (epoch 48.348), train_loss = 0.93778808, grad/param norm = 1.7636e-01, time/batch = 20.0424s	
29300/30300 (epoch 48.350), train_loss = 0.97314430, grad/param norm = 1.9188e-01, time/batch = 19.2045s	
29301/30300 (epoch 48.351), train_loss = 0.96085150, grad/param norm = 1.7828e-01, time/batch = 18.9627s	
29302/30300 (epoch 48.353), train_loss = 0.89380827, grad/param norm = 1.7868e-01, time/batch = 18.4635s	
29303/30300 (epoch 48.355), train_loss = 0.93155946, grad/param norm = 1.7678e-01, time/batch = 18.6821s	
29304/30300 (epoch 48.356), train_loss = 1.02224239, grad/param norm = 2.1002e-01, time/batch = 18.7118s	
29305/30300 (epoch 48.358), train_loss = 1.21174928, grad/param norm = 1.8726e-01, time/batch = 19.6384s	
29306/30300 (epoch 48.360), train_loss = 0.95805287, grad/param norm = 1.9448e-01, time/batch = 19.8869s	
29307/30300 (epoch 48.361), train_loss = 0.98206438, grad/param norm = 1.9411e-01, time/batch = 18.0499s	
29308/30300 (epoch 48.363), train_loss = 1.00403452, grad/param norm = 1.7647e-01, time/batch = 19.1357s	
29309/30300 (epoch 48.365), train_loss = 0.83112665, grad/param norm = 1.9752e-01, time/batch = 20.1237s	
29310/30300 (epoch 48.366), train_loss = 0.94041856, grad/param norm = 1.6133e-01, time/batch = 18.9566s	
29311/30300 (epoch 48.368), train_loss = 0.85768667, grad/param norm = 1.7691e-01, time/batch = 18.5442s	
29312/30300 (epoch 48.370), train_loss = 0.87350737, grad/param norm = 1.8413e-01, time/batch = 17.8629s	
29313/30300 (epoch 48.371), train_loss = 1.05897337, grad/param norm = 2.1053e-01, time/batch = 18.3738s	
29314/30300 (epoch 48.373), train_loss = 0.90816842, grad/param norm = 1.6555e-01, time/batch = 19.0304s	
29315/30300 (epoch 48.375), train_loss = 0.90539441, grad/param norm = 1.5899e-01, time/batch = 19.5524s	
29316/30300 (epoch 48.376), train_loss = 0.92207630, grad/param norm = 1.6021e-01, time/batch = 18.5378s	
29317/30300 (epoch 48.378), train_loss = 0.89080072, grad/param norm = 1.9978e-01, time/batch = 18.9779s	
29318/30300 (epoch 48.380), train_loss = 1.07220070, grad/param norm = 1.7966e-01, time/batch = 19.1326s	
29319/30300 (epoch 48.381), train_loss = 0.82099468, grad/param norm = 1.8165e-01, time/batch = 18.8784s	
29320/30300 (epoch 48.383), train_loss = 0.87740035, grad/param norm = 2.0252e-01, time/batch = 18.4662s	
29321/30300 (epoch 48.384), train_loss = 0.99970638, grad/param norm = 2.0773e-01, time/batch = 18.7670s	
29322/30300 (epoch 48.386), train_loss = 0.87607991, grad/param norm = 1.6857e-01, time/batch = 18.7742s	
29323/30300 (epoch 48.388), train_loss = 0.86637842, grad/param norm = 1.8175e-01, time/batch = 19.4546s	
29324/30300 (epoch 48.389), train_loss = 0.94488363, grad/param norm = 1.6919e-01, time/batch = 17.6281s	
29325/30300 (epoch 48.391), train_loss = 1.02054652, grad/param norm = 2.0106e-01, time/batch = 17.1008s	
29326/30300 (epoch 48.393), train_loss = 0.86652082, grad/param norm = 1.5365e-01, time/batch = 18.2001s	
29327/30300 (epoch 48.394), train_loss = 0.97834079, grad/param norm = 1.5853e-01, time/batch = 18.2944s	
29328/30300 (epoch 48.396), train_loss = 1.09765850, grad/param norm = 1.6365e-01, time/batch = 18.1970s	
29329/30300 (epoch 48.398), train_loss = 0.95551702, grad/param norm = 1.7802e-01, time/batch = 18.5331s	
29330/30300 (epoch 48.399), train_loss = 0.85287155, grad/param norm = 1.6517e-01, time/batch = 19.2104s	
29331/30300 (epoch 48.401), train_loss = 0.97310322, grad/param norm = 2.4119e-01, time/batch = 19.2169s	
29332/30300 (epoch 48.403), train_loss = 0.96352273, grad/param norm = 1.7791e-01, time/batch = 18.1267s	
29333/30300 (epoch 48.404), train_loss = 0.91536275, grad/param norm = 1.9938e-01, time/batch = 18.0227s	
29334/30300 (epoch 48.406), train_loss = 0.96792085, grad/param norm = 1.7057e-01, time/batch = 19.8034s	
29335/30300 (epoch 48.408), train_loss = 0.84398468, grad/param norm = 1.5466e-01, time/batch = 18.7885s	
29336/30300 (epoch 48.409), train_loss = 0.86088334, grad/param norm = 1.9344e-01, time/batch = 18.7081s	
29337/30300 (epoch 48.411), train_loss = 0.89533908, grad/param norm = 1.4890e-01, time/batch = 19.5642s	
29338/30300 (epoch 48.413), train_loss = 0.80948535, grad/param norm = 1.6964e-01, time/batch = 19.2070s	
29339/30300 (epoch 48.414), train_loss = 0.98851504, grad/param norm = 1.7538e-01, time/batch = 18.3784s	
29340/30300 (epoch 48.416), train_loss = 0.89024275, grad/param norm = 1.8800e-01, time/batch = 19.8826s	
29341/30300 (epoch 48.417), train_loss = 0.89363072, grad/param norm = 2.0265e-01, time/batch = 18.5242s	
29342/30300 (epoch 48.419), train_loss = 0.86207913, grad/param norm = 1.5172e-01, time/batch = 18.7956s	
29343/30300 (epoch 48.421), train_loss = 0.92141385, grad/param norm = 2.0294e-01, time/batch = 18.2246s	
29344/30300 (epoch 48.422), train_loss = 0.96551892, grad/param norm = 1.9951e-01, time/batch = 19.3820s	
29345/30300 (epoch 48.424), train_loss = 0.97627678, grad/param norm = 1.8770e-01, time/batch = 18.5332s	
29346/30300 (epoch 48.426), train_loss = 0.94822746, grad/param norm = 1.8020e-01, time/batch = 17.8683s	
29347/30300 (epoch 48.427), train_loss = 0.92984194, grad/param norm = 2.0827e-01, time/batch = 18.5412s	
29348/30300 (epoch 48.429), train_loss = 0.95606246, grad/param norm = 1.6836e-01, time/batch = 17.7028s	
29349/30300 (epoch 48.431), train_loss = 0.96977785, grad/param norm = 1.7809e-01, time/batch = 20.0612s	
29350/30300 (epoch 48.432), train_loss = 0.99503778, grad/param norm = 1.7072e-01, time/batch = 19.6277s	
29351/30300 (epoch 48.434), train_loss = 0.85329869, grad/param norm = 1.6786e-01, time/batch = 17.7662s	
29352/30300 (epoch 48.436), train_loss = 1.05109583, grad/param norm = 2.0220e-01, time/batch = 19.2175s	
29353/30300 (epoch 48.437), train_loss = 0.87508938, grad/param norm = 2.1053e-01, time/batch = 19.2068s	
29354/30300 (epoch 48.439), train_loss = 0.91477788, grad/param norm = 1.5130e-01, time/batch = 19.0345s	
29355/30300 (epoch 48.441), train_loss = 0.95407854, grad/param norm = 1.8932e-01, time/batch = 19.1161s	
29356/30300 (epoch 48.442), train_loss = 0.88454775, grad/param norm = 1.7306e-01, time/batch = 18.2019s	
29357/30300 (epoch 48.444), train_loss = 0.79747116, grad/param norm = 1.7511e-01, time/batch = 19.1307s	
29358/30300 (epoch 48.446), train_loss = 0.90472851, grad/param norm = 1.5614e-01, time/batch = 18.5455s	
29359/30300 (epoch 48.447), train_loss = 0.94967339, grad/param norm = 1.6723e-01, time/batch = 19.2060s	
29360/30300 (epoch 48.449), train_loss = 0.90381214, grad/param norm = 1.9752e-01, time/batch = 18.7171s	
29361/30300 (epoch 48.450), train_loss = 0.97643013, grad/param norm = 1.5448e-01, time/batch = 18.3515s	
29362/30300 (epoch 48.452), train_loss = 1.07739515, grad/param norm = 1.7497e-01, time/batch = 19.5477s	
29363/30300 (epoch 48.454), train_loss = 1.00554815, grad/param norm = 1.6932e-01, time/batch = 18.4373s	
29364/30300 (epoch 48.455), train_loss = 0.97498012, grad/param norm = 1.9206e-01, time/batch = 17.7111s	
29365/30300 (epoch 48.457), train_loss = 0.96319080, grad/param norm = 2.1089e-01, time/batch = 19.4594s	
29366/30300 (epoch 48.459), train_loss = 0.99300569, grad/param norm = 2.0319e-01, time/batch = 19.8858s	
29367/30300 (epoch 48.460), train_loss = 1.04612655, grad/param norm = 1.7756e-01, time/batch = 18.1295s	
29368/30300 (epoch 48.462), train_loss = 1.03937086, grad/param norm = 1.9699e-01, time/batch = 16.6195s	
29369/30300 (epoch 48.464), train_loss = 0.78375780, grad/param norm = 2.2096e-01, time/batch = 19.4462s	
29370/30300 (epoch 48.465), train_loss = 0.83235615, grad/param norm = 1.7090e-01, time/batch = 18.5493s	
29371/30300 (epoch 48.467), train_loss = 0.81169257, grad/param norm = 1.6257e-01, time/batch = 17.8590s	
29372/30300 (epoch 48.469), train_loss = 0.89040382, grad/param norm = 1.8277e-01, time/batch = 18.6319s	
29373/30300 (epoch 48.470), train_loss = 0.90980173, grad/param norm = 1.9012e-01, time/batch = 19.4611s	
29374/30300 (epoch 48.472), train_loss = 0.90518912, grad/param norm = 1.5287e-01, time/batch = 19.1331s	
29375/30300 (epoch 48.474), train_loss = 0.90057003, grad/param norm = 1.9456e-01, time/batch = 18.7972s	
29376/30300 (epoch 48.475), train_loss = 0.89330082, grad/param norm = 1.8225e-01, time/batch = 19.2910s	
29377/30300 (epoch 48.477), train_loss = 0.93603943, grad/param norm = 1.7704e-01, time/batch = 18.3552s	
29378/30300 (epoch 48.479), train_loss = 0.89047181, grad/param norm = 1.7629e-01, time/batch = 20.2154s	
29379/30300 (epoch 48.480), train_loss = 0.98291672, grad/param norm = 1.8219e-01, time/batch = 18.5447s	
29380/30300 (epoch 48.482), train_loss = 1.00985518, grad/param norm = 1.7187e-01, time/batch = 17.9404s	
29381/30300 (epoch 48.483), train_loss = 0.95433457, grad/param norm = 1.8639e-01, time/batch = 19.7190s	
29382/30300 (epoch 48.485), train_loss = 0.97052038, grad/param norm = 2.0060e-01, time/batch = 19.8823s	
29383/30300 (epoch 48.487), train_loss = 1.01302938, grad/param norm = 1.7570e-01, time/batch = 17.7720s	
29384/30300 (epoch 48.488), train_loss = 1.08467728, grad/param norm = 1.6345e-01, time/batch = 19.1367s	
29385/30300 (epoch 48.490), train_loss = 0.84143116, grad/param norm = 1.8244e-01, time/batch = 19.5505s	
29386/30300 (epoch 48.492), train_loss = 0.91751174, grad/param norm = 1.9439e-01, time/batch = 18.9590s	
29387/30300 (epoch 48.493), train_loss = 0.96340759, grad/param norm = 1.7898e-01, time/batch = 18.6595s	
29388/30300 (epoch 48.495), train_loss = 0.94506277, grad/param norm = 1.5176e-01, time/batch = 19.2764s	
29389/30300 (epoch 48.497), train_loss = 1.00400535, grad/param norm = 1.7774e-01, time/batch = 18.7126s	
29390/30300 (epoch 48.498), train_loss = 1.02087534, grad/param norm = 1.7361e-01, time/batch = 19.3841s	
29391/30300 (epoch 48.500), train_loss = 0.89746566, grad/param norm = 2.1569e-01, time/batch = 18.1050s	
29392/30300 (epoch 48.502), train_loss = 0.97182109, grad/param norm = 2.5041e-01, time/batch = 18.6281s	
29393/30300 (epoch 48.503), train_loss = 1.05377846, grad/param norm = 1.7296e-01, time/batch = 18.9574s	
29394/30300 (epoch 48.505), train_loss = 0.83989166, grad/param norm = 1.5317e-01, time/batch = 20.0618s	
29395/30300 (epoch 48.507), train_loss = 0.85222053, grad/param norm = 1.9589e-01, time/batch = 18.8763s	
29396/30300 (epoch 48.508), train_loss = 0.90811554, grad/param norm = 2.0207e-01, time/batch = 17.1969s	
29397/30300 (epoch 48.510), train_loss = 1.02481980, grad/param norm = 2.2246e-01, time/batch = 20.1242s	
29398/30300 (epoch 48.512), train_loss = 0.89056001, grad/param norm = 1.6535e-01, time/batch = 19.3745s	
29399/30300 (epoch 48.513), train_loss = 0.96369907, grad/param norm = 1.7910e-01, time/batch = 18.9439s	
29400/30300 (epoch 48.515), train_loss = 0.95379998, grad/param norm = 1.7313e-01, time/batch = 18.3694s	
29401/30300 (epoch 48.517), train_loss = 0.78512375, grad/param norm = 1.8809e-01, time/batch = 19.5500s	
29402/30300 (epoch 48.518), train_loss = 1.04262141, grad/param norm = 2.0457e-01, time/batch = 18.4533s	
29403/30300 (epoch 48.520), train_loss = 0.91676932, grad/param norm = 1.7298e-01, time/batch = 20.2022s	
29404/30300 (epoch 48.521), train_loss = 0.86256708, grad/param norm = 2.1939e-01, time/batch = 19.7093s	
29405/30300 (epoch 48.523), train_loss = 1.04986430, grad/param norm = 2.1636e-01, time/batch = 17.8634s	
29406/30300 (epoch 48.525), train_loss = 0.87626409, grad/param norm = 1.9211e-01, time/batch = 19.2898s	
29407/30300 (epoch 48.526), train_loss = 0.97036643, grad/param norm = 1.6976e-01, time/batch = 19.2022s	
29408/30300 (epoch 48.528), train_loss = 0.82935372, grad/param norm = 1.6261e-01, time/batch = 18.3755s	
29409/30300 (epoch 48.530), train_loss = 0.81911460, grad/param norm = 1.7630e-01, time/batch = 18.5452s	
29410/30300 (epoch 48.531), train_loss = 0.92914442, grad/param norm = 1.9105e-01, time/batch = 17.6950s	
29411/30300 (epoch 48.533), train_loss = 0.93095256, grad/param norm = 2.0912e-01, time/batch = 19.2814s	
29412/30300 (epoch 48.535), train_loss = 0.95947517, grad/param norm = 1.5632e-01, time/batch = 17.5203s	
29413/30300 (epoch 48.536), train_loss = 0.95530268, grad/param norm = 2.0312e-01, time/batch = 19.0497s	
29414/30300 (epoch 48.538), train_loss = 0.84184156, grad/param norm = 2.1383e-01, time/batch = 19.3684s	
29415/30300 (epoch 48.540), train_loss = 0.89846765, grad/param norm = 2.2282e-01, time/batch = 18.4437s	
29416/30300 (epoch 48.541), train_loss = 0.92721611, grad/param norm = 1.8931e-01, time/batch = 19.2848s	
29417/30300 (epoch 48.543), train_loss = 0.93024289, grad/param norm = 1.6641e-01, time/batch = 19.5425s	
29418/30300 (epoch 48.545), train_loss = 1.00604181, grad/param norm = 2.3363e-01, time/batch = 18.8753s	
29419/30300 (epoch 48.546), train_loss = 1.10538292, grad/param norm = 1.7493e-01, time/batch = 19.1339s	
29420/30300 (epoch 48.548), train_loss = 0.91030041, grad/param norm = 1.5879e-01, time/batch = 18.9599s	
29421/30300 (epoch 48.550), train_loss = 1.00703451, grad/param norm = 2.2889e-01, time/batch = 17.9381s	
29422/30300 (epoch 48.551), train_loss = 0.88533390, grad/param norm = 1.7972e-01, time/batch = 19.8781s	
29423/30300 (epoch 48.553), train_loss = 0.91752794, grad/param norm = 1.8363e-01, time/batch = 18.3062s	
29424/30300 (epoch 48.554), train_loss = 0.93959478, grad/param norm = 1.7937e-01, time/batch = 17.9679s	
29425/30300 (epoch 48.556), train_loss = 0.98017966, grad/param norm = 1.7158e-01, time/batch = 19.1390s	
29426/30300 (epoch 48.558), train_loss = 1.06685324, grad/param norm = 2.3075e-01, time/batch = 19.7107s	
29427/30300 (epoch 48.559), train_loss = 0.97999357, grad/param norm = 2.1149e-01, time/batch = 17.9566s	
29428/30300 (epoch 48.561), train_loss = 0.77169938, grad/param norm = 1.8357e-01, time/batch = 19.3003s	
29429/30300 (epoch 48.563), train_loss = 0.84545950, grad/param norm = 1.9812e-01, time/batch = 18.0455s	
29430/30300 (epoch 48.564), train_loss = 0.92108721, grad/param norm = 1.5915e-01, time/batch = 18.5356s	
29431/30300 (epoch 48.566), train_loss = 0.91854922, grad/param norm = 1.6646e-01, time/batch = 19.2985s	
29432/30300 (epoch 48.568), train_loss = 0.81875055, grad/param norm = 2.2421e-01, time/batch = 20.1365s	
29433/30300 (epoch 48.569), train_loss = 0.96924717, grad/param norm = 1.6860e-01, time/batch = 18.7171s	
29434/30300 (epoch 48.571), train_loss = 0.95817093, grad/param norm = 1.9724e-01, time/batch = 19.6341s	
29435/30300 (epoch 48.573), train_loss = 0.96485765, grad/param norm = 1.7477e-01, time/batch = 19.8914s	
29436/30300 (epoch 48.574), train_loss = 0.96966340, grad/param norm = 1.8193e-01, time/batch = 18.0910s	
29437/30300 (epoch 48.576), train_loss = 0.93020548, grad/param norm = 1.5771e-01, time/batch = 19.0472s	
29438/30300 (epoch 48.578), train_loss = 0.82424141, grad/param norm = 1.6570e-01, time/batch = 19.7925s	
29439/30300 (epoch 48.579), train_loss = 1.00887451, grad/param norm = 2.1333e-01, time/batch = 18.6104s	
29440/30300 (epoch 48.581), train_loss = 1.05224437, grad/param norm = 1.7120e-01, time/batch = 19.1128s	
29441/30300 (epoch 48.583), train_loss = 1.06279188, grad/param norm = 2.1159e-01, time/batch = 19.6326s	
29442/30300 (epoch 48.584), train_loss = 1.06563480, grad/param norm = 1.7717e-01, time/batch = 19.0508s	
29443/30300 (epoch 48.586), train_loss = 0.91025120, grad/param norm = 1.7533e-01, time/batch = 33.0215s	
29444/30300 (epoch 48.587), train_loss = 0.94910700, grad/param norm = 2.0798e-01, time/batch = 19.7234s	
29445/30300 (epoch 48.589), train_loss = 0.87350189, grad/param norm = 1.7315e-01, time/batch = 17.2016s	
29446/30300 (epoch 48.591), train_loss = 0.99681055, grad/param norm = 1.6072e-01, time/batch = 18.4529s	
29447/30300 (epoch 48.592), train_loss = 0.92797187, grad/param norm = 1.6523e-01, time/batch = 18.5473s	
29448/30300 (epoch 48.594), train_loss = 1.02426020, grad/param norm = 1.8470e-01, time/batch = 18.9518s	
29449/30300 (epoch 48.596), train_loss = 0.87861268, grad/param norm = 1.6246e-01, time/batch = 18.9486s	
29450/30300 (epoch 48.597), train_loss = 0.89338272, grad/param norm = 2.0620e-01, time/batch = 20.1276s	
29451/30300 (epoch 48.599), train_loss = 0.81531991, grad/param norm = 1.8138e-01, time/batch = 18.5521s	
29452/30300 (epoch 48.601), train_loss = 0.96253634, grad/param norm = 1.9042e-01, time/batch = 20.0429s	
29453/30300 (epoch 48.602), train_loss = 0.95501413, grad/param norm = 1.5571e-01, time/batch = 18.7279s	
29454/30300 (epoch 48.604), train_loss = 0.87132877, grad/param norm = 1.6013e-01, time/batch = 18.6228s	
29455/30300 (epoch 48.606), train_loss = 0.88681868, grad/param norm = 2.2234e-01, time/batch = 19.4504s	
29456/30300 (epoch 48.607), train_loss = 1.01106205, grad/param norm = 2.0130e-01, time/batch = 19.2941s	
29457/30300 (epoch 48.609), train_loss = 1.09860506, grad/param norm = 1.7969e-01, time/batch = 19.8816s	
29458/30300 (epoch 48.611), train_loss = 0.92835050, grad/param norm = 1.6334e-01, time/batch = 19.4421s	
29459/30300 (epoch 48.612), train_loss = 0.85831402, grad/param norm = 1.4898e-01, time/batch = 18.8751s	
29460/30300 (epoch 48.614), train_loss = 0.93228275, grad/param norm = 1.6702e-01, time/batch = 19.9363s	
29461/30300 (epoch 48.616), train_loss = 0.95675490, grad/param norm = 2.0598e-01, time/batch = 18.4483s	
29462/30300 (epoch 48.617), train_loss = 0.93094802, grad/param norm = 1.8696e-01, time/batch = 19.5393s	
29463/30300 (epoch 48.619), train_loss = 0.77746727, grad/param norm = 1.5168e-01, time/batch = 19.1321s	
29464/30300 (epoch 48.620), train_loss = 0.99223330, grad/param norm = 2.0320e-01, time/batch = 19.2848s	
29465/30300 (epoch 48.622), train_loss = 0.93975431, grad/param norm = 2.1229e-01, time/batch = 17.2910s	
29466/30300 (epoch 48.624), train_loss = 0.93548070, grad/param norm = 1.8809e-01, time/batch = 19.5399s	
29467/30300 (epoch 48.625), train_loss = 0.92930061, grad/param norm = 1.9561e-01, time/batch = 18.2876s	
29468/30300 (epoch 48.627), train_loss = 1.04464906, grad/param norm = 2.1246e-01, time/batch = 20.2967s	
29469/30300 (epoch 48.629), train_loss = 1.04874432, grad/param norm = 1.6752e-01, time/batch = 19.8007s	
29470/30300 (epoch 48.630), train_loss = 0.93425631, grad/param norm = 1.6997e-01, time/batch = 16.8679s	
29471/30300 (epoch 48.632), train_loss = 0.97635746, grad/param norm = 1.8790e-01, time/batch = 18.0388s	
29472/30300 (epoch 48.634), train_loss = 0.88346628, grad/param norm = 1.8162e-01, time/batch = 19.7947s	
29473/30300 (epoch 48.635), train_loss = 0.96584994, grad/param norm = 1.8926e-01, time/batch = 17.8596s	
29474/30300 (epoch 48.637), train_loss = 1.02218873, grad/param norm = 2.2699e-01, time/batch = 18.8717s	
29475/30300 (epoch 48.639), train_loss = 0.93987979, grad/param norm = 1.9379e-01, time/batch = 20.0569s	
29476/30300 (epoch 48.640), train_loss = 1.06172803, grad/param norm = 2.0013e-01, time/batch = 19.5489s	
29477/30300 (epoch 48.642), train_loss = 0.94568096, grad/param norm = 1.7676e-01, time/batch = 19.2875s	
29478/30300 (epoch 48.644), train_loss = 1.02725786, grad/param norm = 1.7986e-01, time/batch = 19.7088s	
29479/30300 (epoch 48.645), train_loss = 0.88905367, grad/param norm = 1.6981e-01, time/batch = 19.3771s	
29480/30300 (epoch 48.647), train_loss = 0.93297074, grad/param norm = 1.7014e-01, time/batch = 18.6034s	
29481/30300 (epoch 48.649), train_loss = 0.95263548, grad/param norm = 2.2548e-01, time/batch = 19.0942s	
29482/30300 (epoch 48.650), train_loss = 0.95418580, grad/param norm = 1.6326e-01, time/batch = 20.2044s	
29483/30300 (epoch 48.652), train_loss = 0.93989973, grad/param norm = 1.8341e-01, time/batch = 18.3761s	
29484/30300 (epoch 48.653), train_loss = 1.08898319, grad/param norm = 1.6771e-01, time/batch = 19.7025s	
29485/30300 (epoch 48.655), train_loss = 0.92983745, grad/param norm = 1.8862e-01, time/batch = 18.8706s	
29486/30300 (epoch 48.657), train_loss = 0.85615258, grad/param norm = 1.9814e-01, time/batch = 17.1995s	
29487/30300 (epoch 48.658), train_loss = 0.92202615, grad/param norm = 1.7095e-01, time/batch = 18.7089s	
29488/30300 (epoch 48.660), train_loss = 0.94324846, grad/param norm = 1.9086e-01, time/batch = 20.3719s	
29489/30300 (epoch 48.662), train_loss = 0.97537708, grad/param norm = 2.6207e-01, time/batch = 18.5224s	
29490/30300 (epoch 48.663), train_loss = 1.01775820, grad/param norm = 1.8071e-01, time/batch = 20.0468s	
29491/30300 (epoch 48.665), train_loss = 0.87000853, grad/param norm = 1.9145e-01, time/batch = 20.5370s	
29492/30300 (epoch 48.667), train_loss = 1.00270836, grad/param norm = 1.9442e-01, time/batch = 18.8764s	
29493/30300 (epoch 48.668), train_loss = 1.03548162, grad/param norm = 1.8931e-01, time/batch = 19.4756s	
29494/30300 (epoch 48.670), train_loss = 1.05821250, grad/param norm = 1.9378e-01, time/batch = 18.9635s	
29495/30300 (epoch 48.672), train_loss = 0.95306313, grad/param norm = 1.8600e-01, time/batch = 19.0426s	
29496/30300 (epoch 48.673), train_loss = 0.99911872, grad/param norm = 2.0291e-01, time/batch = 18.7106s	
29497/30300 (epoch 48.675), train_loss = 0.94599817, grad/param norm = 1.9525e-01, time/batch = 19.4610s	
29498/30300 (epoch 48.677), train_loss = 0.90746293, grad/param norm = 1.6948e-01, time/batch = 19.1333s	
29499/30300 (epoch 48.678), train_loss = 0.92913726, grad/param norm = 1.9757e-01, time/batch = 19.7068s	
29500/30300 (epoch 48.680), train_loss = 0.86079609, grad/param norm = 1.7086e-01, time/batch = 20.1335s	
29501/30300 (epoch 48.682), train_loss = 0.94598926, grad/param norm = 1.7452e-01, time/batch = 16.5873s	
29502/30300 (epoch 48.683), train_loss = 1.00946256, grad/param norm = 1.7836e-01, time/batch = 19.2134s	
29503/30300 (epoch 48.685), train_loss = 1.00172641, grad/param norm = 2.0281e-01, time/batch = 19.5381s	
29504/30300 (epoch 48.686), train_loss = 0.94866786, grad/param norm = 1.7691e-01, time/batch = 18.7159s	
29505/30300 (epoch 48.688), train_loss = 0.95583496, grad/param norm = 1.6047e-01, time/batch = 18.3353s	
29506/30300 (epoch 48.690), train_loss = 0.90865420, grad/param norm = 1.7710e-01, time/batch = 17.2821s	
29507/30300 (epoch 48.691), train_loss = 0.94562738, grad/param norm = 1.8484e-01, time/batch = 18.9549s	
29508/30300 (epoch 48.693), train_loss = 1.22082807, grad/param norm = 2.2346e-01, time/batch = 18.6131s	
29509/30300 (epoch 48.695), train_loss = 1.02098618, grad/param norm = 1.9525e-01, time/batch = 19.7022s	
29510/30300 (epoch 48.696), train_loss = 0.97840670, grad/param norm = 2.3394e-01, time/batch = 19.7941s	
29511/30300 (epoch 48.698), train_loss = 0.91731906, grad/param norm = 1.9066e-01, time/batch = 18.3754s	
29512/30300 (epoch 48.700), train_loss = 0.88678918, grad/param norm = 1.6861e-01, time/batch = 19.5494s	
29513/30300 (epoch 48.701), train_loss = 0.84771371, grad/param norm = 1.6782e-01, time/batch = 15.0716s	
29514/30300 (epoch 48.703), train_loss = 0.95193463, grad/param norm = 1.6695e-01, time/batch = 18.3625s	
29515/30300 (epoch 48.705), train_loss = 0.87308980, grad/param norm = 1.6803e-01, time/batch = 18.8574s	
29516/30300 (epoch 48.706), train_loss = 1.01685130, grad/param norm = 1.6970e-01, time/batch = 19.3023s	
29517/30300 (epoch 48.708), train_loss = 0.94594234, grad/param norm = 1.6079e-01, time/batch = 19.1077s	
29518/30300 (epoch 48.710), train_loss = 0.93286202, grad/param norm = 1.7618e-01, time/batch = 17.2851s	
29519/30300 (epoch 48.711), train_loss = 0.88705624, grad/param norm = 1.8380e-01, time/batch = 19.4448s	
29520/30300 (epoch 48.713), train_loss = 0.88788666, grad/param norm = 1.7683e-01, time/batch = 20.0394s	
29521/30300 (epoch 48.715), train_loss = 0.93441080, grad/param norm = 1.7828e-01, time/batch = 18.9497s	
29522/30300 (epoch 48.716), train_loss = 1.00514719, grad/param norm = 1.7135e-01, time/batch = 18.2619s	
29523/30300 (epoch 48.718), train_loss = 1.05118830, grad/param norm = 1.8478e-01, time/batch = 19.9625s	
29524/30300 (epoch 48.719), train_loss = 0.91178968, grad/param norm = 2.0464e-01, time/batch = 18.5406s	
29525/30300 (epoch 48.721), train_loss = 0.94035379, grad/param norm = 1.8916e-01, time/batch = 19.6231s	
29526/30300 (epoch 48.723), train_loss = 0.88021414, grad/param norm = 1.6022e-01, time/batch = 19.5566s	
29527/30300 (epoch 48.724), train_loss = 0.96371382, grad/param norm = 2.0103e-01, time/batch = 18.7016s	
29528/30300 (epoch 48.726), train_loss = 1.19689671, grad/param norm = 2.4349e-01, time/batch = 19.2993s	
29529/30300 (epoch 48.728), train_loss = 0.99799539, grad/param norm = 1.9295e-01, time/batch = 19.8923s	
29530/30300 (epoch 48.729), train_loss = 0.91374467, grad/param norm = 1.8053e-01, time/batch = 17.9671s	
29531/30300 (epoch 48.731), train_loss = 0.91067269, grad/param norm = 1.9419e-01, time/batch = 19.9616s	
29532/30300 (epoch 48.733), train_loss = 0.95144015, grad/param norm = 1.7878e-01, time/batch = 17.2641s	
29533/30300 (epoch 48.734), train_loss = 1.02240981, grad/param norm = 1.6944e-01, time/batch = 18.1977s	
29534/30300 (epoch 48.736), train_loss = 0.98301409, grad/param norm = 1.9084e-01, time/batch = 19.3672s	
29535/30300 (epoch 48.738), train_loss = 0.90188943, grad/param norm = 1.5029e-01, time/batch = 19.8888s	
29536/30300 (epoch 48.739), train_loss = 1.06301441, grad/param norm = 2.3444e-01, time/batch = 18.6275s	
29537/30300 (epoch 48.741), train_loss = 1.08157433, grad/param norm = 1.8747e-01, time/batch = 19.5282s	
29538/30300 (epoch 48.743), train_loss = 0.92608891, grad/param norm = 1.8709e-01, time/batch = 19.6234s	
29539/30300 (epoch 48.744), train_loss = 1.00041394, grad/param norm = 1.9101e-01, time/batch = 18.2107s	
29540/30300 (epoch 48.746), train_loss = 0.91554833, grad/param norm = 1.5731e-01, time/batch = 19.2901s	
29541/30300 (epoch 48.748), train_loss = 0.94425853, grad/param norm = 2.1381e-01, time/batch = 18.3689s	
29542/30300 (epoch 48.749), train_loss = 0.97945853, grad/param norm = 1.8662e-01, time/batch = 20.0798s	
29543/30300 (epoch 48.751), train_loss = 0.99537798, grad/param norm = 1.7217e-01, time/batch = 18.7100s	
29544/30300 (epoch 48.752), train_loss = 0.93701685, grad/param norm = 1.8717e-01, time/batch = 20.4685s	
29545/30300 (epoch 48.754), train_loss = 0.93388459, grad/param norm = 1.7424e-01, time/batch = 19.6188s	
29546/30300 (epoch 48.756), train_loss = 0.95094331, grad/param norm = 1.8340e-01, time/batch = 18.2146s	
29547/30300 (epoch 48.757), train_loss = 0.86430313, grad/param norm = 1.8867e-01, time/batch = 19.0240s	
29548/30300 (epoch 48.759), train_loss = 0.96283346, grad/param norm = 1.7163e-01, time/batch = 19.4545s	
29549/30300 (epoch 48.761), train_loss = 0.81592051, grad/param norm = 1.6086e-01, time/batch = 17.2670s	
29550/30300 (epoch 48.762), train_loss = 0.84701931, grad/param norm = 1.6980e-01, time/batch = 19.6290s	
29551/30300 (epoch 48.764), train_loss = 0.93495359, grad/param norm = 1.9308e-01, time/batch = 20.2153s	
29552/30300 (epoch 48.766), train_loss = 1.06608250, grad/param norm = 1.8587e-01, time/batch = 17.0239s	
29553/30300 (epoch 48.767), train_loss = 0.93019685, grad/param norm = 2.0377e-01, time/batch = 19.5539s	
29554/30300 (epoch 48.769), train_loss = 0.96735953, grad/param norm = 2.3988e-01, time/batch = 19.7150s	
29555/30300 (epoch 48.771), train_loss = 0.88221234, grad/param norm = 2.2021e-01, time/batch = 18.8854s	
29556/30300 (epoch 48.772), train_loss = 0.93638030, grad/param norm = 1.7964e-01, time/batch = 18.7098s	
29557/30300 (epoch 48.774), train_loss = 1.13794034, grad/param norm = 1.9878e-01, time/batch = 19.3744s	
29558/30300 (epoch 48.776), train_loss = 0.90972943, grad/param norm = 1.8338e-01, time/batch = 19.1127s	
29559/30300 (epoch 48.777), train_loss = 1.07802844, grad/param norm = 1.7999e-01, time/batch = 19.3786s	
29560/30300 (epoch 48.779), train_loss = 1.07748448, grad/param norm = 1.7871e-01, time/batch = 19.9609s	
29561/30300 (epoch 48.781), train_loss = 0.94159725, grad/param norm = 1.9128e-01, time/batch = 18.7026s	
29562/30300 (epoch 48.782), train_loss = 0.87884129, grad/param norm = 1.7817e-01, time/batch = 19.6953s	
29563/30300 (epoch 48.784), train_loss = 0.91105445, grad/param norm = 1.9875e-01, time/batch = 18.9677s	
29564/30300 (epoch 48.785), train_loss = 0.99347492, grad/param norm = 2.0674e-01, time/batch = 19.2045s	
29565/30300 (epoch 48.787), train_loss = 0.81592325, grad/param norm = 1.7246e-01, time/batch = 19.7889s	
29566/30300 (epoch 48.789), train_loss = 1.12079603, grad/param norm = 6.6804e-01, time/batch = 19.1283s	
29567/30300 (epoch 48.790), train_loss = 0.97057059, grad/param norm = 2.4783e-01, time/batch = 18.6089s	
29568/30300 (epoch 48.792), train_loss = 0.77042563, grad/param norm = 1.8292e-01, time/batch = 18.2750s	
29569/30300 (epoch 48.794), train_loss = 0.97768496, grad/param norm = 1.8662e-01, time/batch = 18.1171s	
29570/30300 (epoch 48.795), train_loss = 0.87914877, grad/param norm = 1.6733e-01, time/batch = 19.4712s	
29571/30300 (epoch 48.797), train_loss = 1.10813811, grad/param norm = 2.7976e-01, time/batch = 18.8555s	
29572/30300 (epoch 48.799), train_loss = 1.01436494, grad/param norm = 2.2165e-01, time/batch = 19.9645s	
29573/30300 (epoch 48.800), train_loss = 1.01557601, grad/param norm = 1.8194e-01, time/batch = 18.8867s	
29574/30300 (epoch 48.802), train_loss = 1.20203238, grad/param norm = 2.2375e-01, time/batch = 18.3783s	
29575/30300 (epoch 48.804), train_loss = 1.01997801, grad/param norm = 2.1302e-01, time/batch = 20.6254s	
29576/30300 (epoch 48.805), train_loss = 1.09010005, grad/param norm = 1.9539e-01, time/batch = 19.5643s	
29577/30300 (epoch 48.807), train_loss = 0.93131046, grad/param norm = 2.1898e-01, time/batch = 17.8774s	
29578/30300 (epoch 48.809), train_loss = 1.05902264, grad/param norm = 1.9674e-01, time/batch = 20.4628s	
29579/30300 (epoch 48.810), train_loss = 1.01946458, grad/param norm = 2.0219e-01, time/batch = 19.4577s	
29580/30300 (epoch 48.812), train_loss = 0.92150664, grad/param norm = 1.8145e-01, time/batch = 17.1804s	
29581/30300 (epoch 48.814), train_loss = 0.96734949, grad/param norm = 1.9843e-01, time/batch = 19.9591s	
29582/30300 (epoch 48.815), train_loss = 0.98243646, grad/param norm = 2.3105e-01, time/batch = 19.3026s	
29583/30300 (epoch 48.817), train_loss = 1.04106342, grad/param norm = 2.1007e-01, time/batch = 18.7009s	
29584/30300 (epoch 48.818), train_loss = 1.00727051, grad/param norm = 1.8573e-01, time/batch = 19.2089s	
29585/30300 (epoch 48.820), train_loss = 1.12180508, grad/param norm = 2.4954e-01, time/batch = 18.1223s	
29586/30300 (epoch 48.822), train_loss = 1.10980617, grad/param norm = 2.0204e-01, time/batch = 18.5206s	
29587/30300 (epoch 48.823), train_loss = 1.07933634, grad/param norm = 2.1015e-01, time/batch = 19.3662s	
29588/30300 (epoch 48.825), train_loss = 1.08959437, grad/param norm = 1.8357e-01, time/batch = 20.2871s	
29589/30300 (epoch 48.827), train_loss = 0.82071098, grad/param norm = 1.9126e-01, time/batch = 19.2785s	
29590/30300 (epoch 48.828), train_loss = 1.07358048, grad/param norm = 1.8183e-01, time/batch = 18.9499s	
29591/30300 (epoch 48.830), train_loss = 1.02302923, grad/param norm = 1.7843e-01, time/batch = 20.2984s	
29592/30300 (epoch 48.832), train_loss = 0.89998437, grad/param norm = 1.9638e-01, time/batch = 18.2664s	
29593/30300 (epoch 48.833), train_loss = 0.98693503, grad/param norm = 1.9190e-01, time/batch = 19.5470s	
29594/30300 (epoch 48.835), train_loss = 0.90696720, grad/param norm = 1.8624e-01, time/batch = 19.7825s	
29595/30300 (epoch 48.837), train_loss = 0.87679024, grad/param norm = 1.8511e-01, time/batch = 18.8693s	
29596/30300 (epoch 48.838), train_loss = 0.89984062, grad/param norm = 2.4136e-01, time/batch = 18.9422s	
29597/30300 (epoch 48.840), train_loss = 1.01386650, grad/param norm = 1.6522e-01, time/batch = 19.4675s	
29598/30300 (epoch 48.842), train_loss = 0.95177380, grad/param norm = 1.6518e-01, time/batch = 19.5538s	
29599/30300 (epoch 48.843), train_loss = 1.00802031, grad/param norm = 1.7364e-01, time/batch = 19.0967s	
29600/30300 (epoch 48.845), train_loss = 0.99945979, grad/param norm = 1.6239e-01, time/batch = 18.2702s	
29601/30300 (epoch 48.847), train_loss = 0.95288776, grad/param norm = 2.0653e-01, time/batch = 17.4517s	
29602/30300 (epoch 48.848), train_loss = 1.01310319, grad/param norm = 2.0060e-01, time/batch = 18.8649s	
29603/30300 (epoch 48.850), train_loss = 0.95059919, grad/param norm = 1.6817e-01, time/batch = 19.7162s	
29604/30300 (epoch 48.851), train_loss = 1.00726579, grad/param norm = 2.2945e-01, time/batch = 19.4768s	
29605/30300 (epoch 48.853), train_loss = 0.95679595, grad/param norm = 2.1677e-01, time/batch = 18.9606s	
29606/30300 (epoch 48.855), train_loss = 0.91034261, grad/param norm = 1.6534e-01, time/batch = 19.6277s	
29607/30300 (epoch 48.856), train_loss = 0.98514312, grad/param norm = 1.8871e-01, time/batch = 19.4712s	
29608/30300 (epoch 48.858), train_loss = 0.90191684, grad/param norm = 1.5967e-01, time/batch = 17.6289s	
29609/30300 (epoch 48.860), train_loss = 0.87151313, grad/param norm = 1.6119e-01, time/batch = 19.0571s	
29610/30300 (epoch 48.861), train_loss = 1.09891035, grad/param norm = 1.9003e-01, time/batch = 19.8632s	
29611/30300 (epoch 48.863), train_loss = 0.91413458, grad/param norm = 1.6659e-01, time/batch = 18.3425s	
29612/30300 (epoch 48.865), train_loss = 1.00793862, grad/param norm = 1.9089e-01, time/batch = 18.6998s	
29613/30300 (epoch 48.866), train_loss = 1.01852910, grad/param norm = 1.7321e-01, time/batch = 19.8729s	
29614/30300 (epoch 48.868), train_loss = 0.99087289, grad/param norm = 1.8519e-01, time/batch = 18.6211s	
29615/30300 (epoch 48.870), train_loss = 0.90356300, grad/param norm = 1.7655e-01, time/batch = 19.8686s	
29616/30300 (epoch 48.871), train_loss = 0.99376095, grad/param norm = 1.7951e-01, time/batch = 19.1263s	
29617/30300 (epoch 48.873), train_loss = 0.97894232, grad/param norm = 1.6296e-01, time/batch = 19.2686s	
29618/30300 (epoch 48.875), train_loss = 0.90970190, grad/param norm = 1.6093e-01, time/batch = 18.5184s	
29619/30300 (epoch 48.876), train_loss = 0.85359018, grad/param norm = 1.7394e-01, time/batch = 19.7152s	
29620/30300 (epoch 48.878), train_loss = 0.79653556, grad/param norm = 1.7267e-01, time/batch = 19.8720s	
29621/30300 (epoch 48.880), train_loss = 0.88110283, grad/param norm = 1.7093e-01, time/batch = 18.7994s	
29622/30300 (epoch 48.881), train_loss = 1.10037056, grad/param norm = 2.5686e-01, time/batch = 19.7892s	
29623/30300 (epoch 48.883), train_loss = 1.03671498, grad/param norm = 1.9179e-01, time/batch = 19.8074s	
29624/30300 (epoch 48.884), train_loss = 0.95359901, grad/param norm = 1.6017e-01, time/batch = 18.8691s	
29625/30300 (epoch 48.886), train_loss = 1.00683058, grad/param norm = 1.8006e-01, time/batch = 18.4429s	
29626/30300 (epoch 48.888), train_loss = 0.91799655, grad/param norm = 1.8454e-01, time/batch = 19.6960s	
29627/30300 (epoch 48.889), train_loss = 1.01493714, grad/param norm = 1.8642e-01, time/batch = 19.1261s	
29628/30300 (epoch 48.891), train_loss = 0.94797992, grad/param norm = 1.9196e-01, time/batch = 19.2029s	
29629/30300 (epoch 48.893), train_loss = 1.18133829, grad/param norm = 1.9689e-01, time/batch = 19.4712s	
29630/30300 (epoch 48.894), train_loss = 0.96784213, grad/param norm = 1.9679e-01, time/batch = 31.7052s	
29631/30300 (epoch 48.896), train_loss = 0.82812963, grad/param norm = 1.9412e-01, time/batch = 18.7679s	
29632/30300 (epoch 48.898), train_loss = 0.81028493, grad/param norm = 1.8068e-01, time/batch = 18.2180s	
29633/30300 (epoch 48.899), train_loss = 0.85842533, grad/param norm = 1.7415e-01, time/batch = 18.8070s	
29634/30300 (epoch 48.901), train_loss = 0.95942041, grad/param norm = 1.9474e-01, time/batch = 19.5485s	
29635/30300 (epoch 48.903), train_loss = 0.94970002, grad/param norm = 2.4784e-01, time/batch = 18.6373s	
29636/30300 (epoch 48.904), train_loss = 0.97998874, grad/param norm = 1.6552e-01, time/batch = 19.1191s	
29637/30300 (epoch 48.906), train_loss = 0.96322967, grad/param norm = 1.9562e-01, time/batch = 19.6282s	
29638/30300 (epoch 48.908), train_loss = 0.91156469, grad/param norm = 1.7087e-01, time/batch = 19.0559s	
29639/30300 (epoch 48.909), train_loss = 0.92831409, grad/param norm = 2.1311e-01, time/batch = 18.6962s	
29640/30300 (epoch 48.911), train_loss = 0.93374554, grad/param norm = 1.7121e-01, time/batch = 20.3617s	
29641/30300 (epoch 48.913), train_loss = 0.95377898, grad/param norm = 1.6731e-01, time/batch = 18.6161s	
29642/30300 (epoch 48.914), train_loss = 0.93533212, grad/param norm = 1.9500e-01, time/batch = 17.4403s	
29643/30300 (epoch 48.916), train_loss = 0.99023894, grad/param norm = 1.5903e-01, time/batch = 19.4546s	
29644/30300 (epoch 48.917), train_loss = 0.91804019, grad/param norm = 1.6530e-01, time/batch = 19.3851s	
29645/30300 (epoch 48.919), train_loss = 0.84305592, grad/param norm = 1.7849e-01, time/batch = 17.9576s	
29646/30300 (epoch 48.921), train_loss = 0.93535382, grad/param norm = 1.6727e-01, time/batch = 19.6274s	
29647/30300 (epoch 48.922), train_loss = 1.03950688, grad/param norm = 1.9361e-01, time/batch = 20.2103s	
29648/30300 (epoch 48.924), train_loss = 0.94605037, grad/param norm = 1.8309e-01, time/batch = 18.6348s	
29649/30300 (epoch 48.926), train_loss = 1.00037423, grad/param norm = 1.8646e-01, time/batch = 19.3840s	
29650/30300 (epoch 48.927), train_loss = 0.96769086, grad/param norm = 1.8331e-01, time/batch = 20.0449s	
29651/30300 (epoch 48.929), train_loss = 0.88046640, grad/param norm = 1.7969e-01, time/batch = 19.1216s	
29652/30300 (epoch 48.931), train_loss = 1.01511518, grad/param norm = 2.0247e-01, time/batch = 20.0448s	
29653/30300 (epoch 48.932), train_loss = 0.89645427, grad/param norm = 1.7602e-01, time/batch = 19.7254s	
29654/30300 (epoch 48.934), train_loss = 0.98799681, grad/param norm = 1.8345e-01, time/batch = 18.0927s	
29655/30300 (epoch 48.936), train_loss = 0.92602366, grad/param norm = 1.8164e-01, time/batch = 17.7816s	
29656/30300 (epoch 48.937), train_loss = 0.91690853, grad/param norm = 1.8564e-01, time/batch = 20.3957s	
29657/30300 (epoch 48.939), train_loss = 1.04491471, grad/param norm = 2.0073e-01, time/batch = 17.9527s	
29658/30300 (epoch 48.941), train_loss = 0.94460167, grad/param norm = 1.8688e-01, time/batch = 18.5384s	
29659/30300 (epoch 48.942), train_loss = 0.93043702, grad/param norm = 1.9659e-01, time/batch = 19.3738s	
29660/30300 (epoch 48.944), train_loss = 0.85234654, grad/param norm = 1.9545e-01, time/batch = 18.7901s	
29661/30300 (epoch 48.946), train_loss = 1.03904995, grad/param norm = 2.6332e-01, time/batch = 19.3769s	
29662/30300 (epoch 48.947), train_loss = 0.96617162, grad/param norm = 2.2041e-01, time/batch = 18.9523s	
29663/30300 (epoch 48.949), train_loss = 1.03836127, grad/param norm = 2.1057e-01, time/batch = 19.2814s	
29664/30300 (epoch 48.950), train_loss = 1.06837573, grad/param norm = 1.9938e-01, time/batch = 19.3644s	
29665/30300 (epoch 48.952), train_loss = 0.98819827, grad/param norm = 2.0992e-01, time/batch = 18.3596s	
29666/30300 (epoch 48.954), train_loss = 1.19295206, grad/param norm = 1.8045e-01, time/batch = 19.3746s	
29667/30300 (epoch 48.955), train_loss = 0.94118462, grad/param norm = 1.7222e-01, time/batch = 18.4598s	
29668/30300 (epoch 48.957), train_loss = 1.01715803, grad/param norm = 1.9545e-01, time/batch = 18.2718s	
29669/30300 (epoch 48.959), train_loss = 0.87660954, grad/param norm = 1.8357e-01, time/batch = 19.7135s	
29670/30300 (epoch 48.960), train_loss = 0.93426341, grad/param norm = 1.8638e-01, time/batch = 18.2890s	
29671/30300 (epoch 48.962), train_loss = 0.89904870, grad/param norm = 2.2608e-01, time/batch = 19.9594s	
29672/30300 (epoch 48.964), train_loss = 0.88803266, grad/param norm = 2.1562e-01, time/batch = 19.3735s	
29673/30300 (epoch 48.965), train_loss = 0.90142038, grad/param norm = 2.2184e-01, time/batch = 19.3544s	
29674/30300 (epoch 48.967), train_loss = 0.93426579, grad/param norm = 2.3224e-01, time/batch = 19.0397s	
29675/30300 (epoch 48.969), train_loss = 0.91540496, grad/param norm = 2.0402e-01, time/batch = 19.9447s	
29676/30300 (epoch 48.970), train_loss = 0.92777994, grad/param norm = 2.0837e-01, time/batch = 19.0288s	
29677/30300 (epoch 48.972), train_loss = 0.84228347, grad/param norm = 1.7149e-01, time/batch = 17.4261s	
29678/30300 (epoch 48.974), train_loss = 1.07201345, grad/param norm = 1.9825e-01, time/batch = 19.1939s	
29679/30300 (epoch 48.975), train_loss = 1.08818963, grad/param norm = 2.3203e-01, time/batch = 18.0359s	
29680/30300 (epoch 48.977), train_loss = 1.15576158, grad/param norm = 1.8256e-01, time/batch = 19.4620s	
29681/30300 (epoch 48.979), train_loss = 1.01400707, grad/param norm = 1.8936e-01, time/batch = 18.5557s	
29682/30300 (epoch 48.980), train_loss = 1.05483842, grad/param norm = 2.1959e-01, time/batch = 19.3740s	
29683/30300 (epoch 48.982), train_loss = 1.01779219, grad/param norm = 2.0136e-01, time/batch = 19.1286s	
29684/30300 (epoch 48.983), train_loss = 1.06499550, grad/param norm = 1.6789e-01, time/batch = 19.4596s	
29685/30300 (epoch 48.985), train_loss = 1.01251011, grad/param norm = 2.3685e-01, time/batch = 18.9663s	
29686/30300 (epoch 48.987), train_loss = 0.97968615, grad/param norm = 1.7652e-01, time/batch = 17.1293s	
29687/30300 (epoch 48.988), train_loss = 1.10123998, grad/param norm = 2.1313e-01, time/batch = 19.7982s	
29688/30300 (epoch 48.990), train_loss = 0.91174877, grad/param norm = 1.8408e-01, time/batch = 19.4690s	
29689/30300 (epoch 48.992), train_loss = 1.05830553, grad/param norm = 1.6613e-01, time/batch = 18.6082s	
29690/30300 (epoch 48.993), train_loss = 1.03943844, grad/param norm = 2.4504e-01, time/batch = 18.0097s	
29691/30300 (epoch 48.995), train_loss = 0.95217723, grad/param norm = 2.3163e-01, time/batch = 19.9648s	
29692/30300 (epoch 48.997), train_loss = 1.03839043, grad/param norm = 1.9025e-01, time/batch = 18.0362s	
29693/30300 (epoch 48.998), train_loss = 1.05915727, grad/param norm = 2.1051e-01, time/batch = 19.7966s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
29694/30300 (epoch 49.000), train_loss = 0.90833388, grad/param norm = 2.1977e-01, time/batch = 19.5561s	
29695/30300 (epoch 49.002), train_loss = 1.08096941, grad/param norm = 2.4388e-01, time/batch = 19.0431s	
29696/30300 (epoch 49.003), train_loss = 0.98167211, grad/param norm = 1.7437e-01, time/batch = 19.0037s	
29697/30300 (epoch 49.005), train_loss = 0.94500230, grad/param norm = 1.9618e-01, time/batch = 18.8048s	
29698/30300 (epoch 49.007), train_loss = 1.04127767, grad/param norm = 2.1326e-01, time/batch = 18.7979s	
29699/30300 (epoch 49.008), train_loss = 0.97074397, grad/param norm = 1.7666e-01, time/batch = 20.3741s	
29700/30300 (epoch 49.010), train_loss = 0.85712108, grad/param norm = 1.7897e-01, time/batch = 18.9697s	
29701/30300 (epoch 49.012), train_loss = 0.93503605, grad/param norm = 1.7511e-01, time/batch = 19.3046s	
29702/30300 (epoch 49.013), train_loss = 1.06378526, grad/param norm = 2.0981e-01, time/batch = 19.6978s	
29703/30300 (epoch 49.015), train_loss = 0.91615336, grad/param norm = 1.7213e-01, time/batch = 19.7133s	
29704/30300 (epoch 49.017), train_loss = 0.95210203, grad/param norm = 1.5071e-01, time/batch = 18.7188s	
29705/30300 (epoch 49.018), train_loss = 0.84148981, grad/param norm = 1.5505e-01, time/batch = 19.7183s	
29706/30300 (epoch 49.020), train_loss = 1.07130192, grad/param norm = 2.2170e-01, time/batch = 18.4511s	
29707/30300 (epoch 49.021), train_loss = 1.09075797, grad/param norm = 1.9838e-01, time/batch = 18.7086s	
29708/30300 (epoch 49.023), train_loss = 0.99933204, grad/param norm = 1.5958e-01, time/batch = 19.0430s	
29709/30300 (epoch 49.025), train_loss = 0.89791681, grad/param norm = 1.9187e-01, time/batch = 18.1247s	
29710/30300 (epoch 49.026), train_loss = 1.05848597, grad/param norm = 2.0326e-01, time/batch = 19.7972s	
29711/30300 (epoch 49.028), train_loss = 1.02454978, grad/param norm = 1.8582e-01, time/batch = 17.6916s	
29712/30300 (epoch 49.030), train_loss = 0.93219212, grad/param norm = 1.9978e-01, time/batch = 19.8797s	
29713/30300 (epoch 49.031), train_loss = 0.99473845, grad/param norm = 1.7591e-01, time/batch = 20.0460s	
29714/30300 (epoch 49.033), train_loss = 0.98363085, grad/param norm = 1.9338e-01, time/batch = 18.3800s	
29715/30300 (epoch 49.035), train_loss = 0.98754117, grad/param norm = 1.9817e-01, time/batch = 19.1164s	
29716/30300 (epoch 49.036), train_loss = 1.00842023, grad/param norm = 1.8987e-01, time/batch = 20.4627s	
29717/30300 (epoch 49.038), train_loss = 1.02242514, grad/param norm = 1.6396e-01, time/batch = 19.0398s	
29718/30300 (epoch 49.040), train_loss = 0.86181266, grad/param norm = 1.7165e-01, time/batch = 19.7880s	
29719/30300 (epoch 49.041), train_loss = 0.80873145, grad/param norm = 1.9181e-01, time/batch = 19.2167s	
29720/30300 (epoch 49.043), train_loss = 1.00733226, grad/param norm = 1.9400e-01, time/batch = 18.2084s	
29721/30300 (epoch 49.045), train_loss = 0.92319560, grad/param norm = 1.7140e-01, time/batch = 20.2859s	
29722/30300 (epoch 49.046), train_loss = 1.07998723, grad/param norm = 2.0043e-01, time/batch = 19.4667s	
29723/30300 (epoch 49.048), train_loss = 1.00074953, grad/param norm = 2.0450e-01, time/batch = 18.7875s	
29724/30300 (epoch 49.050), train_loss = 0.89071581, grad/param norm = 1.9916e-01, time/batch = 17.2784s	
29725/30300 (epoch 49.051), train_loss = 1.00319478, grad/param norm = 2.2249e-01, time/batch = 20.2854s	
29726/30300 (epoch 49.053), train_loss = 0.82907965, grad/param norm = 2.0803e-01, time/batch = 17.3677s	
29727/30300 (epoch 49.054), train_loss = 1.00978444, grad/param norm = 1.9105e-01, time/batch = 19.4591s	
29728/30300 (epoch 49.056), train_loss = 0.89793727, grad/param norm = 1.9927e-01, time/batch = 19.2121s	
29729/30300 (epoch 49.058), train_loss = 0.94041890, grad/param norm = 2.4366e-01, time/batch = 19.3004s	
29730/30300 (epoch 49.059), train_loss = 0.92552778, grad/param norm = 1.9099e-01, time/batch = 19.2218s	
29731/30300 (epoch 49.061), train_loss = 1.02237556, grad/param norm = 1.9171e-01, time/batch = 18.1157s	
29732/30300 (epoch 49.063), train_loss = 0.88197498, grad/param norm = 2.0200e-01, time/batch = 19.2947s	
29733/30300 (epoch 49.064), train_loss = 0.93661984, grad/param norm = 1.8411e-01, time/batch = 17.2694s	
29734/30300 (epoch 49.066), train_loss = 0.99278038, grad/param norm = 1.8713e-01, time/batch = 19.6262s	
29735/30300 (epoch 49.068), train_loss = 0.94710612, grad/param norm = 1.7900e-01, time/batch = 19.4653s	
29736/30300 (epoch 49.069), train_loss = 1.03593488, grad/param norm = 2.1784e-01, time/batch = 18.5296s	
29737/30300 (epoch 49.071), train_loss = 0.99367510, grad/param norm = 1.8487e-01, time/batch = 18.8797s	
29738/30300 (epoch 49.073), train_loss = 0.89463689, grad/param norm = 2.0028e-01, time/batch = 20.0432s	
29739/30300 (epoch 49.074), train_loss = 0.93298552, grad/param norm = 1.6908e-01, time/batch = 17.8785s	
29740/30300 (epoch 49.076), train_loss = 0.95550689, grad/param norm = 1.7626e-01, time/batch = 20.2983s	
29741/30300 (epoch 49.078), train_loss = 0.88086500, grad/param norm = 1.6758e-01, time/batch = 19.4576s	
29742/30300 (epoch 49.079), train_loss = 0.92583610, grad/param norm = 1.7128e-01, time/batch = 18.1868s	
29743/30300 (epoch 49.081), train_loss = 0.97858832, grad/param norm = 2.0023e-01, time/batch = 20.4675s	
29744/30300 (epoch 49.083), train_loss = 1.03901883, grad/param norm = 3.0302e-01, time/batch = 19.9350s	
29745/30300 (epoch 49.084), train_loss = 0.91502487, grad/param norm = 1.8823e-01, time/batch = 19.0251s	
29746/30300 (epoch 49.086), train_loss = 0.90557956, grad/param norm = 1.9120e-01, time/batch = 17.4536s	
29747/30300 (epoch 49.087), train_loss = 0.91612466, grad/param norm = 1.6305e-01, time/batch = 19.8834s	
29748/30300 (epoch 49.089), train_loss = 0.87533306, grad/param norm = 1.7549e-01, time/batch = 17.9719s	
29749/30300 (epoch 49.091), train_loss = 0.99631628, grad/param norm = 1.7311e-01, time/batch = 18.2105s	
29750/30300 (epoch 49.092), train_loss = 1.01851493, grad/param norm = 1.7091e-01, time/batch = 19.7997s	
29751/30300 (epoch 49.094), train_loss = 1.03765871, grad/param norm = 2.0144e-01, time/batch = 18.0443s	
29752/30300 (epoch 49.096), train_loss = 1.09969473, grad/param norm = 2.0273e-01, time/batch = 19.3733s	
29753/30300 (epoch 49.097), train_loss = 0.91862623, grad/param norm = 1.9417e-01, time/batch = 19.2788s	
29754/30300 (epoch 49.099), train_loss = 1.01274108, grad/param norm = 1.7253e-01, time/batch = 18.5409s	
29755/30300 (epoch 49.101), train_loss = 1.04982243, grad/param norm = 2.2281e-01, time/batch = 18.3552s	
29756/30300 (epoch 49.102), train_loss = 0.88794837, grad/param norm = 1.8814e-01, time/batch = 19.3766s	
29757/30300 (epoch 49.104), train_loss = 0.93446961, grad/param norm = 2.6043e-01, time/batch = 20.0398s	
29758/30300 (epoch 49.106), train_loss = 0.86560572, grad/param norm = 1.8835e-01, time/batch = 18.7856s	
29759/30300 (epoch 49.107), train_loss = 1.01656075, grad/param norm = 1.6660e-01, time/batch = 19.5468s	
29760/30300 (epoch 49.109), train_loss = 1.04486784, grad/param norm = 2.3230e-01, time/batch = 19.5476s	
29761/30300 (epoch 49.111), train_loss = 1.00348715, grad/param norm = 2.1252e-01, time/batch = 19.2852s	
29762/30300 (epoch 49.112), train_loss = 1.09984715, grad/param norm = 2.0870e-01, time/batch = 19.8670s	
29763/30300 (epoch 49.114), train_loss = 0.92209383, grad/param norm = 1.8232e-01, time/batch = 19.7142s	
29764/30300 (epoch 49.116), train_loss = 1.00919372, grad/param norm = 2.2482e-01, time/batch = 17.4902s	
29765/30300 (epoch 49.117), train_loss = 1.06797876, grad/param norm = 1.7230e-01, time/batch = 19.7837s	
29766/30300 (epoch 49.119), train_loss = 0.86441692, grad/param norm = 2.0235e-01, time/batch = 19.7968s	
29767/30300 (epoch 49.120), train_loss = 0.93959675, grad/param norm = 2.0789e-01, time/batch = 18.5441s	
29768/30300 (epoch 49.122), train_loss = 1.05791028, grad/param norm = 2.2909e-01, time/batch = 19.6978s	
29769/30300 (epoch 49.124), train_loss = 1.13526586, grad/param norm = 2.1369e-01, time/batch = 18.8677s	
29770/30300 (epoch 49.125), train_loss = 0.89020873, grad/param norm = 1.8713e-01, time/batch = 18.5367s	
29771/30300 (epoch 49.127), train_loss = 0.96941603, grad/param norm = 1.9658e-01, time/batch = 19.9563s	
29772/30300 (epoch 49.129), train_loss = 1.00150676, grad/param norm = 1.8902e-01, time/batch = 19.4562s	
29773/30300 (epoch 49.130), train_loss = 1.09716151, grad/param norm = 1.9970e-01, time/batch = 17.6881s	
29774/30300 (epoch 49.132), train_loss = 1.08293566, grad/param norm = 2.1392e-01, time/batch = 20.0359s	
29775/30300 (epoch 49.134), train_loss = 0.90968758, grad/param norm = 2.0559e-01, time/batch = 18.6114s	
29776/30300 (epoch 49.135), train_loss = 0.92670776, grad/param norm = 2.0618e-01, time/batch = 18.6819s	
29777/30300 (epoch 49.137), train_loss = 0.97903680, grad/param norm = 2.1117e-01, time/batch = 18.6224s	
29778/30300 (epoch 49.139), train_loss = 0.89727207, grad/param norm = 3.4422e-01, time/batch = 19.7104s	
29779/30300 (epoch 49.140), train_loss = 0.99052852, grad/param norm = 2.8047e-01, time/batch = 19.3802s	
29780/30300 (epoch 49.142), train_loss = 1.03477557, grad/param norm = 2.4329e-01, time/batch = 19.2147s	
29781/30300 (epoch 49.144), train_loss = 0.88217170, grad/param norm = 2.2870e-01, time/batch = 18.1924s	
29782/30300 (epoch 49.145), train_loss = 1.04184596, grad/param norm = 2.9994e-01, time/batch = 17.9410s	
29783/30300 (epoch 49.147), train_loss = 0.92872228, grad/param norm = 1.8050e-01, time/batch = 19.2778s	
29784/30300 (epoch 49.149), train_loss = 1.03248506, grad/param norm = 2.2572e-01, time/batch = 19.8813s	
29785/30300 (epoch 49.150), train_loss = 0.91893514, grad/param norm = 2.2044e-01, time/batch = 18.8645s	
29786/30300 (epoch 49.152), train_loss = 0.88615717, grad/param norm = 2.3181e-01, time/batch = 18.3618s	
29787/30300 (epoch 49.153), train_loss = 0.98531934, grad/param norm = 2.1923e-01, time/batch = 19.7969s	
29788/30300 (epoch 49.155), train_loss = 0.85268920, grad/param norm = 1.9881e-01, time/batch = 19.9573s	
29789/30300 (epoch 49.157), train_loss = 0.90431669, grad/param norm = 1.9886e-01, time/batch = 18.7911s	
29790/30300 (epoch 49.158), train_loss = 1.00234342, grad/param norm = 2.9738e-01, time/batch = 20.0497s	
29791/30300 (epoch 49.160), train_loss = 0.90237424, grad/param norm = 2.1435e-01, time/batch = 19.8014s	
29792/30300 (epoch 49.162), train_loss = 0.94972463, grad/param norm = 1.6532e-01, time/batch = 18.6143s	
29793/30300 (epoch 49.163), train_loss = 0.98662891, grad/param norm = 2.2602e-01, time/batch = 20.3031s	
29794/30300 (epoch 49.165), train_loss = 1.08272593, grad/param norm = 2.0745e-01, time/batch = 18.7213s	
29795/30300 (epoch 49.167), train_loss = 0.96818803, grad/param norm = 2.0815e-01, time/batch = 19.0402s	
29796/30300 (epoch 49.168), train_loss = 1.00776592, grad/param norm = 1.9023e-01, time/batch = 18.3856s	
29797/30300 (epoch 49.170), train_loss = 1.00835655, grad/param norm = 2.1904e-01, time/batch = 19.1791s	
29798/30300 (epoch 49.172), train_loss = 0.98216776, grad/param norm = 2.1977e-01, time/batch = 18.2175s	
29799/30300 (epoch 49.173), train_loss = 0.94250925, grad/param norm = 2.5026e-01, time/batch = 19.3840s	
29800/30300 (epoch 49.175), train_loss = 1.00709833, grad/param norm = 1.9388e-01, time/batch = 19.0315s	
29801/30300 (epoch 49.177), train_loss = 1.02440522, grad/param norm = 2.4978e-01, time/batch = 17.8535s	
29802/30300 (epoch 49.178), train_loss = 0.82267737, grad/param norm = 1.8657e-01, time/batch = 18.0096s	
29803/30300 (epoch 49.180), train_loss = 0.94409378, grad/param norm = 1.7554e-01, time/batch = 18.9523s	
29804/30300 (epoch 49.182), train_loss = 0.97844045, grad/param norm = 1.8967e-01, time/batch = 19.5534s	
29805/30300 (epoch 49.183), train_loss = 0.91414492, grad/param norm = 2.0286e-01, time/batch = 18.2140s	
29806/30300 (epoch 49.185), train_loss = 1.06542241, grad/param norm = 2.0114e-01, time/batch = 19.9508s	
29807/30300 (epoch 49.186), train_loss = 1.17418561, grad/param norm = 2.2313e-01, time/batch = 19.5507s	
29808/30300 (epoch 49.188), train_loss = 1.02402607, grad/param norm = 2.0311e-01, time/batch = 19.7830s	
29809/30300 (epoch 49.190), train_loss = 0.96976518, grad/param norm = 2.4983e-01, time/batch = 20.1232s	
29810/30300 (epoch 49.191), train_loss = 1.00632870, grad/param norm = 1.9146e-01, time/batch = 19.6259s	
29811/30300 (epoch 49.193), train_loss = 0.89451318, grad/param norm = 1.9890e-01, time/batch = 19.0294s	
29812/30300 (epoch 49.195), train_loss = 0.91974255, grad/param norm = 1.7810e-01, time/batch = 19.2123s	
29813/30300 (epoch 49.196), train_loss = 1.01324631, grad/param norm = 1.6621e-01, time/batch = 18.4677s	
29814/30300 (epoch 49.198), train_loss = 0.83405044, grad/param norm = 1.8946e-01, time/batch = 19.1955s	
29815/30300 (epoch 49.200), train_loss = 0.93813330, grad/param norm = 1.7469e-01, time/batch = 19.6194s	
29816/30300 (epoch 49.201), train_loss = 1.07516839, grad/param norm = 2.8941e-01, time/batch = 19.2266s	
29817/30300 (epoch 49.203), train_loss = 0.96394802, grad/param norm = 1.8334e-01, time/batch = 32.9591s	
29818/30300 (epoch 49.205), train_loss = 1.12587372, grad/param norm = 2.0220e-01, time/batch = 19.6061s	
29819/30300 (epoch 49.206), train_loss = 1.06441124, grad/param norm = 2.1732e-01, time/batch = 18.2841s	
29820/30300 (epoch 49.208), train_loss = 1.02402077, grad/param norm = 2.5312e-01, time/batch = 19.0550s	
29821/30300 (epoch 49.210), train_loss = 1.03740821, grad/param norm = 1.6789e-01, time/batch = 19.1197s	
29822/30300 (epoch 49.211), train_loss = 1.09364940, grad/param norm = 1.9278e-01, time/batch = 16.7833s	
29823/30300 (epoch 49.213), train_loss = 0.99411158, grad/param norm = 1.6829e-01, time/batch = 18.1839s	
29824/30300 (epoch 49.215), train_loss = 0.89962305, grad/param norm = 1.7630e-01, time/batch = 19.4611s	
29825/30300 (epoch 49.216), train_loss = 0.93966953, grad/param norm = 2.2785e-01, time/batch = 19.9602s	
29826/30300 (epoch 49.218), train_loss = 0.89485965, grad/param norm = 1.7827e-01, time/batch = 19.0272s	
29827/30300 (epoch 49.219), train_loss = 0.84987353, grad/param norm = 1.8808e-01, time/batch = 19.4623s	
29828/30300 (epoch 49.221), train_loss = 0.82253953, grad/param norm = 1.7207e-01, time/batch = 19.2978s	
29829/30300 (epoch 49.223), train_loss = 0.97279172, grad/param norm = 1.7988e-01, time/batch = 18.1092s	
29830/30300 (epoch 49.224), train_loss = 0.81419497, grad/param norm = 2.0279e-01, time/batch = 19.2290s	
29831/30300 (epoch 49.226), train_loss = 1.03416841, grad/param norm = 2.7276e-01, time/batch = 18.7103s	
29832/30300 (epoch 49.228), train_loss = 1.09886198, grad/param norm = 2.4494e-01, time/batch = 17.9539s	
29833/30300 (epoch 49.229), train_loss = 0.95796606, grad/param norm = 1.8604e-01, time/batch = 19.7963s	
29834/30300 (epoch 49.231), train_loss = 1.04494862, grad/param norm = 2.0795e-01, time/batch = 20.0560s	
29835/30300 (epoch 49.233), train_loss = 1.02440232, grad/param norm = 1.6240e-01, time/batch = 17.8677s	
29836/30300 (epoch 49.234), train_loss = 1.04025858, grad/param norm = 2.9397e-01, time/batch = 18.8898s	
29837/30300 (epoch 49.236), train_loss = 1.01269104, grad/param norm = 1.6634e-01, time/batch = 19.4661s	
29838/30300 (epoch 49.238), train_loss = 0.97311375, grad/param norm = 2.2225e-01, time/batch = 18.2304s	
29839/30300 (epoch 49.239), train_loss = 0.92256929, grad/param norm = 2.1677e-01, time/batch = 18.9576s	
29840/30300 (epoch 49.241), train_loss = 1.03276286, grad/param norm = 2.0797e-01, time/batch = 18.2716s	
29841/30300 (epoch 49.243), train_loss = 1.02950587, grad/param norm = 1.9409e-01, time/batch = 18.8803s	
29842/30300 (epoch 49.244), train_loss = 1.15771050, grad/param norm = 1.9829e-01, time/batch = 18.3048s	
29843/30300 (epoch 49.246), train_loss = 1.01942766, grad/param norm = 1.9515e-01, time/batch = 18.8915s	
29844/30300 (epoch 49.248), train_loss = 0.95695680, grad/param norm = 1.6968e-01, time/batch = 18.9687s	
29845/30300 (epoch 49.249), train_loss = 0.87128827, grad/param norm = 1.8475e-01, time/batch = 18.8637s	
29846/30300 (epoch 49.251), train_loss = 0.90434646, grad/param norm = 1.9156e-01, time/batch = 19.3049s	
29847/30300 (epoch 49.252), train_loss = 1.06042410, grad/param norm = 2.0727e-01, time/batch = 18.3042s	
29848/30300 (epoch 49.254), train_loss = 1.05189282, grad/param norm = 2.2141e-01, time/batch = 17.1818s	
29849/30300 (epoch 49.256), train_loss = 1.01827180, grad/param norm = 1.9892e-01, time/batch = 19.4397s	
29850/30300 (epoch 49.257), train_loss = 1.02954879, grad/param norm = 2.0801e-01, time/batch = 20.0547s	
29851/30300 (epoch 49.259), train_loss = 0.95861244, grad/param norm = 1.9172e-01, time/batch = 17.9493s	
29852/30300 (epoch 49.261), train_loss = 1.10312541, grad/param norm = 1.9052e-01, time/batch = 19.6369s	
29853/30300 (epoch 49.262), train_loss = 0.91978586, grad/param norm = 1.9466e-01, time/batch = 19.2099s	
29854/30300 (epoch 49.264), train_loss = 1.00052578, grad/param norm = 2.2252e-01, time/batch = 17.9510s	
29855/30300 (epoch 49.266), train_loss = 0.98899158, grad/param norm = 1.7961e-01, time/batch = 18.6989s	
29856/30300 (epoch 49.267), train_loss = 1.10987589, grad/param norm = 2.1986e-01, time/batch = 19.8031s	
29857/30300 (epoch 49.269), train_loss = 1.00854858, grad/param norm = 1.9427e-01, time/batch = 19.0361s	
29858/30300 (epoch 49.271), train_loss = 0.99477988, grad/param norm = 1.9238e-01, time/batch = 18.7992s	
29859/30300 (epoch 49.272), train_loss = 0.99181525, grad/param norm = 2.2407e-01, time/batch = 19.0239s	
29860/30300 (epoch 49.274), train_loss = 1.04358246, grad/param norm = 1.9841e-01, time/batch = 18.7856s	
29861/30300 (epoch 49.276), train_loss = 1.00635289, grad/param norm = 2.1752e-01, time/batch = 18.2974s	
29862/30300 (epoch 49.277), train_loss = 0.87527379, grad/param norm = 1.8642e-01, time/batch = 19.7089s	
29863/30300 (epoch 49.279), train_loss = 0.98614939, grad/param norm = 2.1600e-01, time/batch = 18.1982s	
29864/30300 (epoch 49.281), train_loss = 1.07176816, grad/param norm = 2.7153e-01, time/batch = 18.3582s	
29865/30300 (epoch 49.282), train_loss = 1.00795835, grad/param norm = 2.0244e-01, time/batch = 19.5528s	
29866/30300 (epoch 49.284), train_loss = 1.04710102, grad/param norm = 2.3819e-01, time/batch = 18.7214s	
29867/30300 (epoch 49.285), train_loss = 1.03310482, grad/param norm = 1.6699e-01, time/batch = 18.4507s	
29868/30300 (epoch 49.287), train_loss = 0.99306940, grad/param norm = 2.1288e-01, time/batch = 18.9654s	
29869/30300 (epoch 49.289), train_loss = 1.08221058, grad/param norm = 2.1566e-01, time/batch = 19.2064s	
29870/30300 (epoch 49.290), train_loss = 0.78786674, grad/param norm = 1.8039e-01, time/batch = 18.4563s	
29871/30300 (epoch 49.292), train_loss = 0.88183030, grad/param norm = 1.7830e-01, time/batch = 17.6065s	
29872/30300 (epoch 49.294), train_loss = 1.01810764, grad/param norm = 2.2797e-01, time/batch = 18.2717s	
29873/30300 (epoch 49.295), train_loss = 0.94717101, grad/param norm = 1.9606e-01, time/batch = 19.0400s	
29874/30300 (epoch 49.297), train_loss = 0.95762924, grad/param norm = 1.8673e-01, time/batch = 18.7128s	
29875/30300 (epoch 49.299), train_loss = 0.98100664, grad/param norm = 1.8670e-01, time/batch = 18.0600s	
29876/30300 (epoch 49.300), train_loss = 0.90596004, grad/param norm = 1.8538e-01, time/batch = 15.2442s	
29877/30300 (epoch 49.302), train_loss = 1.04500460, grad/param norm = 2.1777e-01, time/batch = 18.2926s	
29878/30300 (epoch 49.304), train_loss = 0.91785564, grad/param norm = 1.7722e-01, time/batch = 18.7321s	
29879/30300 (epoch 49.305), train_loss = 0.99777903, grad/param norm = 1.7402e-01, time/batch = 19.8079s	
29880/30300 (epoch 49.307), train_loss = 1.06696803, grad/param norm = 1.7934e-01, time/batch = 18.5070s	
29881/30300 (epoch 49.309), train_loss = 1.01553975, grad/param norm = 2.1609e-01, time/batch = 20.0489s	
29882/30300 (epoch 49.310), train_loss = 0.93926639, grad/param norm = 1.7798e-01, time/batch = 18.8584s	
29883/30300 (epoch 49.312), train_loss = 1.09818160, grad/param norm = 1.8593e-01, time/batch = 18.4597s	
29884/30300 (epoch 49.314), train_loss = 0.95029582, grad/param norm = 1.8392e-01, time/batch = 19.7993s	
29885/30300 (epoch 49.315), train_loss = 0.92300070, grad/param norm = 1.8407e-01, time/batch = 18.6123s	
29886/30300 (epoch 49.317), train_loss = 0.99457983, grad/param norm = 1.7286e-01, time/batch = 19.0495s	
29887/30300 (epoch 49.318), train_loss = 1.01193742, grad/param norm = 2.8949e-01, time/batch = 18.8837s	
29888/30300 (epoch 49.320), train_loss = 1.03267315, grad/param norm = 2.0114e-01, time/batch = 19.4612s	
29889/30300 (epoch 49.322), train_loss = 0.91012724, grad/param norm = 1.8489e-01, time/batch = 18.9648s	
29890/30300 (epoch 49.323), train_loss = 1.06750090, grad/param norm = 2.0398e-01, time/batch = 17.8800s	
29891/30300 (epoch 49.325), train_loss = 0.96217151, grad/param norm = 1.9188e-01, time/batch = 19.9596s	
29892/30300 (epoch 49.327), train_loss = 0.95640643, grad/param norm = 1.6754e-01, time/batch = 19.1961s	
29893/30300 (epoch 49.328), train_loss = 1.01960818, grad/param norm = 1.7499e-01, time/batch = 17.4588s	
29894/30300 (epoch 49.330), train_loss = 1.01781855, grad/param norm = 1.8165e-01, time/batch = 19.0252s	
29895/30300 (epoch 49.332), train_loss = 1.07728868, grad/param norm = 2.0885e-01, time/batch = 19.5314s	
29896/30300 (epoch 49.333), train_loss = 0.89225147, grad/param norm = 1.8807e-01, time/batch = 18.8769s	
29897/30300 (epoch 49.335), train_loss = 0.88226733, grad/param norm = 1.7031e-01, time/batch = 18.8812s	
29898/30300 (epoch 49.337), train_loss = 1.07999115, grad/param norm = 2.0445e-01, time/batch = 19.8711s	
29899/30300 (epoch 49.338), train_loss = 0.93305114, grad/param norm = 1.7523e-01, time/batch = 18.5372s	
29900/30300 (epoch 49.340), train_loss = 0.94623191, grad/param norm = 1.7190e-01, time/batch = 18.4546s	
29901/30300 (epoch 49.342), train_loss = 1.06741503, grad/param norm = 2.0111e-01, time/batch = 20.2144s	
29902/30300 (epoch 49.343), train_loss = 1.02205602, grad/param norm = 2.1506e-01, time/batch = 18.6939s	
29903/30300 (epoch 49.345), train_loss = 0.99027846, grad/param norm = 1.7942e-01, time/batch = 18.7878s	
29904/30300 (epoch 49.347), train_loss = 0.88947218, grad/param norm = 2.0044e-01, time/batch = 20.1471s	
29905/30300 (epoch 49.348), train_loss = 0.93241771, grad/param norm = 1.7737e-01, time/batch = 18.9562s	
29906/30300 (epoch 49.350), train_loss = 0.96911459, grad/param norm = 2.0509e-01, time/batch = 19.3784s	
29907/30300 (epoch 49.351), train_loss = 0.95690482, grad/param norm = 1.7563e-01, time/batch = 19.5441s	
29908/30300 (epoch 49.353), train_loss = 0.88928249, grad/param norm = 1.7891e-01, time/batch = 19.2075s	
29909/30300 (epoch 49.355), train_loss = 0.92881535, grad/param norm = 1.7366e-01, time/batch = 20.2284s	
29910/30300 (epoch 49.356), train_loss = 1.00572192, grad/param norm = 1.9636e-01, time/batch = 19.2211s	
29911/30300 (epoch 49.358), train_loss = 1.20412167, grad/param norm = 1.9511e-01, time/batch = 17.3394s	
29912/30300 (epoch 49.360), train_loss = 0.93414097, grad/param norm = 1.8339e-01, time/batch = 19.7814s	
29913/30300 (epoch 49.361), train_loss = 0.97727135, grad/param norm = 1.8812e-01, time/batch = 18.7238s	
29914/30300 (epoch 49.363), train_loss = 1.01408236, grad/param norm = 1.9737e-01, time/batch = 17.8520s	
29915/30300 (epoch 49.365), train_loss = 0.83030514, grad/param norm = 2.5276e-01, time/batch = 18.8745s	
29916/30300 (epoch 49.366), train_loss = 0.93986910, grad/param norm = 1.7104e-01, time/batch = 19.2902s	
29917/30300 (epoch 49.368), train_loss = 0.85606002, grad/param norm = 1.8806e-01, time/batch = 18.8565s	
29918/30300 (epoch 49.370), train_loss = 0.87964183, grad/param norm = 1.8599e-01, time/batch = 19.6220s	
29919/30300 (epoch 49.371), train_loss = 1.05362287, grad/param norm = 2.1375e-01, time/batch = 19.6282s	
29920/30300 (epoch 49.373), train_loss = 0.91322310, grad/param norm = 1.6256e-01, time/batch = 18.9699s	
29921/30300 (epoch 49.375), train_loss = 0.91404462, grad/param norm = 1.8166e-01, time/batch = 19.2946s	
29922/30300 (epoch 49.376), train_loss = 0.91023969, grad/param norm = 1.7270e-01, time/batch = 18.5328s	
29923/30300 (epoch 49.378), train_loss = 0.87736768, grad/param norm = 2.0051e-01, time/batch = 19.1249s	
29924/30300 (epoch 49.380), train_loss = 1.05663377, grad/param norm = 1.8204e-01, time/batch = 18.1859s	
29925/30300 (epoch 49.381), train_loss = 0.82413463, grad/param norm = 1.6225e-01, time/batch = 19.7869s	
29926/30300 (epoch 49.383), train_loss = 0.87013317, grad/param norm = 2.0118e-01, time/batch = 20.1311s	
29927/30300 (epoch 49.384), train_loss = 1.00638509, grad/param norm = 1.9964e-01, time/batch = 17.9975s	
29928/30300 (epoch 49.386), train_loss = 0.87571875, grad/param norm = 1.8015e-01, time/batch = 19.9758s	
29929/30300 (epoch 49.388), train_loss = 0.85131811, grad/param norm = 1.6814e-01, time/batch = 19.6335s	
29930/30300 (epoch 49.389), train_loss = 0.95053250, grad/param norm = 1.9591e-01, time/batch = 18.7842s	
29931/30300 (epoch 49.391), train_loss = 1.01294620, grad/param norm = 1.8427e-01, time/batch = 20.4546s	
29932/30300 (epoch 49.393), train_loss = 0.85561804, grad/param norm = 1.6344e-01, time/batch = 18.8851s	
29933/30300 (epoch 49.394), train_loss = 0.97711693, grad/param norm = 1.6869e-01, time/batch = 18.6315s	
29934/30300 (epoch 49.396), train_loss = 1.09793345, grad/param norm = 1.6940e-01, time/batch = 18.5185s	
29935/30300 (epoch 49.398), train_loss = 0.95167333, grad/param norm = 1.9189e-01, time/batch = 19.2941s	
29936/30300 (epoch 49.399), train_loss = 0.84752327, grad/param norm = 1.7299e-01, time/batch = 18.6126s	
29937/30300 (epoch 49.401), train_loss = 0.96466086, grad/param norm = 2.2330e-01, time/batch = 18.2059s	
29938/30300 (epoch 49.403), train_loss = 0.96752622, grad/param norm = 2.0380e-01, time/batch = 19.5484s	
29939/30300 (epoch 49.404), train_loss = 0.91040163, grad/param norm = 1.9754e-01, time/batch = 18.5459s	
29940/30300 (epoch 49.406), train_loss = 0.95302997, grad/param norm = 1.5942e-01, time/batch = 19.0582s	
29941/30300 (epoch 49.408), train_loss = 0.85180948, grad/param norm = 1.6752e-01, time/batch = 19.6173s	
29942/30300 (epoch 49.409), train_loss = 0.84686809, grad/param norm = 1.8492e-01, time/batch = 18.2043s	
29943/30300 (epoch 49.411), train_loss = 0.88865435, grad/param norm = 1.5448e-01, time/batch = 18.3690s	
29944/30300 (epoch 49.413), train_loss = 0.80326135, grad/param norm = 1.7474e-01, time/batch = 19.2206s	
29945/30300 (epoch 49.414), train_loss = 0.97721101, grad/param norm = 1.7893e-01, time/batch = 17.6120s	
29946/30300 (epoch 49.416), train_loss = 0.88926345, grad/param norm = 1.6532e-01, time/batch = 19.4551s	
29947/30300 (epoch 49.417), train_loss = 0.87370816, grad/param norm = 1.6847e-01, time/batch = 18.2809s	
29948/30300 (epoch 49.419), train_loss = 0.85877658, grad/param norm = 1.7911e-01, time/batch = 18.7211s	
29949/30300 (epoch 49.421), train_loss = 0.92223731, grad/param norm = 2.4077e-01, time/batch = 17.8641s	
29950/30300 (epoch 49.422), train_loss = 0.95066290, grad/param norm = 1.6499e-01, time/batch = 19.5393s	
29951/30300 (epoch 49.424), train_loss = 0.96441689, grad/param norm = 1.8545e-01, time/batch = 19.6239s	
29952/30300 (epoch 49.426), train_loss = 0.94296530, grad/param norm = 1.7630e-01, time/batch = 18.8735s	
29953/30300 (epoch 49.427), train_loss = 0.92116872, grad/param norm = 1.8757e-01, time/batch = 19.7117s	
29954/30300 (epoch 49.429), train_loss = 0.94530900, grad/param norm = 1.6123e-01, time/batch = 18.4559s	
29955/30300 (epoch 49.431), train_loss = 0.96950298, grad/param norm = 2.1580e-01, time/batch = 18.2928s	
29956/30300 (epoch 49.432), train_loss = 0.98018173, grad/param norm = 1.7026e-01, time/batch = 19.0427s	
29957/30300 (epoch 49.434), train_loss = 0.84011333, grad/param norm = 1.6409e-01, time/batch = 20.2273s	
29958/30300 (epoch 49.436), train_loss = 1.03683952, grad/param norm = 1.8309e-01, time/batch = 18.2035s	
29959/30300 (epoch 49.437), train_loss = 0.87574402, grad/param norm = 1.7641e-01, time/batch = 17.8820s	
29960/30300 (epoch 49.439), train_loss = 0.92377331, grad/param norm = 1.8924e-01, time/batch = 19.4863s	
29961/30300 (epoch 49.441), train_loss = 0.95681075, grad/param norm = 1.6576e-01, time/batch = 18.9599s	
29962/30300 (epoch 49.442), train_loss = 0.88064091, grad/param norm = 1.8533e-01, time/batch = 18.9599s	
29963/30300 (epoch 49.444), train_loss = 0.79782039, grad/param norm = 1.7092e-01, time/batch = 18.2032s	
29964/30300 (epoch 49.446), train_loss = 0.90366856, grad/param norm = 1.6139e-01, time/batch = 18.7028s	
29965/30300 (epoch 49.447), train_loss = 0.95856906, grad/param norm = 2.0215e-01, time/batch = 19.1384s	
29966/30300 (epoch 49.449), train_loss = 0.89669272, grad/param norm = 1.8455e-01, time/batch = 19.1337s	
29967/30300 (epoch 49.450), train_loss = 0.97604476, grad/param norm = 1.5947e-01, time/batch = 18.5353s	
29968/30300 (epoch 49.452), train_loss = 1.06859365, grad/param norm = 1.6998e-01, time/batch = 18.3751s	
29969/30300 (epoch 49.454), train_loss = 0.98896499, grad/param norm = 1.6260e-01, time/batch = 19.7200s	
29970/30300 (epoch 49.455), train_loss = 0.97627706, grad/param norm = 2.1936e-01, time/batch = 18.4704s	
29971/30300 (epoch 49.457), train_loss = 0.94119669, grad/param norm = 1.7334e-01, time/batch = 18.9490s	
29972/30300 (epoch 49.459), train_loss = 0.98144182, grad/param norm = 1.9518e-01, time/batch = 17.5502s	
29973/30300 (epoch 49.460), train_loss = 1.03916471, grad/param norm = 1.7404e-01, time/batch = 20.1194s	
29974/30300 (epoch 49.462), train_loss = 1.03420576, grad/param norm = 2.2218e-01, time/batch = 18.5505s	
29975/30300 (epoch 49.464), train_loss = 0.80324161, grad/param norm = 2.2862e-01, time/batch = 18.1322s	
29976/30300 (epoch 49.465), train_loss = 0.81852150, grad/param norm = 1.5929e-01, time/batch = 18.9747s	
29977/30300 (epoch 49.467), train_loss = 0.79910645, grad/param norm = 1.6468e-01, time/batch = 19.1185s	
29978/30300 (epoch 49.469), train_loss = 0.89059680, grad/param norm = 1.9212e-01, time/batch = 18.9563s	
29979/30300 (epoch 49.470), train_loss = 0.89050402, grad/param norm = 1.7113e-01, time/batch = 19.0698s	
29980/30300 (epoch 49.472), train_loss = 0.90249993, grad/param norm = 1.6507e-01, time/batch = 18.0396s	
29981/30300 (epoch 49.474), train_loss = 0.88991681, grad/param norm = 2.0963e-01, time/batch = 18.4427s	
29982/30300 (epoch 49.475), train_loss = 0.87366535, grad/param norm = 1.6571e-01, time/batch = 19.4446s	
29983/30300 (epoch 49.477), train_loss = 0.92565992, grad/param norm = 1.8267e-01, time/batch = 19.2899s	
29984/30300 (epoch 49.479), train_loss = 0.88083433, grad/param norm = 1.8031e-01, time/batch = 19.6298s	
29985/30300 (epoch 49.480), train_loss = 0.96522950, grad/param norm = 1.6730e-01, time/batch = 17.8092s	
29986/30300 (epoch 49.482), train_loss = 0.99861061, grad/param norm = 1.6716e-01, time/batch = 18.8733s	
29987/30300 (epoch 49.483), train_loss = 0.93690582, grad/param norm = 1.8233e-01, time/batch = 18.1069s	
29988/30300 (epoch 49.485), train_loss = 0.97051433, grad/param norm = 1.8741e-01, time/batch = 19.3871s	
29989/30300 (epoch 49.487), train_loss = 1.00812163, grad/param norm = 1.8257e-01, time/batch = 19.8880s	
29990/30300 (epoch 49.488), train_loss = 1.08118431, grad/param norm = 1.6484e-01, time/batch = 17.7645s	
29991/30300 (epoch 49.490), train_loss = 0.82804466, grad/param norm = 1.6943e-01, time/batch = 19.6315s	
29992/30300 (epoch 49.492), train_loss = 0.91186123, grad/param norm = 1.9724e-01, time/batch = 19.1336s	
29993/30300 (epoch 49.493), train_loss = 0.94633927, grad/param norm = 1.6817e-01, time/batch = 18.7043s	
29994/30300 (epoch 49.495), train_loss = 0.96054269, grad/param norm = 1.7305e-01, time/batch = 18.8036s	
29995/30300 (epoch 49.497), train_loss = 1.00268591, grad/param norm = 1.8539e-01, time/batch = 19.6155s	
29996/30300 (epoch 49.498), train_loss = 1.02838846, grad/param norm = 2.1812e-01, time/batch = 17.1261s	
29997/30300 (epoch 49.500), train_loss = 0.89791731, grad/param norm = 2.2421e-01, time/batch = 18.3547s	
29998/30300 (epoch 49.502), train_loss = 0.96259279, grad/param norm = 2.0099e-01, time/batch = 19.8170s	
29999/30300 (epoch 49.503), train_loss = 1.04642032, grad/param norm = 1.7566e-01, time/batch = 19.0380s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch49.50_2.1043.t7	
30000/30300 (epoch 49.505), train_loss = 0.83648029, grad/param norm = 1.6173e-01, time/batch = 19.0504s	
30001/30300 (epoch 49.507), train_loss = 1.57471643, grad/param norm = 5.4907e-01, time/batch = 18.0443s	
30002/30300 (epoch 49.508), train_loss = 1.00520918, grad/param norm = 3.2649e-01, time/batch = 19.6358s	
30003/30300 (epoch 49.510), train_loss = 1.04591606, grad/param norm = 2.6297e-01, time/batch = 19.7996s	
30004/30300 (epoch 49.512), train_loss = 0.89320559, grad/param norm = 1.6671e-01, time/batch = 17.3633s	
30005/30300 (epoch 49.513), train_loss = 0.97964222, grad/param norm = 2.0601e-01, time/batch = 19.4694s	
30006/30300 (epoch 49.515), train_loss = 0.96259231, grad/param norm = 1.8072e-01, time/batch = 18.2929s	
30007/30300 (epoch 49.517), train_loss = 0.79431355, grad/param norm = 1.8379e-01, time/batch = 18.1904s	
30008/30300 (epoch 49.518), train_loss = 1.04071097, grad/param norm = 1.9982e-01, time/batch = 19.2849s	
30009/30300 (epoch 49.520), train_loss = 0.92823385, grad/param norm = 1.9132e-01, time/batch = 19.0386s	
30010/30300 (epoch 49.521), train_loss = 0.84733747, grad/param norm = 2.1376e-01, time/batch = 19.1952s	
30011/30300 (epoch 49.523), train_loss = 1.06326959, grad/param norm = 2.3665e-01, time/batch = 18.7085s	
30012/30300 (epoch 49.525), train_loss = 0.87601781, grad/param norm = 1.7459e-01, time/batch = 19.7952s	
30013/30300 (epoch 49.526), train_loss = 0.96646343, grad/param norm = 1.6427e-01, time/batch = 19.5486s	
30014/30300 (epoch 49.528), train_loss = 0.83561943, grad/param norm = 1.8110e-01, time/batch = 18.5444s	
30015/30300 (epoch 49.530), train_loss = 0.82547014, grad/param norm = 2.0338e-01, time/batch = 19.2060s	
30016/30300 (epoch 49.531), train_loss = 0.91619430, grad/param norm = 1.8773e-01, time/batch = 17.7902s	
30017/30300 (epoch 49.533), train_loss = 0.92588239, grad/param norm = 2.2301e-01, time/batch = 18.5367s	
30018/30300 (epoch 49.535), train_loss = 0.96782157, grad/param norm = 2.0148e-01, time/batch = 20.0462s	
30019/30300 (epoch 49.536), train_loss = 0.94711497, grad/param norm = 1.7831e-01, time/batch = 19.4705s	
30020/30300 (epoch 49.538), train_loss = 0.84353074, grad/param norm = 2.0456e-01, time/batch = 18.5236s	
30021/30300 (epoch 49.540), train_loss = 0.89799415, grad/param norm = 2.2122e-01, time/batch = 18.1117s	
30022/30300 (epoch 49.541), train_loss = 0.94020417, grad/param norm = 2.1830e-01, time/batch = 19.5525s	
30023/30300 (epoch 49.543), train_loss = 0.93100498, grad/param norm = 1.7807e-01, time/batch = 18.7192s	
30024/30300 (epoch 49.545), train_loss = 1.00266794, grad/param norm = 2.4446e-01, time/batch = 19.4680s	
30025/30300 (epoch 49.546), train_loss = 1.09948498, grad/param norm = 1.7166e-01, time/batch = 18.2139s	
30026/30300 (epoch 49.548), train_loss = 0.91176506, grad/param norm = 1.7360e-01, time/batch = 18.4779s	
30027/30300 (epoch 49.550), train_loss = 1.00211038, grad/param norm = 2.3773e-01, time/batch = 19.1321s	
30028/30300 (epoch 49.551), train_loss = 0.89141239, grad/param norm = 1.8995e-01, time/batch = 18.6117s	
30029/30300 (epoch 49.553), train_loss = 0.92524194, grad/param norm = 1.7765e-01, time/batch = 18.5373s	
30030/30300 (epoch 49.554), train_loss = 0.92945783, grad/param norm = 1.7892e-01, time/batch = 19.2124s	
30031/30300 (epoch 49.556), train_loss = 0.97765808, grad/param norm = 1.8138e-01, time/batch = 20.1223s	
30032/30300 (epoch 49.558), train_loss = 1.06408783, grad/param norm = 2.3198e-01, time/batch = 18.8758s	
30033/30300 (epoch 49.559), train_loss = 0.97814730, grad/param norm = 2.0174e-01, time/batch = 19.1281s	
30034/30300 (epoch 49.561), train_loss = 0.76571606, grad/param norm = 1.8609e-01, time/batch = 19.7152s	
30035/30300 (epoch 49.563), train_loss = 0.82780053, grad/param norm = 1.7947e-01, time/batch = 19.5543s	
30036/30300 (epoch 49.564), train_loss = 0.91248660, grad/param norm = 1.7584e-01, time/batch = 18.6189s	
30037/30300 (epoch 49.566), train_loss = 0.91773532, grad/param norm = 1.8266e-01, time/batch = 17.7294s	
30038/30300 (epoch 49.568), train_loss = 0.79666129, grad/param norm = 2.0140e-01, time/batch = 18.5257s	
30039/30300 (epoch 49.569), train_loss = 0.96284381, grad/param norm = 1.6929e-01, time/batch = 17.3486s	
30040/30300 (epoch 49.571), train_loss = 0.95250105, grad/param norm = 1.9013e-01, time/batch = 19.4594s	
30041/30300 (epoch 49.573), train_loss = 0.96759132, grad/param norm = 1.7729e-01, time/batch = 19.3757s	
30042/30300 (epoch 49.574), train_loss = 0.96426354, grad/param norm = 1.7882e-01, time/batch = 18.6823s	
30043/30300 (epoch 49.576), train_loss = 0.92275017, grad/param norm = 1.6479e-01, time/batch = 16.4785s	
30044/30300 (epoch 49.578), train_loss = 0.81097917, grad/param norm = 1.7149e-01, time/batch = 18.1262s	
30045/30300 (epoch 49.579), train_loss = 1.01889555, grad/param norm = 1.9376e-01, time/batch = 18.4488s	
30046/30300 (epoch 49.581), train_loss = 1.04257683, grad/param norm = 1.8030e-01, time/batch = 19.5470s	
30047/30300 (epoch 49.583), train_loss = 1.07043360, grad/param norm = 2.4610e-01, time/batch = 19.3706s	
30048/30300 (epoch 49.584), train_loss = 1.05927137, grad/param norm = 1.9579e-01, time/batch = 18.2088s	
30049/30300 (epoch 49.586), train_loss = 0.90522178, grad/param norm = 1.8262e-01, time/batch = 19.0391s	
30050/30300 (epoch 49.587), train_loss = 0.95104689, grad/param norm = 1.9503e-01, time/batch = 17.9501s	
30051/30300 (epoch 49.589), train_loss = 0.87721209, grad/param norm = 1.7706e-01, time/batch = 19.6394s	
30052/30300 (epoch 49.591), train_loss = 0.99385976, grad/param norm = 1.6212e-01, time/batch = 18.8609s	
30053/30300 (epoch 49.592), train_loss = 0.92196593, grad/param norm = 1.6170e-01, time/batch = 19.2920s	
30054/30300 (epoch 49.594), train_loss = 1.03022553, grad/param norm = 1.8432e-01, time/batch = 19.6450s	
30055/30300 (epoch 49.596), train_loss = 0.87036966, grad/param norm = 1.7305e-01, time/batch = 19.0499s	
30056/30300 (epoch 49.597), train_loss = 0.89159290, grad/param norm = 1.8764e-01, time/batch = 19.3746s	
30057/30300 (epoch 49.599), train_loss = 0.81335850, grad/param norm = 1.7375e-01, time/batch = 19.0570s	
30058/30300 (epoch 49.601), train_loss = 0.95073737, grad/param norm = 1.7994e-01, time/batch = 18.1812s	
30059/30300 (epoch 49.602), train_loss = 0.95570739, grad/param norm = 1.5828e-01, time/batch = 17.7807s	
30060/30300 (epoch 49.604), train_loss = 0.85790795, grad/param norm = 1.6230e-01, time/batch = 19.8683s	
30061/30300 (epoch 49.606), train_loss = 0.88008579, grad/param norm = 2.0127e-01, time/batch = 18.3594s	
30062/30300 (epoch 49.607), train_loss = 1.00911844, grad/param norm = 2.1422e-01, time/batch = 19.2747s	
30063/30300 (epoch 49.609), train_loss = 1.10279560, grad/param norm = 1.9945e-01, time/batch = 20.0320s	
30064/30300 (epoch 49.611), train_loss = 0.93536883, grad/param norm = 1.6597e-01, time/batch = 18.8768s	
30065/30300 (epoch 49.612), train_loss = 0.85405171, grad/param norm = 1.5138e-01, time/batch = 19.0358s	
30066/30300 (epoch 49.614), train_loss = 0.92130226, grad/param norm = 1.6451e-01, time/batch = 19.1189s	
30067/30300 (epoch 49.616), train_loss = 0.95643320, grad/param norm = 2.0869e-01, time/batch = 18.7881s	
30068/30300 (epoch 49.617), train_loss = 0.91597444, grad/param norm = 2.0674e-01, time/batch = 17.8702s	
30069/30300 (epoch 49.619), train_loss = 0.76834390, grad/param norm = 1.4871e-01, time/batch = 18.5501s	
30070/30300 (epoch 49.620), train_loss = 1.00628211, grad/param norm = 1.8441e-01, time/batch = 19.4598s	
30071/30300 (epoch 49.622), train_loss = 0.94124499, grad/param norm = 2.0247e-01, time/batch = 19.8767s	
30072/30300 (epoch 49.624), train_loss = 0.92744502, grad/param norm = 1.9025e-01, time/batch = 17.5324s	
30073/30300 (epoch 49.625), train_loss = 0.93054451, grad/param norm = 2.2651e-01, time/batch = 19.1256s	
30074/30300 (epoch 49.627), train_loss = 1.02195887, grad/param norm = 1.8016e-01, time/batch = 18.9461s	
30075/30300 (epoch 49.629), train_loss = 1.04289486, grad/param norm = 1.7391e-01, time/batch = 19.0358s	
30076/30300 (epoch 49.630), train_loss = 0.93385055, grad/param norm = 1.6327e-01, time/batch = 19.7869s	
30077/30300 (epoch 49.632), train_loss = 0.98400033, grad/param norm = 1.8864e-01, time/batch = 18.4421s	
30078/30300 (epoch 49.634), train_loss = 0.86512252, grad/param norm = 1.5923e-01, time/batch = 19.3839s	
30079/30300 (epoch 49.635), train_loss = 0.98245883, grad/param norm = 2.4773e-01, time/batch = 20.0445s	
30080/30300 (epoch 49.637), train_loss = 1.01623794, grad/param norm = 2.3783e-01, time/batch = 18.2774s	
30081/30300 (epoch 49.639), train_loss = 0.92687056, grad/param norm = 1.8278e-01, time/batch = 17.3596s	
30082/30300 (epoch 49.640), train_loss = 1.05389802, grad/param norm = 2.3418e-01, time/batch = 18.4701s	
30083/30300 (epoch 49.642), train_loss = 0.94443940, grad/param norm = 1.7743e-01, time/batch = 18.0455s	
30084/30300 (epoch 49.644), train_loss = 1.02755669, grad/param norm = 1.9043e-01, time/batch = 19.7098s	
30085/30300 (epoch 49.645), train_loss = 0.87111616, grad/param norm = 1.5393e-01, time/batch = 19.7163s	
30086/30300 (epoch 49.647), train_loss = 0.92723953, grad/param norm = 1.7341e-01, time/batch = 18.7882s	
30087/30300 (epoch 49.649), train_loss = 0.93516800, grad/param norm = 2.1121e-01, time/batch = 19.3841s	
30088/30300 (epoch 49.650), train_loss = 0.96058740, grad/param norm = 1.6885e-01, time/batch = 19.3856s	
30089/30300 (epoch 49.652), train_loss = 0.92573720, grad/param norm = 1.8076e-01, time/batch = 18.4518s	
30090/30300 (epoch 49.653), train_loss = 1.07632370, grad/param norm = 1.5829e-01, time/batch = 19.0466s	
30091/30300 (epoch 49.655), train_loss = 0.91656207, grad/param norm = 1.8929e-01, time/batch = 17.5358s	
30092/30300 (epoch 49.657), train_loss = 0.84202251, grad/param norm = 1.8912e-01, time/batch = 19.5345s	
30093/30300 (epoch 49.658), train_loss = 0.90522700, grad/param norm = 1.6202e-01, time/batch = 17.4236s	
30094/30300 (epoch 49.660), train_loss = 0.92719618, grad/param norm = 1.7805e-01, time/batch = 19.3635s	
30095/30300 (epoch 49.662), train_loss = 0.95679082, grad/param norm = 1.9183e-01, time/batch = 19.7969s	
30096/30300 (epoch 49.663), train_loss = 1.01436809, grad/param norm = 2.0532e-01, time/batch = 17.8698s	
30097/30300 (epoch 49.665), train_loss = 0.87154041, grad/param norm = 2.1025e-01, time/batch = 19.4586s	
30098/30300 (epoch 49.667), train_loss = 1.00249247, grad/param norm = 1.9865e-01, time/batch = 19.1308s	
30099/30300 (epoch 49.668), train_loss = 1.02518293, grad/param norm = 1.7518e-01, time/batch = 18.2096s	
30100/30300 (epoch 49.670), train_loss = 1.05463656, grad/param norm = 1.9590e-01, time/batch = 18.3086s	
30101/30300 (epoch 49.672), train_loss = 0.94632385, grad/param norm = 2.0212e-01, time/batch = 20.2129s	
30102/30300 (epoch 49.673), train_loss = 0.99243435, grad/param norm = 2.0756e-01, time/batch = 18.3812s	
30103/30300 (epoch 49.675), train_loss = 0.92984133, grad/param norm = 1.7630e-01, time/batch = 19.0236s	
30104/30300 (epoch 49.677), train_loss = 0.90929675, grad/param norm = 1.6706e-01, time/batch = 18.5330s	
30105/30300 (epoch 49.678), train_loss = 0.93305945, grad/param norm = 1.7687e-01, time/batch = 18.4482s	
30106/30300 (epoch 49.680), train_loss = 0.86040767, grad/param norm = 1.7697e-01, time/batch = 19.5375s	
30107/30300 (epoch 49.682), train_loss = 0.94617461, grad/param norm = 1.9427e-01, time/batch = 18.3740s	
30108/30300 (epoch 49.683), train_loss = 1.00912206, grad/param norm = 1.7380e-01, time/batch = 19.3660s	
30109/30300 (epoch 49.685), train_loss = 1.01093240, grad/param norm = 2.0296e-01, time/batch = 19.5464s	
30110/30300 (epoch 49.686), train_loss = 0.93195595, grad/param norm = 1.6802e-01, time/batch = 18.2866s	
30111/30300 (epoch 49.688), train_loss = 0.95333992, grad/param norm = 1.6324e-01, time/batch = 19.7100s	
30112/30300 (epoch 49.690), train_loss = 0.89872859, grad/param norm = 1.8424e-01, time/batch = 18.5492s	
30113/30300 (epoch 49.691), train_loss = 0.92118752, grad/param norm = 1.6880e-01, time/batch = 19.6309s	
30114/30300 (epoch 49.693), train_loss = 1.20522865, grad/param norm = 2.3943e-01, time/batch = 18.1142s	
30115/30300 (epoch 49.695), train_loss = 1.01642231, grad/param norm = 1.9446e-01, time/batch = 17.8358s	
30116/30300 (epoch 49.696), train_loss = 0.96524978, grad/param norm = 2.1342e-01, time/batch = 19.2197s	
30117/30300 (epoch 49.698), train_loss = 0.92603942, grad/param norm = 2.0667e-01, time/batch = 19.2268s	
30118/30300 (epoch 49.700), train_loss = 0.89379889, grad/param norm = 1.9084e-01, time/batch = 17.6212s	
30119/30300 (epoch 49.701), train_loss = 0.83889359, grad/param norm = 1.7339e-01, time/batch = 19.2972s	
30120/30300 (epoch 49.703), train_loss = 0.94966946, grad/param norm = 1.6632e-01, time/batch = 18.5439s	
30121/30300 (epoch 49.705), train_loss = 0.85610524, grad/param norm = 1.6396e-01, time/batch = 18.6083s	
30122/30300 (epoch 49.706), train_loss = 1.01549619, grad/param norm = 1.8449e-01, time/batch = 19.5545s	
30123/30300 (epoch 49.708), train_loss = 0.94304367, grad/param norm = 1.7193e-01, time/batch = 18.3829s	
30124/30300 (epoch 49.710), train_loss = 0.93034987, grad/param norm = 1.8487e-01, time/batch = 18.0449s	
30125/30300 (epoch 49.711), train_loss = 0.89520112, grad/param norm = 1.7761e-01, time/batch = 19.3854s	
30126/30300 (epoch 49.713), train_loss = 0.88125814, grad/param norm = 1.9532e-01, time/batch = 19.2168s	
30127/30300 (epoch 49.715), train_loss = 0.92467773, grad/param norm = 1.7528e-01, time/batch = 18.9745s	
30128/30300 (epoch 49.716), train_loss = 0.99456725, grad/param norm = 1.7209e-01, time/batch = 19.6258s	
30129/30300 (epoch 49.718), train_loss = 1.04823450, grad/param norm = 1.7878e-01, time/batch = 18.3602s	
30130/30300 (epoch 49.719), train_loss = 0.89999612, grad/param norm = 1.8387e-01, time/batch = 19.5543s	
30131/30300 (epoch 49.721), train_loss = 0.92709790, grad/param norm = 1.8688e-01, time/batch = 18.6981s	
30132/30300 (epoch 49.723), train_loss = 0.88887738, grad/param norm = 1.8702e-01, time/batch = 19.4603s	
30133/30300 (epoch 49.724), train_loss = 0.97263947, grad/param norm = 2.1921e-01, time/batch = 19.8018s	
30134/30300 (epoch 49.726), train_loss = 1.20662808, grad/param norm = 2.5969e-01, time/batch = 18.8000s	
30135/30300 (epoch 49.728), train_loss = 0.98663671, grad/param norm = 1.8238e-01, time/batch = 19.8090s	
30136/30300 (epoch 49.729), train_loss = 0.91444840, grad/param norm = 1.8160e-01, time/batch = 16.9613s	
30137/30300 (epoch 49.731), train_loss = 0.89812165, grad/param norm = 2.0997e-01, time/batch = 18.0379s	
30138/30300 (epoch 49.733), train_loss = 0.96621827, grad/param norm = 1.7746e-01, time/batch = 19.4640s	
30139/30300 (epoch 49.734), train_loss = 1.03861873, grad/param norm = 1.7942e-01, time/batch = 19.5598s	
30140/30300 (epoch 49.736), train_loss = 0.97402055, grad/param norm = 1.7178e-01, time/batch = 17.9533s	
30141/30300 (epoch 49.738), train_loss = 0.89258690, grad/param norm = 1.4865e-01, time/batch = 18.7238s	
30142/30300 (epoch 49.739), train_loss = 1.06024806, grad/param norm = 1.8966e-01, time/batch = 19.0416s	
30143/30300 (epoch 49.741), train_loss = 1.06948149, grad/param norm = 1.7476e-01, time/batch = 19.1382s	
30144/30300 (epoch 49.743), train_loss = 0.92196937, grad/param norm = 1.7678e-01, time/batch = 19.5466s	
30145/30300 (epoch 49.744), train_loss = 0.98893055, grad/param norm = 1.8520e-01, time/batch = 19.5180s	
30146/30300 (epoch 49.746), train_loss = 0.92213602, grad/param norm = 1.6591e-01, time/batch = 18.8713s	
30147/30300 (epoch 49.748), train_loss = 0.93240502, grad/param norm = 1.9689e-01, time/batch = 19.6228s	
30148/30300 (epoch 49.749), train_loss = 0.96413439, grad/param norm = 1.7953e-01, time/batch = 19.3037s	
30149/30300 (epoch 49.751), train_loss = 0.98701629, grad/param norm = 1.7253e-01, time/batch = 18.8843s	
30150/30300 (epoch 49.752), train_loss = 0.92991336, grad/param norm = 1.7280e-01, time/batch = 18.0192s	
30151/30300 (epoch 49.754), train_loss = 0.93052383, grad/param norm = 1.8021e-01, time/batch = 19.8843s	
30152/30300 (epoch 49.756), train_loss = 0.94307474, grad/param norm = 1.8209e-01, time/batch = 19.0446s	
30153/30300 (epoch 49.757), train_loss = 0.85807703, grad/param norm = 1.7069e-01, time/batch = 18.4493s	
30154/30300 (epoch 49.759), train_loss = 0.94584128, grad/param norm = 1.6598e-01, time/batch = 19.7957s	
30155/30300 (epoch 49.761), train_loss = 0.81034218, grad/param norm = 1.6374e-01, time/batch = 19.7852s	
30156/30300 (epoch 49.762), train_loss = 0.83931628, grad/param norm = 1.8639e-01, time/batch = 18.8621s	
30157/30300 (epoch 49.764), train_loss = 0.93040352, grad/param norm = 1.8013e-01, time/batch = 19.4687s	
30158/30300 (epoch 49.766), train_loss = 1.05592318, grad/param norm = 1.9977e-01, time/batch = 17.6028s	
30159/30300 (epoch 49.767), train_loss = 0.92271416, grad/param norm = 2.2390e-01, time/batch = 16.9474s	
30160/30300 (epoch 49.769), train_loss = 0.94955964, grad/param norm = 1.9191e-01, time/batch = 19.7018s	
30161/30300 (epoch 49.771), train_loss = 0.89237488, grad/param norm = 2.3237e-01, time/batch = 19.7079s	
30162/30300 (epoch 49.772), train_loss = 0.92876594, grad/param norm = 1.8385e-01, time/batch = 18.8776s	
30163/30300 (epoch 49.774), train_loss = 1.11977026, grad/param norm = 1.8665e-01, time/batch = 19.7135s	
30164/30300 (epoch 49.776), train_loss = 0.91572042, grad/param norm = 2.0187e-01, time/batch = 19.0447s	
30165/30300 (epoch 49.777), train_loss = 1.06776603, grad/param norm = 1.7745e-01, time/batch = 17.9622s	
30166/30300 (epoch 49.779), train_loss = 1.08939236, grad/param norm = 2.6107e-01, time/batch = 19.3923s	
30167/30300 (epoch 49.781), train_loss = 0.94105828, grad/param norm = 2.1714e-01, time/batch = 19.7996s	
30168/30300 (epoch 49.782), train_loss = 0.86953055, grad/param norm = 1.7356e-01, time/batch = 18.4638s	
30169/30300 (epoch 49.784), train_loss = 0.89524239, grad/param norm = 1.7327e-01, time/batch = 18.9680s	
30170/30300 (epoch 49.785), train_loss = 0.99094609, grad/param norm = 2.3820e-01, time/batch = 19.3754s	
30171/30300 (epoch 49.787), train_loss = 0.81159655, grad/param norm = 2.2468e-01, time/batch = 19.1096s	
30172/30300 (epoch 49.789), train_loss = 1.10334562, grad/param norm = 2.0175e-01, time/batch = 18.8855s	
30173/30300 (epoch 49.790), train_loss = 0.92771331, grad/param norm = 1.8794e-01, time/batch = 19.3796s	
30174/30300 (epoch 49.792), train_loss = 0.77083738, grad/param norm = 1.7265e-01, time/batch = 18.3088s	
30175/30300 (epoch 49.794), train_loss = 0.97690562, grad/param norm = 2.0259e-01, time/batch = 17.6889s	
30176/30300 (epoch 49.795), train_loss = 0.87674279, grad/param norm = 1.7446e-01, time/batch = 19.2284s	
30177/30300 (epoch 49.797), train_loss = 1.10341138, grad/param norm = 2.6189e-01, time/batch = 19.3835s	
30178/30300 (epoch 49.799), train_loss = 1.00227134, grad/param norm = 2.2073e-01, time/batch = 19.4461s	
30179/30300 (epoch 49.800), train_loss = 1.02736168, grad/param norm = 2.1252e-01, time/batch = 18.9700s	
30180/30300 (epoch 49.802), train_loss = 1.19580637, grad/param norm = 3.4067e-01, time/batch = 18.8717s	
30181/30300 (epoch 49.804), train_loss = 1.00592474, grad/param norm = 2.1847e-01, time/batch = 19.2867s	
30182/30300 (epoch 49.805), train_loss = 1.08618932, grad/param norm = 1.9474e-01, time/batch = 39.9547s	
30183/30300 (epoch 49.807), train_loss = 0.94281246, grad/param norm = 2.1961e-01, time/batch = 33.2873s	
30184/30300 (epoch 49.809), train_loss = 1.05432583, grad/param norm = 2.0885e-01, time/batch = 44.6473s	
30185/30300 (epoch 49.810), train_loss = 0.99424610, grad/param norm = 1.8241e-01, time/batch = 69.4567s	
30186/30300 (epoch 49.812), train_loss = 0.92115850, grad/param norm = 1.8516e-01, time/batch = 38.9579s	
30187/30300 (epoch 49.814), train_loss = 0.96216959, grad/param norm = 1.8185e-01, time/batch = 40.2396s	
30188/30300 (epoch 49.815), train_loss = 0.96129358, grad/param norm = 2.2006e-01, time/batch = 39.7207s	
30189/30300 (epoch 49.817), train_loss = 1.01957636, grad/param norm = 1.8860e-01, time/batch = 40.7721s	
30190/30300 (epoch 49.818), train_loss = 1.00109666, grad/param norm = 1.8333e-01, time/batch = 38.8868s	
30191/30300 (epoch 49.820), train_loss = 1.10385898, grad/param norm = 2.0156e-01, time/batch = 20.0337s	
30192/30300 (epoch 49.822), train_loss = 1.10505214, grad/param norm = 2.2247e-01, time/batch = 18.3925s	
30193/30300 (epoch 49.823), train_loss = 1.06821097, grad/param norm = 2.0614e-01, time/batch = 17.7623s	
30194/30300 (epoch 49.825), train_loss = 1.08893486, grad/param norm = 2.1144e-01, time/batch = 18.7916s	
30195/30300 (epoch 49.827), train_loss = 0.87958842, grad/param norm = 3.2122e-01, time/batch = 18.9499s	
30196/30300 (epoch 49.828), train_loss = 1.06715901, grad/param norm = 1.9242e-01, time/batch = 19.7862s	
30197/30300 (epoch 49.830), train_loss = 1.00801231, grad/param norm = 1.7818e-01, time/batch = 19.8849s	
30198/30300 (epoch 49.832), train_loss = 0.88175194, grad/param norm = 1.8406e-01, time/batch = 17.9417s	
30199/30300 (epoch 49.833), train_loss = 0.97971629, grad/param norm = 2.0568e-01, time/batch = 19.6161s	
30200/30300 (epoch 49.835), train_loss = 0.89339186, grad/param norm = 1.7523e-01, time/batch = 19.6410s	
30201/30300 (epoch 49.837), train_loss = 0.87437156, grad/param norm = 1.7391e-01, time/batch = 18.8896s	
30202/30300 (epoch 49.838), train_loss = 0.88201491, grad/param norm = 1.6499e-01, time/batch = 19.5519s	
30203/30300 (epoch 49.840), train_loss = 1.01719625, grad/param norm = 1.6916e-01, time/batch = 18.3878s	
30204/30300 (epoch 49.842), train_loss = 0.94768043, grad/param norm = 1.6756e-01, time/batch = 17.8814s	
30205/30300 (epoch 49.843), train_loss = 1.02088297, grad/param norm = 3.1010e-01, time/batch = 19.2218s	
30206/30300 (epoch 49.845), train_loss = 1.00302092, grad/param norm = 1.9152e-01, time/batch = 18.4529s	
30207/30300 (epoch 49.847), train_loss = 0.94977623, grad/param norm = 1.9778e-01, time/batch = 18.7870s	
30208/30300 (epoch 49.848), train_loss = 1.02044011, grad/param norm = 2.1884e-01, time/batch = 19.6280s	
30209/30300 (epoch 49.850), train_loss = 0.95198522, grad/param norm = 1.6947e-01, time/batch = 17.5246s	
30210/30300 (epoch 49.851), train_loss = 1.01969475, grad/param norm = 2.3860e-01, time/batch = 18.3079s	
30211/30300 (epoch 49.853), train_loss = 0.94828671, grad/param norm = 2.0174e-01, time/batch = 18.7936s	
30212/30300 (epoch 49.855), train_loss = 0.90295822, grad/param norm = 1.6147e-01, time/batch = 19.5469s	
30213/30300 (epoch 49.856), train_loss = 0.98659804, grad/param norm = 1.9163e-01, time/batch = 17.9512s	
30214/30300 (epoch 49.858), train_loss = 0.89379293, grad/param norm = 1.7330e-01, time/batch = 19.0288s	
30215/30300 (epoch 49.860), train_loss = 0.86182880, grad/param norm = 1.5284e-01, time/batch = 19.6319s	
30216/30300 (epoch 49.861), train_loss = 1.09324151, grad/param norm = 1.8349e-01, time/batch = 19.0372s	
30217/30300 (epoch 49.863), train_loss = 0.90451262, grad/param norm = 1.6960e-01, time/batch = 18.6151s	
30218/30300 (epoch 49.865), train_loss = 1.01731863, grad/param norm = 2.0820e-01, time/batch = 19.1173s	
30219/30300 (epoch 49.866), train_loss = 1.02575101, grad/param norm = 1.8816e-01, time/batch = 19.3708s	
30220/30300 (epoch 49.868), train_loss = 0.98534955, grad/param norm = 1.7074e-01, time/batch = 17.9499s	
30221/30300 (epoch 49.870), train_loss = 0.90291317, grad/param norm = 1.7988e-01, time/batch = 19.6286s	
30222/30300 (epoch 49.871), train_loss = 0.98591503, grad/param norm = 1.7776e-01, time/batch = 19.5471s	
30223/30300 (epoch 49.873), train_loss = 0.97139466, grad/param norm = 1.5596e-01, time/batch = 17.3759s	
30224/30300 (epoch 49.875), train_loss = 0.90985891, grad/param norm = 1.5311e-01, time/batch = 19.2194s	
30225/30300 (epoch 49.876), train_loss = 0.84339857, grad/param norm = 1.6810e-01, time/batch = 18.8058s	
30226/30300 (epoch 49.878), train_loss = 0.79725526, grad/param norm = 1.8452e-01, time/batch = 18.0331s	
30227/30300 (epoch 49.880), train_loss = 0.86373596, grad/param norm = 1.6025e-01, time/batch = 16.6862s	
30228/30300 (epoch 49.881), train_loss = 1.09948794, grad/param norm = 2.4587e-01, time/batch = 18.4842s	
30229/30300 (epoch 49.883), train_loss = 1.02721320, grad/param norm = 2.2071e-01, time/batch = 17.7813s	
30230/30300 (epoch 49.884), train_loss = 0.95990364, grad/param norm = 1.6964e-01, time/batch = 18.3731s	
30231/30300 (epoch 49.886), train_loss = 0.99470662, grad/param norm = 2.2323e-01, time/batch = 19.1378s	
30232/30300 (epoch 49.888), train_loss = 0.91749725, grad/param norm = 1.7630e-01, time/batch = 19.1379s	
30233/30300 (epoch 49.889), train_loss = 1.01094642, grad/param norm = 1.8564e-01, time/batch = 18.3825s	
30234/30300 (epoch 49.891), train_loss = 0.93371674, grad/param norm = 1.7429e-01, time/batch = 18.8006s	
30235/30300 (epoch 49.893), train_loss = 1.15881124, grad/param norm = 1.8030e-01, time/batch = 18.2307s	
30236/30300 (epoch 49.894), train_loss = 0.95631393, grad/param norm = 1.8015e-01, time/batch = 17.0165s	
30237/30300 (epoch 49.896), train_loss = 0.81921396, grad/param norm = 1.7043e-01, time/batch = 17.7161s	
30238/30300 (epoch 49.898), train_loss = 0.80081504, grad/param norm = 1.6693e-01, time/batch = 19.3134s	
30239/30300 (epoch 49.899), train_loss = 0.86052120, grad/param norm = 1.8664e-01, time/batch = 18.3803s	
30240/30300 (epoch 49.901), train_loss = 0.96335946, grad/param norm = 2.0201e-01, time/batch = 18.5491s	
30241/30300 (epoch 49.903), train_loss = 0.94403072, grad/param norm = 2.2645e-01, time/batch = 17.6298s	
30242/30300 (epoch 49.904), train_loss = 0.97976829, grad/param norm = 1.8538e-01, time/batch = 19.2247s	
30243/30300 (epoch 49.906), train_loss = 0.95128093, grad/param norm = 2.1372e-01, time/batch = 17.9414s	
30244/30300 (epoch 49.908), train_loss = 0.90704624, grad/param norm = 1.6403e-01, time/batch = 17.8966s	
30245/30300 (epoch 49.909), train_loss = 0.93319252, grad/param norm = 2.3482e-01, time/batch = 18.9857s	
30246/30300 (epoch 49.911), train_loss = 0.93196274, grad/param norm = 1.7727e-01, time/batch = 16.6001s	
30247/30300 (epoch 49.913), train_loss = 0.94321122, grad/param norm = 1.6701e-01, time/batch = 18.6373s	
30248/30300 (epoch 49.914), train_loss = 0.93550162, grad/param norm = 1.9535e-01, time/batch = 17.2096s	
30249/30300 (epoch 49.916), train_loss = 0.96888274, grad/param norm = 1.5485e-01, time/batch = 17.8779s	
30250/30300 (epoch 49.917), train_loss = 0.90798604, grad/param norm = 1.6446e-01, time/batch = 18.8832s	
30251/30300 (epoch 49.919), train_loss = 0.83562846, grad/param norm = 1.8260e-01, time/batch = 18.4674s	
30252/30300 (epoch 49.921), train_loss = 0.92493762, grad/param norm = 1.6369e-01, time/batch = 17.7093s	
30253/30300 (epoch 49.922), train_loss = 1.03333249, grad/param norm = 1.8244e-01, time/batch = 18.1401s	
30254/30300 (epoch 49.924), train_loss = 0.93882298, grad/param norm = 1.8348e-01, time/batch = 19.2180s	
30255/30300 (epoch 49.926), train_loss = 0.99657123, grad/param norm = 1.8742e-01, time/batch = 18.6294s	
30256/30300 (epoch 49.927), train_loss = 0.96644533, grad/param norm = 1.6740e-01, time/batch = 17.9531s	
30257/30300 (epoch 49.929), train_loss = 0.87295715, grad/param norm = 1.8334e-01, time/batch = 18.4780s	
30258/30300 (epoch 49.931), train_loss = 1.01416316, grad/param norm = 2.0487e-01, time/batch = 18.9759s	
30259/30300 (epoch 49.932), train_loss = 0.89367520, grad/param norm = 1.7411e-01, time/batch = 16.8799s	
30260/30300 (epoch 49.934), train_loss = 0.98537147, grad/param norm = 1.8437e-01, time/batch = 19.1356s	
30261/30300 (epoch 49.936), train_loss = 0.92764565, grad/param norm = 2.0063e-01, time/batch = 17.3761s	
30262/30300 (epoch 49.937), train_loss = 0.90092464, grad/param norm = 1.7854e-01, time/batch = 18.5480s	
30263/30300 (epoch 49.939), train_loss = 1.04773448, grad/param norm = 1.9947e-01, time/batch = 17.8138s	
30264/30300 (epoch 49.941), train_loss = 0.93089419, grad/param norm = 1.8344e-01, time/batch = 18.3060s	
30265/30300 (epoch 49.942), train_loss = 0.92458947, grad/param norm = 1.9066e-01, time/batch = 19.2194s	
30266/30300 (epoch 49.944), train_loss = 0.84499102, grad/param norm = 1.7189e-01, time/batch = 17.0147s	
30267/30300 (epoch 49.946), train_loss = 1.00245388, grad/param norm = 2.5257e-01, time/batch = 19.2975s	
30268/30300 (epoch 49.947), train_loss = 0.97784968, grad/param norm = 2.4111e-01, time/batch = 18.4747s	
30269/30300 (epoch 49.949), train_loss = 1.03224089, grad/param norm = 2.2808e-01, time/batch = 17.7096s	
30270/30300 (epoch 49.950), train_loss = 1.05726469, grad/param norm = 2.0065e-01, time/batch = 17.8052s	
30271/30300 (epoch 49.952), train_loss = 0.98949421, grad/param norm = 1.8712e-01, time/batch = 19.0592s	
30272/30300 (epoch 49.954), train_loss = 1.18714269, grad/param norm = 1.7575e-01, time/batch = 17.7944s	
30273/30300 (epoch 49.955), train_loss = 0.93302778, grad/param norm = 1.7405e-01, time/batch = 17.4550s	
30274/30300 (epoch 49.957), train_loss = 1.01811918, grad/param norm = 2.0091e-01, time/batch = 18.2798s	
30275/30300 (epoch 49.959), train_loss = 0.86932178, grad/param norm = 1.9263e-01, time/batch = 18.2180s	
30276/30300 (epoch 49.960), train_loss = 0.92098222, grad/param norm = 1.9447e-01, time/batch = 17.2967s	
30277/30300 (epoch 49.962), train_loss = 0.90350036, grad/param norm = 3.1298e-01, time/batch = 18.7228s	
30278/30300 (epoch 49.964), train_loss = 0.87564760, grad/param norm = 2.3755e-01, time/batch = 18.7980s	
30279/30300 (epoch 49.965), train_loss = 0.88761459, grad/param norm = 2.1378e-01, time/batch = 17.9627s	
30280/30300 (epoch 49.967), train_loss = 0.93408522, grad/param norm = 2.3451e-01, time/batch = 19.0464s	
30281/30300 (epoch 49.969), train_loss = 0.89233931, grad/param norm = 1.8451e-01, time/batch = 19.2123s	
30282/30300 (epoch 49.970), train_loss = 0.92383814, grad/param norm = 1.8551e-01, time/batch = 17.2090s	
30283/30300 (epoch 49.972), train_loss = 0.85133215, grad/param norm = 2.0501e-01, time/batch = 19.0461s	
30284/30300 (epoch 49.974), train_loss = 1.05841644, grad/param norm = 2.0086e-01, time/batch = 18.4775s	
30285/30300 (epoch 49.975), train_loss = 1.08714127, grad/param norm = 2.3866e-01, time/batch = 18.1201s	
30286/30300 (epoch 49.977), train_loss = 1.12831708, grad/param norm = 1.9063e-01, time/batch = 17.5531s	
30287/30300 (epoch 49.979), train_loss = 1.00704794, grad/param norm = 1.8922e-01, time/batch = 19.1341s	
30288/30300 (epoch 49.980), train_loss = 1.04167463, grad/param norm = 2.0370e-01, time/batch = 18.2959s	
30289/30300 (epoch 49.982), train_loss = 1.02597452, grad/param norm = 2.0460e-01, time/batch = 18.6201s	
30290/30300 (epoch 49.983), train_loss = 1.06740192, grad/param norm = 1.8891e-01, time/batch = 18.3107s	
30291/30300 (epoch 49.985), train_loss = 1.01236905, grad/param norm = 3.3523e-01, time/batch = 17.8523s	
30292/30300 (epoch 49.987), train_loss = 0.98548621, grad/param norm = 1.7077e-01, time/batch = 16.9233s	
30293/30300 (epoch 49.988), train_loss = 1.09731141, grad/param norm = 1.9784e-01, time/batch = 18.8116s	
30294/30300 (epoch 49.990), train_loss = 0.90432001, grad/param norm = 2.1973e-01, time/batch = 19.2180s	
30295/30300 (epoch 49.992), train_loss = 1.05856656, grad/param norm = 1.8945e-01, time/batch = 17.7253s	
30296/30300 (epoch 49.993), train_loss = 1.03078781, grad/param norm = 2.1285e-01, time/batch = 17.9480s	
30297/30300 (epoch 49.995), train_loss = 0.94373169, grad/param norm = 2.2352e-01, time/batch = 18.9693s	
30298/30300 (epoch 49.997), train_loss = 1.04072597, grad/param norm = 2.2372e-01, time/batch = 18.6269s	
30299/30300 (epoch 49.998), train_loss = 1.04116985, grad/param norm = 1.9713e-01, time/batch = 15.9714s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_alex_epoch50.00_2.1234.t7	
30300/30300 (epoch 50.000), train_loss = 0.89888007, grad/param norm = 1.9643e-01, time/batch = 18.5613s	

real	5230m48.625s
user	5188m53.920s
sys	3m56.416s
