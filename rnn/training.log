tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 589, val: 32, test: 0	
vocab size: 175	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 310831	
cloning rnn	
cloning criterion	
1/29450 (epoch 0.002), train_loss = 5.16626258, grad/param norm = 5.6325e-01, time/batch = 0.7474s	
2/29450 (epoch 0.003), train_loss = 4.76545615, grad/param norm = 2.0754e+00, time/batch = 0.7003s	
3/29450 (epoch 0.005), train_loss = 3.75327252, grad/param norm = 1.4486e+00, time/batch = 0.7145s	
4/29450 (epoch 0.007), train_loss = 3.50834981, grad/param norm = 9.3263e-01, time/batch = 0.7114s	
5/29450 (epoch 0.008), train_loss = 3.38537156, grad/param norm = 7.4776e-01, time/batch = 0.6966s	
6/29450 (epoch 0.010), train_loss = 3.44863516, grad/param norm = 7.5221e-01, time/batch = 0.7012s	
7/29450 (epoch 0.012), train_loss = 3.41121727, grad/param norm = 8.1523e-01, time/batch = 0.6983s	
8/29450 (epoch 0.014), train_loss = 3.59654997, grad/param norm = 9.4552e-01, time/batch = 0.6989s	
9/29450 (epoch 0.015), train_loss = 3.39019325, grad/param norm = 7.2642e-01, time/batch = 0.7156s	
10/29450 (epoch 0.017), train_loss = 3.34319098, grad/param norm = 6.5165e-01, time/batch = 0.6983s	
11/29450 (epoch 0.019), train_loss = 3.31332223, grad/param norm = 7.3204e-01, time/batch = 0.7012s	
12/29450 (epoch 0.020), train_loss = 3.46899624, grad/param norm = 8.8812e-01, time/batch = 0.7000s	
13/29450 (epoch 0.022), train_loss = 3.37057317, grad/param norm = 8.3395e-01, time/batch = 0.7122s	
14/29450 (epoch 0.024), train_loss = 3.32184747, grad/param norm = 6.1271e-01, time/batch = 0.7096s	
15/29450 (epoch 0.025), train_loss = 3.29155803, grad/param norm = 7.8255e-01, time/batch = 0.6951s	
16/29450 (epoch 0.027), train_loss = 3.43518417, grad/param norm = 5.8894e-01, time/batch = 0.6963s	
17/29450 (epoch 0.029), train_loss = 3.43004897, grad/param norm = 7.0475e-01, time/batch = 0.7085s	
18/29450 (epoch 0.031), train_loss = 3.70086829, grad/param norm = 8.0669e-01, time/batch = 0.7139s	
19/29450 (epoch 0.032), train_loss = 3.74746172, grad/param norm = 8.2973e-01, time/batch = 0.6981s	
20/29450 (epoch 0.034), train_loss = 3.75692594, grad/param norm = 7.3687e-01, time/batch = 0.6962s	
21/29450 (epoch 0.036), train_loss = 3.70458076, grad/param norm = 7.0860e-01, time/batch = 0.6968s	
22/29450 (epoch 0.037), train_loss = 3.69475448, grad/param norm = 6.2276e-01, time/batch = 0.6965s	
23/29450 (epoch 0.039), train_loss = 3.29780001, grad/param norm = 7.1470e-01, time/batch = 0.6958s	
24/29450 (epoch 0.041), train_loss = 3.43052020, grad/param norm = 4.7596e-01, time/batch = 0.6960s	
25/29450 (epoch 0.042), train_loss = 3.33464361, grad/param norm = 7.1400e-01, time/batch = 0.6963s	
26/29450 (epoch 0.044), train_loss = 3.36668357, grad/param norm = 4.9592e-01, time/batch = 0.7250s	
27/29450 (epoch 0.046), train_loss = 3.69697568, grad/param norm = 6.7881e-01, time/batch = 0.7164s	
28/29450 (epoch 0.048), train_loss = 3.43143568, grad/param norm = 5.8485e-01, time/batch = 0.7076s	
29/29450 (epoch 0.049), train_loss = 3.46952933, grad/param norm = 6.6932e-01, time/batch = 0.6977s	
30/29450 (epoch 0.051), train_loss = 3.52262984, grad/param norm = 6.9640e-01, time/batch = 0.7046s	
31/29450 (epoch 0.053), train_loss = 3.49294722, grad/param norm = 5.9542e-01, time/batch = 0.7249s	
32/29450 (epoch 0.054), train_loss = 3.36466863, grad/param norm = 5.2469e-01, time/batch = 0.7181s	
33/29450 (epoch 0.056), train_loss = 3.33075669, grad/param norm = 5.7787e-01, time/batch = 0.7066s	
34/29450 (epoch 0.058), train_loss = 3.58160137, grad/param norm = 6.2424e-01, time/batch = 0.7019s	
35/29450 (epoch 0.059), train_loss = 3.30631634, grad/param norm = 8.5265e-01, time/batch = 0.7068s	
36/29450 (epoch 0.061), train_loss = 3.36380728, grad/param norm = 6.6139e-01, time/batch = 0.7256s	
37/29450 (epoch 0.063), train_loss = 3.44070039, grad/param norm = 5.9229e-01, time/batch = 0.6980s	
38/29450 (epoch 0.065), train_loss = 3.34660872, grad/param norm = 6.4370e-01, time/batch = 0.6970s	
39/29450 (epoch 0.066), train_loss = 3.24369592, grad/param norm = 7.2174e-01, time/batch = 0.7011s	
40/29450 (epoch 0.068), train_loss = 3.44463785, grad/param norm = 7.4853e-01, time/batch = 0.7215s	
41/29450 (epoch 0.070), train_loss = 3.45796233, grad/param norm = 5.6911e-01, time/batch = 0.7141s	
42/29450 (epoch 0.071), train_loss = 3.52135214, grad/param norm = 7.0036e-01, time/batch = 0.7079s	
43/29450 (epoch 0.073), train_loss = 3.40981754, grad/param norm = 7.0725e-01, time/batch = 0.6969s	
44/29450 (epoch 0.075), train_loss = 3.64237166, grad/param norm = 7.3262e-01, time/batch = 0.6906s	
45/29450 (epoch 0.076), train_loss = 3.38202776, grad/param norm = 5.7189e-01, time/batch = 0.7103s	
46/29450 (epoch 0.078), train_loss = 3.46554813, grad/param norm = 7.5102e-01, time/batch = 0.7256s	
47/29450 (epoch 0.080), train_loss = 3.54634218, grad/param norm = 7.5061e-01, time/batch = 0.7060s	
48/29450 (epoch 0.081), train_loss = 3.47249885, grad/param norm = 6.1891e-01, time/batch = 0.7013s	
49/29450 (epoch 0.083), train_loss = 3.51979885, grad/param norm = 6.0327e-01, time/batch = 0.6948s	
50/29450 (epoch 0.085), train_loss = 3.50327593, grad/param norm = 5.6379e-01, time/batch = 0.6950s	
51/29450 (epoch 0.087), train_loss = 3.39794732, grad/param norm = 4.6097e-01, time/batch = 0.7042s	
52/29450 (epoch 0.088), train_loss = 3.46173801, grad/param norm = 5.4037e-01, time/batch = 0.7053s	
53/29450 (epoch 0.090), train_loss = 3.44627089, grad/param norm = 5.0184e-01, time/batch = 0.7033s	
54/29450 (epoch 0.092), train_loss = 3.83053853, grad/param norm = 7.9460e-01, time/batch = 0.7000s	
55/29450 (epoch 0.093), train_loss = 3.58391550, grad/param norm = 5.4438e-01, time/batch = 0.7162s	
56/29450 (epoch 0.095), train_loss = 3.31925196, grad/param norm = 7.4666e-01, time/batch = 0.7217s	
57/29450 (epoch 0.097), train_loss = 3.35733668, grad/param norm = 4.6940e-01, time/batch = 0.7009s	
58/29450 (epoch 0.098), train_loss = 3.26624065, grad/param norm = 7.8825e-01, time/batch = 0.7000s	
59/29450 (epoch 0.100), train_loss = 3.57254175, grad/param norm = 8.0765e-01, time/batch = 0.7006s	
60/29450 (epoch 0.102), train_loss = 3.75276998, grad/param norm = 8.0635e-01, time/batch = 0.7022s	
61/29450 (epoch 0.104), train_loss = 3.41756479, grad/param norm = 5.8321e-01, time/batch = 0.7039s	
62/29450 (epoch 0.105), train_loss = 3.36795304, grad/param norm = 5.5769e-01, time/batch = 0.7063s	
63/29450 (epoch 0.107), train_loss = 3.29272972, grad/param norm = 6.1559e-01, time/batch = 0.6999s	
64/29450 (epoch 0.109), train_loss = 3.31347979, grad/param norm = 6.5125e-01, time/batch = 0.6964s	
65/29450 (epoch 0.110), train_loss = 3.56875977, grad/param norm = 7.4063e-01, time/batch = 0.7151s	
66/29450 (epoch 0.112), train_loss = 3.32221957, grad/param norm = 6.5222e-01, time/batch = 0.7168s	
67/29450 (epoch 0.114), train_loss = 3.38298460, grad/param norm = 6.4186e-01, time/batch = 0.6960s	
68/29450 (epoch 0.115), train_loss = 3.49712409, grad/param norm = 5.3861e-01, time/batch = 0.6971s	
69/29450 (epoch 0.117), train_loss = 3.33816467, grad/param norm = 4.8538e-01, time/batch = 0.7001s	
70/29450 (epoch 0.119), train_loss = 3.44198790, grad/param norm = 6.8724e-01, time/batch = 0.7031s	
71/29450 (epoch 0.121), train_loss = 3.42440191, grad/param norm = 7.0813e-01, time/batch = 0.7213s	
72/29450 (epoch 0.122), train_loss = 3.34230767, grad/param norm = 7.5539e-01, time/batch = 0.7320s	
73/29450 (epoch 0.124), train_loss = 3.44442397, grad/param norm = 5.8226e-01, time/batch = 0.7190s	
74/29450 (epoch 0.126), train_loss = 3.42598857, grad/param norm = 5.4895e-01, time/batch = 0.7071s	
75/29450 (epoch 0.127), train_loss = 3.34946771, grad/param norm = 5.5658e-01, time/batch = 0.6997s	
76/29450 (epoch 0.129), train_loss = 3.38023165, grad/param norm = 5.0282e-01, time/batch = 0.7057s	
77/29450 (epoch 0.131), train_loss = 3.38419101, grad/param norm = 5.8921e-01, time/batch = 0.7021s	
78/29450 (epoch 0.132), train_loss = 3.25109631, grad/param norm = 5.6048e-01, time/batch = 0.7034s	
79/29450 (epoch 0.134), train_loss = 3.53244263, grad/param norm = 5.8347e-01, time/batch = 0.7172s	
80/29450 (epoch 0.136), train_loss = 3.33492180, grad/param norm = 4.9863e-01, time/batch = 0.7080s	
81/29450 (epoch 0.138), train_loss = 3.54303505, grad/param norm = 5.3534e-01, time/batch = 0.7068s	
82/29450 (epoch 0.139), train_loss = 3.37786023, grad/param norm = 5.9069e-01, time/batch = 0.7054s	
83/29450 (epoch 0.141), train_loss = 3.42673823, grad/param norm = 7.0778e-01, time/batch = 0.7076s	
84/29450 (epoch 0.143), train_loss = 3.38932690, grad/param norm = 7.6765e-01, time/batch = 0.7037s	
85/29450 (epoch 0.144), train_loss = 3.32393617, grad/param norm = 7.3060e-01, time/batch = 0.7076s	
86/29450 (epoch 0.146), train_loss = 3.38794423, grad/param norm = 6.5459e-01, time/batch = 0.6976s	
87/29450 (epoch 0.148), train_loss = 3.48924209, grad/param norm = 5.2845e-01, time/batch = 0.7056s	
88/29450 (epoch 0.149), train_loss = 3.43329987, grad/param norm = 6.0562e-01, time/batch = 0.7035s	
89/29450 (epoch 0.151), train_loss = 3.45680300, grad/param norm = 5.1617e-01, time/batch = 0.7006s	
90/29450 (epoch 0.153), train_loss = 3.44765283, grad/param norm = 6.1996e-01, time/batch = 0.7003s	
91/29450 (epoch 0.154), train_loss = 3.36578552, grad/param norm = 5.1519e-01, time/batch = 0.7018s	
92/29450 (epoch 0.156), train_loss = 3.44629822, grad/param norm = 5.9207e-01, time/batch = 0.6996s	
93/29450 (epoch 0.158), train_loss = 3.44720443, grad/param norm = 3.9971e-01, time/batch = 0.6941s	
94/29450 (epoch 0.160), train_loss = 3.55625932, grad/param norm = 5.1126e-01, time/batch = 0.7013s	
95/29450 (epoch 0.161), train_loss = 3.46667694, grad/param norm = 6.0041e-01, time/batch = 0.7258s	
96/29450 (epoch 0.163), train_loss = 3.46340820, grad/param norm = 5.9332e-01, time/batch = 0.7058s	
97/29450 (epoch 0.165), train_loss = 3.41363906, grad/param norm = 4.4800e-01, time/batch = 0.6954s	
98/29450 (epoch 0.166), train_loss = 3.48499302, grad/param norm = 4.6311e-01, time/batch = 0.6991s	
99/29450 (epoch 0.168), train_loss = 3.86584531, grad/param norm = 6.5113e-01, time/batch = 0.7059s	
100/29450 (epoch 0.170), train_loss = 3.91779130, grad/param norm = 4.7635e-01, time/batch = 0.7060s	
101/29450 (epoch 0.171), train_loss = 3.80295834, grad/param norm = 6.9695e-01, time/batch = 0.7012s	
102/29450 (epoch 0.173), train_loss = 3.60974371, grad/param norm = 6.6624e-01, time/batch = 0.6993s	
103/29450 (epoch 0.175), train_loss = 3.38757898, grad/param norm = 4.3965e-01, time/batch = 0.6977s	
104/29450 (epoch 0.177), train_loss = 3.57687065, grad/param norm = 5.9550e-01, time/batch = 0.7044s	
105/29450 (epoch 0.178), train_loss = 3.37069884, grad/param norm = 4.7285e-01, time/batch = 0.7262s	
106/29450 (epoch 0.180), train_loss = 3.32588484, grad/param norm = 4.3682e-01, time/batch = 0.7026s	
107/29450 (epoch 0.182), train_loss = 3.36802049, grad/param norm = 3.8349e-01, time/batch = 0.6952s	
108/29450 (epoch 0.183), train_loss = 3.39499266, grad/param norm = 5.3511e-01, time/batch = 0.6986s	
109/29450 (epoch 0.185), train_loss = 3.38060288, grad/param norm = 4.6425e-01, time/batch = 0.6988s	
110/29450 (epoch 0.187), train_loss = 3.32775436, grad/param norm = 4.5474e-01, time/batch = 0.6930s	
111/29450 (epoch 0.188), train_loss = 3.49952559, grad/param norm = 4.1780e-01, time/batch = 0.6994s	
112/29450 (epoch 0.190), train_loss = 3.37482031, grad/param norm = 4.8949e-01, time/batch = 0.7046s	
113/29450 (epoch 0.192), train_loss = 3.49797716, grad/param norm = 4.4851e-01, time/batch = 0.6993s	
114/29450 (epoch 0.194), train_loss = 3.43331507, grad/param norm = 4.4200e-01, time/batch = 0.7175s	
115/29450 (epoch 0.195), train_loss = 3.38334483, grad/param norm = 4.7799e-01, time/batch = 0.7289s	
116/29450 (epoch 0.197), train_loss = 3.49632012, grad/param norm = 4.9137e-01, time/batch = 0.7107s	
117/29450 (epoch 0.199), train_loss = 3.38399633, grad/param norm = 5.2559e-01, time/batch = 0.7022s	
118/29450 (epoch 0.200), train_loss = 3.53464715, grad/param norm = 6.1487e-01, time/batch = 0.7028s	
119/29450 (epoch 0.202), train_loss = 3.44603944, grad/param norm = 6.5252e-01, time/batch = 0.7243s	
120/29450 (epoch 0.204), train_loss = 3.36004922, grad/param norm = 5.6284e-01, time/batch = 0.7069s	
121/29450 (epoch 0.205), train_loss = 3.36410967, grad/param norm = 3.9653e-01, time/batch = 0.7106s	
122/29450 (epoch 0.207), train_loss = 3.33386542, grad/param norm = 4.6883e-01, time/batch = 0.7012s	
123/29450 (epoch 0.209), train_loss = 3.42054878, grad/param norm = 4.7981e-01, time/batch = 0.6999s	
124/29450 (epoch 0.211), train_loss = 3.53955649, grad/param norm = 5.9138e-01, time/batch = 0.7001s	
125/29450 (epoch 0.212), train_loss = 3.38797210, grad/param norm = 5.3967e-01, time/batch = 0.6991s	
126/29450 (epoch 0.214), train_loss = 3.37691991, grad/param norm = 6.3545e-01, time/batch = 0.7040s	
127/29450 (epoch 0.216), train_loss = 3.44323820, grad/param norm = 4.4502e-01, time/batch = 0.7071s	
128/29450 (epoch 0.217), train_loss = 3.38536208, grad/param norm = 6.2542e-01, time/batch = 0.7029s	
129/29450 (epoch 0.219), train_loss = 3.25952143, grad/param norm = 6.6708e-01, time/batch = 0.6984s	
130/29450 (epoch 0.221), train_loss = 3.32537520, grad/param norm = 4.9695e-01, time/batch = 0.7041s	
131/29450 (epoch 0.222), train_loss = 3.33499218, grad/param norm = 5.0850e-01, time/batch = 0.7072s	
132/29450 (epoch 0.224), train_loss = 3.21092362, grad/param norm = 6.1556e-01, time/batch = 0.7007s	
133/29450 (epoch 0.226), train_loss = 3.64593863, grad/param norm = 7.9810e-01, time/batch = 0.7078s	
134/29450 (epoch 0.228), train_loss = 3.41965698, grad/param norm = 7.0996e-01, time/batch = 0.7183s	
135/29450 (epoch 0.229), train_loss = 3.27662469, grad/param norm = 4.1189e-01, time/batch = 0.7214s	
136/29450 (epoch 0.231), train_loss = 3.33379423, grad/param norm = 3.7664e-01, time/batch = 0.6955s	
137/29450 (epoch 0.233), train_loss = 3.25273548, grad/param norm = 5.6012e-01, time/batch = 0.6987s	
138/29450 (epoch 0.234), train_loss = 3.10120799, grad/param norm = 4.3363e-01, time/batch = 0.6975s	
139/29450 (epoch 0.236), train_loss = 3.28248560, grad/param norm = 6.0187e-01, time/batch = 0.6946s	
140/29450 (epoch 0.238), train_loss = 3.35724665, grad/param norm = 6.9363e-01, time/batch = 0.6999s	
141/29450 (epoch 0.239), train_loss = 3.24846356, grad/param norm = 9.0799e-01, time/batch = 0.7051s	
142/29450 (epoch 0.241), train_loss = 3.18795097, grad/param norm = 6.1146e-01, time/batch = 0.6989s	
143/29450 (epoch 0.243), train_loss = 3.32468702, grad/param norm = 6.8006e-01, time/batch = 0.6995s	
144/29450 (epoch 0.244), train_loss = 3.34605958, grad/param norm = 6.8492e-01, time/batch = 0.7041s	
145/29450 (epoch 0.246), train_loss = 3.26499460, grad/param norm = 4.7563e-01, time/batch = 0.7066s	
146/29450 (epoch 0.248), train_loss = 3.31324821, grad/param norm = 4.0285e-01, time/batch = 0.7046s	
147/29450 (epoch 0.250), train_loss = 3.20189219, grad/param norm = 4.8262e-01, time/batch = 0.7035s	
148/29450 (epoch 0.251), train_loss = 3.28580274, grad/param norm = 5.5527e-01, time/batch = 0.7014s	
149/29450 (epoch 0.253), train_loss = 3.16526498, grad/param norm = 4.5722e-01, time/batch = 0.7268s	
150/29450 (epoch 0.255), train_loss = 3.16885280, grad/param norm = 5.0861e-01, time/batch = 0.7228s	
151/29450 (epoch 0.256), train_loss = 3.14846707, grad/param norm = 6.9892e-01, time/batch = 0.7092s	
152/29450 (epoch 0.258), train_loss = 3.22657141, grad/param norm = 6.7403e-01, time/batch = 0.6994s	
153/29450 (epoch 0.260), train_loss = 3.18969854, grad/param norm = 8.1650e-01, time/batch = 0.7008s	
154/29450 (epoch 0.261), train_loss = 3.26972372, grad/param norm = 7.6086e-01, time/batch = 0.7200s	
155/29450 (epoch 0.263), train_loss = 3.26173042, grad/param norm = 7.9149e-01, time/batch = 0.7262s	
156/29450 (epoch 0.265), train_loss = 3.19853696, grad/param norm = 5.1182e-01, time/batch = 0.7243s	
157/29450 (epoch 0.267), train_loss = 3.26182512, grad/param norm = 3.6060e-01, time/batch = 0.7289s	
158/29450 (epoch 0.268), train_loss = 3.22216920, grad/param norm = 3.9141e-01, time/batch = 0.7215s	
159/29450 (epoch 0.270), train_loss = 3.28670469, grad/param norm = 8.5171e-01, time/batch = 0.7444s	
160/29450 (epoch 0.272), train_loss = 3.26536359, grad/param norm = 1.0277e+00, time/batch = 0.7260s	
161/29450 (epoch 0.273), train_loss = 3.38486368, grad/param norm = 5.7841e-01, time/batch = 0.7195s	
162/29450 (epoch 0.275), train_loss = 3.71406055, grad/param norm = 7.9219e-01, time/batch = 0.7047s	
163/29450 (epoch 0.277), train_loss = 3.49299606, grad/param norm = 1.0281e+00, time/batch = 0.7049s	
164/29450 (epoch 0.278), train_loss = 3.53428269, grad/param norm = 6.1332e-01, time/batch = 0.7275s	
165/29450 (epoch 0.280), train_loss = 3.30740167, grad/param norm = 3.6774e-01, time/batch = 0.7088s	
166/29450 (epoch 0.282), train_loss = 3.23423032, grad/param norm = 3.6077e-01, time/batch = 0.6984s	
167/29450 (epoch 0.284), train_loss = 3.17480146, grad/param norm = 3.7851e-01, time/batch = 0.6970s	
168/29450 (epoch 0.285), train_loss = 3.13176712, grad/param norm = 3.8484e-01, time/batch = 0.6973s	
169/29450 (epoch 0.287), train_loss = 3.26944951, grad/param norm = 5.0793e-01, time/batch = 0.6955s	
170/29450 (epoch 0.289), train_loss = 3.20642147, grad/param norm = 8.0953e-01, time/batch = 0.6969s	
171/29450 (epoch 0.290), train_loss = 3.24078581, grad/param norm = 7.0053e-01, time/batch = 0.6984s	
172/29450 (epoch 0.292), train_loss = 3.16314563, grad/param norm = 5.9559e-01, time/batch = 0.6993s	
173/29450 (epoch 0.294), train_loss = 3.28256977, grad/param norm = 7.2096e-01, time/batch = 0.7057s	
174/29450 (epoch 0.295), train_loss = 3.20036090, grad/param norm = 7.8588e-01, time/batch = 0.7273s	
175/29450 (epoch 0.297), train_loss = 3.16907958, grad/param norm = 6.1046e-01, time/batch = 0.7086s	
176/29450 (epoch 0.299), train_loss = 3.09122935, grad/param norm = 5.7775e-01, time/batch = 0.7040s	
177/29450 (epoch 0.301), train_loss = 3.08064293, grad/param norm = 6.8815e-01, time/batch = 0.7045s	
178/29450 (epoch 0.302), train_loss = 3.11470291, grad/param norm = 7.0309e-01, time/batch = 0.6957s	
179/29450 (epoch 0.304), train_loss = 3.17263842, grad/param norm = 5.5195e-01, time/batch = 0.7006s	
180/29450 (epoch 0.306), train_loss = 3.07842451, grad/param norm = 5.3345e-01, time/batch = 0.6991s	
181/29450 (epoch 0.307), train_loss = 3.14519726, grad/param norm = 7.3021e-01, time/batch = 0.7024s	
182/29450 (epoch 0.309), train_loss = 3.19206381, grad/param norm = 8.5610e-01, time/batch = 0.7024s	
183/29450 (epoch 0.311), train_loss = 3.09423254, grad/param norm = 6.7266e-01, time/batch = 0.7164s	
184/29450 (epoch 0.312), train_loss = 3.09272446, grad/param norm = 4.1709e-01, time/batch = 0.7297s	
185/29450 (epoch 0.314), train_loss = 3.11672266, grad/param norm = 3.5219e-01, time/batch = 0.6953s	
186/29450 (epoch 0.316), train_loss = 3.07396415, grad/param norm = 4.2735e-01, time/batch = 0.7054s	
187/29450 (epoch 0.317), train_loss = 3.15466664, grad/param norm = 5.3094e-01, time/batch = 0.7052s	
188/29450 (epoch 0.319), train_loss = 2.99158085, grad/param norm = 7.1093e-01, time/batch = 0.7007s	
189/29450 (epoch 0.321), train_loss = 3.18305650, grad/param norm = 6.5158e-01, time/batch = 0.7140s	
190/29450 (epoch 0.323), train_loss = 3.14185665, grad/param norm = 5.2741e-01, time/batch = 0.7204s	
191/29450 (epoch 0.324), train_loss = 3.05617355, grad/param norm = 7.6219e-01, time/batch = 0.7268s	
192/29450 (epoch 0.326), train_loss = 2.87580006, grad/param norm = 8.2373e-01, time/batch = 0.7184s	
193/29450 (epoch 0.328), train_loss = 3.08378535, grad/param norm = 6.7585e-01, time/batch = 0.7059s	
194/29450 (epoch 0.329), train_loss = 2.98620292, grad/param norm = 4.3303e-01, time/batch = 0.7018s	
195/29450 (epoch 0.331), train_loss = 2.87657174, grad/param norm = 3.9495e-01, time/batch = 0.7059s	
196/29450 (epoch 0.333), train_loss = 3.11167040, grad/param norm = 6.4991e-01, time/batch = 0.7134s	
197/29450 (epoch 0.334), train_loss = 2.98307717, grad/param norm = 7.9776e-01, time/batch = 0.6981s	
198/29450 (epoch 0.336), train_loss = 3.08911706, grad/param norm = 1.4145e+00, time/batch = 0.6990s	
199/29450 (epoch 0.338), train_loss = 3.11639321, grad/param norm = 1.5059e+00, time/batch = 0.6980s	
200/29450 (epoch 0.340), train_loss = 3.05384724, grad/param norm = 9.2068e-01, time/batch = 0.7017s	
201/29450 (epoch 0.341), train_loss = 3.08608494, grad/param norm = 7.2390e-01, time/batch = 0.7042s	
202/29450 (epoch 0.343), train_loss = 3.00965491, grad/param norm = 4.6411e-01, time/batch = 0.7033s	
203/29450 (epoch 0.345), train_loss = 3.25171289, grad/param norm = 3.5696e-01, time/batch = 0.7196s	
204/29450 (epoch 0.346), train_loss = 3.00691115, grad/param norm = 5.6301e-01, time/batch = 0.7234s	
205/29450 (epoch 0.348), train_loss = 3.13091604, grad/param norm = 7.5828e-01, time/batch = 0.6994s	
206/29450 (epoch 0.350), train_loss = 3.01495718, grad/param norm = 4.8381e-01, time/batch = 0.7001s	
207/29450 (epoch 0.351), train_loss = 3.02196819, grad/param norm = 4.5396e-01, time/batch = 0.7008s	
208/29450 (epoch 0.353), train_loss = 2.84050700, grad/param norm = 7.6836e-01, time/batch = 0.6990s	
209/29450 (epoch 0.355), train_loss = 3.03405527, grad/param norm = 8.6757e-01, time/batch = 0.6985s	
210/29450 (epoch 0.357), train_loss = 2.85875742, grad/param norm = 9.1689e-01, time/batch = 0.7008s	
211/29450 (epoch 0.358), train_loss = 2.84889110, grad/param norm = 7.1760e-01, time/batch = 0.6989s	
212/29450 (epoch 0.360), train_loss = 2.94004126, grad/param norm = 7.7260e-01, time/batch = 0.7019s	
213/29450 (epoch 0.362), train_loss = 2.88569381, grad/param norm = 4.4517e-01, time/batch = 0.7005s	
214/29450 (epoch 0.363), train_loss = 3.07650948, grad/param norm = 5.2580e-01, time/batch = 0.6952s	
215/29450 (epoch 0.365), train_loss = 2.92461609, grad/param norm = 5.3641e-01, time/batch = 0.7066s	
216/29450 (epoch 0.367), train_loss = 2.95663150, grad/param norm = 6.9032e-01, time/batch = 0.7033s	
217/29450 (epoch 0.368), train_loss = 3.16385458, grad/param norm = 1.0051e+00, time/batch = 0.7038s	
218/29450 (epoch 0.370), train_loss = 2.94498955, grad/param norm = 9.8374e-01, time/batch = 0.6995s	
219/29450 (epoch 0.372), train_loss = 3.52869147, grad/param norm = 9.4143e-01, time/batch = 0.6981s	
220/29450 (epoch 0.374), train_loss = 3.39675391, grad/param norm = 5.2494e-01, time/batch = 0.6987s	
221/29450 (epoch 0.375), train_loss = 3.37543115, grad/param norm = 7.3758e-01, time/batch = 0.7032s	
222/29450 (epoch 0.377), train_loss = 5.09249164, grad/param norm = 3.0960e+00, time/batch = 0.7020s	
223/29450 (epoch 0.379), train_loss = 3.70249979, grad/param norm = 5.9441e+00, time/batch = 0.6975s	
224/29450 (epoch 0.380), train_loss = 3.08589166, grad/param norm = 1.5229e+00, time/batch = 0.7011s	
225/29450 (epoch 0.382), train_loss = 3.05992444, grad/param norm = 1.0488e+00, time/batch = 0.6989s	
226/29450 (epoch 0.384), train_loss = 3.05065231, grad/param norm = 5.5885e-01, time/batch = 0.7037s	
227/29450 (epoch 0.385), train_loss = 3.11396604, grad/param norm = 5.5822e-01, time/batch = 0.6981s	
228/29450 (epoch 0.387), train_loss = 3.04137625, grad/param norm = 2.8851e-01, time/batch = 0.6977s	
229/29450 (epoch 0.389), train_loss = 3.09088882, grad/param norm = 3.3670e-01, time/batch = 0.6975s	
230/29450 (epoch 0.390), train_loss = 2.88390913, grad/param norm = 5.3516e-01, time/batch = 0.7084s	
231/29450 (epoch 0.392), train_loss = 3.07464120, grad/param norm = 5.2733e-01, time/batch = 0.7171s	
232/29450 (epoch 0.394), train_loss = 2.97279624, grad/param norm = 3.7244e-01, time/batch = 0.7020s	
233/29450 (epoch 0.396), train_loss = 2.91470525, grad/param norm = 5.1500e-01, time/batch = 0.7090s	
234/29450 (epoch 0.397), train_loss = 2.88801117, grad/param norm = 6.4909e-01, time/batch = 0.6984s	
235/29450 (epoch 0.399), train_loss = 2.83199574, grad/param norm = 7.8762e-01, time/batch = 0.6941s	
236/29450 (epoch 0.401), train_loss = 3.00837058, grad/param norm = 6.0339e-01, time/batch = 0.6974s	
237/29450 (epoch 0.402), train_loss = 2.97952607, grad/param norm = 5.8612e-01, time/batch = 0.7009s	
238/29450 (epoch 0.404), train_loss = 2.89768902, grad/param norm = 5.4088e-01, time/batch = 0.6950s	
239/29450 (epoch 0.406), train_loss = 2.81194198, grad/param norm = 5.4640e-01, time/batch = 0.7009s	
240/29450 (epoch 0.407), train_loss = 2.95948987, grad/param norm = 6.7048e-01, time/batch = 0.7184s	
241/29450 (epoch 0.409), train_loss = 2.90276644, grad/param norm = 6.4843e-01, time/batch = 0.7270s	
242/29450 (epoch 0.411), train_loss = 2.88323127, grad/param norm = 9.9225e-01, time/batch = 0.7291s	
243/29450 (epoch 0.413), train_loss = 3.19047307, grad/param norm = 1.0146e+00, time/batch = 0.7054s	
244/29450 (epoch 0.414), train_loss = 2.86070486, grad/param norm = 7.4320e-01, time/batch = 0.6979s	
245/29450 (epoch 0.416), train_loss = 2.78870599, grad/param norm = 3.4652e-01, time/batch = 0.7164s	
246/29450 (epoch 0.418), train_loss = 3.06234113, grad/param norm = 5.1761e-01, time/batch = 0.7074s	
247/29450 (epoch 0.419), train_loss = 3.36863307, grad/param norm = 7.8619e-01, time/batch = 0.7016s	
248/29450 (epoch 0.421), train_loss = 3.08448209, grad/param norm = 9.6747e-01, time/batch = 0.6997s	
249/29450 (epoch 0.423), train_loss = 3.15849392, grad/param norm = 1.0724e+00, time/batch = 0.7084s	
250/29450 (epoch 0.424), train_loss = 2.93504320, grad/param norm = 5.8510e-01, time/batch = 0.7125s	
251/29450 (epoch 0.426), train_loss = 3.10721161, grad/param norm = 7.6223e-01, time/batch = 0.6991s	
252/29450 (epoch 0.428), train_loss = 3.02254999, grad/param norm = 9.6429e-01, time/batch = 0.6997s	
253/29450 (epoch 0.430), train_loss = 3.19518711, grad/param norm = 8.8875e-01, time/batch = 0.7018s	
254/29450 (epoch 0.431), train_loss = 3.03524217, grad/param norm = 7.1813e-01, time/batch = 0.7039s	
255/29450 (epoch 0.433), train_loss = 3.07895178, grad/param norm = 6.4998e-01, time/batch = 0.6977s	
256/29450 (epoch 0.435), train_loss = 2.80074758, grad/param norm = 6.4695e-01, time/batch = 0.6990s	
257/29450 (epoch 0.436), train_loss = 2.99474110, grad/param norm = 8.8485e-01, time/batch = 0.7009s	
258/29450 (epoch 0.438), train_loss = 2.84685787, grad/param norm = 1.0346e+00, time/batch = 0.7046s	
259/29450 (epoch 0.440), train_loss = 2.98866830, grad/param norm = 7.9520e-01, time/batch = 0.7036s	
260/29450 (epoch 0.441), train_loss = 2.95858071, grad/param norm = 6.7136e-01, time/batch = 0.7003s	
261/29450 (epoch 0.443), train_loss = 2.84322760, grad/param norm = 7.7199e-01, time/batch = 0.6987s	
262/29450 (epoch 0.445), train_loss = 2.91169315, grad/param norm = 8.8520e-01, time/batch = 0.6971s	
263/29450 (epoch 0.447), train_loss = 3.01718595, grad/param norm = 8.3923e-01, time/batch = 0.6988s	
264/29450 (epoch 0.448), train_loss = 2.85462463, grad/param norm = 5.9612e-01, time/batch = 0.6984s	
265/29450 (epoch 0.450), train_loss = 2.91321955, grad/param norm = 3.6003e-01, time/batch = 0.6945s	
266/29450 (epoch 0.452), train_loss = 2.84225931, grad/param norm = 5.1760e-01, time/batch = 0.6979s	
267/29450 (epoch 0.453), train_loss = 2.87608280, grad/param norm = 7.2507e-01, time/batch = 0.7020s	
268/29450 (epoch 0.455), train_loss = 2.96190747, grad/param norm = 6.3665e-01, time/batch = 0.7029s	
269/29450 (epoch 0.457), train_loss = 2.92351596, grad/param norm = 6.8035e-01, time/batch = 0.7004s	
270/29450 (epoch 0.458), train_loss = 3.11801027, grad/param norm = 7.2619e-01, time/batch = 0.6951s	
271/29450 (epoch 0.460), train_loss = 2.96379678, grad/param norm = 6.9157e-01, time/batch = 0.6990s	
272/29450 (epoch 0.462), train_loss = 2.80196354, grad/param norm = 5.3946e-01, time/batch = 0.6996s	
273/29450 (epoch 0.463), train_loss = 2.89895180, grad/param norm = 5.4002e-01, time/batch = 0.7053s	
274/29450 (epoch 0.465), train_loss = 2.70168040, grad/param norm = 7.4201e-01, time/batch = 0.7258s	
275/29450 (epoch 0.467), train_loss = 2.83358493, grad/param norm = 6.7735e-01, time/batch = 0.6978s	
276/29450 (epoch 0.469), train_loss = 2.94275323, grad/param norm = 4.6226e-01, time/batch = 0.7070s	
277/29450 (epoch 0.470), train_loss = 2.64722326, grad/param norm = 4.1129e-01, time/batch = 0.7305s	
278/29450 (epoch 0.472), train_loss = 3.00201580, grad/param norm = 5.6960e-01, time/batch = 0.7143s	
279/29450 (epoch 0.474), train_loss = 2.91916381, grad/param norm = 6.0079e-01, time/batch = 0.6995s	
280/29450 (epoch 0.475), train_loss = 2.85965429, grad/param norm = 9.6212e-01, time/batch = 0.6997s	
281/29450 (epoch 0.477), train_loss = 2.94463874, grad/param norm = 1.3486e+00, time/batch = 0.7267s	
282/29450 (epoch 0.479), train_loss = 3.00336437, grad/param norm = 1.3548e+00, time/batch = 0.7026s	
283/29450 (epoch 0.480), train_loss = 3.07714615, grad/param norm = 7.9415e-01, time/batch = 0.7056s	
284/29450 (epoch 0.482), train_loss = 3.02540844, grad/param norm = 1.1008e+00, time/batch = 0.7007s	
285/29450 (epoch 0.484), train_loss = 3.09527728, grad/param norm = 1.8103e+00, time/batch = 0.7013s	
286/29450 (epoch 0.486), train_loss = 3.64416218, grad/param norm = 3.8363e+00, time/batch = 0.7024s	
287/29450 (epoch 0.487), train_loss = 2.82982538, grad/param norm = 4.4566e-01, time/batch = 0.7012s	
288/29450 (epoch 0.489), train_loss = 2.85067252, grad/param norm = 6.6557e-01, time/batch = 0.7061s	
289/29450 (epoch 0.491), train_loss = 2.86025693, grad/param norm = 5.3079e-01, time/batch = 0.6997s	
290/29450 (epoch 0.492), train_loss = 2.81780294, grad/param norm = 4.6907e-01, time/batch = 0.7024s	
291/29450 (epoch 0.494), train_loss = 2.97799443, grad/param norm = 4.8700e-01, time/batch = 0.6994s	
292/29450 (epoch 0.496), train_loss = 2.92169327, grad/param norm = 3.9964e-01, time/batch = 0.6999s	
293/29450 (epoch 0.497), train_loss = 2.78526693, grad/param norm = 3.4680e-01, time/batch = 0.7012s	
294/29450 (epoch 0.499), train_loss = 2.80001695, grad/param norm = 2.7991e-01, time/batch = 0.7032s	
295/29450 (epoch 0.501), train_loss = 2.91333773, grad/param norm = 3.6832e-01, time/batch = 0.7022s	
296/29450 (epoch 0.503), train_loss = 2.85054983, grad/param norm = 5.7247e-01, time/batch = 0.7030s	
297/29450 (epoch 0.504), train_loss = 2.92258450, grad/param norm = 7.5523e-01, time/batch = 0.7012s	
298/29450 (epoch 0.506), train_loss = 2.95541727, grad/param norm = 7.3464e-01, time/batch = 0.7012s	
299/29450 (epoch 0.508), train_loss = 2.92737776, grad/param norm = 4.8221e-01, time/batch = 0.7034s	
300/29450 (epoch 0.509), train_loss = 2.82208882, grad/param norm = 2.3711e-01, time/batch = 0.7009s	
301/29450 (epoch 0.511), train_loss = 3.05196660, grad/param norm = 3.2746e-01, time/batch = 0.7137s	
302/29450 (epoch 0.513), train_loss = 2.88045184, grad/param norm = 4.4276e-01, time/batch = 0.7017s	
303/29450 (epoch 0.514), train_loss = 2.82582016, grad/param norm = 6.3254e-01, time/batch = 0.6986s	
304/29450 (epoch 0.516), train_loss = 3.14529588, grad/param norm = 7.9214e-01, time/batch = 0.6958s	
305/29450 (epoch 0.518), train_loss = 3.24468830, grad/param norm = 8.7638e-01, time/batch = 0.7004s	
306/29450 (epoch 0.520), train_loss = 2.83647098, grad/param norm = 6.7874e-01, time/batch = 0.7002s	
307/29450 (epoch 0.521), train_loss = 3.08211314, grad/param norm = 4.7732e-01, time/batch = 0.6984s	
308/29450 (epoch 0.523), train_loss = 2.98914171, grad/param norm = 4.9772e-01, time/batch = 0.6963s	
309/29450 (epoch 0.525), train_loss = 2.93900692, grad/param norm = 8.3008e-01, time/batch = 0.7011s	
310/29450 (epoch 0.526), train_loss = 2.89248489, grad/param norm = 6.3315e-01, time/batch = 0.7120s	
311/29450 (epoch 0.528), train_loss = 2.95688431, grad/param norm = 6.4640e-01, time/batch = 0.7327s	
312/29450 (epoch 0.530), train_loss = 2.99172371, grad/param norm = 7.7222e-01, time/batch = 0.7301s	
313/29450 (epoch 0.531), train_loss = 2.76051923, grad/param norm = 7.4885e-01, time/batch = 0.7269s	
314/29450 (epoch 0.533), train_loss = 2.90636370, grad/param norm = 6.5970e-01, time/batch = 0.7221s	
315/29450 (epoch 0.535), train_loss = 3.39877214, grad/param norm = 1.1240e+00, time/batch = 0.7202s	
316/29450 (epoch 0.537), train_loss = 3.24658139, grad/param norm = 2.2434e+00, time/batch = 0.6998s	
317/29450 (epoch 0.538), train_loss = 3.36940504, grad/param norm = 1.6073e+00, time/batch = 0.6983s	
318/29450 (epoch 0.540), train_loss = 3.20605790, grad/param norm = 4.1980e-01, time/batch = 0.6993s	
319/29450 (epoch 0.542), train_loss = 3.05020883, grad/param norm = 3.5436e-01, time/batch = 0.6960s	
320/29450 (epoch 0.543), train_loss = 2.89116672, grad/param norm = 3.4626e-01, time/batch = 0.6947s	
321/29450 (epoch 0.545), train_loss = 2.77305055, grad/param norm = 3.1788e-01, time/batch = 0.7006s	
322/29450 (epoch 0.547), train_loss = 2.90862811, grad/param norm = 3.2208e-01, time/batch = 0.7187s	
323/29450 (epoch 0.548), train_loss = 2.82927919, grad/param norm = 6.0567e-01, time/batch = 0.7185s	
324/29450 (epoch 0.550), train_loss = 2.82781297, grad/param norm = 7.3849e-01, time/batch = 0.7190s	
325/29450 (epoch 0.552), train_loss = 2.78739606, grad/param norm = 7.3860e-01, time/batch = 0.7304s	
326/29450 (epoch 0.553), train_loss = 2.89586837, grad/param norm = 6.4570e-01, time/batch = 0.7352s	
327/29450 (epoch 0.555), train_loss = 2.98809385, grad/param norm = 4.1620e-01, time/batch = 0.7312s	
328/29450 (epoch 0.557), train_loss = 2.91247869, grad/param norm = 3.4600e-01, time/batch = 0.7406s	
329/29450 (epoch 0.559), train_loss = 2.83594968, grad/param norm = 4.9609e-01, time/batch = 0.7543s	
330/29450 (epoch 0.560), train_loss = 3.01921200, grad/param norm = 7.3669e-01, time/batch = 0.7486s	
331/29450 (epoch 0.562), train_loss = 2.78868521, grad/param norm = 5.1105e-01, time/batch = 0.7327s	
332/29450 (epoch 0.564), train_loss = 2.90349784, grad/param norm = 4.1647e-01, time/batch = 0.7243s	
333/29450 (epoch 0.565), train_loss = 3.04250347, grad/param norm = 7.2687e-01, time/batch = 0.7107s	
334/29450 (epoch 0.567), train_loss = 2.87591398, grad/param norm = 8.8501e-01, time/batch = 0.7164s	
335/29450 (epoch 0.569), train_loss = 2.78103513, grad/param norm = 1.0894e+00, time/batch = 0.7132s	
336/29450 (epoch 0.570), train_loss = 3.06692161, grad/param norm = 9.5540e-01, time/batch = 0.7151s	
337/29450 (epoch 0.572), train_loss = 2.84934051, grad/param norm = 6.7636e-01, time/batch = 0.7158s	
338/29450 (epoch 0.574), train_loss = 2.83121965, grad/param norm = 4.9152e-01, time/batch = 0.7135s	
339/29450 (epoch 0.576), train_loss = 2.78189867, grad/param norm = 3.9330e-01, time/batch = 0.7153s	
340/29450 (epoch 0.577), train_loss = 2.98595819, grad/param norm = 4.1812e-01, time/batch = 0.7169s	
341/29450 (epoch 0.579), train_loss = 2.73108485, grad/param norm = 4.4070e-01, time/batch = 0.7276s	
342/29450 (epoch 0.581), train_loss = 2.99763956, grad/param norm = 5.2693e-01, time/batch = 0.7115s	
343/29450 (epoch 0.582), train_loss = 2.76955092, grad/param norm = 5.1252e-01, time/batch = 0.6998s	
344/29450 (epoch 0.584), train_loss = 2.78141384, grad/param norm = 5.9408e-01, time/batch = 0.7379s	
345/29450 (epoch 0.586), train_loss = 3.04488430, grad/param norm = 8.2744e-01, time/batch = 0.7224s	
346/29450 (epoch 0.587), train_loss = 3.12912921, grad/param norm = 8.4796e-01, time/batch = 0.7044s	
347/29450 (epoch 0.589), train_loss = 2.88968574, grad/param norm = 6.4094e-01, time/batch = 0.7123s	
348/29450 (epoch 0.591), train_loss = 2.75541959, grad/param norm = 4.4220e-01, time/batch = 0.7059s	
349/29450 (epoch 0.593), train_loss = 2.80794614, grad/param norm = 4.8377e-01, time/batch = 0.7031s	
350/29450 (epoch 0.594), train_loss = 2.70200501, grad/param norm = 4.6987e-01, time/batch = 0.7014s	
351/29450 (epoch 0.596), train_loss = 2.75355249, grad/param norm = 5.7365e-01, time/batch = 0.7148s	
352/29450 (epoch 0.598), train_loss = 2.78558634, grad/param norm = 6.7679e-01, time/batch = 0.7036s	
353/29450 (epoch 0.599), train_loss = 2.82127129, grad/param norm = 6.2540e-01, time/batch = 0.6964s	
354/29450 (epoch 0.601), train_loss = 2.83480177, grad/param norm = 3.6493e-01, time/batch = 0.6971s	
355/29450 (epoch 0.603), train_loss = 2.90883672, grad/param norm = 2.9275e-01, time/batch = 0.7130s	
356/29450 (epoch 0.604), train_loss = 2.84289138, grad/param norm = 2.8945e-01, time/batch = 0.7180s	
357/29450 (epoch 0.606), train_loss = 2.97102696, grad/param norm = 4.6911e-01, time/batch = 0.7012s	
358/29450 (epoch 0.608), train_loss = 2.79366075, grad/param norm = 3.1671e-01, time/batch = 0.6988s	
359/29450 (epoch 0.610), train_loss = 2.85354705, grad/param norm = 2.9725e-01, time/batch = 0.6958s	
360/29450 (epoch 0.611), train_loss = 2.73429280, grad/param norm = 3.9762e-01, time/batch = 0.6985s	
361/29450 (epoch 0.613), train_loss = 2.65958321, grad/param norm = 3.2079e-01, time/batch = 0.7036s	
362/29450 (epoch 0.615), train_loss = 2.69506679, grad/param norm = 3.1621e-01, time/batch = 0.7047s	
363/29450 (epoch 0.616), train_loss = 2.74269706, grad/param norm = 5.2524e-01, time/batch = 0.7008s	
364/29450 (epoch 0.618), train_loss = 2.60941806, grad/param norm = 6.4992e-01, time/batch = 0.7123s	
365/29450 (epoch 0.620), train_loss = 2.99973343, grad/param norm = 1.0000e+00, time/batch = 0.7238s	
366/29450 (epoch 0.621), train_loss = 2.84065216, grad/param norm = 1.0746e+00, time/batch = 0.7013s	
367/29450 (epoch 0.623), train_loss = 2.74196131, grad/param norm = 8.4111e-01, time/batch = 0.6999s	
368/29450 (epoch 0.625), train_loss = 2.77445608, grad/param norm = 9.1968e-01, time/batch = 0.6995s	
369/29450 (epoch 0.626), train_loss = 2.86561394, grad/param norm = 8.2404e-01, time/batch = 0.7034s	
370/29450 (epoch 0.628), train_loss = 2.73436605, grad/param norm = 5.0526e-01, time/batch = 0.7050s	
371/29450 (epoch 0.630), train_loss = 2.73308780, grad/param norm = 5.5790e-01, time/batch = 0.7096s	
372/29450 (epoch 0.632), train_loss = 2.78030293, grad/param norm = 4.1954e-01, time/batch = 0.7075s	
373/29450 (epoch 0.633), train_loss = 2.87194424, grad/param norm = 4.0627e-01, time/batch = 0.7035s	
374/29450 (epoch 0.635), train_loss = 2.56946317, grad/param norm = 4.6620e-01, time/batch = 0.7173s	
375/29450 (epoch 0.637), train_loss = 2.66791643, grad/param norm = 5.0819e-01, time/batch = 0.7270s	
376/29450 (epoch 0.638), train_loss = 2.60637904, grad/param norm = 6.5654e-01, time/batch = 0.7173s	
377/29450 (epoch 0.640), train_loss = 2.91386776, grad/param norm = 8.9510e-01, time/batch = 0.7009s	
378/29450 (epoch 0.642), train_loss = 2.89687905, grad/param norm = 8.9796e-01, time/batch = 0.6988s	
379/29450 (epoch 0.643), train_loss = 2.84056394, grad/param norm = 5.9587e-01, time/batch = 0.7022s	
380/29450 (epoch 0.645), train_loss = 2.84256374, grad/param norm = 4.8412e-01, time/batch = 0.7035s	
381/29450 (epoch 0.647), train_loss = 3.08990626, grad/param norm = 3.5537e-01, time/batch = 0.6998s	
382/29450 (epoch 0.649), train_loss = 3.05935680, grad/param norm = 4.3278e-01, time/batch = 0.6998s	
383/29450 (epoch 0.650), train_loss = 2.89520946, grad/param norm = 6.2726e-01, time/batch = 0.7024s	
384/29450 (epoch 0.652), train_loss = 2.82457407, grad/param norm = 4.7748e-01, time/batch = 0.7010s	
385/29450 (epoch 0.654), train_loss = 2.88389394, grad/param norm = 4.1003e-01, time/batch = 0.7107s	
386/29450 (epoch 0.655), train_loss = 2.78465848, grad/param norm = 4.7652e-01, time/batch = 0.6995s	
387/29450 (epoch 0.657), train_loss = 2.77465041, grad/param norm = 4.9874e-01, time/batch = 0.6995s	
388/29450 (epoch 0.659), train_loss = 2.91774442, grad/param norm = 4.1795e-01, time/batch = 0.7003s	
389/29450 (epoch 0.660), train_loss = 2.68079495, grad/param norm = 4.8107e-01, time/batch = 0.6967s	
390/29450 (epoch 0.662), train_loss = 2.63000700, grad/param norm = 5.3334e-01, time/batch = 0.6999s	
391/29450 (epoch 0.664), train_loss = 2.72318208, grad/param norm = 5.1120e-01, time/batch = 0.7075s	
392/29450 (epoch 0.666), train_loss = 2.78918151, grad/param norm = 4.6603e-01, time/batch = 0.6968s	
393/29450 (epoch 0.667), train_loss = 2.94738652, grad/param norm = 4.8705e-01, time/batch = 0.6981s	
394/29450 (epoch 0.669), train_loss = 2.85884539, grad/param norm = 3.8329e-01, time/batch = 0.6996s	
395/29450 (epoch 0.671), train_loss = 2.57571292, grad/param norm = 3.3205e-01, time/batch = 0.6976s	
396/29450 (epoch 0.672), train_loss = 2.60613021, grad/param norm = 3.6973e-01, time/batch = 0.7015s	
397/29450 (epoch 0.674), train_loss = 2.71574171, grad/param norm = 5.7299e-01, time/batch = 0.6997s	
398/29450 (epoch 0.676), train_loss = 2.76395566, grad/param norm = 8.5524e-01, time/batch = 0.7026s	
399/29450 (epoch 0.677), train_loss = 2.99956701, grad/param norm = 9.7607e-01, time/batch = 0.7025s	
400/29450 (epoch 0.679), train_loss = 2.74210831, grad/param norm = 7.0332e-01, time/batch = 0.7055s	
401/29450 (epoch 0.681), train_loss = 2.95691224, grad/param norm = 4.6528e-01, time/batch = 0.7041s	
402/29450 (epoch 0.683), train_loss = 2.73835636, grad/param norm = 3.6718e-01, time/batch = 0.7053s	
403/29450 (epoch 0.684), train_loss = 2.70083394, grad/param norm = 3.2895e-01, time/batch = 0.7018s	
404/29450 (epoch 0.686), train_loss = 2.80145836, grad/param norm = 4.2439e-01, time/batch = 0.7037s	
405/29450 (epoch 0.688), train_loss = 2.72077860, grad/param norm = 6.2643e-01, time/batch = 0.7022s	
406/29450 (epoch 0.689), train_loss = 2.68387139, grad/param norm = 7.2695e-01, time/batch = 0.7095s	
407/29450 (epoch 0.691), train_loss = 2.65760833, grad/param norm = 6.3138e-01, time/batch = 0.7076s	
408/29450 (epoch 0.693), train_loss = 2.84774587, grad/param norm = 4.4780e-01, time/batch = 0.7044s	
409/29450 (epoch 0.694), train_loss = 2.68208148, grad/param norm = 3.4934e-01, time/batch = 0.7253s	
410/29450 (epoch 0.696), train_loss = 2.93892700, grad/param norm = 5.4824e-01, time/batch = 0.7439s	
411/29450 (epoch 0.698), train_loss = 2.73268784, grad/param norm = 7.8741e-01, time/batch = 0.7462s	
412/29450 (epoch 0.699), train_loss = 2.92522213, grad/param norm = 8.0587e-01, time/batch = 0.7295s	
413/29450 (epoch 0.701), train_loss = 2.61128736, grad/param norm = 4.8233e-01, time/batch = 0.7142s	
414/29450 (epoch 0.703), train_loss = 2.76729492, grad/param norm = 3.7615e-01, time/batch = 0.7321s	
415/29450 (epoch 0.705), train_loss = 2.65004769, grad/param norm = 3.5461e-01, time/batch = 0.7233s	
416/29450 (epoch 0.706), train_loss = 2.65901187, grad/param norm = 4.1796e-01, time/batch = 0.7274s	
417/29450 (epoch 0.708), train_loss = 2.73278347, grad/param norm = 3.8250e-01, time/batch = 0.7103s	
418/29450 (epoch 0.710), train_loss = 2.68410738, grad/param norm = 3.2668e-01, time/batch = 0.6992s	
419/29450 (epoch 0.711), train_loss = 2.71785698, grad/param norm = 2.9695e-01, time/batch = 0.7043s	
420/29450 (epoch 0.713), train_loss = 2.61194300, grad/param norm = 2.8272e-01, time/batch = 0.7042s	
421/29450 (epoch 0.715), train_loss = 2.87564566, grad/param norm = 4.7071e-01, time/batch = 0.7162s	
422/29450 (epoch 0.716), train_loss = 2.64666903, grad/param norm = 6.3609e-01, time/batch = 0.7442s	
423/29450 (epoch 0.718), train_loss = 2.72982607, grad/param norm = 5.4997e-01, time/batch = 0.7013s	
424/29450 (epoch 0.720), train_loss = 2.66000319, grad/param norm = 3.2774e-01, time/batch = 0.7208s	
425/29450 (epoch 0.722), train_loss = 2.64025235, grad/param norm = 5.2324e-01, time/batch = 0.7246s	
426/29450 (epoch 0.723), train_loss = 2.70761706, grad/param norm = 5.0374e-01, time/batch = 0.7121s	
427/29450 (epoch 0.725), train_loss = 2.63924604, grad/param norm = 5.7293e-01, time/batch = 0.7087s	
428/29450 (epoch 0.727), train_loss = 2.73502795, grad/param norm = 8.0137e-01, time/batch = 0.7048s	
429/29450 (epoch 0.728), train_loss = 2.73999749, grad/param norm = 7.2341e-01, time/batch = 0.6977s	
430/29450 (epoch 0.730), train_loss = 2.90592777, grad/param norm = 6.1693e-01, time/batch = 0.6940s	
431/29450 (epoch 0.732), train_loss = 2.91307704, grad/param norm = 1.1516e+00, time/batch = 0.7084s	
432/29450 (epoch 0.733), train_loss = 2.98317237, grad/param norm = 1.3922e+00, time/batch = 0.7206s	
433/29450 (epoch 0.735), train_loss = 2.80100326, grad/param norm = 3.9799e-01, time/batch = 0.7020s	
434/29450 (epoch 0.737), train_loss = 2.74941675, grad/param norm = 3.8189e-01, time/batch = 0.6992s	
435/29450 (epoch 0.739), train_loss = 2.72083271, grad/param norm = 3.5237e-01, time/batch = 0.7058s	
436/29450 (epoch 0.740), train_loss = 2.84479546, grad/param norm = 3.9421e-01, time/batch = 0.7166s	
437/29450 (epoch 0.742), train_loss = 2.72998473, grad/param norm = 5.6159e-01, time/batch = 0.7039s	
438/29450 (epoch 0.744), train_loss = 2.89036655, grad/param norm = 8.3252e-01, time/batch = 0.6957s	
439/29450 (epoch 0.745), train_loss = 2.78124215, grad/param norm = 9.9856e-01, time/batch = 0.7037s	
440/29450 (epoch 0.747), train_loss = 2.68171363, grad/param norm = 5.2802e-01, time/batch = 0.7132s	
441/29450 (epoch 0.749), train_loss = 2.88057301, grad/param norm = 3.1033e-01, time/batch = 0.7047s	
442/29450 (epoch 0.750), train_loss = 2.73146635, grad/param norm = 3.8791e-01, time/batch = 0.6977s	
443/29450 (epoch 0.752), train_loss = 2.79614020, grad/param norm = 3.5918e-01, time/batch = 0.6973s	
444/29450 (epoch 0.754), train_loss = 2.62391353, grad/param norm = 2.4946e-01, time/batch = 0.7000s	
445/29450 (epoch 0.756), train_loss = 2.87232447, grad/param norm = 2.7194e-01, time/batch = 0.6978s	
446/29450 (epoch 0.757), train_loss = 2.85022642, grad/param norm = 3.5558e-01, time/batch = 0.6958s	
447/29450 (epoch 0.759), train_loss = 2.88137310, grad/param norm = 4.7866e-01, time/batch = 0.6983s	
448/29450 (epoch 0.761), train_loss = 2.87705751, grad/param norm = 4.8732e-01, time/batch = 0.7006s	
449/29450 (epoch 0.762), train_loss = 2.77822749, grad/param norm = 4.2375e-01, time/batch = 0.7036s	
450/29450 (epoch 0.764), train_loss = 2.83658601, grad/param norm = 3.7097e-01, time/batch = 0.7183s	
451/29450 (epoch 0.766), train_loss = 2.80570241, grad/param norm = 5.0669e-01, time/batch = 0.7046s	
452/29450 (epoch 0.767), train_loss = 2.78545270, grad/param norm = 7.4157e-01, time/batch = 0.7047s	
453/29450 (epoch 0.769), train_loss = 3.00631967, grad/param norm = 6.8941e-01, time/batch = 0.7205s	
454/29450 (epoch 0.771), train_loss = 2.86028694, grad/param norm = 3.9583e-01, time/batch = 0.7215s	
455/29450 (epoch 0.772), train_loss = 2.66588476, grad/param norm = 2.9035e-01, time/batch = 0.7102s	
456/29450 (epoch 0.774), train_loss = 2.48871807, grad/param norm = 2.7580e-01, time/batch = 0.6995s	
457/29450 (epoch 0.776), train_loss = 2.78298167, grad/param norm = 3.2783e-01, time/batch = 0.7029s	
458/29450 (epoch 0.778), train_loss = 2.77524308, grad/param norm = 3.5929e-01, time/batch = 0.7227s	
459/29450 (epoch 0.779), train_loss = 2.73394543, grad/param norm = 3.4408e-01, time/batch = 0.7036s	
460/29450 (epoch 0.781), train_loss = 2.54587786, grad/param norm = 3.9457e-01, time/batch = 0.7022s	
461/29450 (epoch 0.783), train_loss = 2.57266859, grad/param norm = 4.7949e-01, time/batch = 0.7250s	
462/29450 (epoch 0.784), train_loss = 2.69648748, grad/param norm = 4.7754e-01, time/batch = 0.7273s	
463/29450 (epoch 0.786), train_loss = 2.63532595, grad/param norm = 4.0236e-01, time/batch = 0.7231s	
464/29450 (epoch 0.788), train_loss = 2.91533161, grad/param norm = 5.1897e-01, time/batch = 0.7269s	
465/29450 (epoch 0.789), train_loss = 2.80456748, grad/param norm = 4.5068e-01, time/batch = 0.7303s	
466/29450 (epoch 0.791), train_loss = 2.61324271, grad/param norm = 5.7452e-01, time/batch = 0.7410s	
467/29450 (epoch 0.793), train_loss = 2.84598326, grad/param norm = 7.8309e-01, time/batch = 0.7351s	
468/29450 (epoch 0.795), train_loss = 2.79147401, grad/param norm = 6.9540e-01, time/batch = 0.7317s	
469/29450 (epoch 0.796), train_loss = 2.64016129, grad/param norm = 5.2519e-01, time/batch = 0.7312s	
470/29450 (epoch 0.798), train_loss = 2.67739468, grad/param norm = 4.6014e-01, time/batch = 0.7068s	
471/29450 (epoch 0.800), train_loss = 2.59612002, grad/param norm = 5.3991e-01, time/batch = 0.7049s	
472/29450 (epoch 0.801), train_loss = 2.69409775, grad/param norm = 5.9986e-01, time/batch = 0.7009s	
473/29450 (epoch 0.803), train_loss = 2.70930413, grad/param norm = 5.0992e-01, time/batch = 0.7021s	
474/29450 (epoch 0.805), train_loss = 2.65909859, grad/param norm = 3.0935e-01, time/batch = 0.6990s	
475/29450 (epoch 0.806), train_loss = 2.62386803, grad/param norm = 2.7810e-01, time/batch = 0.7040s	
476/29450 (epoch 0.808), train_loss = 2.85493558, grad/param norm = 4.1607e-01, time/batch = 0.7012s	
477/29450 (epoch 0.810), train_loss = 2.85262314, grad/param norm = 2.9108e-01, time/batch = 0.7070s	
478/29450 (epoch 0.812), train_loss = 2.59485224, grad/param norm = 2.9732e-01, time/batch = 0.7128s	
479/29450 (epoch 0.813), train_loss = 2.71846610, grad/param norm = 3.1495e-01, time/batch = 0.7041s	
480/29450 (epoch 0.815), train_loss = 2.75497200, grad/param norm = 3.0179e-01, time/batch = 0.7016s	
481/29450 (epoch 0.817), train_loss = 2.67485923, grad/param norm = 2.9223e-01, time/batch = 0.7001s	
482/29450 (epoch 0.818), train_loss = 2.52982576, grad/param norm = 2.7797e-01, time/batch = 0.6997s	
483/29450 (epoch 0.820), train_loss = 2.64585993, grad/param norm = 3.9382e-01, time/batch = 0.6999s	
484/29450 (epoch 0.822), train_loss = 2.74132890, grad/param norm = 5.5400e-01, time/batch = 0.6998s	
485/29450 (epoch 0.823), train_loss = 2.71761433, grad/param norm = 5.3566e-01, time/batch = 0.7043s	
486/29450 (epoch 0.825), train_loss = 2.70243816, grad/param norm = 3.6539e-01, time/batch = 0.7006s	
487/29450 (epoch 0.827), train_loss = 2.69667897, grad/param norm = 3.5269e-01, time/batch = 0.7170s	
488/29450 (epoch 0.829), train_loss = 2.64079190, grad/param norm = 4.1639e-01, time/batch = 0.7263s	
489/29450 (epoch 0.830), train_loss = 2.86139444, grad/param norm = 4.6654e-01, time/batch = 0.7020s	
490/29450 (epoch 0.832), train_loss = 2.82411599, grad/param norm = 5.4486e-01, time/batch = 0.7012s	
491/29450 (epoch 0.834), train_loss = 2.54728428, grad/param norm = 5.6727e-01, time/batch = 0.7001s	
492/29450 (epoch 0.835), train_loss = 2.56876452, grad/param norm = 5.8008e-01, time/batch = 0.7077s	
493/29450 (epoch 0.837), train_loss = 2.64422919, grad/param norm = 5.4914e-01, time/batch = 0.7285s	
494/29450 (epoch 0.839), train_loss = 2.68887235, grad/param norm = 5.4587e-01, time/batch = 0.7295s	
495/29450 (epoch 0.840), train_loss = 2.70106662, grad/param norm = 5.7920e-01, time/batch = 0.7140s	
496/29450 (epoch 0.842), train_loss = 2.50654666, grad/param norm = 5.6576e-01, time/batch = 0.7039s	
497/29450 (epoch 0.844), train_loss = 2.53846295, grad/param norm = 3.9365e-01, time/batch = 0.7239s	
498/29450 (epoch 0.846), train_loss = 2.60162170, grad/param norm = 2.5769e-01, time/batch = 0.7229s	
499/29450 (epoch 0.847), train_loss = 2.63234223, grad/param norm = 3.8709e-01, time/batch = 0.7051s	
500/29450 (epoch 0.849), train_loss = 2.65517314, grad/param norm = 6.2126e-01, time/batch = 0.7067s	
501/29450 (epoch 0.851), train_loss = 2.78934454, grad/param norm = 5.9428e-01, time/batch = 0.7095s	
502/29450 (epoch 0.852), train_loss = 2.65763798, grad/param norm = 4.2382e-01, time/batch = 0.7478s	
503/29450 (epoch 0.854), train_loss = 2.52498560, grad/param norm = 3.7904e-01, time/batch = 0.7336s	
504/29450 (epoch 0.856), train_loss = 2.44874608, grad/param norm = 3.8960e-01, time/batch = 0.7372s	
505/29450 (epoch 0.857), train_loss = 2.48451479, grad/param norm = 5.0839e-01, time/batch = 0.7333s	
506/29450 (epoch 0.859), train_loss = 2.46535160, grad/param norm = 5.4547e-01, time/batch = 0.7284s	
507/29450 (epoch 0.861), train_loss = 2.69204530, grad/param norm = 4.4310e-01, time/batch = 0.7282s	
508/29450 (epoch 0.862), train_loss = 2.64188510, grad/param norm = 3.6580e-01, time/batch = 0.7265s	
509/29450 (epoch 0.864), train_loss = 2.59795501, grad/param norm = 3.3890e-01, time/batch = 0.7036s	
510/29450 (epoch 0.866), train_loss = 2.64636955, grad/param norm = 4.2982e-01, time/batch = 0.6948s	
511/29450 (epoch 0.868), train_loss = 2.91000007, grad/param norm = 5.9446e-01, time/batch = 0.6963s	
512/29450 (epoch 0.869), train_loss = 2.78782502, grad/param norm = 5.1581e-01, time/batch = 0.6987s	
513/29450 (epoch 0.871), train_loss = 2.53175693, grad/param norm = 4.5826e-01, time/batch = 0.6909s	
514/29450 (epoch 0.873), train_loss = 2.75303545, grad/param norm = 4.1726e-01, time/batch = 0.6851s	
515/29450 (epoch 0.874), train_loss = 2.59993617, grad/param norm = 3.2767e-01, time/batch = 0.6818s	
516/29450 (epoch 0.876), train_loss = 2.54064325, grad/param norm = 2.7441e-01, time/batch = 0.6838s	
517/29450 (epoch 0.878), train_loss = 2.68160502, grad/param norm = 3.5926e-01, time/batch = 0.6841s	
518/29450 (epoch 0.879), train_loss = 2.78303892, grad/param norm = 3.3180e-01, time/batch = 0.6824s	
519/29450 (epoch 0.881), train_loss = 2.64895994, grad/param norm = 3.6788e-01, time/batch = 0.6821s	
520/29450 (epoch 0.883), train_loss = 2.69875809, grad/param norm = 3.9068e-01, time/batch = 0.6846s	
521/29450 (epoch 0.885), train_loss = 2.74876813, grad/param norm = 3.3691e-01, time/batch = 0.6911s	
522/29450 (epoch 0.886), train_loss = 2.62950307, grad/param norm = 3.4473e-01, time/batch = 0.6875s	
523/29450 (epoch 0.888), train_loss = 2.52794465, grad/param norm = 4.9776e-01, time/batch = 0.6841s	
524/29450 (epoch 0.890), train_loss = 2.58140746, grad/param norm = 6.0011e-01, time/batch = 0.6849s	
525/29450 (epoch 0.891), train_loss = 2.84085695, grad/param norm = 6.2965e-01, time/batch = 0.6854s	
526/29450 (epoch 0.893), train_loss = 2.54146336, grad/param norm = 6.6138e-01, time/batch = 0.6810s	
527/29450 (epoch 0.895), train_loss = 2.86031470, grad/param norm = 7.6933e-01, time/batch = 0.6854s	
528/29450 (epoch 0.896), train_loss = 2.69538302, grad/param norm = 4.4492e-01, time/batch = 0.6882s	
529/29450 (epoch 0.898), train_loss = 2.58221862, grad/param norm = 2.7816e-01, time/batch = 0.6859s	
530/29450 (epoch 0.900), train_loss = 2.84040046, grad/param norm = 4.4091e-01, time/batch = 0.6839s	
531/29450 (epoch 0.902), train_loss = 2.55519703, grad/param norm = 4.8844e-01, time/batch = 0.6923s	
532/29450 (epoch 0.903), train_loss = 2.58775743, grad/param norm = 4.7826e-01, time/batch = 0.7085s	
533/29450 (epoch 0.905), train_loss = 2.58815523, grad/param norm = 3.2043e-01, time/batch = 0.7159s	
534/29450 (epoch 0.907), train_loss = 2.81894824, grad/param norm = 3.6629e-01, time/batch = 0.7003s	
535/29450 (epoch 0.908), train_loss = 2.78076182, grad/param norm = 3.4440e-01, time/batch = 0.6959s	
536/29450 (epoch 0.910), train_loss = 2.64050867, grad/param norm = 3.6285e-01, time/batch = 0.6917s	
537/29450 (epoch 0.912), train_loss = 2.58051353, grad/param norm = 5.6257e-01, time/batch = 0.6912s	
538/29450 (epoch 0.913), train_loss = 2.64738277, grad/param norm = 7.5644e-01, time/batch = 0.6905s	
539/29450 (epoch 0.915), train_loss = 2.64607153, grad/param norm = 4.8529e-01, time/batch = 0.6908s	
540/29450 (epoch 0.917), train_loss = 2.59730116, grad/param norm = 3.8560e-01, time/batch = 0.6907s	
541/29450 (epoch 0.919), train_loss = 2.56020799, grad/param norm = 4.1596e-01, time/batch = 0.6954s	
542/29450 (epoch 0.920), train_loss = 2.73702428, grad/param norm = 3.1917e-01, time/batch = 0.6900s	
543/29450 (epoch 0.922), train_loss = 2.67865426, grad/param norm = 3.2762e-01, time/batch = 0.7155s	
544/29450 (epoch 0.924), train_loss = 2.85561054, grad/param norm = 4.3377e-01, time/batch = 0.6904s	
545/29450 (epoch 0.925), train_loss = 2.71432669, grad/param norm = 5.3208e-01, time/batch = 0.7029s	
546/29450 (epoch 0.927), train_loss = 2.79269263, grad/param norm = 4.6012e-01, time/batch = 0.6883s	
547/29450 (epoch 0.929), train_loss = 3.20500677, grad/param norm = 6.4654e-01, time/batch = 0.6852s	
548/29450 (epoch 0.930), train_loss = 3.08204478, grad/param norm = 4.4968e-01, time/batch = 0.6844s	
549/29450 (epoch 0.932), train_loss = 2.92370716, grad/param norm = 4.0176e-01, time/batch = 0.6930s	
550/29450 (epoch 0.934), train_loss = 2.64104344, grad/param norm = 3.7033e-01, time/batch = 0.6858s	
551/29450 (epoch 0.935), train_loss = 2.74946214, grad/param norm = 4.7373e-01, time/batch = 0.6851s	
552/29450 (epoch 0.937), train_loss = 2.64931234, grad/param norm = 4.8348e-01, time/batch = 0.6833s	
553/29450 (epoch 0.939), train_loss = 2.56630147, grad/param norm = 4.5523e-01, time/batch = 0.6836s	
554/29450 (epoch 0.941), train_loss = 2.69043264, grad/param norm = 4.4055e-01, time/batch = 0.6850s	
555/29450 (epoch 0.942), train_loss = 2.50178979, grad/param norm = 4.0868e-01, time/batch = 0.6929s	
556/29450 (epoch 0.944), train_loss = 2.62676270, grad/param norm = 4.1482e-01, time/batch = 0.6888s	
557/29450 (epoch 0.946), train_loss = 2.42879461, grad/param norm = 2.9726e-01, time/batch = 0.6910s	
558/29450 (epoch 0.947), train_loss = 2.54229864, grad/param norm = 2.7982e-01, time/batch = 0.6839s	
559/29450 (epoch 0.949), train_loss = 2.52432318, grad/param norm = 2.9958e-01, time/batch = 0.6776s	
560/29450 (epoch 0.951), train_loss = 2.46317488, grad/param norm = 3.0383e-01, time/batch = 0.6857s	
561/29450 (epoch 0.952), train_loss = 2.71255687, grad/param norm = 3.7623e-01, time/batch = 0.6849s	
562/29450 (epoch 0.954), train_loss = 2.60226126, grad/param norm = 3.1958e-01, time/batch = 0.6842s	
563/29450 (epoch 0.956), train_loss = 2.50441702, grad/param norm = 3.8949e-01, time/batch = 0.6843s	
564/29450 (epoch 0.958), train_loss = 2.57178124, grad/param norm = 5.2177e-01, time/batch = 0.6846s	
565/29450 (epoch 0.959), train_loss = 2.67237309, grad/param norm = 7.0189e-01, time/batch = 0.6845s	
566/29450 (epoch 0.961), train_loss = 2.60976766, grad/param norm = 7.0820e-01, time/batch = 0.6836s	
567/29450 (epoch 0.963), train_loss = 2.53497866, grad/param norm = 4.7014e-01, time/batch = 0.6893s	
568/29450 (epoch 0.964), train_loss = 2.70062922, grad/param norm = 3.3650e-01, time/batch = 0.6865s	
569/29450 (epoch 0.966), train_loss = 2.67674958, grad/param norm = 3.0877e-01, time/batch = 0.6887s	
570/29450 (epoch 0.968), train_loss = 2.69074782, grad/param norm = 2.8172e-01, time/batch = 0.6915s	
571/29450 (epoch 0.969), train_loss = 2.64192697, grad/param norm = 3.2927e-01, time/batch = 0.6931s	
572/29450 (epoch 0.971), train_loss = 2.43081268, grad/param norm = 3.0919e-01, time/batch = 0.6861s	
573/29450 (epoch 0.973), train_loss = 2.65626384, grad/param norm = 3.8732e-01, time/batch = 0.7095s	
574/29450 (epoch 0.975), train_loss = 2.68148566, grad/param norm = 3.1255e-01, time/batch = 0.7088s	
575/29450 (epoch 0.976), train_loss = 2.70677699, grad/param norm = 3.1113e-01, time/batch = 0.7015s	
576/29450 (epoch 0.978), train_loss = 2.58645516, grad/param norm = 3.5661e-01, time/batch = 0.6992s	
577/29450 (epoch 0.980), train_loss = 2.41959927, grad/param norm = 4.3693e-01, time/batch = 0.6922s	
578/29450 (epoch 0.981), train_loss = 2.50366953, grad/param norm = 4.0832e-01, time/batch = 0.6950s	
579/29450 (epoch 0.983), train_loss = 2.52064560, grad/param norm = 3.4641e-01, time/batch = 0.7084s	
580/29450 (epoch 0.985), train_loss = 2.61135077, grad/param norm = 4.1446e-01, time/batch = 0.7172s	
581/29450 (epoch 0.986), train_loss = 2.70984761, grad/param norm = 4.3440e-01, time/batch = 0.7041s	
582/29450 (epoch 0.988), train_loss = 2.49232655, grad/param norm = 4.3467e-01, time/batch = 0.6961s	
583/29450 (epoch 0.990), train_loss = 2.72009468, grad/param norm = 4.8784e-01, time/batch = 0.7171s	
584/29450 (epoch 0.992), train_loss = 2.39385375, grad/param norm = 4.5929e-01, time/batch = 0.7043s	
585/29450 (epoch 0.993), train_loss = 2.64179580, grad/param norm = 4.3309e-01, time/batch = 0.7048s	
586/29450 (epoch 0.995), train_loss = 2.52600170, grad/param norm = 3.5733e-01, time/batch = 0.7036s	
587/29450 (epoch 0.997), train_loss = 2.46137677, grad/param norm = 3.0183e-01, time/batch = 0.6839s	
588/29450 (epoch 0.998), train_loss = 2.57013475, grad/param norm = 2.9256e-01, time/batch = 0.6808s	
589/29450 (epoch 1.000), train_loss = 2.65069514, grad/param norm = 6.0029e-01, time/batch = 0.6857s	
590/29450 (epoch 1.002), train_loss = 2.62159811, grad/param norm = 5.9788e-01, time/batch = 0.6827s	
591/29450 (epoch 1.003), train_loss = 2.73318681, grad/param norm = 4.2833e-01, time/batch = 0.6897s	
592/29450 (epoch 1.005), train_loss = 2.38449437, grad/param norm = 3.2972e-01, time/batch = 0.6850s	
593/29450 (epoch 1.007), train_loss = 2.48482960, grad/param norm = 2.7518e-01, time/batch = 0.7119s	
594/29450 (epoch 1.008), train_loss = 2.47200086, grad/param norm = 2.5013e-01, time/batch = 0.7037s	
595/29450 (epoch 1.010), train_loss = 2.58399039, grad/param norm = 3.0405e-01, time/batch = 0.6863s	
596/29450 (epoch 1.012), train_loss = 2.55998727, grad/param norm = 3.9324e-01, time/batch = 0.6894s	
597/29450 (epoch 1.014), train_loss = 2.73169197, grad/param norm = 4.7789e-01, time/batch = 0.6914s	
598/29450 (epoch 1.015), train_loss = 2.41386637, grad/param norm = 3.5871e-01, time/batch = 0.6854s	
599/29450 (epoch 1.017), train_loss = 2.45530321, grad/param norm = 2.4879e-01, time/batch = 0.6882s	
600/29450 (epoch 1.019), train_loss = 2.29598110, grad/param norm = 2.5666e-01, time/batch = 0.6806s	
601/29450 (epoch 1.020), train_loss = 2.55802291, grad/param norm = 4.5683e-01, time/batch = 0.6812s	
602/29450 (epoch 1.022), train_loss = 2.50759576, grad/param norm = 5.3064e-01, time/batch = 0.6825s	
603/29450 (epoch 1.024), train_loss = 2.49396616, grad/param norm = 3.9454e-01, time/batch = 0.7079s	
604/29450 (epoch 1.025), train_loss = 2.53977825, grad/param norm = 4.8087e-01, time/batch = 0.7038s	
605/29450 (epoch 1.027), train_loss = 2.55524066, grad/param norm = 4.0654e-01, time/batch = 0.6792s	
606/29450 (epoch 1.029), train_loss = 2.59201105, grad/param norm = 3.9454e-01, time/batch = 0.6841s	
607/29450 (epoch 1.031), train_loss = 2.41194144, grad/param norm = 3.3128e-01, time/batch = 0.6891s	
608/29450 (epoch 1.032), train_loss = 2.47617674, grad/param norm = 2.6239e-01, time/batch = 0.6857s	
609/29450 (epoch 1.034), train_loss = 2.48569549, grad/param norm = 2.4858e-01, time/batch = 0.6844s	
610/29450 (epoch 1.036), train_loss = 2.55174594, grad/param norm = 2.5622e-01, time/batch = 0.6854s	
611/29450 (epoch 1.037), train_loss = 2.69978909, grad/param norm = 3.4836e-01, time/batch = 0.6876s	
612/29450 (epoch 1.039), train_loss = 2.39313209, grad/param norm = 3.8185e-01, time/batch = 0.6883s	
613/29450 (epoch 1.041), train_loss = 2.55126549, grad/param norm = 2.9562e-01, time/batch = 0.6932s	
614/29450 (epoch 1.042), train_loss = 2.46484385, grad/param norm = 3.8049e-01, time/batch = 0.6911s	
615/29450 (epoch 1.044), train_loss = 2.46090040, grad/param norm = 3.7962e-01, time/batch = 0.6890s	
616/29450 (epoch 1.046), train_loss = 2.80600156, grad/param norm = 5.4666e-01, time/batch = 0.6928s	
617/29450 (epoch 1.048), train_loss = 2.52695580, grad/param norm = 5.7855e-01, time/batch = 0.6920s	
618/29450 (epoch 1.049), train_loss = 2.66041324, grad/param norm = 3.2950e-01, time/batch = 0.6977s	
619/29450 (epoch 1.051), train_loss = 2.59410960, grad/param norm = 2.8648e-01, time/batch = 0.7030s	
620/29450 (epoch 1.053), train_loss = 2.39419733, grad/param norm = 2.7027e-01, time/batch = 0.7062s	
621/29450 (epoch 1.054), train_loss = 2.49947988, grad/param norm = 2.9228e-01, time/batch = 0.7083s	
622/29450 (epoch 1.056), train_loss = 2.49946768, grad/param norm = 3.6193e-01, time/batch = 0.7063s	
623/29450 (epoch 1.058), train_loss = 2.58674626, grad/param norm = 4.0705e-01, time/batch = 0.7104s	
624/29450 (epoch 1.059), train_loss = 2.43286099, grad/param norm = 4.5964e-01, time/batch = 0.7030s	
625/29450 (epoch 1.061), train_loss = 2.39222614, grad/param norm = 4.8482e-01, time/batch = 0.6833s	
626/29450 (epoch 1.063), train_loss = 2.50981686, grad/param norm = 4.0832e-01, time/batch = 0.6858s	
627/29450 (epoch 1.065), train_loss = 2.49490929, grad/param norm = 4.8644e-01, time/batch = 0.6948s	
628/29450 (epoch 1.066), train_loss = 2.44286432, grad/param norm = 5.8163e-01, time/batch = 0.7074s	
629/29450 (epoch 1.068), train_loss = 2.62868085, grad/param norm = 4.4810e-01, time/batch = 0.6866s	
630/29450 (epoch 1.070), train_loss = 2.52607873, grad/param norm = 2.8565e-01, time/batch = 0.7207s	
631/29450 (epoch 1.071), train_loss = 2.66129163, grad/param norm = 3.7548e-01, time/batch = 0.7095s	
632/29450 (epoch 1.073), train_loss = 2.59371944, grad/param norm = 4.2090e-01, time/batch = 0.7017s	
633/29450 (epoch 1.075), train_loss = 2.74919379, grad/param norm = 4.8363e-01, time/batch = 0.7114s	
634/29450 (epoch 1.076), train_loss = 2.55079869, grad/param norm = 4.0866e-01, time/batch = 0.7040s	
635/29450 (epoch 1.078), train_loss = 2.52454676, grad/param norm = 2.9399e-01, time/batch = 0.6855s	
636/29450 (epoch 1.080), train_loss = 2.59144149, grad/param norm = 2.8977e-01, time/batch = 0.6881s	
637/29450 (epoch 1.081), train_loss = 2.56589394, grad/param norm = 3.1403e-01, time/batch = 0.6949s	
638/29450 (epoch 1.083), train_loss = 2.52755500, grad/param norm = 3.1942e-01, time/batch = 0.6859s	
639/29450 (epoch 1.085), train_loss = 2.57641303, grad/param norm = 2.8559e-01, time/batch = 0.6875s	
640/29450 (epoch 1.087), train_loss = 2.40854729, grad/param norm = 3.1976e-01, time/batch = 0.6934s	
641/29450 (epoch 1.088), train_loss = 2.50937945, grad/param norm = 3.5341e-01, time/batch = 0.6855s	
642/29450 (epoch 1.090), train_loss = 2.42352920, grad/param norm = 2.9296e-01, time/batch = 0.6897s	
643/29450 (epoch 1.092), train_loss = 2.59158603, grad/param norm = 2.7595e-01, time/batch = 0.6843s	
644/29450 (epoch 1.093), train_loss = 2.44314821, grad/param norm = 2.6858e-01, time/batch = 0.6799s	
645/29450 (epoch 1.095), train_loss = 2.32354825, grad/param norm = 2.9114e-01, time/batch = 0.6794s	
646/29450 (epoch 1.097), train_loss = 2.44961980, grad/param norm = 2.3573e-01, time/batch = 0.6831s	
647/29450 (epoch 1.098), train_loss = 2.42339850, grad/param norm = 4.7926e-01, time/batch = 0.6907s	
648/29450 (epoch 1.100), train_loss = 2.68465248, grad/param norm = 7.9210e-01, time/batch = 0.6849s	
649/29450 (epoch 1.102), train_loss = 2.61042954, grad/param norm = 5.5292e-01, time/batch = 0.6850s	
650/29450 (epoch 1.104), train_loss = 2.52316446, grad/param norm = 4.5096e-01, time/batch = 0.6931s	
651/29450 (epoch 1.105), train_loss = 2.40689382, grad/param norm = 2.7010e-01, time/batch = 0.6979s	
652/29450 (epoch 1.107), train_loss = 2.37655951, grad/param norm = 3.3845e-01, time/batch = 0.6896s	
653/29450 (epoch 1.109), train_loss = 2.36531046, grad/param norm = 4.0990e-01, time/batch = 0.6849s	
654/29450 (epoch 1.110), train_loss = 2.54007281, grad/param norm = 3.4861e-01, time/batch = 0.6869s	
655/29450 (epoch 1.112), train_loss = 2.40808137, grad/param norm = 3.5688e-01, time/batch = 0.6890s	
656/29450 (epoch 1.114), train_loss = 2.41409262, grad/param norm = 3.7506e-01, time/batch = 0.6963s	
657/29450 (epoch 1.115), train_loss = 2.63256614, grad/param norm = 4.0076e-01, time/batch = 0.6893s	
658/29450 (epoch 1.117), train_loss = 2.48708720, grad/param norm = 2.9955e-01, time/batch = 0.6803s	
659/29450 (epoch 1.119), train_loss = 2.58063503, grad/param norm = 3.1370e-01, time/batch = 0.6793s	
660/29450 (epoch 1.121), train_loss = 2.50163814, grad/param norm = 3.3320e-01, time/batch = 0.6809s	
661/29450 (epoch 1.122), train_loss = 2.41358485, grad/param norm = 2.7124e-01, time/batch = 0.6856s	
662/29450 (epoch 1.124), train_loss = 2.42537820, grad/param norm = 2.6369e-01, time/batch = 0.6828s	
663/29450 (epoch 1.126), train_loss = 2.47139859, grad/param norm = 2.4759e-01, time/batch = 0.6847s	
664/29450 (epoch 1.127), train_loss = 2.50506306, grad/param norm = 2.7649e-01, time/batch = 0.6917s	
665/29450 (epoch 1.129), train_loss = 2.48864300, grad/param norm = 2.7694e-01, time/batch = 0.7117s	
666/29450 (epoch 1.131), train_loss = 2.59594152, grad/param norm = 3.0705e-01, time/batch = 0.7170s	
667/29450 (epoch 1.132), train_loss = 2.32844561, grad/param norm = 2.5897e-01, time/batch = 0.7199s	
668/29450 (epoch 1.134), train_loss = 2.38801914, grad/param norm = 2.7842e-01, time/batch = 0.7273s	
669/29450 (epoch 1.136), train_loss = 2.25889393, grad/param norm = 2.8797e-01, time/batch = 0.7102s	
670/29450 (epoch 1.138), train_loss = 2.54520064, grad/param norm = 3.7947e-01, time/batch = 0.7050s	
671/29450 (epoch 1.139), train_loss = 2.36648325, grad/param norm = 3.9753e-01, time/batch = 0.7063s	
672/29450 (epoch 1.141), train_loss = 2.38494073, grad/param norm = 3.6579e-01, time/batch = 0.7023s	
673/29450 (epoch 1.143), train_loss = 2.42767571, grad/param norm = 3.6418e-01, time/batch = 0.7029s	
674/29450 (epoch 1.144), train_loss = 2.43309187, grad/param norm = 4.0093e-01, time/batch = 0.7009s	
675/29450 (epoch 1.146), train_loss = 2.56260831, grad/param norm = 4.0591e-01, time/batch = 0.6996s	
676/29450 (epoch 1.148), train_loss = 2.60779125, grad/param norm = 4.8931e-01, time/batch = 0.6990s	
677/29450 (epoch 1.149), train_loss = 2.31828114, grad/param norm = 5.8418e-01, time/batch = 0.6994s	
678/29450 (epoch 1.151), train_loss = 2.62479011, grad/param norm = 4.9166e-01, time/batch = 0.6966s	
679/29450 (epoch 1.153), train_loss = 2.32361556, grad/param norm = 3.2141e-01, time/batch = 0.7012s	
680/29450 (epoch 1.154), train_loss = 2.44375213, grad/param norm = 2.7749e-01, time/batch = 0.7011s	
681/29450 (epoch 1.156), train_loss = 2.50067334, grad/param norm = 3.0267e-01, time/batch = 0.6992s	
682/29450 (epoch 1.158), train_loss = 2.52867348, grad/param norm = 2.4972e-01, time/batch = 0.7023s	
683/29450 (epoch 1.160), train_loss = 2.65820676, grad/param norm = 3.2261e-01, time/batch = 0.7040s	
684/29450 (epoch 1.161), train_loss = 2.51473400, grad/param norm = 4.5912e-01, time/batch = 0.7071s	
685/29450 (epoch 1.163), train_loss = 2.51611078, grad/param norm = 2.9119e-01, time/batch = 0.7095s	
686/29450 (epoch 1.165), train_loss = 2.55366611, grad/param norm = 2.5356e-01, time/batch = 0.7057s	
687/29450 (epoch 1.166), train_loss = 2.68427290, grad/param norm = 2.9921e-01, time/batch = 0.6972s	
688/29450 (epoch 1.168), train_loss = 2.63650312, grad/param norm = 4.0825e-01, time/batch = 0.7059s	
689/29450 (epoch 1.170), train_loss = 2.69024508, grad/param norm = 3.1690e-01, time/batch = 0.6986s	
690/29450 (epoch 1.171), train_loss = 2.67890127, grad/param norm = 3.6153e-01, time/batch = 0.6988s	
691/29450 (epoch 1.173), train_loss = 2.47953260, grad/param norm = 3.4187e-01, time/batch = 0.7007s	
692/29450 (epoch 1.175), train_loss = 2.38010892, grad/param norm = 2.8969e-01, time/batch = 0.7034s	
693/29450 (epoch 1.177), train_loss = 2.61804898, grad/param norm = 3.6888e-01, time/batch = 0.7053s	
694/29450 (epoch 1.178), train_loss = 2.45616500, grad/param norm = 3.5562e-01, time/batch = 0.6988s	
695/29450 (epoch 1.180), train_loss = 2.39486801, grad/param norm = 2.6390e-01, time/batch = 0.7029s	
696/29450 (epoch 1.182), train_loss = 2.41608124, grad/param norm = 2.1586e-01, time/batch = 0.7035s	
697/29450 (epoch 1.183), train_loss = 2.46464138, grad/param norm = 3.1138e-01, time/batch = 0.7222s	
698/29450 (epoch 1.185), train_loss = 2.45411818, grad/param norm = 4.1163e-01, time/batch = 0.7051s	
699/29450 (epoch 1.187), train_loss = 2.53267011, grad/param norm = 4.1116e-01, time/batch = 0.7207s	
700/29450 (epoch 1.188), train_loss = 2.58444042, grad/param norm = 3.9884e-01, time/batch = 0.7142s	
701/29450 (epoch 1.190), train_loss = 2.38779711, grad/param norm = 3.4962e-01, time/batch = 0.6933s	
702/29450 (epoch 1.192), train_loss = 2.53841011, grad/param norm = 3.4841e-01, time/batch = 0.6952s	
703/29450 (epoch 1.194), train_loss = 2.52482334, grad/param norm = 2.9357e-01, time/batch = 0.7041s	
704/29450 (epoch 1.195), train_loss = 2.47559184, grad/param norm = 2.7769e-01, time/batch = 0.6853s	
705/29450 (epoch 1.197), train_loss = 2.55038498, grad/param norm = 2.6774e-01, time/batch = 0.6818s	
706/29450 (epoch 1.199), train_loss = 2.39113868, grad/param norm = 2.7543e-01, time/batch = 0.6853s	
707/29450 (epoch 1.200), train_loss = 2.60087991, grad/param norm = 2.2906e-01, time/batch = 0.6845s	
708/29450 (epoch 1.202), train_loss = 2.42371643, grad/param norm = 2.9913e-01, time/batch = 0.6840s	
709/29450 (epoch 1.204), train_loss = 2.33850794, grad/param norm = 4.0747e-01, time/batch = 0.6882s	
710/29450 (epoch 1.205), train_loss = 2.33383786, grad/param norm = 3.6828e-01, time/batch = 0.6846s	
711/29450 (epoch 1.207), train_loss = 2.28964261, grad/param norm = 3.1257e-01, time/batch = 0.6912s	
712/29450 (epoch 1.209), train_loss = 2.43552999, grad/param norm = 3.6205e-01, time/batch = 0.6919s	
713/29450 (epoch 1.211), train_loss = 2.63357100, grad/param norm = 5.4063e-01, time/batch = 0.6984s	
714/29450 (epoch 1.212), train_loss = 2.44145161, grad/param norm = 5.8097e-01, time/batch = 0.6971s	
715/29450 (epoch 1.214), train_loss = 2.50191463, grad/param norm = 4.7002e-01, time/batch = 0.6910s	
716/29450 (epoch 1.216), train_loss = 2.44191010, grad/param norm = 2.6825e-01, time/batch = 0.6876s	
717/29450 (epoch 1.217), train_loss = 2.54442805, grad/param norm = 2.4584e-01, time/batch = 0.6847s	
718/29450 (epoch 1.219), train_loss = 2.19172608, grad/param norm = 2.5589e-01, time/batch = 0.6862s	
719/29450 (epoch 1.221), train_loss = 2.54973940, grad/param norm = 2.7228e-01, time/batch = 0.6826s	
720/29450 (epoch 1.222), train_loss = 2.39173951, grad/param norm = 2.7342e-01, time/batch = 0.6852s	
721/29450 (epoch 1.224), train_loss = 2.38955944, grad/param norm = 3.9328e-01, time/batch = 0.6886s	
722/29450 (epoch 1.226), train_loss = 2.66911437, grad/param norm = 3.5312e-01, time/batch = 0.6951s	
723/29450 (epoch 1.228), train_loss = 2.48602140, grad/param norm = 3.1955e-01, time/batch = 0.6861s	
724/29450 (epoch 1.229), train_loss = 2.39891759, grad/param norm = 3.0127e-01, time/batch = 0.6842s	
725/29450 (epoch 1.231), train_loss = 2.36483534, grad/param norm = 3.2076e-01, time/batch = 0.6859s	
726/29450 (epoch 1.233), train_loss = 2.32198906, grad/param norm = 3.4573e-01, time/batch = 0.6895s	
727/29450 (epoch 1.234), train_loss = 2.29296070, grad/param norm = 2.7410e-01, time/batch = 0.6955s	
728/29450 (epoch 1.236), train_loss = 2.57570930, grad/param norm = 3.9407e-01, time/batch = 0.7161s	
729/29450 (epoch 1.238), train_loss = 2.50724323, grad/param norm = 2.9629e-01, time/batch = 0.6967s	
730/29450 (epoch 1.239), train_loss = 2.53037169, grad/param norm = 3.1842e-01, time/batch = 0.6881s	
731/29450 (epoch 1.241), train_loss = 2.39113027, grad/param norm = 3.0936e-01, time/batch = 0.6901s	
732/29450 (epoch 1.243), train_loss = 2.42933386, grad/param norm = 2.4027e-01, time/batch = 0.6896s	
733/29450 (epoch 1.244), train_loss = 2.62562945, grad/param norm = 2.1523e-01, time/batch = 0.6853s	
734/29450 (epoch 1.246), train_loss = 2.47318992, grad/param norm = 2.3041e-01, time/batch = 0.6865s	
735/29450 (epoch 1.248), train_loss = 2.48466380, grad/param norm = 2.7909e-01, time/batch = 0.6843s	
736/29450 (epoch 1.250), train_loss = 2.37663396, grad/param norm = 3.5069e-01, time/batch = 0.6866s	
737/29450 (epoch 1.251), train_loss = 2.50439838, grad/param norm = 3.9594e-01, time/batch = 0.6841s	
738/29450 (epoch 1.253), train_loss = 2.25990074, grad/param norm = 2.9817e-01, time/batch = 0.6847s	
739/29450 (epoch 1.255), train_loss = 2.40839367, grad/param norm = 2.9625e-01, time/batch = 0.6892s	
740/29450 (epoch 1.256), train_loss = 2.34897288, grad/param norm = 2.4352e-01, time/batch = 0.6891s	
741/29450 (epoch 1.258), train_loss = 2.34847142, grad/param norm = 3.3322e-01, time/batch = 0.6893s	
742/29450 (epoch 1.260), train_loss = 2.48333725, grad/param norm = 3.7227e-01, time/batch = 0.6937s	
743/29450 (epoch 1.261), train_loss = 2.59015571, grad/param norm = 3.5629e-01, time/batch = 0.6917s	
744/29450 (epoch 1.263), train_loss = 2.39566731, grad/param norm = 2.9738e-01, time/batch = 0.6854s	
745/29450 (epoch 1.265), train_loss = 2.34443009, grad/param norm = 3.3614e-01, time/batch = 0.6869s	
746/29450 (epoch 1.267), train_loss = 2.48441987, grad/param norm = 3.3014e-01, time/batch = 0.6925s	
747/29450 (epoch 1.268), train_loss = 2.30511795, grad/param norm = 2.8249e-01, time/batch = 0.6837s	
748/29450 (epoch 1.270), train_loss = 2.41621469, grad/param norm = 2.6709e-01, time/batch = 0.7080s	
749/29450 (epoch 1.272), train_loss = 2.30116802, grad/param norm = 2.6715e-01, time/batch = 0.7073s	
750/29450 (epoch 1.273), train_loss = 2.48773848, grad/param norm = 3.5864e-01, time/batch = 0.7093s	
751/29450 (epoch 1.275), train_loss = 2.55315324, grad/param norm = 3.4802e-01, time/batch = 0.7245s	
752/29450 (epoch 1.277), train_loss = 2.31120208, grad/param norm = 3.6646e-01, time/batch = 0.7237s	
753/29450 (epoch 1.278), train_loss = 2.59038182, grad/param norm = 3.3360e-01, time/batch = 0.7161s	
754/29450 (epoch 1.280), train_loss = 2.38588155, grad/param norm = 2.8217e-01, time/batch = 0.7090s	
755/29450 (epoch 1.282), train_loss = 2.57113838, grad/param norm = 3.3286e-01, time/batch = 0.7056s	
756/29450 (epoch 1.284), train_loss = 2.47410869, grad/param norm = 3.3694e-01, time/batch = 0.7068s	
757/29450 (epoch 1.285), train_loss = 2.46739308, grad/param norm = 3.3156e-01, time/batch = 0.7093s	
758/29450 (epoch 1.287), train_loss = 2.52706123, grad/param norm = 2.6629e-01, time/batch = 0.6992s	
759/29450 (epoch 1.289), train_loss = 2.61629529, grad/param norm = 3.4154e-01, time/batch = 0.6873s	
760/29450 (epoch 1.290), train_loss = 2.52036632, grad/param norm = 3.5315e-01, time/batch = 0.6852s	
761/29450 (epoch 1.292), train_loss = 2.51822753, grad/param norm = 4.5107e-01, time/batch = 0.6871s	
762/29450 (epoch 1.294), train_loss = 2.55113641, grad/param norm = 4.3334e-01, time/batch = 0.6888s	
763/29450 (epoch 1.295), train_loss = 2.37519991, grad/param norm = 3.3049e-01, time/batch = 0.6886s	
764/29450 (epoch 1.297), train_loss = 2.50772727, grad/param norm = 2.4978e-01, time/batch = 0.6896s	
765/29450 (epoch 1.299), train_loss = 2.41485857, grad/param norm = 4.0630e-01, time/batch = 0.6859s	
766/29450 (epoch 1.301), train_loss = 2.42907899, grad/param norm = 4.4717e-01, time/batch = 0.6804s	
767/29450 (epoch 1.302), train_loss = 2.39250041, grad/param norm = 3.5341e-01, time/batch = 0.6854s	
768/29450 (epoch 1.304), train_loss = 2.33172397, grad/param norm = 2.9354e-01, time/batch = 0.6831s	
769/29450 (epoch 1.306), train_loss = 2.39334738, grad/param norm = 2.3390e-01, time/batch = 0.6853s	
770/29450 (epoch 1.307), train_loss = 2.45870105, grad/param norm = 2.3010e-01, time/batch = 0.6907s	
771/29450 (epoch 1.309), train_loss = 2.58196465, grad/param norm = 2.9193e-01, time/batch = 0.6912s	
772/29450 (epoch 1.311), train_loss = 2.51066399, grad/param norm = 2.8778e-01, time/batch = 0.6886s	
773/29450 (epoch 1.312), train_loss = 2.47078795, grad/param norm = 2.4200e-01, time/batch = 0.6842s	
774/29450 (epoch 1.314), train_loss = 2.48783725, grad/param norm = 3.4297e-01, time/batch = 0.6831s	
775/29450 (epoch 1.316), train_loss = 2.38785790, grad/param norm = 4.1614e-01, time/batch = 0.6851s	
776/29450 (epoch 1.317), train_loss = 2.44332708, grad/param norm = 3.4768e-01, time/batch = 0.6819s	
777/29450 (epoch 1.319), train_loss = 2.26185910, grad/param norm = 2.5138e-01, time/batch = 0.6828s	
778/29450 (epoch 1.321), train_loss = 2.43137203, grad/param norm = 3.0326e-01, time/batch = 0.7145s	
779/29450 (epoch 1.323), train_loss = 2.55093736, grad/param norm = 2.7912e-01, time/batch = 0.7015s	
780/29450 (epoch 1.324), train_loss = 2.36434418, grad/param norm = 3.2658e-01, time/batch = 0.6873s	
781/29450 (epoch 1.326), train_loss = 2.40395109, grad/param norm = 4.0947e-01, time/batch = 0.6868s	
782/29450 (epoch 1.328), train_loss = 2.48883139, grad/param norm = 4.4902e-01, time/batch = 0.6868s	
783/29450 (epoch 1.329), train_loss = 2.49991442, grad/param norm = 3.9166e-01, time/batch = 0.6855s	
784/29450 (epoch 1.331), train_loss = 2.22644743, grad/param norm = 3.0507e-01, time/batch = 0.6879s	
785/29450 (epoch 1.333), train_loss = 2.51766083, grad/param norm = 2.2992e-01, time/batch = 0.6851s	
786/29450 (epoch 1.334), train_loss = 2.38100024, grad/param norm = 2.7606e-01, time/batch = 0.6855s	
787/29450 (epoch 1.336), train_loss = 2.30151249, grad/param norm = 2.4085e-01, time/batch = 0.6851s	
788/29450 (epoch 1.338), train_loss = 2.23027454, grad/param norm = 2.2242e-01, time/batch = 0.7109s	
789/29450 (epoch 1.340), train_loss = 2.32888408, grad/param norm = 2.5477e-01, time/batch = 0.7024s	
790/29450 (epoch 1.341), train_loss = 2.46686328, grad/param norm = 3.2961e-01, time/batch = 0.7084s	
791/29450 (epoch 1.343), train_loss = 2.39804119, grad/param norm = 3.5135e-01, time/batch = 0.6852s	
792/29450 (epoch 1.345), train_loss = 2.75252302, grad/param norm = 3.0221e-01, time/batch = 0.6885s	
793/29450 (epoch 1.346), train_loss = 2.46437353, grad/param norm = 2.7470e-01, time/batch = 0.6884s	
794/29450 (epoch 1.348), train_loss = 2.54519000, grad/param norm = 3.6403e-01, time/batch = 0.6917s	
795/29450 (epoch 1.350), train_loss = 2.49623547, grad/param norm = 3.9867e-01, time/batch = 0.6894s	
796/29450 (epoch 1.351), train_loss = 2.53857580, grad/param norm = 2.6931e-01, time/batch = 0.7030s	
797/29450 (epoch 1.353), train_loss = 2.32366724, grad/param norm = 2.6472e-01, time/batch = 0.7056s	
798/29450 (epoch 1.355), train_loss = 2.34683440, grad/param norm = 2.7776e-01, time/batch = 0.7144s	
799/29450 (epoch 1.357), train_loss = 2.28854058, grad/param norm = 2.6277e-01, time/batch = 0.7089s	
800/29450 (epoch 1.358), train_loss = 2.20150265, grad/param norm = 3.0124e-01, time/batch = 0.7407s	
801/29450 (epoch 1.360), train_loss = 2.41977925, grad/param norm = 4.8613e-01, time/batch = 0.7118s	
802/29450 (epoch 1.362), train_loss = 2.38039898, grad/param norm = 2.8149e-01, time/batch = 0.7085s	
803/29450 (epoch 1.363), train_loss = 2.43568266, grad/param norm = 3.0296e-01, time/batch = 0.7160s	
804/29450 (epoch 1.365), train_loss = 2.43592999, grad/param norm = 3.7494e-01, time/batch = 0.7065s	
805/29450 (epoch 1.367), train_loss = 2.39302798, grad/param norm = 4.2282e-01, time/batch = 0.6984s	
806/29450 (epoch 1.368), train_loss = 2.53206862, grad/param norm = 3.5964e-01, time/batch = 0.7047s	
807/29450 (epoch 1.370), train_loss = 2.38553489, grad/param norm = 2.6879e-01, time/batch = 0.7082s	
808/29450 (epoch 1.372), train_loss = 2.76867893, grad/param norm = 4.3539e-01, time/batch = 0.7065s	
809/29450 (epoch 1.374), train_loss = 2.64865576, grad/param norm = 4.9111e-01, time/batch = 0.7023s	
810/29450 (epoch 1.375), train_loss = 2.78812645, grad/param norm = 4.5354e-01, time/batch = 0.7089s	
811/29450 (epoch 1.377), train_loss = 2.51538110, grad/param norm = 3.8079e-01, time/batch = 0.7155s	
812/29450 (epoch 1.379), train_loss = 2.25467807, grad/param norm = 2.3840e-01, time/batch = 0.7099s	
813/29450 (epoch 1.380), train_loss = 2.27798819, grad/param norm = 3.2743e-01, time/batch = 0.7024s	
814/29450 (epoch 1.382), train_loss = 2.44963108, grad/param norm = 3.3830e-01, time/batch = 0.7065s	
815/29450 (epoch 1.384), train_loss = 2.45982183, grad/param norm = 2.3063e-01, time/batch = 0.7017s	
816/29450 (epoch 1.385), train_loss = 2.47391977, grad/param norm = 2.8369e-01, time/batch = 0.7000s	
817/29450 (epoch 1.387), train_loss = 2.46802837, grad/param norm = 2.7126e-01, time/batch = 0.7057s	
818/29450 (epoch 1.389), train_loss = 2.61344724, grad/param norm = 3.0299e-01, time/batch = 0.7226s	
819/29450 (epoch 1.390), train_loss = 2.33905071, grad/param norm = 3.1395e-01, time/batch = 0.7010s	
820/29450 (epoch 1.392), train_loss = 2.37002872, grad/param norm = 3.0073e-01, time/batch = 0.7069s	
821/29450 (epoch 1.394), train_loss = 2.40794628, grad/param norm = 2.9030e-01, time/batch = 0.7103s	
822/29450 (epoch 1.396), train_loss = 2.26179518, grad/param norm = 2.5181e-01, time/batch = 0.7036s	
823/29450 (epoch 1.397), train_loss = 2.39725785, grad/param norm = 3.2634e-01, time/batch = 0.7023s	
824/29450 (epoch 1.399), train_loss = 2.26055352, grad/param norm = 4.2063e-01, time/batch = 0.7007s	
825/29450 (epoch 1.401), train_loss = 2.48795592, grad/param norm = 3.2188e-01, time/batch = 0.7092s	
826/29450 (epoch 1.402), train_loss = 2.45218845, grad/param norm = 2.8914e-01, time/batch = 0.7053s	
827/29450 (epoch 1.404), train_loss = 2.29107430, grad/param norm = 2.7281e-01, time/batch = 0.7098s	
828/29450 (epoch 1.406), train_loss = 2.27908870, grad/param norm = 2.3452e-01, time/batch = 0.7288s	
829/29450 (epoch 1.407), train_loss = 2.43650122, grad/param norm = 2.4593e-01, time/batch = 0.6984s	
830/29450 (epoch 1.409), train_loss = 2.36300469, grad/param norm = 2.8224e-01, time/batch = 0.6958s	
831/29450 (epoch 1.411), train_loss = 2.34507626, grad/param norm = 3.2018e-01, time/batch = 0.7146s	
832/29450 (epoch 1.413), train_loss = 2.58452087, grad/param norm = 3.3551e-01, time/batch = 0.7005s	
833/29450 (epoch 1.414), train_loss = 2.25225669, grad/param norm = 3.3551e-01, time/batch = 0.7014s	
834/29450 (epoch 1.416), train_loss = 2.15547827, grad/param norm = 2.6701e-01, time/batch = 0.7046s	
835/29450 (epoch 1.418), train_loss = 2.44508091, grad/param norm = 2.9664e-01, time/batch = 0.7107s	
836/29450 (epoch 1.419), train_loss = 2.49943440, grad/param norm = 3.3858e-01, time/batch = 0.7286s	
837/29450 (epoch 1.421), train_loss = 2.34532452, grad/param norm = 3.4584e-01, time/batch = 0.7365s	
838/29450 (epoch 1.423), train_loss = 2.34797239, grad/param norm = 4.0046e-01, time/batch = 0.7316s	
839/29450 (epoch 1.424), train_loss = 2.39672619, grad/param norm = 3.9249e-01, time/batch = 0.7358s	
840/29450 (epoch 1.426), train_loss = 2.45792264, grad/param norm = 3.2281e-01, time/batch = 0.7146s	
841/29450 (epoch 1.428), train_loss = 2.37357591, grad/param norm = 3.0683e-01, time/batch = 0.7534s	
842/29450 (epoch 1.430), train_loss = 2.50242148, grad/param norm = 3.8983e-01, time/batch = 0.7136s	
843/29450 (epoch 1.431), train_loss = 2.30225645, grad/param norm = 3.4036e-01, time/batch = 0.7237s	
844/29450 (epoch 1.433), train_loss = 2.62043352, grad/param norm = 2.9953e-01, time/batch = 0.7171s	
845/29450 (epoch 1.435), train_loss = 2.23244030, grad/param norm = 2.5908e-01, time/batch = 0.7190s	
846/29450 (epoch 1.436), train_loss = 2.52948732, grad/param norm = 3.3225e-01, time/batch = 0.7191s	
847/29450 (epoch 1.438), train_loss = 2.34993794, grad/param norm = 3.3334e-01, time/batch = 0.7105s	
848/29450 (epoch 1.440), train_loss = 2.54768344, grad/param norm = 2.8265e-01, time/batch = 0.7146s	
849/29450 (epoch 1.441), train_loss = 2.40363183, grad/param norm = 2.5313e-01, time/batch = 0.7154s	
850/29450 (epoch 1.443), train_loss = 2.34539220, grad/param norm = 2.7384e-01, time/batch = 0.7013s	
851/29450 (epoch 1.445), train_loss = 2.30964741, grad/param norm = 2.9921e-01, time/batch = 0.6997s	
852/29450 (epoch 1.447), train_loss = 2.38998892, grad/param norm = 2.6177e-01, time/batch = 0.7211s	
853/29450 (epoch 1.448), train_loss = 2.27764892, grad/param norm = 2.4678e-01, time/batch = 0.7239s	
854/29450 (epoch 1.450), train_loss = 2.39019681, grad/param norm = 2.4956e-01, time/batch = 0.7147s	
855/29450 (epoch 1.452), train_loss = 2.35136079, grad/param norm = 2.5590e-01, time/batch = 0.6973s	
856/29450 (epoch 1.453), train_loss = 2.25168255, grad/param norm = 2.6479e-01, time/batch = 0.7000s	
857/29450 (epoch 1.455), train_loss = 2.33627932, grad/param norm = 2.8807e-01, time/batch = 0.6958s	
858/29450 (epoch 1.457), train_loss = 2.37999153, grad/param norm = 2.7764e-01, time/batch = 0.7049s	
859/29450 (epoch 1.458), train_loss = 2.51642004, grad/param norm = 2.4922e-01, time/batch = 0.7197s	
860/29450 (epoch 1.460), train_loss = 2.43645114, grad/param norm = 2.4618e-01, time/batch = 0.6965s	
861/29450 (epoch 1.462), train_loss = 2.30701966, grad/param norm = 2.3629e-01, time/batch = 0.6960s	
862/29450 (epoch 1.463), train_loss = 2.38021351, grad/param norm = 3.3488e-01, time/batch = 0.6954s	
863/29450 (epoch 1.465), train_loss = 2.17572722, grad/param norm = 2.9236e-01, time/batch = 0.7020s	
864/29450 (epoch 1.467), train_loss = 2.22413266, grad/param norm = 2.5024e-01, time/batch = 0.6851s	
865/29450 (epoch 1.469), train_loss = 2.49262981, grad/param norm = 2.5307e-01, time/batch = 0.6817s	
866/29450 (epoch 1.470), train_loss = 2.01590275, grad/param norm = 2.1886e-01, time/batch = 0.6912s	
867/29450 (epoch 1.472), train_loss = 2.48487237, grad/param norm = 3.0205e-01, time/batch = 0.7003s	
868/29450 (epoch 1.474), train_loss = 2.41521983, grad/param norm = 2.9953e-01, time/batch = 0.6913s	
869/29450 (epoch 1.475), train_loss = 2.39810224, grad/param norm = 2.5612e-01, time/batch = 0.6820s	
870/29450 (epoch 1.477), train_loss = 2.26404686, grad/param norm = 2.2679e-01, time/batch = 0.6854s	
871/29450 (epoch 1.479), train_loss = 2.43327340, grad/param norm = 2.6243e-01, time/batch = 0.6863s	
872/29450 (epoch 1.480), train_loss = 2.48392429, grad/param norm = 2.8057e-01, time/batch = 0.6828s	
873/29450 (epoch 1.482), train_loss = 2.35745562, grad/param norm = 2.3844e-01, time/batch = 0.6880s	
874/29450 (epoch 1.484), train_loss = 2.32527361, grad/param norm = 2.3832e-01, time/batch = 0.6880s	
875/29450 (epoch 1.486), train_loss = 2.34788453, grad/param norm = 2.3587e-01, time/batch = 0.6844s	
876/29450 (epoch 1.487), train_loss = 2.39140733, grad/param norm = 2.5811e-01, time/batch = 0.6908s	
877/29450 (epoch 1.489), train_loss = 2.28810956, grad/param norm = 3.1004e-01, time/batch = 0.7172s	
878/29450 (epoch 1.491), train_loss = 2.35242334, grad/param norm = 3.4237e-01, time/batch = 0.7274s	
879/29450 (epoch 1.492), train_loss = 2.31899269, grad/param norm = 3.6266e-01, time/batch = 0.7032s	
880/29450 (epoch 1.494), train_loss = 2.57212557, grad/param norm = 4.6506e-01, time/batch = 0.7141s	
881/29450 (epoch 1.496), train_loss = 2.43407626, grad/param norm = 3.3217e-01, time/batch = 0.7065s	
882/29450 (epoch 1.497), train_loss = 2.28977615, grad/param norm = 3.1632e-01, time/batch = 0.7032s	
883/29450 (epoch 1.499), train_loss = 2.29724298, grad/param norm = 2.5703e-01, time/batch = 0.7023s	
884/29450 (epoch 1.501), train_loss = 2.43424330, grad/param norm = 2.4666e-01, time/batch = 0.6893s	
885/29450 (epoch 1.503), train_loss = 2.35678254, grad/param norm = 3.4734e-01, time/batch = 0.6920s	
886/29450 (epoch 1.504), train_loss = 2.40402872, grad/param norm = 3.6569e-01, time/batch = 0.6885s	
887/29450 (epoch 1.506), train_loss = 2.43418639, grad/param norm = 3.1750e-01, time/batch = 0.6888s	
888/29450 (epoch 1.508), train_loss = 2.29360467, grad/param norm = 2.4044e-01, time/batch = 0.6850s	
889/29450 (epoch 1.509), train_loss = 2.27986035, grad/param norm = 2.3284e-01, time/batch = 0.6865s	
890/29450 (epoch 1.511), train_loss = 2.45273670, grad/param norm = 2.3427e-01, time/batch = 0.7035s	
891/29450 (epoch 1.513), train_loss = 2.44234712, grad/param norm = 2.9834e-01, time/batch = 0.6984s	
892/29450 (epoch 1.514), train_loss = 2.32967748, grad/param norm = 2.9073e-01, time/batch = 0.6889s	
893/29450 (epoch 1.516), train_loss = 2.47184188, grad/param norm = 2.9451e-01, time/batch = 0.6860s	
894/29450 (epoch 1.518), train_loss = 2.60827003, grad/param norm = 3.0207e-01, time/batch = 0.6791s	
895/29450 (epoch 1.520), train_loss = 2.25902138, grad/param norm = 2.6976e-01, time/batch = 0.6921s	
896/29450 (epoch 1.521), train_loss = 2.52288257, grad/param norm = 2.8939e-01, time/batch = 0.7032s	
897/29450 (epoch 1.523), train_loss = 2.50757901, grad/param norm = 2.6382e-01, time/batch = 0.6852s	
898/29450 (epoch 1.525), train_loss = 2.56965263, grad/param norm = 2.8104e-01, time/batch = 0.6816s	
899/29450 (epoch 1.526), train_loss = 2.42472359, grad/param norm = 3.2054e-01, time/batch = 0.6939s	
900/29450 (epoch 1.528), train_loss = 2.42674152, grad/param norm = 2.4942e-01, time/batch = 0.6866s	
901/29450 (epoch 1.530), train_loss = 2.41201733, grad/param norm = 2.9910e-01, time/batch = 0.6955s	
902/29450 (epoch 1.531), train_loss = 2.24775882, grad/param norm = 2.4281e-01, time/batch = 0.6862s	
903/29450 (epoch 1.533), train_loss = 2.34335007, grad/param norm = 2.8890e-01, time/batch = 0.6883s	
904/29450 (epoch 1.535), train_loss = 2.99457794, grad/param norm = 4.0239e-01, time/batch = 0.6843s	
905/29450 (epoch 1.537), train_loss = 2.61544671, grad/param norm = 5.4539e-01, time/batch = 0.6879s	
906/29450 (epoch 1.538), train_loss = 2.47012366, grad/param norm = 3.8414e-01, time/batch = 0.6891s	
907/29450 (epoch 1.540), train_loss = 2.62159495, grad/param norm = 3.2744e-01, time/batch = 0.6879s	
908/29450 (epoch 1.542), train_loss = 2.52654723, grad/param norm = 3.3057e-01, time/batch = 0.6904s	
909/29450 (epoch 1.543), train_loss = 2.35323417, grad/param norm = 2.3534e-01, time/batch = 0.6893s	
910/29450 (epoch 1.545), train_loss = 2.26913568, grad/param norm = 2.1028e-01, time/batch = 0.6876s	
911/29450 (epoch 1.547), train_loss = 2.40082801, grad/param norm = 2.1681e-01, time/batch = 0.6919s	
912/29450 (epoch 1.548), train_loss = 2.24812571, grad/param norm = 2.4984e-01, time/batch = 0.6922s	
913/29450 (epoch 1.550), train_loss = 2.33411044, grad/param norm = 2.8411e-01, time/batch = 0.7138s	
914/29450 (epoch 1.552), train_loss = 2.29217438, grad/param norm = 2.4023e-01, time/batch = 0.6922s	
915/29450 (epoch 1.553), train_loss = 2.38795171, grad/param norm = 2.7691e-01, time/batch = 0.6859s	
916/29450 (epoch 1.555), train_loss = 2.45799983, grad/param norm = 3.0845e-01, time/batch = 0.6850s	
917/29450 (epoch 1.557), train_loss = 2.42828045, grad/param norm = 3.0520e-01, time/batch = 0.6886s	
918/29450 (epoch 1.559), train_loss = 2.23252338, grad/param norm = 3.0966e-01, time/batch = 0.6842s	
919/29450 (epoch 1.560), train_loss = 2.42228531, grad/param norm = 3.4369e-01, time/batch = 0.6802s	
920/29450 (epoch 1.562), train_loss = 2.31423125, grad/param norm = 2.5721e-01, time/batch = 0.6852s	
921/29450 (epoch 1.564), train_loss = 2.43537547, grad/param norm = 2.6139e-01, time/batch = 0.7123s	
922/29450 (epoch 1.565), train_loss = 2.53370948, grad/param norm = 3.2008e-01, time/batch = 0.7143s	
923/29450 (epoch 1.567), train_loss = 2.47515832, grad/param norm = 3.3506e-01, time/batch = 0.7168s	
924/29450 (epoch 1.569), train_loss = 2.29487065, grad/param norm = 3.2786e-01, time/batch = 0.6879s	
925/29450 (epoch 1.570), train_loss = 2.59140413, grad/param norm = 2.8977e-01, time/batch = 0.6886s	
926/29450 (epoch 1.572), train_loss = 2.32922382, grad/param norm = 2.5897e-01, time/batch = 0.6872s	
927/29450 (epoch 1.574), train_loss = 2.30892714, grad/param norm = 3.0093e-01, time/batch = 0.6942s	
928/29450 (epoch 1.576), train_loss = 2.41287665, grad/param norm = 3.4283e-01, time/batch = 0.7031s	
929/29450 (epoch 1.577), train_loss = 2.55540750, grad/param norm = 3.1324e-01, time/batch = 0.6866s	
930/29450 (epoch 1.579), train_loss = 2.28047310, grad/param norm = 3.1427e-01, time/batch = 0.6967s	
931/29450 (epoch 1.581), train_loss = 2.52580656, grad/param norm = 3.1343e-01, time/batch = 0.6944s	
932/29450 (epoch 1.582), train_loss = 2.19066009, grad/param norm = 2.8344e-01, time/batch = 0.7059s	
933/29450 (epoch 1.584), train_loss = 2.30778016, grad/param norm = 2.4238e-01, time/batch = 0.7176s	
934/29450 (epoch 1.586), train_loss = 2.45590713, grad/param norm = 2.4648e-01, time/batch = 0.7181s	
935/29450 (epoch 1.587), train_loss = 2.63750152, grad/param norm = 2.6658e-01, time/batch = 0.7187s	
936/29450 (epoch 1.589), train_loss = 2.37770503, grad/param norm = 2.6658e-01, time/batch = 0.7160s	
937/29450 (epoch 1.591), train_loss = 2.27456325, grad/param norm = 2.5299e-01, time/batch = 0.7118s	
938/29450 (epoch 1.593), train_loss = 2.37920005, grad/param norm = 2.5927e-01, time/batch = 0.7120s	
939/29450 (epoch 1.594), train_loss = 2.19775465, grad/param norm = 2.4627e-01, time/batch = 0.7088s	
940/29450 (epoch 1.596), train_loss = 2.25498582, grad/param norm = 2.6775e-01, time/batch = 0.7026s	
941/29450 (epoch 1.598), train_loss = 2.37464779, grad/param norm = 2.8825e-01, time/batch = 0.6945s	
942/29450 (epoch 1.599), train_loss = 2.37016686, grad/param norm = 3.0958e-01, time/batch = 0.6914s	
943/29450 (epoch 1.601), train_loss = 2.34187146, grad/param norm = 2.3766e-01, time/batch = 0.6831s	
944/29450 (epoch 1.603), train_loss = 2.43175590, grad/param norm = 2.5240e-01, time/batch = 0.6849s	
945/29450 (epoch 1.604), train_loss = 2.34832633, grad/param norm = 2.2399e-01, time/batch = 0.6895s	
946/29450 (epoch 1.606), train_loss = 2.43828948, grad/param norm = 2.2744e-01, time/batch = 0.6871s	
947/29450 (epoch 1.608), train_loss = 2.27540837, grad/param norm = 2.3265e-01, time/batch = 0.6839s	
948/29450 (epoch 1.610), train_loss = 2.36249735, grad/param norm = 2.5093e-01, time/batch = 0.6872s	
949/29450 (epoch 1.611), train_loss = 2.22551457, grad/param norm = 2.7878e-01, time/batch = 0.6902s	
950/29450 (epoch 1.613), train_loss = 2.15676731, grad/param norm = 2.8119e-01, time/batch = 0.6867s	
951/29450 (epoch 1.615), train_loss = 2.24475781, grad/param norm = 2.8765e-01, time/batch = 0.6857s	
952/29450 (epoch 1.616), train_loss = 2.26195905, grad/param norm = 3.2238e-01, time/batch = 0.6848s	
953/29450 (epoch 1.618), train_loss = 2.02226448, grad/param norm = 2.3976e-01, time/batch = 0.6849s	
954/29450 (epoch 1.620), train_loss = 2.49413147, grad/param norm = 2.3574e-01, time/batch = 0.6851s	
955/29450 (epoch 1.621), train_loss = 2.27535824, grad/param norm = 2.4167e-01, time/batch = 0.6907s	
956/29450 (epoch 1.623), train_loss = 2.24085488, grad/param norm = 2.5927e-01, time/batch = 0.6872s	
957/29450 (epoch 1.625), train_loss = 2.25329822, grad/param norm = 2.6995e-01, time/batch = 0.6853s	
958/29450 (epoch 1.626), train_loss = 2.37962063, grad/param norm = 2.7815e-01, time/batch = 0.6864s	
959/29450 (epoch 1.628), train_loss = 2.29776468, grad/param norm = 3.2269e-01, time/batch = 0.6897s	
960/29450 (epoch 1.630), train_loss = 2.25346993, grad/param norm = 2.6456e-01, time/batch = 0.6865s	
961/29450 (epoch 1.632), train_loss = 2.33944524, grad/param norm = 2.5045e-01, time/batch = 0.6883s	
962/29450 (epoch 1.633), train_loss = 2.47140025, grad/param norm = 2.9960e-01, time/batch = 0.6898s	
963/29450 (epoch 1.635), train_loss = 2.02808470, grad/param norm = 2.4987e-01, time/batch = 0.6846s	
964/29450 (epoch 1.637), train_loss = 2.27977769, grad/param norm = 2.5888e-01, time/batch = 0.6887s	
965/29450 (epoch 1.638), train_loss = 2.06021160, grad/param norm = 3.0189e-01, time/batch = 0.6884s	
966/29450 (epoch 1.640), train_loss = 2.45416660, grad/param norm = 3.8963e-01, time/batch = 0.6880s	
967/29450 (epoch 1.642), train_loss = 2.38355138, grad/param norm = 3.2196e-01, time/batch = 0.6893s	
968/29450 (epoch 1.643), train_loss = 2.31638086, grad/param norm = 2.8116e-01, time/batch = 0.6887s	
969/29450 (epoch 1.645), train_loss = 2.32845264, grad/param norm = 2.7661e-01, time/batch = 0.6941s	
970/29450 (epoch 1.647), train_loss = 2.62054919, grad/param norm = 2.7298e-01, time/batch = 0.6915s	
971/29450 (epoch 1.649), train_loss = 2.56137368, grad/param norm = 5.3933e-01, time/batch = 0.6910s	
972/29450 (epoch 1.650), train_loss = 2.44728946, grad/param norm = 3.5754e-01, time/batch = 0.6984s	
973/29450 (epoch 1.652), train_loss = 2.34672407, grad/param norm = 2.5198e-01, time/batch = 0.6912s	
974/29450 (epoch 1.654), train_loss = 2.40941215, grad/param norm = 2.4239e-01, time/batch = 0.6865s	
975/29450 (epoch 1.655), train_loss = 2.33108994, grad/param norm = 2.8579e-01, time/batch = 0.7202s	
976/29450 (epoch 1.657), train_loss = 2.32275754, grad/param norm = 3.3304e-01, time/batch = 0.7048s	
977/29450 (epoch 1.659), train_loss = 2.51152990, grad/param norm = 2.5060e-01, time/batch = 0.7059s	
978/29450 (epoch 1.660), train_loss = 2.12674746, grad/param norm = 2.5327e-01, time/batch = 0.7136s	
979/29450 (epoch 1.662), train_loss = 2.14599046, grad/param norm = 2.2227e-01, time/batch = 0.7075s	
980/29450 (epoch 1.664), train_loss = 2.26132635, grad/param norm = 2.3113e-01, time/batch = 0.7012s	
981/29450 (epoch 1.666), train_loss = 2.32857334, grad/param norm = 2.5342e-01, time/batch = 0.6955s	
982/29450 (epoch 1.667), train_loss = 2.50065435, grad/param norm = 3.5397e-01, time/batch = 0.6931s	
983/29450 (epoch 1.669), train_loss = 2.37212107, grad/param norm = 2.2603e-01, time/batch = 0.7068s	
984/29450 (epoch 1.671), train_loss = 2.10271130, grad/param norm = 2.4522e-01, time/batch = 0.6881s	
985/29450 (epoch 1.672), train_loss = 2.11278841, grad/param norm = 2.1298e-01, time/batch = 0.6889s	
986/29450 (epoch 1.674), train_loss = 2.28918527, grad/param norm = 2.6933e-01, time/batch = 0.6947s	
987/29450 (epoch 1.676), train_loss = 2.31583743, grad/param norm = 2.7493e-01, time/batch = 0.7044s	
988/29450 (epoch 1.677), train_loss = 2.45561688, grad/param norm = 3.4065e-01, time/batch = 0.7067s	
989/29450 (epoch 1.679), train_loss = 2.22149673, grad/param norm = 2.9665e-01, time/batch = 0.6985s	
990/29450 (epoch 1.681), train_loss = 2.47933648, grad/param norm = 2.4989e-01, time/batch = 0.7097s	
991/29450 (epoch 1.683), train_loss = 2.25845153, grad/param norm = 2.3709e-01, time/batch = 0.7102s	
992/29450 (epoch 1.684), train_loss = 2.27830456, grad/param norm = 2.6154e-01, time/batch = 0.7073s	
993/29450 (epoch 1.686), train_loss = 2.39106758, grad/param norm = 2.4818e-01, time/batch = 0.7048s	
994/29450 (epoch 1.688), train_loss = 2.27498160, grad/param norm = 2.8715e-01, time/batch = 0.7051s	
995/29450 (epoch 1.689), train_loss = 2.18025971, grad/param norm = 2.6022e-01, time/batch = 0.7059s	
996/29450 (epoch 1.691), train_loss = 2.20473535, grad/param norm = 2.7087e-01, time/batch = 0.7053s	
997/29450 (epoch 1.693), train_loss = 2.45796893, grad/param norm = 3.3288e-01, time/batch = 0.7199s	
998/29450 (epoch 1.694), train_loss = 2.24563980, grad/param norm = 2.6656e-01, time/batch = 0.7067s	
999/29450 (epoch 1.696), train_loss = 2.54056113, grad/param norm = 2.3719e-01, time/batch = 0.6917s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_torproject_epoch1.70_2.3270.t7	
1000/29450 (epoch 1.698), train_loss = 2.33299160, grad/param norm = 3.0757e-01, time/batch = 0.6867s	
1001/29450 (epoch 1.699), train_loss = 2.51937016, grad/param norm = 3.2020e-01, time/batch = 0.7547s	
1002/29450 (epoch 1.701), train_loss = 2.19092566, grad/param norm = 2.5054e-01, time/batch = 0.7209s	
1003/29450 (epoch 1.703), train_loss = 2.28796930, grad/param norm = 3.1580e-01, time/batch = 0.7128s	
1004/29450 (epoch 1.705), train_loss = 2.30962390, grad/param norm = 2.8586e-01, time/batch = 0.7180s	
1005/29450 (epoch 1.706), train_loss = 2.19455482, grad/param norm = 2.7552e-01, time/batch = 0.7048s	
1006/29450 (epoch 1.708), train_loss = 2.27682319, grad/param norm = 2.3881e-01, time/batch = 0.6963s	
1007/29450 (epoch 1.710), train_loss = 2.36288236, grad/param norm = 2.5041e-01, time/batch = 0.6982s	
1008/29450 (epoch 1.711), train_loss = 2.34036884, grad/param norm = 2.5619e-01, time/batch = 0.7249s	
1009/29450 (epoch 1.713), train_loss = 2.30612918, grad/param norm = 2.6386e-01, time/batch = 0.7081s	
1010/29450 (epoch 1.715), train_loss = 2.46095270, grad/param norm = 2.7199e-01, time/batch = 0.6971s	
1011/29450 (epoch 1.716), train_loss = 2.21403988, grad/param norm = 2.1904e-01, time/batch = 0.7005s	
1012/29450 (epoch 1.718), train_loss = 2.30967402, grad/param norm = 2.6360e-01, time/batch = 0.7112s	
1013/29450 (epoch 1.720), train_loss = 2.20782913, grad/param norm = 3.1482e-01, time/batch = 0.6942s	
1014/29450 (epoch 1.722), train_loss = 2.23586242, grad/param norm = 3.8646e-01, time/batch = 0.7058s	
1015/29450 (epoch 1.723), train_loss = 2.33371028, grad/param norm = 3.4503e-01, time/batch = 0.6980s	
1016/29450 (epoch 1.725), train_loss = 2.19512967, grad/param norm = 2.7609e-01, time/batch = 0.7067s	
1017/29450 (epoch 1.727), train_loss = 2.28302293, grad/param norm = 2.4055e-01, time/batch = 0.6997s	
1018/29450 (epoch 1.728), train_loss = 2.24246036, grad/param norm = 2.4291e-01, time/batch = 0.7027s	
1019/29450 (epoch 1.730), train_loss = 2.44371840, grad/param norm = 2.2296e-01, time/batch = 0.6974s	
1020/29450 (epoch 1.732), train_loss = 2.29003294, grad/param norm = 2.0492e-01, time/batch = 0.6937s	
1021/29450 (epoch 1.733), train_loss = 2.43861235, grad/param norm = 3.0190e-01, time/batch = 0.6963s	
1022/29450 (epoch 1.735), train_loss = 2.31928154, grad/param norm = 3.2023e-01, time/batch = 0.6963s	
1023/29450 (epoch 1.737), train_loss = 2.33969876, grad/param norm = 3.1692e-01, time/batch = 0.6960s	
1024/29450 (epoch 1.739), train_loss = 2.35523720, grad/param norm = 2.9150e-01, time/batch = 0.6956s	
1025/29450 (epoch 1.740), train_loss = 2.47385177, grad/param norm = 2.5599e-01, time/batch = 0.6974s	
1026/29450 (epoch 1.742), train_loss = 2.36772391, grad/param norm = 2.5422e-01, time/batch = 0.6968s	
1027/29450 (epoch 1.744), train_loss = 2.41286607, grad/param norm = 2.7999e-01, time/batch = 0.7018s	
1028/29450 (epoch 1.745), train_loss = 2.25742570, grad/param norm = 3.4871e-01, time/batch = 0.7265s	
1029/29450 (epoch 1.747), train_loss = 2.18558322, grad/param norm = 2.6187e-01, time/batch = 0.7068s	
1030/29450 (epoch 1.749), train_loss = 2.41944343, grad/param norm = 2.3319e-01, time/batch = 0.7002s	
1031/29450 (epoch 1.750), train_loss = 2.35887858, grad/param norm = 2.3785e-01, time/batch = 0.7000s	
1032/29450 (epoch 1.752), train_loss = 2.33718749, grad/param norm = 2.2533e-01, time/batch = 0.7021s	
1033/29450 (epoch 1.754), train_loss = 2.14050969, grad/param norm = 2.6013e-01, time/batch = 0.7018s	
1034/29450 (epoch 1.756), train_loss = 2.43000392, grad/param norm = 2.6236e-01, time/batch = 0.7059s	
1035/29450 (epoch 1.757), train_loss = 2.53437011, grad/param norm = 3.2606e-01, time/batch = 0.7010s	
1036/29450 (epoch 1.759), train_loss = 2.43514740, grad/param norm = 3.2303e-01, time/batch = 0.7034s	
1037/29450 (epoch 1.761), train_loss = 2.54072566, grad/param norm = 2.9553e-01, time/batch = 0.6999s	
1038/29450 (epoch 1.762), train_loss = 2.33418676, grad/param norm = 2.4794e-01, time/batch = 0.6991s	
1039/29450 (epoch 1.764), train_loss = 2.42151256, grad/param norm = 2.6656e-01, time/batch = 0.7049s	
1040/29450 (epoch 1.766), train_loss = 2.41293119, grad/param norm = 2.4885e-01, time/batch = 0.7026s	
1041/29450 (epoch 1.767), train_loss = 2.27547686, grad/param norm = 2.1981e-01, time/batch = 0.7028s	
1042/29450 (epoch 1.769), train_loss = 2.64173012, grad/param norm = 3.0326e-01, time/batch = 0.6995s	
1043/29450 (epoch 1.771), train_loss = 2.50047153, grad/param norm = 2.7153e-01, time/batch = 0.7001s	
1044/29450 (epoch 1.772), train_loss = 2.31989908, grad/param norm = 2.2650e-01, time/batch = 0.7031s	
1045/29450 (epoch 1.774), train_loss = 2.06505043, grad/param norm = 2.3024e-01, time/batch = 0.7064s	
1046/29450 (epoch 1.776), train_loss = 2.34926411, grad/param norm = 2.4405e-01, time/batch = 0.6993s	
1047/29450 (epoch 1.778), train_loss = 2.36041082, grad/param norm = 2.2232e-01, time/batch = 0.7137s	
1048/29450 (epoch 1.779), train_loss = 2.36822790, grad/param norm = 2.4349e-01, time/batch = 0.7064s	
1049/29450 (epoch 1.781), train_loss = 2.08935289, grad/param norm = 2.7145e-01, time/batch = 0.6978s	
1050/29450 (epoch 1.783), train_loss = 2.17275939, grad/param norm = 2.8949e-01, time/batch = 0.7120s	
1051/29450 (epoch 1.784), train_loss = 2.25269675, grad/param norm = 2.3434e-01, time/batch = 0.7122s	
1052/29450 (epoch 1.786), train_loss = 2.16734713, grad/param norm = 2.3433e-01, time/batch = 0.7099s	
1053/29450 (epoch 1.788), train_loss = 2.47465673, grad/param norm = 3.4394e-01, time/batch = 0.7097s	
1054/29450 (epoch 1.789), train_loss = 2.44023610, grad/param norm = 2.8300e-01, time/batch = 0.6998s	
1055/29450 (epoch 1.791), train_loss = 2.11476397, grad/param norm = 3.0605e-01, time/batch = 0.7040s	
1056/29450 (epoch 1.793), train_loss = 2.30649107, grad/param norm = 3.3674e-01, time/batch = 0.7013s	
1057/29450 (epoch 1.795), train_loss = 2.36149346, grad/param norm = 3.0170e-01, time/batch = 0.6984s	
1058/29450 (epoch 1.796), train_loss = 2.28707207, grad/param norm = 2.4383e-01, time/batch = 0.7041s	
1059/29450 (epoch 1.798), train_loss = 2.26300984, grad/param norm = 2.1661e-01, time/batch = 0.6972s	
1060/29450 (epoch 1.800), train_loss = 2.06463797, grad/param norm = 2.5363e-01, time/batch = 0.6986s	
1061/29450 (epoch 1.801), train_loss = 2.30880881, grad/param norm = 2.7643e-01, time/batch = 0.7065s	
1062/29450 (epoch 1.803), train_loss = 2.34333415, grad/param norm = 2.7404e-01, time/batch = 0.7084s	
1063/29450 (epoch 1.805), train_loss = 2.30784071, grad/param norm = 2.2999e-01, time/batch = 0.6965s	
1064/29450 (epoch 1.806), train_loss = 2.26652383, grad/param norm = 2.4534e-01, time/batch = 0.6962s	
1065/29450 (epoch 1.808), train_loss = 2.56119277, grad/param norm = 2.9381e-01, time/batch = 0.7030s	
1066/29450 (epoch 1.810), train_loss = 2.45382655, grad/param norm = 3.0803e-01, time/batch = 0.6994s	
1067/29450 (epoch 1.812), train_loss = 2.24700220, grad/param norm = 2.4824e-01, time/batch = 0.7104s	
1068/29450 (epoch 1.813), train_loss = 2.44531484, grad/param norm = 2.2572e-01, time/batch = 0.7252s	
1069/29450 (epoch 1.815), train_loss = 2.41801793, grad/param norm = 2.2872e-01, time/batch = 0.7005s	
1070/29450 (epoch 1.817), train_loss = 2.30045503, grad/param norm = 2.4452e-01, time/batch = 0.6981s	
1071/29450 (epoch 1.818), train_loss = 2.13648377, grad/param norm = 2.5022e-01, time/batch = 0.7027s	
1072/29450 (epoch 1.820), train_loss = 2.26076863, grad/param norm = 2.7918e-01, time/batch = 0.7010s	
1073/29450 (epoch 1.822), train_loss = 2.39110374, grad/param norm = 2.9825e-01, time/batch = 0.7043s	
1074/29450 (epoch 1.823), train_loss = 2.25952707, grad/param norm = 2.3331e-01, time/batch = 0.6981s	
1075/29450 (epoch 1.825), train_loss = 2.16599783, grad/param norm = 2.2222e-01, time/batch = 0.6994s	
1076/29450 (epoch 1.827), train_loss = 2.29478884, grad/param norm = 2.3561e-01, time/batch = 0.6967s	
1077/29450 (epoch 1.829), train_loss = 2.21924715, grad/param norm = 2.6512e-01, time/batch = 0.6984s	
1078/29450 (epoch 1.830), train_loss = 2.48132684, grad/param norm = 2.7214e-01, time/batch = 0.6970s	
1079/29450 (epoch 1.832), train_loss = 2.48114761, grad/param norm = 2.8205e-01, time/batch = 0.6964s	
1080/29450 (epoch 1.834), train_loss = 2.18141303, grad/param norm = 2.9792e-01, time/batch = 0.6935s	
1081/29450 (epoch 1.835), train_loss = 2.13528735, grad/param norm = 2.6674e-01, time/batch = 0.7008s	
1082/29450 (epoch 1.837), train_loss = 2.22308009, grad/param norm = 2.3452e-01, time/batch = 0.7056s	
1083/29450 (epoch 1.839), train_loss = 2.31049731, grad/param norm = 2.6201e-01, time/batch = 0.7235s	
1084/29450 (epoch 1.840), train_loss = 2.35613137, grad/param norm = 2.6067e-01, time/batch = 0.7348s	
1085/29450 (epoch 1.842), train_loss = 2.08257748, grad/param norm = 2.9111e-01, time/batch = 0.7147s	
1086/29450 (epoch 1.844), train_loss = 2.09026009, grad/param norm = 2.3828e-01, time/batch = 0.7031s	
1087/29450 (epoch 1.846), train_loss = 2.24987021, grad/param norm = 2.0117e-01, time/batch = 0.7184s	
1088/29450 (epoch 1.847), train_loss = 2.24245101, grad/param norm = 2.6652e-01, time/batch = 0.7202s	
1089/29450 (epoch 1.849), train_loss = 2.22888910, grad/param norm = 2.6255e-01, time/batch = 0.7062s	
1090/29450 (epoch 1.851), train_loss = 2.33095490, grad/param norm = 2.3580e-01, time/batch = 0.7276s	
1091/29450 (epoch 1.852), train_loss = 2.29286542, grad/param norm = 2.2867e-01, time/batch = 0.7191s	
1092/29450 (epoch 1.854), train_loss = 2.11712105, grad/param norm = 2.5178e-01, time/batch = 0.6981s	
1093/29450 (epoch 1.856), train_loss = 2.12289173, grad/param norm = 2.6490e-01, time/batch = 0.7023s	
1094/29450 (epoch 1.857), train_loss = 2.05544058, grad/param norm = 2.4967e-01, time/batch = 0.6964s	
1095/29450 (epoch 1.859), train_loss = 2.09891709, grad/param norm = 2.9392e-01, time/batch = 0.7140s	
1096/29450 (epoch 1.861), train_loss = 2.28610560, grad/param norm = 3.1834e-01, time/batch = 0.7039s	
1097/29450 (epoch 1.862), train_loss = 2.20305267, grad/param norm = 3.0123e-01, time/batch = 0.7004s	
1098/29450 (epoch 1.864), train_loss = 2.27579895, grad/param norm = 2.9318e-01, time/batch = 0.7009s	
1099/29450 (epoch 1.866), train_loss = 2.25850255, grad/param norm = 3.1632e-01, time/batch = 0.6999s	
1100/29450 (epoch 1.868), train_loss = 2.41092988, grad/param norm = 2.8214e-01, time/batch = 0.6993s	
1101/29450 (epoch 1.869), train_loss = 2.23919982, grad/param norm = 2.8287e-01, time/batch = 0.7125s	
1102/29450 (epoch 1.871), train_loss = 2.12841233, grad/param norm = 3.0177e-01, time/batch = 0.7102s	
1103/29450 (epoch 1.873), train_loss = 2.30446537, grad/param norm = 2.6887e-01, time/batch = 0.7061s	
1104/29450 (epoch 1.874), train_loss = 2.14084060, grad/param norm = 2.3489e-01, time/batch = 0.7007s	
1105/29450 (epoch 1.876), train_loss = 2.13724079, grad/param norm = 2.5763e-01, time/batch = 0.6925s	
1106/29450 (epoch 1.878), train_loss = 2.36281431, grad/param norm = 3.0554e-01, time/batch = 0.6930s	
1107/29450 (epoch 1.879), train_loss = 2.50708636, grad/param norm = 2.7309e-01, time/batch = 0.6950s	
1108/29450 (epoch 1.881), train_loss = 2.32178605, grad/param norm = 2.7837e-01, time/batch = 0.6940s	
1109/29450 (epoch 1.883), train_loss = 2.37617623, grad/param norm = 2.7050e-01, time/batch = 0.6989s	
1110/29450 (epoch 1.885), train_loss = 2.32590401, grad/param norm = 2.2658e-01, time/batch = 0.7049s	
1111/29450 (epoch 1.886), train_loss = 2.26930429, grad/param norm = 2.1125e-01, time/batch = 0.7088s	
1112/29450 (epoch 1.888), train_loss = 2.13921152, grad/param norm = 2.8617e-01, time/batch = 0.6990s	
1113/29450 (epoch 1.890), train_loss = 2.28902749, grad/param norm = 2.7035e-01, time/batch = 0.6970s	
1114/29450 (epoch 1.891), train_loss = 2.46624650, grad/param norm = 2.4609e-01, time/batch = 0.7012s	
1115/29450 (epoch 1.893), train_loss = 2.17372672, grad/param norm = 1.9715e-01, time/batch = 0.6988s	
1116/29450 (epoch 1.895), train_loss = 2.41503448, grad/param norm = 2.7454e-01, time/batch = 0.6963s	
1117/29450 (epoch 1.896), train_loss = 2.27755329, grad/param norm = 2.6479e-01, time/batch = 0.6997s	
1118/29450 (epoch 1.898), train_loss = 2.21985894, grad/param norm = 2.3727e-01, time/batch = 0.6945s	
1119/29450 (epoch 1.900), train_loss = 2.48689185, grad/param norm = 3.1903e-01, time/batch = 0.6962s	
1120/29450 (epoch 1.902), train_loss = 2.20380853, grad/param norm = 2.7380e-01, time/batch = 0.7245s	
1121/29450 (epoch 1.903), train_loss = 2.20853275, grad/param norm = 2.4510e-01, time/batch = 0.7286s	
1122/29450 (epoch 1.905), train_loss = 2.21885357, grad/param norm = 2.3624e-01, time/batch = 0.7293s	
1123/29450 (epoch 1.907), train_loss = 2.42278624, grad/param norm = 2.9861e-01, time/batch = 0.7283s	
1124/29450 (epoch 1.908), train_loss = 2.47196846, grad/param norm = 2.3820e-01, time/batch = 0.7313s	
1125/29450 (epoch 1.910), train_loss = 2.28421456, grad/param norm = 2.2296e-01, time/batch = 0.7299s	
1126/29450 (epoch 1.912), train_loss = 2.16625617, grad/param norm = 2.9472e-01, time/batch = 0.7260s	
1127/29450 (epoch 1.913), train_loss = 2.22856659, grad/param norm = 3.4305e-01, time/batch = 0.7265s	
1128/29450 (epoch 1.915), train_loss = 2.25690070, grad/param norm = 2.9239e-01, time/batch = 0.7271s	
1129/29450 (epoch 1.917), train_loss = 2.22999572, grad/param norm = 2.5057e-01, time/batch = 0.7272s	
1130/29450 (epoch 1.919), train_loss = 2.24348157, grad/param norm = 2.7384e-01, time/batch = 0.7075s	
1131/29450 (epoch 1.920), train_loss = 2.39830231, grad/param norm = 2.6946e-01, time/batch = 0.7301s	
1132/29450 (epoch 1.922), train_loss = 2.32014294, grad/param norm = 2.5580e-01, time/batch = 0.7069s	
1133/29450 (epoch 1.924), train_loss = 2.45182712, grad/param norm = 2.9819e-01, time/batch = 0.6972s	
1134/29450 (epoch 1.925), train_loss = 2.32755005, grad/param norm = 3.0651e-01, time/batch = 0.7059s	
1135/29450 (epoch 1.927), train_loss = 2.49709443, grad/param norm = 2.8137e-01, time/batch = 0.6996s	
1136/29450 (epoch 1.929), train_loss = 2.69371581, grad/param norm = 6.0419e-01, time/batch = 0.6969s	
1137/29450 (epoch 1.930), train_loss = 2.60635238, grad/param norm = 4.2000e-01, time/batch = 0.6961s	
1138/29450 (epoch 1.932), train_loss = 2.53088272, grad/param norm = 3.0246e-01, time/batch = 0.7075s	
1139/29450 (epoch 1.934), train_loss = 2.28289038, grad/param norm = 2.5725e-01, time/batch = 0.7048s	
1140/29450 (epoch 1.935), train_loss = 2.33818621, grad/param norm = 2.5487e-01, time/batch = 0.7035s	
1141/29450 (epoch 1.937), train_loss = 2.24634009, grad/param norm = 2.5099e-01, time/batch = 0.7287s	
1142/29450 (epoch 1.939), train_loss = 2.15481703, grad/param norm = 2.1336e-01, time/batch = 0.7090s	
1143/29450 (epoch 1.941), train_loss = 2.33481197, grad/param norm = 2.8344e-01, time/batch = 0.7055s	
1144/29450 (epoch 1.942), train_loss = 2.12139681, grad/param norm = 2.5485e-01, time/batch = 0.7012s	
1145/29450 (epoch 1.944), train_loss = 2.28932475, grad/param norm = 2.3856e-01, time/batch = 0.7229s	
1146/29450 (epoch 1.946), train_loss = 2.08781612, grad/param norm = 2.1421e-01, time/batch = 0.7166s	
1147/29450 (epoch 1.947), train_loss = 2.16817784, grad/param norm = 2.1253e-01, time/batch = 0.7213s	
1148/29450 (epoch 1.949), train_loss = 2.16230967, grad/param norm = 2.2625e-01, time/batch = 0.7113s	
1149/29450 (epoch 1.951), train_loss = 2.10456824, grad/param norm = 2.4884e-01, time/batch = 0.7057s	
1150/29450 (epoch 1.952), train_loss = 2.34458873, grad/param norm = 2.4716e-01, time/batch = 0.7142s	
1151/29450 (epoch 1.954), train_loss = 2.17351388, grad/param norm = 2.1871e-01, time/batch = 0.7364s	
1152/29450 (epoch 1.956), train_loss = 2.18394956, grad/param norm = 2.6672e-01, time/batch = 0.6995s	
1153/29450 (epoch 1.958), train_loss = 2.21884152, grad/param norm = 2.9380e-01, time/batch = 0.7044s	
1154/29450 (epoch 1.959), train_loss = 2.29782348, grad/param norm = 2.6800e-01, time/batch = 0.7004s	
1155/29450 (epoch 1.961), train_loss = 2.21593566, grad/param norm = 2.8785e-01, time/batch = 0.7000s	
1156/29450 (epoch 1.963), train_loss = 2.09740346, grad/param norm = 3.0869e-01, time/batch = 0.7050s	
1157/29450 (epoch 1.964), train_loss = 2.32341824, grad/param norm = 3.1483e-01, time/batch = 0.7011s	
1158/29450 (epoch 1.966), train_loss = 2.30704023, grad/param norm = 2.7224e-01, time/batch = 0.7045s	
1159/29450 (epoch 1.968), train_loss = 2.30350572, grad/param norm = 2.5307e-01, time/batch = 0.7021s	
1160/29450 (epoch 1.969), train_loss = 2.37363561, grad/param norm = 2.2927e-01, time/batch = 0.6971s	
1161/29450 (epoch 1.971), train_loss = 2.04609718, grad/param norm = 2.2507e-01, time/batch = 0.7107s	
1162/29450 (epoch 1.973), train_loss = 2.19464746, grad/param norm = 2.7698e-01, time/batch = 0.6982s	
1163/29450 (epoch 1.975), train_loss = 2.27662625, grad/param norm = 2.5724e-01, time/batch = 0.6977s	
1164/29450 (epoch 1.976), train_loss = 2.32325132, grad/param norm = 2.5138e-01, time/batch = 0.7218s	
1165/29450 (epoch 1.978), train_loss = 2.18720452, grad/param norm = 3.0954e-01, time/batch = 0.7110s	
1166/29450 (epoch 1.980), train_loss = 2.04484133, grad/param norm = 3.2061e-01, time/batch = 0.7124s	
1167/29450 (epoch 1.981), train_loss = 2.13280700, grad/param norm = 2.4089e-01, time/batch = 0.7251s	
1168/29450 (epoch 1.983), train_loss = 2.14350384, grad/param norm = 2.4835e-01, time/batch = 0.7331s	
1169/29450 (epoch 1.985), train_loss = 2.28681699, grad/param norm = 2.7617e-01, time/batch = 0.7343s	
1170/29450 (epoch 1.986), train_loss = 2.39583006, grad/param norm = 3.3226e-01, time/batch = 0.7106s	
1171/29450 (epoch 1.988), train_loss = 2.11335193, grad/param norm = 2.7288e-01, time/batch = 0.7177s	
1172/29450 (epoch 1.990), train_loss = 2.28785691, grad/param norm = 3.1205e-01, time/batch = 0.7100s	
1173/29450 (epoch 1.992), train_loss = 1.96058487, grad/param norm = 2.5985e-01, time/batch = 0.7177s	
1174/29450 (epoch 1.993), train_loss = 2.31396023, grad/param norm = 2.1368e-01, time/batch = 0.7123s	
1175/29450 (epoch 1.995), train_loss = 2.17971135, grad/param norm = 2.0726e-01, time/batch = 0.7309s	
1176/29450 (epoch 1.997), train_loss = 2.13789131, grad/param norm = 2.2858e-01, time/batch = 0.7249s	
1177/29450 (epoch 1.998), train_loss = 2.23070210, grad/param norm = 2.1397e-01, time/batch = 0.7233s	
1178/29450 (epoch 2.000), train_loss = 2.28572850, grad/param norm = 2.9129e-01, time/batch = 0.7027s	
1179/29450 (epoch 2.002), train_loss = 2.25853471, grad/param norm = 2.7628e-01, time/batch = 0.7084s	
1180/29450 (epoch 2.003), train_loss = 2.41844724, grad/param norm = 2.5129e-01, time/batch = 0.7273s	
1181/29450 (epoch 2.005), train_loss = 1.95900026, grad/param norm = 2.3691e-01, time/batch = 0.7083s	
1182/29450 (epoch 2.007), train_loss = 2.10243102, grad/param norm = 2.1222e-01, time/batch = 0.7008s	
1183/29450 (epoch 2.008), train_loss = 2.12282601, grad/param norm = 2.2798e-01, time/batch = 0.6981s	
1184/29450 (epoch 2.010), train_loss = 2.25117846, grad/param norm = 2.3129e-01, time/batch = 0.6952s	
1185/29450 (epoch 2.012), train_loss = 2.22479331, grad/param norm = 2.4556e-01, time/batch = 0.6979s	
1186/29450 (epoch 2.014), train_loss = 2.38054881, grad/param norm = 2.4601e-01, time/batch = 0.7024s	
1187/29450 (epoch 2.015), train_loss = 2.08880337, grad/param norm = 2.3385e-01, time/batch = 0.7169s	
1188/29450 (epoch 2.017), train_loss = 2.18658835, grad/param norm = 2.5066e-01, time/batch = 0.7058s	
1189/29450 (epoch 2.019), train_loss = 2.00732546, grad/param norm = 2.8033e-01, time/batch = 0.7083s	
1190/29450 (epoch 2.020), train_loss = 2.24823770, grad/param norm = 3.5292e-01, time/batch = 0.7267s	
1191/29450 (epoch 2.022), train_loss = 2.18669850, grad/param norm = 3.5099e-01, time/batch = 0.6995s	
1192/29450 (epoch 2.024), train_loss = 2.23855071, grad/param norm = 2.5878e-01, time/batch = 0.6956s	
1193/29450 (epoch 2.025), train_loss = 2.20226746, grad/param norm = 2.9711e-01, time/batch = 0.6983s	
1194/29450 (epoch 2.027), train_loss = 2.17298842, grad/param norm = 2.2372e-01, time/batch = 0.7024s	
1195/29450 (epoch 2.029), train_loss = 2.26463484, grad/param norm = 2.3720e-01, time/batch = 0.7097s	
1196/29450 (epoch 2.031), train_loss = 1.98565604, grad/param norm = 2.3806e-01, time/batch = 0.7046s	
1197/29450 (epoch 2.032), train_loss = 2.12025928, grad/param norm = 2.3008e-01, time/batch = 0.7179s	
1198/29450 (epoch 2.034), train_loss = 2.06249233, grad/param norm = 2.2540e-01, time/batch = 0.7168s	
1199/29450 (epoch 2.036), train_loss = 2.18723877, grad/param norm = 2.3322e-01, time/batch = 0.7158s	
1200/29450 (epoch 2.037), train_loss = 2.36897870, grad/param norm = 2.6577e-01, time/batch = 0.7257s	
1201/29450 (epoch 2.039), train_loss = 2.08066083, grad/param norm = 2.5653e-01, time/batch = 0.7048s	
1202/29450 (epoch 2.041), train_loss = 2.22076624, grad/param norm = 3.3214e-01, time/batch = 0.7156s	
1203/29450 (epoch 2.042), train_loss = 2.13630588, grad/param norm = 3.5183e-01, time/batch = 0.6999s	
1204/29450 (epoch 2.044), train_loss = 2.16774053, grad/param norm = 2.0027e-01, time/batch = 0.6982s	
1205/29450 (epoch 2.046), train_loss = 2.40508900, grad/param norm = 3.0695e-01, time/batch = 0.6992s	
1206/29450 (epoch 2.048), train_loss = 2.15025920, grad/param norm = 3.3292e-01, time/batch = 0.6993s	
1207/29450 (epoch 2.049), train_loss = 2.34386773, grad/param norm = 2.3513e-01, time/batch = 0.6998s	
1208/29450 (epoch 2.051), train_loss = 2.27012820, grad/param norm = 2.5299e-01, time/batch = 0.7052s	
1209/29450 (epoch 2.053), train_loss = 2.02495327, grad/param norm = 2.2989e-01, time/batch = 0.7050s	
1210/29450 (epoch 2.054), train_loss = 2.16466058, grad/param norm = 2.3045e-01, time/batch = 0.7007s	
1211/29450 (epoch 2.056), train_loss = 2.23322921, grad/param norm = 2.5077e-01, time/batch = 0.7094s	
1212/29450 (epoch 2.058), train_loss = 2.22156388, grad/param norm = 2.4660e-01, time/batch = 0.7042s	
1213/29450 (epoch 2.059), train_loss = 2.05446688, grad/param norm = 2.6623e-01, time/batch = 0.7036s	
1214/29450 (epoch 2.061), train_loss = 1.98308183, grad/param norm = 2.3783e-01, time/batch = 0.7083s	
1215/29450 (epoch 2.063), train_loss = 2.20678442, grad/param norm = 2.2037e-01, time/batch = 0.7158s	
1216/29450 (epoch 2.065), train_loss = 2.13450271, grad/param norm = 2.6068e-01, time/batch = 0.7079s	
1217/29450 (epoch 2.066), train_loss = 2.09583600, grad/param norm = 3.2885e-01, time/batch = 0.7031s	
1218/29450 (epoch 2.068), train_loss = 2.31765024, grad/param norm = 2.7290e-01, time/batch = 0.6977s	
1219/29450 (epoch 2.070), train_loss = 2.17530479, grad/param norm = 2.3505e-01, time/batch = 0.6993s	
1220/29450 (epoch 2.071), train_loss = 2.34223702, grad/param norm = 2.9176e-01, time/batch = 0.6936s	
1221/29450 (epoch 2.073), train_loss = 2.31932778, grad/param norm = 2.8310e-01, time/batch = 0.6952s	
1222/29450 (epoch 2.075), train_loss = 2.49949295, grad/param norm = 3.0178e-01, time/batch = 0.6982s	
1223/29450 (epoch 2.076), train_loss = 2.26162442, grad/param norm = 2.6344e-01, time/batch = 0.6979s	
1224/29450 (epoch 2.078), train_loss = 2.10986331, grad/param norm = 2.4225e-01, time/batch = 0.6944s	
1225/29450 (epoch 2.080), train_loss = 2.21584067, grad/param norm = 2.6252e-01, time/batch = 0.6968s	
1226/29450 (epoch 2.081), train_loss = 2.24940896, grad/param norm = 2.4537e-01, time/batch = 0.6974s	
1227/29450 (epoch 2.083), train_loss = 2.18342694, grad/param norm = 2.0276e-01, time/batch = 0.7004s	
1228/29450 (epoch 2.085), train_loss = 2.24219203, grad/param norm = 2.2940e-01, time/batch = 0.6995s	
1229/29450 (epoch 2.087), train_loss = 2.09158271, grad/param norm = 2.7047e-01, time/batch = 0.7197s	
1230/29450 (epoch 2.088), train_loss = 2.20000619, grad/param norm = 2.7765e-01, time/batch = 0.7176s	
1231/29450 (epoch 2.090), train_loss = 2.05927973, grad/param norm = 2.2644e-01, time/batch = 0.7011s	
1232/29450 (epoch 2.092), train_loss = 2.19868269, grad/param norm = 2.2580e-01, time/batch = 0.7075s	
1233/29450 (epoch 2.093), train_loss = 2.06099311, grad/param norm = 2.2811e-01, time/batch = 0.7000s	
1234/29450 (epoch 2.095), train_loss = 1.95425560, grad/param norm = 2.1409e-01, time/batch = 0.6983s	
1235/29450 (epoch 2.097), train_loss = 2.16639199, grad/param norm = 2.2360e-01, time/batch = 0.6974s	
1236/29450 (epoch 2.098), train_loss = 2.09189246, grad/param norm = 3.1881e-01, time/batch = 0.6966s	
1237/29450 (epoch 2.100), train_loss = 2.31914156, grad/param norm = 3.9882e-01, time/batch = 0.6996s	
1238/29450 (epoch 2.102), train_loss = 2.15589944, grad/param norm = 2.6452e-01, time/batch = 0.7011s	
1239/29450 (epoch 2.104), train_loss = 2.16425522, grad/param norm = 2.7687e-01, time/batch = 0.6991s	
1240/29450 (epoch 2.105), train_loss = 2.08550293, grad/param norm = 2.1006e-01, time/batch = 0.6955s	
1241/29450 (epoch 2.107), train_loss = 2.01049333, grad/param norm = 2.2122e-01, time/batch = 0.7020s	
1242/29450 (epoch 2.109), train_loss = 2.02475886, grad/param norm = 2.4020e-01, time/batch = 0.6974s	
1243/29450 (epoch 2.110), train_loss = 2.19347365, grad/param norm = 2.3116e-01, time/batch = 0.6961s	
1244/29450 (epoch 2.112), train_loss = 2.05950172, grad/param norm = 2.5734e-01, time/batch = 0.7064s	
1245/29450 (epoch 2.114), train_loss = 2.08321063, grad/param norm = 2.7405e-01, time/batch = 0.6992s	
1246/29450 (epoch 2.115), train_loss = 2.30027336, grad/param norm = 2.7790e-01, time/batch = 0.6967s	
1247/29450 (epoch 2.117), train_loss = 2.11410809, grad/param norm = 2.3874e-01, time/batch = 0.7048s	
1248/29450 (epoch 2.119), train_loss = 2.34169364, grad/param norm = 2.7302e-01, time/batch = 0.7006s	
1249/29450 (epoch 2.121), train_loss = 2.18147242, grad/param norm = 2.4066e-01, time/batch = 0.7049s	
1250/29450 (epoch 2.122), train_loss = 2.16514357, grad/param norm = 2.2460e-01, time/batch = 0.7010s	
1251/29450 (epoch 2.124), train_loss = 2.10289808, grad/param norm = 2.1611e-01, time/batch = 0.7174s	
1252/29450 (epoch 2.126), train_loss = 2.13123906, grad/param norm = 2.1273e-01, time/batch = 0.7271s	
1253/29450 (epoch 2.127), train_loss = 2.20377037, grad/param norm = 2.5370e-01, time/batch = 0.7436s	
1254/29450 (epoch 2.129), train_loss = 2.22377832, grad/param norm = 2.3753e-01, time/batch = 0.7465s	
1255/29450 (epoch 2.131), train_loss = 2.25823287, grad/param norm = 2.2415e-01, time/batch = 0.7267s	
1256/29450 (epoch 2.132), train_loss = 2.07343020, grad/param norm = 2.1922e-01, time/batch = 0.7590s	
1257/29450 (epoch 2.134), train_loss = 1.90556095, grad/param norm = 2.0938e-01, time/batch = 0.7595s	
1258/29450 (epoch 2.136), train_loss = 1.88756313, grad/param norm = 2.3299e-01, time/batch = 0.7450s	
1259/29450 (epoch 2.138), train_loss = 2.22847885, grad/param norm = 2.4880e-01, time/batch = 0.7442s	
1260/29450 (epoch 2.139), train_loss = 2.02460091, grad/param norm = 2.0291e-01, time/batch = 0.7350s	
1261/29450 (epoch 2.141), train_loss = 2.02269891, grad/param norm = 2.4231e-01, time/batch = 0.7365s	
1262/29450 (epoch 2.143), train_loss = 2.15682702, grad/param norm = 2.6281e-01, time/batch = 0.7315s	
1263/29450 (epoch 2.144), train_loss = 2.07406959, grad/param norm = 2.2907e-01, time/batch = 0.7229s	
1264/29450 (epoch 2.146), train_loss = 2.22247700, grad/param norm = 2.4417e-01, time/batch = 0.7205s	
1265/29450 (epoch 2.148), train_loss = 2.20463273, grad/param norm = 2.2141e-01, time/batch = 0.6941s	
1266/29450 (epoch 2.149), train_loss = 1.95672572, grad/param norm = 3.0782e-01, time/batch = 0.6893s	
1267/29450 (epoch 2.151), train_loss = 2.32263642, grad/param norm = 3.2114e-01, time/batch = 0.6837s	
1268/29450 (epoch 2.153), train_loss = 1.98630581, grad/param norm = 2.3650e-01, time/batch = 0.7023s	
1269/29450 (epoch 2.154), train_loss = 2.12559509, grad/param norm = 2.4160e-01, time/batch = 0.6996s	
1270/29450 (epoch 2.156), train_loss = 2.18398254, grad/param norm = 2.4680e-01, time/batch = 0.6887s	
1271/29450 (epoch 2.158), train_loss = 2.16968540, grad/param norm = 2.4411e-01, time/batch = 0.6892s	
1272/29450 (epoch 2.160), train_loss = 2.37158288, grad/param norm = 2.6550e-01, time/batch = 0.6901s	
1273/29450 (epoch 2.161), train_loss = 2.13447779, grad/param norm = 2.8748e-01, time/batch = 0.6835s	
1274/29450 (epoch 2.163), train_loss = 2.18287875, grad/param norm = 2.4261e-01, time/batch = 0.7073s	
1275/29450 (epoch 2.165), train_loss = 2.24704131, grad/param norm = 2.3181e-01, time/batch = 0.7115s	
1276/29450 (epoch 2.166), train_loss = 2.28258802, grad/param norm = 2.6336e-01, time/batch = 0.6928s	
1277/29450 (epoch 2.168), train_loss = 2.18240971, grad/param norm = 2.4617e-01, time/batch = 0.6813s	
1278/29450 (epoch 2.170), train_loss = 2.33537715, grad/param norm = 2.3661e-01, time/batch = 0.6989s	
1279/29450 (epoch 2.171), train_loss = 2.37604556, grad/param norm = 2.3918e-01, time/batch = 0.7044s	
1280/29450 (epoch 2.173), train_loss = 2.11001054, grad/param norm = 2.1552e-01, time/batch = 0.6866s	
1281/29450 (epoch 2.175), train_loss = 2.01980183, grad/param norm = 2.1041e-01, time/batch = 0.6834s	
1282/29450 (epoch 2.177), train_loss = 2.26722027, grad/param norm = 2.8791e-01, time/batch = 0.6941s	
1283/29450 (epoch 2.178), train_loss = 2.08940253, grad/param norm = 2.7036e-01, time/batch = 0.7020s	
1284/29450 (epoch 2.180), train_loss = 2.07558388, grad/param norm = 2.2132e-01, time/batch = 0.6892s	
1285/29450 (epoch 2.182), train_loss = 2.11288571, grad/param norm = 1.9126e-01, time/batch = 0.6805s	
1286/29450 (epoch 2.183), train_loss = 2.10477665, grad/param norm = 2.4522e-01, time/batch = 0.6819s	
1287/29450 (epoch 2.185), train_loss = 2.19776419, grad/param norm = 2.7467e-01, time/batch = 0.6867s	
1288/29450 (epoch 2.187), train_loss = 2.22913623, grad/param norm = 2.6686e-01, time/batch = 0.6965s	
1289/29450 (epoch 2.188), train_loss = 2.28051642, grad/param norm = 2.7785e-01, time/batch = 0.7141s	
1290/29450 (epoch 2.190), train_loss = 2.00891595, grad/param norm = 2.2883e-01, time/batch = 0.6882s	
1291/29450 (epoch 2.192), train_loss = 2.21918436, grad/param norm = 2.3950e-01, time/batch = 0.6862s	
1292/29450 (epoch 2.194), train_loss = 2.22499134, grad/param norm = 2.1648e-01, time/batch = 0.6920s	
1293/29450 (epoch 2.195), train_loss = 2.18123722, grad/param norm = 2.2566e-01, time/batch = 0.7005s	
1294/29450 (epoch 2.197), train_loss = 2.29723406, grad/param norm = 2.1739e-01, time/batch = 0.6918s	
1295/29450 (epoch 2.199), train_loss = 2.02990671, grad/param norm = 2.0976e-01, time/batch = 0.6897s	
1296/29450 (epoch 2.200), train_loss = 2.34226109, grad/param norm = 2.1379e-01, time/batch = 0.6896s	
1297/29450 (epoch 2.202), train_loss = 2.11356001, grad/param norm = 2.3034e-01, time/batch = 0.6879s	
1298/29450 (epoch 2.204), train_loss = 2.00990014, grad/param norm = 2.7301e-01, time/batch = 0.6882s	
1299/29450 (epoch 2.205), train_loss = 2.04319569, grad/param norm = 2.2416e-01, time/batch = 0.6894s	
1300/29450 (epoch 2.207), train_loss = 2.01602385, grad/param norm = 2.1648e-01, time/batch = 0.7063s	
1301/29450 (epoch 2.209), train_loss = 2.06444861, grad/param norm = 2.4174e-01, time/batch = 0.7182s	
1302/29450 (epoch 2.211), train_loss = 2.24707742, grad/param norm = 2.9762e-01, time/batch = 0.6886s	
1303/29450 (epoch 2.212), train_loss = 2.07262443, grad/param norm = 3.1681e-01, time/batch = 0.6974s	
1304/29450 (epoch 2.214), train_loss = 2.22903086, grad/param norm = 3.4699e-01, time/batch = 0.6980s	
1305/29450 (epoch 2.216), train_loss = 2.11981840, grad/param norm = 2.4037e-01, time/batch = 0.6991s	
1306/29450 (epoch 2.217), train_loss = 2.30418201, grad/param norm = 2.3333e-01, time/batch = 0.6933s	
1307/29450 (epoch 2.219), train_loss = 1.82713016, grad/param norm = 2.1350e-01, time/batch = 0.6923s	
1308/29450 (epoch 2.221), train_loss = 2.21823687, grad/param norm = 2.3480e-01, time/batch = 0.7136s	
1309/29450 (epoch 2.222), train_loss = 2.14275046, grad/param norm = 2.4371e-01, time/batch = 0.7127s	
1310/29450 (epoch 2.224), train_loss = 2.06725296, grad/param norm = 2.9733e-01, time/batch = 0.6851s	
1311/29450 (epoch 2.226), train_loss = 2.32373195, grad/param norm = 2.3324e-01, time/batch = 0.6877s	
1312/29450 (epoch 2.228), train_loss = 2.11785344, grad/param norm = 2.0544e-01, time/batch = 0.6924s	
1313/29450 (epoch 2.229), train_loss = 2.06324303, grad/param norm = 2.1038e-01, time/batch = 0.6862s	
1314/29450 (epoch 2.231), train_loss = 2.02976204, grad/param norm = 2.2085e-01, time/batch = 0.6864s	
1315/29450 (epoch 2.233), train_loss = 1.98725150, grad/param norm = 2.2669e-01, time/batch = 0.6846s	
1316/29450 (epoch 2.234), train_loss = 2.00938426, grad/param norm = 1.9669e-01, time/batch = 0.6825s	
1317/29450 (epoch 2.236), train_loss = 2.34131662, grad/param norm = 2.6341e-01, time/batch = 0.7011s	
1318/29450 (epoch 2.238), train_loss = 2.18775931, grad/param norm = 2.4151e-01, time/batch = 0.7036s	
1319/29450 (epoch 2.239), train_loss = 2.27792278, grad/param norm = 2.8372e-01, time/batch = 0.7141s	
1320/29450 (epoch 2.241), train_loss = 2.10750062, grad/param norm = 2.3703e-01, time/batch = 0.6826s	
1321/29450 (epoch 2.243), train_loss = 2.13184768, grad/param norm = 1.9938e-01, time/batch = 0.6895s	
1322/29450 (epoch 2.244), train_loss = 2.37134755, grad/param norm = 2.0118e-01, time/batch = 0.6878s	
1323/29450 (epoch 2.246), train_loss = 2.17092902, grad/param norm = 2.2836e-01, time/batch = 0.6952s	
1324/29450 (epoch 2.248), train_loss = 2.18131621, grad/param norm = 2.6407e-01, time/batch = 0.6909s	
1325/29450 (epoch 2.250), train_loss = 2.09898205, grad/param norm = 2.6386e-01, time/batch = 0.6891s	
1326/29450 (epoch 2.251), train_loss = 2.19546062, grad/param norm = 2.7704e-01, time/batch = 0.6890s	
1327/29450 (epoch 2.253), train_loss = 1.97787662, grad/param norm = 2.2987e-01, time/batch = 0.6905s	
1328/29450 (epoch 2.255), train_loss = 2.09503632, grad/param norm = 2.2809e-01, time/batch = 0.6999s	
1329/29450 (epoch 2.256), train_loss = 2.04211635, grad/param norm = 2.0999e-01, time/batch = 0.7157s	
1330/29450 (epoch 2.258), train_loss = 2.11891503, grad/param norm = 2.4406e-01, time/batch = 0.6922s	
1331/29450 (epoch 2.260), train_loss = 2.23247661, grad/param norm = 2.6207e-01, time/batch = 0.6970s	
1332/29450 (epoch 2.261), train_loss = 2.28936045, grad/param norm = 2.6602e-01, time/batch = 0.6935s	
1333/29450 (epoch 2.263), train_loss = 2.11737601, grad/param norm = 2.5191e-01, time/batch = 0.6912s	
1334/29450 (epoch 2.265), train_loss = 2.01865753, grad/param norm = 2.5952e-01, time/batch = 0.6874s	
1335/29450 (epoch 2.267), train_loss = 2.19405147, grad/param norm = 2.1801e-01, time/batch = 0.6858s	
1336/29450 (epoch 2.268), train_loss = 1.97836401, grad/param norm = 2.1563e-01, time/batch = 0.6945s	
1337/29450 (epoch 2.270), train_loss = 2.10689783, grad/param norm = 2.2429e-01, time/batch = 0.7140s	
1338/29450 (epoch 2.272), train_loss = 1.97859707, grad/param norm = 2.2020e-01, time/batch = 0.7158s	
1339/29450 (epoch 2.273), train_loss = 2.13211298, grad/param norm = 2.4193e-01, time/batch = 0.7104s	
1340/29450 (epoch 2.275), train_loss = 2.13373091, grad/param norm = 2.1118e-01, time/batch = 0.6929s	
1341/29450 (epoch 2.277), train_loss = 1.97773608, grad/param norm = 2.7375e-01, time/batch = 0.6919s	
1342/29450 (epoch 2.278), train_loss = 2.22124440, grad/param norm = 2.8862e-01, time/batch = 0.6949s	
1343/29450 (epoch 2.280), train_loss = 2.04287795, grad/param norm = 2.2463e-01, time/batch = 0.7088s	
1344/29450 (epoch 2.282), train_loss = 2.27459376, grad/param norm = 2.5305e-01, time/batch = 0.7061s	
1345/29450 (epoch 2.284), train_loss = 2.20752898, grad/param norm = 2.0806e-01, time/batch = 0.6934s	
1346/29450 (epoch 2.285), train_loss = 2.14670951, grad/param norm = 2.3868e-01, time/batch = 0.6958s	
1347/29450 (epoch 2.287), train_loss = 2.20786860, grad/param norm = 2.7982e-01, time/batch = 0.6969s	
1348/29450 (epoch 2.289), train_loss = 2.36403790, grad/param norm = 3.0779e-01, time/batch = 0.7119s	
1349/29450 (epoch 2.290), train_loss = 2.19837592, grad/param norm = 2.3255e-01, time/batch = 0.7145s	
1350/29450 (epoch 2.292), train_loss = 2.13634779, grad/param norm = 2.5330e-01, time/batch = 0.6882s	
1351/29450 (epoch 2.294), train_loss = 2.28190516, grad/param norm = 2.7083e-01, time/batch = 0.6915s	
1352/29450 (epoch 2.295), train_loss = 2.00612221, grad/param norm = 2.5451e-01, time/batch = 0.6901s	
1353/29450 (epoch 2.297), train_loss = 2.27841297, grad/param norm = 2.5266e-01, time/batch = 0.6874s	
1354/29450 (epoch 2.299), train_loss = 2.12051797, grad/param norm = 3.2128e-01, time/batch = 0.6857s	
1355/29450 (epoch 2.301), train_loss = 2.16587857, grad/param norm = 2.7898e-01, time/batch = 0.6903s	
1356/29450 (epoch 2.302), train_loss = 2.10803296, grad/param norm = 2.0822e-01, time/batch = 0.6984s	
1357/29450 (epoch 2.304), train_loss = 2.02548756, grad/param norm = 2.1232e-01, time/batch = 0.7012s	
1358/29450 (epoch 2.306), train_loss = 2.16434850, grad/param norm = 2.0939e-01, time/batch = 0.7143s	
1359/29450 (epoch 2.307), train_loss = 2.24941277, grad/param norm = 2.1396e-01, time/batch = 0.7161s	
1360/29450 (epoch 2.309), train_loss = 2.35792045, grad/param norm = 2.5307e-01, time/batch = 0.7202s	
1361/29450 (epoch 2.311), train_loss = 2.20694707, grad/param norm = 2.6075e-01, time/batch = 0.7119s	
1362/29450 (epoch 2.312), train_loss = 2.23188760, grad/param norm = 2.1754e-01, time/batch = 0.7046s	
1363/29450 (epoch 2.314), train_loss = 2.25749152, grad/param norm = 2.1565e-01, time/batch = 0.7045s	
1364/29450 (epoch 2.316), train_loss = 2.05559008, grad/param norm = 2.5810e-01, time/batch = 0.7049s	
1365/29450 (epoch 2.317), train_loss = 2.07452888, grad/param norm = 2.2215e-01, time/batch = 0.7043s	
1366/29450 (epoch 2.319), train_loss = 1.95315727, grad/param norm = 2.1025e-01, time/batch = 0.7035s	
1367/29450 (epoch 2.321), train_loss = 2.09846661, grad/param norm = 2.1846e-01, time/batch = 0.6991s	
1368/29450 (epoch 2.323), train_loss = 2.26402584, grad/param norm = 2.2390e-01, time/batch = 0.7076s	
1369/29450 (epoch 2.324), train_loss = 2.10810860, grad/param norm = 2.4865e-01, time/batch = 0.7101s	
1370/29450 (epoch 2.326), train_loss = 2.18032659, grad/param norm = 2.4669e-01, time/batch = 0.7006s	
1371/29450 (epoch 2.328), train_loss = 2.26473221, grad/param norm = 2.6203e-01, time/batch = 0.7071s	
1372/29450 (epoch 2.329), train_loss = 2.26804445, grad/param norm = 2.5688e-01, time/batch = 0.7074s	
1373/29450 (epoch 2.331), train_loss = 1.93745289, grad/param norm = 2.4152e-01, time/batch = 0.6957s	
1374/29450 (epoch 2.333), train_loss = 2.24939768, grad/param norm = 2.1246e-01, time/batch = 0.6857s	
1375/29450 (epoch 2.334), train_loss = 2.09236805, grad/param norm = 2.2896e-01, time/batch = 0.6827s	
1376/29450 (epoch 2.336), train_loss = 1.98246639, grad/param norm = 2.0324e-01, time/batch = 0.6855s	
1377/29450 (epoch 2.338), train_loss = 1.93789189, grad/param norm = 2.1710e-01, time/batch = 0.6883s	
1378/29450 (epoch 2.340), train_loss = 2.08599713, grad/param norm = 2.5207e-01, time/batch = 0.6855s	
1379/29450 (epoch 2.341), train_loss = 2.18599287, grad/param norm = 2.4603e-01, time/batch = 0.6935s	
1380/29450 (epoch 2.343), train_loss = 2.09346722, grad/param norm = 2.4719e-01, time/batch = 0.6862s	
1381/29450 (epoch 2.345), train_loss = 2.46692942, grad/param norm = 2.3506e-01, time/batch = 0.6870s	
1382/29450 (epoch 2.346), train_loss = 2.22582680, grad/param norm = 2.2514e-01, time/batch = 0.6886s	
1383/29450 (epoch 2.348), train_loss = 2.33083721, grad/param norm = 2.6487e-01, time/batch = 0.6881s	
1384/29450 (epoch 2.350), train_loss = 2.22592031, grad/param norm = 2.4899e-01, time/batch = 0.6980s	
1385/29450 (epoch 2.351), train_loss = 2.35381701, grad/param norm = 2.1425e-01, time/batch = 0.6972s	
1386/29450 (epoch 2.353), train_loss = 2.03879761, grad/param norm = 2.1668e-01, time/batch = 0.7083s	
1387/29450 (epoch 2.355), train_loss = 2.02758032, grad/param norm = 2.2788e-01, time/batch = 0.6974s	
1388/29450 (epoch 2.357), train_loss = 1.99809666, grad/param norm = 2.3924e-01, time/batch = 0.7007s	
1389/29450 (epoch 2.358), train_loss = 1.91973081, grad/param norm = 2.7399e-01, time/batch = 0.7138s	
1390/29450 (epoch 2.360), train_loss = 2.19375948, grad/param norm = 3.1430e-01, time/batch = 0.6942s	
1391/29450 (epoch 2.362), train_loss = 2.09406004, grad/param norm = 2.0837e-01, time/batch = 0.6918s	
1392/29450 (epoch 2.363), train_loss = 2.10352203, grad/param norm = 2.2897e-01, time/batch = 0.6892s	
1393/29450 (epoch 2.365), train_loss = 2.11882646, grad/param norm = 2.6114e-01, time/batch = 0.6868s	
1394/29450 (epoch 2.367), train_loss = 2.10892604, grad/param norm = 2.7089e-01, time/batch = 0.6871s	
1395/29450 (epoch 2.368), train_loss = 2.19381313, grad/param norm = 2.3990e-01, time/batch = 0.6861s	
1396/29450 (epoch 2.370), train_loss = 2.01245286, grad/param norm = 2.0503e-01, time/batch = 0.6856s	
1397/29450 (epoch 2.372), train_loss = 2.35694811, grad/param norm = 2.9008e-01, time/batch = 0.6860s	
1398/29450 (epoch 2.374), train_loss = 2.23991855, grad/param norm = 2.8089e-01, time/batch = 0.6942s	
1399/29450 (epoch 2.375), train_loss = 2.40452142, grad/param norm = 2.6638e-01, time/batch = 0.6853s	
1400/29450 (epoch 2.377), train_loss = 2.15916965, grad/param norm = 2.3729e-01, time/batch = 0.6857s	
1401/29450 (epoch 2.379), train_loss = 2.01557312, grad/param norm = 2.0847e-01, time/batch = 0.6875s	
1402/29450 (epoch 2.380), train_loss = 1.95001923, grad/param norm = 2.6317e-01, time/batch = 0.6818s	
1403/29450 (epoch 2.382), train_loss = 2.15723717, grad/param norm = 2.7165e-01, time/batch = 0.6912s	
1404/29450 (epoch 2.384), train_loss = 2.21933001, grad/param norm = 2.1666e-01, time/batch = 0.6871s	
1405/29450 (epoch 2.385), train_loss = 2.18236809, grad/param norm = 2.5394e-01, time/batch = 0.6883s	
1406/29450 (epoch 2.387), train_loss = 2.17279300, grad/param norm = 2.2786e-01, time/batch = 0.6865s	
1407/29450 (epoch 2.389), train_loss = 2.37238534, grad/param norm = 2.8535e-01, time/batch = 0.6857s	
1408/29450 (epoch 2.390), train_loss = 2.07139852, grad/param norm = 2.7781e-01, time/batch = 0.6896s	
1409/29450 (epoch 2.392), train_loss = 2.02368268, grad/param norm = 2.7259e-01, time/batch = 0.6910s	
1410/29450 (epoch 2.394), train_loss = 2.08202775, grad/param norm = 2.2809e-01, time/batch = 0.6882s	
1411/29450 (epoch 2.396), train_loss = 1.98343874, grad/param norm = 2.1207e-01, time/batch = 0.6894s	
1412/29450 (epoch 2.397), train_loss = 2.14949813, grad/param norm = 2.3558e-01, time/batch = 0.6895s	
1413/29450 (epoch 2.399), train_loss = 1.96051298, grad/param norm = 2.3249e-01, time/batch = 0.6928s	
1414/29450 (epoch 2.401), train_loss = 2.20531356, grad/param norm = 2.2119e-01, time/batch = 0.6892s	
1415/29450 (epoch 2.402), train_loss = 2.19946788, grad/param norm = 2.2585e-01, time/batch = 0.6938s	
1416/29450 (epoch 2.404), train_loss = 1.99581589, grad/param norm = 2.2292e-01, time/batch = 0.6858s	
1417/29450 (epoch 2.406), train_loss = 2.06698777, grad/param norm = 1.9812e-01, time/batch = 0.6868s	
1418/29450 (epoch 2.407), train_loss = 2.19463950, grad/param norm = 2.4088e-01, time/batch = 0.6945s	
1419/29450 (epoch 2.409), train_loss = 2.10384467, grad/param norm = 2.3913e-01, time/batch = 0.7163s	
1420/29450 (epoch 2.411), train_loss = 2.00375489, grad/param norm = 2.5792e-01, time/batch = 0.7047s	
1421/29450 (epoch 2.413), train_loss = 2.23973528, grad/param norm = 2.4671e-01, time/batch = 0.7019s	
1422/29450 (epoch 2.414), train_loss = 1.91610997, grad/param norm = 2.7924e-01, time/batch = 0.6988s	
1423/29450 (epoch 2.416), train_loss = 1.89689105, grad/param norm = 2.5219e-01, time/batch = 0.7143s	
1424/29450 (epoch 2.418), train_loss = 2.15109297, grad/param norm = 2.5753e-01, time/batch = 0.7193s	
1425/29450 (epoch 2.419), train_loss = 2.10290319, grad/param norm = 2.2555e-01, time/batch = 0.6987s	
1426/29450 (epoch 2.421), train_loss = 1.89965319, grad/param norm = 2.4168e-01, time/batch = 0.6900s	
1427/29450 (epoch 2.423), train_loss = 2.06023346, grad/param norm = 2.6106e-01, time/batch = 0.6906s	
1428/29450 (epoch 2.424), train_loss = 2.20918268, grad/param norm = 2.5955e-01, time/batch = 0.6963s	
1429/29450 (epoch 2.426), train_loss = 2.14244449, grad/param norm = 2.1958e-01, time/batch = 0.6888s	
1430/29450 (epoch 2.428), train_loss = 2.07080606, grad/param norm = 2.1826e-01, time/batch = 0.6901s	
1431/29450 (epoch 2.430), train_loss = 2.17865719, grad/param norm = 2.4756e-01, time/batch = 0.6862s	
1432/29450 (epoch 2.431), train_loss = 1.86193629, grad/param norm = 2.2298e-01, time/batch = 0.6869s	
1433/29450 (epoch 2.433), train_loss = 2.32760447, grad/param norm = 2.6975e-01, time/batch = 0.6923s	
1434/29450 (epoch 2.435), train_loss = 1.97870245, grad/param norm = 2.3234e-01, time/batch = 0.7061s	
1435/29450 (epoch 2.436), train_loss = 2.23512519, grad/param norm = 2.5713e-01, time/batch = 0.7146s	
1436/29450 (epoch 2.438), train_loss = 2.14906501, grad/param norm = 2.6979e-01, time/batch = 0.6953s	
1437/29450 (epoch 2.440), train_loss = 2.32813876, grad/param norm = 2.5362e-01, time/batch = 0.6931s	
1438/29450 (epoch 2.441), train_loss = 2.15906043, grad/param norm = 2.2021e-01, time/batch = 0.6945s	
1439/29450 (epoch 2.443), train_loss = 2.12473103, grad/param norm = 2.6340e-01, time/batch = 0.7152s	
1440/29450 (epoch 2.445), train_loss = 2.01571604, grad/param norm = 2.3465e-01, time/batch = 0.6907s	
1441/29450 (epoch 2.447), train_loss = 2.09914287, grad/param norm = 2.1906e-01, time/batch = 0.6919s	
1442/29450 (epoch 2.448), train_loss = 1.97654259, grad/param norm = 2.2316e-01, time/batch = 0.6938s	
1443/29450 (epoch 2.450), train_loss = 2.16378425, grad/param norm = 2.1477e-01, time/batch = 0.6895s	
1444/29450 (epoch 2.452), train_loss = 2.12518268, grad/param norm = 2.1350e-01, time/batch = 0.7036s	
1445/29450 (epoch 2.453), train_loss = 1.99428238, grad/param norm = 2.0751e-01, time/batch = 0.6885s	
1446/29450 (epoch 2.455), train_loss = 2.07152186, grad/param norm = 2.1869e-01, time/batch = 0.6820s	
1447/29450 (epoch 2.457), train_loss = 2.11508185, grad/param norm = 2.4461e-01, time/batch = 0.6821s	
1448/29450 (epoch 2.458), train_loss = 2.23967054, grad/param norm = 2.2569e-01, time/batch = 0.6896s	
1449/29450 (epoch 2.460), train_loss = 2.12685599, grad/param norm = 2.1223e-01, time/batch = 0.7156s	
1450/29450 (epoch 2.462), train_loss = 2.04955743, grad/param norm = 2.3529e-01, time/batch = 0.6911s	
1451/29450 (epoch 2.463), train_loss = 2.22392035, grad/param norm = 2.7018e-01, time/batch = 0.6913s	
1452/29450 (epoch 2.465), train_loss = 1.95243459, grad/param norm = 2.2209e-01, time/batch = 0.6947s	
1453/29450 (epoch 2.467), train_loss = 1.95266924, grad/param norm = 2.0688e-01, time/batch = 0.6996s	
1454/29450 (epoch 2.469), train_loss = 2.24468042, grad/param norm = 2.3840e-01, time/batch = 0.6855s	
1455/29450 (epoch 2.470), train_loss = 1.75232474, grad/param norm = 1.8754e-01, time/batch = 0.6894s	
1456/29450 (epoch 2.472), train_loss = 2.22200275, grad/param norm = 2.2790e-01, time/batch = 0.6880s	
1457/29450 (epoch 2.474), train_loss = 2.13307140, grad/param norm = 2.1566e-01, time/batch = 0.6879s	
1458/29450 (epoch 2.475), train_loss = 2.20250338, grad/param norm = 2.0646e-01, time/batch = 0.6893s	
1459/29450 (epoch 2.477), train_loss = 2.02745537, grad/param norm = 1.9460e-01, time/batch = 0.7156s	
1460/29450 (epoch 2.479), train_loss = 2.16847450, grad/param norm = 2.2267e-01, time/batch = 0.6958s	
1461/29450 (epoch 2.480), train_loss = 2.17475564, grad/param norm = 2.7750e-01, time/batch = 0.6906s	
1462/29450 (epoch 2.482), train_loss = 2.05409495, grad/param norm = 2.2681e-01, time/batch = 0.6916s	
1463/29450 (epoch 2.484), train_loss = 1.97946563, grad/param norm = 2.1639e-01, time/batch = 0.6992s	
1464/29450 (epoch 2.486), train_loss = 2.06096833, grad/param norm = 1.9366e-01, time/batch = 0.6891s	
1465/29450 (epoch 2.487), train_loss = 2.10570310, grad/param norm = 2.0630e-01, time/batch = 0.6945s	
1466/29450 (epoch 2.489), train_loss = 1.99677311, grad/param norm = 2.3046e-01, time/batch = 0.7014s	
1467/29450 (epoch 2.491), train_loss = 2.04423174, grad/param norm = 2.3561e-01, time/batch = 0.6844s	
1468/29450 (epoch 2.492), train_loss = 2.08596666, grad/param norm = 2.5786e-01, time/batch = 0.6900s	
1469/29450 (epoch 2.494), train_loss = 2.30904207, grad/param norm = 2.7412e-01, time/batch = 0.7158s	
1470/29450 (epoch 2.496), train_loss = 2.18039428, grad/param norm = 2.1025e-01, time/batch = 0.6929s	
1471/29450 (epoch 2.497), train_loss = 2.01099443, grad/param norm = 2.1590e-01, time/batch = 0.6952s	
1472/29450 (epoch 2.499), train_loss = 2.06598223, grad/param norm = 2.1063e-01, time/batch = 0.6960s	
1473/29450 (epoch 2.501), train_loss = 2.12881805, grad/param norm = 2.3149e-01, time/batch = 0.6966s	
1474/29450 (epoch 2.503), train_loss = 2.11121406, grad/param norm = 2.6658e-01, time/batch = 0.6837s	
1475/29450 (epoch 2.504), train_loss = 2.16105342, grad/param norm = 2.8824e-01, time/batch = 0.6841s	
1476/29450 (epoch 2.506), train_loss = 2.21461253, grad/param norm = 2.4535e-01, time/batch = 0.6846s	
1477/29450 (epoch 2.508), train_loss = 2.02917874, grad/param norm = 2.1477e-01, time/batch = 0.6840s	
1478/29450 (epoch 2.509), train_loss = 1.96879079, grad/param norm = 2.2917e-01, time/batch = 0.6889s	
1479/29450 (epoch 2.511), train_loss = 2.17692867, grad/param norm = 2.2313e-01, time/batch = 0.7156s	
1480/29450 (epoch 2.513), train_loss = 2.19610677, grad/param norm = 2.7487e-01, time/batch = 0.6953s	
1481/29450 (epoch 2.514), train_loss = 2.06544161, grad/param norm = 2.3991e-01, time/batch = 0.6909s	
1482/29450 (epoch 2.516), train_loss = 2.16369253, grad/param norm = 2.3502e-01, time/batch = 0.7272s	
1483/29450 (epoch 2.518), train_loss = 2.28850113, grad/param norm = 2.3810e-01, time/batch = 0.6914s	
1484/29450 (epoch 2.520), train_loss = 1.94944013, grad/param norm = 2.2482e-01, time/batch = 0.7035s	
1485/29450 (epoch 2.521), train_loss = 2.23977932, grad/param norm = 2.2281e-01, time/batch = 0.6994s	
1486/29450 (epoch 2.523), train_loss = 2.26537932, grad/param norm = 2.4175e-01, time/batch = 0.6946s	
1487/29450 (epoch 2.525), train_loss = 2.39888707, grad/param norm = 2.6177e-01, time/batch = 0.6905s	
1488/29450 (epoch 2.526), train_loss = 2.16971840, grad/param norm = 2.6659e-01, time/batch = 0.6901s	
1489/29450 (epoch 2.528), train_loss = 2.21983577, grad/param norm = 2.1176e-01, time/batch = 0.7043s	
1490/29450 (epoch 2.530), train_loss = 2.13627887, grad/param norm = 2.1738e-01, time/batch = 0.6916s	
1491/29450 (epoch 2.531), train_loss = 1.99701555, grad/param norm = 1.9873e-01, time/batch = 0.6862s	
1492/29450 (epoch 2.533), train_loss = 2.09236496, grad/param norm = 2.0073e-01, time/batch = 0.6867s	
1493/29450 (epoch 2.535), train_loss = 2.68304635, grad/param norm = 3.0672e-01, time/batch = 0.6918s	
1494/29450 (epoch 2.537), train_loss = 2.25285781, grad/param norm = 3.0677e-01, time/batch = 0.7024s	
1495/29450 (epoch 2.538), train_loss = 2.08619946, grad/param norm = 1.9607e-01, time/batch = 0.6926s	
1496/29450 (epoch 2.540), train_loss = 2.28943553, grad/param norm = 2.5021e-01, time/batch = 0.6920s	
1497/29450 (epoch 2.542), train_loss = 2.16714687, grad/param norm = 2.5853e-01, time/batch = 0.6908s	
1498/29450 (epoch 2.543), train_loss = 2.08638500, grad/param norm = 1.9217e-01, time/batch = 0.6953s	
1499/29450 (epoch 2.545), train_loss = 2.02743352, grad/param norm = 1.9914e-01, time/batch = 0.6935s	
1500/29450 (epoch 2.547), train_loss = 2.16019918, grad/param norm = 1.9604e-01, time/batch = 0.6868s	
1501/29450 (epoch 2.548), train_loss = 1.94485852, grad/param norm = 2.1201e-01, time/batch = 0.6967s	
1502/29450 (epoch 2.550), train_loss = 2.08055356, grad/param norm = 2.3498e-01, time/batch = 0.6956s	
1503/29450 (epoch 2.552), train_loss = 2.04359474, grad/param norm = 2.1629e-01, time/batch = 0.6911s	
1504/29450 (epoch 2.553), train_loss = 2.12398776, grad/param norm = 2.0085e-01, time/batch = 0.6868s	
1505/29450 (epoch 2.555), train_loss = 2.14952818, grad/param norm = 2.1689e-01, time/batch = 0.6882s	
1506/29450 (epoch 2.557), train_loss = 2.11684374, grad/param norm = 2.2948e-01, time/batch = 0.6882s	
1507/29450 (epoch 2.559), train_loss = 1.89459567, grad/param norm = 2.4404e-01, time/batch = 0.6891s	
1508/29450 (epoch 2.560), train_loss = 2.10943049, grad/param norm = 2.3389e-01, time/batch = 0.7051s	
1509/29450 (epoch 2.562), train_loss = 2.07498380, grad/param norm = 2.4078e-01, time/batch = 0.7143s	
1510/29450 (epoch 2.564), train_loss = 2.15111028, grad/param norm = 2.3627e-01, time/batch = 0.7248s	
1511/29450 (epoch 2.565), train_loss = 2.23921604, grad/param norm = 2.7232e-01, time/batch = 0.7038s	
1512/29450 (epoch 2.567), train_loss = 2.24212151, grad/param norm = 2.6761e-01, time/batch = 0.6912s	
1513/29450 (epoch 2.569), train_loss = 2.07414663, grad/param norm = 2.2559e-01, time/batch = 0.6892s	
1514/29450 (epoch 2.570), train_loss = 2.32728551, grad/param norm = 2.2296e-01, time/batch = 0.6895s	
1515/29450 (epoch 2.572), train_loss = 2.12411164, grad/param norm = 2.2361e-01, time/batch = 0.6896s	
1516/29450 (epoch 2.574), train_loss = 2.01610550, grad/param norm = 2.4696e-01, time/batch = 0.6878s	
1517/29450 (epoch 2.576), train_loss = 2.19650885, grad/param norm = 2.8894e-01, time/batch = 0.6894s	
1518/29450 (epoch 2.577), train_loss = 2.29681135, grad/param norm = 2.4704e-01, time/batch = 0.6912s	
1519/29450 (epoch 2.579), train_loss = 2.05380314, grad/param norm = 2.4137e-01, time/batch = 0.6952s	
1520/29450 (epoch 2.581), train_loss = 2.22380076, grad/param norm = 2.3617e-01, time/batch = 0.6861s	
1521/29450 (epoch 2.582), train_loss = 1.86716825, grad/param norm = 2.2393e-01, time/batch = 0.6868s	
1522/29450 (epoch 2.584), train_loss = 2.11734900, grad/param norm = 2.5130e-01, time/batch = 0.6858s	
1523/29450 (epoch 2.586), train_loss = 2.11397382, grad/param norm = 2.4015e-01, time/batch = 0.6859s	
1524/29450 (epoch 2.587), train_loss = 2.36533196, grad/param norm = 2.4866e-01, time/batch = 0.6877s	
1525/29450 (epoch 2.589), train_loss = 2.10269534, grad/param norm = 2.6446e-01, time/batch = 0.6953s	
1526/29450 (epoch 2.591), train_loss = 2.02641121, grad/param norm = 2.3691e-01, time/batch = 0.6932s	
1527/29450 (epoch 2.593), train_loss = 2.11012166, grad/param norm = 2.4389e-01, time/batch = 0.6860s	
1528/29450 (epoch 2.594), train_loss = 1.94829575, grad/param norm = 2.1337e-01, time/batch = 0.6856s	
1529/29450 (epoch 2.596), train_loss = 2.00234648, grad/param norm = 2.1756e-01, time/batch = 0.6831s	
1530/29450 (epoch 2.598), train_loss = 2.18064898, grad/param norm = 2.3389e-01, time/batch = 0.6867s	
1531/29450 (epoch 2.599), train_loss = 2.12094082, grad/param norm = 2.2686e-01, time/batch = 0.6865s	
1532/29450 (epoch 2.601), train_loss = 2.05298016, grad/param norm = 1.9132e-01, time/batch = 0.6855s	
1533/29450 (epoch 2.603), train_loss = 2.16003079, grad/param norm = 2.3268e-01, time/batch = 0.6825s	
1534/29450 (epoch 2.604), train_loss = 2.09612482, grad/param norm = 2.0432e-01, time/batch = 0.6839s	
1535/29450 (epoch 2.606), train_loss = 2.13635523, grad/param norm = 2.1270e-01, time/batch = 0.6855s	
1536/29450 (epoch 2.608), train_loss = 1.95043427, grad/param norm = 2.0681e-01, time/batch = 0.6847s	
1537/29450 (epoch 2.610), train_loss = 2.01071368, grad/param norm = 1.9534e-01, time/batch = 0.6943s	
1538/29450 (epoch 2.611), train_loss = 1.97974316, grad/param norm = 2.1555e-01, time/batch = 0.6957s	
1539/29450 (epoch 2.613), train_loss = 1.86863628, grad/param norm = 2.0950e-01, time/batch = 0.7129s	
1540/29450 (epoch 2.615), train_loss = 1.97772593, grad/param norm = 2.0949e-01, time/batch = 0.7148s	
1541/29450 (epoch 2.616), train_loss = 2.01413373, grad/param norm = 2.1669e-01, time/batch = 0.7186s	
1542/29450 (epoch 2.618), train_loss = 1.74853803, grad/param norm = 2.1673e-01, time/batch = 0.7174s	
1543/29450 (epoch 2.620), train_loss = 2.21327136, grad/param norm = 2.3105e-01, time/batch = 0.7139s	
1544/29450 (epoch 2.621), train_loss = 1.99735316, grad/param norm = 2.2766e-01, time/batch = 0.7151s	
1545/29450 (epoch 2.623), train_loss = 1.99482379, grad/param norm = 2.2669e-01, time/batch = 0.7012s	
1546/29450 (epoch 2.625), train_loss = 2.03153062, grad/param norm = 2.1848e-01, time/batch = 0.7069s	
1547/29450 (epoch 2.626), train_loss = 2.14808724, grad/param norm = 2.3585e-01, time/batch = 0.6980s	
1548/29450 (epoch 2.628), train_loss = 2.03478090, grad/param norm = 2.2265e-01, time/batch = 0.6819s	
1549/29450 (epoch 2.630), train_loss = 1.97280131, grad/param norm = 1.8606e-01, time/batch = 0.6805s	
1550/29450 (epoch 2.632), train_loss = 2.05010615, grad/param norm = 1.9488e-01, time/batch = 0.6819s	
1551/29450 (epoch 2.633), train_loss = 2.21956909, grad/param norm = 2.5206e-01, time/batch = 0.6827s	
1552/29450 (epoch 2.635), train_loss = 1.77342811, grad/param norm = 2.0074e-01, time/batch = 0.6832s	
1553/29450 (epoch 2.637), train_loss = 2.05760588, grad/param norm = 2.4611e-01, time/batch = 0.6871s	
1554/29450 (epoch 2.638), train_loss = 1.81858590, grad/param norm = 2.5441e-01, time/batch = 0.6838s	
1555/29450 (epoch 2.640), train_loss = 2.20621258, grad/param norm = 2.8428e-01, time/batch = 0.6843s	
1556/29450 (epoch 2.642), train_loss = 2.05821505, grad/param norm = 2.3579e-01, time/batch = 0.6932s	
1557/29450 (epoch 2.643), train_loss = 1.99802393, grad/param norm = 2.3426e-01, time/batch = 0.6927s	
1558/29450 (epoch 2.645), train_loss = 2.07113507, grad/param norm = 2.4742e-01, time/batch = 0.6862s	
1559/29450 (epoch 2.647), train_loss = 2.35921105, grad/param norm = 2.4944e-01, time/batch = 0.6918s	
1560/29450 (epoch 2.649), train_loss = 2.28886888, grad/param norm = 2.6020e-01, time/batch = 0.6786s	
1561/29450 (epoch 2.650), train_loss = 2.14814492, grad/param norm = 2.2962e-01, time/batch = 0.6804s	
1562/29450 (epoch 2.652), train_loss = 2.06566146, grad/param norm = 2.3293e-01, time/batch = 0.6849s	
1563/29450 (epoch 2.654), train_loss = 2.15115849, grad/param norm = 2.4214e-01, time/batch = 0.6827s	
1564/29450 (epoch 2.655), train_loss = 2.10457558, grad/param norm = 2.7322e-01, time/batch = 0.6829s	
1565/29450 (epoch 2.657), train_loss = 2.11705788, grad/param norm = 2.3150e-01, time/batch = 0.6851s	
1566/29450 (epoch 2.659), train_loss = 2.30890728, grad/param norm = 2.2101e-01, time/batch = 0.6904s	
1567/29450 (epoch 2.660), train_loss = 1.86725378, grad/param norm = 2.1569e-01, time/batch = 0.6800s	
1568/29450 (epoch 2.662), train_loss = 1.86434989, grad/param norm = 1.9396e-01, time/batch = 0.6830s	
1569/29450 (epoch 2.664), train_loss = 1.99077539, grad/param norm = 2.0408e-01, time/batch = 0.6864s	
1570/29450 (epoch 2.666), train_loss = 2.12024648, grad/param norm = 2.2587e-01, time/batch = 0.6860s	
1571/29450 (epoch 2.667), train_loss = 2.19648221, grad/param norm = 2.2721e-01, time/batch = 0.6910s	
1572/29450 (epoch 2.669), train_loss = 2.13164208, grad/param norm = 1.9998e-01, time/batch = 0.6979s	
1573/29450 (epoch 2.671), train_loss = 1.88037476, grad/param norm = 2.3626e-01, time/batch = 0.7104s	
1574/29450 (epoch 2.672), train_loss = 1.90918079, grad/param norm = 1.9288e-01, time/batch = 0.6827s	
1575/29450 (epoch 2.674), train_loss = 2.06374867, grad/param norm = 2.1869e-01, time/batch = 0.6907s	
1576/29450 (epoch 2.676), train_loss = 2.10063485, grad/param norm = 2.2230e-01, time/batch = 0.7084s	
1577/29450 (epoch 2.677), train_loss = 2.16314746, grad/param norm = 2.4204e-01, time/batch = 0.6869s	
1578/29450 (epoch 2.679), train_loss = 2.00074166, grad/param norm = 2.3110e-01, time/batch = 0.6830s	
1579/29450 (epoch 2.681), train_loss = 2.29579784, grad/param norm = 2.1406e-01, time/batch = 0.6858s	
1580/29450 (epoch 2.683), train_loss = 2.08063491, grad/param norm = 2.2180e-01, time/batch = 0.7022s	
1581/29450 (epoch 2.684), train_loss = 2.07599712, grad/param norm = 2.1377e-01, time/batch = 0.6840s	
1582/29450 (epoch 2.686), train_loss = 2.19713841, grad/param norm = 2.1070e-01, time/batch = 0.6812s	
1583/29450 (epoch 2.688), train_loss = 2.02167387, grad/param norm = 2.2914e-01, time/batch = 0.6850s	
1584/29450 (epoch 2.689), train_loss = 1.94044009, grad/param norm = 2.2720e-01, time/batch = 0.6838s	
1585/29450 (epoch 2.691), train_loss = 1.99338456, grad/param norm = 2.3797e-01, time/batch = 0.7050s	
1586/29450 (epoch 2.693), train_loss = 2.23747606, grad/param norm = 2.6094e-01, time/batch = 0.7016s	
1587/29450 (epoch 2.694), train_loss = 2.04328470, grad/param norm = 2.0818e-01, time/batch = 0.6984s	
1588/29450 (epoch 2.696), train_loss = 2.28990145, grad/param norm = 2.2210e-01, time/batch = 0.6808s	
1589/29450 (epoch 2.698), train_loss = 2.09589205, grad/param norm = 2.5286e-01, time/batch = 0.6801s	
1590/29450 (epoch 2.699), train_loss = 2.24455760, grad/param norm = 2.4929e-01, time/batch = 0.6816s	
1591/29450 (epoch 2.701), train_loss = 1.94930847, grad/param norm = 2.1252e-01, time/batch = 0.6862s	
1592/29450 (epoch 2.703), train_loss = 2.04244157, grad/param norm = 2.3423e-01, time/batch = 0.6848s	
1593/29450 (epoch 2.705), train_loss = 2.14765367, grad/param norm = 2.2843e-01, time/batch = 0.7084s	
1594/29450 (epoch 2.706), train_loss = 1.94617277, grad/param norm = 2.0178e-01, time/batch = 0.7028s	
1595/29450 (epoch 2.708), train_loss = 1.97694987, grad/param norm = 1.8891e-01, time/batch = 0.7139s	
1596/29450 (epoch 2.710), train_loss = 2.19605110, grad/param norm = 2.3356e-01, time/batch = 0.7191s	
1597/29450 (epoch 2.711), train_loss = 2.12221233, grad/param norm = 2.1119e-01, time/batch = 0.7172s	
1598/29450 (epoch 2.713), train_loss = 2.13825071, grad/param norm = 2.4387e-01, time/batch = 0.7184s	
1599/29450 (epoch 2.715), train_loss = 2.18701008, grad/param norm = 2.1392e-01, time/batch = 0.7204s	
1600/29450 (epoch 2.716), train_loss = 1.97374523, grad/param norm = 2.2810e-01, time/batch = 0.7128s	
1601/29450 (epoch 2.718), train_loss = 2.06973567, grad/param norm = 2.3470e-01, time/batch = 0.7065s	
1602/29450 (epoch 2.720), train_loss = 1.93734174, grad/param norm = 2.3189e-01, time/batch = 0.7014s	
1603/29450 (epoch 2.722), train_loss = 1.95439303, grad/param norm = 2.4180e-01, time/batch = 0.7037s	
1604/29450 (epoch 2.723), train_loss = 2.07172650, grad/param norm = 2.5894e-01, time/batch = 0.6887s	
1605/29450 (epoch 2.725), train_loss = 1.96823725, grad/param norm = 2.0579e-01, time/batch = 0.6871s	
1606/29450 (epoch 2.727), train_loss = 2.04085238, grad/param norm = 2.0885e-01, time/batch = 0.6869s	
1607/29450 (epoch 2.728), train_loss = 2.00392369, grad/param norm = 2.2623e-01, time/batch = 0.6911s	
1608/29450 (epoch 2.730), train_loss = 2.21161279, grad/param norm = 2.0970e-01, time/batch = 0.6988s	
1609/29450 (epoch 2.732), train_loss = 2.02815273, grad/param norm = 1.9008e-01, time/batch = 0.7153s	
1610/29450 (epoch 2.733), train_loss = 2.25024234, grad/param norm = 2.7545e-01, time/batch = 0.7023s	
1611/29450 (epoch 2.735), train_loss = 2.09126920, grad/param norm = 2.6494e-01, time/batch = 0.6990s	
1612/29450 (epoch 2.737), train_loss = 2.11419419, grad/param norm = 2.6851e-01, time/batch = 0.7017s	
1613/29450 (epoch 2.739), train_loss = 2.08156739, grad/param norm = 2.6234e-01, time/batch = 0.6982s	
1614/29450 (epoch 2.740), train_loss = 2.26746885, grad/param norm = 2.5175e-01, time/batch = 0.6951s	
1615/29450 (epoch 2.742), train_loss = 2.17022582, grad/param norm = 2.1470e-01, time/batch = 0.6922s	
1616/29450 (epoch 2.744), train_loss = 2.12462927, grad/param norm = 2.3373e-01, time/batch = 0.7089s	
1617/29450 (epoch 2.745), train_loss = 1.99840932, grad/param norm = 2.7161e-01, time/batch = 0.6809s	
1618/29450 (epoch 2.747), train_loss = 1.93459677, grad/param norm = 2.3991e-01, time/batch = 0.6926s	
1619/29450 (epoch 2.749), train_loss = 2.17238832, grad/param norm = 2.0571e-01, time/batch = 0.7018s	
1620/29450 (epoch 2.750), train_loss = 2.14326984, grad/param norm = 1.9430e-01, time/batch = 0.6830s	
1621/29450 (epoch 2.752), train_loss = 2.09259687, grad/param norm = 2.1140e-01, time/batch = 0.6823s	
1622/29450 (epoch 2.754), train_loss = 1.92472266, grad/param norm = 2.0296e-01, time/batch = 0.6835s	
1623/29450 (epoch 2.756), train_loss = 2.13781583, grad/param norm = 2.2417e-01, time/batch = 0.6873s	
1624/29450 (epoch 2.757), train_loss = 2.30822902, grad/param norm = 2.4483e-01, time/batch = 0.6824s	
1625/29450 (epoch 2.759), train_loss = 2.18152771, grad/param norm = 2.3756e-01, time/batch = 0.7099s	
1626/29450 (epoch 2.761), train_loss = 2.30874333, grad/param norm = 2.3003e-01, time/batch = 0.7057s	
1627/29450 (epoch 2.762), train_loss = 2.12304452, grad/param norm = 2.1072e-01, time/batch = 0.7053s	
1628/29450 (epoch 2.764), train_loss = 2.17264709, grad/param norm = 2.3365e-01, time/batch = 0.6904s	
1629/29450 (epoch 2.766), train_loss = 2.21473763, grad/param norm = 2.1784e-01, time/batch = 0.6845s	
1630/29450 (epoch 2.767), train_loss = 1.96498631, grad/param norm = 1.8556e-01, time/batch = 0.6840s	
1631/29450 (epoch 2.769), train_loss = 2.38203431, grad/param norm = 2.5998e-01, time/batch = 0.6863s	
1632/29450 (epoch 2.771), train_loss = 2.24223347, grad/param norm = 2.5445e-01, time/batch = 0.6830s	
1633/29450 (epoch 2.772), train_loss = 2.12465814, grad/param norm = 2.1122e-01, time/batch = 0.6800s	
1634/29450 (epoch 2.774), train_loss = 1.83248562, grad/param norm = 2.0545e-01, time/batch = 0.6860s	
1635/29450 (epoch 2.776), train_loss = 2.08358778, grad/param norm = 2.2279e-01, time/batch = 0.7074s	
1636/29450 (epoch 2.778), train_loss = 2.11947979, grad/param norm = 2.1101e-01, time/batch = 0.7053s	
1637/29450 (epoch 2.779), train_loss = 2.19815446, grad/param norm = 2.0016e-01, time/batch = 0.6880s	
1638/29450 (epoch 2.781), train_loss = 1.82724892, grad/param norm = 2.4182e-01, time/batch = 0.6892s	
1639/29450 (epoch 2.783), train_loss = 1.91904190, grad/param norm = 2.3305e-01, time/batch = 0.6830s	
1640/29450 (epoch 2.784), train_loss = 2.00990130, grad/param norm = 1.9746e-01, time/batch = 0.6847s	
1641/29450 (epoch 2.786), train_loss = 1.86873928, grad/param norm = 1.8828e-01, time/batch = 0.6874s	
1642/29450 (epoch 2.788), train_loss = 2.16714731, grad/param norm = 2.4246e-01, time/batch = 0.6902s	
1643/29450 (epoch 2.789), train_loss = 2.24097490, grad/param norm = 2.1091e-01, time/batch = 0.7033s	
1644/29450 (epoch 2.791), train_loss = 1.80305945, grad/param norm = 2.2781e-01, time/batch = 0.6951s	
1645/29450 (epoch 2.793), train_loss = 1.99081709, grad/param norm = 2.2200e-01, time/batch = 0.7027s	
1646/29450 (epoch 2.795), train_loss = 2.15696807, grad/param norm = 2.2004e-01, time/batch = 0.6968s	
1647/29450 (epoch 2.796), train_loss = 2.05447496, grad/param norm = 2.0429e-01, time/batch = 0.7139s	
1648/29450 (epoch 2.798), train_loss = 2.05109241, grad/param norm = 2.0853e-01, time/batch = 0.7021s	
1649/29450 (epoch 2.800), train_loss = 1.81567298, grad/param norm = 2.0003e-01, time/batch = 0.7120s	
1650/29450 (epoch 2.801), train_loss = 2.09392016, grad/param norm = 2.2709e-01, time/batch = 0.7139s	
1651/29450 (epoch 2.803), train_loss = 2.10718623, grad/param norm = 2.2878e-01, time/batch = 0.6974s	
1652/29450 (epoch 2.805), train_loss = 2.11011198, grad/param norm = 2.1736e-01, time/batch = 0.6938s	
1653/29450 (epoch 2.806), train_loss = 2.04395706, grad/param norm = 2.3939e-01, time/batch = 0.6997s	
1654/29450 (epoch 2.808), train_loss = 2.31764136, grad/param norm = 2.5473e-01, time/batch = 0.6891s	
1655/29450 (epoch 2.810), train_loss = 2.18264243, grad/param norm = 2.4745e-01, time/batch = 0.6870s	
1656/29450 (epoch 2.812), train_loss = 1.98402126, grad/param norm = 2.0855e-01, time/batch = 0.6855s	
1657/29450 (epoch 2.813), train_loss = 2.24956190, grad/param norm = 2.3192e-01, time/batch = 0.6884s	
1658/29450 (epoch 2.815), train_loss = 2.13365552, grad/param norm = 2.1571e-01, time/batch = 0.6865s	
1659/29450 (epoch 2.817), train_loss = 2.06846109, grad/param norm = 2.1358e-01, time/batch = 0.6986s	
1660/29450 (epoch 2.818), train_loss = 1.93703230, grad/param norm = 2.1133e-01, time/batch = 0.6853s	
1661/29450 (epoch 2.820), train_loss = 2.06678506, grad/param norm = 2.6387e-01, time/batch = 0.6838s	
1662/29450 (epoch 2.822), train_loss = 2.20837888, grad/param norm = 2.5293e-01, time/batch = 0.6886s	
1663/29450 (epoch 2.823), train_loss = 2.00740373, grad/param norm = 1.9885e-01, time/batch = 0.6896s	
1664/29450 (epoch 2.825), train_loss = 1.89097572, grad/param norm = 2.1020e-01, time/batch = 0.6820s	
1665/29450 (epoch 2.827), train_loss = 2.09987213, grad/param norm = 2.3249e-01, time/batch = 0.6837s	
1666/29450 (epoch 2.829), train_loss = 1.94945658, grad/param norm = 2.4853e-01, time/batch = 0.6856s	
1667/29450 (epoch 2.830), train_loss = 2.25177327, grad/param norm = 2.2433e-01, time/batch = 0.6855s	
1668/29450 (epoch 2.832), train_loss = 2.29987266, grad/param norm = 2.4915e-01, time/batch = 0.6899s	
1669/29450 (epoch 2.834), train_loss = 1.97493723, grad/param norm = 2.5434e-01, time/batch = 0.6831s	
1670/29450 (epoch 2.835), train_loss = 1.93582809, grad/param norm = 2.2209e-01, time/batch = 0.6870s	
1671/29450 (epoch 2.837), train_loss = 1.99699198, grad/param norm = 2.1074e-01, time/batch = 0.6908s	
1672/29450 (epoch 2.839), train_loss = 2.09805707, grad/param norm = 2.3073e-01, time/batch = 0.7021s	
1673/29450 (epoch 2.840), train_loss = 2.18670129, grad/param norm = 2.2834e-01, time/batch = 0.7164s	
1674/29450 (epoch 2.842), train_loss = 1.91571171, grad/param norm = 2.5906e-01, time/batch = 0.6893s	
1675/29450 (epoch 2.844), train_loss = 1.86241594, grad/param norm = 1.9600e-01, time/batch = 0.6898s	
1676/29450 (epoch 2.846), train_loss = 2.06383122, grad/param norm = 2.1679e-01, time/batch = 0.6981s	
1677/29450 (epoch 2.847), train_loss = 1.98287413, grad/param norm = 2.3637e-01, time/batch = 0.6913s	
1678/29450 (epoch 2.849), train_loss = 2.00146308, grad/param norm = 2.3985e-01, time/batch = 0.6880s	
1679/29450 (epoch 2.851), train_loss = 2.13052685, grad/param norm = 2.1991e-01, time/batch = 0.6890s	
1680/29450 (epoch 2.852), train_loss = 2.06868402, grad/param norm = 2.1251e-01, time/batch = 0.6932s	
1681/29450 (epoch 2.854), train_loss = 1.88922569, grad/param norm = 2.3044e-01, time/batch = 0.7154s	
1682/29450 (epoch 2.856), train_loss = 1.91683118, grad/param norm = 2.4026e-01, time/batch = 0.7206s	
1683/29450 (epoch 2.857), train_loss = 1.82328410, grad/param norm = 2.0320e-01, time/batch = 0.7195s	
1684/29450 (epoch 2.859), train_loss = 1.88567729, grad/param norm = 2.1224e-01, time/batch = 0.6967s	
1685/29450 (epoch 2.861), train_loss = 2.06060621, grad/param norm = 2.1111e-01, time/batch = 0.7058s	
1686/29450 (epoch 2.862), train_loss = 1.95678252, grad/param norm = 2.0040e-01, time/batch = 0.7138s	
1687/29450 (epoch 2.864), train_loss = 2.05492155, grad/param norm = 1.8998e-01, time/batch = 0.6952s	
1688/29450 (epoch 2.866), train_loss = 2.02522495, grad/param norm = 2.0909e-01, time/batch = 0.7060s	
1689/29450 (epoch 2.868), train_loss = 2.11687548, grad/param norm = 2.1478e-01, time/batch = 0.7008s	
1690/29450 (epoch 2.869), train_loss = 1.93658161, grad/param norm = 2.3433e-01, time/batch = 0.6852s	
1691/29450 (epoch 2.871), train_loss = 1.87033503, grad/param norm = 2.3076e-01, time/batch = 0.6852s	
1692/29450 (epoch 2.873), train_loss = 2.01655937, grad/param norm = 2.1446e-01, time/batch = 0.7231s	
1693/29450 (epoch 2.874), train_loss = 1.87854988, grad/param norm = 2.1135e-01, time/batch = 0.7137s	
1694/29450 (epoch 2.876), train_loss = 1.93077327, grad/param norm = 2.3747e-01, time/batch = 0.7188s	
1695/29450 (epoch 2.878), train_loss = 2.17442525, grad/param norm = 2.6545e-01, time/batch = 0.7595s	
1696/29450 (epoch 2.879), train_loss = 2.33693361, grad/param norm = 2.5356e-01, time/batch = 0.7357s	
1697/29450 (epoch 2.881), train_loss = 2.10329086, grad/param norm = 2.6123e-01, time/batch = 0.7240s	
1698/29450 (epoch 2.883), train_loss = 2.16689147, grad/param norm = 2.1814e-01, time/batch = 0.7255s	
1699/29450 (epoch 2.885), train_loss = 2.06694039, grad/param norm = 1.9080e-01, time/batch = 0.7360s	
1700/29450 (epoch 2.886), train_loss = 2.08296166, grad/param norm = 2.0484e-01, time/batch = 0.7279s	
1701/29450 (epoch 2.888), train_loss = 1.93046152, grad/param norm = 2.4391e-01, time/batch = 0.7195s	
1702/29450 (epoch 2.890), train_loss = 2.09826408, grad/param norm = 2.1509e-01, time/batch = 0.7055s	
1703/29450 (epoch 2.891), train_loss = 2.25474491, grad/param norm = 2.2333e-01, time/batch = 0.7116s	
1704/29450 (epoch 2.893), train_loss = 1.97017819, grad/param norm = 1.9760e-01, time/batch = 0.7307s	
1705/29450 (epoch 2.895), train_loss = 2.23685574, grad/param norm = 2.5663e-01, time/batch = 0.7239s	
1706/29450 (epoch 2.896), train_loss = 2.07451335, grad/param norm = 2.3178e-01, time/batch = 0.6938s	
1707/29450 (epoch 2.898), train_loss = 1.95721414, grad/param norm = 2.1672e-01, time/batch = 0.6924s	
1708/29450 (epoch 2.900), train_loss = 2.26513423, grad/param norm = 2.6908e-01, time/batch = 0.6971s	
1709/29450 (epoch 2.902), train_loss = 2.03012280, grad/param norm = 2.5844e-01, time/batch = 0.6902s	
1710/29450 (epoch 2.903), train_loss = 2.01015976, grad/param norm = 2.3966e-01, time/batch = 0.6868s	
1711/29450 (epoch 2.905), train_loss = 2.01366768, grad/param norm = 2.1353e-01, time/batch = 0.6914s	
1712/29450 (epoch 2.907), train_loss = 2.20468466, grad/param norm = 2.3252e-01, time/batch = 0.7018s	
1713/29450 (epoch 2.908), train_loss = 2.31694775, grad/param norm = 2.1449e-01, time/batch = 0.6979s	
1714/29450 (epoch 2.910), train_loss = 2.12009224, grad/param norm = 2.1127e-01, time/batch = 0.6876s	
1715/29450 (epoch 2.912), train_loss = 1.93932219, grad/param norm = 2.1424e-01, time/batch = 0.6894s	
1716/29450 (epoch 2.913), train_loss = 1.99118139, grad/param norm = 2.0678e-01, time/batch = 0.6877s	
1717/29450 (epoch 2.915), train_loss = 2.02045588, grad/param norm = 2.1557e-01, time/batch = 0.6887s	
1718/29450 (epoch 2.917), train_loss = 1.99766202, grad/param norm = 1.9327e-01, time/batch = 0.6850s	
1719/29450 (epoch 2.919), train_loss = 2.08216046, grad/param norm = 2.1910e-01, time/batch = 0.6835s	
1720/29450 (epoch 2.920), train_loss = 2.16854258, grad/param norm = 2.4069e-01, time/batch = 0.6802s	
1721/29450 (epoch 2.922), train_loss = 2.13736424, grad/param norm = 2.4653e-01, time/batch = 0.6892s	
1722/29450 (epoch 2.924), train_loss = 2.21302505, grad/param norm = 2.7473e-01, time/batch = 0.6982s	
1723/29450 (epoch 2.925), train_loss = 2.05195126, grad/param norm = 2.3211e-01, time/batch = 0.6908s	
1724/29450 (epoch 2.927), train_loss = 2.29316112, grad/param norm = 2.1975e-01, time/batch = 0.6914s	
1725/29450 (epoch 2.929), train_loss = 2.30871623, grad/param norm = 2.4726e-01, time/batch = 0.6977s	
1726/29450 (epoch 2.930), train_loss = 2.28312912, grad/param norm = 2.6255e-01, time/batch = 0.7144s	
1727/29450 (epoch 2.932), train_loss = 2.26627939, grad/param norm = 2.6069e-01, time/batch = 0.6975s	
1728/29450 (epoch 2.934), train_loss = 2.10418487, grad/param norm = 2.1910e-01, time/batch = 0.6899s	
1729/29450 (epoch 2.935), train_loss = 2.10234053, grad/param norm = 2.1555e-01, time/batch = 0.6898s	
1730/29450 (epoch 2.937), train_loss = 2.02840055, grad/param norm = 2.2562e-01, time/batch = 0.6894s	
1731/29450 (epoch 2.939), train_loss = 1.97704000, grad/param norm = 2.0173e-01, time/batch = 0.7011s	
1732/29450 (epoch 2.941), train_loss = 2.14699551, grad/param norm = 2.3619e-01, time/batch = 0.6868s	
1733/29450 (epoch 2.942), train_loss = 1.89168856, grad/param norm = 2.2228e-01, time/batch = 0.6848s	
1734/29450 (epoch 2.944), train_loss = 2.04588923, grad/param norm = 2.2612e-01, time/batch = 0.6840s	
1735/29450 (epoch 2.946), train_loss = 1.90493331, grad/param norm = 1.9588e-01, time/batch = 0.6864s	
1736/29450 (epoch 2.947), train_loss = 1.94262099, grad/param norm = 1.9425e-01, time/batch = 0.6934s	
1737/29450 (epoch 2.949), train_loss = 1.95578726, grad/param norm = 2.1665e-01, time/batch = 0.7079s	
1738/29450 (epoch 2.951), train_loss = 1.90522307, grad/param norm = 2.0628e-01, time/batch = 0.7131s	
1739/29450 (epoch 2.952), train_loss = 2.11897078, grad/param norm = 2.2206e-01, time/batch = 0.7117s	
1740/29450 (epoch 2.954), train_loss = 1.92421477, grad/param norm = 1.9797e-01, time/batch = 0.7122s	
1741/29450 (epoch 2.956), train_loss = 1.99952480, grad/param norm = 2.1679e-01, time/batch = 0.7086s	
1742/29450 (epoch 2.958), train_loss = 2.00554729, grad/param norm = 2.2501e-01, time/batch = 0.6890s	
1743/29450 (epoch 2.959), train_loss = 2.10066775, grad/param norm = 2.0714e-01, time/batch = 0.6839s	
1744/29450 (epoch 2.961), train_loss = 2.02356252, grad/param norm = 2.1424e-01, time/batch = 0.6819s	
1745/29450 (epoch 2.963), train_loss = 1.89968732, grad/param norm = 2.1722e-01, time/batch = 0.6849s	
1746/29450 (epoch 2.964), train_loss = 2.06290427, grad/param norm = 2.4413e-01, time/batch = 0.6959s	
1747/29450 (epoch 2.966), train_loss = 2.07716129, grad/param norm = 2.1221e-01, time/batch = 0.6970s	
1748/29450 (epoch 2.968), train_loss = 2.02812579, grad/param norm = 2.2020e-01, time/batch = 0.7298s	
1749/29450 (epoch 2.969), train_loss = 2.20030404, grad/param norm = 2.2807e-01, time/batch = 0.7055s	
1750/29450 (epoch 2.971), train_loss = 1.81053508, grad/param norm = 2.0262e-01, time/batch = 0.6868s	
1751/29450 (epoch 2.973), train_loss = 1.91432199, grad/param norm = 2.2520e-01, time/batch = 0.6999s	
1752/29450 (epoch 2.975), train_loss = 2.07153797, grad/param norm = 2.7103e-01, time/batch = 0.7132s	
1753/29450 (epoch 2.976), train_loss = 2.11604396, grad/param norm = 2.0899e-01, time/batch = 0.7282s	
1754/29450 (epoch 2.978), train_loss = 1.98076762, grad/param norm = 2.1915e-01, time/batch = 0.7255s	
1755/29450 (epoch 2.980), train_loss = 1.83838101, grad/param norm = 2.1980e-01, time/batch = 0.7049s	
1756/29450 (epoch 2.981), train_loss = 1.90658213, grad/param norm = 2.2772e-01, time/batch = 0.7155s	
1757/29450 (epoch 2.983), train_loss = 1.92473845, grad/param norm = 2.4541e-01, time/batch = 0.7035s	
1758/29450 (epoch 2.985), train_loss = 2.11509097, grad/param norm = 2.3603e-01, time/batch = 0.6974s	
1759/29450 (epoch 2.986), train_loss = 2.24042794, grad/param norm = 2.6685e-01, time/batch = 0.6978s	
1760/29450 (epoch 2.988), train_loss = 1.92063697, grad/param norm = 2.2635e-01, time/batch = 0.6917s	
1761/29450 (epoch 2.990), train_loss = 2.03329272, grad/param norm = 2.4689e-01, time/batch = 0.6976s	
1762/29450 (epoch 2.992), train_loss = 1.73613700, grad/param norm = 2.2871e-01, time/batch = 0.6982s	
1763/29450 (epoch 2.993), train_loss = 2.14422483, grad/param norm = 1.9564e-01, time/batch = 0.7009s	
1764/29450 (epoch 2.995), train_loss = 1.99873358, grad/param norm = 2.0066e-01, time/batch = 0.7063s	
1765/29450 (epoch 2.997), train_loss = 1.94594162, grad/param norm = 2.0066e-01, time/batch = 0.7027s	
1766/29450 (epoch 2.998), train_loss = 2.00648391, grad/param norm = 2.1369e-01, time/batch = 0.7159s	
1767/29450 (epoch 3.000), train_loss = 2.09091739, grad/param norm = 2.4823e-01, time/batch = 0.7183s	
1768/29450 (epoch 3.002), train_loss = 2.08322324, grad/param norm = 2.4493e-01, time/batch = 0.7144s	
1769/29450 (epoch 3.003), train_loss = 2.21716710, grad/param norm = 2.3463e-01, time/batch = 0.6923s	
1770/29450 (epoch 3.005), train_loss = 1.72291160, grad/param norm = 2.0157e-01, time/batch = 0.6944s	
1771/29450 (epoch 3.007), train_loss = 1.88481004, grad/param norm = 1.8949e-01, time/batch = 0.6896s	
1772/29450 (epoch 3.008), train_loss = 1.89348681, grad/param norm = 2.0054e-01, time/batch = 0.6905s	
1773/29450 (epoch 3.010), train_loss = 1.98904059, grad/param norm = 2.1522e-01, time/batch = 0.6915s	
1774/29450 (epoch 3.012), train_loss = 2.05091461, grad/param norm = 2.0476e-01, time/batch = 0.6974s	
1775/29450 (epoch 3.014), train_loss = 2.19075330, grad/param norm = 2.2573e-01, time/batch = 0.7183s	
1776/29450 (epoch 3.015), train_loss = 1.91463844, grad/param norm = 1.9837e-01, time/batch = 0.6972s	
1777/29450 (epoch 3.017), train_loss = 2.02653884, grad/param norm = 2.2028e-01, time/batch = 0.6902s	
1778/29450 (epoch 3.019), train_loss = 1.81596660, grad/param norm = 2.3330e-01, time/batch = 0.6987s	
1779/29450 (epoch 3.020), train_loss = 2.05084724, grad/param norm = 2.6399e-01, time/batch = 0.6926s	
1780/29450 (epoch 3.022), train_loss = 2.01570724, grad/param norm = 2.5710e-01, time/batch = 0.7050s	
1781/29450 (epoch 3.024), train_loss = 2.08773181, grad/param norm = 2.1380e-01, time/batch = 0.7019s	
1782/29450 (epoch 3.025), train_loss = 2.00166932, grad/param norm = 2.5178e-01, time/batch = 0.6962s	
1783/29450 (epoch 3.027), train_loss = 1.95546614, grad/param norm = 2.0857e-01, time/batch = 0.6947s	
1784/29450 (epoch 3.029), train_loss = 2.07653411, grad/param norm = 2.0202e-01, time/batch = 0.6922s	
1785/29450 (epoch 3.031), train_loss = 1.78044014, grad/param norm = 1.9298e-01, time/batch = 0.6947s	
1786/29450 (epoch 3.032), train_loss = 1.87812877, grad/param norm = 2.1312e-01, time/batch = 0.6931s	
1787/29450 (epoch 3.034), train_loss = 1.80774847, grad/param norm = 1.8153e-01, time/batch = 0.6945s	
1788/29450 (epoch 3.036), train_loss = 1.95929407, grad/param norm = 2.0089e-01, time/batch = 0.6852s	
1789/29450 (epoch 3.037), train_loss = 2.22459919, grad/param norm = 2.5158e-01, time/batch = 0.6840s	
1790/29450 (epoch 3.039), train_loss = 1.91328325, grad/param norm = 2.2468e-01, time/batch = 0.6876s	
1791/29450 (epoch 3.041), train_loss = 2.01671271, grad/param norm = 2.8872e-01, time/batch = 0.6871s	
1792/29450 (epoch 3.042), train_loss = 1.90591084, grad/param norm = 2.4676e-01, time/batch = 0.6851s	
1793/29450 (epoch 3.044), train_loss = 2.00522972, grad/param norm = 1.8842e-01, time/batch = 0.6903s	
1794/29450 (epoch 3.046), train_loss = 2.17278152, grad/param norm = 2.4427e-01, time/batch = 0.6897s	
1795/29450 (epoch 3.048), train_loss = 1.95279096, grad/param norm = 2.3255e-01, time/batch = 0.6887s	
1796/29450 (epoch 3.049), train_loss = 2.12192046, grad/param norm = 2.0842e-01, time/batch = 0.6876s	
1797/29450 (epoch 3.051), train_loss = 2.03622116, grad/param norm = 2.2600e-01, time/batch = 0.6885s	
1798/29450 (epoch 3.053), train_loss = 1.81687833, grad/param norm = 2.1018e-01, time/batch = 0.6929s	
1799/29450 (epoch 3.054), train_loss = 1.96522448, grad/param norm = 2.1514e-01, time/batch = 0.6903s	
1800/29450 (epoch 3.056), train_loss = 2.09904033, grad/param norm = 2.0531e-01, time/batch = 0.6874s	
1801/29450 (epoch 3.058), train_loss = 2.03077085, grad/param norm = 1.9657e-01, time/batch = 0.6910s	
1802/29450 (epoch 3.059), train_loss = 1.82747259, grad/param norm = 2.1318e-01, time/batch = 0.6894s	
1803/29450 (epoch 3.061), train_loss = 1.77314920, grad/param norm = 2.0594e-01, time/batch = 0.6855s	
1804/29450 (epoch 3.063), train_loss = 1.98461088, grad/param norm = 1.9649e-01, time/batch = 0.6913s	
1805/29450 (epoch 3.065), train_loss = 1.94886009, grad/param norm = 2.1450e-01, time/batch = 0.7158s	
1806/29450 (epoch 3.066), train_loss = 1.91316775, grad/param norm = 2.3726e-01, time/batch = 0.6989s	
1807/29450 (epoch 3.068), train_loss = 2.08553956, grad/param norm = 2.3671e-01, time/batch = 0.6886s	
1808/29450 (epoch 3.070), train_loss = 1.98581473, grad/param norm = 2.3715e-01, time/batch = 0.6876s	
1809/29450 (epoch 3.071), train_loss = 2.17071955, grad/param norm = 2.4632e-01, time/batch = 0.6892s	
1810/29450 (epoch 3.073), train_loss = 2.12535136, grad/param norm = 2.1020e-01, time/batch = 0.6853s	
1811/29450 (epoch 3.075), train_loss = 2.27853102, grad/param norm = 2.3196e-01, time/batch = 0.6914s	
1812/29450 (epoch 3.076), train_loss = 2.07919412, grad/param norm = 1.9520e-01, time/batch = 0.6869s	
1813/29450 (epoch 3.078), train_loss = 1.86540193, grad/param norm = 1.9036e-01, time/batch = 0.6850s	
1814/29450 (epoch 3.080), train_loss = 1.97380807, grad/param norm = 2.1802e-01, time/batch = 0.6960s	
1815/29450 (epoch 3.081), train_loss = 2.06446424, grad/param norm = 1.9285e-01, time/batch = 0.7162s	
1816/29450 (epoch 3.083), train_loss = 2.00702751, grad/param norm = 1.8187e-01, time/batch = 0.7254s	
1817/29450 (epoch 3.085), train_loss = 2.04560188, grad/param norm = 2.0509e-01, time/batch = 0.7160s	
1818/29450 (epoch 3.087), train_loss = 1.87558318, grad/param norm = 2.2970e-01, time/batch = 0.7212s	
1819/29450 (epoch 3.088), train_loss = 1.98499741, grad/param norm = 2.2802e-01, time/batch = 0.7219s	
1820/29450 (epoch 3.090), train_loss = 1.82803990, grad/param norm = 2.0831e-01, time/batch = 0.7262s	
1821/29450 (epoch 3.092), train_loss = 1.98538912, grad/param norm = 1.8930e-01, time/batch = 0.7330s	
1822/29450 (epoch 3.093), train_loss = 1.81733735, grad/param norm = 1.9669e-01, time/batch = 0.7280s	
1823/29450 (epoch 3.095), train_loss = 1.78512345, grad/param norm = 1.9155e-01, time/batch = 0.7167s	
1824/29450 (epoch 3.097), train_loss = 1.93137824, grad/param norm = 2.1922e-01, time/batch = 0.7135s	
1825/29450 (epoch 3.098), train_loss = 1.93659260, grad/param norm = 2.8890e-01, time/batch = 0.7146s	
1826/29450 (epoch 3.100), train_loss = 2.10202724, grad/param norm = 2.8941e-01, time/batch = 0.7145s	
1827/29450 (epoch 3.102), train_loss = 1.88293599, grad/param norm = 1.9381e-01, time/batch = 0.7148s	
1828/29450 (epoch 3.104), train_loss = 1.95521555, grad/param norm = 2.2954e-01, time/batch = 0.6918s	
1829/29450 (epoch 3.105), train_loss = 1.91509081, grad/param norm = 2.0859e-01, time/batch = 0.6935s	
1830/29450 (epoch 3.107), train_loss = 1.81666273, grad/param norm = 1.9438e-01, time/batch = 0.6882s	
1831/29450 (epoch 3.109), train_loss = 1.82570026, grad/param norm = 1.9995e-01, time/batch = 0.6874s	
1832/29450 (epoch 3.110), train_loss = 1.95309646, grad/param norm = 2.1347e-01, time/batch = 0.6883s	
1833/29450 (epoch 3.112), train_loss = 1.89843412, grad/param norm = 2.1199e-01, time/batch = 0.6887s	
1834/29450 (epoch 3.114), train_loss = 1.89523019, grad/param norm = 2.1457e-01, time/batch = 0.7107s	
1835/29450 (epoch 3.115), train_loss = 2.08533723, grad/param norm = 2.1555e-01, time/batch = 0.7161s	
1836/29450 (epoch 3.117), train_loss = 1.86845684, grad/param norm = 2.0317e-01, time/batch = 0.6915s	
1837/29450 (epoch 3.119), train_loss = 2.15442131, grad/param norm = 2.2665e-01, time/batch = 0.6866s	
1838/29450 (epoch 3.121), train_loss = 1.98257252, grad/param norm = 1.9963e-01, time/batch = 0.6876s	
1839/29450 (epoch 3.122), train_loss = 1.99340671, grad/param norm = 2.0721e-01, time/batch = 0.6823s	
1840/29450 (epoch 3.124), train_loss = 1.93435586, grad/param norm = 1.9647e-01, time/batch = 0.6864s	
1841/29450 (epoch 3.126), train_loss = 1.93259052, grad/param norm = 1.9562e-01, time/batch = 0.6893s	
1842/29450 (epoch 3.127), train_loss = 1.98911317, grad/param norm = 2.2486e-01, time/batch = 0.6882s	
1843/29450 (epoch 3.129), train_loss = 2.03524990, grad/param norm = 2.2020e-01, time/batch = 0.6969s	
1844/29450 (epoch 3.131), train_loss = 2.07226160, grad/param norm = 2.1972e-01, time/batch = 0.7009s	
1845/29450 (epoch 3.132), train_loss = 1.90256768, grad/param norm = 2.1868e-01, time/batch = 0.7244s	
1846/29450 (epoch 3.134), train_loss = 1.65545157, grad/param norm = 1.9598e-01, time/batch = 0.7000s	
1847/29450 (epoch 3.136), train_loss = 1.66204460, grad/param norm = 2.1050e-01, time/batch = 0.6859s	
1848/29450 (epoch 3.138), train_loss = 2.04467228, grad/param norm = 2.2109e-01, time/batch = 0.6863s	
1849/29450 (epoch 3.139), train_loss = 1.82447578, grad/param norm = 1.8914e-01, time/batch = 0.6851s	
1850/29450 (epoch 3.141), train_loss = 1.78982671, grad/param norm = 2.0197e-01, time/batch = 0.6901s	
1851/29450 (epoch 3.143), train_loss = 1.98586366, grad/param norm = 2.0070e-01, time/batch = 0.7084s	
1852/29450 (epoch 3.144), train_loss = 1.88091277, grad/param norm = 2.0459e-01, time/batch = 0.7173s	
1853/29450 (epoch 3.146), train_loss = 2.04040879, grad/param norm = 2.5571e-01, time/batch = 0.7175s	
1854/29450 (epoch 3.148), train_loss = 2.00999879, grad/param norm = 2.6172e-01, time/batch = 0.6992s	
1855/29450 (epoch 3.149), train_loss = 1.79447825, grad/param norm = 2.7224e-01, time/batch = 0.6905s	
1856/29450 (epoch 3.151), train_loss = 2.12051220, grad/param norm = 2.2284e-01, time/batch = 0.6921s	
1857/29450 (epoch 3.153), train_loss = 1.76268835, grad/param norm = 2.0502e-01, time/batch = 0.6893s	
1858/29450 (epoch 3.154), train_loss = 1.93282789, grad/param norm = 2.0984e-01, time/batch = 0.6908s	
1859/29450 (epoch 3.156), train_loss = 1.97013737, grad/param norm = 2.1820e-01, time/batch = 0.7217s	
1860/29450 (epoch 3.158), train_loss = 1.94543896, grad/param norm = 2.4263e-01, time/batch = 0.7195s	
1861/29450 (epoch 3.160), train_loss = 2.16646800, grad/param norm = 2.3552e-01, time/batch = 0.7138s	
1862/29450 (epoch 3.161), train_loss = 1.90155757, grad/param norm = 2.2835e-01, time/batch = 0.7144s	
1863/29450 (epoch 3.163), train_loss = 1.95563148, grad/param norm = 2.0371e-01, time/batch = 0.7036s	
1864/29450 (epoch 3.165), train_loss = 2.09171199, grad/param norm = 2.0067e-01, time/batch = 0.6930s	
1865/29450 (epoch 3.166), train_loss = 2.05219455, grad/param norm = 2.3434e-01, time/batch = 0.6919s	
1866/29450 (epoch 3.168), train_loss = 1.98087033, grad/param norm = 2.0392e-01, time/batch = 0.6947s	
1867/29450 (epoch 3.170), train_loss = 2.12948250, grad/param norm = 1.9171e-01, time/batch = 0.6965s	
1868/29450 (epoch 3.171), train_loss = 2.18156779, grad/param norm = 2.3638e-01, time/batch = 0.6910s	
1869/29450 (epoch 3.173), train_loss = 1.89690937, grad/param norm = 2.0457e-01, time/batch = 0.6886s	
1870/29450 (epoch 3.175), train_loss = 1.83136022, grad/param norm = 2.0531e-01, time/batch = 0.6864s	
1871/29450 (epoch 3.177), train_loss = 2.00798572, grad/param norm = 2.3430e-01, time/batch = 0.6944s	
1872/29450 (epoch 3.178), train_loss = 1.83450066, grad/param norm = 2.1098e-01, time/batch = 0.6886s	
1873/29450 (epoch 3.180), train_loss = 1.86723535, grad/param norm = 2.1571e-01, time/batch = 0.6924s	
1874/29450 (epoch 3.182), train_loss = 1.92467473, grad/param norm = 2.0206e-01, time/batch = 0.6838s	
1875/29450 (epoch 3.183), train_loss = 1.88930822, grad/param norm = 2.3658e-01, time/batch = 0.6852s	
1876/29450 (epoch 3.185), train_loss = 2.03245712, grad/param norm = 2.3248e-01, time/batch = 0.6897s	
1877/29450 (epoch 3.187), train_loss = 2.01029347, grad/param norm = 2.1467e-01, time/batch = 0.6850s	
1878/29450 (epoch 3.188), train_loss = 2.08005152, grad/param norm = 2.2640e-01, time/batch = 0.6868s	
1879/29450 (epoch 3.190), train_loss = 1.79948385, grad/param norm = 1.8866e-01, time/batch = 0.7157s	
1880/29450 (epoch 3.192), train_loss = 2.01037358, grad/param norm = 2.1201e-01, time/batch = 0.6976s	
1881/29450 (epoch 3.194), train_loss = 2.04806610, grad/param norm = 2.2064e-01, time/batch = 0.6891s	
1882/29450 (epoch 3.195), train_loss = 1.95689895, grad/param norm = 1.9600e-01, time/batch = 0.6850s	
1883/29450 (epoch 3.197), train_loss = 2.11389410, grad/param norm = 1.9821e-01, time/batch = 0.6840s	
1884/29450 (epoch 3.199), train_loss = 1.85103237, grad/param norm = 1.8913e-01, time/batch = 0.6854s	
1885/29450 (epoch 3.200), train_loss = 2.15483924, grad/param norm = 1.9851e-01, time/batch = 0.6865s	
1886/29450 (epoch 3.202), train_loss = 1.92558295, grad/param norm = 2.0074e-01, time/batch = 0.6903s	
1887/29450 (epoch 3.204), train_loss = 1.80929049, grad/param norm = 2.1805e-01, time/batch = 0.6892s	
1888/29450 (epoch 3.205), train_loss = 1.88765907, grad/param norm = 2.0158e-01, time/batch = 0.6869s	
1889/29450 (epoch 3.207), train_loss = 1.89096485, grad/param norm = 2.0828e-01, time/batch = 0.6864s	
1890/29450 (epoch 3.209), train_loss = 1.83516510, grad/param norm = 2.3263e-01, time/batch = 0.6935s	
1891/29450 (epoch 3.211), train_loss = 2.05585531, grad/param norm = 2.2076e-01, time/batch = 0.6878s	
1892/29450 (epoch 3.212), train_loss = 1.82347230, grad/param norm = 2.3317e-01, time/batch = 0.6999s	
1893/29450 (epoch 3.214), train_loss = 2.05426588, grad/param norm = 2.4792e-01, time/batch = 0.6908s	
1894/29450 (epoch 3.216), train_loss = 1.91920998, grad/param norm = 2.0657e-01, time/batch = 0.6939s	
1895/29450 (epoch 3.217), train_loss = 2.12633741, grad/param norm = 2.0650e-01, time/batch = 0.6903s	
1896/29450 (epoch 3.219), train_loss = 1.62638960, grad/param norm = 2.1435e-01, time/batch = 0.6940s	
1897/29450 (epoch 3.221), train_loss = 1.99815277, grad/param norm = 2.2219e-01, time/batch = 0.6917s	
1898/29450 (epoch 3.222), train_loss = 1.96241622, grad/param norm = 2.1280e-01, time/batch = 0.6907s	
1899/29450 (epoch 3.224), train_loss = 1.85007606, grad/param norm = 2.2271e-01, time/batch = 0.6956s	
1900/29450 (epoch 3.226), train_loss = 2.10267352, grad/param norm = 2.1431e-01, time/batch = 0.6940s	
1901/29450 (epoch 3.228), train_loss = 1.94295393, grad/param norm = 1.9683e-01, time/batch = 0.7028s	
1902/29450 (epoch 3.229), train_loss = 1.85101580, grad/param norm = 1.9677e-01, time/batch = 0.6884s	
1903/29450 (epoch 3.231), train_loss = 1.81165918, grad/param norm = 2.0414e-01, time/batch = 0.6878s	
1904/29450 (epoch 3.233), train_loss = 1.78335239, grad/param norm = 2.0658e-01, time/batch = 0.6856s	
1905/29450 (epoch 3.234), train_loss = 1.84863794, grad/param norm = 2.0377e-01, time/batch = 0.6923s	
1906/29450 (epoch 3.236), train_loss = 2.14581880, grad/param norm = 2.2900e-01, time/batch = 0.6870s	
1907/29450 (epoch 3.238), train_loss = 1.97961882, grad/param norm = 2.4341e-01, time/batch = 0.6975s	
1908/29450 (epoch 3.239), train_loss = 2.05960056, grad/param norm = 2.6350e-01, time/batch = 0.6955s	
1909/29450 (epoch 3.241), train_loss = 1.94765481, grad/param norm = 2.1250e-01, time/batch = 0.6896s	
1910/29450 (epoch 3.243), train_loss = 1.96845573, grad/param norm = 1.9216e-01, time/batch = 0.6842s	
1911/29450 (epoch 3.244), train_loss = 2.18654844, grad/param norm = 2.0482e-01, time/batch = 0.6853s	
1912/29450 (epoch 3.246), train_loss = 2.00209945, grad/param norm = 2.3682e-01, time/batch = 0.6864s	
1913/29450 (epoch 3.248), train_loss = 1.96225685, grad/param norm = 2.4702e-01, time/batch = 0.6864s	
1914/29450 (epoch 3.250), train_loss = 1.91287546, grad/param norm = 2.2096e-01, time/batch = 0.6884s	
1915/29450 (epoch 3.251), train_loss = 1.98530341, grad/param norm = 2.2857e-01, time/batch = 0.6891s	
1916/29450 (epoch 3.253), train_loss = 1.81381929, grad/param norm = 2.0061e-01, time/batch = 0.6890s	
1917/29450 (epoch 3.255), train_loss = 1.90994420, grad/param norm = 2.0007e-01, time/batch = 0.6873s	
1918/29450 (epoch 3.256), train_loss = 1.89281208, grad/param norm = 1.9601e-01, time/batch = 0.6862s	
1919/29450 (epoch 3.258), train_loss = 1.96168085, grad/param norm = 2.0593e-01, time/batch = 0.7065s	
1920/29450 (epoch 3.260), train_loss = 2.08083731, grad/param norm = 2.3831e-01, time/batch = 0.7062s	
1921/29450 (epoch 3.261), train_loss = 2.09207683, grad/param norm = 2.2608e-01, time/batch = 0.6991s	
1922/29450 (epoch 3.263), train_loss = 1.92763274, grad/param norm = 2.1969e-01, time/batch = 0.6872s	
1923/29450 (epoch 3.265), train_loss = 1.82139947, grad/param norm = 2.0570e-01, time/batch = 0.6868s	
1924/29450 (epoch 3.267), train_loss = 2.02300838, grad/param norm = 1.8362e-01, time/batch = 0.6879s	
1925/29450 (epoch 3.268), train_loss = 1.77180187, grad/param norm = 1.7785e-01, time/batch = 0.6870s	
1926/29450 (epoch 3.270), train_loss = 1.90266991, grad/param norm = 2.1332e-01, time/batch = 0.6921s	
1927/29450 (epoch 3.272), train_loss = 1.81442914, grad/param norm = 2.0865e-01, time/batch = 0.6915s	
1928/29450 (epoch 3.273), train_loss = 1.94144021, grad/param norm = 2.1361e-01, time/batch = 0.6968s	
1929/29450 (epoch 3.275), train_loss = 1.90580289, grad/param norm = 1.8677e-01, time/batch = 0.7101s	
1930/29450 (epoch 3.277), train_loss = 1.78078405, grad/param norm = 2.4055e-01, time/batch = 0.7124s	
1931/29450 (epoch 3.278), train_loss = 1.94021828, grad/param norm = 2.1427e-01, time/batch = 0.7094s	
1932/29450 (epoch 3.280), train_loss = 1.85465384, grad/param norm = 1.8457e-01, time/batch = 0.6929s	
1933/29450 (epoch 3.282), train_loss = 2.05384966, grad/param norm = 2.1906e-01, time/batch = 0.6914s	
1934/29450 (epoch 3.284), train_loss = 2.05500066, grad/param norm = 2.1154e-01, time/batch = 0.6919s	
1935/29450 (epoch 3.285), train_loss = 1.94459139, grad/param norm = 2.1498e-01, time/batch = 0.6868s	
1936/29450 (epoch 3.287), train_loss = 2.01313653, grad/param norm = 2.2399e-01, time/batch = 0.6912s	
1937/29450 (epoch 3.289), train_loss = 2.16229133, grad/param norm = 2.4758e-01, time/batch = 0.7085s	
1938/29450 (epoch 3.290), train_loss = 1.99959177, grad/param norm = 2.1070e-01, time/batch = 0.7149s	
1939/29450 (epoch 3.292), train_loss = 1.93455123, grad/param norm = 2.1705e-01, time/batch = 0.7217s	
1940/29450 (epoch 3.294), train_loss = 2.13068732, grad/param norm = 2.3196e-01, time/batch = 0.7069s	
1941/29450 (epoch 3.295), train_loss = 1.79474613, grad/param norm = 2.1195e-01, time/batch = 0.7047s	
1942/29450 (epoch 3.297), train_loss = 2.11770938, grad/param norm = 2.1933e-01, time/batch = 0.6887s	
1943/29450 (epoch 3.299), train_loss = 1.89204475, grad/param norm = 2.3886e-01, time/batch = 0.7019s	
1944/29450 (epoch 3.301), train_loss = 2.01283603, grad/param norm = 2.1446e-01, time/batch = 0.6959s	
1945/29450 (epoch 3.302), train_loss = 1.95377333, grad/param norm = 1.9591e-01, time/batch = 0.6844s	
1946/29450 (epoch 3.304), train_loss = 1.84942656, grad/param norm = 2.0299e-01, time/batch = 0.6840s	
1947/29450 (epoch 3.306), train_loss = 2.02240323, grad/param norm = 2.0246e-01, time/batch = 0.6907s	
1948/29450 (epoch 3.307), train_loss = 2.06514797, grad/param norm = 2.0555e-01, time/batch = 0.6864s	
1949/29450 (epoch 3.309), train_loss = 2.17478055, grad/param norm = 2.2765e-01, time/batch = 0.7071s	
1950/29450 (epoch 3.311), train_loss = 2.00105799, grad/param norm = 2.3171e-01, time/batch = 0.7069s	
1951/29450 (epoch 3.312), train_loss = 2.06667426, grad/param norm = 2.1933e-01, time/batch = 0.6906s	
1952/29450 (epoch 3.314), train_loss = 2.08786563, grad/param norm = 2.0711e-01, time/batch = 0.7019s	
1953/29450 (epoch 3.316), train_loss = 1.85185208, grad/param norm = 2.2337e-01, time/batch = 0.7083s	
1954/29450 (epoch 3.317), train_loss = 1.87737749, grad/param norm = 1.9332e-01, time/batch = 0.7089s	
1955/29450 (epoch 3.319), train_loss = 1.76725080, grad/param norm = 1.8678e-01, time/batch = 0.7065s	
1956/29450 (epoch 3.321), train_loss = 1.90006552, grad/param norm = 1.9758e-01, time/batch = 0.6967s	
1957/29450 (epoch 3.323), train_loss = 2.09463127, grad/param norm = 2.2224e-01, time/batch = 0.6958s	
1958/29450 (epoch 3.324), train_loss = 1.97204751, grad/param norm = 2.4122e-01, time/batch = 0.6872s	
1959/29450 (epoch 3.326), train_loss = 2.01080489, grad/param norm = 2.1435e-01, time/batch = 0.7176s	
1960/29450 (epoch 3.328), train_loss = 2.12867919, grad/param norm = 2.2750e-01, time/batch = 0.7019s	
1961/29450 (epoch 3.329), train_loss = 2.08000755, grad/param norm = 2.2579e-01, time/batch = 0.6866s	
1962/29450 (epoch 3.331), train_loss = 1.75774107, grad/param norm = 2.1461e-01, time/batch = 0.6856s	
1963/29450 (epoch 3.333), train_loss = 2.03175084, grad/param norm = 2.0364e-01, time/batch = 0.6832s	
1964/29450 (epoch 3.334), train_loss = 1.88793363, grad/param norm = 2.1603e-01, time/batch = 0.6856s	
1965/29450 (epoch 3.336), train_loss = 1.75744520, grad/param norm = 1.9226e-01, time/batch = 0.6873s	
1966/29450 (epoch 3.338), train_loss = 1.79057531, grad/param norm = 2.0813e-01, time/batch = 0.6902s	
1967/29450 (epoch 3.340), train_loss = 1.90626130, grad/param norm = 2.3255e-01, time/batch = 0.6868s	
1968/29450 (epoch 3.341), train_loss = 2.00785673, grad/param norm = 2.1517e-01, time/batch = 0.6935s	
1969/29450 (epoch 3.343), train_loss = 1.87586050, grad/param norm = 2.2622e-01, time/batch = 0.6868s	
1970/29450 (epoch 3.345), train_loss = 2.29522246, grad/param norm = 2.3014e-01, time/batch = 0.6978s	
1971/29450 (epoch 3.346), train_loss = 2.05138112, grad/param norm = 1.9738e-01, time/batch = 0.7054s	
1972/29450 (epoch 3.348), train_loss = 2.20933903, grad/param norm = 2.3436e-01, time/batch = 0.7046s	
1973/29450 (epoch 3.350), train_loss = 2.08352329, grad/param norm = 2.3496e-01, time/batch = 0.6988s	
1974/29450 (epoch 3.351), train_loss = 2.20463266, grad/param norm = 2.0593e-01, time/batch = 0.7028s	
1975/29450 (epoch 3.353), train_loss = 1.86337900, grad/param norm = 1.9602e-01, time/batch = 0.7095s	
1976/29450 (epoch 3.355), train_loss = 1.81846079, grad/param norm = 2.0135e-01, time/batch = 0.6953s	
1977/29450 (epoch 3.357), train_loss = 1.81143085, grad/param norm = 2.0020e-01, time/batch = 0.6921s	
1978/29450 (epoch 3.358), train_loss = 1.72958543, grad/param norm = 2.2108e-01, time/batch = 0.6977s	
1979/29450 (epoch 3.360), train_loss = 2.04170680, grad/param norm = 2.5267e-01, time/batch = 0.6958s	
1980/29450 (epoch 3.362), train_loss = 1.91905478, grad/param norm = 1.9938e-01, time/batch = 0.6978s	
1981/29450 (epoch 3.363), train_loss = 1.90228365, grad/param norm = 2.2456e-01, time/batch = 0.6989s	
1982/29450 (epoch 3.365), train_loss = 1.88548322, grad/param norm = 2.1514e-01, time/batch = 0.7026s	
1983/29450 (epoch 3.367), train_loss = 1.89573871, grad/param norm = 2.1351e-01, time/batch = 0.7060s	
1984/29450 (epoch 3.368), train_loss = 1.99008354, grad/param norm = 2.0425e-01, time/batch = 0.7050s	
1985/29450 (epoch 3.370), train_loss = 1.80101053, grad/param norm = 1.9566e-01, time/batch = 0.7051s	
1986/29450 (epoch 3.372), train_loss = 2.06863451, grad/param norm = 2.3411e-01, time/batch = 0.7089s	
1987/29450 (epoch 3.374), train_loss = 1.97938903, grad/param norm = 2.6542e-01, time/batch = 0.7066s	
1988/29450 (epoch 3.375), train_loss = 2.16110375, grad/param norm = 2.3738e-01, time/batch = 0.6876s	
1989/29450 (epoch 3.377), train_loss = 1.98320689, grad/param norm = 2.2998e-01, time/batch = 0.7096s	
1990/29450 (epoch 3.379), train_loss = 1.84119342, grad/param norm = 2.0860e-01, time/batch = 0.7031s	
1991/29450 (epoch 3.380), train_loss = 1.76397580, grad/param norm = 2.3083e-01, time/batch = 0.6857s	
1992/29450 (epoch 3.382), train_loss = 1.97171749, grad/param norm = 2.3012e-01, time/batch = 0.6860s	
1993/29450 (epoch 3.384), train_loss = 2.06307374, grad/param norm = 2.2347e-01, time/batch = 0.6896s	
1994/29450 (epoch 3.385), train_loss = 2.00784010, grad/param norm = 2.3795e-01, time/batch = 0.6857s	
1995/29450 (epoch 3.387), train_loss = 1.99184859, grad/param norm = 2.0176e-01, time/batch = 0.6881s	
1996/29450 (epoch 3.389), train_loss = 2.19489719, grad/param norm = 2.4640e-01, time/batch = 0.6834s	
1997/29450 (epoch 3.390), train_loss = 1.89385870, grad/param norm = 2.2253e-01, time/batch = 0.6827s	
1998/29450 (epoch 3.392), train_loss = 1.81205719, grad/param norm = 2.3117e-01, time/batch = 0.6855s	
1999/29450 (epoch 3.394), train_loss = 1.89321422, grad/param norm = 2.2203e-01, time/batch = 0.6886s	
evaluating loss over split index 2	
1/32...	
2/32...	
3/32...	
4/32...	
5/32...	
6/32...	
7/32...	
8/32...	
9/32...	
10/32...	
11/32...	
12/32...	
13/32...	
14/32...	
15/32...	
16/32...	
17/32...	
18/32...	
19/32...	
20/32...	
21/32...	
22/32...	
23/32...	
24/32...	
25/32...	
26/32...	
27/32...	
28/32...	
29/32...	
30/32...	
31/32...	
32/32...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_torproject_epoch3.40_2.0034.t7	
2000/29450 (epoch 3.396), train_loss = 1.82688233, grad/param norm = 2.0064e-01, time/batch = 0.6863s	
2001/29450 (epoch 3.397), train_loss = 2.05382967, grad/param norm = 2.3496e-01, time/batch = 0.7201s	
2002/29450 (epoch 3.399), train_loss = 1.79537196, grad/param norm = 2.0909e-01, time/batch = 0.7007s	
2003/29450 (epoch 3.401), train_loss = 2.04518146, grad/param norm = 2.1406e-01, time/batch = 0.6953s	
2004/29450 (epoch 3.402), train_loss = 2.02465437, grad/param norm = 2.0390e-01, time/batch = 0.6951s	
2005/29450 (epoch 3.404), train_loss = 1.81640514, grad/param norm = 1.8266e-01, time/batch = 0.6912s	
2006/29450 (epoch 3.406), train_loss = 1.91628857, grad/param norm = 1.7605e-01, time/batch = 0.6887s	
2007/29450 (epoch 3.407), train_loss = 2.01328406, grad/param norm = 2.2101e-01, time/batch = 0.6875s	
2008/29450 (epoch 3.409), train_loss = 1.95684022, grad/param norm = 1.9874e-01, time/batch = 0.6847s	
2009/29450 (epoch 3.411), train_loss = 1.77160179, grad/param norm = 2.2130e-01, time/batch = 0.6837s	
2010/29450 (epoch 3.413), train_loss = 2.03171797, grad/param norm = 2.2941e-01, time/batch = 0.7007s	
2011/29450 (epoch 3.414), train_loss = 1.72375602, grad/param norm = 2.6184e-01, time/batch = 0.6867s	
2012/29450 (epoch 3.416), train_loss = 1.73836541, grad/param norm = 2.1806e-01, time/batch = 0.6854s	
2013/29450 (epoch 3.418), train_loss = 1.92261464, grad/param norm = 2.0911e-01, time/batch = 0.6902s	
2014/29450 (epoch 3.419), train_loss = 1.86868443, grad/param norm = 1.8629e-01, time/batch = 0.7064s	
2015/29450 (epoch 3.421), train_loss = 1.66636237, grad/param norm = 1.9084e-01, time/batch = 0.7174s	
2016/29450 (epoch 3.423), train_loss = 1.94019285, grad/param norm = 2.2016e-01, time/batch = 0.7233s	
2017/29450 (epoch 3.424), train_loss = 2.06579457, grad/param norm = 2.1778e-01, time/batch = 0.7132s	
2018/29450 (epoch 3.426), train_loss = 1.98073967, grad/param norm = 1.9815e-01, time/batch = 0.7144s	
2019/29450 (epoch 3.428), train_loss = 1.86709410, grad/param norm = 1.8973e-01, time/batch = 0.7108s	
2020/29450 (epoch 3.430), train_loss = 1.97354455, grad/param norm = 2.2979e-01, time/batch = 0.7149s	
2021/29450 (epoch 3.431), train_loss = 1.63578494, grad/param norm = 2.2016e-01, time/batch = 0.7182s	
2022/29450 (epoch 3.433), train_loss = 2.12150545, grad/param norm = 2.3985e-01, time/batch = 0.7068s	
2023/29450 (epoch 3.435), train_loss = 1.82547495, grad/param norm = 2.0109e-01, time/batch = 0.7058s	
2024/29450 (epoch 3.436), train_loss = 2.04056374, grad/param norm = 2.0636e-01, time/batch = 0.6931s	
2025/29450 (epoch 3.438), train_loss = 2.00300950, grad/param norm = 2.3931e-01, time/batch = 0.6885s	
2026/29450 (epoch 3.440), train_loss = 2.20845538, grad/param norm = 2.3454e-01, time/batch = 0.6859s	
2027/29450 (epoch 3.441), train_loss = 2.00908312, grad/param norm = 2.0469e-01, time/batch = 0.6871s	
2028/29450 (epoch 3.443), train_loss = 1.96145418, grad/param norm = 2.4093e-01, time/batch = 0.6900s	
2029/29450 (epoch 3.445), train_loss = 1.85251106, grad/param norm = 2.0266e-01, time/batch = 0.6856s	
2030/29450 (epoch 3.447), train_loss = 1.89840444, grad/param norm = 1.9088e-01, time/batch = 0.6824s	
2031/29450 (epoch 3.448), train_loss = 1.81744613, grad/param norm = 1.9709e-01, time/batch = 0.6862s	
2032/29450 (epoch 3.450), train_loss = 2.02597806, grad/param norm = 1.9553e-01, time/batch = 0.6943s	
2033/29450 (epoch 3.452), train_loss = 1.98959749, grad/param norm = 1.9864e-01, time/batch = 0.6904s	
2034/29450 (epoch 3.453), train_loss = 1.84400856, grad/param norm = 1.9190e-01, time/batch = 0.6923s	
2035/29450 (epoch 3.455), train_loss = 1.92101880, grad/param norm = 2.0349e-01, time/batch = 0.6862s	
2036/29450 (epoch 3.457), train_loss = 1.98195879, grad/param norm = 2.4438e-01, time/batch = 0.6900s	
2037/29450 (epoch 3.458), train_loss = 2.08210788, grad/param norm = 2.1751e-01, time/batch = 0.6854s	
2038/29450 (epoch 3.460), train_loss = 1.91835707, grad/param norm = 2.0193e-01, time/batch = 0.6876s	
2039/29450 (epoch 3.462), train_loss = 1.90457835, grad/param norm = 2.1396e-01, time/batch = 0.6857s	
2040/29450 (epoch 3.463), train_loss = 2.09978890, grad/param norm = 2.3664e-01, time/batch = 0.7033s	
2041/29450 (epoch 3.465), train_loss = 1.79489273, grad/param norm = 1.9838e-01, time/batch = 0.7119s	
2042/29450 (epoch 3.467), train_loss = 1.79794476, grad/param norm = 1.8034e-01, time/batch = 0.6893s	
2043/29450 (epoch 3.469), train_loss = 2.07459078, grad/param norm = 2.2438e-01, time/batch = 0.6868s	
2044/29450 (epoch 3.470), train_loss = 1.56771563, grad/param norm = 1.7680e-01, time/batch = 0.6884s	
2045/29450 (epoch 3.472), train_loss = 2.07507489, grad/param norm = 2.1628e-01, time/batch = 0.6877s	
2046/29450 (epoch 3.474), train_loss = 1.97898753, grad/param norm = 2.0256e-01, time/batch = 0.6861s	
2047/29450 (epoch 3.475), train_loss = 2.02062136, grad/param norm = 1.9488e-01, time/batch = 0.6866s	
2048/29450 (epoch 3.477), train_loss = 1.86445607, grad/param norm = 1.8210e-01, time/batch = 0.6866s	
2049/29450 (epoch 3.479), train_loss = 1.98184842, grad/param norm = 2.0855e-01, time/batch = 0.6895s	
2050/29450 (epoch 3.480), train_loss = 1.97977024, grad/param norm = 2.5734e-01, time/batch = 0.7018s	
2051/29450 (epoch 3.482), train_loss = 1.88922679, grad/param norm = 1.9477e-01, time/batch = 0.7140s	
2052/29450 (epoch 3.484), train_loss = 1.74817630, grad/param norm = 1.8803e-01, time/batch = 0.6848s	
2053/29450 (epoch 3.486), train_loss = 1.91029969, grad/param norm = 1.8718e-01, time/batch = 0.6874s	
2054/29450 (epoch 3.487), train_loss = 1.91875791, grad/param norm = 1.9078e-01, time/batch = 0.6838s	
2055/29450 (epoch 3.489), train_loss = 1.79086902, grad/param norm = 2.0003e-01, time/batch = 0.7243s	
2056/29450 (epoch 3.491), train_loss = 1.85604510, grad/param norm = 2.0716e-01, time/batch = 0.7034s	
2057/29450 (epoch 3.492), train_loss = 1.88516425, grad/param norm = 2.1102e-01, time/batch = 0.7048s	
2058/29450 (epoch 3.494), train_loss = 2.14044456, grad/param norm = 2.2113e-01, time/batch = 0.7017s	
2059/29450 (epoch 3.496), train_loss = 2.00285917, grad/param norm = 1.9517e-01, time/batch = 0.6926s	
2060/29450 (epoch 3.497), train_loss = 1.84493813, grad/param norm = 1.9842e-01, time/batch = 0.6877s	
2061/29450 (epoch 3.499), train_loss = 1.89390747, grad/param norm = 1.8260e-01, time/batch = 0.6963s	
2062/29450 (epoch 3.501), train_loss = 1.93855543, grad/param norm = 2.0921e-01, time/batch = 0.7022s	
2063/29450 (epoch 3.503), train_loss = 1.95933074, grad/param norm = 2.2663e-01, time/batch = 0.7043s	
2064/29450 (epoch 3.504), train_loss = 1.97385066, grad/param norm = 2.2930e-01, time/batch = 0.6946s	
2065/29450 (epoch 3.506), train_loss = 2.05080010, grad/param norm = 2.1486e-01, time/batch = 0.6893s	
2066/29450 (epoch 3.508), train_loss = 1.85392801, grad/param norm = 1.9764e-01, time/batch = 0.6976s	
2067/29450 (epoch 3.509), train_loss = 1.76279063, grad/param norm = 1.9412e-01, time/batch = 0.6937s	
2068/29450 (epoch 3.511), train_loss = 1.99420673, grad/param norm = 2.0374e-01, time/batch = 0.6984s	
2069/29450 (epoch 3.513), train_loss = 2.02761488, grad/param norm = 2.4702e-01, time/batch = 0.6935s	
2070/29450 (epoch 3.514), train_loss = 1.88780388, grad/param norm = 2.0657e-01, time/batch = 0.7052s	
2071/29450 (epoch 3.516), train_loss = 1.97700087, grad/param norm = 2.0902e-01, time/batch = 0.7174s	
2072/29450 (epoch 3.518), train_loss = 2.11916643, grad/param norm = 2.1632e-01, time/batch = 0.6896s	
2073/29450 (epoch 3.520), train_loss = 1.78136507, grad/param norm = 2.1053e-01, time/batch = 0.6862s	
2074/29450 (epoch 3.521), train_loss = 2.09724922, grad/param norm = 2.0350e-01, time/batch = 0.6867s	
2075/29450 (epoch 3.523), train_loss = 2.10927617, grad/param norm = 2.3166e-01, time/batch = 0.6952s	
2076/29450 (epoch 3.525), train_loss = 2.24624794, grad/param norm = 2.4639e-01, time/batch = 0.6929s	
2077/29450 (epoch 3.526), train_loss = 2.01319074, grad/param norm = 2.3441e-01, time/batch = 0.7026s	
2078/29450 (epoch 3.528), train_loss = 2.08043383, grad/param norm = 2.0714e-01, time/batch = 0.6858s	
2079/29450 (epoch 3.530), train_loss = 1.94962474, grad/param norm = 2.0641e-01, time/batch = 0.6853s	
2080/29450 (epoch 3.531), train_loss = 1.84109914, grad/param norm = 1.7852e-01, time/batch = 0.6964s	
2081/29450 (epoch 3.533), train_loss = 1.93505620, grad/param norm = 2.0009e-01, time/batch = 0.7139s	
2082/29450 (epoch 3.535), train_loss = 2.47913663, grad/param norm = 3.1823e-01, time/batch = 0.6877s	
2083/29450 (epoch 3.537), train_loss = 2.05942590, grad/param norm = 2.5510e-01, time/batch = 0.6869s	
2084/29450 (epoch 3.538), train_loss = 1.86753260, grad/param norm = 2.0205e-01, time/batch = 0.6973s	
2085/29450 (epoch 3.540), train_loss = 2.10903805, grad/param norm = 2.0993e-01, time/batch = 0.6878s	
2086/29450 (epoch 3.542), train_loss = 1.95613291, grad/param norm = 2.3270e-01, time/batch = 0.6913s	
2087/29450 (epoch 3.543), train_loss = 1.92191626, grad/param norm = 2.0640e-01, time/batch = 0.6895s	
2088/29450 (epoch 3.545), train_loss = 1.88119524, grad/param norm = 1.8976e-01, time/batch = 0.6929s	
2089/29450 (epoch 3.547), train_loss = 2.00434710, grad/param norm = 1.9329e-01, time/batch = 0.6858s	
2090/29450 (epoch 3.548), train_loss = 1.75543950, grad/param norm = 2.0788e-01, time/batch = 0.6842s	
2091/29450 (epoch 3.550), train_loss = 1.88393821, grad/param norm = 1.9331e-01, time/batch = 0.6915s	
2092/29450 (epoch 3.552), train_loss = 1.86967087, grad/param norm = 1.8762e-01, time/batch = 0.6914s	
2093/29450 (epoch 3.553), train_loss = 1.94998485, grad/param norm = 1.8766e-01, time/batch = 0.6926s	
2094/29450 (epoch 3.555), train_loss = 1.99722003, grad/param norm = 2.1457e-01, time/batch = 0.6854s	
2095/29450 (epoch 3.557), train_loss = 1.93994852, grad/param norm = 2.1766e-01, time/batch = 0.6802s	
2096/29450 (epoch 3.559), train_loss = 1.71864877, grad/param norm = 2.1975e-01, time/batch = 0.6851s	
2097/29450 (epoch 3.560), train_loss = 1.93932437, grad/param norm = 2.1287e-01, time/batch = 0.6822s	
2098/29450 (epoch 3.562), train_loss = 1.91273742, grad/param norm = 1.9899e-01, time/batch = 0.6823s	
2099/29450 (epoch 3.564), train_loss = 1.96045539, grad/param norm = 2.0441e-01, time/batch = 0.6868s	
2100/29450 (epoch 3.565), train_loss = 2.04021302, grad/param norm = 2.4347e-01, time/batch = 0.7094s	
2101/29450 (epoch 3.567), train_loss = 2.08850013, grad/param norm = 2.3633e-01, time/batch = 0.7247s	
2102/29450 (epoch 3.569), train_loss = 1.95381645, grad/param norm = 2.0110e-01, time/batch = 0.7279s	
2103/29450 (epoch 3.570), train_loss = 2.13384996, grad/param norm = 2.0540e-01, time/batch = 0.7259s	
2104/29450 (epoch 3.572), train_loss = 1.97331244, grad/param norm = 1.9802e-01, time/batch = 0.7095s	
2105/29450 (epoch 3.574), train_loss = 1.82886081, grad/param norm = 2.1887e-01, time/batch = 0.7172s	
2106/29450 (epoch 3.576), train_loss = 2.03614247, grad/param norm = 2.4690e-01, time/batch = 0.7197s	
2107/29450 (epoch 3.577), train_loss = 2.10008715, grad/param norm = 2.1757e-01, time/batch = 0.6968s	
2108/29450 (epoch 3.579), train_loss = 1.89428909, grad/param norm = 2.0994e-01, time/batch = 0.6996s	
2109/29450 (epoch 3.581), train_loss = 2.02160990, grad/param norm = 1.9026e-01, time/batch = 0.6917s	
2110/29450 (epoch 3.582), train_loss = 1.64683657, grad/param norm = 1.9008e-01, time/batch = 0.6942s	
2111/29450 (epoch 3.584), train_loss = 1.99148966, grad/param norm = 2.4924e-01, time/batch = 0.6896s	
2112/29450 (epoch 3.586), train_loss = 1.91180723, grad/param norm = 2.0512e-01, time/batch = 0.7134s	
2113/29450 (epoch 3.587), train_loss = 2.18058076, grad/param norm = 2.2245e-01, time/batch = 0.6998s	
2114/29450 (epoch 3.589), train_loss = 1.90444327, grad/param norm = 2.2965e-01, time/batch = 0.7057s	
2115/29450 (epoch 3.591), train_loss = 1.82426159, grad/param norm = 1.9765e-01, time/batch = 0.7196s	
2116/29450 (epoch 3.593), train_loss = 1.93163359, grad/param norm = 2.1921e-01, time/batch = 0.7060s	
2117/29450 (epoch 3.594), train_loss = 1.82460384, grad/param norm = 1.9539e-01, time/batch = 0.7151s	
2118/29450 (epoch 3.596), train_loss = 1.85396423, grad/param norm = 1.9718e-01, time/batch = 0.7134s	
2119/29450 (epoch 3.598), train_loss = 2.00942820, grad/param norm = 2.1685e-01, time/batch = 0.6947s	
2120/29450 (epoch 3.599), train_loss = 1.94221102, grad/param norm = 2.1738e-01, time/batch = 0.6953s	
2121/29450 (epoch 3.601), train_loss = 1.89294537, grad/param norm = 1.8289e-01, time/batch = 0.6954s	
2122/29450 (epoch 3.603), train_loss = 1.94929451, grad/param norm = 2.1443e-01, time/batch = 0.6855s	
2123/29450 (epoch 3.604), train_loss = 1.94385984, grad/param norm = 1.9050e-01, time/batch = 0.7236s	
2124/29450 (epoch 3.606), train_loss = 1.95047851, grad/param norm = 1.9694e-01, time/batch = 0.7188s	
2125/29450 (epoch 3.608), train_loss = 1.76510074, grad/param norm = 1.9090e-01, time/batch = 0.7064s	
2126/29450 (epoch 3.610), train_loss = 1.80914694, grad/param norm = 1.8884e-01, time/batch = 0.7062s	
2127/29450 (epoch 3.611), train_loss = 1.84160503, grad/param norm = 1.8992e-01, time/batch = 0.7074s	
2128/29450 (epoch 3.613), train_loss = 1.72610540, grad/param norm = 1.7678e-01, time/batch = 0.7057s	
2129/29450 (epoch 3.615), train_loss = 1.81998274, grad/param norm = 2.0178e-01, time/batch = 0.6975s	
2130/29450 (epoch 3.616), train_loss = 1.84943903, grad/param norm = 1.9538e-01, time/batch = 0.6961s	
2131/29450 (epoch 3.618), train_loss = 1.58416413, grad/param norm = 1.8206e-01, time/batch = 0.7055s	
2132/29450 (epoch 3.620), train_loss = 2.01247323, grad/param norm = 2.1192e-01, time/batch = 0.7104s	
2133/29450 (epoch 3.621), train_loss = 1.81877782, grad/param norm = 2.1099e-01, time/batch = 0.7006s	
2134/29450 (epoch 3.623), train_loss = 1.82878116, grad/param norm = 2.0537e-01, time/batch = 0.6985s	
2135/29450 (epoch 3.625), train_loss = 1.87942623, grad/param norm = 1.9360e-01, time/batch = 0.6992s	
2136/29450 (epoch 3.626), train_loss = 1.99495016, grad/param norm = 2.1202e-01, time/batch = 0.7003s	
2137/29450 (epoch 3.628), train_loss = 1.87738839, grad/param norm = 2.0259e-01, time/batch = 0.6975s	
2138/29450 (epoch 3.630), train_loss = 1.77498365, grad/param norm = 1.8148e-01, time/batch = 0.6969s	
2139/29450 (epoch 3.632), train_loss = 1.85409070, grad/param norm = 1.7741e-01, time/batch = 0.6959s	
2140/29450 (epoch 3.633), train_loss = 2.06116821, grad/param norm = 2.3411e-01, time/batch = 0.6956s	
2141/29450 (epoch 3.635), train_loss = 1.61738488, grad/param norm = 1.8212e-01, time/batch = 0.7053s	
2142/29450 (epoch 3.637), train_loss = 1.87687202, grad/param norm = 2.2216e-01, time/batch = 0.6989s	
2143/29450 (epoch 3.638), train_loss = 1.67070251, grad/param norm = 2.1589e-01, time/batch = 0.6979s	
2144/29450 (epoch 3.640), train_loss = 2.03215908, grad/param norm = 2.2995e-01, time/batch = 0.7016s	
2145/29450 (epoch 3.642), train_loss = 1.87321680, grad/param norm = 2.1688e-01, time/batch = 0.6996s	
2146/29450 (epoch 3.643), train_loss = 1.77374943, grad/param norm = 1.9733e-01, time/batch = 0.7000s	
2147/29450 (epoch 3.645), train_loss = 1.88561845, grad/param norm = 2.1288e-01, time/batch = 0.6999s	
2148/29450 (epoch 3.647), train_loss = 2.17860890, grad/param norm = 2.3453e-01, time/batch = 0.7005s	
2149/29450 (epoch 3.649), train_loss = 2.10772159, grad/param norm = 2.2163e-01, time/batch = 0.7014s	
2150/29450 (epoch 3.650), train_loss = 1.94199422, grad/param norm = 1.9950e-01, time/batch = 0.7126s	
2151/29450 (epoch 3.652), train_loss = 1.88260538, grad/param norm = 1.9683e-01, time/batch = 0.7012s	
2152/29450 (epoch 3.654), train_loss = 1.97864571, grad/param norm = 2.1772e-01, time/batch = 0.6991s	
2153/29450 (epoch 3.655), train_loss = 1.95098838, grad/param norm = 2.3650e-01, time/batch = 0.6961s	
2154/29450 (epoch 3.657), train_loss = 1.97722786, grad/param norm = 2.0690e-01, time/batch = 0.7123s	
2155/29450 (epoch 3.659), train_loss = 2.17506778, grad/param norm = 2.0906e-01, time/batch = 0.7213s	
2156/29450 (epoch 3.660), train_loss = 1.72695786, grad/param norm = 2.0169e-01, time/batch = 0.7294s	
2157/29450 (epoch 3.662), train_loss = 1.71231963, grad/param norm = 1.7878e-01, time/batch = 0.7287s	
2158/29450 (epoch 3.664), train_loss = 1.80620369, grad/param norm = 1.8694e-01, time/batch = 0.7289s	
2159/29450 (epoch 3.666), train_loss = 2.00462830, grad/param norm = 1.9858e-01, time/batch = 0.7257s	
2160/29450 (epoch 3.667), train_loss = 2.02167443, grad/param norm = 1.9199e-01, time/batch = 0.7243s	
2161/29450 (epoch 3.669), train_loss = 2.01306682, grad/param norm = 2.0223e-01, time/batch = 0.7255s	
2162/29450 (epoch 3.671), train_loss = 1.71842673, grad/param norm = 2.2680e-01, time/batch = 0.6946s	
2163/29450 (epoch 3.672), train_loss = 1.76638463, grad/param norm = 1.8010e-01, time/batch = 0.6875s	
2164/29450 (epoch 3.674), train_loss = 1.90091259, grad/param norm = 2.0352e-01, time/batch = 0.6868s	
2165/29450 (epoch 3.676), train_loss = 1.97580052, grad/param norm = 2.1676e-01, time/batch = 0.6860s	
2166/29450 (epoch 3.677), train_loss = 2.01747457, grad/param norm = 2.1052e-01, time/batch = 0.6859s	
2167/29450 (epoch 3.679), train_loss = 1.83893378, grad/param norm = 2.0042e-01, time/batch = 0.6883s	
2168/29450 (epoch 3.681), train_loss = 2.19112930, grad/param norm = 2.0966e-01, time/batch = 0.6843s	
2169/29450 (epoch 3.683), train_loss = 1.95473363, grad/param norm = 1.9024e-01, time/batch = 0.6843s	
2170/29450 (epoch 3.684), train_loss = 1.91611461, grad/param norm = 1.9619e-01, time/batch = 0.6927s	
2171/29450 (epoch 3.686), train_loss = 2.06053242, grad/param norm = 1.8556e-01, time/batch = 0.6871s	
2172/29450 (epoch 3.688), train_loss = 1.86875214, grad/param norm = 2.1256e-01, time/batch = 0.6851s	
2173/29450 (epoch 3.689), train_loss = 1.77647385, grad/param norm = 2.1081e-01, time/batch = 0.6873s	
2174/29450 (epoch 3.691), train_loss = 1.85500345, grad/param norm = 2.2255e-01, time/batch = 0.6866s	
2175/29450 (epoch 3.693), train_loss = 2.09969701, grad/param norm = 2.2208e-01, time/batch = 0.6899s	
2176/29450 (epoch 3.694), train_loss = 1.93279893, grad/param norm = 1.9824e-01, time/batch = 0.6998s	
2177/29450 (epoch 3.696), train_loss = 2.10483780, grad/param norm = 2.1109e-01, time/batch = 0.7022s	
2178/29450 (epoch 3.698), train_loss = 1.92023503, grad/param norm = 2.0062e-01, time/batch = 0.7044s	
2179/29450 (epoch 3.699), train_loss = 2.09093938, grad/param norm = 2.1381e-01, time/batch = 0.7131s	
2180/29450 (epoch 3.701), train_loss = 1.79303389, grad/param norm = 1.9317e-01, time/batch = 0.6891s	
2181/29450 (epoch 3.703), train_loss = 1.88966611, grad/param norm = 2.0565e-01, time/batch = 0.6900s	
2182/29450 (epoch 3.705), train_loss = 2.04363461, grad/param norm = 2.1091e-01, time/batch = 0.6862s	
2183/29450 (epoch 3.706), train_loss = 1.79070765, grad/param norm = 1.8921e-01, time/batch = 0.6845s	
2184/29450 (epoch 3.708), train_loss = 1.77486450, grad/param norm = 1.6313e-01, time/batch = 0.6865s	
2185/29450 (epoch 3.710), train_loss = 2.05617779, grad/param norm = 2.0441e-01, time/batch = 0.7042s	
2186/29450 (epoch 3.711), train_loss = 1.95597990, grad/param norm = 1.9658e-01, time/batch = 0.7103s	
2187/29450 (epoch 3.713), train_loss = 1.99778079, grad/param norm = 2.1815e-01, time/batch = 0.7213s	
2188/29450 (epoch 3.715), train_loss = 2.02137322, grad/param norm = 2.1289e-01, time/batch = 0.6933s	
2189/29450 (epoch 3.716), train_loss = 1.79103294, grad/param norm = 1.9418e-01, time/batch = 0.6897s	
2190/29450 (epoch 3.718), train_loss = 1.91915608, grad/param norm = 1.9552e-01, time/batch = 0.6857s	
2191/29450 (epoch 3.720), train_loss = 1.75465018, grad/param norm = 1.9807e-01, time/batch = 0.6956s	
2192/29450 (epoch 3.722), train_loss = 1.81409634, grad/param norm = 2.0511e-01, time/batch = 0.6887s	
2193/29450 (epoch 3.723), train_loss = 1.86829179, grad/param norm = 2.1356e-01, time/batch = 0.6860s	
2194/29450 (epoch 3.725), train_loss = 1.83937517, grad/param norm = 1.8541e-01, time/batch = 0.6860s	
2195/29450 (epoch 3.727), train_loss = 1.87650272, grad/param norm = 2.0524e-01, time/batch = 0.6862s	
2196/29450 (epoch 3.728), train_loss = 1.85561725, grad/param norm = 2.0213e-01, time/batch = 0.6861s	
2197/29450 (epoch 3.730), train_loss = 2.06793045, grad/param norm = 1.9537e-01, time/batch = 0.6846s	
2198/29450 (epoch 3.732), train_loss = 1.85466252, grad/param norm = 1.8004e-01, time/batch = 0.7067s	
2199/29450 (epoch 3.733), train_loss = 2.10461941, grad/param norm = 2.3012e-01, time/batch = 0.7140s	
2200/29450 (epoch 3.735), train_loss = 1.93895253, grad/param norm = 2.2408e-01, time/batch = 0.6876s	
2201/29450 (epoch 3.737), train_loss = 1.96001325, grad/param norm = 2.5979e-01, time/batch = 0.6888s	
2202/29450 (epoch 3.739), train_loss = 1.93530872, grad/param norm = 2.5308e-01, time/batch = 0.6893s	
2203/29450 (epoch 3.740), train_loss = 2.12477851, grad/param norm = 2.2601e-01, time/batch = 0.6867s	
2204/29450 (epoch 3.742), train_loss = 2.01359517, grad/param norm = 2.0575e-01, time/batch = 0.6955s	
2205/29450 (epoch 3.744), train_loss = 1.96890388, grad/param norm = 2.0016e-01, time/batch = 0.6913s	
2206/29450 (epoch 3.745), train_loss = 1.83989334, grad/param norm = 2.2521e-01, time/batch = 0.6939s	
2207/29450 (epoch 3.747), train_loss = 1.76922015, grad/param norm = 2.0710e-01, time/batch = 0.7029s	
2208/29450 (epoch 3.749), train_loss = 2.01401350, grad/param norm = 2.0192e-01, time/batch = 0.6959s	
2209/29450 (epoch 3.750), train_loss = 2.00577728, grad/param norm = 1.9188e-01, time/batch = 0.7141s	
2210/29450 (epoch 3.752), train_loss = 1.93439841, grad/param norm = 1.8889e-01, time/batch = 0.6901s	
2211/29450 (epoch 3.754), train_loss = 1.81594407, grad/param norm = 1.7974e-01, time/batch = 0.6836s	
2212/29450 (epoch 3.756), train_loss = 1.94254301, grad/param norm = 2.0665e-01, time/batch = 0.6842s	
2213/29450 (epoch 3.757), train_loss = 2.15246578, grad/param norm = 2.1929e-01, time/batch = 0.6851s	
2214/29450 (epoch 3.759), train_loss = 2.02104513, grad/param norm = 2.2046e-01, time/batch = 0.6865s	
2215/29450 (epoch 3.761), train_loss = 2.12905853, grad/param norm = 2.1705e-01, time/batch = 0.6829s	
2216/29450 (epoch 3.762), train_loss = 1.96388323, grad/param norm = 2.0906e-01, time/batch = 0.6831s	
2217/29450 (epoch 3.764), train_loss = 1.99277230, grad/param norm = 2.0277e-01, time/batch = 0.6836s	
2218/29450 (epoch 3.766), train_loss = 2.07289562, grad/param norm = 2.0491e-01, time/batch = 0.6839s	
2219/29450 (epoch 3.767), train_loss = 1.77596508, grad/param norm = 1.8253e-01, time/batch = 0.6900s	
2220/29450 (epoch 3.769), train_loss = 2.15109277, grad/param norm = 2.4309e-01, time/batch = 0.6871s	
2221/29450 (epoch 3.771), train_loss = 2.01558502, grad/param norm = 2.2942e-01, time/batch = 0.6836s	
2222/29450 (epoch 3.772), train_loss = 1.97679686, grad/param norm = 2.1091e-01, time/batch = 0.6838s	
2223/29450 (epoch 3.774), train_loss = 1.67112004, grad/param norm = 1.8225e-01, time/batch = 0.6814s	
2224/29450 (epoch 3.776), train_loss = 1.88216249, grad/param norm = 2.0996e-01, time/batch = 0.6811s	
2225/29450 (epoch 3.778), train_loss = 1.94886343, grad/param norm = 2.1394e-01, time/batch = 0.6813s	
2226/29450 (epoch 3.779), train_loss = 2.06116658, grad/param norm = 1.9209e-01, time/batch = 0.6805s	
2227/29450 (epoch 3.781), train_loss = 1.66923553, grad/param norm = 2.2456e-01, time/batch = 0.6855s	
2228/29450 (epoch 3.783), train_loss = 1.73713423, grad/param norm = 2.0211e-01, time/batch = 0.6863s	
2229/29450 (epoch 3.784), train_loss = 1.86196748, grad/param norm = 1.8550e-01, time/batch = 0.6916s	
2230/29450 (epoch 3.786), train_loss = 1.66769495, grad/param norm = 1.7826e-01, time/batch = 0.6853s	
2231/29450 (epoch 3.788), train_loss = 1.99188216, grad/param norm = 2.0554e-01, time/batch = 0.6946s	
2232/29450 (epoch 3.789), train_loss = 2.10795672, grad/param norm = 1.9113e-01, time/batch = 0.6901s	
2233/29450 (epoch 3.791), train_loss = 1.62886144, grad/param norm = 2.0455e-01, time/batch = 0.6909s	
2234/29450 (epoch 3.793), train_loss = 1.81022699, grad/param norm = 1.9901e-01, time/batch = 0.6927s	
2235/29450 (epoch 3.795), train_loss = 2.01536619, grad/param norm = 2.1013e-01, time/batch = 0.6923s	
2236/29450 (epoch 3.796), train_loss = 1.92523595, grad/param norm = 2.1136e-01, time/batch = 0.6922s	
2237/29450 (epoch 3.798), train_loss = 1.90962629, grad/param norm = 1.9430e-01, time/batch = 0.6936s	
2238/29450 (epoch 3.800), train_loss = 1.67452396, grad/param norm = 1.7621e-01, time/batch = 0.6874s	
2239/29450 (epoch 3.801), train_loss = 1.93851440, grad/param norm = 2.0261e-01, time/batch = 0.6868s	
2240/29450 (epoch 3.803), train_loss = 1.92871425, grad/param norm = 2.0662e-01, time/batch = 0.6951s	
2241/29450 (epoch 3.805), train_loss = 1.98887793, grad/param norm = 2.1264e-01, time/batch = 0.6862s	
2242/29450 (epoch 3.806), train_loss = 1.87889737, grad/param norm = 2.1856e-01, time/batch = 0.6927s	
2243/29450 (epoch 3.808), train_loss = 2.11979247, grad/param norm = 2.1670e-01, time/batch = 0.6850s	
2244/29450 (epoch 3.810), train_loss = 1.97942531, grad/param norm = 2.1020e-01, time/batch = 0.6854s	
2245/29450 (epoch 3.812), train_loss = 1.80747638, grad/param norm = 2.0511e-01, time/batch = 0.6937s	
2246/29450 (epoch 3.813), train_loss = 2.09565368, grad/param norm = 2.1320e-01, time/batch = 0.7193s	
2247/29450 (epoch 3.815), train_loss = 1.93001992, grad/param norm = 2.1074e-01, time/batch = 0.6856s	
2248/29450 (epoch 3.817), train_loss = 1.91065703, grad/param norm = 2.0417e-01, time/batch = 0.6918s	
2249/29450 (epoch 3.818), train_loss = 1.78846686, grad/param norm = 1.9712e-01, time/batch = 0.7028s	
2250/29450 (epoch 3.820), train_loss = 1.95233054, grad/param norm = 2.2114e-01, time/batch = 0.6983s	
2251/29450 (epoch 3.822), train_loss = 2.06676635, grad/param norm = 2.0927e-01, time/batch = 0.6897s	
2252/29450 (epoch 3.823), train_loss = 1.83999361, grad/param norm = 1.7800e-01, time/batch = 0.6888s	
2253/29450 (epoch 3.825), train_loss = 1.73262008, grad/param norm = 1.9753e-01, time/batch = 0.7153s	
2254/29450 (epoch 3.827), train_loss = 1.93359887, grad/param norm = 2.0240e-01, time/batch = 0.7040s	
2255/29450 (epoch 3.829), train_loss = 1.78590363, grad/param norm = 1.9869e-01, time/batch = 0.6988s	
2256/29450 (epoch 3.830), train_loss = 2.11349500, grad/param norm = 1.9912e-01, time/batch = 0.7094s	
2257/29450 (epoch 3.832), train_loss = 2.16023241, grad/param norm = 2.2853e-01, time/batch = 0.7048s	
2258/29450 (epoch 3.834), train_loss = 1.81777875, grad/param norm = 2.2539e-01, time/batch = 0.7030s	
2259/29450 (epoch 3.835), train_loss = 1.80291046, grad/param norm = 1.9917e-01, time/batch = 0.6996s	
2260/29450 (epoch 3.837), train_loss = 1.83482584, grad/param norm = 1.9799e-01, time/batch = 0.7013s	
2261/29450 (epoch 3.839), train_loss = 1.97398793, grad/param norm = 2.1619e-01, time/batch = 0.7038s	
2262/29450 (epoch 3.840), train_loss = 2.07618125, grad/param norm = 2.2017e-01, time/batch = 0.7003s	
2263/29450 (epoch 3.842), train_loss = 1.76440216, grad/param norm = 2.2256e-01, time/batch = 0.7100s	
2264/29450 (epoch 3.844), train_loss = 1.71219945, grad/param norm = 1.8258e-01, time/batch = 0.7059s	
2265/29450 (epoch 3.846), train_loss = 1.94233464, grad/param norm = 1.9932e-01, time/batch = 0.7005s	
2266/29450 (epoch 3.847), train_loss = 1.79572791, grad/param norm = 2.0652e-01, time/batch = 0.7058s	
2267/29450 (epoch 3.849), train_loss = 1.85988190, grad/param norm = 2.0810e-01, time/batch = 0.7050s	
2268/29450 (epoch 3.851), train_loss = 1.98756949, grad/param norm = 2.0784e-01, time/batch = 0.7017s	
2269/29450 (epoch 3.852), train_loss = 1.90121812, grad/param norm = 2.0029e-01, time/batch = 0.7276s	
2270/29450 (epoch 3.854), train_loss = 1.72866661, grad/param norm = 2.1295e-01, time/batch = 0.7260s	
2271/29450 (epoch 3.856), train_loss = 1.77748830, grad/param norm = 2.2641e-01, time/batch = 0.7197s	
2272/29450 (epoch 3.857), train_loss = 1.68014031, grad/param norm = 1.9843e-01, time/batch = 0.7186s	
2273/29450 (epoch 3.859), train_loss = 1.74771514, grad/param norm = 1.9269e-01, time/batch = 0.7184s	
2274/29450 (epoch 3.861), train_loss = 1.92106167, grad/param norm = 1.9297e-01, time/batch = 0.7103s	
2275/29450 (epoch 3.862), train_loss = 1.83823382, grad/param norm = 1.8901e-01, time/batch = 0.7193s	
2276/29450 (epoch 3.864), train_loss = 1.94799242, grad/param norm = 1.8159e-01, time/batch = 0.7074s	
2277/29450 (epoch 3.866), train_loss = 1.85461298, grad/param norm = 1.9427e-01, time/batch = 0.7376s	
2278/29450 (epoch 3.868), train_loss = 1.91201321, grad/param norm = 2.0051e-01, time/batch = 0.7180s	
2279/29450 (epoch 3.869), train_loss = 1.71648506, grad/param norm = 2.1001e-01, time/batch = 0.7013s	
2280/29450 (epoch 3.871), train_loss = 1.69852901, grad/param norm = 1.9596e-01, time/batch = 0.6924s	
2281/29450 (epoch 3.873), train_loss = 1.80857502, grad/param norm = 1.9634e-01, time/batch = 0.7017s	
2282/29450 (epoch 3.874), train_loss = 1.67941884, grad/param norm = 1.9481e-01, time/batch = 0.6915s	
2283/29450 (epoch 3.876), train_loss = 1.78472851, grad/param norm = 2.1095e-01, time/batch = 0.6925s	
2284/29450 (epoch 3.878), train_loss = 2.01665636, grad/param norm = 2.3211e-01, time/batch = 0.6923s	
2285/29450 (epoch 3.879), train_loss = 2.21751405, grad/param norm = 2.3705e-01, time/batch = 0.7095s	
2286/29450 (epoch 3.881), train_loss = 1.93557309, grad/param norm = 2.4759e-01, time/batch = 0.6982s	
2287/29450 (epoch 3.883), train_loss = 2.02972468, grad/param norm = 2.0077e-01, time/batch = 0.6867s	
2288/29450 (epoch 3.885), train_loss = 1.88904195, grad/param norm = 1.7976e-01, time/batch = 0.6859s	
2289/29450 (epoch 3.886), train_loss = 1.94337626, grad/param norm = 1.9636e-01, time/batch = 0.6907s	
2290/29450 (epoch 3.888), train_loss = 1.79898804, grad/param norm = 2.1962e-01, time/batch = 0.6903s	
2291/29450 (epoch 3.890), train_loss = 1.96236700, grad/param norm = 1.8918e-01, time/batch = 0.6930s	
2292/29450 (epoch 3.891), train_loss = 2.10385857, grad/param norm = 2.1119e-01, time/batch = 0.6869s	
2293/29450 (epoch 3.893), train_loss = 1.83492581, grad/param norm = 1.8124e-01, time/batch = 0.6866s	
2294/29450 (epoch 3.895), train_loss = 2.11153995, grad/param norm = 2.3549e-01, time/batch = 0.6830s	
2295/29450 (epoch 3.896), train_loss = 1.92369545, grad/param norm = 2.0160e-01, time/batch = 0.6882s	
2296/29450 (epoch 3.898), train_loss = 1.79067273, grad/param norm = 1.9132e-01, time/batch = 0.7008s	
2297/29450 (epoch 3.900), train_loss = 2.10993220, grad/param norm = 2.3190e-01, time/batch = 0.6844s	
2298/29450 (epoch 3.902), train_loss = 1.90443627, grad/param norm = 2.2673e-01, time/batch = 0.6923s	
2299/29450 (epoch 3.903), train_loss = 1.90643970, grad/param norm = 2.0995e-01, time/batch = 0.7163s	
2300/29450 (epoch 3.905), train_loss = 1.86940572, grad/param norm = 1.8215e-01, time/batch = 0.6929s	
2301/29450 (epoch 3.907), train_loss = 2.07794788, grad/param norm = 2.1551e-01, time/batch = 0.6844s	
2302/29450 (epoch 3.908), train_loss = 2.18302485, grad/param norm = 2.1193e-01, time/batch = 0.6849s	
2303/29450 (epoch 3.910), train_loss = 1.99172666, grad/param norm = 1.9204e-01, time/batch = 0.6852s	
2304/29450 (epoch 3.912), train_loss = 1.78400654, grad/param norm = 2.0301e-01, time/batch = 0.6845s	
2305/29450 (epoch 3.913), train_loss = 1.83614231, grad/param norm = 2.0045e-01, time/batch = 0.6855s	
2306/29450 (epoch 3.915), train_loss = 1.87746654, grad/param norm = 2.0552e-01, time/batch = 0.6868s	
2307/29450 (epoch 3.917), train_loss = 1.85774841, grad/param norm = 1.9279e-01, time/batch = 0.6861s	
2308/29450 (epoch 3.919), train_loss = 1.96371230, grad/param norm = 2.0053e-01, time/batch = 0.6847s	
2309/29450 (epoch 3.920), train_loss = 2.02045639, grad/param norm = 2.1563e-01, time/batch = 0.7135s	
2310/29450 (epoch 3.922), train_loss = 1.96575618, grad/param norm = 2.0946e-01, time/batch = 0.6907s	
2311/29450 (epoch 3.924), train_loss = 2.04628846, grad/param norm = 2.1990e-01, time/batch = 0.6884s	
2312/29450 (epoch 3.925), train_loss = 1.86055534, grad/param norm = 1.8273e-01, time/batch = 0.6854s	
2313/29450 (epoch 3.927), train_loss = 2.13636995, grad/param norm = 2.0644e-01, time/batch = 0.6853s	
2314/29450 (epoch 3.929), train_loss = 2.12267361, grad/param norm = 2.4953e-01, time/batch = 0.6846s	
2315/29450 (epoch 3.930), train_loss = 2.09149099, grad/param norm = 2.5372e-01, time/batch = 0.6844s	
2316/29450 (epoch 3.932), train_loss = 2.09239043, grad/param norm = 2.1124e-01, time/batch = 0.6811s	
2317/29450 (epoch 3.934), train_loss = 1.97959338, grad/param norm = 1.8750e-01, time/batch = 0.6858s	
2318/29450 (epoch 3.935), train_loss = 1.93346597, grad/param norm = 1.9215e-01, time/batch = 0.6839s	
2319/29450 (epoch 3.937), train_loss = 1.88921934, grad/param norm = 2.1147e-01, time/batch = 0.7137s	
2320/29450 (epoch 3.939), train_loss = 1.85704087, grad/param norm = 1.9595e-01, time/batch = 0.7045s	
2321/29450 (epoch 3.941), train_loss = 2.01350384, grad/param norm = 2.1752e-01, time/batch = 0.6947s	
2322/29450 (epoch 3.942), train_loss = 1.74737620, grad/param norm = 2.0368e-01, time/batch = 0.6925s	
2323/29450 (epoch 3.944), train_loss = 1.86995462, grad/param norm = 2.0184e-01, time/batch = 0.6859s	
2324/29450 (epoch 3.946), train_loss = 1.77943008, grad/param norm = 1.9511e-01, time/batch = 0.6878s	
2325/29450 (epoch 3.947), train_loss = 1.78342622, grad/param norm = 1.8921e-01, time/batch = 0.6909s	
2326/29450 (epoch 3.949), train_loss = 1.81624878, grad/param norm = 2.0566e-01, time/batch = 0.6828s	
2327/29450 (epoch 3.951), train_loss = 1.78023697, grad/param norm = 1.8636e-01, time/batch = 0.6863s	
2328/29450 (epoch 3.952), train_loss = 1.94684058, grad/param norm = 1.9728e-01, time/batch = 0.6874s	
2329/29450 (epoch 3.954), train_loss = 1.78675087, grad/param norm = 1.9868e-01, time/batch = 0.6821s	
2330/29450 (epoch 3.956), train_loss = 1.87068455, grad/param norm = 2.0585e-01, time/batch = 0.6847s	
2331/29450 (epoch 3.958), train_loss = 1.86507179, grad/param norm = 1.9999e-01, time/batch = 0.6858s	
2332/29450 (epoch 3.959), train_loss = 1.94931660, grad/param norm = 1.8072e-01, time/batch = 0.6813s	
2333/29450 (epoch 3.961), train_loss = 1.89770708, grad/param norm = 1.9929e-01, time/batch = 0.6864s	
2334/29450 (epoch 3.963), train_loss = 1.76710164, grad/param norm = 1.9253e-01, time/batch = 0.6843s	
2335/29450 (epoch 3.964), train_loss = 1.88729514, grad/param norm = 2.1251e-01, time/batch = 0.6845s	
2336/29450 (epoch 3.966), train_loss = 1.94359882, grad/param norm = 1.9978e-01, time/batch = 0.6819s	
2337/29450 (epoch 3.968), train_loss = 1.83343382, grad/param norm = 1.9565e-01, time/batch = 0.6799s	
2338/29450 (epoch 3.969), train_loss = 2.05848917, grad/param norm = 2.2655e-01, time/batch = 0.6794s	
2339/29450 (epoch 3.971), train_loss = 1.65639540, grad/param norm = 1.7929e-01, time/batch = 0.6809s	
2340/29450 (epoch 3.973), train_loss = 1.76054038, grad/param norm = 1.9129e-01, time/batch = 0.6804s	
2341/29450 (epoch 3.975), train_loss = 1.94008421, grad/param norm = 2.1971e-01, time/batch = 0.6854s	
2342/29450 (epoch 3.976), train_loss = 1.99297462, grad/param norm = 2.0430e-01, time/batch = 0.6930s	
2343/29450 (epoch 3.978), train_loss = 1.83565774, grad/param norm = 2.0534e-01, time/batch = 0.6956s	
2344/29450 (epoch 3.980), train_loss = 1.71062694, grad/param norm = 2.0441e-01, time/batch = 0.6829s	
2345/29450 (epoch 3.981), train_loss = 1.77369061, grad/param norm = 2.0961e-01, time/batch = 0.6840s	
2346/29450 (epoch 3.983), train_loss = 1.77950816, grad/param norm = 2.2405e-01, time/batch = 0.6890s	
2347/29450 (epoch 3.985), train_loss = 1.96521672, grad/param norm = 2.0205e-01, time/batch = 0.6825s	
2348/29450 (epoch 3.986), train_loss = 2.12904692, grad/param norm = 2.2558e-01, time/batch = 0.6816s	
2349/29450 (epoch 3.988), train_loss = 1.81542143, grad/param norm = 2.0510e-01, time/batch = 0.6896s	
2350/29450 (epoch 3.990), train_loss = 1.85635697, grad/param norm = 2.0212e-01, time/batch = 0.6856s	
2351/29450 (epoch 3.992), train_loss = 1.57850210, grad/param norm = 1.8172e-01, time/batch = 0.6915s	
2352/29450 (epoch 3.993), train_loss = 2.03887462, grad/param norm = 1.9058e-01, time/batch = 0.6868s	
2353/29450 (epoch 3.995), train_loss = 1.87613554, grad/param norm = 1.8178e-01, time/batch = 0.6828s	
2354/29450 (epoch 3.997), train_loss = 1.81010902, grad/param norm = 2.0019e-01, time/batch = 0.6799s	
2355/29450 (epoch 3.998), train_loss = 1.84461682, grad/param norm = 2.0461e-01, time/batch = 0.6833s	
2356/29450 (epoch 4.000), train_loss = 1.98012984, grad/param norm = 2.1801e-01, time/batch = 0.6841s	
2357/29450 (epoch 4.002), train_loss = 1.95080225, grad/param norm = 2.1288e-01, time/batch = 0.6996s	
2358/29450 (epoch 4.003), train_loss = 2.07371301, grad/param norm = 2.2284e-01, time/batch = 0.7135s	
2359/29450 (epoch 4.005), train_loss = 1.56538706, grad/param norm = 1.8197e-01, time/batch = 0.7200s	
2360/29450 (epoch 4.007), train_loss = 1.75520494, grad/param norm = 1.9354e-01, time/batch = 0.7024s	
2361/29450 (epoch 4.008), train_loss = 1.77297464, grad/param norm = 1.9427e-01, time/batch = 0.6987s	
2362/29450 (epoch 4.010), train_loss = 1.83607827, grad/param norm = 2.1503e-01, time/batch = 0.6993s	
2363/29450 (epoch 4.012), train_loss = 1.94933292, grad/param norm = 1.9523e-01, time/batch = 0.7276s	
2364/29450 (epoch 4.014), train_loss = 2.06057962, grad/param norm = 2.2655e-01, time/batch = 0.7046s	
2365/29450 (epoch 4.015), train_loss = 1.77020471, grad/param norm = 1.8568e-01, time/batch = 0.7002s	
2366/29450 (epoch 4.017), train_loss = 1.92287331, grad/param norm = 2.1775e-01, time/batch = 0.6820s	
2367/29450 (epoch 4.019), train_loss = 1.67802838, grad/param norm = 2.1974e-01, time/batch = 0.6828s	
2368/29450 (epoch 4.020), train_loss = 1.93520314, grad/param norm = 2.2960e-01, time/batch = 0.6874s	
2369/29450 (epoch 4.022), train_loss = 1.90276950, grad/param norm = 2.2731e-01, time/batch = 0.6994s	
2370/29450 (epoch 4.024), train_loss = 1.98657269, grad/param norm = 2.0935e-01, time/batch = 0.7117s	
2371/29450 (epoch 4.025), train_loss = 1.86551596, grad/param norm = 2.1319e-01, time/batch = 0.6890s	
2372/29450 (epoch 4.027), train_loss = 1.83186753, grad/param norm = 1.8839e-01, time/batch = 0.6868s	
2373/29450 (epoch 4.029), train_loss = 1.94205920, grad/param norm = 1.8914e-01, time/batch = 0.6973s	
2374/29450 (epoch 4.031), train_loss = 1.66885729, grad/param norm = 1.8330e-01, time/batch = 0.6836s	
2375/29450 (epoch 4.032), train_loss = 1.68697346, grad/param norm = 1.9648e-01, time/batch = 0.6900s	
2376/29450 (epoch 4.034), train_loss = 1.65814618, grad/param norm = 1.6493e-01, time/batch = 0.6899s	
2377/29450 (epoch 4.036), train_loss = 1.80642606, grad/param norm = 1.8508e-01, time/batch = 0.6911s	
2378/29450 (epoch 4.037), train_loss = 2.08187225, grad/param norm = 2.2283e-01, time/batch = 0.6936s	
2379/29450 (epoch 4.039), train_loss = 1.80157596, grad/param norm = 2.0142e-01, time/batch = 0.6978s	
2380/29450 (epoch 4.041), train_loss = 1.88594984, grad/param norm = 2.4525e-01, time/batch = 0.7116s	
2381/29450 (epoch 4.042), train_loss = 1.76067325, grad/param norm = 2.0409e-01, time/batch = 0.6797s	
2382/29450 (epoch 4.044), train_loss = 1.89179531, grad/param norm = 1.8229e-01, time/batch = 0.6817s	
2383/29450 (epoch 4.046), train_loss = 2.00700606, grad/param norm = 2.0511e-01, time/batch = 0.6825s	
2384/29450 (epoch 4.048), train_loss = 1.82160737, grad/param norm = 1.9742e-01, time/batch = 0.6831s	
2385/29450 (epoch 4.049), train_loss = 1.96644524, grad/param norm = 2.0922e-01, time/batch = 0.6857s	
2386/29450 (epoch 4.051), train_loss = 1.86284606, grad/param norm = 1.9863e-01, time/batch = 0.6869s	
2387/29450 (epoch 4.053), train_loss = 1.66582596, grad/param norm = 1.9125e-01, time/batch = 0.6848s	
2388/29450 (epoch 4.054), train_loss = 1.80955621, grad/param norm = 2.0188e-01, time/batch = 0.6960s	
2389/29450 (epoch 4.056), train_loss = 2.01161411, grad/param norm = 1.9098e-01, time/batch = 0.7167s	
2390/29450 (epoch 4.058), train_loss = 1.90645097, grad/param norm = 1.9284e-01, time/batch = 0.6919s	
2391/29450 (epoch 4.059), train_loss = 1.67663271, grad/param norm = 1.9055e-01, time/batch = 0.7021s	
2392/29450 (epoch 4.061), train_loss = 1.62738882, grad/param norm = 1.9402e-01, time/batch = 0.7032s	
2393/29450 (epoch 4.063), train_loss = 1.83481451, grad/param norm = 1.8619e-01, time/batch = 0.7217s	
2394/29450 (epoch 4.065), train_loss = 1.81416342, grad/param norm = 1.9392e-01, time/batch = 0.6899s	
2395/29450 (epoch 4.066), train_loss = 1.79167609, grad/param norm = 2.0455e-01, time/batch = 0.6873s	
2396/29450 (epoch 4.068), train_loss = 1.92727927, grad/param norm = 2.1345e-01, time/batch = 0.7006s	
2397/29450 (epoch 4.070), train_loss = 1.85743431, grad/param norm = 2.2017e-01, time/batch = 0.6938s	
2398/29450 (epoch 4.071), train_loss = 2.03109533, grad/param norm = 2.1414e-01, time/batch = 0.6899s	
2399/29450 (epoch 4.073), train_loss = 1.97561555, grad/param norm = 2.0142e-01, time/batch = 0.6962s	
2400/29450 (epoch 4.075), train_loss = 2.16434217, grad/param norm = 2.2220e-01, time/batch = 0.6944s	
2401/29450 (epoch 4.076), train_loss = 1.94535843, grad/param norm = 1.7732e-01, time/batch = 0.6873s	
2402/29450 (epoch 4.078), train_loss = 1.71920969, grad/param norm = 1.7800e-01, time/batch = 0.6858s	
2403/29450 (epoch 4.080), train_loss = 1.82702659, grad/param norm = 1.8999e-01, time/batch = 0.6869s	
2404/29450 (epoch 4.081), train_loss = 1.95379626, grad/param norm = 1.8251e-01, time/batch = 0.6856s	
2405/29450 (epoch 4.083), train_loss = 1.89411155, grad/param norm = 1.7527e-01, time/batch = 0.6860s	
2406/29450 (epoch 4.085), train_loss = 1.91084713, grad/param norm = 1.9803e-01, time/batch = 0.6855s	
2407/29450 (epoch 4.087), train_loss = 1.74610749, grad/param norm = 2.0685e-01, time/batch = 0.6900s	
2408/29450 (epoch 4.088), train_loss = 1.85505163, grad/param norm = 1.9295e-01, time/batch = 0.6878s	
2409/29450 (epoch 4.090), train_loss = 1.68850009, grad/param norm = 1.8686e-01, time/batch = 0.6902s	
2410/29450 (epoch 4.092), train_loss = 1.83872608, grad/param norm = 1.7624e-01, time/batch = 0.7137s	
2411/29450 (epoch 4.093), train_loss = 1.67676344, grad/param norm = 1.7971e-01, time/batch = 0.6896s	
2412/29450 (epoch 4.095), train_loss = 1.68363351, grad/param norm = 1.8928e-01, time/batch = 0.6822s	
2413/29450 (epoch 4.097), train_loss = 1.78137042, grad/param norm = 1.9686e-01, time/batch = 0.6855s	
2414/29450 (epoch 4.098), train_loss = 1.82431836, grad/param norm = 2.3854e-01, time/batch = 0.6869s	
2415/29450 (epoch 4.100), train_loss = 1.95182598, grad/param norm = 2.2441e-01, time/batch = 0.6867s	
2416/29450 (epoch 4.102), train_loss = 1.70805933, grad/param norm = 1.7598e-01, time/batch = 0.6846s	
2417/29450 (epoch 4.104), train_loss = 1.82063801, grad/param norm = 2.2013e-01, time/batch = 0.6880s	
2418/29450 (epoch 4.105), train_loss = 1.79981916, grad/param norm = 2.0596e-01, time/batch = 0.6902s	
2419/29450 (epoch 4.107), train_loss = 1.68345992, grad/param norm = 1.9276e-01, time/batch = 0.6886s	
2420/29450 (epoch 4.109), train_loss = 1.68280312, grad/param norm = 1.8803e-01, time/batch = 0.6885s	
2421/29450 (epoch 4.110), train_loss = 1.78310208, grad/param norm = 1.9385e-01, time/batch = 0.6884s	
2422/29450 (epoch 4.112), train_loss = 1.77339891, grad/param norm = 1.9830e-01, time/batch = 0.6870s	
2423/29450 (epoch 4.114), train_loss = 1.75058072, grad/param norm = 1.9142e-01, time/batch = 0.6841s	
2424/29450 (epoch 4.115), train_loss = 1.94224915, grad/param norm = 1.9337e-01, time/batch = 0.6851s	
2425/29450 (epoch 4.117), train_loss = 1.72622527, grad/param norm = 1.8491e-01, time/batch = 0.6855s	
2426/29450 (epoch 4.119), train_loss = 2.02329406, grad/param norm = 1.9888e-01, time/batch = 0.6886s	
2427/29450 (epoch 4.121), train_loss = 1.86648924, grad/param norm = 1.8854e-01, time/batch = 0.6887s	
2428/29450 (epoch 4.122), train_loss = 1.87612840, grad/param norm = 2.0032e-01, time/batch = 0.6853s	
2429/29450 (epoch 4.124), train_loss = 1.82642484, grad/param norm = 1.9233e-01, time/batch = 0.6922s	
2430/29450 (epoch 4.126), train_loss = 1.78836649, grad/param norm = 1.8155e-01, time/batch = 0.6884s	
2431/29450 (epoch 4.127), train_loss = 1.83367697, grad/param norm = 2.0257e-01, time/batch = 0.6884s	
2432/29450 (epoch 4.129), train_loss = 1.89471030, grad/param norm = 1.9457e-01, time/batch = 0.6873s	
2433/29450 (epoch 4.131), train_loss = 1.91589994, grad/param norm = 2.0351e-01, time/batch = 0.6883s	
2434/29450 (epoch 4.132), train_loss = 1.78166892, grad/param norm = 2.1019e-01, time/batch = 0.6907s	
2435/29450 (epoch 4.134), train_loss = 1.52389006, grad/param norm = 1.7630e-01, time/batch = 0.6931s	
2436/29450 (epoch 4.136), train_loss = 1.50327196, grad/param norm = 1.9337e-01, time/batch = 0.6830s	
2437/29450 (epoch 4.138), train_loss = 1.90168052, grad/param norm = 1.9184e-01, time/batch = 0.6891s	
2438/29450 (epoch 4.139), train_loss = 1.68268303, grad/param norm = 1.8225e-01, time/batch = 0.6970s	
2439/29450 (epoch 4.141), train_loss = 1.64826838, grad/param norm = 2.0775e-01, time/batch = 0.6977s	
2440/29450 (epoch 4.143), train_loss = 1.88070020, grad/param norm = 1.8520e-01, time/batch = 0.7055s	
2441/29450 (epoch 4.144), train_loss = 1.76146741, grad/param norm = 1.9723e-01, time/batch = 0.7002s	
2442/29450 (epoch 4.146), train_loss = 1.90902016, grad/param norm = 2.3251e-01, time/batch = 0.7082s	
2443/29450 (epoch 4.148), train_loss = 1.86207734, grad/param norm = 2.1403e-01, time/batch = 0.7285s	
2444/29450 (epoch 4.149), train_loss = 1.66813715, grad/param norm = 2.1189e-01, time/batch = 0.7281s	
2445/29450 (epoch 4.151), train_loss = 2.00662090, grad/param norm = 2.0825e-01, time/batch = 0.7331s	
2446/29450 (epoch 4.153), train_loss = 1.61896929, grad/param norm = 1.7978e-01, time/batch = 0.7254s	
2447/29450 (epoch 4.154), train_loss = 1.78893196, grad/param norm = 1.8234e-01, time/batch = 0.7119s	
2448/29450 (epoch 4.156), train_loss = 1.82682550, grad/param norm = 2.0054e-01, time/batch = 0.7128s	
2449/29450 (epoch 4.158), train_loss = 1.81274787, grad/param norm = 2.1757e-01, time/batch = 0.7104s	
2450/29450 (epoch 4.160), train_loss = 2.01108652, grad/param norm = 2.0759e-01, time/batch = 0.7126s	
2451/29450 (epoch 4.161), train_loss = 1.74579705, grad/param norm = 1.9440e-01, time/batch = 0.7103s	
2452/29450 (epoch 4.163), train_loss = 1.78574746, grad/param norm = 1.8323e-01, time/batch = 0.7061s	
2453/29450 (epoch 4.165), train_loss = 1.98956440, grad/param norm = 1.8685e-01, time/batch = 0.6921s	
2454/29450 (epoch 4.166), train_loss = 1.90018554, grad/param norm = 2.0297e-01, time/batch = 0.6994s	
2455/29450 (epoch 4.168), train_loss = 1.84562283, grad/param norm = 1.7670e-01, time/batch = 0.6943s	
2456/29450 (epoch 4.170), train_loss = 2.02011310, grad/param norm = 1.9217e-01, time/batch = 0.6965s	
2457/29450 (epoch 4.171), train_loss = 2.04513294, grad/param norm = 2.0132e-01, time/batch = 0.6989s	
2458/29450 (epoch 4.173), train_loss = 1.76888164, grad/param norm = 1.8681e-01, time/batch = 0.7044s	
2459/29450 (epoch 4.175), train_loss = 1.71327142, grad/param norm = 1.9219e-01, time/batch = 0.7169s	
2460/29450 (epoch 4.177), train_loss = 1.84868876, grad/param norm = 2.0893e-01, time/batch = 0.7094s	
2461/29450 (epoch 4.178), train_loss = 1.67601527, grad/param norm = 1.9022e-01, time/batch = 0.7036s	
2462/29450 (epoch 4.180), train_loss = 1.72051046, grad/param norm = 2.0164e-01, time/batch = 0.7020s	
2463/29450 (epoch 4.182), train_loss = 1.79229524, grad/param norm = 1.8968e-01, time/batch = 0.7018s	
2464/29450 (epoch 4.183), train_loss = 1.74519571, grad/param norm = 2.1366e-01, time/batch = 0.7050s	
2465/29450 (epoch 4.185), train_loss = 1.91797344, grad/param norm = 2.0748e-01, time/batch = 0.7036s	
2466/29450 (epoch 4.187), train_loss = 1.84634369, grad/param norm = 1.9033e-01, time/batch = 0.6974s	
2467/29450 (epoch 4.188), train_loss = 1.93677243, grad/param norm = 2.0008e-01, time/batch = 0.6980s	
2468/29450 (epoch 4.190), train_loss = 1.70092827, grad/param norm = 1.6826e-01, time/batch = 0.7036s	
2469/29450 (epoch 4.192), train_loss = 1.85167577, grad/param norm = 1.8134e-01, time/batch = 0.7030s	
2470/29450 (epoch 4.194), train_loss = 1.93150947, grad/param norm = 2.1122e-01, time/batch = 0.7051s	
2471/29450 (epoch 4.195), train_loss = 1.80815488, grad/param norm = 1.8364e-01, time/batch = 0.6986s	
2472/29450 (epoch 4.197), train_loss = 1.98910748, grad/param norm = 1.8367e-01, time/batch = 0.7008s	
2473/29450 (epoch 4.199), train_loss = 1.72821812, grad/param norm = 1.8735e-01, time/batch = 0.6959s	
2474/29450 (epoch 4.200), train_loss = 2.01867762, grad/param norm = 1.8210e-01, time/batch = 0.6954s	
2475/29450 (epoch 4.202), train_loss = 1.81391501, grad/param norm = 1.8823e-01, time/batch = 0.6975s	
2476/29450 (epoch 4.204), train_loss = 1.66644789, grad/param norm = 1.9415e-01, time/batch = 0.6977s	
2477/29450 (epoch 4.205), train_loss = 1.76662787, grad/param norm = 1.8981e-01, time/batch = 0.7015s	
2478/29450 (epoch 4.207), train_loss = 1.79011097, grad/param norm = 1.9410e-01, time/batch = 0.7030s	
2479/29450 (epoch 4.209), train_loss = 1.69228772, grad/param norm = 2.1799e-01, time/batch = 0.7030s	
2480/29450 (epoch 4.211), train_loss = 1.93031428, grad/param norm = 1.9486e-01, time/batch = 0.7007s	
2481/29450 (epoch 4.212), train_loss = 1.65669837, grad/param norm = 1.9898e-01, time/batch = 0.6997s	
2482/29450 (epoch 4.214), train_loss = 1.91708460, grad/param norm = 1.9463e-01, time/batch = 0.6993s	
2483/29450 (epoch 4.216), train_loss = 1.80677297, grad/param norm = 1.9208e-01, time/batch = 0.7065s	
2484/29450 (epoch 4.217), train_loss = 2.00168532, grad/param norm = 1.9340e-01, time/batch = 0.7277s	
2485/29450 (epoch 4.219), train_loss = 1.50702864, grad/param norm = 1.9985e-01, time/batch = 0.7053s	
2486/29450 (epoch 4.221), train_loss = 1.86168192, grad/param norm = 2.0861e-01, time/batch = 0.7085s	
2487/29450 (epoch 4.222), train_loss = 1.84700686, grad/param norm = 2.1887e-01, time/batch = 0.6973s	
2488/29450 (epoch 4.224), train_loss = 1.71570766, grad/param norm = 2.0153e-01, time/batch = 0.7017s	
2489/29450 (epoch 4.226), train_loss = 1.92342195, grad/param norm = 2.2557e-01, time/batch = 0.6958s	
2490/29450 (epoch 4.228), train_loss = 1.85081854, grad/param norm = 2.0166e-01, time/batch = 0.6972s	
2491/29450 (epoch 4.229), train_loss = 1.72318773, grad/param norm = 1.7911e-01, time/batch = 0.7005s	
2492/29450 (epoch 4.231), train_loss = 1.67434139, grad/param norm = 1.8665e-01, time/batch = 0.7017s	
2493/29450 (epoch 4.233), train_loss = 1.63468568, grad/param norm = 1.8623e-01, time/batch = 0.7092s	
2494/29450 (epoch 4.234), train_loss = 1.73309794, grad/param norm = 1.8791e-01, time/batch = 0.7315s	
2495/29450 (epoch 4.236), train_loss = 2.02456748, grad/param norm = 2.1873e-01, time/batch = 0.7026s	
2496/29450 (epoch 4.238), train_loss = 1.82499957, grad/param norm = 1.9834e-01, time/batch = 0.7021s	
2497/29450 (epoch 4.239), train_loss = 1.91030216, grad/param norm = 2.4570e-01, time/batch = 0.7000s	
2498/29450 (epoch 4.241), train_loss = 1.86383931, grad/param norm = 2.0762e-01, time/batch = 0.7085s	
2499/29450 (epoch 4.243), train_loss = 1.84294478, grad/param norm = 1.8794e-01, time/batch = 0.7017s	
2500/29450 (epoch 4.244), train_loss = 2.06287115, grad/param norm = 2.1006e-01, time/batch = 0.7014s	
2501/29450 (epoch 4.246), train_loss = 1.90488162, grad/param norm = 2.2413e-01, time/batch = 0.6984s	
2502/29450 (epoch 4.248), train_loss = 1.82383840, grad/param norm = 2.1946e-01, time/batch = 0.6981s	
2503/29450 (epoch 4.250), train_loss = 1.78686453, grad/param norm = 2.0012e-01, time/batch = 0.7002s	
2504/29450 (epoch 4.251), train_loss = 1.82559822, grad/param norm = 2.0078e-01, time/batch = 0.7004s	
2505/29450 (epoch 4.253), train_loss = 1.71510975, grad/param norm = 1.8297e-01, time/batch = 0.7014s	
2506/29450 (epoch 4.255), train_loss = 1.78269033, grad/param norm = 1.8458e-01, time/batch = 0.7317s	
2507/29450 (epoch 4.256), train_loss = 1.78696096, grad/param norm = 1.8815e-01, time/batch = 0.7047s	
2508/29450 (epoch 4.258), train_loss = 1.85638911, grad/param norm = 1.9493e-01, time/batch = 0.7087s	
2509/29450 (epoch 4.260), train_loss = 1.95020733, grad/param norm = 2.1076e-01, time/batch = 0.7145s	
2510/29450 (epoch 4.261), train_loss = 1.96844269, grad/param norm = 1.9991e-01, time/batch = 0.7119s	
2511/29450 (epoch 4.263), train_loss = 1.78149043, grad/param norm = 1.9542e-01, time/batch = 0.6942s	
2512/29450 (epoch 4.265), train_loss = 1.69980737, grad/param norm = 1.7713e-01, time/batch = 0.6916s	
2513/29450 (epoch 4.267), train_loss = 1.89737293, grad/param norm = 1.7854e-01, time/batch = 0.7044s	
2514/29450 (epoch 4.268), train_loss = 1.63822560, grad/param norm = 1.6362e-01, time/batch = 0.7008s	
2515/29450 (epoch 4.270), train_loss = 1.76579599, grad/param norm = 1.8824e-01, time/batch = 0.6938s	
2516/29450 (epoch 4.272), train_loss = 1.70381782, grad/param norm = 1.8096e-01, time/batch = 0.6853s	
2517/29450 (epoch 4.273), train_loss = 1.80759529, grad/param norm = 2.0155e-01, time/batch = 0.6841s	
2518/29450 (epoch 4.275), train_loss = 1.76669511, grad/param norm = 1.7019e-01, time/batch = 0.6876s	
2519/29450 (epoch 4.277), train_loss = 1.65523650, grad/param norm = 2.1449e-01, time/batch = 0.6872s	
2520/29450 (epoch 4.278), train_loss = 1.79439936, grad/param norm = 1.8117e-01, time/batch = 0.6924s	
2521/29450 (epoch 4.280), train_loss = 1.76910645, grad/param norm = 1.8151e-01, time/batch = 0.6880s	
2522/29450 (epoch 4.282), train_loss = 1.91402177, grad/param norm = 2.0795e-01, time/batch = 0.6875s	
2523/29450 (epoch 4.284), train_loss = 1.94355540, grad/param norm = 2.0307e-01, time/batch = 0.6817s	
2524/29450 (epoch 4.285), train_loss = 1.79893266, grad/param norm = 1.8452e-01, time/batch = 0.6811s	
2525/29450 (epoch 4.287), train_loss = 1.89366977, grad/param norm = 2.0622e-01, time/batch = 0.6816s	
2526/29450 (epoch 4.289), train_loss = 2.00876488, grad/param norm = 2.1446e-01, time/batch = 0.6818s	
2527/29450 (epoch 4.290), train_loss = 1.84545862, grad/param norm = 1.8866e-01, time/batch = 0.6851s	
2528/29450 (epoch 4.292), train_loss = 1.79994427, grad/param norm = 2.0695e-01, time/batch = 0.6951s	
2529/29450 (epoch 4.294), train_loss = 2.02174794, grad/param norm = 2.1286e-01, time/batch = 0.7125s	
2530/29450 (epoch 4.295), train_loss = 1.64568989, grad/param norm = 1.9562e-01, time/batch = 1.2261s	
2531/29450 (epoch 4.297), train_loss = 1.98605837, grad/param norm = 2.0351e-01, time/batch = 1.0472s	
2532/29450 (epoch 4.299), train_loss = 1.76461894, grad/param norm = 2.0835e-01, time/batch = 0.7181s	
2533/29450 (epoch 4.301), train_loss = 1.90115176, grad/param norm = 1.9478e-01, time/batch = 0.7134s	
2534/29450 (epoch 4.302), train_loss = 1.85274321, grad/param norm = 1.8591e-01, time/batch = 0.6874s	
2535/29450 (epoch 4.304), train_loss = 1.71779521, grad/param norm = 1.8614e-01, time/batch = 0.6967s	
2536/29450 (epoch 4.306), train_loss = 1.90895857, grad/param norm = 1.9158e-01, time/batch = 0.6950s	
