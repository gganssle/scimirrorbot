tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 506, val: 27, test: 0	
vocab size: 127	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 280063	
cloning rnn	
cloning criterion	
1/25300 (epoch 0.002), train_loss = 4.82826686, grad/param norm = 5.9137e-01, time/batch = 0.7126s	
2/25300 (epoch 0.004), train_loss = 4.31831299, grad/param norm = 1.9037e+00, time/batch = 0.6648s	
3/25300 (epoch 0.006), train_loss = 3.60207518, grad/param norm = 1.2375e+00, time/batch = 0.6578s	
4/25300 (epoch 0.008), train_loss = 3.55964882, grad/param norm = 6.4856e-01, time/batch = 0.6686s	
5/25300 (epoch 0.010), train_loss = 3.57217483, grad/param norm = 8.0407e-01, time/batch = 0.6581s	
6/25300 (epoch 0.012), train_loss = 3.46757628, grad/param norm = 8.8739e-01, time/batch = 0.6552s	
7/25300 (epoch 0.014), train_loss = 3.42985005, grad/param norm = 7.3049e-01, time/batch = 0.6542s	
8/25300 (epoch 0.016), train_loss = 3.48186216, grad/param norm = 6.7245e-01, time/batch = 0.6580s	
9/25300 (epoch 0.018), train_loss = 3.49221261, grad/param norm = 7.1300e-01, time/batch = 0.6578s	
10/25300 (epoch 0.020), train_loss = 3.48135847, grad/param norm = 6.4811e-01, time/batch = 0.6594s	
11/25300 (epoch 0.022), train_loss = 3.39507823, grad/param norm = 8.2404e-01, time/batch = 0.6604s	
12/25300 (epoch 0.024), train_loss = 3.47541833, grad/param norm = 8.7767e-01, time/batch = 0.6545s	
13/25300 (epoch 0.026), train_loss = 3.38777237, grad/param norm = 7.9705e-01, time/batch = 0.6562s	
14/25300 (epoch 0.028), train_loss = 3.43486971, grad/param norm = 6.0900e-01, time/batch = 0.6506s	
15/25300 (epoch 0.030), train_loss = 3.44195529, grad/param norm = 6.5132e-01, time/batch = 0.6566s	
16/25300 (epoch 0.032), train_loss = 3.36937943, grad/param norm = 4.8068e-01, time/batch = 0.6574s	
17/25300 (epoch 0.034), train_loss = 3.48139482, grad/param norm = 6.8774e-01, time/batch = 0.6574s	
18/25300 (epoch 0.036), train_loss = 3.38992812, grad/param norm = 4.7236e-01, time/batch = 0.6557s	
19/25300 (epoch 0.038), train_loss = 3.46083845, grad/param norm = 6.1901e-01, time/batch = 0.6544s	
20/25300 (epoch 0.040), train_loss = 3.40641854, grad/param norm = 5.2923e-01, time/batch = 0.6569s	
21/25300 (epoch 0.042), train_loss = 3.42063092, grad/param norm = 7.3943e-01, time/batch = 0.6594s	
22/25300 (epoch 0.043), train_loss = 3.34296728, grad/param norm = 6.2752e-01, time/batch = 0.6553s	
23/25300 (epoch 0.045), train_loss = 3.43348334, grad/param norm = 7.0909e-01, time/batch = 0.6509s	
24/25300 (epoch 0.047), train_loss = 3.41921220, grad/param norm = 6.8276e-01, time/batch = 0.6588s	
25/25300 (epoch 0.049), train_loss = 3.56940135, grad/param norm = 8.1632e-01, time/batch = 0.6733s	
26/25300 (epoch 0.051), train_loss = 3.40163436, grad/param norm = 7.6526e-01, time/batch = 0.6690s	
27/25300 (epoch 0.053), train_loss = 3.51045286, grad/param norm = 7.8747e-01, time/batch = 0.6681s	
28/25300 (epoch 0.055), train_loss = 3.42194354, grad/param norm = 5.5184e-01, time/batch = 0.6700s	
29/25300 (epoch 0.057), train_loss = 3.30870358, grad/param norm = 5.2353e-01, time/batch = 0.6669s	
30/25300 (epoch 0.059), train_loss = 3.37312074, grad/param norm = 6.3864e-01, time/batch = 0.6700s	
31/25300 (epoch 0.061), train_loss = 3.43795419, grad/param norm = 7.2139e-01, time/batch = 0.6794s	
32/25300 (epoch 0.063), train_loss = 3.47360534, grad/param norm = 6.0093e-01, time/batch = 0.6806s	
33/25300 (epoch 0.065), train_loss = 3.34693040, grad/param norm = 7.0253e-01, time/batch = 0.6759s	
34/25300 (epoch 0.067), train_loss = 3.34144509, grad/param norm = 6.1016e-01, time/batch = 0.6803s	
35/25300 (epoch 0.069), train_loss = 3.42640366, grad/param norm = 7.4665e-01, time/batch = 0.6696s	
36/25300 (epoch 0.071), train_loss = 3.38276932, grad/param norm = 8.0782e-01, time/batch = 0.6647s	
37/25300 (epoch 0.073), train_loss = 3.40041521, grad/param norm = 5.5135e-01, time/batch = 0.6548s	
38/25300 (epoch 0.075), train_loss = 3.59000908, grad/param norm = 7.4199e-01, time/batch = 0.6569s	
39/25300 (epoch 0.077), train_loss = 3.43672468, grad/param norm = 5.8851e-01, time/batch = 0.6582s	
40/25300 (epoch 0.079), train_loss = 3.44694162, grad/param norm = 7.0749e-01, time/batch = 0.6569s	
41/25300 (epoch 0.081), train_loss = 3.37013686, grad/param norm = 6.3866e-01, time/batch = 0.6571s	
42/25300 (epoch 0.083), train_loss = 3.38347555, grad/param norm = 5.3567e-01, time/batch = 0.6552s	
43/25300 (epoch 0.085), train_loss = 3.46312464, grad/param norm = 7.7176e-01, time/batch = 0.6567s	
44/25300 (epoch 0.087), train_loss = 3.36257105, grad/param norm = 8.3594e-01, time/batch = 0.6585s	
45/25300 (epoch 0.089), train_loss = 3.37743067, grad/param norm = 7.4333e-01, time/batch = 0.6569s	
46/25300 (epoch 0.091), train_loss = 3.49116128, grad/param norm = 6.7334e-01, time/batch = 0.6574s	
47/25300 (epoch 0.093), train_loss = 3.48055630, grad/param norm = 6.7405e-01, time/batch = 0.6539s	
48/25300 (epoch 0.095), train_loss = 3.42965968, grad/param norm = 5.6134e-01, time/batch = 0.6562s	
49/25300 (epoch 0.097), train_loss = 3.39093410, grad/param norm = 4.1132e-01, time/batch = 0.6601s	
50/25300 (epoch 0.099), train_loss = 3.42171660, grad/param norm = 5.0889e-01, time/batch = 0.6571s	
51/25300 (epoch 0.101), train_loss = 3.40309871, grad/param norm = 4.8050e-01, time/batch = 0.6608s	
52/25300 (epoch 0.103), train_loss = 3.29272692, grad/param norm = 7.0106e-01, time/batch = 0.6571s	
53/25300 (epoch 0.105), train_loss = 3.44110790, grad/param norm = 6.3991e-01, time/batch = 0.6592s	
54/25300 (epoch 0.107), train_loss = 3.52435467, grad/param norm = 6.5794e-01, time/batch = 0.6598s	
55/25300 (epoch 0.109), train_loss = 3.53527332, grad/param norm = 8.4908e-01, time/batch = 0.6557s	
56/25300 (epoch 0.111), train_loss = 3.40736939, grad/param norm = 8.0422e-01, time/batch = 0.6564s	
57/25300 (epoch 0.113), train_loss = 3.44913780, grad/param norm = 9.3534e-01, time/batch = 0.6574s	
58/25300 (epoch 0.115), train_loss = 3.43732256, grad/param norm = 6.3584e-01, time/batch = 0.6560s	
59/25300 (epoch 0.117), train_loss = 3.41507762, grad/param norm = 6.3840e-01, time/batch = 0.6567s	
60/25300 (epoch 0.119), train_loss = 3.46185750, grad/param norm = 6.8540e-01, time/batch = 0.6556s	
61/25300 (epoch 0.121), train_loss = 3.50703448, grad/param norm = 6.0840e-01, time/batch = 0.6572s	
62/25300 (epoch 0.123), train_loss = 3.45322082, grad/param norm = 5.9181e-01, time/batch = 0.6564s	
63/25300 (epoch 0.125), train_loss = 3.50002657, grad/param norm = 5.0733e-01, time/batch = 0.6574s	
64/25300 (epoch 0.126), train_loss = 3.38245138, grad/param norm = 6.1103e-01, time/batch = 0.6544s	
65/25300 (epoch 0.128), train_loss = 3.38993210, grad/param norm = 4.8776e-01, time/batch = 0.6554s	
66/25300 (epoch 0.130), train_loss = 3.41081227, grad/param norm = 6.7398e-01, time/batch = 0.6551s	
67/25300 (epoch 0.132), train_loss = 3.32986159, grad/param norm = 5.4257e-01, time/batch = 0.6556s	
68/25300 (epoch 0.134), train_loss = 3.40512586, grad/param norm = 6.6316e-01, time/batch = 0.6570s	
69/25300 (epoch 0.136), train_loss = 3.49136917, grad/param norm = 5.8696e-01, time/batch = 0.6571s	
70/25300 (epoch 0.138), train_loss = 3.38628620, grad/param norm = 7.3295e-01, time/batch = 0.6559s	
71/25300 (epoch 0.140), train_loss = 3.40090656, grad/param norm = 6.9957e-01, time/batch = 0.6639s	
72/25300 (epoch 0.142), train_loss = 3.32539708, grad/param norm = 4.3174e-01, time/batch = 0.6624s	
73/25300 (epoch 0.144), train_loss = 3.41361454, grad/param norm = 4.8726e-01, time/batch = 0.6657s	
74/25300 (epoch 0.146), train_loss = 3.40345877, grad/param norm = 4.3596e-01, time/batch = 0.6668s	
75/25300 (epoch 0.148), train_loss = 3.56379400, grad/param norm = 4.8145e-01, time/batch = 0.6627s	
76/25300 (epoch 0.150), train_loss = 3.42136213, grad/param norm = 6.5000e-01, time/batch = 0.6523s	
77/25300 (epoch 0.152), train_loss = 3.57619373, grad/param norm = 6.1862e-01, time/batch = 0.6552s	
78/25300 (epoch 0.154), train_loss = 3.41540248, grad/param norm = 4.1044e-01, time/batch = 0.6531s	
79/25300 (epoch 0.156), train_loss = 3.41889416, grad/param norm = 4.3857e-01, time/batch = 0.6545s	
80/25300 (epoch 0.158), train_loss = 3.42948964, grad/param norm = 4.2905e-01, time/batch = 0.6559s	
81/25300 (epoch 0.160), train_loss = 3.26566461, grad/param norm = 7.1526e-01, time/batch = 0.6596s	
82/25300 (epoch 0.162), train_loss = 3.40111501, grad/param norm = 8.4021e-01, time/batch = 0.7146s	
83/25300 (epoch 0.164), train_loss = 3.42768600, grad/param norm = 5.0771e-01, time/batch = 0.6575s	
84/25300 (epoch 0.166), train_loss = 3.47120883, grad/param norm = 6.8178e-01, time/batch = 0.6564s	
85/25300 (epoch 0.168), train_loss = 3.32620304, grad/param norm = 5.5846e-01, time/batch = 0.6561s	
86/25300 (epoch 0.170), train_loss = 3.41756282, grad/param norm = 6.6828e-01, time/batch = 0.6570s	
87/25300 (epoch 0.172), train_loss = 3.37894808, grad/param norm = 7.5307e-01, time/batch = 0.6628s	
88/25300 (epoch 0.174), train_loss = 3.58655395, grad/param norm = 7.9001e-01, time/batch = 0.6591s	
89/25300 (epoch 0.176), train_loss = 3.49135119, grad/param norm = 5.8000e-01, time/batch = 0.6592s	
90/25300 (epoch 0.178), train_loss = 3.39417820, grad/param norm = 9.0778e-01, time/batch = 0.6676s	
91/25300 (epoch 0.180), train_loss = 3.54144943, grad/param norm = 1.0602e+00, time/batch = 0.6643s	
92/25300 (epoch 0.182), train_loss = 3.44139694, grad/param norm = 5.5208e-01, time/batch = 0.6641s	
93/25300 (epoch 0.184), train_loss = 3.38307008, grad/param norm = 5.3181e-01, time/batch = 0.6557s	
94/25300 (epoch 0.186), train_loss = 3.36940470, grad/param norm = 5.2801e-01, time/batch = 0.6582s	
95/25300 (epoch 0.188), train_loss = 3.33680427, grad/param norm = 4.9071e-01, time/batch = 0.6622s	
96/25300 (epoch 0.190), train_loss = 3.41704755, grad/param norm = 4.4043e-01, time/batch = 0.6572s	
97/25300 (epoch 0.192), train_loss = 3.36705248, grad/param norm = 4.3674e-01, time/batch = 0.6589s	
98/25300 (epoch 0.194), train_loss = 3.35501175, grad/param norm = 6.4899e-01, time/batch = 0.6588s	
99/25300 (epoch 0.196), train_loss = 3.31171102, grad/param norm = 4.7457e-01, time/batch = 0.6565s	
100/25300 (epoch 0.198), train_loss = 3.37332169, grad/param norm = 4.4459e-01, time/batch = 0.6571s	
101/25300 (epoch 0.200), train_loss = 3.41580207, grad/param norm = 4.7466e-01, time/batch = 0.6617s	
102/25300 (epoch 0.202), train_loss = 3.45035793, grad/param norm = 5.7484e-01, time/batch = 0.6588s	
103/25300 (epoch 0.204), train_loss = 3.29428399, grad/param norm = 6.2062e-01, time/batch = 0.6655s	
104/25300 (epoch 0.206), train_loss = 3.33928765, grad/param norm = 5.2861e-01, time/batch = 0.6665s	
105/25300 (epoch 0.208), train_loss = 3.41455379, grad/param norm = 6.3352e-01, time/batch = 0.6640s	
106/25300 (epoch 0.209), train_loss = 3.33777246, grad/param norm = 8.1919e-01, time/batch = 0.6591s	
107/25300 (epoch 0.211), train_loss = 3.40234979, grad/param norm = 8.1211e-01, time/batch = 0.6605s	
108/25300 (epoch 0.213), train_loss = 3.41384138, grad/param norm = 5.7301e-01, time/batch = 0.6618s	
109/25300 (epoch 0.215), train_loss = 3.37496497, grad/param norm = 4.3217e-01, time/batch = 0.6576s	
110/25300 (epoch 0.217), train_loss = 3.42848283, grad/param norm = 5.1719e-01, time/batch = 0.6613s	
111/25300 (epoch 0.219), train_loss = 3.24714046, grad/param norm = 4.6964e-01, time/batch = 0.6608s	
112/25300 (epoch 0.221), train_loss = 3.29450910, grad/param norm = 4.5458e-01, time/batch = 0.6585s	
113/25300 (epoch 0.223), train_loss = 3.36998439, grad/param norm = 5.1790e-01, time/batch = 0.6594s	
114/25300 (epoch 0.225), train_loss = 3.40379678, grad/param norm = 5.1386e-01, time/batch = 0.6590s	
115/25300 (epoch 0.227), train_loss = 3.34983905, grad/param norm = 5.1991e-01, time/batch = 0.6583s	
116/25300 (epoch 0.229), train_loss = 3.33959218, grad/param norm = 9.6530e-01, time/batch = 0.6657s	
117/25300 (epoch 0.231), train_loss = 3.57213199, grad/param norm = 2.2615e+00, time/batch = 0.6654s	
118/25300 (epoch 0.233), train_loss = 3.48074675, grad/param norm = 8.1396e-01, time/batch = 0.6667s	
119/25300 (epoch 0.235), train_loss = 3.39201629, grad/param norm = 5.6603e-01, time/batch = 0.6655s	
120/25300 (epoch 0.237), train_loss = 3.42699545, grad/param norm = 4.8330e-01, time/batch = 0.6643s	
121/25300 (epoch 0.239), train_loss = 3.31574644, grad/param norm = 5.4418e-01, time/batch = 0.6649s	
122/25300 (epoch 0.241), train_loss = 3.31380505, grad/param norm = 3.9110e-01, time/batch = 0.6696s	
123/25300 (epoch 0.243), train_loss = 3.39533413, grad/param norm = 4.9714e-01, time/batch = 0.6627s	
124/25300 (epoch 0.245), train_loss = 3.29547732, grad/param norm = 5.3507e-01, time/batch = 0.6656s	
125/25300 (epoch 0.247), train_loss = 3.32740710, grad/param norm = 8.0352e-01, time/batch = 0.6640s	
126/25300 (epoch 0.249), train_loss = 3.42082206, grad/param norm = 7.3556e-01, time/batch = 0.6603s	
127/25300 (epoch 0.251), train_loss = 3.31356818, grad/param norm = 4.3481e-01, time/batch = 0.6628s	
128/25300 (epoch 0.253), train_loss = 3.29863794, grad/param norm = 3.5814e-01, time/batch = 0.6617s	
129/25300 (epoch 0.255), train_loss = 3.29427221, grad/param norm = 3.6920e-01, time/batch = 0.6576s	
130/25300 (epoch 0.257), train_loss = 3.35164408, grad/param norm = 5.5345e-01, time/batch = 0.6576s	
131/25300 (epoch 0.259), train_loss = 3.53882369, grad/param norm = 5.1831e-01, time/batch = 0.6583s	
132/25300 (epoch 0.261), train_loss = 3.23715584, grad/param norm = 3.8818e-01, time/batch = 0.6586s	
133/25300 (epoch 0.263), train_loss = 3.24456587, grad/param norm = 4.0940e-01, time/batch = 0.6594s	
134/25300 (epoch 0.265), train_loss = 3.25669960, grad/param norm = 8.4585e-01, time/batch = 0.6595s	
135/25300 (epoch 0.267), train_loss = 3.37345100, grad/param norm = 1.6225e+00, time/batch = 0.6575s	
136/25300 (epoch 0.269), train_loss = 3.36311203, grad/param norm = 9.1347e-01, time/batch = 0.6544s	
137/25300 (epoch 0.271), train_loss = 3.26655041, grad/param norm = 4.4388e-01, time/batch = 0.6586s	
138/25300 (epoch 0.273), train_loss = 3.29988479, grad/param norm = 5.0345e-01, time/batch = 0.6572s	
139/25300 (epoch 0.275), train_loss = 3.19657118, grad/param norm = 4.4865e-01, time/batch = 0.6597s	
140/25300 (epoch 0.277), train_loss = 3.26209349, grad/param norm = 3.9702e-01, time/batch = 0.6596s	
141/25300 (epoch 0.279), train_loss = 3.18030841, grad/param norm = 3.5736e-01, time/batch = 0.6601s	
142/25300 (epoch 0.281), train_loss = 3.26760969, grad/param norm = 4.2178e-01, time/batch = 0.6610s	
143/25300 (epoch 0.283), train_loss = 3.21566730, grad/param norm = 3.9373e-01, time/batch = 0.6598s	
144/25300 (epoch 0.285), train_loss = 3.23106255, grad/param norm = 3.6358e-01, time/batch = 0.6603s	
145/25300 (epoch 0.287), train_loss = 3.23916430, grad/param norm = 3.6440e-01, time/batch = 0.6573s	
146/25300 (epoch 0.289), train_loss = 3.15521399, grad/param norm = 5.3532e-01, time/batch = 0.6588s	
147/25300 (epoch 0.291), train_loss = 3.13255426, grad/param norm = 1.0793e+00, time/batch = 0.6552s	
148/25300 (epoch 0.292), train_loss = 3.30401247, grad/param norm = 1.7831e+00, time/batch = 0.6558s	
149/25300 (epoch 0.294), train_loss = 3.41504731, grad/param norm = 1.3131e+00, time/batch = 0.6587s	
150/25300 (epoch 0.296), train_loss = 3.24543385, grad/param norm = 4.6269e-01, time/batch = 0.6560s	
151/25300 (epoch 0.298), train_loss = 3.15445789, grad/param norm = 2.8769e-01, time/batch = 0.6582s	
152/25300 (epoch 0.300), train_loss = 3.30257895, grad/param norm = 4.5142e-01, time/batch = 0.6536s	
153/25300 (epoch 0.302), train_loss = 3.09487947, grad/param norm = 4.1363e-01, time/batch = 0.6615s	
154/25300 (epoch 0.304), train_loss = 3.19301721, grad/param norm = 5.1039e-01, time/batch = 0.6548s	
155/25300 (epoch 0.306), train_loss = 3.14611357, grad/param norm = 3.2281e-01, time/batch = 0.6577s	
156/25300 (epoch 0.308), train_loss = 3.21019062, grad/param norm = 4.3371e-01, time/batch = 0.6592s	
157/25300 (epoch 0.310), train_loss = 3.09864846, grad/param norm = 6.6096e-01, time/batch = 0.6607s	
158/25300 (epoch 0.312), train_loss = 3.22086267, grad/param norm = 8.6917e-01, time/batch = 0.6600s	
159/25300 (epoch 0.314), train_loss = 3.15936103, grad/param norm = 8.4947e-01, time/batch = 0.6579s	
160/25300 (epoch 0.316), train_loss = 3.15863025, grad/param norm = 7.9782e-01, time/batch = 0.6598s	
161/25300 (epoch 0.318), train_loss = 3.00851809, grad/param norm = 8.9084e-01, time/batch = 0.6564s	
162/25300 (epoch 0.320), train_loss = 3.18696867, grad/param norm = 8.2750e-01, time/batch = 0.6596s	
163/25300 (epoch 0.322), train_loss = 3.24000713, grad/param norm = 7.5395e-01, time/batch = 0.6663s	
164/25300 (epoch 0.324), train_loss = 3.04567328, grad/param norm = 7.1975e-01, time/batch = 0.6671s	
165/25300 (epoch 0.326), train_loss = 3.00101466, grad/param norm = 1.0283e+00, time/batch = 0.6722s	
166/25300 (epoch 0.328), train_loss = 3.23758853, grad/param norm = 1.1799e+00, time/batch = 0.6676s	
167/25300 (epoch 0.330), train_loss = 3.14852498, grad/param norm = 6.4054e-01, time/batch = 0.6609s	
168/25300 (epoch 0.332), train_loss = 3.31353191, grad/param norm = 4.5022e-01, time/batch = 0.6598s	
169/25300 (epoch 0.334), train_loss = 3.13043859, grad/param norm = 5.0530e-01, time/batch = 0.6621s	
170/25300 (epoch 0.336), train_loss = 3.05552103, grad/param norm = 6.3946e-01, time/batch = 0.6695s	
171/25300 (epoch 0.338), train_loss = 3.02466339, grad/param norm = 6.4295e-01, time/batch = 0.6647s	
172/25300 (epoch 0.340), train_loss = 3.00983839, grad/param norm = 5.5239e-01, time/batch = 0.6638s	
173/25300 (epoch 0.342), train_loss = 3.05114435, grad/param norm = 5.8977e-01, time/batch = 0.6626s	
174/25300 (epoch 0.344), train_loss = 3.14134359, grad/param norm = 8.3709e-01, time/batch = 0.6681s	
175/25300 (epoch 0.346), train_loss = 3.17941057, grad/param norm = 1.0406e+00, time/batch = 0.6590s	
176/25300 (epoch 0.348), train_loss = 2.96926047, grad/param norm = 6.0575e-01, time/batch = 0.6667s	
177/25300 (epoch 0.350), train_loss = 3.10297058, grad/param norm = 2.8777e-01, time/batch = 0.6628s	
178/25300 (epoch 0.352), train_loss = 3.07654236, grad/param norm = 3.9213e-01, time/batch = 0.6558s	
179/25300 (epoch 0.354), train_loss = 2.96184225, grad/param norm = 6.6416e-01, time/batch = 0.6584s	
180/25300 (epoch 0.356), train_loss = 2.97738885, grad/param norm = 1.0959e+00, time/batch = 0.6586s	
181/25300 (epoch 0.358), train_loss = 3.21332452, grad/param norm = 1.4895e+00, time/batch = 0.6613s	
182/25300 (epoch 0.360), train_loss = 3.09090004, grad/param norm = 1.0992e+00, time/batch = 0.6572s	
183/25300 (epoch 0.362), train_loss = 3.14563942, grad/param norm = 5.3665e-01, time/batch = 0.6525s	
184/25300 (epoch 0.364), train_loss = 3.12647290, grad/param norm = 3.4851e-01, time/batch = 0.6546s	
185/25300 (epoch 0.366), train_loss = 3.07536073, grad/param norm = 3.6607e-01, time/batch = 0.6563s	
186/25300 (epoch 0.368), train_loss = 3.19380036, grad/param norm = 5.4373e-01, time/batch = 0.6582s	
187/25300 (epoch 0.370), train_loss = 3.16585217, grad/param norm = 6.9038e-01, time/batch = 0.6581s	
188/25300 (epoch 0.372), train_loss = 3.05059989, grad/param norm = 5.1162e-01, time/batch = 0.6555s	
189/25300 (epoch 0.374), train_loss = 2.93544202, grad/param norm = 5.2824e-01, time/batch = 0.6605s	
190/25300 (epoch 0.375), train_loss = 3.07305415, grad/param norm = 6.7757e-01, time/batch = 0.6568s	
191/25300 (epoch 0.377), train_loss = 2.96738734, grad/param norm = 6.2396e-01, time/batch = 0.6564s	
192/25300 (epoch 0.379), train_loss = 3.09658269, grad/param norm = 6.3992e-01, time/batch = 0.6560s	
193/25300 (epoch 0.381), train_loss = 3.02662963, grad/param norm = 6.4581e-01, time/batch = 0.6554s	
194/25300 (epoch 0.383), train_loss = 3.01414731, grad/param norm = 4.8437e-01, time/batch = 0.6589s	
195/25300 (epoch 0.385), train_loss = 2.90531508, grad/param norm = 4.3956e-01, time/batch = 0.6608s	
196/25300 (epoch 0.387), train_loss = 3.09056741, grad/param norm = 6.4165e-01, time/batch = 0.6647s	
197/25300 (epoch 0.389), train_loss = 3.03042015, grad/param norm = 7.0296e-01, time/batch = 0.6663s	
198/25300 (epoch 0.391), train_loss = 2.95701756, grad/param norm = 1.1123e+00, time/batch = 0.6652s	
199/25300 (epoch 0.393), train_loss = 3.10849860, grad/param norm = 1.2456e+00, time/batch = 0.6623s	
200/25300 (epoch 0.395), train_loss = 2.84370845, grad/param norm = 8.6125e-01, time/batch = 0.6632s	
201/25300 (epoch 0.397), train_loss = 2.95080002, grad/param norm = 7.7836e-01, time/batch = 0.6615s	
202/25300 (epoch 0.399), train_loss = 3.01887866, grad/param norm = 4.9420e-01, time/batch = 0.6660s	
203/25300 (epoch 0.401), train_loss = 2.94177339, grad/param norm = 6.1309e-01, time/batch = 0.6610s	
204/25300 (epoch 0.403), train_loss = 3.01177298, grad/param norm = 9.7030e-01, time/batch = 0.6680s	
205/25300 (epoch 0.405), train_loss = 2.97058197, grad/param norm = 1.0694e+00, time/batch = 0.6538s	
206/25300 (epoch 0.407), train_loss = 2.85816056, grad/param norm = 8.1251e-01, time/batch = 0.6569s	
207/25300 (epoch 0.409), train_loss = 2.94644459, grad/param norm = 5.6495e-01, time/batch = 0.6550s	
208/25300 (epoch 0.411), train_loss = 2.79141980, grad/param norm = 3.6066e-01, time/batch = 0.6482s	
209/25300 (epoch 0.413), train_loss = 2.86219509, grad/param norm = 3.8405e-01, time/batch = 0.6563s	
210/25300 (epoch 0.415), train_loss = 2.84866095, grad/param norm = 4.8713e-01, time/batch = 0.6609s	
211/25300 (epoch 0.417), train_loss = 2.94629773, grad/param norm = 4.0811e-01, time/batch = 0.6615s	
212/25300 (epoch 0.419), train_loss = 2.80380245, grad/param norm = 4.1931e-01, time/batch = 0.6653s	
213/25300 (epoch 0.421), train_loss = 2.90637112, grad/param norm = 6.5039e-01, time/batch = 0.6567s	
214/25300 (epoch 0.423), train_loss = 2.94411673, grad/param norm = 1.1845e+00, time/batch = 0.6609s	
215/25300 (epoch 0.425), train_loss = 2.98320460, grad/param norm = 1.0431e+00, time/batch = 0.6544s	
216/25300 (epoch 0.427), train_loss = 3.07408918, grad/param norm = 4.2705e-01, time/batch = 0.6573s	
217/25300 (epoch 0.429), train_loss = 2.81472726, grad/param norm = 3.6854e-01, time/batch = 0.6602s	
218/25300 (epoch 0.431), train_loss = 2.99090226, grad/param norm = 5.0972e-01, time/batch = 0.6567s	
219/25300 (epoch 0.433), train_loss = 2.95952385, grad/param norm = 4.7031e-01, time/batch = 0.6625s	
220/25300 (epoch 0.435), train_loss = 2.79390949, grad/param norm = 6.8209e-01, time/batch = 0.6567s	
221/25300 (epoch 0.437), train_loss = 3.01554943, grad/param norm = 9.4974e-01, time/batch = 0.6571s	
222/25300 (epoch 0.439), train_loss = 2.90555975, grad/param norm = 7.3986e-01, time/batch = 0.6580s	
223/25300 (epoch 0.441), train_loss = 2.78656374, grad/param norm = 4.2540e-01, time/batch = 0.6579s	
224/25300 (epoch 0.443), train_loss = 2.85549980, grad/param norm = 5.8118e-01, time/batch = 0.6580s	
225/25300 (epoch 0.445), train_loss = 2.96813136, grad/param norm = 6.8814e-01, time/batch = 0.6615s	
226/25300 (epoch 0.447), train_loss = 2.77293823, grad/param norm = 4.7095e-01, time/batch = 0.6612s	
227/25300 (epoch 0.449), train_loss = 2.92344011, grad/param norm = 7.6590e-01, time/batch = 0.6573s	
228/25300 (epoch 0.451), train_loss = 3.02240604, grad/param norm = 9.3595e-01, time/batch = 0.6619s	
229/25300 (epoch 0.453), train_loss = 2.97469051, grad/param norm = 8.4487e-01, time/batch = 0.6613s	
230/25300 (epoch 0.455), train_loss = 2.93307970, grad/param norm = 5.8450e-01, time/batch = 0.6608s	
231/25300 (epoch 0.457), train_loss = 2.95314446, grad/param norm = 4.6133e-01, time/batch = 0.6606s	
232/25300 (epoch 0.458), train_loss = 2.90816976, grad/param norm = 4.6437e-01, time/batch = 0.6624s	
233/25300 (epoch 0.460), train_loss = 2.93226415, grad/param norm = 3.5670e-01, time/batch = 0.6632s	
234/25300 (epoch 0.462), train_loss = 2.72395842, grad/param norm = 4.4692e-01, time/batch = 0.6610s	
235/25300 (epoch 0.464), train_loss = 2.90164458, grad/param norm = 4.9508e-01, time/batch = 0.6573s	
236/25300 (epoch 0.466), train_loss = 2.72740392, grad/param norm = 7.0637e-01, time/batch = 0.6576s	
237/25300 (epoch 0.468), train_loss = 3.06873322, grad/param norm = 7.7726e-01, time/batch = 0.6606s	
238/25300 (epoch 0.470), train_loss = 2.89365643, grad/param norm = 7.4811e-01, time/batch = 0.6569s	
239/25300 (epoch 0.472), train_loss = 2.85374627, grad/param norm = 1.0724e+00, time/batch = 0.6614s	
240/25300 (epoch 0.474), train_loss = 2.95928821, grad/param norm = 1.1015e+00, time/batch = 0.6614s	
241/25300 (epoch 0.476), train_loss = 2.97688165, grad/param norm = 9.4937e-01, time/batch = 0.6576s	
242/25300 (epoch 0.478), train_loss = 2.97248692, grad/param norm = 9.6012e-01, time/batch = 0.6584s	
243/25300 (epoch 0.480), train_loss = 2.83947586, grad/param norm = 7.6236e-01, time/batch = 0.6572s	
244/25300 (epoch 0.482), train_loss = 2.86983551, grad/param norm = 4.7822e-01, time/batch = 0.6587s	
245/25300 (epoch 0.484), train_loss = 2.88245324, grad/param norm = 2.9564e-01, time/batch = 0.6635s	
246/25300 (epoch 0.486), train_loss = 2.86519238, grad/param norm = 3.9214e-01, time/batch = 0.6603s	
247/25300 (epoch 0.488), train_loss = 2.77426389, grad/param norm = 3.6063e-01, time/batch = 0.6674s	
248/25300 (epoch 0.490), train_loss = 2.87412595, grad/param norm = 4.5906e-01, time/batch = 0.6577s	
249/25300 (epoch 0.492), train_loss = 2.80541848, grad/param norm = 4.4334e-01, time/batch = 0.6564s	
250/25300 (epoch 0.494), train_loss = 2.74612093, grad/param norm = 3.0233e-01, time/batch = 0.6548s	
251/25300 (epoch 0.496), train_loss = 2.70692915, grad/param norm = 3.2995e-01, time/batch = 0.6556s	
252/25300 (epoch 0.498), train_loss = 2.71331209, grad/param norm = 4.2426e-01, time/batch = 0.6554s	
253/25300 (epoch 0.500), train_loss = 2.84013935, grad/param norm = 3.8532e-01, time/batch = 0.6634s	
254/25300 (epoch 0.502), train_loss = 2.77225802, grad/param norm = 5.1904e-01, time/batch = 0.6673s	
255/25300 (epoch 0.504), train_loss = 2.80973549, grad/param norm = 8.0783e-01, time/batch = 0.6686s	
256/25300 (epoch 0.506), train_loss = 2.78514247, grad/param norm = 7.8972e-01, time/batch = 0.6635s	
257/25300 (epoch 0.508), train_loss = 2.82565595, grad/param norm = 6.8148e-01, time/batch = 0.6563s	
258/25300 (epoch 0.510), train_loss = 2.80295190, grad/param norm = 6.6644e-01, time/batch = 0.6596s	
259/25300 (epoch 0.512), train_loss = 2.73210755, grad/param norm = 6.0217e-01, time/batch = 0.6599s	
260/25300 (epoch 0.514), train_loss = 2.63628968, grad/param norm = 5.6056e-01, time/batch = 0.6616s	
261/25300 (epoch 0.516), train_loss = 2.84065357, grad/param norm = 8.6581e-01, time/batch = 0.6564s	
262/25300 (epoch 0.518), train_loss = 2.94913999, grad/param norm = 7.8656e-01, time/batch = 0.6594s	
263/25300 (epoch 0.520), train_loss = 2.66075105, grad/param norm = 4.3869e-01, time/batch = 0.6567s	
264/25300 (epoch 0.522), train_loss = 2.73473507, grad/param norm = 4.0102e-01, time/batch = 0.6591s	
265/25300 (epoch 0.524), train_loss = 2.60294677, grad/param norm = 5.5989e-01, time/batch = 0.6611s	
266/25300 (epoch 0.526), train_loss = 2.86879309, grad/param norm = 5.4013e-01, time/batch = 0.6591s	
267/25300 (epoch 0.528), train_loss = 2.90328853, grad/param norm = 3.5735e-01, time/batch = 0.6613s	
268/25300 (epoch 0.530), train_loss = 2.60622109, grad/param norm = 3.4579e-01, time/batch = 0.6587s	
269/25300 (epoch 0.532), train_loss = 2.73112057, grad/param norm = 4.0191e-01, time/batch = 0.6615s	
270/25300 (epoch 0.534), train_loss = 2.84796729, grad/param norm = 7.6681e-01, time/batch = 0.6670s	
271/25300 (epoch 0.536), train_loss = 2.74577007, grad/param norm = 1.0784e+00, time/batch = 0.6659s	
272/25300 (epoch 0.538), train_loss = 2.74553707, grad/param norm = 6.3754e-01, time/batch = 0.6598s	
273/25300 (epoch 0.540), train_loss = 2.78680631, grad/param norm = 3.9736e-01, time/batch = 0.6674s	
274/25300 (epoch 0.542), train_loss = 2.81658738, grad/param norm = 3.7118e-01, time/batch = 0.6610s	
275/25300 (epoch 0.543), train_loss = 2.70568148, grad/param norm = 2.7078e-01, time/batch = 0.6627s	
276/25300 (epoch 0.545), train_loss = 3.04781696, grad/param norm = 4.0278e-01, time/batch = 0.6566s	
277/25300 (epoch 0.547), train_loss = 2.58941013, grad/param norm = 5.1946e-01, time/batch = 0.6558s	
278/25300 (epoch 0.549), train_loss = 2.83370321, grad/param norm = 5.7217e-01, time/batch = 0.6564s	
279/25300 (epoch 0.551), train_loss = 2.82322320, grad/param norm = 9.1635e-01, time/batch = 0.6592s	
280/25300 (epoch 0.553), train_loss = 2.83469520, grad/param norm = 1.0240e+00, time/batch = 0.6603s	
281/25300 (epoch 0.555), train_loss = 2.78423348, grad/param norm = 7.8696e-01, time/batch = 0.6609s	
282/25300 (epoch 0.557), train_loss = 2.65064687, grad/param norm = 3.6393e-01, time/batch = 0.6605s	
283/25300 (epoch 0.559), train_loss = 2.80739448, grad/param norm = 4.3627e-01, time/batch = 0.6611s	
284/25300 (epoch 0.561), train_loss = 2.73134398, grad/param norm = 4.5174e-01, time/batch = 0.6571s	
285/25300 (epoch 0.563), train_loss = 2.70670593, grad/param norm = 5.5855e-01, time/batch = 0.6605s	
286/25300 (epoch 0.565), train_loss = 2.78715297, grad/param norm = 5.8387e-01, time/batch = 0.6586s	
287/25300 (epoch 0.567), train_loss = 2.59905456, grad/param norm = 6.5009e-01, time/batch = 0.6564s	
288/25300 (epoch 0.569), train_loss = 2.61816108, grad/param norm = 5.5286e-01, time/batch = 0.6585s	
289/25300 (epoch 0.571), train_loss = 2.75254156, grad/param norm = 4.8429e-01, time/batch = 0.6603s	
290/25300 (epoch 0.573), train_loss = 2.63958671, grad/param norm = 3.8390e-01, time/batch = 0.6576s	
291/25300 (epoch 0.575), train_loss = 2.71186183, grad/param norm = 3.9778e-01, time/batch = 0.6605s	
292/25300 (epoch 0.577), train_loss = 2.77673394, grad/param norm = 8.0041e-01, time/batch = 0.6605s	
293/25300 (epoch 0.579), train_loss = 2.91885196, grad/param norm = 6.6839e-01, time/batch = 0.6578s	
294/25300 (epoch 0.581), train_loss = 2.63602203, grad/param norm = 4.7941e-01, time/batch = 0.6570s	
295/25300 (epoch 0.583), train_loss = 2.75407688, grad/param norm = 5.7224e-01, time/batch = 0.6587s	
296/25300 (epoch 0.585), train_loss = 2.76129105, grad/param norm = 3.8694e-01, time/batch = 0.6623s	
297/25300 (epoch 0.587), train_loss = 2.74734268, grad/param norm = 5.0410e-01, time/batch = 0.6643s	
298/25300 (epoch 0.589), train_loss = 2.64762259, grad/param norm = 6.4840e-01, time/batch = 0.6604s	
299/25300 (epoch 0.591), train_loss = 2.66826465, grad/param norm = 7.2850e-01, time/batch = 0.6596s	
300/25300 (epoch 0.593), train_loss = 2.63343497, grad/param norm = 5.7845e-01, time/batch = 0.6599s	
301/25300 (epoch 0.595), train_loss = 2.74907145, grad/param norm = 7.3854e-01, time/batch = 0.6617s	
302/25300 (epoch 0.597), train_loss = 2.68644955, grad/param norm = 8.5658e-01, time/batch = 0.6597s	
303/25300 (epoch 0.599), train_loss = 2.60978236, grad/param norm = 6.2745e-01, time/batch = 0.6621s	
304/25300 (epoch 0.601), train_loss = 2.81878231, grad/param norm = 3.6634e-01, time/batch = 0.6605s	
305/25300 (epoch 0.603), train_loss = 2.74421474, grad/param norm = 2.8673e-01, time/batch = 0.6644s	
306/25300 (epoch 0.605), train_loss = 2.66363736, grad/param norm = 3.3638e-01, time/batch = 0.6521s	
307/25300 (epoch 0.607), train_loss = 2.72028324, grad/param norm = 3.7994e-01, time/batch = 0.6560s	
308/25300 (epoch 0.609), train_loss = 2.79057525, grad/param norm = 4.6942e-01, time/batch = 0.6559s	
309/25300 (epoch 0.611), train_loss = 2.85783439, grad/param norm = 5.1513e-01, time/batch = 0.6577s	
310/25300 (epoch 0.613), train_loss = 2.72944234, grad/param norm = 4.0834e-01, time/batch = 0.6547s	
311/25300 (epoch 0.615), train_loss = 2.69669822, grad/param norm = 3.3064e-01, time/batch = 0.6602s	
312/25300 (epoch 0.617), train_loss = 2.76123289, grad/param norm = 4.8251e-01, time/batch = 0.6596s	
313/25300 (epoch 0.619), train_loss = 2.67057607, grad/param norm = 8.8325e-01, time/batch = 0.6596s	
314/25300 (epoch 0.621), train_loss = 2.68441641, grad/param norm = 8.0891e-01, time/batch = 0.6670s	
315/25300 (epoch 0.623), train_loss = 2.65047079, grad/param norm = 6.3178e-01, time/batch = 0.6649s	
316/25300 (epoch 0.625), train_loss = 2.66760079, grad/param norm = 6.2370e-01, time/batch = 0.6675s	
317/25300 (epoch 0.626), train_loss = 2.64244999, grad/param norm = 5.1261e-01, time/batch = 0.6689s	
318/25300 (epoch 0.628), train_loss = 2.58776516, grad/param norm = 3.1954e-01, time/batch = 0.6700s	
319/25300 (epoch 0.630), train_loss = 2.63446640, grad/param norm = 3.5466e-01, time/batch = 0.6591s	
320/25300 (epoch 0.632), train_loss = 2.77081758, grad/param norm = 3.0511e-01, time/batch = 0.6572s	
321/25300 (epoch 0.634), train_loss = 2.69361548, grad/param norm = 3.5373e-01, time/batch = 0.6573s	
322/25300 (epoch 0.636), train_loss = 2.78713222, grad/param norm = 4.8452e-01, time/batch = 0.6563s	
323/25300 (epoch 0.638), train_loss = 2.71775902, grad/param norm = 4.4601e-01, time/batch = 0.6559s	
324/25300 (epoch 0.640), train_loss = 2.69535239, grad/param norm = 3.2198e-01, time/batch = 0.6644s	
325/25300 (epoch 0.642), train_loss = 2.60960302, grad/param norm = 3.7788e-01, time/batch = 0.6534s	
326/25300 (epoch 0.644), train_loss = 2.69582359, grad/param norm = 3.9883e-01, time/batch = 0.6535s	
327/25300 (epoch 0.646), train_loss = 2.69767540, grad/param norm = 8.2448e-01, time/batch = 0.6557s	
328/25300 (epoch 0.648), train_loss = 2.78745306, grad/param norm = 1.1855e+00, time/batch = 0.6553s	
329/25300 (epoch 0.650), train_loss = 2.84047883, grad/param norm = 7.1955e-01, time/batch = 0.6559s	
330/25300 (epoch 0.652), train_loss = 2.70488657, grad/param norm = 6.8181e-01, time/batch = 0.6611s	
331/25300 (epoch 0.654), train_loss = 2.83610443, grad/param norm = 6.0623e-01, time/batch = 0.6614s	
332/25300 (epoch 0.656), train_loss = 2.73373702, grad/param norm = 4.8356e-01, time/batch = 0.6563s	
333/25300 (epoch 0.658), train_loss = 2.66202058, grad/param norm = 3.6674e-01, time/batch = 0.6586s	
334/25300 (epoch 0.660), train_loss = 2.64019597, grad/param norm = 3.5657e-01, time/batch = 0.6570s	
335/25300 (epoch 0.662), train_loss = 2.38583018, grad/param norm = 3.5633e-01, time/batch = 0.6574s	
336/25300 (epoch 0.664), train_loss = 2.57046400, grad/param norm = 4.0336e-01, time/batch = 0.6559s	
337/25300 (epoch 0.666), train_loss = 2.55737930, grad/param norm = 4.9860e-01, time/batch = 0.6609s	
338/25300 (epoch 0.668), train_loss = 2.66116090, grad/param norm = 7.3177e-01, time/batch = 0.6612s	
339/25300 (epoch 0.670), train_loss = 2.73428432, grad/param norm = 7.5555e-01, time/batch = 0.6593s	
340/25300 (epoch 0.672), train_loss = 2.67900429, grad/param norm = 4.7393e-01, time/batch = 0.6591s	
341/25300 (epoch 0.674), train_loss = 2.66648179, grad/param norm = 5.2424e-01, time/batch = 0.6613s	
342/25300 (epoch 0.676), train_loss = 2.70000780, grad/param norm = 6.2831e-01, time/batch = 0.6581s	
343/25300 (epoch 0.678), train_loss = 2.75181602, grad/param norm = 4.9211e-01, time/batch = 0.6590s	
344/25300 (epoch 0.680), train_loss = 2.53138982, grad/param norm = 3.3391e-01, time/batch = 0.6669s	
345/25300 (epoch 0.682), train_loss = 2.49137888, grad/param norm = 3.7802e-01, time/batch = 0.6693s	
346/25300 (epoch 0.684), train_loss = 2.40747059, grad/param norm = 5.2567e-01, time/batch = 0.6756s	
347/25300 (epoch 0.686), train_loss = 2.60599357, grad/param norm = 9.4646e-01, time/batch = 0.6670s	
348/25300 (epoch 0.688), train_loss = 2.81800513, grad/param norm = 1.1084e+00, time/batch = 0.6665s	
349/25300 (epoch 0.690), train_loss = 2.70959341, grad/param norm = 5.3829e-01, time/batch = 0.6585s	
350/25300 (epoch 0.692), train_loss = 2.60645541, grad/param norm = 3.3237e-01, time/batch = 0.6613s	
351/25300 (epoch 0.694), train_loss = 2.66354146, grad/param norm = 3.2638e-01, time/batch = 0.6603s	
352/25300 (epoch 0.696), train_loss = 2.59739586, grad/param norm = 3.2276e-01, time/batch = 0.6586s	
353/25300 (epoch 0.698), train_loss = 2.59456213, grad/param norm = 3.2004e-01, time/batch = 0.6581s	
354/25300 (epoch 0.700), train_loss = 2.38053912, grad/param norm = 4.3768e-01, time/batch = 0.6576s	
355/25300 (epoch 0.702), train_loss = 2.71461231, grad/param norm = 4.0386e-01, time/batch = 0.6555s	
356/25300 (epoch 0.704), train_loss = 2.45286159, grad/param norm = 3.0164e-01, time/batch = 0.6570s	
357/25300 (epoch 0.706), train_loss = 2.47299830, grad/param norm = 3.0159e-01, time/batch = 0.6570s	
358/25300 (epoch 0.708), train_loss = 2.38610040, grad/param norm = 5.0318e-01, time/batch = 0.6580s	
359/25300 (epoch 0.709), train_loss = 2.63370248, grad/param norm = 7.1323e-01, time/batch = 0.6581s	
360/25300 (epoch 0.711), train_loss = 2.69776281, grad/param norm = 7.6426e-01, time/batch = 0.6625s	
361/25300 (epoch 0.713), train_loss = 2.65074790, grad/param norm = 7.2139e-01, time/batch = 0.6588s	
362/25300 (epoch 0.715), train_loss = 2.47569763, grad/param norm = 4.8931e-01, time/batch = 0.6571s	
363/25300 (epoch 0.717), train_loss = 2.59822968, grad/param norm = 4.2674e-01, time/batch = 0.6588s	
364/25300 (epoch 0.719), train_loss = 2.63007171, grad/param norm = 3.3636e-01, time/batch = 0.6583s	
365/25300 (epoch 0.721), train_loss = 2.47620152, grad/param norm = 4.0035e-01, time/batch = 0.6584s	
366/25300 (epoch 0.723), train_loss = 2.31439734, grad/param norm = 3.7458e-01, time/batch = 0.6627s	
367/25300 (epoch 0.725), train_loss = 2.49146992, grad/param norm = 3.9005e-01, time/batch = 0.6601s	
368/25300 (epoch 0.727), train_loss = 2.48882543, grad/param norm = 4.1457e-01, time/batch = 0.6609s	
369/25300 (epoch 0.729), train_loss = 2.40632722, grad/param norm = 4.0101e-01, time/batch = 0.6610s	
370/25300 (epoch 0.731), train_loss = 2.58620085, grad/param norm = 3.7466e-01, time/batch = 0.6543s	
371/25300 (epoch 0.733), train_loss = 2.35951476, grad/param norm = 3.9282e-01, time/batch = 0.6600s	
372/25300 (epoch 0.735), train_loss = 2.66035801, grad/param norm = 4.4269e-01, time/batch = 0.6560s	
373/25300 (epoch 0.737), train_loss = 2.47966449, grad/param norm = 5.6194e-01, time/batch = 0.6592s	
374/25300 (epoch 0.739), train_loss = 2.51033046, grad/param norm = 8.0149e-01, time/batch = 0.6594s	
375/25300 (epoch 0.741), train_loss = 2.56703559, grad/param norm = 7.3326e-01, time/batch = 0.6658s	
376/25300 (epoch 0.743), train_loss = 2.57928586, grad/param norm = 5.9191e-01, time/batch = 0.6608s	
377/25300 (epoch 0.745), train_loss = 2.40638444, grad/param norm = 3.8245e-01, time/batch = 0.6585s	
378/25300 (epoch 0.747), train_loss = 2.54746136, grad/param norm = 3.4535e-01, time/batch = 0.6578s	
379/25300 (epoch 0.749), train_loss = 2.57093525, grad/param norm = 3.3199e-01, time/batch = 0.6592s	
380/25300 (epoch 0.751), train_loss = 2.55473159, grad/param norm = 2.7259e-01, time/batch = 0.6608s	
381/25300 (epoch 0.753), train_loss = 2.48083816, grad/param norm = 4.1419e-01, time/batch = 0.6634s	
382/25300 (epoch 0.755), train_loss = 2.56688710, grad/param norm = 5.5147e-01, time/batch = 0.6611s	
383/25300 (epoch 0.757), train_loss = 2.58103463, grad/param norm = 7.8042e-01, time/batch = 0.6622s	
384/25300 (epoch 0.759), train_loss = 2.53275243, grad/param norm = 7.6538e-01, time/batch = 0.6740s	
385/25300 (epoch 0.761), train_loss = 2.58467220, grad/param norm = 5.3737e-01, time/batch = 0.6635s	
386/25300 (epoch 0.763), train_loss = 2.49715000, grad/param norm = 4.0071e-01, time/batch = 0.6659s	
387/25300 (epoch 0.765), train_loss = 2.56930750, grad/param norm = 3.9761e-01, time/batch = 0.6653s	
388/25300 (epoch 0.767), train_loss = 2.45651192, grad/param norm = 4.2866e-01, time/batch = 0.6614s	
389/25300 (epoch 0.769), train_loss = 2.53694570, grad/param norm = 3.7034e-01, time/batch = 0.6675s	
390/25300 (epoch 0.771), train_loss = 2.73741098, grad/param norm = 3.5172e-01, time/batch = 0.6580s	
391/25300 (epoch 0.773), train_loss = 2.57811370, grad/param norm = 5.8344e-01, time/batch = 0.6610s	
392/25300 (epoch 0.775), train_loss = 2.53473166, grad/param norm = 8.0511e-01, time/batch = 0.6588s	
393/25300 (epoch 0.777), train_loss = 2.67274902, grad/param norm = 6.2550e-01, time/batch = 0.6555s	
394/25300 (epoch 0.779), train_loss = 2.59423183, grad/param norm = 4.2801e-01, time/batch = 0.6580s	
395/25300 (epoch 0.781), train_loss = 2.44665883, grad/param norm = 4.5406e-01, time/batch = 0.6617s	
396/25300 (epoch 0.783), train_loss = 2.58327043, grad/param norm = 4.2552e-01, time/batch = 0.6564s	
397/25300 (epoch 0.785), train_loss = 2.55336286, grad/param norm = 4.9350e-01, time/batch = 0.6572s	
398/25300 (epoch 0.787), train_loss = 2.68890171, grad/param norm = 7.0669e-01, time/batch = 0.6601s	
399/25300 (epoch 0.789), train_loss = 2.74908669, grad/param norm = 6.4558e-01, time/batch = 0.6525s	
400/25300 (epoch 0.791), train_loss = 2.51655855, grad/param norm = 3.7867e-01, time/batch = 0.6564s	
401/25300 (epoch 0.792), train_loss = 2.46130512, grad/param norm = 3.4260e-01, time/batch = 0.6590s	
402/25300 (epoch 0.794), train_loss = 2.58802351, grad/param norm = 4.0630e-01, time/batch = 0.6597s	
403/25300 (epoch 0.796), train_loss = 2.40616865, grad/param norm = 3.8310e-01, time/batch = 0.6575s	
404/25300 (epoch 0.798), train_loss = 2.61967647, grad/param norm = 4.3185e-01, time/batch = 0.6573s	
405/25300 (epoch 0.800), train_loss = 2.52452467, grad/param norm = 5.3371e-01, time/batch = 0.6561s	
406/25300 (epoch 0.802), train_loss = 2.25583477, grad/param norm = 3.7030e-01, time/batch = 0.6595s	
407/25300 (epoch 0.804), train_loss = 2.56440247, grad/param norm = 4.9381e-01, time/batch = 0.6595s	
408/25300 (epoch 0.806), train_loss = 2.66341766, grad/param norm = 6.9692e-01, time/batch = 0.6587s	
409/25300 (epoch 0.808), train_loss = 2.44748012, grad/param norm = 5.4208e-01, time/batch = 0.6618s	
410/25300 (epoch 0.810), train_loss = 2.45501003, grad/param norm = 4.1491e-01, time/batch = 0.6603s	
411/25300 (epoch 0.812), train_loss = 2.54091898, grad/param norm = 3.4723e-01, time/batch = 0.6594s	
412/25300 (epoch 0.814), train_loss = 2.72274390, grad/param norm = 3.0911e-01, time/batch = 0.6591s	
413/25300 (epoch 0.816), train_loss = 2.66870831, grad/param norm = 4.7520e-01, time/batch = 0.6589s	
414/25300 (epoch 0.818), train_loss = 2.71512729, grad/param norm = 5.1975e-01, time/batch = 0.6625s	
415/25300 (epoch 0.820), train_loss = 2.66243641, grad/param norm = 4.6910e-01, time/batch = 0.6562s	
416/25300 (epoch 0.822), train_loss = 2.44133773, grad/param norm = 4.5259e-01, time/batch = 0.6587s	
417/25300 (epoch 0.824), train_loss = 2.50523434, grad/param norm = 4.3304e-01, time/batch = 0.6558s	
418/25300 (epoch 0.826), train_loss = 2.42358937, grad/param norm = 5.5605e-01, time/batch = 0.6557s	
419/25300 (epoch 0.828), train_loss = 2.47294525, grad/param norm = 4.7659e-01, time/batch = 0.6571s	
420/25300 (epoch 0.830), train_loss = 2.42346498, grad/param norm = 3.6418e-01, time/batch = 0.6568s	
421/25300 (epoch 0.832), train_loss = 2.33880114, grad/param norm = 3.2697e-01, time/batch = 0.6605s	
422/25300 (epoch 0.834), train_loss = 2.37141390, grad/param norm = 2.8022e-01, time/batch = 0.6589s	
423/25300 (epoch 0.836), train_loss = 2.48736658, grad/param norm = 4.6397e-01, time/batch = 0.6570s	
424/25300 (epoch 0.838), train_loss = 2.45133375, grad/param norm = 5.5486e-01, time/batch = 0.6574s	
425/25300 (epoch 0.840), train_loss = 2.45852078, grad/param norm = 3.5561e-01, time/batch = 0.6597s	
426/25300 (epoch 0.842), train_loss = 2.56967926, grad/param norm = 3.9470e-01, time/batch = 0.6551s	
427/25300 (epoch 0.844), train_loss = 2.50923377, grad/param norm = 6.3388e-01, time/batch = 0.6556s	
428/25300 (epoch 0.846), train_loss = 2.29340030, grad/param norm = 5.3158e-01, time/batch = 0.6592s	
429/25300 (epoch 0.848), train_loss = 2.60717509, grad/param norm = 4.8006e-01, time/batch = 0.6510s	
430/25300 (epoch 0.850), train_loss = 2.46142569, grad/param norm = 5.1314e-01, time/batch = 0.6541s	
431/25300 (epoch 0.852), train_loss = 2.44234285, grad/param norm = 5.4761e-01, time/batch = 0.6516s	
432/25300 (epoch 0.854), train_loss = 2.67696492, grad/param norm = 4.5894e-01, time/batch = 0.6519s	
433/25300 (epoch 0.856), train_loss = 2.42909211, grad/param norm = 3.4715e-01, time/batch = 0.6547s	
434/25300 (epoch 0.858), train_loss = 2.46009005, grad/param norm = 2.9993e-01, time/batch = 0.6633s	
435/25300 (epoch 0.860), train_loss = 2.17533060, grad/param norm = 2.9033e-01, time/batch = 0.6655s	
436/25300 (epoch 0.862), train_loss = 2.49745370, grad/param norm = 3.7496e-01, time/batch = 0.6713s	
437/25300 (epoch 0.864), train_loss = 2.51898308, grad/param norm = 4.1501e-01, time/batch = 0.6688s	
438/25300 (epoch 0.866), train_loss = 2.46034948, grad/param norm = 4.7103e-01, time/batch = 0.6759s	
439/25300 (epoch 0.868), train_loss = 2.51747637, grad/param norm = 4.8066e-01, time/batch = 0.6676s	
440/25300 (epoch 0.870), train_loss = 2.49324482, grad/param norm = 3.6374e-01, time/batch = 0.6594s	
441/25300 (epoch 0.872), train_loss = 2.40981180, grad/param norm = 3.5043e-01, time/batch = 0.6740s	
442/25300 (epoch 0.874), train_loss = 2.51026662, grad/param norm = 4.6524e-01, time/batch = 0.6668s	
443/25300 (epoch 0.875), train_loss = 2.52471524, grad/param norm = 5.5755e-01, time/batch = 0.6597s	
444/25300 (epoch 0.877), train_loss = 2.40584545, grad/param norm = 5.2469e-01, time/batch = 0.6572s	
445/25300 (epoch 0.879), train_loss = 2.66357526, grad/param norm = 5.2555e-01, time/batch = 0.6551s	
446/25300 (epoch 0.881), train_loss = 2.60119100, grad/param norm = 4.0376e-01, time/batch = 0.6535s	
447/25300 (epoch 0.883), train_loss = 2.57015313, grad/param norm = 4.5757e-01, time/batch = 0.6551s	
448/25300 (epoch 0.885), train_loss = 2.50477346, grad/param norm = 5.0966e-01, time/batch = 0.6547s	
449/25300 (epoch 0.887), train_loss = 2.42376567, grad/param norm = 3.9382e-01, time/batch = 0.6568s	
450/25300 (epoch 0.889), train_loss = 2.66137414, grad/param norm = 5.2185e-01, time/batch = 0.6549s	
451/25300 (epoch 0.891), train_loss = 2.62878945, grad/param norm = 5.3373e-01, time/batch = 0.6575s	
452/25300 (epoch 0.893), train_loss = 2.74215300, grad/param norm = 4.4688e-01, time/batch = 0.6543s	
453/25300 (epoch 0.895), train_loss = 2.18788365, grad/param norm = 4.7774e-01, time/batch = 0.6522s	
454/25300 (epoch 0.897), train_loss = 2.38500973, grad/param norm = 4.1928e-01, time/batch = 0.6587s	
455/25300 (epoch 0.899), train_loss = 2.41185307, grad/param norm = 3.8362e-01, time/batch = 0.6541s	
456/25300 (epoch 0.901), train_loss = 2.55653869, grad/param norm = 3.9211e-01, time/batch = 0.6537s	
457/25300 (epoch 0.903), train_loss = 2.35660163, grad/param norm = 3.4969e-01, time/batch = 0.6586s	
458/25300 (epoch 0.905), train_loss = 2.41638173, grad/param norm = 4.3398e-01, time/batch = 0.6607s	
459/25300 (epoch 0.907), train_loss = 2.67535150, grad/param norm = 6.0362e-01, time/batch = 0.6759s	
460/25300 (epoch 0.909), train_loss = 2.53057170, grad/param norm = 6.5211e-01, time/batch = 0.6583s	
461/25300 (epoch 0.911), train_loss = 2.53664549, grad/param norm = 3.5579e-01, time/batch = 0.6668s	
462/25300 (epoch 0.913), train_loss = 2.40688653, grad/param norm = 3.5503e-01, time/batch = 0.6599s	
463/25300 (epoch 0.915), train_loss = 2.50134970, grad/param norm = 4.0962e-01, time/batch = 0.6559s	
464/25300 (epoch 0.917), train_loss = 2.55134090, grad/param norm = 4.0955e-01, time/batch = 0.6626s	
465/25300 (epoch 0.919), train_loss = 2.53017904, grad/param norm = 3.2599e-01, time/batch = 0.6572s	
466/25300 (epoch 0.921), train_loss = 2.35575838, grad/param norm = 4.2153e-01, time/batch = 0.6572s	
467/25300 (epoch 0.923), train_loss = 2.49598723, grad/param norm = 3.8130e-01, time/batch = 0.6522s	
468/25300 (epoch 0.925), train_loss = 2.53163654, grad/param norm = 4.7521e-01, time/batch = 0.6576s	
469/25300 (epoch 0.927), train_loss = 2.48749369, grad/param norm = 5.0676e-01, time/batch = 0.6662s	
470/25300 (epoch 0.929), train_loss = 2.18444489, grad/param norm = 3.4834e-01, time/batch = 0.6565s	
471/25300 (epoch 0.931), train_loss = 2.48461371, grad/param norm = 2.9131e-01, time/batch = 0.6577s	
472/25300 (epoch 0.933), train_loss = 2.55194781, grad/param norm = 3.0096e-01, time/batch = 0.6618s	
473/25300 (epoch 0.935), train_loss = 2.39685396, grad/param norm = 4.0725e-01, time/batch = 0.6637s	
474/25300 (epoch 0.937), train_loss = 2.23697354, grad/param norm = 3.7805e-01, time/batch = 0.6601s	
475/25300 (epoch 0.939), train_loss = 2.62686744, grad/param norm = 3.8584e-01, time/batch = 0.6577s	
476/25300 (epoch 0.941), train_loss = 2.37564150, grad/param norm = 4.2260e-01, time/batch = 0.6596s	
477/25300 (epoch 0.943), train_loss = 2.34550894, grad/param norm = 4.4916e-01, time/batch = 0.6581s	
478/25300 (epoch 0.945), train_loss = 2.40810061, grad/param norm = 3.8114e-01, time/batch = 0.6557s	
479/25300 (epoch 0.947), train_loss = 2.44112931, grad/param norm = 3.6532e-01, time/batch = 0.6533s	
480/25300 (epoch 0.949), train_loss = 2.46221229, grad/param norm = 4.4110e-01, time/batch = 0.6574s	
481/25300 (epoch 0.951), train_loss = 2.49721110, grad/param norm = 4.8251e-01, time/batch = 0.6658s	
482/25300 (epoch 0.953), train_loss = 2.53214322, grad/param norm = 3.4801e-01, time/batch = 0.6557s	
483/25300 (epoch 0.955), train_loss = 2.57400316, grad/param norm = 3.1253e-01, time/batch = 0.6543s	
484/25300 (epoch 0.957), train_loss = 2.46020540, grad/param norm = 3.8815e-01, time/batch = 0.6558s	
485/25300 (epoch 0.958), train_loss = 2.50256151, grad/param norm = 3.6018e-01, time/batch = 0.6582s	
486/25300 (epoch 0.960), train_loss = 2.51884801, grad/param norm = 3.9227e-01, time/batch = 0.6548s	
487/25300 (epoch 0.962), train_loss = 2.33058214, grad/param norm = 4.1922e-01, time/batch = 0.6558s	
488/25300 (epoch 0.964), train_loss = 2.36434761, grad/param norm = 5.4930e-01, time/batch = 0.6596s	
489/25300 (epoch 0.966), train_loss = 2.37434140, grad/param norm = 8.4341e-01, time/batch = 0.6570s	
490/25300 (epoch 0.968), train_loss = 2.29587401, grad/param norm = 7.0565e-01, time/batch = 0.6530s	
491/25300 (epoch 0.970), train_loss = 2.49752710, grad/param norm = 3.4791e-01, time/batch = 0.6551s	
492/25300 (epoch 0.972), train_loss = 2.35098766, grad/param norm = 2.8841e-01, time/batch = 0.6550s	
493/25300 (epoch 0.974), train_loss = 2.51390716, grad/param norm = 2.8092e-01, time/batch = 0.6570s	
494/25300 (epoch 0.976), train_loss = 2.47529039, grad/param norm = 4.0717e-01, time/batch = 0.6583s	
495/25300 (epoch 0.978), train_loss = 2.43757831, grad/param norm = 4.0340e-01, time/batch = 0.6560s	
496/25300 (epoch 0.980), train_loss = 2.43725773, grad/param norm = 3.0753e-01, time/batch = 0.6567s	
497/25300 (epoch 0.982), train_loss = 2.48451715, grad/param norm = 3.3977e-01, time/batch = 0.6559s	
498/25300 (epoch 0.984), train_loss = 2.49443913, grad/param norm = 3.4003e-01, time/batch = 0.6575s	
499/25300 (epoch 0.986), train_loss = 2.32315841, grad/param norm = 3.1966e-01, time/batch = 0.6526s	
500/25300 (epoch 0.988), train_loss = 2.43653400, grad/param norm = 4.6320e-01, time/batch = 0.6569s	
501/25300 (epoch 0.990), train_loss = 2.39062476, grad/param norm = 4.8311e-01, time/batch = 0.6602s	
502/25300 (epoch 0.992), train_loss = 2.18480887, grad/param norm = 4.4960e-01, time/batch = 0.6661s	
503/25300 (epoch 0.994), train_loss = 2.46473848, grad/param norm = 3.5057e-01, time/batch = 0.6608s	
504/25300 (epoch 0.996), train_loss = 2.47795551, grad/param norm = 3.4803e-01, time/batch = 0.6644s	
505/25300 (epoch 0.998), train_loss = 2.41103387, grad/param norm = 3.7992e-01, time/batch = 0.6669s	
506/25300 (epoch 1.000), train_loss = 2.47283486, grad/param norm = 4.1630e-01, time/batch = 0.6642s	
507/25300 (epoch 1.002), train_loss = 2.24109338, grad/param norm = 3.2403e-01, time/batch = 0.6608s	
508/25300 (epoch 1.004), train_loss = 2.28999766, grad/param norm = 3.4224e-01, time/batch = 0.6588s	
509/25300 (epoch 1.006), train_loss = 2.29993647, grad/param norm = 3.4439e-01, time/batch = 0.6570s	
510/25300 (epoch 1.008), train_loss = 2.36790146, grad/param norm = 2.9346e-01, time/batch = 0.6594s	
511/25300 (epoch 1.010), train_loss = 2.33367316, grad/param norm = 4.2878e-01, time/batch = 0.6680s	
512/25300 (epoch 1.012), train_loss = 2.24647483, grad/param norm = 5.5454e-01, time/batch = 0.6602s	
513/25300 (epoch 1.014), train_loss = 2.28588148, grad/param norm = 4.6047e-01, time/batch = 0.6585s	
514/25300 (epoch 1.016), train_loss = 2.47390635, grad/param norm = 5.7300e-01, time/batch = 0.6579s	
515/25300 (epoch 1.018), train_loss = 2.38927008, grad/param norm = 5.3460e-01, time/batch = 0.6677s	
516/25300 (epoch 1.020), train_loss = 2.35920051, grad/param norm = 4.4501e-01, time/batch = 0.6643s	
517/25300 (epoch 1.022), train_loss = 2.40492566, grad/param norm = 5.0529e-01, time/batch = 0.6560s	
518/25300 (epoch 1.024), train_loss = 2.08802753, grad/param norm = 3.7254e-01, time/batch = 0.6585s	
519/25300 (epoch 1.026), train_loss = 2.32899485, grad/param norm = 3.3203e-01, time/batch = 0.6592s	
520/25300 (epoch 1.028), train_loss = 2.21617996, grad/param norm = 2.9199e-01, time/batch = 0.6572s	
521/25300 (epoch 1.030), train_loss = 2.36061083, grad/param norm = 3.2585e-01, time/batch = 0.6584s	
522/25300 (epoch 1.032), train_loss = 2.32941998, grad/param norm = 3.0823e-01, time/batch = 0.6570s	
523/25300 (epoch 1.034), train_loss = 2.13006584, grad/param norm = 2.5635e-01, time/batch = 0.6553s	
524/25300 (epoch 1.036), train_loss = 2.17194964, grad/param norm = 2.9212e-01, time/batch = 0.6548s	
525/25300 (epoch 1.038), train_loss = 2.22986733, grad/param norm = 4.0047e-01, time/batch = 0.6669s	
526/25300 (epoch 1.040), train_loss = 2.41183205, grad/param norm = 4.7254e-01, time/batch = 0.6677s	
527/25300 (epoch 1.042), train_loss = 2.28786321, grad/param norm = 6.9515e-01, time/batch = 0.6716s	
528/25300 (epoch 1.043), train_loss = 2.13239127, grad/param norm = 4.0050e-01, time/batch = 0.6507s	
529/25300 (epoch 1.045), train_loss = 2.16595514, grad/param norm = 3.1577e-01, time/batch = 0.6565s	
530/25300 (epoch 1.047), train_loss = 2.43644488, grad/param norm = 3.4357e-01, time/batch = 0.6577s	
531/25300 (epoch 1.049), train_loss = 2.22329041, grad/param norm = 3.2511e-01, time/batch = 0.6591s	
532/25300 (epoch 1.051), train_loss = 2.40754998, grad/param norm = 4.5175e-01, time/batch = 0.6593s	
533/25300 (epoch 1.053), train_loss = 2.08402495, grad/param norm = 4.3210e-01, time/batch = 0.6586s	
534/25300 (epoch 1.055), train_loss = 2.27564348, grad/param norm = 3.8426e-01, time/batch = 0.6614s	
535/25300 (epoch 1.057), train_loss = 2.11122556, grad/param norm = 4.2727e-01, time/batch = 0.6615s	
536/25300 (epoch 1.059), train_loss = 2.34615436, grad/param norm = 5.1457e-01, time/batch = 0.6595s	
537/25300 (epoch 1.061), train_loss = 2.28233156, grad/param norm = 4.8208e-01, time/batch = 0.6567s	
538/25300 (epoch 1.063), train_loss = 2.41388524, grad/param norm = 3.4607e-01, time/batch = 0.6678s	
539/25300 (epoch 1.065), train_loss = 2.41329666, grad/param norm = 3.3580e-01, time/batch = 0.6657s	
540/25300 (epoch 1.067), train_loss = 2.24788511, grad/param norm = 3.0606e-01, time/batch = 0.6638s	
541/25300 (epoch 1.069), train_loss = 2.32225580, grad/param norm = 4.7892e-01, time/batch = 0.6624s	
542/25300 (epoch 1.071), train_loss = 2.44276362, grad/param norm = 6.1903e-01, time/batch = 0.6610s	
543/25300 (epoch 1.073), train_loss = 2.34541111, grad/param norm = 5.4442e-01, time/batch = 0.6622s	
544/25300 (epoch 1.075), train_loss = 2.21233498, grad/param norm = 4.3717e-01, time/batch = 0.6617s	
545/25300 (epoch 1.077), train_loss = 2.40859001, grad/param norm = 3.2321e-01, time/batch = 0.6580s	
546/25300 (epoch 1.079), train_loss = 2.34134586, grad/param norm = 3.3082e-01, time/batch = 0.6595s	
547/25300 (epoch 1.081), train_loss = 2.33148971, grad/param norm = 3.0218e-01, time/batch = 0.6624s	
548/25300 (epoch 1.083), train_loss = 2.16925024, grad/param norm = 3.4876e-01, time/batch = 0.6671s	
549/25300 (epoch 1.085), train_loss = 2.46807992, grad/param norm = 3.2087e-01, time/batch = 0.6667s	
550/25300 (epoch 1.087), train_loss = 2.29050622, grad/param norm = 3.3620e-01, time/batch = 0.6609s	
551/25300 (epoch 1.089), train_loss = 2.19052056, grad/param norm = 2.9873e-01, time/batch = 0.6682s	
552/25300 (epoch 1.091), train_loss = 2.18465420, grad/param norm = 2.7084e-01, time/batch = 0.6666s	
553/25300 (epoch 1.093), train_loss = 2.43304711, grad/param norm = 3.0711e-01, time/batch = 0.6657s	
554/25300 (epoch 1.095), train_loss = 2.29367301, grad/param norm = 3.0967e-01, time/batch = 0.6682s	
555/25300 (epoch 1.097), train_loss = 2.22860781, grad/param norm = 3.1443e-01, time/batch = 0.6684s	
556/25300 (epoch 1.099), train_loss = 2.23577549, grad/param norm = 4.7866e-01, time/batch = 0.6708s	
557/25300 (epoch 1.101), train_loss = 2.21914694, grad/param norm = 6.8104e-01, time/batch = 0.6706s	
558/25300 (epoch 1.103), train_loss = 2.20492223, grad/param norm = 4.4228e-01, time/batch = 0.6639s	
559/25300 (epoch 1.105), train_loss = 2.43377480, grad/param norm = 3.8936e-01, time/batch = 0.6605s	
560/25300 (epoch 1.107), train_loss = 2.38479635, grad/param norm = 3.2367e-01, time/batch = 0.6675s	
561/25300 (epoch 1.109), train_loss = 2.41040968, grad/param norm = 4.0664e-01, time/batch = 0.6706s	
562/25300 (epoch 1.111), train_loss = 2.18631977, grad/param norm = 3.4462e-01, time/batch = 0.6699s	
563/25300 (epoch 1.113), train_loss = 2.35747977, grad/param norm = 4.3577e-01, time/batch = 0.6686s	
564/25300 (epoch 1.115), train_loss = 2.28795156, grad/param norm = 4.6020e-01, time/batch = 0.6634s	
565/25300 (epoch 1.117), train_loss = 2.39843987, grad/param norm = 5.0013e-01, time/batch = 0.6543s	
566/25300 (epoch 1.119), train_loss = 2.27730667, grad/param norm = 3.8288e-01, time/batch = 0.6539s	
567/25300 (epoch 1.121), train_loss = 2.52318973, grad/param norm = 2.7699e-01, time/batch = 0.6568s	
568/25300 (epoch 1.123), train_loss = 2.28260466, grad/param norm = 2.8193e-01, time/batch = 0.6574s	
569/25300 (epoch 1.125), train_loss = 2.34311211, grad/param norm = 3.4160e-01, time/batch = 0.6593s	
570/25300 (epoch 1.126), train_loss = 2.14853818, grad/param norm = 3.7350e-01, time/batch = 0.6756s	
571/25300 (epoch 1.128), train_loss = 2.32458916, grad/param norm = 3.7096e-01, time/batch = 0.6638s	
572/25300 (epoch 1.130), train_loss = 2.00407546, grad/param norm = 3.9820e-01, time/batch = 0.6651s	
573/25300 (epoch 1.132), train_loss = 2.24565376, grad/param norm = 3.5170e-01, time/batch = 0.6590s	
574/25300 (epoch 1.134), train_loss = 2.00982879, grad/param norm = 2.9614e-01, time/batch = 0.6649s	
575/25300 (epoch 1.136), train_loss = 2.28812723, grad/param norm = 3.0507e-01, time/batch = 0.6594s	
576/25300 (epoch 1.138), train_loss = 2.12423529, grad/param norm = 2.8864e-01, time/batch = 0.6567s	
577/25300 (epoch 1.140), train_loss = 2.18070771, grad/param norm = 3.0322e-01, time/batch = 0.6589s	
578/25300 (epoch 1.142), train_loss = 2.28888660, grad/param norm = 3.3816e-01, time/batch = 0.6598s	
579/25300 (epoch 1.144), train_loss = 2.14683193, grad/param norm = 3.8138e-01, time/batch = 0.6628s	
580/25300 (epoch 1.146), train_loss = 2.33739127, grad/param norm = 4.3686e-01, time/batch = 0.6557s	
581/25300 (epoch 1.148), train_loss = 2.44301487, grad/param norm = 4.7771e-01, time/batch = 0.6600s	
582/25300 (epoch 1.150), train_loss = 2.32134378, grad/param norm = 3.6160e-01, time/batch = 0.6621s	
583/25300 (epoch 1.152), train_loss = 2.43726061, grad/param norm = 3.0250e-01, time/batch = 0.6554s	
584/25300 (epoch 1.154), train_loss = 2.18367213, grad/param norm = 3.0780e-01, time/batch = 0.6515s	
585/25300 (epoch 1.156), train_loss = 2.31598029, grad/param norm = 3.0623e-01, time/batch = 0.6583s	
586/25300 (epoch 1.158), train_loss = 2.25160606, grad/param norm = 3.2212e-01, time/batch = 0.6587s	
587/25300 (epoch 1.160), train_loss = 2.27738118, grad/param norm = 4.9706e-01, time/batch = 0.6651s	
588/25300 (epoch 1.162), train_loss = 2.23347779, grad/param norm = 6.8713e-01, time/batch = 0.6583s	
589/25300 (epoch 1.164), train_loss = 2.42041611, grad/param norm = 5.0137e-01, time/batch = 0.6589s	
590/25300 (epoch 1.166), train_loss = 2.36129615, grad/param norm = 4.3957e-01, time/batch = 0.6586s	
591/25300 (epoch 1.168), train_loss = 2.14406458, grad/param norm = 5.3531e-01, time/batch = 0.6578s	
592/25300 (epoch 1.170), train_loss = 2.24503171, grad/param norm = 5.4153e-01, time/batch = 0.6555s	
593/25300 (epoch 1.172), train_loss = 2.28380865, grad/param norm = 5.1937e-01, time/batch = 0.6587s	
594/25300 (epoch 1.174), train_loss = 2.18907195, grad/param norm = 4.1446e-01, time/batch = 0.6624s	
595/25300 (epoch 1.176), train_loss = 2.35479697, grad/param norm = 3.1671e-01, time/batch = 0.6584s	
596/25300 (epoch 1.178), train_loss = 2.42473955, grad/param norm = 2.9374e-01, time/batch = 0.6561s	
597/25300 (epoch 1.180), train_loss = 2.23484137, grad/param norm = 3.3178e-01, time/batch = 0.6563s	
598/25300 (epoch 1.182), train_loss = 2.26365727, grad/param norm = 2.8870e-01, time/batch = 0.6562s	
599/25300 (epoch 1.184), train_loss = 2.30255078, grad/param norm = 3.2991e-01, time/batch = 0.6564s	
600/25300 (epoch 1.186), train_loss = 2.35351816, grad/param norm = 3.6110e-01, time/batch = 0.6597s	
601/25300 (epoch 1.188), train_loss = 2.13651812, grad/param norm = 3.2789e-01, time/batch = 0.6606s	
602/25300 (epoch 1.190), train_loss = 2.15564005, grad/param norm = 2.6169e-01, time/batch = 0.6621s	
603/25300 (epoch 1.192), train_loss = 2.32647662, grad/param norm = 2.6652e-01, time/batch = 0.6606s	
604/25300 (epoch 1.194), train_loss = 2.15644882, grad/param norm = 3.6213e-01, time/batch = 0.6590s	
605/25300 (epoch 1.196), train_loss = 2.23860552, grad/param norm = 4.0344e-01, time/batch = 0.6566s	
606/25300 (epoch 1.198), train_loss = 2.30136152, grad/param norm = 3.9623e-01, time/batch = 0.6579s	
607/25300 (epoch 1.200), train_loss = 2.29152991, grad/param norm = 3.7939e-01, time/batch = 0.6578s	
608/25300 (epoch 1.202), train_loss = 2.24920855, grad/param norm = 3.7904e-01, time/batch = 0.6580s	
609/25300 (epoch 1.204), train_loss = 2.22321538, grad/param norm = 4.3031e-01, time/batch = 0.6609s	
610/25300 (epoch 1.206), train_loss = 2.21381987, grad/param norm = 4.3945e-01, time/batch = 0.6569s	
611/25300 (epoch 1.208), train_loss = 2.15484353, grad/param norm = 4.5415e-01, time/batch = 0.6579s	
612/25300 (epoch 1.209), train_loss = 2.11471019, grad/param norm = 4.8820e-01, time/batch = 0.6582s	
613/25300 (epoch 1.211), train_loss = 2.28545070, grad/param norm = 3.4900e-01, time/batch = 0.6584s	
614/25300 (epoch 1.213), train_loss = 2.18633196, grad/param norm = 3.1022e-01, time/batch = 0.6559s	
615/25300 (epoch 1.215), train_loss = 2.31996801, grad/param norm = 3.0332e-01, time/batch = 0.6572s	
616/25300 (epoch 1.217), train_loss = 2.28513697, grad/param norm = 3.0910e-01, time/batch = 0.6674s	
617/25300 (epoch 1.219), train_loss = 2.22633296, grad/param norm = 3.0506e-01, time/batch = 0.6630s	
618/25300 (epoch 1.221), train_loss = 2.36834549, grad/param norm = 3.5817e-01, time/batch = 0.6653s	
619/25300 (epoch 1.223), train_loss = 2.36063468, grad/param norm = 4.1216e-01, time/batch = 0.6673s	
620/25300 (epoch 1.225), train_loss = 2.46119099, grad/param norm = 4.4304e-01, time/batch = 0.6652s	
621/25300 (epoch 1.227), train_loss = 2.24177762, grad/param norm = 3.6584e-01, time/batch = 0.6698s	
622/25300 (epoch 1.229), train_loss = 2.24792740, grad/param norm = 2.6199e-01, time/batch = 0.6734s	
623/25300 (epoch 1.231), train_loss = 2.33126215, grad/param norm = 4.2120e-01, time/batch = 0.6686s	
624/25300 (epoch 1.233), train_loss = 2.33148788, grad/param norm = 4.0607e-01, time/batch = 0.6636s	
625/25300 (epoch 1.235), train_loss = 2.16711167, grad/param norm = 3.9014e-01, time/batch = 0.6643s	
626/25300 (epoch 1.237), train_loss = 2.35756548, grad/param norm = 3.4324e-01, time/batch = 0.6581s	
627/25300 (epoch 1.239), train_loss = 2.25835626, grad/param norm = 3.4481e-01, time/batch = 0.6583s	
628/25300 (epoch 1.241), train_loss = 2.37835631, grad/param norm = 3.0106e-01, time/batch = 0.6590s	
629/25300 (epoch 1.243), train_loss = 2.44219283, grad/param norm = 3.7911e-01, time/batch = 0.6568s	
630/25300 (epoch 1.245), train_loss = 2.10236269, grad/param norm = 3.2008e-01, time/batch = 0.6554s	
631/25300 (epoch 1.247), train_loss = 2.32559310, grad/param norm = 3.3733e-01, time/batch = 0.6594s	
632/25300 (epoch 1.249), train_loss = 2.15996060, grad/param norm = 3.2402e-01, time/batch = 0.6572s	
633/25300 (epoch 1.251), train_loss = 2.09884464, grad/param norm = 4.0701e-01, time/batch = 0.6553s	
634/25300 (epoch 1.253), train_loss = 2.23940336, grad/param norm = 4.4989e-01, time/batch = 0.6541s	
635/25300 (epoch 1.255), train_loss = 2.14760061, grad/param norm = 3.0131e-01, time/batch = 0.6533s	
636/25300 (epoch 1.257), train_loss = 2.47589794, grad/param norm = 3.2492e-01, time/batch = 0.6572s	
637/25300 (epoch 1.259), train_loss = 2.58902161, grad/param norm = 3.3706e-01, time/batch = 0.6567s	
638/25300 (epoch 1.261), train_loss = 2.32670396, grad/param norm = 2.4978e-01, time/batch = 0.6568s	
639/25300 (epoch 1.263), train_loss = 2.29048382, grad/param norm = 3.5313e-01, time/batch = 0.6564s	
640/25300 (epoch 1.265), train_loss = 2.29236542, grad/param norm = 4.3890e-01, time/batch = 0.6588s	
641/25300 (epoch 1.267), train_loss = 2.32461833, grad/param norm = 3.1504e-01, time/batch = 0.6588s	
642/25300 (epoch 1.269), train_loss = 2.21039041, grad/param norm = 3.1104e-01, time/batch = 0.6564s	
643/25300 (epoch 1.271), train_loss = 2.12580829, grad/param norm = 2.8016e-01, time/batch = 0.6567s	
644/25300 (epoch 1.273), train_loss = 2.23417810, grad/param norm = 3.1500e-01, time/batch = 0.6563s	
645/25300 (epoch 1.275), train_loss = 2.09217784, grad/param norm = 3.4524e-01, time/batch = 0.6577s	
646/25300 (epoch 1.277), train_loss = 2.29528067, grad/param norm = 3.7813e-01, time/batch = 0.6581s	
647/25300 (epoch 1.279), train_loss = 2.30163804, grad/param norm = 4.3866e-01, time/batch = 0.6599s	
648/25300 (epoch 1.281), train_loss = 2.31842431, grad/param norm = 5.0767e-01, time/batch = 0.6601s	
649/25300 (epoch 1.283), train_loss = 2.24914423, grad/param norm = 4.2441e-01, time/batch = 0.6582s	
650/25300 (epoch 1.285), train_loss = 2.31334704, grad/param norm = 3.6657e-01, time/batch = 0.6583s	
651/25300 (epoch 1.287), train_loss = 2.24080675, grad/param norm = 4.3078e-01, time/batch = 0.6564s	
652/25300 (epoch 1.289), train_loss = 2.30193330, grad/param norm = 4.5358e-01, time/batch = 0.6617s	
653/25300 (epoch 1.291), train_loss = 2.04824819, grad/param norm = 3.4393e-01, time/batch = 0.6554s	
654/25300 (epoch 1.292), train_loss = 2.24702013, grad/param norm = 2.8381e-01, time/batch = 0.6589s	
655/25300 (epoch 1.294), train_loss = 2.12754706, grad/param norm = 2.9174e-01, time/batch = 0.6599s	
656/25300 (epoch 1.296), train_loss = 2.14948371, grad/param norm = 2.7616e-01, time/batch = 0.6624s	
657/25300 (epoch 1.298), train_loss = 2.28285105, grad/param norm = 3.2931e-01, time/batch = 0.6634s	
658/25300 (epoch 1.300), train_loss = 2.49375094, grad/param norm = 3.4354e-01, time/batch = 0.6643s	
659/25300 (epoch 1.302), train_loss = 2.00133884, grad/param norm = 3.7524e-01, time/batch = 0.6636s	
660/25300 (epoch 1.304), train_loss = 2.30204891, grad/param norm = 4.1604e-01, time/batch = 0.6652s	
661/25300 (epoch 1.306), train_loss = 2.08887126, grad/param norm = 3.7037e-01, time/batch = 0.6665s	
662/25300 (epoch 1.308), train_loss = 2.25128493, grad/param norm = 4.0839e-01, time/batch = 0.6609s	
663/25300 (epoch 1.310), train_loss = 2.16020052, grad/param norm = 3.8260e-01, time/batch = 0.6586s	
664/25300 (epoch 1.312), train_loss = 2.32171618, grad/param norm = 4.0657e-01, time/batch = 0.6575s	
665/25300 (epoch 1.314), train_loss = 2.16020527, grad/param norm = 3.9016e-01, time/batch = 0.6591s	
666/25300 (epoch 1.316), train_loss = 2.21651693, grad/param norm = 3.0444e-01, time/batch = 0.6590s	
667/25300 (epoch 1.318), train_loss = 1.98160385, grad/param norm = 3.3639e-01, time/batch = 0.6576s	
668/25300 (epoch 1.320), train_loss = 2.13759195, grad/param norm = 3.3990e-01, time/batch = 0.6632s	
669/25300 (epoch 1.322), train_loss = 2.35798006, grad/param norm = 2.9087e-01, time/batch = 0.6790s	
670/25300 (epoch 1.324), train_loss = 2.00514829, grad/param norm = 4.3532e-01, time/batch = 0.6634s	
671/25300 (epoch 1.326), train_loss = 1.92053344, grad/param norm = 4.3214e-01, time/batch = 0.6628s	
672/25300 (epoch 1.328), train_loss = 2.26667293, grad/param norm = 3.8741e-01, time/batch = 0.6667s	
673/25300 (epoch 1.330), train_loss = 2.12486268, grad/param norm = 3.0909e-01, time/batch = 0.6740s	
674/25300 (epoch 1.332), train_loss = 2.23290668, grad/param norm = 3.0125e-01, time/batch = 0.6664s	
675/25300 (epoch 1.334), train_loss = 2.29232271, grad/param norm = 3.1571e-01, time/batch = 0.6646s	
676/25300 (epoch 1.336), train_loss = 2.06987390, grad/param norm = 3.1646e-01, time/batch = 0.6560s	
677/25300 (epoch 1.338), train_loss = 2.07036760, grad/param norm = 3.6529e-01, time/batch = 0.6549s	
678/25300 (epoch 1.340), train_loss = 2.11430633, grad/param norm = 3.7726e-01, time/batch = 0.6547s	
679/25300 (epoch 1.342), train_loss = 2.19325127, grad/param norm = 3.4595e-01, time/batch = 0.6545s	
680/25300 (epoch 1.344), train_loss = 2.19980859, grad/param norm = 3.6618e-01, time/batch = 0.6552s	
681/25300 (epoch 1.346), train_loss = 2.22734135, grad/param norm = 3.9056e-01, time/batch = 0.6571s	
682/25300 (epoch 1.348), train_loss = 2.00590879, grad/param norm = 3.2694e-01, time/batch = 0.6587s	
683/25300 (epoch 1.350), train_loss = 2.14066814, grad/param norm = 3.0627e-01, time/batch = 0.6630s	
684/25300 (epoch 1.352), train_loss = 2.22252952, grad/param norm = 3.6647e-01, time/batch = 0.6575s	
685/25300 (epoch 1.354), train_loss = 2.14176138, grad/param norm = 3.7492e-01, time/batch = 0.6558s	
686/25300 (epoch 1.356), train_loss = 2.17412932, grad/param norm = 3.5621e-01, time/batch = 0.6567s	
687/25300 (epoch 1.358), train_loss = 2.33067396, grad/param norm = 4.0553e-01, time/batch = 0.6557s	
688/25300 (epoch 1.360), train_loss = 2.18743650, grad/param norm = 3.0130e-01, time/batch = 0.6547s	
689/25300 (epoch 1.362), train_loss = 2.34832917, grad/param norm = 2.7839e-01, time/batch = 0.6507s	
690/25300 (epoch 1.364), train_loss = 2.28291243, grad/param norm = 2.9433e-01, time/batch = 0.6511s	
691/25300 (epoch 1.366), train_loss = 2.09199226, grad/param norm = 3.0854e-01, time/batch = 0.6511s	
692/25300 (epoch 1.368), train_loss = 2.22927785, grad/param norm = 3.5789e-01, time/batch = 0.6551s	
693/25300 (epoch 1.370), train_loss = 2.23077077, grad/param norm = 3.8710e-01, time/batch = 0.6596s	
694/25300 (epoch 1.372), train_loss = 2.28314221, grad/param norm = 4.1329e-01, time/batch = 0.6575s	
695/25300 (epoch 1.374), train_loss = 2.08254077, grad/param norm = 3.9986e-01, time/batch = 0.6588s	
696/25300 (epoch 1.375), train_loss = 2.30858941, grad/param norm = 3.7521e-01, time/batch = 0.6637s	
697/25300 (epoch 1.377), train_loss = 1.99503403, grad/param norm = 2.4141e-01, time/batch = 0.6674s	
698/25300 (epoch 1.379), train_loss = 2.47822933, grad/param norm = 3.6063e-01, time/batch = 0.6626s	
699/25300 (epoch 1.381), train_loss = 2.13770940, grad/param norm = 3.2638e-01, time/batch = 0.6608s	
700/25300 (epoch 1.383), train_loss = 2.04662144, grad/param norm = 3.5246e-01, time/batch = 0.6583s	
701/25300 (epoch 1.385), train_loss = 2.13208106, grad/param norm = 3.8393e-01, time/batch = 0.6608s	
702/25300 (epoch 1.387), train_loss = 2.33088557, grad/param norm = 3.2093e-01, time/batch = 0.6590s	
703/25300 (epoch 1.389), train_loss = 2.30286907, grad/param norm = 2.7435e-01, time/batch = 0.6606s	
704/25300 (epoch 1.391), train_loss = 1.99530024, grad/param norm = 2.9029e-01, time/batch = 0.6583s	
705/25300 (epoch 1.393), train_loss = 2.23579358, grad/param norm = 3.4998e-01, time/batch = 0.6571s	
706/25300 (epoch 1.395), train_loss = 1.97692714, grad/param norm = 3.6433e-01, time/batch = 0.6673s	
707/25300 (epoch 1.397), train_loss = 2.02420281, grad/param norm = 3.8655e-01, time/batch = 0.6705s	
708/25300 (epoch 1.399), train_loss = 2.09480255, grad/param norm = 3.2258e-01, time/batch = 0.6598s	
709/25300 (epoch 1.401), train_loss = 2.12847019, grad/param norm = 2.9466e-01, time/batch = 0.6617s	
710/25300 (epoch 1.403), train_loss = 2.08207486, grad/param norm = 3.6369e-01, time/batch = 0.6690s	
711/25300 (epoch 1.405), train_loss = 2.20060627, grad/param norm = 4.2537e-01, time/batch = 0.6686s	
712/25300 (epoch 1.407), train_loss = 2.06920539, grad/param norm = 4.5223e-01, time/batch = 0.6568s	
713/25300 (epoch 1.409), train_loss = 2.13047838, grad/param norm = 3.2179e-01, time/batch = 0.6476s	
714/25300 (epoch 1.411), train_loss = 2.06936113, grad/param norm = 3.5337e-01, time/batch = 0.6553s	
715/25300 (epoch 1.413), train_loss = 2.13631538, grad/param norm = 3.4564e-01, time/batch = 0.6598s	
716/25300 (epoch 1.415), train_loss = 2.12581529, grad/param norm = 3.5963e-01, time/batch = 0.6604s	
717/25300 (epoch 1.417), train_loss = 2.18889493, grad/param norm = 3.2598e-01, time/batch = 0.6612s	
718/25300 (epoch 1.419), train_loss = 1.96391264, grad/param norm = 3.2869e-01, time/batch = 0.6658s	
719/25300 (epoch 1.421), train_loss = 2.13870188, grad/param norm = 2.7715e-01, time/batch = 0.6557s	
720/25300 (epoch 1.423), train_loss = 2.08020221, grad/param norm = 2.5378e-01, time/batch = 0.6545s	
721/25300 (epoch 1.425), train_loss = 2.11230335, grad/param norm = 2.8396e-01, time/batch = 0.6560s	
722/25300 (epoch 1.427), train_loss = 2.38411962, grad/param norm = 3.5814e-01, time/batch = 0.6548s	
723/25300 (epoch 1.429), train_loss = 2.15529252, grad/param norm = 3.8393e-01, time/batch = 0.6558s	
724/25300 (epoch 1.431), train_loss = 2.29260144, grad/param norm = 4.6217e-01, time/batch = 0.6566s	
725/25300 (epoch 1.433), train_loss = 2.18840237, grad/param norm = 3.6991e-01, time/batch = 0.6566s	
726/25300 (epoch 1.435), train_loss = 1.93193683, grad/param norm = 2.9592e-01, time/batch = 0.6546s	
727/25300 (epoch 1.437), train_loss = 2.10324222, grad/param norm = 2.6602e-01, time/batch = 0.6615s	
728/25300 (epoch 1.439), train_loss = 2.20172191, grad/param norm = 2.7259e-01, time/batch = 0.6578s	
729/25300 (epoch 1.441), train_loss = 2.08628590, grad/param norm = 3.3512e-01, time/batch = 0.6585s	
730/25300 (epoch 1.443), train_loss = 2.24585444, grad/param norm = 3.6303e-01, time/batch = 0.6582s	
731/25300 (epoch 1.445), train_loss = 2.26507956, grad/param norm = 3.4320e-01, time/batch = 0.6580s	
732/25300 (epoch 1.447), train_loss = 1.99600225, grad/param norm = 3.2000e-01, time/batch = 0.6573s	
733/25300 (epoch 1.449), train_loss = 2.11914350, grad/param norm = 3.5166e-01, time/batch = 0.6564s	
734/25300 (epoch 1.451), train_loss = 2.37476902, grad/param norm = 3.7297e-01, time/batch = 0.6577s	
735/25300 (epoch 1.453), train_loss = 2.13845556, grad/param norm = 4.3194e-01, time/batch = 0.6576s	
736/25300 (epoch 1.455), train_loss = 2.28602073, grad/param norm = 4.4348e-01, time/batch = 0.6562s	
737/25300 (epoch 1.457), train_loss = 2.19600165, grad/param norm = 3.8287e-01, time/batch = 0.6579s	
738/25300 (epoch 1.458), train_loss = 2.28937547, grad/param norm = 3.8062e-01, time/batch = 0.6570s	
739/25300 (epoch 1.460), train_loss = 2.38071836, grad/param norm = 3.6094e-01, time/batch = 0.6689s	
740/25300 (epoch 1.462), train_loss = 1.94356195, grad/param norm = 2.9350e-01, time/batch = 0.6673s	
741/25300 (epoch 1.464), train_loss = 2.24412356, grad/param norm = 3.3582e-01, time/batch = 0.6691s	
742/25300 (epoch 1.466), train_loss = 2.08764925, grad/param norm = 3.2196e-01, time/batch = 0.6686s	
743/25300 (epoch 1.468), train_loss = 2.34062591, grad/param norm = 3.6557e-01, time/batch = 0.6618s	
744/25300 (epoch 1.470), train_loss = 2.09265304, grad/param norm = 3.2890e-01, time/batch = 0.6675s	
745/25300 (epoch 1.472), train_loss = 1.98011437, grad/param norm = 3.3684e-01, time/batch = 0.6613s	
746/25300 (epoch 1.474), train_loss = 2.09521854, grad/param norm = 3.3141e-01, time/batch = 0.6577s	
747/25300 (epoch 1.476), train_loss = 2.25676017, grad/param norm = 3.6303e-01, time/batch = 0.6581s	
748/25300 (epoch 1.478), train_loss = 2.21122621, grad/param norm = 2.9218e-01, time/batch = 0.6575s	
749/25300 (epoch 1.480), train_loss = 1.93380603, grad/param norm = 3.4473e-01, time/batch = 0.6561s	
750/25300 (epoch 1.482), train_loss = 2.23349498, grad/param norm = 3.2229e-01, time/batch = 0.6562s	
751/25300 (epoch 1.484), train_loss = 2.25107102, grad/param norm = 3.0159e-01, time/batch = 0.6589s	
752/25300 (epoch 1.486), train_loss = 2.27646529, grad/param norm = 3.4694e-01, time/batch = 0.6625s	
753/25300 (epoch 1.488), train_loss = 2.19964796, grad/param norm = 3.2893e-01, time/batch = 0.6601s	
754/25300 (epoch 1.490), train_loss = 2.27457014, grad/param norm = 4.0637e-01, time/batch = 0.6572s	
755/25300 (epoch 1.492), train_loss = 2.09003150, grad/param norm = 3.5874e-01, time/batch = 0.6597s	
756/25300 (epoch 1.494), train_loss = 2.03104590, grad/param norm = 2.9652e-01, time/batch = 0.6620s	
757/25300 (epoch 1.496), train_loss = 2.14780828, grad/param norm = 3.4664e-01, time/batch = 0.6599s	
758/25300 (epoch 1.498), train_loss = 1.99333690, grad/param norm = 3.3516e-01, time/batch = 0.6583s	
759/25300 (epoch 1.500), train_loss = 2.25940126, grad/param norm = 3.3063e-01, time/batch = 0.6594s	
760/25300 (epoch 1.502), train_loss = 2.06743439, grad/param norm = 3.1759e-01, time/batch = 0.6584s	
761/25300 (epoch 1.504), train_loss = 2.08760879, grad/param norm = 3.2798e-01, time/batch = 0.6597s	
762/25300 (epoch 1.506), train_loss = 2.22779654, grad/param norm = 4.7256e-01, time/batch = 0.6591s	
763/25300 (epoch 1.508), train_loss = 2.18821737, grad/param norm = 3.9516e-01, time/batch = 0.6624s	
764/25300 (epoch 1.510), train_loss = 2.13091483, grad/param norm = 3.0320e-01, time/batch = 0.6605s	
765/25300 (epoch 1.512), train_loss = 1.90184243, grad/param norm = 2.7582e-01, time/batch = 0.6593s	
766/25300 (epoch 1.514), train_loss = 1.89459195, grad/param norm = 2.5517e-01, time/batch = 0.6624s	
767/25300 (epoch 1.516), train_loss = 2.07298093, grad/param norm = 2.6240e-01, time/batch = 0.6606s	
768/25300 (epoch 1.518), train_loss = 2.27479426, grad/param norm = 3.7546e-01, time/batch = 0.6587s	
769/25300 (epoch 1.520), train_loss = 1.96784266, grad/param norm = 4.3153e-01, time/batch = 0.6595s	
770/25300 (epoch 1.522), train_loss = 2.12355245, grad/param norm = 3.4889e-01, time/batch = 0.6592s	
771/25300 (epoch 1.524), train_loss = 2.05496015, grad/param norm = 3.2117e-01, time/batch = 0.6608s	
772/25300 (epoch 1.526), train_loss = 2.26066985, grad/param norm = 3.8831e-01, time/batch = 0.6605s	
773/25300 (epoch 1.528), train_loss = 2.28086554, grad/param norm = 4.1577e-01, time/batch = 0.6603s	
774/25300 (epoch 1.530), train_loss = 2.01120192, grad/param norm = 3.8822e-01, time/batch = 0.6599s	
775/25300 (epoch 1.532), train_loss = 2.15478203, grad/param norm = 3.5240e-01, time/batch = 0.6611s	
776/25300 (epoch 1.534), train_loss = 2.12742822, grad/param norm = 3.9470e-01, time/batch = 0.6616s	
777/25300 (epoch 1.536), train_loss = 2.03874763, grad/param norm = 3.6026e-01, time/batch = 0.6603s	
778/25300 (epoch 1.538), train_loss = 1.98252997, grad/param norm = 3.1494e-01, time/batch = 0.6586s	
779/25300 (epoch 1.540), train_loss = 2.17140335, grad/param norm = 3.4847e-01, time/batch = 0.6552s	
780/25300 (epoch 1.542), train_loss = 1.96320424, grad/param norm = 3.3516e-01, time/batch = 0.6578s	
781/25300 (epoch 1.543), train_loss = 1.98218135, grad/param norm = 2.7467e-01, time/batch = 0.6624s	
782/25300 (epoch 1.545), train_loss = 2.53924120, grad/param norm = 2.7517e-01, time/batch = 0.6585s	
783/25300 (epoch 1.547), train_loss = 1.93142238, grad/param norm = 2.8256e-01, time/batch = 0.6568s	
784/25300 (epoch 1.549), train_loss = 2.28978727, grad/param norm = 3.2179e-01, time/batch = 0.6593s	
785/25300 (epoch 1.551), train_loss = 2.09748697, grad/param norm = 2.5735e-01, time/batch = 0.6592s	
786/25300 (epoch 1.553), train_loss = 2.18579105, grad/param norm = 2.8891e-01, time/batch = 0.6600s	
787/25300 (epoch 1.555), train_loss = 2.16282779, grad/param norm = 3.2330e-01, time/batch = 0.6586s	
788/25300 (epoch 1.557), train_loss = 2.15665981, grad/param norm = 2.6311e-01, time/batch = 0.6567s	
789/25300 (epoch 1.559), train_loss = 2.21874087, grad/param norm = 3.2556e-01, time/batch = 0.6571s	
790/25300 (epoch 1.561), train_loss = 2.23908633, grad/param norm = 2.7358e-01, time/batch = 0.6606s	
791/25300 (epoch 1.563), train_loss = 2.10004531, grad/param norm = 2.6401e-01, time/batch = 0.6572s	
792/25300 (epoch 1.565), train_loss = 2.06675190, grad/param norm = 3.0044e-01, time/batch = 0.6619s	
793/25300 (epoch 1.567), train_loss = 1.79821634, grad/param norm = 3.1434e-01, time/batch = 0.6651s	
794/25300 (epoch 1.569), train_loss = 2.03059643, grad/param norm = 2.8848e-01, time/batch = 0.6595s	
795/25300 (epoch 1.571), train_loss = 2.14353120, grad/param norm = 2.9280e-01, time/batch = 0.6603s	
796/25300 (epoch 1.573), train_loss = 2.12351242, grad/param norm = 3.1223e-01, time/batch = 0.6642s	
797/25300 (epoch 1.575), train_loss = 2.10596617, grad/param norm = 2.8939e-01, time/batch = 0.6653s	
798/25300 (epoch 1.577), train_loss = 2.22965985, grad/param norm = 3.3118e-01, time/batch = 0.6699s	
799/25300 (epoch 1.579), train_loss = 2.30192421, grad/param norm = 3.1270e-01, time/batch = 0.6642s	
800/25300 (epoch 1.581), train_loss = 2.05080612, grad/param norm = 2.9195e-01, time/batch = 0.6599s	
801/25300 (epoch 1.583), train_loss = 1.97392420, grad/param norm = 2.7402e-01, time/batch = 0.6590s	
802/25300 (epoch 1.585), train_loss = 2.08370589, grad/param norm = 2.4839e-01, time/batch = 0.6602s	
803/25300 (epoch 1.587), train_loss = 2.15114084, grad/param norm = 2.7321e-01, time/batch = 0.6580s	
804/25300 (epoch 1.589), train_loss = 1.95521283, grad/param norm = 2.8054e-01, time/batch = 0.6608s	
805/25300 (epoch 1.591), train_loss = 2.02276649, grad/param norm = 3.0687e-01, time/batch = 0.6672s	
806/25300 (epoch 1.593), train_loss = 1.93257980, grad/param norm = 2.7568e-01, time/batch = 0.6549s	
807/25300 (epoch 1.595), train_loss = 2.12327592, grad/param norm = 3.2239e-01, time/batch = 0.6581s	
808/25300 (epoch 1.597), train_loss = 1.97828294, grad/param norm = 3.6550e-01, time/batch = 0.6590s	
809/25300 (epoch 1.599), train_loss = 1.97142578, grad/param norm = 3.1131e-01, time/batch = 0.6597s	
810/25300 (epoch 1.601), train_loss = 2.22838493, grad/param norm = 3.2406e-01, time/batch = 0.6516s	
811/25300 (epoch 1.603), train_loss = 2.11585966, grad/param norm = 3.0167e-01, time/batch = 0.6582s	
812/25300 (epoch 1.605), train_loss = 2.02472756, grad/param norm = 3.1085e-01, time/batch = 0.6605s	
813/25300 (epoch 1.607), train_loss = 2.06195906, grad/param norm = 3.6970e-01, time/batch = 0.6585s	
814/25300 (epoch 1.609), train_loss = 2.13210694, grad/param norm = 3.4805e-01, time/batch = 0.6590s	
815/25300 (epoch 1.611), train_loss = 2.26364647, grad/param norm = 3.0859e-01, time/batch = 0.6578s	
816/25300 (epoch 1.613), train_loss = 2.06952852, grad/param norm = 3.7833e-01, time/batch = 0.6582s	
817/25300 (epoch 1.615), train_loss = 2.17676280, grad/param norm = 4.3671e-01, time/batch = 0.6576s	
818/25300 (epoch 1.617), train_loss = 2.17530832, grad/param norm = 3.2492e-01, time/batch = 0.6579s	
819/25300 (epoch 1.619), train_loss = 2.08302358, grad/param norm = 3.6885e-01, time/batch = 0.6597s	
820/25300 (epoch 1.621), train_loss = 2.12847126, grad/param norm = 3.9461e-01, time/batch = 0.6606s	
821/25300 (epoch 1.623), train_loss = 2.07972016, grad/param norm = 2.8605e-01, time/batch = 0.6638s	
822/25300 (epoch 1.625), train_loss = 1.89507419, grad/param norm = 2.9191e-01, time/batch = 0.6589s	
823/25300 (epoch 1.626), train_loss = 2.07243369, grad/param norm = 3.3623e-01, time/batch = 0.6579s	
824/25300 (epoch 1.628), train_loss = 2.13146000, grad/param norm = 3.2435e-01, time/batch = 0.6580s	
825/25300 (epoch 1.630), train_loss = 2.08083904, grad/param norm = 2.5799e-01, time/batch = 0.6591s	
826/25300 (epoch 1.632), train_loss = 2.22343202, grad/param norm = 2.9508e-01, time/batch = 0.6585s	
827/25300 (epoch 1.634), train_loss = 2.25431769, grad/param norm = 2.8074e-01, time/batch = 0.6579s	
828/25300 (epoch 1.636), train_loss = 2.17877804, grad/param norm = 2.6926e-01, time/batch = 0.6589s	
829/25300 (epoch 1.638), train_loss = 2.17944271, grad/param norm = 3.3480e-01, time/batch = 0.6566s	
830/25300 (epoch 1.640), train_loss = 2.23279704, grad/param norm = 3.3999e-01, time/batch = 0.6579s	
831/25300 (epoch 1.642), train_loss = 2.11813902, grad/param norm = 2.7895e-01, time/batch = 0.6617s	
832/25300 (epoch 1.644), train_loss = 2.25686198, grad/param norm = 2.7691e-01, time/batch = 0.6587s	
833/25300 (epoch 1.646), train_loss = 2.15780660, grad/param norm = 2.9755e-01, time/batch = 0.6591s	
834/25300 (epoch 1.648), train_loss = 2.20823139, grad/param norm = 3.3097e-01, time/batch = 0.6597s	
835/25300 (epoch 1.650), train_loss = 2.20147654, grad/param norm = 3.1542e-01, time/batch = 0.6599s	
836/25300 (epoch 1.652), train_loss = 2.26518643, grad/param norm = 2.7825e-01, time/batch = 0.6600s	
837/25300 (epoch 1.654), train_loss = 2.30293740, grad/param norm = 2.9695e-01, time/batch = 0.6575s	
838/25300 (epoch 1.656), train_loss = 2.29282464, grad/param norm = 2.7569e-01, time/batch = 0.6571s	
839/25300 (epoch 1.658), train_loss = 2.06420747, grad/param norm = 2.8728e-01, time/batch = 0.6575s	
840/25300 (epoch 1.660), train_loss = 1.94889710, grad/param norm = 2.9629e-01, time/batch = 0.6538s	
841/25300 (epoch 1.662), train_loss = 1.84064943, grad/param norm = 3.7832e-01, time/batch = 0.6616s	
842/25300 (epoch 1.664), train_loss = 1.89963744, grad/param norm = 3.7559e-01, time/batch = 0.6635s	
843/25300 (epoch 1.666), train_loss = 1.90196142, grad/param norm = 3.3972e-01, time/batch = 0.6600s	
844/25300 (epoch 1.668), train_loss = 2.04674003, grad/param norm = 3.6566e-01, time/batch = 0.6582s	
845/25300 (epoch 1.670), train_loss = 2.06240524, grad/param norm = 2.8252e-01, time/batch = 0.6578s	
846/25300 (epoch 1.672), train_loss = 2.04425281, grad/param norm = 2.7490e-01, time/batch = 0.6598s	
847/25300 (epoch 1.674), train_loss = 2.06311575, grad/param norm = 2.3375e-01, time/batch = 0.6595s	
848/25300 (epoch 1.676), train_loss = 2.12717520, grad/param norm = 2.6970e-01, time/batch = 0.6609s	
849/25300 (epoch 1.678), train_loss = 2.16781778, grad/param norm = 3.0214e-01, time/batch = 0.6601s	
850/25300 (epoch 1.680), train_loss = 1.97202063, grad/param norm = 3.4694e-01, time/batch = 0.6587s	
851/25300 (epoch 1.682), train_loss = 1.78998409, grad/param norm = 2.6979e-01, time/batch = 0.6589s	
852/25300 (epoch 1.684), train_loss = 1.88148069, grad/param norm = 2.7322e-01, time/batch = 0.6593s	
853/25300 (epoch 1.686), train_loss = 1.99640949, grad/param norm = 3.0874e-01, time/batch = 0.6656s	
854/25300 (epoch 1.688), train_loss = 2.18919595, grad/param norm = 3.7217e-01, time/batch = 0.6696s	
855/25300 (epoch 1.690), train_loss = 2.06721744, grad/param norm = 2.6076e-01, time/batch = 0.6669s	
856/25300 (epoch 1.692), train_loss = 2.07047355, grad/param norm = 2.8258e-01, time/batch = 0.6651s	
857/25300 (epoch 1.694), train_loss = 1.95398426, grad/param norm = 2.8288e-01, time/batch = 0.6599s	
858/25300 (epoch 1.696), train_loss = 2.05290456, grad/param norm = 2.7622e-01, time/batch = 0.6609s	
859/25300 (epoch 1.698), train_loss = 2.03624269, grad/param norm = 2.5736e-01, time/batch = 0.6619s	
860/25300 (epoch 1.700), train_loss = 1.82211977, grad/param norm = 3.1150e-01, time/batch = 0.6574s	
861/25300 (epoch 1.702), train_loss = 2.24851226, grad/param norm = 3.5934e-01, time/batch = 0.6585s	
862/25300 (epoch 1.704), train_loss = 1.84877172, grad/param norm = 2.7276e-01, time/batch = 0.6571s	
863/25300 (epoch 1.706), train_loss = 2.04332691, grad/param norm = 3.0437e-01, time/batch = 0.6586s	
864/25300 (epoch 1.708), train_loss = 1.75054490, grad/param norm = 2.9168e-01, time/batch = 0.6595s	
865/25300 (epoch 1.709), train_loss = 2.15069532, grad/param norm = 3.0474e-01, time/batch = 0.6566s	
866/25300 (epoch 1.711), train_loss = 2.17795133, grad/param norm = 3.4560e-01, time/batch = 0.6590s	
867/25300 (epoch 1.713), train_loss = 2.05561561, grad/param norm = 4.1092e-01, time/batch = 0.6587s	
868/25300 (epoch 1.715), train_loss = 1.98349353, grad/param norm = 4.7292e-01, time/batch = 0.6570s	
869/25300 (epoch 1.717), train_loss = 2.20297022, grad/param norm = 4.4465e-01, time/batch = 0.6522s	
870/25300 (epoch 1.719), train_loss = 2.04127610, grad/param norm = 4.3007e-01, time/batch = 0.6511s	
871/25300 (epoch 1.721), train_loss = 1.93221270, grad/param norm = 3.4151e-01, time/batch = 0.6559s	
872/25300 (epoch 1.723), train_loss = 1.85296045, grad/param norm = 3.2542e-01, time/batch = 0.6565s	
873/25300 (epoch 1.725), train_loss = 2.04842456, grad/param norm = 3.4106e-01, time/batch = 0.6609s	
874/25300 (epoch 1.727), train_loss = 1.97216458, grad/param norm = 3.7488e-01, time/batch = 0.6576s	
875/25300 (epoch 1.729), train_loss = 1.93656328, grad/param norm = 3.5943e-01, time/batch = 0.6590s	
876/25300 (epoch 1.731), train_loss = 2.15759278, grad/param norm = 3.1252e-01, time/batch = 0.6603s	
877/25300 (epoch 1.733), train_loss = 1.82288964, grad/param norm = 2.2232e-01, time/batch = 0.6587s	
878/25300 (epoch 1.735), train_loss = 2.24104765, grad/param norm = 2.4840e-01, time/batch = 0.6539s	
879/25300 (epoch 1.737), train_loss = 1.94126374, grad/param norm = 2.7075e-01, time/batch = 0.6552s	
880/25300 (epoch 1.739), train_loss = 2.01344277, grad/param norm = 3.0363e-01, time/batch = 0.6554s	
881/25300 (epoch 1.741), train_loss = 2.04670053, grad/param norm = 3.5381e-01, time/batch = 0.6594s	
882/25300 (epoch 1.743), train_loss = 1.97916280, grad/param norm = 3.3132e-01, time/batch = 0.6613s	
883/25300 (epoch 1.745), train_loss = 1.87419966, grad/param norm = 2.4986e-01, time/batch = 0.6574s	
884/25300 (epoch 1.747), train_loss = 1.95933995, grad/param norm = 2.4668e-01, time/batch = 0.6575s	
885/25300 (epoch 1.749), train_loss = 2.01663529, grad/param norm = 2.4552e-01, time/batch = 0.6585s	
886/25300 (epoch 1.751), train_loss = 2.06095384, grad/param norm = 2.4525e-01, time/batch = 0.6610s	
887/25300 (epoch 1.753), train_loss = 1.97740347, grad/param norm = 2.2569e-01, time/batch = 0.6660s	
888/25300 (epoch 1.755), train_loss = 2.15026941, grad/param norm = 2.8420e-01, time/batch = 0.6679s	
889/25300 (epoch 1.757), train_loss = 1.97293286, grad/param norm = 3.4962e-01, time/batch = 0.6671s	
890/25300 (epoch 1.759), train_loss = 1.91744547, grad/param norm = 3.4930e-01, time/batch = 0.6611s	
891/25300 (epoch 1.761), train_loss = 2.06670356, grad/param norm = 3.2591e-01, time/batch = 0.6643s	
892/25300 (epoch 1.763), train_loss = 1.98216783, grad/param norm = 4.8584e-01, time/batch = 0.6703s	
893/25300 (epoch 1.765), train_loss = 2.05209394, grad/param norm = 4.4934e-01, time/batch = 0.6712s	
894/25300 (epoch 1.767), train_loss = 1.96383845, grad/param norm = 3.3159e-01, time/batch = 0.6755s	
895/25300 (epoch 1.769), train_loss = 1.99207591, grad/param norm = 3.0409e-01, time/batch = 0.6696s	
896/25300 (epoch 1.771), train_loss = 2.33952014, grad/param norm = 2.8367e-01, time/batch = 0.6650s	
897/25300 (epoch 1.773), train_loss = 2.11613360, grad/param norm = 2.9173e-01, time/batch = 0.6630s	
898/25300 (epoch 1.775), train_loss = 1.98041146, grad/param norm = 3.0684e-01, time/batch = 0.6689s	
899/25300 (epoch 1.777), train_loss = 2.10403693, grad/param norm = 2.8452e-01, time/batch = 0.6578s	
900/25300 (epoch 1.779), train_loss = 2.09479770, grad/param norm = 2.6472e-01, time/batch = 0.6593s	
901/25300 (epoch 1.781), train_loss = 1.87288169, grad/param norm = 2.6831e-01, time/batch = 0.6650s	
902/25300 (epoch 1.783), train_loss = 2.11877990, grad/param norm = 3.0261e-01, time/batch = 0.6583s	
903/25300 (epoch 1.785), train_loss = 2.03933421, grad/param norm = 3.0496e-01, time/batch = 0.6590s	
904/25300 (epoch 1.787), train_loss = 2.21137959, grad/param norm = 2.9466e-01, time/batch = 0.6593s	
905/25300 (epoch 1.789), train_loss = 2.20042220, grad/param norm = 2.5779e-01, time/batch = 0.6586s	
906/25300 (epoch 1.791), train_loss = 2.03408275, grad/param norm = 2.4287e-01, time/batch = 0.6594s	
907/25300 (epoch 1.792), train_loss = 2.02116855, grad/param norm = 2.3143e-01, time/batch = 0.6567s	
908/25300 (epoch 1.794), train_loss = 2.18360981, grad/param norm = 2.4784e-01, time/batch = 0.6573s	
909/25300 (epoch 1.796), train_loss = 1.88814456, grad/param norm = 2.3940e-01, time/batch = 0.6614s	
910/25300 (epoch 1.798), train_loss = 2.16299804, grad/param norm = 2.5939e-01, time/batch = 0.6587s	
911/25300 (epoch 1.800), train_loss = 2.06346741, grad/param norm = 2.9301e-01, time/batch = 0.6585s	
912/25300 (epoch 1.802), train_loss = 1.72299074, grad/param norm = 2.6595e-01, time/batch = 0.6585s	
913/25300 (epoch 1.804), train_loss = 2.04844151, grad/param norm = 2.7395e-01, time/batch = 0.6588s	
914/25300 (epoch 1.806), train_loss = 2.10748960, grad/param norm = 2.7920e-01, time/batch = 0.6574s	
915/25300 (epoch 1.808), train_loss = 1.93258063, grad/param norm = 2.5096e-01, time/batch = 0.6587s	
916/25300 (epoch 1.810), train_loss = 1.89814568, grad/param norm = 2.9049e-01, time/batch = 0.6554s	
917/25300 (epoch 1.812), train_loss = 2.00608505, grad/param norm = 2.5690e-01, time/batch = 0.6599s	
918/25300 (epoch 1.814), train_loss = 2.25199009, grad/param norm = 2.7586e-01, time/batch = 0.6566s	
919/25300 (epoch 1.816), train_loss = 2.19680869, grad/param norm = 3.1810e-01, time/batch = 0.6555s	
920/25300 (epoch 1.818), train_loss = 2.17502634, grad/param norm = 2.9058e-01, time/batch = 0.6567s	
921/25300 (epoch 1.820), train_loss = 2.08471453, grad/param norm = 2.8052e-01, time/batch = 0.6605s	
922/25300 (epoch 1.822), train_loss = 1.93707346, grad/param norm = 2.4203e-01, time/batch = 0.6545s	
923/25300 (epoch 1.824), train_loss = 2.07048886, grad/param norm = 2.5164e-01, time/batch = 0.6593s	
924/25300 (epoch 1.826), train_loss = 1.93685812, grad/param norm = 3.3654e-01, time/batch = 0.6625s	
925/25300 (epoch 1.828), train_loss = 1.95135611, grad/param norm = 3.5716e-01, time/batch = 0.6611s	
926/25300 (epoch 1.830), train_loss = 1.95682037, grad/param norm = 2.9730e-01, time/batch = 0.6571s	
927/25300 (epoch 1.832), train_loss = 1.92234820, grad/param norm = 2.7637e-01, time/batch = 0.6552s	
928/25300 (epoch 1.834), train_loss = 1.85673572, grad/param norm = 3.0800e-01, time/batch = 0.6569s	
929/25300 (epoch 1.836), train_loss = 2.00268961, grad/param norm = 3.1986e-01, time/batch = 0.6566s	
930/25300 (epoch 1.838), train_loss = 2.01839409, grad/param norm = 3.2688e-01, time/batch = 0.6600s	
931/25300 (epoch 1.840), train_loss = 2.07369065, grad/param norm = 2.7695e-01, time/batch = 0.6602s	
932/25300 (epoch 1.842), train_loss = 2.16984462, grad/param norm = 2.9548e-01, time/batch = 0.6629s	
933/25300 (epoch 1.844), train_loss = 1.99836394, grad/param norm = 2.9865e-01, time/batch = 0.6649s	
934/25300 (epoch 1.846), train_loss = 1.84226976, grad/param norm = 2.6895e-01, time/batch = 0.6613s	
935/25300 (epoch 1.848), train_loss = 2.11953791, grad/param norm = 3.0835e-01, time/batch = 0.6568s	
936/25300 (epoch 1.850), train_loss = 2.03195316, grad/param norm = 2.9031e-01, time/batch = 0.6540s	
937/25300 (epoch 1.852), train_loss = 1.97502576, grad/param norm = 2.8680e-01, time/batch = 0.6575s	
938/25300 (epoch 1.854), train_loss = 2.22667250, grad/param norm = 2.7982e-01, time/batch = 0.6585s	
939/25300 (epoch 1.856), train_loss = 1.97990463, grad/param norm = 2.6527e-01, time/batch = 0.6570s	
940/25300 (epoch 1.858), train_loss = 2.01725188, grad/param norm = 2.4830e-01, time/batch = 0.6563s	
941/25300 (epoch 1.860), train_loss = 1.75504362, grad/param norm = 2.4142e-01, time/batch = 0.6632s	
942/25300 (epoch 1.862), train_loss = 2.09216670, grad/param norm = 2.8203e-01, time/batch = 0.6570s	
943/25300 (epoch 1.864), train_loss = 2.10179904, grad/param norm = 2.7631e-01, time/batch = 0.6558s	
944/25300 (epoch 1.866), train_loss = 2.08250682, grad/param norm = 3.0410e-01, time/batch = 0.6588s	
945/25300 (epoch 1.868), train_loss = 2.10724944, grad/param norm = 3.1445e-01, time/batch = 0.6581s	
946/25300 (epoch 1.870), train_loss = 2.04768828, grad/param norm = 2.6809e-01, time/batch = 0.6606s	
947/25300 (epoch 1.872), train_loss = 1.94359327, grad/param norm = 2.5137e-01, time/batch = 0.6605s	
948/25300 (epoch 1.874), train_loss = 2.04803322, grad/param norm = 2.9893e-01, time/batch = 0.6580s	
949/25300 (epoch 1.875), train_loss = 2.08335840, grad/param norm = 3.6095e-01, time/batch = 0.6556s	
950/25300 (epoch 1.877), train_loss = 1.92172849, grad/param norm = 2.7899e-01, time/batch = 0.6591s	
951/25300 (epoch 1.879), train_loss = 2.12366531, grad/param norm = 2.6064e-01, time/batch = 0.6575s	
952/25300 (epoch 1.881), train_loss = 2.26392481, grad/param norm = 2.3198e-01, time/batch = 0.6586s	
953/25300 (epoch 1.883), train_loss = 2.20666426, grad/param norm = 2.6221e-01, time/batch = 0.6598s	
954/25300 (epoch 1.885), train_loss = 2.05485846, grad/param norm = 2.8969e-01, time/batch = 0.6585s	
955/25300 (epoch 1.887), train_loss = 1.94694907, grad/param norm = 2.5235e-01, time/batch = 0.6598s	
956/25300 (epoch 1.889), train_loss = 2.23472915, grad/param norm = 3.5516e-01, time/batch = 0.6584s	
957/25300 (epoch 1.891), train_loss = 2.26912066, grad/param norm = 2.9407e-01, time/batch = 0.6563s	
958/25300 (epoch 1.893), train_loss = 2.28950446, grad/param norm = 2.6639e-01, time/batch = 0.6570s	
959/25300 (epoch 1.895), train_loss = 1.68511548, grad/param norm = 2.9706e-01, time/batch = 0.6569s	
960/25300 (epoch 1.897), train_loss = 1.97738590, grad/param norm = 2.9603e-01, time/batch = 0.6562s	
961/25300 (epoch 1.899), train_loss = 2.00615916, grad/param norm = 2.6511e-01, time/batch = 0.6582s	
962/25300 (epoch 1.901), train_loss = 2.15063313, grad/param norm = 3.1369e-01, time/batch = 0.6567s	
963/25300 (epoch 1.903), train_loss = 1.87526929, grad/param norm = 3.9223e-01, time/batch = 0.6580s	
964/25300 (epoch 1.905), train_loss = 1.96866771, grad/param norm = 4.2001e-01, time/batch = 0.6583s	
965/25300 (epoch 1.907), train_loss = 2.28772436, grad/param norm = 3.6785e-01, time/batch = 0.6606s	
966/25300 (epoch 1.909), train_loss = 2.05230870, grad/param norm = 3.0788e-01, time/batch = 0.6573s	
967/25300 (epoch 1.911), train_loss = 2.15733298, grad/param norm = 2.5230e-01, time/batch = 0.6530s	
968/25300 (epoch 1.913), train_loss = 2.06259818, grad/param norm = 2.4047e-01, time/batch = 0.6561s	
969/25300 (epoch 1.915), train_loss = 2.03697212, grad/param norm = 2.8466e-01, time/batch = 0.6562s	
970/25300 (epoch 1.917), train_loss = 2.08269918, grad/param norm = 2.5383e-01, time/batch = 0.6561s	
971/25300 (epoch 1.919), train_loss = 2.06567606, grad/param norm = 2.4112e-01, time/batch = 0.6607s	
972/25300 (epoch 1.921), train_loss = 1.89936696, grad/param norm = 3.1204e-01, time/batch = 0.6604s	
973/25300 (epoch 1.923), train_loss = 2.06196052, grad/param norm = 2.7521e-01, time/batch = 0.6574s	
974/25300 (epoch 1.925), train_loss = 2.10011440, grad/param norm = 2.4596e-01, time/batch = 0.6553s	
975/25300 (epoch 1.927), train_loss = 2.01615161, grad/param norm = 2.9008e-01, time/batch = 0.6585s	
976/25300 (epoch 1.929), train_loss = 1.81181777, grad/param norm = 3.5029e-01, time/batch = 0.6580s	
977/25300 (epoch 1.931), train_loss = 2.09871496, grad/param norm = 3.1379e-01, time/batch = 0.6656s	
978/25300 (epoch 1.933), train_loss = 2.08198461, grad/param norm = 2.8467e-01, time/batch = 0.6703s	
979/25300 (epoch 1.935), train_loss = 1.93037726, grad/param norm = 2.4840e-01, time/batch = 0.6767s	
980/25300 (epoch 1.937), train_loss = 1.74133027, grad/param norm = 2.1577e-01, time/batch = 0.6586s	
981/25300 (epoch 1.939), train_loss = 2.17400484, grad/param norm = 2.7849e-01, time/batch = 0.6574s	
982/25300 (epoch 1.941), train_loss = 1.88029024, grad/param norm = 2.8255e-01, time/batch = 0.6556s	
983/25300 (epoch 1.943), train_loss = 1.82339400, grad/param norm = 2.7310e-01, time/batch = 0.6563s	
984/25300 (epoch 1.945), train_loss = 1.95920597, grad/param norm = 2.5467e-01, time/batch = 0.6593s	
985/25300 (epoch 1.947), train_loss = 2.00752833, grad/param norm = 2.5140e-01, time/batch = 0.6614s	
986/25300 (epoch 1.949), train_loss = 2.08970476, grad/param norm = 2.9104e-01, time/batch = 0.6683s	
987/25300 (epoch 1.951), train_loss = 2.01681001, grad/param norm = 2.7581e-01, time/batch = 0.6631s	
988/25300 (epoch 1.953), train_loss = 2.16380095, grad/param norm = 2.5320e-01, time/batch = 0.6595s	
989/25300 (epoch 1.955), train_loss = 2.23036558, grad/param norm = 2.9201e-01, time/batch = 0.6654s	
990/25300 (epoch 1.957), train_loss = 2.07314921, grad/param norm = 3.7717e-01, time/batch = 0.6589s	
991/25300 (epoch 1.958), train_loss = 2.09713494, grad/param norm = 3.1843e-01, time/batch = 0.6587s	
992/25300 (epoch 1.960), train_loss = 2.16132621, grad/param norm = 3.3567e-01, time/batch = 0.6591s	
993/25300 (epoch 1.962), train_loss = 2.00463633, grad/param norm = 3.1900e-01, time/batch = 0.6595s	
994/25300 (epoch 1.964), train_loss = 1.96925323, grad/param norm = 2.7295e-01, time/batch = 0.6649s	
995/25300 (epoch 1.966), train_loss = 1.84426791, grad/param norm = 2.7184e-01, time/batch = 0.6617s	
996/25300 (epoch 1.968), train_loss = 1.79071268, grad/param norm = 3.2791e-01, time/batch = 0.6596s	
997/25300 (epoch 1.970), train_loss = 2.07226350, grad/param norm = 2.9609e-01, time/batch = 0.6643s	
998/25300 (epoch 1.972), train_loss = 1.99270941, grad/param norm = 2.6501e-01, time/batch = 0.6665s	
999/25300 (epoch 1.974), train_loss = 2.17721434, grad/param norm = 2.7602e-01, time/batch = 0.6627s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch1.98_1.9614.t7	
1000/25300 (epoch 1.976), train_loss = 2.04869366, grad/param norm = 2.6747e-01, time/batch = 0.6589s	
1001/25300 (epoch 1.978), train_loss = 2.14777117, grad/param norm = 2.7151e-01, time/batch = 0.6655s	
1002/25300 (epoch 1.980), train_loss = 2.08615525, grad/param norm = 2.5364e-01, time/batch = 0.6578s	
1003/25300 (epoch 1.982), train_loss = 2.06265400, grad/param norm = 2.8247e-01, time/batch = 0.6605s	
1004/25300 (epoch 1.984), train_loss = 2.03144698, grad/param norm = 2.6808e-01, time/batch = 0.6618s	
1005/25300 (epoch 1.986), train_loss = 1.91204126, grad/param norm = 2.8593e-01, time/batch = 0.6577s	
1006/25300 (epoch 1.988), train_loss = 1.97808567, grad/param norm = 3.1302e-01, time/batch = 0.6576s	
1007/25300 (epoch 1.990), train_loss = 1.93366760, grad/param norm = 2.7705e-01, time/batch = 0.6653s	
1008/25300 (epoch 1.992), train_loss = 1.68434547, grad/param norm = 2.7151e-01, time/batch = 0.6615s	
1009/25300 (epoch 1.994), train_loss = 2.07490412, grad/param norm = 2.7586e-01, time/batch = 0.6651s	
1010/25300 (epoch 1.996), train_loss = 2.10138683, grad/param norm = 2.7921e-01, time/batch = 0.6635s	
1011/25300 (epoch 1.998), train_loss = 2.02759939, grad/param norm = 2.7492e-01, time/batch = 0.6591s	
1012/25300 (epoch 2.000), train_loss = 2.01578216, grad/param norm = 3.2137e-01, time/batch = 0.6632s	
1013/25300 (epoch 2.002), train_loss = 1.85919572, grad/param norm = 3.4457e-01, time/batch = 0.6587s	
1014/25300 (epoch 2.004), train_loss = 1.85851958, grad/param norm = 2.4150e-01, time/batch = 0.6577s	
1015/25300 (epoch 2.006), train_loss = 1.92144934, grad/param norm = 2.5035e-01, time/batch = 0.6575s	
1016/25300 (epoch 2.008), train_loss = 1.99204421, grad/param norm = 2.4964e-01, time/batch = 0.6567s	
1017/25300 (epoch 2.010), train_loss = 1.99170974, grad/param norm = 2.5047e-01, time/batch = 0.6578s	
1018/25300 (epoch 2.012), train_loss = 1.82503511, grad/param norm = 3.0537e-01, time/batch = 0.6558s	
1019/25300 (epoch 2.014), train_loss = 1.97267496, grad/param norm = 2.6219e-01, time/batch = 0.6527s	
1020/25300 (epoch 2.016), train_loss = 2.02622654, grad/param norm = 2.4875e-01, time/batch = 0.6538s	
1021/25300 (epoch 2.018), train_loss = 1.92142554, grad/param norm = 2.4042e-01, time/batch = 0.6622s	
1022/25300 (epoch 2.020), train_loss = 1.93990669, grad/param norm = 2.6540e-01, time/batch = 0.6548s	
1023/25300 (epoch 2.022), train_loss = 1.93672705, grad/param norm = 2.6458e-01, time/batch = 0.6568s	
1024/25300 (epoch 2.024), train_loss = 1.63864696, grad/param norm = 2.6003e-01, time/batch = 0.6605s	
1025/25300 (epoch 2.026), train_loss = 1.93516417, grad/param norm = 2.9177e-01, time/batch = 0.6546s	
1026/25300 (epoch 2.028), train_loss = 1.76392774, grad/param norm = 2.4437e-01, time/batch = 0.6582s	
1027/25300 (epoch 2.030), train_loss = 2.04467904, grad/param norm = 2.5493e-01, time/batch = 0.6560s	
1028/25300 (epoch 2.032), train_loss = 1.88049638, grad/param norm = 2.4404e-01, time/batch = 0.6548s	
1029/25300 (epoch 2.034), train_loss = 1.68506331, grad/param norm = 2.5040e-01, time/batch = 0.6555s	
1030/25300 (epoch 2.036), train_loss = 1.74447617, grad/param norm = 2.7386e-01, time/batch = 0.6544s	
1031/25300 (epoch 2.038), train_loss = 1.75227480, grad/param norm = 3.0899e-01, time/batch = 0.6570s	
1032/25300 (epoch 2.040), train_loss = 2.02827473, grad/param norm = 2.3686e-01, time/batch = 0.6560s	
1033/25300 (epoch 2.042), train_loss = 1.78251024, grad/param norm = 2.9447e-01, time/batch = 0.6620s	
1034/25300 (epoch 2.043), train_loss = 1.67114892, grad/param norm = 2.2890e-01, time/batch = 0.6562s	
1035/25300 (epoch 2.045), train_loss = 1.67522152, grad/param norm = 2.5064e-01, time/batch = 0.6575s	
1036/25300 (epoch 2.047), train_loss = 2.05547054, grad/param norm = 2.7599e-01, time/batch = 0.6557s	
1037/25300 (epoch 2.049), train_loss = 1.90486820, grad/param norm = 2.7766e-01, time/batch = 0.6576s	
1038/25300 (epoch 2.051), train_loss = 2.04689177, grad/param norm = 3.1824e-01, time/batch = 0.6579s	
1039/25300 (epoch 2.053), train_loss = 1.71696961, grad/param norm = 2.5140e-01, time/batch = 0.6589s	
1040/25300 (epoch 2.055), train_loss = 1.71267658, grad/param norm = 2.5887e-01, time/batch = 0.6641s	
1041/25300 (epoch 2.057), train_loss = 1.70564550, grad/param norm = 2.3424e-01, time/batch = 0.6613s	
1042/25300 (epoch 2.059), train_loss = 1.98883649, grad/param norm = 2.8310e-01, time/batch = 0.6580s	
1043/25300 (epoch 2.061), train_loss = 1.82351047, grad/param norm = 2.8683e-01, time/batch = 0.6572s	
1044/25300 (epoch 2.063), train_loss = 1.96551788, grad/param norm = 3.0341e-01, time/batch = 0.6553s	
1045/25300 (epoch 2.065), train_loss = 2.11482310, grad/param norm = 3.0369e-01, time/batch = 0.6566s	
1046/25300 (epoch 2.067), train_loss = 1.96365253, grad/param norm = 2.8284e-01, time/batch = 0.6606s	
1047/25300 (epoch 2.069), train_loss = 2.02139228, grad/param norm = 3.6309e-01, time/batch = 0.6588s	
1048/25300 (epoch 2.071), train_loss = 2.08892251, grad/param norm = 4.3998e-01, time/batch = 0.6583s	
1049/25300 (epoch 2.073), train_loss = 1.97534074, grad/param norm = 3.5166e-01, time/batch = 0.6594s	
1050/25300 (epoch 2.075), train_loss = 1.81460702, grad/param norm = 2.3673e-01, time/batch = 0.6596s	
1051/25300 (epoch 2.077), train_loss = 2.02154825, grad/param norm = 2.6693e-01, time/batch = 0.6589s	
1052/25300 (epoch 2.079), train_loss = 2.01456205, grad/param norm = 2.7844e-01, time/batch = 0.6561s	
1053/25300 (epoch 2.081), train_loss = 1.93596832, grad/param norm = 2.4462e-01, time/batch = 0.6560s	
1054/25300 (epoch 2.083), train_loss = 1.77633164, grad/param norm = 2.6333e-01, time/batch = 0.6594s	
1055/25300 (epoch 2.085), train_loss = 2.10608952, grad/param norm = 2.5555e-01, time/batch = 0.6629s	
1056/25300 (epoch 2.087), train_loss = 1.93860848, grad/param norm = 2.4700e-01, time/batch = 0.6608s	
1057/25300 (epoch 2.089), train_loss = 1.82756294, grad/param norm = 2.4602e-01, time/batch = 0.6586s	
1058/25300 (epoch 2.091), train_loss = 1.89835763, grad/param norm = 2.3909e-01, time/batch = 0.6598s	
1059/25300 (epoch 2.093), train_loss = 2.12515039, grad/param norm = 2.4694e-01, time/batch = 0.6587s	
1060/25300 (epoch 2.095), train_loss = 1.94281759, grad/param norm = 2.3741e-01, time/batch = 0.6623s	
1061/25300 (epoch 2.097), train_loss = 1.85773356, grad/param norm = 2.2172e-01, time/batch = 0.6692s	
1062/25300 (epoch 2.099), train_loss = 1.90214250, grad/param norm = 2.5845e-01, time/batch = 0.6692s	
1063/25300 (epoch 2.101), train_loss = 1.83556029, grad/param norm = 2.6780e-01, time/batch = 0.6650s	
1064/25300 (epoch 2.103), train_loss = 1.87483747, grad/param norm = 2.3520e-01, time/batch = 0.6594s	
1065/25300 (epoch 2.105), train_loss = 2.01290684, grad/param norm = 2.6435e-01, time/batch = 0.6602s	
1066/25300 (epoch 2.107), train_loss = 2.02325016, grad/param norm = 2.5151e-01, time/batch = 0.6595s	
1067/25300 (epoch 2.109), train_loss = 2.01639985, grad/param norm = 3.3615e-01, time/batch = 0.6800s	
1068/25300 (epoch 2.111), train_loss = 1.84792094, grad/param norm = 2.8849e-01, time/batch = 0.6679s	
1069/25300 (epoch 2.113), train_loss = 1.95467007, grad/param norm = 2.6583e-01, time/batch = 0.6620s	
1070/25300 (epoch 2.115), train_loss = 1.89270405, grad/param norm = 2.4494e-01, time/batch = 0.6656s	
1071/25300 (epoch 2.117), train_loss = 1.97940467, grad/param norm = 2.7844e-01, time/batch = 0.6659s	
1072/25300 (epoch 2.119), train_loss = 1.92932257, grad/param norm = 2.9079e-01, time/batch = 0.6682s	
1073/25300 (epoch 2.121), train_loss = 2.09749441, grad/param norm = 2.6044e-01, time/batch = 0.6854s	
1074/25300 (epoch 2.123), train_loss = 1.90284458, grad/param norm = 2.6570e-01, time/batch = 0.6717s	
1075/25300 (epoch 2.125), train_loss = 1.96393776, grad/param norm = 3.1883e-01, time/batch = 0.6692s	
1076/25300 (epoch 2.126), train_loss = 1.86481565, grad/param norm = 2.8619e-01, time/batch = 0.6715s	
1077/25300 (epoch 2.128), train_loss = 1.94203720, grad/param norm = 2.7642e-01, time/batch = 0.6618s	
1078/25300 (epoch 2.130), train_loss = 1.59928762, grad/param norm = 2.5484e-01, time/batch = 0.6703s	
1079/25300 (epoch 2.132), train_loss = 1.80718365, grad/param norm = 2.3728e-01, time/batch = 0.6596s	
1080/25300 (epoch 2.134), train_loss = 1.59789845, grad/param norm = 2.3123e-01, time/batch = 0.6615s	
1081/25300 (epoch 2.136), train_loss = 1.96058626, grad/param norm = 2.5933e-01, time/batch = 0.6640s	
1082/25300 (epoch 2.138), train_loss = 1.75828631, grad/param norm = 2.5967e-01, time/batch = 0.6585s	
1083/25300 (epoch 2.140), train_loss = 1.72769790, grad/param norm = 2.2370e-01, time/batch = 0.6569s	
1084/25300 (epoch 2.142), train_loss = 1.96066276, grad/param norm = 2.5605e-01, time/batch = 0.6586s	
1085/25300 (epoch 2.144), train_loss = 1.81618104, grad/param norm = 2.4903e-01, time/batch = 0.6555s	
1086/25300 (epoch 2.146), train_loss = 2.01535106, grad/param norm = 3.1569e-01, time/batch = 0.6588s	
1087/25300 (epoch 2.148), train_loss = 2.06800276, grad/param norm = 3.1834e-01, time/batch = 0.6590s	
1088/25300 (epoch 2.150), train_loss = 2.01634013, grad/param norm = 2.7437e-01, time/batch = 0.6641s	
1089/25300 (epoch 2.152), train_loss = 2.15688892, grad/param norm = 2.5889e-01, time/batch = 0.6623s	
1090/25300 (epoch 2.154), train_loss = 1.86417791, grad/param norm = 2.4550e-01, time/batch = 0.6613s	
1091/25300 (epoch 2.156), train_loss = 1.98703321, grad/param norm = 2.5220e-01, time/batch = 0.6625s	
1092/25300 (epoch 2.158), train_loss = 1.94491995, grad/param norm = 2.7433e-01, time/batch = 0.6598s	
1093/25300 (epoch 2.160), train_loss = 1.93597571, grad/param norm = 3.6952e-01, time/batch = 0.6599s	
1094/25300 (epoch 2.162), train_loss = 1.85043244, grad/param norm = 3.3429e-01, time/batch = 0.6577s	
1095/25300 (epoch 2.164), train_loss = 1.95453380, grad/param norm = 2.5988e-01, time/batch = 0.6556s	
1096/25300 (epoch 2.166), train_loss = 1.99405278, grad/param norm = 3.0193e-01, time/batch = 0.6560s	
1097/25300 (epoch 2.168), train_loss = 1.75892673, grad/param norm = 3.2339e-01, time/batch = 0.6575s	
1098/25300 (epoch 2.170), train_loss = 1.83534385, grad/param norm = 3.2296e-01, time/batch = 0.6571s	
1099/25300 (epoch 2.172), train_loss = 1.82414868, grad/param norm = 3.5428e-01, time/batch = 0.6593s	
1100/25300 (epoch 2.174), train_loss = 1.78747666, grad/param norm = 3.3911e-01, time/batch = 0.6596s	
1101/25300 (epoch 2.176), train_loss = 1.98246521, grad/param norm = 2.9524e-01, time/batch = 0.6605s	
1102/25300 (epoch 2.178), train_loss = 2.12853766, grad/param norm = 2.9720e-01, time/batch = 0.6597s	
1103/25300 (epoch 2.180), train_loss = 1.75230397, grad/param norm = 2.4939e-01, time/batch = 0.6567s	
1104/25300 (epoch 2.182), train_loss = 1.92052895, grad/param norm = 2.3481e-01, time/batch = 0.6588s	
1105/25300 (epoch 2.184), train_loss = 1.92356068, grad/param norm = 2.3678e-01, time/batch = 0.6538s	
1106/25300 (epoch 2.186), train_loss = 1.98687563, grad/param norm = 2.8931e-01, time/batch = 0.6595s	
1107/25300 (epoch 2.188), train_loss = 1.82308437, grad/param norm = 2.8481e-01, time/batch = 0.6563s	
1108/25300 (epoch 2.190), train_loss = 1.89632224, grad/param norm = 2.2727e-01, time/batch = 0.6628s	
1109/25300 (epoch 2.192), train_loss = 1.99501593, grad/param norm = 2.5039e-01, time/batch = 0.6665s	
1110/25300 (epoch 2.194), train_loss = 1.80470258, grad/param norm = 2.3401e-01, time/batch = 0.6680s	
1111/25300 (epoch 2.196), train_loss = 1.90465588, grad/param norm = 2.7455e-01, time/batch = 0.6684s	
1112/25300 (epoch 2.198), train_loss = 1.92386954, grad/param norm = 2.3778e-01, time/batch = 0.6679s	
1113/25300 (epoch 2.200), train_loss = 1.95176555, grad/param norm = 2.3834e-01, time/batch = 0.6678s	
1114/25300 (epoch 2.202), train_loss = 1.93869325, grad/param norm = 2.3247e-01, time/batch = 0.6623s	
1115/25300 (epoch 2.204), train_loss = 1.88690316, grad/param norm = 2.7747e-01, time/batch = 0.6660s	
1116/25300 (epoch 2.206), train_loss = 1.93249713, grad/param norm = 2.6949e-01, time/batch = 0.6647s	
1117/25300 (epoch 2.208), train_loss = 1.78002769, grad/param norm = 2.5316e-01, time/batch = 0.6619s	
1118/25300 (epoch 2.209), train_loss = 1.72833764, grad/param norm = 3.0051e-01, time/batch = 0.6581s	
1119/25300 (epoch 2.211), train_loss = 1.95316678, grad/param norm = 3.0532e-01, time/batch = 0.6568s	
1120/25300 (epoch 2.213), train_loss = 1.91099711, grad/param norm = 2.8466e-01, time/batch = 0.6554s	
1121/25300 (epoch 2.215), train_loss = 1.92726302, grad/param norm = 2.6261e-01, time/batch = 0.6602s	
1122/25300 (epoch 2.217), train_loss = 1.95547452, grad/param norm = 2.8905e-01, time/batch = 0.6576s	
1123/25300 (epoch 2.219), train_loss = 1.88165327, grad/param norm = 2.4180e-01, time/batch = 0.6550s	
1124/25300 (epoch 2.221), train_loss = 2.02417279, grad/param norm = 2.3971e-01, time/batch = 0.6556s	
1125/25300 (epoch 2.223), train_loss = 2.00396037, grad/param norm = 2.8234e-01, time/batch = 0.6649s	
1126/25300 (epoch 2.225), train_loss = 2.23296040, grad/param norm = 3.6851e-01, time/batch = 0.6577s	
1127/25300 (epoch 2.227), train_loss = 1.90055473, grad/param norm = 2.5571e-01, time/batch = 0.6584s	
1128/25300 (epoch 2.229), train_loss = 1.99010104, grad/param norm = 2.2428e-01, time/batch = 0.6579s	
1129/25300 (epoch 2.231), train_loss = 1.98217687, grad/param norm = 3.3929e-01, time/batch = 0.6589s	
1130/25300 (epoch 2.233), train_loss = 1.96150262, grad/param norm = 2.9497e-01, time/batch = 0.6595s	
1131/25300 (epoch 2.235), train_loss = 1.86110008, grad/param norm = 2.4819e-01, time/batch = 0.6636s	
1132/25300 (epoch 2.237), train_loss = 2.05060755, grad/param norm = 2.6264e-01, time/batch = 0.6588s	
1133/25300 (epoch 2.239), train_loss = 1.90736007, grad/param norm = 2.9147e-01, time/batch = 0.6591s	
1134/25300 (epoch 2.241), train_loss = 2.01107054, grad/param norm = 2.4005e-01, time/batch = 0.6576s	
1135/25300 (epoch 2.243), train_loss = 2.20493409, grad/param norm = 3.1169e-01, time/batch = 0.6581s	
1136/25300 (epoch 2.245), train_loss = 1.81460072, grad/param norm = 2.7950e-01, time/batch = 0.6596s	
1137/25300 (epoch 2.247), train_loss = 2.04225694, grad/param norm = 2.6996e-01, time/batch = 0.6612s	
1138/25300 (epoch 2.249), train_loss = 1.80648597, grad/param norm = 2.5576e-01, time/batch = 0.6554s	
1139/25300 (epoch 2.251), train_loss = 1.69694606, grad/param norm = 2.7791e-01, time/batch = 0.6591s	
1140/25300 (epoch 2.253), train_loss = 1.83989140, grad/param norm = 2.9390e-01, time/batch = 0.6557s	
1141/25300 (epoch 2.255), train_loss = 1.83043735, grad/param norm = 2.3024e-01, time/batch = 0.6546s	
1142/25300 (epoch 2.257), train_loss = 2.14222850, grad/param norm = 2.8286e-01, time/batch = 0.6634s	
1143/25300 (epoch 2.259), train_loss = 2.24067482, grad/param norm = 2.8172e-01, time/batch = 0.6605s	
1144/25300 (epoch 2.261), train_loss = 2.05249908, grad/param norm = 2.5588e-01, time/batch = 0.6556s	
1145/25300 (epoch 2.263), train_loss = 1.98462215, grad/param norm = 2.5941e-01, time/batch = 0.6555s	
1146/25300 (epoch 2.265), train_loss = 2.02408701, grad/param norm = 2.6826e-01, time/batch = 0.6593s	
1147/25300 (epoch 2.267), train_loss = 2.00662586, grad/param norm = 2.2582e-01, time/batch = 0.6562s	
1148/25300 (epoch 2.269), train_loss = 1.79686844, grad/param norm = 2.4591e-01, time/batch = 0.6557s	
1149/25300 (epoch 2.271), train_loss = 1.75670483, grad/param norm = 2.9186e-01, time/batch = 0.6557s	
1150/25300 (epoch 2.273), train_loss = 1.93722198, grad/param norm = 2.9981e-01, time/batch = 0.6598s	
1151/25300 (epoch 2.275), train_loss = 1.72379097, grad/param norm = 2.9019e-01, time/batch = 0.6684s	
1152/25300 (epoch 2.277), train_loss = 1.87504100, grad/param norm = 2.5862e-01, time/batch = 0.6712s	
1153/25300 (epoch 2.279), train_loss = 1.95990051, grad/param norm = 2.8211e-01, time/batch = 0.6615s	
1154/25300 (epoch 2.281), train_loss = 2.03264425, grad/param norm = 2.9554e-01, time/batch = 0.6595s	
1155/25300 (epoch 2.283), train_loss = 1.83494553, grad/param norm = 2.5458e-01, time/batch = 0.6583s	
1156/25300 (epoch 2.285), train_loss = 1.89749147, grad/param norm = 2.3853e-01, time/batch = 0.6604s	
1157/25300 (epoch 2.287), train_loss = 1.84201727, grad/param norm = 2.1803e-01, time/batch = 0.6642s	
1158/25300 (epoch 2.289), train_loss = 1.88474089, grad/param norm = 2.1614e-01, time/batch = 0.6643s	
1159/25300 (epoch 2.291), train_loss = 1.69743741, grad/param norm = 2.4299e-01, time/batch = 0.6643s	
1160/25300 (epoch 2.292), train_loss = 1.96166313, grad/param norm = 2.6096e-01, time/batch = 0.6622s	
1161/25300 (epoch 2.294), train_loss = 1.83072436, grad/param norm = 2.6207e-01, time/batch = 0.6655s	
1162/25300 (epoch 2.296), train_loss = 1.80286946, grad/param norm = 2.4595e-01, time/batch = 0.6620s	
1163/25300 (epoch 2.298), train_loss = 1.99793693, grad/param norm = 2.4915e-01, time/batch = 0.6602s	
1164/25300 (epoch 2.300), train_loss = 2.14900012, grad/param norm = 2.7586e-01, time/batch = 0.6596s	
1165/25300 (epoch 2.302), train_loss = 1.67570597, grad/param norm = 2.9162e-01, time/batch = 0.6613s	
1166/25300 (epoch 2.304), train_loss = 2.01632467, grad/param norm = 3.0804e-01, time/batch = 0.6603s	
1167/25300 (epoch 2.306), train_loss = 1.63389169, grad/param norm = 2.4261e-01, time/batch = 0.6606s	
1168/25300 (epoch 2.308), train_loss = 1.89711527, grad/param norm = 2.3341e-01, time/batch = 0.6597s	
1169/25300 (epoch 2.310), train_loss = 1.84384860, grad/param norm = 2.3053e-01, time/batch = 0.6585s	
1170/25300 (epoch 2.312), train_loss = 1.93297207, grad/param norm = 2.5411e-01, time/batch = 0.6579s	
1171/25300 (epoch 2.314), train_loss = 1.75750439, grad/param norm = 2.6120e-01, time/batch = 0.6660s	
1172/25300 (epoch 2.316), train_loss = 1.88087614, grad/param norm = 2.3303e-01, time/batch = 0.6637s	
1173/25300 (epoch 2.318), train_loss = 1.60218390, grad/param norm = 2.5174e-01, time/batch = 0.6585s	
1174/25300 (epoch 2.320), train_loss = 1.81254903, grad/param norm = 3.1929e-01, time/batch = 0.6613s	
1175/25300 (epoch 2.322), train_loss = 2.14301920, grad/param norm = 2.9276e-01, time/batch = 0.6614s	
1176/25300 (epoch 2.324), train_loss = 1.73047405, grad/param norm = 2.8470e-01, time/batch = 0.6629s	
1177/25300 (epoch 2.326), train_loss = 1.58385437, grad/param norm = 2.3998e-01, time/batch = 0.6794s	
1178/25300 (epoch 2.328), train_loss = 1.83401431, grad/param norm = 2.9115e-01, time/batch = 0.6635s	
1179/25300 (epoch 2.330), train_loss = 1.76624347, grad/param norm = 2.2812e-01, time/batch = 0.6669s	
1180/25300 (epoch 2.332), train_loss = 1.89281787, grad/param norm = 2.2945e-01, time/batch = 0.6600s	
1181/25300 (epoch 2.334), train_loss = 1.92595302, grad/param norm = 2.6204e-01, time/batch = 0.6625s	
1182/25300 (epoch 2.336), train_loss = 1.72514503, grad/param norm = 2.5819e-01, time/batch = 0.6705s	
1183/25300 (epoch 2.338), train_loss = 1.77657925, grad/param norm = 2.8181e-01, time/batch = 0.6550s	
1184/25300 (epoch 2.340), train_loss = 1.78494677, grad/param norm = 3.0280e-01, time/batch = 0.6575s	
1185/25300 (epoch 2.342), train_loss = 1.81474437, grad/param norm = 2.9723e-01, time/batch = 0.6567s	
1186/25300 (epoch 2.344), train_loss = 1.83191502, grad/param norm = 2.5611e-01, time/batch = 0.6625s	
1187/25300 (epoch 2.346), train_loss = 1.85241429, grad/param norm = 2.8303e-01, time/batch = 0.6588s	
1188/25300 (epoch 2.348), train_loss = 1.70713180, grad/param norm = 2.6224e-01, time/batch = 0.6587s	
1189/25300 (epoch 2.350), train_loss = 1.80222567, grad/param norm = 2.4318e-01, time/batch = 0.6588s	
1190/25300 (epoch 2.352), train_loss = 1.91533245, grad/param norm = 2.4258e-01, time/batch = 0.6576s	
1191/25300 (epoch 2.354), train_loss = 1.79926570, grad/param norm = 2.5610e-01, time/batch = 0.6602s	
1192/25300 (epoch 2.356), train_loss = 1.87787291, grad/param norm = 2.5584e-01, time/batch = 0.6600s	
1193/25300 (epoch 2.358), train_loss = 2.02276276, grad/param norm = 3.0017e-01, time/batch = 0.6595s	
1194/25300 (epoch 2.360), train_loss = 1.86164463, grad/param norm = 2.3131e-01, time/batch = 0.6582s	
1195/25300 (epoch 2.362), train_loss = 2.02433606, grad/param norm = 2.3569e-01, time/batch = 0.6616s	
1196/25300 (epoch 2.364), train_loss = 1.98930873, grad/param norm = 2.6629e-01, time/batch = 0.6629s	
1197/25300 (epoch 2.366), train_loss = 1.71837136, grad/param norm = 2.6819e-01, time/batch = 0.6580s	
1198/25300 (epoch 2.368), train_loss = 1.91056311, grad/param norm = 2.5508e-01, time/batch = 0.6538s	
1199/25300 (epoch 2.370), train_loss = 1.89899284, grad/param norm = 3.0347e-01, time/batch = 0.6583s	
1200/25300 (epoch 2.372), train_loss = 1.95697327, grad/param norm = 3.5823e-01, time/batch = 0.6575s	
1201/25300 (epoch 2.374), train_loss = 1.74676097, grad/param norm = 3.0059e-01, time/batch = 0.6615s	
1202/25300 (epoch 2.375), train_loss = 2.05237687, grad/param norm = 2.7506e-01, time/batch = 0.6612s	
1203/25300 (epoch 2.377), train_loss = 1.72842387, grad/param norm = 2.2562e-01, time/batch = 0.6584s	
1204/25300 (epoch 2.379), train_loss = 2.19363657, grad/param norm = 2.8217e-01, time/batch = 0.6584s	
1205/25300 (epoch 2.381), train_loss = 1.79394809, grad/param norm = 2.2881e-01, time/batch = 0.6590s	
1206/25300 (epoch 2.383), train_loss = 1.73496083, grad/param norm = 2.8682e-01, time/batch = 0.6552s	
1207/25300 (epoch 2.385), train_loss = 1.77770677, grad/param norm = 2.5609e-01, time/batch = 0.6554s	
1208/25300 (epoch 2.387), train_loss = 2.04018721, grad/param norm = 2.4521e-01, time/batch = 0.6571s	
1209/25300 (epoch 2.389), train_loss = 2.02232454, grad/param norm = 2.3711e-01, time/batch = 0.6559s	
1210/25300 (epoch 2.391), train_loss = 1.66843880, grad/param norm = 2.4057e-01, time/batch = 0.6554s	
1211/25300 (epoch 2.393), train_loss = 1.95363765, grad/param norm = 2.8658e-01, time/batch = 0.6639s	
1212/25300 (epoch 2.395), train_loss = 1.65619388, grad/param norm = 2.3376e-01, time/batch = 0.6621s	
1213/25300 (epoch 2.397), train_loss = 1.68313948, grad/param norm = 2.4764e-01, time/batch = 0.6571s	
1214/25300 (epoch 2.399), train_loss = 1.75405118, grad/param norm = 2.4693e-01, time/batch = 0.6618s	
1215/25300 (epoch 2.401), train_loss = 1.88841785, grad/param norm = 2.3822e-01, time/batch = 0.6598s	
1216/25300 (epoch 2.403), train_loss = 1.81850280, grad/param norm = 2.6559e-01, time/batch = 0.6646s	
1217/25300 (epoch 2.405), train_loss = 1.92097567, grad/param norm = 3.0360e-01, time/batch = 0.6610s	
1218/25300 (epoch 2.407), train_loss = 1.75322187, grad/param norm = 3.1221e-01, time/batch = 0.6572s	
1219/25300 (epoch 2.409), train_loss = 1.80164783, grad/param norm = 2.6073e-01, time/batch = 0.6554s	
1220/25300 (epoch 2.411), train_loss = 1.81475431, grad/param norm = 2.7949e-01, time/batch = 0.6592s	
1221/25300 (epoch 2.413), train_loss = 1.81808198, grad/param norm = 2.9083e-01, time/batch = 0.6578s	
1222/25300 (epoch 2.415), train_loss = 1.78659735, grad/param norm = 2.5722e-01, time/batch = 0.6589s	
1223/25300 (epoch 2.417), train_loss = 1.82873798, grad/param norm = 2.5917e-01, time/batch = 0.6573s	
1224/25300 (epoch 2.419), train_loss = 1.66904181, grad/param norm = 2.3430e-01, time/batch = 0.6567s	
1225/25300 (epoch 2.421), train_loss = 1.73411123, grad/param norm = 2.1049e-01, time/batch = 0.6559s	
1226/25300 (epoch 2.423), train_loss = 1.75304229, grad/param norm = 2.2605e-01, time/batch = 0.6589s	
1227/25300 (epoch 2.425), train_loss = 1.82707979, grad/param norm = 2.7531e-01, time/batch = 0.6615s	
1228/25300 (epoch 2.427), train_loss = 2.03427930, grad/param norm = 2.8684e-01, time/batch = 0.6573s	
1229/25300 (epoch 2.429), train_loss = 1.90921164, grad/param norm = 2.4901e-01, time/batch = 0.6587s	
1230/25300 (epoch 2.431), train_loss = 1.94335642, grad/param norm = 3.1695e-01, time/batch = 0.6589s	
1231/25300 (epoch 2.433), train_loss = 1.86272158, grad/param norm = 2.8199e-01, time/batch = 0.6594s	
1232/25300 (epoch 2.435), train_loss = 1.65421857, grad/param norm = 2.5738e-01, time/batch = 0.6600s	
1233/25300 (epoch 2.437), train_loss = 1.82391787, grad/param norm = 2.5775e-01, time/batch = 0.6585s	
1234/25300 (epoch 2.439), train_loss = 1.89019858, grad/param norm = 2.6381e-01, time/batch = 0.6589s	
1235/25300 (epoch 2.441), train_loss = 1.82718886, grad/param norm = 2.4618e-01, time/batch = 0.6613s	
1236/25300 (epoch 2.443), train_loss = 1.97214031, grad/param norm = 2.7138e-01, time/batch = 0.6567s	
1237/25300 (epoch 2.445), train_loss = 1.93448619, grad/param norm = 2.6963e-01, time/batch = 0.6561s	
1238/25300 (epoch 2.447), train_loss = 1.69692138, grad/param norm = 2.2684e-01, time/batch = 0.6590s	
1239/25300 (epoch 2.449), train_loss = 1.77627278, grad/param norm = 2.2762e-01, time/batch = 0.6617s	
1240/25300 (epoch 2.451), train_loss = 2.04807722, grad/param norm = 2.5619e-01, time/batch = 0.6565s	
1241/25300 (epoch 2.453), train_loss = 1.82955939, grad/param norm = 2.6917e-01, time/batch = 0.6660s	
1242/25300 (epoch 2.455), train_loss = 1.98533601, grad/param norm = 2.5635e-01, time/batch = 0.6679s	
1243/25300 (epoch 2.457), train_loss = 1.84662873, grad/param norm = 2.7144e-01, time/batch = 0.6777s	
1244/25300 (epoch 2.458), train_loss = 1.97328966, grad/param norm = 2.8617e-01, time/batch = 0.6570s	
1245/25300 (epoch 2.460), train_loss = 2.06269703, grad/param norm = 2.6350e-01, time/batch = 0.6582s	
1246/25300 (epoch 2.462), train_loss = 1.67715965, grad/param norm = 2.6680e-01, time/batch = 0.6607s	
1247/25300 (epoch 2.464), train_loss = 1.92498729, grad/param norm = 3.1764e-01, time/batch = 0.6597s	
1248/25300 (epoch 2.466), train_loss = 1.83321438, grad/param norm = 2.8577e-01, time/batch = 0.6589s	
1249/25300 (epoch 2.468), train_loss = 2.04919840, grad/param norm = 3.0108e-01, time/batch = 0.6578s	
1250/25300 (epoch 2.470), train_loss = 1.76102259, grad/param norm = 2.3797e-01, time/batch = 0.6586s	
1251/25300 (epoch 2.472), train_loss = 1.65476572, grad/param norm = 2.3140e-01, time/batch = 0.6623s	
1252/25300 (epoch 2.474), train_loss = 1.81760598, grad/param norm = 2.6175e-01, time/batch = 0.6633s	
1253/25300 (epoch 2.476), train_loss = 1.92459100, grad/param norm = 2.9769e-01, time/batch = 0.6594s	
1254/25300 (epoch 2.478), train_loss = 1.90429378, grad/param norm = 2.3719e-01, time/batch = 0.6591s	
1255/25300 (epoch 2.480), train_loss = 1.61862289, grad/param norm = 2.3339e-01, time/batch = 0.6597s	
1256/25300 (epoch 2.482), train_loss = 1.99242165, grad/param norm = 2.6102e-01, time/batch = 0.6577s	
1257/25300 (epoch 2.484), train_loss = 1.99245382, grad/param norm = 2.4856e-01, time/batch = 0.6585s	
1258/25300 (epoch 2.486), train_loss = 1.89375022, grad/param norm = 2.5378e-01, time/batch = 0.6592s	
1259/25300 (epoch 2.488), train_loss = 1.90590342, grad/param norm = 2.4649e-01, time/batch = 0.6545s	
1260/25300 (epoch 2.490), train_loss = 1.95940579, grad/param norm = 2.7925e-01, time/batch = 0.6577s	
1261/25300 (epoch 2.492), train_loss = 1.77516310, grad/param norm = 2.6214e-01, time/batch = 0.6694s	
1262/25300 (epoch 2.494), train_loss = 1.71097234, grad/param norm = 2.6380e-01, time/batch = 0.6612s	
1263/25300 (epoch 2.496), train_loss = 1.87309282, grad/param norm = 2.7046e-01, time/batch = 0.6640s	
1264/25300 (epoch 2.498), train_loss = 1.71818439, grad/param norm = 2.5979e-01, time/batch = 0.6583s	
1265/25300 (epoch 2.500), train_loss = 2.02505331, grad/param norm = 2.8455e-01, time/batch = 0.6563s	
1266/25300 (epoch 2.502), train_loss = 1.79345574, grad/param norm = 2.7487e-01, time/batch = 0.6559s	
1267/25300 (epoch 2.504), train_loss = 1.79444542, grad/param norm = 2.5213e-01, time/batch = 0.6569s	
1268/25300 (epoch 2.506), train_loss = 1.89180411, grad/param norm = 3.1294e-01, time/batch = 0.6551s	
1269/25300 (epoch 2.508), train_loss = 1.91281561, grad/param norm = 2.7056e-01, time/batch = 0.6564s	
1270/25300 (epoch 2.510), train_loss = 1.84323501, grad/param norm = 2.6417e-01, time/batch = 0.6541s	
1271/25300 (epoch 2.512), train_loss = 1.52515569, grad/param norm = 2.0784e-01, time/batch = 0.6588s	
1272/25300 (epoch 2.514), train_loss = 1.66506358, grad/param norm = 2.4168e-01, time/batch = 0.6593s	
1273/25300 (epoch 2.516), train_loss = 1.78811680, grad/param norm = 2.4972e-01, time/batch = 0.6659s	
1274/25300 (epoch 2.518), train_loss = 1.99180964, grad/param norm = 2.9450e-01, time/batch = 0.6670s	
1275/25300 (epoch 2.520), train_loss = 1.64719663, grad/param norm = 3.1796e-01, time/batch = 0.6586s	
1276/25300 (epoch 2.522), train_loss = 1.75289341, grad/param norm = 2.2793e-01, time/batch = 0.6597s	
1277/25300 (epoch 2.524), train_loss = 1.72700600, grad/param norm = 2.4174e-01, time/batch = 0.6652s	
1278/25300 (epoch 2.526), train_loss = 1.99237540, grad/param norm = 3.1507e-01, time/batch = 0.6589s	
1279/25300 (epoch 2.528), train_loss = 1.99340640, grad/param norm = 3.1596e-01, time/batch = 0.6623s	
1280/25300 (epoch 2.530), train_loss = 1.77052961, grad/param norm = 2.9971e-01, time/batch = 0.6657s	
1281/25300 (epoch 2.532), train_loss = 1.88185146, grad/param norm = 2.5260e-01, time/batch = 0.6612s	
1282/25300 (epoch 2.534), train_loss = 1.76968746, grad/param norm = 2.4363e-01, time/batch = 0.6575s	
1283/25300 (epoch 2.536), train_loss = 1.75176332, grad/param norm = 2.9105e-01, time/batch = 0.6614s	
1284/25300 (epoch 2.538), train_loss = 1.68069962, grad/param norm = 2.4163e-01, time/batch = 0.6574s	
1285/25300 (epoch 2.540), train_loss = 1.82875184, grad/param norm = 2.6771e-01, time/batch = 0.6573s	
1286/25300 (epoch 2.542), train_loss = 1.63709302, grad/param norm = 2.4740e-01, time/batch = 0.6567s	
1287/25300 (epoch 2.543), train_loss = 1.63973464, grad/param norm = 2.3732e-01, time/batch = 0.6644s	
1288/25300 (epoch 2.545), train_loss = 2.25447670, grad/param norm = 2.3942e-01, time/batch = 0.6715s	
1289/25300 (epoch 2.547), train_loss = 1.66572333, grad/param norm = 2.2392e-01, time/batch = 0.6592s	
1290/25300 (epoch 2.549), train_loss = 2.08444785, grad/param norm = 2.5479e-01, time/batch = 0.6773s	
1291/25300 (epoch 2.551), train_loss = 1.83597373, grad/param norm = 2.6322e-01, time/batch = 0.6676s	
1292/25300 (epoch 2.553), train_loss = 1.91587848, grad/param norm = 2.6510e-01, time/batch = 0.6589s	
1293/25300 (epoch 2.555), train_loss = 1.94866774, grad/param norm = 2.4612e-01, time/batch = 0.6578s	
1294/25300 (epoch 2.557), train_loss = 1.93695671, grad/param norm = 2.3239e-01, time/batch = 0.6576s	
1295/25300 (epoch 2.559), train_loss = 1.93061357, grad/param norm = 2.7266e-01, time/batch = 0.6606s	
1296/25300 (epoch 2.561), train_loss = 2.00103989, grad/param norm = 2.5485e-01, time/batch = 0.6564s	
1297/25300 (epoch 2.563), train_loss = 1.84059470, grad/param norm = 2.2231e-01, time/batch = 0.6552s	
1298/25300 (epoch 2.565), train_loss = 1.74310492, grad/param norm = 2.5173e-01, time/batch = 0.6593s	
1299/25300 (epoch 2.567), train_loss = 1.46092541, grad/param norm = 2.3374e-01, time/batch = 0.6561s	
1300/25300 (epoch 2.569), train_loss = 1.76011969, grad/param norm = 2.4947e-01, time/batch = 0.6596s	
1301/25300 (epoch 2.571), train_loss = 1.87595747, grad/param norm = 2.4427e-01, time/batch = 0.6640s	
1302/25300 (epoch 2.573), train_loss = 1.86451507, grad/param norm = 2.4622e-01, time/batch = 0.6629s	
1303/25300 (epoch 2.575), train_loss = 1.85630834, grad/param norm = 2.2309e-01, time/batch = 0.6589s	
1304/25300 (epoch 2.577), train_loss = 1.92023191, grad/param norm = 2.9089e-01, time/batch = 0.6575s	
1305/25300 (epoch 2.579), train_loss = 2.04254793, grad/param norm = 2.5067e-01, time/batch = 0.6590s	
1306/25300 (epoch 2.581), train_loss = 1.82923864, grad/param norm = 2.2479e-01, time/batch = 0.6586s	
1307/25300 (epoch 2.583), train_loss = 1.67648091, grad/param norm = 2.3901e-01, time/batch = 0.6566s	
1308/25300 (epoch 2.585), train_loss = 1.75261095, grad/param norm = 2.2631e-01, time/batch = 0.6612s	
1309/25300 (epoch 2.587), train_loss = 1.80647076, grad/param norm = 2.6990e-01, time/batch = 0.6632s	
1310/25300 (epoch 2.589), train_loss = 1.66117036, grad/param norm = 2.3900e-01, time/batch = 0.6574s	
1311/25300 (epoch 2.591), train_loss = 1.74765798, grad/param norm = 2.6341e-01, time/batch = 0.6597s	
1312/25300 (epoch 2.593), train_loss = 1.66429839, grad/param norm = 2.2843e-01, time/batch = 0.6596s	
1313/25300 (epoch 2.595), train_loss = 1.82102879, grad/param norm = 2.3911e-01, time/batch = 0.6592s	
1314/25300 (epoch 2.597), train_loss = 1.63025927, grad/param norm = 2.3544e-01, time/batch = 0.6559s	
1315/25300 (epoch 2.599), train_loss = 1.72950659, grad/param norm = 2.7335e-01, time/batch = 0.6566s	
1316/25300 (epoch 2.601), train_loss = 1.90527705, grad/param norm = 2.8198e-01, time/batch = 0.6571s	
1317/25300 (epoch 2.603), train_loss = 1.81243196, grad/param norm = 2.4077e-01, time/batch = 0.6540s	
1318/25300 (epoch 2.605), train_loss = 1.74555529, grad/param norm = 2.3868e-01, time/batch = 0.6587s	
1319/25300 (epoch 2.607), train_loss = 1.73719352, grad/param norm = 2.7099e-01, time/batch = 0.6567s	
1320/25300 (epoch 2.609), train_loss = 1.83374185, grad/param norm = 2.6561e-01, time/batch = 0.6619s	
1321/25300 (epoch 2.611), train_loss = 1.98258862, grad/param norm = 2.5064e-01, time/batch = 0.6569s	
1322/25300 (epoch 2.613), train_loss = 1.79379032, grad/param norm = 2.7974e-01, time/batch = 0.6543s	
1323/25300 (epoch 2.615), train_loss = 1.89222503, grad/param norm = 2.5930e-01, time/batch = 0.6543s	
1324/25300 (epoch 2.617), train_loss = 1.81239547, grad/param norm = 2.2970e-01, time/batch = 0.6555s	
1325/25300 (epoch 2.619), train_loss = 1.83504958, grad/param norm = 2.6700e-01, time/batch = 0.6558s	
1326/25300 (epoch 2.621), train_loss = 1.91785489, grad/param norm = 2.9921e-01, time/batch = 0.6619s	
1327/25300 (epoch 2.623), train_loss = 1.77812657, grad/param norm = 2.3941e-01, time/batch = 0.6564s	
1328/25300 (epoch 2.625), train_loss = 1.62104233, grad/param norm = 2.4972e-01, time/batch = 0.6605s	
1329/25300 (epoch 2.626), train_loss = 1.80556760, grad/param norm = 2.7777e-01, time/batch = 0.6618s	
1330/25300 (epoch 2.628), train_loss = 1.94325370, grad/param norm = 2.8992e-01, time/batch = 0.6591s	
1331/25300 (epoch 2.630), train_loss = 1.87808782, grad/param norm = 2.3884e-01, time/batch = 0.6645s	
1332/25300 (epoch 2.632), train_loss = 1.95446175, grad/param norm = 2.7826e-01, time/batch = 0.6705s	
1333/25300 (epoch 2.634), train_loss = 2.02371802, grad/param norm = 2.3632e-01, time/batch = 0.6711s	
1334/25300 (epoch 2.636), train_loss = 1.88765796, grad/param norm = 2.5237e-01, time/batch = 0.6762s	
1335/25300 (epoch 2.638), train_loss = 1.92041313, grad/param norm = 2.7930e-01, time/batch = 0.6733s	
1336/25300 (epoch 2.640), train_loss = 2.03653594, grad/param norm = 2.9185e-01, time/batch = 0.6594s	
1337/25300 (epoch 2.642), train_loss = 1.90966016, grad/param norm = 2.5609e-01, time/batch = 0.6619s	
1338/25300 (epoch 2.644), train_loss = 1.99685262, grad/param norm = 2.7238e-01, time/batch = 0.6572s	
1339/25300 (epoch 2.646), train_loss = 1.91513026, grad/param norm = 2.5152e-01, time/batch = 0.6862s	
1340/25300 (epoch 2.648), train_loss = 1.95746021, grad/param norm = 2.2883e-01, time/batch = 0.6691s	
1341/25300 (epoch 2.650), train_loss = 1.90162726, grad/param norm = 2.4632e-01, time/batch = 0.6625s	
1342/25300 (epoch 2.652), train_loss = 2.06222216, grad/param norm = 2.4018e-01, time/batch = 0.6579s	
1343/25300 (epoch 2.654), train_loss = 2.02443836, grad/param norm = 2.6913e-01, time/batch = 0.6571s	
1344/25300 (epoch 2.656), train_loss = 2.06458901, grad/param norm = 2.6786e-01, time/batch = 0.6570s	
1345/25300 (epoch 2.658), train_loss = 1.74598770, grad/param norm = 2.7160e-01, time/batch = 0.6592s	
1346/25300 (epoch 2.660), train_loss = 1.68205283, grad/param norm = 2.5740e-01, time/batch = 0.6597s	
1347/25300 (epoch 2.662), train_loss = 1.61521398, grad/param norm = 2.8464e-01, time/batch = 0.6596s	
1348/25300 (epoch 2.664), train_loss = 1.58139305, grad/param norm = 2.3551e-01, time/batch = 0.6575s	
1349/25300 (epoch 2.666), train_loss = 1.62495512, grad/param norm = 2.5407e-01, time/batch = 0.6598s	
1350/25300 (epoch 2.668), train_loss = 1.72033345, grad/param norm = 2.8281e-01, time/batch = 0.6576s	
1351/25300 (epoch 2.670), train_loss = 1.78173265, grad/param norm = 2.5770e-01, time/batch = 0.6562s	
1352/25300 (epoch 2.672), train_loss = 1.80047658, grad/param norm = 2.8775e-01, time/batch = 0.6589s	
1353/25300 (epoch 2.674), train_loss = 1.78329985, grad/param norm = 2.2232e-01, time/batch = 0.6568s	
1354/25300 (epoch 2.676), train_loss = 1.86931289, grad/param norm = 2.2421e-01, time/batch = 0.6581s	
1355/25300 (epoch 2.678), train_loss = 1.85646101, grad/param norm = 2.7266e-01, time/batch = 0.6630s	
1356/25300 (epoch 2.680), train_loss = 1.66495282, grad/param norm = 2.6176e-01, time/batch = 0.6580s	
1357/25300 (epoch 2.682), train_loss = 1.48697436, grad/param norm = 2.3474e-01, time/batch = 0.6535s	
1358/25300 (epoch 2.684), train_loss = 1.61375067, grad/param norm = 2.2486e-01, time/batch = 0.6541s	
1359/25300 (epoch 2.686), train_loss = 1.72905110, grad/param norm = 2.4713e-01, time/batch = 0.6562s	
1360/25300 (epoch 2.688), train_loss = 1.90525265, grad/param norm = 2.4159e-01, time/batch = 0.6556s	
1361/25300 (epoch 2.690), train_loss = 1.79423001, grad/param norm = 2.2794e-01, time/batch = 0.6577s	
1362/25300 (epoch 2.692), train_loss = 1.84971212, grad/param norm = 2.3012e-01, time/batch = 0.6608s	
1363/25300 (epoch 2.694), train_loss = 1.65307928, grad/param norm = 2.1666e-01, time/batch = 0.6666s	
1364/25300 (epoch 2.696), train_loss = 1.77161808, grad/param norm = 2.3117e-01, time/batch = 0.6599s	
1365/25300 (epoch 2.698), train_loss = 1.79983908, grad/param norm = 2.4039e-01, time/batch = 0.6602s	
1366/25300 (epoch 2.700), train_loss = 1.57605375, grad/param norm = 2.8641e-01, time/batch = 0.6575s	
1367/25300 (epoch 2.702), train_loss = 2.00476967, grad/param norm = 2.6651e-01, time/batch = 0.6643s	
1368/25300 (epoch 2.704), train_loss = 1.57020519, grad/param norm = 2.1101e-01, time/batch = 0.6580s	
1369/25300 (epoch 2.706), train_loss = 1.78892228, grad/param norm = 2.7132e-01, time/batch = 0.6537s	
1370/25300 (epoch 2.708), train_loss = 1.51995396, grad/param norm = 2.3548e-01, time/batch = 0.6562s	
1371/25300 (epoch 2.709), train_loss = 1.93363106, grad/param norm = 2.6381e-01, time/batch = 0.6620s	
1372/25300 (epoch 2.711), train_loss = 1.99363984, grad/param norm = 2.7336e-01, time/batch = 0.6496s	
1373/25300 (epoch 2.713), train_loss = 1.78573069, grad/param norm = 2.7650e-01, time/batch = 0.6554s	
1374/25300 (epoch 2.715), train_loss = 1.72386435, grad/param norm = 2.7800e-01, time/batch = 0.6590s	
1375/25300 (epoch 2.717), train_loss = 1.89410367, grad/param norm = 2.8354e-01, time/batch = 0.6610s	
1376/25300 (epoch 2.719), train_loss = 1.73251665, grad/param norm = 2.8333e-01, time/batch = 0.6557s	
1377/25300 (epoch 2.721), train_loss = 1.71436487, grad/param norm = 2.7964e-01, time/batch = 0.6581s	
1378/25300 (epoch 2.723), train_loss = 1.63080419, grad/param norm = 2.3498e-01, time/batch = 0.6595s	
1379/25300 (epoch 2.725), train_loss = 1.79958622, grad/param norm = 2.8961e-01, time/batch = 0.6614s	
1380/25300 (epoch 2.727), train_loss = 1.70709015, grad/param norm = 3.1954e-01, time/batch = 0.6603s	
1381/25300 (epoch 2.729), train_loss = 1.72137830, grad/param norm = 2.6990e-01, time/batch = 0.6648s	
1382/25300 (epoch 2.731), train_loss = 1.97148134, grad/param norm = 2.8538e-01, time/batch = 0.6582s	
1383/25300 (epoch 2.733), train_loss = 1.58790501, grad/param norm = 2.1450e-01, time/batch = 0.6529s	
1384/25300 (epoch 2.735), train_loss = 2.04726210, grad/param norm = 2.4996e-01, time/batch = 0.6534s	
1385/25300 (epoch 2.737), train_loss = 1.65125225, grad/param norm = 2.4480e-01, time/batch = 0.6584s	
1386/25300 (epoch 2.739), train_loss = 1.80680224, grad/param norm = 2.4513e-01, time/batch = 0.6629s	
1387/25300 (epoch 2.741), train_loss = 1.82145618, grad/param norm = 2.5715e-01, time/batch = 0.6589s	
1388/25300 (epoch 2.743), train_loss = 1.71802696, grad/param norm = 2.5289e-01, time/batch = 0.6598s	
1389/25300 (epoch 2.745), train_loss = 1.64381379, grad/param norm = 2.1142e-01, time/batch = 0.6584s	
1390/25300 (epoch 2.747), train_loss = 1.61947689, grad/param norm = 2.0991e-01, time/batch = 0.6542s	
1391/25300 (epoch 2.749), train_loss = 1.78675748, grad/param norm = 2.2702e-01, time/batch = 0.6591s	
1392/25300 (epoch 2.751), train_loss = 1.85174812, grad/param norm = 2.3004e-01, time/batch = 0.6568s	
1393/25300 (epoch 2.753), train_loss = 1.74165603, grad/param norm = 2.4531e-01, time/batch = 0.6586s	
1394/25300 (epoch 2.755), train_loss = 1.87895687, grad/param norm = 2.5447e-01, time/batch = 0.6584s	
1395/25300 (epoch 2.757), train_loss = 1.69181915, grad/param norm = 2.7468e-01, time/batch = 0.6593s	
1396/25300 (epoch 2.759), train_loss = 1.62625609, grad/param norm = 2.4856e-01, time/batch = 0.6579s	
1397/25300 (epoch 2.761), train_loss = 1.87250086, grad/param norm = 2.9097e-01, time/batch = 0.6573s	
1398/25300 (epoch 2.763), train_loss = 1.66740062, grad/param norm = 3.1877e-01, time/batch = 0.6551s	
1399/25300 (epoch 2.765), train_loss = 1.77235287, grad/param norm = 3.1008e-01, time/batch = 0.6584s	
1400/25300 (epoch 2.767), train_loss = 1.70529055, grad/param norm = 2.6761e-01, time/batch = 0.6563s	
1401/25300 (epoch 2.769), train_loss = 1.75768133, grad/param norm = 2.5558e-01, time/batch = 0.6615s	
1402/25300 (epoch 2.771), train_loss = 2.12423050, grad/param norm = 2.5664e-01, time/batch = 0.6618s	
1403/25300 (epoch 2.773), train_loss = 1.93257634, grad/param norm = 2.4677e-01, time/batch = 0.6615s	
1404/25300 (epoch 2.775), train_loss = 1.71205354, grad/param norm = 2.2275e-01, time/batch = 0.6578s	
1405/25300 (epoch 2.777), train_loss = 1.83985199, grad/param norm = 2.3487e-01, time/batch = 0.6546s	
1406/25300 (epoch 2.779), train_loss = 1.87234231, grad/param norm = 2.4543e-01, time/batch = 0.6592s	
1407/25300 (epoch 2.781), train_loss = 1.66353413, grad/param norm = 2.5906e-01, time/batch = 0.6637s	
1408/25300 (epoch 2.783), train_loss = 1.92559315, grad/param norm = 2.4707e-01, time/batch = 0.6613s	
1409/25300 (epoch 2.785), train_loss = 1.82107400, grad/param norm = 2.4347e-01, time/batch = 0.6588s	
1410/25300 (epoch 2.787), train_loss = 1.94604711, grad/param norm = 2.3316e-01, time/batch = 0.6590s	
1411/25300 (epoch 2.789), train_loss = 1.98057574, grad/param norm = 2.1762e-01, time/batch = 0.6614s	
1412/25300 (epoch 2.791), train_loss = 1.77315566, grad/param norm = 2.2086e-01, time/batch = 0.6587s	
1413/25300 (epoch 2.792), train_loss = 1.81660203, grad/param norm = 2.1928e-01, time/batch = 0.6594s	
1414/25300 (epoch 2.794), train_loss = 1.92480568, grad/param norm = 2.3417e-01, time/batch = 0.6575s	
1415/25300 (epoch 2.796), train_loss = 1.68345675, grad/param norm = 2.0737e-01, time/batch = 0.6597s	
1416/25300 (epoch 2.798), train_loss = 1.91378642, grad/param norm = 2.1723e-01, time/batch = 0.6577s	
1417/25300 (epoch 2.800), train_loss = 1.84182973, grad/param norm = 2.3106e-01, time/batch = 0.6563s	
1418/25300 (epoch 2.802), train_loss = 1.48625760, grad/param norm = 2.1184e-01, time/batch = 0.6563s	
1419/25300 (epoch 2.804), train_loss = 1.79269406, grad/param norm = 2.1163e-01, time/batch = 0.6554s	
1420/25300 (epoch 2.806), train_loss = 1.86431021, grad/param norm = 2.3082e-01, time/batch = 0.6554s	
1421/25300 (epoch 2.808), train_loss = 1.70505850, grad/param norm = 2.2442e-01, time/batch = 0.6567s	
1422/25300 (epoch 2.810), train_loss = 1.72667501, grad/param norm = 2.7152e-01, time/batch = 0.6638s	
1423/25300 (epoch 2.812), train_loss = 1.76633595, grad/param norm = 2.1958e-01, time/batch = 0.6669s	
1424/25300 (epoch 2.814), train_loss = 1.98999615, grad/param norm = 2.2772e-01, time/batch = 0.6671s	
1425/25300 (epoch 2.816), train_loss = 1.98172346, grad/param norm = 2.5121e-01, time/batch = 0.6630s	
1426/25300 (epoch 2.818), train_loss = 1.93005004, grad/param norm = 2.5047e-01, time/batch = 0.6607s	
1427/25300 (epoch 2.820), train_loss = 1.80433050, grad/param norm = 2.1574e-01, time/batch = 0.6589s	
1428/25300 (epoch 2.822), train_loss = 1.71597758, grad/param norm = 2.0654e-01, time/batch = 0.6566s	
1429/25300 (epoch 2.824), train_loss = 1.83250175, grad/param norm = 2.2414e-01, time/batch = 0.6590s	
1430/25300 (epoch 2.826), train_loss = 1.71912814, grad/param norm = 2.6618e-01, time/batch = 0.6653s	
1431/25300 (epoch 2.828), train_loss = 1.68563921, grad/param norm = 2.6096e-01, time/batch = 0.6622s	
1432/25300 (epoch 2.830), train_loss = 1.72711846, grad/param norm = 2.4053e-01, time/batch = 0.6633s	
1433/25300 (epoch 2.832), train_loss = 1.71721080, grad/param norm = 2.5766e-01, time/batch = 0.6612s	
1434/25300 (epoch 2.834), train_loss = 1.61622334, grad/param norm = 2.7125e-01, time/batch = 0.6563s	
1435/25300 (epoch 2.836), train_loss = 1.72085280, grad/param norm = 2.6790e-01, time/batch = 0.6605s	
1436/25300 (epoch 2.838), train_loss = 1.77721066, grad/param norm = 2.5603e-01, time/batch = 0.6690s	
1437/25300 (epoch 2.840), train_loss = 1.89743204, grad/param norm = 2.2417e-01, time/batch = 0.6621s	
1438/25300 (epoch 2.842), train_loss = 1.90720246, grad/param norm = 2.5432e-01, time/batch = 0.6644s	
1439/25300 (epoch 2.844), train_loss = 1.75793621, grad/param norm = 2.4819e-01, time/batch = 0.6592s	
1440/25300 (epoch 2.846), train_loss = 1.65872189, grad/param norm = 2.2666e-01, time/batch = 0.6601s	
1441/25300 (epoch 2.848), train_loss = 1.92405413, grad/param norm = 2.5435e-01, time/batch = 0.6616s	
1442/25300 (epoch 2.850), train_loss = 1.83753785, grad/param norm = 2.3961e-01, time/batch = 0.6585s	
1443/25300 (epoch 2.852), train_loss = 1.76952445, grad/param norm = 2.7524e-01, time/batch = 0.6562s	
1444/25300 (epoch 2.854), train_loss = 2.01091003, grad/param norm = 2.5730e-01, time/batch = 0.6606s	
1445/25300 (epoch 2.856), train_loss = 1.76929078, grad/param norm = 2.3418e-01, time/batch = 0.6575s	
1446/25300 (epoch 2.858), train_loss = 1.81983986, grad/param norm = 2.2392e-01, time/batch = 0.6657s	
1447/25300 (epoch 2.860), train_loss = 1.56074632, grad/param norm = 2.1968e-01, time/batch = 0.6656s	
1448/25300 (epoch 2.862), train_loss = 1.85193605, grad/param norm = 2.3411e-01, time/batch = 0.6588s	
1449/25300 (epoch 2.864), train_loss = 1.92800862, grad/param norm = 2.4692e-01, time/batch = 0.6559s	
1450/25300 (epoch 2.866), train_loss = 1.86882074, grad/param norm = 2.3996e-01, time/batch = 0.6561s	
1451/25300 (epoch 2.868), train_loss = 1.92348207, grad/param norm = 2.5694e-01, time/batch = 0.6589s	
1452/25300 (epoch 2.870), train_loss = 1.85764538, grad/param norm = 2.3525e-01, time/batch = 0.6549s	
1453/25300 (epoch 2.872), train_loss = 1.79138219, grad/param norm = 2.2475e-01, time/batch = 0.6575s	
1454/25300 (epoch 2.874), train_loss = 1.83636451, grad/param norm = 2.6160e-01, time/batch = 0.6563s	
1455/25300 (epoch 2.875), train_loss = 1.80953986, grad/param norm = 2.7085e-01, time/batch = 0.6596s	
1456/25300 (epoch 2.877), train_loss = 1.65368072, grad/param norm = 2.1558e-01, time/batch = 0.6574s	
1457/25300 (epoch 2.879), train_loss = 1.86982579, grad/param norm = 2.1611e-01, time/batch = 0.6551s	
1458/25300 (epoch 2.881), train_loss = 2.08136879, grad/param norm = 2.3085e-01, time/batch = 0.6489s	
1459/25300 (epoch 2.883), train_loss = 2.01249453, grad/param norm = 2.1825e-01, time/batch = 0.6556s	
1460/25300 (epoch 2.885), train_loss = 1.87291858, grad/param norm = 2.2634e-01, time/batch = 0.6575s	
1461/25300 (epoch 2.887), train_loss = 1.75420892, grad/param norm = 2.2219e-01, time/batch = 0.6577s	
1462/25300 (epoch 2.889), train_loss = 2.03694706, grad/param norm = 2.7224e-01, time/batch = 0.6579s	
1463/25300 (epoch 2.891), train_loss = 2.03868923, grad/param norm = 2.7183e-01, time/batch = 0.6590s	
1464/25300 (epoch 2.893), train_loss = 2.11194500, grad/param norm = 2.9097e-01, time/batch = 0.6600s	
1465/25300 (epoch 2.895), train_loss = 1.50325841, grad/param norm = 2.9490e-01, time/batch = 0.6607s	
1466/25300 (epoch 2.897), train_loss = 1.74038825, grad/param norm = 2.4545e-01, time/batch = 0.6586s	
1467/25300 (epoch 2.899), train_loss = 1.79489305, grad/param norm = 2.4178e-01, time/batch = 0.6657s	
1468/25300 (epoch 2.901), train_loss = 1.91179519, grad/param norm = 2.4756e-01, time/batch = 0.6669s	
1469/25300 (epoch 2.903), train_loss = 1.62872737, grad/param norm = 2.8887e-01, time/batch = 0.6676s	
1470/25300 (epoch 2.905), train_loss = 1.69748659, grad/param norm = 2.4987e-01, time/batch = 0.6619s	
1471/25300 (epoch 2.907), train_loss = 2.01845879, grad/param norm = 2.8915e-01, time/batch = 0.6666s	
1472/25300 (epoch 2.909), train_loss = 1.85554515, grad/param norm = 2.3261e-01, time/batch = 0.6676s	
1473/25300 (epoch 2.911), train_loss = 1.94589705, grad/param norm = 2.3007e-01, time/batch = 0.6521s	
1474/25300 (epoch 2.913), train_loss = 1.89460082, grad/param norm = 2.5177e-01, time/batch = 0.6550s	
1475/25300 (epoch 2.915), train_loss = 1.80713967, grad/param norm = 2.5256e-01, time/batch = 0.6547s	
1476/25300 (epoch 2.917), train_loss = 1.86486331, grad/param norm = 2.2263e-01, time/batch = 0.6559s	
1477/25300 (epoch 2.919), train_loss = 1.85790820, grad/param norm = 2.5123e-01, time/batch = 0.6561s	
1478/25300 (epoch 2.921), train_loss = 1.64672870, grad/param norm = 2.6908e-01, time/batch = 0.6590s	
1479/25300 (epoch 2.923), train_loss = 1.86441063, grad/param norm = 2.3443e-01, time/batch = 0.6585s	
1480/25300 (epoch 2.925), train_loss = 1.87024120, grad/param norm = 2.1770e-01, time/batch = 0.6571s	
1481/25300 (epoch 2.927), train_loss = 1.80106110, grad/param norm = 2.4384e-01, time/batch = 0.6558s	
1482/25300 (epoch 2.929), train_loss = 1.63241698, grad/param norm = 2.7632e-01, time/batch = 0.6561s	
1483/25300 (epoch 2.931), train_loss = 1.90682165, grad/param norm = 2.4012e-01, time/batch = 0.6604s	
1484/25300 (epoch 2.933), train_loss = 1.83763503, grad/param norm = 2.4968e-01, time/batch = 0.6605s	
1485/25300 (epoch 2.935), train_loss = 1.73729078, grad/param norm = 2.3261e-01, time/batch = 0.6597s	
1486/25300 (epoch 2.937), train_loss = 1.50227682, grad/param norm = 1.9059e-01, time/batch = 0.6591s	
1487/25300 (epoch 2.939), train_loss = 1.91925881, grad/param norm = 2.3459e-01, time/batch = 0.6565s	
1488/25300 (epoch 2.941), train_loss = 1.66199152, grad/param norm = 2.1053e-01, time/batch = 0.6557s	
1489/25300 (epoch 2.943), train_loss = 1.60573861, grad/param norm = 2.1714e-01, time/batch = 0.6555s	
1490/25300 (epoch 2.945), train_loss = 1.73351499, grad/param norm = 2.1223e-01, time/batch = 0.6577s	
1491/25300 (epoch 2.947), train_loss = 1.78250069, grad/param norm = 2.3559e-01, time/batch = 0.6596s	
1492/25300 (epoch 2.949), train_loss = 1.90253797, grad/param norm = 2.5292e-01, time/batch = 0.6565s	
1493/25300 (epoch 2.951), train_loss = 1.76049516, grad/param norm = 2.1687e-01, time/batch = 0.6561s	
1494/25300 (epoch 2.953), train_loss = 1.95268714, grad/param norm = 2.4444e-01, time/batch = 0.6625s	
1495/25300 (epoch 2.955), train_loss = 2.03693679, grad/param norm = 2.7185e-01, time/batch = 0.6556s	
1496/25300 (epoch 2.957), train_loss = 1.92596624, grad/param norm = 3.2037e-01, time/batch = 0.6592s	
1497/25300 (epoch 2.958), train_loss = 1.85347609, grad/param norm = 2.4921e-01, time/batch = 0.6601s	
1498/25300 (epoch 2.960), train_loss = 1.96833091, grad/param norm = 2.5409e-01, time/batch = 0.6605s	
1499/25300 (epoch 2.962), train_loss = 1.83043111, grad/param norm = 2.6644e-01, time/batch = 0.6566s	
1500/25300 (epoch 2.964), train_loss = 1.80061212, grad/param norm = 2.3182e-01, time/batch = 0.6585s	
1501/25300 (epoch 2.966), train_loss = 1.61309004, grad/param norm = 2.4336e-01, time/batch = 0.6614s	
1502/25300 (epoch 2.968), train_loss = 1.56523070, grad/param norm = 2.4366e-01, time/batch = 0.6567s	
1503/25300 (epoch 2.970), train_loss = 1.84312650, grad/param norm = 2.4051e-01, time/batch = 0.6532s	
1504/25300 (epoch 2.972), train_loss = 1.77996018, grad/param norm = 2.2124e-01, time/batch = 0.6566s	
1505/25300 (epoch 2.974), train_loss = 2.01051585, grad/param norm = 2.6238e-01, time/batch = 0.6565s	
1506/25300 (epoch 2.976), train_loss = 1.83444781, grad/param norm = 2.6717e-01, time/batch = 0.6594s	
1507/25300 (epoch 2.978), train_loss = 1.85149665, grad/param norm = 2.2173e-01, time/batch = 0.6547s	
1508/25300 (epoch 2.980), train_loss = 1.88971060, grad/param norm = 2.5301e-01, time/batch = 0.6553s	
1509/25300 (epoch 2.982), train_loss = 1.81913465, grad/param norm = 2.7225e-01, time/batch = 0.6579s	
1510/25300 (epoch 2.984), train_loss = 1.75922736, grad/param norm = 2.2940e-01, time/batch = 0.6587s	
1511/25300 (epoch 2.986), train_loss = 1.75864292, grad/param norm = 2.6809e-01, time/batch = 0.6602s	
1512/25300 (epoch 2.988), train_loss = 1.71825286, grad/param norm = 2.3719e-01, time/batch = 0.6593s	
1513/25300 (epoch 2.990), train_loss = 1.74588733, grad/param norm = 2.5238e-01, time/batch = 0.6659s	
1514/25300 (epoch 2.992), train_loss = 1.46769033, grad/param norm = 2.3073e-01, time/batch = 0.6679s	
1515/25300 (epoch 2.994), train_loss = 1.87043516, grad/param norm = 2.1824e-01, time/batch = 0.6697s	
1516/25300 (epoch 2.996), train_loss = 1.90372583, grad/param norm = 2.3831e-01, time/batch = 0.6638s	
1517/25300 (epoch 2.998), train_loss = 1.86723570, grad/param norm = 2.2187e-01, time/batch = 0.6654s	
1518/25300 (epoch 3.000), train_loss = 1.77721866, grad/param norm = 2.5353e-01, time/batch = 0.6590s	
1519/25300 (epoch 3.002), train_loss = 1.63017948, grad/param norm = 2.1911e-01, time/batch = 0.6614s	
1520/25300 (epoch 3.004), train_loss = 1.59037098, grad/param norm = 2.2179e-01, time/batch = 0.6671s	
1521/25300 (epoch 3.006), train_loss = 1.73117110, grad/param norm = 2.2782e-01, time/batch = 0.6700s	
1522/25300 (epoch 3.008), train_loss = 1.80294804, grad/param norm = 2.4483e-01, time/batch = 0.6645s	
1523/25300 (epoch 3.010), train_loss = 1.81829430, grad/param norm = 2.3453e-01, time/batch = 0.6613s	
1524/25300 (epoch 3.012), train_loss = 1.63533979, grad/param norm = 2.4857e-01, time/batch = 0.6621s	
1525/25300 (epoch 3.014), train_loss = 1.81207909, grad/param norm = 2.2451e-01, time/batch = 0.6633s	
1526/25300 (epoch 3.016), train_loss = 1.80856097, grad/param norm = 2.2636e-01, time/batch = 0.6624s	
1527/25300 (epoch 3.018), train_loss = 1.70590362, grad/param norm = 2.3341e-01, time/batch = 0.6626s	
1528/25300 (epoch 3.020), train_loss = 1.72395149, grad/param norm = 2.3066e-01, time/batch = 0.6602s	
1529/25300 (epoch 3.022), train_loss = 1.73926596, grad/param norm = 2.5295e-01, time/batch = 0.6594s	
1530/25300 (epoch 3.024), train_loss = 1.42356778, grad/param norm = 2.2893e-01, time/batch = 0.6598s	
1531/25300 (epoch 3.026), train_loss = 1.70545326, grad/param norm = 2.7631e-01, time/batch = 0.6617s	
1532/25300 (epoch 3.028), train_loss = 1.55794093, grad/param norm = 2.3541e-01, time/batch = 0.6613s	
1533/25300 (epoch 3.030), train_loss = 1.84084533, grad/param norm = 2.3715e-01, time/batch = 0.6610s	
1534/25300 (epoch 3.032), train_loss = 1.68578268, grad/param norm = 2.1196e-01, time/batch = 0.6610s	
1535/25300 (epoch 3.034), train_loss = 1.46238166, grad/param norm = 2.1881e-01, time/batch = 0.6603s	
1536/25300 (epoch 3.036), train_loss = 1.54397954, grad/param norm = 2.2199e-01, time/batch = 0.6573s	
1537/25300 (epoch 3.038), train_loss = 1.47834239, grad/param norm = 2.1519e-01, time/batch = 0.6565s	
1538/25300 (epoch 3.040), train_loss = 1.82358269, grad/param norm = 2.1375e-01, time/batch = 0.6577s	
1539/25300 (epoch 3.042), train_loss = 1.54841541, grad/param norm = 2.5788e-01, time/batch = 0.6597s	
1540/25300 (epoch 3.043), train_loss = 1.48662680, grad/param norm = 1.9867e-01, time/batch = 0.6573s	
1541/25300 (epoch 3.045), train_loss = 1.47891227, grad/param norm = 2.2042e-01, time/batch = 0.6578s	
1542/25300 (epoch 3.047), train_loss = 1.84557102, grad/param norm = 2.6169e-01, time/batch = 0.6556s	
1543/25300 (epoch 3.049), train_loss = 1.75421775, grad/param norm = 2.3461e-01, time/batch = 0.6577s	
1544/25300 (epoch 3.051), train_loss = 1.85294474, grad/param norm = 2.5417e-01, time/batch = 0.6596s	
1545/25300 (epoch 3.053), train_loss = 1.53058852, grad/param norm = 2.1279e-01, time/batch = 0.6586s	
1546/25300 (epoch 3.055), train_loss = 1.46419948, grad/param norm = 2.1099e-01, time/batch = 0.6597s	
1547/25300 (epoch 3.057), train_loss = 1.50292583, grad/param norm = 1.9464e-01, time/batch = 0.6594s	
1548/25300 (epoch 3.059), train_loss = 1.79804945, grad/param norm = 2.5083e-01, time/batch = 0.6696s	
1549/25300 (epoch 3.061), train_loss = 1.63789180, grad/param norm = 2.4888e-01, time/batch = 0.6668s	
1550/25300 (epoch 3.063), train_loss = 1.71063230, grad/param norm = 2.2038e-01, time/batch = 0.6574s	
1551/25300 (epoch 3.065), train_loss = 1.90549686, grad/param norm = 2.5014e-01, time/batch = 0.6550s	
1552/25300 (epoch 3.067), train_loss = 1.80125184, grad/param norm = 2.2682e-01, time/batch = 0.6601s	
1553/25300 (epoch 3.069), train_loss = 1.81484870, grad/param norm = 2.3788e-01, time/batch = 0.6546s	
1554/25300 (epoch 3.071), train_loss = 1.84800019, grad/param norm = 2.4848e-01, time/batch = 0.6558s	
1555/25300 (epoch 3.073), train_loss = 1.75449949, grad/param norm = 2.5833e-01, time/batch = 0.6572s	
1556/25300 (epoch 3.075), train_loss = 1.61712985, grad/param norm = 1.8562e-01, time/batch = 0.6565s	
1557/25300 (epoch 3.077), train_loss = 1.81489750, grad/param norm = 2.3095e-01, time/batch = 0.6512s	
1558/25300 (epoch 3.079), train_loss = 1.80997967, grad/param norm = 2.4151e-01, time/batch = 0.6570s	
1559/25300 (epoch 3.081), train_loss = 1.71200062, grad/param norm = 2.1345e-01, time/batch = 0.6580s	
1560/25300 (epoch 3.083), train_loss = 1.58070325, grad/param norm = 2.3179e-01, time/batch = 0.6576s	
1561/25300 (epoch 3.085), train_loss = 1.91691807, grad/param norm = 2.3921e-01, time/batch = 0.6608s	
1562/25300 (epoch 3.087), train_loss = 1.74600574, grad/param norm = 2.3817e-01, time/batch = 0.6575s	
1563/25300 (epoch 3.089), train_loss = 1.66530286, grad/param norm = 2.3094e-01, time/batch = 0.6562s	
1564/25300 (epoch 3.091), train_loss = 1.74943283, grad/param norm = 2.2456e-01, time/batch = 0.6578s	
1565/25300 (epoch 3.093), train_loss = 1.97697450, grad/param norm = 2.3588e-01, time/batch = 0.6606s	
1566/25300 (epoch 3.095), train_loss = 1.75740970, grad/param norm = 2.0347e-01, time/batch = 0.6617s	
1567/25300 (epoch 3.097), train_loss = 1.68841085, grad/param norm = 2.0085e-01, time/batch = 0.6596s	
1568/25300 (epoch 3.099), train_loss = 1.73982511, grad/param norm = 2.3959e-01, time/batch = 0.6736s	
1569/25300 (epoch 3.101), train_loss = 1.68087588, grad/param norm = 2.3931e-01, time/batch = 0.6649s	
1570/25300 (epoch 3.103), train_loss = 1.69895400, grad/param norm = 2.1272e-01, time/batch = 0.6776s	
1571/25300 (epoch 3.105), train_loss = 1.78651124, grad/param norm = 2.3200e-01, time/batch = 0.6727s	
1572/25300 (epoch 3.107), train_loss = 1.83003913, grad/param norm = 2.2741e-01, time/batch = 0.6674s	
1573/25300 (epoch 3.109), train_loss = 1.82188383, grad/param norm = 2.6452e-01, time/batch = 0.6674s	
1574/25300 (epoch 3.111), train_loss = 1.64243342, grad/param norm = 2.2243e-01, time/batch = 0.6701s	
1575/25300 (epoch 3.113), train_loss = 1.74132992, grad/param norm = 2.4280e-01, time/batch = 0.6708s	
1576/25300 (epoch 3.115), train_loss = 1.71147036, grad/param norm = 2.2374e-01, time/batch = 0.6644s	
1577/25300 (epoch 3.117), train_loss = 1.77010632, grad/param norm = 2.3094e-01, time/batch = 0.6593s	
1578/25300 (epoch 3.119), train_loss = 1.75263073, grad/param norm = 2.7367e-01, time/batch = 0.6579s	
1579/25300 (epoch 3.121), train_loss = 1.90027331, grad/param norm = 2.4120e-01, time/batch = 0.6534s	
1580/25300 (epoch 3.123), train_loss = 1.71371790, grad/param norm = 2.4205e-01, time/batch = 0.6580s	
1581/25300 (epoch 3.125), train_loss = 1.76135039, grad/param norm = 2.5008e-01, time/batch = 0.6601s	
1582/25300 (epoch 3.126), train_loss = 1.70346648, grad/param norm = 2.2987e-01, time/batch = 0.6592s	
1583/25300 (epoch 3.128), train_loss = 1.74584776, grad/param norm = 2.3222e-01, time/batch = 0.6588s	
1584/25300 (epoch 3.130), train_loss = 1.41913461, grad/param norm = 2.0402e-01, time/batch = 0.6632s	
1585/25300 (epoch 3.132), train_loss = 1.60737334, grad/param norm = 2.0615e-01, time/batch = 0.6618s	
1586/25300 (epoch 3.134), train_loss = 1.40566311, grad/param norm = 2.0691e-01, time/batch = 0.6574s	
1587/25300 (epoch 3.136), train_loss = 1.76436645, grad/param norm = 2.3285e-01, time/batch = 0.6579s	
1588/25300 (epoch 3.138), train_loss = 1.56757126, grad/param norm = 2.1872e-01, time/batch = 0.6566s	
1589/25300 (epoch 3.140), train_loss = 1.54186923, grad/param norm = 2.0308e-01, time/batch = 0.6577s	
1590/25300 (epoch 3.142), train_loss = 1.77740744, grad/param norm = 2.2546e-01, time/batch = 0.6583s	
1591/25300 (epoch 3.144), train_loss = 1.66935023, grad/param norm = 2.4413e-01, time/batch = 0.6573s	
1592/25300 (epoch 3.146), train_loss = 1.86756322, grad/param norm = 2.8679e-01, time/batch = 0.6562s	
1593/25300 (epoch 3.148), train_loss = 1.88064515, grad/param norm = 2.7450e-01, time/batch = 0.6554s	
1594/25300 (epoch 3.150), train_loss = 1.85821798, grad/param norm = 2.3595e-01, time/batch = 0.6563s	
1595/25300 (epoch 3.152), train_loss = 1.99942141, grad/param norm = 2.3361e-01, time/batch = 0.6628s	
1596/25300 (epoch 3.154), train_loss = 1.67372801, grad/param norm = 2.1971e-01, time/batch = 0.6609s	
1597/25300 (epoch 3.156), train_loss = 1.78058676, grad/param norm = 2.1928e-01, time/batch = 0.6585s	
1598/25300 (epoch 3.158), train_loss = 1.75755811, grad/param norm = 2.4157e-01, time/batch = 0.6548s	
1599/25300 (epoch 3.160), train_loss = 1.74387294, grad/param norm = 2.7007e-01, time/batch = 0.6599s	
1600/25300 (epoch 3.162), train_loss = 1.66087806, grad/param norm = 2.5620e-01, time/batch = 0.6561s	
1601/25300 (epoch 3.164), train_loss = 1.74722460, grad/param norm = 2.3209e-01, time/batch = 0.6557s	
1602/25300 (epoch 3.166), train_loss = 1.79061783, grad/param norm = 2.3844e-01, time/batch = 0.6567s	
1603/25300 (epoch 3.168), train_loss = 1.54426104, grad/param norm = 2.5180e-01, time/batch = 0.6613s	
1604/25300 (epoch 3.170), train_loss = 1.64245770, grad/param norm = 2.4838e-01, time/batch = 0.6668s	
1605/25300 (epoch 3.172), train_loss = 1.59839552, grad/param norm = 2.5395e-01, time/batch = 0.6670s	
1606/25300 (epoch 3.174), train_loss = 1.58343802, grad/param norm = 2.3033e-01, time/batch = 0.6644s	
1607/25300 (epoch 3.176), train_loss = 1.73970414, grad/param norm = 2.3706e-01, time/batch = 0.6559s	
1608/25300 (epoch 3.178), train_loss = 1.92170350, grad/param norm = 2.4706e-01, time/batch = 0.6553s	
1609/25300 (epoch 3.180), train_loss = 1.52356876, grad/param norm = 2.0935e-01, time/batch = 0.6586s	
1610/25300 (epoch 3.182), train_loss = 1.71326847, grad/param norm = 2.3095e-01, time/batch = 0.6757s	
1611/25300 (epoch 3.184), train_loss = 1.70906837, grad/param norm = 2.1054e-01, time/batch = 0.6620s	
1612/25300 (epoch 3.186), train_loss = 1.78653633, grad/param norm = 2.4979e-01, time/batch = 0.6610s	
1613/25300 (epoch 3.188), train_loss = 1.63684230, grad/param norm = 2.3235e-01, time/batch = 0.6601s	
1614/25300 (epoch 3.190), train_loss = 1.73930300, grad/param norm = 2.1903e-01, time/batch = 0.6639s	
1615/25300 (epoch 3.192), train_loss = 1.79228357, grad/param norm = 2.4428e-01, time/batch = 0.6627s	
1616/25300 (epoch 3.194), train_loss = 1.66271731, grad/param norm = 2.1702e-01, time/batch = 0.6608s	
1617/25300 (epoch 3.196), train_loss = 1.73322883, grad/param norm = 2.3301e-01, time/batch = 0.6599s	
1618/25300 (epoch 3.198), train_loss = 1.70454778, grad/param norm = 2.2220e-01, time/batch = 0.6580s	
1619/25300 (epoch 3.200), train_loss = 1.76238895, grad/param norm = 2.1301e-01, time/batch = 0.6613s	
1620/25300 (epoch 3.202), train_loss = 1.76607857, grad/param norm = 2.1662e-01, time/batch = 0.6569s	
1621/25300 (epoch 3.204), train_loss = 1.67094029, grad/param norm = 2.3866e-01, time/batch = 0.6596s	
1622/25300 (epoch 3.206), train_loss = 1.76265564, grad/param norm = 2.5011e-01, time/batch = 0.6620s	
1623/25300 (epoch 3.208), train_loss = 1.58911723, grad/param norm = 2.3498e-01, time/batch = 0.6617s	
1624/25300 (epoch 3.209), train_loss = 1.50463018, grad/param norm = 2.5555e-01, time/batch = 0.6605s	
1625/25300 (epoch 3.211), train_loss = 1.71476839, grad/param norm = 2.3882e-01, time/batch = 0.6573s	
1626/25300 (epoch 3.213), train_loss = 1.76252241, grad/param norm = 2.5256e-01, time/batch = 0.6566s	
1627/25300 (epoch 3.215), train_loss = 1.71627784, grad/param norm = 2.4411e-01, time/batch = 0.6562s	
1628/25300 (epoch 3.217), train_loss = 1.79532380, grad/param norm = 2.5100e-01, time/batch = 0.6525s	
1629/25300 (epoch 3.219), train_loss = 1.67978071, grad/param norm = 2.0819e-01, time/batch = 0.6551s	
1630/25300 (epoch 3.221), train_loss = 1.85184943, grad/param norm = 2.2767e-01, time/batch = 0.6558s	
1631/25300 (epoch 3.223), train_loss = 1.78645843, grad/param norm = 2.3303e-01, time/batch = 0.6644s	
1632/25300 (epoch 3.225), train_loss = 2.10510674, grad/param norm = 2.8173e-01, time/batch = 0.6598s	
1633/25300 (epoch 3.227), train_loss = 1.74062239, grad/param norm = 2.1623e-01, time/batch = 0.6582s	
1634/25300 (epoch 3.229), train_loss = 1.82303151, grad/param norm = 2.1076e-01, time/batch = 0.6563s	
1635/25300 (epoch 3.231), train_loss = 1.78300201, grad/param norm = 2.6561e-01, time/batch = 0.6587s	
1636/25300 (epoch 3.233), train_loss = 1.75737916, grad/param norm = 2.3629e-01, time/batch = 0.6598s	
1637/25300 (epoch 3.235), train_loss = 1.68836504, grad/param norm = 2.2680e-01, time/batch = 0.6592s	
1638/25300 (epoch 3.237), train_loss = 1.87612777, grad/param norm = 2.3706e-01, time/batch = 0.6602s	
1639/25300 (epoch 3.239), train_loss = 1.71085635, grad/param norm = 2.5215e-01, time/batch = 0.6576s	
1640/25300 (epoch 3.241), train_loss = 1.81196275, grad/param norm = 2.3206e-01, time/batch = 0.6550s	
1641/25300 (epoch 3.243), train_loss = 2.06602285, grad/param norm = 2.7684e-01, time/batch = 0.6576s	
1642/25300 (epoch 3.245), train_loss = 1.61665042, grad/param norm = 2.4788e-01, time/batch = 0.6594s	
1643/25300 (epoch 3.247), train_loss = 1.87502720, grad/param norm = 2.5536e-01, time/batch = 0.6566s	
1644/25300 (epoch 3.249), train_loss = 1.63135943, grad/param norm = 2.4298e-01, time/batch = 0.6573s	
1645/25300 (epoch 3.251), train_loss = 1.51177243, grad/param norm = 2.1999e-01, time/batch = 0.6562s	
1646/25300 (epoch 3.253), train_loss = 1.64565323, grad/param norm = 2.2304e-01, time/batch = 0.6557s	
1647/25300 (epoch 3.255), train_loss = 1.65174583, grad/param norm = 2.1986e-01, time/batch = 0.6574s	
1648/25300 (epoch 3.257), train_loss = 1.92068002, grad/param norm = 2.4763e-01, time/batch = 0.6567s	
1649/25300 (epoch 3.259), train_loss = 2.06393527, grad/param norm = 2.3584e-01, time/batch = 0.6619s	
1650/25300 (epoch 3.261), train_loss = 1.88659687, grad/param norm = 2.4199e-01, time/batch = 0.6563s	
1651/25300 (epoch 3.263), train_loss = 1.80405757, grad/param norm = 2.1603e-01, time/batch = 0.6615s	
1652/25300 (epoch 3.265), train_loss = 1.86279031, grad/param norm = 2.4401e-01, time/batch = 0.6600s	
1653/25300 (epoch 3.267), train_loss = 1.84656997, grad/param norm = 2.2775e-01, time/batch = 0.6552s	
1654/25300 (epoch 3.269), train_loss = 1.58961242, grad/param norm = 2.1686e-01, time/batch = 0.6581s	
1655/25300 (epoch 3.271), train_loss = 1.57231569, grad/param norm = 2.3592e-01, time/batch = 0.6586s	
1656/25300 (epoch 3.273), train_loss = 1.76798475, grad/param norm = 2.5330e-01, time/batch = 0.6582s	
1657/25300 (epoch 3.275), train_loss = 1.51785540, grad/param norm = 2.2150e-01, time/batch = 0.6589s	
1658/25300 (epoch 3.277), train_loss = 1.66437907, grad/param norm = 2.2715e-01, time/batch = 0.6595s	
1659/25300 (epoch 3.279), train_loss = 1.75587447, grad/param norm = 2.4532e-01, time/batch = 0.6598s	
1660/25300 (epoch 3.281), train_loss = 1.89035741, grad/param norm = 2.6112e-01, time/batch = 0.6586s	
1661/25300 (epoch 3.283), train_loss = 1.62678720, grad/param norm = 2.3396e-01, time/batch = 0.6604s	
1662/25300 (epoch 3.285), train_loss = 1.69454821, grad/param norm = 2.2342e-01, time/batch = 0.6591s	
1663/25300 (epoch 3.287), train_loss = 1.66478676, grad/param norm = 1.9826e-01, time/batch = 0.6583s	
1664/25300 (epoch 3.289), train_loss = 1.67094581, grad/param norm = 1.9314e-01, time/batch = 0.6642s	
1665/25300 (epoch 3.291), train_loss = 1.53273432, grad/param norm = 2.1909e-01, time/batch = 0.6636s	
1666/25300 (epoch 3.292), train_loss = 1.81580518, grad/param norm = 2.3225e-01, time/batch = 0.6605s	
1667/25300 (epoch 3.294), train_loss = 1.68300094, grad/param norm = 2.3771e-01, time/batch = 0.6564s	
1668/25300 (epoch 3.296), train_loss = 1.60360039, grad/param norm = 2.2684e-01, time/batch = 0.6611s	
1669/25300 (epoch 3.298), train_loss = 1.83260437, grad/param norm = 2.2452e-01, time/batch = 0.6511s	
1670/25300 (epoch 3.300), train_loss = 1.97704407, grad/param norm = 2.4425e-01, time/batch = 0.6546s	
1671/25300 (epoch 3.302), train_loss = 1.51890684, grad/param norm = 2.3302e-01, time/batch = 0.6574s	
1672/25300 (epoch 3.304), train_loss = 1.83797191, grad/param norm = 2.6485e-01, time/batch = 0.6564s	
1673/25300 (epoch 3.306), train_loss = 1.41746766, grad/param norm = 2.0612e-01, time/batch = 0.6571s	
1674/25300 (epoch 3.308), train_loss = 1.72182899, grad/param norm = 1.9881e-01, time/batch = 0.6615s	
1675/25300 (epoch 3.310), train_loss = 1.67527174, grad/param norm = 2.1077e-01, time/batch = 0.6588s	
1676/25300 (epoch 3.312), train_loss = 1.72126231, grad/param norm = 2.2707e-01, time/batch = 0.6628s	
1677/25300 (epoch 3.314), train_loss = 1.53466600, grad/param norm = 2.2701e-01, time/batch = 0.6569s	
1678/25300 (epoch 3.316), train_loss = 1.72507430, grad/param norm = 2.2202e-01, time/batch = 0.6551s	
1679/25300 (epoch 3.318), train_loss = 1.42030789, grad/param norm = 2.2248e-01, time/batch = 0.6563s	
1680/25300 (epoch 3.320), train_loss = 1.62981511, grad/param norm = 2.4628e-01, time/batch = 0.6572s	
1681/25300 (epoch 3.322), train_loss = 1.97766556, grad/param norm = 2.3948e-01, time/batch = 0.6589s	
1682/25300 (epoch 3.324), train_loss = 1.57752160, grad/param norm = 2.2376e-01, time/batch = 0.6606s	
1683/25300 (epoch 3.326), train_loss = 1.41218520, grad/param norm = 1.9114e-01, time/batch = 0.6616s	
1684/25300 (epoch 3.328), train_loss = 1.57079777, grad/param norm = 2.3383e-01, time/batch = 0.6596s	
1685/25300 (epoch 3.330), train_loss = 1.59045761, grad/param norm = 2.1582e-01, time/batch = 0.6610s	
1686/25300 (epoch 3.332), train_loss = 1.73624881, grad/param norm = 2.1304e-01, time/batch = 0.6596s	
1687/25300 (epoch 3.334), train_loss = 1.67718188, grad/param norm = 2.1677e-01, time/batch = 0.6627s	
1688/25300 (epoch 3.336), train_loss = 1.53664719, grad/param norm = 2.1121e-01, time/batch = 0.6623s	
1689/25300 (epoch 3.338), train_loss = 1.56711717, grad/param norm = 2.3107e-01, time/batch = 0.6591s	
1690/25300 (epoch 3.340), train_loss = 1.62542937, grad/param norm = 2.4478e-01, time/batch = 0.6593s	
1691/25300 (epoch 3.342), train_loss = 1.60478551, grad/param norm = 2.4650e-01, time/batch = 0.6600s	
1692/25300 (epoch 3.344), train_loss = 1.62484976, grad/param norm = 2.4074e-01, time/batch = 0.6549s	
1693/25300 (epoch 3.346), train_loss = 1.65943389, grad/param norm = 2.6015e-01, time/batch = 0.6606s	
1694/25300 (epoch 3.348), train_loss = 1.49944533, grad/param norm = 2.4172e-01, time/batch = 0.6686s	
1695/25300 (epoch 3.350), train_loss = 1.61665244, grad/param norm = 2.2120e-01, time/batch = 0.6710s	
1696/25300 (epoch 3.352), train_loss = 1.71294182, grad/param norm = 2.1502e-01, time/batch = 0.6755s	
1697/25300 (epoch 3.354), train_loss = 1.63686451, grad/param norm = 2.3104e-01, time/batch = 0.6687s	
1698/25300 (epoch 3.356), train_loss = 1.71259879, grad/param norm = 2.3315e-01, time/batch = 0.6843s	
1699/25300 (epoch 3.358), train_loss = 1.82681791, grad/param norm = 2.7910e-01, time/batch = 0.6710s	
1700/25300 (epoch 3.360), train_loss = 1.64418715, grad/param norm = 2.1389e-01, time/batch = 0.6637s	
1701/25300 (epoch 3.362), train_loss = 1.84068360, grad/param norm = 2.2106e-01, time/batch = 0.6724s	
1702/25300 (epoch 3.364), train_loss = 1.82954103, grad/param norm = 2.5550e-01, time/batch = 0.6654s	
1703/25300 (epoch 3.366), train_loss = 1.52802208, grad/param norm = 2.2960e-01, time/batch = 0.6669s	
1704/25300 (epoch 3.368), train_loss = 1.72968106, grad/param norm = 2.0848e-01, time/batch = 0.6648s	
1705/25300 (epoch 3.370), train_loss = 1.69448419, grad/param norm = 2.6475e-01, time/batch = 0.6602s	
1706/25300 (epoch 3.372), train_loss = 1.72355710, grad/param norm = 2.8334e-01, time/batch = 0.6533s	
1707/25300 (epoch 3.374), train_loss = 1.55123530, grad/param norm = 2.3676e-01, time/batch = 0.6543s	
1708/25300 (epoch 3.375), train_loss = 1.91165405, grad/param norm = 2.5344e-01, time/batch = 0.6528s	
1709/25300 (epoch 3.377), train_loss = 1.58950868, grad/param norm = 2.2198e-01, time/batch = 0.6538s	
1710/25300 (epoch 3.379), train_loss = 2.01858122, grad/param norm = 2.5300e-01, time/batch = 0.6591s	
1711/25300 (epoch 3.381), train_loss = 1.63416741, grad/param norm = 1.9812e-01, time/batch = 0.6655s	
1712/25300 (epoch 3.383), train_loss = 1.53803832, grad/param norm = 2.1649e-01, time/batch = 0.6646s	
1713/25300 (epoch 3.385), train_loss = 1.59838098, grad/param norm = 2.2358e-01, time/batch = 0.6647s	
1714/25300 (epoch 3.387), train_loss = 1.85461111, grad/param norm = 2.4095e-01, time/batch = 0.6675s	
1715/25300 (epoch 3.389), train_loss = 1.89109481, grad/param norm = 2.3386e-01, time/batch = 0.6667s	
1716/25300 (epoch 3.391), train_loss = 1.49934328, grad/param norm = 2.3392e-01, time/batch = 0.6578s	
1717/25300 (epoch 3.393), train_loss = 1.78212523, grad/param norm = 2.4953e-01, time/batch = 0.6593s	
1718/25300 (epoch 3.395), train_loss = 1.47984948, grad/param norm = 2.1001e-01, time/batch = 0.6624s	
1719/25300 (epoch 3.397), train_loss = 1.53750925, grad/param norm = 2.1419e-01, time/batch = 0.6525s	
1720/25300 (epoch 3.399), train_loss = 1.56646730, grad/param norm = 2.0855e-01, time/batch = 0.6571s	
1721/25300 (epoch 3.401), train_loss = 1.75875728, grad/param norm = 2.1615e-01, time/batch = 0.6634s	
1722/25300 (epoch 3.403), train_loss = 1.65597979, grad/param norm = 2.4750e-01, time/batch = 0.6620s	
1723/25300 (epoch 3.405), train_loss = 1.75853253, grad/param norm = 2.5624e-01, time/batch = 0.6616s	
1724/25300 (epoch 3.407), train_loss = 1.55853032, grad/param norm = 2.1357e-01, time/batch = 0.6643s	
1725/25300 (epoch 3.409), train_loss = 1.59941941, grad/param norm = 2.2290e-01, time/batch = 0.6594s	
1726/25300 (epoch 3.411), train_loss = 1.65485299, grad/param norm = 2.4006e-01, time/batch = 0.6594s	
1727/25300 (epoch 3.413), train_loss = 1.59646448, grad/param norm = 2.3803e-01, time/batch = 0.6592s	
1728/25300 (epoch 3.415), train_loss = 1.59213042, grad/param norm = 2.3718e-01, time/batch = 0.6546s	
1729/25300 (epoch 3.417), train_loss = 1.61225228, grad/param norm = 2.5116e-01, time/batch = 0.6560s	
1730/25300 (epoch 3.419), train_loss = 1.48775144, grad/param norm = 2.1279e-01, time/batch = 0.6561s	
1731/25300 (epoch 3.421), train_loss = 1.52164546, grad/param norm = 2.0572e-01, time/batch = 0.6579s	
1732/25300 (epoch 3.423), train_loss = 1.55347538, grad/param norm = 2.0916e-01, time/batch = 0.6590s	
1733/25300 (epoch 3.425), train_loss = 1.66376333, grad/param norm = 2.6977e-01, time/batch = 0.6603s	
1734/25300 (epoch 3.427), train_loss = 1.85339118, grad/param norm = 2.3834e-01, time/batch = 0.6577s	
1735/25300 (epoch 3.429), train_loss = 1.77375222, grad/param norm = 2.4259e-01, time/batch = 0.6563s	
1736/25300 (epoch 3.431), train_loss = 1.74855967, grad/param norm = 2.6292e-01, time/batch = 0.6574s	
1737/25300 (epoch 3.433), train_loss = 1.67639534, grad/param norm = 2.4813e-01, time/batch = 0.6601s	
1738/25300 (epoch 3.435), train_loss = 1.50895811, grad/param norm = 2.2999e-01, time/batch = 0.6583s	
1739/25300 (epoch 3.437), train_loss = 1.65252474, grad/param norm = 2.2457e-01, time/batch = 0.6576s	
1740/25300 (epoch 3.439), train_loss = 1.69441182, grad/param norm = 2.4982e-01, time/batch = 0.6585s	
1741/25300 (epoch 3.441), train_loss = 1.66961967, grad/param norm = 2.2057e-01, time/batch = 0.6596s	
1742/25300 (epoch 3.443), train_loss = 1.81674423, grad/param norm = 2.5094e-01, time/batch = 0.6600s	
1743/25300 (epoch 3.445), train_loss = 1.77024238, grad/param norm = 2.3328e-01, time/batch = 0.6563s	
1744/25300 (epoch 3.447), train_loss = 1.53280612, grad/param norm = 2.1751e-01, time/batch = 0.6584s	
1745/25300 (epoch 3.449), train_loss = 1.56602982, grad/param norm = 2.0238e-01, time/batch = 0.6574s	
1746/25300 (epoch 3.451), train_loss = 1.86009697, grad/param norm = 2.2922e-01, time/batch = 0.6596s	
1747/25300 (epoch 3.453), train_loss = 1.69401868, grad/param norm = 2.3545e-01, time/batch = 0.6592s	
1748/25300 (epoch 3.455), train_loss = 1.82361396, grad/param norm = 2.2263e-01, time/batch = 0.6595s	
1749/25300 (epoch 3.457), train_loss = 1.65700399, grad/param norm = 2.4135e-01, time/batch = 0.6593s	
1750/25300 (epoch 3.458), train_loss = 1.79747251, grad/param norm = 2.7419e-01, time/batch = 0.6587s	
1751/25300 (epoch 3.460), train_loss = 1.86224755, grad/param norm = 2.3750e-01, time/batch = 0.6639s	
1752/25300 (epoch 3.462), train_loss = 1.50598183, grad/param norm = 2.5241e-01, time/batch = 0.6606s	
1753/25300 (epoch 3.464), train_loss = 1.73838637, grad/param norm = 2.8424e-01, time/batch = 0.6614s	
1754/25300 (epoch 3.466), train_loss = 1.69066411, grad/param norm = 2.4068e-01, time/batch = 0.6602s	
1755/25300 (epoch 3.468), train_loss = 1.86893701, grad/param norm = 2.4332e-01, time/batch = 0.6600s	
1756/25300 (epoch 3.470), train_loss = 1.58440793, grad/param norm = 2.1971e-01, time/batch = 0.6594s	
1757/25300 (epoch 3.472), train_loss = 1.46467931, grad/param norm = 2.1791e-01, time/batch = 0.6597s	
1758/25300 (epoch 3.474), train_loss = 1.68395529, grad/param norm = 2.4569e-01, time/batch = 0.6607s	
1759/25300 (epoch 3.476), train_loss = 1.72630972, grad/param norm = 2.3942e-01, time/batch = 0.6593s	
1760/25300 (epoch 3.478), train_loss = 1.73445658, grad/param norm = 2.1278e-01, time/batch = 0.6545s	
1761/25300 (epoch 3.480), train_loss = 1.48143166, grad/param norm = 2.1712e-01, time/batch = 0.6581s	
1762/25300 (epoch 3.482), train_loss = 1.84635044, grad/param norm = 2.5434e-01, time/batch = 0.6627s	
1763/25300 (epoch 3.484), train_loss = 1.83516065, grad/param norm = 2.2756e-01, time/batch = 0.6588s	
1764/25300 (epoch 3.486), train_loss = 1.67379102, grad/param norm = 2.1729e-01, time/batch = 0.6582s	
1765/25300 (epoch 3.488), train_loss = 1.73474811, grad/param norm = 2.1750e-01, time/batch = 0.6612s	
1766/25300 (epoch 3.490), train_loss = 1.78129106, grad/param norm = 2.2694e-01, time/batch = 0.6593s	
1767/25300 (epoch 3.492), train_loss = 1.58383079, grad/param norm = 2.0904e-01, time/batch = 0.6606s	
1768/25300 (epoch 3.494), train_loss = 1.52025661, grad/param norm = 2.2889e-01, time/batch = 0.6624s	
1769/25300 (epoch 3.496), train_loss = 1.70011461, grad/param norm = 2.3545e-01, time/batch = 0.6579s	
1770/25300 (epoch 3.498), train_loss = 1.55511313, grad/param norm = 2.2266e-01, time/batch = 0.6584s	
1771/25300 (epoch 3.500), train_loss = 1.86730415, grad/param norm = 2.6106e-01, time/batch = 0.6645s	
1772/25300 (epoch 3.502), train_loss = 1.62767268, grad/param norm = 2.3121e-01, time/batch = 0.6607s	
1773/25300 (epoch 3.504), train_loss = 1.62027075, grad/param norm = 2.2890e-01, time/batch = 0.6578s	
1774/25300 (epoch 3.506), train_loss = 1.70019574, grad/param norm = 2.3533e-01, time/batch = 0.6593s	
1775/25300 (epoch 3.508), train_loss = 1.71634611, grad/param norm = 2.1493e-01, time/batch = 0.6559s	
1776/25300 (epoch 3.510), train_loss = 1.64153370, grad/param norm = 2.3962e-01, time/batch = 0.6563s	
1777/25300 (epoch 3.512), train_loss = 1.32980147, grad/param norm = 1.7723e-01, time/batch = 0.6571s	
1778/25300 (epoch 3.514), train_loss = 1.51527914, grad/param norm = 2.2046e-01, time/batch = 0.6576s	
1779/25300 (epoch 3.516), train_loss = 1.60847049, grad/param norm = 2.2070e-01, time/batch = 0.6535s	
1780/25300 (epoch 3.518), train_loss = 1.79343708, grad/param norm = 2.7035e-01, time/batch = 0.6563s	
1781/25300 (epoch 3.520), train_loss = 1.46723788, grad/param norm = 2.7944e-01, time/batch = 0.6571s	
1782/25300 (epoch 3.522), train_loss = 1.55578328, grad/param norm = 2.0021e-01, time/batch = 0.6558s	
1783/25300 (epoch 3.524), train_loss = 1.54342089, grad/param norm = 2.0364e-01, time/batch = 0.6586s	
1784/25300 (epoch 3.526), train_loss = 1.86983596, grad/param norm = 2.8408e-01, time/batch = 0.6662s	
1785/25300 (epoch 3.528), train_loss = 1.82222393, grad/param norm = 2.8395e-01, time/batch = 0.6669s	
1786/25300 (epoch 3.530), train_loss = 1.61152282, grad/param norm = 2.3971e-01, time/batch = 0.6771s	
1787/25300 (epoch 3.532), train_loss = 1.72521674, grad/param norm = 2.3113e-01, time/batch = 0.6628s	
1788/25300 (epoch 3.534), train_loss = 1.59467302, grad/param norm = 2.1668e-01, time/batch = 0.6613s	
1789/25300 (epoch 3.536), train_loss = 1.55802875, grad/param norm = 2.4672e-01, time/batch = 0.6571s	
1790/25300 (epoch 3.538), train_loss = 1.49890866, grad/param norm = 2.2084e-01, time/batch = 0.6549s	
1791/25300 (epoch 3.540), train_loss = 1.62674114, grad/param norm = 2.4375e-01, time/batch = 0.6677s	
1792/25300 (epoch 3.542), train_loss = 1.49312863, grad/param norm = 2.2409e-01, time/batch = 0.6701s	
1793/25300 (epoch 3.543), train_loss = 1.46947039, grad/param norm = 2.1349e-01, time/batch = 0.6591s	
1794/25300 (epoch 3.545), train_loss = 2.08323541, grad/param norm = 2.3372e-01, time/batch = 0.6537s	
1795/25300 (epoch 3.547), train_loss = 1.54496666, grad/param norm = 2.1043e-01, time/batch = 0.6628s	
1796/25300 (epoch 3.549), train_loss = 1.93252333, grad/param norm = 2.5224e-01, time/batch = 0.6725s	
1797/25300 (epoch 3.551), train_loss = 1.68600818, grad/param norm = 2.5675e-01, time/batch = 0.6646s	
1798/25300 (epoch 3.553), train_loss = 1.75118284, grad/param norm = 2.2587e-01, time/batch = 0.6524s	
1799/25300 (epoch 3.555), train_loss = 1.79649647, grad/param norm = 2.3431e-01, time/batch = 0.6548s	
1800/25300 (epoch 3.557), train_loss = 1.80622263, grad/param norm = 2.3135e-01, time/batch = 0.6580s	
1801/25300 (epoch 3.559), train_loss = 1.76922912, grad/param norm = 2.3451e-01, time/batch = 0.6591s	
1802/25300 (epoch 3.561), train_loss = 1.84693815, grad/param norm = 2.3299e-01, time/batch = 0.6564s	
1803/25300 (epoch 3.563), train_loss = 1.68809677, grad/param norm = 2.0016e-01, time/batch = 0.6555s	
1804/25300 (epoch 3.565), train_loss = 1.53505259, grad/param norm = 2.1129e-01, time/batch = 0.6568s	
1805/25300 (epoch 3.567), train_loss = 1.30723578, grad/param norm = 2.1318e-01, time/batch = 0.6536s	
1806/25300 (epoch 3.569), train_loss = 1.62578767, grad/param norm = 2.2370e-01, time/batch = 0.6561s	
1807/25300 (epoch 3.571), train_loss = 1.73078070, grad/param norm = 2.2087e-01, time/batch = 0.6545s	
1808/25300 (epoch 3.573), train_loss = 1.69646296, grad/param norm = 2.1697e-01, time/batch = 0.6549s	
1809/25300 (epoch 3.575), train_loss = 1.72065769, grad/param norm = 2.1037e-01, time/batch = 0.6542s	
1810/25300 (epoch 3.577), train_loss = 1.74030816, grad/param norm = 2.4635e-01, time/batch = 0.6549s	
1811/25300 (epoch 3.579), train_loss = 1.87953502, grad/param norm = 2.3533e-01, time/batch = 0.6567s	
1812/25300 (epoch 3.581), train_loss = 1.67649555, grad/param norm = 2.0386e-01, time/batch = 0.6548s	
1813/25300 (epoch 3.583), train_loss = 1.53073133, grad/param norm = 2.1441e-01, time/batch = 0.6600s	
1814/25300 (epoch 3.585), train_loss = 1.54799752, grad/param norm = 2.2558e-01, time/batch = 0.6646s	
1815/25300 (epoch 3.587), train_loss = 1.61464696, grad/param norm = 2.3041e-01, time/batch = 0.6593s	
1816/25300 (epoch 3.589), train_loss = 1.46710126, grad/param norm = 1.9941e-01, time/batch = 0.6588s	
1817/25300 (epoch 3.591), train_loss = 1.54572012, grad/param norm = 2.3981e-01, time/batch = 0.6566s	
1818/25300 (epoch 3.593), train_loss = 1.53735258, grad/param norm = 2.0626e-01, time/batch = 0.6589s	
1819/25300 (epoch 3.595), train_loss = 1.65662891, grad/param norm = 2.1932e-01, time/batch = 0.6720s	
1820/25300 (epoch 3.597), train_loss = 1.45797803, grad/param norm = 2.1219e-01, time/batch = 0.6668s	
1821/25300 (epoch 3.599), train_loss = 1.59396688, grad/param norm = 2.2832e-01, time/batch = 0.6603s	
1822/25300 (epoch 3.601), train_loss = 1.70676619, grad/param norm = 2.5095e-01, time/batch = 0.6584s	
1823/25300 (epoch 3.603), train_loss = 1.67016842, grad/param norm = 2.1777e-01, time/batch = 0.6665s	
1824/25300 (epoch 3.605), train_loss = 1.59239257, grad/param norm = 2.1143e-01, time/batch = 0.6559s	
1825/25300 (epoch 3.607), train_loss = 1.53841088, grad/param norm = 2.2234e-01, time/batch = 0.6555s	
1826/25300 (epoch 3.609), train_loss = 1.64463182, grad/param norm = 2.2871e-01, time/batch = 0.6566s	
1827/25300 (epoch 3.611), train_loss = 1.80540033, grad/param norm = 2.2533e-01, time/batch = 0.6754s	
1828/25300 (epoch 3.613), train_loss = 1.62778050, grad/param norm = 2.4711e-01, time/batch = 0.6688s	
1829/25300 (epoch 3.615), train_loss = 1.71572553, grad/param norm = 2.2138e-01, time/batch = 0.6691s	
1830/25300 (epoch 3.617), train_loss = 1.63473873, grad/param norm = 2.0003e-01, time/batch = 0.6704s	
1831/25300 (epoch 3.619), train_loss = 1.70267126, grad/param norm = 2.3317e-01, time/batch = 0.6732s	
1832/25300 (epoch 3.621), train_loss = 1.74752230, grad/param norm = 2.4751e-01, time/batch = 0.6757s	
1833/25300 (epoch 3.623), train_loss = 1.60073266, grad/param norm = 2.2777e-01, time/batch = 0.6798s	
1834/25300 (epoch 3.625), train_loss = 1.48245548, grad/param norm = 2.4150e-01, time/batch = 0.6815s	
1835/25300 (epoch 3.626), train_loss = 1.62121063, grad/param norm = 2.4226e-01, time/batch = 0.6813s	
1836/25300 (epoch 3.628), train_loss = 1.80532683, grad/param norm = 2.5053e-01, time/batch = 0.6738s	
1837/25300 (epoch 3.630), train_loss = 1.77477324, grad/param norm = 2.3498e-01, time/batch = 0.6726s	
1838/25300 (epoch 3.632), train_loss = 1.80865203, grad/param norm = 2.5594e-01, time/batch = 0.6593s	
1839/25300 (epoch 3.634), train_loss = 1.86407952, grad/param norm = 2.2122e-01, time/batch = 0.6593s	
1840/25300 (epoch 3.636), train_loss = 1.70181577, grad/param norm = 2.3198e-01, time/batch = 0.6576s	
1841/25300 (epoch 3.638), train_loss = 1.77970538, grad/param norm = 2.4920e-01, time/batch = 0.6573s	
1842/25300 (epoch 3.640), train_loss = 1.90212964, grad/param norm = 2.4440e-01, time/batch = 0.6582s	
1843/25300 (epoch 3.642), train_loss = 1.75318576, grad/param norm = 2.3559e-01, time/batch = 0.6559s	
1844/25300 (epoch 3.644), train_loss = 1.81675210, grad/param norm = 2.4568e-01, time/batch = 0.6595s	
1845/25300 (epoch 3.646), train_loss = 1.72463457, grad/param norm = 2.1253e-01, time/batch = 0.6592s	
1846/25300 (epoch 3.648), train_loss = 1.79522236, grad/param norm = 2.0790e-01, time/batch = 0.6582s	
1847/25300 (epoch 3.650), train_loss = 1.75796178, grad/param norm = 2.2280e-01, time/batch = 0.6582s	
1848/25300 (epoch 3.652), train_loss = 1.88057896, grad/param norm = 2.2491e-01, time/batch = 0.6607s	
1849/25300 (epoch 3.654), train_loss = 1.85768442, grad/param norm = 2.4213e-01, time/batch = 0.6576s	
1850/25300 (epoch 3.656), train_loss = 1.89547127, grad/param norm = 2.6834e-01, time/batch = 0.6591s	
1851/25300 (epoch 3.658), train_loss = 1.55427202, grad/param norm = 2.5210e-01, time/batch = 0.6614s	
1852/25300 (epoch 3.660), train_loss = 1.52443066, grad/param norm = 2.1387e-01, time/batch = 0.6594s	
1853/25300 (epoch 3.662), train_loss = 1.45864206, grad/param norm = 2.3133e-01, time/batch = 0.6592s	
1854/25300 (epoch 3.664), train_loss = 1.41229359, grad/param norm = 1.9781e-01, time/batch = 0.6595s	
1855/25300 (epoch 3.666), train_loss = 1.48008557, grad/param norm = 2.3635e-01, time/batch = 0.6580s	
1856/25300 (epoch 3.668), train_loss = 1.55272150, grad/param norm = 2.4425e-01, time/batch = 0.6610s	
1857/25300 (epoch 3.670), train_loss = 1.61869295, grad/param norm = 2.2715e-01, time/batch = 0.6564s	
1858/25300 (epoch 3.672), train_loss = 1.64456876, grad/param norm = 2.4396e-01, time/batch = 0.6599s	
1859/25300 (epoch 3.674), train_loss = 1.62097185, grad/param norm = 1.9837e-01, time/batch = 0.6612s	
1860/25300 (epoch 3.676), train_loss = 1.72040791, grad/param norm = 2.2409e-01, time/batch = 0.6663s	
1861/25300 (epoch 3.678), train_loss = 1.66968397, grad/param norm = 2.9159e-01, time/batch = 0.6585s	
1862/25300 (epoch 3.680), train_loss = 1.49140393, grad/param norm = 2.1691e-01, time/batch = 0.6587s	
1863/25300 (epoch 3.682), train_loss = 1.31427725, grad/param norm = 2.1515e-01, time/batch = 0.6585s	
1864/25300 (epoch 3.684), train_loss = 1.44801767, grad/param norm = 2.0283e-01, time/batch = 0.6572s	
1865/25300 (epoch 3.686), train_loss = 1.55559678, grad/param norm = 2.3638e-01, time/batch = 0.6583s	
1866/25300 (epoch 3.688), train_loss = 1.72866518, grad/param norm = 2.1356e-01, time/batch = 0.6586s	
1867/25300 (epoch 3.690), train_loss = 1.62102425, grad/param norm = 2.0362e-01, time/batch = 0.6599s	
1868/25300 (epoch 3.692), train_loss = 1.70328104, grad/param norm = 2.0453e-01, time/batch = 0.6640s	
1869/25300 (epoch 3.694), train_loss = 1.49749529, grad/param norm = 1.9276e-01, time/batch = 0.6541s	
1870/25300 (epoch 3.696), train_loss = 1.61074002, grad/param norm = 2.0876e-01, time/batch = 0.6546s	
1871/25300 (epoch 3.698), train_loss = 1.64943053, grad/param norm = 2.1289e-01, time/batch = 0.6630s	
1872/25300 (epoch 3.700), train_loss = 1.41597575, grad/param norm = 2.1694e-01, time/batch = 0.6609s	
1873/25300 (epoch 3.702), train_loss = 1.82878483, grad/param norm = 2.3078e-01, time/batch = 0.6590s	
1874/25300 (epoch 3.704), train_loss = 1.40279328, grad/param norm = 2.0062e-01, time/batch = 0.6799s	
1875/25300 (epoch 3.706), train_loss = 1.61105139, grad/param norm = 2.4882e-01, time/batch = 0.6707s	
1876/25300 (epoch 3.708), train_loss = 1.37771473, grad/param norm = 2.2034e-01, time/batch = 0.6702s	
1877/25300 (epoch 3.709), train_loss = 1.79844840, grad/param norm = 2.2919e-01, time/batch = 0.6677s	
1878/25300 (epoch 3.711), train_loss = 1.86518279, grad/param norm = 2.3378e-01, time/batch = 0.6551s	
1879/25300 (epoch 3.713), train_loss = 1.61796869, grad/param norm = 2.2600e-01, time/batch = 0.6563s	
1880/25300 (epoch 3.715), train_loss = 1.56610601, grad/param norm = 2.2848e-01, time/batch = 0.6562s	
1881/25300 (epoch 3.717), train_loss = 1.70801890, grad/param norm = 2.4452e-01, time/batch = 0.6576s	
1882/25300 (epoch 3.719), train_loss = 1.58707507, grad/param norm = 2.3949e-01, time/batch = 0.6600s	
1883/25300 (epoch 3.721), train_loss = 1.59317258, grad/param norm = 2.3911e-01, time/batch = 0.6542s	
1884/25300 (epoch 3.723), train_loss = 1.47608497, grad/param norm = 1.9888e-01, time/batch = 0.6599s	
1885/25300 (epoch 3.725), train_loss = 1.63305826, grad/param norm = 2.6324e-01, time/batch = 0.6694s	
1886/25300 (epoch 3.727), train_loss = 1.55875999, grad/param norm = 2.4244e-01, time/batch = 0.6575s	
1887/25300 (epoch 3.729), train_loss = 1.55928798, grad/param norm = 2.1991e-01, time/batch = 0.6596s	
1888/25300 (epoch 3.731), train_loss = 1.85139997, grad/param norm = 2.4811e-01, time/batch = 0.6581s	
1889/25300 (epoch 3.733), train_loss = 1.45545328, grad/param norm = 1.8551e-01, time/batch = 0.6583s	
1890/25300 (epoch 3.735), train_loss = 1.91428019, grad/param norm = 2.5337e-01, time/batch = 0.6582s	
1891/25300 (epoch 3.737), train_loss = 1.45759106, grad/param norm = 2.3079e-01, time/batch = 0.6679s	
1892/25300 (epoch 3.739), train_loss = 1.69395173, grad/param norm = 2.2993e-01, time/batch = 0.6587s	
1893/25300 (epoch 3.741), train_loss = 1.66297491, grad/param norm = 2.1518e-01, time/batch = 0.6566s	
1894/25300 (epoch 3.743), train_loss = 1.54021647, grad/param norm = 2.1354e-01, time/batch = 0.6563s	
1895/25300 (epoch 3.745), train_loss = 1.51601785, grad/param norm = 1.8925e-01, time/batch = 0.6595s	
1896/25300 (epoch 3.747), train_loss = 1.43392072, grad/param norm = 1.8418e-01, time/batch = 0.6597s	
1897/25300 (epoch 3.749), train_loss = 1.63824316, grad/param norm = 2.1569e-01, time/batch = 0.6598s	
1898/25300 (epoch 3.751), train_loss = 1.73608857, grad/param norm = 2.1241e-01, time/batch = 0.6563s	
1899/25300 (epoch 3.753), train_loss = 1.58686903, grad/param norm = 2.3732e-01, time/batch = 0.6567s	
1900/25300 (epoch 3.755), train_loss = 1.72767783, grad/param norm = 2.3772e-01, time/batch = 0.6592s	
1901/25300 (epoch 3.757), train_loss = 1.51515539, grad/param norm = 2.4696e-01, time/batch = 0.6588s	
1902/25300 (epoch 3.759), train_loss = 1.45954651, grad/param norm = 2.2515e-01, time/batch = 0.6572s	
1903/25300 (epoch 3.761), train_loss = 1.75617983, grad/param norm = 2.5809e-01, time/batch = 0.6550s	
1904/25300 (epoch 3.763), train_loss = 1.51171918, grad/param norm = 2.4139e-01, time/batch = 0.6509s	
1905/25300 (epoch 3.765), train_loss = 1.59120403, grad/param norm = 2.4751e-01, time/batch = 0.6619s	
1906/25300 (epoch 3.767), train_loss = 1.52715586, grad/param norm = 2.3170e-01, time/batch = 0.6556s	
1907/25300 (epoch 3.769), train_loss = 1.63093557, grad/param norm = 2.2919e-01, time/batch = 0.6591s	
1908/25300 (epoch 3.771), train_loss = 1.96615222, grad/param norm = 2.3292e-01, time/batch = 0.6555s	
1909/25300 (epoch 3.773), train_loss = 1.78283195, grad/param norm = 2.3532e-01, time/batch = 0.6540s	
1910/25300 (epoch 3.775), train_loss = 1.56419256, grad/param norm = 2.0764e-01, time/batch = 0.6556s	
1911/25300 (epoch 3.777), train_loss = 1.68252117, grad/param norm = 2.2361e-01, time/batch = 0.6574s	
1912/25300 (epoch 3.779), train_loss = 1.73733192, grad/param norm = 2.0344e-01, time/batch = 0.6539s	
1913/25300 (epoch 3.781), train_loss = 1.54777807, grad/param norm = 2.2627e-01, time/batch = 0.6575s	
1914/25300 (epoch 3.783), train_loss = 1.79592535, grad/param norm = 2.1167e-01, time/batch = 0.6611s	
1915/25300 (epoch 3.785), train_loss = 1.70893407, grad/param norm = 2.3002e-01, time/batch = 0.6539s	
1916/25300 (epoch 3.787), train_loss = 1.77572390, grad/param norm = 2.2214e-01, time/batch = 0.6579s	
1917/25300 (epoch 3.789), train_loss = 1.84504084, grad/param norm = 2.0882e-01, time/batch = 0.6636s	
1918/25300 (epoch 3.791), train_loss = 1.60720249, grad/param norm = 2.0573e-01, time/batch = 0.6642s	
1919/25300 (epoch 3.792), train_loss = 1.69521624, grad/param norm = 2.0726e-01, time/batch = 0.6651s	
1920/25300 (epoch 3.794), train_loss = 1.75392424, grad/param norm = 2.2017e-01, time/batch = 0.6645s	
1921/25300 (epoch 3.796), train_loss = 1.57599888, grad/param norm = 2.0045e-01, time/batch = 0.6631s	
1922/25300 (epoch 3.798), train_loss = 1.77038991, grad/param norm = 2.0700e-01, time/batch = 0.6563s	
1923/25300 (epoch 3.800), train_loss = 1.70107592, grad/param norm = 2.2481e-01, time/batch = 0.6569s	
1924/25300 (epoch 3.802), train_loss = 1.35443745, grad/param norm = 1.9562e-01, time/batch = 0.6587s	
1925/25300 (epoch 3.804), train_loss = 1.62785915, grad/param norm = 2.0279e-01, time/batch = 0.6567s	
1926/25300 (epoch 3.806), train_loss = 1.72741795, grad/param norm = 2.1290e-01, time/batch = 0.6576s	
1927/25300 (epoch 3.808), train_loss = 1.58764901, grad/param norm = 2.1609e-01, time/batch = 0.6592s	
1928/25300 (epoch 3.810), train_loss = 1.62265681, grad/param norm = 2.7215e-01, time/batch = 0.6572s	
1929/25300 (epoch 3.812), train_loss = 1.63157290, grad/param norm = 2.1137e-01, time/batch = 0.6562s	
1930/25300 (epoch 3.814), train_loss = 1.85389254, grad/param norm = 2.1800e-01, time/batch = 0.6540s	
1931/25300 (epoch 3.816), train_loss = 1.87047504, grad/param norm = 2.3376e-01, time/batch = 0.6548s	
1932/25300 (epoch 3.818), train_loss = 1.76475574, grad/param norm = 2.2067e-01, time/batch = 0.6572s	
1933/25300 (epoch 3.820), train_loss = 1.64281606, grad/param norm = 1.9377e-01, time/batch = 0.6603s	
1934/25300 (epoch 3.822), train_loss = 1.58059198, grad/param norm = 1.9654e-01, time/batch = 0.6566s	
1935/25300 (epoch 3.824), train_loss = 1.69379239, grad/param norm = 2.1827e-01, time/batch = 0.6582s	
1936/25300 (epoch 3.826), train_loss = 1.56707948, grad/param norm = 2.4368e-01, time/batch = 0.6563s	
1937/25300 (epoch 3.828), train_loss = 1.55594471, grad/param norm = 2.2970e-01, time/batch = 0.6565s	
1938/25300 (epoch 3.830), train_loss = 1.58422646, grad/param norm = 2.2017e-01, time/batch = 0.6588s	
1939/25300 (epoch 3.832), train_loss = 1.58051372, grad/param norm = 2.1010e-01, time/batch = 0.6580s	
1940/25300 (epoch 3.834), train_loss = 1.44848802, grad/param norm = 2.2125e-01, time/batch = 0.6567s	
1941/25300 (epoch 3.836), train_loss = 1.53980565, grad/param norm = 2.2524e-01, time/batch = 0.6592s	
1942/25300 (epoch 3.838), train_loss = 1.63082237, grad/param norm = 2.2185e-01, time/batch = 0.6553s	
1943/25300 (epoch 3.840), train_loss = 1.78719865, grad/param norm = 2.1457e-01, time/batch = 0.6576s	
1944/25300 (epoch 3.842), train_loss = 1.74133410, grad/param norm = 2.4428e-01, time/batch = 0.6563s	
1945/25300 (epoch 3.844), train_loss = 1.62825986, grad/param norm = 2.3021e-01, time/batch = 0.6535s	
1946/25300 (epoch 3.846), train_loss = 1.53480394, grad/param norm = 2.0583e-01, time/batch = 0.6564s	
1947/25300 (epoch 3.848), train_loss = 1.81609322, grad/param norm = 2.3131e-01, time/batch = 0.6552s	
1948/25300 (epoch 3.850), train_loss = 1.70843438, grad/param norm = 2.1569e-01, time/batch = 0.6562s	
1949/25300 (epoch 3.852), train_loss = 1.62736135, grad/param norm = 2.5375e-01, time/batch = 0.6593s	
1950/25300 (epoch 3.854), train_loss = 1.85451079, grad/param norm = 2.2818e-01, time/batch = 0.6633s	
1951/25300 (epoch 3.856), train_loss = 1.61748858, grad/param norm = 2.1469e-01, time/batch = 0.6589s	
1952/25300 (epoch 3.858), train_loss = 1.67568377, grad/param norm = 2.0777e-01, time/batch = 0.6536s	
1953/25300 (epoch 3.860), train_loss = 1.42338884, grad/param norm = 2.0561e-01, time/batch = 0.6523s	
1954/25300 (epoch 3.862), train_loss = 1.70057179, grad/param norm = 2.2724e-01, time/batch = 0.6540s	
1955/25300 (epoch 3.864), train_loss = 1.79414330, grad/param norm = 2.1603e-01, time/batch = 0.6557s	
1956/25300 (epoch 3.866), train_loss = 1.74634449, grad/param norm = 2.4175e-01, time/batch = 0.6568s	
1957/25300 (epoch 3.868), train_loss = 1.79814975, grad/param norm = 2.4940e-01, time/batch = 0.6581s	
1958/25300 (epoch 3.870), train_loss = 1.71693906, grad/param norm = 2.2592e-01, time/batch = 0.6585s	
1959/25300 (epoch 3.872), train_loss = 1.67794783, grad/param norm = 2.1043e-01, time/batch = 0.6583s	
1960/25300 (epoch 3.874), train_loss = 1.71023473, grad/param norm = 2.5002e-01, time/batch = 0.6571s	
1961/25300 (epoch 3.875), train_loss = 1.63404411, grad/param norm = 2.3288e-01, time/batch = 0.6606s	
1962/25300 (epoch 3.877), train_loss = 1.48554526, grad/param norm = 1.9020e-01, time/batch = 0.6585s	
1963/25300 (epoch 3.879), train_loss = 1.70144796, grad/param norm = 2.0693e-01, time/batch = 0.6555s	
1964/25300 (epoch 3.881), train_loss = 1.95455079, grad/param norm = 2.2161e-01, time/batch = 0.6574s	
1965/25300 (epoch 3.883), train_loss = 1.87598197, grad/param norm = 2.1213e-01, time/batch = 0.6633s	
1966/25300 (epoch 3.885), train_loss = 1.76684196, grad/param norm = 2.1779e-01, time/batch = 0.6672s	
1967/25300 (epoch 3.887), train_loss = 1.61801761, grad/param norm = 2.0095e-01, time/batch = 0.6674s	
1968/25300 (epoch 3.889), train_loss = 1.88570561, grad/param norm = 2.3655e-01, time/batch = 0.6608s	
1969/25300 (epoch 3.891), train_loss = 1.87094008, grad/param norm = 2.3943e-01, time/batch = 0.6612s	
1970/25300 (epoch 3.893), train_loss = 1.95228174, grad/param norm = 2.3740e-01, time/batch = 0.6643s	
1971/25300 (epoch 3.895), train_loss = 1.36593633, grad/param norm = 2.2375e-01, time/batch = 0.6644s	
1972/25300 (epoch 3.897), train_loss = 1.57381410, grad/param norm = 2.2254e-01, time/batch = 0.6691s	
1973/25300 (epoch 3.899), train_loss = 1.65133134, grad/param norm = 2.2926e-01, time/batch = 0.6592s	
1974/25300 (epoch 3.901), train_loss = 1.74939065, grad/param norm = 2.3097e-01, time/batch = 0.6567s	
1975/25300 (epoch 3.903), train_loss = 1.46524341, grad/param norm = 2.4354e-01, time/batch = 0.6569s	
1976/25300 (epoch 3.905), train_loss = 1.55317109, grad/param norm = 2.2076e-01, time/batch = 0.6791s	
1977/25300 (epoch 3.907), train_loss = 1.83736122, grad/param norm = 2.6682e-01, time/batch = 0.6702s	
1978/25300 (epoch 3.909), train_loss = 1.74036692, grad/param norm = 2.0420e-01, time/batch = 0.6621s	
1979/25300 (epoch 3.911), train_loss = 1.83867351, grad/param norm = 2.4397e-01, time/batch = 0.6625s	
1980/25300 (epoch 3.913), train_loss = 1.80310384, grad/param norm = 2.4736e-01, time/batch = 0.6586s	
1981/25300 (epoch 3.915), train_loss = 1.65452343, grad/param norm = 2.3768e-01, time/batch = 0.6614s	
1982/25300 (epoch 3.917), train_loss = 1.73034955, grad/param norm = 2.1024e-01, time/batch = 0.6570s	
1983/25300 (epoch 3.919), train_loss = 1.73524265, grad/param norm = 2.3555e-01, time/batch = 0.6552s	
1984/25300 (epoch 3.921), train_loss = 1.51379218, grad/param norm = 2.3841e-01, time/batch = 0.6565s	
1985/25300 (epoch 3.923), train_loss = 1.73768245, grad/param norm = 2.0389e-01, time/batch = 0.6568s	
1986/25300 (epoch 3.925), train_loss = 1.71492570, grad/param norm = 2.1507e-01, time/batch = 0.6574s	
1987/25300 (epoch 3.927), train_loss = 1.65518994, grad/param norm = 2.2792e-01, time/batch = 0.6581s	
1988/25300 (epoch 3.929), train_loss = 1.50731531, grad/param norm = 2.2652e-01, time/batch = 0.6637s	
1989/25300 (epoch 3.931), train_loss = 1.78653930, grad/param norm = 2.2169e-01, time/batch = 0.6597s	
1990/25300 (epoch 3.933), train_loss = 1.68284124, grad/param norm = 2.1952e-01, time/batch = 0.6582s	
1991/25300 (epoch 3.935), train_loss = 1.59606485, grad/param norm = 2.1084e-01, time/batch = 0.6585s	
1992/25300 (epoch 3.937), train_loss = 1.35326743, grad/param norm = 1.7838e-01, time/batch = 0.6609s	
1993/25300 (epoch 3.939), train_loss = 1.76960307, grad/param norm = 2.0932e-01, time/batch = 0.6698s	
1994/25300 (epoch 3.941), train_loss = 1.55046527, grad/param norm = 1.9959e-01, time/batch = 0.6650s	
1995/25300 (epoch 3.943), train_loss = 1.47705054, grad/param norm = 2.0805e-01, time/batch = 0.6664s	
1996/25300 (epoch 3.945), train_loss = 1.60957729, grad/param norm = 2.0262e-01, time/batch = 0.6654s	
1997/25300 (epoch 3.947), train_loss = 1.60943360, grad/param norm = 2.2618e-01, time/batch = 0.6648s	
1998/25300 (epoch 3.949), train_loss = 1.74989671, grad/param norm = 2.2351e-01, time/batch = 0.6614s	
1999/25300 (epoch 3.951), train_loss = 1.63213580, grad/param norm = 2.0044e-01, time/batch = 0.6558s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch3.95_1.6468.t7	
2000/25300 (epoch 3.953), train_loss = 1.79060868, grad/param norm = 2.1536e-01, time/batch = 0.6545s	
2001/25300 (epoch 3.955), train_loss = 2.02602106, grad/param norm = 2.4157e-01, time/batch = 0.6648s	
2002/25300 (epoch 3.957), train_loss = 1.81889155, grad/param norm = 2.6154e-01, time/batch = 0.6601s	
2003/25300 (epoch 3.958), train_loss = 1.68583350, grad/param norm = 2.1826e-01, time/batch = 0.6617s	
2004/25300 (epoch 3.960), train_loss = 1.84030542, grad/param norm = 2.2926e-01, time/batch = 0.6607s	
2005/25300 (epoch 3.962), train_loss = 1.72225201, grad/param norm = 2.4242e-01, time/batch = 0.6613s	
2006/25300 (epoch 3.964), train_loss = 1.68094745, grad/param norm = 2.1410e-01, time/batch = 0.6586s	
2007/25300 (epoch 3.966), train_loss = 1.47808542, grad/param norm = 2.1562e-01, time/batch = 0.6753s	
2008/25300 (epoch 3.968), train_loss = 1.43714513, grad/param norm = 2.0697e-01, time/batch = 0.6726s	
2009/25300 (epoch 3.970), train_loss = 1.70913805, grad/param norm = 2.4380e-01, time/batch = 0.6629s	
2010/25300 (epoch 3.972), train_loss = 1.65724030, grad/param norm = 2.1677e-01, time/batch = 0.6663s	
2011/25300 (epoch 3.974), train_loss = 1.87685829, grad/param norm = 2.4402e-01, time/batch = 0.6618s	
2012/25300 (epoch 3.976), train_loss = 1.67889826, grad/param norm = 2.3847e-01, time/batch = 0.6582s	
2013/25300 (epoch 3.978), train_loss = 1.69768353, grad/param norm = 2.0292e-01, time/batch = 0.6585s	
2014/25300 (epoch 3.980), train_loss = 1.74457023, grad/param norm = 2.3296e-01, time/batch = 0.6610s	
2015/25300 (epoch 3.982), train_loss = 1.64049627, grad/param norm = 2.2804e-01, time/batch = 0.6603s	
2016/25300 (epoch 3.984), train_loss = 1.61354537, grad/param norm = 2.1458e-01, time/batch = 0.6628s	
2017/25300 (epoch 3.986), train_loss = 1.66240389, grad/param norm = 2.5390e-01, time/batch = 0.6669s	
2018/25300 (epoch 3.988), train_loss = 1.60435130, grad/param norm = 2.2196e-01, time/batch = 0.6581s	
2019/25300 (epoch 3.990), train_loss = 1.63075110, grad/param norm = 2.3053e-01, time/batch = 0.6582s	
2020/25300 (epoch 3.992), train_loss = 1.32987394, grad/param norm = 2.0612e-01, time/batch = 0.6623s	
2021/25300 (epoch 3.994), train_loss = 1.73816089, grad/param norm = 2.2029e-01, time/batch = 0.6725s	
2022/25300 (epoch 3.996), train_loss = 1.78030373, grad/param norm = 2.2407e-01, time/batch = 0.6692s	
2023/25300 (epoch 3.998), train_loss = 1.75886047, grad/param norm = 2.0975e-01, time/batch = 0.6683s	
2024/25300 (epoch 4.000), train_loss = 1.62918150, grad/param norm = 2.2691e-01, time/batch = 0.6666s	
2025/25300 (epoch 4.002), train_loss = 1.49122775, grad/param norm = 1.8839e-01, time/batch = 0.6655s	
2026/25300 (epoch 4.004), train_loss = 1.42980385, grad/param norm = 2.1735e-01, time/batch = 0.6629s	
2027/25300 (epoch 4.006), train_loss = 1.61695228, grad/param norm = 2.1112e-01, time/batch = 0.6635s	
2028/25300 (epoch 4.008), train_loss = 1.67754893, grad/param norm = 2.1277e-01, time/batch = 0.6548s	
2029/25300 (epoch 4.010), train_loss = 1.68717341, grad/param norm = 2.0727e-01, time/batch = 0.6554s	
2030/25300 (epoch 4.012), train_loss = 1.49265271, grad/param norm = 2.2579e-01, time/batch = 0.6589s	
2031/25300 (epoch 4.014), train_loss = 1.69765569, grad/param norm = 2.1724e-01, time/batch = 0.6569s	
2032/25300 (epoch 4.016), train_loss = 1.70343029, grad/param norm = 2.2438e-01, time/batch = 0.6563s	
2033/25300 (epoch 4.018), train_loss = 1.57257224, grad/param norm = 2.1109e-01, time/batch = 0.6596s	
2034/25300 (epoch 4.020), train_loss = 1.57396152, grad/param norm = 2.0554e-01, time/batch = 0.6599s	
2035/25300 (epoch 4.022), train_loss = 1.62590421, grad/param norm = 2.4185e-01, time/batch = 0.6602s	
2036/25300 (epoch 4.024), train_loss = 1.28730111, grad/param norm = 2.0528e-01, time/batch = 0.6592s	
2037/25300 (epoch 4.026), train_loss = 1.56354497, grad/param norm = 2.4390e-01, time/batch = 0.6558s	
2038/25300 (epoch 4.028), train_loss = 1.42854221, grad/param norm = 2.1079e-01, time/batch = 0.6559s	
2039/25300 (epoch 4.030), train_loss = 1.69894334, grad/param norm = 2.1960e-01, time/batch = 0.6601s	
2040/25300 (epoch 4.032), train_loss = 1.56077621, grad/param norm = 1.9545e-01, time/batch = 0.6617s	
2041/25300 (epoch 4.034), train_loss = 1.32479402, grad/param norm = 2.0239e-01, time/batch = 0.6573s	
2042/25300 (epoch 4.036), train_loss = 1.42655752, grad/param norm = 1.9826e-01, time/batch = 0.6546s	
2043/25300 (epoch 4.038), train_loss = 1.30547024, grad/param norm = 1.8339e-01, time/batch = 0.6556s	
2044/25300 (epoch 4.040), train_loss = 1.69490679, grad/param norm = 2.1247e-01, time/batch = 0.6580s	
2045/25300 (epoch 4.042), train_loss = 1.39755898, grad/param norm = 2.0411e-01, time/batch = 0.6595s	
2046/25300 (epoch 4.043), train_loss = 1.36599147, grad/param norm = 1.8397e-01, time/batch = 0.6592s	
2047/25300 (epoch 4.045), train_loss = 1.36882571, grad/param norm = 1.9601e-01, time/batch = 0.6612s	
2048/25300 (epoch 4.047), train_loss = 1.70042139, grad/param norm = 2.2524e-01, time/batch = 0.6643s	
2049/25300 (epoch 4.049), train_loss = 1.65722832, grad/param norm = 2.1935e-01, time/batch = 0.6664s	
2050/25300 (epoch 4.051), train_loss = 1.72740822, grad/param norm = 2.2498e-01, time/batch = 0.6642s	
2051/25300 (epoch 4.053), train_loss = 1.39530967, grad/param norm = 1.9461e-01, time/batch = 0.6657s	
2052/25300 (epoch 4.055), train_loss = 1.33608339, grad/param norm = 1.8461e-01, time/batch = 0.6637s	
2053/25300 (epoch 4.057), train_loss = 1.35838918, grad/param norm = 1.7519e-01, time/batch = 0.6664s	
2054/25300 (epoch 4.059), train_loss = 1.65395299, grad/param norm = 2.2866e-01, time/batch = 0.6676s	
2055/25300 (epoch 4.061), train_loss = 1.51887711, grad/param norm = 2.1898e-01, time/batch = 0.6642s	
2056/25300 (epoch 4.063), train_loss = 1.54203072, grad/param norm = 1.8541e-01, time/batch = 0.6632s	
2057/25300 (epoch 4.065), train_loss = 1.76277709, grad/param norm = 2.3616e-01, time/batch = 0.6560s	
2058/25300 (epoch 4.067), train_loss = 1.68384744, grad/param norm = 2.0951e-01, time/batch = 0.6577s	
2059/25300 (epoch 4.069), train_loss = 1.65824947, grad/param norm = 2.1973e-01, time/batch = 0.6614s	
2060/25300 (epoch 4.071), train_loss = 1.71096036, grad/param norm = 2.2561e-01, time/batch = 0.6592s	
2061/25300 (epoch 4.073), train_loss = 1.58877070, grad/param norm = 2.1088e-01, time/batch = 0.6636s	
2062/25300 (epoch 4.075), train_loss = 1.50898585, grad/param norm = 1.7923e-01, time/batch = 0.6610s	
2063/25300 (epoch 4.077), train_loss = 1.68437984, grad/param norm = 2.1480e-01, time/batch = 0.6558s	
2064/25300 (epoch 4.079), train_loss = 1.66861681, grad/param norm = 2.1923e-01, time/batch = 0.6555s	
2065/25300 (epoch 4.081), train_loss = 1.55818766, grad/param norm = 1.9937e-01, time/batch = 0.6561s	
2066/25300 (epoch 4.083), train_loss = 1.45954367, grad/param norm = 2.2006e-01, time/batch = 0.6547s	
2067/25300 (epoch 4.085), train_loss = 1.80755349, grad/param norm = 2.3044e-01, time/batch = 0.6543s	
2068/25300 (epoch 4.087), train_loss = 1.60552378, grad/param norm = 2.2307e-01, time/batch = 0.6561s	
2069/25300 (epoch 4.089), train_loss = 1.55870068, grad/param norm = 2.1497e-01, time/batch = 0.6571s	
2070/25300 (epoch 4.091), train_loss = 1.66596990, grad/param norm = 2.2487e-01, time/batch = 0.6592s	
2071/25300 (epoch 4.093), train_loss = 1.87269913, grad/param norm = 2.2613e-01, time/batch = 0.6680s	
2072/25300 (epoch 4.095), train_loss = 1.63805883, grad/param norm = 1.9370e-01, time/batch = 0.6567s	
2073/25300 (epoch 4.097), train_loss = 1.58271567, grad/param norm = 2.0497e-01, time/batch = 0.6547s	
2074/25300 (epoch 4.099), train_loss = 1.62512641, grad/param norm = 2.2695e-01, time/batch = 0.6569s	
2075/25300 (epoch 4.101), train_loss = 1.55673968, grad/param norm = 2.1590e-01, time/batch = 0.6594s	
2076/25300 (epoch 4.103), train_loss = 1.56419715, grad/param norm = 2.0265e-01, time/batch = 0.6587s	
2077/25300 (epoch 4.105), train_loss = 1.65084227, grad/param norm = 2.1440e-01, time/batch = 0.6581s	
2078/25300 (epoch 4.107), train_loss = 1.71286584, grad/param norm = 2.2483e-01, time/batch = 0.6566s	
2079/25300 (epoch 4.109), train_loss = 1.70100313, grad/param norm = 2.3333e-01, time/batch = 0.6663s	
2080/25300 (epoch 4.111), train_loss = 1.52313888, grad/param norm = 1.9135e-01, time/batch = 0.6687s	
2081/25300 (epoch 4.113), train_loss = 1.60343828, grad/param norm = 2.2492e-01, time/batch = 0.6689s	
2082/25300 (epoch 4.115), train_loss = 1.58727144, grad/param norm = 2.0301e-01, time/batch = 0.6669s	
2083/25300 (epoch 4.117), train_loss = 1.64711702, grad/param norm = 2.0997e-01, time/batch = 0.6661s	
2084/25300 (epoch 4.119), train_loss = 1.60505233, grad/param norm = 2.3486e-01, time/batch = 0.6667s	
2085/25300 (epoch 4.121), train_loss = 1.77970260, grad/param norm = 2.3813e-01, time/batch = 0.6636s	
2086/25300 (epoch 4.123), train_loss = 1.58015546, grad/param norm = 2.1935e-01, time/batch = 0.6526s	
2087/25300 (epoch 4.125), train_loss = 1.67140354, grad/param norm = 2.3585e-01, time/batch = 0.6588s	
2088/25300 (epoch 4.126), train_loss = 1.60700002, grad/param norm = 2.2596e-01, time/batch = 0.6533s	
2089/25300 (epoch 4.128), train_loss = 1.61180101, grad/param norm = 2.0723e-01, time/batch = 0.6497s	
2090/25300 (epoch 4.130), train_loss = 1.29008624, grad/param norm = 1.7191e-01, time/batch = 0.6616s	
2091/25300 (epoch 4.132), train_loss = 1.47621488, grad/param norm = 2.0069e-01, time/batch = 0.6547s	
2092/25300 (epoch 4.134), train_loss = 1.29461774, grad/param norm = 2.0518e-01, time/batch = 0.6560s	
2093/25300 (epoch 4.136), train_loss = 1.63114240, grad/param norm = 2.2898e-01, time/batch = 0.6589s	
2094/25300 (epoch 4.138), train_loss = 1.44889084, grad/param norm = 1.9912e-01, time/batch = 0.6606s	
2095/25300 (epoch 4.140), train_loss = 1.42900241, grad/param norm = 1.9581e-01, time/batch = 0.6543s	
2096/25300 (epoch 4.142), train_loss = 1.65923858, grad/param norm = 2.0934e-01, time/batch = 0.6553s	
2097/25300 (epoch 4.144), train_loss = 1.57868810, grad/param norm = 2.2242e-01, time/batch = 0.6579s	
2098/25300 (epoch 4.146), train_loss = 1.74839930, grad/param norm = 2.4801e-01, time/batch = 0.6557s	
2099/25300 (epoch 4.148), train_loss = 1.70855272, grad/param norm = 2.1650e-01, time/batch = 0.6572s	
2100/25300 (epoch 4.150), train_loss = 1.75292049, grad/param norm = 2.3329e-01, time/batch = 0.6532s	
2101/25300 (epoch 4.152), train_loss = 1.88332984, grad/param norm = 2.3408e-01, time/batch = 0.6596s	
2102/25300 (epoch 4.154), train_loss = 1.53189234, grad/param norm = 2.0470e-01, time/batch = 0.6548s	
2103/25300 (epoch 4.156), train_loss = 1.64420250, grad/param norm = 2.1068e-01, time/batch = 0.6553s	
2104/25300 (epoch 4.158), train_loss = 1.59130022, grad/param norm = 2.1662e-01, time/batch = 0.6580s	
2105/25300 (epoch 4.160), train_loss = 1.60590615, grad/param norm = 2.2270e-01, time/batch = 0.6587s	
2106/25300 (epoch 4.162), train_loss = 1.53206717, grad/param norm = 2.2810e-01, time/batch = 0.6583s	
2107/25300 (epoch 4.164), train_loss = 1.62027975, grad/param norm = 2.2162e-01, time/batch = 0.6612s	
2108/25300 (epoch 4.166), train_loss = 1.65442201, grad/param norm = 2.2749e-01, time/batch = 0.6554s	
2109/25300 (epoch 4.168), train_loss = 1.40744853, grad/param norm = 2.1016e-01, time/batch = 0.6605s	
2110/25300 (epoch 4.170), train_loss = 1.50313716, grad/param norm = 2.1567e-01, time/batch = 0.6556s	
2111/25300 (epoch 4.172), train_loss = 1.46466722, grad/param norm = 2.0271e-01, time/batch = 0.6575s	
2112/25300 (epoch 4.174), train_loss = 1.45112263, grad/param norm = 1.8989e-01, time/batch = 0.6552s	
2113/25300 (epoch 4.176), train_loss = 1.56617878, grad/param norm = 2.1151e-01, time/batch = 0.6567s	
2114/25300 (epoch 4.178), train_loss = 1.78609539, grad/param norm = 2.2635e-01, time/batch = 0.6566s	
2115/25300 (epoch 4.180), train_loss = 1.38202962, grad/param norm = 1.9768e-01, time/batch = 0.6575s	
2116/25300 (epoch 4.182), train_loss = 1.56358084, grad/param norm = 2.2532e-01, time/batch = 0.6588s	
2117/25300 (epoch 4.184), train_loss = 1.56998573, grad/param norm = 2.0491e-01, time/batch = 0.6560s	
2118/25300 (epoch 4.186), train_loss = 1.61953943, grad/param norm = 2.2419e-01, time/batch = 0.6563s	
2119/25300 (epoch 4.188), train_loss = 1.51455765, grad/param norm = 2.0377e-01, time/batch = 0.6540s	
2120/25300 (epoch 4.190), train_loss = 1.63277829, grad/param norm = 2.1671e-01, time/batch = 0.6539s	
2121/25300 (epoch 4.192), train_loss = 1.65817598, grad/param norm = 2.4130e-01, time/batch = 0.6558s	
2122/25300 (epoch 4.194), train_loss = 1.56693296, grad/param norm = 2.0595e-01, time/batch = 0.6559s	
2123/25300 (epoch 4.196), train_loss = 1.63829295, grad/param norm = 2.0486e-01, time/batch = 0.6555s	
2124/25300 (epoch 4.198), train_loss = 1.55666273, grad/param norm = 2.0553e-01, time/batch = 0.6568s	
2125/25300 (epoch 4.200), train_loss = 1.64575924, grad/param norm = 2.0501e-01, time/batch = 0.6546s	
2126/25300 (epoch 4.202), train_loss = 1.64035617, grad/param norm = 2.0667e-01, time/batch = 0.6546s	
2127/25300 (epoch 4.204), train_loss = 1.54149970, grad/param norm = 2.1823e-01, time/batch = 0.6577s	
2128/25300 (epoch 4.206), train_loss = 1.63804205, grad/param norm = 2.2451e-01, time/batch = 0.6599s	
2129/25300 (epoch 4.208), train_loss = 1.46501263, grad/param norm = 2.3399e-01, time/batch = 0.6542s	
2130/25300 (epoch 4.209), train_loss = 1.34390055, grad/param norm = 2.0790e-01, time/batch = 0.6561s	
2131/25300 (epoch 4.211), train_loss = 1.56650469, grad/param norm = 2.1379e-01, time/batch = 0.6601s	
2132/25300 (epoch 4.213), train_loss = 1.64788512, grad/param norm = 2.3362e-01, time/batch = 0.6601s	
2133/25300 (epoch 4.215), train_loss = 1.58039096, grad/param norm = 2.2529e-01, time/batch = 0.6590s	
2134/25300 (epoch 4.217), train_loss = 1.67872510, grad/param norm = 2.2989e-01, time/batch = 0.6556s	
2135/25300 (epoch 4.219), train_loss = 1.57223052, grad/param norm = 2.0114e-01, time/batch = 0.6550s	
2136/25300 (epoch 4.221), train_loss = 1.72240404, grad/param norm = 2.1200e-01, time/batch = 0.6564s	
2137/25300 (epoch 4.223), train_loss = 1.67045543, grad/param norm = 2.1993e-01, time/batch = 0.6542s	
2138/25300 (epoch 4.225), train_loss = 2.01902046, grad/param norm = 2.6029e-01, time/batch = 0.6562s	
2139/25300 (epoch 4.227), train_loss = 1.63476131, grad/param norm = 1.9323e-01, time/batch = 0.6656s	
2140/25300 (epoch 4.229), train_loss = 1.69626330, grad/param norm = 2.1356e-01, time/batch = 0.6663s	
2141/25300 (epoch 4.231), train_loss = 1.64267839, grad/param norm = 2.2164e-01, time/batch = 0.6655s	
2142/25300 (epoch 4.233), train_loss = 1.62287932, grad/param norm = 2.0970e-01, time/batch = 0.6595s	
2143/25300 (epoch 4.235), train_loss = 1.55856932, grad/param norm = 2.0189e-01, time/batch = 0.6541s	
2144/25300 (epoch 4.237), train_loss = 1.75448683, grad/param norm = 2.1405e-01, time/batch = 0.6520s	
2145/25300 (epoch 4.239), train_loss = 1.58423879, grad/param norm = 2.2530e-01, time/batch = 0.6533s	
2146/25300 (epoch 4.241), train_loss = 1.67920143, grad/param norm = 2.1628e-01, time/batch = 0.6580s	
2147/25300 (epoch 4.243), train_loss = 1.95490075, grad/param norm = 2.5188e-01, time/batch = 0.6596s	
2148/25300 (epoch 4.245), train_loss = 1.49337180, grad/param norm = 2.3577e-01, time/batch = 0.6584s	
2149/25300 (epoch 4.247), train_loss = 1.76168918, grad/param norm = 2.4585e-01, time/batch = 0.6546s	
2150/25300 (epoch 4.249), train_loss = 1.48643060, grad/param norm = 2.2191e-01, time/batch = 0.6639s	
2151/25300 (epoch 4.251), train_loss = 1.39164965, grad/param norm = 2.0038e-01, time/batch = 0.6690s	
2152/25300 (epoch 4.253), train_loss = 1.54264478, grad/param norm = 2.0374e-01, time/batch = 0.6673s	
2153/25300 (epoch 4.255), train_loss = 1.52545502, grad/param norm = 1.9929e-01, time/batch = 0.6647s	
2154/25300 (epoch 4.257), train_loss = 1.77772046, grad/param norm = 2.3107e-01, time/batch = 0.6653s	
2155/25300 (epoch 4.259), train_loss = 1.94242632, grad/param norm = 2.3033e-01, time/batch = 0.6638s	
2156/25300 (epoch 4.261), train_loss = 1.77395709, grad/param norm = 2.3195e-01, time/batch = 0.6642s	
2157/25300 (epoch 4.263), train_loss = 1.67720972, grad/param norm = 1.9657e-01, time/batch = 0.6639s	
2158/25300 (epoch 4.265), train_loss = 1.74703402, grad/param norm = 2.3024e-01, time/batch = 0.6622s	
2159/25300 (epoch 4.267), train_loss = 1.72489821, grad/param norm = 2.0535e-01, time/batch = 0.6654s	
2160/25300 (epoch 4.269), train_loss = 1.43873461, grad/param norm = 1.9050e-01, time/batch = 0.6624s	
2161/25300 (epoch 4.271), train_loss = 1.46411499, grad/param norm = 2.1111e-01, time/batch = 0.6617s	
2162/25300 (epoch 4.273), train_loss = 1.64122831, grad/param norm = 2.1301e-01, time/batch = 0.6557s	
2163/25300 (epoch 4.275), train_loss = 1.39798285, grad/param norm = 1.8973e-01, time/batch = 0.6498s	
2164/25300 (epoch 4.277), train_loss = 1.54375546, grad/param norm = 2.1601e-01, time/batch = 0.6507s	
2165/25300 (epoch 4.279), train_loss = 1.63119762, grad/param norm = 2.2724e-01, time/batch = 0.6494s	
2166/25300 (epoch 4.281), train_loss = 1.78271113, grad/param norm = 2.4942e-01, time/batch = 0.6515s	
2167/25300 (epoch 4.283), train_loss = 1.50213555, grad/param norm = 2.1980e-01, time/batch = 0.6480s	
2168/25300 (epoch 4.285), train_loss = 1.58161526, grad/param norm = 2.1707e-01, time/batch = 0.6489s	
2169/25300 (epoch 4.287), train_loss = 1.56296926, grad/param norm = 1.9208e-01, time/batch = 0.6540s	
2170/25300 (epoch 4.289), train_loss = 1.53532459, grad/param norm = 1.9191e-01, time/batch = 0.6560s	
2171/25300 (epoch 4.291), train_loss = 1.42676574, grad/param norm = 2.0428e-01, time/batch = 0.6595s	
2172/25300 (epoch 4.292), train_loss = 1.69110032, grad/param norm = 2.1663e-01, time/batch = 0.6569s	
2173/25300 (epoch 4.294), train_loss = 1.57961402, grad/param norm = 2.2078e-01, time/batch = 0.6558s	
2174/25300 (epoch 4.296), train_loss = 1.46651328, grad/param norm = 2.0343e-01, time/batch = 0.6557s	
2175/25300 (epoch 4.298), train_loss = 1.71031377, grad/param norm = 2.1745e-01, time/batch = 0.6583s	
2176/25300 (epoch 4.300), train_loss = 1.85050179, grad/param norm = 2.2775e-01, time/batch = 0.6533s	
2177/25300 (epoch 4.302), train_loss = 1.42214163, grad/param norm = 2.2597e-01, time/batch = 0.6551s	
2178/25300 (epoch 4.304), train_loss = 1.68642444, grad/param norm = 2.2780e-01, time/batch = 0.6581s	
2179/25300 (epoch 4.306), train_loss = 1.29328863, grad/param norm = 1.9709e-01, time/batch = 0.6522s	
2180/25300 (epoch 4.308), train_loss = 1.61440850, grad/param norm = 1.9376e-01, time/batch = 0.6534s	
2181/25300 (epoch 4.310), train_loss = 1.54996861, grad/param norm = 2.0960e-01, time/batch = 0.6553s	
2182/25300 (epoch 4.312), train_loss = 1.59692225, grad/param norm = 2.1721e-01, time/batch = 0.6547s	
2183/25300 (epoch 4.314), train_loss = 1.37218814, grad/param norm = 2.0631e-01, time/batch = 0.6552s	
2184/25300 (epoch 4.316), train_loss = 1.60422067, grad/param norm = 2.0462e-01, time/batch = 0.6585s	
2185/25300 (epoch 4.318), train_loss = 1.29469719, grad/param norm = 2.0665e-01, time/batch = 0.6588s	
2186/25300 (epoch 4.320), train_loss = 1.50896088, grad/param norm = 2.2383e-01, time/batch = 0.6562s	
2187/25300 (epoch 4.322), train_loss = 1.87157017, grad/param norm = 2.1887e-01, time/batch = 0.6548s	
2188/25300 (epoch 4.324), train_loss = 1.44127023, grad/param norm = 2.0250e-01, time/batch = 0.6586s	
2189/25300 (epoch 4.326), train_loss = 1.30764668, grad/param norm = 1.7580e-01, time/batch = 0.6663s	
2190/25300 (epoch 4.328), train_loss = 1.40933245, grad/param norm = 1.9318e-01, time/batch = 0.6581s	
2191/25300 (epoch 4.330), train_loss = 1.47764818, grad/param norm = 1.9524e-01, time/batch = 0.6603s	
2192/25300 (epoch 4.332), train_loss = 1.62501479, grad/param norm = 2.0841e-01, time/batch = 0.6645s	
2193/25300 (epoch 4.334), train_loss = 1.50365090, grad/param norm = 2.0215e-01, time/batch = 0.6556s	
2194/25300 (epoch 4.336), train_loss = 1.41319833, grad/param norm = 2.0058e-01, time/batch = 0.6545s	
2195/25300 (epoch 4.338), train_loss = 1.42817312, grad/param norm = 2.1500e-01, time/batch = 0.6542s	
2196/25300 (epoch 4.340), train_loss = 1.51783425, grad/param norm = 2.3128e-01, time/batch = 0.6495s	
2197/25300 (epoch 4.342), train_loss = 1.48653824, grad/param norm = 2.2858e-01, time/batch = 0.6550s	
2198/25300 (epoch 4.344), train_loss = 1.48946791, grad/param norm = 2.1583e-01, time/batch = 0.6563s	
2199/25300 (epoch 4.346), train_loss = 1.54747790, grad/param norm = 2.2766e-01, time/batch = 0.6601s	
2200/25300 (epoch 4.348), train_loss = 1.34804271, grad/param norm = 1.8476e-01, time/batch = 0.6585s	
2201/25300 (epoch 4.350), train_loss = 1.49397596, grad/param norm = 2.1087e-01, time/batch = 0.6604s	
2202/25300 (epoch 4.352), train_loss = 1.57885136, grad/param norm = 2.0345e-01, time/batch = 0.6589s	
2203/25300 (epoch 4.354), train_loss = 1.51711634, grad/param norm = 2.1832e-01, time/batch = 0.6527s	
2204/25300 (epoch 4.356), train_loss = 1.60085357, grad/param norm = 2.3346e-01, time/batch = 0.6533s	
2205/25300 (epoch 4.358), train_loss = 1.69305255, grad/param norm = 2.5657e-01, time/batch = 0.6599s	
2206/25300 (epoch 4.360), train_loss = 1.47142488, grad/param norm = 1.9619e-01, time/batch = 0.6548s	
2207/25300 (epoch 4.362), train_loss = 1.68491291, grad/param norm = 2.1104e-01, time/batch = 0.6538s	
2208/25300 (epoch 4.364), train_loss = 1.71711874, grad/param norm = 2.4930e-01, time/batch = 0.6572s	
2209/25300 (epoch 4.366), train_loss = 1.40204317, grad/param norm = 2.0164e-01, time/batch = 0.6547s	
2210/25300 (epoch 4.368), train_loss = 1.59211669, grad/param norm = 1.9975e-01, time/batch = 0.6514s	
2211/25300 (epoch 4.370), train_loss = 1.57257673, grad/param norm = 2.4278e-01, time/batch = 0.6565s	
2212/25300 (epoch 4.372), train_loss = 1.57144406, grad/param norm = 2.4133e-01, time/batch = 0.6551s	
2213/25300 (epoch 4.374), train_loss = 1.44499561, grad/param norm = 2.1471e-01, time/batch = 0.6529s	
2214/25300 (epoch 4.375), train_loss = 1.79738880, grad/param norm = 2.2901e-01, time/batch = 0.6511s	
2215/25300 (epoch 4.377), train_loss = 1.49207237, grad/param norm = 2.0802e-01, time/batch = 0.6573s	
2216/25300 (epoch 4.379), train_loss = 1.87219420, grad/param norm = 2.4006e-01, time/batch = 0.6534s	
2217/25300 (epoch 4.381), train_loss = 1.52256132, grad/param norm = 1.8513e-01, time/batch = 0.6547s	
2218/25300 (epoch 4.383), train_loss = 1.41447251, grad/param norm = 1.9350e-01, time/batch = 0.6530s	
2219/25300 (epoch 4.385), train_loss = 1.48471902, grad/param norm = 2.0795e-01, time/batch = 0.6522s	
2220/25300 (epoch 4.387), train_loss = 1.70329043, grad/param norm = 2.1725e-01, time/batch = 0.6528s	
2221/25300 (epoch 4.389), train_loss = 1.78842349, grad/param norm = 2.2795e-01, time/batch = 0.6592s	
2222/25300 (epoch 4.391), train_loss = 1.39285494, grad/param norm = 2.1874e-01, time/batch = 0.6562s	
2223/25300 (epoch 4.393), train_loss = 1.65937805, grad/param norm = 2.2426e-01, time/batch = 0.6565s	
2224/25300 (epoch 4.395), train_loss = 1.35618261, grad/param norm = 2.0227e-01, time/batch = 0.6565s	
2225/25300 (epoch 4.397), train_loss = 1.42914848, grad/param norm = 2.0645e-01, time/batch = 0.6552s	
2226/25300 (epoch 4.399), train_loss = 1.43485365, grad/param norm = 1.9434e-01, time/batch = 0.6555s	
2227/25300 (epoch 4.401), train_loss = 1.65548006, grad/param norm = 2.0898e-01, time/batch = 0.6545s	
2228/25300 (epoch 4.403), train_loss = 1.54957712, grad/param norm = 2.4060e-01, time/batch = 0.6522s	
2229/25300 (epoch 4.405), train_loss = 1.64173446, grad/param norm = 2.3178e-01, time/batch = 0.6578s	
2230/25300 (epoch 4.407), train_loss = 1.43928688, grad/param norm = 1.9368e-01, time/batch = 0.6676s	
2231/25300 (epoch 4.409), train_loss = 1.46539048, grad/param norm = 1.9947e-01, time/batch = 0.6722s	
2232/25300 (epoch 4.411), train_loss = 1.54471060, grad/param norm = 2.1521e-01, time/batch = 0.6739s	
2233/25300 (epoch 4.413), train_loss = 1.45795753, grad/param norm = 2.1903e-01, time/batch = 0.6568s	
2234/25300 (epoch 4.415), train_loss = 1.46640436, grad/param norm = 2.1203e-01, time/batch = 0.6591s	
2235/25300 (epoch 4.417), train_loss = 1.45836314, grad/param norm = 2.1608e-01, time/batch = 0.6575s	
2236/25300 (epoch 4.419), train_loss = 1.35805430, grad/param norm = 2.0748e-01, time/batch = 0.6598s	
2237/25300 (epoch 4.421), train_loss = 1.38911800, grad/param norm = 1.9865e-01, time/batch = 0.6700s	
2238/25300 (epoch 4.423), train_loss = 1.41446591, grad/param norm = 1.9146e-01, time/batch = 0.6601s	
2239/25300 (epoch 4.425), train_loss = 1.53659347, grad/param norm = 2.5794e-01, time/batch = 0.6568s	
2240/25300 (epoch 4.427), train_loss = 1.72814805, grad/param norm = 2.1844e-01, time/batch = 0.6555s	
2241/25300 (epoch 4.429), train_loss = 1.66666031, grad/param norm = 2.3821e-01, time/batch = 0.6547s	
2242/25300 (epoch 4.431), train_loss = 1.62808306, grad/param norm = 2.3327e-01, time/batch = 0.6574s	
2243/25300 (epoch 4.433), train_loss = 1.54244399, grad/param norm = 2.1214e-01, time/batch = 0.6574s	
2244/25300 (epoch 4.435), train_loss = 1.40679642, grad/param norm = 2.2569e-01, time/batch = 0.6606s	
2245/25300 (epoch 4.437), train_loss = 1.51639889, grad/param norm = 2.1086e-01, time/batch = 0.6598s	
2246/25300 (epoch 4.439), train_loss = 1.55615491, grad/param norm = 2.2040e-01, time/batch = 0.6595s	
2247/25300 (epoch 4.441), train_loss = 1.56933489, grad/param norm = 2.2090e-01, time/batch = 0.6594s	
2248/25300 (epoch 4.443), train_loss = 1.71278413, grad/param norm = 2.3115e-01, time/batch = 0.6611s	
2249/25300 (epoch 4.445), train_loss = 1.65048000, grad/param norm = 2.1509e-01, time/batch = 0.6556s	
2250/25300 (epoch 4.447), train_loss = 1.42229812, grad/param norm = 2.0107e-01, time/batch = 0.6547s	
2251/25300 (epoch 4.449), train_loss = 1.42827570, grad/param norm = 1.9200e-01, time/batch = 0.6606s	
2252/25300 (epoch 4.451), train_loss = 1.74080061, grad/param norm = 2.2676e-01, time/batch = 0.6599s	
2253/25300 (epoch 4.453), train_loss = 1.60051193, grad/param norm = 2.1366e-01, time/batch = 0.6564s	
2254/25300 (epoch 4.455), train_loss = 1.72460648, grad/param norm = 2.0627e-01, time/batch = 0.6567s	
2255/25300 (epoch 4.457), train_loss = 1.54774252, grad/param norm = 2.1096e-01, time/batch = 0.6573s	
2256/25300 (epoch 4.458), train_loss = 1.66571202, grad/param norm = 2.4353e-01, time/batch = 0.6581s	
2257/25300 (epoch 4.460), train_loss = 1.69754496, grad/param norm = 2.2772e-01, time/batch = 0.6574s	
2258/25300 (epoch 4.462), train_loss = 1.37649135, grad/param norm = 2.3283e-01, time/batch = 0.6555s	
2259/25300 (epoch 4.464), train_loss = 1.61456382, grad/param norm = 2.6124e-01, time/batch = 0.6578s	
2260/25300 (epoch 4.466), train_loss = 1.60247011, grad/param norm = 2.3293e-01, time/batch = 0.6587s	
2261/25300 (epoch 4.468), train_loss = 1.74294955, grad/param norm = 2.2437e-01, time/batch = 0.6593s	
2262/25300 (epoch 4.470), train_loss = 1.46062703, grad/param norm = 2.1504e-01, time/batch = 0.6600s	
2263/25300 (epoch 4.472), train_loss = 1.32338280, grad/param norm = 2.1550e-01, time/batch = 0.6575s	
2264/25300 (epoch 4.474), train_loss = 1.59339976, grad/param norm = 2.3066e-01, time/batch = 0.6553s	
2265/25300 (epoch 4.476), train_loss = 1.58996840, grad/param norm = 2.1494e-01, time/batch = 0.6564s	
2266/25300 (epoch 4.478), train_loss = 1.60594512, grad/param norm = 1.9563e-01, time/batch = 0.6570s	
2267/25300 (epoch 4.480), train_loss = 1.39260592, grad/param norm = 1.9980e-01, time/batch = 0.6547s	
2268/25300 (epoch 4.482), train_loss = 1.73363469, grad/param norm = 2.2767e-01, time/batch = 0.6602s	
2269/25300 (epoch 4.484), train_loss = 1.71295608, grad/param norm = 2.2416e-01, time/batch = 0.6584s	
2270/25300 (epoch 4.486), train_loss = 1.54009095, grad/param norm = 2.1054e-01, time/batch = 0.6530s	
2271/25300 (epoch 4.488), train_loss = 1.61267422, grad/param norm = 2.0152e-01, time/batch = 0.6545s	
2272/25300 (epoch 4.490), train_loss = 1.67141305, grad/param norm = 2.0422e-01, time/batch = 0.6558s	
2273/25300 (epoch 4.492), train_loss = 1.48222708, grad/param norm = 1.9678e-01, time/batch = 0.6580s	
2274/25300 (epoch 4.494), train_loss = 1.39822362, grad/param norm = 2.0768e-01, time/batch = 0.6744s	
2275/25300 (epoch 4.496), train_loss = 1.57400612, grad/param norm = 2.1530e-01, time/batch = 0.6576s	
2276/25300 (epoch 4.498), train_loss = 1.42512014, grad/param norm = 2.0197e-01, time/batch = 0.6674s	
2277/25300 (epoch 4.500), train_loss = 1.73293069, grad/param norm = 2.3566e-01, time/batch = 0.6622s	
2278/25300 (epoch 4.502), train_loss = 1.52160862, grad/param norm = 2.0966e-01, time/batch = 0.6581s	
2279/25300 (epoch 4.504), train_loss = 1.49168174, grad/param norm = 2.1133e-01, time/batch = 0.6619s	
2280/25300 (epoch 4.506), train_loss = 1.57986618, grad/param norm = 2.0895e-01, time/batch = 0.6539s	
2281/25300 (epoch 4.508), train_loss = 1.57985256, grad/param norm = 2.1079e-01, time/batch = 0.6547s	
2282/25300 (epoch 4.510), train_loss = 1.49984428, grad/param norm = 2.2221e-01, time/batch = 0.6536s	
2283/25300 (epoch 4.512), train_loss = 1.21778973, grad/param norm = 1.7173e-01, time/batch = 0.6552s	
2284/25300 (epoch 4.514), train_loss = 1.40506210, grad/param norm = 1.9564e-01, time/batch = 0.6547s	
2285/25300 (epoch 4.516), train_loss = 1.49287374, grad/param norm = 2.0129e-01, time/batch = 0.6587s	
2286/25300 (epoch 4.518), train_loss = 1.65544156, grad/param norm = 2.6600e-01, time/batch = 0.6603s	
2287/25300 (epoch 4.520), train_loss = 1.34707705, grad/param norm = 2.4521e-01, time/batch = 0.6637s	
2288/25300 (epoch 4.522), train_loss = 1.44468896, grad/param norm = 1.8885e-01, time/batch = 0.6556s	
2289/25300 (epoch 4.524), train_loss = 1.42458499, grad/param norm = 1.9509e-01, time/batch = 0.6552s	
2290/25300 (epoch 4.526), train_loss = 1.77499284, grad/param norm = 2.6883e-01, time/batch = 0.6541s	
2291/25300 (epoch 4.528), train_loss = 1.69115603, grad/param norm = 2.4121e-01, time/batch = 0.6574s	
2292/25300 (epoch 4.530), train_loss = 1.51236426, grad/param norm = 2.1118e-01, time/batch = 0.6565s	
2293/25300 (epoch 4.532), train_loss = 1.60415812, grad/param norm = 2.1380e-01, time/batch = 0.6579s	
2294/25300 (epoch 4.534), train_loss = 1.48732070, grad/param norm = 2.0673e-01, time/batch = 0.6560s	
2295/25300 (epoch 4.536), train_loss = 1.42018349, grad/param norm = 2.2654e-01, time/batch = 0.6557s	
2296/25300 (epoch 4.538), train_loss = 1.37612113, grad/param norm = 2.1108e-01, time/batch = 0.6503s	
2297/25300 (epoch 4.540), train_loss = 1.48251191, grad/param norm = 2.1976e-01, time/batch = 0.6566s	
2298/25300 (epoch 4.542), train_loss = 1.39741823, grad/param norm = 2.1538e-01, time/batch = 0.6538s	
2299/25300 (epoch 4.543), train_loss = 1.35771480, grad/param norm = 1.9524e-01, time/batch = 0.6551s	
2300/25300 (epoch 4.545), train_loss = 1.97297047, grad/param norm = 2.2898e-01, time/batch = 0.6540s	
2301/25300 (epoch 4.547), train_loss = 1.45586908, grad/param norm = 2.0531e-01, time/batch = 0.6576s	
2302/25300 (epoch 4.549), train_loss = 1.80998912, grad/param norm = 2.3065e-01, time/batch = 0.6587s	
2303/25300 (epoch 4.551), train_loss = 1.56098796, grad/param norm = 2.3117e-01, time/batch = 0.6571s	
2304/25300 (epoch 4.553), train_loss = 1.62444552, grad/param norm = 2.1235e-01, time/batch = 0.6577s	
2305/25300 (epoch 4.555), train_loss = 1.68002851, grad/param norm = 2.1870e-01, time/batch = 0.6570s	
2306/25300 (epoch 4.557), train_loss = 1.70249190, grad/param norm = 2.1098e-01, time/batch = 0.6600s	
2307/25300 (epoch 4.559), train_loss = 1.66715261, grad/param norm = 2.1911e-01, time/batch = 0.6573s	
2308/25300 (epoch 4.561), train_loss = 1.73226672, grad/param norm = 2.1807e-01, time/batch = 0.6584s	
2309/25300 (epoch 4.563), train_loss = 1.60069526, grad/param norm = 1.9176e-01, time/batch = 0.6575s	
2310/25300 (epoch 4.565), train_loss = 1.40045442, grad/param norm = 1.9011e-01, time/batch = 0.6561s	
2311/25300 (epoch 4.567), train_loss = 1.20926417, grad/param norm = 2.0842e-01, time/batch = 0.6591s	
2312/25300 (epoch 4.569), train_loss = 1.53311440, grad/param norm = 2.0354e-01, time/batch = 0.6591s	
2313/25300 (epoch 4.571), train_loss = 1.62724976, grad/param norm = 2.0433e-01, time/batch = 0.6561s	
2314/25300 (epoch 4.573), train_loss = 1.55649039, grad/param norm = 2.0888e-01, time/batch = 0.6635s	
2315/25300 (epoch 4.575), train_loss = 1.62890181, grad/param norm = 2.1206e-01, time/batch = 0.6634s	
2316/25300 (epoch 4.577), train_loss = 1.61569780, grad/param norm = 2.1998e-01, time/batch = 0.6546s	
2317/25300 (epoch 4.579), train_loss = 1.77491700, grad/param norm = 2.2055e-01, time/batch = 0.6535s	
2318/25300 (epoch 4.581), train_loss = 1.59220201, grad/param norm = 2.0546e-01, time/batch = 0.6521s	
2319/25300 (epoch 4.583), train_loss = 1.44583992, grad/param norm = 2.1459e-01, time/batch = 0.6521s	
2320/25300 (epoch 4.585), train_loss = 1.41558253, grad/param norm = 2.0405e-01, time/batch = 0.6605s	
2321/25300 (epoch 4.587), train_loss = 1.49896539, grad/param norm = 2.0641e-01, time/batch = 0.6690s	
2322/25300 (epoch 4.589), train_loss = 1.34425081, grad/param norm = 1.8588e-01, time/batch = 0.6653s	
2323/25300 (epoch 4.591), train_loss = 1.39920693, grad/param norm = 2.0652e-01, time/batch = 0.6634s	
2324/25300 (epoch 4.593), train_loss = 1.46001544, grad/param norm = 1.9468e-01, time/batch = 0.6576s	
2325/25300 (epoch 4.595), train_loss = 1.53728594, grad/param norm = 2.0481e-01, time/batch = 0.6566s	
2326/25300 (epoch 4.597), train_loss = 1.33164503, grad/param norm = 1.9735e-01, time/batch = 0.6548s	
2327/25300 (epoch 4.599), train_loss = 1.49549139, grad/param norm = 2.0405e-01, time/batch = 0.6543s	
2328/25300 (epoch 4.601), train_loss = 1.57358913, grad/param norm = 2.3370e-01, time/batch = 0.6513s	
2329/25300 (epoch 4.603), train_loss = 1.57015770, grad/param norm = 1.9667e-01, time/batch = 0.6546s	
2330/25300 (epoch 4.605), train_loss = 1.48237564, grad/param norm = 2.0355e-01, time/batch = 0.6480s	
2331/25300 (epoch 4.607), train_loss = 1.40732969, grad/param norm = 2.0424e-01, time/batch = 0.6566s	
2332/25300 (epoch 4.609), train_loss = 1.51720921, grad/param norm = 2.0015e-01, time/batch = 0.6708s	
2333/25300 (epoch 4.611), train_loss = 1.67769242, grad/param norm = 2.0935e-01, time/batch = 0.6598s	
2334/25300 (epoch 4.613), train_loss = 1.48480039, grad/param norm = 2.0802e-01, time/batch = 0.6567s	
2335/25300 (epoch 4.615), train_loss = 1.58757522, grad/param norm = 1.9768e-01, time/batch = 0.6531s	
2336/25300 (epoch 4.617), train_loss = 1.53130769, grad/param norm = 1.9469e-01, time/batch = 0.6578s	
2337/25300 (epoch 4.619), train_loss = 1.60297873, grad/param norm = 2.0929e-01, time/batch = 0.6764s	
2338/25300 (epoch 4.621), train_loss = 1.62794239, grad/param norm = 2.2128e-01, time/batch = 0.6600s	
2339/25300 (epoch 4.623), train_loss = 1.48591146, grad/param norm = 2.1394e-01, time/batch = 0.6623s	
2340/25300 (epoch 4.625), train_loss = 1.38106720, grad/param norm = 2.2391e-01, time/batch = 0.6547s	
2341/25300 (epoch 4.626), train_loss = 1.50677847, grad/param norm = 2.1800e-01, time/batch = 0.6554s	
2342/25300 (epoch 4.628), train_loss = 1.71076998, grad/param norm = 2.2376e-01, time/batch = 0.6657s	
2343/25300 (epoch 4.630), train_loss = 1.70161916, grad/param norm = 2.2213e-01, time/batch = 0.6551s	
2344/25300 (epoch 4.632), train_loss = 1.69856571, grad/param norm = 2.3706e-01, time/batch = 0.6554s	
2345/25300 (epoch 4.634), train_loss = 1.74229784, grad/param norm = 2.1293e-01, time/batch = 0.6536s	
2346/25300 (epoch 4.636), train_loss = 1.56966644, grad/param norm = 2.1984e-01, time/batch = 0.6529s	
2347/25300 (epoch 4.638), train_loss = 1.66599174, grad/param norm = 2.2321e-01, time/batch = 0.6532s	
2348/25300 (epoch 4.640), train_loss = 1.78731506, grad/param norm = 2.2266e-01, time/batch = 0.6531s	
2349/25300 (epoch 4.642), train_loss = 1.63676743, grad/param norm = 2.3495e-01, time/batch = 0.6551s	
2350/25300 (epoch 4.644), train_loss = 1.67660877, grad/param norm = 2.2252e-01, time/batch = 0.6539s	
2351/25300 (epoch 4.646), train_loss = 1.59977758, grad/param norm = 1.9870e-01, time/batch = 0.6558s	
2352/25300 (epoch 4.648), train_loss = 1.67875466, grad/param norm = 2.0062e-01, time/batch = 0.6544s	
2353/25300 (epoch 4.650), train_loss = 1.66891141, grad/param norm = 2.2170e-01, time/batch = 0.6533s	
2354/25300 (epoch 4.652), train_loss = 1.72423134, grad/param norm = 2.2293e-01, time/batch = 0.6558s	
2355/25300 (epoch 4.654), train_loss = 1.75322396, grad/param norm = 2.2635e-01, time/batch = 0.6551s	
2356/25300 (epoch 4.656), train_loss = 1.74503139, grad/param norm = 2.4406e-01, time/batch = 0.6553s	
2357/25300 (epoch 4.658), train_loss = 1.40906943, grad/param norm = 2.0592e-01, time/batch = 0.6553s	
2358/25300 (epoch 4.660), train_loss = 1.40721923, grad/param norm = 1.9876e-01, time/batch = 0.6558s	
2359/25300 (epoch 4.662), train_loss = 1.33965729, grad/param norm = 2.0407e-01, time/batch = 0.6599s	
2360/25300 (epoch 4.664), train_loss = 1.30893792, grad/param norm = 1.7912e-01, time/batch = 0.6638s	
2361/25300 (epoch 4.666), train_loss = 1.37364930, grad/param norm = 2.1410e-01, time/batch = 0.6570s	
2362/25300 (epoch 4.668), train_loss = 1.44886100, grad/param norm = 2.2659e-01, time/batch = 0.6558s	
2363/25300 (epoch 4.670), train_loss = 1.49872609, grad/param norm = 2.0706e-01, time/batch = 0.6569s	
2364/25300 (epoch 4.672), train_loss = 1.52685765, grad/param norm = 2.1487e-01, time/batch = 0.6579s	
2365/25300 (epoch 4.674), train_loss = 1.51906260, grad/param norm = 1.9461e-01, time/batch = 0.6566s	
2366/25300 (epoch 4.676), train_loss = 1.62129652, grad/param norm = 2.2382e-01, time/batch = 0.6587s	
2367/25300 (epoch 4.678), train_loss = 1.52830084, grad/param norm = 2.6598e-01, time/batch = 0.6580s	
2368/25300 (epoch 4.680), train_loss = 1.37205334, grad/param norm = 1.9260e-01, time/batch = 0.6557s	
2369/25300 (epoch 4.682), train_loss = 1.19138690, grad/param norm = 1.8960e-01, time/batch = 0.6557s	
2370/25300 (epoch 4.684), train_loss = 1.33574281, grad/param norm = 1.8413e-01, time/batch = 0.6538s	
2371/25300 (epoch 4.686), train_loss = 1.42408647, grad/param norm = 2.2202e-01, time/batch = 0.6562s	
2372/25300 (epoch 4.688), train_loss = 1.59780374, grad/param norm = 1.9390e-01, time/batch = 0.6568s	
2373/25300 (epoch 4.690), train_loss = 1.48005162, grad/param norm = 1.8381e-01, time/batch = 0.6564s	
2374/25300 (epoch 4.692), train_loss = 1.59303322, grad/param norm = 1.9457e-01, time/batch = 0.6573s	
2375/25300 (epoch 4.694), train_loss = 1.39524502, grad/param norm = 1.7912e-01, time/batch = 0.6558s	
2376/25300 (epoch 4.696), train_loss = 1.52995082, grad/param norm = 1.9633e-01, time/batch = 0.6567s	
2377/25300 (epoch 4.698), train_loss = 1.54345089, grad/param norm = 1.9986e-01, time/batch = 0.6531s	
2378/25300 (epoch 4.700), train_loss = 1.31352768, grad/param norm = 1.9214e-01, time/batch = 0.6554s	
2379/25300 (epoch 4.702), train_loss = 1.70084373, grad/param norm = 2.1880e-01, time/batch = 0.6545s	
2380/25300 (epoch 4.704), train_loss = 1.30016632, grad/param norm = 1.9466e-01, time/batch = 0.6537s	
2381/25300 (epoch 4.706), train_loss = 1.50420721, grad/param norm = 2.3306e-01, time/batch = 0.6596s	
2382/25300 (epoch 4.708), train_loss = 1.27887158, grad/param norm = 1.9299e-01, time/batch = 0.6571s	
2383/25300 (epoch 4.709), train_loss = 1.69850127, grad/param norm = 2.1187e-01, time/batch = 0.6567s	
2384/25300 (epoch 4.711), train_loss = 1.77230773, grad/param norm = 2.3247e-01, time/batch = 0.6568s	
2385/25300 (epoch 4.713), train_loss = 1.50358131, grad/param norm = 2.0609e-01, time/batch = 0.6565s	
2386/25300 (epoch 4.715), train_loss = 1.45346687, grad/param norm = 2.0719e-01, time/batch = 0.6580s	
2387/25300 (epoch 4.717), train_loss = 1.57132965, grad/param norm = 2.2645e-01, time/batch = 0.6568s	
2388/25300 (epoch 4.719), train_loss = 1.48998831, grad/param norm = 2.1974e-01, time/batch = 0.6561s	
2389/25300 (epoch 4.721), train_loss = 1.51044892, grad/param norm = 2.2482e-01, time/batch = 0.6563s	
2390/25300 (epoch 4.723), train_loss = 1.38258137, grad/param norm = 1.9613e-01, time/batch = 0.6571s	
2391/25300 (epoch 4.725), train_loss = 1.51642149, grad/param norm = 2.3866e-01, time/batch = 0.6641s	
2392/25300 (epoch 4.727), train_loss = 1.46570488, grad/param norm = 1.9634e-01, time/batch = 0.6595s	
2393/25300 (epoch 4.729), train_loss = 1.44956912, grad/param norm = 1.9694e-01, time/batch = 0.6582s	
2394/25300 (epoch 4.731), train_loss = 1.75254153, grad/param norm = 2.3775e-01, time/batch = 0.6570s	
2395/25300 (epoch 4.733), train_loss = 1.37200423, grad/param norm = 1.6847e-01, time/batch = 0.6585s	
2396/25300 (epoch 4.735), train_loss = 1.81479145, grad/param norm = 2.2764e-01, time/batch = 0.6568s	
2397/25300 (epoch 4.737), train_loss = 1.34500172, grad/param norm = 2.0340e-01, time/batch = 0.6560s	
2398/25300 (epoch 4.739), train_loss = 1.60446764, grad/param norm = 2.0353e-01, time/batch = 0.6563s	
2399/25300 (epoch 4.741), train_loss = 1.55907542, grad/param norm = 1.9952e-01, time/batch = 0.6570s	
2400/25300 (epoch 4.743), train_loss = 1.43019169, grad/param norm = 1.9231e-01, time/batch = 0.6560s	
2401/25300 (epoch 4.745), train_loss = 1.43090004, grad/param norm = 1.8787e-01, time/batch = 0.6593s	
2402/25300 (epoch 4.747), train_loss = 1.32020967, grad/param norm = 1.6557e-01, time/batch = 0.6586s	
2403/25300 (epoch 4.749), train_loss = 1.53291258, grad/param norm = 2.0507e-01, time/batch = 0.6595s	
2404/25300 (epoch 4.751), train_loss = 1.65082041, grad/param norm = 2.0941e-01, time/batch = 0.6573s	
2405/25300 (epoch 4.753), train_loss = 1.48301076, grad/param norm = 2.2675e-01, time/batch = 0.6599s	
2406/25300 (epoch 4.755), train_loss = 1.61936229, grad/param norm = 2.1773e-01, time/batch = 0.6609s	
2407/25300 (epoch 4.757), train_loss = 1.38921575, grad/param norm = 2.0910e-01, time/batch = 0.6525s	
2408/25300 (epoch 4.759), train_loss = 1.35660571, grad/param norm = 2.1138e-01, time/batch = 0.6538s	
2409/25300 (epoch 4.761), train_loss = 1.65112560, grad/param norm = 2.4508e-01, time/batch = 0.6559s	
2410/25300 (epoch 4.763), train_loss = 1.42183075, grad/param norm = 2.3736e-01, time/batch = 0.6574s	
2411/25300 (epoch 4.765), train_loss = 1.47285693, grad/param norm = 2.2309e-01, time/batch = 0.6615s	
2412/25300 (epoch 4.767), train_loss = 1.39655056, grad/param norm = 2.0983e-01, time/batch = 0.6666s	
2413/25300 (epoch 4.769), train_loss = 1.54648129, grad/param norm = 2.1600e-01, time/batch = 0.6647s	
2414/25300 (epoch 4.771), train_loss = 1.83431340, grad/param norm = 2.2025e-01, time/batch = 0.6781s	
2415/25300 (epoch 4.773), train_loss = 1.68723185, grad/param norm = 2.1669e-01, time/batch = 0.6667s	
2416/25300 (epoch 4.775), train_loss = 1.46203602, grad/param norm = 1.9166e-01, time/batch = 0.6647s	
2417/25300 (epoch 4.777), train_loss = 1.56385282, grad/param norm = 2.1061e-01, time/batch = 0.6585s	
2418/25300 (epoch 4.779), train_loss = 1.64472664, grad/param norm = 1.9158e-01, time/batch = 0.6596s	
2419/25300 (epoch 4.781), train_loss = 1.46037166, grad/param norm = 2.0415e-01, time/batch = 0.6696s	
2420/25300 (epoch 4.783), train_loss = 1.70499295, grad/param norm = 2.0789e-01, time/batch = 0.6621s	
2421/25300 (epoch 4.785), train_loss = 1.61133874, grad/param norm = 2.1693e-01, time/batch = 0.6576s	
2422/25300 (epoch 4.787), train_loss = 1.65610499, grad/param norm = 2.1493e-01, time/batch = 0.6572s	
2423/25300 (epoch 4.789), train_loss = 1.76521794, grad/param norm = 1.9976e-01, time/batch = 0.6542s	
2424/25300 (epoch 4.791), train_loss = 1.49974787, grad/param norm = 2.0295e-01, time/batch = 0.6594s	
2425/25300 (epoch 4.792), train_loss = 1.60486366, grad/param norm = 2.0281e-01, time/batch = 0.6537s	
2426/25300 (epoch 4.794), train_loss = 1.61814169, grad/param norm = 2.0428e-01, time/batch = 0.6498s	
2427/25300 (epoch 4.796), train_loss = 1.48935318, grad/param norm = 1.8984e-01, time/batch = 0.6580s	
2428/25300 (epoch 4.798), train_loss = 1.66495756, grad/param norm = 1.9526e-01, time/batch = 0.6540s	
2429/25300 (epoch 4.800), train_loss = 1.58439272, grad/param norm = 2.1416e-01, time/batch = 0.6610s	
2430/25300 (epoch 4.802), train_loss = 1.25262833, grad/param norm = 1.9020e-01, time/batch = 0.6619s	
2431/25300 (epoch 4.804), train_loss = 1.52822271, grad/param norm = 1.9418e-01, time/batch = 0.6599s	
2432/25300 (epoch 4.806), train_loss = 1.61906604, grad/param norm = 2.0827e-01, time/batch = 0.6579s	
2433/25300 (epoch 4.808), train_loss = 1.50510564, grad/param norm = 1.9864e-01, time/batch = 0.6598s	
2434/25300 (epoch 4.810), train_loss = 1.52129325, grad/param norm = 2.4143e-01, time/batch = 0.6765s	
2435/25300 (epoch 4.812), train_loss = 1.54244138, grad/param norm = 1.9752e-01, time/batch = 0.6569s	
2436/25300 (epoch 4.814), train_loss = 1.74884732, grad/param norm = 2.0675e-01, time/batch = 0.6578s	
2437/25300 (epoch 4.816), train_loss = 1.79609657, grad/param norm = 2.2433e-01, time/batch = 0.6571s	
2438/25300 (epoch 4.818), train_loss = 1.66474520, grad/param norm = 1.9945e-01, time/batch = 0.6550s	
2439/25300 (epoch 4.820), train_loss = 1.54197795, grad/param norm = 1.8440e-01, time/batch = 0.6572s	
2440/25300 (epoch 4.822), train_loss = 1.48411936, grad/param norm = 1.7987e-01, time/batch = 0.6536s	
2441/25300 (epoch 4.824), train_loss = 1.59860300, grad/param norm = 2.0137e-01, time/batch = 0.6531s	
2442/25300 (epoch 4.826), train_loss = 1.45986046, grad/param norm = 2.2975e-01, time/batch = 0.6612s	
2443/25300 (epoch 4.828), train_loss = 1.46135684, grad/param norm = 2.0317e-01, time/batch = 0.6645s	
2444/25300 (epoch 4.830), train_loss = 1.48450102, grad/param norm = 1.9828e-01, time/batch = 0.6616s	
2445/25300 (epoch 4.832), train_loss = 1.49223696, grad/param norm = 1.9948e-01, time/batch = 0.6654s	
2446/25300 (epoch 4.834), train_loss = 1.34534116, grad/param norm = 2.0503e-01, time/batch = 0.6661s	
2447/25300 (epoch 4.836), train_loss = 1.43129406, grad/param norm = 2.0517e-01, time/batch = 0.6606s	
2448/25300 (epoch 4.838), train_loss = 1.51946369, grad/param norm = 2.0915e-01, time/batch = 0.6625s	
2449/25300 (epoch 4.840), train_loss = 1.69062753, grad/param norm = 1.9975e-01, time/batch = 0.6638s	
2450/25300 (epoch 4.842), train_loss = 1.62361826, grad/param norm = 2.3629e-01, time/batch = 0.6643s	
2451/25300 (epoch 4.844), train_loss = 1.52846407, grad/param norm = 1.9757e-01, time/batch = 0.6665s	
2452/25300 (epoch 4.846), train_loss = 1.44434528, grad/param norm = 1.8958e-01, time/batch = 0.6641s	
2453/25300 (epoch 4.848), train_loss = 1.74674304, grad/param norm = 2.2905e-01, time/batch = 0.6570s	
2454/25300 (epoch 4.850), train_loss = 1.61919065, grad/param norm = 2.0525e-01, time/batch = 0.6570s	
2455/25300 (epoch 4.852), train_loss = 1.52350531, grad/param norm = 2.2572e-01, time/batch = 0.6562s	
2456/25300 (epoch 4.854), train_loss = 1.73965531, grad/param norm = 2.2109e-01, time/batch = 0.6543s	
2457/25300 (epoch 4.856), train_loss = 1.51591619, grad/param norm = 2.0574e-01, time/batch = 0.6619s	
2458/25300 (epoch 4.858), train_loss = 1.58052817, grad/param norm = 2.0732e-01, time/batch = 0.6575s	
2459/25300 (epoch 4.860), train_loss = 1.32085294, grad/param norm = 2.1640e-01, time/batch = 0.6543s	
2460/25300 (epoch 4.862), train_loss = 1.61524285, grad/param norm = 2.2805e-01, time/batch = 0.6522s	
2461/25300 (epoch 4.864), train_loss = 1.68225105, grad/param norm = 2.0214e-01, time/batch = 0.6524s	
2462/25300 (epoch 4.866), train_loss = 1.64595960, grad/param norm = 2.3095e-01, time/batch = 0.6501s	
2463/25300 (epoch 4.868), train_loss = 1.71591483, grad/param norm = 2.4281e-01, time/batch = 0.6536s	
2464/25300 (epoch 4.870), train_loss = 1.61396719, grad/param norm = 2.0813e-01, time/batch = 0.6548s	
2465/25300 (epoch 4.872), train_loss = 1.59605775, grad/param norm = 2.1430e-01, time/batch = 0.6659s	
2466/25300 (epoch 4.874), train_loss = 1.61567650, grad/param norm = 2.3488e-01, time/batch = 0.6623s	
2467/25300 (epoch 4.875), train_loss = 1.52243891, grad/param norm = 2.1154e-01, time/batch = 0.6576s	
2468/25300 (epoch 4.877), train_loss = 1.39274353, grad/param norm = 1.7958e-01, time/batch = 0.6563s	
2469/25300 (epoch 4.879), train_loss = 1.58492415, grad/param norm = 1.9265e-01, time/batch = 0.6621s	
2470/25300 (epoch 4.881), train_loss = 1.86607321, grad/param norm = 2.1258e-01, time/batch = 0.6562s	
2471/25300 (epoch 4.883), train_loss = 1.77569853, grad/param norm = 2.0041e-01, time/batch = 0.6565s	
2472/25300 (epoch 4.885), train_loss = 1.69200585, grad/param norm = 2.1601e-01, time/batch = 0.6584s	
2473/25300 (epoch 4.887), train_loss = 1.51813984, grad/param norm = 1.9181e-01, time/batch = 0.6548s	
2474/25300 (epoch 4.889), train_loss = 1.76947322, grad/param norm = 2.2288e-01, time/batch = 0.6510s	
2475/25300 (epoch 4.891), train_loss = 1.72669074, grad/param norm = 2.2411e-01, time/batch = 0.6537s	
2476/25300 (epoch 4.893), train_loss = 1.82282994, grad/param norm = 2.3718e-01, time/batch = 0.6546s	
2477/25300 (epoch 4.895), train_loss = 1.26375479, grad/param norm = 1.9425e-01, time/batch = 0.6527s	
2478/25300 (epoch 4.897), train_loss = 1.44286287, grad/param norm = 1.9485e-01, time/batch = 0.6546s	
2479/25300 (epoch 4.899), train_loss = 1.53763629, grad/param norm = 2.1849e-01, time/batch = 0.6540s	
2480/25300 (epoch 4.901), train_loss = 1.63639482, grad/param norm = 2.2010e-01, time/batch = 0.6570s	
2481/25300 (epoch 4.903), train_loss = 1.35566441, grad/param norm = 2.0517e-01, time/batch = 0.6591s	
2482/25300 (epoch 4.905), train_loss = 1.45182669, grad/param norm = 2.1384e-01, time/batch = 0.6589s	
2483/25300 (epoch 4.907), train_loss = 1.69411519, grad/param norm = 2.4530e-01, time/batch = 0.6633s	
2484/25300 (epoch 4.909), train_loss = 1.64887684, grad/param norm = 1.9099e-01, time/batch = 0.6644s	
2485/25300 (epoch 4.911), train_loss = 1.75260495, grad/param norm = 2.2267e-01, time/batch = 0.6616s	
2486/25300 (epoch 4.913), train_loss = 1.72690797, grad/param norm = 2.2726e-01, time/batch = 0.6620s	
2487/25300 (epoch 4.915), train_loss = 1.52109979, grad/param norm = 2.1769e-01, time/batch = 0.6650s	
2488/25300 (epoch 4.917), train_loss = 1.63040780, grad/param norm = 2.0897e-01, time/batch = 0.6651s	
2489/25300 (epoch 4.919), train_loss = 1.66264799, grad/param norm = 2.2597e-01, time/batch = 0.6557s	
2490/25300 (epoch 4.921), train_loss = 1.43159035, grad/param norm = 2.2779e-01, time/batch = 0.6565s	
2491/25300 (epoch 4.923), train_loss = 1.66050342, grad/param norm = 1.9482e-01, time/batch = 0.6589s	
2492/25300 (epoch 4.925), train_loss = 1.59516600, grad/param norm = 2.0554e-01, time/batch = 0.6592s	
2493/25300 (epoch 4.927), train_loss = 1.54285745, grad/param norm = 2.0400e-01, time/batch = 0.6647s	
2494/25300 (epoch 4.929), train_loss = 1.43610069, grad/param norm = 2.0383e-01, time/batch = 0.6571s	
2495/25300 (epoch 4.931), train_loss = 1.69910219, grad/param norm = 2.1298e-01, time/batch = 0.6617s	
2496/25300 (epoch 4.933), train_loss = 1.57375157, grad/param norm = 1.9822e-01, time/batch = 0.6584s	
2497/25300 (epoch 4.935), train_loss = 1.50091850, grad/param norm = 1.9423e-01, time/batch = 0.6644s	
2498/25300 (epoch 4.937), train_loss = 1.24502047, grad/param norm = 1.6450e-01, time/batch = 0.6572s	
2499/25300 (epoch 4.939), train_loss = 1.65270241, grad/param norm = 1.9607e-01, time/batch = 0.6561s	
2500/25300 (epoch 4.941), train_loss = 1.47368435, grad/param norm = 1.9114e-01, time/batch = 0.6612s	
2501/25300 (epoch 4.943), train_loss = 1.38242421, grad/param norm = 1.8549e-01, time/batch = 0.6669s	
2502/25300 (epoch 4.945), train_loss = 1.52967087, grad/param norm = 1.9687e-01, time/batch = 0.6671s	
2503/25300 (epoch 4.947), train_loss = 1.48365242, grad/param norm = 2.1760e-01, time/batch = 0.6678s	
2504/25300 (epoch 4.949), train_loss = 1.64355207, grad/param norm = 2.1155e-01, time/batch = 0.6721s	
2505/25300 (epoch 4.951), train_loss = 1.54574712, grad/param norm = 1.8775e-01, time/batch = 0.6655s	
2506/25300 (epoch 4.953), train_loss = 1.68493412, grad/param norm = 1.9856e-01, time/batch = 0.6659s	
2507/25300 (epoch 4.955), train_loss = 1.78670866, grad/param norm = 2.2029e-01, time/batch = 0.6637s	
2508/25300 (epoch 4.957), train_loss = 1.73430620, grad/param norm = 2.3082e-01, time/batch = 0.6559s	
2509/25300 (epoch 4.958), train_loss = 1.58490161, grad/param norm = 2.1364e-01, time/batch = 0.6550s	
2510/25300 (epoch 4.960), train_loss = 1.75769796, grad/param norm = 2.1693e-01, time/batch = 0.6572s	
2511/25300 (epoch 4.962), train_loss = 1.63662676, grad/param norm = 2.2187e-01, time/batch = 0.6514s	
2512/25300 (epoch 4.964), train_loss = 1.59140378, grad/param norm = 1.9527e-01, time/batch = 0.6565s	
2513/25300 (epoch 4.966), train_loss = 1.37232385, grad/param norm = 1.8817e-01, time/batch = 0.6568s	
2514/25300 (epoch 4.968), train_loss = 1.33825353, grad/param norm = 1.8012e-01, time/batch = 0.6561s	
2515/25300 (epoch 4.970), train_loss = 1.61036615, grad/param norm = 2.3402e-01, time/batch = 0.6580s	
2516/25300 (epoch 4.972), train_loss = 1.56674230, grad/param norm = 2.0782e-01, time/batch = 0.6602s	
2517/25300 (epoch 4.974), train_loss = 1.77093747, grad/param norm = 2.2644e-01, time/batch = 0.6636s	
2518/25300 (epoch 4.976), train_loss = 1.57484183, grad/param norm = 2.0874e-01, time/batch = 0.6703s	
2519/25300 (epoch 4.978), train_loss = 1.59203311, grad/param norm = 1.9938e-01, time/batch = 0.6674s	
2520/25300 (epoch 4.980), train_loss = 1.63725586, grad/param norm = 2.1435e-01, time/batch = 0.6559s	
2521/25300 (epoch 4.982), train_loss = 1.53592756, grad/param norm = 2.0559e-01, time/batch = 0.6642s	
2522/25300 (epoch 4.984), train_loss = 1.51852955, grad/param norm = 1.9957e-01, time/batch = 0.6688s	
2523/25300 (epoch 4.986), train_loss = 1.57537112, grad/param norm = 2.3089e-01, time/batch = 0.6606s	
2524/25300 (epoch 4.988), train_loss = 1.53094454, grad/param norm = 2.0455e-01, time/batch = 0.6602s	
2525/25300 (epoch 4.990), train_loss = 1.54408550, grad/param norm = 2.0561e-01, time/batch = 0.6600s	
2526/25300 (epoch 4.992), train_loss = 1.22906909, grad/param norm = 1.8610e-01, time/batch = 0.6628s	
2527/25300 (epoch 4.994), train_loss = 1.60682487, grad/param norm = 2.1631e-01, time/batch = 0.6642s	
2528/25300 (epoch 4.996), train_loss = 1.68813124, grad/param norm = 2.1828e-01, time/batch = 0.6568s	
2529/25300 (epoch 4.998), train_loss = 1.67137071, grad/param norm = 1.9874e-01, time/batch = 0.6544s	
2530/25300 (epoch 5.000), train_loss = 1.53548326, grad/param norm = 2.2208e-01, time/batch = 0.6567s	
2531/25300 (epoch 5.002), train_loss = 1.39365839, grad/param norm = 1.7800e-01, time/batch = 0.6556s	
2532/25300 (epoch 5.004), train_loss = 1.31979697, grad/param norm = 2.0908e-01, time/batch = 0.6571s	
2533/25300 (epoch 5.006), train_loss = 1.55291235, grad/param norm = 1.9854e-01, time/batch = 0.6579s	
2534/25300 (epoch 5.008), train_loss = 1.57538715, grad/param norm = 1.9850e-01, time/batch = 0.6568s	
2535/25300 (epoch 5.010), train_loss = 1.60007747, grad/param norm = 1.9978e-01, time/batch = 0.6537s	
2536/25300 (epoch 5.012), train_loss = 1.39232370, grad/param norm = 2.0722e-01, time/batch = 0.6553s	
2537/25300 (epoch 5.014), train_loss = 1.60823213, grad/param norm = 2.0706e-01, time/batch = 0.6579s	
2538/25300 (epoch 5.016), train_loss = 1.61513219, grad/param norm = 2.1639e-01, time/batch = 0.6563s	
2539/25300 (epoch 5.018), train_loss = 1.45719519, grad/param norm = 1.9697e-01, time/batch = 0.6532s	
2540/25300 (epoch 5.020), train_loss = 1.46690372, grad/param norm = 1.9119e-01, time/batch = 0.6574s	
2541/25300 (epoch 5.022), train_loss = 1.53453098, grad/param norm = 2.1679e-01, time/batch = 0.6592s	
2542/25300 (epoch 5.024), train_loss = 1.19915628, grad/param norm = 1.8577e-01, time/batch = 0.6604s	
2543/25300 (epoch 5.026), train_loss = 1.46843818, grad/param norm = 2.1980e-01, time/batch = 0.6604s	
2544/25300 (epoch 5.028), train_loss = 1.32588759, grad/param norm = 1.8921e-01, time/batch = 0.6595s	
2545/25300 (epoch 5.030), train_loss = 1.60250285, grad/param norm = 2.1066e-01, time/batch = 0.6579s	
2546/25300 (epoch 5.032), train_loss = 1.46965316, grad/param norm = 1.8343e-01, time/batch = 0.6565s	
2547/25300 (epoch 5.034), train_loss = 1.24391666, grad/param norm = 2.0119e-01, time/batch = 0.6594s	
2548/25300 (epoch 5.036), train_loss = 1.33094103, grad/param norm = 1.8583e-01, time/batch = 0.6590s	
2549/25300 (epoch 5.038), train_loss = 1.18502424, grad/param norm = 1.6454e-01, time/batch = 0.6576s	
2550/25300 (epoch 5.040), train_loss = 1.60021767, grad/param norm = 2.0364e-01, time/batch = 0.6580s	
2551/25300 (epoch 5.042), train_loss = 1.29358583, grad/param norm = 1.7495e-01, time/batch = 0.6609s	
2552/25300 (epoch 5.043), train_loss = 1.26889233, grad/param norm = 1.7701e-01, time/batch = 0.6613s	
2553/25300 (epoch 5.045), train_loss = 1.29168758, grad/param norm = 1.8547e-01, time/batch = 0.6574s	
2554/25300 (epoch 5.047), train_loss = 1.60012501, grad/param norm = 1.9804e-01, time/batch = 0.6568s	
2555/25300 (epoch 5.049), train_loss = 1.57529672, grad/param norm = 2.1749e-01, time/batch = 0.6600s	
2556/25300 (epoch 5.051), train_loss = 1.63111022, grad/param norm = 2.1718e-01, time/batch = 0.6573s	
2557/25300 (epoch 5.053), train_loss = 1.30291538, grad/param norm = 1.8597e-01, time/batch = 0.6564s	
2558/25300 (epoch 5.055), train_loss = 1.25631453, grad/param norm = 1.6943e-01, time/batch = 0.6588s	
2559/25300 (epoch 5.057), train_loss = 1.26709202, grad/param norm = 1.7238e-01, time/batch = 0.6610s	
2560/25300 (epoch 5.059), train_loss = 1.54793129, grad/param norm = 2.1162e-01, time/batch = 0.6545s	
2561/25300 (epoch 5.061), train_loss = 1.41539722, grad/param norm = 2.0031e-01, time/batch = 0.6576s	
2562/25300 (epoch 5.063), train_loss = 1.43045303, grad/param norm = 1.7993e-01, time/batch = 0.6568s	
2563/25300 (epoch 5.065), train_loss = 1.65727711, grad/param norm = 2.2988e-01, time/batch = 0.6574s	
2564/25300 (epoch 5.067), train_loss = 1.60779352, grad/param norm = 2.0050e-01, time/batch = 0.6544s	
2565/25300 (epoch 5.069), train_loss = 1.54170873, grad/param norm = 1.9898e-01, time/batch = 0.6571s	
2566/25300 (epoch 5.071), train_loss = 1.60802311, grad/param norm = 1.9623e-01, time/batch = 0.6565s	
2567/25300 (epoch 5.073), train_loss = 1.46464764, grad/param norm = 1.9117e-01, time/batch = 0.6569s	
2568/25300 (epoch 5.075), train_loss = 1.43898424, grad/param norm = 1.7483e-01, time/batch = 0.6567s	
2569/25300 (epoch 5.077), train_loss = 1.58690462, grad/param norm = 2.0836e-01, time/batch = 0.6567s	
2570/25300 (epoch 5.079), train_loss = 1.56444332, grad/param norm = 2.0345e-01, time/batch = 0.6567s	
2571/25300 (epoch 5.081), train_loss = 1.45323640, grad/param norm = 1.8566e-01, time/batch = 0.6577s	
2572/25300 (epoch 5.083), train_loss = 1.37197473, grad/param norm = 2.0649e-01, time/batch = 0.6601s	
2573/25300 (epoch 5.085), train_loss = 1.72532460, grad/param norm = 2.1496e-01, time/batch = 0.6569s	
2574/25300 (epoch 5.087), train_loss = 1.49785080, grad/param norm = 2.1090e-01, time/batch = 0.6564s	
2575/25300 (epoch 5.089), train_loss = 1.49090309, grad/param norm = 1.9724e-01, time/batch = 0.6555s	
2576/25300 (epoch 5.091), train_loss = 1.59019555, grad/param norm = 2.0688e-01, time/batch = 0.6553s	
2577/25300 (epoch 5.093), train_loss = 1.77486462, grad/param norm = 2.2478e-01, time/batch = 0.6666s	
2578/25300 (epoch 5.095), train_loss = 1.55378223, grad/param norm = 1.8747e-01, time/batch = 0.6607s	
2579/25300 (epoch 5.097), train_loss = 1.50304007, grad/param norm = 1.9669e-01, time/batch = 0.6586s	
2580/25300 (epoch 5.099), train_loss = 1.54338599, grad/param norm = 2.1419e-01, time/batch = 0.6549s	
2581/25300 (epoch 5.101), train_loss = 1.46756192, grad/param norm = 2.1243e-01, time/batch = 0.6568s	
2582/25300 (epoch 5.103), train_loss = 1.46707048, grad/param norm = 1.9293e-01, time/batch = 0.6543s	
2583/25300 (epoch 5.105), train_loss = 1.55838450, grad/param norm = 2.0378e-01, time/batch = 0.6514s	
2584/25300 (epoch 5.107), train_loss = 1.62978903, grad/param norm = 2.1121e-01, time/batch = 0.6533s	
2585/25300 (epoch 5.109), train_loss = 1.59607664, grad/param norm = 2.1210e-01, time/batch = 0.6523s	
2586/25300 (epoch 5.111), train_loss = 1.43220571, grad/param norm = 1.8850e-01, time/batch = 0.6539s	
2587/25300 (epoch 5.113), train_loss = 1.49859856, grad/param norm = 2.0489e-01, time/batch = 0.6536s	
2588/25300 (epoch 5.115), train_loss = 1.49148920, grad/param norm = 1.8314e-01, time/batch = 0.6570s	
2589/25300 (epoch 5.117), train_loss = 1.55599557, grad/param norm = 1.8694e-01, time/batch = 0.6576s	
2590/25300 (epoch 5.119), train_loss = 1.48884214, grad/param norm = 2.0554e-01, time/batch = 0.6616s	
2591/25300 (epoch 5.121), train_loss = 1.67767682, grad/param norm = 2.2062e-01, time/batch = 0.6574s	
2592/25300 (epoch 5.123), train_loss = 1.49292448, grad/param norm = 2.1086e-01, time/batch = 0.6589s	
2593/25300 (epoch 5.125), train_loss = 1.60314516, grad/param norm = 2.1173e-01, time/batch = 0.6665s	
2594/25300 (epoch 5.126), train_loss = 1.52606296, grad/param norm = 2.1201e-01, time/batch = 0.6689s	
2595/25300 (epoch 5.128), train_loss = 1.51406578, grad/param norm = 1.9241e-01, time/batch = 0.6655s	
2596/25300 (epoch 5.130), train_loss = 1.19449561, grad/param norm = 1.6492e-01, time/batch = 0.6586s	
2597/25300 (epoch 5.132), train_loss = 1.37473675, grad/param norm = 1.9241e-01, time/batch = 0.6598s	
2598/25300 (epoch 5.134), train_loss = 1.20865643, grad/param norm = 1.9123e-01, time/batch = 0.6547s	
2599/25300 (epoch 5.136), train_loss = 1.54604935, grad/param norm = 2.1936e-01, time/batch = 0.6560s	
2600/25300 (epoch 5.138), train_loss = 1.36244274, grad/param norm = 1.8856e-01, time/batch = 0.6514s	
2601/25300 (epoch 5.140), train_loss = 1.35305488, grad/param norm = 1.8657e-01, time/batch = 0.6513s	
2602/25300 (epoch 5.142), train_loss = 1.58965620, grad/param norm = 2.0398e-01, time/batch = 0.6551s	
2603/25300 (epoch 5.144), train_loss = 1.50133869, grad/param norm = 2.0836e-01, time/batch = 0.6535s	
2604/25300 (epoch 5.146), train_loss = 1.64874037, grad/param norm = 2.1466e-01, time/batch = 0.6545s	
2605/25300 (epoch 5.148), train_loss = 1.57501434, grad/param norm = 1.9706e-01, time/batch = 0.6529s	
2606/25300 (epoch 5.150), train_loss = 1.66289166, grad/param norm = 2.3746e-01, time/batch = 0.6540s	
2607/25300 (epoch 5.152), train_loss = 1.79751613, grad/param norm = 2.3247e-01, time/batch = 0.6566s	
2608/25300 (epoch 5.154), train_loss = 1.42206585, grad/param norm = 2.0016e-01, time/batch = 0.6592s	
2609/25300 (epoch 5.156), train_loss = 1.54944153, grad/param norm = 2.0178e-01, time/batch = 0.6624s	
2610/25300 (epoch 5.158), train_loss = 1.46799145, grad/param norm = 1.9958e-01, time/batch = 0.6584s	
2611/25300 (epoch 5.160), train_loss = 1.50141411, grad/param norm = 2.0629e-01, time/batch = 0.6621s	
2612/25300 (epoch 5.162), train_loss = 1.44061481, grad/param norm = 2.1871e-01, time/batch = 0.6700s	
2613/25300 (epoch 5.164), train_loss = 1.53624196, grad/param norm = 2.1221e-01, time/batch = 0.6671s	
2614/25300 (epoch 5.166), train_loss = 1.54998050, grad/param norm = 2.1058e-01, time/batch = 0.6676s	
2615/25300 (epoch 5.168), train_loss = 1.30928073, grad/param norm = 1.8163e-01, time/batch = 0.6618s	
2616/25300 (epoch 5.170), train_loss = 1.40312306, grad/param norm = 1.9604e-01, time/batch = 0.6625s	
2617/25300 (epoch 5.172), train_loss = 1.37660512, grad/param norm = 1.9029e-01, time/batch = 0.6631s	
2618/25300 (epoch 5.174), train_loss = 1.36143766, grad/param norm = 1.7905e-01, time/batch = 0.6635s	
2619/25300 (epoch 5.176), train_loss = 1.46495049, grad/param norm = 2.0439e-01, time/batch = 0.6606s	
2620/25300 (epoch 5.178), train_loss = 1.68560372, grad/param norm = 2.1081e-01, time/batch = 0.6584s	
2621/25300 (epoch 5.180), train_loss = 1.27266269, grad/param norm = 1.8257e-01, time/batch = 0.6623s	
2622/25300 (epoch 5.182), train_loss = 1.44073924, grad/param norm = 1.9596e-01, time/batch = 0.6693s	
2623/25300 (epoch 5.184), train_loss = 1.47163962, grad/param norm = 1.9404e-01, time/batch = 0.6658s	
2624/25300 (epoch 5.186), train_loss = 1.49820677, grad/param norm = 2.0854e-01, time/batch = 0.6640s	
2625/25300 (epoch 5.188), train_loss = 1.43079355, grad/param norm = 1.9322e-01, time/batch = 0.6611s	
2626/25300 (epoch 5.190), train_loss = 1.55636196, grad/param norm = 2.1023e-01, time/batch = 0.6569s	
2627/25300 (epoch 5.192), train_loss = 1.54312509, grad/param norm = 2.2310e-01, time/batch = 0.6524s	
2628/25300 (epoch 5.194), train_loss = 1.48324898, grad/param norm = 1.8479e-01, time/batch = 0.6574s	
2629/25300 (epoch 5.196), train_loss = 1.56169756, grad/param norm = 2.0855e-01, time/batch = 0.6566s	
2630/25300 (epoch 5.198), train_loss = 1.45634583, grad/param norm = 1.9946e-01, time/batch = 0.6560s	
2631/25300 (epoch 5.200), train_loss = 1.55958524, grad/param norm = 1.9569e-01, time/batch = 0.6577s	
2632/25300 (epoch 5.202), train_loss = 1.54708011, grad/param norm = 1.9586e-01, time/batch = 0.6540s	
2633/25300 (epoch 5.204), train_loss = 1.44585238, grad/param norm = 1.9010e-01, time/batch = 0.6557s	
2634/25300 (epoch 5.206), train_loss = 1.53712455, grad/param norm = 2.0930e-01, time/batch = 0.6562s	
2635/25300 (epoch 5.208), train_loss = 1.36936374, grad/param norm = 2.2000e-01, time/batch = 0.6614s	
2636/25300 (epoch 5.209), train_loss = 1.24029415, grad/param norm = 1.8173e-01, time/batch = 0.6555s	
2637/25300 (epoch 5.211), train_loss = 1.46703981, grad/param norm = 1.9972e-01, time/batch = 0.6537s	
2638/25300 (epoch 5.213), train_loss = 1.54741206, grad/param norm = 2.1074e-01, time/batch = 0.6539s	
2639/25300 (epoch 5.215), train_loss = 1.48116195, grad/param norm = 2.0734e-01, time/batch = 0.6593s	
2640/25300 (epoch 5.217), train_loss = 1.58519133, grad/param norm = 2.1961e-01, time/batch = 0.6627s	
2641/25300 (epoch 5.219), train_loss = 1.50180841, grad/param norm = 1.9713e-01, time/batch = 0.6625s	
2642/25300 (epoch 5.221), train_loss = 1.62439849, grad/param norm = 2.1135e-01, time/batch = 0.6580s	
2643/25300 (epoch 5.223), train_loss = 1.59444668, grad/param norm = 2.1089e-01, time/batch = 0.6665s	
2644/25300 (epoch 5.225), train_loss = 1.96677703, grad/param norm = 2.4369e-01, time/batch = 0.6548s	
2645/25300 (epoch 5.227), train_loss = 1.56268856, grad/param norm = 1.8466e-01, time/batch = 0.6546s	
2646/25300 (epoch 5.229), train_loss = 1.59144736, grad/param norm = 2.1193e-01, time/batch = 0.6559s	
2647/25300 (epoch 5.231), train_loss = 1.53329665, grad/param norm = 1.9905e-01, time/batch = 0.6583s	
2648/25300 (epoch 5.233), train_loss = 1.52773126, grad/param norm = 1.9040e-01, time/batch = 0.6567s	
2649/25300 (epoch 5.235), train_loss = 1.47553020, grad/param norm = 1.9556e-01, time/batch = 0.6573s	
2650/25300 (epoch 5.237), train_loss = 1.66272648, grad/param norm = 2.0237e-01, time/batch = 0.6550s	
2651/25300 (epoch 5.239), train_loss = 1.51037704, grad/param norm = 2.1606e-01, time/batch = 0.6565s	
2652/25300 (epoch 5.241), train_loss = 1.58149916, grad/param norm = 2.0537e-01, time/batch = 0.6539s	
2653/25300 (epoch 5.243), train_loss = 1.86757161, grad/param norm = 2.3003e-01, time/batch = 0.6551s	
2654/25300 (epoch 5.245), train_loss = 1.40923227, grad/param norm = 2.1451e-01, time/batch = 0.6576s	
2655/25300 (epoch 5.247), train_loss = 1.66784340, grad/param norm = 2.2726e-01, time/batch = 0.6635s	
2656/25300 (epoch 5.249), train_loss = 1.36751076, grad/param norm = 2.0050e-01, time/batch = 0.6552s	
2657/25300 (epoch 5.251), train_loss = 1.30418628, grad/param norm = 1.9082e-01, time/batch = 0.6552s	
2658/25300 (epoch 5.253), train_loss = 1.46410727, grad/param norm = 1.8680e-01, time/batch = 0.6532s	
2659/25300 (epoch 5.255), train_loss = 1.43681764, grad/param norm = 1.9322e-01, time/batch = 0.6501s	
2660/25300 (epoch 5.257), train_loss = 1.66384807, grad/param norm = 2.1020e-01, time/batch = 0.6547s	
2661/25300 (epoch 5.259), train_loss = 1.84397821, grad/param norm = 2.3115e-01, time/batch = 0.6568s	
2662/25300 (epoch 5.261), train_loss = 1.68016044, grad/param norm = 2.2391e-01, time/batch = 0.6562s	
2663/25300 (epoch 5.263), train_loss = 1.59761951, grad/param norm = 1.9813e-01, time/batch = 0.6541s	
2664/25300 (epoch 5.265), train_loss = 1.66721452, grad/param norm = 2.0967e-01, time/batch = 0.6552s	
2665/25300 (epoch 5.267), train_loss = 1.63031913, grad/param norm = 1.9657e-01, time/batch = 0.6593s	
2666/25300 (epoch 5.269), train_loss = 1.34364313, grad/param norm = 1.8800e-01, time/batch = 0.6565s	
2667/25300 (epoch 5.271), train_loss = 1.38833183, grad/param norm = 1.9920e-01, time/batch = 0.6555s	
2668/25300 (epoch 5.273), train_loss = 1.54702055, grad/param norm = 1.9398e-01, time/batch = 0.6546s	
2669/25300 (epoch 5.275), train_loss = 1.32648195, grad/param norm = 1.7354e-01, time/batch = 0.6563s	
2670/25300 (epoch 5.277), train_loss = 1.46328175, grad/param norm = 1.9735e-01, time/batch = 0.6567s	
2671/25300 (epoch 5.279), train_loss = 1.53770920, grad/param norm = 2.1441e-01, time/batch = 0.6569s	
2672/25300 (epoch 5.281), train_loss = 1.68609854, grad/param norm = 2.3361e-01, time/batch = 0.6508s	
2673/25300 (epoch 5.283), train_loss = 1.41262758, grad/param norm = 2.1200e-01, time/batch = 0.6521s	
2674/25300 (epoch 5.285), train_loss = 1.49482938, grad/param norm = 2.1189e-01, time/batch = 0.6537s	
2675/25300 (epoch 5.287), train_loss = 1.47605298, grad/param norm = 1.8452e-01, time/batch = 0.6552s	
2676/25300 (epoch 5.289), train_loss = 1.43575160, grad/param norm = 1.9666e-01, time/batch = 0.6544s	
2677/25300 (epoch 5.291), train_loss = 1.35888198, grad/param norm = 1.9839e-01, time/batch = 0.6554s	
2678/25300 (epoch 5.292), train_loss = 1.60400360, grad/param norm = 2.1130e-01, time/batch = 0.6555s	
2679/25300 (epoch 5.294), train_loss = 1.50178041, grad/param norm = 2.0866e-01, time/batch = 0.6585s	
2680/25300 (epoch 5.296), train_loss = 1.36660003, grad/param norm = 1.9974e-01, time/batch = 0.6551s	
2681/25300 (epoch 5.298), train_loss = 1.60371978, grad/param norm = 2.1008e-01, time/batch = 0.6628s	
2682/25300 (epoch 5.300), train_loss = 1.76286376, grad/param norm = 2.3617e-01, time/batch = 0.6562s	
2683/25300 (epoch 5.302), train_loss = 1.33915138, grad/param norm = 2.0578e-01, time/batch = 0.6656s	
2684/25300 (epoch 5.304), train_loss = 1.57129861, grad/param norm = 2.1546e-01, time/batch = 0.6625s	
2685/25300 (epoch 5.306), train_loss = 1.21651742, grad/param norm = 1.8590e-01, time/batch = 1.4370s	
2686/25300 (epoch 5.308), train_loss = 1.52604653, grad/param norm = 1.7643e-01, time/batch = 0.7140s	
2687/25300 (epoch 5.310), train_loss = 1.44874941, grad/param norm = 1.9945e-01, time/batch = 0.6850s	
2688/25300 (epoch 5.312), train_loss = 1.50045472, grad/param norm = 2.0393e-01, time/batch = 0.6811s	
2689/25300 (epoch 5.314), train_loss = 1.25916915, grad/param norm = 1.9293e-01, time/batch = 0.6858s	
2690/25300 (epoch 5.316), train_loss = 1.51879640, grad/param norm = 1.9432e-01, time/batch = 0.6896s	
2691/25300 (epoch 5.318), train_loss = 1.19922850, grad/param norm = 1.8759e-01, time/batch = 0.7063s	
2692/25300 (epoch 5.320), train_loss = 1.40400186, grad/param norm = 2.0423e-01, time/batch = 0.6755s	
2693/25300 (epoch 5.322), train_loss = 1.78334491, grad/param norm = 2.0758e-01, time/batch = 0.6735s	
2694/25300 (epoch 5.324), train_loss = 1.36311573, grad/param norm = 1.8963e-01, time/batch = 0.6735s	
2695/25300 (epoch 5.326), train_loss = 1.22805042, grad/param norm = 1.6541e-01, time/batch = 0.6751s	
2696/25300 (epoch 5.328), train_loss = 1.30380470, grad/param norm = 1.8345e-01, time/batch = 0.6758s	
2697/25300 (epoch 5.330), train_loss = 1.40095184, grad/param norm = 1.8599e-01, time/batch = 0.6773s	
2698/25300 (epoch 5.332), train_loss = 1.53685611, grad/param norm = 1.9875e-01, time/batch = 0.6769s	
2699/25300 (epoch 5.334), train_loss = 1.38346304, grad/param norm = 1.8399e-01, time/batch = 0.6760s	
2700/25300 (epoch 5.336), train_loss = 1.32058647, grad/param norm = 1.9022e-01, time/batch = 0.6755s	
2701/25300 (epoch 5.338), train_loss = 1.33169115, grad/param norm = 1.9593e-01, time/batch = 0.6774s	
2702/25300 (epoch 5.340), train_loss = 1.42695242, grad/param norm = 2.1790e-01, time/batch = 0.6771s	
2703/25300 (epoch 5.342), train_loss = 1.39911347, grad/param norm = 2.0605e-01, time/batch = 0.6781s	
2704/25300 (epoch 5.344), train_loss = 1.40500280, grad/param norm = 1.9790e-01, time/batch = 0.6802s	
2705/25300 (epoch 5.346), train_loss = 1.46488588, grad/param norm = 2.0466e-01, time/batch = 0.6754s	
2706/25300 (epoch 5.348), train_loss = 1.25496060, grad/param norm = 1.6070e-01, time/batch = 0.6738s	
2707/25300 (epoch 5.350), train_loss = 1.40657357, grad/param norm = 1.9996e-01, time/batch = 0.6737s	
2708/25300 (epoch 5.352), train_loss = 1.48443047, grad/param norm = 1.9159e-01, time/batch = 0.6752s	
2709/25300 (epoch 5.354), train_loss = 1.44092270, grad/param norm = 2.0950e-01, time/batch = 0.6752s	
2710/25300 (epoch 5.356), train_loss = 1.51475661, grad/param norm = 2.1598e-01, time/batch = 0.6731s	
2711/25300 (epoch 5.358), train_loss = 1.59248595, grad/param norm = 2.3238e-01, time/batch = 0.6757s	
2712/25300 (epoch 5.360), train_loss = 1.37436808, grad/param norm = 1.8858e-01, time/batch = 0.6830s	
2713/25300 (epoch 5.362), train_loss = 1.55852198, grad/param norm = 2.0554e-01, time/batch = 0.6753s	
2714/25300 (epoch 5.364), train_loss = 1.62175580, grad/param norm = 2.2779e-01, time/batch = 0.6783s	
2715/25300 (epoch 5.366), train_loss = 1.32285263, grad/param norm = 1.9094e-01, time/batch = 0.6834s	
2716/25300 (epoch 5.368), train_loss = 1.48831525, grad/param norm = 1.8720e-01, time/batch = 0.6832s	
2717/25300 (epoch 5.370), train_loss = 1.48231668, grad/param norm = 2.2544e-01, time/batch = 0.6777s	
2718/25300 (epoch 5.372), train_loss = 1.46424398, grad/param norm = 2.2072e-01, time/batch = 0.6831s	
2719/25300 (epoch 5.374), train_loss = 1.37160387, grad/param norm = 2.0214e-01, time/batch = 0.6828s	
2720/25300 (epoch 5.375), train_loss = 1.71816467, grad/param norm = 2.2157e-01, time/batch = 0.6792s	
2721/25300 (epoch 5.377), train_loss = 1.42278477, grad/param norm = 1.9974e-01, time/batch = 0.6855s	
2722/25300 (epoch 5.379), train_loss = 1.75407977, grad/param norm = 2.2373e-01, time/batch = 0.6856s	
2723/25300 (epoch 5.381), train_loss = 1.44075860, grad/param norm = 1.7657e-01, time/batch = 0.6839s	
2724/25300 (epoch 5.383), train_loss = 1.33412775, grad/param norm = 1.8241e-01, time/batch = 0.6884s	
2725/25300 (epoch 5.385), train_loss = 1.39765172, grad/param norm = 1.9587e-01, time/batch = 0.6873s	
2726/25300 (epoch 5.387), train_loss = 1.58752752, grad/param norm = 2.0481e-01, time/batch = 0.6856s	
2727/25300 (epoch 5.389), train_loss = 1.69907410, grad/param norm = 2.2525e-01, time/batch = 0.6873s	
2728/25300 (epoch 5.391), train_loss = 1.31105803, grad/param norm = 2.0123e-01, time/batch = 0.6890s	
2729/25300 (epoch 5.393), train_loss = 1.56480933, grad/param norm = 2.0439e-01, time/batch = 0.6921s	
2730/25300 (epoch 5.395), train_loss = 1.27250251, grad/param norm = 1.8710e-01, time/batch = 0.6763s	
2731/25300 (epoch 5.397), train_loss = 1.34191283, grad/param norm = 2.0101e-01, time/batch = 0.6837s	
2732/25300 (epoch 5.399), train_loss = 1.33489039, grad/param norm = 1.8030e-01, time/batch = 0.6908s	
2733/25300 (epoch 5.401), train_loss = 1.57263982, grad/param norm = 2.0085e-01, time/batch = 0.6911s	
2734/25300 (epoch 5.403), train_loss = 1.48210965, grad/param norm = 2.4056e-01, time/batch = 0.6903s	
2735/25300 (epoch 5.405), train_loss = 1.54931669, grad/param norm = 2.1118e-01, time/batch = 0.6861s	
2736/25300 (epoch 5.407), train_loss = 1.36081981, grad/param norm = 1.9474e-01, time/batch = 0.6862s	
2737/25300 (epoch 5.409), train_loss = 1.36920613, grad/param norm = 1.8103e-01, time/batch = 0.6905s	
2738/25300 (epoch 5.411), train_loss = 1.46330531, grad/param norm = 2.0462e-01, time/batch = 0.6850s	
2739/25300 (epoch 5.413), train_loss = 1.35056668, grad/param norm = 1.9212e-01, time/batch = 0.6868s	
2740/25300 (epoch 5.415), train_loss = 1.35862419, grad/param norm = 1.9129e-01, time/batch = 0.6764s	
2741/25300 (epoch 5.417), train_loss = 1.34489626, grad/param norm = 1.9896e-01, time/batch = 0.6849s	
2742/25300 (epoch 5.419), train_loss = 1.26514476, grad/param norm = 2.0438e-01, time/batch = 0.6830s	
2743/25300 (epoch 5.421), train_loss = 1.28792075, grad/param norm = 1.9498e-01, time/batch = 0.6852s	
2744/25300 (epoch 5.423), train_loss = 1.32894114, grad/param norm = 1.8165e-01, time/batch = 0.6844s	
2745/25300 (epoch 5.425), train_loss = 1.44493085, grad/param norm = 2.3152e-01, time/batch = 0.6846s	
2746/25300 (epoch 5.427), train_loss = 1.64756977, grad/param norm = 2.1178e-01, time/batch = 0.6824s	
2747/25300 (epoch 5.429), train_loss = 1.57754116, grad/param norm = 2.2769e-01, time/batch = 0.6881s	
2748/25300 (epoch 5.431), train_loss = 1.53068946, grad/param norm = 2.1429e-01, time/batch = 0.6863s	
2749/25300 (epoch 5.433), train_loss = 1.44927134, grad/param norm = 1.8912e-01, time/batch = 0.6820s	
2750/25300 (epoch 5.435), train_loss = 1.33089979, grad/param norm = 2.0750e-01, time/batch = 0.6850s	
2751/25300 (epoch 5.437), train_loss = 1.41887674, grad/param norm = 1.9562e-01, time/batch = 0.6888s	
2752/25300 (epoch 5.439), train_loss = 1.46375061, grad/param norm = 2.0963e-01, time/batch = 0.6811s	
2753/25300 (epoch 5.441), train_loss = 1.49366205, grad/param norm = 2.1488e-01, time/batch = 0.6894s	
2754/25300 (epoch 5.443), train_loss = 1.63939979, grad/param norm = 2.2505e-01, time/batch = 0.6871s	
2755/25300 (epoch 5.445), train_loss = 1.56517626, grad/param norm = 2.0202e-01, time/batch = 0.6858s	
2756/25300 (epoch 5.447), train_loss = 1.33947992, grad/param norm = 1.8905e-01, time/batch = 0.6823s	
2757/25300 (epoch 5.449), train_loss = 1.31854193, grad/param norm = 1.8585e-01, time/batch = 0.6859s	
2758/25300 (epoch 5.451), train_loss = 1.64623465, grad/param norm = 2.1167e-01, time/batch = 0.6882s	
2759/25300 (epoch 5.453), train_loss = 1.52687400, grad/param norm = 2.0336e-01, time/batch = 0.6832s	
2760/25300 (epoch 5.455), train_loss = 1.65124576, grad/param norm = 1.9614e-01, time/batch = 0.6853s	
2761/25300 (epoch 5.457), train_loss = 1.46158544, grad/param norm = 1.9823e-01, time/batch = 0.6840s	
2762/25300 (epoch 5.458), train_loss = 1.55873655, grad/param norm = 2.2071e-01, time/batch = 0.6818s	
2763/25300 (epoch 5.460), train_loss = 1.57526966, grad/param norm = 2.2447e-01, time/batch = 0.6844s	
2764/25300 (epoch 5.462), train_loss = 1.27453264, grad/param norm = 2.1299e-01, time/batch = 0.6837s	
2765/25300 (epoch 5.464), train_loss = 1.52995579, grad/param norm = 2.4033e-01, time/batch = 0.6779s	
2766/25300 (epoch 5.466), train_loss = 1.53831416, grad/param norm = 2.2127e-01, time/batch = 0.6852s	
2767/25300 (epoch 5.468), train_loss = 1.65195156, grad/param norm = 2.1289e-01, time/batch = 0.6860s	
2768/25300 (epoch 5.470), train_loss = 1.37366846, grad/param norm = 2.0775e-01, time/batch = 0.6838s	
2769/25300 (epoch 5.472), train_loss = 1.22045786, grad/param norm = 1.9165e-01, time/batch = 0.6826s	
2770/25300 (epoch 5.474), train_loss = 1.50878457, grad/param norm = 2.0882e-01, time/batch = 0.6839s	
2771/25300 (epoch 5.476), train_loss = 1.46908053, grad/param norm = 1.9589e-01, time/batch = 0.6898s	
2772/25300 (epoch 5.478), train_loss = 1.51295253, grad/param norm = 1.8634e-01, time/batch = 0.6886s	
2773/25300 (epoch 5.480), train_loss = 1.33006557, grad/param norm = 1.8855e-01, time/batch = 0.6845s	
2774/25300 (epoch 5.482), train_loss = 1.65132614, grad/param norm = 2.1624e-01, time/batch = 0.6822s	
2775/25300 (epoch 5.484), train_loss = 1.61662280, grad/param norm = 2.2052e-01, time/batch = 0.6776s	
2776/25300 (epoch 5.486), train_loss = 1.45871738, grad/param norm = 2.0425e-01, time/batch = 0.6809s	
2777/25300 (epoch 5.488), train_loss = 1.52528063, grad/param norm = 2.0637e-01, time/batch = 0.6800s	
2778/25300 (epoch 5.490), train_loss = 1.57855031, grad/param norm = 1.9601e-01, time/batch = 0.6812s	
2779/25300 (epoch 5.492), train_loss = 1.38888884, grad/param norm = 1.8255e-01, time/batch = 0.6818s	
2780/25300 (epoch 5.494), train_loss = 1.31229152, grad/param norm = 1.9285e-01, time/batch = 0.6806s	
2781/25300 (epoch 5.496), train_loss = 1.49139497, grad/param norm = 1.9518e-01, time/batch = 0.6857s	
2782/25300 (epoch 5.498), train_loss = 1.33980442, grad/param norm = 1.8776e-01, time/batch = 0.6841s	
2783/25300 (epoch 5.500), train_loss = 1.63479819, grad/param norm = 2.1719e-01, time/batch = 0.6804s	
2784/25300 (epoch 5.502), train_loss = 1.44516059, grad/param norm = 1.9773e-01, time/batch = 0.6856s	
2785/25300 (epoch 5.504), train_loss = 1.40456452, grad/param norm = 1.9872e-01, time/batch = 0.6863s	
2786/25300 (epoch 5.506), train_loss = 1.48798678, grad/param norm = 2.1120e-01, time/batch = 0.6838s	
2787/25300 (epoch 5.508), train_loss = 1.48966302, grad/param norm = 2.1453e-01, time/batch = 0.6873s	
2788/25300 (epoch 5.510), train_loss = 1.39930900, grad/param norm = 2.1457e-01, time/batch = 0.6846s	
2789/25300 (epoch 5.512), train_loss = 1.14099002, grad/param norm = 1.6686e-01, time/batch = 0.6846s	
2790/25300 (epoch 5.514), train_loss = 1.32044875, grad/param norm = 1.8337e-01, time/batch = 0.6753s	
2791/25300 (epoch 5.516), train_loss = 1.42115677, grad/param norm = 2.0041e-01, time/batch = 0.6826s	
2792/25300 (epoch 5.518), train_loss = 1.54334541, grad/param norm = 2.3501e-01, time/batch = 0.6820s	
2793/25300 (epoch 5.520), train_loss = 1.24649577, grad/param norm = 2.0368e-01, time/batch = 0.6789s	
2794/25300 (epoch 5.522), train_loss = 1.35521807, grad/param norm = 1.7798e-01, time/batch = 0.6785s	
2795/25300 (epoch 5.524), train_loss = 1.34456087, grad/param norm = 1.9047e-01, time/batch = 0.6796s	
2796/25300 (epoch 5.526), train_loss = 1.69324450, grad/param norm = 2.4376e-01, time/batch = 0.6791s	
2797/25300 (epoch 5.528), train_loss = 1.58646302, grad/param norm = 2.1769e-01, time/batch = 0.6815s	
2798/25300 (epoch 5.530), train_loss = 1.44309482, grad/param norm = 2.1530e-01, time/batch = 0.6872s	
2799/25300 (epoch 5.532), train_loss = 1.49955781, grad/param norm = 2.0295e-01, time/batch = 0.6869s	
2800/25300 (epoch 5.534), train_loss = 1.41273785, grad/param norm = 2.0421e-01, time/batch = 0.6864s	
2801/25300 (epoch 5.536), train_loss = 1.32635859, grad/param norm = 2.1573e-01, time/batch = 0.6839s	
2802/25300 (epoch 5.538), train_loss = 1.27769740, grad/param norm = 1.8609e-01, time/batch = 0.6795s	
2803/25300 (epoch 5.540), train_loss = 1.37918832, grad/param norm = 1.9668e-01, time/batch = 0.6842s	
2804/25300 (epoch 5.542), train_loss = 1.32161022, grad/param norm = 2.0125e-01, time/batch = 0.6769s	
2805/25300 (epoch 5.543), train_loss = 1.28416324, grad/param norm = 1.8701e-01, time/batch = 0.6788s	
2806/25300 (epoch 5.545), train_loss = 1.89055297, grad/param norm = 2.2411e-01, time/batch = 0.6845s	
2807/25300 (epoch 5.547), train_loss = 1.39156712, grad/param norm = 1.9839e-01, time/batch = 0.6831s	
2808/25300 (epoch 5.549), train_loss = 1.71445768, grad/param norm = 2.2657e-01, time/batch = 0.6845s	
2809/25300 (epoch 5.551), train_loss = 1.46797464, grad/param norm = 2.0292e-01, time/batch = 0.6981s	
2810/25300 (epoch 5.553), train_loss = 1.51998239, grad/param norm = 2.0303e-01, time/batch = 0.6836s	
2811/25300 (epoch 5.555), train_loss = 1.58819661, grad/param norm = 2.0799e-01, time/batch = 0.6846s	
2812/25300 (epoch 5.557), train_loss = 1.62375420, grad/param norm = 2.0129e-01, time/batch = 0.6805s	
2813/25300 (epoch 5.559), train_loss = 1.60042801, grad/param norm = 2.1341e-01, time/batch = 0.6820s	
2814/25300 (epoch 5.561), train_loss = 1.65818644, grad/param norm = 2.1511e-01, time/batch = 0.6884s	
2815/25300 (epoch 5.563), train_loss = 1.53735062, grad/param norm = 1.8893e-01, time/batch = 0.6865s	
2816/25300 (epoch 5.565), train_loss = 1.30840970, grad/param norm = 1.8015e-01, time/batch = 0.6849s	
2817/25300 (epoch 5.567), train_loss = 1.13195993, grad/param norm = 1.9578e-01, time/batch = 0.6870s	
2818/25300 (epoch 5.569), train_loss = 1.45116469, grad/param norm = 1.9585e-01, time/batch = 0.6944s	
2819/25300 (epoch 5.571), train_loss = 1.54948903, grad/param norm = 1.9434e-01, time/batch = 0.6852s	
2820/25300 (epoch 5.573), train_loss = 1.45882968, grad/param norm = 1.9434e-01, time/batch = 0.6809s	
2821/25300 (epoch 5.575), train_loss = 1.54501925, grad/param norm = 2.0505e-01, time/batch = 0.6870s	
2822/25300 (epoch 5.577), train_loss = 1.52550767, grad/param norm = 2.0031e-01, time/batch = 0.6841s	
2823/25300 (epoch 5.579), train_loss = 1.69340152, grad/param norm = 2.1220e-01, time/batch = 0.6846s	
2824/25300 (epoch 5.581), train_loss = 1.51932354, grad/param norm = 2.0254e-01, time/batch = 0.6845s	
2825/25300 (epoch 5.583), train_loss = 1.37285573, grad/param norm = 1.9620e-01, time/batch = 0.6761s	
2826/25300 (epoch 5.585), train_loss = 1.32615996, grad/param norm = 1.9097e-01, time/batch = 0.6822s	
2827/25300 (epoch 5.587), train_loss = 1.40879351, grad/param norm = 1.9631e-01, time/batch = 0.6798s	
2828/25300 (epoch 5.589), train_loss = 1.27069935, grad/param norm = 1.7672e-01, time/batch = 0.6784s	
2829/25300 (epoch 5.591), train_loss = 1.31337180, grad/param norm = 1.9267e-01, time/batch = 0.6789s	
2830/25300 (epoch 5.593), train_loss = 1.39694880, grad/param norm = 1.8419e-01, time/batch = 0.6809s	
2831/25300 (epoch 5.595), train_loss = 1.44631722, grad/param norm = 1.9919e-01, time/batch = 0.6842s	
2832/25300 (epoch 5.597), train_loss = 1.23738849, grad/param norm = 1.8244e-01, time/batch = 0.6784s	
2833/25300 (epoch 5.599), train_loss = 1.42443880, grad/param norm = 1.8768e-01, time/batch = 0.6788s	
2834/25300 (epoch 5.601), train_loss = 1.47590722, grad/param norm = 2.1183e-01, time/batch = 0.6840s	
2835/25300 (epoch 5.603), train_loss = 1.49190448, grad/param norm = 1.8590e-01, time/batch = 0.6833s	
2836/25300 (epoch 5.605), train_loss = 1.38226236, grad/param norm = 1.9371e-01, time/batch = 0.6820s	
2837/25300 (epoch 5.607), train_loss = 1.29436698, grad/param norm = 1.8882e-01, time/batch = 0.6801s	
2838/25300 (epoch 5.609), train_loss = 1.43460042, grad/param norm = 1.8560e-01, time/batch = 0.6805s	
2839/25300 (epoch 5.611), train_loss = 1.57972324, grad/param norm = 1.9331e-01, time/batch = 0.6875s	
2840/25300 (epoch 5.613), train_loss = 1.36353356, grad/param norm = 1.8833e-01, time/batch = 0.6792s	
2841/25300 (epoch 5.615), train_loss = 1.50064610, grad/param norm = 1.9612e-01, time/batch = 0.6828s	
2842/25300 (epoch 5.617), train_loss = 1.45311825, grad/param norm = 1.8430e-01, time/batch = 0.6860s	
2843/25300 (epoch 5.619), train_loss = 1.53263029, grad/param norm = 1.9748e-01, time/batch = 0.6801s	
2844/25300 (epoch 5.621), train_loss = 1.53490137, grad/param norm = 2.0359e-01, time/batch = 0.6784s	
2845/25300 (epoch 5.623), train_loss = 1.39837459, grad/param norm = 2.0760e-01, time/batch = 0.6762s	
2846/25300 (epoch 5.625), train_loss = 1.28912705, grad/param norm = 2.0695e-01, time/batch = 0.6844s	
2847/25300 (epoch 5.626), train_loss = 1.41680143, grad/param norm = 1.9824e-01, time/batch = 0.6787s	
2848/25300 (epoch 5.628), train_loss = 1.63073739, grad/param norm = 2.1401e-01, time/batch = 0.6785s	
2849/25300 (epoch 5.630), train_loss = 1.63304325, grad/param norm = 2.0462e-01, time/batch = 0.6779s	
2850/25300 (epoch 5.632), train_loss = 1.58925329, grad/param norm = 2.2408e-01, time/batch = 0.6783s	
2851/25300 (epoch 5.634), train_loss = 1.63514675, grad/param norm = 2.0885e-01, time/batch = 0.6846s	
2852/25300 (epoch 5.636), train_loss = 1.48912393, grad/param norm = 2.1176e-01, time/batch = 0.6825s	
2853/25300 (epoch 5.638), train_loss = 1.59243275, grad/param norm = 2.0879e-01, time/batch = 0.6756s	
2854/25300 (epoch 5.640), train_loss = 1.70967114, grad/param norm = 2.2035e-01, time/batch = 0.6815s	
2855/25300 (epoch 5.642), train_loss = 1.54950897, grad/param norm = 2.2433e-01, time/batch = 0.6760s	
2856/25300 (epoch 5.644), train_loss = 1.57030726, grad/param norm = 1.9701e-01, time/batch = 0.6762s	
2857/25300 (epoch 5.646), train_loss = 1.50213494, grad/param norm = 1.8627e-01, time/batch = 0.6820s	
2858/25300 (epoch 5.648), train_loss = 1.59208734, grad/param norm = 1.8535e-01, time/batch = 0.6773s	
2859/25300 (epoch 5.650), train_loss = 1.56792582, grad/param norm = 2.1056e-01, time/batch = 0.6808s	
2860/25300 (epoch 5.652), train_loss = 1.59307054, grad/param norm = 2.1353e-01, time/batch = 0.6892s	
2861/25300 (epoch 5.654), train_loss = 1.67304119, grad/param norm = 2.1078e-01, time/batch = 0.6890s	
2862/25300 (epoch 5.656), train_loss = 1.62948768, grad/param norm = 2.1603e-01, time/batch = 0.6824s	
2863/25300 (epoch 5.658), train_loss = 1.29714091, grad/param norm = 1.7150e-01, time/batch = 0.6827s	
2864/25300 (epoch 5.660), train_loss = 1.31877194, grad/param norm = 1.9006e-01, time/batch = 0.6810s	
2865/25300 (epoch 5.662), train_loss = 1.25082431, grad/param norm = 1.9060e-01, time/batch = 0.6877s	
2866/25300 (epoch 5.664), train_loss = 1.23586028, grad/param norm = 1.7278e-01, time/batch = 0.6763s	
2867/25300 (epoch 5.666), train_loss = 1.29824430, grad/param norm = 1.9726e-01, time/batch = 0.6689s	
2868/25300 (epoch 5.668), train_loss = 1.36469429, grad/param norm = 2.2624e-01, time/batch = 0.6683s	
2869/25300 (epoch 5.670), train_loss = 1.39993912, grad/param norm = 1.9767e-01, time/batch = 0.6787s	
2870/25300 (epoch 5.672), train_loss = 1.42685505, grad/param norm = 1.9145e-01, time/batch = 0.6703s	
2871/25300 (epoch 5.674), train_loss = 1.43196146, grad/param norm = 1.9448e-01, time/batch = 0.6725s	
2872/25300 (epoch 5.676), train_loss = 1.53181189, grad/param norm = 2.1033e-01, time/batch = 0.6690s	
2873/25300 (epoch 5.678), train_loss = 1.42089459, grad/param norm = 2.2671e-01, time/batch = 0.6685s	
2874/25300 (epoch 5.680), train_loss = 1.27993887, grad/param norm = 1.8542e-01, time/batch = 0.6756s	
2875/25300 (epoch 5.682), train_loss = 1.10444974, grad/param norm = 1.7238e-01, time/batch = 0.6735s	
2876/25300 (epoch 5.684), train_loss = 1.26087445, grad/param norm = 1.7684e-01, time/batch = 0.6703s	
2877/25300 (epoch 5.686), train_loss = 1.32874339, grad/param norm = 2.0662e-01, time/batch = 0.6727s	
2878/25300 (epoch 5.688), train_loss = 1.50162650, grad/param norm = 1.8387e-01, time/batch = 0.6762s	
2879/25300 (epoch 5.690), train_loss = 1.38011940, grad/param norm = 1.7956e-01, time/batch = 0.6786s	
2880/25300 (epoch 5.692), train_loss = 1.49661714, grad/param norm = 1.9439e-01, time/batch = 0.6716s	
2881/25300 (epoch 5.694), train_loss = 1.33502727, grad/param norm = 1.6942e-01, time/batch = 0.6831s	
2882/25300 (epoch 5.696), train_loss = 1.45862099, grad/param norm = 1.9128e-01, time/batch = 0.6784s	
2883/25300 (epoch 5.698), train_loss = 1.46302675, grad/param norm = 1.9308e-01, time/batch = 0.6764s	
2884/25300 (epoch 5.700), train_loss = 1.24913448, grad/param norm = 1.8919e-01, time/batch = 0.6752s	
2885/25300 (epoch 5.702), train_loss = 1.59942788, grad/param norm = 2.0683e-01, time/batch = 0.6778s	
2886/25300 (epoch 5.704), train_loss = 1.21664271, grad/param norm = 1.8484e-01, time/batch = 0.6794s	
2887/25300 (epoch 5.706), train_loss = 1.41988116, grad/param norm = 2.2177e-01, time/batch = 0.6774s	
2888/25300 (epoch 5.708), train_loss = 1.20148443, grad/param norm = 1.7694e-01, time/batch = 0.6755s	
2889/25300 (epoch 5.709), train_loss = 1.61627229, grad/param norm = 2.0403e-01, time/batch = 0.6697s	
2890/25300 (epoch 5.711), train_loss = 1.68889239, grad/param norm = 2.1495e-01, time/batch = 0.6724s	
2891/25300 (epoch 5.713), train_loss = 1.41091113, grad/param norm = 1.9479e-01, time/batch = 0.6736s	
2892/25300 (epoch 5.715), train_loss = 1.37395632, grad/param norm = 1.9186e-01, time/batch = 0.6738s	
2893/25300 (epoch 5.717), train_loss = 1.47129057, grad/param norm = 2.1285e-01, time/batch = 0.6850s	
2894/25300 (epoch 5.719), train_loss = 1.41274915, grad/param norm = 2.0970e-01, time/batch = 0.6913s	
2895/25300 (epoch 5.721), train_loss = 1.43864026, grad/param norm = 2.1625e-01, time/batch = 0.6847s	
2896/25300 (epoch 5.723), train_loss = 1.31397761, grad/param norm = 1.9355e-01, time/batch = 0.6820s	
2897/25300 (epoch 5.725), train_loss = 1.44356991, grad/param norm = 2.1440e-01, time/batch = 0.6768s	
2898/25300 (epoch 5.727), train_loss = 1.40607302, grad/param norm = 1.8683e-01, time/batch = 0.6829s	
2899/25300 (epoch 5.729), train_loss = 1.37607517, grad/param norm = 1.9255e-01, time/batch = 0.6827s	
2900/25300 (epoch 5.731), train_loss = 1.67049537, grad/param norm = 2.2188e-01, time/batch = 0.6737s	
2901/25300 (epoch 5.733), train_loss = 1.31051765, grad/param norm = 1.5940e-01, time/batch = 0.6752s	
2902/25300 (epoch 5.735), train_loss = 1.73500495, grad/param norm = 2.1235e-01, time/batch = 0.6770s	
2903/25300 (epoch 5.737), train_loss = 1.25087990, grad/param norm = 1.8698e-01, time/batch = 0.6801s	
2904/25300 (epoch 5.739), train_loss = 1.54917313, grad/param norm = 1.9338e-01, time/batch = 0.6808s	
2905/25300 (epoch 5.741), train_loss = 1.47971826, grad/param norm = 1.9412e-01, time/batch = 0.6821s	
2906/25300 (epoch 5.743), train_loss = 1.34700146, grad/param norm = 1.8327e-01, time/batch = 0.6787s	
2907/25300 (epoch 5.745), train_loss = 1.36412454, grad/param norm = 1.8552e-01, time/batch = 0.6835s	
2908/25300 (epoch 5.747), train_loss = 1.23773086, grad/param norm = 1.5482e-01, time/batch = 0.6760s	
2909/25300 (epoch 5.749), train_loss = 1.46172920, grad/param norm = 1.9782e-01, time/batch = 0.6757s	
2910/25300 (epoch 5.751), train_loss = 1.57419051, grad/param norm = 1.9786e-01, time/batch = 0.6831s	
2911/25300 (epoch 5.753), train_loss = 1.39834015, grad/param norm = 2.0821e-01, time/batch = 0.6733s	
2912/25300 (epoch 5.755), train_loss = 1.52378754, grad/param norm = 2.0505e-01, time/batch = 0.6754s	
2913/25300 (epoch 5.757), train_loss = 1.29902229, grad/param norm = 1.9989e-01, time/batch = 0.6734s	
2914/25300 (epoch 5.759), train_loss = 1.28345613, grad/param norm = 2.0375e-01, time/batch = 0.6760s	
2915/25300 (epoch 5.761), train_loss = 1.57000242, grad/param norm = 2.2943e-01, time/batch = 0.6787s	
2916/25300 (epoch 5.763), train_loss = 1.34127663, grad/param norm = 2.1750e-01, time/batch = 0.6780s	
2917/25300 (epoch 5.765), train_loss = 1.38644442, grad/param norm = 2.0603e-01, time/batch = 0.6827s	
2918/25300 (epoch 5.767), train_loss = 1.30734534, grad/param norm = 1.9591e-01, time/batch = 0.6765s	
2919/25300 (epoch 5.769), train_loss = 1.48757343, grad/param norm = 2.1299e-01, time/batch = 0.6756s	
2920/25300 (epoch 5.771), train_loss = 1.72897808, grad/param norm = 2.2209e-01, time/batch = 0.6767s	
2921/25300 (epoch 5.773), train_loss = 1.61143746, grad/param norm = 2.0810e-01, time/batch = 0.6765s	
2922/25300 (epoch 5.775), train_loss = 1.37926934, grad/param norm = 1.7792e-01, time/batch = 0.6763s	
2923/25300 (epoch 5.777), train_loss = 1.46658507, grad/param norm = 1.9997e-01, time/batch = 0.6774s	
2924/25300 (epoch 5.779), train_loss = 1.57234496, grad/param norm = 2.0766e-01, time/batch = 0.6823s	
2925/25300 (epoch 5.781), train_loss = 1.38708730, grad/param norm = 1.9125e-01, time/batch = 0.6838s	
2926/25300 (epoch 5.783), train_loss = 1.63094773, grad/param norm = 2.0823e-01, time/batch = 0.6736s	
2927/25300 (epoch 5.785), train_loss = 1.53306292, grad/param norm = 2.0496e-01, time/batch = 0.6756s	
2928/25300 (epoch 5.787), train_loss = 1.55858478, grad/param norm = 1.9826e-01, time/batch = 0.6757s	
2929/25300 (epoch 5.789), train_loss = 1.69828297, grad/param norm = 1.9607e-01, time/batch = 0.6753s	
2930/25300 (epoch 5.791), train_loss = 1.41382892, grad/param norm = 1.9210e-01, time/batch = 0.6842s	
2931/25300 (epoch 5.792), train_loss = 1.53205563, grad/param norm = 2.0035e-01, time/batch = 0.6749s	
2932/25300 (epoch 5.794), train_loss = 1.51714179, grad/param norm = 1.9897e-01, time/batch = 0.6766s	
2933/25300 (epoch 5.796), train_loss = 1.41991030, grad/param norm = 1.8116e-01, time/batch = 0.6894s	
2934/25300 (epoch 5.798), train_loss = 1.58673630, grad/param norm = 1.9581e-01, time/batch = 0.6838s	
2935/25300 (epoch 5.800), train_loss = 1.48864385, grad/param norm = 2.1345e-01, time/batch = 0.6832s	
2936/25300 (epoch 5.802), train_loss = 1.17879560, grad/param norm = 1.7387e-01, time/batch = 0.6841s	
2937/25300 (epoch 5.804), train_loss = 1.45301126, grad/param norm = 1.8689e-01, time/batch = 0.6878s	
2938/25300 (epoch 5.806), train_loss = 1.54107753, grad/param norm = 2.0208e-01, time/batch = 0.6834s	
2939/25300 (epoch 5.808), train_loss = 1.42910689, grad/param norm = 1.8845e-01, time/batch = 0.6839s	
2940/25300 (epoch 5.810), train_loss = 1.44521957, grad/param norm = 2.2022e-01, time/batch = 0.6758s	
2941/25300 (epoch 5.812), train_loss = 1.47795821, grad/param norm = 1.9163e-01, time/batch = 0.6720s	
2942/25300 (epoch 5.814), train_loss = 1.66693412, grad/param norm = 2.0309e-01, time/batch = 0.6889s	
2943/25300 (epoch 5.816), train_loss = 1.74055004, grad/param norm = 2.1924e-01, time/batch = 0.6736s	
2944/25300 (epoch 5.818), train_loss = 1.58981571, grad/param norm = 1.9753e-01, time/batch = 0.6729s	
2945/25300 (epoch 5.820), train_loss = 1.48307553, grad/param norm = 1.8482e-01, time/batch = 0.6829s	
2946/25300 (epoch 5.822), train_loss = 1.41050188, grad/param norm = 1.6949e-01, time/batch = 0.6832s	
2947/25300 (epoch 5.824), train_loss = 1.51150738, grad/param norm = 1.7511e-01, time/batch = 0.6851s	
2948/25300 (epoch 5.826), train_loss = 1.37580210, grad/param norm = 2.0894e-01, time/batch = 0.6754s	
2949/25300 (epoch 5.828), train_loss = 1.38330183, grad/param norm = 1.8782e-01, time/batch = 0.6745s	
2950/25300 (epoch 5.830), train_loss = 1.40388716, grad/param norm = 1.8765e-01, time/batch = 0.6750s	
2951/25300 (epoch 5.832), train_loss = 1.42949042, grad/param norm = 1.9405e-01, time/batch = 0.6781s	
2952/25300 (epoch 5.834), train_loss = 1.26333621, grad/param norm = 1.9002e-01, time/batch = 0.6746s	
2953/25300 (epoch 5.836), train_loss = 1.34160339, grad/param norm = 1.8527e-01, time/batch = 0.6726s	
2954/25300 (epoch 5.838), train_loss = 1.42485411, grad/param norm = 1.9421e-01, time/batch = 0.6828s	
2955/25300 (epoch 5.840), train_loss = 1.60355782, grad/param norm = 1.8952e-01, time/batch = 0.6770s	
2956/25300 (epoch 5.842), train_loss = 1.52466489, grad/param norm = 2.2853e-01, time/batch = 0.6801s	
2957/25300 (epoch 5.844), train_loss = 1.44352976, grad/param norm = 1.8451e-01, time/batch = 0.6774s	
2958/25300 (epoch 5.846), train_loss = 1.38508595, grad/param norm = 1.9228e-01, time/batch = 0.6741s	
2959/25300 (epoch 5.848), train_loss = 1.67536357, grad/param norm = 2.2253e-01, time/batch = 0.6733s	
2960/25300 (epoch 5.850), train_loss = 1.54182594, grad/param norm = 1.9503e-01, time/batch = 0.6768s	
2961/25300 (epoch 5.852), train_loss = 1.45359560, grad/param norm = 2.1207e-01, time/batch = 0.6754s	
2962/25300 (epoch 5.854), train_loss = 1.65865700, grad/param norm = 2.1843e-01, time/batch = 0.6765s	
2963/25300 (epoch 5.856), train_loss = 1.44119772, grad/param norm = 2.0028e-01, time/batch = 0.6765s	
2964/25300 (epoch 5.858), train_loss = 1.51734445, grad/param norm = 2.0994e-01, time/batch = 0.6740s	
2965/25300 (epoch 5.860), train_loss = 1.23296892, grad/param norm = 2.0555e-01, time/batch = 0.6742s	
2966/25300 (epoch 5.862), train_loss = 1.54495552, grad/param norm = 2.1938e-01, time/batch = 0.6760s	
2967/25300 (epoch 5.864), train_loss = 1.59006522, grad/param norm = 1.9436e-01, time/batch = 0.6856s	
2968/25300 (epoch 5.866), train_loss = 1.56254687, grad/param norm = 2.2158e-01, time/batch = 0.6744s	
2969/25300 (epoch 5.868), train_loss = 1.63619832, grad/param norm = 2.3326e-01, time/batch = 0.6768s	
2970/25300 (epoch 5.870), train_loss = 1.54231807, grad/param norm = 1.9536e-01, time/batch = 0.6716s	
2971/25300 (epoch 5.872), train_loss = 1.53219010, grad/param norm = 2.1711e-01, time/batch = 0.6743s	
2972/25300 (epoch 5.874), train_loss = 1.54300895, grad/param norm = 2.2440e-01, time/batch = 0.6767s	
2973/25300 (epoch 5.875), train_loss = 1.43624259, grad/param norm = 1.9184e-01, time/batch = 0.6739s	
2974/25300 (epoch 5.877), train_loss = 1.32287451, grad/param norm = 1.7448e-01, time/batch = 0.6746s	
2975/25300 (epoch 5.879), train_loss = 1.50100467, grad/param norm = 1.9128e-01, time/batch = 0.6765s	
2976/25300 (epoch 5.881), train_loss = 1.79252044, grad/param norm = 2.1066e-01, time/batch = 0.6751s	
2977/25300 (epoch 5.883), train_loss = 1.70365481, grad/param norm = 1.9249e-01, time/batch = 0.6748s	
2978/25300 (epoch 5.885), train_loss = 1.61586994, grad/param norm = 2.1470e-01, time/batch = 0.6712s	
2979/25300 (epoch 5.887), train_loss = 1.44470371, grad/param norm = 1.8543e-01, time/batch = 0.6720s	
2980/25300 (epoch 5.889), train_loss = 1.67087376, grad/param norm = 2.1542e-01, time/batch = 0.6758s	
2981/25300 (epoch 5.891), train_loss = 1.64825382, grad/param norm = 4.8127e-01, time/batch = 0.6768s	
2982/25300 (epoch 5.893), train_loss = 1.79705278, grad/param norm = 2.4961e-01, time/batch = 0.6742s	
2983/25300 (epoch 5.895), train_loss = 1.19334769, grad/param norm = 1.9413e-01, time/batch = 0.6754s	
2984/25300 (epoch 5.897), train_loss = 1.35530709, grad/param norm = 1.8413e-01, time/batch = 0.6760s	
2985/25300 (epoch 5.899), train_loss = 1.45559332, grad/param norm = 2.0356e-01, time/batch = 0.6752s	
2986/25300 (epoch 5.901), train_loss = 1.54597640, grad/param norm = 2.0055e-01, time/batch = 0.6764s	
2987/25300 (epoch 5.903), train_loss = 1.27325334, grad/param norm = 1.7358e-01, time/batch = 0.6769s	
2988/25300 (epoch 5.905), train_loss = 1.37819725, grad/param norm = 1.9272e-01, time/batch = 0.6776s	
2989/25300 (epoch 5.907), train_loss = 1.57411070, grad/param norm = 2.1957e-01, time/batch = 0.6754s	
2990/25300 (epoch 5.909), train_loss = 1.56574632, grad/param norm = 1.8305e-01, time/batch = 0.6779s	
2991/25300 (epoch 5.911), train_loss = 1.68709827, grad/param norm = 2.0710e-01, time/batch = 0.6994s	
2992/25300 (epoch 5.913), train_loss = 1.66099163, grad/param norm = 2.1701e-01, time/batch = 0.6867s	
2993/25300 (epoch 5.915), train_loss = 1.40802836, grad/param norm = 2.0623e-01, time/batch = 0.6820s	
2994/25300 (epoch 5.917), train_loss = 1.54937227, grad/param norm = 2.0781e-01, time/batch = 0.6781s	
2995/25300 (epoch 5.919), train_loss = 1.60647870, grad/param norm = 2.1943e-01, time/batch = 0.6773s	
2996/25300 (epoch 5.921), train_loss = 1.36311918, grad/param norm = 2.2220e-01, time/batch = 0.6824s	
2997/25300 (epoch 5.923), train_loss = 1.60184238, grad/param norm = 1.8329e-01, time/batch = 0.6743s	
2998/25300 (epoch 5.925), train_loss = 1.49994720, grad/param norm = 1.8988e-01, time/batch = 0.6739s	
2999/25300 (epoch 5.927), train_loss = 1.46429195, grad/param norm = 1.9669e-01, time/batch = 0.6744s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch5.93_1.5182.t7	
3000/25300 (epoch 5.929), train_loss = 1.37751678, grad/param norm = 1.8793e-01, time/batch = 0.6755s	
3001/25300 (epoch 5.931), train_loss = 1.74682033, grad/param norm = 2.0075e-01, time/batch = 0.6783s	
3002/25300 (epoch 5.933), train_loss = 1.50442788, grad/param norm = 1.9391e-01, time/batch = 0.6736s	
3003/25300 (epoch 5.935), train_loss = 1.43995813, grad/param norm = 1.8778e-01, time/batch = 0.6746s	
3004/25300 (epoch 5.937), train_loss = 1.16750886, grad/param norm = 1.5616e-01, time/batch = 0.6739s	
3005/25300 (epoch 5.939), train_loss = 1.56749691, grad/param norm = 1.8342e-01, time/batch = 0.6777s	
3006/25300 (epoch 5.941), train_loss = 1.40939829, grad/param norm = 1.8039e-01, time/batch = 0.6739s	
3007/25300 (epoch 5.943), train_loss = 1.31946473, grad/param norm = 1.6972e-01, time/batch = 0.6819s	
3008/25300 (epoch 5.945), train_loss = 1.46874935, grad/param norm = 1.9535e-01, time/batch = 0.6771s	
3009/25300 (epoch 5.947), train_loss = 1.39780485, grad/param norm = 2.0549e-01, time/batch = 0.6767s	
3010/25300 (epoch 5.949), train_loss = 1.56197199, grad/param norm = 1.9988e-01, time/batch = 0.6827s	
3011/25300 (epoch 5.951), train_loss = 1.47836318, grad/param norm = 1.8191e-01, time/batch = 0.6767s	
3012/25300 (epoch 5.953), train_loss = 1.59132076, grad/param norm = 1.8898e-01, time/batch = 0.6761s	
3013/25300 (epoch 5.955), train_loss = 1.71625288, grad/param norm = 2.1406e-01, time/batch = 0.6798s	
3014/25300 (epoch 5.957), train_loss = 1.67025817, grad/param norm = 2.0951e-01, time/batch = 0.6775s	
3015/25300 (epoch 5.958), train_loss = 1.50773184, grad/param norm = 2.0964e-01, time/batch = 0.6770s	
3016/25300 (epoch 5.960), train_loss = 1.68991188, grad/param norm = 2.1069e-01, time/batch = 0.6743s	
3017/25300 (epoch 5.962), train_loss = 1.57128444, grad/param norm = 2.0905e-01, time/batch = 0.6760s	
3018/25300 (epoch 5.964), train_loss = 1.52041836, grad/param norm = 1.8324e-01, time/batch = 0.6768s	
3019/25300 (epoch 5.966), train_loss = 1.29153973, grad/param norm = 1.7495e-01, time/batch = 0.6786s	
3020/25300 (epoch 5.968), train_loss = 1.26932034, grad/param norm = 1.7120e-01, time/batch = 0.6798s	
3021/25300 (epoch 5.970), train_loss = 1.53451337, grad/param norm = 2.2036e-01, time/batch = 0.6763s	
3022/25300 (epoch 5.972), train_loss = 1.48360225, grad/param norm = 1.9922e-01, time/batch = 0.6790s	
3023/25300 (epoch 5.974), train_loss = 1.70115272, grad/param norm = 2.3154e-01, time/batch = 0.6872s	
3024/25300 (epoch 5.976), train_loss = 1.50139835, grad/param norm = 1.9732e-01, time/batch = 0.6850s	
3025/25300 (epoch 5.978), train_loss = 1.51085591, grad/param norm = 1.8953e-01, time/batch = 0.6746s	
3026/25300 (epoch 5.980), train_loss = 1.55585884, grad/param norm = 2.0292e-01, time/batch = 0.6826s	
3027/25300 (epoch 5.982), train_loss = 1.46236556, grad/param norm = 1.8894e-01, time/batch = 0.6862s	
3028/25300 (epoch 5.984), train_loss = 1.44893196, grad/param norm = 1.8170e-01, time/batch = 0.6940s	
3029/25300 (epoch 5.986), train_loss = 1.49560091, grad/param norm = 2.1033e-01, time/batch = 0.6832s	
3030/25300 (epoch 5.988), train_loss = 1.47417837, grad/param norm = 1.9126e-01, time/batch = 0.6790s	
3031/25300 (epoch 5.990), train_loss = 1.46912810, grad/param norm = 1.8995e-01, time/batch = 0.6762s	
3032/25300 (epoch 5.992), train_loss = 1.16409800, grad/param norm = 1.8301e-01, time/batch = 0.6734s	
3033/25300 (epoch 5.994), train_loss = 1.51138954, grad/param norm = 2.0248e-01, time/batch = 0.6782s	
3034/25300 (epoch 5.996), train_loss = 1.61087637, grad/param norm = 2.1453e-01, time/batch = 0.6775s	
3035/25300 (epoch 5.998), train_loss = 1.60759338, grad/param norm = 1.9591e-01, time/batch = 0.6728s	
3036/25300 (epoch 6.000), train_loss = 1.45315120, grad/param norm = 2.1001e-01, time/batch = 0.6831s	
3037/25300 (epoch 6.002), train_loss = 1.31742492, grad/param norm = 1.7115e-01, time/batch = 0.6785s	
3038/25300 (epoch 6.004), train_loss = 1.23987178, grad/param norm = 1.9567e-01, time/batch = 0.6721s	
3039/25300 (epoch 6.006), train_loss = 1.49079576, grad/param norm = 1.8730e-01, time/batch = 0.6716s	
3040/25300 (epoch 6.008), train_loss = 1.48824034, grad/param norm = 1.9345e-01, time/batch = 0.6839s	
3041/25300 (epoch 6.010), train_loss = 1.52706348, grad/param norm = 1.9544e-01, time/batch = 0.6811s	
3042/25300 (epoch 6.012), train_loss = 1.32383880, grad/param norm = 1.9930e-01, time/batch = 0.6791s	
3043/25300 (epoch 6.014), train_loss = 1.54583382, grad/param norm = 1.9787e-01, time/batch = 0.6723s	
3044/25300 (epoch 6.016), train_loss = 1.52321650, grad/param norm = 2.1239e-01, time/batch = 0.6769s	
3045/25300 (epoch 6.018), train_loss = 1.36393081, grad/param norm = 1.9247e-01, time/batch = 0.6791s	
3046/25300 (epoch 6.020), train_loss = 1.39139929, grad/param norm = 1.8105e-01, time/batch = 0.6756s	
3047/25300 (epoch 6.022), train_loss = 1.46455164, grad/param norm = 2.0646e-01, time/batch = 0.6796s	
3048/25300 (epoch 6.024), train_loss = 1.13809815, grad/param norm = 1.7507e-01, time/batch = 0.6747s	
3049/25300 (epoch 6.026), train_loss = 1.39292323, grad/param norm = 2.1259e-01, time/batch = 0.6819s	
3050/25300 (epoch 6.028), train_loss = 1.25898830, grad/param norm = 1.7884e-01, time/batch = 0.6742s	
3051/25300 (epoch 6.030), train_loss = 1.52169129, grad/param norm = 2.0005e-01, time/batch = 0.6744s	
3052/25300 (epoch 6.032), train_loss = 1.39163255, grad/param norm = 1.8033e-01, time/batch = 0.6720s	
3053/25300 (epoch 6.034), train_loss = 1.19116232, grad/param norm = 1.9119e-01, time/batch = 0.6717s	
3054/25300 (epoch 6.036), train_loss = 1.25380173, grad/param norm = 1.7500e-01, time/batch = 0.6736s	
3055/25300 (epoch 6.038), train_loss = 1.10515504, grad/param norm = 1.5566e-01, time/batch = 0.6708s	
3056/25300 (epoch 6.040), train_loss = 1.51275910, grad/param norm = 1.8911e-01, time/batch = 0.6692s	
3057/25300 (epoch 6.042), train_loss = 1.22587991, grad/param norm = 1.6401e-01, time/batch = 0.6727s	
3058/25300 (epoch 6.043), train_loss = 1.19697770, grad/param norm = 1.6882e-01, time/batch = 0.6769s	
3059/25300 (epoch 6.045), train_loss = 1.22493890, grad/param norm = 1.7518e-01, time/batch = 0.6705s	
3060/25300 (epoch 6.047), train_loss = 1.52179129, grad/param norm = 1.8703e-01, time/batch = 0.6763s	
3061/25300 (epoch 6.049), train_loss = 1.49296551, grad/param norm = 2.1249e-01, time/batch = 0.6777s	
3062/25300 (epoch 6.051), train_loss = 1.56172201, grad/param norm = 2.1447e-01, time/batch = 0.6737s	
3063/25300 (epoch 6.053), train_loss = 1.22961974, grad/param norm = 1.7944e-01, time/batch = 0.6677s	
3064/25300 (epoch 6.055), train_loss = 1.20320460, grad/param norm = 1.6586e-01, time/batch = 0.6741s	
3065/25300 (epoch 6.057), train_loss = 1.19617480, grad/param norm = 1.6475e-01, time/batch = 0.6677s	
3066/25300 (epoch 6.059), train_loss = 1.45243788, grad/param norm = 1.9731e-01, time/batch = 0.6752s	
3067/25300 (epoch 6.061), train_loss = 1.33533167, grad/param norm = 1.9297e-01, time/batch = 0.6750s	
3068/25300 (epoch 6.063), train_loss = 1.34083307, grad/param norm = 1.7398e-01, time/batch = 0.6766s	
3069/25300 (epoch 6.065), train_loss = 1.56946463, grad/param norm = 2.1991e-01, time/batch = 0.6746s	
3070/25300 (epoch 6.067), train_loss = 1.54478838, grad/param norm = 1.9460e-01, time/batch = 0.6760s	
3071/25300 (epoch 6.069), train_loss = 1.45018590, grad/param norm = 1.9012e-01, time/batch = 0.6767s	
3072/25300 (epoch 6.071), train_loss = 1.53716435, grad/param norm = 1.8545e-01, time/batch = 0.6798s	
3073/25300 (epoch 6.073), train_loss = 1.37881328, grad/param norm = 1.7935e-01, time/batch = 0.6785s	
3074/25300 (epoch 6.075), train_loss = 1.38173218, grad/param norm = 1.6761e-01, time/batch = 0.6739s	
3075/25300 (epoch 6.077), train_loss = 1.51112448, grad/param norm = 1.9849e-01, time/batch = 0.6786s	
3076/25300 (epoch 6.079), train_loss = 1.47362704, grad/param norm = 1.8928e-01, time/batch = 0.6756s	
3077/25300 (epoch 6.081), train_loss = 1.38301933, grad/param norm = 1.7979e-01, time/batch = 0.6740s	
3078/25300 (epoch 6.083), train_loss = 1.30146906, grad/param norm = 1.8989e-01, time/batch = 0.6775s	
3079/25300 (epoch 6.085), train_loss = 1.65931042, grad/param norm = 2.1229e-01, time/batch = 0.6768s	
3080/25300 (epoch 6.087), train_loss = 1.41571010, grad/param norm = 2.0035e-01, time/batch = 0.6718s	
3081/25300 (epoch 6.089), train_loss = 1.43947910, grad/param norm = 1.8788e-01, time/batch = 0.6776s	
3082/25300 (epoch 6.091), train_loss = 1.53133888, grad/param norm = 1.9393e-01, time/batch = 0.6825s	
3083/25300 (epoch 6.093), train_loss = 1.66548845, grad/param norm = 2.1147e-01, time/batch = 0.6796s	
3084/25300 (epoch 6.095), train_loss = 1.48068730, grad/param norm = 1.8637e-01, time/batch = 0.6800s	
3085/25300 (epoch 6.097), train_loss = 1.45173663, grad/param norm = 1.9421e-01, time/batch = 0.6822s	
3086/25300 (epoch 6.099), train_loss = 1.46882669, grad/param norm = 2.0509e-01, time/batch = 0.6748s	
3087/25300 (epoch 6.101), train_loss = 1.40024166, grad/param norm = 1.9617e-01, time/batch = 0.6737s	
3088/25300 (epoch 6.103), train_loss = 1.38358919, grad/param norm = 1.8368e-01, time/batch = 0.6711s	
3089/25300 (epoch 6.105), train_loss = 1.48422824, grad/param norm = 1.9345e-01, time/batch = 0.6726s	
3090/25300 (epoch 6.107), train_loss = 1.56089663, grad/param norm = 2.0603e-01, time/batch = 0.6738s	
3091/25300 (epoch 6.109), train_loss = 1.50543622, grad/param norm = 2.0577e-01, time/batch = 0.6780s	
3092/25300 (epoch 6.111), train_loss = 1.35859002, grad/param norm = 1.7947e-01, time/batch = 0.6738s	
3093/25300 (epoch 6.113), train_loss = 1.42173765, grad/param norm = 1.8553e-01, time/batch = 0.6755s	
3094/25300 (epoch 6.115), train_loss = 1.40924739, grad/param norm = 1.6803e-01, time/batch = 0.6773s	
3095/25300 (epoch 6.117), train_loss = 1.49454432, grad/param norm = 1.7640e-01, time/batch = 0.6818s	
3096/25300 (epoch 6.119), train_loss = 1.40961593, grad/param norm = 1.9754e-01, time/batch = 0.6783s	
3097/25300 (epoch 6.121), train_loss = 1.59201374, grad/param norm = 2.1358e-01, time/batch = 0.6830s	
3098/25300 (epoch 6.123), train_loss = 1.41503489, grad/param norm = 1.9175e-01, time/batch = 0.6843s	
3099/25300 (epoch 6.125), train_loss = 1.54498119, grad/param norm = 2.0005e-01, time/batch = 0.6737s	
3100/25300 (epoch 6.126), train_loss = 1.45312825, grad/param norm = 2.0233e-01, time/batch = 0.6675s	
3101/25300 (epoch 6.128), train_loss = 1.44337159, grad/param norm = 1.8438e-01, time/batch = 0.6759s	
3102/25300 (epoch 6.130), train_loss = 1.11863377, grad/param norm = 1.5740e-01, time/batch = 0.6731s	
3103/25300 (epoch 6.132), train_loss = 1.28999983, grad/param norm = 1.7574e-01, time/batch = 0.6748s	
3104/25300 (epoch 6.134), train_loss = 1.14133934, grad/param norm = 1.7124e-01, time/batch = 0.6728s	
3105/25300 (epoch 6.136), train_loss = 1.47452395, grad/param norm = 2.0345e-01, time/batch = 0.6731s	
3106/25300 (epoch 6.138), train_loss = 1.29291236, grad/param norm = 1.8920e-01, time/batch = 0.6694s	
3107/25300 (epoch 6.140), train_loss = 1.29577773, grad/param norm = 1.7727e-01, time/batch = 0.6698s	
3108/25300 (epoch 6.142), train_loss = 1.52237735, grad/param norm = 1.9487e-01, time/batch = 0.6781s	
3109/25300 (epoch 6.144), train_loss = 1.43302210, grad/param norm = 2.0274e-01, time/batch = 0.6801s	
3110/25300 (epoch 6.146), train_loss = 1.57593715, grad/param norm = 2.0598e-01, time/batch = 0.6721s	
3111/25300 (epoch 6.148), train_loss = 1.47642959, grad/param norm = 1.8333e-01, time/batch = 0.6714s	
3112/25300 (epoch 6.150), train_loss = 1.58165132, grad/param norm = 2.2562e-01, time/batch = 0.6787s	
3113/25300 (epoch 6.152), train_loss = 1.72351467, grad/param norm = 2.1918e-01, time/batch = 0.6717s	
3114/25300 (epoch 6.154), train_loss = 1.34280764, grad/param norm = 1.9778e-01, time/batch = 0.6782s	
3115/25300 (epoch 6.156), train_loss = 1.46570541, grad/param norm = 1.9576e-01, time/batch = 0.6827s	
3116/25300 (epoch 6.158), train_loss = 1.38568972, grad/param norm = 1.9056e-01, time/batch = 0.7013s	
3117/25300 (epoch 6.160), train_loss = 1.43093905, grad/param norm = 1.9451e-01, time/batch = 0.6955s	
3118/25300 (epoch 6.162), train_loss = 1.37429276, grad/param norm = 2.0743e-01, time/batch = 0.6835s	
3119/25300 (epoch 6.164), train_loss = 1.47283892, grad/param norm = 2.0086e-01, time/batch = 0.6785s	
3120/25300 (epoch 6.166), train_loss = 1.46960604, grad/param norm = 1.9763e-01, time/batch = 0.6734s	
3121/25300 (epoch 6.168), train_loss = 1.23948119, grad/param norm = 1.5912e-01, time/batch = 0.6892s	
3122/25300 (epoch 6.170), train_loss = 1.31953856, grad/param norm = 1.7825e-01, time/batch = 0.6811s	
3123/25300 (epoch 6.172), train_loss = 1.30794408, grad/param norm = 1.8322e-01, time/batch = 0.6747s	
3124/25300 (epoch 6.174), train_loss = 1.29420252, grad/param norm = 1.7659e-01, time/batch = 0.6761s	
3125/25300 (epoch 6.176), train_loss = 1.38895938, grad/param norm = 1.9665e-01, time/batch = 0.6741s	
3126/25300 (epoch 6.178), train_loss = 1.59395285, grad/param norm = 1.9882e-01, time/batch = 0.6698s	
3127/25300 (epoch 6.180), train_loss = 1.19159223, grad/param norm = 1.8246e-01, time/batch = 0.6717s	
3128/25300 (epoch 6.182), train_loss = 1.36435001, grad/param norm = 1.8198e-01, time/batch = 0.6733s	
3129/25300 (epoch 6.184), train_loss = 1.39648560, grad/param norm = 1.8567e-01, time/batch = 0.6726s	
3130/25300 (epoch 6.186), train_loss = 1.40636412, grad/param norm = 2.0018e-01, time/batch = 0.6734s	
3131/25300 (epoch 6.188), train_loss = 1.36858430, grad/param norm = 1.9005e-01, time/batch = 0.6770s	
3132/25300 (epoch 6.190), train_loss = 1.48991774, grad/param norm = 1.9964e-01, time/batch = 0.6768s	
3133/25300 (epoch 6.192), train_loss = 1.43603896, grad/param norm = 2.0116e-01, time/batch = 0.6874s	
3134/25300 (epoch 6.194), train_loss = 1.41544442, grad/param norm = 1.8030e-01, time/batch = 0.6882s	
3135/25300 (epoch 6.196), train_loss = 1.50205271, grad/param norm = 2.0909e-01, time/batch = 0.6834s	
3136/25300 (epoch 6.198), train_loss = 1.37768227, grad/param norm = 1.9993e-01, time/batch = 0.6800s	
3137/25300 (epoch 6.200), train_loss = 1.48543425, grad/param norm = 1.9921e-01, time/batch = 0.6766s	
3138/25300 (epoch 6.202), train_loss = 1.47486334, grad/param norm = 1.9499e-01, time/batch = 0.6832s	
3139/25300 (epoch 6.204), train_loss = 1.38379858, grad/param norm = 1.8196e-01, time/batch = 0.6672s	
3140/25300 (epoch 6.206), train_loss = 1.46884556, grad/param norm = 2.0556e-01, time/batch = 0.6703s	
3141/25300 (epoch 6.208), train_loss = 1.28806175, grad/param norm = 2.0519e-01, time/batch = 0.6784s	
3142/25300 (epoch 6.209), train_loss = 1.17388258, grad/param norm = 1.6779e-01, time/batch = 0.6789s	
3143/25300 (epoch 6.211), train_loss = 1.38943730, grad/param norm = 1.8526e-01, time/batch = 0.6695s	
3144/25300 (epoch 6.213), train_loss = 1.48043185, grad/param norm = 2.0783e-01, time/batch = 0.6736s	
3145/25300 (epoch 6.215), train_loss = 1.41471228, grad/param norm = 2.0376e-01, time/batch = 0.6811s	
3146/25300 (epoch 6.217), train_loss = 1.50898493, grad/param norm = 2.1902e-01, time/batch = 0.6776s	
3147/25300 (epoch 6.219), train_loss = 1.45513594, grad/param norm = 1.9454e-01, time/batch = 0.6697s	
3148/25300 (epoch 6.221), train_loss = 1.54551314, grad/param norm = 2.0497e-01, time/batch = 0.6841s	
3149/25300 (epoch 6.223), train_loss = 1.53024110, grad/param norm = 2.0978e-01, time/batch = 0.6752s	
3150/25300 (epoch 6.225), train_loss = 1.92392904, grad/param norm = 2.4017e-01, time/batch = 0.6739s	
3151/25300 (epoch 6.227), train_loss = 1.50799595, grad/param norm = 1.8803e-01, time/batch = 0.6746s	
3152/25300 (epoch 6.229), train_loss = 1.50275423, grad/param norm = 2.0705e-01, time/batch = 0.6741s	
3153/25300 (epoch 6.231), train_loss = 1.45075735, grad/param norm = 1.9047e-01, time/batch = 0.6772s	
3154/25300 (epoch 6.233), train_loss = 1.46010762, grad/param norm = 1.8124e-01, time/batch = 0.6825s	
3155/25300 (epoch 6.235), train_loss = 1.40856320, grad/param norm = 1.8715e-01, time/batch = 0.6792s	
3156/25300 (epoch 6.237), train_loss = 1.59177117, grad/param norm = 2.0427e-01, time/batch = 0.6719s	
3157/25300 (epoch 6.239), train_loss = 1.45747412, grad/param norm = 2.0445e-01, time/batch = 0.6774s	
3158/25300 (epoch 6.241), train_loss = 1.51603286, grad/param norm = 1.9995e-01, time/batch = 0.6774s	
3159/25300 (epoch 6.243), train_loss = 1.79668538, grad/param norm = 2.1548e-01, time/batch = 0.6767s	
3160/25300 (epoch 6.245), train_loss = 1.34017185, grad/param norm = 1.9463e-01, time/batch = 0.6833s	
3161/25300 (epoch 6.247), train_loss = 1.59613680, grad/param norm = 2.0817e-01, time/batch = 0.6846s	
3162/25300 (epoch 6.249), train_loss = 1.28026461, grad/param norm = 1.9335e-01, time/batch = 0.6779s	
3163/25300 (epoch 6.251), train_loss = 1.23775487, grad/param norm = 1.8681e-01, time/batch = 0.6769s	
3164/25300 (epoch 6.253), train_loss = 1.39879498, grad/param norm = 1.8289e-01, time/batch = 0.6760s	
3165/25300 (epoch 6.255), train_loss = 1.36775191, grad/param norm = 1.8575e-01, time/batch = 0.6757s	
3166/25300 (epoch 6.257), train_loss = 1.56893681, grad/param norm = 1.9972e-01, time/batch = 0.6817s	
3167/25300 (epoch 6.259), train_loss = 1.74528543, grad/param norm = 2.1831e-01, time/batch = 0.6780s	
3168/25300 (epoch 6.261), train_loss = 1.60177410, grad/param norm = 2.1208e-01, time/batch = 0.6752s	
3169/25300 (epoch 6.263), train_loss = 1.54080702, grad/param norm = 1.9296e-01, time/batch = 0.6756s	
3170/25300 (epoch 6.265), train_loss = 1.61063398, grad/param norm = 1.9610e-01, time/batch = 0.6729s	
3171/25300 (epoch 6.267), train_loss = 1.55191665, grad/param norm = 1.7408e-01, time/batch = 0.6742s	
3172/25300 (epoch 6.269), train_loss = 1.26452285, grad/param norm = 1.8216e-01, time/batch = 0.6692s	
3173/25300 (epoch 6.271), train_loss = 1.32978505, grad/param norm = 1.9682e-01, time/batch = 0.6782s	
3174/25300 (epoch 6.273), train_loss = 1.48743442, grad/param norm = 1.8988e-01, time/batch = 0.6800s	
3175/25300 (epoch 6.275), train_loss = 1.27454876, grad/param norm = 1.7349e-01, time/batch = 0.6729s	
3176/25300 (epoch 6.277), train_loss = 1.40205807, grad/param norm = 1.8365e-01, time/batch = 0.6711s	
3177/25300 (epoch 6.279), train_loss = 1.45869724, grad/param norm = 1.9943e-01, time/batch = 0.6722s	
3178/25300 (epoch 6.281), train_loss = 1.60991892, grad/param norm = 2.2133e-01, time/batch = 0.6734s	
3179/25300 (epoch 6.283), train_loss = 1.34049316, grad/param norm = 2.0081e-01, time/batch = 0.6694s	
3180/25300 (epoch 6.285), train_loss = 1.43529569, grad/param norm = 2.0817e-01, time/batch = 0.6741s	
3181/25300 (epoch 6.287), train_loss = 1.40913873, grad/param norm = 1.8287e-01, time/batch = 0.6728s	
3182/25300 (epoch 6.289), train_loss = 1.36393845, grad/param norm = 1.8399e-01, time/batch = 0.6740s	
3183/25300 (epoch 6.291), train_loss = 1.31775847, grad/param norm = 1.9619e-01, time/batch = 0.6755s	
3184/25300 (epoch 6.292), train_loss = 1.54016589, grad/param norm = 2.0474e-01, time/batch = 0.6788s	
3185/25300 (epoch 6.294), train_loss = 1.44410316, grad/param norm = 2.0202e-01, time/batch = 0.6826s	
3186/25300 (epoch 6.296), train_loss = 1.28969969, grad/param norm = 1.9786e-01, time/batch = 0.6764s	
3187/25300 (epoch 6.298), train_loss = 1.51896352, grad/param norm = 2.0244e-01, time/batch = 0.6757s	
3188/25300 (epoch 6.300), train_loss = 1.68971270, grad/param norm = 2.3670e-01, time/batch = 0.6885s	
3189/25300 (epoch 6.302), train_loss = 1.26811250, grad/param norm = 1.9269e-01, time/batch = 0.6850s	
3190/25300 (epoch 6.304), train_loss = 1.48090375, grad/param norm = 2.0646e-01, time/batch = 0.6773s	
3191/25300 (epoch 6.306), train_loss = 1.15527217, grad/param norm = 1.7438e-01, time/batch = 0.6778s	
3192/25300 (epoch 6.308), train_loss = 1.45917373, grad/param norm = 1.6812e-01, time/batch = 0.6732s	
3193/25300 (epoch 6.310), train_loss = 1.37790499, grad/param norm = 1.9328e-01, time/batch = 0.6749s	
3194/25300 (epoch 6.312), train_loss = 1.42442147, grad/param norm = 1.9324e-01, time/batch = 0.6740s	
3195/25300 (epoch 6.314), train_loss = 1.17983583, grad/param norm = 1.8431e-01, time/batch = 0.6780s	
3196/25300 (epoch 6.316), train_loss = 1.44705306, grad/param norm = 1.8000e-01, time/batch = 0.6755s	
3197/25300 (epoch 6.318), train_loss = 1.13022906, grad/param norm = 1.7296e-01, time/batch = 0.6757s	
3198/25300 (epoch 6.320), train_loss = 1.31912005, grad/param norm = 1.9306e-01, time/batch = 0.6763s	
3199/25300 (epoch 6.322), train_loss = 1.71896584, grad/param norm = 2.0825e-01, time/batch = 0.6809s	
3200/25300 (epoch 6.324), train_loss = 1.29986444, grad/param norm = 1.8641e-01, time/batch = 0.6784s	
3201/25300 (epoch 6.326), train_loss = 1.16150368, grad/param norm = 1.6186e-01, time/batch = 0.6909s	
3202/25300 (epoch 6.328), train_loss = 1.21921245, grad/param norm = 1.7827e-01, time/batch = 0.6823s	
3203/25300 (epoch 6.330), train_loss = 1.34438507, grad/param norm = 1.8669e-01, time/batch = 0.6840s	
3204/25300 (epoch 6.332), train_loss = 1.46393931, grad/param norm = 1.9021e-01, time/batch = 0.6860s	
3205/25300 (epoch 6.334), train_loss = 1.29698843, grad/param norm = 1.7019e-01, time/batch = 0.6793s	
3206/25300 (epoch 6.336), train_loss = 1.24965452, grad/param norm = 1.8744e-01, time/batch = 0.6765s	
3207/25300 (epoch 6.338), train_loss = 1.26151876, grad/param norm = 1.9124e-01, time/batch = 0.6782s	
3208/25300 (epoch 6.340), train_loss = 1.35498065, grad/param norm = 2.0247e-01, time/batch = 0.6935s	
3209/25300 (epoch 6.342), train_loss = 1.34040587, grad/param norm = 1.9405e-01, time/batch = 0.6774s	
3210/25300 (epoch 6.344), train_loss = 1.35359510, grad/param norm = 1.9407e-01, time/batch = 0.6780s	
3211/25300 (epoch 6.346), train_loss = 1.38808930, grad/param norm = 1.9825e-01, time/batch = 0.6764s	
3212/25300 (epoch 6.348), train_loss = 1.19975311, grad/param norm = 1.5489e-01, time/batch = 0.6792s	
3213/25300 (epoch 6.350), train_loss = 1.34424129, grad/param norm = 1.8617e-01, time/batch = 0.6765s	
3214/25300 (epoch 6.352), train_loss = 1.41241536, grad/param norm = 1.8611e-01, time/batch = 0.6850s	
3215/25300 (epoch 6.354), train_loss = 1.37829913, grad/param norm = 2.0861e-01, time/batch = 0.6742s	
3216/25300 (epoch 6.356), train_loss = 1.44950727, grad/param norm = 2.1027e-01, time/batch = 0.6785s	
3217/25300 (epoch 6.358), train_loss = 1.51502868, grad/param norm = 2.1590e-01, time/batch = 0.6878s	
3218/25300 (epoch 6.360), train_loss = 1.30258767, grad/param norm = 1.8977e-01, time/batch = 0.6769s	
3219/25300 (epoch 6.362), train_loss = 1.46661333, grad/param norm = 2.0090e-01, time/batch = 0.6749s	
3220/25300 (epoch 6.364), train_loss = 1.53740062, grad/param norm = 2.1578e-01, time/batch = 0.6807s	
3221/25300 (epoch 6.366), train_loss = 1.25234869, grad/param norm = 1.7990e-01, time/batch = 0.6779s	
3222/25300 (epoch 6.368), train_loss = 1.40771575, grad/param norm = 1.7643e-01, time/batch = 0.6767s	
3223/25300 (epoch 6.370), train_loss = 1.41566374, grad/param norm = 2.1475e-01, time/batch = 0.6738s	
3224/25300 (epoch 6.372), train_loss = 1.37777874, grad/param norm = 1.9991e-01, time/batch = 0.6786s	
3225/25300 (epoch 6.374), train_loss = 1.30506758, grad/param norm = 1.9187e-01, time/batch = 0.6756s	
3226/25300 (epoch 6.375), train_loss = 1.65213541, grad/param norm = 2.1083e-01, time/batch = 0.6754s	
3227/25300 (epoch 6.377), train_loss = 1.37619073, grad/param norm = 1.8855e-01, time/batch = 0.6847s	
3228/25300 (epoch 6.379), train_loss = 1.65738878, grad/param norm = 2.1834e-01, time/batch = 0.6776s	
3229/25300 (epoch 6.381), train_loss = 1.37933268, grad/param norm = 1.7349e-01, time/batch = 0.6731s	
3230/25300 (epoch 6.383), train_loss = 1.26971190, grad/param norm = 1.7834e-01, time/batch = 0.6796s	
3231/25300 (epoch 6.385), train_loss = 1.33083333, grad/param norm = 1.8802e-01, time/batch = 0.6749s	
3232/25300 (epoch 6.387), train_loss = 1.50972354, grad/param norm = 2.0239e-01, time/batch = 0.6754s	
3233/25300 (epoch 6.389), train_loss = 1.61709171, grad/param norm = 2.1974e-01, time/batch = 0.6748s	
3234/25300 (epoch 6.391), train_loss = 1.24511306, grad/param norm = 1.8305e-01, time/batch = 0.6758s	
3235/25300 (epoch 6.393), train_loss = 1.48874174, grad/param norm = 1.8967e-01, time/batch = 0.6732s	
3236/25300 (epoch 6.395), train_loss = 1.20843802, grad/param norm = 1.7805e-01, time/batch = 0.6732s	
3237/25300 (epoch 6.397), train_loss = 1.27229471, grad/param norm = 1.9355e-01, time/batch = 0.6784s	
3238/25300 (epoch 6.399), train_loss = 1.25554292, grad/param norm = 1.7465e-01, time/batch = 0.6771s	
3239/25300 (epoch 6.401), train_loss = 1.52025614, grad/param norm = 2.0445e-01, time/batch = 0.6758s	
3240/25300 (epoch 6.403), train_loss = 1.43035623, grad/param norm = 2.3247e-01, time/batch = 0.6863s	
3241/25300 (epoch 6.405), train_loss = 1.46715092, grad/param norm = 1.9673e-01, time/batch = 0.6761s	
3242/25300 (epoch 6.407), train_loss = 1.29844076, grad/param norm = 1.8680e-01, time/batch = 0.6693s	
3243/25300 (epoch 6.409), train_loss = 1.30162299, grad/param norm = 1.7103e-01, time/batch = 0.6702s	
3244/25300 (epoch 6.411), train_loss = 1.39464802, grad/param norm = 1.9619e-01, time/batch = 0.6682s	
3245/25300 (epoch 6.413), train_loss = 1.27183007, grad/param norm = 1.7750e-01, time/batch = 0.6718s	
3246/25300 (epoch 6.415), train_loss = 1.27374165, grad/param norm = 1.8223e-01, time/batch = 0.6730s	
3247/25300 (epoch 6.417), train_loss = 1.25451497, grad/param norm = 1.8716e-01, time/batch = 0.6766s	
3248/25300 (epoch 6.419), train_loss = 1.19397560, grad/param norm = 1.9672e-01, time/batch = 0.6715s	
3249/25300 (epoch 6.421), train_loss = 1.19398749, grad/param norm = 1.7754e-01, time/batch = 0.6720s	
3250/25300 (epoch 6.423), train_loss = 1.26610517, grad/param norm = 1.7685e-01, time/batch = 0.6774s	
3251/25300 (epoch 6.425), train_loss = 1.37307670, grad/param norm = 2.1626e-01, time/batch = 0.6789s	
3252/25300 (epoch 6.427), train_loss = 1.60091567, grad/param norm = 2.0553e-01, time/batch = 0.6744s	
3253/25300 (epoch 6.429), train_loss = 1.50551651, grad/param norm = 2.2598e-01, time/batch = 0.6815s	
3254/25300 (epoch 6.431), train_loss = 1.45828835, grad/param norm = 2.0949e-01, time/batch = 0.6814s	
3255/25300 (epoch 6.433), train_loss = 1.37694284, grad/param norm = 1.8372e-01, time/batch = 0.6840s	
3256/25300 (epoch 6.435), train_loss = 1.26473301, grad/param norm = 1.9364e-01, time/batch = 0.6828s	
3257/25300 (epoch 6.437), train_loss = 1.33877813, grad/param norm = 1.8670e-01, time/batch = 0.6840s	
3258/25300 (epoch 6.439), train_loss = 1.38965750, grad/param norm = 1.9825e-01, time/batch = 0.6831s	
3259/25300 (epoch 6.441), train_loss = 1.42110089, grad/param norm = 2.0295e-01, time/batch = 0.6795s	
3260/25300 (epoch 6.443), train_loss = 1.58422753, grad/param norm = 2.1873e-01, time/batch = 0.6771s	
3261/25300 (epoch 6.445), train_loss = 1.51180169, grad/param norm = 1.9215e-01, time/batch = 0.6764s	
3262/25300 (epoch 6.447), train_loss = 1.28342998, grad/param norm = 1.8815e-01, time/batch = 0.6729s	
3263/25300 (epoch 6.449), train_loss = 1.22601970, grad/param norm = 1.7844e-01, time/batch = 0.6726s	
3264/25300 (epoch 6.451), train_loss = 1.57021782, grad/param norm = 2.0167e-01, time/batch = 0.6694s	
3265/25300 (epoch 6.453), train_loss = 1.46176713, grad/param norm = 1.8957e-01, time/batch = 0.6791s	
3266/25300 (epoch 6.455), train_loss = 1.58323322, grad/param norm = 1.9266e-01, time/batch = 0.6850s	
3267/25300 (epoch 6.457), train_loss = 1.38830353, grad/param norm = 1.8942e-01, time/batch = 0.6758s	
3268/25300 (epoch 6.458), train_loss = 1.46969268, grad/param norm = 2.0910e-01, time/batch = 0.6764s	
3269/25300 (epoch 6.460), train_loss = 1.47409733, grad/param norm = 2.1238e-01, time/batch = 0.6752s	
3270/25300 (epoch 6.462), train_loss = 1.18408293, grad/param norm = 1.9249e-01, time/batch = 0.6737s	
3271/25300 (epoch 6.464), train_loss = 1.47147985, grad/param norm = 2.2386e-01, time/batch = 0.6775s	
3272/25300 (epoch 6.466), train_loss = 1.48518324, grad/param norm = 2.1737e-01, time/batch = 0.6788s	
3273/25300 (epoch 6.468), train_loss = 1.57666482, grad/param norm = 2.0497e-01, time/batch = 0.6764s	
3274/25300 (epoch 6.470), train_loss = 1.29621728, grad/param norm = 1.9016e-01, time/batch = 0.6730s	
3275/25300 (epoch 6.472), train_loss = 1.15247170, grad/param norm = 1.7463e-01, time/batch = 0.6773s	
3276/25300 (epoch 6.474), train_loss = 1.44647845, grad/param norm = 1.9801e-01, time/batch = 0.6762s	
3277/25300 (epoch 6.476), train_loss = 1.37856155, grad/param norm = 1.8281e-01, time/batch = 0.6749s	
3278/25300 (epoch 6.478), train_loss = 1.44728882, grad/param norm = 1.8607e-01, time/batch = 0.6790s	
3279/25300 (epoch 6.480), train_loss = 1.27782849, grad/param norm = 1.8352e-01, time/batch = 0.6798s	
3280/25300 (epoch 6.482), train_loss = 1.58459854, grad/param norm = 2.1130e-01, time/batch = 0.6747s	
3281/25300 (epoch 6.484), train_loss = 1.53200908, grad/param norm = 2.1486e-01, time/batch = 0.6808s	
3282/25300 (epoch 6.486), train_loss = 1.39243090, grad/param norm = 1.9801e-01, time/batch = 0.6750s	
3283/25300 (epoch 6.488), train_loss = 1.45893107, grad/param norm = 2.0227e-01, time/batch = 0.6749s	
3284/25300 (epoch 6.490), train_loss = 1.50580640, grad/param norm = 1.9666e-01, time/batch = 0.6794s	
3285/25300 (epoch 6.492), train_loss = 1.31644436, grad/param norm = 1.7814e-01, time/batch = 0.6781s	
3286/25300 (epoch 6.494), train_loss = 1.24626604, grad/param norm = 1.7942e-01, time/batch = 0.6757s	
3287/25300 (epoch 6.496), train_loss = 1.42430124, grad/param norm = 1.9144e-01, time/batch = 0.6774s	
3288/25300 (epoch 6.498), train_loss = 1.27685717, grad/param norm = 1.8097e-01, time/batch = 0.6789s	
3289/25300 (epoch 6.500), train_loss = 1.57020591, grad/param norm = 2.0737e-01, time/batch = 0.6790s	
3290/25300 (epoch 6.502), train_loss = 1.37381746, grad/param norm = 1.8682e-01, time/batch = 0.6797s	
3291/25300 (epoch 6.504), train_loss = 1.33970441, grad/param norm = 1.9569e-01, time/batch = 0.6888s	
3292/25300 (epoch 6.506), train_loss = 1.41148340, grad/param norm = 2.0627e-01, time/batch = 0.6830s	
3293/25300 (epoch 6.508), train_loss = 1.42184231, grad/param norm = 2.1360e-01, time/batch = 0.6827s	
3294/25300 (epoch 6.510), train_loss = 1.32529631, grad/param norm = 2.0720e-01, time/batch = 0.6736s	
3295/25300 (epoch 6.512), train_loss = 1.07727156, grad/param norm = 1.6029e-01, time/batch = 0.6756s	
3296/25300 (epoch 6.514), train_loss = 1.26074369, grad/param norm = 1.7853e-01, time/batch = 0.6952s	
3297/25300 (epoch 6.516), train_loss = 1.36461593, grad/param norm = 1.9788e-01, time/batch = 0.6873s	
3298/25300 (epoch 6.518), train_loss = 1.45706607, grad/param norm = 2.2243e-01, time/batch = 0.6837s	
3299/25300 (epoch 6.520), train_loss = 1.17710842, grad/param norm = 1.8856e-01, time/batch = 0.6735s	
3300/25300 (epoch 6.522), train_loss = 1.28951229, grad/param norm = 1.7696e-01, time/batch = 0.6782s	
3301/25300 (epoch 6.524), train_loss = 1.28559753, grad/param norm = 1.8224e-01, time/batch = 0.6830s	
3302/25300 (epoch 6.526), train_loss = 1.63201185, grad/param norm = 2.3729e-01, time/batch = 0.6732s	
3303/25300 (epoch 6.528), train_loss = 1.50742134, grad/param norm = 2.0705e-01, time/batch = 0.6840s	
3304/25300 (epoch 6.530), train_loss = 1.38339836, grad/param norm = 2.1106e-01, time/batch = 0.6797s	
3305/25300 (epoch 6.532), train_loss = 1.42196992, grad/param norm = 1.9809e-01, time/batch = 0.6759s	
3306/25300 (epoch 6.534), train_loss = 1.34755820, grad/param norm = 2.0411e-01, time/batch = 0.6761s	
3307/25300 (epoch 6.536), train_loss = 1.25486373, grad/param norm = 2.0597e-01, time/batch = 0.6753s	
3308/25300 (epoch 6.538), train_loss = 1.19526317, grad/param norm = 1.6270e-01, time/batch = 0.6784s	
3309/25300 (epoch 6.540), train_loss = 1.29422218, grad/param norm = 1.8230e-01, time/batch = 0.6721s	
3310/25300 (epoch 6.542), train_loss = 1.26402166, grad/param norm = 1.9279e-01, time/batch = 0.6723s	
3311/25300 (epoch 6.543), train_loss = 1.22077678, grad/param norm = 1.7700e-01, time/batch = 0.6735s	
3312/25300 (epoch 6.545), train_loss = 1.81636643, grad/param norm = 2.2847e-01, time/batch = 0.6766s	
3313/25300 (epoch 6.547), train_loss = 1.35652552, grad/param norm = 2.0010e-01, time/batch = 0.6759s	
3314/25300 (epoch 6.549), train_loss = 1.65047872, grad/param norm = 2.1742e-01, time/batch = 0.6751s	
3315/25300 (epoch 6.551), train_loss = 1.40726916, grad/param norm = 2.0334e-01, time/batch = 0.6765s	
3316/25300 (epoch 6.553), train_loss = 1.42828448, grad/param norm = 1.9637e-01, time/batch = 0.6756s	
3317/25300 (epoch 6.555), train_loss = 1.51953191, grad/param norm = 1.9951e-01, time/batch = 0.6729s	
3318/25300 (epoch 6.557), train_loss = 1.55721101, grad/param norm = 1.9492e-01, time/batch = 0.6761s	
3319/25300 (epoch 6.559), train_loss = 1.54637128, grad/param norm = 2.0621e-01, time/batch = 0.6718s	
3320/25300 (epoch 6.561), train_loss = 1.59750255, grad/param norm = 2.1175e-01, time/batch = 0.6730s	
3321/25300 (epoch 6.563), train_loss = 1.48900761, grad/param norm = 1.8969e-01, time/batch = 0.6915s	
3322/25300 (epoch 6.565), train_loss = 1.23661539, grad/param norm = 1.7372e-01, time/batch = 0.6874s	
3323/25300 (epoch 6.567), train_loss = 1.07289266, grad/param norm = 1.8443e-01, time/batch = 0.6789s	
3324/25300 (epoch 6.569), train_loss = 1.38064422, grad/param norm = 1.9207e-01, time/batch = 0.6750s	
3325/25300 (epoch 6.571), train_loss = 1.48823647, grad/param norm = 1.9307e-01, time/batch = 0.6761s	
3326/25300 (epoch 6.573), train_loss = 1.39094778, grad/param norm = 1.8601e-01, time/batch = 0.6749s	
3327/25300 (epoch 6.575), train_loss = 1.47833878, grad/param norm = 1.9442e-01, time/batch = 0.6740s	
3328/25300 (epoch 6.577), train_loss = 1.45105847, grad/param norm = 1.9051e-01, time/batch = 0.6873s	
3329/25300 (epoch 6.579), train_loss = 1.62152165, grad/param norm = 2.1248e-01, time/batch = 0.6791s	
3330/25300 (epoch 6.581), train_loss = 1.45690763, grad/param norm = 1.9836e-01, time/batch = 0.6753s	
3331/25300 (epoch 6.583), train_loss = 1.30929471, grad/param norm = 1.8658e-01, time/batch = 0.6760s	
3332/25300 (epoch 6.585), train_loss = 1.25306666, grad/param norm = 1.7859e-01, time/batch = 0.6754s	
3333/25300 (epoch 6.587), train_loss = 1.33300928, grad/param norm = 1.8234e-01, time/batch = 0.6743s	
3334/25300 (epoch 6.589), train_loss = 1.21626908, grad/param norm = 1.6944e-01, time/batch = 0.6863s	
3335/25300 (epoch 6.591), train_loss = 1.25112838, grad/param norm = 1.9235e-01, time/batch = 0.6745s	
3336/25300 (epoch 6.593), train_loss = 1.34578096, grad/param norm = 1.7884e-01, time/batch = 0.6737s	
3337/25300 (epoch 6.595), train_loss = 1.36076289, grad/param norm = 1.8973e-01, time/batch = 0.6832s	
3338/25300 (epoch 6.597), train_loss = 1.16557514, grad/param norm = 1.7154e-01, time/batch = 0.6818s	
3339/25300 (epoch 6.599), train_loss = 1.37425032, grad/param norm = 1.8174e-01, time/batch = 0.6860s	
3340/25300 (epoch 6.601), train_loss = 1.40563437, grad/param norm = 1.8815e-01, time/batch = 0.6823s	
3341/25300 (epoch 6.603), train_loss = 1.43207591, grad/param norm = 1.7305e-01, time/batch = 0.6862s	
3342/25300 (epoch 6.605), train_loss = 1.30140939, grad/param norm = 1.8575e-01, time/batch = 0.6861s	
3343/25300 (epoch 6.607), train_loss = 1.19731553, grad/param norm = 1.7909e-01, time/batch = 0.6857s	
3344/25300 (epoch 6.609), train_loss = 1.37164371, grad/param norm = 1.8111e-01, time/batch = 0.6809s	
3345/25300 (epoch 6.611), train_loss = 1.49653744, grad/param norm = 1.7844e-01, time/batch = 0.6775s	
3346/25300 (epoch 6.613), train_loss = 1.27230112, grad/param norm = 1.8061e-01, time/batch = 0.6844s	
3347/25300 (epoch 6.615), train_loss = 1.43108734, grad/param norm = 2.1007e-01, time/batch = 0.6842s	
3348/25300 (epoch 6.617), train_loss = 1.38627580, grad/param norm = 1.8318e-01, time/batch = 0.6819s	
3349/25300 (epoch 6.619), train_loss = 1.47550952, grad/param norm = 1.9397e-01, time/batch = 0.6782s	
3350/25300 (epoch 6.621), train_loss = 1.46019348, grad/param norm = 1.9362e-01, time/batch = 0.6760s	
3351/25300 (epoch 6.623), train_loss = 1.32451121, grad/param norm = 1.9861e-01, time/batch = 0.6775s	
3352/25300 (epoch 6.625), train_loss = 1.20181537, grad/param norm = 1.9482e-01, time/batch = 0.6783s	
3353/25300 (epoch 6.626), train_loss = 1.33546236, grad/param norm = 1.8570e-01, time/batch = 0.6790s	
3354/25300 (epoch 6.628), train_loss = 1.55579205, grad/param norm = 2.1112e-01, time/batch = 0.6783s	
3355/25300 (epoch 6.630), train_loss = 1.57328898, grad/param norm = 2.0096e-01, time/batch = 0.6760s	
3356/25300 (epoch 6.632), train_loss = 1.50764915, grad/param norm = 2.1168e-01, time/batch = 0.6750s	
3357/25300 (epoch 6.634), train_loss = 1.54976491, grad/param norm = 2.0755e-01, time/batch = 0.6776s	
3358/25300 (epoch 6.636), train_loss = 1.42568646, grad/param norm = 2.0083e-01, time/batch = 0.6790s	
3359/25300 (epoch 6.638), train_loss = 1.53598883, grad/param norm = 2.0818e-01, time/batch = 0.6744s	
3360/25300 (epoch 6.640), train_loss = 1.63755140, grad/param norm = 2.1196e-01, time/batch = 0.6809s	
3361/25300 (epoch 6.642), train_loss = 1.46348511, grad/param norm = 2.0938e-01, time/batch = 0.6852s	
3362/25300 (epoch 6.644), train_loss = 1.49433205, grad/param norm = 1.9505e-01, time/batch = 0.6736s	
3363/25300 (epoch 6.646), train_loss = 1.43002506, grad/param norm = 1.9016e-01, time/batch = 0.6756s	
3364/25300 (epoch 6.648), train_loss = 1.51605301, grad/param norm = 1.8093e-01, time/batch = 0.6771s	
3365/25300 (epoch 6.650), train_loss = 1.47977181, grad/param norm = 1.9993e-01, time/batch = 0.6785s	
3366/25300 (epoch 6.652), train_loss = 1.49581181, grad/param norm = 2.0481e-01, time/batch = 0.6765s	
3367/25300 (epoch 6.654), train_loss = 1.60439145, grad/param norm = 1.9835e-01, time/batch = 0.6719s	
3368/25300 (epoch 6.656), train_loss = 1.55019872, grad/param norm = 2.0736e-01, time/batch = 0.6736s	
3369/25300 (epoch 6.658), train_loss = 1.21899786, grad/param norm = 1.6310e-01, time/batch = 0.6692s	
3370/25300 (epoch 6.660), train_loss = 1.25813705, grad/param norm = 1.8901e-01, time/batch = 0.6820s	
3371/25300 (epoch 6.662), train_loss = 1.18510768, grad/param norm = 1.8331e-01, time/batch = 0.6785s	
3372/25300 (epoch 6.664), train_loss = 1.17678966, grad/param norm = 1.6719e-01, time/batch = 0.6772s	
3373/25300 (epoch 6.666), train_loss = 1.22830706, grad/param norm = 1.8385e-01, time/batch = 0.6836s	
3374/25300 (epoch 6.668), train_loss = 1.28444833, grad/param norm = 2.1489e-01, time/batch = 0.6763s	
3375/25300 (epoch 6.670), train_loss = 1.31020877, grad/param norm = 1.8614e-01, time/batch = 0.6828s	
3376/25300 (epoch 6.672), train_loss = 1.33522960, grad/param norm = 1.8197e-01, time/batch = 0.6853s	
3377/25300 (epoch 6.674), train_loss = 1.35563779, grad/param norm = 1.9322e-01, time/batch = 0.6825s	
3378/25300 (epoch 6.676), train_loss = 1.45362325, grad/param norm = 1.9739e-01, time/batch = 0.6835s	
3379/25300 (epoch 6.678), train_loss = 1.33926014, grad/param norm = 2.1219e-01, time/batch = 0.6845s	
3380/25300 (epoch 6.680), train_loss = 1.21903678, grad/param norm = 1.8764e-01, time/batch = 0.6853s	
3381/25300 (epoch 6.682), train_loss = 1.03580998, grad/param norm = 1.6403e-01, time/batch = 0.6790s	
3382/25300 (epoch 6.684), train_loss = 1.20596377, grad/param norm = 1.7190e-01, time/batch = 0.6735s	
3383/25300 (epoch 6.686), train_loss = 1.25197955, grad/param norm = 1.8571e-01, time/batch = 0.6733s	
3384/25300 (epoch 6.688), train_loss = 1.41925498, grad/param norm = 1.8161e-01, time/batch = 0.6759s	
3385/25300 (epoch 6.690), train_loss = 1.29118867, grad/param norm = 1.7506e-01, time/batch = 0.6830s	
3386/25300 (epoch 6.692), train_loss = 1.41593083, grad/param norm = 1.8584e-01, time/batch = 0.6732s	
3387/25300 (epoch 6.694), train_loss = 1.29316657, grad/param norm = 1.6969e-01, time/batch = 0.6752s	
3388/25300 (epoch 6.696), train_loss = 1.38581363, grad/param norm = 1.8830e-01, time/batch = 0.6844s	
3389/25300 (epoch 6.698), train_loss = 1.40284089, grad/param norm = 1.8654e-01, time/batch = 0.6758s	
3390/25300 (epoch 6.700), train_loss = 1.18556056, grad/param norm = 1.7696e-01, time/batch = 0.6755s	
3391/25300 (epoch 6.702), train_loss = 1.51028301, grad/param norm = 1.9724e-01, time/batch = 0.6784s	
3392/25300 (epoch 6.704), train_loss = 1.14906165, grad/param norm = 1.8315e-01, time/batch = 0.6829s	
3393/25300 (epoch 6.706), train_loss = 1.36747171, grad/param norm = 2.1868e-01, time/batch = 0.6800s	
3394/25300 (epoch 6.708), train_loss = 1.13544670, grad/param norm = 1.6802e-01, time/batch = 0.6809s	
3395/25300 (epoch 6.709), train_loss = 1.55050539, grad/param norm = 2.0218e-01, time/batch = 0.6839s	
3396/25300 (epoch 6.711), train_loss = 1.62335642, grad/param norm = 2.0839e-01, time/batch = 0.6797s	
3397/25300 (epoch 6.713), train_loss = 1.33270753, grad/param norm = 1.8827e-01, time/batch = 0.6851s	
3398/25300 (epoch 6.715), train_loss = 1.31291853, grad/param norm = 1.8550e-01, time/batch = 0.6816s	
3399/25300 (epoch 6.717), train_loss = 1.38649721, grad/param norm = 2.0544e-01, time/batch = 0.6705s	
3400/25300 (epoch 6.719), train_loss = 1.35414582, grad/param norm = 2.0151e-01, time/batch = 0.6800s	
3401/25300 (epoch 6.721), train_loss = 1.38039859, grad/param norm = 2.1323e-01, time/batch = 0.6777s	
3402/25300 (epoch 6.723), train_loss = 1.26048339, grad/param norm = 1.8946e-01, time/batch = 0.6769s	
3403/25300 (epoch 6.725), train_loss = 1.38667777, grad/param norm = 1.9944e-01, time/batch = 0.6749s	
3404/25300 (epoch 6.727), train_loss = 1.36533290, grad/param norm = 1.8430e-01, time/batch = 0.6768s	
3405/25300 (epoch 6.729), train_loss = 1.30997688, grad/param norm = 1.8843e-01, time/batch = 0.6764s	
3406/25300 (epoch 6.731), train_loss = 1.59497881, grad/param norm = 2.1097e-01, time/batch = 0.6764s	
3407/25300 (epoch 6.733), train_loss = 1.26713021, grad/param norm = 1.6350e-01, time/batch = 0.6795s	
3408/25300 (epoch 6.735), train_loss = 1.67672940, grad/param norm = 2.0862e-01, time/batch = 0.6791s	
3409/25300 (epoch 6.737), train_loss = 1.18404960, grad/param norm = 1.8171e-01, time/batch = 0.6740s	
3410/25300 (epoch 6.739), train_loss = 1.50274900, grad/param norm = 1.8920e-01, time/batch = 0.6732s	
3411/25300 (epoch 6.741), train_loss = 1.41555725, grad/param norm = 1.9292e-01, time/batch = 0.6827s	
3412/25300 (epoch 6.743), train_loss = 1.27360231, grad/param norm = 1.7570e-01, time/batch = 0.6828s	
3413/25300 (epoch 6.745), train_loss = 1.29796512, grad/param norm = 1.8338e-01, time/batch = 0.6758s	
3414/25300 (epoch 6.747), train_loss = 1.17758752, grad/param norm = 1.5132e-01, time/batch = 0.6745s	
3415/25300 (epoch 6.749), train_loss = 1.40355624, grad/param norm = 1.9701e-01, time/batch = 0.6822s	
3416/25300 (epoch 6.751), train_loss = 1.50957036, grad/param norm = 1.9402e-01, time/batch = 0.6768s	
3417/25300 (epoch 6.753), train_loss = 1.32846029, grad/param norm = 2.0075e-01, time/batch = 0.6761s	
3418/25300 (epoch 6.755), train_loss = 1.45769800, grad/param norm = 1.9840e-01, time/batch = 0.6767s	
3419/25300 (epoch 6.757), train_loss = 1.23207912, grad/param norm = 2.0123e-01, time/batch = 0.6769s	
3420/25300 (epoch 6.759), train_loss = 1.21955518, grad/param norm = 1.9627e-01, time/batch = 0.6777s	
3421/25300 (epoch 6.761), train_loss = 1.50747994, grad/param norm = 2.1059e-01, time/batch = 0.6782s	
3422/25300 (epoch 6.763), train_loss = 1.27615936, grad/param norm = 1.9473e-01, time/batch = 0.6725s	
3423/25300 (epoch 6.765), train_loss = 1.31909434, grad/param norm = 1.9361e-01, time/batch = 0.6754s	
3424/25300 (epoch 6.767), train_loss = 1.24201529, grad/param norm = 1.9528e-01, time/batch = 0.6744s	
3425/25300 (epoch 6.769), train_loss = 1.43309841, grad/param norm = 2.0667e-01, time/batch = 0.6777s	
3426/25300 (epoch 6.771), train_loss = 1.63992459, grad/param norm = 2.2218e-01, time/batch = 0.6765s	
3427/25300 (epoch 6.773), train_loss = 1.54108722, grad/param norm = 2.0259e-01, time/batch = 0.6855s	
3428/25300 (epoch 6.775), train_loss = 1.31631252, grad/param norm = 1.7152e-01, time/batch = 0.6799s	
3429/25300 (epoch 6.777), train_loss = 1.39525924, grad/param norm = 1.9120e-01, time/batch = 0.6801s	
3430/25300 (epoch 6.779), train_loss = 1.50093741, grad/param norm = 1.9644e-01, time/batch = 0.6863s	
3431/25300 (epoch 6.781), train_loss = 1.31568943, grad/param norm = 1.8086e-01, time/batch = 0.6785s	
3432/25300 (epoch 6.783), train_loss = 1.56756950, grad/param norm = 2.0649e-01, time/batch = 0.6756s	
3433/25300 (epoch 6.785), train_loss = 1.47221324, grad/param norm = 1.9654e-01, time/batch = 0.6770s	
3434/25300 (epoch 6.787), train_loss = 1.49230699, grad/param norm = 1.8747e-01, time/batch = 0.6776s	
3435/25300 (epoch 6.789), train_loss = 1.62664812, grad/param norm = 1.9187e-01, time/batch = 0.6692s	
3436/25300 (epoch 6.791), train_loss = 1.34736766, grad/param norm = 1.8738e-01, time/batch = 0.6751s	
3437/25300 (epoch 6.792), train_loss = 1.46294502, grad/param norm = 1.9326e-01, time/batch = 0.6783s	
3438/25300 (epoch 6.794), train_loss = 1.44560136, grad/param norm = 1.9478e-01, time/batch = 0.6755s	
3439/25300 (epoch 6.796), train_loss = 1.36206392, grad/param norm = 1.7288e-01, time/batch = 0.6765s	
3440/25300 (epoch 6.798), train_loss = 1.51993287, grad/param norm = 1.8735e-01, time/batch = 0.6803s	
3441/25300 (epoch 6.800), train_loss = 1.40138638, grad/param norm = 2.0923e-01, time/batch = 0.6736s	
3442/25300 (epoch 6.802), train_loss = 1.11930237, grad/param norm = 1.6731e-01, time/batch = 0.6742s	
3443/25300 (epoch 6.804), train_loss = 1.38840755, grad/param norm = 1.8364e-01, time/batch = 0.6873s	
3444/25300 (epoch 6.806), train_loss = 1.47565332, grad/param norm = 1.9690e-01, time/batch = 0.6733s	
3445/25300 (epoch 6.808), train_loss = 1.36612312, grad/param norm = 1.8110e-01, time/batch = 0.6689s	
3446/25300 (epoch 6.810), train_loss = 1.38435004, grad/param norm = 2.0278e-01, time/batch = 0.6747s	
3447/25300 (epoch 6.812), train_loss = 1.42869562, grad/param norm = 1.9350e-01, time/batch = 0.6755s	
3448/25300 (epoch 6.814), train_loss = 1.59524976, grad/param norm = 1.9797e-01, time/batch = 0.6771s	
3449/25300 (epoch 6.816), train_loss = 1.69115667, grad/param norm = 2.1226e-01, time/batch = 0.6683s	
3450/25300 (epoch 6.818), train_loss = 1.51891453, grad/param norm = 1.9727e-01, time/batch = 0.6742s	
3451/25300 (epoch 6.820), train_loss = 1.42999447, grad/param norm = 1.7604e-01, time/batch = 0.6746s	
3452/25300 (epoch 6.822), train_loss = 1.35585158, grad/param norm = 1.6790e-01, time/batch = 0.6739s	
3453/25300 (epoch 6.824), train_loss = 1.45398505, grad/param norm = 1.7055e-01, time/batch = 0.6810s	
3454/25300 (epoch 6.826), train_loss = 1.31092939, grad/param norm = 2.0073e-01, time/batch = 0.6784s	
3455/25300 (epoch 6.828), train_loss = 1.32117966, grad/param norm = 1.8864e-01, time/batch = 0.6705s	
3456/25300 (epoch 6.830), train_loss = 1.33956103, grad/param norm = 1.7509e-01, time/batch = 0.6811s	
3457/25300 (epoch 6.832), train_loss = 1.38124145, grad/param norm = 1.8080e-01, time/batch = 0.6831s	
3458/25300 (epoch 6.834), train_loss = 1.19242958, grad/param norm = 1.7033e-01, time/batch = 0.6734s	
3459/25300 (epoch 6.836), train_loss = 1.28026720, grad/param norm = 1.7466e-01, time/batch = 0.6735s	
3460/25300 (epoch 6.838), train_loss = 1.36275721, grad/param norm = 1.8839e-01, time/batch = 0.6761s	
3461/25300 (epoch 6.840), train_loss = 1.52729986, grad/param norm = 1.8220e-01, time/batch = 0.6753s	
3462/25300 (epoch 6.842), train_loss = 1.44094478, grad/param norm = 2.2722e-01, time/batch = 0.6730s	
3463/25300 (epoch 6.844), train_loss = 1.38142659, grad/param norm = 1.8025e-01, time/batch = 0.6760s	
3464/25300 (epoch 6.846), train_loss = 1.34391954, grad/param norm = 1.9001e-01, time/batch = 0.6734s	
3465/25300 (epoch 6.848), train_loss = 1.60251150, grad/param norm = 2.1495e-01, time/batch = 0.6755s	
3466/25300 (epoch 6.850), train_loss = 1.47829826, grad/param norm = 1.8740e-01, time/batch = 0.6787s	
3467/25300 (epoch 6.852), train_loss = 1.39309884, grad/param norm = 2.0453e-01, time/batch = 0.6858s	
3468/25300 (epoch 6.854), train_loss = 1.59544461, grad/param norm = 2.0981e-01, time/batch = 0.6857s	
3469/25300 (epoch 6.856), train_loss = 1.38190041, grad/param norm = 1.9525e-01, time/batch = 0.6925s	
3470/25300 (epoch 6.858), train_loss = 1.46345221, grad/param norm = 2.0894e-01, time/batch = 0.6821s	
3471/25300 (epoch 6.860), train_loss = 1.16922109, grad/param norm = 1.9720e-01, time/batch = 0.6780s	
3472/25300 (epoch 6.862), train_loss = 1.48695734, grad/param norm = 2.2219e-01, time/batch = 0.6744s	
3473/25300 (epoch 6.864), train_loss = 1.51248233, grad/param norm = 1.9318e-01, time/batch = 0.6733s	
3474/25300 (epoch 6.866), train_loss = 1.49210263, grad/param norm = 2.1575e-01, time/batch = 0.6750s	
3475/25300 (epoch 6.868), train_loss = 1.55467699, grad/param norm = 2.2666e-01, time/batch = 0.6760s	
3476/25300 (epoch 6.870), train_loss = 1.48785948, grad/param norm = 1.9265e-01, time/batch = 0.6710s	
3477/25300 (epoch 6.872), train_loss = 1.48021494, grad/param norm = 2.1068e-01, time/batch = 0.6744s	
3478/25300 (epoch 6.874), train_loss = 1.48166866, grad/param norm = 2.0987e-01, time/batch = 0.6721s	
3479/25300 (epoch 6.875), train_loss = 1.36813447, grad/param norm = 1.8116e-01, time/batch = 0.6937s	
3480/25300 (epoch 6.877), train_loss = 1.27829203, grad/param norm = 1.7632e-01, time/batch = 0.6902s	
3481/25300 (epoch 6.879), train_loss = 1.43502299, grad/param norm = 1.9224e-01, time/batch = 0.6768s	
3482/25300 (epoch 6.881), train_loss = 1.74084530, grad/param norm = 2.1687e-01, time/batch = 0.6822s	
3483/25300 (epoch 6.883), train_loss = 1.64595501, grad/param norm = 1.8909e-01, time/batch = 0.6768s	
3484/25300 (epoch 6.885), train_loss = 1.55002792, grad/param norm = 2.0923e-01, time/batch = 0.6775s	
3485/25300 (epoch 6.887), train_loss = 1.38500874, grad/param norm = 1.7977e-01, time/batch = 0.6823s	
3486/25300 (epoch 6.889), train_loss = 1.60382159, grad/param norm = 2.0012e-01, time/batch = 0.6785s	
3487/25300 (epoch 6.891), train_loss = 1.58550983, grad/param norm = 2.4048e-01, time/batch = 0.6780s	
3488/25300 (epoch 6.893), train_loss = 1.66481165, grad/param norm = 2.0730e-01, time/batch = 0.6795s	
3489/25300 (epoch 6.895), train_loss = 1.14566078, grad/param norm = 1.9497e-01, time/batch = 0.6777s	
3490/25300 (epoch 6.897), train_loss = 1.29022061, grad/param norm = 1.8123e-01, time/batch = 0.6857s	
3491/25300 (epoch 6.899), train_loss = 1.38526587, grad/param norm = 1.9529e-01, time/batch = 0.6869s	
3492/25300 (epoch 6.901), train_loss = 1.49157816, grad/param norm = 2.1203e-01, time/batch = 0.6782s	
3493/25300 (epoch 6.903), train_loss = 1.20150516, grad/param norm = 1.6244e-01, time/batch = 0.6778s	
3494/25300 (epoch 6.905), train_loss = 1.31342333, grad/param norm = 1.7960e-01, time/batch = 0.6820s	
3495/25300 (epoch 6.907), train_loss = 1.48853214, grad/param norm = 2.1563e-01, time/batch = 0.6750s	
3496/25300 (epoch 6.909), train_loss = 1.50814348, grad/param norm = 1.8328e-01, time/batch = 0.6755s	
3497/25300 (epoch 6.911), train_loss = 1.62957216, grad/param norm = 2.0264e-01, time/batch = 0.6783s	
3498/25300 (epoch 6.913), train_loss = 1.60627703, grad/param norm = 2.1590e-01, time/batch = 0.6740s	
3499/25300 (epoch 6.915), train_loss = 1.33947946, grad/param norm = 1.9981e-01, time/batch = 0.6746s	
3500/25300 (epoch 6.917), train_loss = 1.47554239, grad/param norm = 2.0336e-01, time/batch = 0.6759s	
3501/25300 (epoch 6.919), train_loss = 1.55563516, grad/param norm = 2.1664e-01, time/batch = 0.6762s	
3502/25300 (epoch 6.921), train_loss = 1.30647299, grad/param norm = 2.0593e-01, time/batch = 0.6725s	
3503/25300 (epoch 6.923), train_loss = 1.54544033, grad/param norm = 1.7501e-01, time/batch = 0.6723s	
3504/25300 (epoch 6.925), train_loss = 1.42727425, grad/param norm = 1.8083e-01, time/batch = 0.6759s	
3505/25300 (epoch 6.927), train_loss = 1.39602038, grad/param norm = 1.8844e-01, time/batch = 0.6724s	
3506/25300 (epoch 6.929), train_loss = 1.32150630, grad/param norm = 1.8315e-01, time/batch = 0.6813s	
3507/25300 (epoch 6.931), train_loss = 1.54988019, grad/param norm = 1.9581e-01, time/batch = 0.6729s	
3508/25300 (epoch 6.933), train_loss = 1.44526537, grad/param norm = 1.8922e-01, time/batch = 0.6698s	
3509/25300 (epoch 6.935), train_loss = 1.39390425, grad/param norm = 1.7878e-01, time/batch = 0.6696s	
3510/25300 (epoch 6.937), train_loss = 1.11913334, grad/param norm = 1.5424e-01, time/batch = 0.6734s	
3511/25300 (epoch 6.939), train_loss = 1.49666992, grad/param norm = 1.8253e-01, time/batch = 0.6769s	
3512/25300 (epoch 6.941), train_loss = 1.34791390, grad/param norm = 1.7675e-01, time/batch = 0.6733s	
3513/25300 (epoch 6.943), train_loss = 1.27525882, grad/param norm = 1.6310e-01, time/batch = 0.6701s	
3514/25300 (epoch 6.945), train_loss = 1.42030648, grad/param norm = 1.9195e-01, time/batch = 0.6744s	
3515/25300 (epoch 6.947), train_loss = 1.32411397, grad/param norm = 1.9913e-01, time/batch = 0.6749s	
3516/25300 (epoch 6.949), train_loss = 1.50771443, grad/param norm = 2.0359e-01, time/batch = 0.6818s	
3517/25300 (epoch 6.951), train_loss = 1.41347260, grad/param norm = 1.7980e-01, time/batch = 0.6842s	
3518/25300 (epoch 6.953), train_loss = 1.50478420, grad/param norm = 1.8433e-01, time/batch = 0.6701s	
3519/25300 (epoch 6.955), train_loss = 1.66058572, grad/param norm = 2.1032e-01, time/batch = 0.6774s	
3520/25300 (epoch 6.957), train_loss = 1.61403707, grad/param norm = 2.0346e-01, time/batch = 0.6909s	
3521/25300 (epoch 6.958), train_loss = 1.45085247, grad/param norm = 2.0506e-01, time/batch = 0.6784s	
3522/25300 (epoch 6.960), train_loss = 1.62276084, grad/param norm = 1.9869e-01, time/batch = 0.6768s	
3523/25300 (epoch 6.962), train_loss = 1.53020297, grad/param norm = 2.1111e-01, time/batch = 0.6770s	
3524/25300 (epoch 6.964), train_loss = 1.46145788, grad/param norm = 1.6959e-01, time/batch = 0.6779s	
3525/25300 (epoch 6.966), train_loss = 1.22510500, grad/param norm = 1.6637e-01, time/batch = 0.6770s	
3526/25300 (epoch 6.968), train_loss = 1.22091555, grad/param norm = 1.7166e-01, time/batch = 0.6752s	
3527/25300 (epoch 6.970), train_loss = 1.47073089, grad/param norm = 2.2598e-01, time/batch = 0.6775s	
3528/25300 (epoch 6.972), train_loss = 1.40281470, grad/param norm = 1.8665e-01, time/batch = 0.6793s	
3529/25300 (epoch 6.974), train_loss = 1.63572882, grad/param norm = 2.2285e-01, time/batch = 0.6765s	
3530/25300 (epoch 6.976), train_loss = 1.43393653, grad/param norm = 1.9085e-01, time/batch = 0.6823s	
3531/25300 (epoch 6.978), train_loss = 1.44558092, grad/param norm = 1.8389e-01, time/batch = 0.6856s	
3532/25300 (epoch 6.980), train_loss = 1.48989534, grad/param norm = 2.0124e-01, time/batch = 0.6867s	
3533/25300 (epoch 6.982), train_loss = 1.38950453, grad/param norm = 1.8233e-01, time/batch = 0.6779s	
3534/25300 (epoch 6.984), train_loss = 1.39340174, grad/param norm = 1.7897e-01, time/batch = 0.6730s	
3535/25300 (epoch 6.986), train_loss = 1.43399428, grad/param norm = 2.0364e-01, time/batch = 0.6754s	
3536/25300 (epoch 6.988), train_loss = 1.43518822, grad/param norm = 1.8492e-01, time/batch = 0.6737s	
3537/25300 (epoch 6.990), train_loss = 1.40849337, grad/param norm = 1.8048e-01, time/batch = 0.6752s	
3538/25300 (epoch 6.992), train_loss = 1.11367461, grad/param norm = 1.7993e-01, time/batch = 0.6719s	
3539/25300 (epoch 6.994), train_loss = 1.43962967, grad/param norm = 1.9051e-01, time/batch = 0.6725s	
3540/25300 (epoch 6.996), train_loss = 1.55077328, grad/param norm = 2.1083e-01, time/batch = 0.6755s	
3541/25300 (epoch 6.998), train_loss = 1.54574617, grad/param norm = 1.9024e-01, time/batch = 0.6772s	
3542/25300 (epoch 7.000), train_loss = 1.39682001, grad/param norm = 2.0037e-01, time/batch = 0.6853s	
3543/25300 (epoch 7.002), train_loss = 1.24004734, grad/param norm = 1.6395e-01, time/batch = 0.6765s	
3544/25300 (epoch 7.004), train_loss = 1.17360851, grad/param norm = 1.8307e-01, time/batch = 0.6725s	
3545/25300 (epoch 7.006), train_loss = 1.44050642, grad/param norm = 1.8025e-01, time/batch = 0.6754s	
3546/25300 (epoch 7.008), train_loss = 1.41458105, grad/param norm = 1.9309e-01, time/batch = 0.6872s	
3547/25300 (epoch 7.010), train_loss = 1.45824050, grad/param norm = 1.8420e-01, time/batch = 0.6740s	
3548/25300 (epoch 7.012), train_loss = 1.25870533, grad/param norm = 1.8980e-01, time/batch = 0.6735s	
3549/25300 (epoch 7.014), train_loss = 1.48697407, grad/param norm = 1.9785e-01, time/batch = 0.6763s	
3550/25300 (epoch 7.016), train_loss = 1.44674077, grad/param norm = 2.0901e-01, time/batch = 0.6724s	
3551/25300 (epoch 7.018), train_loss = 1.29341443, grad/param norm = 1.8862e-01, time/batch = 0.6761s	
3552/25300 (epoch 7.020), train_loss = 1.32932316, grad/param norm = 1.7807e-01, time/batch = 0.6766s	
3553/25300 (epoch 7.022), train_loss = 1.40891796, grad/param norm = 2.0176e-01, time/batch = 0.6761s	
3554/25300 (epoch 7.024), train_loss = 1.08323132, grad/param norm = 1.6618e-01, time/batch = 0.6761s	
3555/25300 (epoch 7.026), train_loss = 1.33615151, grad/param norm = 2.1176e-01, time/batch = 0.6801s	
3556/25300 (epoch 7.028), train_loss = 1.20083232, grad/param norm = 1.7116e-01, time/batch = 0.6862s	
3557/25300 (epoch 7.030), train_loss = 1.45609955, grad/param norm = 1.9109e-01, time/batch = 0.7051s	
3558/25300 (epoch 7.032), train_loss = 1.33091609, grad/param norm = 1.7838e-01, time/batch = 0.6932s	
3559/25300 (epoch 7.034), train_loss = 1.14570329, grad/param norm = 1.8462e-01, time/batch = 0.6842s	
3560/25300 (epoch 7.036), train_loss = 1.19316404, grad/param norm = 1.7298e-01, time/batch = 0.6884s	
3561/25300 (epoch 7.038), train_loss = 1.04678205, grad/param norm = 1.5069e-01, time/batch = 0.6915s	
3562/25300 (epoch 7.040), train_loss = 1.44886424, grad/param norm = 1.8203e-01, time/batch = 0.6920s	
3563/25300 (epoch 7.042), train_loss = 1.18041349, grad/param norm = 1.5976e-01, time/batch = 0.6761s	
3564/25300 (epoch 7.043), train_loss = 1.13934002, grad/param norm = 1.6313e-01, time/batch = 0.6783s	
3565/25300 (epoch 7.045), train_loss = 1.16740304, grad/param norm = 1.7033e-01, time/batch = 0.6858s	
3566/25300 (epoch 7.047), train_loss = 1.44621915, grad/param norm = 1.7814e-01, time/batch = 0.6813s	
3567/25300 (epoch 7.049), train_loss = 1.42162540, grad/param norm = 2.0482e-01, time/batch = 0.6929s	
3568/25300 (epoch 7.051), train_loss = 1.49904123, grad/param norm = 2.0591e-01, time/batch = 0.6865s	
3569/25300 (epoch 7.053), train_loss = 1.17077755, grad/param norm = 1.7416e-01, time/batch = 0.6772s	
3570/25300 (epoch 7.055), train_loss = 1.15841322, grad/param norm = 1.6107e-01, time/batch = 0.6773s	
3571/25300 (epoch 7.057), train_loss = 1.13555949, grad/param norm = 1.6043e-01, time/batch = 0.6771s	
3572/25300 (epoch 7.059), train_loss = 1.37517314, grad/param norm = 1.8777e-01, time/batch = 0.6732s	
3573/25300 (epoch 7.061), train_loss = 1.27082243, grad/param norm = 1.8658e-01, time/batch = 0.6739s	
3574/25300 (epoch 7.063), train_loss = 1.26894833, grad/param norm = 1.6665e-01, time/batch = 0.6792s	
3575/25300 (epoch 7.065), train_loss = 1.49870369, grad/param norm = 2.1315e-01, time/batch = 0.6750s	
3576/25300 (epoch 7.067), train_loss = 1.48700366, grad/param norm = 1.8883e-01, time/batch = 0.6816s	
3577/25300 (epoch 7.069), train_loss = 1.37344894, grad/param norm = 1.8146e-01, time/batch = 0.6830s	
3578/25300 (epoch 7.071), train_loss = 1.48833125, grad/param norm = 1.8312e-01, time/batch = 0.6792s	
3579/25300 (epoch 7.073), train_loss = 1.31603433, grad/param norm = 1.7286e-01, time/batch = 0.6737s	
3580/25300 (epoch 7.075), train_loss = 1.34028786, grad/param norm = 1.6683e-01, time/batch = 0.6731s	
3581/25300 (epoch 7.077), train_loss = 1.45575637, grad/param norm = 1.9477e-01, time/batch = 0.6778s	
3582/25300 (epoch 7.079), train_loss = 1.41099453, grad/param norm = 1.8470e-01, time/batch = 0.6812s	
3583/25300 (epoch 7.081), train_loss = 1.32414221, grad/param norm = 1.7651e-01, time/batch = 0.6761s	
3584/25300 (epoch 7.083), train_loss = 1.25439027, grad/param norm = 1.8076e-01, time/batch = 0.6765s	
3585/25300 (epoch 7.085), train_loss = 1.59615425, grad/param norm = 2.0570e-01, time/batch = 0.6785s	
3586/25300 (epoch 7.087), train_loss = 1.35599574, grad/param norm = 1.9866e-01, time/batch = 0.6764s	
3587/25300 (epoch 7.089), train_loss = 1.38930607, grad/param norm = 1.8195e-01, time/batch = 0.6757s	
3588/25300 (epoch 7.091), train_loss = 1.48598463, grad/param norm = 1.9072e-01, time/batch = 0.6767s	
3589/25300 (epoch 7.093), train_loss = 1.56904779, grad/param norm = 2.0259e-01, time/batch = 0.6763s	
3590/25300 (epoch 7.095), train_loss = 1.42016261, grad/param norm = 1.7733e-01, time/batch = 0.6751s	
3591/25300 (epoch 7.097), train_loss = 1.39895434, grad/param norm = 1.8717e-01, time/batch = 0.6760s	
3592/25300 (epoch 7.099), train_loss = 1.40216854, grad/param norm = 1.9592e-01, time/batch = 0.6772s	
3593/25300 (epoch 7.101), train_loss = 1.34234250, grad/param norm = 1.8440e-01, time/batch = 0.6758s	
3594/25300 (epoch 7.103), train_loss = 1.31453137, grad/param norm = 1.7693e-01, time/batch = 0.6750s	
3595/25300 (epoch 7.105), train_loss = 1.41152218, grad/param norm = 1.8806e-01, time/batch = 0.6770s	
3596/25300 (epoch 7.107), train_loss = 1.50300076, grad/param norm = 2.0618e-01, time/batch = 0.6889s	
3597/25300 (epoch 7.109), train_loss = 1.42893747, grad/param norm = 1.9847e-01, time/batch = 0.6886s	
3598/25300 (epoch 7.111), train_loss = 1.30488316, grad/param norm = 1.7139e-01, time/batch = 0.6832s	
3599/25300 (epoch 7.113), train_loss = 1.36468092, grad/param norm = 1.7551e-01, time/batch = 0.6817s	
3600/25300 (epoch 7.115), train_loss = 1.34213915, grad/param norm = 1.6447e-01, time/batch = 0.6874s	
3601/25300 (epoch 7.117), train_loss = 1.44310104, grad/param norm = 1.7732e-01, time/batch = 0.6920s	
3602/25300 (epoch 7.119), train_loss = 1.34682117, grad/param norm = 1.8965e-01, time/batch = 0.6980s	
3603/25300 (epoch 7.121), train_loss = 1.51402739, grad/param norm = 2.0679e-01, time/batch = 0.6977s	
3604/25300 (epoch 7.123), train_loss = 1.35338528, grad/param norm = 1.8376e-01, time/batch = 0.7010s	
3605/25300 (epoch 7.125), train_loss = 1.49373287, grad/param norm = 1.9640e-01, time/batch = 0.6977s	
3606/25300 (epoch 7.126), train_loss = 1.38700522, grad/param norm = 1.9489e-01, time/batch = 0.6876s	
3607/25300 (epoch 7.128), train_loss = 1.39412170, grad/param norm = 1.8249e-01, time/batch = 0.6800s	
3608/25300 (epoch 7.130), train_loss = 1.07295190, grad/param norm = 1.5449e-01, time/batch = 0.6832s	
3609/25300 (epoch 7.132), train_loss = 1.22634254, grad/param norm = 1.6921e-01, time/batch = 0.6736s	
3610/25300 (epoch 7.134), train_loss = 1.08736376, grad/param norm = 1.6565e-01, time/batch = 0.6737s	
3611/25300 (epoch 7.136), train_loss = 1.41180441, grad/param norm = 1.8770e-01, time/batch = 0.6766s	
3612/25300 (epoch 7.138), train_loss = 1.22545529, grad/param norm = 1.7756e-01, time/batch = 0.6878s	
3613/25300 (epoch 7.140), train_loss = 1.24815166, grad/param norm = 1.7333e-01, time/batch = 0.6844s	
3614/25300 (epoch 7.142), train_loss = 1.45904509, grad/param norm = 1.8756e-01, time/batch = 0.6818s	
3615/25300 (epoch 7.144), train_loss = 1.37902880, grad/param norm = 1.9659e-01, time/batch = 0.6786s	
3616/25300 (epoch 7.146), train_loss = 1.51519929, grad/param norm = 2.0073e-01, time/batch = 0.6805s	
3617/25300 (epoch 7.148), train_loss = 1.40985857, grad/param norm = 1.8104e-01, time/batch = 0.6733s	
3618/25300 (epoch 7.150), train_loss = 1.51174992, grad/param norm = 2.1548e-01, time/batch = 0.6765s	
3619/25300 (epoch 7.152), train_loss = 1.65477758, grad/param norm = 2.0792e-01, time/batch = 0.6734s	
3620/25300 (epoch 7.154), train_loss = 1.27441720, grad/param norm = 1.9460e-01, time/batch = 0.6770s	
3621/25300 (epoch 7.156), train_loss = 1.40617728, grad/param norm = 1.8560e-01, time/batch = 0.6842s	
3622/25300 (epoch 7.158), train_loss = 1.32236172, grad/param norm = 1.8742e-01, time/batch = 0.6776s	
3623/25300 (epoch 7.160), train_loss = 1.38088762, grad/param norm = 1.8688e-01, time/batch = 0.6761s	
3624/25300 (epoch 7.162), train_loss = 1.31823463, grad/param norm = 2.0228e-01, time/batch = 0.6773s	
3625/25300 (epoch 7.164), train_loss = 1.41822231, grad/param norm = 1.8820e-01, time/batch = 0.6745s	
3626/25300 (epoch 7.166), train_loss = 1.40882893, grad/param norm = 1.9160e-01, time/batch = 0.6756s	
3627/25300 (epoch 7.168), train_loss = 1.18829131, grad/param norm = 1.5490e-01, time/batch = 0.6709s	
3628/25300 (epoch 7.170), train_loss = 1.26368366, grad/param norm = 1.7456e-01, time/batch = 0.6797s	
3629/25300 (epoch 7.172), train_loss = 1.25379341, grad/param norm = 1.8090e-01, time/batch = 0.6832s	
3630/25300 (epoch 7.174), train_loss = 1.23840871, grad/param norm = 1.7518e-01, time/batch = 0.6818s	
3631/25300 (epoch 7.176), train_loss = 1.32896278, grad/param norm = 1.8900e-01, time/batch = 0.6765s	
3632/25300 (epoch 7.178), train_loss = 1.52915910, grad/param norm = 1.9450e-01, time/batch = 0.6758s	
3633/25300 (epoch 7.180), train_loss = 1.13040179, grad/param norm = 1.8114e-01, time/batch = 0.6740s	
3634/25300 (epoch 7.182), train_loss = 1.29304963, grad/param norm = 1.7384e-01, time/batch = 0.6723s	
3635/25300 (epoch 7.184), train_loss = 1.33830109, grad/param norm = 1.7904e-01, time/batch = 0.6696s	
3636/25300 (epoch 7.186), train_loss = 1.32569525, grad/param norm = 1.8517e-01, time/batch = 0.6740s	
3637/25300 (epoch 7.188), train_loss = 1.31645875, grad/param norm = 1.8397e-01, time/batch = 0.6743s	
3638/25300 (epoch 7.190), train_loss = 1.42842351, grad/param norm = 1.9945e-01, time/batch = 0.6741s	
3639/25300 (epoch 7.192), train_loss = 1.35638950, grad/param norm = 1.9207e-01, time/batch = 0.6742s	
3640/25300 (epoch 7.194), train_loss = 1.34924521, grad/param norm = 1.8263e-01, time/batch = 0.6720s	
3641/25300 (epoch 7.196), train_loss = 1.46084961, grad/param norm = 2.1784e-01, time/batch = 0.6761s	
3642/25300 (epoch 7.198), train_loss = 1.30875465, grad/param norm = 1.9838e-01, time/batch = 0.6754s	
3643/25300 (epoch 7.200), train_loss = 1.41966442, grad/param norm = 2.0318e-01, time/batch = 0.6845s	
3644/25300 (epoch 7.202), train_loss = 1.42047878, grad/param norm = 1.9723e-01, time/batch = 0.6861s	
3645/25300 (epoch 7.204), train_loss = 1.33126513, grad/param norm = 1.7930e-01, time/batch = 0.6850s	
3646/25300 (epoch 7.206), train_loss = 1.41232345, grad/param norm = 2.0157e-01, time/batch = 0.6767s	
3647/25300 (epoch 7.208), train_loss = 1.22724185, grad/param norm = 1.9921e-01, time/batch = 0.6780s	
3648/25300 (epoch 7.209), train_loss = 1.11902838, grad/param norm = 1.6120e-01, time/batch = 0.6741s	
3649/25300 (epoch 7.211), train_loss = 1.33350543, grad/param norm = 1.7870e-01, time/batch = 0.6819s	
3650/25300 (epoch 7.213), train_loss = 1.41556579, grad/param norm = 2.0456e-01, time/batch = 0.6834s	
3651/25300 (epoch 7.215), train_loss = 1.37307561, grad/param norm = 2.0526e-01, time/batch = 0.6804s	
3652/25300 (epoch 7.217), train_loss = 1.44318622, grad/param norm = 2.1088e-01, time/batch = 0.6774s	
3653/25300 (epoch 7.219), train_loss = 1.40992655, grad/param norm = 1.9104e-01, time/batch = 0.6801s	
3654/25300 (epoch 7.221), train_loss = 1.49100438, grad/param norm = 1.9830e-01, time/batch = 0.6758s	
3655/25300 (epoch 7.223), train_loss = 1.46795095, grad/param norm = 2.0212e-01, time/batch = 0.6768s	
3656/25300 (epoch 7.225), train_loss = 1.89277211, grad/param norm = 2.3725e-01, time/batch = 0.6747s	
3657/25300 (epoch 7.227), train_loss = 1.46069823, grad/param norm = 1.8986e-01, time/batch = 0.6709s	
3658/25300 (epoch 7.229), train_loss = 1.43450184, grad/param norm = 2.0459e-01, time/batch = 0.6749s	
3659/25300 (epoch 7.231), train_loss = 1.39150269, grad/param norm = 1.8539e-01, time/batch = 0.6746s	
3660/25300 (epoch 7.233), train_loss = 1.40561721, grad/param norm = 1.7971e-01, time/batch = 0.6692s	
3661/25300 (epoch 7.235), train_loss = 1.35824097, grad/param norm = 1.8161e-01, time/batch = 0.6766s	
3662/25300 (epoch 7.237), train_loss = 1.52543669, grad/param norm = 2.0005e-01, time/batch = 0.6761s	
3663/25300 (epoch 7.239), train_loss = 1.40396070, grad/param norm = 1.9772e-01, time/batch = 0.6805s	
3664/25300 (epoch 7.241), train_loss = 1.45953808, grad/param norm = 1.9490e-01, time/batch = 0.6786s	
3665/25300 (epoch 7.243), train_loss = 1.73631973, grad/param norm = 2.1215e-01, time/batch = 0.6839s	
3666/25300 (epoch 7.245), train_loss = 1.28901313, grad/param norm = 1.8830e-01, time/batch = 0.6855s	
3667/25300 (epoch 7.247), train_loss = 1.52899914, grad/param norm = 1.9210e-01, time/batch = 0.6760s	
3668/25300 (epoch 7.249), train_loss = 1.20987174, grad/param norm = 1.7803e-01, time/batch = 0.6761s	
3669/25300 (epoch 7.251), train_loss = 1.18271442, grad/param norm = 1.8042e-01, time/batch = 0.6755s	
3670/25300 (epoch 7.253), train_loss = 1.34461824, grad/param norm = 1.8089e-01, time/batch = 0.6757s	
3671/25300 (epoch 7.255), train_loss = 1.30616662, grad/param norm = 1.7934e-01, time/batch = 0.6732s	
3672/25300 (epoch 7.257), train_loss = 1.49453628, grad/param norm = 1.9839e-01, time/batch = 0.6792s	
3673/25300 (epoch 7.259), train_loss = 1.65979116, grad/param norm = 2.1205e-01, time/batch = 0.6782s	
3674/25300 (epoch 7.261), train_loss = 1.54007333, grad/param norm = 2.0601e-01, time/batch = 0.6804s	
3675/25300 (epoch 7.263), train_loss = 1.48730385, grad/param norm = 1.8375e-01, time/batch = 0.6761s	
3676/25300 (epoch 7.265), train_loss = 1.56474755, grad/param norm = 1.9208e-01, time/batch = 0.6736s	
3677/25300 (epoch 7.267), train_loss = 1.49750941, grad/param norm = 1.6897e-01, time/batch = 0.6760s	
3678/25300 (epoch 7.269), train_loss = 1.20844272, grad/param norm = 1.7322e-01, time/batch = 0.6746s	
3679/25300 (epoch 7.271), train_loss = 1.27229996, grad/param norm = 1.8973e-01, time/batch = 0.6763s	
3680/25300 (epoch 7.273), train_loss = 1.43989965, grad/param norm = 1.8884e-01, time/batch = 0.6768s	
3681/25300 (epoch 7.275), train_loss = 1.22471119, grad/param norm = 1.7106e-01, time/batch = 0.6775s	
3682/25300 (epoch 7.277), train_loss = 1.34874885, grad/param norm = 1.7935e-01, time/batch = 0.6741s	
3683/25300 (epoch 7.279), train_loss = 1.39472869, grad/param norm = 1.9153e-01, time/batch = 0.6769s	
3684/25300 (epoch 7.281), train_loss = 1.54605294, grad/param norm = 2.1277e-01, time/batch = 0.6765s	
3685/25300 (epoch 7.283), train_loss = 1.27317443, grad/param norm = 1.9053e-01, time/batch = 0.6724s	
3686/25300 (epoch 7.285), train_loss = 1.38513093, grad/param norm = 1.9894e-01, time/batch = 0.6737s	
3687/25300 (epoch 7.287), train_loss = 1.36653190, grad/param norm = 1.8595e-01, time/batch = 0.6735s	
3688/25300 (epoch 7.289), train_loss = 1.31003072, grad/param norm = 1.7687e-01, time/batch = 0.6755s	
3689/25300 (epoch 7.291), train_loss = 1.27920083, grad/param norm = 1.9420e-01, time/batch = 0.6767s	
3690/25300 (epoch 7.292), train_loss = 1.48223405, grad/param norm = 1.9586e-01, time/batch = 0.6745s	
3691/25300 (epoch 7.294), train_loss = 1.39192352, grad/param norm = 1.8677e-01, time/batch = 0.6758s	
3692/25300 (epoch 7.296), train_loss = 1.23106136, grad/param norm = 1.8891e-01, time/batch = 0.6764s	
3693/25300 (epoch 7.298), train_loss = 1.46122977, grad/param norm = 1.9231e-01, time/batch = 0.6735s	
3694/25300 (epoch 7.300), train_loss = 1.61335752, grad/param norm = 2.3491e-01, time/batch = 0.6781s	
3695/25300 (epoch 7.302), train_loss = 1.20433177, grad/param norm = 1.8506e-01, time/batch = 0.6766s	
3696/25300 (epoch 7.304), train_loss = 1.40513496, grad/param norm = 1.9637e-01, time/batch = 0.6940s	
3697/25300 (epoch 7.306), train_loss = 1.10418069, grad/param norm = 1.6812e-01, time/batch = 0.6840s	
3698/25300 (epoch 7.308), train_loss = 1.40975657, grad/param norm = 1.6514e-01, time/batch = 0.6860s	
3699/25300 (epoch 7.310), train_loss = 1.30948385, grad/param norm = 1.9427e-01, time/batch = 0.6790s	
3700/25300 (epoch 7.312), train_loss = 1.36448706, grad/param norm = 1.8775e-01, time/batch = 0.6776s	
3701/25300 (epoch 7.314), train_loss = 1.11634931, grad/param norm = 1.7689e-01, time/batch = 0.6833s	
3702/25300 (epoch 7.316), train_loss = 1.39319777, grad/param norm = 1.7414e-01, time/batch = 0.6783s	
3703/25300 (epoch 7.318), train_loss = 1.08128075, grad/param norm = 1.6822e-01, time/batch = 0.6755s	
3704/25300 (epoch 7.320), train_loss = 1.24403616, grad/param norm = 1.8179e-01, time/batch = 0.6769s	
3705/25300 (epoch 7.322), train_loss = 1.66473030, grad/param norm = 2.0691e-01, time/batch = 0.6744s	
3706/25300 (epoch 7.324), train_loss = 1.24085115, grad/param norm = 1.7978e-01, time/batch = 0.6757s	
3707/25300 (epoch 7.326), train_loss = 1.10454792, grad/param norm = 1.5568e-01, time/batch = 0.6831s	
3708/25300 (epoch 7.328), train_loss = 1.14134594, grad/param norm = 1.6931e-01, time/batch = 0.6789s	
3709/25300 (epoch 7.330), train_loss = 1.29000926, grad/param norm = 1.8355e-01, time/batch = 0.6788s	
3710/25300 (epoch 7.332), train_loss = 1.39825143, grad/param norm = 1.6839e-01, time/batch = 0.6763s	
3711/25300 (epoch 7.334), train_loss = 1.22820466, grad/param norm = 1.6034e-01, time/batch = 0.6764s	
3712/25300 (epoch 7.336), train_loss = 1.18674835, grad/param norm = 1.8660e-01, time/batch = 0.6757s	
3713/25300 (epoch 7.338), train_loss = 1.19452596, grad/param norm = 1.8712e-01, time/batch = 0.6786s	
3714/25300 (epoch 7.340), train_loss = 1.29063539, grad/param norm = 1.9026e-01, time/batch = 0.6788s	
3715/25300 (epoch 7.342), train_loss = 1.29212656, grad/param norm = 1.8960e-01, time/batch = 0.6741s	
3716/25300 (epoch 7.344), train_loss = 1.30593874, grad/param norm = 1.8577e-01, time/batch = 0.6769s	
3717/25300 (epoch 7.346), train_loss = 1.32668549, grad/param norm = 1.9054e-01, time/batch = 0.6783s	
3718/25300 (epoch 7.348), train_loss = 1.16263856, grad/param norm = 1.5592e-01, time/batch = 0.6768s	
3719/25300 (epoch 7.350), train_loss = 1.29703681, grad/param norm = 1.8026e-01, time/batch = 0.6759s	
3720/25300 (epoch 7.352), train_loss = 1.35013877, grad/param norm = 1.8031e-01, time/batch = 0.6767s	
3721/25300 (epoch 7.354), train_loss = 1.32341187, grad/param norm = 2.0278e-01, time/batch = 0.6805s	
3722/25300 (epoch 7.356), train_loss = 1.38644584, grad/param norm = 1.9963e-01, time/batch = 0.6743s	
3723/25300 (epoch 7.358), train_loss = 1.46143670, grad/param norm = 2.0455e-01, time/batch = 0.6765s	
3724/25300 (epoch 7.360), train_loss = 1.24593442, grad/param norm = 1.9613e-01, time/batch = 0.6774s	
3725/25300 (epoch 7.362), train_loss = 1.37455252, grad/param norm = 1.9250e-01, time/batch = 0.6745s	
3726/25300 (epoch 7.364), train_loss = 1.45995750, grad/param norm = 2.0697e-01, time/batch = 0.6706s	
3727/25300 (epoch 7.366), train_loss = 1.19706927, grad/param norm = 1.7344e-01, time/batch = 0.6702s	
3728/25300 (epoch 7.368), train_loss = 1.33061475, grad/param norm = 1.6789e-01, time/batch = 0.6712s	
3729/25300 (epoch 7.370), train_loss = 1.36318787, grad/param norm = 2.1330e-01, time/batch = 0.6699s	
3730/25300 (epoch 7.372), train_loss = 1.31063716, grad/param norm = 1.8637e-01, time/batch = 0.6686s	
3731/25300 (epoch 7.374), train_loss = 1.24281950, grad/param norm = 1.8321e-01, time/batch = 0.6805s	
3732/25300 (epoch 7.375), train_loss = 1.58472020, grad/param norm = 2.0466e-01, time/batch = 0.6857s	
3733/25300 (epoch 7.377), train_loss = 1.33853575, grad/param norm = 1.8522e-01, time/batch = 0.6876s	
3734/25300 (epoch 7.379), train_loss = 1.56885651, grad/param norm = 2.0708e-01, time/batch = 0.6732s	
3735/25300 (epoch 7.381), train_loss = 1.33351781, grad/param norm = 1.6911e-01, time/batch = 0.6736s	
3736/25300 (epoch 7.383), train_loss = 1.21351150, grad/param norm = 1.7005e-01, time/batch = 0.6733s	
3737/25300 (epoch 7.385), train_loss = 1.27350439, grad/param norm = 1.7983e-01, time/batch = 0.6850s	
3738/25300 (epoch 7.387), train_loss = 1.44794878, grad/param norm = 2.1128e-01, time/batch = 0.6832s	
3739/25300 (epoch 7.389), train_loss = 1.54149187, grad/param norm = 2.0815e-01, time/batch = 0.6747s	
3740/25300 (epoch 7.391), train_loss = 1.19696505, grad/param norm = 1.6824e-01, time/batch = 0.6824s	
3741/25300 (epoch 7.393), train_loss = 1.42118165, grad/param norm = 1.8746e-01, time/batch = 0.6948s	
3742/25300 (epoch 7.395), train_loss = 1.15671258, grad/param norm = 1.7190e-01, time/batch = 0.6856s	
3743/25300 (epoch 7.397), train_loss = 1.22069530, grad/param norm = 1.8856e-01, time/batch = 0.6825s	
3744/25300 (epoch 7.399), train_loss = 1.19314537, grad/param norm = 1.6819e-01, time/batch = 0.6693s	
3745/25300 (epoch 7.401), train_loss = 1.47879406, grad/param norm = 2.0172e-01, time/batch = 0.6754s	
3746/25300 (epoch 7.403), train_loss = 1.36995287, grad/param norm = 2.0882e-01, time/batch = 0.6788s	
3747/25300 (epoch 7.405), train_loss = 1.40308485, grad/param norm = 2.0217e-01, time/batch = 0.6780s	
3748/25300 (epoch 7.407), train_loss = 1.24693706, grad/param norm = 1.8139e-01, time/batch = 0.6764s	
3749/25300 (epoch 7.409), train_loss = 1.24785166, grad/param norm = 1.6750e-01, time/batch = 0.6765s	
3750/25300 (epoch 7.411), train_loss = 1.32816251, grad/param norm = 1.8280e-01, time/batch = 0.6727s	
3751/25300 (epoch 7.413), train_loss = 1.21150460, grad/param norm = 1.6815e-01, time/batch = 0.6772s	
3752/25300 (epoch 7.415), train_loss = 1.20601235, grad/param norm = 1.7636e-01, time/batch = 0.6746s	
3753/25300 (epoch 7.417), train_loss = 1.18200520, grad/param norm = 1.7417e-01, time/batch = 0.6777s	
3754/25300 (epoch 7.419), train_loss = 1.13550506, grad/param norm = 1.8734e-01, time/batch = 0.6771s	
3755/25300 (epoch 7.421), train_loss = 1.12412579, grad/param norm = 1.6493e-01, time/batch = 0.6732s	
3756/25300 (epoch 7.423), train_loss = 1.21871431, grad/param norm = 1.7320e-01, time/batch = 0.6802s	
3757/25300 (epoch 7.425), train_loss = 1.31326487, grad/param norm = 2.0461e-01, time/batch = 0.6811s	
3758/25300 (epoch 7.427), train_loss = 1.55494496, grad/param norm = 1.9273e-01, time/batch = 0.6834s	
3759/25300 (epoch 7.429), train_loss = 1.44205968, grad/param norm = 2.1192e-01, time/batch = 0.6830s	
3760/25300 (epoch 7.431), train_loss = 1.38812736, grad/param norm = 2.0125e-01, time/batch = 0.6758s	
3761/25300 (epoch 7.433), train_loss = 1.31691793, grad/param norm = 1.8362e-01, time/batch = 0.6845s	
3762/25300 (epoch 7.435), train_loss = 1.21251671, grad/param norm = 1.8693e-01, time/batch = 0.6853s	
3763/25300 (epoch 7.437), train_loss = 1.27770902, grad/param norm = 1.7872e-01, time/batch = 0.6834s	
3764/25300 (epoch 7.439), train_loss = 1.33296466, grad/param norm = 1.9094e-01, time/batch = 0.6800s	
3765/25300 (epoch 7.441), train_loss = 1.36065980, grad/param norm = 1.9700e-01, time/batch = 0.6722s	
3766/25300 (epoch 7.443), train_loss = 1.54712170, grad/param norm = 2.1160e-01, time/batch = 0.6757s	
3767/25300 (epoch 7.445), train_loss = 1.47278817, grad/param norm = 1.8755e-01, time/batch = 0.6765s	
3768/25300 (epoch 7.447), train_loss = 1.24218605, grad/param norm = 1.8555e-01, time/batch = 0.6763s	
3769/25300 (epoch 7.449), train_loss = 1.15705403, grad/param norm = 1.7425e-01, time/batch = 0.6788s	
3770/25300 (epoch 7.451), train_loss = 1.51243604, grad/param norm = 1.9483e-01, time/batch = 0.6781s	
3771/25300 (epoch 7.453), train_loss = 1.40628355, grad/param norm = 1.8345e-01, time/batch = 0.6793s	
3772/25300 (epoch 7.455), train_loss = 1.51387254, grad/param norm = 1.8426e-01, time/batch = 0.6805s	
3773/25300 (epoch 7.457), train_loss = 1.32732512, grad/param norm = 1.8270e-01, time/batch = 0.6774s	
3774/25300 (epoch 7.458), train_loss = 1.39308565, grad/param norm = 1.9740e-01, time/batch = 0.6772s	
3775/25300 (epoch 7.460), train_loss = 1.39664416, grad/param norm = 2.0894e-01, time/batch = 0.6796s	
3776/25300 (epoch 7.462), train_loss = 1.11410537, grad/param norm = 1.7734e-01, time/batch = 0.6778s	
3777/25300 (epoch 7.464), train_loss = 1.41579777, grad/param norm = 2.0501e-01, time/batch = 0.6768s	
3778/25300 (epoch 7.466), train_loss = 1.43021598, grad/param norm = 2.0540e-01, time/batch = 0.6778s	
3779/25300 (epoch 7.468), train_loss = 1.50860716, grad/param norm = 1.9660e-01, time/batch = 0.6804s	
3780/25300 (epoch 7.470), train_loss = 1.23434818, grad/param norm = 1.7256e-01, time/batch = 0.6774s	
3781/25300 (epoch 7.472), train_loss = 1.11097066, grad/param norm = 1.7305e-01, time/batch = 0.6794s	
3782/25300 (epoch 7.474), train_loss = 1.38935705, grad/param norm = 1.9259e-01, time/batch = 0.6756s	
3783/25300 (epoch 7.476), train_loss = 1.31361860, grad/param norm = 1.7670e-01, time/batch = 0.6759s	
3784/25300 (epoch 7.478), train_loss = 1.39738655, grad/param norm = 1.8944e-01, time/batch = 0.6749s	
3785/25300 (epoch 7.480), train_loss = 1.23075446, grad/param norm = 1.7883e-01, time/batch = 0.6760s	
3786/25300 (epoch 7.482), train_loss = 1.52564244, grad/param norm = 2.0488e-01, time/batch = 0.6777s	
3787/25300 (epoch 7.484), train_loss = 1.46198470, grad/param norm = 2.0581e-01, time/batch = 0.6747s	
3788/25300 (epoch 7.486), train_loss = 1.34215019, grad/param norm = 1.8814e-01, time/batch = 0.6737s	
3789/25300 (epoch 7.488), train_loss = 1.41261049, grad/param norm = 1.9860e-01, time/batch = 0.6766s	
3790/25300 (epoch 7.490), train_loss = 1.43935335, grad/param norm = 1.8973e-01, time/batch = 0.6752s	
3791/25300 (epoch 7.492), train_loss = 1.26028361, grad/param norm = 1.6756e-01, time/batch = 0.6759s	
3792/25300 (epoch 7.494), train_loss = 1.18980650, grad/param norm = 1.7286e-01, time/batch = 0.6750s	
3793/25300 (epoch 7.496), train_loss = 1.35855820, grad/param norm = 1.8764e-01, time/batch = 0.6750s	
3794/25300 (epoch 7.498), train_loss = 1.23156500, grad/param norm = 1.8070e-01, time/batch = 0.6738s	
3795/25300 (epoch 7.500), train_loss = 1.51962458, grad/param norm = 1.9913e-01, time/batch = 0.6768s	
3796/25300 (epoch 7.502), train_loss = 1.31929588, grad/param norm = 1.8201e-01, time/batch = 0.6761s	
3797/25300 (epoch 7.504), train_loss = 1.28223105, grad/param norm = 1.9116e-01, time/batch = 0.6747s	
3798/25300 (epoch 7.506), train_loss = 1.32810762, grad/param norm = 1.9325e-01, time/batch = 0.6800s	
3799/25300 (epoch 7.508), train_loss = 1.35890429, grad/param norm = 2.0101e-01, time/batch = 0.6796s	
3800/25300 (epoch 7.510), train_loss = 1.27211131, grad/param norm = 2.0505e-01, time/batch = 0.6781s	
3801/25300 (epoch 7.512), train_loss = 1.02867000, grad/param norm = 1.5658e-01, time/batch = 0.6760s	
3802/25300 (epoch 7.514), train_loss = 1.21555804, grad/param norm = 1.7240e-01, time/batch = 0.6767s	
3803/25300 (epoch 7.516), train_loss = 1.31819324, grad/param norm = 1.9034e-01, time/batch = 0.6777s	
3804/25300 (epoch 7.518), train_loss = 1.39315422, grad/param norm = 2.0578e-01, time/batch = 0.6766s	
3805/25300 (epoch 7.520), train_loss = 1.11820460, grad/param norm = 1.7350e-01, time/batch = 0.6758s	
3806/25300 (epoch 7.522), train_loss = 1.23619881, grad/param norm = 1.7209e-01, time/batch = 0.6732s	
3807/25300 (epoch 7.524), train_loss = 1.24541406, grad/param norm = 1.7630e-01, time/batch = 0.6739s	
3808/25300 (epoch 7.526), train_loss = 1.58144378, grad/param norm = 2.2534e-01, time/batch = 0.6738s	
3809/25300 (epoch 7.528), train_loss = 1.45373835, grad/param norm = 1.9669e-01, time/batch = 0.6717s	
3810/25300 (epoch 7.530), train_loss = 1.33489926, grad/param norm = 2.0540e-01, time/batch = 0.6747s	
3811/25300 (epoch 7.532), train_loss = 1.36942227, grad/param norm = 2.0097e-01, time/batch = 0.6873s	
3812/25300 (epoch 7.534), train_loss = 1.28440168, grad/param norm = 1.9231e-01, time/batch = 0.6808s	
3813/25300 (epoch 7.536), train_loss = 1.19001104, grad/param norm = 1.9637e-01, time/batch = 0.6773s	
3814/25300 (epoch 7.538), train_loss = 1.13477546, grad/param norm = 1.5127e-01, time/batch = 0.6787s	
3815/25300 (epoch 7.540), train_loss = 1.23300395, grad/param norm = 1.7514e-01, time/batch = 0.6771s	
3816/25300 (epoch 7.542), train_loss = 1.21720160, grad/param norm = 1.8694e-01, time/batch = 0.6765s	
3817/25300 (epoch 7.543), train_loss = 1.16138330, grad/param norm = 1.7113e-01, time/batch = 0.6769s	
3818/25300 (epoch 7.545), train_loss = 1.74947270, grad/param norm = 2.2561e-01, time/batch = 0.6755s	
3819/25300 (epoch 7.547), train_loss = 1.32354584, grad/param norm = 1.9251e-01, time/batch = 0.6771s	
3820/25300 (epoch 7.549), train_loss = 1.60410238, grad/param norm = 2.2016e-01, time/batch = 0.6820s	
3821/25300 (epoch 7.551), train_loss = 1.36484693, grad/param norm = 2.0266e-01, time/batch = 0.6817s	
3822/25300 (epoch 7.553), train_loss = 1.35323680, grad/param norm = 1.8806e-01, time/batch = 0.6841s	
3823/25300 (epoch 7.555), train_loss = 1.46279818, grad/param norm = 1.8784e-01, time/batch = 0.6843s	
3824/25300 (epoch 7.557), train_loss = 1.48631583, grad/param norm = 1.8566e-01, time/batch = 0.6832s	
3825/25300 (epoch 7.559), train_loss = 1.50063294, grad/param norm = 1.9794e-01, time/batch = 0.6825s	
3826/25300 (epoch 7.561), train_loss = 1.53606709, grad/param norm = 2.0557e-01, time/batch = 0.6823s	
3827/25300 (epoch 7.563), train_loss = 1.44794371, grad/param norm = 1.9025e-01, time/batch = 0.6838s	
3828/25300 (epoch 7.565), train_loss = 1.18473641, grad/param norm = 1.7079e-01, time/batch = 0.6784s	
3829/25300 (epoch 7.567), train_loss = 1.02221213, grad/param norm = 1.7447e-01, time/batch = 0.6686s	
3830/25300 (epoch 7.569), train_loss = 1.31533890, grad/param norm = 1.8736e-01, time/batch = 0.6711s	
3831/25300 (epoch 7.571), train_loss = 1.43338516, grad/param norm = 1.9181e-01, time/batch = 0.7007s	
3832/25300 (epoch 7.573), train_loss = 1.33191332, grad/param norm = 1.8057e-01, time/batch = 0.6771s	
3833/25300 (epoch 7.575), train_loss = 1.41392167, grad/param norm = 1.8679e-01, time/batch = 0.6757s	
3834/25300 (epoch 7.577), train_loss = 1.39643039, grad/param norm = 1.8995e-01, time/batch = 0.6773s	
3835/25300 (epoch 7.579), train_loss = 1.55978490, grad/param norm = 2.0279e-01, time/batch = 0.6851s	
3836/25300 (epoch 7.581), train_loss = 1.40107024, grad/param norm = 1.9244e-01, time/batch = 0.6740s	
3837/25300 (epoch 7.583), train_loss = 1.24729893, grad/param norm = 1.7796e-01, time/batch = 0.6752s	
3838/25300 (epoch 7.585), train_loss = 1.20176572, grad/param norm = 1.7544e-01, time/batch = 0.6760s	
3839/25300 (epoch 7.587), train_loss = 1.28308515, grad/param norm = 1.7692e-01, time/batch = 0.6706s	
3840/25300 (epoch 7.589), train_loss = 1.17271645, grad/param norm = 1.7014e-01, time/batch = 0.6771s	
3841/25300 (epoch 7.591), train_loss = 1.20952963, grad/param norm = 1.9122e-01, time/batch = 0.6790s	
3842/25300 (epoch 7.593), train_loss = 1.30311879, grad/param norm = 1.7232e-01, time/batch = 0.6737s	
3843/25300 (epoch 7.595), train_loss = 1.30052250, grad/param norm = 1.8372e-01, time/batch = 0.6727s	
3844/25300 (epoch 7.597), train_loss = 1.10431125, grad/param norm = 1.6049e-01, time/batch = 0.6756s	
3845/25300 (epoch 7.599), train_loss = 1.32507724, grad/param norm = 1.7759e-01, time/batch = 0.6797s	
3846/25300 (epoch 7.601), train_loss = 1.36152332, grad/param norm = 1.8060e-01, time/batch = 0.6755s	
3847/25300 (epoch 7.603), train_loss = 1.37638794, grad/param norm = 1.6765e-01, time/batch = 0.6722s	
3848/25300 (epoch 7.605), train_loss = 1.23043278, grad/param norm = 1.7247e-01, time/batch = 0.6736s	
3849/25300 (epoch 7.607), train_loss = 1.11861939, grad/param norm = 1.7352e-01, time/batch = 0.6784s	
3850/25300 (epoch 7.609), train_loss = 1.31356196, grad/param norm = 1.7565e-01, time/batch = 0.6776s	
3851/25300 (epoch 7.611), train_loss = 1.42791153, grad/param norm = 1.7071e-01, time/batch = 0.6761s	
3852/25300 (epoch 7.613), train_loss = 1.20281051, grad/param norm = 1.7288e-01, time/batch = 0.6729s	
3853/25300 (epoch 7.615), train_loss = 1.37045723, grad/param norm = 1.9922e-01, time/batch = 0.6739s	
3854/25300 (epoch 7.617), train_loss = 1.32356654, grad/param norm = 1.7437e-01, time/batch = 0.6734s	
3855/25300 (epoch 7.619), train_loss = 1.41446883, grad/param norm = 1.8851e-01, time/batch = 0.6749s	
3856/25300 (epoch 7.621), train_loss = 1.41097625, grad/param norm = 1.9190e-01, time/batch = 0.6942s	
3857/25300 (epoch 7.623), train_loss = 1.26492034, grad/param norm = 1.8837e-01, time/batch = 0.6759s	
3858/25300 (epoch 7.625), train_loss = 1.12382501, grad/param norm = 1.8063e-01, time/batch = 0.6819s	
3859/25300 (epoch 7.626), train_loss = 1.26348881, grad/param norm = 1.7365e-01, time/batch = 0.6766s	
3860/25300 (epoch 7.628), train_loss = 1.48150702, grad/param norm = 2.0579e-01, time/batch = 0.6763s	
3861/25300 (epoch 7.630), train_loss = 1.51958741, grad/param norm = 2.0152e-01, time/batch = 0.6805s	
3862/25300 (epoch 7.632), train_loss = 1.45107718, grad/param norm = 2.0454e-01, time/batch = 0.6717s	
3863/25300 (epoch 7.634), train_loss = 1.47061014, grad/param norm = 2.0087e-01, time/batch = 0.6861s	
3864/25300 (epoch 7.636), train_loss = 1.36746643, grad/param norm = 1.9411e-01, time/batch = 0.6842s	
3865/25300 (epoch 7.638), train_loss = 1.47469835, grad/param norm = 2.0541e-01, time/batch = 0.6779s	
3866/25300 (epoch 7.640), train_loss = 1.58846855, grad/param norm = 2.1242e-01, time/batch = 0.6798s	
3867/25300 (epoch 7.642), train_loss = 1.39601038, grad/param norm = 2.0412e-01, time/batch = 0.6788s	
3868/25300 (epoch 7.644), train_loss = 1.41807878, grad/param norm = 1.9272e-01, time/batch = 0.6719s	
3869/25300 (epoch 7.646), train_loss = 1.36412754, grad/param norm = 1.8998e-01, time/batch = 0.6763s	
3870/25300 (epoch 7.648), train_loss = 1.44852842, grad/param norm = 1.7728e-01, time/batch = 0.6694s	
3871/25300 (epoch 7.650), train_loss = 1.40567061, grad/param norm = 1.9081e-01, time/batch = 0.6786s	
3872/25300 (epoch 7.652), train_loss = 1.42139068, grad/param norm = 1.9786e-01, time/batch = 0.6777s	
3873/25300 (epoch 7.654), train_loss = 1.54508701, grad/param norm = 1.9196e-01, time/batch = 0.6801s	
3874/25300 (epoch 7.656), train_loss = 1.48353840, grad/param norm = 2.0300e-01, time/batch = 0.6789s	
3875/25300 (epoch 7.658), train_loss = 1.15576572, grad/param norm = 1.6208e-01, time/batch = 0.6823s	
3876/25300 (epoch 7.660), train_loss = 1.20286201, grad/param norm = 1.8008e-01, time/batch = 0.6839s	
3877/25300 (epoch 7.662), train_loss = 1.13737067, grad/param norm = 1.7692e-01, time/batch = 0.6823s	
3878/25300 (epoch 7.664), train_loss = 1.13356358, grad/param norm = 1.6944e-01, time/batch = 0.6853s	
3879/25300 (epoch 7.666), train_loss = 1.17011041, grad/param norm = 1.7127e-01, time/batch = 0.6838s	
3880/25300 (epoch 7.668), train_loss = 1.21991815, grad/param norm = 2.0117e-01, time/batch = 0.6786s	
3881/25300 (epoch 7.670), train_loss = 1.23736223, grad/param norm = 1.7349e-01, time/batch = 0.6814s	
3882/25300 (epoch 7.672), train_loss = 1.25491371, grad/param norm = 1.7275e-01, time/batch = 0.6806s	
3883/25300 (epoch 7.674), train_loss = 1.28692360, grad/param norm = 1.8706e-01, time/batch = 0.6698s	
3884/25300 (epoch 7.676), train_loss = 1.38144369, grad/param norm = 1.8612e-01, time/batch = 0.6712s	
3885/25300 (epoch 7.678), train_loss = 1.28171419, grad/param norm = 2.0630e-01, time/batch = 0.6717s	
3886/25300 (epoch 7.680), train_loss = 1.17345796, grad/param norm = 1.7832e-01, time/batch = 0.6724s	
3887/25300 (epoch 7.682), train_loss = 0.98588725, grad/param norm = 1.6130e-01, time/batch = 0.6756s	
3888/25300 (epoch 7.684), train_loss = 1.15645357, grad/param norm = 1.6524e-01, time/batch = 0.6707s	
3889/25300 (epoch 7.686), train_loss = 1.18342500, grad/param norm = 1.7267e-01, time/batch = 0.6759s	
3890/25300 (epoch 7.688), train_loss = 1.34760566, grad/param norm = 1.8124e-01, time/batch = 0.6784s	
3891/25300 (epoch 7.690), train_loss = 1.21132889, grad/param norm = 1.6695e-01, time/batch = 0.6914s	
3892/25300 (epoch 7.692), train_loss = 1.35019681, grad/param norm = 1.8064e-01, time/batch = 0.6909s	
3893/25300 (epoch 7.694), train_loss = 1.24644799, grad/param norm = 1.6541e-01, time/batch = 0.6746s	
3894/25300 (epoch 7.696), train_loss = 1.33157124, grad/param norm = 1.9679e-01, time/batch = 0.6775s	
3895/25300 (epoch 7.698), train_loss = 1.36124818, grad/param norm = 1.7914e-01, time/batch = 0.6742s	
3896/25300 (epoch 7.700), train_loss = 1.11448732, grad/param norm = 1.6654e-01, time/batch = 0.6720s	
3897/25300 (epoch 7.702), train_loss = 1.43146985, grad/param norm = 1.9157e-01, time/batch = 0.6707s	
3898/25300 (epoch 7.704), train_loss = 1.08747987, grad/param norm = 1.7238e-01, time/batch = 0.6702s	
3899/25300 (epoch 7.706), train_loss = 1.33120239, grad/param norm = 2.1661e-01, time/batch = 0.6696s	
3900/25300 (epoch 7.708), train_loss = 1.08879274, grad/param norm = 1.6668e-01, time/batch = 0.6689s	
3901/25300 (epoch 7.709), train_loss = 1.48188334, grad/param norm = 1.9819e-01, time/batch = 0.6769s	
3902/25300 (epoch 7.711), train_loss = 1.55737798, grad/param norm = 1.9978e-01, time/batch = 0.6768s	
3903/25300 (epoch 7.713), train_loss = 1.26747906, grad/param norm = 1.8276e-01, time/batch = 0.6725s	
3904/25300 (epoch 7.715), train_loss = 1.26354150, grad/param norm = 1.8431e-01, time/batch = 0.6706s	
3905/25300 (epoch 7.717), train_loss = 1.31532122, grad/param norm = 1.9413e-01, time/batch = 0.6738s	
3906/25300 (epoch 7.719), train_loss = 1.30625372, grad/param norm = 1.9722e-01, time/batch = 0.6707s	
3907/25300 (epoch 7.721), train_loss = 1.33251739, grad/param norm = 2.0920e-01, time/batch = 0.6760s	
3908/25300 (epoch 7.723), train_loss = 1.21512049, grad/param norm = 1.8633e-01, time/batch = 0.6823s	
3909/25300 (epoch 7.725), train_loss = 1.33884888, grad/param norm = 1.9140e-01, time/batch = 0.7071s	
3910/25300 (epoch 7.727), train_loss = 1.32784970, grad/param norm = 1.7928e-01, time/batch = 0.6769s	
3911/25300 (epoch 7.729), train_loss = 1.25049503, grad/param norm = 1.8528e-01, time/batch = 0.6777s	
3912/25300 (epoch 7.731), train_loss = 1.53787671, grad/param norm = 2.0846e-01, time/batch = 0.6734s	
3913/25300 (epoch 7.733), train_loss = 1.22598598, grad/param norm = 1.6556e-01, time/batch = 0.6721s	
3914/25300 (epoch 7.735), train_loss = 1.63029820, grad/param norm = 2.0996e-01, time/batch = 0.6770s	
3915/25300 (epoch 7.737), train_loss = 1.12922746, grad/param norm = 1.7786e-01, time/batch = 0.6742s	
3916/25300 (epoch 7.739), train_loss = 1.44922338, grad/param norm = 1.8568e-01, time/batch = 0.6764s	
3917/25300 (epoch 7.741), train_loss = 1.35592128, grad/param norm = 1.9198e-01, time/batch = 0.6756s	
3918/25300 (epoch 7.743), train_loss = 1.21807345, grad/param norm = 1.6885e-01, time/batch = 0.6744s	
3919/25300 (epoch 7.745), train_loss = 1.24099302, grad/param norm = 1.7466e-01, time/batch = 0.6754s	
3920/25300 (epoch 7.747), train_loss = 1.13397200, grad/param norm = 1.5261e-01, time/batch = 0.6816s	
3921/25300 (epoch 7.749), train_loss = 1.35909878, grad/param norm = 1.9060e-01, time/batch = 0.6801s	
3922/25300 (epoch 7.751), train_loss = 1.45540817, grad/param norm = 1.9615e-01, time/batch = 0.6763s	
3923/25300 (epoch 7.753), train_loss = 1.26870581, grad/param norm = 2.0526e-01, time/batch = 0.6784s	
3924/25300 (epoch 7.755), train_loss = 1.41572815, grad/param norm = 1.9897e-01, time/batch = 0.6757s	
3925/25300 (epoch 7.757), train_loss = 1.17731358, grad/param norm = 1.9860e-01, time/batch = 0.6734s	
3926/25300 (epoch 7.759), train_loss = 1.16649222, grad/param norm = 1.8626e-01, time/batch = 0.6842s	
3927/25300 (epoch 7.761), train_loss = 1.45482140, grad/param norm = 2.0208e-01, time/batch = 0.6790s	
3928/25300 (epoch 7.763), train_loss = 1.21711486, grad/param norm = 1.8767e-01, time/batch = 0.6792s	
3929/25300 (epoch 7.765), train_loss = 1.26471722, grad/param norm = 1.9103e-01, time/batch = 0.6760s	
3930/25300 (epoch 7.767), train_loss = 1.18527633, grad/param norm = 1.9055e-01, time/batch = 0.6743s	
3931/25300 (epoch 7.769), train_loss = 1.37719723, grad/param norm = 1.9995e-01, time/batch = 0.6790s	
3932/25300 (epoch 7.771), train_loss = 1.56660414, grad/param norm = 2.2618e-01, time/batch = 0.6797s	
3933/25300 (epoch 7.773), train_loss = 1.47803249, grad/param norm = 1.9891e-01, time/batch = 0.6750s	
3934/25300 (epoch 7.775), train_loss = 1.26845640, grad/param norm = 1.6799e-01, time/batch = 0.6819s	
3935/25300 (epoch 7.777), train_loss = 1.34684362, grad/param norm = 1.8761e-01, time/batch = 0.6765s	
3936/25300 (epoch 7.779), train_loss = 1.43268346, grad/param norm = 1.8139e-01, time/batch = 0.6745s	
3937/25300 (epoch 7.781), train_loss = 1.26053918, grad/param norm = 1.7615e-01, time/batch = 0.6872s	
3938/25300 (epoch 7.783), train_loss = 1.51158309, grad/param norm = 1.9949e-01, time/batch = 0.6790s	
3939/25300 (epoch 7.785), train_loss = 1.42238953, grad/param norm = 1.9028e-01, time/batch = 0.6827s	
3940/25300 (epoch 7.787), train_loss = 1.43175232, grad/param norm = 1.8303e-01, time/batch = 0.6741s	
3941/25300 (epoch 7.789), train_loss = 1.55981588, grad/param norm = 1.8894e-01, time/batch = 0.6752s	
3942/25300 (epoch 7.791), train_loss = 1.30513100, grad/param norm = 1.8360e-01, time/batch = 0.6819s	
3943/25300 (epoch 7.792), train_loss = 1.39799410, grad/param norm = 1.8576e-01, time/batch = 0.6738s	
3944/25300 (epoch 7.794), train_loss = 1.38080658, grad/param norm = 1.9534e-01, time/batch = 0.6734s	
3945/25300 (epoch 7.796), train_loss = 1.30442312, grad/param norm = 1.7013e-01, time/batch = 0.6740s	
3946/25300 (epoch 7.798), train_loss = 1.46452987, grad/param norm = 1.8335e-01, time/batch = 0.6734s	
3947/25300 (epoch 7.800), train_loss = 1.33358974, grad/param norm = 1.9962e-01, time/batch = 0.6715s	
3948/25300 (epoch 7.802), train_loss = 1.07161089, grad/param norm = 1.6510e-01, time/batch = 0.6748s	
3949/25300 (epoch 7.804), train_loss = 1.32645722, grad/param norm = 1.8020e-01, time/batch = 0.6744s	
3950/25300 (epoch 7.806), train_loss = 1.40959063, grad/param norm = 1.9118e-01, time/batch = 0.6706s	
3951/25300 (epoch 7.808), train_loss = 1.31999135, grad/param norm = 1.8003e-01, time/batch = 0.6774s	
3952/25300 (epoch 7.810), train_loss = 1.33772815, grad/param norm = 1.9130e-01, time/batch = 0.6785s	
3953/25300 (epoch 7.812), train_loss = 1.39033323, grad/param norm = 1.9422e-01, time/batch = 0.6796s	
3954/25300 (epoch 7.814), train_loss = 1.53673089, grad/param norm = 1.9975e-01, time/batch = 0.6752s	
3955/25300 (epoch 7.816), train_loss = 1.64083962, grad/param norm = 2.0509e-01, time/batch = 0.6773s	
3956/25300 (epoch 7.818), train_loss = 1.44765164, grad/param norm = 1.9097e-01, time/batch = 0.6784s	
3957/25300 (epoch 7.820), train_loss = 1.37444436, grad/param norm = 1.7081e-01, time/batch = 0.6757s	
3958/25300 (epoch 7.822), train_loss = 1.31131324, grad/param norm = 1.7063e-01, time/batch = 0.6777s	
3959/25300 (epoch 7.824), train_loss = 1.40571404, grad/param norm = 1.7096e-01, time/batch = 0.6783s	
3960/25300 (epoch 7.826), train_loss = 1.26066120, grad/param norm = 1.9597e-01, time/batch = 0.6785s	
3961/25300 (epoch 7.828), train_loss = 1.26353016, grad/param norm = 1.8888e-01, time/batch = 0.6822s	
3962/25300 (epoch 7.830), train_loss = 1.29903457, grad/param norm = 1.7123e-01, time/batch = 0.6790s	
3963/25300 (epoch 7.832), train_loss = 1.34168772, grad/param norm = 1.7822e-01, time/batch = 0.6733s	
3964/25300 (epoch 7.834), train_loss = 1.14815822, grad/param norm = 1.6319e-01, time/batch = 0.6766s	
3965/25300 (epoch 7.836), train_loss = 1.23902582, grad/param norm = 1.7262e-01, time/batch = 0.6756s	
3966/25300 (epoch 7.838), train_loss = 1.31497979, grad/param norm = 1.9466e-01, time/batch = 0.6758s	
3967/25300 (epoch 7.840), train_loss = 1.47350036, grad/param norm = 1.8252e-01, time/batch = 0.6772s	
3968/25300 (epoch 7.842), train_loss = 1.35749836, grad/param norm = 2.2169e-01, time/batch = 0.6789s	
3969/25300 (epoch 7.844), train_loss = 1.33053712, grad/param norm = 1.7645e-01, time/batch = 0.6772s	
3970/25300 (epoch 7.846), train_loss = 1.30949476, grad/param norm = 1.7952e-01, time/batch = 0.6720s	
3971/25300 (epoch 7.848), train_loss = 1.53048957, grad/param norm = 2.0584e-01, time/batch = 0.6760s	
3972/25300 (epoch 7.850), train_loss = 1.42970185, grad/param norm = 1.9111e-01, time/batch = 0.6749s	
3973/25300 (epoch 7.852), train_loss = 1.34107527, grad/param norm = 2.0113e-01, time/batch = 0.6735s	
3974/25300 (epoch 7.854), train_loss = 1.54621498, grad/param norm = 2.0353e-01, time/batch = 0.6761s	
3975/25300 (epoch 7.856), train_loss = 1.33269433, grad/param norm = 1.8601e-01, time/batch = 0.6777s	
3976/25300 (epoch 7.858), train_loss = 1.41112147, grad/param norm = 2.1201e-01, time/batch = 0.6761s	
3977/25300 (epoch 7.860), train_loss = 1.12123652, grad/param norm = 1.8429e-01, time/batch = 0.6756s	
3978/25300 (epoch 7.862), train_loss = 1.41968118, grad/param norm = 2.1612e-01, time/batch = 0.6763s	
3979/25300 (epoch 7.864), train_loss = 1.44941859, grad/param norm = 1.9426e-01, time/batch = 0.6769s	
3980/25300 (epoch 7.866), train_loss = 1.42879523, grad/param norm = 2.1277e-01, time/batch = 0.6726s	
3981/25300 (epoch 7.868), train_loss = 1.48491672, grad/param norm = 2.4275e-01, time/batch = 0.6772s	
3982/25300 (epoch 7.870), train_loss = 1.44412215, grad/param norm = 1.9007e-01, time/batch = 0.6737s	
3983/25300 (epoch 7.872), train_loss = 1.43741051, grad/param norm = 2.0972e-01, time/batch = 0.6748s	
3984/25300 (epoch 7.874), train_loss = 1.43381170, grad/param norm = 1.9884e-01, time/batch = 0.6740s	
3985/25300 (epoch 7.875), train_loss = 1.31354553, grad/param norm = 1.7517e-01, time/batch = 0.6773s	
3986/25300 (epoch 7.877), train_loss = 1.24475580, grad/param norm = 1.7221e-01, time/batch = 0.6803s	
3987/25300 (epoch 7.879), train_loss = 1.38560689, grad/param norm = 1.9263e-01, time/batch = 0.6739s	
3988/25300 (epoch 7.881), train_loss = 1.68109677, grad/param norm = 2.0570e-01, time/batch = 0.6731s	
3989/25300 (epoch 7.883), train_loss = 1.59585284, grad/param norm = 1.8827e-01, time/batch = 0.6750s	
3990/25300 (epoch 7.885), train_loss = 1.48382521, grad/param norm = 2.0510e-01, time/batch = 0.6752s	
3991/25300 (epoch 7.887), train_loss = 1.34136653, grad/param norm = 1.7779e-01, time/batch = 0.6748s	
3992/25300 (epoch 7.889), train_loss = 1.53200462, grad/param norm = 1.9107e-01, time/batch = 0.6738s	
3993/25300 (epoch 7.891), train_loss = 1.51909748, grad/param norm = 2.6267e-01, time/batch = 0.6690s	
3994/25300 (epoch 7.893), train_loss = 1.59684375, grad/param norm = 1.9324e-01, time/batch = 0.6719s	
3995/25300 (epoch 7.895), train_loss = 1.11047683, grad/param norm = 2.0291e-01, time/batch = 0.6799s	
3996/25300 (epoch 7.897), train_loss = 1.24294492, grad/param norm = 1.7558e-01, time/batch = 0.6797s	
3997/25300 (epoch 7.899), train_loss = 1.33174723, grad/param norm = 1.8973e-01, time/batch = 0.6978s	
3998/25300 (epoch 7.901), train_loss = 1.42491489, grad/param norm = 2.0082e-01, time/batch = 0.6948s	
3999/25300 (epoch 7.903), train_loss = 1.15580769, grad/param norm = 1.6382e-01, time/batch = 0.6777s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch7.91_1.4788.t7	
4000/25300 (epoch 7.905), train_loss = 1.25906279, grad/param norm = 1.7495e-01, time/batch = 0.6762s	
4001/25300 (epoch 7.907), train_loss = 1.58661226, grad/param norm = 2.2899e-01, time/batch = 0.6860s	
4002/25300 (epoch 7.909), train_loss = 1.45129029, grad/param norm = 1.8317e-01, time/batch = 0.6882s	
4003/25300 (epoch 7.911), train_loss = 1.58407768, grad/param norm = 2.0662e-01, time/batch = 0.6722s	
4004/25300 (epoch 7.913), train_loss = 1.55647883, grad/param norm = 2.0823e-01, time/batch = 0.6755s	
4005/25300 (epoch 7.915), train_loss = 1.27829454, grad/param norm = 1.8964e-01, time/batch = 0.6755s	
4006/25300 (epoch 7.917), train_loss = 1.41616001, grad/param norm = 2.0005e-01, time/batch = 0.6734s	
4007/25300 (epoch 7.919), train_loss = 1.52175144, grad/param norm = 2.0873e-01, time/batch = 0.6831s	
4008/25300 (epoch 7.921), train_loss = 1.25737348, grad/param norm = 1.9377e-01, time/batch = 0.6808s	
4009/25300 (epoch 7.923), train_loss = 1.50089415, grad/param norm = 1.7843e-01, time/batch = 0.6826s	
4010/25300 (epoch 7.925), train_loss = 1.36688676, grad/param norm = 1.8045e-01, time/batch = 0.6811s	
4011/25300 (epoch 7.927), train_loss = 1.34321309, grad/param norm = 1.7953e-01, time/batch = 0.6747s	
4012/25300 (epoch 7.929), train_loss = 1.26624426, grad/param norm = 1.7641e-01, time/batch = 0.6724s	
4013/25300 (epoch 7.931), train_loss = 1.49852313, grad/param norm = 2.0087e-01, time/batch = 0.6704s	
4014/25300 (epoch 7.933), train_loss = 1.40203797, grad/param norm = 1.8874e-01, time/batch = 0.6723s	
4015/25300 (epoch 7.935), train_loss = 1.35507784, grad/param norm = 1.7236e-01, time/batch = 0.6741s	
4016/25300 (epoch 7.937), train_loss = 1.07445142, grad/param norm = 1.4956e-01, time/batch = 0.6761s	
4017/25300 (epoch 7.939), train_loss = 1.44698386, grad/param norm = 1.8449e-01, time/batch = 0.6770s	
4018/25300 (epoch 7.941), train_loss = 1.29381954, grad/param norm = 1.6890e-01, time/batch = 0.6762s	
4019/25300 (epoch 7.943), train_loss = 1.23682619, grad/param norm = 1.5767e-01, time/batch = 0.6754s	
4020/25300 (epoch 7.945), train_loss = 1.37165210, grad/param norm = 1.8781e-01, time/batch = 0.6711s	
4021/25300 (epoch 7.947), train_loss = 1.25606761, grad/param norm = 1.8209e-01, time/batch = 0.6729s	
4022/25300 (epoch 7.949), train_loss = 1.45139395, grad/param norm = 1.9432e-01, time/batch = 0.6741s	
4023/25300 (epoch 7.951), train_loss = 1.34823555, grad/param norm = 1.7568e-01, time/batch = 0.6727s	
4024/25300 (epoch 7.953), train_loss = 1.43166464, grad/param norm = 1.7338e-01, time/batch = 0.6750s	
4025/25300 (epoch 7.955), train_loss = 1.61583804, grad/param norm = 2.0860e-01, time/batch = 0.6769s	
4026/25300 (epoch 7.957), train_loss = 1.56851016, grad/param norm = 1.9861e-01, time/batch = 0.6754s	
4027/25300 (epoch 7.958), train_loss = 1.40045179, grad/param norm = 1.9791e-01, time/batch = 0.6756s	
4028/25300 (epoch 7.960), train_loss = 1.56965556, grad/param norm = 1.9958e-01, time/batch = 0.6742s	
4029/25300 (epoch 7.962), train_loss = 1.50653267, grad/param norm = 2.1359e-01, time/batch = 0.6684s	
4030/25300 (epoch 7.964), train_loss = 1.41690387, grad/param norm = 1.6764e-01, time/batch = 0.6791s	
4031/25300 (epoch 7.966), train_loss = 1.17618784, grad/param norm = 1.5901e-01, time/batch = 0.6751s	
4032/25300 (epoch 7.968), train_loss = 1.17170675, grad/param norm = 1.6609e-01, time/batch = 0.6761s	
4033/25300 (epoch 7.970), train_loss = 1.40406268, grad/param norm = 2.1855e-01, time/batch = 0.6801s	
4034/25300 (epoch 7.972), train_loss = 1.34527876, grad/param norm = 1.8019e-01, time/batch = 0.6808s	
4035/25300 (epoch 7.974), train_loss = 1.57552848, grad/param norm = 2.1235e-01, time/batch = 0.6738s	
4036/25300 (epoch 7.976), train_loss = 1.37426424, grad/param norm = 1.7881e-01, time/batch = 0.6737s	
4037/25300 (epoch 7.978), train_loss = 1.38774236, grad/param norm = 1.7905e-01, time/batch = 0.6764s	
4038/25300 (epoch 7.980), train_loss = 1.42719887, grad/param norm = 2.0505e-01, time/batch = 0.6705s	
4039/25300 (epoch 7.982), train_loss = 1.33114453, grad/param norm = 1.7906e-01, time/batch = 0.6726s	
4040/25300 (epoch 7.984), train_loss = 1.34381665, grad/param norm = 1.7619e-01, time/batch = 0.6761s	
4041/25300 (epoch 7.986), train_loss = 1.38970199, grad/param norm = 1.9728e-01, time/batch = 0.6811s	
4042/25300 (epoch 7.988), train_loss = 1.40048324, grad/param norm = 1.8722e-01, time/batch = 0.6873s	
4043/25300 (epoch 7.990), train_loss = 1.36135763, grad/param norm = 1.7876e-01, time/batch = 0.6843s	
4044/25300 (epoch 7.992), train_loss = 1.07083369, grad/param norm = 1.7431e-01, time/batch = 0.6842s	
4045/25300 (epoch 7.994), train_loss = 1.38158655, grad/param norm = 1.9118e-01, time/batch = 0.6799s	
4046/25300 (epoch 7.996), train_loss = 1.50483259, grad/param norm = 2.0553e-01, time/batch = 0.6784s	
4047/25300 (epoch 7.998), train_loss = 1.49503447, grad/param norm = 1.8934e-01, time/batch = 0.6761s	
4048/25300 (epoch 8.000), train_loss = 1.35146535, grad/param norm = 1.9391e-01, time/batch = 0.6842s	
4049/25300 (epoch 8.002), train_loss = 1.18045143, grad/param norm = 1.5904e-01, time/batch = 0.6771s	
4050/25300 (epoch 8.004), train_loss = 1.12130526, grad/param norm = 1.7407e-01, time/batch = 0.6790s	
4051/25300 (epoch 8.006), train_loss = 1.39603917, grad/param norm = 1.7797e-01, time/batch = 0.6767s	
4052/25300 (epoch 8.008), train_loss = 1.36171245, grad/param norm = 1.8822e-01, time/batch = 0.6757s	
4053/25300 (epoch 8.010), train_loss = 1.40147879, grad/param norm = 1.8027e-01, time/batch = 0.6734s	
4054/25300 (epoch 8.012), train_loss = 1.20333639, grad/param norm = 1.8300e-01, time/batch = 0.6711s	
4055/25300 (epoch 8.014), train_loss = 1.43707025, grad/param norm = 2.0039e-01, time/batch = 0.6752s	
4056/25300 (epoch 8.016), train_loss = 1.39255002, grad/param norm = 2.0360e-01, time/batch = 0.6738s	
4057/25300 (epoch 8.018), train_loss = 1.23701481, grad/param norm = 1.8207e-01, time/batch = 0.6732s	
4058/25300 (epoch 8.020), train_loss = 1.26925344, grad/param norm = 1.7473e-01, time/batch = 0.6744s	
4059/25300 (epoch 8.022), train_loss = 1.36023182, grad/param norm = 1.8797e-01, time/batch = 0.6745s	
4060/25300 (epoch 8.024), train_loss = 1.03372322, grad/param norm = 1.5993e-01, time/batch = 0.6754s	
4061/25300 (epoch 8.026), train_loss = 1.28235340, grad/param norm = 2.0994e-01, time/batch = 0.6718s	
4062/25300 (epoch 8.028), train_loss = 1.15362133, grad/param norm = 1.6531e-01, time/batch = 0.6754s	
4063/25300 (epoch 8.030), train_loss = 1.40951750, grad/param norm = 1.8138e-01, time/batch = 0.6773s	
4064/25300 (epoch 8.032), train_loss = 1.27929419, grad/param norm = 1.7719e-01, time/batch = 0.6741s	
4065/25300 (epoch 8.034), train_loss = 1.09481832, grad/param norm = 1.8043e-01, time/batch = 0.6757s	
4066/25300 (epoch 8.036), train_loss = 1.14402368, grad/param norm = 1.7439e-01, time/batch = 0.6763s	
4067/25300 (epoch 8.038), train_loss = 1.00102505, grad/param norm = 1.4718e-01, time/batch = 0.6762s	
4068/25300 (epoch 8.040), train_loss = 1.39895744, grad/param norm = 1.8245e-01, time/batch = 0.6779s	
4069/25300 (epoch 8.042), train_loss = 1.14868598, grad/param norm = 1.5635e-01, time/batch = 0.6759s	
4070/25300 (epoch 8.043), train_loss = 1.08919481, grad/param norm = 1.5697e-01, time/batch = 0.6780s	
4071/25300 (epoch 8.045), train_loss = 1.11878498, grad/param norm = 1.6594e-01, time/batch = 0.6906s	
4072/25300 (epoch 8.047), train_loss = 1.37788485, grad/param norm = 1.7010e-01, time/batch = 0.6938s	
4073/25300 (epoch 8.049), train_loss = 1.36710370, grad/param norm = 1.9419e-01, time/batch = 0.6801s	
4074/25300 (epoch 8.051), train_loss = 1.43957273, grad/param norm = 1.9766e-01, time/batch = 0.6736s	
4075/25300 (epoch 8.053), train_loss = 1.11903451, grad/param norm = 1.6843e-01, time/batch = 0.6750s	
4076/25300 (epoch 8.055), train_loss = 1.12665520, grad/param norm = 1.5929e-01, time/batch = 0.6809s	
4077/25300 (epoch 8.057), train_loss = 1.08003950, grad/param norm = 1.5491e-01, time/batch = 0.6844s	
4078/25300 (epoch 8.059), train_loss = 1.30972603, grad/param norm = 1.8227e-01, time/batch = 0.6869s	
4079/25300 (epoch 8.061), train_loss = 1.20484208, grad/param norm = 1.7239e-01, time/batch = 0.6854s	
4080/25300 (epoch 8.063), train_loss = 1.21495915, grad/param norm = 1.6848e-01, time/batch = 0.6802s	
4081/25300 (epoch 8.065), train_loss = 1.43962881, grad/param norm = 2.0466e-01, time/batch = 0.6801s	
4082/25300 (epoch 8.067), train_loss = 1.44134417, grad/param norm = 1.8494e-01, time/batch = 0.6853s	
4083/25300 (epoch 8.069), train_loss = 1.31672273, grad/param norm = 1.7371e-01, time/batch = 0.6653s	
4084/25300 (epoch 8.071), train_loss = 1.44430130, grad/param norm = 1.7728e-01, time/batch = 0.6679s	
4085/25300 (epoch 8.073), train_loss = 1.27330430, grad/param norm = 1.7183e-01, time/batch = 0.6739s	
4086/25300 (epoch 8.075), train_loss = 1.31057685, grad/param norm = 1.6778e-01, time/batch = 0.6743s	
4087/25300 (epoch 8.077), train_loss = 1.39828562, grad/param norm = 1.8916e-01, time/batch = 0.6768s	
4088/25300 (epoch 8.079), train_loss = 1.35238243, grad/param norm = 1.8520e-01, time/batch = 0.6734s	
4089/25300 (epoch 8.081), train_loss = 1.27528383, grad/param norm = 1.7715e-01, time/batch = 0.6745s	
4090/25300 (epoch 8.083), train_loss = 1.21582143, grad/param norm = 1.7637e-01, time/batch = 0.6732s	
4091/25300 (epoch 8.085), train_loss = 1.53715391, grad/param norm = 2.0411e-01, time/batch = 0.6757s	
4092/25300 (epoch 8.087), train_loss = 1.31188359, grad/param norm = 1.9936e-01, time/batch = 0.6732s	
4093/25300 (epoch 8.089), train_loss = 1.33549938, grad/param norm = 1.7485e-01, time/batch = 0.6736s	
4094/25300 (epoch 8.091), train_loss = 1.44489603, grad/param norm = 1.9142e-01, time/batch = 0.6738s	
4095/25300 (epoch 8.093), train_loss = 1.49607793, grad/param norm = 1.9346e-01, time/batch = 0.6727s	
4096/25300 (epoch 8.095), train_loss = 1.37116253, grad/param norm = 1.7423e-01, time/batch = 0.6798s	
4097/25300 (epoch 8.097), train_loss = 1.34521576, grad/param norm = 1.8028e-01, time/batch = 0.6798s	
4098/25300 (epoch 8.099), train_loss = 1.35137749, grad/param norm = 1.9216e-01, time/batch = 0.6701s	
4099/25300 (epoch 8.101), train_loss = 1.29137938, grad/param norm = 1.7786e-01, time/batch = 0.6753s	
4100/25300 (epoch 8.103), train_loss = 1.24982768, grad/param norm = 1.6879e-01, time/batch = 0.6762s	
4101/25300 (epoch 8.105), train_loss = 1.35062807, grad/param norm = 1.8651e-01, time/batch = 0.6777s	
4102/25300 (epoch 8.107), train_loss = 1.44774900, grad/param norm = 2.0072e-01, time/batch = 0.6767s	
4103/25300 (epoch 8.109), train_loss = 1.36757588, grad/param norm = 1.9214e-01, time/batch = 0.6760s	
4104/25300 (epoch 8.111), train_loss = 1.25949763, grad/param norm = 1.6751e-01, time/batch = 0.6749s	
4105/25300 (epoch 8.113), train_loss = 1.32141939, grad/param norm = 1.7509e-01, time/batch = 0.6754s	
4106/25300 (epoch 8.115), train_loss = 1.28755688, grad/param norm = 1.6624e-01, time/batch = 0.6962s	
4107/25300 (epoch 8.117), train_loss = 1.39288200, grad/param norm = 1.8000e-01, time/batch = 0.6802s	
4108/25300 (epoch 8.119), train_loss = 1.29314277, grad/param norm = 1.8616e-01, time/batch = 0.6773s	
4109/25300 (epoch 8.121), train_loss = 1.45092107, grad/param norm = 2.1113e-01, time/batch = 0.6703s	
4110/25300 (epoch 8.123), train_loss = 1.30772310, grad/param norm = 1.8395e-01, time/batch = 0.6710s	
4111/25300 (epoch 8.125), train_loss = 1.43897841, grad/param norm = 1.9380e-01, time/batch = 0.6761s	
4112/25300 (epoch 8.126), train_loss = 1.33449259, grad/param norm = 1.9432e-01, time/batch = 0.6743s	
4113/25300 (epoch 8.128), train_loss = 1.34994889, grad/param norm = 1.7991e-01, time/batch = 0.6748s	
4114/25300 (epoch 8.130), train_loss = 1.03460533, grad/param norm = 1.4984e-01, time/batch = 0.6773s	
4115/25300 (epoch 8.132), train_loss = 1.17875074, grad/param norm = 1.7073e-01, time/batch = 0.6754s	
4116/25300 (epoch 8.134), train_loss = 1.04358666, grad/param norm = 1.5894e-01, time/batch = 0.6744s	
4117/25300 (epoch 8.136), train_loss = 1.35746398, grad/param norm = 1.7467e-01, time/batch = 0.6699s	
4118/25300 (epoch 8.138), train_loss = 1.16484367, grad/param norm = 1.6937e-01, time/batch = 0.6745s	
4119/25300 (epoch 8.140), train_loss = 1.20593509, grad/param norm = 1.6745e-01, time/batch = 0.6748s	
4120/25300 (epoch 8.142), train_loss = 1.41147041, grad/param norm = 1.8443e-01, time/batch = 0.6747s	
4121/25300 (epoch 8.144), train_loss = 1.33399765, grad/param norm = 1.9099e-01, time/batch = 0.6756s	
4122/25300 (epoch 8.146), train_loss = 1.46307084, grad/param norm = 1.9930e-01, time/batch = 0.6747s	
4123/25300 (epoch 8.148), train_loss = 1.34377577, grad/param norm = 1.7572e-01, time/batch = 0.6750s	
4124/25300 (epoch 8.150), train_loss = 1.44746109, grad/param norm = 2.0995e-01, time/batch = 0.6734s	
4125/25300 (epoch 8.152), train_loss = 1.59360637, grad/param norm = 1.9672e-01, time/batch = 0.6752s	
4126/25300 (epoch 8.154), train_loss = 1.21939897, grad/param norm = 1.9123e-01, time/batch = 0.6734s	
4127/25300 (epoch 8.156), train_loss = 1.35849041, grad/param norm = 1.7910e-01, time/batch = 0.6737s	
4128/25300 (epoch 8.158), train_loss = 1.25764117, grad/param norm = 1.7781e-01, time/batch = 0.6740s	
4129/25300 (epoch 8.160), train_loss = 1.33578680, grad/param norm = 1.7811e-01, time/batch = 0.6819s	
4130/25300 (epoch 8.162), train_loss = 1.25909702, grad/param norm = 1.9503e-01, time/batch = 0.6851s	
4131/25300 (epoch 8.164), train_loss = 1.37650937, grad/param norm = 1.8743e-01, time/batch = 0.6867s	
4132/25300 (epoch 8.166), train_loss = 1.35397389, grad/param norm = 1.8878e-01, time/batch = 0.6752s	
4133/25300 (epoch 8.168), train_loss = 1.14928052, grad/param norm = 1.5329e-01, time/batch = 0.6770s	
4134/25300 (epoch 8.170), train_loss = 1.22092838, grad/param norm = 1.6720e-01, time/batch = 0.6837s	
4135/25300 (epoch 8.172), train_loss = 1.20212533, grad/param norm = 1.7512e-01, time/batch = 0.6728s	
4136/25300 (epoch 8.174), train_loss = 1.19060046, grad/param norm = 1.7631e-01, time/batch = 0.6763s	
4137/25300 (epoch 8.176), train_loss = 1.28391693, grad/param norm = 1.8536e-01, time/batch = 0.6828s	
4138/25300 (epoch 8.178), train_loss = 1.48042992, grad/param norm = 1.9070e-01, time/batch = 0.6890s	
4139/25300 (epoch 8.180), train_loss = 1.08205865, grad/param norm = 1.7532e-01, time/batch = 0.6913s	
4140/25300 (epoch 8.182), train_loss = 1.23664370, grad/param norm = 1.7043e-01, time/batch = 0.6750s	
4141/25300 (epoch 8.184), train_loss = 1.29595741, grad/param norm = 1.8404e-01, time/batch = 0.6769s	
4142/25300 (epoch 8.186), train_loss = 1.26266331, grad/param norm = 1.8063e-01, time/batch = 0.6788s	
4143/25300 (epoch 8.188), train_loss = 1.27267410, grad/param norm = 1.7762e-01, time/batch = 0.6778s	
4144/25300 (epoch 8.190), train_loss = 1.36361618, grad/param norm = 1.9135e-01, time/batch = 0.6809s	
4145/25300 (epoch 8.192), train_loss = 1.28701773, grad/param norm = 1.8547e-01, time/batch = 0.6789s	
4146/25300 (epoch 8.194), train_loss = 1.29259427, grad/param norm = 1.8460e-01, time/batch = 0.6770s	
4147/25300 (epoch 8.196), train_loss = 1.41826285, grad/param norm = 2.1935e-01, time/batch = 0.6765s	
4148/25300 (epoch 8.198), train_loss = 1.25419788, grad/param norm = 1.9162e-01, time/batch = 0.6767s	
4149/25300 (epoch 8.200), train_loss = 1.35718717, grad/param norm = 2.0052e-01, time/batch = 0.6774s	
4150/25300 (epoch 8.202), train_loss = 1.36337077, grad/param norm = 1.9127e-01, time/batch = 0.6768s	
4151/25300 (epoch 8.204), train_loss = 1.28876143, grad/param norm = 1.7770e-01, time/batch = 0.6775s	
4152/25300 (epoch 8.206), train_loss = 1.36298679, grad/param norm = 1.9329e-01, time/batch = 0.6827s	
4153/25300 (epoch 8.208), train_loss = 1.18841656, grad/param norm = 2.0333e-01, time/batch = 0.6734s	
4154/25300 (epoch 8.209), train_loss = 1.07851350, grad/param norm = 1.5964e-01, time/batch = 0.6721s	
4155/25300 (epoch 8.211), train_loss = 1.28256021, grad/param norm = 1.7476e-01, time/batch = 0.6733s	
4156/25300 (epoch 8.213), train_loss = 1.36441095, grad/param norm = 2.0233e-01, time/batch = 0.6718s	
4157/25300 (epoch 8.215), train_loss = 1.33275568, grad/param norm = 2.0002e-01, time/batch = 0.6738s	
4158/25300 (epoch 8.217), train_loss = 1.38928942, grad/param norm = 1.9675e-01, time/batch = 0.6760s	
4159/25300 (epoch 8.219), train_loss = 1.36978319, grad/param norm = 1.8733e-01, time/batch = 0.6765s	
4160/25300 (epoch 8.221), train_loss = 1.43419166, grad/param norm = 1.9111e-01, time/batch = 0.6753s	
4161/25300 (epoch 8.223), train_loss = 1.41226599, grad/param norm = 2.0388e-01, time/batch = 0.6728s	
4162/25300 (epoch 8.225), train_loss = 1.85427796, grad/param norm = 2.4164e-01, time/batch = 0.6776s	
4163/25300 (epoch 8.227), train_loss = 1.41257161, grad/param norm = 1.8569e-01, time/batch = 0.6745s	
4164/25300 (epoch 8.229), train_loss = 1.37635345, grad/param norm = 1.9587e-01, time/batch = 0.6782s	
4165/25300 (epoch 8.231), train_loss = 1.34029457, grad/param norm = 1.7983e-01, time/batch = 0.6844s	
4166/25300 (epoch 8.233), train_loss = 1.36543806, grad/param norm = 1.8570e-01, time/batch = 0.6966s	
4167/25300 (epoch 8.235), train_loss = 1.31624761, grad/param norm = 1.8512e-01, time/batch = 0.6872s	
4168/25300 (epoch 8.237), train_loss = 1.47304587, grad/param norm = 1.9616e-01, time/batch = 0.6777s	
4169/25300 (epoch 8.239), train_loss = 1.35384474, grad/param norm = 1.9314e-01, time/batch = 0.6781s	
4170/25300 (epoch 8.241), train_loss = 1.41439428, grad/param norm = 1.8858e-01, time/batch = 0.6743s	
4171/25300 (epoch 8.243), train_loss = 1.68860106, grad/param norm = 2.0978e-01, time/batch = 0.6817s	
4172/25300 (epoch 8.245), train_loss = 1.23830675, grad/param norm = 1.8342e-01, time/batch = 0.6758s	
4173/25300 (epoch 8.247), train_loss = 1.47380100, grad/param norm = 1.8412e-01, time/batch = 0.6737s	
4174/25300 (epoch 8.249), train_loss = 1.15472169, grad/param norm = 1.6751e-01, time/batch = 0.6747s	
4175/25300 (epoch 8.251), train_loss = 1.13290226, grad/param norm = 1.7252e-01, time/batch = 0.6721s	
4176/25300 (epoch 8.253), train_loss = 1.30375000, grad/param norm = 1.7584e-01, time/batch = 0.6773s	
4177/25300 (epoch 8.255), train_loss = 1.26139836, grad/param norm = 1.7936e-01, time/batch = 0.6918s	
4178/25300 (epoch 8.257), train_loss = 1.42930743, grad/param norm = 1.8871e-01, time/batch = 0.6722s	
4179/25300 (epoch 8.259), train_loss = 1.59723500, grad/param norm = 2.0930e-01, time/batch = 0.6708s	
4180/25300 (epoch 8.261), train_loss = 1.49204076, grad/param norm = 2.0072e-01, time/batch = 0.6742s	
4181/25300 (epoch 8.263), train_loss = 1.44658715, grad/param norm = 1.8077e-01, time/batch = 0.6763s	
4182/25300 (epoch 8.265), train_loss = 1.52272289, grad/param norm = 1.8784e-01, time/batch = 0.6780s	
4183/25300 (epoch 8.267), train_loss = 1.44553170, grad/param norm = 1.7005e-01, time/batch = 0.6757s	
4184/25300 (epoch 8.269), train_loss = 1.15547429, grad/param norm = 1.6496e-01, time/batch = 0.6772s	
4185/25300 (epoch 8.271), train_loss = 1.23255638, grad/param norm = 1.8657e-01, time/batch = 0.6813s	
4186/25300 (epoch 8.273), train_loss = 1.38267552, grad/param norm = 1.8004e-01, time/batch = 0.6786s	
4187/25300 (epoch 8.275), train_loss = 1.18111290, grad/param norm = 1.6501e-01, time/batch = 0.6735s	
4188/25300 (epoch 8.277), train_loss = 1.30725988, grad/param norm = 2.0414e-01, time/batch = 0.6769s	
4189/25300 (epoch 8.279), train_loss = 1.34490582, grad/param norm = 1.8836e-01, time/batch = 0.6765s	
4190/25300 (epoch 8.281), train_loss = 1.49668299, grad/param norm = 2.1501e-01, time/batch = 0.6728s	
4191/25300 (epoch 8.283), train_loss = 1.20867237, grad/param norm = 1.8330e-01, time/batch = 0.6744s	
4192/25300 (epoch 8.285), train_loss = 1.33535684, grad/param norm = 1.9575e-01, time/batch = 0.6779s	
4193/25300 (epoch 8.287), train_loss = 1.32357286, grad/param norm = 1.8326e-01, time/batch = 0.6720s	
4194/25300 (epoch 8.289), train_loss = 1.25718382, grad/param norm = 1.7359e-01, time/batch = 0.6783s	
4195/25300 (epoch 8.291), train_loss = 1.24391475, grad/param norm = 1.8822e-01, time/batch = 0.6760s	
4196/25300 (epoch 8.292), train_loss = 1.43200153, grad/param norm = 1.9456e-01, time/batch = 0.6717s	
4197/25300 (epoch 8.294), train_loss = 1.34360861, grad/param norm = 1.7781e-01, time/batch = 0.6820s	
4198/25300 (epoch 8.296), train_loss = 1.18091414, grad/param norm = 1.8850e-01, time/batch = 0.6783s	
4199/25300 (epoch 8.298), train_loss = 1.41915542, grad/param norm = 1.9018e-01, time/batch = 0.6748s	
4200/25300 (epoch 8.300), train_loss = 1.53871243, grad/param norm = 2.2478e-01, time/batch = 0.6744s	
4201/25300 (epoch 8.302), train_loss = 1.14738388, grad/param norm = 1.8155e-01, time/batch = 0.6717s	
4202/25300 (epoch 8.304), train_loss = 1.34665824, grad/param norm = 1.9028e-01, time/batch = 0.6762s	
4203/25300 (epoch 8.306), train_loss = 1.06107937, grad/param norm = 1.5984e-01, time/batch = 0.6745s	
4204/25300 (epoch 8.308), train_loss = 1.36808631, grad/param norm = 1.6898e-01, time/batch = 0.6754s	
4205/25300 (epoch 8.310), train_loss = 1.24981305, grad/param norm = 1.9538e-01, time/batch = 0.6704s	
4206/25300 (epoch 8.312), train_loss = 1.31215585, grad/param norm = 1.8330e-01, time/batch = 0.6734s	
4207/25300 (epoch 8.314), train_loss = 1.06659290, grad/param norm = 1.7263e-01, time/batch = 0.6757s	
4208/25300 (epoch 8.316), train_loss = 1.35417197, grad/param norm = 1.7570e-01, time/batch = 0.6745s	
4209/25300 (epoch 8.318), train_loss = 1.03407307, grad/param norm = 1.6205e-01, time/batch = 0.6734s	
4210/25300 (epoch 8.320), train_loss = 1.17998965, grad/param norm = 1.6699e-01, time/batch = 0.6762s	
4211/25300 (epoch 8.322), train_loss = 1.62479184, grad/param norm = 2.0797e-01, time/batch = 0.6783s	
4212/25300 (epoch 8.324), train_loss = 1.18826720, grad/param norm = 1.7315e-01, time/batch = 0.6798s	
4213/25300 (epoch 8.326), train_loss = 1.05586591, grad/param norm = 1.5300e-01, time/batch = 0.6758s	
4214/25300 (epoch 8.328), train_loss = 1.07998150, grad/param norm = 1.6735e-01, time/batch = 0.6754s	
4215/25300 (epoch 8.330), train_loss = 1.23971301, grad/param norm = 1.7662e-01, time/batch = 0.6800s	
4216/25300 (epoch 8.332), train_loss = 1.35067713, grad/param norm = 1.6214e-01, time/batch = 0.6820s	
4217/25300 (epoch 8.334), train_loss = 1.17372634, grad/param norm = 1.5942e-01, time/batch = 0.6823s	
4218/25300 (epoch 8.336), train_loss = 1.12811788, grad/param norm = 1.8786e-01, time/batch = 0.6815s	
4219/25300 (epoch 8.338), train_loss = 1.14220490, grad/param norm = 1.8319e-01, time/batch = 0.6802s	
4220/25300 (epoch 8.340), train_loss = 1.24111560, grad/param norm = 1.8498e-01, time/batch = 0.6772s	
4221/25300 (epoch 8.342), train_loss = 1.24345999, grad/param norm = 1.8697e-01, time/batch = 0.6862s	
4222/25300 (epoch 8.344), train_loss = 1.26700837, grad/param norm = 1.7828e-01, time/batch = 0.6730s	
4223/25300 (epoch 8.346), train_loss = 1.27564143, grad/param norm = 1.7942e-01, time/batch = 0.6641s	
4224/25300 (epoch 8.348), train_loss = 1.13360758, grad/param norm = 1.5682e-01, time/batch = 0.6705s	
4225/25300 (epoch 8.350), train_loss = 1.24186896, grad/param norm = 1.7704e-01, time/batch = 0.6730s	
4226/25300 (epoch 8.352), train_loss = 1.29772605, grad/param norm = 1.7460e-01, time/batch = 0.6704s	
4227/25300 (epoch 8.354), train_loss = 1.26168871, grad/param norm = 1.8822e-01, time/batch = 0.6762s	
4228/25300 (epoch 8.356), train_loss = 1.33165138, grad/param norm = 1.9156e-01, time/batch = 0.6745s	
4229/25300 (epoch 8.358), train_loss = 1.42148601, grad/param norm = 1.9899e-01, time/batch = 0.6746s	
4230/25300 (epoch 8.360), train_loss = 1.19411041, grad/param norm = 2.0378e-01, time/batch = 0.6763s	
4231/25300 (epoch 8.362), train_loss = 1.29732693, grad/param norm = 1.8821e-01, time/batch = 0.6783s	
4232/25300 (epoch 8.364), train_loss = 1.39770155, grad/param norm = 1.9833e-01, time/batch = 0.6758s	
4233/25300 (epoch 8.366), train_loss = 1.14778035, grad/param norm = 1.6658e-01, time/batch = 0.6770s	
4234/25300 (epoch 8.368), train_loss = 1.27001930, grad/param norm = 1.6465e-01, time/batch = 0.6761s	
4235/25300 (epoch 8.370), train_loss = 1.31409053, grad/param norm = 2.0783e-01, time/batch = 0.6758s	
4236/25300 (epoch 8.372), train_loss = 1.25419175, grad/param norm = 1.8268e-01, time/batch = 0.6787s	
4237/25300 (epoch 8.374), train_loss = 1.18733772, grad/param norm = 1.7251e-01, time/batch = 0.6767s	
4238/25300 (epoch 8.375), train_loss = 1.52921281, grad/param norm = 1.9960e-01, time/batch = 0.6756s	
4239/25300 (epoch 8.377), train_loss = 1.29755797, grad/param norm = 1.7935e-01, time/batch = 0.6796s	
4240/25300 (epoch 8.379), train_loss = 1.49281601, grad/param norm = 1.9854e-01, time/batch = 0.6772s	
4241/25300 (epoch 8.381), train_loss = 1.28875486, grad/param norm = 1.7016e-01, time/batch = 0.6758s	
4242/25300 (epoch 8.383), train_loss = 1.16873161, grad/param norm = 1.7156e-01, time/batch = 0.6780s	
4243/25300 (epoch 8.385), train_loss = 1.23030747, grad/param norm = 1.7588e-01, time/batch = 0.6694s	
4244/25300 (epoch 8.387), train_loss = 1.39345565, grad/param norm = 1.9376e-01, time/batch = 0.6744s	
4245/25300 (epoch 8.389), train_loss = 1.47111209, grad/param norm = 2.0406e-01, time/batch = 0.6769s	
4246/25300 (epoch 8.391), train_loss = 1.16068742, grad/param norm = 1.6779e-01, time/batch = 0.6738s	
4247/25300 (epoch 8.393), train_loss = 1.35316484, grad/param norm = 1.8588e-01, time/batch = 0.6758s	
4248/25300 (epoch 8.395), train_loss = 1.11255080, grad/param norm = 1.6644e-01, time/batch = 0.6761s	
4249/25300 (epoch 8.397), train_loss = 1.16987210, grad/param norm = 1.8450e-01, time/batch = 0.6735s	
4250/25300 (epoch 8.399), train_loss = 1.14699539, grad/param norm = 1.6021e-01, time/batch = 0.6722s	
4251/25300 (epoch 8.401), train_loss = 1.43435875, grad/param norm = 1.9208e-01, time/batch = 0.6719s	
4252/25300 (epoch 8.403), train_loss = 1.32261406, grad/param norm = 1.9953e-01, time/batch = 0.6743s	
4253/25300 (epoch 8.405), train_loss = 1.34963148, grad/param norm = 2.0785e-01, time/batch = 0.6821s	
4254/25300 (epoch 8.407), train_loss = 1.20247639, grad/param norm = 1.7592e-01, time/batch = 0.6863s	
4255/25300 (epoch 8.409), train_loss = 1.20463611, grad/param norm = 1.6448e-01, time/batch = 0.6818s	
4256/25300 (epoch 8.411), train_loss = 1.27414343, grad/param norm = 1.7629e-01, time/batch = 0.6730s	
4257/25300 (epoch 8.413), train_loss = 1.16280968, grad/param norm = 1.6725e-01, time/batch = 0.6739s	
4258/25300 (epoch 8.415), train_loss = 1.15533795, grad/param norm = 1.7689e-01, time/batch = 0.6736s	
4259/25300 (epoch 8.417), train_loss = 1.12526614, grad/param norm = 1.6732e-01, time/batch = 0.6916s	
4260/25300 (epoch 8.419), train_loss = 1.09255445, grad/param norm = 1.8449e-01, time/batch = 0.6754s	
4261/25300 (epoch 8.421), train_loss = 1.07575565, grad/param norm = 1.5550e-01, time/batch = 0.6744s	
4262/25300 (epoch 8.423), train_loss = 1.17643286, grad/param norm = 1.6795e-01, time/batch = 0.6805s	
4263/25300 (epoch 8.425), train_loss = 1.26197380, grad/param norm = 1.9662e-01, time/batch = 0.6827s	
4264/25300 (epoch 8.427), train_loss = 1.50874724, grad/param norm = 1.8639e-01, time/batch = 0.6835s	
4265/25300 (epoch 8.429), train_loss = 1.40396617, grad/param norm = 2.0459e-01, time/batch = 0.6843s	
4266/25300 (epoch 8.431), train_loss = 1.31712962, grad/param norm = 1.8872e-01, time/batch = 0.6828s	
4267/25300 (epoch 8.433), train_loss = 1.26094657, grad/param norm = 1.7918e-01, time/batch = 0.6833s	
4268/25300 (epoch 8.435), train_loss = 1.16895404, grad/param norm = 1.8333e-01, time/batch = 0.6813s	
4269/25300 (epoch 8.437), train_loss = 1.22680148, grad/param norm = 1.7368e-01, time/batch = 0.6762s	
4270/25300 (epoch 8.439), train_loss = 1.28291468, grad/param norm = 1.8252e-01, time/batch = 0.6708s	
4271/25300 (epoch 8.441), train_loss = 1.30772795, grad/param norm = 1.9511e-01, time/batch = 0.6715s	
4272/25300 (epoch 8.443), train_loss = 1.51462706, grad/param norm = 2.1382e-01, time/batch = 0.6777s	
4273/25300 (epoch 8.445), train_loss = 1.42981867, grad/param norm = 1.8419e-01, time/batch = 0.6768s	
4274/25300 (epoch 8.447), train_loss = 1.20030126, grad/param norm = 1.8322e-01, time/batch = 0.6739s	
4275/25300 (epoch 8.449), train_loss = 1.10214867, grad/param norm = 1.7150e-01, time/batch = 0.6799s	
4276/25300 (epoch 8.451), train_loss = 1.46269722, grad/param norm = 1.9063e-01, time/batch = 0.6755s	
4277/25300 (epoch 8.453), train_loss = 1.36713299, grad/param norm = 1.8671e-01, time/batch = 0.6761s	
4278/25300 (epoch 8.455), train_loss = 1.45783636, grad/param norm = 1.8106e-01, time/batch = 0.6722s	
4279/25300 (epoch 8.457), train_loss = 1.27247752, grad/param norm = 1.7985e-01, time/batch = 0.6720s	
4280/25300 (epoch 8.458), train_loss = 1.34242915, grad/param norm = 1.9997e-01, time/batch = 0.6694s	
4281/25300 (epoch 8.460), train_loss = 1.34116236, grad/param norm = 2.1223e-01, time/batch = 0.6701s	
4282/25300 (epoch 8.462), train_loss = 1.06849689, grad/param norm = 1.7066e-01, time/batch = 0.6765s	
4283/25300 (epoch 8.464), train_loss = 1.36354478, grad/param norm = 1.9576e-01, time/batch = 0.6764s	
4284/25300 (epoch 8.466), train_loss = 1.38205293, grad/param norm = 1.9557e-01, time/batch = 0.6753s	
4285/25300 (epoch 8.468), train_loss = 1.45336442, grad/param norm = 2.0299e-01, time/batch = 0.6787s	
4286/25300 (epoch 8.470), train_loss = 1.18317546, grad/param norm = 1.6509e-01, time/batch = 0.6790s	
4287/25300 (epoch 8.472), train_loss = 1.06661494, grad/param norm = 1.6483e-01, time/batch = 0.6756s	
4288/25300 (epoch 8.474), train_loss = 1.34006699, grad/param norm = 1.8926e-01, time/batch = 0.6774s	
4289/25300 (epoch 8.476), train_loss = 1.25876494, grad/param norm = 1.6904e-01, time/batch = 0.6821s	
4290/25300 (epoch 8.478), train_loss = 1.35819496, grad/param norm = 1.9239e-01, time/batch = 0.6951s	
4291/25300 (epoch 8.480), train_loss = 1.18440021, grad/param norm = 1.7568e-01, time/batch = 0.6891s	
4292/25300 (epoch 8.482), train_loss = 1.47915663, grad/param norm = 2.0402e-01, time/batch = 0.6834s	
4293/25300 (epoch 8.484), train_loss = 1.39737610, grad/param norm = 1.9532e-01, time/batch = 0.6742s	
4294/25300 (epoch 8.486), train_loss = 1.30457892, grad/param norm = 1.8259e-01, time/batch = 0.6757s	
4295/25300 (epoch 8.488), train_loss = 1.37553273, grad/param norm = 1.8482e-01, time/batch = 0.6852s	
4296/25300 (epoch 8.490), train_loss = 1.37960992, grad/param norm = 1.8440e-01, time/batch = 0.6733s	
4297/25300 (epoch 8.492), train_loss = 1.22289268, grad/param norm = 1.6521e-01, time/batch = 0.6745s	
4298/25300 (epoch 8.494), train_loss = 1.15095723, grad/param norm = 1.7246e-01, time/batch = 0.6728s	
4299/25300 (epoch 8.496), train_loss = 1.30368383, grad/param norm = 1.8478e-01, time/batch = 0.6725s	
4300/25300 (epoch 8.498), train_loss = 1.18796578, grad/param norm = 1.7909e-01, time/batch = 0.6736s	
4301/25300 (epoch 8.500), train_loss = 1.46960562, grad/param norm = 1.9294e-01, time/batch = 0.6744s	
4302/25300 (epoch 8.502), train_loss = 1.28177876, grad/param norm = 1.8434e-01, time/batch = 0.6776s	
4303/25300 (epoch 8.504), train_loss = 1.23206518, grad/param norm = 1.8722e-01, time/batch = 0.6776s	
4304/25300 (epoch 8.506), train_loss = 1.25498405, grad/param norm = 1.7683e-01, time/batch = 0.6727s	
4305/25300 (epoch 8.508), train_loss = 1.31464868, grad/param norm = 1.8938e-01, time/batch = 0.6738s	
4306/25300 (epoch 8.510), train_loss = 1.22456608, grad/param norm = 1.9746e-01, time/batch = 0.6758s	
4307/25300 (epoch 8.512), train_loss = 0.99168933, grad/param norm = 1.5143e-01, time/batch = 0.6782s	
4308/25300 (epoch 8.514), train_loss = 1.18538824, grad/param norm = 1.6751e-01, time/batch = 0.6748s	
4309/25300 (epoch 8.516), train_loss = 1.27776739, grad/param norm = 1.8115e-01, time/batch = 0.6769s	
4310/25300 (epoch 8.518), train_loss = 1.34375169, grad/param norm = 1.9370e-01, time/batch = 0.6745s	
4311/25300 (epoch 8.520), train_loss = 1.07436453, grad/param norm = 1.6347e-01, time/batch = 0.6779s	
4312/25300 (epoch 8.522), train_loss = 1.19419150, grad/param norm = 1.6761e-01, time/batch = 0.6838s	
4313/25300 (epoch 8.524), train_loss = 1.21725219, grad/param norm = 1.7321e-01, time/batch = 0.6756s	
4314/25300 (epoch 8.526), train_loss = 1.53546992, grad/param norm = 2.0607e-01, time/batch = 0.6760s	
4315/25300 (epoch 8.528), train_loss = 1.41509778, grad/param norm = 1.9022e-01, time/batch = 0.6738s	
4316/25300 (epoch 8.530), train_loss = 1.29148604, grad/param norm = 1.9578e-01, time/batch = 0.6755s	
4317/25300 (epoch 8.532), train_loss = 1.31856139, grad/param norm = 1.9536e-01, time/batch = 0.6754s	
4318/25300 (epoch 8.534), train_loss = 1.23205819, grad/param norm = 1.8787e-01, time/batch = 0.6770s	
4319/25300 (epoch 8.536), train_loss = 1.13134208, grad/param norm = 1.8408e-01, time/batch = 0.6765s	
4320/25300 (epoch 8.538), train_loss = 1.09026648, grad/param norm = 1.5032e-01, time/batch = 0.6734s	
4321/25300 (epoch 8.540), train_loss = 1.18240554, grad/param norm = 1.7000e-01, time/batch = 0.6782s	
4322/25300 (epoch 8.542), train_loss = 1.17218390, grad/param norm = 1.8142e-01, time/batch = 0.6784s	
4323/25300 (epoch 8.543), train_loss = 1.11274048, grad/param norm = 1.6872e-01, time/batch = 0.6782s	
4324/25300 (epoch 8.545), train_loss = 1.68373900, grad/param norm = 2.1965e-01, time/batch = 0.6812s	
4325/25300 (epoch 8.547), train_loss = 1.28430083, grad/param norm = 1.8790e-01, time/batch = 0.6770s	
4326/25300 (epoch 8.549), train_loss = 1.55460527, grad/param norm = 2.0504e-01, time/batch = 0.6796s	
4327/25300 (epoch 8.551), train_loss = 1.31517263, grad/param norm = 1.8756e-01, time/batch = 0.6786s	
4328/25300 (epoch 8.553), train_loss = 1.29509188, grad/param norm = 1.8492e-01, time/batch = 0.6800s	
4329/25300 (epoch 8.555), train_loss = 1.41089608, grad/param norm = 1.8083e-01, time/batch = 0.6803s	
4330/25300 (epoch 8.557), train_loss = 1.43504333, grad/param norm = 1.8333e-01, time/batch = 0.6828s	
4331/25300 (epoch 8.559), train_loss = 1.46278741, grad/param norm = 1.9748e-01, time/batch = 0.6796s	
4332/25300 (epoch 8.561), train_loss = 1.48245293, grad/param norm = 1.9721e-01, time/batch = 0.6747s	
4333/25300 (epoch 8.563), train_loss = 1.40600599, grad/param norm = 1.9117e-01, time/batch = 0.6745s	
4334/25300 (epoch 8.565), train_loss = 1.13994776, grad/param norm = 1.7356e-01, time/batch = 0.6789s	
4335/25300 (epoch 8.567), train_loss = 0.97377431, grad/param norm = 1.6757e-01, time/batch = 0.6759s	
4336/25300 (epoch 8.569), train_loss = 1.26699105, grad/param norm = 1.8582e-01, time/batch = 0.6759s	
4337/25300 (epoch 8.571), train_loss = 1.38047225, grad/param norm = 1.9203e-01, time/batch = 0.6730s	
4338/25300 (epoch 8.573), train_loss = 1.27417042, grad/param norm = 1.7737e-01, time/batch = 0.6777s	
4339/25300 (epoch 8.575), train_loss = 1.36316713, grad/param norm = 1.8444e-01, time/batch = 0.6756s	
4340/25300 (epoch 8.577), train_loss = 1.34460926, grad/param norm = 1.8954e-01, time/batch = 0.6759s	
4341/25300 (epoch 8.579), train_loss = 1.51047829, grad/param norm = 1.9483e-01, time/batch = 0.6835s	
4342/25300 (epoch 8.581), train_loss = 1.34536057, grad/param norm = 1.8963e-01, time/batch = 0.6878s	
4343/25300 (epoch 8.583), train_loss = 1.19294870, grad/param norm = 1.7359e-01, time/batch = 0.7013s	
4344/25300 (epoch 8.585), train_loss = 1.15736145, grad/param norm = 1.7196e-01, time/batch = 0.6900s	
4345/25300 (epoch 8.587), train_loss = 1.23567895, grad/param norm = 1.7571e-01, time/batch = 0.6848s	
4346/25300 (epoch 8.589), train_loss = 1.13631474, grad/param norm = 1.7441e-01, time/batch = 0.6788s	
4347/25300 (epoch 8.591), train_loss = 1.17274684, grad/param norm = 1.8720e-01, time/batch = 0.6753s	
4348/25300 (epoch 8.593), train_loss = 1.26169822, grad/param norm = 1.6602e-01, time/batch = 0.6819s	
4349/25300 (epoch 8.595), train_loss = 1.25510115, grad/param norm = 1.8183e-01, time/batch = 0.6727s	
4350/25300 (epoch 8.597), train_loss = 1.05986211, grad/param norm = 1.5681e-01, time/batch = 0.6754s	
4351/25300 (epoch 8.599), train_loss = 1.27656408, grad/param norm = 1.7606e-01, time/batch = 0.6746s	
4352/25300 (epoch 8.601), train_loss = 1.32335619, grad/param norm = 1.7905e-01, time/batch = 0.6747s	
4353/25300 (epoch 8.603), train_loss = 1.32629978, grad/param norm = 1.6709e-01, time/batch = 0.6751s	
4354/25300 (epoch 8.605), train_loss = 1.17239368, grad/param norm = 1.6533e-01, time/batch = 0.6735s	
4355/25300 (epoch 8.607), train_loss = 1.05335924, grad/param norm = 1.7414e-01, time/batch = 0.6764s	
4356/25300 (epoch 8.609), train_loss = 1.26513756, grad/param norm = 1.7742e-01, time/batch = 0.6767s	
4357/25300 (epoch 8.611), train_loss = 1.37283107, grad/param norm = 1.6918e-01, time/batch = 0.6770s	
4358/25300 (epoch 8.613), train_loss = 1.15062456, grad/param norm = 1.6879e-01, time/batch = 0.6764s	
4359/25300 (epoch 8.615), train_loss = 1.31926322, grad/param norm = 1.8757e-01, time/batch = 0.6746s	
4360/25300 (epoch 8.617), train_loss = 1.26955826, grad/param norm = 1.6805e-01, time/batch = 0.6762s	
4361/25300 (epoch 8.619), train_loss = 1.36297257, grad/param norm = 1.8333e-01, time/batch = 0.6811s	
4362/25300 (epoch 8.621), train_loss = 1.36950089, grad/param norm = 1.9379e-01, time/batch = 0.6799s	
4363/25300 (epoch 8.623), train_loss = 1.20962907, grad/param norm = 1.8249e-01, time/batch = 0.6758s	
4364/25300 (epoch 8.625), train_loss = 1.06392165, grad/param norm = 1.6958e-01, time/batch = 0.6764s	
4365/25300 (epoch 8.626), train_loss = 1.20718765, grad/param norm = 1.6697e-01, time/batch = 0.6765s	
4366/25300 (epoch 8.628), train_loss = 1.42432340, grad/param norm = 2.0172e-01, time/batch = 0.6750s	
4367/25300 (epoch 8.630), train_loss = 1.46405864, grad/param norm = 2.0426e-01, time/batch = 0.6734s	
4368/25300 (epoch 8.632), train_loss = 1.39538087, grad/param norm = 2.0214e-01, time/batch = 0.6744s	
4369/25300 (epoch 8.634), train_loss = 1.40966124, grad/param norm = 1.9668e-01, time/batch = 0.6720s	
4370/25300 (epoch 8.636), train_loss = 1.30620171, grad/param norm = 1.9062e-01, time/batch = 0.6762s	
4371/25300 (epoch 8.638), train_loss = 1.40745756, grad/param norm = 2.0097e-01, time/batch = 0.6743s	
4372/25300 (epoch 8.640), train_loss = 1.54125654, grad/param norm = 2.1154e-01, time/batch = 0.6748s	
4373/25300 (epoch 8.642), train_loss = 1.34927855, grad/param norm = 2.0104e-01, time/batch = 0.6793s	
4374/25300 (epoch 8.644), train_loss = 1.35921515, grad/param norm = 1.9494e-01, time/batch = 0.6761s	
4375/25300 (epoch 8.646), train_loss = 1.30627114, grad/param norm = 1.8671e-01, time/batch = 0.6726s	
4376/25300 (epoch 8.648), train_loss = 1.39235427, grad/param norm = 1.7622e-01, time/batch = 0.6731s	
4377/25300 (epoch 8.650), train_loss = 1.35214283, grad/param norm = 1.8869e-01, time/batch = 0.6733s	
4378/25300 (epoch 8.652), train_loss = 1.35606420, grad/param norm = 1.9297e-01, time/batch = 0.6749s	
4379/25300 (epoch 8.654), train_loss = 1.49280443, grad/param norm = 1.9441e-01, time/batch = 0.6765s	
4380/25300 (epoch 8.656), train_loss = 1.42941226, grad/param norm = 2.0186e-01, time/batch = 0.6749s	
4381/25300 (epoch 8.658), train_loss = 1.10422219, grad/param norm = 1.6365e-01, time/batch = 0.6771s	
4382/25300 (epoch 8.660), train_loss = 1.15338570, grad/param norm = 1.7568e-01, time/batch = 0.6819s	
4383/25300 (epoch 8.662), train_loss = 1.09690666, grad/param norm = 1.7465e-01, time/batch = 0.6747s	
4384/25300 (epoch 8.664), train_loss = 1.09340111, grad/param norm = 1.6749e-01, time/batch = 0.6782s	
4385/25300 (epoch 8.666), train_loss = 1.12428025, grad/param norm = 1.6783e-01, time/batch = 0.6771s	
4386/25300 (epoch 8.668), train_loss = 1.18303186, grad/param norm = 2.0161e-01, time/batch = 0.6795s	
4387/25300 (epoch 8.670), train_loss = 1.17939004, grad/param norm = 1.7064e-01, time/batch = 0.6781s	
4388/25300 (epoch 8.672), train_loss = 1.19085766, grad/param norm = 1.6428e-01, time/batch = 0.6744s	
4389/25300 (epoch 8.674), train_loss = 1.23076949, grad/param norm = 1.8558e-01, time/batch = 0.6751s	
4390/25300 (epoch 8.676), train_loss = 1.31790403, grad/param norm = 1.8611e-01, time/batch = 0.6762s	
4391/25300 (epoch 8.678), train_loss = 1.23620281, grad/param norm = 2.0230e-01, time/batch = 0.6768s	
4392/25300 (epoch 8.680), train_loss = 1.12585127, grad/param norm = 1.7622e-01, time/batch = 0.6781s	
4393/25300 (epoch 8.682), train_loss = 0.94478017, grad/param norm = 1.5861e-01, time/batch = 0.6765s	
4394/25300 (epoch 8.684), train_loss = 1.11607844, grad/param norm = 1.6427e-01, time/batch = 0.6775s	
4395/25300 (epoch 8.686), train_loss = 1.12102159, grad/param norm = 1.6571e-01, time/batch = 0.6847s	
4396/25300 (epoch 8.688), train_loss = 1.28860419, grad/param norm = 1.8204e-01, time/batch = 0.6827s	
4397/25300 (epoch 8.690), train_loss = 1.14912793, grad/param norm = 1.6182e-01, time/batch = 0.6846s	
4398/25300 (epoch 8.692), train_loss = 1.29230330, grad/param norm = 1.7311e-01, time/batch = 0.6788s	
4399/25300 (epoch 8.694), train_loss = 1.20203282, grad/param norm = 1.6618e-01, time/batch = 0.6837s	
4400/25300 (epoch 8.696), train_loss = 1.28962838, grad/param norm = 1.9842e-01, time/batch = 0.6821s	
4401/25300 (epoch 8.698), train_loss = 1.32803505, grad/param norm = 1.7599e-01, time/batch = 0.6846s	
4402/25300 (epoch 8.700), train_loss = 1.06102902, grad/param norm = 1.6073e-01, time/batch = 0.6846s	
4403/25300 (epoch 8.702), train_loss = 1.36929192, grad/param norm = 1.8635e-01, time/batch = 0.6810s	
4404/25300 (epoch 8.704), train_loss = 1.03693946, grad/param norm = 1.6374e-01, time/batch = 0.6710s	
4405/25300 (epoch 8.706), train_loss = 1.29195931, grad/param norm = 2.1864e-01, time/batch = 0.6718s	
4406/25300 (epoch 8.708), train_loss = 1.04605391, grad/param norm = 1.6507e-01, time/batch = 0.6727s	
4407/25300 (epoch 8.709), train_loss = 1.42224003, grad/param norm = 1.9340e-01, time/batch = 0.6747s	
4408/25300 (epoch 8.711), train_loss = 1.49218383, grad/param norm = 1.9778e-01, time/batch = 0.6764s	
4409/25300 (epoch 8.713), train_loss = 1.21691400, grad/param norm = 1.8074e-01, time/batch = 0.6757s	
4410/25300 (epoch 8.715), train_loss = 1.21769276, grad/param norm = 1.8094e-01, time/batch = 0.6762s	
4411/25300 (epoch 8.717), train_loss = 1.25459253, grad/param norm = 1.8988e-01, time/batch = 0.6773s	
4412/25300 (epoch 8.719), train_loss = 1.26072276, grad/param norm = 1.9106e-01, time/batch = 0.6764s	
4413/25300 (epoch 8.721), train_loss = 1.29827154, grad/param norm = 2.1833e-01, time/batch = 0.6765s	
4414/25300 (epoch 8.723), train_loss = 1.17405827, grad/param norm = 1.7978e-01, time/batch = 0.6706s	
4415/25300 (epoch 8.725), train_loss = 1.29745389, grad/param norm = 1.8409e-01, time/batch = 0.6734s	
4416/25300 (epoch 8.727), train_loss = 1.28904211, grad/param norm = 1.7692e-01, time/batch = 0.6746s	
4417/25300 (epoch 8.729), train_loss = 1.19935627, grad/param norm = 1.7751e-01, time/batch = 0.6737s	
4418/25300 (epoch 8.731), train_loss = 1.49227466, grad/param norm = 2.0584e-01, time/batch = 0.6791s	
4419/25300 (epoch 8.733), train_loss = 1.18017374, grad/param norm = 1.6174e-01, time/batch = 0.6797s	
4420/25300 (epoch 8.735), train_loss = 1.58414379, grad/param norm = 2.0637e-01, time/batch = 0.6763s	
4421/25300 (epoch 8.737), train_loss = 1.08362552, grad/param norm = 1.7457e-01, time/batch = 0.6756s	
4422/25300 (epoch 8.739), train_loss = 1.39858599, grad/param norm = 1.8369e-01, time/batch = 0.6760s	
4423/25300 (epoch 8.741), train_loss = 1.31131853, grad/param norm = 1.9341e-01, time/batch = 0.6764s	
4424/25300 (epoch 8.743), train_loss = 1.17352295, grad/param norm = 1.6761e-01, time/batch = 0.6773s	
4425/25300 (epoch 8.745), train_loss = 1.18954947, grad/param norm = 1.6895e-01, time/batch = 0.6762s	
4426/25300 (epoch 8.747), train_loss = 1.09550386, grad/param norm = 1.5343e-01, time/batch = 0.6751s	
4427/25300 (epoch 8.749), train_loss = 1.32760642, grad/param norm = 1.8855e-01, time/batch = 0.6744s	
4428/25300 (epoch 8.751), train_loss = 1.42029419, grad/param norm = 2.0270e-01, time/batch = 0.6736s	
4429/25300 (epoch 8.753), train_loss = 1.21142853, grad/param norm = 2.0388e-01, time/batch = 0.6855s	
4430/25300 (epoch 8.755), train_loss = 1.37403727, grad/param norm = 1.9819e-01, time/batch = 0.6809s	
4431/25300 (epoch 8.757), train_loss = 1.13461715, grad/param norm = 1.9433e-01, time/batch = 0.6982s	
4432/25300 (epoch 8.759), train_loss = 1.13045813, grad/param norm = 1.8484e-01, time/batch = 0.6795s	
4433/25300 (epoch 8.761), train_loss = 1.39964279, grad/param norm = 1.9670e-01, time/batch = 0.6859s	
4434/25300 (epoch 8.763), train_loss = 1.16441593, grad/param norm = 1.8193e-01, time/batch = 0.6790s	
4435/25300 (epoch 8.765), train_loss = 1.21679721, grad/param norm = 1.9318e-01, time/batch = 0.6791s	
4436/25300 (epoch 8.767), train_loss = 1.14171449, grad/param norm = 1.8501e-01, time/batch = 0.7077s	
4437/25300 (epoch 8.769), train_loss = 1.33252875, grad/param norm = 1.9725e-01, time/batch = 0.6764s	
4438/25300 (epoch 8.771), train_loss = 1.49651096, grad/param norm = 2.2792e-01, time/batch = 0.6755s	
4439/25300 (epoch 8.773), train_loss = 1.42632408, grad/param norm = 2.0143e-01, time/batch = 0.6755s	
4440/25300 (epoch 8.775), train_loss = 1.22263223, grad/param norm = 1.7050e-01, time/batch = 0.6777s	
4441/25300 (epoch 8.777), train_loss = 1.30433995, grad/param norm = 1.8484e-01, time/batch = 0.6785s	
4442/25300 (epoch 8.779), train_loss = 1.38114905, grad/param norm = 1.7668e-01, time/batch = 0.6759s	
4443/25300 (epoch 8.781), train_loss = 1.21762632, grad/param norm = 1.7148e-01, time/batch = 0.6773s	
4444/25300 (epoch 8.783), train_loss = 1.46553666, grad/param norm = 1.9634e-01, time/batch = 0.6740s	
4445/25300 (epoch 8.785), train_loss = 1.37734258, grad/param norm = 1.8402e-01, time/batch = 0.6747s	
4446/25300 (epoch 8.787), train_loss = 1.38315816, grad/param norm = 1.8249e-01, time/batch = 0.6753s	
4447/25300 (epoch 8.789), train_loss = 1.50462009, grad/param norm = 1.8920e-01, time/batch = 0.6739s	
4448/25300 (epoch 8.791), train_loss = 1.27300286, grad/param norm = 1.8353e-01, time/batch = 0.6754s	
4449/25300 (epoch 8.792), train_loss = 1.34781486, grad/param norm = 1.8031e-01, time/batch = 0.6745s	
4450/25300 (epoch 8.794), train_loss = 1.32087962, grad/param norm = 1.9018e-01, time/batch = 0.6742s	
4451/25300 (epoch 8.796), train_loss = 1.25420305, grad/param norm = 1.6880e-01, time/batch = 0.6738s	
4452/25300 (epoch 8.798), train_loss = 1.42026488, grad/param norm = 1.8010e-01, time/batch = 0.6742s	
4453/25300 (epoch 8.800), train_loss = 1.27988865, grad/param norm = 1.9198e-01, time/batch = 0.6761s	
4454/25300 (epoch 8.802), train_loss = 1.03062625, grad/param norm = 1.6224e-01, time/batch = 0.6732s	
4455/25300 (epoch 8.804), train_loss = 1.27451721, grad/param norm = 1.7452e-01, time/batch = 0.6740s	
4456/25300 (epoch 8.806), train_loss = 1.35610183, grad/param norm = 1.8727e-01, time/batch = 0.6730s	
4457/25300 (epoch 8.808), train_loss = 1.28890862, grad/param norm = 1.8473e-01, time/batch = 0.6740s	
4458/25300 (epoch 8.810), train_loss = 1.29348556, grad/param norm = 1.8496e-01, time/batch = 0.6817s	
4459/25300 (epoch 8.812), train_loss = 1.35433573, grad/param norm = 1.8887e-01, time/batch = 0.6843s	
4460/25300 (epoch 8.814), train_loss = 1.48204355, grad/param norm = 1.9791e-01, time/batch = 0.6837s	
4461/25300 (epoch 8.816), train_loss = 1.59043747, grad/param norm = 2.0044e-01, time/batch = 0.6760s	
4462/25300 (epoch 8.818), train_loss = 1.38984471, grad/param norm = 1.8848e-01, time/batch = 0.6743s	
4463/25300 (epoch 8.820), train_loss = 1.33133251, grad/param norm = 1.7356e-01, time/batch = 0.6777s	
4464/25300 (epoch 8.822), train_loss = 1.28224621, grad/param norm = 1.7609e-01, time/batch = 0.6851s	
4465/25300 (epoch 8.824), train_loss = 1.35897190, grad/param norm = 1.7458e-01, time/batch = 0.6847s	
4466/25300 (epoch 8.826), train_loss = 1.21628707, grad/param norm = 1.9548e-01, time/batch = 0.6765s	
4467/25300 (epoch 8.828), train_loss = 1.20405759, grad/param norm = 1.8023e-01, time/batch = 0.6753s	
4468/25300 (epoch 8.830), train_loss = 1.26104513, grad/param norm = 1.7282e-01, time/batch = 0.6755s	
4469/25300 (epoch 8.832), train_loss = 1.30657262, grad/param norm = 1.7824e-01, time/batch = 0.6725s	
4470/25300 (epoch 8.834), train_loss = 1.11227448, grad/param norm = 1.6133e-01, time/batch = 0.6729s	
4471/25300 (epoch 8.836), train_loss = 1.19858582, grad/param norm = 1.7024e-01, time/batch = 0.6818s	
4472/25300 (epoch 8.838), train_loss = 1.27073629, grad/param norm = 1.8797e-01, time/batch = 0.6787s	
4473/25300 (epoch 8.840), train_loss = 1.42995767, grad/param norm = 1.8172e-01, time/batch = 0.6770s	
4474/25300 (epoch 8.842), train_loss = 1.29282312, grad/param norm = 2.1781e-01, time/batch = 0.6780s	
4475/25300 (epoch 8.844), train_loss = 1.28381275, grad/param norm = 1.7113e-01, time/batch = 0.6794s	
4476/25300 (epoch 8.846), train_loss = 1.27035754, grad/param norm = 1.7119e-01, time/batch = 0.6795s	
4477/25300 (epoch 8.848), train_loss = 1.46233232, grad/param norm = 1.9149e-01, time/batch = 0.6819s	
4478/25300 (epoch 8.850), train_loss = 1.38473333, grad/param norm = 1.9027e-01, time/batch = 0.6796s	
4479/25300 (epoch 8.852), train_loss = 1.28856914, grad/param norm = 1.9588e-01, time/batch = 0.6767s	
4480/25300 (epoch 8.854), train_loss = 1.49838848, grad/param norm = 2.0280e-01, time/batch = 0.6800s	
4481/25300 (epoch 8.856), train_loss = 1.28491153, grad/param norm = 1.8115e-01, time/batch = 0.6841s	
4482/25300 (epoch 8.858), train_loss = 1.36378306, grad/param norm = 2.1072e-01, time/batch = 0.6775s	
4483/25300 (epoch 8.860), train_loss = 1.08227944, grad/param norm = 1.7572e-01, time/batch = 0.6794s	
4484/25300 (epoch 8.862), train_loss = 1.35360109, grad/param norm = 2.0530e-01, time/batch = 0.6821s	
4485/25300 (epoch 8.864), train_loss = 1.40409856, grad/param norm = 1.9417e-01, time/batch = 0.6789s	
4486/25300 (epoch 8.866), train_loss = 1.37205307, grad/param norm = 2.1358e-01, time/batch = 0.6750s	
4487/25300 (epoch 8.868), train_loss = 1.42683678, grad/param norm = 2.1594e-01, time/batch = 0.6768s	
4488/25300 (epoch 8.870), train_loss = 1.38991845, grad/param norm = 1.7656e-01, time/batch = 0.6773s	
4489/25300 (epoch 8.872), train_loss = 1.38970331, grad/param norm = 2.0375e-01, time/batch = 0.6775s	
4490/25300 (epoch 8.874), train_loss = 1.38848430, grad/param norm = 1.9209e-01, time/batch = 0.6755s	
4491/25300 (epoch 8.875), train_loss = 1.26938849, grad/param norm = 1.7030e-01, time/batch = 0.6766s	
4492/25300 (epoch 8.877), train_loss = 1.20150887, grad/param norm = 1.6131e-01, time/batch = 0.6749s	
4493/25300 (epoch 8.879), train_loss = 1.32854881, grad/param norm = 1.8852e-01, time/batch = 0.6902s	
4494/25300 (epoch 8.881), train_loss = 1.62465415, grad/param norm = 2.0820e-01, time/batch = 0.6828s	
4495/25300 (epoch 8.883), train_loss = 1.54280164, grad/param norm = 1.8641e-01, time/batch = 0.6843s	
4496/25300 (epoch 8.885), train_loss = 1.41745335, grad/param norm = 1.9835e-01, time/batch = 0.6786s	
4497/25300 (epoch 8.887), train_loss = 1.30583916, grad/param norm = 1.7393e-01, time/batch = 0.6761s	
4498/25300 (epoch 8.889), train_loss = 1.47382297, grad/param norm = 1.8281e-01, time/batch = 0.6852s	
4499/25300 (epoch 8.891), train_loss = 1.42716480, grad/param norm = 2.0098e-01, time/batch = 0.6757s	
4500/25300 (epoch 8.893), train_loss = 1.54332644, grad/param norm = 1.9737e-01, time/batch = 0.6740s	
4501/25300 (epoch 8.895), train_loss = 1.06390574, grad/param norm = 1.9504e-01, time/batch = 0.6807s	
4502/25300 (epoch 8.897), train_loss = 1.19622658, grad/param norm = 1.7686e-01, time/batch = 0.6766s	
4503/25300 (epoch 8.899), train_loss = 1.28179931, grad/param norm = 1.8854e-01, time/batch = 0.6785s	
4504/25300 (epoch 8.901), train_loss = 1.36579419, grad/param norm = 1.9396e-01, time/batch = 0.6763s	
4505/25300 (epoch 8.903), train_loss = 1.10890591, grad/param norm = 1.6040e-01, time/batch = 0.6771s	
4506/25300 (epoch 8.905), train_loss = 1.21680842, grad/param norm = 1.8131e-01, time/batch = 0.6773s	
4507/25300 (epoch 8.907), train_loss = 1.35277823, grad/param norm = 2.1641e-01, time/batch = 0.6831s	
4508/25300 (epoch 8.909), train_loss = 1.41713603, grad/param norm = 1.8797e-01, time/batch = 0.6762s	
4509/25300 (epoch 8.911), train_loss = 1.54190886, grad/param norm = 2.0544e-01, time/batch = 0.6757s	
4510/25300 (epoch 8.913), train_loss = 1.51328848, grad/param norm = 2.0265e-01, time/batch = 0.6735s	
4511/25300 (epoch 8.915), train_loss = 1.22377266, grad/param norm = 1.8024e-01, time/batch = 0.6761s	
4512/25300 (epoch 8.917), train_loss = 1.36646611, grad/param norm = 2.0255e-01, time/batch = 0.6785s	
4513/25300 (epoch 8.919), train_loss = 1.49054022, grad/param norm = 2.0945e-01, time/batch = 0.6779s	
4514/25300 (epoch 8.921), train_loss = 1.21974999, grad/param norm = 1.8740e-01, time/batch = 0.6771s	
4515/25300 (epoch 8.923), train_loss = 1.46959470, grad/param norm = 1.8410e-01, time/batch = 0.6764s	
4516/25300 (epoch 8.925), train_loss = 1.31146100, grad/param norm = 1.7998e-01, time/batch = 0.6718s	
4517/25300 (epoch 8.927), train_loss = 1.29796370, grad/param norm = 1.7644e-01, time/batch = 0.6831s	
4518/25300 (epoch 8.929), train_loss = 1.21240546, grad/param norm = 1.6988e-01, time/batch = 0.6856s	
4519/25300 (epoch 8.931), train_loss = 1.44563229, grad/param norm = 2.0359e-01, time/batch = 0.6878s	
4520/25300 (epoch 8.933), train_loss = 1.35663812, grad/param norm = 1.8811e-01, time/batch = 0.6823s	
4521/25300 (epoch 8.935), train_loss = 1.32145721, grad/param norm = 1.7399e-01, time/batch = 0.6774s	
4522/25300 (epoch 8.937), train_loss = 1.03522445, grad/param norm = 1.4987e-01, time/batch = 0.6757s	
4523/25300 (epoch 8.939), train_loss = 1.40660052, grad/param norm = 1.8703e-01, time/batch = 0.6735s	
4524/25300 (epoch 8.941), train_loss = 1.25447956, grad/param norm = 1.6673e-01, time/batch = 0.6795s	
4525/25300 (epoch 8.943), train_loss = 1.21598716, grad/param norm = 1.6414e-01, time/batch = 0.6832s	
4526/25300 (epoch 8.945), train_loss = 1.33364961, grad/param norm = 1.8766e-01, time/batch = 0.6812s	
4527/25300 (epoch 8.947), train_loss = 1.20394439, grad/param norm = 1.7521e-01, time/batch = 0.6811s	
4528/25300 (epoch 8.949), train_loss = 1.39298350, grad/param norm = 1.8717e-01, time/batch = 0.6748s	
4529/25300 (epoch 8.951), train_loss = 1.29150554, grad/param norm = 1.7303e-01, time/batch = 0.6751s	
4530/25300 (epoch 8.953), train_loss = 1.37408990, grad/param norm = 1.6826e-01, time/batch = 0.6761s	
4531/25300 (epoch 8.955), train_loss = 1.57531179, grad/param norm = 2.0611e-01, time/batch = 0.6767s	
4532/25300 (epoch 8.957), train_loss = 1.52113627, grad/param norm = 1.9527e-01, time/batch = 0.6724s	
4533/25300 (epoch 8.958), train_loss = 1.34895158, grad/param norm = 1.8969e-01, time/batch = 0.6741s	
4534/25300 (epoch 8.960), train_loss = 1.52234882, grad/param norm = 2.0145e-01, time/batch = 0.6757s	
4535/25300 (epoch 8.962), train_loss = 1.47586111, grad/param norm = 2.1310e-01, time/batch = 0.6730s	
4536/25300 (epoch 8.964), train_loss = 1.37775114, grad/param norm = 1.6930e-01, time/batch = 0.6749s	
4537/25300 (epoch 8.966), train_loss = 1.14201104, grad/param norm = 1.5959e-01, time/batch = 0.6743s	
4538/25300 (epoch 8.968), train_loss = 1.13033600, grad/param norm = 1.7083e-01, time/batch = 0.6767s	
4539/25300 (epoch 8.970), train_loss = 1.34824625, grad/param norm = 2.1433e-01, time/batch = 0.6748s	
4540/25300 (epoch 8.972), train_loss = 1.30044460, grad/param norm = 1.8588e-01, time/batch = 0.6731s	
4541/25300 (epoch 8.974), train_loss = 1.52920588, grad/param norm = 2.1038e-01, time/batch = 0.6779s	
4542/25300 (epoch 8.976), train_loss = 1.33385681, grad/param norm = 1.8343e-01, time/batch = 0.6755s	
4543/25300 (epoch 8.978), train_loss = 1.34758831, grad/param norm = 1.7884e-01, time/batch = 0.6730s	
4544/25300 (epoch 8.980), train_loss = 1.36649817, grad/param norm = 1.9553e-01, time/batch = 0.6701s	
4545/25300 (epoch 8.982), train_loss = 1.28800920, grad/param norm = 1.7305e-01, time/batch = 0.6717s	
4546/25300 (epoch 8.984), train_loss = 1.30293053, grad/param norm = 1.7963e-01, time/batch = 0.6716s	
4547/25300 (epoch 8.986), train_loss = 1.35007694, grad/param norm = 1.9326e-01, time/batch = 0.6743s	
4548/25300 (epoch 8.988), train_loss = 1.37322817, grad/param norm = 1.9245e-01, time/batch = 0.6755s	
4549/25300 (epoch 8.990), train_loss = 1.31697280, grad/param norm = 1.7089e-01, time/batch = 0.6721s	
4550/25300 (epoch 8.992), train_loss = 1.03631395, grad/param norm = 1.6841e-01, time/batch = 0.6723s	
4551/25300 (epoch 8.994), train_loss = 1.32263118, grad/param norm = 1.9209e-01, time/batch = 0.6797s	
4552/25300 (epoch 8.996), train_loss = 1.46493031, grad/param norm = 2.0820e-01, time/batch = 0.6800s	
4553/25300 (epoch 8.998), train_loss = 1.44984315, grad/param norm = 1.8435e-01, time/batch = 0.6754s	
4554/25300 (epoch 9.000), train_loss = 1.30696077, grad/param norm = 1.8826e-01, time/batch = 0.6719s	
4555/25300 (epoch 9.002), train_loss = 1.14126332, grad/param norm = 1.5885e-01, time/batch = 0.6739s	
4556/25300 (epoch 9.004), train_loss = 1.08490668, grad/param norm = 1.7409e-01, time/batch = 0.6765s	
4557/25300 (epoch 9.006), train_loss = 1.36308796, grad/param norm = 1.7713e-01, time/batch = 0.6763s	
4558/25300 (epoch 9.008), train_loss = 1.32123401, grad/param norm = 1.8326e-01, time/batch = 0.6752s	
4559/25300 (epoch 9.010), train_loss = 1.34931400, grad/param norm = 1.6832e-01, time/batch = 0.6764s	
4560/25300 (epoch 9.012), train_loss = 1.15801825, grad/param norm = 1.8566e-01, time/batch = 0.6754s	
4561/25300 (epoch 9.014), train_loss = 1.39385977, grad/param norm = 1.9714e-01, time/batch = 0.6796s	
4562/25300 (epoch 9.016), train_loss = 1.35208330, grad/param norm = 2.1079e-01, time/batch = 0.6766s	
4563/25300 (epoch 9.018), train_loss = 1.20018504, grad/param norm = 1.8913e-01, time/batch = 0.6754s	
4564/25300 (epoch 9.020), train_loss = 1.23476093, grad/param norm = 1.7609e-01, time/batch = 0.6757s	
4565/25300 (epoch 9.022), train_loss = 1.31648725, grad/param norm = 1.8316e-01, time/batch = 0.6749s	
4566/25300 (epoch 9.024), train_loss = 0.99438354, grad/param norm = 1.5889e-01, time/batch = 0.6755s	
4567/25300 (epoch 9.026), train_loss = 1.22981590, grad/param norm = 2.0440e-01, time/batch = 0.6752s	
4568/25300 (epoch 9.028), train_loss = 1.11613109, grad/param norm = 1.5745e-01, time/batch = 0.6737s	
4569/25300 (epoch 9.030), train_loss = 1.37057305, grad/param norm = 1.7585e-01, time/batch = 0.6715s	
4570/25300 (epoch 9.032), train_loss = 1.23013580, grad/param norm = 1.7253e-01, time/batch = 0.6763s	
4571/25300 (epoch 9.034), train_loss = 1.05321818, grad/param norm = 1.7762e-01, time/batch = 0.6789s	
4572/25300 (epoch 9.036), train_loss = 1.10192132, grad/param norm = 1.7836e-01, time/batch = 0.6793s	
4573/25300 (epoch 9.038), train_loss = 0.96721076, grad/param norm = 1.4559e-01, time/batch = 0.6750s	
4574/25300 (epoch 9.040), train_loss = 1.34904436, grad/param norm = 1.8115e-01, time/batch = 0.6759s	
4575/25300 (epoch 9.042), train_loss = 1.12307096, grad/param norm = 1.5922e-01, time/batch = 0.6847s	
4576/25300 (epoch 9.043), train_loss = 1.05264631, grad/param norm = 1.5542e-01, time/batch = 0.6824s	
4577/25300 (epoch 9.045), train_loss = 1.08085974, grad/param norm = 1.6252e-01, time/batch = 0.6743s	
4578/25300 (epoch 9.047), train_loss = 1.32503587, grad/param norm = 1.6615e-01, time/batch = 0.6761s	
4579/25300 (epoch 9.049), train_loss = 1.32168982, grad/param norm = 1.8905e-01, time/batch = 0.6824s	
4580/25300 (epoch 9.051), train_loss = 1.39210256, grad/param norm = 1.9316e-01, time/batch = 0.6728s	
4581/25300 (epoch 9.053), train_loss = 1.07010883, grad/param norm = 1.6171e-01, time/batch = 0.6775s	
4582/25300 (epoch 9.055), train_loss = 1.09888296, grad/param norm = 1.5982e-01, time/batch = 0.6741s	
4583/25300 (epoch 9.057), train_loss = 1.03352033, grad/param norm = 1.5204e-01, time/batch = 0.6784s	
4584/25300 (epoch 9.059), train_loss = 1.25682661, grad/param norm = 1.7986e-01, time/batch = 0.6761s	
4585/25300 (epoch 9.061), train_loss = 1.14922726, grad/param norm = 1.6121e-01, time/batch = 0.6756s	
4586/25300 (epoch 9.063), train_loss = 1.16855364, grad/param norm = 1.7039e-01, time/batch = 0.6753s	
4587/25300 (epoch 9.065), train_loss = 1.39460393, grad/param norm = 2.0284e-01, time/batch = 0.6756s	
4588/25300 (epoch 9.067), train_loss = 1.40727794, grad/param norm = 1.8288e-01, time/batch = 0.6742s	
4589/25300 (epoch 9.069), train_loss = 1.26724705, grad/param norm = 1.7313e-01, time/batch = 0.6721s	
4590/25300 (epoch 9.071), train_loss = 1.40453410, grad/param norm = 1.7474e-01, time/batch = 0.6760s	
4591/25300 (epoch 9.073), train_loss = 1.22909208, grad/param norm = 1.6944e-01, time/batch = 0.6763s	
4592/25300 (epoch 9.075), train_loss = 1.28044249, grad/param norm = 1.6793e-01, time/batch = 0.6781s	
4593/25300 (epoch 9.077), train_loss = 1.34574987, grad/param norm = 1.8411e-01, time/batch = 0.6751s	
4594/25300 (epoch 9.079), train_loss = 1.29746875, grad/param norm = 1.7881e-01, time/batch = 0.6765s	
4595/25300 (epoch 9.081), train_loss = 1.23214024, grad/param norm = 1.7124e-01, time/batch = 0.6755s	
4596/25300 (epoch 9.083), train_loss = 1.18080383, grad/param norm = 1.6864e-01, time/batch = 0.6841s	
4597/25300 (epoch 9.085), train_loss = 1.48080197, grad/param norm = 1.9564e-01, time/batch = 0.6830s	
4598/25300 (epoch 9.087), train_loss = 1.26835168, grad/param norm = 1.9543e-01, time/batch = 0.6841s	
4599/25300 (epoch 9.089), train_loss = 1.29411656, grad/param norm = 1.7214e-01, time/batch = 0.6775s	
4600/25300 (epoch 9.091), train_loss = 1.40699301, grad/param norm = 1.8587e-01, time/batch = 0.6762s	
4601/25300 (epoch 9.093), train_loss = 1.43720815, grad/param norm = 1.9389e-01, time/batch = 0.6789s	
4602/25300 (epoch 9.095), train_loss = 1.33025689, grad/param norm = 1.7046e-01, time/batch = 0.6779s	
4603/25300 (epoch 9.097), train_loss = 1.29512363, grad/param norm = 1.7497e-01, time/batch = 0.6778s	
4604/25300 (epoch 9.099), train_loss = 1.31224635, grad/param norm = 1.8861e-01, time/batch = 0.6752s	
4605/25300 (epoch 9.101), train_loss = 1.25824997, grad/param norm = 1.7692e-01, time/batch = 0.6831s	
4606/25300 (epoch 9.103), train_loss = 1.20458220, grad/param norm = 1.6331e-01, time/batch = 0.6858s	
4607/25300 (epoch 9.105), train_loss = 1.30667258, grad/param norm = 1.8677e-01, time/batch = 0.6878s	
4608/25300 (epoch 9.107), train_loss = 1.39876930, grad/param norm = 1.9356e-01, time/batch = 0.6791s	
4609/25300 (epoch 9.109), train_loss = 1.31329142, grad/param norm = 1.8813e-01, time/batch = 0.6770s	
4610/25300 (epoch 9.111), train_loss = 1.21836258, grad/param norm = 1.6597e-01, time/batch = 0.6759s	
4611/25300 (epoch 9.113), train_loss = 1.28037094, grad/param norm = 1.7892e-01, time/batch = 0.6770s	
4612/25300 (epoch 9.115), train_loss = 1.24707765, grad/param norm = 1.6589e-01, time/batch = 0.6761s	
4613/25300 (epoch 9.117), train_loss = 1.34782755, grad/param norm = 1.7596e-01, time/batch = 0.6742s	
4614/25300 (epoch 9.119), train_loss = 1.24850972, grad/param norm = 1.8194e-01, time/batch = 0.6752s	
4615/25300 (epoch 9.121), train_loss = 1.39271738, grad/param norm = 2.1041e-01, time/batch = 0.6902s	
4616/25300 (epoch 9.123), train_loss = 1.27291472, grad/param norm = 1.8795e-01, time/batch = 0.6766s	
4617/25300 (epoch 9.125), train_loss = 1.39868463, grad/param norm = 2.0167e-01, time/batch = 0.6773s	
4618/25300 (epoch 9.126), train_loss = 1.29470468, grad/param norm = 1.8984e-01, time/batch = 0.6766s	
4619/25300 (epoch 9.128), train_loss = 1.30709980, grad/param norm = 1.7630e-01, time/batch = 0.6793s	
4620/25300 (epoch 9.130), train_loss = 1.00018716, grad/param norm = 1.5106e-01, time/batch = 0.6750s	
4621/25300 (epoch 9.132), train_loss = 1.12927638, grad/param norm = 1.6484e-01, time/batch = 0.6806s	
4622/25300 (epoch 9.134), train_loss = 1.01157626, grad/param norm = 1.5576e-01, time/batch = 0.6816s	
4623/25300 (epoch 9.136), train_loss = 1.31849650, grad/param norm = 1.7006e-01, time/batch = 0.6800s	
4624/25300 (epoch 9.138), train_loss = 1.12055809, grad/param norm = 1.6706e-01, time/batch = 0.6769s	
4625/25300 (epoch 9.140), train_loss = 1.17267307, grad/param norm = 1.6424e-01, time/batch = 0.6766s	
4626/25300 (epoch 9.142), train_loss = 1.36586138, grad/param norm = 1.8088e-01, time/batch = 0.6771s	
4627/25300 (epoch 9.144), train_loss = 1.29000486, grad/param norm = 1.8553e-01, time/batch = 0.6746s	
4628/25300 (epoch 9.146), train_loss = 1.41115896, grad/param norm = 1.9746e-01, time/batch = 0.6735s	
4629/25300 (epoch 9.148), train_loss = 1.28211298, grad/param norm = 1.7599e-01, time/batch = 0.6754s	
4630/25300 (epoch 9.150), train_loss = 1.39434339, grad/param norm = 2.0828e-01, time/batch = 0.6740s	
4631/25300 (epoch 9.152), train_loss = 1.54185575, grad/param norm = 1.9595e-01, time/batch = 0.6754s	
4632/25300 (epoch 9.154), train_loss = 1.17181972, grad/param norm = 1.8544e-01, time/batch = 0.6730s	
4633/25300 (epoch 9.156), train_loss = 1.32000417, grad/param norm = 1.7439e-01, time/batch = 0.6753s	
4634/25300 (epoch 9.158), train_loss = 1.19934915, grad/param norm = 1.6850e-01, time/batch = 0.6744s	
4635/25300 (epoch 9.160), train_loss = 1.28776728, grad/param norm = 1.7399e-01, time/batch = 0.6756s	
4636/25300 (epoch 9.162), train_loss = 1.20738664, grad/param norm = 1.8639e-01, time/batch = 0.6762s	
4637/25300 (epoch 9.164), train_loss = 1.33813886, grad/param norm = 1.8486e-01, time/batch = 0.6743s	
4638/25300 (epoch 9.166), train_loss = 1.31217997, grad/param norm = 1.8807e-01, time/batch = 0.6713s	
4639/25300 (epoch 9.168), train_loss = 1.10982825, grad/param norm = 1.5304e-01, time/batch = 0.6728s	
4640/25300 (epoch 9.170), train_loss = 1.18645281, grad/param norm = 1.6298e-01, time/batch = 0.6729s	
4641/25300 (epoch 9.172), train_loss = 1.15850395, grad/param norm = 1.7066e-01, time/batch = 0.6797s	
4642/25300 (epoch 9.174), train_loss = 1.14120135, grad/param norm = 1.7246e-01, time/batch = 0.6721s	
4643/25300 (epoch 9.176), train_loss = 1.24293820, grad/param norm = 1.8258e-01, time/batch = 0.6728s	
4644/25300 (epoch 9.178), train_loss = 1.43816020, grad/param norm = 1.8891e-01, time/batch = 0.6721s	
4645/25300 (epoch 9.180), train_loss = 1.04188007, grad/param norm = 1.6444e-01, time/batch = 0.6728s	
4646/25300 (epoch 9.182), train_loss = 1.18735118, grad/param norm = 1.6143e-01, time/batch = 0.6718s	
4647/25300 (epoch 9.184), train_loss = 1.26497058, grad/param norm = 1.8688e-01, time/batch = 0.6686s	
4648/25300 (epoch 9.186), train_loss = 1.21141383, grad/param norm = 1.8230e-01, time/batch = 0.6695s	
4649/25300 (epoch 9.188), train_loss = 1.23875866, grad/param norm = 1.7593e-01, time/batch = 0.6708s	
4650/25300 (epoch 9.190), train_loss = 1.32070447, grad/param norm = 1.9123e-01, time/batch = 0.6695s	
4651/25300 (epoch 9.192), train_loss = 1.22722249, grad/param norm = 1.7957e-01, time/batch = 0.6701s	
4652/25300 (epoch 9.194), train_loss = 1.23899209, grad/param norm = 1.8380e-01, time/batch = 0.6720s	
4653/25300 (epoch 9.196), train_loss = 1.36952625, grad/param norm = 2.1214e-01, time/batch = 0.6709s	
4654/25300 (epoch 9.198), train_loss = 1.21541396, grad/param norm = 1.9200e-01, time/batch = 0.6753s	
4655/25300 (epoch 9.200), train_loss = 1.30198287, grad/param norm = 2.0281e-01, time/batch = 0.6721s	
4656/25300 (epoch 9.202), train_loss = 1.30508421, grad/param norm = 1.9012e-01, time/batch = 0.6736s	
4657/25300 (epoch 9.204), train_loss = 1.24563980, grad/param norm = 1.7983e-01, time/batch = 0.6871s	
4658/25300 (epoch 9.206), train_loss = 1.32366125, grad/param norm = 1.8763e-01, time/batch = 0.6861s	
4659/25300 (epoch 9.208), train_loss = 1.14991533, grad/param norm = 2.0073e-01, time/batch = 0.6794s	
4660/25300 (epoch 9.209), train_loss = 1.04016550, grad/param norm = 1.5806e-01, time/batch = 0.6801s	
4661/25300 (epoch 9.211), train_loss = 1.24067098, grad/param norm = 1.6998e-01, time/batch = 0.6882s	
4662/25300 (epoch 9.213), train_loss = 1.32010969, grad/param norm = 2.0060e-01, time/batch = 0.6996s	
4663/25300 (epoch 9.215), train_loss = 1.29524257, grad/param norm = 1.9840e-01, time/batch = 0.6824s	
4664/25300 (epoch 9.217), train_loss = 1.33844811, grad/param norm = 1.9539e-01, time/batch = 0.6764s	
4665/25300 (epoch 9.219), train_loss = 1.33468223, grad/param norm = 1.9086e-01, time/batch = 0.6780s	
4666/25300 (epoch 9.221), train_loss = 1.38928912, grad/param norm = 1.8985e-01, time/batch = 0.6832s	
4667/25300 (epoch 9.223), train_loss = 1.36441818, grad/param norm = 1.9637e-01, time/batch = 0.6802s	
4668/25300 (epoch 9.225), train_loss = 1.80067044, grad/param norm = 2.3098e-01, time/batch = 0.6761s	
4669/25300 (epoch 9.227), train_loss = 1.37066030, grad/param norm = 1.8053e-01, time/batch = 0.6770s	
4670/25300 (epoch 9.229), train_loss = 1.33040350, grad/param norm = 1.9760e-01, time/batch = 0.6750s	
4671/25300 (epoch 9.231), train_loss = 1.28661215, grad/param norm = 1.7672e-01, time/batch = 0.6812s	
4672/25300 (epoch 9.233), train_loss = 1.32116298, grad/param norm = 1.7877e-01, time/batch = 0.6812s	
4673/25300 (epoch 9.235), train_loss = 1.28091530, grad/param norm = 1.8512e-01, time/batch = 0.6793s	
4674/25300 (epoch 9.237), train_loss = 1.42773090, grad/param norm = 1.9022e-01, time/batch = 0.6788s	
4675/25300 (epoch 9.239), train_loss = 1.30255538, grad/param norm = 1.8393e-01, time/batch = 0.6782s	
4676/25300 (epoch 9.241), train_loss = 1.37652503, grad/param norm = 1.8729e-01, time/batch = 0.6774s	
4677/25300 (epoch 9.243), train_loss = 1.64361935, grad/param norm = 2.0645e-01, time/batch = 0.6792s	
4678/25300 (epoch 9.245), train_loss = 1.19332594, grad/param norm = 1.7593e-01, time/batch = 0.6757s	
4679/25300 (epoch 9.247), train_loss = 1.42136742, grad/param norm = 1.8180e-01, time/batch = 0.6750s	
4680/25300 (epoch 9.249), train_loss = 1.11271567, grad/param norm = 1.6180e-01, time/batch = 0.6775s	
4681/25300 (epoch 9.251), train_loss = 1.09648398, grad/param norm = 1.6889e-01, time/batch = 0.6850s	
4682/25300 (epoch 9.253), train_loss = 1.27377805, grad/param norm = 1.7589e-01, time/batch = 0.6768s	
4683/25300 (epoch 9.255), train_loss = 1.22334238, grad/param norm = 1.8257e-01, time/batch = 0.6725s	
4684/25300 (epoch 9.257), train_loss = 1.37703392, grad/param norm = 1.8952e-01, time/batch = 0.6736s	
4685/25300 (epoch 9.259), train_loss = 1.54026800, grad/param norm = 2.0511e-01, time/batch = 0.6815s	
4686/25300 (epoch 9.261), train_loss = 1.44695577, grad/param norm = 2.0182e-01, time/batch = 0.6739s	
4687/25300 (epoch 9.263), train_loss = 1.40744744, grad/param norm = 1.8518e-01, time/batch = 0.6810s	
4688/25300 (epoch 9.265), train_loss = 1.49399589, grad/param norm = 1.9796e-01, time/batch = 0.6753s	
4689/25300 (epoch 9.267), train_loss = 1.39778822, grad/param norm = 1.7435e-01, time/batch = 0.6740s	
4690/25300 (epoch 9.269), train_loss = 1.11617234, grad/param norm = 1.5879e-01, time/batch = 0.6724s	
4691/25300 (epoch 9.271), train_loss = 1.20825776, grad/param norm = 1.8774e-01, time/batch = 0.6773s	
4692/25300 (epoch 9.273), train_loss = 1.32839348, grad/param norm = 1.7786e-01, time/batch = 0.6782s	
4693/25300 (epoch 9.275), train_loss = 1.14327325, grad/param norm = 1.5977e-01, time/batch = 0.6818s	
4694/25300 (epoch 9.277), train_loss = 1.25709061, grad/param norm = 1.8115e-01, time/batch = 0.6850s	
4695/25300 (epoch 9.279), train_loss = 1.30461923, grad/param norm = 1.8744e-01, time/batch = 0.6881s	
4696/25300 (epoch 9.281), train_loss = 1.43541511, grad/param norm = 1.9856e-01, time/batch = 0.6748s	
4697/25300 (epoch 9.283), train_loss = 1.16781690, grad/param norm = 1.8182e-01, time/batch = 0.6905s	
4698/25300 (epoch 9.285), train_loss = 1.29907422, grad/param norm = 1.9989e-01, time/batch = 0.6856s	
4699/25300 (epoch 9.287), train_loss = 1.28211562, grad/param norm = 1.7785e-01, time/batch = 0.6808s	
4700/25300 (epoch 9.289), train_loss = 1.21385435, grad/param norm = 1.7232e-01, time/batch = 0.6955s	
4701/25300 (epoch 9.291), train_loss = 1.21244771, grad/param norm = 1.8679e-01, time/batch = 0.6805s	
4702/25300 (epoch 9.292), train_loss = 1.39558906, grad/param norm = 1.9493e-01, time/batch = 0.6871s	
4703/25300 (epoch 9.294), train_loss = 1.30007799, grad/param norm = 1.7523e-01, time/batch = 0.6781s	
4704/25300 (epoch 9.296), train_loss = 1.13299431, grad/param norm = 1.8224e-01, time/batch = 0.6782s	
4705/25300 (epoch 9.298), train_loss = 1.37880685, grad/param norm = 1.9062e-01, time/batch = 0.6753s	
4706/25300 (epoch 9.300), train_loss = 1.47175952, grad/param norm = 2.0638e-01, time/batch = 0.6764s	
4707/25300 (epoch 9.302), train_loss = 1.09794741, grad/param norm = 1.7783e-01, time/batch = 0.6764s	
4708/25300 (epoch 9.304), train_loss = 1.30488737, grad/param norm = 1.8317e-01, time/batch = 0.6760s	
4709/25300 (epoch 9.306), train_loss = 1.02448587, grad/param norm = 1.5438e-01, time/batch = 0.6765s	
4710/25300 (epoch 9.308), train_loss = 1.32012868, grad/param norm = 1.6804e-01, time/batch = 0.6768s	
4711/25300 (epoch 9.310), train_loss = 1.20088816, grad/param norm = 1.9036e-01, time/batch = 0.6823s	
4712/25300 (epoch 9.312), train_loss = 1.26531636, grad/param norm = 1.7935e-01, time/batch = 0.6831s	
4713/25300 (epoch 9.314), train_loss = 1.02309515, grad/param norm = 1.6575e-01, time/batch = 0.6837s	
4714/25300 (epoch 9.316), train_loss = 1.31012938, grad/param norm = 1.7895e-01, time/batch = 0.6848s	
4715/25300 (epoch 9.318), train_loss = 0.99322808, grad/param norm = 1.6421e-01, time/batch = 0.6840s	
4716/25300 (epoch 9.320), train_loss = 1.12662205, grad/param norm = 1.6068e-01, time/batch = 0.6817s	
4717/25300 (epoch 9.322), train_loss = 1.58751745, grad/param norm = 2.1398e-01, time/batch = 0.6783s	
4718/25300 (epoch 9.324), train_loss = 1.14309082, grad/param norm = 1.6975e-01, time/batch = 0.6719s	
4719/25300 (epoch 9.326), train_loss = 1.01216798, grad/param norm = 1.5491e-01, time/batch = 0.6741s	
4720/25300 (epoch 9.328), train_loss = 1.03054977, grad/param norm = 1.6677e-01, time/batch = 0.6717s	
4721/25300 (epoch 9.330), train_loss = 1.19995950, grad/param norm = 1.7365e-01, time/batch = 0.6758s	
4722/25300 (epoch 9.332), train_loss = 1.31148247, grad/param norm = 1.6770e-01, time/batch = 0.6745s	
4723/25300 (epoch 9.334), train_loss = 1.11610400, grad/param norm = 1.5897e-01, time/batch = 0.6711s	
4724/25300 (epoch 9.336), train_loss = 1.07861022, grad/param norm = 1.8274e-01, time/batch = 0.6739s	
4725/25300 (epoch 9.338), train_loss = 1.09586032, grad/param norm = 1.8413e-01, time/batch = 0.6742s	
4726/25300 (epoch 9.340), train_loss = 1.20397617, grad/param norm = 1.8675e-01, time/batch = 0.6711s	
4727/25300 (epoch 9.342), train_loss = 1.19569544, grad/param norm = 1.8661e-01, time/batch = 0.6704s	
4728/25300 (epoch 9.344), train_loss = 1.23326303, grad/param norm = 1.7591e-01, time/batch = 0.6747s	
4729/25300 (epoch 9.346), train_loss = 1.23122135, grad/param norm = 1.7604e-01, time/batch = 0.6766s	
4730/25300 (epoch 9.348), train_loss = 1.10323817, grad/param norm = 1.5900e-01, time/batch = 0.6782s	
4731/25300 (epoch 9.350), train_loss = 1.20149890, grad/param norm = 1.7582e-01, time/batch = 0.6812s	
4732/25300 (epoch 9.352), train_loss = 1.26088919, grad/param norm = 1.7393e-01, time/batch = 0.6834s	
4733/25300 (epoch 9.354), train_loss = 1.21180488, grad/param norm = 1.8188e-01, time/batch = 0.6748s	
4734/25300 (epoch 9.356), train_loss = 1.27668329, grad/param norm = 1.8099e-01, time/batch = 0.6767s	
4735/25300 (epoch 9.358), train_loss = 1.38604567, grad/param norm = 1.9560e-01, time/batch = 0.6741s	
4736/25300 (epoch 9.360), train_loss = 1.14395902, grad/param norm = 1.8665e-01, time/batch = 0.6765s	
4737/25300 (epoch 9.362), train_loss = 1.22804694, grad/param norm = 1.7753e-01, time/batch = 0.6748s	
4738/25300 (epoch 9.364), train_loss = 1.33970811, grad/param norm = 1.8924e-01, time/batch = 0.6738s	
4739/25300 (epoch 9.366), train_loss = 1.10805366, grad/param norm = 1.6333e-01, time/batch = 0.6755s	
4740/25300 (epoch 9.368), train_loss = 1.22156926, grad/param norm = 1.6568e-01, time/batch = 0.6744s	
4741/25300 (epoch 9.370), train_loss = 1.26838630, grad/param norm = 2.0571e-01, time/batch = 0.6763s	
4742/25300 (epoch 9.372), train_loss = 1.20027178, grad/param norm = 1.8222e-01, time/batch = 0.6748s	
4743/25300 (epoch 9.374), train_loss = 1.13640600, grad/param norm = 1.6547e-01, time/batch = 0.6777s	
4744/25300 (epoch 9.375), train_loss = 1.48307190, grad/param norm = 2.0167e-01, time/batch = 0.6757s	
4745/25300 (epoch 9.377), train_loss = 1.26112653, grad/param norm = 1.8054e-01, time/batch = 0.6726s	
4746/25300 (epoch 9.379), train_loss = 1.41705173, grad/param norm = 1.9625e-01, time/batch = 0.6805s	
4747/25300 (epoch 9.381), train_loss = 1.24656901, grad/param norm = 1.6028e-01, time/batch = 0.6800s	
4748/25300 (epoch 9.383), train_loss = 1.13904459, grad/param norm = 1.7893e-01, time/batch = 0.6739s	
4749/25300 (epoch 9.385), train_loss = 1.19601514, grad/param norm = 1.6894e-01, time/batch = 0.6726s	
4750/25300 (epoch 9.387), train_loss = 1.34593173, grad/param norm = 1.9173e-01, time/batch = 0.6734s	
4751/25300 (epoch 9.389), train_loss = 1.41208618, grad/param norm = 2.0026e-01, time/batch = 0.6685s	
4752/25300 (epoch 9.391), train_loss = 1.12720028, grad/param norm = 1.6123e-01, time/batch = 0.6751s	
4753/25300 (epoch 9.393), train_loss = 1.29505909, grad/param norm = 1.7448e-01, time/batch = 0.6769s	
4754/25300 (epoch 9.395), train_loss = 1.07622624, grad/param norm = 1.6414e-01, time/batch = 0.6721s	
4755/25300 (epoch 9.397), train_loss = 1.12390769, grad/param norm = 1.7896e-01, time/batch = 0.6725s	
4756/25300 (epoch 9.399), train_loss = 1.11593683, grad/param norm = 1.6227e-01, time/batch = 0.6740s	
4757/25300 (epoch 9.401), train_loss = 1.39738469, grad/param norm = 1.9033e-01, time/batch = 0.6731s	
4758/25300 (epoch 9.403), train_loss = 1.27325032, grad/param norm = 1.9986e-01, time/batch = 0.6715s	
4759/25300 (epoch 9.405), train_loss = 1.28810000, grad/param norm = 1.9858e-01, time/batch = 0.6732s	
4760/25300 (epoch 9.407), train_loss = 1.15447622, grad/param norm = 1.7083e-01, time/batch = 0.6706s	
4761/25300 (epoch 9.409), train_loss = 1.17102378, grad/param norm = 1.6425e-01, time/batch = 0.6781s	
4762/25300 (epoch 9.411), train_loss = 1.23631415, grad/param norm = 1.7623e-01, time/batch = 0.6772s	
4763/25300 (epoch 9.413), train_loss = 1.11977525, grad/param norm = 1.7155e-01, time/batch = 0.6727s	
4764/25300 (epoch 9.415), train_loss = 1.10994883, grad/param norm = 1.6901e-01, time/batch = 0.6728s	
4765/25300 (epoch 9.417), train_loss = 1.07910090, grad/param norm = 1.6124e-01, time/batch = 0.6745s	
4766/25300 (epoch 9.419), train_loss = 1.04985159, grad/param norm = 1.7811e-01, time/batch = 0.6703s	
4767/25300 (epoch 9.421), train_loss = 1.04001787, grad/param norm = 1.5217e-01, time/batch = 0.6722s	
4768/25300 (epoch 9.423), train_loss = 1.14023769, grad/param norm = 1.6710e-01, time/batch = 0.6750s	
4769/25300 (epoch 9.425), train_loss = 1.21140141, grad/param norm = 1.8781e-01, time/batch = 0.6734s	
4770/25300 (epoch 9.427), train_loss = 1.47199173, grad/param norm = 1.8684e-01, time/batch = 0.6749s	
4771/25300 (epoch 9.429), train_loss = 1.37410875, grad/param norm = 1.9544e-01, time/batch = 0.6777s	
4772/25300 (epoch 9.431), train_loss = 1.25616571, grad/param norm = 1.7921e-01, time/batch = 0.6762s	
4773/25300 (epoch 9.433), train_loss = 1.20727124, grad/param norm = 1.7559e-01, time/batch = 0.6738s	
4774/25300 (epoch 9.435), train_loss = 1.13586126, grad/param norm = 1.8133e-01, time/batch = 0.6765s	
4775/25300 (epoch 9.437), train_loss = 1.18147747, grad/param norm = 1.6912e-01, time/batch = 0.6800s	
4776/25300 (epoch 9.439), train_loss = 1.23520742, grad/param norm = 1.7345e-01, time/batch = 0.6761s	
4777/25300 (epoch 9.441), train_loss = 1.26293139, grad/param norm = 1.9186e-01, time/batch = 0.6779s	
4778/25300 (epoch 9.443), train_loss = 1.48446273, grad/param norm = 2.1594e-01, time/batch = 0.6774s	
4779/25300 (epoch 9.445), train_loss = 1.39006583, grad/param norm = 1.8574e-01, time/batch = 0.6744s	
4780/25300 (epoch 9.447), train_loss = 1.15977909, grad/param norm = 1.8258e-01, time/batch = 0.6743s	
4781/25300 (epoch 9.449), train_loss = 1.05807426, grad/param norm = 1.7020e-01, time/batch = 0.6762s	
4782/25300 (epoch 9.451), train_loss = 1.42573144, grad/param norm = 1.9406e-01, time/batch = 0.6850s	
4783/25300 (epoch 9.453), train_loss = 1.33336094, grad/param norm = 1.8439e-01, time/batch = 0.6897s	
4784/25300 (epoch 9.455), train_loss = 1.41753755, grad/param norm = 1.8213e-01, time/batch = 0.7091s	
4785/25300 (epoch 9.457), train_loss = 1.21925273, grad/param norm = 1.7591e-01, time/batch = 0.6876s	
4786/25300 (epoch 9.458), train_loss = 1.29191232, grad/param norm = 1.9289e-01, time/batch = 0.6781s	
4787/25300 (epoch 9.460), train_loss = 1.29071999, grad/param norm = 2.0335e-01, time/batch = 0.6810s	
4788/25300 (epoch 9.462), train_loss = 1.03418934, grad/param norm = 1.6676e-01, time/batch = 0.6797s	
4789/25300 (epoch 9.464), train_loss = 1.30936010, grad/param norm = 1.8710e-01, time/batch = 0.6768s	
4790/25300 (epoch 9.466), train_loss = 1.34551688, grad/param norm = 1.9495e-01, time/batch = 0.6731s	
4791/25300 (epoch 9.468), train_loss = 1.39210219, grad/param norm = 1.9281e-01, time/batch = 0.6773s	
4792/25300 (epoch 9.470), train_loss = 1.13624414, grad/param norm = 1.6219e-01, time/batch = 0.6742s	
4793/25300 (epoch 9.472), train_loss = 1.03014135, grad/param norm = 1.5939e-01, time/batch = 0.6734s	
4794/25300 (epoch 9.474), train_loss = 1.29276710, grad/param norm = 1.8965e-01, time/batch = 0.6710s	
4795/25300 (epoch 9.476), train_loss = 1.21657219, grad/param norm = 1.6731e-01, time/batch = 0.6706s	
4796/25300 (epoch 9.478), train_loss = 1.32304004, grad/param norm = 1.9479e-01, time/batch = 0.6743s	
4797/25300 (epoch 9.480), train_loss = 1.14431920, grad/param norm = 1.7033e-01, time/batch = 0.6778s	
4798/25300 (epoch 9.482), train_loss = 1.42428133, grad/param norm = 2.0561e-01, time/batch = 0.6741s	
4799/25300 (epoch 9.484), train_loss = 1.33611358, grad/param norm = 1.8605e-01, time/batch = 0.6724s	
4800/25300 (epoch 9.486), train_loss = 1.26697937, grad/param norm = 1.7733e-01, time/batch = 0.6708s	
4801/25300 (epoch 9.488), train_loss = 1.34968294, grad/param norm = 1.8345e-01, time/batch = 0.6725s	
4802/25300 (epoch 9.490), train_loss = 1.32647499, grad/param norm = 1.8130e-01, time/batch = 0.6747s	
4803/25300 (epoch 9.492), train_loss = 1.19001746, grad/param norm = 1.6450e-01, time/batch = 0.6946s	
4804/25300 (epoch 9.494), train_loss = 1.11302287, grad/param norm = 1.7013e-01, time/batch = 0.6850s	
4805/25300 (epoch 9.496), train_loss = 1.25265834, grad/param norm = 1.7900e-01, time/batch = 0.6787s	
4806/25300 (epoch 9.498), train_loss = 1.15155646, grad/param norm = 1.7675e-01, time/batch = 0.6762s	
4807/25300 (epoch 9.500), train_loss = 1.42060762, grad/param norm = 1.9079e-01, time/batch = 0.6738s	
4808/25300 (epoch 9.502), train_loss = 1.24899719, grad/param norm = 1.8421e-01, time/batch = 0.6809s	
4809/25300 (epoch 9.504), train_loss = 1.18920368, grad/param norm = 1.8453e-01, time/batch = 0.6774s	
4810/25300 (epoch 9.506), train_loss = 1.19838822, grad/param norm = 1.7179e-01, time/batch = 0.6756s	
4811/25300 (epoch 9.508), train_loss = 1.27783828, grad/param norm = 1.9028e-01, time/batch = 0.6745s	
4812/25300 (epoch 9.510), train_loss = 1.18107797, grad/param norm = 1.8999e-01, time/batch = 0.6770s	
4813/25300 (epoch 9.512), train_loss = 0.95335652, grad/param norm = 1.5157e-01, time/batch = 0.6744s	
4814/25300 (epoch 9.514), train_loss = 1.15810912, grad/param norm = 1.6629e-01, time/batch = 0.6742s	
4815/25300 (epoch 9.516), train_loss = 1.24021879, grad/param norm = 1.7728e-01, time/batch = 0.6738s	
4816/25300 (epoch 9.518), train_loss = 1.30168067, grad/param norm = 1.8165e-01, time/batch = 0.6741s	
4817/25300 (epoch 9.520), train_loss = 1.04559145, grad/param norm = 1.6154e-01, time/batch = 0.6741s	
4818/25300 (epoch 9.522), train_loss = 1.16158754, grad/param norm = 1.6977e-01, time/batch = 0.6719s	
4819/25300 (epoch 9.524), train_loss = 1.18735984, grad/param norm = 1.7230e-01, time/batch = 0.6732s	
4820/25300 (epoch 9.526), train_loss = 1.49212047, grad/param norm = 1.9520e-01, time/batch = 0.6801s	
4821/25300 (epoch 9.528), train_loss = 1.38041450, grad/param norm = 1.9266e-01, time/batch = 0.6727s	
4822/25300 (epoch 9.530), train_loss = 1.24971056, grad/param norm = 1.8899e-01, time/batch = 0.6699s	
4823/25300 (epoch 9.532), train_loss = 1.27546985, grad/param norm = 1.9154e-01, time/batch = 0.6734s	
4824/25300 (epoch 9.534), train_loss = 1.18950150, grad/param norm = 1.7709e-01, time/batch = 0.6778s	
4825/25300 (epoch 9.536), train_loss = 1.08069480, grad/param norm = 1.7722e-01, time/batch = 0.6815s	
4826/25300 (epoch 9.538), train_loss = 1.05016242, grad/param norm = 1.4808e-01, time/batch = 0.6829s	
4827/25300 (epoch 9.540), train_loss = 1.13532618, grad/param norm = 1.7051e-01, time/batch = 0.6839s	
4828/25300 (epoch 9.542), train_loss = 1.13090934, grad/param norm = 1.7731e-01, time/batch = 0.6823s	
4829/25300 (epoch 9.543), train_loss = 1.07578587, grad/param norm = 1.6885e-01, time/batch = 0.6789s	
4830/25300 (epoch 9.545), train_loss = 1.62727111, grad/param norm = 2.1777e-01, time/batch = 0.6828s	
4831/25300 (epoch 9.547), train_loss = 1.25454616, grad/param norm = 1.8720e-01, time/batch = 0.6824s	
4832/25300 (epoch 9.549), train_loss = 1.51259950, grad/param norm = 1.9895e-01, time/batch = 0.6826s	
4833/25300 (epoch 9.551), train_loss = 1.27539049, grad/param norm = 1.8195e-01, time/batch = 0.6802s	
4834/25300 (epoch 9.553), train_loss = 1.23728498, grad/param norm = 1.7954e-01, time/batch = 0.6787s	
4835/25300 (epoch 9.555), train_loss = 1.36568543, grad/param norm = 1.8312e-01, time/batch = 0.6763s	
4836/25300 (epoch 9.557), train_loss = 1.39632424, grad/param norm = 1.8831e-01, time/batch = 0.6737s	
4837/25300 (epoch 9.559), train_loss = 1.42056882, grad/param norm = 1.9943e-01, time/batch = 0.6712s	
4838/25300 (epoch 9.561), train_loss = 1.44432801, grad/param norm = 1.9471e-01, time/batch = 0.6715s	
4839/25300 (epoch 9.563), train_loss = 1.36238012, grad/param norm = 1.8940e-01, time/batch = 0.6718s	
4840/25300 (epoch 9.565), train_loss = 1.09454913, grad/param norm = 1.7585e-01, time/batch = 0.6688s	
4841/25300 (epoch 9.567), train_loss = 0.94141345, grad/param norm = 1.6719e-01, time/batch = 0.6744s	
4842/25300 (epoch 9.569), train_loss = 1.23150183, grad/param norm = 1.8888e-01, time/batch = 0.6740s	
4843/25300 (epoch 9.571), train_loss = 1.33185775, grad/param norm = 1.9187e-01, time/batch = 0.6710s	
4844/25300 (epoch 9.573), train_loss = 1.22395801, grad/param norm = 1.7929e-01, time/batch = 0.6740s	
4845/25300 (epoch 9.575), train_loss = 1.31945233, grad/param norm = 1.8442e-01, time/batch = 0.6742s	
4846/25300 (epoch 9.577), train_loss = 1.28460909, grad/param norm = 1.9058e-01, time/batch = 0.6735s	
4847/25300 (epoch 9.579), train_loss = 1.47231852, grad/param norm = 1.9651e-01, time/batch = 0.6756s	
4848/25300 (epoch 9.581), train_loss = 1.29134899, grad/param norm = 1.8247e-01, time/batch = 0.6766s	
4849/25300 (epoch 9.583), train_loss = 1.14155428, grad/param norm = 1.7594e-01, time/batch = 0.6761s	
4850/25300 (epoch 9.585), train_loss = 1.11105828, grad/param norm = 1.7382e-01, time/batch = 0.6764s	
4851/25300 (epoch 9.587), train_loss = 1.19384269, grad/param norm = 1.7609e-01, time/batch = 0.6809s	
4852/25300 (epoch 9.589), train_loss = 1.09591796, grad/param norm = 1.7588e-01, time/batch = 0.6759s	
4853/25300 (epoch 9.591), train_loss = 1.13666710, grad/param norm = 1.8874e-01, time/batch = 0.6738s	
4854/25300 (epoch 9.593), train_loss = 1.22655082, grad/param norm = 1.6520e-01, time/batch = 0.6758s	
4855/25300 (epoch 9.595), train_loss = 1.21642031, grad/param norm = 1.8181e-01, time/batch = 0.6750s	
4856/25300 (epoch 9.597), train_loss = 1.02160827, grad/param norm = 1.5429e-01, time/batch = 0.6735s	
4857/25300 (epoch 9.599), train_loss = 1.23549419, grad/param norm = 1.7442e-01, time/batch = 0.6774s	
4858/25300 (epoch 9.601), train_loss = 1.27695674, grad/param norm = 1.7349e-01, time/batch = 0.6746s	
4859/25300 (epoch 9.603), train_loss = 1.28122045, grad/param norm = 1.6995e-01, time/batch = 0.6772s	
4860/25300 (epoch 9.605), train_loss = 1.13519903, grad/param norm = 1.6734e-01, time/batch = 0.6785s	
4861/25300 (epoch 9.607), train_loss = 0.99815755, grad/param norm = 1.7244e-01, time/batch = 0.6728s	
4862/25300 (epoch 9.609), train_loss = 1.22239275, grad/param norm = 1.8150e-01, time/batch = 0.6757s	
4863/25300 (epoch 9.611), train_loss = 1.32527084, grad/param norm = 1.6937e-01, time/batch = 0.6775s	
4864/25300 (epoch 9.613), train_loss = 1.10570252, grad/param norm = 1.6840e-01, time/batch = 0.6781s	
4865/25300 (epoch 9.615), train_loss = 1.27238188, grad/param norm = 1.8054e-01, time/batch = 0.6832s	
4866/25300 (epoch 9.617), train_loss = 1.22870987, grad/param norm = 1.6656e-01, time/batch = 0.6749s	
4867/25300 (epoch 9.619), train_loss = 1.32485778, grad/param norm = 1.8716e-01, time/batch = 0.6740s	
4868/25300 (epoch 9.621), train_loss = 1.33081918, grad/param norm = 1.9910e-01, time/batch = 0.6755s	
4869/25300 (epoch 9.623), train_loss = 1.16724893, grad/param norm = 1.8582e-01, time/batch = 0.6755s	
4870/25300 (epoch 9.625), train_loss = 1.02585637, grad/param norm = 1.6831e-01, time/batch = 0.6809s	
4871/25300 (epoch 9.626), train_loss = 1.16439299, grad/param norm = 1.6727e-01, time/batch = 0.6910s	
4872/25300 (epoch 9.628), train_loss = 1.36893880, grad/param norm = 1.9579e-01, time/batch = 0.6900s	
4873/25300 (epoch 9.630), train_loss = 1.40016591, grad/param norm = 1.9791e-01, time/batch = 0.6764s	
4874/25300 (epoch 9.632), train_loss = 1.34130482, grad/param norm = 2.1111e-01, time/batch = 0.6815s	
4875/25300 (epoch 9.634), train_loss = 1.35918191, grad/param norm = 1.9119e-01, time/batch = 0.6793s	
4876/25300 (epoch 9.636), train_loss = 1.25228553, grad/param norm = 1.8909e-01, time/batch = 0.6773s	
4877/25300 (epoch 9.638), train_loss = 1.34998321, grad/param norm = 2.0098e-01, time/batch = 0.6869s	
4878/25300 (epoch 9.640), train_loss = 1.49423771, grad/param norm = 2.0967e-01, time/batch = 0.6988s	
4879/25300 (epoch 9.642), train_loss = 1.30397990, grad/param norm = 1.9721e-01, time/batch = 0.6747s	
4880/25300 (epoch 9.644), train_loss = 1.30582030, grad/param norm = 1.9893e-01, time/batch = 0.6744s	
4881/25300 (epoch 9.646), train_loss = 1.25866734, grad/param norm = 1.8607e-01, time/batch = 0.6783s	
4882/25300 (epoch 9.648), train_loss = 1.34175787, grad/param norm = 1.8040e-01, time/batch = 0.6738s	
4883/25300 (epoch 9.650), train_loss = 1.30210633, grad/param norm = 1.8596e-01, time/batch = 0.6787s	
4884/25300 (epoch 9.652), train_loss = 1.29601086, grad/param norm = 1.9106e-01, time/batch = 0.6804s	
4885/25300 (epoch 9.654), train_loss = 1.45178605, grad/param norm = 1.9103e-01, time/batch = 0.6832s	
4886/25300 (epoch 9.656), train_loss = 1.37350243, grad/param norm = 1.9066e-01, time/batch = 0.6797s	
4887/25300 (epoch 9.658), train_loss = 1.05766438, grad/param norm = 1.5785e-01, time/batch = 0.6858s	
4888/25300 (epoch 9.660), train_loss = 1.10987711, grad/param norm = 1.7449e-01, time/batch = 0.6711s	
4889/25300 (epoch 9.662), train_loss = 1.06707668, grad/param norm = 1.7210e-01, time/batch = 0.6724s	
4890/25300 (epoch 9.664), train_loss = 1.05621581, grad/param norm = 1.6583e-01, time/batch = 0.6746s	
4891/25300 (epoch 9.666), train_loss = 1.07808902, grad/param norm = 1.6511e-01, time/batch = 0.6796s	
4892/25300 (epoch 9.668), train_loss = 1.15070061, grad/param norm = 1.9056e-01, time/batch = 0.6727s	
4893/25300 (epoch 9.670), train_loss = 1.12719912, grad/param norm = 1.6983e-01, time/batch = 0.6771s	
4894/25300 (epoch 9.672), train_loss = 1.14201801, grad/param norm = 1.6743e-01, time/batch = 0.6789s	
4895/25300 (epoch 9.674), train_loss = 1.18114034, grad/param norm = 1.8129e-01, time/batch = 0.6745s	
4896/25300 (epoch 9.676), train_loss = 1.26048656, grad/param norm = 1.8175e-01, time/batch = 0.6748s	
4897/25300 (epoch 9.678), train_loss = 1.19280048, grad/param norm = 2.0398e-01, time/batch = 0.6707s	
4898/25300 (epoch 9.680), train_loss = 1.07373963, grad/param norm = 1.7779e-01, time/batch = 0.6765s	
4899/25300 (epoch 9.682), train_loss = 0.91364981, grad/param norm = 1.5535e-01, time/batch = 0.6744s	
4900/25300 (epoch 9.684), train_loss = 1.07997931, grad/param norm = 1.6048e-01, time/batch = 0.6744s	
4901/25300 (epoch 9.686), train_loss = 1.06998256, grad/param norm = 1.6017e-01, time/batch = 0.6734s	
4902/25300 (epoch 9.688), train_loss = 1.23115815, grad/param norm = 1.8006e-01, time/batch = 0.6728s	
4903/25300 (epoch 9.690), train_loss = 1.09921855, grad/param norm = 1.5813e-01, time/batch = 0.6730s	
4904/25300 (epoch 9.692), train_loss = 1.24628807, grad/param norm = 1.6907e-01, time/batch = 0.6761s	
4905/25300 (epoch 9.694), train_loss = 1.15807210, grad/param norm = 1.6367e-01, time/batch = 0.6735s	
4906/25300 (epoch 9.696), train_loss = 1.23898248, grad/param norm = 1.8625e-01, time/batch = 0.6775s	
4907/25300 (epoch 9.698), train_loss = 1.29179534, grad/param norm = 1.7759e-01, time/batch = 0.6755s	
4908/25300 (epoch 9.700), train_loss = 1.01925988, grad/param norm = 1.5852e-01, time/batch = 0.6751s	
4909/25300 (epoch 9.702), train_loss = 1.32108759, grad/param norm = 1.8514e-01, time/batch = 0.6760s	
4910/25300 (epoch 9.704), train_loss = 0.99829329, grad/param norm = 1.6095e-01, time/batch = 0.6766s	
4911/25300 (epoch 9.706), train_loss = 1.25039414, grad/param norm = 2.1173e-01, time/batch = 0.6779s	
4912/25300 (epoch 9.708), train_loss = 1.00149354, grad/param norm = 1.5689e-01, time/batch = 0.6770s	
4913/25300 (epoch 9.709), train_loss = 1.36794882, grad/param norm = 1.8520e-01, time/batch = 0.6759s	
4914/25300 (epoch 9.711), train_loss = 1.43397246, grad/param norm = 1.9235e-01, time/batch = 0.6775s	
4915/25300 (epoch 9.713), train_loss = 1.17052810, grad/param norm = 1.7643e-01, time/batch = 0.6816s	
4916/25300 (epoch 9.715), train_loss = 1.17593091, grad/param norm = 1.7949e-01, time/batch = 0.6760s	
4917/25300 (epoch 9.717), train_loss = 1.20724183, grad/param norm = 1.8787e-01, time/batch = 0.6747s	
4918/25300 (epoch 9.719), train_loss = 1.21717060, grad/param norm = 1.8508e-01, time/batch = 0.6720s	
4919/25300 (epoch 9.721), train_loss = 1.26267275, grad/param norm = 2.1137e-01, time/batch = 0.6741s	
4920/25300 (epoch 9.723), train_loss = 1.14100433, grad/param norm = 1.7687e-01, time/batch = 0.6747s	
4921/25300 (epoch 9.725), train_loss = 1.25468971, grad/param norm = 1.8267e-01, time/batch = 0.6741s	
4922/25300 (epoch 9.727), train_loss = 1.25000118, grad/param norm = 1.7815e-01, time/batch = 0.6745s	
4923/25300 (epoch 9.729), train_loss = 1.15777083, grad/param norm = 1.7392e-01, time/batch = 0.6768s	
4924/25300 (epoch 9.731), train_loss = 1.45127135, grad/param norm = 2.0088e-01, time/batch = 0.6709s	
4925/25300 (epoch 9.733), train_loss = 1.14150523, grad/param norm = 1.5931e-01, time/batch = 0.6733s	
4926/25300 (epoch 9.735), train_loss = 1.53609734, grad/param norm = 1.9985e-01, time/batch = 0.6727s	
4927/25300 (epoch 9.737), train_loss = 1.05014585, grad/param norm = 1.7024e-01, time/batch = 0.6734s	
4928/25300 (epoch 9.739), train_loss = 1.35653182, grad/param norm = 1.8483e-01, time/batch = 0.6757s	
4929/25300 (epoch 9.741), train_loss = 1.26637611, grad/param norm = 1.9499e-01, time/batch = 0.6738s	
4930/25300 (epoch 9.743), train_loss = 1.14092096, grad/param norm = 1.7094e-01, time/batch = 0.6746s	
4931/25300 (epoch 9.745), train_loss = 1.14827717, grad/param norm = 1.6851e-01, time/batch = 0.6738s	
4932/25300 (epoch 9.747), train_loss = 1.05484581, grad/param norm = 1.5327e-01, time/batch = 0.6750s	
4933/25300 (epoch 9.749), train_loss = 1.28505252, grad/param norm = 1.8672e-01, time/batch = 0.6707s	
4934/25300 (epoch 9.751), train_loss = 1.37990493, grad/param norm = 2.0939e-01, time/batch = 0.6696s	
4935/25300 (epoch 9.753), train_loss = 1.16151950, grad/param norm = 1.9364e-01, time/batch = 0.6712s	
4936/25300 (epoch 9.755), train_loss = 1.32854725, grad/param norm = 1.9829e-01, time/batch = 0.6717s	
4937/25300 (epoch 9.757), train_loss = 1.10474173, grad/param norm = 1.8828e-01, time/batch = 0.6750s	
4938/25300 (epoch 9.759), train_loss = 1.10424182, grad/param norm = 1.8502e-01, time/batch = 0.6744s	
4939/25300 (epoch 9.761), train_loss = 1.34874916, grad/param norm = 1.9383e-01, time/batch = 0.6738s	
4940/25300 (epoch 9.763), train_loss = 1.12336630, grad/param norm = 1.7486e-01, time/batch = 0.6764s	
4941/25300 (epoch 9.765), train_loss = 1.17551311, grad/param norm = 1.9274e-01, time/batch = 0.6785s	
4942/25300 (epoch 9.767), train_loss = 1.10131758, grad/param norm = 1.6962e-01, time/batch = 0.6763s	
4943/25300 (epoch 9.769), train_loss = 1.29117015, grad/param norm = 1.9377e-01, time/batch = 0.6775s	
4944/25300 (epoch 9.771), train_loss = 1.43000887, grad/param norm = 2.1233e-01, time/batch = 0.6761s	
4945/25300 (epoch 9.773), train_loss = 1.38103394, grad/param norm = 2.0144e-01, time/batch = 0.6755s	
4946/25300 (epoch 9.775), train_loss = 1.18159067, grad/param norm = 1.7047e-01, time/batch = 0.6749s	
4947/25300 (epoch 9.777), train_loss = 1.26628266, grad/param norm = 1.8342e-01, time/batch = 0.6734s	
4948/25300 (epoch 9.779), train_loss = 1.34416406, grad/param norm = 1.7342e-01, time/batch = 0.6708s	
4949/25300 (epoch 9.781), train_loss = 1.18516399, grad/param norm = 1.6506e-01, time/batch = 0.6747s	
4950/25300 (epoch 9.783), train_loss = 1.41994689, grad/param norm = 1.9963e-01, time/batch = 0.6740s	
4951/25300 (epoch 9.785), train_loss = 1.33315799, grad/param norm = 1.8401e-01, time/batch = 0.6733s	
4952/25300 (epoch 9.787), train_loss = 1.34302247, grad/param norm = 1.8053e-01, time/batch = 0.6796s	
4953/25300 (epoch 9.789), train_loss = 1.45898117, grad/param norm = 1.8589e-01, time/batch = 0.6767s	
4954/25300 (epoch 9.791), train_loss = 1.24187330, grad/param norm = 1.8659e-01, time/batch = 0.6722s	
4955/25300 (epoch 9.792), train_loss = 1.30564765, grad/param norm = 1.7182e-01, time/batch = 0.6808s	
4956/25300 (epoch 9.794), train_loss = 1.26916304, grad/param norm = 1.8729e-01, time/batch = 0.6744s	
4957/25300 (epoch 9.796), train_loss = 1.20572048, grad/param norm = 1.6612e-01, time/batch = 0.6753s	
4958/25300 (epoch 9.798), train_loss = 1.38933388, grad/param norm = 1.8522e-01, time/batch = 0.6813s	
4959/25300 (epoch 9.800), train_loss = 1.23810605, grad/param norm = 1.8648e-01, time/batch = 0.6840s	
4960/25300 (epoch 9.802), train_loss = 0.99423970, grad/param norm = 1.5935e-01, time/batch = 0.6860s	
4961/25300 (epoch 9.804), train_loss = 1.23558841, grad/param norm = 1.6958e-01, time/batch = 0.6760s	
4962/25300 (epoch 9.806), train_loss = 1.31770701, grad/param norm = 1.7973e-01, time/batch = 0.6769s	
4963/25300 (epoch 9.808), train_loss = 1.25670425, grad/param norm = 1.8314e-01, time/batch = 0.6762s	
4964/25300 (epoch 9.810), train_loss = 1.25302571, grad/param norm = 1.8743e-01, time/batch = 0.6749s	
4965/25300 (epoch 9.812), train_loss = 1.32181428, grad/param norm = 1.8766e-01, time/batch = 0.6753s	
4966/25300 (epoch 9.814), train_loss = 1.42813313, grad/param norm = 1.9341e-01, time/batch = 0.6764s	
4967/25300 (epoch 9.816), train_loss = 1.54290682, grad/param norm = 1.8962e-01, time/batch = 0.6797s	
4968/25300 (epoch 9.818), train_loss = 1.34190624, grad/param norm = 1.8739e-01, time/batch = 0.7005s	
4969/25300 (epoch 9.820), train_loss = 1.29542436, grad/param norm = 1.7757e-01, time/batch = 0.6729s	
4970/25300 (epoch 9.822), train_loss = 1.24938251, grad/param norm = 1.7656e-01, time/batch = 0.6744s	
4971/25300 (epoch 9.824), train_loss = 1.32287108, grad/param norm = 1.8293e-01, time/batch = 0.6773s	
4972/25300 (epoch 9.826), train_loss = 1.17436180, grad/param norm = 1.8572e-01, time/batch = 0.6763s	
4973/25300 (epoch 9.828), train_loss = 1.15694804, grad/param norm = 1.7932e-01, time/batch = 0.6754s	
4974/25300 (epoch 9.830), train_loss = 1.22911272, grad/param norm = 1.7489e-01, time/batch = 0.6787s	
4975/25300 (epoch 9.832), train_loss = 1.27346020, grad/param norm = 1.7694e-01, time/batch = 0.6731s	
4976/25300 (epoch 9.834), train_loss = 1.08007518, grad/param norm = 1.6129e-01, time/batch = 0.6729s	
4977/25300 (epoch 9.836), train_loss = 1.15646955, grad/param norm = 1.6594e-01, time/batch = 0.6691s	
4978/25300 (epoch 9.838), train_loss = 1.22120489, grad/param norm = 1.8102e-01, time/batch = 0.6682s	
4979/25300 (epoch 9.840), train_loss = 1.39837170, grad/param norm = 1.8564e-01, time/batch = 0.6738s	
4980/25300 (epoch 9.842), train_loss = 1.24637638, grad/param norm = 2.1986e-01, time/batch = 0.6709s	
4981/25300 (epoch 9.844), train_loss = 1.24178441, grad/param norm = 1.6762e-01, time/batch = 0.6744s	
4982/25300 (epoch 9.846), train_loss = 1.24422774, grad/param norm = 1.6891e-01, time/batch = 0.6744s	
4983/25300 (epoch 9.848), train_loss = 1.41339173, grad/param norm = 1.9014e-01, time/batch = 0.6749s	
4984/25300 (epoch 9.850), train_loss = 1.33906144, grad/param norm = 1.8710e-01, time/batch = 0.6765s	
4985/25300 (epoch 9.852), train_loss = 1.25825690, grad/param norm = 1.9123e-01, time/batch = 0.6728s	
4986/25300 (epoch 9.854), train_loss = 1.45463606, grad/param norm = 1.9967e-01, time/batch = 0.6756s	
4987/25300 (epoch 9.856), train_loss = 1.23732707, grad/param norm = 1.7875e-01, time/batch = 0.6777s	
4988/25300 (epoch 9.858), train_loss = 1.31555794, grad/param norm = 2.0456e-01, time/batch = 0.6754s	
4989/25300 (epoch 9.860), train_loss = 1.04017931, grad/param norm = 1.7083e-01, time/batch = 0.6759s	
4990/25300 (epoch 9.862), train_loss = 1.30699861, grad/param norm = 1.9889e-01, time/batch = 0.6764s	
4991/25300 (epoch 9.864), train_loss = 1.36419014, grad/param norm = 1.9508e-01, time/batch = 0.6799s	
4992/25300 (epoch 9.866), train_loss = 1.32485103, grad/param norm = 2.0990e-01, time/batch = 0.6800s	
4993/25300 (epoch 9.868), train_loss = 1.37748755, grad/param norm = 2.0265e-01, time/batch = 0.6764s	
4994/25300 (epoch 9.870), train_loss = 1.34200690, grad/param norm = 1.7189e-01, time/batch = 0.6749s	
4995/25300 (epoch 9.872), train_loss = 1.34646588, grad/param norm = 2.0105e-01, time/batch = 0.6732s	
4996/25300 (epoch 9.874), train_loss = 1.34996935, grad/param norm = 1.9084e-01, time/batch = 0.6755s	
4997/25300 (epoch 9.875), train_loss = 1.23237836, grad/param norm = 1.7333e-01, time/batch = 0.6767s	
4998/25300 (epoch 9.877), train_loss = 1.15733492, grad/param norm = 1.5441e-01, time/batch = 0.6795s	
4999/25300 (epoch 9.879), train_loss = 1.28393450, grad/param norm = 1.8576e-01, time/batch = 0.6857s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch9.88_1.4555.t7	
5000/25300 (epoch 9.881), train_loss = 1.58114163, grad/param norm = 2.0508e-01, time/batch = 0.6865s	
5001/25300 (epoch 9.883), train_loss = 1.73110942, grad/param norm = 2.0040e-01, time/batch = 0.6819s	
5002/25300 (epoch 9.885), train_loss = 1.36601585, grad/param norm = 1.9774e-01, time/batch = 0.6737s	
5003/25300 (epoch 9.887), train_loss = 1.27474100, grad/param norm = 1.7301e-01, time/batch = 0.6741s	
5004/25300 (epoch 9.889), train_loss = 1.42694350, grad/param norm = 1.8013e-01, time/batch = 0.6780s	
5005/25300 (epoch 9.891), train_loss = 1.36049662, grad/param norm = 2.0226e-01, time/batch = 0.6731s	
5006/25300 (epoch 9.893), train_loss = 1.48719789, grad/param norm = 1.8846e-01, time/batch = 0.6734s	
5007/25300 (epoch 9.895), train_loss = 1.01936180, grad/param norm = 1.8069e-01, time/batch = 0.6815s	
5008/25300 (epoch 9.897), train_loss = 1.15116474, grad/param norm = 1.7527e-01, time/batch = 0.6782s	
5009/25300 (epoch 9.899), train_loss = 1.24058871, grad/param norm = 1.8887e-01, time/batch = 0.6789s	
5010/25300 (epoch 9.901), train_loss = 1.30514293, grad/param norm = 1.8429e-01, time/batch = 0.6816s	
5011/25300 (epoch 9.903), train_loss = 1.05952473, grad/param norm = 1.7566e-01, time/batch = 0.6742s	
5012/25300 (epoch 9.905), train_loss = 1.17554260, grad/param norm = 1.8385e-01, time/batch = 0.6731s	
5013/25300 (epoch 9.907), train_loss = 1.29332179, grad/param norm = 2.1204e-01, time/batch = 0.6749s	
5014/25300 (epoch 9.909), train_loss = 1.37555045, grad/param norm = 1.8884e-01, time/batch = 0.6723s	
5015/25300 (epoch 9.911), train_loss = 1.50718785, grad/param norm = 2.0304e-01, time/batch = 0.6736s	
5016/25300 (epoch 9.913), train_loss = 1.47638829, grad/param norm = 1.9962e-01, time/batch = 0.6763s	
5017/25300 (epoch 9.915), train_loss = 1.17882451, grad/param norm = 1.7823e-01, time/batch = 0.6745s	
5018/25300 (epoch 9.917), train_loss = 1.31945718, grad/param norm = 1.9378e-01, time/batch = 0.6737s	
5019/25300 (epoch 9.919), train_loss = 1.45295045, grad/param norm = 2.0497e-01, time/batch = 0.6728s	
5020/25300 (epoch 9.921), train_loss = 1.17438384, grad/param norm = 1.7542e-01, time/batch = 0.6729s	
5021/25300 (epoch 9.923), train_loss = 1.41812628, grad/param norm = 1.8708e-01, time/batch = 0.6734s	
5022/25300 (epoch 9.925), train_loss = 1.26424273, grad/param norm = 1.8704e-01, time/batch = 0.6708s	
5023/25300 (epoch 9.927), train_loss = 1.25025796, grad/param norm = 1.7654e-01, time/batch = 0.6746s	
5024/25300 (epoch 9.929), train_loss = 1.16617894, grad/param norm = 1.6649e-01, time/batch = 0.6788s	
5025/25300 (epoch 9.931), train_loss = 1.40456597, grad/param norm = 1.9994e-01, time/batch = 0.6761s	
5026/25300 (epoch 9.933), train_loss = 1.31561574, grad/param norm = 1.8613e-01, time/batch = 0.6756s	
5027/25300 (epoch 9.935), train_loss = 1.29339466, grad/param norm = 1.7141e-01, time/batch = 0.6710s	
5028/25300 (epoch 9.937), train_loss = 1.00348175, grad/param norm = 1.5131e-01, time/batch = 0.6731s	
5029/25300 (epoch 9.939), train_loss = 1.36890105, grad/param norm = 1.9115e-01, time/batch = 0.6733s	
5030/25300 (epoch 9.941), train_loss = 1.21344037, grad/param norm = 1.6621e-01, time/batch = 0.6719s	
5031/25300 (epoch 9.943), train_loss = 1.20323507, grad/param norm = 1.7142e-01, time/batch = 0.6766s	
5032/25300 (epoch 9.945), train_loss = 1.29663127, grad/param norm = 1.8861e-01, time/batch = 0.6773s	
5033/25300 (epoch 9.947), train_loss = 1.16524624, grad/param norm = 1.8222e-01, time/batch = 0.6745s	
5034/25300 (epoch 9.949), train_loss = 1.34604090, grad/param norm = 1.9446e-01, time/batch = 0.6738s	
5035/25300 (epoch 9.951), train_loss = 1.23786764, grad/param norm = 1.6860e-01, time/batch = 0.6732s	
5036/25300 (epoch 9.953), train_loss = 1.32249860, grad/param norm = 1.6635e-01, time/batch = 0.6712s	
5037/25300 (epoch 9.955), train_loss = 1.53308007, grad/param norm = 2.0427e-01, time/batch = 0.6735s	
5038/25300 (epoch 9.957), train_loss = 1.48391402, grad/param norm = 1.9646e-01, time/batch = 0.6766s	
5039/25300 (epoch 9.958), train_loss = 1.31193111, grad/param norm = 1.8279e-01, time/batch = 0.6807s	
5040/25300 (epoch 9.960), train_loss = 1.48286615, grad/param norm = 2.0076e-01, time/batch = 0.6837s	
5041/25300 (epoch 9.962), train_loss = 1.44480738, grad/param norm = 2.0306e-01, time/batch = 0.6844s	
5042/25300 (epoch 9.964), train_loss = 1.33955770, grad/param norm = 1.7245e-01, time/batch = 0.6875s	
5043/25300 (epoch 9.966), train_loss = 1.10237394, grad/param norm = 1.5554e-01, time/batch = 0.6794s	
5044/25300 (epoch 9.968), train_loss = 1.08915260, grad/param norm = 1.6896e-01, time/batch = 0.6776s	
5045/25300 (epoch 9.970), train_loss = 1.29058015, grad/param norm = 2.0383e-01, time/batch = 0.6795s	
5046/25300 (epoch 9.972), train_loss = 1.26033250, grad/param norm = 1.7883e-01, time/batch = 0.6865s	
5047/25300 (epoch 9.974), train_loss = 1.48617342, grad/param norm = 2.1008e-01, time/batch = 0.6772s	
5048/25300 (epoch 9.976), train_loss = 1.28972381, grad/param norm = 1.7600e-01, time/batch = 0.6785s	
5049/25300 (epoch 9.978), train_loss = 1.31423628, grad/param norm = 1.7774e-01, time/batch = 0.6772s	
5050/25300 (epoch 9.980), train_loss = 1.31956531, grad/param norm = 1.9464e-01, time/batch = 0.6748s	
5051/25300 (epoch 9.982), train_loss = 1.25149831, grad/param norm = 1.6909e-01, time/batch = 0.6955s	
5052/25300 (epoch 9.984), train_loss = 1.27088815, grad/param norm = 1.7705e-01, time/batch = 0.6786s	
5053/25300 (epoch 9.986), train_loss = 1.32188797, grad/param norm = 1.9199e-01, time/batch = 0.6763s	
5054/25300 (epoch 9.988), train_loss = 1.34028739, grad/param norm = 1.9355e-01, time/batch = 0.6749s	
5055/25300 (epoch 9.990), train_loss = 1.27272322, grad/param norm = 1.6546e-01, time/batch = 0.6781s	
5056/25300 (epoch 9.992), train_loss = 1.01095603, grad/param norm = 1.6774e-01, time/batch = 0.6787s	
5057/25300 (epoch 9.994), train_loss = 1.28086791, grad/param norm = 1.8288e-01, time/batch = 0.6762s	
5058/25300 (epoch 9.996), train_loss = 1.42421306, grad/param norm = 2.1353e-01, time/batch = 0.6787s	
5059/25300 (epoch 9.998), train_loss = 1.41214598, grad/param norm = 1.9219e-01, time/batch = 0.6787s	
decayed learning rate by a factor 0.97 to 0.00194	
5060/25300 (epoch 10.000), train_loss = 1.26261954, grad/param norm = 1.8385e-01, time/batch = 0.6773s	
5061/25300 (epoch 10.002), train_loss = 1.10738600, grad/param norm = 1.5741e-01, time/batch = 0.6810s	
5062/25300 (epoch 10.004), train_loss = 1.05526418, grad/param norm = 1.7397e-01, time/batch = 0.6747s	
5063/25300 (epoch 10.006), train_loss = 1.33616683, grad/param norm = 1.7681e-01, time/batch = 0.6762s	
5064/25300 (epoch 10.008), train_loss = 1.27528706, grad/param norm = 1.7814e-01, time/batch = 0.6772s	
5065/25300 (epoch 10.010), train_loss = 1.29157734, grad/param norm = 1.6273e-01, time/batch = 0.6769s	
5066/25300 (epoch 10.012), train_loss = 1.12818123, grad/param norm = 1.8980e-01, time/batch = 0.6794s	
5067/25300 (epoch 10.014), train_loss = 1.35127281, grad/param norm = 1.9272e-01, time/batch = 0.6769s	
5068/25300 (epoch 10.016), train_loss = 1.31244527, grad/param norm = 2.0389e-01, time/batch = 0.6772s	
5069/25300 (epoch 10.018), train_loss = 1.14953136, grad/param norm = 1.8134e-01, time/batch = 0.6758s	
5070/25300 (epoch 10.020), train_loss = 1.20452302, grad/param norm = 1.7686e-01, time/batch = 0.6771s	
5071/25300 (epoch 10.022), train_loss = 1.27261199, grad/param norm = 1.8348e-01, time/batch = 0.6771s	
5072/25300 (epoch 10.024), train_loss = 0.95859945, grad/param norm = 1.6118e-01, time/batch = 0.6734s	
5073/25300 (epoch 10.026), train_loss = 1.18257099, grad/param norm = 2.0776e-01, time/batch = 0.6728s	
5074/25300 (epoch 10.028), train_loss = 1.08333106, grad/param norm = 1.5448e-01, time/batch = 0.6749s	
5075/25300 (epoch 10.030), train_loss = 1.33392342, grad/param norm = 1.7042e-01, time/batch = 0.6712s	
5076/25300 (epoch 10.032), train_loss = 1.18622901, grad/param norm = 1.6864e-01, time/batch = 0.6813s	
5077/25300 (epoch 10.034), train_loss = 1.01707518, grad/param norm = 1.8147e-01, time/batch = 0.6795s	
5078/25300 (epoch 10.036), train_loss = 1.06652874, grad/param norm = 1.7671e-01, time/batch = 0.6789s	
5079/25300 (epoch 10.038), train_loss = 0.93830540, grad/param norm = 1.4245e-01, time/batch = 0.6774s	
5080/25300 (epoch 10.040), train_loss = 1.30033820, grad/param norm = 1.7391e-01, time/batch = 0.6748s	
5081/25300 (epoch 10.042), train_loss = 1.10261564, grad/param norm = 1.6029e-01, time/batch = 0.6767s	
5082/25300 (epoch 10.043), train_loss = 1.02129361, grad/param norm = 1.5314e-01, time/batch = 0.6763s	
5083/25300 (epoch 10.045), train_loss = 1.04798639, grad/param norm = 1.6176e-01, time/batch = 0.6819s	
5084/25300 (epoch 10.047), train_loss = 1.28253797, grad/param norm = 1.6569e-01, time/batch = 0.6776s	
5085/25300 (epoch 10.049), train_loss = 1.28369005, grad/param norm = 1.8724e-01, time/batch = 0.6761s	
5086/25300 (epoch 10.051), train_loss = 1.35454347, grad/param norm = 1.9447e-01, time/batch = 0.6775s	
5087/25300 (epoch 10.053), train_loss = 1.01867495, grad/param norm = 1.5826e-01, time/batch = 0.6831s	
5088/25300 (epoch 10.055), train_loss = 1.07086550, grad/param norm = 1.6128e-01, time/batch = 0.6723s	
5089/25300 (epoch 10.057), train_loss = 0.99793511, grad/param norm = 1.5032e-01, time/batch = 0.6725s	
5090/25300 (epoch 10.059), train_loss = 1.20565475, grad/param norm = 1.7429e-01, time/batch = 0.6719s	
5091/25300 (epoch 10.061), train_loss = 1.10536206, grad/param norm = 1.5813e-01, time/batch = 0.6738s	
5092/25300 (epoch 10.063), train_loss = 1.12663438, grad/param norm = 1.6966e-01, time/batch = 0.6777s	
5093/25300 (epoch 10.065), train_loss = 1.34256022, grad/param norm = 1.9476e-01, time/batch = 0.6748s	
5094/25300 (epoch 10.067), train_loss = 1.36734258, grad/param norm = 1.8238e-01, time/batch = 0.6743s	
5095/25300 (epoch 10.069), train_loss = 1.22250532, grad/param norm = 1.7375e-01, time/batch = 0.6773s	
5096/25300 (epoch 10.071), train_loss = 1.36741247, grad/param norm = 1.7226e-01, time/batch = 0.6754s	
5097/25300 (epoch 10.073), train_loss = 1.18213754, grad/param norm = 1.6589e-01, time/batch = 0.6766s	
5098/25300 (epoch 10.075), train_loss = 1.24653791, grad/param norm = 1.6827e-01, time/batch = 0.6770s	
5099/25300 (epoch 10.077), train_loss = 1.30511416, grad/param norm = 1.8413e-01, time/batch = 0.6758s	
5100/25300 (epoch 10.079), train_loss = 1.24456974, grad/param norm = 1.7270e-01, time/batch = 0.6779s	
5101/25300 (epoch 10.081), train_loss = 1.20083255, grad/param norm = 1.6700e-01, time/batch = 0.6763s	
5102/25300 (epoch 10.083), train_loss = 1.14730889, grad/param norm = 1.6050e-01, time/batch = 0.6760s	
5103/25300 (epoch 10.085), train_loss = 1.44145694, grad/param norm = 1.9624e-01, time/batch = 0.6759s	
5104/25300 (epoch 10.087), train_loss = 1.23458055, grad/param norm = 1.8941e-01, time/batch = 0.6768s	
5105/25300 (epoch 10.089), train_loss = 1.25974475, grad/param norm = 1.7117e-01, time/batch = 0.6772s	
5106/25300 (epoch 10.091), train_loss = 1.37843129, grad/param norm = 1.8900e-01, time/batch = 0.6748s	
5107/25300 (epoch 10.093), train_loss = 1.38025544, grad/param norm = 1.9103e-01, time/batch = 0.6751s	
5108/25300 (epoch 10.095), train_loss = 1.28979128, grad/param norm = 1.6749e-01, time/batch = 0.6753s	
5109/25300 (epoch 10.097), train_loss = 1.24792214, grad/param norm = 1.6549e-01, time/batch = 0.6781s	
5110/25300 (epoch 10.099), train_loss = 1.27419951, grad/param norm = 1.8605e-01, time/batch = 0.6754s	
5111/25300 (epoch 10.101), train_loss = 1.21688351, grad/param norm = 1.7575e-01, time/batch = 0.6769s	
5112/25300 (epoch 10.103), train_loss = 1.17216589, grad/param norm = 1.6559e-01, time/batch = 0.6779s	
5113/25300 (epoch 10.105), train_loss = 1.27128538, grad/param norm = 1.8931e-01, time/batch = 0.6778s	
5114/25300 (epoch 10.107), train_loss = 1.34877894, grad/param norm = 1.9058e-01, time/batch = 0.6780s	
5115/25300 (epoch 10.109), train_loss = 1.25897743, grad/param norm = 1.8413e-01, time/batch = 0.6776s	
5116/25300 (epoch 10.111), train_loss = 1.19345272, grad/param norm = 1.7048e-01, time/batch = 0.6782s	
5117/25300 (epoch 10.113), train_loss = 1.24020352, grad/param norm = 1.8308e-01, time/batch = 0.6786s	
5118/25300 (epoch 10.115), train_loss = 1.21714943, grad/param norm = 1.7467e-01, time/batch = 0.6708s	
5119/25300 (epoch 10.117), train_loss = 1.31040420, grad/param norm = 1.7641e-01, time/batch = 0.6851s	
5120/25300 (epoch 10.119), train_loss = 1.20706291, grad/param norm = 1.7758e-01, time/batch = 0.6763s	
5121/25300 (epoch 10.121), train_loss = 1.33745554, grad/param norm = 2.0464e-01, time/batch = 0.6795s	
5122/25300 (epoch 10.123), train_loss = 1.23231866, grad/param norm = 1.9055e-01, time/batch = 0.6775s	
5123/25300 (epoch 10.125), train_loss = 1.35055077, grad/param norm = 1.9860e-01, time/batch = 0.6755s	
5124/25300 (epoch 10.126), train_loss = 1.25764130, grad/param norm = 1.8547e-01, time/batch = 0.6729s	
5125/25300 (epoch 10.128), train_loss = 1.26566296, grad/param norm = 1.7389e-01, time/batch = 0.6772s	
5126/25300 (epoch 10.130), train_loss = 0.97664202, grad/param norm = 1.6097e-01, time/batch = 0.6739s	
5127/25300 (epoch 10.132), train_loss = 1.07772571, grad/param norm = 1.5800e-01, time/batch = 0.6801s	
5128/25300 (epoch 10.134), train_loss = 0.98043773, grad/param norm = 1.5152e-01, time/batch = 0.6838s	
5129/25300 (epoch 10.136), train_loss = 1.28400135, grad/param norm = 1.7311e-01, time/batch = 0.6888s	
5130/25300 (epoch 10.138), train_loss = 1.08111768, grad/param norm = 1.6203e-01, time/batch = 0.6746s	
5131/25300 (epoch 10.140), train_loss = 1.14316673, grad/param norm = 1.6613e-01, time/batch = 0.6787s	
5132/25300 (epoch 10.142), train_loss = 1.32628952, grad/param norm = 1.8150e-01, time/batch = 0.6729s	
5133/25300 (epoch 10.144), train_loss = 1.25557281, grad/param norm = 1.8441e-01, time/batch = 0.6725s	
5134/25300 (epoch 10.146), train_loss = 1.36527758, grad/param norm = 1.9849e-01, time/batch = 0.6789s	
5135/25300 (epoch 10.148), train_loss = 1.23015885, grad/param norm = 1.7467e-01, time/batch = 0.6801s	
5136/25300 (epoch 10.150), train_loss = 1.34934681, grad/param norm = 2.0198e-01, time/batch = 0.6787s	
5137/25300 (epoch 10.152), train_loss = 1.49123587, grad/param norm = 2.0089e-01, time/batch = 0.6795s	
5138/25300 (epoch 10.154), train_loss = 1.12439909, grad/param norm = 1.7665e-01, time/batch = 0.6775s	
5139/25300 (epoch 10.156), train_loss = 1.27838796, grad/param norm = 1.7214e-01, time/batch = 0.6851s	
5140/25300 (epoch 10.158), train_loss = 1.15531999, grad/param norm = 1.6340e-01, time/batch = 0.6793s	
5141/25300 (epoch 10.160), train_loss = 1.24969283, grad/param norm = 1.7145e-01, time/batch = 0.6754s	
5142/25300 (epoch 10.162), train_loss = 1.16353425, grad/param norm = 1.8097e-01, time/batch = 0.6727s	
5143/25300 (epoch 10.164), train_loss = 1.30427023, grad/param norm = 1.8040e-01, time/batch = 0.6737s	
5144/25300 (epoch 10.166), train_loss = 1.27255610, grad/param norm = 1.8682e-01, time/batch = 0.6712s	
5145/25300 (epoch 10.168), train_loss = 1.07797509, grad/param norm = 1.5113e-01, time/batch = 0.6739s	
5146/25300 (epoch 10.170), train_loss = 1.15775737, grad/param norm = 1.6233e-01, time/batch = 0.6749s	
5147/25300 (epoch 10.172), train_loss = 1.12160038, grad/param norm = 1.6637e-01, time/batch = 0.6744s	
5148/25300 (epoch 10.174), train_loss = 1.09359582, grad/param norm = 1.6885e-01, time/batch = 0.6727s	
5149/25300 (epoch 10.176), train_loss = 1.20058489, grad/param norm = 1.7982e-01, time/batch = 0.6780s	
5150/25300 (epoch 10.178), train_loss = 1.39626557, grad/param norm = 1.8793e-01, time/batch = 0.6799s	
5151/25300 (epoch 10.180), train_loss = 1.01959401, grad/param norm = 1.6316e-01, time/batch = 0.6773s	
5152/25300 (epoch 10.182), train_loss = 1.14584508, grad/param norm = 1.6120e-01, time/batch = 0.6795s	
5153/25300 (epoch 10.184), train_loss = 1.21973761, grad/param norm = 1.8485e-01, time/batch = 0.6841s	
5154/25300 (epoch 10.186), train_loss = 1.17224042, grad/param norm = 1.8015e-01, time/batch = 0.6858s	
5155/25300 (epoch 10.188), train_loss = 1.21399442, grad/param norm = 1.8556e-01, time/batch = 0.6845s	
5156/25300 (epoch 10.190), train_loss = 1.27524994, grad/param norm = 1.8944e-01, time/batch = 0.6840s	
5157/25300 (epoch 10.192), train_loss = 1.17579916, grad/param norm = 1.7983e-01, time/batch = 0.6829s	
5158/25300 (epoch 10.194), train_loss = 1.18982391, grad/param norm = 1.7931e-01, time/batch = 0.6806s	
5159/25300 (epoch 10.196), train_loss = 1.32617565, grad/param norm = 2.0535e-01, time/batch = 0.6740s	
5160/25300 (epoch 10.198), train_loss = 1.17387553, grad/param norm = 1.9826e-01, time/batch = 0.6754s	
5161/25300 (epoch 10.200), train_loss = 1.25589815, grad/param norm = 2.0366e-01, time/batch = 0.6766s	
5162/25300 (epoch 10.202), train_loss = 1.24764158, grad/param norm = 1.8770e-01, time/batch = 0.6745s	
5163/25300 (epoch 10.204), train_loss = 1.20308254, grad/param norm = 1.8063e-01, time/batch = 0.6733s	
5164/25300 (epoch 10.206), train_loss = 1.30263521, grad/param norm = 1.9060e-01, time/batch = 0.6748s	
5165/25300 (epoch 10.208), train_loss = 1.10570926, grad/param norm = 1.8681e-01, time/batch = 0.6765s	
5166/25300 (epoch 10.209), train_loss = 1.00960199, grad/param norm = 1.6171e-01, time/batch = 0.6744s	
5167/25300 (epoch 10.211), train_loss = 1.20552317, grad/param norm = 1.7248e-01, time/batch = 0.6750s	
5168/25300 (epoch 10.213), train_loss = 1.28311230, grad/param norm = 1.9620e-01, time/batch = 0.6803s	
5169/25300 (epoch 10.215), train_loss = 1.25747189, grad/param norm = 2.0046e-01, time/batch = 0.6719s	
5170/25300 (epoch 10.217), train_loss = 1.28649596, grad/param norm = 1.9074e-01, time/batch = 0.6722s	
5171/25300 (epoch 10.219), train_loss = 1.30573775, grad/param norm = 1.9527e-01, time/batch = 0.6761s	
5172/25300 (epoch 10.221), train_loss = 1.34415712, grad/param norm = 1.8492e-01, time/batch = 0.6821s	
5173/25300 (epoch 10.223), train_loss = 1.32282369, grad/param norm = 2.0312e-01, time/batch = 0.6854s	
5174/25300 (epoch 10.225), train_loss = 1.75748573, grad/param norm = 2.3484e-01, time/batch = 0.6781s	
5175/25300 (epoch 10.227), train_loss = 1.33137576, grad/param norm = 1.8214e-01, time/batch = 0.6774s	
5176/25300 (epoch 10.229), train_loss = 1.28436102, grad/param norm = 1.9571e-01, time/batch = 0.6773s	
5177/25300 (epoch 10.231), train_loss = 1.23556027, grad/param norm = 1.7377e-01, time/batch = 0.6744s	
5178/25300 (epoch 10.233), train_loss = 1.28463651, grad/param norm = 1.7836e-01, time/batch = 0.6731s	
5179/25300 (epoch 10.235), train_loss = 1.23125870, grad/param norm = 1.7844e-01, time/batch = 0.6773s	
5180/25300 (epoch 10.237), train_loss = 1.38925869, grad/param norm = 1.8494e-01, time/batch = 0.6791s	
5181/25300 (epoch 10.239), train_loss = 1.27189380, grad/param norm = 1.8235e-01, time/batch = 0.6805s	
5182/25300 (epoch 10.241), train_loss = 1.34632243, grad/param norm = 1.8206e-01, time/batch = 0.6783s	
5183/25300 (epoch 10.243), train_loss = 1.60661587, grad/param norm = 2.0594e-01, time/batch = 0.6761s	
5184/25300 (epoch 10.245), train_loss = 1.15328230, grad/param norm = 1.7132e-01, time/batch = 0.6753s	
5185/25300 (epoch 10.247), train_loss = 1.36519554, grad/param norm = 1.8128e-01, time/batch = 0.6737s	
5186/25300 (epoch 10.249), train_loss = 1.08234537, grad/param norm = 1.5972e-01, time/batch = 0.6736s	
5187/25300 (epoch 10.251), train_loss = 1.05498649, grad/param norm = 1.6818e-01, time/batch = 0.6768s	
5188/25300 (epoch 10.253), train_loss = 1.23786017, grad/param norm = 1.7419e-01, time/batch = 0.6751s	
5189/25300 (epoch 10.255), train_loss = 1.18048467, grad/param norm = 1.7764e-01, time/batch = 0.6737s	
5190/25300 (epoch 10.257), train_loss = 1.33220901, grad/param norm = 1.9029e-01, time/batch = 0.6751s	
5191/25300 (epoch 10.259), train_loss = 1.48705139, grad/param norm = 1.9911e-01, time/batch = 0.6760s	
5192/25300 (epoch 10.261), train_loss = 1.40563823, grad/param norm = 2.0128e-01, time/batch = 0.6751s	
5193/25300 (epoch 10.263), train_loss = 1.37034662, grad/param norm = 1.9122e-01, time/batch = 0.6771s	
5194/25300 (epoch 10.265), train_loss = 1.45653486, grad/param norm = 2.0479e-01, time/batch = 0.6828s	
5195/25300 (epoch 10.267), train_loss = 1.36261385, grad/param norm = 1.8060e-01, time/batch = 0.6815s	
5196/25300 (epoch 10.269), train_loss = 1.08343313, grad/param norm = 1.5811e-01, time/batch = 0.6851s	
5197/25300 (epoch 10.271), train_loss = 1.18129362, grad/param norm = 1.8804e-01, time/batch = 0.6857s	
5198/25300 (epoch 10.273), train_loss = 1.29439737, grad/param norm = 1.7724e-01, time/batch = 0.6844s	
5199/25300 (epoch 10.275), train_loss = 1.11171016, grad/param norm = 1.5493e-01, time/batch = 0.6851s	
5200/25300 (epoch 10.277), train_loss = 1.20626287, grad/param norm = 1.7643e-01, time/batch = 0.6836s	
5201/25300 (epoch 10.279), train_loss = 1.26159066, grad/param norm = 1.8111e-01, time/batch = 0.6830s	
5202/25300 (epoch 10.281), train_loss = 1.38897806, grad/param norm = 1.9295e-01, time/batch = 0.6870s	
5203/25300 (epoch 10.283), train_loss = 1.12346671, grad/param norm = 1.8041e-01, time/batch = 0.6783s	
5204/25300 (epoch 10.285), train_loss = 1.26225362, grad/param norm = 2.0001e-01, time/batch = 0.6765s	
5205/25300 (epoch 10.287), train_loss = 1.24754173, grad/param norm = 1.7704e-01, time/batch = 0.6776s	
5206/25300 (epoch 10.289), train_loss = 1.17316773, grad/param norm = 1.7024e-01, time/batch = 0.6768s	
5207/25300 (epoch 10.291), train_loss = 1.18546078, grad/param norm = 1.8242e-01, time/batch = 0.6762s	
5208/25300 (epoch 10.292), train_loss = 1.35899168, grad/param norm = 1.8829e-01, time/batch = 0.6752s	
5209/25300 (epoch 10.294), train_loss = 1.26055708, grad/param norm = 1.7783e-01, time/batch = 0.6776s	
5210/25300 (epoch 10.296), train_loss = 1.09552373, grad/param norm = 1.7178e-01, time/batch = 0.6772s	
5211/25300 (epoch 10.298), train_loss = 1.33698916, grad/param norm = 1.8807e-01, time/batch = 0.6794s	
5212/25300 (epoch 10.300), train_loss = 1.41097406, grad/param norm = 1.9499e-01, time/batch = 0.6801s	
5213/25300 (epoch 10.302), train_loss = 1.05183830, grad/param norm = 1.7946e-01, time/batch = 0.6764s	
5214/25300 (epoch 10.304), train_loss = 1.27274349, grad/param norm = 1.8575e-01, time/batch = 0.6761s	
5215/25300 (epoch 10.306), train_loss = 0.98992944, grad/param norm = 1.5489e-01, time/batch = 0.6812s	
5216/25300 (epoch 10.308), train_loss = 1.28552869, grad/param norm = 1.7035e-01, time/batch = 0.6844s	
5217/25300 (epoch 10.310), train_loss = 1.15484395, grad/param norm = 1.9144e-01, time/batch = 0.6860s	
5218/25300 (epoch 10.312), train_loss = 1.21807717, grad/param norm = 1.7071e-01, time/batch = 0.6830s	
5219/25300 (epoch 10.314), train_loss = 0.98565665, grad/param norm = 1.6573e-01, time/batch = 0.6764s	
5220/25300 (epoch 10.316), train_loss = 1.26843809, grad/param norm = 1.8054e-01, time/batch = 0.6867s	
5221/25300 (epoch 10.318), train_loss = 0.95888215, grad/param norm = 1.6794e-01, time/batch = 0.6811s	
5222/25300 (epoch 10.320), train_loss = 1.08985884, grad/param norm = 1.6472e-01, time/batch = 0.6778s	
5223/25300 (epoch 10.322), train_loss = 1.53620223, grad/param norm = 2.1656e-01, time/batch = 0.6772s	
5224/25300 (epoch 10.324), train_loss = 1.10842395, grad/param norm = 1.6956e-01, time/batch = 0.6769s	
5225/25300 (epoch 10.326), train_loss = 0.97350531, grad/param norm = 1.5488e-01, time/batch = 0.6766s	
5226/25300 (epoch 10.328), train_loss = 0.98810825, grad/param norm = 1.6712e-01, time/batch = 0.6738s	
5227/25300 (epoch 10.330), train_loss = 1.16629815, grad/param norm = 1.7231e-01, time/batch = 0.6734s	
5228/25300 (epoch 10.332), train_loss = 1.26591305, grad/param norm = 1.6330e-01, time/batch = 0.6774s	
5229/25300 (epoch 10.334), train_loss = 1.05981351, grad/param norm = 1.5656e-01, time/batch = 0.6783s	
5230/25300 (epoch 10.336), train_loss = 1.03599418, grad/param norm = 1.7604e-01, time/batch = 0.6744s	
5231/25300 (epoch 10.338), train_loss = 1.05670546, grad/param norm = 1.7976e-01, time/batch = 0.6800s	
5232/25300 (epoch 10.340), train_loss = 1.16435099, grad/param norm = 1.8652e-01, time/batch = 0.6768s	
5233/25300 (epoch 10.342), train_loss = 1.15683670, grad/param norm = 1.8014e-01, time/batch = 0.6788s	
5234/25300 (epoch 10.344), train_loss = 1.20092803, grad/param norm = 1.7086e-01, time/batch = 0.6865s	
5235/25300 (epoch 10.346), train_loss = 1.19208620, grad/param norm = 1.7694e-01, time/batch = 0.6833s	
5236/25300 (epoch 10.348), train_loss = 1.06312161, grad/param norm = 1.5448e-01, time/batch = 0.6813s	
5237/25300 (epoch 10.350), train_loss = 1.16761849, grad/param norm = 1.7112e-01, time/batch = 0.6759s	
5238/25300 (epoch 10.352), train_loss = 1.21007294, grad/param norm = 1.6847e-01, time/batch = 0.6812s	
5239/25300 (epoch 10.354), train_loss = 1.16556001, grad/param norm = 1.8201e-01, time/batch = 0.6747s	
5240/25300 (epoch 10.356), train_loss = 1.23360865, grad/param norm = 1.7447e-01, time/batch = 0.6771s	
5241/25300 (epoch 10.358), train_loss = 1.35115727, grad/param norm = 2.0046e-01, time/batch = 0.6806s	
5242/25300 (epoch 10.360), train_loss = 1.10453266, grad/param norm = 1.8201e-01, time/batch = 0.6759s	
5243/25300 (epoch 10.362), train_loss = 1.16469766, grad/param norm = 1.7124e-01, time/batch = 0.6744s	
5244/25300 (epoch 10.364), train_loss = 1.28928851, grad/param norm = 1.8529e-01, time/batch = 0.6749s	
5245/25300 (epoch 10.366), train_loss = 1.07398449, grad/param norm = 1.6334e-01, time/batch = 0.6755s	
5246/25300 (epoch 10.368), train_loss = 1.17352638, grad/param norm = 1.6529e-01, time/batch = 0.6749s	
5247/25300 (epoch 10.370), train_loss = 1.20983156, grad/param norm = 1.9561e-01, time/batch = 0.6765s	
5248/25300 (epoch 10.372), train_loss = 1.14616377, grad/param norm = 1.7517e-01, time/batch = 0.6740s	
5249/25300 (epoch 10.374), train_loss = 1.09499403, grad/param norm = 1.6683e-01, time/batch = 0.6742s	
5250/25300 (epoch 10.375), train_loss = 1.42755009, grad/param norm = 1.9958e-01, time/batch = 0.6745s	
5251/25300 (epoch 10.377), train_loss = 1.23521411, grad/param norm = 1.8843e-01, time/batch = 0.6735s	
5252/25300 (epoch 10.379), train_loss = 1.34746652, grad/param norm = 1.9814e-01, time/batch = 0.6755s	
5253/25300 (epoch 10.381), train_loss = 1.21561041, grad/param norm = 1.6331e-01, time/batch = 0.6763s	
5254/25300 (epoch 10.383), train_loss = 1.11064991, grad/param norm = 1.8210e-01, time/batch = 0.6818s	
5255/25300 (epoch 10.385), train_loss = 1.16352379, grad/param norm = 1.6135e-01, time/batch = 0.6776s	
5256/25300 (epoch 10.387), train_loss = 1.28890097, grad/param norm = 1.8353e-01, time/batch = 0.6739s	
5257/25300 (epoch 10.389), train_loss = 1.35831557, grad/param norm = 1.9708e-01, time/batch = 0.6708s	
5258/25300 (epoch 10.391), train_loss = 1.09829860, grad/param norm = 1.5797e-01, time/batch = 0.6727s	
5259/25300 (epoch 10.393), train_loss = 1.24767522, grad/param norm = 1.7244e-01, time/batch = 0.6703s	
5260/25300 (epoch 10.395), train_loss = 1.03738523, grad/param norm = 1.5821e-01, time/batch = 0.6725s	
5261/25300 (epoch 10.397), train_loss = 1.08200547, grad/param norm = 1.7216e-01, time/batch = 0.6775s	
5262/25300 (epoch 10.399), train_loss = 1.08042211, grad/param norm = 1.6532e-01, time/batch = 0.6809s	
5263/25300 (epoch 10.401), train_loss = 1.36040864, grad/param norm = 1.9127e-01, time/batch = 0.6755s	
5264/25300 (epoch 10.403), train_loss = 1.22412968, grad/param norm = 1.9799e-01, time/batch = 0.6735s	
5265/25300 (epoch 10.405), train_loss = 1.24425041, grad/param norm = 1.9924e-01, time/batch = 0.6718s	
5266/25300 (epoch 10.407), train_loss = 1.12688590, grad/param norm = 1.6852e-01, time/batch = 0.6722s	
5267/25300 (epoch 10.409), train_loss = 1.13372298, grad/param norm = 1.5737e-01, time/batch = 0.6759s	
5268/25300 (epoch 10.411), train_loss = 1.18662046, grad/param norm = 1.7757e-01, time/batch = 0.6770s	
5269/25300 (epoch 10.413), train_loss = 1.08480953, grad/param norm = 1.7162e-01, time/batch = 0.6743s	
5270/25300 (epoch 10.415), train_loss = 1.07143849, grad/param norm = 1.6373e-01, time/batch = 0.6782s	
5271/25300 (epoch 10.417), train_loss = 1.03581496, grad/param norm = 1.5560e-01, time/batch = 0.6797s	
5272/25300 (epoch 10.419), train_loss = 1.01240955, grad/param norm = 1.7698e-01, time/batch = 0.6763s	
5273/25300 (epoch 10.421), train_loss = 1.01222107, grad/param norm = 1.5073e-01, time/batch = 0.6732s	
5274/25300 (epoch 10.423), train_loss = 1.10103871, grad/param norm = 1.6643e-01, time/batch = 0.6779s	
5275/25300 (epoch 10.425), train_loss = 1.16470652, grad/param norm = 1.7889e-01, time/batch = 0.6765s	
5276/25300 (epoch 10.427), train_loss = 1.42806555, grad/param norm = 1.8876e-01, time/batch = 0.6729s	
5277/25300 (epoch 10.429), train_loss = 1.33761574, grad/param norm = 1.8971e-01, time/batch = 0.6757s	
5278/25300 (epoch 10.431), train_loss = 1.21404373, grad/param norm = 1.7552e-01, time/batch = 0.6751s	
5279/25300 (epoch 10.433), train_loss = 1.15692413, grad/param norm = 1.6970e-01, time/batch = 0.6752s	
5280/25300 (epoch 10.435), train_loss = 1.09978230, grad/param norm = 1.7962e-01, time/batch = 0.6766s	
5281/25300 (epoch 10.437), train_loss = 1.13621605, grad/param norm = 1.6507e-01, time/batch = 0.6787s	
5282/25300 (epoch 10.439), train_loss = 1.19487181, grad/param norm = 1.7168e-01, time/batch = 0.6772s	
5283/25300 (epoch 10.441), train_loss = 1.22783201, grad/param norm = 1.9611e-01, time/batch = 0.6821s	
5284/25300 (epoch 10.443), train_loss = 1.45484436, grad/param norm = 2.2369e-01, time/batch = 0.6804s	
5285/25300 (epoch 10.445), train_loss = 1.35561563, grad/param norm = 1.9236e-01, time/batch = 0.6780s	
5286/25300 (epoch 10.447), train_loss = 1.10791836, grad/param norm = 1.7728e-01, time/batch = 0.6785s	
5287/25300 (epoch 10.449), train_loss = 1.01739144, grad/param norm = 1.6975e-01, time/batch = 0.6777s	
5288/25300 (epoch 10.451), train_loss = 1.37787936, grad/param norm = 1.9254e-01, time/batch = 0.6785s	
5289/25300 (epoch 10.453), train_loss = 1.29816054, grad/param norm = 1.9963e-01, time/batch = 0.6777s	
5290/25300 (epoch 10.455), train_loss = 1.36870053, grad/param norm = 1.7864e-01, time/batch = 0.6773s	
5291/25300 (epoch 10.457), train_loss = 1.17380312, grad/param norm = 1.7992e-01, time/batch = 0.6798s	
5292/25300 (epoch 10.458), train_loss = 1.23877107, grad/param norm = 1.8167e-01, time/batch = 0.6820s	
5293/25300 (epoch 10.460), train_loss = 1.25023151, grad/param norm = 1.9588e-01, time/batch = 0.6793s	
5294/25300 (epoch 10.462), train_loss = 0.99639312, grad/param norm = 1.6519e-01, time/batch = 0.6789s	
5295/25300 (epoch 10.464), train_loss = 1.26991146, grad/param norm = 1.8706e-01, time/batch = 0.6799s	
5296/25300 (epoch 10.466), train_loss = 1.31033567, grad/param norm = 1.9452e-01, time/batch = 0.6760s	
5297/25300 (epoch 10.468), train_loss = 1.34464356, grad/param norm = 1.9219e-01, time/batch = 0.6763s	
5298/25300 (epoch 10.470), train_loss = 1.09279475, grad/param norm = 1.5861e-01, time/batch = 0.6827s	
5299/25300 (epoch 10.472), train_loss = 0.99235278, grad/param norm = 1.5642e-01, time/batch = 0.6817s	
5300/25300 (epoch 10.474), train_loss = 1.24392434, grad/param norm = 1.8744e-01, time/batch = 0.6770s	
5301/25300 (epoch 10.476), train_loss = 1.17963610, grad/param norm = 1.7541e-01, time/batch = 0.6761s	
5302/25300 (epoch 10.478), train_loss = 1.29054888, grad/param norm = 1.9922e-01, time/batch = 0.6750s	
5303/25300 (epoch 10.480), train_loss = 1.10750787, grad/param norm = 1.6970e-01, time/batch = 0.6785s	
5304/25300 (epoch 10.482), train_loss = 1.36461495, grad/param norm = 2.0964e-01, time/batch = 0.6844s	
5305/25300 (epoch 10.484), train_loss = 1.28826857, grad/param norm = 1.9055e-01, time/batch = 0.6857s	
5306/25300 (epoch 10.486), train_loss = 1.22367904, grad/param norm = 1.7030e-01, time/batch = 0.6928s	
5307/25300 (epoch 10.488), train_loss = 1.32589398, grad/param norm = 1.8975e-01, time/batch = 0.6963s	
5308/25300 (epoch 10.490), train_loss = 1.28298269, grad/param norm = 1.8036e-01, time/batch = 0.6901s	
5309/25300 (epoch 10.492), train_loss = 1.15283427, grad/param norm = 1.6344e-01, time/batch = 0.6896s	
5310/25300 (epoch 10.494), train_loss = 1.08006044, grad/param norm = 1.6778e-01, time/batch = 0.6896s	
5311/25300 (epoch 10.496), train_loss = 1.20813789, grad/param norm = 1.7837e-01, time/batch = 0.7099s	
5312/25300 (epoch 10.498), train_loss = 1.11301425, grad/param norm = 1.7299e-01, time/batch = 0.6864s	
5313/25300 (epoch 10.500), train_loss = 1.36744030, grad/param norm = 1.8770e-01, time/batch = 0.6842s	
5314/25300 (epoch 10.502), train_loss = 1.21086640, grad/param norm = 1.7601e-01, time/batch = 0.6787s	
5315/25300 (epoch 10.504), train_loss = 1.16453513, grad/param norm = 1.9105e-01, time/batch = 0.6804s	
5316/25300 (epoch 10.506), train_loss = 1.14681967, grad/param norm = 1.6670e-01, time/batch = 0.6803s	
5317/25300 (epoch 10.508), train_loss = 1.23468962, grad/param norm = 1.8646e-01, time/batch = 0.6790s	
5318/25300 (epoch 10.510), train_loss = 1.14559892, grad/param norm = 1.8738e-01, time/batch = 0.6791s	
5319/25300 (epoch 10.512), train_loss = 0.91240889, grad/param norm = 1.4884e-01, time/batch = 0.6807s	
5320/25300 (epoch 10.514), train_loss = 1.12104532, grad/param norm = 1.5900e-01, time/batch = 0.6789s	
5321/25300 (epoch 10.516), train_loss = 1.20416093, grad/param norm = 1.7432e-01, time/batch = 0.6793s	
5322/25300 (epoch 10.518), train_loss = 1.27171166, grad/param norm = 1.8314e-01, time/batch = 0.6791s	
5323/25300 (epoch 10.520), train_loss = 1.01762940, grad/param norm = 1.5771e-01, time/batch = 0.6788s	
5324/25300 (epoch 10.522), train_loss = 1.12651999, grad/param norm = 1.7396e-01, time/batch = 0.6805s	
5325/25300 (epoch 10.524), train_loss = 1.15488499, grad/param norm = 1.6979e-01, time/batch = 0.6826s	
5326/25300 (epoch 10.526), train_loss = 1.45183472, grad/param norm = 1.9529e-01, time/batch = 0.6806s	
5327/25300 (epoch 10.528), train_loss = 1.34426587, grad/param norm = 1.9731e-01, time/batch = 0.6806s	
5328/25300 (epoch 10.530), train_loss = 1.20748682, grad/param norm = 1.8312e-01, time/batch = 0.6816s	
5329/25300 (epoch 10.532), train_loss = 1.24128300, grad/param norm = 1.9102e-01, time/batch = 0.6808s	
5330/25300 (epoch 10.534), train_loss = 1.15649834, grad/param norm = 1.7438e-01, time/batch = 0.6788s	
5331/25300 (epoch 10.536), train_loss = 1.04065933, grad/param norm = 1.7770e-01, time/batch = 0.6830s	
5332/25300 (epoch 10.538), train_loss = 1.01605135, grad/param norm = 1.4362e-01, time/batch = 0.6814s	
5333/25300 (epoch 10.540), train_loss = 1.08626934, grad/param norm = 1.7178e-01, time/batch = 0.6847s	
5334/25300 (epoch 10.542), train_loss = 1.08159801, grad/param norm = 1.7305e-01, time/batch = 0.6842s	
5335/25300 (epoch 10.543), train_loss = 1.03510240, grad/param norm = 1.7077e-01, time/batch = 0.6820s	
5336/25300 (epoch 10.545), train_loss = 1.57678462, grad/param norm = 2.1603e-01, time/batch = 0.6812s	
5337/25300 (epoch 10.547), train_loss = 1.22892016, grad/param norm = 1.8871e-01, time/batch = 0.6823s	
5338/25300 (epoch 10.549), train_loss = 1.48047621, grad/param norm = 2.0197e-01, time/batch = 0.6798s	
5339/25300 (epoch 10.551), train_loss = 1.23566606, grad/param norm = 1.7367e-01, time/batch = 0.6834s	
5340/25300 (epoch 10.553), train_loss = 1.18074825, grad/param norm = 1.7984e-01, time/batch = 0.6812s	
5341/25300 (epoch 10.555), train_loss = 1.32386040, grad/param norm = 1.8752e-01, time/batch = 0.6826s	
5342/25300 (epoch 10.557), train_loss = 1.35786057, grad/param norm = 1.8766e-01, time/batch = 0.6781s	
5343/25300 (epoch 10.559), train_loss = 1.36505913, grad/param norm = 1.9640e-01, time/batch = 0.6783s	
5344/25300 (epoch 10.561), train_loss = 1.39659400, grad/param norm = 1.9798e-01, time/batch = 0.6767s	
5345/25300 (epoch 10.563), train_loss = 1.31580801, grad/param norm = 1.8566e-01, time/batch = 0.6907s	
5346/25300 (epoch 10.565), train_loss = 1.05244726, grad/param norm = 1.7746e-01, time/batch = 0.6886s	
5347/25300 (epoch 10.567), train_loss = 0.91510972, grad/param norm = 1.6854e-01, time/batch = 0.6890s	
5348/25300 (epoch 10.569), train_loss = 1.20252618, grad/param norm = 1.8784e-01, time/batch = 0.6892s	
5349/25300 (epoch 10.571), train_loss = 1.30031490, grad/param norm = 1.9435e-01, time/batch = 0.6899s	
5350/25300 (epoch 10.573), train_loss = 1.17166597, grad/param norm = 1.7192e-01, time/batch = 0.6907s	
5351/25300 (epoch 10.575), train_loss = 1.27750430, grad/param norm = 1.7978e-01, time/batch = 0.6989s	
5352/25300 (epoch 10.577), train_loss = 1.23841774, grad/param norm = 1.8726e-01, time/batch = 0.7006s	
5353/25300 (epoch 10.579), train_loss = 1.43459862, grad/param norm = 1.9697e-01, time/batch = 0.6970s	
5354/25300 (epoch 10.581), train_loss = 1.24834541, grad/param norm = 1.8352e-01, time/batch = 0.7029s	
5355/25300 (epoch 10.583), train_loss = 1.09680669, grad/param norm = 1.7781e-01, time/batch = 0.6771s	
5356/25300 (epoch 10.585), train_loss = 1.06096689, grad/param norm = 1.7300e-01, time/batch = 0.6762s	
5357/25300 (epoch 10.587), train_loss = 1.15677521, grad/param norm = 1.7776e-01, time/batch = 0.6805s	
5358/25300 (epoch 10.589), train_loss = 1.05345948, grad/param norm = 1.6856e-01, time/batch = 0.6743s	
5359/25300 (epoch 10.591), train_loss = 1.09865125, grad/param norm = 1.8937e-01, time/batch = 0.6735s	
5360/25300 (epoch 10.593), train_loss = 1.19031113, grad/param norm = 1.6072e-01, time/batch = 0.6744s	
5361/25300 (epoch 10.595), train_loss = 1.17349038, grad/param norm = 1.7924e-01, time/batch = 0.6875s	
5362/25300 (epoch 10.597), train_loss = 0.98453005, grad/param norm = 1.4962e-01, time/batch = 0.6842s	
5363/25300 (epoch 10.599), train_loss = 1.20114631, grad/param norm = 1.7547e-01, time/batch = 0.6836s	
5364/25300 (epoch 10.601), train_loss = 1.23131851, grad/param norm = 1.6598e-01, time/batch = 0.6842s	
5365/25300 (epoch 10.603), train_loss = 1.24724045, grad/param norm = 1.7826e-01, time/batch = 0.6789s	
5366/25300 (epoch 10.605), train_loss = 1.09459509, grad/param norm = 1.6844e-01, time/batch = 0.6802s	
5367/25300 (epoch 10.607), train_loss = 0.95145932, grad/param norm = 1.6718e-01, time/batch = 0.6749s	
5368/25300 (epoch 10.609), train_loss = 1.18392334, grad/param norm = 1.8448e-01, time/batch = 0.6728s	
5369/25300 (epoch 10.611), train_loss = 1.28124390, grad/param norm = 1.7673e-01, time/batch = 0.6723s	
5370/25300 (epoch 10.613), train_loss = 1.06759335, grad/param norm = 1.7050e-01, time/batch = 0.6746s	
5371/25300 (epoch 10.615), train_loss = 1.22058809, grad/param norm = 1.7754e-01, time/batch = 0.6807s	
5372/25300 (epoch 10.617), train_loss = 1.19203268, grad/param norm = 1.6861e-01, time/batch = 0.6751s	
5373/25300 (epoch 10.619), train_loss = 1.27872870, grad/param norm = 1.8951e-01, time/batch = 0.6759s	
5374/25300 (epoch 10.621), train_loss = 1.29297807, grad/param norm = 1.9802e-01, time/batch = 0.6753s	
5375/25300 (epoch 10.623), train_loss = 1.12616955, grad/param norm = 1.7909e-01, time/batch = 0.6744s	
5376/25300 (epoch 10.625), train_loss = 0.99024012, grad/param norm = 1.6737e-01, time/batch = 0.6783s	
5377/25300 (epoch 10.626), train_loss = 1.12491857, grad/param norm = 1.6826e-01, time/batch = 0.6785s	
5378/25300 (epoch 10.628), train_loss = 1.31872766, grad/param norm = 1.9502e-01, time/batch = 0.6755s	
5379/25300 (epoch 10.630), train_loss = 1.33641096, grad/param norm = 1.9504e-01, time/batch = 0.6766s	
5380/25300 (epoch 10.632), train_loss = 1.28515375, grad/param norm = 2.0387e-01, time/batch = 0.6770s	
5381/25300 (epoch 10.634), train_loss = 1.30832895, grad/param norm = 1.8517e-01, time/batch = 0.6775s	
5382/25300 (epoch 10.636), train_loss = 1.20128227, grad/param norm = 1.8514e-01, time/batch = 0.6769s	
5383/25300 (epoch 10.638), train_loss = 1.30113285, grad/param norm = 2.1171e-01, time/batch = 0.6775s	
5384/25300 (epoch 10.640), train_loss = 1.44883730, grad/param norm = 2.0644e-01, time/batch = 0.6790s	
5385/25300 (epoch 10.642), train_loss = 1.25733547, grad/param norm = 1.8678e-01, time/batch = 0.6776s	
5386/25300 (epoch 10.644), train_loss = 1.25605858, grad/param norm = 1.9766e-01, time/batch = 0.6724s	
5387/25300 (epoch 10.646), train_loss = 1.21765264, grad/param norm = 1.8611e-01, time/batch = 0.6774s	
5388/25300 (epoch 10.648), train_loss = 1.29655478, grad/param norm = 1.8749e-01, time/batch = 0.6757s	
5389/25300 (epoch 10.650), train_loss = 1.24864927, grad/param norm = 1.8426e-01, time/batch = 0.6700s	
5390/25300 (epoch 10.652), train_loss = 1.24974961, grad/param norm = 1.9218e-01, time/batch = 0.6734s	
5391/25300 (epoch 10.654), train_loss = 1.40813310, grad/param norm = 1.9078e-01, time/batch = 0.6815s	
5392/25300 (epoch 10.656), train_loss = 1.32312904, grad/param norm = 1.8610e-01, time/batch = 0.6844s	
5393/25300 (epoch 10.658), train_loss = 1.01953359, grad/param norm = 1.5553e-01, time/batch = 0.6859s	
5394/25300 (epoch 10.660), train_loss = 1.07122024, grad/param norm = 1.7654e-01, time/batch = 0.6822s	
5395/25300 (epoch 10.662), train_loss = 1.02961760, grad/param norm = 1.6981e-01, time/batch = 0.6832s	
5396/25300 (epoch 10.664), train_loss = 1.01598588, grad/param norm = 1.6572e-01, time/batch = 0.6879s	
5397/25300 (epoch 10.666), train_loss = 1.03674496, grad/param norm = 1.6889e-01, time/batch = 0.6800s	
5398/25300 (epoch 10.668), train_loss = 1.11309126, grad/param norm = 1.9879e-01, time/batch = 0.6743s	
5399/25300 (epoch 10.670), train_loss = 1.07821480, grad/param norm = 1.7401e-01, time/batch = 0.6744s	
5400/25300 (epoch 10.672), train_loss = 1.09694510, grad/param norm = 1.7488e-01, time/batch = 0.6721s	
5401/25300 (epoch 10.674), train_loss = 1.12925270, grad/param norm = 1.7755e-01, time/batch = 0.6794s	
5402/25300 (epoch 10.676), train_loss = 1.20872312, grad/param norm = 1.8939e-01, time/batch = 0.6752s	
5403/25300 (epoch 10.678), train_loss = 1.15081085, grad/param norm = 2.0560e-01, time/batch = 0.6771s	
5404/25300 (epoch 10.680), train_loss = 1.02465938, grad/param norm = 1.7962e-01, time/batch = 0.6755s	
5405/25300 (epoch 10.682), train_loss = 0.88445793, grad/param norm = 1.5711e-01, time/batch = 0.6738s	
5406/25300 (epoch 10.684), train_loss = 1.05007505, grad/param norm = 1.5707e-01, time/batch = 0.6758s	
5407/25300 (epoch 10.686), train_loss = 1.02546000, grad/param norm = 1.5390e-01, time/batch = 0.6813s	
5408/25300 (epoch 10.688), train_loss = 1.17840106, grad/param norm = 1.7578e-01, time/batch = 0.7009s	
5409/25300 (epoch 10.690), train_loss = 1.05660864, grad/param norm = 1.5533e-01, time/batch = 0.6873s	
5410/25300 (epoch 10.692), train_loss = 1.19709840, grad/param norm = 1.6909e-01, time/batch = 0.6850s	
5411/25300 (epoch 10.694), train_loss = 1.11332462, grad/param norm = 1.6131e-01, time/batch = 0.6815s	
5412/25300 (epoch 10.696), train_loss = 1.18620333, grad/param norm = 1.8018e-01, time/batch = 0.6813s	
5413/25300 (epoch 10.698), train_loss = 1.24901503, grad/param norm = 1.7872e-01, time/batch = 0.6827s	
5414/25300 (epoch 10.700), train_loss = 0.98079785, grad/param norm = 1.5773e-01, time/batch = 0.6753s	
5415/25300 (epoch 10.702), train_loss = 1.27643487, grad/param norm = 1.8446e-01, time/batch = 0.6726s	
5416/25300 (epoch 10.704), train_loss = 0.95692180, grad/param norm = 1.6310e-01, time/batch = 0.6748s	
5417/25300 (epoch 10.706), train_loss = 1.20830000, grad/param norm = 2.0619e-01, time/batch = 0.6751s	
5418/25300 (epoch 10.708), train_loss = 0.96511195, grad/param norm = 1.5419e-01, time/batch = 0.6773s	
5419/25300 (epoch 10.709), train_loss = 1.32511805, grad/param norm = 1.7873e-01, time/batch = 0.6754s	
5420/25300 (epoch 10.711), train_loss = 1.38061248, grad/param norm = 1.8864e-01, time/batch = 0.6771s	
5421/25300 (epoch 10.713), train_loss = 1.13371106, grad/param norm = 1.7263e-01, time/batch = 0.6793s	
5422/25300 (epoch 10.715), train_loss = 1.13894094, grad/param norm = 1.8219e-01, time/batch = 0.6763s	
5423/25300 (epoch 10.717), train_loss = 1.15818019, grad/param norm = 1.8396e-01, time/batch = 0.6767s	
5424/25300 (epoch 10.719), train_loss = 1.16728740, grad/param norm = 1.7906e-01, time/batch = 0.6767s	
5425/25300 (epoch 10.721), train_loss = 1.22027787, grad/param norm = 2.0470e-01, time/batch = 0.6755s	
5426/25300 (epoch 10.723), train_loss = 1.11451896, grad/param norm = 1.7929e-01, time/batch = 0.6751s	
5427/25300 (epoch 10.725), train_loss = 1.21085825, grad/param norm = 1.7519e-01, time/batch = 0.6734s	
5428/25300 (epoch 10.727), train_loss = 1.21174615, grad/param norm = 1.7930e-01, time/batch = 0.6753s	
5429/25300 (epoch 10.729), train_loss = 1.12734649, grad/param norm = 1.7398e-01, time/batch = 0.6776s	
5430/25300 (epoch 10.731), train_loss = 1.40749205, grad/param norm = 1.9920e-01, time/batch = 0.6767s	
5431/25300 (epoch 10.733), train_loss = 1.10690406, grad/param norm = 1.5756e-01, time/batch = 0.6824s	
5432/25300 (epoch 10.735), train_loss = 1.49511479, grad/param norm = 2.0180e-01, time/batch = 0.6768s	
5433/25300 (epoch 10.737), train_loss = 1.01461382, grad/param norm = 1.6420e-01, time/batch = 0.6732s	
5434/25300 (epoch 10.739), train_loss = 1.31180630, grad/param norm = 1.8201e-01, time/batch = 0.6731s	
5435/25300 (epoch 10.741), train_loss = 1.23359019, grad/param norm = 1.9942e-01, time/batch = 0.6757s	
5436/25300 (epoch 10.743), train_loss = 1.10974392, grad/param norm = 1.6940e-01, time/batch = 0.6740s	
5437/25300 (epoch 10.745), train_loss = 1.10649444, grad/param norm = 1.6970e-01, time/batch = 0.6762s	
5438/25300 (epoch 10.747), train_loss = 1.01645442, grad/param norm = 1.5423e-01, time/batch = 0.6786s	
5439/25300 (epoch 10.749), train_loss = 1.24442640, grad/param norm = 1.8769e-01, time/batch = 0.6758s	
5440/25300 (epoch 10.751), train_loss = 1.32878934, grad/param norm = 2.0167e-01, time/batch = 0.6793s	
5441/25300 (epoch 10.753), train_loss = 1.11533408, grad/param norm = 1.8552e-01, time/batch = 0.6760s	
5442/25300 (epoch 10.755), train_loss = 1.29501151, grad/param norm = 2.0471e-01, time/batch = 0.6743s	
5443/25300 (epoch 10.757), train_loss = 1.07976373, grad/param norm = 1.7851e-01, time/batch = 0.6710s	
5444/25300 (epoch 10.759), train_loss = 1.07057186, grad/param norm = 1.7805e-01, time/batch = 0.6769s	
5445/25300 (epoch 10.761), train_loss = 1.30951311, grad/param norm = 1.9202e-01, time/batch = 0.6743s	
5446/25300 (epoch 10.763), train_loss = 1.08728517, grad/param norm = 1.6968e-01, time/batch = 0.6761s	
5447/25300 (epoch 10.765), train_loss = 1.13261132, grad/param norm = 1.8387e-01, time/batch = 0.6747s	
5448/25300 (epoch 10.767), train_loss = 1.07102045, grad/param norm = 1.6275e-01, time/batch = 0.6710s	
5449/25300 (epoch 10.769), train_loss = 1.24473956, grad/param norm = 1.9244e-01, time/batch = 0.6760s	
5450/25300 (epoch 10.771), train_loss = 1.37236047, grad/param norm = 1.9975e-01, time/batch = 0.6740s	
5451/25300 (epoch 10.773), train_loss = 1.33597987, grad/param norm = 2.0198e-01, time/batch = 0.6780s	
5452/25300 (epoch 10.775), train_loss = 1.13822527, grad/param norm = 1.6385e-01, time/batch = 0.6697s	
5453/25300 (epoch 10.777), train_loss = 1.23159977, grad/param norm = 1.8763e-01, time/batch = 0.6790s	
5454/25300 (epoch 10.779), train_loss = 1.30029617, grad/param norm = 1.7468e-01, time/batch = 0.6763s	
5455/25300 (epoch 10.781), train_loss = 1.16290444, grad/param norm = 1.6505e-01, time/batch = 0.6760s	
5456/25300 (epoch 10.783), train_loss = 1.37080180, grad/param norm = 2.0122e-01, time/batch = 0.6758s	
5457/25300 (epoch 10.785), train_loss = 1.28338621, grad/param norm = 1.8256e-01, time/batch = 0.6743s	
5458/25300 (epoch 10.787), train_loss = 1.30338986, grad/param norm = 1.8195e-01, time/batch = 0.6747s	
5459/25300 (epoch 10.789), train_loss = 1.41168709, grad/param norm = 1.8427e-01, time/batch = 0.6762s	
5460/25300 (epoch 10.791), train_loss = 1.21267128, grad/param norm = 1.8889e-01, time/batch = 0.6792s	
5461/25300 (epoch 10.792), train_loss = 1.27647497, grad/param norm = 1.7166e-01, time/batch = 0.6793s	
5462/25300 (epoch 10.794), train_loss = 1.22043448, grad/param norm = 1.7932e-01, time/batch = 0.6719s	
5463/25300 (epoch 10.796), train_loss = 1.16000236, grad/param norm = 1.6963e-01, time/batch = 0.6736s	
5464/25300 (epoch 10.798), train_loss = 1.35587152, grad/param norm = 1.9198e-01, time/batch = 0.6761s	
5465/25300 (epoch 10.800), train_loss = 1.20051573, grad/param norm = 1.8461e-01, time/batch = 0.6792s	
5466/25300 (epoch 10.802), train_loss = 0.96251937, grad/param norm = 1.6086e-01, time/batch = 0.6836s	
5467/25300 (epoch 10.804), train_loss = 1.20513828, grad/param norm = 1.6925e-01, time/batch = 0.6809s	
5468/25300 (epoch 10.806), train_loss = 1.27638941, grad/param norm = 1.7442e-01, time/batch = 0.6763s	
5469/25300 (epoch 10.808), train_loss = 1.22477440, grad/param norm = 1.8687e-01, time/batch = 0.6716s	
5470/25300 (epoch 10.810), train_loss = 1.21828822, grad/param norm = 1.9572e-01, time/batch = 0.6756s	
5471/25300 (epoch 10.812), train_loss = 1.28851580, grad/param norm = 1.9241e-01, time/batch = 0.6751s	
5472/25300 (epoch 10.814), train_loss = 1.37608752, grad/param norm = 1.8845e-01, time/batch = 0.6768s	
5473/25300 (epoch 10.816), train_loss = 1.49663457, grad/param norm = 1.8278e-01, time/batch = 0.6749s	
5474/25300 (epoch 10.818), train_loss = 1.29843463, grad/param norm = 1.8159e-01, time/batch = 0.6695s	
5475/25300 (epoch 10.820), train_loss = 1.25457488, grad/param norm = 1.7627e-01, time/batch = 0.6731s	
5476/25300 (epoch 10.822), train_loss = 1.21017513, grad/param norm = 1.7366e-01, time/batch = 0.6726s	
5477/25300 (epoch 10.824), train_loss = 1.28073898, grad/param norm = 1.8521e-01, time/batch = 0.6783s	
5478/25300 (epoch 10.826), train_loss = 1.12261199, grad/param norm = 1.7496e-01, time/batch = 0.6749s	
5479/25300 (epoch 10.828), train_loss = 1.11499573, grad/param norm = 1.8287e-01, time/batch = 0.6800s	
5480/25300 (epoch 10.830), train_loss = 1.19388505, grad/param norm = 1.7426e-01, time/batch = 0.6838s	
5481/25300 (epoch 10.832), train_loss = 1.23863786, grad/param norm = 1.7491e-01, time/batch = 0.6879s	
5482/25300 (epoch 10.834), train_loss = 1.04937483, grad/param norm = 1.5836e-01, time/batch = 0.6953s	
5483/25300 (epoch 10.836), train_loss = 1.11985827, grad/param norm = 1.6225e-01, time/batch = 0.6905s	
5484/25300 (epoch 10.838), train_loss = 1.18029597, grad/param norm = 1.7418e-01, time/batch = 0.6867s	
5485/25300 (epoch 10.840), train_loss = 1.36287675, grad/param norm = 1.9323e-01, time/batch = 0.6887s	
5486/25300 (epoch 10.842), train_loss = 1.20492120, grad/param norm = 2.1813e-01, time/batch = 0.6860s	
5487/25300 (epoch 10.844), train_loss = 1.21540904, grad/param norm = 1.6835e-01, time/batch = 0.6872s	
5488/25300 (epoch 10.846), train_loss = 1.22205083, grad/param norm = 1.6958e-01, time/batch = 0.6876s	
5489/25300 (epoch 10.848), train_loss = 1.36289805, grad/param norm = 1.8774e-01, time/batch = 0.6798s	
5490/25300 (epoch 10.850), train_loss = 1.29693480, grad/param norm = 1.8629e-01, time/batch = 0.6804s	
5491/25300 (epoch 10.852), train_loss = 1.23052507, grad/param norm = 1.8660e-01, time/batch = 0.6772s	
5492/25300 (epoch 10.854), train_loss = 1.40958629, grad/param norm = 1.9730e-01, time/batch = 0.6765s	
5493/25300 (epoch 10.856), train_loss = 1.19308433, grad/param norm = 1.7696e-01, time/batch = 0.6757s	
5494/25300 (epoch 10.858), train_loss = 1.27579281, grad/param norm = 2.0334e-01, time/batch = 0.6787s	
5495/25300 (epoch 10.860), train_loss = 1.00474006, grad/param norm = 1.6715e-01, time/batch = 0.6780s	
5496/25300 (epoch 10.862), train_loss = 1.26389931, grad/param norm = 2.0322e-01, time/batch = 0.6774s	
5497/25300 (epoch 10.864), train_loss = 1.32623081, grad/param norm = 1.9646e-01, time/batch = 0.6762s	
5498/25300 (epoch 10.866), train_loss = 1.28024734, grad/param norm = 2.1206e-01, time/batch = 0.6795s	
5499/25300 (epoch 10.868), train_loss = 1.32771964, grad/param norm = 1.9868e-01, time/batch = 0.6788s	
5500/25300 (epoch 10.870), train_loss = 1.30007840, grad/param norm = 1.7280e-01, time/batch = 0.6783s	
5501/25300 (epoch 10.872), train_loss = 1.30631590, grad/param norm = 2.0544e-01, time/batch = 0.6817s	
5502/25300 (epoch 10.874), train_loss = 1.30623023, grad/param norm = 1.9117e-01, time/batch = 0.6761s	
5503/25300 (epoch 10.875), train_loss = 1.19875832, grad/param norm = 1.7963e-01, time/batch = 0.6763s	
5504/25300 (epoch 10.877), train_loss = 1.12497567, grad/param norm = 1.5856e-01, time/batch = 0.6752s	
5505/25300 (epoch 10.879), train_loss = 1.23802465, grad/param norm = 1.8603e-01, time/batch = 0.6753s	
5506/25300 (epoch 10.881), train_loss = 1.54126171, grad/param norm = 2.0532e-01, time/batch = 0.6756s	
5507/25300 (epoch 10.883), train_loss = 1.47370989, grad/param norm = 1.8281e-01, time/batch = 0.6729s	
5508/25300 (epoch 10.885), train_loss = 1.31403390, grad/param norm = 1.9018e-01, time/batch = 0.6792s	
5509/25300 (epoch 10.887), train_loss = 1.24741134, grad/param norm = 1.7827e-01, time/batch = 0.6925s	
5510/25300 (epoch 10.889), train_loss = 1.38640377, grad/param norm = 1.8106e-01, time/batch = 0.6778s	
5511/25300 (epoch 10.891), train_loss = 1.30521615, grad/param norm = 2.1680e-01, time/batch = 0.6845s	
5512/25300 (epoch 10.893), train_loss = 1.43564430, grad/param norm = 1.8968e-01, time/batch = 0.6815s	
5513/25300 (epoch 10.895), train_loss = 0.97883731, grad/param norm = 1.7919e-01, time/batch = 0.6801s	
5514/25300 (epoch 10.897), train_loss = 1.10875037, grad/param norm = 1.6737e-01, time/batch = 0.6860s	
5515/25300 (epoch 10.899), train_loss = 1.20595411, grad/param norm = 1.8756e-01, time/batch = 0.6764s	
5516/25300 (epoch 10.901), train_loss = 1.25040970, grad/param norm = 1.8016e-01, time/batch = 0.6751s	
5517/25300 (epoch 10.903), train_loss = 1.00908606, grad/param norm = 1.6624e-01, time/batch = 0.6769s	
5518/25300 (epoch 10.905), train_loss = 1.12545184, grad/param norm = 1.8375e-01, time/batch = 0.6764s	
5519/25300 (epoch 10.907), train_loss = 1.24723827, grad/param norm = 2.1925e-01, time/batch = 0.6771s	
5520/25300 (epoch 10.909), train_loss = 1.33916368, grad/param norm = 1.9710e-01, time/batch = 0.6759s	
5521/25300 (epoch 10.911), train_loss = 1.47712567, grad/param norm = 2.0408e-01, time/batch = 0.6776s	
5522/25300 (epoch 10.913), train_loss = 1.43759003, grad/param norm = 2.0117e-01, time/batch = 0.6764s	
5523/25300 (epoch 10.915), train_loss = 1.13999301, grad/param norm = 1.7596e-01, time/batch = 0.6774s	
5524/25300 (epoch 10.917), train_loss = 1.28039761, grad/param norm = 1.8756e-01, time/batch = 0.6770s	
5525/25300 (epoch 10.919), train_loss = 1.41754038, grad/param norm = 2.0268e-01, time/batch = 0.6754s	
5526/25300 (epoch 10.921), train_loss = 1.13271323, grad/param norm = 1.7697e-01, time/batch = 0.6748s	
5527/25300 (epoch 10.923), train_loss = 1.38675510, grad/param norm = 1.9179e-01, time/batch = 0.6736s	
5528/25300 (epoch 10.925), train_loss = 1.21598608, grad/param norm = 1.8586e-01, time/batch = 0.6822s	
5529/25300 (epoch 10.927), train_loss = 1.20538338, grad/param norm = 1.7703e-01, time/batch = 0.6745s	
5530/25300 (epoch 10.929), train_loss = 1.13194765, grad/param norm = 1.6864e-01, time/batch = 0.6749s	
5531/25300 (epoch 10.931), train_loss = 1.36237521, grad/param norm = 1.9223e-01, time/batch = 0.6793s	
5532/25300 (epoch 10.933), train_loss = 1.28364495, grad/param norm = 1.8798e-01, time/batch = 0.6776s	
5533/25300 (epoch 10.935), train_loss = 1.26298000, grad/param norm = 1.7503e-01, time/batch = 0.6798s	
5534/25300 (epoch 10.937), train_loss = 0.97168227, grad/param norm = 1.4950e-01, time/batch = 0.6785s	
5535/25300 (epoch 10.939), train_loss = 1.32441536, grad/param norm = 1.8890e-01, time/batch = 0.6775s	
5536/25300 (epoch 10.941), train_loss = 1.17478202, grad/param norm = 1.6743e-01, time/batch = 0.6753s	
5537/25300 (epoch 10.943), train_loss = 1.18088106, grad/param norm = 1.7186e-01, time/batch = 0.6760s	
5538/25300 (epoch 10.945), train_loss = 1.25659473, grad/param norm = 1.8695e-01, time/batch = 0.6798s	
5539/25300 (epoch 10.947), train_loss = 1.11851974, grad/param norm = 1.7603e-01, time/batch = 0.6790s	
5540/25300 (epoch 10.949), train_loss = 1.30495554, grad/param norm = 1.9596e-01, time/batch = 0.6781s	
5541/25300 (epoch 10.951), train_loss = 1.19835903, grad/param norm = 1.7226e-01, time/batch = 0.6782s	
5542/25300 (epoch 10.953), train_loss = 1.27882206, grad/param norm = 1.6521e-01, time/batch = 0.6780s	
5543/25300 (epoch 10.955), train_loss = 1.49059598, grad/param norm = 2.0646e-01, time/batch = 0.6773s	
5544/25300 (epoch 10.957), train_loss = 1.44921518, grad/param norm = 2.0206e-01, time/batch = 0.6769s	
5545/25300 (epoch 10.958), train_loss = 1.27746116, grad/param norm = 1.8142e-01, time/batch = 0.6772s	
5546/25300 (epoch 10.960), train_loss = 1.43575066, grad/param norm = 1.9625e-01, time/batch = 0.6788s	
5547/25300 (epoch 10.962), train_loss = 1.40850137, grad/param norm = 2.0019e-01, time/batch = 0.6767s	
5548/25300 (epoch 10.964), train_loss = 1.29910404, grad/param norm = 1.6963e-01, time/batch = 0.6776s	
5549/25300 (epoch 10.966), train_loss = 1.07250111, grad/param norm = 1.5845e-01, time/batch = 0.6756s	
5550/25300 (epoch 10.968), train_loss = 1.05315483, grad/param norm = 1.6487e-01, time/batch = 0.6754s	
5551/25300 (epoch 10.970), train_loss = 1.22922295, grad/param norm = 1.9814e-01, time/batch = 0.6769s	
5552/25300 (epoch 10.972), train_loss = 1.23432346, grad/param norm = 1.9510e-01, time/batch = 0.6766s	
5553/25300 (epoch 10.974), train_loss = 1.43754710, grad/param norm = 2.1029e-01, time/batch = 0.6734s	
5554/25300 (epoch 10.976), train_loss = 1.25169782, grad/param norm = 1.8892e-01, time/batch = 0.6749s	
5555/25300 (epoch 10.978), train_loss = 1.28188811, grad/param norm = 1.8930e-01, time/batch = 0.6750s	
5556/25300 (epoch 10.980), train_loss = 1.27986700, grad/param norm = 2.0160e-01, time/batch = 0.6751s	
5557/25300 (epoch 10.982), train_loss = 1.21338323, grad/param norm = 1.6902e-01, time/batch = 0.6758s	
5558/25300 (epoch 10.984), train_loss = 1.23131504, grad/param norm = 1.7953e-01, time/batch = 0.6749s	
5559/25300 (epoch 10.986), train_loss = 1.28982655, grad/param norm = 1.9426e-01, time/batch = 0.6803s	
5560/25300 (epoch 10.988), train_loss = 1.31315488, grad/param norm = 2.0549e-01, time/batch = 0.6739s	
5561/25300 (epoch 10.990), train_loss = 1.23483548, grad/param norm = 1.6729e-01, time/batch = 0.6765s	
5562/25300 (epoch 10.992), train_loss = 0.98238593, grad/param norm = 1.6523e-01, time/batch = 0.6747s	
5563/25300 (epoch 10.994), train_loss = 1.24945468, grad/param norm = 1.8150e-01, time/batch = 0.6751s	
5564/25300 (epoch 10.996), train_loss = 1.38496285, grad/param norm = 2.0572e-01, time/batch = 0.6756s	
5565/25300 (epoch 10.998), train_loss = 1.36987708, grad/param norm = 1.9619e-01, time/batch = 0.6781s	
decayed learning rate by a factor 0.97 to 0.0018818	
5566/25300 (epoch 11.000), train_loss = 1.22174086, grad/param norm = 1.8294e-01, time/batch = 0.6758s	
5567/25300 (epoch 11.002), train_loss = 1.07069251, grad/param norm = 1.5612e-01, time/batch = 0.6793s	
5568/25300 (epoch 11.004), train_loss = 1.02001957, grad/param norm = 1.6782e-01, time/batch = 0.6856s	
5569/25300 (epoch 11.006), train_loss = 1.31307818, grad/param norm = 1.7833e-01, time/batch = 0.6870s	
5570/25300 (epoch 11.008), train_loss = 1.22648745, grad/param norm = 1.6859e-01, time/batch = 0.6820s	
5571/25300 (epoch 11.010), train_loss = 1.23650170, grad/param norm = 1.5843e-01, time/batch = 0.6737s	
5572/25300 (epoch 11.012), train_loss = 1.09743112, grad/param norm = 1.8872e-01, time/batch = 0.6828s	
5573/25300 (epoch 11.014), train_loss = 1.31769134, grad/param norm = 2.0071e-01, time/batch = 0.6910s	
5574/25300 (epoch 11.016), train_loss = 1.28222431, grad/param norm = 2.0368e-01, time/batch = 0.6828s	
5575/25300 (epoch 11.018), train_loss = 1.10584764, grad/param norm = 1.7713e-01, time/batch = 0.6795s	
5576/25300 (epoch 11.020), train_loss = 1.17169248, grad/param norm = 1.7595e-01, time/batch = 0.6752s	
5577/25300 (epoch 11.022), train_loss = 1.23695648, grad/param norm = 1.8580e-01, time/batch = 0.6751s	
5578/25300 (epoch 11.024), train_loss = 0.92483369, grad/param norm = 1.5564e-01, time/batch = 0.6721s	
5579/25300 (epoch 11.026), train_loss = 1.13384712, grad/param norm = 1.9786e-01, time/batch = 0.6745s	
5580/25300 (epoch 11.028), train_loss = 1.05003419, grad/param norm = 1.5031e-01, time/batch = 0.6742s	
5581/25300 (epoch 11.030), train_loss = 1.29806018, grad/param norm = 1.7611e-01, time/batch = 0.6750s	
5582/25300 (epoch 11.032), train_loss = 1.14472460, grad/param norm = 1.6834e-01, time/batch = 0.6784s	
5583/25300 (epoch 11.034), train_loss = 0.98673372, grad/param norm = 1.8432e-01, time/batch = 0.6742s	
5584/25300 (epoch 11.036), train_loss = 1.03496731, grad/param norm = 1.7517e-01, time/batch = 0.6730s	
5585/25300 (epoch 11.038), train_loss = 0.91110540, grad/param norm = 1.4089e-01, time/batch = 0.6733s	
5586/25300 (epoch 11.040), train_loss = 1.25639686, grad/param norm = 1.7178e-01, time/batch = 0.6720s	
5587/25300 (epoch 11.042), train_loss = 1.09250506, grad/param norm = 1.6198e-01, time/batch = 0.6722s	
5588/25300 (epoch 11.043), train_loss = 0.99004225, grad/param norm = 1.4995e-01, time/batch = 0.6733s	
5589/25300 (epoch 11.045), train_loss = 1.01728866, grad/param norm = 1.6543e-01, time/batch = 0.6749s	
5590/25300 (epoch 11.047), train_loss = 1.23708099, grad/param norm = 1.6383e-01, time/batch = 0.6720s	
5591/25300 (epoch 11.049), train_loss = 1.24184112, grad/param norm = 1.9231e-01, time/batch = 0.6754s	
5592/25300 (epoch 11.051), train_loss = 1.31931035, grad/param norm = 2.0269e-01, time/batch = 0.6742s	
5593/25300 (epoch 11.053), train_loss = 0.97581956, grad/param norm = 1.5737e-01, time/batch = 0.6724s	
5594/25300 (epoch 11.055), train_loss = 1.03621007, grad/param norm = 1.5818e-01, time/batch = 0.6695s	
5595/25300 (epoch 11.057), train_loss = 0.96636142, grad/param norm = 1.5027e-01, time/batch = 0.6721s	
5596/25300 (epoch 11.059), train_loss = 1.16811406, grad/param norm = 1.7927e-01, time/batch = 0.6756s	
5597/25300 (epoch 11.061), train_loss = 1.07426143, grad/param norm = 1.6200e-01, time/batch = 0.6740s	
5598/25300 (epoch 11.063), train_loss = 1.08521418, grad/param norm = 1.7306e-01, time/batch = 0.6789s	
5599/25300 (epoch 11.065), train_loss = 1.29736757, grad/param norm = 1.8479e-01, time/batch = 0.6781s	
5600/25300 (epoch 11.067), train_loss = 1.32768461, grad/param norm = 1.8421e-01, time/batch = 0.6841s	
5601/25300 (epoch 11.069), train_loss = 1.18051057, grad/param norm = 1.7411e-01, time/batch = 0.6876s	
5602/25300 (epoch 11.071), train_loss = 1.32962552, grad/param norm = 1.6963e-01, time/batch = 0.6830s	
5603/25300 (epoch 11.073), train_loss = 1.14310713, grad/param norm = 1.6386e-01, time/batch = 0.6856s	
5604/25300 (epoch 11.075), train_loss = 1.20594356, grad/param norm = 1.6981e-01, time/batch = 0.6830s	
5605/25300 (epoch 11.077), train_loss = 1.26693905, grad/param norm = 1.8960e-01, time/batch = 0.6825s	
5606/25300 (epoch 11.079), train_loss = 1.19912484, grad/param norm = 1.7370e-01, time/batch = 0.6768s	
5607/25300 (epoch 11.081), train_loss = 1.16951990, grad/param norm = 1.6354e-01, time/batch = 0.6770s	
5608/25300 (epoch 11.083), train_loss = 1.11914707, grad/param norm = 1.5820e-01, time/batch = 0.6812s	
5609/25300 (epoch 11.085), train_loss = 1.40572923, grad/param norm = 1.9651e-01, time/batch = 0.6846s	
5610/25300 (epoch 11.087), train_loss = 1.20920279, grad/param norm = 1.8560e-01, time/batch = 0.6772s	
5611/25300 (epoch 11.089), train_loss = 1.22899490, grad/param norm = 1.7597e-01, time/batch = 0.6815s	
5612/25300 (epoch 11.091), train_loss = 1.34888429, grad/param norm = 1.8786e-01, time/batch = 0.6809s	
5613/25300 (epoch 11.093), train_loss = 1.32873690, grad/param norm = 1.8465e-01, time/batch = 0.6825s	
5614/25300 (epoch 11.095), train_loss = 1.25320929, grad/param norm = 1.6907e-01, time/batch = 0.6812s	
5615/25300 (epoch 11.097), train_loss = 1.21229571, grad/param norm = 1.6653e-01, time/batch = 0.6801s	
5616/25300 (epoch 11.099), train_loss = 1.24292268, grad/param norm = 1.8603e-01, time/batch = 0.6855s	
5617/25300 (epoch 11.101), train_loss = 1.18124784, grad/param norm = 1.7270e-01, time/batch = 0.6798s	
5618/25300 (epoch 11.103), train_loss = 1.14807382, grad/param norm = 1.7402e-01, time/batch = 0.6740s	
5619/25300 (epoch 11.105), train_loss = 1.23484037, grad/param norm = 1.9184e-01, time/batch = 0.6734s	
5620/25300 (epoch 11.107), train_loss = 1.30128696, grad/param norm = 1.9073e-01, time/batch = 0.6752s	
5621/25300 (epoch 11.109), train_loss = 1.21376430, grad/param norm = 1.8603e-01, time/batch = 0.6743s	
5622/25300 (epoch 11.111), train_loss = 1.16915833, grad/param norm = 1.7444e-01, time/batch = 0.6746s	
5623/25300 (epoch 11.113), train_loss = 1.20236422, grad/param norm = 1.8981e-01, time/batch = 0.6748s	
5624/25300 (epoch 11.115), train_loss = 1.18361175, grad/param norm = 1.7749e-01, time/batch = 0.6745s	
5625/25300 (epoch 11.117), train_loss = 1.27402006, grad/param norm = 1.7797e-01, time/batch = 0.6759s	
5626/25300 (epoch 11.119), train_loss = 1.17697930, grad/param norm = 1.7712e-01, time/batch = 0.6749s	
5627/25300 (epoch 11.121), train_loss = 1.28682862, grad/param norm = 1.9657e-01, time/batch = 0.6766s	
5628/25300 (epoch 11.123), train_loss = 1.20030277, grad/param norm = 1.9649e-01, time/batch = 0.6750s	
5629/25300 (epoch 11.125), train_loss = 1.30057151, grad/param norm = 1.9004e-01, time/batch = 0.6763s	
5630/25300 (epoch 11.126), train_loss = 1.22565899, grad/param norm = 1.8602e-01, time/batch = 0.6748s	
5631/25300 (epoch 11.128), train_loss = 1.22540533, grad/param norm = 1.7260e-01, time/batch = 0.6789s	
5632/25300 (epoch 11.130), train_loss = 0.95366570, grad/param norm = 1.6443e-01, time/batch = 0.6748s	
5633/25300 (epoch 11.132), train_loss = 1.03745142, grad/param norm = 1.5710e-01, time/batch = 0.6778s	
5634/25300 (epoch 11.134), train_loss = 0.95435954, grad/param norm = 1.4834e-01, time/batch = 0.6914s	
5635/25300 (epoch 11.136), train_loss = 1.24433921, grad/param norm = 1.7390e-01, time/batch = 0.6844s	
5636/25300 (epoch 11.138), train_loss = 1.04616327, grad/param norm = 1.6019e-01, time/batch = 0.6835s	
5637/25300 (epoch 11.140), train_loss = 1.11601505, grad/param norm = 1.6909e-01, time/batch = 0.6782s	
5638/25300 (epoch 11.142), train_loss = 1.28357221, grad/param norm = 1.7891e-01, time/batch = 0.6787s	
5639/25300 (epoch 11.144), train_loss = 1.21872384, grad/param norm = 1.7760e-01, time/batch = 0.6787s	
5640/25300 (epoch 11.146), train_loss = 1.33342815, grad/param norm = 1.9979e-01, time/batch = 0.6757s	
5641/25300 (epoch 11.148), train_loss = 1.18566018, grad/param norm = 1.7563e-01, time/batch = 0.6775s	
5642/25300 (epoch 11.150), train_loss = 1.31590200, grad/param norm = 2.0691e-01, time/batch = 0.6768s	
5643/25300 (epoch 11.152), train_loss = 1.44046168, grad/param norm = 2.0406e-01, time/batch = 0.6755s	
5644/25300 (epoch 11.154), train_loss = 1.08503707, grad/param norm = 1.7189e-01, time/batch = 0.6750s	
5645/25300 (epoch 11.156), train_loss = 1.24054729, grad/param norm = 1.7230e-01, time/batch = 0.6758s	
5646/25300 (epoch 11.158), train_loss = 1.11905739, grad/param norm = 1.6434e-01, time/batch = 0.6755s	
5647/25300 (epoch 11.160), train_loss = 1.21526215, grad/param norm = 1.7409e-01, time/batch = 0.6764s	
5648/25300 (epoch 11.162), train_loss = 1.12532718, grad/param norm = 1.8170e-01, time/batch = 0.6748s	
5649/25300 (epoch 11.164), train_loss = 1.27499747, grad/param norm = 1.7719e-01, time/batch = 0.6784s	
5650/25300 (epoch 11.166), train_loss = 1.23327915, grad/param norm = 1.8066e-01, time/batch = 0.6757s	
5651/25300 (epoch 11.168), train_loss = 1.04943293, grad/param norm = 1.5083e-01, time/batch = 0.6779s	
5652/25300 (epoch 11.170), train_loss = 1.13593798, grad/param norm = 1.6679e-01, time/batch = 0.6772s	
5653/25300 (epoch 11.172), train_loss = 1.08875147, grad/param norm = 1.6398e-01, time/batch = 0.6758s	
5654/25300 (epoch 11.174), train_loss = 1.05313709, grad/param norm = 1.6481e-01, time/batch = 0.6766s	
5655/25300 (epoch 11.176), train_loss = 1.15932863, grad/param norm = 1.7987e-01, time/batch = 0.6795s	
5656/25300 (epoch 11.178), train_loss = 1.35546899, grad/param norm = 1.9500e-01, time/batch = 0.6856s	
5657/25300 (epoch 11.180), train_loss = 0.99806809, grad/param norm = 1.6269e-01, time/batch = 0.6866s	
5658/25300 (epoch 11.182), train_loss = 1.11461025, grad/param norm = 1.6497e-01, time/batch = 0.6859s	
5659/25300 (epoch 11.184), train_loss = 1.17634896, grad/param norm = 1.8271e-01, time/batch = 0.6826s	
5660/25300 (epoch 11.186), train_loss = 1.13981385, grad/param norm = 1.7680e-01, time/batch = 0.6924s	
5661/25300 (epoch 11.188), train_loss = 1.18107561, grad/param norm = 1.7767e-01, time/batch = 0.6802s	
5662/25300 (epoch 11.190), train_loss = 1.22917276, grad/param norm = 1.8094e-01, time/batch = 0.6715s	
5663/25300 (epoch 11.192), train_loss = 1.13755789, grad/param norm = 1.8073e-01, time/batch = 0.6934s	
5664/25300 (epoch 11.194), train_loss = 1.15632432, grad/param norm = 1.8308e-01, time/batch = 0.6863s	
5665/25300 (epoch 11.196), train_loss = 1.29032493, grad/param norm = 2.0388e-01, time/batch = 0.6889s	
5666/25300 (epoch 11.198), train_loss = 1.13842797, grad/param norm = 1.9980e-01, time/batch = 0.6811s	
5667/25300 (epoch 11.200), train_loss = 1.21110056, grad/param norm = 1.9636e-01, time/batch = 0.6806s	
5668/25300 (epoch 11.202), train_loss = 1.19775342, grad/param norm = 1.8044e-01, time/batch = 0.6859s	
5669/25300 (epoch 11.204), train_loss = 1.15660302, grad/param norm = 1.7719e-01, time/batch = 0.6722s	
5670/25300 (epoch 11.206), train_loss = 1.27201873, grad/param norm = 1.9125e-01, time/batch = 0.6722s	
5671/25300 (epoch 11.208), train_loss = 1.06236763, grad/param norm = 1.8399e-01, time/batch = 0.6754s	
5672/25300 (epoch 11.209), train_loss = 0.98299673, grad/param norm = 1.6772e-01, time/batch = 0.6724s	
5673/25300 (epoch 11.211), train_loss = 1.17141631, grad/param norm = 1.7126e-01, time/batch = 0.6755s	
5674/25300 (epoch 11.213), train_loss = 1.25386536, grad/param norm = 1.9087e-01, time/batch = 0.6749s	
5675/25300 (epoch 11.215), train_loss = 1.22602185, grad/param norm = 2.0124e-01, time/batch = 0.6729s	
5676/25300 (epoch 11.217), train_loss = 1.24094570, grad/param norm = 1.8759e-01, time/batch = 0.6753s	
5677/25300 (epoch 11.219), train_loss = 1.28177979, grad/param norm = 1.9675e-01, time/batch = 0.6749s	
5678/25300 (epoch 11.221), train_loss = 1.30719228, grad/param norm = 1.8123e-01, time/batch = 0.6699s	
5679/25300 (epoch 11.223), train_loss = 1.27544884, grad/param norm = 1.9030e-01, time/batch = 0.6736s	
5680/25300 (epoch 11.225), train_loss = 1.71221656, grad/param norm = 2.2691e-01, time/batch = 0.6726s	
5681/25300 (epoch 11.227), train_loss = 1.30023631, grad/param norm = 1.8330e-01, time/batch = 0.6743s	
5682/25300 (epoch 11.229), train_loss = 1.23728713, grad/param norm = 1.9338e-01, time/batch = 0.6787s	
5683/25300 (epoch 11.231), train_loss = 1.19095584, grad/param norm = 1.7158e-01, time/batch = 0.6763s	
5684/25300 (epoch 11.233), train_loss = 1.25301350, grad/param norm = 1.7591e-01, time/batch = 0.6766s	
5685/25300 (epoch 11.235), train_loss = 1.18939689, grad/param norm = 1.7456e-01, time/batch = 0.6742s	
5686/25300 (epoch 11.237), train_loss = 1.37399687, grad/param norm = 1.9231e-01, time/batch = 0.6746s	
5687/25300 (epoch 11.239), train_loss = 1.23605088, grad/param norm = 1.8507e-01, time/batch = 0.6740s	
5688/25300 (epoch 11.241), train_loss = 1.31052089, grad/param norm = 1.7666e-01, time/batch = 0.6739s	
5689/25300 (epoch 11.243), train_loss = 1.56216560, grad/param norm = 2.0625e-01, time/batch = 0.6736s	
5690/25300 (epoch 11.245), train_loss = 1.11923551, grad/param norm = 1.7260e-01, time/batch = 0.6698s	
5691/25300 (epoch 11.247), train_loss = 1.31866491, grad/param norm = 1.7683e-01, time/batch = 0.6733s	
5692/25300 (epoch 11.249), train_loss = 1.05452093, grad/param norm = 1.5754e-01, time/batch = 0.6701s	
5693/25300 (epoch 11.251), train_loss = 1.01842143, grad/param norm = 1.7095e-01, time/batch = 0.6736s	
5694/25300 (epoch 11.253), train_loss = 1.20488664, grad/param norm = 1.7299e-01, time/batch = 0.6747s	
5695/25300 (epoch 11.255), train_loss = 1.14509748, grad/param norm = 1.7560e-01, time/batch = 0.6740s	
5696/25300 (epoch 11.257), train_loss = 1.28581421, grad/param norm = 1.9260e-01, time/batch = 0.6753s	
5697/25300 (epoch 11.259), train_loss = 1.44265536, grad/param norm = 1.9633e-01, time/batch = 0.6749s	
5698/25300 (epoch 11.261), train_loss = 1.36716140, grad/param norm = 1.9545e-01, time/batch = 0.6747s	
5699/25300 (epoch 11.263), train_loss = 1.32984750, grad/param norm = 1.8313e-01, time/batch = 0.6767s	
5700/25300 (epoch 11.265), train_loss = 1.41840316, grad/param norm = 1.8659e-01, time/batch = 0.6721s	
5701/25300 (epoch 11.267), train_loss = 1.32565910, grad/param norm = 1.7859e-01, time/batch = 0.6777s	
5702/25300 (epoch 11.269), train_loss = 1.05417514, grad/param norm = 1.6207e-01, time/batch = 0.6765s	
5703/25300 (epoch 11.271), train_loss = 1.15129511, grad/param norm = 1.8841e-01, time/batch = 0.6792s	
5704/25300 (epoch 11.273), train_loss = 1.27635504, grad/param norm = 1.8949e-01, time/batch = 0.6828s	
5705/25300 (epoch 11.275), train_loss = 1.08984356, grad/param norm = 1.5560e-01, time/batch = 0.6797s	
5706/25300 (epoch 11.277), train_loss = 1.17606462, grad/param norm = 2.1566e-01, time/batch = 0.6761s	
5707/25300 (epoch 11.279), train_loss = 1.21216504, grad/param norm = 1.7578e-01, time/batch = 0.6754s	
5708/25300 (epoch 11.281), train_loss = 1.35824686, grad/param norm = 1.9467e-01, time/batch = 0.6755s	
5709/25300 (epoch 11.283), train_loss = 1.08821686, grad/param norm = 1.8538e-01, time/batch = 0.6759s	
5710/25300 (epoch 11.285), train_loss = 1.22917526, grad/param norm = 1.9082e-01, time/batch = 0.6759s	
5711/25300 (epoch 11.287), train_loss = 1.21840198, grad/param norm = 1.7405e-01, time/batch = 0.6799s	
5712/25300 (epoch 11.289), train_loss = 1.13101514, grad/param norm = 1.6459e-01, time/batch = 0.6747s	
5713/25300 (epoch 11.291), train_loss = 1.15741350, grad/param norm = 1.8163e-01, time/batch = 0.6754s	
5714/25300 (epoch 11.292), train_loss = 1.32941698, grad/param norm = 1.8464e-01, time/batch = 0.6769s	
5715/25300 (epoch 11.294), train_loss = 1.23362383, grad/param norm = 1.8244e-01, time/batch = 0.6773s	
5716/25300 (epoch 11.296), train_loss = 1.06819437, grad/param norm = 1.7149e-01, time/batch = 0.6756s	
5717/25300 (epoch 11.298), train_loss = 1.29530066, grad/param norm = 1.7831e-01, time/batch = 0.6731s	
5718/25300 (epoch 11.300), train_loss = 1.35751969, grad/param norm = 1.9176e-01, time/batch = 0.6751s	
5719/25300 (epoch 11.302), train_loss = 1.01477393, grad/param norm = 1.8352e-01, time/batch = 0.6748s	
5720/25300 (epoch 11.304), train_loss = 1.24955914, grad/param norm = 1.9192e-01, time/batch = 0.6754s	
5721/25300 (epoch 11.306), train_loss = 0.95903409, grad/param norm = 1.5709e-01, time/batch = 0.6742s	
5722/25300 (epoch 11.308), train_loss = 1.25925411, grad/param norm = 1.7415e-01, time/batch = 0.6760s	
5723/25300 (epoch 11.310), train_loss = 1.11192354, grad/param norm = 1.7921e-01, time/batch = 0.6767s	
5724/25300 (epoch 11.312), train_loss = 1.18595475, grad/param norm = 1.6643e-01, time/batch = 0.6741s	
5725/25300 (epoch 11.314), train_loss = 0.96155618, grad/param norm = 1.6973e-01, time/batch = 0.6744s	
5726/25300 (epoch 11.316), train_loss = 1.22927802, grad/param norm = 1.7738e-01, time/batch = 0.6760s	
5727/25300 (epoch 11.318), train_loss = 0.92832496, grad/param norm = 1.6621e-01, time/batch = 0.6844s	
5728/25300 (epoch 11.320), train_loss = 1.05279596, grad/param norm = 1.6243e-01, time/batch = 0.6757s	
5729/25300 (epoch 11.322), train_loss = 1.48105997, grad/param norm = 2.1678e-01, time/batch = 0.6779s	
5730/25300 (epoch 11.324), train_loss = 1.07493697, grad/param norm = 1.6552e-01, time/batch = 0.6744s	
5731/25300 (epoch 11.326), train_loss = 0.94695409, grad/param norm = 1.5635e-01, time/batch = 0.6784s	
5732/25300 (epoch 11.328), train_loss = 0.96084905, grad/param norm = 1.6992e-01, time/batch = 0.6743s	
5733/25300 (epoch 11.330), train_loss = 1.14452287, grad/param norm = 1.7583e-01, time/batch = 0.6769s	
5734/25300 (epoch 11.332), train_loss = 1.22143620, grad/param norm = 1.6562e-01, time/batch = 0.6750s	
5735/25300 (epoch 11.334), train_loss = 1.01220101, grad/param norm = 1.5449e-01, time/batch = 0.6775s	
5736/25300 (epoch 11.336), train_loss = 1.00555304, grad/param norm = 1.7673e-01, time/batch = 0.6743s	
5737/25300 (epoch 11.338), train_loss = 1.01154305, grad/param norm = 1.7093e-01, time/batch = 0.6749s	
5738/25300 (epoch 11.340), train_loss = 1.12561592, grad/param norm = 1.8567e-01, time/batch = 0.6773s	
5739/25300 (epoch 11.342), train_loss = 1.12699522, grad/param norm = 1.8684e-01, time/batch = 0.6762s	
5740/25300 (epoch 11.344), train_loss = 1.16916795, grad/param norm = 1.7278e-01, time/batch = 0.6750s	
5741/25300 (epoch 11.346), train_loss = 1.16005207, grad/param norm = 1.7884e-01, time/batch = 0.6785s	
5742/25300 (epoch 11.348), train_loss = 1.03498890, grad/param norm = 1.5359e-01, time/batch = 0.6797s	
5743/25300 (epoch 11.350), train_loss = 1.13994628, grad/param norm = 1.7072e-01, time/batch = 0.6756s	
5744/25300 (epoch 11.352), train_loss = 1.16754996, grad/param norm = 1.6531e-01, time/batch = 0.6845s	
5745/25300 (epoch 11.354), train_loss = 1.11837742, grad/param norm = 1.7122e-01, time/batch = 0.8748s	
5746/25300 (epoch 11.356), train_loss = 1.20118175, grad/param norm = 1.7797e-01, time/batch = 1.0276s	
5747/25300 (epoch 11.358), train_loss = 1.31368590, grad/param norm = 1.9540e-01, time/batch = 0.9950s	
5748/25300 (epoch 11.360), train_loss = 1.06563577, grad/param norm = 1.7131e-01, time/batch = 0.9908s	
5749/25300 (epoch 11.362), train_loss = 1.11327725, grad/param norm = 1.6468e-01, time/batch = 1.0090s	
5750/25300 (epoch 11.364), train_loss = 1.23664992, grad/param norm = 1.7853e-01, time/batch = 0.7897s	
5751/25300 (epoch 11.366), train_loss = 1.03870588, grad/param norm = 1.6649e-01, time/batch = 0.6775s	
5752/25300 (epoch 11.368), train_loss = 1.13369820, grad/param norm = 1.6691e-01, time/batch = 0.6853s	
5753/25300 (epoch 11.370), train_loss = 1.15961225, grad/param norm = 1.9513e-01, time/batch = 0.6760s	
5754/25300 (epoch 11.372), train_loss = 1.10062466, grad/param norm = 1.7045e-01, time/batch = 0.6724s	
5755/25300 (epoch 11.374), train_loss = 1.05781354, grad/param norm = 1.6830e-01, time/batch = 0.6733s	
5756/25300 (epoch 11.375), train_loss = 1.37977060, grad/param norm = 2.0481e-01, time/batch = 0.6727s	
5757/25300 (epoch 11.377), train_loss = 1.20743799, grad/param norm = 1.8856e-01, time/batch = 0.6713s	
5758/25300 (epoch 11.379), train_loss = 1.28657908, grad/param norm = 1.9585e-01, time/batch = 0.6719s	
5759/25300 (epoch 11.381), train_loss = 1.17958860, grad/param norm = 1.6402e-01, time/batch = 0.6699s	
5760/25300 (epoch 11.383), train_loss = 1.07572405, grad/param norm = 1.8010e-01, time/batch = 0.6718s	
5761/25300 (epoch 11.385), train_loss = 1.14029471, grad/param norm = 1.6119e-01, time/batch = 0.6707s	
5762/25300 (epoch 11.387), train_loss = 1.23344460, grad/param norm = 1.7733e-01, time/batch = 0.6787s	
5763/25300 (epoch 11.389), train_loss = 1.30902646, grad/param norm = 1.9541e-01, time/batch = 0.6695s	
5764/25300 (epoch 11.391), train_loss = 1.06664275, grad/param norm = 1.6095e-01, time/batch = 0.6674s	
5765/25300 (epoch 11.393), train_loss = 1.21035215, grad/param norm = 1.7764e-01, time/batch = 0.6728s	
5766/25300 (epoch 11.395), train_loss = 1.00718990, grad/param norm = 1.5688e-01, time/batch = 0.6750s	
5767/25300 (epoch 11.397), train_loss = 1.04758144, grad/param norm = 1.7279e-01, time/batch = 0.6710s	
5768/25300 (epoch 11.399), train_loss = 1.04136529, grad/param norm = 1.6626e-01, time/batch = 0.6702s	
5769/25300 (epoch 11.401), train_loss = 1.32415604, grad/param norm = 1.9676e-01, time/batch = 0.6719s	
5770/25300 (epoch 11.403), train_loss = 1.17761596, grad/param norm = 1.9478e-01, time/batch = 0.6751s	
5771/25300 (epoch 11.405), train_loss = 1.20559615, grad/param norm = 1.9973e-01, time/batch = 0.6762s	
5772/25300 (epoch 11.407), train_loss = 1.09635716, grad/param norm = 1.7283e-01, time/batch = 0.6744s	
5773/25300 (epoch 11.409), train_loss = 1.09494579, grad/param norm = 1.5220e-01, time/batch = 0.6744s	
5774/25300 (epoch 11.411), train_loss = 1.14223989, grad/param norm = 1.7847e-01, time/batch = 0.6674s	
5775/25300 (epoch 11.413), train_loss = 1.05092105, grad/param norm = 1.7788e-01, time/batch = 0.6724s	
5776/25300 (epoch 11.415), train_loss = 1.03361599, grad/param norm = 1.6866e-01, time/batch = 0.6896s	
5777/25300 (epoch 11.417), train_loss = 0.99200865, grad/param norm = 1.5346e-01, time/batch = 0.6776s	
5778/25300 (epoch 11.419), train_loss = 0.98103718, grad/param norm = 1.7153e-01, time/batch = 0.6823s	
5779/25300 (epoch 11.421), train_loss = 0.97600194, grad/param norm = 1.4821e-01, time/batch = 0.6750s	
5780/25300 (epoch 11.423), train_loss = 1.06426248, grad/param norm = 1.6712e-01, time/batch = 0.6768s	
5781/25300 (epoch 11.425), train_loss = 1.12666762, grad/param norm = 1.7418e-01, time/batch = 0.6842s	
5782/25300 (epoch 11.427), train_loss = 1.38504397, grad/param norm = 1.9300e-01, time/batch = 0.6737s	
5783/25300 (epoch 11.429), train_loss = 1.29378678, grad/param norm = 1.8643e-01, time/batch = 0.6750s	
5784/25300 (epoch 11.431), train_loss = 1.17866916, grad/param norm = 1.7549e-01, time/batch = 0.6770s	
5785/25300 (epoch 11.433), train_loss = 1.11830080, grad/param norm = 1.6752e-01, time/batch = 0.6740s	
5786/25300 (epoch 11.435), train_loss = 1.06898325, grad/param norm = 1.7716e-01, time/batch = 0.6743s	
5787/25300 (epoch 11.437), train_loss = 1.10311205, grad/param norm = 1.6680e-01, time/batch = 0.6763s	
5788/25300 (epoch 11.439), train_loss = 1.16442353, grad/param norm = 1.6986e-01, time/batch = 0.6753s	
5789/25300 (epoch 11.441), train_loss = 1.19550622, grad/param norm = 1.9849e-01, time/batch = 0.6731s	
5790/25300 (epoch 11.443), train_loss = 1.42499047, grad/param norm = 2.2239e-01, time/batch = 0.6766s	
5791/25300 (epoch 11.445), train_loss = 1.33168920, grad/param norm = 1.9603e-01, time/batch = 0.6787s	
5792/25300 (epoch 11.447), train_loss = 1.06498616, grad/param norm = 1.6631e-01, time/batch = 0.6722s	
5793/25300 (epoch 11.449), train_loss = 0.98084933, grad/param norm = 1.6810e-01, time/batch = 0.6729s	
5794/25300 (epoch 11.451), train_loss = 1.33891597, grad/param norm = 1.9025e-01, time/batch = 0.6760s	
5795/25300 (epoch 11.453), train_loss = 1.25662827, grad/param norm = 1.9078e-01, time/batch = 0.6764s	
5796/25300 (epoch 11.455), train_loss = 1.32496707, grad/param norm = 1.8152e-01, time/batch = 0.6814s	
5797/25300 (epoch 11.457), train_loss = 1.13133547, grad/param norm = 1.8629e-01, time/batch = 0.6784s	
5798/25300 (epoch 11.458), train_loss = 1.18982949, grad/param norm = 1.8328e-01, time/batch = 0.6785s	
5799/25300 (epoch 11.460), train_loss = 1.21145311, grad/param norm = 1.9443e-01, time/batch = 0.6779s	
5800/25300 (epoch 11.462), train_loss = 0.95529912, grad/param norm = 1.6049e-01, time/batch = 0.6750s	
5801/25300 (epoch 11.464), train_loss = 1.23860253, grad/param norm = 1.8266e-01, time/batch = 0.6780s	
5802/25300 (epoch 11.466), train_loss = 1.26912602, grad/param norm = 1.8453e-01, time/batch = 0.6768s	
5803/25300 (epoch 11.468), train_loss = 1.29589060, grad/param norm = 1.8903e-01, time/batch = 0.6758s	
5804/25300 (epoch 11.470), train_loss = 1.05917093, grad/param norm = 1.6144e-01, time/batch = 0.6747s	
5805/25300 (epoch 11.472), train_loss = 0.95660867, grad/param norm = 1.5398e-01, time/batch = 0.6733s	
5806/25300 (epoch 11.474), train_loss = 1.19690734, grad/param norm = 1.8699e-01, time/batch = 0.6749s	
5807/25300 (epoch 11.476), train_loss = 1.14226505, grad/param norm = 1.8263e-01, time/batch = 0.6743s	
5808/25300 (epoch 11.478), train_loss = 1.25041573, grad/param norm = 1.9344e-01, time/batch = 0.6748s	
5809/25300 (epoch 11.480), train_loss = 1.07538488, grad/param norm = 1.7035e-01, time/batch = 0.6771s	
5810/25300 (epoch 11.482), train_loss = 1.30485995, grad/param norm = 2.0450e-01, time/batch = 0.6764s	
5811/25300 (epoch 11.484), train_loss = 1.25554714, grad/param norm = 1.9170e-01, time/batch = 0.6775s	
5812/25300 (epoch 11.486), train_loss = 1.18532586, grad/param norm = 1.7189e-01, time/batch = 0.6798s	
5813/25300 (epoch 11.488), train_loss = 1.30287625, grad/param norm = 1.8839e-01, time/batch = 0.6772s	
5814/25300 (epoch 11.490), train_loss = 1.23757015, grad/param norm = 1.7520e-01, time/batch = 0.6785s	
5815/25300 (epoch 11.492), train_loss = 1.11897860, grad/param norm = 1.6749e-01, time/batch = 0.6767s	
5816/25300 (epoch 11.494), train_loss = 1.05071499, grad/param norm = 1.7056e-01, time/batch = 0.6751s	
5817/25300 (epoch 11.496), train_loss = 1.17107467, grad/param norm = 1.7813e-01, time/batch = 0.6740s	
5818/25300 (epoch 11.498), train_loss = 1.07656516, grad/param norm = 1.7210e-01, time/batch = 0.6746s	
5819/25300 (epoch 11.500), train_loss = 1.32575718, grad/param norm = 1.8966e-01, time/batch = 0.6718s	
5820/25300 (epoch 11.502), train_loss = 1.17263167, grad/param norm = 1.7722e-01, time/batch = 0.6753s	
5821/25300 (epoch 11.504), train_loss = 1.13366360, grad/param norm = 1.8992e-01, time/batch = 0.6791s	
5822/25300 (epoch 11.506), train_loss = 1.10529918, grad/param norm = 1.6674e-01, time/batch = 0.6755s	
5823/25300 (epoch 11.508), train_loss = 1.19950205, grad/param norm = 1.8740e-01, time/batch = 0.6737s	
5824/25300 (epoch 11.510), train_loss = 1.10536289, grad/param norm = 1.8207e-01, time/batch = 0.6755s	
5825/25300 (epoch 11.512), train_loss = 0.87535440, grad/param norm = 1.4099e-01, time/batch = 0.6744s	
5826/25300 (epoch 11.514), train_loss = 1.09316722, grad/param norm = 1.6242e-01, time/batch = 0.6716s	
5827/25300 (epoch 11.516), train_loss = 1.17413860, grad/param norm = 1.7518e-01, time/batch = 0.6717s	
5828/25300 (epoch 11.518), train_loss = 1.24995216, grad/param norm = 1.9138e-01, time/batch = 0.6758s	
5829/25300 (epoch 11.520), train_loss = 0.98658527, grad/param norm = 1.5704e-01, time/batch = 0.6757s	
5830/25300 (epoch 11.522), train_loss = 1.08927261, grad/param norm = 1.7739e-01, time/batch = 0.6828s	
5831/25300 (epoch 11.524), train_loss = 1.12151276, grad/param norm = 1.6772e-01, time/batch = 0.6900s	
5832/25300 (epoch 11.526), train_loss = 1.40853866, grad/param norm = 1.9478e-01, time/batch = 0.6778s	
5833/25300 (epoch 11.528), train_loss = 1.31204665, grad/param norm = 1.9985e-01, time/batch = 0.6808s	
5834/25300 (epoch 11.530), train_loss = 1.17124887, grad/param norm = 1.7783e-01, time/batch = 0.6880s	
5835/25300 (epoch 11.532), train_loss = 1.20133137, grad/param norm = 1.9192e-01, time/batch = 0.6797s	
5836/25300 (epoch 11.534), train_loss = 1.13393295, grad/param norm = 1.7494e-01, time/batch = 0.6759s	
5837/25300 (epoch 11.536), train_loss = 0.99953393, grad/param norm = 1.7675e-01, time/batch = 0.6838s	
5838/25300 (epoch 11.538), train_loss = 0.98332722, grad/param norm = 1.4520e-01, time/batch = 0.6786s	
5839/25300 (epoch 11.540), train_loss = 1.04710742, grad/param norm = 1.6804e-01, time/batch = 0.6765s	
5840/25300 (epoch 11.542), train_loss = 1.04382632, grad/param norm = 1.7878e-01, time/batch = 0.6770s	
5841/25300 (epoch 11.543), train_loss = 1.00049147, grad/param norm = 1.7264e-01, time/batch = 0.6871s	
5842/25300 (epoch 11.545), train_loss = 1.52472011, grad/param norm = 2.0947e-01, time/batch = 0.6763s	
5843/25300 (epoch 11.547), train_loss = 1.20083825, grad/param norm = 1.8743e-01, time/batch = 0.6744s	
5844/25300 (epoch 11.549), train_loss = 1.45134484, grad/param norm = 2.0417e-01, time/batch = 0.6762s	
5845/25300 (epoch 11.551), train_loss = 1.20217867, grad/param norm = 1.7341e-01, time/batch = 0.6716s	
5846/25300 (epoch 11.553), train_loss = 1.13264008, grad/param norm = 1.7821e-01, time/batch = 0.6730s	
5847/25300 (epoch 11.555), train_loss = 1.28624829, grad/param norm = 1.9285e-01, time/batch = 0.6696s	
5848/25300 (epoch 11.557), train_loss = 1.31658820, grad/param norm = 1.9392e-01, time/batch = 0.6721s	
5849/25300 (epoch 11.559), train_loss = 1.31435550, grad/param norm = 1.9366e-01, time/batch = 0.6739s	
5850/25300 (epoch 11.561), train_loss = 1.34721872, grad/param norm = 1.9376e-01, time/batch = 0.6724s	
5851/25300 (epoch 11.563), train_loss = 1.28094660, grad/param norm = 1.8542e-01, time/batch = 0.6766s	
5852/25300 (epoch 11.565), train_loss = 1.00912492, grad/param norm = 1.7359e-01, time/batch = 0.6776s	
5853/25300 (epoch 11.567), train_loss = 0.89394197, grad/param norm = 1.7129e-01, time/batch = 0.6754s	
5854/25300 (epoch 11.569), train_loss = 1.17404108, grad/param norm = 1.8396e-01, time/batch = 0.6715s	
5855/25300 (epoch 11.571), train_loss = 1.26618895, grad/param norm = 1.9519e-01, time/batch = 0.6726s	
5856/25300 (epoch 11.573), train_loss = 1.12784730, grad/param norm = 1.6712e-01, time/batch = 0.6719s	
5857/25300 (epoch 11.575), train_loss = 1.24424492, grad/param norm = 1.7736e-01, time/batch = 0.6713s	
5858/25300 (epoch 11.577), train_loss = 1.20451615, grad/param norm = 1.8035e-01, time/batch = 0.6751s	
5859/25300 (epoch 11.579), train_loss = 1.39642897, grad/param norm = 2.0231e-01, time/batch = 0.6744s	
5860/25300 (epoch 11.581), train_loss = 1.21755985, grad/param norm = 1.8661e-01, time/batch = 0.6757s	
5861/25300 (epoch 11.583), train_loss = 1.05213679, grad/param norm = 1.7445e-01, time/batch = 0.6784s	
5862/25300 (epoch 11.585), train_loss = 1.01284173, grad/param norm = 1.6886e-01, time/batch = 0.6741s	
5863/25300 (epoch 11.587), train_loss = 1.12216104, grad/param norm = 1.7635e-01, time/batch = 0.6723s	
5864/25300 (epoch 11.589), train_loss = 1.01472539, grad/param norm = 1.6499e-01, time/batch = 0.6748s	
5865/25300 (epoch 11.591), train_loss = 1.05641991, grad/param norm = 1.9016e-01, time/batch = 0.6733s	
5866/25300 (epoch 11.593), train_loss = 1.17536911, grad/param norm = 1.6174e-01, time/batch = 0.6725s	
5867/25300 (epoch 11.595), train_loss = 1.14874382, grad/param norm = 1.8340e-01, time/batch = 0.6724s	
5868/25300 (epoch 11.597), train_loss = 0.95465062, grad/param norm = 1.4825e-01, time/batch = 0.6734s	
5869/25300 (epoch 11.599), train_loss = 1.16685131, grad/param norm = 1.7332e-01, time/batch = 0.6716s	
5870/25300 (epoch 11.601), train_loss = 1.19237371, grad/param norm = 1.6549e-01, time/batch = 0.6724s	
5871/25300 (epoch 11.603), train_loss = 1.21818833, grad/param norm = 1.8635e-01, time/batch = 0.6752s	
5872/25300 (epoch 11.605), train_loss = 1.06672085, grad/param norm = 1.7793e-01, time/batch = 0.6772s	
5873/25300 (epoch 11.607), train_loss = 0.90877852, grad/param norm = 1.6650e-01, time/batch = 0.6761s	
5874/25300 (epoch 11.609), train_loss = 1.14066742, grad/param norm = 1.8558e-01, time/batch = 0.6769s	
5875/25300 (epoch 11.611), train_loss = 1.24254072, grad/param norm = 1.8249e-01, time/batch = 0.6771s	
5876/25300 (epoch 11.613), train_loss = 1.03569100, grad/param norm = 1.7485e-01, time/batch = 0.6756s	
5877/25300 (epoch 11.615), train_loss = 1.17911593, grad/param norm = 1.8599e-01, time/batch = 0.6738s	
5878/25300 (epoch 11.617), train_loss = 1.15680688, grad/param norm = 1.7057e-01, time/batch = 0.6786s	
5879/25300 (epoch 11.619), train_loss = 1.23034146, grad/param norm = 1.8554e-01, time/batch = 0.6834s	
5880/25300 (epoch 11.621), train_loss = 1.26047078, grad/param norm = 1.9394e-01, time/batch = 0.6737s	
5881/25300 (epoch 11.623), train_loss = 1.09042103, grad/param norm = 1.7386e-01, time/batch = 0.6767s	
5882/25300 (epoch 11.625), train_loss = 0.96479193, grad/param norm = 1.6625e-01, time/batch = 0.6762s	
5883/25300 (epoch 11.626), train_loss = 1.08498654, grad/param norm = 1.6875e-01, time/batch = 0.6774s	
5884/25300 (epoch 11.628), train_loss = 1.27055541, grad/param norm = 1.9324e-01, time/batch = 0.6770s	
5885/25300 (epoch 11.630), train_loss = 1.27838361, grad/param norm = 1.8659e-01, time/batch = 0.6777s	
5886/25300 (epoch 11.632), train_loss = 1.23350878, grad/param norm = 1.9539e-01, time/batch = 0.6788s	
5887/25300 (epoch 11.634), train_loss = 1.26668055, grad/param norm = 1.8778e-01, time/batch = 0.6745s	
5888/25300 (epoch 11.636), train_loss = 1.14935467, grad/param norm = 1.7540e-01, time/batch = 0.6753s	
5889/25300 (epoch 11.638), train_loss = 1.26353444, grad/param norm = 2.1822e-01, time/batch = 0.6757s	
5890/25300 (epoch 11.640), train_loss = 1.39972059, grad/param norm = 2.0602e-01, time/batch = 0.6762s	
5891/25300 (epoch 11.642), train_loss = 1.22015573, grad/param norm = 1.8799e-01, time/batch = 0.6795s	
5892/25300 (epoch 11.644), train_loss = 1.21743600, grad/param norm = 2.0207e-01, time/batch = 0.6765s	
5893/25300 (epoch 11.646), train_loss = 1.18362942, grad/param norm = 1.8705e-01, time/batch = 0.6721s	
5894/25300 (epoch 11.648), train_loss = 1.25842476, grad/param norm = 1.8478e-01, time/batch = 0.6757s	
5895/25300 (epoch 11.650), train_loss = 1.19549232, grad/param norm = 1.7219e-01, time/batch = 0.6760s	
5896/25300 (epoch 11.652), train_loss = 1.21407476, grad/param norm = 1.8655e-01, time/batch = 0.6777s	
5897/25300 (epoch 11.654), train_loss = 1.35968316, grad/param norm = 1.9060e-01, time/batch = 0.6781s	
5898/25300 (epoch 11.656), train_loss = 1.28051563, grad/param norm = 1.9111e-01, time/batch = 0.6770s	
5899/25300 (epoch 11.658), train_loss = 0.98473819, grad/param norm = 1.6536e-01, time/batch = 0.6766s	
5900/25300 (epoch 11.660), train_loss = 1.03802847, grad/param norm = 1.7549e-01, time/batch = 0.6762s	
5901/25300 (epoch 11.662), train_loss = 1.00099075, grad/param norm = 1.6723e-01, time/batch = 0.6795s	
5902/25300 (epoch 11.664), train_loss = 0.97974871, grad/param norm = 1.6278e-01, time/batch = 0.6752s	
5903/25300 (epoch 11.666), train_loss = 1.00312937, grad/param norm = 1.7083e-01, time/batch = 0.6779s	
5904/25300 (epoch 11.668), train_loss = 1.08330774, grad/param norm = 1.8453e-01, time/batch = 0.6741s	
5905/25300 (epoch 11.670), train_loss = 1.02986256, grad/param norm = 1.6936e-01, time/batch = 0.6785s	
5906/25300 (epoch 11.672), train_loss = 1.05528345, grad/param norm = 1.7175e-01, time/batch = 0.6744s	
5907/25300 (epoch 11.674), train_loss = 1.08508227, grad/param norm = 1.7262e-01, time/batch = 0.6753s	
5908/25300 (epoch 11.676), train_loss = 1.15861161, grad/param norm = 1.9173e-01, time/batch = 0.6756s	
5909/25300 (epoch 11.678), train_loss = 1.11098710, grad/param norm = 2.0245e-01, time/batch = 0.6739s	
5910/25300 (epoch 11.680), train_loss = 0.98028462, grad/param norm = 1.6988e-01, time/batch = 0.6746s	
5911/25300 (epoch 11.682), train_loss = 0.85006810, grad/param norm = 1.5927e-01, time/batch = 0.6777s	
5912/25300 (epoch 11.684), train_loss = 1.01493242, grad/param norm = 1.5664e-01, time/batch = 0.6772s	
5913/25300 (epoch 11.686), train_loss = 0.98845716, grad/param norm = 1.5221e-01, time/batch = 0.6752s	
5914/25300 (epoch 11.688), train_loss = 1.14217012, grad/param norm = 1.7645e-01, time/batch = 0.6755s	
5915/25300 (epoch 11.690), train_loss = 1.01994934, grad/param norm = 1.5423e-01, time/batch = 0.6757s	
5916/25300 (epoch 11.692), train_loss = 1.15052030, grad/param norm = 1.6794e-01, time/batch = 0.6760s	
5917/25300 (epoch 11.694), train_loss = 1.07446441, grad/param norm = 1.6397e-01, time/batch = 0.6742s	
5918/25300 (epoch 11.696), train_loss = 1.14789586, grad/param norm = 1.8013e-01, time/batch = 0.6796s	
5919/25300 (epoch 11.698), train_loss = 1.20865320, grad/param norm = 1.7528e-01, time/batch = 0.6845s	
5920/25300 (epoch 11.700), train_loss = 0.95171337, grad/param norm = 1.6193e-01, time/batch = 0.6841s	
5921/25300 (epoch 11.702), train_loss = 1.23501871, grad/param norm = 1.8256e-01, time/batch = 0.6742s	
5922/25300 (epoch 11.704), train_loss = 0.92245584, grad/param norm = 1.6686e-01, time/batch = 0.6728s	
5923/25300 (epoch 11.706), train_loss = 1.16826667, grad/param norm = 2.0533e-01, time/batch = 0.6773s	
5924/25300 (epoch 11.708), train_loss = 0.92820440, grad/param norm = 1.4999e-01, time/batch = 0.6680s	
5925/25300 (epoch 11.709), train_loss = 1.29263611, grad/param norm = 1.7922e-01, time/batch = 0.6723s	
5926/25300 (epoch 11.711), train_loss = 1.34002082, grad/param norm = 1.9405e-01, time/batch = 0.6730s	
5927/25300 (epoch 11.713), train_loss = 1.09505319, grad/param norm = 1.6621e-01, time/batch = 0.6752s	
5928/25300 (epoch 11.715), train_loss = 1.10746932, grad/param norm = 1.8694e-01, time/batch = 0.6739s	
5929/25300 (epoch 11.717), train_loss = 1.11723112, grad/param norm = 2.0387e-01, time/batch = 0.6730s	
5930/25300 (epoch 11.719), train_loss = 1.12311369, grad/param norm = 1.7855e-01, time/batch = 0.6752s	
5931/25300 (epoch 11.721), train_loss = 1.18239535, grad/param norm = 1.9964e-01, time/batch = 0.6775s	
5932/25300 (epoch 11.723), train_loss = 1.08616165, grad/param norm = 1.8279e-01, time/batch = 0.6773s	
5933/25300 (epoch 11.725), train_loss = 1.17213494, grad/param norm = 1.7555e-01, time/batch = 0.6892s	
5934/25300 (epoch 11.727), train_loss = 1.18187082, grad/param norm = 1.8255e-01, time/batch = 0.6810s	
5935/25300 (epoch 11.729), train_loss = 1.09356942, grad/param norm = 1.7225e-01, time/batch = 0.6765s	
5936/25300 (epoch 11.731), train_loss = 1.35971028, grad/param norm = 2.0173e-01, time/batch = 0.6758s	
5937/25300 (epoch 11.733), train_loss = 1.07561286, grad/param norm = 1.5612e-01, time/batch = 0.6756s	
5938/25300 (epoch 11.735), train_loss = 1.46935695, grad/param norm = 2.0355e-01, time/batch = 0.6788s	
5939/25300 (epoch 11.737), train_loss = 0.98119375, grad/param norm = 1.6244e-01, time/batch = 0.6749s	
5940/25300 (epoch 11.739), train_loss = 1.26984013, grad/param norm = 1.7436e-01, time/batch = 0.6697s	
5941/25300 (epoch 11.741), train_loss = 1.21541484, grad/param norm = 2.0748e-01, time/batch = 0.6714s	
5942/25300 (epoch 11.743), train_loss = 1.08503159, grad/param norm = 1.6768e-01, time/batch = 0.6655s	
5943/25300 (epoch 11.745), train_loss = 1.06865120, grad/param norm = 1.6804e-01, time/batch = 0.6692s	
5944/25300 (epoch 11.747), train_loss = 0.98479953, grad/param norm = 1.5300e-01, time/batch = 0.6715s	
5945/25300 (epoch 11.749), train_loss = 1.20830218, grad/param norm = 1.8427e-01, time/batch = 0.6728s	
5946/25300 (epoch 11.751), train_loss = 1.27928540, grad/param norm = 1.9633e-01, time/batch = 0.6718s	
5947/25300 (epoch 11.753), train_loss = 1.08348222, grad/param norm = 1.8670e-01, time/batch = 0.6722s	
5948/25300 (epoch 11.755), train_loss = 1.26744002, grad/param norm = 2.0348e-01, time/batch = 0.6725s	
5949/25300 (epoch 11.757), train_loss = 1.04989560, grad/param norm = 1.7375e-01, time/batch = 0.6743s	
5950/25300 (epoch 11.759), train_loss = 1.03847623, grad/param norm = 1.7686e-01, time/batch = 0.6721s	
5951/25300 (epoch 11.761), train_loss = 1.28106734, grad/param norm = 1.9507e-01, time/batch = 0.6731s	
5952/25300 (epoch 11.763), train_loss = 1.05773197, grad/param norm = 1.7017e-01, time/batch = 0.6718s	
5953/25300 (epoch 11.765), train_loss = 1.09896699, grad/param norm = 1.7403e-01, time/batch = 0.6727s	
5954/25300 (epoch 11.767), train_loss = 1.04646727, grad/param norm = 1.6792e-01, time/batch = 0.6692s	
5955/25300 (epoch 11.769), train_loss = 1.19065286, grad/param norm = 1.8828e-01, time/batch = 0.6708s	
5956/25300 (epoch 11.771), train_loss = 1.31382417, grad/param norm = 1.9403e-01, time/batch = 0.6745s	
5957/25300 (epoch 11.773), train_loss = 1.29409509, grad/param norm = 2.0005e-01, time/batch = 0.6764s	
5958/25300 (epoch 11.775), train_loss = 1.10521580, grad/param norm = 1.5916e-01, time/batch = 0.6714s	
5959/25300 (epoch 11.777), train_loss = 1.19382015, grad/param norm = 1.8846e-01, time/batch = 0.6728s	
5960/25300 (epoch 11.779), train_loss = 1.25943329, grad/param norm = 1.7512e-01, time/batch = 0.6764s	
5961/25300 (epoch 11.781), train_loss = 1.14051622, grad/param norm = 1.6269e-01, time/batch = 0.6755s	
5962/25300 (epoch 11.783), train_loss = 1.33198404, grad/param norm = 2.0618e-01, time/batch = 0.6774s	
5963/25300 (epoch 11.785), train_loss = 1.24547464, grad/param norm = 1.7949e-01, time/batch = 0.6753s	
5964/25300 (epoch 11.787), train_loss = 1.26416398, grad/param norm = 1.8421e-01, time/batch = 0.6747s	
5965/25300 (epoch 11.789), train_loss = 1.37011452, grad/param norm = 1.9508e-01, time/batch = 0.6717s	
5966/25300 (epoch 11.791), train_loss = 1.18536805, grad/param norm = 1.8771e-01, time/batch = 0.6729s	
5967/25300 (epoch 11.792), train_loss = 1.24584252, grad/param norm = 1.6907e-01, time/batch = 0.6796s	
5968/25300 (epoch 11.794), train_loss = 1.18258422, grad/param norm = 1.7971e-01, time/batch = 0.6730s	
5969/25300 (epoch 11.796), train_loss = 1.12561918, grad/param norm = 1.7515e-01, time/batch = 0.6725s	
5970/25300 (epoch 11.798), train_loss = 1.31924451, grad/param norm = 1.9493e-01, time/batch = 0.6857s	
5971/25300 (epoch 11.800), train_loss = 1.15358484, grad/param norm = 1.8007e-01, time/batch = 0.6934s	
5972/25300 (epoch 11.802), train_loss = 0.93450785, grad/param norm = 1.6656e-01, time/batch = 0.6860s	
5973/25300 (epoch 11.804), train_loss = 1.17644639, grad/param norm = 1.6864e-01, time/batch = 0.6836s	
5974/25300 (epoch 11.806), train_loss = 1.24704699, grad/param norm = 1.8071e-01, time/batch = 0.6866s	
5975/25300 (epoch 11.808), train_loss = 1.19886571, grad/param norm = 1.8617e-01, time/batch = 0.6861s	
5976/25300 (epoch 11.810), train_loss = 1.17945294, grad/param norm = 2.0165e-01, time/batch = 0.6780s	
5977/25300 (epoch 11.812), train_loss = 1.25382683, grad/param norm = 1.8581e-01, time/batch = 0.6742s	
5978/25300 (epoch 11.814), train_loss = 1.33595149, grad/param norm = 1.8368e-01, time/batch = 0.6717s	
5979/25300 (epoch 11.816), train_loss = 1.45778971, grad/param norm = 1.8809e-01, time/batch = 0.6769s	
5980/25300 (epoch 11.818), train_loss = 1.25439652, grad/param norm = 1.7714e-01, time/batch = 0.6734s	
5981/25300 (epoch 11.820), train_loss = 1.22024620, grad/param norm = 1.7657e-01, time/batch = 0.6748s	
5982/25300 (epoch 11.822), train_loss = 1.16981800, grad/param norm = 1.7170e-01, time/batch = 0.6715s	
5983/25300 (epoch 11.824), train_loss = 1.23775222, grad/param norm = 1.8311e-01, time/batch = 0.6778s	
5984/25300 (epoch 11.826), train_loss = 1.07961494, grad/param norm = 1.6948e-01, time/batch = 0.6833s	
5985/25300 (epoch 11.828), train_loss = 1.08959260, grad/param norm = 1.8388e-01, time/batch = 0.6729s	
5986/25300 (epoch 11.830), train_loss = 1.15558022, grad/param norm = 1.7035e-01, time/batch = 0.6743s	
5987/25300 (epoch 11.832), train_loss = 1.20908213, grad/param norm = 1.7885e-01, time/batch = 0.6804s	
5988/25300 (epoch 11.834), train_loss = 1.01172578, grad/param norm = 1.5355e-01, time/batch = 0.6658s	
5989/25300 (epoch 11.836), train_loss = 1.08824564, grad/param norm = 1.6265e-01, time/batch = 0.6713s	
5990/25300 (epoch 11.838), train_loss = 1.13713799, grad/param norm = 1.7569e-01, time/batch = 0.6742s	
5991/25300 (epoch 11.840), train_loss = 1.31642175, grad/param norm = 1.8740e-01, time/batch = 0.6818s	
5992/25300 (epoch 11.842), train_loss = 1.16760364, grad/param norm = 2.1101e-01, time/batch = 0.6777s	
5993/25300 (epoch 11.844), train_loss = 1.19960818, grad/param norm = 1.6969e-01, time/batch = 0.6779s	
5994/25300 (epoch 11.846), train_loss = 1.20361628, grad/param norm = 1.7212e-01, time/batch = 0.6693s	
5995/25300 (epoch 11.848), train_loss = 1.30999546, grad/param norm = 1.8463e-01, time/batch = 0.6766s	
5996/25300 (epoch 11.850), train_loss = 1.26832545, grad/param norm = 1.9241e-01, time/batch = 0.6767s	
5997/25300 (epoch 11.852), train_loss = 1.21295584, grad/param norm = 1.8692e-01, time/batch = 0.6758s	
5998/25300 (epoch 11.854), train_loss = 1.35822213, grad/param norm = 1.9658e-01, time/batch = 0.6836s	
5999/25300 (epoch 11.856), train_loss = 1.15378724, grad/param norm = 1.7938e-01, time/batch = 0.6787s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch11.86_1.4846.t7	
6000/25300 (epoch 11.858), train_loss = 1.24163502, grad/param norm = 2.0471e-01, time/batch = 0.6774s	
6001/25300 (epoch 11.860), train_loss = 1.16030575, grad/param norm = 1.9179e-01, time/batch = 0.6899s	
6002/25300 (epoch 11.862), train_loss = 1.23110151, grad/param norm = 2.0243e-01, time/batch = 0.6835s	
6003/25300 (epoch 11.864), train_loss = 1.27924773, grad/param norm = 1.8536e-01, time/batch = 0.6776s	
6004/25300 (epoch 11.866), train_loss = 1.23657983, grad/param norm = 2.0545e-01, time/batch = 0.6855s	
6005/25300 (epoch 11.868), train_loss = 1.29744858, grad/param norm = 2.0223e-01, time/batch = 0.6810s	
6006/25300 (epoch 11.870), train_loss = 1.26241047, grad/param norm = 1.7344e-01, time/batch = 0.6775s	
6007/25300 (epoch 11.872), train_loss = 1.26555717, grad/param norm = 2.1037e-01, time/batch = 0.6835s	
6008/25300 (epoch 11.874), train_loss = 1.26941564, grad/param norm = 1.9396e-01, time/batch = 0.6787s	
6009/25300 (epoch 11.875), train_loss = 1.16122167, grad/param norm = 1.8247e-01, time/batch = 0.6810s	
6010/25300 (epoch 11.877), train_loss = 1.09657495, grad/param norm = 1.6418e-01, time/batch = 0.6810s	
6011/25300 (epoch 11.879), train_loss = 1.20526185, grad/param norm = 1.8934e-01, time/batch = 0.6752s	
6012/25300 (epoch 11.881), train_loss = 1.50288355, grad/param norm = 2.1056e-01, time/batch = 0.6747s	
6013/25300 (epoch 11.883), train_loss = 1.43721950, grad/param norm = 1.8726e-01, time/batch = 0.6747s	
6014/25300 (epoch 11.885), train_loss = 1.28343591, grad/param norm = 2.0735e-01, time/batch = 0.6802s	
6015/25300 (epoch 11.887), train_loss = 1.22125692, grad/param norm = 1.8421e-01, time/batch = 0.6735s	
6016/25300 (epoch 11.889), train_loss = 1.35404933, grad/param norm = 1.9804e-01, time/batch = 0.6732s	
6017/25300 (epoch 11.891), train_loss = 1.45201733, grad/param norm = 6.2346e-01, time/batch = 0.6725s	
6018/25300 (epoch 11.893), train_loss = 1.47466253, grad/param norm = 2.6750e-01, time/batch = 0.6767s	
6019/25300 (epoch 11.895), train_loss = 0.96037315, grad/param norm = 1.7960e-01, time/batch = 0.6768s	
6020/25300 (epoch 11.897), train_loss = 1.08549270, grad/param norm = 1.7892e-01, time/batch = 0.6777s	
6021/25300 (epoch 11.899), train_loss = 1.19200726, grad/param norm = 1.9906e-01, time/batch = 0.6810s	
6022/25300 (epoch 11.901), train_loss = 1.21274569, grad/param norm = 1.7744e-01, time/batch = 0.6820s	
6023/25300 (epoch 11.903), train_loss = 0.97742739, grad/param norm = 1.6226e-01, time/batch = 0.6779s	
6024/25300 (epoch 11.905), train_loss = 1.10957374, grad/param norm = 1.9082e-01, time/batch = 0.6835s	
6025/25300 (epoch 11.907), train_loss = 1.19970824, grad/param norm = 1.9909e-01, time/batch = 0.6832s	
6026/25300 (epoch 11.909), train_loss = 1.29378880, grad/param norm = 1.8348e-01, time/batch = 0.6824s	
6027/25300 (epoch 11.911), train_loss = 1.41537591, grad/param norm = 1.9429e-01, time/batch = 0.6826s	
6028/25300 (epoch 11.913), train_loss = 1.40206752, grad/param norm = 2.0936e-01, time/batch = 0.6709s	
6029/25300 (epoch 11.915), train_loss = 1.10815486, grad/param norm = 1.8099e-01, time/batch = 0.6733s	
6030/25300 (epoch 11.917), train_loss = 1.25128489, grad/param norm = 1.8913e-01, time/batch = 0.6738s	
6031/25300 (epoch 11.919), train_loss = 1.39016286, grad/param norm = 2.0303e-01, time/batch = 0.6746s	
6032/25300 (epoch 11.921), train_loss = 1.09419958, grad/param norm = 1.7279e-01, time/batch = 0.6739s	
6033/25300 (epoch 11.923), train_loss = 1.35285427, grad/param norm = 1.9361e-01, time/batch = 0.6719s	
6034/25300 (epoch 11.925), train_loss = 1.17181237, grad/param norm = 1.8288e-01, time/batch = 0.6720s	
6035/25300 (epoch 11.927), train_loss = 1.17113170, grad/param norm = 1.8148e-01, time/batch = 0.6723s	
6036/25300 (epoch 11.929), train_loss = 1.11554966, grad/param norm = 1.6770e-01, time/batch = 0.6666s	
6037/25300 (epoch 11.931), train_loss = 1.34121485, grad/param norm = 2.0703e-01, time/batch = 0.6727s	
6038/25300 (epoch 11.933), train_loss = 1.24357307, grad/param norm = 1.8302e-01, time/batch = 0.6798s	
6039/25300 (epoch 11.935), train_loss = 1.22284365, grad/param norm = 1.7609e-01, time/batch = 0.6821s	
6040/25300 (epoch 11.937), train_loss = 0.94244571, grad/param norm = 1.5380e-01, time/batch = 0.6806s	
6041/25300 (epoch 11.939), train_loss = 1.29628537, grad/param norm = 1.8587e-01, time/batch = 0.6826s	
6042/25300 (epoch 11.941), train_loss = 1.14712346, grad/param norm = 1.6806e-01, time/batch = 0.6827s	
6043/25300 (epoch 11.943), train_loss = 1.15092368, grad/param norm = 1.7556e-01, time/batch = 0.6794s	
6044/25300 (epoch 11.945), train_loss = 1.22428648, grad/param norm = 1.8075e-01, time/batch = 0.6792s	
6045/25300 (epoch 11.947), train_loss = 1.08923830, grad/param norm = 1.7034e-01, time/batch = 0.6688s	
6046/25300 (epoch 11.949), train_loss = 1.26992425, grad/param norm = 1.9103e-01, time/batch = 0.6690s	
6047/25300 (epoch 11.951), train_loss = 1.16604925, grad/param norm = 1.7592e-01, time/batch = 0.6695s	
6048/25300 (epoch 11.953), train_loss = 1.23737294, grad/param norm = 1.6328e-01, time/batch = 0.6775s	
6049/25300 (epoch 11.955), train_loss = 1.45658009, grad/param norm = 2.0397e-01, time/batch = 0.6696s	
6050/25300 (epoch 11.957), train_loss = 1.41727424, grad/param norm = 2.1456e-01, time/batch = 0.6684s	
6051/25300 (epoch 11.958), train_loss = 1.25037487, grad/param norm = 1.8444e-01, time/batch = 0.6711s	
6052/25300 (epoch 11.960), train_loss = 1.41298106, grad/param norm = 2.0941e-01, time/batch = 0.6780s	
6053/25300 (epoch 11.962), train_loss = 1.37337990, grad/param norm = 1.9959e-01, time/batch = 0.6718s	
6054/25300 (epoch 11.964), train_loss = 1.28190047, grad/param norm = 1.7805e-01, time/batch = 0.6705s	
6055/25300 (epoch 11.966), train_loss = 1.03586059, grad/param norm = 1.6129e-01, time/batch = 0.6722s	
6056/25300 (epoch 11.968), train_loss = 1.02152333, grad/param norm = 1.7024e-01, time/batch = 0.6720s	
6057/25300 (epoch 11.970), train_loss = 1.18953569, grad/param norm = 2.1226e-01, time/batch = 0.6817s	
6058/25300 (epoch 11.972), train_loss = 1.20507347, grad/param norm = 1.9487e-01, time/batch = 0.6753s	
6059/25300 (epoch 11.974), train_loss = 1.39336743, grad/param norm = 1.9956e-01, time/batch = 0.6725s	
6060/25300 (epoch 11.976), train_loss = 1.22360788, grad/param norm = 1.9553e-01, time/batch = 0.6781s	
6061/25300 (epoch 11.978), train_loss = 1.25235870, grad/param norm = 1.7966e-01, time/batch = 0.6743s	
6062/25300 (epoch 11.980), train_loss = 1.24814563, grad/param norm = 2.0190e-01, time/batch = 0.6709s	
6063/25300 (epoch 11.982), train_loss = 1.16917073, grad/param norm = 1.6616e-01, time/batch = 0.6726s	
6064/25300 (epoch 11.984), train_loss = 1.19527384, grad/param norm = 1.8534e-01, time/batch = 0.6698s	
6065/25300 (epoch 11.986), train_loss = 1.25762477, grad/param norm = 1.9691e-01, time/batch = 0.6694s	
6066/25300 (epoch 11.988), train_loss = 1.28889491, grad/param norm = 2.0718e-01, time/batch = 0.6695s	
6067/25300 (epoch 11.990), train_loss = 1.19638933, grad/param norm = 1.6761e-01, time/batch = 0.6713s	
6068/25300 (epoch 11.992), train_loss = 0.97049123, grad/param norm = 1.7351e-01, time/batch = 0.6734s	
6069/25300 (epoch 11.994), train_loss = 1.21524527, grad/param norm = 1.8032e-01, time/batch = 0.6733s	
6070/25300 (epoch 11.996), train_loss = 1.34707861, grad/param norm = 2.0250e-01, time/batch = 0.6716s	
6071/25300 (epoch 11.998), train_loss = 1.33883078, grad/param norm = 1.9464e-01, time/batch = 0.6743s	
decayed learning rate by a factor 0.97 to 0.001825346	
6072/25300 (epoch 12.000), train_loss = 1.20289729, grad/param norm = 1.9256e-01, time/batch = 0.6755s	
6073/25300 (epoch 12.002), train_loss = 1.03161568, grad/param norm = 1.6921e-01, time/batch = 0.6778s	
6074/25300 (epoch 12.004), train_loss = 0.99500951, grad/param norm = 1.6677e-01, time/batch = 0.8626s	
6075/25300 (epoch 12.006), train_loss = 1.28569705, grad/param norm = 1.7439e-01, time/batch = 0.9930s	
6076/25300 (epoch 12.008), train_loss = 1.19195894, grad/param norm = 1.6949e-01, time/batch = 0.9972s	
6077/25300 (epoch 12.010), train_loss = 1.19454720, grad/param norm = 1.6435e-01, time/batch = 0.9973s	
6078/25300 (epoch 12.012), train_loss = 1.08423095, grad/param norm = 1.9058e-01, time/batch = 0.9933s	
6079/25300 (epoch 12.014), train_loss = 1.28446349, grad/param norm = 1.9593e-01, time/batch = 1.4726s	
6080/25300 (epoch 12.016), train_loss = 1.24586789, grad/param norm = 1.9323e-01, time/batch = 1.8155s	
6081/25300 (epoch 12.018), train_loss = 1.07410150, grad/param norm = 1.7904e-01, time/batch = 1.8498s	
6082/25300 (epoch 12.020), train_loss = 1.13479471, grad/param norm = 1.7401e-01, time/batch = 16.5388s	
6083/25300 (epoch 12.022), train_loss = 1.21112672, grad/param norm = 1.9539e-01, time/batch = 17.8004s	
6084/25300 (epoch 12.024), train_loss = 0.89293584, grad/param norm = 1.5038e-01, time/batch = 19.6414s	
6085/25300 (epoch 12.026), train_loss = 1.10058866, grad/param norm = 1.9599e-01, time/batch = 15.9658s	
6086/25300 (epoch 12.028), train_loss = 1.02634996, grad/param norm = 1.5002e-01, time/batch = 17.2168s	
6087/25300 (epoch 12.030), train_loss = 1.26596013, grad/param norm = 1.7735e-01, time/batch = 15.6602s	
6088/25300 (epoch 12.032), train_loss = 1.10594390, grad/param norm = 1.6425e-01, time/batch = 17.9846s	
6089/25300 (epoch 12.034), train_loss = 0.96291648, grad/param norm = 1.8256e-01, time/batch = 18.3830s	
6090/25300 (epoch 12.036), train_loss = 0.99494974, grad/param norm = 1.5909e-01, time/batch = 18.0587s	
6091/25300 (epoch 12.038), train_loss = 0.88664494, grad/param norm = 1.4232e-01, time/batch = 17.2136s	
6092/25300 (epoch 12.040), train_loss = 1.22083284, grad/param norm = 1.7214e-01, time/batch = 16.3765s	
6093/25300 (epoch 12.042), train_loss = 1.07249286, grad/param norm = 1.6086e-01, time/batch = 19.3816s	
6094/25300 (epoch 12.043), train_loss = 0.96017532, grad/param norm = 1.5112e-01, time/batch = 16.5329s	
6095/25300 (epoch 12.045), train_loss = 0.99407449, grad/param norm = 1.7046e-01, time/batch = 16.8855s	
6096/25300 (epoch 12.047), train_loss = 1.18956031, grad/param norm = 1.6183e-01, time/batch = 16.6279s	
6097/25300 (epoch 12.049), train_loss = 1.20208120, grad/param norm = 1.9105e-01, time/batch = 16.9644s	
6098/25300 (epoch 12.051), train_loss = 1.28232088, grad/param norm = 2.1073e-01, time/batch = 19.2321s	
6099/25300 (epoch 12.053), train_loss = 0.94046025, grad/param norm = 1.5668e-01, time/batch = 16.3047s	
6100/25300 (epoch 12.055), train_loss = 1.00955890, grad/param norm = 1.5677e-01, time/batch = 19.3853s	
6101/25300 (epoch 12.057), train_loss = 0.94233045, grad/param norm = 1.4964e-01, time/batch = 18.7978s	
6102/25300 (epoch 12.059), train_loss = 1.13447523, grad/param norm = 1.7892e-01, time/batch = 17.0510s	
6103/25300 (epoch 12.061), train_loss = 1.04176406, grad/param norm = 1.5809e-01, time/batch = 18.1412s	
6104/25300 (epoch 12.063), train_loss = 1.03895623, grad/param norm = 1.6641e-01, time/batch = 17.5510s	
6105/25300 (epoch 12.065), train_loss = 1.26576226, grad/param norm = 1.8626e-01, time/batch = 15.1223s	
6106/25300 (epoch 12.067), train_loss = 1.28556169, grad/param norm = 1.9079e-01, time/batch = 15.2685s	
6107/25300 (epoch 12.069), train_loss = 1.14800329, grad/param norm = 1.7795e-01, time/batch = 15.2883s	
6108/25300 (epoch 12.071), train_loss = 1.30282242, grad/param norm = 1.7662e-01, time/batch = 15.6041s	
6109/25300 (epoch 12.073), train_loss = 1.11155728, grad/param norm = 1.6103e-01, time/batch = 15.6827s	
6110/25300 (epoch 12.075), train_loss = 1.18060810, grad/param norm = 1.7290e-01, time/batch = 15.7209s	
6111/25300 (epoch 12.077), train_loss = 1.22579121, grad/param norm = 1.8152e-01, time/batch = 16.3013s	
6112/25300 (epoch 12.079), train_loss = 1.15442204, grad/param norm = 1.6972e-01, time/batch = 17.2236s	
6113/25300 (epoch 12.081), train_loss = 1.13185322, grad/param norm = 1.5856e-01, time/batch = 16.3726s	
6114/25300 (epoch 12.083), train_loss = 1.10148444, grad/param norm = 1.6281e-01, time/batch = 15.9000s	
6115/25300 (epoch 12.085), train_loss = 1.38642629, grad/param norm = 1.9853e-01, time/batch = 15.4792s	
6116/25300 (epoch 12.087), train_loss = 1.18162535, grad/param norm = 1.8240e-01, time/batch = 17.0659s	
6117/25300 (epoch 12.089), train_loss = 1.19981762, grad/param norm = 1.7922e-01, time/batch = 16.5456s	
6118/25300 (epoch 12.091), train_loss = 1.32358036, grad/param norm = 1.8277e-01, time/batch = 18.1389s	
6119/25300 (epoch 12.093), train_loss = 1.29463523, grad/param norm = 1.8365e-01, time/batch = 18.8744s	
6120/25300 (epoch 12.095), train_loss = 1.22675938, grad/param norm = 1.7398e-01, time/batch = 16.5506s	
6121/25300 (epoch 12.097), train_loss = 1.18357211, grad/param norm = 1.7125e-01, time/batch = 17.3039s	
6122/25300 (epoch 12.099), train_loss = 1.21573900, grad/param norm = 1.9182e-01, time/batch = 15.7957s	
6123/25300 (epoch 12.101), train_loss = 1.15535299, grad/param norm = 1.7219e-01, time/batch = 18.4752s	
6124/25300 (epoch 12.103), train_loss = 1.12725649, grad/param norm = 1.8209e-01, time/batch = 18.0446s	
6125/25300 (epoch 12.105), train_loss = 1.20179367, grad/param norm = 1.8718e-01, time/batch = 17.7172s	
6126/25300 (epoch 12.107), train_loss = 1.26394277, grad/param norm = 1.8495e-01, time/batch = 18.1248s	
6127/25300 (epoch 12.109), train_loss = 1.17559015, grad/param norm = 1.8931e-01, time/batch = 16.7907s	
6128/25300 (epoch 12.111), train_loss = 1.14578383, grad/param norm = 1.7645e-01, time/batch = 16.9844s	
6129/25300 (epoch 12.113), train_loss = 1.17270213, grad/param norm = 1.9777e-01, time/batch = 15.9875s	
6130/25300 (epoch 12.115), train_loss = 1.15511191, grad/param norm = 1.7823e-01, time/batch = 18.3024s	
6131/25300 (epoch 12.117), train_loss = 1.24169206, grad/param norm = 1.7873e-01, time/batch = 16.9845s	
6132/25300 (epoch 12.119), train_loss = 1.14661219, grad/param norm = 1.8217e-01, time/batch = 16.9687s	
6133/25300 (epoch 12.121), train_loss = 1.24202854, grad/param norm = 1.8885e-01, time/batch = 16.1851s	
6134/25300 (epoch 12.123), train_loss = 1.16667714, grad/param norm = 1.9384e-01, time/batch = 15.6997s	
6135/25300 (epoch 12.125), train_loss = 1.26536404, grad/param norm = 1.9101e-01, time/batch = 16.1411s	
6136/25300 (epoch 12.126), train_loss = 1.18639305, grad/param norm = 1.8352e-01, time/batch = 16.9775s	
6137/25300 (epoch 12.128), train_loss = 1.18857753, grad/param norm = 1.7879e-01, time/batch = 17.5509s	
6138/25300 (epoch 12.130), train_loss = 0.93267584, grad/param norm = 1.6105e-01, time/batch = 15.7932s	
6139/25300 (epoch 12.132), train_loss = 1.00692361, grad/param norm = 1.5675e-01, time/batch = 16.5641s	
6140/25300 (epoch 12.134), train_loss = 0.93053138, grad/param norm = 1.4717e-01, time/batch = 16.7350s	
6141/25300 (epoch 12.136), train_loss = 1.19992765, grad/param norm = 1.7112e-01, time/batch = 16.6587s	
6142/25300 (epoch 12.138), train_loss = 1.01863574, grad/param norm = 1.5915e-01, time/batch = 17.8252s	
6143/25300 (epoch 12.140), train_loss = 1.09243443, grad/param norm = 1.7025e-01, time/batch = 16.1573s	
6144/25300 (epoch 12.142), train_loss = 1.24748542, grad/param norm = 1.7393e-01, time/batch = 16.5784s	
6145/25300 (epoch 12.144), train_loss = 1.18639659, grad/param norm = 1.7574e-01, time/batch = 16.6360s	
6146/25300 (epoch 12.146), train_loss = 1.28691460, grad/param norm = 1.9725e-01, time/batch = 18.4597s	
6147/25300 (epoch 12.148), train_loss = 1.14759195, grad/param norm = 1.7296e-01, time/batch = 18.1429s	
6148/25300 (epoch 12.150), train_loss = 1.28884666, grad/param norm = 2.1818e-01, time/batch = 16.2853s	
6149/25300 (epoch 12.152), train_loss = 1.38766614, grad/param norm = 1.9222e-01, time/batch = 17.7042s	
6150/25300 (epoch 12.154), train_loss = 1.05529105, grad/param norm = 1.7306e-01, time/batch = 18.5519s	
6151/25300 (epoch 12.156), train_loss = 1.20828351, grad/param norm = 1.7751e-01, time/batch = 15.8964s	
6152/25300 (epoch 12.158), train_loss = 1.07690382, grad/param norm = 1.6455e-01, time/batch = 17.5445s	
6153/25300 (epoch 12.160), train_loss = 1.18635768, grad/param norm = 1.7526e-01, time/batch = 17.6319s	
6154/25300 (epoch 12.162), train_loss = 1.09332866, grad/param norm = 1.7777e-01, time/batch = 17.6491s	
6155/25300 (epoch 12.164), train_loss = 1.25946531, grad/param norm = 1.8004e-01, time/batch = 25.0433s	
6156/25300 (epoch 12.166), train_loss = 1.19914197, grad/param norm = 1.7637e-01, time/batch = 20.0190s	
6157/25300 (epoch 12.168), train_loss = 1.01196910, grad/param norm = 1.4965e-01, time/batch = 18.0724s	
6158/25300 (epoch 12.170), train_loss = 1.10992872, grad/param norm = 1.6386e-01, time/batch = 15.3239s	
6159/25300 (epoch 12.172), train_loss = 1.05720307, grad/param norm = 1.6393e-01, time/batch = 16.4029s	
6160/25300 (epoch 12.174), train_loss = 1.01936687, grad/param norm = 1.6397e-01, time/batch = 18.1548s	
6161/25300 (epoch 12.176), train_loss = 1.11739486, grad/param norm = 1.7516e-01, time/batch = 17.3797s	
6162/25300 (epoch 12.178), train_loss = 1.31810354, grad/param norm = 1.9482e-01, time/batch = 15.5679s	
6163/25300 (epoch 12.180), train_loss = 0.97843694, grad/param norm = 1.6466e-01, time/batch = 18.2998s	
6164/25300 (epoch 12.182), train_loss = 1.09048929, grad/param norm = 1.6851e-01, time/batch = 17.1318s	
6165/25300 (epoch 12.184), train_loss = 1.13931201, grad/param norm = 1.8677e-01, time/batch = 16.6355s	
6166/25300 (epoch 12.186), train_loss = 1.09811344, grad/param norm = 1.7545e-01, time/batch = 18.8041s	
6167/25300 (epoch 12.188), train_loss = 1.14710876, grad/param norm = 1.7774e-01, time/batch = 16.9821s	
6168/25300 (epoch 12.190), train_loss = 1.18620327, grad/param norm = 1.8394e-01, time/batch = 15.5366s	
6169/25300 (epoch 12.192), train_loss = 1.10000070, grad/param norm = 1.7681e-01, time/batch = 16.3144s	
6170/25300 (epoch 12.194), train_loss = 1.12377530, grad/param norm = 1.7608e-01, time/batch = 15.2234s	
6171/25300 (epoch 12.196), train_loss = 1.25881810, grad/param norm = 2.1762e-01, time/batch = 15.2013s	
6172/25300 (epoch 12.198), train_loss = 1.10117739, grad/param norm = 1.9401e-01, time/batch = 15.5283s	
6173/25300 (epoch 12.200), train_loss = 1.16727048, grad/param norm = 1.9042e-01, time/batch = 15.1936s	
6174/25300 (epoch 12.202), train_loss = 1.15498797, grad/param norm = 1.7475e-01, time/batch = 14.9452s	
6175/25300 (epoch 12.204), train_loss = 1.11197295, grad/param norm = 1.7578e-01, time/batch = 15.1434s	
6176/25300 (epoch 12.206), train_loss = 1.23428200, grad/param norm = 1.8995e-01, time/batch = 16.4524s	
6177/25300 (epoch 12.208), train_loss = 1.04368279, grad/param norm = 1.9407e-01, time/batch = 16.8234s	
6178/25300 (epoch 12.209), train_loss = 0.96179589, grad/param norm = 1.6557e-01, time/batch = 17.7336s	
6179/25300 (epoch 12.211), train_loss = 1.13896326, grad/param norm = 1.7498e-01, time/batch = 18.3005s	
6180/25300 (epoch 12.213), train_loss = 1.22290119, grad/param norm = 1.9305e-01, time/batch = 18.2091s	
6181/25300 (epoch 12.215), train_loss = 1.19028527, grad/param norm = 1.9272e-01, time/batch = 16.7245s	
6182/25300 (epoch 12.217), train_loss = 1.21684141, grad/param norm = 1.9526e-01, time/batch = 18.1274s	
6183/25300 (epoch 12.219), train_loss = 1.25795652, grad/param norm = 2.0024e-01, time/batch = 16.8946s	
6184/25300 (epoch 12.221), train_loss = 1.27847772, grad/param norm = 1.8560e-01, time/batch = 18.4669s	
6185/25300 (epoch 12.223), train_loss = 1.23567038, grad/param norm = 1.9299e-01, time/batch = 18.1439s	
6186/25300 (epoch 12.225), train_loss = 1.67685256, grad/param norm = 2.2776e-01, time/batch = 15.7785s	
6187/25300 (epoch 12.227), train_loss = 1.27310590, grad/param norm = 1.8332e-01, time/batch = 19.3831s	
6188/25300 (epoch 12.229), train_loss = 1.19653973, grad/param norm = 1.8775e-01, time/batch = 19.7062s	
6189/25300 (epoch 12.231), train_loss = 1.15174329, grad/param norm = 1.6760e-01, time/batch = 16.3799s	
6190/25300 (epoch 12.233), train_loss = 1.22047541, grad/param norm = 1.7746e-01, time/batch = 19.1194s	
6191/25300 (epoch 12.235), train_loss = 1.14801768, grad/param norm = 1.6225e-01, time/batch = 16.4803s	
6192/25300 (epoch 12.237), train_loss = 1.34820086, grad/param norm = 1.9440e-01, time/batch = 17.9665s	
6193/25300 (epoch 12.239), train_loss = 1.20317963, grad/param norm = 1.8841e-01, time/batch = 15.4000s	
6194/25300 (epoch 12.241), train_loss = 1.27474567, grad/param norm = 1.7732e-01, time/batch = 17.4685s	
6195/25300 (epoch 12.243), train_loss = 1.53256364, grad/param norm = 2.1368e-01, time/batch = 18.0518s	
6196/25300 (epoch 12.245), train_loss = 1.09148922, grad/param norm = 1.7598e-01, time/batch = 18.3887s	
6197/25300 (epoch 12.247), train_loss = 1.27681238, grad/param norm = 1.7847e-01, time/batch = 18.2195s	
6198/25300 (epoch 12.249), train_loss = 1.02942146, grad/param norm = 1.5833e-01, time/batch = 17.7298s	
6199/25300 (epoch 12.251), train_loss = 0.99106579, grad/param norm = 1.7166e-01, time/batch = 16.3886s	
6200/25300 (epoch 12.253), train_loss = 1.17145669, grad/param norm = 1.7660e-01, time/batch = 16.8069s	
6201/25300 (epoch 12.255), train_loss = 1.10322507, grad/param norm = 1.8067e-01, time/batch = 17.9518s	
6202/25300 (epoch 12.257), train_loss = 1.23784984, grad/param norm = 1.8918e-01, time/batch = 19.0270s	
6203/25300 (epoch 12.259), train_loss = 1.39709067, grad/param norm = 1.9268e-01, time/batch = 17.2016s	
6204/25300 (epoch 12.261), train_loss = 1.33810308, grad/param norm = 2.0304e-01, time/batch = 18.0526s	
6205/25300 (epoch 12.263), train_loss = 1.29975838, grad/param norm = 1.7968e-01, time/batch = 18.4694s	
6206/25300 (epoch 12.265), train_loss = 1.38797225, grad/param norm = 1.8545e-01, time/batch = 18.6376s	
6207/25300 (epoch 12.267), train_loss = 1.29930484, grad/param norm = 1.8371e-01, time/batch = 19.2123s	
6208/25300 (epoch 12.269), train_loss = 1.01582262, grad/param norm = 1.6168e-01, time/batch = 16.8965s	
6209/25300 (epoch 12.271), train_loss = 1.11810566, grad/param norm = 1.8281e-01, time/batch = 20.1452s	
6210/25300 (epoch 12.273), train_loss = 1.24605420, grad/param norm = 1.9579e-01, time/batch = 16.6366s	
6211/25300 (epoch 12.275), train_loss = 1.07418381, grad/param norm = 1.6059e-01, time/batch = 17.9769s	
6212/25300 (epoch 12.277), train_loss = 1.13294574, grad/param norm = 1.7218e-01, time/batch = 19.6256s	
6213/25300 (epoch 12.279), train_loss = 1.16660212, grad/param norm = 1.7002e-01, time/batch = 16.2156s	
6214/25300 (epoch 12.281), train_loss = 1.32545866, grad/param norm = 1.9138e-01, time/batch = 17.4011s	
6215/25300 (epoch 12.283), train_loss = 1.06263293, grad/param norm = 1.8227e-01, time/batch = 16.7403s	
6216/25300 (epoch 12.285), train_loss = 1.19737137, grad/param norm = 1.9222e-01, time/batch = 17.3879s	
6217/25300 (epoch 12.287), train_loss = 1.19945079, grad/param norm = 1.7469e-01, time/batch = 17.7994s	
6218/25300 (epoch 12.289), train_loss = 1.09747926, grad/param norm = 1.6291e-01, time/batch = 17.6540s	
6219/25300 (epoch 12.291), train_loss = 1.12810838, grad/param norm = 1.8112e-01, time/batch = 15.5684s	
6220/25300 (epoch 12.292), train_loss = 1.30885222, grad/param norm = 1.8832e-01, time/batch = 16.2994s	
6221/25300 (epoch 12.294), train_loss = 1.20689714, grad/param norm = 1.8824e-01, time/batch = 18.1481s	
6222/25300 (epoch 12.296), train_loss = 1.03854852, grad/param norm = 1.7467e-01, time/batch = 17.5511s	
6223/25300 (epoch 12.298), train_loss = 1.26963476, grad/param norm = 1.8991e-01, time/batch = 18.1238s	
6224/25300 (epoch 12.300), train_loss = 1.32144590, grad/param norm = 2.0326e-01, time/batch = 17.3027s	
6225/25300 (epoch 12.302), train_loss = 0.97927530, grad/param norm = 1.8757e-01, time/batch = 18.6390s	
6226/25300 (epoch 12.304), train_loss = 1.22472578, grad/param norm = 1.9103e-01, time/batch = 17.3046s	
6227/25300 (epoch 12.306), train_loss = 0.92678194, grad/param norm = 1.5641e-01, time/batch = 15.8920s	
6228/25300 (epoch 12.308), train_loss = 1.22841280, grad/param norm = 1.6991e-01, time/batch = 17.8925s	
6229/25300 (epoch 12.310), train_loss = 1.07789401, grad/param norm = 1.8238e-01, time/batch = 15.7255s	
6230/25300 (epoch 12.312), train_loss = 1.14834045, grad/param norm = 1.6258e-01, time/batch = 15.9929s	
6231/25300 (epoch 12.314), train_loss = 0.94144567, grad/param norm = 1.7114e-01, time/batch = 17.3106s	
6232/25300 (epoch 12.316), train_loss = 1.19621526, grad/param norm = 1.7854e-01, time/batch = 17.1390s	
6233/25300 (epoch 12.318), train_loss = 0.90448571, grad/param norm = 1.6622e-01, time/batch = 18.2301s	
6234/25300 (epoch 12.320), train_loss = 1.01969653, grad/param norm = 1.6140e-01, time/batch = 15.4046s	
6235/25300 (epoch 12.322), train_loss = 1.42845292, grad/param norm = 2.1646e-01, time/batch = 18.6446s	
6236/25300 (epoch 12.324), train_loss = 1.04156410, grad/param norm = 1.6198e-01, time/batch = 18.3819s	
6237/25300 (epoch 12.326), train_loss = 0.92089717, grad/param norm = 1.5709e-01, time/batch = 15.9796s	
6238/25300 (epoch 12.328), train_loss = 0.93806804, grad/param norm = 1.6832e-01, time/batch = 15.6425s	
6239/25300 (epoch 12.330), train_loss = 1.11798540, grad/param norm = 1.8094e-01, time/batch = 18.9801s	
6240/25300 (epoch 12.332), train_loss = 1.16863445, grad/param norm = 1.5470e-01, time/batch = 17.2377s	
6241/25300 (epoch 12.334), train_loss = 0.97052757, grad/param norm = 1.5036e-01, time/batch = 16.3723s	
6242/25300 (epoch 12.336), train_loss = 0.98101742, grad/param norm = 1.7882e-01, time/batch = 18.2320s	
6243/25300 (epoch 12.338), train_loss = 0.98132630, grad/param norm = 1.7003e-01, time/batch = 18.4036s	
6244/25300 (epoch 12.340), train_loss = 1.09823890, grad/param norm = 1.9356e-01, time/batch = 18.3112s	
6245/25300 (epoch 12.342), train_loss = 1.10135433, grad/param norm = 1.8174e-01, time/batch = 16.8021s	
6246/25300 (epoch 12.344), train_loss = 1.13837029, grad/param norm = 1.7319e-01, time/batch = 18.5549s	
6247/25300 (epoch 12.346), train_loss = 1.13360693, grad/param norm = 1.8157e-01, time/batch = 19.2914s	
6248/25300 (epoch 12.348), train_loss = 1.01146836, grad/param norm = 1.5470e-01, time/batch = 17.5567s	
6249/25300 (epoch 12.350), train_loss = 1.10698380, grad/param norm = 1.7425e-01, time/batch = 17.1377s	
6250/25300 (epoch 12.352), train_loss = 1.13684734, grad/param norm = 1.7015e-01, time/batch = 16.6556s	
6251/25300 (epoch 12.354), train_loss = 1.07600341, grad/param norm = 1.6716e-01, time/batch = 16.2939s	
6252/25300 (epoch 12.356), train_loss = 1.16161912, grad/param norm = 1.8467e-01, time/batch = 15.7398s	
6253/25300 (epoch 12.358), train_loss = 1.27604195, grad/param norm = 1.9728e-01, time/batch = 16.7329s	
6254/25300 (epoch 12.360), train_loss = 1.03451075, grad/param norm = 1.7333e-01, time/batch = 16.6280s	
6255/25300 (epoch 12.362), train_loss = 1.07358213, grad/param norm = 1.6704e-01, time/batch = 16.1546s	
6256/25300 (epoch 12.364), train_loss = 1.18978703, grad/param norm = 1.7826e-01, time/batch = 18.3840s	
6257/25300 (epoch 12.366), train_loss = 1.00481267, grad/param norm = 1.6683e-01, time/batch = 19.0614s	
6258/25300 (epoch 12.368), train_loss = 1.09992578, grad/param norm = 1.7031e-01, time/batch = 16.1613s	
6259/25300 (epoch 12.370), train_loss = 1.11534090, grad/param norm = 1.9228e-01, time/batch = 16.6367s	
6260/25300 (epoch 12.372), train_loss = 1.06543678, grad/param norm = 1.6818e-01, time/batch = 16.2247s	
6261/25300 (epoch 12.374), train_loss = 1.02356068, grad/param norm = 1.7007e-01, time/batch = 17.5455s	
6262/25300 (epoch 12.375), train_loss = 1.33395670, grad/param norm = 2.0210e-01, time/batch = 15.6887s	
6263/25300 (epoch 12.377), train_loss = 1.18323293, grad/param norm = 1.9582e-01, time/batch = 15.2142s	
6264/25300 (epoch 12.379), train_loss = 1.22418243, grad/param norm = 1.8723e-01, time/batch = 15.4478s	
6265/25300 (epoch 12.381), train_loss = 1.14820093, grad/param norm = 1.7139e-01, time/batch = 16.2973s	
6266/25300 (epoch 12.383), train_loss = 1.03979094, grad/param norm = 1.7858e-01, time/batch = 16.8001s	
6267/25300 (epoch 12.385), train_loss = 1.11308552, grad/param norm = 1.6739e-01, time/batch = 17.1286s	
6268/25300 (epoch 12.387), train_loss = 1.18791500, grad/param norm = 1.7519e-01, time/batch = 17.6384s	
6269/25300 (epoch 12.389), train_loss = 1.26343169, grad/param norm = 1.9988e-01, time/batch = 16.5453s	
6270/25300 (epoch 12.391), train_loss = 1.04126694, grad/param norm = 1.6339e-01, time/batch = 16.6533s	
6271/25300 (epoch 12.393), train_loss = 1.18418866, grad/param norm = 1.9401e-01, time/batch = 15.7287s	
6272/25300 (epoch 12.395), train_loss = 0.98791761, grad/param norm = 1.5844e-01, time/batch = 16.3732s	
6273/25300 (epoch 12.397), train_loss = 1.01343123, grad/param norm = 1.7328e-01, time/batch = 17.4683s	
6274/25300 (epoch 12.399), train_loss = 1.00942955, grad/param norm = 1.7789e-01, time/batch = 18.9465s	
6275/25300 (epoch 12.401), train_loss = 1.28593220, grad/param norm = 1.9918e-01, time/batch = 17.7938s	
6276/25300 (epoch 12.403), train_loss = 1.14763386, grad/param norm = 1.9937e-01, time/batch = 15.8759s	
6277/25300 (epoch 12.405), train_loss = 1.15936364, grad/param norm = 1.9137e-01, time/batch = 18.2223s	
6278/25300 (epoch 12.407), train_loss = 1.06738689, grad/param norm = 1.7213e-01, time/batch = 17.9614s	
6279/25300 (epoch 12.409), train_loss = 1.06391809, grad/param norm = 1.5776e-01, time/batch = 16.8136s	
6280/25300 (epoch 12.411), train_loss = 1.10082737, grad/param norm = 1.7613e-01, time/batch = 15.7971s	
6281/25300 (epoch 12.413), train_loss = 1.01354030, grad/param norm = 1.8089e-01, time/batch = 18.4744s	
6282/25300 (epoch 12.415), train_loss = 0.99836940, grad/param norm = 1.7106e-01, time/batch = 19.1332s	
6283/25300 (epoch 12.417), train_loss = 0.96631616, grad/param norm = 1.5543e-01, time/batch = 16.3829s	
6284/25300 (epoch 12.419), train_loss = 0.94549214, grad/param norm = 1.6621e-01, time/batch = 16.6238s	
6285/25300 (epoch 12.421), train_loss = 0.94133028, grad/param norm = 1.4694e-01, time/batch = 17.3725s	
6286/25300 (epoch 12.423), train_loss = 1.02496329, grad/param norm = 1.6469e-01, time/batch = 16.6377s	
6287/25300 (epoch 12.425), train_loss = 1.09598211, grad/param norm = 1.6951e-01, time/batch = 16.9005s	
6288/25300 (epoch 12.427), train_loss = 1.34226777, grad/param norm = 1.9270e-01, time/batch = 15.6577s	
6289/25300 (epoch 12.429), train_loss = 1.25313942, grad/param norm = 1.8428e-01, time/batch = 16.9711s	
6290/25300 (epoch 12.431), train_loss = 1.14805410, grad/param norm = 1.7830e-01, time/batch = 16.4638s	
6291/25300 (epoch 12.433), train_loss = 1.08208954, grad/param norm = 1.6362e-01, time/batch = 16.3673s	
6292/25300 (epoch 12.435), train_loss = 1.03660389, grad/param norm = 1.8183e-01, time/batch = 17.2274s	
6293/25300 (epoch 12.437), train_loss = 1.06964695, grad/param norm = 1.7461e-01, time/batch = 16.7889s	
6294/25300 (epoch 12.439), train_loss = 1.13591459, grad/param norm = 1.6965e-01, time/batch = 17.3948s	
6295/25300 (epoch 12.441), train_loss = 1.16106399, grad/param norm = 1.9297e-01, time/batch = 15.7083s	
6296/25300 (epoch 12.443), train_loss = 1.38913199, grad/param norm = 2.1931e-01, time/batch = 17.4063s	
6297/25300 (epoch 12.445), train_loss = 1.30367379, grad/param norm = 1.9586e-01, time/batch = 15.8896s	
6298/25300 (epoch 12.447), train_loss = 1.03053006, grad/param norm = 1.6200e-01, time/batch = 19.0553s	
6299/25300 (epoch 12.449), train_loss = 0.95505074, grad/param norm = 1.7709e-01, time/batch = 17.3092s	
6300/25300 (epoch 12.451), train_loss = 1.30712519, grad/param norm = 1.9293e-01, time/batch = 16.7150s	
6301/25300 (epoch 12.453), train_loss = 1.22013117, grad/param norm = 1.8567e-01, time/batch = 17.8890s	
6302/25300 (epoch 12.455), train_loss = 1.27768196, grad/param norm = 1.8881e-01, time/batch = 17.8933s	
6303/25300 (epoch 12.457), train_loss = 1.09905805, grad/param norm = 1.7946e-01, time/batch = 17.7238s	
6304/25300 (epoch 12.458), train_loss = 1.16282103, grad/param norm = 1.8985e-01, time/batch = 17.5344s	
6305/25300 (epoch 12.460), train_loss = 1.17626557, grad/param norm = 1.9213e-01, time/batch = 18.7117s	
6306/25300 (epoch 12.462), train_loss = 0.92711935, grad/param norm = 1.6403e-01, time/batch = 18.7303s	
6307/25300 (epoch 12.464), train_loss = 1.20347673, grad/param norm = 1.8199e-01, time/batch = 17.2928s	
6308/25300 (epoch 12.466), train_loss = 1.23012447, grad/param norm = 1.8149e-01, time/batch = 19.0413s	
6309/25300 (epoch 12.468), train_loss = 1.25569125, grad/param norm = 1.8755e-01, time/batch = 18.2766s	
6310/25300 (epoch 12.470), train_loss = 1.03008659, grad/param norm = 1.6193e-01, time/batch = 16.7969s	
6311/25300 (epoch 12.472), train_loss = 0.93167721, grad/param norm = 1.5054e-01, time/batch = 16.2974s	
6312/25300 (epoch 12.474), train_loss = 1.16813458, grad/param norm = 1.9332e-01, time/batch = 18.1511s	
6313/25300 (epoch 12.476), train_loss = 1.10456628, grad/param norm = 1.8797e-01, time/batch = 18.2839s	
6314/25300 (epoch 12.478), train_loss = 1.21363268, grad/param norm = 1.9662e-01, time/batch = 17.1289s	
6315/25300 (epoch 12.480), train_loss = 1.04408920, grad/param norm = 1.6988e-01, time/batch = 19.4557s	
6316/25300 (epoch 12.482), train_loss = 1.25615471, grad/param norm = 1.9896e-01, time/batch = 18.1192s	
6317/25300 (epoch 12.484), train_loss = 1.22144458, grad/param norm = 1.9838e-01, time/batch = 16.8900s	
6318/25300 (epoch 12.486), train_loss = 1.14992836, grad/param norm = 1.8026e-01, time/batch = 18.8827s	
6319/25300 (epoch 12.488), train_loss = 1.27837584, grad/param norm = 1.8501e-01, time/batch = 17.4740s	
6320/25300 (epoch 12.490), train_loss = 1.19989263, grad/param norm = 1.6897e-01, time/batch = 17.3703s	
6321/25300 (epoch 12.492), train_loss = 1.08969590, grad/param norm = 1.7014e-01, time/batch = 17.8128s	
6322/25300 (epoch 12.494), train_loss = 1.02427389, grad/param norm = 1.7205e-01, time/batch = 16.2504s	
6323/25300 (epoch 12.496), train_loss = 1.13771014, grad/param norm = 1.8420e-01, time/batch = 18.8083s	
6324/25300 (epoch 12.498), train_loss = 1.04370847, grad/param norm = 1.6691e-01, time/batch = 16.7981s	
6325/25300 (epoch 12.500), train_loss = 1.28853031, grad/param norm = 1.9511e-01, time/batch = 17.4700s	
6326/25300 (epoch 12.502), train_loss = 1.14675876, grad/param norm = 1.8634e-01, time/batch = 17.1372s	
6327/25300 (epoch 12.504), train_loss = 1.10098466, grad/param norm = 1.8787e-01, time/batch = 16.9730s	
6328/25300 (epoch 12.506), train_loss = 1.07540119, grad/param norm = 1.7023e-01, time/batch = 17.5681s	
6329/25300 (epoch 12.508), train_loss = 1.16493435, grad/param norm = 1.8413e-01, time/batch = 15.4908s	
6330/25300 (epoch 12.510), train_loss = 1.07424554, grad/param norm = 1.8193e-01, time/batch = 19.8140s	
6331/25300 (epoch 12.512), train_loss = 0.84520661, grad/param norm = 1.3869e-01, time/batch = 16.2352s	
6332/25300 (epoch 12.514), train_loss = 1.07028972, grad/param norm = 1.5778e-01, time/batch = 16.9606s	
6333/25300 (epoch 12.516), train_loss = 1.15126950, grad/param norm = 1.7370e-01, time/batch = 17.4891s	
6334/25300 (epoch 12.518), train_loss = 1.22825744, grad/param norm = 1.9969e-01, time/batch = 16.7057s	
6335/25300 (epoch 12.520), train_loss = 0.95672920, grad/param norm = 1.5245e-01, time/batch = 18.4890s	
6336/25300 (epoch 12.522), train_loss = 1.06139511, grad/param norm = 1.7596e-01, time/batch = 17.5425s	
6337/25300 (epoch 12.524), train_loss = 1.09867643, grad/param norm = 1.6742e-01, time/batch = 15.9061s	
6338/25300 (epoch 12.526), train_loss = 1.37010515, grad/param norm = 1.9244e-01, time/batch = 17.1280s	
6339/25300 (epoch 12.528), train_loss = 1.27655156, grad/param norm = 1.9581e-01, time/batch = 19.4814s	
6340/25300 (epoch 12.530), train_loss = 1.13458709, grad/param norm = 1.7580e-01, time/batch = 16.2274s	
6341/25300 (epoch 12.532), train_loss = 1.16809848, grad/param norm = 1.8877e-01, time/batch = 16.7084s	
6342/25300 (epoch 12.534), train_loss = 1.10995931, grad/param norm = 1.7563e-01, time/batch = 19.2066s	
6343/25300 (epoch 12.536), train_loss = 0.95844032, grad/param norm = 1.7422e-01, time/batch = 17.3816s	
6344/25300 (epoch 12.538), train_loss = 0.94950254, grad/param norm = 1.3589e-01, time/batch = 17.0511s	
6345/25300 (epoch 12.540), train_loss = 1.02274579, grad/param norm = 1.6680e-01, time/batch = 16.5684s	
6346/25300 (epoch 12.542), train_loss = 1.00186033, grad/param norm = 1.6872e-01, time/batch = 17.0532s	
6347/25300 (epoch 12.543), train_loss = 0.96492980, grad/param norm = 1.6772e-01, time/batch = 17.5458s	
6348/25300 (epoch 12.545), train_loss = 1.46813408, grad/param norm = 2.1844e-01, time/batch = 17.3836s	
6349/25300 (epoch 12.547), train_loss = 1.16570040, grad/param norm = 1.8109e-01, time/batch = 17.8709s	
6350/25300 (epoch 12.549), train_loss = 1.42641115, grad/param norm = 2.1363e-01, time/batch = 16.6535s	
6351/25300 (epoch 12.551), train_loss = 1.16993329, grad/param norm = 1.6899e-01, time/batch = 17.3043s	
6352/25300 (epoch 12.553), train_loss = 1.08458595, grad/param norm = 1.7727e-01, time/batch = 15.6558s	
6353/25300 (epoch 12.555), train_loss = 1.25411524, grad/param norm = 2.0005e-01, time/batch = 18.5632s	
6354/25300 (epoch 12.557), train_loss = 1.29173039, grad/param norm = 2.0126e-01, time/batch = 16.6539s	
6355/25300 (epoch 12.559), train_loss = 1.27819651, grad/param norm = 1.9486e-01, time/batch = 15.7396s	
6356/25300 (epoch 12.561), train_loss = 1.30714395, grad/param norm = 1.9440e-01, time/batch = 18.4685s	
6357/25300 (epoch 12.563), train_loss = 1.25411752, grad/param norm = 1.8582e-01, time/batch = 16.4023s	
6358/25300 (epoch 12.565), train_loss = 0.97407413, grad/param norm = 1.6902e-01, time/batch = 18.2192s	
6359/25300 (epoch 12.567), train_loss = 0.87034638, grad/param norm = 1.6332e-01, time/batch = 18.3834s	
6360/25300 (epoch 12.569), train_loss = 1.13580220, grad/param norm = 1.8348e-01, time/batch = 18.0551s	
6361/25300 (epoch 12.571), train_loss = 1.24536289, grad/param norm = 2.0158e-01, time/batch = 17.1417s	
6362/25300 (epoch 12.573), train_loss = 1.09665795, grad/param norm = 1.6892e-01, time/batch = 32.7361s	
6363/25300 (epoch 12.575), train_loss = 1.21340280, grad/param norm = 1.7934e-01, time/batch = 17.0668s	
6364/25300 (epoch 12.577), train_loss = 1.16702618, grad/param norm = 1.7749e-01, time/batch = 16.5435s	
6365/25300 (epoch 12.579), train_loss = 1.36403212, grad/param norm = 2.0408e-01, time/batch = 17.1226s	
6366/25300 (epoch 12.581), train_loss = 1.18884143, grad/param norm = 1.8766e-01, time/batch = 20.0426s	
6367/25300 (epoch 12.583), train_loss = 1.00733235, grad/param norm = 1.7569e-01, time/batch = 18.6206s	
6368/25300 (epoch 12.585), train_loss = 0.97590406, grad/param norm = 1.7112e-01, time/batch = 18.2060s	
6369/25300 (epoch 12.587), train_loss = 1.09801989, grad/param norm = 1.7940e-01, time/batch = 19.2150s	
6370/25300 (epoch 12.589), train_loss = 0.98599682, grad/param norm = 1.6347e-01, time/batch = 19.3078s	
6371/25300 (epoch 12.591), train_loss = 1.01598347, grad/param norm = 1.8914e-01, time/batch = 17.7974s	
6372/25300 (epoch 12.593), train_loss = 1.16102741, grad/param norm = 1.6505e-01, time/batch = 20.2107s	
6373/25300 (epoch 12.595), train_loss = 1.12476198, grad/param norm = 1.8677e-01, time/batch = 17.9730s	
6374/25300 (epoch 12.597), train_loss = 0.93372523, grad/param norm = 1.4659e-01, time/batch = 16.8794s	
6375/25300 (epoch 12.599), train_loss = 1.13512583, grad/param norm = 1.8091e-01, time/batch = 16.7239s	
6376/25300 (epoch 12.601), train_loss = 1.15866604, grad/param norm = 1.7031e-01, time/batch = 19.7156s	
6377/25300 (epoch 12.603), train_loss = 1.17457792, grad/param norm = 1.8685e-01, time/batch = 16.1181s	
6378/25300 (epoch 12.605), train_loss = 1.03606483, grad/param norm = 1.7511e-01, time/batch = 17.2143s	
6379/25300 (epoch 12.607), train_loss = 0.86438467, grad/param norm = 1.6404e-01, time/batch = 16.3188s	
6380/25300 (epoch 12.609), train_loss = 1.09574095, grad/param norm = 1.7987e-01, time/batch = 19.2219s	
6381/25300 (epoch 12.611), train_loss = 1.21018991, grad/param norm = 1.9365e-01, time/batch = 17.4594s	
6382/25300 (epoch 12.613), train_loss = 0.99798979, grad/param norm = 1.7042e-01, time/batch = 18.6362s	
6383/25300 (epoch 12.615), train_loss = 1.13201124, grad/param norm = 1.8322e-01, time/batch = 19.3805s	
6384/25300 (epoch 12.617), train_loss = 1.12417157, grad/param norm = 1.7891e-01, time/batch = 15.7944s	
6385/25300 (epoch 12.619), train_loss = 1.18784975, grad/param norm = 1.8751e-01, time/batch = 17.9755s	
6386/25300 (epoch 12.621), train_loss = 1.23473946, grad/param norm = 1.9440e-01, time/batch = 17.7195s	
6387/25300 (epoch 12.623), train_loss = 1.05487046, grad/param norm = 1.7209e-01, time/batch = 17.9689s	
6388/25300 (epoch 12.625), train_loss = 0.93806019, grad/param norm = 1.6308e-01, time/batch = 18.4692s	
6389/25300 (epoch 12.626), train_loss = 1.05174944, grad/param norm = 1.6782e-01, time/batch = 19.6275s	
6390/25300 (epoch 12.628), train_loss = 1.22622765, grad/param norm = 1.9537e-01, time/batch = 17.4500s	
6391/25300 (epoch 12.630), train_loss = 1.22964030, grad/param norm = 1.8938e-01, time/batch = 16.5499s	
6392/25300 (epoch 12.632), train_loss = 1.19328503, grad/param norm = 1.9912e-01, time/batch = 20.1162s	
6393/25300 (epoch 12.634), train_loss = 1.24076302, grad/param norm = 1.9137e-01, time/batch = 18.3875s	
6394/25300 (epoch 12.636), train_loss = 1.10379208, grad/param norm = 1.7304e-01, time/batch = 16.0270s	
6395/25300 (epoch 12.638), train_loss = 1.22472810, grad/param norm = 2.1987e-01, time/batch = 17.4669s	
6396/25300 (epoch 12.640), train_loss = 1.35262786, grad/param norm = 2.1976e-01, time/batch = 15.7346s	
6397/25300 (epoch 12.642), train_loss = 1.18628165, grad/param norm = 1.9020e-01, time/batch = 16.9673s	
6398/25300 (epoch 12.644), train_loss = 1.18305633, grad/param norm = 1.9818e-01, time/batch = 16.0645s	
6399/25300 (epoch 12.646), train_loss = 1.14441666, grad/param norm = 1.8689e-01, time/batch = 17.6308s	
6400/25300 (epoch 12.648), train_loss = 1.21745293, grad/param norm = 1.8060e-01, time/batch = 19.7973s	
6401/25300 (epoch 12.650), train_loss = 1.16181449, grad/param norm = 1.7418e-01, time/batch = 16.3835s	
6402/25300 (epoch 12.652), train_loss = 1.17606639, grad/param norm = 1.9558e-01, time/batch = 19.4656s	
6403/25300 (epoch 12.654), train_loss = 1.31112404, grad/param norm = 1.8629e-01, time/batch = 18.8924s	
6404/25300 (epoch 12.656), train_loss = 1.23857439, grad/param norm = 1.9896e-01, time/batch = 16.8923s	
6405/25300 (epoch 12.658), train_loss = 0.95296625, grad/param norm = 1.5999e-01, time/batch = 18.3801s	
6406/25300 (epoch 12.660), train_loss = 1.00787499, grad/param norm = 1.7639e-01, time/batch = 17.9585s	
6407/25300 (epoch 12.662), train_loss = 0.96800276, grad/param norm = 1.7076e-01, time/batch = 17.9734s	
6408/25300 (epoch 12.664), train_loss = 0.93345353, grad/param norm = 1.6159e-01, time/batch = 16.2199s	
6409/25300 (epoch 12.666), train_loss = 0.97609792, grad/param norm = 1.6950e-01, time/batch = 18.7915s	
6410/25300 (epoch 12.668), train_loss = 1.06289332, grad/param norm = 2.0293e-01, time/batch = 19.0497s	
6411/25300 (epoch 12.670), train_loss = 0.98821716, grad/param norm = 1.7090e-01, time/batch = 16.0351s	
6412/25300 (epoch 12.672), train_loss = 1.01816883, grad/param norm = 1.7466e-01, time/batch = 18.1227s	
6413/25300 (epoch 12.674), train_loss = 1.04600310, grad/param norm = 1.7459e-01, time/batch = 16.3943s	
6414/25300 (epoch 12.676), train_loss = 1.11214303, grad/param norm = 1.9652e-01, time/batch = 15.9738s	
6415/25300 (epoch 12.678), train_loss = 1.06996796, grad/param norm = 1.9532e-01, time/batch = 15.1185s	
6416/25300 (epoch 12.680), train_loss = 0.94730349, grad/param norm = 1.7028e-01, time/batch = 15.2149s	
6417/25300 (epoch 12.682), train_loss = 0.81591247, grad/param norm = 1.5744e-01, time/batch = 15.4483s	
6418/25300 (epoch 12.684), train_loss = 0.98081128, grad/param norm = 1.5623e-01, time/batch = 15.5297s	
6419/25300 (epoch 12.686), train_loss = 0.96195736, grad/param norm = 1.5327e-01, time/batch = 15.1390s	
6420/25300 (epoch 12.688), train_loss = 1.10558854, grad/param norm = 1.7813e-01, time/batch = 15.0777s	
6421/25300 (epoch 12.690), train_loss = 0.98294756, grad/param norm = 1.5359e-01, time/batch = 17.4822s	
6422/25300 (epoch 12.692), train_loss = 1.11779146, grad/param norm = 1.7296e-01, time/batch = 15.5495s	
6423/25300 (epoch 12.694), train_loss = 1.04077117, grad/param norm = 1.6189e-01, time/batch = 17.6312s	
6424/25300 (epoch 12.696), train_loss = 1.11139061, grad/param norm = 1.7750e-01, time/batch = 18.0509s	
6425/25300 (epoch 12.698), train_loss = 1.17503019, grad/param norm = 1.8095e-01, time/batch = 17.2926s	
6426/25300 (epoch 12.700), train_loss = 0.92263503, grad/param norm = 1.6577e-01, time/batch = 17.0460s	
6427/25300 (epoch 12.702), train_loss = 1.19447026, grad/param norm = 1.7721e-01, time/batch = 17.9894s	
6428/25300 (epoch 12.704), train_loss = 0.88830024, grad/param norm = 1.6721e-01, time/batch = 18.3858s	
6429/25300 (epoch 12.706), train_loss = 1.13383926, grad/param norm = 2.0184e-01, time/batch = 16.0285s	
6430/25300 (epoch 12.708), train_loss = 0.90106806, grad/param norm = 1.5049e-01, time/batch = 17.4823s	
6431/25300 (epoch 12.709), train_loss = 1.26408817, grad/param norm = 1.8168e-01, time/batch = 17.4553s	
6432/25300 (epoch 12.711), train_loss = 1.30939898, grad/param norm = 1.9573e-01, time/batch = 17.8034s	
6433/25300 (epoch 12.713), train_loss = 1.05935142, grad/param norm = 1.6290e-01, time/batch = 16.3055s	
6434/25300 (epoch 12.715), train_loss = 1.07401868, grad/param norm = 1.8035e-01, time/batch = 18.3858s	
6435/25300 (epoch 12.717), train_loss = 1.07716708, grad/param norm = 2.0457e-01, time/batch = 18.3048s	
6436/25300 (epoch 12.719), train_loss = 1.08924495, grad/param norm = 1.7726e-01, time/batch = 17.2823s	
6437/25300 (epoch 12.721), train_loss = 1.14075921, grad/param norm = 1.9737e-01, time/batch = 17.2885s	
6438/25300 (epoch 12.723), train_loss = 1.04911162, grad/param norm = 1.7362e-01, time/batch = 15.8854s	
6439/25300 (epoch 12.725), train_loss = 1.14830019, grad/param norm = 1.7643e-01, time/batch = 15.4004s	
6440/25300 (epoch 12.727), train_loss = 1.14853403, grad/param norm = 1.8020e-01, time/batch = 15.3168s	
6441/25300 (epoch 12.729), train_loss = 1.06481630, grad/param norm = 1.6930e-01, time/batch = 18.8044s	
6442/25300 (epoch 12.731), train_loss = 1.32202864, grad/param norm = 2.0048e-01, time/batch = 17.0521s	
6443/25300 (epoch 12.733), train_loss = 1.05003373, grad/param norm = 1.5428e-01, time/batch = 15.7226s	
6444/25300 (epoch 12.735), train_loss = 1.43827855, grad/param norm = 2.1261e-01, time/batch = 15.6382s	
6445/25300 (epoch 12.737), train_loss = 0.94936239, grad/param norm = 1.6473e-01, time/batch = 16.5023s	
6446/25300 (epoch 12.739), train_loss = 1.24340053, grad/param norm = 1.7438e-01, time/batch = 16.7261s	
6447/25300 (epoch 12.741), train_loss = 1.19399827, grad/param norm = 2.1001e-01, time/batch = 15.6997s	
6448/25300 (epoch 12.743), train_loss = 1.04257829, grad/param norm = 1.6824e-01, time/batch = 18.1378s	
6449/25300 (epoch 12.745), train_loss = 1.02650633, grad/param norm = 1.6352e-01, time/batch = 17.8870s	
6450/25300 (epoch 12.747), train_loss = 0.95772378, grad/param norm = 1.5259e-01, time/batch = 16.7792s	
6451/25300 (epoch 12.749), train_loss = 1.16886266, grad/param norm = 1.8170e-01, time/batch = 15.9709s	
6452/25300 (epoch 12.751), train_loss = 1.24212725, grad/param norm = 1.9408e-01, time/batch = 17.9683s	
6453/25300 (epoch 12.753), train_loss = 1.05477237, grad/param norm = 1.8855e-01, time/batch = 18.3793s	
6454/25300 (epoch 12.755), train_loss = 1.23761360, grad/param norm = 2.0825e-01, time/batch = 16.8799s	
6455/25300 (epoch 12.757), train_loss = 1.02780084, grad/param norm = 1.7107e-01, time/batch = 19.2101s	
6456/25300 (epoch 12.759), train_loss = 1.02080650, grad/param norm = 1.7938e-01, time/batch = 18.0581s	
6457/25300 (epoch 12.761), train_loss = 1.25134617, grad/param norm = 1.9521e-01, time/batch = 17.0563s	
6458/25300 (epoch 12.763), train_loss = 1.02957966, grad/param norm = 1.7071e-01, time/batch = 16.1568s	
6459/25300 (epoch 12.765), train_loss = 1.06200067, grad/param norm = 1.7605e-01, time/batch = 18.5617s	
6460/25300 (epoch 12.767), train_loss = 1.02012117, grad/param norm = 1.7082e-01, time/batch = 16.7303s	
6461/25300 (epoch 12.769), train_loss = 1.15519896, grad/param norm = 1.8564e-01, time/batch = 16.4603s	
6462/25300 (epoch 12.771), train_loss = 1.27434830, grad/param norm = 2.0120e-01, time/batch = 17.9033s	
6463/25300 (epoch 12.773), train_loss = 1.25867663, grad/param norm = 1.9642e-01, time/batch = 17.1428s	
6464/25300 (epoch 12.775), train_loss = 1.06912001, grad/param norm = 1.5693e-01, time/batch = 16.3702s	
6465/25300 (epoch 12.777), train_loss = 1.14866893, grad/param norm = 1.9167e-01, time/batch = 15.5708s	
6466/25300 (epoch 12.779), train_loss = 1.22849407, grad/param norm = 1.8118e-01, time/batch = 15.6525s	
6467/25300 (epoch 12.781), train_loss = 1.13142798, grad/param norm = 1.6372e-01, time/batch = 16.0584s	
6468/25300 (epoch 12.783), train_loss = 1.29689763, grad/param norm = 2.0621e-01, time/batch = 15.4782s	
6469/25300 (epoch 12.785), train_loss = 1.21774083, grad/param norm = 1.8100e-01, time/batch = 15.9756s	
6470/25300 (epoch 12.787), train_loss = 1.22194114, grad/param norm = 1.8208e-01, time/batch = 16.0744s	
6471/25300 (epoch 12.789), train_loss = 1.33130355, grad/param norm = 1.9651e-01, time/batch = 15.7284s	
6472/25300 (epoch 12.791), train_loss = 1.16326135, grad/param norm = 1.8972e-01, time/batch = 16.7097s	
6473/25300 (epoch 12.792), train_loss = 1.22546047, grad/param norm = 1.6885e-01, time/batch = 15.5693s	
6474/25300 (epoch 12.794), train_loss = 1.14402348, grad/param norm = 1.7617e-01, time/batch = 16.3006s	
6475/25300 (epoch 12.796), train_loss = 1.08646521, grad/param norm = 1.7233e-01, time/batch = 15.5240s	
6476/25300 (epoch 12.798), train_loss = 1.28398345, grad/param norm = 1.9567e-01, time/batch = 16.6402s	
6477/25300 (epoch 12.800), train_loss = 1.11069548, grad/param norm = 1.7971e-01, time/batch = 18.3145s	
6478/25300 (epoch 12.802), train_loss = 0.91112791, grad/param norm = 1.7233e-01, time/batch = 17.1268s	
6479/25300 (epoch 12.804), train_loss = 1.15191108, grad/param norm = 1.7046e-01, time/batch = 16.3263s	
6480/25300 (epoch 12.806), train_loss = 1.21152412, grad/param norm = 1.8342e-01, time/batch = 16.8211s	
6481/25300 (epoch 12.808), train_loss = 1.18411983, grad/param norm = 1.9162e-01, time/batch = 20.4349s	
6482/25300 (epoch 12.810), train_loss = 1.14459444, grad/param norm = 2.0500e-01, time/batch = 15.8053s	
6483/25300 (epoch 12.812), train_loss = 1.21743494, grad/param norm = 1.8296e-01, time/batch = 16.2173s	
6484/25300 (epoch 12.814), train_loss = 1.30037052, grad/param norm = 1.8073e-01, time/batch = 17.7155s	
6485/25300 (epoch 12.816), train_loss = 1.41739359, grad/param norm = 1.9072e-01, time/batch = 17.6163s	
6486/25300 (epoch 12.818), train_loss = 1.21817575, grad/param norm = 1.8225e-01, time/batch = 18.1283s	
6487/25300 (epoch 12.820), train_loss = 1.18614775, grad/param norm = 1.7795e-01, time/batch = 16.8238s	
6488/25300 (epoch 12.822), train_loss = 1.12899522, grad/param norm = 1.6551e-01, time/batch = 19.5485s	
6489/25300 (epoch 12.824), train_loss = 1.20334113, grad/param norm = 1.7913e-01, time/batch = 16.0553s	
6490/25300 (epoch 12.826), train_loss = 1.04724881, grad/param norm = 1.6823e-01, time/batch = 17.3974s	
6491/25300 (epoch 12.828), train_loss = 1.06096596, grad/param norm = 1.7770e-01, time/batch = 17.5471s	
6492/25300 (epoch 12.830), train_loss = 1.12688104, grad/param norm = 1.6503e-01, time/batch = 17.7977s	
6493/25300 (epoch 12.832), train_loss = 1.18558885, grad/param norm = 1.8188e-01, time/batch = 18.3788s	
6494/25300 (epoch 12.834), train_loss = 0.98335575, grad/param norm = 1.6051e-01, time/batch = 17.0619s	
6495/25300 (epoch 12.836), train_loss = 1.05338476, grad/param norm = 1.5959e-01, time/batch = 18.6955s	
6496/25300 (epoch 12.838), train_loss = 1.10031720, grad/param norm = 1.6830e-01, time/batch = 17.0682s	
6497/25300 (epoch 12.840), train_loss = 1.28076846, grad/param norm = 1.8937e-01, time/batch = 15.8964s	
6498/25300 (epoch 12.842), train_loss = 1.13855287, grad/param norm = 2.0949e-01, time/batch = 20.7833s	
6499/25300 (epoch 12.844), train_loss = 1.16955521, grad/param norm = 1.7059e-01, time/batch = 15.9731s	
6500/25300 (epoch 12.846), train_loss = 1.18366830, grad/param norm = 1.7338e-01, time/batch = 18.2093s	
6501/25300 (epoch 12.848), train_loss = 1.26590679, grad/param norm = 1.8847e-01, time/batch = 18.7069s	
6502/25300 (epoch 12.850), train_loss = 1.23772783, grad/param norm = 1.9108e-01, time/batch = 16.5552s	
6503/25300 (epoch 12.852), train_loss = 1.19080424, grad/param norm = 1.8670e-01, time/batch = 17.8025s	
6504/25300 (epoch 12.854), train_loss = 1.31327253, grad/param norm = 1.9908e-01, time/batch = 17.0488s	
6505/25300 (epoch 12.856), train_loss = 1.12193458, grad/param norm = 1.8680e-01, time/batch = 18.8104s	
6506/25300 (epoch 12.858), train_loss = 1.21463634, grad/param norm = 2.1116e-01, time/batch = 16.7084s	
6507/25300 (epoch 12.860), train_loss = 0.96014037, grad/param norm = 1.6311e-01, time/batch = 15.7918s	
6508/25300 (epoch 12.862), train_loss = 1.20017023, grad/param norm = 2.1486e-01, time/batch = 17.9642s	
6509/25300 (epoch 12.864), train_loss = 1.24739302, grad/param norm = 1.9230e-01, time/batch = 16.6260s	
6510/25300 (epoch 12.866), train_loss = 1.19197809, grad/param norm = 2.0402e-01, time/batch = 17.1873s	
6511/25300 (epoch 12.868), train_loss = 1.26723156, grad/param norm = 2.0497e-01, time/batch = 19.2919s	
6512/25300 (epoch 12.870), train_loss = 1.23322931, grad/param norm = 1.7099e-01, time/batch = 18.8792s	
6513/25300 (epoch 12.872), train_loss = 1.23429513, grad/param norm = 2.0660e-01, time/batch = 18.8675s	
6514/25300 (epoch 12.874), train_loss = 1.23798720, grad/param norm = 1.9380e-01, time/batch = 19.0482s	
6515/25300 (epoch 12.875), train_loss = 1.13229168, grad/param norm = 1.8054e-01, time/batch = 19.1269s	
6516/25300 (epoch 12.877), train_loss = 1.07113018, grad/param norm = 1.6545e-01, time/batch = 15.8186s	
6517/25300 (epoch 12.879), train_loss = 1.17155704, grad/param norm = 1.8389e-01, time/batch = 16.6578s	
6518/25300 (epoch 12.881), train_loss = 1.46209055, grad/param norm = 2.1238e-01, time/batch = 18.3039s	
6519/25300 (epoch 12.883), train_loss = 1.40816792, grad/param norm = 1.9015e-01, time/batch = 16.4793s	
6520/25300 (epoch 12.885), train_loss = 1.24417042, grad/param norm = 1.9692e-01, time/batch = 18.2988s	
6521/25300 (epoch 12.887), train_loss = 1.18341045, grad/param norm = 1.7871e-01, time/batch = 16.9052s	
6522/25300 (epoch 12.889), train_loss = 1.31089227, grad/param norm = 1.7827e-01, time/batch = 16.5544s	
6523/25300 (epoch 12.891), train_loss = 1.31835667, grad/param norm = 4.0269e-01, time/batch = 16.5698s	
6524/25300 (epoch 12.893), train_loss = 1.39034935, grad/param norm = 2.6829e-01, time/batch = 18.0549s	
6525/25300 (epoch 12.895), train_loss = 0.93477865, grad/param norm = 1.8572e-01, time/batch = 17.8185s	
6526/25300 (epoch 12.897), train_loss = 1.07177979, grad/param norm = 1.9033e-01, time/batch = 16.6540s	
6527/25300 (epoch 12.899), train_loss = 1.16866552, grad/param norm = 1.9567e-01, time/batch = 19.0349s	
6528/25300 (epoch 12.901), train_loss = 1.18453767, grad/param norm = 1.7886e-01, time/batch = 17.0606s	
6529/25300 (epoch 12.903), train_loss = 0.94782776, grad/param norm = 1.6628e-01, time/batch = 15.9601s	
6530/25300 (epoch 12.905), train_loss = 1.07849846, grad/param norm = 1.9152e-01, time/batch = 17.1449s	
6531/25300 (epoch 12.907), train_loss = 1.15982012, grad/param norm = 2.0463e-01, time/batch = 20.7958s	
6532/25300 (epoch 12.909), train_loss = 1.25853410, grad/param norm = 1.8234e-01, time/batch = 17.4512s	
6533/25300 (epoch 12.911), train_loss = 1.39899173, grad/param norm = 1.9611e-01, time/batch = 15.5518s	
6534/25300 (epoch 12.913), train_loss = 1.38952082, grad/param norm = 2.1239e-01, time/batch = 17.7114s	
6535/25300 (epoch 12.915), train_loss = 1.09303181, grad/param norm = 1.8957e-01, time/batch = 16.2082s	
6536/25300 (epoch 12.917), train_loss = 1.21134142, grad/param norm = 1.9094e-01, time/batch = 17.9636s	
6537/25300 (epoch 12.919), train_loss = 1.33938966, grad/param norm = 1.9541e-01, time/batch = 17.3030s	
6538/25300 (epoch 12.921), train_loss = 1.05709842, grad/param norm = 1.7419e-01, time/batch = 16.8175s	
6539/25300 (epoch 12.923), train_loss = 1.31926693, grad/param norm = 1.8892e-01, time/batch = 16.9905s	
6540/25300 (epoch 12.925), train_loss = 1.14282300, grad/param norm = 1.8997e-01, time/batch = 15.8958s	
6541/25300 (epoch 12.927), train_loss = 1.13784525, grad/param norm = 1.8556e-01, time/batch = 17.1394s	
6542/25300 (epoch 12.929), train_loss = 1.09714933, grad/param norm = 1.7298e-01, time/batch = 16.3066s	
6543/25300 (epoch 12.931), train_loss = 1.28828605, grad/param norm = 2.0373e-01, time/batch = 17.9062s	
6544/25300 (epoch 12.933), train_loss = 1.23002780, grad/param norm = 1.8552e-01, time/batch = 18.2877s	
6545/25300 (epoch 12.935), train_loss = 1.20179973, grad/param norm = 1.7734e-01, time/batch = 19.1430s	
6546/25300 (epoch 12.937), train_loss = 0.89812850, grad/param norm = 1.4792e-01, time/batch = 18.5520s	
6547/25300 (epoch 12.939), train_loss = 1.25273076, grad/param norm = 1.7882e-01, time/batch = 17.8065s	
6548/25300 (epoch 12.941), train_loss = 1.11691666, grad/param norm = 1.6939e-01, time/batch = 19.5551s	
6549/25300 (epoch 12.943), train_loss = 1.12863085, grad/param norm = 1.7462e-01, time/batch = 18.7956s	
6550/25300 (epoch 12.945), train_loss = 1.21009143, grad/param norm = 1.9056e-01, time/batch = 16.8144s	
6551/25300 (epoch 12.947), train_loss = 1.06413931, grad/param norm = 1.7137e-01, time/batch = 19.2941s	
6552/25300 (epoch 12.949), train_loss = 1.23463331, grad/param norm = 1.8889e-01, time/batch = 17.0514s	
6553/25300 (epoch 12.951), train_loss = 1.13091890, grad/param norm = 1.7066e-01, time/batch = 16.8683s	
6554/25300 (epoch 12.953), train_loss = 1.21037644, grad/param norm = 1.6884e-01, time/batch = 19.2175s	
6555/25300 (epoch 12.955), train_loss = 1.42810253, grad/param norm = 2.0661e-01, time/batch = 18.8982s	
6556/25300 (epoch 12.957), train_loss = 1.37447427, grad/param norm = 2.1678e-01, time/batch = 17.4598s	
6557/25300 (epoch 12.958), train_loss = 1.22913445, grad/param norm = 1.9124e-01, time/batch = 16.4617s	
6558/25300 (epoch 12.960), train_loss = 1.39542265, grad/param norm = 2.1967e-01, time/batch = 20.1937s	
6559/25300 (epoch 12.962), train_loss = 1.34058797, grad/param norm = 2.0195e-01, time/batch = 18.6431s	
6560/25300 (epoch 12.964), train_loss = 1.25220828, grad/param norm = 1.7572e-01, time/batch = 18.8030s	
6561/25300 (epoch 12.966), train_loss = 1.01151450, grad/param norm = 1.6490e-01, time/batch = 19.9547s	
6562/25300 (epoch 12.968), train_loss = 0.98823910, grad/param norm = 1.6294e-01, time/batch = 16.4772s	
6563/25300 (epoch 12.970), train_loss = 1.14573936, grad/param norm = 1.9372e-01, time/batch = 16.7307s	
6564/25300 (epoch 12.972), train_loss = 1.18211023, grad/param norm = 2.0525e-01, time/batch = 18.8950s	
6565/25300 (epoch 12.974), train_loss = 1.34499666, grad/param norm = 2.0548e-01, time/batch = 18.7248s	
6566/25300 (epoch 12.976), train_loss = 1.20210567, grad/param norm = 1.9358e-01, time/batch = 22.2353s	
6567/25300 (epoch 12.978), train_loss = 1.21789888, grad/param norm = 1.8153e-01, time/batch = 25.6295s	
6568/25300 (epoch 12.980), train_loss = 1.21106910, grad/param norm = 1.9872e-01, time/batch = 15.1292s	
6569/25300 (epoch 12.982), train_loss = 1.12239612, grad/param norm = 1.6962e-01, time/batch = 15.1287s	
6570/25300 (epoch 12.984), train_loss = 1.15518837, grad/param norm = 1.8909e-01, time/batch = 15.6842s	
6571/25300 (epoch 12.986), train_loss = 1.24003291, grad/param norm = 1.9780e-01, time/batch = 15.6846s	
6572/25300 (epoch 12.988), train_loss = 1.25730397, grad/param norm = 2.0168e-01, time/batch = 16.4631s	
6573/25300 (epoch 12.990), train_loss = 1.16283968, grad/param norm = 1.6880e-01, time/batch = 16.3632s	
6574/25300 (epoch 12.992), train_loss = 0.94413261, grad/param norm = 1.7249e-01, time/batch = 16.7867s	
6575/25300 (epoch 12.994), train_loss = 1.18740434, grad/param norm = 1.8723e-01, time/batch = 16.8132s	
6576/25300 (epoch 12.996), train_loss = 1.31800378, grad/param norm = 2.0880e-01, time/batch = 16.9785s	
6577/25300 (epoch 12.998), train_loss = 1.29789203, grad/param norm = 1.8675e-01, time/batch = 17.1445s	
decayed learning rate by a factor 0.97 to 0.00177058562	
6578/25300 (epoch 13.000), train_loss = 1.18021034, grad/param norm = 1.9543e-01, time/batch = 16.7327s	
6579/25300 (epoch 13.002), train_loss = 1.00255539, grad/param norm = 1.5918e-01, time/batch = 16.4128s	
6580/25300 (epoch 13.004), train_loss = 0.97282977, grad/param norm = 1.6518e-01, time/batch = 15.4683s	
6581/25300 (epoch 13.006), train_loss = 1.26660086, grad/param norm = 1.7988e-01, time/batch = 16.9684s	
6582/25300 (epoch 13.008), train_loss = 1.15046717, grad/param norm = 1.7003e-01, time/batch = 16.7253s	
6583/25300 (epoch 13.010), train_loss = 1.16066616, grad/param norm = 1.6402e-01, time/batch = 17.9572s	
6584/25300 (epoch 13.012), train_loss = 1.05818422, grad/param norm = 1.9332e-01, time/batch = 15.5313s	
6585/25300 (epoch 13.014), train_loss = 1.25542305, grad/param norm = 1.9200e-01, time/batch = 17.4769s	
6586/25300 (epoch 13.016), train_loss = 1.21130477, grad/param norm = 1.9597e-01, time/batch = 16.7425s	
6587/25300 (epoch 13.018), train_loss = 1.05443185, grad/param norm = 1.7648e-01, time/batch = 16.8862s	
6588/25300 (epoch 13.020), train_loss = 1.10553257, grad/param norm = 1.7253e-01, time/batch = 16.1520s	
6589/25300 (epoch 13.022), train_loss = 1.18047784, grad/param norm = 1.9718e-01, time/batch = 16.6636s	
6590/25300 (epoch 13.024), train_loss = 0.86443093, grad/param norm = 1.5213e-01, time/batch = 17.8061s	
6591/25300 (epoch 13.026), train_loss = 1.07587012, grad/param norm = 2.0046e-01, time/batch = 15.6360s	
6592/25300 (epoch 13.028), train_loss = 1.00947387, grad/param norm = 1.5740e-01, time/batch = 16.3771s	
6593/25300 (epoch 13.030), train_loss = 1.23999103, grad/param norm = 1.7639e-01, time/batch = 17.4702s	
6594/25300 (epoch 13.032), train_loss = 1.07206292, grad/param norm = 1.7040e-01, time/batch = 16.6348s	
6595/25300 (epoch 13.034), train_loss = 0.93699932, grad/param norm = 1.8219e-01, time/batch = 16.0747s	
6596/25300 (epoch 13.036), train_loss = 0.95810187, grad/param norm = 1.5424e-01, time/batch = 17.7211s	
6597/25300 (epoch 13.038), train_loss = 0.86381277, grad/param norm = 1.4100e-01, time/batch = 19.0608s	
6598/25300 (epoch 13.040), train_loss = 1.18836944, grad/param norm = 1.7727e-01, time/batch = 16.9550s	
6599/25300 (epoch 13.042), train_loss = 1.06094176, grad/param norm = 1.6326e-01, time/batch = 16.7383s	
6600/25300 (epoch 13.043), train_loss = 0.92950708, grad/param norm = 1.4910e-01, time/batch = 16.6445s	
6601/25300 (epoch 13.045), train_loss = 0.96608604, grad/param norm = 1.6590e-01, time/batch = 16.0185s	
6602/25300 (epoch 13.047), train_loss = 1.15962095, grad/param norm = 1.6275e-01, time/batch = 16.6512s	
6603/25300 (epoch 13.049), train_loss = 1.17220397, grad/param norm = 1.9179e-01, time/batch = 16.3936s	
6604/25300 (epoch 13.051), train_loss = 1.23662619, grad/param norm = 2.0893e-01, time/batch = 16.6265s	
6605/25300 (epoch 13.053), train_loss = 0.91591195, grad/param norm = 1.5532e-01, time/batch = 16.3651s	
6606/25300 (epoch 13.055), train_loss = 0.98132308, grad/param norm = 1.5653e-01, time/batch = 18.4689s	
6607/25300 (epoch 13.057), train_loss = 0.92590480, grad/param norm = 1.5114e-01, time/batch = 18.2208s	
6608/25300 (epoch 13.059), train_loss = 1.10535012, grad/param norm = 1.8299e-01, time/batch = 18.2019s	
6609/25300 (epoch 13.061), train_loss = 1.01620845, grad/param norm = 1.6380e-01, time/batch = 17.9775s	
6610/25300 (epoch 13.063), train_loss = 1.00472237, grad/param norm = 1.7384e-01, time/batch = 18.3016s	
6611/25300 (epoch 13.065), train_loss = 1.23805263, grad/param norm = 1.9146e-01, time/batch = 18.2127s	
6612/25300 (epoch 13.067), train_loss = 1.25097852, grad/param norm = 1.9056e-01, time/batch = 17.8876s	
6613/25300 (epoch 13.069), train_loss = 1.10596663, grad/param norm = 1.8204e-01, time/batch = 18.7895s	
6614/25300 (epoch 13.071), train_loss = 1.26209771, grad/param norm = 1.7662e-01, time/batch = 17.3791s	
6615/25300 (epoch 13.073), train_loss = 1.08652541, grad/param norm = 1.6341e-01, time/batch = 16.3907s	
6616/25300 (epoch 13.075), train_loss = 1.16224012, grad/param norm = 1.7711e-01, time/batch = 18.8013s	
6617/25300 (epoch 13.077), train_loss = 1.18533411, grad/param norm = 1.8050e-01, time/batch = 19.9633s	
6618/25300 (epoch 13.079), train_loss = 1.11351206, grad/param norm = 1.6795e-01, time/batch = 16.7248s	
6619/25300 (epoch 13.081), train_loss = 1.09790228, grad/param norm = 1.5812e-01, time/batch = 18.9797s	
6620/25300 (epoch 13.083), train_loss = 1.08626372, grad/param norm = 1.6717e-01, time/batch = 16.6490s	
6621/25300 (epoch 13.085), train_loss = 1.36056891, grad/param norm = 1.9650e-01, time/batch = 18.3707s	
6622/25300 (epoch 13.087), train_loss = 1.15933457, grad/param norm = 1.8159e-01, time/batch = 17.0583s	
6623/25300 (epoch 13.089), train_loss = 1.17521301, grad/param norm = 1.7934e-01, time/batch = 16.7371s	
6624/25300 (epoch 13.091), train_loss = 1.30065798, grad/param norm = 1.8597e-01, time/batch = 17.9585s	
6625/25300 (epoch 13.093), train_loss = 1.26024720, grad/param norm = 1.8892e-01, time/batch = 16.2213s	
6626/25300 (epoch 13.095), train_loss = 1.19956930, grad/param norm = 1.7011e-01, time/batch = 19.1392s	
6627/25300 (epoch 13.097), train_loss = 1.15359267, grad/param norm = 1.7170e-01, time/batch = 16.7378s	
6628/25300 (epoch 13.099), train_loss = 1.19152948, grad/param norm = 1.9246e-01, time/batch = 17.3139s	
6629/25300 (epoch 13.101), train_loss = 1.12729012, grad/param norm = 1.7434e-01, time/batch = 15.3883s	
6630/25300 (epoch 13.103), train_loss = 1.10617505, grad/param norm = 1.7851e-01, time/batch = 17.3872s	
6631/25300 (epoch 13.105), train_loss = 1.17499948, grad/param norm = 1.8734e-01, time/batch = 18.3063s	
6632/25300 (epoch 13.107), train_loss = 1.22533044, grad/param norm = 1.8000e-01, time/batch = 15.6241s	
6633/25300 (epoch 13.109), train_loss = 1.14101260, grad/param norm = 1.9088e-01, time/batch = 16.8813s	
6634/25300 (epoch 13.111), train_loss = 1.10908144, grad/param norm = 1.7084e-01, time/batch = 17.6499s	
6635/25300 (epoch 13.113), train_loss = 1.13712789, grad/param norm = 2.0630e-01, time/batch = 17.1332s	
6636/25300 (epoch 13.115), train_loss = 1.12788562, grad/param norm = 1.8497e-01, time/batch = 15.8922s	
6637/25300 (epoch 13.117), train_loss = 1.20207320, grad/param norm = 1.7738e-01, time/batch = 17.3118s	
6638/25300 (epoch 13.119), train_loss = 1.10747587, grad/param norm = 1.7402e-01, time/batch = 18.5479s	
6639/25300 (epoch 13.121), train_loss = 1.19976533, grad/param norm = 1.8848e-01, time/batch = 15.6339s	
6640/25300 (epoch 13.123), train_loss = 1.13547861, grad/param norm = 1.9578e-01, time/batch = 17.0526s	
6641/25300 (epoch 13.125), train_loss = 1.23256764, grad/param norm = 1.9081e-01, time/batch = 18.6306s	
6642/25300 (epoch 13.126), train_loss = 1.15659244, grad/param norm = 1.8458e-01, time/batch = 16.6427s	
6643/25300 (epoch 13.128), train_loss = 1.15687203, grad/param norm = 1.8379e-01, time/batch = 17.2060s	
6644/25300 (epoch 13.130), train_loss = 0.90912241, grad/param norm = 1.5859e-01, time/batch = 16.4042s	
6645/25300 (epoch 13.132), train_loss = 0.97846635, grad/param norm = 1.5580e-01, time/batch = 15.6553s	
6646/25300 (epoch 13.134), train_loss = 0.90421484, grad/param norm = 1.4951e-01, time/batch = 17.3942s	
6647/25300 (epoch 13.136), train_loss = 1.16581759, grad/param norm = 1.7399e-01, time/batch = 16.9592s	
6648/25300 (epoch 13.138), train_loss = 1.00000921, grad/param norm = 1.6277e-01, time/batch = 18.8912s	
6649/25300 (epoch 13.140), train_loss = 1.06810725, grad/param norm = 1.6567e-01, time/batch = 17.1981s	
6650/25300 (epoch 13.142), train_loss = 1.22355145, grad/param norm = 1.7373e-01, time/batch = 16.7236s	
6651/25300 (epoch 13.144), train_loss = 1.17179896, grad/param norm = 1.7945e-01, time/batch = 18.8005s	
6652/25300 (epoch 13.146), train_loss = 1.24843853, grad/param norm = 2.0208e-01, time/batch = 18.4708s	
6653/25300 (epoch 13.148), train_loss = 1.11027893, grad/param norm = 1.7089e-01, time/batch = 15.8840s	
6654/25300 (epoch 13.150), train_loss = 1.27282847, grad/param norm = 2.3399e-01, time/batch = 17.8855s	
6655/25300 (epoch 13.152), train_loss = 1.34895113, grad/param norm = 1.9351e-01, time/batch = 17.1156s	
6656/25300 (epoch 13.154), train_loss = 1.02889528, grad/param norm = 1.7166e-01, time/batch = 16.5483s	
6657/25300 (epoch 13.156), train_loss = 1.18188330, grad/param norm = 1.7768e-01, time/batch = 16.9505s	
6658/25300 (epoch 13.158), train_loss = 1.03608596, grad/param norm = 1.6048e-01, time/batch = 15.6470s	
6659/25300 (epoch 13.160), train_loss = 1.14717488, grad/param norm = 1.7883e-01, time/batch = 16.9866s	
6660/25300 (epoch 13.162), train_loss = 1.06305496, grad/param norm = 1.7785e-01, time/batch = 16.3771s	
6661/25300 (epoch 13.164), train_loss = 1.23548787, grad/param norm = 1.8754e-01, time/batch = 16.7194s	
6662/25300 (epoch 13.166), train_loss = 1.16448035, grad/param norm = 1.7156e-01, time/batch = 19.8788s	
6663/25300 (epoch 13.168), train_loss = 0.98933882, grad/param norm = 1.5135e-01, time/batch = 17.1524s	
6664/25300 (epoch 13.170), train_loss = 1.08688859, grad/param norm = 1.6252e-01, time/batch = 17.8928s	
6665/25300 (epoch 13.172), train_loss = 1.02221390, grad/param norm = 1.6668e-01, time/batch = 17.1431s	
6666/25300 (epoch 13.174), train_loss = 0.99147130, grad/param norm = 1.6871e-01, time/batch = 18.4776s	
6667/25300 (epoch 13.176), train_loss = 1.07997973, grad/param norm = 1.7116e-01, time/batch = 16.8006s	
6668/25300 (epoch 13.178), train_loss = 1.28394340, grad/param norm = 1.9534e-01, time/batch = 18.2196s	
6669/25300 (epoch 13.180), train_loss = 0.94092986, grad/param norm = 1.5661e-01, time/batch = 20.2286s	
6670/25300 (epoch 13.182), train_loss = 1.06326650, grad/param norm = 1.6988e-01, time/batch = 15.6345s	
6671/25300 (epoch 13.184), train_loss = 1.10807733, grad/param norm = 1.8800e-01, time/batch = 17.5645s	
6672/25300 (epoch 13.186), train_loss = 1.06190848, grad/param norm = 1.7301e-01, time/batch = 17.2219s	
6673/25300 (epoch 13.188), train_loss = 1.11847809, grad/param norm = 1.7563e-01, time/batch = 18.7877s	
6674/25300 (epoch 13.190), train_loss = 1.14246435, grad/param norm = 1.8625e-01, time/batch = 15.6367s	
6675/25300 (epoch 13.192), train_loss = 1.07636656, grad/param norm = 1.7709e-01, time/batch = 18.3165s	
6676/25300 (epoch 13.194), train_loss = 1.10039246, grad/param norm = 1.7213e-01, time/batch = 18.6505s	
6677/25300 (epoch 13.196), train_loss = 1.21742691, grad/param norm = 2.0601e-01, time/batch = 15.4839s	
6678/25300 (epoch 13.198), train_loss = 1.07084284, grad/param norm = 1.9199e-01, time/batch = 17.4787s	
6679/25300 (epoch 13.200), train_loss = 1.12510783, grad/param norm = 1.9273e-01, time/batch = 18.1452s	
6680/25300 (epoch 13.202), train_loss = 1.11743751, grad/param norm = 1.7011e-01, time/batch = 16.2360s	
6681/25300 (epoch 13.204), train_loss = 1.07885352, grad/param norm = 1.7477e-01, time/batch = 18.4657s	
6682/25300 (epoch 13.206), train_loss = 1.20199384, grad/param norm = 1.8442e-01, time/batch = 15.9040s	
6683/25300 (epoch 13.208), train_loss = 1.02147433, grad/param norm = 1.9163e-01, time/batch = 18.4738s	
6684/25300 (epoch 13.209), train_loss = 0.93931181, grad/param norm = 1.6231e-01, time/batch = 16.4742s	
6685/25300 (epoch 13.211), train_loss = 1.10557165, grad/param norm = 1.7977e-01, time/batch = 16.8107s	
6686/25300 (epoch 13.213), train_loss = 1.19013990, grad/param norm = 1.8429e-01, time/batch = 16.9816s	
6687/25300 (epoch 13.215), train_loss = 1.15607733, grad/param norm = 1.8882e-01, time/batch = 17.0506s	
6688/25300 (epoch 13.217), train_loss = 1.17852838, grad/param norm = 2.0301e-01, time/batch = 17.8967s	
6689/25300 (epoch 13.219), train_loss = 1.22548111, grad/param norm = 1.9476e-01, time/batch = 16.8986s	
6690/25300 (epoch 13.221), train_loss = 1.24908227, grad/param norm = 1.8627e-01, time/batch = 18.9590s	
6691/25300 (epoch 13.223), train_loss = 1.19764407, grad/param norm = 1.8947e-01, time/batch = 17.2289s	
6692/25300 (epoch 13.225), train_loss = 1.64098880, grad/param norm = 2.3934e-01, time/batch = 18.2843s	
6693/25300 (epoch 13.227), train_loss = 1.24208837, grad/param norm = 1.8441e-01, time/batch = 19.3753s	
6694/25300 (epoch 13.229), train_loss = 1.16350733, grad/param norm = 1.9648e-01, time/batch = 16.0475s	
6695/25300 (epoch 13.231), train_loss = 1.11226336, grad/param norm = 1.6439e-01, time/batch = 17.7916s	
6696/25300 (epoch 13.233), train_loss = 1.19939943, grad/param norm = 1.8169e-01, time/batch = 17.3691s	
6697/25300 (epoch 13.235), train_loss = 1.11820901, grad/param norm = 1.5868e-01, time/batch = 18.2035s	
6698/25300 (epoch 13.237), train_loss = 1.31219835, grad/param norm = 1.9664e-01, time/batch = 16.9720s	
6699/25300 (epoch 13.239), train_loss = 1.16310912, grad/param norm = 1.9097e-01, time/batch = 16.7341s	
6700/25300 (epoch 13.241), train_loss = 1.25436799, grad/param norm = 1.8022e-01, time/batch = 18.6331s	
6701/25300 (epoch 13.243), train_loss = 1.48630715, grad/param norm = 2.0624e-01, time/batch = 15.6425s	
6702/25300 (epoch 13.245), train_loss = 1.06057222, grad/param norm = 1.8227e-01, time/batch = 18.9719s	
6703/25300 (epoch 13.247), train_loss = 1.23537900, grad/param norm = 1.8168e-01, time/batch = 18.1160s	
6704/25300 (epoch 13.249), train_loss = 1.01068575, grad/param norm = 1.6059e-01, time/batch = 17.2944s	
6705/25300 (epoch 13.251), train_loss = 0.96067063, grad/param norm = 1.7134e-01, time/batch = 18.3821s	
6706/25300 (epoch 13.253), train_loss = 1.13625981, grad/param norm = 1.8384e-01, time/batch = 16.6581s	
6707/25300 (epoch 13.255), train_loss = 1.07535985, grad/param norm = 1.9384e-01, time/batch = 16.0633s	
6708/25300 (epoch 13.257), train_loss = 1.19057282, grad/param norm = 1.9008e-01, time/batch = 16.0386s	
6709/25300 (epoch 13.259), train_loss = 1.36400470, grad/param norm = 1.9773e-01, time/batch = 17.9552s	
6710/25300 (epoch 13.261), train_loss = 1.31132679, grad/param norm = 2.0010e-01, time/batch = 16.7160s	
6711/25300 (epoch 13.263), train_loss = 1.28187800, grad/param norm = 1.8186e-01, time/batch = 17.1391s	
6712/25300 (epoch 13.265), train_loss = 1.36677080, grad/param norm = 1.8652e-01, time/batch = 18.7927s	
6713/25300 (epoch 13.267), train_loss = 1.26350107, grad/param norm = 1.8900e-01, time/batch = 18.2215s	
6714/25300 (epoch 13.269), train_loss = 0.97979845, grad/param norm = 1.5818e-01, time/batch = 17.6403s	
6715/25300 (epoch 13.271), train_loss = 1.09839556, grad/param norm = 1.8833e-01, time/batch = 17.2213s	
6716/25300 (epoch 13.273), train_loss = 1.21650245, grad/param norm = 1.9959e-01, time/batch = 17.9625s	
6717/25300 (epoch 13.275), train_loss = 1.05141426, grad/param norm = 1.5931e-01, time/batch = 19.2741s	
6718/25300 (epoch 13.277), train_loss = 1.10503836, grad/param norm = 1.7554e-01, time/batch = 17.2906s	
6719/25300 (epoch 13.279), train_loss = 1.12051899, grad/param norm = 1.6457e-01, time/batch = 18.6339s	
6720/25300 (epoch 13.281), train_loss = 1.29891380, grad/param norm = 1.9717e-01, time/batch = 16.9846s	
6721/25300 (epoch 13.283), train_loss = 1.02077594, grad/param norm = 1.7175e-01, time/batch = 17.0545s	
6722/25300 (epoch 13.285), train_loss = 1.17568961, grad/param norm = 2.0028e-01, time/batch = 16.1404s	
6723/25300 (epoch 13.287), train_loss = 1.17029463, grad/param norm = 1.7242e-01, time/batch = 15.1370s	
6724/25300 (epoch 13.289), train_loss = 1.07446091, grad/param norm = 1.6946e-01, time/batch = 16.8985s	
6725/25300 (epoch 13.291), train_loss = 1.09666016, grad/param norm = 1.7760e-01, time/batch = 15.2598s	
6726/25300 (epoch 13.292), train_loss = 1.28543919, grad/param norm = 1.8665e-01, time/batch = 15.0512s	
6727/25300 (epoch 13.294), train_loss = 1.17379928, grad/param norm = 1.7699e-01, time/batch = 15.2737s	
6728/25300 (epoch 13.296), train_loss = 1.01145300, grad/param norm = 1.7782e-01, time/batch = 15.2771s	
6729/25300 (epoch 13.298), train_loss = 1.24077033, grad/param norm = 1.7733e-01, time/batch = 16.0381s	
6730/25300 (epoch 13.300), train_loss = 1.26909412, grad/param norm = 1.8969e-01, time/batch = 17.4742s	
6731/25300 (epoch 13.302), train_loss = 0.94528427, grad/param norm = 1.8765e-01, time/batch = 16.8898s	
6732/25300 (epoch 13.304), train_loss = 1.19394168, grad/param norm = 1.8800e-01, time/batch = 16.3756s	
6733/25300 (epoch 13.306), train_loss = 0.90271282, grad/param norm = 1.5862e-01, time/batch = 16.1411s	
6734/25300 (epoch 13.308), train_loss = 1.19161038, grad/param norm = 1.6385e-01, time/batch = 17.4680s	
6735/25300 (epoch 13.310), train_loss = 1.05279465, grad/param norm = 1.8066e-01, time/batch = 17.4608s	
6736/25300 (epoch 13.312), train_loss = 1.12487106, grad/param norm = 1.6318e-01, time/batch = 15.4786s	
6737/25300 (epoch 13.314), train_loss = 0.92543417, grad/param norm = 1.7645e-01, time/batch = 17.5630s	
6738/25300 (epoch 13.316), train_loss = 1.17354914, grad/param norm = 1.7646e-01, time/batch = 17.2302s	
6739/25300 (epoch 13.318), train_loss = 0.88868532, grad/param norm = 1.6477e-01, time/batch = 16.1331s	
6740/25300 (epoch 13.320), train_loss = 0.99189219, grad/param norm = 1.6625e-01, time/batch = 16.1569s	
6741/25300 (epoch 13.322), train_loss = 1.39265164, grad/param norm = 2.1869e-01, time/batch = 16.7383s	
6742/25300 (epoch 13.324), train_loss = 1.01575788, grad/param norm = 1.6231e-01, time/batch = 15.1632s	
6743/25300 (epoch 13.326), train_loss = 0.89791085, grad/param norm = 1.5700e-01, time/batch = 15.3094s	
6744/25300 (epoch 13.328), train_loss = 0.91632592, grad/param norm = 1.6889e-01, time/batch = 17.0472s	
6745/25300 (epoch 13.330), train_loss = 1.09589648, grad/param norm = 1.8062e-01, time/batch = 16.5347s	
6746/25300 (epoch 13.332), train_loss = 1.12808232, grad/param norm = 1.5115e-01, time/batch = 16.8657s	
6747/25300 (epoch 13.334), train_loss = 0.94464473, grad/param norm = 1.5223e-01, time/batch = 15.9617s	
6748/25300 (epoch 13.336), train_loss = 0.95776615, grad/param norm = 1.7076e-01, time/batch = 16.9707s	
6749/25300 (epoch 13.338), train_loss = 0.94843062, grad/param norm = 1.6622e-01, time/batch = 17.1275s	
6750/25300 (epoch 13.340), train_loss = 1.07358925, grad/param norm = 1.9549e-01, time/batch = 16.8787s	
6751/25300 (epoch 13.342), train_loss = 1.08000529, grad/param norm = 1.8330e-01, time/batch = 17.4741s	
6752/25300 (epoch 13.344), train_loss = 1.11217681, grad/param norm = 1.7411e-01, time/batch = 17.3816s	
6753/25300 (epoch 13.346), train_loss = 1.10820407, grad/param norm = 1.8921e-01, time/batch = 17.8758s	
6754/25300 (epoch 13.348), train_loss = 0.99100976, grad/param norm = 1.5719e-01, time/batch = 16.1357s	
6755/25300 (epoch 13.350), train_loss = 1.07042447, grad/param norm = 1.7266e-01, time/batch = 16.6397s	
6756/25300 (epoch 13.352), train_loss = 1.10492687, grad/param norm = 1.7246e-01, time/batch = 18.2237s	
6757/25300 (epoch 13.354), train_loss = 1.04108047, grad/param norm = 1.6703e-01, time/batch = 16.4671s	
6758/25300 (epoch 13.356), train_loss = 1.12922702, grad/param norm = 1.9278e-01, time/batch = 17.3096s	
6759/25300 (epoch 13.358), train_loss = 1.24607537, grad/param norm = 2.0522e-01, time/batch = 16.7191s	
6760/25300 (epoch 13.360), train_loss = 1.01314122, grad/param norm = 1.6914e-01, time/batch = 16.4934s	
6761/25300 (epoch 13.362), train_loss = 1.03863284, grad/param norm = 1.7383e-01, time/batch = 16.4677s	
6762/25300 (epoch 13.364), train_loss = 1.15040473, grad/param norm = 1.8221e-01, time/batch = 19.2263s	
6763/25300 (epoch 13.366), train_loss = 0.97467727, grad/param norm = 1.6822e-01, time/batch = 15.7340s	
6764/25300 (epoch 13.368), train_loss = 1.06284262, grad/param norm = 1.6282e-01, time/batch = 17.2263s	
6765/25300 (epoch 13.370), train_loss = 1.07298624, grad/param norm = 1.8827e-01, time/batch = 16.5548s	
6766/25300 (epoch 13.372), train_loss = 1.04120222, grad/param norm = 1.6814e-01, time/batch = 17.7356s	
6767/25300 (epoch 13.374), train_loss = 0.98665439, grad/param norm = 1.7218e-01, time/batch = 19.0377s	
6768/25300 (epoch 13.375), train_loss = 1.29122233, grad/param norm = 2.0593e-01, time/batch = 16.8787s	
6769/25300 (epoch 13.377), train_loss = 1.15419576, grad/param norm = 2.0852e-01, time/batch = 16.8973s	
6770/25300 (epoch 13.379), train_loss = 1.18476383, grad/param norm = 2.0405e-01, time/batch = 16.5641s	
6771/25300 (epoch 13.381), train_loss = 1.12674508, grad/param norm = 1.6958e-01, time/batch = 17.8728s	
6772/25300 (epoch 13.383), train_loss = 1.00741619, grad/param norm = 1.7587e-01, time/batch = 17.6497s	
6773/25300 (epoch 13.385), train_loss = 1.09169235, grad/param norm = 1.7548e-01, time/batch = 17.6421s	
6774/25300 (epoch 13.387), train_loss = 1.14219489, grad/param norm = 1.7271e-01, time/batch = 17.8847s	
6775/25300 (epoch 13.389), train_loss = 1.22455933, grad/param norm = 1.9827e-01, time/batch = 31.6621s	
6776/25300 (epoch 13.391), train_loss = 1.02192415, grad/param norm = 1.6325e-01, time/batch = 18.2967s	
6777/25300 (epoch 13.393), train_loss = 1.14256157, grad/param norm = 1.9018e-01, time/batch = 16.3782s	
6778/25300 (epoch 13.395), train_loss = 0.97201170, grad/param norm = 1.6302e-01, time/batch = 17.8084s	
6779/25300 (epoch 13.397), train_loss = 0.98450097, grad/param norm = 1.7146e-01, time/batch = 18.2219s	
6780/25300 (epoch 13.399), train_loss = 0.98134012, grad/param norm = 1.7963e-01, time/batch = 16.7153s	
6781/25300 (epoch 13.401), train_loss = 1.24183086, grad/param norm = 1.9956e-01, time/batch = 16.0364s	
6782/25300 (epoch 13.403), train_loss = 1.11872376, grad/param norm = 2.1843e-01, time/batch = 19.7223s	
6783/25300 (epoch 13.405), train_loss = 1.13088825, grad/param norm = 1.9829e-01, time/batch = 17.4858s	
6784/25300 (epoch 13.407), train_loss = 1.03758843, grad/param norm = 1.6779e-01, time/batch = 16.2985s	
6785/25300 (epoch 13.409), train_loss = 1.02660250, grad/param norm = 1.6372e-01, time/batch = 18.2994s	
6786/25300 (epoch 13.411), train_loss = 1.06118237, grad/param norm = 1.7673e-01, time/batch = 18.0640s	
6787/25300 (epoch 13.413), train_loss = 0.97786578, grad/param norm = 1.8443e-01, time/batch = 17.8792s	
6788/25300 (epoch 13.415), train_loss = 0.96939986, grad/param norm = 1.7250e-01, time/batch = 16.4749s	
6789/25300 (epoch 13.417), train_loss = 0.94448284, grad/param norm = 1.6334e-01, time/batch = 15.5726s	
6790/25300 (epoch 13.419), train_loss = 0.91681421, grad/param norm = 1.5953e-01, time/batch = 18.7182s	
6791/25300 (epoch 13.421), train_loss = 0.91809148, grad/param norm = 1.4668e-01, time/batch = 17.2859s	
6792/25300 (epoch 13.423), train_loss = 0.98714027, grad/param norm = 1.6691e-01, time/batch = 18.1514s	
6793/25300 (epoch 13.425), train_loss = 1.07076789, grad/param norm = 1.8321e-01, time/batch = 16.8009s	
6794/25300 (epoch 13.427), train_loss = 1.30334445, grad/param norm = 1.9505e-01, time/batch = 17.2264s	
6795/25300 (epoch 13.429), train_loss = 1.21996031, grad/param norm = 1.8391e-01, time/batch = 16.1502s	
6796/25300 (epoch 13.431), train_loss = 1.12185600, grad/param norm = 1.7793e-01, time/batch = 17.8019s	
6797/25300 (epoch 13.433), train_loss = 1.05617002, grad/param norm = 1.7244e-01, time/batch = 15.7041s	
6798/25300 (epoch 13.435), train_loss = 1.01119136, grad/param norm = 1.8567e-01, time/batch = 17.2130s	
6799/25300 (epoch 13.437), train_loss = 1.04672127, grad/param norm = 1.7744e-01, time/batch = 16.8863s	
6800/25300 (epoch 13.439), train_loss = 1.11002552, grad/param norm = 1.7208e-01, time/batch = 16.6351s	
6801/25300 (epoch 13.441), train_loss = 1.13310177, grad/param norm = 1.9459e-01, time/batch = 17.9648s	
6802/25300 (epoch 13.443), train_loss = 1.35024921, grad/param norm = 2.2024e-01, time/batch = 16.8910s	
6803/25300 (epoch 13.445), train_loss = 1.27702485, grad/param norm = 1.9904e-01, time/batch = 15.9729s	
6804/25300 (epoch 13.447), train_loss = 0.99969050, grad/param norm = 1.5756e-01, time/batch = 18.3912s	
6805/25300 (epoch 13.449), train_loss = 0.92253387, grad/param norm = 1.8228e-01, time/batch = 17.0319s	
6806/25300 (epoch 13.451), train_loss = 1.27828043, grad/param norm = 1.9337e-01, time/batch = 20.1242s	
6807/25300 (epoch 13.453), train_loss = 1.19351700, grad/param norm = 1.8826e-01, time/batch = 18.0497s	
6808/25300 (epoch 13.455), train_loss = 1.23779921, grad/param norm = 2.0278e-01, time/batch = 16.5516s	
6809/25300 (epoch 13.457), train_loss = 1.06609161, grad/param norm = 1.7734e-01, time/batch = 16.4683s	
6810/25300 (epoch 13.458), train_loss = 1.13775297, grad/param norm = 1.9933e-01, time/batch = 16.9940s	
6811/25300 (epoch 13.460), train_loss = 1.14082648, grad/param norm = 1.9691e-01, time/batch = 17.6432s	
6812/25300 (epoch 13.462), train_loss = 0.89393039, grad/param norm = 1.7158e-01, time/batch = 15.6467s	
6813/25300 (epoch 13.464), train_loss = 1.17388141, grad/param norm = 1.9140e-01, time/batch = 16.4472s	
6814/25300 (epoch 13.466), train_loss = 1.19869129, grad/param norm = 1.8383e-01, time/batch = 18.8866s	
6815/25300 (epoch 13.468), train_loss = 1.21624044, grad/param norm = 1.8400e-01, time/batch = 16.4609s	
6816/25300 (epoch 13.470), train_loss = 1.00592349, grad/param norm = 1.6728e-01, time/batch = 16.3067s	
6817/25300 (epoch 13.472), train_loss = 0.91184160, grad/param norm = 1.5466e-01, time/batch = 19.2824s	
6818/25300 (epoch 13.474), train_loss = 1.13845837, grad/param norm = 1.9493e-01, time/batch = 18.5432s	
6819/25300 (epoch 13.476), train_loss = 1.06533533, grad/param norm = 1.7367e-01, time/batch = 17.6361s	
6820/25300 (epoch 13.478), train_loss = 1.18177161, grad/param norm = 1.9741e-01, time/batch = 18.8040s	
6821/25300 (epoch 13.480), train_loss = 1.02251220, grad/param norm = 1.7206e-01, time/batch = 17.9728s	
6822/25300 (epoch 13.482), train_loss = 1.20318494, grad/param norm = 1.9495e-01, time/batch = 15.7968s	
6823/25300 (epoch 13.484), train_loss = 1.18638050, grad/param norm = 1.9976e-01, time/batch = 18.7947s	
6824/25300 (epoch 13.486), train_loss = 1.11599641, grad/param norm = 1.7670e-01, time/batch = 18.5586s	
6825/25300 (epoch 13.488), train_loss = 1.26170624, grad/param norm = 1.8895e-01, time/batch = 16.6353s	
6826/25300 (epoch 13.490), train_loss = 1.16783353, grad/param norm = 1.6934e-01, time/batch = 17.2409s	
6827/25300 (epoch 13.492), train_loss = 1.07539325, grad/param norm = 1.7793e-01, time/batch = 16.0737s	
6828/25300 (epoch 13.494), train_loss = 0.99899790, grad/param norm = 1.6960e-01, time/batch = 17.9723s	
6829/25300 (epoch 13.496), train_loss = 1.10763814, grad/param norm = 1.7973e-01, time/batch = 16.8817s	
6830/25300 (epoch 13.498), train_loss = 1.01931717, grad/param norm = 1.6539e-01, time/batch = 16.9876s	
6831/25300 (epoch 13.500), train_loss = 1.25760168, grad/param norm = 1.9822e-01, time/batch = 18.7027s	
6832/25300 (epoch 13.502), train_loss = 1.12571612, grad/param norm = 1.8425e-01, time/batch = 15.9461s	
6833/25300 (epoch 13.504), train_loss = 1.07178944, grad/param norm = 1.8459e-01, time/batch = 17.5568s	
6834/25300 (epoch 13.506), train_loss = 1.04844455, grad/param norm = 1.7074e-01, time/batch = 17.7125s	
6835/25300 (epoch 13.508), train_loss = 1.12955352, grad/param norm = 1.8353e-01, time/batch = 17.4765s	
6836/25300 (epoch 13.510), train_loss = 1.04540894, grad/param norm = 1.7952e-01, time/batch = 16.4773s	
6837/25300 (epoch 13.512), train_loss = 0.82815196, grad/param norm = 1.4984e-01, time/batch = 18.5662s	
6838/25300 (epoch 13.514), train_loss = 1.04504506, grad/param norm = 1.5427e-01, time/batch = 19.2972s	
6839/25300 (epoch 13.516), train_loss = 1.13796290, grad/param norm = 1.7970e-01, time/batch = 16.2167s	
6840/25300 (epoch 13.518), train_loss = 1.21341747, grad/param norm = 2.0626e-01, time/batch = 17.4847s	
6841/25300 (epoch 13.520), train_loss = 0.92684956, grad/param norm = 1.5389e-01, time/batch = 17.9906s	
6842/25300 (epoch 13.522), train_loss = 1.03163673, grad/param norm = 1.7479e-01, time/batch = 17.6303s	
6843/25300 (epoch 13.524), train_loss = 1.07688882, grad/param norm = 1.7336e-01, time/batch = 16.8811s	
6844/25300 (epoch 13.526), train_loss = 1.33324123, grad/param norm = 1.9098e-01, time/batch = 17.5618s	
6845/25300 (epoch 13.528), train_loss = 1.23231005, grad/param norm = 1.9422e-01, time/batch = 18.4752s	
6846/25300 (epoch 13.530), train_loss = 1.11344903, grad/param norm = 1.7998e-01, time/batch = 15.3796s	
6847/25300 (epoch 13.532), train_loss = 1.12938763, grad/param norm = 1.8850e-01, time/batch = 16.7967s	
6848/25300 (epoch 13.534), train_loss = 1.07963850, grad/param norm = 1.7090e-01, time/batch = 16.9920s	
6849/25300 (epoch 13.536), train_loss = 0.91380743, grad/param norm = 1.6230e-01, time/batch = 17.2821s	
6850/25300 (epoch 13.538), train_loss = 0.92924992, grad/param norm = 1.4131e-01, time/batch = 16.1332s	
6851/25300 (epoch 13.540), train_loss = 0.99884190, grad/param norm = 1.6540e-01, time/batch = 18.3084s	
6852/25300 (epoch 13.542), train_loss = 0.96803606, grad/param norm = 1.6274e-01, time/batch = 18.1322s	
6853/25300 (epoch 13.543), train_loss = 0.93331004, grad/param norm = 1.6381e-01, time/batch = 16.1372s	
6854/25300 (epoch 13.545), train_loss = 1.43091168, grad/param norm = 2.1356e-01, time/batch = 19.8896s	
6855/25300 (epoch 13.547), train_loss = 1.14981128, grad/param norm = 1.9254e-01, time/batch = 17.5513s	
6856/25300 (epoch 13.549), train_loss = 1.39133703, grad/param norm = 2.0652e-01, time/batch = 16.5388s	
6857/25300 (epoch 13.551), train_loss = 1.14484396, grad/param norm = 1.6510e-01, time/batch = 19.7106s	
6858/25300 (epoch 13.553), train_loss = 1.04378123, grad/param norm = 1.7565e-01, time/batch = 18.6510s	
6859/25300 (epoch 13.555), train_loss = 1.22294470, grad/param norm = 1.9903e-01, time/batch = 17.2271s	
6860/25300 (epoch 13.557), train_loss = 1.25320411, grad/param norm = 1.9375e-01, time/batch = 16.6332s	
6861/25300 (epoch 13.559), train_loss = 1.23742148, grad/param norm = 1.9708e-01, time/batch = 16.2528s	
6862/25300 (epoch 13.561), train_loss = 1.26953762, grad/param norm = 1.9067e-01, time/batch = 18.8002s	
6863/25300 (epoch 13.563), train_loss = 1.22635620, grad/param norm = 1.9275e-01, time/batch = 15.9017s	
6864/25300 (epoch 13.565), train_loss = 0.95099725, grad/param norm = 1.6745e-01, time/batch = 17.6446s	
6865/25300 (epoch 13.567), train_loss = 0.84234753, grad/param norm = 1.5681e-01, time/batch = 18.6471s	
6866/25300 (epoch 13.569), train_loss = 1.10766922, grad/param norm = 1.8154e-01, time/batch = 15.8965s	
6867/25300 (epoch 13.571), train_loss = 1.21173730, grad/param norm = 2.0187e-01, time/batch = 16.1361s	
6868/25300 (epoch 13.573), train_loss = 1.07583155, grad/param norm = 1.6941e-01, time/batch = 17.8813s	
6869/25300 (epoch 13.575), train_loss = 1.18704937, grad/param norm = 1.7768e-01, time/batch = 17.2305s	
6870/25300 (epoch 13.577), train_loss = 1.13368154, grad/param norm = 1.7973e-01, time/batch = 16.2232s	
6871/25300 (epoch 13.579), train_loss = 1.31724483, grad/param norm = 2.0144e-01, time/batch = 16.0793s	
6872/25300 (epoch 13.581), train_loss = 1.16488938, grad/param norm = 1.9119e-01, time/batch = 16.1639s	
6873/25300 (epoch 13.583), train_loss = 0.96961937, grad/param norm = 1.7885e-01, time/batch = 17.2126s	
6874/25300 (epoch 13.585), train_loss = 0.94598866, grad/param norm = 1.6677e-01, time/batch = 17.5603s	
6875/25300 (epoch 13.587), train_loss = 1.06769988, grad/param norm = 1.7343e-01, time/batch = 20.5303s	
6876/25300 (epoch 13.589), train_loss = 0.96299876, grad/param norm = 1.6461e-01, time/batch = 18.7966s	
6877/25300 (epoch 13.591), train_loss = 0.98569527, grad/param norm = 1.8607e-01, time/batch = 16.3913s	
6878/25300 (epoch 13.593), train_loss = 1.13877400, grad/param norm = 1.6158e-01, time/batch = 17.2288s	
6879/25300 (epoch 13.595), train_loss = 1.09830852, grad/param norm = 1.8392e-01, time/batch = 17.4096s	
6880/25300 (epoch 13.597), train_loss = 0.91480648, grad/param norm = 1.4587e-01, time/batch = 16.1203s	
6881/25300 (epoch 13.599), train_loss = 1.10417671, grad/param norm = 1.7236e-01, time/batch = 15.7809s	
6882/25300 (epoch 13.601), train_loss = 1.13462278, grad/param norm = 1.9552e-01, time/batch = 15.6301s	
6883/25300 (epoch 13.603), train_loss = 1.13537534, grad/param norm = 1.8070e-01, time/batch = 15.6259s	
6884/25300 (epoch 13.605), train_loss = 1.01733347, grad/param norm = 1.7988e-01, time/batch = 15.6967s	
6885/25300 (epoch 13.607), train_loss = 0.82875565, grad/param norm = 1.5727e-01, time/batch = 16.5480s	
6886/25300 (epoch 13.609), train_loss = 1.06104215, grad/param norm = 1.8782e-01, time/batch = 16.3094s	
6887/25300 (epoch 13.611), train_loss = 1.18194998, grad/param norm = 2.0077e-01, time/batch = 16.1259s	
6888/25300 (epoch 13.613), train_loss = 0.96264576, grad/param norm = 1.7050e-01, time/batch = 16.1301s	
6889/25300 (epoch 13.615), train_loss = 1.08843039, grad/param norm = 1.8033e-01, time/batch = 15.9841s	
6890/25300 (epoch 13.617), train_loss = 1.08498815, grad/param norm = 1.7636e-01, time/batch = 16.2339s	
6891/25300 (epoch 13.619), train_loss = 1.14946584, grad/param norm = 1.8697e-01, time/batch = 16.4593s	
6892/25300 (epoch 13.621), train_loss = 1.21458946, grad/param norm = 1.9898e-01, time/batch = 16.3908s	
6893/25300 (epoch 13.623), train_loss = 1.02931901, grad/param norm = 1.7195e-01, time/batch = 16.4014s	
6894/25300 (epoch 13.625), train_loss = 0.91878434, grad/param norm = 1.6705e-01, time/batch = 16.7399s	
6895/25300 (epoch 13.626), train_loss = 1.01693879, grad/param norm = 1.6594e-01, time/batch = 15.6278s	
6896/25300 (epoch 13.628), train_loss = 1.19480512, grad/param norm = 2.0465e-01, time/batch = 17.3273s	
6897/25300 (epoch 13.630), train_loss = 1.19119705, grad/param norm = 1.9321e-01, time/batch = 17.4724s	
6898/25300 (epoch 13.632), train_loss = 1.15419340, grad/param norm = 2.0545e-01, time/batch = 16.5468s	
6899/25300 (epoch 13.634), train_loss = 1.21510239, grad/param norm = 1.9448e-01, time/batch = 16.4466s	
6900/25300 (epoch 13.636), train_loss = 1.06659854, grad/param norm = 1.7460e-01, time/batch = 17.4785s	
6901/25300 (epoch 13.638), train_loss = 1.17407071, grad/param norm = 2.0445e-01, time/batch = 17.7242s	
6902/25300 (epoch 13.640), train_loss = 1.30014981, grad/param norm = 2.0433e-01, time/batch = 16.0528s	
6903/25300 (epoch 13.642), train_loss = 1.15982657, grad/param norm = 1.8768e-01, time/batch = 15.6241s	
6904/25300 (epoch 13.644), train_loss = 1.14508662, grad/param norm = 1.9329e-01, time/batch = 17.7886s	
6905/25300 (epoch 13.646), train_loss = 1.10051144, grad/param norm = 1.8727e-01, time/batch = 17.3759s	
6906/25300 (epoch 13.648), train_loss = 1.19027251, grad/param norm = 1.8474e-01, time/batch = 15.6490s	
6907/25300 (epoch 13.650), train_loss = 1.13101048, grad/param norm = 1.7643e-01, time/batch = 16.5773s	
6908/25300 (epoch 13.652), train_loss = 1.15180830, grad/param norm = 2.0922e-01, time/batch = 17.1562s	
6909/25300 (epoch 13.654), train_loss = 1.28064591, grad/param norm = 1.8839e-01, time/batch = 15.6391s	
6910/25300 (epoch 13.656), train_loss = 1.20490413, grad/param norm = 2.1163e-01, time/batch = 15.2930s	
6911/25300 (epoch 13.658), train_loss = 0.93126459, grad/param norm = 1.5938e-01, time/batch = 15.4439s	
6912/25300 (epoch 13.660), train_loss = 0.98545250, grad/param norm = 1.7690e-01, time/batch = 16.8088s	
6913/25300 (epoch 13.662), train_loss = 0.94598259, grad/param norm = 1.6692e-01, time/batch = 15.7218s	
6914/25300 (epoch 13.664), train_loss = 0.89832232, grad/param norm = 1.5946e-01, time/batch = 16.1248s	
6915/25300 (epoch 13.666), train_loss = 0.95065155, grad/param norm = 1.6589e-01, time/batch = 16.8839s	
6916/25300 (epoch 13.668), train_loss = 1.05829939, grad/param norm = 2.6855e-01, time/batch = 17.6298s	
6917/25300 (epoch 13.670), train_loss = 0.96103126, grad/param norm = 1.8206e-01, time/batch = 16.0735s	
6918/25300 (epoch 13.672), train_loss = 0.99274081, grad/param norm = 1.7143e-01, time/batch = 18.5516s	
6919/25300 (epoch 13.674), train_loss = 1.00543457, grad/param norm = 1.7794e-01, time/batch = 18.1417s	
6920/25300 (epoch 13.676), train_loss = 1.08779174, grad/param norm = 2.1827e-01, time/batch = 16.6928s	
6921/25300 (epoch 13.678), train_loss = 1.04406983, grad/param norm = 2.0027e-01, time/batch = 17.3785s	
6922/25300 (epoch 13.680), train_loss = 0.92151201, grad/param norm = 1.7035e-01, time/batch = 18.7236s	
6923/25300 (epoch 13.682), train_loss = 0.78285652, grad/param norm = 1.5916e-01, time/batch = 16.3757s	
6924/25300 (epoch 13.684), train_loss = 0.94791917, grad/param norm = 1.5918e-01, time/batch = 15.6224s	
6925/25300 (epoch 13.686), train_loss = 0.93813349, grad/param norm = 1.5635e-01, time/batch = 17.0461s	
6926/25300 (epoch 13.688), train_loss = 1.08387070, grad/param norm = 1.9085e-01, time/batch = 16.2138s	
6927/25300 (epoch 13.690), train_loss = 0.96218458, grad/param norm = 1.5713e-01, time/batch = 16.1472s	
6928/25300 (epoch 13.692), train_loss = 1.06642585, grad/param norm = 1.6990e-01, time/batch = 17.4786s	
6929/25300 (epoch 13.694), train_loss = 1.01048127, grad/param norm = 1.6640e-01, time/batch = 18.3838s	
6930/25300 (epoch 13.696), train_loss = 1.08330459, grad/param norm = 1.7454e-01, time/batch = 17.3814s	
6931/25300 (epoch 13.698), train_loss = 1.13525448, grad/param norm = 1.8049e-01, time/batch = 18.2977s	
6932/25300 (epoch 13.700), train_loss = 0.89525485, grad/param norm = 1.7067e-01, time/batch = 16.7315s	
6933/25300 (epoch 13.702), train_loss = 1.17187055, grad/param norm = 1.8454e-01, time/batch = 18.0416s	
6934/25300 (epoch 13.704), train_loss = 0.86133438, grad/param norm = 1.6609e-01, time/batch = 16.3841s	
6935/25300 (epoch 13.706), train_loss = 1.09955786, grad/param norm = 1.9462e-01, time/batch = 18.3060s	
6936/25300 (epoch 13.708), train_loss = 0.88178921, grad/param norm = 1.5650e-01, time/batch = 16.8257s	
6937/25300 (epoch 13.709), train_loss = 1.24626811, grad/param norm = 1.8638e-01, time/batch = 17.8713s	
6938/25300 (epoch 13.711), train_loss = 1.27418603, grad/param norm = 2.0673e-01, time/batch = 17.2159s	
6939/25300 (epoch 13.713), train_loss = 1.02598666, grad/param norm = 1.5958e-01, time/batch = 16.3986s	
6940/25300 (epoch 13.715), train_loss = 1.05321030, grad/param norm = 1.8076e-01, time/batch = 20.2708s	
6941/25300 (epoch 13.717), train_loss = 1.04252724, grad/param norm = 2.0526e-01, time/batch = 17.8782s	
6942/25300 (epoch 13.719), train_loss = 1.05992539, grad/param norm = 1.8548e-01, time/batch = 17.8744s	
6943/25300 (epoch 13.721), train_loss = 1.10896265, grad/param norm = 1.9441e-01, time/batch = 18.2105s	
6944/25300 (epoch 13.723), train_loss = 1.02314280, grad/param norm = 1.7401e-01, time/batch = 15.7175s	
6945/25300 (epoch 13.725), train_loss = 1.11777425, grad/param norm = 1.8140e-01, time/batch = 19.1350s	
6946/25300 (epoch 13.727), train_loss = 1.12173765, grad/param norm = 1.8411e-01, time/batch = 18.3030s	
6947/25300 (epoch 13.729), train_loss = 1.04565427, grad/param norm = 1.7124e-01, time/batch = 17.7201s	
6948/25300 (epoch 13.731), train_loss = 1.28261955, grad/param norm = 1.9907e-01, time/batch = 15.7408s	
6949/25300 (epoch 13.733), train_loss = 1.02108389, grad/param norm = 1.5344e-01, time/batch = 16.6560s	
6950/25300 (epoch 13.735), train_loss = 1.39890769, grad/param norm = 2.0535e-01, time/batch = 15.5455s	
6951/25300 (epoch 13.737), train_loss = 0.92789070, grad/param norm = 1.6889e-01, time/batch = 15.7194s	
6952/25300 (epoch 13.739), train_loss = 1.21379718, grad/param norm = 1.7508e-01, time/batch = 15.2034s	
6953/25300 (epoch 13.741), train_loss = 1.17136595, grad/param norm = 2.1130e-01, time/batch = 15.3759s	
6954/25300 (epoch 13.743), train_loss = 1.01961824, grad/param norm = 1.6707e-01, time/batch = 16.1710s	
6955/25300 (epoch 13.745), train_loss = 0.99612182, grad/param norm = 1.6787e-01, time/batch = 15.6801s	
6956/25300 (epoch 13.747), train_loss = 0.93810742, grad/param norm = 1.5114e-01, time/batch = 15.2668s	
6957/25300 (epoch 13.749), train_loss = 1.13363291, grad/param norm = 1.8160e-01, time/batch = 15.1241s	
6958/25300 (epoch 13.751), train_loss = 1.20852698, grad/param norm = 1.9732e-01, time/batch = 16.9668s	
6959/25300 (epoch 13.753), train_loss = 1.02234719, grad/param norm = 1.9029e-01, time/batch = 17.6289s	
6960/25300 (epoch 13.755), train_loss = 1.20758076, grad/param norm = 2.0672e-01, time/batch = 18.2350s	
6961/25300 (epoch 13.757), train_loss = 1.00587005, grad/param norm = 1.7680e-01, time/batch = 16.8077s	
6962/25300 (epoch 13.759), train_loss = 0.99963619, grad/param norm = 1.7733e-01, time/batch = 16.4738s	
6963/25300 (epoch 13.761), train_loss = 1.22324155, grad/param norm = 1.9954e-01, time/batch = 16.1595s	
6964/25300 (epoch 13.763), train_loss = 1.00430615, grad/param norm = 1.7268e-01, time/batch = 19.8852s	
6965/25300 (epoch 13.765), train_loss = 1.02726509, grad/param norm = 1.7405e-01, time/batch = 17.8689s	
6966/25300 (epoch 13.767), train_loss = 0.99941967, grad/param norm = 1.7216e-01, time/batch = 16.8072s	
6967/25300 (epoch 13.769), train_loss = 1.12768415, grad/param norm = 1.8586e-01, time/batch = 15.8752s	
6968/25300 (epoch 13.771), train_loss = 1.23245542, grad/param norm = 1.9080e-01, time/batch = 17.6464s	
6969/25300 (epoch 13.773), train_loss = 1.21675640, grad/param norm = 1.9665e-01, time/batch = 16.6284s	
6970/25300 (epoch 13.775), train_loss = 1.03949435, grad/param norm = 1.5646e-01, time/batch = 16.7884s	
6971/25300 (epoch 13.777), train_loss = 1.10892204, grad/param norm = 1.8971e-01, time/batch = 18.8112s	
6972/25300 (epoch 13.779), train_loss = 1.19187551, grad/param norm = 1.7721e-01, time/batch = 16.6465s	
6973/25300 (epoch 13.781), train_loss = 1.11569123, grad/param norm = 1.6881e-01, time/batch = 17.5579s	
6974/25300 (epoch 13.783), train_loss = 1.25215259, grad/param norm = 1.9856e-01, time/batch = 16.8874s	
6975/25300 (epoch 13.785), train_loss = 1.19428767, grad/param norm = 1.8436e-01, time/batch = 18.0314s	
6976/25300 (epoch 13.787), train_loss = 1.18359244, grad/param norm = 1.8297e-01, time/batch = 16.2827s	
6977/25300 (epoch 13.789), train_loss = 1.30493732, grad/param norm = 1.9854e-01, time/batch = 17.9668s	
6978/25300 (epoch 13.791), train_loss = 1.13972716, grad/param norm = 1.9379e-01, time/batch = 18.1365s	
6979/25300 (epoch 13.792), train_loss = 1.19622989, grad/param norm = 1.6903e-01, time/batch = 17.0505s	
6980/25300 (epoch 13.794), train_loss = 1.11123515, grad/param norm = 1.7244e-01, time/batch = 17.2227s	
6981/25300 (epoch 13.796), train_loss = 1.06118721, grad/param norm = 1.7735e-01, time/batch = 18.7168s	
6982/25300 (epoch 13.798), train_loss = 1.26106101, grad/param norm = 1.9807e-01, time/batch = 20.1057s	
6983/25300 (epoch 13.800), train_loss = 1.08652858, grad/param norm = 1.7957e-01, time/batch = 28.9847s	
6984/25300 (epoch 13.802), train_loss = 0.88758930, grad/param norm = 1.7495e-01, time/batch = 20.2838s	
6985/25300 (epoch 13.804), train_loss = 1.12435007, grad/param norm = 1.7155e-01, time/batch = 16.6522s	
6986/25300 (epoch 13.806), train_loss = 1.18500432, grad/param norm = 1.8737e-01, time/batch = 16.3142s	
6987/25300 (epoch 13.808), train_loss = 1.15506172, grad/param norm = 1.9153e-01, time/batch = 17.7975s	
6988/25300 (epoch 13.810), train_loss = 1.10210929, grad/param norm = 1.8986e-01, time/batch = 18.1397s	
6989/25300 (epoch 13.812), train_loss = 1.18317699, grad/param norm = 1.7829e-01, time/batch = 16.0559s	
6990/25300 (epoch 13.814), train_loss = 1.27335505, grad/param norm = 1.8425e-01, time/batch = 18.0655s	
6991/25300 (epoch 13.816), train_loss = 1.38248445, grad/param norm = 1.9358e-01, time/batch = 18.0504s	
6992/25300 (epoch 13.818), train_loss = 1.17936609, grad/param norm = 1.8055e-01, time/batch = 15.8192s	
6993/25300 (epoch 13.820), train_loss = 1.15731254, grad/param norm = 1.8092e-01, time/batch = 16.9687s	
6994/25300 (epoch 13.822), train_loss = 1.08788764, grad/param norm = 1.6254e-01, time/batch = 18.5428s	
6995/25300 (epoch 13.824), train_loss = 1.17069800, grad/param norm = 1.8583e-01, time/batch = 18.5287s	
6996/25300 (epoch 13.826), train_loss = 1.02916406, grad/param norm = 1.7570e-01, time/batch = 16.9797s	
6997/25300 (epoch 13.828), train_loss = 1.03289326, grad/param norm = 1.7721e-01, time/batch = 18.9716s	
6998/25300 (epoch 13.830), train_loss = 1.09980429, grad/param norm = 1.6515e-01, time/batch = 18.6345s	
6999/25300 (epoch 13.832), train_loss = 1.15284004, grad/param norm = 1.8372e-01, time/batch = 16.6518s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch13.83_1.4808.t7	
7000/25300 (epoch 13.834), train_loss = 0.95787138, grad/param norm = 1.5390e-01, time/batch = 15.3264s	
7001/25300 (epoch 13.836), train_loss = 1.28449570, grad/param norm = 1.9400e-01, time/batch = 19.1373s	
7002/25300 (epoch 13.838), train_loss = 1.06930894, grad/param norm = 1.7070e-01, time/batch = 16.9600s	
7003/25300 (epoch 13.840), train_loss = 1.25236570, grad/param norm = 1.9335e-01, time/batch = 15.9683s	
7004/25300 (epoch 13.842), train_loss = 1.11247521, grad/param norm = 2.0909e-01, time/batch = 16.3088s	
7005/25300 (epoch 13.844), train_loss = 1.14583339, grad/param norm = 1.6982e-01, time/batch = 17.3963s	
7006/25300 (epoch 13.846), train_loss = 1.15659653, grad/param norm = 1.7534e-01, time/batch = 16.9007s	
7007/25300 (epoch 13.848), train_loss = 1.22572444, grad/param norm = 1.8895e-01, time/batch = 15.7279s	
7008/25300 (epoch 13.850), train_loss = 1.19271868, grad/param norm = 1.9526e-01, time/batch = 18.9815s	
7009/25300 (epoch 13.852), train_loss = 1.16451860, grad/param norm = 1.8608e-01, time/batch = 19.1244s	
7010/25300 (epoch 13.854), train_loss = 1.27629598, grad/param norm = 2.0394e-01, time/batch = 16.0511s	
7011/25300 (epoch 13.856), train_loss = 1.08468374, grad/param norm = 1.7868e-01, time/batch = 18.3969s	
7012/25300 (epoch 13.858), train_loss = 1.18023746, grad/param norm = 2.1936e-01, time/batch = 16.6397s	
7013/25300 (epoch 13.860), train_loss = 0.93558470, grad/param norm = 1.6594e-01, time/batch = 17.2298s	
7014/25300 (epoch 13.862), train_loss = 1.16416322, grad/param norm = 2.0811e-01, time/batch = 16.2986s	
7015/25300 (epoch 13.864), train_loss = 1.20360649, grad/param norm = 1.8365e-01, time/batch = 16.5434s	
7016/25300 (epoch 13.866), train_loss = 1.16360925, grad/param norm = 1.9553e-01, time/batch = 16.2233s	
7017/25300 (epoch 13.868), train_loss = 1.23949578, grad/param norm = 2.0647e-01, time/batch = 15.9034s	
7018/25300 (epoch 13.870), train_loss = 1.20294925, grad/param norm = 1.7007e-01, time/batch = 17.4738s	
7019/25300 (epoch 13.872), train_loss = 1.20984200, grad/param norm = 2.1195e-01, time/batch = 17.3141s	
7020/25300 (epoch 13.874), train_loss = 1.21439415, grad/param norm = 2.0089e-01, time/batch = 16.4673s	
7021/25300 (epoch 13.875), train_loss = 1.10425045, grad/param norm = 1.8361e-01, time/batch = 16.0675s	
7022/25300 (epoch 13.877), train_loss = 1.04905803, grad/param norm = 1.6885e-01, time/batch = 18.8078s	
7023/25300 (epoch 13.879), train_loss = 1.13495063, grad/param norm = 1.8394e-01, time/batch = 18.1514s	
7024/25300 (epoch 13.881), train_loss = 1.44491634, grad/param norm = 2.4253e-01, time/batch = 16.1473s	
7025/25300 (epoch 13.883), train_loss = 1.36957960, grad/param norm = 1.8659e-01, time/batch = 18.1416s	
7026/25300 (epoch 13.885), train_loss = 1.22803562, grad/param norm = 2.1752e-01, time/batch = 18.9927s	
7027/25300 (epoch 13.887), train_loss = 1.16180002, grad/param norm = 1.8382e-01, time/batch = 15.3184s	
7028/25300 (epoch 13.889), train_loss = 1.28344884, grad/param norm = 1.8103e-01, time/batch = 16.1515s	
7029/25300 (epoch 13.891), train_loss = 1.21600190, grad/param norm = 2.0516e-01, time/batch = 15.8823s	
7030/25300 (epoch 13.893), train_loss = 1.32854579, grad/param norm = 2.1989e-01, time/batch = 18.3917s	
7031/25300 (epoch 13.895), train_loss = 0.89840022, grad/param norm = 1.7986e-01, time/batch = 15.3883s	
7032/25300 (epoch 13.897), train_loss = 1.03534474, grad/param norm = 1.8560e-01, time/batch = 15.4302s	
7033/25300 (epoch 13.899), train_loss = 1.12727389, grad/param norm = 1.8934e-01, time/batch = 15.5559s	
7034/25300 (epoch 13.901), train_loss = 1.16454610, grad/param norm = 1.7917e-01, time/batch = 15.5517s	
7035/25300 (epoch 13.903), train_loss = 0.91721317, grad/param norm = 1.6116e-01, time/batch = 16.0361s	
7036/25300 (epoch 13.905), train_loss = 1.04811774, grad/param norm = 1.8314e-01, time/batch = 17.6292s	
7037/25300 (epoch 13.907), train_loss = 1.11649647, grad/param norm = 2.0124e-01, time/batch = 17.5581s	
7038/25300 (epoch 13.909), train_loss = 1.21872103, grad/param norm = 1.7997e-01, time/batch = 15.9633s	
7039/25300 (epoch 13.911), train_loss = 1.34760653, grad/param norm = 2.0205e-01, time/batch = 17.2293s	
7040/25300 (epoch 13.913), train_loss = 1.36430966, grad/param norm = 2.1551e-01, time/batch = 16.7302s	
7041/25300 (epoch 13.915), train_loss = 1.07202387, grad/param norm = 1.9257e-01, time/batch = 16.0367s	
7042/25300 (epoch 13.917), train_loss = 1.18891428, grad/param norm = 1.9366e-01, time/batch = 15.8879s	
7043/25300 (epoch 13.919), train_loss = 1.31195461, grad/param norm = 2.0669e-01, time/batch = 15.9786s	
7044/25300 (epoch 13.921), train_loss = 1.03711648, grad/param norm = 1.8131e-01, time/batch = 17.2192s	
7045/25300 (epoch 13.923), train_loss = 1.28952886, grad/param norm = 1.8851e-01, time/batch = 17.4558s	
7046/25300 (epoch 13.925), train_loss = 1.11103853, grad/param norm = 1.9223e-01, time/batch = 15.3054s	
7047/25300 (epoch 13.927), train_loss = 1.10495160, grad/param norm = 1.8647e-01, time/batch = 15.7522s	
7048/25300 (epoch 13.929), train_loss = 1.07638815, grad/param norm = 1.7701e-01, time/batch = 18.6299s	
7049/25300 (epoch 13.931), train_loss = 1.24820533, grad/param norm = 2.1576e-01, time/batch = 16.7214s	
7050/25300 (epoch 13.933), train_loss = 1.20837548, grad/param norm = 1.8531e-01, time/batch = 15.9940s	
7051/25300 (epoch 13.935), train_loss = 1.17051227, grad/param norm = 1.7615e-01, time/batch = 17.7892s	
7052/25300 (epoch 13.937), train_loss = 0.87357393, grad/param norm = 1.5229e-01, time/batch = 18.2209s	
7053/25300 (epoch 13.939), train_loss = 1.22940126, grad/param norm = 1.8008e-01, time/batch = 16.2101s	
7054/25300 (epoch 13.941), train_loss = 1.09061139, grad/param norm = 1.7342e-01, time/batch = 16.7078s	
7055/25300 (epoch 13.943), train_loss = 1.11853716, grad/param norm = 1.8213e-01, time/batch = 15.9667s	
7056/25300 (epoch 13.945), train_loss = 1.18339366, grad/param norm = 1.8488e-01, time/batch = 15.7284s	
7057/25300 (epoch 13.947), train_loss = 1.03228909, grad/param norm = 1.7324e-01, time/batch = 16.5657s	
7058/25300 (epoch 13.949), train_loss = 1.20178867, grad/param norm = 1.8623e-01, time/batch = 16.4470s	
7059/25300 (epoch 13.951), train_loss = 1.11336583, grad/param norm = 1.7326e-01, time/batch = 17.8875s	
7060/25300 (epoch 13.953), train_loss = 1.17393550, grad/param norm = 1.6571e-01, time/batch = 15.7079s	
7061/25300 (epoch 13.955), train_loss = 1.40131859, grad/param norm = 2.1805e-01, time/batch = 17.7867s	
7062/25300 (epoch 13.957), train_loss = 1.34347037, grad/param norm = 2.2756e-01, time/batch = 18.3715s	
7063/25300 (epoch 13.958), train_loss = 1.19997437, grad/param norm = 1.9132e-01, time/batch = 17.2806s	
7064/25300 (epoch 13.960), train_loss = 1.35548705, grad/param norm = 2.1503e-01, time/batch = 17.1453s	
7065/25300 (epoch 13.962), train_loss = 1.31459720, grad/param norm = 2.1447e-01, time/batch = 16.6415s	
7066/25300 (epoch 13.964), train_loss = 1.21784148, grad/param norm = 1.7623e-01, time/batch = 18.3891s	
7067/25300 (epoch 13.966), train_loss = 0.97471429, grad/param norm = 1.6082e-01, time/batch = 16.2079s	
7068/25300 (epoch 13.968), train_loss = 0.96784343, grad/param norm = 1.6840e-01, time/batch = 18.3838s	
7069/25300 (epoch 13.970), train_loss = 1.12577100, grad/param norm = 2.2090e-01, time/batch = 18.3088s	
7070/25300 (epoch 13.972), train_loss = 1.14865095, grad/param norm = 1.9231e-01, time/batch = 16.8044s	
7071/25300 (epoch 13.974), train_loss = 1.34002264, grad/param norm = 2.1695e-01, time/batch = 16.6065s	
7072/25300 (epoch 13.976), train_loss = 1.18117360, grad/param norm = 2.0219e-01, time/batch = 16.9049s	
7073/25300 (epoch 13.978), train_loss = 1.17534474, grad/param norm = 1.8492e-01, time/batch = 18.0608s	
7074/25300 (epoch 13.980), train_loss = 1.18437043, grad/param norm = 1.9462e-01, time/batch = 15.8789s	
7075/25300 (epoch 13.982), train_loss = 1.08062250, grad/param norm = 1.7448e-01, time/batch = 19.1376s	
7076/25300 (epoch 13.984), train_loss = 1.13011477, grad/param norm = 2.0493e-01, time/batch = 17.8045s	
7077/25300 (epoch 13.986), train_loss = 1.21181676, grad/param norm = 1.9985e-01, time/batch = 16.2983s	
7078/25300 (epoch 13.988), train_loss = 1.23165755, grad/param norm = 2.0045e-01, time/batch = 18.0509s	
7079/25300 (epoch 13.990), train_loss = 1.13075927, grad/param norm = 1.7209e-01, time/batch = 18.8014s	
7080/25300 (epoch 13.992), train_loss = 0.92473406, grad/param norm = 1.7158e-01, time/batch = 18.3644s	
7081/25300 (epoch 13.994), train_loss = 1.15718190, grad/param norm = 1.8281e-01, time/batch = 17.1386s	
7082/25300 (epoch 13.996), train_loss = 1.27744520, grad/param norm = 2.0978e-01, time/batch = 16.2393s	
7083/25300 (epoch 13.998), train_loss = 1.26211261, grad/param norm = 1.9125e-01, time/batch = 16.9060s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
7084/25300 (epoch 14.000), train_loss = 1.15591836, grad/param norm = 1.9884e-01, time/batch = 16.4757s	
7085/25300 (epoch 14.002), train_loss = 0.97258661, grad/param norm = 1.8250e-01, time/batch = 18.6194s	
7086/25300 (epoch 14.004), train_loss = 0.96196505, grad/param norm = 1.6910e-01, time/batch = 15.8348s	
7087/25300 (epoch 14.006), train_loss = 1.24444759, grad/param norm = 1.7861e-01, time/batch = 16.9744s	
7088/25300 (epoch 14.008), train_loss = 1.11003695, grad/param norm = 1.6743e-01, time/batch = 15.2953s	
7089/25300 (epoch 14.010), train_loss = 1.12837460, grad/param norm = 1.6541e-01, time/batch = 15.3859s	
7090/25300 (epoch 14.012), train_loss = 1.04162735, grad/param norm = 1.9710e-01, time/batch = 17.2385s	
7091/25300 (epoch 14.014), train_loss = 1.24202220, grad/param norm = 1.9899e-01, time/batch = 16.9808s	
7092/25300 (epoch 14.016), train_loss = 1.17141772, grad/param norm = 2.0096e-01, time/batch = 18.0424s	
7093/25300 (epoch 14.018), train_loss = 1.03700440, grad/param norm = 1.7611e-01, time/batch = 17.8031s	
7094/25300 (epoch 14.020), train_loss = 1.08078926, grad/param norm = 1.7580e-01, time/batch = 18.0398s	
7095/25300 (epoch 14.022), train_loss = 1.15790632, grad/param norm = 2.0036e-01, time/batch = 19.0322s	
7096/25300 (epoch 14.024), train_loss = 0.84152408, grad/param norm = 1.4747e-01, time/batch = 18.1356s	
7097/25300 (epoch 14.026), train_loss = 1.05765924, grad/param norm = 1.9899e-01, time/batch = 17.8934s	
7098/25300 (epoch 14.028), train_loss = 0.98432217, grad/param norm = 1.5303e-01, time/batch = 16.2124s	
7099/25300 (epoch 14.030), train_loss = 1.21692491, grad/param norm = 1.7077e-01, time/batch = 17.8143s	
7100/25300 (epoch 14.032), train_loss = 1.04658697, grad/param norm = 1.7179e-01, time/batch = 17.2073s	
7101/25300 (epoch 14.034), train_loss = 0.90446729, grad/param norm = 1.7094e-01, time/batch = 16.7090s	
7102/25300 (epoch 14.036), train_loss = 0.93180519, grad/param norm = 1.5740e-01, time/batch = 19.1942s	
7103/25300 (epoch 14.038), train_loss = 0.83812799, grad/param norm = 1.4378e-01, time/batch = 16.8732s	
7104/25300 (epoch 14.040), train_loss = 1.16479533, grad/param norm = 1.8660e-01, time/batch = 18.0536s	
7105/25300 (epoch 14.042), train_loss = 1.03606022, grad/param norm = 1.6872e-01, time/batch = 17.5525s	
7106/25300 (epoch 14.043), train_loss = 0.90350972, grad/param norm = 1.4927e-01, time/batch = 16.5646s	
7107/25300 (epoch 14.045), train_loss = 0.94878203, grad/param norm = 1.6502e-01, time/batch = 18.0555s	
7108/25300 (epoch 14.047), train_loss = 1.13272180, grad/param norm = 1.6669e-01, time/batch = 15.8941s	
7109/25300 (epoch 14.049), train_loss = 1.14282455, grad/param norm = 1.9787e-01, time/batch = 15.8094s	
7110/25300 (epoch 14.051), train_loss = 1.20984483, grad/param norm = 2.0364e-01, time/batch = 18.4823s	
7111/25300 (epoch 14.053), train_loss = 0.89097365, grad/param norm = 1.5594e-01, time/batch = 17.3892s	
7112/25300 (epoch 14.055), train_loss = 0.96199028, grad/param norm = 1.5237e-01, time/batch = 16.8898s	
7113/25300 (epoch 14.057), train_loss = 0.91181889, grad/param norm = 1.5341e-01, time/batch = 16.7301s	
7114/25300 (epoch 14.059), train_loss = 1.07060190, grad/param norm = 1.8174e-01, time/batch = 18.8065s	
7115/25300 (epoch 14.061), train_loss = 0.99548131, grad/param norm = 1.6390e-01, time/batch = 15.8882s	
7116/25300 (epoch 14.063), train_loss = 0.97314183, grad/param norm = 1.7424e-01, time/batch = 16.3038s	
7117/25300 (epoch 14.065), train_loss = 1.20761319, grad/param norm = 1.9402e-01, time/batch = 17.5591s	
7118/25300 (epoch 14.067), train_loss = 1.20994881, grad/param norm = 1.7759e-01, time/batch = 17.3984s	
7119/25300 (epoch 14.069), train_loss = 1.07477693, grad/param norm = 1.8859e-01, time/batch = 16.1470s	
7120/25300 (epoch 14.071), train_loss = 1.23209672, grad/param norm = 1.8222e-01, time/batch = 16.1298s	
7121/25300 (epoch 14.073), train_loss = 1.04731183, grad/param norm = 1.5861e-01, time/batch = 19.8728s	
7122/25300 (epoch 14.075), train_loss = 1.14599933, grad/param norm = 1.7886e-01, time/batch = 16.1447s	
7123/25300 (epoch 14.077), train_loss = 1.13690036, grad/param norm = 1.7614e-01, time/batch = 18.2201s	
7124/25300 (epoch 14.079), train_loss = 1.08490197, grad/param norm = 1.6830e-01, time/batch = 18.2257s	
7125/25300 (epoch 14.081), train_loss = 1.06276516, grad/param norm = 1.5696e-01, time/batch = 17.4590s	
7126/25300 (epoch 14.083), train_loss = 1.07203401, grad/param norm = 1.7269e-01, time/batch = 18.0524s	
7127/25300 (epoch 14.085), train_loss = 1.33003382, grad/param norm = 2.0126e-01, time/batch = 16.6182s	
7128/25300 (epoch 14.087), train_loss = 1.14380075, grad/param norm = 1.8330e-01, time/batch = 17.3096s	
7129/25300 (epoch 14.089), train_loss = 1.15648124, grad/param norm = 1.7767e-01, time/batch = 18.5409s	
7130/25300 (epoch 14.091), train_loss = 1.28254314, grad/param norm = 1.8643e-01, time/batch = 37.5114s	
7131/25300 (epoch 14.093), train_loss = 1.23866783, grad/param norm = 1.9071e-01, time/batch = 31.8638s	
7132/25300 (epoch 14.095), train_loss = 1.18524165, grad/param norm = 1.7393e-01, time/batch = 36.6440s	
7133/25300 (epoch 14.097), train_loss = 1.12466703, grad/param norm = 1.7414e-01, time/batch = 37.8120s	
7134/25300 (epoch 14.099), train_loss = 1.17073350, grad/param norm = 1.9450e-01, time/batch = 32.9416s	
7135/25300 (epoch 14.101), train_loss = 1.10680895, grad/param norm = 1.7651e-01, time/batch = 38.5235s	
7136/25300 (epoch 14.103), train_loss = 1.08687496, grad/param norm = 1.7872e-01, time/batch = 34.2590s	
7137/25300 (epoch 14.105), train_loss = 1.14437874, grad/param norm = 1.8068e-01, time/batch = 37.6547s	
7138/25300 (epoch 14.107), train_loss = 1.19615451, grad/param norm = 1.9016e-01, time/batch = 37.4296s	
7139/25300 (epoch 14.109), train_loss = 1.09872348, grad/param norm = 1.8330e-01, time/batch = 31.7890s	
7140/25300 (epoch 14.111), train_loss = 1.08448180, grad/param norm = 1.7011e-01, time/batch = 16.4805s	
7141/25300 (epoch 14.113), train_loss = 1.10140827, grad/param norm = 2.0632e-01, time/batch = 16.9017s	
7142/25300 (epoch 14.115), train_loss = 1.10566986, grad/param norm = 1.8383e-01, time/batch = 17.3885s	
7143/25300 (epoch 14.117), train_loss = 1.17210866, grad/param norm = 1.6832e-01, time/batch = 16.3177s	
7144/25300 (epoch 14.119), train_loss = 1.07417082, grad/param norm = 1.7302e-01, time/batch = 17.7240s	
7145/25300 (epoch 14.121), train_loss = 1.16412193, grad/param norm = 2.0322e-01, time/batch = 17.6233s	
7146/25300 (epoch 14.123), train_loss = 1.10887960, grad/param norm = 1.9794e-01, time/batch = 15.8913s	
7147/25300 (epoch 14.125), train_loss = 1.20535707, grad/param norm = 1.9584e-01, time/batch = 19.7832s	
7148/25300 (epoch 14.126), train_loss = 1.12403806, grad/param norm = 1.8752e-01, time/batch = 17.5466s	
7149/25300 (epoch 14.128), train_loss = 1.13261457, grad/param norm = 1.8916e-01, time/batch = 18.1219s	
7150/25300 (epoch 14.130), train_loss = 0.89632217, grad/param norm = 1.5942e-01, time/batch = 17.2330s	
7151/25300 (epoch 14.132), train_loss = 0.95702073, grad/param norm = 1.5899e-01, time/batch = 17.1322s	
7152/25300 (epoch 14.134), train_loss = 0.88686012, grad/param norm = 1.5311e-01, time/batch = 17.6285s	
7153/25300 (epoch 14.136), train_loss = 1.12944289, grad/param norm = 1.7455e-01, time/batch = 17.8957s	
7154/25300 (epoch 14.138), train_loss = 0.97264178, grad/param norm = 1.6044e-01, time/batch = 19.0484s	
7155/25300 (epoch 14.140), train_loss = 1.04140443, grad/param norm = 1.6794e-01, time/batch = 17.6448s	
7156/25300 (epoch 14.142), train_loss = 1.19860868, grad/param norm = 1.7570e-01, time/batch = 17.0423s	
7157/25300 (epoch 14.144), train_loss = 1.15062796, grad/param norm = 1.8712e-01, time/batch = 18.3839s	
7158/25300 (epoch 14.146), train_loss = 1.20738190, grad/param norm = 2.0151e-01, time/batch = 18.1291s	
7159/25300 (epoch 14.148), train_loss = 1.08267735, grad/param norm = 1.7563e-01, time/batch = 16.1355s	
7160/25300 (epoch 14.150), train_loss = 1.22934508, grad/param norm = 2.3112e-01, time/batch = 16.8945s	
7161/25300 (epoch 14.152), train_loss = 1.30904201, grad/param norm = 1.9363e-01, time/batch = 17.2135s	
7162/25300 (epoch 14.154), train_loss = 0.99818298, grad/param norm = 1.7200e-01, time/batch = 19.4522s	
7163/25300 (epoch 14.156), train_loss = 1.15805322, grad/param norm = 1.8579e-01, time/batch = 17.7964s	
7164/25300 (epoch 14.158), train_loss = 1.00482693, grad/param norm = 1.5870e-01, time/batch = 18.6247s	
7165/25300 (epoch 14.160), train_loss = 1.12132312, grad/param norm = 1.7688e-01, time/batch = 18.7920s	
7166/25300 (epoch 14.162), train_loss = 1.03762732, grad/param norm = 1.8166e-01, time/batch = 16.3874s	
7167/25300 (epoch 14.164), train_loss = 1.20205865, grad/param norm = 1.8294e-01, time/batch = 17.3076s	
7168/25300 (epoch 14.166), train_loss = 1.13103729, grad/param norm = 1.7076e-01, time/batch = 17.8822s	
7169/25300 (epoch 14.168), train_loss = 0.97226711, grad/param norm = 1.5716e-01, time/batch = 16.4754s	
7170/25300 (epoch 14.170), train_loss = 1.06412788, grad/param norm = 1.6752e-01, time/batch = 17.6423s	
7171/25300 (epoch 14.172), train_loss = 0.99365013, grad/param norm = 1.6274e-01, time/batch = 15.8903s	
7172/25300 (epoch 14.174), train_loss = 0.97374500, grad/param norm = 1.6439e-01, time/batch = 18.9555s	
7173/25300 (epoch 14.176), train_loss = 1.05750831, grad/param norm = 1.7923e-01, time/batch = 26.1660s	
7174/25300 (epoch 14.178), train_loss = 1.25357469, grad/param norm = 1.9474e-01, time/batch = 20.7532s	
7175/25300 (epoch 14.180), train_loss = 0.91932475, grad/param norm = 1.6611e-01, time/batch = 17.2891s	
7176/25300 (epoch 14.182), train_loss = 1.03187525, grad/param norm = 1.6679e-01, time/batch = 15.3530s	
7177/25300 (epoch 14.184), train_loss = 1.08250760, grad/param norm = 1.9445e-01, time/batch = 15.5052s	
7178/25300 (epoch 14.186), train_loss = 1.03439492, grad/param norm = 1.8117e-01, time/batch = 15.0458s	
7179/25300 (epoch 14.188), train_loss = 1.09289895, grad/param norm = 1.7436e-01, time/batch = 15.2804s	
7180/25300 (epoch 14.190), train_loss = 1.10579638, grad/param norm = 1.8503e-01, time/batch = 15.2953s	
7181/25300 (epoch 14.192), train_loss = 1.05257955, grad/param norm = 1.8072e-01, time/batch = 16.1182s	
7182/25300 (epoch 14.194), train_loss = 1.07300742, grad/param norm = 1.6639e-01, time/batch = 19.3565s	
7183/25300 (epoch 14.196), train_loss = 1.17761312, grad/param norm = 2.0536e-01, time/batch = 16.8862s	
7184/25300 (epoch 14.198), train_loss = 1.03758997, grad/param norm = 1.8766e-01, time/batch = 17.9571s	
7185/25300 (epoch 14.200), train_loss = 1.09819425, grad/param norm = 2.0136e-01, time/batch = 16.2831s	
7186/25300 (epoch 14.202), train_loss = 1.09431814, grad/param norm = 1.8441e-01, time/batch = 17.4709s	
7187/25300 (epoch 14.204), train_loss = 1.04696504, grad/param norm = 1.7427e-01, time/batch = 15.8927s	
7188/25300 (epoch 14.206), train_loss = 1.17350952, grad/param norm = 1.8087e-01, time/batch = 17.6433s	
7189/25300 (epoch 14.208), train_loss = 0.99794096, grad/param norm = 1.9415e-01, time/batch = 16.7289s	
7190/25300 (epoch 14.209), train_loss = 0.91709887, grad/param norm = 1.6575e-01, time/batch = 16.4612s	
7191/25300 (epoch 14.211), train_loss = 1.07313412, grad/param norm = 1.7861e-01, time/batch = 17.0307s	
7192/25300 (epoch 14.213), train_loss = 1.15440310, grad/param norm = 1.8003e-01, time/batch = 16.2044s	
7193/25300 (epoch 14.215), train_loss = 1.12191139, grad/param norm = 1.7810e-01, time/batch = 17.4659s	
7194/25300 (epoch 14.217), train_loss = 1.14856978, grad/param norm = 2.2393e-01, time/batch = 15.5709s	
7195/25300 (epoch 14.219), train_loss = 1.19806432, grad/param norm = 1.9718e-01, time/batch = 17.6190s	
7196/25300 (epoch 14.221), train_loss = 1.21899956, grad/param norm = 1.8365e-01, time/batch = 16.4782s	
7197/25300 (epoch 14.223), train_loss = 1.16794913, grad/param norm = 2.0343e-01, time/batch = 16.7168s	
7198/25300 (epoch 14.225), train_loss = 1.59057639, grad/param norm = 2.3376e-01, time/batch = 15.6601s	
7199/25300 (epoch 14.227), train_loss = 1.22271437, grad/param norm = 1.9280e-01, time/batch = 15.4084s	
7200/25300 (epoch 14.229), train_loss = 1.11458568, grad/param norm = 1.8504e-01, time/batch = 16.6561s	
7201/25300 (epoch 14.231), train_loss = 1.08019187, grad/param norm = 1.6901e-01, time/batch = 15.8872s	
7202/25300 (epoch 14.233), train_loss = 1.17563442, grad/param norm = 1.9330e-01, time/batch = 17.8885s	
7203/25300 (epoch 14.235), train_loss = 1.09649501, grad/param norm = 1.6549e-01, time/batch = 16.4685s	
7204/25300 (epoch 14.237), train_loss = 1.29008351, grad/param norm = 2.0841e-01, time/batch = 15.6089s	
7205/25300 (epoch 14.239), train_loss = 1.13661728, grad/param norm = 1.9191e-01, time/batch = 15.5679s	
7206/25300 (epoch 14.241), train_loss = 1.22859318, grad/param norm = 1.8521e-01, time/batch = 19.2200s	
7207/25300 (epoch 14.243), train_loss = 1.44294360, grad/param norm = 2.0612e-01, time/batch = 17.8915s	
7208/25300 (epoch 14.245), train_loss = 1.04068768, grad/param norm = 1.9025e-01, time/batch = 15.7084s	
7209/25300 (epoch 14.247), train_loss = 1.20237410, grad/param norm = 1.8568e-01, time/batch = 17.0624s	
7210/25300 (epoch 14.249), train_loss = 0.98527869, grad/param norm = 1.5745e-01, time/batch = 17.3012s	
7211/25300 (epoch 14.251), train_loss = 0.93585216, grad/param norm = 1.7366e-01, time/batch = 17.8746s	
7212/25300 (epoch 14.253), train_loss = 1.10058698, grad/param norm = 1.8910e-01, time/batch = 17.6976s	
7213/25300 (epoch 14.255), train_loss = 1.04544745, grad/param norm = 1.9433e-01, time/batch = 19.6180s	
7214/25300 (epoch 14.257), train_loss = 1.14303484, grad/param norm = 1.8465e-01, time/batch = 17.2900s	
7215/25300 (epoch 14.259), train_loss = 1.34112411, grad/param norm = 2.0023e-01, time/batch = 18.0379s	
7216/25300 (epoch 14.261), train_loss = 1.28123999, grad/param norm = 1.9898e-01, time/batch = 16.9731s	
7217/25300 (epoch 14.263), train_loss = 1.24496577, grad/param norm = 1.8012e-01, time/batch = 18.7066s	
7218/25300 (epoch 14.265), train_loss = 1.33250393, grad/param norm = 1.8077e-01, time/batch = 15.7237s	
7219/25300 (epoch 14.267), train_loss = 1.22461118, grad/param norm = 1.8842e-01, time/batch = 16.2207s	
7220/25300 (epoch 14.269), train_loss = 0.94589597, grad/param norm = 1.5574e-01, time/batch = 17.5606s	
7221/25300 (epoch 14.271), train_loss = 1.07637775, grad/param norm = 1.8436e-01, time/batch = 16.9676s	
7222/25300 (epoch 14.273), train_loss = 1.18903887, grad/param norm = 2.0429e-01, time/batch = 16.8570s	
7223/25300 (epoch 14.275), train_loss = 1.03444545, grad/param norm = 1.5903e-01, time/batch = 17.6417s	
7224/25300 (epoch 14.277), train_loss = 1.07801705, grad/param norm = 1.8096e-01, time/batch = 18.0532s	
7225/25300 (epoch 14.279), train_loss = 1.08529865, grad/param norm = 1.6594e-01, time/batch = 16.5445s	
7226/25300 (epoch 14.281), train_loss = 1.26385436, grad/param norm = 1.8930e-01, time/batch = 16.3695s	
7227/25300 (epoch 14.283), train_loss = 0.99126162, grad/param norm = 1.6788e-01, time/batch = 16.7272s	
7228/25300 (epoch 14.285), train_loss = 1.15108724, grad/param norm = 2.0100e-01, time/batch = 18.0441s	
7229/25300 (epoch 14.287), train_loss = 1.14296827, grad/param norm = 1.7168e-01, time/batch = 16.2444s	
7230/25300 (epoch 14.289), train_loss = 1.05310414, grad/param norm = 1.7160e-01, time/batch = 18.2227s	
7231/25300 (epoch 14.291), train_loss = 1.07085619, grad/param norm = 1.7774e-01, time/batch = 20.1292s	
7232/25300 (epoch 14.292), train_loss = 1.26094587, grad/param norm = 1.8092e-01, time/batch = 16.9775s	
7233/25300 (epoch 14.294), train_loss = 1.14007360, grad/param norm = 1.8299e-01, time/batch = 16.9688s	
7234/25300 (epoch 14.296), train_loss = 0.98642800, grad/param norm = 1.7820e-01, time/batch = 19.3079s	
7235/25300 (epoch 14.298), train_loss = 1.21742099, grad/param norm = 1.8775e-01, time/batch = 17.3810s	
7236/25300 (epoch 14.300), train_loss = 1.23818961, grad/param norm = 1.9466e-01, time/batch = 17.8744s	
7237/25300 (epoch 14.302), train_loss = 0.92234452, grad/param norm = 1.8496e-01, time/batch = 18.2271s	
7238/25300 (epoch 14.304), train_loss = 1.16786948, grad/param norm = 1.8618e-01, time/batch = 17.2940s	
7239/25300 (epoch 14.306), train_loss = 0.87420097, grad/param norm = 1.5971e-01, time/batch = 18.3560s	
7240/25300 (epoch 14.308), train_loss = 1.16347644, grad/param norm = 1.6432e-01, time/batch = 17.6411s	
7241/25300 (epoch 14.310), train_loss = 1.02377032, grad/param norm = 1.7918e-01, time/batch = 19.2234s	
7242/25300 (epoch 14.312), train_loss = 1.09575694, grad/param norm = 1.5968e-01, time/batch = 16.0326s	
7243/25300 (epoch 14.314), train_loss = 0.91198803, grad/param norm = 1.7514e-01, time/batch = 18.6207s	
7244/25300 (epoch 14.316), train_loss = 1.14371192, grad/param norm = 1.7962e-01, time/batch = 16.3638s	
7245/25300 (epoch 14.318), train_loss = 0.87191743, grad/param norm = 1.6131e-01, time/batch = 17.8840s	
7246/25300 (epoch 14.320), train_loss = 0.96715934, grad/param norm = 1.6413e-01, time/batch = 16.2261s	
7247/25300 (epoch 14.322), train_loss = 1.34511851, grad/param norm = 2.0950e-01, time/batch = 16.3920s	
7248/25300 (epoch 14.324), train_loss = 0.99283978, grad/param norm = 1.6341e-01, time/batch = 18.4036s	
7249/25300 (epoch 14.326), train_loss = 0.87529527, grad/param norm = 1.5485e-01, time/batch = 16.3930s	
7250/25300 (epoch 14.328), train_loss = 0.89287280, grad/param norm = 1.6733e-01, time/batch = 17.6526s	
7251/25300 (epoch 14.330), train_loss = 1.06910588, grad/param norm = 1.8209e-01, time/batch = 17.3903s	
7252/25300 (epoch 14.332), train_loss = 1.09949759, grad/param norm = 1.5361e-01, time/batch = 16.8089s	
7253/25300 (epoch 14.334), train_loss = 0.91545223, grad/param norm = 1.5107e-01, time/batch = 16.2820s	
7254/25300 (epoch 14.336), train_loss = 0.93555862, grad/param norm = 1.7087e-01, time/batch = 19.2301s	
7255/25300 (epoch 14.338), train_loss = 0.92156482, grad/param norm = 1.6807e-01, time/batch = 18.4607s	
7256/25300 (epoch 14.340), train_loss = 1.04723630, grad/param norm = 1.9830e-01, time/batch = 15.5176s	
7257/25300 (epoch 14.342), train_loss = 1.05371820, grad/param norm = 1.8128e-01, time/batch = 16.8194s	
7258/25300 (epoch 14.344), train_loss = 1.08959841, grad/param norm = 1.7324e-01, time/batch = 18.3975s	
7259/25300 (epoch 14.346), train_loss = 1.07262063, grad/param norm = 1.8933e-01, time/batch = 16.4692s	
7260/25300 (epoch 14.348), train_loss = 0.96906887, grad/param norm = 1.6197e-01, time/batch = 17.8890s	
7261/25300 (epoch 14.350), train_loss = 1.03356501, grad/param norm = 1.7281e-01, time/batch = 15.8295s	
7262/25300 (epoch 14.352), train_loss = 1.08047199, grad/param norm = 1.7046e-01, time/batch = 18.6282s	
7263/25300 (epoch 14.354), train_loss = 1.01302871, grad/param norm = 1.7132e-01, time/batch = 16.0467s	
7264/25300 (epoch 14.356), train_loss = 1.08827416, grad/param norm = 1.8578e-01, time/batch = 18.7206s	
7265/25300 (epoch 14.358), train_loss = 1.21434310, grad/param norm = 2.0433e-01, time/batch = 16.6401s	
7266/25300 (epoch 14.360), train_loss = 0.98789709, grad/param norm = 1.7003e-01, time/batch = 17.1271s	
7267/25300 (epoch 14.362), train_loss = 1.01637809, grad/param norm = 1.7609e-01, time/batch = 19.0390s	
7268/25300 (epoch 14.364), train_loss = 1.11107847, grad/param norm = 1.8313e-01, time/batch = 17.6453s	
7269/25300 (epoch 14.366), train_loss = 0.94557010, grad/param norm = 1.6928e-01, time/batch = 18.9533s	
7270/25300 (epoch 14.368), train_loss = 1.03540414, grad/param norm = 1.6388e-01, time/batch = 16.9020s	
7271/25300 (epoch 14.370), train_loss = 1.03591146, grad/param norm = 1.8677e-01, time/batch = 18.3961s	
7272/25300 (epoch 14.372), train_loss = 1.01730802, grad/param norm = 1.6920e-01, time/batch = 19.0435s	
7273/25300 (epoch 14.374), train_loss = 0.95128696, grad/param norm = 1.6558e-01, time/batch = 16.2183s	
7274/25300 (epoch 14.375), train_loss = 1.24991735, grad/param norm = 2.0702e-01, time/batch = 17.8921s	
7275/25300 (epoch 14.377), train_loss = 1.12412884, grad/param norm = 2.0317e-01, time/batch = 19.7950s	
7276/25300 (epoch 14.379), train_loss = 1.14477962, grad/param norm = 1.9352e-01, time/batch = 15.7966s	
7277/25300 (epoch 14.381), train_loss = 1.09916319, grad/param norm = 1.7319e-01, time/batch = 16.9075s	
7278/25300 (epoch 14.383), train_loss = 0.99047467, grad/param norm = 1.7221e-01, time/batch = 15.8134s	
7279/25300 (epoch 14.385), train_loss = 1.06096206, grad/param norm = 1.7786e-01, time/batch = 16.2071s	
7280/25300 (epoch 14.387), train_loss = 1.11141292, grad/param norm = 1.7480e-01, time/batch = 17.0529s	
7281/25300 (epoch 14.389), train_loss = 1.18707453, grad/param norm = 1.9987e-01, time/batch = 19.0428s	
7282/25300 (epoch 14.391), train_loss = 0.99902011, grad/param norm = 1.5887e-01, time/batch = 20.3682s	
7283/25300 (epoch 14.393), train_loss = 1.10393720, grad/param norm = 1.8042e-01, time/batch = 17.2959s	
7284/25300 (epoch 14.395), train_loss = 0.94441844, grad/param norm = 1.6206e-01, time/batch = 18.3063s	
7285/25300 (epoch 14.397), train_loss = 0.95869921, grad/param norm = 1.7602e-01, time/batch = 19.4007s	
7286/25300 (epoch 14.399), train_loss = 0.95009025, grad/param norm = 1.7576e-01, time/batch = 16.5551s	
7287/25300 (epoch 14.401), train_loss = 1.20867504, grad/param norm = 2.0823e-01, time/batch = 17.7432s	
7288/25300 (epoch 14.403), train_loss = 1.08626501, grad/param norm = 1.9395e-01, time/batch = 17.2231s	
7289/25300 (epoch 14.405), train_loss = 1.11268637, grad/param norm = 2.0304e-01, time/batch = 15.7293s	
7290/25300 (epoch 14.407), train_loss = 1.01525802, grad/param norm = 1.6622e-01, time/batch = 15.7701s	
7291/25300 (epoch 14.409), train_loss = 0.98912828, grad/param norm = 1.6043e-01, time/batch = 18.3118s	
7292/25300 (epoch 14.411), train_loss = 1.01807471, grad/param norm = 1.7721e-01, time/batch = 19.4675s	
7293/25300 (epoch 14.413), train_loss = 0.95046559, grad/param norm = 1.8462e-01, time/batch = 16.2990s	
7294/25300 (epoch 14.415), train_loss = 0.94223359, grad/param norm = 1.7770e-01, time/batch = 18.6414s	
7295/25300 (epoch 14.417), train_loss = 0.91338722, grad/param norm = 1.6490e-01, time/batch = 19.7973s	
7296/25300 (epoch 14.419), train_loss = 0.88835200, grad/param norm = 1.5964e-01, time/batch = 16.0375s	
7297/25300 (epoch 14.421), train_loss = 0.89882049, grad/param norm = 1.4788e-01, time/batch = 17.5599s	
7298/25300 (epoch 14.423), train_loss = 0.95052812, grad/param norm = 1.6867e-01, time/batch = 17.6457s	
7299/25300 (epoch 14.425), train_loss = 1.04449517, grad/param norm = 1.8839e-01, time/batch = 19.4654s	
7300/25300 (epoch 14.427), train_loss = 1.26575226, grad/param norm = 2.0013e-01, time/batch = 16.2222s	
7301/25300 (epoch 14.429), train_loss = 1.17975885, grad/param norm = 1.7915e-01, time/batch = 18.3046s	
7302/25300 (epoch 14.431), train_loss = 1.09588528, grad/param norm = 1.8183e-01, time/batch = 16.5600s	
7303/25300 (epoch 14.433), train_loss = 1.02325472, grad/param norm = 1.6986e-01, time/batch = 17.1387s	
7304/25300 (epoch 14.435), train_loss = 0.97824972, grad/param norm = 1.7932e-01, time/batch = 17.5588s	
7305/25300 (epoch 14.437), train_loss = 1.01587517, grad/param norm = 1.8008e-01, time/batch = 18.6299s	
7306/25300 (epoch 14.439), train_loss = 1.07884875, grad/param norm = 1.7189e-01, time/batch = 17.7996s	
7307/25300 (epoch 14.441), train_loss = 1.10293712, grad/param norm = 1.9203e-01, time/batch = 17.4584s	
7308/25300 (epoch 14.443), train_loss = 1.32346942, grad/param norm = 2.2115e-01, time/batch = 19.5512s	
7309/25300 (epoch 14.445), train_loss = 1.25383283, grad/param norm = 2.0872e-01, time/batch = 18.0621s	
7310/25300 (epoch 14.447), train_loss = 0.97553055, grad/param norm = 1.6257e-01, time/batch = 15.9658s	
7311/25300 (epoch 14.449), train_loss = 0.89490320, grad/param norm = 1.8371e-01, time/batch = 17.4144s	
7312/25300 (epoch 14.451), train_loss = 1.26153876, grad/param norm = 1.9584e-01, time/batch = 16.1370s	
7313/25300 (epoch 14.453), train_loss = 1.16091129, grad/param norm = 1.8952e-01, time/batch = 16.2094s	
7314/25300 (epoch 14.455), train_loss = 1.18579227, grad/param norm = 1.9232e-01, time/batch = 17.1174s	
7315/25300 (epoch 14.457), train_loss = 1.03829105, grad/param norm = 1.7873e-01, time/batch = 16.2129s	
7316/25300 (epoch 14.458), train_loss = 1.11306700, grad/param norm = 2.1143e-01, time/batch = 19.7954s	
7317/25300 (epoch 14.460), train_loss = 1.10736414, grad/param norm = 1.9871e-01, time/batch = 15.8928s	
7318/25300 (epoch 14.462), train_loss = 0.85780624, grad/param norm = 1.7133e-01, time/batch = 19.6289s	
7319/25300 (epoch 14.464), train_loss = 1.15711918, grad/param norm = 1.9622e-01, time/batch = 16.8111s	
7320/25300 (epoch 14.466), train_loss = 1.16286727, grad/param norm = 1.8722e-01, time/batch = 17.3913s	
7321/25300 (epoch 14.468), train_loss = 1.17949585, grad/param norm = 1.8108e-01, time/batch = 16.8151s	
7322/25300 (epoch 14.470), train_loss = 0.98768286, grad/param norm = 1.6608e-01, time/batch = 15.5028s	
7323/25300 (epoch 14.472), train_loss = 0.89455329, grad/param norm = 1.5907e-01, time/batch = 18.0543s	
7324/25300 (epoch 14.474), train_loss = 1.10737343, grad/param norm = 1.8509e-01, time/batch = 15.7187s	
7325/25300 (epoch 14.476), train_loss = 1.04063478, grad/param norm = 1.7515e-01, time/batch = 16.4620s	
7326/25300 (epoch 14.478), train_loss = 1.14160026, grad/param norm = 1.8698e-01, time/batch = 17.2153s	
7327/25300 (epoch 14.480), train_loss = 0.99162418, grad/param norm = 1.6780e-01, time/batch = 16.4671s	
7328/25300 (epoch 14.482), train_loss = 1.16210609, grad/param norm = 1.9424e-01, time/batch = 17.7879s	
7329/25300 (epoch 14.484), train_loss = 1.16488946, grad/param norm = 2.2286e-01, time/batch = 15.8019s	
7330/25300 (epoch 14.486), train_loss = 1.08948895, grad/param norm = 1.7998e-01, time/batch = 15.5309s	
7331/25300 (epoch 14.488), train_loss = 1.23123091, grad/param norm = 1.8841e-01, time/batch = 15.5291s	
7332/25300 (epoch 14.490), train_loss = 1.14516535, grad/param norm = 1.7332e-01, time/batch = 15.5377s	
7333/25300 (epoch 14.492), train_loss = 1.06714975, grad/param norm = 1.8499e-01, time/batch = 15.0600s	
7334/25300 (epoch 14.494), train_loss = 0.99073757, grad/param norm = 1.7750e-01, time/batch = 15.3877s	
7335/25300 (epoch 14.496), train_loss = 1.07868425, grad/param norm = 1.8707e-01, time/batch = 15.5350s	
7336/25300 (epoch 14.498), train_loss = 0.99604003, grad/param norm = 1.6861e-01, time/batch = 19.7856s	
7337/25300 (epoch 14.500), train_loss = 1.21631864, grad/param norm = 1.9607e-01, time/batch = 18.7034s	
7338/25300 (epoch 14.502), train_loss = 1.09618839, grad/param norm = 1.8608e-01, time/batch = 17.4557s	
7339/25300 (epoch 14.504), train_loss = 1.04371761, grad/param norm = 1.8561e-01, time/batch = 16.4679s	
7340/25300 (epoch 14.506), train_loss = 1.02140018, grad/param norm = 1.7865e-01, time/batch = 18.7936s	
7341/25300 (epoch 14.508), train_loss = 1.10700338, grad/param norm = 1.8947e-01, time/batch = 15.7962s	
7342/25300 (epoch 14.510), train_loss = 1.01251651, grad/param norm = 1.7652e-01, time/batch = 15.5285s	
7343/25300 (epoch 14.512), train_loss = 0.80797984, grad/param norm = 1.5926e-01, time/batch = 16.4497s	
7344/25300 (epoch 14.514), train_loss = 1.02238355, grad/param norm = 1.5523e-01, time/batch = 17.4792s	
7345/25300 (epoch 14.516), train_loss = 1.10932999, grad/param norm = 1.8518e-01, time/batch = 16.8070s	
7346/25300 (epoch 14.518), train_loss = 1.19866139, grad/param norm = 2.1149e-01, time/batch = 16.8182s	
7347/25300 (epoch 14.520), train_loss = 0.89810486, grad/param norm = 1.5620e-01, time/batch = 15.5473s	
7348/25300 (epoch 14.522), train_loss = 1.00838556, grad/param norm = 1.7583e-01, time/batch = 16.6392s	
7349/25300 (epoch 14.524), train_loss = 1.04750656, grad/param norm = 1.6867e-01, time/batch = 15.2337s	
7350/25300 (epoch 14.526), train_loss = 1.29251404, grad/param norm = 1.9039e-01, time/batch = 15.4551s	
7351/25300 (epoch 14.528), train_loss = 1.20497400, grad/param norm = 1.9284e-01, time/batch = 18.3171s	
7352/25300 (epoch 14.530), train_loss = 1.09472990, grad/param norm = 1.8145e-01, time/batch = 17.2213s	
7353/25300 (epoch 14.532), train_loss = 1.08715511, grad/param norm = 1.7767e-01, time/batch = 16.3074s	
7354/25300 (epoch 14.534), train_loss = 1.05621427, grad/param norm = 1.7405e-01, time/batch = 16.0804s	
7355/25300 (epoch 14.536), train_loss = 0.88395476, grad/param norm = 1.6410e-01, time/batch = 16.6444s	
7356/25300 (epoch 14.538), train_loss = 0.91077767, grad/param norm = 1.4365e-01, time/batch = 16.6482s	
7357/25300 (epoch 14.540), train_loss = 0.98169888, grad/param norm = 1.7505e-01, time/batch = 17.8076s	
7358/25300 (epoch 14.542), train_loss = 0.93717276, grad/param norm = 1.6200e-01, time/batch = 16.4669s	
7359/25300 (epoch 14.543), train_loss = 0.91059714, grad/param norm = 1.7001e-01, time/batch = 17.1328s	
7360/25300 (epoch 14.545), train_loss = 1.39617170, grad/param norm = 2.2533e-01, time/batch = 16.2140s	
7361/25300 (epoch 14.547), train_loss = 1.12755161, grad/param norm = 2.0243e-01, time/batch = 17.8722s	
7362/25300 (epoch 14.549), train_loss = 1.36047189, grad/param norm = 2.3592e-01, time/batch = 17.4599s	
7363/25300 (epoch 14.551), train_loss = 1.13304587, grad/param norm = 1.7969e-01, time/batch = 16.7281s	
7364/25300 (epoch 14.553), train_loss = 0.99580968, grad/param norm = 1.7962e-01, time/batch = 15.4808s	
7365/25300 (epoch 14.555), train_loss = 1.19674965, grad/param norm = 2.0414e-01, time/batch = 16.9092s	
7366/25300 (epoch 14.557), train_loss = 1.22711273, grad/param norm = 1.9315e-01, time/batch = 17.8870s	
7367/25300 (epoch 14.559), train_loss = 1.19850437, grad/param norm = 1.9439e-01, time/batch = 15.8070s	
7368/25300 (epoch 14.561), train_loss = 1.23387320, grad/param norm = 1.8700e-01, time/batch = 16.7986s	
7369/25300 (epoch 14.563), train_loss = 1.19147650, grad/param norm = 2.0291e-01, time/batch = 16.9893s	
7370/25300 (epoch 14.565), train_loss = 0.93088133, grad/param norm = 1.6850e-01, time/batch = 17.7200s	
7371/25300 (epoch 14.567), train_loss = 0.81749183, grad/param norm = 1.5590e-01, time/batch = 17.4752s	
7372/25300 (epoch 14.569), train_loss = 1.09260159, grad/param norm = 1.8338e-01, time/batch = 15.8125s	
7373/25300 (epoch 14.571), train_loss = 1.19100637, grad/param norm = 2.0991e-01, time/batch = 15.3942s	
7374/25300 (epoch 14.573), train_loss = 1.05524582, grad/param norm = 1.7119e-01, time/batch = 16.1508s	
7375/25300 (epoch 14.575), train_loss = 1.16925375, grad/param norm = 1.8382e-01, time/batch = 16.9691s	
7376/25300 (epoch 14.577), train_loss = 1.10194780, grad/param norm = 1.7945e-01, time/batch = 18.4746s	
7377/25300 (epoch 14.579), train_loss = 1.27118850, grad/param norm = 2.0229e-01, time/batch = 16.7284s	
7378/25300 (epoch 14.581), train_loss = 1.13974079, grad/param norm = 1.8833e-01, time/batch = 16.6267s	
7379/25300 (epoch 14.583), train_loss = 0.93609576, grad/param norm = 1.8555e-01, time/batch = 17.8919s	
7380/25300 (epoch 14.585), train_loss = 0.91399553, grad/param norm = 1.7136e-01, time/batch = 17.9525s	
7381/25300 (epoch 14.587), train_loss = 1.03383881, grad/param norm = 1.6873e-01, time/batch = 30.2200s	
7382/25300 (epoch 14.589), train_loss = 0.94388336, grad/param norm = 1.6528e-01, time/batch = 16.4907s	
7383/25300 (epoch 14.591), train_loss = 0.94691616, grad/param norm = 1.7768e-01, time/batch = 17.7280s	
7384/25300 (epoch 14.593), train_loss = 1.11814119, grad/param norm = 1.6765e-01, time/batch = 15.4887s	
7385/25300 (epoch 14.595), train_loss = 1.07273451, grad/param norm = 1.8992e-01, time/batch = 17.2239s	
7386/25300 (epoch 14.597), train_loss = 0.90516279, grad/param norm = 1.5107e-01, time/batch = 16.1581s	
7387/25300 (epoch 14.599), train_loss = 1.08015855, grad/param norm = 1.7272e-01, time/batch = 16.1193s	
7388/25300 (epoch 14.601), train_loss = 1.10800499, grad/param norm = 1.9184e-01, time/batch = 15.4706s	
7389/25300 (epoch 14.603), train_loss = 1.10867475, grad/param norm = 1.9004e-01, time/batch = 17.3288s	
7390/25300 (epoch 14.605), train_loss = 0.99147787, grad/param norm = 1.8454e-01, time/batch = 17.3921s	
7391/25300 (epoch 14.607), train_loss = 0.80582947, grad/param norm = 1.5306e-01, time/batch = 16.3135s	
7392/25300 (epoch 14.609), train_loss = 1.02414051, grad/param norm = 1.7469e-01, time/batch = 18.3214s	
7393/25300 (epoch 14.611), train_loss = 1.13475325, grad/param norm = 1.7972e-01, time/batch = 17.0586s	
7394/25300 (epoch 14.613), train_loss = 0.92891261, grad/param norm = 1.7425e-01, time/batch = 15.9678s	
7395/25300 (epoch 14.615), train_loss = 1.04474308, grad/param norm = 1.6742e-01, time/batch = 17.7199s	
7396/25300 (epoch 14.617), train_loss = 1.06328673, grad/param norm = 1.7960e-01, time/batch = 18.3180s	
7397/25300 (epoch 14.619), train_loss = 1.14365292, grad/param norm = 2.1454e-01, time/batch = 18.5264s	
7398/25300 (epoch 14.621), train_loss = 1.19169277, grad/param norm = 1.9570e-01, time/batch = 16.2170s	
7399/25300 (epoch 14.623), train_loss = 1.00773120, grad/param norm = 1.7305e-01, time/batch = 18.3755s	
7400/25300 (epoch 14.625), train_loss = 0.88540746, grad/param norm = 1.6365e-01, time/batch = 17.9517s	
7401/25300 (epoch 14.626), train_loss = 1.00156810, grad/param norm = 1.6945e-01, time/batch = 16.7154s	
7402/25300 (epoch 14.628), train_loss = 1.14884429, grad/param norm = 1.9110e-01, time/batch = 19.0464s	
7403/25300 (epoch 14.630), train_loss = 1.16091835, grad/param norm = 2.0886e-01, time/batch = 19.2926s	
7404/25300 (epoch 14.632), train_loss = 1.12114402, grad/param norm = 2.0414e-01, time/batch = 17.7109s	
7405/25300 (epoch 14.634), train_loss = 1.18656607, grad/param norm = 1.9547e-01, time/batch = 18.0659s	
7406/25300 (epoch 14.636), train_loss = 1.03851216, grad/param norm = 1.8269e-01, time/batch = 16.8016s	
7407/25300 (epoch 14.638), train_loss = 1.14251909, grad/param norm = 2.1139e-01, time/batch = 18.2205s	
7408/25300 (epoch 14.640), train_loss = 1.26310478, grad/param norm = 2.1519e-01, time/batch = 16.3047s	
7409/25300 (epoch 14.642), train_loss = 1.13354041, grad/param norm = 1.9149e-01, time/batch = 17.4835s	
7410/25300 (epoch 14.644), train_loss = 1.12108666, grad/param norm = 1.9530e-01, time/batch = 18.3922s	
7411/25300 (epoch 14.646), train_loss = 1.06135183, grad/param norm = 1.9237e-01, time/batch = 15.6310s	
7412/25300 (epoch 14.648), train_loss = 1.17005503, grad/param norm = 1.8317e-01, time/batch = 17.8921s	
7413/25300 (epoch 14.650), train_loss = 1.10340973, grad/param norm = 1.8239e-01, time/batch = 17.4796s	
7414/25300 (epoch 14.652), train_loss = 1.11186834, grad/param norm = 2.0220e-01, time/batch = 16.4824s	
7415/25300 (epoch 14.654), train_loss = 1.24078843, grad/param norm = 1.8784e-01, time/batch = 16.9722s	
7416/25300 (epoch 14.656), train_loss = 1.17467886, grad/param norm = 2.1232e-01, time/batch = 16.9955s	
7417/25300 (epoch 14.658), train_loss = 0.91042073, grad/param norm = 1.6827e-01, time/batch = 18.4901s	
7418/25300 (epoch 14.660), train_loss = 0.96585943, grad/param norm = 1.8091e-01, time/batch = 16.5543s	
7419/25300 (epoch 14.662), train_loss = 0.92328136, grad/param norm = 1.6970e-01, time/batch = 16.5673s	
7420/25300 (epoch 14.664), train_loss = 0.88205800, grad/param norm = 1.5899e-01, time/batch = 17.7336s	
7421/25300 (epoch 14.666), train_loss = 0.93077886, grad/param norm = 1.7206e-01, time/batch = 18.3827s	
7422/25300 (epoch 14.668), train_loss = 1.03529994, grad/param norm = 2.4386e-01, time/batch = 18.4646s	
7423/25300 (epoch 14.670), train_loss = 0.92798566, grad/param norm = 1.7733e-01, time/batch = 18.2224s	
7424/25300 (epoch 14.672), train_loss = 0.96721105, grad/param norm = 1.7822e-01, time/batch = 18.4566s	
7425/25300 (epoch 14.674), train_loss = 0.97737138, grad/param norm = 1.7880e-01, time/batch = 16.6431s	
7426/25300 (epoch 14.676), train_loss = 1.04981749, grad/param norm = 1.9792e-01, time/batch = 17.4844s	
7427/25300 (epoch 14.678), train_loss = 1.01359303, grad/param norm = 1.9473e-01, time/batch = 17.1493s	
7428/25300 (epoch 14.680), train_loss = 0.89345337, grad/param norm = 1.6436e-01, time/batch = 18.2186s	
7429/25300 (epoch 14.682), train_loss = 0.75951175, grad/param norm = 1.6128e-01, time/batch = 18.1407s	
7430/25300 (epoch 14.684), train_loss = 0.91956909, grad/param norm = 1.5907e-01, time/batch = 18.0659s	
7431/25300 (epoch 14.686), train_loss = 0.91391330, grad/param norm = 1.6400e-01, time/batch = 17.2854s	
7432/25300 (epoch 14.688), train_loss = 1.04231123, grad/param norm = 1.8354e-01, time/batch = 17.7990s	
7433/25300 (epoch 14.690), train_loss = 0.93292603, grad/param norm = 1.5784e-01, time/batch = 18.7112s	
7434/25300 (epoch 14.692), train_loss = 1.04368757, grad/param norm = 1.7503e-01, time/batch = 17.3743s	
7435/25300 (epoch 14.694), train_loss = 0.97391270, grad/param norm = 1.6680e-01, time/batch = 16.1296s	
7436/25300 (epoch 14.696), train_loss = 1.05703053, grad/param norm = 1.8192e-01, time/batch = 18.6421s	
7437/25300 (epoch 14.698), train_loss = 1.11316767, grad/param norm = 1.9511e-01, time/batch = 17.6468s	
7438/25300 (epoch 14.700), train_loss = 0.86399220, grad/param norm = 1.6702e-01, time/batch = 16.2137s	
7439/25300 (epoch 14.702), train_loss = 1.14138641, grad/param norm = 1.7951e-01, time/batch = 18.4657s	
7440/25300 (epoch 14.704), train_loss = 0.84518306, grad/param norm = 1.6657e-01, time/batch = 16.8911s	
7441/25300 (epoch 14.706), train_loss = 1.07905872, grad/param norm = 1.9594e-01, time/batch = 17.8177s	
7442/25300 (epoch 14.708), train_loss = 0.86951872, grad/param norm = 1.6236e-01, time/batch = 17.4503s	
7443/25300 (epoch 14.709), train_loss = 1.22152725, grad/param norm = 1.7946e-01, time/batch = 18.3924s	
7444/25300 (epoch 14.711), train_loss = 1.24534344, grad/param norm = 2.0100e-01, time/batch = 17.2098s	
7445/25300 (epoch 14.713), train_loss = 1.00936266, grad/param norm = 1.6258e-01, time/batch = 16.3743s	
7446/25300 (epoch 14.715), train_loss = 1.03268689, grad/param norm = 1.7364e-01, time/batch = 18.2152s	
7447/25300 (epoch 14.717), train_loss = 1.00836380, grad/param norm = 1.9901e-01, time/batch = 18.5510s	
7448/25300 (epoch 14.719), train_loss = 1.02815496, grad/param norm = 1.8015e-01, time/batch = 17.3726s	
7449/25300 (epoch 14.721), train_loss = 1.07332870, grad/param norm = 1.8743e-01, time/batch = 16.8908s	
7450/25300 (epoch 14.723), train_loss = 1.00477687, grad/param norm = 1.7483e-01, time/batch = 18.8825s	
7451/25300 (epoch 14.725), train_loss = 1.10021574, grad/param norm = 1.9013e-01, time/batch = 17.4609s	
7452/25300 (epoch 14.727), train_loss = 1.09669832, grad/param norm = 1.8067e-01, time/batch = 17.2098s	
7453/25300 (epoch 14.729), train_loss = 1.03446930, grad/param norm = 1.7455e-01, time/batch = 18.1449s	
7454/25300 (epoch 14.731), train_loss = 1.23942060, grad/param norm = 1.9609e-01, time/batch = 18.7177s	
7455/25300 (epoch 14.733), train_loss = 1.00276541, grad/param norm = 1.5499e-01, time/batch = 17.1391s	
7456/25300 (epoch 14.735), train_loss = 1.36616893, grad/param norm = 2.0756e-01, time/batch = 19.3007s	
7457/25300 (epoch 14.737), train_loss = 0.90555088, grad/param norm = 1.6614e-01, time/batch = 17.9772s	
7458/25300 (epoch 14.739), train_loss = 1.19293975, grad/param norm = 1.7907e-01, time/batch = 16.7881s	
7459/25300 (epoch 14.741), train_loss = 1.13853668, grad/param norm = 2.0875e-01, time/batch = 17.8932s	
7460/25300 (epoch 14.743), train_loss = 0.99854492, grad/param norm = 1.6936e-01, time/batch = 18.7151s	
7461/25300 (epoch 14.745), train_loss = 0.96292603, grad/param norm = 1.6302e-01, time/batch = 19.7001s	
7462/25300 (epoch 14.747), train_loss = 0.92456547, grad/param norm = 1.5360e-01, time/batch = 17.0479s	
7463/25300 (epoch 14.749), train_loss = 1.10049450, grad/param norm = 1.8628e-01, time/batch = 19.0640s	
7464/25300 (epoch 14.751), train_loss = 1.17068205, grad/param norm = 1.9201e-01, time/batch = 18.9660s	
7465/25300 (epoch 14.753), train_loss = 0.99221772, grad/param norm = 1.8803e-01, time/batch = 15.8913s	
7466/25300 (epoch 14.755), train_loss = 1.17784586, grad/param norm = 2.0555e-01, time/batch = 18.3804s	
7467/25300 (epoch 14.757), train_loss = 0.98083430, grad/param norm = 1.8514e-01, time/batch = 18.0341s	
7468/25300 (epoch 14.759), train_loss = 0.97692988, grad/param norm = 1.8162e-01, time/batch = 16.9731s	
7469/25300 (epoch 14.761), train_loss = 1.19879589, grad/param norm = 1.9180e-01, time/batch = 16.0730s	
7470/25300 (epoch 14.763), train_loss = 0.98091647, grad/param norm = 1.7956e-01, time/batch = 18.7262s	
7471/25300 (epoch 14.765), train_loss = 0.99592766, grad/param norm = 1.7508e-01, time/batch = 19.5534s	
7472/25300 (epoch 14.767), train_loss = 0.97883160, grad/param norm = 1.6714e-01, time/batch = 17.6268s	
7473/25300 (epoch 14.769), train_loss = 1.10505573, grad/param norm = 1.9000e-01, time/batch = 16.9690s	
7474/25300 (epoch 14.771), train_loss = 1.19923791, grad/param norm = 1.9536e-01, time/batch = 17.3250s	
7475/25300 (epoch 14.773), train_loss = 1.18492059, grad/param norm = 2.0179e-01, time/batch = 17.5582s	
7476/25300 (epoch 14.775), train_loss = 1.01108881, grad/param norm = 1.5475e-01, time/batch = 17.3282s	
7477/25300 (epoch 14.777), train_loss = 1.08338855, grad/param norm = 1.9248e-01, time/batch = 18.6328s	
7478/25300 (epoch 14.779), train_loss = 1.14697499, grad/param norm = 1.7412e-01, time/batch = 18.9525s	
7479/25300 (epoch 14.781), train_loss = 1.09873403, grad/param norm = 1.7381e-01, time/batch = 18.3708s	
7480/25300 (epoch 14.783), train_loss = 1.21648320, grad/param norm = 2.0058e-01, time/batch = 18.3048s	
7481/25300 (epoch 14.785), train_loss = 1.16101518, grad/param norm = 1.8240e-01, time/batch = 18.2232s	
7482/25300 (epoch 14.787), train_loss = 1.15011822, grad/param norm = 1.8592e-01, time/batch = 15.3804s	
7483/25300 (epoch 14.789), train_loss = 1.28057668, grad/param norm = 1.9691e-01, time/batch = 16.8910s	
7484/25300 (epoch 14.791), train_loss = 1.11465239, grad/param norm = 1.9214e-01, time/batch = 16.8962s	
7485/25300 (epoch 14.792), train_loss = 1.18105672, grad/param norm = 1.7688e-01, time/batch = 17.0412s	
7486/25300 (epoch 14.794), train_loss = 1.08390467, grad/param norm = 1.7701e-01, time/batch = 16.2156s	
7487/25300 (epoch 14.796), train_loss = 1.03350742, grad/param norm = 1.8633e-01, time/batch = 16.3083s	
7488/25300 (epoch 14.798), train_loss = 1.22423228, grad/param norm = 1.9932e-01, time/batch = 15.6458s	
7489/25300 (epoch 14.800), train_loss = 1.06335560, grad/param norm = 1.8357e-01, time/batch = 16.2030s	
7490/25300 (epoch 14.802), train_loss = 0.86513551, grad/param norm = 1.7672e-01, time/batch = 17.1179s	
7491/25300 (epoch 14.804), train_loss = 1.09418541, grad/param norm = 1.7644e-01, time/batch = 19.2151s	
7492/25300 (epoch 14.806), train_loss = 1.15814591, grad/param norm = 1.9789e-01, time/batch = 16.9652s	
7493/25300 (epoch 14.808), train_loss = 1.12160352, grad/param norm = 1.9021e-01, time/batch = 17.3140s	
7494/25300 (epoch 14.810), train_loss = 1.06991484, grad/param norm = 1.9225e-01, time/batch = 16.0428s	
7495/25300 (epoch 14.812), train_loss = 1.15701978, grad/param norm = 1.7956e-01, time/batch = 16.3821s	
7496/25300 (epoch 14.814), train_loss = 1.24564861, grad/param norm = 1.9855e-01, time/batch = 15.6327s	
7497/25300 (epoch 14.816), train_loss = 1.35429642, grad/param norm = 1.9815e-01, time/batch = 16.2344s	
7498/25300 (epoch 14.818), train_loss = 1.14315565, grad/param norm = 1.8896e-01, time/batch = 15.9821s	
7499/25300 (epoch 14.820), train_loss = 1.14096649, grad/param norm = 1.9297e-01, time/batch = 18.7158s	
7500/25300 (epoch 14.822), train_loss = 1.06428437, grad/param norm = 1.6808e-01, time/batch = 15.7007s	
7501/25300 (epoch 14.824), train_loss = 1.15070056, grad/param norm = 1.8493e-01, time/batch = 15.4472s	
7502/25300 (epoch 14.826), train_loss = 1.00702559, grad/param norm = 1.7623e-01, time/batch = 18.3003s	
7503/25300 (epoch 14.828), train_loss = 1.01095762, grad/param norm = 1.8043e-01, time/batch = 16.2858s	
7504/25300 (epoch 14.830), train_loss = 1.08004631, grad/param norm = 1.7100e-01, time/batch = 16.3973s	
7505/25300 (epoch 14.832), train_loss = 1.12841207, grad/param norm = 1.8508e-01, time/batch = 18.2221s	
7506/25300 (epoch 14.834), train_loss = 0.93351873, grad/param norm = 1.5594e-01, time/batch = 18.6301s	
7507/25300 (epoch 14.836), train_loss = 1.01547345, grad/param norm = 1.7811e-01, time/batch = 16.3029s	
7508/25300 (epoch 14.838), train_loss = 1.04441175, grad/param norm = 1.8282e-01, time/batch = 18.7995s	
7509/25300 (epoch 14.840), train_loss = 1.21669660, grad/param norm = 1.8873e-01, time/batch = 16.4822s	
7510/25300 (epoch 14.842), train_loss = 1.08283690, grad/param norm = 2.0278e-01, time/batch = 16.1477s	
7511/25300 (epoch 14.844), train_loss = 1.12394128, grad/param norm = 1.7038e-01, time/batch = 17.8884s	
7512/25300 (epoch 14.846), train_loss = 1.13127052, grad/param norm = 1.7780e-01, time/batch = 19.2828s	
7513/25300 (epoch 14.848), train_loss = 1.19608256, grad/param norm = 1.8436e-01, time/batch = 17.2078s	
7514/25300 (epoch 14.850), train_loss = 1.16034784, grad/param norm = 1.9999e-01, time/batch = 15.8960s	
7515/25300 (epoch 14.852), train_loss = 1.13709227, grad/param norm = 1.8296e-01, time/batch = 19.0396s	
7516/25300 (epoch 14.854), train_loss = 1.24810256, grad/param norm = 2.0333e-01, time/batch = 16.9658s	
7517/25300 (epoch 14.856), train_loss = 1.06620965, grad/param norm = 1.8843e-01, time/batch = 17.1248s	
7518/25300 (epoch 14.858), train_loss = 1.14650624, grad/param norm = 2.1124e-01, time/batch = 17.1113s	
7519/25300 (epoch 14.860), train_loss = 0.92305502, grad/param norm = 1.7786e-01, time/batch = 19.1976s	
7520/25300 (epoch 14.862), train_loss = 1.13130151, grad/param norm = 2.1587e-01, time/batch = 17.2961s	
7521/25300 (epoch 14.864), train_loss = 1.18751708, grad/param norm = 1.8861e-01, time/batch = 16.1441s	
7522/25300 (epoch 14.866), train_loss = 1.12544726, grad/param norm = 2.1023e-01, time/batch = 16.6156s	
7523/25300 (epoch 14.868), train_loss = 1.21365212, grad/param norm = 2.0355e-01, time/batch = 18.0543s	
7524/25300 (epoch 14.870), train_loss = 1.18073928, grad/param norm = 1.7148e-01, time/batch = 15.9458s	
7525/25300 (epoch 14.872), train_loss = 1.18590046, grad/param norm = 2.1955e-01, time/batch = 18.2048s	
7526/25300 (epoch 14.874), train_loss = 1.18761511, grad/param norm = 2.0402e-01, time/batch = 18.1373s	
7527/25300 (epoch 14.875), train_loss = 1.08467190, grad/param norm = 1.7346e-01, time/batch = 17.3773s	
7528/25300 (epoch 14.877), train_loss = 1.03057693, grad/param norm = 1.7133e-01, time/batch = 17.0326s	
7529/25300 (epoch 14.879), train_loss = 1.09590697, grad/param norm = 1.9997e-01, time/batch = 17.9890s	
7530/25300 (epoch 14.881), train_loss = 1.39258741, grad/param norm = 2.2790e-01, time/batch = 17.3094s	
7531/25300 (epoch 14.883), train_loss = 1.35437624, grad/param norm = 1.9582e-01, time/batch = 15.2297s	
7532/25300 (epoch 14.885), train_loss = 1.19097195, grad/param norm = 2.0704e-01, time/batch = 17.4641s	
7533/25300 (epoch 14.887), train_loss = 1.13951077, grad/param norm = 1.9202e-01, time/batch = 18.9706s	
7534/25300 (epoch 14.889), train_loss = 1.26456573, grad/param norm = 1.9007e-01, time/batch = 17.2005s	
7535/25300 (epoch 14.891), train_loss = 1.16977897, grad/param norm = 1.9729e-01, time/batch = 16.2089s	
7536/25300 (epoch 14.893), train_loss = 1.25928443, grad/param norm = 2.1756e-01, time/batch = 17.4831s	
7537/25300 (epoch 14.895), train_loss = 0.87500909, grad/param norm = 1.8001e-01, time/batch = 18.4557s	
7538/25300 (epoch 14.897), train_loss = 1.01345965, grad/param norm = 1.9149e-01, time/batch = 17.5624s	
7539/25300 (epoch 14.899), train_loss = 1.10510225, grad/param norm = 1.8736e-01, time/batch = 17.6201s	
7540/25300 (epoch 14.901), train_loss = 1.13513142, grad/param norm = 1.7705e-01, time/batch = 17.9579s	
7541/25300 (epoch 14.903), train_loss = 0.89185821, grad/param norm = 1.6156e-01, time/batch = 16.7972s	
7542/25300 (epoch 14.905), train_loss = 1.03611750, grad/param norm = 2.0218e-01, time/batch = 17.8014s	
7543/25300 (epoch 14.907), train_loss = 1.06954874, grad/param norm = 1.9939e-01, time/batch = 19.1379s	
7544/25300 (epoch 14.909), train_loss = 1.17670950, grad/param norm = 1.8070e-01, time/batch = 17.0471s	
7545/25300 (epoch 14.911), train_loss = 1.30478201, grad/param norm = 2.0627e-01, time/batch = 17.2109s	
7546/25300 (epoch 14.913), train_loss = 1.33254960, grad/param norm = 2.1613e-01, time/batch = 17.6283s	
7547/25300 (epoch 14.915), train_loss = 1.04440448, grad/param norm = 2.0355e-01, time/batch = 16.7239s	
7548/25300 (epoch 14.917), train_loss = 1.17037920, grad/param norm = 2.0553e-01, time/batch = 16.4807s	
7549/25300 (epoch 14.919), train_loss = 1.27648564, grad/param norm = 1.9627e-01, time/batch = 19.5453s	
7550/25300 (epoch 14.921), train_loss = 0.99423844, grad/param norm = 1.6446e-01, time/batch = 17.3985s	
7551/25300 (epoch 14.923), train_loss = 1.26462036, grad/param norm = 1.8851e-01, time/batch = 16.5521s	
7552/25300 (epoch 14.925), train_loss = 1.07985137, grad/param norm = 1.8724e-01, time/batch = 16.8011s	
7553/25300 (epoch 14.927), train_loss = 1.07550602, grad/param norm = 1.8974e-01, time/batch = 16.2277s	
7554/25300 (epoch 14.929), train_loss = 1.06319835, grad/param norm = 1.8196e-01, time/batch = 18.0483s	
7555/25300 (epoch 14.931), train_loss = 1.20256828, grad/param norm = 1.9023e-01, time/batch = 15.5513s	
7556/25300 (epoch 14.933), train_loss = 1.18833014, grad/param norm = 1.9435e-01, time/batch = 17.2257s	
7557/25300 (epoch 14.935), train_loss = 1.15121658, grad/param norm = 1.7660e-01, time/batch = 17.7193s	
7558/25300 (epoch 14.937), train_loss = 0.85085807, grad/param norm = 1.5270e-01, time/batch = 16.7965s	
7559/25300 (epoch 14.939), train_loss = 1.19749392, grad/param norm = 1.8637e-01, time/batch = 17.1507s	
7560/25300 (epoch 14.941), train_loss = 1.05940493, grad/param norm = 1.8572e-01, time/batch = 15.8210s	
7561/25300 (epoch 14.943), train_loss = 1.10079379, grad/param norm = 1.7826e-01, time/batch = 17.4786s	
7562/25300 (epoch 14.945), train_loss = 1.15125745, grad/param norm = 1.8583e-01, time/batch = 16.2091s	
7563/25300 (epoch 14.947), train_loss = 1.00962721, grad/param norm = 1.7653e-01, time/batch = 16.3102s	
7564/25300 (epoch 14.949), train_loss = 1.16880936, grad/param norm = 1.8402e-01, time/batch = 17.6379s	
7565/25300 (epoch 14.951), train_loss = 1.08864391, grad/param norm = 1.7787e-01, time/batch = 16.4398s	
7566/25300 (epoch 14.953), train_loss = 1.14435972, grad/param norm = 1.6896e-01, time/batch = 15.6439s	
7567/25300 (epoch 14.955), train_loss = 1.36601909, grad/param norm = 2.2472e-01, time/batch = 16.6475s	
7568/25300 (epoch 14.957), train_loss = 1.30081769, grad/param norm = 2.2899e-01, time/batch = 17.3216s	
7569/25300 (epoch 14.958), train_loss = 1.17806030, grad/param norm = 1.9724e-01, time/batch = 15.5535s	
7570/25300 (epoch 14.960), train_loss = 1.32052393, grad/param norm = 2.1118e-01, time/batch = 16.7955s	
7571/25300 (epoch 14.962), train_loss = 1.28198063, grad/param norm = 2.1316e-01, time/batch = 16.1261s	
7572/25300 (epoch 14.964), train_loss = 1.19310582, grad/param norm = 1.8352e-01, time/batch = 17.7208s	
7573/25300 (epoch 14.966), train_loss = 0.93704110, grad/param norm = 1.5651e-01, time/batch = 15.9802s	
7574/25300 (epoch 14.968), train_loss = 0.94575180, grad/param norm = 1.7148e-01, time/batch = 16.4863s	
7575/25300 (epoch 14.970), train_loss = 1.08510618, grad/param norm = 1.8962e-01, time/batch = 19.4606s	
7576/25300 (epoch 14.972), train_loss = 1.12941959, grad/param norm = 2.0267e-01, time/batch = 17.2073s	
7577/25300 (epoch 14.974), train_loss = 1.30168143, grad/param norm = 2.0574e-01, time/batch = 17.7973s	
7578/25300 (epoch 14.976), train_loss = 1.15456633, grad/param norm = 2.0084e-01, time/batch = 17.2250s	
7579/25300 (epoch 14.978), train_loss = 1.15173194, grad/param norm = 1.9987e-01, time/batch = 17.0702s	
7580/25300 (epoch 14.980), train_loss = 1.16921084, grad/param norm = 2.0502e-01, time/batch = 17.9747s	
7581/25300 (epoch 14.982), train_loss = 1.05760168, grad/param norm = 1.9796e-01, time/batch = 16.8976s	
7582/25300 (epoch 14.984), train_loss = 1.10554261, grad/param norm = 2.0355e-01, time/batch = 17.6388s	
7583/25300 (epoch 14.986), train_loss = 1.20066228, grad/param norm = 2.0096e-01, time/batch = 18.0232s	
7584/25300 (epoch 14.988), train_loss = 1.19212466, grad/param norm = 1.9920e-01, time/batch = 17.9723s	
7585/25300 (epoch 14.990), train_loss = 1.11202591, grad/param norm = 1.8566e-01, time/batch = 18.1386s	
7586/25300 (epoch 14.992), train_loss = 0.90373833, grad/param norm = 1.7448e-01, time/batch = 25.3614s	
7587/25300 (epoch 14.994), train_loss = 1.13015791, grad/param norm = 1.8566e-01, time/batch = 21.8155s	
7588/25300 (epoch 14.996), train_loss = 1.25621492, grad/param norm = 2.2545e-01, time/batch = 18.2717s	
7589/25300 (epoch 14.998), train_loss = 1.23828578, grad/param norm = 1.9917e-01, time/batch = 16.3665s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
7590/25300 (epoch 15.000), train_loss = 1.12665362, grad/param norm = 1.9594e-01, time/batch = 16.4628s	
7591/25300 (epoch 15.002), train_loss = 0.95300609, grad/param norm = 1.6114e-01, time/batch = 18.4753s	
7592/25300 (epoch 15.004), train_loss = 0.93866942, grad/param norm = 1.7255e-01, time/batch = 16.3820s	
7593/25300 (epoch 15.006), train_loss = 1.22720810, grad/param norm = 1.8668e-01, time/batch = 17.1244s	
7594/25300 (epoch 15.008), train_loss = 1.08410133, grad/param norm = 1.7192e-01, time/batch = 17.9710s	
7595/25300 (epoch 15.010), train_loss = 1.10847680, grad/param norm = 1.6909e-01, time/batch = 17.0606s	
7596/25300 (epoch 15.012), train_loss = 1.01531451, grad/param norm = 1.9385e-01, time/batch = 15.8901s	
7597/25300 (epoch 15.014), train_loss = 1.22472072, grad/param norm = 1.8842e-01, time/batch = 16.6367s	
7598/25300 (epoch 15.016), train_loss = 1.12500955, grad/param norm = 1.9583e-01, time/batch = 17.0568s	
7599/25300 (epoch 15.018), train_loss = 1.01844517, grad/param norm = 1.8198e-01, time/batch = 15.5704s	
7600/25300 (epoch 15.020), train_loss = 1.05014730, grad/param norm = 1.7256e-01, time/batch = 16.2074s	
7601/25300 (epoch 15.022), train_loss = 1.13489985, grad/param norm = 1.9893e-01, time/batch = 17.4563s	
7602/25300 (epoch 15.024), train_loss = 0.82226282, grad/param norm = 1.4441e-01, time/batch = 16.8984s	
7603/25300 (epoch 15.026), train_loss = 1.03015883, grad/param norm = 1.9315e-01, time/batch = 15.9599s	
7604/25300 (epoch 15.028), train_loss = 0.96718220, grad/param norm = 1.5501e-01, time/batch = 16.7331s	
7605/25300 (epoch 15.030), train_loss = 1.19719770, grad/param norm = 1.7935e-01, time/batch = 16.8034s	
7606/25300 (epoch 15.032), train_loss = 1.02981641, grad/param norm = 1.8206e-01, time/batch = 16.5558s	
7607/25300 (epoch 15.034), train_loss = 0.87954283, grad/param norm = 1.6976e-01, time/batch = 16.0445s	
7608/25300 (epoch 15.036), train_loss = 0.91245495, grad/param norm = 1.7160e-01, time/batch = 15.5522s	
7609/25300 (epoch 15.038), train_loss = 0.80493257, grad/param norm = 1.3817e-01, time/batch = 15.6426s	
7610/25300 (epoch 15.040), train_loss = 1.13159205, grad/param norm = 1.8513e-01, time/batch = 15.8033s	
7611/25300 (epoch 15.042), train_loss = 1.02269431, grad/param norm = 1.7897e-01, time/batch = 15.7719s	
7612/25300 (epoch 15.043), train_loss = 0.88537244, grad/param norm = 1.5409e-01, time/batch = 16.4664s	
7613/25300 (epoch 15.045), train_loss = 0.93549337, grad/param norm = 1.7325e-01, time/batch = 15.7824s	
7614/25300 (epoch 15.047), train_loss = 1.11397765, grad/param norm = 1.7334e-01, time/batch = 15.6188s	
7615/25300 (epoch 15.049), train_loss = 1.10590276, grad/param norm = 2.0086e-01, time/batch = 17.3086s	
7616/25300 (epoch 15.051), train_loss = 1.17864550, grad/param norm = 2.0163e-01, time/batch = 17.6360s	
7617/25300 (epoch 15.053), train_loss = 0.87952533, grad/param norm = 1.5512e-01, time/batch = 18.7827s	
7618/25300 (epoch 15.055), train_loss = 0.94444770, grad/param norm = 1.5688e-01, time/batch = 15.7313s	
7619/25300 (epoch 15.057), train_loss = 0.90068678, grad/param norm = 1.5992e-01, time/batch = 18.8099s	
7620/25300 (epoch 15.059), train_loss = 1.03310462, grad/param norm = 1.8156e-01, time/batch = 17.7264s	
7621/25300 (epoch 15.061), train_loss = 0.97567313, grad/param norm = 1.6794e-01, time/batch = 15.7297s	
7622/25300 (epoch 15.063), train_loss = 0.95214575, grad/param norm = 1.8312e-01, time/batch = 15.8850s	
7623/25300 (epoch 15.065), train_loss = 1.17502203, grad/param norm = 2.0357e-01, time/batch = 15.6493s	
7624/25300 (epoch 15.067), train_loss = 1.17487944, grad/param norm = 1.7828e-01, time/batch = 16.2044s	
7625/25300 (epoch 15.069), train_loss = 1.04348575, grad/param norm = 1.8714e-01, time/batch = 16.1292s	
7626/25300 (epoch 15.071), train_loss = 1.20482474, grad/param norm = 1.9088e-01, time/batch = 15.5678s	
7627/25300 (epoch 15.073), train_loss = 1.02203706, grad/param norm = 1.5859e-01, time/batch = 17.4014s	
7628/25300 (epoch 15.075), train_loss = 1.12453027, grad/param norm = 1.8038e-01, time/batch = 16.0482s	
7629/25300 (epoch 15.077), train_loss = 1.10262388, grad/param norm = 1.7614e-01, time/batch = 16.4053s	
7630/25300 (epoch 15.079), train_loss = 1.05630485, grad/param norm = 1.7152e-01, time/batch = 17.6349s	
7631/25300 (epoch 15.081), train_loss = 1.04002135, grad/param norm = 1.6084e-01, time/batch = 17.2192s	
7632/25300 (epoch 15.083), train_loss = 1.05349600, grad/param norm = 1.6729e-01, time/batch = 16.6995s	
7633/25300 (epoch 15.085), train_loss = 1.30920076, grad/param norm = 2.0299e-01, time/batch = 17.9636s	
7634/25300 (epoch 15.087), train_loss = 1.13142230, grad/param norm = 1.8753e-01, time/batch = 17.1607s	
7635/25300 (epoch 15.089), train_loss = 1.13613585, grad/param norm = 1.8232e-01, time/batch = 15.4631s	
7636/25300 (epoch 15.091), train_loss = 1.25431501, grad/param norm = 1.8359e-01, time/batch = 15.7294s	
7637/25300 (epoch 15.093), train_loss = 1.21840959, grad/param norm = 1.9432e-01, time/batch = 16.0573s	
7638/25300 (epoch 15.095), train_loss = 1.16589742, grad/param norm = 1.8473e-01, time/batch = 16.2367s	
7639/25300 (epoch 15.097), train_loss = 1.10454056, grad/param norm = 1.8149e-01, time/batch = 15.6146s	
7640/25300 (epoch 15.099), train_loss = 1.15285689, grad/param norm = 1.9193e-01, time/batch = 16.0628s	
7641/25300 (epoch 15.101), train_loss = 1.07193183, grad/param norm = 1.7383e-01, time/batch = 15.5424s	
7642/25300 (epoch 15.103), train_loss = 1.07090655, grad/param norm = 1.7996e-01, time/batch = 15.6065s	
7643/25300 (epoch 15.105), train_loss = 1.12289910, grad/param norm = 1.7911e-01, time/batch = 15.6344s	
7644/25300 (epoch 15.107), train_loss = 1.16796804, grad/param norm = 1.9648e-01, time/batch = 15.5222s	
7645/25300 (epoch 15.109), train_loss = 1.07082276, grad/param norm = 1.8950e-01, time/batch = 15.2036s	
7646/25300 (epoch 15.111), train_loss = 1.07017600, grad/param norm = 1.7137e-01, time/batch = 15.7213s	
7647/25300 (epoch 15.113), train_loss = 1.06052244, grad/param norm = 1.9787e-01, time/batch = 15.6161s	
7648/25300 (epoch 15.115), train_loss = 1.07836169, grad/param norm = 1.9063e-01, time/batch = 15.1384s	
7649/25300 (epoch 15.117), train_loss = 1.14823886, grad/param norm = 1.7306e-01, time/batch = 15.7295s	
7650/25300 (epoch 15.119), train_loss = 1.04413497, grad/param norm = 1.7218e-01, time/batch = 17.0468s	
7651/25300 (epoch 15.121), train_loss = 1.12985953, grad/param norm = 1.9405e-01, time/batch = 16.6526s	
7652/25300 (epoch 15.123), train_loss = 1.08268099, grad/param norm = 1.9383e-01, time/batch = 15.7117s	
7653/25300 (epoch 15.125), train_loss = 1.19084036, grad/param norm = 2.4233e-01, time/batch = 17.7143s	
7654/25300 (epoch 15.126), train_loss = 1.09843685, grad/param norm = 2.0241e-01, time/batch = 16.3947s	
7655/25300 (epoch 15.128), train_loss = 1.10789661, grad/param norm = 1.9091e-01, time/batch = 16.8767s	
7656/25300 (epoch 15.130), train_loss = 0.88014975, grad/param norm = 1.5723e-01, time/batch = 18.8612s	
7657/25300 (epoch 15.132), train_loss = 0.92320025, grad/param norm = 1.6133e-01, time/batch = 16.8612s	
7658/25300 (epoch 15.134), train_loss = 0.86834621, grad/param norm = 1.5710e-01, time/batch = 16.4423s	
7659/25300 (epoch 15.136), train_loss = 1.09407189, grad/param norm = 1.7546e-01, time/batch = 17.3961s	
7660/25300 (epoch 15.138), train_loss = 0.94261650, grad/param norm = 1.5993e-01, time/batch = 17.3798s	
7661/25300 (epoch 15.140), train_loss = 1.01493042, grad/param norm = 1.6686e-01, time/batch = 16.5381s	
7662/25300 (epoch 15.142), train_loss = 1.17816663, grad/param norm = 1.7889e-01, time/batch = 16.4920s	
7663/25300 (epoch 15.144), train_loss = 1.13434919, grad/param norm = 1.8275e-01, time/batch = 16.8902s	
7664/25300 (epoch 15.146), train_loss = 1.17617886, grad/param norm = 2.1283e-01, time/batch = 17.6171s	
7665/25300 (epoch 15.148), train_loss = 1.06707287, grad/param norm = 1.8663e-01, time/batch = 15.6316s	
7666/25300 (epoch 15.150), train_loss = 1.20761862, grad/param norm = 2.2039e-01, time/batch = 17.9827s	
7667/25300 (epoch 15.152), train_loss = 1.28211683, grad/param norm = 1.9879e-01, time/batch = 18.5512s	
7668/25300 (epoch 15.154), train_loss = 0.97066040, grad/param norm = 1.7351e-01, time/batch = 16.7193s	
7669/25300 (epoch 15.156), train_loss = 1.13475206, grad/param norm = 1.7748e-01, time/batch = 16.5543s	
7670/25300 (epoch 15.158), train_loss = 0.97534662, grad/param norm = 1.6409e-01, time/batch = 18.7874s	
7671/25300 (epoch 15.160), train_loss = 1.08863456, grad/param norm = 1.7741e-01, time/batch = 15.3705s	
7672/25300 (epoch 15.162), train_loss = 1.01208549, grad/param norm = 1.8934e-01, time/batch = 16.3003s	
7673/25300 (epoch 15.164), train_loss = 1.16955576, grad/param norm = 1.8469e-01, time/batch = 16.7160s	
7674/25300 (epoch 15.166), train_loss = 1.08975614, grad/param norm = 1.7341e-01, time/batch = 17.6439s	
7675/25300 (epoch 15.168), train_loss = 0.95505673, grad/param norm = 1.5724e-01, time/batch = 16.4715s	
7676/25300 (epoch 15.170), train_loss = 1.03861025, grad/param norm = 1.6547e-01, time/batch = 15.3913s	
7677/25300 (epoch 15.172), train_loss = 0.97376112, grad/param norm = 1.6595e-01, time/batch = 16.7306s	
7678/25300 (epoch 15.174), train_loss = 0.95353928, grad/param norm = 1.6628e-01, time/batch = 19.4412s	
7679/25300 (epoch 15.176), train_loss = 1.01442654, grad/param norm = 1.7565e-01, time/batch = 15.9626s	
7680/25300 (epoch 15.178), train_loss = 1.22214232, grad/param norm = 2.0320e-01, time/batch = 16.3144s	
7681/25300 (epoch 15.180), train_loss = 0.89845495, grad/param norm = 1.6364e-01, time/batch = 16.8244s	
7682/25300 (epoch 15.182), train_loss = 1.00906043, grad/param norm = 1.6674e-01, time/batch = 17.1220s	
7683/25300 (epoch 15.184), train_loss = 1.05236928, grad/param norm = 1.8294e-01, time/batch = 18.2914s	
7684/25300 (epoch 15.186), train_loss = 1.00944475, grad/param norm = 1.8473e-01, time/batch = 16.5631s	
7685/25300 (epoch 15.188), train_loss = 1.06944052, grad/param norm = 1.8107e-01, time/batch = 17.6341s	
7686/25300 (epoch 15.190), train_loss = 1.06252451, grad/param norm = 1.8873e-01, time/batch = 16.3097s	
7687/25300 (epoch 15.192), train_loss = 1.03423527, grad/param norm = 1.8399e-01, time/batch = 19.1299s	
7688/25300 (epoch 15.194), train_loss = 1.04653992, grad/param norm = 1.7258e-01, time/batch = 17.1425s	
7689/25300 (epoch 15.196), train_loss = 1.15006123, grad/param norm = 2.0535e-01, time/batch = 15.3822s	
7690/25300 (epoch 15.198), train_loss = 1.01409317, grad/param norm = 1.8507e-01, time/batch = 16.8989s	
7691/25300 (epoch 15.200), train_loss = 1.06718718, grad/param norm = 1.9865e-01, time/batch = 17.1409s	
7692/25300 (epoch 15.202), train_loss = 1.06127361, grad/param norm = 1.8673e-01, time/batch = 16.9865s	
7693/25300 (epoch 15.204), train_loss = 1.02438981, grad/param norm = 1.7293e-01, time/batch = 15.6265s	
7694/25300 (epoch 15.206), train_loss = 1.14802093, grad/param norm = 1.8244e-01, time/batch = 16.9760s	
7695/25300 (epoch 15.208), train_loss = 0.95727517, grad/param norm = 1.8749e-01, time/batch = 17.4721s	
7696/25300 (epoch 15.209), train_loss = 0.89404332, grad/param norm = 1.6878e-01, time/batch = 17.4692s	
7697/25300 (epoch 15.211), train_loss = 1.03068395, grad/param norm = 1.7634e-01, time/batch = 17.4699s	
7698/25300 (epoch 15.213), train_loss = 1.12332166, grad/param norm = 1.8217e-01, time/batch = 17.0673s	
7699/25300 (epoch 15.215), train_loss = 1.10262480, grad/param norm = 1.8627e-01, time/batch = 17.4648s	
7700/25300 (epoch 15.217), train_loss = 1.11969159, grad/param norm = 2.2240e-01, time/batch = 16.6273s	
7701/25300 (epoch 15.219), train_loss = 1.18267636, grad/param norm = 1.9712e-01, time/batch = 19.9425s	
7702/25300 (epoch 15.221), train_loss = 1.21186297, grad/param norm = 1.9192e-01, time/batch = 17.3869s	
7703/25300 (epoch 15.223), train_loss = 1.14568248, grad/param norm = 1.9736e-01, time/batch = 17.1252s	
7704/25300 (epoch 15.225), train_loss = 1.57400713, grad/param norm = 2.6792e-01, time/batch = 18.2946s	
7705/25300 (epoch 15.227), train_loss = 1.18685879, grad/param norm = 1.8815e-01, time/batch = 16.9489s	
7706/25300 (epoch 15.229), train_loss = 1.08145042, grad/param norm = 1.8252e-01, time/batch = 17.3891s	
7707/25300 (epoch 15.231), train_loss = 1.05261717, grad/param norm = 1.7666e-01, time/batch = 17.2122s	
7708/25300 (epoch 15.233), train_loss = 1.15115710, grad/param norm = 1.9260e-01, time/batch = 18.8028s	
7709/25300 (epoch 15.235), train_loss = 1.06862532, grad/param norm = 1.7441e-01, time/batch = 18.5550s	
7710/25300 (epoch 15.237), train_loss = 1.26587365, grad/param norm = 1.9769e-01, time/batch = 16.2719s	
7711/25300 (epoch 15.239), train_loss = 1.10961663, grad/param norm = 1.9100e-01, time/batch = 17.1442s	
7712/25300 (epoch 15.241), train_loss = 1.20661700, grad/param norm = 1.8396e-01, time/batch = 17.8128s	
7713/25300 (epoch 15.243), train_loss = 1.41495287, grad/param norm = 2.1904e-01, time/batch = 17.8717s	
7714/25300 (epoch 15.245), train_loss = 1.02673763, grad/param norm = 1.8483e-01, time/batch = 15.8089s	
7715/25300 (epoch 15.247), train_loss = 1.17490292, grad/param norm = 1.8427e-01, time/batch = 16.9722s	
7716/25300 (epoch 15.249), train_loss = 0.96904415, grad/param norm = 1.6199e-01, time/batch = 17.9566s	
7717/25300 (epoch 15.251), train_loss = 0.91004699, grad/param norm = 1.6277e-01, time/batch = 16.3029s	
7718/25300 (epoch 15.253), train_loss = 1.06944016, grad/param norm = 1.9111e-01, time/batch = 16.8881s	
7719/25300 (epoch 15.255), train_loss = 1.02045426, grad/param norm = 2.0162e-01, time/batch = 15.2043s	
7720/25300 (epoch 15.257), train_loss = 1.11029276, grad/param norm = 1.8891e-01, time/batch = 16.6582s	
7721/25300 (epoch 15.259), train_loss = 1.31619822, grad/param norm = 1.9687e-01, time/batch = 17.3107s	
7722/25300 (epoch 15.261), train_loss = 1.25953309, grad/param norm = 2.0777e-01, time/batch = 16.3126s	
7723/25300 (epoch 15.263), train_loss = 1.22691315, grad/param norm = 1.9103e-01, time/batch = 17.4651s	
7724/25300 (epoch 15.265), train_loss = 1.30294389, grad/param norm = 1.8410e-01, time/batch = 15.5450s	
7725/25300 (epoch 15.267), train_loss = 1.19484867, grad/param norm = 1.8850e-01, time/batch = 16.3995s	
7726/25300 (epoch 15.269), train_loss = 0.91628897, grad/param norm = 1.5664e-01, time/batch = 16.1546s	
7727/25300 (epoch 15.271), train_loss = 1.04759762, grad/param norm = 1.7371e-01, time/batch = 18.4580s	
7728/25300 (epoch 15.273), train_loss = 1.16828183, grad/param norm = 2.1686e-01, time/batch = 15.5461s	
7729/25300 (epoch 15.275), train_loss = 1.01288429, grad/param norm = 1.5355e-01, time/batch = 17.0246s	
7730/25300 (epoch 15.277), train_loss = 1.05786524, grad/param norm = 1.7922e-01, time/batch = 17.0522s	
7731/25300 (epoch 15.279), train_loss = 1.06106664, grad/param norm = 1.6492e-01, time/batch = 16.6497s	
7732/25300 (epoch 15.281), train_loss = 1.23807034, grad/param norm = 1.9649e-01, time/batch = 15.6461s	
7733/25300 (epoch 15.283), train_loss = 0.96778123, grad/param norm = 1.6489e-01, time/batch = 18.0555s	
7734/25300 (epoch 15.285), train_loss = 1.12720209, grad/param norm = 2.0356e-01, time/batch = 17.7225s	
7735/25300 (epoch 15.287), train_loss = 1.11919732, grad/param norm = 1.7087e-01, time/batch = 17.5425s	
7736/25300 (epoch 15.289), train_loss = 1.03099617, grad/param norm = 1.7091e-01, time/batch = 16.9689s	
7737/25300 (epoch 15.291), train_loss = 1.04533820, grad/param norm = 1.7655e-01, time/batch = 17.2896s	
7738/25300 (epoch 15.292), train_loss = 1.25145122, grad/param norm = 1.8270e-01, time/batch = 15.9683s	
7739/25300 (epoch 15.294), train_loss = 1.11153722, grad/param norm = 1.8130e-01, time/batch = 17.1373s	
7740/25300 (epoch 15.296), train_loss = 0.97003569, grad/param norm = 1.8302e-01, time/batch = 16.1555s	
7741/25300 (epoch 15.298), train_loss = 1.18699950, grad/param norm = 1.8983e-01, time/batch = 17.4576s	
7742/25300 (epoch 15.300), train_loss = 1.19892523, grad/param norm = 1.8760e-01, time/batch = 17.6450s	
7743/25300 (epoch 15.302), train_loss = 0.89735058, grad/param norm = 1.8526e-01, time/batch = 17.3942s	
7744/25300 (epoch 15.304), train_loss = 1.14992390, grad/param norm = 1.7735e-01, time/batch = 18.1243s	
7745/25300 (epoch 15.306), train_loss = 0.85086943, grad/param norm = 1.6357e-01, time/batch = 16.0405s	
7746/25300 (epoch 15.308), train_loss = 1.13332144, grad/param norm = 1.6450e-01, time/batch = 15.3877s	
7747/25300 (epoch 15.310), train_loss = 1.00608350, grad/param norm = 1.8518e-01, time/batch = 15.6304s	
7748/25300 (epoch 15.312), train_loss = 1.07609508, grad/param norm = 1.6046e-01, time/batch = 16.5573s	
7749/25300 (epoch 15.314), train_loss = 0.89790243, grad/param norm = 1.7085e-01, time/batch = 16.1137s	
7750/25300 (epoch 15.316), train_loss = 1.12276614, grad/param norm = 1.7822e-01, time/batch = 16.2931s	
7751/25300 (epoch 15.318), train_loss = 0.85675922, grad/param norm = 1.6213e-01, time/batch = 17.8805s	
7752/25300 (epoch 15.320), train_loss = 0.94967165, grad/param norm = 1.7048e-01, time/batch = 16.8827s	
7753/25300 (epoch 15.322), train_loss = 1.31319848, grad/param norm = 2.1842e-01, time/batch = 16.2327s	
7754/25300 (epoch 15.324), train_loss = 0.96360034, grad/param norm = 1.5888e-01, time/batch = 16.1508s	
7755/25300 (epoch 15.326), train_loss = 0.86136020, grad/param norm = 1.5639e-01, time/batch = 16.4791s	
7756/25300 (epoch 15.328), train_loss = 0.86384273, grad/param norm = 1.6938e-01, time/batch = 15.7156s	
7757/25300 (epoch 15.330), train_loss = 1.03948978, grad/param norm = 1.8215e-01, time/batch = 15.8967s	
7758/25300 (epoch 15.332), train_loss = 1.07576576, grad/param norm = 1.5581e-01, time/batch = 16.0723s	
7759/25300 (epoch 15.334), train_loss = 0.88890104, grad/param norm = 1.5214e-01, time/batch = 16.9057s	
7760/25300 (epoch 15.336), train_loss = 0.91885252, grad/param norm = 1.6397e-01, time/batch = 16.0616s	
7761/25300 (epoch 15.338), train_loss = 0.90189220, grad/param norm = 1.6661e-01, time/batch = 18.9790s	
7762/25300 (epoch 15.340), train_loss = 1.02437254, grad/param norm = 1.9706e-01, time/batch = 18.6400s	
7763/25300 (epoch 15.342), train_loss = 1.02322510, grad/param norm = 1.8589e-01, time/batch = 16.4596s	
7764/25300 (epoch 15.344), train_loss = 1.07239838, grad/param norm = 1.7494e-01, time/batch = 15.9514s	
7765/25300 (epoch 15.346), train_loss = 1.04455911, grad/param norm = 1.9113e-01, time/batch = 16.0777s	
7766/25300 (epoch 15.348), train_loss = 0.93969509, grad/param norm = 1.6777e-01, time/batch = 17.8067s	
7767/25300 (epoch 15.350), train_loss = 1.00984129, grad/param norm = 1.7106e-01, time/batch = 17.3155s	
7768/25300 (epoch 15.352), train_loss = 1.06115590, grad/param norm = 1.7009e-01, time/batch = 15.8891s	
7769/25300 (epoch 15.354), train_loss = 0.98019027, grad/param norm = 1.7472e-01, time/batch = 16.7357s	
7770/25300 (epoch 15.356), train_loss = 1.07250158, grad/param norm = 1.9278e-01, time/batch = 15.5478s	
7771/25300 (epoch 15.358), train_loss = 1.18258597, grad/param norm = 2.0706e-01, time/batch = 17.6446s	
7772/25300 (epoch 15.360), train_loss = 0.97010225, grad/param norm = 1.7061e-01, time/batch = 15.4725s	
7773/25300 (epoch 15.362), train_loss = 0.98912092, grad/param norm = 1.7714e-01, time/batch = 18.0673s	
7774/25300 (epoch 15.364), train_loss = 1.06020630, grad/param norm = 1.7290e-01, time/batch = 16.8834s	
7775/25300 (epoch 15.366), train_loss = 0.92025374, grad/param norm = 1.7140e-01, time/batch = 19.4531s	
7776/25300 (epoch 15.368), train_loss = 1.00508919, grad/param norm = 1.6075e-01, time/batch = 17.7928s	
7777/25300 (epoch 15.370), train_loss = 1.01248269, grad/param norm = 1.8913e-01, time/batch = 16.5561s	
7778/25300 (epoch 15.372), train_loss = 0.99167643, grad/param norm = 1.7034e-01, time/batch = 18.5446s	
7779/25300 (epoch 15.374), train_loss = 0.93062494, grad/param norm = 1.7017e-01, time/batch = 18.8798s	
7780/25300 (epoch 15.375), train_loss = 1.21521595, grad/param norm = 1.9978e-01, time/batch = 17.7847s	
7781/25300 (epoch 15.377), train_loss = 1.09568475, grad/param norm = 2.0594e-01, time/batch = 16.4746s	
7782/25300 (epoch 15.379), train_loss = 1.11956967, grad/param norm = 1.9443e-01, time/batch = 16.5599s	
7783/25300 (epoch 15.381), train_loss = 1.07331568, grad/param norm = 1.7948e-01, time/batch = 19.2950s	
7784/25300 (epoch 15.383), train_loss = 0.95629721, grad/param norm = 1.6623e-01, time/batch = 16.4603s	
7785/25300 (epoch 15.385), train_loss = 1.04119681, grad/param norm = 1.7782e-01, time/batch = 18.0472s	
7786/25300 (epoch 15.387), train_loss = 1.09270760, grad/param norm = 1.8222e-01, time/batch = 19.8660s	
7787/25300 (epoch 15.389), train_loss = 1.15301668, grad/param norm = 1.9506e-01, time/batch = 17.0315s	
7788/25300 (epoch 15.391), train_loss = 0.97668627, grad/param norm = 1.5725e-01, time/batch = 17.4413s	
7789/25300 (epoch 15.393), train_loss = 1.08227772, grad/param norm = 2.0800e-01, time/batch = 16.5582s	
7790/25300 (epoch 15.395), train_loss = 0.91207594, grad/param norm = 1.6064e-01, time/batch = 17.0600s	
7791/25300 (epoch 15.397), train_loss = 0.93514107, grad/param norm = 1.8485e-01, time/batch = 18.3784s	
7792/25300 (epoch 15.399), train_loss = 0.93469856, grad/param norm = 1.8388e-01, time/batch = 17.7344s	
7793/25300 (epoch 15.401), train_loss = 1.16841997, grad/param norm = 2.0617e-01, time/batch = 18.0563s	
7794/25300 (epoch 15.403), train_loss = 1.06769913, grad/param norm = 2.3193e-01, time/batch = 16.9724s	
7795/25300 (epoch 15.405), train_loss = 1.07139812, grad/param norm = 1.9193e-01, time/batch = 18.2102s	
7796/25300 (epoch 15.407), train_loss = 0.98992676, grad/param norm = 1.6474e-01, time/batch = 18.6196s	
7797/25300 (epoch 15.409), train_loss = 0.96286637, grad/param norm = 1.6939e-01, time/batch = 18.2595s	
7798/25300 (epoch 15.411), train_loss = 0.99213923, grad/param norm = 1.8271e-01, time/batch = 24.8734s	
7799/25300 (epoch 15.413), train_loss = 0.91441112, grad/param norm = 1.6931e-01, time/batch = 17.2979s	
7800/25300 (epoch 15.415), train_loss = 0.92924333, grad/param norm = 1.9042e-01, time/batch = 15.7193s	
7801/25300 (epoch 15.417), train_loss = 0.88279404, grad/param norm = 1.6694e-01, time/batch = 15.7897s	
7802/25300 (epoch 15.419), train_loss = 0.85648431, grad/param norm = 1.5815e-01, time/batch = 15.7070s	
7803/25300 (epoch 15.421), train_loss = 0.88406635, grad/param norm = 1.5471e-01, time/batch = 15.3799s	
7804/25300 (epoch 15.423), train_loss = 0.92624555, grad/param norm = 1.7328e-01, time/batch = 15.3397s	
7805/25300 (epoch 15.425), train_loss = 1.01950451, grad/param norm = 1.9567e-01, time/batch = 15.2058s	
7806/25300 (epoch 15.427), train_loss = 1.24186815, grad/param norm = 2.0538e-01, time/batch = 15.3071s	
7807/25300 (epoch 15.429), train_loss = 1.15192745, grad/param norm = 1.9208e-01, time/batch = 15.3592s	
7808/25300 (epoch 15.431), train_loss = 1.07087082, grad/param norm = 1.8184e-01, time/batch = 15.3491s	
7809/25300 (epoch 15.433), train_loss = 1.01020607, grad/param norm = 1.7395e-01, time/batch = 15.2969s	
7810/25300 (epoch 15.435), train_loss = 0.96755645, grad/param norm = 1.9155e-01, time/batch = 15.2924s	
7811/25300 (epoch 15.437), train_loss = 0.99649809, grad/param norm = 1.8801e-01, time/batch = 17.3183s	
7812/25300 (epoch 15.439), train_loss = 1.05528188, grad/param norm = 1.7244e-01, time/batch = 16.4528s	
7813/25300 (epoch 15.441), train_loss = 1.09197501, grad/param norm = 1.9056e-01, time/batch = 18.2921s	
7814/25300 (epoch 15.443), train_loss = 1.30408278, grad/param norm = 2.2113e-01, time/batch = 17.7174s	
7815/25300 (epoch 15.445), train_loss = 1.23005283, grad/param norm = 1.9970e-01, time/batch = 16.3836s	
7816/25300 (epoch 15.447), train_loss = 0.94823705, grad/param norm = 1.5924e-01, time/batch = 16.0590s	
7817/25300 (epoch 15.449), train_loss = 0.86917076, grad/param norm = 1.8378e-01, time/batch = 15.8837s	
7818/25300 (epoch 15.451), train_loss = 1.22952147, grad/param norm = 1.9303e-01, time/batch = 18.2107s	
7819/25300 (epoch 15.453), train_loss = 1.13845995, grad/param norm = 2.1434e-01, time/batch = 15.6395s	
7820/25300 (epoch 15.455), train_loss = 1.15081091, grad/param norm = 1.9275e-01, time/batch = 16.5224s	
7821/25300 (epoch 15.457), train_loss = 1.00817856, grad/param norm = 1.7544e-01, time/batch = 15.3819s	
7822/25300 (epoch 15.458), train_loss = 1.08171764, grad/param norm = 2.0543e-01, time/batch = 16.9679s	
7823/25300 (epoch 15.460), train_loss = 1.07109283, grad/param norm = 1.8737e-01, time/batch = 16.8776s	
7824/25300 (epoch 15.462), train_loss = 0.82137136, grad/param norm = 1.7166e-01, time/batch = 16.5605s	
7825/25300 (epoch 15.464), train_loss = 1.12851392, grad/param norm = 1.9352e-01, time/batch = 15.9763s	
7826/25300 (epoch 15.466), train_loss = 1.13519035, grad/param norm = 1.8207e-01, time/batch = 15.7026s	
7827/25300 (epoch 15.468), train_loss = 1.14636137, grad/param norm = 1.8350e-01, time/batch = 17.5583s	
7828/25300 (epoch 15.470), train_loss = 0.96265763, grad/param norm = 1.6725e-01, time/batch = 17.2257s	
7829/25300 (epoch 15.472), train_loss = 0.87602810, grad/param norm = 1.5775e-01, time/batch = 17.4641s	
7830/25300 (epoch 15.474), train_loss = 1.07976161, grad/param norm = 1.7771e-01, time/batch = 16.6532s	
7831/25300 (epoch 15.476), train_loss = 1.01503122, grad/param norm = 1.7650e-01, time/batch = 19.0492s	
7832/25300 (epoch 15.478), train_loss = 1.11393977, grad/param norm = 1.8382e-01, time/batch = 17.2134s	
7833/25300 (epoch 15.480), train_loss = 0.96282477, grad/param norm = 1.6509e-01, time/batch = 15.9687s	
7834/25300 (epoch 15.482), train_loss = 1.13150765, grad/param norm = 1.9746e-01, time/batch = 16.7217s	
7835/25300 (epoch 15.484), train_loss = 1.13320414, grad/param norm = 1.9744e-01, time/batch = 16.4696s	
7836/25300 (epoch 15.486), train_loss = 1.05597468, grad/param norm = 1.7789e-01, time/batch = 17.7254s	
7837/25300 (epoch 15.488), train_loss = 1.20587624, grad/param norm = 1.8760e-01, time/batch = 17.9586s	
7838/25300 (epoch 15.490), train_loss = 1.12187896, grad/param norm = 1.7632e-01, time/batch = 16.1246s	
7839/25300 (epoch 15.492), train_loss = 1.05360079, grad/param norm = 1.8301e-01, time/batch = 15.2772s	
7840/25300 (epoch 15.494), train_loss = 0.97011571, grad/param norm = 1.7363e-01, time/batch = 15.8735s	
7841/25300 (epoch 15.496), train_loss = 1.05723830, grad/param norm = 1.8868e-01, time/batch = 17.6258s	
7842/25300 (epoch 15.498), train_loss = 0.97635512, grad/param norm = 1.7036e-01, time/batch = 17.5697s	
7843/25300 (epoch 15.500), train_loss = 1.18692803, grad/param norm = 1.9942e-01, time/batch = 17.2259s	
7844/25300 (epoch 15.502), train_loss = 1.08106877, grad/param norm = 1.9171e-01, time/batch = 15.7197s	
7845/25300 (epoch 15.504), train_loss = 1.01900297, grad/param norm = 1.8653e-01, time/batch = 19.2176s	
7846/25300 (epoch 15.506), train_loss = 1.00327812, grad/param norm = 1.8639e-01, time/batch = 19.1277s	
7847/25300 (epoch 15.508), train_loss = 1.07519389, grad/param norm = 1.8772e-01, time/batch = 16.4806s	
7848/25300 (epoch 15.510), train_loss = 0.97900975, grad/param norm = 1.8075e-01, time/batch = 18.9681s	
7849/25300 (epoch 15.512), train_loss = 0.79717623, grad/param norm = 1.5964e-01, time/batch = 17.4762s	
7850/25300 (epoch 15.514), train_loss = 1.00259748, grad/param norm = 1.6035e-01, time/batch = 17.4651s	
7851/25300 (epoch 15.516), train_loss = 1.08439975, grad/param norm = 1.8161e-01, time/batch = 15.8887s	
7852/25300 (epoch 15.518), train_loss = 1.16279860, grad/param norm = 2.0616e-01, time/batch = 17.7187s	
7853/25300 (epoch 15.520), train_loss = 0.88054732, grad/param norm = 1.5747e-01, time/batch = 17.0678s	
7854/25300 (epoch 15.522), train_loss = 0.97830568, grad/param norm = 1.7464e-01, time/batch = 15.9597s	
7855/25300 (epoch 15.524), train_loss = 1.02553948, grad/param norm = 1.7279e-01, time/batch = 20.1167s	
7856/25300 (epoch 15.526), train_loss = 1.25589318, grad/param norm = 1.9664e-01, time/batch = 17.4619s	
7857/25300 (epoch 15.528), train_loss = 1.18428656, grad/param norm = 1.8939e-01, time/batch = 15.9404s	
7858/25300 (epoch 15.530), train_loss = 1.06492101, grad/param norm = 1.8409e-01, time/batch = 17.2281s	
7859/25300 (epoch 15.532), train_loss = 1.06068191, grad/param norm = 1.7929e-01, time/batch = 18.3152s	
7860/25300 (epoch 15.534), train_loss = 1.03387000, grad/param norm = 1.8210e-01, time/batch = 17.8098s	
7861/25300 (epoch 15.536), train_loss = 0.85282642, grad/param norm = 1.6537e-01, time/batch = 18.5304s	
7862/25300 (epoch 15.538), train_loss = 0.89577729, grad/param norm = 1.4279e-01, time/batch = 16.6628s	
7863/25300 (epoch 15.540), train_loss = 0.96308457, grad/param norm = 1.7730e-01, time/batch = 17.8030s	
7864/25300 (epoch 15.542), train_loss = 0.91151780, grad/param norm = 1.5710e-01, time/batch = 16.6365s	
7865/25300 (epoch 15.543), train_loss = 0.88406561, grad/param norm = 1.7490e-01, time/batch = 15.8973s	
7866/25300 (epoch 15.545), train_loss = 1.35396583, grad/param norm = 2.1268e-01, time/batch = 18.1450s	
7867/25300 (epoch 15.547), train_loss = 1.09026246, grad/param norm = 1.8821e-01, time/batch = 17.7176s	
7868/25300 (epoch 15.549), train_loss = 1.31164729, grad/param norm = 2.2306e-01, time/batch = 15.2198s	
7869/25300 (epoch 15.551), train_loss = 1.12121843, grad/param norm = 1.7929e-01, time/batch = 16.2311s	
7870/25300 (epoch 15.553), train_loss = 0.96988187, grad/param norm = 1.6545e-01, time/batch = 16.1301s	
7871/25300 (epoch 15.555), train_loss = 1.17563377, grad/param norm = 2.1736e-01, time/batch = 17.7894s	
7872/25300 (epoch 15.557), train_loss = 1.19915665, grad/param norm = 1.9987e-01, time/batch = 17.5631s	
7873/25300 (epoch 15.559), train_loss = 1.16487463, grad/param norm = 1.9446e-01, time/batch = 17.2944s	
7874/25300 (epoch 15.561), train_loss = 1.21833595, grad/param norm = 1.9313e-01, time/batch = 17.2967s	
7875/25300 (epoch 15.563), train_loss = 1.16216752, grad/param norm = 1.8659e-01, time/batch = 16.2166s	
7876/25300 (epoch 15.565), train_loss = 0.90376988, grad/param norm = 1.6700e-01, time/batch = 17.5516s	
7877/25300 (epoch 15.567), train_loss = 0.80216879, grad/param norm = 1.6126e-01, time/batch = 15.8849s	
7878/25300 (epoch 15.569), train_loss = 1.06725815, grad/param norm = 1.9175e-01, time/batch = 16.5507s	
7879/25300 (epoch 15.571), train_loss = 1.17118609, grad/param norm = 2.0931e-01, time/batch = 17.0583s	
7880/25300 (epoch 15.573), train_loss = 1.04002694, grad/param norm = 1.7924e-01, time/batch = 15.3313s	
7881/25300 (epoch 15.575), train_loss = 1.15025394, grad/param norm = 1.8915e-01, time/batch = 17.0524s	
7882/25300 (epoch 15.577), train_loss = 1.08355671, grad/param norm = 1.8090e-01, time/batch = 16.0413s	
7883/25300 (epoch 15.579), train_loss = 1.24534503, grad/param norm = 2.0854e-01, time/batch = 16.5005s	
7884/25300 (epoch 15.581), train_loss = 1.11803857, grad/param norm = 1.9155e-01, time/batch = 18.8836s	
7885/25300 (epoch 15.583), train_loss = 0.90541124, grad/param norm = 1.8323e-01, time/batch = 16.2959s	
7886/25300 (epoch 15.585), train_loss = 0.89299154, grad/param norm = 1.9068e-01, time/batch = 17.6399s	
7887/25300 (epoch 15.587), train_loss = 1.01813342, grad/param norm = 1.7928e-01, time/batch = 16.0587s	
7888/25300 (epoch 15.589), train_loss = 0.92310514, grad/param norm = 1.5937e-01, time/batch = 17.7285s	
7889/25300 (epoch 15.591), train_loss = 0.92479746, grad/param norm = 1.8145e-01, time/batch = 16.2177s	
7890/25300 (epoch 15.593), train_loss = 1.09851906, grad/param norm = 1.7659e-01, time/batch = 17.0598s	
7891/25300 (epoch 15.595), train_loss = 1.04872857, grad/param norm = 1.9127e-01, time/batch = 18.8826s	
7892/25300 (epoch 15.597), train_loss = 0.88561448, grad/param norm = 1.4932e-01, time/batch = 16.3775s	
7893/25300 (epoch 15.599), train_loss = 1.06893345, grad/param norm = 1.8572e-01, time/batch = 17.1240s	
7894/25300 (epoch 15.601), train_loss = 1.07408975, grad/param norm = 1.9102e-01, time/batch = 18.8843s	
7895/25300 (epoch 15.603), train_loss = 1.06810080, grad/param norm = 1.8212e-01, time/batch = 19.0509s	
7896/25300 (epoch 15.605), train_loss = 0.96375161, grad/param norm = 1.7980e-01, time/batch = 18.2102s	
7897/25300 (epoch 15.607), train_loss = 0.78704558, grad/param norm = 1.5235e-01, time/batch = 18.6345s	
7898/25300 (epoch 15.609), train_loss = 1.01099025, grad/param norm = 1.7941e-01, time/batch = 18.3060s	
7899/25300 (epoch 15.611), train_loss = 1.10387804, grad/param norm = 1.8669e-01, time/batch = 16.7329s	
7900/25300 (epoch 15.613), train_loss = 0.90397040, grad/param norm = 1.8123e-01, time/batch = 18.7142s	
7901/25300 (epoch 15.615), train_loss = 1.01591371, grad/param norm = 2.0342e-01, time/batch = 18.9665s	
7902/25300 (epoch 15.617), train_loss = 1.05551686, grad/param norm = 2.0772e-01, time/batch = 16.8879s	
7903/25300 (epoch 15.619), train_loss = 1.14186590, grad/param norm = 2.0613e-01, time/batch = 17.1330s	
7904/25300 (epoch 15.621), train_loss = 1.17268920, grad/param norm = 2.0638e-01, time/batch = 15.8026s	
7905/25300 (epoch 15.623), train_loss = 0.98355411, grad/param norm = 1.7469e-01, time/batch = 15.7192s	
7906/25300 (epoch 15.625), train_loss = 0.87016127, grad/param norm = 1.7180e-01, time/batch = 16.3094s	
7907/25300 (epoch 15.626), train_loss = 0.98556003, grad/param norm = 1.7451e-01, time/batch = 15.7317s	
7908/25300 (epoch 15.628), train_loss = 1.12954310, grad/param norm = 1.9611e-01, time/batch = 18.1316s	
7909/25300 (epoch 15.630), train_loss = 1.14093610, grad/param norm = 2.2629e-01, time/batch = 17.4723s	
7910/25300 (epoch 15.632), train_loss = 1.07480167, grad/param norm = 1.8664e-01, time/batch = 16.8000s	
7911/25300 (epoch 15.634), train_loss = 1.15270711, grad/param norm = 1.9907e-01, time/batch = 20.1149s	
7912/25300 (epoch 15.636), train_loss = 1.00359788, grad/param norm = 1.8556e-01, time/batch = 18.3885s	
7913/25300 (epoch 15.638), train_loss = 1.11402710, grad/param norm = 2.0585e-01, time/batch = 16.5456s	
7914/25300 (epoch 15.640), train_loss = 1.23474910, grad/param norm = 2.1387e-01, time/batch = 17.8118s	
7915/25300 (epoch 15.642), train_loss = 1.10494351, grad/param norm = 1.9485e-01, time/batch = 16.1209s	
7916/25300 (epoch 15.644), train_loss = 1.08896724, grad/param norm = 2.0391e-01, time/batch = 16.1395s	
7917/25300 (epoch 15.646), train_loss = 1.02678534, grad/param norm = 1.9310e-01, time/batch = 17.2149s	
7918/25300 (epoch 15.648), train_loss = 1.14151777, grad/param norm = 1.8280e-01, time/batch = 18.4824s	
7919/25300 (epoch 15.650), train_loss = 1.09253820, grad/param norm = 1.9506e-01, time/batch = 19.2982s	
7920/25300 (epoch 15.652), train_loss = 1.08550186, grad/param norm = 2.0852e-01, time/batch = 16.4824s	
7921/25300 (epoch 15.654), train_loss = 1.20723358, grad/param norm = 1.9130e-01, time/batch = 16.5467s	
7922/25300 (epoch 15.656), train_loss = 1.14159471, grad/param norm = 2.0466e-01, time/batch = 19.2940s	
7923/25300 (epoch 15.658), train_loss = 0.89977573, grad/param norm = 1.7247e-01, time/batch = 16.4746s	
7924/25300 (epoch 15.660), train_loss = 0.94181581, grad/param norm = 1.7997e-01, time/batch = 20.2213s	
7925/25300 (epoch 15.662), train_loss = 0.91175607, grad/param norm = 1.7240e-01, time/batch = 17.4886s	
7926/25300 (epoch 15.664), train_loss = 0.87350160, grad/param norm = 1.7275e-01, time/batch = 16.3914s	
7927/25300 (epoch 15.666), train_loss = 0.90463898, grad/param norm = 1.6267e-01, time/batch = 15.6998s	
7928/25300 (epoch 15.668), train_loss = 1.01890763, grad/param norm = 2.5100e-01, time/batch = 17.8030s	
7929/25300 (epoch 15.670), train_loss = 0.91680361, grad/param norm = 1.9506e-01, time/batch = 16.2269s	
7930/25300 (epoch 15.672), train_loss = 0.95039879, grad/param norm = 1.7776e-01, time/batch = 17.6293s	
7931/25300 (epoch 15.674), train_loss = 0.96582824, grad/param norm = 2.0806e-01, time/batch = 20.2127s	
7932/25300 (epoch 15.676), train_loss = 1.01811080, grad/param norm = 1.8701e-01, time/batch = 17.7269s	
7933/25300 (epoch 15.678), train_loss = 0.99020955, grad/param norm = 1.9939e-01, time/batch = 15.7187s	
7934/25300 (epoch 15.680), train_loss = 0.87057824, grad/param norm = 1.6400e-01, time/batch = 16.5356s	
7935/25300 (epoch 15.682), train_loss = 0.74508603, grad/param norm = 1.6437e-01, time/batch = 19.3950s	
7936/25300 (epoch 15.684), train_loss = 0.89683642, grad/param norm = 1.5988e-01, time/batch = 18.7912s	
7937/25300 (epoch 15.686), train_loss = 0.88947477, grad/param norm = 1.6412e-01, time/batch = 16.2222s	
7938/25300 (epoch 15.688), train_loss = 1.00728531, grad/param norm = 1.8531e-01, time/batch = 16.5621s	
7939/25300 (epoch 15.690), train_loss = 0.90311605, grad/param norm = 1.5554e-01, time/batch = 18.5504s	
7940/25300 (epoch 15.692), train_loss = 1.01594247, grad/param norm = 1.7185e-01, time/batch = 15.7201s	
7941/25300 (epoch 15.694), train_loss = 0.94863810, grad/param norm = 1.6856e-01, time/batch = 17.3890s	
7942/25300 (epoch 15.696), train_loss = 1.03344585, grad/param norm = 1.8188e-01, time/batch = 16.6494s	
7943/25300 (epoch 15.698), train_loss = 1.10066862, grad/param norm = 1.9239e-01, time/batch = 17.8772s	
7944/25300 (epoch 15.700), train_loss = 0.83860754, grad/param norm = 1.6866e-01, time/batch = 15.7207s	
7945/25300 (epoch 15.702), train_loss = 1.13254801, grad/param norm = 1.8783e-01, time/batch = 16.4792s	
7946/25300 (epoch 15.704), train_loss = 0.82718385, grad/param norm = 1.6593e-01, time/batch = 17.4774s	
7947/25300 (epoch 15.706), train_loss = 1.03937991, grad/param norm = 1.9141e-01, time/batch = 16.6306s	
7948/25300 (epoch 15.708), train_loss = 0.85399202, grad/param norm = 1.6099e-01, time/batch = 16.2332s	
7949/25300 (epoch 15.709), train_loss = 1.20480860, grad/param norm = 1.8906e-01, time/batch = 15.2946s	
7950/25300 (epoch 15.711), train_loss = 1.22802168, grad/param norm = 2.1022e-01, time/batch = 17.7365s	
7951/25300 (epoch 15.713), train_loss = 0.98821585, grad/param norm = 1.6507e-01, time/batch = 15.5480s	
7952/25300 (epoch 15.715), train_loss = 1.01814220, grad/param norm = 1.7487e-01, time/batch = 16.5625s	
7953/25300 (epoch 15.717), train_loss = 0.96601860, grad/param norm = 1.9565e-01, time/batch = 16.9093s	
7954/25300 (epoch 15.719), train_loss = 0.99959493, grad/param norm = 1.7857e-01, time/batch = 16.8809s	
7955/25300 (epoch 15.721), train_loss = 1.04970758, grad/param norm = 1.9370e-01, time/batch = 15.5452s	
7956/25300 (epoch 15.723), train_loss = 0.98278659, grad/param norm = 1.7874e-01, time/batch = 16.8213s	
7957/25300 (epoch 15.725), train_loss = 1.08088616, grad/param norm = 2.0074e-01, time/batch = 15.9756s	
7958/25300 (epoch 15.727), train_loss = 1.07062672, grad/param norm = 1.8303e-01, time/batch = 15.6017s	
7959/25300 (epoch 15.729), train_loss = 1.01380493, grad/param norm = 1.7038e-01, time/batch = 15.3107s	
7960/25300 (epoch 15.731), train_loss = 1.20956825, grad/param norm = 1.9175e-01, time/batch = 15.4743s	
7961/25300 (epoch 15.733), train_loss = 0.99265447, grad/param norm = 1.5639e-01, time/batch = 15.3897s	
7962/25300 (epoch 15.735), train_loss = 1.34370419, grad/param norm = 2.0583e-01, time/batch = 15.5246s	
7963/25300 (epoch 15.737), train_loss = 0.87921468, grad/param norm = 1.6112e-01, time/batch = 15.5255s	
7964/25300 (epoch 15.739), train_loss = 1.16590135, grad/param norm = 1.8225e-01, time/batch = 15.5356s	
7965/25300 (epoch 15.741), train_loss = 1.10101609, grad/param norm = 2.0075e-01, time/batch = 15.4641s	
7966/25300 (epoch 15.743), train_loss = 0.98774037, grad/param norm = 1.7735e-01, time/batch = 15.7967s	
7967/25300 (epoch 15.745), train_loss = 0.94093810, grad/param norm = 1.6274e-01, time/batch = 17.3004s	
7968/25300 (epoch 15.747), train_loss = 0.90902281, grad/param norm = 1.6176e-01, time/batch = 15.8021s	
7969/25300 (epoch 15.749), train_loss = 1.06465947, grad/param norm = 1.8107e-01, time/batch = 16.6860s	
7970/25300 (epoch 15.751), train_loss = 1.13837507, grad/param norm = 1.9364e-01, time/batch = 16.5582s	
7971/25300 (epoch 15.753), train_loss = 0.96098025, grad/param norm = 1.9253e-01, time/batch = 17.6391s	
7972/25300 (epoch 15.755), train_loss = 1.16057942, grad/param norm = 2.1276e-01, time/batch = 18.7265s	
7973/25300 (epoch 15.757), train_loss = 0.94752574, grad/param norm = 1.7531e-01, time/batch = 15.7101s	
7974/25300 (epoch 15.759), train_loss = 0.95780523, grad/param norm = 1.8043e-01, time/batch = 16.9905s	
7975/25300 (epoch 15.761), train_loss = 1.17700246, grad/param norm = 1.8622e-01, time/batch = 17.0678s	
7976/25300 (epoch 15.763), train_loss = 0.95483836, grad/param norm = 1.7358e-01, time/batch = 17.7103s	
7977/25300 (epoch 15.765), train_loss = 0.96975850, grad/param norm = 1.7564e-01, time/batch = 17.2192s	
7978/25300 (epoch 15.767), train_loss = 0.96538220, grad/param norm = 1.7509e-01, time/batch = 16.3982s	
7979/25300 (epoch 15.769), train_loss = 1.07890748, grad/param norm = 1.9028e-01, time/batch = 16.9534s	
7980/25300 (epoch 15.771), train_loss = 1.17767511, grad/param norm = 1.9482e-01, time/batch = 15.9649s	
7981/25300 (epoch 15.773), train_loss = 1.15216915, grad/param norm = 2.0025e-01, time/batch = 15.4791s	
7982/25300 (epoch 15.775), train_loss = 0.99035934, grad/param norm = 1.5894e-01, time/batch = 15.9804s	
7983/25300 (epoch 15.777), train_loss = 1.04531212, grad/param norm = 1.8993e-01, time/batch = 16.0732s	
7984/25300 (epoch 15.779), train_loss = 1.10849009, grad/param norm = 1.6876e-01, time/batch = 15.4585s	
7985/25300 (epoch 15.781), train_loss = 1.07208226, grad/param norm = 1.7355e-01, time/batch = 17.8850s	
7986/25300 (epoch 15.783), train_loss = 1.18984754, grad/param norm = 1.9889e-01, time/batch = 16.3127s	
7987/25300 (epoch 15.785), train_loss = 1.13475760, grad/param norm = 1.8189e-01, time/batch = 16.2355s	
7988/25300 (epoch 15.787), train_loss = 1.12460428, grad/param norm = 1.9212e-01, time/batch = 15.8853s	
7989/25300 (epoch 15.789), train_loss = 1.26085670, grad/param norm = 2.0234e-01, time/batch = 16.8232s	
7990/25300 (epoch 15.791), train_loss = 1.11627065, grad/param norm = 2.1017e-01, time/batch = 17.9748s	
7991/25300 (epoch 15.792), train_loss = 1.15944966, grad/param norm = 1.7873e-01, time/batch = 15.9550s	
7992/25300 (epoch 15.794), train_loss = 1.05820972, grad/param norm = 1.8891e-01, time/batch = 17.6297s	
7993/25300 (epoch 15.796), train_loss = 1.00189767, grad/param norm = 1.9174e-01, time/batch = 15.7969s	
7994/25300 (epoch 15.798), train_loss = 1.18992927, grad/param norm = 2.0456e-01, time/batch = 17.7077s	
7995/25300 (epoch 15.800), train_loss = 1.03903679, grad/param norm = 1.7220e-01, time/batch = 16.9688s	
7996/25300 (epoch 15.802), train_loss = 0.84140133, grad/param norm = 1.7269e-01, time/batch = 17.8196s	
7997/25300 (epoch 15.804), train_loss = 1.06830276, grad/param norm = 1.7979e-01, time/batch = 17.1409s	
7998/25300 (epoch 15.806), train_loss = 1.12752937, grad/param norm = 1.9767e-01, time/batch = 16.0583s	
7999/25300 (epoch 15.808), train_loss = 1.10443153, grad/param norm = 1.9962e-01, time/batch = 16.1429s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch15.81_1.5228.t7	
8000/25300 (epoch 15.810), train_loss = 1.05064631, grad/param norm = 2.0165e-01, time/batch = 17.2141s	
8001/25300 (epoch 15.812), train_loss = 1.38745313, grad/param norm = 2.2009e-01, time/batch = 19.4636s	
8002/25300 (epoch 15.814), train_loss = 1.22855558, grad/param norm = 2.1441e-01, time/batch = 25.7549s	
8003/25300 (epoch 15.816), train_loss = 1.33010065, grad/param norm = 2.0373e-01, time/batch = 22.3520s	
8004/25300 (epoch 15.818), train_loss = 1.11101593, grad/param norm = 1.7858e-01, time/batch = 16.2250s	
8005/25300 (epoch 15.820), train_loss = 1.12312784, grad/param norm = 1.9555e-01, time/batch = 16.4583s	
8006/25300 (epoch 15.822), train_loss = 1.03914208, grad/param norm = 1.6801e-01, time/batch = 16.6381s	
8007/25300 (epoch 15.824), train_loss = 1.13059718, grad/param norm = 1.9073e-01, time/batch = 16.9603s	
8008/25300 (epoch 15.826), train_loss = 0.99561803, grad/param norm = 1.8670e-01, time/batch = 17.0469s	
8009/25300 (epoch 15.828), train_loss = 0.98285795, grad/param norm = 1.8046e-01, time/batch = 17.8940s	
8010/25300 (epoch 15.830), train_loss = 1.07329521, grad/param norm = 1.7755e-01, time/batch = 16.1279s	
8011/25300 (epoch 15.832), train_loss = 1.10792985, grad/param norm = 1.8737e-01, time/batch = 18.5577s	
8012/25300 (epoch 15.834), train_loss = 0.91471324, grad/param norm = 1.6147e-01, time/batch = 16.1405s	
8013/25300 (epoch 15.836), train_loss = 0.99581749, grad/param norm = 1.7963e-01, time/batch = 18.3910s	
8014/25300 (epoch 15.838), train_loss = 1.02214541, grad/param norm = 1.7161e-01, time/batch = 18.5560s	
8015/25300 (epoch 15.840), train_loss = 1.18470180, grad/param norm = 1.9509e-01, time/batch = 16.6337s	
8016/25300 (epoch 15.842), train_loss = 1.07273854, grad/param norm = 2.2890e-01, time/batch = 18.2845s	
8017/25300 (epoch 15.844), train_loss = 1.10261420, grad/param norm = 1.7391e-01, time/batch = 19.1213s	
8018/25300 (epoch 15.846), train_loss = 1.10641325, grad/param norm = 1.7954e-01, time/batch = 17.8831s	
8019/25300 (epoch 15.848), train_loss = 1.17897794, grad/param norm = 1.9373e-01, time/batch = 16.4788s	
8020/25300 (epoch 15.850), train_loss = 1.13424995, grad/param norm = 1.9730e-01, time/batch = 16.0492s	
8021/25300 (epoch 15.852), train_loss = 1.11846779, grad/param norm = 1.8734e-01, time/batch = 18.0642s	
8022/25300 (epoch 15.854), train_loss = 1.22515773, grad/param norm = 2.0492e-01, time/batch = 16.6968s	
8023/25300 (epoch 15.856), train_loss = 1.04155621, grad/param norm = 1.9080e-01, time/batch = 17.3118s	
8024/25300 (epoch 15.858), train_loss = 1.12093944, grad/param norm = 2.0874e-01, time/batch = 17.3194s	
8025/25300 (epoch 15.860), train_loss = 0.89892631, grad/param norm = 1.7366e-01, time/batch = 15.7341s	
8026/25300 (epoch 15.862), train_loss = 1.09999521, grad/param norm = 2.0348e-01, time/batch = 16.9738s	
8027/25300 (epoch 15.864), train_loss = 1.16849146, grad/param norm = 1.8111e-01, time/batch = 16.4798s	
8028/25300 (epoch 15.866), train_loss = 1.08951040, grad/param norm = 1.9530e-01, time/batch = 15.3798s	
8029/25300 (epoch 15.868), train_loss = 1.18335767, grad/param norm = 2.0724e-01, time/batch = 16.1412s	
8030/25300 (epoch 15.870), train_loss = 1.15660102, grad/param norm = 1.7510e-01, time/batch = 17.1443s	
8031/25300 (epoch 15.872), train_loss = 1.16331358, grad/param norm = 2.1541e-01, time/batch = 17.4703s	
8032/25300 (epoch 15.874), train_loss = 1.15559554, grad/param norm = 2.0007e-01, time/batch = 17.2333s	
8033/25300 (epoch 15.875), train_loss = 1.05751484, grad/param norm = 1.7749e-01, time/batch = 15.9604s	
8034/25300 (epoch 15.877), train_loss = 1.01218099, grad/param norm = 1.7567e-01, time/batch = 18.3816s	
8035/25300 (epoch 15.879), train_loss = 1.06543567, grad/param norm = 1.8946e-01, time/batch = 15.6484s	
8036/25300 (epoch 15.881), train_loss = 1.38722283, grad/param norm = 2.5804e-01, time/batch = 17.6201s	
8037/25300 (epoch 15.883), train_loss = 1.32362939, grad/param norm = 1.9398e-01, time/batch = 15.7078s	
8038/25300 (epoch 15.885), train_loss = 1.18351986, grad/param norm = 2.2779e-01, time/batch = 15.8320s	
8039/25300 (epoch 15.887), train_loss = 1.12719725, grad/param norm = 1.9698e-01, time/batch = 17.6451s	
8040/25300 (epoch 15.889), train_loss = 1.26557501, grad/param norm = 2.5298e-01, time/batch = 16.4572s	
8041/25300 (epoch 15.891), train_loss = 1.17664969, grad/param norm = 3.1445e-01, time/batch = 17.3911s	
8042/25300 (epoch 15.893), train_loss = 1.23399906, grad/param norm = 2.4371e-01, time/batch = 16.4799s	
8043/25300 (epoch 15.895), train_loss = 0.84384812, grad/param norm = 1.6673e-01, time/batch = 16.7201s	
8044/25300 (epoch 15.897), train_loss = 0.98580584, grad/param norm = 1.8575e-01, time/batch = 17.4753s	
8045/25300 (epoch 15.899), train_loss = 1.08364749, grad/param norm = 1.8412e-01, time/batch = 18.4618s	
8046/25300 (epoch 15.901), train_loss = 1.12190228, grad/param norm = 1.8249e-01, time/batch = 16.8777s	
8047/25300 (epoch 15.903), train_loss = 0.86972901, grad/param norm = 1.7201e-01, time/batch = 16.3168s	
8048/25300 (epoch 15.905), train_loss = 1.00729991, grad/param norm = 1.9261e-01, time/batch = 18.8055s	
8049/25300 (epoch 15.907), train_loss = 1.04254887, grad/param norm = 2.0236e-01, time/batch = 16.8063s	
8050/25300 (epoch 15.909), train_loss = 1.14609637, grad/param norm = 1.9025e-01, time/batch = 16.6497s	
8051/25300 (epoch 15.911), train_loss = 1.26922724, grad/param norm = 1.9914e-01, time/batch = 17.1429s	
8052/25300 (epoch 15.913), train_loss = 1.30241535, grad/param norm = 2.1188e-01, time/batch = 18.7189s	
8053/25300 (epoch 15.915), train_loss = 1.02518171, grad/param norm = 2.0566e-01, time/batch = 16.8841s	
8054/25300 (epoch 15.917), train_loss = 1.16093481, grad/param norm = 2.1391e-01, time/batch = 16.2920s	
8055/25300 (epoch 15.919), train_loss = 1.25440323, grad/param norm = 2.1169e-01, time/batch = 17.4831s	
8056/25300 (epoch 15.921), train_loss = 0.97622653, grad/param norm = 1.7558e-01, time/batch = 18.4642s	
8057/25300 (epoch 15.923), train_loss = 1.23819622, grad/param norm = 1.9543e-01, time/batch = 16.8828s	
8058/25300 (epoch 15.925), train_loss = 1.05855351, grad/param norm = 1.8893e-01, time/batch = 15.6509s	
8059/25300 (epoch 15.927), train_loss = 1.03108402, grad/param norm = 1.8457e-01, time/batch = 18.0579s	
8060/25300 (epoch 15.929), train_loss = 1.05467797, grad/param norm = 1.8225e-01, time/batch = 18.7162s	
8061/25300 (epoch 15.931), train_loss = 1.16690003, grad/param norm = 1.9814e-01, time/batch = 16.8080s	
8062/25300 (epoch 15.933), train_loss = 1.15756659, grad/param norm = 1.9046e-01, time/batch = 16.4744s	
8063/25300 (epoch 15.935), train_loss = 1.12432704, grad/param norm = 1.8088e-01, time/batch = 15.6537s	
8064/25300 (epoch 15.937), train_loss = 0.82821760, grad/param norm = 1.4892e-01, time/batch = 15.9665s	
8065/25300 (epoch 15.939), train_loss = 1.17389782, grad/param norm = 1.8569e-01, time/batch = 15.9687s	
8066/25300 (epoch 15.941), train_loss = 1.03627378, grad/param norm = 1.9603e-01, time/batch = 15.9000s	
8067/25300 (epoch 15.943), train_loss = 1.09210541, grad/param norm = 1.8099e-01, time/batch = 16.2412s	
8068/25300 (epoch 15.945), train_loss = 1.11657275, grad/param norm = 1.8308e-01, time/batch = 16.5342s	
8069/25300 (epoch 15.947), train_loss = 0.98670684, grad/param norm = 1.8552e-01, time/batch = 19.2201s	
8070/25300 (epoch 15.949), train_loss = 1.13424838, grad/param norm = 1.7782e-01, time/batch = 17.2906s	
8071/25300 (epoch 15.951), train_loss = 1.06079911, grad/param norm = 1.7785e-01, time/batch = 17.4546s	
8072/25300 (epoch 15.953), train_loss = 1.11574815, grad/param norm = 1.7719e-01, time/batch = 17.0552s	
8073/25300 (epoch 15.955), train_loss = 1.34464417, grad/param norm = 2.4718e-01, time/batch = 16.1272s	
8074/25300 (epoch 15.957), train_loss = 1.27594946, grad/param norm = 2.2675e-01, time/batch = 18.7124s	
8075/25300 (epoch 15.958), train_loss = 1.15470224, grad/param norm = 2.0574e-01, time/batch = 15.7872s	
8076/25300 (epoch 15.960), train_loss = 1.30325799, grad/param norm = 2.1434e-01, time/batch = 17.2200s	
8077/25300 (epoch 15.962), train_loss = 1.24234897, grad/param norm = 2.1305e-01, time/batch = 17.7881s	
8078/25300 (epoch 15.964), train_loss = 1.17040513, grad/param norm = 1.9685e-01, time/batch = 17.6182s	
8079/25300 (epoch 15.966), train_loss = 0.91443511, grad/param norm = 1.6607e-01, time/batch = 16.8133s	
8080/25300 (epoch 15.968), train_loss = 0.92010853, grad/param norm = 1.6524e-01, time/batch = 17.3080s	
8081/25300 (epoch 15.970), train_loss = 1.06407750, grad/param norm = 2.0383e-01, time/batch = 17.2042s	
8082/25300 (epoch 15.972), train_loss = 1.10712199, grad/param norm = 1.9310e-01, time/batch = 17.0633s	
8083/25300 (epoch 15.974), train_loss = 1.28064100, grad/param norm = 2.0592e-01, time/batch = 16.7137s	
8084/25300 (epoch 15.976), train_loss = 1.12159225, grad/param norm = 1.9098e-01, time/batch = 16.6514s	
8085/25300 (epoch 15.978), train_loss = 1.11722186, grad/param norm = 1.9751e-01, time/batch = 16.9747s	
8086/25300 (epoch 15.980), train_loss = 1.13835793, grad/param norm = 2.0278e-01, time/batch = 17.4757s	
8087/25300 (epoch 15.982), train_loss = 1.03580644, grad/param norm = 1.8859e-01, time/batch = 17.3263s	
8088/25300 (epoch 15.984), train_loss = 1.07086813, grad/param norm = 1.9763e-01, time/batch = 18.9663s	
8089/25300 (epoch 15.986), train_loss = 1.17424301, grad/param norm = 2.0426e-01, time/batch = 16.7295s	
8090/25300 (epoch 15.988), train_loss = 1.17439714, grad/param norm = 2.1456e-01, time/batch = 18.6984s	
8091/25300 (epoch 15.990), train_loss = 1.08255851, grad/param norm = 1.7961e-01, time/batch = 19.0385s	
8092/25300 (epoch 15.992), train_loss = 0.88445758, grad/param norm = 1.7086e-01, time/batch = 16.1430s	
8093/25300 (epoch 15.994), train_loss = 1.09225439, grad/param norm = 1.7673e-01, time/batch = 17.8009s	
8094/25300 (epoch 15.996), train_loss = 1.23670269, grad/param norm = 2.3266e-01, time/batch = 17.1361s	
8095/25300 (epoch 15.998), train_loss = 1.21583108, grad/param norm = 2.0204e-01, time/batch = 19.0321s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
8096/25300 (epoch 16.000), train_loss = 1.09881551, grad/param norm = 1.9659e-01, time/batch = 17.3766s	
8097/25300 (epoch 16.002), train_loss = 0.93739276, grad/param norm = 1.6171e-01, time/batch = 18.6620s	
8098/25300 (epoch 16.004), train_loss = 0.92774893, grad/param norm = 1.7710e-01, time/batch = 18.2097s	
8099/25300 (epoch 16.006), train_loss = 1.20590439, grad/param norm = 1.8676e-01, time/batch = 17.0525s	
8100/25300 (epoch 16.008), train_loss = 1.05597864, grad/param norm = 1.7218e-01, time/batch = 16.1095s	
8101/25300 (epoch 16.010), train_loss = 1.08517929, grad/param norm = 1.6727e-01, time/batch = 19.2980s	
8102/25300 (epoch 16.012), train_loss = 1.00098217, grad/param norm = 1.8881e-01, time/batch = 16.8835s	
8103/25300 (epoch 16.014), train_loss = 1.20685149, grad/param norm = 1.9568e-01, time/batch = 15.5599s	
8104/25300 (epoch 16.016), train_loss = 1.10274470, grad/param norm = 1.9603e-01, time/batch = 18.6277s	
8105/25300 (epoch 16.018), train_loss = 0.98369207, grad/param norm = 1.8284e-01, time/batch = 17.6455s	
8106/25300 (epoch 16.020), train_loss = 1.02580631, grad/param norm = 1.7968e-01, time/batch = 16.7153s	
8107/25300 (epoch 16.022), train_loss = 1.12539610, grad/param norm = 2.2221e-01, time/batch = 15.3866s	
8108/25300 (epoch 16.024), train_loss = 0.81067796, grad/param norm = 1.4340e-01, time/batch = 15.8716s	
8109/25300 (epoch 16.026), train_loss = 1.02563104, grad/param norm = 2.0022e-01, time/batch = 15.3022s	
8110/25300 (epoch 16.028), train_loss = 0.95396776, grad/param norm = 1.5780e-01, time/batch = 15.2251s	
8111/25300 (epoch 16.030), train_loss = 1.18234112, grad/param norm = 1.8394e-01, time/batch = 15.4614s	
8112/25300 (epoch 16.032), train_loss = 1.00817816, grad/param norm = 1.7567e-01, time/batch = 15.4377s	
8113/25300 (epoch 16.034), train_loss = 0.87534018, grad/param norm = 1.7585e-01, time/batch = 15.2019s	
8114/25300 (epoch 16.036), train_loss = 0.88683882, grad/param norm = 1.6947e-01, time/batch = 15.2209s	
8115/25300 (epoch 16.038), train_loss = 0.78704507, grad/param norm = 1.3683e-01, time/batch = 16.3163s	
8116/25300 (epoch 16.040), train_loss = 1.09729653, grad/param norm = 1.8234e-01, time/batch = 16.1295s	
8117/25300 (epoch 16.042), train_loss = 1.00518315, grad/param norm = 1.8175e-01, time/batch = 16.6083s	
8118/25300 (epoch 16.043), train_loss = 0.86745424, grad/param norm = 1.5192e-01, time/batch = 18.4681s	
8119/25300 (epoch 16.045), train_loss = 0.90671074, grad/param norm = 1.6792e-01, time/batch = 17.0609s	
8120/25300 (epoch 16.047), train_loss = 1.10493498, grad/param norm = 1.8191e-01, time/batch = 17.4614s	
8121/25300 (epoch 16.049), train_loss = 1.07787028, grad/param norm = 1.8539e-01, time/batch = 16.9909s	
8122/25300 (epoch 16.051), train_loss = 1.15720329, grad/param norm = 1.9791e-01, time/batch = 16.7282s	
8123/25300 (epoch 16.053), train_loss = 0.86607120, grad/param norm = 1.5609e-01, time/batch = 17.1469s	
8124/25300 (epoch 16.055), train_loss = 0.92486384, grad/param norm = 1.5995e-01, time/batch = 15.7014s	
8125/25300 (epoch 16.057), train_loss = 0.88260382, grad/param norm = 1.5779e-01, time/batch = 16.2110s	
8126/25300 (epoch 16.059), train_loss = 1.00187324, grad/param norm = 1.7754e-01, time/batch = 17.1379s	
8127/25300 (epoch 16.061), train_loss = 0.95439985, grad/param norm = 1.7142e-01, time/batch = 16.0425s	
8128/25300 (epoch 16.063), train_loss = 0.92827620, grad/param norm = 1.8122e-01, time/batch = 16.2209s	
8129/25300 (epoch 16.065), train_loss = 1.13281449, grad/param norm = 1.9909e-01, time/batch = 16.2334s	
8130/25300 (epoch 16.067), train_loss = 1.14362354, grad/param norm = 1.7685e-01, time/batch = 18.8062s	
8131/25300 (epoch 16.069), train_loss = 1.01830124, grad/param norm = 1.9240e-01, time/batch = 15.7881s	
8132/25300 (epoch 16.071), train_loss = 1.18473489, grad/param norm = 1.9176e-01, time/batch = 16.8125s	
8133/25300 (epoch 16.073), train_loss = 0.98844369, grad/param norm = 1.6477e-01, time/batch = 16.3036s	
8134/25300 (epoch 16.075), train_loss = 1.10178742, grad/param norm = 1.7999e-01, time/batch = 18.3912s	
8135/25300 (epoch 16.077), train_loss = 1.07641950, grad/param norm = 1.7662e-01, time/batch = 16.1034s	
8136/25300 (epoch 16.079), train_loss = 1.03364406, grad/param norm = 1.7365e-01, time/batch = 18.3781s	
8137/25300 (epoch 16.081), train_loss = 1.01690822, grad/param norm = 1.6877e-01, time/batch = 16.7223s	
8138/25300 (epoch 16.083), train_loss = 1.03041822, grad/param norm = 1.6916e-01, time/batch = 16.7980s	
8139/25300 (epoch 16.085), train_loss = 1.28465369, grad/param norm = 2.0876e-01, time/batch = 16.0466s	
8140/25300 (epoch 16.087), train_loss = 1.11776246, grad/param norm = 1.8849e-01, time/batch = 18.6244s	
8141/25300 (epoch 16.089), train_loss = 1.11689841, grad/param norm = 1.8509e-01, time/batch = 18.6074s	
8142/25300 (epoch 16.091), train_loss = 1.23774389, grad/param norm = 1.9547e-01, time/batch = 15.8717s	
8143/25300 (epoch 16.093), train_loss = 1.19194078, grad/param norm = 1.9229e-01, time/batch = 17.1315s	
8144/25300 (epoch 16.095), train_loss = 1.15087721, grad/param norm = 1.8922e-01, time/batch = 16.4846s	
8145/25300 (epoch 16.097), train_loss = 1.08190480, grad/param norm = 1.8308e-01, time/batch = 16.8711s	
8146/25300 (epoch 16.099), train_loss = 1.13301457, grad/param norm = 1.9290e-01, time/batch = 15.3230s	
8147/25300 (epoch 16.101), train_loss = 1.04152511, grad/param norm = 1.7370e-01, time/batch = 15.7404s	
8148/25300 (epoch 16.103), train_loss = 1.05310670, grad/param norm = 1.7181e-01, time/batch = 19.2225s	
8149/25300 (epoch 16.105), train_loss = 1.09410040, grad/param norm = 1.7406e-01, time/batch = 16.0532s	
8150/25300 (epoch 16.107), train_loss = 1.14106067, grad/param norm = 1.9806e-01, time/batch = 16.9045s	
8151/25300 (epoch 16.109), train_loss = 1.03770398, grad/param norm = 1.9543e-01, time/batch = 19.5372s	
8152/25300 (epoch 16.111), train_loss = 1.03930762, grad/param norm = 1.7218e-01, time/batch = 16.1175s	
8153/25300 (epoch 16.113), train_loss = 1.01946279, grad/param norm = 1.8656e-01, time/batch = 15.9671s	
8154/25300 (epoch 16.115), train_loss = 1.04218741, grad/param norm = 1.8933e-01, time/batch = 17.8049s	
8155/25300 (epoch 16.117), train_loss = 1.12372701, grad/param norm = 1.7473e-01, time/batch = 19.0452s	
8156/25300 (epoch 16.119), train_loss = 1.03031725, grad/param norm = 1.7722e-01, time/batch = 16.3001s	
8157/25300 (epoch 16.121), train_loss = 1.09367628, grad/param norm = 1.8753e-01, time/batch = 17.8838s	
8158/25300 (epoch 16.123), train_loss = 1.04853634, grad/param norm = 1.8716e-01, time/batch = 17.1368s	
8159/25300 (epoch 16.125), train_loss = 1.14769968, grad/param norm = 2.0153e-01, time/batch = 16.0289s	
8160/25300 (epoch 16.126), train_loss = 1.05808477, grad/param norm = 1.8856e-01, time/batch = 19.0325s	
8161/25300 (epoch 16.128), train_loss = 1.06768556, grad/param norm = 1.8667e-01, time/batch = 16.6545s	
8162/25300 (epoch 16.130), train_loss = 0.86385975, grad/param norm = 1.5695e-01, time/batch = 19.4456s	
8163/25300 (epoch 16.132), train_loss = 0.89808075, grad/param norm = 1.6632e-01, time/batch = 17.3077s	
8164/25300 (epoch 16.134), train_loss = 0.84786437, grad/param norm = 1.5946e-01, time/batch = 17.4795s	
8165/25300 (epoch 16.136), train_loss = 1.05922331, grad/param norm = 1.7577e-01, time/batch = 16.4088s	
8166/25300 (epoch 16.138), train_loss = 0.91769754, grad/param norm = 1.5932e-01, time/batch = 15.2174s	
8167/25300 (epoch 16.140), train_loss = 0.99138423, grad/param norm = 1.6815e-01, time/batch = 16.1517s	
8168/25300 (epoch 16.142), train_loss = 1.16664251, grad/param norm = 1.9186e-01, time/batch = 17.4084s	
8169/25300 (epoch 16.144), train_loss = 1.11163292, grad/param norm = 1.8382e-01, time/batch = 17.4752s	
8170/25300 (epoch 16.146), train_loss = 1.13334956, grad/param norm = 2.0669e-01, time/batch = 17.1414s	
8171/25300 (epoch 16.148), train_loss = 1.03376658, grad/param norm = 1.7553e-01, time/batch = 17.1413s	
8172/25300 (epoch 16.150), train_loss = 1.17456505, grad/param norm = 2.2325e-01, time/batch = 18.7238s	
8173/25300 (epoch 16.152), train_loss = 1.23941442, grad/param norm = 1.9764e-01, time/batch = 15.7345s	
8174/25300 (epoch 16.154), train_loss = 0.93791920, grad/param norm = 1.7358e-01, time/batch = 17.2388s	
8175/25300 (epoch 16.156), train_loss = 1.11715333, grad/param norm = 1.9082e-01, time/batch = 16.8066s	
8176/25300 (epoch 16.158), train_loss = 0.96528724, grad/param norm = 1.7206e-01, time/batch = 17.9744s	
8177/25300 (epoch 16.160), train_loss = 1.06677358, grad/param norm = 1.8063e-01, time/batch = 17.2986s	
8178/25300 (epoch 16.162), train_loss = 0.98998468, grad/param norm = 1.8747e-01, time/batch = 16.6498s	
8179/25300 (epoch 16.164), train_loss = 1.13553717, grad/param norm = 1.8689e-01, time/batch = 19.3119s	
8180/25300 (epoch 16.166), train_loss = 1.06537513, grad/param norm = 1.7516e-01, time/batch = 16.2220s	
8181/25300 (epoch 16.168), train_loss = 0.93308666, grad/param norm = 1.5759e-01, time/batch = 19.7053s	
8182/25300 (epoch 16.170), train_loss = 1.01617560, grad/param norm = 1.7441e-01, time/batch = 15.7281s	
8183/25300 (epoch 16.172), train_loss = 0.95899872, grad/param norm = 1.7876e-01, time/batch = 17.4708s	
8184/25300 (epoch 16.174), train_loss = 0.93059673, grad/param norm = 1.6892e-01, time/batch = 17.7198s	
8185/25300 (epoch 16.176), train_loss = 0.98782253, grad/param norm = 1.8073e-01, time/batch = 16.8893s	
8186/25300 (epoch 16.178), train_loss = 1.18756344, grad/param norm = 1.9628e-01, time/batch = 16.3899s	
8187/25300 (epoch 16.180), train_loss = 0.87595272, grad/param norm = 1.7086e-01, time/batch = 15.7150s	
8188/25300 (epoch 16.182), train_loss = 0.99304765, grad/param norm = 1.8047e-01, time/batch = 16.6346s	
8189/25300 (epoch 16.184), train_loss = 1.01811971, grad/param norm = 1.8682e-01, time/batch = 17.6406s	
8190/25300 (epoch 16.186), train_loss = 0.97436542, grad/param norm = 1.8370e-01, time/batch = 18.5436s	
8191/25300 (epoch 16.188), train_loss = 1.05120769, grad/param norm = 2.1477e-01, time/batch = 18.4708s	
8192/25300 (epoch 16.190), train_loss = 1.03133251, grad/param norm = 1.9514e-01, time/batch = 18.7940s	
8193/25300 (epoch 16.192), train_loss = 1.01068660, grad/param norm = 1.8701e-01, time/batch = 19.0262s	
8194/25300 (epoch 16.194), train_loss = 1.02035190, grad/param norm = 1.7677e-01, time/batch = 17.2950s	
8195/25300 (epoch 16.196), train_loss = 1.12238263, grad/param norm = 2.0732e-01, time/batch = 19.1374s	
8196/25300 (epoch 16.198), train_loss = 0.97750285, grad/param norm = 1.8456e-01, time/batch = 18.9592s	
8197/25300 (epoch 16.200), train_loss = 1.03627918, grad/param norm = 1.9556e-01, time/batch = 16.4721s	
8198/25300 (epoch 16.202), train_loss = 1.02854209, grad/param norm = 1.8239e-01, time/batch = 19.5578s	
8199/25300 (epoch 16.204), train_loss = 1.00317929, grad/param norm = 1.7352e-01, time/batch = 19.7145s	
8200/25300 (epoch 16.206), train_loss = 1.12033211, grad/param norm = 1.7771e-01, time/batch = 16.6250s	
8201/25300 (epoch 16.208), train_loss = 0.93406751, grad/param norm = 1.9869e-01, time/batch = 15.7945s	
8202/25300 (epoch 16.209), train_loss = 0.87545524, grad/param norm = 1.6861e-01, time/batch = 18.2248s	
8203/25300 (epoch 16.211), train_loss = 1.00407427, grad/param norm = 1.8103e-01, time/batch = 17.0367s	
8204/25300 (epoch 16.213), train_loss = 1.09592903, grad/param norm = 1.8748e-01, time/batch = 16.5579s	
8205/25300 (epoch 16.215), train_loss = 1.06893830, grad/param norm = 1.7993e-01, time/batch = 15.4527s	
8206/25300 (epoch 16.217), train_loss = 1.09388022, grad/param norm = 2.1933e-01, time/batch = 17.8937s	
8207/25300 (epoch 16.219), train_loss = 1.16525818, grad/param norm = 1.9959e-01, time/batch = 15.4906s	
8208/25300 (epoch 16.221), train_loss = 1.18865115, grad/param norm = 1.9824e-01, time/batch = 18.2187s	
8209/25300 (epoch 16.223), train_loss = 1.11400867, grad/param norm = 2.0637e-01, time/batch = 17.7168s	
8210/25300 (epoch 16.225), train_loss = 1.52267659, grad/param norm = 2.5158e-01, time/batch = 16.7175s	
8211/25300 (epoch 16.227), train_loss = 1.16425035, grad/param norm = 1.8605e-01, time/batch = 28.9173s	
8212/25300 (epoch 16.229), train_loss = 1.05147892, grad/param norm = 1.7763e-01, time/batch = 15.6478s	
8213/25300 (epoch 16.231), train_loss = 1.03608140, grad/param norm = 1.9539e-01, time/batch = 16.1380s	
8214/25300 (epoch 16.233), train_loss = 1.12886115, grad/param norm = 1.9788e-01, time/batch = 16.9700s	
8215/25300 (epoch 16.235), train_loss = 1.03207127, grad/param norm = 1.6711e-01, time/batch = 18.7983s	
8216/25300 (epoch 16.237), train_loss = 1.25421591, grad/param norm = 2.1177e-01, time/batch = 18.7217s	
8217/25300 (epoch 16.239), train_loss = 1.08126727, grad/param norm = 1.8971e-01, time/batch = 17.5328s	
8218/25300 (epoch 16.241), train_loss = 1.18393996, grad/param norm = 1.8452e-01, time/batch = 18.6915s	
8219/25300 (epoch 16.243), train_loss = 1.38325183, grad/param norm = 2.0964e-01, time/batch = 19.0347s	
8220/25300 (epoch 16.245), train_loss = 1.01078724, grad/param norm = 2.3622e-01, time/batch = 16.3812s	
8221/25300 (epoch 16.247), train_loss = 1.15477113, grad/param norm = 1.9187e-01, time/batch = 17.8014s	
8222/25300 (epoch 16.249), train_loss = 0.94095451, grad/param norm = 1.6707e-01, time/batch = 16.1267s	
8223/25300 (epoch 16.251), train_loss = 0.89284303, grad/param norm = 1.7084e-01, time/batch = 17.2111s	
8224/25300 (epoch 16.253), train_loss = 1.03624036, grad/param norm = 1.8981e-01, time/batch = 17.3162s	
8225/25300 (epoch 16.255), train_loss = 1.00106488, grad/param norm = 2.0037e-01, time/batch = 16.0582s	
8226/25300 (epoch 16.257), train_loss = 1.08689660, grad/param norm = 1.9961e-01, time/batch = 19.2189s	
8227/25300 (epoch 16.259), train_loss = 1.29192704, grad/param norm = 1.9965e-01, time/batch = 16.0307s	
8228/25300 (epoch 16.261), train_loss = 1.22446761, grad/param norm = 2.0849e-01, time/batch = 17.1077s	
8229/25300 (epoch 16.263), train_loss = 1.20011352, grad/param norm = 1.8720e-01, time/batch = 19.1300s	
8230/25300 (epoch 16.265), train_loss = 1.26544703, grad/param norm = 1.8517e-01, time/batch = 16.7098s	
8231/25300 (epoch 16.267), train_loss = 1.18088401, grad/param norm = 1.9735e-01, time/batch = 18.1360s	
8232/25300 (epoch 16.269), train_loss = 0.89991093, grad/param norm = 1.5794e-01, time/batch = 16.9701s	
8233/25300 (epoch 16.271), train_loss = 1.03497853, grad/param norm = 1.7729e-01, time/batch = 19.7108s	
8234/25300 (epoch 16.273), train_loss = 1.13703439, grad/param norm = 2.0219e-01, time/batch = 16.4599s	
8235/25300 (epoch 16.275), train_loss = 0.99249501, grad/param norm = 1.5920e-01, time/batch = 16.5726s	
8236/25300 (epoch 16.277), train_loss = 1.04332748, grad/param norm = 2.2193e-01, time/batch = 15.7345s	
8237/25300 (epoch 16.279), train_loss = 1.04301182, grad/param norm = 1.7605e-01, time/batch = 16.5537s	
8238/25300 (epoch 16.281), train_loss = 1.21438771, grad/param norm = 2.0068e-01, time/batch = 15.8235s	
8239/25300 (epoch 16.283), train_loss = 0.94165295, grad/param norm = 1.5687e-01, time/batch = 18.3051s	
8240/25300 (epoch 16.285), train_loss = 1.10356586, grad/param norm = 2.0035e-01, time/batch = 19.0406s	
8241/25300 (epoch 16.287), train_loss = 1.10748446, grad/param norm = 1.7665e-01, time/batch = 15.8663s	
8242/25300 (epoch 16.289), train_loss = 1.02159680, grad/param norm = 1.8349e-01, time/batch = 16.9778s	
8243/25300 (epoch 16.291), train_loss = 1.02342115, grad/param norm = 1.7531e-01, time/batch = 16.6390s	
8244/25300 (epoch 16.292), train_loss = 1.23444760, grad/param norm = 1.9314e-01, time/batch = 16.9497s	
8245/25300 (epoch 16.294), train_loss = 1.08638496, grad/param norm = 1.8275e-01, time/batch = 15.4057s	
8246/25300 (epoch 16.296), train_loss = 0.95465136, grad/param norm = 1.9406e-01, time/batch = 16.0628s	
8247/25300 (epoch 16.298), train_loss = 1.14829818, grad/param norm = 1.9361e-01, time/batch = 17.8101s	
8248/25300 (epoch 16.300), train_loss = 1.17127678, grad/param norm = 1.9605e-01, time/batch = 16.5535s	
8249/25300 (epoch 16.302), train_loss = 0.88567122, grad/param norm = 1.8763e-01, time/batch = 15.8806s	
8250/25300 (epoch 16.304), train_loss = 1.13308960, grad/param norm = 1.7705e-01, time/batch = 16.6427s	
8251/25300 (epoch 16.306), train_loss = 0.83223716, grad/param norm = 1.6200e-01, time/batch = 18.5418s	
8252/25300 (epoch 16.308), train_loss = 1.10532516, grad/param norm = 1.6938e-01, time/batch = 17.0533s	
8253/25300 (epoch 16.310), train_loss = 0.97600942, grad/param norm = 1.8940e-01, time/batch = 15.9843s	
8254/25300 (epoch 16.312), train_loss = 1.05646235, grad/param norm = 1.7053e-01, time/batch = 19.2032s	
8255/25300 (epoch 16.314), train_loss = 0.88019497, grad/param norm = 1.6570e-01, time/batch = 15.7258s	
8256/25300 (epoch 16.316), train_loss = 1.09439066, grad/param norm = 1.8285e-01, time/batch = 17.9594s	
8257/25300 (epoch 16.318), train_loss = 0.84034099, grad/param norm = 1.6585e-01, time/batch = 15.2134s	
8258/25300 (epoch 16.320), train_loss = 0.92287249, grad/param norm = 1.7206e-01, time/batch = 17.7026s	
8259/25300 (epoch 16.322), train_loss = 1.27678142, grad/param norm = 2.1148e-01, time/batch = 16.5555s	
8260/25300 (epoch 16.324), train_loss = 0.94071729, grad/param norm = 1.6039e-01, time/batch = 17.1401s	
8261/25300 (epoch 16.326), train_loss = 0.84358167, grad/param norm = 1.5467e-01, time/batch = 18.9544s	
8262/25300 (epoch 16.328), train_loss = 0.83619811, grad/param norm = 1.6230e-01, time/batch = 16.2203s	
8263/25300 (epoch 16.330), train_loss = 1.01668004, grad/param norm = 1.8616e-01, time/batch = 16.4754s	
8264/25300 (epoch 16.332), train_loss = 1.04225504, grad/param norm = 1.5397e-01, time/batch = 18.2901s	
8265/25300 (epoch 16.334), train_loss = 0.87474919, grad/param norm = 1.6408e-01, time/batch = 15.6244s	
8266/25300 (epoch 16.336), train_loss = 0.89871217, grad/param norm = 1.6134e-01, time/batch = 15.2710s	
8267/25300 (epoch 16.338), train_loss = 0.88000742, grad/param norm = 1.7173e-01, time/batch = 15.4978s	
8268/25300 (epoch 16.340), train_loss = 0.98737039, grad/param norm = 1.9485e-01, time/batch = 15.4465s	
8269/25300 (epoch 16.342), train_loss = 0.99571632, grad/param norm = 1.8391e-01, time/batch = 15.6198s	
8270/25300 (epoch 16.344), train_loss = 1.04978944, grad/param norm = 1.7019e-01, time/batch = 15.4612s	
8271/25300 (epoch 16.346), train_loss = 1.02920570, grad/param norm = 2.0453e-01, time/batch = 17.3071s	
8272/25300 (epoch 16.348), train_loss = 0.90991466, grad/param norm = 1.6085e-01, time/batch = 16.7042s	
8273/25300 (epoch 16.350), train_loss = 0.98552783, grad/param norm = 1.7165e-01, time/batch = 15.7098s	
8274/25300 (epoch 16.352), train_loss = 1.03639703, grad/param norm = 1.7339e-01, time/batch = 16.7290s	
8275/25300 (epoch 16.354), train_loss = 0.95060203, grad/param norm = 1.6419e-01, time/batch = 16.2281s	
8276/25300 (epoch 16.356), train_loss = 1.04460586, grad/param norm = 2.0177e-01, time/batch = 16.0647s	
8277/25300 (epoch 16.358), train_loss = 1.14882431, grad/param norm = 2.0923e-01, time/batch = 16.5448s	
8278/25300 (epoch 16.360), train_loss = 0.94493613, grad/param norm = 1.6772e-01, time/batch = 17.3859s	
8279/25300 (epoch 16.362), train_loss = 0.96576472, grad/param norm = 1.7828e-01, time/batch = 17.9760s	
8280/25300 (epoch 16.364), train_loss = 1.02605172, grad/param norm = 1.9273e-01, time/batch = 16.7104s	
8281/25300 (epoch 16.366), train_loss = 0.88854167, grad/param norm = 1.6888e-01, time/batch = 17.7265s	
8282/25300 (epoch 16.368), train_loss = 0.98214828, grad/param norm = 1.6245e-01, time/batch = 16.7310s	
8283/25300 (epoch 16.370), train_loss = 0.97868605, grad/param norm = 1.9248e-01, time/batch = 19.1294s	
8284/25300 (epoch 16.372), train_loss = 0.97265453, grad/param norm = 1.7593e-01, time/batch = 16.8951s	
8285/25300 (epoch 16.374), train_loss = 0.90770239, grad/param norm = 1.7160e-01, time/batch = 17.0461s	
8286/25300 (epoch 16.375), train_loss = 1.19098108, grad/param norm = 2.0668e-01, time/batch = 15.4139s	
8287/25300 (epoch 16.377), train_loss = 1.07332184, grad/param norm = 2.1180e-01, time/batch = 15.3689s	
8288/25300 (epoch 16.379), train_loss = 1.08140584, grad/param norm = 1.9781e-01, time/batch = 16.9773s	
8289/25300 (epoch 16.381), train_loss = 1.06014237, grad/param norm = 1.9193e-01, time/batch = 16.5424s	
8290/25300 (epoch 16.383), train_loss = 0.94460513, grad/param norm = 1.7254e-01, time/batch = 17.7999s	
8291/25300 (epoch 16.385), train_loss = 1.03025084, grad/param norm = 1.8527e-01, time/batch = 16.9662s	
8292/25300 (epoch 16.387), train_loss = 1.06597904, grad/param norm = 1.8566e-01, time/batch = 17.4712s	
8293/25300 (epoch 16.389), train_loss = 1.12283527, grad/param norm = 1.9720e-01, time/batch = 16.5561s	
8294/25300 (epoch 16.391), train_loss = 0.95418917, grad/param norm = 1.6201e-01, time/batch = 15.6787s	
8295/25300 (epoch 16.393), train_loss = 1.06426987, grad/param norm = 2.1828e-01, time/batch = 17.0395s	
8296/25300 (epoch 16.395), train_loss = 0.88995617, grad/param norm = 1.6355e-01, time/batch = 17.3909s	
8297/25300 (epoch 16.397), train_loss = 0.90511211, grad/param norm = 1.7805e-01, time/batch = 18.1500s	
8298/25300 (epoch 16.399), train_loss = 0.90116606, grad/param norm = 1.8012e-01, time/batch = 16.3667s	
8299/25300 (epoch 16.401), train_loss = 1.14522613, grad/param norm = 2.1696e-01, time/batch = 17.8050s	
8300/25300 (epoch 16.403), train_loss = 1.03806733, grad/param norm = 1.9527e-01, time/batch = 16.6393s	
8301/25300 (epoch 16.405), train_loss = 1.05368990, grad/param norm = 2.0096e-01, time/batch = 16.3905s	
8302/25300 (epoch 16.407), train_loss = 0.97323471, grad/param norm = 1.6865e-01, time/batch = 17.7202s	
8303/25300 (epoch 16.409), train_loss = 0.94278392, grad/param norm = 1.6651e-01, time/batch = 15.4837s	
8304/25300 (epoch 16.411), train_loss = 0.95742451, grad/param norm = 1.8045e-01, time/batch = 18.1346s	
8305/25300 (epoch 16.413), train_loss = 0.89155446, grad/param norm = 1.7527e-01, time/batch = 15.8835s	
8306/25300 (epoch 16.415), train_loss = 0.89877028, grad/param norm = 1.8744e-01, time/batch = 16.6233s	
8307/25300 (epoch 16.417), train_loss = 0.85133426, grad/param norm = 1.5825e-01, time/batch = 15.8140s	
8308/25300 (epoch 16.419), train_loss = 0.83128859, grad/param norm = 1.6094e-01, time/batch = 16.3147s	
8309/25300 (epoch 16.421), train_loss = 0.87194877, grad/param norm = 1.5706e-01, time/batch = 16.1358s	
8310/25300 (epoch 16.423), train_loss = 0.90118080, grad/param norm = 1.7355e-01, time/batch = 16.3907s	
8311/25300 (epoch 16.425), train_loss = 0.99689922, grad/param norm = 1.7973e-01, time/batch = 16.7302s	
8312/25300 (epoch 16.427), train_loss = 1.20323921, grad/param norm = 2.0972e-01, time/batch = 15.8799s	
8313/25300 (epoch 16.429), train_loss = 1.11423917, grad/param norm = 1.9700e-01, time/batch = 15.7139s	
8314/25300 (epoch 16.431), train_loss = 1.04542170, grad/param norm = 1.7524e-01, time/batch = 19.4510s	
8315/25300 (epoch 16.433), train_loss = 0.98761273, grad/param norm = 1.6628e-01, time/batch = 17.6272s	
8316/25300 (epoch 16.435), train_loss = 0.93875172, grad/param norm = 1.8924e-01, time/batch = 16.6351s	
8317/25300 (epoch 16.437), train_loss = 0.97522760, grad/param norm = 2.0457e-01, time/batch = 16.2321s	
8318/25300 (epoch 16.439), train_loss = 1.03849434, grad/param norm = 1.7641e-01, time/batch = 17.8032s	
8319/25300 (epoch 16.441), train_loss = 1.07148848, grad/param norm = 1.9560e-01, time/batch = 17.8816s	
8320/25300 (epoch 16.443), train_loss = 1.27677097, grad/param norm = 2.2438e-01, time/batch = 18.3871s	
8321/25300 (epoch 16.445), train_loss = 1.20875338, grad/param norm = 1.9703e-01, time/batch = 16.6508s	
8322/25300 (epoch 16.447), train_loss = 0.92295705, grad/param norm = 1.6107e-01, time/batch = 17.5548s	
8323/25300 (epoch 16.449), train_loss = 0.85107084, grad/param norm = 1.7998e-01, time/batch = 17.5578s	
8324/25300 (epoch 16.451), train_loss = 1.20897515, grad/param norm = 1.9530e-01, time/batch = 18.1393s	
8325/25300 (epoch 16.453), train_loss = 1.11812563, grad/param norm = 2.1029e-01, time/batch = 18.5704s	
8326/25300 (epoch 16.455), train_loss = 1.12500873, grad/param norm = 2.0476e-01, time/batch = 17.2871s	
8327/25300 (epoch 16.457), train_loss = 0.98797343, grad/param norm = 1.8084e-01, time/batch = 17.0548s	
8328/25300 (epoch 16.458), train_loss = 1.04379485, grad/param norm = 1.9255e-01, time/batch = 18.9564s	
8329/25300 (epoch 16.460), train_loss = 1.04626509, grad/param norm = 1.9422e-01, time/batch = 16.0251s	
8330/25300 (epoch 16.462), train_loss = 0.80279546, grad/param norm = 1.8148e-01, time/batch = 18.2182s	
8331/25300 (epoch 16.464), train_loss = 1.12250633, grad/param norm = 2.0261e-01, time/batch = 16.6383s	
8332/25300 (epoch 16.466), train_loss = 1.10726249, grad/param norm = 1.8000e-01, time/batch = 19.2871s	
8333/25300 (epoch 16.468), train_loss = 1.12035641, grad/param norm = 1.9175e-01, time/batch = 16.3398s	
8334/25300 (epoch 16.470), train_loss = 0.94747159, grad/param norm = 1.7207e-01, time/batch = 17.5421s	
8335/25300 (epoch 16.472), train_loss = 0.86281629, grad/param norm = 1.6138e-01, time/batch = 19.1115s	
8336/25300 (epoch 16.474), train_loss = 1.05262340, grad/param norm = 1.7012e-01, time/batch = 17.2169s	
8337/25300 (epoch 16.476), train_loss = 0.99351527, grad/param norm = 1.7443e-01, time/batch = 17.5532s	
8338/25300 (epoch 16.478), train_loss = 1.08636816, grad/param norm = 1.7881e-01, time/batch = 17.2161s	
8339/25300 (epoch 16.480), train_loss = 0.94114438, grad/param norm = 1.6463e-01, time/batch = 17.6274s	
8340/25300 (epoch 16.482), train_loss = 1.09867592, grad/param norm = 1.9845e-01, time/batch = 16.5794s	
8341/25300 (epoch 16.484), train_loss = 1.10498609, grad/param norm = 2.1043e-01, time/batch = 16.8896s	
8342/25300 (epoch 16.486), train_loss = 1.03719469, grad/param norm = 1.8254e-01, time/batch = 16.7329s	
8343/25300 (epoch 16.488), train_loss = 1.19345624, grad/param norm = 1.9661e-01, time/batch = 17.0512s	
8344/25300 (epoch 16.490), train_loss = 1.08352768, grad/param norm = 1.7749e-01, time/batch = 16.9547s	
8345/25300 (epoch 16.492), train_loss = 1.03868430, grad/param norm = 1.7638e-01, time/batch = 19.3789s	
8346/25300 (epoch 16.494), train_loss = 0.96770911, grad/param norm = 1.7888e-01, time/batch = 16.4702s	
8347/25300 (epoch 16.496), train_loss = 1.02650771, grad/param norm = 1.8656e-01, time/batch = 16.0392s	
8348/25300 (epoch 16.498), train_loss = 0.94885278, grad/param norm = 1.6703e-01, time/batch = 18.6236s	
8349/25300 (epoch 16.500), train_loss = 1.15523798, grad/param norm = 2.0242e-01, time/batch = 18.3767s	
8350/25300 (epoch 16.502), train_loss = 1.06566456, grad/param norm = 1.9794e-01, time/batch = 16.5303s	
8351/25300 (epoch 16.504), train_loss = 0.99426878, grad/param norm = 1.8602e-01, time/batch = 16.2255s	
8352/25300 (epoch 16.506), train_loss = 0.97269870, grad/param norm = 1.8659e-01, time/batch = 17.1418s	
8353/25300 (epoch 16.508), train_loss = 1.04796223, grad/param norm = 1.9649e-01, time/batch = 18.3834s	
8354/25300 (epoch 16.510), train_loss = 0.94876629, grad/param norm = 1.7809e-01, time/batch = 16.3326s	
8355/25300 (epoch 16.512), train_loss = 0.78449918, grad/param norm = 1.6159e-01, time/batch = 15.8237s	
8356/25300 (epoch 16.514), train_loss = 0.98345139, grad/param norm = 1.5864e-01, time/batch = 16.8987s	
8357/25300 (epoch 16.516), train_loss = 1.06090871, grad/param norm = 1.8992e-01, time/batch = 16.5559s	
8358/25300 (epoch 16.518), train_loss = 1.13870524, grad/param norm = 2.1313e-01, time/batch = 17.9706s	
8359/25300 (epoch 16.520), train_loss = 0.86027487, grad/param norm = 1.5675e-01, time/batch = 15.4837s	
8360/25300 (epoch 16.522), train_loss = 0.95480174, grad/param norm = 1.8037e-01, time/batch = 16.2182s	
8361/25300 (epoch 16.524), train_loss = 0.99828132, grad/param norm = 1.7465e-01, time/batch = 15.9542s	
8362/25300 (epoch 16.526), train_loss = 1.22344153, grad/param norm = 2.0263e-01, time/batch = 16.3274s	
8363/25300 (epoch 16.528), train_loss = 1.17309151, grad/param norm = 2.0167e-01, time/batch = 18.2124s	
8364/25300 (epoch 16.530), train_loss = 1.04006400, grad/param norm = 1.8154e-01, time/batch = 16.0437s	
8365/25300 (epoch 16.532), train_loss = 1.02865091, grad/param norm = 1.8223e-01, time/batch = 18.4545s	
8366/25300 (epoch 16.534), train_loss = 1.00438341, grad/param norm = 1.8339e-01, time/batch = 15.8867s	
8367/25300 (epoch 16.536), train_loss = 0.83273830, grad/param norm = 1.6988e-01, time/batch = 16.4684s	
8368/25300 (epoch 16.538), train_loss = 0.86731540, grad/param norm = 1.3876e-01, time/batch = 15.6165s	
8369/25300 (epoch 16.540), train_loss = 0.94943909, grad/param norm = 1.7748e-01, time/batch = 16.1303s	
8370/25300 (epoch 16.542), train_loss = 0.90170980, grad/param norm = 1.6715e-01, time/batch = 17.4749s	
8371/25300 (epoch 16.543), train_loss = 0.86326904, grad/param norm = 1.7900e-01, time/batch = 15.8907s	
8372/25300 (epoch 16.545), train_loss = 1.31634829, grad/param norm = 2.1741e-01, time/batch = 18.0354s	
8373/25300 (epoch 16.547), train_loss = 1.06101855, grad/param norm = 1.8882e-01, time/batch = 17.9785s	
8374/25300 (epoch 16.549), train_loss = 1.27300280, grad/param norm = 2.2962e-01, time/batch = 17.7956s	
8375/25300 (epoch 16.551), train_loss = 1.10792899, grad/param norm = 1.9391e-01, time/batch = 16.3055s	
8376/25300 (epoch 16.553), train_loss = 0.95405570, grad/param norm = 1.7805e-01, time/batch = 17.7285s	
8377/25300 (epoch 16.555), train_loss = 1.15234465, grad/param norm = 2.0504e-01, time/batch = 16.9683s	
8378/25300 (epoch 16.557), train_loss = 1.16788912, grad/param norm = 1.9218e-01, time/batch = 16.4804s	
8379/25300 (epoch 16.559), train_loss = 1.13129199, grad/param norm = 1.8845e-01, time/batch = 18.0321s	
8380/25300 (epoch 16.561), train_loss = 1.19338555, grad/param norm = 2.0582e-01, time/batch = 18.0475s	
8381/25300 (epoch 16.563), train_loss = 1.14304090, grad/param norm = 2.0169e-01, time/batch = 17.2869s	
8382/25300 (epoch 16.565), train_loss = 0.87864654, grad/param norm = 1.6390e-01, time/batch = 15.6420s	
8383/25300 (epoch 16.567), train_loss = 0.77683760, grad/param norm = 1.6206e-01, time/batch = 18.8908s	
8384/25300 (epoch 16.569), train_loss = 1.03694436, grad/param norm = 1.9741e-01, time/batch = 17.3984s	
8385/25300 (epoch 16.571), train_loss = 1.13860600, grad/param norm = 2.0942e-01, time/batch = 16.7909s	
8386/25300 (epoch 16.573), train_loss = 1.01896017, grad/param norm = 1.7958e-01, time/batch = 18.3863s	
8387/25300 (epoch 16.575), train_loss = 1.13385418, grad/param norm = 1.9153e-01, time/batch = 16.1253s	
8388/25300 (epoch 16.577), train_loss = 1.06366663, grad/param norm = 1.8952e-01, time/batch = 17.3914s	
8389/25300 (epoch 16.579), train_loss = 1.22200937, grad/param norm = 2.1394e-01, time/batch = 18.0476s	
8390/25300 (epoch 16.581), train_loss = 1.09819138, grad/param norm = 1.9419e-01, time/batch = 18.9625s	
8391/25300 (epoch 16.583), train_loss = 0.88354216, grad/param norm = 1.9622e-01, time/batch = 17.3635s	
8392/25300 (epoch 16.585), train_loss = 0.88140047, grad/param norm = 2.0827e-01, time/batch = 16.1426s	
8393/25300 (epoch 16.587), train_loss = 0.99566155, grad/param norm = 1.8077e-01, time/batch = 18.2113s	
8394/25300 (epoch 16.589), train_loss = 0.91193178, grad/param norm = 1.7306e-01, time/batch = 17.3004s	
8395/25300 (epoch 16.591), train_loss = 0.90152460, grad/param norm = 1.9644e-01, time/batch = 16.3834s	
8396/25300 (epoch 16.593), train_loss = 1.07670662, grad/param norm = 1.8299e-01, time/batch = 16.3182s	
8397/25300 (epoch 16.595), train_loss = 1.01660213, grad/param norm = 1.9402e-01, time/batch = 15.7177s	
8398/25300 (epoch 16.597), train_loss = 0.86530671, grad/param norm = 1.5254e-01, time/batch = 18.8827s	
8399/25300 (epoch 16.599), train_loss = 1.04451972, grad/param norm = 1.9160e-01, time/batch = 17.0517s	
8400/25300 (epoch 16.601), train_loss = 1.04528822, grad/param norm = 1.8723e-01, time/batch = 16.9578s	
8401/25300 (epoch 16.603), train_loss = 1.04157287, grad/param norm = 1.8065e-01, time/batch = 18.9818s	
8402/25300 (epoch 16.605), train_loss = 0.93365981, grad/param norm = 1.7688e-01, time/batch = 16.1301s	
8403/25300 (epoch 16.607), train_loss = 0.77519789, grad/param norm = 1.5408e-01, time/batch = 17.9703s	
8404/25300 (epoch 16.609), train_loss = 0.99564573, grad/param norm = 1.8516e-01, time/batch = 17.7221s	
8405/25300 (epoch 16.611), train_loss = 1.07725462, grad/param norm = 1.8709e-01, time/batch = 17.6509s	
8406/25300 (epoch 16.613), train_loss = 0.88324001, grad/param norm = 1.8830e-01, time/batch = 17.9757s	
8407/25300 (epoch 16.615), train_loss = 1.00195024, grad/param norm = 2.4443e-01, time/batch = 17.8840s	
8408/25300 (epoch 16.617), train_loss = 1.04846705, grad/param norm = 2.1696e-01, time/batch = 19.3760s	
8409/25300 (epoch 16.619), train_loss = 1.11427646, grad/param norm = 2.0444e-01, time/batch = 16.6062s	
8410/25300 (epoch 16.621), train_loss = 1.15333729, grad/param norm = 2.1995e-01, time/batch = 17.1463s	
8411/25300 (epoch 16.623), train_loss = 0.95481658, grad/param norm = 1.8336e-01, time/batch = 17.1437s	
8412/25300 (epoch 16.625), train_loss = 0.84289679, grad/param norm = 1.6312e-01, time/batch = 18.0589s	
8413/25300 (epoch 16.626), train_loss = 0.99255662, grad/param norm = 1.8582e-01, time/batch = 18.3796s	
8414/25300 (epoch 16.628), train_loss = 1.09852763, grad/param norm = 1.8796e-01, time/batch = 15.8194s	
8415/25300 (epoch 16.630), train_loss = 1.10221869, grad/param norm = 2.1284e-01, time/batch = 17.1906s	
8416/25300 (epoch 16.632), train_loss = 1.05698367, grad/param norm = 2.0832e-01, time/batch = 18.7034s	
8417/25300 (epoch 16.634), train_loss = 1.12585345, grad/param norm = 2.0923e-01, time/batch = 15.8840s	
8418/25300 (epoch 16.636), train_loss = 0.97954037, grad/param norm = 1.8579e-01, time/batch = 18.3048s	
8419/25300 (epoch 16.638), train_loss = 1.08080934, grad/param norm = 2.1129e-01, time/batch = 26.0972s	
8420/25300 (epoch 16.640), train_loss = 1.21730209, grad/param norm = 2.1899e-01, time/batch = 21.3369s	
8421/25300 (epoch 16.642), train_loss = 1.08323337, grad/param norm = 1.9030e-01, time/batch = 18.0428s	
8422/25300 (epoch 16.644), train_loss = 1.05666772, grad/param norm = 1.9435e-01, time/batch = 16.0453s	
8423/25300 (epoch 16.646), train_loss = 0.99183739, grad/param norm = 2.2812e-01, time/batch = 15.7209s	
8424/25300 (epoch 16.648), train_loss = 1.12444323, grad/param norm = 1.8836e-01, time/batch = 16.3909s	
8425/25300 (epoch 16.650), train_loss = 1.07758752, grad/param norm = 2.0710e-01, time/batch = 15.4760s	
8426/25300 (epoch 16.652), train_loss = 1.05462538, grad/param norm = 1.9451e-01, time/batch = 15.6197s	
8427/25300 (epoch 16.654), train_loss = 1.17779849, grad/param norm = 1.8723e-01, time/batch = 15.6111s	
8428/25300 (epoch 16.656), train_loss = 1.12364278, grad/param norm = 2.0338e-01, time/batch = 15.7807s	
8429/25300 (epoch 16.658), train_loss = 0.88237603, grad/param norm = 1.7147e-01, time/batch = 15.7836s	
8430/25300 (epoch 16.660), train_loss = 0.92917351, grad/param norm = 1.9311e-01, time/batch = 15.8770s	
8431/25300 (epoch 16.662), train_loss = 0.87686408, grad/param norm = 1.7100e-01, time/batch = 17.8884s	
8432/25300 (epoch 16.664), train_loss = 0.85746231, grad/param norm = 1.6146e-01, time/batch = 16.8932s	
8433/25300 (epoch 16.666), train_loss = 0.88650088, grad/param norm = 1.6040e-01, time/batch = 16.1327s	
8434/25300 (epoch 16.668), train_loss = 0.99841462, grad/param norm = 2.5362e-01, time/batch = 15.8032s	
8435/25300 (epoch 16.670), train_loss = 0.89515688, grad/param norm = 1.9856e-01, time/batch = 15.7687s	
8436/25300 (epoch 16.672), train_loss = 0.91207118, grad/param norm = 1.7865e-01, time/batch = 15.5698s	
8437/25300 (epoch 16.674), train_loss = 0.92969669, grad/param norm = 1.7300e-01, time/batch = 15.6390s	
8438/25300 (epoch 16.676), train_loss = 0.98334795, grad/param norm = 1.7875e-01, time/batch = 16.3943s	
8439/25300 (epoch 16.678), train_loss = 0.96039665, grad/param norm = 2.0059e-01, time/batch = 17.2003s	
8440/25300 (epoch 16.680), train_loss = 0.84343301, grad/param norm = 1.5916e-01, time/batch = 16.5569s	
8441/25300 (epoch 16.682), train_loss = 0.71980799, grad/param norm = 1.6039e-01, time/batch = 16.9794s	
8442/25300 (epoch 16.684), train_loss = 0.87656972, grad/param norm = 1.6106e-01, time/batch = 17.8064s	
8443/25300 (epoch 16.686), train_loss = 0.86458481, grad/param norm = 1.6675e-01, time/batch = 17.4697s	
8444/25300 (epoch 16.688), train_loss = 0.97986676, grad/param norm = 1.8304e-01, time/batch = 15.8107s	
8445/25300 (epoch 16.690), train_loss = 0.89042043, grad/param norm = 1.6202e-01, time/batch = 17.8996s	
8446/25300 (epoch 16.692), train_loss = 0.98827159, grad/param norm = 1.7751e-01, time/batch = 17.3772s	
8447/25300 (epoch 16.694), train_loss = 0.92287438, grad/param norm = 1.6864e-01, time/batch = 16.7978s	
8448/25300 (epoch 16.696), train_loss = 1.01661947, grad/param norm = 2.0236e-01, time/batch = 17.1527s	
8449/25300 (epoch 16.698), train_loss = 1.07623844, grad/param norm = 1.9552e-01, time/batch = 17.1562s	
8450/25300 (epoch 16.700), train_loss = 0.81634337, grad/param norm = 1.6979e-01, time/batch = 17.8031s	
8451/25300 (epoch 16.702), train_loss = 1.10606241, grad/param norm = 1.9156e-01, time/batch = 15.4003s	
8452/25300 (epoch 16.704), train_loss = 0.82148012, grad/param norm = 1.7198e-01, time/batch = 17.3006s	
8453/25300 (epoch 16.706), train_loss = 1.01582623, grad/param norm = 2.0360e-01, time/batch = 15.3764s	
8454/25300 (epoch 16.708), train_loss = 0.84014890, grad/param norm = 1.5856e-01, time/batch = 16.0446s	
8455/25300 (epoch 16.709), train_loss = 1.18528011, grad/param norm = 1.9260e-01, time/batch = 17.2275s	
8456/25300 (epoch 16.711), train_loss = 1.19114121, grad/param norm = 2.0072e-01, time/batch = 15.9022s	
8457/25300 (epoch 16.713), train_loss = 0.97448226, grad/param norm = 1.7532e-01, time/batch = 16.4037s	
8458/25300 (epoch 16.715), train_loss = 0.99009763, grad/param norm = 1.7086e-01, time/batch = 15.4715s	
8459/25300 (epoch 16.717), train_loss = 0.93695046, grad/param norm = 1.9555e-01, time/batch = 17.1420s	
8460/25300 (epoch 16.719), train_loss = 0.97810437, grad/param norm = 1.8049e-01, time/batch = 15.8084s	
8461/25300 (epoch 16.721), train_loss = 1.02674168, grad/param norm = 1.9004e-01, time/batch = 16.7966s	
8462/25300 (epoch 16.723), train_loss = 0.95329324, grad/param norm = 1.7929e-01, time/batch = 15.5335s	
8463/25300 (epoch 16.725), train_loss = 1.05374622, grad/param norm = 2.0146e-01, time/batch = 18.6336s	
8464/25300 (epoch 16.727), train_loss = 1.04375872, grad/param norm = 1.8455e-01, time/batch = 15.7057s	
8465/25300 (epoch 16.729), train_loss = 0.99565293, grad/param norm = 1.7094e-01, time/batch = 14.9669s	
8466/25300 (epoch 16.731), train_loss = 1.18843907, grad/param norm = 1.9558e-01, time/batch = 15.7949s	
8467/25300 (epoch 16.733), train_loss = 0.97069474, grad/param norm = 1.5438e-01, time/batch = 17.5167s	
8468/25300 (epoch 16.735), train_loss = 1.31889575, grad/param norm = 2.1035e-01, time/batch = 16.2233s	
8469/25300 (epoch 16.737), train_loss = 0.85768256, grad/param norm = 1.5731e-01, time/batch = 16.2237s	
8470/25300 (epoch 16.739), train_loss = 1.14143894, grad/param norm = 1.8286e-01, time/batch = 16.3791s	
8471/25300 (epoch 16.741), train_loss = 1.08314769, grad/param norm = 2.0087e-01, time/batch = 16.8631s	
8472/25300 (epoch 16.743), train_loss = 0.97447351, grad/param norm = 1.7650e-01, time/batch = 17.4701s	
8473/25300 (epoch 16.745), train_loss = 0.92585482, grad/param norm = 1.6405e-01, time/batch = 16.6199s	
8474/25300 (epoch 16.747), train_loss = 0.90417942, grad/param norm = 1.7297e-01, time/batch = 15.7995s	
8475/25300 (epoch 16.749), train_loss = 1.05087689, grad/param norm = 1.8362e-01, time/batch = 17.2365s	
8476/25300 (epoch 16.751), train_loss = 1.10650854, grad/param norm = 1.9461e-01, time/batch = 15.7229s	
8477/25300 (epoch 16.753), train_loss = 0.93564091, grad/param norm = 1.9228e-01, time/batch = 15.8803s	
8478/25300 (epoch 16.755), train_loss = 1.13088702, grad/param norm = 2.1668e-01, time/batch = 15.8998s	
8479/25300 (epoch 16.757), train_loss = 0.92508367, grad/param norm = 1.7762e-01, time/batch = 17.1376s	
8480/25300 (epoch 16.759), train_loss = 0.92145344, grad/param norm = 1.8093e-01, time/batch = 16.1298s	
8481/25300 (epoch 16.761), train_loss = 1.15967886, grad/param norm = 1.9464e-01, time/batch = 19.6287s	
8482/25300 (epoch 16.763), train_loss = 0.94411145, grad/param norm = 1.8102e-01, time/batch = 19.2966s	
8483/25300 (epoch 16.765), train_loss = 0.95379214, grad/param norm = 1.7795e-01, time/batch = 17.0440s	
8484/25300 (epoch 16.767), train_loss = 0.94776327, grad/param norm = 1.7143e-01, time/batch = 19.2038s	
8485/25300 (epoch 16.769), train_loss = 1.04875364, grad/param norm = 1.9209e-01, time/batch = 18.0374s	
8486/25300 (epoch 16.771), train_loss = 1.13224036, grad/param norm = 1.9830e-01, time/batch = 17.2952s	
8487/25300 (epoch 16.773), train_loss = 1.13159236, grad/param norm = 2.0252e-01, time/batch = 15.7331s	
8488/25300 (epoch 16.775), train_loss = 0.97958692, grad/param norm = 1.6187e-01, time/batch = 17.2182s	
8489/25300 (epoch 16.777), train_loss = 1.02403839, grad/param norm = 1.9190e-01, time/batch = 15.8659s	
8490/25300 (epoch 16.779), train_loss = 1.08471929, grad/param norm = 1.7124e-01, time/batch = 17.1176s	
8491/25300 (epoch 16.781), train_loss = 1.04337468, grad/param norm = 1.7639e-01, time/batch = 17.4706s	
8492/25300 (epoch 16.783), train_loss = 1.16155556, grad/param norm = 1.9846e-01, time/batch = 17.4767s	
8493/25300 (epoch 16.785), train_loss = 1.11853645, grad/param norm = 1.9095e-01, time/batch = 15.8169s	
8494/25300 (epoch 16.787), train_loss = 1.09930167, grad/param norm = 1.9594e-01, time/batch = 15.3202s	
8495/25300 (epoch 16.789), train_loss = 1.24503610, grad/param norm = 2.0575e-01, time/batch = 16.0652s	
8496/25300 (epoch 16.791), train_loss = 1.08698929, grad/param norm = 1.9773e-01, time/batch = 16.3890s	
8497/25300 (epoch 16.792), train_loss = 1.12311082, grad/param norm = 1.7610e-01, time/batch = 16.5533s	
8498/25300 (epoch 16.794), train_loss = 1.02407378, grad/param norm = 1.8114e-01, time/batch = 17.4639s	
8499/25300 (epoch 16.796), train_loss = 0.97672735, grad/param norm = 1.9899e-01, time/batch = 16.4598s	
8500/25300 (epoch 16.798), train_loss = 1.15529162, grad/param norm = 1.9989e-01, time/batch = 17.3085s	
8501/25300 (epoch 16.800), train_loss = 1.02058035, grad/param norm = 1.7147e-01, time/batch = 16.3632s	
8502/25300 (epoch 16.802), train_loss = 0.81478757, grad/param norm = 1.6674e-01, time/batch = 17.4534s	
8503/25300 (epoch 16.804), train_loss = 1.03310779, grad/param norm = 1.7320e-01, time/batch = 19.0569s	
8504/25300 (epoch 16.806), train_loss = 1.10045062, grad/param norm = 1.9931e-01, time/batch = 17.1120s	
8505/25300 (epoch 16.808), train_loss = 1.07804376, grad/param norm = 1.9847e-01, time/batch = 17.3051s	
8506/25300 (epoch 16.810), train_loss = 1.02479619, grad/param norm = 1.8991e-01, time/batch = 19.3771s	
8507/25300 (epoch 16.812), train_loss = 1.12327031, grad/param norm = 1.8556e-01, time/batch = 16.9561s	
8508/25300 (epoch 16.814), train_loss = 1.20487692, grad/param norm = 2.1154e-01, time/batch = 16.0479s	
8509/25300 (epoch 16.816), train_loss = 1.28293217, grad/param norm = 2.0381e-01, time/batch = 17.7994s	
8510/25300 (epoch 16.818), train_loss = 1.07747670, grad/param norm = 1.7258e-01, time/batch = 18.8745s	
8511/25300 (epoch 16.820), train_loss = 1.09907832, grad/param norm = 1.9331e-01, time/batch = 15.6838s	
8512/25300 (epoch 16.822), train_loss = 1.00937138, grad/param norm = 1.7275e-01, time/batch = 15.3556s	
8513/25300 (epoch 16.824), train_loss = 1.10739114, grad/param norm = 1.8755e-01, time/batch = 16.0397s	
8514/25300 (epoch 16.826), train_loss = 0.98098910, grad/param norm = 1.8424e-01, time/batch = 15.5309s	
8515/25300 (epoch 16.828), train_loss = 0.96541743, grad/param norm = 1.8865e-01, time/batch = 15.5313s	
8516/25300 (epoch 16.830), train_loss = 1.05097055, grad/param norm = 1.7460e-01, time/batch = 16.0748s	
8517/25300 (epoch 16.832), train_loss = 1.09636671, grad/param norm = 1.9410e-01, time/batch = 15.7265s	
8518/25300 (epoch 16.834), train_loss = 0.89707991, grad/param norm = 1.6508e-01, time/batch = 16.1386s	
8519/25300 (epoch 16.836), train_loss = 0.97050944, grad/param norm = 1.7567e-01, time/batch = 17.0474s	
8520/25300 (epoch 16.838), train_loss = 0.99936830, grad/param norm = 1.7585e-01, time/batch = 16.3040s	
8521/25300 (epoch 16.840), train_loss = 1.16335454, grad/param norm = 1.9331e-01, time/batch = 17.9560s	
8522/25300 (epoch 16.842), train_loss = 1.04812763, grad/param norm = 2.2632e-01, time/batch = 16.1435s	
8523/25300 (epoch 16.844), train_loss = 1.08343960, grad/param norm = 1.7660e-01, time/batch = 15.4710s	
8524/25300 (epoch 16.846), train_loss = 1.07811911, grad/param norm = 1.7353e-01, time/batch = 16.6386s	
8525/25300 (epoch 16.848), train_loss = 1.14768899, grad/param norm = 2.0168e-01, time/batch = 15.8060s	
8526/25300 (epoch 16.850), train_loss = 1.11477094, grad/param norm = 1.9977e-01, time/batch = 16.6274s	
8527/25300 (epoch 16.852), train_loss = 1.10018927, grad/param norm = 1.9471e-01, time/batch = 15.9833s	
8528/25300 (epoch 16.854), train_loss = 1.20020469, grad/param norm = 1.9695e-01, time/batch = 16.4756s	
8529/25300 (epoch 16.856), train_loss = 1.02030738, grad/param norm = 1.9160e-01, time/batch = 17.6914s	
8530/25300 (epoch 16.858), train_loss = 1.09041214, grad/param norm = 2.0442e-01, time/batch = 18.4669s	
8531/25300 (epoch 16.860), train_loss = 0.87970311, grad/param norm = 1.7447e-01, time/batch = 18.0413s	
8532/25300 (epoch 16.862), train_loss = 1.06016527, grad/param norm = 2.0251e-01, time/batch = 17.7070s	
8533/25300 (epoch 16.864), train_loss = 1.15352785, grad/param norm = 1.8343e-01, time/batch = 15.7130s	
8534/25300 (epoch 16.866), train_loss = 1.05512684, grad/param norm = 1.9615e-01, time/batch = 16.9626s	
8535/25300 (epoch 16.868), train_loss = 1.16177823, grad/param norm = 1.9944e-01, time/batch = 17.3046s	
8536/25300 (epoch 16.870), train_loss = 1.12973351, grad/param norm = 1.7908e-01, time/batch = 16.2131s	
8537/25300 (epoch 16.872), train_loss = 1.13405520, grad/param norm = 2.2053e-01, time/batch = 15.4922s	
8538/25300 (epoch 16.874), train_loss = 1.11998396, grad/param norm = 1.9466e-01, time/batch = 17.1475s	
8539/25300 (epoch 16.875), train_loss = 1.02913569, grad/param norm = 1.7604e-01, time/batch = 15.9757s	
8540/25300 (epoch 16.877), train_loss = 0.99824812, grad/param norm = 1.7332e-01, time/batch = 15.8129s	
8541/25300 (epoch 16.879), train_loss = 1.03697181, grad/param norm = 2.0091e-01, time/batch = 15.5700s	
8542/25300 (epoch 16.881), train_loss = 1.34146153, grad/param norm = 2.2731e-01, time/batch = 17.9708s	
8543/25300 (epoch 16.883), train_loss = 1.30102351, grad/param norm = 1.9084e-01, time/batch = 15.4649s	
8544/25300 (epoch 16.885), train_loss = 1.15299455, grad/param norm = 2.1641e-01, time/batch = 16.1099s	
8545/25300 (epoch 16.887), train_loss = 1.10974038, grad/param norm = 2.0020e-01, time/batch = 17.0597s	
8546/25300 (epoch 16.889), train_loss = 1.24028135, grad/param norm = 2.2078e-01, time/batch = 17.8117s	
8547/25300 (epoch 16.891), train_loss = 1.19397467, grad/param norm = 2.7175e-01, time/batch = 15.1502s	
8548/25300 (epoch 16.893), train_loss = 1.19606194, grad/param norm = 2.4765e-01, time/batch = 16.0684s	
8549/25300 (epoch 16.895), train_loss = 0.84019861, grad/param norm = 1.9246e-01, time/batch = 16.0816s	
8550/25300 (epoch 16.897), train_loss = 0.97345673, grad/param norm = 1.9719e-01, time/batch = 15.5829s	
8551/25300 (epoch 16.899), train_loss = 1.05596744, grad/param norm = 1.8506e-01, time/batch = 15.5465s	
8552/25300 (epoch 16.901), train_loss = 1.10675173, grad/param norm = 1.8144e-01, time/batch = 16.4093s	
8553/25300 (epoch 16.903), train_loss = 0.85499537, grad/param norm = 1.7516e-01, time/batch = 16.2161s	
8554/25300 (epoch 16.905), train_loss = 0.99552094, grad/param norm = 2.1110e-01, time/batch = 16.3088s	
8555/25300 (epoch 16.907), train_loss = 1.00455096, grad/param norm = 1.9975e-01, time/batch = 16.4757s	
8556/25300 (epoch 16.909), train_loss = 1.11802990, grad/param norm = 1.9105e-01, time/batch = 16.0610s	
8557/25300 (epoch 16.911), train_loss = 1.24556840, grad/param norm = 2.0741e-01, time/batch = 17.9061s	
8558/25300 (epoch 16.913), train_loss = 1.27655298, grad/param norm = 2.1756e-01, time/batch = 15.3988s	
8559/25300 (epoch 16.915), train_loss = 1.01822046, grad/param norm = 2.0963e-01, time/batch = 15.7256s	
8560/25300 (epoch 16.917), train_loss = 1.13280371, grad/param norm = 2.1574e-01, time/batch = 16.6329s	
8561/25300 (epoch 16.919), train_loss = 1.21631024, grad/param norm = 2.0802e-01, time/batch = 15.6355s	
8562/25300 (epoch 16.921), train_loss = 0.95692534, grad/param norm = 1.7934e-01, time/batch = 15.6007s	
8563/25300 (epoch 16.923), train_loss = 1.21606469, grad/param norm = 1.9216e-01, time/batch = 15.6384s	
8564/25300 (epoch 16.925), train_loss = 1.04421146, grad/param norm = 2.0024e-01, time/batch = 15.6486s	
8565/25300 (epoch 16.927), train_loss = 1.01391712, grad/param norm = 1.9005e-01, time/batch = 15.2265s	
8566/25300 (epoch 16.929), train_loss = 1.02931343, grad/param norm = 1.7140e-01, time/batch = 15.2260s	
8567/25300 (epoch 16.931), train_loss = 1.14569812, grad/param norm = 2.0298e-01, time/batch = 15.3237s	
8568/25300 (epoch 16.933), train_loss = 1.13688385, grad/param norm = 1.9177e-01, time/batch = 15.3160s	
8569/25300 (epoch 16.935), train_loss = 1.10169166, grad/param norm = 1.8241e-01, time/batch = 15.5057s	
8570/25300 (epoch 16.937), train_loss = 0.80877557, grad/param norm = 1.5496e-01, time/batch = 15.3781s	
8571/25300 (epoch 16.939), train_loss = 1.14535337, grad/param norm = 2.1415e-01, time/batch = 16.5736s	
8572/25300 (epoch 16.941), train_loss = 1.00108428, grad/param norm = 1.9260e-01, time/batch = 15.5559s	
8573/25300 (epoch 16.943), train_loss = 1.07056802, grad/param norm = 1.7337e-01, time/batch = 15.7287s	
8574/25300 (epoch 16.945), train_loss = 1.11594449, grad/param norm = 1.9172e-01, time/batch = 15.8094s	
8575/25300 (epoch 16.947), train_loss = 0.95985316, grad/param norm = 1.7776e-01, time/batch = 15.9903s	
8576/25300 (epoch 16.949), train_loss = 1.11516088, grad/param norm = 1.8276e-01, time/batch = 15.9690s	
8577/25300 (epoch 16.951), train_loss = 1.04471509, grad/param norm = 1.7994e-01, time/batch = 15.9475s	
8578/25300 (epoch 16.953), train_loss = 1.09775215, grad/param norm = 1.9813e-01, time/batch = 16.1439s	
8579/25300 (epoch 16.955), train_loss = 1.30856469, grad/param norm = 2.2599e-01, time/batch = 15.7352s	
8580/25300 (epoch 16.957), train_loss = 1.24590725, grad/param norm = 2.1810e-01, time/batch = 15.6554s	
8581/25300 (epoch 16.958), train_loss = 1.13843014, grad/param norm = 2.1267e-01, time/batch = 16.2869s	
8582/25300 (epoch 16.960), train_loss = 1.27981151, grad/param norm = 2.2116e-01, time/batch = 15.3078s	
8583/25300 (epoch 16.962), train_loss = 1.21634238, grad/param norm = 2.1958e-01, time/batch = 15.4680s	
8584/25300 (epoch 16.964), train_loss = 1.15641758, grad/param norm = 2.0233e-01, time/batch = 15.0563s	
8585/25300 (epoch 16.966), train_loss = 0.88930829, grad/param norm = 1.6948e-01, time/batch = 15.3503s	
8586/25300 (epoch 16.968), train_loss = 0.90102225, grad/param norm = 1.6214e-01, time/batch = 15.2267s	
8587/25300 (epoch 16.970), train_loss = 1.02984126, grad/param norm = 2.3343e-01, time/batch = 15.2929s	
8588/25300 (epoch 16.972), train_loss = 1.07118777, grad/param norm = 1.9280e-01, time/batch = 15.3900s	
8589/25300 (epoch 16.974), train_loss = 1.26341379, grad/param norm = 2.2329e-01, time/batch = 15.3750s	
8590/25300 (epoch 16.976), train_loss = 1.10771421, grad/param norm = 1.9682e-01, time/batch = 15.7062s	
8591/25300 (epoch 16.978), train_loss = 1.06764852, grad/param norm = 1.7445e-01, time/batch = 15.9002s	
8592/25300 (epoch 16.980), train_loss = 1.11419279, grad/param norm = 1.9876e-01, time/batch = 15.9669s	
8593/25300 (epoch 16.982), train_loss = 1.01257445, grad/param norm = 1.8903e-01, time/batch = 15.4882s	
8594/25300 (epoch 16.984), train_loss = 1.05162808, grad/param norm = 2.0288e-01, time/batch = 15.5764s	
8595/25300 (epoch 16.986), train_loss = 1.15329433, grad/param norm = 2.0184e-01, time/batch = 15.3120s	
8596/25300 (epoch 16.988), train_loss = 1.13310442, grad/param norm = 1.9440e-01, time/batch = 15.3850s	
8597/25300 (epoch 16.990), train_loss = 1.05801248, grad/param norm = 1.8241e-01, time/batch = 15.3271s	
8598/25300 (epoch 16.992), train_loss = 0.88396501, grad/param norm = 1.7777e-01, time/batch = 15.5606s	
8599/25300 (epoch 16.994), train_loss = 1.07273738, grad/param norm = 1.9220e-01, time/batch = 15.2314s	
8600/25300 (epoch 16.996), train_loss = 1.23534990, grad/param norm = 2.4734e-01, time/batch = 15.3023s	
8601/25300 (epoch 16.998), train_loss = 1.19143978, grad/param norm = 2.0720e-01, time/batch = 15.5481s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
8602/25300 (epoch 17.000), train_loss = 1.07933321, grad/param norm = 2.0175e-01, time/batch = 15.4890s	
8603/25300 (epoch 17.002), train_loss = 0.91378720, grad/param norm = 1.5793e-01, time/batch = 15.4135s	
8604/25300 (epoch 17.004), train_loss = 0.90975171, grad/param norm = 1.8321e-01, time/batch = 15.2877s	
8605/25300 (epoch 17.006), train_loss = 1.19248294, grad/param norm = 1.9321e-01, time/batch = 15.3242s	
8606/25300 (epoch 17.008), train_loss = 1.03663740, grad/param norm = 1.7636e-01, time/batch = 15.8120s	
8607/25300 (epoch 17.010), train_loss = 1.06331961, grad/param norm = 1.7600e-01, time/batch = 15.3166s	
8608/25300 (epoch 17.012), train_loss = 0.97157668, grad/param norm = 1.8484e-01, time/batch = 15.2216s	
8609/25300 (epoch 17.014), train_loss = 1.19243094, grad/param norm = 1.9491e-01, time/batch = 15.2372s	
8610/25300 (epoch 17.016), train_loss = 1.08468643, grad/param norm = 2.0207e-01, time/batch = 15.5436s	
8611/25300 (epoch 17.018), train_loss = 0.96206799, grad/param norm = 1.8469e-01, time/batch = 15.9872s	
8612/25300 (epoch 17.020), train_loss = 1.01141599, grad/param norm = 1.8259e-01, time/batch = 15.4728s	
8613/25300 (epoch 17.022), train_loss = 1.09373007, grad/param norm = 2.0487e-01, time/batch = 15.7275s	
8614/25300 (epoch 17.024), train_loss = 0.79005572, grad/param norm = 1.4254e-01, time/batch = 15.3238s	
8615/25300 (epoch 17.026), train_loss = 1.00004339, grad/param norm = 1.9858e-01, time/batch = 15.4018s	
8616/25300 (epoch 17.028), train_loss = 0.93849299, grad/param norm = 1.7224e-01, time/batch = 15.6779s	
8617/25300 (epoch 17.030), train_loss = 1.15936874, grad/param norm = 1.8008e-01, time/batch = 15.5793s	
8618/25300 (epoch 17.032), train_loss = 0.98539085, grad/param norm = 1.8005e-01, time/batch = 15.4128s	
8619/25300 (epoch 17.034), train_loss = 0.84325748, grad/param norm = 1.6536e-01, time/batch = 15.5597s	
8620/25300 (epoch 17.036), train_loss = 0.86715589, grad/param norm = 1.6247e-01, time/batch = 15.3994s	
8621/25300 (epoch 17.038), train_loss = 0.76806401, grad/param norm = 1.3994e-01, time/batch = 15.8869s	
8622/25300 (epoch 17.040), train_loss = 1.07189831, grad/param norm = 1.8440e-01, time/batch = 16.3103s	
8623/25300 (epoch 17.042), train_loss = 0.98945811, grad/param norm = 1.7199e-01, time/batch = 15.5514s	
8624/25300 (epoch 17.043), train_loss = 0.84771855, grad/param norm = 1.5281e-01, time/batch = 16.4723s	
8625/25300 (epoch 17.045), train_loss = 0.89204114, grad/param norm = 1.7064e-01, time/batch = 15.7291s	
8626/25300 (epoch 17.047), train_loss = 1.08612612, grad/param norm = 1.8667e-01, time/batch = 15.7405s	
8627/25300 (epoch 17.049), train_loss = 1.05964476, grad/param norm = 1.9854e-01, time/batch = 15.7197s	
8628/25300 (epoch 17.051), train_loss = 1.13812776, grad/param norm = 2.0189e-01, time/batch = 15.7315s	
8629/25300 (epoch 17.053), train_loss = 0.84860593, grad/param norm = 1.5295e-01, time/batch = 15.8221s	
8630/25300 (epoch 17.055), train_loss = 0.90338402, grad/param norm = 1.6533e-01, time/batch = 15.7219s	
8631/25300 (epoch 17.057), train_loss = 0.86766082, grad/param norm = 1.5652e-01, time/batch = 15.7201s	
8632/25300 (epoch 17.059), train_loss = 0.97461588, grad/param norm = 1.8100e-01, time/batch = 15.6580s	
8633/25300 (epoch 17.061), train_loss = 0.93827354, grad/param norm = 1.7666e-01, time/batch = 15.9733s	
8634/25300 (epoch 17.063), train_loss = 0.90937179, grad/param norm = 1.8214e-01, time/batch = 15.2025s	
8635/25300 (epoch 17.065), train_loss = 1.10112815, grad/param norm = 2.0280e-01, time/batch = 15.7331s	
8636/25300 (epoch 17.067), train_loss = 1.12903823, grad/param norm = 1.8351e-01, time/batch = 15.6532s	
8637/25300 (epoch 17.069), train_loss = 0.99172263, grad/param norm = 1.8652e-01, time/batch = 15.5580s	
8638/25300 (epoch 17.071), train_loss = 1.15241339, grad/param norm = 1.8855e-01, time/batch = 17.8498s	
8639/25300 (epoch 17.073), train_loss = 0.96418281, grad/param norm = 1.5488e-01, time/batch = 25.4967s	
8640/25300 (epoch 17.075), train_loss = 1.09792455, grad/param norm = 1.9901e-01, time/batch = 15.3323s	
8641/25300 (epoch 17.077), train_loss = 1.04719365, grad/param norm = 2.0187e-01, time/batch = 15.4798s	
8642/25300 (epoch 17.079), train_loss = 1.00274986, grad/param norm = 1.7288e-01, time/batch = 15.5621s	
8643/25300 (epoch 17.081), train_loss = 0.99592678, grad/param norm = 1.7296e-01, time/batch = 15.4007s	
8644/25300 (epoch 17.083), train_loss = 1.00646047, grad/param norm = 1.7328e-01, time/batch = 15.4705s	
8645/25300 (epoch 17.085), train_loss = 1.26848018, grad/param norm = 2.2612e-01, time/batch = 15.4106s	
8646/25300 (epoch 17.087), train_loss = 1.09949446, grad/param norm = 1.8358e-01, time/batch = 15.4867s	
8647/25300 (epoch 17.089), train_loss = 1.09271170, grad/param norm = 1.8979e-01, time/batch = 15.4132s	
8648/25300 (epoch 17.091), train_loss = 1.21838089, grad/param norm = 1.9942e-01, time/batch = 15.8995s	
8649/25300 (epoch 17.093), train_loss = 1.15898548, grad/param norm = 1.9449e-01, time/batch = 15.4868s	
8650/25300 (epoch 17.095), train_loss = 1.11689684, grad/param norm = 1.8526e-01, time/batch = 15.7201s	
8651/25300 (epoch 17.097), train_loss = 1.05247586, grad/param norm = 1.7564e-01, time/batch = 16.2422s	
8652/25300 (epoch 17.099), train_loss = 1.09942646, grad/param norm = 1.8957e-01, time/batch = 15.6566s	
8653/25300 (epoch 17.101), train_loss = 1.02169317, grad/param norm = 1.7932e-01, time/batch = 16.2986s	
8654/25300 (epoch 17.103), train_loss = 1.03993761, grad/param norm = 1.8443e-01, time/batch = 15.5991s	
8655/25300 (epoch 17.105), train_loss = 1.08237363, grad/param norm = 1.7217e-01, time/batch = 15.3205s	
8656/25300 (epoch 17.107), train_loss = 1.12102435, grad/param norm = 2.0854e-01, time/batch = 15.4785s	
8657/25300 (epoch 17.109), train_loss = 1.02322254, grad/param norm = 1.9498e-01, time/batch = 15.6320s	
8658/25300 (epoch 17.111), train_loss = 1.02788017, grad/param norm = 1.7073e-01, time/batch = 15.5637s	
8659/25300 (epoch 17.113), train_loss = 0.99258899, grad/param norm = 1.8826e-01, time/batch = 16.0586s	
8660/25300 (epoch 17.115), train_loss = 1.01697716, grad/param norm = 1.8515e-01, time/batch = 16.5496s	
8661/25300 (epoch 17.117), train_loss = 1.09452108, grad/param norm = 1.6929e-01, time/batch = 15.7263s	
8662/25300 (epoch 17.119), train_loss = 1.00350415, grad/param norm = 1.8367e-01, time/batch = 16.6496s	
8663/25300 (epoch 17.121), train_loss = 1.08031708, grad/param norm = 2.0006e-01, time/batch = 16.3097s	
8664/25300 (epoch 17.123), train_loss = 1.02450777, grad/param norm = 2.0914e-01, time/batch = 15.6478s	
8665/25300 (epoch 17.125), train_loss = 1.13965348, grad/param norm = 2.0504e-01, time/batch = 16.8201s	
8666/25300 (epoch 17.126), train_loss = 1.03929735, grad/param norm = 2.0908e-01, time/batch = 15.5592s	
8667/25300 (epoch 17.128), train_loss = 1.03630142, grad/param norm = 1.8538e-01, time/batch = 16.4896s	
8668/25300 (epoch 17.130), train_loss = 0.85368294, grad/param norm = 1.5587e-01, time/batch = 15.3120s	
8669/25300 (epoch 17.132), train_loss = 0.87464018, grad/param norm = 1.6963e-01, time/batch = 15.5698s	
8670/25300 (epoch 17.134), train_loss = 0.82916810, grad/param norm = 1.5628e-01, time/batch = 15.8190s	
8671/25300 (epoch 17.136), train_loss = 1.03757757, grad/param norm = 1.7804e-01, time/batch = 15.8905s	
8672/25300 (epoch 17.138), train_loss = 0.89493397, grad/param norm = 1.5935e-01, time/batch = 15.7196s	
8673/25300 (epoch 17.140), train_loss = 0.96714103, grad/param norm = 1.7509e-01, time/batch = 16.0578s	
8674/25300 (epoch 17.142), train_loss = 1.14499130, grad/param norm = 1.9297e-01, time/batch = 15.6414s	
8675/25300 (epoch 17.144), train_loss = 1.08740956, grad/param norm = 1.8516e-01, time/batch = 15.5545s	
8676/25300 (epoch 17.146), train_loss = 1.10214329, grad/param norm = 2.0489e-01, time/batch = 15.9832s	
8677/25300 (epoch 17.148), train_loss = 1.02557955, grad/param norm = 1.9472e-01, time/batch = 15.7382s	
8678/25300 (epoch 17.150), train_loss = 1.14987636, grad/param norm = 2.1822e-01, time/batch = 15.1891s	
8679/25300 (epoch 17.152), train_loss = 1.21181244, grad/param norm = 2.1177e-01, time/batch = 15.3399s	
8680/25300 (epoch 17.154), train_loss = 0.90817897, grad/param norm = 1.7248e-01, time/batch = 15.2690s	
8681/25300 (epoch 17.156), train_loss = 1.09505627, grad/param norm = 1.8942e-01, time/batch = 15.7279s	
8682/25300 (epoch 17.158), train_loss = 0.93773072, grad/param norm = 1.7683e-01, time/batch = 16.6481s	
8683/25300 (epoch 17.160), train_loss = 1.02922710, grad/param norm = 1.7914e-01, time/batch = 15.7191s	
8684/25300 (epoch 17.162), train_loss = 0.97746523, grad/param norm = 1.9418e-01, time/batch = 16.4071s	
8685/25300 (epoch 17.164), train_loss = 1.10580061, grad/param norm = 1.8873e-01, time/batch = 16.1531s	
8686/25300 (epoch 17.166), train_loss = 1.04322305, grad/param norm = 1.8021e-01, time/batch = 15.5748s	
8687/25300 (epoch 17.168), train_loss = 0.91259396, grad/param norm = 1.5576e-01, time/batch = 16.0503s	
8688/25300 (epoch 17.170), train_loss = 0.99750636, grad/param norm = 1.7425e-01, time/batch = 15.8244s	
8689/25300 (epoch 17.172), train_loss = 0.93522023, grad/param norm = 1.7500e-01, time/batch = 15.6463s	
8690/25300 (epoch 17.174), train_loss = 0.91847927, grad/param norm = 1.7434e-01, time/batch = 15.6428s	
8691/25300 (epoch 17.176), train_loss = 0.95912795, grad/param norm = 1.9116e-01, time/batch = 15.5605s	
8692/25300 (epoch 17.178), train_loss = 1.15734743, grad/param norm = 1.9477e-01, time/batch = 15.6643s	
8693/25300 (epoch 17.180), train_loss = 0.84845790, grad/param norm = 1.5725e-01, time/batch = 15.8175s	
8694/25300 (epoch 17.182), train_loss = 0.98497786, grad/param norm = 1.7969e-01, time/batch = 15.4757s	
8695/25300 (epoch 17.184), train_loss = 0.99203953, grad/param norm = 1.8414e-01, time/batch = 15.4777s	
8696/25300 (epoch 17.186), train_loss = 0.95334305, grad/param norm = 1.9492e-01, time/batch = 15.5799s	
8697/25300 (epoch 17.188), train_loss = 1.04129028, grad/param norm = 2.0184e-01, time/batch = 15.4516s	
8698/25300 (epoch 17.190), train_loss = 0.99113761, grad/param norm = 1.9184e-01, time/batch = 15.7240s	
8699/25300 (epoch 17.192), train_loss = 1.00300499, grad/param norm = 1.9344e-01, time/batch = 15.6457s	
8700/25300 (epoch 17.194), train_loss = 1.00940938, grad/param norm = 1.8929e-01, time/batch = 15.4031s	
8701/25300 (epoch 17.196), train_loss = 1.09548155, grad/param norm = 2.1867e-01, time/batch = 16.5668s	
8702/25300 (epoch 17.198), train_loss = 0.96649618, grad/param norm = 1.9418e-01, time/batch = 15.7968s	
8703/25300 (epoch 17.200), train_loss = 1.01833611, grad/param norm = 1.9788e-01, time/batch = 15.7472s	
8704/25300 (epoch 17.202), train_loss = 0.99708154, grad/param norm = 1.8739e-01, time/batch = 15.6522s	
8705/25300 (epoch 17.204), train_loss = 0.98342152, grad/param norm = 1.7088e-01, time/batch = 16.2257s	
8706/25300 (epoch 17.206), train_loss = 1.09993385, grad/param norm = 1.7691e-01, time/batch = 15.3660s	
8707/25300 (epoch 17.208), train_loss = 0.90929628, grad/param norm = 1.9910e-01, time/batch = 15.6534s	
8708/25300 (epoch 17.209), train_loss = 0.86040284, grad/param norm = 1.7416e-01, time/batch = 15.7238s	
8709/25300 (epoch 17.211), train_loss = 0.98490863, grad/param norm = 1.8888e-01, time/batch = 15.8709s	
8710/25300 (epoch 17.213), train_loss = 1.05593353, grad/param norm = 1.8169e-01, time/batch = 15.3813s	
8711/25300 (epoch 17.215), train_loss = 1.04499801, grad/param norm = 1.8631e-01, time/batch = 15.9964s	
8712/25300 (epoch 17.217), train_loss = 1.06065582, grad/param norm = 2.0876e-01, time/batch = 16.2336s	
8713/25300 (epoch 17.219), train_loss = 1.12858124, grad/param norm = 1.9520e-01, time/batch = 15.5585s	
8714/25300 (epoch 17.221), train_loss = 1.16662402, grad/param norm = 2.0246e-01, time/batch = 15.7111s	
8715/25300 (epoch 17.223), train_loss = 1.09712522, grad/param norm = 2.2570e-01, time/batch = 16.5447s	
8716/25300 (epoch 17.225), train_loss = 1.48969856, grad/param norm = 2.9352e-01, time/batch = 15.6359s	
8717/25300 (epoch 17.227), train_loss = 1.14773902, grad/param norm = 1.8385e-01, time/batch = 15.4782s	
8718/25300 (epoch 17.229), train_loss = 1.02363877, grad/param norm = 1.7612e-01, time/batch = 16.2216s	
8719/25300 (epoch 17.231), train_loss = 1.00572264, grad/param norm = 1.7891e-01, time/batch = 17.1446s	
8720/25300 (epoch 17.233), train_loss = 1.11662364, grad/param norm = 2.4458e-01, time/batch = 15.3819s	
8721/25300 (epoch 17.235), train_loss = 1.02214067, grad/param norm = 1.9744e-01, time/batch = 15.9594s	
8722/25300 (epoch 17.237), train_loss = 1.22915171, grad/param norm = 2.1644e-01, time/batch = 15.7392s	
8723/25300 (epoch 17.239), train_loss = 1.04489816, grad/param norm = 1.8395e-01, time/batch = 16.2003s	
8724/25300 (epoch 17.241), train_loss = 1.16834805, grad/param norm = 1.9170e-01, time/batch = 15.6477s	
8725/25300 (epoch 17.243), train_loss = 1.36387624, grad/param norm = 2.2515e-01, time/batch = 15.6613s	
8726/25300 (epoch 17.245), train_loss = 0.97858353, grad/param norm = 1.8638e-01, time/batch = 15.9887s	
8727/25300 (epoch 17.247), train_loss = 1.13905769, grad/param norm = 1.8917e-01, time/batch = 15.6527s	
8728/25300 (epoch 17.249), train_loss = 0.90880601, grad/param norm = 1.5901e-01, time/batch = 15.8144s	
8729/25300 (epoch 17.251), train_loss = 0.87825932, grad/param norm = 1.7606e-01, time/batch = 16.2248s	
8730/25300 (epoch 17.253), train_loss = 1.00592871, grad/param norm = 1.9071e-01, time/batch = 15.7327s	
8731/25300 (epoch 17.255), train_loss = 0.99560765, grad/param norm = 2.3166e-01, time/batch = 15.7426s	
8732/25300 (epoch 17.257), train_loss = 1.07255789, grad/param norm = 2.1682e-01, time/batch = 16.2908s	
8733/25300 (epoch 17.259), train_loss = 1.26932546, grad/param norm = 2.0475e-01, time/batch = 15.4123s	
8734/25300 (epoch 17.261), train_loss = 1.19693340, grad/param norm = 2.0586e-01, time/batch = 17.2697s	
8735/25300 (epoch 17.263), train_loss = 1.19430618, grad/param norm = 2.1156e-01, time/batch = 15.3809s	
8736/25300 (epoch 17.265), train_loss = 1.24405822, grad/param norm = 2.0221e-01, time/batch = 15.8961s	
8737/25300 (epoch 17.267), train_loss = 1.15047044, grad/param norm = 1.9144e-01, time/batch = 15.4812s	
8738/25300 (epoch 17.269), train_loss = 0.87796319, grad/param norm = 1.5904e-01, time/batch = 16.2370s	
8739/25300 (epoch 17.271), train_loss = 1.01633908, grad/param norm = 1.8371e-01, time/batch = 15.4828s	
8740/25300 (epoch 17.273), train_loss = 1.11715188, grad/param norm = 2.2825e-01, time/batch = 16.0540s	
8741/25300 (epoch 17.275), train_loss = 0.97974755, grad/param norm = 1.5819e-01, time/batch = 15.6443s	
8742/25300 (epoch 17.277), train_loss = 1.01314107, grad/param norm = 1.7930e-01, time/batch = 15.6415s	
8743/25300 (epoch 17.279), train_loss = 1.02122993, grad/param norm = 1.7395e-01, time/batch = 16.7045s	
8744/25300 (epoch 17.281), train_loss = 1.20841944, grad/param norm = 2.1172e-01, time/batch = 15.7057s	
8745/25300 (epoch 17.283), train_loss = 0.93887429, grad/param norm = 1.6495e-01, time/batch = 16.3235s	
8746/25300 (epoch 17.285), train_loss = 1.08741906, grad/param norm = 2.0918e-01, time/batch = 16.3236s	
8747/25300 (epoch 17.287), train_loss = 1.08233261, grad/param norm = 1.7363e-01, time/batch = 15.9670s	
8748/25300 (epoch 17.289), train_loss = 0.99173352, grad/param norm = 1.7449e-01, time/batch = 16.3955s	
8749/25300 (epoch 17.291), train_loss = 0.99174523, grad/param norm = 1.6913e-01, time/batch = 15.6539s	
8750/25300 (epoch 17.292), train_loss = 1.20852598, grad/param norm = 1.8959e-01, time/batch = 16.0669s	
8751/25300 (epoch 17.294), train_loss = 1.06939160, grad/param norm = 1.9566e-01, time/batch = 15.9587s	
8752/25300 (epoch 17.296), train_loss = 0.93854142, grad/param norm = 1.8619e-01, time/batch = 15.4709s	
8753/25300 (epoch 17.298), train_loss = 1.12211201, grad/param norm = 1.9823e-01, time/batch = 16.1571s	
8754/25300 (epoch 17.300), train_loss = 1.16895717, grad/param norm = 2.1318e-01, time/batch = 15.7207s	
8755/25300 (epoch 17.302), train_loss = 0.85941412, grad/param norm = 1.8653e-01, time/batch = 15.5720s	
8756/25300 (epoch 17.304), train_loss = 1.12151025, grad/param norm = 1.7451e-01, time/batch = 15.5558s	
8757/25300 (epoch 17.306), train_loss = 0.80759431, grad/param norm = 1.6152e-01, time/batch = 15.5636s	
8758/25300 (epoch 17.308), train_loss = 1.08563038, grad/param norm = 1.7523e-01, time/batch = 15.5255s	
8759/25300 (epoch 17.310), train_loss = 0.96239214, grad/param norm = 1.9489e-01, time/batch = 15.5269s	
8760/25300 (epoch 17.312), train_loss = 1.03987778, grad/param norm = 1.7272e-01, time/batch = 15.6048s	
8761/25300 (epoch 17.314), train_loss = 0.87232132, grad/param norm = 1.6820e-01, time/batch = 15.7290s	
8762/25300 (epoch 17.316), train_loss = 1.07282680, grad/param norm = 1.8695e-01, time/batch = 15.8920s	
8763/25300 (epoch 17.318), train_loss = 0.83251819, grad/param norm = 1.7670e-01, time/batch = 15.6588s	
8764/25300 (epoch 17.320), train_loss = 0.90603867, grad/param norm = 1.7402e-01, time/batch = 15.5334s	
8765/25300 (epoch 17.322), train_loss = 1.25055430, grad/param norm = 2.2271e-01, time/batch = 15.3298s	
8766/25300 (epoch 17.324), train_loss = 0.91625666, grad/param norm = 1.6017e-01, time/batch = 15.3785s	
8767/25300 (epoch 17.326), train_loss = 0.81651722, grad/param norm = 1.5150e-01, time/batch = 15.3114s	
8768/25300 (epoch 17.328), train_loss = 0.83015335, grad/param norm = 1.9235e-01, time/batch = 16.5628s	
8769/25300 (epoch 17.330), train_loss = 1.00202642, grad/param norm = 1.8791e-01, time/batch = 16.5592s	
8770/25300 (epoch 17.332), train_loss = 1.03049796, grad/param norm = 1.7062e-01, time/batch = 15.7051s	
8771/25300 (epoch 17.334), train_loss = 0.85822494, grad/param norm = 1.6816e-01, time/batch = 15.6150s	
8772/25300 (epoch 17.336), train_loss = 0.87557024, grad/param norm = 1.6459e-01, time/batch = 15.6265s	
8773/25300 (epoch 17.338), train_loss = 0.87423138, grad/param norm = 1.7261e-01, time/batch = 15.8673s	
8774/25300 (epoch 17.340), train_loss = 0.96862298, grad/param norm = 1.9960e-01, time/batch = 15.3891s	
8775/25300 (epoch 17.342), train_loss = 0.95916101, grad/param norm = 1.8495e-01, time/batch = 15.8721s	
8776/25300 (epoch 17.344), train_loss = 1.02872934, grad/param norm = 1.7558e-01, time/batch = 17.7217s	
8777/25300 (epoch 17.346), train_loss = 1.00326138, grad/param norm = 2.0824e-01, time/batch = 15.6454s	
8778/25300 (epoch 17.348), train_loss = 0.88729139, grad/param norm = 1.6367e-01, time/batch = 16.9682s	
8779/25300 (epoch 17.350), train_loss = 0.96109339, grad/param norm = 1.7602e-01, time/batch = 16.4519s	
8780/25300 (epoch 17.352), train_loss = 1.01433066, grad/param norm = 1.7013e-01, time/batch = 16.7280s	
8781/25300 (epoch 17.354), train_loss = 0.93479066, grad/param norm = 1.7173e-01, time/batch = 15.7984s	
8782/25300 (epoch 17.356), train_loss = 1.02128704, grad/param norm = 1.9362e-01, time/batch = 16.0495s	
8783/25300 (epoch 17.358), train_loss = 1.12090298, grad/param norm = 2.1970e-01, time/batch = 17.0534s	
8784/25300 (epoch 17.360), train_loss = 0.92572288, grad/param norm = 1.8162e-01, time/batch = 16.2256s	
8785/25300 (epoch 17.362), train_loss = 0.95144902, grad/param norm = 1.8588e-01, time/batch = 15.8038s	
8786/25300 (epoch 17.364), train_loss = 0.98625430, grad/param norm = 1.7921e-01, time/batch = 15.7234s	
8787/25300 (epoch 17.366), train_loss = 0.87115603, grad/param norm = 1.6891e-01, time/batch = 16.9728s	
8788/25300 (epoch 17.368), train_loss = 0.95857559, grad/param norm = 1.6428e-01, time/batch = 15.4557s	
8789/25300 (epoch 17.370), train_loss = 0.96132748, grad/param norm = 2.0158e-01, time/batch = 15.6332s	
8790/25300 (epoch 17.372), train_loss = 0.94360184, grad/param norm = 1.7120e-01, time/batch = 15.7325s	
8791/25300 (epoch 17.374), train_loss = 0.89252605, grad/param norm = 1.7867e-01, time/batch = 16.8046s	
8792/25300 (epoch 17.375), train_loss = 1.16025869, grad/param norm = 2.1958e-01, time/batch = 15.6911s	
8793/25300 (epoch 17.377), train_loss = 1.04956137, grad/param norm = 2.0844e-01, time/batch = 15.5669s	
8794/25300 (epoch 17.379), train_loss = 1.05716690, grad/param norm = 1.9497e-01, time/batch = 15.2371s	
8795/25300 (epoch 17.381), train_loss = 1.02154827, grad/param norm = 1.7837e-01, time/batch = 15.6554s	
8796/25300 (epoch 17.383), train_loss = 0.92068025, grad/param norm = 1.7360e-01, time/batch = 15.4309s	
8797/25300 (epoch 17.385), train_loss = 1.00871744, grad/param norm = 1.8281e-01, time/batch = 15.9109s	
8798/25300 (epoch 17.387), train_loss = 1.03892739, grad/param norm = 1.8421e-01, time/batch = 16.2996s	
8799/25300 (epoch 17.389), train_loss = 1.08863823, grad/param norm = 1.9383e-01, time/batch = 16.2935s	
8800/25300 (epoch 17.391), train_loss = 0.93649615, grad/param norm = 1.6132e-01, time/batch = 16.3732s	
8801/25300 (epoch 17.393), train_loss = 1.05117751, grad/param norm = 2.2880e-01, time/batch = 16.6335s	
8802/25300 (epoch 17.395), train_loss = 0.86791923, grad/param norm = 1.6475e-01, time/batch = 16.8991s	
8803/25300 (epoch 17.397), train_loss = 0.88771624, grad/param norm = 1.9226e-01, time/batch = 16.5577s	
8804/25300 (epoch 17.399), train_loss = 0.88248365, grad/param norm = 1.8230e-01, time/batch = 15.6414s	
8805/25300 (epoch 17.401), train_loss = 1.12379315, grad/param norm = 2.1582e-01, time/batch = 15.9898s	
8806/25300 (epoch 17.403), train_loss = 1.01666600, grad/param norm = 1.9231e-01, time/batch = 16.2323s	
8807/25300 (epoch 17.405), train_loss = 1.01301849, grad/param norm = 1.9371e-01, time/batch = 15.3848s	
8808/25300 (epoch 17.407), train_loss = 0.96481721, grad/param norm = 1.7467e-01, time/batch = 15.9890s	
8809/25300 (epoch 17.409), train_loss = 0.91744661, grad/param norm = 1.6015e-01, time/batch = 15.4849s	
8810/25300 (epoch 17.411), train_loss = 0.92458560, grad/param norm = 1.7692e-01, time/batch = 15.2591s	
8811/25300 (epoch 17.413), train_loss = 0.86135338, grad/param norm = 1.7108e-01, time/batch = 15.7946s	
8812/25300 (epoch 17.415), train_loss = 0.88562310, grad/param norm = 1.9505e-01, time/batch = 15.8326s	
8813/25300 (epoch 17.417), train_loss = 0.83299615, grad/param norm = 1.6137e-01, time/batch = 15.7340s	
8814/25300 (epoch 17.419), train_loss = 0.79532376, grad/param norm = 1.5872e-01, time/batch = 15.4898s	
8815/25300 (epoch 17.421), train_loss = 0.85043228, grad/param norm = 1.5078e-01, time/batch = 15.7044s	
8816/25300 (epoch 17.423), train_loss = 0.87999915, grad/param norm = 1.7038e-01, time/batch = 16.0674s	
8817/25300 (epoch 17.425), train_loss = 0.97740056, grad/param norm = 2.1757e-01, time/batch = 16.3978s	
8818/25300 (epoch 17.427), train_loss = 1.18787345, grad/param norm = 2.1577e-01, time/batch = 15.6323s	
8819/25300 (epoch 17.429), train_loss = 1.10514668, grad/param norm = 2.0730e-01, time/batch = 15.9689s	
8820/25300 (epoch 17.431), train_loss = 1.02480122, grad/param norm = 1.7814e-01, time/batch = 15.9809s	
8821/25300 (epoch 17.433), train_loss = 0.96232531, grad/param norm = 1.6356e-01, time/batch = 15.9751s	
8822/25300 (epoch 17.435), train_loss = 0.92495841, grad/param norm = 1.9821e-01, time/batch = 15.6372s	
8823/25300 (epoch 17.437), train_loss = 0.96318117, grad/param norm = 2.0126e-01, time/batch = 16.1511s	
8824/25300 (epoch 17.439), train_loss = 1.02199368, grad/param norm = 1.7679e-01, time/batch = 15.4847s	
8825/25300 (epoch 17.441), train_loss = 1.05043552, grad/param norm = 1.9455e-01, time/batch = 15.3310s	
8826/25300 (epoch 17.443), train_loss = 1.27543243, grad/param norm = 2.4109e-01, time/batch = 15.7935s	
8827/25300 (epoch 17.445), train_loss = 1.19139935, grad/param norm = 2.0127e-01, time/batch = 15.1573s	
8828/25300 (epoch 17.447), train_loss = 0.90458809, grad/param norm = 1.6468e-01, time/batch = 15.4042s	
8829/25300 (epoch 17.449), train_loss = 0.82127032, grad/param norm = 1.6534e-01, time/batch = 15.2187s	
8830/25300 (epoch 17.451), train_loss = 1.19971963, grad/param norm = 2.0742e-01, time/batch = 15.5450s	
8831/25300 (epoch 17.453), train_loss = 1.08996222, grad/param norm = 2.1374e-01, time/batch = 15.9765s	
8832/25300 (epoch 17.455), train_loss = 1.09239384, grad/param norm = 1.9891e-01, time/batch = 15.3102s	
8833/25300 (epoch 17.457), train_loss = 0.95942810, grad/param norm = 1.7850e-01, time/batch = 15.5639s	
8834/25300 (epoch 17.458), train_loss = 1.01063916, grad/param norm = 1.8919e-01, time/batch = 15.6491s	
8835/25300 (epoch 17.460), train_loss = 1.02362429, grad/param norm = 1.8604e-01, time/batch = 16.3213s	
8836/25300 (epoch 17.462), train_loss = 0.77673498, grad/param norm = 1.7977e-01, time/batch = 15.2195s	
8837/25300 (epoch 17.464), train_loss = 1.09960319, grad/param norm = 2.0410e-01, time/batch = 15.7364s	
8838/25300 (epoch 17.466), train_loss = 1.08897800, grad/param norm = 1.8784e-01, time/batch = 15.6489s	
8839/25300 (epoch 17.468), train_loss = 1.08441079, grad/param norm = 2.0791e-01, time/batch = 15.5568s	
8840/25300 (epoch 17.470), train_loss = 0.94613368, grad/param norm = 1.8683e-01, time/batch = 16.7265s	
8841/25300 (epoch 17.472), train_loss = 0.84834255, grad/param norm = 1.7046e-01, time/batch = 15.9760s	
8842/25300 (epoch 17.474), train_loss = 1.02393247, grad/param norm = 1.7604e-01, time/batch = 15.4758s	
8843/25300 (epoch 17.476), train_loss = 0.97070151, grad/param norm = 1.8759e-01, time/batch = 15.2829s	
8844/25300 (epoch 17.478), train_loss = 1.06816510, grad/param norm = 2.0463e-01, time/batch = 15.6613s	
8845/25300 (epoch 17.480), train_loss = 0.92664231, grad/param norm = 1.7560e-01, time/batch = 15.3163s	
8846/25300 (epoch 17.482), train_loss = 1.08266532, grad/param norm = 2.0952e-01, time/batch = 15.1585s	
8847/25300 (epoch 17.484), train_loss = 1.08609659, grad/param norm = 2.0500e-01, time/batch = 15.2503s	
8848/25300 (epoch 17.486), train_loss = 1.02516603, grad/param norm = 1.9218e-01, time/batch = 15.3129s	
8849/25300 (epoch 17.488), train_loss = 1.15279272, grad/param norm = 1.8858e-01, time/batch = 15.6079s	
8850/25300 (epoch 17.490), train_loss = 1.07455328, grad/param norm = 1.9108e-01, time/batch = 15.3102s	
8851/25300 (epoch 17.492), train_loss = 1.03014327, grad/param norm = 1.8159e-01, time/batch = 15.1614s	
8852/25300 (epoch 17.494), train_loss = 0.94171891, grad/param norm = 1.7510e-01, time/batch = 15.4079s	
8853/25300 (epoch 17.496), train_loss = 1.00755434, grad/param norm = 1.8867e-01, time/batch = 15.8954s	
8854/25300 (epoch 17.498), train_loss = 0.93331278, grad/param norm = 1.7636e-01, time/batch = 16.7328s	
8855/25300 (epoch 17.500), train_loss = 1.13781938, grad/param norm = 2.0690e-01, time/batch = 16.7334s	
8856/25300 (epoch 17.502), train_loss = 1.05501189, grad/param norm = 2.0776e-01, time/batch = 15.6325s	
8857/25300 (epoch 17.504), train_loss = 0.97018154, grad/param norm = 1.8644e-01, time/batch = 15.5657s	
8858/25300 (epoch 17.506), train_loss = 0.94878337, grad/param norm = 1.9451e-01, time/batch = 16.1735s	
8859/25300 (epoch 17.508), train_loss = 1.01584829, grad/param norm = 1.9649e-01, time/batch = 15.9853s	
8860/25300 (epoch 17.510), train_loss = 0.92047100, grad/param norm = 1.7682e-01, time/batch = 15.6372s	
8861/25300 (epoch 17.512), train_loss = 0.77125757, grad/param norm = 1.6519e-01, time/batch = 15.6353s	
8862/25300 (epoch 17.514), train_loss = 0.97396627, grad/param norm = 1.7257e-01, time/batch = 15.7379s	
8863/25300 (epoch 17.516), train_loss = 1.05145751, grad/param norm = 1.9006e-01, time/batch = 15.9902s	
8864/25300 (epoch 17.518), train_loss = 1.11529615, grad/param norm = 2.1969e-01, time/batch = 28.3877s	
8865/25300 (epoch 17.520), train_loss = 0.84488248, grad/param norm = 1.5525e-01, time/batch = 15.4710s	
8866/25300 (epoch 17.522), train_loss = 0.93129970, grad/param norm = 1.8360e-01, time/batch = 15.8929s	
8867/25300 (epoch 17.524), train_loss = 0.97243238, grad/param norm = 1.7442e-01, time/batch = 16.1317s	
8868/25300 (epoch 17.526), train_loss = 1.20754311, grad/param norm = 2.1465e-01, time/batch = 15.5660s	
8869/25300 (epoch 17.528), train_loss = 1.13811822, grad/param norm = 1.9944e-01, time/batch = 15.8163s	
8870/25300 (epoch 17.530), train_loss = 1.01665110, grad/param norm = 1.9546e-01, time/batch = 15.6497s	
8871/25300 (epoch 17.532), train_loss = 0.99867491, grad/param norm = 1.7989e-01, time/batch = 15.7307s	
8872/25300 (epoch 17.534), train_loss = 0.99340917, grad/param norm = 1.8676e-01, time/batch = 15.2176s	
8873/25300 (epoch 17.536), train_loss = 0.81743738, grad/param norm = 1.6889e-01, time/batch = 15.4807s	
8874/25300 (epoch 17.538), train_loss = 0.85456427, grad/param norm = 1.5023e-01, time/batch = 15.6471s	
8875/25300 (epoch 17.540), train_loss = 0.92230830, grad/param norm = 1.7503e-01, time/batch = 15.4910s	
8876/25300 (epoch 17.542), train_loss = 0.87870138, grad/param norm = 1.6235e-01, time/batch = 15.4040s	
8877/25300 (epoch 17.543), train_loss = 0.85300761, grad/param norm = 1.7627e-01, time/batch = 15.5001s	
8878/25300 (epoch 17.545), train_loss = 1.29250711, grad/param norm = 2.5280e-01, time/batch = 15.3893s	
8879/25300 (epoch 17.547), train_loss = 1.04676841, grad/param norm = 1.8112e-01, time/batch = 16.2324s	
8880/25300 (epoch 17.549), train_loss = 1.25586973, grad/param norm = 2.1525e-01, time/batch = 16.0734s	
8881/25300 (epoch 17.551), train_loss = 1.08539905, grad/param norm = 1.9294e-01, time/batch = 17.1450s	
8882/25300 (epoch 17.553), train_loss = 0.94901673, grad/param norm = 1.8802e-01, time/batch = 15.4758s	
8883/25300 (epoch 17.555), train_loss = 1.12755362, grad/param norm = 2.2262e-01, time/batch = 15.4965s	
8884/25300 (epoch 17.557), train_loss = 1.13534533, grad/param norm = 1.9260e-01, time/batch = 15.9821s	
8885/25300 (epoch 17.559), train_loss = 1.11233925, grad/param norm = 1.9610e-01, time/batch = 16.9815s	
8886/25300 (epoch 17.561), train_loss = 1.17210718, grad/param norm = 2.0122e-01, time/batch = 16.2320s	
8887/25300 (epoch 17.563), train_loss = 1.11394043, grad/param norm = 2.1291e-01, time/batch = 17.1276s	
8888/25300 (epoch 17.565), train_loss = 0.85779414, grad/param norm = 1.6501e-01, time/batch = 18.1508s	
8889/25300 (epoch 17.567), train_loss = 0.76063860, grad/param norm = 1.6265e-01, time/batch = 17.1294s	
8890/25300 (epoch 17.569), train_loss = 1.00868593, grad/param norm = 1.9178e-01, time/batch = 17.3279s	
8891/25300 (epoch 17.571), train_loss = 1.11560593, grad/param norm = 2.0801e-01, time/batch = 16.2289s	
8892/25300 (epoch 17.573), train_loss = 0.99780014, grad/param norm = 1.8356e-01, time/batch = 17.0606s	
8893/25300 (epoch 17.575), train_loss = 1.11618488, grad/param norm = 1.9500e-01, time/batch = 16.4008s	
8894/25300 (epoch 17.577), train_loss = 1.03742110, grad/param norm = 1.9918e-01, time/batch = 18.0611s	
8895/25300 (epoch 17.579), train_loss = 1.18528765, grad/param norm = 2.2222e-01, time/batch = 17.3809s	
8896/25300 (epoch 17.581), train_loss = 1.08587065, grad/param norm = 2.0499e-01, time/batch = 16.0457s	
8897/25300 (epoch 17.583), train_loss = 0.86373386, grad/param norm = 1.8713e-01, time/batch = 18.3896s	
8898/25300 (epoch 17.585), train_loss = 0.85221437, grad/param norm = 1.7598e-01, time/batch = 17.2965s	
8899/25300 (epoch 17.587), train_loss = 0.97767295, grad/param norm = 1.8177e-01, time/batch = 17.8658s	
8900/25300 (epoch 17.589), train_loss = 0.87797171, grad/param norm = 1.5997e-01, time/batch = 16.5674s	
8901/25300 (epoch 17.591), train_loss = 0.87865569, grad/param norm = 2.0284e-01, time/batch = 15.6529s	
8902/25300 (epoch 17.593), train_loss = 1.06318049, grad/param norm = 1.8324e-01, time/batch = 18.0646s	
8903/25300 (epoch 17.595), train_loss = 0.98886652, grad/param norm = 1.9383e-01, time/batch = 16.6194s	
8904/25300 (epoch 17.597), train_loss = 0.84105911, grad/param norm = 1.5373e-01, time/batch = 19.1218s	
8905/25300 (epoch 17.599), train_loss = 1.03341875, grad/param norm = 1.8805e-01, time/batch = 16.8650s	
8906/25300 (epoch 17.601), train_loss = 1.03287118, grad/param norm = 2.1375e-01, time/batch = 17.4545s	
8907/25300 (epoch 17.603), train_loss = 1.01895395, grad/param norm = 1.9455e-01, time/batch = 18.2148s	
8908/25300 (epoch 17.605), train_loss = 0.91460024, grad/param norm = 1.8757e-01, time/batch = 18.3752s	
8909/25300 (epoch 17.607), train_loss = 0.75935975, grad/param norm = 1.5450e-01, time/batch = 18.7000s	
8910/25300 (epoch 17.609), train_loss = 0.97780283, grad/param norm = 1.8055e-01, time/batch = 16.3677s	
8911/25300 (epoch 17.611), train_loss = 1.04185708, grad/param norm = 1.8920e-01, time/batch = 18.2971s	
8912/25300 (epoch 17.613), train_loss = 0.85683891, grad/param norm = 1.8835e-01, time/batch = 19.4609s	
8913/25300 (epoch 17.615), train_loss = 0.97132677, grad/param norm = 2.1139e-01, time/batch = 16.4809s	
8914/25300 (epoch 17.617), train_loss = 0.99798894, grad/param norm = 1.9450e-01, time/batch = 20.2865s	
8915/25300 (epoch 17.619), train_loss = 1.09366619, grad/param norm = 2.1376e-01, time/batch = 18.2224s	
8916/25300 (epoch 17.621), train_loss = 1.12938189, grad/param norm = 2.2674e-01, time/batch = 18.0452s	
8917/25300 (epoch 17.623), train_loss = 0.93209663, grad/param norm = 1.8170e-01, time/batch = 17.0535s	
8918/25300 (epoch 17.625), train_loss = 0.82552804, grad/param norm = 1.7500e-01, time/batch = 15.5608s	
8919/25300 (epoch 17.626), train_loss = 0.96731288, grad/param norm = 1.7515e-01, time/batch = 16.2290s	
8920/25300 (epoch 17.628), train_loss = 1.09057942, grad/param norm = 2.0542e-01, time/batch = 15.2868s	
8921/25300 (epoch 17.630), train_loss = 1.07419578, grad/param norm = 2.1912e-01, time/batch = 15.2191s	
8922/25300 (epoch 17.632), train_loss = 1.03896213, grad/param norm = 1.9825e-01, time/batch = 15.1190s	
8923/25300 (epoch 17.634), train_loss = 1.10755839, grad/param norm = 2.1957e-01, time/batch = 15.3004s	
8924/25300 (epoch 17.636), train_loss = 0.95294029, grad/param norm = 1.8997e-01, time/batch = 16.1008s	
8925/25300 (epoch 17.638), train_loss = 1.06003091, grad/param norm = 2.1850e-01, time/batch = 17.3873s	
8926/25300 (epoch 17.640), train_loss = 1.19568890, grad/param norm = 2.1291e-01, time/batch = 16.8856s	
8927/25300 (epoch 17.642), train_loss = 1.06415282, grad/param norm = 2.0203e-01, time/batch = 18.4471s	
8928/25300 (epoch 17.644), train_loss = 1.03884290, grad/param norm = 2.0655e-01, time/batch = 17.6414s	
8929/25300 (epoch 17.646), train_loss = 0.96309928, grad/param norm = 2.1345e-01, time/batch = 16.3117s	
8930/25300 (epoch 17.648), train_loss = 1.09772747, grad/param norm = 1.8749e-01, time/batch = 16.6449s	
8931/25300 (epoch 17.650), train_loss = 1.04960758, grad/param norm = 2.0008e-01, time/batch = 15.8808s	
8932/25300 (epoch 17.652), train_loss = 1.03131997, grad/param norm = 2.1685e-01, time/batch = 17.3098s	
8933/25300 (epoch 17.654), train_loss = 1.16759545, grad/param norm = 2.0285e-01, time/batch = 15.4710s	
8934/25300 (epoch 17.656), train_loss = 1.08864606, grad/param norm = 2.0713e-01, time/batch = 16.1503s	
8935/25300 (epoch 17.658), train_loss = 0.86317648, grad/param norm = 1.6804e-01, time/batch = 15.7384s	
8936/25300 (epoch 17.660), train_loss = 0.90821375, grad/param norm = 1.7882e-01, time/batch = 16.3161s	
8937/25300 (epoch 17.662), train_loss = 0.86138972, grad/param norm = 1.6616e-01, time/batch = 16.4751s	
8938/25300 (epoch 17.664), train_loss = 0.84824070, grad/param norm = 1.7796e-01, time/batch = 15.2239s	
8939/25300 (epoch 17.666), train_loss = 0.87477824, grad/param norm = 1.7086e-01, time/batch = 15.9906s	
8940/25300 (epoch 17.668), train_loss = 0.96697112, grad/param norm = 2.5176e-01, time/batch = 15.5752s	
8941/25300 (epoch 17.670), train_loss = 0.89509102, grad/param norm = 2.1446e-01, time/batch = 16.1280s	
8942/25300 (epoch 17.672), train_loss = 0.89155229, grad/param norm = 1.7822e-01, time/batch = 15.3156s	
8943/25300 (epoch 17.674), train_loss = 0.91164758, grad/param norm = 1.8144e-01, time/batch = 16.7341s	
8944/25300 (epoch 17.676), train_loss = 0.95528866, grad/param norm = 1.8819e-01, time/batch = 15.3692s	
8945/25300 (epoch 17.678), train_loss = 0.94994953, grad/param norm = 2.0073e-01, time/batch = 16.8927s	
8946/25300 (epoch 17.680), train_loss = 0.82629944, grad/param norm = 1.5739e-01, time/batch = 16.4592s	
8947/25300 (epoch 17.682), train_loss = 0.70616488, grad/param norm = 1.6098e-01, time/batch = 17.0530s	
8948/25300 (epoch 17.684), train_loss = 0.85159126, grad/param norm = 1.5387e-01, time/batch = 16.3200s	
8949/25300 (epoch 17.686), train_loss = 0.84205960, grad/param norm = 1.6387e-01, time/batch = 16.6383s	
8950/25300 (epoch 17.688), train_loss = 0.95862229, grad/param norm = 1.8906e-01, time/batch = 16.3032s	
8951/25300 (epoch 17.690), train_loss = 0.86238707, grad/param norm = 1.6179e-01, time/batch = 18.7226s	
8952/25300 (epoch 17.692), train_loss = 0.95337749, grad/param norm = 1.8412e-01, time/batch = 18.6329s	
8953/25300 (epoch 17.694), train_loss = 0.88890109, grad/param norm = 1.6040e-01, time/batch = 16.1931s	
8954/25300 (epoch 17.696), train_loss = 0.99763087, grad/param norm = 1.9670e-01, time/batch = 16.5732s	
8955/25300 (epoch 17.698), train_loss = 1.05992927, grad/param norm = 1.9256e-01, time/batch = 17.3997s	
8956/25300 (epoch 17.700), train_loss = 0.80101053, grad/param norm = 1.7533e-01, time/batch = 15.4791s	
8957/25300 (epoch 17.702), train_loss = 1.08717603, grad/param norm = 1.8167e-01, time/batch = 16.4923s	
8958/25300 (epoch 17.704), train_loss = 0.80639243, grad/param norm = 1.7966e-01, time/batch = 15.5675s	
8959/25300 (epoch 17.706), train_loss = 0.99335358, grad/param norm = 2.0618e-01, time/batch = 16.4693s	
8960/25300 (epoch 17.708), train_loss = 0.81959080, grad/param norm = 1.6040e-01, time/batch = 15.1495s	
8961/25300 (epoch 17.709), train_loss = 1.16796214, grad/param norm = 2.0804e-01, time/batch = 16.2249s	
8962/25300 (epoch 17.711), train_loss = 1.16578297, grad/param norm = 2.0072e-01, time/batch = 16.6325s	
8963/25300 (epoch 17.713), train_loss = 0.95614782, grad/param norm = 1.7111e-01, time/batch = 16.9673s	
8964/25300 (epoch 17.715), train_loss = 0.97458183, grad/param norm = 1.7164e-01, time/batch = 16.0672s	
8965/25300 (epoch 17.717), train_loss = 0.89530318, grad/param norm = 1.9764e-01, time/batch = 17.2261s	
8966/25300 (epoch 17.719), train_loss = 0.94934123, grad/param norm = 1.7741e-01, time/batch = 15.7541s	
8967/25300 (epoch 17.721), train_loss = 1.00812412, grad/param norm = 1.9239e-01, time/batch = 16.6339s	
8968/25300 (epoch 17.723), train_loss = 0.92195894, grad/param norm = 1.8099e-01, time/batch = 17.8095s	
8969/25300 (epoch 17.725), train_loss = 1.01943003, grad/param norm = 1.9580e-01, time/batch = 17.0579s	
8970/25300 (epoch 17.727), train_loss = 1.02093477, grad/param norm = 1.8095e-01, time/batch = 19.3732s	
8971/25300 (epoch 17.729), train_loss = 0.97319103, grad/param norm = 1.7049e-01, time/batch = 16.5642s	
8972/25300 (epoch 17.731), train_loss = 1.15821997, grad/param norm = 1.9842e-01, time/batch = 16.7360s	
8973/25300 (epoch 17.733), train_loss = 0.95092044, grad/param norm = 1.5689e-01, time/batch = 15.5710s	
8974/25300 (epoch 17.735), train_loss = 1.27673190, grad/param norm = 2.0543e-01, time/batch = 16.5514s	
8975/25300 (epoch 17.737), train_loss = 0.84721627, grad/param norm = 1.5516e-01, time/batch = 15.5438s	
8976/25300 (epoch 17.739), train_loss = 1.12714929, grad/param norm = 1.9082e-01, time/batch = 15.5729s	
8977/25300 (epoch 17.741), train_loss = 1.05422932, grad/param norm = 2.0339e-01, time/batch = 17.3126s	
8978/25300 (epoch 17.743), train_loss = 0.95758210, grad/param norm = 1.8127e-01, time/batch = 15.6861s	
8979/25300 (epoch 17.745), train_loss = 0.90752898, grad/param norm = 1.6674e-01, time/batch = 16.9705s	
8980/25300 (epoch 17.747), train_loss = 0.87947979, grad/param norm = 1.7360e-01, time/batch = 19.4675s	
8981/25300 (epoch 17.749), train_loss = 1.02746758, grad/param norm = 1.8593e-01, time/batch = 17.1279s	
8982/25300 (epoch 17.751), train_loss = 1.08693521, grad/param norm = 1.9929e-01, time/batch = 17.3808s	
8983/25300 (epoch 17.753), train_loss = 0.91684008, grad/param norm = 2.0029e-01, time/batch = 17.3040s	
8984/25300 (epoch 17.755), train_loss = 1.11683416, grad/param norm = 2.2297e-01, time/batch = 17.3067s	
8985/25300 (epoch 17.757), train_loss = 0.91169476, grad/param norm = 1.8428e-01, time/batch = 17.4510s	
8986/25300 (epoch 17.759), train_loss = 0.89466691, grad/param norm = 1.7842e-01, time/batch = 18.5501s	
8987/25300 (epoch 17.761), train_loss = 1.13584081, grad/param norm = 1.9180e-01, time/batch = 18.6094s	
8988/25300 (epoch 17.763), train_loss = 0.92355707, grad/param norm = 1.8678e-01, time/batch = 16.2221s	
8989/25300 (epoch 17.765), train_loss = 0.93914583, grad/param norm = 1.9369e-01, time/batch = 18.1334s	
8990/25300 (epoch 17.767), train_loss = 0.92338864, grad/param norm = 1.7406e-01, time/batch = 17.4772s	
8991/25300 (epoch 17.769), train_loss = 1.02131931, grad/param norm = 2.0160e-01, time/batch = 16.5246s	
8992/25300 (epoch 17.771), train_loss = 1.10282609, grad/param norm = 2.0030e-01, time/batch = 17.2989s	
8993/25300 (epoch 17.773), train_loss = 1.10994288, grad/param norm = 2.1295e-01, time/batch = 18.9629s	
8994/25300 (epoch 17.775), train_loss = 0.96150518, grad/param norm = 1.6487e-01, time/batch = 19.2248s	
8995/25300 (epoch 17.777), train_loss = 0.99882099, grad/param norm = 1.9714e-01, time/batch = 16.1198s	
8996/25300 (epoch 17.779), train_loss = 1.07115261, grad/param norm = 1.8387e-01, time/batch = 18.3843s	
8997/25300 (epoch 17.781), train_loss = 1.03357839, grad/param norm = 1.8345e-01, time/batch = 17.0571s	
8998/25300 (epoch 17.783), train_loss = 1.13059534, grad/param norm = 1.8829e-01, time/batch = 16.7316s	
8999/25300 (epoch 17.785), train_loss = 1.09551136, grad/param norm = 1.9487e-01, time/batch = 16.1492s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch17.79_1.5390.t7	
9000/25300 (epoch 17.787), train_loss = 1.08056516, grad/param norm = 1.9858e-01, time/batch = 19.0539s	
9001/25300 (epoch 17.789), train_loss = 1.58360301, grad/param norm = 2.6780e-01, time/batch = 18.4569s	
9002/25300 (epoch 17.791), train_loss = 1.06381417, grad/param norm = 1.8999e-01, time/batch = 16.9610s	
9003/25300 (epoch 17.792), train_loss = 1.12073272, grad/param norm = 1.8753e-01, time/batch = 16.5568s	
9004/25300 (epoch 17.794), train_loss = 1.00483801, grad/param norm = 1.8493e-01, time/batch = 17.1513s	
9005/25300 (epoch 17.796), train_loss = 0.94472244, grad/param norm = 1.7662e-01, time/batch = 18.7126s	
9006/25300 (epoch 17.798), train_loss = 1.12785347, grad/param norm = 2.0203e-01, time/batch = 16.2907s	
9007/25300 (epoch 17.800), train_loss = 0.99444428, grad/param norm = 1.7137e-01, time/batch = 17.8857s	
9008/25300 (epoch 17.802), train_loss = 0.80746147, grad/param norm = 1.7497e-01, time/batch = 17.3874s	
9009/25300 (epoch 17.804), train_loss = 1.01239567, grad/param norm = 1.7572e-01, time/batch = 16.6184s	
9010/25300 (epoch 17.806), train_loss = 1.07227586, grad/param norm = 2.0129e-01, time/batch = 18.7131s	
9011/25300 (epoch 17.808), train_loss = 1.06186470, grad/param norm = 1.9318e-01, time/batch = 17.1420s	
9012/25300 (epoch 17.810), train_loss = 1.01604912, grad/param norm = 2.1000e-01, time/batch = 17.3835s	
9013/25300 (epoch 17.812), train_loss = 1.10330493, grad/param norm = 1.8240e-01, time/batch = 16.7131s	
9014/25300 (epoch 17.814), train_loss = 1.17767607, grad/param norm = 2.0706e-01, time/batch = 17.8896s	
9015/25300 (epoch 17.816), train_loss = 1.26994105, grad/param norm = 2.2123e-01, time/batch = 16.3338s	
9016/25300 (epoch 17.818), train_loss = 1.05014753, grad/param norm = 1.7253e-01, time/batch = 16.0606s	
9017/25300 (epoch 17.820), train_loss = 1.07213820, grad/param norm = 1.9165e-01, time/batch = 16.3826s	
9018/25300 (epoch 17.822), train_loss = 0.98374234, grad/param norm = 1.7174e-01, time/batch = 16.5630s	
9019/25300 (epoch 17.824), train_loss = 1.09735284, grad/param norm = 1.8986e-01, time/batch = 17.6438s	
9020/25300 (epoch 17.826), train_loss = 0.96606168, grad/param norm = 1.9015e-01, time/batch = 15.6195s	
9021/25300 (epoch 17.828), train_loss = 0.93837795, grad/param norm = 1.8331e-01, time/batch = 19.3892s	
9022/25300 (epoch 17.830), train_loss = 1.02333174, grad/param norm = 1.7635e-01, time/batch = 18.7251s	
9023/25300 (epoch 17.832), train_loss = 1.07958180, grad/param norm = 1.9370e-01, time/batch = 16.3794s	
9024/25300 (epoch 17.834), train_loss = 0.88201190, grad/param norm = 1.6597e-01, time/batch = 17.2204s	
9025/25300 (epoch 17.836), train_loss = 0.95736008, grad/param norm = 1.7549e-01, time/batch = 16.5664s	
9026/25300 (epoch 17.838), train_loss = 0.97349489, grad/param norm = 1.7041e-01, time/batch = 17.2107s	
9027/25300 (epoch 17.840), train_loss = 1.13494550, grad/param norm = 1.8926e-01, time/batch = 17.4719s	
9028/25300 (epoch 17.842), train_loss = 1.02021938, grad/param norm = 2.1268e-01, time/batch = 18.5464s	
9029/25300 (epoch 17.844), train_loss = 1.06194833, grad/param norm = 1.7463e-01, time/batch = 18.8110s	
9030/25300 (epoch 17.846), train_loss = 1.06285801, grad/param norm = 1.8174e-01, time/batch = 16.7132s	
9031/25300 (epoch 17.848), train_loss = 1.12323664, grad/param norm = 2.0908e-01, time/batch = 17.2196s	
9032/25300 (epoch 17.850), train_loss = 1.06848261, grad/param norm = 1.8659e-01, time/batch = 17.1279s	
9033/25300 (epoch 17.852), train_loss = 1.08828164, grad/param norm = 1.9487e-01, time/batch = 18.6079s	
9034/25300 (epoch 17.854), train_loss = 1.17308219, grad/param norm = 2.0072e-01, time/batch = 19.1219s	
9035/25300 (epoch 17.856), train_loss = 0.99680062, grad/param norm = 1.9384e-01, time/batch = 16.6319s	
9036/25300 (epoch 17.858), train_loss = 1.05325420, grad/param norm = 1.9950e-01, time/batch = 19.1204s	
9037/25300 (epoch 17.860), train_loss = 0.86486110, grad/param norm = 1.8073e-01, time/batch = 16.7011s	
9038/25300 (epoch 17.862), train_loss = 1.02528484, grad/param norm = 2.0688e-01, time/batch = 18.7966s	
9039/25300 (epoch 17.864), train_loss = 1.12206790, grad/param norm = 1.8564e-01, time/batch = 16.7944s	
9040/25300 (epoch 17.866), train_loss = 1.02094794, grad/param norm = 2.0810e-01, time/batch = 17.3612s	
9041/25300 (epoch 17.868), train_loss = 1.13946150, grad/param norm = 2.0311e-01, time/batch = 16.4642s	
9042/25300 (epoch 17.870), train_loss = 1.10693706, grad/param norm = 1.8328e-01, time/batch = 18.1269s	
9043/25300 (epoch 17.872), train_loss = 1.10720413, grad/param norm = 2.1409e-01, time/batch = 18.7974s	
9044/25300 (epoch 17.874), train_loss = 1.09767544, grad/param norm = 1.9354e-01, time/batch = 16.9809s	
9045/25300 (epoch 17.875), train_loss = 1.00858678, grad/param norm = 1.8443e-01, time/batch = 19.9523s	
9046/25300 (epoch 17.877), train_loss = 0.97860959, grad/param norm = 1.7582e-01, time/batch = 18.1867s	
9047/25300 (epoch 17.879), train_loss = 1.00992128, grad/param norm = 2.0210e-01, time/batch = 17.0347s	
9048/25300 (epoch 17.881), train_loss = 1.33590293, grad/param norm = 2.5718e-01, time/batch = 20.7783s	
9049/25300 (epoch 17.883), train_loss = 1.28162931, grad/param norm = 1.9588e-01, time/batch = 18.8731s	
9050/25300 (epoch 17.885), train_loss = 1.13028016, grad/param norm = 2.2053e-01, time/batch = 16.1371s	
9051/25300 (epoch 17.887), train_loss = 1.09844743, grad/param norm = 2.1945e-01, time/batch = 18.1322s	
9052/25300 (epoch 17.889), train_loss = 1.21553626, grad/param norm = 2.1742e-01, time/batch = 17.2906s	
9053/25300 (epoch 17.891), train_loss = 1.08248546, grad/param norm = 2.2765e-01, time/batch = 18.7088s	
9054/25300 (epoch 17.893), train_loss = 1.13180114, grad/param norm = 2.0585e-01, time/batch = 17.3089s	
9055/25300 (epoch 17.895), train_loss = 0.80188834, grad/param norm = 1.6878e-01, time/batch = 16.4800s	
9056/25300 (epoch 17.897), train_loss = 0.96033962, grad/param norm = 2.0009e-01, time/batch = 16.8891s	
9057/25300 (epoch 17.899), train_loss = 1.04056962, grad/param norm = 1.8435e-01, time/batch = 15.4697s	
9058/25300 (epoch 17.901), train_loss = 1.07885064, grad/param norm = 1.7973e-01, time/batch = 15.3850s	
9059/25300 (epoch 17.903), train_loss = 0.83041912, grad/param norm = 1.8564e-01, time/batch = 18.8836s	
9060/25300 (epoch 17.905), train_loss = 0.96562876, grad/param norm = 2.0102e-01, time/batch = 17.4593s	
9061/25300 (epoch 17.907), train_loss = 0.99833900, grad/param norm = 2.9994e-01, time/batch = 16.3271s	
9062/25300 (epoch 17.909), train_loss = 1.09665346, grad/param norm = 2.0001e-01, time/batch = 18.3937s	
9063/25300 (epoch 17.911), train_loss = 1.20646239, grad/param norm = 2.1979e-01, time/batch = 18.4560s	
9064/25300 (epoch 17.913), train_loss = 1.25537861, grad/param norm = 2.1541e-01, time/batch = 15.6485s	
9065/25300 (epoch 17.915), train_loss = 0.99101787, grad/param norm = 2.1765e-01, time/batch = 15.7356s	
9066/25300 (epoch 17.917), train_loss = 1.11966726, grad/param norm = 2.1454e-01, time/batch = 19.7885s	
9067/25300 (epoch 17.919), train_loss = 1.17652396, grad/param norm = 2.0034e-01, time/batch = 22.7358s	
9068/25300 (epoch 17.921), train_loss = 0.94566585, grad/param norm = 2.1901e-01, time/batch = 24.1424s	
9069/25300 (epoch 17.923), train_loss = 1.18860431, grad/param norm = 1.9319e-01, time/batch = 16.3846s	
9070/25300 (epoch 17.925), train_loss = 1.02485034, grad/param norm = 1.9963e-01, time/batch = 15.5172s	
9071/25300 (epoch 17.927), train_loss = 0.98287172, grad/param norm = 1.8197e-01, time/batch = 15.5922s	
9072/25300 (epoch 17.929), train_loss = 1.01707388, grad/param norm = 1.8111e-01, time/batch = 15.6030s	
9073/25300 (epoch 17.931), train_loss = 1.12064056, grad/param norm = 2.1759e-01, time/batch = 15.6049s	
9074/25300 (epoch 17.933), train_loss = 1.10440149, grad/param norm = 2.0140e-01, time/batch = 15.2940s	
9075/25300 (epoch 17.935), train_loss = 1.08218697, grad/param norm = 1.9979e-01, time/batch = 15.4650s	
9076/25300 (epoch 17.937), train_loss = 0.78619335, grad/param norm = 1.5951e-01, time/batch = 15.8910s	
9077/25300 (epoch 17.939), train_loss = 1.11903961, grad/param norm = 2.1453e-01, time/batch = 15.9771s	
9078/25300 (epoch 17.941), train_loss = 0.97583950, grad/param norm = 1.9085e-01, time/batch = 17.2991s	
9079/25300 (epoch 17.943), train_loss = 1.06535988, grad/param norm = 1.7969e-01, time/batch = 17.0456s	
9080/25300 (epoch 17.945), train_loss = 1.09742591, grad/param norm = 1.9484e-01, time/batch = 18.0489s	
9081/25300 (epoch 17.947), train_loss = 0.93740486, grad/param norm = 1.8125e-01, time/batch = 16.3717s	
9082/25300 (epoch 17.949), train_loss = 1.10041775, grad/param norm = 1.8138e-01, time/batch = 18.2076s	
9083/25300 (epoch 17.951), train_loss = 1.02205094, grad/param norm = 1.8021e-01, time/batch = 16.2277s	
9084/25300 (epoch 17.953), train_loss = 1.07074769, grad/param norm = 1.8959e-01, time/batch = 18.3729s	
9085/25300 (epoch 17.955), train_loss = 1.27377411, grad/param norm = 2.3239e-01, time/batch = 17.3758s	
9086/25300 (epoch 17.957), train_loss = 1.21441681, grad/param norm = 2.2866e-01, time/batch = 17.9655s	
9087/25300 (epoch 17.958), train_loss = 1.12124750, grad/param norm = 2.0546e-01, time/batch = 17.6534s	
9088/25300 (epoch 17.960), train_loss = 1.24942011, grad/param norm = 2.0771e-01, time/batch = 16.5523s	
9089/25300 (epoch 17.962), train_loss = 1.19669093, grad/param norm = 2.1922e-01, time/batch = 16.7337s	
9090/25300 (epoch 17.964), train_loss = 1.12005560, grad/param norm = 2.1644e-01, time/batch = 17.7227s	
9091/25300 (epoch 17.966), train_loss = 0.87636386, grad/param norm = 1.7896e-01, time/batch = 17.1296s	
9092/25300 (epoch 17.968), train_loss = 0.88770793, grad/param norm = 1.7128e-01, time/batch = 17.9581s	
9093/25300 (epoch 17.970), train_loss = 1.01264054, grad/param norm = 2.1627e-01, time/batch = 15.7046s	
9094/25300 (epoch 17.972), train_loss = 1.03198918, grad/param norm = 1.9051e-01, time/batch = 17.2176s	
9095/25300 (epoch 17.974), train_loss = 1.22851808, grad/param norm = 2.1007e-01, time/batch = 16.2081s	
9096/25300 (epoch 17.976), train_loss = 1.09097857, grad/param norm = 1.8860e-01, time/batch = 15.5404s	
9097/25300 (epoch 17.978), train_loss = 1.04913977, grad/param norm = 2.3832e-01, time/batch = 17.1137s	
9098/25300 (epoch 17.980), train_loss = 1.09819389, grad/param norm = 2.1911e-01, time/batch = 16.8774s	
9099/25300 (epoch 17.982), train_loss = 1.01209504, grad/param norm = 2.0045e-01, time/batch = 16.1307s	
9100/25300 (epoch 17.984), train_loss = 1.02745433, grad/param norm = 2.0782e-01, time/batch = 17.2337s	
9101/25300 (epoch 17.986), train_loss = 1.13132055, grad/param norm = 2.0909e-01, time/batch = 18.6420s	
9102/25300 (epoch 17.988), train_loss = 1.09987436, grad/param norm = 1.9738e-01, time/batch = 16.6764s	
9103/25300 (epoch 17.990), train_loss = 1.03294373, grad/param norm = 1.8565e-01, time/batch = 15.5848s	
9104/25300 (epoch 17.992), train_loss = 0.86442299, grad/param norm = 1.6525e-01, time/batch = 15.7507s	
9105/25300 (epoch 17.994), train_loss = 1.04403307, grad/param norm = 1.8478e-01, time/batch = 15.3684s	
9106/25300 (epoch 17.996), train_loss = 1.18859054, grad/param norm = 2.1649e-01, time/batch = 16.2081s	
9107/25300 (epoch 17.998), train_loss = 1.15907490, grad/param norm = 2.1914e-01, time/batch = 15.9239s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
9108/25300 (epoch 18.000), train_loss = 1.06384533, grad/param norm = 2.0218e-01, time/batch = 17.2733s	
9109/25300 (epoch 18.002), train_loss = 0.90611373, grad/param norm = 1.5931e-01, time/batch = 17.5368s	
9110/25300 (epoch 18.004), train_loss = 0.88081230, grad/param norm = 1.7215e-01, time/batch = 16.8058s	
9111/25300 (epoch 18.006), train_loss = 1.17343600, grad/param norm = 1.8660e-01, time/batch = 16.0577s	
9112/25300 (epoch 18.008), train_loss = 1.00875384, grad/param norm = 1.7521e-01, time/batch = 19.1230s	
9113/25300 (epoch 18.010), train_loss = 1.04196679, grad/param norm = 1.7451e-01, time/batch = 16.0531s	
9114/25300 (epoch 18.012), train_loss = 0.94839684, grad/param norm = 1.8539e-01, time/batch = 18.3673s	
9115/25300 (epoch 18.014), train_loss = 1.16502360, grad/param norm = 1.8993e-01, time/batch = 18.8084s	
9116/25300 (epoch 18.016), train_loss = 1.06241610, grad/param norm = 2.0798e-01, time/batch = 16.0522s	
9117/25300 (epoch 18.018), train_loss = 0.93598455, grad/param norm = 1.7962e-01, time/batch = 15.8183s	
9118/25300 (epoch 18.020), train_loss = 0.99710135, grad/param norm = 1.7753e-01, time/batch = 17.3807s	
9119/25300 (epoch 18.022), train_loss = 1.07642308, grad/param norm = 2.0481e-01, time/batch = 17.9085s	
9120/25300 (epoch 18.024), train_loss = 0.77697378, grad/param norm = 1.3956e-01, time/batch = 16.6281s	
9121/25300 (epoch 18.026), train_loss = 0.98286837, grad/param norm = 1.9758e-01, time/batch = 17.0570s	
9122/25300 (epoch 18.028), train_loss = 0.91819378, grad/param norm = 1.8587e-01, time/batch = 18.5395s	
9123/25300 (epoch 18.030), train_loss = 1.15213269, grad/param norm = 1.9952e-01, time/batch = 16.8778s	
9124/25300 (epoch 18.032), train_loss = 0.96695839, grad/param norm = 1.8151e-01, time/batch = 17.8035s	
9125/25300 (epoch 18.034), train_loss = 0.85230783, grad/param norm = 1.7403e-01, time/batch = 16.9004s	
9126/25300 (epoch 18.036), train_loss = 0.84777124, grad/param norm = 1.6113e-01, time/batch = 18.6410s	
9127/25300 (epoch 18.038), train_loss = 0.75007390, grad/param norm = 1.3900e-01, time/batch = 16.7941s	
9128/25300 (epoch 18.040), train_loss = 1.04675348, grad/param norm = 1.8940e-01, time/batch = 18.2189s	
9129/25300 (epoch 18.042), train_loss = 0.97640370, grad/param norm = 1.7508e-01, time/batch = 15.4577s	
9130/25300 (epoch 18.043), train_loss = 0.83466791, grad/param norm = 1.5333e-01, time/batch = 15.6442s	
9131/25300 (epoch 18.045), train_loss = 0.87329944, grad/param norm = 1.7734e-01, time/batch = 15.7416s	
9132/25300 (epoch 18.047), train_loss = 1.07178504, grad/param norm = 1.8927e-01, time/batch = 16.9812s	
9133/25300 (epoch 18.049), train_loss = 1.03771371, grad/param norm = 2.0538e-01, time/batch = 17.0789s	
9134/25300 (epoch 18.051), train_loss = 1.11704484, grad/param norm = 2.0370e-01, time/batch = 15.3782s	
9135/25300 (epoch 18.053), train_loss = 0.83190633, grad/param norm = 1.6082e-01, time/batch = 17.3093s	
9136/25300 (epoch 18.055), train_loss = 0.88312287, grad/param norm = 1.7050e-01, time/batch = 17.0633s	
9137/25300 (epoch 18.057), train_loss = 0.84466072, grad/param norm = 1.5917e-01, time/batch = 18.2894s	
9138/25300 (epoch 18.059), train_loss = 0.95059275, grad/param norm = 1.8245e-01, time/batch = 17.2262s	
9139/25300 (epoch 18.061), train_loss = 0.93136893, grad/param norm = 1.8415e-01, time/batch = 15.5586s	
9140/25300 (epoch 18.063), train_loss = 0.89699894, grad/param norm = 1.8381e-01, time/batch = 19.4571s	
9141/25300 (epoch 18.065), train_loss = 1.07002179, grad/param norm = 1.9979e-01, time/batch = 16.9612s	
9142/25300 (epoch 18.067), train_loss = 1.11075398, grad/param norm = 1.7782e-01, time/batch = 18.0456s	
9143/25300 (epoch 18.069), train_loss = 0.96614239, grad/param norm = 1.8851e-01, time/batch = 17.0643s	
9144/25300 (epoch 18.071), train_loss = 1.12749402, grad/param norm = 1.8396e-01, time/batch = 18.4547s	
9145/25300 (epoch 18.073), train_loss = 0.94237327, grad/param norm = 1.5829e-01, time/batch = 16.6661s	
9146/25300 (epoch 18.075), train_loss = 1.07443221, grad/param norm = 1.9666e-01, time/batch = 15.8604s	
9147/25300 (epoch 18.077), train_loss = 1.02951058, grad/param norm = 1.8606e-01, time/batch = 17.8937s	
9148/25300 (epoch 18.079), train_loss = 0.98557519, grad/param norm = 1.8332e-01, time/batch = 17.2925s	
9149/25300 (epoch 18.081), train_loss = 0.97370658, grad/param norm = 1.7237e-01, time/batch = 17.7229s	
9150/25300 (epoch 18.083), train_loss = 0.98987424, grad/param norm = 1.7928e-01, time/batch = 19.7259s	
9151/25300 (epoch 18.085), train_loss = 1.23238048, grad/param norm = 2.1196e-01, time/batch = 16.9751s	
9152/25300 (epoch 18.087), train_loss = 1.08320254, grad/param norm = 1.8329e-01, time/batch = 18.0578s	
9153/25300 (epoch 18.089), train_loss = 1.06843744, grad/param norm = 1.9965e-01, time/batch = 15.3962s	
9154/25300 (epoch 18.091), train_loss = 1.20036779, grad/param norm = 2.0191e-01, time/batch = 19.2919s	
9155/25300 (epoch 18.093), train_loss = 1.13818593, grad/param norm = 1.9564e-01, time/batch = 16.1549s	
9156/25300 (epoch 18.095), train_loss = 1.09896160, grad/param norm = 1.8617e-01, time/batch = 17.4805s	
9157/25300 (epoch 18.097), train_loss = 1.04423999, grad/param norm = 1.7888e-01, time/batch = 19.4478s	
9158/25300 (epoch 18.099), train_loss = 1.08079530, grad/param norm = 1.8778e-01, time/batch = 16.4835s	
9159/25300 (epoch 18.101), train_loss = 0.99564281, grad/param norm = 1.8555e-01, time/batch = 16.9751s	
9160/25300 (epoch 18.103), train_loss = 1.03298615, grad/param norm = 1.8116e-01, time/batch = 16.5560s	
9161/25300 (epoch 18.105), train_loss = 1.07520953, grad/param norm = 1.7996e-01, time/batch = 18.6329s	
9162/25300 (epoch 18.107), train_loss = 1.10389303, grad/param norm = 2.1119e-01, time/batch = 16.7247s	
9163/25300 (epoch 18.109), train_loss = 0.99869793, grad/param norm = 1.9429e-01, time/batch = 18.1188s	
9164/25300 (epoch 18.111), train_loss = 1.01195275, grad/param norm = 1.8074e-01, time/batch = 16.2093s	
9165/25300 (epoch 18.113), train_loss = 0.97278425, grad/param norm = 1.9005e-01, time/batch = 17.7115s	
9166/25300 (epoch 18.115), train_loss = 0.99082777, grad/param norm = 1.8644e-01, time/batch = 16.3282s	
9167/25300 (epoch 18.117), train_loss = 1.07084445, grad/param norm = 1.6817e-01, time/batch = 17.4710s	
9168/25300 (epoch 18.119), train_loss = 0.98181115, grad/param norm = 1.8283e-01, time/batch = 16.8912s	
9169/25300 (epoch 18.121), train_loss = 1.06168701, grad/param norm = 2.2632e-01, time/batch = 18.2876s	
9170/25300 (epoch 18.123), train_loss = 0.99039876, grad/param norm = 1.8798e-01, time/batch = 20.6988s	
9171/25300 (epoch 18.125), train_loss = 1.12221512, grad/param norm = 2.0731e-01, time/batch = 18.2009s	
9172/25300 (epoch 18.126), train_loss = 1.01501009, grad/param norm = 2.0153e-01, time/batch = 19.3504s	
9173/25300 (epoch 18.128), train_loss = 1.01019136, grad/param norm = 1.8923e-01, time/batch = 16.4106s	
9174/25300 (epoch 18.130), train_loss = 0.83600869, grad/param norm = 1.5944e-01, time/batch = 17.4978s	
9175/25300 (epoch 18.132), train_loss = 0.86463346, grad/param norm = 1.7883e-01, time/batch = 16.0502s	
9176/25300 (epoch 18.134), train_loss = 0.82306032, grad/param norm = 1.6347e-01, time/batch = 17.3993s	
9177/25300 (epoch 18.136), train_loss = 1.01192282, grad/param norm = 1.8183e-01, time/batch = 17.9919s	
9178/25300 (epoch 18.138), train_loss = 0.88122429, grad/param norm = 1.6721e-01, time/batch = 16.8020s	
9179/25300 (epoch 18.140), train_loss = 0.94439288, grad/param norm = 1.7179e-01, time/batch = 17.3945s	
9180/25300 (epoch 18.142), train_loss = 1.11222493, grad/param norm = 1.8051e-01, time/batch = 16.8924s	
9181/25300 (epoch 18.144), train_loss = 1.07497039, grad/param norm = 1.8190e-01, time/batch = 16.7983s	
9182/25300 (epoch 18.146), train_loss = 1.08026780, grad/param norm = 2.2448e-01, time/batch = 16.4678s	
9183/25300 (epoch 18.148), train_loss = 0.99682396, grad/param norm = 1.8377e-01, time/batch = 17.3886s	
9184/25300 (epoch 18.150), train_loss = 1.12934070, grad/param norm = 2.1194e-01, time/batch = 16.6537s	
9185/25300 (epoch 18.152), train_loss = 1.19215665, grad/param norm = 2.2081e-01, time/batch = 16.8886s	
9186/25300 (epoch 18.154), train_loss = 0.86827051, grad/param norm = 1.7015e-01, time/batch = 16.8954s	
9187/25300 (epoch 18.156), train_loss = 1.08134659, grad/param norm = 1.9607e-01, time/batch = 16.6436s	
9188/25300 (epoch 18.158), train_loss = 0.91801672, grad/param norm = 1.7847e-01, time/batch = 16.9634s	
9189/25300 (epoch 18.160), train_loss = 1.00780369, grad/param norm = 1.8692e-01, time/batch = 15.3752s	
9190/25300 (epoch 18.162), train_loss = 0.95371776, grad/param norm = 1.8496e-01, time/batch = 15.8127s	
9191/25300 (epoch 18.164), train_loss = 1.07768486, grad/param norm = 1.8964e-01, time/batch = 18.4736s	
9192/25300 (epoch 18.166), train_loss = 1.02250476, grad/param norm = 1.8083e-01, time/batch = 16.3977s	
9193/25300 (epoch 18.168), train_loss = 0.89174325, grad/param norm = 1.5769e-01, time/batch = 17.3157s	
9194/25300 (epoch 18.170), train_loss = 0.98012172, grad/param norm = 1.7503e-01, time/batch = 15.9728s	
9195/25300 (epoch 18.172), train_loss = 0.90161391, grad/param norm = 1.7244e-01, time/batch = 17.4769s	
9196/25300 (epoch 18.174), train_loss = 0.89617353, grad/param norm = 1.7045e-01, time/batch = 16.7039s	
9197/25300 (epoch 18.176), train_loss = 0.93831761, grad/param norm = 1.9067e-01, time/batch = 18.7336s	
9198/25300 (epoch 18.178), train_loss = 1.12568426, grad/param norm = 1.8872e-01, time/batch = 15.4814s	
9199/25300 (epoch 18.180), train_loss = 0.82384711, grad/param norm = 1.6334e-01, time/batch = 16.7161s	
9200/25300 (epoch 18.182), train_loss = 0.95262193, grad/param norm = 1.9167e-01, time/batch = 16.2312s	
9201/25300 (epoch 18.184), train_loss = 0.96095749, grad/param norm = 1.8750e-01, time/batch = 17.4771s	
9202/25300 (epoch 18.186), train_loss = 0.92816647, grad/param norm = 1.8008e-01, time/batch = 18.2188s	
9203/25300 (epoch 18.188), train_loss = 1.01484763, grad/param norm = 1.9637e-01, time/batch = 15.4458s	
9204/25300 (epoch 18.190), train_loss = 0.96918839, grad/param norm = 1.8738e-01, time/batch = 17.9589s	
9205/25300 (epoch 18.192), train_loss = 0.98685044, grad/param norm = 1.9472e-01, time/batch = 19.3633s	
9206/25300 (epoch 18.194), train_loss = 0.99230258, grad/param norm = 1.9240e-01, time/batch = 17.6305s	
9207/25300 (epoch 18.196), train_loss = 1.06896215, grad/param norm = 2.3970e-01, time/batch = 16.4724s	
9208/25300 (epoch 18.198), train_loss = 0.93797265, grad/param norm = 1.8902e-01, time/batch = 15.5687s	
9209/25300 (epoch 18.200), train_loss = 0.98700130, grad/param norm = 2.0368e-01, time/batch = 18.8022s	
9210/25300 (epoch 18.202), train_loss = 0.98268830, grad/param norm = 1.7990e-01, time/batch = 15.3838s	
9211/25300 (epoch 18.204), train_loss = 0.95571734, grad/param norm = 1.8460e-01, time/batch = 18.6387s	
9212/25300 (epoch 18.206), train_loss = 1.08309085, grad/param norm = 2.0716e-01, time/batch = 16.9525s	
9213/25300 (epoch 18.208), train_loss = 0.88935495, grad/param norm = 1.8821e-01, time/batch = 18.2965s	
9214/25300 (epoch 18.209), train_loss = 0.83622962, grad/param norm = 1.6914e-01, time/batch = 16.4774s	
9215/25300 (epoch 18.211), train_loss = 0.95881217, grad/param norm = 1.8838e-01, time/batch = 18.0556s	
9216/25300 (epoch 18.213), train_loss = 1.04184979, grad/param norm = 1.9524e-01, time/batch = 19.4679s	
9217/25300 (epoch 18.215), train_loss = 1.02275378, grad/param norm = 1.8653e-01, time/batch = 16.2962s	
9218/25300 (epoch 18.217), train_loss = 1.04781442, grad/param norm = 2.2225e-01, time/batch = 15.8089s	
9219/25300 (epoch 18.219), train_loss = 1.12069410, grad/param norm = 2.0004e-01, time/batch = 17.4833s	
9220/25300 (epoch 18.221), train_loss = 1.13854450, grad/param norm = 2.0107e-01, time/batch = 15.3188s	
9221/25300 (epoch 18.223), train_loss = 1.05743937, grad/param norm = 2.2069e-01, time/batch = 18.4671s	
9222/25300 (epoch 18.225), train_loss = 1.45458147, grad/param norm = 2.8464e-01, time/batch = 18.1305s	
9223/25300 (epoch 18.227), train_loss = 1.14007185, grad/param norm = 2.1110e-01, time/batch = 18.8852s	
9224/25300 (epoch 18.229), train_loss = 1.00982841, grad/param norm = 1.8408e-01, time/batch = 17.5357s	
9225/25300 (epoch 18.231), train_loss = 0.98489383, grad/param norm = 1.9766e-01, time/batch = 17.2098s	
9226/25300 (epoch 18.233), train_loss = 1.08676842, grad/param norm = 1.9739e-01, time/batch = 16.3134s	
9227/25300 (epoch 18.235), train_loss = 1.00716517, grad/param norm = 1.8208e-01, time/batch = 15.7797s	
9228/25300 (epoch 18.237), train_loss = 1.19232844, grad/param norm = 2.0077e-01, time/batch = 15.5548s	
9229/25300 (epoch 18.239), train_loss = 1.03334144, grad/param norm = 2.0285e-01, time/batch = 15.6854s	
9230/25300 (epoch 18.241), train_loss = 1.15402129, grad/param norm = 1.9425e-01, time/batch = 15.6924s	
9231/25300 (epoch 18.243), train_loss = 1.33623617, grad/param norm = 2.1499e-01, time/batch = 15.6220s	
9232/25300 (epoch 18.245), train_loss = 0.95342642, grad/param norm = 1.8147e-01, time/batch = 17.1384s	
9233/25300 (epoch 18.247), train_loss = 1.11033038, grad/param norm = 1.9464e-01, time/batch = 16.2212s	
9234/25300 (epoch 18.249), train_loss = 0.88626740, grad/param norm = 1.6528e-01, time/batch = 17.6201s	
9235/25300 (epoch 18.251), train_loss = 0.85640265, grad/param norm = 1.7152e-01, time/batch = 15.8907s	
9236/25300 (epoch 18.253), train_loss = 0.98433045, grad/param norm = 1.8711e-01, time/batch = 16.5568s	
9237/25300 (epoch 18.255), train_loss = 0.97659254, grad/param norm = 2.2039e-01, time/batch = 17.1590s	
9238/25300 (epoch 18.257), train_loss = 1.03949938, grad/param norm = 2.1101e-01, time/batch = 15.5493s	
9239/25300 (epoch 18.259), train_loss = 1.24666813, grad/param norm = 2.4066e-01, time/batch = 17.2252s	
9240/25300 (epoch 18.261), train_loss = 1.19364146, grad/param norm = 2.2070e-01, time/batch = 18.4759s	
9241/25300 (epoch 18.263), train_loss = 1.17089040, grad/param norm = 1.9962e-01, time/batch = 17.4716s	
9242/25300 (epoch 18.265), train_loss = 1.21407061, grad/param norm = 2.0200e-01, time/batch = 15.8169s	
9243/25300 (epoch 18.267), train_loss = 1.12149766, grad/param norm = 1.9708e-01, time/batch = 16.3141s	
9244/25300 (epoch 18.269), train_loss = 0.85891216, grad/param norm = 1.5896e-01, time/batch = 17.7190s	
9245/25300 (epoch 18.271), train_loss = 0.99806191, grad/param norm = 1.8138e-01, time/batch = 16.2887s	
9246/25300 (epoch 18.273), train_loss = 1.08079140, grad/param norm = 2.0441e-01, time/batch = 15.6495s	
9247/25300 (epoch 18.275), train_loss = 0.96627795, grad/param norm = 1.6073e-01, time/batch = 16.6317s	
9248/25300 (epoch 18.277), train_loss = 0.99868695, grad/param norm = 1.8599e-01, time/batch = 16.7156s	
9249/25300 (epoch 18.279), train_loss = 1.00222455, grad/param norm = 1.7908e-01, time/batch = 16.3697s	
9250/25300 (epoch 18.281), train_loss = 1.18325020, grad/param norm = 2.0734e-01, time/batch = 17.5632s	
9251/25300 (epoch 18.283), train_loss = 0.90075407, grad/param norm = 1.5952e-01, time/batch = 16.3947s	
9252/25300 (epoch 18.285), train_loss = 1.05942225, grad/param norm = 2.0049e-01, time/batch = 16.6381s	
9253/25300 (epoch 18.287), train_loss = 1.06132510, grad/param norm = 1.7987e-01, time/batch = 16.3703s	
9254/25300 (epoch 18.289), train_loss = 0.98090483, grad/param norm = 1.7949e-01, time/batch = 17.5548s	
9255/25300 (epoch 18.291), train_loss = 0.98868114, grad/param norm = 1.7777e-01, time/batch = 18.4561s	
9256/25300 (epoch 18.292), train_loss = 1.17256512, grad/param norm = 1.8444e-01, time/batch = 16.9719s	
9257/25300 (epoch 18.294), train_loss = 1.04845085, grad/param norm = 1.9446e-01, time/batch = 16.5696s	
9258/25300 (epoch 18.296), train_loss = 0.92281318, grad/param norm = 1.8808e-01, time/batch = 16.4703s	
9259/25300 (epoch 18.298), train_loss = 1.09962889, grad/param norm = 1.9178e-01, time/batch = 17.2068s	
9260/25300 (epoch 18.300), train_loss = 1.13819579, grad/param norm = 2.0893e-01, time/batch = 16.1328s	
9261/25300 (epoch 18.302), train_loss = 0.84869363, grad/param norm = 1.9395e-01, time/batch = 16.9032s	
9262/25300 (epoch 18.304), train_loss = 1.10721586, grad/param norm = 1.8471e-01, time/batch = 15.6617s	
9263/25300 (epoch 18.306), train_loss = 0.80142884, grad/param norm = 1.6615e-01, time/batch = 16.2262s	
9264/25300 (epoch 18.308), train_loss = 1.06225261, grad/param norm = 1.7541e-01, time/batch = 16.3925s	
9265/25300 (epoch 18.310), train_loss = 0.93196701, grad/param norm = 1.9448e-01, time/batch = 17.2272s	
9266/25300 (epoch 18.312), train_loss = 1.02684107, grad/param norm = 1.7674e-01, time/batch = 17.7198s	
9267/25300 (epoch 18.314), train_loss = 0.84915078, grad/param norm = 1.6652e-01, time/batch = 16.1439s	
9268/25300 (epoch 18.316), train_loss = 1.04586848, grad/param norm = 1.8715e-01, time/batch = 19.2178s	
9269/25300 (epoch 18.318), train_loss = 0.81643755, grad/param norm = 1.7026e-01, time/batch = 17.9056s	
9270/25300 (epoch 18.320), train_loss = 0.89130981, grad/param norm = 1.7421e-01, time/batch = 17.2111s	
9271/25300 (epoch 18.322), train_loss = 1.22826266, grad/param norm = 2.2519e-01, time/batch = 16.4733s	
9272/25300 (epoch 18.324), train_loss = 0.90429594, grad/param norm = 1.6756e-01, time/batch = 16.9387s	
9273/25300 (epoch 18.326), train_loss = 0.80680033, grad/param norm = 1.5584e-01, time/batch = 17.2138s	
9274/25300 (epoch 18.328), train_loss = 0.81703606, grad/param norm = 1.9279e-01, time/batch = 16.3033s	
9275/25300 (epoch 18.330), train_loss = 0.97934975, grad/param norm = 1.8023e-01, time/batch = 17.8111s	
9276/25300 (epoch 18.332), train_loss = 1.01521784, grad/param norm = 1.7006e-01, time/batch = 18.7093s	
9277/25300 (epoch 18.334), train_loss = 0.83590026, grad/param norm = 1.7157e-01, time/batch = 30.6242s	
9278/25300 (epoch 18.336), train_loss = 0.85476395, grad/param norm = 1.6427e-01, time/batch = 17.2348s	
9279/25300 (epoch 18.338), train_loss = 0.85188420, grad/param norm = 1.6174e-01, time/batch = 17.2848s	
9280/25300 (epoch 18.340), train_loss = 0.94828362, grad/param norm = 2.0169e-01, time/batch = 17.2246s	
9281/25300 (epoch 18.342), train_loss = 0.94291799, grad/param norm = 1.9836e-01, time/batch = 17.4685s	
9282/25300 (epoch 18.344), train_loss = 1.01134295, grad/param norm = 1.8714e-01, time/batch = 16.6452s	
9283/25300 (epoch 18.346), train_loss = 0.96584382, grad/param norm = 1.9804e-01, time/batch = 15.6431s	
9284/25300 (epoch 18.348), train_loss = 0.87059258, grad/param norm = 1.6374e-01, time/batch = 17.4757s	
9285/25300 (epoch 18.350), train_loss = 0.94912052, grad/param norm = 1.7693e-01, time/batch = 18.4748s	
9286/25300 (epoch 18.352), train_loss = 0.98236114, grad/param norm = 1.6194e-01, time/batch = 18.1327s	
9287/25300 (epoch 18.354), train_loss = 0.92337667, grad/param norm = 1.7236e-01, time/batch = 15.9847s	
9288/25300 (epoch 18.356), train_loss = 0.99202292, grad/param norm = 1.9813e-01, time/batch = 19.3737s	
9289/25300 (epoch 18.358), train_loss = 1.08475556, grad/param norm = 2.0794e-01, time/batch = 17.9682s	
9290/25300 (epoch 18.360), train_loss = 0.90462476, grad/param norm = 1.7483e-01, time/batch = 16.2813s	
9291/25300 (epoch 18.362), train_loss = 0.92757139, grad/param norm = 2.1990e-01, time/batch = 16.4011s	
9292/25300 (epoch 18.364), train_loss = 0.96277727, grad/param norm = 1.9999e-01, time/batch = 18.1342s	
9293/25300 (epoch 18.366), train_loss = 0.84555364, grad/param norm = 1.7645e-01, time/batch = 15.9659s	
9294/25300 (epoch 18.368), train_loss = 0.95135207, grad/param norm = 1.7134e-01, time/batch = 15.6086s	
9295/25300 (epoch 18.370), train_loss = 0.93276081, grad/param norm = 1.8801e-01, time/batch = 15.6535s	
9296/25300 (epoch 18.372), train_loss = 0.92767281, grad/param norm = 1.7007e-01, time/batch = 15.3954s	
9297/25300 (epoch 18.374), train_loss = 0.87082448, grad/param norm = 1.8080e-01, time/batch = 15.1053s	
9298/25300 (epoch 18.375), train_loss = 1.12888071, grad/param norm = 2.1139e-01, time/batch = 14.9448s	
9299/25300 (epoch 18.377), train_loss = 1.03575355, grad/param norm = 2.0193e-01, time/batch = 15.3746s	
9300/25300 (epoch 18.379), train_loss = 1.02485029, grad/param norm = 1.9930e-01, time/batch = 15.7184s	
9301/25300 (epoch 18.381), train_loss = 0.99955049, grad/param norm = 1.8592e-01, time/batch = 15.3700s	
9302/25300 (epoch 18.383), train_loss = 0.89853306, grad/param norm = 1.7002e-01, time/batch = 15.0302s	
9303/25300 (epoch 18.385), train_loss = 0.98726885, grad/param norm = 1.7390e-01, time/batch = 15.1276s	
9304/25300 (epoch 18.387), train_loss = 1.01655298, grad/param norm = 1.8319e-01, time/batch = 15.3800s	
9305/25300 (epoch 18.389), train_loss = 1.05583288, grad/param norm = 2.0094e-01, time/batch = 16.1394s	
9306/25300 (epoch 18.391), train_loss = 0.90951591, grad/param norm = 1.5695e-01, time/batch = 16.0611s	
9307/25300 (epoch 18.393), train_loss = 1.01758523, grad/param norm = 2.2103e-01, time/batch = 16.9690s	
9308/25300 (epoch 18.395), train_loss = 0.84577446, grad/param norm = 1.6238e-01, time/batch = 16.7841s	
9309/25300 (epoch 18.397), train_loss = 0.87114826, grad/param norm = 2.0608e-01, time/batch = 17.1297s	
9310/25300 (epoch 18.399), train_loss = 0.86397664, grad/param norm = 1.9038e-01, time/batch = 19.1271s	
9311/25300 (epoch 18.401), train_loss = 1.08636055, grad/param norm = 2.0603e-01, time/batch = 18.2932s	
9312/25300 (epoch 18.403), train_loss = 0.99556901, grad/param norm = 2.2309e-01, time/batch = 15.7255s	
9313/25300 (epoch 18.405), train_loss = 0.99664843, grad/param norm = 1.9948e-01, time/batch = 16.1142s	
9314/25300 (epoch 18.407), train_loss = 0.94678128, grad/param norm = 1.7969e-01, time/batch = 17.7237s	
9315/25300 (epoch 18.409), train_loss = 0.89734253, grad/param norm = 1.7211e-01, time/batch = 16.9745s	
9316/25300 (epoch 18.411), train_loss = 0.91046716, grad/param norm = 1.8057e-01, time/batch = 17.3964s	
9317/25300 (epoch 18.413), train_loss = 0.84049332, grad/param norm = 1.6733e-01, time/batch = 16.9798s	
9318/25300 (epoch 18.415), train_loss = 0.86108566, grad/param norm = 1.8562e-01, time/batch = 16.5698s	
9319/25300 (epoch 18.417), train_loss = 0.81773562, grad/param norm = 1.6534e-01, time/batch = 16.4525s	
9320/25300 (epoch 18.419), train_loss = 0.77900773, grad/param norm = 1.5995e-01, time/batch = 15.8015s	
9321/25300 (epoch 18.421), train_loss = 0.83905646, grad/param norm = 1.5527e-01, time/batch = 17.0399s	
9322/25300 (epoch 18.423), train_loss = 0.86976002, grad/param norm = 1.9318e-01, time/batch = 15.5707s	
9323/25300 (epoch 18.425), train_loss = 0.95260676, grad/param norm = 1.9759e-01, time/batch = 15.3038s	
9324/25300 (epoch 18.427), train_loss = 1.15293788, grad/param norm = 2.1200e-01, time/batch = 16.6491s	
9325/25300 (epoch 18.429), train_loss = 1.07863158, grad/param norm = 2.1127e-01, time/batch = 16.3843s	
9326/25300 (epoch 18.431), train_loss = 1.01293787, grad/param norm = 1.8316e-01, time/batch = 16.4875s	
9327/25300 (epoch 18.433), train_loss = 0.96088847, grad/param norm = 1.7379e-01, time/batch = 16.5686s	
9328/25300 (epoch 18.435), train_loss = 0.90837363, grad/param norm = 1.9753e-01, time/batch = 16.6561s	
9329/25300 (epoch 18.437), train_loss = 0.93488096, grad/param norm = 1.9483e-01, time/batch = 17.0575s	
9330/25300 (epoch 18.439), train_loss = 0.99763727, grad/param norm = 1.8281e-01, time/batch = 15.9570s	
9331/25300 (epoch 18.441), train_loss = 1.02680620, grad/param norm = 1.9318e-01, time/batch = 18.3834s	
9332/25300 (epoch 18.443), train_loss = 1.23292477, grad/param norm = 2.2896e-01, time/batch = 17.3890s	
9333/25300 (epoch 18.445), train_loss = 1.17174904, grad/param norm = 2.0783e-01, time/batch = 16.5589s	
9334/25300 (epoch 18.447), train_loss = 0.88341773, grad/param norm = 1.6318e-01, time/batch = 17.2125s	
9335/25300 (epoch 18.449), train_loss = 0.81049913, grad/param norm = 1.7346e-01, time/batch = 17.2946s	
9336/25300 (epoch 18.451), train_loss = 1.18434299, grad/param norm = 2.0606e-01, time/batch = 18.1451s	
9337/25300 (epoch 18.453), train_loss = 1.06550310, grad/param norm = 2.1663e-01, time/batch = 16.7148s	
9338/25300 (epoch 18.455), train_loss = 1.06574950, grad/param norm = 2.0514e-01, time/batch = 18.6232s	
9339/25300 (epoch 18.457), train_loss = 0.93296354, grad/param norm = 1.7664e-01, time/batch = 18.3851s	
9340/25300 (epoch 18.458), train_loss = 0.98820140, grad/param norm = 2.0651e-01, time/batch = 18.6277s	
9341/25300 (epoch 18.460), train_loss = 0.98701332, grad/param norm = 1.8027e-01, time/batch = 17.3104s	
9342/25300 (epoch 18.462), train_loss = 0.75105456, grad/param norm = 1.7912e-01, time/batch = 15.7384s	
9343/25300 (epoch 18.464), train_loss = 1.07385661, grad/param norm = 2.1085e-01, time/batch = 17.7112s	
9344/25300 (epoch 18.466), train_loss = 1.04142036, grad/param norm = 1.8183e-01, time/batch = 18.8038s	
9345/25300 (epoch 18.468), train_loss = 1.08361959, grad/param norm = 2.3626e-01, time/batch = 17.4783s	
9346/25300 (epoch 18.470), train_loss = 0.93469672, grad/param norm = 1.8174e-01, time/batch = 19.6421s	
9347/25300 (epoch 18.472), train_loss = 0.84473718, grad/param norm = 1.6875e-01, time/batch = 16.3005s	
9348/25300 (epoch 18.474), train_loss = 1.00118693, grad/param norm = 1.7773e-01, time/batch = 17.5612s	
9349/25300 (epoch 18.476), train_loss = 0.95064277, grad/param norm = 1.7713e-01, time/batch = 19.2895s	
9350/25300 (epoch 18.478), train_loss = 1.04140837, grad/param norm = 1.8971e-01, time/batch = 15.9580s	
9351/25300 (epoch 18.480), train_loss = 0.91772703, grad/param norm = 1.9033e-01, time/batch = 18.7104s	
9352/25300 (epoch 18.482), train_loss = 1.06169616, grad/param norm = 2.1674e-01, time/batch = 18.7591s	
9353/25300 (epoch 18.484), train_loss = 1.05881617, grad/param norm = 2.0277e-01, time/batch = 18.0329s	
9354/25300 (epoch 18.486), train_loss = 0.99930432, grad/param norm = 1.9850e-01, time/batch = 16.6422s	
9355/25300 (epoch 18.488), train_loss = 1.14571723, grad/param norm = 2.0126e-01, time/batch = 15.6284s	
9356/25300 (epoch 18.490), train_loss = 1.04546300, grad/param norm = 1.8639e-01, time/batch = 17.2095s	
9357/25300 (epoch 18.492), train_loss = 1.01281429, grad/param norm = 1.8209e-01, time/batch = 18.7864s	
9358/25300 (epoch 18.494), train_loss = 0.92371908, grad/param norm = 1.6997e-01, time/batch = 17.5357s	
9359/25300 (epoch 18.496), train_loss = 0.98140084, grad/param norm = 1.7692e-01, time/batch = 16.8682s	
9360/25300 (epoch 18.498), train_loss = 0.91085366, grad/param norm = 1.7444e-01, time/batch = 16.4379s	
9361/25300 (epoch 18.500), train_loss = 1.10940200, grad/param norm = 2.0222e-01, time/batch = 16.5526s	
9362/25300 (epoch 18.502), train_loss = 1.03151683, grad/param norm = 2.0660e-01, time/batch = 20.0556s	
9363/25300 (epoch 18.504), train_loss = 0.95206129, grad/param norm = 1.8851e-01, time/batch = 18.9658s	
9364/25300 (epoch 18.506), train_loss = 0.90456988, grad/param norm = 1.7501e-01, time/batch = 15.8735s	
9365/25300 (epoch 18.508), train_loss = 0.98634640, grad/param norm = 2.0319e-01, time/batch = 16.8051s	
9366/25300 (epoch 18.510), train_loss = 0.90362519, grad/param norm = 1.8398e-01, time/batch = 16.0581s	
9367/25300 (epoch 18.512), train_loss = 0.75031077, grad/param norm = 1.6857e-01, time/batch = 16.2987s	
9368/25300 (epoch 18.514), train_loss = 0.96167216, grad/param norm = 1.7048e-01, time/batch = 15.9700s	
9369/25300 (epoch 18.516), train_loss = 1.02395084, grad/param norm = 1.9118e-01, time/batch = 17.2311s	
9370/25300 (epoch 18.518), train_loss = 1.09399874, grad/param norm = 2.1744e-01, time/batch = 16.6667s	
9371/25300 (epoch 18.520), train_loss = 0.83261683, grad/param norm = 1.5689e-01, time/batch = 16.8781s	
9372/25300 (epoch 18.522), train_loss = 0.91664406, grad/param norm = 1.8223e-01, time/batch = 19.7135s	
9373/25300 (epoch 18.524), train_loss = 0.94439828, grad/param norm = 1.7269e-01, time/batch = 20.4611s	
9374/25300 (epoch 18.526), train_loss = 1.17933807, grad/param norm = 2.1980e-01, time/batch = 17.3062s	
9375/25300 (epoch 18.528), train_loss = 1.13381960, grad/param norm = 2.0919e-01, time/batch = 15.7047s	
9376/25300 (epoch 18.530), train_loss = 0.99657417, grad/param norm = 1.8880e-01, time/batch = 17.8205s	
9377/25300 (epoch 18.532), train_loss = 0.98664904, grad/param norm = 1.8875e-01, time/batch = 17.0429s	
9378/25300 (epoch 18.534), train_loss = 0.97730849, grad/param norm = 2.1825e-01, time/batch = 16.1320s	
9379/25300 (epoch 18.536), train_loss = 0.79845788, grad/param norm = 1.7259e-01, time/batch = 20.2068s	
9380/25300 (epoch 18.538), train_loss = 0.83993672, grad/param norm = 1.4933e-01, time/batch = 18.2933s	
9381/25300 (epoch 18.540), train_loss = 0.89485918, grad/param norm = 1.7111e-01, time/batch = 15.8715s	
9382/25300 (epoch 18.542), train_loss = 0.87582204, grad/param norm = 1.6910e-01, time/batch = 15.2642s	
9383/25300 (epoch 18.543), train_loss = 0.83060875, grad/param norm = 1.7720e-01, time/batch = 15.2661s	
9384/25300 (epoch 18.545), train_loss = 1.27247566, grad/param norm = 2.6186e-01, time/batch = 15.0182s	
9385/25300 (epoch 18.547), train_loss = 1.05080613, grad/param norm = 2.0398e-01, time/batch = 15.2625s	
9386/25300 (epoch 18.549), train_loss = 1.23506433, grad/param norm = 2.2379e-01, time/batch = 15.5026s	
9387/25300 (epoch 18.551), train_loss = 1.06215758, grad/param norm = 1.9900e-01, time/batch = 15.4897s	
9388/25300 (epoch 18.553), train_loss = 0.92463278, grad/param norm = 2.1047e-01, time/batch = 15.6926s	
9389/25300 (epoch 18.555), train_loss = 1.10449095, grad/param norm = 2.1595e-01, time/batch = 15.7526s	
9390/25300 (epoch 18.557), train_loss = 1.11806096, grad/param norm = 2.0270e-01, time/batch = 17.3674s	
9391/25300 (epoch 18.559), train_loss = 1.08560306, grad/param norm = 1.9728e-01, time/batch = 16.2944s	
9392/25300 (epoch 18.561), train_loss = 1.13008111, grad/param norm = 2.0262e-01, time/batch = 17.2088s	
9393/25300 (epoch 18.563), train_loss = 1.09019157, grad/param norm = 1.9306e-01, time/batch = 16.9472s	
9394/25300 (epoch 18.565), train_loss = 0.84827902, grad/param norm = 1.6132e-01, time/batch = 17.2937s	
9395/25300 (epoch 18.567), train_loss = 0.75028044, grad/param norm = 1.6794e-01, time/batch = 15.8794s	
9396/25300 (epoch 18.569), train_loss = 0.98745989, grad/param norm = 1.9339e-01, time/batch = 16.7069s	
9397/25300 (epoch 18.571), train_loss = 1.08099767, grad/param norm = 2.0445e-01, time/batch = 17.7258s	
9398/25300 (epoch 18.573), train_loss = 0.98854838, grad/param norm = 1.8813e-01, time/batch = 16.4011s	
9399/25300 (epoch 18.575), train_loss = 1.09849974, grad/param norm = 1.9460e-01, time/batch = 17.4543s	
9400/25300 (epoch 18.577), train_loss = 1.02003886, grad/param norm = 1.9527e-01, time/batch = 17.5365s	
9401/25300 (epoch 18.579), train_loss = 1.15901839, grad/param norm = 2.1805e-01, time/batch = 16.0606s	
9402/25300 (epoch 18.581), train_loss = 1.05989755, grad/param norm = 2.0109e-01, time/batch = 17.3936s	
9403/25300 (epoch 18.583), train_loss = 0.84653609, grad/param norm = 2.0104e-01, time/batch = 16.2206s	
9404/25300 (epoch 18.585), train_loss = 0.84591706, grad/param norm = 1.8509e-01, time/batch = 16.5445s	
9405/25300 (epoch 18.587), train_loss = 0.96051246, grad/param norm = 1.7878e-01, time/batch = 17.3823s	
9406/25300 (epoch 18.589), train_loss = 0.86740638, grad/param norm = 1.7319e-01, time/batch = 15.8670s	
9407/25300 (epoch 18.591), train_loss = 0.87971741, grad/param norm = 2.1172e-01, time/batch = 16.3113s	
9408/25300 (epoch 18.593), train_loss = 1.05663313, grad/param norm = 1.9602e-01, time/batch = 17.7962s	
9409/25300 (epoch 18.595), train_loss = 0.97789209, grad/param norm = 2.1291e-01, time/batch = 17.3064s	
9410/25300 (epoch 18.597), train_loss = 0.82705684, grad/param norm = 1.6264e-01, time/batch = 16.9686s	
9411/25300 (epoch 18.599), train_loss = 1.02501092, grad/param norm = 1.9722e-01, time/batch = 16.5517s	
9412/25300 (epoch 18.601), train_loss = 1.00823252, grad/param norm = 1.9731e-01, time/batch = 16.0457s	
9413/25300 (epoch 18.603), train_loss = 0.99119045, grad/param norm = 1.9468e-01, time/batch = 16.3676s	
9414/25300 (epoch 18.605), train_loss = 0.89641072, grad/param norm = 1.8143e-01, time/batch = 16.2202s	
9415/25300 (epoch 18.607), train_loss = 0.74720801, grad/param norm = 1.5931e-01, time/batch = 16.8003s	
9416/25300 (epoch 18.609), train_loss = 0.95594290, grad/param norm = 1.8360e-01, time/batch = 18.5441s	
9417/25300 (epoch 18.611), train_loss = 1.02039105, grad/param norm = 1.9215e-01, time/batch = 15.5604s	
9418/25300 (epoch 18.613), train_loss = 0.82979856, grad/param norm = 1.7156e-01, time/batch = 16.3105s	
9419/25300 (epoch 18.615), train_loss = 0.94818158, grad/param norm = 1.8886e-01, time/batch = 15.6529s	
9420/25300 (epoch 18.617), train_loss = 0.99225439, grad/param norm = 2.0306e-01, time/batch = 16.8135s	
9421/25300 (epoch 18.619), train_loss = 1.06063145, grad/param norm = 2.0814e-01, time/batch = 16.0187s	
9422/25300 (epoch 18.621), train_loss = 1.10007274, grad/param norm = 2.1476e-01, time/batch = 16.5562s	
9423/25300 (epoch 18.623), train_loss = 0.91882593, grad/param norm = 1.8798e-01, time/batch = 18.1285s	
9424/25300 (epoch 18.625), train_loss = 0.79942066, grad/param norm = 1.6698e-01, time/batch = 16.2981s	
9425/25300 (epoch 18.626), train_loss = 0.94499754, grad/param norm = 1.7527e-01, time/batch = 23.8932s	
9426/25300 (epoch 18.628), train_loss = 1.04288160, grad/param norm = 1.8422e-01, time/batch = 34.1726s	
9427/25300 (epoch 18.630), train_loss = 1.05816729, grad/param norm = 2.5178e-01, time/batch = 32.8423s	
9428/25300 (epoch 18.632), train_loss = 1.02420119, grad/param norm = 2.3440e-01, time/batch = 31.6394s	
9429/25300 (epoch 18.634), train_loss = 1.08882497, grad/param norm = 2.1778e-01, time/batch = 34.8602s	
9430/25300 (epoch 18.636), train_loss = 0.92319414, grad/param norm = 1.7915e-01, time/batch = 31.2986s	
9431/25300 (epoch 18.638), train_loss = 1.03480869, grad/param norm = 2.1889e-01, time/batch = 33.5175s	
9432/25300 (epoch 18.640), train_loss = 1.17132739, grad/param norm = 2.2336e-01, time/batch = 34.7681s	
9433/25300 (epoch 18.642), train_loss = 1.03425250, grad/param norm = 1.9799e-01, time/batch = 32.5980s	
9434/25300 (epoch 18.644), train_loss = 1.02732564, grad/param norm = 2.2012e-01, time/batch = 31.9549s	
9435/25300 (epoch 18.646), train_loss = 0.94023759, grad/param norm = 2.1958e-01, time/batch = 16.4717s	
9436/25300 (epoch 18.648), train_loss = 1.07723795, grad/param norm = 1.8206e-01, time/batch = 16.7336s	
9437/25300 (epoch 18.650), train_loss = 1.03305922, grad/param norm = 1.9284e-01, time/batch = 16.4828s	
9438/25300 (epoch 18.652), train_loss = 1.01457221, grad/param norm = 2.0261e-01, time/batch = 16.3864s	
9439/25300 (epoch 18.654), train_loss = 1.13545191, grad/param norm = 1.9100e-01, time/batch = 16.7204s	
9440/25300 (epoch 18.656), train_loss = 1.06724879, grad/param norm = 2.1260e-01, time/batch = 15.7881s	
9441/25300 (epoch 18.658), train_loss = 0.82875894, grad/param norm = 1.6624e-01, time/batch = 16.8898s	
9442/25300 (epoch 18.660), train_loss = 0.88557342, grad/param norm = 1.8549e-01, time/batch = 16.7322s	
9443/25300 (epoch 18.662), train_loss = 0.84793994, grad/param norm = 1.7143e-01, time/batch = 16.5638s	
9444/25300 (epoch 18.664), train_loss = 0.83050665, grad/param norm = 1.6740e-01, time/batch = 15.8040s	
9445/25300 (epoch 18.666), train_loss = 0.86734123, grad/param norm = 1.8178e-01, time/batch = 16.6490s	
9446/25300 (epoch 18.668), train_loss = 0.95874146, grad/param norm = 2.4830e-01, time/batch = 17.1342s	
9447/25300 (epoch 18.670), train_loss = 0.85886891, grad/param norm = 1.9071e-01, time/batch = 15.9755s	
9448/25300 (epoch 18.672), train_loss = 0.87182209, grad/param norm = 1.8098e-01, time/batch = 16.3995s	
9449/25300 (epoch 18.674), train_loss = 0.88658192, grad/param norm = 1.7061e-01, time/batch = 16.5595s	
9450/25300 (epoch 18.676), train_loss = 0.94095784, grad/param norm = 1.9625e-01, time/batch = 16.7262s	
9451/25300 (epoch 18.678), train_loss = 0.91813325, grad/param norm = 2.0639e-01, time/batch = 17.1203s	
9452/25300 (epoch 18.680), train_loss = 0.80949282, grad/param norm = 1.7777e-01, time/batch = 17.3670s	
9453/25300 (epoch 18.682), train_loss = 0.67859295, grad/param norm = 1.6057e-01, time/batch = 15.8022s	
9454/25300 (epoch 18.684), train_loss = 0.84402609, grad/param norm = 1.6025e-01, time/batch = 15.7945s	
9455/25300 (epoch 18.686), train_loss = 0.82774868, grad/param norm = 1.6915e-01, time/batch = 16.0496s	
9456/25300 (epoch 18.688), train_loss = 0.94107174, grad/param norm = 1.9191e-01, time/batch = 16.4632s	
9457/25300 (epoch 18.690), train_loss = 0.83967464, grad/param norm = 1.6064e-01, time/batch = 18.8666s	
9458/25300 (epoch 18.692), train_loss = 0.90682839, grad/param norm = 1.7600e-01, time/batch = 16.1404s	
9459/25300 (epoch 18.694), train_loss = 0.87227876, grad/param norm = 1.6456e-01, time/batch = 16.2812s	
9460/25300 (epoch 18.696), train_loss = 0.97915629, grad/param norm = 2.0668e-01, time/batch = 17.3703s	
9461/25300 (epoch 18.698), train_loss = 1.02463339, grad/param norm = 1.8467e-01, time/batch = 18.1181s	
9462/25300 (epoch 18.700), train_loss = 0.78077764, grad/param norm = 1.7308e-01, time/batch = 16.0312s	
9463/25300 (epoch 18.702), train_loss = 1.06076730, grad/param norm = 1.9038e-01, time/batch = 16.8794s	
9464/25300 (epoch 18.704), train_loss = 0.79553108, grad/param norm = 1.8570e-01, time/batch = 18.1159s	
9465/25300 (epoch 18.706), train_loss = 0.96119828, grad/param norm = 2.0769e-01, time/batch = 16.3015s	
9466/25300 (epoch 18.708), train_loss = 0.80247927, grad/param norm = 1.6585e-01, time/batch = 16.8134s	
9467/25300 (epoch 18.709), train_loss = 1.14209005, grad/param norm = 2.0305e-01, time/batch = 15.8905s	
9468/25300 (epoch 18.711), train_loss = 1.13547279, grad/param norm = 2.0072e-01, time/batch = 16.2981s	
9469/25300 (epoch 18.713), train_loss = 0.94188855, grad/param norm = 1.7422e-01, time/batch = 16.2176s	
9470/25300 (epoch 18.715), train_loss = 0.95007840, grad/param norm = 1.6792e-01, time/batch = 16.9816s	
9471/25300 (epoch 18.717), train_loss = 0.87935425, grad/param norm = 2.0077e-01, time/batch = 16.6347s	
9472/25300 (epoch 18.719), train_loss = 0.93914663, grad/param norm = 1.7932e-01, time/batch = 16.3028s	
9473/25300 (epoch 18.721), train_loss = 0.98895015, grad/param norm = 1.8465e-01, time/batch = 16.6448s	
9474/25300 (epoch 18.723), train_loss = 0.90059035, grad/param norm = 1.8098e-01, time/batch = 15.9782s	
9475/25300 (epoch 18.725), train_loss = 0.99025401, grad/param norm = 1.9137e-01, time/batch = 17.2112s	
9476/25300 (epoch 18.727), train_loss = 0.98939453, grad/param norm = 1.8269e-01, time/batch = 16.2895s	
9477/25300 (epoch 18.729), train_loss = 0.95588823, grad/param norm = 1.7010e-01, time/batch = 16.5500s	
9478/25300 (epoch 18.731), train_loss = 1.13325472, grad/param norm = 1.9568e-01, time/batch = 16.5487s	
9479/25300 (epoch 18.733), train_loss = 0.93456567, grad/param norm = 1.5712e-01, time/batch = 15.6484s	
9480/25300 (epoch 18.735), train_loss = 1.26907780, grad/param norm = 2.1842e-01, time/batch = 26.1314s	
9481/25300 (epoch 18.737), train_loss = 0.83065692, grad/param norm = 1.5924e-01, time/batch = 19.5063s	
9482/25300 (epoch 18.739), train_loss = 1.11399756, grad/param norm = 1.8782e-01, time/batch = 15.8076s	
9483/25300 (epoch 18.741), train_loss = 1.03312049, grad/param norm = 2.0607e-01, time/batch = 16.5525s	
9484/25300 (epoch 18.743), train_loss = 0.93420018, grad/param norm = 1.7275e-01, time/batch = 17.0484s	
9485/25300 (epoch 18.745), train_loss = 0.89081977, grad/param norm = 1.7610e-01, time/batch = 17.2267s	
9486/25300 (epoch 18.747), train_loss = 0.88207727, grad/param norm = 1.8438e-01, time/batch = 15.9736s	
9487/25300 (epoch 18.749), train_loss = 1.01230022, grad/param norm = 1.9092e-01, time/batch = 16.2282s	
9488/25300 (epoch 18.751), train_loss = 1.06453142, grad/param norm = 1.9599e-01, time/batch = 16.2225s	
9489/25300 (epoch 18.753), train_loss = 0.88457464, grad/param norm = 1.9253e-01, time/batch = 17.0511s	
9490/25300 (epoch 18.755), train_loss = 1.09430271, grad/param norm = 2.2223e-01, time/batch = 15.6317s	
9491/25300 (epoch 18.757), train_loss = 0.88671064, grad/param norm = 1.7051e-01, time/batch = 16.7325s	
9492/25300 (epoch 18.759), train_loss = 0.87427521, grad/param norm = 1.8318e-01, time/batch = 17.7226s	
9493/25300 (epoch 18.761), train_loss = 1.12113342, grad/param norm = 1.9453e-01, time/batch = 16.6131s	
9494/25300 (epoch 18.763), train_loss = 0.91020862, grad/param norm = 1.8837e-01, time/batch = 15.5536s	
9495/25300 (epoch 18.765), train_loss = 0.92780787, grad/param norm = 2.0081e-01, time/batch = 16.8773s	
9496/25300 (epoch 18.767), train_loss = 0.90203708, grad/param norm = 1.8048e-01, time/batch = 16.8835s	
9497/25300 (epoch 18.769), train_loss = 1.00244328, grad/param norm = 2.4417e-01, time/batch = 16.5350s	
9498/25300 (epoch 18.771), train_loss = 1.09299390, grad/param norm = 2.2065e-01, time/batch = 16.5580s	
9499/25300 (epoch 18.773), train_loss = 1.10016394, grad/param norm = 2.2996e-01, time/batch = 17.2928s	
9500/25300 (epoch 18.775), train_loss = 0.93529875, grad/param norm = 1.7098e-01, time/batch = 17.0596s	
9501/25300 (epoch 18.777), train_loss = 0.98902661, grad/param norm = 2.0881e-01, time/batch = 16.3902s	
9502/25300 (epoch 18.779), train_loss = 1.04877008, grad/param norm = 1.7856e-01, time/batch = 17.5538s	
9503/25300 (epoch 18.781), train_loss = 1.00736385, grad/param norm = 1.8076e-01, time/batch = 16.2285s	
9504/25300 (epoch 18.783), train_loss = 1.11362764, grad/param norm = 1.9526e-01, time/batch = 16.9645s	
9505/25300 (epoch 18.785), train_loss = 1.07081546, grad/param norm = 1.9371e-01, time/batch = 16.8149s	
9506/25300 (epoch 18.787), train_loss = 1.06185038, grad/param norm = 1.9840e-01, time/batch = 16.4701s	
9507/25300 (epoch 18.789), train_loss = 1.22995657, grad/param norm = 2.2561e-01, time/batch = 15.7017s	
9508/25300 (epoch 18.791), train_loss = 1.04707328, grad/param norm = 1.9464e-01, time/batch = 16.8049s	
9509/25300 (epoch 18.792), train_loss = 1.09469748, grad/param norm = 1.8619e-01, time/batch = 15.8956s	
9510/25300 (epoch 18.794), train_loss = 0.98735725, grad/param norm = 1.9220e-01, time/batch = 18.2143s	
9511/25300 (epoch 18.796), train_loss = 0.92973012, grad/param norm = 1.9767e-01, time/batch = 16.3837s	
9512/25300 (epoch 18.798), train_loss = 1.10156930, grad/param norm = 2.0632e-01, time/batch = 16.2316s	
9513/25300 (epoch 18.800), train_loss = 0.96732168, grad/param norm = 1.7723e-01, time/batch = 15.8034s	
9514/25300 (epoch 18.802), train_loss = 0.79100305, grad/param norm = 1.7092e-01, time/batch = 17.0621s	
9515/25300 (epoch 18.804), train_loss = 0.99620423, grad/param norm = 1.7561e-01, time/batch = 16.5377s	
9516/25300 (epoch 18.806), train_loss = 1.06035613, grad/param norm = 1.9816e-01, time/batch = 17.4714s	
9517/25300 (epoch 18.808), train_loss = 1.04536606, grad/param norm = 1.9155e-01, time/batch = 17.3702s	
9518/25300 (epoch 18.810), train_loss = 0.99383519, grad/param norm = 1.9900e-01, time/batch = 16.5354s	
9519/25300 (epoch 18.812), train_loss = 1.08814162, grad/param norm = 1.8838e-01, time/batch = 17.2236s	
9520/25300 (epoch 18.814), train_loss = 1.15812743, grad/param norm = 2.1240e-01, time/batch = 18.1417s	
9521/25300 (epoch 18.816), train_loss = 1.24539656, grad/param norm = 2.1131e-01, time/batch = 17.4690s	
9522/25300 (epoch 18.818), train_loss = 1.02372192, grad/param norm = 1.8268e-01, time/batch = 16.5481s	
9523/25300 (epoch 18.820), train_loss = 1.04574450, grad/param norm = 1.9669e-01, time/batch = 16.3016s	
9524/25300 (epoch 18.822), train_loss = 0.97008737, grad/param norm = 1.8302e-01, time/batch = 16.4759s	
9525/25300 (epoch 18.824), train_loss = 1.08203215, grad/param norm = 1.9492e-01, time/batch = 16.0615s	
9526/25300 (epoch 18.826), train_loss = 0.94286751, grad/param norm = 1.8888e-01, time/batch = 16.3181s	
9527/25300 (epoch 18.828), train_loss = 0.92695576, grad/param norm = 1.9127e-01, time/batch = 17.3939s	
9528/25300 (epoch 18.830), train_loss = 1.00060868, grad/param norm = 1.8009e-01, time/batch = 18.0409s	
9529/25300 (epoch 18.832), train_loss = 1.05549799, grad/param norm = 1.9196e-01, time/batch = 16.3016s	
9530/25300 (epoch 18.834), train_loss = 0.85841023, grad/param norm = 1.6881e-01, time/batch = 16.6541s	
9531/25300 (epoch 18.836), train_loss = 0.95386868, grad/param norm = 1.8104e-01, time/batch = 16.4696s	
9532/25300 (epoch 18.838), train_loss = 0.95325320, grad/param norm = 1.9373e-01, time/batch = 16.7167s	
9533/25300 (epoch 18.840), train_loss = 1.11621869, grad/param norm = 1.9689e-01, time/batch = 15.9699s	
9534/25300 (epoch 18.842), train_loss = 0.99432455, grad/param norm = 2.0811e-01, time/batch = 15.7884s	
9535/25300 (epoch 18.844), train_loss = 1.03722047, grad/param norm = 1.7500e-01, time/batch = 15.5191s	
9536/25300 (epoch 18.846), train_loss = 1.04150119, grad/param norm = 1.7898e-01, time/batch = 15.3952s	
9537/25300 (epoch 18.848), train_loss = 1.09716542, grad/param norm = 2.0927e-01, time/batch = 15.2748s	
9538/25300 (epoch 18.850), train_loss = 1.05399526, grad/param norm = 1.9927e-01, time/batch = 15.3727s	
9539/25300 (epoch 18.852), train_loss = 1.07862233, grad/param norm = 1.9807e-01, time/batch = 15.6092s	
9540/25300 (epoch 18.854), train_loss = 1.15371036, grad/param norm = 2.0401e-01, time/batch = 15.5297s	
9541/25300 (epoch 18.856), train_loss = 0.98265447, grad/param norm = 2.0683e-01, time/batch = 15.1148s	
9542/25300 (epoch 18.858), train_loss = 1.03955756, grad/param norm = 2.2016e-01, time/batch = 15.8124s	
9543/25300 (epoch 18.860), train_loss = 0.85150430, grad/param norm = 1.7770e-01, time/batch = 16.4615s	
9544/25300 (epoch 18.862), train_loss = 0.99476398, grad/param norm = 2.1054e-01, time/batch = 15.3018s	
9545/25300 (epoch 18.864), train_loss = 1.08878917, grad/param norm = 1.9262e-01, time/batch = 15.7168s	
9546/25300 (epoch 18.866), train_loss = 0.99305815, grad/param norm = 1.9569e-01, time/batch = 16.0651s	
9547/25300 (epoch 18.868), train_loss = 1.13354097, grad/param norm = 2.1088e-01, time/batch = 16.0634s	
9548/25300 (epoch 18.870), train_loss = 1.08364622, grad/param norm = 1.7539e-01, time/batch = 15.9677s	
9549/25300 (epoch 18.872), train_loss = 1.08162676, grad/param norm = 2.2443e-01, time/batch = 15.9724s	
9550/25300 (epoch 18.874), train_loss = 1.06876472, grad/param norm = 1.9194e-01, time/batch = 15.2150s	
9551/25300 (epoch 18.875), train_loss = 0.97412767, grad/param norm = 1.8279e-01, time/batch = 15.7170s	
9552/25300 (epoch 18.877), train_loss = 0.97716226, grad/param norm = 1.8577e-01, time/batch = 15.6251s	
9553/25300 (epoch 18.879), train_loss = 0.97801284, grad/param norm = 1.8782e-01, time/batch = 16.8805s	
9554/25300 (epoch 18.881), train_loss = 1.31129768, grad/param norm = 2.5047e-01, time/batch = 16.5235s	
9555/25300 (epoch 18.883), train_loss = 1.24271204, grad/param norm = 1.9307e-01, time/batch = 15.4622s	
9556/25300 (epoch 18.885), train_loss = 1.10208657, grad/param norm = 2.2685e-01, time/batch = 16.1364s	
9557/25300 (epoch 18.887), train_loss = 1.06993157, grad/param norm = 2.0757e-01, time/batch = 16.0637s	
9558/25300 (epoch 18.889), train_loss = 1.18448651, grad/param norm = 2.2725e-01, time/batch = 17.1316s	
9559/25300 (epoch 18.891), train_loss = 1.07168734, grad/param norm = 2.3200e-01, time/batch = 15.9601s	
9560/25300 (epoch 18.893), train_loss = 1.10451215, grad/param norm = 2.1134e-01, time/batch = 16.8859s	
9561/25300 (epoch 18.895), train_loss = 0.79614839, grad/param norm = 1.8252e-01, time/batch = 16.5541s	
9562/25300 (epoch 18.897), train_loss = 0.93473533, grad/param norm = 2.0045e-01, time/batch = 16.2223s	
9563/25300 (epoch 18.899), train_loss = 1.03109333, grad/param norm = 1.9054e-01, time/batch = 15.6313s	
9564/25300 (epoch 18.901), train_loss = 1.07898458, grad/param norm = 1.9212e-01, time/batch = 15.5573s	
9565/25300 (epoch 18.903), train_loss = 0.81629795, grad/param norm = 1.7254e-01, time/batch = 16.5647s	
9566/25300 (epoch 18.905), train_loss = 0.94510148, grad/param norm = 2.0234e-01, time/batch = 15.5583s	
9567/25300 (epoch 18.907), train_loss = 0.96621832, grad/param norm = 2.1484e-01, time/batch = 15.8980s	
9568/25300 (epoch 18.909), train_loss = 1.06663398, grad/param norm = 1.9637e-01, time/batch = 16.0752s	
9569/25300 (epoch 18.911), train_loss = 1.17241621, grad/param norm = 2.1787e-01, time/batch = 16.4658s	
9570/25300 (epoch 18.913), train_loss = 1.24514102, grad/param norm = 2.3869e-01, time/batch = 15.9500s	
9571/25300 (epoch 18.915), train_loss = 0.97636185, grad/param norm = 2.1676e-01, time/batch = 16.2072s	
9572/25300 (epoch 18.917), train_loss = 1.09821677, grad/param norm = 2.1758e-01, time/batch = 16.8748s	
9573/25300 (epoch 18.919), train_loss = 1.14625539, grad/param norm = 2.1037e-01, time/batch = 17.0561s	
9574/25300 (epoch 18.921), train_loss = 0.93293975, grad/param norm = 1.9965e-01, time/batch = 16.1286s	
9575/25300 (epoch 18.923), train_loss = 1.15848571, grad/param norm = 1.9543e-01, time/batch = 15.4520s	
9576/25300 (epoch 18.925), train_loss = 1.00104767, grad/param norm = 2.1591e-01, time/batch = 17.3920s	
9577/25300 (epoch 18.927), train_loss = 0.96071276, grad/param norm = 2.0075e-01, time/batch = 16.2143s	
9578/25300 (epoch 18.929), train_loss = 1.00867221, grad/param norm = 1.9589e-01, time/batch = 17.1265s	
9579/25300 (epoch 18.931), train_loss = 1.10153595, grad/param norm = 2.1427e-01, time/batch = 16.3912s	
9580/25300 (epoch 18.933), train_loss = 1.08569572, grad/param norm = 2.0719e-01, time/batch = 16.2146s	
9581/25300 (epoch 18.935), train_loss = 1.04758858, grad/param norm = 1.8797e-01, time/batch = 15.6201s	
9582/25300 (epoch 18.937), train_loss = 0.78042967, grad/param norm = 1.6201e-01, time/batch = 17.2257s	
9583/25300 (epoch 18.939), train_loss = 1.08667331, grad/param norm = 1.9202e-01, time/batch = 16.6357s	
9584/25300 (epoch 18.941), train_loss = 0.94730056, grad/param norm = 1.8666e-01, time/batch = 15.5249s	
9585/25300 (epoch 18.943), train_loss = 1.03179752, grad/param norm = 1.7884e-01, time/batch = 16.8690s	
9586/25300 (epoch 18.945), train_loss = 1.06921161, grad/param norm = 1.9829e-01, time/batch = 17.0387s	
9587/25300 (epoch 18.947), train_loss = 0.92082833, grad/param norm = 1.7628e-01, time/batch = 16.6423s	
9588/25300 (epoch 18.949), train_loss = 1.07543442, grad/param norm = 1.7997e-01, time/batch = 16.0570s	
9589/25300 (epoch 18.951), train_loss = 0.99652254, grad/param norm = 1.7395e-01, time/batch = 16.3540s	
9590/25300 (epoch 18.953), train_loss = 1.03601787, grad/param norm = 1.8777e-01, time/batch = 15.9793s	
9591/25300 (epoch 18.955), train_loss = 1.25260411, grad/param norm = 2.2931e-01, time/batch = 17.3831s	
9592/25300 (epoch 18.957), train_loss = 1.18342106, grad/param norm = 2.1606e-01, time/batch = 16.4429s	
9593/25300 (epoch 18.958), train_loss = 1.10727447, grad/param norm = 2.1268e-01, time/batch = 17.3787s	
9594/25300 (epoch 18.960), train_loss = 1.22758052, grad/param norm = 2.2350e-01, time/batch = 17.2157s	
9595/25300 (epoch 18.962), train_loss = 1.17391801, grad/param norm = 2.1590e-01, time/batch = 15.6289s	
9596/25300 (epoch 18.964), train_loss = 1.10004242, grad/param norm = 2.2167e-01, time/batch = 16.0603s	
9597/25300 (epoch 18.966), train_loss = 0.86283260, grad/param norm = 1.7306e-01, time/batch = 15.5562s	
9598/25300 (epoch 18.968), train_loss = 0.86195784, grad/param norm = 1.6619e-01, time/batch = 16.8124s	
9599/25300 (epoch 18.970), train_loss = 0.98349779, grad/param norm = 2.2471e-01, time/batch = 15.6318s	
9600/25300 (epoch 18.972), train_loss = 1.00826137, grad/param norm = 1.8831e-01, time/batch = 18.3764s	
9601/25300 (epoch 18.974), train_loss = 1.21692090, grad/param norm = 2.5011e-01, time/batch = 16.6478s	
9602/25300 (epoch 18.976), train_loss = 1.06528039, grad/param norm = 1.9139e-01, time/batch = 16.4743s	
9603/25300 (epoch 18.978), train_loss = 1.02301824, grad/param norm = 2.0204e-01, time/batch = 15.8798s	
9604/25300 (epoch 18.980), train_loss = 1.07373948, grad/param norm = 2.3203e-01, time/batch = 16.8104s	
9605/25300 (epoch 18.982), train_loss = 0.98145741, grad/param norm = 1.9079e-01, time/batch = 16.3892s	
9606/25300 (epoch 18.984), train_loss = 1.00493571, grad/param norm = 2.0320e-01, time/batch = 15.3516s	
9607/25300 (epoch 18.986), train_loss = 1.11726757, grad/param norm = 2.0867e-01, time/batch = 17.7136s	
9608/25300 (epoch 18.988), train_loss = 1.07057945, grad/param norm = 2.0056e-01, time/batch = 16.4714s	
9609/25300 (epoch 18.990), train_loss = 1.01125947, grad/param norm = 1.8380e-01, time/batch = 18.3873s	
9610/25300 (epoch 18.992), train_loss = 0.84259088, grad/param norm = 1.6533e-01, time/batch = 16.4610s	
9611/25300 (epoch 18.994), train_loss = 1.01948351, grad/param norm = 1.9845e-01, time/batch = 16.7227s	
9612/25300 (epoch 18.996), train_loss = 1.17790081, grad/param norm = 2.3078e-01, time/batch = 16.4892s	
9613/25300 (epoch 18.998), train_loss = 1.14499370, grad/param norm = 2.0940e-01, time/batch = 17.0584s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
9614/25300 (epoch 19.000), train_loss = 1.03580187, grad/param norm = 1.9897e-01, time/batch = 16.4826s	
9615/25300 (epoch 19.002), train_loss = 0.89533617, grad/param norm = 1.6957e-01, time/batch = 15.5527s	
9616/25300 (epoch 19.004), train_loss = 0.85180101, grad/param norm = 1.7233e-01, time/batch = 15.2697s	
9617/25300 (epoch 19.006), train_loss = 1.16129106, grad/param norm = 1.9379e-01, time/batch = 15.3067s	
9618/25300 (epoch 19.008), train_loss = 0.99110184, grad/param norm = 1.7131e-01, time/batch = 15.5524s	
9619/25300 (epoch 19.010), train_loss = 1.02155724, grad/param norm = 1.8423e-01, time/batch = 15.8883s	
9620/25300 (epoch 19.012), train_loss = 0.94743584, grad/param norm = 1.9648e-01, time/batch = 17.0627s	
9621/25300 (epoch 19.014), train_loss = 1.16234944, grad/param norm = 1.9588e-01, time/batch = 16.1217s	
9622/25300 (epoch 19.016), train_loss = 1.03972021, grad/param norm = 2.0256e-01, time/batch = 16.1331s	
9623/25300 (epoch 19.018), train_loss = 0.91361074, grad/param norm = 1.8885e-01, time/batch = 16.8138s	
9624/25300 (epoch 19.020), train_loss = 0.97823797, grad/param norm = 1.7856e-01, time/batch = 16.0209s	
9625/25300 (epoch 19.022), train_loss = 1.05792303, grad/param norm = 2.1909e-01, time/batch = 16.5653s	
9626/25300 (epoch 19.024), train_loss = 0.76013021, grad/param norm = 1.4639e-01, time/batch = 16.0707s	
9627/25300 (epoch 19.026), train_loss = 0.95394620, grad/param norm = 1.9639e-01, time/batch = 16.0668s	
9628/25300 (epoch 19.028), train_loss = 0.90909669, grad/param norm = 1.7703e-01, time/batch = 16.0549s	
9629/25300 (epoch 19.030), train_loss = 1.12738923, grad/param norm = 1.9919e-01, time/batch = 16.6471s	
9630/25300 (epoch 19.032), train_loss = 0.94800687, grad/param norm = 1.8319e-01, time/batch = 15.5577s	
9631/25300 (epoch 19.034), train_loss = 0.83802237, grad/param norm = 1.7533e-01, time/batch = 15.7338s	
9632/25300 (epoch 19.036), train_loss = 0.83955319, grad/param norm = 1.6310e-01, time/batch = 16.0510s	
9633/25300 (epoch 19.038), train_loss = 0.74728021, grad/param norm = 1.4929e-01, time/batch = 17.1338s	
9634/25300 (epoch 19.040), train_loss = 1.02572187, grad/param norm = 1.9363e-01, time/batch = 16.6379s	
9635/25300 (epoch 19.042), train_loss = 0.95634101, grad/param norm = 1.8237e-01, time/batch = 15.7119s	
9636/25300 (epoch 19.043), train_loss = 0.82421365, grad/param norm = 1.5585e-01, time/batch = 16.3092s	
9637/25300 (epoch 19.045), train_loss = 0.85585070, grad/param norm = 1.7070e-01, time/batch = 16.1462s	
9638/25300 (epoch 19.047), train_loss = 1.04218824, grad/param norm = 1.8040e-01, time/batch = 16.4743s	
9639/25300 (epoch 19.049), train_loss = 1.01549072, grad/param norm = 1.9761e-01, time/batch = 15.6306s	
9640/25300 (epoch 19.051), train_loss = 1.09381451, grad/param norm = 2.0670e-01, time/batch = 15.8832s	
9641/25300 (epoch 19.053), train_loss = 0.80623205, grad/param norm = 1.6455e-01, time/batch = 17.8795s	
9642/25300 (epoch 19.055), train_loss = 0.87095367, grad/param norm = 1.7149e-01, time/batch = 16.7308s	
9643/25300 (epoch 19.057), train_loss = 0.82854793, grad/param norm = 1.6137e-01, time/batch = 16.1813s	
9644/25300 (epoch 19.059), train_loss = 0.92802415, grad/param norm = 1.7196e-01, time/batch = 17.1456s	
9645/25300 (epoch 19.061), train_loss = 0.91212530, grad/param norm = 1.9566e-01, time/batch = 17.3078s	
9646/25300 (epoch 19.063), train_loss = 0.87779003, grad/param norm = 1.7806e-01, time/batch = 17.0499s	
9647/25300 (epoch 19.065), train_loss = 1.04818198, grad/param norm = 1.9581e-01, time/batch = 16.1448s	
9648/25300 (epoch 19.067), train_loss = 1.09667197, grad/param norm = 1.8499e-01, time/batch = 16.1479s	
9649/25300 (epoch 19.069), train_loss = 0.94998946, grad/param norm = 1.8760e-01, time/batch = 17.2915s	
9650/25300 (epoch 19.071), train_loss = 1.11562064, grad/param norm = 2.0141e-01, time/batch = 16.3757s	
9651/25300 (epoch 19.073), train_loss = 0.92236581, grad/param norm = 1.6336e-01, time/batch = 16.6332s	
9652/25300 (epoch 19.075), train_loss = 1.05924994, grad/param norm = 1.9354e-01, time/batch = 16.0435s	
9653/25300 (epoch 19.077), train_loss = 1.01421104, grad/param norm = 2.0265e-01, time/batch = 16.4536s	
9654/25300 (epoch 19.079), train_loss = 0.96632822, grad/param norm = 2.0577e-01, time/batch = 16.3123s	
9655/25300 (epoch 19.081), train_loss = 0.96085123, grad/param norm = 1.7045e-01, time/batch = 16.7175s	
9656/25300 (epoch 19.083), train_loss = 0.97046224, grad/param norm = 1.7182e-01, time/batch = 17.7994s	
9657/25300 (epoch 19.085), train_loss = 1.20905507, grad/param norm = 2.2652e-01, time/batch = 15.7872s	
9658/25300 (epoch 19.087), train_loss = 1.06420608, grad/param norm = 1.8338e-01, time/batch = 16.6345s	
9659/25300 (epoch 19.089), train_loss = 1.04970357, grad/param norm = 2.0207e-01, time/batch = 16.7218s	
9660/25300 (epoch 19.091), train_loss = 1.18046300, grad/param norm = 2.0502e-01, time/batch = 17.2219s	
9661/25300 (epoch 19.093), train_loss = 1.11063316, grad/param norm = 1.9985e-01, time/batch = 16.1158s	
9662/25300 (epoch 19.095), train_loss = 1.08913155, grad/param norm = 1.9762e-01, time/batch = 16.7258s	
9663/25300 (epoch 19.097), train_loss = 1.03391475, grad/param norm = 1.7956e-01, time/batch = 17.9649s	
9664/25300 (epoch 19.099), train_loss = 1.05411925, grad/param norm = 1.9492e-01, time/batch = 17.5399s	
9665/25300 (epoch 19.101), train_loss = 0.97110613, grad/param norm = 1.8973e-01, time/batch = 16.5522s	
9666/25300 (epoch 19.103), train_loss = 1.01151139, grad/param norm = 1.8737e-01, time/batch = 16.7150s	
9667/25300 (epoch 19.105), train_loss = 1.06013487, grad/param norm = 1.7648e-01, time/batch = 16.1510s	
9668/25300 (epoch 19.107), train_loss = 1.09385844, grad/param norm = 2.1292e-01, time/batch = 16.0509s	
9669/25300 (epoch 19.109), train_loss = 0.98524019, grad/param norm = 2.0048e-01, time/batch = 17.0610s	
9670/25300 (epoch 19.111), train_loss = 0.98904711, grad/param norm = 1.7801e-01, time/batch = 15.9010s	
9671/25300 (epoch 19.113), train_loss = 0.94971156, grad/param norm = 1.9778e-01, time/batch = 16.8077s	
9672/25300 (epoch 19.115), train_loss = 0.98436518, grad/param norm = 1.9472e-01, time/batch = 16.4630s	
9673/25300 (epoch 19.117), train_loss = 1.05536137, grad/param norm = 1.7453e-01, time/batch = 16.1388s	
9674/25300 (epoch 19.119), train_loss = 0.96404439, grad/param norm = 1.9115e-01, time/batch = 15.4638s	
9675/25300 (epoch 19.121), train_loss = 1.03402410, grad/param norm = 1.9560e-01, time/batch = 15.7209s	
9676/25300 (epoch 19.123), train_loss = 0.97514313, grad/param norm = 2.1738e-01, time/batch = 15.7403s	
9677/25300 (epoch 19.125), train_loss = 1.09627494, grad/param norm = 2.2585e-01, time/batch = 16.4749s	
9678/25300 (epoch 19.126), train_loss = 0.99258133, grad/param norm = 2.2681e-01, time/batch = 16.8868s	
9679/25300 (epoch 19.128), train_loss = 0.99624182, grad/param norm = 1.9343e-01, time/batch = 15.5356s	
9680/25300 (epoch 19.130), train_loss = 0.81297521, grad/param norm = 1.5450e-01, time/batch = 16.8067s	
9681/25300 (epoch 19.132), train_loss = 0.83057675, grad/param norm = 1.7337e-01, time/batch = 16.7163s	
9682/25300 (epoch 19.134), train_loss = 0.81346073, grad/param norm = 1.6332e-01, time/batch = 16.4654s	
9683/25300 (epoch 19.136), train_loss = 0.98924939, grad/param norm = 1.8141e-01, time/batch = 17.9754s	
9684/25300 (epoch 19.138), train_loss = 0.86085701, grad/param norm = 1.7310e-01, time/batch = 16.6272s	
9685/25300 (epoch 19.140), train_loss = 0.92146978, grad/param norm = 1.7349e-01, time/batch = 15.9646s	
9686/25300 (epoch 19.142), train_loss = 1.09493861, grad/param norm = 1.8961e-01, time/batch = 15.7992s	
9687/25300 (epoch 19.144), train_loss = 1.06793541, grad/param norm = 1.9238e-01, time/batch = 16.9860s	
9688/25300 (epoch 19.146), train_loss = 1.05138111, grad/param norm = 2.1710e-01, time/batch = 16.5718s	
9689/25300 (epoch 19.148), train_loss = 0.98733615, grad/param norm = 1.9381e-01, time/batch = 16.4522s	
9690/25300 (epoch 19.150), train_loss = 1.11487849, grad/param norm = 2.1132e-01, time/batch = 15.7372s	
9691/25300 (epoch 19.152), train_loss = 1.16897344, grad/param norm = 2.1260e-01, time/batch = 16.6472s	
9692/25300 (epoch 19.154), train_loss = 0.85277459, grad/param norm = 1.6848e-01, time/batch = 16.9869s	
9693/25300 (epoch 19.156), train_loss = 1.07455491, grad/param norm = 2.4332e-01, time/batch = 16.3874s	
9694/25300 (epoch 19.158), train_loss = 0.89521806, grad/param norm = 1.9082e-01, time/batch = 16.8067s	
9695/25300 (epoch 19.160), train_loss = 0.98075266, grad/param norm = 1.7586e-01, time/batch = 16.8121s	
9696/25300 (epoch 19.162), train_loss = 0.93599719, grad/param norm = 1.8927e-01, time/batch = 17.2323s	
9697/25300 (epoch 19.164), train_loss = 1.05528150, grad/param norm = 1.8385e-01, time/batch = 27.9636s	
9698/25300 (epoch 19.166), train_loss = 0.99998254, grad/param norm = 1.7464e-01, time/batch = 15.2326s	
9699/25300 (epoch 19.168), train_loss = 0.87651124, grad/param norm = 1.5430e-01, time/batch = 15.5243s	
9700/25300 (epoch 19.170), train_loss = 0.97023899, grad/param norm = 1.8664e-01, time/batch = 15.4908s	
9701/25300 (epoch 19.172), train_loss = 0.88391652, grad/param norm = 1.7328e-01, time/batch = 15.4204s	
9702/25300 (epoch 19.174), train_loss = 0.87769870, grad/param norm = 1.8291e-01, time/batch = 15.0397s	
9703/25300 (epoch 19.176), train_loss = 0.91799739, grad/param norm = 1.9606e-01, time/batch = 15.0911s	
9704/25300 (epoch 19.178), train_loss = 1.10276229, grad/param norm = 1.8938e-01, time/batch = 15.3466s	
9705/25300 (epoch 19.180), train_loss = 0.79758513, grad/param norm = 1.5730e-01, time/batch = 17.2090s	
9706/25300 (epoch 19.182), train_loss = 0.94439981, grad/param norm = 2.0806e-01, time/batch = 16.6947s	
9707/25300 (epoch 19.184), train_loss = 0.94448767, grad/param norm = 1.9692e-01, time/batch = 15.8132s	
9708/25300 (epoch 19.186), train_loss = 0.91035003, grad/param norm = 1.8926e-01, time/batch = 15.1943s	
9709/25300 (epoch 19.188), train_loss = 1.00249350, grad/param norm = 1.9462e-01, time/batch = 15.7823s	
9710/25300 (epoch 19.190), train_loss = 0.94008456, grad/param norm = 1.8018e-01, time/batch = 15.8625s	
9711/25300 (epoch 19.192), train_loss = 0.95732945, grad/param norm = 1.9774e-01, time/batch = 15.7883s	
9712/25300 (epoch 19.194), train_loss = 0.97462022, grad/param norm = 1.9550e-01, time/batch = 16.6966s	
9713/25300 (epoch 19.196), train_loss = 1.06691604, grad/param norm = 2.2382e-01, time/batch = 16.8650s	
9714/25300 (epoch 19.198), train_loss = 0.92446954, grad/param norm = 1.9668e-01, time/batch = 15.7988s	
9715/25300 (epoch 19.200), train_loss = 0.97587580, grad/param norm = 1.9421e-01, time/batch = 16.3491s	
9716/25300 (epoch 19.202), train_loss = 0.97703089, grad/param norm = 2.0400e-01, time/batch = 16.1180s	
9717/25300 (epoch 19.204), train_loss = 0.94633065, grad/param norm = 1.7900e-01, time/batch = 16.2948s	
9718/25300 (epoch 19.206), train_loss = 1.05235696, grad/param norm = 1.8246e-01, time/batch = 16.6207s	
9719/25300 (epoch 19.208), train_loss = 0.86974482, grad/param norm = 1.9262e-01, time/batch = 16.1962s	
9720/25300 (epoch 19.209), train_loss = 0.82557014, grad/param norm = 1.7654e-01, time/batch = 16.3137s	
9721/25300 (epoch 19.211), train_loss = 0.93179876, grad/param norm = 1.7713e-01, time/batch = 15.9790s	
9722/25300 (epoch 19.213), train_loss = 1.01554998, grad/param norm = 1.9100e-01, time/batch = 15.3887s	
9723/25300 (epoch 19.215), train_loss = 0.99981313, grad/param norm = 1.9704e-01, time/batch = 16.4014s	
9724/25300 (epoch 19.217), train_loss = 1.00534633, grad/param norm = 1.9997e-01, time/batch = 15.6283s	
9725/25300 (epoch 19.219), train_loss = 1.08857819, grad/param norm = 1.9902e-01, time/batch = 17.1982s	
9726/25300 (epoch 19.221), train_loss = 1.13442662, grad/param norm = 2.0356e-01, time/batch = 16.2218s	
9727/25300 (epoch 19.223), train_loss = 1.04197062, grad/param norm = 2.1809e-01, time/batch = 16.5671s	
9728/25300 (epoch 19.225), train_loss = 1.40780953, grad/param norm = 3.3425e-01, time/batch = 15.8852s	
9729/25300 (epoch 19.227), train_loss = 1.12765839, grad/param norm = 2.1781e-01, time/batch = 16.7096s	
9730/25300 (epoch 19.229), train_loss = 0.99689732, grad/param norm = 1.7852e-01, time/batch = 16.2076s	
9731/25300 (epoch 19.231), train_loss = 0.97774055, grad/param norm = 2.0049e-01, time/batch = 16.2861s	
9732/25300 (epoch 19.233), train_loss = 1.06954688, grad/param norm = 1.9264e-01, time/batch = 16.9666s	
9733/25300 (epoch 19.235), train_loss = 0.97725077, grad/param norm = 1.7752e-01, time/batch = 17.0389s	
9734/25300 (epoch 19.237), train_loss = 1.16519383, grad/param norm = 2.1081e-01, time/batch = 16.5280s	
9735/25300 (epoch 19.239), train_loss = 0.99101494, grad/param norm = 1.8463e-01, time/batch = 15.3783s	
9736/25300 (epoch 19.241), train_loss = 1.13279852, grad/param norm = 1.9565e-01, time/batch = 16.2362s	
9737/25300 (epoch 19.243), train_loss = 1.30206897, grad/param norm = 2.1929e-01, time/batch = 15.8875s	
9738/25300 (epoch 19.245), train_loss = 0.93331880, grad/param norm = 1.8542e-01, time/batch = 15.9059s	
9739/25300 (epoch 19.247), train_loss = 1.07588891, grad/param norm = 1.7792e-01, time/batch = 15.9826s	
9740/25300 (epoch 19.249), train_loss = 0.86134538, grad/param norm = 1.6463e-01, time/batch = 15.8115s	
9741/25300 (epoch 19.251), train_loss = 0.83599705, grad/param norm = 1.6950e-01, time/batch = 17.0575s	
9742/25300 (epoch 19.253), train_loss = 0.95528798, grad/param norm = 1.8703e-01, time/batch = 16.8765s	
9743/25300 (epoch 19.255), train_loss = 0.94642950, grad/param norm = 2.1019e-01, time/batch = 16.1569s	
9744/25300 (epoch 19.257), train_loss = 1.01923976, grad/param norm = 2.0662e-01, time/batch = 15.9657s	
9745/25300 (epoch 19.259), train_loss = 1.23144563, grad/param norm = 2.4232e-01, time/batch = 16.7873s	
9746/25300 (epoch 19.261), train_loss = 1.15813164, grad/param norm = 2.1429e-01, time/batch = 16.9738s	
9747/25300 (epoch 19.263), train_loss = 1.14192111, grad/param norm = 1.9935e-01, time/batch = 16.7933s	
9748/25300 (epoch 19.265), train_loss = 1.18578805, grad/param norm = 2.0633e-01, time/batch = 16.5514s	
9749/25300 (epoch 19.267), train_loss = 1.10201516, grad/param norm = 2.0234e-01, time/batch = 17.1412s	
9750/25300 (epoch 19.269), train_loss = 0.83936722, grad/param norm = 1.6337e-01, time/batch = 16.0550s	
9751/25300 (epoch 19.271), train_loss = 0.97195423, grad/param norm = 1.8883e-01, time/batch = 16.7911s	
9752/25300 (epoch 19.273), train_loss = 1.07424200, grad/param norm = 2.0857e-01, time/batch = 16.4639s	
9753/25300 (epoch 19.275), train_loss = 0.96389266, grad/param norm = 1.6371e-01, time/batch = 15.7167s	
9754/25300 (epoch 19.277), train_loss = 0.97236290, grad/param norm = 2.3921e-01, time/batch = 17.2190s	
9755/25300 (epoch 19.279), train_loss = 0.98603474, grad/param norm = 1.8136e-01, time/batch = 16.4536s	
9756/25300 (epoch 19.281), train_loss = 1.17326212, grad/param norm = 2.1748e-01, time/batch = 16.1362s	
9757/25300 (epoch 19.283), train_loss = 0.88298955, grad/param norm = 1.6457e-01, time/batch = 17.7059s	
9758/25300 (epoch 19.285), train_loss = 1.04322744, grad/param norm = 2.0318e-01, time/batch = 15.3774s	
9759/25300 (epoch 19.287), train_loss = 1.05379014, grad/param norm = 1.8623e-01, time/batch = 15.7902s	
9760/25300 (epoch 19.289), train_loss = 0.96131059, grad/param norm = 1.7084e-01, time/batch = 16.3017s	
9761/25300 (epoch 19.291), train_loss = 0.96296611, grad/param norm = 1.7580e-01, time/batch = 15.7347s	
9762/25300 (epoch 19.292), train_loss = 1.14975714, grad/param norm = 1.8650e-01, time/batch = 15.7293s	
9763/25300 (epoch 19.294), train_loss = 1.03053416, grad/param norm = 1.9076e-01, time/batch = 15.3948s	
9764/25300 (epoch 19.296), train_loss = 0.89791419, grad/param norm = 2.0154e-01, time/batch = 16.3133s	
9765/25300 (epoch 19.298), train_loss = 1.08700541, grad/param norm = 2.0739e-01, time/batch = 16.7317s	
9766/25300 (epoch 19.300), train_loss = 1.11558626, grad/param norm = 2.1474e-01, time/batch = 15.9595s	
9767/25300 (epoch 19.302), train_loss = 0.83022354, grad/param norm = 1.8547e-01, time/batch = 16.4818s	
9768/25300 (epoch 19.304), train_loss = 1.09232018, grad/param norm = 1.9587e-01, time/batch = 16.4875s	
9769/25300 (epoch 19.306), train_loss = 0.78808170, grad/param norm = 1.7017e-01, time/batch = 15.1397s	
9770/25300 (epoch 19.308), train_loss = 1.05234234, grad/param norm = 1.8064e-01, time/batch = 15.8009s	
9771/25300 (epoch 19.310), train_loss = 0.90883375, grad/param norm = 1.9015e-01, time/batch = 16.3863s	
9772/25300 (epoch 19.312), train_loss = 1.00745117, grad/param norm = 1.7904e-01, time/batch = 16.9745s	
9773/25300 (epoch 19.314), train_loss = 0.83004926, grad/param norm = 1.7790e-01, time/batch = 16.4653s	
9774/25300 (epoch 19.316), train_loss = 1.01818308, grad/param norm = 1.7729e-01, time/batch = 16.2393s	
9775/25300 (epoch 19.318), train_loss = 0.80992496, grad/param norm = 1.7809e-01, time/batch = 17.6419s	
9776/25300 (epoch 19.320), train_loss = 0.88016791, grad/param norm = 1.7928e-01, time/batch = 16.6317s	
9777/25300 (epoch 19.322), train_loss = 1.18815602, grad/param norm = 2.0989e-01, time/batch = 15.7184s	
9778/25300 (epoch 19.324), train_loss = 0.88995302, grad/param norm = 1.6521e-01, time/batch = 17.9653s	
9779/25300 (epoch 19.326), train_loss = 0.79715958, grad/param norm = 1.5990e-01, time/batch = 16.3775s	
9780/25300 (epoch 19.328), train_loss = 0.80243876, grad/param norm = 1.9816e-01, time/batch = 16.2137s	
9781/25300 (epoch 19.330), train_loss = 0.96043959, grad/param norm = 1.9454e-01, time/batch = 16.6259s	
9782/25300 (epoch 19.332), train_loss = 0.99330250, grad/param norm = 1.8029e-01, time/batch = 17.5415s	
9783/25300 (epoch 19.334), train_loss = 0.82885078, grad/param norm = 1.7220e-01, time/batch = 17.3030s	
9784/25300 (epoch 19.336), train_loss = 0.83780060, grad/param norm = 1.7616e-01, time/batch = 15.7276s	
9785/25300 (epoch 19.338), train_loss = 0.84242778, grad/param norm = 1.7920e-01, time/batch = 17.1383s	
9786/25300 (epoch 19.340), train_loss = 0.90751000, grad/param norm = 1.8760e-01, time/batch = 17.8756s	
9787/25300 (epoch 19.342), train_loss = 0.92366125, grad/param norm = 1.9872e-01, time/batch = 18.5867s	
9788/25300 (epoch 19.344), train_loss = 0.98826259, grad/param norm = 1.6971e-01, time/batch = 18.5972s	
9789/25300 (epoch 19.346), train_loss = 0.95661505, grad/param norm = 2.2760e-01, time/batch = 17.3923s	
9790/25300 (epoch 19.348), train_loss = 0.84274968, grad/param norm = 1.6704e-01, time/batch = 18.3598s	
9791/25300 (epoch 19.350), train_loss = 0.93615290, grad/param norm = 1.8357e-01, time/batch = 19.4340s	
9792/25300 (epoch 19.352), train_loss = 0.97332475, grad/param norm = 1.7067e-01, time/batch = 20.1838s	
9793/25300 (epoch 19.354), train_loss = 0.90359280, grad/param norm = 1.8277e-01, time/batch = 21.9970s	
9794/25300 (epoch 19.356), train_loss = 0.95532066, grad/param norm = 1.8907e-01, time/batch = 20.8576s	
9795/25300 (epoch 19.358), train_loss = 1.05206428, grad/param norm = 2.0895e-01, time/batch = 20.2918s	
9796/25300 (epoch 19.360), train_loss = 0.89034454, grad/param norm = 1.8142e-01, time/batch = 19.3012s	
9797/25300 (epoch 19.362), train_loss = 0.91128377, grad/param norm = 1.8155e-01, time/batch = 19.0699s	
9798/25300 (epoch 19.364), train_loss = 0.92786708, grad/param norm = 1.9088e-01, time/batch = 20.0078s	
9799/25300 (epoch 19.366), train_loss = 0.83255276, grad/param norm = 1.7483e-01, time/batch = 27.0001s	
9800/25300 (epoch 19.368), train_loss = 0.93006821, grad/param norm = 1.6822e-01, time/batch = 16.9654s	
9801/25300 (epoch 19.370), train_loss = 0.90787515, grad/param norm = 2.1018e-01, time/batch = 16.4804s	
9802/25300 (epoch 19.372), train_loss = 0.91724925, grad/param norm = 1.7893e-01, time/batch = 16.0635s	
9803/25300 (epoch 19.374), train_loss = 0.85730516, grad/param norm = 1.9363e-01, time/batch = 15.6685s	
9804/25300 (epoch 19.375), train_loss = 1.10198785, grad/param norm = 2.1161e-01, time/batch = 15.3744s	
9805/25300 (epoch 19.377), train_loss = 1.01119233, grad/param norm = 2.0131e-01, time/batch = 15.6251s	
9806/25300 (epoch 19.379), train_loss = 0.98866834, grad/param norm = 1.8346e-01, time/batch = 15.1641s	
9807/25300 (epoch 19.381), train_loss = 0.96001113, grad/param norm = 1.8332e-01, time/batch = 14.8801s	
9808/25300 (epoch 19.383), train_loss = 0.87555726, grad/param norm = 1.7140e-01, time/batch = 15.1311s	
9809/25300 (epoch 19.385), train_loss = 0.97005359, grad/param norm = 1.7801e-01, time/batch = 17.0355s	
9810/25300 (epoch 19.387), train_loss = 1.00162335, grad/param norm = 1.8815e-01, time/batch = 15.8066s	
9811/25300 (epoch 19.389), train_loss = 1.03204166, grad/param norm = 1.9892e-01, time/batch = 16.6203s	
9812/25300 (epoch 19.391), train_loss = 0.89500721, grad/param norm = 1.6745e-01, time/batch = 17.1327s	
9813/25300 (epoch 19.393), train_loss = 1.00176187, grad/param norm = 2.2506e-01, time/batch = 16.8872s	
9814/25300 (epoch 19.395), train_loss = 0.81871550, grad/param norm = 1.6240e-01, time/batch = 16.2108s	
9815/25300 (epoch 19.397), train_loss = 0.85556357, grad/param norm = 1.9900e-01, time/batch = 16.8105s	
9816/25300 (epoch 19.399), train_loss = 0.83596379, grad/param norm = 1.7837e-01, time/batch = 16.8125s	
9817/25300 (epoch 19.401), train_loss = 1.05626063, grad/param norm = 2.0713e-01, time/batch = 17.3746s	
9818/25300 (epoch 19.403), train_loss = 0.96915628, grad/param norm = 2.0631e-01, time/batch = 17.3088s	
9819/25300 (epoch 19.405), train_loss = 0.96771109, grad/param norm = 1.9574e-01, time/batch = 16.3127s	
9820/25300 (epoch 19.407), train_loss = 0.92606765, grad/param norm = 1.8056e-01, time/batch = 16.5466s	
9821/25300 (epoch 19.409), train_loss = 0.88067136, grad/param norm = 1.7092e-01, time/batch = 16.7849s	
9822/25300 (epoch 19.411), train_loss = 0.88288783, grad/param norm = 1.8289e-01, time/batch = 17.0615s	
9823/25300 (epoch 19.413), train_loss = 0.80949335, grad/param norm = 1.6841e-01, time/batch = 15.8963s	
9824/25300 (epoch 19.415), train_loss = 0.84433611, grad/param norm = 1.8177e-01, time/batch = 16.2261s	
9825/25300 (epoch 19.417), train_loss = 0.81009311, grad/param norm = 1.6898e-01, time/batch = 15.7068s	
9826/25300 (epoch 19.419), train_loss = 0.75426041, grad/param norm = 1.6499e-01, time/batch = 17.2229s	
9827/25300 (epoch 19.421), train_loss = 0.82626993, grad/param norm = 1.5938e-01, time/batch = 16.8051s	
9828/25300 (epoch 19.423), train_loss = 0.84035444, grad/param norm = 1.8203e-01, time/batch = 17.3798s	
9829/25300 (epoch 19.425), train_loss = 0.93707138, grad/param norm = 2.2226e-01, time/batch = 16.3124s	
9830/25300 (epoch 19.427), train_loss = 1.12674869, grad/param norm = 2.1329e-01, time/batch = 15.3820s	
9831/25300 (epoch 19.429), train_loss = 1.05111933, grad/param norm = 1.9324e-01, time/batch = 16.5608s	
9832/25300 (epoch 19.431), train_loss = 1.01347358, grad/param norm = 1.9274e-01, time/batch = 16.0438s	
9833/25300 (epoch 19.433), train_loss = 0.94412589, grad/param norm = 1.7063e-01, time/batch = 16.5568s	
9834/25300 (epoch 19.435), train_loss = 0.88157987, grad/param norm = 1.8751e-01, time/batch = 18.0577s	
9835/25300 (epoch 19.437), train_loss = 0.91742678, grad/param norm = 1.9157e-01, time/batch = 16.0309s	
9836/25300 (epoch 19.439), train_loss = 0.98638242, grad/param norm = 1.8530e-01, time/batch = 15.7364s	
9837/25300 (epoch 19.441), train_loss = 1.01938140, grad/param norm = 2.0322e-01, time/batch = 17.0648s	
9838/25300 (epoch 19.443), train_loss = 1.20246765, grad/param norm = 2.2351e-01, time/batch = 17.6465s	
9839/25300 (epoch 19.445), train_loss = 1.14847854, grad/param norm = 2.2971e-01, time/batch = 15.5115s	
9840/25300 (epoch 19.447), train_loss = 0.86983001, grad/param norm = 1.6172e-01, time/batch = 16.4494s	
9841/25300 (epoch 19.449), train_loss = 0.79140553, grad/param norm = 1.7406e-01, time/batch = 16.2210s	
9842/25300 (epoch 19.451), train_loss = 1.17579930, grad/param norm = 2.1183e-01, time/batch = 17.3843s	
9843/25300 (epoch 19.453), train_loss = 1.04773513, grad/param norm = 2.3471e-01, time/batch = 16.5500s	
9844/25300 (epoch 19.455), train_loss = 1.04949543, grad/param norm = 2.0935e-01, time/batch = 17.7889s	
9845/25300 (epoch 19.457), train_loss = 0.91676707, grad/param norm = 1.9071e-01, time/batch = 16.3773s	
9846/25300 (epoch 19.458), train_loss = 0.94222224, grad/param norm = 1.8684e-01, time/batch = 15.7137s	
9847/25300 (epoch 19.460), train_loss = 0.97110916, grad/param norm = 1.9175e-01, time/batch = 15.2968s	
9848/25300 (epoch 19.462), train_loss = 0.73572403, grad/param norm = 1.8455e-01, time/batch = 16.7983s	
9849/25300 (epoch 19.464), train_loss = 1.04624756, grad/param norm = 2.0716e-01, time/batch = 15.8023s	
9850/25300 (epoch 19.466), train_loss = 1.02928416, grad/param norm = 1.9062e-01, time/batch = 15.3953s	
9851/25300 (epoch 19.468), train_loss = 1.04713618, grad/param norm = 2.1586e-01, time/batch = 17.5650s	
9852/25300 (epoch 19.470), train_loss = 0.91783768, grad/param norm = 1.8690e-01, time/batch = 16.9774s	
9853/25300 (epoch 19.472), train_loss = 0.82882857, grad/param norm = 1.6792e-01, time/batch = 16.0609s	
9854/25300 (epoch 19.474), train_loss = 0.98210326, grad/param norm = 1.8806e-01, time/batch = 15.9017s	
9855/25300 (epoch 19.476), train_loss = 0.93419488, grad/param norm = 1.9506e-01, time/batch = 15.4891s	
9856/25300 (epoch 19.478), train_loss = 1.02673994, grad/param norm = 2.1387e-01, time/batch = 16.6463s	
9857/25300 (epoch 19.480), train_loss = 0.88959246, grad/param norm = 1.7186e-01, time/batch = 16.3787s	
9858/25300 (epoch 19.482), train_loss = 1.04044845, grad/param norm = 2.1641e-01, time/batch = 15.5415s	
9859/25300 (epoch 19.484), train_loss = 1.04364421, grad/param norm = 2.0893e-01, time/batch = 15.0378s	
9860/25300 (epoch 19.486), train_loss = 0.96399483, grad/param norm = 1.8495e-01, time/batch = 15.1230s	
9861/25300 (epoch 19.488), train_loss = 1.11690792, grad/param norm = 2.0298e-01, time/batch = 15.3449s	
9862/25300 (epoch 19.490), train_loss = 1.02270985, grad/param norm = 1.9043e-01, time/batch = 15.1118s	
9863/25300 (epoch 19.492), train_loss = 0.98713842, grad/param norm = 1.8402e-01, time/batch = 15.1118s	
9864/25300 (epoch 19.494), train_loss = 0.90486333, grad/param norm = 1.7577e-01, time/batch = 15.0266s	
9865/25300 (epoch 19.496), train_loss = 0.96911132, grad/param norm = 1.8522e-01, time/batch = 15.2480s	
9866/25300 (epoch 19.498), train_loss = 0.89414692, grad/param norm = 1.8045e-01, time/batch = 15.2186s	
9867/25300 (epoch 19.500), train_loss = 1.09188022, grad/param norm = 2.0862e-01, time/batch = 16.3716s	
9868/25300 (epoch 19.502), train_loss = 1.00414623, grad/param norm = 2.0446e-01, time/batch = 15.7216s	
9869/25300 (epoch 19.504), train_loss = 0.93256306, grad/param norm = 1.9414e-01, time/batch = 15.1163s	
9870/25300 (epoch 19.506), train_loss = 0.88491124, grad/param norm = 1.8734e-01, time/batch = 15.3678s	
9871/25300 (epoch 19.508), train_loss = 0.97069413, grad/param norm = 2.1086e-01, time/batch = 15.3076s	
9872/25300 (epoch 19.510), train_loss = 0.89309677, grad/param norm = 1.8149e-01, time/batch = 17.0593s	
9873/25300 (epoch 19.512), train_loss = 0.73877015, grad/param norm = 1.7991e-01, time/batch = 15.8929s	
9874/25300 (epoch 19.514), train_loss = 0.94502370, grad/param norm = 1.7179e-01, time/batch = 16.2224s	
9875/25300 (epoch 19.516), train_loss = 1.00918754, grad/param norm = 1.8850e-01, time/batch = 16.1492s	
9876/25300 (epoch 19.518), train_loss = 1.06574381, grad/param norm = 2.2604e-01, time/batch = 15.6201s	
9877/25300 (epoch 19.520), train_loss = 0.80535457, grad/param norm = 1.6651e-01, time/batch = 15.4650s	
9878/25300 (epoch 19.522), train_loss = 0.89784320, grad/param norm = 1.8123e-01, time/batch = 15.9636s	
9879/25300 (epoch 19.524), train_loss = 0.91932639, grad/param norm = 1.8029e-01, time/batch = 16.4828s	
9880/25300 (epoch 19.526), train_loss = 1.13743788, grad/param norm = 2.1597e-01, time/batch = 15.9610s	
9881/25300 (epoch 19.528), train_loss = 1.12161308, grad/param norm = 2.0177e-01, time/batch = 15.4715s	
9882/25300 (epoch 19.530), train_loss = 0.97569236, grad/param norm = 1.8089e-01, time/batch = 16.3042s	
9883/25300 (epoch 19.532), train_loss = 0.96183422, grad/param norm = 1.7955e-01, time/batch = 17.2182s	
9884/25300 (epoch 19.534), train_loss = 0.94983919, grad/param norm = 2.0665e-01, time/batch = 15.8165s	
9885/25300 (epoch 19.536), train_loss = 0.77185955, grad/param norm = 1.5276e-01, time/batch = 17.3090s	
9886/25300 (epoch 19.538), train_loss = 0.82120159, grad/param norm = 1.5012e-01, time/batch = 15.8079s	
9887/25300 (epoch 19.540), train_loss = 0.88317995, grad/param norm = 1.8867e-01, time/batch = 16.6337s	
9888/25300 (epoch 19.542), train_loss = 0.85184522, grad/param norm = 1.6333e-01, time/batch = 16.5514s	
9889/25300 (epoch 19.543), train_loss = 0.82943007, grad/param norm = 1.8519e-01, time/batch = 15.8706s	
9890/25300 (epoch 19.545), train_loss = 1.23978416, grad/param norm = 2.4990e-01, time/batch = 16.3456s	
9891/25300 (epoch 19.547), train_loss = 1.02380005, grad/param norm = 1.9910e-01, time/batch = 15.6348s	
9892/25300 (epoch 19.549), train_loss = 1.21225209, grad/param norm = 2.2124e-01, time/batch = 16.8109s	
9893/25300 (epoch 19.551), train_loss = 1.04586680, grad/param norm = 1.9500e-01, time/batch = 16.2303s	
9894/25300 (epoch 19.553), train_loss = 0.90749025, grad/param norm = 2.0057e-01, time/batch = 16.5611s	
9895/25300 (epoch 19.555), train_loss = 1.07415189, grad/param norm = 2.2860e-01, time/batch = 15.6093s	
9896/25300 (epoch 19.557), train_loss = 1.09576363, grad/param norm = 1.9862e-01, time/batch = 17.6166s	
9897/25300 (epoch 19.559), train_loss = 1.06086671, grad/param norm = 1.9894e-01, time/batch = 15.9727s	
9898/25300 (epoch 19.561), train_loss = 1.12485803, grad/param norm = 2.1744e-01, time/batch = 16.5328s	
9899/25300 (epoch 19.563), train_loss = 1.07219267, grad/param norm = 2.0562e-01, time/batch = 16.1865s	
9900/25300 (epoch 19.565), train_loss = 0.83938388, grad/param norm = 1.7579e-01, time/batch = 17.0491s	
9901/25300 (epoch 19.567), train_loss = 0.72938251, grad/param norm = 1.6616e-01, time/batch = 17.8003s	
9902/25300 (epoch 19.569), train_loss = 0.95321269, grad/param norm = 1.8875e-01, time/batch = 16.0601s	
9903/25300 (epoch 19.571), train_loss = 1.05216505, grad/param norm = 2.1257e-01, time/batch = 17.3979s	
9904/25300 (epoch 19.573), train_loss = 0.97187814, grad/param norm = 1.8774e-01, time/batch = 17.3891s	
9905/25300 (epoch 19.575), train_loss = 1.09558471, grad/param norm = 1.9585e-01, time/batch = 16.6431s	
9906/25300 (epoch 19.577), train_loss = 0.98838879, grad/param norm = 2.1154e-01, time/batch = 16.1371s	
9907/25300 (epoch 19.579), train_loss = 1.12908150, grad/param norm = 2.0797e-01, time/batch = 18.4729s	
9908/25300 (epoch 19.581), train_loss = 1.03738276, grad/param norm = 2.0193e-01, time/batch = 16.8045s	
9909/25300 (epoch 19.583), train_loss = 0.81500322, grad/param norm = 1.8694e-01, time/batch = 16.5492s	
9910/25300 (epoch 19.585), train_loss = 0.81927083, grad/param norm = 1.8586e-01, time/batch = 16.2374s	
9911/25300 (epoch 19.587), train_loss = 0.92958910, grad/param norm = 1.8133e-01, time/batch = 18.7156s	
9912/25300 (epoch 19.589), train_loss = 0.84628349, grad/param norm = 1.6828e-01, time/batch = 16.1229s	
9913/25300 (epoch 19.591), train_loss = 0.84474371, grad/param norm = 1.9776e-01, time/batch = 24.3416s	
9914/25300 (epoch 19.593), train_loss = 1.04149416, grad/param norm = 1.9700e-01, time/batch = 23.6327s	
9915/25300 (epoch 19.595), train_loss = 0.96306254, grad/param norm = 2.1762e-01, time/batch = 16.7342s	
9916/25300 (epoch 19.597), train_loss = 0.81800641, grad/param norm = 1.6615e-01, time/batch = 15.6211s	
9917/25300 (epoch 19.599), train_loss = 0.99964961, grad/param norm = 1.9793e-01, time/batch = 16.4060s	
9918/25300 (epoch 19.601), train_loss = 0.97341207, grad/param norm = 1.8634e-01, time/batch = 17.7152s	
9919/25300 (epoch 19.603), train_loss = 0.97625318, grad/param norm = 1.9172e-01, time/batch = 16.1386s	
9920/25300 (epoch 19.605), train_loss = 0.88252044, grad/param norm = 1.8822e-01, time/batch = 16.5547s	
9921/25300 (epoch 19.607), train_loss = 0.72165958, grad/param norm = 1.5829e-01, time/batch = 17.6407s	
9922/25300 (epoch 19.609), train_loss = 0.93205567, grad/param norm = 1.7456e-01, time/batch = 15.5404s	
9923/25300 (epoch 19.611), train_loss = 0.99632035, grad/param norm = 1.9669e-01, time/batch = 17.3792s	
9924/25300 (epoch 19.613), train_loss = 0.82258148, grad/param norm = 1.8002e-01, time/batch = 18.0390s	
9925/25300 (epoch 19.615), train_loss = 0.92466290, grad/param norm = 1.8929e-01, time/batch = 18.5438s	
9926/25300 (epoch 19.617), train_loss = 0.97255818, grad/param norm = 2.0725e-01, time/batch = 15.6091s	
9927/25300 (epoch 19.619), train_loss = 1.04668073, grad/param norm = 2.0059e-01, time/batch = 18.2151s	
9928/25300 (epoch 19.621), train_loss = 1.07050624, grad/param norm = 2.0496e-01, time/batch = 17.5477s	
9929/25300 (epoch 19.623), train_loss = 0.89542040, grad/param norm = 1.9151e-01, time/batch = 16.2161s	
9930/25300 (epoch 19.625), train_loss = 0.77838156, grad/param norm = 1.7646e-01, time/batch = 16.8918s	
9931/25300 (epoch 19.626), train_loss = 0.92758236, grad/param norm = 1.7102e-01, time/batch = 16.5623s	
9932/25300 (epoch 19.628), train_loss = 1.03291655, grad/param norm = 2.0464e-01, time/batch = 17.2974s	
9933/25300 (epoch 19.630), train_loss = 1.03465922, grad/param norm = 2.4760e-01, time/batch = 16.5490s	
9934/25300 (epoch 19.632), train_loss = 0.99574409, grad/param norm = 2.1496e-01, time/batch = 15.7145s	
9935/25300 (epoch 19.634), train_loss = 1.04547754, grad/param norm = 2.1157e-01, time/batch = 15.5422s	
9936/25300 (epoch 19.636), train_loss = 0.90863141, grad/param norm = 1.7223e-01, time/batch = 15.7299s	
9937/25300 (epoch 19.638), train_loss = 1.01229582, grad/param norm = 2.2140e-01, time/batch = 15.9724s	
9938/25300 (epoch 19.640), train_loss = 1.16681573, grad/param norm = 2.6011e-01, time/batch = 15.4087s	
9939/25300 (epoch 19.642), train_loss = 1.02632371, grad/param norm = 2.0662e-01, time/batch = 16.3868s	
9940/25300 (epoch 19.644), train_loss = 1.00217354, grad/param norm = 2.0852e-01, time/batch = 15.3243s	
9941/25300 (epoch 19.646), train_loss = 0.91809335, grad/param norm = 2.1708e-01, time/batch = 15.9058s	
9942/25300 (epoch 19.648), train_loss = 1.07227875, grad/param norm = 2.0749e-01, time/batch = 16.1189s	
9943/25300 (epoch 19.650), train_loss = 1.00348783, grad/param norm = 2.0785e-01, time/batch = 17.3729s	
9944/25300 (epoch 19.652), train_loss = 1.00115315, grad/param norm = 2.3027e-01, time/batch = 16.4681s	
9945/25300 (epoch 19.654), train_loss = 1.12389169, grad/param norm = 2.0222e-01, time/batch = 16.5490s	
9946/25300 (epoch 19.656), train_loss = 1.04992704, grad/param norm = 2.0738e-01, time/batch = 16.3966s	
9947/25300 (epoch 19.658), train_loss = 0.82678501, grad/param norm = 1.7834e-01, time/batch = 16.7986s	
9948/25300 (epoch 19.660), train_loss = 0.86763814, grad/param norm = 1.8729e-01, time/batch = 15.6983s	
9949/25300 (epoch 19.662), train_loss = 0.83115255, grad/param norm = 1.8236e-01, time/batch = 16.2193s	
9950/25300 (epoch 19.664), train_loss = 0.81604636, grad/param norm = 1.7426e-01, time/batch = 16.6503s	
9951/25300 (epoch 19.666), train_loss = 0.85160897, grad/param norm = 1.8828e-01, time/batch = 15.7172s	
9952/25300 (epoch 19.668), train_loss = 0.94283971, grad/param norm = 2.4785e-01, time/batch = 16.3931s	
9953/25300 (epoch 19.670), train_loss = 0.85266118, grad/param norm = 2.2853e-01, time/batch = 15.3879s	
9954/25300 (epoch 19.672), train_loss = 0.84052651, grad/param norm = 1.7481e-01, time/batch = 16.6449s	
9955/25300 (epoch 19.674), train_loss = 0.87726401, grad/param norm = 1.8062e-01, time/batch = 15.7165s	
9956/25300 (epoch 19.676), train_loss = 0.92399778, grad/param norm = 2.1222e-01, time/batch = 15.7305s	
9957/25300 (epoch 19.678), train_loss = 0.91998619, grad/param norm = 2.0672e-01, time/batch = 16.8170s	
9958/25300 (epoch 19.680), train_loss = 0.79606591, grad/param norm = 1.8012e-01, time/batch = 16.4004s	
9959/25300 (epoch 19.682), train_loss = 0.66642808, grad/param norm = 1.6457e-01, time/batch = 15.6284s	
9960/25300 (epoch 19.684), train_loss = 0.82681203, grad/param norm = 1.5616e-01, time/batch = 16.5539s	
9961/25300 (epoch 19.686), train_loss = 0.81564093, grad/param norm = 1.6934e-01, time/batch = 17.2352s	
9962/25300 (epoch 19.688), train_loss = 0.91832696, grad/param norm = 2.0439e-01, time/batch = 17.2252s	
9963/25300 (epoch 19.690), train_loss = 0.82166475, grad/param norm = 1.6234e-01, time/batch = 17.8835s	
9964/25300 (epoch 19.692), train_loss = 0.89549712, grad/param norm = 1.8461e-01, time/batch = 16.8060s	
9965/25300 (epoch 19.694), train_loss = 0.85842146, grad/param norm = 1.6088e-01, time/batch = 18.0635s	
9966/25300 (epoch 19.696), train_loss = 0.96784872, grad/param norm = 2.1698e-01, time/batch = 15.6049s	
9967/25300 (epoch 19.698), train_loss = 1.00398467, grad/param norm = 1.9000e-01, time/batch = 18.3028s	
9968/25300 (epoch 19.700), train_loss = 0.75583088, grad/param norm = 1.6978e-01, time/batch = 17.7238s	
9969/25300 (epoch 19.702), train_loss = 1.03554852, grad/param norm = 1.8607e-01, time/batch = 16.7840s	
9970/25300 (epoch 19.704), train_loss = 0.77601318, grad/param norm = 1.9407e-01, time/batch = 17.5566s	
9971/25300 (epoch 19.706), train_loss = 0.95588645, grad/param norm = 2.1078e-01, time/batch = 16.2221s	
9972/25300 (epoch 19.708), train_loss = 0.78819049, grad/param norm = 1.6077e-01, time/batch = 18.0487s	
9973/25300 (epoch 19.709), train_loss = 1.10369455, grad/param norm = 2.0028e-01, time/batch = 16.8728s	
9974/25300 (epoch 19.711), train_loss = 1.11349920, grad/param norm = 2.0705e-01, time/batch = 17.6224s	
9975/25300 (epoch 19.713), train_loss = 0.91088314, grad/param norm = 1.6782e-01, time/batch = 17.9731s	
9976/25300 (epoch 19.715), train_loss = 0.92518390, grad/param norm = 1.6660e-01, time/batch = 16.9562s	
9977/25300 (epoch 19.717), train_loss = 0.85006855, grad/param norm = 2.0044e-01, time/batch = 16.8880s	
9978/25300 (epoch 19.719), train_loss = 0.92505958, grad/param norm = 1.8465e-01, time/batch = 15.8117s	
9979/25300 (epoch 19.721), train_loss = 0.96475525, grad/param norm = 1.8888e-01, time/batch = 17.2256s	
9980/25300 (epoch 19.723), train_loss = 0.89556260, grad/param norm = 1.8191e-01, time/batch = 17.1274s	
9981/25300 (epoch 19.725), train_loss = 0.97339231, grad/param norm = 2.0849e-01, time/batch = 18.2077s	
9982/25300 (epoch 19.727), train_loss = 0.96975149, grad/param norm = 1.8725e-01, time/batch = 16.9684s	
9983/25300 (epoch 19.729), train_loss = 0.93019807, grad/param norm = 1.6894e-01, time/batch = 16.1101s	
9984/25300 (epoch 19.731), train_loss = 1.11797736, grad/param norm = 2.0602e-01, time/batch = 15.9718s	
9985/25300 (epoch 19.733), train_loss = 0.92329254, grad/param norm = 1.6693e-01, time/batch = 15.9835s	
9986/25300 (epoch 19.735), train_loss = 1.23637079, grad/param norm = 2.0691e-01, time/batch = 17.7101s	
9987/25300 (epoch 19.737), train_loss = 0.81673984, grad/param norm = 1.7051e-01, time/batch = 16.9559s	
9988/25300 (epoch 19.739), train_loss = 1.09103577, grad/param norm = 1.9632e-01, time/batch = 17.4659s	
9989/25300 (epoch 19.741), train_loss = 1.00721012, grad/param norm = 2.0262e-01, time/batch = 16.4614s	
9990/25300 (epoch 19.743), train_loss = 0.92519141, grad/param norm = 1.9882e-01, time/batch = 15.0840s	
9991/25300 (epoch 19.745), train_loss = 0.89450862, grad/param norm = 1.9366e-01, time/batch = 15.0382s	
9992/25300 (epoch 19.747), train_loss = 0.85797717, grad/param norm = 1.8320e-01, time/batch = 17.5888s	
9993/25300 (epoch 19.749), train_loss = 0.98321964, grad/param norm = 1.8387e-01, time/batch = 17.6345s	
9994/25300 (epoch 19.751), train_loss = 1.04275010, grad/param norm = 1.9056e-01, time/batch = 15.7331s	
9995/25300 (epoch 19.753), train_loss = 0.85757191, grad/param norm = 1.8861e-01, time/batch = 16.2021s	
9996/25300 (epoch 19.755), train_loss = 1.06511695, grad/param norm = 2.1457e-01, time/batch = 15.8980s	
9997/25300 (epoch 19.757), train_loss = 0.87766419, grad/param norm = 1.8299e-01, time/batch = 16.4860s	
9998/25300 (epoch 19.759), train_loss = 0.86956827, grad/param norm = 1.9599e-01, time/batch = 15.3878s	
9999/25300 (epoch 19.761), train_loss = 1.10515136, grad/param norm = 1.9627e-01, time/batch = 16.6468s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch19.76_1.5759.t7	
10000/25300 (epoch 19.763), train_loss = 0.88769438, grad/param norm = 1.9110e-01, time/batch = 17.2264s	
10001/25300 (epoch 19.765), train_loss = 1.35969311, grad/param norm = 2.4433e-01, time/batch = 16.7092s	
10002/25300 (epoch 19.767), train_loss = 0.90018954, grad/param norm = 2.0010e-01, time/batch = 16.8810s	
10003/25300 (epoch 19.769), train_loss = 0.97853814, grad/param norm = 2.0509e-01, time/batch = 16.3758s	
10004/25300 (epoch 19.771), train_loss = 1.07232889, grad/param norm = 2.1427e-01, time/batch = 17.2171s	
10005/25300 (epoch 19.773), train_loss = 1.08553207, grad/param norm = 2.3745e-01, time/batch = 15.9529s	
10006/25300 (epoch 19.775), train_loss = 0.91732813, grad/param norm = 1.6490e-01, time/batch = 16.6282s	
10007/25300 (epoch 19.777), train_loss = 0.94888995, grad/param norm = 1.9748e-01, time/batch = 16.6226s	
10008/25300 (epoch 19.779), train_loss = 1.03890747, grad/param norm = 1.9305e-01, time/batch = 17.8755s	
10009/25300 (epoch 19.781), train_loss = 0.98682716, grad/param norm = 1.7773e-01, time/batch = 16.2267s	
10010/25300 (epoch 19.783), train_loss = 1.09485007, grad/param norm = 1.9803e-01, time/batch = 16.2335s	
10011/25300 (epoch 19.785), train_loss = 1.05087621, grad/param norm = 2.0128e-01, time/batch = 16.1570s	
10012/25300 (epoch 19.787), train_loss = 1.03583932, grad/param norm = 1.9392e-01, time/batch = 16.2286s	
10013/25300 (epoch 19.789), train_loss = 1.19828769, grad/param norm = 2.2237e-01, time/batch = 15.7983s	
10014/25300 (epoch 19.791), train_loss = 1.02995650, grad/param norm = 1.9512e-01, time/batch = 15.2975s	
10015/25300 (epoch 19.792), train_loss = 1.08066299, grad/param norm = 1.8897e-01, time/batch = 15.6050s	
10016/25300 (epoch 19.794), train_loss = 0.96113617, grad/param norm = 2.0175e-01, time/batch = 15.4304s	
10017/25300 (epoch 19.796), train_loss = 0.90605150, grad/param norm = 1.9561e-01, time/batch = 15.3915s	
10018/25300 (epoch 19.798), train_loss = 1.07395817, grad/param norm = 2.0273e-01, time/batch = 15.4440s	
10019/25300 (epoch 19.800), train_loss = 0.93970583, grad/param norm = 1.7755e-01, time/batch = 15.4446s	
10020/25300 (epoch 19.802), train_loss = 0.77278001, grad/param norm = 1.8285e-01, time/batch = 15.2677s	
10021/25300 (epoch 19.804), train_loss = 0.96637855, grad/param norm = 1.8012e-01, time/batch = 15.5783s	
10022/25300 (epoch 19.806), train_loss = 1.04669469, grad/param norm = 2.0619e-01, time/batch = 15.9502s	
10023/25300 (epoch 19.808), train_loss = 1.02708748, grad/param norm = 1.9936e-01, time/batch = 16.3054s	
10024/25300 (epoch 19.810), train_loss = 0.96533884, grad/param norm = 2.0103e-01, time/batch = 15.4517s	
10025/25300 (epoch 19.812), train_loss = 1.06668752, grad/param norm = 1.9260e-01, time/batch = 17.3770s	
10026/25300 (epoch 19.814), train_loss = 1.12653596, grad/param norm = 2.1086e-01, time/batch = 15.6174s	
10027/25300 (epoch 19.816), train_loss = 1.23476691, grad/param norm = 2.3541e-01, time/batch = 16.0477s	
10028/25300 (epoch 19.818), train_loss = 1.00104463, grad/param norm = 1.6846e-01, time/batch = 15.2954s	
10029/25300 (epoch 19.820), train_loss = 1.03984251, grad/param norm = 2.1155e-01, time/batch = 15.4527s	
10030/25300 (epoch 19.822), train_loss = 0.93744194, grad/param norm = 1.8349e-01, time/batch = 16.2225s	
10031/25300 (epoch 19.824), train_loss = 1.06896052, grad/param norm = 2.0637e-01, time/batch = 15.7200s	
10032/25300 (epoch 19.826), train_loss = 0.91402724, grad/param norm = 1.8900e-01, time/batch = 15.6171s	
10033/25300 (epoch 19.828), train_loss = 0.90440530, grad/param norm = 1.8762e-01, time/batch = 16.2297s	
10034/25300 (epoch 19.830), train_loss = 0.97201741, grad/param norm = 2.0034e-01, time/batch = 16.4040s	
10035/25300 (epoch 19.832), train_loss = 1.03728198, grad/param norm = 1.9465e-01, time/batch = 16.4748s	
10036/25300 (epoch 19.834), train_loss = 0.84792279, grad/param norm = 1.7005e-01, time/batch = 16.6345s	
10037/25300 (epoch 19.836), train_loss = 0.93657518, grad/param norm = 1.8313e-01, time/batch = 17.7186s	
10038/25300 (epoch 19.838), train_loss = 0.94931994, grad/param norm = 1.8305e-01, time/batch = 15.8515s	
10039/25300 (epoch 19.840), train_loss = 1.09147245, grad/param norm = 1.9718e-01, time/batch = 15.7984s	
10040/25300 (epoch 19.842), train_loss = 0.99054092, grad/param norm = 2.0841e-01, time/batch = 16.0514s	
10041/25300 (epoch 19.844), train_loss = 1.03203843, grad/param norm = 1.7904e-01, time/batch = 16.3795s	
10042/25300 (epoch 19.846), train_loss = 1.03501691, grad/param norm = 1.8151e-01, time/batch = 16.6430s	
10043/25300 (epoch 19.848), train_loss = 1.07460931, grad/param norm = 2.0338e-01, time/batch = 16.4651s	
10044/25300 (epoch 19.850), train_loss = 1.03021344, grad/param norm = 1.9623e-01, time/batch = 17.1288s	
10045/25300 (epoch 19.852), train_loss = 1.05815862, grad/param norm = 2.0384e-01, time/batch = 16.8875s	
10046/25300 (epoch 19.854), train_loss = 1.12821263, grad/param norm = 1.9828e-01, time/batch = 15.4596s	
10047/25300 (epoch 19.856), train_loss = 0.95558497, grad/param norm = 2.0315e-01, time/batch = 15.4845s	
10048/25300 (epoch 19.858), train_loss = 1.01240600, grad/param norm = 2.0662e-01, time/batch = 17.7993s	
10049/25300 (epoch 19.860), train_loss = 0.83780208, grad/param norm = 1.7497e-01, time/batch = 16.7351s	
10050/25300 (epoch 19.862), train_loss = 0.96787521, grad/param norm = 2.0340e-01, time/batch = 16.1209s	
10051/25300 (epoch 19.864), train_loss = 1.07529733, grad/param norm = 1.9677e-01, time/batch = 16.3833s	
10052/25300 (epoch 19.866), train_loss = 0.96824967, grad/param norm = 2.0088e-01, time/batch = 15.4510s	
10053/25300 (epoch 19.868), train_loss = 1.11059973, grad/param norm = 2.1136e-01, time/batch = 16.4672s	
10054/25300 (epoch 19.870), train_loss = 1.06657240, grad/param norm = 1.7409e-01, time/batch = 15.8117s	
10055/25300 (epoch 19.872), train_loss = 1.05466612, grad/param norm = 2.2623e-01, time/batch = 15.6494s	
10056/25300 (epoch 19.874), train_loss = 1.06007814, grad/param norm = 1.9673e-01, time/batch = 15.8201s	
10057/25300 (epoch 19.875), train_loss = 0.96729798, grad/param norm = 1.9717e-01, time/batch = 16.1934s	
10058/25300 (epoch 19.877), train_loss = 0.94906942, grad/param norm = 1.7826e-01, time/batch = 15.8183s	
10059/25300 (epoch 19.879), train_loss = 0.95378458, grad/param norm = 2.0361e-01, time/batch = 16.9834s	
10060/25300 (epoch 19.881), train_loss = 1.33026771, grad/param norm = 2.9654e-01, time/batch = 16.5541s	
10061/25300 (epoch 19.883), train_loss = 1.22414040, grad/param norm = 2.0279e-01, time/batch = 15.4765s	
10062/25300 (epoch 19.885), train_loss = 1.09724110, grad/param norm = 2.4970e-01, time/batch = 16.6534s	
10063/25300 (epoch 19.887), train_loss = 1.05487509, grad/param norm = 2.0629e-01, time/batch = 16.1483s	
10064/25300 (epoch 19.889), train_loss = 1.16605486, grad/param norm = 2.3137e-01, time/batch = 16.3991s	
10065/25300 (epoch 19.891), train_loss = 1.04959320, grad/param norm = 2.2018e-01, time/batch = 15.9618s	
10066/25300 (epoch 19.893), train_loss = 1.09200866, grad/param norm = 2.4207e-01, time/batch = 16.9756s	
10067/25300 (epoch 19.895), train_loss = 0.77158143, grad/param norm = 1.8405e-01, time/batch = 16.6366s	
10068/25300 (epoch 19.897), train_loss = 0.91001809, grad/param norm = 2.0033e-01, time/batch = 16.7211s	
10069/25300 (epoch 19.899), train_loss = 1.02140969, grad/param norm = 1.9607e-01, time/batch = 15.6495s	
10070/25300 (epoch 19.901), train_loss = 1.04120131, grad/param norm = 1.8394e-01, time/batch = 16.3917s	
10071/25300 (epoch 19.903), train_loss = 0.79093956, grad/param norm = 1.7025e-01, time/batch = 16.6235s	
10072/25300 (epoch 19.905), train_loss = 0.92294778, grad/param norm = 2.0492e-01, time/batch = 16.4682s	
10073/25300 (epoch 19.907), train_loss = 0.93307531, grad/param norm = 2.0716e-01, time/batch = 16.0445s	
10074/25300 (epoch 19.909), train_loss = 1.05426947, grad/param norm = 1.9733e-01, time/batch = 15.2203s	
10075/25300 (epoch 19.911), train_loss = 1.14812711, grad/param norm = 2.2800e-01, time/batch = 17.0649s	
10076/25300 (epoch 19.913), train_loss = 1.22690081, grad/param norm = 2.3102e-01, time/batch = 14.9628s	
10077/25300 (epoch 19.915), train_loss = 0.94002044, grad/param norm = 2.2083e-01, time/batch = 16.1609s	
10078/25300 (epoch 19.917), train_loss = 1.09080008, grad/param norm = 2.1939e-01, time/batch = 16.1566s	
10079/25300 (epoch 19.919), train_loss = 1.12493069, grad/param norm = 2.1061e-01, time/batch = 16.1464s	
10080/25300 (epoch 19.921), train_loss = 0.90450121, grad/param norm = 2.1108e-01, time/batch = 16.1346s	
10081/25300 (epoch 19.923), train_loss = 1.13731489, grad/param norm = 1.9459e-01, time/batch = 16.7199s	
10082/25300 (epoch 19.925), train_loss = 0.99129704, grad/param norm = 1.9877e-01, time/batch = 16.9280s	
10083/25300 (epoch 19.927), train_loss = 0.96054105, grad/param norm = 2.0983e-01, time/batch = 15.3788s	
10084/25300 (epoch 19.929), train_loss = 0.98498962, grad/param norm = 1.8420e-01, time/batch = 15.8063s	
10085/25300 (epoch 19.931), train_loss = 1.07306122, grad/param norm = 2.1208e-01, time/batch = 16.3196s	
10086/25300 (epoch 19.933), train_loss = 1.06538304, grad/param norm = 2.1137e-01, time/batch = 16.9882s	
10087/25300 (epoch 19.935), train_loss = 1.03731956, grad/param norm = 1.9960e-01, time/batch = 15.5326s	
10088/25300 (epoch 19.937), train_loss = 0.77589336, grad/param norm = 1.7314e-01, time/batch = 17.3025s	
10089/25300 (epoch 19.939), train_loss = 1.06228060, grad/param norm = 1.9161e-01, time/batch = 17.1338s	
10090/25300 (epoch 19.941), train_loss = 0.92183739, grad/param norm = 1.8447e-01, time/batch = 17.2952s	
10091/25300 (epoch 19.943), train_loss = 1.02586251, grad/param norm = 1.8695e-01, time/batch = 17.5382s	
10092/25300 (epoch 19.945), train_loss = 1.06189830, grad/param norm = 2.0544e-01, time/batch = 16.7217s	
10093/25300 (epoch 19.947), train_loss = 0.90384940, grad/param norm = 1.8312e-01, time/batch = 16.8038s	
10094/25300 (epoch 19.949), train_loss = 1.06545522, grad/param norm = 1.9596e-01, time/batch = 15.3633s	
10095/25300 (epoch 19.951), train_loss = 0.98265770, grad/param norm = 1.9136e-01, time/batch = 16.6396s	
10096/25300 (epoch 19.953), train_loss = 1.00590063, grad/param norm = 1.8675e-01, time/batch = 16.1574s	
10097/25300 (epoch 19.955), train_loss = 1.22101469, grad/param norm = 2.2316e-01, time/batch = 16.8222s	
10098/25300 (epoch 19.957), train_loss = 1.17138247, grad/param norm = 2.4199e-01, time/batch = 15.5585s	
10099/25300 (epoch 19.958), train_loss = 1.09047562, grad/param norm = 2.1744e-01, time/batch = 17.5596s	
10100/25300 (epoch 19.960), train_loss = 1.21604669, grad/param norm = 2.3115e-01, time/batch = 16.0613s	
10101/25300 (epoch 19.962), train_loss = 1.14509276, grad/param norm = 2.0943e-01, time/batch = 15.6449s	
10102/25300 (epoch 19.964), train_loss = 1.06700228, grad/param norm = 2.1768e-01, time/batch = 16.4755s	
10103/25300 (epoch 19.966), train_loss = 0.85129926, grad/param norm = 1.8260e-01, time/batch = 16.3059s	
10104/25300 (epoch 19.968), train_loss = 0.84605408, grad/param norm = 1.6927e-01, time/batch = 16.0648s	
10105/25300 (epoch 19.970), train_loss = 0.95352366, grad/param norm = 1.9527e-01, time/batch = 15.9651s	
10106/25300 (epoch 19.972), train_loss = 0.98457889, grad/param norm = 1.9923e-01, time/batch = 16.5483s	
10107/25300 (epoch 19.974), train_loss = 1.17350314, grad/param norm = 2.2525e-01, time/batch = 16.8093s	
10108/25300 (epoch 19.976), train_loss = 1.04026385, grad/param norm = 1.8803e-01, time/batch = 16.7335s	
10109/25300 (epoch 19.978), train_loss = 0.99729181, grad/param norm = 1.9418e-01, time/batch = 15.7355s	
10110/25300 (epoch 19.980), train_loss = 1.03794739, grad/param norm = 2.2242e-01, time/batch = 15.5853s	
10111/25300 (epoch 19.982), train_loss = 0.95366517, grad/param norm = 1.8041e-01, time/batch = 17.5585s	
10112/25300 (epoch 19.984), train_loss = 0.97755683, grad/param norm = 2.0247e-01, time/batch = 16.1076s	
10113/25300 (epoch 19.986), train_loss = 1.10126946, grad/param norm = 2.1441e-01, time/batch = 15.8142s	
10114/25300 (epoch 19.988), train_loss = 1.05035315, grad/param norm = 2.0019e-01, time/batch = 15.8088s	
10115/25300 (epoch 19.990), train_loss = 0.98431631, grad/param norm = 1.8452e-01, time/batch = 16.0659s	
10116/25300 (epoch 19.992), train_loss = 0.82855871, grad/param norm = 1.6982e-01, time/batch = 15.8888s	
10117/25300 (epoch 19.994), train_loss = 1.01164992, grad/param norm = 1.9589e-01, time/batch = 16.2283s	
10118/25300 (epoch 19.996), train_loss = 1.15360352, grad/param norm = 2.6498e-01, time/batch = 16.3226s	
10119/25300 (epoch 19.998), train_loss = 1.13404211, grad/param norm = 2.0670e-01, time/batch = 17.9620s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
10120/25300 (epoch 20.000), train_loss = 1.04473553, grad/param norm = 2.2312e-01, time/batch = 16.7266s	
10121/25300 (epoch 20.002), train_loss = 0.88560727, grad/param norm = 1.6871e-01, time/batch = 17.8016s	
10122/25300 (epoch 20.004), train_loss = 0.83416129, grad/param norm = 1.7065e-01, time/batch = 16.7322s	
10123/25300 (epoch 20.006), train_loss = 1.13225970, grad/param norm = 1.8742e-01, time/batch = 22.9424s	
10124/25300 (epoch 20.008), train_loss = 0.97530752, grad/param norm = 1.7093e-01, time/batch = 23.4113s	
10125/25300 (epoch 20.010), train_loss = 1.01177176, grad/param norm = 1.8416e-01, time/batch = 16.2137s	
10126/25300 (epoch 20.012), train_loss = 0.92851070, grad/param norm = 1.8143e-01, time/batch = 15.9535s	
10127/25300 (epoch 20.014), train_loss = 1.13113279, grad/param norm = 1.9141e-01, time/batch = 15.9610s	
10128/25300 (epoch 20.016), train_loss = 1.01584692, grad/param norm = 1.9779e-01, time/batch = 17.8117s	
10129/25300 (epoch 20.018), train_loss = 0.88571727, grad/param norm = 1.8142e-01, time/batch = 16.1277s	
10130/25300 (epoch 20.020), train_loss = 0.96718760, grad/param norm = 1.8427e-01, time/batch = 16.1227s	
10131/25300 (epoch 20.022), train_loss = 1.03261532, grad/param norm = 2.2008e-01, time/batch = 16.9661s	
10132/25300 (epoch 20.024), train_loss = 0.75233792, grad/param norm = 1.6166e-01, time/batch = 17.2996s	
10133/25300 (epoch 20.026), train_loss = 0.93734710, grad/param norm = 1.9809e-01, time/batch = 17.3605s	
10134/25300 (epoch 20.028), train_loss = 0.89383861, grad/param norm = 1.8196e-01, time/batch = 16.9642s	
10135/25300 (epoch 20.030), train_loss = 1.10402091, grad/param norm = 1.9572e-01, time/batch = 17.0448s	
10136/25300 (epoch 20.032), train_loss = 0.92729676, grad/param norm = 1.8660e-01, time/batch = 16.0585s	
10137/25300 (epoch 20.034), train_loss = 0.84387955, grad/param norm = 1.9881e-01, time/batch = 18.0288s	
10138/25300 (epoch 20.036), train_loss = 0.81480574, grad/param norm = 1.6087e-01, time/batch = 16.0497s	
10139/25300 (epoch 20.038), train_loss = 0.73603359, grad/param norm = 1.4488e-01, time/batch = 17.1357s	
10140/25300 (epoch 20.040), train_loss = 0.99959301, grad/param norm = 1.8937e-01, time/batch = 15.8522s	
10141/25300 (epoch 20.042), train_loss = 0.94463325, grad/param norm = 1.8424e-01, time/batch = 16.1478s	
10142/25300 (epoch 20.043), train_loss = 0.81176779, grad/param norm = 1.5441e-01, time/batch = 15.4594s	
10143/25300 (epoch 20.045), train_loss = 0.83327212, grad/param norm = 1.6211e-01, time/batch = 16.7216s	
10144/25300 (epoch 20.047), train_loss = 1.02889192, grad/param norm = 1.8386e-01, time/batch = 15.6408s	
10145/25300 (epoch 20.049), train_loss = 1.00126449, grad/param norm = 2.0431e-01, time/batch = 16.5567s	
10146/25300 (epoch 20.051), train_loss = 1.07004549, grad/param norm = 2.1043e-01, time/batch = 14.6444s	
10147/25300 (epoch 20.053), train_loss = 0.79378059, grad/param norm = 1.5855e-01, time/batch = 14.5727s	
10148/25300 (epoch 20.055), train_loss = 0.85365534, grad/param norm = 1.7609e-01, time/batch = 15.8651s	
10149/25300 (epoch 20.057), train_loss = 0.81234135, grad/param norm = 1.5746e-01, time/batch = 16.0618s	
10150/25300 (epoch 20.059), train_loss = 0.90851314, grad/param norm = 1.7251e-01, time/batch = 16.6360s	
10151/25300 (epoch 20.061), train_loss = 0.88449856, grad/param norm = 1.9204e-01, time/batch = 15.8919s	
10152/25300 (epoch 20.063), train_loss = 0.86617373, grad/param norm = 1.7255e-01, time/batch = 15.9086s	
10153/25300 (epoch 20.065), train_loss = 1.01831029, grad/param norm = 1.9282e-01, time/batch = 17.3897s	
10154/25300 (epoch 20.067), train_loss = 1.07320698, grad/param norm = 1.8683e-01, time/batch = 17.4785s	
10155/25300 (epoch 20.069), train_loss = 0.91347960, grad/param norm = 1.8540e-01, time/batch = 16.2089s	
10156/25300 (epoch 20.071), train_loss = 1.09499756, grad/param norm = 2.0654e-01, time/batch = 17.8059s	
10157/25300 (epoch 20.073), train_loss = 0.90365001, grad/param norm = 1.5782e-01, time/batch = 18.8016s	
10158/25300 (epoch 20.075), train_loss = 1.05057631, grad/param norm = 1.9990e-01, time/batch = 16.3834s	
10159/25300 (epoch 20.077), train_loss = 0.99887892, grad/param norm = 1.9105e-01, time/batch = 15.8905s	
10160/25300 (epoch 20.079), train_loss = 0.93770002, grad/param norm = 1.8624e-01, time/batch = 16.2172s	
10161/25300 (epoch 20.081), train_loss = 0.94242896, grad/param norm = 1.6781e-01, time/batch = 17.6254s	
10162/25300 (epoch 20.083), train_loss = 0.95316769, grad/param norm = 1.7162e-01, time/batch = 17.1226s	
10163/25300 (epoch 20.085), train_loss = 1.17924774, grad/param norm = 2.1689e-01, time/batch = 18.3870s	
10164/25300 (epoch 20.087), train_loss = 1.04666830, grad/param norm = 1.8912e-01, time/batch = 16.7320s	
10165/25300 (epoch 20.089), train_loss = 1.03546376, grad/param norm = 2.0230e-01, time/batch = 16.5468s	
10166/25300 (epoch 20.091), train_loss = 1.16645370, grad/param norm = 2.2251e-01, time/batch = 15.8937s	
10167/25300 (epoch 20.093), train_loss = 1.09242173, grad/param norm = 1.9907e-01, time/batch = 16.2193s	
10168/25300 (epoch 20.095), train_loss = 1.06294493, grad/param norm = 1.9687e-01, time/batch = 17.3049s	
10169/25300 (epoch 20.097), train_loss = 1.01837407, grad/param norm = 1.7935e-01, time/batch = 15.6860s	
10170/25300 (epoch 20.099), train_loss = 1.03939043, grad/param norm = 1.9598e-01, time/batch = 17.5371s	
10171/25300 (epoch 20.101), train_loss = 0.96967923, grad/param norm = 2.0248e-01, time/batch = 16.5555s	
10172/25300 (epoch 20.103), train_loss = 0.99940120, grad/param norm = 1.9252e-01, time/batch = 17.6205s	
10173/25300 (epoch 20.105), train_loss = 1.05664339, grad/param norm = 1.8561e-01, time/batch = 16.7089s	
10174/25300 (epoch 20.107), train_loss = 1.06783903, grad/param norm = 2.1683e-01, time/batch = 17.3091s	
10175/25300 (epoch 20.109), train_loss = 0.97493167, grad/param norm = 1.9780e-01, time/batch = 16.4691s	
10176/25300 (epoch 20.111), train_loss = 0.96486627, grad/param norm = 1.8403e-01, time/batch = 16.3776s	
10177/25300 (epoch 20.113), train_loss = 0.92873834, grad/param norm = 2.0906e-01, time/batch = 15.7174s	
10178/25300 (epoch 20.115), train_loss = 0.96598112, grad/param norm = 2.0991e-01, time/batch = 16.2685s	
10179/25300 (epoch 20.117), train_loss = 1.04235458, grad/param norm = 1.8672e-01, time/batch = 15.4391s	
10180/25300 (epoch 20.119), train_loss = 0.93616792, grad/param norm = 1.9284e-01, time/batch = 15.3382s	
10181/25300 (epoch 20.121), train_loss = 1.00850180, grad/param norm = 2.0393e-01, time/batch = 15.4958s	
10182/25300 (epoch 20.123), train_loss = 0.93920515, grad/param norm = 1.9917e-01, time/batch = 15.4389s	
10183/25300 (epoch 20.125), train_loss = 1.07355652, grad/param norm = 2.1265e-01, time/batch = 15.2743s	
10184/25300 (epoch 20.126), train_loss = 0.97368933, grad/param norm = 2.0209e-01, time/batch = 15.5354s	
10185/25300 (epoch 20.128), train_loss = 0.97838529, grad/param norm = 2.2181e-01, time/batch = 17.1098s	
10186/25300 (epoch 20.130), train_loss = 0.78875936, grad/param norm = 1.6366e-01, time/batch = 16.3685s	
10187/25300 (epoch 20.132), train_loss = 0.81555668, grad/param norm = 1.7408e-01, time/batch = 15.7147s	
10188/25300 (epoch 20.134), train_loss = 0.79760962, grad/param norm = 1.7501e-01, time/batch = 15.5235s	
10189/25300 (epoch 20.136), train_loss = 0.96419634, grad/param norm = 1.8392e-01, time/batch = 16.7147s	
10190/25300 (epoch 20.138), train_loss = 0.83741675, grad/param norm = 1.7554e-01, time/batch = 16.7142s	
10191/25300 (epoch 20.140), train_loss = 0.89586138, grad/param norm = 1.7418e-01, time/batch = 15.4376s	
10192/25300 (epoch 20.142), train_loss = 1.06989233, grad/param norm = 1.8981e-01, time/batch = 16.3164s	
10193/25300 (epoch 20.144), train_loss = 1.05089904, grad/param norm = 1.8771e-01, time/batch = 16.7278s	
10194/25300 (epoch 20.146), train_loss = 1.03379166, grad/param norm = 2.1696e-01, time/batch = 16.3069s	
10195/25300 (epoch 20.148), train_loss = 0.97838651, grad/param norm = 1.8789e-01, time/batch = 15.6268s	
10196/25300 (epoch 20.150), train_loss = 1.07848528, grad/param norm = 2.1629e-01, time/batch = 16.3785s	
10197/25300 (epoch 20.152), train_loss = 1.14961397, grad/param norm = 2.2508e-01, time/batch = 15.7418s	
10198/25300 (epoch 20.154), train_loss = 0.82757390, grad/param norm = 1.7148e-01, time/batch = 16.2939s	
10199/25300 (epoch 20.156), train_loss = 1.05083040, grad/param norm = 2.1367e-01, time/batch = 15.8128s	
10200/25300 (epoch 20.158), train_loss = 0.88248180, grad/param norm = 1.9640e-01, time/batch = 16.0579s	
10201/25300 (epoch 20.160), train_loss = 0.95942448, grad/param norm = 1.7844e-01, time/batch = 16.3976s	
10202/25300 (epoch 20.162), train_loss = 0.91855842, grad/param norm = 1.9159e-01, time/batch = 15.9593s	
10203/25300 (epoch 20.164), train_loss = 1.04295907, grad/param norm = 1.9589e-01, time/batch = 15.4708s	
10204/25300 (epoch 20.166), train_loss = 0.98125453, grad/param norm = 1.7775e-01, time/batch = 15.5313s	
10205/25300 (epoch 20.168), train_loss = 0.87236400, grad/param norm = 1.6380e-01, time/batch = 15.4587s	
10206/25300 (epoch 20.170), train_loss = 0.95222593, grad/param norm = 1.8530e-01, time/batch = 16.5295s	
10207/25300 (epoch 20.172), train_loss = 0.86655245, grad/param norm = 1.7500e-01, time/batch = 16.3075s	
10208/25300 (epoch 20.174), train_loss = 0.86451527, grad/param norm = 1.8121e-01, time/batch = 16.1445s	
10209/25300 (epoch 20.176), train_loss = 0.89975596, grad/param norm = 2.1002e-01, time/batch = 16.1446s	
10210/25300 (epoch 20.178), train_loss = 1.08716326, grad/param norm = 1.9618e-01, time/batch = 15.4647s	
10211/25300 (epoch 20.180), train_loss = 0.78946175, grad/param norm = 1.6868e-01, time/batch = 15.9762s	
10212/25300 (epoch 20.182), train_loss = 0.91205299, grad/param norm = 1.7477e-01, time/batch = 15.3909s	
10213/25300 (epoch 20.184), train_loss = 0.90856412, grad/param norm = 1.9488e-01, time/batch = 16.2176s	
10214/25300 (epoch 20.186), train_loss = 0.88437138, grad/param norm = 1.8462e-01, time/batch = 15.8910s	
10215/25300 (epoch 20.188), train_loss = 0.97741957, grad/param norm = 1.8280e-01, time/batch = 16.8033s	
10216/25300 (epoch 20.190), train_loss = 0.91722191, grad/param norm = 1.8015e-01, time/batch = 18.2116s	
10217/25300 (epoch 20.192), train_loss = 0.94293041, grad/param norm = 1.9628e-01, time/batch = 16.2870s	
10218/25300 (epoch 20.194), train_loss = 0.94923591, grad/param norm = 1.9468e-01, time/batch = 16.8036s	
10219/25300 (epoch 20.196), train_loss = 1.05981949, grad/param norm = 2.3283e-01, time/batch = 16.2302s	
10220/25300 (epoch 20.198), train_loss = 0.90512531, grad/param norm = 2.0413e-01, time/batch = 17.1523s	
10221/25300 (epoch 20.200), train_loss = 0.94022527, grad/param norm = 1.8857e-01, time/batch = 16.3884s	
10222/25300 (epoch 20.202), train_loss = 0.94545187, grad/param norm = 1.8281e-01, time/batch = 16.3084s	
10223/25300 (epoch 20.204), train_loss = 0.92154309, grad/param norm = 1.7793e-01, time/batch = 16.5660s	
10224/25300 (epoch 20.206), train_loss = 1.03452891, grad/param norm = 1.9336e-01, time/batch = 16.0595s	
10225/25300 (epoch 20.208), train_loss = 0.83750866, grad/param norm = 1.7953e-01, time/batch = 16.1248s	
10226/25300 (epoch 20.209), train_loss = 0.81425789, grad/param norm = 1.7389e-01, time/batch = 16.5596s	
10227/25300 (epoch 20.211), train_loss = 0.91281806, grad/param norm = 1.7918e-01, time/batch = 15.6880s	
10228/25300 (epoch 20.213), train_loss = 0.98795128, grad/param norm = 1.8745e-01, time/batch = 16.3643s	
10229/25300 (epoch 20.215), train_loss = 0.96526482, grad/param norm = 1.8432e-01, time/batch = 16.0639s	
10230/25300 (epoch 20.217), train_loss = 0.98530024, grad/param norm = 2.0054e-01, time/batch = 17.4530s	
10231/25300 (epoch 20.219), train_loss = 1.06005303, grad/param norm = 2.1122e-01, time/batch = 16.7071s	
10232/25300 (epoch 20.221), train_loss = 1.10625725, grad/param norm = 2.0752e-01, time/batch = 15.2934s	
10233/25300 (epoch 20.223), train_loss = 1.02130586, grad/param norm = 2.0767e-01, time/batch = 16.3997s	
10234/25300 (epoch 20.225), train_loss = 1.39355704, grad/param norm = 3.2276e-01, time/batch = 16.5624s	
10235/25300 (epoch 20.227), train_loss = 1.09984531, grad/param norm = 2.1388e-01, time/batch = 16.7124s	
10236/25300 (epoch 20.229), train_loss = 0.96878183, grad/param norm = 1.8912e-01, time/batch = 16.6184s	
10237/25300 (epoch 20.231), train_loss = 0.95566995, grad/param norm = 1.9695e-01, time/batch = 16.6459s	
10238/25300 (epoch 20.233), train_loss = 1.04875835, grad/param norm = 2.0501e-01, time/batch = 16.9826s	
10239/25300 (epoch 20.235), train_loss = 0.96289502, grad/param norm = 1.8038e-01, time/batch = 15.6305s	
10240/25300 (epoch 20.237), train_loss = 1.14745927, grad/param norm = 2.2296e-01, time/batch = 16.0607s	
10241/25300 (epoch 20.239), train_loss = 0.97849579, grad/param norm = 1.9320e-01, time/batch = 16.6359s	
10242/25300 (epoch 20.241), train_loss = 1.11618962, grad/param norm = 1.9334e-01, time/batch = 16.8783s	
10243/25300 (epoch 20.243), train_loss = 1.27731643, grad/param norm = 2.2304e-01, time/batch = 15.6086s	
10244/25300 (epoch 20.245), train_loss = 0.91352980, grad/param norm = 1.7611e-01, time/batch = 16.6339s	
10245/25300 (epoch 20.247), train_loss = 1.06237572, grad/param norm = 1.9344e-01, time/batch = 16.7240s	
10246/25300 (epoch 20.249), train_loss = 0.84796057, grad/param norm = 1.6613e-01, time/batch = 15.9714s	
10247/25300 (epoch 20.251), train_loss = 0.82904245, grad/param norm = 1.7254e-01, time/batch = 16.8843s	
10248/25300 (epoch 20.253), train_loss = 0.95374479, grad/param norm = 1.9510e-01, time/batch = 15.7259s	
10249/25300 (epoch 20.255), train_loss = 0.93754779, grad/param norm = 2.0647e-01, time/batch = 16.4711s	
10250/25300 (epoch 20.257), train_loss = 0.99560686, grad/param norm = 2.1431e-01, time/batch = 15.7914s	
10251/25300 (epoch 20.259), train_loss = 1.18539735, grad/param norm = 2.3564e-01, time/batch = 16.8011s	
10252/25300 (epoch 20.261), train_loss = 1.14645607, grad/param norm = 2.2757e-01, time/batch = 15.8818s	
10253/25300 (epoch 20.263), train_loss = 1.13135958, grad/param norm = 2.0229e-01, time/batch = 16.5552s	
10254/25300 (epoch 20.265), train_loss = 1.16334938, grad/param norm = 2.0669e-01, time/batch = 15.8984s	
10255/25300 (epoch 20.267), train_loss = 1.08208189, grad/param norm = 2.1072e-01, time/batch = 16.2349s	
10256/25300 (epoch 20.269), train_loss = 0.81530849, grad/param norm = 1.5954e-01, time/batch = 15.9748s	
10257/25300 (epoch 20.271), train_loss = 0.94754566, grad/param norm = 1.8060e-01, time/batch = 15.8143s	
10258/25300 (epoch 20.273), train_loss = 1.04508327, grad/param norm = 2.0425e-01, time/batch = 16.7229s	
10259/25300 (epoch 20.275), train_loss = 0.94973158, grad/param norm = 1.5933e-01, time/batch = 15.8775s	
10260/25300 (epoch 20.277), train_loss = 0.95141344, grad/param norm = 1.9146e-01, time/batch = 16.3820s	
10261/25300 (epoch 20.279), train_loss = 0.97595871, grad/param norm = 1.8651e-01, time/batch = 16.2251s	
10262/25300 (epoch 20.281), train_loss = 1.14645760, grad/param norm = 2.2531e-01, time/batch = 17.3692s	
10263/25300 (epoch 20.283), train_loss = 0.86386920, grad/param norm = 1.7486e-01, time/batch = 16.9781s	
10264/25300 (epoch 20.285), train_loss = 1.02306102, grad/param norm = 2.0826e-01, time/batch = 15.8858s	
10265/25300 (epoch 20.287), train_loss = 1.04359353, grad/param norm = 2.0606e-01, time/batch = 16.7193s	
10266/25300 (epoch 20.289), train_loss = 0.94722372, grad/param norm = 1.8262e-01, time/batch = 17.3951s	
10267/25300 (epoch 20.291), train_loss = 0.95851462, grad/param norm = 1.8325e-01, time/batch = 16.5549s	
10268/25300 (epoch 20.292), train_loss = 1.12624741, grad/param norm = 1.8914e-01, time/batch = 15.5365s	
10269/25300 (epoch 20.294), train_loss = 1.00686669, grad/param norm = 1.8609e-01, time/batch = 16.5515s	
10270/25300 (epoch 20.296), train_loss = 0.89319983, grad/param norm = 1.9053e-01, time/batch = 15.6450s	
10271/25300 (epoch 20.298), train_loss = 1.06787752, grad/param norm = 2.0502e-01, time/batch = 17.3777s	
10272/25300 (epoch 20.300), train_loss = 1.10024900, grad/param norm = 2.3291e-01, time/batch = 15.5578s	
10273/25300 (epoch 20.302), train_loss = 0.80342691, grad/param norm = 1.8591e-01, time/batch = 15.5461s	
10274/25300 (epoch 20.304), train_loss = 1.07382159, grad/param norm = 1.8427e-01, time/batch = 15.4008s	
10275/25300 (epoch 20.306), train_loss = 0.77448654, grad/param norm = 1.6713e-01, time/batch = 15.4739s	
10276/25300 (epoch 20.308), train_loss = 1.03252735, grad/param norm = 1.7617e-01, time/batch = 15.1567s	
10277/25300 (epoch 20.310), train_loss = 0.88513197, grad/param norm = 1.8408e-01, time/batch = 16.3177s	
10278/25300 (epoch 20.312), train_loss = 0.98737677, grad/param norm = 1.8180e-01, time/batch = 16.7876s	
10279/25300 (epoch 20.314), train_loss = 0.81480605, grad/param norm = 1.6902e-01, time/batch = 15.7176s	
10280/25300 (epoch 20.316), train_loss = 1.00365257, grad/param norm = 1.8159e-01, time/batch = 16.4046s	
10281/25300 (epoch 20.318), train_loss = 0.80142519, grad/param norm = 1.7660e-01, time/batch = 16.0546s	
10282/25300 (epoch 20.320), train_loss = 0.86485849, grad/param norm = 1.7406e-01, time/batch = 16.2972s	
10283/25300 (epoch 20.322), train_loss = 1.16601682, grad/param norm = 2.2241e-01, time/batch = 16.7763s	
10284/25300 (epoch 20.324), train_loss = 0.87163791, grad/param norm = 1.6989e-01, time/batch = 16.2119s	
10285/25300 (epoch 20.326), train_loss = 0.78064589, grad/param norm = 1.6259e-01, time/batch = 16.1381s	
10286/25300 (epoch 20.328), train_loss = 0.79341001, grad/param norm = 2.0207e-01, time/batch = 16.8812s	
10287/25300 (epoch 20.330), train_loss = 0.93646892, grad/param norm = 1.8423e-01, time/batch = 16.6192s	
10288/25300 (epoch 20.332), train_loss = 0.99267763, grad/param norm = 1.8460e-01, time/batch = 18.0481s	
10289/25300 (epoch 20.334), train_loss = 0.81496800, grad/param norm = 1.7719e-01, time/batch = 17.0484s	
10290/25300 (epoch 20.336), train_loss = 0.82665654, grad/param norm = 1.8189e-01, time/batch = 15.4749s	
10291/25300 (epoch 20.338), train_loss = 0.82196261, grad/param norm = 1.7506e-01, time/batch = 17.1311s	
10292/25300 (epoch 20.340), train_loss = 0.89499350, grad/param norm = 1.8989e-01, time/batch = 16.1164s	
10293/25300 (epoch 20.342), train_loss = 0.92340583, grad/param norm = 2.1214e-01, time/batch = 17.7962s	
10294/25300 (epoch 20.344), train_loss = 0.98410244, grad/param norm = 1.8140e-01, time/batch = 16.1951s	
10295/25300 (epoch 20.346), train_loss = 0.91093553, grad/param norm = 1.9451e-01, time/batch = 17.4675s	
10296/25300 (epoch 20.348), train_loss = 0.82827127, grad/param norm = 1.7960e-01, time/batch = 17.1369s	
10297/25300 (epoch 20.350), train_loss = 0.91982682, grad/param norm = 1.8660e-01, time/batch = 16.2094s	
10298/25300 (epoch 20.352), train_loss = 0.94970110, grad/param norm = 1.8181e-01, time/batch = 15.9778s	
10299/25300 (epoch 20.354), train_loss = 0.91211317, grad/param norm = 1.9524e-01, time/batch = 16.0344s	
10300/25300 (epoch 20.356), train_loss = 0.94765724, grad/param norm = 1.9042e-01, time/batch = 16.0627s	
10301/25300 (epoch 20.358), train_loss = 1.03011747, grad/param norm = 2.2186e-01, time/batch = 15.1353s	
10302/25300 (epoch 20.360), train_loss = 0.86117052, grad/param norm = 1.6411e-01, time/batch = 15.9957s	
10303/25300 (epoch 20.362), train_loss = 0.88219454, grad/param norm = 1.8225e-01, time/batch = 16.1380s	
10304/25300 (epoch 20.364), train_loss = 0.91042550, grad/param norm = 1.9313e-01, time/batch = 16.4814s	
10305/25300 (epoch 20.366), train_loss = 0.81790492, grad/param norm = 1.7822e-01, time/batch = 15.8772s	
10306/25300 (epoch 20.368), train_loss = 0.91779203, grad/param norm = 1.7897e-01, time/batch = 16.2168s	
10307/25300 (epoch 20.370), train_loss = 0.89386418, grad/param norm = 1.9495e-01, time/batch = 16.0475s	
10308/25300 (epoch 20.372), train_loss = 0.90073768, grad/param norm = 1.8158e-01, time/batch = 16.6293s	
10309/25300 (epoch 20.374), train_loss = 0.83032115, grad/param norm = 1.8921e-01, time/batch = 15.5603s	
10310/25300 (epoch 20.375), train_loss = 1.08597193, grad/param norm = 2.2080e-01, time/batch = 16.5510s	
10311/25300 (epoch 20.377), train_loss = 1.00931708, grad/param norm = 2.0947e-01, time/batch = 15.8703s	
10312/25300 (epoch 20.379), train_loss = 0.98289041, grad/param norm = 1.9393e-01, time/batch = 16.1307s	
10313/25300 (epoch 20.381), train_loss = 0.93426531, grad/param norm = 1.8396e-01, time/batch = 16.5553s	
10314/25300 (epoch 20.383), train_loss = 0.85942575, grad/param norm = 1.7110e-01, time/batch = 16.0665s	
10315/25300 (epoch 20.385), train_loss = 0.95388781, grad/param norm = 1.7872e-01, time/batch = 16.3298s	
10316/25300 (epoch 20.387), train_loss = 0.98729642, grad/param norm = 1.8928e-01, time/batch = 15.2040s	
10317/25300 (epoch 20.389), train_loss = 1.01289085, grad/param norm = 2.0831e-01, time/batch = 16.6304s	
10318/25300 (epoch 20.391), train_loss = 0.87228269, grad/param norm = 1.6772e-01, time/batch = 17.3879s	
10319/25300 (epoch 20.393), train_loss = 0.98034392, grad/param norm = 2.4220e-01, time/batch = 15.8081s	
10320/25300 (epoch 20.395), train_loss = 0.79244984, grad/param norm = 1.5723e-01, time/batch = 17.6320s	
10321/25300 (epoch 20.397), train_loss = 0.83759283, grad/param norm = 2.3891e-01, time/batch = 16.6466s	
10322/25300 (epoch 20.399), train_loss = 0.81853882, grad/param norm = 2.2057e-01, time/batch = 16.3163s	
10323/25300 (epoch 20.401), train_loss = 1.04049478, grad/param norm = 2.1083e-01, time/batch = 15.6303s	
10324/25300 (epoch 20.403), train_loss = 0.95848710, grad/param norm = 2.3881e-01, time/batch = 15.8185s	
10325/25300 (epoch 20.405), train_loss = 0.93428731, grad/param norm = 1.8320e-01, time/batch = 16.9809s	
10326/25300 (epoch 20.407), train_loss = 0.92004877, grad/param norm = 1.9372e-01, time/batch = 16.6470s	
10327/25300 (epoch 20.409), train_loss = 0.86665589, grad/param norm = 1.7815e-01, time/batch = 15.5378s	
10328/25300 (epoch 20.411), train_loss = 0.87079715, grad/param norm = 1.9609e-01, time/batch = 16.1443s	
10329/25300 (epoch 20.413), train_loss = 0.80095774, grad/param norm = 1.7473e-01, time/batch = 17.1291s	
10330/25300 (epoch 20.415), train_loss = 0.83315703, grad/param norm = 1.9102e-01, time/batch = 16.4639s	
10331/25300 (epoch 20.417), train_loss = 0.79785498, grad/param norm = 1.7013e-01, time/batch = 17.0493s	
10332/25300 (epoch 20.419), train_loss = 0.73005478, grad/param norm = 1.5483e-01, time/batch = 17.3090s	
10333/25300 (epoch 20.421), train_loss = 0.82337417, grad/param norm = 1.6108e-01, time/batch = 16.6440s	
10334/25300 (epoch 20.423), train_loss = 0.82537388, grad/param norm = 1.8136e-01, time/batch = 16.1218s	
10335/25300 (epoch 20.425), train_loss = 0.90924520, grad/param norm = 2.0055e-01, time/batch = 16.2303s	
10336/25300 (epoch 20.427), train_loss = 1.10907867, grad/param norm = 2.1228e-01, time/batch = 15.9862s	
10337/25300 (epoch 20.429), train_loss = 1.01550248, grad/param norm = 1.9276e-01, time/batch = 15.4875s	
10338/25300 (epoch 20.431), train_loss = 0.98358847, grad/param norm = 1.8908e-01, time/batch = 16.9680s	
10339/25300 (epoch 20.433), train_loss = 0.92737843, grad/param norm = 1.7189e-01, time/batch = 15.0621s	
10340/25300 (epoch 20.435), train_loss = 0.86989635, grad/param norm = 2.1124e-01, time/batch = 15.8591s	
10341/25300 (epoch 20.437), train_loss = 0.89316839, grad/param norm = 1.9241e-01, time/batch = 19.0941s	
10342/25300 (epoch 20.439), train_loss = 0.96888210, grad/param norm = 1.9623e-01, time/batch = 25.7791s	
10343/25300 (epoch 20.441), train_loss = 0.99717151, grad/param norm = 2.0458e-01, time/batch = 17.6406s	
10344/25300 (epoch 20.443), train_loss = 1.17147585, grad/param norm = 2.2835e-01, time/batch = 15.5202s	
10345/25300 (epoch 20.445), train_loss = 1.12337632, grad/param norm = 2.2222e-01, time/batch = 15.2751s	
10346/25300 (epoch 20.447), train_loss = 0.85690122, grad/param norm = 1.7486e-01, time/batch = 15.3778s	
10347/25300 (epoch 20.449), train_loss = 0.77184157, grad/param norm = 1.7102e-01, time/batch = 15.5099s	
10348/25300 (epoch 20.451), train_loss = 1.14947182, grad/param norm = 2.0330e-01, time/batch = 15.5167s	
10349/25300 (epoch 20.453), train_loss = 1.02011736, grad/param norm = 2.1230e-01, time/batch = 15.4394s	
10350/25300 (epoch 20.455), train_loss = 1.02149504, grad/param norm = 2.0601e-01, time/batch = 16.0546s	
10351/25300 (epoch 20.457), train_loss = 0.88804528, grad/param norm = 1.8187e-01, time/batch = 15.7061s	
10352/25300 (epoch 20.458), train_loss = 0.92277066, grad/param norm = 1.9265e-01, time/batch = 16.0164s	
10353/25300 (epoch 20.460), train_loss = 0.95542823, grad/param norm = 2.0749e-01, time/batch = 16.2000s	
10354/25300 (epoch 20.462), train_loss = 0.71653157, grad/param norm = 1.7978e-01, time/batch = 16.4432s	
10355/25300 (epoch 20.464), train_loss = 1.01211765, grad/param norm = 2.0414e-01, time/batch = 16.3877s	
10356/25300 (epoch 20.466), train_loss = 0.99928561, grad/param norm = 1.8233e-01, time/batch = 15.5570s	
10357/25300 (epoch 20.468), train_loss = 1.01949285, grad/param norm = 2.3359e-01, time/batch = 15.9586s	
10358/25300 (epoch 20.470), train_loss = 0.90291201, grad/param norm = 1.8658e-01, time/batch = 15.8666s	
10359/25300 (epoch 20.472), train_loss = 0.81024507, grad/param norm = 1.7242e-01, time/batch = 16.1156s	
10360/25300 (epoch 20.474), train_loss = 0.95913700, grad/param norm = 1.8111e-01, time/batch = 16.2832s	
10361/25300 (epoch 20.476), train_loss = 0.91877409, grad/param norm = 1.9506e-01, time/batch = 15.9701s	
10362/25300 (epoch 20.478), train_loss = 1.01903077, grad/param norm = 2.1504e-01, time/batch = 15.4872s	
10363/25300 (epoch 20.480), train_loss = 0.88250693, grad/param norm = 1.8771e-01, time/batch = 15.5383s	
10364/25300 (epoch 20.482), train_loss = 1.00813145, grad/param norm = 2.2635e-01, time/batch = 16.7320s	
10365/25300 (epoch 20.484), train_loss = 1.03419651, grad/param norm = 2.1447e-01, time/batch = 16.0696s	
10366/25300 (epoch 20.486), train_loss = 0.94485346, grad/param norm = 1.8963e-01, time/batch = 16.1418s	
10367/25300 (epoch 20.488), train_loss = 1.10059376, grad/param norm = 2.0619e-01, time/batch = 15.8768s	
10368/25300 (epoch 20.490), train_loss = 1.00104199, grad/param norm = 1.9183e-01, time/batch = 15.6448s	
10369/25300 (epoch 20.492), train_loss = 0.97162264, grad/param norm = 1.8864e-01, time/batch = 15.8755s	
10370/25300 (epoch 20.494), train_loss = 0.88440631, grad/param norm = 1.7642e-01, time/batch = 16.3012s	
10371/25300 (epoch 20.496), train_loss = 0.96333493, grad/param norm = 1.8985e-01, time/batch = 15.4784s	
10372/25300 (epoch 20.498), train_loss = 0.87208779, grad/param norm = 1.7092e-01, time/batch = 15.9708s	
10373/25300 (epoch 20.500), train_loss = 1.07700758, grad/param norm = 2.0890e-01, time/batch = 16.9691s	
10374/25300 (epoch 20.502), train_loss = 0.98883109, grad/param norm = 2.1564e-01, time/batch = 15.9407s	
10375/25300 (epoch 20.504), train_loss = 0.91174721, grad/param norm = 1.9201e-01, time/batch = 15.5573s	
10376/25300 (epoch 20.506), train_loss = 0.86481153, grad/param norm = 1.8718e-01, time/batch = 16.4714s	
10377/25300 (epoch 20.508), train_loss = 0.95997576, grad/param norm = 2.1626e-01, time/batch = 17.5509s	
10378/25300 (epoch 20.510), train_loss = 0.86936610, grad/param norm = 1.8606e-01, time/batch = 15.3773s	
10379/25300 (epoch 20.512), train_loss = 0.72082475, grad/param norm = 1.8519e-01, time/batch = 16.4723s	
10380/25300 (epoch 20.514), train_loss = 0.93640984, grad/param norm = 1.8284e-01, time/batch = 15.8982s	
10381/25300 (epoch 20.516), train_loss = 0.99725244, grad/param norm = 1.9599e-01, time/batch = 16.6417s	
10382/25300 (epoch 20.518), train_loss = 1.05428705, grad/param norm = 2.1851e-01, time/batch = 15.5415s	
10383/25300 (epoch 20.520), train_loss = 0.78086680, grad/param norm = 1.5377e-01, time/batch = 16.7225s	
10384/25300 (epoch 20.522), train_loss = 0.87213517, grad/param norm = 1.7845e-01, time/batch = 15.8155s	
10385/25300 (epoch 20.524), train_loss = 0.88471068, grad/param norm = 1.7417e-01, time/batch = 15.1420s	
10386/25300 (epoch 20.526), train_loss = 1.11900206, grad/param norm = 2.1683e-01, time/batch = 17.0603s	
10387/25300 (epoch 20.528), train_loss = 1.10528721, grad/param norm = 2.1721e-01, time/batch = 16.1588s	
10388/25300 (epoch 20.530), train_loss = 0.97256549, grad/param norm = 2.3789e-01, time/batch = 16.4838s	
10389/25300 (epoch 20.532), train_loss = 0.95192346, grad/param norm = 1.9021e-01, time/batch = 16.4631s	
10390/25300 (epoch 20.534), train_loss = 0.92975755, grad/param norm = 2.0803e-01, time/batch = 15.8072s	
10391/25300 (epoch 20.536), train_loss = 0.75824047, grad/param norm = 1.7370e-01, time/batch = 15.6349s	
10392/25300 (epoch 20.538), train_loss = 0.81257696, grad/param norm = 1.5088e-01, time/batch = 16.3772s	
10393/25300 (epoch 20.540), train_loss = 0.87172903, grad/param norm = 1.8631e-01, time/batch = 16.1367s	
10394/25300 (epoch 20.542), train_loss = 0.83865381, grad/param norm = 1.6026e-01, time/batch = 16.5611s	
10395/25300 (epoch 20.543), train_loss = 0.79277601, grad/param norm = 1.7988e-01, time/batch = 15.4847s	
10396/25300 (epoch 20.545), train_loss = 1.22085676, grad/param norm = 2.8620e-01, time/batch = 15.9818s	
10397/25300 (epoch 20.547), train_loss = 1.02667865, grad/param norm = 2.1883e-01, time/batch = 15.3150s	
10398/25300 (epoch 20.549), train_loss = 1.20616691, grad/param norm = 2.5032e-01, time/batch = 15.6518s	
10399/25300 (epoch 20.551), train_loss = 1.02736562, grad/param norm = 2.0503e-01, time/batch = 16.6390s	
10400/25300 (epoch 20.553), train_loss = 0.88850431, grad/param norm = 1.9952e-01, time/batch = 15.5467s	
10401/25300 (epoch 20.555), train_loss = 1.04962243, grad/param norm = 2.1863e-01, time/batch = 17.5525s	
10402/25300 (epoch 20.557), train_loss = 1.07221854, grad/param norm = 1.9943e-01, time/batch = 17.3674s	
10403/25300 (epoch 20.559), train_loss = 1.04311786, grad/param norm = 2.0857e-01, time/batch = 15.3037s	
10404/25300 (epoch 20.561), train_loss = 1.09821776, grad/param norm = 2.0770e-01, time/batch = 15.6320s	
10405/25300 (epoch 20.563), train_loss = 1.04922356, grad/param norm = 1.9796e-01, time/batch = 17.2208s	
10406/25300 (epoch 20.565), train_loss = 0.82071971, grad/param norm = 1.7112e-01, time/batch = 15.8181s	
10407/25300 (epoch 20.567), train_loss = 0.72728086, grad/param norm = 1.6761e-01, time/batch = 15.6465s	
10408/25300 (epoch 20.569), train_loss = 0.93310275, grad/param norm = 1.8746e-01, time/batch = 15.9038s	
10409/25300 (epoch 20.571), train_loss = 1.02820804, grad/param norm = 1.9743e-01, time/batch = 15.5428s	
10410/25300 (epoch 20.573), train_loss = 0.95317049, grad/param norm = 1.9321e-01, time/batch = 16.5612s	
10411/25300 (epoch 20.575), train_loss = 1.07500651, grad/param norm = 2.0035e-01, time/batch = 15.7022s	
10412/25300 (epoch 20.577), train_loss = 0.98492418, grad/param norm = 2.1118e-01, time/batch = 16.8163s	
10413/25300 (epoch 20.579), train_loss = 1.10460591, grad/param norm = 2.1829e-01, time/batch = 15.9742s	
10414/25300 (epoch 20.581), train_loss = 1.02665284, grad/param norm = 2.1170e-01, time/batch = 16.9789s	
10415/25300 (epoch 20.583), train_loss = 0.79928635, grad/param norm = 1.9491e-01, time/batch = 15.7938s	
10416/25300 (epoch 20.585), train_loss = 0.80304934, grad/param norm = 1.8805e-01, time/batch = 16.2329s	
10417/25300 (epoch 20.587), train_loss = 0.92059716, grad/param norm = 1.7614e-01, time/batch = 15.6340s	
10418/25300 (epoch 20.589), train_loss = 0.83267710, grad/param norm = 1.6998e-01, time/batch = 16.7205s	
10419/25300 (epoch 20.591), train_loss = 0.85255226, grad/param norm = 2.1202e-01, time/batch = 16.1462s	
10420/25300 (epoch 20.593), train_loss = 1.00978100, grad/param norm = 1.9396e-01, time/batch = 17.3911s	
10421/25300 (epoch 20.595), train_loss = 0.93867047, grad/param norm = 1.9683e-01, time/batch = 15.9759s	
10422/25300 (epoch 20.597), train_loss = 0.81212404, grad/param norm = 1.6698e-01, time/batch = 15.4657s	
10423/25300 (epoch 20.599), train_loss = 0.98071973, grad/param norm = 1.8884e-01, time/batch = 16.3965s	
10424/25300 (epoch 20.601), train_loss = 0.96192069, grad/param norm = 2.0049e-01, time/batch = 16.3084s	
10425/25300 (epoch 20.603), train_loss = 0.94479262, grad/param norm = 2.0547e-01, time/batch = 16.2255s	
10426/25300 (epoch 20.605), train_loss = 0.85854562, grad/param norm = 2.0100e-01, time/batch = 15.9462s	
10427/25300 (epoch 20.607), train_loss = 0.71142279, grad/param norm = 1.6224e-01, time/batch = 15.7148s	
10428/25300 (epoch 20.609), train_loss = 0.91315021, grad/param norm = 1.7571e-01, time/batch = 16.3726s	
10429/25300 (epoch 20.611), train_loss = 0.97295245, grad/param norm = 2.0560e-01, time/batch = 15.9747s	
10430/25300 (epoch 20.613), train_loss = 0.80858694, grad/param norm = 1.7517e-01, time/batch = 15.9104s	
10431/25300 (epoch 20.615), train_loss = 0.91875510, grad/param norm = 1.9965e-01, time/batch = 16.1509s	
10432/25300 (epoch 20.617), train_loss = 0.94292261, grad/param norm = 1.8937e-01, time/batch = 17.1306s	
10433/25300 (epoch 20.619), train_loss = 1.01133448, grad/param norm = 1.9286e-01, time/batch = 16.3802s	
10434/25300 (epoch 20.621), train_loss = 1.04956916, grad/param norm = 2.1476e-01, time/batch = 16.2209s	
10435/25300 (epoch 20.623), train_loss = 0.87988022, grad/param norm = 1.8741e-01, time/batch = 16.8066s	
10436/25300 (epoch 20.625), train_loss = 0.75329747, grad/param norm = 1.6606e-01, time/batch = 16.9030s	
10437/25300 (epoch 20.626), train_loss = 0.91029242, grad/param norm = 1.7132e-01, time/batch = 16.4745s	
10438/25300 (epoch 20.628), train_loss = 1.01269683, grad/param norm = 2.0367e-01, time/batch = 16.9617s	
10439/25300 (epoch 20.630), train_loss = 0.99867790, grad/param norm = 2.2529e-01, time/batch = 16.7909s	
10440/25300 (epoch 20.632), train_loss = 0.97358830, grad/param norm = 2.1268e-01, time/batch = 16.7196s	
10441/25300 (epoch 20.634), train_loss = 1.04159874, grad/param norm = 2.2983e-01, time/batch = 17.3014s	
10442/25300 (epoch 20.636), train_loss = 0.87579240, grad/param norm = 1.7714e-01, time/batch = 16.5554s	
10443/25300 (epoch 20.638), train_loss = 0.98723518, grad/param norm = 2.2168e-01, time/batch = 16.1507s	
10444/25300 (epoch 20.640), train_loss = 1.13494540, grad/param norm = 2.2117e-01, time/batch = 15.4687s	
10445/25300 (epoch 20.642), train_loss = 1.01279313, grad/param norm = 2.2005e-01, time/batch = 16.0774s	
10446/25300 (epoch 20.644), train_loss = 0.97524979, grad/param norm = 2.0772e-01, time/batch = 16.0527s	
10447/25300 (epoch 20.646), train_loss = 0.88990315, grad/param norm = 1.9802e-01, time/batch = 16.3175s	
10448/25300 (epoch 20.648), train_loss = 1.03498450, grad/param norm = 1.9043e-01, time/batch = 15.5608s	
10449/25300 (epoch 20.650), train_loss = 1.00755509, grad/param norm = 2.2582e-01, time/batch = 15.5774s	
10450/25300 (epoch 20.652), train_loss = 0.97497816, grad/param norm = 2.0899e-01, time/batch = 17.2196s	
10451/25300 (epoch 20.654), train_loss = 1.10237890, grad/param norm = 2.0781e-01, time/batch = 16.0512s	
10452/25300 (epoch 20.656), train_loss = 1.02482285, grad/param norm = 2.2294e-01, time/batch = 16.7306s	
10453/25300 (epoch 20.658), train_loss = 0.80311806, grad/param norm = 1.6802e-01, time/batch = 16.2046s	
10454/25300 (epoch 20.660), train_loss = 0.83456409, grad/param norm = 1.8517e-01, time/batch = 16.2307s	
10455/25300 (epoch 20.662), train_loss = 0.81754045, grad/param norm = 1.8141e-01, time/batch = 16.3762s	
10456/25300 (epoch 20.664), train_loss = 0.79845445, grad/param norm = 1.7741e-01, time/batch = 15.9690s	
10457/25300 (epoch 20.666), train_loss = 0.83203764, grad/param norm = 1.9831e-01, time/batch = 16.2392s	
10458/25300 (epoch 20.668), train_loss = 0.92628210, grad/param norm = 2.3389e-01, time/batch = 16.2324s	
10459/25300 (epoch 20.670), train_loss = 0.83622819, grad/param norm = 2.0569e-01, time/batch = 15.6277s	
10460/25300 (epoch 20.672), train_loss = 0.81320087, grad/param norm = 1.7541e-01, time/batch = 17.0584s	
10461/25300 (epoch 20.674), train_loss = 0.85415681, grad/param norm = 1.7338e-01, time/batch = 16.6482s	
10462/25300 (epoch 20.676), train_loss = 0.90323846, grad/param norm = 2.0790e-01, time/batch = 16.7925s	
10463/25300 (epoch 20.678), train_loss = 0.89858185, grad/param norm = 2.1409e-01, time/batch = 16.0366s	
10464/25300 (epoch 20.680), train_loss = 0.76394997, grad/param norm = 1.6676e-01, time/batch = 16.0667s	
10465/25300 (epoch 20.682), train_loss = 0.65133589, grad/param norm = 1.5378e-01, time/batch = 16.2978s	
10466/25300 (epoch 20.684), train_loss = 0.82334018, grad/param norm = 1.6057e-01, time/batch = 15.3011s	
10467/25300 (epoch 20.686), train_loss = 0.79916527, grad/param norm = 1.6629e-01, time/batch = 16.0686s	
10468/25300 (epoch 20.688), train_loss = 0.89604481, grad/param norm = 1.9604e-01, time/batch = 15.3728s	
10469/25300 (epoch 20.690), train_loss = 0.79919035, grad/param norm = 1.5619e-01, time/batch = 16.9871s	
10470/25300 (epoch 20.692), train_loss = 0.86594877, grad/param norm = 1.7443e-01, time/batch = 15.3030s	
10471/25300 (epoch 20.694), train_loss = 0.84767207, grad/param norm = 1.7587e-01, time/batch = 16.1332s	
10472/25300 (epoch 20.696), train_loss = 0.94858973, grad/param norm = 2.0579e-01, time/batch = 16.8808s	
10473/25300 (epoch 20.698), train_loss = 0.97413895, grad/param norm = 1.8593e-01, time/batch = 16.0453s	
10474/25300 (epoch 20.700), train_loss = 0.73651965, grad/param norm = 1.6939e-01, time/batch = 16.4697s	
10475/25300 (epoch 20.702), train_loss = 1.02394246, grad/param norm = 2.0314e-01, time/batch = 16.8852s	
10476/25300 (epoch 20.704), train_loss = 0.75798641, grad/param norm = 1.9001e-01, time/batch = 17.7148s	
10477/25300 (epoch 20.706), train_loss = 0.94506860, grad/param norm = 2.1550e-01, time/batch = 15.7127s	
10478/25300 (epoch 20.708), train_loss = 0.77955039, grad/param norm = 1.6706e-01, time/batch = 16.6378s	
10479/25300 (epoch 20.709), train_loss = 1.09145002, grad/param norm = 2.0981e-01, time/batch = 16.1226s	
10480/25300 (epoch 20.711), train_loss = 1.08997631, grad/param norm = 2.0696e-01, time/batch = 16.6392s	
10481/25300 (epoch 20.713), train_loss = 0.89827479, grad/param norm = 1.7132e-01, time/batch = 15.6325s	
10482/25300 (epoch 20.715), train_loss = 0.90416917, grad/param norm = 1.7150e-01, time/batch = 17.2926s	
10483/25300 (epoch 20.717), train_loss = 0.83498810, grad/param norm = 1.9865e-01, time/batch = 16.2139s	
10484/25300 (epoch 20.719), train_loss = 0.92768838, grad/param norm = 2.2548e-01, time/batch = 16.3958s	
10485/25300 (epoch 20.721), train_loss = 0.95106842, grad/param norm = 1.9546e-01, time/batch = 16.4022s	
10486/25300 (epoch 20.723), train_loss = 0.88424866, grad/param norm = 1.8221e-01, time/batch = 18.1314s	
10487/25300 (epoch 20.725), train_loss = 0.95194060, grad/param norm = 1.8587e-01, time/batch = 16.7337s	
10488/25300 (epoch 20.727), train_loss = 0.95331624, grad/param norm = 1.9387e-01, time/batch = 15.8865s	
10489/25300 (epoch 20.729), train_loss = 0.93246302, grad/param norm = 1.8497e-01, time/batch = 15.4684s	
10490/25300 (epoch 20.731), train_loss = 1.08170289, grad/param norm = 1.9908e-01, time/batch = 15.5640s	
10491/25300 (epoch 20.733), train_loss = 0.90785986, grad/param norm = 1.6600e-01, time/batch = 16.3764s	
10492/25300 (epoch 20.735), train_loss = 1.20113098, grad/param norm = 2.1011e-01, time/batch = 16.5596s	
10493/25300 (epoch 20.737), train_loss = 0.81016479, grad/param norm = 1.8754e-01, time/batch = 16.0726s	
10494/25300 (epoch 20.739), train_loss = 1.07079921, grad/param norm = 1.9820e-01, time/batch = 16.2167s	
10495/25300 (epoch 20.741), train_loss = 0.99452835, grad/param norm = 2.1146e-01, time/batch = 16.1232s	
10496/25300 (epoch 20.743), train_loss = 0.90836889, grad/param norm = 1.9236e-01, time/batch = 16.3149s	
10497/25300 (epoch 20.745), train_loss = 0.86689024, grad/param norm = 1.8374e-01, time/batch = 16.3922s	
10498/25300 (epoch 20.747), train_loss = 0.84430466, grad/param norm = 1.7491e-01, time/batch = 16.2399s	
10499/25300 (epoch 20.749), train_loss = 0.95639279, grad/param norm = 1.8272e-01, time/batch = 16.3867s	
10500/25300 (epoch 20.751), train_loss = 1.02101084, grad/param norm = 1.9435e-01, time/batch = 16.7990s	
10501/25300 (epoch 20.753), train_loss = 0.83341312, grad/param norm = 1.8645e-01, time/batch = 16.6472s	
10502/25300 (epoch 20.755), train_loss = 1.05271985, grad/param norm = 2.1757e-01, time/batch = 15.3816s	
10503/25300 (epoch 20.757), train_loss = 0.87368021, grad/param norm = 2.0109e-01, time/batch = 16.0517s	
10504/25300 (epoch 20.759), train_loss = 0.85190991, grad/param norm = 1.9045e-01, time/batch = 15.8272s	
10505/25300 (epoch 20.761), train_loss = 1.08506977, grad/param norm = 1.9477e-01, time/batch = 15.9753s	
10506/25300 (epoch 20.763), train_loss = 0.86887273, grad/param norm = 1.7419e-01, time/batch = 16.4658s	
10507/25300 (epoch 20.765), train_loss = 0.90484446, grad/param norm = 2.0827e-01, time/batch = 15.0447s	
10508/25300 (epoch 20.767), train_loss = 0.87942070, grad/param norm = 1.8347e-01, time/batch = 15.1972s	
10509/25300 (epoch 20.769), train_loss = 0.95763840, grad/param norm = 2.2045e-01, time/batch = 15.2037s	
10510/25300 (epoch 20.771), train_loss = 1.05579686, grad/param norm = 2.2398e-01, time/batch = 15.2840s	
10511/25300 (epoch 20.773), train_loss = 1.06011676, grad/param norm = 2.1801e-01, time/batch = 15.1142s	
10512/25300 (epoch 20.775), train_loss = 0.91449949, grad/param norm = 1.8210e-01, time/batch = 15.2426s	
10513/25300 (epoch 20.777), train_loss = 0.92673367, grad/param norm = 1.9160e-01, time/batch = 15.1058s	
10514/25300 (epoch 20.779), train_loss = 1.01118884, grad/param norm = 1.8306e-01, time/batch = 15.0928s	
10515/25300 (epoch 20.781), train_loss = 0.97664649, grad/param norm = 1.8279e-01, time/batch = 16.0350s	
10516/25300 (epoch 20.783), train_loss = 1.06295315, grad/param norm = 1.9374e-01, time/batch = 16.0529s	
10517/25300 (epoch 20.785), train_loss = 1.03004459, grad/param norm = 1.9756e-01, time/batch = 15.2958s	
10518/25300 (epoch 20.787), train_loss = 1.02368848, grad/param norm = 2.0191e-01, time/batch = 15.1377s	
10519/25300 (epoch 20.789), train_loss = 1.16951265, grad/param norm = 2.2201e-01, time/batch = 15.8867s	
10520/25300 (epoch 20.791), train_loss = 1.00534032, grad/param norm = 1.9838e-01, time/batch = 15.4850s	
10521/25300 (epoch 20.792), train_loss = 1.04771061, grad/param norm = 1.9045e-01, time/batch = 16.0476s	
10522/25300 (epoch 20.794), train_loss = 0.95056884, grad/param norm = 2.0907e-01, time/batch = 16.4518s	
10523/25300 (epoch 20.796), train_loss = 0.88407000, grad/param norm = 2.0286e-01, time/batch = 16.0558s	
10524/25300 (epoch 20.798), train_loss = 1.05427771, grad/param norm = 2.1208e-01, time/batch = 17.3720s	
10525/25300 (epoch 20.800), train_loss = 0.90938454, grad/param norm = 1.8959e-01, time/batch = 15.8779s	
10526/25300 (epoch 20.802), train_loss = 0.77025361, grad/param norm = 1.8950e-01, time/batch = 15.9842s	
10527/25300 (epoch 20.804), train_loss = 0.93473890, grad/param norm = 1.7752e-01, time/batch = 15.5544s	
10528/25300 (epoch 20.806), train_loss = 1.02147260, grad/param norm = 2.0487e-01, time/batch = 15.6346s	
10529/25300 (epoch 20.808), train_loss = 1.02333378, grad/param norm = 2.1001e-01, time/batch = 15.6389s	
10530/25300 (epoch 20.810), train_loss = 0.94985913, grad/param norm = 2.2837e-01, time/batch = 16.4678s	
10531/25300 (epoch 20.812), train_loss = 1.05438490, grad/param norm = 1.8951e-01, time/batch = 15.7275s	
10532/25300 (epoch 20.814), train_loss = 1.10297508, grad/param norm = 2.2328e-01, time/batch = 16.5301s	
10533/25300 (epoch 20.816), train_loss = 1.20501673, grad/param norm = 2.2926e-01, time/batch = 15.0500s	
10534/25300 (epoch 20.818), train_loss = 0.98573495, grad/param norm = 1.7296e-01, time/batch = 15.6499s	
10535/25300 (epoch 20.820), train_loss = 1.02628215, grad/param norm = 2.0601e-01, time/batch = 15.2874s	
10536/25300 (epoch 20.822), train_loss = 0.91622452, grad/param norm = 1.7219e-01, time/batch = 15.7388s	
10537/25300 (epoch 20.824), train_loss = 1.06293152, grad/param norm = 2.0917e-01, time/batch = 16.1211s	
10538/25300 (epoch 20.826), train_loss = 0.90877582, grad/param norm = 1.9829e-01, time/batch = 15.4135s	
10539/25300 (epoch 20.828), train_loss = 0.88419924, grad/param norm = 1.9975e-01, time/batch = 15.6182s	
10540/25300 (epoch 20.830), train_loss = 0.95039055, grad/param norm = 1.8610e-01, time/batch = 15.6099s	
10541/25300 (epoch 20.832), train_loss = 1.01746057, grad/param norm = 1.9546e-01, time/batch = 15.7072s	
10542/25300 (epoch 20.834), train_loss = 0.83022632, grad/param norm = 1.7454e-01, time/batch = 16.3761s	
10543/25300 (epoch 20.836), train_loss = 0.92872563, grad/param norm = 1.8516e-01, time/batch = 17.5407s	
10544/25300 (epoch 20.838), train_loss = 0.92368128, grad/param norm = 1.8639e-01, time/batch = 16.0422s	
10545/25300 (epoch 20.840), train_loss = 1.06891367, grad/param norm = 2.0356e-01, time/batch = 15.8096s	
10546/25300 (epoch 20.842), train_loss = 0.96625273, grad/param norm = 2.0660e-01, time/batch = 15.9679s	
10547/25300 (epoch 20.844), train_loss = 1.01723746, grad/param norm = 1.8565e-01, time/batch = 16.3814s	
10548/25300 (epoch 20.846), train_loss = 1.01502288, grad/param norm = 1.8201e-01, time/batch = 16.5409s	
10549/25300 (epoch 20.848), train_loss = 1.05951316, grad/param norm = 2.2042e-01, time/batch = 16.9580s	
10550/25300 (epoch 20.850), train_loss = 1.01007246, grad/param norm = 1.9514e-01, time/batch = 17.2093s	
10551/25300 (epoch 20.852), train_loss = 1.04390875, grad/param norm = 2.0410e-01, time/batch = 16.0366s	
10552/25300 (epoch 20.854), train_loss = 1.11188070, grad/param norm = 2.0014e-01, time/batch = 15.7943s	
10553/25300 (epoch 20.856), train_loss = 0.95848929, grad/param norm = 2.1136e-01, time/batch = 16.8901s	
10554/25300 (epoch 20.858), train_loss = 0.99735923, grad/param norm = 2.1403e-01, time/batch = 16.9628s	
10555/25300 (epoch 20.860), train_loss = 0.81810639, grad/param norm = 1.7638e-01, time/batch = 16.0530s	
10556/25300 (epoch 20.862), train_loss = 0.95796033, grad/param norm = 2.3309e-01, time/batch = 16.0567s	
10557/25300 (epoch 20.864), train_loss = 1.04582758, grad/param norm = 2.1205e-01, time/batch = 15.8117s	
10558/25300 (epoch 20.866), train_loss = 0.95814399, grad/param norm = 2.0732e-01, time/batch = 16.1162s	
10559/25300 (epoch 20.868), train_loss = 1.08559362, grad/param norm = 1.9596e-01, time/batch = 15.8685s	
10560/25300 (epoch 20.870), train_loss = 1.04536474, grad/param norm = 1.7110e-01, time/batch = 16.0536s	
10561/25300 (epoch 20.872), train_loss = 1.02588492, grad/param norm = 2.1249e-01, time/batch = 16.1507s	
10562/25300 (epoch 20.874), train_loss = 1.02578319, grad/param norm = 1.9666e-01, time/batch = 18.6833s	
10563/25300 (epoch 20.875), train_loss = 0.94665674, grad/param norm = 2.0107e-01, time/batch = 25.4246s	
10564/25300 (epoch 20.877), train_loss = 0.94627693, grad/param norm = 1.8502e-01, time/batch = 14.9668s	
10565/25300 (epoch 20.879), train_loss = 0.93950766, grad/param norm = 2.0893e-01, time/batch = 15.5410s	
10566/25300 (epoch 20.881), train_loss = 1.27520843, grad/param norm = 2.6123e-01, time/batch = 15.6082s	
10567/25300 (epoch 20.883), train_loss = 1.21086531, grad/param norm = 2.1527e-01, time/batch = 15.5534s	
10568/25300 (epoch 20.885), train_loss = 1.08207057, grad/param norm = 2.3481e-01, time/batch = 15.5559s	
10569/25300 (epoch 20.887), train_loss = 1.04577383, grad/param norm = 2.1002e-01, time/batch = 15.0405s	
10570/25300 (epoch 20.889), train_loss = 1.15678865, grad/param norm = 2.9685e-01, time/batch = 15.8802s	
10571/25300 (epoch 20.891), train_loss = 1.07979827, grad/param norm = 3.5381e-01, time/batch = 15.4642s	
10572/25300 (epoch 20.893), train_loss = 1.08678652, grad/param norm = 2.4191e-01, time/batch = 15.4684s	
10573/25300 (epoch 20.895), train_loss = 0.76430828, grad/param norm = 1.8765e-01, time/batch = 15.4538s	
10574/25300 (epoch 20.897), train_loss = 0.89117524, grad/param norm = 1.8840e-01, time/batch = 16.5558s	
10575/25300 (epoch 20.899), train_loss = 1.00221653, grad/param norm = 1.9582e-01, time/batch = 16.9681s	
10576/25300 (epoch 20.901), train_loss = 1.03405170, grad/param norm = 2.0567e-01, time/batch = 15.5364s	
10577/25300 (epoch 20.903), train_loss = 0.77975388, grad/param norm = 1.8865e-01, time/batch = 15.8033s	
10578/25300 (epoch 20.905), train_loss = 0.91277915, grad/param norm = 2.0460e-01, time/batch = 16.8008s	
10579/25300 (epoch 20.907), train_loss = 0.92429122, grad/param norm = 2.0733e-01, time/batch = 17.1418s	
10580/25300 (epoch 20.909), train_loss = 1.02319014, grad/param norm = 1.8203e-01, time/batch = 16.4504s	
10581/25300 (epoch 20.911), train_loss = 1.11315761, grad/param norm = 2.2390e-01, time/batch = 15.8828s	
10582/25300 (epoch 20.913), train_loss = 1.19477023, grad/param norm = 2.3415e-01, time/batch = 16.3092s	
10583/25300 (epoch 20.915), train_loss = 0.92804958, grad/param norm = 2.1937e-01, time/batch = 15.3190s	
10584/25300 (epoch 20.917), train_loss = 1.07982936, grad/param norm = 2.3134e-01, time/batch = 16.2756s	
10585/25300 (epoch 20.919), train_loss = 1.11438430, grad/param norm = 2.1210e-01, time/batch = 15.9883s	
10586/25300 (epoch 20.921), train_loss = 0.88155357, grad/param norm = 1.8692e-01, time/batch = 16.4784s	
10587/25300 (epoch 20.923), train_loss = 1.10893874, grad/param norm = 1.9308e-01, time/batch = 16.6433s	
10588/25300 (epoch 20.925), train_loss = 0.96232602, grad/param norm = 2.0733e-01, time/batch = 15.3032s	
10589/25300 (epoch 20.927), train_loss = 0.93592736, grad/param norm = 1.8086e-01, time/batch = 16.0645s	
10590/25300 (epoch 20.929), train_loss = 0.98420727, grad/param norm = 1.8604e-01, time/batch = 15.7352s	
10591/25300 (epoch 20.931), train_loss = 1.05155377, grad/param norm = 2.1251e-01, time/batch = 17.0367s	
10592/25300 (epoch 20.933), train_loss = 1.02102377, grad/param norm = 1.9607e-01, time/batch = 15.7128s	
10593/25300 (epoch 20.935), train_loss = 1.00742470, grad/param norm = 1.8411e-01, time/batch = 16.4864s	
10594/25300 (epoch 20.937), train_loss = 0.75064906, grad/param norm = 1.6335e-01, time/batch = 15.8258s	
10595/25300 (epoch 20.939), train_loss = 1.04326173, grad/param norm = 2.0904e-01, time/batch = 15.9786s	
10596/25300 (epoch 20.941), train_loss = 0.89911588, grad/param norm = 1.8081e-01, time/batch = 16.1301s	
10597/25300 (epoch 20.943), train_loss = 1.00360475, grad/param norm = 1.8884e-01, time/batch = 15.7256s	
10598/25300 (epoch 20.945), train_loss = 1.03208706, grad/param norm = 1.9806e-01, time/batch = 16.1378s	
10599/25300 (epoch 20.947), train_loss = 0.88023163, grad/param norm = 1.7303e-01, time/batch = 15.6364s	
10600/25300 (epoch 20.949), train_loss = 1.04071561, grad/param norm = 1.8184e-01, time/batch = 15.9708s	
10601/25300 (epoch 20.951), train_loss = 0.96555526, grad/param norm = 1.8264e-01, time/batch = 15.6603s	
10602/25300 (epoch 20.953), train_loss = 0.97532653, grad/param norm = 1.8734e-01, time/batch = 16.4804s	
10603/25300 (epoch 20.955), train_loss = 1.20870760, grad/param norm = 2.3723e-01, time/batch = 16.2312s	
10604/25300 (epoch 20.957), train_loss = 1.14699753, grad/param norm = 2.3631e-01, time/batch = 16.0776s	
10605/25300 (epoch 20.958), train_loss = 1.06115637, grad/param norm = 2.2551e-01, time/batch = 16.4946s	
10606/25300 (epoch 20.960), train_loss = 1.18733741, grad/param norm = 2.2267e-01, time/batch = 17.4581s	
10607/25300 (epoch 20.962), train_loss = 1.14690492, grad/param norm = 2.2329e-01, time/batch = 15.5595s	
10608/25300 (epoch 20.964), train_loss = 1.05060239, grad/param norm = 2.2229e-01, time/batch = 17.9677s	
10609/25300 (epoch 20.966), train_loss = 0.84527893, grad/param norm = 1.7700e-01, time/batch = 16.3929s	
10610/25300 (epoch 20.968), train_loss = 0.83078122, grad/param norm = 1.8507e-01, time/batch = 15.3650s	
10611/25300 (epoch 20.970), train_loss = 0.94046671, grad/param norm = 2.1432e-01, time/batch = 16.8898s	
10612/25300 (epoch 20.972), train_loss = 0.97453927, grad/param norm = 1.9660e-01, time/batch = 16.4732s	
10613/25300 (epoch 20.974), train_loss = 1.15576321, grad/param norm = 2.2859e-01, time/batch = 16.6405s	
10614/25300 (epoch 20.976), train_loss = 1.03026857, grad/param norm = 1.9042e-01, time/batch = 16.0415s	
10615/25300 (epoch 20.978), train_loss = 0.97292230, grad/param norm = 1.9958e-01, time/batch = 16.2875s	
10616/25300 (epoch 20.980), train_loss = 1.01510105, grad/param norm = 2.3472e-01, time/batch = 16.4755s	
10617/25300 (epoch 20.982), train_loss = 0.93865550, grad/param norm = 1.8745e-01, time/batch = 16.5399s	
10618/25300 (epoch 20.984), train_loss = 0.97115884, grad/param norm = 2.2071e-01, time/batch = 16.3064s	
10619/25300 (epoch 20.986), train_loss = 1.08194563, grad/param norm = 2.1153e-01, time/batch = 17.1486s	
10620/25300 (epoch 20.988), train_loss = 1.02256481, grad/param norm = 2.0851e-01, time/batch = 15.6444s	
10621/25300 (epoch 20.990), train_loss = 0.96922955, grad/param norm = 1.8298e-01, time/batch = 15.4615s	
10622/25300 (epoch 20.992), train_loss = 0.83223413, grad/param norm = 1.7879e-01, time/batch = 16.5569s	
10623/25300 (epoch 20.994), train_loss = 0.99893593, grad/param norm = 2.0992e-01, time/batch = 18.2997s	
10624/25300 (epoch 20.996), train_loss = 1.13147943, grad/param norm = 2.2939e-01, time/batch = 17.1225s	
10625/25300 (epoch 20.998), train_loss = 1.11662322, grad/param norm = 2.1683e-01, time/batch = 17.0552s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
10626/25300 (epoch 21.000), train_loss = 1.00256258, grad/param norm = 2.0275e-01, time/batch = 16.4674s	
10627/25300 (epoch 21.002), train_loss = 0.87476201, grad/param norm = 1.7501e-01, time/batch = 18.2932s	
10628/25300 (epoch 21.004), train_loss = 0.81678785, grad/param norm = 1.7497e-01, time/batch = 15.5537s	
10629/25300 (epoch 21.006), train_loss = 1.11569074, grad/param norm = 1.8409e-01, time/batch = 17.5557s	
10630/25300 (epoch 21.008), train_loss = 0.95801552, grad/param norm = 1.7081e-01, time/batch = 17.3938s	
10631/25300 (epoch 21.010), train_loss = 0.99964593, grad/param norm = 1.9002e-01, time/batch = 16.5215s	
10632/25300 (epoch 21.012), train_loss = 0.92070394, grad/param norm = 1.8740e-01, time/batch = 16.1537s	
10633/25300 (epoch 21.014), train_loss = 1.12139634, grad/param norm = 1.9533e-01, time/batch = 15.9693s	
10634/25300 (epoch 21.016), train_loss = 0.99733791, grad/param norm = 2.0818e-01, time/batch = 16.8166s	
10635/25300 (epoch 21.018), train_loss = 0.86668179, grad/param norm = 1.8148e-01, time/batch = 17.4455s	
10636/25300 (epoch 21.020), train_loss = 0.95049184, grad/param norm = 1.8619e-01, time/batch = 15.8102s	
10637/25300 (epoch 21.022), train_loss = 1.00047476, grad/param norm = 2.4984e-01, time/batch = 17.2988s	
10638/25300 (epoch 21.024), train_loss = 0.73704186, grad/param norm = 1.5172e-01, time/batch = 18.0446s	
10639/25300 (epoch 21.026), train_loss = 0.93364435, grad/param norm = 2.0290e-01, time/batch = 15.6429s	
10640/25300 (epoch 21.028), train_loss = 0.88668562, grad/param norm = 1.8790e-01, time/batch = 15.9053s	
10641/25300 (epoch 21.030), train_loss = 1.07868281, grad/param norm = 1.9499e-01, time/batch = 16.9816s	
10642/25300 (epoch 21.032), train_loss = 0.92231263, grad/param norm = 1.8556e-01, time/batch = 16.9645s	
10643/25300 (epoch 21.034), train_loss = 0.84186826, grad/param norm = 1.9919e-01, time/batch = 15.9918s	
10644/25300 (epoch 21.036), train_loss = 0.80420778, grad/param norm = 1.6233e-01, time/batch = 15.7355s	
10645/25300 (epoch 21.038), train_loss = 0.73569685, grad/param norm = 1.6036e-01, time/batch = 15.4750s	
10646/25300 (epoch 21.040), train_loss = 0.98421439, grad/param norm = 1.9341e-01, time/batch = 15.7943s	
10647/25300 (epoch 21.042), train_loss = 0.92490009, grad/param norm = 1.7880e-01, time/batch = 16.5636s	
10648/25300 (epoch 21.043), train_loss = 0.79550879, grad/param norm = 1.6145e-01, time/batch = 17.0355s	
10649/25300 (epoch 21.045), train_loss = 0.81175676, grad/param norm = 1.5104e-01, time/batch = 15.7879s	
10650/25300 (epoch 21.047), train_loss = 1.02300889, grad/param norm = 1.9535e-01, time/batch = 16.6312s	
10651/25300 (epoch 21.049), train_loss = 0.98763794, grad/param norm = 2.1990e-01, time/batch = 16.3175s	
10652/25300 (epoch 21.051), train_loss = 1.06154102, grad/param norm = 2.1544e-01, time/batch = 16.9591s	
10653/25300 (epoch 21.053), train_loss = 0.78537315, grad/param norm = 1.8062e-01, time/batch = 16.8782s	
10654/25300 (epoch 21.055), train_loss = 0.83551157, grad/param norm = 1.6958e-01, time/batch = 16.1580s	
10655/25300 (epoch 21.057), train_loss = 0.80628267, grad/param norm = 1.7017e-01, time/batch = 16.3951s	
10656/25300 (epoch 21.059), train_loss = 0.89552810, grad/param norm = 1.7493e-01, time/batch = 18.2955s	
10657/25300 (epoch 21.061), train_loss = 0.87667459, grad/param norm = 1.8873e-01, time/batch = 16.4647s	
10658/25300 (epoch 21.063), train_loss = 0.85529590, grad/param norm = 1.7531e-01, time/batch = 15.8130s	
10659/25300 (epoch 21.065), train_loss = 1.00389296, grad/param norm = 1.9371e-01, time/batch = 15.6561s	
10660/25300 (epoch 21.067), train_loss = 1.04829793, grad/param norm = 1.7969e-01, time/batch = 15.8138s	
10661/25300 (epoch 21.069), train_loss = 0.89775746, grad/param norm = 1.9122e-01, time/batch = 15.9703s	
10662/25300 (epoch 21.071), train_loss = 1.07539834, grad/param norm = 2.0477e-01, time/batch = 16.8952s	
10663/25300 (epoch 21.073), train_loss = 0.87548278, grad/param norm = 1.5400e-01, time/batch = 16.5602s	
10664/25300 (epoch 21.075), train_loss = 1.01288497, grad/param norm = 1.9854e-01, time/batch = 15.7816s	
10665/25300 (epoch 21.077), train_loss = 0.99328359, grad/param norm = 2.0338e-01, time/batch = 17.9805s	
10666/25300 (epoch 21.079), train_loss = 0.91734247, grad/param norm = 1.8660e-01, time/batch = 17.3038s	
10667/25300 (epoch 21.081), train_loss = 0.93757991, grad/param norm = 1.7218e-01, time/batch = 16.9784s	
10668/25300 (epoch 21.083), train_loss = 0.94038850, grad/param norm = 1.7710e-01, time/batch = 17.5340s	
10669/25300 (epoch 21.085), train_loss = 1.16019883, grad/param norm = 2.3040e-01, time/batch = 18.9655s	
10670/25300 (epoch 21.087), train_loss = 1.03697309, grad/param norm = 1.8816e-01, time/batch = 19.5161s	
10671/25300 (epoch 21.089), train_loss = 1.01843230, grad/param norm = 1.9302e-01, time/batch = 16.5247s	
10672/25300 (epoch 21.091), train_loss = 1.13806249, grad/param norm = 2.0440e-01, time/batch = 16.8703s	
10673/25300 (epoch 21.093), train_loss = 1.07196838, grad/param norm = 2.1496e-01, time/batch = 16.1086s	
10674/25300 (epoch 21.095), train_loss = 1.04829351, grad/param norm = 1.9376e-01, time/batch = 15.6799s	
10675/25300 (epoch 21.097), train_loss = 1.00522835, grad/param norm = 1.9054e-01, time/batch = 15.5879s	
10676/25300 (epoch 21.099), train_loss = 1.00860315, grad/param norm = 1.9724e-01, time/batch = 15.4157s	
10677/25300 (epoch 21.101), train_loss = 0.94431530, grad/param norm = 2.0502e-01, time/batch = 15.5029s	
10678/25300 (epoch 21.103), train_loss = 0.96915027, grad/param norm = 1.8280e-01, time/batch = 15.4130s	
10679/25300 (epoch 21.105), train_loss = 1.03635249, grad/param norm = 1.8480e-01, time/batch = 17.3631s	
10680/25300 (epoch 21.107), train_loss = 1.05629452, grad/param norm = 2.2824e-01, time/batch = 16.7054s	
10681/25300 (epoch 21.109), train_loss = 0.97685579, grad/param norm = 2.1158e-01, time/batch = 15.9608s	
10682/25300 (epoch 21.111), train_loss = 0.94260460, grad/param norm = 1.8112e-01, time/batch = 15.4778s	
10683/25300 (epoch 21.113), train_loss = 0.92329326, grad/param norm = 2.2175e-01, time/batch = 16.8824s	
10684/25300 (epoch 21.115), train_loss = 0.95287013, grad/param norm = 1.9839e-01, time/batch = 15.8875s	
10685/25300 (epoch 21.117), train_loss = 1.03230505, grad/param norm = 1.8315e-01, time/batch = 17.9454s	
10686/25300 (epoch 21.119), train_loss = 0.92060731, grad/param norm = 2.0380e-01, time/batch = 17.3024s	
10687/25300 (epoch 21.121), train_loss = 1.00254253, grad/param norm = 2.2531e-01, time/batch = 18.2903s	
10688/25300 (epoch 21.123), train_loss = 0.92110513, grad/param norm = 1.9802e-01, time/batch = 16.4317s	
10689/25300 (epoch 21.125), train_loss = 1.04744435, grad/param norm = 1.9276e-01, time/batch = 16.1144s	
10690/25300 (epoch 21.126), train_loss = 0.94336287, grad/param norm = 1.9977e-01, time/batch = 16.6348s	
10691/25300 (epoch 21.128), train_loss = 0.95340533, grad/param norm = 1.9687e-01, time/batch = 16.7408s	
10692/25300 (epoch 21.130), train_loss = 0.77523342, grad/param norm = 1.6553e-01, time/batch = 17.1459s	
10693/25300 (epoch 21.132), train_loss = 0.80957006, grad/param norm = 1.7694e-01, time/batch = 15.7163s	
10694/25300 (epoch 21.134), train_loss = 0.78219165, grad/param norm = 1.6132e-01, time/batch = 16.8998s	
10695/25300 (epoch 21.136), train_loss = 0.94952222, grad/param norm = 1.8199e-01, time/batch = 17.4061s	
10696/25300 (epoch 21.138), train_loss = 0.82420792, grad/param norm = 1.6918e-01, time/batch = 15.5479s	
10697/25300 (epoch 21.140), train_loss = 0.87474603, grad/param norm = 1.7804e-01, time/batch = 15.9674s	
10698/25300 (epoch 21.142), train_loss = 1.06413872, grad/param norm = 2.0006e-01, time/batch = 16.3682s	
10699/25300 (epoch 21.144), train_loss = 1.02867674, grad/param norm = 1.9785e-01, time/batch = 16.1350s	
10700/25300 (epoch 21.146), train_loss = 1.01380536, grad/param norm = 2.2727e-01, time/batch = 15.6900s	
10701/25300 (epoch 21.148), train_loss = 0.97088612, grad/param norm = 1.8457e-01, time/batch = 18.5343s	
10702/25300 (epoch 21.150), train_loss = 1.06289135, grad/param norm = 2.1822e-01, time/batch = 16.9788s	
10703/25300 (epoch 21.152), train_loss = 1.13227589, grad/param norm = 2.2301e-01, time/batch = 16.3116s	
10704/25300 (epoch 21.154), train_loss = 0.80301955, grad/param norm = 1.6397e-01, time/batch = 17.1273s	
10705/25300 (epoch 21.156), train_loss = 1.03498221, grad/param norm = 2.0676e-01, time/batch = 16.7314s	
10706/25300 (epoch 21.158), train_loss = 0.85025642, grad/param norm = 1.8970e-01, time/batch = 15.5569s	
10707/25300 (epoch 21.160), train_loss = 0.95583563, grad/param norm = 1.9642e-01, time/batch = 15.6267s	
10708/25300 (epoch 21.162), train_loss = 0.90604143, grad/param norm = 1.9743e-01, time/batch = 16.4581s	
10709/25300 (epoch 21.164), train_loss = 1.02980054, grad/param norm = 2.0481e-01, time/batch = 15.8116s	
10710/25300 (epoch 21.166), train_loss = 0.96467255, grad/param norm = 1.8674e-01, time/batch = 17.3890s	
10711/25300 (epoch 21.168), train_loss = 0.85333904, grad/param norm = 1.6227e-01, time/batch = 15.8892s	
10712/25300 (epoch 21.170), train_loss = 0.93122993, grad/param norm = 1.8599e-01, time/batch = 18.2155s	
10713/25300 (epoch 21.172), train_loss = 0.85275431, grad/param norm = 1.7866e-01, time/batch = 16.4017s	
10714/25300 (epoch 21.174), train_loss = 0.84845893, grad/param norm = 1.8594e-01, time/batch = 16.3908s	
10715/25300 (epoch 21.176), train_loss = 0.86682285, grad/param norm = 1.9092e-01, time/batch = 17.9031s	
10716/25300 (epoch 21.178), train_loss = 1.07833812, grad/param norm = 1.9758e-01, time/batch = 17.1451s	
10717/25300 (epoch 21.180), train_loss = 0.76845308, grad/param norm = 1.6449e-01, time/batch = 16.1411s	
10718/25300 (epoch 21.182), train_loss = 0.88833900, grad/param norm = 1.7667e-01, time/batch = 15.6160s	
10719/25300 (epoch 21.184), train_loss = 0.89122221, grad/param norm = 1.9120e-01, time/batch = 16.8204s	
10720/25300 (epoch 21.186), train_loss = 0.87262501, grad/param norm = 1.9980e-01, time/batch = 17.3011s	
10721/25300 (epoch 21.188), train_loss = 0.97669627, grad/param norm = 2.2054e-01, time/batch = 16.1497s	
10722/25300 (epoch 21.190), train_loss = 0.90365359, grad/param norm = 1.8746e-01, time/batch = 16.0376s	
10723/25300 (epoch 21.192), train_loss = 0.93336246, grad/param norm = 2.0422e-01, time/batch = 16.0741s	
10724/25300 (epoch 21.194), train_loss = 0.92868477, grad/param norm = 2.0457e-01, time/batch = 15.6486s	
10725/25300 (epoch 21.196), train_loss = 1.04409162, grad/param norm = 3.0106e-01, time/batch = 15.7128s	
10726/25300 (epoch 21.198), train_loss = 0.90354006, grad/param norm = 2.1344e-01, time/batch = 16.8821s	
10727/25300 (epoch 21.200), train_loss = 0.92746154, grad/param norm = 1.9126e-01, time/batch = 16.3174s	
10728/25300 (epoch 21.202), train_loss = 0.94164300, grad/param norm = 2.0105e-01, time/batch = 16.1568s	
10729/25300 (epoch 21.204), train_loss = 0.89649102, grad/param norm = 1.7230e-01, time/batch = 15.9696s	
10730/25300 (epoch 21.206), train_loss = 1.03300870, grad/param norm = 1.8848e-01, time/batch = 16.3756s	
10731/25300 (epoch 21.208), train_loss = 0.81621656, grad/param norm = 1.8421e-01, time/batch = 17.5535s	
10732/25300 (epoch 21.209), train_loss = 0.79711073, grad/param norm = 1.6441e-01, time/batch = 15.6407s	
10733/25300 (epoch 21.211), train_loss = 0.90089388, grad/param norm = 1.8425e-01, time/batch = 17.8832s	
10734/25300 (epoch 21.213), train_loss = 0.98897122, grad/param norm = 2.0142e-01, time/batch = 18.2145s	
10735/25300 (epoch 21.215), train_loss = 0.94369892, grad/param norm = 1.9749e-01, time/batch = 18.2133s	
10736/25300 (epoch 21.217), train_loss = 0.97696191, grad/param norm = 1.9910e-01, time/batch = 17.2171s	
10737/25300 (epoch 21.219), train_loss = 1.04850590, grad/param norm = 2.0317e-01, time/batch = 20.2775s	
10738/25300 (epoch 21.221), train_loss = 1.09893224, grad/param norm = 2.1269e-01, time/batch = 15.9123s	
10739/25300 (epoch 21.223), train_loss = 1.01636984, grad/param norm = 2.4304e-01, time/batch = 16.1322s	
10740/25300 (epoch 21.225), train_loss = 1.35955049, grad/param norm = 2.9356e-01, time/batch = 17.2160s	
10741/25300 (epoch 21.227), train_loss = 1.07511846, grad/param norm = 2.0771e-01, time/batch = 18.3017s	
10742/25300 (epoch 21.229), train_loss = 0.95769941, grad/param norm = 1.8757e-01, time/batch = 16.9653s	
10743/25300 (epoch 21.231), train_loss = 0.93162823, grad/param norm = 1.9631e-01, time/batch = 17.2154s	
10744/25300 (epoch 21.233), train_loss = 1.02768737, grad/param norm = 2.0536e-01, time/batch = 16.4989s	
10745/25300 (epoch 21.235), train_loss = 0.94784407, grad/param norm = 1.7973e-01, time/batch = 17.8141s	
10746/25300 (epoch 21.237), train_loss = 1.11471953, grad/param norm = 2.3078e-01, time/batch = 16.1334s	
10747/25300 (epoch 21.239), train_loss = 0.93884662, grad/param norm = 1.7630e-01, time/batch = 17.9765s	
10748/25300 (epoch 21.241), train_loss = 1.10249210, grad/param norm = 2.1728e-01, time/batch = 18.7238s	
10749/25300 (epoch 21.243), train_loss = 1.25788349, grad/param norm = 2.1909e-01, time/batch = 16.5604s	
10750/25300 (epoch 21.245), train_loss = 0.90143747, grad/param norm = 1.8604e-01, time/batch = 16.2214s	
10751/25300 (epoch 21.247), train_loss = 1.04812753, grad/param norm = 1.9465e-01, time/batch = 16.2389s	
10752/25300 (epoch 21.249), train_loss = 0.82864136, grad/param norm = 1.6966e-01, time/batch = 15.8999s	
10753/25300 (epoch 21.251), train_loss = 0.82157316, grad/param norm = 1.7038e-01, time/batch = 16.2271s	
10754/25300 (epoch 21.253), train_loss = 0.93235564, grad/param norm = 1.9521e-01, time/batch = 15.6460s	
10755/25300 (epoch 21.255), train_loss = 0.90001549, grad/param norm = 2.0639e-01, time/batch = 17.3731s	
10756/25300 (epoch 21.257), train_loss = 0.96893233, grad/param norm = 2.0351e-01, time/batch = 17.3072s	
10757/25300 (epoch 21.259), train_loss = 1.16488597, grad/param norm = 2.4444e-01, time/batch = 16.2959s	
10758/25300 (epoch 21.261), train_loss = 1.12670924, grad/param norm = 2.4211e-01, time/batch = 17.9639s	
10759/25300 (epoch 21.263), train_loss = 1.11761093, grad/param norm = 2.0390e-01, time/batch = 17.7233s	
10760/25300 (epoch 21.265), train_loss = 1.13991861, grad/param norm = 2.1079e-01, time/batch = 16.6166s	
10761/25300 (epoch 21.267), train_loss = 1.04923371, grad/param norm = 2.0545e-01, time/batch = 16.6517s	
10762/25300 (epoch 21.269), train_loss = 0.80812274, grad/param norm = 1.7153e-01, time/batch = 18.1266s	
10763/25300 (epoch 21.271), train_loss = 0.91247684, grad/param norm = 1.8347e-01, time/batch = 18.4745s	
10764/25300 (epoch 21.273), train_loss = 1.03359020, grad/param norm = 2.1057e-01, time/batch = 17.0505s	
10765/25300 (epoch 21.275), train_loss = 0.92837392, grad/param norm = 1.5561e-01, time/batch = 18.6340s	
10766/25300 (epoch 21.277), train_loss = 0.90595932, grad/param norm = 2.1787e-01, time/batch = 16.6609s	
10767/25300 (epoch 21.279), train_loss = 0.95492029, grad/param norm = 1.8976e-01, time/batch = 16.6352s	
10768/25300 (epoch 21.281), train_loss = 1.13502358, grad/param norm = 2.2281e-01, time/batch = 16.1379s	
10769/25300 (epoch 21.283), train_loss = 0.84508394, grad/param norm = 1.6555e-01, time/batch = 17.1463s	
10770/25300 (epoch 21.285), train_loss = 0.99692820, grad/param norm = 2.1274e-01, time/batch = 16.1360s	
10771/25300 (epoch 21.287), train_loss = 1.01407990, grad/param norm = 1.9219e-01, time/batch = 17.5435s	
10772/25300 (epoch 21.289), train_loss = 0.92419318, grad/param norm = 1.8162e-01, time/batch = 16.8983s	
10773/25300 (epoch 21.291), train_loss = 0.93097452, grad/param norm = 1.8243e-01, time/batch = 19.3051s	
10774/25300 (epoch 21.292), train_loss = 1.12022500, grad/param norm = 1.9860e-01, time/batch = 16.8166s	
10775/25300 (epoch 21.294), train_loss = 0.99685116, grad/param norm = 1.9260e-01, time/batch = 17.8121s	
10776/25300 (epoch 21.296), train_loss = 0.86687535, grad/param norm = 1.9507e-01, time/batch = 19.8021s	
10777/25300 (epoch 21.298), train_loss = 1.04669346, grad/param norm = 1.9880e-01, time/batch = 20.5756s	
10778/25300 (epoch 21.300), train_loss = 1.07580164, grad/param norm = 2.3112e-01, time/batch = 27.0367s	
10779/25300 (epoch 21.302), train_loss = 0.78423560, grad/param norm = 1.8812e-01, time/batch = 18.0563s	
10780/25300 (epoch 21.304), train_loss = 1.05485693, grad/param norm = 1.9714e-01, time/batch = 16.3908s	
10781/25300 (epoch 21.306), train_loss = 0.76295468, grad/param norm = 1.7440e-01, time/batch = 18.8088s	
10782/25300 (epoch 21.308), train_loss = 1.01803962, grad/param norm = 1.7987e-01, time/batch = 17.9682s	
10783/25300 (epoch 21.310), train_loss = 0.87042316, grad/param norm = 1.9849e-01, time/batch = 16.7134s	
10784/25300 (epoch 21.312), train_loss = 0.98019760, grad/param norm = 1.8454e-01, time/batch = 17.8895s	
10785/25300 (epoch 21.314), train_loss = 0.79257988, grad/param norm = 1.7399e-01, time/batch = 18.7147s	
10786/25300 (epoch 21.316), train_loss = 0.97892227, grad/param norm = 1.8514e-01, time/batch = 16.8211s	
10787/25300 (epoch 21.318), train_loss = 0.80578363, grad/param norm = 1.9066e-01, time/batch = 17.2137s	
10788/25300 (epoch 21.320), train_loss = 0.85218579, grad/param norm = 1.8293e-01, time/batch = 17.2166s	
10789/25300 (epoch 21.322), train_loss = 1.12890166, grad/param norm = 2.0700e-01, time/batch = 16.9017s	
10790/25300 (epoch 21.324), train_loss = 0.85936986, grad/param norm = 1.6429e-01, time/batch = 16.2893s	
10791/25300 (epoch 21.326), train_loss = 0.76995370, grad/param norm = 1.6793e-01, time/batch = 18.3919s	
10792/25300 (epoch 21.328), train_loss = 0.77601606, grad/param norm = 1.9171e-01, time/batch = 17.4664s	
10793/25300 (epoch 21.330), train_loss = 0.92799588, grad/param norm = 1.9071e-01, time/batch = 18.8744s	
10794/25300 (epoch 21.332), train_loss = 0.95968680, grad/param norm = 1.7417e-01, time/batch = 15.5413s	
10795/25300 (epoch 21.334), train_loss = 0.79470720, grad/param norm = 1.7513e-01, time/batch = 17.8033s	
10796/25300 (epoch 21.336), train_loss = 0.81947649, grad/param norm = 1.8107e-01, time/batch = 19.0499s	
10797/25300 (epoch 21.338), train_loss = 0.81154121, grad/param norm = 1.7775e-01, time/batch = 15.9692s	
10798/25300 (epoch 21.340), train_loss = 0.87403031, grad/param norm = 1.9311e-01, time/batch = 17.4751s	
10799/25300 (epoch 21.342), train_loss = 0.90272115, grad/param norm = 2.0184e-01, time/batch = 17.8028s	
10800/25300 (epoch 21.344), train_loss = 0.96395022, grad/param norm = 1.8263e-01, time/batch = 18.7923s	
10801/25300 (epoch 21.346), train_loss = 0.90653492, grad/param norm = 1.9379e-01, time/batch = 19.3699s	
10802/25300 (epoch 21.348), train_loss = 0.80770240, grad/param norm = 1.8119e-01, time/batch = 16.1290s	
10803/25300 (epoch 21.350), train_loss = 0.90759305, grad/param norm = 1.9211e-01, time/batch = 18.3803s	
10804/25300 (epoch 21.352), train_loss = 0.93562701, grad/param norm = 1.8657e-01, time/batch = 15.7789s	
10805/25300 (epoch 21.354), train_loss = 0.89212839, grad/param norm = 1.8345e-01, time/batch = 17.9723s	
10806/25300 (epoch 21.356), train_loss = 0.92715172, grad/param norm = 1.9489e-01, time/batch = 16.4085s	
10807/25300 (epoch 21.358), train_loss = 1.00237386, grad/param norm = 2.2224e-01, time/batch = 17.8816s	
10808/25300 (epoch 21.360), train_loss = 0.84209636, grad/param norm = 1.8071e-01, time/batch = 17.2253s	
10809/25300 (epoch 21.362), train_loss = 0.86719315, grad/param norm = 1.8490e-01, time/batch = 18.2191s	
10810/25300 (epoch 21.364), train_loss = 0.89910925, grad/param norm = 2.1969e-01, time/batch = 17.3130s	
10811/25300 (epoch 21.366), train_loss = 0.80925674, grad/param norm = 1.7855e-01, time/batch = 16.5419s	
10812/25300 (epoch 21.368), train_loss = 0.90988430, grad/param norm = 1.7332e-01, time/batch = 17.7186s	
10813/25300 (epoch 21.370), train_loss = 0.87792315, grad/param norm = 1.9653e-01, time/batch = 16.3898s	
10814/25300 (epoch 21.372), train_loss = 0.87415315, grad/param norm = 1.8631e-01, time/batch = 15.7883s	
10815/25300 (epoch 21.374), train_loss = 0.80896394, grad/param norm = 1.8677e-01, time/batch = 15.7903s	
10816/25300 (epoch 21.375), train_loss = 1.04944354, grad/param norm = 2.1020e-01, time/batch = 19.0439s	
10817/25300 (epoch 21.377), train_loss = 0.97948523, grad/param norm = 1.9610e-01, time/batch = 16.6574s	
10818/25300 (epoch 21.379), train_loss = 0.96762391, grad/param norm = 2.0197e-01, time/batch = 16.0453s	
10819/25300 (epoch 21.381), train_loss = 0.92377763, grad/param norm = 1.8198e-01, time/batch = 17.8155s	
10820/25300 (epoch 21.383), train_loss = 0.85776876, grad/param norm = 1.8047e-01, time/batch = 18.4767s	
10821/25300 (epoch 21.385), train_loss = 0.94208133, grad/param norm = 1.8523e-01, time/batch = 17.1311s	
10822/25300 (epoch 21.387), train_loss = 0.98226901, grad/param norm = 1.9785e-01, time/batch = 20.0319s	
10823/25300 (epoch 21.389), train_loss = 0.98314530, grad/param norm = 2.0246e-01, time/batch = 18.2065s	
10824/25300 (epoch 21.391), train_loss = 0.85717687, grad/param norm = 1.8170e-01, time/batch = 17.4563s	
10825/25300 (epoch 21.393), train_loss = 0.96135539, grad/param norm = 2.1312e-01, time/batch = 15.8783s	
10826/25300 (epoch 21.395), train_loss = 0.77848430, grad/param norm = 1.6312e-01, time/batch = 16.9590s	
10827/25300 (epoch 21.397), train_loss = 0.81364189, grad/param norm = 2.1343e-01, time/batch = 17.5620s	
10828/25300 (epoch 21.399), train_loss = 0.79792583, grad/param norm = 1.9076e-01, time/batch = 15.4099s	
10829/25300 (epoch 21.401), train_loss = 1.01872448, grad/param norm = 2.3635e-01, time/batch = 16.4691s	
10830/25300 (epoch 21.403), train_loss = 0.93343841, grad/param norm = 2.1804e-01, time/batch = 17.1071s	
10831/25300 (epoch 21.405), train_loss = 0.92056588, grad/param norm = 1.8583e-01, time/batch = 16.0519s	
10832/25300 (epoch 21.407), train_loss = 0.89687044, grad/param norm = 1.9362e-01, time/batch = 15.5142s	
10833/25300 (epoch 21.409), train_loss = 0.84883293, grad/param norm = 1.7202e-01, time/batch = 15.7140s	
10834/25300 (epoch 21.411), train_loss = 0.85133590, grad/param norm = 1.8880e-01, time/batch = 15.7004s	
10835/25300 (epoch 21.413), train_loss = 0.77461452, grad/param norm = 1.6765e-01, time/batch = 15.6586s	
10836/25300 (epoch 21.415), train_loss = 0.81324009, grad/param norm = 1.8861e-01, time/batch = 15.2625s	
10837/25300 (epoch 21.417), train_loss = 0.78212802, grad/param norm = 1.9066e-01, time/batch = 16.2299s	
10838/25300 (epoch 21.419), train_loss = 0.71363255, grad/param norm = 1.5764e-01, time/batch = 16.8955s	
10839/25300 (epoch 21.421), train_loss = 0.80867749, grad/param norm = 1.6209e-01, time/batch = 15.9785s	
10840/25300 (epoch 21.423), train_loss = 0.79413357, grad/param norm = 1.8091e-01, time/batch = 15.6457s	
10841/25300 (epoch 21.425), train_loss = 0.89619821, grad/param norm = 2.3105e-01, time/batch = 16.3962s	
10842/25300 (epoch 21.427), train_loss = 1.08405912, grad/param norm = 2.1815e-01, time/batch = 15.5592s	
10843/25300 (epoch 21.429), train_loss = 0.99703197, grad/param norm = 2.1313e-01, time/batch = 15.9535s	
10844/25300 (epoch 21.431), train_loss = 0.97067999, grad/param norm = 1.8873e-01, time/batch = 16.6476s	
10845/25300 (epoch 21.433), train_loss = 0.91616161, grad/param norm = 1.7992e-01, time/batch = 15.8186s	
10846/25300 (epoch 21.435), train_loss = 0.85372224, grad/param norm = 1.9815e-01, time/batch = 15.3303s	
10847/25300 (epoch 21.437), train_loss = 0.86190403, grad/param norm = 1.8518e-01, time/batch = 15.4731s	
10848/25300 (epoch 21.439), train_loss = 0.94054940, grad/param norm = 1.9410e-01, time/batch = 15.3869s	
10849/25300 (epoch 21.441), train_loss = 0.97666148, grad/param norm = 2.0306e-01, time/batch = 15.6589s	
10850/25300 (epoch 21.443), train_loss = 1.15018990, grad/param norm = 2.3813e-01, time/batch = 15.8973s	
10851/25300 (epoch 21.445), train_loss = 1.09437123, grad/param norm = 2.3077e-01, time/batch = 16.2061s	
10852/25300 (epoch 21.447), train_loss = 0.83868917, grad/param norm = 1.7689e-01, time/batch = 16.8198s	
10853/25300 (epoch 21.449), train_loss = 0.75711104, grad/param norm = 1.7251e-01, time/batch = 15.7318s	
10854/25300 (epoch 21.451), train_loss = 1.13970244, grad/param norm = 2.0952e-01, time/batch = 15.6190s	
10855/25300 (epoch 21.453), train_loss = 0.98937247, grad/param norm = 1.9825e-01, time/batch = 16.4675s	
10856/25300 (epoch 21.455), train_loss = 0.98931247, grad/param norm = 2.0884e-01, time/batch = 15.7362s	
10857/25300 (epoch 21.457), train_loss = 0.87605519, grad/param norm = 1.8982e-01, time/batch = 16.2718s	
10858/25300 (epoch 21.458), train_loss = 0.90386148, grad/param norm = 1.9931e-01, time/batch = 16.2909s	
10859/25300 (epoch 21.460), train_loss = 0.94057133, grad/param norm = 2.0485e-01, time/batch = 18.3061s	
10860/25300 (epoch 21.462), train_loss = 0.69671417, grad/param norm = 1.8260e-01, time/batch = 17.3904s	
10861/25300 (epoch 21.464), train_loss = 1.00267725, grad/param norm = 2.0043e-01, time/batch = 16.7053s	
10862/25300 (epoch 21.466), train_loss = 0.97859529, grad/param norm = 1.9341e-01, time/batch = 16.4687s	
10863/25300 (epoch 21.468), train_loss = 0.99594451, grad/param norm = 2.1803e-01, time/batch = 16.2205s	
10864/25300 (epoch 21.470), train_loss = 0.88879709, grad/param norm = 1.8882e-01, time/batch = 16.2084s	
10865/25300 (epoch 21.472), train_loss = 0.79649245, grad/param norm = 1.8028e-01, time/batch = 15.7943s	
10866/25300 (epoch 21.474), train_loss = 0.96258709, grad/param norm = 1.9851e-01, time/batch = 15.2636s	
10867/25300 (epoch 21.476), train_loss = 0.89379781, grad/param norm = 1.8863e-01, time/batch = 17.5409s	
10868/25300 (epoch 21.478), train_loss = 0.98525717, grad/param norm = 2.1465e-01, time/batch = 16.6413s	
10869/25300 (epoch 21.480), train_loss = 0.86599575, grad/param norm = 1.8886e-01, time/batch = 17.2144s	
10870/25300 (epoch 21.482), train_loss = 0.98643223, grad/param norm = 2.2545e-01, time/batch = 17.9561s	
10871/25300 (epoch 21.484), train_loss = 0.99605816, grad/param norm = 2.0775e-01, time/batch = 18.1291s	
10872/25300 (epoch 21.486), train_loss = 0.92983132, grad/param norm = 1.8679e-01, time/batch = 15.8836s	
10873/25300 (epoch 21.488), train_loss = 1.09896382, grad/param norm = 2.2499e-01, time/batch = 17.3135s	
10874/25300 (epoch 21.490), train_loss = 0.97143097, grad/param norm = 1.9756e-01, time/batch = 18.6327s	
10875/25300 (epoch 21.492), train_loss = 0.94983122, grad/param norm = 1.8202e-01, time/batch = 17.1469s	
10876/25300 (epoch 21.494), train_loss = 0.86402855, grad/param norm = 1.7471e-01, time/batch = 17.4115s	
10877/25300 (epoch 21.496), train_loss = 0.93958698, grad/param norm = 1.9024e-01, time/batch = 17.3802s	
10878/25300 (epoch 21.498), train_loss = 0.85667688, grad/param norm = 1.8609e-01, time/batch = 16.4103s	
10879/25300 (epoch 21.500), train_loss = 1.07458374, grad/param norm = 2.1378e-01, time/batch = 15.8998s	
10880/25300 (epoch 21.502), train_loss = 0.97053381, grad/param norm = 2.1854e-01, time/batch = 17.6433s	
10881/25300 (epoch 21.504), train_loss = 0.90627776, grad/param norm = 2.0393e-01, time/batch = 16.8902s	
10882/25300 (epoch 21.506), train_loss = 0.84371029, grad/param norm = 1.8284e-01, time/batch = 17.7959s	
10883/25300 (epoch 21.508), train_loss = 0.92930736, grad/param norm = 1.9161e-01, time/batch = 16.3982s	
10884/25300 (epoch 21.510), train_loss = 0.85820472, grad/param norm = 1.8401e-01, time/batch = 16.9752s	
10885/25300 (epoch 21.512), train_loss = 0.69871723, grad/param norm = 1.7345e-01, time/batch = 17.4682s	
10886/25300 (epoch 21.514), train_loss = 0.91425658, grad/param norm = 1.8383e-01, time/batch = 15.8154s	
10887/25300 (epoch 21.516), train_loss = 0.98170310, grad/param norm = 2.0247e-01, time/batch = 19.0425s	
10888/25300 (epoch 21.518), train_loss = 1.03294458, grad/param norm = 2.2257e-01, time/batch = 17.2091s	
10889/25300 (epoch 21.520), train_loss = 0.77173328, grad/param norm = 1.6437e-01, time/batch = 17.3836s	
10890/25300 (epoch 21.522), train_loss = 0.85310600, grad/param norm = 1.8032e-01, time/batch = 17.7070s	
10891/25300 (epoch 21.524), train_loss = 0.86218927, grad/param norm = 1.7867e-01, time/batch = 15.5646s	
10892/25300 (epoch 21.526), train_loss = 1.07554186, grad/param norm = 2.1154e-01, time/batch = 17.1449s	
10893/25300 (epoch 21.528), train_loss = 1.07531817, grad/param norm = 2.0217e-01, time/batch = 15.9440s	
10894/25300 (epoch 21.530), train_loss = 0.95024487, grad/param norm = 2.0203e-01, time/batch = 15.6603s	
10895/25300 (epoch 21.532), train_loss = 0.92078850, grad/param norm = 1.9663e-01, time/batch = 17.3918s	
10896/25300 (epoch 21.534), train_loss = 0.91252201, grad/param norm = 2.0423e-01, time/batch = 17.8848s	
10897/25300 (epoch 21.536), train_loss = 0.74858371, grad/param norm = 1.7973e-01, time/batch = 16.3923s	
10898/25300 (epoch 21.538), train_loss = 0.80528782, grad/param norm = 1.6578e-01, time/batch = 18.4651s	
10899/25300 (epoch 21.540), train_loss = 0.86065959, grad/param norm = 1.9868e-01, time/batch = 16.8932s	
10900/25300 (epoch 21.542), train_loss = 0.83606465, grad/param norm = 1.7509e-01, time/batch = 16.3967s	
10901/25300 (epoch 21.543), train_loss = 0.79727838, grad/param norm = 1.8668e-01, time/batch = 16.9764s	
10902/25300 (epoch 21.545), train_loss = 1.19255142, grad/param norm = 2.5546e-01, time/batch = 16.1319s	
10903/25300 (epoch 21.547), train_loss = 1.01165894, grad/param norm = 2.0844e-01, time/batch = 17.5395s	
10904/25300 (epoch 21.549), train_loss = 1.19340542, grad/param norm = 2.7910e-01, time/batch = 16.0292s	
10905/25300 (epoch 21.551), train_loss = 1.02229843, grad/param norm = 2.1326e-01, time/batch = 17.4038s	
10906/25300 (epoch 21.553), train_loss = 0.85568524, grad/param norm = 1.8289e-01, time/batch = 17.3829s	
10907/25300 (epoch 21.555), train_loss = 1.02980197, grad/param norm = 2.2354e-01, time/batch = 16.1492s	
10908/25300 (epoch 21.557), train_loss = 1.05189159, grad/param norm = 2.0185e-01, time/batch = 16.6314s	
10909/25300 (epoch 21.559), train_loss = 1.02117578, grad/param norm = 1.9715e-01, time/batch = 15.7491s	
10910/25300 (epoch 21.561), train_loss = 1.06842952, grad/param norm = 2.0812e-01, time/batch = 16.8981s	
10911/25300 (epoch 21.563), train_loss = 1.02884784, grad/param norm = 2.1177e-01, time/batch = 15.7201s	
10912/25300 (epoch 21.565), train_loss = 0.80544064, grad/param norm = 1.7868e-01, time/batch = 16.1693s	
10913/25300 (epoch 21.567), train_loss = 0.70903240, grad/param norm = 1.7572e-01, time/batch = 15.5563s	
10914/25300 (epoch 21.569), train_loss = 0.92342254, grad/param norm = 1.9738e-01, time/batch = 16.9805s	
10915/25300 (epoch 21.571), train_loss = 1.02147747, grad/param norm = 2.0108e-01, time/batch = 16.7309s	
10916/25300 (epoch 21.573), train_loss = 0.93365951, grad/param norm = 1.8989e-01, time/batch = 17.2330s	
10917/25300 (epoch 21.575), train_loss = 1.06860773, grad/param norm = 1.9988e-01, time/batch = 17.0819s	
10918/25300 (epoch 21.577), train_loss = 0.95596059, grad/param norm = 2.0546e-01, time/batch = 9.5889s	
10919/25300 (epoch 21.579), train_loss = 1.07675151, grad/param norm = 2.2222e-01, time/batch = 0.6635s	
10920/25300 (epoch 21.581), train_loss = 0.99186248, grad/param norm = 2.0477e-01, time/batch = 0.6592s	
10921/25300 (epoch 21.583), train_loss = 0.78042912, grad/param norm = 1.9419e-01, time/batch = 0.6605s	
10922/25300 (epoch 21.585), train_loss = 0.80067685, grad/param norm = 2.3480e-01, time/batch = 0.6605s	
10923/25300 (epoch 21.587), train_loss = 0.90268584, grad/param norm = 1.9142e-01, time/batch = 0.6691s	
10924/25300 (epoch 21.589), train_loss = 0.81146554, grad/param norm = 1.6143e-01, time/batch = 0.6615s	
10925/25300 (epoch 21.591), train_loss = 0.82596583, grad/param norm = 2.0520e-01, time/batch = 0.6539s	
10926/25300 (epoch 21.593), train_loss = 1.00995133, grad/param norm = 2.0679e-01, time/batch = 0.6574s	
10927/25300 (epoch 21.595), train_loss = 0.91391982, grad/param norm = 1.9727e-01, time/batch = 0.6536s	
10928/25300 (epoch 21.597), train_loss = 0.80781602, grad/param norm = 1.7064e-01, time/batch = 0.6539s	
10929/25300 (epoch 21.599), train_loss = 0.96343590, grad/param norm = 2.0804e-01, time/batch = 0.6552s	
10930/25300 (epoch 21.601), train_loss = 0.95332464, grad/param norm = 2.3146e-01, time/batch = 0.6548s	
10931/25300 (epoch 21.603), train_loss = 0.94312647, grad/param norm = 2.2807e-01, time/batch = 0.6632s	
10932/25300 (epoch 21.605), train_loss = 0.85171748, grad/param norm = 2.1672e-01, time/batch = 0.6535s	
10933/25300 (epoch 21.607), train_loss = 0.70020511, grad/param norm = 1.6941e-01, time/batch = 0.6595s	
10934/25300 (epoch 21.609), train_loss = 0.90937417, grad/param norm = 1.8994e-01, time/batch = 0.6581s	
10935/25300 (epoch 21.611), train_loss = 0.95607534, grad/param norm = 1.9408e-01, time/batch = 0.6548s	
10936/25300 (epoch 21.613), train_loss = 0.79973099, grad/param norm = 1.6669e-01, time/batch = 0.6547s	
10937/25300 (epoch 21.615), train_loss = 0.91172763, grad/param norm = 2.2739e-01, time/batch = 0.6544s	
10938/25300 (epoch 21.617), train_loss = 0.93156829, grad/param norm = 1.9782e-01, time/batch = 0.6545s	
10939/25300 (epoch 21.619), train_loss = 1.01202825, grad/param norm = 2.0587e-01, time/batch = 0.6539s	
10940/25300 (epoch 21.621), train_loss = 1.04532744, grad/param norm = 2.2665e-01, time/batch = 0.6566s	
10941/25300 (epoch 21.623), train_loss = 0.85581849, grad/param norm = 1.9814e-01, time/batch = 0.6595s	
10942/25300 (epoch 21.625), train_loss = 0.74434862, grad/param norm = 1.7636e-01, time/batch = 0.6574s	
10943/25300 (epoch 21.626), train_loss = 0.89334258, grad/param norm = 1.7107e-01, time/batch = 0.6576s	
10944/25300 (epoch 21.628), train_loss = 1.00263297, grad/param norm = 2.1577e-01, time/batch = 0.6567s	
10945/25300 (epoch 21.630), train_loss = 0.98160026, grad/param norm = 2.2645e-01, time/batch = 0.6554s	
10946/25300 (epoch 21.632), train_loss = 0.95840521, grad/param norm = 2.2911e-01, time/batch = 0.6561s	
10947/25300 (epoch 21.634), train_loss = 1.02761536, grad/param norm = 2.3042e-01, time/batch = 0.6567s	
10948/25300 (epoch 21.636), train_loss = 0.85783701, grad/param norm = 1.8725e-01, time/batch = 0.6584s	
10949/25300 (epoch 21.638), train_loss = 0.96435007, grad/param norm = 2.2989e-01, time/batch = 0.6617s	
10950/25300 (epoch 21.640), train_loss = 1.12855649, grad/param norm = 2.4083e-01, time/batch = 0.6591s	
10951/25300 (epoch 21.642), train_loss = 0.98369675, grad/param norm = 2.0728e-01, time/batch = 0.6550s	
10952/25300 (epoch 21.644), train_loss = 0.96628381, grad/param norm = 2.1376e-01, time/batch = 0.6551s	
10953/25300 (epoch 21.646), train_loss = 0.90098032, grad/param norm = 2.4922e-01, time/batch = 0.6569s	
10954/25300 (epoch 21.648), train_loss = 1.01820288, grad/param norm = 1.9203e-01, time/batch = 0.6560s	
10955/25300 (epoch 21.650), train_loss = 0.97624758, grad/param norm = 2.1550e-01, time/batch = 0.6510s	
10956/25300 (epoch 21.652), train_loss = 0.96350429, grad/param norm = 2.2170e-01, time/batch = 0.6590s	
10957/25300 (epoch 21.654), train_loss = 1.07929836, grad/param norm = 2.1189e-01, time/batch = 0.6622s	
10958/25300 (epoch 21.656), train_loss = 1.00917960, grad/param norm = 2.1988e-01, time/batch = 0.6641s	
10959/25300 (epoch 21.658), train_loss = 0.79275163, grad/param norm = 1.6512e-01, time/batch = 0.6565s	
10960/25300 (epoch 21.660), train_loss = 0.83050123, grad/param norm = 1.9483e-01, time/batch = 0.6591s	
10961/25300 (epoch 21.662), train_loss = 0.79660044, grad/param norm = 1.7639e-01, time/batch = 0.6600s	
10962/25300 (epoch 21.664), train_loss = 0.78956417, grad/param norm = 1.9644e-01, time/batch = 0.6540s	
10963/25300 (epoch 21.666), train_loss = 0.83044482, grad/param norm = 1.9964e-01, time/batch = 0.6549s	
10964/25300 (epoch 21.668), train_loss = 0.90054187, grad/param norm = 2.4195e-01, time/batch = 0.6535s	
10965/25300 (epoch 21.670), train_loss = 0.81776622, grad/param norm = 2.1299e-01, time/batch = 0.6541s	
10966/25300 (epoch 21.672), train_loss = 0.80776159, grad/param norm = 1.7964e-01, time/batch = 0.6580s	
10967/25300 (epoch 21.674), train_loss = 0.83278662, grad/param norm = 1.6636e-01, time/batch = 0.6624s	
10968/25300 (epoch 21.676), train_loss = 0.88321922, grad/param norm = 2.2803e-01, time/batch = 0.6547s	
10969/25300 (epoch 21.678), train_loss = 0.88207753, grad/param norm = 2.1654e-01, time/batch = 0.6543s	
10970/25300 (epoch 21.680), train_loss = 0.75144121, grad/param norm = 1.7491e-01, time/batch = 0.6528s	
10971/25300 (epoch 21.682), train_loss = 0.64007866, grad/param norm = 1.6512e-01, time/batch = 0.6555s	
10972/25300 (epoch 21.684), train_loss = 0.81424658, grad/param norm = 1.6789e-01, time/batch = 0.6586s	
10973/25300 (epoch 21.686), train_loss = 0.78153917, grad/param norm = 1.6850e-01, time/batch = 0.6554s	
10974/25300 (epoch 21.688), train_loss = 0.88407020, grad/param norm = 2.0114e-01, time/batch = 0.6563s	
10975/25300 (epoch 21.690), train_loss = 0.79011586, grad/param norm = 1.6770e-01, time/batch = 0.6562s	
10976/25300 (epoch 21.692), train_loss = 0.84183876, grad/param norm = 1.8003e-01, time/batch = 0.6653s	
10977/25300 (epoch 21.694), train_loss = 0.83095250, grad/param norm = 1.6303e-01, time/batch = 0.6645s	
10978/25300 (epoch 21.696), train_loss = 0.93762903, grad/param norm = 2.1052e-01, time/batch = 0.6526s	
10979/25300 (epoch 21.698), train_loss = 0.96029806, grad/param norm = 1.9106e-01, time/batch = 0.6586s	
10980/25300 (epoch 21.700), train_loss = 0.72911836, grad/param norm = 1.7457e-01, time/batch = 0.6790s	
10981/25300 (epoch 21.702), train_loss = 0.99873794, grad/param norm = 2.0650e-01, time/batch = 0.6664s	
10982/25300 (epoch 21.704), train_loss = 0.73258446, grad/param norm = 1.9831e-01, time/batch = 0.6647s	
10983/25300 (epoch 21.706), train_loss = 0.92246043, grad/param norm = 2.2036e-01, time/batch = 0.6641s	
10984/25300 (epoch 21.708), train_loss = 0.76469587, grad/param norm = 1.7613e-01, time/batch = 0.6648s	
10985/25300 (epoch 21.709), train_loss = 1.07661784, grad/param norm = 2.1898e-01, time/batch = 0.6630s	
10986/25300 (epoch 21.711), train_loss = 1.07974409, grad/param norm = 2.2534e-01, time/batch = 0.6626s	
10987/25300 (epoch 21.713), train_loss = 0.88484878, grad/param norm = 1.7081e-01, time/batch = 0.6515s	
10988/25300 (epoch 21.715), train_loss = 0.87918230, grad/param norm = 1.7246e-01, time/batch = 0.6541s	
10989/25300 (epoch 21.717), train_loss = 0.83669070, grad/param norm = 2.1639e-01, time/batch = 0.6546s	
10990/25300 (epoch 21.719), train_loss = 0.89705034, grad/param norm = 2.0257e-01, time/batch = 0.6567s	
10991/25300 (epoch 21.721), train_loss = 0.93454332, grad/param norm = 1.9940e-01, time/batch = 0.6621s	
10992/25300 (epoch 21.723), train_loss = 0.87200505, grad/param norm = 1.8066e-01, time/batch = 0.6608s	
10993/25300 (epoch 21.725), train_loss = 0.94723713, grad/param norm = 2.0189e-01, time/batch = 0.6568s	
10994/25300 (epoch 21.727), train_loss = 0.91578096, grad/param norm = 1.8808e-01, time/batch = 0.6543s	
10995/25300 (epoch 21.729), train_loss = 0.91023948, grad/param norm = 1.7855e-01, time/batch = 0.6561s	
10996/25300 (epoch 21.731), train_loss = 1.06586739, grad/param norm = 2.0576e-01, time/batch = 0.6560s	
10997/25300 (epoch 21.733), train_loss = 0.89906134, grad/param norm = 1.8046e-01, time/batch = 0.6583s	
10998/25300 (epoch 21.735), train_loss = 1.17193250, grad/param norm = 2.0844e-01, time/batch = 0.6556s	
10999/25300 (epoch 21.737), train_loss = 0.80565639, grad/param norm = 1.7624e-01, time/batch = 0.6497s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch21.74_1.5932.t7	
11000/25300 (epoch 21.739), train_loss = 1.05369389, grad/param norm = 2.0158e-01, time/batch = 0.6588s	
11001/25300 (epoch 21.741), train_loss = 1.30017114, grad/param norm = 2.4410e-01, time/batch = 0.6629s	
11002/25300 (epoch 21.743), train_loss = 0.88856677, grad/param norm = 1.8596e-01, time/batch = 0.6623s	
11003/25300 (epoch 21.745), train_loss = 0.86309871, grad/param norm = 1.9322e-01, time/batch = 0.6592s	
11004/25300 (epoch 21.747), train_loss = 0.81581002, grad/param norm = 1.7503e-01, time/batch = 0.6566s	
11005/25300 (epoch 21.749), train_loss = 0.93387156, grad/param norm = 1.8497e-01, time/batch = 0.6574s	
11006/25300 (epoch 21.751), train_loss = 0.99492819, grad/param norm = 1.8914e-01, time/batch = 0.6565s	
11007/25300 (epoch 21.753), train_loss = 0.81289153, grad/param norm = 1.8444e-01, time/batch = 0.6549s	
11008/25300 (epoch 21.755), train_loss = 1.01509290, grad/param norm = 2.1022e-01, time/batch = 0.6630s	
11009/25300 (epoch 21.757), train_loss = 0.86688076, grad/param norm = 2.1889e-01, time/batch = 0.6556s	
11010/25300 (epoch 21.759), train_loss = 0.83567111, grad/param norm = 2.0053e-01, time/batch = 0.6551s	
11011/25300 (epoch 21.761), train_loss = 1.07664932, grad/param norm = 2.0193e-01, time/batch = 0.6615s	
11012/25300 (epoch 21.763), train_loss = 0.85197580, grad/param norm = 1.8121e-01, time/batch = 0.6603s	
11013/25300 (epoch 21.765), train_loss = 0.89623867, grad/param norm = 1.9451e-01, time/batch = 0.6615s	
11014/25300 (epoch 21.767), train_loss = 0.85878939, grad/param norm = 2.0612e-01, time/batch = 0.6632s	
11015/25300 (epoch 21.769), train_loss = 0.92517697, grad/param norm = 2.0397e-01, time/batch = 0.6550s	
11016/25300 (epoch 21.771), train_loss = 1.03818714, grad/param norm = 2.2562e-01, time/batch = 0.6530s	
11017/25300 (epoch 21.773), train_loss = 1.05956825, grad/param norm = 2.3750e-01, time/batch = 0.6588s	
11018/25300 (epoch 21.775), train_loss = 0.89970233, grad/param norm = 1.7707e-01, time/batch = 0.6575s	
11019/25300 (epoch 21.777), train_loss = 0.90559712, grad/param norm = 1.9932e-01, time/batch = 0.6586s	
11020/25300 (epoch 21.779), train_loss = 0.99356668, grad/param norm = 1.8232e-01, time/batch = 0.6583s	
11021/25300 (epoch 21.781), train_loss = 0.96015079, grad/param norm = 1.9088e-01, time/batch = 0.6583s	
11022/25300 (epoch 21.783), train_loss = 1.04036977, grad/param norm = 1.9333e-01, time/batch = 0.6553s	
11023/25300 (epoch 21.785), train_loss = 1.01681153, grad/param norm = 2.0913e-01, time/batch = 0.6564s	
11024/25300 (epoch 21.787), train_loss = 1.00497283, grad/param norm = 2.1247e-01, time/batch = 0.6546s	
11025/25300 (epoch 21.789), train_loss = 1.15380132, grad/param norm = 2.2341e-01, time/batch = 0.6579s	
11026/25300 (epoch 21.791), train_loss = 0.97949397, grad/param norm = 1.9379e-01, time/batch = 0.6582s	
11027/25300 (epoch 21.792), train_loss = 1.04443451, grad/param norm = 2.0969e-01, time/batch = 0.6566s	
11028/25300 (epoch 21.794), train_loss = 0.92561341, grad/param norm = 1.9964e-01, time/batch = 0.6573s	
11029/25300 (epoch 21.796), train_loss = 0.88149484, grad/param norm = 2.0586e-01, time/batch = 0.6544s	
11030/25300 (epoch 21.798), train_loss = 1.03686349, grad/param norm = 2.1803e-01, time/batch = 0.6562s	
11031/25300 (epoch 21.800), train_loss = 0.88701049, grad/param norm = 1.8278e-01, time/batch = 0.6570s	
11032/25300 (epoch 21.802), train_loss = 0.76008389, grad/param norm = 1.9447e-01, time/batch = 0.6583s	
11033/25300 (epoch 21.804), train_loss = 0.93553469, grad/param norm = 1.8399e-01, time/batch = 0.6559s	
11034/25300 (epoch 21.806), train_loss = 1.00275846, grad/param norm = 2.1393e-01, time/batch = 0.6619s	
11035/25300 (epoch 21.808), train_loss = 1.01667150, grad/param norm = 2.0583e-01, time/batch = 0.6613s	
11036/25300 (epoch 21.810), train_loss = 0.91719170, grad/param norm = 2.0234e-01, time/batch = 0.6552s	
11037/25300 (epoch 21.812), train_loss = 1.01201697, grad/param norm = 1.8434e-01, time/batch = 0.6584s	
11038/25300 (epoch 21.814), train_loss = 1.08587532, grad/param norm = 2.3827e-01, time/batch = 0.6631s	
11039/25300 (epoch 21.816), train_loss = 1.18870632, grad/param norm = 2.1758e-01, time/batch = 0.6652s	
11040/25300 (epoch 21.818), train_loss = 0.96550315, grad/param norm = 2.0315e-01, time/batch = 0.6608s	
11041/25300 (epoch 21.820), train_loss = 0.99400411, grad/param norm = 2.0063e-01, time/batch = 0.6620s	
11042/25300 (epoch 21.822), train_loss = 0.89991165, grad/param norm = 1.7783e-01, time/batch = 0.6616s	
11043/25300 (epoch 21.824), train_loss = 1.03707082, grad/param norm = 2.0606e-01, time/batch = 0.6579s	
11044/25300 (epoch 21.826), train_loss = 0.87009758, grad/param norm = 1.8003e-01, time/batch = 0.6582s	
11045/25300 (epoch 21.828), train_loss = 0.87529540, grad/param norm = 2.2977e-01, time/batch = 0.6572s	
11046/25300 (epoch 21.830), train_loss = 0.94362208, grad/param norm = 1.9604e-01, time/batch = 0.6584s	
11047/25300 (epoch 21.832), train_loss = 0.98546758, grad/param norm = 1.9150e-01, time/batch = 0.6615s	
11048/25300 (epoch 21.834), train_loss = 0.81643704, grad/param norm = 1.6530e-01, time/batch = 0.6603s	
11049/25300 (epoch 21.836), train_loss = 0.91038332, grad/param norm = 1.8101e-01, time/batch = 0.6586s	
11050/25300 (epoch 21.838), train_loss = 0.91611504, grad/param norm = 1.9913e-01, time/batch = 0.6582s	
11051/25300 (epoch 21.840), train_loss = 1.05094204, grad/param norm = 2.0691e-01, time/batch = 0.6603s	
11052/25300 (epoch 21.842), train_loss = 0.96085100, grad/param norm = 2.1769e-01, time/batch = 0.6573s	
11053/25300 (epoch 21.844), train_loss = 1.00200845, grad/param norm = 1.8649e-01, time/batch = 0.6585s	
11054/25300 (epoch 21.846), train_loss = 1.01599108, grad/param norm = 1.9297e-01, time/batch = 0.6580s	
11055/25300 (epoch 21.848), train_loss = 1.03663110, grad/param norm = 2.1569e-01, time/batch = 0.6565s	
11056/25300 (epoch 21.850), train_loss = 0.99564618, grad/param norm = 2.0930e-01, time/batch = 0.6591s	
11057/25300 (epoch 21.852), train_loss = 1.02321537, grad/param norm = 2.0418e-01, time/batch = 0.6643s	
11058/25300 (epoch 21.854), train_loss = 1.08119650, grad/param norm = 1.9548e-01, time/batch = 0.6591s	
11059/25300 (epoch 21.856), train_loss = 0.94010429, grad/param norm = 2.1418e-01, time/batch = 0.6541s	
11060/25300 (epoch 21.858), train_loss = 0.97143066, grad/param norm = 1.9831e-01, time/batch = 0.6536s	
11061/25300 (epoch 21.860), train_loss = 0.80440772, grad/param norm = 1.7268e-01, time/batch = 0.6560s	
11062/25300 (epoch 21.862), train_loss = 0.94380720, grad/param norm = 2.2270e-01, time/batch = 0.6550s	
11063/25300 (epoch 21.864), train_loss = 1.03787358, grad/param norm = 2.0474e-01, time/batch = 0.6541s	
11064/25300 (epoch 21.866), train_loss = 0.93898471, grad/param norm = 2.1734e-01, time/batch = 0.6576s	
11065/25300 (epoch 21.868), train_loss = 1.07246083, grad/param norm = 2.2278e-01, time/batch = 0.6578s	
11066/25300 (epoch 21.870), train_loss = 1.03089935, grad/param norm = 1.7656e-01, time/batch = 0.6549s	
11067/25300 (epoch 21.872), train_loss = 1.02251704, grad/param norm = 2.4376e-01, time/batch = 0.6555s	
11068/25300 (epoch 21.874), train_loss = 1.00371664, grad/param norm = 2.0434e-01, time/batch = 0.6590s	
11069/25300 (epoch 21.875), train_loss = 0.92570797, grad/param norm = 1.9882e-01, time/batch = 0.6544s	
11070/25300 (epoch 21.877), train_loss = 0.91470960, grad/param norm = 1.7505e-01, time/batch = 0.6535s	
11071/25300 (epoch 21.879), train_loss = 0.91263538, grad/param norm = 2.1968e-01, time/batch = 0.6551s	
11072/25300 (epoch 21.881), train_loss = 1.27286475, grad/param norm = 2.7443e-01, time/batch = 0.6564s	
11073/25300 (epoch 21.883), train_loss = 1.19016168, grad/param norm = 2.2400e-01, time/batch = 0.6567s	
11074/25300 (epoch 21.885), train_loss = 1.05114362, grad/param norm = 2.3187e-01, time/batch = 0.6569s	
11075/25300 (epoch 21.887), train_loss = 1.02373392, grad/param norm = 1.9644e-01, time/batch = 0.6567s	
11076/25300 (epoch 21.889), train_loss = 1.14159236, grad/param norm = 2.1499e-01, time/batch = 0.6594s	
11077/25300 (epoch 21.891), train_loss = 1.00243000, grad/param norm = 2.2830e-01, time/batch = 0.6580s	
11078/25300 (epoch 21.893), train_loss = 1.03621613, grad/param norm = 2.1416e-01, time/batch = 0.6530s	
11079/25300 (epoch 21.895), train_loss = 0.74583683, grad/param norm = 1.8785e-01, time/batch = 0.6551s	
11080/25300 (epoch 21.897), train_loss = 0.86897322, grad/param norm = 1.9298e-01, time/batch = 0.6593s	
11081/25300 (epoch 21.899), train_loss = 0.99266091, grad/param norm = 1.9431e-01, time/batch = 0.6575s	
11082/25300 (epoch 21.901), train_loss = 1.01334120, grad/param norm = 1.9525e-01, time/batch = 0.6535s	
11083/25300 (epoch 21.903), train_loss = 0.77164925, grad/param norm = 2.2230e-01, time/batch = 0.6564s	
11084/25300 (epoch 21.905), train_loss = 0.87652532, grad/param norm = 2.0005e-01, time/batch = 0.6563s	
11085/25300 (epoch 21.907), train_loss = 0.89982889, grad/param norm = 2.0757e-01, time/batch = 0.6603s	
11086/25300 (epoch 21.909), train_loss = 1.02863732, grad/param norm = 2.1251e-01, time/batch = 0.6657s	
11087/25300 (epoch 21.911), train_loss = 1.10394156, grad/param norm = 2.3594e-01, time/batch = 0.6630s	
11088/25300 (epoch 21.913), train_loss = 1.18104168, grad/param norm = 2.4168e-01, time/batch = 0.6556s	
11089/25300 (epoch 21.915), train_loss = 0.91465864, grad/param norm = 2.3248e-01, time/batch = 0.6546s	
11090/25300 (epoch 21.917), train_loss = 1.06204564, grad/param norm = 2.1124e-01, time/batch = 0.6557s	
11091/25300 (epoch 21.919), train_loss = 1.08341156, grad/param norm = 2.1693e-01, time/batch = 0.6561s	
11092/25300 (epoch 21.921), train_loss = 0.88163869, grad/param norm = 1.9090e-01, time/batch = 0.6563s	
11093/25300 (epoch 21.923), train_loss = 1.10042205, grad/param norm = 2.0071e-01, time/batch = 0.6583s	
11094/25300 (epoch 21.925), train_loss = 0.95807043, grad/param norm = 2.1282e-01, time/batch = 0.6566s	
11095/25300 (epoch 21.927), train_loss = 0.91569591, grad/param norm = 2.0090e-01, time/batch = 0.6583s	
11096/25300 (epoch 21.929), train_loss = 0.97335244, grad/param norm = 1.8860e-01, time/batch = 0.6588s	
11097/25300 (epoch 21.931), train_loss = 1.02860782, grad/param norm = 2.0974e-01, time/batch = 0.6619s	
11098/25300 (epoch 21.933), train_loss = 1.01439951, grad/param norm = 2.1013e-01, time/batch = 0.6613s	
11099/25300 (epoch 21.935), train_loss = 0.99500801, grad/param norm = 1.9354e-01, time/batch = 0.6567s	
11100/25300 (epoch 21.937), train_loss = 0.74355022, grad/param norm = 1.7969e-01, time/batch = 0.6699s	
11101/25300 (epoch 21.939), train_loss = 1.00720689, grad/param norm = 1.8814e-01, time/batch = 0.6663s	
11102/25300 (epoch 21.941), train_loss = 0.88824695, grad/param norm = 2.1193e-01, time/batch = 0.6579s	
11103/25300 (epoch 21.943), train_loss = 0.97967603, grad/param norm = 1.8472e-01, time/batch = 0.6534s	
11104/25300 (epoch 21.945), train_loss = 1.02348785, grad/param norm = 2.0400e-01, time/batch = 0.6528s	
11105/25300 (epoch 21.947), train_loss = 0.86811074, grad/param norm = 1.8480e-01, time/batch = 0.6522s	
11106/25300 (epoch 21.949), train_loss = 1.03063860, grad/param norm = 1.9906e-01, time/batch = 0.6529s	
11107/25300 (epoch 21.951), train_loss = 0.95489152, grad/param norm = 1.8471e-01, time/batch = 0.6565s	
11108/25300 (epoch 21.953), train_loss = 0.96791336, grad/param norm = 2.0908e-01, time/batch = 0.6560s	
11109/25300 (epoch 21.955), train_loss = 1.17767119, grad/param norm = 2.2689e-01, time/batch = 0.6543s	
11110/25300 (epoch 21.957), train_loss = 1.11615051, grad/param norm = 2.2456e-01, time/batch = 0.6579s	
11111/25300 (epoch 21.958), train_loss = 1.05698080, grad/param norm = 2.3084e-01, time/batch = 0.6544s	
11112/25300 (epoch 21.960), train_loss = 1.16629546, grad/param norm = 2.3598e-01, time/batch = 0.6528s	
11113/25300 (epoch 21.962), train_loss = 1.12090486, grad/param norm = 2.2364e-01, time/batch = 0.6540s	
11114/25300 (epoch 21.964), train_loss = 1.03609604, grad/param norm = 2.1368e-01, time/batch = 0.6526s	
11115/25300 (epoch 21.966), train_loss = 0.83582887, grad/param norm = 1.9569e-01, time/batch = 0.6508s	
11116/25300 (epoch 21.968), train_loss = 0.81423015, grad/param norm = 1.7361e-01, time/batch = 0.6524s	
11117/25300 (epoch 21.970), train_loss = 0.94280363, grad/param norm = 2.5340e-01, time/batch = 0.6509s	
11118/25300 (epoch 21.972), train_loss = 0.95936404, grad/param norm = 2.0290e-01, time/batch = 0.6536s	
11119/25300 (epoch 21.974), train_loss = 1.12106749, grad/param norm = 2.3217e-01, time/batch = 0.6506s	
11120/25300 (epoch 21.976), train_loss = 1.00730332, grad/param norm = 1.9837e-01, time/batch = 0.6464s	
11121/25300 (epoch 21.978), train_loss = 0.96192987, grad/param norm = 2.0599e-01, time/batch = 0.6473s	
11122/25300 (epoch 21.980), train_loss = 1.00881951, grad/param norm = 2.3666e-01, time/batch = 0.6512s	
11123/25300 (epoch 21.982), train_loss = 0.92559031, grad/param norm = 1.9730e-01, time/batch = 0.6523s	
11124/25300 (epoch 21.984), train_loss = 0.96156780, grad/param norm = 2.2268e-01, time/batch = 0.6558s	
11125/25300 (epoch 21.986), train_loss = 1.06942283, grad/param norm = 2.2375e-01, time/batch = 0.6560s	
11126/25300 (epoch 21.988), train_loss = 0.99789170, grad/param norm = 2.0630e-01, time/batch = 0.6575s	
11127/25300 (epoch 21.990), train_loss = 0.95519333, grad/param norm = 1.9530e-01, time/batch = 0.6562s	
11128/25300 (epoch 21.992), train_loss = 0.81754854, grad/param norm = 1.9694e-01, time/batch = 0.6550s	
11129/25300 (epoch 21.994), train_loss = 0.98350357, grad/param norm = 1.9940e-01, time/batch = 0.6548s	
11130/25300 (epoch 21.996), train_loss = 1.10818568, grad/param norm = 2.2255e-01, time/batch = 0.8071s	
11131/25300 (epoch 21.998), train_loss = 1.08295531, grad/param norm = 2.1375e-01, time/batch = 0.9587s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
11132/25300 (epoch 22.000), train_loss = 0.97653637, grad/param norm = 1.9111e-01, time/batch = 0.9811s	
11133/25300 (epoch 22.002), train_loss = 0.87757603, grad/param norm = 1.7823e-01, time/batch = 0.9620s	
11134/25300 (epoch 22.004), train_loss = 0.80274348, grad/param norm = 1.7326e-01, time/batch = 0.9627s	
11135/25300 (epoch 22.006), train_loss = 1.10886053, grad/param norm = 1.9726e-01, time/batch = 1.2966s	
11136/25300 (epoch 22.008), train_loss = 0.95476965, grad/param norm = 1.7005e-01, time/batch = 1.8067s	
11137/25300 (epoch 22.010), train_loss = 0.97302865, grad/param norm = 1.8311e-01, time/batch = 1.7814s	
11138/25300 (epoch 22.012), train_loss = 0.91414133, grad/param norm = 1.9595e-01, time/batch = 11.3266s	
11139/25300 (epoch 22.014), train_loss = 1.09950507, grad/param norm = 1.9403e-01, time/batch = 16.1399s	
11140/25300 (epoch 22.016), train_loss = 0.97446800, grad/param norm = 1.9957e-01, time/batch = 16.3429s	
11141/25300 (epoch 22.018), train_loss = 0.85406242, grad/param norm = 1.9024e-01, time/batch = 15.8877s	
11142/25300 (epoch 22.020), train_loss = 0.94322431, grad/param norm = 1.8989e-01, time/batch = 16.3271s	
11143/25300 (epoch 22.022), train_loss = 0.98032993, grad/param norm = 2.2051e-01, time/batch = 16.7911s	
11144/25300 (epoch 22.024), train_loss = 0.73466326, grad/param norm = 1.6098e-01, time/batch = 18.8052s	
11145/25300 (epoch 22.026), train_loss = 0.90901367, grad/param norm = 2.0627e-01, time/batch = 16.7405s	
11146/25300 (epoch 22.028), train_loss = 0.86396459, grad/param norm = 1.7185e-01, time/batch = 16.6111s	
11147/25300 (epoch 22.030), train_loss = 1.05148448, grad/param norm = 1.8767e-01, time/batch = 0.6720s	
11148/25300 (epoch 22.032), train_loss = 0.90391214, grad/param norm = 1.9461e-01, time/batch = 0.6599s	
11149/25300 (epoch 22.034), train_loss = 0.83723649, grad/param norm = 1.9710e-01, time/batch = 0.6595s	
11150/25300 (epoch 22.036), train_loss = 0.79302638, grad/param norm = 1.6724e-01, time/batch = 0.6615s	
11151/25300 (epoch 22.038), train_loss = 0.72393549, grad/param norm = 1.5222e-01, time/batch = 0.6611s	
11152/25300 (epoch 22.040), train_loss = 0.96394946, grad/param norm = 1.9769e-01, time/batch = 0.6574s	
11153/25300 (epoch 22.042), train_loss = 0.92932368, grad/param norm = 1.8987e-01, time/batch = 0.6615s	
11154/25300 (epoch 22.043), train_loss = 0.78255766, grad/param norm = 1.5615e-01, time/batch = 0.6591s	
11155/25300 (epoch 22.045), train_loss = 0.81026799, grad/param norm = 1.6072e-01, time/batch = 0.6589s	
11156/25300 (epoch 22.047), train_loss = 0.99757832, grad/param norm = 1.9082e-01, time/batch = 0.6591s	
11157/25300 (epoch 22.049), train_loss = 0.95558887, grad/param norm = 1.9814e-01, time/batch = 0.6594s	
11158/25300 (epoch 22.051), train_loss = 1.05173873, grad/param norm = 2.2098e-01, time/batch = 0.6581s	
11159/25300 (epoch 22.053), train_loss = 0.76776718, grad/param norm = 1.6665e-01, time/batch = 0.6578s	
11160/25300 (epoch 22.055), train_loss = 0.82508093, grad/param norm = 1.7256e-01, time/batch = 0.6565s	
11161/25300 (epoch 22.057), train_loss = 0.77858784, grad/param norm = 1.5599e-01, time/batch = 0.6614s	
11162/25300 (epoch 22.059), train_loss = 0.88330732, grad/param norm = 1.8087e-01, time/batch = 0.6637s	
11163/25300 (epoch 22.061), train_loss = 0.86408080, grad/param norm = 1.7879e-01, time/batch = 0.6638s	
11164/25300 (epoch 22.063), train_loss = 0.83883699, grad/param norm = 1.7841e-01, time/batch = 0.6549s	
11165/25300 (epoch 22.065), train_loss = 0.97295678, grad/param norm = 1.9462e-01, time/batch = 0.6576s	
11166/25300 (epoch 22.067), train_loss = 1.03425430, grad/param norm = 1.9990e-01, time/batch = 0.6597s	
11167/25300 (epoch 22.069), train_loss = 0.86305163, grad/param norm = 1.8127e-01, time/batch = 0.6613s	
11168/25300 (epoch 22.071), train_loss = 1.05008962, grad/param norm = 1.9956e-01, time/batch = 0.6605s	
11169/25300 (epoch 22.073), train_loss = 0.87781619, grad/param norm = 1.6987e-01, time/batch = 0.6601s	
11170/25300 (epoch 22.075), train_loss = 1.00479075, grad/param norm = 1.9818e-01, time/batch = 0.6602s	
11171/25300 (epoch 22.077), train_loss = 0.96678330, grad/param norm = 2.0679e-01, time/batch = 0.6629s	
11172/25300 (epoch 22.079), train_loss = 0.90995396, grad/param norm = 2.0075e-01, time/batch = 0.6595s	
11173/25300 (epoch 22.081), train_loss = 0.91091133, grad/param norm = 1.6777e-01, time/batch = 0.6591s	
11174/25300 (epoch 22.083), train_loss = 0.92787136, grad/param norm = 1.7139e-01, time/batch = 0.6606s	
11175/25300 (epoch 22.085), train_loss = 1.13586837, grad/param norm = 2.2797e-01, time/batch = 0.6593s	
11176/25300 (epoch 22.087), train_loss = 1.03749039, grad/param norm = 1.9849e-01, time/batch = 0.6658s	
11177/25300 (epoch 22.089), train_loss = 0.98760032, grad/param norm = 1.8933e-01, time/batch = 0.6671s	
11178/25300 (epoch 22.091), train_loss = 1.10341407, grad/param norm = 2.0549e-01, time/batch = 0.6626s	
11179/25300 (epoch 22.093), train_loss = 1.05643688, grad/param norm = 2.2034e-01, time/batch = 0.6708s	
11180/25300 (epoch 22.095), train_loss = 1.02135529, grad/param norm = 1.9460e-01, time/batch = 0.6605s	
11181/25300 (epoch 22.097), train_loss = 0.99258094, grad/param norm = 2.1591e-01, time/batch = 0.6597s	
11182/25300 (epoch 22.099), train_loss = 0.99227109, grad/param norm = 1.9871e-01, time/batch = 0.6608s	
11183/25300 (epoch 22.101), train_loss = 0.91136277, grad/param norm = 1.9282e-01, time/batch = 0.6592s	
11184/25300 (epoch 22.103), train_loss = 0.95108508, grad/param norm = 1.8096e-01, time/batch = 0.6624s	
11185/25300 (epoch 22.105), train_loss = 1.02388398, grad/param norm = 1.8716e-01, time/batch = 0.6624s	
11186/25300 (epoch 22.107), train_loss = 1.03282012, grad/param norm = 2.2569e-01, time/batch = 0.6601s	
11187/25300 (epoch 22.109), train_loss = 0.96175134, grad/param norm = 2.0543e-01, time/batch = 0.6611s	
11188/25300 (epoch 22.111), train_loss = 0.92501757, grad/param norm = 2.0074e-01, time/batch = 0.6586s	
11189/25300 (epoch 22.113), train_loss = 0.90277856, grad/param norm = 2.0134e-01, time/batch = 0.6603s	
11190/25300 (epoch 22.115), train_loss = 0.94080870, grad/param norm = 2.1140e-01, time/batch = 0.6601s	
11191/25300 (epoch 22.117), train_loss = 1.01548632, grad/param norm = 1.8482e-01, time/batch = 0.6631s	
11192/25300 (epoch 22.119), train_loss = 0.90986628, grad/param norm = 1.9801e-01, time/batch = 0.6614s	
11193/25300 (epoch 22.121), train_loss = 0.96577412, grad/param norm = 1.9986e-01, time/batch = 0.6616s	
11194/25300 (epoch 22.123), train_loss = 0.90602452, grad/param norm = 1.9407e-01, time/batch = 0.6600s	
11195/25300 (epoch 22.125), train_loss = 1.03457196, grad/param norm = 1.9113e-01, time/batch = 0.6582s	
11196/25300 (epoch 22.126), train_loss = 0.92984825, grad/param norm = 2.1143e-01, time/batch = 0.6592s	
11197/25300 (epoch 22.128), train_loss = 0.93774589, grad/param norm = 2.2010e-01, time/batch = 0.6607s	
11198/25300 (epoch 22.130), train_loss = 0.76162660, grad/param norm = 1.7638e-01, time/batch = 0.6616s	
11199/25300 (epoch 22.132), train_loss = 0.80724937, grad/param norm = 1.8692e-01, time/batch = 0.6607s	
11200/25300 (epoch 22.134), train_loss = 0.76690020, grad/param norm = 1.6545e-01, time/batch = 0.6590s	
11201/25300 (epoch 22.136), train_loss = 0.92266486, grad/param norm = 1.8451e-01, time/batch = 0.6606s	
11202/25300 (epoch 22.138), train_loss = 0.80649866, grad/param norm = 1.8128e-01, time/batch = 0.6571s	
11203/25300 (epoch 22.140), train_loss = 0.84869141, grad/param norm = 1.7512e-01, time/batch = 0.6562s	
11204/25300 (epoch 22.142), train_loss = 1.03002556, grad/param norm = 1.8829e-01, time/batch = 0.6596s	
11205/25300 (epoch 22.144), train_loss = 1.00968624, grad/param norm = 1.9863e-01, time/batch = 0.6590s	
11206/25300 (epoch 22.146), train_loss = 0.99006082, grad/param norm = 2.2851e-01, time/batch = 0.6516s	
11207/25300 (epoch 22.148), train_loss = 0.94820578, grad/param norm = 1.8573e-01, time/batch = 0.6571s	
11208/25300 (epoch 22.150), train_loss = 1.04395539, grad/param norm = 2.1805e-01, time/batch = 0.6580s	
11209/25300 (epoch 22.152), train_loss = 1.10392226, grad/param norm = 2.2660e-01, time/batch = 0.6549s	
11210/25300 (epoch 22.154), train_loss = 0.78838375, grad/param norm = 1.7934e-01, time/batch = 0.6562s	
11211/25300 (epoch 22.156), train_loss = 1.01730905, grad/param norm = 2.0445e-01, time/batch = 0.6592s	
11212/25300 (epoch 22.158), train_loss = 0.83923463, grad/param norm = 1.8510e-01, time/batch = 0.6582s	
11213/25300 (epoch 22.160), train_loss = 0.92452700, grad/param norm = 1.8059e-01, time/batch = 0.6536s	
11214/25300 (epoch 22.162), train_loss = 0.89187065, grad/param norm = 2.2338e-01, time/batch = 0.6558s	
11215/25300 (epoch 22.164), train_loss = 1.00629725, grad/param norm = 1.9783e-01, time/batch = 0.6580s	
11216/25300 (epoch 22.166), train_loss = 0.93677080, grad/param norm = 1.7977e-01, time/batch = 0.6657s	
11217/25300 (epoch 22.168), train_loss = 0.83694394, grad/param norm = 1.5880e-01, time/batch = 0.6675s	
11218/25300 (epoch 22.170), train_loss = 0.90784522, grad/param norm = 1.8231e-01, time/batch = 0.6623s	
11219/25300 (epoch 22.172), train_loss = 0.83854132, grad/param norm = 1.8135e-01, time/batch = 0.6610s	
11220/25300 (epoch 22.174), train_loss = 0.83414193, grad/param norm = 1.8008e-01, time/batch = 0.6634s	
11221/25300 (epoch 22.176), train_loss = 0.84490697, grad/param norm = 1.9432e-01, time/batch = 0.6688s	
11222/25300 (epoch 22.178), train_loss = 1.05518078, grad/param norm = 1.9940e-01, time/batch = 0.6644s	
11223/25300 (epoch 22.180), train_loss = 0.76149343, grad/param norm = 1.6251e-01, time/batch = 0.6554s	
11224/25300 (epoch 22.182), train_loss = 0.87218434, grad/param norm = 2.0548e-01, time/batch = 0.6535s	
11225/25300 (epoch 22.184), train_loss = 0.86276585, grad/param norm = 1.9059e-01, time/batch = 0.6512s	
11226/25300 (epoch 22.186), train_loss = 0.84710219, grad/param norm = 1.9454e-01, time/batch = 0.6544s	
11227/25300 (epoch 22.188), train_loss = 0.95510063, grad/param norm = 2.1183e-01, time/batch = 0.6559s	
11228/25300 (epoch 22.190), train_loss = 0.89202055, grad/param norm = 1.9276e-01, time/batch = 0.6562s	
11229/25300 (epoch 22.192), train_loss = 0.91669285, grad/param norm = 1.9997e-01, time/batch = 0.6556s	
11230/25300 (epoch 22.194), train_loss = 0.90957892, grad/param norm = 2.0381e-01, time/batch = 0.6660s	
11231/25300 (epoch 22.196), train_loss = 1.04020162, grad/param norm = 2.7896e-01, time/batch = 0.6702s	
11232/25300 (epoch 22.198), train_loss = 0.88506006, grad/param norm = 2.1663e-01, time/batch = 0.6731s	
11233/25300 (epoch 22.200), train_loss = 0.89027606, grad/param norm = 2.0493e-01, time/batch = 0.6762s	
11234/25300 (epoch 22.202), train_loss = 0.90576908, grad/param norm = 1.7633e-01, time/batch = 0.6781s	
11235/25300 (epoch 22.204), train_loss = 0.89717596, grad/param norm = 1.8303e-01, time/batch = 0.6726s	
11236/25300 (epoch 22.206), train_loss = 1.01805162, grad/param norm = 2.0072e-01, time/batch = 0.6627s	
11237/25300 (epoch 22.208), train_loss = 0.81161693, grad/param norm = 1.9813e-01, time/batch = 0.6601s	
11238/25300 (epoch 22.209), train_loss = 0.78918512, grad/param norm = 1.7955e-01, time/batch = 0.6594s	
11239/25300 (epoch 22.211), train_loss = 0.87445400, grad/param norm = 1.8109e-01, time/batch = 0.6587s	
11240/25300 (epoch 22.213), train_loss = 0.95888804, grad/param norm = 1.9715e-01, time/batch = 0.6580s	
11241/25300 (epoch 22.215), train_loss = 0.92243762, grad/param norm = 1.8216e-01, time/batch = 0.6565s	
11242/25300 (epoch 22.217), train_loss = 0.96055459, grad/param norm = 2.2384e-01, time/batch = 0.6558s	
11243/25300 (epoch 22.219), train_loss = 1.02432375, grad/param norm = 2.1049e-01, time/batch = 0.6549s	
11244/25300 (epoch 22.221), train_loss = 1.06815880, grad/param norm = 2.0235e-01, time/batch = 0.6492s	
11245/25300 (epoch 22.223), train_loss = 1.00915932, grad/param norm = 2.2445e-01, time/batch = 0.6559s	
11246/25300 (epoch 22.225), train_loss = 1.33143667, grad/param norm = 2.8728e-01, time/batch = 0.6600s	
11247/25300 (epoch 22.227), train_loss = 1.06384600, grad/param norm = 2.1156e-01, time/batch = 0.6528s	
11248/25300 (epoch 22.229), train_loss = 0.94611432, grad/param norm = 1.8691e-01, time/batch = 0.6556s	
11249/25300 (epoch 22.231), train_loss = 0.91904537, grad/param norm = 1.9546e-01, time/batch = 0.6611s	
11250/25300 (epoch 22.233), train_loss = 1.00229337, grad/param norm = 1.9890e-01, time/batch = 0.6549s	
11251/25300 (epoch 22.235), train_loss = 0.93099168, grad/param norm = 1.9156e-01, time/batch = 0.6570s	
11252/25300 (epoch 22.237), train_loss = 1.09371397, grad/param norm = 2.2280e-01, time/batch = 0.6618s	
11253/25300 (epoch 22.239), train_loss = 0.91353620, grad/param norm = 1.7552e-01, time/batch = 0.6595s	
11254/25300 (epoch 22.241), train_loss = 1.07981432, grad/param norm = 2.0013e-01, time/batch = 0.6624s	
11255/25300 (epoch 22.243), train_loss = 1.23181795, grad/param norm = 2.4504e-01, time/batch = 0.6603s	
11256/25300 (epoch 22.245), train_loss = 0.89401070, grad/param norm = 1.8094e-01, time/batch = 0.6587s	
11257/25300 (epoch 22.247), train_loss = 1.02559039, grad/param norm = 1.9425e-01, time/batch = 0.6612s	
11258/25300 (epoch 22.249), train_loss = 0.81334006, grad/param norm = 1.7134e-01, time/batch = 0.6589s	
11259/25300 (epoch 22.251), train_loss = 0.81173884, grad/param norm = 1.8105e-01, time/batch = 0.6608s	
11260/25300 (epoch 22.253), train_loss = 0.91094540, grad/param norm = 1.8485e-01, time/batch = 0.6645s	
11261/25300 (epoch 22.255), train_loss = 0.88339303, grad/param norm = 2.0415e-01, time/batch = 0.6650s	
11262/25300 (epoch 22.257), train_loss = 0.94015771, grad/param norm = 1.9966e-01, time/batch = 0.6590s	
11263/25300 (epoch 22.259), train_loss = 1.14804698, grad/param norm = 2.5605e-01, time/batch = 0.6555s	
11264/25300 (epoch 22.261), train_loss = 1.11115068, grad/param norm = 2.5410e-01, time/batch = 0.6596s	
11265/25300 (epoch 22.263), train_loss = 1.09646109, grad/param norm = 2.0895e-01, time/batch = 0.6615s	
11266/25300 (epoch 22.265), train_loss = 1.13506793, grad/param norm = 2.2294e-01, time/batch = 0.6624s	
11267/25300 (epoch 22.267), train_loss = 1.02437744, grad/param norm = 2.0860e-01, time/batch = 0.6589s	
11268/25300 (epoch 22.269), train_loss = 0.78787848, grad/param norm = 1.6461e-01, time/batch = 0.6598s	
11269/25300 (epoch 22.271), train_loss = 0.88970111, grad/param norm = 1.9445e-01, time/batch = 0.6619s	
11270/25300 (epoch 22.273), train_loss = 1.00644274, grad/param norm = 2.1145e-01, time/batch = 0.6598s	
11271/25300 (epoch 22.275), train_loss = 0.91061230, grad/param norm = 1.5389e-01, time/batch = 0.6602s	
11272/25300 (epoch 22.277), train_loss = 0.89418389, grad/param norm = 2.0102e-01, time/batch = 0.6640s	
11273/25300 (epoch 22.279), train_loss = 0.92625289, grad/param norm = 1.8552e-01, time/batch = 0.6612s	
11274/25300 (epoch 22.281), train_loss = 1.10627718, grad/param norm = 2.2099e-01, time/batch = 0.6615s	
11275/25300 (epoch 22.283), train_loss = 0.82283791, grad/param norm = 1.6760e-01, time/batch = 0.6617s	
11276/25300 (epoch 22.285), train_loss = 0.97779213, grad/param norm = 2.1415e-01, time/batch = 0.6597s	
11277/25300 (epoch 22.287), train_loss = 1.01165993, grad/param norm = 1.9653e-01, time/batch = 0.6590s	
11278/25300 (epoch 22.289), train_loss = 0.91105634, grad/param norm = 1.8385e-01, time/batch = 0.6565s	
11279/25300 (epoch 22.291), train_loss = 0.92730654, grad/param norm = 1.9503e-01, time/batch = 0.6592s	
11280/25300 (epoch 22.292), train_loss = 1.09223238, grad/param norm = 1.9410e-01, time/batch = 0.6590s	
11281/25300 (epoch 22.294), train_loss = 0.97514558, grad/param norm = 1.8771e-01, time/batch = 0.6622s	
11282/25300 (epoch 22.296), train_loss = 0.85125268, grad/param norm = 1.8216e-01, time/batch = 0.6626s	
11283/25300 (epoch 22.298), train_loss = 1.03105581, grad/param norm = 2.2406e-01, time/batch = 0.6591s	
11284/25300 (epoch 22.300), train_loss = 1.05709091, grad/param norm = 2.3374e-01, time/batch = 0.6605s	
11285/25300 (epoch 22.302), train_loss = 0.77631393, grad/param norm = 1.9538e-01, time/batch = 0.6596s	
11286/25300 (epoch 22.304), train_loss = 1.03935768, grad/param norm = 2.0113e-01, time/batch = 0.6599s	
11287/25300 (epoch 22.306), train_loss = 0.74833153, grad/param norm = 1.8320e-01, time/batch = 0.6581s	
11288/25300 (epoch 22.308), train_loss = 0.99743315, grad/param norm = 1.7952e-01, time/batch = 0.6578s	
11289/25300 (epoch 22.310), train_loss = 0.84082759, grad/param norm = 1.8863e-01, time/batch = 0.6587s	
11290/25300 (epoch 22.312), train_loss = 0.96709665, grad/param norm = 1.8395e-01, time/batch = 0.6589s	
11291/25300 (epoch 22.314), train_loss = 0.77802570, grad/param norm = 1.7094e-01, time/batch = 0.6630s	
11292/25300 (epoch 22.316), train_loss = 0.96250241, grad/param norm = 1.8596e-01, time/batch = 0.6598s	
11293/25300 (epoch 22.318), train_loss = 0.78325505, grad/param norm = 1.8249e-01, time/batch = 0.6598s	
11294/25300 (epoch 22.320), train_loss = 0.84445601, grad/param norm = 1.9003e-01, time/batch = 0.6593s	
11295/25300 (epoch 22.322), train_loss = 1.12462412, grad/param norm = 2.2628e-01, time/batch = 0.6616s	
11296/25300 (epoch 22.324), train_loss = 0.84442682, grad/param norm = 1.7387e-01, time/batch = 0.6598s	
11297/25300 (epoch 22.326), train_loss = 0.76299861, grad/param norm = 1.7451e-01, time/batch = 0.6606s	
11298/25300 (epoch 22.328), train_loss = 0.77224560, grad/param norm = 1.9290e-01, time/batch = 0.6600s	
11299/25300 (epoch 22.330), train_loss = 0.89975428, grad/param norm = 1.9350e-01, time/batch = 0.6582s	
11300/25300 (epoch 22.332), train_loss = 0.95129990, grad/param norm = 1.8527e-01, time/batch = 0.6602s	
11301/25300 (epoch 22.334), train_loss = 0.78910920, grad/param norm = 1.9136e-01, time/batch = 0.6623s	
11302/25300 (epoch 22.336), train_loss = 0.80215724, grad/param norm = 1.8307e-01, time/batch = 0.6624s	
11303/25300 (epoch 22.338), train_loss = 0.79990183, grad/param norm = 1.7906e-01, time/batch = 0.6661s	
11304/25300 (epoch 22.340), train_loss = 0.85225537, grad/param norm = 1.8886e-01, time/batch = 0.6596s	
11305/25300 (epoch 22.342), train_loss = 0.88587788, grad/param norm = 2.1083e-01, time/batch = 0.6584s	
11306/25300 (epoch 22.344), train_loss = 0.96258823, grad/param norm = 1.9561e-01, time/batch = 0.6587s	
11307/25300 (epoch 22.346), train_loss = 0.89035540, grad/param norm = 2.0967e-01, time/batch = 0.6590s	
11308/25300 (epoch 22.348), train_loss = 0.79678909, grad/param norm = 1.8760e-01, time/batch = 0.6570s	
11309/25300 (epoch 22.350), train_loss = 0.89693699, grad/param norm = 1.8900e-01, time/batch = 0.6598s	
11310/25300 (epoch 22.352), train_loss = 0.91547881, grad/param norm = 1.8313e-01, time/batch = 0.6587s	
11311/25300 (epoch 22.354), train_loss = 0.87257240, grad/param norm = 1.9876e-01, time/batch = 0.6558s	
11312/25300 (epoch 22.356), train_loss = 0.91011673, grad/param norm = 1.9032e-01, time/batch = 0.6577s	
11313/25300 (epoch 22.358), train_loss = 0.99309061, grad/param norm = 2.3024e-01, time/batch = 0.6535s	
11314/25300 (epoch 22.360), train_loss = 0.83455382, grad/param norm = 1.7924e-01, time/batch = 0.6576s	
11315/25300 (epoch 22.362), train_loss = 0.85206027, grad/param norm = 1.9162e-01, time/batch = 0.6609s	
11316/25300 (epoch 22.364), train_loss = 0.87576267, grad/param norm = 2.0285e-01, time/batch = 0.6616s	
11317/25300 (epoch 22.366), train_loss = 0.78708373, grad/param norm = 1.7538e-01, time/batch = 0.6562s	
11318/25300 (epoch 22.368), train_loss = 0.89105218, grad/param norm = 1.7973e-01, time/batch = 0.6575s	
11319/25300 (epoch 22.370), train_loss = 0.86668945, grad/param norm = 1.9623e-01, time/batch = 0.6581s	
11320/25300 (epoch 22.372), train_loss = 0.86300917, grad/param norm = 2.0742e-01, time/batch = 0.6650s	
11321/25300 (epoch 22.374), train_loss = 0.78422740, grad/param norm = 1.8728e-01, time/batch = 0.6699s	
11322/25300 (epoch 22.375), train_loss = 1.02962919, grad/param norm = 2.1096e-01, time/batch = 0.6688s	
11323/25300 (epoch 22.377), train_loss = 0.97053743, grad/param norm = 2.0657e-01, time/batch = 0.6742s	
11324/25300 (epoch 22.379), train_loss = 0.94588263, grad/param norm = 1.9975e-01, time/batch = 0.6571s	
11325/25300 (epoch 22.381), train_loss = 0.89991822, grad/param norm = 1.8469e-01, time/batch = 0.6565s	
11326/25300 (epoch 22.383), train_loss = 0.83567078, grad/param norm = 1.8581e-01, time/batch = 0.6595s	
11327/25300 (epoch 22.385), train_loss = 0.92726983, grad/param norm = 1.9104e-01, time/batch = 0.6597s	
11328/25300 (epoch 22.387), train_loss = 0.94621396, grad/param norm = 1.9663e-01, time/batch = 0.6646s	
11329/25300 (epoch 22.389), train_loss = 0.96602323, grad/param norm = 2.0041e-01, time/batch = 0.6619s	
11330/25300 (epoch 22.391), train_loss = 0.85778916, grad/param norm = 1.7964e-01, time/batch = 0.6605s	
11331/25300 (epoch 22.393), train_loss = 0.95672027, grad/param norm = 2.3403e-01, time/batch = 0.6588s	
11332/25300 (epoch 22.395), train_loss = 0.76532490, grad/param norm = 1.6568e-01, time/batch = 0.6582s	
11333/25300 (epoch 22.397), train_loss = 0.78347815, grad/param norm = 2.1411e-01, time/batch = 0.6590s	
11334/25300 (epoch 22.399), train_loss = 0.76976585, grad/param norm = 1.8363e-01, time/batch = 0.6723s	
11335/25300 (epoch 22.401), train_loss = 0.98826241, grad/param norm = 2.1350e-01, time/batch = 0.6643s	
11336/25300 (epoch 22.403), train_loss = 0.91993902, grad/param norm = 3.1879e-01, time/batch = 0.6833s	
11337/25300 (epoch 22.405), train_loss = 0.92308654, grad/param norm = 2.0788e-01, time/batch = 0.6665s	
11338/25300 (epoch 22.407), train_loss = 0.89965586, grad/param norm = 2.0416e-01, time/batch = 0.6683s	
11339/25300 (epoch 22.409), train_loss = 0.84638648, grad/param norm = 1.9187e-01, time/batch = 0.6627s	
11340/25300 (epoch 22.411), train_loss = 0.82647427, grad/param norm = 1.8685e-01, time/batch = 0.6601s	
11341/25300 (epoch 22.413), train_loss = 0.76889536, grad/param norm = 1.8348e-01, time/batch = 0.6697s	
11342/25300 (epoch 22.415), train_loss = 0.80462463, grad/param norm = 1.9911e-01, time/batch = 0.6576s	
11343/25300 (epoch 22.417), train_loss = 0.77192961, grad/param norm = 1.7808e-01, time/batch = 0.6593s	
11344/25300 (epoch 22.419), train_loss = 0.70272177, grad/param norm = 1.6058e-01, time/batch = 0.6579s	
11345/25300 (epoch 22.421), train_loss = 0.79229345, grad/param norm = 1.5778e-01, time/batch = 0.6571s	
11346/25300 (epoch 22.423), train_loss = 0.78115915, grad/param norm = 1.7004e-01, time/batch = 0.6551s	
11347/25300 (epoch 22.425), train_loss = 0.86540190, grad/param norm = 2.0489e-01, time/batch = 0.6537s	
11348/25300 (epoch 22.427), train_loss = 1.05910348, grad/param norm = 2.0893e-01, time/batch = 0.6566s	
11349/25300 (epoch 22.429), train_loss = 0.96960373, grad/param norm = 1.8845e-01, time/batch = 0.6580s	
11350/25300 (epoch 22.431), train_loss = 0.95569214, grad/param norm = 2.0052e-01, time/batch = 0.6592s	
11351/25300 (epoch 22.433), train_loss = 0.89586580, grad/param norm = 1.7853e-01, time/batch = 0.6626s	
11352/25300 (epoch 22.435), train_loss = 0.83718989, grad/param norm = 2.1071e-01, time/batch = 0.6589s	
11353/25300 (epoch 22.437), train_loss = 0.85376989, grad/param norm = 1.9444e-01, time/batch = 0.6575s	
11354/25300 (epoch 22.439), train_loss = 0.92630556, grad/param norm = 1.9227e-01, time/batch = 0.6593s	
11355/25300 (epoch 22.441), train_loss = 0.95275006, grad/param norm = 2.1331e-01, time/batch = 0.6594s	
11356/25300 (epoch 22.443), train_loss = 1.12721970, grad/param norm = 2.3408e-01, time/batch = 0.6591s	
11357/25300 (epoch 22.445), train_loss = 1.05635419, grad/param norm = 2.1860e-01, time/batch = 0.6587s	
11358/25300 (epoch 22.447), train_loss = 0.82657459, grad/param norm = 1.7478e-01, time/batch = 0.6638s	
11359/25300 (epoch 22.449), train_loss = 0.74909960, grad/param norm = 1.6733e-01, time/batch = 0.6593s	
11360/25300 (epoch 22.451), train_loss = 1.10628622, grad/param norm = 2.1789e-01, time/batch = 0.6596s	
11361/25300 (epoch 22.453), train_loss = 0.98317243, grad/param norm = 2.0860e-01, time/batch = 0.6635s	
11362/25300 (epoch 22.455), train_loss = 0.98136858, grad/param norm = 2.2281e-01, time/batch = 0.6598s	
11363/25300 (epoch 22.457), train_loss = 0.85491571, grad/param norm = 2.0231e-01, time/batch = 0.6597s	
11364/25300 (epoch 22.458), train_loss = 0.88970094, grad/param norm = 1.9722e-01, time/batch = 0.6605s	
11365/25300 (epoch 22.460), train_loss = 0.90518121, grad/param norm = 1.9770e-01, time/batch = 0.6610s	
11366/25300 (epoch 22.462), train_loss = 0.68028342, grad/param norm = 1.8340e-01, time/batch = 0.6625s	
11367/25300 (epoch 22.464), train_loss = 0.98945279, grad/param norm = 2.0333e-01, time/batch = 0.6626s	
11368/25300 (epoch 22.466), train_loss = 0.96545855, grad/param norm = 1.9549e-01, time/batch = 0.6591s	
11369/25300 (epoch 22.468), train_loss = 0.95823946, grad/param norm = 1.7959e-01, time/batch = 0.6550s	
11370/25300 (epoch 22.470), train_loss = 0.86047905, grad/param norm = 1.7537e-01, time/batch = 0.6587s	
11371/25300 (epoch 22.472), train_loss = 0.77570706, grad/param norm = 1.8089e-01, time/batch = 0.6598s	
11372/25300 (epoch 22.474), train_loss = 0.94774390, grad/param norm = 1.9730e-01, time/batch = 0.6599s	
11373/25300 (epoch 22.476), train_loss = 0.87740294, grad/param norm = 2.3013e-01, time/batch = 0.6606s	
11374/25300 (epoch 22.478), train_loss = 0.97696358, grad/param norm = 2.1805e-01, time/batch = 0.6605s	
11375/25300 (epoch 22.480), train_loss = 0.84812434, grad/param norm = 1.7431e-01, time/batch = 0.6600s	
11376/25300 (epoch 22.482), train_loss = 0.96117880, grad/param norm = 2.2218e-01, time/batch = 0.6625s	
11377/25300 (epoch 22.484), train_loss = 0.97517055, grad/param norm = 2.2304e-01, time/batch = 0.6564s	
11378/25300 (epoch 22.486), train_loss = 0.91906575, grad/param norm = 2.1710e-01, time/batch = 0.6599s	
11379/25300 (epoch 22.488), train_loss = 1.07923785, grad/param norm = 2.1360e-01, time/batch = 0.6676s	
11380/25300 (epoch 22.490), train_loss = 0.96232148, grad/param norm = 2.0101e-01, time/batch = 0.6669s	
11381/25300 (epoch 22.492), train_loss = 0.95030069, grad/param norm = 1.9484e-01, time/batch = 0.6698s	
11382/25300 (epoch 22.494), train_loss = 0.85424347, grad/param norm = 1.7411e-01, time/batch = 0.6610s	
11383/25300 (epoch 22.496), train_loss = 0.93294723, grad/param norm = 1.9262e-01, time/batch = 0.6559s	
11384/25300 (epoch 22.498), train_loss = 0.85030293, grad/param norm = 1.8722e-01, time/batch = 0.6667s	
11385/25300 (epoch 22.500), train_loss = 1.04428559, grad/param norm = 2.1171e-01, time/batch = 0.6672s	
11386/25300 (epoch 22.502), train_loss = 0.97930849, grad/param norm = 2.3336e-01, time/batch = 0.6660s	
11387/25300 (epoch 22.504), train_loss = 0.89674845, grad/param norm = 2.0089e-01, time/batch = 0.6583s	
11388/25300 (epoch 22.506), train_loss = 0.82591037, grad/param norm = 1.8500e-01, time/batch = 0.6538s	
11389/25300 (epoch 22.508), train_loss = 0.91554503, grad/param norm = 2.0329e-01, time/batch = 0.6581s	
11390/25300 (epoch 22.510), train_loss = 0.82615667, grad/param norm = 1.7303e-01, time/batch = 0.6569s	
11391/25300 (epoch 22.512), train_loss = 0.68198909, grad/param norm = 1.6055e-01, time/batch = 0.6589s	
11392/25300 (epoch 22.514), train_loss = 0.90316522, grad/param norm = 1.9684e-01, time/batch = 0.6582s	
11393/25300 (epoch 22.516), train_loss = 0.97434787, grad/param norm = 2.1954e-01, time/batch = 0.6584s	
11394/25300 (epoch 22.518), train_loss = 1.00806760, grad/param norm = 2.0519e-01, time/batch = 0.6580s	
11395/25300 (epoch 22.520), train_loss = 0.74370000, grad/param norm = 1.5098e-01, time/batch = 0.6559s	
11396/25300 (epoch 22.522), train_loss = 0.85076614, grad/param norm = 2.0006e-01, time/batch = 0.6576s	
11397/25300 (epoch 22.524), train_loss = 0.85090953, grad/param norm = 1.7891e-01, time/batch = 0.6576s	
11398/25300 (epoch 22.526), train_loss = 1.06725679, grad/param norm = 2.2440e-01, time/batch = 0.6585s	
11399/25300 (epoch 22.528), train_loss = 1.07005598, grad/param norm = 2.1059e-01, time/batch = 0.6592s	
11400/25300 (epoch 22.530), train_loss = 0.92303706, grad/param norm = 1.8994e-01, time/batch = 0.6615s	
11401/25300 (epoch 22.532), train_loss = 0.90273820, grad/param norm = 1.8828e-01, time/batch = 0.6618s	
11402/25300 (epoch 22.534), train_loss = 0.90040217, grad/param norm = 2.1008e-01, time/batch = 0.6675s	
11403/25300 (epoch 22.536), train_loss = 0.72372990, grad/param norm = 1.7379e-01, time/batch = 0.6619s	
11404/25300 (epoch 22.538), train_loss = 0.79362333, grad/param norm = 1.5989e-01, time/batch = 0.6601s	
11405/25300 (epoch 22.540), train_loss = 0.84827501, grad/param norm = 2.0010e-01, time/batch = 0.6606s	
11406/25300 (epoch 22.542), train_loss = 0.81127054, grad/param norm = 1.6294e-01, time/batch = 0.6620s	
11407/25300 (epoch 22.543), train_loss = 0.76554701, grad/param norm = 1.7101e-01, time/batch = 0.6634s	
11408/25300 (epoch 22.545), train_loss = 1.15826329, grad/param norm = 2.6141e-01, time/batch = 0.6588s	
11409/25300 (epoch 22.547), train_loss = 1.00792229, grad/param norm = 2.1648e-01, time/batch = 0.6580s	
11410/25300 (epoch 22.549), train_loss = 1.16379385, grad/param norm = 2.3602e-01, time/batch = 0.6597s	
11411/25300 (epoch 22.551), train_loss = 1.00058626, grad/param norm = 1.9772e-01, time/batch = 0.6689s	
11412/25300 (epoch 22.553), train_loss = 0.85077441, grad/param norm = 2.0034e-01, time/batch = 0.6756s	
11413/25300 (epoch 22.555), train_loss = 1.02433820, grad/param norm = 2.2633e-01, time/batch = 0.6828s	
11414/25300 (epoch 22.557), train_loss = 1.04452970, grad/param norm = 2.2509e-01, time/batch = 0.6587s	
11415/25300 (epoch 22.559), train_loss = 1.01573545, grad/param norm = 2.1685e-01, time/batch = 0.6594s	
11416/25300 (epoch 22.561), train_loss = 1.04896939, grad/param norm = 2.1635e-01, time/batch = 0.6575s	
11417/25300 (epoch 22.563), train_loss = 1.00845114, grad/param norm = 2.0931e-01, time/batch = 0.6576s	
11418/25300 (epoch 22.565), train_loss = 0.78853480, grad/param norm = 1.7826e-01, time/batch = 0.6643s	
11419/25300 (epoch 22.567), train_loss = 0.69936164, grad/param norm = 1.6654e-01, time/batch = 0.6613s	
11420/25300 (epoch 22.569), train_loss = 0.90186694, grad/param norm = 1.9198e-01, time/batch = 0.6665s	
11421/25300 (epoch 22.571), train_loss = 1.00667530, grad/param norm = 2.0554e-01, time/batch = 0.6695s	
11422/25300 (epoch 22.573), train_loss = 0.90400381, grad/param norm = 1.9084e-01, time/batch = 0.6643s	
11423/25300 (epoch 22.575), train_loss = 1.04070500, grad/param norm = 2.0313e-01, time/batch = 0.6663s	
11424/25300 (epoch 22.577), train_loss = 0.93352182, grad/param norm = 2.1259e-01, time/batch = 0.6644s	
11425/25300 (epoch 22.579), train_loss = 1.07308939, grad/param norm = 2.4081e-01, time/batch = 0.6632s	
11426/25300 (epoch 22.581), train_loss = 0.98959961, grad/param norm = 2.1473e-01, time/batch = 0.6620s	
11427/25300 (epoch 22.583), train_loss = 0.76840699, grad/param norm = 2.0140e-01, time/batch = 0.6618s	
11428/25300 (epoch 22.585), train_loss = 0.77714657, grad/param norm = 2.1039e-01, time/batch = 0.6621s	
11429/25300 (epoch 22.587), train_loss = 0.87746876, grad/param norm = 1.7035e-01, time/batch = 0.6594s	
11430/25300 (epoch 22.589), train_loss = 0.79695520, grad/param norm = 1.7184e-01, time/batch = 0.6645s	
11431/25300 (epoch 22.591), train_loss = 0.79774723, grad/param norm = 2.0558e-01, time/batch = 0.6710s	
11432/25300 (epoch 22.593), train_loss = 0.97952380, grad/param norm = 2.1482e-01, time/batch = 0.6702s	
11433/25300 (epoch 22.595), train_loss = 0.90182233, grad/param norm = 2.0272e-01, time/batch = 0.6649s	
11434/25300 (epoch 22.597), train_loss = 0.79614404, grad/param norm = 1.8128e-01, time/batch = 0.6603s	
11435/25300 (epoch 22.599), train_loss = 0.96288269, grad/param norm = 2.1503e-01, time/batch = 0.6602s	
11436/25300 (epoch 22.601), train_loss = 0.91302810, grad/param norm = 1.9853e-01, time/batch = 0.6609s	
11437/25300 (epoch 22.603), train_loss = 0.90666942, grad/param norm = 2.0962e-01, time/batch = 0.6613s	
11438/25300 (epoch 22.605), train_loss = 0.84560670, grad/param norm = 2.2316e-01, time/batch = 0.6605s	
11439/25300 (epoch 22.607), train_loss = 0.67524118, grad/param norm = 1.6223e-01, time/batch = 0.6616s	
11440/25300 (epoch 22.609), train_loss = 0.87756397, grad/param norm = 1.9280e-01, time/batch = 0.6630s	
11441/25300 (epoch 22.611), train_loss = 0.93664402, grad/param norm = 1.8841e-01, time/batch = 0.6598s	
11442/25300 (epoch 22.613), train_loss = 0.78596299, grad/param norm = 1.7955e-01, time/batch = 0.6616s	
11443/25300 (epoch 22.615), train_loss = 0.92436289, grad/param norm = 2.6238e-01, time/batch = 0.6597s	
11444/25300 (epoch 22.617), train_loss = 0.92794861, grad/param norm = 2.8989e-01, time/batch = 0.6621s	
11445/25300 (epoch 22.619), train_loss = 0.99793605, grad/param norm = 2.1880e-01, time/batch = 0.6595s	
11446/25300 (epoch 22.621), train_loss = 1.02723092, grad/param norm = 2.5239e-01, time/batch = 0.6577s	
11447/25300 (epoch 22.623), train_loss = 0.85606750, grad/param norm = 1.9827e-01, time/batch = 0.6605s	
11448/25300 (epoch 22.625), train_loss = 0.73619408, grad/param norm = 1.8575e-01, time/batch = 0.6596s	
11449/25300 (epoch 22.626), train_loss = 0.87907037, grad/param norm = 1.7873e-01, time/batch = 0.6578s	
11450/25300 (epoch 22.628), train_loss = 0.97809800, grad/param norm = 2.0337e-01, time/batch = 0.6641s	
11451/25300 (epoch 22.630), train_loss = 0.99298121, grad/param norm = 2.4256e-01, time/batch = 0.6625s	
11452/25300 (epoch 22.632), train_loss = 0.93294861, grad/param norm = 2.1358e-01, time/batch = 0.6644s	
11453/25300 (epoch 22.634), train_loss = 1.01984248, grad/param norm = 2.2399e-01, time/batch = 0.6643s	
11454/25300 (epoch 22.636), train_loss = 0.83579863, grad/param norm = 1.6844e-01, time/batch = 0.6611s	
11455/25300 (epoch 22.638), train_loss = 0.95709147, grad/param norm = 2.1800e-01, time/batch = 0.6615s	
11456/25300 (epoch 22.640), train_loss = 1.10394816, grad/param norm = 2.4321e-01, time/batch = 0.6548s	
11457/25300 (epoch 22.642), train_loss = 0.97272271, grad/param norm = 2.2755e-01, time/batch = 0.6559s	
11458/25300 (epoch 22.644), train_loss = 0.95109615, grad/param norm = 2.1751e-01, time/batch = 0.6552s	
11459/25300 (epoch 22.646), train_loss = 0.87401257, grad/param norm = 2.1972e-01, time/batch = 0.6541s	
11460/25300 (epoch 22.648), train_loss = 1.00515133, grad/param norm = 1.9454e-01, time/batch = 0.6573s	
11461/25300 (epoch 22.650), train_loss = 0.97519329, grad/param norm = 2.2874e-01, time/batch = 0.6605s	
11462/25300 (epoch 22.652), train_loss = 0.93612132, grad/param norm = 2.1825e-01, time/batch = 0.6552s	
11463/25300 (epoch 22.654), train_loss = 1.05858780, grad/param norm = 1.9471e-01, time/batch = 0.6599s	
11464/25300 (epoch 22.656), train_loss = 0.98094201, grad/param norm = 2.1057e-01, time/batch = 0.6595s	
11465/25300 (epoch 22.658), train_loss = 0.78331322, grad/param norm = 1.8262e-01, time/batch = 0.6606s	
11466/25300 (epoch 22.660), train_loss = 0.80954588, grad/param norm = 2.0215e-01, time/batch = 0.6589s	
11467/25300 (epoch 22.662), train_loss = 0.78754543, grad/param norm = 1.8743e-01, time/batch = 0.6581s	
11468/25300 (epoch 22.664), train_loss = 0.76562936, grad/param norm = 1.8330e-01, time/batch = 0.6575s	
11469/25300 (epoch 22.666), train_loss = 0.81324371, grad/param norm = 1.8844e-01, time/batch = 0.6587s	
11470/25300 (epoch 22.668), train_loss = 0.87927848, grad/param norm = 2.2113e-01, time/batch = 0.6572s	
11471/25300 (epoch 22.670), train_loss = 0.80531768, grad/param norm = 2.0160e-01, time/batch = 0.6573s	
11472/25300 (epoch 22.672), train_loss = 0.80454066, grad/param norm = 1.8690e-01, time/batch = 0.6579s	
11473/25300 (epoch 22.674), train_loss = 0.82801331, grad/param norm = 1.7715e-01, time/batch = 0.6637s	
11474/25300 (epoch 22.676), train_loss = 0.87241174, grad/param norm = 2.0584e-01, time/batch = 0.6551s	
11475/25300 (epoch 22.678), train_loss = 0.86715254, grad/param norm = 2.1117e-01, time/batch = 0.6544s	
11476/25300 (epoch 22.680), train_loss = 0.74417498, grad/param norm = 1.8302e-01, time/batch = 0.6544s	
11477/25300 (epoch 22.682), train_loss = 0.63285588, grad/param norm = 1.6414e-01, time/batch = 0.6574s	
11478/25300 (epoch 22.684), train_loss = 0.79955400, grad/param norm = 1.6418e-01, time/batch = 0.6553s	
11479/25300 (epoch 22.686), train_loss = 0.77029622, grad/param norm = 1.7472e-01, time/batch = 0.6585s	
11480/25300 (epoch 22.688), train_loss = 0.87651652, grad/param norm = 2.0292e-01, time/batch = 0.6620s	
11481/25300 (epoch 22.690), train_loss = 0.77252837, grad/param norm = 1.7207e-01, time/batch = 0.6595s	
11482/25300 (epoch 22.692), train_loss = 0.82230834, grad/param norm = 1.7801e-01, time/batch = 0.6578s	
11483/25300 (epoch 22.694), train_loss = 0.81345895, grad/param norm = 1.7814e-01, time/batch = 0.6569s	
11484/25300 (epoch 22.696), train_loss = 0.91803477, grad/param norm = 2.2035e-01, time/batch = 0.6549s	
11485/25300 (epoch 22.698), train_loss = 0.93842481, grad/param norm = 1.9134e-01, time/batch = 0.6603s	
11486/25300 (epoch 22.700), train_loss = 0.71003006, grad/param norm = 1.7476e-01, time/batch = 0.6636s	
11487/25300 (epoch 22.702), train_loss = 0.98266103, grad/param norm = 2.0097e-01, time/batch = 0.6639s	
11488/25300 (epoch 22.704), train_loss = 0.71804395, grad/param norm = 1.8545e-01, time/batch = 0.6620s	
11489/25300 (epoch 22.706), train_loss = 0.89197209, grad/param norm = 2.1192e-01, time/batch = 0.6624s	
11490/25300 (epoch 22.708), train_loss = 0.74560091, grad/param norm = 1.7205e-01, time/batch = 0.6593s	
11491/25300 (epoch 22.709), train_loss = 1.04490837, grad/param norm = 2.1214e-01, time/batch = 0.6633s	
11492/25300 (epoch 22.711), train_loss = 1.05753739, grad/param norm = 2.1360e-01, time/batch = 0.6626s	
11493/25300 (epoch 22.713), train_loss = 0.86170015, grad/param norm = 1.7605e-01, time/batch = 0.6646s	
11494/25300 (epoch 22.715), train_loss = 0.86292731, grad/param norm = 1.7263e-01, time/batch = 0.6597s	
11495/25300 (epoch 22.717), train_loss = 0.81085765, grad/param norm = 2.0752e-01, time/batch = 0.6615s	
11496/25300 (epoch 22.719), train_loss = 0.87230449, grad/param norm = 1.9439e-01, time/batch = 0.6609s	
11497/25300 (epoch 22.721), train_loss = 0.92941917, grad/param norm = 2.1010e-01, time/batch = 0.6616s	
11498/25300 (epoch 22.723), train_loss = 0.86203985, grad/param norm = 1.8889e-01, time/batch = 0.6601s	
11499/25300 (epoch 22.725), train_loss = 0.92398066, grad/param norm = 1.9946e-01, time/batch = 0.6610s	
11500/25300 (epoch 22.727), train_loss = 0.90153250, grad/param norm = 1.9054e-01, time/batch = 0.6613s	
11501/25300 (epoch 22.729), train_loss = 0.89069874, grad/param norm = 1.8171e-01, time/batch = 0.6695s	
11502/25300 (epoch 22.731), train_loss = 1.06080481, grad/param norm = 2.0536e-01, time/batch = 0.6695s	
11503/25300 (epoch 22.733), train_loss = 0.88770244, grad/param norm = 1.7717e-01, time/batch = 0.6833s	
11504/25300 (epoch 22.735), train_loss = 1.15445366, grad/param norm = 2.2042e-01, time/batch = 0.6673s	
11505/25300 (epoch 22.737), train_loss = 0.78878799, grad/param norm = 1.7661e-01, time/batch = 0.6606s	
11506/25300 (epoch 22.739), train_loss = 1.03980970, grad/param norm = 2.1470e-01, time/batch = 0.6591s	
11507/25300 (epoch 22.741), train_loss = 0.98235579, grad/param norm = 2.2354e-01, time/batch = 0.6591s	
11508/25300 (epoch 22.743), train_loss = 0.88186513, grad/param norm = 1.8445e-01, time/batch = 0.6606s	
11509/25300 (epoch 22.745), train_loss = 0.83768949, grad/param norm = 1.8175e-01, time/batch = 0.6613s	
11510/25300 (epoch 22.747), train_loss = 0.81827400, grad/param norm = 1.8658e-01, time/batch = 0.6639s	
11511/25300 (epoch 22.749), train_loss = 0.92444705, grad/param norm = 2.0415e-01, time/batch = 0.6639s	
11512/25300 (epoch 22.751), train_loss = 0.97886951, grad/param norm = 2.0935e-01, time/batch = 0.6609s	
11513/25300 (epoch 22.753), train_loss = 0.79255624, grad/param norm = 1.7984e-01, time/batch = 0.6632s	
11514/25300 (epoch 22.755), train_loss = 1.01589378, grad/param norm = 2.2645e-01, time/batch = 0.6663s	
11515/25300 (epoch 22.757), train_loss = 0.82450442, grad/param norm = 1.8380e-01, time/batch = 0.6589s	
11516/25300 (epoch 22.759), train_loss = 0.82497619, grad/param norm = 2.0019e-01, time/batch = 0.6561s	
11517/25300 (epoch 22.761), train_loss = 1.04143254, grad/param norm = 1.9541e-01, time/batch = 0.6725s	
11518/25300 (epoch 22.763), train_loss = 0.84048096, grad/param norm = 1.8393e-01, time/batch = 0.6592s	
11519/25300 (epoch 22.765), train_loss = 0.87211282, grad/param norm = 2.0699e-01, time/batch = 0.6570s	
11520/25300 (epoch 22.767), train_loss = 0.85413119, grad/param norm = 1.9341e-01, time/batch = 0.6584s	
11521/25300 (epoch 22.769), train_loss = 0.90251472, grad/param norm = 1.9529e-01, time/batch = 0.6583s	
11522/25300 (epoch 22.771), train_loss = 1.01534380, grad/param norm = 2.2512e-01, time/batch = 0.6595s	
11523/25300 (epoch 22.773), train_loss = 1.02503089, grad/param norm = 2.2515e-01, time/batch = 0.6636s	
11524/25300 (epoch 22.775), train_loss = 0.88177143, grad/param norm = 1.7455e-01, time/batch = 0.6600s	
11525/25300 (epoch 22.777), train_loss = 0.88829108, grad/param norm = 2.0136e-01, time/batch = 0.6609s	
11526/25300 (epoch 22.779), train_loss = 0.97920355, grad/param norm = 2.0166e-01, time/batch = 0.6617s	
11527/25300 (epoch 22.781), train_loss = 0.95182682, grad/param norm = 2.0228e-01, time/batch = 0.6580s	
11528/25300 (epoch 22.783), train_loss = 1.01609496, grad/param norm = 2.0384e-01, time/batch = 0.6595s	
11529/25300 (epoch 22.785), train_loss = 0.99063434, grad/param norm = 2.0288e-01, time/batch = 0.6608s	
11530/25300 (epoch 22.787), train_loss = 0.98528091, grad/param norm = 2.1182e-01, time/batch = 0.6639s	
11531/25300 (epoch 22.789), train_loss = 1.12714348, grad/param norm = 2.2864e-01, time/batch = 0.6694s	
11532/25300 (epoch 22.791), train_loss = 0.96690345, grad/param norm = 2.0069e-01, time/batch = 0.6666s	
11533/25300 (epoch 22.792), train_loss = 1.01959607, grad/param norm = 2.1459e-01, time/batch = 0.6672s	
11534/25300 (epoch 22.794), train_loss = 0.92016784, grad/param norm = 2.0892e-01, time/batch = 0.6676s	
11535/25300 (epoch 22.796), train_loss = 0.87014667, grad/param norm = 2.0548e-01, time/batch = 0.6676s	
11536/25300 (epoch 22.798), train_loss = 1.01551400, grad/param norm = 2.2747e-01, time/batch = 0.6664s	
11537/25300 (epoch 22.800), train_loss = 0.86947438, grad/param norm = 1.9006e-01, time/batch = 0.6642s	
11538/25300 (epoch 22.802), train_loss = 0.73649389, grad/param norm = 1.8970e-01, time/batch = 0.6659s	
11539/25300 (epoch 22.804), train_loss = 0.89939107, grad/param norm = 1.9210e-01, time/batch = 0.6643s	
11540/25300 (epoch 22.806), train_loss = 0.98491067, grad/param norm = 2.3467e-01, time/batch = 0.6700s	
11541/25300 (epoch 22.808), train_loss = 1.01647851, grad/param norm = 2.2061e-01, time/batch = 0.6743s	
11542/25300 (epoch 22.810), train_loss = 0.91059888, grad/param norm = 2.6879e-01, time/batch = 0.6694s	
11543/25300 (epoch 22.812), train_loss = 0.99547317, grad/param norm = 1.8947e-01, time/batch = 0.6657s	
11544/25300 (epoch 22.814), train_loss = 1.07850690, grad/param norm = 2.3458e-01, time/batch = 0.6601s	
11545/25300 (epoch 22.816), train_loss = 1.15425916, grad/param norm = 2.2061e-01, time/batch = 0.6604s	
11546/25300 (epoch 22.818), train_loss = 0.95719107, grad/param norm = 1.8959e-01, time/batch = 0.6667s	
11547/25300 (epoch 22.820), train_loss = 0.99888888, grad/param norm = 2.0970e-01, time/batch = 0.6601s	
11548/25300 (epoch 22.822), train_loss = 0.88240693, grad/param norm = 2.0700e-01, time/batch = 0.6609s	
11549/25300 (epoch 22.824), train_loss = 1.03376283, grad/param norm = 2.1731e-01, time/batch = 0.6586s	
11550/25300 (epoch 22.826), train_loss = 0.85205259, grad/param norm = 1.8100e-01, time/batch = 0.6588s	
11551/25300 (epoch 22.828), train_loss = 0.84537832, grad/param norm = 1.9740e-01, time/batch = 0.6604s	
11552/25300 (epoch 22.830), train_loss = 0.92279845, grad/param norm = 1.9698e-01, time/batch = 0.6661s	
11553/25300 (epoch 22.832), train_loss = 0.97769074, grad/param norm = 2.0122e-01, time/batch = 0.6612s	
11554/25300 (epoch 22.834), train_loss = 0.80714328, grad/param norm = 1.6885e-01, time/batch = 0.6594s	
11555/25300 (epoch 22.836), train_loss = 0.90437689, grad/param norm = 1.9232e-01, time/batch = 0.6595s	
11556/25300 (epoch 22.838), train_loss = 0.90118905, grad/param norm = 1.9677e-01, time/batch = 0.6590s	
11557/25300 (epoch 22.840), train_loss = 1.02024729, grad/param norm = 2.1256e-01, time/batch = 0.6602s	
11558/25300 (epoch 22.842), train_loss = 0.94067147, grad/param norm = 2.1874e-01, time/batch = 0.6588s	
11559/25300 (epoch 22.844), train_loss = 0.99637141, grad/param norm = 1.9430e-01, time/batch = 0.6586s	
11560/25300 (epoch 22.846), train_loss = 0.98967244, grad/param norm = 1.8702e-01, time/batch = 0.6594s	
11561/25300 (epoch 22.848), train_loss = 1.02725133, grad/param norm = 2.1503e-01, time/batch = 0.6621s	
11562/25300 (epoch 22.850), train_loss = 0.96640931, grad/param norm = 1.9936e-01, time/batch = 0.6638s	
11563/25300 (epoch 22.852), train_loss = 0.99387636, grad/param norm = 1.9882e-01, time/batch = 0.6605s	
11564/25300 (epoch 22.854), train_loss = 1.07331727, grad/param norm = 2.1444e-01, time/batch = 0.6618s	
11565/25300 (epoch 22.856), train_loss = 0.92344566, grad/param norm = 2.0301e-01, time/batch = 0.6593s	
11566/25300 (epoch 22.858), train_loss = 0.95437352, grad/param norm = 2.1168e-01, time/batch = 0.6586s	
11567/25300 (epoch 22.860), train_loss = 0.79834429, grad/param norm = 1.8222e-01, time/batch = 0.6577s	
11568/25300 (epoch 22.862), train_loss = 0.91706266, grad/param norm = 2.3418e-01, time/batch = 0.6573s	
11569/25300 (epoch 22.864), train_loss = 1.01878961, grad/param norm = 2.2676e-01, time/batch = 0.6578s	
11570/25300 (epoch 22.866), train_loss = 0.91712718, grad/param norm = 2.2007e-01, time/batch = 0.6607s	
11571/25300 (epoch 22.868), train_loss = 1.05355343, grad/param norm = 2.1045e-01, time/batch = 0.6589s	
11572/25300 (epoch 22.870), train_loss = 1.01535919, grad/param norm = 1.7339e-01, time/batch = 0.6594s	
11573/25300 (epoch 22.872), train_loss = 0.99160602, grad/param norm = 2.3135e-01, time/batch = 0.6622s	
11574/25300 (epoch 22.874), train_loss = 0.98558123, grad/param norm = 2.1276e-01, time/batch = 0.6581s	
11575/25300 (epoch 22.875), train_loss = 0.91967567, grad/param norm = 2.1042e-01, time/batch = 0.6546s	
11576/25300 (epoch 22.877), train_loss = 0.90515672, grad/param norm = 1.8404e-01, time/batch = 0.6579s	
11577/25300 (epoch 22.879), train_loss = 0.89078574, grad/param norm = 1.9787e-01, time/batch = 0.6582s	
11578/25300 (epoch 22.881), train_loss = 1.21166205, grad/param norm = 2.4465e-01, time/batch = 0.6582s	
11579/25300 (epoch 22.883), train_loss = 1.17622137, grad/param norm = 2.1521e-01, time/batch = 0.6580s	
11580/25300 (epoch 22.885), train_loss = 1.02382695, grad/param norm = 2.6414e-01, time/batch = 0.6569s	
11581/25300 (epoch 22.887), train_loss = 1.01468074, grad/param norm = 2.1183e-01, time/batch = 0.6561s	
11582/25300 (epoch 22.889), train_loss = 1.13325299, grad/param norm = 2.6964e-01, time/batch = 0.6595s	
11583/25300 (epoch 22.891), train_loss = 0.98785499, grad/param norm = 2.5297e-01, time/batch = 0.6549s	
11584/25300 (epoch 22.893), train_loss = 1.02930379, grad/param norm = 2.7869e-01, time/batch = 0.6603s	
11585/25300 (epoch 22.895), train_loss = 0.71992233, grad/param norm = 1.8010e-01, time/batch = 0.6581s	
11586/25300 (epoch 22.897), train_loss = 0.83940701, grad/param norm = 1.8245e-01, time/batch = 0.6559s	
11587/25300 (epoch 22.899), train_loss = 0.95887967, grad/param norm = 2.0283e-01, time/batch = 0.6543s	
11588/25300 (epoch 22.901), train_loss = 1.00625054, grad/param norm = 2.0645e-01, time/batch = 0.6571s	
11589/25300 (epoch 22.903), train_loss = 0.74845245, grad/param norm = 1.9813e-01, time/batch = 0.6563s	
11590/25300 (epoch 22.905), train_loss = 0.87904451, grad/param norm = 2.2250e-01, time/batch = 0.6606s	
11591/25300 (epoch 22.907), train_loss = 0.88734348, grad/param norm = 2.1561e-01, time/batch = 0.6673s	
11592/25300 (epoch 22.909), train_loss = 1.00510261, grad/param norm = 2.0058e-01, time/batch = 0.6659s	
11593/25300 (epoch 22.911), train_loss = 1.07561102, grad/param norm = 2.3471e-01, time/batch = 0.6751s	
11594/25300 (epoch 22.913), train_loss = 1.15241967, grad/param norm = 2.3383e-01, time/batch = 0.6679s	
11595/25300 (epoch 22.915), train_loss = 0.89409843, grad/param norm = 2.2299e-01, time/batch = 0.6693s	
11596/25300 (epoch 22.917), train_loss = 1.05907849, grad/param norm = 2.2287e-01, time/batch = 0.6593s	
11597/25300 (epoch 22.919), train_loss = 1.08366378, grad/param norm = 2.6360e-01, time/batch = 0.6576s	
11598/25300 (epoch 22.921), train_loss = 0.87217283, grad/param norm = 1.8988e-01, time/batch = 0.6712s	
11599/25300 (epoch 22.923), train_loss = 1.07580971, grad/param norm = 2.0393e-01, time/batch = 0.6636s	
11600/25300 (epoch 22.925), train_loss = 0.94759735, grad/param norm = 2.1533e-01, time/batch = 0.6592s	
11601/25300 (epoch 22.927), train_loss = 0.89601562, grad/param norm = 1.8328e-01, time/batch = 0.6662s	
11602/25300 (epoch 22.929), train_loss = 0.95981228, grad/param norm = 1.8882e-01, time/batch = 0.6614s	
11603/25300 (epoch 22.931), train_loss = 0.99857764, grad/param norm = 2.1893e-01, time/batch = 0.6600s	
11604/25300 (epoch 22.933), train_loss = 0.98675100, grad/param norm = 1.9830e-01, time/batch = 0.6605s	
11605/25300 (epoch 22.935), train_loss = 0.97508519, grad/param norm = 1.9292e-01, time/batch = 0.6617s	
11606/25300 (epoch 22.937), train_loss = 0.72373130, grad/param norm = 1.7165e-01, time/batch = 0.6591s	
11607/25300 (epoch 22.939), train_loss = 0.99171657, grad/param norm = 1.9111e-01, time/batch = 0.6608s	
11608/25300 (epoch 22.941), train_loss = 0.87170657, grad/param norm = 1.9384e-01, time/batch = 0.6675s	
11609/25300 (epoch 22.943), train_loss = 0.97391370, grad/param norm = 1.9292e-01, time/batch = 0.6623s	
11610/25300 (epoch 22.945), train_loss = 1.01263202, grad/param norm = 2.2966e-01, time/batch = 0.6619s	
11611/25300 (epoch 22.947), train_loss = 0.84338312, grad/param norm = 1.8673e-01, time/batch = 0.6695s	
11612/25300 (epoch 22.949), train_loss = 1.00689274, grad/param norm = 1.8955e-01, time/batch = 0.6602s	
11613/25300 (epoch 22.951), train_loss = 0.94851583, grad/param norm = 2.0169e-01, time/batch = 0.6645s	
11614/25300 (epoch 22.953), train_loss = 0.93369857, grad/param norm = 1.8994e-01, time/batch = 0.6638s	
11615/25300 (epoch 22.955), train_loss = 1.16409422, grad/param norm = 2.5626e-01, time/batch = 0.6640s	
11616/25300 (epoch 22.957), train_loss = 1.09010577, grad/param norm = 2.2192e-01, time/batch = 0.6609s	
11617/25300 (epoch 22.958), train_loss = 1.03238841, grad/param norm = 2.3226e-01, time/batch = 0.6610s	
11618/25300 (epoch 22.960), train_loss = 1.14027561, grad/param norm = 2.3579e-01, time/batch = 0.6582s	
11619/25300 (epoch 22.962), train_loss = 1.10598514, grad/param norm = 2.3320e-01, time/batch = 0.6595s	
11620/25300 (epoch 22.964), train_loss = 1.01486680, grad/param norm = 2.1485e-01, time/batch = 0.6622s	
11621/25300 (epoch 22.966), train_loss = 0.82282423, grad/param norm = 1.8007e-01, time/batch = 0.6613s	
11622/25300 (epoch 22.968), train_loss = 0.79219760, grad/param norm = 1.9599e-01, time/batch = 0.6580s	
11623/25300 (epoch 22.970), train_loss = 0.91949706, grad/param norm = 2.2844e-01, time/batch = 0.6634s	
11624/25300 (epoch 22.972), train_loss = 0.93646268, grad/param norm = 1.9026e-01, time/batch = 0.6590s	
11625/25300 (epoch 22.974), train_loss = 1.10616246, grad/param norm = 2.2802e-01, time/batch = 0.6596s	
11626/25300 (epoch 22.976), train_loss = 0.99900219, grad/param norm = 2.0474e-01, time/batch = 0.6606s	
11627/25300 (epoch 22.978), train_loss = 0.95231123, grad/param norm = 2.2404e-01, time/batch = 0.6620s	
11628/25300 (epoch 22.980), train_loss = 0.96756582, grad/param norm = 2.2096e-01, time/batch = 0.6593s	
11629/25300 (epoch 22.982), train_loss = 0.89998424, grad/param norm = 1.8555e-01, time/batch = 0.6558s	
11630/25300 (epoch 22.984), train_loss = 0.93151418, grad/param norm = 2.1442e-01, time/batch = 0.6595s	
11631/25300 (epoch 22.986), train_loss = 1.04770008, grad/param norm = 2.0793e-01, time/batch = 0.6608s	
11632/25300 (epoch 22.988), train_loss = 0.97692267, grad/param norm = 2.1701e-01, time/batch = 0.6576s	
11633/25300 (epoch 22.990), train_loss = 0.94329380, grad/param norm = 1.8623e-01, time/batch = 0.6744s	
11634/25300 (epoch 22.992), train_loss = 0.80830322, grad/param norm = 1.9000e-01, time/batch = 0.6630s	
11635/25300 (epoch 22.994), train_loss = 0.96182272, grad/param norm = 2.1002e-01, time/batch = 0.6693s	
11636/25300 (epoch 22.996), train_loss = 1.09841149, grad/param norm = 2.7412e-01, time/batch = 0.6806s	
11637/25300 (epoch 22.998), train_loss = 1.07910684, grad/param norm = 2.1150e-01, time/batch = 0.6707s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
11638/25300 (epoch 23.000), train_loss = 0.96602764, grad/param norm = 2.1424e-01, time/batch = 0.6822s	
11639/25300 (epoch 23.002), train_loss = 0.86718081, grad/param norm = 1.8703e-01, time/batch = 0.6723s	
11640/25300 (epoch 23.004), train_loss = 0.79000453, grad/param norm = 1.7308e-01, time/batch = 0.6709s	
11641/25300 (epoch 23.006), train_loss = 1.08543860, grad/param norm = 1.9415e-01, time/batch = 0.6785s	
11642/25300 (epoch 23.008), train_loss = 0.93041158, grad/param norm = 1.7050e-01, time/batch = 0.6810s	
11643/25300 (epoch 23.010), train_loss = 0.97752643, grad/param norm = 2.0008e-01, time/batch = 0.6822s	
11644/25300 (epoch 23.012), train_loss = 0.89245809, grad/param norm = 1.9400e-01, time/batch = 0.6827s	
11645/25300 (epoch 23.014), train_loss = 1.08366324, grad/param norm = 2.0598e-01, time/batch = 0.6889s	
11646/25300 (epoch 23.016), train_loss = 0.96684451, grad/param norm = 2.1983e-01, time/batch = 0.6832s	
11647/25300 (epoch 23.018), train_loss = 0.85422693, grad/param norm = 1.9178e-01, time/batch = 0.6606s	
11648/25300 (epoch 23.020), train_loss = 0.93632621, grad/param norm = 1.9698e-01, time/batch = 0.6600s	
11649/25300 (epoch 23.022), train_loss = 0.95778598, grad/param norm = 2.0472e-01, time/batch = 0.6595s	
11650/25300 (epoch 23.024), train_loss = 0.70984049, grad/param norm = 1.4586e-01, time/batch = 0.6572s	
11651/25300 (epoch 23.026), train_loss = 0.89455346, grad/param norm = 2.1787e-01, time/batch = 0.6616s	
11652/25300 (epoch 23.028), train_loss = 0.85150522, grad/param norm = 1.7732e-01, time/batch = 0.6614s	
11653/25300 (epoch 23.030), train_loss = 1.03577821, grad/param norm = 1.9802e-01, time/batch = 0.6599s	
11654/25300 (epoch 23.032), train_loss = 0.89344704, grad/param norm = 2.0535e-01, time/batch = 0.6603s	
11655/25300 (epoch 23.034), train_loss = 0.81917233, grad/param norm = 2.0469e-01, time/batch = 0.6591s	
11656/25300 (epoch 23.036), train_loss = 0.78622180, grad/param norm = 1.7466e-01, time/batch = 0.6623s	
11657/25300 (epoch 23.038), train_loss = 0.71313325, grad/param norm = 1.5064e-01, time/batch = 0.6630s	
11658/25300 (epoch 23.040), train_loss = 0.94475063, grad/param norm = 2.0463e-01, time/batch = 0.6587s	
11659/25300 (epoch 23.042), train_loss = 0.90907705, grad/param norm = 1.7903e-01, time/batch = 0.6629s	
11660/25300 (epoch 23.043), train_loss = 0.78140107, grad/param norm = 1.6915e-01, time/batch = 0.6647s	
11661/25300 (epoch 23.045), train_loss = 0.78809459, grad/param norm = 1.6030e-01, time/batch = 0.6641s	
11662/25300 (epoch 23.047), train_loss = 0.98390646, grad/param norm = 1.9316e-01, time/batch = 0.6622s	
11663/25300 (epoch 23.049), train_loss = 0.95447733, grad/param norm = 2.4290e-01, time/batch = 0.6640s	
11664/25300 (epoch 23.051), train_loss = 1.03836194, grad/param norm = 2.1914e-01, time/batch = 0.6587s	
11665/25300 (epoch 23.053), train_loss = 0.74421297, grad/param norm = 1.5921e-01, time/batch = 0.6564s	
11666/25300 (epoch 23.055), train_loss = 0.80749982, grad/param norm = 1.8142e-01, time/batch = 0.6615s	
11667/25300 (epoch 23.057), train_loss = 0.76204990, grad/param norm = 1.5538e-01, time/batch = 0.6560s	
11668/25300 (epoch 23.059), train_loss = 0.86714089, grad/param norm = 1.7965e-01, time/batch = 0.6601s	
11669/25300 (epoch 23.061), train_loss = 0.86068521, grad/param norm = 1.8718e-01, time/batch = 0.6589s	
11670/25300 (epoch 23.063), train_loss = 0.83903025, grad/param norm = 1.8015e-01, time/batch = 0.6612s	
11671/25300 (epoch 23.065), train_loss = 0.96985860, grad/param norm = 2.0804e-01, time/batch = 0.6603s	
11672/25300 (epoch 23.067), train_loss = 1.01817715, grad/param norm = 1.9869e-01, time/batch = 0.6614s	
11673/25300 (epoch 23.069), train_loss = 0.85898734, grad/param norm = 1.9389e-01, time/batch = 0.6608s	
11674/25300 (epoch 23.071), train_loss = 1.03200378, grad/param norm = 2.2699e-01, time/batch = 0.6637s	
11675/25300 (epoch 23.073), train_loss = 0.86289380, grad/param norm = 1.6359e-01, time/batch = 0.6684s	
11676/25300 (epoch 23.075), train_loss = 0.98887491, grad/param norm = 2.0470e-01, time/batch = 0.6667s	
11677/25300 (epoch 23.077), train_loss = 0.94699764, grad/param norm = 2.1192e-01, time/batch = 0.6671s	
11678/25300 (epoch 23.079), train_loss = 0.89164261, grad/param norm = 1.9700e-01, time/batch = 0.6685s	
11679/25300 (epoch 23.081), train_loss = 0.90444072, grad/param norm = 1.7549e-01, time/batch = 0.6685s	
11680/25300 (epoch 23.083), train_loss = 0.90374253, grad/param norm = 1.7386e-01, time/batch = 0.6692s	
11681/25300 (epoch 23.085), train_loss = 1.11709068, grad/param norm = 2.2703e-01, time/batch = 0.6695s	
11682/25300 (epoch 23.087), train_loss = 1.04188537, grad/param norm = 2.0879e-01, time/batch = 0.6675s	
11683/25300 (epoch 23.089), train_loss = 0.96683145, grad/param norm = 1.8574e-01, time/batch = 0.6638s	
11684/25300 (epoch 23.091), train_loss = 1.07494454, grad/param norm = 2.0526e-01, time/batch = 0.6628s	
11685/25300 (epoch 23.093), train_loss = 1.04434666, grad/param norm = 2.2526e-01, time/batch = 0.6578s	
11686/25300 (epoch 23.095), train_loss = 0.99834215, grad/param norm = 1.9042e-01, time/batch = 0.6590s	
11687/25300 (epoch 23.097), train_loss = 0.98394741, grad/param norm = 2.0249e-01, time/batch = 0.6632s	
11688/25300 (epoch 23.099), train_loss = 0.97925306, grad/param norm = 2.0690e-01, time/batch = 0.6575s	
11689/25300 (epoch 23.101), train_loss = 0.89650085, grad/param norm = 1.9617e-01, time/batch = 0.6521s	
11690/25300 (epoch 23.103), train_loss = 0.93673723, grad/param norm = 1.9006e-01, time/batch = 0.6709s	
11691/25300 (epoch 23.105), train_loss = 1.00646049, grad/param norm = 1.8922e-01, time/batch = 0.6817s	
11692/25300 (epoch 23.107), train_loss = 1.02125258, grad/param norm = 2.3303e-01, time/batch = 0.6726s	
11693/25300 (epoch 23.109), train_loss = 0.94196688, grad/param norm = 2.1325e-01, time/batch = 0.6647s	
11694/25300 (epoch 23.111), train_loss = 0.89582767, grad/param norm = 1.7865e-01, time/batch = 0.6566s	
11695/25300 (epoch 23.113), train_loss = 0.86779379, grad/param norm = 1.9228e-01, time/batch = 0.6665s	
11696/25300 (epoch 23.115), train_loss = 0.91693984, grad/param norm = 2.1543e-01, time/batch = 0.6580s	
11697/25300 (epoch 23.117), train_loss = 1.01203141, grad/param norm = 2.0855e-01, time/batch = 0.6574s	
11698/25300 (epoch 23.119), train_loss = 0.88759158, grad/param norm = 2.0106e-01, time/batch = 0.6586s	
11699/25300 (epoch 23.121), train_loss = 0.97611034, grad/param norm = 2.4833e-01, time/batch = 0.6596s	
11700/25300 (epoch 23.123), train_loss = 0.88122732, grad/param norm = 2.0089e-01, time/batch = 0.6568s	
11701/25300 (epoch 23.125), train_loss = 1.01356730, grad/param norm = 2.1197e-01, time/batch = 0.6609s	
11702/25300 (epoch 23.126), train_loss = 0.91643417, grad/param norm = 2.0317e-01, time/batch = 0.6564s	
11703/25300 (epoch 23.128), train_loss = 0.91560951, grad/param norm = 2.1838e-01, time/batch = 0.6620s	
11704/25300 (epoch 23.130), train_loss = 0.74785435, grad/param norm = 1.6197e-01, time/batch = 0.6561s	
11705/25300 (epoch 23.132), train_loss = 0.78843366, grad/param norm = 1.7771e-01, time/batch = 0.6613s	
11706/25300 (epoch 23.134), train_loss = 0.75496088, grad/param norm = 1.6908e-01, time/batch = 0.6559s	
11707/25300 (epoch 23.136), train_loss = 0.89923165, grad/param norm = 1.8035e-01, time/batch = 0.6578s	
11708/25300 (epoch 23.138), train_loss = 0.79437131, grad/param norm = 1.7888e-01, time/batch = 0.6579s	
11709/25300 (epoch 23.140), train_loss = 0.83659589, grad/param norm = 1.7581e-01, time/batch = 0.6603s	
11710/25300 (epoch 23.142), train_loss = 1.01756580, grad/param norm = 2.0091e-01, time/batch = 0.6609s	
11711/25300 (epoch 23.144), train_loss = 1.00636755, grad/param norm = 2.1117e-01, time/batch = 0.6621s	
11712/25300 (epoch 23.146), train_loss = 0.96732662, grad/param norm = 2.2176e-01, time/batch = 0.6586s	
11713/25300 (epoch 23.148), train_loss = 0.92987130, grad/param norm = 1.9612e-01, time/batch = 0.6610s	
11714/25300 (epoch 23.150), train_loss = 1.02461775, grad/param norm = 2.1482e-01, time/batch = 0.6602s	
11715/25300 (epoch 23.152), train_loss = 1.09169006, grad/param norm = 2.3005e-01, time/batch = 0.6569s	
11716/25300 (epoch 23.154), train_loss = 0.77660973, grad/param norm = 1.7311e-01, time/batch = 0.6612s	
11717/25300 (epoch 23.156), train_loss = 0.99305854, grad/param norm = 1.9753e-01, time/batch = 0.6602s	
11718/25300 (epoch 23.158), train_loss = 0.81721946, grad/param norm = 1.7671e-01, time/batch = 0.6633s	
11719/25300 (epoch 23.160), train_loss = 0.92253331, grad/param norm = 2.0099e-01, time/batch = 0.6597s	
11720/25300 (epoch 23.162), train_loss = 0.87878700, grad/param norm = 1.9716e-01, time/batch = 0.6620s	
11721/25300 (epoch 23.164), train_loss = 0.98680684, grad/param norm = 1.9650e-01, time/batch = 0.6671s	
11722/25300 (epoch 23.166), train_loss = 0.93249275, grad/param norm = 1.8684e-01, time/batch = 0.6635s	
11723/25300 (epoch 23.168), train_loss = 0.83048568, grad/param norm = 1.6733e-01, time/batch = 0.6639s	
11724/25300 (epoch 23.170), train_loss = 0.88585545, grad/param norm = 1.9751e-01, time/batch = 0.6621s	
11725/25300 (epoch 23.172), train_loss = 0.82243477, grad/param norm = 1.8745e-01, time/batch = 0.6645s	
11726/25300 (epoch 23.174), train_loss = 0.82089350, grad/param norm = 1.8262e-01, time/batch = 0.6634s	
11727/25300 (epoch 23.176), train_loss = 0.83197683, grad/param norm = 1.9778e-01, time/batch = 0.6610s	
11728/25300 (epoch 23.178), train_loss = 1.04426057, grad/param norm = 2.0901e-01, time/batch = 0.6629s	
11729/25300 (epoch 23.180), train_loss = 0.74415769, grad/param norm = 1.6425e-01, time/batch = 0.6605s	
11730/25300 (epoch 23.182), train_loss = 0.87441694, grad/param norm = 2.0478e-01, time/batch = 0.6634s	
11731/25300 (epoch 23.184), train_loss = 0.86845805, grad/param norm = 2.0205e-01, time/batch = 0.6634s	
11732/25300 (epoch 23.186), train_loss = 0.83075658, grad/param norm = 1.8952e-01, time/batch = 0.6563s	
11733/25300 (epoch 23.188), train_loss = 0.93829501, grad/param norm = 2.5785e-01, time/batch = 0.6610s	
11734/25300 (epoch 23.190), train_loss = 0.87215601, grad/param norm = 2.0113e-01, time/batch = 0.6603s	
11735/25300 (epoch 23.192), train_loss = 0.88318091, grad/param norm = 1.9240e-01, time/batch = 0.6593s	
11736/25300 (epoch 23.194), train_loss = 0.90072096, grad/param norm = 2.0077e-01, time/batch = 0.6611s	
11737/25300 (epoch 23.196), train_loss = 1.00585059, grad/param norm = 2.3614e-01, time/batch = 0.6618s	
11738/25300 (epoch 23.198), train_loss = 0.87129282, grad/param norm = 2.3711e-01, time/batch = 0.6573s	
11739/25300 (epoch 23.200), train_loss = 0.87649509, grad/param norm = 1.9561e-01, time/batch = 0.6557s	
11740/25300 (epoch 23.202), train_loss = 0.90460181, grad/param norm = 1.8092e-01, time/batch = 0.6582s	
11741/25300 (epoch 23.204), train_loss = 0.87452282, grad/param norm = 1.8688e-01, time/batch = 0.6595s	
11742/25300 (epoch 23.206), train_loss = 1.00255690, grad/param norm = 1.9259e-01, time/batch = 0.6575s	
11743/25300 (epoch 23.208), train_loss = 0.79121224, grad/param norm = 1.7772e-01, time/batch = 0.6588s	
11744/25300 (epoch 23.209), train_loss = 0.78215232, grad/param norm = 1.7812e-01, time/batch = 0.6598s	
11745/25300 (epoch 23.211), train_loss = 0.87053361, grad/param norm = 1.8939e-01, time/batch = 0.6584s	
11746/25300 (epoch 23.213), train_loss = 0.96243948, grad/param norm = 1.9716e-01, time/batch = 0.6622s	
11747/25300 (epoch 23.215), train_loss = 0.91181598, grad/param norm = 1.8683e-01, time/batch = 0.6603s	
11748/25300 (epoch 23.217), train_loss = 0.93255792, grad/param norm = 2.0405e-01, time/batch = 0.6606s	
11749/25300 (epoch 23.219), train_loss = 1.01110729, grad/param norm = 2.0651e-01, time/batch = 0.6577s	
11750/25300 (epoch 23.221), train_loss = 1.05989409, grad/param norm = 2.2627e-01, time/batch = 0.6589s	
11751/25300 (epoch 23.223), train_loss = 0.97518907, grad/param norm = 2.1792e-01, time/batch = 0.6611s	
11752/25300 (epoch 23.225), train_loss = 1.30497239, grad/param norm = 3.0619e-01, time/batch = 0.6622s	
11753/25300 (epoch 23.227), train_loss = 1.04982523, grad/param norm = 2.2099e-01, time/batch = 0.6597s	
11754/25300 (epoch 23.229), train_loss = 0.91223498, grad/param norm = 1.8345e-01, time/batch = 0.6577s	
11755/25300 (epoch 23.231), train_loss = 0.89720780, grad/param norm = 2.1138e-01, time/batch = 0.6602s	
11756/25300 (epoch 23.233), train_loss = 0.99661715, grad/param norm = 2.2583e-01, time/batch = 0.6601s	
11757/25300 (epoch 23.235), train_loss = 0.92102343, grad/param norm = 1.9633e-01, time/batch = 0.6589s	
11758/25300 (epoch 23.237), train_loss = 1.06046311, grad/param norm = 2.2909e-01, time/batch = 0.6581s	
11759/25300 (epoch 23.239), train_loss = 0.88986167, grad/param norm = 1.8544e-01, time/batch = 0.6594s	
11760/25300 (epoch 23.241), train_loss = 1.07107497, grad/param norm = 2.1279e-01, time/batch = 0.6598s	
11761/25300 (epoch 23.243), train_loss = 1.20554168, grad/param norm = 2.2809e-01, time/batch = 0.6808s	
11762/25300 (epoch 23.245), train_loss = 0.88200453, grad/param norm = 2.0208e-01, time/batch = 0.6630s	
11763/25300 (epoch 23.247), train_loss = 1.01087230, grad/param norm = 2.1041e-01, time/batch = 0.6587s	
11764/25300 (epoch 23.249), train_loss = 0.79394491, grad/param norm = 1.6820e-01, time/batch = 0.6573s	
11765/25300 (epoch 23.251), train_loss = 0.78982455, grad/param norm = 1.8591e-01, time/batch = 0.6627s	
11766/25300 (epoch 23.253), train_loss = 0.90861022, grad/param norm = 1.9072e-01, time/batch = 0.6598s	
11767/25300 (epoch 23.255), train_loss = 0.86632545, grad/param norm = 2.0766e-01, time/batch = 0.6607s	
11768/25300 (epoch 23.257), train_loss = 0.92345880, grad/param norm = 2.3077e-01, time/batch = 0.6679s	
11769/25300 (epoch 23.259), train_loss = 1.14703488, grad/param norm = 2.5609e-01, time/batch = 0.6708s	
11770/25300 (epoch 23.261), train_loss = 1.09684053, grad/param norm = 2.5057e-01, time/batch = 0.6697s	
11771/25300 (epoch 23.263), train_loss = 1.08693878, grad/param norm = 2.1854e-01, time/batch = 0.6709s	
11772/25300 (epoch 23.265), train_loss = 1.11620815, grad/param norm = 2.1701e-01, time/batch = 0.6673s	
11773/25300 (epoch 23.267), train_loss = 1.01863392, grad/param norm = 2.2720e-01, time/batch = 0.6640s	
11774/25300 (epoch 23.269), train_loss = 0.77737906, grad/param norm = 1.8087e-01, time/batch = 0.6664s	
11775/25300 (epoch 23.271), train_loss = 0.87180122, grad/param norm = 2.0875e-01, time/batch = 0.6620s	
11776/25300 (epoch 23.273), train_loss = 1.00541058, grad/param norm = 2.3821e-01, time/batch = 0.6855s	
11777/25300 (epoch 23.275), train_loss = 0.89641726, grad/param norm = 1.5820e-01, time/batch = 0.6699s	
11778/25300 (epoch 23.277), train_loss = 0.88076470, grad/param norm = 1.9883e-01, time/batch = 0.6685s	
11779/25300 (epoch 23.279), train_loss = 0.92259025, grad/param norm = 1.9676e-01, time/batch = 0.6642s	
11780/25300 (epoch 23.281), train_loss = 1.09501596, grad/param norm = 2.4882e-01, time/batch = 0.6617s	
11781/25300 (epoch 23.283), train_loss = 0.81551617, grad/param norm = 1.6917e-01, time/batch = 0.6602s	
11782/25300 (epoch 23.285), train_loss = 0.98032028, grad/param norm = 2.3210e-01, time/batch = 0.6606s	
11783/25300 (epoch 23.287), train_loss = 0.99096278, grad/param norm = 1.9988e-01, time/batch = 0.6589s	
11784/25300 (epoch 23.289), train_loss = 0.89057477, grad/param norm = 1.9306e-01, time/batch = 0.6632s	
11785/25300 (epoch 23.291), train_loss = 0.90793277, grad/param norm = 1.9785e-01, time/batch = 0.6665s	
11786/25300 (epoch 23.292), train_loss = 1.08848762, grad/param norm = 2.0864e-01, time/batch = 0.6677s	
11787/25300 (epoch 23.294), train_loss = 0.96710909, grad/param norm = 2.2541e-01, time/batch = 0.6629s	
11788/25300 (epoch 23.296), train_loss = 0.82976802, grad/param norm = 1.8198e-01, time/batch = 0.6577s	
11789/25300 (epoch 23.298), train_loss = 0.99979457, grad/param norm = 2.1067e-01, time/batch = 0.6581s	
11790/25300 (epoch 23.300), train_loss = 1.05052761, grad/param norm = 2.5861e-01, time/batch = 0.6574s	
11791/25300 (epoch 23.302), train_loss = 0.76150177, grad/param norm = 1.9745e-01, time/batch = 0.6628s	
11792/25300 (epoch 23.304), train_loss = 1.01460582, grad/param norm = 1.9584e-01, time/batch = 0.6631s	
11793/25300 (epoch 23.306), train_loss = 0.73871346, grad/param norm = 1.7837e-01, time/batch = 0.6659s	
11794/25300 (epoch 23.308), train_loss = 0.98744109, grad/param norm = 1.8384e-01, time/batch = 0.6671s	
11795/25300 (epoch 23.310), train_loss = 0.83090452, grad/param norm = 1.9277e-01, time/batch = 0.6653s	
11796/25300 (epoch 23.312), train_loss = 0.93922601, grad/param norm = 1.8291e-01, time/batch = 0.6605s	
11797/25300 (epoch 23.314), train_loss = 0.77070078, grad/param norm = 1.8109e-01, time/batch = 0.6636s	
11798/25300 (epoch 23.316), train_loss = 0.92600650, grad/param norm = 1.8632e-01, time/batch = 0.6602s	
11799/25300 (epoch 23.318), train_loss = 0.76328544, grad/param norm = 1.8729e-01, time/batch = 0.6622s	
11800/25300 (epoch 23.320), train_loss = 0.83233342, grad/param norm = 1.7721e-01, time/batch = 0.6607s	
11801/25300 (epoch 23.322), train_loss = 1.09371117, grad/param norm = 2.0853e-01, time/batch = 0.6703s	
11802/25300 (epoch 23.324), train_loss = 0.83122992, grad/param norm = 1.7984e-01, time/batch = 0.6604s	
11803/25300 (epoch 23.326), train_loss = 0.74593044, grad/param norm = 1.8264e-01, time/batch = 0.6608s	
11804/25300 (epoch 23.328), train_loss = 0.74818149, grad/param norm = 1.9669e-01, time/batch = 0.6595s	
11805/25300 (epoch 23.330), train_loss = 0.89241939, grad/param norm = 1.9508e-01, time/batch = 0.6583s	
11806/25300 (epoch 23.332), train_loss = 0.91986557, grad/param norm = 1.7917e-01, time/batch = 0.6540s	
11807/25300 (epoch 23.334), train_loss = 0.76464104, grad/param norm = 1.8722e-01, time/batch = 0.6596s	
11808/25300 (epoch 23.336), train_loss = 0.78053204, grad/param norm = 2.0034e-01, time/batch = 0.6643s	
11809/25300 (epoch 23.338), train_loss = 0.78781113, grad/param norm = 1.6940e-01, time/batch = 0.6645s	
11810/25300 (epoch 23.340), train_loss = 0.83242629, grad/param norm = 1.8374e-01, time/batch = 0.6611s	
11811/25300 (epoch 23.342), train_loss = 0.88331843, grad/param norm = 2.6312e-01, time/batch = 0.6586s	
11812/25300 (epoch 23.344), train_loss = 0.94175047, grad/param norm = 1.8644e-01, time/batch = 0.6603s	
11813/25300 (epoch 23.346), train_loss = 0.87374270, grad/param norm = 2.1511e-01, time/batch = 0.6562s	
11814/25300 (epoch 23.348), train_loss = 0.78132239, grad/param norm = 1.8736e-01, time/batch = 0.6589s	
11815/25300 (epoch 23.350), train_loss = 0.89288771, grad/param norm = 2.0957e-01, time/batch = 0.6624s	
11816/25300 (epoch 23.352), train_loss = 0.90668211, grad/param norm = 1.8073e-01, time/batch = 0.6625s	
11817/25300 (epoch 23.354), train_loss = 0.85577498, grad/param norm = 1.8741e-01, time/batch = 0.6636s	
11818/25300 (epoch 23.356), train_loss = 0.89380673, grad/param norm = 1.9291e-01, time/batch = 0.6651s	
11819/25300 (epoch 23.358), train_loss = 0.96482745, grad/param norm = 2.2350e-01, time/batch = 0.6672s	
11820/25300 (epoch 23.360), train_loss = 0.81345716, grad/param norm = 1.7467e-01, time/batch = 0.6655s	
11821/25300 (epoch 23.362), train_loss = 0.83307116, grad/param norm = 1.9607e-01, time/batch = 0.6782s	
11822/25300 (epoch 23.364), train_loss = 0.86514573, grad/param norm = 2.1800e-01, time/batch = 0.6645s	
11823/25300 (epoch 23.366), train_loss = 0.77170632, grad/param norm = 1.8164e-01, time/batch = 0.6603s	
11824/25300 (epoch 23.368), train_loss = 0.87379464, grad/param norm = 1.7919e-01, time/batch = 0.6647s	
11825/25300 (epoch 23.370), train_loss = 0.84034154, grad/param norm = 1.9843e-01, time/batch = 0.6598s	
11826/25300 (epoch 23.372), train_loss = 0.83320720, grad/param norm = 1.8597e-01, time/batch = 0.6790s	
11827/25300 (epoch 23.374), train_loss = 0.76286253, grad/param norm = 1.8420e-01, time/batch = 0.6708s	
11828/25300 (epoch 23.375), train_loss = 1.01916841, grad/param norm = 2.1938e-01, time/batch = 0.6694s	
11829/25300 (epoch 23.377), train_loss = 0.97146949, grad/param norm = 2.0785e-01, time/batch = 0.6651s	
11830/25300 (epoch 23.379), train_loss = 0.94426709, grad/param norm = 2.1790e-01, time/batch = 0.6624s	
11831/25300 (epoch 23.381), train_loss = 0.89289710, grad/param norm = 2.3104e-01, time/batch = 0.6768s	
11832/25300 (epoch 23.383), train_loss = 0.81384460, grad/param norm = 1.8411e-01, time/batch = 0.6644s	
11833/25300 (epoch 23.385), train_loss = 0.90063076, grad/param norm = 1.9906e-01, time/batch = 0.6636s	
11834/25300 (epoch 23.387), train_loss = 0.94124090, grad/param norm = 2.0756e-01, time/batch = 0.6538s	
11835/25300 (epoch 23.389), train_loss = 0.93795009, grad/param norm = 2.1071e-01, time/batch = 0.6561s	
11836/25300 (epoch 23.391), train_loss = 0.84429711, grad/param norm = 1.8113e-01, time/batch = 0.6618s	
11837/25300 (epoch 23.393), train_loss = 0.92505880, grad/param norm = 2.4264e-01, time/batch = 0.6576s	
11838/25300 (epoch 23.395), train_loss = 0.74517867, grad/param norm = 1.6968e-01, time/batch = 0.6616s	
11839/25300 (epoch 23.397), train_loss = 0.77908599, grad/param norm = 2.4228e-01, time/batch = 0.6610s	
11840/25300 (epoch 23.399), train_loss = 0.76728770, grad/param norm = 2.0994e-01, time/batch = 0.6621s	
11841/25300 (epoch 23.401), train_loss = 0.98466576, grad/param norm = 2.3197e-01, time/batch = 0.6649s	
11842/25300 (epoch 23.403), train_loss = 0.92426244, grad/param norm = 2.3439e-01, time/batch = 0.6638s	
11843/25300 (epoch 23.405), train_loss = 0.89522422, grad/param norm = 1.9382e-01, time/batch = 0.6634s	
11844/25300 (epoch 23.407), train_loss = 0.88213676, grad/param norm = 1.9767e-01, time/batch = 0.6625s	
11845/25300 (epoch 23.409), train_loss = 0.82829243, grad/param norm = 1.7199e-01, time/batch = 0.6635s	
11846/25300 (epoch 23.411), train_loss = 0.83094148, grad/param norm = 1.9552e-01, time/batch = 0.6661s	
11847/25300 (epoch 23.413), train_loss = 0.75088521, grad/param norm = 1.8591e-01, time/batch = 0.6623s	
11848/25300 (epoch 23.415), train_loss = 0.79306679, grad/param norm = 1.8443e-01, time/batch = 0.6642s	
11849/25300 (epoch 23.417), train_loss = 0.74664759, grad/param norm = 1.6724e-01, time/batch = 0.6547s	
11850/25300 (epoch 23.419), train_loss = 0.69211932, grad/param norm = 1.7095e-01, time/batch = 0.6583s	
11851/25300 (epoch 23.421), train_loss = 0.76766020, grad/param norm = 1.5179e-01, time/batch = 0.6677s	
11852/25300 (epoch 23.423), train_loss = 0.75994844, grad/param norm = 1.7499e-01, time/batch = 0.6615s	
11853/25300 (epoch 23.425), train_loss = 0.85707559, grad/param norm = 2.2865e-01, time/batch = 0.6640s	
11854/25300 (epoch 23.427), train_loss = 1.02343287, grad/param norm = 2.1505e-01, time/batch = 0.6647s	
11855/25300 (epoch 23.429), train_loss = 0.96927860, grad/param norm = 2.1433e-01, time/batch = 0.6607s	
11856/25300 (epoch 23.431), train_loss = 0.93262236, grad/param norm = 1.9556e-01, time/batch = 0.6540s	
11857/25300 (epoch 23.433), train_loss = 0.89922160, grad/param norm = 2.1091e-01, time/batch = 0.6584s	
11858/25300 (epoch 23.435), train_loss = 0.83652259, grad/param norm = 2.0871e-01, time/batch = 0.6617s	
11859/25300 (epoch 23.437), train_loss = 0.83307787, grad/param norm = 2.0851e-01, time/batch = 0.6569s	
11860/25300 (epoch 23.439), train_loss = 0.91564683, grad/param norm = 2.0073e-01, time/batch = 0.6613s	
11861/25300 (epoch 23.441), train_loss = 0.94279171, grad/param norm = 2.1395e-01, time/batch = 0.6632s	
11862/25300 (epoch 23.443), train_loss = 1.10727686, grad/param norm = 2.3800e-01, time/batch = 0.6671s	
11863/25300 (epoch 23.445), train_loss = 1.03996144, grad/param norm = 2.2192e-01, time/batch = 0.6651s	
11864/25300 (epoch 23.447), train_loss = 0.81966806, grad/param norm = 1.7353e-01, time/batch = 0.6660s	
11865/25300 (epoch 23.449), train_loss = 0.74162496, grad/param norm = 1.8338e-01, time/batch = 0.6629s	
11866/25300 (epoch 23.451), train_loss = 1.10460559, grad/param norm = 2.2491e-01, time/batch = 0.6582s	
11867/25300 (epoch 23.453), train_loss = 0.96935387, grad/param norm = 2.2106e-01, time/batch = 0.6604s	
11868/25300 (epoch 23.455), train_loss = 0.96942453, grad/param norm = 2.2538e-01, time/batch = 0.6593s	
11869/25300 (epoch 23.457), train_loss = 0.83893069, grad/param norm = 1.8589e-01, time/batch = 0.6602s	
11870/25300 (epoch 23.458), train_loss = 0.85869747, grad/param norm = 1.9484e-01, time/batch = 0.6592s	
11871/25300 (epoch 23.460), train_loss = 0.88569078, grad/param norm = 1.9389e-01, time/batch = 0.6602s	
11872/25300 (epoch 23.462), train_loss = 0.66366277, grad/param norm = 1.8630e-01, time/batch = 0.6639s	
11873/25300 (epoch 23.464), train_loss = 0.96346163, grad/param norm = 2.2169e-01, time/batch = 0.6574s	
11874/25300 (epoch 23.466), train_loss = 0.95701781, grad/param norm = 2.1111e-01, time/batch = 0.6598s	
11875/25300 (epoch 23.468), train_loss = 0.93942098, grad/param norm = 1.8804e-01, time/batch = 0.6591s	
11876/25300 (epoch 23.470), train_loss = 0.85385732, grad/param norm = 1.8578e-01, time/batch = 0.6588s	
11877/25300 (epoch 23.472), train_loss = 0.76314611, grad/param norm = 1.9178e-01, time/batch = 0.6613s	
11878/25300 (epoch 23.474), train_loss = 0.92907409, grad/param norm = 1.8656e-01, time/batch = 0.6586s	
11879/25300 (epoch 23.476), train_loss = 0.85215442, grad/param norm = 1.9572e-01, time/batch = 0.6635s	
11880/25300 (epoch 23.478), train_loss = 0.95729197, grad/param norm = 2.2775e-01, time/batch = 0.6588s	
11881/25300 (epoch 23.480), train_loss = 0.85216568, grad/param norm = 1.9064e-01, time/batch = 0.6657s	
11882/25300 (epoch 23.482), train_loss = 0.94339705, grad/param norm = 2.2205e-01, time/batch = 0.6618s	
11883/25300 (epoch 23.484), train_loss = 0.95546599, grad/param norm = 2.6072e-01, time/batch = 0.6585s	
11884/25300 (epoch 23.486), train_loss = 0.89635167, grad/param norm = 2.0159e-01, time/batch = 0.6601s	
11885/25300 (epoch 23.488), train_loss = 1.05992923, grad/param norm = 2.0681e-01, time/batch = 0.6557s	
11886/25300 (epoch 23.490), train_loss = 0.96200899, grad/param norm = 2.1161e-01, time/batch = 0.6553s	
11887/25300 (epoch 23.492), train_loss = 0.94912342, grad/param norm = 1.9454e-01, time/batch = 0.6611s	
11888/25300 (epoch 23.494), train_loss = 0.84217277, grad/param norm = 1.8525e-01, time/batch = 0.6593s	
11889/25300 (epoch 23.496), train_loss = 0.90245561, grad/param norm = 1.8789e-01, time/batch = 0.6602s	
11890/25300 (epoch 23.498), train_loss = 0.82814287, grad/param norm = 1.7834e-01, time/batch = 0.6597s	
11891/25300 (epoch 23.500), train_loss = 1.03283017, grad/param norm = 2.2442e-01, time/batch = 0.6583s	
11892/25300 (epoch 23.502), train_loss = 0.95709416, grad/param norm = 2.1586e-01, time/batch = 0.6625s	
11893/25300 (epoch 23.504), train_loss = 0.87279786, grad/param norm = 2.0363e-01, time/batch = 0.6571s	
11894/25300 (epoch 23.506), train_loss = 0.80383788, grad/param norm = 1.8743e-01, time/batch = 0.6592s	
11895/25300 (epoch 23.508), train_loss = 0.89408162, grad/param norm = 2.1118e-01, time/batch = 0.6760s	
11896/25300 (epoch 23.510), train_loss = 0.83100558, grad/param norm = 2.6123e-01, time/batch = 0.6589s	
11897/25300 (epoch 23.512), train_loss = 0.66828136, grad/param norm = 1.6580e-01, time/batch = 0.6601s	
11898/25300 (epoch 23.514), train_loss = 0.87230966, grad/param norm = 1.8495e-01, time/batch = 0.6593s	
11899/25300 (epoch 23.516), train_loss = 0.96018210, grad/param norm = 2.1562e-01, time/batch = 0.6541s	
11900/25300 (epoch 23.518), train_loss = 1.00642615, grad/param norm = 2.3941e-01, time/batch = 0.6569s	
11901/25300 (epoch 23.520), train_loss = 0.74169417, grad/param norm = 1.5696e-01, time/batch = 0.6630s	
11902/25300 (epoch 23.522), train_loss = 0.83785964, grad/param norm = 2.1075e-01, time/batch = 0.6611s	
11903/25300 (epoch 23.524), train_loss = 0.83160405, grad/param norm = 1.9262e-01, time/batch = 0.6625s	
11904/25300 (epoch 23.526), train_loss = 1.04708116, grad/param norm = 2.2370e-01, time/batch = 0.6574s	
11905/25300 (epoch 23.528), train_loss = 1.05637466, grad/param norm = 2.2096e-01, time/batch = 0.6548s	
11906/25300 (epoch 23.530), train_loss = 0.91400106, grad/param norm = 2.4465e-01, time/batch = 0.6582s	
11907/25300 (epoch 23.532), train_loss = 0.87927090, grad/param norm = 2.1309e-01, time/batch = 0.6533s	
11908/25300 (epoch 23.534), train_loss = 0.89710113, grad/param norm = 2.3150e-01, time/batch = 0.6596s	
11909/25300 (epoch 23.536), train_loss = 0.70265987, grad/param norm = 1.7688e-01, time/batch = 0.6607s	
11910/25300 (epoch 23.538), train_loss = 0.77845304, grad/param norm = 1.7439e-01, time/batch = 0.6600s	
11911/25300 (epoch 23.540), train_loss = 0.83449280, grad/param norm = 2.0770e-01, time/batch = 0.6669s	
11912/25300 (epoch 23.542), train_loss = 0.80596491, grad/param norm = 1.7902e-01, time/batch = 0.6649s	
11913/25300 (epoch 23.543), train_loss = 0.75168927, grad/param norm = 1.7626e-01, time/batch = 0.6638s	
11914/25300 (epoch 23.545), train_loss = 1.12942957, grad/param norm = 2.5783e-01, time/batch = 0.6611s	
11915/25300 (epoch 23.547), train_loss = 0.97635041, grad/param norm = 2.2559e-01, time/batch = 0.6654s	
11916/25300 (epoch 23.549), train_loss = 1.16023665, grad/param norm = 2.8399e-01, time/batch = 0.6637s	
11917/25300 (epoch 23.551), train_loss = 0.97409474, grad/param norm = 1.9931e-01, time/batch = 0.6750s	
11918/25300 (epoch 23.553), train_loss = 0.82373514, grad/param norm = 1.8595e-01, time/batch = 0.6684s	
11919/25300 (epoch 23.555), train_loss = 0.99599464, grad/param norm = 2.1247e-01, time/batch = 0.6688s	
11920/25300 (epoch 23.557), train_loss = 1.02005964, grad/param norm = 2.1058e-01, time/batch = 0.6680s	
11921/25300 (epoch 23.559), train_loss = 1.00117739, grad/param norm = 2.1149e-01, time/batch = 0.6652s	
11922/25300 (epoch 23.561), train_loss = 1.02758819, grad/param norm = 2.1310e-01, time/batch = 0.6645s	
11923/25300 (epoch 23.563), train_loss = 0.99552461, grad/param norm = 2.2699e-01, time/batch = 0.6627s	
11924/25300 (epoch 23.565), train_loss = 0.78091847, grad/param norm = 1.8317e-01, time/batch = 0.6627s	
11925/25300 (epoch 23.567), train_loss = 0.69045526, grad/param norm = 1.6414e-01, time/batch = 0.6610s	
11926/25300 (epoch 23.569), train_loss = 0.89965153, grad/param norm = 2.0410e-01, time/batch = 0.6575s	
11927/25300 (epoch 23.571), train_loss = 0.99529068, grad/param norm = 2.0315e-01, time/batch = 0.6631s	
11928/25300 (epoch 23.573), train_loss = 0.89785183, grad/param norm = 1.9711e-01, time/batch = 0.6613s	
11929/25300 (epoch 23.575), train_loss = 1.02107333, grad/param norm = 1.9922e-01, time/batch = 0.6649s	
11930/25300 (epoch 23.577), train_loss = 0.92844903, grad/param norm = 2.4148e-01, time/batch = 0.6714s	
11931/25300 (epoch 23.579), train_loss = 1.03886716, grad/param norm = 2.2803e-01, time/batch = 0.6805s	
11932/25300 (epoch 23.581), train_loss = 0.96836357, grad/param norm = 2.1121e-01, time/batch = 0.6715s	
11933/25300 (epoch 23.583), train_loss = 0.76009557, grad/param norm = 2.1864e-01, time/batch = 0.6728s	
11934/25300 (epoch 23.585), train_loss = 0.77076080, grad/param norm = 2.0549e-01, time/batch = 0.6718s	
11935/25300 (epoch 23.587), train_loss = 0.87373863, grad/param norm = 1.8672e-01, time/batch = 0.6657s	
11936/25300 (epoch 23.589), train_loss = 0.77763984, grad/param norm = 1.7278e-01, time/batch = 0.6617s	
11937/25300 (epoch 23.591), train_loss = 0.79142291, grad/param norm = 2.0938e-01, time/batch = 0.6739s	
11938/25300 (epoch 23.593), train_loss = 0.95385655, grad/param norm = 1.9033e-01, time/batch = 0.6717s	
11939/25300 (epoch 23.595), train_loss = 0.88799794, grad/param norm = 2.0446e-01, time/batch = 0.6705s	
11940/25300 (epoch 23.597), train_loss = 0.78000792, grad/param norm = 1.8255e-01, time/batch = 0.6608s	
11941/25300 (epoch 23.599), train_loss = 0.94175866, grad/param norm = 2.0461e-01, time/batch = 0.6628s	
11942/25300 (epoch 23.601), train_loss = 0.88408506, grad/param norm = 2.0121e-01, time/batch = 0.6627s	
11943/25300 (epoch 23.603), train_loss = 0.88505151, grad/param norm = 2.0299e-01, time/batch = 0.6600s	
11944/25300 (epoch 23.605), train_loss = 0.83303624, grad/param norm = 2.2642e-01, time/batch = 0.6637s	
11945/25300 (epoch 23.607), train_loss = 0.66025924, grad/param norm = 1.6992e-01, time/batch = 0.6612s	
11946/25300 (epoch 23.609), train_loss = 0.86803757, grad/param norm = 1.9623e-01, time/batch = 0.6639s	
11947/25300 (epoch 23.611), train_loss = 0.92535813, grad/param norm = 2.0854e-01, time/batch = 0.6589s	
11948/25300 (epoch 23.613), train_loss = 0.76534576, grad/param norm = 1.6576e-01, time/batch = 0.6589s	
11949/25300 (epoch 23.615), train_loss = 0.88511268, grad/param norm = 2.2056e-01, time/batch = 0.6646s	
11950/25300 (epoch 23.617), train_loss = 0.90385918, grad/param norm = 2.1905e-01, time/batch = 0.6584s	
11951/25300 (epoch 23.619), train_loss = 0.97901247, grad/param norm = 2.0682e-01, time/batch = 0.6652s	
11952/25300 (epoch 23.621), train_loss = 1.00235107, grad/param norm = 2.4021e-01, time/batch = 0.6691s	
11953/25300 (epoch 23.623), train_loss = 0.82471059, grad/param norm = 1.9558e-01, time/batch = 0.6753s	
11954/25300 (epoch 23.625), train_loss = 0.72937549, grad/param norm = 1.8371e-01, time/batch = 0.6744s	
11955/25300 (epoch 23.626), train_loss = 0.87334143, grad/param norm = 1.8330e-01, time/batch = 0.6669s	
11956/25300 (epoch 23.628), train_loss = 0.96590055, grad/param norm = 2.3366e-01, time/batch = 0.6679s	
11957/25300 (epoch 23.630), train_loss = 0.96569066, grad/param norm = 2.4228e-01, time/batch = 0.6678s	
11958/25300 (epoch 23.632), train_loss = 0.90910926, grad/param norm = 2.1077e-01, time/batch = 0.6682s	
11959/25300 (epoch 23.634), train_loss = 1.01142310, grad/param norm = 2.4723e-01, time/batch = 0.6629s	
11960/25300 (epoch 23.636), train_loss = 0.81617805, grad/param norm = 1.8874e-01, time/batch = 0.6694s	
11961/25300 (epoch 23.638), train_loss = 0.95158797, grad/param norm = 2.4328e-01, time/batch = 0.6657s	
11962/25300 (epoch 23.640), train_loss = 1.07024885, grad/param norm = 2.5126e-01, time/batch = 0.6575s	
11963/25300 (epoch 23.642), train_loss = 0.94168440, grad/param norm = 2.1278e-01, time/batch = 0.6605s	
11964/25300 (epoch 23.644), train_loss = 0.92999784, grad/param norm = 2.0594e-01, time/batch = 0.6534s	
11965/25300 (epoch 23.646), train_loss = 0.85067947, grad/param norm = 2.6577e-01, time/batch = 0.6674s	
11966/25300 (epoch 23.648), train_loss = 0.98564400, grad/param norm = 1.9991e-01, time/batch = 0.6682s	
11967/25300 (epoch 23.650), train_loss = 0.94946791, grad/param norm = 2.3201e-01, time/batch = 0.6571s	
11968/25300 (epoch 23.652), train_loss = 0.94269073, grad/param norm = 2.6395e-01, time/batch = 0.6610s	
11969/25300 (epoch 23.654), train_loss = 1.02878090, grad/param norm = 1.9425e-01, time/batch = 0.6581s	
11970/25300 (epoch 23.656), train_loss = 0.97300384, grad/param norm = 2.2188e-01, time/batch = 0.6605s	
11971/25300 (epoch 23.658), train_loss = 0.75377242, grad/param norm = 1.7249e-01, time/batch = 0.6581s	
11972/25300 (epoch 23.660), train_loss = 0.79219848, grad/param norm = 1.9623e-01, time/batch = 0.6645s	
11973/25300 (epoch 23.662), train_loss = 0.76845439, grad/param norm = 1.7923e-01, time/batch = 0.6590s	
11974/25300 (epoch 23.664), train_loss = 0.75261954, grad/param norm = 1.8688e-01, time/batch = 0.6610s	
11975/25300 (epoch 23.666), train_loss = 0.81822188, grad/param norm = 2.0483e-01, time/batch = 0.6611s	
11976/25300 (epoch 23.668), train_loss = 0.87262894, grad/param norm = 2.3468e-01, time/batch = 0.6590s	
11977/25300 (epoch 23.670), train_loss = 0.79974246, grad/param norm = 2.0956e-01, time/batch = 0.6621s	
11978/25300 (epoch 23.672), train_loss = 0.78049038, grad/param norm = 1.8963e-01, time/batch = 0.6694s	
11979/25300 (epoch 23.674), train_loss = 0.80938827, grad/param norm = 1.8106e-01, time/batch = 0.6696s	
11980/25300 (epoch 23.676), train_loss = 0.85358791, grad/param norm = 2.1573e-01, time/batch = 0.6602s	
11981/25300 (epoch 23.678), train_loss = 0.83217745, grad/param norm = 1.9904e-01, time/batch = 0.6634s	
11982/25300 (epoch 23.680), train_loss = 0.72145282, grad/param norm = 1.7321e-01, time/batch = 0.6743s	
11983/25300 (epoch 23.682), train_loss = 0.62619848, grad/param norm = 1.7316e-01, time/batch = 0.6609s	
11984/25300 (epoch 23.684), train_loss = 0.78627006, grad/param norm = 1.7365e-01, time/batch = 0.6644s	
11985/25300 (epoch 23.686), train_loss = 0.74015645, grad/param norm = 1.6279e-01, time/batch = 0.6596s	
11986/25300 (epoch 23.688), train_loss = 0.86804309, grad/param norm = 2.1450e-01, time/batch = 0.6592s	
11987/25300 (epoch 23.690), train_loss = 0.75467753, grad/param norm = 1.7271e-01, time/batch = 0.6676s	
11988/25300 (epoch 23.692), train_loss = 0.80288924, grad/param norm = 1.8193e-01, time/batch = 0.6612s	
11989/25300 (epoch 23.694), train_loss = 0.81024039, grad/param norm = 1.8598e-01, time/batch = 0.6602s	
11990/25300 (epoch 23.696), train_loss = 0.92952657, grad/param norm = 2.3511e-01, time/batch = 0.6591s	
11991/25300 (epoch 23.698), train_loss = 0.92384336, grad/param norm = 2.0263e-01, time/batch = 0.6630s	
11992/25300 (epoch 23.700), train_loss = 0.70130710, grad/param norm = 1.8014e-01, time/batch = 0.6553s	
11993/25300 (epoch 23.702), train_loss = 0.96469820, grad/param norm = 2.4026e-01, time/batch = 0.6575s	
11994/25300 (epoch 23.704), train_loss = 0.70181474, grad/param norm = 1.8512e-01, time/batch = 0.6568s	
11995/25300 (epoch 23.706), train_loss = 0.86675357, grad/param norm = 2.1004e-01, time/batch = 0.6567s	
11996/25300 (epoch 23.708), train_loss = 0.73349712, grad/param norm = 1.7779e-01, time/batch = 0.6625s	
11997/25300 (epoch 23.709), train_loss = 1.03703950, grad/param norm = 2.3705e-01, time/batch = 0.6582s	
11998/25300 (epoch 23.711), train_loss = 1.04130290, grad/param norm = 2.0858e-01, time/batch = 0.6628s	
11999/25300 (epoch 23.713), train_loss = 0.85745542, grad/param norm = 1.7947e-01, time/batch = 0.6613s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch23.72_1.6372.t7	
12000/25300 (epoch 23.715), train_loss = 0.85002546, grad/param norm = 1.7546e-01, time/batch = 0.6591s	
12001/25300 (epoch 23.717), train_loss = 1.27954347, grad/param norm = 2.7350e-01, time/batch = 0.6661s	
12002/25300 (epoch 23.719), train_loss = 0.88200461, grad/param norm = 2.1242e-01, time/batch = 0.6647s	
12003/25300 (epoch 23.721), train_loss = 0.92482763, grad/param norm = 2.1441e-01, time/batch = 0.6645s	
12004/25300 (epoch 23.723), train_loss = 0.84097096, grad/param norm = 1.9348e-01, time/batch = 0.6659s	
12005/25300 (epoch 23.725), train_loss = 0.91544762, grad/param norm = 2.1147e-01, time/batch = 0.6634s	
12006/25300 (epoch 23.727), train_loss = 0.89268881, grad/param norm = 1.9865e-01, time/batch = 0.6655s	
12007/25300 (epoch 23.729), train_loss = 0.87266352, grad/param norm = 1.8347e-01, time/batch = 0.6646s	
12008/25300 (epoch 23.731), train_loss = 1.04314316, grad/param norm = 2.1329e-01, time/batch = 0.6733s	
12009/25300 (epoch 23.733), train_loss = 0.86367322, grad/param norm = 1.7607e-01, time/batch = 0.6673s	
12010/25300 (epoch 23.735), train_loss = 1.14822293, grad/param norm = 2.2692e-01, time/batch = 0.6686s	
12011/25300 (epoch 23.737), train_loss = 0.77380440, grad/param norm = 1.7343e-01, time/batch = 0.6607s	
12012/25300 (epoch 23.739), train_loss = 1.02643213, grad/param norm = 2.0392e-01, time/batch = 0.6636s	
12013/25300 (epoch 23.741), train_loss = 0.95439928, grad/param norm = 2.1065e-01, time/batch = 0.6596s	
12014/25300 (epoch 23.743), train_loss = 0.86975675, grad/param norm = 1.9586e-01, time/batch = 0.6622s	
12015/25300 (epoch 23.745), train_loss = 0.83032627, grad/param norm = 1.9681e-01, time/batch = 0.6634s	
12016/25300 (epoch 23.747), train_loss = 0.79512746, grad/param norm = 1.7357e-01, time/batch = 0.6640s	
12017/25300 (epoch 23.749), train_loss = 0.89873007, grad/param norm = 2.0826e-01, time/batch = 0.6643s	
12018/25300 (epoch 23.751), train_loss = 0.95279165, grad/param norm = 1.9789e-01, time/batch = 0.6626s	
12019/25300 (epoch 23.753), train_loss = 0.78675585, grad/param norm = 1.9435e-01, time/batch = 0.6653s	
12020/25300 (epoch 23.755), train_loss = 1.00418270, grad/param norm = 2.6392e-01, time/batch = 0.6615s	
12021/25300 (epoch 23.757), train_loss = 0.83043948, grad/param norm = 1.9375e-01, time/batch = 0.6632s	
12022/25300 (epoch 23.759), train_loss = 0.81283616, grad/param norm = 1.9855e-01, time/batch = 0.6612s	
12023/25300 (epoch 23.761), train_loss = 1.02771508, grad/param norm = 2.1000e-01, time/batch = 0.6631s	
12024/25300 (epoch 23.763), train_loss = 0.83318379, grad/param norm = 1.8656e-01, time/batch = 0.6646s	
12025/25300 (epoch 23.765), train_loss = 0.86823882, grad/param norm = 2.0777e-01, time/batch = 0.6623s	
12026/25300 (epoch 23.767), train_loss = 0.82889674, grad/param norm = 1.8772e-01, time/batch = 0.6604s	
12027/25300 (epoch 23.769), train_loss = 0.88535171, grad/param norm = 2.1743e-01, time/batch = 0.6619s	
12028/25300 (epoch 23.771), train_loss = 1.02080941, grad/param norm = 2.3875e-01, time/batch = 0.6635s	
12029/25300 (epoch 23.773), train_loss = 1.02566008, grad/param norm = 2.4433e-01, time/batch = 0.6650s	
12030/25300 (epoch 23.775), train_loss = 0.87570887, grad/param norm = 1.7925e-01, time/batch = 0.6619s	
12031/25300 (epoch 23.777), train_loss = 0.87672701, grad/param norm = 2.2249e-01, time/batch = 0.6655s	
12032/25300 (epoch 23.779), train_loss = 0.98078876, grad/param norm = 1.9808e-01, time/batch = 0.6597s	
12033/25300 (epoch 23.781), train_loss = 0.94144959, grad/param norm = 1.9444e-01, time/batch = 0.6643s	
12034/25300 (epoch 23.783), train_loss = 0.99903438, grad/param norm = 2.0135e-01, time/batch = 0.6683s	
12035/25300 (epoch 23.785), train_loss = 0.97318116, grad/param norm = 2.1487e-01, time/batch = 0.6740s	
12036/25300 (epoch 23.787), train_loss = 0.96108547, grad/param norm = 2.2608e-01, time/batch = 0.6700s	
12037/25300 (epoch 23.789), train_loss = 1.11126074, grad/param norm = 2.3350e-01, time/batch = 0.6618s	
12038/25300 (epoch 23.791), train_loss = 0.95638778, grad/param norm = 2.2031e-01, time/batch = 0.6711s	
12039/25300 (epoch 23.792), train_loss = 1.01742885, grad/param norm = 2.0815e-01, time/batch = 0.6673s	
12040/25300 (epoch 23.794), train_loss = 0.90071528, grad/param norm = 2.0778e-01, time/batch = 0.6635s	
12041/25300 (epoch 23.796), train_loss = 0.85250577, grad/param norm = 1.9846e-01, time/batch = 0.6753s	
12042/25300 (epoch 23.798), train_loss = 0.99549517, grad/param norm = 2.2179e-01, time/batch = 0.6792s	
12043/25300 (epoch 23.800), train_loss = 0.85469215, grad/param norm = 1.8183e-01, time/batch = 0.6661s	
12044/25300 (epoch 23.802), train_loss = 0.71619931, grad/param norm = 1.8157e-01, time/batch = 0.6637s	
12045/25300 (epoch 23.804), train_loss = 0.89595833, grad/param norm = 1.9568e-01, time/batch = 0.6572s	
12046/25300 (epoch 23.806), train_loss = 0.97026102, grad/param norm = 2.1930e-01, time/batch = 0.6605s	
12047/25300 (epoch 23.808), train_loss = 0.98316135, grad/param norm = 2.0457e-01, time/batch = 0.6683s	
12048/25300 (epoch 23.810), train_loss = 0.87746098, grad/param norm = 2.0191e-01, time/batch = 0.6581s	
12049/25300 (epoch 23.812), train_loss = 0.98788116, grad/param norm = 1.8778e-01, time/batch = 0.6592s	
12050/25300 (epoch 23.814), train_loss = 1.04605899, grad/param norm = 2.3625e-01, time/batch = 0.6586s	
12051/25300 (epoch 23.816), train_loss = 1.14232210, grad/param norm = 2.2123e-01, time/batch = 0.6593s	
12052/25300 (epoch 23.818), train_loss = 0.94366779, grad/param norm = 1.8560e-01, time/batch = 0.6555s	
12053/25300 (epoch 23.820), train_loss = 0.97814533, grad/param norm = 2.0043e-01, time/batch = 0.6526s	
12054/25300 (epoch 23.822), train_loss = 0.86039163, grad/param norm = 1.8060e-01, time/batch = 0.6578s	
12055/25300 (epoch 23.824), train_loss = 1.00329339, grad/param norm = 2.0220e-01, time/batch = 0.6562s	
12056/25300 (epoch 23.826), train_loss = 0.83470297, grad/param norm = 1.7817e-01, time/batch = 0.6613s	
12057/25300 (epoch 23.828), train_loss = 0.82802396, grad/param norm = 2.2141e-01, time/batch = 0.6598s	
12058/25300 (epoch 23.830), train_loss = 0.92490810, grad/param norm = 2.0416e-01, time/batch = 0.6630s	
12059/25300 (epoch 23.832), train_loss = 0.96209040, grad/param norm = 2.0396e-01, time/batch = 0.6564s	
12060/25300 (epoch 23.834), train_loss = 0.79702845, grad/param norm = 1.7487e-01, time/batch = 0.6621s	
12061/25300 (epoch 23.836), train_loss = 0.89647196, grad/param norm = 2.0095e-01, time/batch = 0.6597s	
12062/25300 (epoch 23.838), train_loss = 0.86770844, grad/param norm = 1.9864e-01, time/batch = 0.6623s	
12063/25300 (epoch 23.840), train_loss = 1.00252017, grad/param norm = 2.2484e-01, time/batch = 0.6574s	
12064/25300 (epoch 23.842), train_loss = 0.91905228, grad/param norm = 2.1179e-01, time/batch = 0.6622s	
12065/25300 (epoch 23.844), train_loss = 0.97588621, grad/param norm = 1.8715e-01, time/batch = 0.6583s	
12066/25300 (epoch 23.846), train_loss = 0.97400264, grad/param norm = 1.8719e-01, time/batch = 0.6602s	
12067/25300 (epoch 23.848), train_loss = 0.99999684, grad/param norm = 2.1779e-01, time/batch = 0.6618s	
12068/25300 (epoch 23.850), train_loss = 0.95276021, grad/param norm = 2.0191e-01, time/batch = 0.6590s	
12069/25300 (epoch 23.852), train_loss = 0.98216678, grad/param norm = 2.0375e-01, time/batch = 0.6625s	
12070/25300 (epoch 23.854), train_loss = 1.05365190, grad/param norm = 2.0450e-01, time/batch = 0.6586s	
12071/25300 (epoch 23.856), train_loss = 0.91039362, grad/param norm = 2.1783e-01, time/batch = 0.6609s	
12072/25300 (epoch 23.858), train_loss = 0.92645300, grad/param norm = 1.9423e-01, time/batch = 0.6629s	
12073/25300 (epoch 23.860), train_loss = 0.78155778, grad/param norm = 1.9395e-01, time/batch = 0.6616s	
12074/25300 (epoch 23.862), train_loss = 0.90454576, grad/param norm = 2.3338e-01, time/batch = 0.6616s	
12075/25300 (epoch 23.864), train_loss = 0.99734186, grad/param norm = 2.1105e-01, time/batch = 0.6623s	
12076/25300 (epoch 23.866), train_loss = 0.88324489, grad/param norm = 2.0086e-01, time/batch = 0.6610s	
12077/25300 (epoch 23.868), train_loss = 1.04551732, grad/param norm = 2.1697e-01, time/batch = 0.6606s	
12078/25300 (epoch 23.870), train_loss = 1.00011226, grad/param norm = 1.7663e-01, time/batch = 0.6644s	
12079/25300 (epoch 23.872), train_loss = 0.98632987, grad/param norm = 2.3578e-01, time/batch = 0.6626s	
12080/25300 (epoch 23.874), train_loss = 0.95956972, grad/param norm = 2.0840e-01, time/batch = 0.6676s	
12081/25300 (epoch 23.875), train_loss = 0.90289478, grad/param norm = 2.2468e-01, time/batch = 0.6612s	
12082/25300 (epoch 23.877), train_loss = 0.88495826, grad/param norm = 1.8162e-01, time/batch = 0.6608s	
12083/25300 (epoch 23.879), train_loss = 0.89169962, grad/param norm = 3.0276e-01, time/batch = 0.6588s	
12084/25300 (epoch 23.881), train_loss = 1.24082840, grad/param norm = 3.0089e-01, time/batch = 0.6572s	
12085/25300 (epoch 23.883), train_loss = 1.14489164, grad/param norm = 2.2271e-01, time/batch = 0.6593s	
12086/25300 (epoch 23.885), train_loss = 1.01549586, grad/param norm = 2.6765e-01, time/batch = 0.6491s	
12087/25300 (epoch 23.887), train_loss = 1.00592019, grad/param norm = 2.1785e-01, time/batch = 0.6549s	
12088/25300 (epoch 23.889), train_loss = 1.10265815, grad/param norm = 2.3400e-01, time/batch = 0.6580s	
12089/25300 (epoch 23.891), train_loss = 0.97832260, grad/param norm = 2.7125e-01, time/batch = 0.6591s	
12090/25300 (epoch 23.893), train_loss = 0.98906267, grad/param norm = 2.4490e-01, time/batch = 0.6615s	
12091/25300 (epoch 23.895), train_loss = 0.72271127, grad/param norm = 1.9062e-01, time/batch = 0.6620s	
12092/25300 (epoch 23.897), train_loss = 0.83610065, grad/param norm = 1.8903e-01, time/batch = 0.6598s	
12093/25300 (epoch 23.899), train_loss = 0.95071919, grad/param norm = 2.1408e-01, time/batch = 0.6592s	
12094/25300 (epoch 23.901), train_loss = 0.97931160, grad/param norm = 1.9147e-01, time/batch = 0.6677s	
12095/25300 (epoch 23.903), train_loss = 0.74359058, grad/param norm = 1.9219e-01, time/batch = 0.6570s	
12096/25300 (epoch 23.905), train_loss = 0.86598573, grad/param norm = 2.3837e-01, time/batch = 0.6579s	
12097/25300 (epoch 23.907), train_loss = 0.87372549, grad/param norm = 2.1706e-01, time/batch = 0.6631s	
12098/25300 (epoch 23.909), train_loss = 0.98162937, grad/param norm = 1.9645e-01, time/batch = 0.6624s	
12099/25300 (epoch 23.911), train_loss = 1.05901601, grad/param norm = 2.5442e-01, time/batch = 0.6563s	
12100/25300 (epoch 23.913), train_loss = 1.14007639, grad/param norm = 2.2879e-01, time/batch = 0.6666s	
12101/25300 (epoch 23.915), train_loss = 0.85455074, grad/param norm = 2.0230e-01, time/batch = 0.6631s	
12102/25300 (epoch 23.917), train_loss = 1.03781581, grad/param norm = 2.1950e-01, time/batch = 0.6625s	
12103/25300 (epoch 23.919), train_loss = 1.07176209, grad/param norm = 2.4742e-01, time/batch = 0.6590s	
12104/25300 (epoch 23.921), train_loss = 0.86148777, grad/param norm = 1.9956e-01, time/batch = 0.6636s	
12105/25300 (epoch 23.923), train_loss = 1.05987767, grad/param norm = 2.1160e-01, time/batch = 0.6581s	
12106/25300 (epoch 23.925), train_loss = 0.92301174, grad/param norm = 2.3256e-01, time/batch = 0.6588s	
12107/25300 (epoch 23.927), train_loss = 0.89283493, grad/param norm = 1.8593e-01, time/batch = 0.6689s	
12108/25300 (epoch 23.929), train_loss = 0.94832922, grad/param norm = 1.9339e-01, time/batch = 0.6644s	
12109/25300 (epoch 23.931), train_loss = 0.99561545, grad/param norm = 2.4333e-01, time/batch = 0.6615s	
12110/25300 (epoch 23.933), train_loss = 0.97219840, grad/param norm = 2.0192e-01, time/batch = 0.6629s	
12111/25300 (epoch 23.935), train_loss = 0.95986706, grad/param norm = 1.9592e-01, time/batch = 0.6655s	
12112/25300 (epoch 23.937), train_loss = 0.70999210, grad/param norm = 1.7709e-01, time/batch = 0.6581s	
12113/25300 (epoch 23.939), train_loss = 0.96764063, grad/param norm = 1.9461e-01, time/batch = 0.6687s	
12114/25300 (epoch 23.941), train_loss = 0.85812565, grad/param norm = 2.1399e-01, time/batch = 0.6637s	
12115/25300 (epoch 23.943), train_loss = 0.96069361, grad/param norm = 1.9313e-01, time/batch = 0.6633s	
12116/25300 (epoch 23.945), train_loss = 1.00042388, grad/param norm = 2.3346e-01, time/batch = 0.6662s	
12117/25300 (epoch 23.947), train_loss = 0.84032759, grad/param norm = 1.9336e-01, time/batch = 0.6560s	
12118/25300 (epoch 23.949), train_loss = 0.98694054, grad/param norm = 1.8919e-01, time/batch = 0.6581s	
12119/25300 (epoch 23.951), train_loss = 0.91629447, grad/param norm = 1.7593e-01, time/batch = 0.6630s	
12120/25300 (epoch 23.953), train_loss = 0.93132792, grad/param norm = 2.0321e-01, time/batch = 0.6585s	
12121/25300 (epoch 23.955), train_loss = 1.13815367, grad/param norm = 2.3487e-01, time/batch = 0.6638s	
12122/25300 (epoch 23.957), train_loss = 1.07243846, grad/param norm = 2.3310e-01, time/batch = 0.6594s	
12123/25300 (epoch 23.958), train_loss = 1.00564720, grad/param norm = 2.2440e-01, time/batch = 0.6654s	
12124/25300 (epoch 23.960), train_loss = 1.11149648, grad/param norm = 2.2601e-01, time/batch = 0.6641s	
12125/25300 (epoch 23.962), train_loss = 1.09444059, grad/param norm = 2.2355e-01, time/batch = 0.6684s	
12126/25300 (epoch 23.964), train_loss = 0.98993683, grad/param norm = 2.2215e-01, time/batch = 0.6681s	
12127/25300 (epoch 23.966), train_loss = 0.80475974, grad/param norm = 1.8570e-01, time/batch = 0.6631s	
12128/25300 (epoch 23.968), train_loss = 0.77420152, grad/param norm = 1.6303e-01, time/batch = 0.6656s	
12129/25300 (epoch 23.970), train_loss = 0.91830314, grad/param norm = 2.5757e-01, time/batch = 0.6693s	
12130/25300 (epoch 23.972), train_loss = 0.93322355, grad/param norm = 2.0419e-01, time/batch = 0.6679s	
12131/25300 (epoch 23.974), train_loss = 1.07496139, grad/param norm = 2.4585e-01, time/batch = 0.6696s	
12132/25300 (epoch 23.976), train_loss = 0.98680275, grad/param norm = 2.2081e-01, time/batch = 0.6633s	
12133/25300 (epoch 23.978), train_loss = 0.93291643, grad/param norm = 2.3631e-01, time/batch = 0.6655s	
12134/25300 (epoch 23.980), train_loss = 0.95096362, grad/param norm = 2.3955e-01, time/batch = 0.6663s	
12135/25300 (epoch 23.982), train_loss = 0.88001436, grad/param norm = 2.0166e-01, time/batch = 0.6618s	
12136/25300 (epoch 23.984), train_loss = 0.91808729, grad/param norm = 2.5784e-01, time/batch = 0.6763s	
12137/25300 (epoch 23.986), train_loss = 1.02971888, grad/param norm = 2.2752e-01, time/batch = 0.6836s	
12138/25300 (epoch 23.988), train_loss = 0.97023189, grad/param norm = 2.2168e-01, time/batch = 0.6660s	
12139/25300 (epoch 23.990), train_loss = 0.93006776, grad/param norm = 2.0653e-01, time/batch = 0.6703s	
12140/25300 (epoch 23.992), train_loss = 0.80554419, grad/param norm = 2.0073e-01, time/batch = 0.6619s	
12141/25300 (epoch 23.994), train_loss = 0.95292783, grad/param norm = 2.3274e-01, time/batch = 0.6649s	
12142/25300 (epoch 23.996), train_loss = 1.07160227, grad/param norm = 2.6929e-01, time/batch = 0.6728s	
12143/25300 (epoch 23.998), train_loss = 1.07876244, grad/param norm = 2.5612e-01, time/batch = 0.6629s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
12144/25300 (epoch 24.000), train_loss = 0.95835753, grad/param norm = 2.0504e-01, time/batch = 0.6560s	
12145/25300 (epoch 24.002), train_loss = 0.86268024, grad/param norm = 1.7307e-01, time/batch = 0.6592s	
12146/25300 (epoch 24.004), train_loss = 0.77843662, grad/param norm = 1.7387e-01, time/batch = 0.6615s	
12147/25300 (epoch 24.006), train_loss = 1.06909860, grad/param norm = 2.1214e-01, time/batch = 0.6583s	
12148/25300 (epoch 24.008), train_loss = 0.92755206, grad/param norm = 1.7566e-01, time/batch = 0.6619s	
12149/25300 (epoch 24.010), train_loss = 0.94969790, grad/param norm = 2.0275e-01, time/batch = 0.6593s	
12150/25300 (epoch 24.012), train_loss = 0.88388805, grad/param norm = 2.0825e-01, time/batch = 0.6635s	
12151/25300 (epoch 24.014), train_loss = 1.08051994, grad/param norm = 2.1488e-01, time/batch = 0.6619s	
12152/25300 (epoch 24.016), train_loss = 0.95083261, grad/param norm = 2.1473e-01, time/batch = 0.6609s	
12153/25300 (epoch 24.018), train_loss = 0.82124872, grad/param norm = 1.9188e-01, time/batch = 0.6639s	
12154/25300 (epoch 24.020), train_loss = 0.92388429, grad/param norm = 1.9534e-01, time/batch = 0.6589s	
12155/25300 (epoch 24.022), train_loss = 0.92493238, grad/param norm = 1.9329e-01, time/batch = 0.6650s	
12156/25300 (epoch 24.024), train_loss = 0.69697457, grad/param norm = 1.5298e-01, time/batch = 0.6604s	
12157/25300 (epoch 24.026), train_loss = 0.88739825, grad/param norm = 2.1100e-01, time/batch = 0.6593s	
12158/25300 (epoch 24.028), train_loss = 0.83882909, grad/param norm = 1.7548e-01, time/batch = 0.6630s	
12159/25300 (epoch 24.030), train_loss = 1.02285062, grad/param norm = 1.8472e-01, time/batch = 0.6635s	
12160/25300 (epoch 24.032), train_loss = 0.88345592, grad/param norm = 1.9850e-01, time/batch = 0.6625s	
12161/25300 (epoch 24.034), train_loss = 0.80327201, grad/param norm = 1.9058e-01, time/batch = 0.6624s	
12162/25300 (epoch 24.036), train_loss = 0.77322475, grad/param norm = 1.6667e-01, time/batch = 0.6622s	
12163/25300 (epoch 24.038), train_loss = 0.70001002, grad/param norm = 1.5746e-01, time/batch = 0.6593s	
12164/25300 (epoch 24.040), train_loss = 0.93513517, grad/param norm = 1.9677e-01, time/batch = 0.6640s	
12165/25300 (epoch 24.042), train_loss = 0.88900598, grad/param norm = 1.7967e-01, time/batch = 0.6626s	
12166/25300 (epoch 24.043), train_loss = 0.77601746, grad/param norm = 1.7647e-01, time/batch = 0.6603s	
12167/25300 (epoch 24.045), train_loss = 0.77058415, grad/param norm = 1.7011e-01, time/batch = 0.6612s	
12168/25300 (epoch 24.047), train_loss = 0.97458261, grad/param norm = 2.0701e-01, time/batch = 0.6620s	
12169/25300 (epoch 24.049), train_loss = 0.92886067, grad/param norm = 1.9091e-01, time/batch = 0.6612s	
12170/25300 (epoch 24.051), train_loss = 1.01647953, grad/param norm = 2.1197e-01, time/batch = 0.6615s	
12171/25300 (epoch 24.053), train_loss = 0.72453913, grad/param norm = 1.6121e-01, time/batch = 0.6616s	
12172/25300 (epoch 24.055), train_loss = 0.78774840, grad/param norm = 1.7437e-01, time/batch = 0.6605s	
12173/25300 (epoch 24.057), train_loss = 0.75278182, grad/param norm = 1.5850e-01, time/batch = 0.6602s	
12174/25300 (epoch 24.059), train_loss = 0.84674459, grad/param norm = 1.8184e-01, time/batch = 0.6591s	
12175/25300 (epoch 24.061), train_loss = 0.84127898, grad/param norm = 1.9069e-01, time/batch = 0.6640s	
12176/25300 (epoch 24.063), train_loss = 0.81564096, grad/param norm = 1.7187e-01, time/batch = 0.6633s	
12177/25300 (epoch 24.065), train_loss = 0.93416985, grad/param norm = 2.0910e-01, time/batch = 0.6617s	
12178/25300 (epoch 24.067), train_loss = 0.99928081, grad/param norm = 1.9530e-01, time/batch = 0.6546s	
12179/25300 (epoch 24.069), train_loss = 0.83629912, grad/param norm = 1.9687e-01, time/batch = 0.6616s	
12180/25300 (epoch 24.071), train_loss = 1.00479056, grad/param norm = 2.2352e-01, time/batch = 0.6572s	
12181/25300 (epoch 24.073), train_loss = 0.85064301, grad/param norm = 1.6651e-01, time/batch = 0.6607s	
12182/25300 (epoch 24.075), train_loss = 0.98487994, grad/param norm = 2.3141e-01, time/batch = 0.6622s	
12183/25300 (epoch 24.077), train_loss = 0.95082066, grad/param norm = 2.3745e-01, time/batch = 0.6566s	
12184/25300 (epoch 24.079), train_loss = 0.87373701, grad/param norm = 1.9660e-01, time/batch = 0.6607s	
12185/25300 (epoch 24.081), train_loss = 0.88737773, grad/param norm = 1.9003e-01, time/batch = 0.6573s	
12186/25300 (epoch 24.083), train_loss = 0.89283901, grad/param norm = 1.7834e-01, time/batch = 0.6595s	
12187/25300 (epoch 24.085), train_loss = 1.11544808, grad/param norm = 2.3333e-01, time/batch = 0.6598s	
12188/25300 (epoch 24.087), train_loss = 1.00548206, grad/param norm = 2.0640e-01, time/batch = 0.6598s	
12189/25300 (epoch 24.089), train_loss = 0.96425431, grad/param norm = 2.0255e-01, time/batch = 0.6562s	
12190/25300 (epoch 24.091), train_loss = 1.05178670, grad/param norm = 1.9641e-01, time/batch = 0.6595s	
12191/25300 (epoch 24.093), train_loss = 1.03266294, grad/param norm = 2.3690e-01, time/batch = 0.6602s	
12192/25300 (epoch 24.095), train_loss = 0.98659390, grad/param norm = 1.9937e-01, time/batch = 0.6610s	
12193/25300 (epoch 24.097), train_loss = 0.97221308, grad/param norm = 2.1438e-01, time/batch = 0.6570s	
12194/25300 (epoch 24.099), train_loss = 0.95959709, grad/param norm = 2.0837e-01, time/batch = 0.6635s	
12195/25300 (epoch 24.101), train_loss = 0.89220263, grad/param norm = 2.1458e-01, time/batch = 0.6604s	
12196/25300 (epoch 24.103), train_loss = 0.91825683, grad/param norm = 1.9232e-01, time/batch = 0.6637s	
12197/25300 (epoch 24.105), train_loss = 0.99517005, grad/param norm = 2.0100e-01, time/batch = 0.6571s	
12198/25300 (epoch 24.107), train_loss = 1.00211561, grad/param norm = 2.3278e-01, time/batch = 0.6611s	
12199/25300 (epoch 24.109), train_loss = 0.91139168, grad/param norm = 2.2147e-01, time/batch = 0.6597s	
12200/25300 (epoch 24.111), train_loss = 0.88094668, grad/param norm = 1.8589e-01, time/batch = 0.6598s	
12201/25300 (epoch 24.113), train_loss = 0.86638996, grad/param norm = 2.0482e-01, time/batch = 0.6643s	
12202/25300 (epoch 24.115), train_loss = 0.90570829, grad/param norm = 2.1640e-01, time/batch = 0.6616s	
12203/25300 (epoch 24.117), train_loss = 0.99200276, grad/param norm = 1.9480e-01, time/batch = 0.6639s	
12204/25300 (epoch 24.119), train_loss = 0.88592082, grad/param norm = 2.1592e-01, time/batch = 0.6604s	
12205/25300 (epoch 24.121), train_loss = 0.94757499, grad/param norm = 2.2765e-01, time/batch = 0.6649s	
12206/25300 (epoch 24.123), train_loss = 0.87190561, grad/param norm = 2.0948e-01, time/batch = 0.6629s	
12207/25300 (epoch 24.125), train_loss = 1.00847080, grad/param norm = 2.3169e-01, time/batch = 0.6639s	
12208/25300 (epoch 24.126), train_loss = 0.90298095, grad/param norm = 2.0605e-01, time/batch = 0.6612s	
12209/25300 (epoch 24.128), train_loss = 0.90425406, grad/param norm = 2.1500e-01, time/batch = 0.6600s	
12210/25300 (epoch 24.130), train_loss = 0.74231529, grad/param norm = 1.7438e-01, time/batch = 0.6617s	
12211/25300 (epoch 24.132), train_loss = 0.78845731, grad/param norm = 1.9758e-01, time/batch = 0.6620s	
12212/25300 (epoch 24.134), train_loss = 0.75196598, grad/param norm = 1.7282e-01, time/batch = 0.6617s	
12213/25300 (epoch 24.136), train_loss = 0.88550988, grad/param norm = 1.8357e-01, time/batch = 0.6589s	
12214/25300 (epoch 24.138), train_loss = 0.78389736, grad/param norm = 1.8434e-01, time/batch = 0.6635s	
12215/25300 (epoch 24.140), train_loss = 0.81038394, grad/param norm = 1.7404e-01, time/batch = 0.6680s	
12216/25300 (epoch 24.142), train_loss = 1.01139303, grad/param norm = 2.0176e-01, time/batch = 0.6684s	
12217/25300 (epoch 24.144), train_loss = 0.99353830, grad/param norm = 2.2879e-01, time/batch = 0.6653s	
12218/25300 (epoch 24.146), train_loss = 0.93908263, grad/param norm = 2.1583e-01, time/batch = 0.6645s	
12219/25300 (epoch 24.148), train_loss = 0.90144318, grad/param norm = 1.8416e-01, time/batch = 0.6845s	
12220/25300 (epoch 24.150), train_loss = 1.00248239, grad/param norm = 2.1103e-01, time/batch = 0.6645s	
12221/25300 (epoch 24.152), train_loss = 1.06203699, grad/param norm = 2.2235e-01, time/batch = 0.6675s	
12222/25300 (epoch 24.154), train_loss = 0.74851282, grad/param norm = 1.6372e-01, time/batch = 0.6684s	
12223/25300 (epoch 24.156), train_loss = 0.97250889, grad/param norm = 2.2187e-01, time/batch = 0.6641s	
12224/25300 (epoch 24.158), train_loss = 0.80618694, grad/param norm = 1.8176e-01, time/batch = 0.6648s	
12225/25300 (epoch 24.160), train_loss = 0.90346845, grad/param norm = 1.8692e-01, time/batch = 0.6626s	
12226/25300 (epoch 24.162), train_loss = 0.86282642, grad/param norm = 1.9925e-01, time/batch = 0.6610s	
12227/25300 (epoch 24.164), train_loss = 0.97003412, grad/param norm = 1.9914e-01, time/batch = 0.6591s	
12228/25300 (epoch 24.166), train_loss = 0.91908839, grad/param norm = 1.9203e-01, time/batch = 0.6635s	
12229/25300 (epoch 24.168), train_loss = 0.82830798, grad/param norm = 1.7357e-01, time/batch = 0.6598s	
12230/25300 (epoch 24.170), train_loss = 0.86161011, grad/param norm = 1.9651e-01, time/batch = 0.6653s	
12231/25300 (epoch 24.172), train_loss = 0.79710857, grad/param norm = 1.8044e-01, time/batch = 0.6666s	
12232/25300 (epoch 24.174), train_loss = 0.80595807, grad/param norm = 1.8010e-01, time/batch = 0.6711s	
12233/25300 (epoch 24.176), train_loss = 0.81385182, grad/param norm = 2.0028e-01, time/batch = 0.6659s	
12234/25300 (epoch 24.178), train_loss = 1.03854286, grad/param norm = 2.2662e-01, time/batch = 0.6674s	
12235/25300 (epoch 24.180), train_loss = 0.74938255, grad/param norm = 1.7207e-01, time/batch = 0.6640s	
12236/25300 (epoch 24.182), train_loss = 0.86129700, grad/param norm = 2.0018e-01, time/batch = 0.6612s	
12237/25300 (epoch 24.184), train_loss = 0.82196634, grad/param norm = 2.0290e-01, time/batch = 0.6709s	
12238/25300 (epoch 24.186), train_loss = 0.80654227, grad/param norm = 1.9435e-01, time/batch = 0.6609s	
12239/25300 (epoch 24.188), train_loss = 0.92465825, grad/param norm = 2.2188e-01, time/batch = 0.6597s	
12240/25300 (epoch 24.190), train_loss = 0.85819101, grad/param norm = 1.9512e-01, time/batch = 0.6623s	
12241/25300 (epoch 24.192), train_loss = 0.89014533, grad/param norm = 2.1750e-01, time/batch = 0.6621s	
12242/25300 (epoch 24.194), train_loss = 0.88068059, grad/param norm = 2.0938e-01, time/batch = 0.6667s	
12243/25300 (epoch 24.196), train_loss = 0.99041541, grad/param norm = 2.1883e-01, time/batch = 0.6616s	
12244/25300 (epoch 24.198), train_loss = 0.84093891, grad/param norm = 2.0198e-01, time/batch = 0.6649s	
12245/25300 (epoch 24.200), train_loss = 0.86125321, grad/param norm = 2.2073e-01, time/batch = 0.6641s	
12246/25300 (epoch 24.202), train_loss = 0.88778484, grad/param norm = 1.8432e-01, time/batch = 0.6764s	
12247/25300 (epoch 24.204), train_loss = 0.86367258, grad/param norm = 1.9454e-01, time/batch = 0.6592s	
12248/25300 (epoch 24.206), train_loss = 0.99014530, grad/param norm = 2.1540e-01, time/batch = 0.6598s	
12249/25300 (epoch 24.208), train_loss = 0.77768119, grad/param norm = 1.8388e-01, time/batch = 0.6615s	
12250/25300 (epoch 24.209), train_loss = 0.76639950, grad/param norm = 1.7995e-01, time/batch = 0.6584s	
12251/25300 (epoch 24.211), train_loss = 0.85704507, grad/param norm = 1.8757e-01, time/batch = 0.6656s	
12252/25300 (epoch 24.213), train_loss = 0.93631017, grad/param norm = 2.0636e-01, time/batch = 0.6622s	
12253/25300 (epoch 24.215), train_loss = 0.89285100, grad/param norm = 2.1155e-01, time/batch = 0.6638s	
12254/25300 (epoch 24.217), train_loss = 0.93148103, grad/param norm = 2.2316e-01, time/batch = 0.6574s	
12255/25300 (epoch 24.219), train_loss = 1.00564461, grad/param norm = 2.1799e-01, time/batch = 0.6604s	
12256/25300 (epoch 24.221), train_loss = 1.03787525, grad/param norm = 2.1522e-01, time/batch = 0.6621s	
12257/25300 (epoch 24.223), train_loss = 0.97954042, grad/param norm = 2.1820e-01, time/batch = 0.6584s	
12258/25300 (epoch 24.225), train_loss = 1.26941481, grad/param norm = 3.7279e-01, time/batch = 0.6604s	
12259/25300 (epoch 24.227), train_loss = 1.02939701, grad/param norm = 2.1777e-01, time/batch = 0.6571s	
12260/25300 (epoch 24.229), train_loss = 0.90098502, grad/param norm = 1.9402e-01, time/batch = 0.6613s	
12261/25300 (epoch 24.231), train_loss = 0.89152104, grad/param norm = 1.9987e-01, time/batch = 0.6607s	
12262/25300 (epoch 24.233), train_loss = 0.98381632, grad/param norm = 2.0595e-01, time/batch = 0.6607s	
12263/25300 (epoch 24.235), train_loss = 0.90153113, grad/param norm = 1.9591e-01, time/batch = 0.6596s	
12264/25300 (epoch 24.237), train_loss = 1.03428211, grad/param norm = 2.0988e-01, time/batch = 0.6613s	
12265/25300 (epoch 24.239), train_loss = 0.87162267, grad/param norm = 1.9757e-01, time/batch = 0.6599s	
12266/25300 (epoch 24.241), train_loss = 1.05124321, grad/param norm = 2.0970e-01, time/batch = 0.6613s	
12267/25300 (epoch 24.243), train_loss = 1.19643394, grad/param norm = 2.3863e-01, time/batch = 0.6586s	
12268/25300 (epoch 24.245), train_loss = 0.86120819, grad/param norm = 2.1765e-01, time/batch = 0.6610s	
12269/25300 (epoch 24.247), train_loss = 0.98923906, grad/param norm = 2.1510e-01, time/batch = 0.6624s	
12270/25300 (epoch 24.249), train_loss = 0.78460951, grad/param norm = 1.7251e-01, time/batch = 0.6596s	
12271/25300 (epoch 24.251), train_loss = 0.78694817, grad/param norm = 1.8010e-01, time/batch = 0.6640s	
12272/25300 (epoch 24.253), train_loss = 0.88502089, grad/param norm = 1.8683e-01, time/batch = 0.6609s	
12273/25300 (epoch 24.255), train_loss = 0.83548191, grad/param norm = 2.0661e-01, time/batch = 0.6676s	
12274/25300 (epoch 24.257), train_loss = 0.91516842, grad/param norm = 2.2609e-01, time/batch = 0.6614s	
12275/25300 (epoch 24.259), train_loss = 1.12514749, grad/param norm = 2.7364e-01, time/batch = 0.6656s	
12276/25300 (epoch 24.261), train_loss = 1.07864095, grad/param norm = 2.5729e-01, time/batch = 0.6607s	
12277/25300 (epoch 24.263), train_loss = 1.06771735, grad/param norm = 2.2183e-01, time/batch = 0.6603s	
12278/25300 (epoch 24.265), train_loss = 1.11554961, grad/param norm = 2.3903e-01, time/batch = 0.6608s	
12279/25300 (epoch 24.267), train_loss = 0.99836657, grad/param norm = 2.0720e-01, time/batch = 0.6640s	
12280/25300 (epoch 24.269), train_loss = 0.78115454, grad/param norm = 1.8936e-01, time/batch = 0.6582s	
12281/25300 (epoch 24.271), train_loss = 0.86580735, grad/param norm = 2.0226e-01, time/batch = 0.6641s	
12282/25300 (epoch 24.273), train_loss = 0.98779122, grad/param norm = 2.2152e-01, time/batch = 0.6566s	
12283/25300 (epoch 24.275), train_loss = 0.89313721, grad/param norm = 1.8427e-01, time/batch = 0.6524s	
12284/25300 (epoch 24.277), train_loss = 0.87007440, grad/param norm = 2.0726e-01, time/batch = 0.6602s	
12285/25300 (epoch 24.279), train_loss = 0.90383754, grad/param norm = 1.9488e-01, time/batch = 0.6568s	
12286/25300 (epoch 24.281), train_loss = 1.06066587, grad/param norm = 2.1975e-01, time/batch = 0.6595s	
12287/25300 (epoch 24.283), train_loss = 0.79052203, grad/param norm = 1.6887e-01, time/batch = 0.6618s	
12288/25300 (epoch 24.285), train_loss = 0.94919561, grad/param norm = 2.1380e-01, time/batch = 0.6624s	
12289/25300 (epoch 24.287), train_loss = 0.97735942, grad/param norm = 1.9512e-01, time/batch = 0.6612s	
12290/25300 (epoch 24.289), train_loss = 0.88442493, grad/param norm = 1.9624e-01, time/batch = 0.6636s	
12291/25300 (epoch 24.291), train_loss = 0.89673104, grad/param norm = 1.9124e-01, time/batch = 0.6607s	
12292/25300 (epoch 24.292), train_loss = 1.08133611, grad/param norm = 2.0509e-01, time/batch = 0.6613s	
12293/25300 (epoch 24.294), train_loss = 0.95667348, grad/param norm = 1.9366e-01, time/batch = 0.6615s	
12294/25300 (epoch 24.296), train_loss = 0.81510008, grad/param norm = 1.9013e-01, time/batch = 0.6585s	
12295/25300 (epoch 24.298), train_loss = 0.99317760, grad/param norm = 2.1276e-01, time/batch = 0.6629s	
12296/25300 (epoch 24.300), train_loss = 1.01774620, grad/param norm = 2.2254e-01, time/batch = 0.6653s	
12297/25300 (epoch 24.302), train_loss = 0.73548172, grad/param norm = 1.9789e-01, time/batch = 0.6647s	
12298/25300 (epoch 24.304), train_loss = 1.01153599, grad/param norm = 2.1302e-01, time/batch = 0.6629s	
12299/25300 (epoch 24.306), train_loss = 0.73006727, grad/param norm = 1.8225e-01, time/batch = 0.6640s	
12300/25300 (epoch 24.308), train_loss = 0.97508975, grad/param norm = 1.8724e-01, time/batch = 0.6600s	
12301/25300 (epoch 24.310), train_loss = 0.81213730, grad/param norm = 1.8663e-01, time/batch = 0.6641s	
12302/25300 (epoch 24.312), train_loss = 0.92301023, grad/param norm = 1.8040e-01, time/batch = 0.6594s	
12303/25300 (epoch 24.314), train_loss = 0.75048676, grad/param norm = 1.7673e-01, time/batch = 0.6615s	
12304/25300 (epoch 24.316), train_loss = 0.92869918, grad/param norm = 1.8813e-01, time/batch = 0.6665s	
12305/25300 (epoch 24.318), train_loss = 0.75021365, grad/param norm = 1.8371e-01, time/batch = 0.6675s	
12306/25300 (epoch 24.320), train_loss = 0.82200170, grad/param norm = 1.9018e-01, time/batch = 0.6673s	
12307/25300 (epoch 24.322), train_loss = 1.08280117, grad/param norm = 2.3228e-01, time/batch = 0.6641s	
12308/25300 (epoch 24.324), train_loss = 0.81647453, grad/param norm = 1.7593e-01, time/batch = 0.6622s	
12309/25300 (epoch 24.326), train_loss = 0.73456531, grad/param norm = 1.7177e-01, time/batch = 0.6562s	
12310/25300 (epoch 24.328), train_loss = 0.73509310, grad/param norm = 1.8715e-01, time/batch = 0.6633s	
12311/25300 (epoch 24.330), train_loss = 0.87647209, grad/param norm = 1.9482e-01, time/batch = 0.6623s	
12312/25300 (epoch 24.332), train_loss = 0.91563384, grad/param norm = 1.8635e-01, time/batch = 0.6594s	
12313/25300 (epoch 24.334), train_loss = 0.76330005, grad/param norm = 2.1315e-01, time/batch = 0.6641s	
12314/25300 (epoch 24.336), train_loss = 0.77862701, grad/param norm = 2.1069e-01, time/batch = 0.6635s	
12315/25300 (epoch 24.338), train_loss = 0.77758630, grad/param norm = 1.8629e-01, time/batch = 0.6789s	
12316/25300 (epoch 24.340), train_loss = 0.82706979, grad/param norm = 1.9635e-01, time/batch = 0.6631s	
12317/25300 (epoch 24.342), train_loss = 0.87433588, grad/param norm = 2.3555e-01, time/batch = 0.6652s	
12318/25300 (epoch 24.344), train_loss = 0.94301085, grad/param norm = 1.9326e-01, time/batch = 0.6636s	
12319/25300 (epoch 24.346), train_loss = 0.86083983, grad/param norm = 2.0587e-01, time/batch = 0.6646s	
12320/25300 (epoch 24.348), train_loss = 0.75938097, grad/param norm = 1.8013e-01, time/batch = 0.6576s	
12321/25300 (epoch 24.350), train_loss = 0.86443927, grad/param norm = 1.8649e-01, time/batch = 0.6643s	
12322/25300 (epoch 24.352), train_loss = 0.89750171, grad/param norm = 1.9731e-01, time/batch = 0.6605s	
12323/25300 (epoch 24.354), train_loss = 0.82231126, grad/param norm = 2.0275e-01, time/batch = 0.6616s	
12324/25300 (epoch 24.356), train_loss = 0.88205766, grad/param norm = 1.9735e-01, time/batch = 0.6644s	
12325/25300 (epoch 24.358), train_loss = 0.93709210, grad/param norm = 2.0150e-01, time/batch = 0.6606s	
12326/25300 (epoch 24.360), train_loss = 0.79991747, grad/param norm = 1.7724e-01, time/batch = 0.6646s	
12327/25300 (epoch 24.362), train_loss = 0.82752670, grad/param norm = 1.9430e-01, time/batch = 0.6628s	
12328/25300 (epoch 24.364), train_loss = 0.84360524, grad/param norm = 2.0409e-01, time/batch = 0.6664s	
12329/25300 (epoch 24.366), train_loss = 0.76450998, grad/param norm = 1.8997e-01, time/batch = 0.6616s	
12330/25300 (epoch 24.368), train_loss = 0.86363160, grad/param norm = 1.7998e-01, time/batch = 0.6611s	
12331/25300 (epoch 24.370), train_loss = 0.83739329, grad/param norm = 2.6562e-01, time/batch = 0.6627s	
12332/25300 (epoch 24.372), train_loss = 0.83664050, grad/param norm = 2.1025e-01, time/batch = 0.6617s	
12333/25300 (epoch 24.374), train_loss = 0.75030495, grad/param norm = 1.8927e-01, time/batch = 0.6626s	
12334/25300 (epoch 24.375), train_loss = 0.99324296, grad/param norm = 2.2315e-01, time/batch = 0.6632s	
12335/25300 (epoch 24.377), train_loss = 0.95278494, grad/param norm = 2.1322e-01, time/batch = 0.6586s	
12336/25300 (epoch 24.379), train_loss = 0.92263081, grad/param norm = 2.1275e-01, time/batch = 0.6634s	
12337/25300 (epoch 24.381), train_loss = 0.87314280, grad/param norm = 1.9264e-01, time/batch = 0.6594s	
12338/25300 (epoch 24.383), train_loss = 0.80234076, grad/param norm = 1.8474e-01, time/batch = 0.6634s	
12339/25300 (epoch 24.385), train_loss = 0.89101142, grad/param norm = 1.8703e-01, time/batch = 0.6594s	
12340/25300 (epoch 24.387), train_loss = 0.91101267, grad/param norm = 1.9879e-01, time/batch = 0.6626s	
12341/25300 (epoch 24.389), train_loss = 0.91209473, grad/param norm = 1.9425e-01, time/batch = 0.6653s	
12342/25300 (epoch 24.391), train_loss = 0.83598647, grad/param norm = 1.8070e-01, time/batch = 0.6653s	
12343/25300 (epoch 24.393), train_loss = 0.92437652, grad/param norm = 2.3255e-01, time/batch = 0.6622s	
12344/25300 (epoch 24.395), train_loss = 0.71898860, grad/param norm = 1.6855e-01, time/batch = 0.6610s	
12345/25300 (epoch 24.397), train_loss = 0.75244607, grad/param norm = 2.0860e-01, time/batch = 0.6658s	
12346/25300 (epoch 24.399), train_loss = 0.75001145, grad/param norm = 1.9991e-01, time/batch = 0.6609s	
12347/25300 (epoch 24.401), train_loss = 0.97633871, grad/param norm = 2.3862e-01, time/batch = 0.6650s	
12348/25300 (epoch 24.403), train_loss = 0.89887233, grad/param norm = 2.3278e-01, time/batch = 0.6667s	
12349/25300 (epoch 24.405), train_loss = 0.88056384, grad/param norm = 1.9152e-01, time/batch = 0.6689s	
12350/25300 (epoch 24.407), train_loss = 0.86171566, grad/param norm = 1.9666e-01, time/batch = 0.6701s	
12351/25300 (epoch 24.409), train_loss = 0.81462315, grad/param norm = 1.8934e-01, time/batch = 0.6645s	
12352/25300 (epoch 24.411), train_loss = 0.81083705, grad/param norm = 1.8976e-01, time/batch = 0.6610s	
12353/25300 (epoch 24.413), train_loss = 0.72488841, grad/param norm = 1.7409e-01, time/batch = 0.6670s	
12354/25300 (epoch 24.415), train_loss = 0.77907309, grad/param norm = 1.8804e-01, time/batch = 0.6642s	
12355/25300 (epoch 24.417), train_loss = 0.72881819, grad/param norm = 1.6800e-01, time/batch = 0.6585s	
12356/25300 (epoch 24.419), train_loss = 0.68309426, grad/param norm = 1.6253e-01, time/batch = 0.6662s	
12357/25300 (epoch 24.421), train_loss = 0.75797651, grad/param norm = 1.5730e-01, time/batch = 0.6608s	
12358/25300 (epoch 24.423), train_loss = 0.76210545, grad/param norm = 1.8246e-01, time/batch = 0.6622s	
12359/25300 (epoch 24.425), train_loss = 0.84607280, grad/param norm = 2.3702e-01, time/batch = 0.6624s	
12360/25300 (epoch 24.427), train_loss = 1.00687603, grad/param norm = 2.1315e-01, time/batch = 0.6619s	
12361/25300 (epoch 24.429), train_loss = 0.96411309, grad/param norm = 2.0341e-01, time/batch = 0.6625s	
12362/25300 (epoch 24.431), train_loss = 0.91857026, grad/param norm = 2.0665e-01, time/batch = 0.6647s	
12363/25300 (epoch 24.433), train_loss = 0.87777421, grad/param norm = 1.8996e-01, time/batch = 0.6608s	
12364/25300 (epoch 24.435), train_loss = 0.81485291, grad/param norm = 1.9988e-01, time/batch = 0.6659s	
12365/25300 (epoch 24.437), train_loss = 0.81061469, grad/param norm = 1.9184e-01, time/batch = 0.6636s	
12366/25300 (epoch 24.439), train_loss = 0.89878114, grad/param norm = 2.0428e-01, time/batch = 0.6594s	
12367/25300 (epoch 24.441), train_loss = 0.92284780, grad/param norm = 2.1381e-01, time/batch = 0.6684s	
12368/25300 (epoch 24.443), train_loss = 1.09295946, grad/param norm = 2.3325e-01, time/batch = 0.6620s	
12369/25300 (epoch 24.445), train_loss = 1.03130869, grad/param norm = 2.4546e-01, time/batch = 0.6745s	
12370/25300 (epoch 24.447), train_loss = 0.79267585, grad/param norm = 1.7381e-01, time/batch = 0.6620s	
12371/25300 (epoch 24.449), train_loss = 0.72736053, grad/param norm = 1.9094e-01, time/batch = 0.6671s	
12372/25300 (epoch 24.451), train_loss = 1.08179541, grad/param norm = 2.2302e-01, time/batch = 0.6614s	
12373/25300 (epoch 24.453), train_loss = 0.94125600, grad/param norm = 1.9653e-01, time/batch = 0.6645s	
12374/25300 (epoch 24.455), train_loss = 0.95038274, grad/param norm = 2.3548e-01, time/batch = 0.6593s	
12375/25300 (epoch 24.457), train_loss = 0.82412109, grad/param norm = 1.9716e-01, time/batch = 0.6633s	
12376/25300 (epoch 24.458), train_loss = 0.82282045, grad/param norm = 1.9298e-01, time/batch = 0.6613s	
12377/25300 (epoch 24.460), train_loss = 0.86002566, grad/param norm = 1.8797e-01, time/batch = 0.6616s	
12378/25300 (epoch 24.462), train_loss = 0.65049515, grad/param norm = 1.7990e-01, time/batch = 0.6605s	
12379/25300 (epoch 24.464), train_loss = 0.94138926, grad/param norm = 2.0231e-01, time/batch = 0.6676s	
12380/25300 (epoch 24.466), train_loss = 0.94576181, grad/param norm = 1.9998e-01, time/batch = 0.6680s	
12381/25300 (epoch 24.468), train_loss = 0.93022799, grad/param norm = 2.0132e-01, time/batch = 0.6696s	
12382/25300 (epoch 24.470), train_loss = 0.84186827, grad/param norm = 1.7822e-01, time/batch = 0.6702s	
12383/25300 (epoch 24.472), train_loss = 0.74307127, grad/param norm = 1.8000e-01, time/batch = 0.6685s	
12384/25300 (epoch 24.474), train_loss = 0.92276750, grad/param norm = 1.9591e-01, time/batch = 0.6648s	
12385/25300 (epoch 24.476), train_loss = 0.84889150, grad/param norm = 2.1586e-01, time/batch = 0.6597s	
12386/25300 (epoch 24.478), train_loss = 0.94583458, grad/param norm = 2.4129e-01, time/batch = 0.6615s	
12387/25300 (epoch 24.480), train_loss = 0.83256059, grad/param norm = 1.8092e-01, time/batch = 0.6571s	
12388/25300 (epoch 24.482), train_loss = 0.93841684, grad/param norm = 2.5010e-01, time/batch = 0.6566s	
12389/25300 (epoch 24.484), train_loss = 0.93287336, grad/param norm = 2.3101e-01, time/batch = 0.6558s	
12390/25300 (epoch 24.486), train_loss = 0.88002856, grad/param norm = 2.0789e-01, time/batch = 0.6615s	
12391/25300 (epoch 24.488), train_loss = 1.02963146, grad/param norm = 2.1164e-01, time/batch = 0.6600s	
12392/25300 (epoch 24.490), train_loss = 0.94693076, grad/param norm = 2.1067e-01, time/batch = 0.6617s	
12393/25300 (epoch 24.492), train_loss = 0.95652717, grad/param norm = 2.0238e-01, time/batch = 0.6580s	
12394/25300 (epoch 24.494), train_loss = 0.84463288, grad/param norm = 2.0238e-01, time/batch = 0.6607s	
12395/25300 (epoch 24.496), train_loss = 0.90366231, grad/param norm = 2.0880e-01, time/batch = 0.6661s	
12396/25300 (epoch 24.498), train_loss = 0.82100490, grad/param norm = 1.8513e-01, time/batch = 0.6703s	
12397/25300 (epoch 24.500), train_loss = 1.02470760, grad/param norm = 2.1560e-01, time/batch = 0.6724s	
12398/25300 (epoch 24.502), train_loss = 0.94361277, grad/param norm = 2.3035e-01, time/batch = 0.6618s	
12399/25300 (epoch 24.504), train_loss = 0.86281626, grad/param norm = 1.9461e-01, time/batch = 0.6759s	
12400/25300 (epoch 24.506), train_loss = 0.78485544, grad/param norm = 2.0549e-01, time/batch = 0.6705s	
12401/25300 (epoch 24.508), train_loss = 0.87007329, grad/param norm = 2.0591e-01, time/batch = 0.6636s	
12402/25300 (epoch 24.510), train_loss = 0.81551035, grad/param norm = 2.1151e-01, time/batch = 0.6686s	
12403/25300 (epoch 24.512), train_loss = 0.65344942, grad/param norm = 1.6646e-01, time/batch = 0.6687s	
12404/25300 (epoch 24.514), train_loss = 0.86701529, grad/param norm = 2.0648e-01, time/batch = 0.6604s	
12405/25300 (epoch 24.516), train_loss = 0.92748187, grad/param norm = 2.0028e-01, time/batch = 0.6644s	
12406/25300 (epoch 24.518), train_loss = 0.96689296, grad/param norm = 2.1329e-01, time/batch = 0.6629s	
12407/25300 (epoch 24.520), train_loss = 0.72211790, grad/param norm = 1.5870e-01, time/batch = 0.6567s	
12408/25300 (epoch 24.522), train_loss = 0.82086183, grad/param norm = 2.0798e-01, time/batch = 0.6634s	
12409/25300 (epoch 24.524), train_loss = 0.81596313, grad/param norm = 1.9506e-01, time/batch = 0.6629s	
12410/25300 (epoch 24.526), train_loss = 1.02421923, grad/param norm = 2.1447e-01, time/batch = 0.6658s	
12411/25300 (epoch 24.528), train_loss = 1.02968171, grad/param norm = 2.1419e-01, time/batch = 0.6639s	
12412/25300 (epoch 24.530), train_loss = 0.89319791, grad/param norm = 1.9450e-01, time/batch = 0.6622s	
12413/25300 (epoch 24.532), train_loss = 0.87195694, grad/param norm = 2.0140e-01, time/batch = 0.6601s	
12414/25300 (epoch 24.534), train_loss = 0.87903377, grad/param norm = 2.0738e-01, time/batch = 0.6591s	
12415/25300 (epoch 24.536), train_loss = 0.69854683, grad/param norm = 1.8542e-01, time/batch = 0.6596s	
12416/25300 (epoch 24.538), train_loss = 0.76957376, grad/param norm = 1.7078e-01, time/batch = 0.6683s	
12417/25300 (epoch 24.540), train_loss = 0.81433807, grad/param norm = 1.9526e-01, time/batch = 0.6589s	
12418/25300 (epoch 24.542), train_loss = 0.77659836, grad/param norm = 1.7574e-01, time/batch = 0.6661s	
12419/25300 (epoch 24.543), train_loss = 0.73919512, grad/param norm = 1.7306e-01, time/batch = 0.6596s	
12420/25300 (epoch 24.545), train_loss = 1.09849706, grad/param norm = 2.7138e-01, time/batch = 0.6619s	
12421/25300 (epoch 24.547), train_loss = 0.95752614, grad/param norm = 2.1135e-01, time/batch = 0.6557s	
12422/25300 (epoch 24.549), train_loss = 1.12738858, grad/param norm = 2.6720e-01, time/batch = 0.6631s	
12423/25300 (epoch 24.551), train_loss = 0.96195883, grad/param norm = 1.9643e-01, time/batch = 0.6594s	
12424/25300 (epoch 24.553), train_loss = 0.81509475, grad/param norm = 2.0401e-01, time/batch = 0.6570s	
12425/25300 (epoch 24.555), train_loss = 0.97350521, grad/param norm = 2.1273e-01, time/batch = 0.6563s	
12426/25300 (epoch 24.557), train_loss = 1.01749413, grad/param norm = 2.3917e-01, time/batch = 0.6602s	
12427/25300 (epoch 24.559), train_loss = 0.99798023, grad/param norm = 2.2451e-01, time/batch = 0.6583s	
12428/25300 (epoch 24.561), train_loss = 1.01451442, grad/param norm = 2.0683e-01, time/batch = 0.6578s	
12429/25300 (epoch 24.563), train_loss = 0.97240674, grad/param norm = 2.1517e-01, time/batch = 0.6599s	
12430/25300 (epoch 24.565), train_loss = 0.76360680, grad/param norm = 1.8627e-01, time/batch = 0.6573s	
12431/25300 (epoch 24.567), train_loss = 0.69020139, grad/param norm = 1.7723e-01, time/batch = 0.6592s	
12432/25300 (epoch 24.569), train_loss = 0.88394821, grad/param norm = 2.0368e-01, time/batch = 0.6626s	
12433/25300 (epoch 24.571), train_loss = 0.97773393, grad/param norm = 2.2222e-01, time/batch = 0.6586s	
12434/25300 (epoch 24.573), train_loss = 0.86741578, grad/param norm = 2.0406e-01, time/batch = 0.6653s	
12435/25300 (epoch 24.575), train_loss = 1.01380483, grad/param norm = 2.0208e-01, time/batch = 0.6605s	
12436/25300 (epoch 24.577), train_loss = 0.88496803, grad/param norm = 2.2175e-01, time/batch = 0.6622s	
12437/25300 (epoch 24.579), train_loss = 1.01712756, grad/param norm = 2.2502e-01, time/batch = 0.6589s	
12438/25300 (epoch 24.581), train_loss = 0.96767963, grad/param norm = 2.2086e-01, time/batch = 0.6572s	
12439/25300 (epoch 24.583), train_loss = 0.75865447, grad/param norm = 2.1799e-01, time/batch = 0.6611s	
12440/25300 (epoch 24.585), train_loss = 0.75122623, grad/param norm = 2.1273e-01, time/batch = 0.6550s	
12441/25300 (epoch 24.587), train_loss = 0.86504612, grad/param norm = 1.8295e-01, time/batch = 0.6652s	
12442/25300 (epoch 24.589), train_loss = 0.75752685, grad/param norm = 1.7279e-01, time/batch = 0.6609s	
12443/25300 (epoch 24.591), train_loss = 0.77512789, grad/param norm = 2.2425e-01, time/batch = 0.6587s	
12444/25300 (epoch 24.593), train_loss = 0.94867275, grad/param norm = 1.9869e-01, time/batch = 0.6594s	
12445/25300 (epoch 24.595), train_loss = 0.87961889, grad/param norm = 2.0399e-01, time/batch = 0.6568s	
12446/25300 (epoch 24.597), train_loss = 0.77925997, grad/param norm = 1.8810e-01, time/batch = 0.6598s	
12447/25300 (epoch 24.599), train_loss = 0.92129961, grad/param norm = 2.0934e-01, time/batch = 0.6598s	
12448/25300 (epoch 24.601), train_loss = 0.88659983, grad/param norm = 2.5074e-01, time/batch = 0.6565s	
12449/25300 (epoch 24.603), train_loss = 0.88567432, grad/param norm = 2.2413e-01, time/batch = 0.6636s	
12450/25300 (epoch 24.605), train_loss = 0.81115749, grad/param norm = 2.1409e-01, time/batch = 0.6597s	
12451/25300 (epoch 24.607), train_loss = 0.65703591, grad/param norm = 1.7558e-01, time/batch = 0.6643s	
12452/25300 (epoch 24.609), train_loss = 0.84134983, grad/param norm = 1.8822e-01, time/batch = 0.6591s	
12453/25300 (epoch 24.611), train_loss = 0.90342308, grad/param norm = 2.1358e-01, time/batch = 0.6576s	
12454/25300 (epoch 24.613), train_loss = 0.75027217, grad/param norm = 1.7316e-01, time/batch = 0.6637s	
12455/25300 (epoch 24.615), train_loss = 0.86911335, grad/param norm = 2.2044e-01, time/batch = 0.6587s	
12456/25300 (epoch 24.617), train_loss = 0.88431948, grad/param norm = 2.0672e-01, time/batch = 0.6624s	
12457/25300 (epoch 24.619), train_loss = 0.95038532, grad/param norm = 2.0761e-01, time/batch = 0.6602s	
12458/25300 (epoch 24.621), train_loss = 0.98155992, grad/param norm = 2.4152e-01, time/batch = 0.6639s	
12459/25300 (epoch 24.623), train_loss = 0.81619575, grad/param norm = 1.9675e-01, time/batch = 0.6599s	
12460/25300 (epoch 24.625), train_loss = 0.71182266, grad/param norm = 1.8034e-01, time/batch = 0.6565s	
12461/25300 (epoch 24.626), train_loss = 0.86226233, grad/param norm = 1.9076e-01, time/batch = 0.6629s	
12462/25300 (epoch 24.628), train_loss = 0.95441956, grad/param norm = 2.3965e-01, time/batch = 0.6623s	
12463/25300 (epoch 24.630), train_loss = 0.94271907, grad/param norm = 2.3105e-01, time/batch = 0.6590s	
12464/25300 (epoch 24.632), train_loss = 0.90562604, grad/param norm = 2.7827e-01, time/batch = 0.6575s	
12465/25300 (epoch 24.634), train_loss = 1.02626762, grad/param norm = 2.6838e-01, time/batch = 0.6603s	
12466/25300 (epoch 24.636), train_loss = 0.79424180, grad/param norm = 1.7767e-01, time/batch = 0.6558s	
12467/25300 (epoch 24.638), train_loss = 0.92042510, grad/param norm = 2.2389e-01, time/batch = 0.6627s	
12468/25300 (epoch 24.640), train_loss = 1.07853102, grad/param norm = 2.6362e-01, time/batch = 0.6567s	
12469/25300 (epoch 24.642), train_loss = 0.92221172, grad/param norm = 2.1266e-01, time/batch = 0.6594s	
12470/25300 (epoch 24.644), train_loss = 0.91377718, grad/param norm = 2.1808e-01, time/batch = 0.6594s	
12471/25300 (epoch 24.646), train_loss = 0.84185262, grad/param norm = 2.2131e-01, time/batch = 0.6642s	
12472/25300 (epoch 24.648), train_loss = 0.96984302, grad/param norm = 1.9842e-01, time/batch = 0.6583s	
12473/25300 (epoch 24.650), train_loss = 0.92837553, grad/param norm = 2.3474e-01, time/batch = 0.6593s	
12474/25300 (epoch 24.652), train_loss = 0.91383826, grad/param norm = 2.0746e-01, time/batch = 0.6580s	
12475/25300 (epoch 24.654), train_loss = 1.02667858, grad/param norm = 2.0582e-01, time/batch = 0.6545s	
12476/25300 (epoch 24.656), train_loss = 0.95555592, grad/param norm = 2.3444e-01, time/batch = 0.6614s	
12477/25300 (epoch 24.658), train_loss = 0.73640961, grad/param norm = 1.6177e-01, time/batch = 0.6555s	
12478/25300 (epoch 24.660), train_loss = 0.77502290, grad/param norm = 2.1746e-01, time/batch = 0.6604s	
12479/25300 (epoch 24.662), train_loss = 0.76417278, grad/param norm = 2.0527e-01, time/batch = 0.6600s	
12480/25300 (epoch 24.664), train_loss = 0.72881004, grad/param norm = 1.8687e-01, time/batch = 0.6750s	
12481/25300 (epoch 24.666), train_loss = 0.78187626, grad/param norm = 1.9165e-01, time/batch = 0.6591s	
12482/25300 (epoch 24.668), train_loss = 0.85484770, grad/param norm = 2.2188e-01, time/batch = 0.6585s	
12483/25300 (epoch 24.670), train_loss = 0.79879297, grad/param norm = 2.2330e-01, time/batch = 0.6562s	
12484/25300 (epoch 24.672), train_loss = 0.76662373, grad/param norm = 1.7661e-01, time/batch = 0.6643s	
12485/25300 (epoch 24.674), train_loss = 0.81326042, grad/param norm = 1.8341e-01, time/batch = 0.6683s	
12486/25300 (epoch 24.676), train_loss = 0.83038510, grad/param norm = 2.1361e-01, time/batch = 0.9501s	
12487/25300 (epoch 24.678), train_loss = 0.82792366, grad/param norm = 2.0589e-01, time/batch = 1.1467s	
12488/25300 (epoch 24.680), train_loss = 0.71099416, grad/param norm = 1.7280e-01, time/batch = 0.6715s	
12489/25300 (epoch 24.682), train_loss = 0.61976116, grad/param norm = 1.8046e-01, time/batch = 0.6667s	
12490/25300 (epoch 24.684), train_loss = 0.77727348, grad/param norm = 1.7273e-01, time/batch = 0.6653s	
12491/25300 (epoch 24.686), train_loss = 0.73309693, grad/param norm = 1.6685e-01, time/batch = 0.6724s	
12492/25300 (epoch 24.688), train_loss = 0.85164422, grad/param norm = 2.2351e-01, time/batch = 0.7144s	
12493/25300 (epoch 24.690), train_loss = 0.74715697, grad/param norm = 1.7431e-01, time/batch = 0.7272s	
12494/25300 (epoch 24.692), train_loss = 0.77125585, grad/param norm = 1.7869e-01, time/batch = 0.6621s	
12495/25300 (epoch 24.694), train_loss = 0.79209332, grad/param norm = 1.8396e-01, time/batch = 0.6609s	
12496/25300 (epoch 24.696), train_loss = 0.90766197, grad/param norm = 2.2820e-01, time/batch = 0.6579s	
12497/25300 (epoch 24.698), train_loss = 0.90846635, grad/param norm = 1.9767e-01, time/batch = 0.6599s	
12498/25300 (epoch 24.700), train_loss = 0.68074618, grad/param norm = 1.8397e-01, time/batch = 0.6792s	
12499/25300 (epoch 24.702), train_loss = 0.95138420, grad/param norm = 2.2857e-01, time/batch = 0.6725s	
12500/25300 (epoch 24.704), train_loss = 0.69515996, grad/param norm = 1.9370e-01, time/batch = 0.6670s	
12501/25300 (epoch 24.706), train_loss = 0.84301175, grad/param norm = 2.1054e-01, time/batch = 0.6682s	
12502/25300 (epoch 24.708), train_loss = 0.70823388, grad/param norm = 1.6335e-01, time/batch = 0.6619s	
12503/25300 (epoch 24.709), train_loss = 1.01804460, grad/param norm = 2.2449e-01, time/batch = 0.6630s	
12504/25300 (epoch 24.711), train_loss = 1.03993797, grad/param norm = 2.4096e-01, time/batch = 0.6675s	
12505/25300 (epoch 24.713), train_loss = 0.84194792, grad/param norm = 1.7162e-01, time/batch = 0.6619s	
12506/25300 (epoch 24.715), train_loss = 0.83640606, grad/param norm = 1.8248e-01, time/batch = 0.6603s	
12507/25300 (epoch 24.717), train_loss = 0.79445495, grad/param norm = 2.0541e-01, time/batch = 0.6527s	
12508/25300 (epoch 24.719), train_loss = 0.85778689, grad/param norm = 2.0282e-01, time/batch = 0.6613s	
12509/25300 (epoch 24.721), train_loss = 0.90264151, grad/param norm = 2.1664e-01, time/batch = 0.6571s	
12510/25300 (epoch 24.723), train_loss = 0.82698495, grad/param norm = 1.8864e-01, time/batch = 0.6619s	
12511/25300 (epoch 24.725), train_loss = 0.89468858, grad/param norm = 2.0062e-01, time/batch = 0.6554s	
12512/25300 (epoch 24.727), train_loss = 0.86874385, grad/param norm = 2.1621e-01, time/batch = 0.6620s	
12513/25300 (epoch 24.729), train_loss = 0.87126310, grad/param norm = 2.1367e-01, time/batch = 0.6718s	
12514/25300 (epoch 24.731), train_loss = 1.02163290, grad/param norm = 2.0751e-01, time/batch = 0.6668s	
12515/25300 (epoch 24.733), train_loss = 0.84610653, grad/param norm = 1.7983e-01, time/batch = 0.6723s	
12516/25300 (epoch 24.735), train_loss = 1.13228673, grad/param norm = 2.2791e-01, time/batch = 0.6753s	
12517/25300 (epoch 24.737), train_loss = 0.76216872, grad/param norm = 1.7519e-01, time/batch = 0.6659s	
12518/25300 (epoch 24.739), train_loss = 0.99760397, grad/param norm = 2.0066e-01, time/batch = 0.6651s	
12519/25300 (epoch 24.741), train_loss = 0.93444039, grad/param norm = 2.2452e-01, time/batch = 0.6659s	
12520/25300 (epoch 24.743), train_loss = 0.86422171, grad/param norm = 2.0104e-01, time/batch = 0.6687s	
12521/25300 (epoch 24.745), train_loss = 0.81178822, grad/param norm = 1.9383e-01, time/batch = 0.6746s	
12522/25300 (epoch 24.747), train_loss = 0.78721029, grad/param norm = 1.9049e-01, time/batch = 0.6664s	
12523/25300 (epoch 24.749), train_loss = 0.88553951, grad/param norm = 2.0211e-01, time/batch = 0.6649s	
12524/25300 (epoch 24.751), train_loss = 0.93514543, grad/param norm = 2.0336e-01, time/batch = 0.6662s	
12525/25300 (epoch 24.753), train_loss = 0.77402698, grad/param norm = 1.9589e-01, time/batch = 0.6678s	
12526/25300 (epoch 24.755), train_loss = 0.97312216, grad/param norm = 2.2383e-01, time/batch = 0.6682s	
12527/25300 (epoch 24.757), train_loss = 0.82373754, grad/param norm = 2.3272e-01, time/batch = 0.6689s	
12528/25300 (epoch 24.759), train_loss = 0.79272901, grad/param norm = 2.0693e-01, time/batch = 0.6715s	
12529/25300 (epoch 24.761), train_loss = 1.00767941, grad/param norm = 1.9874e-01, time/batch = 0.6677s	
12530/25300 (epoch 24.763), train_loss = 0.82427319, grad/param norm = 1.9692e-01, time/batch = 0.6661s	
12531/25300 (epoch 24.765), train_loss = 0.84751983, grad/param norm = 1.9616e-01, time/batch = 0.6697s	
12532/25300 (epoch 24.767), train_loss = 0.83182615, grad/param norm = 1.9447e-01, time/batch = 0.6736s	
12533/25300 (epoch 24.769), train_loss = 0.87465272, grad/param norm = 1.9929e-01, time/batch = 0.6700s	
12534/25300 (epoch 24.771), train_loss = 0.98133963, grad/param norm = 2.3361e-01, time/batch = 0.6685s	
12535/25300 (epoch 24.773), train_loss = 1.00946730, grad/param norm = 2.5607e-01, time/batch = 0.6723s	
12536/25300 (epoch 24.775), train_loss = 0.85799199, grad/param norm = 1.7665e-01, time/batch = 0.6701s	
12537/25300 (epoch 24.777), train_loss = 0.85706281, grad/param norm = 2.0284e-01, time/batch = 0.6671s	
12538/25300 (epoch 24.779), train_loss = 0.94515763, grad/param norm = 1.8341e-01, time/batch = 0.6636s	
12539/25300 (epoch 24.781), train_loss = 0.91874753, grad/param norm = 1.9697e-01, time/batch = 0.6633s	
12540/25300 (epoch 24.783), train_loss = 1.00860791, grad/param norm = 2.2110e-01, time/batch = 0.6663s	
12541/25300 (epoch 24.785), train_loss = 0.94512015, grad/param norm = 1.9752e-01, time/batch = 0.6690s	
12542/25300 (epoch 24.787), train_loss = 0.93704107, grad/param norm = 2.3921e-01, time/batch = 0.6700s	
12543/25300 (epoch 24.789), train_loss = 1.07745334, grad/param norm = 2.2515e-01, time/batch = 0.6696s	
12544/25300 (epoch 24.791), train_loss = 0.94241428, grad/param norm = 2.2028e-01, time/batch = 0.6642s	
12545/25300 (epoch 24.792), train_loss = 0.99648336, grad/param norm = 2.1277e-01, time/batch = 0.6654s	
12546/25300 (epoch 24.794), train_loss = 0.89467461, grad/param norm = 2.3122e-01, time/batch = 0.6731s	
12547/25300 (epoch 24.796), train_loss = 0.84265298, grad/param norm = 2.1346e-01, time/batch = 0.6716s	
12548/25300 (epoch 24.798), train_loss = 0.98112981, grad/param norm = 2.1959e-01, time/batch = 0.6698s	
12549/25300 (epoch 24.800), train_loss = 0.83705282, grad/param norm = 1.7700e-01, time/batch = 0.6690s	
12550/25300 (epoch 24.802), train_loss = 0.71531142, grad/param norm = 2.0214e-01, time/batch = 0.6681s	
12551/25300 (epoch 24.804), train_loss = 0.88172608, grad/param norm = 1.9617e-01, time/batch = 0.6681s	
12552/25300 (epoch 24.806), train_loss = 0.96395823, grad/param norm = 2.4345e-01, time/batch = 0.6636s	
12553/25300 (epoch 24.808), train_loss = 0.98184008, grad/param norm = 2.0951e-01, time/batch = 0.6611s	
12554/25300 (epoch 24.810), train_loss = 0.85023137, grad/param norm = 1.9819e-01, time/batch = 0.6638s	
12555/25300 (epoch 24.812), train_loss = 0.96984363, grad/param norm = 1.9135e-01, time/batch = 0.6615s	
12556/25300 (epoch 24.814), train_loss = 1.02900801, grad/param norm = 2.2614e-01, time/batch = 0.6707s	
12557/25300 (epoch 24.816), train_loss = 1.11732550, grad/param norm = 2.6264e-01, time/batch = 0.6653s	
12558/25300 (epoch 24.818), train_loss = 0.94718691, grad/param norm = 1.9549e-01, time/batch = 0.6663s	
12559/25300 (epoch 24.820), train_loss = 0.98048352, grad/param norm = 2.2002e-01, time/batch = 0.6687s	
12560/25300 (epoch 24.822), train_loss = 0.85126297, grad/param norm = 2.0398e-01, time/batch = 0.6711s	
12561/25300 (epoch 24.824), train_loss = 1.00321375, grad/param norm = 2.3257e-01, time/batch = 0.6702s	
12562/25300 (epoch 24.826), train_loss = 0.80825193, grad/param norm = 1.8550e-01, time/batch = 0.6712s	
12563/25300 (epoch 24.828), train_loss = 0.83168874, grad/param norm = 2.4884e-01, time/batch = 0.6717s	
12564/25300 (epoch 24.830), train_loss = 0.92797438, grad/param norm = 2.2199e-01, time/batch = 0.6653s	
12565/25300 (epoch 24.832), train_loss = 0.95935893, grad/param norm = 2.0311e-01, time/batch = 0.6673s	
12566/25300 (epoch 24.834), train_loss = 0.79709430, grad/param norm = 1.8377e-01, time/batch = 0.6721s	
12567/25300 (epoch 24.836), train_loss = 0.86511682, grad/param norm = 1.9242e-01, time/batch = 0.6738s	
12568/25300 (epoch 24.838), train_loss = 0.88195700, grad/param norm = 2.2411e-01, time/batch = 0.6723s	
12569/25300 (epoch 24.840), train_loss = 0.99304109, grad/param norm = 2.0568e-01, time/batch = 0.6699s	
12570/25300 (epoch 24.842), train_loss = 0.92543869, grad/param norm = 2.3860e-01, time/batch = 0.6688s	
12571/25300 (epoch 24.844), train_loss = 0.97026722, grad/param norm = 1.8988e-01, time/batch = 0.6675s	
12572/25300 (epoch 24.846), train_loss = 0.96304512, grad/param norm = 1.8886e-01, time/batch = 0.6718s	
12573/25300 (epoch 24.848), train_loss = 0.98230681, grad/param norm = 2.1817e-01, time/batch = 0.6659s	
12574/25300 (epoch 24.850), train_loss = 0.94173749, grad/param norm = 2.0568e-01, time/batch = 0.6680s	
12575/25300 (epoch 24.852), train_loss = 0.96262453, grad/param norm = 1.9872e-01, time/batch = 0.6718s	
12576/25300 (epoch 24.854), train_loss = 1.04302870, grad/param norm = 2.0986e-01, time/batch = 0.6731s	
12577/25300 (epoch 24.856), train_loss = 0.90455939, grad/param norm = 2.1584e-01, time/batch = 0.6639s	
12578/25300 (epoch 24.858), train_loss = 0.92171127, grad/param norm = 2.1380e-01, time/batch = 0.6635s	
12579/25300 (epoch 24.860), train_loss = 0.75986117, grad/param norm = 1.8541e-01, time/batch = 0.6665s	
12580/25300 (epoch 24.862), train_loss = 0.89445862, grad/param norm = 2.5176e-01, time/batch = 0.6653s	
12581/25300 (epoch 24.864), train_loss = 0.98435959, grad/param norm = 2.2205e-01, time/batch = 0.6752s	
12582/25300 (epoch 24.866), train_loss = 0.87022780, grad/param norm = 2.1284e-01, time/batch = 0.6668s	
12583/25300 (epoch 24.868), train_loss = 1.02113075, grad/param norm = 2.1040e-01, time/batch = 0.6669s	
12584/25300 (epoch 24.870), train_loss = 0.99571260, grad/param norm = 1.9248e-01, time/batch = 0.6660s	
12585/25300 (epoch 24.872), train_loss = 0.96332599, grad/param norm = 2.3057e-01, time/batch = 0.6663s	
12586/25300 (epoch 24.874), train_loss = 0.93649397, grad/param norm = 1.9932e-01, time/batch = 0.6664s	
12587/25300 (epoch 24.875), train_loss = 0.89079621, grad/param norm = 2.1777e-01, time/batch = 0.6663s	
12588/25300 (epoch 24.877), train_loss = 0.88552360, grad/param norm = 2.0101e-01, time/batch = 0.6682s	
12589/25300 (epoch 24.879), train_loss = 0.86646595, grad/param norm = 2.1733e-01, time/batch = 0.6672s	
12590/25300 (epoch 24.881), train_loss = 1.18634405, grad/param norm = 2.5404e-01, time/batch = 0.6686s	
12591/25300 (epoch 24.883), train_loss = 1.13120314, grad/param norm = 2.2501e-01, time/batch = 0.6703s	
12592/25300 (epoch 24.885), train_loss = 0.97432599, grad/param norm = 2.3215e-01, time/batch = 0.6687s	
12593/25300 (epoch 24.887), train_loss = 0.98544428, grad/param norm = 2.0428e-01, time/batch = 0.6665s	
12594/25300 (epoch 24.889), train_loss = 1.07329494, grad/param norm = 2.2441e-01, time/batch = 0.6698s	
12595/25300 (epoch 24.891), train_loss = 0.94255557, grad/param norm = 2.5324e-01, time/batch = 0.6720s	
12596/25300 (epoch 24.893), train_loss = 0.95778550, grad/param norm = 2.5909e-01, time/batch = 0.6690s	
12597/25300 (epoch 24.895), train_loss = 0.70196297, grad/param norm = 1.8896e-01, time/batch = 0.6669s	
12598/25300 (epoch 24.897), train_loss = 0.81532717, grad/param norm = 1.8755e-01, time/batch = 0.6711s	
12599/25300 (epoch 24.899), train_loss = 0.94852645, grad/param norm = 2.2267e-01, time/batch = 0.6654s	
12600/25300 (epoch 24.901), train_loss = 0.97302944, grad/param norm = 2.1024e-01, time/batch = 0.6662s	
12601/25300 (epoch 24.903), train_loss = 0.74219077, grad/param norm = 2.0980e-01, time/batch = 0.6664s	
12602/25300 (epoch 24.905), train_loss = 0.85243580, grad/param norm = 2.4760e-01, time/batch = 0.6645s	
12603/25300 (epoch 24.907), train_loss = 0.86130775, grad/param norm = 2.4672e-01, time/batch = 0.6664s	
12604/25300 (epoch 24.909), train_loss = 0.97338915, grad/param norm = 2.0254e-01, time/batch = 0.6693s	
12605/25300 (epoch 24.911), train_loss = 1.02949645, grad/param norm = 2.3380e-01, time/batch = 0.6680s	
12606/25300 (epoch 24.913), train_loss = 1.10616188, grad/param norm = 2.4712e-01, time/batch = 0.6681s	
12607/25300 (epoch 24.915), train_loss = 0.85393203, grad/param norm = 2.1400e-01, time/batch = 0.6667s	
12608/25300 (epoch 24.917), train_loss = 1.03426449, grad/param norm = 2.3285e-01, time/batch = 0.6673s	
12609/25300 (epoch 24.919), train_loss = 1.04799435, grad/param norm = 2.3333e-01, time/batch = 0.6665s	
12610/25300 (epoch 24.921), train_loss = 0.84494715, grad/param norm = 1.8881e-01, time/batch = 0.6684s	
12611/25300 (epoch 24.923), train_loss = 1.03326180, grad/param norm = 2.0852e-01, time/batch = 0.6705s	
12612/25300 (epoch 24.925), train_loss = 0.90762511, grad/param norm = 2.1161e-01, time/batch = 0.6689s	
12613/25300 (epoch 24.927), train_loss = 0.89041960, grad/param norm = 2.0467e-01, time/batch = 0.6652s	
12614/25300 (epoch 24.929), train_loss = 0.95232543, grad/param norm = 2.1907e-01, time/batch = 0.6648s	
12615/25300 (epoch 24.931), train_loss = 0.98399613, grad/param norm = 2.4894e-01, time/batch = 0.6633s	
12616/25300 (epoch 24.933), train_loss = 0.93723393, grad/param norm = 2.0535e-01, time/batch = 0.6648s	
12617/25300 (epoch 24.935), train_loss = 0.92967659, grad/param norm = 1.8291e-01, time/batch = 0.6641s	
12618/25300 (epoch 24.937), train_loss = 0.70719066, grad/param norm = 1.9265e-01, time/batch = 0.6610s	
12619/25300 (epoch 24.939), train_loss = 0.94623104, grad/param norm = 1.8924e-01, time/batch = 0.6671s	
12620/25300 (epoch 24.941), train_loss = 0.81484721, grad/param norm = 1.8449e-01, time/batch = 0.6666s	
12621/25300 (epoch 24.943), train_loss = 0.94311923, grad/param norm = 1.9413e-01, time/batch = 0.6694s	
12622/25300 (epoch 24.945), train_loss = 0.96118345, grad/param norm = 2.1728e-01, time/batch = 0.6732s	
12623/25300 (epoch 24.947), train_loss = 0.81900729, grad/param norm = 1.8914e-01, time/batch = 0.6666s	
12624/25300 (epoch 24.949), train_loss = 0.96958207, grad/param norm = 1.9696e-01, time/batch = 0.6681s	
12625/25300 (epoch 24.951), train_loss = 0.91073674, grad/param norm = 1.8548e-01, time/batch = 0.6694s	
12626/25300 (epoch 24.953), train_loss = 0.90520935, grad/param norm = 2.0739e-01, time/batch = 0.6750s	
12627/25300 (epoch 24.955), train_loss = 1.11163052, grad/param norm = 2.3689e-01, time/batch = 0.6700s	
12628/25300 (epoch 24.957), train_loss = 1.04925221, grad/param norm = 2.3671e-01, time/batch = 0.6678s	
12629/25300 (epoch 24.958), train_loss = 0.99856489, grad/param norm = 2.3551e-01, time/batch = 0.6716s	
12630/25300 (epoch 24.960), train_loss = 1.11420452, grad/param norm = 2.3447e-01, time/batch = 0.6718s	
12631/25300 (epoch 24.962), train_loss = 1.07267016, grad/param norm = 2.2283e-01, time/batch = 0.6691s	
12632/25300 (epoch 24.964), train_loss = 0.97462753, grad/param norm = 2.3581e-01, time/batch = 0.6695s	
12633/25300 (epoch 24.966), train_loss = 0.79730520, grad/param norm = 1.8918e-01, time/batch = 0.6671s	
12634/25300 (epoch 24.968), train_loss = 0.74966122, grad/param norm = 1.7092e-01, time/batch = 0.6666s	
12635/25300 (epoch 24.970), train_loss = 0.88558791, grad/param norm = 2.4406e-01, time/batch = 0.6686s	
12636/25300 (epoch 24.972), train_loss = 0.91927709, grad/param norm = 1.9167e-01, time/batch = 0.6670s	
12637/25300 (epoch 24.974), train_loss = 1.05921642, grad/param norm = 2.5269e-01, time/batch = 0.6654s	
12638/25300 (epoch 24.976), train_loss = 0.97817045, grad/param norm = 2.2434e-01, time/batch = 0.6656s	
12639/25300 (epoch 24.978), train_loss = 0.91888447, grad/param norm = 2.1853e-01, time/batch = 0.6665s	
12640/25300 (epoch 24.980), train_loss = 0.92948129, grad/param norm = 2.2257e-01, time/batch = 0.6674s	
12641/25300 (epoch 24.982), train_loss = 0.86428072, grad/param norm = 1.9707e-01, time/batch = 0.6728s	
12642/25300 (epoch 24.984), train_loss = 0.91043839, grad/param norm = 2.1669e-01, time/batch = 0.6690s	
12643/25300 (epoch 24.986), train_loss = 1.00525398, grad/param norm = 1.9856e-01, time/batch = 0.6675s	
12644/25300 (epoch 24.988), train_loss = 0.97011388, grad/param norm = 2.3759e-01, time/batch = 0.6650s	
12645/25300 (epoch 24.990), train_loss = 0.91517859, grad/param norm = 1.9386e-01, time/batch = 0.6656s	
12646/25300 (epoch 24.992), train_loss = 0.79410026, grad/param norm = 1.7705e-01, time/batch = 0.6684s	
12647/25300 (epoch 24.994), train_loss = 0.94259844, grad/param norm = 2.4855e-01, time/batch = 0.6681s	
12648/25300 (epoch 24.996), train_loss = 1.07435005, grad/param norm = 2.9480e-01, time/batch = 0.6649s	
12649/25300 (epoch 24.998), train_loss = 1.03747158, grad/param norm = 2.3526e-01, time/batch = 0.6642s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
12650/25300 (epoch 25.000), train_loss = 0.94599884, grad/param norm = 2.1399e-01, time/batch = 0.6645s	
12651/25300 (epoch 25.002), train_loss = 0.85412840, grad/param norm = 1.7793e-01, time/batch = 0.6658s	
12652/25300 (epoch 25.004), train_loss = 0.77213372, grad/param norm = 1.9133e-01, time/batch = 0.6600s	
12653/25300 (epoch 25.006), train_loss = 1.05690409, grad/param norm = 1.9727e-01, time/batch = 0.6617s	
12654/25300 (epoch 25.008), train_loss = 0.89588494, grad/param norm = 1.7317e-01, time/batch = 0.6650s	
12655/25300 (epoch 25.010), train_loss = 0.94030769, grad/param norm = 2.1856e-01, time/batch = 0.6630s	
12656/25300 (epoch 25.012), train_loss = 0.88929053, grad/param norm = 2.1094e-01, time/batch = 0.6652s	
12657/25300 (epoch 25.014), train_loss = 1.05639560, grad/param norm = 2.1581e-01, time/batch = 0.6638s	
12658/25300 (epoch 25.016), train_loss = 0.92163787, grad/param norm = 2.0600e-01, time/batch = 0.6673s	
12659/25300 (epoch 25.018), train_loss = 0.81256335, grad/param norm = 1.8895e-01, time/batch = 0.6665s	
12660/25300 (epoch 25.020), train_loss = 0.90956929, grad/param norm = 1.9140e-01, time/batch = 0.6658s	
12661/25300 (epoch 25.022), train_loss = 0.91940316, grad/param norm = 2.1847e-01, time/batch = 0.6689s	
12662/25300 (epoch 25.024), train_loss = 0.68328901, grad/param norm = 1.4893e-01, time/batch = 0.6667s	
12663/25300 (epoch 25.026), train_loss = 0.86484139, grad/param norm = 2.0640e-01, time/batch = 0.6689s	
12664/25300 (epoch 25.028), train_loss = 0.83693484, grad/param norm = 1.8278e-01, time/batch = 0.6739s	
12665/25300 (epoch 25.030), train_loss = 1.00476574, grad/param norm = 1.8563e-01, time/batch = 0.6765s	
12666/25300 (epoch 25.032), train_loss = 0.85679829, grad/param norm = 1.9049e-01, time/batch = 0.6736s	
12667/25300 (epoch 25.034), train_loss = 0.78033807, grad/param norm = 1.8999e-01, time/batch = 0.6714s	
12668/25300 (epoch 25.036), train_loss = 0.76394311, grad/param norm = 1.8755e-01, time/batch = 0.6704s	
12669/25300 (epoch 25.038), train_loss = 0.69868355, grad/param norm = 1.6553e-01, time/batch = 0.6687s	
12670/25300 (epoch 25.040), train_loss = 0.91022888, grad/param norm = 2.0449e-01, time/batch = 0.6715s	
12671/25300 (epoch 25.042), train_loss = 0.87900454, grad/param norm = 1.7914e-01, time/batch = 0.6711s	
12672/25300 (epoch 25.043), train_loss = 0.77045039, grad/param norm = 1.7818e-01, time/batch = 0.6684s	
12673/25300 (epoch 25.045), train_loss = 0.75643570, grad/param norm = 1.7127e-01, time/batch = 0.6641s	
12674/25300 (epoch 25.047), train_loss = 0.95637133, grad/param norm = 2.0250e-01, time/batch = 0.6637s	
12675/25300 (epoch 25.049), train_loss = 0.92420657, grad/param norm = 2.1468e-01, time/batch = 0.6673s	
12676/25300 (epoch 25.051), train_loss = 1.00719854, grad/param norm = 2.2211e-01, time/batch = 0.6687s	
12677/25300 (epoch 25.053), train_loss = 0.72968760, grad/param norm = 1.7503e-01, time/batch = 0.6649s	
12678/25300 (epoch 25.055), train_loss = 0.76974891, grad/param norm = 1.8369e-01, time/batch = 0.6670s	
12679/25300 (epoch 25.057), train_loss = 0.74909251, grad/param norm = 1.6650e-01, time/batch = 0.6717s	
12680/25300 (epoch 25.059), train_loss = 0.83810149, grad/param norm = 1.9632e-01, time/batch = 0.6634s	
12681/25300 (epoch 25.061), train_loss = 0.82320973, grad/param norm = 1.9208e-01, time/batch = 0.6643s	
12682/25300 (epoch 25.063), train_loss = 0.80965952, grad/param norm = 1.7759e-01, time/batch = 0.6686s	
12683/25300 (epoch 25.065), train_loss = 0.91454855, grad/param norm = 2.1108e-01, time/batch = 0.6609s	
12684/25300 (epoch 25.067), train_loss = 0.98240756, grad/param norm = 1.9895e-01, time/batch = 0.6640s	
12685/25300 (epoch 25.069), train_loss = 0.81648268, grad/param norm = 2.0557e-01, time/batch = 0.6637s	
12686/25300 (epoch 25.071), train_loss = 0.98304492, grad/param norm = 2.3925e-01, time/batch = 0.6621s	
12687/25300 (epoch 25.073), train_loss = 0.84907579, grad/param norm = 1.7093e-01, time/batch = 0.6602s	
12688/25300 (epoch 25.075), train_loss = 0.96039781, grad/param norm = 2.0100e-01, time/batch = 0.6666s	
12689/25300 (epoch 25.077), train_loss = 0.92929871, grad/param norm = 2.1328e-01, time/batch = 0.6629s	
12690/25300 (epoch 25.079), train_loss = 0.86314636, grad/param norm = 2.1197e-01, time/batch = 0.6615s	
12691/25300 (epoch 25.081), train_loss = 0.88305871, grad/param norm = 1.8898e-01, time/batch = 0.6644s	
12692/25300 (epoch 25.083), train_loss = 0.87791961, grad/param norm = 1.7986e-01, time/batch = 0.6622s	
12693/25300 (epoch 25.085), train_loss = 1.08019524, grad/param norm = 2.2990e-01, time/batch = 0.6571s	
12694/25300 (epoch 25.087), train_loss = 1.00311507, grad/param norm = 1.9714e-01, time/batch = 0.6670s	
12695/25300 (epoch 25.089), train_loss = 0.94814276, grad/param norm = 1.9004e-01, time/batch = 0.6615s	
12696/25300 (epoch 25.091), train_loss = 1.05621402, grad/param norm = 2.2502e-01, time/batch = 0.6680s	
12697/25300 (epoch 25.093), train_loss = 1.00222505, grad/param norm = 2.3673e-01, time/batch = 0.6620s	
12698/25300 (epoch 25.095), train_loss = 0.96955889, grad/param norm = 2.0953e-01, time/batch = 0.6584s	
12699/25300 (epoch 25.097), train_loss = 0.96137323, grad/param norm = 2.1875e-01, time/batch = 0.6640s	
12700/25300 (epoch 25.099), train_loss = 0.95699987, grad/param norm = 2.1996e-01, time/batch = 0.6600s	
12701/25300 (epoch 25.101), train_loss = 0.87431074, grad/param norm = 2.0950e-01, time/batch = 0.6675s	
12702/25300 (epoch 25.103), train_loss = 0.90753951, grad/param norm = 2.0133e-01, time/batch = 0.6623s	
12703/25300 (epoch 25.105), train_loss = 0.97627423, grad/param norm = 2.0399e-01, time/batch = 0.6635s	
12704/25300 (epoch 25.107), train_loss = 0.99725904, grad/param norm = 2.3494e-01, time/batch = 0.6698s	
12705/25300 (epoch 25.109), train_loss = 0.89116028, grad/param norm = 2.1152e-01, time/batch = 0.6660s	
12706/25300 (epoch 25.111), train_loss = 0.87357610, grad/param norm = 1.8779e-01, time/batch = 0.6650s	
12707/25300 (epoch 25.113), train_loss = 0.84544841, grad/param norm = 2.0326e-01, time/batch = 0.6623s	
12708/25300 (epoch 25.115), train_loss = 0.88984927, grad/param norm = 2.1128e-01, time/batch = 0.6671s	
12709/25300 (epoch 25.117), train_loss = 0.97769096, grad/param norm = 2.1530e-01, time/batch = 0.6589s	
12710/25300 (epoch 25.119), train_loss = 0.86267922, grad/param norm = 2.1557e-01, time/batch = 0.6544s	
12711/25300 (epoch 25.121), train_loss = 0.92720049, grad/param norm = 2.0780e-01, time/batch = 0.6594s	
12712/25300 (epoch 25.123), train_loss = 0.84416656, grad/param norm = 1.9494e-01, time/batch = 0.6574s	
12713/25300 (epoch 25.125), train_loss = 0.96305776, grad/param norm = 1.9092e-01, time/batch = 0.6641s	
12714/25300 (epoch 25.126), train_loss = 0.88959199, grad/param norm = 1.9482e-01, time/batch = 0.6614s	
12715/25300 (epoch 25.128), train_loss = 0.88433218, grad/param norm = 2.3981e-01, time/batch = 0.6628s	
12716/25300 (epoch 25.130), train_loss = 0.71237183, grad/param norm = 1.6296e-01, time/batch = 0.6640s	
12717/25300 (epoch 25.132), train_loss = 0.76086673, grad/param norm = 1.8883e-01, time/batch = 0.6601s	
12718/25300 (epoch 25.134), train_loss = 0.72844009, grad/param norm = 1.6219e-01, time/batch = 0.6662s	
12719/25300 (epoch 25.136), train_loss = 0.86826343, grad/param norm = 1.8670e-01, time/batch = 0.6653s	
12720/25300 (epoch 25.138), train_loss = 0.77050044, grad/param norm = 1.8874e-01, time/batch = 0.6652s	
12721/25300 (epoch 25.140), train_loss = 0.79247190, grad/param norm = 1.8013e-01, time/batch = 0.6615s	
12722/25300 (epoch 25.142), train_loss = 0.98504102, grad/param norm = 2.0059e-01, time/batch = 0.6638s	
12723/25300 (epoch 25.144), train_loss = 0.96062059, grad/param norm = 1.9553e-01, time/batch = 0.6580s	
12724/25300 (epoch 25.146), train_loss = 0.92799362, grad/param norm = 2.4171e-01, time/batch = 0.6625s	
12725/25300 (epoch 25.148), train_loss = 0.88382145, grad/param norm = 1.9238e-01, time/batch = 0.6613s	
12726/25300 (epoch 25.150), train_loss = 0.98016133, grad/param norm = 2.1433e-01, time/batch = 0.6556s	
12727/25300 (epoch 25.152), train_loss = 1.05036175, grad/param norm = 2.2691e-01, time/batch = 0.6651s	
12728/25300 (epoch 25.154), train_loss = 0.74663038, grad/param norm = 1.9200e-01, time/batch = 0.6622s	
12729/25300 (epoch 25.156), train_loss = 0.94250448, grad/param norm = 1.9483e-01, time/batch = 0.6642s	
12730/25300 (epoch 25.158), train_loss = 0.79448463, grad/param norm = 1.9129e-01, time/batch = 0.6664s	
12731/25300 (epoch 25.160), train_loss = 0.89185276, grad/param norm = 1.8506e-01, time/batch = 0.6585s	
12732/25300 (epoch 25.162), train_loss = 0.84701691, grad/param norm = 1.9335e-01, time/batch = 0.6614s	
12733/25300 (epoch 25.164), train_loss = 0.94928702, grad/param norm = 1.9702e-01, time/batch = 0.6677s	
12734/25300 (epoch 25.166), train_loss = 0.89076178, grad/param norm = 1.8860e-01, time/batch = 0.6638s	
12735/25300 (epoch 25.168), train_loss = 0.80998211, grad/param norm = 1.7163e-01, time/batch = 0.6655s	
12736/25300 (epoch 25.170), train_loss = 0.84630329, grad/param norm = 2.1060e-01, time/batch = 0.6591s	
12737/25300 (epoch 25.172), train_loss = 0.79177252, grad/param norm = 1.8913e-01, time/batch = 0.6569s	
12738/25300 (epoch 25.174), train_loss = 0.79818084, grad/param norm = 1.9019e-01, time/batch = 0.6638s	
12739/25300 (epoch 25.176), train_loss = 0.80837298, grad/param norm = 2.1605e-01, time/batch = 0.6601s	
12740/25300 (epoch 25.178), train_loss = 1.02236177, grad/param norm = 2.2442e-01, time/batch = 0.6591s	
12741/25300 (epoch 25.180), train_loss = 0.73138638, grad/param norm = 1.7439e-01, time/batch = 0.6655s	
12742/25300 (epoch 25.182), train_loss = 0.83854646, grad/param norm = 1.8586e-01, time/batch = 0.6577s	
12743/25300 (epoch 25.184), train_loss = 0.80703427, grad/param norm = 2.0721e-01, time/batch = 0.6579s	
12744/25300 (epoch 25.186), train_loss = 0.78830427, grad/param norm = 1.9342e-01, time/batch = 0.6707s	
12745/25300 (epoch 25.188), train_loss = 0.90209183, grad/param norm = 2.1195e-01, time/batch = 0.6600s	
12746/25300 (epoch 25.190), train_loss = 0.83266041, grad/param norm = 1.8892e-01, time/batch = 0.6639s	
12747/25300 (epoch 25.192), train_loss = 0.86396895, grad/param norm = 1.9793e-01, time/batch = 0.6678s	
12748/25300 (epoch 25.194), train_loss = 0.87822063, grad/param norm = 2.1459e-01, time/batch = 0.6598s	
12749/25300 (epoch 25.196), train_loss = 1.00292976, grad/param norm = 3.6357e-01, time/batch = 0.6663s	
12750/25300 (epoch 25.198), train_loss = 0.83727742, grad/param norm = 2.4942e-01, time/batch = 0.6634s	
12751/25300 (epoch 25.200), train_loss = 0.84682311, grad/param norm = 2.0257e-01, time/batch = 0.6613s	
12752/25300 (epoch 25.202), train_loss = 0.87997829, grad/param norm = 2.0159e-01, time/batch = 0.6674s	
12753/25300 (epoch 25.204), train_loss = 0.87434202, grad/param norm = 2.1269e-01, time/batch = 0.6680s	
12754/25300 (epoch 25.206), train_loss = 0.97702576, grad/param norm = 2.1434e-01, time/batch = 0.6683s	
12755/25300 (epoch 25.208), train_loss = 0.78264294, grad/param norm = 2.0425e-01, time/batch = 0.6701s	
12756/25300 (epoch 25.209), train_loss = 0.75108456, grad/param norm = 1.8078e-01, time/batch = 0.6586s	
12757/25300 (epoch 25.211), train_loss = 0.84849738, grad/param norm = 2.0606e-01, time/batch = 0.6661s	
12758/25300 (epoch 25.213), train_loss = 0.92268084, grad/param norm = 2.0965e-01, time/batch = 0.6571s	
12759/25300 (epoch 25.215), train_loss = 0.89170649, grad/param norm = 1.9883e-01, time/batch = 0.6580s	
12760/25300 (epoch 25.217), train_loss = 0.93384161, grad/param norm = 2.3896e-01, time/batch = 0.6626s	
12761/25300 (epoch 25.219), train_loss = 0.98861738, grad/param norm = 2.1808e-01, time/batch = 0.6683s	
12762/25300 (epoch 25.221), train_loss = 1.02344939, grad/param norm = 2.1712e-01, time/batch = 0.6641s	
12763/25300 (epoch 25.223), train_loss = 0.94933753, grad/param norm = 2.2545e-01, time/batch = 0.6592s	
12764/25300 (epoch 25.225), train_loss = 1.25558831, grad/param norm = 3.2090e-01, time/batch = 0.6624s	
12765/25300 (epoch 25.227), train_loss = 1.03081333, grad/param norm = 2.5401e-01, time/batch = 0.6633s	
12766/25300 (epoch 25.229), train_loss = 0.89195274, grad/param norm = 2.1041e-01, time/batch = 0.6554s	
12767/25300 (epoch 25.231), train_loss = 0.87952929, grad/param norm = 2.0045e-01, time/batch = 0.6641s	
12768/25300 (epoch 25.233), train_loss = 0.95549593, grad/param norm = 2.0498e-01, time/batch = 0.6584s	
12769/25300 (epoch 25.235), train_loss = 0.89505843, grad/param norm = 2.0455e-01, time/batch = 0.6598s	
12770/25300 (epoch 25.237), train_loss = 1.04165212, grad/param norm = 2.4138e-01, time/batch = 0.6660s	
12771/25300 (epoch 25.239), train_loss = 0.85139140, grad/param norm = 1.8580e-01, time/batch = 0.6635s	
12772/25300 (epoch 25.241), train_loss = 1.04891108, grad/param norm = 2.0921e-01, time/batch = 0.6661s	
12773/25300 (epoch 25.243), train_loss = 1.15659576, grad/param norm = 2.2114e-01, time/batch = 0.6600s	
12774/25300 (epoch 25.245), train_loss = 0.85851021, grad/param norm = 2.0308e-01, time/batch = 0.6668s	
12775/25300 (epoch 25.247), train_loss = 0.97303819, grad/param norm = 2.0714e-01, time/batch = 0.6609s	
12776/25300 (epoch 25.249), train_loss = 0.77023922, grad/param norm = 1.8207e-01, time/batch = 0.6599s	
12777/25300 (epoch 25.251), train_loss = 0.77678101, grad/param norm = 1.8990e-01, time/batch = 0.6623s	
12778/25300 (epoch 25.253), train_loss = 0.88615908, grad/param norm = 2.0539e-01, time/batch = 0.6567s	
12779/25300 (epoch 25.255), train_loss = 0.84034824, grad/param norm = 2.4366e-01, time/batch = 0.6598s	
12780/25300 (epoch 25.257), train_loss = 0.89404936, grad/param norm = 2.2132e-01, time/batch = 0.6687s	
12781/25300 (epoch 25.259), train_loss = 1.08453422, grad/param norm = 2.5127e-01, time/batch = 0.6750s	
12782/25300 (epoch 25.261), train_loss = 1.04629604, grad/param norm = 2.5420e-01, time/batch = 0.6650s	
12783/25300 (epoch 25.263), train_loss = 1.06209759, grad/param norm = 2.3129e-01, time/batch = 0.6668s	
12784/25300 (epoch 25.265), train_loss = 1.07812337, grad/param norm = 2.2338e-01, time/batch = 0.6579s	
12785/25300 (epoch 25.267), train_loss = 0.98020421, grad/param norm = 2.0320e-01, time/batch = 0.6626s	
12786/25300 (epoch 25.269), train_loss = 0.76280174, grad/param norm = 1.8328e-01, time/batch = 0.6668s	
12787/25300 (epoch 25.271), train_loss = 0.83616099, grad/param norm = 2.0341e-01, time/batch = 0.6672s	
12788/25300 (epoch 25.273), train_loss = 0.97783563, grad/param norm = 2.3084e-01, time/batch = 0.6587s	
12789/25300 (epoch 25.275), train_loss = 0.87787418, grad/param norm = 1.8068e-01, time/batch = 0.6608s	
12790/25300 (epoch 25.277), train_loss = 0.88025268, grad/param norm = 2.1986e-01, time/batch = 0.6563s	
12791/25300 (epoch 25.279), train_loss = 0.88411529, grad/param norm = 1.8614e-01, time/batch = 0.6595s	
12792/25300 (epoch 25.281), train_loss = 1.04653235, grad/param norm = 2.2230e-01, time/batch = 0.6638s	
12793/25300 (epoch 25.283), train_loss = 0.78823058, grad/param norm = 1.7019e-01, time/batch = 0.6630s	
12794/25300 (epoch 25.285), train_loss = 0.93586208, grad/param norm = 2.2369e-01, time/batch = 0.6564s	
12795/25300 (epoch 25.287), train_loss = 0.96317600, grad/param norm = 1.9265e-01, time/batch = 0.6584s	
12796/25300 (epoch 25.289), train_loss = 0.86141204, grad/param norm = 1.9625e-01, time/batch = 0.6562s	
12797/25300 (epoch 25.291), train_loss = 0.87714205, grad/param norm = 2.0140e-01, time/batch = 0.6620s	
12798/25300 (epoch 25.292), train_loss = 1.06907239, grad/param norm = 2.2509e-01, time/batch = 0.6604s	
12799/25300 (epoch 25.294), train_loss = 0.93084492, grad/param norm = 2.0041e-01, time/batch = 0.6616s	
12800/25300 (epoch 25.296), train_loss = 0.79619551, grad/param norm = 2.0393e-01, time/batch = 0.6647s	
12801/25300 (epoch 25.298), train_loss = 0.98930691, grad/param norm = 2.2009e-01, time/batch = 0.6636s	
12802/25300 (epoch 25.300), train_loss = 1.00828072, grad/param norm = 2.5074e-01, time/batch = 0.6584s	
12803/25300 (epoch 25.302), train_loss = 0.73243892, grad/param norm = 1.9378e-01, time/batch = 0.6646s	
12804/25300 (epoch 25.304), train_loss = 0.98718331, grad/param norm = 2.1848e-01, time/batch = 0.6647s	
12805/25300 (epoch 25.306), train_loss = 0.71456922, grad/param norm = 1.8151e-01, time/batch = 0.6595s	
12806/25300 (epoch 25.308), train_loss = 0.96267107, grad/param norm = 1.8757e-01, time/batch = 0.6624s	
12807/25300 (epoch 25.310), train_loss = 0.80410061, grad/param norm = 2.0640e-01, time/batch = 0.6588s	
12808/25300 (epoch 25.312), train_loss = 0.91112026, grad/param norm = 1.8986e-01, time/batch = 0.6640s	
12809/25300 (epoch 25.314), train_loss = 0.74448588, grad/param norm = 1.9174e-01, time/batch = 0.6599s	
12810/25300 (epoch 25.316), train_loss = 0.90518379, grad/param norm = 1.8117e-01, time/batch = 0.6608s	
12811/25300 (epoch 25.318), train_loss = 0.74831022, grad/param norm = 1.8806e-01, time/batch = 0.6626s	
12812/25300 (epoch 25.320), train_loss = 0.80934349, grad/param norm = 1.8165e-01, time/batch = 0.6601s	
12813/25300 (epoch 25.322), train_loss = 1.05344693, grad/param norm = 2.0442e-01, time/batch = 0.6647s	
12814/25300 (epoch 25.324), train_loss = 0.80164068, grad/param norm = 1.8039e-01, time/batch = 0.6608s	
12815/25300 (epoch 25.326), train_loss = 0.73355717, grad/param norm = 1.8695e-01, time/batch = 0.6670s	
12816/25300 (epoch 25.328), train_loss = 0.72472773, grad/param norm = 1.9781e-01, time/batch = 0.6565s	
12817/25300 (epoch 25.330), train_loss = 0.86481573, grad/param norm = 2.0303e-01, time/batch = 0.6606s	
12818/25300 (epoch 25.332), train_loss = 0.90165042, grad/param norm = 1.8868e-01, time/batch = 0.6567s	
12819/25300 (epoch 25.334), train_loss = 0.73569616, grad/param norm = 1.9928e-01, time/batch = 0.6606s	
12820/25300 (epoch 25.336), train_loss = 0.76078155, grad/param norm = 1.9153e-01, time/batch = 0.6599s	
12821/25300 (epoch 25.338), train_loss = 0.77350033, grad/param norm = 1.9629e-01, time/batch = 0.6624s	
12822/25300 (epoch 25.340), train_loss = 0.81270001, grad/param norm = 2.0873e-01, time/batch = 0.6659s	
12823/25300 (epoch 25.342), train_loss = 0.85702836, grad/param norm = 2.6117e-01, time/batch = 0.6602s	
12824/25300 (epoch 25.344), train_loss = 0.93990874, grad/param norm = 2.2530e-01, time/batch = 0.6576s	
12825/25300 (epoch 25.346), train_loss = 0.83360116, grad/param norm = 2.0201e-01, time/batch = 0.6600s	
12826/25300 (epoch 25.348), train_loss = 0.75082237, grad/param norm = 1.9762e-01, time/batch = 0.6602s	
12827/25300 (epoch 25.350), train_loss = 0.86702613, grad/param norm = 2.4700e-01, time/batch = 0.6655s	
12828/25300 (epoch 25.352), train_loss = 0.88038682, grad/param norm = 2.0264e-01, time/batch = 0.6607s	
12829/25300 (epoch 25.354), train_loss = 0.79872947, grad/param norm = 1.9275e-01, time/batch = 0.6605s	
12830/25300 (epoch 25.356), train_loss = 0.86926169, grad/param norm = 2.0468e-01, time/batch = 0.6572s	
12831/25300 (epoch 25.358), train_loss = 0.93085395, grad/param norm = 2.1573e-01, time/batch = 0.6609s	
12832/25300 (epoch 25.360), train_loss = 0.79350726, grad/param norm = 1.9462e-01, time/batch = 0.6584s	
12833/25300 (epoch 25.362), train_loss = 0.80801319, grad/param norm = 2.0220e-01, time/batch = 0.6583s	
12834/25300 (epoch 25.364), train_loss = 0.83195420, grad/param norm = 2.1329e-01, time/batch = 0.6637s	
12835/25300 (epoch 25.366), train_loss = 0.75044483, grad/param norm = 1.8939e-01, time/batch = 0.6628s	
12836/25300 (epoch 25.368), train_loss = 0.85314615, grad/param norm = 2.0131e-01, time/batch = 0.6649s	
12837/25300 (epoch 25.370), train_loss = 0.81382549, grad/param norm = 2.2371e-01, time/batch = 0.6663s	
12838/25300 (epoch 25.372), train_loss = 0.80731776, grad/param norm = 2.0761e-01, time/batch = 0.6586s	
12839/25300 (epoch 25.374), train_loss = 0.74257459, grad/param norm = 1.9187e-01, time/batch = 0.6615s	
12840/25300 (epoch 25.375), train_loss = 0.98223039, grad/param norm = 2.1111e-01, time/batch = 0.6599s	
12841/25300 (epoch 25.377), train_loss = 0.94254499, grad/param norm = 2.0910e-01, time/batch = 0.6632s	
12842/25300 (epoch 25.379), train_loss = 0.91910445, grad/param norm = 2.2824e-01, time/batch = 0.6612s	
12843/25300 (epoch 25.381), train_loss = 0.85461236, grad/param norm = 1.9589e-01, time/batch = 0.6672s	
12844/25300 (epoch 25.383), train_loss = 0.79535868, grad/param norm = 1.9909e-01, time/batch = 0.6686s	
12845/25300 (epoch 25.385), train_loss = 0.87520816, grad/param norm = 1.7939e-01, time/batch = 0.6783s	
12846/25300 (epoch 25.387), train_loss = 0.89571273, grad/param norm = 2.0104e-01, time/batch = 0.6693s	
12847/25300 (epoch 25.389), train_loss = 0.89677346, grad/param norm = 2.0815e-01, time/batch = 0.6616s	
12848/25300 (epoch 25.391), train_loss = 0.82183811, grad/param norm = 1.8256e-01, time/batch = 0.6641s	
12849/25300 (epoch 25.393), train_loss = 0.90310988, grad/param norm = 2.3013e-01, time/batch = 0.6594s	
12850/25300 (epoch 25.395), train_loss = 0.72231343, grad/param norm = 1.8382e-01, time/batch = 0.6607s	
12851/25300 (epoch 25.397), train_loss = 0.73385370, grad/param norm = 2.0860e-01, time/batch = 0.6681s	
12852/25300 (epoch 25.399), train_loss = 0.74265429, grad/param norm = 2.0002e-01, time/batch = 0.6636s	
12853/25300 (epoch 25.401), train_loss = 0.93066988, grad/param norm = 2.1627e-01, time/batch = 0.6637s	
12854/25300 (epoch 25.403), train_loss = 0.90070811, grad/param norm = 2.5301e-01, time/batch = 0.6687s	
12855/25300 (epoch 25.405), train_loss = 0.86914929, grad/param norm = 2.1302e-01, time/batch = 0.6613s	
12856/25300 (epoch 25.407), train_loss = 0.85314808, grad/param norm = 2.0463e-01, time/batch = 0.6823s	
12857/25300 (epoch 25.409), train_loss = 0.80079656, grad/param norm = 1.9296e-01, time/batch = 0.6647s	
12858/25300 (epoch 25.411), train_loss = 0.80199465, grad/param norm = 1.9832e-01, time/batch = 0.6637s	
12859/25300 (epoch 25.413), train_loss = 0.71947629, grad/param norm = 1.7445e-01, time/batch = 0.6665s	
12860/25300 (epoch 25.415), train_loss = 0.77529900, grad/param norm = 1.7607e-01, time/batch = 0.6627s	
12861/25300 (epoch 25.417), train_loss = 0.72204896, grad/param norm = 1.6903e-01, time/batch = 0.6621s	
12862/25300 (epoch 25.419), train_loss = 0.66947231, grad/param norm = 1.6950e-01, time/batch = 0.6648s	
12863/25300 (epoch 25.421), train_loss = 0.75364540, grad/param norm = 1.6343e-01, time/batch = 0.6597s	
12864/25300 (epoch 25.423), train_loss = 0.74918518, grad/param norm = 1.9206e-01, time/batch = 0.6651s	
12865/25300 (epoch 25.425), train_loss = 0.82505862, grad/param norm = 2.0979e-01, time/batch = 0.6619s	
12866/25300 (epoch 25.427), train_loss = 0.97655242, grad/param norm = 2.0304e-01, time/batch = 0.6614s	
12867/25300 (epoch 25.429), train_loss = 0.97614866, grad/param norm = 2.2879e-01, time/batch = 0.6666s	
12868/25300 (epoch 25.431), train_loss = 0.89419913, grad/param norm = 2.0006e-01, time/batch = 0.6584s	
12869/25300 (epoch 25.433), train_loss = 0.84890884, grad/param norm = 1.8183e-01, time/batch = 0.6623s	
12870/25300 (epoch 25.435), train_loss = 0.80726957, grad/param norm = 2.4541e-01, time/batch = 0.6638s	
12871/25300 (epoch 25.437), train_loss = 0.78678222, grad/param norm = 2.0032e-01, time/batch = 0.6645s	
12872/25300 (epoch 25.439), train_loss = 0.88432229, grad/param norm = 2.0104e-01, time/batch = 0.6628s	
12873/25300 (epoch 25.441), train_loss = 0.90949840, grad/param norm = 2.0578e-01, time/batch = 0.6632s	
12874/25300 (epoch 25.443), train_loss = 1.07175604, grad/param norm = 2.5212e-01, time/batch = 0.6616s	
12875/25300 (epoch 25.445), train_loss = 1.01397655, grad/param norm = 2.4137e-01, time/batch = 0.6653s	
12876/25300 (epoch 25.447), train_loss = 0.78547559, grad/param norm = 1.7939e-01, time/batch = 0.6626s	
12877/25300 (epoch 25.449), train_loss = 0.71288032, grad/param norm = 1.8900e-01, time/batch = 0.6639s	
12878/25300 (epoch 25.451), train_loss = 1.06865106, grad/param norm = 2.3242e-01, time/batch = 0.6615s	
12879/25300 (epoch 25.453), train_loss = 0.93497984, grad/param norm = 2.3964e-01, time/batch = 0.6613s	
12880/25300 (epoch 25.455), train_loss = 0.94385552, grad/param norm = 2.4507e-01, time/batch = 0.6700s	
12881/25300 (epoch 25.457), train_loss = 0.81225614, grad/param norm = 2.0836e-01, time/batch = 0.6681s	
12882/25300 (epoch 25.458), train_loss = 0.82974400, grad/param norm = 2.0180e-01, time/batch = 0.6702s	
12883/25300 (epoch 25.460), train_loss = 0.83706738, grad/param norm = 1.8273e-01, time/batch = 0.6610s	
12884/25300 (epoch 25.462), train_loss = 0.63121015, grad/param norm = 1.8398e-01, time/batch = 0.6653s	
12885/25300 (epoch 25.464), train_loss = 0.92476890, grad/param norm = 2.0205e-01, time/batch = 0.6590s	
12886/25300 (epoch 25.466), train_loss = 0.93280680, grad/param norm = 2.1202e-01, time/batch = 0.6578s	
12887/25300 (epoch 25.468), train_loss = 0.94440055, grad/param norm = 2.9544e-01, time/batch = 0.6580s	
12888/25300 (epoch 25.470), train_loss = 0.84193316, grad/param norm = 1.9064e-01, time/batch = 0.6575s	
12889/25300 (epoch 25.472), train_loss = 0.74282613, grad/param norm = 1.9985e-01, time/batch = 0.6635s	
12890/25300 (epoch 25.474), train_loss = 0.92176935, grad/param norm = 2.0204e-01, time/batch = 0.6670s	
12891/25300 (epoch 25.476), train_loss = 0.83658509, grad/param norm = 2.2216e-01, time/batch = 0.6685s	
12892/25300 (epoch 25.478), train_loss = 0.95672271, grad/param norm = 2.4796e-01, time/batch = 0.6601s	
12893/25300 (epoch 25.480), train_loss = 0.82677373, grad/param norm = 2.0329e-01, time/batch = 0.6632s	
12894/25300 (epoch 25.482), train_loss = 0.92858830, grad/param norm = 2.5868e-01, time/batch = 0.6615s	
12895/25300 (epoch 25.484), train_loss = 0.92283034, grad/param norm = 2.4074e-01, time/batch = 0.6575s	
12896/25300 (epoch 25.486), train_loss = 0.86284903, grad/param norm = 2.1280e-01, time/batch = 0.6613s	
12897/25300 (epoch 25.488), train_loss = 1.03055517, grad/param norm = 2.4196e-01, time/batch = 0.6593s	
12898/25300 (epoch 25.490), train_loss = 0.91033080, grad/param norm = 2.0143e-01, time/batch = 0.6572s	
12899/25300 (epoch 25.492), train_loss = 0.93547795, grad/param norm = 1.9523e-01, time/batch = 0.6609s	
12900/25300 (epoch 25.494), train_loss = 0.82772376, grad/param norm = 2.0045e-01, time/batch = 0.6553s	
12901/25300 (epoch 25.496), train_loss = 0.88835528, grad/param norm = 2.0372e-01, time/batch = 0.6644s	
12902/25300 (epoch 25.498), train_loss = 0.81887374, grad/param norm = 1.9340e-01, time/batch = 0.6572s	
12903/25300 (epoch 25.500), train_loss = 1.01640756, grad/param norm = 2.3265e-01, time/batch = 0.6586s	
12904/25300 (epoch 25.502), train_loss = 0.94317827, grad/param norm = 2.4167e-01, time/batch = 0.6586s	
12905/25300 (epoch 25.504), train_loss = 0.85111077, grad/param norm = 2.0972e-01, time/batch = 0.6580s	
12906/25300 (epoch 25.506), train_loss = 0.78478331, grad/param norm = 1.9644e-01, time/batch = 0.6627s	
12907/25300 (epoch 25.508), train_loss = 0.86595153, grad/param norm = 2.0948e-01, time/batch = 0.6623s	
12908/25300 (epoch 25.510), train_loss = 0.79419071, grad/param norm = 1.8593e-01, time/batch = 0.6603s	
12909/25300 (epoch 25.512), train_loss = 0.64616661, grad/param norm = 1.7028e-01, time/batch = 0.6563s	
12910/25300 (epoch 25.514), train_loss = 0.84137496, grad/param norm = 1.9584e-01, time/batch = 0.6587s	
12911/25300 (epoch 25.516), train_loss = 0.92149852, grad/param norm = 2.0418e-01, time/batch = 0.6647s	
12912/25300 (epoch 25.518), train_loss = 0.96212435, grad/param norm = 2.3566e-01, time/batch = 0.6819s	
12913/25300 (epoch 25.520), train_loss = 0.71101055, grad/param norm = 1.5051e-01, time/batch = 0.6624s	
12914/25300 (epoch 25.522), train_loss = 0.81666605, grad/param norm = 1.9835e-01, time/batch = 0.6593s	
12915/25300 (epoch 25.524), train_loss = 0.80533663, grad/param norm = 1.9148e-01, time/batch = 0.6624s	
12916/25300 (epoch 25.526), train_loss = 0.99137655, grad/param norm = 2.0537e-01, time/batch = 0.6594s	
12917/25300 (epoch 25.528), train_loss = 1.01891143, grad/param norm = 2.1507e-01, time/batch = 0.6590s	
12918/25300 (epoch 25.530), train_loss = 0.88981198, grad/param norm = 1.9799e-01, time/batch = 0.6613s	
12919/25300 (epoch 25.532), train_loss = 0.85934522, grad/param norm = 2.0896e-01, time/batch = 0.6627s	
12920/25300 (epoch 25.534), train_loss = 0.84618619, grad/param norm = 1.9350e-01, time/batch = 0.6644s	
12921/25300 (epoch 25.536), train_loss = 0.68248922, grad/param norm = 1.8944e-01, time/batch = 0.6664s	
12922/25300 (epoch 25.538), train_loss = 0.75913381, grad/param norm = 1.7866e-01, time/batch = 0.6621s	
12923/25300 (epoch 25.540), train_loss = 0.78358254, grad/param norm = 1.8354e-01, time/batch = 0.6627s	
12924/25300 (epoch 25.542), train_loss = 0.75962689, grad/param norm = 1.7769e-01, time/batch = 0.6542s	
12925/25300 (epoch 25.543), train_loss = 0.72759687, grad/param norm = 1.7399e-01, time/batch = 0.6645s	
12926/25300 (epoch 25.545), train_loss = 1.07473641, grad/param norm = 2.3079e-01, time/batch = 0.6608s	
12927/25300 (epoch 25.547), train_loss = 0.93892649, grad/param norm = 2.1887e-01, time/batch = 0.6634s	
12928/25300 (epoch 25.549), train_loss = 1.10761818, grad/param norm = 2.6919e-01, time/batch = 0.6611s	
12929/25300 (epoch 25.551), train_loss = 0.95747726, grad/param norm = 2.0834e-01, time/batch = 0.6587s	
12930/25300 (epoch 25.553), train_loss = 0.78197036, grad/param norm = 1.9894e-01, time/batch = 0.6605s	
12931/25300 (epoch 25.555), train_loss = 0.95857135, grad/param norm = 2.1224e-01, time/batch = 0.6627s	
12932/25300 (epoch 25.557), train_loss = 0.99133134, grad/param norm = 2.8370e-01, time/batch = 0.6593s	
12933/25300 (epoch 25.559), train_loss = 0.97046341, grad/param norm = 2.0342e-01, time/batch = 0.6712s	
12934/25300 (epoch 25.561), train_loss = 1.00198564, grad/param norm = 2.3068e-01, time/batch = 0.6737s	
12935/25300 (epoch 25.563), train_loss = 0.96293073, grad/param norm = 2.3267e-01, time/batch = 0.6689s	
12936/25300 (epoch 25.565), train_loss = 0.77210337, grad/param norm = 1.8717e-01, time/batch = 0.6737s	
12937/25300 (epoch 25.567), train_loss = 0.68696688, grad/param norm = 1.7504e-01, time/batch = 0.6703s	
12938/25300 (epoch 25.569), train_loss = 0.87012081, grad/param norm = 2.0354e-01, time/batch = 0.6697s	
12939/25300 (epoch 25.571), train_loss = 0.96193469, grad/param norm = 2.2375e-01, time/batch = 0.6604s	
12940/25300 (epoch 25.573), train_loss = 0.85651053, grad/param norm = 2.0168e-01, time/batch = 0.6710s	
12941/25300 (epoch 25.575), train_loss = 0.98577479, grad/param norm = 2.0562e-01, time/batch = 0.6772s	
12942/25300 (epoch 25.577), train_loss = 0.87078143, grad/param norm = 2.1603e-01, time/batch = 0.6638s	
12943/25300 (epoch 25.579), train_loss = 1.02504632, grad/param norm = 2.5053e-01, time/batch = 0.6686s	
12944/25300 (epoch 25.581), train_loss = 0.94480571, grad/param norm = 2.0805e-01, time/batch = 0.6628s	
12945/25300 (epoch 25.583), train_loss = 0.75769026, grad/param norm = 2.3201e-01, time/batch = 0.6671s	
12946/25300 (epoch 25.585), train_loss = 0.73764508, grad/param norm = 2.0119e-01, time/batch = 0.6605s	
12947/25300 (epoch 25.587), train_loss = 0.85305466, grad/param norm = 1.9450e-01, time/batch = 0.6632s	
12948/25300 (epoch 25.589), train_loss = 0.75332631, grad/param norm = 1.8005e-01, time/batch = 0.6573s	
12949/25300 (epoch 25.591), train_loss = 0.75313544, grad/param norm = 2.0177e-01, time/batch = 0.6605s	
12950/25300 (epoch 25.593), train_loss = 0.94066210, grad/param norm = 2.2077e-01, time/batch = 0.6609s	
12951/25300 (epoch 25.595), train_loss = 0.84980563, grad/param norm = 1.9043e-01, time/batch = 0.6604s	
12952/25300 (epoch 25.597), train_loss = 0.75808728, grad/param norm = 1.8935e-01, time/batch = 0.6690s	
12953/25300 (epoch 25.599), train_loss = 0.92862366, grad/param norm = 2.1974e-01, time/batch = 0.6624s	
12954/25300 (epoch 25.601), train_loss = 0.85649188, grad/param norm = 1.9593e-01, time/batch = 0.6629s	
12955/25300 (epoch 25.603), train_loss = 0.86709790, grad/param norm = 2.0827e-01, time/batch = 0.6646s	
12956/25300 (epoch 25.605), train_loss = 0.80684208, grad/param norm = 2.2289e-01, time/batch = 0.6634s	
12957/25300 (epoch 25.607), train_loss = 0.64656014, grad/param norm = 1.8271e-01, time/batch = 0.6644s	
12958/25300 (epoch 25.609), train_loss = 0.82958262, grad/param norm = 1.9173e-01, time/batch = 0.6607s	
12959/25300 (epoch 25.611), train_loss = 0.88490892, grad/param norm = 1.9996e-01, time/batch = 0.6638s	
12960/25300 (epoch 25.613), train_loss = 0.74245958, grad/param norm = 1.6969e-01, time/batch = 0.6580s	
12961/25300 (epoch 25.615), train_loss = 0.85800095, grad/param norm = 2.3695e-01, time/batch = 0.6634s	
12962/25300 (epoch 25.617), train_loss = 0.87138473, grad/param norm = 2.0363e-01, time/batch = 0.6642s	
12963/25300 (epoch 25.619), train_loss = 0.94415179, grad/param norm = 2.0828e-01, time/batch = 0.6693s	
12964/25300 (epoch 25.621), train_loss = 0.95298942, grad/param norm = 2.1492e-01, time/batch = 0.6639s	
12965/25300 (epoch 25.623), train_loss = 0.78289658, grad/param norm = 1.9679e-01, time/batch = 0.6702s	
12966/25300 (epoch 25.625), train_loss = 0.70846007, grad/param norm = 1.8978e-01, time/batch = 0.6631s	
12967/25300 (epoch 25.626), train_loss = 0.83947990, grad/param norm = 1.7926e-01, time/batch = 0.6608s	
12968/25300 (epoch 25.628), train_loss = 0.93742363, grad/param norm = 2.3729e-01, time/batch = 0.6637s	
12969/25300 (epoch 25.630), train_loss = 0.91666845, grad/param norm = 2.1014e-01, time/batch = 0.6663s	
12970/25300 (epoch 25.632), train_loss = 0.88428687, grad/param norm = 2.1934e-01, time/batch = 0.6624s	
12971/25300 (epoch 25.634), train_loss = 1.00094410, grad/param norm = 2.4707e-01, time/batch = 0.6605s	
12972/25300 (epoch 25.636), train_loss = 0.79470889, grad/param norm = 2.0128e-01, time/batch = 0.6647s	
12973/25300 (epoch 25.638), train_loss = 0.89093684, grad/param norm = 2.1948e-01, time/batch = 0.6595s	
12974/25300 (epoch 25.640), train_loss = 1.04474091, grad/param norm = 2.4976e-01, time/batch = 0.6606s	
12975/25300 (epoch 25.642), train_loss = 0.90786861, grad/param norm = 2.2718e-01, time/batch = 0.6596s	
12976/25300 (epoch 25.644), train_loss = 0.90846088, grad/param norm = 2.1678e-01, time/batch = 0.6636s	
12977/25300 (epoch 25.646), train_loss = 0.82594542, grad/param norm = 2.3445e-01, time/batch = 0.6578s	
12978/25300 (epoch 25.648), train_loss = 0.96751108, grad/param norm = 2.0439e-01, time/batch = 0.6637s	
12979/25300 (epoch 25.650), train_loss = 0.91248039, grad/param norm = 2.3213e-01, time/batch = 0.6607s	
12980/25300 (epoch 25.652), train_loss = 0.90783660, grad/param norm = 2.1539e-01, time/batch = 0.6648s	
12981/25300 (epoch 25.654), train_loss = 1.02686621, grad/param norm = 2.1991e-01, time/batch = 0.6695s	
12982/25300 (epoch 25.656), train_loss = 0.93004943, grad/param norm = 2.1223e-01, time/batch = 0.6588s	
12983/25300 (epoch 25.658), train_loss = 0.72450580, grad/param norm = 1.7455e-01, time/batch = 0.6635s	
12984/25300 (epoch 25.660), train_loss = 0.76299672, grad/param norm = 2.0180e-01, time/batch = 0.6605s	
12985/25300 (epoch 25.662), train_loss = 0.76163579, grad/param norm = 2.0428e-01, time/batch = 0.6568s	
12986/25300 (epoch 25.664), train_loss = 0.72710805, grad/param norm = 2.0862e-01, time/batch = 0.6602s	
12987/25300 (epoch 25.666), train_loss = 0.77582282, grad/param norm = 2.0728e-01, time/batch = 0.6592s	
12988/25300 (epoch 25.668), train_loss = 0.83194255, grad/param norm = 2.8001e-01, time/batch = 0.6585s	
12989/25300 (epoch 25.670), train_loss = 0.80319990, grad/param norm = 2.3387e-01, time/batch = 0.6669s	
12990/25300 (epoch 25.672), train_loss = 0.78522703, grad/param norm = 2.4125e-01, time/batch = 0.6656s	
12991/25300 (epoch 25.674), train_loss = 0.79767701, grad/param norm = 1.8846e-01, time/batch = 0.6679s	
12992/25300 (epoch 25.676), train_loss = 0.82642843, grad/param norm = 2.2788e-01, time/batch = 0.6626s	
12993/25300 (epoch 25.678), train_loss = 0.81890603, grad/param norm = 2.3788e-01, time/batch = 0.6784s	
12994/25300 (epoch 25.680), train_loss = 0.70536337, grad/param norm = 1.8446e-01, time/batch = 0.6599s	
12995/25300 (epoch 25.682), train_loss = 0.60061325, grad/param norm = 1.6284e-01, time/batch = 0.6644s	
12996/25300 (epoch 25.684), train_loss = 0.76787131, grad/param norm = 1.7615e-01, time/batch = 0.6589s	
12997/25300 (epoch 25.686), train_loss = 0.70623877, grad/param norm = 1.6752e-01, time/batch = 0.6597s	
12998/25300 (epoch 25.688), train_loss = 0.83342877, grad/param norm = 2.3162e-01, time/batch = 0.6612s	
12999/25300 (epoch 25.690), train_loss = 0.74138216, grad/param norm = 1.9128e-01, time/batch = 0.6570s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch25.69_1.6571.t7	
13000/25300 (epoch 25.692), train_loss = 0.77047231, grad/param norm = 1.8281e-01, time/batch = 0.6575s	
13001/25300 (epoch 25.694), train_loss = 1.10994053, grad/param norm = 2.4707e-01, time/batch = 0.6662s	
13002/25300 (epoch 25.696), train_loss = 0.88494643, grad/param norm = 2.2640e-01, time/batch = 0.6613s	
13003/25300 (epoch 25.698), train_loss = 0.89604676, grad/param norm = 2.0034e-01, time/batch = 0.6637s	
13004/25300 (epoch 25.700), train_loss = 0.68727429, grad/param norm = 1.8516e-01, time/batch = 0.6770s	
13005/25300 (epoch 25.702), train_loss = 0.92562950, grad/param norm = 2.4662e-01, time/batch = 0.6606s	
13006/25300 (epoch 25.704), train_loss = 0.68385836, grad/param norm = 1.8515e-01, time/batch = 0.6632s	
13007/25300 (epoch 25.706), train_loss = 0.81376028, grad/param norm = 2.1139e-01, time/batch = 0.6627s	
13008/25300 (epoch 25.708), train_loss = 0.69691103, grad/param norm = 1.6980e-01, time/batch = 0.6710s	
13009/25300 (epoch 25.709), train_loss = 0.99373459, grad/param norm = 2.1930e-01, time/batch = 0.6778s	
13010/25300 (epoch 25.711), train_loss = 1.02789698, grad/param norm = 2.3923e-01, time/batch = 0.6724s	
13011/25300 (epoch 25.713), train_loss = 0.83921630, grad/param norm = 1.7634e-01, time/batch = 0.6623s	
13012/25300 (epoch 25.715), train_loss = 0.83770737, grad/param norm = 1.8913e-01, time/batch = 0.6623s	
13013/25300 (epoch 25.717), train_loss = 0.77448626, grad/param norm = 2.1481e-01, time/batch = 0.6607s	
13014/25300 (epoch 25.719), train_loss = 0.83239932, grad/param norm = 2.1007e-01, time/batch = 0.6630s	
13015/25300 (epoch 25.721), train_loss = 0.89776800, grad/param norm = 2.3002e-01, time/batch = 0.6660s	
13016/25300 (epoch 25.723), train_loss = 0.82399738, grad/param norm = 2.0325e-01, time/batch = 0.6689s	
13017/25300 (epoch 25.725), train_loss = 0.88519789, grad/param norm = 2.0168e-01, time/batch = 0.6689s	
13018/25300 (epoch 25.727), train_loss = 0.86223311, grad/param norm = 2.0451e-01, time/batch = 0.6704s	
13019/25300 (epoch 25.729), train_loss = 0.84271260, grad/param norm = 1.9372e-01, time/batch = 0.6632s	
13020/25300 (epoch 25.731), train_loss = 1.00253232, grad/param norm = 2.1500e-01, time/batch = 0.6649s	
13021/25300 (epoch 25.733), train_loss = 0.83112874, grad/param norm = 1.8315e-01, time/batch = 0.6683s	
13022/25300 (epoch 25.735), train_loss = 1.09113644, grad/param norm = 2.1858e-01, time/batch = 0.6670s	
13023/25300 (epoch 25.737), train_loss = 0.74373716, grad/param norm = 1.7915e-01, time/batch = 0.6641s	
13024/25300 (epoch 25.739), train_loss = 0.99646040, grad/param norm = 2.1508e-01, time/batch = 0.6642s	
13025/25300 (epoch 25.741), train_loss = 0.90707369, grad/param norm = 2.2007e-01, time/batch = 0.6672s	
13026/25300 (epoch 25.743), train_loss = 0.83956287, grad/param norm = 1.9816e-01, time/batch = 0.6654s	
13027/25300 (epoch 25.745), train_loss = 0.80497057, grad/param norm = 2.0339e-01, time/batch = 0.6705s	
13028/25300 (epoch 25.747), train_loss = 0.76360812, grad/param norm = 1.7107e-01, time/batch = 0.6578s	
13029/25300 (epoch 25.749), train_loss = 0.86175854, grad/param norm = 2.2198e-01, time/batch = 0.6650s	
13030/25300 (epoch 25.751), train_loss = 0.92006417, grad/param norm = 2.2021e-01, time/batch = 0.6615s	
13031/25300 (epoch 25.753), train_loss = 0.76272477, grad/param norm = 2.0605e-01, time/batch = 0.6652s	
13032/25300 (epoch 25.755), train_loss = 0.95084156, grad/param norm = 2.2052e-01, time/batch = 0.6681s	
13033/25300 (epoch 25.757), train_loss = 0.80597038, grad/param norm = 2.0673e-01, time/batch = 0.6648s	
13034/25300 (epoch 25.759), train_loss = 0.79062834, grad/param norm = 2.1613e-01, time/batch = 0.6703s	
13035/25300 (epoch 25.761), train_loss = 1.01355354, grad/param norm = 2.5007e-01, time/batch = 0.6668s	
13036/25300 (epoch 25.763), train_loss = 0.81577289, grad/param norm = 1.9026e-01, time/batch = 0.6658s	
13037/25300 (epoch 25.765), train_loss = 0.85186097, grad/param norm = 2.3855e-01, time/batch = 0.6670s	
13038/25300 (epoch 25.767), train_loss = 0.81312516, grad/param norm = 1.8540e-01, time/batch = 0.6656s	
13039/25300 (epoch 25.769), train_loss = 0.87437455, grad/param norm = 2.2898e-01, time/batch = 0.6628s	
13040/25300 (epoch 25.771), train_loss = 0.97692238, grad/param norm = 2.2543e-01, time/batch = 0.6643s	
13041/25300 (epoch 25.773), train_loss = 0.98800619, grad/param norm = 2.3444e-01, time/batch = 0.6602s	
13042/25300 (epoch 25.775), train_loss = 0.85711171, grad/param norm = 1.7421e-01, time/batch = 0.6651s	
13043/25300 (epoch 25.777), train_loss = 0.84827450, grad/param norm = 2.1854e-01, time/batch = 0.6603s	
13044/25300 (epoch 25.779), train_loss = 0.94045318, grad/param norm = 2.0824e-01, time/batch = 0.6647s	
13045/25300 (epoch 25.781), train_loss = 0.90504194, grad/param norm = 2.0600e-01, time/batch = 0.6578s	
13046/25300 (epoch 25.783), train_loss = 0.96874957, grad/param norm = 2.1750e-01, time/batch = 0.6653s	
13047/25300 (epoch 25.785), train_loss = 0.94051785, grad/param norm = 2.1150e-01, time/batch = 0.6581s	
13048/25300 (epoch 25.787), train_loss = 0.93113766, grad/param norm = 2.3012e-01, time/batch = 0.6599s	
13049/25300 (epoch 25.789), train_loss = 1.04640414, grad/param norm = 2.2750e-01, time/batch = 0.6625s	
13050/25300 (epoch 25.791), train_loss = 0.92956561, grad/param norm = 2.0837e-01, time/batch = 0.6617s	
13051/25300 (epoch 25.792), train_loss = 0.98652108, grad/param norm = 2.1383e-01, time/batch = 0.6692s	
13052/25300 (epoch 25.794), train_loss = 0.86986030, grad/param norm = 2.0763e-01, time/batch = 0.6623s	
13053/25300 (epoch 25.796), train_loss = 0.82701949, grad/param norm = 2.0931e-01, time/batch = 0.6628s	
13054/25300 (epoch 25.798), train_loss = 0.97916350, grad/param norm = 2.7569e-01, time/batch = 0.6589s	
13055/25300 (epoch 25.800), train_loss = 0.83436255, grad/param norm = 1.9506e-01, time/batch = 0.6644s	
13056/25300 (epoch 25.802), train_loss = 0.70492151, grad/param norm = 1.9699e-01, time/batch = 0.6616s	
13057/25300 (epoch 25.804), train_loss = 0.87754522, grad/param norm = 1.9149e-01, time/batch = 0.6667s	
13058/25300 (epoch 25.806), train_loss = 0.94183769, grad/param norm = 2.2459e-01, time/batch = 0.6621s	
13059/25300 (epoch 25.808), train_loss = 0.95682222, grad/param norm = 2.1580e-01, time/batch = 0.6567s	
13060/25300 (epoch 25.810), train_loss = 0.83614354, grad/param norm = 2.0132e-01, time/batch = 0.6595s	
13061/25300 (epoch 25.812), train_loss = 0.96550321, grad/param norm = 2.0541e-01, time/batch = 0.6623s	
13062/25300 (epoch 25.814), train_loss = 1.03454986, grad/param norm = 2.4530e-01, time/batch = 0.6817s	
13063/25300 (epoch 25.816), train_loss = 1.09848218, grad/param norm = 2.3347e-01, time/batch = 0.6684s	
13064/25300 (epoch 25.818), train_loss = 0.93006283, grad/param norm = 1.9060e-01, time/batch = 0.6659s	
13065/25300 (epoch 25.820), train_loss = 0.96701861, grad/param norm = 2.3445e-01, time/batch = 0.6593s	
13066/25300 (epoch 25.822), train_loss = 0.84569887, grad/param norm = 1.9478e-01, time/batch = 0.6556s	
13067/25300 (epoch 25.824), train_loss = 0.97443565, grad/param norm = 2.1074e-01, time/batch = 0.6669s	
13068/25300 (epoch 25.826), train_loss = 0.79849381, grad/param norm = 1.8881e-01, time/batch = 0.6549s	
13069/25300 (epoch 25.828), train_loss = 0.81757631, grad/param norm = 2.3103e-01, time/batch = 0.6599s	
13070/25300 (epoch 25.830), train_loss = 0.89431262, grad/param norm = 1.9340e-01, time/batch = 0.6632s	
13071/25300 (epoch 25.832), train_loss = 0.96916717, grad/param norm = 2.3441e-01, time/batch = 0.6634s	
13072/25300 (epoch 25.834), train_loss = 0.78660243, grad/param norm = 1.8697e-01, time/batch = 0.6614s	
13073/25300 (epoch 25.836), train_loss = 0.85646786, grad/param norm = 1.8926e-01, time/batch = 0.6598s	
13074/25300 (epoch 25.838), train_loss = 0.85456009, grad/param norm = 1.9442e-01, time/batch = 0.6559s	
13075/25300 (epoch 25.840), train_loss = 0.96730443, grad/param norm = 2.1386e-01, time/batch = 0.6586s	
13076/25300 (epoch 25.842), train_loss = 0.90055500, grad/param norm = 2.2570e-01, time/batch = 0.6607s	
13077/25300 (epoch 25.844), train_loss = 0.95750519, grad/param norm = 1.9033e-01, time/batch = 0.6582s	
13078/25300 (epoch 25.846), train_loss = 0.94593178, grad/param norm = 1.7618e-01, time/batch = 0.6609s	
13079/25300 (epoch 25.848), train_loss = 0.96514261, grad/param norm = 2.2026e-01, time/batch = 0.6618s	
13080/25300 (epoch 25.850), train_loss = 0.89769964, grad/param norm = 2.0375e-01, time/batch = 0.6563s	
13081/25300 (epoch 25.852), train_loss = 0.95933606, grad/param norm = 2.0801e-01, time/batch = 0.6700s	
13082/25300 (epoch 25.854), train_loss = 1.02625305, grad/param norm = 2.1671e-01, time/batch = 0.6600s	
13083/25300 (epoch 25.856), train_loss = 0.87064032, grad/param norm = 2.1915e-01, time/batch = 0.6608s	
13084/25300 (epoch 25.858), train_loss = 0.91018406, grad/param norm = 2.3478e-01, time/batch = 0.6625s	
13085/25300 (epoch 25.860), train_loss = 0.74683303, grad/param norm = 1.9595e-01, time/batch = 0.6616s	
13086/25300 (epoch 25.862), train_loss = 0.88996606, grad/param norm = 2.3530e-01, time/batch = 0.6619s	
13087/25300 (epoch 25.864), train_loss = 0.96665331, grad/param norm = 2.2393e-01, time/batch = 0.6612s	
13088/25300 (epoch 25.866), train_loss = 0.84892860, grad/param norm = 2.1392e-01, time/batch = 0.6582s	
13089/25300 (epoch 25.868), train_loss = 1.01087635, grad/param norm = 2.1737e-01, time/batch = 0.6633s	
13090/25300 (epoch 25.870), train_loss = 0.96658636, grad/param norm = 1.8013e-01, time/batch = 0.6550s	
13091/25300 (epoch 25.872), train_loss = 0.94877207, grad/param norm = 2.3352e-01, time/batch = 0.6679s	
13092/25300 (epoch 25.874), train_loss = 0.91717227, grad/param norm = 2.0616e-01, time/batch = 0.6623s	
13093/25300 (epoch 25.875), train_loss = 0.87700573, grad/param norm = 2.2388e-01, time/batch = 0.6637s	
13094/25300 (epoch 25.877), train_loss = 0.84664040, grad/param norm = 1.8325e-01, time/batch = 0.6626s	
13095/25300 (epoch 25.879), train_loss = 0.83110286, grad/param norm = 1.8756e-01, time/batch = 0.6578s	
13096/25300 (epoch 25.881), train_loss = 1.15234429, grad/param norm = 2.5008e-01, time/batch = 0.6595s	
13097/25300 (epoch 25.883), train_loss = 1.11709410, grad/param norm = 2.1988e-01, time/batch = 0.6592s	
13098/25300 (epoch 25.885), train_loss = 0.96601070, grad/param norm = 2.3234e-01, time/batch = 0.6608s	
13099/25300 (epoch 25.887), train_loss = 0.98481816, grad/param norm = 2.3391e-01, time/batch = 0.6620s	
13100/25300 (epoch 25.889), train_loss = 1.05171570, grad/param norm = 2.4842e-01, time/batch = 0.6645s	
13101/25300 (epoch 25.891), train_loss = 0.92258099, grad/param norm = 2.3556e-01, time/batch = 0.6594s	
13102/25300 (epoch 25.893), train_loss = 0.96016793, grad/param norm = 2.5665e-01, time/batch = 0.6567s	
13103/25300 (epoch 25.895), train_loss = 0.69091114, grad/param norm = 1.9684e-01, time/batch = 0.6604s	
13104/25300 (epoch 25.897), train_loss = 0.79078752, grad/param norm = 1.8395e-01, time/batch = 0.6552s	
13105/25300 (epoch 25.899), train_loss = 0.93392939, grad/param norm = 2.1777e-01, time/batch = 0.6666s	
13106/25300 (epoch 25.901), train_loss = 0.96027373, grad/param norm = 2.1149e-01, time/batch = 0.6660s	
13107/25300 (epoch 25.903), train_loss = 0.72983890, grad/param norm = 2.1843e-01, time/batch = 0.6660s	
13108/25300 (epoch 25.905), train_loss = 0.84707524, grad/param norm = 2.1750e-01, time/batch = 0.6699s	
13109/25300 (epoch 25.907), train_loss = 0.82991792, grad/param norm = 1.9525e-01, time/batch = 0.6612s	
13110/25300 (epoch 25.909), train_loss = 0.96383424, grad/param norm = 2.1216e-01, time/batch = 0.6620s	
13111/25300 (epoch 25.911), train_loss = 1.00891606, grad/param norm = 2.3950e-01, time/batch = 0.6614s	
13112/25300 (epoch 25.913), train_loss = 1.09974934, grad/param norm = 2.3086e-01, time/batch = 0.6583s	
13113/25300 (epoch 25.915), train_loss = 0.83169778, grad/param norm = 2.0311e-01, time/batch = 0.6722s	
13114/25300 (epoch 25.917), train_loss = 1.01944924, grad/param norm = 2.2827e-01, time/batch = 0.6686s	
13115/25300 (epoch 25.919), train_loss = 1.04665925, grad/param norm = 2.6501e-01, time/batch = 0.6670s	
13116/25300 (epoch 25.921), train_loss = 0.81790322, grad/param norm = 1.8846e-01, time/batch = 0.6612s	
13117/25300 (epoch 25.923), train_loss = 1.01267508, grad/param norm = 2.0402e-01, time/batch = 0.6640s	
13118/25300 (epoch 25.925), train_loss = 0.89001645, grad/param norm = 2.4465e-01, time/batch = 0.6669s	
13119/25300 (epoch 25.927), train_loss = 0.87329271, grad/param norm = 2.0742e-01, time/batch = 0.6578s	
13120/25300 (epoch 25.929), train_loss = 0.91782925, grad/param norm = 2.0064e-01, time/batch = 0.6696s	
13121/25300 (epoch 25.931), train_loss = 0.95606149, grad/param norm = 2.3593e-01, time/batch = 0.6761s	
13122/25300 (epoch 25.933), train_loss = 0.93699165, grad/param norm = 2.0211e-01, time/batch = 0.6692s	
13123/25300 (epoch 25.935), train_loss = 0.91652179, grad/param norm = 1.8863e-01, time/batch = 0.6510s	
13124/25300 (epoch 25.937), train_loss = 0.68897332, grad/param norm = 1.7911e-01, time/batch = 0.6583s	
13125/25300 (epoch 25.939), train_loss = 0.93178926, grad/param norm = 2.1449e-01, time/batch = 0.6594s	
13126/25300 (epoch 25.941), train_loss = 0.82154790, grad/param norm = 2.1466e-01, time/batch = 0.6604s	
13127/25300 (epoch 25.943), train_loss = 0.93161430, grad/param norm = 1.9281e-01, time/batch = 0.6599s	
13128/25300 (epoch 25.945), train_loss = 0.94617218, grad/param norm = 2.2485e-01, time/batch = 0.6583s	
13129/25300 (epoch 25.947), train_loss = 0.79913162, grad/param norm = 1.9266e-01, time/batch = 0.6596s	
13130/25300 (epoch 25.949), train_loss = 0.96213335, grad/param norm = 1.9735e-01, time/batch = 0.6585s	
13131/25300 (epoch 25.951), train_loss = 0.89674963, grad/param norm = 1.8468e-01, time/batch = 0.6613s	
13132/25300 (epoch 25.953), train_loss = 0.88745562, grad/param norm = 2.2157e-01, time/batch = 0.6749s	
13133/25300 (epoch 25.955), train_loss = 1.10797062, grad/param norm = 2.9452e-01, time/batch = 0.6667s	
13134/25300 (epoch 25.957), train_loss = 1.03002762, grad/param norm = 2.4108e-01, time/batch = 0.6666s	
13135/25300 (epoch 25.958), train_loss = 0.98656279, grad/param norm = 2.4702e-01, time/batch = 0.6632s	
13136/25300 (epoch 25.960), train_loss = 1.08714501, grad/param norm = 2.4127e-01, time/batch = 0.6696s	
13137/25300 (epoch 25.962), train_loss = 1.05169212, grad/param norm = 2.2777e-01, time/batch = 0.6645s	
13138/25300 (epoch 25.964), train_loss = 0.94778441, grad/param norm = 2.3218e-01, time/batch = 0.6654s	
13139/25300 (epoch 25.966), train_loss = 0.78834763, grad/param norm = 2.1104e-01, time/batch = 0.6682s	
13140/25300 (epoch 25.968), train_loss = 0.74180117, grad/param norm = 1.7939e-01, time/batch = 0.6601s	
13141/25300 (epoch 25.970), train_loss = 0.86761123, grad/param norm = 2.2089e-01, time/batch = 0.6670s	
13142/25300 (epoch 25.972), train_loss = 0.91008629, grad/param norm = 2.1031e-01, time/batch = 0.6586s	
13143/25300 (epoch 25.974), train_loss = 1.02715866, grad/param norm = 2.4194e-01, time/batch = 0.6608s	
13144/25300 (epoch 25.976), train_loss = 0.95570563, grad/param norm = 2.1930e-01, time/batch = 0.6538s	
13145/25300 (epoch 25.978), train_loss = 0.90711676, grad/param norm = 2.3768e-01, time/batch = 0.6570s	
13146/25300 (epoch 25.980), train_loss = 0.90854147, grad/param norm = 2.2385e-01, time/batch = 0.6580s	
13147/25300 (epoch 25.982), train_loss = 0.86560520, grad/param norm = 2.2072e-01, time/batch = 0.6597s	
13148/25300 (epoch 25.984), train_loss = 0.88783515, grad/param norm = 2.1111e-01, time/batch = 0.6576s	
13149/25300 (epoch 25.986), train_loss = 0.98527411, grad/param norm = 2.1335e-01, time/batch = 0.6562s	
13150/25300 (epoch 25.988), train_loss = 0.96635257, grad/param norm = 2.4829e-01, time/batch = 0.6596s	
13151/25300 (epoch 25.990), train_loss = 0.88563006, grad/param norm = 1.8399e-01, time/batch = 0.6641s	
13152/25300 (epoch 25.992), train_loss = 0.78685866, grad/param norm = 1.8815e-01, time/batch = 0.6620s	
13153/25300 (epoch 25.994), train_loss = 0.92783377, grad/param norm = 2.2616e-01, time/batch = 0.6629s	
13154/25300 (epoch 25.996), train_loss = 1.02720803, grad/param norm = 2.5071e-01, time/batch = 0.6605s	
13155/25300 (epoch 25.998), train_loss = 1.01829630, grad/param norm = 2.5485e-01, time/batch = 0.6624s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
13156/25300 (epoch 26.000), train_loss = 0.93067497, grad/param norm = 2.1225e-01, time/batch = 0.6590s	
13157/25300 (epoch 26.002), train_loss = 0.85070789, grad/param norm = 1.8726e-01, time/batch = 0.6639s	
13158/25300 (epoch 26.004), train_loss = 0.76243369, grad/param norm = 1.9706e-01, time/batch = 0.6632s	
13159/25300 (epoch 26.006), train_loss = 1.05096743, grad/param norm = 2.0672e-01, time/batch = 0.6641s	
13160/25300 (epoch 26.008), train_loss = 0.89879742, grad/param norm = 1.7702e-01, time/batch = 0.6667s	
13161/25300 (epoch 26.010), train_loss = 0.91646484, grad/param norm = 1.9291e-01, time/batch = 0.6731s	
13162/25300 (epoch 26.012), train_loss = 0.85654561, grad/param norm = 2.0780e-01, time/batch = 0.6658s	
13163/25300 (epoch 26.014), train_loss = 1.04066701, grad/param norm = 2.2732e-01, time/batch = 0.6686s	
13164/25300 (epoch 26.016), train_loss = 0.90453368, grad/param norm = 2.2394e-01, time/batch = 0.6817s	
13165/25300 (epoch 26.018), train_loss = 0.79570242, grad/param norm = 1.9384e-01, time/batch = 0.6606s	
13166/25300 (epoch 26.020), train_loss = 0.89338246, grad/param norm = 1.8814e-01, time/batch = 0.6616s	
13167/25300 (epoch 26.022), train_loss = 0.90727713, grad/param norm = 2.1919e-01, time/batch = 0.6630s	
13168/25300 (epoch 26.024), train_loss = 0.67299784, grad/param norm = 1.6059e-01, time/batch = 0.6574s	
13169/25300 (epoch 26.026), train_loss = 0.84702438, grad/param norm = 1.9947e-01, time/batch = 0.6598s	
13170/25300 (epoch 26.028), train_loss = 0.82484783, grad/param norm = 1.8056e-01, time/batch = 0.6586s	
13171/25300 (epoch 26.030), train_loss = 1.00656476, grad/param norm = 1.9076e-01, time/batch = 0.6656s	
13172/25300 (epoch 26.032), train_loss = 0.87085077, grad/param norm = 2.2348e-01, time/batch = 0.6590s	
13173/25300 (epoch 26.034), train_loss = 0.78126417, grad/param norm = 1.8813e-01, time/batch = 0.6518s	
13174/25300 (epoch 26.036), train_loss = 0.74820331, grad/param norm = 1.9528e-01, time/batch = 0.6606s	
13175/25300 (epoch 26.038), train_loss = 0.68684130, grad/param norm = 1.7484e-01, time/batch = 0.6598s	
13176/25300 (epoch 26.040), train_loss = 0.88687582, grad/param norm = 1.9595e-01, time/batch = 0.6641s	
13177/25300 (epoch 26.042), train_loss = 0.87073288, grad/param norm = 1.7776e-01, time/batch = 0.6618s	
13178/25300 (epoch 26.043), train_loss = 0.75959074, grad/param norm = 1.8203e-01, time/batch = 0.6639s	
13179/25300 (epoch 26.045), train_loss = 0.74715645, grad/param norm = 1.8187e-01, time/batch = 0.6609s	
13180/25300 (epoch 26.047), train_loss = 0.93017495, grad/param norm = 1.8912e-01, time/batch = 0.6596s	
13181/25300 (epoch 26.049), train_loss = 0.91292649, grad/param norm = 2.1134e-01, time/batch = 0.6657s	
13182/25300 (epoch 26.051), train_loss = 0.99609762, grad/param norm = 2.0863e-01, time/batch = 0.6587s	
13183/25300 (epoch 26.053), train_loss = 0.70800336, grad/param norm = 1.6322e-01, time/batch = 0.6582s	
13184/25300 (epoch 26.055), train_loss = 0.75887129, grad/param norm = 1.7959e-01, time/batch = 0.6623s	
13185/25300 (epoch 26.057), train_loss = 0.72403099, grad/param norm = 1.6180e-01, time/batch = 0.6628s	
13186/25300 (epoch 26.059), train_loss = 0.82278599, grad/param norm = 1.8705e-01, time/batch = 0.6572s	
13187/25300 (epoch 26.061), train_loss = 0.81480676, grad/param norm = 2.2793e-01, time/batch = 0.6696s	
13188/25300 (epoch 26.063), train_loss = 0.80810849, grad/param norm = 1.8983e-01, time/batch = 0.6627s	
13189/25300 (epoch 26.065), train_loss = 0.90370573, grad/param norm = 2.3036e-01, time/batch = 0.6632s	
13190/25300 (epoch 26.067), train_loss = 0.96954592, grad/param norm = 2.0876e-01, time/batch = 0.6610s	
13191/25300 (epoch 26.069), train_loss = 0.80081037, grad/param norm = 2.0119e-01, time/batch = 0.6637s	
13192/25300 (epoch 26.071), train_loss = 0.96667201, grad/param norm = 2.2612e-01, time/batch = 0.6556s	
13193/25300 (epoch 26.073), train_loss = 0.82904209, grad/param norm = 1.7852e-01, time/batch = 0.6585s	
13194/25300 (epoch 26.075), train_loss = 0.95075876, grad/param norm = 2.1814e-01, time/batch = 0.6616s	
13195/25300 (epoch 26.077), train_loss = 0.91633577, grad/param norm = 2.0769e-01, time/batch = 0.6626s	
13196/25300 (epoch 26.079), train_loss = 0.83919938, grad/param norm = 2.1292e-01, time/batch = 0.6680s	
13197/25300 (epoch 26.081), train_loss = 0.86306863, grad/param norm = 1.6825e-01, time/batch = 0.6717s	
13198/25300 (epoch 26.083), train_loss = 0.86820224, grad/param norm = 1.8540e-01, time/batch = 0.6726s	
13199/25300 (epoch 26.085), train_loss = 1.07162835, grad/param norm = 2.1867e-01, time/batch = 0.6663s	
13200/25300 (epoch 26.087), train_loss = 0.96656271, grad/param norm = 1.9284e-01, time/batch = 0.6665s	
13201/25300 (epoch 26.089), train_loss = 0.93177129, grad/param norm = 1.9584e-01, time/batch = 0.6678s	
13202/25300 (epoch 26.091), train_loss = 1.04544530, grad/param norm = 2.2176e-01, time/batch = 0.6664s	
13203/25300 (epoch 26.093), train_loss = 1.00344539, grad/param norm = 2.3717e-01, time/batch = 0.6777s	
13204/25300 (epoch 26.095), train_loss = 0.95678604, grad/param norm = 2.0363e-01, time/batch = 0.6693s	
13205/25300 (epoch 26.097), train_loss = 0.94980599, grad/param norm = 2.1813e-01, time/batch = 0.6757s	
13206/25300 (epoch 26.099), train_loss = 0.94201255, grad/param norm = 2.2585e-01, time/batch = 0.6641s	
13207/25300 (epoch 26.101), train_loss = 0.84681516, grad/param norm = 2.0196e-01, time/batch = 0.6586s	
13208/25300 (epoch 26.103), train_loss = 0.89241079, grad/param norm = 1.9773e-01, time/batch = 0.6646s	
13209/25300 (epoch 26.105), train_loss = 0.96461477, grad/param norm = 2.1132e-01, time/batch = 0.6617s	
13210/25300 (epoch 26.107), train_loss = 0.96955038, grad/param norm = 2.3921e-01, time/batch = 0.6584s	
13211/25300 (epoch 26.109), train_loss = 0.87127599, grad/param norm = 2.2138e-01, time/batch = 0.6641s	
13212/25300 (epoch 26.111), train_loss = 0.86193830, grad/param norm = 1.9403e-01, time/batch = 0.6586s	
13213/25300 (epoch 26.113), train_loss = 0.82539633, grad/param norm = 2.0353e-01, time/batch = 0.6578s	
13214/25300 (epoch 26.115), train_loss = 0.87996113, grad/param norm = 2.0948e-01, time/batch = 0.6620s	
13215/25300 (epoch 26.117), train_loss = 0.96870704, grad/param norm = 2.1593e-01, time/batch = 0.6558s	
13216/25300 (epoch 26.119), train_loss = 0.85186780, grad/param norm = 2.1879e-01, time/batch = 0.6610s	
13217/25300 (epoch 26.121), train_loss = 0.92271189, grad/param norm = 2.4593e-01, time/batch = 0.6581s	
13218/25300 (epoch 26.123), train_loss = 0.83579734, grad/param norm = 2.0169e-01, time/batch = 0.6597s	
13219/25300 (epoch 26.125), train_loss = 0.95820393, grad/param norm = 1.9682e-01, time/batch = 0.6590s	
13220/25300 (epoch 26.126), train_loss = 0.87824111, grad/param norm = 1.9502e-01, time/batch = 0.6570s	
13221/25300 (epoch 26.128), train_loss = 0.87577386, grad/param norm = 2.1904e-01, time/batch = 0.6588s	
13222/25300 (epoch 26.130), train_loss = 0.71042160, grad/param norm = 1.7928e-01, time/batch = 0.6581s	
13223/25300 (epoch 26.132), train_loss = 0.74892221, grad/param norm = 1.8913e-01, time/batch = 0.6661s	
13224/25300 (epoch 26.134), train_loss = 0.72218186, grad/param norm = 1.6599e-01, time/batch = 0.6601s	
13225/25300 (epoch 26.136), train_loss = 0.85094931, grad/param norm = 1.7964e-01, time/batch = 0.6578s	
13226/25300 (epoch 26.138), train_loss = 0.76684552, grad/param norm = 1.7975e-01, time/batch = 0.6606s	
13227/25300 (epoch 26.140), train_loss = 0.78144642, grad/param norm = 1.8808e-01, time/batch = 0.6578s	
13228/25300 (epoch 26.142), train_loss = 0.96338076, grad/param norm = 2.0548e-01, time/batch = 0.6613s	
13229/25300 (epoch 26.144), train_loss = 0.94912622, grad/param norm = 2.0795e-01, time/batch = 0.6570s	
13230/25300 (epoch 26.146), train_loss = 0.91177957, grad/param norm = 2.2676e-01, time/batch = 0.6610s	
13231/25300 (epoch 26.148), train_loss = 0.86104289, grad/param norm = 1.9035e-01, time/batch = 0.6610s	
13232/25300 (epoch 26.150), train_loss = 0.96865741, grad/param norm = 2.3112e-01, time/batch = 0.6630s	
13233/25300 (epoch 26.152), train_loss = 1.03278884, grad/param norm = 2.3228e-01, time/batch = 0.6614s	
13234/25300 (epoch 26.154), train_loss = 0.74047792, grad/param norm = 1.7364e-01, time/batch = 0.6587s	
13235/25300 (epoch 26.156), train_loss = 0.94132069, grad/param norm = 2.1014e-01, time/batch = 0.6633s	
13236/25300 (epoch 26.158), train_loss = 0.79150343, grad/param norm = 1.8217e-01, time/batch = 0.6567s	
13237/25300 (epoch 26.160), train_loss = 0.87850797, grad/param norm = 1.9833e-01, time/batch = 0.6538s	
13238/25300 (epoch 26.162), train_loss = 0.83855557, grad/param norm = 2.0049e-01, time/batch = 0.6543s	
13239/25300 (epoch 26.164), train_loss = 0.93680310, grad/param norm = 2.1594e-01, time/batch = 0.6547s	
13240/25300 (epoch 26.166), train_loss = 0.88517321, grad/param norm = 1.8797e-01, time/batch = 0.6600s	
13241/25300 (epoch 26.168), train_loss = 0.80771758, grad/param norm = 1.8226e-01, time/batch = 0.6584s	
13242/25300 (epoch 26.170), train_loss = 0.81746571, grad/param norm = 1.9633e-01, time/batch = 0.6619s	
13243/25300 (epoch 26.172), train_loss = 0.77260120, grad/param norm = 1.8275e-01, time/batch = 0.6584s	
13244/25300 (epoch 26.174), train_loss = 0.78528987, grad/param norm = 1.8588e-01, time/batch = 0.6637s	
13245/25300 (epoch 26.176), train_loss = 0.79711984, grad/param norm = 2.1438e-01, time/batch = 0.6654s	
13246/25300 (epoch 26.178), train_loss = 0.99661809, grad/param norm = 2.0367e-01, time/batch = 0.6585s	
13247/25300 (epoch 26.180), train_loss = 0.72694140, grad/param norm = 1.7251e-01, time/batch = 0.6626s	
13248/25300 (epoch 26.182), train_loss = 0.81873322, grad/param norm = 1.9862e-01, time/batch = 0.6648s	
13249/25300 (epoch 26.184), train_loss = 0.79692802, grad/param norm = 2.2278e-01, time/batch = 0.6605s	
13250/25300 (epoch 26.186), train_loss = 0.77363480, grad/param norm = 1.9970e-01, time/batch = 0.6629s	
13251/25300 (epoch 26.188), train_loss = 0.88739644, grad/param norm = 2.2116e-01, time/batch = 0.6581s	
13252/25300 (epoch 26.190), train_loss = 0.82303386, grad/param norm = 1.9988e-01, time/batch = 0.6574s	
13253/25300 (epoch 26.192), train_loss = 0.85497854, grad/param norm = 2.1043e-01, time/batch = 0.6615s	
13254/25300 (epoch 26.194), train_loss = 0.85470089, grad/param norm = 2.1218e-01, time/batch = 0.6556s	
13255/25300 (epoch 26.196), train_loss = 0.97653187, grad/param norm = 2.4702e-01, time/batch = 0.6610s	
13256/25300 (epoch 26.198), train_loss = 0.82168338, grad/param norm = 2.4199e-01, time/batch = 0.6574s	
13257/25300 (epoch 26.200), train_loss = 0.83288668, grad/param norm = 2.1810e-01, time/batch = 0.6640s	
13258/25300 (epoch 26.202), train_loss = 0.86475064, grad/param norm = 1.9349e-01, time/batch = 0.6609s	
13259/25300 (epoch 26.204), train_loss = 0.85089681, grad/param norm = 2.1564e-01, time/batch = 0.6575s	
13260/25300 (epoch 26.206), train_loss = 0.96478968, grad/param norm = 2.1044e-01, time/batch = 0.6588s	
13261/25300 (epoch 26.208), train_loss = 0.77330935, grad/param norm = 2.0797e-01, time/batch = 0.6628s	
13262/25300 (epoch 26.209), train_loss = 0.72888438, grad/param norm = 1.8607e-01, time/batch = 0.6607s	
13263/25300 (epoch 26.211), train_loss = 0.82419666, grad/param norm = 1.7617e-01, time/batch = 0.6599s	
13264/25300 (epoch 26.213), train_loss = 0.90776349, grad/param norm = 2.1302e-01, time/batch = 0.6566s	
13265/25300 (epoch 26.215), train_loss = 0.86663407, grad/param norm = 1.9668e-01, time/batch = 0.6559s	
13266/25300 (epoch 26.217), train_loss = 0.90952257, grad/param norm = 2.2980e-01, time/batch = 0.6597s	
13267/25300 (epoch 26.219), train_loss = 0.96477525, grad/param norm = 2.1819e-01, time/batch = 0.6562s	
13268/25300 (epoch 26.221), train_loss = 1.02007334, grad/param norm = 2.1305e-01, time/batch = 0.6558s	
13269/25300 (epoch 26.223), train_loss = 0.94952990, grad/param norm = 2.4387e-01, time/batch = 0.6617s	
13270/25300 (epoch 26.225), train_loss = 1.22567296, grad/param norm = 2.9223e-01, time/batch = 0.6615s	
13271/25300 (epoch 26.227), train_loss = 1.00667887, grad/param norm = 2.2245e-01, time/batch = 0.6589s	
13272/25300 (epoch 26.229), train_loss = 0.86077380, grad/param norm = 1.9481e-01, time/batch = 0.6593s	
13273/25300 (epoch 26.231), train_loss = 0.86583328, grad/param norm = 1.8995e-01, time/batch = 0.6624s	
13274/25300 (epoch 26.233), train_loss = 0.95593611, grad/param norm = 2.1944e-01, time/batch = 0.6606s	
13275/25300 (epoch 26.235), train_loss = 0.87267913, grad/param norm = 1.9792e-01, time/batch = 0.6610s	
13276/25300 (epoch 26.237), train_loss = 1.02741819, grad/param norm = 2.1762e-01, time/batch = 0.6607s	
13277/25300 (epoch 26.239), train_loss = 0.83969037, grad/param norm = 1.9451e-01, time/batch = 0.6579s	
13278/25300 (epoch 26.241), train_loss = 1.01224477, grad/param norm = 2.1717e-01, time/batch = 0.6590s	
13279/25300 (epoch 26.243), train_loss = 1.16066913, grad/param norm = 2.5468e-01, time/batch = 0.6559s	
13280/25300 (epoch 26.245), train_loss = 0.82979670, grad/param norm = 2.0643e-01, time/batch = 0.6603s	
13281/25300 (epoch 26.247), train_loss = 0.97083370, grad/param norm = 2.2683e-01, time/batch = 0.6643s	
13282/25300 (epoch 26.249), train_loss = 0.76032566, grad/param norm = 1.8563e-01, time/batch = 0.6631s	
13283/25300 (epoch 26.251), train_loss = 0.76575600, grad/param norm = 1.6625e-01, time/batch = 0.6610s	
13284/25300 (epoch 26.253), train_loss = 0.85603498, grad/param norm = 1.8258e-01, time/batch = 0.6582s	
13285/25300 (epoch 26.255), train_loss = 0.81665208, grad/param norm = 2.3216e-01, time/batch = 0.6570s	
13286/25300 (epoch 26.257), train_loss = 0.86798968, grad/param norm = 2.2115e-01, time/batch = 0.6655s	
13287/25300 (epoch 26.259), train_loss = 1.06951762, grad/param norm = 2.5955e-01, time/batch = 0.6663s	
13288/25300 (epoch 26.261), train_loss = 1.03104164, grad/param norm = 2.4617e-01, time/batch = 0.6824s	
13289/25300 (epoch 26.263), train_loss = 1.03404459, grad/param norm = 2.3556e-01, time/batch = 0.6684s	
13290/25300 (epoch 26.265), train_loss = 1.06504333, grad/param norm = 2.2873e-01, time/batch = 0.6687s	
13291/25300 (epoch 26.267), train_loss = 0.98613879, grad/param norm = 2.2060e-01, time/batch = 0.6668s	
13292/25300 (epoch 26.269), train_loss = 0.75238365, grad/param norm = 1.8356e-01, time/batch = 0.6578s	
13293/25300 (epoch 26.271), train_loss = 0.82914781, grad/param norm = 2.3094e-01, time/batch = 0.6644s	
13294/25300 (epoch 26.273), train_loss = 0.96843038, grad/param norm = 2.6696e-01, time/batch = 0.6576s	
13295/25300 (epoch 26.275), train_loss = 0.85306925, grad/param norm = 1.7051e-01, time/batch = 0.6620s	
13296/25300 (epoch 26.277), train_loss = 0.85557650, grad/param norm = 2.1326e-01, time/batch = 0.6555s	
13297/25300 (epoch 26.279), train_loss = 0.88663421, grad/param norm = 2.0620e-01, time/batch = 0.6592s	
13298/25300 (epoch 26.281), train_loss = 1.03901140, grad/param norm = 2.3976e-01, time/batch = 0.6577s	
13299/25300 (epoch 26.283), train_loss = 0.78454129, grad/param norm = 2.1168e-01, time/batch = 0.6568s	
13300/25300 (epoch 26.285), train_loss = 0.92013742, grad/param norm = 2.2570e-01, time/batch = 0.6655s	
13301/25300 (epoch 26.287), train_loss = 0.95670081, grad/param norm = 1.9184e-01, time/batch = 0.6608s	
13302/25300 (epoch 26.289), train_loss = 0.86619898, grad/param norm = 2.1039e-01, time/batch = 0.6636s	
13303/25300 (epoch 26.291), train_loss = 0.84961125, grad/param norm = 1.9211e-01, time/batch = 0.6570s	
13304/25300 (epoch 26.292), train_loss = 1.05666184, grad/param norm = 2.2373e-01, time/batch = 0.6549s	
13305/25300 (epoch 26.294), train_loss = 0.92598804, grad/param norm = 2.1656e-01, time/batch = 0.6628s	
13306/25300 (epoch 26.296), train_loss = 0.78815292, grad/param norm = 2.9333e-01, time/batch = 0.6541s	
13307/25300 (epoch 26.298), train_loss = 0.99999326, grad/param norm = 2.3909e-01, time/batch = 0.6615s	
13308/25300 (epoch 26.300), train_loss = 0.99719863, grad/param norm = 2.5532e-01, time/batch = 0.6560s	
13309/25300 (epoch 26.302), train_loss = 0.72774639, grad/param norm = 2.1669e-01, time/batch = 0.6532s	
13310/25300 (epoch 26.304), train_loss = 0.96761512, grad/param norm = 1.9772e-01, time/batch = 0.6588s	
13311/25300 (epoch 26.306), train_loss = 0.69968133, grad/param norm = 1.8782e-01, time/batch = 0.6571s	
13312/25300 (epoch 26.308), train_loss = 0.95064564, grad/param norm = 1.9543e-01, time/batch = 0.6618s	
13313/25300 (epoch 26.310), train_loss = 0.78831226, grad/param norm = 2.0197e-01, time/batch = 0.6570s	
13314/25300 (epoch 26.312), train_loss = 0.90758524, grad/param norm = 1.8920e-01, time/batch = 0.6652s	
13315/25300 (epoch 26.314), train_loss = 0.73280155, grad/param norm = 1.9367e-01, time/batch = 0.6581s	
13316/25300 (epoch 26.316), train_loss = 0.89505739, grad/param norm = 1.9820e-01, time/batch = 0.6623s	
13317/25300 (epoch 26.318), train_loss = 0.72472189, grad/param norm = 1.7792e-01, time/batch = 0.6630s	
13318/25300 (epoch 26.320), train_loss = 0.79981518, grad/param norm = 1.8435e-01, time/batch = 0.6595s	
13319/25300 (epoch 26.322), train_loss = 1.05086683, grad/param norm = 2.4393e-01, time/batch = 0.6628s	
13320/25300 (epoch 26.324), train_loss = 0.79649360, grad/param norm = 1.8742e-01, time/batch = 0.6600s	
13321/25300 (epoch 26.326), train_loss = 0.72252246, grad/param norm = 1.7533e-01, time/batch = 0.6584s	
13322/25300 (epoch 26.328), train_loss = 0.71161524, grad/param norm = 2.0601e-01, time/batch = 0.6606s	
13323/25300 (epoch 26.330), train_loss = 0.85696582, grad/param norm = 2.0646e-01, time/batch = 0.6567s	
13324/25300 (epoch 26.332), train_loss = 0.88826396, grad/param norm = 2.0985e-01, time/batch = 0.6600s	
13325/25300 (epoch 26.334), train_loss = 0.72425369, grad/param norm = 1.9215e-01, time/batch = 0.6560s	
13326/25300 (epoch 26.336), train_loss = 0.75437142, grad/param norm = 2.3074e-01, time/batch = 0.6583s	
13327/25300 (epoch 26.338), train_loss = 0.76172770, grad/param norm = 1.7204e-01, time/batch = 0.6631s	
13328/25300 (epoch 26.340), train_loss = 0.78605591, grad/param norm = 1.8555e-01, time/batch = 0.6599s	
13329/25300 (epoch 26.342), train_loss = 0.85816537, grad/param norm = 3.8220e-01, time/batch = 0.6606s	
13330/25300 (epoch 26.344), train_loss = 0.91370864, grad/param norm = 1.9699e-01, time/batch = 0.6631s	
13331/25300 (epoch 26.346), train_loss = 0.83746726, grad/param norm = 2.3959e-01, time/batch = 0.6635s	
13332/25300 (epoch 26.348), train_loss = 0.76638724, grad/param norm = 1.9004e-01, time/batch = 0.6588s	
13333/25300 (epoch 26.350), train_loss = 0.85725172, grad/param norm = 2.1720e-01, time/batch = 0.6608s	
13334/25300 (epoch 26.352), train_loss = 0.87304081, grad/param norm = 2.0536e-01, time/batch = 0.6564s	
13335/25300 (epoch 26.354), train_loss = 0.81519956, grad/param norm = 2.2318e-01, time/batch = 0.6558s	
13336/25300 (epoch 26.356), train_loss = 0.85912678, grad/param norm = 2.0284e-01, time/batch = 0.6593s	
13337/25300 (epoch 26.358), train_loss = 0.91777625, grad/param norm = 2.3549e-01, time/batch = 0.6563s	
13338/25300 (epoch 26.360), train_loss = 0.78115187, grad/param norm = 1.8820e-01, time/batch = 0.6631s	
13339/25300 (epoch 26.362), train_loss = 0.78781957, grad/param norm = 2.0119e-01, time/batch = 0.6654s	
13340/25300 (epoch 26.364), train_loss = 0.79933710, grad/param norm = 2.0563e-01, time/batch = 0.6633s	
13341/25300 (epoch 26.366), train_loss = 0.74751842, grad/param norm = 1.9400e-01, time/batch = 0.6591s	
13342/25300 (epoch 26.368), train_loss = 0.85104726, grad/param norm = 1.9673e-01, time/batch = 0.6604s	
13343/25300 (epoch 26.370), train_loss = 0.80267493, grad/param norm = 2.0539e-01, time/batch = 0.6586s	
13344/25300 (epoch 26.372), train_loss = 0.81030860, grad/param norm = 2.2313e-01, time/batch = 0.6610s	
13345/25300 (epoch 26.374), train_loss = 0.72886477, grad/param norm = 1.9080e-01, time/batch = 0.6554s	
13346/25300 (epoch 26.375), train_loss = 0.96909164, grad/param norm = 2.3204e-01, time/batch = 0.6621s	
13347/25300 (epoch 26.377), train_loss = 0.94039698, grad/param norm = 2.1166e-01, time/batch = 0.6599s	
13348/25300 (epoch 26.379), train_loss = 0.89965724, grad/param norm = 2.2186e-01, time/batch = 0.6637s	
13349/25300 (epoch 26.381), train_loss = 0.82380346, grad/param norm = 1.8053e-01, time/batch = 0.6561s	
13350/25300 (epoch 26.383), train_loss = 0.77205623, grad/param norm = 1.9133e-01, time/batch = 0.6583s	
13351/25300 (epoch 26.385), train_loss = 0.86051019, grad/param norm = 1.8884e-01, time/batch = 0.6654s	
13352/25300 (epoch 26.387), train_loss = 0.88858809, grad/param norm = 2.0446e-01, time/batch = 0.6622s	
13353/25300 (epoch 26.389), train_loss = 0.87729671, grad/param norm = 2.0934e-01, time/batch = 0.6672s	
13354/25300 (epoch 26.391), train_loss = 0.81388163, grad/param norm = 1.7409e-01, time/batch = 0.6595s	
13355/25300 (epoch 26.393), train_loss = 0.86690991, grad/param norm = 2.3089e-01, time/batch = 0.6675s	
13356/25300 (epoch 26.395), train_loss = 0.69534549, grad/param norm = 1.8312e-01, time/batch = 0.6729s	
13357/25300 (epoch 26.397), train_loss = 0.72166243, grad/param norm = 1.9748e-01, time/batch = 0.6724s	
13358/25300 (epoch 26.399), train_loss = 0.72691421, grad/param norm = 2.0323e-01, time/batch = 0.6691s	
13359/25300 (epoch 26.401), train_loss = 0.91642221, grad/param norm = 2.1988e-01, time/batch = 0.6695s	
13360/25300 (epoch 26.403), train_loss = 0.87105524, grad/param norm = 2.2061e-01, time/batch = 0.6585s	
13361/25300 (epoch 26.405), train_loss = 0.83737882, grad/param norm = 1.9334e-01, time/batch = 0.6621s	
13362/25300 (epoch 26.407), train_loss = 0.83533830, grad/param norm = 1.9662e-01, time/batch = 0.6588s	
13363/25300 (epoch 26.409), train_loss = 0.79258976, grad/param norm = 2.0470e-01, time/batch = 0.6583s	
13364/25300 (epoch 26.411), train_loss = 0.79322416, grad/param norm = 2.0692e-01, time/batch = 0.6810s	
13365/25300 (epoch 26.413), train_loss = 0.70444468, grad/param norm = 1.8818e-01, time/batch = 0.6687s	
13366/25300 (epoch 26.415), train_loss = 0.74673108, grad/param norm = 1.8735e-01, time/batch = 0.6624s	
13367/25300 (epoch 26.417), train_loss = 0.70945508, grad/param norm = 1.7174e-01, time/batch = 0.6594s	
13368/25300 (epoch 26.419), train_loss = 0.66741802, grad/param norm = 1.7582e-01, time/batch = 0.6639s	
13369/25300 (epoch 26.421), train_loss = 0.73721683, grad/param norm = 1.6020e-01, time/batch = 0.6639s	
13370/25300 (epoch 26.423), train_loss = 0.73251555, grad/param norm = 1.7742e-01, time/batch = 0.6604s	
13371/25300 (epoch 26.425), train_loss = 0.81723045, grad/param norm = 2.2364e-01, time/batch = 0.6639s	
13372/25300 (epoch 26.427), train_loss = 0.95765755, grad/param norm = 1.9958e-01, time/batch = 0.6587s	
13373/25300 (epoch 26.429), train_loss = 0.94606375, grad/param norm = 2.3073e-01, time/batch = 0.6554s	
13374/25300 (epoch 26.431), train_loss = 0.88450159, grad/param norm = 1.9751e-01, time/batch = 0.6606s	
13375/25300 (epoch 26.433), train_loss = 0.85520468, grad/param norm = 1.9648e-01, time/batch = 0.6570s	
13376/25300 (epoch 26.435), train_loss = 0.78735107, grad/param norm = 1.9699e-01, time/batch = 0.6642s	
13377/25300 (epoch 26.437), train_loss = 0.78075370, grad/param norm = 1.8692e-01, time/batch = 0.6667s	
13378/25300 (epoch 26.439), train_loss = 0.87079677, grad/param norm = 1.9852e-01, time/batch = 0.6796s	
13379/25300 (epoch 26.441), train_loss = 0.89260498, grad/param norm = 2.1695e-01, time/batch = 0.6773s	
13380/25300 (epoch 26.443), train_loss = 1.04220143, grad/param norm = 2.3726e-01, time/batch = 0.6632s	
13381/25300 (epoch 26.445), train_loss = 0.98197023, grad/param norm = 2.3047e-01, time/batch = 0.6662s	
13382/25300 (epoch 26.447), train_loss = 0.77451406, grad/param norm = 1.7829e-01, time/batch = 0.6634s	
13383/25300 (epoch 26.449), train_loss = 0.71436163, grad/param norm = 1.9941e-01, time/batch = 0.6751s	
13384/25300 (epoch 26.451), train_loss = 1.03984349, grad/param norm = 2.2382e-01, time/batch = 0.6688s	
13385/25300 (epoch 26.453), train_loss = 0.90998466, grad/param norm = 2.1911e-01, time/batch = 0.6641s	
13386/25300 (epoch 26.455), train_loss = 0.91194690, grad/param norm = 2.5496e-01, time/batch = 0.6585s	
13387/25300 (epoch 26.457), train_loss = 0.80716504, grad/param norm = 2.1370e-01, time/batch = 0.6630s	
13388/25300 (epoch 26.458), train_loss = 0.80714910, grad/param norm = 1.9819e-01, time/batch = 0.6579s	
13389/25300 (epoch 26.460), train_loss = 0.83742846, grad/param norm = 2.1626e-01, time/batch = 0.6564s	
13390/25300 (epoch 26.462), train_loss = 0.61475777, grad/param norm = 1.8196e-01, time/batch = 0.6639s	
13391/25300 (epoch 26.464), train_loss = 0.91318615, grad/param norm = 2.0580e-01, time/batch = 0.6606s	
13392/25300 (epoch 26.466), train_loss = 0.91809641, grad/param norm = 2.3043e-01, time/batch = 0.6620s	
13393/25300 (epoch 26.468), train_loss = 0.91481925, grad/param norm = 2.1659e-01, time/batch = 0.6683s	
13394/25300 (epoch 26.470), train_loss = 0.82442526, grad/param norm = 2.0443e-01, time/batch = 0.6666s	
13395/25300 (epoch 26.472), train_loss = 0.72506203, grad/param norm = 1.8490e-01, time/batch = 0.6610s	
13396/25300 (epoch 26.474), train_loss = 0.91699879, grad/param norm = 2.1061e-01, time/batch = 0.6666s	
13397/25300 (epoch 26.476), train_loss = 0.82144488, grad/param norm = 1.9877e-01, time/batch = 0.6677s	
13398/25300 (epoch 26.478), train_loss = 0.91452796, grad/param norm = 2.2445e-01, time/batch = 0.6654s	
13399/25300 (epoch 26.480), train_loss = 0.81637429, grad/param norm = 1.9411e-01, time/batch = 0.6634s	
13400/25300 (epoch 26.482), train_loss = 0.90699642, grad/param norm = 2.3898e-01, time/batch = 0.6603s	
13401/25300 (epoch 26.484), train_loss = 0.93432217, grad/param norm = 2.8768e-01, time/batch = 0.6649s	
13402/25300 (epoch 26.486), train_loss = 0.86910913, grad/param norm = 2.1911e-01, time/batch = 0.6606s	
13403/25300 (epoch 26.488), train_loss = 1.00978878, grad/param norm = 2.2134e-01, time/batch = 0.6633s	
13404/25300 (epoch 26.490), train_loss = 0.91300041, grad/param norm = 2.0619e-01, time/batch = 0.6593s	
13405/25300 (epoch 26.492), train_loss = 0.95665116, grad/param norm = 2.2481e-01, time/batch = 0.6612s	
13406/25300 (epoch 26.494), train_loss = 0.82394901, grad/param norm = 2.1352e-01, time/batch = 0.6576s	
13407/25300 (epoch 26.496), train_loss = 0.87844452, grad/param norm = 2.1410e-01, time/batch = 0.6582s	
13408/25300 (epoch 26.498), train_loss = 0.81220622, grad/param norm = 1.9423e-01, time/batch = 0.6592s	
13409/25300 (epoch 26.500), train_loss = 1.01311585, grad/param norm = 2.3697e-01, time/batch = 0.6538s	
13410/25300 (epoch 26.502), train_loss = 0.93224208, grad/param norm = 2.2907e-01, time/batch = 0.6649s	
13411/25300 (epoch 26.504), train_loss = 0.83936495, grad/param norm = 2.1153e-01, time/batch = 0.6635s	
13412/25300 (epoch 26.506), train_loss = 0.77286756, grad/param norm = 2.0661e-01, time/batch = 0.6594s	
13413/25300 (epoch 26.508), train_loss = 0.85360494, grad/param norm = 2.3528e-01, time/batch = 0.6617s	
13414/25300 (epoch 26.510), train_loss = 0.78562856, grad/param norm = 2.0677e-01, time/batch = 0.6585s	
13415/25300 (epoch 26.512), train_loss = 0.63122789, grad/param norm = 1.7120e-01, time/batch = 0.6637s	
13416/25300 (epoch 26.514), train_loss = 0.83257606, grad/param norm = 1.9374e-01, time/batch = 0.6618s	
13417/25300 (epoch 26.516), train_loss = 0.91334447, grad/param norm = 2.2079e-01, time/batch = 0.6635s	
13418/25300 (epoch 26.518), train_loss = 0.93757322, grad/param norm = 2.1602e-01, time/batch = 0.6667s	
13419/25300 (epoch 26.520), train_loss = 0.70796659, grad/param norm = 1.5824e-01, time/batch = 0.6671s	
13420/25300 (epoch 26.522), train_loss = 0.80095809, grad/param norm = 2.0497e-01, time/batch = 0.6730s	
13421/25300 (epoch 26.524), train_loss = 0.80244360, grad/param norm = 2.0137e-01, time/batch = 0.6821s	
13422/25300 (epoch 26.526), train_loss = 0.97498536, grad/param norm = 2.1101e-01, time/batch = 0.6766s	
13423/25300 (epoch 26.528), train_loss = 1.00408392, grad/param norm = 2.1028e-01, time/batch = 0.6697s	
13424/25300 (epoch 26.530), train_loss = 0.88881030, grad/param norm = 2.1417e-01, time/batch = 0.6677s	
13425/25300 (epoch 26.532), train_loss = 0.82758784, grad/param norm = 1.9000e-01, time/batch = 0.6712s	
13426/25300 (epoch 26.534), train_loss = 0.83394057, grad/param norm = 2.0571e-01, time/batch = 0.6796s	
13427/25300 (epoch 26.536), train_loss = 0.66452753, grad/param norm = 1.6575e-01, time/batch = 0.6709s	
13428/25300 (epoch 26.538), train_loss = 0.74781188, grad/param norm = 1.7682e-01, time/batch = 0.6715s	
13429/25300 (epoch 26.540), train_loss = 0.77343604, grad/param norm = 1.9758e-01, time/batch = 0.6791s	
13430/25300 (epoch 26.542), train_loss = 0.74171833, grad/param norm = 1.6908e-01, time/batch = 0.6845s	
13431/25300 (epoch 26.543), train_loss = 0.72033967, grad/param norm = 1.8387e-01, time/batch = 0.6847s	
13432/25300 (epoch 26.545), train_loss = 1.04727903, grad/param norm = 2.3937e-01, time/batch = 0.6766s	
13433/25300 (epoch 26.547), train_loss = 0.92317215, grad/param norm = 2.0746e-01, time/batch = 0.6574s	
13434/25300 (epoch 26.549), train_loss = 1.08685059, grad/param norm = 2.5921e-01, time/batch = 0.6539s	
13435/25300 (epoch 26.551), train_loss = 0.93695563, grad/param norm = 2.0227e-01, time/batch = 0.6582s	
13436/25300 (epoch 26.553), train_loss = 0.78510074, grad/param norm = 2.3334e-01, time/batch = 0.6514s	
13437/25300 (epoch 26.555), train_loss = 0.94565581, grad/param norm = 2.4384e-01, time/batch = 0.6572s	
13438/25300 (epoch 26.557), train_loss = 0.96948481, grad/param norm = 2.3782e-01, time/batch = 0.6579s	
13439/25300 (epoch 26.559), train_loss = 0.98364148, grad/param norm = 2.3379e-01, time/batch = 0.6573s	
13440/25300 (epoch 26.561), train_loss = 0.98513303, grad/param norm = 2.0936e-01, time/batch = 0.6592s	
13441/25300 (epoch 26.563), train_loss = 0.94972644, grad/param norm = 2.1134e-01, time/batch = 0.6592s	
13442/25300 (epoch 26.565), train_loss = 0.74688566, grad/param norm = 1.9150e-01, time/batch = 0.6580s	
13443/25300 (epoch 26.567), train_loss = 0.68555541, grad/param norm = 1.9566e-01, time/batch = 0.6582s	
13444/25300 (epoch 26.569), train_loss = 0.86278181, grad/param norm = 2.1259e-01, time/batch = 0.6586s	
13445/25300 (epoch 26.571), train_loss = 0.95994129, grad/param norm = 2.2084e-01, time/batch = 0.6572s	
13446/25300 (epoch 26.573), train_loss = 0.85174792, grad/param norm = 2.0297e-01, time/batch = 0.6592s	
13447/25300 (epoch 26.575), train_loss = 0.95987044, grad/param norm = 1.9993e-01, time/batch = 0.6598s	
13448/25300 (epoch 26.577), train_loss = 0.84511698, grad/param norm = 2.2377e-01, time/batch = 0.6587s	
13449/25300 (epoch 26.579), train_loss = 0.99119230, grad/param norm = 2.2583e-01, time/batch = 0.6615s	
13450/25300 (epoch 26.581), train_loss = 0.94015272, grad/param norm = 2.2462e-01, time/batch = 0.6626s	
13451/25300 (epoch 26.583), train_loss = 0.73439621, grad/param norm = 2.0571e-01, time/batch = 0.6624s	
13452/25300 (epoch 26.585), train_loss = 0.72160351, grad/param norm = 2.0110e-01, time/batch = 0.6659s	
13453/25300 (epoch 26.587), train_loss = 0.83012054, grad/param norm = 2.0291e-01, time/batch = 0.6589s	
13454/25300 (epoch 26.589), train_loss = 0.73825375, grad/param norm = 1.7561e-01, time/batch = 0.6639s	
13455/25300 (epoch 26.591), train_loss = 0.73065853, grad/param norm = 2.0603e-01, time/batch = 0.6632s	
13456/25300 (epoch 26.593), train_loss = 0.92464202, grad/param norm = 1.9989e-01, time/batch = 0.6619s	
13457/25300 (epoch 26.595), train_loss = 0.85025639, grad/param norm = 2.0980e-01, time/batch = 0.6595s	
13458/25300 (epoch 26.597), train_loss = 0.74607841, grad/param norm = 1.9999e-01, time/batch = 0.6576s	
13459/25300 (epoch 26.599), train_loss = 0.91662734, grad/param norm = 2.2225e-01, time/batch = 0.6632s	
13460/25300 (epoch 26.601), train_loss = 0.84569496, grad/param norm = 2.1596e-01, time/batch = 0.6584s	
13461/25300 (epoch 26.603), train_loss = 0.84840243, grad/param norm = 2.0619e-01, time/batch = 0.6616s	
13462/25300 (epoch 26.605), train_loss = 0.79559908, grad/param norm = 2.1356e-01, time/batch = 0.6560s	
13463/25300 (epoch 26.607), train_loss = 0.61834164, grad/param norm = 1.6337e-01, time/batch = 0.6532s	
13464/25300 (epoch 26.609), train_loss = 0.81413026, grad/param norm = 2.0909e-01, time/batch = 0.6561s	
13465/25300 (epoch 26.611), train_loss = 0.86877676, grad/param norm = 2.1570e-01, time/batch = 0.6544s	
13466/25300 (epoch 26.613), train_loss = 0.73281497, grad/param norm = 1.7767e-01, time/batch = 0.6649s	
13467/25300 (epoch 26.615), train_loss = 0.83178819, grad/param norm = 2.9113e-01, time/batch = 0.6653s	
13468/25300 (epoch 26.617), train_loss = 0.88138010, grad/param norm = 2.3461e-01, time/batch = 0.6803s	
13469/25300 (epoch 26.619), train_loss = 0.95151107, grad/param norm = 2.1312e-01, time/batch = 0.6735s	
13470/25300 (epoch 26.621), train_loss = 0.95010559, grad/param norm = 2.3164e-01, time/batch = 0.6595s	
13471/25300 (epoch 26.623), train_loss = 0.78406684, grad/param norm = 2.1117e-01, time/batch = 0.6571s	
13472/25300 (epoch 26.625), train_loss = 0.69724562, grad/param norm = 1.8171e-01, time/batch = 0.6628s	
13473/25300 (epoch 26.626), train_loss = 0.83593020, grad/param norm = 1.9664e-01, time/batch = 0.6575s	
13474/25300 (epoch 26.628), train_loss = 0.93780579, grad/param norm = 2.7165e-01, time/batch = 0.6578s	
13475/25300 (epoch 26.630), train_loss = 0.94542232, grad/param norm = 2.7226e-01, time/batch = 0.6604s	
13476/25300 (epoch 26.632), train_loss = 0.88545034, grad/param norm = 2.3634e-01, time/batch = 0.6599s	
13477/25300 (epoch 26.634), train_loss = 1.00066064, grad/param norm = 2.7414e-01, time/batch = 0.6617s	
13478/25300 (epoch 26.636), train_loss = 0.77948957, grad/param norm = 2.0709e-01, time/batch = 0.6608s	
13479/25300 (epoch 26.638), train_loss = 0.88693634, grad/param norm = 2.4681e-01, time/batch = 0.6628s	
13480/25300 (epoch 26.640), train_loss = 1.03150090, grad/param norm = 2.4660e-01, time/batch = 0.6569s	
13481/25300 (epoch 26.642), train_loss = 0.88933929, grad/param norm = 2.2477e-01, time/batch = 0.6612s	
13482/25300 (epoch 26.644), train_loss = 0.89581312, grad/param norm = 2.1495e-01, time/batch = 0.6595s	
13483/25300 (epoch 26.646), train_loss = 0.80506348, grad/param norm = 2.3568e-01, time/batch = 0.6567s	
13484/25300 (epoch 26.648), train_loss = 0.94064879, grad/param norm = 2.0251e-01, time/batch = 0.6586s	
13485/25300 (epoch 26.650), train_loss = 0.88676917, grad/param norm = 2.0544e-01, time/batch = 0.6561s	
13486/25300 (epoch 26.652), train_loss = 0.89606170, grad/param norm = 2.6277e-01, time/batch = 0.6549s	
13487/25300 (epoch 26.654), train_loss = 0.99152775, grad/param norm = 1.9586e-01, time/batch = 0.6596s	
13488/25300 (epoch 26.656), train_loss = 0.92596627, grad/param norm = 2.2225e-01, time/batch = 0.6650s	
13489/25300 (epoch 26.658), train_loss = 0.70982549, grad/param norm = 1.6952e-01, time/batch = 0.6599s	
13490/25300 (epoch 26.660), train_loss = 0.75228728, grad/param norm = 2.2660e-01, time/batch = 0.6619s	
13491/25300 (epoch 26.662), train_loss = 0.72666481, grad/param norm = 1.9840e-01, time/batch = 0.6675s	
13492/25300 (epoch 26.664), train_loss = 0.70834672, grad/param norm = 2.0440e-01, time/batch = 0.6661s	
13493/25300 (epoch 26.666), train_loss = 0.76781563, grad/param norm = 2.5852e-01, time/batch = 0.6673s	
13494/25300 (epoch 26.668), train_loss = 0.83669877, grad/param norm = 2.4005e-01, time/batch = 0.6651s	
13495/25300 (epoch 26.670), train_loss = 0.77446801, grad/param norm = 2.0350e-01, time/batch = 0.6658s	
13496/25300 (epoch 26.672), train_loss = 0.75011432, grad/param norm = 1.7112e-01, time/batch = 0.6644s	
13497/25300 (epoch 26.674), train_loss = 0.78206633, grad/param norm = 1.9193e-01, time/batch = 0.6648s	
13498/25300 (epoch 26.676), train_loss = 0.79936793, grad/param norm = 2.2045e-01, time/batch = 0.6678s	
13499/25300 (epoch 26.678), train_loss = 0.80364730, grad/param norm = 2.2548e-01, time/batch = 0.6574s	
13500/25300 (epoch 26.680), train_loss = 0.69326682, grad/param norm = 1.6883e-01, time/batch = 0.6639s	
13501/25300 (epoch 26.682), train_loss = 0.58920026, grad/param norm = 1.7133e-01, time/batch = 0.6665s	
13502/25300 (epoch 26.684), train_loss = 0.74884036, grad/param norm = 1.7962e-01, time/batch = 0.6579s	
13503/25300 (epoch 26.686), train_loss = 0.70978118, grad/param norm = 1.7742e-01, time/batch = 0.6638s	
13504/25300 (epoch 26.688), train_loss = 0.81137198, grad/param norm = 2.1023e-01, time/batch = 0.6571s	
13505/25300 (epoch 26.690), train_loss = 0.72512052, grad/param norm = 1.7938e-01, time/batch = 0.6607s	
13506/25300 (epoch 26.692), train_loss = 0.75279808, grad/param norm = 1.6995e-01, time/batch = 0.6610s	
13507/25300 (epoch 26.694), train_loss = 0.79075995, grad/param norm = 1.9712e-01, time/batch = 0.6593s	
13508/25300 (epoch 26.696), train_loss = 0.87030071, grad/param norm = 2.1793e-01, time/batch = 0.6522s	
13509/25300 (epoch 26.698), train_loss = 0.89014985, grad/param norm = 1.9827e-01, time/batch = 0.6609s	
13510/25300 (epoch 26.700), train_loss = 0.66639582, grad/param norm = 1.8842e-01, time/batch = 0.6578s	
13511/25300 (epoch 26.702), train_loss = 0.89145933, grad/param norm = 2.1497e-01, time/batch = 0.6583s	
13512/25300 (epoch 26.704), train_loss = 0.67742997, grad/param norm = 1.8444e-01, time/batch = 0.6621s	
13513/25300 (epoch 26.706), train_loss = 0.80990805, grad/param norm = 2.0984e-01, time/batch = 0.6589s	
13514/25300 (epoch 26.708), train_loss = 0.69449698, grad/param norm = 1.8341e-01, time/batch = 0.6603s	
13515/25300 (epoch 26.709), train_loss = 0.99609057, grad/param norm = 2.3586e-01, time/batch = 0.6616s	
13516/25300 (epoch 26.711), train_loss = 1.00095839, grad/param norm = 2.1990e-01, time/batch = 0.6652s	
13517/25300 (epoch 26.713), train_loss = 0.82301180, grad/param norm = 1.7978e-01, time/batch = 0.6596s	
13518/25300 (epoch 26.715), train_loss = 0.82551203, grad/param norm = 1.8686e-01, time/batch = 0.6568s	
13519/25300 (epoch 26.717), train_loss = 0.76410191, grad/param norm = 2.0471e-01, time/batch = 0.6619s	
13520/25300 (epoch 26.719), train_loss = 0.81847342, grad/param norm = 2.0117e-01, time/batch = 0.6581s	
13521/25300 (epoch 26.721), train_loss = 0.88587293, grad/param norm = 2.5176e-01, time/batch = 0.6599s	
13522/25300 (epoch 26.723), train_loss = 0.80999043, grad/param norm = 1.9589e-01, time/batch = 0.6628s	
13523/25300 (epoch 26.725), train_loss = 0.87401480, grad/param norm = 2.1229e-01, time/batch = 0.6604s	
13524/25300 (epoch 26.727), train_loss = 0.83231473, grad/param norm = 2.0151e-01, time/batch = 0.6618s	
13525/25300 (epoch 26.729), train_loss = 0.83359302, grad/param norm = 1.9424e-01, time/batch = 0.6604s	
13526/25300 (epoch 26.731), train_loss = 0.98254909, grad/param norm = 2.1103e-01, time/batch = 0.6611s	
13527/25300 (epoch 26.733), train_loss = 0.82876245, grad/param norm = 1.9902e-01, time/batch = 0.6578s	
13528/25300 (epoch 26.735), train_loss = 1.09401167, grad/param norm = 2.3451e-01, time/batch = 0.6572s	
13529/25300 (epoch 26.737), train_loss = 0.72315809, grad/param norm = 1.8554e-01, time/batch = 0.6588s	
13530/25300 (epoch 26.739), train_loss = 0.99015552, grad/param norm = 2.3356e-01, time/batch = 0.6621s	
13531/25300 (epoch 26.741), train_loss = 0.89889916, grad/param norm = 2.1319e-01, time/batch = 0.6672s	
13532/25300 (epoch 26.743), train_loss = 0.83172913, grad/param norm = 1.8919e-01, time/batch = 0.6575s	
13533/25300 (epoch 26.745), train_loss = 0.80225985, grad/param norm = 2.0667e-01, time/batch = 0.6604s	
13534/25300 (epoch 26.747), train_loss = 0.75365993, grad/param norm = 1.8065e-01, time/batch = 0.6619s	
13535/25300 (epoch 26.749), train_loss = 0.85080117, grad/param norm = 2.1779e-01, time/batch = 0.6571s	
13536/25300 (epoch 26.751), train_loss = 0.91554401, grad/param norm = 2.1760e-01, time/batch = 0.6589s	
13537/25300 (epoch 26.753), train_loss = 0.73820038, grad/param norm = 2.0346e-01, time/batch = 0.6560s	
13538/25300 (epoch 26.755), train_loss = 0.95417746, grad/param norm = 2.5406e-01, time/batch = 0.6602s	
13539/25300 (epoch 26.757), train_loss = 0.77895898, grad/param norm = 1.9686e-01, time/batch = 0.6560s	
13540/25300 (epoch 26.759), train_loss = 0.76947457, grad/param norm = 2.0626e-01, time/batch = 0.6530s	
13541/25300 (epoch 26.761), train_loss = 0.98372155, grad/param norm = 2.0651e-01, time/batch = 0.6588s	
13542/25300 (epoch 26.763), train_loss = 0.80070506, grad/param norm = 1.8581e-01, time/batch = 0.6594s	
13543/25300 (epoch 26.765), train_loss = 0.83015407, grad/param norm = 2.3539e-01, time/batch = 0.6573s	
13544/25300 (epoch 26.767), train_loss = 0.81888275, grad/param norm = 1.9781e-01, time/batch = 0.6603s	
13545/25300 (epoch 26.769), train_loss = 0.84844429, grad/param norm = 2.2470e-01, time/batch = 0.6602s	
13546/25300 (epoch 26.771), train_loss = 0.95400212, grad/param norm = 2.1632e-01, time/batch = 0.6579s	
13547/25300 (epoch 26.773), train_loss = 0.98179602, grad/param norm = 2.3826e-01, time/batch = 0.6596s	
13548/25300 (epoch 26.775), train_loss = 0.84015411, grad/param norm = 1.8742e-01, time/batch = 0.6588s	
13549/25300 (epoch 26.777), train_loss = 0.83112251, grad/param norm = 2.1541e-01, time/batch = 0.6632s	
13550/25300 (epoch 26.779), train_loss = 0.93099245, grad/param norm = 2.0458e-01, time/batch = 0.6606s	
13551/25300 (epoch 26.781), train_loss = 0.88377753, grad/param norm = 2.0009e-01, time/batch = 0.6598s	
13552/25300 (epoch 26.783), train_loss = 0.97733856, grad/param norm = 2.2247e-01, time/batch = 0.6606s	
13553/25300 (epoch 26.785), train_loss = 0.93028219, grad/param norm = 2.1751e-01, time/batch = 0.6571s	
13554/25300 (epoch 26.787), train_loss = 0.90802840, grad/param norm = 2.2572e-01, time/batch = 0.6603s	
13555/25300 (epoch 26.789), train_loss = 1.03397199, grad/param norm = 2.3665e-01, time/batch = 0.6597s	
13556/25300 (epoch 26.791), train_loss = 0.90990275, grad/param norm = 2.1594e-01, time/batch = 0.6604s	
13557/25300 (epoch 26.792), train_loss = 0.97244069, grad/param norm = 2.1845e-01, time/batch = 0.6652s	
13558/25300 (epoch 26.794), train_loss = 0.85709275, grad/param norm = 2.1109e-01, time/batch = 0.6670s	
13559/25300 (epoch 26.796), train_loss = 0.82460449, grad/param norm = 2.2643e-01, time/batch = 0.6651s	
13560/25300 (epoch 26.798), train_loss = 0.94552549, grad/param norm = 2.3219e-01, time/batch = 0.6557s	
13561/25300 (epoch 26.800), train_loss = 0.81058269, grad/param norm = 1.8638e-01, time/batch = 0.6612s	
13562/25300 (epoch 26.802), train_loss = 0.66980951, grad/param norm = 1.7562e-01, time/batch = 0.6560s	
13563/25300 (epoch 26.804), train_loss = 0.86198204, grad/param norm = 2.2095e-01, time/batch = 0.6632s	
13564/25300 (epoch 26.806), train_loss = 0.91962658, grad/param norm = 2.3360e-01, time/batch = 0.6679s	
13565/25300 (epoch 26.808), train_loss = 0.95183421, grad/param norm = 2.1681e-01, time/batch = 0.6639s	
13566/25300 (epoch 26.810), train_loss = 0.83469104, grad/param norm = 2.0575e-01, time/batch = 0.6620s	
13567/25300 (epoch 26.812), train_loss = 0.96763016, grad/param norm = 2.2027e-01, time/batch = 0.6606s	
13568/25300 (epoch 26.814), train_loss = 0.99785447, grad/param norm = 2.1445e-01, time/batch = 0.6601s	
13569/25300 (epoch 26.816), train_loss = 1.08720158, grad/param norm = 2.4102e-01, time/batch = 0.6607s	
13570/25300 (epoch 26.818), train_loss = 0.91321872, grad/param norm = 1.9356e-01, time/batch = 0.6591s	
13571/25300 (epoch 26.820), train_loss = 0.95341143, grad/param norm = 2.0096e-01, time/batch = 0.6708s	
13572/25300 (epoch 26.822), train_loss = 0.82214095, grad/param norm = 2.0049e-01, time/batch = 0.6677s	
13573/25300 (epoch 26.824), train_loss = 0.96400955, grad/param norm = 2.1359e-01, time/batch = 0.6772s	
13574/25300 (epoch 26.826), train_loss = 0.77637213, grad/param norm = 1.7482e-01, time/batch = 0.6644s	
13575/25300 (epoch 26.828), train_loss = 0.79117776, grad/param norm = 2.0022e-01, time/batch = 0.6609s	
13576/25300 (epoch 26.830), train_loss = 0.88309328, grad/param norm = 2.0156e-01, time/batch = 0.6576s	
13577/25300 (epoch 26.832), train_loss = 0.94075031, grad/param norm = 2.1316e-01, time/batch = 0.6594s	
13578/25300 (epoch 26.834), train_loss = 0.75953990, grad/param norm = 1.8786e-01, time/batch = 0.6631s	
13579/25300 (epoch 26.836), train_loss = 0.83953120, grad/param norm = 1.8632e-01, time/batch = 0.6594s	
13580/25300 (epoch 26.838), train_loss = 0.84879614, grad/param norm = 2.1555e-01, time/batch = 0.6589s	
13581/25300 (epoch 26.840), train_loss = 0.94840170, grad/param norm = 2.1837e-01, time/batch = 0.6576s	
13582/25300 (epoch 26.842), train_loss = 0.89383852, grad/param norm = 2.4590e-01, time/batch = 0.6634s	
13583/25300 (epoch 26.844), train_loss = 0.94855362, grad/param norm = 1.9381e-01, time/batch = 0.6592s	
13584/25300 (epoch 26.846), train_loss = 0.93008109, grad/param norm = 1.9020e-01, time/batch = 0.6638s	
13585/25300 (epoch 26.848), train_loss = 0.94176874, grad/param norm = 2.4592e-01, time/batch = 0.6586s	
13586/25300 (epoch 26.850), train_loss = 0.89376528, grad/param norm = 2.1234e-01, time/batch = 0.6564s	
13587/25300 (epoch 26.852), train_loss = 0.93384770, grad/param norm = 2.0115e-01, time/batch = 0.6621s	
13588/25300 (epoch 26.854), train_loss = 0.99734791, grad/param norm = 2.0646e-01, time/batch = 0.6589s	
13589/25300 (epoch 26.856), train_loss = 0.84030745, grad/param norm = 1.9884e-01, time/batch = 0.6624s	
13590/25300 (epoch 26.858), train_loss = 0.87582317, grad/param norm = 2.1868e-01, time/batch = 0.6603s	
13591/25300 (epoch 26.860), train_loss = 0.73895296, grad/param norm = 2.0742e-01, time/batch = 0.6665s	
13592/25300 (epoch 26.862), train_loss = 0.86846007, grad/param norm = 2.1551e-01, time/batch = 0.6592s	
13593/25300 (epoch 26.864), train_loss = 0.95764111, grad/param norm = 2.1770e-01, time/batch = 0.6636s	
13594/25300 (epoch 26.866), train_loss = 0.83734760, grad/param norm = 2.1954e-01, time/batch = 0.6605s	
13595/25300 (epoch 26.868), train_loss = 1.00634030, grad/param norm = 2.1434e-01, time/batch = 0.6639s	
13596/25300 (epoch 26.870), train_loss = 0.96834145, grad/param norm = 2.0324e-01, time/batch = 0.6613s	
13597/25300 (epoch 26.872), train_loss = 0.92051718, grad/param norm = 2.5229e-01, time/batch = 0.6636s	
13598/25300 (epoch 26.874), train_loss = 0.90995191, grad/param norm = 2.0258e-01, time/batch = 0.6599s	
13599/25300 (epoch 26.875), train_loss = 0.85289362, grad/param norm = 2.0958e-01, time/batch = 0.6634s	
13600/25300 (epoch 26.877), train_loss = 0.85678057, grad/param norm = 1.9674e-01, time/batch = 0.6617s	
13601/25300 (epoch 26.879), train_loss = 0.81583838, grad/param norm = 2.3684e-01, time/batch = 0.6643s	
13602/25300 (epoch 26.881), train_loss = 1.14887654, grad/param norm = 2.6529e-01, time/batch = 0.6613s	
13603/25300 (epoch 26.883), train_loss = 1.09409860, grad/param norm = 2.2280e-01, time/batch = 0.6563s	
13604/25300 (epoch 26.885), train_loss = 0.93507442, grad/param norm = 2.3043e-01, time/batch = 0.6569s	
13605/25300 (epoch 26.887), train_loss = 0.97502411, grad/param norm = 2.1096e-01, time/batch = 0.6618s	
13606/25300 (epoch 26.889), train_loss = 1.04825429, grad/param norm = 2.5645e-01, time/batch = 0.6650s	
13607/25300 (epoch 26.891), train_loss = 0.93666134, grad/param norm = 2.7157e-01, time/batch = 0.6627s	
13608/25300 (epoch 26.893), train_loss = 0.94095494, grad/param norm = 3.8483e-01, time/batch = 0.6590s	
13609/25300 (epoch 26.895), train_loss = 0.67125474, grad/param norm = 1.7745e-01, time/batch = 0.6600s	
13610/25300 (epoch 26.897), train_loss = 0.79037104, grad/param norm = 2.1833e-01, time/batch = 0.6639s	
13611/25300 (epoch 26.899), train_loss = 0.91658464, grad/param norm = 2.1647e-01, time/batch = 0.6604s	
13612/25300 (epoch 26.901), train_loss = 0.93368966, grad/param norm = 2.0229e-01, time/batch = 0.6591s	
13613/25300 (epoch 26.903), train_loss = 0.73779253, grad/param norm = 2.3215e-01, time/batch = 0.6613s	
13614/25300 (epoch 26.905), train_loss = 0.83650374, grad/param norm = 2.5086e-01, time/batch = 0.6599s	
13615/25300 (epoch 26.907), train_loss = 0.82240814, grad/param norm = 2.2628e-01, time/batch = 0.6596s	
13616/25300 (epoch 26.909), train_loss = 0.95288979, grad/param norm = 2.3705e-01, time/batch = 0.6739s	
13617/25300 (epoch 26.911), train_loss = 1.00512782, grad/param norm = 2.5298e-01, time/batch = 0.6690s	
13618/25300 (epoch 26.913), train_loss = 1.08647925, grad/param norm = 2.5379e-01, time/batch = 0.6637s	
13619/25300 (epoch 26.915), train_loss = 0.82546700, grad/param norm = 2.0778e-01, time/batch = 0.6612s	
13620/25300 (epoch 26.917), train_loss = 1.01881387, grad/param norm = 2.3789e-01, time/batch = 0.6610s	
13621/25300 (epoch 26.919), train_loss = 1.02665044, grad/param norm = 2.7244e-01, time/batch = 0.6728s	
13622/25300 (epoch 26.921), train_loss = 0.83495333, grad/param norm = 2.2729e-01, time/batch = 0.6700s	
13623/25300 (epoch 26.923), train_loss = 1.00091918, grad/param norm = 2.2286e-01, time/batch = 0.6764s	
13624/25300 (epoch 26.925), train_loss = 0.87790319, grad/param norm = 2.3945e-01, time/batch = 0.6704s	
13625/25300 (epoch 26.927), train_loss = 0.84829750, grad/param norm = 1.9240e-01, time/batch = 0.6734s	
13626/25300 (epoch 26.929), train_loss = 0.90300122, grad/param norm = 1.9999e-01, time/batch = 0.6690s	
13627/25300 (epoch 26.931), train_loss = 0.95891327, grad/param norm = 2.5678e-01, time/batch = 0.6670s	
13628/25300 (epoch 26.933), train_loss = 0.89985406, grad/param norm = 1.9561e-01, time/batch = 0.6605s	
13629/25300 (epoch 26.935), train_loss = 0.91009458, grad/param norm = 1.9557e-01, time/batch = 0.6618s	
13630/25300 (epoch 26.937), train_loss = 0.68243269, grad/param norm = 1.7163e-01, time/batch = 0.6707s	
13631/25300 (epoch 26.939), train_loss = 0.91175132, grad/param norm = 1.9962e-01, time/batch = 0.6623s	
13632/25300 (epoch 26.941), train_loss = 0.80828765, grad/param norm = 2.1812e-01, time/batch = 0.6602s	
13633/25300 (epoch 26.943), train_loss = 0.93618293, grad/param norm = 2.1419e-01, time/batch = 0.6601s	
13634/25300 (epoch 26.945), train_loss = 0.91683749, grad/param norm = 2.0846e-01, time/batch = 0.6619s	
13635/25300 (epoch 26.947), train_loss = 0.78998643, grad/param norm = 1.9650e-01, time/batch = 0.6606s	
13636/25300 (epoch 26.949), train_loss = 0.93547831, grad/param norm = 1.9425e-01, time/batch = 0.6575s	
13637/25300 (epoch 26.951), train_loss = 0.88414647, grad/param norm = 1.9058e-01, time/batch = 0.6563s	
13638/25300 (epoch 26.953), train_loss = 0.87681542, grad/param norm = 1.9901e-01, time/batch = 0.6607s	
13639/25300 (epoch 26.955), train_loss = 1.08522961, grad/param norm = 2.4134e-01, time/batch = 0.6566s	
13640/25300 (epoch 26.957), train_loss = 0.99952256, grad/param norm = 2.2914e-01, time/batch = 0.6581s	
13641/25300 (epoch 26.958), train_loss = 0.97307548, grad/param norm = 2.3213e-01, time/batch = 0.6606s	
13642/25300 (epoch 26.960), train_loss = 1.06683216, grad/param norm = 2.3584e-01, time/batch = 0.6595s	
13643/25300 (epoch 26.962), train_loss = 1.03737758, grad/param norm = 2.2930e-01, time/batch = 0.6595s	
13644/25300 (epoch 26.964), train_loss = 0.94523493, grad/param norm = 2.2758e-01, time/batch = 0.6585s	
13645/25300 (epoch 26.966), train_loss = 0.77599500, grad/param norm = 2.0882e-01, time/batch = 0.6561s	
13646/25300 (epoch 26.968), train_loss = 0.73551464, grad/param norm = 1.9220e-01, time/batch = 0.6593s	
13647/25300 (epoch 26.970), train_loss = 0.85773333, grad/param norm = 2.2821e-01, time/batch = 0.6655s	
13648/25300 (epoch 26.972), train_loss = 0.89146502, grad/param norm = 1.9425e-01, time/batch = 0.6657s	
13649/25300 (epoch 26.974), train_loss = 1.00498904, grad/param norm = 2.2726e-01, time/batch = 0.6599s	
13650/25300 (epoch 26.976), train_loss = 0.95511269, grad/param norm = 2.3649e-01, time/batch = 0.6581s	
13651/25300 (epoch 26.978), train_loss = 0.87568869, grad/param norm = 2.0265e-01, time/batch = 0.6782s	
13652/25300 (epoch 26.980), train_loss = 0.89022160, grad/param norm = 2.3385e-01, time/batch = 0.6568s	
13653/25300 (epoch 26.982), train_loss = 0.83771118, grad/param norm = 2.0191e-01, time/batch = 0.6552s	
13654/25300 (epoch 26.984), train_loss = 0.86849597, grad/param norm = 2.0116e-01, time/batch = 0.6577s	
13655/25300 (epoch 26.986), train_loss = 0.97620397, grad/param norm = 2.1736e-01, time/batch = 0.6551s	
13656/25300 (epoch 26.988), train_loss = 0.94412445, grad/param norm = 2.5422e-01, time/batch = 0.6567s	
13657/25300 (epoch 26.990), train_loss = 0.89160933, grad/param norm = 2.0720e-01, time/batch = 0.6575s	
13658/25300 (epoch 26.992), train_loss = 0.77822484, grad/param norm = 1.9691e-01, time/batch = 0.6544s	
13659/25300 (epoch 26.994), train_loss = 0.90671149, grad/param norm = 2.1655e-01, time/batch = 0.6561s	
13660/25300 (epoch 26.996), train_loss = 0.99548078, grad/param norm = 2.3635e-01, time/batch = 0.6594s	
13661/25300 (epoch 26.998), train_loss = 1.01005055, grad/param norm = 2.5327e-01, time/batch = 0.6644s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
13662/25300 (epoch 27.000), train_loss = 0.94067403, grad/param norm = 2.2161e-01, time/batch = 0.6575s	
13663/25300 (epoch 27.002), train_loss = 0.83806500, grad/param norm = 1.7830e-01, time/batch = 0.6605s	
13664/25300 (epoch 27.004), train_loss = 0.75054151, grad/param norm = 2.0159e-01, time/batch = 0.6578s	
13665/25300 (epoch 27.006), train_loss = 1.02599052, grad/param norm = 2.0793e-01, time/batch = 0.6563s	
13666/25300 (epoch 27.008), train_loss = 0.88510110, grad/param norm = 1.9072e-01, time/batch = 0.6589s	
13667/25300 (epoch 27.010), train_loss = 0.90032548, grad/param norm = 2.0519e-01, time/batch = 0.6592s	
13668/25300 (epoch 27.012), train_loss = 0.84260765, grad/param norm = 2.0143e-01, time/batch = 0.6581s	
13669/25300 (epoch 27.014), train_loss = 1.01723449, grad/param norm = 2.2124e-01, time/batch = 0.6595s	
13670/25300 (epoch 27.016), train_loss = 0.88672452, grad/param norm = 2.0418e-01, time/batch = 0.6632s	
13671/25300 (epoch 27.018), train_loss = 0.78623142, grad/param norm = 1.9250e-01, time/batch = 0.6663s	
13672/25300 (epoch 27.020), train_loss = 0.89160757, grad/param norm = 2.0097e-01, time/batch = 0.6610s	
13673/25300 (epoch 27.022), train_loss = 0.89691893, grad/param norm = 2.3670e-01, time/batch = 0.6573s	
13674/25300 (epoch 27.024), train_loss = 0.65599685, grad/param norm = 1.4881e-01, time/batch = 0.6611s	
13675/25300 (epoch 27.026), train_loss = 0.83684773, grad/param norm = 2.0430e-01, time/batch = 0.6602s	
13676/25300 (epoch 27.028), train_loss = 0.81526388, grad/param norm = 1.8555e-01, time/batch = 0.6611s	
13677/25300 (epoch 27.030), train_loss = 0.98123378, grad/param norm = 1.8991e-01, time/batch = 0.6604s	
13678/25300 (epoch 27.032), train_loss = 0.83136400, grad/param norm = 1.9890e-01, time/batch = 0.6632s	
13679/25300 (epoch 27.034), train_loss = 0.76159036, grad/param norm = 2.0114e-01, time/batch = 0.6638s	
13680/25300 (epoch 27.036), train_loss = 0.72926749, grad/param norm = 1.8770e-01, time/batch = 0.6626s	
13681/25300 (epoch 27.038), train_loss = 0.68245937, grad/param norm = 1.8544e-01, time/batch = 0.6651s	
13682/25300 (epoch 27.040), train_loss = 0.88979595, grad/param norm = 2.8210e-01, time/batch = 0.6635s	
13683/25300 (epoch 27.042), train_loss = 0.85254745, grad/param norm = 1.8687e-01, time/batch = 0.6638s	
13684/25300 (epoch 27.043), train_loss = 0.74674949, grad/param norm = 1.7369e-01, time/batch = 0.6644s	
13685/25300 (epoch 27.045), train_loss = 0.74522707, grad/param norm = 1.8303e-01, time/batch = 0.6629s	
13686/25300 (epoch 27.047), train_loss = 0.91484143, grad/param norm = 1.9692e-01, time/batch = 0.6626s	
13687/25300 (epoch 27.049), train_loss = 0.89164529, grad/param norm = 2.3572e-01, time/batch = 0.6626s	
13688/25300 (epoch 27.051), train_loss = 0.99459403, grad/param norm = 2.2756e-01, time/batch = 0.6638s	
13689/25300 (epoch 27.053), train_loss = 0.71166652, grad/param norm = 1.8846e-01, time/batch = 0.6650s	
13690/25300 (epoch 27.055), train_loss = 0.72935084, grad/param norm = 1.8635e-01, time/batch = 0.6628s	
13691/25300 (epoch 27.057), train_loss = 0.72167435, grad/param norm = 1.6382e-01, time/batch = 0.6648s	
13692/25300 (epoch 27.059), train_loss = 0.80317261, grad/param norm = 1.9159e-01, time/batch = 0.6615s	
13693/25300 (epoch 27.061), train_loss = 0.80699377, grad/param norm = 2.4079e-01, time/batch = 0.6624s	
13694/25300 (epoch 27.063), train_loss = 0.78269361, grad/param norm = 1.7740e-01, time/batch = 0.6622s	
13695/25300 (epoch 27.065), train_loss = 0.88437848, grad/param norm = 2.3337e-01, time/batch = 0.6600s	
13696/25300 (epoch 27.067), train_loss = 0.95629564, grad/param norm = 2.0945e-01, time/batch = 0.6602s	
13697/25300 (epoch 27.069), train_loss = 0.78827414, grad/param norm = 2.0809e-01, time/batch = 0.6601s	
13698/25300 (epoch 27.071), train_loss = 0.94904524, grad/param norm = 2.2094e-01, time/batch = 0.6603s	
13699/25300 (epoch 27.073), train_loss = 0.82235621, grad/param norm = 1.8384e-01, time/batch = 0.6779s	
13700/25300 (epoch 27.075), train_loss = 0.93602793, grad/param norm = 2.1863e-01, time/batch = 0.6681s	
13701/25300 (epoch 27.077), train_loss = 0.90392855, grad/param norm = 2.0033e-01, time/batch = 0.6657s	
13702/25300 (epoch 27.079), train_loss = 0.81469121, grad/param norm = 1.9706e-01, time/batch = 0.6623s	
13703/25300 (epoch 27.081), train_loss = 0.85341009, grad/param norm = 1.8055e-01, time/batch = 0.6573s	
13704/25300 (epoch 27.083), train_loss = 0.85357029, grad/param norm = 1.8988e-01, time/batch = 0.6659s	
13705/25300 (epoch 27.085), train_loss = 1.05605567, grad/param norm = 2.1833e-01, time/batch = 0.6555s	
13706/25300 (epoch 27.087), train_loss = 0.95739474, grad/param norm = 1.9248e-01, time/batch = 0.6548s	
13707/25300 (epoch 27.089), train_loss = 0.92039770, grad/param norm = 2.0010e-01, time/batch = 0.6576s	
13708/25300 (epoch 27.091), train_loss = 1.04567462, grad/param norm = 2.4566e-01, time/batch = 0.6557s	
13709/25300 (epoch 27.093), train_loss = 0.97716695, grad/param norm = 2.5182e-01, time/batch = 0.6583s	
13710/25300 (epoch 27.095), train_loss = 0.94760631, grad/param norm = 2.0339e-01, time/batch = 0.6652s	
13711/25300 (epoch 27.097), train_loss = 0.91999768, grad/param norm = 2.2071e-01, time/batch = 0.6706s	
13712/25300 (epoch 27.099), train_loss = 0.93133757, grad/param norm = 2.4798e-01, time/batch = 0.6697s	
13713/25300 (epoch 27.101), train_loss = 0.84888377, grad/param norm = 2.2446e-01, time/batch = 0.6668s	
13714/25300 (epoch 27.103), train_loss = 0.89727612, grad/param norm = 2.0602e-01, time/batch = 0.6642s	
13715/25300 (epoch 27.105), train_loss = 0.94921447, grad/param norm = 2.0399e-01, time/batch = 0.6653s	
13716/25300 (epoch 27.107), train_loss = 0.96727926, grad/param norm = 2.4201e-01, time/batch = 0.6622s	
13717/25300 (epoch 27.109), train_loss = 0.87853472, grad/param norm = 2.3390e-01, time/batch = 0.6663s	
13718/25300 (epoch 27.111), train_loss = 0.85479092, grad/param norm = 1.8764e-01, time/batch = 0.6639s	
13719/25300 (epoch 27.113), train_loss = 0.83817452, grad/param norm = 2.2995e-01, time/batch = 0.6623s	
13720/25300 (epoch 27.115), train_loss = 0.87379312, grad/param norm = 2.1910e-01, time/batch = 0.6646s	
13721/25300 (epoch 27.117), train_loss = 0.95431375, grad/param norm = 2.0077e-01, time/batch = 0.6651s	
13722/25300 (epoch 27.119), train_loss = 0.84219082, grad/param norm = 2.1908e-01, time/batch = 0.6655s	
13723/25300 (epoch 27.121), train_loss = 0.90389569, grad/param norm = 2.3334e-01, time/batch = 0.6595s	
13724/25300 (epoch 27.123), train_loss = 0.81661303, grad/param norm = 2.0559e-01, time/batch = 0.6628s	
13725/25300 (epoch 27.125), train_loss = 0.96273361, grad/param norm = 2.3104e-01, time/batch = 0.6561s	
13726/25300 (epoch 27.126), train_loss = 0.87395978, grad/param norm = 1.9630e-01, time/batch = 0.6563s	
13727/25300 (epoch 27.128), train_loss = 0.87449298, grad/param norm = 2.2888e-01, time/batch = 0.6582s	
13728/25300 (epoch 27.130), train_loss = 0.69136960, grad/param norm = 1.6922e-01, time/batch = 0.6544s	
13729/25300 (epoch 27.132), train_loss = 0.73600307, grad/param norm = 1.8590e-01, time/batch = 0.6600s	
13730/25300 (epoch 27.134), train_loss = 0.71812558, grad/param norm = 1.7345e-01, time/batch = 0.6581s	
13731/25300 (epoch 27.136), train_loss = 0.83819233, grad/param norm = 1.8324e-01, time/batch = 0.6602s	
13732/25300 (epoch 27.138), train_loss = 0.75284731, grad/param norm = 1.7489e-01, time/batch = 0.6616s	
13733/25300 (epoch 27.140), train_loss = 0.75968937, grad/param norm = 1.8850e-01, time/batch = 0.6557s	
13734/25300 (epoch 27.142), train_loss = 0.96168181, grad/param norm = 2.0326e-01, time/batch = 0.6657s	
13735/25300 (epoch 27.144), train_loss = 0.93345131, grad/param norm = 2.4495e-01, time/batch = 0.6563s	
13736/25300 (epoch 27.146), train_loss = 0.89530440, grad/param norm = 2.7507e-01, time/batch = 0.6578s	
13737/25300 (epoch 27.148), train_loss = 0.86702259, grad/param norm = 2.2491e-01, time/batch = 0.6605s	
13738/25300 (epoch 27.150), train_loss = 0.93683651, grad/param norm = 2.0516e-01, time/batch = 0.6644s	
13739/25300 (epoch 27.152), train_loss = 1.02244548, grad/param norm = 2.3467e-01, time/batch = 0.6795s	
13740/25300 (epoch 27.154), train_loss = 0.71515537, grad/param norm = 1.6169e-01, time/batch = 0.6652s	
13741/25300 (epoch 27.156), train_loss = 0.91426857, grad/param norm = 2.0363e-01, time/batch = 0.6611s	
13742/25300 (epoch 27.158), train_loss = 0.76426758, grad/param norm = 2.0098e-01, time/batch = 0.6598s	
13743/25300 (epoch 27.160), train_loss = 0.86915733, grad/param norm = 2.0535e-01, time/batch = 0.6608s	
13744/25300 (epoch 27.162), train_loss = 0.82906753, grad/param norm = 2.0615e-01, time/batch = 0.6633s	
13745/25300 (epoch 27.164), train_loss = 0.91587901, grad/param norm = 2.3273e-01, time/batch = 0.6602s	
13746/25300 (epoch 27.166), train_loss = 0.87697611, grad/param norm = 2.0232e-01, time/batch = 0.6613s	
13747/25300 (epoch 27.168), train_loss = 0.78438432, grad/param norm = 1.7315e-01, time/batch = 0.6568s	
13748/25300 (epoch 27.170), train_loss = 0.80758154, grad/param norm = 2.0350e-01, time/batch = 0.6610s	
13749/25300 (epoch 27.172), train_loss = 0.76112470, grad/param norm = 1.8893e-01, time/batch = 0.6583s	
13750/25300 (epoch 27.174), train_loss = 0.76902633, grad/param norm = 1.9453e-01, time/batch = 0.6603s	
13751/25300 (epoch 27.176), train_loss = 0.77657764, grad/param norm = 2.1479e-01, time/batch = 0.6624s	
13752/25300 (epoch 27.178), train_loss = 0.99259415, grad/param norm = 2.2638e-01, time/batch = 0.6577s	
13753/25300 (epoch 27.180), train_loss = 0.71642028, grad/param norm = 1.8116e-01, time/batch = 0.6632s	
13754/25300 (epoch 27.182), train_loss = 0.79869092, grad/param norm = 1.8981e-01, time/batch = 0.6577s	
13755/25300 (epoch 27.184), train_loss = 0.77305898, grad/param norm = 2.0805e-01, time/batch = 0.6551s	
13756/25300 (epoch 27.186), train_loss = 0.75516289, grad/param norm = 1.9367e-01, time/batch = 0.6588s	
13757/25300 (epoch 27.188), train_loss = 0.87554996, grad/param norm = 2.4409e-01, time/batch = 0.6575s	
13758/25300 (epoch 27.190), train_loss = 0.81739904, grad/param norm = 1.9475e-01, time/batch = 0.6593s	
13759/25300 (epoch 27.192), train_loss = 0.84480209, grad/param norm = 1.9992e-01, time/batch = 0.6599s	
13760/25300 (epoch 27.194), train_loss = 0.83729596, grad/param norm = 2.1925e-01, time/batch = 0.6574s	
13761/25300 (epoch 27.196), train_loss = 0.96125091, grad/param norm = 2.4072e-01, time/batch = 0.6601s	
13762/25300 (epoch 27.198), train_loss = 0.81009773, grad/param norm = 2.3893e-01, time/batch = 0.6584s	
13763/25300 (epoch 27.200), train_loss = 0.82035027, grad/param norm = 2.1609e-01, time/batch = 0.6570s	
13764/25300 (epoch 27.202), train_loss = 0.86953968, grad/param norm = 2.2624e-01, time/batch = 0.6569s	
13765/25300 (epoch 27.204), train_loss = 0.84574865, grad/param norm = 2.0595e-01, time/batch = 0.6563s	
13766/25300 (epoch 27.206), train_loss = 0.94281792, grad/param norm = 2.0529e-01, time/batch = 0.6579s	
13767/25300 (epoch 27.208), train_loss = 0.76411111, grad/param norm = 2.0544e-01, time/batch = 0.6585s	
13768/25300 (epoch 27.209), train_loss = 0.74061466, grad/param norm = 1.9023e-01, time/batch = 0.6565s	
13769/25300 (epoch 27.211), train_loss = 0.82086436, grad/param norm = 1.9899e-01, time/batch = 0.6644s	
13770/25300 (epoch 27.213), train_loss = 0.91102007, grad/param norm = 2.2256e-01, time/batch = 0.6701s	
13771/25300 (epoch 27.215), train_loss = 0.86324308, grad/param norm = 1.9437e-01, time/batch = 0.6628s	
13772/25300 (epoch 27.217), train_loss = 0.89636167, grad/param norm = 2.3403e-01, time/batch = 0.6630s	
13773/25300 (epoch 27.219), train_loss = 0.95230316, grad/param norm = 2.2952e-01, time/batch = 0.6618s	
13774/25300 (epoch 27.221), train_loss = 1.00058075, grad/param norm = 2.2559e-01, time/batch = 0.6571s	
13775/25300 (epoch 27.223), train_loss = 0.92876698, grad/param norm = 2.2328e-01, time/batch = 0.6584s	
13776/25300 (epoch 27.225), train_loss = 1.19456447, grad/param norm = 2.7248e-01, time/batch = 0.6601s	
13777/25300 (epoch 27.227), train_loss = 0.99546533, grad/param norm = 2.3286e-01, time/batch = 0.6580s	
13778/25300 (epoch 27.229), train_loss = 0.85001958, grad/param norm = 2.0804e-01, time/batch = 0.6630s	
13779/25300 (epoch 27.231), train_loss = 0.86746119, grad/param norm = 2.0018e-01, time/batch = 0.6570s	
13780/25300 (epoch 27.233), train_loss = 0.92762801, grad/param norm = 2.2089e-01, time/batch = 0.6575s	
13781/25300 (epoch 27.235), train_loss = 0.87331945, grad/param norm = 2.0174e-01, time/batch = 0.6612s	
13782/25300 (epoch 27.237), train_loss = 0.99719818, grad/param norm = 2.3491e-01, time/batch = 0.6616s	
13783/25300 (epoch 27.239), train_loss = 0.82898630, grad/param norm = 2.0489e-01, time/batch = 0.6619s	
13784/25300 (epoch 27.241), train_loss = 1.00789216, grad/param norm = 2.1858e-01, time/batch = 0.6710s	
13785/25300 (epoch 27.243), train_loss = 1.16184269, grad/param norm = 2.9340e-01, time/batch = 0.6621s	
13786/25300 (epoch 27.245), train_loss = 0.83780133, grad/param norm = 2.5470e-01, time/batch = 0.6573s	
13787/25300 (epoch 27.247), train_loss = 0.94149916, grad/param norm = 2.2256e-01, time/batch = 0.6598s	
13788/25300 (epoch 27.249), train_loss = 0.74838040, grad/param norm = 1.9924e-01, time/batch = 0.6552s	
13789/25300 (epoch 27.251), train_loss = 0.75291056, grad/param norm = 1.7624e-01, time/batch = 0.6586s	
13790/25300 (epoch 27.253), train_loss = 0.84984531, grad/param norm = 2.0418e-01, time/batch = 0.6606s	
13791/25300 (epoch 27.255), train_loss = 0.81526439, grad/param norm = 2.4306e-01, time/batch = 0.6604s	
13792/25300 (epoch 27.257), train_loss = 0.87762964, grad/param norm = 2.3656e-01, time/batch = 0.6632s	
13793/25300 (epoch 27.259), train_loss = 1.06220436, grad/param norm = 2.4802e-01, time/batch = 0.6615s	
13794/25300 (epoch 27.261), train_loss = 0.99776745, grad/param norm = 2.4435e-01, time/batch = 0.6628s	
13795/25300 (epoch 27.263), train_loss = 1.01227057, grad/param norm = 2.2243e-01, time/batch = 0.6617s	
13796/25300 (epoch 27.265), train_loss = 1.04887086, grad/param norm = 2.2075e-01, time/batch = 0.6642s	
13797/25300 (epoch 27.267), train_loss = 0.96039986, grad/param norm = 2.1283e-01, time/batch = 0.6632s	
13798/25300 (epoch 27.269), train_loss = 0.75472161, grad/param norm = 1.9919e-01, time/batch = 0.6631s	
13799/25300 (epoch 27.271), train_loss = 0.81408770, grad/param norm = 2.0742e-01, time/batch = 0.6614s	
13800/25300 (epoch 27.273), train_loss = 0.94662035, grad/param norm = 2.2652e-01, time/batch = 0.6600s	
13801/25300 (epoch 27.275), train_loss = 0.84234569, grad/param norm = 1.7167e-01, time/batch = 0.6640s	
13802/25300 (epoch 27.277), train_loss = 0.84057045, grad/param norm = 2.3724e-01, time/batch = 0.6620s	
13803/25300 (epoch 27.279), train_loss = 0.85985043, grad/param norm = 1.9422e-01, time/batch = 0.6578s	
13804/25300 (epoch 27.281), train_loss = 1.01862373, grad/param norm = 2.2238e-01, time/batch = 0.6605s	
13805/25300 (epoch 27.283), train_loss = 0.76349514, grad/param norm = 1.6723e-01, time/batch = 0.6585s	
13806/25300 (epoch 27.285), train_loss = 0.88099748, grad/param norm = 1.9994e-01, time/batch = 0.6586s	
13807/25300 (epoch 27.287), train_loss = 0.95453359, grad/param norm = 2.1226e-01, time/batch = 0.6590s	
13808/25300 (epoch 27.289), train_loss = 0.84876831, grad/param norm = 1.9470e-01, time/batch = 0.6588s	
13809/25300 (epoch 27.291), train_loss = 0.83988910, grad/param norm = 1.9844e-01, time/batch = 0.6628s	
13810/25300 (epoch 27.292), train_loss = 1.05031120, grad/param norm = 2.1730e-01, time/batch = 0.6639s	
13811/25300 (epoch 27.294), train_loss = 0.90882625, grad/param norm = 2.0553e-01, time/batch = 0.6645s	
13812/25300 (epoch 27.296), train_loss = 0.77524382, grad/param norm = 1.9203e-01, time/batch = 0.6622s	
13813/25300 (epoch 27.298), train_loss = 0.97519868, grad/param norm = 2.1547e-01, time/batch = 0.6590s	
13814/25300 (epoch 27.300), train_loss = 0.99477478, grad/param norm = 2.4853e-01, time/batch = 0.6598s	
13815/25300 (epoch 27.302), train_loss = 0.70139788, grad/param norm = 1.9174e-01, time/batch = 0.6581s	
13816/25300 (epoch 27.304), train_loss = 0.96326688, grad/param norm = 2.0114e-01, time/batch = 0.6596s	
13817/25300 (epoch 27.306), train_loss = 0.69588597, grad/param norm = 1.9078e-01, time/batch = 0.6621s	
13818/25300 (epoch 27.308), train_loss = 0.93727711, grad/param norm = 1.9006e-01, time/batch = 0.6583s	
13819/25300 (epoch 27.310), train_loss = 0.76720925, grad/param norm = 2.0529e-01, time/batch = 0.6611s	
13820/25300 (epoch 27.312), train_loss = 0.89310827, grad/param norm = 1.8430e-01, time/batch = 0.6607s	
13821/25300 (epoch 27.314), train_loss = 0.72625596, grad/param norm = 1.9220e-01, time/batch = 0.6610s	
13822/25300 (epoch 27.316), train_loss = 0.88340685, grad/param norm = 1.8880e-01, time/batch = 0.6584s	
13823/25300 (epoch 27.318), train_loss = 0.71285182, grad/param norm = 1.7920e-01, time/batch = 0.6582s	
13824/25300 (epoch 27.320), train_loss = 0.78240382, grad/param norm = 1.7931e-01, time/batch = 0.6680s	
13825/25300 (epoch 27.322), train_loss = 1.04536280, grad/param norm = 2.5308e-01, time/batch = 0.6620s	
13826/25300 (epoch 27.324), train_loss = 0.78155676, grad/param norm = 1.9497e-01, time/batch = 0.6645s	
13827/25300 (epoch 27.326), train_loss = 0.71817468, grad/param norm = 1.8524e-01, time/batch = 0.6651s	
13828/25300 (epoch 27.328), train_loss = 0.69117207, grad/param norm = 2.0022e-01, time/batch = 0.6675s	
13829/25300 (epoch 27.330), train_loss = 0.85853306, grad/param norm = 2.2035e-01, time/batch = 0.6785s	
13830/25300 (epoch 27.332), train_loss = 0.87713930, grad/param norm = 1.9182e-01, time/batch = 0.6783s	
13831/25300 (epoch 27.334), train_loss = 0.72942476, grad/param norm = 1.9916e-01, time/batch = 0.6718s	
13832/25300 (epoch 27.336), train_loss = 0.75232888, grad/param norm = 2.3390e-01, time/batch = 0.6698s	
13833/25300 (epoch 27.338), train_loss = 0.73688381, grad/param norm = 1.7762e-01, time/batch = 0.6633s	
13834/25300 (epoch 27.340), train_loss = 0.77674193, grad/param norm = 1.9775e-01, time/batch = 0.6743s	
13835/25300 (epoch 27.342), train_loss = 0.84154309, grad/param norm = 2.4345e-01, time/batch = 0.6676s	
13836/25300 (epoch 27.344), train_loss = 0.91185714, grad/param norm = 2.1692e-01, time/batch = 0.6649s	
13837/25300 (epoch 27.346), train_loss = 0.80808800, grad/param norm = 1.9757e-01, time/batch = 0.6602s	
13838/25300 (epoch 27.348), train_loss = 0.75007707, grad/param norm = 1.9352e-01, time/batch = 0.6585s	
13839/25300 (epoch 27.350), train_loss = 0.82828339, grad/param norm = 2.2480e-01, time/batch = 0.6577s	
13840/25300 (epoch 27.352), train_loss = 0.85676738, grad/param norm = 1.8795e-01, time/batch = 0.6569s	
13841/25300 (epoch 27.354), train_loss = 0.79092764, grad/param norm = 2.1760e-01, time/batch = 0.6565s	
13842/25300 (epoch 27.356), train_loss = 0.83908400, grad/param norm = 1.8772e-01, time/batch = 0.6608s	
13843/25300 (epoch 27.358), train_loss = 0.90369881, grad/param norm = 2.2832e-01, time/batch = 0.6586s	
13844/25300 (epoch 27.360), train_loss = 0.76741084, grad/param norm = 1.8318e-01, time/batch = 0.6561s	
13845/25300 (epoch 27.362), train_loss = 0.77253664, grad/param norm = 1.9995e-01, time/batch = 0.6570s	
13846/25300 (epoch 27.364), train_loss = 0.80330294, grad/param norm = 2.1561e-01, time/batch = 0.6573s	
13847/25300 (epoch 27.366), train_loss = 0.74402024, grad/param norm = 1.9909e-01, time/batch = 0.6579s	
13848/25300 (epoch 27.368), train_loss = 0.83290716, grad/param norm = 1.9573e-01, time/batch = 0.6585s	
13849/25300 (epoch 27.370), train_loss = 0.77193042, grad/param norm = 2.2405e-01, time/batch = 0.6592s	
13850/25300 (epoch 27.372), train_loss = 0.77653412, grad/param norm = 2.0316e-01, time/batch = 0.6567s	
13851/25300 (epoch 27.374), train_loss = 0.72506038, grad/param norm = 1.8802e-01, time/batch = 0.6600s	
13852/25300 (epoch 27.375), train_loss = 0.94665665, grad/param norm = 2.3054e-01, time/batch = 0.6602s	
13853/25300 (epoch 27.377), train_loss = 0.92512073, grad/param norm = 2.1972e-01, time/batch = 0.6560s	
13854/25300 (epoch 27.379), train_loss = 0.88583819, grad/param norm = 2.0020e-01, time/batch = 0.6573s	
13855/25300 (epoch 27.381), train_loss = 0.82483237, grad/param norm = 2.0539e-01, time/batch = 0.6577s	
13856/25300 (epoch 27.383), train_loss = 0.75470330, grad/param norm = 1.9367e-01, time/batch = 0.6570s	
13857/25300 (epoch 27.385), train_loss = 0.84981023, grad/param norm = 1.9149e-01, time/batch = 0.6553s	
13858/25300 (epoch 27.387), train_loss = 0.85703808, grad/param norm = 2.0674e-01, time/batch = 0.6572s	
13859/25300 (epoch 27.389), train_loss = 0.86469923, grad/param norm = 2.1471e-01, time/batch = 0.6612s	
13860/25300 (epoch 27.391), train_loss = 0.80361867, grad/param norm = 1.9070e-01, time/batch = 0.6662s	
13861/25300 (epoch 27.393), train_loss = 0.88303842, grad/param norm = 3.0380e-01, time/batch = 0.6631s	
13862/25300 (epoch 27.395), train_loss = 0.68909557, grad/param norm = 1.8556e-01, time/batch = 0.6620s	
13863/25300 (epoch 27.397), train_loss = 0.72217955, grad/param norm = 2.4570e-01, time/batch = 0.6583s	
13864/25300 (epoch 27.399), train_loss = 0.71845530, grad/param norm = 2.1253e-01, time/batch = 0.6618s	
13865/25300 (epoch 27.401), train_loss = 0.90527709, grad/param norm = 2.3006e-01, time/batch = 0.6596s	
13866/25300 (epoch 27.403), train_loss = 0.88453473, grad/param norm = 3.6268e-01, time/batch = 0.6584s	
13867/25300 (epoch 27.405), train_loss = 0.82575327, grad/param norm = 1.8828e-01, time/batch = 0.6619s	
13868/25300 (epoch 27.407), train_loss = 0.80209124, grad/param norm = 1.9746e-01, time/batch = 0.6597s	
13869/25300 (epoch 27.409), train_loss = 0.76412046, grad/param norm = 1.7416e-01, time/batch = 0.6742s	
13870/25300 (epoch 27.411), train_loss = 0.78252400, grad/param norm = 1.9769e-01, time/batch = 0.6644s	
13871/25300 (epoch 27.413), train_loss = 0.68960360, grad/param norm = 1.7642e-01, time/batch = 0.6624s	
13872/25300 (epoch 27.415), train_loss = 0.74960031, grad/param norm = 1.9981e-01, time/batch = 0.6631s	
13873/25300 (epoch 27.417), train_loss = 0.69500556, grad/param norm = 1.7034e-01, time/batch = 0.6584s	
13874/25300 (epoch 27.419), train_loss = 0.65634693, grad/param norm = 1.7236e-01, time/batch = 0.6597s	
13875/25300 (epoch 27.421), train_loss = 0.72351798, grad/param norm = 1.6857e-01, time/batch = 0.6598s	
13876/25300 (epoch 27.423), train_loss = 0.72892138, grad/param norm = 2.0384e-01, time/batch = 0.6565s	
13877/25300 (epoch 27.425), train_loss = 0.82421111, grad/param norm = 2.6883e-01, time/batch = 0.6596s	
13878/25300 (epoch 27.427), train_loss = 0.94560486, grad/param norm = 2.1566e-01, time/batch = 0.6607s	
13879/25300 (epoch 27.429), train_loss = 0.95533376, grad/param norm = 2.3678e-01, time/batch = 0.6610s	
13880/25300 (epoch 27.431), train_loss = 0.85388801, grad/param norm = 1.9597e-01, time/batch = 0.6599s	
13881/25300 (epoch 27.433), train_loss = 0.83871584, grad/param norm = 1.9449e-01, time/batch = 0.6623s	
13882/25300 (epoch 27.435), train_loss = 0.77047465, grad/param norm = 2.1884e-01, time/batch = 0.6668s	
13883/25300 (epoch 27.437), train_loss = 0.76440644, grad/param norm = 2.0898e-01, time/batch = 0.6656s	
13884/25300 (epoch 27.439), train_loss = 0.87300710, grad/param norm = 2.3094e-01, time/batch = 0.6643s	
13885/25300 (epoch 27.441), train_loss = 0.89159644, grad/param norm = 2.1749e-01, time/batch = 0.6586s	
13886/25300 (epoch 27.443), train_loss = 1.02702001, grad/param norm = 2.6779e-01, time/batch = 0.6592s	
13887/25300 (epoch 27.445), train_loss = 0.97757821, grad/param norm = 2.5580e-01, time/batch = 0.6590s	
13888/25300 (epoch 27.447), train_loss = 0.75062051, grad/param norm = 1.8361e-01, time/batch = 0.6587s	
13889/25300 (epoch 27.449), train_loss = 0.68141459, grad/param norm = 1.7382e-01, time/batch = 0.6615s	
13890/25300 (epoch 27.451), train_loss = 1.03023209, grad/param norm = 2.2044e-01, time/batch = 0.6617s	
13891/25300 (epoch 27.453), train_loss = 0.90261617, grad/param norm = 2.0811e-01, time/batch = 0.6612s	
13892/25300 (epoch 27.455), train_loss = 0.89097650, grad/param norm = 2.2073e-01, time/batch = 0.6577s	
13893/25300 (epoch 27.457), train_loss = 0.78052389, grad/param norm = 2.0210e-01, time/batch = 0.6564s	
13894/25300 (epoch 27.458), train_loss = 0.80007769, grad/param norm = 2.1167e-01, time/batch = 0.6558s	
13895/25300 (epoch 27.460), train_loss = 0.81963446, grad/param norm = 2.0044e-01, time/batch = 0.6590s	
13896/25300 (epoch 27.462), train_loss = 0.62555805, grad/param norm = 1.8745e-01, time/batch = 0.6595s	
13897/25300 (epoch 27.464), train_loss = 0.91707910, grad/param norm = 2.2174e-01, time/batch = 0.6601s	
13898/25300 (epoch 27.466), train_loss = 0.90606570, grad/param norm = 2.1223e-01, time/batch = 0.6575s	
13899/25300 (epoch 27.468), train_loss = 0.88658697, grad/param norm = 2.1847e-01, time/batch = 0.6568s	
13900/25300 (epoch 27.470), train_loss = 0.79189017, grad/param norm = 1.6900e-01, time/batch = 0.6584s	
13901/25300 (epoch 27.472), train_loss = 0.71258256, grad/param norm = 1.8370e-01, time/batch = 0.6619s	
13902/25300 (epoch 27.474), train_loss = 0.89822035, grad/param norm = 1.9599e-01, time/batch = 0.6607s	
13903/25300 (epoch 27.476), train_loss = 0.79982355, grad/param norm = 1.9771e-01, time/batch = 0.6623s	
13904/25300 (epoch 27.478), train_loss = 0.90728070, grad/param norm = 2.2581e-01, time/batch = 0.6701s	
13905/25300 (epoch 27.480), train_loss = 0.79539944, grad/param norm = 1.9934e-01, time/batch = 0.6689s	
13906/25300 (epoch 27.482), train_loss = 0.88827605, grad/param norm = 2.5893e-01, time/batch = 0.6704s	
13907/25300 (epoch 27.484), train_loss = 0.90359477, grad/param norm = 2.4698e-01, time/batch = 0.6710s	
13908/25300 (epoch 27.486), train_loss = 0.83878196, grad/param norm = 2.2031e-01, time/batch = 0.6592s	
13909/25300 (epoch 27.488), train_loss = 0.99105837, grad/param norm = 2.2694e-01, time/batch = 0.6575s	
13910/25300 (epoch 27.490), train_loss = 0.90436583, grad/param norm = 2.1346e-01, time/batch = 0.6589s	
13911/25300 (epoch 27.492), train_loss = 0.92824508, grad/param norm = 2.0366e-01, time/batch = 0.6697s	
13912/25300 (epoch 27.494), train_loss = 0.81146912, grad/param norm = 2.2280e-01, time/batch = 0.6584s	
13913/25300 (epoch 27.496), train_loss = 0.86379120, grad/param norm = 2.3216e-01, time/batch = 0.6625s	
13914/25300 (epoch 27.498), train_loss = 0.82469555, grad/param norm = 2.0053e-01, time/batch = 0.6611s	
13915/25300 (epoch 27.500), train_loss = 0.99587179, grad/param norm = 2.1370e-01, time/batch = 0.6651s	
13916/25300 (epoch 27.502), train_loss = 0.90781432, grad/param norm = 2.2204e-01, time/batch = 0.6670s	
13917/25300 (epoch 27.504), train_loss = 0.82320801, grad/param norm = 2.1792e-01, time/batch = 0.6627s	
13918/25300 (epoch 27.506), train_loss = 0.76096008, grad/param norm = 2.0435e-01, time/batch = 0.6672s	
13919/25300 (epoch 27.508), train_loss = 0.84388674, grad/param norm = 2.1424e-01, time/batch = 0.6690s	
13920/25300 (epoch 27.510), train_loss = 0.78118670, grad/param norm = 2.0612e-01, time/batch = 0.6609s	
13921/25300 (epoch 27.512), train_loss = 0.62477888, grad/param norm = 1.8112e-01, time/batch = 0.6584s	
13922/25300 (epoch 27.514), train_loss = 0.82217228, grad/param norm = 2.2164e-01, time/batch = 0.6593s	
13923/25300 (epoch 27.516), train_loss = 0.90001371, grad/param norm = 2.2199e-01, time/batch = 0.6580s	
13924/25300 (epoch 27.518), train_loss = 0.93545387, grad/param norm = 2.1481e-01, time/batch = 0.6581s	
13925/25300 (epoch 27.520), train_loss = 0.69367433, grad/param norm = 1.5949e-01, time/batch = 0.6594s	
13926/25300 (epoch 27.522), train_loss = 0.78103309, grad/param norm = 2.0339e-01, time/batch = 0.6598s	
13927/25300 (epoch 27.524), train_loss = 0.77477793, grad/param norm = 1.9047e-01, time/batch = 0.6597s	
13928/25300 (epoch 27.526), train_loss = 0.96751102, grad/param norm = 2.0148e-01, time/batch = 0.6566s	
13929/25300 (epoch 27.528), train_loss = 0.97844997, grad/param norm = 2.1711e-01, time/batch = 0.6566s	
13930/25300 (epoch 27.530), train_loss = 0.87130796, grad/param norm = 2.2459e-01, time/batch = 0.6618s	
13931/25300 (epoch 27.532), train_loss = 0.81754165, grad/param norm = 2.0731e-01, time/batch = 0.6674s	
13932/25300 (epoch 27.534), train_loss = 0.80952837, grad/param norm = 2.3761e-01, time/batch = 0.6608s	
13933/25300 (epoch 27.536), train_loss = 0.66106716, grad/param norm = 1.9517e-01, time/batch = 0.6611s	
13934/25300 (epoch 27.538), train_loss = 0.74273232, grad/param norm = 1.7233e-01, time/batch = 0.6660s	
13935/25300 (epoch 27.540), train_loss = 0.75860722, grad/param norm = 2.0638e-01, time/batch = 0.6597s	
13936/25300 (epoch 27.542), train_loss = 0.71961903, grad/param norm = 1.7800e-01, time/batch = 0.6583s	
13937/25300 (epoch 27.543), train_loss = 0.69968934, grad/param norm = 1.6982e-01, time/batch = 0.6584s	
13938/25300 (epoch 27.545), train_loss = 1.04770054, grad/param norm = 2.8507e-01, time/batch = 0.6579s	
13939/25300 (epoch 27.547), train_loss = 0.90600233, grad/param norm = 2.2365e-01, time/batch = 0.6618s	
13940/25300 (epoch 27.549), train_loss = 1.06868699, grad/param norm = 2.7186e-01, time/batch = 0.6707s	
13941/25300 (epoch 27.551), train_loss = 0.92198819, grad/param norm = 2.0276e-01, time/batch = 0.6640s	
13942/25300 (epoch 27.553), train_loss = 0.75826276, grad/param norm = 2.0131e-01, time/batch = 0.6640s	
13943/25300 (epoch 27.555), train_loss = 0.92211173, grad/param norm = 2.2808e-01, time/batch = 0.6622s	
13944/25300 (epoch 27.557), train_loss = 0.94591488, grad/param norm = 2.3110e-01, time/batch = 0.6568s	
13945/25300 (epoch 27.559), train_loss = 0.95694976, grad/param norm = 2.1734e-01, time/batch = 0.6629s	
13946/25300 (epoch 27.561), train_loss = 0.96509343, grad/param norm = 2.1247e-01, time/batch = 0.6652s	
13947/25300 (epoch 27.563), train_loss = 0.93974204, grad/param norm = 2.3323e-01, time/batch = 0.6600s	
13948/25300 (epoch 27.565), train_loss = 0.74426788, grad/param norm = 1.9314e-01, time/batch = 0.6615s	
13949/25300 (epoch 27.567), train_loss = 0.66078809, grad/param norm = 1.7961e-01, time/batch = 0.6665s	
13950/25300 (epoch 27.569), train_loss = 0.84907209, grad/param norm = 2.0680e-01, time/batch = 0.6660s	
13951/25300 (epoch 27.571), train_loss = 0.93102776, grad/param norm = 2.3171e-01, time/batch = 0.6721s	
13952/25300 (epoch 27.573), train_loss = 0.82298417, grad/param norm = 1.9614e-01, time/batch = 0.6686s	
13953/25300 (epoch 27.575), train_loss = 0.95559664, grad/param norm = 2.2687e-01, time/batch = 0.6670s	
13954/25300 (epoch 27.577), train_loss = 0.83927985, grad/param norm = 2.5516e-01, time/batch = 0.6623s	
13955/25300 (epoch 27.579), train_loss = 0.98026604, grad/param norm = 2.2802e-01, time/batch = 0.6605s	
13956/25300 (epoch 27.581), train_loss = 0.92686880, grad/param norm = 2.1487e-01, time/batch = 0.6577s	
13957/25300 (epoch 27.583), train_loss = 0.73012437, grad/param norm = 2.0735e-01, time/batch = 0.6556s	
13958/25300 (epoch 27.585), train_loss = 0.71881169, grad/param norm = 2.0088e-01, time/batch = 0.6655s	
13959/25300 (epoch 27.587), train_loss = 0.82299128, grad/param norm = 1.8907e-01, time/batch = 0.6664s	
13960/25300 (epoch 27.589), train_loss = 0.71843637, grad/param norm = 1.6681e-01, time/batch = 0.6688s	
13961/25300 (epoch 27.591), train_loss = 0.71005161, grad/param norm = 2.0374e-01, time/batch = 0.6683s	
13962/25300 (epoch 27.593), train_loss = 0.90480996, grad/param norm = 2.0259e-01, time/batch = 0.6585s	
13963/25300 (epoch 27.595), train_loss = 0.83098129, grad/param norm = 1.9827e-01, time/batch = 0.6590s	
13964/25300 (epoch 27.597), train_loss = 0.73932151, grad/param norm = 1.9308e-01, time/batch = 0.6558s	
13965/25300 (epoch 27.599), train_loss = 0.91756577, grad/param norm = 2.2426e-01, time/batch = 0.6538s	
13966/25300 (epoch 27.601), train_loss = 0.84923060, grad/param norm = 2.1778e-01, time/batch = 0.6536s	
13967/25300 (epoch 27.603), train_loss = 0.84118081, grad/param norm = 2.0892e-01, time/batch = 0.6534s	
13968/25300 (epoch 27.605), train_loss = 0.77507392, grad/param norm = 1.9702e-01, time/batch = 0.6569s	
13969/25300 (epoch 27.607), train_loss = 0.59446506, grad/param norm = 1.6117e-01, time/batch = 0.6578s	
13970/25300 (epoch 27.609), train_loss = 0.80195963, grad/param norm = 1.9796e-01, time/batch = 0.6553s	
13971/25300 (epoch 27.611), train_loss = 0.84593338, grad/param norm = 1.9704e-01, time/batch = 0.6563s	
13972/25300 (epoch 27.613), train_loss = 0.71862552, grad/param norm = 1.6271e-01, time/batch = 0.6586s	
13973/25300 (epoch 27.615), train_loss = 0.83050287, grad/param norm = 2.5652e-01, time/batch = 0.6529s	
13974/25300 (epoch 27.617), train_loss = 0.83842893, grad/param norm = 2.2418e-01, time/batch = 0.6588s	
13975/25300 (epoch 27.619), train_loss = 0.93929504, grad/param norm = 2.2529e-01, time/batch = 0.6572s	
13976/25300 (epoch 27.621), train_loss = 0.93210267, grad/param norm = 2.2050e-01, time/batch = 0.6587s	
13977/25300 (epoch 27.623), train_loss = 0.76467468, grad/param norm = 2.0467e-01, time/batch = 0.6588s	
13978/25300 (epoch 27.625), train_loss = 0.69261799, grad/param norm = 2.0705e-01, time/batch = 0.6581s	
13979/25300 (epoch 27.626), train_loss = 0.82088471, grad/param norm = 1.8436e-01, time/batch = 0.6628s	
13980/25300 (epoch 27.628), train_loss = 0.91655040, grad/param norm = 2.6192e-01, time/batch = 0.6554s	
13981/25300 (epoch 27.630), train_loss = 0.89949204, grad/param norm = 2.2722e-01, time/batch = 0.6613s	
13982/25300 (epoch 27.632), train_loss = 0.85949004, grad/param norm = 2.1976e-01, time/batch = 0.6567s	
13983/25300 (epoch 27.634), train_loss = 0.97157202, grad/param norm = 2.4511e-01, time/batch = 0.6576s	
13984/25300 (epoch 27.636), train_loss = 0.76035076, grad/param norm = 1.8139e-01, time/batch = 0.6537s	
13985/25300 (epoch 27.638), train_loss = 0.86835133, grad/param norm = 2.3889e-01, time/batch = 0.6608s	
13986/25300 (epoch 27.640), train_loss = 1.02845722, grad/param norm = 2.3995e-01, time/batch = 0.6595s	
13987/25300 (epoch 27.642), train_loss = 0.87431993, grad/param norm = 2.2875e-01, time/batch = 0.6595s	
13988/25300 (epoch 27.644), train_loss = 0.88254258, grad/param norm = 2.2995e-01, time/batch = 0.6586s	
13989/25300 (epoch 27.646), train_loss = 0.78135086, grad/param norm = 2.1490e-01, time/batch = 0.6558s	
13990/25300 (epoch 27.648), train_loss = 0.93039613, grad/param norm = 1.8860e-01, time/batch = 0.6537s	
13991/25300 (epoch 27.650), train_loss = 0.87270599, grad/param norm = 2.4164e-01, time/batch = 0.6602s	
13992/25300 (epoch 27.652), train_loss = 0.86811038, grad/param norm = 2.1224e-01, time/batch = 0.6587s	
13993/25300 (epoch 27.654), train_loss = 0.98841875, grad/param norm = 2.0779e-01, time/batch = 0.6535s	
13994/25300 (epoch 27.656), train_loss = 0.91046774, grad/param norm = 2.3775e-01, time/batch = 0.6589s	
13995/25300 (epoch 27.658), train_loss = 0.69350396, grad/param norm = 1.8693e-01, time/batch = 0.6572s	
13996/25300 (epoch 27.660), train_loss = 0.71418096, grad/param norm = 2.0706e-01, time/batch = 0.6577s	
13997/25300 (epoch 27.662), train_loss = 0.72241499, grad/param norm = 1.8233e-01, time/batch = 0.6594s	
13998/25300 (epoch 27.664), train_loss = 0.70064831, grad/param norm = 2.2891e-01, time/batch = 0.6630s	
13999/25300 (epoch 27.666), train_loss = 0.75007418, grad/param norm = 2.1137e-01, time/batch = 0.6608s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch27.67_1.6854.t7	
14000/25300 (epoch 27.668), train_loss = 0.81682516, grad/param norm = 2.7312e-01, time/batch = 0.6609s	
14001/25300 (epoch 27.670), train_loss = 1.11882299, grad/param norm = 3.6646e-01, time/batch = 0.6728s	
14002/25300 (epoch 27.672), train_loss = 0.74852237, grad/param norm = 1.9964e-01, time/batch = 0.6794s	
14003/25300 (epoch 27.674), train_loss = 0.77244659, grad/param norm = 1.8480e-01, time/batch = 0.6721s	
14004/25300 (epoch 27.676), train_loss = 0.79416180, grad/param norm = 2.3425e-01, time/batch = 0.6627s	
14005/25300 (epoch 27.678), train_loss = 0.78818180, grad/param norm = 2.1990e-01, time/batch = 0.6586s	
14006/25300 (epoch 27.680), train_loss = 0.68887036, grad/param norm = 1.8895e-01, time/batch = 0.6555s	
14007/25300 (epoch 27.682), train_loss = 0.58752403, grad/param norm = 1.7250e-01, time/batch = 0.6661s	
14008/25300 (epoch 27.684), train_loss = 0.75614621, grad/param norm = 1.7894e-01, time/batch = 0.6759s	
14009/25300 (epoch 27.686), train_loss = 0.70810019, grad/param norm = 1.9879e-01, time/batch = 0.6609s	
14010/25300 (epoch 27.688), train_loss = 0.81088051, grad/param norm = 2.3757e-01, time/batch = 0.6583s	
14011/25300 (epoch 27.690), train_loss = 0.71415868, grad/param norm = 1.7898e-01, time/batch = 0.6538s	
14012/25300 (epoch 27.692), train_loss = 0.74990724, grad/param norm = 2.0149e-01, time/batch = 0.6573s	
14013/25300 (epoch 27.694), train_loss = 0.75323099, grad/param norm = 1.9399e-01, time/batch = 0.6549s	
14014/25300 (epoch 27.696), train_loss = 0.84669749, grad/param norm = 2.1946e-01, time/batch = 0.6624s	
14015/25300 (epoch 27.698), train_loss = 0.87542865, grad/param norm = 2.0358e-01, time/batch = 0.6600s	
14016/25300 (epoch 27.700), train_loss = 0.66370354, grad/param norm = 1.8331e-01, time/batch = 0.6594s	
14017/25300 (epoch 27.702), train_loss = 0.87880228, grad/param norm = 2.1867e-01, time/batch = 0.6614s	
14018/25300 (epoch 27.704), train_loss = 0.65973731, grad/param norm = 1.7629e-01, time/batch = 0.6610s	
14019/25300 (epoch 27.706), train_loss = 0.78873124, grad/param norm = 2.0750e-01, time/batch = 0.6587s	
14020/25300 (epoch 27.708), train_loss = 0.67531061, grad/param norm = 1.7716e-01, time/batch = 0.6574s	
14021/25300 (epoch 27.709), train_loss = 0.99314711, grad/param norm = 2.6564e-01, time/batch = 0.6672s	
14022/25300 (epoch 27.711), train_loss = 0.98163463, grad/param norm = 2.2898e-01, time/batch = 0.6617s	
14023/25300 (epoch 27.713), train_loss = 0.81233195, grad/param norm = 1.7340e-01, time/batch = 0.6614s	
14024/25300 (epoch 27.715), train_loss = 0.81573535, grad/param norm = 1.9709e-01, time/batch = 0.6579s	
14025/25300 (epoch 27.717), train_loss = 0.75007981, grad/param norm = 2.2829e-01, time/batch = 0.6760s	
14026/25300 (epoch 27.719), train_loss = 0.82022821, grad/param norm = 2.1048e-01, time/batch = 0.6778s	
14027/25300 (epoch 27.721), train_loss = 0.86292361, grad/param norm = 2.1289e-01, time/batch = 0.6639s	
14028/25300 (epoch 27.723), train_loss = 0.81135704, grad/param norm = 2.2861e-01, time/batch = 0.6610s	
14029/25300 (epoch 27.725), train_loss = 0.85372502, grad/param norm = 2.0332e-01, time/batch = 0.6602s	
14030/25300 (epoch 27.727), train_loss = 0.82393527, grad/param norm = 1.9843e-01, time/batch = 0.6516s	
14031/25300 (epoch 27.729), train_loss = 0.82447022, grad/param norm = 1.9200e-01, time/batch = 0.6645s	
14032/25300 (epoch 27.731), train_loss = 0.97150536, grad/param norm = 2.0991e-01, time/batch = 0.6644s	
14033/25300 (epoch 27.733), train_loss = 0.80940964, grad/param norm = 1.7825e-01, time/batch = 0.6648s	
14034/25300 (epoch 27.735), train_loss = 1.07625912, grad/param norm = 2.3267e-01, time/batch = 0.6616s	
14035/25300 (epoch 27.737), train_loss = 0.71960257, grad/param norm = 1.8716e-01, time/batch = 0.6627s	
14036/25300 (epoch 27.739), train_loss = 0.96616983, grad/param norm = 2.1517e-01, time/batch = 0.6656s	
14037/25300 (epoch 27.741), train_loss = 0.87117071, grad/param norm = 2.2007e-01, time/batch = 0.6609s	
14038/25300 (epoch 27.743), train_loss = 0.82296666, grad/param norm = 1.9716e-01, time/batch = 0.6624s	
14039/25300 (epoch 27.745), train_loss = 0.77976421, grad/param norm = 2.0712e-01, time/batch = 0.6606s	
14040/25300 (epoch 27.747), train_loss = 0.74253320, grad/param norm = 1.8752e-01, time/batch = 0.6650s	
14041/25300 (epoch 27.749), train_loss = 0.82934080, grad/param norm = 2.2082e-01, time/batch = 0.6613s	
14042/25300 (epoch 27.751), train_loss = 0.89737481, grad/param norm = 2.0423e-01, time/batch = 0.6660s	
14043/25300 (epoch 27.753), train_loss = 0.71888596, grad/param norm = 1.9553e-01, time/batch = 0.6663s	
14044/25300 (epoch 27.755), train_loss = 0.92401069, grad/param norm = 2.2400e-01, time/batch = 0.6668s	
14045/25300 (epoch 27.757), train_loss = 0.77376342, grad/param norm = 2.1565e-01, time/batch = 0.6616s	
14046/25300 (epoch 27.759), train_loss = 0.76214827, grad/param norm = 2.1413e-01, time/batch = 0.6633s	
14047/25300 (epoch 27.761), train_loss = 0.98149807, grad/param norm = 2.2478e-01, time/batch = 0.6649s	
14048/25300 (epoch 27.763), train_loss = 0.78839671, grad/param norm = 1.8784e-01, time/batch = 0.6579s	
14049/25300 (epoch 27.765), train_loss = 0.81156077, grad/param norm = 2.3269e-01, time/batch = 0.6617s	
14050/25300 (epoch 27.767), train_loss = 0.79864313, grad/param norm = 1.9782e-01, time/batch = 0.6633s	
14051/25300 (epoch 27.769), train_loss = 0.83546319, grad/param norm = 2.2056e-01, time/batch = 0.6659s	
14052/25300 (epoch 27.771), train_loss = 0.94792808, grad/param norm = 2.4880e-01, time/batch = 0.6561s	
14053/25300 (epoch 27.773), train_loss = 0.96272378, grad/param norm = 2.3960e-01, time/batch = 0.6606s	
14054/25300 (epoch 27.775), train_loss = 0.82417314, grad/param norm = 1.8189e-01, time/batch = 0.6574s	
14055/25300 (epoch 27.777), train_loss = 0.81913616, grad/param norm = 2.1274e-01, time/batch = 0.6615s	
14056/25300 (epoch 27.779), train_loss = 0.92215371, grad/param norm = 2.1362e-01, time/batch = 0.6544s	
14057/25300 (epoch 27.781), train_loss = 0.86993383, grad/param norm = 2.0383e-01, time/batch = 0.6548s	
14058/25300 (epoch 27.783), train_loss = 0.96690168, grad/param norm = 2.1579e-01, time/batch = 0.6557s	
14059/25300 (epoch 27.785), train_loss = 0.91404028, grad/param norm = 2.2969e-01, time/batch = 0.6574s	
14060/25300 (epoch 27.787), train_loss = 0.89509322, grad/param norm = 2.2628e-01, time/batch = 0.6560s	
14061/25300 (epoch 27.789), train_loss = 1.00840861, grad/param norm = 2.4420e-01, time/batch = 0.6666s	
14062/25300 (epoch 27.791), train_loss = 0.88317826, grad/param norm = 2.1246e-01, time/batch = 0.6638s	
14063/25300 (epoch 27.792), train_loss = 0.94684918, grad/param norm = 2.0947e-01, time/batch = 0.6588s	
14064/25300 (epoch 27.794), train_loss = 0.84081413, grad/param norm = 2.1524e-01, time/batch = 0.6575s	
14065/25300 (epoch 27.796), train_loss = 0.80542939, grad/param norm = 2.0192e-01, time/batch = 0.6606s	
14066/25300 (epoch 27.798), train_loss = 0.92095645, grad/param norm = 2.3174e-01, time/batch = 0.6555s	
14067/25300 (epoch 27.800), train_loss = 0.80585332, grad/param norm = 1.8741e-01, time/batch = 0.6514s	
14068/25300 (epoch 27.802), train_loss = 0.66342331, grad/param norm = 1.7396e-01, time/batch = 0.6603s	
14069/25300 (epoch 27.804), train_loss = 0.84265542, grad/param norm = 1.8690e-01, time/batch = 0.6583s	
14070/25300 (epoch 27.806), train_loss = 0.89937790, grad/param norm = 2.2494e-01, time/batch = 0.6574s	
14071/25300 (epoch 27.808), train_loss = 0.94008727, grad/param norm = 2.1641e-01, time/batch = 0.6593s	
14072/25300 (epoch 27.810), train_loss = 0.81638797, grad/param norm = 2.2634e-01, time/batch = 0.6593s	
14073/25300 (epoch 27.812), train_loss = 0.94985132, grad/param norm = 2.1500e-01, time/batch = 0.6575s	
14074/25300 (epoch 27.814), train_loss = 0.98280274, grad/param norm = 2.3390e-01, time/batch = 0.6613s	
14075/25300 (epoch 27.816), train_loss = 1.06732592, grad/param norm = 2.2483e-01, time/batch = 0.6594s	
14076/25300 (epoch 27.818), train_loss = 0.91136297, grad/param norm = 1.9601e-01, time/batch = 0.6566s	
14077/25300 (epoch 27.820), train_loss = 0.95522730, grad/param norm = 2.4059e-01, time/batch = 0.6617s	
14078/25300 (epoch 27.822), train_loss = 0.81891260, grad/param norm = 2.1256e-01, time/batch = 0.6588s	
14079/25300 (epoch 27.824), train_loss = 0.95547101, grad/param norm = 2.2816e-01, time/batch = 0.6608s	
14080/25300 (epoch 27.826), train_loss = 0.77956788, grad/param norm = 1.8447e-01, time/batch = 0.6551s	
14081/25300 (epoch 27.828), train_loss = 0.77432698, grad/param norm = 2.0016e-01, time/batch = 0.6622s	
14082/25300 (epoch 27.830), train_loss = 0.86090029, grad/param norm = 2.0348e-01, time/batch = 0.6662s	
14083/25300 (epoch 27.832), train_loss = 0.94214524, grad/param norm = 2.4529e-01, time/batch = 0.6619s	
14084/25300 (epoch 27.834), train_loss = 0.76953994, grad/param norm = 1.9780e-01, time/batch = 0.6562s	
14085/25300 (epoch 27.836), train_loss = 0.83779636, grad/param norm = 1.9418e-01, time/batch = 0.6611s	
14086/25300 (epoch 27.838), train_loss = 0.83680882, grad/param norm = 2.2171e-01, time/batch = 0.6633s	
14087/25300 (epoch 27.840), train_loss = 0.94516487, grad/param norm = 2.4220e-01, time/batch = 0.6676s	
14088/25300 (epoch 27.842), train_loss = 0.86894439, grad/param norm = 2.2705e-01, time/batch = 0.6658s	
14089/25300 (epoch 27.844), train_loss = 0.94480994, grad/param norm = 1.9640e-01, time/batch = 0.6665s	
14090/25300 (epoch 27.846), train_loss = 0.91688303, grad/param norm = 1.8438e-01, time/batch = 0.6607s	
14091/25300 (epoch 27.848), train_loss = 0.93091550, grad/param norm = 2.1419e-01, time/batch = 0.6705s	
14092/25300 (epoch 27.850), train_loss = 0.88218780, grad/param norm = 2.3090e-01, time/batch = 0.6742s	
14093/25300 (epoch 27.852), train_loss = 0.94678217, grad/param norm = 2.1303e-01, time/batch = 0.6627s	
14094/25300 (epoch 27.854), train_loss = 0.97673925, grad/param norm = 2.1466e-01, time/batch = 0.6636s	
14095/25300 (epoch 27.856), train_loss = 0.82644763, grad/param norm = 2.0574e-01, time/batch = 0.6655s	
14096/25300 (epoch 27.858), train_loss = 0.87144069, grad/param norm = 2.4228e-01, time/batch = 0.6755s	
14097/25300 (epoch 27.860), train_loss = 0.72653381, grad/param norm = 2.0710e-01, time/batch = 0.6597s	
14098/25300 (epoch 27.862), train_loss = 0.85351984, grad/param norm = 2.1198e-01, time/batch = 0.6585s	
14099/25300 (epoch 27.864), train_loss = 0.96089892, grad/param norm = 2.2879e-01, time/batch = 0.6589s	
14100/25300 (epoch 27.866), train_loss = 0.80410291, grad/param norm = 1.9844e-01, time/batch = 0.6648s	
14101/25300 (epoch 27.868), train_loss = 0.98256318, grad/param norm = 2.1097e-01, time/batch = 0.6567s	
14102/25300 (epoch 27.870), train_loss = 0.94266586, grad/param norm = 1.9056e-01, time/batch = 0.6598s	
14103/25300 (epoch 27.872), train_loss = 0.91717963, grad/param norm = 2.3132e-01, time/batch = 0.6587s	
14104/25300 (epoch 27.874), train_loss = 0.89532403, grad/param norm = 2.2334e-01, time/batch = 0.6565s	
14105/25300 (epoch 27.875), train_loss = 0.85040470, grad/param norm = 2.2805e-01, time/batch = 0.6612s	
14106/25300 (epoch 27.877), train_loss = 0.83479838, grad/param norm = 1.8487e-01, time/batch = 0.6615s	
14107/25300 (epoch 27.879), train_loss = 0.81221867, grad/param norm = 2.4326e-01, time/batch = 0.6593s	
14108/25300 (epoch 27.881), train_loss = 1.12474567, grad/param norm = 2.5767e-01, time/batch = 0.6637s	
14109/25300 (epoch 27.883), train_loss = 1.09112349, grad/param norm = 2.1268e-01, time/batch = 0.6654s	
14110/25300 (epoch 27.885), train_loss = 0.93528595, grad/param norm = 2.5742e-01, time/batch = 0.6551s	
14111/25300 (epoch 27.887), train_loss = 0.95142036, grad/param norm = 2.0731e-01, time/batch = 0.6582s	
14112/25300 (epoch 27.889), train_loss = 1.03650463, grad/param norm = 2.4482e-01, time/batch = 0.6571s	
14113/25300 (epoch 27.891), train_loss = 0.91739728, grad/param norm = 3.1248e-01, time/batch = 0.6624s	
14114/25300 (epoch 27.893), train_loss = 0.95169718, grad/param norm = 2.9221e-01, time/batch = 0.6618s	
14115/25300 (epoch 27.895), train_loss = 0.68609460, grad/param norm = 2.0702e-01, time/batch = 0.6642s	
14116/25300 (epoch 27.897), train_loss = 0.77114143, grad/param norm = 1.9189e-01, time/batch = 0.6601s	
14117/25300 (epoch 27.899), train_loss = 0.90565550, grad/param norm = 2.2777e-01, time/batch = 0.6627s	
14118/25300 (epoch 27.901), train_loss = 0.91556565, grad/param norm = 2.0834e-01, time/batch = 0.6613s	
14119/25300 (epoch 27.903), train_loss = 0.72204045, grad/param norm = 2.1643e-01, time/batch = 0.6563s	
14120/25300 (epoch 27.905), train_loss = 0.82219804, grad/param norm = 2.4098e-01, time/batch = 0.6634s	
14121/25300 (epoch 27.907), train_loss = 0.83225777, grad/param norm = 2.6736e-01, time/batch = 0.6623s	
14122/25300 (epoch 27.909), train_loss = 0.93457054, grad/param norm = 2.0443e-01, time/batch = 0.6596s	
14123/25300 (epoch 27.911), train_loss = 0.97530814, grad/param norm = 2.3870e-01, time/batch = 0.6569s	
14124/25300 (epoch 27.913), train_loss = 1.07276958, grad/param norm = 2.6558e-01, time/batch = 0.6580s	
14125/25300 (epoch 27.915), train_loss = 0.81134122, grad/param norm = 2.1289e-01, time/batch = 0.6610s	
14126/25300 (epoch 27.917), train_loss = 0.99076281, grad/param norm = 2.2081e-01, time/batch = 0.6568s	
14127/25300 (epoch 27.919), train_loss = 1.00221645, grad/param norm = 2.5042e-01, time/batch = 0.6618s	
14128/25300 (epoch 27.921), train_loss = 0.80094600, grad/param norm = 1.9936e-01, time/batch = 0.6580s	
14129/25300 (epoch 27.923), train_loss = 0.97047623, grad/param norm = 1.9322e-01, time/batch = 0.6581s	
14130/25300 (epoch 27.925), train_loss = 0.86923343, grad/param norm = 2.3510e-01, time/batch = 0.6591s	
14131/25300 (epoch 27.927), train_loss = 0.84550777, grad/param norm = 2.3975e-01, time/batch = 0.6621s	
14132/25300 (epoch 27.929), train_loss = 0.88040051, grad/param norm = 1.9712e-01, time/batch = 0.6583s	
14133/25300 (epoch 27.931), train_loss = 0.94396968, grad/param norm = 2.4204e-01, time/batch = 0.6607s	
14134/25300 (epoch 27.933), train_loss = 0.90417270, grad/param norm = 2.1369e-01, time/batch = 0.6579s	
14135/25300 (epoch 27.935), train_loss = 0.90446434, grad/param norm = 1.9710e-01, time/batch = 0.6668s	
14136/25300 (epoch 27.937), train_loss = 0.67332407, grad/param norm = 1.7192e-01, time/batch = 0.6577s	
14137/25300 (epoch 27.939), train_loss = 0.90033131, grad/param norm = 2.0878e-01, time/batch = 0.6617s	
14138/25300 (epoch 27.941), train_loss = 0.79692553, grad/param norm = 2.0351e-01, time/batch = 0.6592s	
14139/25300 (epoch 27.943), train_loss = 0.91011619, grad/param norm = 2.1147e-01, time/batch = 0.6621s	
14140/25300 (epoch 27.945), train_loss = 0.89867962, grad/param norm = 2.1967e-01, time/batch = 0.6606s	
14141/25300 (epoch 27.947), train_loss = 0.79057255, grad/param norm = 2.0681e-01, time/batch = 0.6632s	
14142/25300 (epoch 27.949), train_loss = 0.92983627, grad/param norm = 1.8949e-01, time/batch = 0.6595s	
14143/25300 (epoch 27.951), train_loss = 0.87170250, grad/param norm = 1.8173e-01, time/batch = 0.6585s	
14144/25300 (epoch 27.953), train_loss = 0.85651211, grad/param norm = 2.1922e-01, time/batch = 0.6628s	
14145/25300 (epoch 27.955), train_loss = 1.08178791, grad/param norm = 2.7312e-01, time/batch = 0.6604s	
14146/25300 (epoch 27.957), train_loss = 1.00223042, grad/param norm = 2.4337e-01, time/batch = 0.6631s	
14147/25300 (epoch 27.958), train_loss = 0.94306270, grad/param norm = 2.4433e-01, time/batch = 0.6574s	
14148/25300 (epoch 27.960), train_loss = 1.04092171, grad/param norm = 2.3072e-01, time/batch = 0.6599s	
14149/25300 (epoch 27.962), train_loss = 1.02403532, grad/param norm = 2.2495e-01, time/batch = 0.6606s	
14150/25300 (epoch 27.964), train_loss = 0.92698314, grad/param norm = 2.2725e-01, time/batch = 0.6624s	
14151/25300 (epoch 27.966), train_loss = 0.76704607, grad/param norm = 2.0763e-01, time/batch = 0.6594s	
14152/25300 (epoch 27.968), train_loss = 0.73065764, grad/param norm = 1.8502e-01, time/batch = 0.6614s	
14153/25300 (epoch 27.970), train_loss = 0.82977205, grad/param norm = 2.1976e-01, time/batch = 0.6630s	
14154/25300 (epoch 27.972), train_loss = 0.88032750, grad/param norm = 2.0986e-01, time/batch = 0.6570s	
14155/25300 (epoch 27.974), train_loss = 0.98918023, grad/param norm = 2.5397e-01, time/batch = 0.6796s	
14156/25300 (epoch 27.976), train_loss = 0.92120641, grad/param norm = 2.6428e-01, time/batch = 0.6677s	
14157/25300 (epoch 27.978), train_loss = 0.86324054, grad/param norm = 2.2493e-01, time/batch = 0.6664s	
14158/25300 (epoch 27.980), train_loss = 0.88456132, grad/param norm = 2.1550e-01, time/batch = 0.6579s	
14159/25300 (epoch 27.982), train_loss = 0.84241308, grad/param norm = 2.0295e-01, time/batch = 0.6581s	
14160/25300 (epoch 27.984), train_loss = 0.84939482, grad/param norm = 2.1336e-01, time/batch = 0.6651s	
14161/25300 (epoch 27.986), train_loss = 0.95723451, grad/param norm = 2.1155e-01, time/batch = 0.6578s	
14162/25300 (epoch 27.988), train_loss = 0.93868670, grad/param norm = 2.8003e-01, time/batch = 0.6581s	
14163/25300 (epoch 27.990), train_loss = 0.88411705, grad/param norm = 1.9732e-01, time/batch = 0.6607s	
14164/25300 (epoch 27.992), train_loss = 0.76039427, grad/param norm = 1.8063e-01, time/batch = 0.6547s	
14165/25300 (epoch 27.994), train_loss = 0.90034499, grad/param norm = 2.4721e-01, time/batch = 0.6616s	
14166/25300 (epoch 27.996), train_loss = 1.02244276, grad/param norm = 2.8024e-01, time/batch = 0.6547s	
14167/25300 (epoch 27.998), train_loss = 0.96895960, grad/param norm = 2.3473e-01, time/batch = 0.6556s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
14168/25300 (epoch 28.000), train_loss = 0.90877626, grad/param norm = 2.0357e-01, time/batch = 0.6596s	
14169/25300 (epoch 28.002), train_loss = 0.83337248, grad/param norm = 1.9129e-01, time/batch = 0.6585s	
14170/25300 (epoch 28.004), train_loss = 0.74532437, grad/param norm = 2.0170e-01, time/batch = 0.6639s	
14171/25300 (epoch 28.006), train_loss = 1.02613191, grad/param norm = 2.2317e-01, time/batch = 0.6620s	
14172/25300 (epoch 28.008), train_loss = 0.87405407, grad/param norm = 1.8220e-01, time/batch = 0.6608s	
14173/25300 (epoch 28.010), train_loss = 0.88607362, grad/param norm = 2.1196e-01, time/batch = 0.6568s	
14174/25300 (epoch 28.012), train_loss = 0.83784280, grad/param norm = 2.0334e-01, time/batch = 0.6603s	
14175/25300 (epoch 28.014), train_loss = 1.01328410, grad/param norm = 2.2222e-01, time/batch = 0.6582s	
14176/25300 (epoch 28.016), train_loss = 0.88011977, grad/param norm = 2.2632e-01, time/batch = 0.6589s	
14177/25300 (epoch 28.018), train_loss = 0.77556362, grad/param norm = 1.9228e-01, time/batch = 0.6562s	
14178/25300 (epoch 28.020), train_loss = 0.86817247, grad/param norm = 1.8744e-01, time/batch = 0.6688s	
14179/25300 (epoch 28.022), train_loss = 0.86806362, grad/param norm = 2.0593e-01, time/batch = 0.6565s	
14180/25300 (epoch 28.024), train_loss = 0.65528286, grad/param norm = 1.5616e-01, time/batch = 0.6568s	
14181/25300 (epoch 28.026), train_loss = 0.81617653, grad/param norm = 2.0144e-01, time/batch = 0.6687s	
14182/25300 (epoch 28.028), train_loss = 0.80854385, grad/param norm = 1.9826e-01, time/batch = 0.6661s	
14183/25300 (epoch 28.030), train_loss = 0.97876825, grad/param norm = 1.9149e-01, time/batch = 0.6753s	
14184/25300 (epoch 28.032), train_loss = 0.84747082, grad/param norm = 2.1510e-01, time/batch = 0.6592s	
14185/25300 (epoch 28.034), train_loss = 0.74693372, grad/param norm = 1.8824e-01, time/batch = 0.6767s	
14186/25300 (epoch 28.036), train_loss = 0.72095188, grad/param norm = 1.9544e-01, time/batch = 0.6577s	
14187/25300 (epoch 28.038), train_loss = 0.67303676, grad/param norm = 1.8340e-01, time/batch = 0.6589s	
14188/25300 (epoch 28.040), train_loss = 0.88030478, grad/param norm = 2.1760e-01, time/batch = 0.6545s	
14189/25300 (epoch 28.042), train_loss = 0.84329142, grad/param norm = 1.7860e-01, time/batch = 0.6683s	
14190/25300 (epoch 28.043), train_loss = 0.72729397, grad/param norm = 1.7640e-01, time/batch = 0.6654s	
14191/25300 (epoch 28.045), train_loss = 0.72646870, grad/param norm = 1.8784e-01, time/batch = 0.6563s	
14192/25300 (epoch 28.047), train_loss = 0.90420344, grad/param norm = 1.9789e-01, time/batch = 0.6634s	
14193/25300 (epoch 28.049), train_loss = 0.88456404, grad/param norm = 2.4583e-01, time/batch = 0.6605s	
14194/25300 (epoch 28.051), train_loss = 0.95991521, grad/param norm = 2.1440e-01, time/batch = 0.6615s	
14195/25300 (epoch 28.053), train_loss = 0.68352844, grad/param norm = 1.5721e-01, time/batch = 0.6597s	
14196/25300 (epoch 28.055), train_loss = 0.73126594, grad/param norm = 1.8677e-01, time/batch = 0.6553s	
14197/25300 (epoch 28.057), train_loss = 0.70084390, grad/param norm = 1.6761e-01, time/batch = 0.6644s	
14198/25300 (epoch 28.059), train_loss = 0.79935228, grad/param norm = 2.0195e-01, time/batch = 0.6564s	
14199/25300 (epoch 28.061), train_loss = 0.78970064, grad/param norm = 2.0739e-01, time/batch = 0.6603s	
14200/25300 (epoch 28.063), train_loss = 0.77905585, grad/param norm = 1.9266e-01, time/batch = 0.6568s	
14201/25300 (epoch 28.065), train_loss = 0.88256469, grad/param norm = 2.3469e-01, time/batch = 0.6579s	
14202/25300 (epoch 28.067), train_loss = 0.93737577, grad/param norm = 1.9562e-01, time/batch = 0.6615s	
14203/25300 (epoch 28.069), train_loss = 0.77446057, grad/param norm = 2.0253e-01, time/batch = 0.6659s	
14204/25300 (epoch 28.071), train_loss = 0.93247760, grad/param norm = 2.3312e-01, time/batch = 0.6599s	
14205/25300 (epoch 28.073), train_loss = 0.80254486, grad/param norm = 1.8249e-01, time/batch = 0.6563s	
14206/25300 (epoch 28.075), train_loss = 0.93784356, grad/param norm = 2.2249e-01, time/batch = 0.6659s	
14207/25300 (epoch 28.077), train_loss = 0.88128645, grad/param norm = 1.9597e-01, time/batch = 0.6586s	
14208/25300 (epoch 28.079), train_loss = 0.80759742, grad/param norm = 2.0803e-01, time/batch = 0.6580s	
14209/25300 (epoch 28.081), train_loss = 0.83613047, grad/param norm = 1.6764e-01, time/batch = 0.6545s	
14210/25300 (epoch 28.083), train_loss = 0.85181921, grad/param norm = 1.9133e-01, time/batch = 0.6569s	
14211/25300 (epoch 28.085), train_loss = 1.03404289, grad/param norm = 2.2049e-01, time/batch = 0.6556s	
14212/25300 (epoch 28.087), train_loss = 0.95198176, grad/param norm = 2.0086e-01, time/batch = 0.6560s	
14213/25300 (epoch 28.089), train_loss = 0.90939126, grad/param norm = 2.0066e-01, time/batch = 0.6579s	
14214/25300 (epoch 28.091), train_loss = 1.02203047, grad/param norm = 2.3518e-01, time/batch = 0.6584s	
14215/25300 (epoch 28.093), train_loss = 0.97429585, grad/param norm = 2.4667e-01, time/batch = 0.6602s	
14216/25300 (epoch 28.095), train_loss = 0.92686475, grad/param norm = 2.0407e-01, time/batch = 0.6652s	
14217/25300 (epoch 28.097), train_loss = 0.91916053, grad/param norm = 2.1080e-01, time/batch = 0.6613s	
14218/25300 (epoch 28.099), train_loss = 0.90889043, grad/param norm = 2.0795e-01, time/batch = 0.6557s	
14219/25300 (epoch 28.101), train_loss = 0.83703925, grad/param norm = 1.9846e-01, time/batch = 0.6628s	
14220/25300 (epoch 28.103), train_loss = 0.87018432, grad/param norm = 1.9472e-01, time/batch = 0.6587s	
14221/25300 (epoch 28.105), train_loss = 0.94903585, grad/param norm = 2.0942e-01, time/batch = 0.6638s	
14222/25300 (epoch 28.107), train_loss = 0.94396512, grad/param norm = 2.1630e-01, time/batch = 0.6599s	
14223/25300 (epoch 28.109), train_loss = 0.85301529, grad/param norm = 2.2274e-01, time/batch = 0.6624s	
14224/25300 (epoch 28.111), train_loss = 0.83404872, grad/param norm = 1.9195e-01, time/batch = 0.6603s	
14225/25300 (epoch 28.113), train_loss = 0.80891857, grad/param norm = 2.0666e-01, time/batch = 0.6608s	
14226/25300 (epoch 28.115), train_loss = 0.84669914, grad/param norm = 2.0333e-01, time/batch = 0.6590s	
14227/25300 (epoch 28.117), train_loss = 0.94622565, grad/param norm = 2.1318e-01, time/batch = 0.6616s	
14228/25300 (epoch 28.119), train_loss = 0.82655049, grad/param norm = 2.1822e-01, time/batch = 0.6583s	
14229/25300 (epoch 28.121), train_loss = 0.88333544, grad/param norm = 2.2798e-01, time/batch = 0.6600s	
14230/25300 (epoch 28.123), train_loss = 0.80106353, grad/param norm = 2.1540e-01, time/batch = 0.6606s	
14231/25300 (epoch 28.125), train_loss = 0.95112123, grad/param norm = 2.0930e-01, time/batch = 0.6588s	
14232/25300 (epoch 28.126), train_loss = 0.86544200, grad/param norm = 1.9454e-01, time/batch = 0.6566s	
14233/25300 (epoch 28.128), train_loss = 0.85674674, grad/param norm = 2.1528e-01, time/batch = 0.6568s	
14234/25300 (epoch 28.130), train_loss = 0.68817622, grad/param norm = 1.8502e-01, time/batch = 0.6571s	
14235/25300 (epoch 28.132), train_loss = 0.72158924, grad/param norm = 1.9536e-01, time/batch = 0.6669s	
14236/25300 (epoch 28.134), train_loss = 0.70632756, grad/param norm = 1.6833e-01, time/batch = 0.6640s	
14237/25300 (epoch 28.136), train_loss = 0.83552217, grad/param norm = 1.9470e-01, time/batch = 0.6655s	
14238/25300 (epoch 28.138), train_loss = 0.75194541, grad/param norm = 1.8615e-01, time/batch = 0.6590s	
14239/25300 (epoch 28.140), train_loss = 0.73375145, grad/param norm = 1.9035e-01, time/batch = 0.6615s	
14240/25300 (epoch 28.142), train_loss = 0.94995756, grad/param norm = 2.0841e-01, time/batch = 0.6569s	
14241/25300 (epoch 28.144), train_loss = 0.92452966, grad/param norm = 2.0963e-01, time/batch = 0.6659s	
14242/25300 (epoch 28.146), train_loss = 0.87480294, grad/param norm = 2.4803e-01, time/batch = 0.6676s	
14243/25300 (epoch 28.148), train_loss = 0.83620520, grad/param norm = 1.9313e-01, time/batch = 0.6668s	
14244/25300 (epoch 28.150), train_loss = 0.91729018, grad/param norm = 2.3302e-01, time/batch = 0.6583s	
14245/25300 (epoch 28.152), train_loss = 0.98659280, grad/param norm = 2.1322e-01, time/batch = 0.6596s	
14246/25300 (epoch 28.154), train_loss = 0.71544220, grad/param norm = 1.8125e-01, time/batch = 0.6636s	
14247/25300 (epoch 28.156), train_loss = 0.90512812, grad/param norm = 2.0929e-01, time/batch = 0.6558s	
14248/25300 (epoch 28.158), train_loss = 0.77096433, grad/param norm = 2.5875e-01, time/batch = 0.6615s	
14249/25300 (epoch 28.160), train_loss = 0.85659676, grad/param norm = 2.0266e-01, time/batch = 0.6573s	
14250/25300 (epoch 28.162), train_loss = 0.82096121, grad/param norm = 2.0061e-01, time/batch = 0.6584s	
14251/25300 (epoch 28.164), train_loss = 0.92252206, grad/param norm = 2.1942e-01, time/batch = 0.6637s	
14252/25300 (epoch 28.166), train_loss = 0.88135430, grad/param norm = 2.0396e-01, time/batch = 0.6571s	
14253/25300 (epoch 28.168), train_loss = 0.79359028, grad/param norm = 1.8687e-01, time/batch = 0.6544s	
14254/25300 (epoch 28.170), train_loss = 0.79123578, grad/param norm = 1.9115e-01, time/batch = 0.6616s	
14255/25300 (epoch 28.172), train_loss = 0.74736775, grad/param norm = 2.0252e-01, time/batch = 0.6598s	
14256/25300 (epoch 28.174), train_loss = 0.75956001, grad/param norm = 1.9223e-01, time/batch = 0.6571s	
14257/25300 (epoch 28.176), train_loss = 0.76992047, grad/param norm = 2.2552e-01, time/batch = 0.6599s	
14258/25300 (epoch 28.178), train_loss = 0.96841915, grad/param norm = 2.2184e-01, time/batch = 0.6598s	
14259/25300 (epoch 28.180), train_loss = 0.70100334, grad/param norm = 1.7475e-01, time/batch = 0.6588s	
14260/25300 (epoch 28.182), train_loss = 0.78094034, grad/param norm = 2.1146e-01, time/batch = 0.6596s	
14261/25300 (epoch 28.184), train_loss = 0.76444725, grad/param norm = 1.9983e-01, time/batch = 0.6626s	
14262/25300 (epoch 28.186), train_loss = 0.75626731, grad/param norm = 2.1217e-01, time/batch = 0.6577s	
14263/25300 (epoch 28.188), train_loss = 0.85835106, grad/param norm = 2.2758e-01, time/batch = 0.6600s	
14264/25300 (epoch 28.190), train_loss = 0.80868306, grad/param norm = 1.9146e-01, time/batch = 0.6629s	
14265/25300 (epoch 28.192), train_loss = 0.81859647, grad/param norm = 1.9088e-01, time/batch = 0.6606s	
14266/25300 (epoch 28.194), train_loss = 0.82240677, grad/param norm = 2.0422e-01, time/batch = 0.6566s	
14267/25300 (epoch 28.196), train_loss = 0.95200840, grad/param norm = 2.3104e-01, time/batch = 0.6563s	
14268/25300 (epoch 28.198), train_loss = 0.78656014, grad/param norm = 2.1801e-01, time/batch = 0.6565s	
14269/25300 (epoch 28.200), train_loss = 0.80786224, grad/param norm = 2.1031e-01, time/batch = 0.6581s	
14270/25300 (epoch 28.202), train_loss = 0.83098743, grad/param norm = 1.9019e-01, time/batch = 0.6575s	
14271/25300 (epoch 28.204), train_loss = 0.83039539, grad/param norm = 2.1594e-01, time/batch = 0.6635s	
14272/25300 (epoch 28.206), train_loss = 0.93117580, grad/param norm = 2.0926e-01, time/batch = 0.6657s	
14273/25300 (epoch 28.208), train_loss = 0.74229873, grad/param norm = 1.8284e-01, time/batch = 0.6729s	
14274/25300 (epoch 28.209), train_loss = 0.71229978, grad/param norm = 1.8859e-01, time/batch = 0.6745s	
14275/25300 (epoch 28.211), train_loss = 0.81192748, grad/param norm = 1.9336e-01, time/batch = 0.6613s	
14276/25300 (epoch 28.213), train_loss = 0.86584419, grad/param norm = 2.2230e-01, time/batch = 0.6664s	
14277/25300 (epoch 28.215), train_loss = 0.84597199, grad/param norm = 1.8986e-01, time/batch = 0.6534s	
14278/25300 (epoch 28.217), train_loss = 0.88157614, grad/param norm = 2.2311e-01, time/batch = 0.6659s	
14279/25300 (epoch 28.219), train_loss = 0.94458385, grad/param norm = 2.1765e-01, time/batch = 0.6681s	
14280/25300 (epoch 28.221), train_loss = 0.97690023, grad/param norm = 2.0731e-01, time/batch = 0.6569s	
14281/25300 (epoch 28.223), train_loss = 0.91695263, grad/param norm = 2.3944e-01, time/batch = 0.6628s	
14282/25300 (epoch 28.225), train_loss = 1.18846802, grad/param norm = 3.2166e-01, time/batch = 0.6592s	
14283/25300 (epoch 28.227), train_loss = 0.99908675, grad/param norm = 2.2808e-01, time/batch = 0.6597s	
14284/25300 (epoch 28.229), train_loss = 0.83621865, grad/param norm = 2.0242e-01, time/batch = 0.6544s	
14285/25300 (epoch 28.231), train_loss = 0.85651371, grad/param norm = 2.1079e-01, time/batch = 0.6595s	
14286/25300 (epoch 28.233), train_loss = 0.92177749, grad/param norm = 2.3149e-01, time/batch = 0.6576s	
14287/25300 (epoch 28.235), train_loss = 0.86101127, grad/param norm = 2.0438e-01, time/batch = 0.6635s	
14288/25300 (epoch 28.237), train_loss = 0.98238861, grad/param norm = 2.2171e-01, time/batch = 0.6724s	
14289/25300 (epoch 28.239), train_loss = 0.82473201, grad/param norm = 2.0195e-01, time/batch = 0.6563s	
14290/25300 (epoch 28.241), train_loss = 0.98704486, grad/param norm = 2.1772e-01, time/batch = 0.6596s	
14291/25300 (epoch 28.243), train_loss = 1.12894131, grad/param norm = 2.5023e-01, time/batch = 0.6544s	
14292/25300 (epoch 28.245), train_loss = 0.82040532, grad/param norm = 2.0605e-01, time/batch = 0.6589s	
14293/25300 (epoch 28.247), train_loss = 0.93912977, grad/param norm = 2.4966e-01, time/batch = 0.6585s	
14294/25300 (epoch 28.249), train_loss = 0.74081523, grad/param norm = 1.9109e-01, time/batch = 0.6545s	
14295/25300 (epoch 28.251), train_loss = 0.74334112, grad/param norm = 1.8377e-01, time/batch = 0.6605s	
14296/25300 (epoch 28.253), train_loss = 0.83578510, grad/param norm = 1.9215e-01, time/batch = 0.6560s	
14297/25300 (epoch 28.255), train_loss = 0.78249402, grad/param norm = 2.0881e-01, time/batch = 0.6573s	
14298/25300 (epoch 28.257), train_loss = 0.84020235, grad/param norm = 2.2532e-01, time/batch = 0.6718s	
14299/25300 (epoch 28.259), train_loss = 1.07493812, grad/param norm = 2.9168e-01, time/batch = 0.6632s	
14300/25300 (epoch 28.261), train_loss = 1.01085748, grad/param norm = 2.4925e-01, time/batch = 0.6629s	
14301/25300 (epoch 28.263), train_loss = 1.03159158, grad/param norm = 2.5747e-01, time/batch = 0.6611s	
14302/25300 (epoch 28.265), train_loss = 1.04772258, grad/param norm = 2.3829e-01, time/batch = 0.6595s	
14303/25300 (epoch 28.267), train_loss = 0.93627677, grad/param norm = 2.1572e-01, time/batch = 0.6640s	
14304/25300 (epoch 28.269), train_loss = 0.74361616, grad/param norm = 1.9182e-01, time/batch = 0.6610s	
14305/25300 (epoch 28.271), train_loss = 0.79596349, grad/param norm = 1.9640e-01, time/batch = 0.6646s	
14306/25300 (epoch 28.273), train_loss = 0.94499924, grad/param norm = 2.1424e-01, time/batch = 0.6721s	
14307/25300 (epoch 28.275), train_loss = 0.82369168, grad/param norm = 1.7142e-01, time/batch = 0.6638s	
14308/25300 (epoch 28.277), train_loss = 0.83084875, grad/param norm = 2.2244e-01, time/batch = 0.6643s	
14309/25300 (epoch 28.279), train_loss = 0.85787013, grad/param norm = 2.0859e-01, time/batch = 0.6592s	
14310/25300 (epoch 28.281), train_loss = 1.00505535, grad/param norm = 2.2068e-01, time/batch = 0.6633s	
14311/25300 (epoch 28.283), train_loss = 0.75579721, grad/param norm = 1.7134e-01, time/batch = 0.6654s	
14312/25300 (epoch 28.285), train_loss = 0.87428632, grad/param norm = 2.2657e-01, time/batch = 0.6638s	
14313/25300 (epoch 28.287), train_loss = 0.95117697, grad/param norm = 1.9715e-01, time/batch = 0.6643s	
14314/25300 (epoch 28.289), train_loss = 0.81256175, grad/param norm = 2.0964e-01, time/batch = 0.6626s	
14315/25300 (epoch 28.291), train_loss = 0.81975699, grad/param norm = 2.0393e-01, time/batch = 0.6579s	
14316/25300 (epoch 28.292), train_loss = 1.02464448, grad/param norm = 2.2209e-01, time/batch = 0.6606s	
14317/25300 (epoch 28.294), train_loss = 0.90973183, grad/param norm = 2.6240e-01, time/batch = 0.6577s	
14318/25300 (epoch 28.296), train_loss = 0.76334503, grad/param norm = 1.8768e-01, time/batch = 0.6613s	
14319/25300 (epoch 28.298), train_loss = 0.95045333, grad/param norm = 2.0269e-01, time/batch = 0.6566s	
14320/25300 (epoch 28.300), train_loss = 0.96841028, grad/param norm = 2.4289e-01, time/batch = 0.6588s	
14321/25300 (epoch 28.302), train_loss = 0.69989290, grad/param norm = 2.2872e-01, time/batch = 0.6567s	
14322/25300 (epoch 28.304), train_loss = 0.96340608, grad/param norm = 2.1166e-01, time/batch = 0.6555s	
14323/25300 (epoch 28.306), train_loss = 0.69188472, grad/param norm = 1.9132e-01, time/batch = 0.6550s	
14324/25300 (epoch 28.308), train_loss = 0.92273699, grad/param norm = 1.9455e-01, time/batch = 0.6580s	
14325/25300 (epoch 28.310), train_loss = 0.75383970, grad/param norm = 2.0151e-01, time/batch = 0.6586s	
14326/25300 (epoch 28.312), train_loss = 0.88723965, grad/param norm = 1.9969e-01, time/batch = 0.6533s	
14327/25300 (epoch 28.314), train_loss = 0.70915287, grad/param norm = 1.9344e-01, time/batch = 0.6618s	
14328/25300 (epoch 28.316), train_loss = 0.87700961, grad/param norm = 1.9088e-01, time/batch = 0.6536s	
14329/25300 (epoch 28.318), train_loss = 0.70559133, grad/param norm = 1.9404e-01, time/batch = 0.6590s	
14330/25300 (epoch 28.320), train_loss = 0.77452738, grad/param norm = 1.9355e-01, time/batch = 0.6560s	
14331/25300 (epoch 28.322), train_loss = 1.00602207, grad/param norm = 2.1185e-01, time/batch = 0.6640s	
14332/25300 (epoch 28.324), train_loss = 0.77472780, grad/param norm = 1.9536e-01, time/batch = 0.6551s	
14333/25300 (epoch 28.326), train_loss = 0.69520560, grad/param norm = 1.7099e-01, time/batch = 0.6562s	
14334/25300 (epoch 28.328), train_loss = 0.68280232, grad/param norm = 2.6448e-01, time/batch = 0.6607s	
14335/25300 (epoch 28.330), train_loss = 0.82987117, grad/param norm = 2.0452e-01, time/batch = 0.6588s	
14336/25300 (epoch 28.332), train_loss = 0.85466961, grad/param norm = 2.0027e-01, time/batch = 0.6557s	
14337/25300 (epoch 28.334), train_loss = 0.71898881, grad/param norm = 1.9903e-01, time/batch = 0.6577s	
14338/25300 (epoch 28.336), train_loss = 0.71769623, grad/param norm = 1.9480e-01, time/batch = 0.6564s	
14339/25300 (epoch 28.338), train_loss = 0.74423963, grad/param norm = 1.9121e-01, time/batch = 0.6617s	
14340/25300 (epoch 28.340), train_loss = 0.76721410, grad/param norm = 1.9094e-01, time/batch = 0.6569s	
14341/25300 (epoch 28.342), train_loss = 0.83692378, grad/param norm = 3.3085e-01, time/batch = 0.6632s	
14342/25300 (epoch 28.344), train_loss = 0.89181028, grad/param norm = 2.1905e-01, time/batch = 0.6597s	
14343/25300 (epoch 28.346), train_loss = 0.80492065, grad/param norm = 2.2700e-01, time/batch = 0.6634s	
14344/25300 (epoch 28.348), train_loss = 0.74541528, grad/param norm = 2.0553e-01, time/batch = 0.6571s	
14345/25300 (epoch 28.350), train_loss = 0.82056252, grad/param norm = 2.2790e-01, time/batch = 0.6618s	
14346/25300 (epoch 28.352), train_loss = 0.83221171, grad/param norm = 1.8598e-01, time/batch = 0.6566s	
14347/25300 (epoch 28.354), train_loss = 0.78096352, grad/param norm = 1.9758e-01, time/batch = 0.6634s	
14348/25300 (epoch 28.356), train_loss = 0.84254344, grad/param norm = 2.0633e-01, time/batch = 0.6624s	
14349/25300 (epoch 28.358), train_loss = 0.87391807, grad/param norm = 2.1537e-01, time/batch = 0.6609s	
14350/25300 (epoch 28.360), train_loss = 0.75844729, grad/param norm = 1.8549e-01, time/batch = 0.6610s	
14351/25300 (epoch 28.362), train_loss = 0.75045687, grad/param norm = 2.2584e-01, time/batch = 0.6575s	
14352/25300 (epoch 28.364), train_loss = 0.78598624, grad/param norm = 2.2705e-01, time/batch = 0.6627s	
14353/25300 (epoch 28.366), train_loss = 0.72327808, grad/param norm = 1.9597e-01, time/batch = 0.6606s	
14354/25300 (epoch 28.368), train_loss = 0.82032066, grad/param norm = 1.9550e-01, time/batch = 0.6562s	
14355/25300 (epoch 28.370), train_loss = 0.75756468, grad/param norm = 1.9285e-01, time/batch = 0.6618s	
14356/25300 (epoch 28.372), train_loss = 0.77347328, grad/param norm = 2.1657e-01, time/batch = 0.6583s	
14357/25300 (epoch 28.374), train_loss = 0.72238823, grad/param norm = 2.2099e-01, time/batch = 0.6589s	
14358/25300 (epoch 28.375), train_loss = 0.94162426, grad/param norm = 2.4156e-01, time/batch = 0.6597s	
14359/25300 (epoch 28.377), train_loss = 0.92092063, grad/param norm = 2.1899e-01, time/batch = 0.6570s	
14360/25300 (epoch 28.379), train_loss = 0.89117278, grad/param norm = 2.3791e-01, time/batch = 0.6587s	
14361/25300 (epoch 28.381), train_loss = 0.80626008, grad/param norm = 2.2120e-01, time/batch = 0.6594s	
14362/25300 (epoch 28.383), train_loss = 0.74738589, grad/param norm = 1.9576e-01, time/batch = 0.6712s	
14363/25300 (epoch 28.385), train_loss = 0.85023081, grad/param norm = 1.8590e-01, time/batch = 0.6738s	
14364/25300 (epoch 28.387), train_loss = 0.85382181, grad/param norm = 2.1099e-01, time/batch = 0.6597s	
14365/25300 (epoch 28.389), train_loss = 0.84434532, grad/param norm = 2.1342e-01, time/batch = 0.6558s	
14366/25300 (epoch 28.391), train_loss = 0.79325783, grad/param norm = 1.9135e-01, time/batch = 0.6637s	
14367/25300 (epoch 28.393), train_loss = 0.86143847, grad/param norm = 2.3693e-01, time/batch = 0.6568s	
14368/25300 (epoch 28.395), train_loss = 0.67783189, grad/param norm = 1.8753e-01, time/batch = 0.6561s	
14369/25300 (epoch 28.397), train_loss = 0.67950862, grad/param norm = 1.9275e-01, time/batch = 0.6614s	
14370/25300 (epoch 28.399), train_loss = 0.72355163, grad/param norm = 2.1291e-01, time/batch = 0.6572s	
14371/25300 (epoch 28.401), train_loss = 0.89891155, grad/param norm = 2.2115e-01, time/batch = 0.6662s	
14372/25300 (epoch 28.403), train_loss = 0.84836621, grad/param norm = 2.3847e-01, time/batch = 0.6571s	
14373/25300 (epoch 28.405), train_loss = 0.81881238, grad/param norm = 1.9975e-01, time/batch = 0.6582s	
14374/25300 (epoch 28.407), train_loss = 0.81000792, grad/param norm = 2.0672e-01, time/batch = 0.6602s	
14375/25300 (epoch 28.409), train_loss = 0.76168310, grad/param norm = 1.9672e-01, time/batch = 0.6556s	
14376/25300 (epoch 28.411), train_loss = 0.77239421, grad/param norm = 2.0987e-01, time/batch = 0.6551s	
14377/25300 (epoch 28.413), train_loss = 0.69768630, grad/param norm = 2.0331e-01, time/batch = 0.6604s	
14378/25300 (epoch 28.415), train_loss = 0.73913419, grad/param norm = 1.8794e-01, time/batch = 0.6576s	
14379/25300 (epoch 28.417), train_loss = 0.70464888, grad/param norm = 1.8034e-01, time/batch = 0.6612s	
14380/25300 (epoch 28.419), train_loss = 0.64268040, grad/param norm = 1.6891e-01, time/batch = 0.6566s	
14381/25300 (epoch 28.421), train_loss = 0.71046837, grad/param norm = 1.6244e-01, time/batch = 0.6599s	
14382/25300 (epoch 28.423), train_loss = 0.71079140, grad/param norm = 1.8324e-01, time/batch = 0.6608s	
14383/25300 (epoch 28.425), train_loss = 0.79717292, grad/param norm = 2.1565e-01, time/batch = 0.6592s	
14384/25300 (epoch 28.427), train_loss = 0.92613298, grad/param norm = 2.0218e-01, time/batch = 0.6645s	
14385/25300 (epoch 28.429), train_loss = 0.94004751, grad/param norm = 2.4010e-01, time/batch = 0.6555s	
14386/25300 (epoch 28.431), train_loss = 0.83479831, grad/param norm = 1.9750e-01, time/batch = 0.6624s	
14387/25300 (epoch 28.433), train_loss = 0.83298494, grad/param norm = 2.1452e-01, time/batch = 0.6617s	
14388/25300 (epoch 28.435), train_loss = 0.76289695, grad/param norm = 2.1520e-01, time/batch = 0.6560s	
14389/25300 (epoch 28.437), train_loss = 0.73464709, grad/param norm = 1.7833e-01, time/batch = 0.6581s	
14390/25300 (epoch 28.439), train_loss = 0.84553177, grad/param norm = 2.3375e-01, time/batch = 0.6574s	
14391/25300 (epoch 28.441), train_loss = 0.88340136, grad/param norm = 2.5105e-01, time/batch = 0.6604s	
14392/25300 (epoch 28.443), train_loss = 0.99886063, grad/param norm = 2.3268e-01, time/batch = 0.6656s	
14393/25300 (epoch 28.445), train_loss = 0.96629676, grad/param norm = 2.4192e-01, time/batch = 0.6557s	
14394/25300 (epoch 28.447), train_loss = 0.75777869, grad/param norm = 1.9339e-01, time/batch = 0.6600s	
14395/25300 (epoch 28.449), train_loss = 0.69145532, grad/param norm = 1.9516e-01, time/batch = 0.6570s	
14396/25300 (epoch 28.451), train_loss = 0.99896797, grad/param norm = 2.1355e-01, time/batch = 0.6615s	
14397/25300 (epoch 28.453), train_loss = 0.89656543, grad/param norm = 2.5990e-01, time/batch = 0.6594s	
14398/25300 (epoch 28.455), train_loss = 0.86898745, grad/param norm = 2.3415e-01, time/batch = 0.6557s	
14399/25300 (epoch 28.457), train_loss = 0.76191046, grad/param norm = 1.9391e-01, time/batch = 0.6631s	
14400/25300 (epoch 28.458), train_loss = 0.78083940, grad/param norm = 2.0627e-01, time/batch = 0.6691s	
14401/25300 (epoch 28.460), train_loss = 0.81939381, grad/param norm = 2.2416e-01, time/batch = 0.6646s	
14402/25300 (epoch 28.462), train_loss = 0.60099964, grad/param norm = 1.8771e-01, time/batch = 0.6672s	
14403/25300 (epoch 28.464), train_loss = 0.89980138, grad/param norm = 2.1448e-01, time/batch = 0.6643s	
14404/25300 (epoch 28.466), train_loss = 0.88673408, grad/param norm = 2.0860e-01, time/batch = 0.6663s	
14405/25300 (epoch 28.468), train_loss = 0.87190745, grad/param norm = 2.0161e-01, time/batch = 0.6611s	
14406/25300 (epoch 28.470), train_loss = 0.79118614, grad/param norm = 2.0471e-01, time/batch = 0.6621s	
14407/25300 (epoch 28.472), train_loss = 0.70578726, grad/param norm = 1.8843e-01, time/batch = 0.6638s	
14408/25300 (epoch 28.474), train_loss = 0.87549569, grad/param norm = 2.0738e-01, time/batch = 0.6565s	
14409/25300 (epoch 28.476), train_loss = 0.80281070, grad/param norm = 2.2611e-01, time/batch = 0.6577s	
14410/25300 (epoch 28.478), train_loss = 0.89089728, grad/param norm = 2.1451e-01, time/batch = 0.6596s	
14411/25300 (epoch 28.480), train_loss = 0.78857502, grad/param norm = 1.9422e-01, time/batch = 0.6571s	
14412/25300 (epoch 28.482), train_loss = 0.86010474, grad/param norm = 2.4571e-01, time/batch = 0.6594s	
14413/25300 (epoch 28.484), train_loss = 0.90732537, grad/param norm = 2.6638e-01, time/batch = 0.6613s	
14414/25300 (epoch 28.486), train_loss = 0.83634445, grad/param norm = 2.3427e-01, time/batch = 0.6580s	
14415/25300 (epoch 28.488), train_loss = 0.96821998, grad/param norm = 2.1494e-01, time/batch = 0.6606s	
14416/25300 (epoch 28.490), train_loss = 0.87446964, grad/param norm = 1.9119e-01, time/batch = 0.6590s	
14417/25300 (epoch 28.492), train_loss = 0.92282333, grad/param norm = 2.1581e-01, time/batch = 0.6596s	
14418/25300 (epoch 28.494), train_loss = 0.79148692, grad/param norm = 1.9374e-01, time/batch = 0.6617s	
14419/25300 (epoch 28.496), train_loss = 0.86142507, grad/param norm = 2.0607e-01, time/batch = 0.6585s	
14420/25300 (epoch 28.498), train_loss = 0.80055497, grad/param norm = 1.8298e-01, time/batch = 0.6593s	
14421/25300 (epoch 28.500), train_loss = 0.98907405, grad/param norm = 2.3867e-01, time/batch = 0.6620s	
14422/25300 (epoch 28.502), train_loss = 0.88911886, grad/param norm = 2.1061e-01, time/batch = 0.6588s	
14423/25300 (epoch 28.504), train_loss = 0.80218851, grad/param norm = 2.0043e-01, time/batch = 0.6629s	
14424/25300 (epoch 28.506), train_loss = 0.74365340, grad/param norm = 2.2783e-01, time/batch = 0.6604s	
14425/25300 (epoch 28.508), train_loss = 0.80675598, grad/param norm = 1.9771e-01, time/batch = 0.6552s	
14426/25300 (epoch 28.510), train_loss = 0.75088850, grad/param norm = 1.9324e-01, time/batch = 0.6616s	
14427/25300 (epoch 28.512), train_loss = 0.62803843, grad/param norm = 1.7915e-01, time/batch = 0.6575s	
14428/25300 (epoch 28.514), train_loss = 0.80389158, grad/param norm = 1.9222e-01, time/batch = 0.6592s	
14429/25300 (epoch 28.516), train_loss = 0.89809922, grad/param norm = 2.3083e-01, time/batch = 0.6530s	
14430/25300 (epoch 28.518), train_loss = 0.90948666, grad/param norm = 2.0177e-01, time/batch = 0.6583s	
14431/25300 (epoch 28.520), train_loss = 0.68108422, grad/param norm = 1.6123e-01, time/batch = 0.6595s	
14432/25300 (epoch 28.522), train_loss = 0.77566344, grad/param norm = 2.0341e-01, time/batch = 0.6604s	
14433/25300 (epoch 28.524), train_loss = 0.77062715, grad/param norm = 2.0204e-01, time/batch = 0.6604s	
14434/25300 (epoch 28.526), train_loss = 0.95018453, grad/param norm = 2.1827e-01, time/batch = 0.6660s	
14435/25300 (epoch 28.528), train_loss = 0.95362490, grad/param norm = 2.0767e-01, time/batch = 0.6566s	
14436/25300 (epoch 28.530), train_loss = 0.86780870, grad/param norm = 2.1538e-01, time/batch = 0.6586s	
14437/25300 (epoch 28.532), train_loss = 0.82076093, grad/param norm = 2.2025e-01, time/batch = 0.6575s	
14438/25300 (epoch 28.534), train_loss = 0.80568598, grad/param norm = 2.7549e-01, time/batch = 0.6604s	
14439/25300 (epoch 28.536), train_loss = 0.66334080, grad/param norm = 2.0776e-01, time/batch = 0.6574s	
14440/25300 (epoch 28.538), train_loss = 0.72659171, grad/param norm = 1.8586e-01, time/batch = 0.6591s	
14441/25300 (epoch 28.540), train_loss = 0.73606041, grad/param norm = 1.9235e-01, time/batch = 0.6623s	
14442/25300 (epoch 28.542), train_loss = 0.71134323, grad/param norm = 1.7674e-01, time/batch = 0.6530s	
14443/25300 (epoch 28.543), train_loss = 0.69771824, grad/param norm = 1.8360e-01, time/batch = 0.6591s	
14444/25300 (epoch 28.545), train_loss = 1.02721166, grad/param norm = 2.7834e-01, time/batch = 0.6614s	
14445/25300 (epoch 28.547), train_loss = 0.91132458, grad/param norm = 2.3209e-01, time/batch = 0.6614s	
14446/25300 (epoch 28.549), train_loss = 1.08490177, grad/param norm = 3.9356e-01, time/batch = 0.6611s	
14447/25300 (epoch 28.551), train_loss = 0.92974590, grad/param norm = 2.2620e-01, time/batch = 0.6632s	
14448/25300 (epoch 28.553), train_loss = 0.76583026, grad/param norm = 2.4291e-01, time/batch = 0.6621s	
14449/25300 (epoch 28.555), train_loss = 0.92405219, grad/param norm = 2.8124e-01, time/batch = 0.6603s	
14450/25300 (epoch 28.557), train_loss = 0.95668808, grad/param norm = 2.9549e-01, time/batch = 0.6612s	
14451/25300 (epoch 28.559), train_loss = 0.95475994, grad/param norm = 2.3015e-01, time/batch = 0.6575s	
14452/25300 (epoch 28.561), train_loss = 0.97652674, grad/param norm = 2.6311e-01, time/batch = 0.6640s	
14453/25300 (epoch 28.563), train_loss = 0.92951262, grad/param norm = 2.3114e-01, time/batch = 0.6661s	
14454/25300 (epoch 28.565), train_loss = 0.73063508, grad/param norm = 1.9792e-01, time/batch = 0.6740s	
14455/25300 (epoch 28.567), train_loss = 0.65821093, grad/param norm = 1.8259e-01, time/batch = 0.6604s	
14456/25300 (epoch 28.569), train_loss = 0.86023462, grad/param norm = 2.1839e-01, time/batch = 0.6611s	
14457/25300 (epoch 28.571), train_loss = 0.93344707, grad/param norm = 2.3528e-01, time/batch = 0.6595s	
14458/25300 (epoch 28.573), train_loss = 0.83574214, grad/param norm = 2.1980e-01, time/batch = 0.6590s	
14459/25300 (epoch 28.575), train_loss = 0.92560994, grad/param norm = 1.9880e-01, time/batch = 0.6659s	
14460/25300 (epoch 28.577), train_loss = 0.83600711, grad/param norm = 2.4468e-01, time/batch = 0.6663s	
14461/25300 (epoch 28.579), train_loss = 0.95706156, grad/param norm = 2.2580e-01, time/batch = 0.6772s	
14462/25300 (epoch 28.581), train_loss = 0.89579676, grad/param norm = 2.0373e-01, time/batch = 0.6724s	
14463/25300 (epoch 28.583), train_loss = 0.70014909, grad/param norm = 1.9935e-01, time/batch = 0.6621s	
14464/25300 (epoch 28.585), train_loss = 0.70238656, grad/param norm = 1.8942e-01, time/batch = 0.6608s	
14465/25300 (epoch 28.587), train_loss = 0.83351691, grad/param norm = 1.9667e-01, time/batch = 0.6647s	
14466/25300 (epoch 28.589), train_loss = 0.71872616, grad/param norm = 1.7125e-01, time/batch = 0.6572s	
14467/25300 (epoch 28.591), train_loss = 0.70878311, grad/param norm = 2.2741e-01, time/batch = 0.6633s	
14468/25300 (epoch 28.593), train_loss = 0.89989819, grad/param norm = 2.5640e-01, time/batch = 0.6627s	
14469/25300 (epoch 28.595), train_loss = 0.82501539, grad/param norm = 2.0266e-01, time/batch = 0.6551s	
14470/25300 (epoch 28.597), train_loss = 0.73295981, grad/param norm = 1.8851e-01, time/batch = 0.6583s	
14471/25300 (epoch 28.599), train_loss = 0.91735214, grad/param norm = 2.2439e-01, time/batch = 0.6608s	
14472/25300 (epoch 28.601), train_loss = 0.82452487, grad/param norm = 2.3080e-01, time/batch = 0.6559s	
14473/25300 (epoch 28.603), train_loss = 0.81603623, grad/param norm = 2.0262e-01, time/batch = 0.6623s	
14474/25300 (epoch 28.605), train_loss = 0.78820079, grad/param norm = 2.3668e-01, time/batch = 0.6637s	
14475/25300 (epoch 28.607), train_loss = 0.59766678, grad/param norm = 1.7105e-01, time/batch = 0.6543s	
14476/25300 (epoch 28.609), train_loss = 0.78869323, grad/param norm = 1.8288e-01, time/batch = 0.6620s	
14477/25300 (epoch 28.611), train_loss = 0.82784946, grad/param norm = 1.9840e-01, time/batch = 0.6589s	
14478/25300 (epoch 28.613), train_loss = 0.71096406, grad/param norm = 1.7723e-01, time/batch = 0.6581s	
14479/25300 (epoch 28.615), train_loss = 0.80706192, grad/param norm = 2.4474e-01, time/batch = 0.6541s	
14480/25300 (epoch 28.617), train_loss = 0.84381947, grad/param norm = 2.3608e-01, time/batch = 0.6563s	
14481/25300 (epoch 28.619), train_loss = 0.90542481, grad/param norm = 2.3835e-01, time/batch = 0.6605s	
14482/25300 (epoch 28.621), train_loss = 0.92447730, grad/param norm = 2.2851e-01, time/batch = 0.6588s	
14483/25300 (epoch 28.623), train_loss = 0.75911861, grad/param norm = 2.3350e-01, time/batch = 0.6606s	
14484/25300 (epoch 28.625), train_loss = 0.68311407, grad/param norm = 1.9467e-01, time/batch = 0.6550s	
14485/25300 (epoch 28.626), train_loss = 0.80274933, grad/param norm = 1.8910e-01, time/batch = 0.6582s	
14486/25300 (epoch 28.628), train_loss = 0.90348386, grad/param norm = 2.2572e-01, time/batch = 0.6570s	
14487/25300 (epoch 28.630), train_loss = 0.90648744, grad/param norm = 2.4330e-01, time/batch = 0.6560s	
14488/25300 (epoch 28.632), train_loss = 0.85424592, grad/param norm = 2.4024e-01, time/batch = 0.6556s	
14489/25300 (epoch 28.634), train_loss = 0.96887147, grad/param norm = 2.5370e-01, time/batch = 0.6587s	
14490/25300 (epoch 28.636), train_loss = 0.75493990, grad/param norm = 2.1694e-01, time/batch = 0.6563s	
14491/25300 (epoch 28.638), train_loss = 0.87066326, grad/param norm = 2.5546e-01, time/batch = 0.6581s	
14492/25300 (epoch 28.640), train_loss = 1.01934135, grad/param norm = 2.4168e-01, time/batch = 0.6563s	
14493/25300 (epoch 28.642), train_loss = 0.85160285, grad/param norm = 2.3157e-01, time/batch = 0.6579s	
14494/25300 (epoch 28.644), train_loss = 0.86683832, grad/param norm = 2.2088e-01, time/batch = 0.6560s	
14495/25300 (epoch 28.646), train_loss = 0.76405932, grad/param norm = 2.4512e-01, time/batch = 0.6589s	
14496/25300 (epoch 28.648), train_loss = 0.90275519, grad/param norm = 1.9776e-01, time/batch = 0.6604s	
14497/25300 (epoch 28.650), train_loss = 0.84536107, grad/param norm = 2.0743e-01, time/batch = 0.6573s	
14498/25300 (epoch 28.652), train_loss = 0.86757865, grad/param norm = 2.3176e-01, time/batch = 0.6540s	
14499/25300 (epoch 28.654), train_loss = 0.95788870, grad/param norm = 2.0862e-01, time/batch = 0.6575s	
14500/25300 (epoch 28.656), train_loss = 0.90647048, grad/param norm = 2.2514e-01, time/batch = 0.6557s	
14501/25300 (epoch 28.658), train_loss = 0.68148204, grad/param norm = 1.7937e-01, time/batch = 0.6618s	
14502/25300 (epoch 28.660), train_loss = 0.70167989, grad/param norm = 2.0924e-01, time/batch = 0.6547s	
14503/25300 (epoch 28.662), train_loss = 0.70189402, grad/param norm = 1.9865e-01, time/batch = 0.6605s	
14504/25300 (epoch 28.664), train_loss = 0.69657811, grad/param norm = 2.1480e-01, time/batch = 0.6542s	
14505/25300 (epoch 28.666), train_loss = 0.73479340, grad/param norm = 2.0681e-01, time/batch = 0.6576s	
14506/25300 (epoch 28.668), train_loss = 0.81380840, grad/param norm = 2.5363e-01, time/batch = 0.6558s	
14507/25300 (epoch 28.670), train_loss = 0.76236971, grad/param norm = 2.1598e-01, time/batch = 0.6730s	
14508/25300 (epoch 28.672), train_loss = 0.74821358, grad/param norm = 1.9022e-01, time/batch = 0.6598s	
14509/25300 (epoch 28.674), train_loss = 0.75461917, grad/param norm = 1.8179e-01, time/batch = 0.6551s	
14510/25300 (epoch 28.676), train_loss = 0.76319412, grad/param norm = 2.0973e-01, time/batch = 0.6575s	
14511/25300 (epoch 28.678), train_loss = 0.77140931, grad/param norm = 2.0867e-01, time/batch = 0.6582s	
14512/25300 (epoch 28.680), train_loss = 0.68045958, grad/param norm = 1.9352e-01, time/batch = 0.6586s	
14513/25300 (epoch 28.682), train_loss = 0.56673135, grad/param norm = 1.7424e-01, time/batch = 0.6543s	
14514/25300 (epoch 28.684), train_loss = 0.73187010, grad/param norm = 1.7558e-01, time/batch = 0.6561s	
14515/25300 (epoch 28.686), train_loss = 0.68411066, grad/param norm = 1.8452e-01, time/batch = 0.6597s	
14516/25300 (epoch 28.688), train_loss = 0.79496630, grad/param norm = 2.3152e-01, time/batch = 0.6627s	
14517/25300 (epoch 28.690), train_loss = 0.70090759, grad/param norm = 1.6803e-01, time/batch = 0.6599s	
14518/25300 (epoch 28.692), train_loss = 0.74509509, grad/param norm = 1.9619e-01, time/batch = 0.6670s	
14519/25300 (epoch 28.694), train_loss = 0.75498843, grad/param norm = 1.9502e-01, time/batch = 0.6636s	
14520/25300 (epoch 28.696), train_loss = 0.83896699, grad/param norm = 2.2699e-01, time/batch = 0.6569s	
14521/25300 (epoch 28.698), train_loss = 0.86002444, grad/param norm = 2.0404e-01, time/batch = 0.6598s	
14522/25300 (epoch 28.700), train_loss = 0.65521872, grad/param norm = 1.9068e-01, time/batch = 0.6614s	
14523/25300 (epoch 28.702), train_loss = 0.85694889, grad/param norm = 2.0778e-01, time/batch = 0.6571s	
14524/25300 (epoch 28.704), train_loss = 0.65197692, grad/param norm = 1.8855e-01, time/batch = 0.6551s	
14525/25300 (epoch 28.706), train_loss = 0.78863816, grad/param norm = 2.1318e-01, time/batch = 0.6589s	
14526/25300 (epoch 28.708), train_loss = 0.67002596, grad/param norm = 1.8403e-01, time/batch = 0.6590s	
14527/25300 (epoch 28.709), train_loss = 0.94661251, grad/param norm = 2.2134e-01, time/batch = 0.6608s	
14528/25300 (epoch 28.711), train_loss = 0.97517228, grad/param norm = 2.2212e-01, time/batch = 0.6578s	
14529/25300 (epoch 28.713), train_loss = 0.80139349, grad/param norm = 1.9372e-01, time/batch = 0.6611s	
14530/25300 (epoch 28.715), train_loss = 0.81398455, grad/param norm = 1.9187e-01, time/batch = 0.6573s	
14531/25300 (epoch 28.717), train_loss = 0.74063783, grad/param norm = 2.3007e-01, time/batch = 0.6626s	
14532/25300 (epoch 28.719), train_loss = 0.80274041, grad/param norm = 2.1366e-01, time/batch = 0.6613s	
14533/25300 (epoch 28.721), train_loss = 0.85989469, grad/param norm = 2.2383e-01, time/batch = 0.6553s	
14534/25300 (epoch 28.723), train_loss = 0.80911450, grad/param norm = 2.3019e-01, time/batch = 0.6608s	
14535/25300 (epoch 28.725), train_loss = 0.84560437, grad/param norm = 2.2936e-01, time/batch = 0.6582s	
14536/25300 (epoch 28.727), train_loss = 0.81220133, grad/param norm = 2.0515e-01, time/batch = 0.6581s	
14537/25300 (epoch 28.729), train_loss = 0.80665159, grad/param norm = 2.0396e-01, time/batch = 0.6615s	
14538/25300 (epoch 28.731), train_loss = 0.97406572, grad/param norm = 2.3011e-01, time/batch = 0.6652s	
14539/25300 (epoch 28.733), train_loss = 0.79565643, grad/param norm = 1.8420e-01, time/batch = 0.6593s	
14540/25300 (epoch 28.735), train_loss = 1.04748072, grad/param norm = 2.2788e-01, time/batch = 0.6580s	
14541/25300 (epoch 28.737), train_loss = 0.69741923, grad/param norm = 1.7572e-01, time/batch = 0.6551s	
14542/25300 (epoch 28.739), train_loss = 0.95753859, grad/param norm = 2.2748e-01, time/batch = 0.6608s	
14543/25300 (epoch 28.741), train_loss = 0.86691303, grad/param norm = 2.2243e-01, time/batch = 0.6652s	
14544/25300 (epoch 28.743), train_loss = 0.80103125, grad/param norm = 1.8495e-01, time/batch = 0.6661s	
14545/25300 (epoch 28.745), train_loss = 0.77136681, grad/param norm = 2.0507e-01, time/batch = 0.6673s	
14546/25300 (epoch 28.747), train_loss = 0.72745458, grad/param norm = 1.9301e-01, time/batch = 0.6686s	
14547/25300 (epoch 28.749), train_loss = 0.81683707, grad/param norm = 1.9975e-01, time/batch = 0.6606s	
14548/25300 (epoch 28.751), train_loss = 0.89506252, grad/param norm = 2.2935e-01, time/batch = 0.6570s	
14549/25300 (epoch 28.753), train_loss = 0.71350540, grad/param norm = 2.1138e-01, time/batch = 0.6596s	
14550/25300 (epoch 28.755), train_loss = 0.92392254, grad/param norm = 2.4267e-01, time/batch = 0.6626s	
14551/25300 (epoch 28.757), train_loss = 0.77139057, grad/param norm = 2.1757e-01, time/batch = 0.6571s	
14552/25300 (epoch 28.759), train_loss = 0.74629209, grad/param norm = 2.0966e-01, time/batch = 0.6592s	
14553/25300 (epoch 28.761), train_loss = 0.95758530, grad/param norm = 2.0974e-01, time/batch = 0.6562s	
14554/25300 (epoch 28.763), train_loss = 0.78319842, grad/param norm = 1.8571e-01, time/batch = 0.6620s	
14555/25300 (epoch 28.765), train_loss = 0.80530451, grad/param norm = 2.3344e-01, time/batch = 0.6587s	
14556/25300 (epoch 28.767), train_loss = 0.78470044, grad/param norm = 1.8011e-01, time/batch = 0.6605s	
14557/25300 (epoch 28.769), train_loss = 0.82302457, grad/param norm = 2.2037e-01, time/batch = 0.6608s	
14558/25300 (epoch 28.771), train_loss = 0.91214244, grad/param norm = 2.2343e-01, time/batch = 0.6604s	
14559/25300 (epoch 28.773), train_loss = 0.93929230, grad/param norm = 2.5789e-01, time/batch = 0.6595s	
14560/25300 (epoch 28.775), train_loss = 0.81720959, grad/param norm = 1.8452e-01, time/batch = 0.6596s	
14561/25300 (epoch 28.777), train_loss = 0.79883823, grad/param norm = 2.1815e-01, time/batch = 0.6641s	
14562/25300 (epoch 28.779), train_loss = 0.90986843, grad/param norm = 2.1564e-01, time/batch = 0.6654s	
14563/25300 (epoch 28.781), train_loss = 0.87691838, grad/param norm = 2.2266e-01, time/batch = 0.6628s	
14564/25300 (epoch 28.783), train_loss = 0.95758143, grad/param norm = 2.1908e-01, time/batch = 0.6628s	
14565/25300 (epoch 28.785), train_loss = 0.89131738, grad/param norm = 2.2350e-01, time/batch = 0.6658s	
14566/25300 (epoch 28.787), train_loss = 0.88695877, grad/param norm = 2.5589e-01, time/batch = 0.6566s	
14567/25300 (epoch 28.789), train_loss = 0.97890223, grad/param norm = 2.2478e-01, time/batch = 0.6602s	
14568/25300 (epoch 28.791), train_loss = 0.86849207, grad/param norm = 1.9592e-01, time/batch = 0.6574s	
14569/25300 (epoch 28.792), train_loss = 0.94504001, grad/param norm = 2.4032e-01, time/batch = 0.6512s	
14570/25300 (epoch 28.794), train_loss = 0.82583431, grad/param norm = 2.0438e-01, time/batch = 0.6568s	
14571/25300 (epoch 28.796), train_loss = 0.80194720, grad/param norm = 2.2284e-01, time/batch = 0.6585s	
14572/25300 (epoch 28.798), train_loss = 0.91493499, grad/param norm = 2.3837e-01, time/batch = 0.6583s	
14573/25300 (epoch 28.800), train_loss = 0.79620562, grad/param norm = 1.8645e-01, time/batch = 0.6571s	
14574/25300 (epoch 28.802), train_loss = 0.65396071, grad/param norm = 1.8110e-01, time/batch = 0.6707s	
14575/25300 (epoch 28.804), train_loss = 0.83511719, grad/param norm = 2.0190e-01, time/batch = 0.6689s	
14576/25300 (epoch 28.806), train_loss = 0.87638995, grad/param norm = 2.2041e-01, time/batch = 0.6682s	
14577/25300 (epoch 28.808), train_loss = 0.90894611, grad/param norm = 2.0349e-01, time/batch = 0.6705s	
14578/25300 (epoch 28.810), train_loss = 0.80442825, grad/param norm = 2.1300e-01, time/batch = 0.6654s	
14579/25300 (epoch 28.812), train_loss = 0.94566224, grad/param norm = 2.0928e-01, time/batch = 0.6649s	
14580/25300 (epoch 28.814), train_loss = 0.97845389, grad/param norm = 2.3408e-01, time/batch = 0.6604s	
14581/25300 (epoch 28.816), train_loss = 1.05756271, grad/param norm = 2.3948e-01, time/batch = 0.6629s	
14582/25300 (epoch 28.818), train_loss = 0.89561655, grad/param norm = 1.9570e-01, time/batch = 0.6597s	
14583/25300 (epoch 28.820), train_loss = 0.94083202, grad/param norm = 2.4727e-01, time/batch = 0.6578s	
14584/25300 (epoch 28.822), train_loss = 0.79232455, grad/param norm = 2.0175e-01, time/batch = 0.6601s	
14585/25300 (epoch 28.824), train_loss = 0.95502986, grad/param norm = 2.3321e-01, time/batch = 0.6638s	
14586/25300 (epoch 28.826), train_loss = 0.76641485, grad/param norm = 1.9366e-01, time/batch = 0.6560s	
14587/25300 (epoch 28.828), train_loss = 0.75694178, grad/param norm = 2.0410e-01, time/batch = 0.6647s	
14588/25300 (epoch 28.830), train_loss = 0.86276574, grad/param norm = 2.2140e-01, time/batch = 0.6599s	
14589/25300 (epoch 28.832), train_loss = 0.93295101, grad/param norm = 2.3320e-01, time/batch = 0.6596s	
14590/25300 (epoch 28.834), train_loss = 0.75208747, grad/param norm = 1.8667e-01, time/batch = 0.6543s	
14591/25300 (epoch 28.836), train_loss = 0.82290619, grad/param norm = 1.9791e-01, time/batch = 0.6590s	
14592/25300 (epoch 28.838), train_loss = 0.82594585, grad/param norm = 1.9845e-01, time/batch = 0.6551s	
14593/25300 (epoch 28.840), train_loss = 0.92361669, grad/param norm = 2.2003e-01, time/batch = 0.6570s	
14594/25300 (epoch 28.842), train_loss = 0.88265383, grad/param norm = 2.5644e-01, time/batch = 0.6546s	
14595/25300 (epoch 28.844), train_loss = 0.92977376, grad/param norm = 1.9395e-01, time/batch = 0.6616s	
14596/25300 (epoch 28.846), train_loss = 0.90543900, grad/param norm = 1.9904e-01, time/batch = 0.6607s	
14597/25300 (epoch 28.848), train_loss = 0.90465122, grad/param norm = 2.3361e-01, time/batch = 0.6568s	
14598/25300 (epoch 28.850), train_loss = 0.85902145, grad/param norm = 1.9993e-01, time/batch = 0.6606s	
14599/25300 (epoch 28.852), train_loss = 0.91812703, grad/param norm = 2.0597e-01, time/batch = 0.6569s	
14600/25300 (epoch 28.854), train_loss = 0.96735912, grad/param norm = 2.1643e-01, time/batch = 0.6690s	
14601/25300 (epoch 28.856), train_loss = 0.81788990, grad/param norm = 2.1410e-01, time/batch = 0.6602s	
14602/25300 (epoch 28.858), train_loss = 0.86261471, grad/param norm = 2.3296e-01, time/batch = 0.6594s	
14603/25300 (epoch 28.860), train_loss = 0.71801183, grad/param norm = 1.9691e-01, time/batch = 0.6593s	
14604/25300 (epoch 28.862), train_loss = 0.85023211, grad/param norm = 2.3907e-01, time/batch = 0.6564s	
14605/25300 (epoch 28.864), train_loss = 0.93376296, grad/param norm = 2.0743e-01, time/batch = 0.6606s	
14606/25300 (epoch 28.866), train_loss = 0.80280978, grad/param norm = 2.0963e-01, time/batch = 0.6631s	
14607/25300 (epoch 28.868), train_loss = 0.95920595, grad/param norm = 2.0612e-01, time/batch = 0.6615s	
14608/25300 (epoch 28.870), train_loss = 0.93641684, grad/param norm = 1.9161e-01, time/batch = 0.6580s	
14609/25300 (epoch 28.872), train_loss = 0.88244441, grad/param norm = 2.3444e-01, time/batch = 0.6573s	
14610/25300 (epoch 28.874), train_loss = 0.89740837, grad/param norm = 2.2378e-01, time/batch = 0.6574s	
14611/25300 (epoch 28.875), train_loss = 0.82206973, grad/param norm = 2.1239e-01, time/batch = 0.6594s	
14612/25300 (epoch 28.877), train_loss = 0.82417567, grad/param norm = 1.9919e-01, time/batch = 0.6603s	
14613/25300 (epoch 28.879), train_loss = 0.78032479, grad/param norm = 2.1602e-01, time/batch = 0.6585s	
14614/25300 (epoch 28.881), train_loss = 1.13114578, grad/param norm = 2.6710e-01, time/batch = 0.6613s	
14615/25300 (epoch 28.883), train_loss = 1.07824049, grad/param norm = 2.5581e-01, time/batch = 0.6582s	
14616/25300 (epoch 28.885), train_loss = 0.92073695, grad/param norm = 2.4622e-01, time/batch = 0.6624s	
14617/25300 (epoch 28.887), train_loss = 0.94142458, grad/param norm = 2.1038e-01, time/batch = 0.6589s	
14618/25300 (epoch 28.889), train_loss = 1.00657071, grad/param norm = 2.4961e-01, time/batch = 0.6598s	
14619/25300 (epoch 28.891), train_loss = 0.89418281, grad/param norm = 2.5712e-01, time/batch = 0.6552s	
14620/25300 (epoch 28.893), train_loss = 0.89342774, grad/param norm = 2.7178e-01, time/batch = 0.6558s	
14621/25300 (epoch 28.895), train_loss = 0.65560254, grad/param norm = 1.8305e-01, time/batch = 0.6584s	
14622/25300 (epoch 28.897), train_loss = 0.76758825, grad/param norm = 1.7798e-01, time/batch = 0.6571s	
14623/25300 (epoch 28.899), train_loss = 0.87193763, grad/param norm = 2.0778e-01, time/batch = 0.6587s	
14624/25300 (epoch 28.901), train_loss = 0.89864943, grad/param norm = 2.3965e-01, time/batch = 0.6566s	
14625/25300 (epoch 28.903), train_loss = 0.71443521, grad/param norm = 2.2381e-01, time/batch = 0.6644s	
14626/25300 (epoch 28.905), train_loss = 0.80275533, grad/param norm = 2.1875e-01, time/batch = 0.6637s	
14627/25300 (epoch 28.907), train_loss = 0.80459602, grad/param norm = 2.4662e-01, time/batch = 0.6654s	
14628/25300 (epoch 28.909), train_loss = 0.92764333, grad/param norm = 2.2867e-01, time/batch = 0.6656s	
14629/25300 (epoch 28.911), train_loss = 0.97303533, grad/param norm = 2.5590e-01, time/batch = 0.6634s	
14630/25300 (epoch 28.913), train_loss = 1.06697850, grad/param norm = 2.5227e-01, time/batch = 0.6634s	
14631/25300 (epoch 28.915), train_loss = 0.79089324, grad/param norm = 2.0290e-01, time/batch = 0.6637s	
14632/25300 (epoch 28.917), train_loss = 0.98535787, grad/param norm = 2.1668e-01, time/batch = 0.6589s	
14633/25300 (epoch 28.919), train_loss = 0.99499269, grad/param norm = 2.7094e-01, time/batch = 0.6641s	
14634/25300 (epoch 28.921), train_loss = 0.80395242, grad/param norm = 2.1722e-01, time/batch = 0.6642s	
14635/25300 (epoch 28.923), train_loss = 0.95718950, grad/param norm = 2.1432e-01, time/batch = 0.6711s	
14636/25300 (epoch 28.925), train_loss = 0.85736773, grad/param norm = 2.5838e-01, time/batch = 0.6636s	
14637/25300 (epoch 28.927), train_loss = 0.82048933, grad/param norm = 2.0852e-01, time/batch = 0.6725s	
14638/25300 (epoch 28.929), train_loss = 0.88282566, grad/param norm = 2.1284e-01, time/batch = 0.6673s	
14639/25300 (epoch 28.931), train_loss = 0.90531888, grad/param norm = 2.3624e-01, time/batch = 0.6562s	
14640/25300 (epoch 28.933), train_loss = 0.88062864, grad/param norm = 2.0676e-01, time/batch = 0.6537s	
14641/25300 (epoch 28.935), train_loss = 0.89267941, grad/param norm = 2.0481e-01, time/batch = 0.6552s	
14642/25300 (epoch 28.937), train_loss = 0.66102035, grad/param norm = 1.7890e-01, time/batch = 0.6605s	
14643/25300 (epoch 28.939), train_loss = 0.89218870, grad/param norm = 2.1389e-01, time/batch = 0.6563s	
14644/25300 (epoch 28.941), train_loss = 0.79566357, grad/param norm = 2.1537e-01, time/batch = 0.6592s	
14645/25300 (epoch 28.943), train_loss = 0.90235701, grad/param norm = 2.1132e-01, time/batch = 0.6543s	
14646/25300 (epoch 28.945), train_loss = 0.89706223, grad/param norm = 2.2680e-01, time/batch = 0.6560s	
14647/25300 (epoch 28.947), train_loss = 0.78131835, grad/param norm = 1.9999e-01, time/batch = 0.6581s	
14648/25300 (epoch 28.949), train_loss = 0.92505217, grad/param norm = 2.0279e-01, time/batch = 0.6556s	
14649/25300 (epoch 28.951), train_loss = 0.84480027, grad/param norm = 1.7197e-01, time/batch = 0.6606s	
14650/25300 (epoch 28.953), train_loss = 0.85841577, grad/param norm = 2.2373e-01, time/batch = 0.6540s	
14651/25300 (epoch 28.955), train_loss = 1.05498252, grad/param norm = 2.4767e-01, time/batch = 0.6599s	
14652/25300 (epoch 28.957), train_loss = 0.96462508, grad/param norm = 2.4481e-01, time/batch = 0.6562s	
14653/25300 (epoch 28.958), train_loss = 0.94766489, grad/param norm = 2.6718e-01, time/batch = 0.6700s	
14654/25300 (epoch 28.960), train_loss = 1.03543796, grad/param norm = 2.3998e-01, time/batch = 0.6643s	
14655/25300 (epoch 28.962), train_loss = 0.99041274, grad/param norm = 2.2243e-01, time/batch = 0.6599s	
14656/25300 (epoch 28.964), train_loss = 0.91675783, grad/param norm = 2.4703e-01, time/batch = 0.6594s	
14657/25300 (epoch 28.966), train_loss = 0.75871435, grad/param norm = 2.2002e-01, time/batch = 0.6526s	
14658/25300 (epoch 28.968), train_loss = 0.71641751, grad/param norm = 1.9487e-01, time/batch = 0.6588s	
14659/25300 (epoch 28.970), train_loss = 0.82374130, grad/param norm = 2.1348e-01, time/batch = 0.6580s	
14660/25300 (epoch 28.972), train_loss = 0.86600713, grad/param norm = 1.9274e-01, time/batch = 0.6565s	
14661/25300 (epoch 28.974), train_loss = 0.97945964, grad/param norm = 2.3601e-01, time/batch = 0.6626s	
14662/25300 (epoch 28.976), train_loss = 0.90208732, grad/param norm = 2.1933e-01, time/batch = 0.6589s	
14663/25300 (epoch 28.978), train_loss = 0.84184607, grad/param norm = 2.1918e-01, time/batch = 0.6642s	
14664/25300 (epoch 28.980), train_loss = 0.85729151, grad/param norm = 2.0632e-01, time/batch = 0.6707s	
14665/25300 (epoch 28.982), train_loss = 0.81923252, grad/param norm = 2.0388e-01, time/batch = 0.6641s	
14666/25300 (epoch 28.984), train_loss = 0.84406557, grad/param norm = 2.0447e-01, time/batch = 0.6588s	
14667/25300 (epoch 28.986), train_loss = 0.94038100, grad/param norm = 2.3165e-01, time/batch = 0.6608s	
14668/25300 (epoch 28.988), train_loss = 0.91054190, grad/param norm = 2.3869e-01, time/batch = 0.6562s	
14669/25300 (epoch 28.990), train_loss = 0.87412221, grad/param norm = 2.0533e-01, time/batch = 0.6593s	
14670/25300 (epoch 28.992), train_loss = 0.75258053, grad/param norm = 1.8390e-01, time/batch = 0.6578s	
14671/25300 (epoch 28.994), train_loss = 0.88317674, grad/param norm = 2.2793e-01, time/batch = 0.6635s	
14672/25300 (epoch 28.996), train_loss = 0.98466744, grad/param norm = 2.6411e-01, time/batch = 0.6578s	
14673/25300 (epoch 28.998), train_loss = 0.95464530, grad/param norm = 2.2097e-01, time/batch = 0.6593s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
14674/25300 (epoch 29.000), train_loss = 0.90831901, grad/param norm = 2.2923e-01, time/batch = 0.6570s	
14675/25300 (epoch 29.002), train_loss = 0.82492410, grad/param norm = 1.9816e-01, time/batch = 0.6590s	
14676/25300 (epoch 29.004), train_loss = 0.72753164, grad/param norm = 2.1544e-01, time/batch = 0.6561s	
14677/25300 (epoch 29.006), train_loss = 1.00819586, grad/param norm = 2.1183e-01, time/batch = 0.6549s	
14678/25300 (epoch 29.008), train_loss = 0.84859506, grad/param norm = 1.7652e-01, time/batch = 0.6557s	
14679/25300 (epoch 29.010), train_loss = 0.88904612, grad/param norm = 2.1926e-01, time/batch = 0.6545s	
14680/25300 (epoch 29.012), train_loss = 0.81924427, grad/param norm = 1.9961e-01, time/batch = 0.6599s	
14681/25300 (epoch 29.014), train_loss = 0.99578440, grad/param norm = 2.2516e-01, time/batch = 0.6565s	
14682/25300 (epoch 29.016), train_loss = 0.86679222, grad/param norm = 2.2959e-01, time/batch = 0.6542s	
14683/25300 (epoch 29.018), train_loss = 0.76365709, grad/param norm = 1.9584e-01, time/batch = 0.6574s	
14684/25300 (epoch 29.020), train_loss = 0.86752684, grad/param norm = 1.9254e-01, time/batch = 0.6625s	
14685/25300 (epoch 29.022), train_loss = 0.86317821, grad/param norm = 2.2593e-01, time/batch = 0.6583s	
14686/25300 (epoch 29.024), train_loss = 0.65070639, grad/param norm = 1.5803e-01, time/batch = 0.6622s	
14687/25300 (epoch 29.026), train_loss = 0.81026429, grad/param norm = 2.0615e-01, time/batch = 0.6581s	
14688/25300 (epoch 29.028), train_loss = 0.79550462, grad/param norm = 1.9908e-01, time/batch = 0.6623s	
14689/25300 (epoch 29.030), train_loss = 0.95715224, grad/param norm = 1.9071e-01, time/batch = 0.6598s	
14690/25300 (epoch 29.032), train_loss = 0.83500017, grad/param norm = 2.4064e-01, time/batch = 0.6572s	
14691/25300 (epoch 29.034), train_loss = 0.73195978, grad/param norm = 1.8220e-01, time/batch = 0.6628s	
14692/25300 (epoch 29.036), train_loss = 0.70963195, grad/param norm = 1.9689e-01, time/batch = 0.6600s	
14693/25300 (epoch 29.038), train_loss = 0.66296786, grad/param norm = 1.7460e-01, time/batch = 0.6659s	
14694/25300 (epoch 29.040), train_loss = 0.85942904, grad/param norm = 2.0927e-01, time/batch = 0.6654s	
14695/25300 (epoch 29.042), train_loss = 0.83902948, grad/param norm = 1.7826e-01, time/batch = 0.6703s	
14696/25300 (epoch 29.043), train_loss = 0.72854495, grad/param norm = 1.8075e-01, time/batch = 0.6704s	
14697/25300 (epoch 29.045), train_loss = 0.71711845, grad/param norm = 1.9546e-01, time/batch = 0.6703s	
14698/25300 (epoch 29.047), train_loss = 0.88085092, grad/param norm = 2.0490e-01, time/batch = 0.6590s	
14699/25300 (epoch 29.049), train_loss = 0.87681469, grad/param norm = 2.4127e-01, time/batch = 0.6734s	
14700/25300 (epoch 29.051), train_loss = 0.98510595, grad/param norm = 2.3676e-01, time/batch = 0.6606s	
14701/25300 (epoch 29.053), train_loss = 0.67443661, grad/param norm = 1.7699e-01, time/batch = 0.6643s	
14702/25300 (epoch 29.055), train_loss = 0.71751513, grad/param norm = 1.9875e-01, time/batch = 0.6629s	
14703/25300 (epoch 29.057), train_loss = 0.71868992, grad/param norm = 1.8289e-01, time/batch = 0.6621s	
14704/25300 (epoch 29.059), train_loss = 0.79359342, grad/param norm = 2.0519e-01, time/batch = 0.6604s	
14705/25300 (epoch 29.061), train_loss = 0.77721730, grad/param norm = 2.0899e-01, time/batch = 0.6636s	
14706/25300 (epoch 29.063), train_loss = 0.76663086, grad/param norm = 1.8031e-01, time/batch = 0.6598s	
14707/25300 (epoch 29.065), train_loss = 0.86061919, grad/param norm = 2.2802e-01, time/batch = 0.6635s	
14708/25300 (epoch 29.067), train_loss = 0.92667770, grad/param norm = 2.0526e-01, time/batch = 0.6667s	
14709/25300 (epoch 29.069), train_loss = 0.76212534, grad/param norm = 2.0461e-01, time/batch = 0.6666s	
14710/25300 (epoch 29.071), train_loss = 0.90327834, grad/param norm = 2.1434e-01, time/batch = 0.6653s	
14711/25300 (epoch 29.073), train_loss = 0.79470166, grad/param norm = 1.7957e-01, time/batch = 0.6596s	
14712/25300 (epoch 29.075), train_loss = 0.91526964, grad/param norm = 2.2561e-01, time/batch = 0.6584s	
14713/25300 (epoch 29.077), train_loss = 0.87626594, grad/param norm = 2.0698e-01, time/batch = 0.6546s	
14714/25300 (epoch 29.079), train_loss = 0.78348352, grad/param norm = 1.9909e-01, time/batch = 0.6571s	
14715/25300 (epoch 29.081), train_loss = 0.83408783, grad/param norm = 1.7141e-01, time/batch = 0.6529s	
14716/25300 (epoch 29.083), train_loss = 0.83603052, grad/param norm = 1.8985e-01, time/batch = 0.6580s	
14717/25300 (epoch 29.085), train_loss = 1.01544637, grad/param norm = 2.1189e-01, time/batch = 0.6557s	
14718/25300 (epoch 29.087), train_loss = 0.93365216, grad/param norm = 2.0596e-01, time/batch = 0.6590s	
14719/25300 (epoch 29.089), train_loss = 0.88142326, grad/param norm = 1.9211e-01, time/batch = 0.6550s	
14720/25300 (epoch 29.091), train_loss = 1.01849376, grad/param norm = 2.3411e-01, time/batch = 0.6605s	
14721/25300 (epoch 29.093), train_loss = 0.95200365, grad/param norm = 2.3834e-01, time/batch = 0.6637s	
14722/25300 (epoch 29.095), train_loss = 0.92578890, grad/param norm = 2.0575e-01, time/batch = 0.6618s	
14723/25300 (epoch 29.097), train_loss = 0.90971819, grad/param norm = 2.1653e-01, time/batch = 0.6623s	
14724/25300 (epoch 29.099), train_loss = 0.91397010, grad/param norm = 2.6287e-01, time/batch = 0.6666s	
14725/25300 (epoch 29.101), train_loss = 0.80395788, grad/param norm = 2.0026e-01, time/batch = 0.6763s	
14726/25300 (epoch 29.103), train_loss = 0.87850597, grad/param norm = 2.0359e-01, time/batch = 0.6653s	
14727/25300 (epoch 29.105), train_loss = 0.92368512, grad/param norm = 2.1603e-01, time/batch = 0.6751s	
14728/25300 (epoch 29.107), train_loss = 0.95201917, grad/param norm = 2.4621e-01, time/batch = 0.6617s	
14729/25300 (epoch 29.109), train_loss = 0.84620523, grad/param norm = 2.3231e-01, time/batch = 0.6599s	
14730/25300 (epoch 29.111), train_loss = 0.83424000, grad/param norm = 2.0225e-01, time/batch = 0.6638s	
14731/25300 (epoch 29.113), train_loss = 0.80671516, grad/param norm = 2.4556e-01, time/batch = 0.6691s	
14732/25300 (epoch 29.115), train_loss = 0.84386472, grad/param norm = 2.1378e-01, time/batch = 0.6598s	
14733/25300 (epoch 29.117), train_loss = 0.94808807, grad/param norm = 2.0951e-01, time/batch = 0.6609s	
14734/25300 (epoch 29.119), train_loss = 0.80459697, grad/param norm = 2.0006e-01, time/batch = 0.6609s	
14735/25300 (epoch 29.121), train_loss = 0.87455766, grad/param norm = 2.8604e-01, time/batch = 0.6588s	
14736/25300 (epoch 29.123), train_loss = 0.79328552, grad/param norm = 2.1704e-01, time/batch = 0.6760s	
14737/25300 (epoch 29.125), train_loss = 0.94902624, grad/param norm = 2.3410e-01, time/batch = 0.6612s	
14738/25300 (epoch 29.126), train_loss = 0.86355675, grad/param norm = 2.0882e-01, time/batch = 0.6609s	
14739/25300 (epoch 29.128), train_loss = 0.85079255, grad/param norm = 2.3255e-01, time/batch = 0.6652s	
14740/25300 (epoch 29.130), train_loss = 0.67960724, grad/param norm = 1.7348e-01, time/batch = 0.6550s	
14741/25300 (epoch 29.132), train_loss = 0.71323540, grad/param norm = 2.1652e-01, time/batch = 0.6613s	
14742/25300 (epoch 29.134), train_loss = 0.71258343, grad/param norm = 1.8061e-01, time/batch = 0.6622s	
14743/25300 (epoch 29.136), train_loss = 0.82626625, grad/param norm = 1.8679e-01, time/batch = 0.6616s	
14744/25300 (epoch 29.138), train_loss = 0.74758047, grad/param norm = 1.8343e-01, time/batch = 0.6648s	
14745/25300 (epoch 29.140), train_loss = 0.72975753, grad/param norm = 1.8794e-01, time/batch = 0.6636s	
14746/25300 (epoch 29.142), train_loss = 0.94262333, grad/param norm = 2.1700e-01, time/batch = 0.6672s	
14747/25300 (epoch 29.144), train_loss = 0.91412409, grad/param norm = 2.1219e-01, time/batch = 0.6642s	
14748/25300 (epoch 29.146), train_loss = 0.85222270, grad/param norm = 2.1733e-01, time/batch = 0.6636s	
14749/25300 (epoch 29.148), train_loss = 0.83154507, grad/param norm = 1.9763e-01, time/batch = 0.6557s	
14750/25300 (epoch 29.150), train_loss = 0.90277956, grad/param norm = 2.1995e-01, time/batch = 0.6541s	
14751/25300 (epoch 29.152), train_loss = 0.98856105, grad/param norm = 2.3979e-01, time/batch = 0.6604s	
14752/25300 (epoch 29.154), train_loss = 0.71250368, grad/param norm = 1.9699e-01, time/batch = 0.6558s	
14753/25300 (epoch 29.156), train_loss = 0.89001712, grad/param norm = 2.0555e-01, time/batch = 0.6573s	
14754/25300 (epoch 29.158), train_loss = 0.74279286, grad/param norm = 2.1195e-01, time/batch = 0.6553s	
14755/25300 (epoch 29.160), train_loss = 0.85633736, grad/param norm = 2.1659e-01, time/batch = 0.6598s	
14756/25300 (epoch 29.162), train_loss = 0.80491707, grad/param norm = 2.0342e-01, time/batch = 0.6591s	
14757/25300 (epoch 29.164), train_loss = 0.90967040, grad/param norm = 2.1852e-01, time/batch = 0.6594s	
14758/25300 (epoch 29.166), train_loss = 0.86287059, grad/param norm = 2.0110e-01, time/batch = 0.6620s	
14759/25300 (epoch 29.168), train_loss = 0.76384392, grad/param norm = 1.7583e-01, time/batch = 0.6583s	
14760/25300 (epoch 29.170), train_loss = 0.77159791, grad/param norm = 2.2075e-01, time/batch = 0.6610s	
14761/25300 (epoch 29.172), train_loss = 0.74894278, grad/param norm = 2.3732e-01, time/batch = 0.6608s	
14762/25300 (epoch 29.174), train_loss = 0.75103660, grad/param norm = 1.9852e-01, time/batch = 0.6616s	
14763/25300 (epoch 29.176), train_loss = 0.75385135, grad/param norm = 2.0532e-01, time/batch = 0.6597s	
14764/25300 (epoch 29.178), train_loss = 0.97615300, grad/param norm = 2.3276e-01, time/batch = 0.6602s	
14765/25300 (epoch 29.180), train_loss = 0.70415674, grad/param norm = 2.0610e-01, time/batch = 0.6604s	
14766/25300 (epoch 29.182), train_loss = 0.79869843, grad/param norm = 2.3912e-01, time/batch = 0.6595s	
14767/25300 (epoch 29.184), train_loss = 0.76375286, grad/param norm = 2.4440e-01, time/batch = 0.6611s	
14768/25300 (epoch 29.186), train_loss = 0.71155006, grad/param norm = 1.9820e-01, time/batch = 0.6615s	
14769/25300 (epoch 29.188), train_loss = 0.84063686, grad/param norm = 2.4043e-01, time/batch = 0.6683s	
14770/25300 (epoch 29.190), train_loss = 0.79836424, grad/param norm = 1.8445e-01, time/batch = 0.6649s	
14771/25300 (epoch 29.192), train_loss = 0.80132008, grad/param norm = 1.9765e-01, time/batch = 0.6649s	
14772/25300 (epoch 29.194), train_loss = 0.81025000, grad/param norm = 2.2925e-01, time/batch = 0.6621s	
14773/25300 (epoch 29.196), train_loss = 0.93539089, grad/param norm = 2.3349e-01, time/batch = 0.6641s	
14774/25300 (epoch 29.198), train_loss = 0.78415677, grad/param norm = 2.2149e-01, time/batch = 0.6622s	
14775/25300 (epoch 29.200), train_loss = 0.80303669, grad/param norm = 2.2144e-01, time/batch = 0.6798s	
14776/25300 (epoch 29.202), train_loss = 0.81898307, grad/param norm = 2.0202e-01, time/batch = 0.6719s	
14777/25300 (epoch 29.204), train_loss = 0.81815480, grad/param norm = 2.0192e-01, time/batch = 0.6681s	
14778/25300 (epoch 29.206), train_loss = 0.92641499, grad/param norm = 2.5259e-01, time/batch = 0.6651s	
14779/25300 (epoch 29.208), train_loss = 0.75667438, grad/param norm = 2.2416e-01, time/batch = 0.6633s	
14780/25300 (epoch 29.209), train_loss = 0.71820224, grad/param norm = 2.0589e-01, time/batch = 0.6669s	
14781/25300 (epoch 29.211), train_loss = 0.81161588, grad/param norm = 2.0445e-01, time/batch = 0.6660s	
14782/25300 (epoch 29.213), train_loss = 0.87406764, grad/param norm = 2.3600e-01, time/batch = 0.6614s	
14783/25300 (epoch 29.215), train_loss = 0.85820681, grad/param norm = 2.1120e-01, time/batch = 0.6574s	
14784/25300 (epoch 29.217), train_loss = 0.86927257, grad/param norm = 2.3625e-01, time/batch = 0.6601s	
14785/25300 (epoch 29.219), train_loss = 0.91884635, grad/param norm = 2.2024e-01, time/batch = 0.6588s	
14786/25300 (epoch 29.221), train_loss = 0.94876434, grad/param norm = 2.0837e-01, time/batch = 0.6594s	
14787/25300 (epoch 29.223), train_loss = 0.88655258, grad/param norm = 2.2388e-01, time/batch = 0.6646s	
14788/25300 (epoch 29.225), train_loss = 1.15711227, grad/param norm = 2.7258e-01, time/batch = 0.6598s	
14789/25300 (epoch 29.227), train_loss = 0.97283821, grad/param norm = 2.3372e-01, time/batch = 0.6625s	
14790/25300 (epoch 29.229), train_loss = 0.83248433, grad/param norm = 2.1909e-01, time/batch = 0.6571s	
14791/25300 (epoch 29.231), train_loss = 0.85634533, grad/param norm = 2.0936e-01, time/batch = 0.6618s	
14792/25300 (epoch 29.233), train_loss = 0.89804550, grad/param norm = 2.3685e-01, time/batch = 0.6613s	
14793/25300 (epoch 29.235), train_loss = 0.84454465, grad/param norm = 2.0612e-01, time/batch = 0.6661s	
14794/25300 (epoch 29.237), train_loss = 0.96967684, grad/param norm = 2.3422e-01, time/batch = 0.6604s	
14795/25300 (epoch 29.239), train_loss = 0.81211735, grad/param norm = 1.9704e-01, time/batch = 0.6597s	
14796/25300 (epoch 29.241), train_loss = 0.97420627, grad/param norm = 2.2619e-01, time/batch = 0.6580s	
14797/25300 (epoch 29.243), train_loss = 1.12506317, grad/param norm = 2.9038e-01, time/batch = 0.6570s	
14798/25300 (epoch 29.245), train_loss = 0.79840378, grad/param norm = 2.2341e-01, time/batch = 0.6600s	
14799/25300 (epoch 29.247), train_loss = 0.90642872, grad/param norm = 2.0773e-01, time/batch = 0.6568s	
14800/25300 (epoch 29.249), train_loss = 0.72153009, grad/param norm = 1.8403e-01, time/batch = 0.6630s	
14801/25300 (epoch 29.251), train_loss = 0.73256611, grad/param norm = 1.8140e-01, time/batch = 0.6631s	
14802/25300 (epoch 29.253), train_loss = 0.82095189, grad/param norm = 1.9785e-01, time/batch = 0.6660s	
14803/25300 (epoch 29.255), train_loss = 0.77220491, grad/param norm = 2.1448e-01, time/batch = 0.6638s	
14804/25300 (epoch 29.257), train_loss = 0.82479121, grad/param norm = 2.2970e-01, time/batch = 0.6622s	
14805/25300 (epoch 29.259), train_loss = 1.04832215, grad/param norm = 2.7799e-01, time/batch = 0.6581s	
14806/25300 (epoch 29.261), train_loss = 0.97500284, grad/param norm = 2.6605e-01, time/batch = 0.6620s	
14807/25300 (epoch 29.263), train_loss = 1.01221243, grad/param norm = 2.4910e-01, time/batch = 0.6556s	
14808/25300 (epoch 29.265), train_loss = 1.02493391, grad/param norm = 2.3972e-01, time/batch = 0.6572s	
14809/25300 (epoch 29.267), train_loss = 0.92508705, grad/param norm = 2.2142e-01, time/batch = 0.6588s	
14810/25300 (epoch 29.269), train_loss = 0.73350704, grad/param norm = 2.0564e-01, time/batch = 0.6599s	
14811/25300 (epoch 29.271), train_loss = 0.77940371, grad/param norm = 2.1373e-01, time/batch = 0.6609s	
14812/25300 (epoch 29.273), train_loss = 0.93715224, grad/param norm = 2.5141e-01, time/batch = 0.6605s	
14813/25300 (epoch 29.275), train_loss = 0.81063201, grad/param norm = 1.8357e-01, time/batch = 0.6633s	
14814/25300 (epoch 29.277), train_loss = 0.81036120, grad/param norm = 2.3424e-01, time/batch = 0.6657s	
14815/25300 (epoch 29.279), train_loss = 0.85935496, grad/param norm = 2.0464e-01, time/batch = 0.6684s	
14816/25300 (epoch 29.281), train_loss = 0.98652066, grad/param norm = 2.2028e-01, time/batch = 0.6642s	
14817/25300 (epoch 29.283), train_loss = 0.74525477, grad/param norm = 1.8000e-01, time/batch = 0.6656s	
14818/25300 (epoch 29.285), train_loss = 0.84525382, grad/param norm = 2.0321e-01, time/batch = 0.6566s	
14819/25300 (epoch 29.287), train_loss = 0.94860639, grad/param norm = 2.0053e-01, time/batch = 0.6580s	
14820/25300 (epoch 29.289), train_loss = 0.81741169, grad/param norm = 2.0969e-01, time/batch = 0.6561s	
14821/25300 (epoch 29.291), train_loss = 0.81253979, grad/param norm = 1.8945e-01, time/batch = 0.6617s	
14822/25300 (epoch 29.292), train_loss = 1.00367941, grad/param norm = 2.1314e-01, time/batch = 0.6589s	
14823/25300 (epoch 29.294), train_loss = 0.89443533, grad/param norm = 2.0181e-01, time/batch = 0.6610s	
14824/25300 (epoch 29.296), train_loss = 0.76630589, grad/param norm = 1.8935e-01, time/batch = 0.6617s	
14825/25300 (epoch 29.298), train_loss = 0.93284714, grad/param norm = 2.1431e-01, time/batch = 0.6573s	
14826/25300 (epoch 29.300), train_loss = 0.94400379, grad/param norm = 2.3382e-01, time/batch = 0.6604s	
14827/25300 (epoch 29.302), train_loss = 0.69739376, grad/param norm = 2.1166e-01, time/batch = 0.6571s	
14828/25300 (epoch 29.304), train_loss = 0.95361024, grad/param norm = 2.1589e-01, time/batch = 0.6587s	
14829/25300 (epoch 29.306), train_loss = 0.67400333, grad/param norm = 1.9462e-01, time/batch = 0.6782s	
14830/25300 (epoch 29.308), train_loss = 0.92120936, grad/param norm = 2.0592e-01, time/batch = 0.6613s	
14831/25300 (epoch 29.310), train_loss = 0.73848795, grad/param norm = 1.9197e-01, time/batch = 0.6571s	
14832/25300 (epoch 29.312), train_loss = 0.88329174, grad/param norm = 1.9897e-01, time/batch = 0.6550s	
14833/25300 (epoch 29.314), train_loss = 0.69969201, grad/param norm = 1.8703e-01, time/batch = 0.6625s	
14834/25300 (epoch 29.316), train_loss = 0.86433146, grad/param norm = 1.8749e-01, time/batch = 0.6574s	
14835/25300 (epoch 29.318), train_loss = 0.69518887, grad/param norm = 1.8709e-01, time/batch = 0.6591s	
14836/25300 (epoch 29.320), train_loss = 0.76305270, grad/param norm = 1.8877e-01, time/batch = 0.6624s	
14837/25300 (epoch 29.322), train_loss = 0.99830745, grad/param norm = 2.3272e-01, time/batch = 0.6605s	
14838/25300 (epoch 29.324), train_loss = 0.76492384, grad/param norm = 1.9050e-01, time/batch = 0.6581s	
14839/25300 (epoch 29.326), train_loss = 0.69009836, grad/param norm = 1.7306e-01, time/batch = 0.6534s	
14840/25300 (epoch 29.328), train_loss = 0.66837627, grad/param norm = 1.8754e-01, time/batch = 0.6598s	
14841/25300 (epoch 29.330), train_loss = 0.82162262, grad/param norm = 2.1881e-01, time/batch = 0.6554s	
14842/25300 (epoch 29.332), train_loss = 0.86469171, grad/param norm = 2.1832e-01, time/batch = 0.6560s	
14843/25300 (epoch 29.334), train_loss = 0.70892253, grad/param norm = 2.3397e-01, time/batch = 0.6546s	
14844/25300 (epoch 29.336), train_loss = 0.73006832, grad/param norm = 2.8326e-01, time/batch = 0.6579s	
14845/25300 (epoch 29.338), train_loss = 0.71760121, grad/param norm = 1.8549e-01, time/batch = 0.6592s	
14846/25300 (epoch 29.340), train_loss = 0.75545877, grad/param norm = 1.9617e-01, time/batch = 0.6561s	
14847/25300 (epoch 29.342), train_loss = 0.81534433, grad/param norm = 2.5579e-01, time/batch = 0.6588s	
14848/25300 (epoch 29.344), train_loss = 0.90502941, grad/param norm = 2.5772e-01, time/batch = 0.6556s	
14849/25300 (epoch 29.346), train_loss = 0.77826770, grad/param norm = 2.0080e-01, time/batch = 0.6599s	
14850/25300 (epoch 29.348), train_loss = 0.73717600, grad/param norm = 1.9644e-01, time/batch = 0.6564s	
14851/25300 (epoch 29.350), train_loss = 0.81865406, grad/param norm = 2.3524e-01, time/batch = 0.6608s	
14852/25300 (epoch 29.352), train_loss = 0.83925937, grad/param norm = 2.2657e-01, time/batch = 0.6568s	
14853/25300 (epoch 29.354), train_loss = 0.77417573, grad/param norm = 2.2115e-01, time/batch = 0.6620s	
14854/25300 (epoch 29.356), train_loss = 0.82510784, grad/param norm = 2.1595e-01, time/batch = 0.6610s	
14855/25300 (epoch 29.358), train_loss = 0.85251362, grad/param norm = 2.1090e-01, time/batch = 0.6603s	
14856/25300 (epoch 29.360), train_loss = 0.73857295, grad/param norm = 1.9562e-01, time/batch = 0.6592s	
14857/25300 (epoch 29.362), train_loss = 0.73636095, grad/param norm = 1.9552e-01, time/batch = 0.6613s	
14858/25300 (epoch 29.364), train_loss = 0.77306360, grad/param norm = 2.3493e-01, time/batch = 0.6673s	
14859/25300 (epoch 29.366), train_loss = 0.71536747, grad/param norm = 1.8784e-01, time/batch = 0.6601s	
14860/25300 (epoch 29.368), train_loss = 0.80688728, grad/param norm = 1.8006e-01, time/batch = 0.6638s	
14861/25300 (epoch 29.370), train_loss = 0.75087010, grad/param norm = 2.0715e-01, time/batch = 0.6679s	
14862/25300 (epoch 29.372), train_loss = 0.75256693, grad/param norm = 1.9947e-01, time/batch = 0.6682s	
14863/25300 (epoch 29.374), train_loss = 0.70534741, grad/param norm = 1.8596e-01, time/batch = 0.6655s	
14864/25300 (epoch 29.375), train_loss = 0.92387312, grad/param norm = 2.5336e-01, time/batch = 0.6674s	
14865/25300 (epoch 29.377), train_loss = 0.89237195, grad/param norm = 2.3561e-01, time/batch = 0.6661s	
14866/25300 (epoch 29.379), train_loss = 0.85890442, grad/param norm = 2.1417e-01, time/batch = 0.6635s	
14867/25300 (epoch 29.381), train_loss = 0.79500380, grad/param norm = 2.0134e-01, time/batch = 0.6575s	
14868/25300 (epoch 29.383), train_loss = 0.73059108, grad/param norm = 1.8325e-01, time/batch = 0.6627s	
14869/25300 (epoch 29.385), train_loss = 0.84567486, grad/param norm = 2.0204e-01, time/batch = 0.6586s	
14870/25300 (epoch 29.387), train_loss = 0.82720787, grad/param norm = 2.1856e-01, time/batch = 0.6578s	
14871/25300 (epoch 29.389), train_loss = 0.83835222, grad/param norm = 2.2871e-01, time/batch = 0.6605s	
14872/25300 (epoch 29.391), train_loss = 0.77671742, grad/param norm = 1.9356e-01, time/batch = 0.6615s	
14873/25300 (epoch 29.393), train_loss = 0.85104598, grad/param norm = 2.8434e-01, time/batch = 0.6600s	
14874/25300 (epoch 29.395), train_loss = 0.67375066, grad/param norm = 1.9584e-01, time/batch = 0.6618s	
14875/25300 (epoch 29.397), train_loss = 0.69131910, grad/param norm = 2.4942e-01, time/batch = 0.6606s	
14876/25300 (epoch 29.399), train_loss = 0.71079424, grad/param norm = 2.0963e-01, time/batch = 0.6592s	
14877/25300 (epoch 29.401), train_loss = 0.87790185, grad/param norm = 2.2486e-01, time/batch = 0.6591s	
14878/25300 (epoch 29.403), train_loss = 0.84883539, grad/param norm = 2.4999e-01, time/batch = 0.6608s	
14879/25300 (epoch 29.405), train_loss = 0.80284051, grad/param norm = 1.9834e-01, time/batch = 0.6627s	
14880/25300 (epoch 29.407), train_loss = 0.79186520, grad/param norm = 1.9343e-01, time/batch = 0.6587s	
14881/25300 (epoch 29.409), train_loss = 0.74591082, grad/param norm = 1.9071e-01, time/batch = 0.6616s	
14882/25300 (epoch 29.411), train_loss = 0.76637206, grad/param norm = 2.2396e-01, time/batch = 0.6669s	
14883/25300 (epoch 29.413), train_loss = 0.66738909, grad/param norm = 1.7344e-01, time/batch = 0.6620s	
14884/25300 (epoch 29.415), train_loss = 0.73024093, grad/param norm = 1.9110e-01, time/batch = 0.6592s	
14885/25300 (epoch 29.417), train_loss = 0.68548734, grad/param norm = 1.8458e-01, time/batch = 0.6659s	
14886/25300 (epoch 29.419), train_loss = 0.63193391, grad/param norm = 1.7620e-01, time/batch = 0.6571s	
14887/25300 (epoch 29.421), train_loss = 0.69622503, grad/param norm = 1.6615e-01, time/batch = 0.6615s	
14888/25300 (epoch 29.423), train_loss = 0.70664977, grad/param norm = 2.1200e-01, time/batch = 0.6618s	
14889/25300 (epoch 29.425), train_loss = 0.79941804, grad/param norm = 2.5747e-01, time/batch = 0.6564s	
14890/25300 (epoch 29.427), train_loss = 0.91805846, grad/param norm = 2.1606e-01, time/batch = 0.6608s	
14891/25300 (epoch 29.429), train_loss = 0.91497530, grad/param norm = 2.2946e-01, time/batch = 0.6650s	
14892/25300 (epoch 29.431), train_loss = 0.82706969, grad/param norm = 2.1692e-01, time/batch = 0.6612s	
14893/25300 (epoch 29.433), train_loss = 0.82436422, grad/param norm = 1.9339e-01, time/batch = 0.6580s	
14894/25300 (epoch 29.435), train_loss = 0.75619613, grad/param norm = 2.3867e-01, time/batch = 0.6594s	
14895/25300 (epoch 29.437), train_loss = 0.73913987, grad/param norm = 1.9938e-01, time/batch = 0.6587s	
14896/25300 (epoch 29.439), train_loss = 0.83006766, grad/param norm = 2.0055e-01, time/batch = 0.6597s	
14897/25300 (epoch 29.441), train_loss = 0.85899013, grad/param norm = 2.0947e-01, time/batch = 0.6528s	
14898/25300 (epoch 29.443), train_loss = 0.97823947, grad/param norm = 2.4359e-01, time/batch = 0.6589s	
14899/25300 (epoch 29.445), train_loss = 0.91488257, grad/param norm = 2.2363e-01, time/batch = 0.6580s	
14900/25300 (epoch 29.447), train_loss = 0.73799307, grad/param norm = 1.8385e-01, time/batch = 0.6587s	
14901/25300 (epoch 29.449), train_loss = 0.66994586, grad/param norm = 2.0197e-01, time/batch = 0.6621s	
14902/25300 (epoch 29.451), train_loss = 1.00862670, grad/param norm = 2.4269e-01, time/batch = 0.6612s	
14903/25300 (epoch 29.453), train_loss = 0.88531742, grad/param norm = 2.4605e-01, time/batch = 0.6596s	
14904/25300 (epoch 29.455), train_loss = 0.86245073, grad/param norm = 2.3981e-01, time/batch = 0.6652s	
14905/25300 (epoch 29.457), train_loss = 0.76938372, grad/param norm = 2.1949e-01, time/batch = 0.6660s	
14906/25300 (epoch 29.458), train_loss = 0.76493580, grad/param norm = 2.0585e-01, time/batch = 0.6675s	
14907/25300 (epoch 29.460), train_loss = 0.79867367, grad/param norm = 2.2101e-01, time/batch = 0.6665s	
14908/25300 (epoch 29.462), train_loss = 0.59904111, grad/param norm = 1.9419e-01, time/batch = 0.6697s	
14909/25300 (epoch 29.464), train_loss = 0.88946705, grad/param norm = 2.3181e-01, time/batch = 0.6726s	
14910/25300 (epoch 29.466), train_loss = 0.86411083, grad/param norm = 2.1530e-01, time/batch = 0.6728s	
14911/25300 (epoch 29.468), train_loss = 0.87357707, grad/param norm = 2.1585e-01, time/batch = 0.6617s	
14912/25300 (epoch 29.470), train_loss = 0.79177798, grad/param norm = 2.1951e-01, time/batch = 0.6754s	
14913/25300 (epoch 29.472), train_loss = 0.70020400, grad/param norm = 1.9167e-01, time/batch = 0.6680s	
14914/25300 (epoch 29.474), train_loss = 0.84319651, grad/param norm = 1.9001e-01, time/batch = 0.6587s	
14915/25300 (epoch 29.476), train_loss = 0.79244910, grad/param norm = 2.4825e-01, time/batch = 0.6585s	
14916/25300 (epoch 29.478), train_loss = 0.87800893, grad/param norm = 2.4238e-01, time/batch = 0.6567s	
14917/25300 (epoch 29.480), train_loss = 0.77545490, grad/param norm = 1.9782e-01, time/batch = 0.6610s	
14918/25300 (epoch 29.482), train_loss = 0.84825767, grad/param norm = 2.2891e-01, time/batch = 0.6651s	
14919/25300 (epoch 29.484), train_loss = 0.88367816, grad/param norm = 2.4988e-01, time/batch = 0.6610s	
14920/25300 (epoch 29.486), train_loss = 0.81187801, grad/param norm = 2.4508e-01, time/batch = 0.6615s	
14921/25300 (epoch 29.488), train_loss = 0.96562951, grad/param norm = 2.3074e-01, time/batch = 0.6602s	
14922/25300 (epoch 29.490), train_loss = 0.86640505, grad/param norm = 2.2001e-01, time/batch = 0.6589s	
14923/25300 (epoch 29.492), train_loss = 0.91675214, grad/param norm = 2.0836e-01, time/batch = 0.6587s	
14924/25300 (epoch 29.494), train_loss = 0.79691316, grad/param norm = 2.1696e-01, time/batch = 0.6590s	
14925/25300 (epoch 29.496), train_loss = 0.84919210, grad/param norm = 2.1784e-01, time/batch = 0.6615s	
14926/25300 (epoch 29.498), train_loss = 0.80595026, grad/param norm = 2.0906e-01, time/batch = 0.6605s	
14927/25300 (epoch 29.500), train_loss = 0.98278710, grad/param norm = 2.2666e-01, time/batch = 0.6630s	
14928/25300 (epoch 29.502), train_loss = 0.90680770, grad/param norm = 2.6834e-01, time/batch = 0.6582s	
14929/25300 (epoch 29.504), train_loss = 0.80055266, grad/param norm = 2.1975e-01, time/batch = 0.6568s	
14930/25300 (epoch 29.506), train_loss = 0.73770472, grad/param norm = 2.4204e-01, time/batch = 0.6576s	
14931/25300 (epoch 29.508), train_loss = 0.81558632, grad/param norm = 2.2433e-01, time/batch = 0.6590s	
14932/25300 (epoch 29.510), train_loss = 0.75674067, grad/param norm = 2.1076e-01, time/batch = 0.6560s	
14933/25300 (epoch 29.512), train_loss = 0.61994861, grad/param norm = 1.6904e-01, time/batch = 0.6578s	
14934/25300 (epoch 29.514), train_loss = 0.80440701, grad/param norm = 2.1456e-01, time/batch = 0.6582s	
14935/25300 (epoch 29.516), train_loss = 0.87476514, grad/param norm = 2.5091e-01, time/batch = 0.6558s	
14936/25300 (epoch 29.518), train_loss = 0.91692952, grad/param norm = 2.2121e-01, time/batch = 0.6571s	
14937/25300 (epoch 29.520), train_loss = 0.67718153, grad/param norm = 1.6312e-01, time/batch = 0.6589s	
14938/25300 (epoch 29.522), train_loss = 0.77046611, grad/param norm = 2.0936e-01, time/batch = 0.6581s	
14939/25300 (epoch 29.524), train_loss = 0.75470991, grad/param norm = 2.0307e-01, time/batch = 0.6564s	
14940/25300 (epoch 29.526), train_loss = 0.92951930, grad/param norm = 2.0005e-01, time/batch = 0.6545s	
14941/25300 (epoch 29.528), train_loss = 0.94251828, grad/param norm = 2.0130e-01, time/batch = 0.6615s	
14942/25300 (epoch 29.530), train_loss = 0.85664069, grad/param norm = 2.1495e-01, time/batch = 0.6546s	
14943/25300 (epoch 29.532), train_loss = 0.79579166, grad/param norm = 1.9807e-01, time/batch = 0.6533s	
14944/25300 (epoch 29.534), train_loss = 0.79089669, grad/param norm = 2.1104e-01, time/batch = 0.6586s	
14945/25300 (epoch 29.536), train_loss = 0.64947088, grad/param norm = 1.9249e-01, time/batch = 0.6563s	
14946/25300 (epoch 29.538), train_loss = 0.71308137, grad/param norm = 1.7137e-01, time/batch = 0.6503s	
14947/25300 (epoch 29.540), train_loss = 0.73151484, grad/param norm = 1.9645e-01, time/batch = 0.6551s	
14948/25300 (epoch 29.542), train_loss = 0.70639190, grad/param norm = 1.8506e-01, time/batch = 0.6530s	
14949/25300 (epoch 29.543), train_loss = 0.67842642, grad/param norm = 1.7993e-01, time/batch = 0.6569s	
14950/25300 (epoch 29.545), train_loss = 1.01533915, grad/param norm = 2.8359e-01, time/batch = 0.6556s	
14951/25300 (epoch 29.547), train_loss = 0.89521468, grad/param norm = 2.4467e-01, time/batch = 0.6577s	
14952/25300 (epoch 29.549), train_loss = 1.03975436, grad/param norm = 2.8252e-01, time/batch = 0.6587s	
14953/25300 (epoch 29.551), train_loss = 0.90549813, grad/param norm = 2.0214e-01, time/batch = 0.6588s	
14954/25300 (epoch 29.553), train_loss = 0.73785642, grad/param norm = 2.0002e-01, time/batch = 0.6554s	
14955/25300 (epoch 29.555), train_loss = 0.90118451, grad/param norm = 2.2321e-01, time/batch = 0.6572s	
14956/25300 (epoch 29.557), train_loss = 0.91778017, grad/param norm = 2.3376e-01, time/batch = 0.6533s	
14957/25300 (epoch 29.559), train_loss = 0.95263214, grad/param norm = 2.2208e-01, time/batch = 0.6529s	
14958/25300 (epoch 29.561), train_loss = 0.94859770, grad/param norm = 2.2279e-01, time/batch = 0.6544s	
14959/25300 (epoch 29.563), train_loss = 0.90736411, grad/param norm = 2.4026e-01, time/batch = 0.6556s	
14960/25300 (epoch 29.565), train_loss = 0.72840439, grad/param norm = 2.0192e-01, time/batch = 0.6578s	
14961/25300 (epoch 29.567), train_loss = 0.64589246, grad/param norm = 1.8663e-01, time/batch = 0.6554s	
14962/25300 (epoch 29.569), train_loss = 0.83474513, grad/param norm = 2.2366e-01, time/batch = 0.6555s	
14963/25300 (epoch 29.571), train_loss = 0.91251229, grad/param norm = 2.4924e-01, time/batch = 0.6488s	
14964/25300 (epoch 29.573), train_loss = 0.80321281, grad/param norm = 1.9750e-01, time/batch = 0.6566s	
14965/25300 (epoch 29.575), train_loss = 0.90020560, grad/param norm = 2.1745e-01, time/batch = 0.6580s	
14966/25300 (epoch 29.577), train_loss = 0.81157085, grad/param norm = 2.3045e-01, time/batch = 0.6586s	
14967/25300 (epoch 29.579), train_loss = 0.94387318, grad/param norm = 2.2370e-01, time/batch = 0.6568s	
14968/25300 (epoch 29.581), train_loss = 0.88747300, grad/param norm = 2.1274e-01, time/batch = 0.6584s	
14969/25300 (epoch 29.583), train_loss = 0.70272400, grad/param norm = 2.0733e-01, time/batch = 0.6656s	
14970/25300 (epoch 29.585), train_loss = 0.70299001, grad/param norm = 2.1107e-01, time/batch = 0.6611s	
14971/25300 (epoch 29.587), train_loss = 0.79462187, grad/param norm = 1.8539e-01, time/batch = 0.6607s	
14972/25300 (epoch 29.589), train_loss = 0.69417423, grad/param norm = 1.5513e-01, time/batch = 0.6655s	
14973/25300 (epoch 29.591), train_loss = 0.70274086, grad/param norm = 2.4358e-01, time/batch = 0.6601s	
14974/25300 (epoch 29.593), train_loss = 0.89370216, grad/param norm = 2.3049e-01, time/batch = 0.6578s	
14975/25300 (epoch 29.595), train_loss = 0.81113842, grad/param norm = 2.0790e-01, time/batch = 0.6599s	
14976/25300 (epoch 29.597), train_loss = 0.73374123, grad/param norm = 2.0044e-01, time/batch = 0.6614s	
14977/25300 (epoch 29.599), train_loss = 0.90737216, grad/param norm = 2.3083e-01, time/batch = 0.6568s	
14978/25300 (epoch 29.601), train_loss = 0.81182441, grad/param norm = 2.1901e-01, time/batch = 0.6558s	
14979/25300 (epoch 29.603), train_loss = 0.82194425, grad/param norm = 2.2567e-01, time/batch = 0.6590s	
14980/25300 (epoch 29.605), train_loss = 0.77195950, grad/param norm = 2.2022e-01, time/batch = 0.6573s	
14981/25300 (epoch 29.607), train_loss = 0.58856204, grad/param norm = 1.7220e-01, time/batch = 0.6609s	
14982/25300 (epoch 29.609), train_loss = 0.78017399, grad/param norm = 2.2924e-01, time/batch = 0.6574s	
14983/25300 (epoch 29.611), train_loss = 0.82688224, grad/param norm = 2.1780e-01, time/batch = 0.6579s	
14984/25300 (epoch 29.613), train_loss = 0.71978375, grad/param norm = 1.9233e-01, time/batch = 0.6594s	
14985/25300 (epoch 29.615), train_loss = 0.79590170, grad/param norm = 2.2790e-01, time/batch = 0.6580s	
14986/25300 (epoch 29.617), train_loss = 0.82674747, grad/param norm = 2.3143e-01, time/batch = 0.6663s	
14987/25300 (epoch 29.619), train_loss = 0.89242139, grad/param norm = 2.2844e-01, time/batch = 0.6600s	
14988/25300 (epoch 29.621), train_loss = 0.90146961, grad/param norm = 2.1273e-01, time/batch = 0.6597s	
14989/25300 (epoch 29.623), train_loss = 0.73685062, grad/param norm = 2.0137e-01, time/batch = 0.6616s	
14990/25300 (epoch 29.625), train_loss = 0.68056967, grad/param norm = 2.0564e-01, time/batch = 0.6588s	
14991/25300 (epoch 29.626), train_loss = 0.78019874, grad/param norm = 1.7998e-01, time/batch = 0.6579s	
14992/25300 (epoch 29.628), train_loss = 0.89272655, grad/param norm = 2.2080e-01, time/batch = 0.6613s	
14993/25300 (epoch 29.630), train_loss = 0.86748790, grad/param norm = 2.1595e-01, time/batch = 0.6597s	
14994/25300 (epoch 29.632), train_loss = 0.86727655, grad/param norm = 2.6900e-01, time/batch = 0.6623s	
14995/25300 (epoch 29.634), train_loss = 0.93561585, grad/param norm = 2.4759e-01, time/batch = 0.6670s	
14996/25300 (epoch 29.636), train_loss = 0.73593997, grad/param norm = 2.0721e-01, time/batch = 0.6685s	
14997/25300 (epoch 29.638), train_loss = 0.87117253, grad/param norm = 2.7801e-01, time/batch = 0.6678s	
14998/25300 (epoch 29.640), train_loss = 1.01357590, grad/param norm = 2.6884e-01, time/batch = 0.6535s	
14999/25300 (epoch 29.642), train_loss = 0.84990334, grad/param norm = 2.1884e-01, time/batch = 0.6582s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch29.64_1.6867.t7	
15000/25300 (epoch 29.644), train_loss = 0.84043148, grad/param norm = 2.1344e-01, time/batch = 0.6835s	
15001/25300 (epoch 29.646), train_loss = 1.31448398, grad/param norm = 2.9288e-01, time/batch = 0.6670s	
15002/25300 (epoch 29.648), train_loss = 0.89076605, grad/param norm = 1.9547e-01, time/batch = 0.6621s	
15003/25300 (epoch 29.650), train_loss = 0.84341668, grad/param norm = 2.0650e-01, time/batch = 0.6603s	
15004/25300 (epoch 29.652), train_loss = 0.85325432, grad/param norm = 2.2033e-01, time/batch = 0.6652s	
15005/25300 (epoch 29.654), train_loss = 0.96698432, grad/param norm = 2.2188e-01, time/batch = 0.6574s	
15006/25300 (epoch 29.656), train_loss = 0.89073658, grad/param norm = 2.2276e-01, time/batch = 0.6588s	
15007/25300 (epoch 29.658), train_loss = 0.67024156, grad/param norm = 1.9078e-01, time/batch = 0.6616s	
15008/25300 (epoch 29.660), train_loss = 0.69716281, grad/param norm = 2.0431e-01, time/batch = 0.6654s	
15009/25300 (epoch 29.662), train_loss = 0.69061703, grad/param norm = 1.9375e-01, time/batch = 0.6643s	
15010/25300 (epoch 29.664), train_loss = 0.66853299, grad/param norm = 2.1287e-01, time/batch = 0.6620s	
15011/25300 (epoch 29.666), train_loss = 0.73095695, grad/param norm = 2.1232e-01, time/batch = 0.6592s	
15012/25300 (epoch 29.668), train_loss = 0.81808339, grad/param norm = 3.1841e-01, time/batch = 0.6613s	
15013/25300 (epoch 29.670), train_loss = 0.77400148, grad/param norm = 2.5441e-01, time/batch = 0.6604s	
15014/25300 (epoch 29.672), train_loss = 0.73142315, grad/param norm = 2.0958e-01, time/batch = 0.6668s	
15015/25300 (epoch 29.674), train_loss = 0.74901253, grad/param norm = 1.8656e-01, time/batch = 0.6621s	
15016/25300 (epoch 29.676), train_loss = 0.78046927, grad/param norm = 2.5400e-01, time/batch = 0.6607s	
15017/25300 (epoch 29.678), train_loss = 0.77241283, grad/param norm = 2.1677e-01, time/batch = 0.6625s	
15018/25300 (epoch 29.680), train_loss = 0.66561133, grad/param norm = 1.8730e-01, time/batch = 0.6616s	
15019/25300 (epoch 29.682), train_loss = 0.56527609, grad/param norm = 1.8038e-01, time/batch = 0.6623s	
15020/25300 (epoch 29.684), train_loss = 0.72167676, grad/param norm = 1.7428e-01, time/batch = 0.6571s	
15021/25300 (epoch 29.686), train_loss = 0.67554615, grad/param norm = 1.8054e-01, time/batch = 0.6807s	
15022/25300 (epoch 29.688), train_loss = 0.76464416, grad/param norm = 2.2013e-01, time/batch = 0.6631s	
15023/25300 (epoch 29.690), train_loss = 0.70081527, grad/param norm = 1.8893e-01, time/batch = 0.6672s	
15024/25300 (epoch 29.692), train_loss = 0.71210860, grad/param norm = 1.6601e-01, time/batch = 0.6584s	
15025/25300 (epoch 29.694), train_loss = 0.71577556, grad/param norm = 1.9680e-01, time/batch = 0.6591s	
15026/25300 (epoch 29.696), train_loss = 0.81640547, grad/param norm = 2.1752e-01, time/batch = 0.6698s	
15027/25300 (epoch 29.698), train_loss = 0.85705507, grad/param norm = 2.1909e-01, time/batch = 0.6590s	
15028/25300 (epoch 29.700), train_loss = 0.64788668, grad/param norm = 1.8445e-01, time/batch = 0.6570s	
15029/25300 (epoch 29.702), train_loss = 0.85140785, grad/param norm = 2.1682e-01, time/batch = 0.6552s	
15030/25300 (epoch 29.704), train_loss = 0.63812942, grad/param norm = 1.7632e-01, time/batch = 0.6558s	
15031/25300 (epoch 29.706), train_loss = 0.77124938, grad/param norm = 2.2034e-01, time/batch = 0.6583s	
15032/25300 (epoch 29.708), train_loss = 0.66472964, grad/param norm = 1.8640e-01, time/batch = 0.6576s	
15033/25300 (epoch 29.709), train_loss = 0.92392438, grad/param norm = 2.2022e-01, time/batch = 0.6578s	
15034/25300 (epoch 29.711), train_loss = 0.96039157, grad/param norm = 2.2647e-01, time/batch = 0.6609s	
15035/25300 (epoch 29.713), train_loss = 0.78234773, grad/param norm = 1.7026e-01, time/batch = 0.6586s	
15036/25300 (epoch 29.715), train_loss = 0.78061628, grad/param norm = 1.8511e-01, time/batch = 0.6616s	
15037/25300 (epoch 29.717), train_loss = 0.71251401, grad/param norm = 2.0580e-01, time/batch = 0.6606s	
15038/25300 (epoch 29.719), train_loss = 0.78227940, grad/param norm = 2.1991e-01, time/batch = 0.6596s	
15039/25300 (epoch 29.721), train_loss = 0.83564522, grad/param norm = 2.0652e-01, time/batch = 0.6586s	
15040/25300 (epoch 29.723), train_loss = 0.78841742, grad/param norm = 2.0174e-01, time/batch = 0.6564s	
15041/25300 (epoch 29.725), train_loss = 0.82268464, grad/param norm = 2.0253e-01, time/batch = 0.6606s	
15042/25300 (epoch 29.727), train_loss = 0.79813766, grad/param norm = 2.1168e-01, time/batch = 0.6597s	
15043/25300 (epoch 29.729), train_loss = 0.78897515, grad/param norm = 1.9401e-01, time/batch = 0.6593s	
15044/25300 (epoch 29.731), train_loss = 0.94873278, grad/param norm = 2.2880e-01, time/batch = 0.6589s	
15045/25300 (epoch 29.733), train_loss = 0.78167482, grad/param norm = 1.9187e-01, time/batch = 0.6595s	
15046/25300 (epoch 29.735), train_loss = 1.03352222, grad/param norm = 2.3327e-01, time/batch = 0.6590s	
15047/25300 (epoch 29.737), train_loss = 0.69757149, grad/param norm = 1.9854e-01, time/batch = 0.6610s	
15048/25300 (epoch 29.739), train_loss = 0.94181205, grad/param norm = 2.2500e-01, time/batch = 0.6602s	
15049/25300 (epoch 29.741), train_loss = 0.85011986, grad/param norm = 2.2846e-01, time/batch = 0.6585s	
15050/25300 (epoch 29.743), train_loss = 0.78636098, grad/param norm = 1.8329e-01, time/batch = 0.6588s	
15051/25300 (epoch 29.745), train_loss = 0.76665707, grad/param norm = 2.1707e-01, time/batch = 0.6596s	
15052/25300 (epoch 29.747), train_loss = 0.69695296, grad/param norm = 1.8338e-01, time/batch = 0.6590s	
15053/25300 (epoch 29.749), train_loss = 0.79946750, grad/param norm = 2.2253e-01, time/batch = 0.6577s	
15054/25300 (epoch 29.751), train_loss = 0.86719346, grad/param norm = 2.2239e-01, time/batch = 0.6607s	
15055/25300 (epoch 29.753), train_loss = 0.70469785, grad/param norm = 2.0872e-01, time/batch = 0.6590s	
15056/25300 (epoch 29.755), train_loss = 0.90991854, grad/param norm = 2.3471e-01, time/batch = 0.6601s	
15057/25300 (epoch 29.757), train_loss = 0.74764300, grad/param norm = 2.1103e-01, time/batch = 0.6581s	
15058/25300 (epoch 29.759), train_loss = 0.73843273, grad/param norm = 2.2876e-01, time/batch = 0.6576s	
15059/25300 (epoch 29.761), train_loss = 0.95621824, grad/param norm = 2.2650e-01, time/batch = 0.6507s	
15060/25300 (epoch 29.763), train_loss = 0.77544136, grad/param norm = 2.0176e-01, time/batch = 0.6585s	
15061/25300 (epoch 29.765), train_loss = 0.78398675, grad/param norm = 2.1440e-01, time/batch = 0.6585s	
15062/25300 (epoch 29.767), train_loss = 0.77594247, grad/param norm = 1.8232e-01, time/batch = 0.6571s	
15063/25300 (epoch 29.769), train_loss = 0.81287824, grad/param norm = 2.4309e-01, time/batch = 0.6540s	
15064/25300 (epoch 29.771), train_loss = 0.91891644, grad/param norm = 2.4142e-01, time/batch = 0.6550s	
15065/25300 (epoch 29.773), train_loss = 0.95256867, grad/param norm = 2.5949e-01, time/batch = 0.6591s	
15066/25300 (epoch 29.775), train_loss = 0.82953001, grad/param norm = 1.9823e-01, time/batch = 0.6611s	
15067/25300 (epoch 29.777), train_loss = 0.79104272, grad/param norm = 2.3401e-01, time/batch = 0.6561s	
15068/25300 (epoch 29.779), train_loss = 0.88967863, grad/param norm = 2.1565e-01, time/batch = 0.6539s	
15069/25300 (epoch 29.781), train_loss = 0.85431038, grad/param norm = 2.1848e-01, time/batch = 0.6548s	
15070/25300 (epoch 29.783), train_loss = 0.94672260, grad/param norm = 2.2264e-01, time/batch = 0.6587s	
15071/25300 (epoch 29.785), train_loss = 0.88024226, grad/param norm = 2.2061e-01, time/batch = 0.6592s	
15072/25300 (epoch 29.787), train_loss = 0.86394738, grad/param norm = 2.4982e-01, time/batch = 0.6608s	
15073/25300 (epoch 29.789), train_loss = 0.98466838, grad/param norm = 2.7280e-01, time/batch = 0.6544s	
15074/25300 (epoch 29.791), train_loss = 0.86079044, grad/param norm = 2.1426e-01, time/batch = 0.6584s	
15075/25300 (epoch 29.792), train_loss = 0.93658419, grad/param norm = 2.2174e-01, time/batch = 0.6570s	
15076/25300 (epoch 29.794), train_loss = 0.82116582, grad/param norm = 2.0952e-01, time/batch = 0.6603s	
15077/25300 (epoch 29.796), train_loss = 0.79965961, grad/param norm = 2.5503e-01, time/batch = 0.6596s	
15078/25300 (epoch 29.798), train_loss = 0.91600089, grad/param norm = 2.5786e-01, time/batch = 0.6661s	
15079/25300 (epoch 29.800), train_loss = 0.80135626, grad/param norm = 1.9281e-01, time/batch = 0.6701s	
15080/25300 (epoch 29.802), train_loss = 0.64008045, grad/param norm = 1.8821e-01, time/batch = 0.6707s	
15081/25300 (epoch 29.804), train_loss = 0.82555865, grad/param norm = 1.9797e-01, time/batch = 0.6645s	
15082/25300 (epoch 29.806), train_loss = 0.88134242, grad/param norm = 2.3994e-01, time/batch = 0.6605s	
15083/25300 (epoch 29.808), train_loss = 0.92586160, grad/param norm = 2.3038e-01, time/batch = 0.6599s	
15084/25300 (epoch 29.810), train_loss = 0.79483105, grad/param norm = 2.4500e-01, time/batch = 0.6664s	
15085/25300 (epoch 29.812), train_loss = 0.93107694, grad/param norm = 2.2139e-01, time/batch = 0.6588s	
15086/25300 (epoch 29.814), train_loss = 0.96648478, grad/param norm = 2.3845e-01, time/batch = 0.6586s	
15087/25300 (epoch 29.816), train_loss = 1.03888152, grad/param norm = 2.6055e-01, time/batch = 0.6619s	
15088/25300 (epoch 29.818), train_loss = 0.89182232, grad/param norm = 1.8574e-01, time/batch = 0.6581s	
15089/25300 (epoch 29.820), train_loss = 0.93529432, grad/param norm = 2.3786e-01, time/batch = 0.6596s	
15090/25300 (epoch 29.822), train_loss = 0.77806210, grad/param norm = 1.9551e-01, time/batch = 0.6628s	
15091/25300 (epoch 29.824), train_loss = 0.93656844, grad/param norm = 2.2603e-01, time/batch = 0.6550s	
15092/25300 (epoch 29.826), train_loss = 0.75257154, grad/param norm = 1.8858e-01, time/batch = 0.6588s	
15093/25300 (epoch 29.828), train_loss = 0.76020492, grad/param norm = 2.1183e-01, time/batch = 0.6737s	
15094/25300 (epoch 29.830), train_loss = 0.85908509, grad/param norm = 2.1846e-01, time/batch = 0.6703s	
15095/25300 (epoch 29.832), train_loss = 0.93256607, grad/param norm = 2.4482e-01, time/batch = 0.6596s	
15096/25300 (epoch 29.834), train_loss = 0.75684802, grad/param norm = 2.1617e-01, time/batch = 0.6508s	
15097/25300 (epoch 29.836), train_loss = 0.81377268, grad/param norm = 1.8850e-01, time/batch = 0.6629s	
15098/25300 (epoch 29.838), train_loss = 0.79619627, grad/param norm = 1.9018e-01, time/batch = 0.6539s	
15099/25300 (epoch 29.840), train_loss = 0.90352253, grad/param norm = 2.2883e-01, time/batch = 0.6603s	
15100/25300 (epoch 29.842), train_loss = 0.84948695, grad/param norm = 2.4574e-01, time/batch = 0.6579s	
15101/25300 (epoch 29.844), train_loss = 0.91360921, grad/param norm = 1.8552e-01, time/batch = 0.6601s	
15102/25300 (epoch 29.846), train_loss = 0.88333845, grad/param norm = 1.9421e-01, time/batch = 0.6558s	
15103/25300 (epoch 29.848), train_loss = 0.88944572, grad/param norm = 2.2020e-01, time/batch = 0.6607s	
15104/25300 (epoch 29.850), train_loss = 0.85152721, grad/param norm = 2.0727e-01, time/batch = 0.6574s	
15105/25300 (epoch 29.852), train_loss = 0.90807493, grad/param norm = 2.0272e-01, time/batch = 0.6596s	
15106/25300 (epoch 29.854), train_loss = 0.95455110, grad/param norm = 2.2900e-01, time/batch = 0.6588s	
15107/25300 (epoch 29.856), train_loss = 0.78457035, grad/param norm = 1.9234e-01, time/batch = 0.6610s	
15108/25300 (epoch 29.858), train_loss = 0.84163511, grad/param norm = 2.2283e-01, time/batch = 0.6570s	
15109/25300 (epoch 29.860), train_loss = 0.69565167, grad/param norm = 1.9365e-01, time/batch = 0.6641s	
15110/25300 (epoch 29.862), train_loss = 0.81821032, grad/param norm = 2.1325e-01, time/batch = 0.6589s	
15111/25300 (epoch 29.864), train_loss = 0.92889413, grad/param norm = 2.1115e-01, time/batch = 0.6616s	
15112/25300 (epoch 29.866), train_loss = 0.78742707, grad/param norm = 2.1203e-01, time/batch = 0.6626s	
15113/25300 (epoch 29.868), train_loss = 0.95650507, grad/param norm = 2.2159e-01, time/batch = 0.6606s	
15114/25300 (epoch 29.870), train_loss = 0.91945094, grad/param norm = 1.8990e-01, time/batch = 0.6630s	
15115/25300 (epoch 29.872), train_loss = 0.86642531, grad/param norm = 2.3021e-01, time/batch = 0.6594s	
15116/25300 (epoch 29.874), train_loss = 0.86347098, grad/param norm = 2.1584e-01, time/batch = 0.6602s	
15117/25300 (epoch 29.875), train_loss = 0.80206706, grad/param norm = 2.3427e-01, time/batch = 0.6559s	
15118/25300 (epoch 29.877), train_loss = 0.80205338, grad/param norm = 1.8633e-01, time/batch = 0.6607s	
15119/25300 (epoch 29.879), train_loss = 0.75980822, grad/param norm = 2.0006e-01, time/batch = 0.6619s	
15120/25300 (epoch 29.881), train_loss = 1.09750223, grad/param norm = 2.5274e-01, time/batch = 0.6540s	
15121/25300 (epoch 29.883), train_loss = 1.05538499, grad/param norm = 2.2532e-01, time/batch = 0.6625s	
15122/25300 (epoch 29.885), train_loss = 0.91716748, grad/param norm = 2.6351e-01, time/batch = 0.6573s	
15123/25300 (epoch 29.887), train_loss = 0.92575202, grad/param norm = 3.4640e-01, time/batch = 0.6560s	
15124/25300 (epoch 29.889), train_loss = 1.00689167, grad/param norm = 2.7170e-01, time/batch = 0.6583s	
15125/25300 (epoch 29.891), train_loss = 0.87849315, grad/param norm = 2.5309e-01, time/batch = 0.6570s	
15126/25300 (epoch 29.893), train_loss = 0.90956612, grad/param norm = 2.9188e-01, time/batch = 0.6597s	
15127/25300 (epoch 29.895), train_loss = 0.65467830, grad/param norm = 1.9748e-01, time/batch = 0.6584s	
15128/25300 (epoch 29.897), train_loss = 0.75786683, grad/param norm = 3.0305e-01, time/batch = 0.6614s	
15129/25300 (epoch 29.899), train_loss = 0.88004172, grad/param norm = 2.3547e-01, time/batch = 0.6567s	
15130/25300 (epoch 29.901), train_loss = 0.89160610, grad/param norm = 2.5203e-01, time/batch = 0.6568s	
15131/25300 (epoch 29.903), train_loss = 0.71065488, grad/param norm = 2.2955e-01, time/batch = 0.6605s	
15132/25300 (epoch 29.905), train_loss = 0.81226043, grad/param norm = 2.5037e-01, time/batch = 0.6581s	
15133/25300 (epoch 29.907), train_loss = 0.77902682, grad/param norm = 2.1609e-01, time/batch = 0.6617s	
15134/25300 (epoch 29.909), train_loss = 0.91736984, grad/param norm = 2.1926e-01, time/batch = 0.6545s	
15135/25300 (epoch 29.911), train_loss = 0.97429951, grad/param norm = 2.5901e-01, time/batch = 0.6573s	
15136/25300 (epoch 29.913), train_loss = 1.05537208, grad/param norm = 2.6800e-01, time/batch = 0.6591s	
15137/25300 (epoch 29.915), train_loss = 0.78778037, grad/param norm = 2.2935e-01, time/batch = 0.6583s	
15138/25300 (epoch 29.917), train_loss = 0.97926903, grad/param norm = 2.3894e-01, time/batch = 0.6577s	
15139/25300 (epoch 29.919), train_loss = 0.97799103, grad/param norm = 2.6145e-01, time/batch = 0.6569s	
15140/25300 (epoch 29.921), train_loss = 0.78415716, grad/param norm = 2.0187e-01, time/batch = 0.6655s	
15141/25300 (epoch 29.923), train_loss = 0.95471173, grad/param norm = 2.2876e-01, time/batch = 0.6582s	
15142/25300 (epoch 29.925), train_loss = 0.85944799, grad/param norm = 2.1897e-01, time/batch = 0.6648s	
15143/25300 (epoch 29.927), train_loss = 0.80855579, grad/param norm = 2.0379e-01, time/batch = 0.6605s	
15144/25300 (epoch 29.929), train_loss = 0.86174778, grad/param norm = 2.0669e-01, time/batch = 0.6573s	
15145/25300 (epoch 29.931), train_loss = 0.91645695, grad/param norm = 2.5779e-01, time/batch = 0.6618s	
15146/25300 (epoch 29.933), train_loss = 0.88465580, grad/param norm = 2.1831e-01, time/batch = 0.6583s	
15147/25300 (epoch 29.935), train_loss = 0.88730332, grad/param norm = 1.9564e-01, time/batch = 0.6557s	
15148/25300 (epoch 29.937), train_loss = 0.65479435, grad/param norm = 1.7391e-01, time/batch = 0.6637s	
15149/25300 (epoch 29.939), train_loss = 0.87553307, grad/param norm = 2.1659e-01, time/batch = 0.6571s	
15150/25300 (epoch 29.941), train_loss = 0.78653389, grad/param norm = 2.1917e-01, time/batch = 0.6600s	
15151/25300 (epoch 29.943), train_loss = 0.90293686, grad/param norm = 2.2577e-01, time/batch = 0.6564s	
15152/25300 (epoch 29.945), train_loss = 0.87899954, grad/param norm = 2.2358e-01, time/batch = 0.6584s	
15153/25300 (epoch 29.947), train_loss = 0.76705395, grad/param norm = 2.2278e-01, time/batch = 0.6605s	
15154/25300 (epoch 29.949), train_loss = 0.90498597, grad/param norm = 2.1061e-01, time/batch = 0.6576s	
15155/25300 (epoch 29.951), train_loss = 0.83865252, grad/param norm = 1.8851e-01, time/batch = 0.6619s	
15156/25300 (epoch 29.953), train_loss = 0.83162193, grad/param norm = 2.0683e-01, time/batch = 0.6581s	
15157/25300 (epoch 29.955), train_loss = 1.05643519, grad/param norm = 2.7071e-01, time/batch = 0.6568s	
15158/25300 (epoch 29.957), train_loss = 0.97432693, grad/param norm = 2.5636e-01, time/batch = 0.6577s	
15159/25300 (epoch 29.958), train_loss = 0.92483657, grad/param norm = 2.3999e-01, time/batch = 0.6613s	
15160/25300 (epoch 29.960), train_loss = 1.02319347, grad/param norm = 2.4909e-01, time/batch = 0.6577s	
15161/25300 (epoch 29.962), train_loss = 0.98643183, grad/param norm = 2.2396e-01, time/batch = 0.6613s	
15162/25300 (epoch 29.964), train_loss = 0.90422041, grad/param norm = 2.3879e-01, time/batch = 0.6592s	
15163/25300 (epoch 29.966), train_loss = 0.73791183, grad/param norm = 1.9990e-01, time/batch = 0.6588s	
15164/25300 (epoch 29.968), train_loss = 0.72512447, grad/param norm = 1.9350e-01, time/batch = 0.6561s	
15165/25300 (epoch 29.970), train_loss = 0.80297824, grad/param norm = 2.4778e-01, time/batch = 0.6577s	
15166/25300 (epoch 29.972), train_loss = 0.85701732, grad/param norm = 2.0478e-01, time/batch = 0.6608s	
15167/25300 (epoch 29.974), train_loss = 0.94885345, grad/param norm = 2.5310e-01, time/batch = 0.6614s	
15168/25300 (epoch 29.976), train_loss = 0.88325034, grad/param norm = 2.2129e-01, time/batch = 0.6646s	
15169/25300 (epoch 29.978), train_loss = 0.82524799, grad/param norm = 2.1116e-01, time/batch = 0.6633s	
15170/25300 (epoch 29.980), train_loss = 0.85386168, grad/param norm = 2.2371e-01, time/batch = 0.6711s	
15171/25300 (epoch 29.982), train_loss = 0.80066269, grad/param norm = 2.0899e-01, time/batch = 0.6734s	
15172/25300 (epoch 29.984), train_loss = 0.82920724, grad/param norm = 2.1789e-01, time/batch = 0.6801s	
15173/25300 (epoch 29.986), train_loss = 0.92170636, grad/param norm = 2.1556e-01, time/batch = 0.6692s	
15174/25300 (epoch 29.988), train_loss = 0.89995290, grad/param norm = 2.5888e-01, time/batch = 0.6689s	
15175/25300 (epoch 29.990), train_loss = 0.86838906, grad/param norm = 2.1597e-01, time/batch = 0.6705s	
15176/25300 (epoch 29.992), train_loss = 0.75242459, grad/param norm = 1.8864e-01, time/batch = 0.6690s	
15177/25300 (epoch 29.994), train_loss = 0.88661993, grad/param norm = 2.6561e-01, time/batch = 0.6606s	
15178/25300 (epoch 29.996), train_loss = 0.97323043, grad/param norm = 2.5664e-01, time/batch = 0.6620s	
15179/25300 (epoch 29.998), train_loss = 0.94306825, grad/param norm = 2.9350e-01, time/batch = 0.6574s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
15180/25300 (epoch 30.000), train_loss = 0.92688259, grad/param norm = 2.4471e-01, time/batch = 0.6584s	
15181/25300 (epoch 30.002), train_loss = 0.81766036, grad/param norm = 2.0319e-01, time/batch = 0.6603s	
15182/25300 (epoch 30.004), train_loss = 0.73902595, grad/param norm = 2.0637e-01, time/batch = 0.6611s	
15183/25300 (epoch 30.006), train_loss = 1.01345674, grad/param norm = 2.4744e-01, time/batch = 0.6617s	
15184/25300 (epoch 30.008), train_loss = 0.84824236, grad/param norm = 1.9174e-01, time/batch = 0.6556s	
15185/25300 (epoch 30.010), train_loss = 0.88107468, grad/param norm = 2.0883e-01, time/batch = 0.6621s	
15186/25300 (epoch 30.012), train_loss = 0.80389860, grad/param norm = 2.1159e-01, time/batch = 0.6582s	
15187/25300 (epoch 30.014), train_loss = 0.97734223, grad/param norm = 2.4029e-01, time/batch = 0.6588s	
15188/25300 (epoch 30.016), train_loss = 0.85516212, grad/param norm = 2.3195e-01, time/batch = 0.6546s	
15189/25300 (epoch 30.018), train_loss = 0.76328652, grad/param norm = 2.1478e-01, time/batch = 0.6619s	
15190/25300 (epoch 30.020), train_loss = 0.85872201, grad/param norm = 2.0391e-01, time/batch = 0.6590s	
15191/25300 (epoch 30.022), train_loss = 0.85793364, grad/param norm = 2.3120e-01, time/batch = 0.6648s	
15192/25300 (epoch 30.024), train_loss = 0.63728861, grad/param norm = 1.5714e-01, time/batch = 0.6639s	
15193/25300 (epoch 30.026), train_loss = 0.80344245, grad/param norm = 2.1817e-01, time/batch = 0.6639s	
15194/25300 (epoch 30.028), train_loss = 0.79135725, grad/param norm = 2.0337e-01, time/batch = 0.6675s	
15195/25300 (epoch 30.030), train_loss = 0.94073017, grad/param norm = 1.8647e-01, time/batch = 0.6628s	
15196/25300 (epoch 30.032), train_loss = 0.81036275, grad/param norm = 2.1079e-01, time/batch = 0.6649s	
15197/25300 (epoch 30.034), train_loss = 0.71638113, grad/param norm = 1.8762e-01, time/batch = 0.6630s	
15198/25300 (epoch 30.036), train_loss = 0.68715834, grad/param norm = 1.8680e-01, time/batch = 0.6646s	
15199/25300 (epoch 30.038), train_loss = 0.65472234, grad/param norm = 1.9132e-01, time/batch = 0.6649s	
15200/25300 (epoch 30.040), train_loss = 0.84294068, grad/param norm = 2.0541e-01, time/batch = 0.6659s	
15201/25300 (epoch 30.042), train_loss = 0.83916712, grad/param norm = 1.8108e-01, time/batch = 0.6612s	
15202/25300 (epoch 30.043), train_loss = 0.72574311, grad/param norm = 1.8498e-01, time/batch = 0.6641s	
15203/25300 (epoch 30.045), train_loss = 0.70299570, grad/param norm = 1.8537e-01, time/batch = 0.6627s	
15204/25300 (epoch 30.047), train_loss = 0.87920232, grad/param norm = 2.2188e-01, time/batch = 0.6598s	
15205/25300 (epoch 30.049), train_loss = 0.85377171, grad/param norm = 2.2654e-01, time/batch = 0.6624s	
15206/25300 (epoch 30.051), train_loss = 0.94875796, grad/param norm = 2.1956e-01, time/batch = 0.6624s	
15207/25300 (epoch 30.053), train_loss = 0.66416394, grad/param norm = 1.5293e-01, time/batch = 0.6619s	
15208/25300 (epoch 30.055), train_loss = 0.70425431, grad/param norm = 1.8677e-01, time/batch = 0.6582s	
15209/25300 (epoch 30.057), train_loss = 0.69583197, grad/param norm = 1.6820e-01, time/batch = 0.6634s	
15210/25300 (epoch 30.059), train_loss = 0.77903259, grad/param norm = 2.0421e-01, time/batch = 0.6567s	
15211/25300 (epoch 30.061), train_loss = 0.76621504, grad/param norm = 1.9002e-01, time/batch = 0.6622s	
15212/25300 (epoch 30.063), train_loss = 0.76008224, grad/param norm = 1.9792e-01, time/batch = 0.6647s	
15213/25300 (epoch 30.065), train_loss = 0.84561610, grad/param norm = 2.1085e-01, time/batch = 0.6781s	
15214/25300 (epoch 30.067), train_loss = 0.91565003, grad/param norm = 2.1183e-01, time/batch = 0.6705s	
15215/25300 (epoch 30.069), train_loss = 0.74610374, grad/param norm = 1.9997e-01, time/batch = 0.6729s	
15216/25300 (epoch 30.071), train_loss = 0.88108634, grad/param norm = 2.2733e-01, time/batch = 0.6610s	
15217/25300 (epoch 30.073), train_loss = 0.78438163, grad/param norm = 1.8800e-01, time/batch = 0.6719s	
15218/25300 (epoch 30.075), train_loss = 0.90422204, grad/param norm = 2.1262e-01, time/batch = 0.6798s	
15219/25300 (epoch 30.077), train_loss = 0.85988529, grad/param norm = 1.9990e-01, time/batch = 0.6833s	
15220/25300 (epoch 30.079), train_loss = 0.76915460, grad/param norm = 2.1419e-01, time/batch = 0.6794s	
15221/25300 (epoch 30.081), train_loss = 0.81795201, grad/param norm = 1.7158e-01, time/batch = 0.6865s	
15222/25300 (epoch 30.083), train_loss = 0.83640445, grad/param norm = 1.9845e-01, time/batch = 0.6861s	
15223/25300 (epoch 30.085), train_loss = 1.00387983, grad/param norm = 2.1700e-01, time/batch = 0.6841s	
15224/25300 (epoch 30.087), train_loss = 0.91293675, grad/param norm = 1.9242e-01, time/batch = 0.6728s	
15225/25300 (epoch 30.089), train_loss = 0.88333335, grad/param norm = 1.9775e-01, time/batch = 0.6626s	
15226/25300 (epoch 30.091), train_loss = 1.00016837, grad/param norm = 2.2196e-01, time/batch = 0.6644s	
15227/25300 (epoch 30.093), train_loss = 0.93775109, grad/param norm = 2.4069e-01, time/batch = 0.6610s	
15228/25300 (epoch 30.095), train_loss = 0.93524647, grad/param norm = 2.3584e-01, time/batch = 0.6573s	
15229/25300 (epoch 30.097), train_loss = 0.88657915, grad/param norm = 2.1645e-01, time/batch = 0.6699s	
15230/25300 (epoch 30.099), train_loss = 0.87863426, grad/param norm = 2.2103e-01, time/batch = 0.6561s	
15231/25300 (epoch 30.101), train_loss = 0.82700308, grad/param norm = 2.2343e-01, time/batch = 0.6598s	
15232/25300 (epoch 30.103), train_loss = 0.86665947, grad/param norm = 2.1003e-01, time/batch = 0.6579s	
15233/25300 (epoch 30.105), train_loss = 0.90605880, grad/param norm = 2.1153e-01, time/batch = 0.6568s	
15234/25300 (epoch 30.107), train_loss = 0.93090526, grad/param norm = 2.5666e-01, time/batch = 0.6547s	
15235/25300 (epoch 30.109), train_loss = 0.81744513, grad/param norm = 2.2040e-01, time/batch = 0.6575s	
15236/25300 (epoch 30.111), train_loss = 0.82119703, grad/param norm = 1.8915e-01, time/batch = 0.6567s	
15237/25300 (epoch 30.113), train_loss = 0.79130618, grad/param norm = 2.2003e-01, time/batch = 0.6585s	
15238/25300 (epoch 30.115), train_loss = 0.82549037, grad/param norm = 2.1664e-01, time/batch = 0.6585s	
15239/25300 (epoch 30.117), train_loss = 0.93820616, grad/param norm = 2.2361e-01, time/batch = 0.6614s	
15240/25300 (epoch 30.119), train_loss = 0.79552783, grad/param norm = 2.4239e-01, time/batch = 0.6541s	
15241/25300 (epoch 30.121), train_loss = 0.86920196, grad/param norm = 2.6570e-01, time/batch = 0.6570s	
15242/25300 (epoch 30.123), train_loss = 0.78448188, grad/param norm = 2.1948e-01, time/batch = 0.6561s	
15243/25300 (epoch 30.125), train_loss = 0.92829114, grad/param norm = 2.1658e-01, time/batch = 0.6600s	
15244/25300 (epoch 30.126), train_loss = 0.85884937, grad/param norm = 1.9804e-01, time/batch = 0.6548s	
15245/25300 (epoch 30.128), train_loss = 0.82739160, grad/param norm = 1.9580e-01, time/batch = 0.6568s	
15246/25300 (epoch 30.130), train_loss = 0.67541894, grad/param norm = 1.7817e-01, time/batch = 0.6582s	
15247/25300 (epoch 30.132), train_loss = 0.70358124, grad/param norm = 2.1775e-01, time/batch = 0.6603s	
15248/25300 (epoch 30.134), train_loss = 0.69794706, grad/param norm = 1.7089e-01, time/batch = 0.6520s	
15249/25300 (epoch 30.136), train_loss = 0.81165904, grad/param norm = 1.8399e-01, time/batch = 0.6529s	
15250/25300 (epoch 30.138), train_loss = 0.73380148, grad/param norm = 1.8181e-01, time/batch = 0.6577s	
15251/25300 (epoch 30.140), train_loss = 0.72867930, grad/param norm = 1.9735e-01, time/batch = 0.6549s	
15252/25300 (epoch 30.142), train_loss = 0.93371649, grad/param norm = 2.2560e-01, time/batch = 0.6574s	
15253/25300 (epoch 30.144), train_loss = 0.90842153, grad/param norm = 2.3096e-01, time/batch = 0.6563s	
15254/25300 (epoch 30.146), train_loss = 0.85037650, grad/param norm = 2.8038e-01, time/batch = 0.6561s	
15255/25300 (epoch 30.148), train_loss = 0.80866156, grad/param norm = 1.8527e-01, time/batch = 0.6609s	
15256/25300 (epoch 30.150), train_loss = 0.87437477, grad/param norm = 2.0228e-01, time/batch = 0.6595s	
15257/25300 (epoch 30.152), train_loss = 0.97701737, grad/param norm = 2.3197e-01, time/batch = 0.6607s	
15258/25300 (epoch 30.154), train_loss = 0.70480557, grad/param norm = 1.8550e-01, time/batch = 0.6636s	
15259/25300 (epoch 30.156), train_loss = 0.88391253, grad/param norm = 2.2158e-01, time/batch = 0.6648s	
15260/25300 (epoch 30.158), train_loss = 0.72697445, grad/param norm = 2.1171e-01, time/batch = 0.6683s	
15261/25300 (epoch 30.160), train_loss = 0.84545894, grad/param norm = 2.2762e-01, time/batch = 0.6617s	
15262/25300 (epoch 30.162), train_loss = 0.78946518, grad/param norm = 2.2914e-01, time/batch = 0.6591s	
15263/25300 (epoch 30.164), train_loss = 0.89022650, grad/param norm = 2.3632e-01, time/batch = 0.6615s	
15264/25300 (epoch 30.166), train_loss = 0.84484563, grad/param norm = 1.9129e-01, time/batch = 0.6567s	
15265/25300 (epoch 30.168), train_loss = 0.74923707, grad/param norm = 1.7182e-01, time/batch = 0.6578s	
15266/25300 (epoch 30.170), train_loss = 0.77047718, grad/param norm = 2.0936e-01, time/batch = 0.6576s	
15267/25300 (epoch 30.172), train_loss = 0.71444080, grad/param norm = 1.8826e-01, time/batch = 0.6564s	
15268/25300 (epoch 30.174), train_loss = 0.74938044, grad/param norm = 1.9582e-01, time/batch = 0.6614s	
15269/25300 (epoch 30.176), train_loss = 0.74750780, grad/param norm = 2.3362e-01, time/batch = 0.6573s	
15270/25300 (epoch 30.178), train_loss = 0.95561742, grad/param norm = 2.0508e-01, time/batch = 0.6654s	
15271/25300 (epoch 30.180), train_loss = 0.69106288, grad/param norm = 1.9322e-01, time/batch = 0.6725s	
15272/25300 (epoch 30.182), train_loss = 0.77832681, grad/param norm = 2.5291e-01, time/batch = 0.6687s	
15273/25300 (epoch 30.184), train_loss = 0.74887491, grad/param norm = 2.3384e-01, time/batch = 0.6631s	
15274/25300 (epoch 30.186), train_loss = 0.72971416, grad/param norm = 2.1215e-01, time/batch = 0.6581s	
15275/25300 (epoch 30.188), train_loss = 0.83126144, grad/param norm = 2.2894e-01, time/batch = 0.6566s	
15276/25300 (epoch 30.190), train_loss = 0.79778469, grad/param norm = 2.1735e-01, time/batch = 0.6650s	
15277/25300 (epoch 30.192), train_loss = 0.80055902, grad/param norm = 2.1835e-01, time/batch = 0.6558s	
15278/25300 (epoch 30.194), train_loss = 0.79851327, grad/param norm = 2.0669e-01, time/batch = 0.6562s	
15279/25300 (epoch 30.196), train_loss = 0.93214182, grad/param norm = 2.5672e-01, time/batch = 0.6605s	
15280/25300 (epoch 30.198), train_loss = 0.77321437, grad/param norm = 2.3537e-01, time/batch = 0.6562s	
15281/25300 (epoch 30.200), train_loss = 0.79268170, grad/param norm = 2.0960e-01, time/batch = 0.6664s	
15282/25300 (epoch 30.202), train_loss = 0.81508038, grad/param norm = 2.0079e-01, time/batch = 0.6600s	
15283/25300 (epoch 30.204), train_loss = 0.81036057, grad/param norm = 2.2734e-01, time/batch = 0.6583s	
15284/25300 (epoch 30.206), train_loss = 0.91905974, grad/param norm = 2.1848e-01, time/batch = 0.6604s	
15285/25300 (epoch 30.208), train_loss = 0.72614567, grad/param norm = 1.8765e-01, time/batch = 0.6539s	
15286/25300 (epoch 30.209), train_loss = 0.70171050, grad/param norm = 1.9698e-01, time/batch = 0.6576s	
15287/25300 (epoch 30.211), train_loss = 0.78173338, grad/param norm = 1.8328e-01, time/batch = 0.6588s	
15288/25300 (epoch 30.213), train_loss = 0.84914391, grad/param norm = 2.2423e-01, time/batch = 0.6554s	
15289/25300 (epoch 30.215), train_loss = 0.84251838, grad/param norm = 1.9388e-01, time/batch = 0.6606s	
15290/25300 (epoch 30.217), train_loss = 0.85006882, grad/param norm = 2.2913e-01, time/batch = 0.6567s	
15291/25300 (epoch 30.219), train_loss = 0.91268843, grad/param norm = 2.3747e-01, time/batch = 0.6572s	
15292/25300 (epoch 30.221), train_loss = 0.96095203, grad/param norm = 2.2642e-01, time/batch = 0.6580s	
15293/25300 (epoch 30.223), train_loss = 0.89111719, grad/param norm = 2.2108e-01, time/batch = 0.6559s	
15294/25300 (epoch 30.225), train_loss = 1.15220920, grad/param norm = 3.3683e-01, time/batch = 0.6580s	
15295/25300 (epoch 30.227), train_loss = 0.96807500, grad/param norm = 2.3450e-01, time/batch = 0.6558s	
15296/25300 (epoch 30.229), train_loss = 0.81258268, grad/param norm = 2.1717e-01, time/batch = 0.6588s	
15297/25300 (epoch 30.231), train_loss = 0.82986956, grad/param norm = 2.1041e-01, time/batch = 0.6571s	
15298/25300 (epoch 30.233), train_loss = 0.88175280, grad/param norm = 2.1925e-01, time/batch = 0.6611s	
15299/25300 (epoch 30.235), train_loss = 0.82082057, grad/param norm = 2.0653e-01, time/batch = 0.6563s	
15300/25300 (epoch 30.237), train_loss = 0.95966025, grad/param norm = 2.4739e-01, time/batch = 0.6557s	
15301/25300 (epoch 30.239), train_loss = 0.81177758, grad/param norm = 2.0347e-01, time/batch = 0.6618s	
15302/25300 (epoch 30.241), train_loss = 0.97062075, grad/param norm = 2.2568e-01, time/batch = 0.6561s	
15303/25300 (epoch 30.243), train_loss = 1.09205323, grad/param norm = 2.4601e-01, time/batch = 0.6555s	
15304/25300 (epoch 30.245), train_loss = 0.78678112, grad/param norm = 1.9933e-01, time/batch = 0.6592s	
15305/25300 (epoch 30.247), train_loss = 0.90069302, grad/param norm = 2.2666e-01, time/batch = 0.6616s	
15306/25300 (epoch 30.249), train_loss = 0.71916878, grad/param norm = 1.9298e-01, time/batch = 0.6553s	
15307/25300 (epoch 30.251), train_loss = 0.71929356, grad/param norm = 1.9135e-01, time/batch = 0.6602s	
15308/25300 (epoch 30.253), train_loss = 0.81253381, grad/param norm = 2.1349e-01, time/batch = 0.6561s	
15309/25300 (epoch 30.255), train_loss = 0.76088936, grad/param norm = 2.1641e-01, time/batch = 0.6606s	
15310/25300 (epoch 30.257), train_loss = 0.80839351, grad/param norm = 2.0783e-01, time/batch = 0.6615s	
15311/25300 (epoch 30.259), train_loss = 1.02693394, grad/param norm = 2.8392e-01, time/batch = 0.6664s	
15312/25300 (epoch 30.261), train_loss = 0.96680766, grad/param norm = 2.8594e-01, time/batch = 0.6673s	
15313/25300 (epoch 30.263), train_loss = 0.98451680, grad/param norm = 2.4588e-01, time/batch = 0.6669s	
15314/25300 (epoch 30.265), train_loss = 1.01223675, grad/param norm = 2.3843e-01, time/batch = 0.6638s	
15315/25300 (epoch 30.267), train_loss = 0.89910254, grad/param norm = 2.0903e-01, time/batch = 0.6683s	
15316/25300 (epoch 30.269), train_loss = 0.72919870, grad/param norm = 2.0620e-01, time/batch = 0.6660s	
15317/25300 (epoch 30.271), train_loss = 0.77236170, grad/param norm = 2.0605e-01, time/batch = 0.6668s	
15318/25300 (epoch 30.273), train_loss = 0.90541539, grad/param norm = 2.1068e-01, time/batch = 0.6660s	
15319/25300 (epoch 30.275), train_loss = 0.79677898, grad/param norm = 1.9056e-01, time/batch = 0.6628s	
15320/25300 (epoch 30.277), train_loss = 0.79177666, grad/param norm = 2.2138e-01, time/batch = 0.6720s	
15321/25300 (epoch 30.279), train_loss = 0.84141710, grad/param norm = 2.0844e-01, time/batch = 0.6610s	
15322/25300 (epoch 30.281), train_loss = 0.96695446, grad/param norm = 2.1885e-01, time/batch = 0.6629s	
15323/25300 (epoch 30.283), train_loss = 0.72198385, grad/param norm = 1.6265e-01, time/batch = 0.6592s	
15324/25300 (epoch 30.285), train_loss = 0.83626773, grad/param norm = 2.1581e-01, time/batch = 0.6600s	
15325/25300 (epoch 30.287), train_loss = 0.94313814, grad/param norm = 1.9256e-01, time/batch = 0.6641s	
15326/25300 (epoch 30.289), train_loss = 0.79987613, grad/param norm = 2.1293e-01, time/batch = 0.6597s	
15327/25300 (epoch 30.291), train_loss = 0.79589905, grad/param norm = 2.1051e-01, time/batch = 0.6573s	
15328/25300 (epoch 30.292), train_loss = 0.99750294, grad/param norm = 2.1948e-01, time/batch = 0.6624s	
15329/25300 (epoch 30.294), train_loss = 0.87263669, grad/param norm = 2.1238e-01, time/batch = 0.6593s	
15330/25300 (epoch 30.296), train_loss = 0.74569934, grad/param norm = 1.9379e-01, time/batch = 0.6565s	
15331/25300 (epoch 30.298), train_loss = 0.92383422, grad/param norm = 2.1458e-01, time/batch = 0.6618s	
15332/25300 (epoch 30.300), train_loss = 0.93749484, grad/param norm = 2.5323e-01, time/batch = 0.6582s	
15333/25300 (epoch 30.302), train_loss = 0.68326308, grad/param norm = 2.0773e-01, time/batch = 0.6570s	
15334/25300 (epoch 30.304), train_loss = 0.94571979, grad/param norm = 2.3056e-01, time/batch = 0.6602s	
15335/25300 (epoch 30.306), train_loss = 0.66591470, grad/param norm = 1.8905e-01, time/batch = 0.6578s	
15336/25300 (epoch 30.308), train_loss = 0.90529119, grad/param norm = 1.9655e-01, time/batch = 0.6607s	
15337/25300 (epoch 30.310), train_loss = 0.73316639, grad/param norm = 1.9533e-01, time/batch = 0.6587s	
15338/25300 (epoch 30.312), train_loss = 0.86037948, grad/param norm = 1.9118e-01, time/batch = 0.6608s	
15339/25300 (epoch 30.314), train_loss = 0.69754950, grad/param norm = 1.8705e-01, time/batch = 0.6631s	
15340/25300 (epoch 30.316), train_loss = 0.85977924, grad/param norm = 2.0579e-01, time/batch = 0.6586s	
15341/25300 (epoch 30.318), train_loss = 0.67513679, grad/param norm = 1.8920e-01, time/batch = 0.6631s	
15342/25300 (epoch 30.320), train_loss = 0.75702223, grad/param norm = 1.9651e-01, time/batch = 0.6576s	
15343/25300 (epoch 30.322), train_loss = 0.97853869, grad/param norm = 2.2120e-01, time/batch = 0.6591s	
15344/25300 (epoch 30.324), train_loss = 0.75758759, grad/param norm = 1.9382e-01, time/batch = 0.6623s	
15345/25300 (epoch 30.326), train_loss = 0.68273136, grad/param norm = 1.7186e-01, time/batch = 0.6569s	
15346/25300 (epoch 30.328), train_loss = 0.67537883, grad/param norm = 2.1622e-01, time/batch = 0.6595s	
15347/25300 (epoch 30.330), train_loss = 0.79974421, grad/param norm = 1.9076e-01, time/batch = 0.6601s	
15348/25300 (epoch 30.332), train_loss = 0.83443818, grad/param norm = 2.0756e-01, time/batch = 0.6628s	
15349/25300 (epoch 30.334), train_loss = 0.68217531, grad/param norm = 2.0011e-01, time/batch = 0.6670s	
15350/25300 (epoch 30.336), train_loss = 0.71445236, grad/param norm = 2.4404e-01, time/batch = 0.6692s	
15351/25300 (epoch 30.338), train_loss = 0.71341603, grad/param norm = 1.9753e-01, time/batch = 0.6720s	
15352/25300 (epoch 30.340), train_loss = 0.76151001, grad/param norm = 2.0471e-01, time/batch = 0.6747s	
15353/25300 (epoch 30.342), train_loss = 0.81560822, grad/param norm = 2.5727e-01, time/batch = 0.6709s	
15354/25300 (epoch 30.344), train_loss = 0.87640076, grad/param norm = 2.1393e-01, time/batch = 0.6679s	
15355/25300 (epoch 30.346), train_loss = 0.77774401, grad/param norm = 2.3049e-01, time/batch = 0.6688s	
15356/25300 (epoch 30.348), train_loss = 0.72114705, grad/param norm = 1.9290e-01, time/batch = 0.6644s	
15357/25300 (epoch 30.350), train_loss = 0.78234129, grad/param norm = 2.0665e-01, time/batch = 0.6712s	
15358/25300 (epoch 30.352), train_loss = 0.80534833, grad/param norm = 1.8727e-01, time/batch = 0.6660s	
15359/25300 (epoch 30.354), train_loss = 0.77036091, grad/param norm = 2.0867e-01, time/batch = 0.6611s	
15360/25300 (epoch 30.356), train_loss = 0.81947065, grad/param norm = 2.0291e-01, time/batch = 0.6568s	
15361/25300 (epoch 30.358), train_loss = 0.85696331, grad/param norm = 2.6227e-01, time/batch = 0.6616s	
15362/25300 (epoch 30.360), train_loss = 0.72410776, grad/param norm = 1.8243e-01, time/batch = 0.6586s	
15363/25300 (epoch 30.362), train_loss = 0.72783032, grad/param norm = 1.9202e-01, time/batch = 0.6583s	
15364/25300 (epoch 30.364), train_loss = 0.75430986, grad/param norm = 2.1365e-01, time/batch = 0.6618s	
15365/25300 (epoch 30.366), train_loss = 0.70002396, grad/param norm = 1.7819e-01, time/batch = 0.6631s	
15366/25300 (epoch 30.368), train_loss = 0.79237523, grad/param norm = 1.9290e-01, time/batch = 0.6680s	
15367/25300 (epoch 30.370), train_loss = 0.72858576, grad/param norm = 2.1212e-01, time/batch = 0.6567s	
15368/25300 (epoch 30.372), train_loss = 0.74264490, grad/param norm = 2.1823e-01, time/batch = 0.6588s	
15369/25300 (epoch 30.374), train_loss = 0.70654631, grad/param norm = 2.1192e-01, time/batch = 0.6563s	
15370/25300 (epoch 30.375), train_loss = 0.90876879, grad/param norm = 2.4815e-01, time/batch = 0.6580s	
15371/25300 (epoch 30.377), train_loss = 0.87167766, grad/param norm = 2.1752e-01, time/batch = 0.6612s	
15372/25300 (epoch 30.379), train_loss = 0.86498473, grad/param norm = 2.3870e-01, time/batch = 0.6585s	
15373/25300 (epoch 30.381), train_loss = 0.78717721, grad/param norm = 2.2826e-01, time/batch = 0.6558s	
15374/25300 (epoch 30.383), train_loss = 0.72222498, grad/param norm = 1.9208e-01, time/batch = 0.6550s	
15375/25300 (epoch 30.385), train_loss = 0.83520306, grad/param norm = 1.9920e-01, time/batch = 0.6580s	
15376/25300 (epoch 30.387), train_loss = 0.80638732, grad/param norm = 2.0116e-01, time/batch = 0.6601s	
15377/25300 (epoch 30.389), train_loss = 0.81011644, grad/param norm = 2.1696e-01, time/batch = 0.6575s	
15378/25300 (epoch 30.391), train_loss = 0.76339256, grad/param norm = 2.0591e-01, time/batch = 0.6562s	
15379/25300 (epoch 30.393), train_loss = 0.84202400, grad/param norm = 2.5840e-01, time/batch = 0.6549s	
15380/25300 (epoch 30.395), train_loss = 0.65579808, grad/param norm = 2.0146e-01, time/batch = 0.6581s	
15381/25300 (epoch 30.397), train_loss = 0.65644779, grad/param norm = 2.1510e-01, time/batch = 0.6580s	
15382/25300 (epoch 30.399), train_loss = 0.69990642, grad/param norm = 2.1019e-01, time/batch = 0.6568s	
15383/25300 (epoch 30.401), train_loss = 0.86950249, grad/param norm = 2.2084e-01, time/batch = 0.6573s	
15384/25300 (epoch 30.403), train_loss = 0.83038910, grad/param norm = 2.6088e-01, time/batch = 0.6603s	
15385/25300 (epoch 30.405), train_loss = 0.78259881, grad/param norm = 2.1627e-01, time/batch = 0.6565s	
15386/25300 (epoch 30.407), train_loss = 0.77485934, grad/param norm = 2.0028e-01, time/batch = 0.6559s	
15387/25300 (epoch 30.409), train_loss = 0.73029526, grad/param norm = 1.9555e-01, time/batch = 0.6572s	
15388/25300 (epoch 30.411), train_loss = 0.75314251, grad/param norm = 2.1346e-01, time/batch = 0.6559s	
15389/25300 (epoch 30.413), train_loss = 0.67480752, grad/param norm = 1.8825e-01, time/batch = 0.6621s	
15390/25300 (epoch 30.415), train_loss = 0.71935010, grad/param norm = 1.9547e-01, time/batch = 0.6635s	
15391/25300 (epoch 30.417), train_loss = 0.68520329, grad/param norm = 1.9295e-01, time/batch = 0.6679s	
15392/25300 (epoch 30.419), train_loss = 0.62573176, grad/param norm = 1.8111e-01, time/batch = 0.6666s	
15393/25300 (epoch 30.421), train_loss = 0.68512942, grad/param norm = 1.6194e-01, time/batch = 0.6657s	
15394/25300 (epoch 30.423), train_loss = 0.68311276, grad/param norm = 1.9542e-01, time/batch = 0.6604s	
15395/25300 (epoch 30.425), train_loss = 0.78625222, grad/param norm = 2.8357e-01, time/batch = 0.6667s	
15396/25300 (epoch 30.427), train_loss = 0.89875969, grad/param norm = 2.0772e-01, time/batch = 0.6677s	
15397/25300 (epoch 30.429), train_loss = 0.90790408, grad/param norm = 2.3153e-01, time/batch = 0.6612s	
15398/25300 (epoch 30.431), train_loss = 0.82117413, grad/param norm = 2.2293e-01, time/batch = 0.6587s	
15399/25300 (epoch 30.433), train_loss = 0.81631626, grad/param norm = 1.8539e-01, time/batch = 0.6563s	
15400/25300 (epoch 30.435), train_loss = 0.76814049, grad/param norm = 3.2031e-01, time/batch = 0.6555s	
15401/25300 (epoch 30.437), train_loss = 0.73307982, grad/param norm = 1.9486e-01, time/batch = 0.6595s	
15402/25300 (epoch 30.439), train_loss = 0.82177114, grad/param norm = 2.1882e-01, time/batch = 0.6593s	
15403/25300 (epoch 30.441), train_loss = 0.84794651, grad/param norm = 2.2333e-01, time/batch = 0.6557s	
15404/25300 (epoch 30.443), train_loss = 0.97390917, grad/param norm = 2.3885e-01, time/batch = 0.6602s	
15405/25300 (epoch 30.445), train_loss = 0.93560431, grad/param norm = 2.6261e-01, time/batch = 0.6578s	
15406/25300 (epoch 30.447), train_loss = 0.72679012, grad/param norm = 2.0791e-01, time/batch = 0.6661s	
15407/25300 (epoch 30.449), train_loss = 0.67804816, grad/param norm = 2.2318e-01, time/batch = 0.6636s	
15408/25300 (epoch 30.451), train_loss = 1.01507598, grad/param norm = 2.4659e-01, time/batch = 0.6651s	
15409/25300 (epoch 30.453), train_loss = 0.86411350, grad/param norm = 2.3609e-01, time/batch = 0.6623s	
15410/25300 (epoch 30.455), train_loss = 0.82763927, grad/param norm = 2.1533e-01, time/batch = 0.6650s	
15411/25300 (epoch 30.457), train_loss = 0.72893934, grad/param norm = 1.8987e-01, time/batch = 0.6653s	
15412/25300 (epoch 30.458), train_loss = 0.74489980, grad/param norm = 1.9910e-01, time/batch = 0.6599s	
15413/25300 (epoch 30.460), train_loss = 0.79906568, grad/param norm = 2.2298e-01, time/batch = 0.6590s	
15414/25300 (epoch 30.462), train_loss = 0.59613039, grad/param norm = 1.9868e-01, time/batch = 0.6612s	
15415/25300 (epoch 30.464), train_loss = 0.88190819, grad/param norm = 2.1605e-01, time/batch = 0.6602s	
15416/25300 (epoch 30.466), train_loss = 0.85062950, grad/param norm = 2.0385e-01, time/batch = 0.6582s	
15417/25300 (epoch 30.468), train_loss = 0.86991129, grad/param norm = 2.2988e-01, time/batch = 0.6687s	
15418/25300 (epoch 30.470), train_loss = 0.77109516, grad/param norm = 1.9795e-01, time/batch = 0.6610s	
15419/25300 (epoch 30.472), train_loss = 0.69306750, grad/param norm = 2.0853e-01, time/batch = 0.6574s	
15420/25300 (epoch 30.474), train_loss = 0.85188277, grad/param norm = 2.1713e-01, time/batch = 0.6591s	
15421/25300 (epoch 30.476), train_loss = 0.77204531, grad/param norm = 2.1804e-01, time/batch = 0.6581s	
15422/25300 (epoch 30.478), train_loss = 0.87155605, grad/param norm = 2.2798e-01, time/batch = 0.6619s	
15423/25300 (epoch 30.480), train_loss = 0.76824711, grad/param norm = 1.9441e-01, time/batch = 0.6571s	
15424/25300 (epoch 30.482), train_loss = 0.83643737, grad/param norm = 2.5896e-01, time/batch = 0.6567s	
15425/25300 (epoch 30.484), train_loss = 0.88470192, grad/param norm = 2.6973e-01, time/batch = 0.6593s	
15426/25300 (epoch 30.486), train_loss = 0.80057247, grad/param norm = 2.2951e-01, time/batch = 0.6582s	
15427/25300 (epoch 30.488), train_loss = 0.96841624, grad/param norm = 2.4580e-01, time/batch = 0.6607s	
15428/25300 (epoch 30.490), train_loss = 0.85229816, grad/param norm = 2.1387e-01, time/batch = 0.6589s	
15429/25300 (epoch 30.492), train_loss = 0.91863958, grad/param norm = 2.2513e-01, time/batch = 0.6571s	
15430/25300 (epoch 30.494), train_loss = 0.78091265, grad/param norm = 1.9156e-01, time/batch = 0.6610s	
15431/25300 (epoch 30.496), train_loss = 0.86386730, grad/param norm = 2.5056e-01, time/batch = 0.6640s	
15432/25300 (epoch 30.498), train_loss = 0.79105891, grad/param norm = 1.9611e-01, time/batch = 0.6589s	
15433/25300 (epoch 30.500), train_loss = 0.97093814, grad/param norm = 2.2789e-01, time/batch = 0.6597s	
15434/25300 (epoch 30.502), train_loss = 0.88695173, grad/param norm = 2.4589e-01, time/batch = 0.6597s	
15435/25300 (epoch 30.504), train_loss = 0.77587060, grad/param norm = 1.9204e-01, time/batch = 0.6609s	
15436/25300 (epoch 30.506), train_loss = 0.71667566, grad/param norm = 2.2238e-01, time/batch = 0.6587s	
15437/25300 (epoch 30.508), train_loss = 0.81444033, grad/param norm = 2.4701e-01, time/batch = 0.6631s	
15438/25300 (epoch 30.510), train_loss = 0.74974795, grad/param norm = 2.2132e-01, time/batch = 0.6613s	
15439/25300 (epoch 30.512), train_loss = 0.61390766, grad/param norm = 1.8994e-01, time/batch = 0.6695s	
15440/25300 (epoch 30.514), train_loss = 0.79267872, grad/param norm = 2.0033e-01, time/batch = 0.6671s	
15441/25300 (epoch 30.516), train_loss = 0.86991667, grad/param norm = 2.3898e-01, time/batch = 0.6663s	
15442/25300 (epoch 30.518), train_loss = 0.90247524, grad/param norm = 2.3285e-01, time/batch = 0.6728s	
15443/25300 (epoch 30.520), train_loss = 0.65610211, grad/param norm = 1.5592e-01, time/batch = 0.6566s	
15444/25300 (epoch 30.522), train_loss = 0.73662503, grad/param norm = 2.0437e-01, time/batch = 0.6543s	
15445/25300 (epoch 30.524), train_loss = 0.74793484, grad/param norm = 2.1795e-01, time/batch = 0.6723s	
15446/25300 (epoch 30.526), train_loss = 0.91934472, grad/param norm = 2.3130e-01, time/batch = 0.6618s	
15447/25300 (epoch 30.528), train_loss = 0.92856826, grad/param norm = 2.1762e-01, time/batch = 0.6691s	
15448/25300 (epoch 30.530), train_loss = 0.84507393, grad/param norm = 1.9871e-01, time/batch = 0.6622s	
15449/25300 (epoch 30.532), train_loss = 0.77533016, grad/param norm = 1.9882e-01, time/batch = 0.6626s	
15450/25300 (epoch 30.534), train_loss = 0.76841737, grad/param norm = 2.2419e-01, time/batch = 0.6650s	
15451/25300 (epoch 30.536), train_loss = 0.64473927, grad/param norm = 2.3302e-01, time/batch = 0.6599s	
15452/25300 (epoch 30.538), train_loss = 0.70865305, grad/param norm = 1.7178e-01, time/batch = 0.6587s	
15453/25300 (epoch 30.540), train_loss = 0.71073831, grad/param norm = 1.8170e-01, time/batch = 0.6605s	
15454/25300 (epoch 30.542), train_loss = 0.68357056, grad/param norm = 2.0821e-01, time/batch = 0.6714s	
15455/25300 (epoch 30.543), train_loss = 0.65969491, grad/param norm = 1.7336e-01, time/batch = 0.6650s	
15456/25300 (epoch 30.545), train_loss = 0.99399704, grad/param norm = 2.9786e-01, time/batch = 0.6789s	
15457/25300 (epoch 30.547), train_loss = 0.88321632, grad/param norm = 2.2045e-01, time/batch = 0.6763s	
15458/25300 (epoch 30.549), train_loss = 1.01067338, grad/param norm = 2.8023e-01, time/batch = 0.6606s	
15459/25300 (epoch 30.551), train_loss = 0.89138529, grad/param norm = 2.0991e-01, time/batch = 0.6588s	
15460/25300 (epoch 30.553), train_loss = 0.73114764, grad/param norm = 2.1699e-01, time/batch = 0.6569s	
15461/25300 (epoch 30.555), train_loss = 0.88962914, grad/param norm = 2.3943e-01, time/batch = 0.6615s	
15462/25300 (epoch 30.557), train_loss = 0.91142127, grad/param norm = 2.5487e-01, time/batch = 0.6640s	
15463/25300 (epoch 30.559), train_loss = 0.92335690, grad/param norm = 2.2419e-01, time/batch = 0.6575s	
15464/25300 (epoch 30.561), train_loss = 0.94465701, grad/param norm = 2.2831e-01, time/batch = 0.6556s	
15465/25300 (epoch 30.563), train_loss = 0.88802146, grad/param norm = 2.1278e-01, time/batch = 0.6609s	
15466/25300 (epoch 30.565), train_loss = 0.71190568, grad/param norm = 1.9850e-01, time/batch = 0.6544s	
15467/25300 (epoch 30.567), train_loss = 0.63677959, grad/param norm = 1.9396e-01, time/batch = 0.6585s	
15468/25300 (epoch 30.569), train_loss = 0.83570014, grad/param norm = 2.1794e-01, time/batch = 0.6559s	
15469/25300 (epoch 30.571), train_loss = 0.89728045, grad/param norm = 2.4933e-01, time/batch = 0.6558s	
15470/25300 (epoch 30.573), train_loss = 0.80371203, grad/param norm = 2.2523e-01, time/batch = 0.6573s	
15471/25300 (epoch 30.575), train_loss = 0.88978885, grad/param norm = 2.1638e-01, time/batch = 0.6599s	
15472/25300 (epoch 30.577), train_loss = 0.77948604, grad/param norm = 2.1181e-01, time/batch = 0.6600s	
15473/25300 (epoch 30.579), train_loss = 0.92999152, grad/param norm = 2.4444e-01, time/batch = 0.6577s	
15474/25300 (epoch 30.581), train_loss = 0.87198209, grad/param norm = 2.2188e-01, time/batch = 0.6622s	
15475/25300 (epoch 30.583), train_loss = 0.70643999, grad/param norm = 2.1835e-01, time/batch = 0.6548s	
15476/25300 (epoch 30.585), train_loss = 0.68317560, grad/param norm = 2.1114e-01, time/batch = 0.6680s	
15477/25300 (epoch 30.587), train_loss = 0.80900081, grad/param norm = 2.0934e-01, time/batch = 0.6591s	
15478/25300 (epoch 30.589), train_loss = 0.70374245, grad/param norm = 1.7537e-01, time/batch = 0.6564s	
15479/25300 (epoch 30.591), train_loss = 0.68938693, grad/param norm = 2.3988e-01, time/batch = 0.6605s	
15480/25300 (epoch 30.593), train_loss = 0.87825528, grad/param norm = 2.4012e-01, time/batch = 0.6585s	
15481/25300 (epoch 30.595), train_loss = 0.80604209, grad/param norm = 2.1836e-01, time/batch = 0.6605s	
15482/25300 (epoch 30.597), train_loss = 0.71687726, grad/param norm = 1.9075e-01, time/batch = 0.6570s	
15483/25300 (epoch 30.599), train_loss = 0.89952666, grad/param norm = 2.2803e-01, time/batch = 0.6625s	
15484/25300 (epoch 30.601), train_loss = 0.79719199, grad/param norm = 2.9965e-01, time/batch = 0.6583s	
15485/25300 (epoch 30.603), train_loss = 0.80254747, grad/param norm = 2.2227e-01, time/batch = 0.6583s	
15486/25300 (epoch 30.605), train_loss = 0.76332113, grad/param norm = 2.5183e-01, time/batch = 0.6586s	
15487/25300 (epoch 30.607), train_loss = 0.58933970, grad/param norm = 1.8583e-01, time/batch = 0.6600s	
15488/25300 (epoch 30.609), train_loss = 0.77522403, grad/param norm = 2.2571e-01, time/batch = 0.6581s	
15489/25300 (epoch 30.611), train_loss = 0.82564667, grad/param norm = 2.0616e-01, time/batch = 0.6610s	
15490/25300 (epoch 30.613), train_loss = 0.69966617, grad/param norm = 1.8057e-01, time/batch = 0.6634s	
15491/25300 (epoch 30.615), train_loss = 0.76523017, grad/param norm = 2.2942e-01, time/batch = 0.6573s	
15492/25300 (epoch 30.617), train_loss = 0.80062886, grad/param norm = 2.3839e-01, time/batch = 0.6567s	
15493/25300 (epoch 30.619), train_loss = 0.87078666, grad/param norm = 2.3956e-01, time/batch = 0.6630s	
15494/25300 (epoch 30.621), train_loss = 0.88601734, grad/param norm = 2.2221e-01, time/batch = 0.6585s	
15495/25300 (epoch 30.623), train_loss = 0.74491142, grad/param norm = 2.2495e-01, time/batch = 0.6617s	
15496/25300 (epoch 30.625), train_loss = 0.66167348, grad/param norm = 2.0012e-01, time/batch = 0.6544s	
15497/25300 (epoch 30.626), train_loss = 0.78809572, grad/param norm = 2.0005e-01, time/batch = 0.6552s	
15498/25300 (epoch 30.628), train_loss = 0.88832210, grad/param norm = 2.6046e-01, time/batch = 0.6589s	
15499/25300 (epoch 30.630), train_loss = 0.87930167, grad/param norm = 2.5051e-01, time/batch = 0.6592s	
15500/25300 (epoch 30.632), train_loss = 0.83429815, grad/param norm = 2.3543e-01, time/batch = 0.6567s	
15501/25300 (epoch 30.634), train_loss = 0.93680441, grad/param norm = 2.5747e-01, time/batch = 0.6604s	
15502/25300 (epoch 30.636), train_loss = 0.72850855, grad/param norm = 2.0404e-01, time/batch = 0.6606s	
15503/25300 (epoch 30.638), train_loss = 0.84729323, grad/param norm = 2.6520e-01, time/batch = 0.6543s	
15504/25300 (epoch 30.640), train_loss = 1.00248729, grad/param norm = 2.7749e-01, time/batch = 0.6592s	
15505/25300 (epoch 30.642), train_loss = 0.82942851, grad/param norm = 2.1790e-01, time/batch = 0.6551s	
15506/25300 (epoch 30.644), train_loss = 0.84531278, grad/param norm = 2.2599e-01, time/batch = 0.6573s	
15507/25300 (epoch 30.646), train_loss = 0.75754124, grad/param norm = 2.6013e-01, time/batch = 0.6579s	
15508/25300 (epoch 30.648), train_loss = 0.88009341, grad/param norm = 1.9188e-01, time/batch = 0.6531s	
15509/25300 (epoch 30.650), train_loss = 0.83626007, grad/param norm = 2.4735e-01, time/batch = 0.6596s	
15510/25300 (epoch 30.652), train_loss = 0.84717061, grad/param norm = 2.0956e-01, time/batch = 0.6578s	
15511/25300 (epoch 30.654), train_loss = 0.95659636, grad/param norm = 2.3086e-01, time/batch = 0.6573s	
15512/25300 (epoch 30.656), train_loss = 0.88817639, grad/param norm = 2.4351e-01, time/batch = 0.6612s	
15513/25300 (epoch 30.658), train_loss = 0.65973136, grad/param norm = 1.8311e-01, time/batch = 0.6571s	
15514/25300 (epoch 30.660), train_loss = 0.68477436, grad/param norm = 2.1348e-01, time/batch = 0.6602s	
15515/25300 (epoch 30.662), train_loss = 0.69202661, grad/param norm = 2.2087e-01, time/batch = 0.6591s	
15516/25300 (epoch 30.664), train_loss = 0.65529661, grad/param norm = 2.0979e-01, time/batch = 0.6624s	
15517/25300 (epoch 30.666), train_loss = 0.71708156, grad/param norm = 2.1713e-01, time/batch = 0.6610s	
15518/25300 (epoch 30.668), train_loss = 0.80063859, grad/param norm = 2.9842e-01, time/batch = 0.6609s	
15519/25300 (epoch 30.670), train_loss = 0.74093813, grad/param norm = 2.1001e-01, time/batch = 0.6601s	
15520/25300 (epoch 30.672), train_loss = 0.72135478, grad/param norm = 1.9567e-01, time/batch = 0.6573s	
15521/25300 (epoch 30.674), train_loss = 0.74489395, grad/param norm = 1.8966e-01, time/batch = 0.6586s	
15522/25300 (epoch 30.676), train_loss = 0.75259464, grad/param norm = 2.3224e-01, time/batch = 0.6565s	
15523/25300 (epoch 30.678), train_loss = 0.77576810, grad/param norm = 2.2494e-01, time/batch = 0.6606s	
15524/25300 (epoch 30.680), train_loss = 0.64831463, grad/param norm = 1.7525e-01, time/batch = 0.6587s	
15525/25300 (epoch 30.682), train_loss = 0.55619469, grad/param norm = 1.7146e-01, time/batch = 0.6618s	
15526/25300 (epoch 30.684), train_loss = 0.71385618, grad/param norm = 1.6928e-01, time/batch = 0.6572s	
15527/25300 (epoch 30.686), train_loss = 0.66419391, grad/param norm = 1.8534e-01, time/batch = 0.6606s	
15528/25300 (epoch 30.688), train_loss = 0.74477524, grad/param norm = 2.1047e-01, time/batch = 0.6594s	
15529/25300 (epoch 30.690), train_loss = 0.68197982, grad/param norm = 1.7986e-01, time/batch = 0.6616s	
15530/25300 (epoch 30.692), train_loss = 0.71808524, grad/param norm = 1.8608e-01, time/batch = 0.6655s	
15531/25300 (epoch 30.694), train_loss = 0.71607146, grad/param norm = 2.0400e-01, time/batch = 0.6705s	
15532/25300 (epoch 30.696), train_loss = 0.80474253, grad/param norm = 2.3950e-01, time/batch = 0.6729s	
15533/25300 (epoch 30.698), train_loss = 0.84403272, grad/param norm = 2.1779e-01, time/batch = 0.6673s	
15534/25300 (epoch 30.700), train_loss = 0.62577631, grad/param norm = 1.9127e-01, time/batch = 0.6739s	
15535/25300 (epoch 30.702), train_loss = 0.82285441, grad/param norm = 2.0965e-01, time/batch = 0.6710s	
15536/25300 (epoch 30.704), train_loss = 0.62469501, grad/param norm = 1.8033e-01, time/batch = 0.6711s	
15537/25300 (epoch 30.706), train_loss = 0.76122988, grad/param norm = 2.2411e-01, time/batch = 0.6681s	
15538/25300 (epoch 30.708), train_loss = 0.64625358, grad/param norm = 1.8964e-01, time/batch = 0.6569s	
15539/25300 (epoch 30.709), train_loss = 0.91368105, grad/param norm = 2.3121e-01, time/batch = 0.6567s	
15540/25300 (epoch 30.711), train_loss = 0.94556999, grad/param norm = 2.2752e-01, time/batch = 0.6610s	
15541/25300 (epoch 30.713), train_loss = 0.78843049, grad/param norm = 1.8863e-01, time/batch = 0.6564s	
15542/25300 (epoch 30.715), train_loss = 0.78200533, grad/param norm = 1.9467e-01, time/batch = 0.6591s	
15543/25300 (epoch 30.717), train_loss = 0.70382969, grad/param norm = 2.2701e-01, time/batch = 0.6562s	
15544/25300 (epoch 30.719), train_loss = 0.78250710, grad/param norm = 2.2878e-01, time/batch = 0.6570s	
15545/25300 (epoch 30.721), train_loss = 0.82912503, grad/param norm = 2.3077e-01, time/batch = 0.6598s	
15546/25300 (epoch 30.723), train_loss = 0.77837786, grad/param norm = 2.4691e-01, time/batch = 0.6587s	
15547/25300 (epoch 30.725), train_loss = 0.81354555, grad/param norm = 2.1068e-01, time/batch = 0.6599s	
15548/25300 (epoch 30.727), train_loss = 0.79665564, grad/param norm = 2.0995e-01, time/batch = 0.6596s	
15549/25300 (epoch 30.729), train_loss = 0.77605284, grad/param norm = 2.0080e-01, time/batch = 0.6584s	
15550/25300 (epoch 30.731), train_loss = 0.93065798, grad/param norm = 2.2041e-01, time/batch = 0.6622s	
15551/25300 (epoch 30.733), train_loss = 0.77265219, grad/param norm = 1.9638e-01, time/batch = 0.6608s	
15552/25300 (epoch 30.735), train_loss = 1.01099506, grad/param norm = 2.2882e-01, time/batch = 0.6648s	
15553/25300 (epoch 30.737), train_loss = 0.66407533, grad/param norm = 1.6656e-01, time/batch = 0.6602s	
15554/25300 (epoch 30.739), train_loss = 0.92887575, grad/param norm = 2.2641e-01, time/batch = 0.6660s	
15555/25300 (epoch 30.741), train_loss = 0.83129474, grad/param norm = 2.3165e-01, time/batch = 0.6697s	
15556/25300 (epoch 30.743), train_loss = 0.77919777, grad/param norm = 1.9166e-01, time/batch = 0.6640s	
15557/25300 (epoch 30.745), train_loss = 0.76645512, grad/param norm = 2.2258e-01, time/batch = 0.6603s	
15558/25300 (epoch 30.747), train_loss = 0.69373928, grad/param norm = 1.9102e-01, time/batch = 0.6589s	
15559/25300 (epoch 30.749), train_loss = 0.78078193, grad/param norm = 2.0695e-01, time/batch = 0.6601s	
15560/25300 (epoch 30.751), train_loss = 0.86103186, grad/param norm = 2.1841e-01, time/batch = 0.6586s	
15561/25300 (epoch 30.753), train_loss = 0.68268972, grad/param norm = 2.0880e-01, time/batch = 0.6621s	
15562/25300 (epoch 30.755), train_loss = 0.90441052, grad/param norm = 2.3548e-01, time/batch = 0.6567s	
15563/25300 (epoch 30.757), train_loss = 0.75409025, grad/param norm = 2.3586e-01, time/batch = 0.6599s	
15564/25300 (epoch 30.759), train_loss = 0.72609892, grad/param norm = 2.2163e-01, time/batch = 0.6569s	
15565/25300 (epoch 30.761), train_loss = 0.95771538, grad/param norm = 2.7841e-01, time/batch = 0.6644s	
15566/25300 (epoch 30.763), train_loss = 0.76441913, grad/param norm = 1.9170e-01, time/batch = 0.6637s	
15567/25300 (epoch 30.765), train_loss = 0.77407498, grad/param norm = 2.1772e-01, time/batch = 0.6644s	
15568/25300 (epoch 30.767), train_loss = 0.77196614, grad/param norm = 1.9584e-01, time/batch = 0.6642s	
15569/25300 (epoch 30.769), train_loss = 0.79091651, grad/param norm = 2.3521e-01, time/batch = 0.6691s	
15570/25300 (epoch 30.771), train_loss = 0.91082295, grad/param norm = 2.4415e-01, time/batch = 0.6618s	
15571/25300 (epoch 30.773), train_loss = 0.92415844, grad/param norm = 2.5311e-01, time/batch = 0.6623s	
15572/25300 (epoch 30.775), train_loss = 0.81030557, grad/param norm = 2.0425e-01, time/batch = 0.6786s	
15573/25300 (epoch 30.777), train_loss = 0.76770328, grad/param norm = 2.4003e-01, time/batch = 0.6657s	
15574/25300 (epoch 30.779), train_loss = 0.89495215, grad/param norm = 2.2633e-01, time/batch = 0.6614s	
15575/25300 (epoch 30.781), train_loss = 0.85300677, grad/param norm = 2.2142e-01, time/batch = 0.6575s	
15576/25300 (epoch 30.783), train_loss = 0.94618400, grad/param norm = 2.2435e-01, time/batch = 0.6664s	
15577/25300 (epoch 30.785), train_loss = 0.87172054, grad/param norm = 2.2937e-01, time/batch = 0.6571s	
15578/25300 (epoch 30.787), train_loss = 0.85646865, grad/param norm = 2.4156e-01, time/batch = 0.6576s	
15579/25300 (epoch 30.789), train_loss = 0.96866451, grad/param norm = 2.5819e-01, time/batch = 0.6579s	
15580/25300 (epoch 30.791), train_loss = 0.86122510, grad/param norm = 2.2833e-01, time/batch = 0.6576s	
15581/25300 (epoch 30.792), train_loss = 0.91149024, grad/param norm = 2.3737e-01, time/batch = 0.6646s	
15582/25300 (epoch 30.794), train_loss = 0.81159946, grad/param norm = 2.2224e-01, time/batch = 0.6613s	
15583/25300 (epoch 30.796), train_loss = 0.77926706, grad/param norm = 2.3009e-01, time/batch = 0.6580s	
15584/25300 (epoch 30.798), train_loss = 0.89761008, grad/param norm = 2.8412e-01, time/batch = 0.6581s	
15585/25300 (epoch 30.800), train_loss = 0.79057201, grad/param norm = 1.9877e-01, time/batch = 0.6513s	
15586/25300 (epoch 30.802), train_loss = 0.64918277, grad/param norm = 1.9324e-01, time/batch = 0.6537s	
15587/25300 (epoch 30.804), train_loss = 0.81193783, grad/param norm = 2.0094e-01, time/batch = 0.6530s	
15588/25300 (epoch 30.806), train_loss = 0.85198180, grad/param norm = 2.3085e-01, time/batch = 0.6521s	
15589/25300 (epoch 30.808), train_loss = 0.90714364, grad/param norm = 2.1266e-01, time/batch = 0.6584s	
15590/25300 (epoch 30.810), train_loss = 0.79665115, grad/param norm = 2.3317e-01, time/batch = 0.6534s	
15591/25300 (epoch 30.812), train_loss = 0.91882316, grad/param norm = 2.0684e-01, time/batch = 0.6586s	
15592/25300 (epoch 30.814), train_loss = 0.95476351, grad/param norm = 2.4103e-01, time/batch = 0.6571s	
15593/25300 (epoch 30.816), train_loss = 1.02407342, grad/param norm = 2.2744e-01, time/batch = 0.6589s	
15594/25300 (epoch 30.818), train_loss = 0.88061697, grad/param norm = 1.9496e-01, time/batch = 0.6568s	
15595/25300 (epoch 30.820), train_loss = 0.91037950, grad/param norm = 2.5128e-01, time/batch = 0.6569s	
15596/25300 (epoch 30.822), train_loss = 0.76148721, grad/param norm = 1.8807e-01, time/batch = 0.6571s	
15597/25300 (epoch 30.824), train_loss = 0.92613714, grad/param norm = 2.3565e-01, time/batch = 0.6592s	
15598/25300 (epoch 30.826), train_loss = 0.73529786, grad/param norm = 1.9366e-01, time/batch = 0.6623s	
15599/25300 (epoch 30.828), train_loss = 0.75204453, grad/param norm = 2.2124e-01, time/batch = 0.6631s	
15600/25300 (epoch 30.830), train_loss = 0.84489243, grad/param norm = 2.3944e-01, time/batch = 0.6589s	
15601/25300 (epoch 30.832), train_loss = 0.91563298, grad/param norm = 2.3971e-01, time/batch = 0.6612s	
15602/25300 (epoch 30.834), train_loss = 0.76195536, grad/param norm = 2.1760e-01, time/batch = 0.6638s	
15603/25300 (epoch 30.836), train_loss = 0.78459224, grad/param norm = 2.0080e-01, time/batch = 0.6583s	
15604/25300 (epoch 30.838), train_loss = 0.77898115, grad/param norm = 2.1368e-01, time/batch = 0.6617s	
15605/25300 (epoch 30.840), train_loss = 0.88797529, grad/param norm = 2.3473e-01, time/batch = 0.6591s	
15606/25300 (epoch 30.842), train_loss = 0.83553522, grad/param norm = 2.4808e-01, time/batch = 0.6575s	
15607/25300 (epoch 30.844), train_loss = 0.90975285, grad/param norm = 2.0098e-01, time/batch = 0.6576s	
15608/25300 (epoch 30.846), train_loss = 0.85865376, grad/param norm = 1.8838e-01, time/batch = 0.6601s	
15609/25300 (epoch 30.848), train_loss = 0.88805986, grad/param norm = 2.8891e-01, time/batch = 0.6649s	
15610/25300 (epoch 30.850), train_loss = 0.83885647, grad/param norm = 2.2566e-01, time/batch = 0.6588s	
15611/25300 (epoch 30.852), train_loss = 0.89706002, grad/param norm = 2.0928e-01, time/batch = 0.6647s	
15612/25300 (epoch 30.854), train_loss = 0.93083344, grad/param norm = 2.2080e-01, time/batch = 0.6564s	
15613/25300 (epoch 30.856), train_loss = 0.78422231, grad/param norm = 2.2072e-01, time/batch = 0.6617s	
15614/25300 (epoch 30.858), train_loss = 0.83327172, grad/param norm = 2.5344e-01, time/batch = 0.6573s	
15615/25300 (epoch 30.860), train_loss = 0.68947649, grad/param norm = 2.0467e-01, time/batch = 0.6623s	
15616/25300 (epoch 30.862), train_loss = 0.82122557, grad/param norm = 2.3641e-01, time/batch = 0.6616s	
15617/25300 (epoch 30.864), train_loss = 0.91708973, grad/param norm = 2.1104e-01, time/batch = 0.6572s	
15618/25300 (epoch 30.866), train_loss = 0.77494499, grad/param norm = 2.0954e-01, time/batch = 0.6632s	
15619/25300 (epoch 30.868), train_loss = 0.92292510, grad/param norm = 2.0653e-01, time/batch = 0.6598s	
15620/25300 (epoch 30.870), train_loss = 0.91208288, grad/param norm = 1.8955e-01, time/batch = 0.6671s	
15621/25300 (epoch 30.872), train_loss = 0.85978373, grad/param norm = 2.5799e-01, time/batch = 0.6758s	
15622/25300 (epoch 30.874), train_loss = 0.85111228, grad/param norm = 2.2182e-01, time/batch = 0.6692s	
15623/25300 (epoch 30.875), train_loss = 0.80078624, grad/param norm = 2.1391e-01, time/batch = 0.6597s	
15624/25300 (epoch 30.877), train_loss = 0.79423120, grad/param norm = 2.0451e-01, time/batch = 0.6675s	
15625/25300 (epoch 30.879), train_loss = 0.75687786, grad/param norm = 2.4454e-01, time/batch = 0.6703s	
15626/25300 (epoch 30.881), train_loss = 1.07738061, grad/param norm = 2.8206e-01, time/batch = 0.6860s	
15627/25300 (epoch 30.883), train_loss = 1.03768435, grad/param norm = 2.3895e-01, time/batch = 0.6763s	
15628/25300 (epoch 30.885), train_loss = 0.89337306, grad/param norm = 2.4272e-01, time/batch = 0.6587s	
15629/25300 (epoch 30.887), train_loss = 0.91636369, grad/param norm = 2.1444e-01, time/batch = 0.6609s	
15630/25300 (epoch 30.889), train_loss = 1.01073382, grad/param norm = 3.5446e-01, time/batch = 0.6558s	
15631/25300 (epoch 30.891), train_loss = 0.92248659, grad/param norm = 2.9831e-01, time/batch = 0.6569s	
15632/25300 (epoch 30.893), train_loss = 0.87089932, grad/param norm = 2.8278e-01, time/batch = 0.6561s	
15633/25300 (epoch 30.895), train_loss = 0.65085877, grad/param norm = 1.9786e-01, time/batch = 0.6575s	
15634/25300 (epoch 30.897), train_loss = 0.74969422, grad/param norm = 1.8367e-01, time/batch = 0.6582s	
15635/25300 (epoch 30.899), train_loss = 0.85285368, grad/param norm = 2.1706e-01, time/batch = 0.6578s	
15636/25300 (epoch 30.901), train_loss = 0.88140515, grad/param norm = 2.2203e-01, time/batch = 0.6535s	
15637/25300 (epoch 30.903), train_loss = 0.69745256, grad/param norm = 2.0309e-01, time/batch = 0.6579s	
15638/25300 (epoch 30.905), train_loss = 0.79687339, grad/param norm = 2.4807e-01, time/batch = 0.6536s	
15639/25300 (epoch 30.907), train_loss = 0.76197940, grad/param norm = 2.2462e-01, time/batch = 0.6631s	
15640/25300 (epoch 30.909), train_loss = 0.89612667, grad/param norm = 2.2660e-01, time/batch = 0.6590s	
15641/25300 (epoch 30.911), train_loss = 0.94452141, grad/param norm = 2.5831e-01, time/batch = 0.6612s	
15642/25300 (epoch 30.913), train_loss = 1.04089722, grad/param norm = 2.8237e-01, time/batch = 0.6617s	
15643/25300 (epoch 30.915), train_loss = 0.78625261, grad/param norm = 2.4464e-01, time/batch = 0.6574s	
15644/25300 (epoch 30.917), train_loss = 0.94936021, grad/param norm = 2.2220e-01, time/batch = 0.6611s	
15645/25300 (epoch 30.919), train_loss = 0.96426866, grad/param norm = 2.8255e-01, time/batch = 0.6671s	
15646/25300 (epoch 30.921), train_loss = 0.78381843, grad/param norm = 2.2233e-01, time/batch = 0.6681s	
15647/25300 (epoch 30.923), train_loss = 0.94935928, grad/param norm = 2.2625e-01, time/batch = 0.6665s	
15648/25300 (epoch 30.925), train_loss = 0.85806931, grad/param norm = 2.7471e-01, time/batch = 0.6666s	
15649/25300 (epoch 30.927), train_loss = 0.80407486, grad/param norm = 2.3718e-01, time/batch = 0.6683s	
15650/25300 (epoch 30.929), train_loss = 0.85277269, grad/param norm = 1.9978e-01, time/batch = 0.6569s	
15651/25300 (epoch 30.931), train_loss = 0.91529707, grad/param norm = 2.6052e-01, time/batch = 0.6600s	
15652/25300 (epoch 30.933), train_loss = 0.86031228, grad/param norm = 2.1861e-01, time/batch = 0.6595s	
15653/25300 (epoch 30.935), train_loss = 0.87281297, grad/param norm = 2.0204e-01, time/batch = 0.6603s	
15654/25300 (epoch 30.937), train_loss = 0.65807024, grad/param norm = 1.9890e-01, time/batch = 0.6635s	
15655/25300 (epoch 30.939), train_loss = 0.86537444, grad/param norm = 2.1977e-01, time/batch = 0.6585s	
15656/25300 (epoch 30.941), train_loss = 0.78054838, grad/param norm = 2.2502e-01, time/batch = 0.6591s	
15657/25300 (epoch 30.943), train_loss = 0.87605755, grad/param norm = 2.1232e-01, time/batch = 0.6596s	
15658/25300 (epoch 30.945), train_loss = 0.85830600, grad/param norm = 2.1848e-01, time/batch = 0.6643s	
15659/25300 (epoch 30.947), train_loss = 0.76210463, grad/param norm = 2.3768e-01, time/batch = 0.6622s	
15660/25300 (epoch 30.949), train_loss = 0.87474853, grad/param norm = 1.9913e-01, time/batch = 0.6641s	
15661/25300 (epoch 30.951), train_loss = 0.81994694, grad/param norm = 1.7362e-01, time/batch = 0.6592s	
15662/25300 (epoch 30.953), train_loss = 0.82212229, grad/param norm = 2.2452e-01, time/batch = 0.6689s	
15663/25300 (epoch 30.955), train_loss = 1.04757093, grad/param norm = 2.9039e-01, time/batch = 0.6656s	
15664/25300 (epoch 30.957), train_loss = 0.94659880, grad/param norm = 2.4868e-01, time/batch = 0.6605s	
15665/25300 (epoch 30.958), train_loss = 0.92381110, grad/param norm = 2.5615e-01, time/batch = 0.6612s	
15666/25300 (epoch 30.960), train_loss = 1.02701563, grad/param norm = 2.5557e-01, time/batch = 0.6683s	
15667/25300 (epoch 30.962), train_loss = 0.98522704, grad/param norm = 2.3427e-01, time/batch = 0.6627s	
15668/25300 (epoch 30.964), train_loss = 0.88694679, grad/param norm = 2.4039e-01, time/batch = 0.6630s	
15669/25300 (epoch 30.966), train_loss = 0.74949713, grad/param norm = 2.2285e-01, time/batch = 0.6638s	
15670/25300 (epoch 30.968), train_loss = 0.72471226, grad/param norm = 2.2689e-01, time/batch = 0.6591s	
15671/25300 (epoch 30.970), train_loss = 0.83626044, grad/param norm = 2.9782e-01, time/batch = 0.6597s	
15672/25300 (epoch 30.972), train_loss = 0.83327853, grad/param norm = 2.0826e-01, time/batch = 0.6629s	
15673/25300 (epoch 30.974), train_loss = 0.98647132, grad/param norm = 2.9282e-01, time/batch = 0.6631s	
15674/25300 (epoch 30.976), train_loss = 0.89467898, grad/param norm = 2.3541e-01, time/batch = 0.6628s	
15675/25300 (epoch 30.978), train_loss = 0.80294754, grad/param norm = 2.2025e-01, time/batch = 0.6590s	
15676/25300 (epoch 30.980), train_loss = 0.84849727, grad/param norm = 2.2265e-01, time/batch = 0.6622s	
15677/25300 (epoch 30.982), train_loss = 0.79704855, grad/param norm = 2.0553e-01, time/batch = 0.6601s	
15678/25300 (epoch 30.984), train_loss = 0.81808344, grad/param norm = 2.2127e-01, time/batch = 0.6600s	
15679/25300 (epoch 30.986), train_loss = 0.90165700, grad/param norm = 2.2812e-01, time/batch = 0.6643s	
15680/25300 (epoch 30.988), train_loss = 0.88241278, grad/param norm = 2.3696e-01, time/batch = 0.6585s	
15681/25300 (epoch 30.990), train_loss = 0.84184746, grad/param norm = 2.1507e-01, time/batch = 0.6598s	
15682/25300 (epoch 30.992), train_loss = 0.72655479, grad/param norm = 1.8531e-01, time/batch = 0.6628s	
15683/25300 (epoch 30.994), train_loss = 0.86617392, grad/param norm = 2.3999e-01, time/batch = 0.6592s	
15684/25300 (epoch 30.996), train_loss = 1.00327388, grad/param norm = 2.8174e-01, time/batch = 0.6581s	
15685/25300 (epoch 30.998), train_loss = 0.92366769, grad/param norm = 2.3519e-01, time/batch = 0.6571s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
15686/25300 (epoch 31.000), train_loss = 0.92025314, grad/param norm = 2.5777e-01, time/batch = 0.6567s	
15687/25300 (epoch 31.002), train_loss = 0.81386707, grad/param norm = 1.9016e-01, time/batch = 0.6605s	
15688/25300 (epoch 31.004), train_loss = 0.71621799, grad/param norm = 1.9309e-01, time/batch = 0.6563s	
15689/25300 (epoch 31.006), train_loss = 0.98349110, grad/param norm = 2.1548e-01, time/batch = 0.6606s	
15690/25300 (epoch 31.008), train_loss = 0.83011239, grad/param norm = 2.4543e-01, time/batch = 0.6610s	
15691/25300 (epoch 31.010), train_loss = 0.88043210, grad/param norm = 2.1597e-01, time/batch = 0.6606s	
15692/25300 (epoch 31.012), train_loss = 0.79191692, grad/param norm = 2.0427e-01, time/batch = 0.6591s	
15693/25300 (epoch 31.014), train_loss = 0.97557821, grad/param norm = 2.2511e-01, time/batch = 0.6586s	
15694/25300 (epoch 31.016), train_loss = 0.84501433, grad/param norm = 2.6593e-01, time/batch = 0.6638s	
15695/25300 (epoch 31.018), train_loss = 0.75393330, grad/param norm = 2.1632e-01, time/batch = 0.6590s	
15696/25300 (epoch 31.020), train_loss = 0.86682017, grad/param norm = 2.3250e-01, time/batch = 0.6625s	
15697/25300 (epoch 31.022), train_loss = 0.83784334, grad/param norm = 2.2015e-01, time/batch = 0.6571s	
15698/25300 (epoch 31.024), train_loss = 0.63171511, grad/param norm = 1.7261e-01, time/batch = 0.6602s	
15699/25300 (epoch 31.026), train_loss = 0.78649795, grad/param norm = 2.0969e-01, time/batch = 0.6569s	
15700/25300 (epoch 31.028), train_loss = 0.77978746, grad/param norm = 2.0382e-01, time/batch = 0.6579s	
15701/25300 (epoch 31.030), train_loss = 0.94645600, grad/param norm = 1.9089e-01, time/batch = 0.6604s	
15702/25300 (epoch 31.032), train_loss = 0.81177203, grad/param norm = 2.1116e-01, time/batch = 0.6612s	
15703/25300 (epoch 31.034), train_loss = 0.71304695, grad/param norm = 2.0346e-01, time/batch = 0.6640s	
15704/25300 (epoch 31.036), train_loss = 0.68390146, grad/param norm = 2.0410e-01, time/batch = 0.6603s	
15705/25300 (epoch 31.038), train_loss = 0.64787346, grad/param norm = 1.6735e-01, time/batch = 0.6584s	
15706/25300 (epoch 31.040), train_loss = 0.82778477, grad/param norm = 1.9962e-01, time/batch = 0.6593s	
15707/25300 (epoch 31.042), train_loss = 0.82883645, grad/param norm = 1.9157e-01, time/batch = 0.6605s	
15708/25300 (epoch 31.043), train_loss = 0.69846964, grad/param norm = 1.7741e-01, time/batch = 0.6587s	
15709/25300 (epoch 31.045), train_loss = 0.69893861, grad/param norm = 1.9430e-01, time/batch = 0.6617s	
15710/25300 (epoch 31.047), train_loss = 0.84775372, grad/param norm = 1.9279e-01, time/batch = 0.6671s	
15711/25300 (epoch 31.049), train_loss = 0.84058489, grad/param norm = 2.1998e-01, time/batch = 0.6720s	
15712/25300 (epoch 31.051), train_loss = 0.94098211, grad/param norm = 2.2842e-01, time/batch = 0.6735s	
15713/25300 (epoch 31.053), train_loss = 0.65781246, grad/param norm = 1.7395e-01, time/batch = 0.6658s	
15714/25300 (epoch 31.055), train_loss = 0.69097287, grad/param norm = 1.9126e-01, time/batch = 0.6646s	
15715/25300 (epoch 31.057), train_loss = 0.67918514, grad/param norm = 1.6130e-01, time/batch = 0.6633s	
15716/25300 (epoch 31.059), train_loss = 0.74736116, grad/param norm = 1.7824e-01, time/batch = 0.6560s	
15717/25300 (epoch 31.061), train_loss = 0.76034124, grad/param norm = 2.0336e-01, time/batch = 0.6596s	
15718/25300 (epoch 31.063), train_loss = 0.75783132, grad/param norm = 2.0165e-01, time/batch = 0.6626s	
15719/25300 (epoch 31.065), train_loss = 0.83699071, grad/param norm = 2.1480e-01, time/batch = 0.6609s	
15720/25300 (epoch 31.067), train_loss = 0.89142671, grad/param norm = 1.8873e-01, time/batch = 0.6626s	
15721/25300 (epoch 31.069), train_loss = 0.73024011, grad/param norm = 1.8644e-01, time/batch = 0.6618s	
15722/25300 (epoch 31.071), train_loss = 0.87390671, grad/param norm = 2.3451e-01, time/batch = 0.6628s	
15723/25300 (epoch 31.073), train_loss = 0.78968456, grad/param norm = 1.9165e-01, time/batch = 0.6597s	
15724/25300 (epoch 31.075), train_loss = 0.90122514, grad/param norm = 2.3599e-01, time/batch = 0.6630s	
15725/25300 (epoch 31.077), train_loss = 0.86076112, grad/param norm = 2.2044e-01, time/batch = 0.6617s	
15726/25300 (epoch 31.079), train_loss = 0.75146975, grad/param norm = 1.9784e-01, time/batch = 0.6628s	
15727/25300 (epoch 31.081), train_loss = 0.81058257, grad/param norm = 1.7053e-01, time/batch = 0.6631s	
15728/25300 (epoch 31.083), train_loss = 0.82611411, grad/param norm = 1.8670e-01, time/batch = 0.6595s	
15729/25300 (epoch 31.085), train_loss = 0.99578280, grad/param norm = 2.2313e-01, time/batch = 0.6590s	
15730/25300 (epoch 31.087), train_loss = 0.90159055, grad/param norm = 1.9609e-01, time/batch = 0.6634s	
15731/25300 (epoch 31.089), train_loss = 0.85987604, grad/param norm = 1.9802e-01, time/batch = 0.6627s	
15732/25300 (epoch 31.091), train_loss = 0.98407464, grad/param norm = 2.1602e-01, time/batch = 0.6648s	
15733/25300 (epoch 31.093), train_loss = 0.93631927, grad/param norm = 2.4840e-01, time/batch = 0.6646s	
15734/25300 (epoch 31.095), train_loss = 0.89187930, grad/param norm = 2.1244e-01, time/batch = 0.6624s	
15735/25300 (epoch 31.097), train_loss = 0.88024119, grad/param norm = 2.2531e-01, time/batch = 0.6610s	
15736/25300 (epoch 31.099), train_loss = 0.86438806, grad/param norm = 2.4129e-01, time/batch = 0.6605s	
15737/25300 (epoch 31.101), train_loss = 0.81610698, grad/param norm = 2.1819e-01, time/batch = 0.6624s	
15738/25300 (epoch 31.103), train_loss = 0.84754710, grad/param norm = 2.0367e-01, time/batch = 0.6581s	
15739/25300 (epoch 31.105), train_loss = 0.90760004, grad/param norm = 2.2214e-01, time/batch = 0.6569s	
15740/25300 (epoch 31.107), train_loss = 0.93834909, grad/param norm = 2.7536e-01, time/batch = 0.6606s	
15741/25300 (epoch 31.109), train_loss = 0.81700751, grad/param norm = 2.3293e-01, time/batch = 0.6595s	
15742/25300 (epoch 31.111), train_loss = 0.83169133, grad/param norm = 2.1191e-01, time/batch = 0.6615s	
15743/25300 (epoch 31.113), train_loss = 0.77961832, grad/param norm = 2.2279e-01, time/batch = 0.6579s	
15744/25300 (epoch 31.115), train_loss = 0.80976592, grad/param norm = 2.1764e-01, time/batch = 0.6596s	
15745/25300 (epoch 31.117), train_loss = 0.93697289, grad/param norm = 2.2253e-01, time/batch = 0.6563s	
15746/25300 (epoch 31.119), train_loss = 0.79112189, grad/param norm = 2.3109e-01, time/batch = 0.6588s	
15747/25300 (epoch 31.121), train_loss = 0.83615372, grad/param norm = 2.2105e-01, time/batch = 0.6646s	
15748/25300 (epoch 31.123), train_loss = 0.75228545, grad/param norm = 1.9651e-01, time/batch = 0.6748s	
15749/25300 (epoch 31.125), train_loss = 0.92733870, grad/param norm = 2.1090e-01, time/batch = 0.6756s	
15750/25300 (epoch 31.126), train_loss = 0.83968461, grad/param norm = 1.9478e-01, time/batch = 0.6620s	
15751/25300 (epoch 31.128), train_loss = 0.81772434, grad/param norm = 2.1436e-01, time/batch = 0.6633s	
15752/25300 (epoch 31.130), train_loss = 0.65783691, grad/param norm = 1.7680e-01, time/batch = 0.6653s	
15753/25300 (epoch 31.132), train_loss = 0.69536309, grad/param norm = 2.1354e-01, time/batch = 0.6674s	
15754/25300 (epoch 31.134), train_loss = 0.68544675, grad/param norm = 1.6754e-01, time/batch = 0.6588s	
15755/25300 (epoch 31.136), train_loss = 0.79835874, grad/param norm = 1.8721e-01, time/batch = 0.6602s	
15756/25300 (epoch 31.138), train_loss = 0.71864226, grad/param norm = 1.8250e-01, time/batch = 0.6566s	
15757/25300 (epoch 31.140), train_loss = 0.72546470, grad/param norm = 2.1000e-01, time/batch = 0.6643s	
15758/25300 (epoch 31.142), train_loss = 0.91898611, grad/param norm = 2.2590e-01, time/batch = 0.6560s	
15759/25300 (epoch 31.144), train_loss = 0.89115277, grad/param norm = 2.1650e-01, time/batch = 0.6565s	
15760/25300 (epoch 31.146), train_loss = 0.83509015, grad/param norm = 2.5240e-01, time/batch = 0.6656s	
15761/25300 (epoch 31.148), train_loss = 0.80985928, grad/param norm = 2.0248e-01, time/batch = 0.6689s	
15762/25300 (epoch 31.150), train_loss = 0.87356808, grad/param norm = 2.4319e-01, time/batch = 0.6716s	
15763/25300 (epoch 31.152), train_loss = 0.95469307, grad/param norm = 2.2942e-01, time/batch = 0.6676s	
15764/25300 (epoch 31.154), train_loss = 0.68962473, grad/param norm = 1.9682e-01, time/batch = 0.6672s	
15765/25300 (epoch 31.156), train_loss = 0.88166967, grad/param norm = 2.6257e-01, time/batch = 0.6618s	
15766/25300 (epoch 31.158), train_loss = 0.73412626, grad/param norm = 2.6591e-01, time/batch = 0.6626s	
15767/25300 (epoch 31.160), train_loss = 0.82937758, grad/param norm = 2.1100e-01, time/batch = 0.6670s	
15768/25300 (epoch 31.162), train_loss = 0.77159598, grad/param norm = 2.0752e-01, time/batch = 0.6667s	
15769/25300 (epoch 31.164), train_loss = 0.88706187, grad/param norm = 2.2244e-01, time/batch = 0.6632s	
15770/25300 (epoch 31.166), train_loss = 0.84197904, grad/param norm = 2.0223e-01, time/batch = 0.6669s	
15771/25300 (epoch 31.168), train_loss = 0.75784453, grad/param norm = 1.7966e-01, time/batch = 0.6714s	
15772/25300 (epoch 31.170), train_loss = 0.76714587, grad/param norm = 2.4052e-01, time/batch = 0.6695s	
15773/25300 (epoch 31.172), train_loss = 0.71988571, grad/param norm = 2.1165e-01, time/batch = 0.6644s	
15774/25300 (epoch 31.174), train_loss = 0.75382179, grad/param norm = 2.3216e-01, time/batch = 0.6677s	
15775/25300 (epoch 31.176), train_loss = 0.73984314, grad/param norm = 2.2277e-01, time/batch = 0.6669s	
15776/25300 (epoch 31.178), train_loss = 0.94943632, grad/param norm = 2.2219e-01, time/batch = 0.6721s	
15777/25300 (epoch 31.180), train_loss = 0.67542853, grad/param norm = 1.8974e-01, time/batch = 0.6660s	
15778/25300 (epoch 31.182), train_loss = 0.76254706, grad/param norm = 2.2384e-01, time/batch = 0.6584s	
15779/25300 (epoch 31.184), train_loss = 0.73412527, grad/param norm = 2.2150e-01, time/batch = 0.6606s	
15780/25300 (epoch 31.186), train_loss = 0.70157051, grad/param norm = 1.9579e-01, time/batch = 0.6563s	
15781/25300 (epoch 31.188), train_loss = 0.81360765, grad/param norm = 2.2336e-01, time/batch = 0.6581s	
15782/25300 (epoch 31.190), train_loss = 0.78944989, grad/param norm = 2.0386e-01, time/batch = 0.6560s	
15783/25300 (epoch 31.192), train_loss = 0.76834981, grad/param norm = 1.8949e-01, time/batch = 0.6526s	
15784/25300 (epoch 31.194), train_loss = 0.77876070, grad/param norm = 2.3351e-01, time/batch = 0.6571s	
15785/25300 (epoch 31.196), train_loss = 0.92781364, grad/param norm = 2.4479e-01, time/batch = 0.6602s	
15786/25300 (epoch 31.198), train_loss = 0.75895889, grad/param norm = 2.2621e-01, time/batch = 0.6622s	
15787/25300 (epoch 31.200), train_loss = 0.78042651, grad/param norm = 2.0031e-01, time/batch = 0.6675s	
15788/25300 (epoch 31.202), train_loss = 0.78538838, grad/param norm = 2.0242e-01, time/batch = 0.6664s	
15789/25300 (epoch 31.204), train_loss = 0.80641676, grad/param norm = 2.1920e-01, time/batch = 0.6677s	
15790/25300 (epoch 31.206), train_loss = 0.89654275, grad/param norm = 2.1227e-01, time/batch = 0.6640s	
15791/25300 (epoch 31.208), train_loss = 0.73297319, grad/param norm = 2.2293e-01, time/batch = 0.6656s	
15792/25300 (epoch 31.209), train_loss = 0.70535927, grad/param norm = 2.1542e-01, time/batch = 0.6588s	
15793/25300 (epoch 31.211), train_loss = 0.77413379, grad/param norm = 2.0360e-01, time/batch = 0.6559s	
15794/25300 (epoch 31.213), train_loss = 0.83329048, grad/param norm = 2.1837e-01, time/batch = 0.6570s	
15795/25300 (epoch 31.215), train_loss = 0.84283872, grad/param norm = 2.1252e-01, time/batch = 0.6559s	
15796/25300 (epoch 31.217), train_loss = 0.83849408, grad/param norm = 2.4642e-01, time/batch = 0.6598s	
15797/25300 (epoch 31.219), train_loss = 0.89141336, grad/param norm = 2.2691e-01, time/batch = 0.6602s	
15798/25300 (epoch 31.221), train_loss = 0.93197858, grad/param norm = 2.1876e-01, time/batch = 0.6616s	
15799/25300 (epoch 31.223), train_loss = 0.87152304, grad/param norm = 2.2184e-01, time/batch = 0.6557s	
15800/25300 (epoch 31.225), train_loss = 1.10717398, grad/param norm = 2.6565e-01, time/batch = 0.6660s	
15801/25300 (epoch 31.227), train_loss = 0.95133906, grad/param norm = 2.2621e-01, time/batch = 0.6673s	
15802/25300 (epoch 31.229), train_loss = 0.79753355, grad/param norm = 2.1939e-01, time/batch = 0.6664s	
15803/25300 (epoch 31.231), train_loss = 0.85033555, grad/param norm = 2.6229e-01, time/batch = 0.6622s	
15804/25300 (epoch 31.233), train_loss = 0.86453287, grad/param norm = 2.2386e-01, time/batch = 0.6613s	
15805/25300 (epoch 31.235), train_loss = 0.82025761, grad/param norm = 2.1480e-01, time/batch = 0.6613s	
15806/25300 (epoch 31.237), train_loss = 0.94354525, grad/param norm = 2.3290e-01, time/batch = 0.6603s	
15807/25300 (epoch 31.239), train_loss = 0.77213640, grad/param norm = 1.9501e-01, time/batch = 0.6643s	
15808/25300 (epoch 31.241), train_loss = 0.95779251, grad/param norm = 2.2076e-01, time/batch = 0.6677s	
15809/25300 (epoch 31.243), train_loss = 1.09461682, grad/param norm = 2.9060e-01, time/batch = 0.6850s	
15810/25300 (epoch 31.245), train_loss = 0.78706146, grad/param norm = 2.1951e-01, time/batch = 0.6674s	
15811/25300 (epoch 31.247), train_loss = 0.88278177, grad/param norm = 2.0768e-01, time/batch = 0.6631s	
15812/25300 (epoch 31.249), train_loss = 0.70413965, grad/param norm = 1.8429e-01, time/batch = 0.6549s	
15813/25300 (epoch 31.251), train_loss = 0.72218529, grad/param norm = 1.9745e-01, time/batch = 0.6705s	
15814/25300 (epoch 31.253), train_loss = 0.78833599, grad/param norm = 2.0530e-01, time/batch = 0.6659s	
15815/25300 (epoch 31.255), train_loss = 0.75355998, grad/param norm = 2.2818e-01, time/batch = 0.6681s	
15816/25300 (epoch 31.257), train_loss = 0.78947718, grad/param norm = 1.9959e-01, time/batch = 0.6670s	
15817/25300 (epoch 31.259), train_loss = 1.00198675, grad/param norm = 2.6183e-01, time/batch = 0.6617s	
15818/25300 (epoch 31.261), train_loss = 0.94577812, grad/param norm = 2.6272e-01, time/batch = 0.6622s	
15819/25300 (epoch 31.263), train_loss = 0.97083562, grad/param norm = 2.3638e-01, time/batch = 0.6633s	
15820/25300 (epoch 31.265), train_loss = 0.99852480, grad/param norm = 2.6118e-01, time/batch = 0.6595s	
15821/25300 (epoch 31.267), train_loss = 0.87109713, grad/param norm = 2.0299e-01, time/batch = 0.6586s	
15822/25300 (epoch 31.269), train_loss = 0.70231590, grad/param norm = 1.8793e-01, time/batch = 0.6612s	
15823/25300 (epoch 31.271), train_loss = 0.75897253, grad/param norm = 1.9111e-01, time/batch = 0.6569s	
15824/25300 (epoch 31.273), train_loss = 0.90432867, grad/param norm = 3.1359e-01, time/batch = 0.6612s	
15825/25300 (epoch 31.275), train_loss = 0.79872223, grad/param norm = 2.0940e-01, time/batch = 0.6587s	
15826/25300 (epoch 31.277), train_loss = 0.78732498, grad/param norm = 2.3512e-01, time/batch = 0.6619s	
15827/25300 (epoch 31.279), train_loss = 0.83303892, grad/param norm = 2.0854e-01, time/batch = 0.6576s	
15828/25300 (epoch 31.281), train_loss = 0.96737830, grad/param norm = 2.5638e-01, time/batch = 0.6629s	
15829/25300 (epoch 31.283), train_loss = 0.72542633, grad/param norm = 1.9203e-01, time/batch = 0.6569s	
15830/25300 (epoch 31.285), train_loss = 0.84495822, grad/param norm = 2.1582e-01, time/batch = 0.6524s	
15831/25300 (epoch 31.287), train_loss = 0.92917564, grad/param norm = 1.8814e-01, time/batch = 0.6609s	
15832/25300 (epoch 31.289), train_loss = 0.79829795, grad/param norm = 2.3484e-01, time/batch = 0.6595s	
15833/25300 (epoch 31.291), train_loss = 0.77672030, grad/param norm = 1.9464e-01, time/batch = 0.6606s	
15834/25300 (epoch 31.292), train_loss = 0.97963731, grad/param norm = 2.2967e-01, time/batch = 0.6589s	
15835/25300 (epoch 31.294), train_loss = 0.86992209, grad/param norm = 2.1240e-01, time/batch = 0.6610s	
15836/25300 (epoch 31.296), train_loss = 0.73660324, grad/param norm = 1.9228e-01, time/batch = 0.6603s	
15837/25300 (epoch 31.298), train_loss = 0.91331051, grad/param norm = 2.2358e-01, time/batch = 0.6589s	
15838/25300 (epoch 31.300), train_loss = 0.91479661, grad/param norm = 2.2578e-01, time/batch = 0.6586s	
15839/25300 (epoch 31.302), train_loss = 0.67112720, grad/param norm = 2.1688e-01, time/batch = 0.6596s	
15840/25300 (epoch 31.304), train_loss = 0.94736291, grad/param norm = 2.3216e-01, time/batch = 0.6565s	
15841/25300 (epoch 31.306), train_loss = 0.66241845, grad/param norm = 1.8719e-01, time/batch = 0.6642s	
15842/25300 (epoch 31.308), train_loss = 0.89775795, grad/param norm = 2.0326e-01, time/batch = 0.6580s	
15843/25300 (epoch 31.310), train_loss = 0.73259924, grad/param norm = 2.2083e-01, time/batch = 0.6590s	
15844/25300 (epoch 31.312), train_loss = 0.85603831, grad/param norm = 2.0217e-01, time/batch = 0.6602s	
15845/25300 (epoch 31.314), train_loss = 0.68890336, grad/param norm = 2.0382e-01, time/batch = 0.6585s	
15846/25300 (epoch 31.316), train_loss = 0.84165262, grad/param norm = 1.8342e-01, time/batch = 0.6628s	
15847/25300 (epoch 31.318), train_loss = 0.67158231, grad/param norm = 1.9593e-01, time/batch = 0.6600s	
15848/25300 (epoch 31.320), train_loss = 0.74185408, grad/param norm = 1.8774e-01, time/batch = 0.6585s	
15849/25300 (epoch 31.322), train_loss = 0.97109722, grad/param norm = 2.3456e-01, time/batch = 0.6568s	
15850/25300 (epoch 31.324), train_loss = 0.74701489, grad/param norm = 2.0810e-01, time/batch = 0.6613s	
15851/25300 (epoch 31.326), train_loss = 0.66919269, grad/param norm = 1.8302e-01, time/batch = 0.6589s	
15852/25300 (epoch 31.328), train_loss = 0.65604306, grad/param norm = 2.0025e-01, time/batch = 0.6615s	
15853/25300 (epoch 31.330), train_loss = 0.79778772, grad/param norm = 2.0454e-01, time/batch = 0.6567s	
15854/25300 (epoch 31.332), train_loss = 0.82778435, grad/param norm = 2.0078e-01, time/batch = 0.6635s	
15855/25300 (epoch 31.334), train_loss = 0.68605510, grad/param norm = 1.9950e-01, time/batch = 0.6810s	
15856/25300 (epoch 31.336), train_loss = 0.69470853, grad/param norm = 2.1410e-01, time/batch = 0.6609s	
15857/25300 (epoch 31.338), train_loss = 0.71372451, grad/param norm = 2.0176e-01, time/batch = 0.6623s	
15858/25300 (epoch 31.340), train_loss = 0.74496119, grad/param norm = 2.2182e-01, time/batch = 0.6656s	
15859/25300 (epoch 31.342), train_loss = 0.79357709, grad/param norm = 3.0503e-01, time/batch = 0.6603s	
15860/25300 (epoch 31.344), train_loss = 0.86509593, grad/param norm = 2.1241e-01, time/batch = 0.6655s	
15861/25300 (epoch 31.346), train_loss = 0.75926545, grad/param norm = 2.2582e-01, time/batch = 0.6654s	
15862/25300 (epoch 31.348), train_loss = 0.71090501, grad/param norm = 1.9577e-01, time/batch = 0.6557s	
15863/25300 (epoch 31.350), train_loss = 0.77922811, grad/param norm = 2.0858e-01, time/batch = 0.6527s	
15864/25300 (epoch 31.352), train_loss = 0.79469929, grad/param norm = 2.0068e-01, time/batch = 0.6570s	
15865/25300 (epoch 31.354), train_loss = 0.76898234, grad/param norm = 2.2928e-01, time/batch = 0.6534s	
15866/25300 (epoch 31.356), train_loss = 0.80348464, grad/param norm = 2.1096e-01, time/batch = 0.6587s	
15867/25300 (epoch 31.358), train_loss = 0.83250852, grad/param norm = 2.3768e-01, time/batch = 0.6604s	
15868/25300 (epoch 31.360), train_loss = 0.73500323, grad/param norm = 1.9566e-01, time/batch = 0.6586s	
15869/25300 (epoch 31.362), train_loss = 0.71494462, grad/param norm = 2.0697e-01, time/batch = 0.6636s	
15870/25300 (epoch 31.364), train_loss = 0.73999549, grad/param norm = 2.1792e-01, time/batch = 0.6600s	
15871/25300 (epoch 31.366), train_loss = 0.70649291, grad/param norm = 1.8503e-01, time/batch = 0.6645s	
15872/25300 (epoch 31.368), train_loss = 0.78050092, grad/param norm = 1.8180e-01, time/batch = 0.6590s	
15873/25300 (epoch 31.370), train_loss = 0.73078433, grad/param norm = 2.1668e-01, time/batch = 0.6618s	
15874/25300 (epoch 31.372), train_loss = 0.74004580, grad/param norm = 2.4175e-01, time/batch = 0.6693s	
15875/25300 (epoch 31.374), train_loss = 0.68280336, grad/param norm = 2.1042e-01, time/batch = 0.6635s	
15876/25300 (epoch 31.375), train_loss = 0.88967060, grad/param norm = 2.5609e-01, time/batch = 0.6657s	
15877/25300 (epoch 31.377), train_loss = 0.87233741, grad/param norm = 2.1594e-01, time/batch = 0.6682s	
15878/25300 (epoch 31.379), train_loss = 0.85098559, grad/param norm = 2.2659e-01, time/batch = 0.6644s	
15879/25300 (epoch 31.381), train_loss = 0.77339742, grad/param norm = 2.0111e-01, time/batch = 0.6597s	
15880/25300 (epoch 31.383), train_loss = 0.71198411, grad/param norm = 2.0426e-01, time/batch = 0.6597s	
15881/25300 (epoch 31.385), train_loss = 0.83244970, grad/param norm = 1.9608e-01, time/batch = 0.6610s	
15882/25300 (epoch 31.387), train_loss = 0.80774915, grad/param norm = 2.1635e-01, time/batch = 0.6671s	
15883/25300 (epoch 31.389), train_loss = 0.79881341, grad/param norm = 2.3125e-01, time/batch = 0.6661s	
15884/25300 (epoch 31.391), train_loss = 0.75348263, grad/param norm = 2.0155e-01, time/batch = 0.6619s	
15885/25300 (epoch 31.393), train_loss = 0.81612760, grad/param norm = 2.6747e-01, time/batch = 0.6643s	
15886/25300 (epoch 31.395), train_loss = 0.64241650, grad/param norm = 1.8330e-01, time/batch = 0.6609s	
15887/25300 (epoch 31.397), train_loss = 0.63838913, grad/param norm = 2.3365e-01, time/batch = 0.6624s	
15888/25300 (epoch 31.399), train_loss = 0.70860242, grad/param norm = 2.2144e-01, time/batch = 0.6630s	
15889/25300 (epoch 31.401), train_loss = 0.85912263, grad/param norm = 2.4141e-01, time/batch = 0.6610s	
15890/25300 (epoch 31.403), train_loss = 0.84286644, grad/param norm = 2.8052e-01, time/batch = 0.6663s	
15891/25300 (epoch 31.405), train_loss = 0.77068950, grad/param norm = 2.1453e-01, time/batch = 0.6713s	
15892/25300 (epoch 31.407), train_loss = 0.77540047, grad/param norm = 2.0380e-01, time/batch = 0.6714s	
15893/25300 (epoch 31.409), train_loss = 0.70968111, grad/param norm = 1.9830e-01, time/batch = 0.6616s	
15894/25300 (epoch 31.411), train_loss = 0.75016061, grad/param norm = 2.3690e-01, time/batch = 0.6552s	
15895/25300 (epoch 31.413), train_loss = 0.66830364, grad/param norm = 2.0184e-01, time/batch = 0.6549s	
15896/25300 (epoch 31.415), train_loss = 0.70781689, grad/param norm = 1.9237e-01, time/batch = 0.6605s	
15897/25300 (epoch 31.417), train_loss = 0.67566509, grad/param norm = 1.8061e-01, time/batch = 0.6638s	
15898/25300 (epoch 31.419), train_loss = 0.61450779, grad/param norm = 1.7087e-01, time/batch = 0.6632s	
15899/25300 (epoch 31.421), train_loss = 0.66893410, grad/param norm = 1.6346e-01, time/batch = 0.6576s	
15900/25300 (epoch 31.423), train_loss = 0.67397783, grad/param norm = 2.1017e-01, time/batch = 0.6615s	
15901/25300 (epoch 31.425), train_loss = 0.78322569, grad/param norm = 2.7457e-01, time/batch = 0.6684s	
15902/25300 (epoch 31.427), train_loss = 0.89527506, grad/param norm = 2.2616e-01, time/batch = 0.6598s	
15903/25300 (epoch 31.429), train_loss = 0.89838707, grad/param norm = 2.4442e-01, time/batch = 0.6646s	
15904/25300 (epoch 31.431), train_loss = 0.80202631, grad/param norm = 2.6320e-01, time/batch = 0.6624s	
15905/25300 (epoch 31.433), train_loss = 0.81760334, grad/param norm = 1.9698e-01, time/batch = 0.6867s	
15906/25300 (epoch 31.435), train_loss = 0.72423550, grad/param norm = 2.2393e-01, time/batch = 0.6677s	
15907/25300 (epoch 31.437), train_loss = 0.71616940, grad/param norm = 2.0730e-01, time/batch = 0.6605s	
15908/25300 (epoch 31.439), train_loss = 0.82584789, grad/param norm = 2.6460e-01, time/batch = 0.6615s	
15909/25300 (epoch 31.441), train_loss = 0.83341778, grad/param norm = 2.2545e-01, time/batch = 0.6608s	
15910/25300 (epoch 31.443), train_loss = 0.95425259, grad/param norm = 2.4095e-01, time/batch = 0.6685s	
15911/25300 (epoch 31.445), train_loss = 0.89842256, grad/param norm = 2.3616e-01, time/batch = 0.6620s	
15912/25300 (epoch 31.447), train_loss = 0.72083284, grad/param norm = 1.9382e-01, time/batch = 0.6665s	
15913/25300 (epoch 31.449), train_loss = 0.65972498, grad/param norm = 2.4693e-01, time/batch = 0.6587s	
15914/25300 (epoch 31.451), train_loss = 0.99674871, grad/param norm = 2.6179e-01, time/batch = 0.6620s	
15915/25300 (epoch 31.453), train_loss = 0.85638515, grad/param norm = 2.2044e-01, time/batch = 0.6589s	
15916/25300 (epoch 31.455), train_loss = 0.82602877, grad/param norm = 2.5183e-01, time/batch = 0.6591s	
15917/25300 (epoch 31.457), train_loss = 0.73806145, grad/param norm = 2.0358e-01, time/batch = 0.6604s	
15918/25300 (epoch 31.458), train_loss = 0.74877039, grad/param norm = 2.2679e-01, time/batch = 0.6583s	
15919/25300 (epoch 31.460), train_loss = 0.76983744, grad/param norm = 2.0759e-01, time/batch = 0.6582s	
15920/25300 (epoch 31.462), train_loss = 0.59358012, grad/param norm = 2.1065e-01, time/batch = 0.6594s	
15921/25300 (epoch 31.464), train_loss = 0.88384507, grad/param norm = 2.3537e-01, time/batch = 0.6560s	
15922/25300 (epoch 31.466), train_loss = 0.83293293, grad/param norm = 2.2091e-01, time/batch = 0.6602s	
15923/25300 (epoch 31.468), train_loss = 0.84325976, grad/param norm = 2.5670e-01, time/batch = 0.6559s	
15924/25300 (epoch 31.470), train_loss = 0.76688238, grad/param norm = 1.8995e-01, time/batch = 0.6618s	
15925/25300 (epoch 31.472), train_loss = 0.68299800, grad/param norm = 2.1834e-01, time/batch = 0.6649s	
15926/25300 (epoch 31.474), train_loss = 0.83664868, grad/param norm = 2.0076e-01, time/batch = 0.6628s	
15927/25300 (epoch 31.476), train_loss = 0.76759451, grad/param norm = 2.2576e-01, time/batch = 0.6574s	
15928/25300 (epoch 31.478), train_loss = 0.87756700, grad/param norm = 2.3528e-01, time/batch = 0.6608s	
15929/25300 (epoch 31.480), train_loss = 0.75168990, grad/param norm = 1.9763e-01, time/batch = 0.6607s	
15930/25300 (epoch 31.482), train_loss = 0.80148512, grad/param norm = 2.2840e-01, time/batch = 0.6611s	
15931/25300 (epoch 31.484), train_loss = 0.87640577, grad/param norm = 2.6005e-01, time/batch = 0.6617s	
15932/25300 (epoch 31.486), train_loss = 0.79717009, grad/param norm = 2.3389e-01, time/batch = 0.6590s	
15933/25300 (epoch 31.488), train_loss = 0.94926079, grad/param norm = 2.2334e-01, time/batch = 0.6640s	
15934/25300 (epoch 31.490), train_loss = 0.83013121, grad/param norm = 2.1489e-01, time/batch = 0.6606s	
15935/25300 (epoch 31.492), train_loss = 0.91467307, grad/param norm = 2.1873e-01, time/batch = 0.6629s	
15936/25300 (epoch 31.494), train_loss = 0.77390518, grad/param norm = 1.9699e-01, time/batch = 0.6586s	
15937/25300 (epoch 31.496), train_loss = 0.83253174, grad/param norm = 2.3150e-01, time/batch = 0.6617s	
15938/25300 (epoch 31.498), train_loss = 0.78416902, grad/param norm = 1.9507e-01, time/batch = 0.6588s	
15939/25300 (epoch 31.500), train_loss = 0.96650997, grad/param norm = 2.5926e-01, time/batch = 0.6621s	
15940/25300 (epoch 31.502), train_loss = 0.87873288, grad/param norm = 2.5030e-01, time/batch = 0.6603s	
15941/25300 (epoch 31.504), train_loss = 0.78470629, grad/param norm = 2.0972e-01, time/batch = 0.6646s	
15942/25300 (epoch 31.506), train_loss = 0.72193698, grad/param norm = 3.0117e-01, time/batch = 0.6609s	
15943/25300 (epoch 31.508), train_loss = 0.78752277, grad/param norm = 2.2462e-01, time/batch = 0.6589s	
15944/25300 (epoch 31.510), train_loss = 0.74489012, grad/param norm = 2.1521e-01, time/batch = 0.6590s	
15945/25300 (epoch 31.512), train_loss = 0.60354600, grad/param norm = 1.8393e-01, time/batch = 0.6594s	
15946/25300 (epoch 31.514), train_loss = 0.77944040, grad/param norm = 2.1784e-01, time/batch = 0.6591s	
15947/25300 (epoch 31.516), train_loss = 0.85891801, grad/param norm = 2.2900e-01, time/batch = 0.6629s	
15948/25300 (epoch 31.518), train_loss = 0.90230621, grad/param norm = 2.7207e-01, time/batch = 0.6592s	
15949/25300 (epoch 31.520), train_loss = 0.66392572, grad/param norm = 1.6867e-01, time/batch = 0.6584s	
15950/25300 (epoch 31.522), train_loss = 0.73526359, grad/param norm = 2.1701e-01, time/batch = 0.6689s	
15951/25300 (epoch 31.524), train_loss = 0.73954075, grad/param norm = 2.0860e-01, time/batch = 0.6665s	
15952/25300 (epoch 31.526), train_loss = 0.91132172, grad/param norm = 2.3400e-01, time/batch = 0.6608s	
15953/25300 (epoch 31.528), train_loss = 0.92637502, grad/param norm = 2.2376e-01, time/batch = 0.6602s	
15954/25300 (epoch 31.530), train_loss = 0.85431767, grad/param norm = 2.6586e-01, time/batch = 0.6608s	
15955/25300 (epoch 31.532), train_loss = 0.78989064, grad/param norm = 2.2721e-01, time/batch = 0.6576s	
15956/25300 (epoch 31.534), train_loss = 0.76909242, grad/param norm = 2.5303e-01, time/batch = 0.6748s	
15957/25300 (epoch 31.536), train_loss = 0.64308579, grad/param norm = 2.3939e-01, time/batch = 0.6639s	
15958/25300 (epoch 31.538), train_loss = 0.69842380, grad/param norm = 1.8712e-01, time/batch = 0.6682s	
15959/25300 (epoch 31.540), train_loss = 0.69502240, grad/param norm = 1.9181e-01, time/batch = 0.6674s	
15960/25300 (epoch 31.542), train_loss = 0.68335682, grad/param norm = 1.8542e-01, time/batch = 0.6637s	
15961/25300 (epoch 31.543), train_loss = 0.64394417, grad/param norm = 1.8442e-01, time/batch = 0.6587s	
15962/25300 (epoch 31.545), train_loss = 1.00932698, grad/param norm = 2.9020e-01, time/batch = 0.6598s	
15963/25300 (epoch 31.547), train_loss = 0.87405005, grad/param norm = 2.4309e-01, time/batch = 0.6568s	
15964/25300 (epoch 31.549), train_loss = 1.00082915, grad/param norm = 2.8104e-01, time/batch = 0.6680s	
15965/25300 (epoch 31.551), train_loss = 0.90782582, grad/param norm = 2.0945e-01, time/batch = 0.6601s	
15966/25300 (epoch 31.553), train_loss = 0.72028544, grad/param norm = 2.1733e-01, time/batch = 0.6628s	
15967/25300 (epoch 31.555), train_loss = 0.87513978, grad/param norm = 2.4655e-01, time/batch = 0.6637s	
15968/25300 (epoch 31.557), train_loss = 0.87741700, grad/param norm = 2.4279e-01, time/batch = 0.6646s	
15969/25300 (epoch 31.559), train_loss = 0.92201580, grad/param norm = 2.2136e-01, time/batch = 0.6611s	
15970/25300 (epoch 31.561), train_loss = 0.93016928, grad/param norm = 2.4278e-01, time/batch = 0.6620s	
15971/25300 (epoch 31.563), train_loss = 0.88327833, grad/param norm = 2.2688e-01, time/batch = 0.6623s	
15972/25300 (epoch 31.565), train_loss = 0.69089140, grad/param norm = 2.0139e-01, time/batch = 0.6617s	
15973/25300 (epoch 31.567), train_loss = 0.64806273, grad/param norm = 2.2928e-01, time/batch = 0.6596s	
15974/25300 (epoch 31.569), train_loss = 0.83130716, grad/param norm = 2.1719e-01, time/batch = 0.6602s	
15975/25300 (epoch 31.571), train_loss = 0.87793582, grad/param norm = 2.1378e-01, time/batch = 0.6633s	
15976/25300 (epoch 31.573), train_loss = 0.78440624, grad/param norm = 1.9684e-01, time/batch = 0.6595s	
15977/25300 (epoch 31.575), train_loss = 0.87584067, grad/param norm = 2.3968e-01, time/batch = 0.6577s	
15978/25300 (epoch 31.577), train_loss = 0.77085552, grad/param norm = 2.4155e-01, time/batch = 0.6609s	
15979/25300 (epoch 31.579), train_loss = 0.91450562, grad/param norm = 2.3110e-01, time/batch = 0.6611s	
15980/25300 (epoch 31.581), train_loss = 0.86928365, grad/param norm = 2.3198e-01, time/batch = 0.6649s	
15981/25300 (epoch 31.583), train_loss = 0.67543069, grad/param norm = 2.0699e-01, time/batch = 0.6697s	
15982/25300 (epoch 31.585), train_loss = 0.68877215, grad/param norm = 2.0939e-01, time/batch = 0.6686s	
15983/25300 (epoch 31.587), train_loss = 0.79644175, grad/param norm = 2.0448e-01, time/batch = 0.6749s	
15984/25300 (epoch 31.589), train_loss = 0.69184618, grad/param norm = 1.6611e-01, time/batch = 0.6660s	
15985/25300 (epoch 31.591), train_loss = 0.67543145, grad/param norm = 2.4502e-01, time/batch = 0.6806s	
15986/25300 (epoch 31.593), train_loss = 0.86330590, grad/param norm = 2.3633e-01, time/batch = 0.6638s	
15987/25300 (epoch 31.595), train_loss = 0.79515972, grad/param norm = 2.0529e-01, time/batch = 0.6606s	
15988/25300 (epoch 31.597), train_loss = 0.69495135, grad/param norm = 1.8131e-01, time/batch = 0.6629s	
15989/25300 (epoch 31.599), train_loss = 0.87692584, grad/param norm = 2.2700e-01, time/batch = 0.6636s	
15990/25300 (epoch 31.601), train_loss = 0.79634437, grad/param norm = 2.3213e-01, time/batch = 0.6625s	
15991/25300 (epoch 31.603), train_loss = 0.80452217, grad/param norm = 2.1984e-01, time/batch = 0.6638s	
15992/25300 (epoch 31.605), train_loss = 0.79000867, grad/param norm = 3.8701e-01, time/batch = 0.6634s	
15993/25300 (epoch 31.607), train_loss = 0.58187321, grad/param norm = 1.8114e-01, time/batch = 0.6616s	
15994/25300 (epoch 31.609), train_loss = 0.74003530, grad/param norm = 2.0791e-01, time/batch = 0.6606s	
15995/25300 (epoch 31.611), train_loss = 0.83121109, grad/param norm = 2.5737e-01, time/batch = 0.6616s	
15996/25300 (epoch 31.613), train_loss = 0.69165296, grad/param norm = 1.8217e-01, time/batch = 0.6634s	
15997/25300 (epoch 31.615), train_loss = 0.77478774, grad/param norm = 2.5671e-01, time/batch = 0.6650s	
15998/25300 (epoch 31.617), train_loss = 0.82166159, grad/param norm = 2.5064e-01, time/batch = 0.6654s	
15999/25300 (epoch 31.619), train_loss = 0.86854328, grad/param norm = 2.3540e-01, time/batch = 0.6621s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch31.62_1.7126.t7	
16000/25300 (epoch 31.621), train_loss = 0.88671209, grad/param norm = 2.4044e-01, time/batch = 0.6603s	
16001/25300 (epoch 31.623), train_loss = 1.35149095, grad/param norm = 2.9941e-01, time/batch = 0.6704s	
16002/25300 (epoch 31.625), train_loss = 0.66466764, grad/param norm = 2.1690e-01, time/batch = 0.6634s	
16003/25300 (epoch 31.626), train_loss = 0.75928094, grad/param norm = 1.8769e-01, time/batch = 0.6630s	
16004/25300 (epoch 31.628), train_loss = 0.89039786, grad/param norm = 2.4259e-01, time/batch = 0.6647s	
16005/25300 (epoch 31.630), train_loss = 0.86265323, grad/param norm = 2.4590e-01, time/batch = 0.6632s	
16006/25300 (epoch 31.632), train_loss = 0.83860370, grad/param norm = 2.7844e-01, time/batch = 0.6598s	
16007/25300 (epoch 31.634), train_loss = 0.91894142, grad/param norm = 3.1448e-01, time/batch = 0.6596s	
16008/25300 (epoch 31.636), train_loss = 0.73075844, grad/param norm = 2.2250e-01, time/batch = 0.6714s	
16009/25300 (epoch 31.638), train_loss = 0.82940917, grad/param norm = 2.5809e-01, time/batch = 0.6698s	
16010/25300 (epoch 31.640), train_loss = 0.99642541, grad/param norm = 2.6726e-01, time/batch = 0.6660s	
16011/25300 (epoch 31.642), train_loss = 0.83124997, grad/param norm = 2.3766e-01, time/batch = 0.6597s	
16012/25300 (epoch 31.644), train_loss = 0.81652194, grad/param norm = 2.3628e-01, time/batch = 0.6631s	
16013/25300 (epoch 31.646), train_loss = 0.74562805, grad/param norm = 2.4420e-01, time/batch = 0.6639s	
16014/25300 (epoch 31.648), train_loss = 0.88451524, grad/param norm = 2.1019e-01, time/batch = 0.6635s	
16015/25300 (epoch 31.650), train_loss = 0.82139558, grad/param norm = 2.0835e-01, time/batch = 0.6593s	
16016/25300 (epoch 31.652), train_loss = 0.83648211, grad/param norm = 2.3053e-01, time/batch = 0.6644s	
16017/25300 (epoch 31.654), train_loss = 0.95293363, grad/param norm = 2.3361e-01, time/batch = 0.6633s	
16018/25300 (epoch 31.656), train_loss = 0.85725100, grad/param norm = 2.2466e-01, time/batch = 0.6630s	
16019/25300 (epoch 31.658), train_loss = 0.64459964, grad/param norm = 1.7426e-01, time/batch = 0.6609s	
16020/25300 (epoch 31.660), train_loss = 0.66760507, grad/param norm = 2.1562e-01, time/batch = 0.6599s	
16021/25300 (epoch 31.662), train_loss = 0.66696769, grad/param norm = 1.9826e-01, time/batch = 0.6601s	
16022/25300 (epoch 31.664), train_loss = 0.64650000, grad/param norm = 2.1630e-01, time/batch = 0.6608s	
16023/25300 (epoch 31.666), train_loss = 0.70325451, grad/param norm = 2.2345e-01, time/batch = 0.6622s	
16024/25300 (epoch 31.668), train_loss = 0.79517743, grad/param norm = 2.4892e-01, time/batch = 0.6630s	
16025/25300 (epoch 31.670), train_loss = 0.74302676, grad/param norm = 2.5278e-01, time/batch = 0.6585s	
16026/25300 (epoch 31.672), train_loss = 0.72212005, grad/param norm = 2.0312e-01, time/batch = 0.6622s	
16027/25300 (epoch 31.674), train_loss = 0.71778331, grad/param norm = 1.9402e-01, time/batch = 0.6609s	
16028/25300 (epoch 31.676), train_loss = 0.74722888, grad/param norm = 2.8953e-01, time/batch = 0.6623s	
16029/25300 (epoch 31.678), train_loss = 0.74666049, grad/param norm = 2.3086e-01, time/batch = 0.6577s	
16030/25300 (epoch 31.680), train_loss = 0.66478261, grad/param norm = 2.1133e-01, time/batch = 0.6605s	
16031/25300 (epoch 31.682), train_loss = 0.55890852, grad/param norm = 1.9182e-01, time/batch = 0.6617s	
16032/25300 (epoch 31.684), train_loss = 0.69747445, grad/param norm = 1.8378e-01, time/batch = 0.6572s	
16033/25300 (epoch 31.686), train_loss = 0.64702792, grad/param norm = 1.7117e-01, time/batch = 0.6604s	
16034/25300 (epoch 31.688), train_loss = 0.74922720, grad/param norm = 2.2608e-01, time/batch = 0.6582s	
16035/25300 (epoch 31.690), train_loss = 0.67740111, grad/param norm = 1.8218e-01, time/batch = 0.6589s	
16036/25300 (epoch 31.692), train_loss = 0.71286629, grad/param norm = 2.0894e-01, time/batch = 0.6560s	
16037/25300 (epoch 31.694), train_loss = 0.68020351, grad/param norm = 1.9832e-01, time/batch = 0.6555s	
16038/25300 (epoch 31.696), train_loss = 0.78646677, grad/param norm = 2.4327e-01, time/batch = 0.6581s	
16039/25300 (epoch 31.698), train_loss = 0.84726039, grad/param norm = 2.2838e-01, time/batch = 0.6565s	
16040/25300 (epoch 31.700), train_loss = 0.61497610, grad/param norm = 1.8170e-01, time/batch = 0.6546s	
16041/25300 (epoch 31.702), train_loss = 0.81590526, grad/param norm = 2.1068e-01, time/batch = 0.6590s	
16042/25300 (epoch 31.704), train_loss = 0.62165509, grad/param norm = 1.8367e-01, time/batch = 0.6635s	
16043/25300 (epoch 31.706), train_loss = 0.74304169, grad/param norm = 2.1110e-01, time/batch = 0.6620s	
16044/25300 (epoch 31.708), train_loss = 0.64697406, grad/param norm = 1.7664e-01, time/batch = 0.6615s	
16045/25300 (epoch 31.709), train_loss = 0.89081571, grad/param norm = 2.2484e-01, time/batch = 0.6600s	
16046/25300 (epoch 31.711), train_loss = 0.94929652, grad/param norm = 2.4076e-01, time/batch = 0.6651s	
16047/25300 (epoch 31.713), train_loss = 0.78380613, grad/param norm = 1.9014e-01, time/batch = 0.6578s	
16048/25300 (epoch 31.715), train_loss = 0.77879895, grad/param norm = 1.9787e-01, time/batch = 0.6607s	
16049/25300 (epoch 31.717), train_loss = 0.68054409, grad/param norm = 2.2068e-01, time/batch = 0.6580s	
16050/25300 (epoch 31.719), train_loss = 0.77927215, grad/param norm = 2.4004e-01, time/batch = 0.6590s	
16051/25300 (epoch 31.721), train_loss = 0.81057836, grad/param norm = 2.0795e-01, time/batch = 0.6635s	
16052/25300 (epoch 31.723), train_loss = 0.76927662, grad/param norm = 2.2733e-01, time/batch = 0.6641s	
16053/25300 (epoch 31.725), train_loss = 0.79526032, grad/param norm = 2.1249e-01, time/batch = 0.6634s	
16054/25300 (epoch 31.727), train_loss = 0.78627020, grad/param norm = 2.1017e-01, time/batch = 0.6621s	
16055/25300 (epoch 31.729), train_loss = 0.76696032, grad/param norm = 2.0351e-01, time/batch = 0.6607s	
16056/25300 (epoch 31.731), train_loss = 0.93093766, grad/param norm = 2.5760e-01, time/batch = 0.6580s	
16057/25300 (epoch 31.733), train_loss = 0.75887631, grad/param norm = 1.8751e-01, time/batch = 0.6583s	
16058/25300 (epoch 31.735), train_loss = 0.99415152, grad/param norm = 2.3790e-01, time/batch = 0.6599s	
16059/25300 (epoch 31.737), train_loss = 0.65925384, grad/param norm = 1.8358e-01, time/batch = 0.6581s	
16060/25300 (epoch 31.739), train_loss = 0.91156292, grad/param norm = 2.2454e-01, time/batch = 0.6568s	
16061/25300 (epoch 31.741), train_loss = 0.83518898, grad/param norm = 2.4201e-01, time/batch = 0.6633s	
16062/25300 (epoch 31.743), train_loss = 0.78112460, grad/param norm = 2.0509e-01, time/batch = 0.6667s	
16063/25300 (epoch 31.745), train_loss = 0.75236031, grad/param norm = 2.1855e-01, time/batch = 0.6675s	
16064/25300 (epoch 31.747), train_loss = 0.67771788, grad/param norm = 1.8135e-01, time/batch = 0.6637s	
16065/25300 (epoch 31.749), train_loss = 0.79568439, grad/param norm = 2.2314e-01, time/batch = 0.6608s	
16066/25300 (epoch 31.751), train_loss = 0.83438780, grad/param norm = 2.2831e-01, time/batch = 0.6787s	
16067/25300 (epoch 31.753), train_loss = 0.67320278, grad/param norm = 1.9877e-01, time/batch = 0.6614s	
16068/25300 (epoch 31.755), train_loss = 0.88473192, grad/param norm = 2.4416e-01, time/batch = 0.6824s	
16069/25300 (epoch 31.757), train_loss = 0.73767924, grad/param norm = 2.1968e-01, time/batch = 0.6667s	
16070/25300 (epoch 31.759), train_loss = 0.70932196, grad/param norm = 2.0995e-01, time/batch = 0.6696s	
16071/25300 (epoch 31.761), train_loss = 0.93724370, grad/param norm = 2.4436e-01, time/batch = 0.6593s	
16072/25300 (epoch 31.763), train_loss = 0.76915589, grad/param norm = 2.1921e-01, time/batch = 0.6592s	
16073/25300 (epoch 31.765), train_loss = 0.75108548, grad/param norm = 2.0141e-01, time/batch = 0.6594s	
16074/25300 (epoch 31.767), train_loss = 0.76487896, grad/param norm = 1.9304e-01, time/batch = 0.6610s	
16075/25300 (epoch 31.769), train_loss = 0.78043317, grad/param norm = 2.6514e-01, time/batch = 0.6592s	
16076/25300 (epoch 31.771), train_loss = 0.87960890, grad/param norm = 2.3365e-01, time/batch = 0.6585s	
16077/25300 (epoch 31.773), train_loss = 0.90969815, grad/param norm = 2.5790e-01, time/batch = 0.6643s	
16078/25300 (epoch 31.775), train_loss = 0.79727773, grad/param norm = 1.9420e-01, time/batch = 0.6634s	
16079/25300 (epoch 31.777), train_loss = 0.75792691, grad/param norm = 2.1298e-01, time/batch = 0.6631s	
16080/25300 (epoch 31.779), train_loss = 0.88918208, grad/param norm = 2.5620e-01, time/batch = 0.6597s	
16081/25300 (epoch 31.781), train_loss = 0.84796127, grad/param norm = 2.1837e-01, time/batch = 0.6612s	
16082/25300 (epoch 31.783), train_loss = 0.92450773, grad/param norm = 2.3211e-01, time/batch = 0.6628s	
16083/25300 (epoch 31.785), train_loss = 0.85599717, grad/param norm = 2.3078e-01, time/batch = 0.6611s	
16084/25300 (epoch 31.787), train_loss = 0.85647609, grad/param norm = 3.1820e-01, time/batch = 0.6570s	
16085/25300 (epoch 31.789), train_loss = 0.95642614, grad/param norm = 2.5646e-01, time/batch = 0.6594s	
16086/25300 (epoch 31.791), train_loss = 0.83510953, grad/param norm = 2.1237e-01, time/batch = 0.6794s	
16087/25300 (epoch 31.792), train_loss = 0.91227316, grad/param norm = 2.1997e-01, time/batch = 0.6645s	
16088/25300 (epoch 31.794), train_loss = 0.78770862, grad/param norm = 2.2462e-01, time/batch = 0.6674s	
16089/25300 (epoch 31.796), train_loss = 0.76781349, grad/param norm = 2.2195e-01, time/batch = 0.6640s	
16090/25300 (epoch 31.798), train_loss = 0.90881911, grad/param norm = 4.0537e-01, time/batch = 0.6600s	
16091/25300 (epoch 31.800), train_loss = 0.76694851, grad/param norm = 2.0875e-01, time/batch = 0.6705s	
16092/25300 (epoch 31.802), train_loss = 0.65028056, grad/param norm = 1.9486e-01, time/batch = 0.6596s	
16093/25300 (epoch 31.804), train_loss = 0.81283922, grad/param norm = 2.0112e-01, time/batch = 0.6567s	
16094/25300 (epoch 31.806), train_loss = 0.86034564, grad/param norm = 2.7055e-01, time/batch = 0.6602s	
16095/25300 (epoch 31.808), train_loss = 0.91135486, grad/param norm = 2.5256e-01, time/batch = 0.6611s	
16096/25300 (epoch 31.810), train_loss = 0.79607150, grad/param norm = 2.6233e-01, time/batch = 0.6612s	
16097/25300 (epoch 31.812), train_loss = 0.91452917, grad/param norm = 2.2712e-01, time/batch = 0.6646s	
16098/25300 (epoch 31.814), train_loss = 0.94963226, grad/param norm = 2.7258e-01, time/batch = 0.6622s	
16099/25300 (epoch 31.816), train_loss = 1.01918718, grad/param norm = 2.3745e-01, time/batch = 0.6630s	
16100/25300 (epoch 31.818), train_loss = 0.87190363, grad/param norm = 1.9964e-01, time/batch = 0.6610s	
16101/25300 (epoch 31.820), train_loss = 0.89868035, grad/param norm = 2.1270e-01, time/batch = 0.6635s	
16102/25300 (epoch 31.822), train_loss = 0.76340459, grad/param norm = 2.2399e-01, time/batch = 0.6626s	
16103/25300 (epoch 31.824), train_loss = 0.91483094, grad/param norm = 2.4240e-01, time/batch = 0.6604s	
16104/25300 (epoch 31.826), train_loss = 0.72811273, grad/param norm = 1.7928e-01, time/batch = 0.6593s	
16105/25300 (epoch 31.828), train_loss = 0.73626556, grad/param norm = 2.1270e-01, time/batch = 0.6600s	
16106/25300 (epoch 31.830), train_loss = 0.83550699, grad/param norm = 2.0149e-01, time/batch = 0.6590s	
16107/25300 (epoch 31.832), train_loss = 0.90994565, grad/param norm = 2.3334e-01, time/batch = 0.6586s	
16108/25300 (epoch 31.834), train_loss = 0.76182817, grad/param norm = 2.0988e-01, time/batch = 0.6630s	
16109/25300 (epoch 31.836), train_loss = 0.80866279, grad/param norm = 2.3174e-01, time/batch = 0.6650s	
16110/25300 (epoch 31.838), train_loss = 0.76862965, grad/param norm = 1.9801e-01, time/batch = 0.6608s	
16111/25300 (epoch 31.840), train_loss = 0.85366609, grad/param norm = 2.1797e-01, time/batch = 0.6614s	
16112/25300 (epoch 31.842), train_loss = 0.83413390, grad/param norm = 2.2392e-01, time/batch = 0.6592s	
16113/25300 (epoch 31.844), train_loss = 0.89211189, grad/param norm = 1.9177e-01, time/batch = 0.6620s	
16114/25300 (epoch 31.846), train_loss = 0.88164313, grad/param norm = 2.1051e-01, time/batch = 0.6628s	
16115/25300 (epoch 31.848), train_loss = 0.87459464, grad/param norm = 2.3643e-01, time/batch = 0.6690s	
16116/25300 (epoch 31.850), train_loss = 0.82555982, grad/param norm = 2.1101e-01, time/batch = 0.6688s	
16117/25300 (epoch 31.852), train_loss = 0.88421492, grad/param norm = 2.1247e-01, time/batch = 0.6685s	
16118/25300 (epoch 31.854), train_loss = 0.92406507, grad/param norm = 2.1488e-01, time/batch = 0.6686s	
16119/25300 (epoch 31.856), train_loss = 0.77517205, grad/param norm = 1.9940e-01, time/batch = 0.6680s	
16120/25300 (epoch 31.858), train_loss = 0.81217155, grad/param norm = 2.3245e-01, time/batch = 0.6681s	
16121/25300 (epoch 31.860), train_loss = 0.68597567, grad/param norm = 1.9690e-01, time/batch = 0.6679s	
16122/25300 (epoch 31.862), train_loss = 0.80980045, grad/param norm = 2.2106e-01, time/batch = 0.6659s	
16123/25300 (epoch 31.864), train_loss = 0.90700583, grad/param norm = 2.2240e-01, time/batch = 0.6673s	
16124/25300 (epoch 31.866), train_loss = 0.77238052, grad/param norm = 2.2566e-01, time/batch = 0.6656s	
16125/25300 (epoch 31.868), train_loss = 0.92174663, grad/param norm = 2.1484e-01, time/batch = 0.6605s	
16126/25300 (epoch 31.870), train_loss = 0.90402802, grad/param norm = 2.0930e-01, time/batch = 0.6672s	
16127/25300 (epoch 31.872), train_loss = 0.83811749, grad/param norm = 2.3148e-01, time/batch = 0.6678s	
16128/25300 (epoch 31.874), train_loss = 0.84657691, grad/param norm = 2.2543e-01, time/batch = 0.6686s	
16129/25300 (epoch 31.875), train_loss = 0.79144072, grad/param norm = 2.2828e-01, time/batch = 0.6710s	
16130/25300 (epoch 31.877), train_loss = 0.79347296, grad/param norm = 2.0200e-01, time/batch = 0.6670s	
16131/25300 (epoch 31.879), train_loss = 0.74180167, grad/param norm = 2.3393e-01, time/batch = 0.6689s	
16132/25300 (epoch 31.881), train_loss = 1.08629803, grad/param norm = 2.9315e-01, time/batch = 0.6610s	
16133/25300 (epoch 31.883), train_loss = 1.02792887, grad/param norm = 2.2949e-01, time/batch = 0.6607s	
16134/25300 (epoch 31.885), train_loss = 0.87255875, grad/param norm = 2.4121e-01, time/batch = 0.6588s	
16135/25300 (epoch 31.887), train_loss = 0.91122624, grad/param norm = 2.2638e-01, time/batch = 0.6595s	
16136/25300 (epoch 31.889), train_loss = 0.98340287, grad/param norm = 2.4601e-01, time/batch = 0.6607s	
16137/25300 (epoch 31.891), train_loss = 0.89671904, grad/param norm = 2.8152e-01, time/batch = 0.6577s	
16138/25300 (epoch 31.893), train_loss = 0.85843403, grad/param norm = 2.6382e-01, time/batch = 0.6595s	
16139/25300 (epoch 31.895), train_loss = 0.64007258, grad/param norm = 1.8651e-01, time/batch = 0.6673s	
16140/25300 (epoch 31.897), train_loss = 0.72955366, grad/param norm = 1.9591e-01, time/batch = 0.6645s	
16141/25300 (epoch 31.899), train_loss = 0.84067969, grad/param norm = 2.1388e-01, time/batch = 0.6634s	
16142/25300 (epoch 31.901), train_loss = 0.87086097, grad/param norm = 2.3147e-01, time/batch = 0.6541s	
16143/25300 (epoch 31.903), train_loss = 0.67456556, grad/param norm = 1.9983e-01, time/batch = 0.6600s	
16144/25300 (epoch 31.905), train_loss = 0.78607532, grad/param norm = 2.3351e-01, time/batch = 0.6606s	
16145/25300 (epoch 31.907), train_loss = 0.76261909, grad/param norm = 2.2732e-01, time/batch = 0.6584s	
16146/25300 (epoch 31.909), train_loss = 0.87689031, grad/param norm = 2.1798e-01, time/batch = 0.6568s	
16147/25300 (epoch 31.911), train_loss = 0.91488549, grad/param norm = 2.3850e-01, time/batch = 0.6614s	
16148/25300 (epoch 31.913), train_loss = 1.02120866, grad/param norm = 2.5836e-01, time/batch = 0.6572s	
16149/25300 (epoch 31.915), train_loss = 0.77100363, grad/param norm = 2.3345e-01, time/batch = 0.6613s	
16150/25300 (epoch 31.917), train_loss = 0.96981778, grad/param norm = 2.3393e-01, time/batch = 0.6568s	
16151/25300 (epoch 31.919), train_loss = 0.95284633, grad/param norm = 3.1198e-01, time/batch = 0.6643s	
16152/25300 (epoch 31.921), train_loss = 0.76555705, grad/param norm = 2.0890e-01, time/batch = 0.6571s	
16153/25300 (epoch 31.923), train_loss = 0.91248018, grad/param norm = 2.2270e-01, time/batch = 0.6654s	
16154/25300 (epoch 31.925), train_loss = 0.82154791, grad/param norm = 2.4657e-01, time/batch = 0.6647s	
16155/25300 (epoch 31.927), train_loss = 0.81223462, grad/param norm = 2.3095e-01, time/batch = 0.6652s	
16156/25300 (epoch 31.929), train_loss = 0.85411904, grad/param norm = 2.3121e-01, time/batch = 0.6569s	
16157/25300 (epoch 31.931), train_loss = 0.89508176, grad/param norm = 2.2881e-01, time/batch = 0.6543s	
16158/25300 (epoch 31.933), train_loss = 0.85314118, grad/param norm = 2.1914e-01, time/batch = 0.6588s	
16159/25300 (epoch 31.935), train_loss = 0.86823368, grad/param norm = 1.9880e-01, time/batch = 0.6574s	
16160/25300 (epoch 31.937), train_loss = 0.65112277, grad/param norm = 1.8320e-01, time/batch = 0.6596s	
16161/25300 (epoch 31.939), train_loss = 0.85565385, grad/param norm = 2.2207e-01, time/batch = 0.6561s	
16162/25300 (epoch 31.941), train_loss = 0.77181917, grad/param norm = 2.4377e-01, time/batch = 0.6575s	
16163/25300 (epoch 31.943), train_loss = 0.84653804, grad/param norm = 2.0264e-01, time/batch = 0.6588s	
16164/25300 (epoch 31.945), train_loss = 0.85299880, grad/param norm = 2.4054e-01, time/batch = 0.6566s	
16165/25300 (epoch 31.947), train_loss = 0.74390216, grad/param norm = 2.0995e-01, time/batch = 0.6601s	
16166/25300 (epoch 31.949), train_loss = 0.87402399, grad/param norm = 1.9661e-01, time/batch = 0.6538s	
16167/25300 (epoch 31.951), train_loss = 0.82119203, grad/param norm = 2.0458e-01, time/batch = 0.6546s	
16168/25300 (epoch 31.953), train_loss = 0.80543585, grad/param norm = 2.6349e-01, time/batch = 0.6780s	
16169/25300 (epoch 31.955), train_loss = 1.04906142, grad/param norm = 2.8935e-01, time/batch = 0.6654s	
16170/25300 (epoch 31.957), train_loss = 0.94221494, grad/param norm = 2.5723e-01, time/batch = 0.6641s	
16171/25300 (epoch 31.958), train_loss = 0.90986746, grad/param norm = 3.0904e-01, time/batch = 0.6623s	
16172/25300 (epoch 31.960), train_loss = 1.01894349, grad/param norm = 2.6618e-01, time/batch = 0.6585s	
16173/25300 (epoch 31.962), train_loss = 0.95927332, grad/param norm = 2.2222e-01, time/batch = 0.6562s	
16174/25300 (epoch 31.964), train_loss = 0.88973480, grad/param norm = 3.2638e-01, time/batch = 0.6585s	
16175/25300 (epoch 31.966), train_loss = 0.73546336, grad/param norm = 2.1656e-01, time/batch = 0.6595s	
16176/25300 (epoch 31.968), train_loss = 0.71929621, grad/param norm = 2.0430e-01, time/batch = 0.6643s	
16177/25300 (epoch 31.970), train_loss = 0.80392953, grad/param norm = 2.6904e-01, time/batch = 0.6563s	
16178/25300 (epoch 31.972), train_loss = 0.81932900, grad/param norm = 2.1589e-01, time/batch = 0.6598s	
16179/25300 (epoch 31.974), train_loss = 0.95028839, grad/param norm = 2.6187e-01, time/batch = 0.6628s	
16180/25300 (epoch 31.976), train_loss = 0.87343720, grad/param norm = 2.4327e-01, time/batch = 0.6577s	
16181/25300 (epoch 31.978), train_loss = 0.80376711, grad/param norm = 2.2195e-01, time/batch = 0.6623s	
16182/25300 (epoch 31.980), train_loss = 0.84028235, grad/param norm = 2.4794e-01, time/batch = 0.6634s	
16183/25300 (epoch 31.982), train_loss = 0.78781866, grad/param norm = 2.1135e-01, time/batch = 0.6630s	
16184/25300 (epoch 31.984), train_loss = 0.80731370, grad/param norm = 2.1722e-01, time/batch = 0.6599s	
16185/25300 (epoch 31.986), train_loss = 0.91032454, grad/param norm = 2.3532e-01, time/batch = 0.6606s	
16186/25300 (epoch 31.988), train_loss = 0.85402325, grad/param norm = 2.3057e-01, time/batch = 0.6618s	
16187/25300 (epoch 31.990), train_loss = 0.83103210, grad/param norm = 2.0219e-01, time/batch = 0.6606s	
16188/25300 (epoch 31.992), train_loss = 0.73497369, grad/param norm = 2.0328e-01, time/batch = 0.6655s	
16189/25300 (epoch 31.994), train_loss = 0.84610495, grad/param norm = 2.2292e-01, time/batch = 0.6607s	
16190/25300 (epoch 31.996), train_loss = 0.96439056, grad/param norm = 2.8216e-01, time/batch = 0.6611s	
16191/25300 (epoch 31.998), train_loss = 0.91441577, grad/param norm = 2.4405e-01, time/batch = 0.6605s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
16192/25300 (epoch 32.000), train_loss = 0.89698474, grad/param norm = 2.5053e-01, time/batch = 0.6612s	
16193/25300 (epoch 32.002), train_loss = 0.80700271, grad/param norm = 2.1753e-01, time/batch = 0.6623s	
16194/25300 (epoch 32.004), train_loss = 0.70249130, grad/param norm = 2.1800e-01, time/batch = 0.6591s	
16195/25300 (epoch 32.006), train_loss = 0.98816854, grad/param norm = 2.4179e-01, time/batch = 0.6601s	
16196/25300 (epoch 32.008), train_loss = 0.82770533, grad/param norm = 1.9532e-01, time/batch = 0.6588s	
16197/25300 (epoch 32.010), train_loss = 0.85859751, grad/param norm = 2.0652e-01, time/batch = 0.6596s	
16198/25300 (epoch 32.012), train_loss = 0.78941206, grad/param norm = 2.0702e-01, time/batch = 0.6627s	
16199/25300 (epoch 32.014), train_loss = 0.96497217, grad/param norm = 2.8226e-01, time/batch = 0.6612s	
16200/25300 (epoch 32.016), train_loss = 0.85157718, grad/param norm = 2.7490e-01, time/batch = 0.6606s	
16201/25300 (epoch 32.018), train_loss = 0.74227229, grad/param norm = 1.9139e-01, time/batch = 0.6657s	
16202/25300 (epoch 32.020), train_loss = 0.84632896, grad/param norm = 2.1776e-01, time/batch = 0.6630s	
16203/25300 (epoch 32.022), train_loss = 0.83794365, grad/param norm = 2.5643e-01, time/batch = 0.6586s	
16204/25300 (epoch 32.024), train_loss = 0.62050060, grad/param norm = 1.5831e-01, time/batch = 0.6753s	
16205/25300 (epoch 32.026), train_loss = 0.79899729, grad/param norm = 2.2914e-01, time/batch = 0.6673s	
16206/25300 (epoch 32.028), train_loss = 0.78183407, grad/param norm = 2.1006e-01, time/batch = 0.6668s	
16207/25300 (epoch 32.030), train_loss = 0.92982678, grad/param norm = 2.0361e-01, time/batch = 0.6627s	
16208/25300 (epoch 32.032), train_loss = 0.80231298, grad/param norm = 2.1062e-01, time/batch = 0.6605s	
16209/25300 (epoch 32.034), train_loss = 0.71963754, grad/param norm = 2.0465e-01, time/batch = 0.6646s	
16210/25300 (epoch 32.036), train_loss = 0.67429438, grad/param norm = 2.0373e-01, time/batch = 0.6624s	
16211/25300 (epoch 32.038), train_loss = 0.64017502, grad/param norm = 1.8929e-01, time/batch = 0.6574s	
16212/25300 (epoch 32.040), train_loss = 0.82351666, grad/param norm = 1.9926e-01, time/batch = 0.6595s	
16213/25300 (epoch 32.042), train_loss = 0.82237127, grad/param norm = 1.9543e-01, time/batch = 0.6652s	
16214/25300 (epoch 32.043), train_loss = 0.69596121, grad/param norm = 1.7826e-01, time/batch = 0.6635s	
16215/25300 (epoch 32.045), train_loss = 0.69178895, grad/param norm = 1.9403e-01, time/batch = 0.6609s	
16216/25300 (epoch 32.047), train_loss = 0.83249012, grad/param norm = 1.9364e-01, time/batch = 0.6591s	
16217/25300 (epoch 32.049), train_loss = 0.83934672, grad/param norm = 2.7303e-01, time/batch = 0.6587s	
16218/25300 (epoch 32.051), train_loss = 0.94075804, grad/param norm = 2.2185e-01, time/batch = 0.6572s	
16219/25300 (epoch 32.053), train_loss = 0.63766266, grad/param norm = 1.5702e-01, time/batch = 0.6596s	
16220/25300 (epoch 32.055), train_loss = 0.68543213, grad/param norm = 1.8507e-01, time/batch = 0.6548s	
16221/25300 (epoch 32.057), train_loss = 0.67350784, grad/param norm = 1.7673e-01, time/batch = 0.6683s	
16222/25300 (epoch 32.059), train_loss = 0.75901271, grad/param norm = 2.0783e-01, time/batch = 0.6683s	
16223/25300 (epoch 32.061), train_loss = 0.75067315, grad/param norm = 2.0981e-01, time/batch = 0.6671s	
16224/25300 (epoch 32.063), train_loss = 0.74428266, grad/param norm = 1.9420e-01, time/batch = 0.6682s	
16225/25300 (epoch 32.065), train_loss = 0.81882772, grad/param norm = 2.3047e-01, time/batch = 0.6690s	
16226/25300 (epoch 32.067), train_loss = 0.89068586, grad/param norm = 2.0344e-01, time/batch = 0.6674s	
16227/25300 (epoch 32.069), train_loss = 0.71433946, grad/param norm = 2.0867e-01, time/batch = 0.6708s	
16228/25300 (epoch 32.071), train_loss = 0.84989588, grad/param norm = 2.1354e-01, time/batch = 0.6665s	
16229/25300 (epoch 32.073), train_loss = 0.77145811, grad/param norm = 1.8320e-01, time/batch = 0.6600s	
16230/25300 (epoch 32.075), train_loss = 0.87334146, grad/param norm = 2.1866e-01, time/batch = 0.6601s	
16231/25300 (epoch 32.077), train_loss = 0.84647787, grad/param norm = 2.1887e-01, time/batch = 0.6628s	
16232/25300 (epoch 32.079), train_loss = 0.73672050, grad/param norm = 2.0161e-01, time/batch = 0.6654s	
16233/25300 (epoch 32.081), train_loss = 0.81078054, grad/param norm = 1.7540e-01, time/batch = 0.6621s	
16234/25300 (epoch 32.083), train_loss = 0.82459025, grad/param norm = 1.8514e-01, time/batch = 0.6599s	
16235/25300 (epoch 32.085), train_loss = 0.99422452, grad/param norm = 2.4690e-01, time/batch = 0.6635s	
16236/25300 (epoch 32.087), train_loss = 0.89604786, grad/param norm = 1.9277e-01, time/batch = 0.6582s	
16237/25300 (epoch 32.089), train_loss = 0.87045476, grad/param norm = 2.0109e-01, time/batch = 0.6632s	
16238/25300 (epoch 32.091), train_loss = 0.98444616, grad/param norm = 2.7754e-01, time/batch = 0.6618s	
16239/25300 (epoch 32.093), train_loss = 0.92816622, grad/param norm = 2.4061e-01, time/batch = 0.6600s	
16240/25300 (epoch 32.095), train_loss = 0.89810321, grad/param norm = 2.1217e-01, time/batch = 0.6592s	
16241/25300 (epoch 32.097), train_loss = 0.87505290, grad/param norm = 2.2087e-01, time/batch = 0.6635s	
16242/25300 (epoch 32.099), train_loss = 0.87006430, grad/param norm = 2.5284e-01, time/batch = 0.6604s	
16243/25300 (epoch 32.101), train_loss = 0.80578721, grad/param norm = 2.1220e-01, time/batch = 0.6632s	
16244/25300 (epoch 32.103), train_loss = 0.84016453, grad/param norm = 2.1790e-01, time/batch = 0.6694s	
16245/25300 (epoch 32.105), train_loss = 0.87845254, grad/param norm = 2.1170e-01, time/batch = 0.6687s	
16246/25300 (epoch 32.107), train_loss = 0.91834632, grad/param norm = 2.8584e-01, time/batch = 0.6696s	
16247/25300 (epoch 32.109), train_loss = 0.80660901, grad/param norm = 2.2717e-01, time/batch = 0.6596s	
16248/25300 (epoch 32.111), train_loss = 0.81348357, grad/param norm = 2.0838e-01, time/batch = 0.6571s	
16249/25300 (epoch 32.113), train_loss = 0.75775066, grad/param norm = 2.1336e-01, time/batch = 0.6637s	
16250/25300 (epoch 32.115), train_loss = 0.80022447, grad/param norm = 2.4275e-01, time/batch = 0.6589s	
16251/25300 (epoch 32.117), train_loss = 0.90910915, grad/param norm = 2.2186e-01, time/batch = 0.6708s	
16252/25300 (epoch 32.119), train_loss = 0.77548425, grad/param norm = 2.2046e-01, time/batch = 0.6682s	
16253/25300 (epoch 32.121), train_loss = 0.84177543, grad/param norm = 2.5496e-01, time/batch = 0.6621s	
16254/25300 (epoch 32.123), train_loss = 0.75711845, grad/param norm = 2.1720e-01, time/batch = 0.6614s	
16255/25300 (epoch 32.125), train_loss = 0.89797433, grad/param norm = 2.0136e-01, time/batch = 0.6812s	
16256/25300 (epoch 32.126), train_loss = 0.82838026, grad/param norm = 2.0072e-01, time/batch = 0.6692s	
16257/25300 (epoch 32.128), train_loss = 0.80298527, grad/param norm = 2.0483e-01, time/batch = 0.6571s	
16258/25300 (epoch 32.130), train_loss = 0.65621782, grad/param norm = 1.8772e-01, time/batch = 0.6631s	
16259/25300 (epoch 32.132), train_loss = 0.68146282, grad/param norm = 1.9820e-01, time/batch = 0.6596s	
16260/25300 (epoch 32.134), train_loss = 0.68417130, grad/param norm = 1.8164e-01, time/batch = 0.6628s	
16261/25300 (epoch 32.136), train_loss = 0.80638591, grad/param norm = 2.0126e-01, time/batch = 0.6644s	
16262/25300 (epoch 32.138), train_loss = 0.71456441, grad/param norm = 1.8482e-01, time/batch = 0.6644s	
16263/25300 (epoch 32.140), train_loss = 0.70731698, grad/param norm = 2.1125e-01, time/batch = 0.6578s	
16264/25300 (epoch 32.142), train_loss = 0.89432059, grad/param norm = 2.1987e-01, time/batch = 0.6616s	
16265/25300 (epoch 32.144), train_loss = 0.88768771, grad/param norm = 2.3884e-01, time/batch = 0.6629s	
16266/25300 (epoch 32.146), train_loss = 0.80810749, grad/param norm = 2.6010e-01, time/batch = 0.6596s	
16267/25300 (epoch 32.148), train_loss = 0.79569258, grad/param norm = 1.8768e-01, time/batch = 0.6569s	
16268/25300 (epoch 32.150), train_loss = 0.84000769, grad/param norm = 2.1557e-01, time/batch = 0.6576s	
16269/25300 (epoch 32.152), train_loss = 0.95599878, grad/param norm = 2.6918e-01, time/batch = 0.6546s	
16270/25300 (epoch 32.154), train_loss = 0.69854433, grad/param norm = 1.8826e-01, time/batch = 0.6545s	
16271/25300 (epoch 32.156), train_loss = 0.85200289, grad/param norm = 2.3474e-01, time/batch = 0.6571s	
16272/25300 (epoch 32.158), train_loss = 0.70154222, grad/param norm = 2.0283e-01, time/batch = 0.6585s	
16273/25300 (epoch 32.160), train_loss = 0.83375289, grad/param norm = 2.2032e-01, time/batch = 0.6607s	
16274/25300 (epoch 32.162), train_loss = 0.75643908, grad/param norm = 2.4568e-01, time/batch = 0.6574s	
16275/25300 (epoch 32.164), train_loss = 0.86535445, grad/param norm = 2.5115e-01, time/batch = 0.6604s	
16276/25300 (epoch 32.166), train_loss = 0.83341912, grad/param norm = 2.1626e-01, time/batch = 0.6589s	
16277/25300 (epoch 32.168), train_loss = 0.73596330, grad/param norm = 1.8310e-01, time/batch = 0.6591s	
16278/25300 (epoch 32.170), train_loss = 0.75980039, grad/param norm = 2.2005e-01, time/batch = 0.6569s	
16279/25300 (epoch 32.172), train_loss = 0.69446128, grad/param norm = 1.8600e-01, time/batch = 0.6597s	
16280/25300 (epoch 32.174), train_loss = 0.73780405, grad/param norm = 1.9951e-01, time/batch = 0.6558s	
16281/25300 (epoch 32.176), train_loss = 0.73186041, grad/param norm = 2.6797e-01, time/batch = 0.6604s	
16282/25300 (epoch 32.178), train_loss = 0.92693660, grad/param norm = 2.0164e-01, time/batch = 0.6629s	
16283/25300 (epoch 32.180), train_loss = 0.66053763, grad/param norm = 2.0016e-01, time/batch = 0.6615s	
16284/25300 (epoch 32.182), train_loss = 0.74836220, grad/param norm = 2.1802e-01, time/batch = 0.6616s	
16285/25300 (epoch 32.184), train_loss = 0.72021921, grad/param norm = 2.0575e-01, time/batch = 0.6580s	
16286/25300 (epoch 32.186), train_loss = 0.69006341, grad/param norm = 2.1412e-01, time/batch = 0.6618s	
16287/25300 (epoch 32.188), train_loss = 0.81025610, grad/param norm = 2.5140e-01, time/batch = 0.6661s	
16288/25300 (epoch 32.190), train_loss = 0.77609590, grad/param norm = 1.9286e-01, time/batch = 0.6653s	
16289/25300 (epoch 32.192), train_loss = 0.77228146, grad/param norm = 2.2209e-01, time/batch = 0.6647s	
16290/25300 (epoch 32.194), train_loss = 0.76327261, grad/param norm = 1.9630e-01, time/batch = 0.6603s	
16291/25300 (epoch 32.196), train_loss = 0.90018833, grad/param norm = 2.4671e-01, time/batch = 0.6644s	
16292/25300 (epoch 32.198), train_loss = 0.74568031, grad/param norm = 2.2430e-01, time/batch = 0.6607s	
16293/25300 (epoch 32.200), train_loss = 0.78302013, grad/param norm = 2.3654e-01, time/batch = 0.6606s	
16294/25300 (epoch 32.202), train_loss = 0.79905271, grad/param norm = 2.1071e-01, time/batch = 0.6571s	
16295/25300 (epoch 32.204), train_loss = 0.78296102, grad/param norm = 2.0094e-01, time/batch = 0.6625s	
16296/25300 (epoch 32.206), train_loss = 0.89684900, grad/param norm = 2.2524e-01, time/batch = 0.6557s	
16297/25300 (epoch 32.208), train_loss = 0.70920787, grad/param norm = 2.2010e-01, time/batch = 0.6559s	
16298/25300 (epoch 32.209), train_loss = 0.68431413, grad/param norm = 1.8575e-01, time/batch = 0.6570s	
16299/25300 (epoch 32.211), train_loss = 0.76047283, grad/param norm = 2.0171e-01, time/batch = 0.6532s	
16300/25300 (epoch 32.213), train_loss = 0.82125150, grad/param norm = 2.2742e-01, time/batch = 0.6589s	
16301/25300 (epoch 32.215), train_loss = 0.83140398, grad/param norm = 2.2706e-01, time/batch = 0.6585s	
16302/25300 (epoch 32.217), train_loss = 0.83707177, grad/param norm = 2.2650e-01, time/batch = 0.6588s	
16303/25300 (epoch 32.219), train_loss = 0.88798858, grad/param norm = 2.4658e-01, time/batch = 0.6530s	
16304/25300 (epoch 32.221), train_loss = 0.93360379, grad/param norm = 2.4047e-01, time/batch = 0.6570s	
16305/25300 (epoch 32.223), train_loss = 0.86515068, grad/param norm = 2.1522e-01, time/batch = 0.6622s	
16306/25300 (epoch 32.225), train_loss = 1.09742273, grad/param norm = 3.2771e-01, time/batch = 0.6575s	
16307/25300 (epoch 32.227), train_loss = 0.94563318, grad/param norm = 2.5155e-01, time/batch = 0.6616s	
16308/25300 (epoch 32.229), train_loss = 0.79001463, grad/param norm = 2.1393e-01, time/batch = 0.6587s	
16309/25300 (epoch 32.231), train_loss = 0.82758428, grad/param norm = 2.4267e-01, time/batch = 0.6599s	
16310/25300 (epoch 32.233), train_loss = 0.86711292, grad/param norm = 2.4496e-01, time/batch = 0.6614s	
16311/25300 (epoch 32.235), train_loss = 0.80862114, grad/param norm = 2.2179e-01, time/batch = 0.6637s	
16312/25300 (epoch 32.237), train_loss = 0.94119071, grad/param norm = 2.5535e-01, time/batch = 0.6615s	
16313/25300 (epoch 32.239), train_loss = 0.78443627, grad/param norm = 2.5190e-01, time/batch = 0.6606s	
16314/25300 (epoch 32.241), train_loss = 0.94092929, grad/param norm = 2.1807e-01, time/batch = 0.6595s	
16315/25300 (epoch 32.243), train_loss = 1.07386879, grad/param norm = 2.8483e-01, time/batch = 0.6555s	
16316/25300 (epoch 32.245), train_loss = 0.77287558, grad/param norm = 2.1720e-01, time/batch = 0.6608s	
16317/25300 (epoch 32.247), train_loss = 0.87550417, grad/param norm = 2.2317e-01, time/batch = 0.6617s	
16318/25300 (epoch 32.249), train_loss = 0.71532902, grad/param norm = 1.8969e-01, time/batch = 0.6611s	
16319/25300 (epoch 32.251), train_loss = 0.70437309, grad/param norm = 1.9230e-01, time/batch = 0.6579s	
16320/25300 (epoch 32.253), train_loss = 0.80527181, grad/param norm = 2.1007e-01, time/batch = 0.6606s	
16321/25300 (epoch 32.255), train_loss = 0.75070887, grad/param norm = 2.2824e-01, time/batch = 0.6639s	
16322/25300 (epoch 32.257), train_loss = 0.77341452, grad/param norm = 2.1966e-01, time/batch = 0.6687s	
16323/25300 (epoch 32.259), train_loss = 0.96822386, grad/param norm = 2.5363e-01, time/batch = 0.6591s	
16324/25300 (epoch 32.261), train_loss = 0.92981809, grad/param norm = 2.7606e-01, time/batch = 0.6584s	
16325/25300 (epoch 32.263), train_loss = 0.95634292, grad/param norm = 2.4213e-01, time/batch = 0.6615s	
16326/25300 (epoch 32.265), train_loss = 0.98383127, grad/param norm = 2.4738e-01, time/batch = 0.6634s	
16327/25300 (epoch 32.267), train_loss = 0.85905778, grad/param norm = 2.2795e-01, time/batch = 0.6582s	
16328/25300 (epoch 32.269), train_loss = 0.69852234, grad/param norm = 1.9211e-01, time/batch = 0.6582s	
16329/25300 (epoch 32.271), train_loss = 0.74165743, grad/param norm = 2.2632e-01, time/batch = 0.6544s	
16330/25300 (epoch 32.273), train_loss = 0.90630826, grad/param norm = 3.0264e-01, time/batch = 0.6577s	
16331/25300 (epoch 32.275), train_loss = 0.78780292, grad/param norm = 2.0635e-01, time/batch = 0.6625s	
16332/25300 (epoch 32.277), train_loss = 0.79053824, grad/param norm = 2.6235e-01, time/batch = 0.6574s	
16333/25300 (epoch 32.279), train_loss = 0.83192377, grad/param norm = 2.4805e-01, time/batch = 0.6648s	
16334/25300 (epoch 32.281), train_loss = 0.95809087, grad/param norm = 2.3318e-01, time/batch = 0.6679s	
16335/25300 (epoch 32.283), train_loss = 0.71526727, grad/param norm = 2.1591e-01, time/batch = 0.6687s	
16336/25300 (epoch 32.285), train_loss = 0.82367724, grad/param norm = 2.3686e-01, time/batch = 0.6619s	
16337/25300 (epoch 32.287), train_loss = 0.92674585, grad/param norm = 1.9892e-01, time/batch = 0.6677s	
16338/25300 (epoch 32.289), train_loss = 0.76961385, grad/param norm = 2.2682e-01, time/batch = 0.6732s	
16339/25300 (epoch 32.291), train_loss = 0.77546873, grad/param norm = 1.9142e-01, time/batch = 0.6681s	
16340/25300 (epoch 32.292), train_loss = 0.97514522, grad/param norm = 2.0671e-01, time/batch = 0.6608s	
16341/25300 (epoch 32.294), train_loss = 0.86658717, grad/param norm = 2.1670e-01, time/batch = 0.6706s	
16342/25300 (epoch 32.296), train_loss = 0.73805760, grad/param norm = 1.9789e-01, time/batch = 0.6592s	
16343/25300 (epoch 32.298), train_loss = 0.90667651, grad/param norm = 2.3361e-01, time/batch = 0.6614s	
16344/25300 (epoch 32.300), train_loss = 0.90595785, grad/param norm = 2.3431e-01, time/batch = 0.6606s	
16345/25300 (epoch 32.302), train_loss = 0.67251436, grad/param norm = 2.0469e-01, time/batch = 0.6621s	
16346/25300 (epoch 32.304), train_loss = 0.93806168, grad/param norm = 2.1821e-01, time/batch = 0.6619s	
16347/25300 (epoch 32.306), train_loss = 0.63604756, grad/param norm = 1.8676e-01, time/batch = 0.6593s	
16348/25300 (epoch 32.308), train_loss = 0.88784639, grad/param norm = 2.0966e-01, time/batch = 0.6587s	
16349/25300 (epoch 32.310), train_loss = 0.73448376, grad/param norm = 2.2120e-01, time/batch = 0.6587s	
16350/25300 (epoch 32.312), train_loss = 0.83951156, grad/param norm = 1.9823e-01, time/batch = 0.6605s	
16351/25300 (epoch 32.314), train_loss = 0.68744495, grad/param norm = 2.1109e-01, time/batch = 0.6577s	
16352/25300 (epoch 32.316), train_loss = 0.82931387, grad/param norm = 2.0393e-01, time/batch = 0.6638s	
16353/25300 (epoch 32.318), train_loss = 0.66605731, grad/param norm = 1.9221e-01, time/batch = 0.6594s	
16354/25300 (epoch 32.320), train_loss = 0.73942545, grad/param norm = 1.8282e-01, time/batch = 0.6607s	
16355/25300 (epoch 32.322), train_loss = 0.96006401, grad/param norm = 2.5026e-01, time/batch = 0.6660s	
16356/25300 (epoch 32.324), train_loss = 0.75505286, grad/param norm = 2.1342e-01, time/batch = 0.6625s	
16357/25300 (epoch 32.326), train_loss = 0.66417859, grad/param norm = 1.7932e-01, time/batch = 0.6609s	
16358/25300 (epoch 32.328), train_loss = 0.65682930, grad/param norm = 2.0787e-01, time/batch = 0.6619s	
16359/25300 (epoch 32.330), train_loss = 0.78394035, grad/param norm = 2.0222e-01, time/batch = 0.6590s	
16360/25300 (epoch 32.332), train_loss = 0.81531329, grad/param norm = 2.0262e-01, time/batch = 0.6616s	
16361/25300 (epoch 32.334), train_loss = 0.67143508, grad/param norm = 1.8997e-01, time/batch = 0.6592s	
16362/25300 (epoch 32.336), train_loss = 0.69746620, grad/param norm = 2.4336e-01, time/batch = 0.6612s	
16363/25300 (epoch 32.338), train_loss = 0.69283478, grad/param norm = 1.7864e-01, time/batch = 0.6602s	
16364/25300 (epoch 32.340), train_loss = 0.72327441, grad/param norm = 2.0541e-01, time/batch = 0.6579s	
16365/25300 (epoch 32.342), train_loss = 0.76183279, grad/param norm = 2.6884e-01, time/batch = 0.6609s	
16366/25300 (epoch 32.344), train_loss = 0.85438179, grad/param norm = 2.6531e-01, time/batch = 0.6635s	
16367/25300 (epoch 32.346), train_loss = 0.76164264, grad/param norm = 2.0688e-01, time/batch = 0.6646s	
16368/25300 (epoch 32.348), train_loss = 0.72578211, grad/param norm = 2.0762e-01, time/batch = 0.6590s	
16369/25300 (epoch 32.350), train_loss = 0.77041949, grad/param norm = 2.0868e-01, time/batch = 0.6605s	
16370/25300 (epoch 32.352), train_loss = 0.79471784, grad/param norm = 2.1784e-01, time/batch = 0.6600s	
16371/25300 (epoch 32.354), train_loss = 0.75081128, grad/param norm = 2.1546e-01, time/batch = 0.6636s	
16372/25300 (epoch 32.356), train_loss = 0.78669617, grad/param norm = 2.0266e-01, time/batch = 0.6620s	
16373/25300 (epoch 32.358), train_loss = 0.82830741, grad/param norm = 2.4685e-01, time/batch = 0.6577s	
16374/25300 (epoch 32.360), train_loss = 0.71466521, grad/param norm = 1.8954e-01, time/batch = 0.6629s	
16375/25300 (epoch 32.362), train_loss = 0.69848815, grad/param norm = 2.0852e-01, time/batch = 0.6582s	
16376/25300 (epoch 32.364), train_loss = 0.72576038, grad/param norm = 2.5434e-01, time/batch = 0.6572s	
16377/25300 (epoch 32.366), train_loss = 0.69224148, grad/param norm = 2.0277e-01, time/batch = 0.6628s	
16378/25300 (epoch 32.368), train_loss = 0.77319863, grad/param norm = 1.9854e-01, time/batch = 0.6597s	
16379/25300 (epoch 32.370), train_loss = 0.72413075, grad/param norm = 2.2023e-01, time/batch = 0.6626s	
16380/25300 (epoch 32.372), train_loss = 0.73429404, grad/param norm = 2.4915e-01, time/batch = 0.6581s	
16381/25300 (epoch 32.374), train_loss = 0.68393172, grad/param norm = 2.0008e-01, time/batch = 0.6588s	
16382/25300 (epoch 32.375), train_loss = 0.87218585, grad/param norm = 2.3044e-01, time/batch = 0.6604s	
16383/25300 (epoch 32.377), train_loss = 0.85632602, grad/param norm = 2.3512e-01, time/batch = 0.6575s	
16384/25300 (epoch 32.379), train_loss = 0.83587946, grad/param norm = 2.0994e-01, time/batch = 0.6602s	
16385/25300 (epoch 32.381), train_loss = 0.76254020, grad/param norm = 2.0687e-01, time/batch = 0.6601s	
16386/25300 (epoch 32.383), train_loss = 0.70857968, grad/param norm = 2.0053e-01, time/batch = 0.6611s	
16387/25300 (epoch 32.385), train_loss = 0.80647312, grad/param norm = 2.1043e-01, time/batch = 0.6612s	
16388/25300 (epoch 32.387), train_loss = 0.78604773, grad/param norm = 2.1308e-01, time/batch = 0.6604s	
16389/25300 (epoch 32.389), train_loss = 0.78642154, grad/param norm = 2.3337e-01, time/batch = 0.6584s	
16390/25300 (epoch 32.391), train_loss = 0.74347081, grad/param norm = 2.0612e-01, time/batch = 0.6758s	
16391/25300 (epoch 32.393), train_loss = 0.80694402, grad/param norm = 2.5604e-01, time/batch = 0.6660s	
16392/25300 (epoch 32.395), train_loss = 0.65055068, grad/param norm = 1.9897e-01, time/batch = 0.6620s	
16393/25300 (epoch 32.397), train_loss = 0.61779390, grad/param norm = 1.9113e-01, time/batch = 0.6578s	
16394/25300 (epoch 32.399), train_loss = 0.69052281, grad/param norm = 2.0359e-01, time/batch = 0.6617s	
16395/25300 (epoch 32.401), train_loss = 0.82863437, grad/param norm = 2.1063e-01, time/batch = 0.6575s	
16396/25300 (epoch 32.403), train_loss = 0.80632148, grad/param norm = 2.3362e-01, time/batch = 0.6567s	
16397/25300 (epoch 32.405), train_loss = 0.75089388, grad/param norm = 2.0498e-01, time/batch = 0.6607s	
16398/25300 (epoch 32.407), train_loss = 0.77103245, grad/param norm = 2.1332e-01, time/batch = 0.6568s	
16399/25300 (epoch 32.409), train_loss = 0.70181706, grad/param norm = 1.9580e-01, time/batch = 0.6599s	
16400/25300 (epoch 32.411), train_loss = 0.73620594, grad/param norm = 2.0981e-01, time/batch = 0.6563s	
16401/25300 (epoch 32.413), train_loss = 0.65973420, grad/param norm = 2.2665e-01, time/batch = 0.6511s	
16402/25300 (epoch 32.415), train_loss = 0.70978256, grad/param norm = 1.9832e-01, time/batch = 0.6598s	
16403/25300 (epoch 32.417), train_loss = 0.65986490, grad/param norm = 1.8757e-01, time/batch = 0.6576s	
16404/25300 (epoch 32.419), train_loss = 0.60040592, grad/param norm = 1.6286e-01, time/batch = 0.6589s	
16405/25300 (epoch 32.421), train_loss = 0.66161769, grad/param norm = 1.6527e-01, time/batch = 0.6574s	
16406/25300 (epoch 32.423), train_loss = 0.65861698, grad/param norm = 2.0307e-01, time/batch = 0.6575s	
16407/25300 (epoch 32.425), train_loss = 0.75505711, grad/param norm = 2.3364e-01, time/batch = 0.6628s	
16408/25300 (epoch 32.427), train_loss = 0.86847614, grad/param norm = 2.0562e-01, time/batch = 0.6565s	
16409/25300 (epoch 32.429), train_loss = 0.87862541, grad/param norm = 2.3524e-01, time/batch = 0.6628s	
16410/25300 (epoch 32.431), train_loss = 0.78288660, grad/param norm = 2.1833e-01, time/batch = 0.6607s	
16411/25300 (epoch 32.433), train_loss = 0.80069251, grad/param norm = 1.9726e-01, time/batch = 0.6652s	
16412/25300 (epoch 32.435), train_loss = 0.72748444, grad/param norm = 2.3700e-01, time/batch = 0.6641s	
16413/25300 (epoch 32.437), train_loss = 0.72664389, grad/param norm = 2.1717e-01, time/batch = 0.6594s	
16414/25300 (epoch 32.439), train_loss = 0.79232998, grad/param norm = 1.9354e-01, time/batch = 0.6586s	
16415/25300 (epoch 32.441), train_loss = 0.83000839, grad/param norm = 2.3756e-01, time/batch = 0.6559s	
16416/25300 (epoch 32.443), train_loss = 0.95075925, grad/param norm = 2.7405e-01, time/batch = 0.6598s	
16417/25300 (epoch 32.445), train_loss = 0.88702731, grad/param norm = 2.2966e-01, time/batch = 0.6558s	
16418/25300 (epoch 32.447), train_loss = 0.70561976, grad/param norm = 1.8136e-01, time/batch = 0.6613s	
16419/25300 (epoch 32.449), train_loss = 0.65554420, grad/param norm = 2.1667e-01, time/batch = 0.6580s	
16420/25300 (epoch 32.451), train_loss = 0.97421190, grad/param norm = 2.5375e-01, time/batch = 0.6571s	
16421/25300 (epoch 32.453), train_loss = 0.84000081, grad/param norm = 2.2299e-01, time/batch = 0.6613s	
16422/25300 (epoch 32.455), train_loss = 0.82468795, grad/param norm = 2.6298e-01, time/batch = 0.6545s	
16423/25300 (epoch 32.457), train_loss = 0.72841661, grad/param norm = 2.0889e-01, time/batch = 0.6598s	
16424/25300 (epoch 32.458), train_loss = 0.73601235, grad/param norm = 2.7392e-01, time/batch = 0.6658s	
16425/25300 (epoch 32.460), train_loss = 0.76987160, grad/param norm = 2.2866e-01, time/batch = 0.6681s	
16426/25300 (epoch 32.462), train_loss = 0.57689396, grad/param norm = 2.0356e-01, time/batch = 0.6783s	
16427/25300 (epoch 32.464), train_loss = 0.86936946, grad/param norm = 2.5436e-01, time/batch = 0.6603s	
16428/25300 (epoch 32.466), train_loss = 0.81310658, grad/param norm = 2.1064e-01, time/batch = 0.6600s	
16429/25300 (epoch 32.468), train_loss = 0.84053303, grad/param norm = 2.2267e-01, time/batch = 0.6620s	
16430/25300 (epoch 32.470), train_loss = 0.74800725, grad/param norm = 2.0540e-01, time/batch = 0.6582s	
16431/25300 (epoch 32.472), train_loss = 0.66195469, grad/param norm = 2.1243e-01, time/batch = 0.6675s	
16432/25300 (epoch 32.474), train_loss = 0.81528929, grad/param norm = 2.1184e-01, time/batch = 0.6612s	
16433/25300 (epoch 32.476), train_loss = 0.75213608, grad/param norm = 2.7363e-01, time/batch = 0.6630s	
16434/25300 (epoch 32.478), train_loss = 0.85162867, grad/param norm = 2.5119e-01, time/batch = 0.6669s	
16435/25300 (epoch 32.480), train_loss = 0.73973810, grad/param norm = 1.8575e-01, time/batch = 0.6616s	
16436/25300 (epoch 32.482), train_loss = 0.80298531, grad/param norm = 2.5154e-01, time/batch = 0.6639s	
16437/25300 (epoch 32.484), train_loss = 0.83618215, grad/param norm = 2.1882e-01, time/batch = 0.6655s	
16438/25300 (epoch 32.486), train_loss = 0.77548230, grad/param norm = 2.4936e-01, time/batch = 0.6597s	
16439/25300 (epoch 32.488), train_loss = 0.94186582, grad/param norm = 2.4396e-01, time/batch = 0.6630s	
16440/25300 (epoch 32.490), train_loss = 0.82744723, grad/param norm = 2.1332e-01, time/batch = 0.6645s	
16441/25300 (epoch 32.492), train_loss = 0.89168997, grad/param norm = 2.1280e-01, time/batch = 0.6700s	
16442/25300 (epoch 32.494), train_loss = 0.77778062, grad/param norm = 2.2266e-01, time/batch = 0.6581s	
16443/25300 (epoch 32.496), train_loss = 0.84243845, grad/param norm = 2.3872e-01, time/batch = 0.6605s	
16444/25300 (epoch 32.498), train_loss = 0.78526494, grad/param norm = 1.9898e-01, time/batch = 0.6559s	
16445/25300 (epoch 32.500), train_loss = 0.94663290, grad/param norm = 2.4626e-01, time/batch = 0.6603s	
16446/25300 (epoch 32.502), train_loss = 0.86923379, grad/param norm = 2.3083e-01, time/batch = 0.6608s	
16447/25300 (epoch 32.504), train_loss = 0.77299992, grad/param norm = 2.1467e-01, time/batch = 0.6639s	
16448/25300 (epoch 32.506), train_loss = 0.70046539, grad/param norm = 2.2945e-01, time/batch = 0.6589s	
16449/25300 (epoch 32.508), train_loss = 0.79505278, grad/param norm = 2.4753e-01, time/batch = 0.6585s	
16450/25300 (epoch 32.510), train_loss = 0.72995591, grad/param norm = 2.2867e-01, time/batch = 0.6608s	
16451/25300 (epoch 32.512), train_loss = 0.61250305, grad/param norm = 1.9305e-01, time/batch = 0.6582s	
16452/25300 (epoch 32.514), train_loss = 0.77199685, grad/param norm = 2.0654e-01, time/batch = 0.6619s	
16453/25300 (epoch 32.516), train_loss = 0.83933659, grad/param norm = 2.3094e-01, time/batch = 0.6582s	
16454/25300 (epoch 32.518), train_loss = 0.87032981, grad/param norm = 2.1541e-01, time/batch = 0.6660s	
16455/25300 (epoch 32.520), train_loss = 0.65376967, grad/param norm = 1.7823e-01, time/batch = 0.6668s	
16456/25300 (epoch 32.522), train_loss = 0.71616482, grad/param norm = 2.0768e-01, time/batch = 0.6640s	
16457/25300 (epoch 32.524), train_loss = 0.72467140, grad/param norm = 2.0537e-01, time/batch = 0.6672s	
16458/25300 (epoch 32.526), train_loss = 0.91667474, grad/param norm = 2.2237e-01, time/batch = 0.6624s	
16459/25300 (epoch 32.528), train_loss = 0.90341736, grad/param norm = 2.3104e-01, time/batch = 0.6606s	
16460/25300 (epoch 32.530), train_loss = 0.82434540, grad/param norm = 2.0700e-01, time/batch = 0.6649s	
16461/25300 (epoch 32.532), train_loss = 0.75884976, grad/param norm = 2.0147e-01, time/batch = 0.6628s	
16462/25300 (epoch 32.534), train_loss = 0.75235133, grad/param norm = 2.4870e-01, time/batch = 0.6636s	
16463/25300 (epoch 32.536), train_loss = 0.63201511, grad/param norm = 2.5280e-01, time/batch = 0.6603s	
16464/25300 (epoch 32.538), train_loss = 0.67603733, grad/param norm = 1.7829e-01, time/batch = 0.6626s	
16465/25300 (epoch 32.540), train_loss = 0.69556219, grad/param norm = 1.9321e-01, time/batch = 0.6580s	
16466/25300 (epoch 32.542), train_loss = 0.66837010, grad/param norm = 2.2197e-01, time/batch = 0.6587s	
16467/25300 (epoch 32.543), train_loss = 0.64955387, grad/param norm = 1.8945e-01, time/batch = 0.6632s	
16468/25300 (epoch 32.545), train_loss = 0.97546332, grad/param norm = 3.0661e-01, time/batch = 0.6654s	
16469/25300 (epoch 32.547), train_loss = 0.86693085, grad/param norm = 2.5482e-01, time/batch = 0.6592s	
16470/25300 (epoch 32.549), train_loss = 0.97697185, grad/param norm = 2.6717e-01, time/batch = 0.6547s	
16471/25300 (epoch 32.551), train_loss = 0.87489563, grad/param norm = 2.3354e-01, time/batch = 0.6596s	
16472/25300 (epoch 32.553), train_loss = 0.72110863, grad/param norm = 2.3747e-01, time/batch = 0.6563s	
16473/25300 (epoch 32.555), train_loss = 0.85539653, grad/param norm = 2.4173e-01, time/batch = 0.6587s	
16474/25300 (epoch 32.557), train_loss = 0.88102064, grad/param norm = 2.5144e-01, time/batch = 0.6584s	
16475/25300 (epoch 32.559), train_loss = 0.90887038, grad/param norm = 2.3780e-01, time/batch = 0.6608s	
16476/25300 (epoch 32.561), train_loss = 0.92605420, grad/param norm = 2.8551e-01, time/batch = 0.6579s	
16477/25300 (epoch 32.563), train_loss = 0.87913173, grad/param norm = 2.3651e-01, time/batch = 0.6612s	
16478/25300 (epoch 32.565), train_loss = 0.68303025, grad/param norm = 1.9814e-01, time/batch = 0.6536s	
16479/25300 (epoch 32.567), train_loss = 0.63120332, grad/param norm = 2.1958e-01, time/batch = 0.6599s	
16480/25300 (epoch 32.569), train_loss = 0.82121543, grad/param norm = 2.1810e-01, time/batch = 0.6597s	
16481/25300 (epoch 32.571), train_loss = 0.85821379, grad/param norm = 2.2960e-01, time/batch = 0.6616s	
16482/25300 (epoch 32.573), train_loss = 0.77277527, grad/param norm = 2.0981e-01, time/batch = 0.6584s	
16483/25300 (epoch 32.575), train_loss = 0.86028377, grad/param norm = 2.2941e-01, time/batch = 0.6573s	
16484/25300 (epoch 32.577), train_loss = 0.75913755, grad/param norm = 2.5552e-01, time/batch = 0.6616s	
16485/25300 (epoch 32.579), train_loss = 0.90172557, grad/param norm = 2.3607e-01, time/batch = 0.6556s	
16486/25300 (epoch 32.581), train_loss = 0.85398267, grad/param norm = 2.2681e-01, time/batch = 0.6587s	
16487/25300 (epoch 32.583), train_loss = 0.66929611, grad/param norm = 1.9749e-01, time/batch = 0.6582s	
16488/25300 (epoch 32.585), train_loss = 0.66683730, grad/param norm = 2.0723e-01, time/batch = 0.6575s	
16489/25300 (epoch 32.587), train_loss = 0.79438515, grad/param norm = 2.2687e-01, time/batch = 0.6590s	
16490/25300 (epoch 32.589), train_loss = 0.68746256, grad/param norm = 1.7286e-01, time/batch = 0.6608s	
16491/25300 (epoch 32.591), train_loss = 0.66297035, grad/param norm = 2.3208e-01, time/batch = 0.6633s	
16492/25300 (epoch 32.593), train_loss = 0.86669107, grad/param norm = 2.2998e-01, time/batch = 0.6565s	
16493/25300 (epoch 32.595), train_loss = 0.78445003, grad/param norm = 2.2043e-01, time/batch = 0.6632s	
16494/25300 (epoch 32.597), train_loss = 0.70962350, grad/param norm = 1.9700e-01, time/batch = 0.6608s	
16495/25300 (epoch 32.599), train_loss = 0.87619229, grad/param norm = 2.3236e-01, time/batch = 0.6601s	
16496/25300 (epoch 32.601), train_loss = 0.77261141, grad/param norm = 2.1650e-01, time/batch = 0.6632s	
16497/25300 (epoch 32.603), train_loss = 0.78438318, grad/param norm = 2.0829e-01, time/batch = 0.6588s	
16498/25300 (epoch 32.605), train_loss = 0.79652001, grad/param norm = 2.4000e-01, time/batch = 0.6572s	
16499/25300 (epoch 32.607), train_loss = 0.56372129, grad/param norm = 1.7517e-01, time/batch = 0.6615s	
16500/25300 (epoch 32.609), train_loss = 0.73469972, grad/param norm = 2.0918e-01, time/batch = 0.6594s	
16501/25300 (epoch 32.611), train_loss = 0.81847952, grad/param norm = 2.1016e-01, time/batch = 0.6656s	
16502/25300 (epoch 32.613), train_loss = 0.68079925, grad/param norm = 1.8387e-01, time/batch = 0.6614s	
16503/25300 (epoch 32.615), train_loss = 0.74935965, grad/param norm = 2.1718e-01, time/batch = 0.6609s	
16504/25300 (epoch 32.617), train_loss = 0.78891005, grad/param norm = 2.3711e-01, time/batch = 0.6602s	
16505/25300 (epoch 32.619), train_loss = 0.83701624, grad/param norm = 2.4577e-01, time/batch = 0.6617s	
16506/25300 (epoch 32.621), train_loss = 0.87843091, grad/param norm = 2.6686e-01, time/batch = 0.6599s	
16507/25300 (epoch 32.623), train_loss = 0.73862714, grad/param norm = 2.3437e-01, time/batch = 0.6590s	
16508/25300 (epoch 32.625), train_loss = 0.64918172, grad/param norm = 2.0839e-01, time/batch = 0.6622s	
16509/25300 (epoch 32.626), train_loss = 0.75651812, grad/param norm = 1.9305e-01, time/batch = 0.6638s	
16510/25300 (epoch 32.628), train_loss = 0.88205489, grad/param norm = 2.6606e-01, time/batch = 0.6600s	
16511/25300 (epoch 32.630), train_loss = 0.85249191, grad/param norm = 2.3482e-01, time/batch = 0.6618s	
16512/25300 (epoch 32.632), train_loss = 0.83578257, grad/param norm = 3.0887e-01, time/batch = 0.6635s	
16513/25300 (epoch 32.634), train_loss = 0.87901111, grad/param norm = 2.7536e-01, time/batch = 0.6588s	
16514/25300 (epoch 32.636), train_loss = 0.71355750, grad/param norm = 2.2313e-01, time/batch = 0.7650s	
16515/25300 (epoch 32.638), train_loss = 0.80737014, grad/param norm = 2.7122e-01, time/batch = 0.9848s	
16516/25300 (epoch 32.640), train_loss = 0.98022394, grad/param norm = 2.9239e-01, time/batch = 1.0047s	
16517/25300 (epoch 32.642), train_loss = 0.82759073, grad/param norm = 2.5337e-01, time/batch = 0.9713s	
16518/25300 (epoch 32.644), train_loss = 0.81302063, grad/param norm = 2.3041e-01, time/batch = 0.9724s	
16519/25300 (epoch 32.646), train_loss = 0.72679732, grad/param norm = 2.6328e-01, time/batch = 0.8903s	
16520/25300 (epoch 32.648), train_loss = 0.87377179, grad/param norm = 2.0614e-01, time/batch = 0.6623s	
16521/25300 (epoch 32.650), train_loss = 0.81321461, grad/param norm = 2.0792e-01, time/batch = 0.6634s	
16522/25300 (epoch 32.652), train_loss = 0.84583563, grad/param norm = 2.5275e-01, time/batch = 0.6577s	
16523/25300 (epoch 32.654), train_loss = 0.93150620, grad/param norm = 2.1680e-01, time/batch = 0.6602s	
16524/25300 (epoch 32.656), train_loss = 0.86729654, grad/param norm = 2.5146e-01, time/batch = 0.6660s	
16525/25300 (epoch 32.658), train_loss = 0.63480903, grad/param norm = 1.7502e-01, time/batch = 0.6605s	
16526/25300 (epoch 32.660), train_loss = 0.65407988, grad/param norm = 2.3665e-01, time/batch = 0.6621s	
16527/25300 (epoch 32.662), train_loss = 0.66599593, grad/param norm = 1.9794e-01, time/batch = 0.6614s	
16528/25300 (epoch 32.664), train_loss = 0.63486588, grad/param norm = 2.0184e-01, time/batch = 0.6630s	
16529/25300 (epoch 32.666), train_loss = 0.68827183, grad/param norm = 2.4481e-01, time/batch = 0.6623s	
16530/25300 (epoch 32.668), train_loss = 0.79746487, grad/param norm = 2.6421e-01, time/batch = 0.6592s	
16531/25300 (epoch 32.670), train_loss = 0.72701262, grad/param norm = 2.2054e-01, time/batch = 0.6609s	
16532/25300 (epoch 32.672), train_loss = 0.70040563, grad/param norm = 2.1191e-01, time/batch = 0.6642s	
16533/25300 (epoch 32.674), train_loss = 0.71840313, grad/param norm = 1.9723e-01, time/batch = 0.6625s	
16534/25300 (epoch 32.676), train_loss = 0.74328710, grad/param norm = 2.9226e-01, time/batch = 0.6674s	
16535/25300 (epoch 32.678), train_loss = 0.74060535, grad/param norm = 2.0925e-01, time/batch = 0.6610s	
16536/25300 (epoch 32.680), train_loss = 0.65182070, grad/param norm = 2.0629e-01, time/batch = 0.6637s	
16537/25300 (epoch 32.682), train_loss = 0.54650421, grad/param norm = 1.7280e-01, time/batch = 0.6592s	
16538/25300 (epoch 32.684), train_loss = 0.70043078, grad/param norm = 1.7616e-01, time/batch = 0.6600s	
16539/25300 (epoch 32.686), train_loss = 0.65667614, grad/param norm = 2.0030e-01, time/batch = 0.6606s	
16540/25300 (epoch 32.688), train_loss = 0.73744799, grad/param norm = 2.1923e-01, time/batch = 0.6622s	
16541/25300 (epoch 32.690), train_loss = 0.67068452, grad/param norm = 1.8920e-01, time/batch = 0.6631s	
16542/25300 (epoch 32.692), train_loss = 0.71065876, grad/param norm = 2.0927e-01, time/batch = 0.6628s	
16543/25300 (epoch 32.694), train_loss = 0.70694736, grad/param norm = 2.4934e-01, time/batch = 0.6573s	
16544/25300 (epoch 32.696), train_loss = 0.77157428, grad/param norm = 2.0870e-01, time/batch = 0.6573s	
16545/25300 (epoch 32.698), train_loss = 0.83150626, grad/param norm = 2.2245e-01, time/batch = 0.6671s	
16546/25300 (epoch 32.700), train_loss = 0.61035900, grad/param norm = 1.9301e-01, time/batch = 0.6616s	
16547/25300 (epoch 32.702), train_loss = 0.82029529, grad/param norm = 2.1062e-01, time/batch = 0.6582s	
16548/25300 (epoch 32.704), train_loss = 0.61078564, grad/param norm = 1.8946e-01, time/batch = 0.6610s	
16549/25300 (epoch 32.706), train_loss = 0.74174248, grad/param norm = 2.2140e-01, time/batch = 0.6572s	
16550/25300 (epoch 32.708), train_loss = 0.63374769, grad/param norm = 1.8504e-01, time/batch = 0.6597s	
16551/25300 (epoch 32.709), train_loss = 0.89684251, grad/param norm = 2.3208e-01, time/batch = 0.6590s	
16552/25300 (epoch 32.711), train_loss = 0.95063010, grad/param norm = 2.6478e-01, time/batch = 0.6567s	
16553/25300 (epoch 32.713), train_loss = 0.75741619, grad/param norm = 1.8541e-01, time/batch = 0.6599s	
16554/25300 (epoch 32.715), train_loss = 0.77444014, grad/param norm = 2.0124e-01, time/batch = 0.6615s	
16555/25300 (epoch 32.717), train_loss = 0.67683535, grad/param norm = 2.1640e-01, time/batch = 0.6644s	
16556/25300 (epoch 32.719), train_loss = 0.75305736, grad/param norm = 2.1977e-01, time/batch = 0.6687s	
16557/25300 (epoch 32.721), train_loss = 0.80437197, grad/param norm = 2.1484e-01, time/batch = 0.6739s	
16558/25300 (epoch 32.723), train_loss = 0.74614639, grad/param norm = 2.1798e-01, time/batch = 0.6698s	
16559/25300 (epoch 32.725), train_loss = 0.76971317, grad/param norm = 2.0498e-01, time/batch = 0.6665s	
16560/25300 (epoch 32.727), train_loss = 0.76970016, grad/param norm = 2.1408e-01, time/batch = 0.6630s	
16561/25300 (epoch 32.729), train_loss = 0.76478119, grad/param norm = 2.1075e-01, time/batch = 0.6765s	
16562/25300 (epoch 32.731), train_loss = 0.92451842, grad/param norm = 2.2197e-01, time/batch = 0.6688s	
16563/25300 (epoch 32.733), train_loss = 0.75371316, grad/param norm = 1.9709e-01, time/batch = 0.6712s	
16564/25300 (epoch 32.735), train_loss = 0.99376726, grad/param norm = 2.4127e-01, time/batch = 0.6677s	
16565/25300 (epoch 32.737), train_loss = 0.64064657, grad/param norm = 1.8362e-01, time/batch = 0.6691s	
16566/25300 (epoch 32.739), train_loss = 0.89353457, grad/param norm = 2.3791e-01, time/batch = 0.6718s	
16567/25300 (epoch 32.741), train_loss = 0.81957914, grad/param norm = 2.3334e-01, time/batch = 0.6696s	
16568/25300 (epoch 32.743), train_loss = 0.76022801, grad/param norm = 1.9969e-01, time/batch = 0.6729s	
16569/25300 (epoch 32.745), train_loss = 0.75666415, grad/param norm = 2.5172e-01, time/batch = 0.6639s	
16570/25300 (epoch 32.747), train_loss = 0.68036235, grad/param norm = 1.9525e-01, time/batch = 0.6578s	
16571/25300 (epoch 32.749), train_loss = 0.78124012, grad/param norm = 2.4746e-01, time/batch = 0.6626s	
16572/25300 (epoch 32.751), train_loss = 0.84112956, grad/param norm = 2.3310e-01, time/batch = 0.6645s	
16573/25300 (epoch 32.753), train_loss = 0.64743586, grad/param norm = 1.8725e-01, time/batch = 0.6632s	
16574/25300 (epoch 32.755), train_loss = 0.87197747, grad/param norm = 2.1889e-01, time/batch = 0.6659s	
16575/25300 (epoch 32.757), train_loss = 0.72060582, grad/param norm = 2.0389e-01, time/batch = 0.6613s	
16576/25300 (epoch 32.759), train_loss = 0.72321069, grad/param norm = 2.3266e-01, time/batch = 0.6639s	
16577/25300 (epoch 32.761), train_loss = 0.91091255, grad/param norm = 2.1478e-01, time/batch = 0.6602s	
16578/25300 (epoch 32.763), train_loss = 0.74844174, grad/param norm = 2.1595e-01, time/batch = 0.6647s	
16579/25300 (epoch 32.765), train_loss = 0.76332799, grad/param norm = 2.3392e-01, time/batch = 0.6641s	
16580/25300 (epoch 32.767), train_loss = 0.75038836, grad/param norm = 1.9566e-01, time/batch = 0.6618s	
16581/25300 (epoch 32.769), train_loss = 0.76234161, grad/param norm = 2.2527e-01, time/batch = 0.6672s	
16582/25300 (epoch 32.771), train_loss = 0.87013171, grad/param norm = 2.6756e-01, time/batch = 0.6629s	
16583/25300 (epoch 32.773), train_loss = 0.91529437, grad/param norm = 2.7267e-01, time/batch = 0.6601s	
16584/25300 (epoch 32.775), train_loss = 0.79382468, grad/param norm = 1.9504e-01, time/batch = 0.6648s	
16585/25300 (epoch 32.777), train_loss = 0.73418817, grad/param norm = 2.2137e-01, time/batch = 0.6716s	
16586/25300 (epoch 32.779), train_loss = 0.86130850, grad/param norm = 2.1503e-01, time/batch = 0.6651s	
16587/25300 (epoch 32.781), train_loss = 0.83770169, grad/param norm = 2.2496e-01, time/batch = 0.6632s	
16588/25300 (epoch 32.783), train_loss = 0.92310430, grad/param norm = 2.4151e-01, time/batch = 0.6624s	
16589/25300 (epoch 32.785), train_loss = 0.86763339, grad/param norm = 2.4780e-01, time/batch = 0.6606s	
16590/25300 (epoch 32.787), train_loss = 0.85427804, grad/param norm = 2.6685e-01, time/batch = 0.6667s	
16591/25300 (epoch 32.789), train_loss = 0.92059971, grad/param norm = 2.1898e-01, time/batch = 0.6651s	
16592/25300 (epoch 32.791), train_loss = 0.82500917, grad/param norm = 2.3539e-01, time/batch = 0.6663s	
16593/25300 (epoch 32.792), train_loss = 0.91094908, grad/param norm = 2.5611e-01, time/batch = 0.6653s	
16594/25300 (epoch 32.794), train_loss = 0.78556889, grad/param norm = 2.5192e-01, time/batch = 0.6640s	
16595/25300 (epoch 32.796), train_loss = 0.75536906, grad/param norm = 2.4605e-01, time/batch = 0.6662s	
16596/25300 (epoch 32.798), train_loss = 0.89194643, grad/param norm = 3.0320e-01, time/batch = 0.6653s	
16597/25300 (epoch 32.800), train_loss = 0.79013137, grad/param norm = 2.0442e-01, time/batch = 0.6685s	
16598/25300 (epoch 32.802), train_loss = 0.63448281, grad/param norm = 1.9335e-01, time/batch = 0.6648s	
16599/25300 (epoch 32.804), train_loss = 0.82216421, grad/param norm = 2.4423e-01, time/batch = 0.6636s	
16600/25300 (epoch 32.806), train_loss = 0.84585930, grad/param norm = 2.3755e-01, time/batch = 0.6634s	
16601/25300 (epoch 32.808), train_loss = 0.90832764, grad/param norm = 2.2178e-01, time/batch = 0.6682s	
16602/25300 (epoch 32.810), train_loss = 0.77914009, grad/param norm = 2.4448e-01, time/batch = 0.6675s	
16603/25300 (epoch 32.812), train_loss = 0.90120775, grad/param norm = 2.2387e-01, time/batch = 0.6694s	
16604/25300 (epoch 32.814), train_loss = 0.93519490, grad/param norm = 2.5783e-01, time/batch = 0.6696s	
16605/25300 (epoch 32.816), train_loss = 0.99116163, grad/param norm = 2.4534e-01, time/batch = 0.6663s	
16606/25300 (epoch 32.818), train_loss = 0.87600468, grad/param norm = 1.9764e-01, time/batch = 0.6658s	
16607/25300 (epoch 32.820), train_loss = 0.89563665, grad/param norm = 2.3115e-01, time/batch = 0.6672s	
16608/25300 (epoch 32.822), train_loss = 0.74482168, grad/param norm = 2.0823e-01, time/batch = 0.6607s	
16609/25300 (epoch 32.824), train_loss = 0.90342984, grad/param norm = 2.3333e-01, time/batch = 0.6648s	
16610/25300 (epoch 32.826), train_loss = 0.73083438, grad/param norm = 1.9207e-01, time/batch = 0.6669s	
16611/25300 (epoch 32.828), train_loss = 0.71104789, grad/param norm = 2.1323e-01, time/batch = 0.6674s	
16612/25300 (epoch 32.830), train_loss = 0.82458124, grad/param norm = 2.5288e-01, time/batch = 0.6689s	
16613/25300 (epoch 32.832), train_loss = 0.90631352, grad/param norm = 2.6719e-01, time/batch = 0.6675s	
16614/25300 (epoch 32.834), train_loss = 0.73805264, grad/param norm = 1.9902e-01, time/batch = 0.6662s	
16615/25300 (epoch 32.836), train_loss = 0.77463873, grad/param norm = 2.0102e-01, time/batch = 0.6756s	
16616/25300 (epoch 32.838), train_loss = 0.77183086, grad/param norm = 2.2848e-01, time/batch = 0.6718s	
16617/25300 (epoch 32.840), train_loss = 0.85973834, grad/param norm = 2.2665e-01, time/batch = 0.6675s	
16618/25300 (epoch 32.842), train_loss = 0.81612404, grad/param norm = 2.2982e-01, time/batch = 0.6703s	
16619/25300 (epoch 32.844), train_loss = 0.88932773, grad/param norm = 2.0430e-01, time/batch = 0.6637s	
16620/25300 (epoch 32.846), train_loss = 0.86037533, grad/param norm = 2.1574e-01, time/batch = 0.6698s	
16621/25300 (epoch 32.848), train_loss = 0.85781941, grad/param norm = 2.3927e-01, time/batch = 0.6687s	
16622/25300 (epoch 32.850), train_loss = 0.81346407, grad/param norm = 2.0317e-01, time/batch = 0.6647s	
16623/25300 (epoch 32.852), train_loss = 0.86565375, grad/param norm = 2.1021e-01, time/batch = 0.6680s	
16624/25300 (epoch 32.854), train_loss = 0.89646630, grad/param norm = 2.1555e-01, time/batch = 0.6682s	
16625/25300 (epoch 32.856), train_loss = 0.76195682, grad/param norm = 2.2184e-01, time/batch = 0.6675s	
16626/25300 (epoch 32.858), train_loss = 0.79812701, grad/param norm = 2.2662e-01, time/batch = 0.6734s	
16627/25300 (epoch 32.860), train_loss = 0.69153474, grad/param norm = 2.3022e-01, time/batch = 0.6734s	
16628/25300 (epoch 32.862), train_loss = 0.81293387, grad/param norm = 2.1401e-01, time/batch = 0.6687s	
16629/25300 (epoch 32.864), train_loss = 0.90997498, grad/param norm = 2.3046e-01, time/batch = 0.6642s	
16630/25300 (epoch 32.866), train_loss = 0.76270063, grad/param norm = 2.4620e-01, time/batch = 0.6702s	
16631/25300 (epoch 32.868), train_loss = 0.90993255, grad/param norm = 2.2218e-01, time/batch = 0.6683s	
16632/25300 (epoch 32.870), train_loss = 0.89327359, grad/param norm = 1.9385e-01, time/batch = 0.6668s	
16633/25300 (epoch 32.872), train_loss = 0.82486471, grad/param norm = 2.3948e-01, time/batch = 0.6666s	
16634/25300 (epoch 32.874), train_loss = 0.84278760, grad/param norm = 2.2698e-01, time/batch = 0.6664s	
16635/25300 (epoch 32.875), train_loss = 0.78073534, grad/param norm = 2.2824e-01, time/batch = 0.6684s	
16636/25300 (epoch 32.877), train_loss = 0.76354314, grad/param norm = 1.9617e-01, time/batch = 0.6726s	
16637/25300 (epoch 32.879), train_loss = 0.72988799, grad/param norm = 2.2852e-01, time/batch = 0.6686s	
16638/25300 (epoch 32.881), train_loss = 1.05186095, grad/param norm = 2.8863e-01, time/batch = 0.6710s	
16639/25300 (epoch 32.883), train_loss = 1.02291030, grad/param norm = 2.5407e-01, time/batch = 0.6689s	
16640/25300 (epoch 32.885), train_loss = 0.89031451, grad/param norm = 3.2011e-01, time/batch = 0.6777s	
16641/25300 (epoch 32.887), train_loss = 0.89957665, grad/param norm = 2.2878e-01, time/batch = 0.6682s	
16642/25300 (epoch 32.889), train_loss = 0.98314318, grad/param norm = 3.1145e-01, time/batch = 0.6726s	
16643/25300 (epoch 32.891), train_loss = 0.85420427, grad/param norm = 2.3191e-01, time/batch = 0.6661s	
16644/25300 (epoch 32.893), train_loss = 0.84229634, grad/param norm = 2.7818e-01, time/batch = 0.6602s	
16645/25300 (epoch 32.895), train_loss = 0.61619368, grad/param norm = 1.9278e-01, time/batch = 0.6664s	
16646/25300 (epoch 32.897), train_loss = 0.72029323, grad/param norm = 1.9168e-01, time/batch = 0.6667s	
16647/25300 (epoch 32.899), train_loss = 0.81494439, grad/param norm = 2.1151e-01, time/batch = 0.6662s	
16648/25300 (epoch 32.901), train_loss = 0.85480129, grad/param norm = 2.4127e-01, time/batch = 0.6689s	
16649/25300 (epoch 32.903), train_loss = 0.69094260, grad/param norm = 2.1208e-01, time/batch = 0.6652s	
16650/25300 (epoch 32.905), train_loss = 0.76405636, grad/param norm = 2.3060e-01, time/batch = 0.6675s	
16651/25300 (epoch 32.907), train_loss = 0.74841888, grad/param norm = 2.2673e-01, time/batch = 0.6635s	
16652/25300 (epoch 32.909), train_loss = 0.87026714, grad/param norm = 2.3487e-01, time/batch = 0.6627s	
16653/25300 (epoch 32.911), train_loss = 0.91360264, grad/param norm = 2.5562e-01, time/batch = 0.6628s	
16654/25300 (epoch 32.913), train_loss = 1.00245075, grad/param norm = 2.7839e-01, time/batch = 0.6656s	
16655/25300 (epoch 32.915), train_loss = 0.74943570, grad/param norm = 2.5282e-01, time/batch = 0.6650s	
16656/25300 (epoch 32.917), train_loss = 0.93574581, grad/param norm = 2.2160e-01, time/batch = 0.6652s	
16657/25300 (epoch 32.919), train_loss = 0.93538850, grad/param norm = 2.7821e-01, time/batch = 0.6651s	
16658/25300 (epoch 32.921), train_loss = 0.76846268, grad/param norm = 2.3267e-01, time/batch = 0.6632s	
16659/25300 (epoch 32.923), train_loss = 0.90849333, grad/param norm = 2.3786e-01, time/batch = 0.6696s	
16660/25300 (epoch 32.925), train_loss = 0.83051111, grad/param norm = 3.0843e-01, time/batch = 0.6679s	
16661/25300 (epoch 32.927), train_loss = 0.80424454, grad/param norm = 2.4760e-01, time/batch = 0.6719s	
16662/25300 (epoch 32.929), train_loss = 0.84982496, grad/param norm = 2.3268e-01, time/batch = 0.6706s	
16663/25300 (epoch 32.931), train_loss = 0.88828354, grad/param norm = 2.7331e-01, time/batch = 0.6693s	
16664/25300 (epoch 32.933), train_loss = 0.84912415, grad/param norm = 2.2119e-01, time/batch = 0.6687s	
16665/25300 (epoch 32.935), train_loss = 0.86297515, grad/param norm = 2.0387e-01, time/batch = 0.6687s	
16666/25300 (epoch 32.937), train_loss = 0.64658072, grad/param norm = 1.8314e-01, time/batch = 0.6687s	
16667/25300 (epoch 32.939), train_loss = 0.84447141, grad/param norm = 2.2128e-01, time/batch = 0.6657s	
16668/25300 (epoch 32.941), train_loss = 0.75604221, grad/param norm = 2.2889e-01, time/batch = 0.6703s	
16669/25300 (epoch 32.943), train_loss = 0.84407288, grad/param norm = 2.2039e-01, time/batch = 0.6622s	
16670/25300 (epoch 32.945), train_loss = 0.84362527, grad/param norm = 2.3405e-01, time/batch = 0.6638s	
16671/25300 (epoch 32.947), train_loss = 0.75013056, grad/param norm = 2.3486e-01, time/batch = 0.6702s	
16672/25300 (epoch 32.949), train_loss = 0.85112219, grad/param norm = 2.0543e-01, time/batch = 0.6650s	
16673/25300 (epoch 32.951), train_loss = 0.79485628, grad/param norm = 1.7827e-01, time/batch = 0.6657s	
16674/25300 (epoch 32.953), train_loss = 0.79336109, grad/param norm = 2.1517e-01, time/batch = 0.6675s	
16675/25300 (epoch 32.955), train_loss = 1.01617286, grad/param norm = 2.7273e-01, time/batch = 0.6677s	
16676/25300 (epoch 32.957), train_loss = 0.94048822, grad/param norm = 2.8608e-01, time/batch = 0.6698s	
16677/25300 (epoch 32.958), train_loss = 0.89822693, grad/param norm = 2.5234e-01, time/batch = 0.6745s	
16678/25300 (epoch 32.960), train_loss = 0.98978773, grad/param norm = 2.6877e-01, time/batch = 0.6678s	
16679/25300 (epoch 32.962), train_loss = 0.96471297, grad/param norm = 2.7276e-01, time/batch = 0.6640s	
16680/25300 (epoch 32.964), train_loss = 0.85938079, grad/param norm = 2.4401e-01, time/batch = 0.6682s	
16681/25300 (epoch 32.966), train_loss = 0.73731330, grad/param norm = 2.4612e-01, time/batch = 0.6678s	
16682/25300 (epoch 32.968), train_loss = 0.72180448, grad/param norm = 2.4534e-01, time/batch = 0.6669s	
16683/25300 (epoch 32.970), train_loss = 0.79954854, grad/param norm = 2.4475e-01, time/batch = 0.6669s	
16684/25300 (epoch 32.972), train_loss = 0.81198080, grad/param norm = 2.0230e-01, time/batch = 0.6684s	
16685/25300 (epoch 32.974), train_loss = 0.94735965, grad/param norm = 2.9482e-01, time/batch = 0.6619s	
16686/25300 (epoch 32.976), train_loss = 0.83950450, grad/param norm = 2.1987e-01, time/batch = 0.6639s	
16687/25300 (epoch 32.978), train_loss = 0.79185122, grad/param norm = 2.4495e-01, time/batch = 0.6639s	
16688/25300 (epoch 32.980), train_loss = 0.82363312, grad/param norm = 2.5573e-01, time/batch = 0.6581s	
16689/25300 (epoch 32.982), train_loss = 0.77882485, grad/param norm = 2.7456e-01, time/batch = 0.6647s	
16690/25300 (epoch 32.984), train_loss = 0.80525013, grad/param norm = 2.4925e-01, time/batch = 0.6642s	
16691/25300 (epoch 32.986), train_loss = 0.87660785, grad/param norm = 2.4006e-01, time/batch = 0.6662s	
16692/25300 (epoch 32.988), train_loss = 0.84412792, grad/param norm = 2.5930e-01, time/batch = 0.6691s	
16693/25300 (epoch 32.990), train_loss = 0.83127723, grad/param norm = 2.1762e-01, time/batch = 0.6796s	
16694/25300 (epoch 32.992), train_loss = 0.72777005, grad/param norm = 1.8837e-01, time/batch = 0.6698s	
16695/25300 (epoch 32.994), train_loss = 0.82739482, grad/param norm = 2.3324e-01, time/batch = 0.6604s	
16696/25300 (epoch 32.996), train_loss = 0.95663840, grad/param norm = 3.1991e-01, time/batch = 0.6669s	
16697/25300 (epoch 32.998), train_loss = 0.90351064, grad/param norm = 2.6051e-01, time/batch = 0.6715s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
16698/25300 (epoch 33.000), train_loss = 0.87590370, grad/param norm = 2.3946e-01, time/batch = 0.6645s	
16699/25300 (epoch 33.002), train_loss = 0.81980456, grad/param norm = 1.9922e-01, time/batch = 0.6714s	
16700/25300 (epoch 33.004), train_loss = 0.70776750, grad/param norm = 2.0694e-01, time/batch = 0.6738s	
16701/25300 (epoch 33.006), train_loss = 0.98408489, grad/param norm = 2.4383e-01, time/batch = 0.6697s	
16702/25300 (epoch 33.008), train_loss = 0.81873471, grad/param norm = 2.0041e-01, time/batch = 0.6629s	
16703/25300 (epoch 33.010), train_loss = 0.85496696, grad/param norm = 2.0106e-01, time/batch = 0.6596s	
16704/25300 (epoch 33.012), train_loss = 0.77932777, grad/param norm = 2.2865e-01, time/batch = 0.6612s	
16705/25300 (epoch 33.014), train_loss = 0.94234465, grad/param norm = 2.2931e-01, time/batch = 0.6621s	
16706/25300 (epoch 33.016), train_loss = 0.83431906, grad/param norm = 2.4699e-01, time/batch = 0.6581s	
16707/25300 (epoch 33.018), train_loss = 0.72570651, grad/param norm = 2.0510e-01, time/batch = 0.6620s	
16708/25300 (epoch 33.020), train_loss = 0.82149209, grad/param norm = 1.9988e-01, time/batch = 0.6684s	
16709/25300 (epoch 33.022), train_loss = 0.83259859, grad/param norm = 2.4683e-01, time/batch = 0.6693s	
16710/25300 (epoch 33.024), train_loss = 0.61852898, grad/param norm = 1.5772e-01, time/batch = 0.6600s	
16711/25300 (epoch 33.026), train_loss = 0.78697304, grad/param norm = 2.3017e-01, time/batch = 0.6603s	
16712/25300 (epoch 33.028), train_loss = 0.77599917, grad/param norm = 2.3471e-01, time/batch = 0.6667s	
16713/25300 (epoch 33.030), train_loss = 0.93040106, grad/param norm = 2.2394e-01, time/batch = 0.6563s	
16714/25300 (epoch 33.032), train_loss = 0.79305162, grad/param norm = 2.2086e-01, time/batch = 0.6565s	
16715/25300 (epoch 33.034), train_loss = 0.70460565, grad/param norm = 1.9575e-01, time/batch = 0.6575s	
16716/25300 (epoch 33.036), train_loss = 0.68317910, grad/param norm = 2.0249e-01, time/batch = 0.6599s	
16717/25300 (epoch 33.038), train_loss = 0.64267938, grad/param norm = 1.9215e-01, time/batch = 0.6574s	
16718/25300 (epoch 33.040), train_loss = 0.81248080, grad/param norm = 2.2769e-01, time/batch = 0.6579s	
16719/25300 (epoch 33.042), train_loss = 0.80751163, grad/param norm = 2.0373e-01, time/batch = 0.6610s	
16720/25300 (epoch 33.043), train_loss = 0.69270844, grad/param norm = 1.8762e-01, time/batch = 0.6594s	
16721/25300 (epoch 33.045), train_loss = 0.68065054, grad/param norm = 1.8720e-01, time/batch = 0.6625s	
16722/25300 (epoch 33.047), train_loss = 0.83519517, grad/param norm = 2.0229e-01, time/batch = 0.6667s	
16723/25300 (epoch 33.049), train_loss = 0.83495804, grad/param norm = 3.0235e-01, time/batch = 0.6589s	
16724/25300 (epoch 33.051), train_loss = 0.94205658, grad/param norm = 2.4569e-01, time/batch = 0.6591s	
16725/25300 (epoch 33.053), train_loss = 0.64210824, grad/param norm = 2.0135e-01, time/batch = 0.6598s	
16726/25300 (epoch 33.055), train_loss = 0.68402667, grad/param norm = 2.2631e-01, time/batch = 0.6567s	
16727/25300 (epoch 33.057), train_loss = 0.65882475, grad/param norm = 1.6215e-01, time/batch = 0.6592s	
16728/25300 (epoch 33.059), train_loss = 0.75172211, grad/param norm = 2.0845e-01, time/batch = 0.6598s	
16729/25300 (epoch 33.061), train_loss = 0.74578097, grad/param norm = 2.3894e-01, time/batch = 0.6579s	
16730/25300 (epoch 33.063), train_loss = 0.72572551, grad/param norm = 1.8403e-01, time/batch = 0.6611s	
16731/25300 (epoch 33.065), train_loss = 0.81920882, grad/param norm = 2.2709e-01, time/batch = 0.6611s	
16732/25300 (epoch 33.067), train_loss = 0.87611169, grad/param norm = 2.0343e-01, time/batch = 0.6589s	
16733/25300 (epoch 33.069), train_loss = 0.70650313, grad/param norm = 2.0061e-01, time/batch = 0.6565s	
16734/25300 (epoch 33.071), train_loss = 0.84645839, grad/param norm = 2.3716e-01, time/batch = 0.6618s	
16735/25300 (epoch 33.073), train_loss = 0.76624678, grad/param norm = 1.8103e-01, time/batch = 0.6592s	
16736/25300 (epoch 33.075), train_loss = 0.87574649, grad/param norm = 2.3398e-01, time/batch = 0.6623s	
16737/25300 (epoch 33.077), train_loss = 0.82994039, grad/param norm = 2.1746e-01, time/batch = 0.6559s	
16738/25300 (epoch 33.079), train_loss = 0.73247197, grad/param norm = 2.1244e-01, time/batch = 0.6604s	
16739/25300 (epoch 33.081), train_loss = 0.79837058, grad/param norm = 1.7449e-01, time/batch = 0.6573s	
16740/25300 (epoch 33.083), train_loss = 0.81639528, grad/param norm = 1.8951e-01, time/batch = 0.6600s	
16741/25300 (epoch 33.085), train_loss = 0.97207245, grad/param norm = 2.3070e-01, time/batch = 0.6569s	
16742/25300 (epoch 33.087), train_loss = 0.88033595, grad/param norm = 1.8814e-01, time/batch = 0.6618s	
16743/25300 (epoch 33.089), train_loss = 0.83633411, grad/param norm = 2.0227e-01, time/batch = 0.6619s	
16744/25300 (epoch 33.091), train_loss = 0.99083222, grad/param norm = 2.3196e-01, time/batch = 0.6607s	
16745/25300 (epoch 33.093), train_loss = 0.92450946, grad/param norm = 2.5446e-01, time/batch = 0.6590s	
16746/25300 (epoch 33.095), train_loss = 0.88035914, grad/param norm = 2.2914e-01, time/batch = 0.6533s	
16747/25300 (epoch 33.097), train_loss = 0.85731736, grad/param norm = 2.1383e-01, time/batch = 0.6591s	
16748/25300 (epoch 33.099), train_loss = 0.85700923, grad/param norm = 2.3893e-01, time/batch = 0.6635s	
16749/25300 (epoch 33.101), train_loss = 0.79281992, grad/param norm = 2.1363e-01, time/batch = 0.6587s	
16750/25300 (epoch 33.103), train_loss = 0.82396103, grad/param norm = 2.1969e-01, time/batch = 0.6605s	
16751/25300 (epoch 33.105), train_loss = 0.86812335, grad/param norm = 2.1710e-01, time/batch = 0.6618s	
16752/25300 (epoch 33.107), train_loss = 0.88423865, grad/param norm = 2.2879e-01, time/batch = 0.6625s	
16753/25300 (epoch 33.109), train_loss = 0.78346597, grad/param norm = 2.2231e-01, time/batch = 0.6577s	
16754/25300 (epoch 33.111), train_loss = 0.79240275, grad/param norm = 2.0392e-01, time/batch = 0.6642s	
16755/25300 (epoch 33.113), train_loss = 0.74864368, grad/param norm = 2.1722e-01, time/batch = 0.6782s	
16756/25300 (epoch 33.115), train_loss = 0.78647667, grad/param norm = 2.3909e-01, time/batch = 0.6607s	
16757/25300 (epoch 33.117), train_loss = 0.91038775, grad/param norm = 2.2398e-01, time/batch = 0.6647s	
16758/25300 (epoch 33.119), train_loss = 0.76276168, grad/param norm = 2.2139e-01, time/batch = 0.6610s	
16759/25300 (epoch 33.121), train_loss = 0.80867718, grad/param norm = 2.2823e-01, time/batch = 0.6613s	
16760/25300 (epoch 33.123), train_loss = 0.72926014, grad/param norm = 1.9026e-01, time/batch = 0.6673s	
16761/25300 (epoch 33.125), train_loss = 0.88495719, grad/param norm = 2.0637e-01, time/batch = 0.6664s	
16762/25300 (epoch 33.126), train_loss = 0.81045629, grad/param norm = 1.9571e-01, time/batch = 0.6642s	
16763/25300 (epoch 33.128), train_loss = 0.78995761, grad/param norm = 2.2148e-01, time/batch = 0.6572s	
16764/25300 (epoch 33.130), train_loss = 0.65744644, grad/param norm = 1.8845e-01, time/batch = 0.6642s	
16765/25300 (epoch 33.132), train_loss = 0.66568118, grad/param norm = 2.0117e-01, time/batch = 0.6656s	
16766/25300 (epoch 33.134), train_loss = 0.67608334, grad/param norm = 1.9527e-01, time/batch = 0.6593s	
16767/25300 (epoch 33.136), train_loss = 0.78751428, grad/param norm = 2.0475e-01, time/batch = 0.6579s	
16768/25300 (epoch 33.138), train_loss = 0.69834157, grad/param norm = 1.8624e-01, time/batch = 0.6609s	
16769/25300 (epoch 33.140), train_loss = 0.69856649, grad/param norm = 2.0332e-01, time/batch = 0.6616s	
16770/25300 (epoch 33.142), train_loss = 0.90593236, grad/param norm = 2.3735e-01, time/batch = 0.6622s	
16771/25300 (epoch 33.144), train_loss = 0.87279215, grad/param norm = 2.2181e-01, time/batch = 0.6670s	
16772/25300 (epoch 33.146), train_loss = 0.81371453, grad/param norm = 2.6501e-01, time/batch = 0.6564s	
16773/25300 (epoch 33.148), train_loss = 0.78984995, grad/param norm = 1.9061e-01, time/batch = 0.6657s	
16774/25300 (epoch 33.150), train_loss = 0.83850837, grad/param norm = 2.2103e-01, time/batch = 0.6642s	
16775/25300 (epoch 33.152), train_loss = 0.93040254, grad/param norm = 2.4386e-01, time/batch = 0.6679s	
16776/25300 (epoch 33.154), train_loss = 0.67959191, grad/param norm = 1.7932e-01, time/batch = 0.6617s	
16777/25300 (epoch 33.156), train_loss = 0.83128365, grad/param norm = 2.1115e-01, time/batch = 0.6618s	
16778/25300 (epoch 33.158), train_loss = 0.68818332, grad/param norm = 2.0561e-01, time/batch = 0.6604s	
16779/25300 (epoch 33.160), train_loss = 0.81411232, grad/param norm = 2.3222e-01, time/batch = 0.6589s	
16780/25300 (epoch 33.162), train_loss = 0.74272414, grad/param norm = 2.0952e-01, time/batch = 0.6661s	
16781/25300 (epoch 33.164), train_loss = 0.86643654, grad/param norm = 2.4390e-01, time/batch = 0.6602s	
16782/25300 (epoch 33.166), train_loss = 0.80757881, grad/param norm = 2.1231e-01, time/batch = 0.6682s	
16783/25300 (epoch 33.168), train_loss = 0.73265068, grad/param norm = 1.7355e-01, time/batch = 0.6683s	
16784/25300 (epoch 33.170), train_loss = 0.73295461, grad/param norm = 1.8896e-01, time/batch = 0.6681s	
16785/25300 (epoch 33.172), train_loss = 0.67627939, grad/param norm = 1.9511e-01, time/batch = 0.6571s	
16786/25300 (epoch 33.174), train_loss = 0.71911951, grad/param norm = 2.1256e-01, time/batch = 0.6593s	
16787/25300 (epoch 33.176), train_loss = 0.71328704, grad/param norm = 2.0915e-01, time/batch = 0.6611s	
16788/25300 (epoch 33.178), train_loss = 0.92803731, grad/param norm = 2.3247e-01, time/batch = 0.6663s	
16789/25300 (epoch 33.180), train_loss = 0.65682587, grad/param norm = 2.2576e-01, time/batch = 0.6634s	
16790/25300 (epoch 33.182), train_loss = 0.77804709, grad/param norm = 2.5286e-01, time/batch = 0.6693s	
16791/25300 (epoch 33.184), train_loss = 0.71221433, grad/param norm = 1.9491e-01, time/batch = 0.6619s	
16792/25300 (epoch 33.186), train_loss = 0.67063277, grad/param norm = 1.9027e-01, time/batch = 0.6658s	
16793/25300 (epoch 33.188), train_loss = 0.79752573, grad/param norm = 2.7358e-01, time/batch = 0.6619s	
16794/25300 (epoch 33.190), train_loss = 0.79594383, grad/param norm = 3.0780e-01, time/batch = 0.6588s	
16795/25300 (epoch 33.192), train_loss = 0.76674986, grad/param norm = 2.1065e-01, time/batch = 0.6630s	
16796/25300 (epoch 33.194), train_loss = 0.75448130, grad/param norm = 2.1631e-01, time/batch = 0.6555s	
16797/25300 (epoch 33.196), train_loss = 0.90792269, grad/param norm = 2.6566e-01, time/batch = 0.6617s	
16798/25300 (epoch 33.198), train_loss = 0.74562792, grad/param norm = 2.3000e-01, time/batch = 0.6592s	
16799/25300 (epoch 33.200), train_loss = 0.76591469, grad/param norm = 2.2289e-01, time/batch = 0.6593s	
16800/25300 (epoch 33.202), train_loss = 0.76531653, grad/param norm = 2.0494e-01, time/batch = 0.6654s	
16801/25300 (epoch 33.204), train_loss = 0.78431963, grad/param norm = 2.0352e-01, time/batch = 0.6669s	
16802/25300 (epoch 33.206), train_loss = 0.88225782, grad/param norm = 2.4049e-01, time/batch = 0.6646s	
16803/25300 (epoch 33.208), train_loss = 0.72079025, grad/param norm = 2.1883e-01, time/batch = 0.6605s	
16804/25300 (epoch 33.209), train_loss = 0.68240295, grad/param norm = 2.1061e-01, time/batch = 0.6642s	
16805/25300 (epoch 33.211), train_loss = 0.76785166, grad/param norm = 2.1826e-01, time/batch = 0.6647s	
16806/25300 (epoch 33.213), train_loss = 0.83271277, grad/param norm = 2.5860e-01, time/batch = 0.6637s	
16807/25300 (epoch 33.215), train_loss = 0.82194518, grad/param norm = 2.1580e-01, time/batch = 0.6628s	
16808/25300 (epoch 33.217), train_loss = 0.82972652, grad/param norm = 2.4405e-01, time/batch = 0.6576s	
16809/25300 (epoch 33.219), train_loss = 0.88035350, grad/param norm = 2.2942e-01, time/batch = 0.6643s	
16810/25300 (epoch 33.221), train_loss = 0.91771389, grad/param norm = 2.3363e-01, time/batch = 0.6579s	
16811/25300 (epoch 33.223), train_loss = 0.85521513, grad/param norm = 2.4459e-01, time/batch = 0.6586s	
16812/25300 (epoch 33.225), train_loss = 1.08280240, grad/param norm = 3.4118e-01, time/batch = 0.6616s	
16813/25300 (epoch 33.227), train_loss = 0.90959610, grad/param norm = 2.3545e-01, time/batch = 0.6611s	
16814/25300 (epoch 33.229), train_loss = 0.77606867, grad/param norm = 2.0990e-01, time/batch = 0.6587s	
16815/25300 (epoch 33.231), train_loss = 0.81344078, grad/param norm = 2.2818e-01, time/batch = 0.6628s	
16816/25300 (epoch 33.233), train_loss = 0.85554287, grad/param norm = 2.6801e-01, time/batch = 0.6573s	
16817/25300 (epoch 33.235), train_loss = 0.78484421, grad/param norm = 2.2395e-01, time/batch = 0.6603s	
16818/25300 (epoch 33.237), train_loss = 0.93065007, grad/param norm = 2.4965e-01, time/batch = 0.6634s	
16819/25300 (epoch 33.239), train_loss = 0.75778051, grad/param norm = 2.1199e-01, time/batch = 0.6676s	
16820/25300 (epoch 33.241), train_loss = 0.93576017, grad/param norm = 2.2119e-01, time/batch = 0.6611s	
16821/25300 (epoch 33.243), train_loss = 1.06217492, grad/param norm = 2.7850e-01, time/batch = 0.6601s	
16822/25300 (epoch 33.245), train_loss = 0.77913039, grad/param norm = 2.4448e-01, time/batch = 0.6623s	
16823/25300 (epoch 33.247), train_loss = 0.85974115, grad/param norm = 2.3064e-01, time/batch = 0.6628s	
16824/25300 (epoch 33.249), train_loss = 0.69332493, grad/param norm = 1.8952e-01, time/batch = 0.6604s	
16825/25300 (epoch 33.251), train_loss = 0.70718468, grad/param norm = 2.4503e-01, time/batch = 0.6656s	
16826/25300 (epoch 33.253), train_loss = 0.79008082, grad/param norm = 2.2498e-01, time/batch = 0.6668s	
16827/25300 (epoch 33.255), train_loss = 0.73839140, grad/param norm = 2.2520e-01, time/batch = 0.6658s	
16828/25300 (epoch 33.257), train_loss = 0.76679918, grad/param norm = 2.2468e-01, time/batch = 0.6586s	
16829/25300 (epoch 33.259), train_loss = 0.97280610, grad/param norm = 2.8189e-01, time/batch = 0.6623s	
16830/25300 (epoch 33.261), train_loss = 0.91273210, grad/param norm = 2.6072e-01, time/batch = 0.6738s	
16831/25300 (epoch 33.263), train_loss = 0.95574398, grad/param norm = 2.5325e-01, time/batch = 0.6649s	
16832/25300 (epoch 33.265), train_loss = 0.96781715, grad/param norm = 2.4709e-01, time/batch = 0.6613s	
16833/25300 (epoch 33.267), train_loss = 0.86148650, grad/param norm = 2.1722e-01, time/batch = 0.6597s	
16834/25300 (epoch 33.269), train_loss = 0.68189438, grad/param norm = 1.9956e-01, time/batch = 0.6588s	
16835/25300 (epoch 33.271), train_loss = 0.74632614, grad/param norm = 2.1611e-01, time/batch = 0.6607s	
16836/25300 (epoch 33.273), train_loss = 0.87545432, grad/param norm = 2.3810e-01, time/batch = 0.6613s	
16837/25300 (epoch 33.275), train_loss = 0.76932763, grad/param norm = 2.0390e-01, time/batch = 0.6766s	
16838/25300 (epoch 33.277), train_loss = 0.75943613, grad/param norm = 2.7163e-01, time/batch = 0.6766s	
16839/25300 (epoch 33.279), train_loss = 0.81386499, grad/param norm = 2.2107e-01, time/batch = 0.6721s	
16840/25300 (epoch 33.281), train_loss = 0.96540328, grad/param norm = 2.6921e-01, time/batch = 0.6688s	
16841/25300 (epoch 33.283), train_loss = 0.71070677, grad/param norm = 2.1087e-01, time/batch = 0.6716s	
16842/25300 (epoch 33.285), train_loss = 0.83609022, grad/param norm = 2.4615e-01, time/batch = 0.6710s	
16843/25300 (epoch 33.287), train_loss = 0.92286238, grad/param norm = 2.0922e-01, time/batch = 0.6725s	
16844/25300 (epoch 33.289), train_loss = 0.76708214, grad/param norm = 2.1812e-01, time/batch = 0.6606s	
16845/25300 (epoch 33.291), train_loss = 0.77508884, grad/param norm = 2.0335e-01, time/batch = 0.6577s	
16846/25300 (epoch 33.292), train_loss = 0.96642339, grad/param norm = 2.1582e-01, time/batch = 0.6564s	
16847/25300 (epoch 33.294), train_loss = 0.85466799, grad/param norm = 2.2624e-01, time/batch = 0.6618s	
16848/25300 (epoch 33.296), train_loss = 0.72261935, grad/param norm = 1.9853e-01, time/batch = 0.6615s	
16849/25300 (epoch 33.298), train_loss = 0.88689571, grad/param norm = 2.2397e-01, time/batch = 0.6572s	
16850/25300 (epoch 33.300), train_loss = 0.89916521, grad/param norm = 2.2131e-01, time/batch = 0.6591s	
16851/25300 (epoch 33.302), train_loss = 0.66291306, grad/param norm = 2.1651e-01, time/batch = 0.6625s	
16852/25300 (epoch 33.304), train_loss = 0.91777168, grad/param norm = 1.9301e-01, time/batch = 0.6626s	
16853/25300 (epoch 33.306), train_loss = 0.64914032, grad/param norm = 2.0288e-01, time/batch = 0.6609s	
16854/25300 (epoch 33.308), train_loss = 0.86870926, grad/param norm = 1.9349e-01, time/batch = 0.6606s	
16855/25300 (epoch 33.310), train_loss = 0.70059861, grad/param norm = 2.0149e-01, time/batch = 0.6700s	
16856/25300 (epoch 33.312), train_loss = 0.83106642, grad/param norm = 1.9500e-01, time/batch = 0.7096s	
16857/25300 (epoch 33.314), train_loss = 0.67954778, grad/param norm = 2.2724e-01, time/batch = 0.9698s	
16858/25300 (epoch 33.316), train_loss = 0.81827241, grad/param norm = 2.0420e-01, time/batch = 0.9676s	
16859/25300 (epoch 33.318), train_loss = 0.66744834, grad/param norm = 1.9654e-01, time/batch = 0.9681s	
16860/25300 (epoch 33.320), train_loss = 0.74560150, grad/param norm = 2.1285e-01, time/batch = 0.9656s	
16861/25300 (epoch 33.322), train_loss = 0.95004414, grad/param norm = 2.5892e-01, time/batch = 1.0089s	
16862/25300 (epoch 33.324), train_loss = 0.72130915, grad/param norm = 2.0226e-01, time/batch = 1.7955s	
16863/25300 (epoch 33.326), train_loss = 0.64825845, grad/param norm = 1.7982e-01, time/batch = 1.8144s	
16864/25300 (epoch 33.328), train_loss = 0.64942385, grad/param norm = 2.1563e-01, time/batch = 5.7311s	
16865/25300 (epoch 33.330), train_loss = 0.76527059, grad/param norm = 1.9961e-01, time/batch = 15.5676s	
16866/25300 (epoch 33.332), train_loss = 0.81854664, grad/param norm = 1.9887e-01, time/batch = 15.6539s	
16867/25300 (epoch 33.334), train_loss = 0.67075678, grad/param norm = 2.1671e-01, time/batch = 15.6526s	
16868/25300 (epoch 33.336), train_loss = 0.68052815, grad/param norm = 2.0038e-01, time/batch = 15.4670s	
16869/25300 (epoch 33.338), train_loss = 0.70276887, grad/param norm = 2.2806e-01, time/batch = 15.4043s	
16870/25300 (epoch 33.340), train_loss = 0.73655464, grad/param norm = 2.2867e-01, time/batch = 15.4030s	
16871/25300 (epoch 33.342), train_loss = 0.74344687, grad/param norm = 2.0541e-01, time/batch = 15.7471s	
16872/25300 (epoch 33.344), train_loss = 0.85893435, grad/param norm = 2.5436e-01, time/batch = 15.7345s	
16873/25300 (epoch 33.346), train_loss = 0.74086438, grad/param norm = 2.2450e-01, time/batch = 16.6610s	
16874/25300 (epoch 33.348), train_loss = 0.70994127, grad/param norm = 2.0901e-01, time/batch = 16.1551s	
16875/25300 (epoch 33.350), train_loss = 0.75593434, grad/param norm = 2.3033e-01, time/batch = 15.9814s	
16876/25300 (epoch 33.352), train_loss = 0.78746235, grad/param norm = 2.0426e-01, time/batch = 15.6321s	
16877/25300 (epoch 33.354), train_loss = 0.73164056, grad/param norm = 2.0134e-01, time/batch = 15.4073s	
16878/25300 (epoch 33.356), train_loss = 0.77425527, grad/param norm = 2.0102e-01, time/batch = 15.4794s	
16879/25300 (epoch 33.358), train_loss = 0.80524359, grad/param norm = 2.1392e-01, time/batch = 15.9855s	
16880/25300 (epoch 33.360), train_loss = 0.71451830, grad/param norm = 2.0814e-01, time/batch = 15.5726s	
16881/25300 (epoch 33.362), train_loss = 0.68601542, grad/param norm = 2.1540e-01, time/batch = 15.6411s	
16882/25300 (epoch 33.364), train_loss = 0.73567841, grad/param norm = 2.5955e-01, time/batch = 15.6630s	
16883/25300 (epoch 33.366), train_loss = 0.69240152, grad/param norm = 2.0398e-01, time/batch = 15.3080s	
16884/25300 (epoch 33.368), train_loss = 0.76649748, grad/param norm = 2.0582e-01, time/batch = 15.5580s	
16885/25300 (epoch 33.370), train_loss = 0.70603067, grad/param norm = 1.9979e-01, time/batch = 15.4005s	
16886/25300 (epoch 33.372), train_loss = 0.71082620, grad/param norm = 2.3184e-01, time/batch = 15.5035s	
16887/25300 (epoch 33.374), train_loss = 0.66930825, grad/param norm = 2.1245e-01, time/batch = 15.4674s	
16888/25300 (epoch 33.375), train_loss = 0.87131462, grad/param norm = 2.5502e-01, time/batch = 15.5694s	
16889/25300 (epoch 33.377), train_loss = 0.85058034, grad/param norm = 2.1318e-01, time/batch = 15.3201s	
16890/25300 (epoch 33.379), train_loss = 0.81768367, grad/param norm = 2.1458e-01, time/batch = 15.1268s	
16891/25300 (epoch 33.381), train_loss = 0.74954109, grad/param norm = 1.9981e-01, time/batch = 15.5503s	
16892/25300 (epoch 33.383), train_loss = 0.71976712, grad/param norm = 2.3459e-01, time/batch = 16.0667s	
16893/25300 (epoch 33.385), train_loss = 0.80154487, grad/param norm = 1.8803e-01, time/batch = 15.3876s	
16894/25300 (epoch 33.387), train_loss = 0.78090425, grad/param norm = 2.2390e-01, time/batch = 15.1710s	
16895/25300 (epoch 33.389), train_loss = 0.78748375, grad/param norm = 2.4259e-01, time/batch = 15.2909s	
16896/25300 (epoch 33.391), train_loss = 0.73379903, grad/param norm = 2.0287e-01, time/batch = 15.4970s	
16897/25300 (epoch 33.393), train_loss = 0.80265379, grad/param norm = 2.3861e-01, time/batch = 15.7459s	
16898/25300 (epoch 33.395), train_loss = 0.63450796, grad/param norm = 1.9823e-01, time/batch = 15.4026s	
16899/25300 (epoch 33.397), train_loss = 0.61956848, grad/param norm = 2.0970e-01, time/batch = 15.3835s	
16900/25300 (epoch 33.399), train_loss = 0.67605814, grad/param norm = 2.0360e-01, time/batch = 15.8220s	
16901/25300 (epoch 33.401), train_loss = 0.81531012, grad/param norm = 2.1877e-01, time/batch = 15.9161s	
16902/25300 (epoch 33.403), train_loss = 0.80239604, grad/param norm = 3.2011e-01, time/batch = 16.5637s	
16903/25300 (epoch 33.405), train_loss = 0.74545745, grad/param norm = 2.2023e-01, time/batch = 15.9747s	
16904/25300 (epoch 33.407), train_loss = 0.74889047, grad/param norm = 2.0969e-01, time/batch = 16.1558s	
16905/25300 (epoch 33.409), train_loss = 0.69750800, grad/param norm = 1.9780e-01, time/batch = 16.1625s	
16906/25300 (epoch 33.411), train_loss = 0.72728899, grad/param norm = 2.2045e-01, time/batch = 19.7615s	
16907/25300 (epoch 33.413), train_loss = 0.64410500, grad/param norm = 2.0263e-01, time/batch = 24.4025s	
16908/25300 (epoch 33.415), train_loss = 0.69894666, grad/param norm = 2.1542e-01, time/batch = 16.0793s	
16909/25300 (epoch 33.417), train_loss = 0.66276137, grad/param norm = 2.0653e-01, time/batch = 15.7495s	
16910/25300 (epoch 33.419), train_loss = 0.58690777, grad/param norm = 1.6536e-01, time/batch = 15.9875s	
16911/25300 (epoch 33.421), train_loss = 0.64695766, grad/param norm = 1.6918e-01, time/batch = 16.3966s	
16912/25300 (epoch 33.423), train_loss = 0.64930931, grad/param norm = 2.0389e-01, time/batch = 15.9803s	
16913/25300 (epoch 33.425), train_loss = 0.74841316, grad/param norm = 3.3827e-01, time/batch = 15.2723s	
16914/25300 (epoch 33.427), train_loss = 0.86443913, grad/param norm = 2.1841e-01, time/batch = 15.8989s	
16915/25300 (epoch 33.429), train_loss = 0.87374105, grad/param norm = 2.5770e-01, time/batch = 16.2469s	
16916/25300 (epoch 33.431), train_loss = 0.78310489, grad/param norm = 2.1582e-01, time/batch = 15.5766s	
16917/25300 (epoch 33.433), train_loss = 0.80854143, grad/param norm = 2.0773e-01, time/batch = 15.7082s	
16918/25300 (epoch 33.435), train_loss = 0.72003537, grad/param norm = 2.4792e-01, time/batch = 15.8237s	
16919/25300 (epoch 33.437), train_loss = 0.69300559, grad/param norm = 2.1156e-01, time/batch = 15.9057s	
16920/25300 (epoch 33.439), train_loss = 0.78565419, grad/param norm = 2.0705e-01, time/batch = 15.5631s	
16921/25300 (epoch 33.441), train_loss = 0.81794131, grad/param norm = 2.1926e-01, time/batch = 16.0614s	
16922/25300 (epoch 33.443), train_loss = 0.93200197, grad/param norm = 2.6698e-01, time/batch = 15.4891s	
16923/25300 (epoch 33.445), train_loss = 0.88376616, grad/param norm = 2.5955e-01, time/batch = 16.4866s	
16924/25300 (epoch 33.447), train_loss = 0.70189114, grad/param norm = 1.7749e-01, time/batch = 15.3029s	
16925/25300 (epoch 33.449), train_loss = 0.65814327, grad/param norm = 2.9266e-01, time/batch = 15.6519s	
16926/25300 (epoch 33.451), train_loss = 0.97627090, grad/param norm = 2.5344e-01, time/batch = 15.9957s	
16927/25300 (epoch 33.453), train_loss = 0.83045369, grad/param norm = 2.4813e-01, time/batch = 15.9877s	
16928/25300 (epoch 33.455), train_loss = 0.80892014, grad/param norm = 2.4126e-01, time/batch = 16.2272s	
16929/25300 (epoch 33.457), train_loss = 0.72324667, grad/param norm = 2.0201e-01, time/batch = 15.4654s	
16930/25300 (epoch 33.458), train_loss = 0.73133973, grad/param norm = 1.9748e-01, time/batch = 15.5050s	
16931/25300 (epoch 33.460), train_loss = 0.75422473, grad/param norm = 2.2247e-01, time/batch = 15.2492s	
16932/25300 (epoch 33.462), train_loss = 0.55508589, grad/param norm = 1.7795e-01, time/batch = 15.1335s	
16933/25300 (epoch 33.464), train_loss = 0.85094136, grad/param norm = 2.4017e-01, time/batch = 15.6493s	
16934/25300 (epoch 33.466), train_loss = 0.80086200, grad/param norm = 2.0899e-01, time/batch = 15.6487s	
16935/25300 (epoch 33.468), train_loss = 0.81332187, grad/param norm = 2.0264e-01, time/batch = 15.5880s	
16936/25300 (epoch 33.470), train_loss = 0.74909383, grad/param norm = 2.1096e-01, time/batch = 15.1618s	
16937/25300 (epoch 33.472), train_loss = 0.63414472, grad/param norm = 1.7675e-01, time/batch = 15.2559s	
16938/25300 (epoch 33.474), train_loss = 0.81728706, grad/param norm = 2.0638e-01, time/batch = 15.3362s	
16939/25300 (epoch 33.476), train_loss = 0.73483133, grad/param norm = 2.2273e-01, time/batch = 15.3445s	
16940/25300 (epoch 33.478), train_loss = 0.83112013, grad/param norm = 2.3710e-01, time/batch = 15.3858s	
16941/25300 (epoch 33.480), train_loss = 0.72857546, grad/param norm = 1.8930e-01, time/batch = 15.6656s	
16942/25300 (epoch 33.482), train_loss = 0.79925035, grad/param norm = 2.3174e-01, time/batch = 15.6628s	
16943/25300 (epoch 33.484), train_loss = 0.83969545, grad/param norm = 2.6162e-01, time/batch = 15.2922s	
16944/25300 (epoch 33.486), train_loss = 0.77378768, grad/param norm = 2.4921e-01, time/batch = 15.2303s	
16945/25300 (epoch 33.488), train_loss = 0.93344243, grad/param norm = 2.4715e-01, time/batch = 15.5650s	
16946/25300 (epoch 33.490), train_loss = 0.81050200, grad/param norm = 2.0177e-01, time/batch = 16.1520s	
16947/25300 (epoch 33.492), train_loss = 0.88012019, grad/param norm = 2.1101e-01, time/batch = 15.6628s	
16948/25300 (epoch 33.494), train_loss = 0.76503548, grad/param norm = 2.0165e-01, time/batch = 15.9126s	
16949/25300 (epoch 33.496), train_loss = 0.81405389, grad/param norm = 2.0408e-01, time/batch = 15.2986s	
16950/25300 (epoch 33.498), train_loss = 0.75453929, grad/param norm = 1.8436e-01, time/batch = 16.0841s	
16951/25300 (epoch 33.500), train_loss = 0.92895045, grad/param norm = 2.3838e-01, time/batch = 15.5702s	
16952/25300 (epoch 33.502), train_loss = 0.83928844, grad/param norm = 2.6026e-01, time/batch = 15.5552s	
16953/25300 (epoch 33.504), train_loss = 0.74321984, grad/param norm = 1.9678e-01, time/batch = 15.4023s	
16954/25300 (epoch 33.506), train_loss = 0.68100008, grad/param norm = 2.3568e-01, time/batch = 15.5014s	
16955/25300 (epoch 33.508), train_loss = 0.76511640, grad/param norm = 2.2573e-01, time/batch = 15.6550s	
16956/25300 (epoch 33.510), train_loss = 0.72804154, grad/param norm = 2.1582e-01, time/batch = 17.3950s	
16957/25300 (epoch 33.512), train_loss = 0.58937765, grad/param norm = 1.9020e-01, time/batch = 15.9730s	
16958/25300 (epoch 33.514), train_loss = 0.74221910, grad/param norm = 2.0149e-01, time/batch = 16.2398s	
16959/25300 (epoch 33.516), train_loss = 0.83360643, grad/param norm = 2.3588e-01, time/batch = 15.1678s	
16960/25300 (epoch 33.518), train_loss = 0.86795735, grad/param norm = 2.4069e-01, time/batch = 15.9111s	
16961/25300 (epoch 33.520), train_loss = 0.64299723, grad/param norm = 1.7014e-01, time/batch = 15.7498s	
16962/25300 (epoch 33.522), train_loss = 0.71105391, grad/param norm = 2.0823e-01, time/batch = 16.2184s	
16963/25300 (epoch 33.524), train_loss = 0.70396428, grad/param norm = 2.2324e-01, time/batch = 15.8268s	
16964/25300 (epoch 33.526), train_loss = 0.89111831, grad/param norm = 2.3338e-01, time/batch = 16.0027s	
16965/25300 (epoch 33.528), train_loss = 0.89270239, grad/param norm = 2.2978e-01, time/batch = 15.7483s	
16966/25300 (epoch 33.530), train_loss = 0.83065067, grad/param norm = 2.4902e-01, time/batch = 15.8144s	
16967/25300 (epoch 33.532), train_loss = 0.75058718, grad/param norm = 2.0786e-01, time/batch = 16.3734s	
16968/25300 (epoch 33.534), train_loss = 0.75766731, grad/param norm = 2.5538e-01, time/batch = 15.7506s	
16969/25300 (epoch 33.536), train_loss = 0.61648595, grad/param norm = 2.4027e-01, time/batch = 16.1622s	
16970/25300 (epoch 33.538), train_loss = 0.68247235, grad/param norm = 1.9319e-01, time/batch = 15.6479s	
16971/25300 (epoch 33.540), train_loss = 0.68036912, grad/param norm = 1.9204e-01, time/batch = 15.6493s	
16972/25300 (epoch 33.542), train_loss = 0.65606244, grad/param norm = 1.9008e-01, time/batch = 16.4849s	
16973/25300 (epoch 33.543), train_loss = 0.63178981, grad/param norm = 1.7675e-01, time/batch = 15.8285s	
16974/25300 (epoch 33.545), train_loss = 0.96676356, grad/param norm = 3.1018e-01, time/batch = 15.4038s	
16975/25300 (epoch 33.547), train_loss = 0.85024923, grad/param norm = 2.2691e-01, time/batch = 16.1456s	
16976/25300 (epoch 33.549), train_loss = 0.97548573, grad/param norm = 3.0006e-01, time/batch = 15.3023s	
16977/25300 (epoch 33.551), train_loss = 0.88241864, grad/param norm = 2.0638e-01, time/batch = 15.7122s	
16978/25300 (epoch 33.553), train_loss = 0.71751018, grad/param norm = 2.2786e-01, time/batch = 15.8861s	
16979/25300 (epoch 33.555), train_loss = 0.86646487, grad/param norm = 2.8455e-01, time/batch = 15.4180s	
16980/25300 (epoch 33.557), train_loss = 0.85610271, grad/param norm = 2.5030e-01, time/batch = 15.6626s	
16981/25300 (epoch 33.559), train_loss = 0.90096484, grad/param norm = 2.2598e-01, time/batch = 15.5771s	
16982/25300 (epoch 33.561), train_loss = 0.90820206, grad/param norm = 2.4192e-01, time/batch = 15.6420s	
16983/25300 (epoch 33.563), train_loss = 0.86820955, grad/param norm = 2.3207e-01, time/batch = 15.7426s	
16984/25300 (epoch 33.565), train_loss = 0.68558464, grad/param norm = 2.1028e-01, time/batch = 15.8285s	
16985/25300 (epoch 33.567), train_loss = 0.62856392, grad/param norm = 2.0515e-01, time/batch = 15.8987s	
16986/25300 (epoch 33.569), train_loss = 0.80254848, grad/param norm = 2.2231e-01, time/batch = 15.6649s	
16987/25300 (epoch 33.571), train_loss = 0.85671266, grad/param norm = 2.2895e-01, time/batch = 15.7431s	
16988/25300 (epoch 33.573), train_loss = 0.76662692, grad/param norm = 2.0267e-01, time/batch = 16.6530s	
16989/25300 (epoch 33.575), train_loss = 0.83767328, grad/param norm = 2.2055e-01, time/batch = 16.1345s	
16990/25300 (epoch 33.577), train_loss = 0.74681905, grad/param norm = 2.6695e-01, time/batch = 16.0558s	
16991/25300 (epoch 33.579), train_loss = 0.89261099, grad/param norm = 2.3577e-01, time/batch = 15.4166s	
16992/25300 (epoch 33.581), train_loss = 0.85418316, grad/param norm = 2.3594e-01, time/batch = 15.4796s	
16993/25300 (epoch 33.583), train_loss = 0.67035144, grad/param norm = 2.2896e-01, time/batch = 15.4060s	
16994/25300 (epoch 33.585), train_loss = 0.67393507, grad/param norm = 2.2571e-01, time/batch = 15.6515s	
16995/25300 (epoch 33.587), train_loss = 0.77520273, grad/param norm = 2.2586e-01, time/batch = 15.7639s	
16996/25300 (epoch 33.589), train_loss = 0.69193172, grad/param norm = 1.7925e-01, time/batch = 15.5530s	
16997/25300 (epoch 33.591), train_loss = 0.65245043, grad/param norm = 2.6022e-01, time/batch = 15.8310s	
16998/25300 (epoch 33.593), train_loss = 0.84255146, grad/param norm = 2.4586e-01, time/batch = 15.4216s	
16999/25300 (epoch 33.595), train_loss = 0.77087116, grad/param norm = 2.0265e-01, time/batch = 15.9883s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch33.60_1.7256.t7	
17000/25300 (epoch 33.597), train_loss = 0.68955629, grad/param norm = 1.8945e-01, time/batch = 15.7216s	
17001/25300 (epoch 33.599), train_loss = 1.39622621, grad/param norm = 3.2697e-01, time/batch = 15.7897s	
17002/25300 (epoch 33.601), train_loss = 0.77283362, grad/param norm = 2.2869e-01, time/batch = 16.4882s	
17003/25300 (epoch 33.603), train_loss = 0.76677344, grad/param norm = 2.1313e-01, time/batch = 15.9882s	
17004/25300 (epoch 33.605), train_loss = 0.77479701, grad/param norm = 2.4545e-01, time/batch = 16.2498s	
17005/25300 (epoch 33.607), train_loss = 0.55986413, grad/param norm = 1.7272e-01, time/batch = 15.9115s	
17006/25300 (epoch 33.609), train_loss = 0.71307030, grad/param norm = 2.1622e-01, time/batch = 15.5966s	
17007/25300 (epoch 33.611), train_loss = 0.80324550, grad/param norm = 2.3980e-01, time/batch = 17.2547s	
17008/25300 (epoch 33.613), train_loss = 0.67972147, grad/param norm = 1.8453e-01, time/batch = 15.9824s	
17009/25300 (epoch 33.615), train_loss = 0.73309502, grad/param norm = 2.7710e-01, time/batch = 16.1508s	
17010/25300 (epoch 33.617), train_loss = 0.77350453, grad/param norm = 2.4941e-01, time/batch = 17.1382s	
17011/25300 (epoch 33.619), train_loss = 0.81842894, grad/param norm = 2.3233e-01, time/batch = 16.8233s	
17012/25300 (epoch 33.621), train_loss = 0.84923704, grad/param norm = 1.9998e-01, time/batch = 15.4511s	
17013/25300 (epoch 33.623), train_loss = 0.72671103, grad/param norm = 2.1059e-01, time/batch = 16.0651s	
17014/25300 (epoch 33.625), train_loss = 0.65294534, grad/param norm = 2.0043e-01, time/batch = 15.2746s	
17015/25300 (epoch 33.626), train_loss = 0.74504228, grad/param norm = 1.8252e-01, time/batch = 15.2992s	
17016/25300 (epoch 33.628), train_loss = 0.88531702, grad/param norm = 2.5559e-01, time/batch = 15.3582s	
17017/25300 (epoch 33.630), train_loss = 0.83305457, grad/param norm = 2.2313e-01, time/batch = 15.2883s	
17018/25300 (epoch 33.632), train_loss = 0.80008325, grad/param norm = 2.5699e-01, time/batch = 15.3597s	
17019/25300 (epoch 33.634), train_loss = 0.90089391, grad/param norm = 2.9835e-01, time/batch = 15.7010s	
17020/25300 (epoch 33.636), train_loss = 0.70379012, grad/param norm = 2.2605e-01, time/batch = 15.7010s	
17021/25300 (epoch 33.638), train_loss = 0.81439160, grad/param norm = 2.8432e-01, time/batch = 15.7145s	
17022/25300 (epoch 33.640), train_loss = 0.98718461, grad/param norm = 3.1934e-01, time/batch = 15.4175s	
17023/25300 (epoch 33.642), train_loss = 0.82020695, grad/param norm = 2.4093e-01, time/batch = 15.6168s	
17024/25300 (epoch 33.644), train_loss = 0.79133334, grad/param norm = 2.3077e-01, time/batch = 15.5500s	
17025/25300 (epoch 33.646), train_loss = 0.72827207, grad/param norm = 2.6169e-01, time/batch = 16.3979s	
17026/25300 (epoch 33.648), train_loss = 0.86391118, grad/param norm = 1.8741e-01, time/batch = 16.4179s	
17027/25300 (epoch 33.650), train_loss = 0.79329353, grad/param norm = 2.0900e-01, time/batch = 15.6443s	
17028/25300 (epoch 33.652), train_loss = 0.80761584, grad/param norm = 2.2515e-01, time/batch = 15.5745s	
17029/25300 (epoch 33.654), train_loss = 0.92282276, grad/param norm = 2.3763e-01, time/batch = 15.4847s	
17030/25300 (epoch 33.656), train_loss = 0.85337256, grad/param norm = 2.5512e-01, time/batch = 15.4063s	
17031/25300 (epoch 33.658), train_loss = 0.61970108, grad/param norm = 1.7087e-01, time/batch = 16.1153s	
17032/25300 (epoch 33.660), train_loss = 0.65597872, grad/param norm = 2.4766e-01, time/batch = 15.4817s	
17033/25300 (epoch 33.662), train_loss = 0.65100476, grad/param norm = 1.8012e-01, time/batch = 15.7400s	
17034/25300 (epoch 33.664), train_loss = 0.63469573, grad/param norm = 2.1119e-01, time/batch = 15.5623s	
17035/25300 (epoch 33.666), train_loss = 0.67639236, grad/param norm = 2.0856e-01, time/batch = 15.3775s	
17036/25300 (epoch 33.668), train_loss = 0.78827501, grad/param norm = 3.0519e-01, time/batch = 16.2348s	
17037/25300 (epoch 33.670), train_loss = 0.71380332, grad/param norm = 2.3042e-01, time/batch = 15.7312s	
17038/25300 (epoch 33.672), train_loss = 0.70664873, grad/param norm = 2.1183e-01, time/batch = 15.7341s	
17039/25300 (epoch 33.674), train_loss = 0.69953837, grad/param norm = 1.8322e-01, time/batch = 15.7115s	
17040/25300 (epoch 33.676), train_loss = 0.70873852, grad/param norm = 2.3814e-01, time/batch = 16.0595s	
17041/25300 (epoch 33.678), train_loss = 0.72261449, grad/param norm = 2.4230e-01, time/batch = 15.6076s	
17042/25300 (epoch 33.680), train_loss = 0.63097665, grad/param norm = 1.7101e-01, time/batch = 15.5495s	
17043/25300 (epoch 33.682), train_loss = 0.54293523, grad/param norm = 1.7994e-01, time/batch = 15.5754s	
17044/25300 (epoch 33.684), train_loss = 0.68943139, grad/param norm = 1.8438e-01, time/batch = 15.6575s	
17045/25300 (epoch 33.686), train_loss = 0.65499429, grad/param norm = 1.9608e-01, time/batch = 15.7443s	
17046/25300 (epoch 33.688), train_loss = 0.73377884, grad/param norm = 2.2509e-01, time/batch = 15.7216s	
17047/25300 (epoch 33.690), train_loss = 0.64967847, grad/param norm = 1.9043e-01, time/batch = 16.2854s	
17048/25300 (epoch 33.692), train_loss = 0.69188419, grad/param norm = 1.8533e-01, time/batch = 16.3230s	
17049/25300 (epoch 33.694), train_loss = 0.68320310, grad/param norm = 2.1571e-01, time/batch = 16.1595s	
17050/25300 (epoch 33.696), train_loss = 0.75386503, grad/param norm = 2.2918e-01, time/batch = 15.4707s	
17051/25300 (epoch 33.698), train_loss = 0.82555142, grad/param norm = 2.3324e-01, time/batch = 15.9698s	
17052/25300 (epoch 33.700), train_loss = 0.61134239, grad/param norm = 1.8276e-01, time/batch = 15.6537s	
17053/25300 (epoch 33.702), train_loss = 0.80864621, grad/param norm = 2.2188e-01, time/batch = 15.5762s	
17054/25300 (epoch 33.704), train_loss = 0.59038297, grad/param norm = 1.7030e-01, time/batch = 15.8149s	
17055/25300 (epoch 33.706), train_loss = 0.73559242, grad/param norm = 2.1336e-01, time/batch = 15.7528s	
17056/25300 (epoch 33.708), train_loss = 0.63571076, grad/param norm = 1.8833e-01, time/batch = 15.5762s	
17057/25300 (epoch 33.709), train_loss = 0.87538895, grad/param norm = 2.2894e-01, time/batch = 15.3282s	
17058/25300 (epoch 33.711), train_loss = 0.91667401, grad/param norm = 2.4097e-01, time/batch = 15.3983s	
17059/25300 (epoch 33.713), train_loss = 0.76867752, grad/param norm = 2.0660e-01, time/batch = 15.9145s	
17060/25300 (epoch 33.715), train_loss = 0.75392811, grad/param norm = 1.8698e-01, time/batch = 15.4989s	
17061/25300 (epoch 33.717), train_loss = 0.67221675, grad/param norm = 2.3862e-01, time/batch = 15.4076s	
17062/25300 (epoch 33.719), train_loss = 0.75650755, grad/param norm = 2.1953e-01, time/batch = 15.5643s	
17063/25300 (epoch 33.721), train_loss = 0.80637249, grad/param norm = 2.4103e-01, time/batch = 15.5786s	
17064/25300 (epoch 33.723), train_loss = 0.75472669, grad/param norm = 2.3343e-01, time/batch = 15.5019s	
17065/25300 (epoch 33.725), train_loss = 0.78365566, grad/param norm = 2.4211e-01, time/batch = 15.4669s	
17066/25300 (epoch 33.727), train_loss = 0.76095228, grad/param norm = 2.1498e-01, time/batch = 15.4086s	
17067/25300 (epoch 33.729), train_loss = 0.74157288, grad/param norm = 2.0704e-01, time/batch = 16.3267s	
17068/25300 (epoch 33.731), train_loss = 0.89766786, grad/param norm = 2.2424e-01, time/batch = 15.5796s	
17069/25300 (epoch 33.733), train_loss = 0.73528579, grad/param norm = 1.8277e-01, time/batch = 15.6217s	
17070/25300 (epoch 33.735), train_loss = 0.96131364, grad/param norm = 2.3638e-01, time/batch = 15.4959s	
17071/25300 (epoch 33.737), train_loss = 0.63915686, grad/param norm = 1.8474e-01, time/batch = 15.9908s	
17072/25300 (epoch 33.739), train_loss = 0.89623919, grad/param norm = 2.2662e-01, time/batch = 16.4055s	
17073/25300 (epoch 33.741), train_loss = 0.80447198, grad/param norm = 2.2848e-01, time/batch = 15.5708s	
17074/25300 (epoch 33.743), train_loss = 0.76889088, grad/param norm = 2.1843e-01, time/batch = 15.4931s	
17075/25300 (epoch 33.745), train_loss = 0.73897390, grad/param norm = 2.4570e-01, time/batch = 15.6590s	
17076/25300 (epoch 33.747), train_loss = 0.66067404, grad/param norm = 1.9905e-01, time/batch = 16.3220s	
17077/25300 (epoch 33.749), train_loss = 0.77458028, grad/param norm = 2.2330e-01, time/batch = 18.2990s	
17078/25300 (epoch 33.751), train_loss = 0.82758828, grad/param norm = 2.3117e-01, time/batch = 15.7036s	
17079/25300 (epoch 33.753), train_loss = 0.65624912, grad/param norm = 2.0120e-01, time/batch = 17.1280s	
17080/25300 (epoch 33.755), train_loss = 0.86857807, grad/param norm = 2.3183e-01, time/batch = 15.7903s	
17081/25300 (epoch 33.757), train_loss = 0.71920513, grad/param norm = 2.2995e-01, time/batch = 16.2393s	
17082/25300 (epoch 33.759), train_loss = 0.69237349, grad/param norm = 2.0531e-01, time/batch = 15.4919s	
17083/25300 (epoch 33.761), train_loss = 0.90924925, grad/param norm = 2.3233e-01, time/batch = 15.7125s	
17084/25300 (epoch 33.763), train_loss = 0.75102372, grad/param norm = 2.0957e-01, time/batch = 15.8950s	
17085/25300 (epoch 33.765), train_loss = 0.75075625, grad/param norm = 2.2756e-01, time/batch = 16.0627s	
17086/25300 (epoch 33.767), train_loss = 0.75497962, grad/param norm = 1.9807e-01, time/batch = 16.7423s	
17087/25300 (epoch 33.769), train_loss = 0.77344708, grad/param norm = 2.5728e-01, time/batch = 16.5737s	
17088/25300 (epoch 33.771), train_loss = 0.87338999, grad/param norm = 2.5895e-01, time/batch = 15.7250s	
17089/25300 (epoch 33.773), train_loss = 0.87391528, grad/param norm = 2.4067e-01, time/batch = 16.0752s	
17090/25300 (epoch 33.775), train_loss = 0.78959813, grad/param norm = 1.9748e-01, time/batch = 16.7350s	
17091/25300 (epoch 33.777), train_loss = 0.72956419, grad/param norm = 2.2562e-01, time/batch = 16.0644s	
17092/25300 (epoch 33.779), train_loss = 0.84424984, grad/param norm = 2.0205e-01, time/batch = 16.1530s	
17093/25300 (epoch 33.781), train_loss = 0.82575789, grad/param norm = 2.2659e-01, time/batch = 15.5643s	
17094/25300 (epoch 33.783), train_loss = 0.89687462, grad/param norm = 2.2714e-01, time/batch = 15.3271s	
17095/25300 (epoch 33.785), train_loss = 0.84366545, grad/param norm = 2.3827e-01, time/batch = 15.5424s	
17096/25300 (epoch 33.787), train_loss = 0.82983077, grad/param norm = 2.6339e-01, time/batch = 16.1295s	
17097/25300 (epoch 33.789), train_loss = 0.90812132, grad/param norm = 2.3971e-01, time/batch = 15.9871s	
17098/25300 (epoch 33.791), train_loss = 0.80763337, grad/param norm = 2.0000e-01, time/batch = 15.8191s	
17099/25300 (epoch 33.792), train_loss = 0.89398500, grad/param norm = 2.3598e-01, time/batch = 15.5511s	
17100/25300 (epoch 33.794), train_loss = 0.76801005, grad/param norm = 2.2246e-01, time/batch = 15.9859s	
17101/25300 (epoch 33.796), train_loss = 0.74968978, grad/param norm = 2.2504e-01, time/batch = 15.6483s	
17102/25300 (epoch 33.798), train_loss = 0.85825724, grad/param norm = 2.4924e-01, time/batch = 16.2287s	
17103/25300 (epoch 33.800), train_loss = 0.74553013, grad/param norm = 1.9952e-01, time/batch = 15.9870s	
17104/25300 (epoch 33.802), train_loss = 0.62178420, grad/param norm = 1.9545e-01, time/batch = 16.5877s	
17105/25300 (epoch 33.804), train_loss = 0.79746255, grad/param norm = 1.9790e-01, time/batch = 16.2411s	
17106/25300 (epoch 33.806), train_loss = 0.83337690, grad/param norm = 2.4254e-01, time/batch = 15.9730s	
17107/25300 (epoch 33.808), train_loss = 0.88092657, grad/param norm = 2.2782e-01, time/batch = 15.8195s	
17108/25300 (epoch 33.810), train_loss = 0.77474206, grad/param norm = 2.4087e-01, time/batch = 15.9929s	
17109/25300 (epoch 33.812), train_loss = 0.88844481, grad/param norm = 2.2649e-01, time/batch = 16.3306s	
17110/25300 (epoch 33.814), train_loss = 0.91803920, grad/param norm = 2.8257e-01, time/batch = 15.9783s	
17111/25300 (epoch 33.816), train_loss = 0.98947836, grad/param norm = 2.2241e-01, time/batch = 16.1536s	
17112/25300 (epoch 33.818), train_loss = 0.87569543, grad/param norm = 2.2659e-01, time/batch = 15.7928s	
17113/25300 (epoch 33.820), train_loss = 0.88588214, grad/param norm = 2.4536e-01, time/batch = 15.7497s	
17114/25300 (epoch 33.822), train_loss = 0.72199973, grad/param norm = 2.0392e-01, time/batch = 15.8917s	
17115/25300 (epoch 33.824), train_loss = 0.88931456, grad/param norm = 2.2870e-01, time/batch = 15.8867s	
17116/25300 (epoch 33.826), train_loss = 0.71257374, grad/param norm = 1.8900e-01, time/batch = 15.6685s	
17117/25300 (epoch 33.828), train_loss = 0.73640188, grad/param norm = 3.6566e-01, time/batch = 15.9621s	
17118/25300 (epoch 33.830), train_loss = 0.82442695, grad/param norm = 2.1231e-01, time/batch = 15.9765s	
17119/25300 (epoch 33.832), train_loss = 0.89853854, grad/param norm = 2.5097e-01, time/batch = 18.2252s	
17120/25300 (epoch 33.834), train_loss = 0.75561685, grad/param norm = 2.2961e-01, time/batch = 16.1700s	
17121/25300 (epoch 33.836), train_loss = 0.76429846, grad/param norm = 2.0689e-01, time/batch = 15.7207s	
17122/25300 (epoch 33.838), train_loss = 0.75097847, grad/param norm = 2.0881e-01, time/batch = 15.9854s	
17123/25300 (epoch 33.840), train_loss = 0.85582279, grad/param norm = 2.4994e-01, time/batch = 15.7571s	
17124/25300 (epoch 33.842), train_loss = 0.80318298, grad/param norm = 2.4730e-01, time/batch = 15.7482s	
17125/25300 (epoch 33.844), train_loss = 0.87728811, grad/param norm = 1.9859e-01, time/batch = 26.4024s	
17126/25300 (epoch 33.846), train_loss = 0.85637995, grad/param norm = 2.1889e-01, time/batch = 17.1433s	
17127/25300 (epoch 33.848), train_loss = 0.84911695, grad/param norm = 2.5458e-01, time/batch = 15.7255s	
17128/25300 (epoch 33.850), train_loss = 0.80095142, grad/param norm = 2.2834e-01, time/batch = 15.3100s	
17129/25300 (epoch 33.852), train_loss = 0.85845491, grad/param norm = 1.9493e-01, time/batch = 15.7557s	
17130/25300 (epoch 33.854), train_loss = 0.89049896, grad/param norm = 2.1202e-01, time/batch = 15.2488s	
17131/25300 (epoch 33.856), train_loss = 0.75752224, grad/param norm = 2.1525e-01, time/batch = 15.4034s	
17132/25300 (epoch 33.858), train_loss = 0.79226725, grad/param norm = 2.3963e-01, time/batch = 15.3817s	
17133/25300 (epoch 33.860), train_loss = 0.67029822, grad/param norm = 2.1235e-01, time/batch = 15.4088s	
17134/25300 (epoch 33.862), train_loss = 0.78503458, grad/param norm = 2.2947e-01, time/batch = 15.5799s	
17135/25300 (epoch 33.864), train_loss = 0.88010855, grad/param norm = 2.0334e-01, time/batch = 15.4163s	
17136/25300 (epoch 33.866), train_loss = 0.75547756, grad/param norm = 2.3389e-01, time/batch = 15.3871s	
17137/25300 (epoch 33.868), train_loss = 0.89246356, grad/param norm = 2.2252e-01, time/batch = 16.1593s	
17138/25300 (epoch 33.870), train_loss = 0.88128659, grad/param norm = 1.9383e-01, time/batch = 16.0011s	
17139/25300 (epoch 33.872), train_loss = 0.81766319, grad/param norm = 2.3763e-01, time/batch = 15.8925s	
17140/25300 (epoch 33.874), train_loss = 0.84396742, grad/param norm = 2.3066e-01, time/batch = 16.8219s	
17141/25300 (epoch 33.875), train_loss = 0.77796685, grad/param norm = 2.2325e-01, time/batch = 16.1322s	
17142/25300 (epoch 33.877), train_loss = 0.75971056, grad/param norm = 1.9154e-01, time/batch = 15.7242s	
17143/25300 (epoch 33.879), train_loss = 0.71729297, grad/param norm = 2.8022e-01, time/batch = 15.7186s	
17144/25300 (epoch 33.881), train_loss = 1.04378974, grad/param norm = 2.9403e-01, time/batch = 15.6404s	
17145/25300 (epoch 33.883), train_loss = 0.99422486, grad/param norm = 2.2527e-01, time/batch = 16.1436s	
17146/25300 (epoch 33.885), train_loss = 0.86321105, grad/param norm = 2.6500e-01, time/batch = 16.1499s	
17147/25300 (epoch 33.887), train_loss = 0.87499010, grad/param norm = 2.1052e-01, time/batch = 15.6473s	
17148/25300 (epoch 33.889), train_loss = 0.97022173, grad/param norm = 2.8216e-01, time/batch = 15.9893s	
17149/25300 (epoch 33.891), train_loss = 0.85312386, grad/param norm = 2.5269e-01, time/batch = 15.5744s	
17150/25300 (epoch 33.893), train_loss = 0.83528538, grad/param norm = 2.7476e-01, time/batch = 16.1436s	
17151/25300 (epoch 33.895), train_loss = 0.60542580, grad/param norm = 1.8095e-01, time/batch = 15.9081s	
17152/25300 (epoch 33.897), train_loss = 0.71715095, grad/param norm = 2.1164e-01, time/batch = 15.5957s	
17153/25300 (epoch 33.899), train_loss = 0.82211311, grad/param norm = 2.4716e-01, time/batch = 15.2657s	
17154/25300 (epoch 33.901), train_loss = 0.83295344, grad/param norm = 2.1509e-01, time/batch = 15.4966s	
17155/25300 (epoch 33.903), train_loss = 0.66562358, grad/param norm = 2.3250e-01, time/batch = 15.4857s	
17156/25300 (epoch 33.905), train_loss = 0.75674113, grad/param norm = 2.3949e-01, time/batch = 15.3187s	
17157/25300 (epoch 33.907), train_loss = 0.75472046, grad/param norm = 2.7365e-01, time/batch = 16.0802s	
17158/25300 (epoch 33.909), train_loss = 0.85368297, grad/param norm = 2.0622e-01, time/batch = 15.4050s	
17159/25300 (epoch 33.911), train_loss = 0.93000466, grad/param norm = 2.9453e-01, time/batch = 17.2196s	
17160/25300 (epoch 33.913), train_loss = 1.01350806, grad/param norm = 2.9374e-01, time/batch = 15.8302s	
17161/25300 (epoch 33.915), train_loss = 0.75257952, grad/param norm = 2.4206e-01, time/batch = 15.8249s	
17162/25300 (epoch 33.917), train_loss = 0.92517816, grad/param norm = 2.1690e-01, time/batch = 15.8102s	
17163/25300 (epoch 33.919), train_loss = 0.92413374, grad/param norm = 2.7089e-01, time/batch = 16.6598s	
17164/25300 (epoch 33.921), train_loss = 0.75645800, grad/param norm = 2.3896e-01, time/batch = 15.7261s	
17165/25300 (epoch 33.923), train_loss = 0.88155269, grad/param norm = 2.4194e-01, time/batch = 15.9205s	
17166/25300 (epoch 33.925), train_loss = 0.82075985, grad/param norm = 2.5058e-01, time/batch = 16.3999s	
17167/25300 (epoch 33.927), train_loss = 0.79665630, grad/param norm = 2.8842e-01, time/batch = 16.9907s	
17168/25300 (epoch 33.929), train_loss = 0.84385072, grad/param norm = 2.4802e-01, time/batch = 15.8035s	
17169/25300 (epoch 33.931), train_loss = 0.89308618, grad/param norm = 2.9428e-01, time/batch = 15.8117s	
17170/25300 (epoch 33.933), train_loss = 0.84756889, grad/param norm = 2.3269e-01, time/batch = 15.7929s	
17171/25300 (epoch 33.935), train_loss = 0.85971518, grad/param norm = 2.0488e-01, time/batch = 16.0804s	
17172/25300 (epoch 33.937), train_loss = 0.63943450, grad/param norm = 1.8143e-01, time/batch = 15.6566s	
17173/25300 (epoch 33.939), train_loss = 0.82258434, grad/param norm = 2.1395e-01, time/batch = 15.4746s	
17174/25300 (epoch 33.941), train_loss = 0.76399632, grad/param norm = 2.5107e-01, time/batch = 15.3153s	
17175/25300 (epoch 33.943), train_loss = 0.82375978, grad/param norm = 2.1561e-01, time/batch = 15.7458s	
17176/25300 (epoch 33.945), train_loss = 0.83540215, grad/param norm = 2.4201e-01, time/batch = 16.0016s	
17177/25300 (epoch 33.947), train_loss = 0.74449898, grad/param norm = 2.3061e-01, time/batch = 15.3969s	
17178/25300 (epoch 33.949), train_loss = 0.84935117, grad/param norm = 2.0658e-01, time/batch = 15.5769s	
17179/25300 (epoch 33.951), train_loss = 0.80268188, grad/param norm = 1.9811e-01, time/batch = 16.0685s	
17180/25300 (epoch 33.953), train_loss = 0.77560014, grad/param norm = 2.1901e-01, time/batch = 15.9992s	
17181/25300 (epoch 33.955), train_loss = 0.99533636, grad/param norm = 2.5128e-01, time/batch = 16.2011s	
17182/25300 (epoch 33.957), train_loss = 0.90541698, grad/param norm = 2.7326e-01, time/batch = 15.9016s	
17183/25300 (epoch 33.958), train_loss = 0.86930946, grad/param norm = 2.7903e-01, time/batch = 15.7292s	
17184/25300 (epoch 33.960), train_loss = 0.99138230, grad/param norm = 3.0587e-01, time/batch = 15.6934s	
17185/25300 (epoch 33.962), train_loss = 0.94255101, grad/param norm = 2.3730e-01, time/batch = 15.7371s	
17186/25300 (epoch 33.964), train_loss = 0.83673138, grad/param norm = 2.3948e-01, time/batch = 15.4258s	
17187/25300 (epoch 33.966), train_loss = 0.71665856, grad/param norm = 2.0330e-01, time/batch = 15.2703s	
17188/25300 (epoch 33.968), train_loss = 0.69577205, grad/param norm = 2.0746e-01, time/batch = 15.3596s	
17189/25300 (epoch 33.970), train_loss = 0.77675126, grad/param norm = 2.3269e-01, time/batch = 15.5494s	
17190/25300 (epoch 33.972), train_loss = 0.80355346, grad/param norm = 2.1710e-01, time/batch = 16.8988s	
17191/25300 (epoch 33.974), train_loss = 0.91918798, grad/param norm = 2.5370e-01, time/batch = 16.8923s	
17192/25300 (epoch 33.976), train_loss = 0.83985967, grad/param norm = 2.4091e-01, time/batch = 15.7356s	
17193/25300 (epoch 33.978), train_loss = 0.78441677, grad/param norm = 2.4941e-01, time/batch = 15.2332s	
17194/25300 (epoch 33.980), train_loss = 0.82262791, grad/param norm = 2.1473e-01, time/batch = 15.6535s	
17195/25300 (epoch 33.982), train_loss = 0.77527270, grad/param norm = 2.4797e-01, time/batch = 15.2494s	
17196/25300 (epoch 33.984), train_loss = 0.79103872, grad/param norm = 2.1128e-01, time/batch = 15.3910s	
17197/25300 (epoch 33.986), train_loss = 0.87799316, grad/param norm = 2.4591e-01, time/batch = 15.3186s	
17198/25300 (epoch 33.988), train_loss = 0.83682844, grad/param norm = 2.3644e-01, time/batch = 15.6702s	
17199/25300 (epoch 33.990), train_loss = 0.81855637, grad/param norm = 2.1558e-01, time/batch = 15.6565s	
17200/25300 (epoch 33.992), train_loss = 0.71060918, grad/param norm = 1.9338e-01, time/batch = 16.1378s	
17201/25300 (epoch 33.994), train_loss = 0.85497310, grad/param norm = 2.9131e-01, time/batch = 15.9886s	
17202/25300 (epoch 33.996), train_loss = 0.96653069, grad/param norm = 2.8112e-01, time/batch = 15.7191s	
17203/25300 (epoch 33.998), train_loss = 0.89684843, grad/param norm = 2.4835e-01, time/batch = 15.6319s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
17204/25300 (epoch 34.000), train_loss = 0.88608067, grad/param norm = 2.6308e-01, time/batch = 15.8693s	
17205/25300 (epoch 34.002), train_loss = 0.80560630, grad/param norm = 2.0632e-01, time/batch = 15.4031s	
17206/25300 (epoch 34.004), train_loss = 0.69866220, grad/param norm = 2.0312e-01, time/batch = 15.5567s	
17207/25300 (epoch 34.006), train_loss = 0.95910912, grad/param norm = 2.2328e-01, time/batch = 15.1498s	
17208/25300 (epoch 34.008), train_loss = 0.80945364, grad/param norm = 1.9709e-01, time/batch = 16.6416s	
17209/25300 (epoch 34.010), train_loss = 0.85614529, grad/param norm = 2.4286e-01, time/batch = 16.5603s	
17210/25300 (epoch 34.012), train_loss = 0.76473728, grad/param norm = 2.0038e-01, time/batch = 15.8992s	
17211/25300 (epoch 34.014), train_loss = 0.94615526, grad/param norm = 2.4667e-01, time/batch = 16.3074s	
17212/25300 (epoch 34.016), train_loss = 0.80924595, grad/param norm = 2.2006e-01, time/batch = 15.4743s	
17213/25300 (epoch 34.018), train_loss = 0.71945435, grad/param norm = 2.0658e-01, time/batch = 15.4153s	
17214/25300 (epoch 34.020), train_loss = 0.83438921, grad/param norm = 2.2488e-01, time/batch = 15.4917s	
17215/25300 (epoch 34.022), train_loss = 0.82850542, grad/param norm = 2.5580e-01, time/batch = 15.6441s	
17216/25300 (epoch 34.024), train_loss = 0.60933327, grad/param norm = 1.6901e-01, time/batch = 15.9865s	
17217/25300 (epoch 34.026), train_loss = 0.77272807, grad/param norm = 2.3770e-01, time/batch = 16.3232s	
17218/25300 (epoch 34.028), train_loss = 0.75997574, grad/param norm = 2.1406e-01, time/batch = 15.8866s	
17219/25300 (epoch 34.030), train_loss = 0.92687718, grad/param norm = 2.0646e-01, time/batch = 15.8056s	
17220/25300 (epoch 34.032), train_loss = 0.78423260, grad/param norm = 2.3850e-01, time/batch = 16.2336s	
17221/25300 (epoch 34.034), train_loss = 0.70731140, grad/param norm = 2.0959e-01, time/batch = 16.4903s	
17222/25300 (epoch 34.036), train_loss = 0.67825007, grad/param norm = 2.3678e-01, time/batch = 15.8772s	
17223/25300 (epoch 34.038), train_loss = 0.62321726, grad/param norm = 1.8596e-01, time/batch = 15.9091s	
17224/25300 (epoch 34.040), train_loss = 0.81338842, grad/param norm = 2.2901e-01, time/batch = 15.9991s	
17225/25300 (epoch 34.042), train_loss = 0.79147360, grad/param norm = 1.9732e-01, time/batch = 15.7330s	
17226/25300 (epoch 34.043), train_loss = 0.68323422, grad/param norm = 1.8936e-01, time/batch = 15.7359s	
17227/25300 (epoch 34.045), train_loss = 0.68436458, grad/param norm = 1.8514e-01, time/batch = 16.0723s	
17228/25300 (epoch 34.047), train_loss = 0.81638472, grad/param norm = 2.1828e-01, time/batch = 16.3152s	
17229/25300 (epoch 34.049), train_loss = 0.81759246, grad/param norm = 2.6152e-01, time/batch = 16.1678s	
17230/25300 (epoch 34.051), train_loss = 0.91926440, grad/param norm = 2.4737e-01, time/batch = 15.5486s	
17231/25300 (epoch 34.053), train_loss = 0.64248652, grad/param norm = 2.1431e-01, time/batch = 16.0738s	
17232/25300 (epoch 34.055), train_loss = 0.67377405, grad/param norm = 2.0363e-01, time/batch = 15.8156s	
17233/25300 (epoch 34.057), train_loss = 0.65931964, grad/param norm = 1.7105e-01, time/batch = 15.6540s	
17234/25300 (epoch 34.059), train_loss = 0.74536200, grad/param norm = 2.0352e-01, time/batch = 15.8334s	
17235/25300 (epoch 34.061), train_loss = 0.72492492, grad/param norm = 1.9628e-01, time/batch = 15.7389s	
17236/25300 (epoch 34.063), train_loss = 0.72552317, grad/param norm = 1.9517e-01, time/batch = 16.4755s	
17237/25300 (epoch 34.065), train_loss = 0.80048824, grad/param norm = 2.2732e-01, time/batch = 15.5320s	
17238/25300 (epoch 34.067), train_loss = 0.85750208, grad/param norm = 1.9823e-01, time/batch = 16.4115s	
17239/25300 (epoch 34.069), train_loss = 0.70490158, grad/param norm = 2.1365e-01, time/batch = 15.9178s	
17240/25300 (epoch 34.071), train_loss = 0.84526406, grad/param norm = 2.6072e-01, time/batch = 15.3882s	
17241/25300 (epoch 34.073), train_loss = 0.77441378, grad/param norm = 2.0237e-01, time/batch = 15.3828s	
17242/25300 (epoch 34.075), train_loss = 0.84583769, grad/param norm = 2.3411e-01, time/batch = 15.1639s	
17243/25300 (epoch 34.077), train_loss = 0.82799461, grad/param norm = 2.4129e-01, time/batch = 15.4842s	
17244/25300 (epoch 34.079), train_loss = 0.71339827, grad/param norm = 2.0601e-01, time/batch = 15.7273s	
17245/25300 (epoch 34.081), train_loss = 0.78612018, grad/param norm = 1.8781e-01, time/batch = 15.6823s	
17246/25300 (epoch 34.083), train_loss = 0.80883329, grad/param norm = 2.0279e-01, time/batch = 15.5587s	
17247/25300 (epoch 34.085), train_loss = 0.95970126, grad/param norm = 2.3820e-01, time/batch = 15.4694s	
17248/25300 (epoch 34.087), train_loss = 0.87118332, grad/param norm = 2.0284e-01, time/batch = 15.5527s	
17249/25300 (epoch 34.089), train_loss = 0.85590260, grad/param norm = 2.1677e-01, time/batch = 15.6313s	
17250/25300 (epoch 34.091), train_loss = 0.97337079, grad/param norm = 2.1883e-01, time/batch = 15.3070s	
17251/25300 (epoch 34.093), train_loss = 0.90495704, grad/param norm = 2.3424e-01, time/batch = 15.3043s	
17252/25300 (epoch 34.095), train_loss = 0.87137170, grad/param norm = 2.1983e-01, time/batch = 15.5551s	
17253/25300 (epoch 34.097), train_loss = 0.84798555, grad/param norm = 2.3103e-01, time/batch = 15.3913s	
17254/25300 (epoch 34.099), train_loss = 0.85123031, grad/param norm = 2.5136e-01, time/batch = 15.7435s	
17255/25300 (epoch 34.101), train_loss = 0.79071460, grad/param norm = 2.2438e-01, time/batch = 15.4173s	
17256/25300 (epoch 34.103), train_loss = 0.80785771, grad/param norm = 2.1351e-01, time/batch = 15.4854s	
17257/25300 (epoch 34.105), train_loss = 0.85985652, grad/param norm = 2.2301e-01, time/batch = 15.5456s	
17258/25300 (epoch 34.107), train_loss = 0.87606034, grad/param norm = 2.5916e-01, time/batch = 15.5628s	
17259/25300 (epoch 34.109), train_loss = 0.78667474, grad/param norm = 2.3705e-01, time/batch = 15.5047s	
17260/25300 (epoch 34.111), train_loss = 0.77292737, grad/param norm = 1.9766e-01, time/batch = 15.6564s	
17261/25300 (epoch 34.113), train_loss = 0.74176982, grad/param norm = 2.4106e-01, time/batch = 15.3879s	
17262/25300 (epoch 34.115), train_loss = 0.77563382, grad/param norm = 2.2882e-01, time/batch = 15.3373s	
17263/25300 (epoch 34.117), train_loss = 0.89179475, grad/param norm = 2.2826e-01, time/batch = 15.9923s	
17264/25300 (epoch 34.119), train_loss = 0.76009035, grad/param norm = 2.2972e-01, time/batch = 15.6373s	
17265/25300 (epoch 34.121), train_loss = 0.80355427, grad/param norm = 2.6632e-01, time/batch = 15.6652s	
17266/25300 (epoch 34.123), train_loss = 0.73535885, grad/param norm = 2.1423e-01, time/batch = 15.7300s	
17267/25300 (epoch 34.125), train_loss = 0.89332138, grad/param norm = 2.4310e-01, time/batch = 16.6611s	
17268/25300 (epoch 34.126), train_loss = 0.80703194, grad/param norm = 1.9323e-01, time/batch = 15.7122s	
17269/25300 (epoch 34.128), train_loss = 0.77397730, grad/param norm = 2.2754e-01, time/batch = 15.9190s	
17270/25300 (epoch 34.130), train_loss = 0.63435120, grad/param norm = 1.7571e-01, time/batch = 15.2375s	
17271/25300 (epoch 34.132), train_loss = 0.65793342, grad/param norm = 2.0372e-01, time/batch = 16.3068s	
17272/25300 (epoch 34.134), train_loss = 0.67859515, grad/param norm = 1.9437e-01, time/batch = 16.1449s	
17273/25300 (epoch 34.136), train_loss = 0.77971636, grad/param norm = 2.0563e-01, time/batch = 17.4016s	
17274/25300 (epoch 34.138), train_loss = 0.68156231, grad/param norm = 1.7287e-01, time/batch = 17.0670s	
17275/25300 (epoch 34.140), train_loss = 0.70023362, grad/param norm = 2.1433e-01, time/batch = 16.6413s	
17276/25300 (epoch 34.142), train_loss = 0.89495976, grad/param norm = 2.3088e-01, time/batch = 15.8796s	
17277/25300 (epoch 34.144), train_loss = 0.86597973, grad/param norm = 2.3805e-01, time/batch = 15.9811s	
17278/25300 (epoch 34.146), train_loss = 0.78816797, grad/param norm = 2.8609e-01, time/batch = 16.4092s	
17279/25300 (epoch 34.148), train_loss = 0.77539390, grad/param norm = 1.8623e-01, time/batch = 15.9820s	
17280/25300 (epoch 34.150), train_loss = 0.82459815, grad/param norm = 2.2460e-01, time/batch = 16.2372s	
17281/25300 (epoch 34.152), train_loss = 0.92400048, grad/param norm = 2.5563e-01, time/batch = 16.5733s	
17282/25300 (epoch 34.154), train_loss = 0.67891934, grad/param norm = 2.0252e-01, time/batch = 16.1540s	
17283/25300 (epoch 34.156), train_loss = 0.81832604, grad/param norm = 2.2808e-01, time/batch = 16.0622s	
17284/25300 (epoch 34.158), train_loss = 0.68908366, grad/param norm = 2.1335e-01, time/batch = 16.0761s	
17285/25300 (epoch 34.160), train_loss = 0.81661251, grad/param norm = 2.3288e-01, time/batch = 15.6267s	
17286/25300 (epoch 34.162), train_loss = 0.74055456, grad/param norm = 2.0874e-01, time/batch = 15.7370s	
17287/25300 (epoch 34.164), train_loss = 0.84050698, grad/param norm = 2.5926e-01, time/batch = 15.6628s	
17288/25300 (epoch 34.166), train_loss = 0.78741356, grad/param norm = 1.9605e-01, time/batch = 15.9879s	
17289/25300 (epoch 34.168), train_loss = 0.72775300, grad/param norm = 1.8593e-01, time/batch = 15.5662s	
17290/25300 (epoch 34.170), train_loss = 0.74163997, grad/param norm = 2.4461e-01, time/batch = 15.3102s	
17291/25300 (epoch 34.172), train_loss = 0.67343673, grad/param norm = 1.8112e-01, time/batch = 16.8251s	
17292/25300 (epoch 34.174), train_loss = 0.70905590, grad/param norm = 1.9966e-01, time/batch = 16.3296s	
17293/25300 (epoch 34.176), train_loss = 0.70388329, grad/param norm = 2.3080e-01, time/batch = 16.1616s	
17294/25300 (epoch 34.178), train_loss = 0.92887492, grad/param norm = 2.2626e-01, time/batch = 16.5383s	
17295/25300 (epoch 34.180), train_loss = 0.65635766, grad/param norm = 2.2480e-01, time/batch = 16.2463s	
17296/25300 (epoch 34.182), train_loss = 0.78689780, grad/param norm = 2.5479e-01, time/batch = 15.6046s	
17297/25300 (epoch 34.184), train_loss = 0.70341370, grad/param norm = 2.2861e-01, time/batch = 15.5660s	
17298/25300 (epoch 34.186), train_loss = 0.67200541, grad/param norm = 2.1414e-01, time/batch = 15.4213s	
17299/25300 (epoch 34.188), train_loss = 0.79267593, grad/param norm = 2.4275e-01, time/batch = 16.1607s	
17300/25300 (epoch 34.190), train_loss = 0.77242777, grad/param norm = 2.0502e-01, time/batch = 16.3990s	
17301/25300 (epoch 34.192), train_loss = 0.74031916, grad/param norm = 1.9329e-01, time/batch = 15.9674s	
17302/25300 (epoch 34.194), train_loss = 0.73578199, grad/param norm = 2.0647e-01, time/batch = 16.1652s	
17303/25300 (epoch 34.196), train_loss = 0.88873016, grad/param norm = 2.7124e-01, time/batch = 15.7185s	
17304/25300 (epoch 34.198), train_loss = 0.73049864, grad/param norm = 2.2954e-01, time/batch = 16.0918s	
17305/25300 (epoch 34.200), train_loss = 0.77837996, grad/param norm = 2.8886e-01, time/batch = 15.8224s	
17306/25300 (epoch 34.202), train_loss = 0.77821995, grad/param norm = 2.4521e-01, time/batch = 15.9096s	
17307/25300 (epoch 34.204), train_loss = 0.76876882, grad/param norm = 2.1514e-01, time/batch = 15.9963s	
17308/25300 (epoch 34.206), train_loss = 0.87599689, grad/param norm = 2.5640e-01, time/batch = 15.4913s	
17309/25300 (epoch 34.208), train_loss = 0.70260410, grad/param norm = 2.1473e-01, time/batch = 15.8075s	
17310/25300 (epoch 34.209), train_loss = 0.67465578, grad/param norm = 2.0705e-01, time/batch = 15.8263s	
17311/25300 (epoch 34.211), train_loss = 0.75389925, grad/param norm = 1.9938e-01, time/batch = 16.0571s	
17312/25300 (epoch 34.213), train_loss = 0.80724419, grad/param norm = 2.2791e-01, time/batch = 15.5700s	
17313/25300 (epoch 34.215), train_loss = 0.81254176, grad/param norm = 2.2469e-01, time/batch = 15.4808s	
17314/25300 (epoch 34.217), train_loss = 0.80509526, grad/param norm = 2.4767e-01, time/batch = 15.5657s	
17315/25300 (epoch 34.219), train_loss = 0.85767546, grad/param norm = 2.4397e-01, time/batch = 16.8099s	
17316/25300 (epoch 34.221), train_loss = 0.89326183, grad/param norm = 2.2569e-01, time/batch = 15.7334s	
17317/25300 (epoch 34.223), train_loss = 0.84655586, grad/param norm = 2.3524e-01, time/batch = 15.5655s	
17318/25300 (epoch 34.225), train_loss = 1.05038833, grad/param norm = 2.7696e-01, time/batch = 15.8339s	
17319/25300 (epoch 34.227), train_loss = 0.91095104, grad/param norm = 2.4102e-01, time/batch = 15.8245s	
17320/25300 (epoch 34.229), train_loss = 0.76038024, grad/param norm = 2.0141e-01, time/batch = 15.5618s	
17321/25300 (epoch 34.231), train_loss = 0.81978771, grad/param norm = 2.5335e-01, time/batch = 15.8959s	
17322/25300 (epoch 34.233), train_loss = 0.83874369, grad/param norm = 2.3527e-01, time/batch = 15.4055s	
17323/25300 (epoch 34.235), train_loss = 0.77828324, grad/param norm = 2.1509e-01, time/batch = 15.3228s	
17324/25300 (epoch 34.237), train_loss = 0.91983839, grad/param norm = 2.7293e-01, time/batch = 15.6460s	
17325/25300 (epoch 34.239), train_loss = 0.76179526, grad/param norm = 2.3992e-01, time/batch = 15.8297s	
17326/25300 (epoch 34.241), train_loss = 0.92051777, grad/param norm = 2.1564e-01, time/batch = 15.2531s	
17327/25300 (epoch 34.243), train_loss = 1.06926957, grad/param norm = 3.3830e-01, time/batch = 15.2262s	
17328/25300 (epoch 34.245), train_loss = 0.76498970, grad/param norm = 2.2623e-01, time/batch = 15.3150s	
17329/25300 (epoch 34.247), train_loss = 0.86637944, grad/param norm = 2.2885e-01, time/batch = 15.4121s	
17330/25300 (epoch 34.249), train_loss = 0.69079437, grad/param norm = 1.9548e-01, time/batch = 15.5746s	
17331/25300 (epoch 34.251), train_loss = 0.69940256, grad/param norm = 1.9335e-01, time/batch = 15.7228s	
17332/25300 (epoch 34.253), train_loss = 0.77655136, grad/param norm = 2.2325e-01, time/batch = 15.7450s	
17333/25300 (epoch 34.255), train_loss = 0.73094151, grad/param norm = 2.3575e-01, time/batch = 15.8354s	
17334/25300 (epoch 34.257), train_loss = 0.75178295, grad/param norm = 2.1261e-01, time/batch = 15.9199s	
17335/25300 (epoch 34.259), train_loss = 0.97280995, grad/param norm = 3.1889e-01, time/batch = 15.9058s	
17336/25300 (epoch 34.261), train_loss = 0.91202787, grad/param norm = 2.7980e-01, time/batch = 15.8129s	
17337/25300 (epoch 34.263), train_loss = 0.93014457, grad/param norm = 2.4574e-01, time/batch = 15.9833s	
17338/25300 (epoch 34.265), train_loss = 0.95575302, grad/param norm = 2.6210e-01, time/batch = 15.5630s	
17339/25300 (epoch 34.267), train_loss = 0.84163683, grad/param norm = 2.2497e-01, time/batch = 15.6569s	
17340/25300 (epoch 34.269), train_loss = 0.68588002, grad/param norm = 1.9755e-01, time/batch = 16.4142s	
17341/25300 (epoch 34.271), train_loss = 0.73189712, grad/param norm = 2.3200e-01, time/batch = 15.8931s	
17342/25300 (epoch 34.273), train_loss = 0.86187817, grad/param norm = 2.3561e-01, time/batch = 16.2503s	
17343/25300 (epoch 34.275), train_loss = 0.75730103, grad/param norm = 1.9305e-01, time/batch = 15.6453s	
17344/25300 (epoch 34.277), train_loss = 0.74363866, grad/param norm = 2.3531e-01, time/batch = 16.3199s	
17345/25300 (epoch 34.279), train_loss = 0.80291984, grad/param norm = 2.1398e-01, time/batch = 16.2973s	
17346/25300 (epoch 34.281), train_loss = 0.95474405, grad/param norm = 2.8231e-01, time/batch = 15.9711s	
17347/25300 (epoch 34.283), train_loss = 0.70815452, grad/param norm = 2.2759e-01, time/batch = 16.2412s	
17348/25300 (epoch 34.285), train_loss = 0.80569430, grad/param norm = 2.3682e-01, time/batch = 16.3182s	
17349/25300 (epoch 34.287), train_loss = 0.91592927, grad/param norm = 2.0684e-01, time/batch = 17.2538s	
17350/25300 (epoch 34.289), train_loss = 0.77376093, grad/param norm = 2.3385e-01, time/batch = 24.3176s	
17351/25300 (epoch 34.291), train_loss = 0.76786302, grad/param norm = 2.1518e-01, time/batch = 18.6670s	
17352/25300 (epoch 34.292), train_loss = 0.95347193, grad/param norm = 2.1549e-01, time/batch = 15.6367s	
17353/25300 (epoch 34.294), train_loss = 0.83143684, grad/param norm = 2.1237e-01, time/batch = 15.5240s	
17354/25300 (epoch 34.296), train_loss = 0.71345201, grad/param norm = 2.0499e-01, time/batch = 15.6985s	
17355/25300 (epoch 34.298), train_loss = 0.86667303, grad/param norm = 2.2070e-01, time/batch = 15.3732s	
17356/25300 (epoch 34.300), train_loss = 0.90672059, grad/param norm = 2.7867e-01, time/batch = 15.2931s	
17357/25300 (epoch 34.302), train_loss = 0.65554100, grad/param norm = 2.4649e-01, time/batch = 15.6744s	
17358/25300 (epoch 34.304), train_loss = 0.92706414, grad/param norm = 2.2809e-01, time/batch = 15.7008s	
17359/25300 (epoch 34.306), train_loss = 0.63800436, grad/param norm = 1.9719e-01, time/batch = 16.0335s	
17360/25300 (epoch 34.308), train_loss = 0.87425738, grad/param norm = 2.2721e-01, time/batch = 15.6532s	
17361/25300 (epoch 34.310), train_loss = 0.70158902, grad/param norm = 2.2140e-01, time/batch = 16.1476s	
17362/25300 (epoch 34.312), train_loss = 0.81817035, grad/param norm = 1.9639e-01, time/batch = 15.8119s	
17363/25300 (epoch 34.314), train_loss = 0.66827730, grad/param norm = 2.0204e-01, time/batch = 16.3277s	
17364/25300 (epoch 34.316), train_loss = 0.80819614, grad/param norm = 1.9608e-01, time/batch = 15.9659s	
17365/25300 (epoch 34.318), train_loss = 0.64387262, grad/param norm = 1.8797e-01, time/batch = 15.3741s	
17366/25300 (epoch 34.320), train_loss = 0.71990368, grad/param norm = 1.7945e-01, time/batch = 16.6344s	
17367/25300 (epoch 34.322), train_loss = 0.91203413, grad/param norm = 2.4474e-01, time/batch = 16.3919s	
17368/25300 (epoch 34.324), train_loss = 0.72314044, grad/param norm = 2.2362e-01, time/batch = 15.7180s	
17369/25300 (epoch 34.326), train_loss = 0.64107351, grad/param norm = 1.7045e-01, time/batch = 15.9762s	
17370/25300 (epoch 34.328), train_loss = 0.65132624, grad/param norm = 2.1671e-01, time/batch = 15.9773s	
17371/25300 (epoch 34.330), train_loss = 0.76601793, grad/param norm = 2.0012e-01, time/batch = 16.1445s	
17372/25300 (epoch 34.332), train_loss = 0.80352658, grad/param norm = 2.1674e-01, time/batch = 15.7946s	
17373/25300 (epoch 34.334), train_loss = 0.66235542, grad/param norm = 2.0776e-01, time/batch = 15.7283s	
17374/25300 (epoch 34.336), train_loss = 0.67482158, grad/param norm = 2.3014e-01, time/batch = 15.6250s	
17375/25300 (epoch 34.338), train_loss = 0.68970090, grad/param norm = 2.0719e-01, time/batch = 15.4937s	
17376/25300 (epoch 34.340), train_loss = 0.71679752, grad/param norm = 1.9986e-01, time/batch = 15.7273s	
17377/25300 (epoch 34.342), train_loss = 0.75079690, grad/param norm = 2.6888e-01, time/batch = 15.7472s	
17378/25300 (epoch 34.344), train_loss = 0.84602629, grad/param norm = 2.1737e-01, time/batch = 15.8121s	
17379/25300 (epoch 34.346), train_loss = 0.72642977, grad/param norm = 2.3155e-01, time/batch = 15.5460s	
17380/25300 (epoch 34.348), train_loss = 0.69271353, grad/param norm = 2.0592e-01, time/batch = 15.7401s	
17381/25300 (epoch 34.350), train_loss = 0.74830879, grad/param norm = 2.6002e-01, time/batch = 16.0718s	
17382/25300 (epoch 34.352), train_loss = 0.77289839, grad/param norm = 2.0721e-01, time/batch = 16.0734s	
17383/25300 (epoch 34.354), train_loss = 0.72106368, grad/param norm = 2.1019e-01, time/batch = 15.5237s	
17384/25300 (epoch 34.356), train_loss = 0.76444062, grad/param norm = 2.0525e-01, time/batch = 15.8667s	
17385/25300 (epoch 34.358), train_loss = 0.79562473, grad/param norm = 2.0471e-01, time/batch = 15.9757s	
17386/25300 (epoch 34.360), train_loss = 0.70349391, grad/param norm = 1.9976e-01, time/batch = 15.5228s	
17387/25300 (epoch 34.362), train_loss = 0.66668155, grad/param norm = 2.1349e-01, time/batch = 15.5180s	
17388/25300 (epoch 34.364), train_loss = 0.70014458, grad/param norm = 2.1954e-01, time/batch = 15.7077s	
17389/25300 (epoch 34.366), train_loss = 0.67815908, grad/param norm = 1.8807e-01, time/batch = 15.5061s	
17390/25300 (epoch 34.368), train_loss = 0.74208684, grad/param norm = 1.8786e-01, time/batch = 15.3213s	
17391/25300 (epoch 34.370), train_loss = 0.70791995, grad/param norm = 2.2643e-01, time/batch = 15.8663s	
17392/25300 (epoch 34.372), train_loss = 0.69276587, grad/param norm = 2.3731e-01, time/batch = 16.6510s	
17393/25300 (epoch 34.374), train_loss = 0.67371048, grad/param norm = 2.1638e-01, time/batch = 15.8264s	
17394/25300 (epoch 34.375), train_loss = 0.86938410, grad/param norm = 2.4894e-01, time/batch = 15.6584s	
17395/25300 (epoch 34.377), train_loss = 0.83143073, grad/param norm = 2.2062e-01, time/batch = 15.7302s	
17396/25300 (epoch 34.379), train_loss = 0.80978929, grad/param norm = 2.2188e-01, time/batch = 15.5733s	
17397/25300 (epoch 34.381), train_loss = 0.74547937, grad/param norm = 2.0904e-01, time/batch = 15.6464s	
17398/25300 (epoch 34.383), train_loss = 0.69294564, grad/param norm = 2.1117e-01, time/batch = 15.9046s	
17399/25300 (epoch 34.385), train_loss = 0.78629180, grad/param norm = 1.8915e-01, time/batch = 17.3887s	
17400/25300 (epoch 34.387), train_loss = 0.76677733, grad/param norm = 2.2711e-01, time/batch = 17.3906s	
17401/25300 (epoch 34.389), train_loss = 0.76139516, grad/param norm = 2.2699e-01, time/batch = 17.6182s	
17402/25300 (epoch 34.391), train_loss = 0.73064445, grad/param norm = 2.0094e-01, time/batch = 16.4380s	
17403/25300 (epoch 34.393), train_loss = 0.78134063, grad/param norm = 2.6633e-01, time/batch = 16.3103s	
17404/25300 (epoch 34.395), train_loss = 0.62683169, grad/param norm = 1.8786e-01, time/batch = 15.6666s	
17405/25300 (epoch 34.397), train_loss = 0.59709933, grad/param norm = 1.9563e-01, time/batch = 16.2188s	
17406/25300 (epoch 34.399), train_loss = 0.66785781, grad/param norm = 1.9729e-01, time/batch = 15.4027s	
17407/25300 (epoch 34.401), train_loss = 0.81235821, grad/param norm = 2.7772e-01, time/batch = 15.5061s	
17408/25300 (epoch 34.403), train_loss = 0.81336003, grad/param norm = 3.1356e-01, time/batch = 16.4846s	
17409/25300 (epoch 34.405), train_loss = 0.73995633, grad/param norm = 2.2032e-01, time/batch = 16.4862s	
17410/25300 (epoch 34.407), train_loss = 0.78415453, grad/param norm = 2.2722e-01, time/batch = 16.2311s	
17411/25300 (epoch 34.409), train_loss = 0.70351498, grad/param norm = 2.4533e-01, time/batch = 16.0825s	
17412/25300 (epoch 34.411), train_loss = 0.72263299, grad/param norm = 2.1983e-01, time/batch = 15.5788s	
17413/25300 (epoch 34.413), train_loss = 0.63215639, grad/param norm = 1.9230e-01, time/batch = 15.4576s	
17414/25300 (epoch 34.415), train_loss = 0.68192582, grad/param norm = 2.0377e-01, time/batch = 15.4914s	
17415/25300 (epoch 34.417), train_loss = 0.64454607, grad/param norm = 1.8785e-01, time/batch = 15.4858s	
17416/25300 (epoch 34.419), train_loss = 0.58084579, grad/param norm = 1.6730e-01, time/batch = 15.8975s	
17417/25300 (epoch 34.421), train_loss = 0.64480792, grad/param norm = 1.7055e-01, time/batch = 15.5673s	
17418/25300 (epoch 34.423), train_loss = 0.64460088, grad/param norm = 2.0614e-01, time/batch = 15.4004s	
17419/25300 (epoch 34.425), train_loss = 0.75083770, grad/param norm = 2.7651e-01, time/batch = 16.5783s	
17420/25300 (epoch 34.427), train_loss = 0.83696723, grad/param norm = 2.2132e-01, time/batch = 16.3233s	
17421/25300 (epoch 34.429), train_loss = 0.89289991, grad/param norm = 3.0532e-01, time/batch = 15.8239s	
17422/25300 (epoch 34.431), train_loss = 0.75986008, grad/param norm = 2.0420e-01, time/batch = 16.0688s	
17423/25300 (epoch 34.433), train_loss = 0.79310148, grad/param norm = 1.9639e-01, time/batch = 16.2862s	
17424/25300 (epoch 34.435), train_loss = 0.69186871, grad/param norm = 2.0070e-01, time/batch = 15.9752s	
17425/25300 (epoch 34.437), train_loss = 0.70443494, grad/param norm = 2.3382e-01, time/batch = 16.2329s	
17426/25300 (epoch 34.439), train_loss = 0.77880719, grad/param norm = 2.2305e-01, time/batch = 15.2427s	
17427/25300 (epoch 34.441), train_loss = 0.81126626, grad/param norm = 2.4042e-01, time/batch = 15.3340s	
17428/25300 (epoch 34.443), train_loss = 0.92478494, grad/param norm = 2.4675e-01, time/batch = 15.3048s	
17429/25300 (epoch 34.445), train_loss = 0.87119900, grad/param norm = 2.4141e-01, time/batch = 16.2359s	
17430/25300 (epoch 34.447), train_loss = 0.69622158, grad/param norm = 1.9867e-01, time/batch = 16.9032s	
17431/25300 (epoch 34.449), train_loss = 0.64291951, grad/param norm = 2.2167e-01, time/batch = 16.7428s	
17432/25300 (epoch 34.451), train_loss = 0.99752312, grad/param norm = 2.8554e-01, time/batch = 15.8068s	
17433/25300 (epoch 34.453), train_loss = 0.83393740, grad/param norm = 2.4538e-01, time/batch = 16.4063s	
17434/25300 (epoch 34.455), train_loss = 0.80023910, grad/param norm = 2.5590e-01, time/batch = 16.2369s	
17435/25300 (epoch 34.457), train_loss = 0.70890261, grad/param norm = 2.1860e-01, time/batch = 15.6395s	
17436/25300 (epoch 34.458), train_loss = 0.71933676, grad/param norm = 2.2030e-01, time/batch = 15.4845s	
17437/25300 (epoch 34.460), train_loss = 0.74467642, grad/param norm = 2.0994e-01, time/batch = 15.5126s	
17438/25300 (epoch 34.462), train_loss = 0.55971902, grad/param norm = 2.1270e-01, time/batch = 15.7486s	
17439/25300 (epoch 34.464), train_loss = 0.83195369, grad/param norm = 2.3661e-01, time/batch = 15.7118s	
17440/25300 (epoch 34.466), train_loss = 0.77859572, grad/param norm = 1.9659e-01, time/batch = 15.9894s	
17441/25300 (epoch 34.468), train_loss = 0.79811323, grad/param norm = 2.2390e-01, time/batch = 16.0412s	
17442/25300 (epoch 34.470), train_loss = 0.74021206, grad/param norm = 2.0571e-01, time/batch = 15.9025s	
17443/25300 (epoch 34.472), train_loss = 0.65089602, grad/param norm = 2.2869e-01, time/batch = 15.6451s	
17444/25300 (epoch 34.474), train_loss = 0.80372170, grad/param norm = 2.1629e-01, time/batch = 16.4794s	
17445/25300 (epoch 34.476), train_loss = 0.73800678, grad/param norm = 2.2794e-01, time/batch = 15.9945s	
17446/25300 (epoch 34.478), train_loss = 0.81986224, grad/param norm = 2.7595e-01, time/batch = 15.5705s	
17447/25300 (epoch 34.480), train_loss = 0.72962839, grad/param norm = 2.0988e-01, time/batch = 15.8012s	
17448/25300 (epoch 34.482), train_loss = 0.79592593, grad/param norm = 2.7822e-01, time/batch = 15.5743s	
17449/25300 (epoch 34.484), train_loss = 0.83818334, grad/param norm = 2.6327e-01, time/batch = 16.2405s	
17450/25300 (epoch 34.486), train_loss = 0.76284248, grad/param norm = 2.4866e-01, time/batch = 15.5764s	
17451/25300 (epoch 34.488), train_loss = 0.92737095, grad/param norm = 2.5040e-01, time/batch = 15.5661s	
17452/25300 (epoch 34.490), train_loss = 0.80583552, grad/param norm = 2.3785e-01, time/batch = 15.5008s	
17453/25300 (epoch 34.492), train_loss = 0.87638083, grad/param norm = 2.1289e-01, time/batch = 15.5806s	
17454/25300 (epoch 34.494), train_loss = 0.76129373, grad/param norm = 1.9848e-01, time/batch = 15.7900s	
17455/25300 (epoch 34.496), train_loss = 0.81910310, grad/param norm = 2.2380e-01, time/batch = 15.8906s	
17456/25300 (epoch 34.498), train_loss = 0.76794833, grad/param norm = 2.0810e-01, time/batch = 16.6586s	
17457/25300 (epoch 34.500), train_loss = 0.91093577, grad/param norm = 2.4741e-01, time/batch = 15.7443s	
17458/25300 (epoch 34.502), train_loss = 0.83343881, grad/param norm = 2.3240e-01, time/batch = 15.6284s	
17459/25300 (epoch 34.504), train_loss = 0.73287629, grad/param norm = 2.2172e-01, time/batch = 15.9782s	
17460/25300 (epoch 34.506), train_loss = 0.67043200, grad/param norm = 2.6641e-01, time/batch = 15.9809s	
17461/25300 (epoch 34.508), train_loss = 0.76611483, grad/param norm = 2.3760e-01, time/batch = 16.6471s	
17462/25300 (epoch 34.510), train_loss = 0.71955264, grad/param norm = 2.1719e-01, time/batch = 15.5334s	
17463/25300 (epoch 34.512), train_loss = 0.60072637, grad/param norm = 2.2836e-01, time/batch = 16.1592s	
17464/25300 (epoch 34.514), train_loss = 0.75356387, grad/param norm = 2.1587e-01, time/batch = 16.0639s	
17465/25300 (epoch 34.516), train_loss = 0.82700952, grad/param norm = 2.5137e-01, time/batch = 15.6494s	
17466/25300 (epoch 34.518), train_loss = 0.87433935, grad/param norm = 2.4137e-01, time/batch = 15.3325s	
17467/25300 (epoch 34.520), train_loss = 0.61740524, grad/param norm = 1.6561e-01, time/batch = 15.7437s	
17468/25300 (epoch 34.522), train_loss = 0.69864889, grad/param norm = 2.1587e-01, time/batch = 15.9962s	
17469/25300 (epoch 34.524), train_loss = 0.70939775, grad/param norm = 2.1332e-01, time/batch = 15.3932s	
17470/25300 (epoch 34.526), train_loss = 0.88813830, grad/param norm = 2.2793e-01, time/batch = 15.4623s	
17471/25300 (epoch 34.528), train_loss = 0.88696185, grad/param norm = 2.3657e-01, time/batch = 16.7275s	
17472/25300 (epoch 34.530), train_loss = 0.81608984, grad/param norm = 2.0739e-01, time/batch = 15.4963s	
17473/25300 (epoch 34.532), train_loss = 0.74644341, grad/param norm = 2.1656e-01, time/batch = 15.2978s	
17474/25300 (epoch 34.534), train_loss = 0.72238245, grad/param norm = 2.3842e-01, time/batch = 15.6423s	
17475/25300 (epoch 34.536), train_loss = 0.61127514, grad/param norm = 2.0141e-01, time/batch = 16.4065s	
17476/25300 (epoch 34.538), train_loss = 0.67733988, grad/param norm = 2.3372e-01, time/batch = 16.4017s	
17477/25300 (epoch 34.540), train_loss = 0.65647427, grad/param norm = 1.8820e-01, time/batch = 16.1441s	
17478/25300 (epoch 34.542), train_loss = 0.63784892, grad/param norm = 2.1169e-01, time/batch = 16.2321s	
17479/25300 (epoch 34.543), train_loss = 0.62467438, grad/param norm = 1.7937e-01, time/batch = 16.0592s	
17480/25300 (epoch 34.545), train_loss = 0.94240605, grad/param norm = 2.3398e-01, time/batch = 16.4742s	
17481/25300 (epoch 34.547), train_loss = 0.83482748, grad/param norm = 2.2657e-01, time/batch = 16.0685s	
17482/25300 (epoch 34.549), train_loss = 0.96246704, grad/param norm = 3.1520e-01, time/batch = 16.6416s	
17483/25300 (epoch 34.551), train_loss = 0.87541675, grad/param norm = 2.5081e-01, time/batch = 16.2287s	
17484/25300 (epoch 34.553), train_loss = 0.73054416, grad/param norm = 2.6706e-01, time/batch = 16.3895s	
17485/25300 (epoch 34.555), train_loss = 0.82306741, grad/param norm = 2.6702e-01, time/batch = 16.1393s	
17486/25300 (epoch 34.557), train_loss = 0.86087441, grad/param norm = 2.4665e-01, time/batch = 16.9033s	
17487/25300 (epoch 34.559), train_loss = 0.90523644, grad/param norm = 2.4990e-01, time/batch = 15.8209s	
17488/25300 (epoch 34.561), train_loss = 0.90428574, grad/param norm = 2.6349e-01, time/batch = 15.6164s	
17489/25300 (epoch 34.563), train_loss = 0.87593964, grad/param norm = 2.4669e-01, time/batch = 16.0727s	
17490/25300 (epoch 34.565), train_loss = 0.65274519, grad/param norm = 1.8304e-01, time/batch = 15.5832s	
17491/25300 (epoch 34.567), train_loss = 0.61014553, grad/param norm = 2.0116e-01, time/batch = 15.9790s	
17492/25300 (epoch 34.569), train_loss = 0.80339046, grad/param norm = 2.3272e-01, time/batch = 15.9004s	
17493/25300 (epoch 34.571), train_loss = 0.84930488, grad/param norm = 2.2798e-01, time/batch = 16.4123s	
17494/25300 (epoch 34.573), train_loss = 0.76296475, grad/param norm = 2.1361e-01, time/batch = 15.8137s	
17495/25300 (epoch 34.575), train_loss = 0.82593761, grad/param norm = 2.4117e-01, time/batch = 15.8051s	
17496/25300 (epoch 34.577), train_loss = 0.73852171, grad/param norm = 2.5933e-01, time/batch = 15.8256s	
17497/25300 (epoch 34.579), train_loss = 0.86521549, grad/param norm = 2.1475e-01, time/batch = 16.1492s	
17498/25300 (epoch 34.581), train_loss = 0.83871267, grad/param norm = 2.3979e-01, time/batch = 15.9798s	
17499/25300 (epoch 34.583), train_loss = 0.64565504, grad/param norm = 2.0766e-01, time/batch = 15.3204s	
17500/25300 (epoch 34.585), train_loss = 0.64486554, grad/param norm = 2.0254e-01, time/batch = 16.0856s	
17501/25300 (epoch 34.587), train_loss = 0.75945423, grad/param norm = 2.0475e-01, time/batch = 15.9040s	
17502/25300 (epoch 34.589), train_loss = 0.67248822, grad/param norm = 1.7465e-01, time/batch = 15.9936s	
17503/25300 (epoch 34.591), train_loss = 0.64044058, grad/param norm = 2.6547e-01, time/batch = 15.6030s	
17504/25300 (epoch 34.593), train_loss = 0.85225839, grad/param norm = 2.5523e-01, time/batch = 16.5734s	
17505/25300 (epoch 34.595), train_loss = 0.76669659, grad/param norm = 2.1190e-01, time/batch = 17.0622s	
17506/25300 (epoch 34.597), train_loss = 0.68827791, grad/param norm = 2.0223e-01, time/batch = 15.8859s	
17507/25300 (epoch 34.599), train_loss = 0.87814522, grad/param norm = 2.4736e-01, time/batch = 15.3248s	
17508/25300 (epoch 34.601), train_loss = 0.76001726, grad/param norm = 2.1217e-01, time/batch = 15.2480s	
17509/25300 (epoch 34.603), train_loss = 0.76720416, grad/param norm = 2.1540e-01, time/batch = 15.3391s	
17510/25300 (epoch 34.605), train_loss = 0.76856610, grad/param norm = 2.7498e-01, time/batch = 15.7321s	
17511/25300 (epoch 34.607), train_loss = 0.54924999, grad/param norm = 1.6993e-01, time/batch = 16.3292s	
17512/25300 (epoch 34.609), train_loss = 0.70342669, grad/param norm = 2.1184e-01, time/batch = 16.6530s	
17513/25300 (epoch 34.611), train_loss = 0.79569912, grad/param norm = 2.1455e-01, time/batch = 15.9662s	
17514/25300 (epoch 34.613), train_loss = 0.66135600, grad/param norm = 1.9007e-01, time/batch = 15.5674s	
17515/25300 (epoch 34.615), train_loss = 0.73490612, grad/param norm = 2.1036e-01, time/batch = 15.9021s	
17516/25300 (epoch 34.617), train_loss = 0.77018643, grad/param norm = 2.2908e-01, time/batch = 16.6505s	
17517/25300 (epoch 34.619), train_loss = 0.79625283, grad/param norm = 2.1278e-01, time/batch = 15.5553s	
17518/25300 (epoch 34.621), train_loss = 0.85013501, grad/param norm = 2.3047e-01, time/batch = 16.3069s	
17519/25300 (epoch 34.623), train_loss = 0.72092879, grad/param norm = 2.2339e-01, time/batch = 15.5880s	
17520/25300 (epoch 34.625), train_loss = 0.65955042, grad/param norm = 2.2211e-01, time/batch = 15.5991s	
17521/25300 (epoch 34.626), train_loss = 0.74728886, grad/param norm = 2.1284e-01, time/batch = 15.6972s	
17522/25300 (epoch 34.628), train_loss = 0.85026056, grad/param norm = 2.3844e-01, time/batch = 15.6727s	
17523/25300 (epoch 34.630), train_loss = 0.83084053, grad/param norm = 2.4065e-01, time/batch = 15.8354s	
17524/25300 (epoch 34.632), train_loss = 0.78729970, grad/param norm = 2.4587e-01, time/batch = 15.7957s	
17525/25300 (epoch 34.634), train_loss = 0.87084730, grad/param norm = 2.8519e-01, time/batch = 15.7139s	
17526/25300 (epoch 34.636), train_loss = 0.69072860, grad/param norm = 2.1651e-01, time/batch = 16.4542s	
17527/25300 (epoch 34.638), train_loss = 0.79639506, grad/param norm = 2.5485e-01, time/batch = 15.6523s	
17528/25300 (epoch 34.640), train_loss = 0.96724962, grad/param norm = 3.0900e-01, time/batch = 15.7277s	
17529/25300 (epoch 34.642), train_loss = 0.81325929, grad/param norm = 2.6417e-01, time/batch = 15.7918s	
17530/25300 (epoch 34.644), train_loss = 0.78709088, grad/param norm = 2.2919e-01, time/batch = 16.3809s	
17531/25300 (epoch 34.646), train_loss = 0.71599789, grad/param norm = 2.8697e-01, time/batch = 15.8974s	
17532/25300 (epoch 34.648), train_loss = 0.86020567, grad/param norm = 2.1314e-01, time/batch = 15.4743s	
17533/25300 (epoch 34.650), train_loss = 0.79802820, grad/param norm = 2.2484e-01, time/batch = 15.1112s	
17534/25300 (epoch 34.652), train_loss = 0.80495111, grad/param norm = 2.4030e-01, time/batch = 15.3297s	
17535/25300 (epoch 34.654), train_loss = 0.91470385, grad/param norm = 2.3932e-01, time/batch = 15.4108s	
17536/25300 (epoch 34.656), train_loss = 0.83725243, grad/param norm = 2.5211e-01, time/batch = 15.5671s	
17537/25300 (epoch 34.658), train_loss = 0.61189400, grad/param norm = 1.9330e-01, time/batch = 15.6218s	
17538/25300 (epoch 34.660), train_loss = 0.62614802, grad/param norm = 2.0059e-01, time/batch = 15.5788s	
17539/25300 (epoch 34.662), train_loss = 0.65522137, grad/param norm = 1.9994e-01, time/batch = 15.7001s	
17540/25300 (epoch 34.664), train_loss = 0.60256553, grad/param norm = 2.0167e-01, time/batch = 15.4033s	
17541/25300 (epoch 34.666), train_loss = 0.65869370, grad/param norm = 1.9675e-01, time/batch = 15.6378s	
17542/25300 (epoch 34.668), train_loss = 0.76353758, grad/param norm = 2.6112e-01, time/batch = 16.2253s	
17543/25300 (epoch 34.670), train_loss = 0.70135863, grad/param norm = 2.6122e-01, time/batch = 16.6502s	
17544/25300 (epoch 34.672), train_loss = 0.67974585, grad/param norm = 2.0849e-01, time/batch = 15.2173s	
17545/25300 (epoch 34.674), train_loss = 0.69753981, grad/param norm = 1.8719e-01, time/batch = 15.8199s	
17546/25300 (epoch 34.676), train_loss = 0.70515349, grad/param norm = 2.3880e-01, time/batch = 15.2030s	
17547/25300 (epoch 34.678), train_loss = 0.70558174, grad/param norm = 2.1558e-01, time/batch = 15.3219s	
17548/25300 (epoch 34.680), train_loss = 0.61994743, grad/param norm = 1.9451e-01, time/batch = 15.4841s	
17549/25300 (epoch 34.682), train_loss = 0.53977341, grad/param norm = 1.8935e-01, time/batch = 15.8008s	
17550/25300 (epoch 34.684), train_loss = 0.69486548, grad/param norm = 1.8413e-01, time/batch = 15.3146s	
17551/25300 (epoch 34.686), train_loss = 0.63546490, grad/param norm = 1.9435e-01, time/batch = 15.8840s	
17552/25300 (epoch 34.688), train_loss = 0.72861913, grad/param norm = 2.2827e-01, time/batch = 15.3988s	
17553/25300 (epoch 34.690), train_loss = 0.63859662, grad/param norm = 1.8280e-01, time/batch = 15.5745s	
17554/25300 (epoch 34.692), train_loss = 0.69527999, grad/param norm = 2.1143e-01, time/batch = 16.2349s	
17555/25300 (epoch 34.694), train_loss = 0.67783203, grad/param norm = 2.1851e-01, time/batch = 15.5508s	
17556/25300 (epoch 34.696), train_loss = 0.74329081, grad/param norm = 2.4592e-01, time/batch = 15.8040s	
17557/25300 (epoch 34.698), train_loss = 0.81090018, grad/param norm = 2.4414e-01, time/batch = 16.4018s	
17558/25300 (epoch 34.700), train_loss = 0.58925968, grad/param norm = 1.7274e-01, time/batch = 15.7383s	
17559/25300 (epoch 34.702), train_loss = 0.80338261, grad/param norm = 2.2481e-01, time/batch = 15.4704s	
17560/25300 (epoch 34.704), train_loss = 0.59293155, grad/param norm = 1.8696e-01, time/batch = 15.3140s	
17561/25300 (epoch 34.706), train_loss = 0.72511543, grad/param norm = 2.2402e-01, time/batch = 15.7281s	
17562/25300 (epoch 34.708), train_loss = 0.62348843, grad/param norm = 1.8267e-01, time/batch = 18.2126s	
17563/25300 (epoch 34.709), train_loss = 0.87758472, grad/param norm = 2.2730e-01, time/batch = 16.7959s	
17564/25300 (epoch 34.711), train_loss = 0.91703455, grad/param norm = 2.4681e-01, time/batch = 23.2870s	
17565/25300 (epoch 34.713), train_loss = 0.75315743, grad/param norm = 1.9016e-01, time/batch = 16.1606s	
17566/25300 (epoch 34.715), train_loss = 0.75124839, grad/param norm = 1.9138e-01, time/batch = 15.7355s	
17567/25300 (epoch 34.717), train_loss = 0.64517214, grad/param norm = 2.0030e-01, time/batch = 16.4693s	
17568/25300 (epoch 34.719), train_loss = 0.73893245, grad/param norm = 2.2250e-01, time/batch = 16.1612s	
17569/25300 (epoch 34.721), train_loss = 0.79963735, grad/param norm = 2.3085e-01, time/batch = 16.9964s	
17570/25300 (epoch 34.723), train_loss = 0.73416052, grad/param norm = 2.1436e-01, time/batch = 15.9106s	
17571/25300 (epoch 34.725), train_loss = 0.76699191, grad/param norm = 2.1053e-01, time/batch = 16.4868s	
17572/25300 (epoch 34.727), train_loss = 0.75528435, grad/param norm = 2.3038e-01, time/batch = 15.8133s	
17573/25300 (epoch 34.729), train_loss = 0.73016823, grad/param norm = 1.9769e-01, time/batch = 15.9073s	
17574/25300 (epoch 34.731), train_loss = 0.89479222, grad/param norm = 2.3737e-01, time/batch = 28.0681s	
17575/25300 (epoch 34.733), train_loss = 0.74220165, grad/param norm = 1.9636e-01, time/batch = 16.6501s	
17576/25300 (epoch 34.735), train_loss = 0.96465752, grad/param norm = 2.6133e-01, time/batch = 16.0665s	
17577/25300 (epoch 34.737), train_loss = 0.62668534, grad/param norm = 1.9884e-01, time/batch = 15.6488s	
17578/25300 (epoch 34.739), train_loss = 0.86819885, grad/param norm = 2.3330e-01, time/batch = 16.3280s	
17579/25300 (epoch 34.741), train_loss = 0.79037014, grad/param norm = 2.3701e-01, time/batch = 15.5341s	
17580/25300 (epoch 34.743), train_loss = 0.75050432, grad/param norm = 2.0448e-01, time/batch = 16.0558s	
17581/25300 (epoch 34.745), train_loss = 0.73184344, grad/param norm = 2.1587e-01, time/batch = 15.7062s	
17582/25300 (epoch 34.747), train_loss = 0.64870258, grad/param norm = 1.8161e-01, time/batch = 15.6648s	
17583/25300 (epoch 34.749), train_loss = 0.75213731, grad/param norm = 2.3965e-01, time/batch = 15.5760s	
17584/25300 (epoch 34.751), train_loss = 0.79832035, grad/param norm = 2.1760e-01, time/batch = 15.6387s	
17585/25300 (epoch 34.753), train_loss = 0.63607569, grad/param norm = 1.9656e-01, time/batch = 16.3118s	
17586/25300 (epoch 34.755), train_loss = 0.86394522, grad/param norm = 2.5187e-01, time/batch = 15.5778s	
17587/25300 (epoch 34.757), train_loss = 0.71125983, grad/param norm = 2.5577e-01, time/batch = 15.7410s	
17588/25300 (epoch 34.759), train_loss = 0.69418241, grad/param norm = 2.0840e-01, time/batch = 15.5679s	
17589/25300 (epoch 34.761), train_loss = 0.88434260, grad/param norm = 2.3757e-01, time/batch = 15.4788s	
17590/25300 (epoch 34.763), train_loss = 0.72749322, grad/param norm = 1.9774e-01, time/batch = 15.1699s	
17591/25300 (epoch 34.765), train_loss = 0.72454097, grad/param norm = 2.2662e-01, time/batch = 15.0894s	
17592/25300 (epoch 34.767), train_loss = 0.73496157, grad/param norm = 1.9639e-01, time/batch = 15.3841s	
17593/25300 (epoch 34.769), train_loss = 0.76286289, grad/param norm = 2.6269e-01, time/batch = 15.3947s	
17594/25300 (epoch 34.771), train_loss = 0.84490459, grad/param norm = 2.5732e-01, time/batch = 15.4915s	
17595/25300 (epoch 34.773), train_loss = 0.87426744, grad/param norm = 2.4459e-01, time/batch = 15.6577s	
17596/25300 (epoch 34.775), train_loss = 0.78185771, grad/param norm = 1.9385e-01, time/batch = 15.8083s	
17597/25300 (epoch 34.777), train_loss = 0.71276623, grad/param norm = 2.2107e-01, time/batch = 15.5534s	
17598/25300 (epoch 34.779), train_loss = 0.83258569, grad/param norm = 1.9556e-01, time/batch = 15.5712s	
17599/25300 (epoch 34.781), train_loss = 0.81716890, grad/param norm = 2.3775e-01, time/batch = 15.8232s	
17600/25300 (epoch 34.783), train_loss = 0.90196113, grad/param norm = 2.5370e-01, time/batch = 15.3861s	
17601/25300 (epoch 34.785), train_loss = 0.83914129, grad/param norm = 2.2598e-01, time/batch = 15.2554s	
17602/25300 (epoch 34.787), train_loss = 0.81791217, grad/param norm = 2.4288e-01, time/batch = 15.5769s	
17603/25300 (epoch 34.789), train_loss = 0.90385543, grad/param norm = 2.7372e-01, time/batch = 16.5566s	
17604/25300 (epoch 34.791), train_loss = 0.79567289, grad/param norm = 2.2718e-01, time/batch = 16.2304s	
17605/25300 (epoch 34.792), train_loss = 0.87219099, grad/param norm = 2.2696e-01, time/batch = 17.4020s	
17606/25300 (epoch 34.794), train_loss = 0.75481638, grad/param norm = 2.2789e-01, time/batch = 15.7477s	
17607/25300 (epoch 34.796), train_loss = 0.72801671, grad/param norm = 2.2823e-01, time/batch = 15.5560s	
17608/25300 (epoch 34.798), train_loss = 0.83588890, grad/param norm = 2.3510e-01, time/batch = 15.5611s	
17609/25300 (epoch 34.800), train_loss = 0.74253346, grad/param norm = 2.1131e-01, time/batch = 15.6337s	
17610/25300 (epoch 34.802), train_loss = 0.61921855, grad/param norm = 1.9208e-01, time/batch = 16.7432s	
17611/25300 (epoch 34.804), train_loss = 0.77822157, grad/param norm = 2.0448e-01, time/batch = 15.7069s	
17612/25300 (epoch 34.806), train_loss = 0.82053208, grad/param norm = 2.4263e-01, time/batch = 16.1646s	
17613/25300 (epoch 34.808), train_loss = 0.87757340, grad/param norm = 2.6808e-01, time/batch = 15.7205s	
17614/25300 (epoch 34.810), train_loss = 0.75258425, grad/param norm = 2.2376e-01, time/batch = 15.6215s	
17615/25300 (epoch 34.812), train_loss = 0.87229759, grad/param norm = 2.1607e-01, time/batch = 15.7495s	
17616/25300 (epoch 34.814), train_loss = 0.90710369, grad/param norm = 2.5738e-01, time/batch = 15.9135s	
17617/25300 (epoch 34.816), train_loss = 0.97931230, grad/param norm = 2.6490e-01, time/batch = 15.3221s	
17618/25300 (epoch 34.818), train_loss = 0.84768011, grad/param norm = 1.9955e-01, time/batch = 15.4070s	
17619/25300 (epoch 34.820), train_loss = 0.85152074, grad/param norm = 2.2381e-01, time/batch = 15.8913s	
17620/25300 (epoch 34.822), train_loss = 0.72153176, grad/param norm = 2.1998e-01, time/batch = 16.4136s	
17621/25300 (epoch 34.824), train_loss = 0.87569434, grad/param norm = 2.2478e-01, time/batch = 15.9971s	
17622/25300 (epoch 34.826), train_loss = 0.69433223, grad/param norm = 2.0371e-01, time/batch = 15.8117s	
17623/25300 (epoch 34.828), train_loss = 0.71237136, grad/param norm = 2.2214e-01, time/batch = 15.4234s	
17624/25300 (epoch 34.830), train_loss = 0.81324418, grad/param norm = 2.2935e-01, time/batch = 15.9201s	
17625/25300 (epoch 34.832), train_loss = 0.89175551, grad/param norm = 2.3633e-01, time/batch = 15.8222s	
17626/25300 (epoch 34.834), train_loss = 0.73329355, grad/param norm = 2.2540e-01, time/batch = 15.8110s	
17627/25300 (epoch 34.836), train_loss = 0.76093901, grad/param norm = 2.1027e-01, time/batch = 15.9928s	
17628/25300 (epoch 34.838), train_loss = 0.73773790, grad/param norm = 1.9832e-01, time/batch = 16.1467s	
17629/25300 (epoch 34.840), train_loss = 0.83066689, grad/param norm = 2.2538e-01, time/batch = 16.1475s	
17630/25300 (epoch 34.842), train_loss = 0.79862655, grad/param norm = 2.5227e-01, time/batch = 15.7248s	
17631/25300 (epoch 34.844), train_loss = 0.85922203, grad/param norm = 2.0298e-01, time/batch = 15.4048s	
17632/25300 (epoch 34.846), train_loss = 0.85302454, grad/param norm = 2.1386e-01, time/batch = 16.0037s	
17633/25300 (epoch 34.848), train_loss = 0.82952659, grad/param norm = 2.5138e-01, time/batch = 15.6484s	
17634/25300 (epoch 34.850), train_loss = 0.80330142, grad/param norm = 2.2347e-01, time/batch = 16.8141s	
17635/25300 (epoch 34.852), train_loss = 0.84442563, grad/param norm = 2.1038e-01, time/batch = 15.6602s	
17636/25300 (epoch 34.854), train_loss = 0.87630743, grad/param norm = 2.2388e-01, time/batch = 15.5819s	
17637/25300 (epoch 34.856), train_loss = 0.73132743, grad/param norm = 1.9918e-01, time/batch = 16.0766s	
17638/25300 (epoch 34.858), train_loss = 0.76639508, grad/param norm = 2.1286e-01, time/batch = 15.9833s	
17639/25300 (epoch 34.860), train_loss = 0.66038841, grad/param norm = 2.0626e-01, time/batch = 15.7181s	
17640/25300 (epoch 34.862), train_loss = 0.78726704, grad/param norm = 2.3577e-01, time/batch = 15.9239s	
17641/25300 (epoch 34.864), train_loss = 0.87743790, grad/param norm = 2.3327e-01, time/batch = 15.2442s	
17642/25300 (epoch 34.866), train_loss = 0.74592386, grad/param norm = 2.3265e-01, time/batch = 15.3159s	
17643/25300 (epoch 34.868), train_loss = 0.88058699, grad/param norm = 2.1192e-01, time/batch = 17.9844s	
17644/25300 (epoch 34.870), train_loss = 0.86488864, grad/param norm = 2.4137e-01, time/batch = 17.2145s	
17645/25300 (epoch 34.872), train_loss = 0.80662387, grad/param norm = 2.5410e-01, time/batch = 16.4774s	
17646/25300 (epoch 34.874), train_loss = 0.82845269, grad/param norm = 2.3098e-01, time/batch = 16.4982s	
17647/25300 (epoch 34.875), train_loss = 0.74855776, grad/param norm = 2.1417e-01, time/batch = 17.2341s	
17648/25300 (epoch 34.877), train_loss = 0.75013655, grad/param norm = 2.1589e-01, time/batch = 17.0358s	
17649/25300 (epoch 34.879), train_loss = 0.71193749, grad/param norm = 2.4942e-01, time/batch = 16.6379s	
17650/25300 (epoch 34.881), train_loss = 1.02393482, grad/param norm = 2.9326e-01, time/batch = 17.8216s	
17651/25300 (epoch 34.883), train_loss = 1.00515446, grad/param norm = 2.6051e-01, time/batch = 16.7126s	
17652/25300 (epoch 34.885), train_loss = 0.86598082, grad/param norm = 2.8619e-01, time/batch = 15.7890s	
17653/25300 (epoch 34.887), train_loss = 0.86009277, grad/param norm = 2.2084e-01, time/batch = 17.5518s	
17654/25300 (epoch 34.889), train_loss = 0.93665357, grad/param norm = 2.5223e-01, time/batch = 19.2232s	
17655/25300 (epoch 34.891), train_loss = 0.82399646, grad/param norm = 2.3473e-01, time/batch = 16.5576s	
17656/25300 (epoch 34.893), train_loss = 0.80085818, grad/param norm = 2.3143e-01, time/batch = 16.0665s	
17657/25300 (epoch 34.895), train_loss = 0.61808018, grad/param norm = 1.9560e-01, time/batch = 17.0489s	
17658/25300 (epoch 34.897), train_loss = 0.69531688, grad/param norm = 1.9410e-01, time/batch = 17.4444s	
17659/25300 (epoch 34.899), train_loss = 0.80678671, grad/param norm = 2.3366e-01, time/batch = 16.6492s	
17660/25300 (epoch 34.901), train_loss = 0.86489707, grad/param norm = 2.3831e-01, time/batch = 16.7366s	
17661/25300 (epoch 34.903), train_loss = 0.65918753, grad/param norm = 2.3615e-01, time/batch = 16.1703s	
17662/25300 (epoch 34.905), train_loss = 0.74024977, grad/param norm = 2.8225e-01, time/batch = 15.4854s	
17663/25300 (epoch 34.907), train_loss = 0.73524824, grad/param norm = 2.4432e-01, time/batch = 15.5725s	
17664/25300 (epoch 34.909), train_loss = 0.82788256, grad/param norm = 2.1764e-01, time/batch = 15.6603s	
17665/25300 (epoch 34.911), train_loss = 0.90083944, grad/param norm = 2.4744e-01, time/batch = 16.1623s	
17666/25300 (epoch 34.913), train_loss = 0.99214522, grad/param norm = 2.7461e-01, time/batch = 15.2365s	
17667/25300 (epoch 34.915), train_loss = 0.74809497, grad/param norm = 2.4621e-01, time/batch = 15.3750s	
17668/25300 (epoch 34.917), train_loss = 0.93188930, grad/param norm = 2.3369e-01, time/batch = 15.7340s	
17669/25300 (epoch 34.919), train_loss = 0.91615377, grad/param norm = 2.5715e-01, time/batch = 15.8279s	
17670/25300 (epoch 34.921), train_loss = 0.76042039, grad/param norm = 2.2119e-01, time/batch = 15.6401s	
17671/25300 (epoch 34.923), train_loss = 0.87621556, grad/param norm = 2.3026e-01, time/batch = 16.1470s	
17672/25300 (epoch 34.925), train_loss = 0.79512210, grad/param norm = 2.2613e-01, time/batch = 15.8296s	
17673/25300 (epoch 34.927), train_loss = 0.77024108, grad/param norm = 2.3369e-01, time/batch = 16.2205s	
17674/25300 (epoch 34.929), train_loss = 0.83631898, grad/param norm = 2.4356e-01, time/batch = 15.9746s	
17675/25300 (epoch 34.931), train_loss = 0.86397026, grad/param norm = 2.3657e-01, time/batch = 15.3826s	
17676/25300 (epoch 34.933), train_loss = 0.82300872, grad/param norm = 2.1088e-01, time/batch = 16.6583s	
17677/25300 (epoch 34.935), train_loss = 0.84006592, grad/param norm = 2.2186e-01, time/batch = 16.8043s	
17678/25300 (epoch 34.937), train_loss = 0.64484549, grad/param norm = 2.0596e-01, time/batch = 15.9649s	
17679/25300 (epoch 34.939), train_loss = 0.81092725, grad/param norm = 2.1689e-01, time/batch = 15.9867s	
17680/25300 (epoch 34.941), train_loss = 0.73677477, grad/param norm = 2.3360e-01, time/batch = 16.7439s	
17681/25300 (epoch 34.943), train_loss = 0.81724310, grad/param norm = 2.2511e-01, time/batch = 15.4811s	
17682/25300 (epoch 34.945), train_loss = 0.82479777, grad/param norm = 2.3971e-01, time/batch = 16.9827s	
17683/25300 (epoch 34.947), train_loss = 0.73256332, grad/param norm = 2.2654e-01, time/batch = 15.9181s	
17684/25300 (epoch 34.949), train_loss = 0.83083926, grad/param norm = 2.0924e-01, time/batch = 16.5662s	
17685/25300 (epoch 34.951), train_loss = 0.78704104, grad/param norm = 2.0426e-01, time/batch = 15.7997s	
17686/25300 (epoch 34.953), train_loss = 0.75702124, grad/param norm = 2.3182e-01, time/batch = 15.3045s	
17687/25300 (epoch 34.955), train_loss = 0.99542078, grad/param norm = 2.8132e-01, time/batch = 15.3745s	
17688/25300 (epoch 34.957), train_loss = 0.90442525, grad/param norm = 2.8572e-01, time/batch = 15.4400s	
17689/25300 (epoch 34.958), train_loss = 0.87726932, grad/param norm = 2.6335e-01, time/batch = 15.4211s	
17690/25300 (epoch 34.960), train_loss = 0.98192538, grad/param norm = 2.7146e-01, time/batch = 15.2830s	
17691/25300 (epoch 34.962), train_loss = 0.92432228, grad/param norm = 2.3796e-01, time/batch = 15.4298s	
17692/25300 (epoch 34.964), train_loss = 0.84232568, grad/param norm = 2.7890e-01, time/batch = 15.3507s	
17693/25300 (epoch 34.966), train_loss = 0.71816958, grad/param norm = 2.3269e-01, time/batch = 15.4719s	
17694/25300 (epoch 34.968), train_loss = 0.70372593, grad/param norm = 2.1737e-01, time/batch = 15.6406s	
17695/25300 (epoch 34.970), train_loss = 0.78059529, grad/param norm = 2.5079e-01, time/batch = 15.4036s	
17696/25300 (epoch 34.972), train_loss = 0.78881227, grad/param norm = 2.1505e-01, time/batch = 15.9694s	
17697/25300 (epoch 34.974), train_loss = 0.90856259, grad/param norm = 2.7474e-01, time/batch = 15.8852s	
17698/25300 (epoch 34.976), train_loss = 0.83070725, grad/param norm = 2.4356e-01, time/batch = 16.5515s	
17699/25300 (epoch 34.978), train_loss = 0.77547472, grad/param norm = 2.2565e-01, time/batch = 15.6314s	
17700/25300 (epoch 34.980), train_loss = 0.79870165, grad/param norm = 2.4434e-01, time/batch = 15.7829s	
17701/25300 (epoch 34.982), train_loss = 0.75208324, grad/param norm = 2.1700e-01, time/batch = 15.9670s	
17702/25300 (epoch 34.984), train_loss = 0.79809354, grad/param norm = 2.4877e-01, time/batch = 16.7196s	
17703/25300 (epoch 34.986), train_loss = 0.85582368, grad/param norm = 2.4176e-01, time/batch = 16.0450s	
17704/25300 (epoch 34.988), train_loss = 0.83049165, grad/param norm = 2.5298e-01, time/batch = 15.7843s	
17705/25300 (epoch 34.990), train_loss = 0.81733660, grad/param norm = 2.2478e-01, time/batch = 15.5641s	
17706/25300 (epoch 34.992), train_loss = 0.69995834, grad/param norm = 1.9881e-01, time/batch = 15.6382s	
17707/25300 (epoch 34.994), train_loss = 0.81112976, grad/param norm = 2.2905e-01, time/batch = 15.5287s	
17708/25300 (epoch 34.996), train_loss = 0.90567934, grad/param norm = 2.3840e-01, time/batch = 15.4002s	
17709/25300 (epoch 34.998), train_loss = 0.87290176, grad/param norm = 2.4048e-01, time/batch = 15.4170s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
17710/25300 (epoch 35.000), train_loss = 0.89094247, grad/param norm = 2.8673e-01, time/batch = 15.6431s	
17711/25300 (epoch 35.002), train_loss = 0.81695223, grad/param norm = 2.1725e-01, time/batch = 15.5705s	
17712/25300 (epoch 35.004), train_loss = 0.69582262, grad/param norm = 2.1965e-01, time/batch = 15.4057s	
17713/25300 (epoch 35.006), train_loss = 0.96908663, grad/param norm = 2.7019e-01, time/batch = 15.3081s	
17714/25300 (epoch 35.008), train_loss = 0.80681320, grad/param norm = 1.9735e-01, time/batch = 15.8101s	
17715/25300 (epoch 35.010), train_loss = 0.84109788, grad/param norm = 2.0208e-01, time/batch = 15.7315s	
17716/25300 (epoch 35.012), train_loss = 0.76930995, grad/param norm = 2.1116e-01, time/batch = 16.1511s	
17717/25300 (epoch 35.014), train_loss = 0.92947433, grad/param norm = 2.4305e-01, time/batch = 16.0769s	
17718/25300 (epoch 35.016), train_loss = 0.81445992, grad/param norm = 2.4542e-01, time/batch = 15.5637s	
17719/25300 (epoch 35.018), train_loss = 0.71503521, grad/param norm = 2.0768e-01, time/batch = 15.7927s	
17720/25300 (epoch 35.020), train_loss = 0.81474270, grad/param norm = 2.0410e-01, time/batch = 15.5553s	
17721/25300 (epoch 35.022), train_loss = 0.80069679, grad/param norm = 2.5465e-01, time/batch = 15.6288s	
17722/25300 (epoch 35.024), train_loss = 0.61705571, grad/param norm = 1.6744e-01, time/batch = 15.2976s	
17723/25300 (epoch 35.026), train_loss = 0.77037542, grad/param norm = 2.3212e-01, time/batch = 15.3638s	
17724/25300 (epoch 35.028), train_loss = 0.75678302, grad/param norm = 2.1780e-01, time/batch = 15.4935s	
17725/25300 (epoch 35.030), train_loss = 0.90447995, grad/param norm = 2.0314e-01, time/batch = 15.1195s	
17726/25300 (epoch 35.032), train_loss = 0.77240911, grad/param norm = 2.2638e-01, time/batch = 15.3215s	
17727/25300 (epoch 35.034), train_loss = 0.70442700, grad/param norm = 2.1095e-01, time/batch = 15.3959s	
17728/25300 (epoch 35.036), train_loss = 0.65532836, grad/param norm = 2.2610e-01, time/batch = 15.6456s	
17729/25300 (epoch 35.038), train_loss = 0.61991414, grad/param norm = 1.9721e-01, time/batch = 15.9073s	
17730/25300 (epoch 35.040), train_loss = 0.79058930, grad/param norm = 2.1445e-01, time/batch = 15.6494s	
17731/25300 (epoch 35.042), train_loss = 0.76763363, grad/param norm = 1.8787e-01, time/batch = 15.8159s	
17732/25300 (epoch 35.043), train_loss = 0.68761427, grad/param norm = 1.8697e-01, time/batch = 16.4751s	
17733/25300 (epoch 35.045), train_loss = 0.67225722, grad/param norm = 1.8224e-01, time/batch = 16.2979s	
17734/25300 (epoch 35.047), train_loss = 0.80890528, grad/param norm = 2.0975e-01, time/batch = 15.6096s	
17735/25300 (epoch 35.049), train_loss = 0.79232242, grad/param norm = 2.3219e-01, time/batch = 15.5413s	
17736/25300 (epoch 35.051), train_loss = 0.91863027, grad/param norm = 2.3136e-01, time/batch = 15.8248s	
17737/25300 (epoch 35.053), train_loss = 0.62921213, grad/param norm = 1.9866e-01, time/batch = 16.7464s	
17738/25300 (epoch 35.055), train_loss = 0.64838631, grad/param norm = 1.9396e-01, time/batch = 15.3878s	
17739/25300 (epoch 35.057), train_loss = 0.64072345, grad/param norm = 1.6524e-01, time/batch = 16.8185s	
17740/25300 (epoch 35.059), train_loss = 0.74425628, grad/param norm = 2.3647e-01, time/batch = 16.6285s	
17741/25300 (epoch 35.061), train_loss = 0.74106832, grad/param norm = 2.6741e-01, time/batch = 16.6345s	
17742/25300 (epoch 35.063), train_loss = 0.72073343, grad/param norm = 1.8842e-01, time/batch = 15.6076s	
17743/25300 (epoch 35.065), train_loss = 0.77140745, grad/param norm = 2.0905e-01, time/batch = 16.7386s	
17744/25300 (epoch 35.067), train_loss = 0.84809964, grad/param norm = 2.0730e-01, time/batch = 15.6373s	
17745/25300 (epoch 35.069), train_loss = 0.68805012, grad/param norm = 2.1232e-01, time/batch = 17.5485s	
17746/25300 (epoch 35.071), train_loss = 0.82154556, grad/param norm = 2.4694e-01, time/batch = 15.7303s	
17747/25300 (epoch 35.073), train_loss = 0.74835625, grad/param norm = 1.8530e-01, time/batch = 15.8297s	
17748/25300 (epoch 35.075), train_loss = 0.83419325, grad/param norm = 2.1454e-01, time/batch = 16.8755s	
17749/25300 (epoch 35.077), train_loss = 0.80013330, grad/param norm = 2.2491e-01, time/batch = 16.8837s	
17750/25300 (epoch 35.079), train_loss = 0.69181421, grad/param norm = 1.8275e-01, time/batch = 17.0682s	
17751/25300 (epoch 35.081), train_loss = 0.77729387, grad/param norm = 1.7811e-01, time/batch = 15.9144s	
17752/25300 (epoch 35.083), train_loss = 0.79330909, grad/param norm = 1.9271e-01, time/batch = 15.8058s	
17753/25300 (epoch 35.085), train_loss = 0.96371341, grad/param norm = 2.4222e-01, time/batch = 15.3325s	
17754/25300 (epoch 35.087), train_loss = 0.86664049, grad/param norm = 2.0233e-01, time/batch = 18.3020s	
17755/25300 (epoch 35.089), train_loss = 0.82421795, grad/param norm = 2.0554e-01, time/batch = 15.8375s	
17756/25300 (epoch 35.091), train_loss = 0.95335131, grad/param norm = 2.3178e-01, time/batch = 15.3072s	
17757/25300 (epoch 35.093), train_loss = 0.89159925, grad/param norm = 2.3589e-01, time/batch = 16.1445s	
17758/25300 (epoch 35.095), train_loss = 0.87186466, grad/param norm = 2.2247e-01, time/batch = 15.4039s	
17759/25300 (epoch 35.097), train_loss = 0.84049363, grad/param norm = 2.3057e-01, time/batch = 15.8224s	
17760/25300 (epoch 35.099), train_loss = 0.83099436, grad/param norm = 2.3250e-01, time/batch = 15.6982s	
17761/25300 (epoch 35.101), train_loss = 0.78767639, grad/param norm = 2.4235e-01, time/batch = 16.0014s	
17762/25300 (epoch 35.103), train_loss = 0.79561043, grad/param norm = 1.9893e-01, time/batch = 16.1399s	
17763/25300 (epoch 35.105), train_loss = 0.84838986, grad/param norm = 2.0294e-01, time/batch = 15.1413s	
17764/25300 (epoch 35.107), train_loss = 0.85210713, grad/param norm = 2.7806e-01, time/batch = 15.5722s	
17765/25300 (epoch 35.109), train_loss = 0.78356855, grad/param norm = 2.3983e-01, time/batch = 15.8221s	
17766/25300 (epoch 35.111), train_loss = 0.76935260, grad/param norm = 2.0617e-01, time/batch = 15.8211s	
17767/25300 (epoch 35.113), train_loss = 0.74122887, grad/param norm = 2.0994e-01, time/batch = 16.1434s	
17768/25300 (epoch 35.115), train_loss = 0.76547252, grad/param norm = 2.3761e-01, time/batch = 15.8032s	
17769/25300 (epoch 35.117), train_loss = 0.86708056, grad/param norm = 2.2077e-01, time/batch = 15.6589s	
17770/25300 (epoch 35.119), train_loss = 0.74233136, grad/param norm = 2.2323e-01, time/batch = 16.0758s	
17771/25300 (epoch 35.121), train_loss = 0.79909032, grad/param norm = 2.4689e-01, time/batch = 15.6538s	
17772/25300 (epoch 35.123), train_loss = 0.71931119, grad/param norm = 2.1908e-01, time/batch = 15.3907s	
17773/25300 (epoch 35.125), train_loss = 0.86841706, grad/param norm = 2.1994e-01, time/batch = 15.1637s	
17774/25300 (epoch 35.126), train_loss = 0.79185212, grad/param norm = 2.0971e-01, time/batch = 15.8306s	
17775/25300 (epoch 35.128), train_loss = 0.76975463, grad/param norm = 2.1705e-01, time/batch = 15.6211s	
17776/25300 (epoch 35.130), train_loss = 0.62633101, grad/param norm = 1.8868e-01, time/batch = 15.4199s	
17777/25300 (epoch 35.132), train_loss = 0.65790527, grad/param norm = 2.1185e-01, time/batch = 16.2462s	
17778/25300 (epoch 35.134), train_loss = 0.65891182, grad/param norm = 1.7466e-01, time/batch = 15.4224s	
17779/25300 (epoch 35.136), train_loss = 0.76766413, grad/param norm = 1.9732e-01, time/batch = 15.8938s	
17780/25300 (epoch 35.138), train_loss = 0.67471617, grad/param norm = 1.7993e-01, time/batch = 16.2368s	
17781/25300 (epoch 35.140), train_loss = 0.67561667, grad/param norm = 2.1975e-01, time/batch = 15.8263s	
17782/25300 (epoch 35.142), train_loss = 0.87710041, grad/param norm = 2.1678e-01, time/batch = 15.4680s	
17783/25300 (epoch 35.144), train_loss = 0.86302610, grad/param norm = 2.3352e-01, time/batch = 15.2490s	
17784/25300 (epoch 35.146), train_loss = 0.77885682, grad/param norm = 2.3967e-01, time/batch = 15.1633s	
17785/25300 (epoch 35.148), train_loss = 0.76848599, grad/param norm = 1.9505e-01, time/batch = 16.0761s	
17786/25300 (epoch 35.150), train_loss = 0.81288715, grad/param norm = 2.1621e-01, time/batch = 15.8261s	
17787/25300 (epoch 35.152), train_loss = 0.91349973, grad/param norm = 2.5222e-01, time/batch = 15.7339s	
17788/25300 (epoch 35.154), train_loss = 0.65297701, grad/param norm = 1.8422e-01, time/batch = 16.6696s	
17789/25300 (epoch 35.156), train_loss = 0.81624365, grad/param norm = 2.3143e-01, time/batch = 16.1503s	
17790/25300 (epoch 35.158), train_loss = 0.68014469, grad/param norm = 2.2966e-01, time/batch = 15.6423s	
17791/25300 (epoch 35.160), train_loss = 0.79478441, grad/param norm = 2.1344e-01, time/batch = 15.8394s	
17792/25300 (epoch 35.162), train_loss = 0.72657315, grad/param norm = 2.2580e-01, time/batch = 15.4887s	
17793/25300 (epoch 35.164), train_loss = 0.84228912, grad/param norm = 2.7297e-01, time/batch = 15.9931s	
17794/25300 (epoch 35.166), train_loss = 0.80017656, grad/param norm = 2.2114e-01, time/batch = 15.4783s	
17795/25300 (epoch 35.168), train_loss = 0.72253752, grad/param norm = 1.7943e-01, time/batch = 15.3984s	
17796/25300 (epoch 35.170), train_loss = 0.71708147, grad/param norm = 1.8695e-01, time/batch = 15.6610s	
17797/25300 (epoch 35.172), train_loss = 0.67536262, grad/param norm = 1.9876e-01, time/batch = 15.5804s	
17798/25300 (epoch 35.174), train_loss = 0.71830027, grad/param norm = 2.6170e-01, time/batch = 28.4226s	
17799/25300 (epoch 35.176), train_loss = 0.68431553, grad/param norm = 2.3003e-01, time/batch = 15.4998s	
17800/25300 (epoch 35.178), train_loss = 0.92232003, grad/param norm = 2.4945e-01, time/batch = 15.7422s	
17801/25300 (epoch 35.180), train_loss = 0.63894043, grad/param norm = 1.9514e-01, time/batch = 17.1400s	
17802/25300 (epoch 35.182), train_loss = 0.73615249, grad/param norm = 2.0677e-01, time/batch = 15.0713s	
17803/25300 (epoch 35.184), train_loss = 0.70412404, grad/param norm = 2.1357e-01, time/batch = 15.8120s	
17804/25300 (epoch 35.186), train_loss = 0.66860813, grad/param norm = 2.2857e-01, time/batch = 15.6487s	
17805/25300 (epoch 35.188), train_loss = 0.78592837, grad/param norm = 2.5087e-01, time/batch = 15.6500s	
17806/25300 (epoch 35.190), train_loss = 0.78360171, grad/param norm = 2.4846e-01, time/batch = 16.4057s	
17807/25300 (epoch 35.192), train_loss = 0.75608574, grad/param norm = 2.0516e-01, time/batch = 17.1591s	
17808/25300 (epoch 35.194), train_loss = 0.72271131, grad/param norm = 2.0521e-01, time/batch = 15.4624s	
17809/25300 (epoch 35.196), train_loss = 0.86790573, grad/param norm = 2.3863e-01, time/batch = 15.4918s	
17810/25300 (epoch 35.198), train_loss = 0.72485453, grad/param norm = 2.3724e-01, time/batch = 15.8875s	
17811/25300 (epoch 35.200), train_loss = 0.75369753, grad/param norm = 2.3392e-01, time/batch = 16.3998s	
17812/25300 (epoch 35.202), train_loss = 0.77735248, grad/param norm = 2.2855e-01, time/batch = 15.8869s	
17813/25300 (epoch 35.204), train_loss = 0.77461459, grad/param norm = 2.1973e-01, time/batch = 16.6568s	
17814/25300 (epoch 35.206), train_loss = 0.86134049, grad/param norm = 2.2316e-01, time/batch = 15.7424s	
17815/25300 (epoch 35.208), train_loss = 0.69567924, grad/param norm = 2.0206e-01, time/batch = 16.8943s	
17816/25300 (epoch 35.209), train_loss = 0.66332833, grad/param norm = 2.0416e-01, time/batch = 15.8917s	
17817/25300 (epoch 35.211), train_loss = 0.73180710, grad/param norm = 1.9705e-01, time/batch = 15.7563s	
17818/25300 (epoch 35.213), train_loss = 0.79825681, grad/param norm = 2.1941e-01, time/batch = 16.4969s	
17819/25300 (epoch 35.215), train_loss = 0.80004154, grad/param norm = 2.3595e-01, time/batch = 15.3181s	
17820/25300 (epoch 35.217), train_loss = 0.81338723, grad/param norm = 2.6892e-01, time/batch = 15.3318s	
17821/25300 (epoch 35.219), train_loss = 0.86270683, grad/param norm = 2.6005e-01, time/batch = 15.4190s	
17822/25300 (epoch 35.221), train_loss = 0.89442125, grad/param norm = 2.4280e-01, time/batch = 15.9165s	
17823/25300 (epoch 35.223), train_loss = 0.84470753, grad/param norm = 2.6648e-01, time/batch = 15.7258s	
17824/25300 (epoch 35.225), train_loss = 1.06415455, grad/param norm = 3.3909e-01, time/batch = 15.3863s	
17825/25300 (epoch 35.227), train_loss = 0.89945928, grad/param norm = 2.3833e-01, time/batch = 15.3909s	
17826/25300 (epoch 35.229), train_loss = 0.76109401, grad/param norm = 2.1719e-01, time/batch = 15.8268s	
17827/25300 (epoch 35.231), train_loss = 0.79184239, grad/param norm = 2.4584e-01, time/batch = 15.5629s	
17828/25300 (epoch 35.233), train_loss = 0.84812384, grad/param norm = 2.5017e-01, time/batch = 15.9950s	
17829/25300 (epoch 35.235), train_loss = 0.76497012, grad/param norm = 2.0642e-01, time/batch = 15.5874s	
17830/25300 (epoch 35.237), train_loss = 0.91294532, grad/param norm = 2.3713e-01, time/batch = 16.4253s	
17831/25300 (epoch 35.239), train_loss = 0.73953438, grad/param norm = 2.1955e-01, time/batch = 16.4669s	
17832/25300 (epoch 35.241), train_loss = 0.91188561, grad/param norm = 2.1835e-01, time/batch = 17.2327s	
17833/25300 (epoch 35.243), train_loss = 1.02805005, grad/param norm = 2.7524e-01, time/batch = 16.1590s	
17834/25300 (epoch 35.245), train_loss = 0.74896039, grad/param norm = 2.3820e-01, time/batch = 15.8190s	
17835/25300 (epoch 35.247), train_loss = 0.83798045, grad/param norm = 2.2345e-01, time/batch = 15.4949s	
17836/25300 (epoch 35.249), train_loss = 0.69344200, grad/param norm = 1.9437e-01, time/batch = 16.2373s	
17837/25300 (epoch 35.251), train_loss = 0.67697268, grad/param norm = 2.0138e-01, time/batch = 15.9958s	
17838/25300 (epoch 35.253), train_loss = 0.77936690, grad/param norm = 2.0888e-01, time/batch = 15.8144s	
17839/25300 (epoch 35.255), train_loss = 0.71982149, grad/param norm = 2.2460e-01, time/batch = 15.6448s	
17840/25300 (epoch 35.257), train_loss = 0.74647441, grad/param norm = 2.1910e-01, time/batch = 15.5809s	
17841/25300 (epoch 35.259), train_loss = 0.93057230, grad/param norm = 2.7221e-01, time/batch = 15.9113s	
17842/25300 (epoch 35.261), train_loss = 0.90288951, grad/param norm = 2.7939e-01, time/batch = 15.8131s	
17843/25300 (epoch 35.263), train_loss = 0.93669134, grad/param norm = 2.5232e-01, time/batch = 15.7490s	
17844/25300 (epoch 35.265), train_loss = 0.93769380, grad/param norm = 2.7946e-01, time/batch = 15.7205s	
17845/25300 (epoch 35.267), train_loss = 0.82257639, grad/param norm = 2.1703e-01, time/batch = 15.6481s	
17846/25300 (epoch 35.269), train_loss = 0.66823372, grad/param norm = 2.0444e-01, time/batch = 15.7177s	
17847/25300 (epoch 35.271), train_loss = 0.72959539, grad/param norm = 2.3818e-01, time/batch = 15.5840s	
17848/25300 (epoch 35.273), train_loss = 0.85155521, grad/param norm = 2.3362e-01, time/batch = 15.3707s	
17849/25300 (epoch 35.275), train_loss = 0.75560074, grad/param norm = 2.0846e-01, time/batch = 15.7277s	
17850/25300 (epoch 35.277), train_loss = 0.71652543, grad/param norm = 2.1261e-01, time/batch = 15.1502s	
17851/25300 (epoch 35.279), train_loss = 0.81552798, grad/param norm = 2.4072e-01, time/batch = 15.3314s	
17852/25300 (epoch 35.281), train_loss = 0.93389874, grad/param norm = 2.5691e-01, time/batch = 15.8155s	
17853/25300 (epoch 35.283), train_loss = 0.69299061, grad/param norm = 1.9847e-01, time/batch = 15.4841s	
17854/25300 (epoch 35.285), train_loss = 0.78380434, grad/param norm = 2.1897e-01, time/batch = 16.0757s	
17855/25300 (epoch 35.287), train_loss = 0.89364296, grad/param norm = 1.9373e-01, time/batch = 15.9128s	
17856/25300 (epoch 35.289), train_loss = 0.75580821, grad/param norm = 2.5117e-01, time/batch = 15.6537s	
17857/25300 (epoch 35.291), train_loss = 0.75929173, grad/param norm = 2.4552e-01, time/batch = 15.8045s	
17858/25300 (epoch 35.292), train_loss = 0.96719750, grad/param norm = 2.3821e-01, time/batch = 15.6691s	
17859/25300 (epoch 35.294), train_loss = 0.83724992, grad/param norm = 2.2910e-01, time/batch = 15.2922s	
17860/25300 (epoch 35.296), train_loss = 0.70642787, grad/param norm = 2.0124e-01, time/batch = 15.4564s	
17861/25300 (epoch 35.298), train_loss = 0.87148282, grad/param norm = 2.7768e-01, time/batch = 15.4866s	
17862/25300 (epoch 35.300), train_loss = 0.88041818, grad/param norm = 2.8848e-01, time/batch = 15.3324s	
17863/25300 (epoch 35.302), train_loss = 0.64620144, grad/param norm = 2.4187e-01, time/batch = 15.6435s	
17864/25300 (epoch 35.304), train_loss = 0.91028015, grad/param norm = 2.2355e-01, time/batch = 15.6215s	
17865/25300 (epoch 35.306), train_loss = 0.63627096, grad/param norm = 2.0506e-01, time/batch = 15.7229s	
17866/25300 (epoch 35.308), train_loss = 0.86243994, grad/param norm = 2.1053e-01, time/batch = 15.8177s	
17867/25300 (epoch 35.310), train_loss = 0.68584234, grad/param norm = 2.2454e-01, time/batch = 15.8927s	
17868/25300 (epoch 35.312), train_loss = 0.80937140, grad/param norm = 2.0128e-01, time/batch = 15.7363s	
17869/25300 (epoch 35.314), train_loss = 0.69051095, grad/param norm = 2.2082e-01, time/batch = 15.8701s	
17870/25300 (epoch 35.316), train_loss = 0.80412928, grad/param norm = 1.9892e-01, time/batch = 15.7353s	
17871/25300 (epoch 35.318), train_loss = 0.64364684, grad/param norm = 1.9218e-01, time/batch = 16.0635s	
17872/25300 (epoch 35.320), train_loss = 0.70840976, grad/param norm = 1.8098e-01, time/batch = 15.8947s	
17873/25300 (epoch 35.322), train_loss = 0.92537843, grad/param norm = 2.6516e-01, time/batch = 15.9681s	
17874/25300 (epoch 35.324), train_loss = 0.72547671, grad/param norm = 2.3029e-01, time/batch = 15.8159s	
17875/25300 (epoch 35.326), train_loss = 0.64011751, grad/param norm = 2.0991e-01, time/batch = 16.8099s	
17876/25300 (epoch 35.328), train_loss = 0.64420699, grad/param norm = 2.2234e-01, time/batch = 16.3081s	
17877/25300 (epoch 35.330), train_loss = 0.75439643, grad/param norm = 2.1554e-01, time/batch = 15.9628s	
17878/25300 (epoch 35.332), train_loss = 0.81142147, grad/param norm = 2.2233e-01, time/batch = 15.9868s	
17879/25300 (epoch 35.334), train_loss = 0.64628316, grad/param norm = 1.9047e-01, time/batch = 16.3793s	
17880/25300 (epoch 35.336), train_loss = 0.66978382, grad/param norm = 2.1836e-01, time/batch = 16.6337s	
17881/25300 (epoch 35.338), train_loss = 0.67577566, grad/param norm = 2.1864e-01, time/batch = 15.9793s	
17882/25300 (epoch 35.340), train_loss = 0.72760381, grad/param norm = 2.2151e-01, time/batch = 15.4510s	
17883/25300 (epoch 35.342), train_loss = 0.73349975, grad/param norm = 2.6751e-01, time/batch = 15.6540s	
17884/25300 (epoch 35.344), train_loss = 0.81144122, grad/param norm = 1.9102e-01, time/batch = 15.5763s	
17885/25300 (epoch 35.346), train_loss = 0.73406537, grad/param norm = 2.2219e-01, time/batch = 15.4153s	
17886/25300 (epoch 35.348), train_loss = 0.68686638, grad/param norm = 1.9364e-01, time/batch = 15.5481s	
17887/25300 (epoch 35.350), train_loss = 0.75225793, grad/param norm = 2.2667e-01, time/batch = 15.4729s	
17888/25300 (epoch 35.352), train_loss = 0.78041058, grad/param norm = 2.0828e-01, time/batch = 15.9729s	
17889/25300 (epoch 35.354), train_loss = 0.73441270, grad/param norm = 2.3234e-01, time/batch = 15.5681s	
17890/25300 (epoch 35.356), train_loss = 0.77543528, grad/param norm = 2.1752e-01, time/batch = 16.2370s	
17891/25300 (epoch 35.358), train_loss = 0.77322869, grad/param norm = 2.2835e-01, time/batch = 15.6770s	
17892/25300 (epoch 35.360), train_loss = 0.70048160, grad/param norm = 1.9485e-01, time/batch = 15.7223s	
17893/25300 (epoch 35.362), train_loss = 0.64687385, grad/param norm = 2.1490e-01, time/batch = 15.8187s	
17894/25300 (epoch 35.364), train_loss = 0.69494243, grad/param norm = 2.1250e-01, time/batch = 17.8124s	
17895/25300 (epoch 35.366), train_loss = 0.67043144, grad/param norm = 2.1727e-01, time/batch = 16.1374s	
17896/25300 (epoch 35.368), train_loss = 0.72976995, grad/param norm = 1.9246e-01, time/batch = 15.6338s	
17897/25300 (epoch 35.370), train_loss = 0.69754798, grad/param norm = 2.3010e-01, time/batch = 15.9950s	
17898/25300 (epoch 35.372), train_loss = 0.69154220, grad/param norm = 2.2662e-01, time/batch = 16.4802s	
17899/25300 (epoch 35.374), train_loss = 0.67115508, grad/param norm = 2.6758e-01, time/batch = 15.8111s	
17900/25300 (epoch 35.375), train_loss = 0.84201796, grad/param norm = 2.3907e-01, time/batch = 16.3195s	
17901/25300 (epoch 35.377), train_loss = 0.82645203, grad/param norm = 2.1406e-01, time/batch = 17.7438s	
17902/25300 (epoch 35.379), train_loss = 0.80088826, grad/param norm = 2.2159e-01, time/batch = 15.8975s	
17903/25300 (epoch 35.381), train_loss = 0.74380915, grad/param norm = 2.6095e-01, time/batch = 15.4871s	
17904/25300 (epoch 35.383), train_loss = 0.69259923, grad/param norm = 2.2425e-01, time/batch = 15.4959s	
17905/25300 (epoch 35.385), train_loss = 0.78928994, grad/param norm = 2.3033e-01, time/batch = 15.2311s	
17906/25300 (epoch 35.387), train_loss = 0.75392990, grad/param norm = 2.2254e-01, time/batch = 15.1407s	
17907/25300 (epoch 35.389), train_loss = 0.75310674, grad/param norm = 2.4959e-01, time/batch = 15.4147s	
17908/25300 (epoch 35.391), train_loss = 0.72393669, grad/param norm = 2.1431e-01, time/batch = 15.5759s	
17909/25300 (epoch 35.393), train_loss = 0.77545997, grad/param norm = 2.8091e-01, time/batch = 15.5675s	
17910/25300 (epoch 35.395), train_loss = 0.61932677, grad/param norm = 1.9106e-01, time/batch = 15.5634s	
17911/25300 (epoch 35.397), train_loss = 0.59993680, grad/param norm = 2.7636e-01, time/batch = 15.4857s	
17912/25300 (epoch 35.399), train_loss = 0.67832277, grad/param norm = 2.3641e-01, time/batch = 15.7404s	
17913/25300 (epoch 35.401), train_loss = 0.82435799, grad/param norm = 2.4704e-01, time/batch = 16.2377s	
17914/25300 (epoch 35.403), train_loss = 0.80130820, grad/param norm = 3.9156e-01, time/batch = 15.5608s	
17915/25300 (epoch 35.405), train_loss = 0.71979803, grad/param norm = 2.2557e-01, time/batch = 15.7174s	
17916/25300 (epoch 35.407), train_loss = 0.72805795, grad/param norm = 2.0999e-01, time/batch = 16.3140s	
17917/25300 (epoch 35.409), train_loss = 0.68562146, grad/param norm = 1.9553e-01, time/batch = 15.4635s	
17918/25300 (epoch 35.411), train_loss = 0.71551418, grad/param norm = 2.2610e-01, time/batch = 15.8971s	
17919/25300 (epoch 35.413), train_loss = 0.64043358, grad/param norm = 2.1055e-01, time/batch = 15.6287s	
17920/25300 (epoch 35.415), train_loss = 0.67596480, grad/param norm = 2.0608e-01, time/batch = 16.1704s	
17921/25300 (epoch 35.417), train_loss = 0.65275111, grad/param norm = 2.0805e-01, time/batch = 15.9048s	
17922/25300 (epoch 35.419), train_loss = 0.56006379, grad/param norm = 1.5700e-01, time/batch = 16.1572s	
17923/25300 (epoch 35.421), train_loss = 0.63740311, grad/param norm = 1.7147e-01, time/batch = 15.6504s	
17924/25300 (epoch 35.423), train_loss = 0.64214286, grad/param norm = 2.0506e-01, time/batch = 16.4175s	
17925/25300 (epoch 35.425), train_loss = 0.72399527, grad/param norm = 2.5427e-01, time/batch = 15.3126s	
17926/25300 (epoch 35.427), train_loss = 0.82757280, grad/param norm = 2.0603e-01, time/batch = 15.4091s	
17927/25300 (epoch 35.429), train_loss = 0.84845363, grad/param norm = 2.6329e-01, time/batch = 15.7514s	
17928/25300 (epoch 35.431), train_loss = 0.75838152, grad/param norm = 2.1442e-01, time/batch = 16.2440s	
17929/25300 (epoch 35.433), train_loss = 0.78392650, grad/param norm = 1.9549e-01, time/batch = 15.9749s	
17930/25300 (epoch 35.435), train_loss = 0.70813864, grad/param norm = 2.9418e-01, time/batch = 15.0901s	
17931/25300 (epoch 35.437), train_loss = 0.68957412, grad/param norm = 2.0545e-01, time/batch = 15.0767s	
17932/25300 (epoch 35.439), train_loss = 0.78066119, grad/param norm = 2.3954e-01, time/batch = 15.3201s	
17933/25300 (epoch 35.441), train_loss = 0.80956222, grad/param norm = 2.4272e-01, time/batch = 15.5348s	
17934/25300 (epoch 35.443), train_loss = 0.89956587, grad/param norm = 2.4213e-01, time/batch = 15.8241s	
17935/25300 (epoch 35.445), train_loss = 0.84236515, grad/param norm = 2.2780e-01, time/batch = 15.8100s	
17936/25300 (epoch 35.447), train_loss = 0.68646100, grad/param norm = 1.8795e-01, time/batch = 15.3940s	
17937/25300 (epoch 35.449), train_loss = 0.63398946, grad/param norm = 2.1434e-01, time/batch = 15.3167s	
17938/25300 (epoch 35.451), train_loss = 0.93643736, grad/param norm = 2.4035e-01, time/batch = 15.7228s	
17939/25300 (epoch 35.453), train_loss = 0.81621450, grad/param norm = 2.5914e-01, time/batch = 15.5531s	
17940/25300 (epoch 35.455), train_loss = 0.78657211, grad/param norm = 2.6000e-01, time/batch = 15.4968s	
17941/25300 (epoch 35.457), train_loss = 0.68679822, grad/param norm = 2.1540e-01, time/batch = 16.3154s	
17942/25300 (epoch 35.458), train_loss = 0.72003160, grad/param norm = 2.1458e-01, time/batch = 16.8203s	
17943/25300 (epoch 35.460), train_loss = 0.74679258, grad/param norm = 2.3852e-01, time/batch = 16.2575s	
17944/25300 (epoch 35.462), train_loss = 0.53501840, grad/param norm = 1.9113e-01, time/batch = 15.4734s	
17945/25300 (epoch 35.464), train_loss = 0.82011421, grad/param norm = 2.2643e-01, time/batch = 16.3802s	
17946/25300 (epoch 35.466), train_loss = 0.78335472, grad/param norm = 2.2243e-01, time/batch = 15.9060s	
17947/25300 (epoch 35.468), train_loss = 0.79022789, grad/param norm = 2.0070e-01, time/batch = 16.5627s	
17948/25300 (epoch 35.470), train_loss = 0.72816643, grad/param norm = 2.3073e-01, time/batch = 16.4829s	
17949/25300 (epoch 35.472), train_loss = 0.62560746, grad/param norm = 1.9914e-01, time/batch = 15.6273s	
17950/25300 (epoch 35.474), train_loss = 0.79429066, grad/param norm = 2.1665e-01, time/batch = 15.9085s	
17951/25300 (epoch 35.476), train_loss = 0.71370462, grad/param norm = 2.3297e-01, time/batch = 15.7315s	
17952/25300 (epoch 35.478), train_loss = 0.81459961, grad/param norm = 2.4931e-01, time/batch = 15.8303s	
17953/25300 (epoch 35.480), train_loss = 0.72957725, grad/param norm = 2.0876e-01, time/batch = 16.2278s	
17954/25300 (epoch 35.482), train_loss = 0.79101648, grad/param norm = 2.5152e-01, time/batch = 17.7973s	
17955/25300 (epoch 35.484), train_loss = 0.82193455, grad/param norm = 2.5430e-01, time/batch = 15.8911s	
17956/25300 (epoch 35.486), train_loss = 0.73281415, grad/param norm = 1.9710e-01, time/batch = 15.6562s	
17957/25300 (epoch 35.488), train_loss = 0.92793758, grad/param norm = 2.4358e-01, time/batch = 16.2407s	
17958/25300 (epoch 35.490), train_loss = 0.80142798, grad/param norm = 2.1032e-01, time/batch = 15.3304s	
17959/25300 (epoch 35.492), train_loss = 0.85638470, grad/param norm = 2.0758e-01, time/batch = 16.4755s	
17960/25300 (epoch 35.494), train_loss = 0.75791346, grad/param norm = 2.0990e-01, time/batch = 16.2979s	
17961/25300 (epoch 35.496), train_loss = 0.79833810, grad/param norm = 2.2388e-01, time/batch = 15.8266s	
17962/25300 (epoch 35.498), train_loss = 0.73623248, grad/param norm = 1.8577e-01, time/batch = 15.9033s	
17963/25300 (epoch 35.500), train_loss = 0.90267810, grad/param norm = 2.4050e-01, time/batch = 15.9782s	
17964/25300 (epoch 35.502), train_loss = 0.82529295, grad/param norm = 2.6620e-01, time/batch = 16.7354s	
17965/25300 (epoch 35.504), train_loss = 0.72987960, grad/param norm = 2.0132e-01, time/batch = 17.2298s	
17966/25300 (epoch 35.506), train_loss = 0.65661570, grad/param norm = 2.6837e-01, time/batch = 15.9781s	
17967/25300 (epoch 35.508), train_loss = 0.74792445, grad/param norm = 2.2977e-01, time/batch = 15.9187s	
17968/25300 (epoch 35.510), train_loss = 0.71573314, grad/param norm = 2.2273e-01, time/batch = 15.7355s	
17969/25300 (epoch 35.512), train_loss = 0.59348296, grad/param norm = 2.2846e-01, time/batch = 16.4829s	
17970/25300 (epoch 35.514), train_loss = 0.74343318, grad/param norm = 2.0693e-01, time/batch = 15.5579s	
17971/25300 (epoch 35.516), train_loss = 0.84323575, grad/param norm = 2.7129e-01, time/batch = 15.4070s	
17972/25300 (epoch 35.518), train_loss = 0.85225286, grad/param norm = 2.6251e-01, time/batch = 15.6407s	
17973/25300 (epoch 35.520), train_loss = 0.61962008, grad/param norm = 1.7147e-01, time/batch = 15.7023s	
17974/25300 (epoch 35.522), train_loss = 0.69852073, grad/param norm = 2.0955e-01, time/batch = 15.9847s	
17975/25300 (epoch 35.524), train_loss = 0.68731440, grad/param norm = 2.1825e-01, time/batch = 16.0856s	
17976/25300 (epoch 35.526), train_loss = 0.87460788, grad/param norm = 2.2825e-01, time/batch = 15.8985s	
17977/25300 (epoch 35.528), train_loss = 0.88262982, grad/param norm = 2.3824e-01, time/batch = 15.4828s	
17978/25300 (epoch 35.530), train_loss = 0.80969089, grad/param norm = 2.2439e-01, time/batch = 15.3395s	
17979/25300 (epoch 35.532), train_loss = 0.73900407, grad/param norm = 2.0111e-01, time/batch = 16.2451s	
17980/25300 (epoch 35.534), train_loss = 0.72644089, grad/param norm = 2.6623e-01, time/batch = 15.4171s	
17981/25300 (epoch 35.536), train_loss = 0.60438045, grad/param norm = 2.2704e-01, time/batch = 15.5435s	
17982/25300 (epoch 35.538), train_loss = 0.66203110, grad/param norm = 1.7750e-01, time/batch = 16.3166s	
17983/25300 (epoch 35.540), train_loss = 0.65943038, grad/param norm = 2.0131e-01, time/batch = 16.3171s	
17984/25300 (epoch 35.542), train_loss = 0.63039159, grad/param norm = 1.8308e-01, time/batch = 15.7210s	
17985/25300 (epoch 35.543), train_loss = 0.61249258, grad/param norm = 1.7871e-01, time/batch = 15.8847s	
17986/25300 (epoch 35.545), train_loss = 0.93980088, grad/param norm = 2.9967e-01, time/batch = 15.7474s	
17987/25300 (epoch 35.547), train_loss = 0.83411598, grad/param norm = 2.4973e-01, time/batch = 15.7403s	
17988/25300 (epoch 35.549), train_loss = 0.94668301, grad/param norm = 2.8218e-01, time/batch = 16.0682s	
17989/25300 (epoch 35.551), train_loss = 0.86876200, grad/param norm = 2.1954e-01, time/batch = 15.3232s	
17990/25300 (epoch 35.553), train_loss = 0.70987263, grad/param norm = 2.3289e-01, time/batch = 16.0795s	
17991/25300 (epoch 35.555), train_loss = 0.80027886, grad/param norm = 2.2399e-01, time/batch = 15.4001s	
17992/25300 (epoch 35.557), train_loss = 0.84023121, grad/param norm = 3.2202e-01, time/batch = 16.0666s	
17993/25300 (epoch 35.559), train_loss = 0.88281442, grad/param norm = 2.2722e-01, time/batch = 15.6600s	
17994/25300 (epoch 35.561), train_loss = 0.90492822, grad/param norm = 2.4498e-01, time/batch = 15.4018s	
17995/25300 (epoch 35.563), train_loss = 0.85422464, grad/param norm = 2.3077e-01, time/batch = 16.0701s	
17996/25300 (epoch 35.565), train_loss = 0.65646561, grad/param norm = 2.1451e-01, time/batch = 15.4102s	
17997/25300 (epoch 35.567), train_loss = 0.61244029, grad/param norm = 2.0722e-01, time/batch = 15.4740s	
17998/25300 (epoch 35.569), train_loss = 0.78653948, grad/param norm = 2.3673e-01, time/batch = 15.5693s	
17999/25300 (epoch 35.571), train_loss = 0.83433046, grad/param norm = 2.5472e-01, time/batch = 15.5811s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch35.57_1.7360.t7	
18000/25300 (epoch 35.573), train_loss = 0.75643646, grad/param norm = 2.2858e-01, time/batch = 15.5753s	
18001/25300 (epoch 35.575), train_loss = 1.35492227, grad/param norm = 3.2558e-01, time/batch = 15.6563s	
18002/25300 (epoch 35.577), train_loss = 0.74213571, grad/param norm = 2.7848e-01, time/batch = 16.5806s	
18003/25300 (epoch 35.579), train_loss = 0.89946324, grad/param norm = 2.7931e-01, time/batch = 16.7438s	
18004/25300 (epoch 35.581), train_loss = 0.84312985, grad/param norm = 2.4807e-01, time/batch = 16.2094s	
18005/25300 (epoch 35.583), train_loss = 0.65418947, grad/param norm = 2.2909e-01, time/batch = 15.9162s	
18006/25300 (epoch 35.585), train_loss = 0.65426836, grad/param norm = 2.4398e-01, time/batch = 16.5566s	
18007/25300 (epoch 35.587), train_loss = 0.77262321, grad/param norm = 2.3288e-01, time/batch = 17.8109s	
18008/25300 (epoch 35.589), train_loss = 0.67845431, grad/param norm = 1.8488e-01, time/batch = 15.7169s	
18009/25300 (epoch 35.591), train_loss = 0.64364038, grad/param norm = 2.4302e-01, time/batch = 16.4994s	
18010/25300 (epoch 35.593), train_loss = 0.82760508, grad/param norm = 2.3579e-01, time/batch = 15.7500s	
18011/25300 (epoch 35.595), train_loss = 0.76223541, grad/param norm = 2.0514e-01, time/batch = 16.0033s	
18012/25300 (epoch 35.597), train_loss = 0.67886184, grad/param norm = 1.9565e-01, time/batch = 16.0483s	
18013/25300 (epoch 35.599), train_loss = 0.89868801, grad/param norm = 2.6686e-01, time/batch = 16.4809s	
18014/25300 (epoch 35.601), train_loss = 0.76757487, grad/param norm = 2.3496e-01, time/batch = 16.4008s	
18015/25300 (epoch 35.603), train_loss = 0.75233347, grad/param norm = 2.1415e-01, time/batch = 16.1515s	
18016/25300 (epoch 35.605), train_loss = 0.75028258, grad/param norm = 2.4209e-01, time/batch = 28.0314s	
18017/25300 (epoch 35.607), train_loss = 0.54324611, grad/param norm = 1.7171e-01, time/batch = 15.6255s	
18018/25300 (epoch 35.609), train_loss = 0.68910885, grad/param norm = 1.9777e-01, time/batch = 15.2042s	
18019/25300 (epoch 35.611), train_loss = 0.78898083, grad/param norm = 2.4017e-01, time/batch = 15.3610s	
18020/25300 (epoch 35.613), train_loss = 0.66466591, grad/param norm = 1.9523e-01, time/batch = 15.2677s	
18021/25300 (epoch 35.615), train_loss = 0.70756843, grad/param norm = 2.2928e-01, time/batch = 15.4501s	
18022/25300 (epoch 35.617), train_loss = 0.76591259, grad/param norm = 2.8573e-01, time/batch = 15.5164s	
18023/25300 (epoch 35.619), train_loss = 0.80733187, grad/param norm = 2.4095e-01, time/batch = 15.6435s	
18024/25300 (epoch 35.621), train_loss = 0.84316627, grad/param norm = 2.3428e-01, time/batch = 15.8939s	
18025/25300 (epoch 35.623), train_loss = 0.69778826, grad/param norm = 2.5009e-01, time/batch = 16.2441s	
18026/25300 (epoch 35.625), train_loss = 0.63880194, grad/param norm = 2.2317e-01, time/batch = 15.3053s	
18027/25300 (epoch 35.626), train_loss = 0.72936881, grad/param norm = 2.0058e-01, time/batch = 15.9726s	
18028/25300 (epoch 35.628), train_loss = 0.86125312, grad/param norm = 2.5531e-01, time/batch = 15.8189s	
18029/25300 (epoch 35.630), train_loss = 0.80410428, grad/param norm = 2.3117e-01, time/batch = 15.5724s	
18030/25300 (epoch 35.632), train_loss = 0.76348922, grad/param norm = 2.3250e-01, time/batch = 15.6321s	
18031/25300 (epoch 35.634), train_loss = 0.85927736, grad/param norm = 2.5362e-01, time/batch = 15.8175s	
18032/25300 (epoch 35.636), train_loss = 0.67394449, grad/param norm = 2.0579e-01, time/batch = 15.8264s	
18033/25300 (epoch 35.638), train_loss = 0.76503818, grad/param norm = 2.5109e-01, time/batch = 15.7384s	
18034/25300 (epoch 35.640), train_loss = 0.95007101, grad/param norm = 3.0798e-01, time/batch = 15.3959s	
18035/25300 (epoch 35.642), train_loss = 0.81323092, grad/param norm = 2.6696e-01, time/batch = 15.4770s	
18036/25300 (epoch 35.644), train_loss = 0.77448151, grad/param norm = 2.3711e-01, time/batch = 15.2327s	
18037/25300 (epoch 35.646), train_loss = 0.70431324, grad/param norm = 2.5361e-01, time/batch = 15.4790s	
18038/25300 (epoch 35.648), train_loss = 0.85621490, grad/param norm = 2.1031e-01, time/batch = 15.4847s	
18039/25300 (epoch 35.650), train_loss = 0.76450451, grad/param norm = 1.9508e-01, time/batch = 15.8119s	
18040/25300 (epoch 35.652), train_loss = 0.79263572, grad/param norm = 2.5752e-01, time/batch = 15.7467s	
18041/25300 (epoch 35.654), train_loss = 0.88899828, grad/param norm = 2.4696e-01, time/batch = 15.7251s	
18042/25300 (epoch 35.656), train_loss = 0.84397409, grad/param norm = 2.5814e-01, time/batch = 15.7082s	
18043/25300 (epoch 35.658), train_loss = 0.60091584, grad/param norm = 1.8810e-01, time/batch = 15.8260s	
18044/25300 (epoch 35.660), train_loss = 0.61157170, grad/param norm = 1.9348e-01, time/batch = 15.8628s	
18045/25300 (epoch 35.662), train_loss = 0.63287101, grad/param norm = 1.8798e-01, time/batch = 15.6351s	
18046/25300 (epoch 35.664), train_loss = 0.61570840, grad/param norm = 2.0281e-01, time/batch = 15.5666s	
18047/25300 (epoch 35.666), train_loss = 0.66231119, grad/param norm = 2.1510e-01, time/batch = 15.5666s	
18048/25300 (epoch 35.668), train_loss = 0.73977559, grad/param norm = 2.2842e-01, time/batch = 16.0728s	
18049/25300 (epoch 35.670), train_loss = 0.68284248, grad/param norm = 2.4123e-01, time/batch = 15.5605s	
18050/25300 (epoch 35.672), train_loss = 0.67362605, grad/param norm = 2.1339e-01, time/batch = 15.4053s	
18051/25300 (epoch 35.674), train_loss = 0.68618087, grad/param norm = 2.0910e-01, time/batch = 15.6538s	
18052/25300 (epoch 35.676), train_loss = 0.68709344, grad/param norm = 2.3610e-01, time/batch = 15.8351s	
18053/25300 (epoch 35.678), train_loss = 0.69299544, grad/param norm = 2.3181e-01, time/batch = 15.6256s	
18054/25300 (epoch 35.680), train_loss = 0.61892783, grad/param norm = 1.9049e-01, time/batch = 15.7442s	
18055/25300 (epoch 35.682), train_loss = 0.52852362, grad/param norm = 1.7109e-01, time/batch = 15.8230s	
18056/25300 (epoch 35.684), train_loss = 0.67034444, grad/param norm = 1.8053e-01, time/batch = 15.9811s	
18057/25300 (epoch 35.686), train_loss = 0.61867555, grad/param norm = 1.8484e-01, time/batch = 15.5609s	
18058/25300 (epoch 35.688), train_loss = 0.71684106, grad/param norm = 2.6520e-01, time/batch = 15.3797s	
18059/25300 (epoch 35.690), train_loss = 0.64658009, grad/param norm = 2.1623e-01, time/batch = 15.5865s	
18060/25300 (epoch 35.692), train_loss = 0.69093919, grad/param norm = 2.2619e-01, time/batch = 15.5643s	
18061/25300 (epoch 35.694), train_loss = 0.67788892, grad/param norm = 2.5114e-01, time/batch = 15.8935s	
18062/25300 (epoch 35.696), train_loss = 0.74897565, grad/param norm = 2.6315e-01, time/batch = 15.8231s	
18063/25300 (epoch 35.698), train_loss = 0.80085097, grad/param norm = 2.3682e-01, time/batch = 15.8252s	
18064/25300 (epoch 35.700), train_loss = 0.59872415, grad/param norm = 1.9084e-01, time/batch = 15.3999s	
18065/25300 (epoch 35.702), train_loss = 0.78872541, grad/param norm = 2.1700e-01, time/batch = 15.5868s	
18066/25300 (epoch 35.704), train_loss = 0.59685340, grad/param norm = 1.9364e-01, time/batch = 16.1635s	
18067/25300 (epoch 35.706), train_loss = 0.72238916, grad/param norm = 2.3656e-01, time/batch = 16.2455s	
18068/25300 (epoch 35.708), train_loss = 0.61702625, grad/param norm = 1.7703e-01, time/batch = 15.3166s	
18069/25300 (epoch 35.709), train_loss = 0.86283783, grad/param norm = 2.3631e-01, time/batch = 16.0663s	
18070/25300 (epoch 35.711), train_loss = 0.91533626, grad/param norm = 2.6521e-01, time/batch = 15.8332s	
18071/25300 (epoch 35.713), train_loss = 0.75789359, grad/param norm = 2.0106e-01, time/batch = 15.9128s	
18072/25300 (epoch 35.715), train_loss = 0.75361679, grad/param norm = 1.9697e-01, time/batch = 15.8850s	
18073/25300 (epoch 35.717), train_loss = 0.64243617, grad/param norm = 2.0630e-01, time/batch = 16.7362s	
18074/25300 (epoch 35.719), train_loss = 0.72850271, grad/param norm = 2.2609e-01, time/batch = 16.3871s	
18075/25300 (epoch 35.721), train_loss = 0.79258238, grad/param norm = 2.3629e-01, time/batch = 16.3908s	
18076/25300 (epoch 35.723), train_loss = 0.71102611, grad/param norm = 2.1583e-01, time/batch = 15.9618s	
18077/25300 (epoch 35.725), train_loss = 0.75554947, grad/param norm = 2.1956e-01, time/batch = 16.4133s	
18078/25300 (epoch 35.727), train_loss = 0.75542926, grad/param norm = 2.2216e-01, time/batch = 15.7578s	
18079/25300 (epoch 35.729), train_loss = 0.72282983, grad/param norm = 2.1699e-01, time/batch = 16.0451s	
18080/25300 (epoch 35.731), train_loss = 0.89521344, grad/param norm = 2.3719e-01, time/batch = 15.7249s	
18081/25300 (epoch 35.733), train_loss = 0.73589675, grad/param norm = 1.8954e-01, time/batch = 15.5866s	
18082/25300 (epoch 35.735), train_loss = 0.95491821, grad/param norm = 2.6347e-01, time/batch = 15.4164s	
18083/25300 (epoch 35.737), train_loss = 0.62396656, grad/param norm = 2.0841e-01, time/batch = 15.3200s	
18084/25300 (epoch 35.739), train_loss = 0.87489919, grad/param norm = 2.5214e-01, time/batch = 15.6643s	
18085/25300 (epoch 35.741), train_loss = 0.77491101, grad/param norm = 2.3262e-01, time/batch = 16.3316s	
18086/25300 (epoch 35.743), train_loss = 0.76066419, grad/param norm = 2.3012e-01, time/batch = 15.5005s	
18087/25300 (epoch 35.745), train_loss = 0.71698509, grad/param norm = 2.1253e-01, time/batch = 15.4738s	
18088/25300 (epoch 35.747), train_loss = 0.65040213, grad/param norm = 2.0567e-01, time/batch = 17.0696s	
18089/25300 (epoch 35.749), train_loss = 0.73770685, grad/param norm = 2.2491e-01, time/batch = 16.9111s	
18090/25300 (epoch 35.751), train_loss = 0.79872448, grad/param norm = 2.3273e-01, time/batch = 15.8997s	
18091/25300 (epoch 35.753), train_loss = 0.64429137, grad/param norm = 2.0316e-01, time/batch = 15.8201s	
18092/25300 (epoch 35.755), train_loss = 0.84432192, grad/param norm = 2.4730e-01, time/batch = 16.0807s	
18093/25300 (epoch 35.757), train_loss = 0.69833358, grad/param norm = 2.4681e-01, time/batch = 15.9134s	
18094/25300 (epoch 35.759), train_loss = 0.69056374, grad/param norm = 2.3087e-01, time/batch = 15.5516s	
18095/25300 (epoch 35.761), train_loss = 0.88268321, grad/param norm = 2.2010e-01, time/batch = 15.7405s	
18096/25300 (epoch 35.763), train_loss = 0.72434849, grad/param norm = 2.2138e-01, time/batch = 15.9916s	
18097/25300 (epoch 35.765), train_loss = 0.73466271, grad/param norm = 2.9587e-01, time/batch = 17.0719s	
18098/25300 (epoch 35.767), train_loss = 0.73426107, grad/param norm = 2.0638e-01, time/batch = 15.8969s	
18099/25300 (epoch 35.769), train_loss = 0.74728379, grad/param norm = 2.8505e-01, time/batch = 15.6362s	
18100/25300 (epoch 35.771), train_loss = 0.84245183, grad/param norm = 2.7854e-01, time/batch = 15.5704s	
18101/25300 (epoch 35.773), train_loss = 0.85599801, grad/param norm = 2.2603e-01, time/batch = 15.9081s	
18102/25300 (epoch 35.775), train_loss = 0.77556863, grad/param norm = 2.1654e-01, time/batch = 16.0572s	
18103/25300 (epoch 35.777), train_loss = 0.70438929, grad/param norm = 2.3365e-01, time/batch = 15.7391s	
18104/25300 (epoch 35.779), train_loss = 0.84089694, grad/param norm = 2.3863e-01, time/batch = 16.3333s	
18105/25300 (epoch 35.781), train_loss = 0.82023929, grad/param norm = 2.3953e-01, time/batch = 15.5733s	
18106/25300 (epoch 35.783), train_loss = 0.88788768, grad/param norm = 2.3738e-01, time/batch = 15.4035s	
18107/25300 (epoch 35.785), train_loss = 0.83700215, grad/param norm = 2.6102e-01, time/batch = 15.9912s	
18108/25300 (epoch 35.787), train_loss = 0.81562101, grad/param norm = 2.4612e-01, time/batch = 15.5030s	
18109/25300 (epoch 35.789), train_loss = 0.88672623, grad/param norm = 2.7036e-01, time/batch = 15.2412s	
18110/25300 (epoch 35.791), train_loss = 0.80185009, grad/param norm = 2.1270e-01, time/batch = 15.4888s	
18111/25300 (epoch 35.792), train_loss = 0.87115112, grad/param norm = 2.3878e-01, time/batch = 18.7968s	
18112/25300 (epoch 35.794), train_loss = 0.74926323, grad/param norm = 2.3676e-01, time/batch = 16.9832s	
18113/25300 (epoch 35.796), train_loss = 0.72360268, grad/param norm = 2.3676e-01, time/batch = 15.8188s	
18114/25300 (epoch 35.798), train_loss = 0.84292289, grad/param norm = 3.1352e-01, time/batch = 16.2406s	
18115/25300 (epoch 35.800), train_loss = 0.71954020, grad/param norm = 1.8685e-01, time/batch = 14.9984s	
18116/25300 (epoch 35.802), train_loss = 0.60553803, grad/param norm = 1.8860e-01, time/batch = 15.0830s	
18117/25300 (epoch 35.804), train_loss = 0.77524890, grad/param norm = 2.0169e-01, time/batch = 15.4851s	
18118/25300 (epoch 35.806), train_loss = 0.82226309, grad/param norm = 2.7622e-01, time/batch = 15.6522s	
18119/25300 (epoch 35.808), train_loss = 0.86305958, grad/param norm = 2.3029e-01, time/batch = 15.5820s	
18120/25300 (epoch 35.810), train_loss = 0.74373206, grad/param norm = 2.3932e-01, time/batch = 15.3149s	
18121/25300 (epoch 35.812), train_loss = 0.87480715, grad/param norm = 2.4098e-01, time/batch = 15.4125s	
18122/25300 (epoch 35.814), train_loss = 0.88278582, grad/param norm = 2.3032e-01, time/batch = 15.7512s	
18123/25300 (epoch 35.816), train_loss = 0.95887322, grad/param norm = 2.2503e-01, time/batch = 15.4710s	
18124/25300 (epoch 35.818), train_loss = 0.84825966, grad/param norm = 2.0581e-01, time/batch = 15.6491s	
18125/25300 (epoch 35.820), train_loss = 0.85107469, grad/param norm = 2.2267e-01, time/batch = 15.5681s	
18126/25300 (epoch 35.822), train_loss = 0.70953046, grad/param norm = 2.1444e-01, time/batch = 15.5529s	
18127/25300 (epoch 35.824), train_loss = 0.85243310, grad/param norm = 2.1610e-01, time/batch = 15.3863s	
18128/25300 (epoch 35.826), train_loss = 0.70136476, grad/param norm = 1.9121e-01, time/batch = 15.7148s	
18129/25300 (epoch 35.828), train_loss = 0.70874953, grad/param norm = 2.3890e-01, time/batch = 16.0745s	
18130/25300 (epoch 35.830), train_loss = 0.80113461, grad/param norm = 2.1597e-01, time/batch = 15.7282s	
18131/25300 (epoch 35.832), train_loss = 0.87450814, grad/param norm = 2.5112e-01, time/batch = 17.1378s	
18132/25300 (epoch 35.834), train_loss = 0.72956189, grad/param norm = 2.1252e-01, time/batch = 15.8129s	
18133/25300 (epoch 35.836), train_loss = 0.74857186, grad/param norm = 2.0263e-01, time/batch = 16.2379s	
18134/25300 (epoch 35.838), train_loss = 0.72773094, grad/param norm = 2.2818e-01, time/batch = 15.8163s	
18135/25300 (epoch 35.840), train_loss = 0.82506180, grad/param norm = 2.2505e-01, time/batch = 16.7232s	
18136/25300 (epoch 35.842), train_loss = 0.78603697, grad/param norm = 2.4362e-01, time/batch = 15.6490s	
18137/25300 (epoch 35.844), train_loss = 0.85704641, grad/param norm = 2.0422e-01, time/batch = 15.9684s	
18138/25300 (epoch 35.846), train_loss = 0.82009567, grad/param norm = 2.0382e-01, time/batch = 15.7458s	
18139/25300 (epoch 35.848), train_loss = 0.83328105, grad/param norm = 2.4090e-01, time/batch = 16.3121s	
18140/25300 (epoch 35.850), train_loss = 0.80674148, grad/param norm = 2.3972e-01, time/batch = 16.2453s	
18141/25300 (epoch 35.852), train_loss = 0.85477343, grad/param norm = 2.2316e-01, time/batch = 15.8234s	
18142/25300 (epoch 35.854), train_loss = 0.87469021, grad/param norm = 2.1859e-01, time/batch = 15.4013s	
18143/25300 (epoch 35.856), train_loss = 0.74158706, grad/param norm = 2.2181e-01, time/batch = 15.4693s	
18144/25300 (epoch 35.858), train_loss = 0.74914459, grad/param norm = 2.2048e-01, time/batch = 15.3244s	
18145/25300 (epoch 35.860), train_loss = 0.66240516, grad/param norm = 2.2306e-01, time/batch = 16.4096s	
18146/25300 (epoch 35.862), train_loss = 0.77080097, grad/param norm = 2.1555e-01, time/batch = 16.3176s	
18147/25300 (epoch 35.864), train_loss = 0.87614894, grad/param norm = 2.1589e-01, time/batch = 15.4835s	
18148/25300 (epoch 35.866), train_loss = 0.73277503, grad/param norm = 2.2535e-01, time/batch = 15.9103s	
18149/25300 (epoch 35.868), train_loss = 0.86964192, grad/param norm = 2.1921e-01, time/batch = 15.8328s	
18150/25300 (epoch 35.870), train_loss = 0.84342154, grad/param norm = 2.0300e-01, time/batch = 15.5795s	
18151/25300 (epoch 35.872), train_loss = 0.79649984, grad/param norm = 2.6093e-01, time/batch = 15.3748s	
18152/25300 (epoch 35.874), train_loss = 0.81548620, grad/param norm = 2.2198e-01, time/batch = 15.5622s	
18153/25300 (epoch 35.875), train_loss = 0.75881665, grad/param norm = 2.6525e-01, time/batch = 15.5774s	
18154/25300 (epoch 35.877), train_loss = 0.74957748, grad/param norm = 2.1139e-01, time/batch = 15.3228s	
18155/25300 (epoch 35.879), train_loss = 0.68872392, grad/param norm = 2.2531e-01, time/batch = 15.8170s	
18156/25300 (epoch 35.881), train_loss = 1.00643061, grad/param norm = 2.8345e-01, time/batch = 15.7112s	
18157/25300 (epoch 35.883), train_loss = 0.97488780, grad/param norm = 2.3112e-01, time/batch = 16.3146s	
18158/25300 (epoch 35.885), train_loss = 0.84179579, grad/param norm = 2.5779e-01, time/batch = 15.8944s	
18159/25300 (epoch 35.887), train_loss = 0.85064855, grad/param norm = 2.1755e-01, time/batch = 16.3960s	
18160/25300 (epoch 35.889), train_loss = 0.94451808, grad/param norm = 2.6386e-01, time/batch = 16.4845s	
18161/25300 (epoch 35.891), train_loss = 0.81588592, grad/param norm = 2.3163e-01, time/batch = 17.1408s	
18162/25300 (epoch 35.893), train_loss = 0.79298426, grad/param norm = 3.1106e-01, time/batch = 15.7199s	
18163/25300 (epoch 35.895), train_loss = 0.60202285, grad/param norm = 2.0374e-01, time/batch = 17.0605s	
18164/25300 (epoch 35.897), train_loss = 0.68772505, grad/param norm = 2.2412e-01, time/batch = 16.9157s	
18165/25300 (epoch 35.899), train_loss = 0.79420256, grad/param norm = 2.4031e-01, time/batch = 15.5625s	
18166/25300 (epoch 35.901), train_loss = 0.84187052, grad/param norm = 2.5179e-01, time/batch = 15.8273s	
18167/25300 (epoch 35.903), train_loss = 0.64525102, grad/param norm = 2.6149e-01, time/batch = 15.7415s	
18168/25300 (epoch 35.905), train_loss = 0.73449584, grad/param norm = 2.6150e-01, time/batch = 16.1662s	
18169/25300 (epoch 35.907), train_loss = 0.74080777, grad/param norm = 2.7661e-01, time/batch = 15.8084s	
18170/25300 (epoch 35.909), train_loss = 0.82443768, grad/param norm = 2.0806e-01, time/batch = 15.5714s	
18171/25300 (epoch 35.911), train_loss = 0.88968777, grad/param norm = 2.4554e-01, time/batch = 15.7291s	
18172/25300 (epoch 35.913), train_loss = 0.97871762, grad/param norm = 2.6058e-01, time/batch = 16.5840s	
18173/25300 (epoch 35.915), train_loss = 0.72594023, grad/param norm = 2.3507e-01, time/batch = 15.8033s	
18174/25300 (epoch 35.917), train_loss = 0.91874193, grad/param norm = 2.2755e-01, time/batch = 15.9961s	
18175/25300 (epoch 35.919), train_loss = 0.91381362, grad/param norm = 3.0371e-01, time/batch = 15.3964s	
18176/25300 (epoch 35.921), train_loss = 0.74163200, grad/param norm = 2.1932e-01, time/batch = 15.9152s	
18177/25300 (epoch 35.923), train_loss = 0.87079075, grad/param norm = 2.6127e-01, time/batch = 15.4694s	
18178/25300 (epoch 35.925), train_loss = 0.81537677, grad/param norm = 2.6524e-01, time/batch = 15.9256s	
18179/25300 (epoch 35.927), train_loss = 0.77213600, grad/param norm = 2.6392e-01, time/batch = 15.3155s	
18180/25300 (epoch 35.929), train_loss = 0.83690826, grad/param norm = 2.3091e-01, time/batch = 15.3393s	
18181/25300 (epoch 35.931), train_loss = 0.86148138, grad/param norm = 2.6924e-01, time/batch = 16.1569s	
18182/25300 (epoch 35.933), train_loss = 0.82233465, grad/param norm = 2.2524e-01, time/batch = 15.4775s	
18183/25300 (epoch 35.935), train_loss = 0.84520858, grad/param norm = 2.1038e-01, time/batch = 15.9893s	
18184/25300 (epoch 35.937), train_loss = 0.63700211, grad/param norm = 1.9205e-01, time/batch = 15.8136s	
18185/25300 (epoch 35.939), train_loss = 0.80357757, grad/param norm = 2.2059e-01, time/batch = 15.8228s	
18186/25300 (epoch 35.941), train_loss = 0.75595257, grad/param norm = 2.8099e-01, time/batch = 15.6451s	
18187/25300 (epoch 35.943), train_loss = 0.80075948, grad/param norm = 2.2540e-01, time/batch = 15.5552s	
18188/25300 (epoch 35.945), train_loss = 0.81639426, grad/param norm = 2.4992e-01, time/batch = 15.5315s	
18189/25300 (epoch 35.947), train_loss = 0.73433450, grad/param norm = 2.3614e-01, time/batch = 15.6022s	
18190/25300 (epoch 35.949), train_loss = 0.82299074, grad/param norm = 2.1825e-01, time/batch = 15.5143s	
18191/25300 (epoch 35.951), train_loss = 0.79130574, grad/param norm = 2.0717e-01, time/batch = 15.5215s	
18192/25300 (epoch 35.953), train_loss = 0.76582660, grad/param norm = 2.6235e-01, time/batch = 15.7159s	
18193/25300 (epoch 35.955), train_loss = 0.98248851, grad/param norm = 2.9181e-01, time/batch = 15.7147s	
18194/25300 (epoch 35.957), train_loss = 0.88587440, grad/param norm = 2.5076e-01, time/batch = 15.6147s	
18195/25300 (epoch 35.958), train_loss = 0.84546224, grad/param norm = 2.6890e-01, time/batch = 15.6535s	
18196/25300 (epoch 35.960), train_loss = 0.96515822, grad/param norm = 3.2066e-01, time/batch = 16.1250s	
18197/25300 (epoch 35.962), train_loss = 0.91851566, grad/param norm = 2.3136e-01, time/batch = 16.4855s	
18198/25300 (epoch 35.964), train_loss = 0.82488684, grad/param norm = 2.5850e-01, time/batch = 15.5704s	
18199/25300 (epoch 35.966), train_loss = 0.69899219, grad/param norm = 2.3135e-01, time/batch = 15.6225s	
18200/25300 (epoch 35.968), train_loss = 0.68728113, grad/param norm = 1.9016e-01, time/batch = 15.8153s	
18201/25300 (epoch 35.970), train_loss = 0.77500455, grad/param norm = 2.4787e-01, time/batch = 16.0385s	
18202/25300 (epoch 35.972), train_loss = 0.78916188, grad/param norm = 2.3368e-01, time/batch = 15.5077s	
18203/25300 (epoch 35.974), train_loss = 0.88202505, grad/param norm = 2.4315e-01, time/batch = 15.6505s	
18204/25300 (epoch 35.976), train_loss = 0.82063026, grad/param norm = 2.5931e-01, time/batch = 15.1505s	
18205/25300 (epoch 35.978), train_loss = 0.76729833, grad/param norm = 2.5815e-01, time/batch = 15.7588s	
18206/25300 (epoch 35.980), train_loss = 0.80954942, grad/param norm = 2.4644e-01, time/batch = 16.2971s	
18207/25300 (epoch 35.982), train_loss = 0.76777491, grad/param norm = 2.5733e-01, time/batch = 16.0701s	
18208/25300 (epoch 35.984), train_loss = 0.78875702, grad/param norm = 2.5682e-01, time/batch = 15.4876s	
18209/25300 (epoch 35.986), train_loss = 0.85419775, grad/param norm = 2.7210e-01, time/batch = 15.5769s	
18210/25300 (epoch 35.988), train_loss = 0.82170805, grad/param norm = 2.5370e-01, time/batch = 15.6664s	
18211/25300 (epoch 35.990), train_loss = 0.82028611, grad/param norm = 2.4298e-01, time/batch = 15.8203s	
18212/25300 (epoch 35.992), train_loss = 0.67860177, grad/param norm = 1.9669e-01, time/batch = 16.4065s	
18213/25300 (epoch 35.994), train_loss = 0.82958071, grad/param norm = 2.8309e-01, time/batch = 16.3068s	
18214/25300 (epoch 35.996), train_loss = 0.91927917, grad/param norm = 2.7726e-01, time/batch = 16.3003s	
18215/25300 (epoch 35.998), train_loss = 0.84395650, grad/param norm = 2.3414e-01, time/batch = 15.5717s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
18216/25300 (epoch 36.000), train_loss = 0.84811144, grad/param norm = 2.4533e-01, time/batch = 15.5603s	
18217/25300 (epoch 36.002), train_loss = 0.78590306, grad/param norm = 2.1710e-01, time/batch = 15.4911s	
18218/25300 (epoch 36.004), train_loss = 0.67031920, grad/param norm = 2.1877e-01, time/batch = 16.1341s	
18219/25300 (epoch 36.006), train_loss = 0.95042153, grad/param norm = 2.4106e-01, time/batch = 15.4137s	
18220/25300 (epoch 36.008), train_loss = 0.78679210, grad/param norm = 1.9847e-01, time/batch = 15.8997s	
18221/25300 (epoch 36.010), train_loss = 0.83207590, grad/param norm = 2.2511e-01, time/batch = 16.4866s	
18222/25300 (epoch 36.012), train_loss = 0.75886983, grad/param norm = 2.1424e-01, time/batch = 15.7242s	
18223/25300 (epoch 36.014), train_loss = 0.91942035, grad/param norm = 2.4014e-01, time/batch = 16.1502s	
18224/25300 (epoch 36.016), train_loss = 0.81059665, grad/param norm = 2.8411e-01, time/batch = 15.5832s	
18225/25300 (epoch 36.018), train_loss = 0.71440545, grad/param norm = 2.1520e-01, time/batch = 16.4120s	
18226/25300 (epoch 36.020), train_loss = 0.83175442, grad/param norm = 2.3656e-01, time/batch = 15.4644s	
18227/25300 (epoch 36.022), train_loss = 0.79418468, grad/param norm = 2.4108e-01, time/batch = 16.1593s	
18228/25300 (epoch 36.024), train_loss = 0.61970657, grad/param norm = 1.9844e-01, time/batch = 15.9983s	
18229/25300 (epoch 36.026), train_loss = 0.75303096, grad/param norm = 2.1123e-01, time/batch = 16.7345s	
18230/25300 (epoch 36.028), train_loss = 0.75970034, grad/param norm = 2.2574e-01, time/batch = 15.8173s	
18231/25300 (epoch 36.030), train_loss = 0.90829795, grad/param norm = 2.1726e-01, time/batch = 15.6451s	
18232/25300 (epoch 36.032), train_loss = 0.76478554, grad/param norm = 2.1999e-01, time/batch = 15.6719s	
18233/25300 (epoch 36.034), train_loss = 0.68587698, grad/param norm = 1.9856e-01, time/batch = 15.8755s	
18234/25300 (epoch 36.036), train_loss = 0.66444963, grad/param norm = 2.3097e-01, time/batch = 16.0769s	
18235/25300 (epoch 36.038), train_loss = 0.62578622, grad/param norm = 2.0238e-01, time/batch = 15.7409s	
18236/25300 (epoch 36.040), train_loss = 0.78500756, grad/param norm = 2.1677e-01, time/batch = 15.9868s	
18237/25300 (epoch 36.042), train_loss = 0.76479447, grad/param norm = 1.8444e-01, time/batch = 15.5536s	
18238/25300 (epoch 36.043), train_loss = 0.66879801, grad/param norm = 1.7818e-01, time/batch = 16.1536s	
18239/25300 (epoch 36.045), train_loss = 0.65632218, grad/param norm = 1.7520e-01, time/batch = 15.7412s	
18240/25300 (epoch 36.047), train_loss = 0.78973151, grad/param norm = 2.0418e-01, time/batch = 16.1617s	
18241/25300 (epoch 36.049), train_loss = 0.78255100, grad/param norm = 2.4840e-01, time/batch = 29.2482s	
18242/25300 (epoch 36.051), train_loss = 0.90201378, grad/param norm = 2.3184e-01, time/batch = 16.8140s	
18243/25300 (epoch 36.053), train_loss = 0.61435978, grad/param norm = 1.7811e-01, time/batch = 16.0728s	
18244/25300 (epoch 36.055), train_loss = 0.65078401, grad/param norm = 1.9541e-01, time/batch = 16.3931s	
18245/25300 (epoch 36.057), train_loss = 0.64883537, grad/param norm = 1.7375e-01, time/batch = 16.4087s	
18246/25300 (epoch 36.059), train_loss = 0.72757317, grad/param norm = 2.0092e-01, time/batch = 15.7390s	
18247/25300 (epoch 36.061), train_loss = 0.71505453, grad/param norm = 2.4575e-01, time/batch = 16.3768s	
18248/25300 (epoch 36.063), train_loss = 0.72974137, grad/param norm = 1.9617e-01, time/batch = 15.5538s	
18249/25300 (epoch 36.065), train_loss = 0.76562891, grad/param norm = 2.1312e-01, time/batch = 15.7900s	
18250/25300 (epoch 36.067), train_loss = 0.83974003, grad/param norm = 2.0555e-01, time/batch = 15.5840s	
18251/25300 (epoch 36.069), train_loss = 0.68398978, grad/param norm = 2.1202e-01, time/batch = 15.7148s	
18252/25300 (epoch 36.071), train_loss = 0.83127308, grad/param norm = 2.4749e-01, time/batch = 15.4919s	
18253/25300 (epoch 36.073), train_loss = 0.75009315, grad/param norm = 2.0352e-01, time/batch = 15.9987s	
18254/25300 (epoch 36.075), train_loss = 0.82899513, grad/param norm = 2.3501e-01, time/batch = 16.2382s	
18255/25300 (epoch 36.077), train_loss = 0.79763128, grad/param norm = 2.2033e-01, time/batch = 15.2301s	
18256/25300 (epoch 36.079), train_loss = 0.69876074, grad/param norm = 2.2816e-01, time/batch = 15.5093s	
18257/25300 (epoch 36.081), train_loss = 0.76889344, grad/param norm = 1.9307e-01, time/batch = 15.5610s	
18258/25300 (epoch 36.083), train_loss = 0.77941716, grad/param norm = 1.8956e-01, time/batch = 16.0579s	
18259/25300 (epoch 36.085), train_loss = 0.96703812, grad/param norm = 2.6413e-01, time/batch = 15.8817s	
18260/25300 (epoch 36.087), train_loss = 0.84294410, grad/param norm = 2.0360e-01, time/batch = 16.0713s	
18261/25300 (epoch 36.089), train_loss = 0.82779180, grad/param norm = 2.2806e-01, time/batch = 15.6547s	
18262/25300 (epoch 36.091), train_loss = 0.94469742, grad/param norm = 2.3080e-01, time/batch = 16.6470s	
18263/25300 (epoch 36.093), train_loss = 0.87266131, grad/param norm = 2.2974e-01, time/batch = 15.4064s	
18264/25300 (epoch 36.095), train_loss = 0.84913192, grad/param norm = 2.2648e-01, time/batch = 15.2935s	
18265/25300 (epoch 36.097), train_loss = 0.83840066, grad/param norm = 2.3822e-01, time/batch = 16.0070s	
18266/25300 (epoch 36.099), train_loss = 0.82127181, grad/param norm = 2.2887e-01, time/batch = 16.0576s	
18267/25300 (epoch 36.101), train_loss = 0.78632819, grad/param norm = 2.6381e-01, time/batch = 15.8066s	
18268/25300 (epoch 36.103), train_loss = 0.79887551, grad/param norm = 2.1184e-01, time/batch = 15.7490s	
18269/25300 (epoch 36.105), train_loss = 0.84047948, grad/param norm = 2.3248e-01, time/batch = 15.7519s	
18270/25300 (epoch 36.107), train_loss = 0.83792216, grad/param norm = 2.5279e-01, time/batch = 15.4825s	
18271/25300 (epoch 36.109), train_loss = 0.77040664, grad/param norm = 2.1659e-01, time/batch = 15.8108s	
18272/25300 (epoch 36.111), train_loss = 0.76068904, grad/param norm = 2.1879e-01, time/batch = 15.4130s	
18273/25300 (epoch 36.113), train_loss = 0.72875353, grad/param norm = 2.0181e-01, time/batch = 16.8284s	
18274/25300 (epoch 36.115), train_loss = 0.76142190, grad/param norm = 2.4564e-01, time/batch = 16.1417s	
18275/25300 (epoch 36.117), train_loss = 0.85938618, grad/param norm = 2.1510e-01, time/batch = 15.8104s	
18276/25300 (epoch 36.119), train_loss = 0.73865704, grad/param norm = 2.3462e-01, time/batch = 16.3165s	
18277/25300 (epoch 36.121), train_loss = 0.80200346, grad/param norm = 2.5558e-01, time/batch = 15.8086s	
18278/25300 (epoch 36.123), train_loss = 0.71205182, grad/param norm = 2.0367e-01, time/batch = 15.7190s	
18279/25300 (epoch 36.125), train_loss = 0.87073772, grad/param norm = 2.6308e-01, time/batch = 15.6586s	
18280/25300 (epoch 36.126), train_loss = 0.78577692, grad/param norm = 2.2147e-01, time/batch = 16.1634s	
18281/25300 (epoch 36.128), train_loss = 0.76313701, grad/param norm = 2.2090e-01, time/batch = 15.7194s	
18282/25300 (epoch 36.130), train_loss = 0.61034910, grad/param norm = 1.8890e-01, time/batch = 15.6564s	
18283/25300 (epoch 36.132), train_loss = 0.65632322, grad/param norm = 2.2588e-01, time/batch = 15.7517s	
18284/25300 (epoch 36.134), train_loss = 0.66094811, grad/param norm = 1.8004e-01, time/batch = 15.5641s	
18285/25300 (epoch 36.136), train_loss = 0.77559747, grad/param norm = 2.4158e-01, time/batch = 15.7308s	
18286/25300 (epoch 36.138), train_loss = 0.67573097, grad/param norm = 1.8783e-01, time/batch = 15.9146s	
18287/25300 (epoch 36.140), train_loss = 0.66757103, grad/param norm = 2.0615e-01, time/batch = 15.6580s	
18288/25300 (epoch 36.142), train_loss = 0.87587517, grad/param norm = 2.3561e-01, time/batch = 15.8304s	
18289/25300 (epoch 36.144), train_loss = 0.83075261, grad/param norm = 2.0915e-01, time/batch = 15.2168s	
18290/25300 (epoch 36.146), train_loss = 0.76131011, grad/param norm = 2.8424e-01, time/batch = 15.3738s	
18291/25300 (epoch 36.148), train_loss = 0.75465200, grad/param norm = 1.9697e-01, time/batch = 15.6416s	
18292/25300 (epoch 36.150), train_loss = 0.81522239, grad/param norm = 2.4689e-01, time/batch = 15.7310s	
18293/25300 (epoch 36.152), train_loss = 0.90865188, grad/param norm = 2.4759e-01, time/batch = 15.3038s	
18294/25300 (epoch 36.154), train_loss = 0.66222716, grad/param norm = 1.9783e-01, time/batch = 16.6361s	
18295/25300 (epoch 36.156), train_loss = 0.80039033, grad/param norm = 2.1925e-01, time/batch = 16.0591s	
18296/25300 (epoch 36.158), train_loss = 0.66858361, grad/param norm = 1.9936e-01, time/batch = 16.1492s	
18297/25300 (epoch 36.160), train_loss = 0.77616794, grad/param norm = 2.2935e-01, time/batch = 15.4717s	
18298/25300 (epoch 36.162), train_loss = 0.71550743, grad/param norm = 2.2948e-01, time/batch = 16.0615s	
18299/25300 (epoch 36.164), train_loss = 0.82693261, grad/param norm = 2.2788e-01, time/batch = 16.1620s	
18300/25300 (epoch 36.166), train_loss = 0.78371113, grad/param norm = 2.3061e-01, time/batch = 15.8842s	
18301/25300 (epoch 36.168), train_loss = 0.70558589, grad/param norm = 1.7972e-01, time/batch = 15.6368s	
18302/25300 (epoch 36.170), train_loss = 0.71503982, grad/param norm = 1.9173e-01, time/batch = 16.0025s	
18303/25300 (epoch 36.172), train_loss = 0.65712147, grad/param norm = 1.8528e-01, time/batch = 15.5549s	
18304/25300 (epoch 36.174), train_loss = 0.66975802, grad/param norm = 2.0578e-01, time/batch = 16.0469s	
18305/25300 (epoch 36.176), train_loss = 0.67478558, grad/param norm = 2.2402e-01, time/batch = 17.3924s	
18306/25300 (epoch 36.178), train_loss = 0.89372693, grad/param norm = 2.4095e-01, time/batch = 17.1533s	
18307/25300 (epoch 36.180), train_loss = 0.61747518, grad/param norm = 2.1542e-01, time/batch = 17.2242s	
18308/25300 (epoch 36.182), train_loss = 0.73174052, grad/param norm = 2.2156e-01, time/batch = 15.6553s	
18309/25300 (epoch 36.184), train_loss = 0.69396580, grad/param norm = 2.1840e-01, time/batch = 16.0418s	
18310/25300 (epoch 36.186), train_loss = 0.64303534, grad/param norm = 2.0882e-01, time/batch = 15.7253s	
18311/25300 (epoch 36.188), train_loss = 0.76140014, grad/param norm = 2.7463e-01, time/batch = 16.0567s	
18312/25300 (epoch 36.190), train_loss = 0.75195552, grad/param norm = 2.1343e-01, time/batch = 16.1597s	
18313/25300 (epoch 36.192), train_loss = 0.72115165, grad/param norm = 1.9249e-01, time/batch = 16.0700s	
18314/25300 (epoch 36.194), train_loss = 0.70525866, grad/param norm = 2.1552e-01, time/batch = 16.6628s	
18315/25300 (epoch 36.196), train_loss = 0.85062369, grad/param norm = 2.7157e-01, time/batch = 15.7211s	
18316/25300 (epoch 36.198), train_loss = 0.70827622, grad/param norm = 2.3530e-01, time/batch = 16.8224s	
18317/25300 (epoch 36.200), train_loss = 0.74054377, grad/param norm = 2.1821e-01, time/batch = 16.0789s	
18318/25300 (epoch 36.202), train_loss = 0.75804959, grad/param norm = 2.1923e-01, time/batch = 15.8318s	
18319/25300 (epoch 36.204), train_loss = 0.75016721, grad/param norm = 2.1246e-01, time/batch = 15.2134s	
18320/25300 (epoch 36.206), train_loss = 0.85026621, grad/param norm = 2.3224e-01, time/batch = 15.1603s	
18321/25300 (epoch 36.208), train_loss = 0.68768156, grad/param norm = 2.5428e-01, time/batch = 15.0878s	
18322/25300 (epoch 36.209), train_loss = 0.67165507, grad/param norm = 2.3708e-01, time/batch = 15.6578s	
18323/25300 (epoch 36.211), train_loss = 0.72860288, grad/param norm = 1.9706e-01, time/batch = 15.1556s	
18324/25300 (epoch 36.213), train_loss = 0.79269707, grad/param norm = 2.5073e-01, time/batch = 15.4120s	
18325/25300 (epoch 36.215), train_loss = 0.77777419, grad/param norm = 2.0328e-01, time/batch = 16.0463s	
18326/25300 (epoch 36.217), train_loss = 0.80053043, grad/param norm = 2.7381e-01, time/batch = 16.0711s	
18327/25300 (epoch 36.219), train_loss = 0.83542755, grad/param norm = 2.4005e-01, time/batch = 15.4808s	
18328/25300 (epoch 36.221), train_loss = 0.88180702, grad/param norm = 2.7005e-01, time/batch = 15.8351s	
18329/25300 (epoch 36.223), train_loss = 0.82843465, grad/param norm = 2.3110e-01, time/batch = 15.8974s	
18330/25300 (epoch 36.225), train_loss = 1.03355041, grad/param norm = 2.7999e-01, time/batch = 15.9799s	
18331/25300 (epoch 36.227), train_loss = 0.88803323, grad/param norm = 2.4085e-01, time/batch = 16.4050s	
18332/25300 (epoch 36.229), train_loss = 0.74148639, grad/param norm = 2.2245e-01, time/batch = 15.9182s	
18333/25300 (epoch 36.231), train_loss = 0.78763088, grad/param norm = 2.6085e-01, time/batch = 16.5011s	
18334/25300 (epoch 36.233), train_loss = 0.81606733, grad/param norm = 2.3291e-01, time/batch = 15.7131s	
18335/25300 (epoch 36.235), train_loss = 0.76598194, grad/param norm = 2.4007e-01, time/batch = 15.4853s	
18336/25300 (epoch 36.237), train_loss = 0.89850482, grad/param norm = 2.5187e-01, time/batch = 15.5650s	
18337/25300 (epoch 36.239), train_loss = 0.73338865, grad/param norm = 2.2548e-01, time/batch = 17.1419s	
18338/25300 (epoch 36.241), train_loss = 0.90790117, grad/param norm = 2.4804e-01, time/batch = 15.9043s	
18339/25300 (epoch 36.243), train_loss = 1.02338893, grad/param norm = 2.8466e-01, time/batch = 16.9772s	
18340/25300 (epoch 36.245), train_loss = 0.74222458, grad/param norm = 2.3748e-01, time/batch = 17.4914s	
18341/25300 (epoch 36.247), train_loss = 0.83411840, grad/param norm = 2.4458e-01, time/batch = 16.0536s	
18342/25300 (epoch 36.249), train_loss = 0.69780750, grad/param norm = 1.9975e-01, time/batch = 15.9877s	
18343/25300 (epoch 36.251), train_loss = 0.68564821, grad/param norm = 2.1324e-01, time/batch = 15.6467s	
18344/25300 (epoch 36.253), train_loss = 0.75279405, grad/param norm = 2.0873e-01, time/batch = 16.1526s	
18345/25300 (epoch 36.255), train_loss = 0.69946705, grad/param norm = 2.1673e-01, time/batch = 15.6556s	
18346/25300 (epoch 36.257), train_loss = 0.72590747, grad/param norm = 2.0944e-01, time/batch = 16.8068s	
18347/25300 (epoch 36.259), train_loss = 0.91006185, grad/param norm = 2.6077e-01, time/batch = 15.5771s	
18348/25300 (epoch 36.261), train_loss = 0.88726684, grad/param norm = 2.8582e-01, time/batch = 16.1535s	
18349/25300 (epoch 36.263), train_loss = 0.90514847, grad/param norm = 2.3668e-01, time/batch = 15.7338s	
18350/25300 (epoch 36.265), train_loss = 0.91937278, grad/param norm = 2.5350e-01, time/batch = 15.5817s	
18351/25300 (epoch 36.267), train_loss = 0.81626728, grad/param norm = 2.1732e-01, time/batch = 15.5813s	
18352/25300 (epoch 36.269), train_loss = 0.66697851, grad/param norm = 2.0588e-01, time/batch = 15.6388s	
18353/25300 (epoch 36.271), train_loss = 0.72020840, grad/param norm = 2.2852e-01, time/batch = 15.9959s	
18354/25300 (epoch 36.273), train_loss = 0.83262032, grad/param norm = 2.2529e-01, time/batch = 15.8190s	
18355/25300 (epoch 36.275), train_loss = 0.74695166, grad/param norm = 1.9470e-01, time/batch = 16.4157s	
18356/25300 (epoch 36.277), train_loss = 0.72369842, grad/param norm = 3.3076e-01, time/batch = 15.2254s	
18357/25300 (epoch 36.279), train_loss = 0.77104734, grad/param norm = 2.1260e-01, time/batch = 15.4714s	
18358/25300 (epoch 36.281), train_loss = 0.92709049, grad/param norm = 2.5563e-01, time/batch = 15.3731s	
18359/25300 (epoch 36.283), train_loss = 0.69183655, grad/param norm = 1.9743e-01, time/batch = 15.5713s	
18360/25300 (epoch 36.285), train_loss = 0.78443013, grad/param norm = 2.2122e-01, time/batch = 15.4705s	
18361/25300 (epoch 36.287), train_loss = 0.89844478, grad/param norm = 2.0793e-01, time/batch = 15.3049s	
18362/25300 (epoch 36.289), train_loss = 0.75818160, grad/param norm = 2.5338e-01, time/batch = 15.5731s	
18363/25300 (epoch 36.291), train_loss = 0.73651111, grad/param norm = 2.2667e-01, time/batch = 15.5749s	
18364/25300 (epoch 36.292), train_loss = 0.94548204, grad/param norm = 2.1218e-01, time/batch = 15.5613s	
18365/25300 (epoch 36.294), train_loss = 0.80761011, grad/param norm = 2.1461e-01, time/batch = 15.5478s	
18366/25300 (epoch 36.296), train_loss = 0.70113759, grad/param norm = 1.9906e-01, time/batch = 15.4357s	
18367/25300 (epoch 36.298), train_loss = 0.84148936, grad/param norm = 2.1966e-01, time/batch = 15.4949s	
18368/25300 (epoch 36.300), train_loss = 0.87451740, grad/param norm = 2.7147e-01, time/batch = 15.2899s	
18369/25300 (epoch 36.302), train_loss = 0.62553280, grad/param norm = 2.0308e-01, time/batch = 15.1491s	
18370/25300 (epoch 36.304), train_loss = 0.90448188, grad/param norm = 2.0625e-01, time/batch = 15.5533s	
18371/25300 (epoch 36.306), train_loss = 0.62702771, grad/param norm = 2.0541e-01, time/batch = 15.6372s	
18372/25300 (epoch 36.308), train_loss = 0.84532451, grad/param norm = 2.1114e-01, time/batch = 15.5578s	
18373/25300 (epoch 36.310), train_loss = 0.69846790, grad/param norm = 2.3413e-01, time/batch = 15.6450s	
18374/25300 (epoch 36.312), train_loss = 0.79912709, grad/param norm = 2.0100e-01, time/batch = 15.7084s	
18375/25300 (epoch 36.314), train_loss = 0.66574509, grad/param norm = 2.1181e-01, time/batch = 15.7150s	
18376/25300 (epoch 36.316), train_loss = 0.80288409, grad/param norm = 2.0170e-01, time/batch = 15.7297s	
18377/25300 (epoch 36.318), train_loss = 0.63536566, grad/param norm = 2.1672e-01, time/batch = 15.3966s	
18378/25300 (epoch 36.320), train_loss = 0.71398853, grad/param norm = 1.9959e-01, time/batch = 15.7404s	
18379/25300 (epoch 36.322), train_loss = 0.92316876, grad/param norm = 2.7661e-01, time/batch = 15.5583s	
18380/25300 (epoch 36.324), train_loss = 0.71020633, grad/param norm = 2.2374e-01, time/batch = 16.0252s	
18381/25300 (epoch 36.326), train_loss = 0.62213242, grad/param norm = 1.7270e-01, time/batch = 15.6360s	
18382/25300 (epoch 36.328), train_loss = 0.63099123, grad/param norm = 2.2915e-01, time/batch = 15.8273s	
18383/25300 (epoch 36.330), train_loss = 0.74644045, grad/param norm = 2.0465e-01, time/batch = 15.6986s	
18384/25300 (epoch 36.332), train_loss = 0.78156093, grad/param norm = 1.9980e-01, time/batch = 16.1593s	
18385/25300 (epoch 36.334), train_loss = 0.63856233, grad/param norm = 2.1629e-01, time/batch = 15.7282s	
18386/25300 (epoch 36.336), train_loss = 0.65144019, grad/param norm = 2.0235e-01, time/batch = 16.1698s	
18387/25300 (epoch 36.338), train_loss = 0.66687148, grad/param norm = 2.1920e-01, time/batch = 15.6392s	
18388/25300 (epoch 36.340), train_loss = 0.70905537, grad/param norm = 2.2338e-01, time/batch = 15.8196s	
18389/25300 (epoch 36.342), train_loss = 0.72151012, grad/param norm = 2.5798e-01, time/batch = 15.5381s	
18390/25300 (epoch 36.344), train_loss = 0.81804976, grad/param norm = 2.1841e-01, time/batch = 15.3625s	
18391/25300 (epoch 36.346), train_loss = 0.72124953, grad/param norm = 2.0933e-01, time/batch = 15.8696s	
18392/25300 (epoch 36.348), train_loss = 0.67857049, grad/param norm = 2.0693e-01, time/batch = 15.5679s	
18393/25300 (epoch 36.350), train_loss = 0.73556238, grad/param norm = 2.3445e-01, time/batch = 15.6584s	
18394/25300 (epoch 36.352), train_loss = 0.75075099, grad/param norm = 2.0499e-01, time/batch = 15.8924s	
18395/25300 (epoch 36.354), train_loss = 0.73686016, grad/param norm = 2.4893e-01, time/batch = 15.4316s	
18396/25300 (epoch 36.356), train_loss = 0.74107488, grad/param norm = 2.0659e-01, time/batch = 16.1197s	
18397/25300 (epoch 36.358), train_loss = 0.78215067, grad/param norm = 2.3710e-01, time/batch = 15.7006s	
18398/25300 (epoch 36.360), train_loss = 0.69718808, grad/param norm = 2.8371e-01, time/batch = 15.8041s	
18399/25300 (epoch 36.362), train_loss = 0.65457259, grad/param norm = 2.2839e-01, time/batch = 16.2050s	
18400/25300 (epoch 36.364), train_loss = 0.68125811, grad/param norm = 2.0984e-01, time/batch = 16.2198s	
18401/25300 (epoch 36.366), train_loss = 0.64891848, grad/param norm = 2.0039e-01, time/batch = 15.8722s	
18402/25300 (epoch 36.368), train_loss = 0.73114995, grad/param norm = 2.1264e-01, time/batch = 15.9179s	
18403/25300 (epoch 36.370), train_loss = 0.68256110, grad/param norm = 2.0533e-01, time/batch = 15.3811s	
18404/25300 (epoch 36.372), train_loss = 0.68490319, grad/param norm = 2.6002e-01, time/batch = 15.9520s	
18405/25300 (epoch 36.374), train_loss = 0.64730372, grad/param norm = 2.0226e-01, time/batch = 16.3942s	
18406/25300 (epoch 36.375), train_loss = 0.84921895, grad/param norm = 2.7147e-01, time/batch = 15.6577s	
18407/25300 (epoch 36.377), train_loss = 0.82897811, grad/param norm = 2.4448e-01, time/batch = 15.8550s	
18408/25300 (epoch 36.379), train_loss = 0.79283431, grad/param norm = 2.2081e-01, time/batch = 17.6346s	
18409/25300 (epoch 36.381), train_loss = 0.73567039, grad/param norm = 2.2241e-01, time/batch = 16.0708s	
18410/25300 (epoch 36.383), train_loss = 0.71005145, grad/param norm = 2.5405e-01, time/batch = 15.8066s	
18411/25300 (epoch 36.385), train_loss = 0.77298278, grad/param norm = 1.9668e-01, time/batch = 16.2357s	
18412/25300 (epoch 36.387), train_loss = 0.74171120, grad/param norm = 2.2599e-01, time/batch = 18.4692s	
18413/25300 (epoch 36.389), train_loss = 0.74671431, grad/param norm = 2.4098e-01, time/batch = 15.7087s	
18414/25300 (epoch 36.391), train_loss = 0.72976635, grad/param norm = 2.1399e-01, time/batch = 16.3844s	
18415/25300 (epoch 36.393), train_loss = 0.77924042, grad/param norm = 3.1119e-01, time/batch = 16.8983s	
18416/25300 (epoch 36.395), train_loss = 0.62841223, grad/param norm = 1.9901e-01, time/batch = 16.2881s	
18417/25300 (epoch 36.397), train_loss = 0.58553543, grad/param norm = 2.5302e-01, time/batch = 17.6349s	
18418/25300 (epoch 36.399), train_loss = 0.66070278, grad/param norm = 2.1564e-01, time/batch = 17.0734s	
18419/25300 (epoch 36.401), train_loss = 0.80481292, grad/param norm = 2.3843e-01, time/batch = 16.8196s	
18420/25300 (epoch 36.403), train_loss = 0.80185911, grad/param norm = 3.0369e-01, time/batch = 15.9751s	
18421/25300 (epoch 36.405), train_loss = 0.73327252, grad/param norm = 2.3636e-01, time/batch = 15.8526s	
18422/25300 (epoch 36.407), train_loss = 0.73273619, grad/param norm = 2.1055e-01, time/batch = 16.2891s	
18423/25300 (epoch 36.409), train_loss = 0.67663972, grad/param norm = 2.0963e-01, time/batch = 16.2342s	
18424/25300 (epoch 36.411), train_loss = 0.69499479, grad/param norm = 2.0631e-01, time/batch = 16.1186s	
18425/25300 (epoch 36.413), train_loss = 0.62961428, grad/param norm = 2.1015e-01, time/batch = 17.0399s	
18426/25300 (epoch 36.415), train_loss = 0.69114844, grad/param norm = 2.3729e-01, time/batch = 19.3756s	
18427/25300 (epoch 36.417), train_loss = 0.62556721, grad/param norm = 1.8281e-01, time/batch = 16.2975s	
18428/25300 (epoch 36.419), train_loss = 0.56078951, grad/param norm = 1.7470e-01, time/batch = 15.7184s	
18429/25300 (epoch 36.421), train_loss = 0.63983511, grad/param norm = 1.6955e-01, time/batch = 15.6471s	
18430/25300 (epoch 36.423), train_loss = 0.62002507, grad/param norm = 1.7723e-01, time/batch = 17.4816s	
18431/25300 (epoch 36.425), train_loss = 0.72957527, grad/param norm = 2.5996e-01, time/batch = 16.0539s	
18432/25300 (epoch 36.427), train_loss = 0.82126701, grad/param norm = 2.2366e-01, time/batch = 15.8133s	
18433/25300 (epoch 36.429), train_loss = 0.85246741, grad/param norm = 2.7693e-01, time/batch = 16.0476s	
18434/25300 (epoch 36.431), train_loss = 0.75534142, grad/param norm = 2.2344e-01, time/batch = 15.8815s	
18435/25300 (epoch 36.433), train_loss = 0.78803663, grad/param norm = 1.9662e-01, time/batch = 16.1579s	
18436/25300 (epoch 36.435), train_loss = 0.68240312, grad/param norm = 2.3687e-01, time/batch = 16.2259s	
18437/25300 (epoch 36.437), train_loss = 0.68789662, grad/param norm = 2.3967e-01, time/batch = 16.3149s	
18438/25300 (epoch 36.439), train_loss = 0.76795745, grad/param norm = 2.1718e-01, time/batch = 15.7363s	
18439/25300 (epoch 36.441), train_loss = 0.78470960, grad/param norm = 2.2975e-01, time/batch = 15.4928s	
18440/25300 (epoch 36.443), train_loss = 0.89529157, grad/param norm = 2.5485e-01, time/batch = 15.1792s	
18441/25300 (epoch 36.445), train_loss = 0.83930155, grad/param norm = 2.5900e-01, time/batch = 17.7086s	
18442/25300 (epoch 36.447), train_loss = 0.67938495, grad/param norm = 1.9962e-01, time/batch = 15.4662s	
18443/25300 (epoch 36.449), train_loss = 0.61978469, grad/param norm = 2.1350e-01, time/batch = 16.0661s	
18444/25300 (epoch 36.451), train_loss = 0.94741005, grad/param norm = 2.6129e-01, time/batch = 16.2236s	
18445/25300 (epoch 36.453), train_loss = 0.82695762, grad/param norm = 2.9084e-01, time/batch = 18.0423s	
18446/25300 (epoch 36.455), train_loss = 0.80233293, grad/param norm = 2.9662e-01, time/batch = 16.0639s	
18447/25300 (epoch 36.457), train_loss = 0.67336804, grad/param norm = 2.1553e-01, time/batch = 15.3156s	
18448/25300 (epoch 36.458), train_loss = 0.71086731, grad/param norm = 2.9323e-01, time/batch = 16.1562s	
18449/25300 (epoch 36.460), train_loss = 0.74685411, grad/param norm = 2.4897e-01, time/batch = 15.7228s	
18450/25300 (epoch 36.462), train_loss = 0.52711396, grad/param norm = 1.8753e-01, time/batch = 15.8092s	
18451/25300 (epoch 36.464), train_loss = 0.81690852, grad/param norm = 2.4824e-01, time/batch = 15.7430s	
18452/25300 (epoch 36.466), train_loss = 0.77288506, grad/param norm = 2.1621e-01, time/batch = 16.5644s	
18453/25300 (epoch 36.468), train_loss = 0.77374592, grad/param norm = 2.3201e-01, time/batch = 15.4013s	
18454/25300 (epoch 36.470), train_loss = 0.72222429, grad/param norm = 2.1363e-01, time/batch = 15.3089s	
18455/25300 (epoch 36.472), train_loss = 0.62890402, grad/param norm = 1.9864e-01, time/batch = 15.3983s	
18456/25300 (epoch 36.474), train_loss = 0.75706655, grad/param norm = 2.0291e-01, time/batch = 15.5692s	
18457/25300 (epoch 36.476), train_loss = 0.70769756, grad/param norm = 2.1340e-01, time/batch = 15.2839s	
18458/25300 (epoch 36.478), train_loss = 0.79598824, grad/param norm = 2.3020e-01, time/batch = 17.4685s	
18459/25300 (epoch 36.480), train_loss = 0.71669537, grad/param norm = 2.0986e-01, time/batch = 16.9890s	
18460/25300 (epoch 36.482), train_loss = 0.77771541, grad/param norm = 2.4242e-01, time/batch = 15.9621s	
18461/25300 (epoch 36.484), train_loss = 0.80650339, grad/param norm = 2.5828e-01, time/batch = 16.8960s	
18462/25300 (epoch 36.486), train_loss = 0.75596530, grad/param norm = 2.6028e-01, time/batch = 18.1309s	
18463/25300 (epoch 36.488), train_loss = 0.91486488, grad/param norm = 2.9311e-01, time/batch = 18.1361s	
18464/25300 (epoch 36.490), train_loss = 0.77044001, grad/param norm = 2.1753e-01, time/batch = 29.5505s	
18465/25300 (epoch 36.492), train_loss = 0.84976217, grad/param norm = 2.1281e-01, time/batch = 16.4768s	
18466/25300 (epoch 36.494), train_loss = 0.76137275, grad/param norm = 2.2174e-01, time/batch = 18.2159s	
18467/25300 (epoch 36.496), train_loss = 0.79482937, grad/param norm = 2.2810e-01, time/batch = 16.0736s	
18468/25300 (epoch 36.498), train_loss = 0.72701874, grad/param norm = 1.9703e-01, time/batch = 16.0443s	
18469/25300 (epoch 36.500), train_loss = 0.88276522, grad/param norm = 2.4833e-01, time/batch = 16.4762s	
18470/25300 (epoch 36.502), train_loss = 0.80695974, grad/param norm = 2.3303e-01, time/batch = 15.7389s	
18471/25300 (epoch 36.504), train_loss = 0.71965418, grad/param norm = 2.3575e-01, time/batch = 15.7989s	
18472/25300 (epoch 36.506), train_loss = 0.65375282, grad/param norm = 3.0281e-01, time/batch = 16.3960s	
18473/25300 (epoch 36.508), train_loss = 0.75507834, grad/param norm = 2.3963e-01, time/batch = 18.9634s	
18474/25300 (epoch 36.510), train_loss = 0.70864297, grad/param norm = 2.3171e-01, time/batch = 16.8940s	
18475/25300 (epoch 36.512), train_loss = 0.58865294, grad/param norm = 1.8857e-01, time/batch = 16.5607s	
18476/25300 (epoch 36.514), train_loss = 0.73062510, grad/param norm = 2.2431e-01, time/batch = 17.8908s	
18477/25300 (epoch 36.516), train_loss = 0.81506752, grad/param norm = 2.3764e-01, time/batch = 15.7107s	
18478/25300 (epoch 36.518), train_loss = 0.84408400, grad/param norm = 2.3462e-01, time/batch = 16.2405s	
18479/25300 (epoch 36.520), train_loss = 0.61182514, grad/param norm = 1.6973e-01, time/batch = 16.8090s	
18480/25300 (epoch 36.522), train_loss = 0.69153759, grad/param norm = 2.2811e-01, time/batch = 17.4711s	
18481/25300 (epoch 36.524), train_loss = 0.68607485, grad/param norm = 2.0300e-01, time/batch = 16.1318s	
18482/25300 (epoch 36.526), train_loss = 0.85532562, grad/param norm = 2.0979e-01, time/batch = 15.4050s	
18483/25300 (epoch 36.528), train_loss = 0.87353221, grad/param norm = 2.3639e-01, time/batch = 15.5523s	
18484/25300 (epoch 36.530), train_loss = 0.79881722, grad/param norm = 2.1158e-01, time/batch = 16.2968s	
18485/25300 (epoch 36.532), train_loss = 0.72840418, grad/param norm = 2.1293e-01, time/batch = 15.4777s	
18486/25300 (epoch 36.534), train_loss = 0.72676790, grad/param norm = 2.4775e-01, time/batch = 15.8193s	
18487/25300 (epoch 36.536), train_loss = 0.59718842, grad/param norm = 2.0121e-01, time/batch = 16.6376s	
18488/25300 (epoch 36.538), train_loss = 0.64756221, grad/param norm = 1.8280e-01, time/batch = 16.5566s	
18489/25300 (epoch 36.540), train_loss = 0.65544552, grad/param norm = 2.0763e-01, time/batch = 16.3837s	
18490/25300 (epoch 36.542), train_loss = 0.62299037, grad/param norm = 2.0895e-01, time/batch = 15.7220s	
18491/25300 (epoch 36.543), train_loss = 0.60897019, grad/param norm = 1.8577e-01, time/batch = 15.6436s	
18492/25300 (epoch 36.545), train_loss = 0.92128832, grad/param norm = 2.8151e-01, time/batch = 15.7810s	
18493/25300 (epoch 36.547), train_loss = 0.81127522, grad/param norm = 2.2636e-01, time/batch = 15.7060s	
18494/25300 (epoch 36.549), train_loss = 0.92592840, grad/param norm = 2.4589e-01, time/batch = 16.8928s	
18495/25300 (epoch 36.551), train_loss = 0.84396170, grad/param norm = 2.1664e-01, time/batch = 16.4647s	
18496/25300 (epoch 36.553), train_loss = 0.71300662, grad/param norm = 2.2815e-01, time/batch = 15.9609s	
18497/25300 (epoch 36.555), train_loss = 0.80286713, grad/param norm = 2.5552e-01, time/batch = 15.8104s	
18498/25300 (epoch 36.557), train_loss = 0.84235688, grad/param norm = 2.7547e-01, time/batch = 17.9778s	
18499/25300 (epoch 36.559), train_loss = 0.87723831, grad/param norm = 2.3921e-01, time/batch = 16.1270s	
18500/25300 (epoch 36.561), train_loss = 0.88284393, grad/param norm = 2.2976e-01, time/batch = 15.9607s	
18501/25300 (epoch 36.563), train_loss = 0.85066685, grad/param norm = 2.2017e-01, time/batch = 16.2343s	
18502/25300 (epoch 36.565), train_loss = 0.64073581, grad/param norm = 2.0137e-01, time/batch = 18.3028s	
18503/25300 (epoch 36.567), train_loss = 0.58546994, grad/param norm = 1.9295e-01, time/batch = 15.9762s	
18504/25300 (epoch 36.569), train_loss = 0.76331942, grad/param norm = 2.1145e-01, time/batch = 15.6512s	
18505/25300 (epoch 36.571), train_loss = 0.84071607, grad/param norm = 2.6402e-01, time/batch = 15.5682s	
18506/25300 (epoch 36.573), train_loss = 0.73002880, grad/param norm = 2.0217e-01, time/batch = 15.7197s	
18507/25300 (epoch 36.575), train_loss = 0.81205504, grad/param norm = 2.4864e-01, time/batch = 15.4691s	
18508/25300 (epoch 36.577), train_loss = 0.70768476, grad/param norm = 2.2387e-01, time/batch = 16.0386s	
18509/25300 (epoch 36.579), train_loss = 0.87689637, grad/param norm = 2.6306e-01, time/batch = 17.7238s	
18510/25300 (epoch 36.581), train_loss = 0.82729583, grad/param norm = 2.5491e-01, time/batch = 16.1472s	
18511/25300 (epoch 36.583), train_loss = 0.62127694, grad/param norm = 2.1862e-01, time/batch = 15.4806s	
18512/25300 (epoch 36.585), train_loss = 0.63658688, grad/param norm = 3.8113e-01, time/batch = 15.6507s	
18513/25300 (epoch 36.587), train_loss = 0.74818314, grad/param norm = 2.1563e-01, time/batch = 17.8148s	
18514/25300 (epoch 36.589), train_loss = 0.66106388, grad/param norm = 1.7922e-01, time/batch = 15.7900s	
18515/25300 (epoch 36.591), train_loss = 0.62244786, grad/param norm = 2.4278e-01, time/batch = 18.7143s	
18516/25300 (epoch 36.593), train_loss = 0.82580494, grad/param norm = 2.5050e-01, time/batch = 16.5544s	
18517/25300 (epoch 36.595), train_loss = 0.75742821, grad/param norm = 2.1516e-01, time/batch = 16.3061s	
18518/25300 (epoch 36.597), train_loss = 0.66466943, grad/param norm = 1.9600e-01, time/batch = 16.0510s	
18519/25300 (epoch 36.599), train_loss = 0.86898566, grad/param norm = 2.9024e-01, time/batch = 15.5354s	
18520/25300 (epoch 36.601), train_loss = 0.76001741, grad/param norm = 2.5509e-01, time/batch = 15.5549s	
18521/25300 (epoch 36.603), train_loss = 0.74828219, grad/param norm = 2.4959e-01, time/batch = 15.4880s	
18522/25300 (epoch 36.605), train_loss = 0.76312196, grad/param norm = 2.6563e-01, time/batch = 15.5354s	
18523/25300 (epoch 36.607), train_loss = 0.54200978, grad/param norm = 1.7059e-01, time/batch = 15.5196s	
18524/25300 (epoch 36.609), train_loss = 0.68605543, grad/param norm = 2.1162e-01, time/batch = 15.6190s	
18525/25300 (epoch 36.611), train_loss = 0.80916243, grad/param norm = 2.4448e-01, time/batch = 15.4474s	
18526/25300 (epoch 36.613), train_loss = 0.66606673, grad/param norm = 2.0242e-01, time/batch = 15.5176s	
18527/25300 (epoch 36.615), train_loss = 0.70764861, grad/param norm = 2.5375e-01, time/batch = 15.6186s	
18528/25300 (epoch 36.617), train_loss = 0.77232351, grad/param norm = 2.6662e-01, time/batch = 15.8969s	
18529/25300 (epoch 36.619), train_loss = 0.80256933, grad/param norm = 2.4817e-01, time/batch = 16.7953s	
18530/25300 (epoch 36.621), train_loss = 0.82839305, grad/param norm = 2.3032e-01, time/batch = 16.4816s	
18531/25300 (epoch 36.623), train_loss = 0.69604999, grad/param norm = 2.3271e-01, time/batch = 17.3155s	
18532/25300 (epoch 36.625), train_loss = 0.61781081, grad/param norm = 1.9444e-01, time/batch = 17.3820s	
18533/25300 (epoch 36.626), train_loss = 0.72428006, grad/param norm = 2.0266e-01, time/batch = 16.1180s	
18534/25300 (epoch 36.628), train_loss = 0.85400840, grad/param norm = 2.6495e-01, time/batch = 17.4040s	
18535/25300 (epoch 36.630), train_loss = 0.78870651, grad/param norm = 2.3279e-01, time/batch = 15.7158s	
18536/25300 (epoch 36.632), train_loss = 0.76430085, grad/param norm = 2.4494e-01, time/batch = 16.3805s	
18537/25300 (epoch 36.634), train_loss = 0.86489881, grad/param norm = 2.9504e-01, time/batch = 16.9672s	
18538/25300 (epoch 36.636), train_loss = 0.65511869, grad/param norm = 2.2474e-01, time/batch = 16.9627s	
18539/25300 (epoch 36.638), train_loss = 0.76063857, grad/param norm = 2.9267e-01, time/batch = 19.1309s	
18540/25300 (epoch 36.640), train_loss = 0.94207839, grad/param norm = 2.9694e-01, time/batch = 15.9833s	
18541/25300 (epoch 36.642), train_loss = 0.79261229, grad/param norm = 2.4844e-01, time/batch = 18.2022s	
18542/25300 (epoch 36.644), train_loss = 0.75423030, grad/param norm = 2.2215e-01, time/batch = 17.2102s	
18543/25300 (epoch 36.646), train_loss = 0.71241394, grad/param norm = 2.4608e-01, time/batch = 15.5593s	
18544/25300 (epoch 36.648), train_loss = 0.84389551, grad/param norm = 2.1505e-01, time/batch = 15.4108s	
18545/25300 (epoch 36.650), train_loss = 0.76388553, grad/param norm = 2.0983e-01, time/batch = 15.2988s	
18546/25300 (epoch 36.652), train_loss = 0.77806106, grad/param norm = 2.2229e-01, time/batch = 16.0474s	
18547/25300 (epoch 36.654), train_loss = 0.88089264, grad/param norm = 2.2805e-01, time/batch = 15.7336s	
18548/25300 (epoch 36.656), train_loss = 0.81136455, grad/param norm = 2.4189e-01, time/batch = 16.7151s	
18549/25300 (epoch 36.658), train_loss = 0.59428438, grad/param norm = 2.0714e-01, time/batch = 15.6226s	
18550/25300 (epoch 36.660), train_loss = 0.62385312, grad/param norm = 2.5856e-01, time/batch = 17.3024s	
18551/25300 (epoch 36.662), train_loss = 0.63628237, grad/param norm = 2.0030e-01, time/batch = 16.1398s	
18552/25300 (epoch 36.664), train_loss = 0.59978510, grad/param norm = 2.3875e-01, time/batch = 16.2367s	
18553/25300 (epoch 36.666), train_loss = 0.64892478, grad/param norm = 2.2490e-01, time/batch = 17.2226s	
18554/25300 (epoch 36.668), train_loss = 0.74892692, grad/param norm = 2.8812e-01, time/batch = 17.0289s	
18555/25300 (epoch 36.670), train_loss = 0.67032655, grad/param norm = 2.3529e-01, time/batch = 17.2101s	
18556/25300 (epoch 36.672), train_loss = 0.69008679, grad/param norm = 2.0408e-01, time/batch = 15.8050s	
18557/25300 (epoch 36.674), train_loss = 0.66829730, grad/param norm = 1.8676e-01, time/batch = 16.8132s	
18558/25300 (epoch 36.676), train_loss = 0.67574154, grad/param norm = 2.4775e-01, time/batch = 15.6360s	
18559/25300 (epoch 36.678), train_loss = 0.70565683, grad/param norm = 2.6507e-01, time/batch = 16.1615s	
18560/25300 (epoch 36.680), train_loss = 0.61877449, grad/param norm = 2.2296e-01, time/batch = 16.8975s	
18561/25300 (epoch 36.682), train_loss = 0.52370899, grad/param norm = 1.7052e-01, time/batch = 15.7201s	
18562/25300 (epoch 36.684), train_loss = 0.67809511, grad/param norm = 2.0036e-01, time/batch = 16.5523s	
18563/25300 (epoch 36.686), train_loss = 0.61739929, grad/param norm = 1.8478e-01, time/batch = 15.9083s	
18564/25300 (epoch 36.688), train_loss = 0.71579770, grad/param norm = 2.6332e-01, time/batch = 17.2976s	
18565/25300 (epoch 36.690), train_loss = 0.63549347, grad/param norm = 2.1009e-01, time/batch = 16.3630s	
18566/25300 (epoch 36.692), train_loss = 0.68539318, grad/param norm = 2.0616e-01, time/batch = 15.9914s	
18567/25300 (epoch 36.694), train_loss = 0.66102425, grad/param norm = 2.1241e-01, time/batch = 15.6429s	
18568/25300 (epoch 36.696), train_loss = 0.72587810, grad/param norm = 2.4708e-01, time/batch = 16.8138s	
18569/25300 (epoch 36.698), train_loss = 0.80162344, grad/param norm = 2.5419e-01, time/batch = 15.5538s	
18570/25300 (epoch 36.700), train_loss = 0.59098593, grad/param norm = 1.9092e-01, time/batch = 16.6163s	
18571/25300 (epoch 36.702), train_loss = 0.78453515, grad/param norm = 2.1935e-01, time/batch = 16.4000s	
18572/25300 (epoch 36.704), train_loss = 0.56652202, grad/param norm = 1.7680e-01, time/batch = 16.2164s	
18573/25300 (epoch 36.706), train_loss = 0.72268903, grad/param norm = 2.3279e-01, time/batch = 16.0758s	
18574/25300 (epoch 36.708), train_loss = 0.61958472, grad/param norm = 1.9011e-01, time/batch = 15.4107s	
18575/25300 (epoch 36.709), train_loss = 0.84689778, grad/param norm = 2.2378e-01, time/batch = 16.1579s	
18576/25300 (epoch 36.711), train_loss = 0.88409022, grad/param norm = 2.4517e-01, time/batch = 15.5630s	
18577/25300 (epoch 36.713), train_loss = 0.74524146, grad/param norm = 2.0364e-01, time/batch = 15.4678s	
18578/25300 (epoch 36.715), train_loss = 0.74311111, grad/param norm = 2.0525e-01, time/batch = 15.9777s	
18579/25300 (epoch 36.717), train_loss = 0.63488728, grad/param norm = 2.0087e-01, time/batch = 15.9743s	
18580/25300 (epoch 36.719), train_loss = 0.70540773, grad/param norm = 2.2164e-01, time/batch = 15.5390s	
18581/25300 (epoch 36.721), train_loss = 0.77854774, grad/param norm = 2.3175e-01, time/batch = 16.1506s	
18582/25300 (epoch 36.723), train_loss = 0.70598342, grad/param norm = 2.1131e-01, time/batch = 17.2239s	
18583/25300 (epoch 36.725), train_loss = 0.73929621, grad/param norm = 2.0975e-01, time/batch = 16.1394s	
18584/25300 (epoch 36.727), train_loss = 0.73557194, grad/param norm = 2.1922e-01, time/batch = 16.8080s	
18585/25300 (epoch 36.729), train_loss = 0.71584767, grad/param norm = 2.1599e-01, time/batch = 15.9129s	
18586/25300 (epoch 36.731), train_loss = 0.88100165, grad/param norm = 2.8236e-01, time/batch = 15.7142s	
18587/25300 (epoch 36.733), train_loss = 0.73769562, grad/param norm = 1.9431e-01, time/batch = 17.2033s	
18588/25300 (epoch 36.735), train_loss = 0.94366015, grad/param norm = 2.4814e-01, time/batch = 16.9904s	
18589/25300 (epoch 36.737), train_loss = 0.60709096, grad/param norm = 1.9818e-01, time/batch = 15.7048s	
18590/25300 (epoch 36.739), train_loss = 0.86937438, grad/param norm = 2.4561e-01, time/batch = 17.6504s	
18591/25300 (epoch 36.741), train_loss = 0.77394036, grad/param norm = 2.3326e-01, time/batch = 15.7288s	
18592/25300 (epoch 36.743), train_loss = 0.72857155, grad/param norm = 2.0265e-01, time/batch = 16.2213s	
18593/25300 (epoch 36.745), train_loss = 0.70801561, grad/param norm = 2.1501e-01, time/batch = 17.2261s	
18594/25300 (epoch 36.747), train_loss = 0.63420703, grad/param norm = 1.8540e-01, time/batch = 16.5345s	
18595/25300 (epoch 36.749), train_loss = 0.73968078, grad/param norm = 2.4282e-01, time/batch = 16.1486s	
18596/25300 (epoch 36.751), train_loss = 0.78703402, grad/param norm = 2.2940e-01, time/batch = 18.4617s	
18597/25300 (epoch 36.753), train_loss = 0.60956137, grad/param norm = 1.9134e-01, time/batch = 17.2154s	
18598/25300 (epoch 36.755), train_loss = 0.84624341, grad/param norm = 2.9055e-01, time/batch = 16.8909s	
18599/25300 (epoch 36.757), train_loss = 0.69200837, grad/param norm = 2.2578e-01, time/batch = 18.1189s	
18600/25300 (epoch 36.759), train_loss = 0.66640259, grad/param norm = 2.0875e-01, time/batch = 16.1510s	
18601/25300 (epoch 36.761), train_loss = 0.88907882, grad/param norm = 2.8053e-01, time/batch = 16.1383s	
18602/25300 (epoch 36.763), train_loss = 0.72274609, grad/param norm = 2.3853e-01, time/batch = 15.8105s	
18603/25300 (epoch 36.765), train_loss = 0.70614435, grad/param norm = 2.2750e-01, time/batch = 16.5542s	
18604/25300 (epoch 36.767), train_loss = 0.72904044, grad/param norm = 2.1209e-01, time/batch = 15.3221s	
18605/25300 (epoch 36.769), train_loss = 0.75155560, grad/param norm = 2.6323e-01, time/batch = 16.4713s	
18606/25300 (epoch 36.771), train_loss = 0.82305571, grad/param norm = 2.4097e-01, time/batch = 15.6381s	
18607/25300 (epoch 36.773), train_loss = 0.85536005, grad/param norm = 2.5097e-01, time/batch = 15.8764s	
18608/25300 (epoch 36.775), train_loss = 0.75214139, grad/param norm = 1.8548e-01, time/batch = 15.9757s	
18609/25300 (epoch 36.777), train_loss = 0.70306405, grad/param norm = 2.4489e-01, time/batch = 15.7133s	
18610/25300 (epoch 36.779), train_loss = 0.81819303, grad/param norm = 2.1173e-01, time/batch = 15.6358s	
18611/25300 (epoch 36.781), train_loss = 0.80004908, grad/param norm = 2.3075e-01, time/batch = 15.8113s	
18612/25300 (epoch 36.783), train_loss = 0.87231528, grad/param norm = 2.4872e-01, time/batch = 16.0443s	
18613/25300 (epoch 36.785), train_loss = 0.83485166, grad/param norm = 2.4190e-01, time/batch = 15.6197s	
18614/25300 (epoch 36.787), train_loss = 0.78754069, grad/param norm = 2.3387e-01, time/batch = 16.7933s	
18615/25300 (epoch 36.789), train_loss = 0.88626204, grad/param norm = 2.5229e-01, time/batch = 17.6363s	
18616/25300 (epoch 36.791), train_loss = 0.77332167, grad/param norm = 2.2147e-01, time/batch = 15.8817s	
18617/25300 (epoch 36.792), train_loss = 0.85639243, grad/param norm = 2.4260e-01, time/batch = 15.6153s	
18618/25300 (epoch 36.794), train_loss = 0.72544830, grad/param norm = 2.6156e-01, time/batch = 17.3703s	
18619/25300 (epoch 36.796), train_loss = 0.70986550, grad/param norm = 2.1895e-01, time/batch = 15.8158s	
18620/25300 (epoch 36.798), train_loss = 0.85509705, grad/param norm = 4.2350e-01, time/batch = 15.8097s	
18621/25300 (epoch 36.800), train_loss = 0.71394826, grad/param norm = 2.0150e-01, time/batch = 15.7330s	
18622/25300 (epoch 36.802), train_loss = 0.61696427, grad/param norm = 2.1088e-01, time/batch = 15.8151s	
18623/25300 (epoch 36.804), train_loss = 0.75102220, grad/param norm = 2.1026e-01, time/batch = 18.4606s	
18624/25300 (epoch 36.806), train_loss = 0.81390032, grad/param norm = 2.6460e-01, time/batch = 15.7844s	
18625/25300 (epoch 36.808), train_loss = 0.85173822, grad/param norm = 2.2236e-01, time/batch = 16.2269s	
18626/25300 (epoch 36.810), train_loss = 0.73840279, grad/param norm = 2.6358e-01, time/batch = 15.6078s	
18627/25300 (epoch 36.812), train_loss = 0.87748767, grad/param norm = 2.5160e-01, time/batch = 15.7207s	
18628/25300 (epoch 36.814), train_loss = 0.87883053, grad/param norm = 2.5443e-01, time/batch = 16.3775s	
18629/25300 (epoch 36.816), train_loss = 0.96142905, grad/param norm = 2.6501e-01, time/batch = 15.9092s	
18630/25300 (epoch 36.818), train_loss = 0.84537314, grad/param norm = 2.0609e-01, time/batch = 15.6562s	
18631/25300 (epoch 36.820), train_loss = 0.82724280, grad/param norm = 2.1306e-01, time/batch = 16.0447s	
18632/25300 (epoch 36.822), train_loss = 0.72036348, grad/param norm = 3.3483e-01, time/batch = 16.0678s	
18633/25300 (epoch 36.824), train_loss = 0.84345423, grad/param norm = 2.3312e-01, time/batch = 16.9048s	
18634/25300 (epoch 36.826), train_loss = 0.68396762, grad/param norm = 1.9175e-01, time/batch = 15.5041s	
18635/25300 (epoch 36.828), train_loss = 0.70002152, grad/param norm = 2.0560e-01, time/batch = 15.4494s	
18636/25300 (epoch 36.830), train_loss = 0.79657628, grad/param norm = 2.5743e-01, time/batch = 16.1389s	
18637/25300 (epoch 36.832), train_loss = 0.88128788, grad/param norm = 2.6827e-01, time/batch = 16.2410s	
18638/25300 (epoch 36.834), train_loss = 0.70698681, grad/param norm = 2.1123e-01, time/batch = 15.9607s	
18639/25300 (epoch 36.836), train_loss = 0.75069014, grad/param norm = 2.2657e-01, time/batch = 15.7947s	
18640/25300 (epoch 36.838), train_loss = 0.71833653, grad/param norm = 1.9554e-01, time/batch = 16.0646s	
18641/25300 (epoch 36.840), train_loss = 0.82501146, grad/param norm = 2.3095e-01, time/batch = 18.2228s	
18642/25300 (epoch 36.842), train_loss = 0.77148916, grad/param norm = 2.7552e-01, time/batch = 16.6991s	
18643/25300 (epoch 36.844), train_loss = 0.82815971, grad/param norm = 1.8356e-01, time/batch = 17.9794s	
18644/25300 (epoch 36.846), train_loss = 0.82346131, grad/param norm = 2.3504e-01, time/batch = 15.9718s	
18645/25300 (epoch 36.848), train_loss = 0.82804166, grad/param norm = 2.5819e-01, time/batch = 17.5570s	
18646/25300 (epoch 36.850), train_loss = 0.77720551, grad/param norm = 2.1590e-01, time/batch = 15.8622s	
18647/25300 (epoch 36.852), train_loss = 0.84754539, grad/param norm = 2.1014e-01, time/batch = 16.0632s	
18648/25300 (epoch 36.854), train_loss = 0.87990668, grad/param norm = 2.3847e-01, time/batch = 16.9015s	
18649/25300 (epoch 36.856), train_loss = 0.73451759, grad/param norm = 2.1158e-01, time/batch = 16.4629s	
18650/25300 (epoch 36.858), train_loss = 0.73654429, grad/param norm = 2.3514e-01, time/batch = 15.3894s	
18651/25300 (epoch 36.860), train_loss = 0.64793126, grad/param norm = 2.1723e-01, time/batch = 15.8213s	
18652/25300 (epoch 36.862), train_loss = 0.77799157, grad/param norm = 2.5721e-01, time/batch = 16.3990s	
18653/25300 (epoch 36.864), train_loss = 0.87262329, grad/param norm = 2.1762e-01, time/batch = 16.1349s	
18654/25300 (epoch 36.866), train_loss = 0.73140054, grad/param norm = 2.3639e-01, time/batch = 15.8930s	
18655/25300 (epoch 36.868), train_loss = 0.86341222, grad/param norm = 2.2732e-01, time/batch = 15.8913s	
18656/25300 (epoch 36.870), train_loss = 0.82940962, grad/param norm = 1.9736e-01, time/batch = 15.7319s	
18657/25300 (epoch 36.872), train_loss = 0.77901533, grad/param norm = 2.5051e-01, time/batch = 16.3030s	
18658/25300 (epoch 36.874), train_loss = 0.81331271, grad/param norm = 2.2649e-01, time/batch = 15.2924s	
18659/25300 (epoch 36.875), train_loss = 0.74220325, grad/param norm = 2.0041e-01, time/batch = 16.3126s	
18660/25300 (epoch 36.877), train_loss = 0.71017454, grad/param norm = 1.8464e-01, time/batch = 17.9590s	
18661/25300 (epoch 36.879), train_loss = 0.69515491, grad/param norm = 2.1011e-01, time/batch = 16.3908s	
18662/25300 (epoch 36.881), train_loss = 0.98807997, grad/param norm = 2.8612e-01, time/batch = 16.9756s	
18663/25300 (epoch 36.883), train_loss = 0.95632657, grad/param norm = 2.3282e-01, time/batch = 16.2844s	
18664/25300 (epoch 36.885), train_loss = 0.83271617, grad/param norm = 2.4727e-01, time/batch = 16.4632s	
18665/25300 (epoch 36.887), train_loss = 0.84192208, grad/param norm = 2.1980e-01, time/batch = 17.5379s	
18666/25300 (epoch 36.889), train_loss = 0.91621480, grad/param norm = 2.3575e-01, time/batch = 17.7993s	
18667/25300 (epoch 36.891), train_loss = 0.81811515, grad/param norm = 2.8272e-01, time/batch = 18.0255s	
18668/25300 (epoch 36.893), train_loss = 0.78320949, grad/param norm = 2.8343e-01, time/batch = 15.6395s	
18669/25300 (epoch 36.895), train_loss = 0.59859312, grad/param norm = 2.3486e-01, time/batch = 16.9719s	
18670/25300 (epoch 36.897), train_loss = 0.66583738, grad/param norm = 1.8830e-01, time/batch = 15.5016s	
18671/25300 (epoch 36.899), train_loss = 0.76927213, grad/param norm = 2.2105e-01, time/batch = 15.6970s	
18672/25300 (epoch 36.901), train_loss = 0.84383217, grad/param norm = 2.3995e-01, time/batch = 16.0417s	
18673/25300 (epoch 36.903), train_loss = 0.63183298, grad/param norm = 2.0362e-01, time/batch = 17.0511s	
18674/25300 (epoch 36.905), train_loss = 0.70572305, grad/param norm = 2.2845e-01, time/batch = 18.7145s	
18675/25300 (epoch 36.907), train_loss = 0.71685973, grad/param norm = 2.5170e-01, time/batch = 16.7931s	
18676/25300 (epoch 36.909), train_loss = 0.82359768, grad/param norm = 2.3803e-01, time/batch = 18.6288s	
18677/25300 (epoch 36.911), train_loss = 0.87517587, grad/param norm = 2.8308e-01, time/batch = 16.0540s	
18678/25300 (epoch 36.913), train_loss = 0.97581066, grad/param norm = 3.1401e-01, time/batch = 16.2840s	
18679/25300 (epoch 36.915), train_loss = 0.73427651, grad/param norm = 2.4749e-01, time/batch = 16.6336s	
18680/25300 (epoch 36.917), train_loss = 0.92604115, grad/param norm = 2.6180e-01, time/batch = 17.1540s	
18681/25300 (epoch 36.919), train_loss = 0.89781692, grad/param norm = 2.7306e-01, time/batch = 17.0550s	
18682/25300 (epoch 36.921), train_loss = 0.73193229, grad/param norm = 2.3196e-01, time/batch = 28.8545s	
18683/25300 (epoch 36.923), train_loss = 0.85947444, grad/param norm = 2.4844e-01, time/batch = 15.7090s	
18684/25300 (epoch 36.925), train_loss = 0.78420118, grad/param norm = 2.3660e-01, time/batch = 15.5238s	
18685/25300 (epoch 36.927), train_loss = 0.77822242, grad/param norm = 2.6178e-01, time/batch = 15.6176s	
18686/25300 (epoch 36.929), train_loss = 0.82972825, grad/param norm = 2.4164e-01, time/batch = 15.8751s	
18687/25300 (epoch 36.931), train_loss = 0.85048257, grad/param norm = 2.6228e-01, time/batch = 15.6588s	
18688/25300 (epoch 36.933), train_loss = 0.81880622, grad/param norm = 2.2382e-01, time/batch = 15.6976s	
18689/25300 (epoch 36.935), train_loss = 0.82197356, grad/param norm = 2.0522e-01, time/batch = 15.7620s	
18690/25300 (epoch 36.937), train_loss = 0.62056390, grad/param norm = 1.8207e-01, time/batch = 15.9562s	
18691/25300 (epoch 36.939), train_loss = 0.79996864, grad/param norm = 2.3870e-01, time/batch = 15.6136s	
18692/25300 (epoch 36.941), train_loss = 0.71084694, grad/param norm = 2.3247e-01, time/batch = 16.0513s	
18693/25300 (epoch 36.943), train_loss = 0.79315587, grad/param norm = 2.1946e-01, time/batch = 15.9886s	
18694/25300 (epoch 36.945), train_loss = 0.82345979, grad/param norm = 2.4891e-01, time/batch = 16.3109s	
18695/25300 (epoch 36.947), train_loss = 0.70456280, grad/param norm = 2.2642e-01, time/batch = 15.9762s	
18696/25300 (epoch 36.949), train_loss = 0.80732598, grad/param norm = 2.2301e-01, time/batch = 16.0357s	
18697/25300 (epoch 36.951), train_loss = 0.78722090, grad/param norm = 2.2654e-01, time/batch = 16.8770s	
18698/25300 (epoch 36.953), train_loss = 0.75175630, grad/param norm = 3.0545e-01, time/batch = 16.0620s	
18699/25300 (epoch 36.955), train_loss = 0.97398944, grad/param norm = 2.9612e-01, time/batch = 15.5373s	
18700/25300 (epoch 36.957), train_loss = 0.87720375, grad/param norm = 2.9927e-01, time/batch = 15.5399s	
18701/25300 (epoch 36.958), train_loss = 0.84303181, grad/param norm = 2.8859e-01, time/batch = 15.3256s	
18702/25300 (epoch 36.960), train_loss = 0.96349167, grad/param norm = 2.7525e-01, time/batch = 15.5600s	
18703/25300 (epoch 36.962), train_loss = 0.90063541, grad/param norm = 2.1818e-01, time/batch = 16.7759s	
18704/25300 (epoch 36.964), train_loss = 0.81391051, grad/param norm = 2.3180e-01, time/batch = 15.1472s	
18705/25300 (epoch 36.966), train_loss = 0.69433498, grad/param norm = 2.3173e-01, time/batch = 16.4942s	
18706/25300 (epoch 36.968), train_loss = 0.69000962, grad/param norm = 2.6289e-01, time/batch = 16.8830s	
18707/25300 (epoch 36.970), train_loss = 0.76742491, grad/param norm = 2.5623e-01, time/batch = 16.0209s	
18708/25300 (epoch 36.972), train_loss = 0.78335604, grad/param norm = 2.1893e-01, time/batch = 16.1468s	
18709/25300 (epoch 36.974), train_loss = 0.88808675, grad/param norm = 2.7924e-01, time/batch = 15.4061s	
18710/25300 (epoch 36.976), train_loss = 0.81069317, grad/param norm = 2.6648e-01, time/batch = 15.5791s	
18711/25300 (epoch 36.978), train_loss = 0.75832592, grad/param norm = 2.5687e-01, time/batch = 15.7186s	
18712/25300 (epoch 36.980), train_loss = 0.79228629, grad/param norm = 2.5255e-01, time/batch = 16.9750s	
18713/25300 (epoch 36.982), train_loss = 0.76151896, grad/param norm = 2.3034e-01, time/batch = 16.4042s	
18714/25300 (epoch 36.984), train_loss = 0.78968449, grad/param norm = 2.6668e-01, time/batch = 16.5443s	
18715/25300 (epoch 36.986), train_loss = 0.82697000, grad/param norm = 2.4167e-01, time/batch = 15.5551s	
18716/25300 (epoch 36.988), train_loss = 0.82350802, grad/param norm = 2.5151e-01, time/batch = 15.5711s	
18717/25300 (epoch 36.990), train_loss = 0.79973176, grad/param norm = 2.2176e-01, time/batch = 16.2184s	
18718/25300 (epoch 36.992), train_loss = 0.68226771, grad/param norm = 1.9193e-01, time/batch = 16.1834s	
18719/25300 (epoch 36.994), train_loss = 0.82060177, grad/param norm = 2.8871e-01, time/batch = 15.8094s	
18720/25300 (epoch 36.996), train_loss = 0.92342572, grad/param norm = 3.4290e-01, time/batch = 15.7357s	
18721/25300 (epoch 36.998), train_loss = 0.86215826, grad/param norm = 2.4491e-01, time/batch = 17.2264s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
18722/25300 (epoch 37.000), train_loss = 0.85005606, grad/param norm = 2.5087e-01, time/batch = 16.5395s	
18723/25300 (epoch 37.002), train_loss = 0.79748974, grad/param norm = 2.2837e-01, time/batch = 15.7112s	
18724/25300 (epoch 37.004), train_loss = 0.69559132, grad/param norm = 2.1300e-01, time/batch = 15.6064s	
18725/25300 (epoch 37.006), train_loss = 0.93726019, grad/param norm = 2.6865e-01, time/batch = 16.6406s	
18726/25300 (epoch 37.008), train_loss = 0.80301840, grad/param norm = 2.1583e-01, time/batch = 15.6990s	
18727/25300 (epoch 37.010), train_loss = 0.82625172, grad/param norm = 2.1579e-01, time/batch = 16.3939s	
18728/25300 (epoch 37.012), train_loss = 0.76038365, grad/param norm = 2.0676e-01, time/batch = 15.7061s	
18729/25300 (epoch 37.014), train_loss = 0.91590095, grad/param norm = 2.7256e-01, time/batch = 15.6378s	
18730/25300 (epoch 37.016), train_loss = 0.77635207, grad/param norm = 2.3438e-01, time/batch = 16.0362s	
18731/25300 (epoch 37.018), train_loss = 0.69071878, grad/param norm = 2.0278e-01, time/batch = 17.8053s	
18732/25300 (epoch 37.020), train_loss = 0.81466689, grad/param norm = 2.3089e-01, time/batch = 17.3968s	
18733/25300 (epoch 37.022), train_loss = 0.78363263, grad/param norm = 2.7390e-01, time/batch = 15.2110s	
18734/25300 (epoch 37.024), train_loss = 0.60342716, grad/param norm = 1.7456e-01, time/batch = 15.5550s	
18735/25300 (epoch 37.026), train_loss = 0.74703498, grad/param norm = 2.2675e-01, time/batch = 16.0599s	
18736/25300 (epoch 37.028), train_loss = 0.73949925, grad/param norm = 2.0487e-01, time/batch = 15.5717s	
18737/25300 (epoch 37.030), train_loss = 0.89469207, grad/param norm = 2.1253e-01, time/batch = 15.5102s	
18738/25300 (epoch 37.032), train_loss = 0.75640266, grad/param norm = 2.2347e-01, time/batch = 16.1539s	
18739/25300 (epoch 37.034), train_loss = 0.69543482, grad/param norm = 2.2447e-01, time/batch = 16.3219s	
18740/25300 (epoch 37.036), train_loss = 0.64343602, grad/param norm = 2.0818e-01, time/batch = 17.2938s	
18741/25300 (epoch 37.038), train_loss = 0.59551855, grad/param norm = 1.7788e-01, time/batch = 16.2437s	
18742/25300 (epoch 37.040), train_loss = 0.80184773, grad/param norm = 2.3848e-01, time/batch = 15.9892s	
18743/25300 (epoch 37.042), train_loss = 0.76648450, grad/param norm = 1.9825e-01, time/batch = 19.2155s	
18744/25300 (epoch 37.043), train_loss = 0.67610926, grad/param norm = 1.8382e-01, time/batch = 15.5671s	
18745/25300 (epoch 37.045), train_loss = 0.65099128, grad/param norm = 1.9493e-01, time/batch = 16.8081s	
18746/25300 (epoch 37.047), train_loss = 0.79645484, grad/param norm = 2.2048e-01, time/batch = 17.7186s	
18747/25300 (epoch 37.049), train_loss = 0.77317238, grad/param norm = 2.5219e-01, time/batch = 15.6599s	
18748/25300 (epoch 37.051), train_loss = 0.91158458, grad/param norm = 2.5012e-01, time/batch = 15.8084s	
18749/25300 (epoch 37.053), train_loss = 0.61359445, grad/param norm = 1.7631e-01, time/batch = 17.2997s	
18750/25300 (epoch 37.055), train_loss = 0.64224360, grad/param norm = 2.0354e-01, time/batch = 15.3827s	
18751/25300 (epoch 37.057), train_loss = 0.63568942, grad/param norm = 1.7590e-01, time/batch = 16.7076s	
18752/25300 (epoch 37.059), train_loss = 0.72863916, grad/param norm = 2.3008e-01, time/batch = 18.0461s	
18753/25300 (epoch 37.061), train_loss = 0.70818758, grad/param norm = 2.2440e-01, time/batch = 16.6526s	
18754/25300 (epoch 37.063), train_loss = 0.71627529, grad/param norm = 1.9017e-01, time/batch = 18.0570s	
18755/25300 (epoch 37.065), train_loss = 0.75574883, grad/param norm = 2.2113e-01, time/batch = 15.5328s	
18756/25300 (epoch 37.067), train_loss = 0.83190200, grad/param norm = 2.1375e-01, time/batch = 16.3914s	
18757/25300 (epoch 37.069), train_loss = 0.69044246, grad/param norm = 2.3082e-01, time/batch = 15.9869s	
18758/25300 (epoch 37.071), train_loss = 0.81358472, grad/param norm = 2.4867e-01, time/batch = 15.8699s	
18759/25300 (epoch 37.073), train_loss = 0.74256143, grad/param norm = 1.9681e-01, time/batch = 16.2952s	
18760/25300 (epoch 37.075), train_loss = 0.81835375, grad/param norm = 2.7358e-01, time/batch = 17.2350s	
18761/25300 (epoch 37.077), train_loss = 0.78530323, grad/param norm = 2.2288e-01, time/batch = 17.4456s	
18762/25300 (epoch 37.079), train_loss = 0.69166919, grad/param norm = 2.4811e-01, time/batch = 15.7208s	
18763/25300 (epoch 37.081), train_loss = 0.76305914, grad/param norm = 1.9423e-01, time/batch = 15.4641s	
18764/25300 (epoch 37.083), train_loss = 0.77954951, grad/param norm = 2.0166e-01, time/batch = 15.4843s	
18765/25300 (epoch 37.085), train_loss = 0.93526748, grad/param norm = 2.5286e-01, time/batch = 15.8334s	
18766/25300 (epoch 37.087), train_loss = 0.83858142, grad/param norm = 1.9620e-01, time/batch = 16.4755s	
18767/25300 (epoch 37.089), train_loss = 0.81058620, grad/param norm = 2.2793e-01, time/batch = 16.8135s	
18768/25300 (epoch 37.091), train_loss = 0.94391738, grad/param norm = 2.2740e-01, time/batch = 16.2117s	
18769/25300 (epoch 37.093), train_loss = 0.87449541, grad/param norm = 2.4736e-01, time/batch = 18.0433s	
18770/25300 (epoch 37.095), train_loss = 0.84561062, grad/param norm = 2.4110e-01, time/batch = 17.7238s	
18771/25300 (epoch 37.097), train_loss = 0.81626224, grad/param norm = 2.2483e-01, time/batch = 17.3129s	
18772/25300 (epoch 37.099), train_loss = 0.82471323, grad/param norm = 2.4155e-01, time/batch = 16.9919s	
18773/25300 (epoch 37.101), train_loss = 0.77807049, grad/param norm = 2.6615e-01, time/batch = 15.8585s	
18774/25300 (epoch 37.103), train_loss = 0.78794068, grad/param norm = 2.2092e-01, time/batch = 15.9651s	
18775/25300 (epoch 37.105), train_loss = 0.82143049, grad/param norm = 2.0694e-01, time/batch = 15.6515s	
18776/25300 (epoch 37.107), train_loss = 0.81277499, grad/param norm = 2.5124e-01, time/batch = 16.5469s	
18777/25300 (epoch 37.109), train_loss = 0.77093086, grad/param norm = 2.4243e-01, time/batch = 15.9737s	
18778/25300 (epoch 37.111), train_loss = 0.74748483, grad/param norm = 2.1816e-01, time/batch = 18.7117s	
18779/25300 (epoch 37.113), train_loss = 0.72128009, grad/param norm = 2.3057e-01, time/batch = 15.3155s	
18780/25300 (epoch 37.115), train_loss = 0.74261216, grad/param norm = 2.1915e-01, time/batch = 15.1441s	
18781/25300 (epoch 37.117), train_loss = 0.84537584, grad/param norm = 2.1844e-01, time/batch = 16.3204s	
18782/25300 (epoch 37.119), train_loss = 0.73140030, grad/param norm = 2.2624e-01, time/batch = 16.2968s	
18783/25300 (epoch 37.121), train_loss = 0.77341325, grad/param norm = 2.5779e-01, time/batch = 15.9693s	
18784/25300 (epoch 37.123), train_loss = 0.70081088, grad/param norm = 2.1309e-01, time/batch = 15.8874s	
18785/25300 (epoch 37.125), train_loss = 0.86009921, grad/param norm = 2.1472e-01, time/batch = 17.1378s	
18786/25300 (epoch 37.126), train_loss = 0.77954971, grad/param norm = 2.0533e-01, time/batch = 16.8936s	
18787/25300 (epoch 37.128), train_loss = 0.74767081, grad/param norm = 2.1210e-01, time/batch = 17.5635s	
18788/25300 (epoch 37.130), train_loss = 0.60724421, grad/param norm = 1.8588e-01, time/batch = 16.3031s	
18789/25300 (epoch 37.132), train_loss = 0.63772247, grad/param norm = 1.9988e-01, time/batch = 18.4715s	
18790/25300 (epoch 37.134), train_loss = 0.64582177, grad/param norm = 1.8082e-01, time/batch = 18.4739s	
18791/25300 (epoch 37.136), train_loss = 0.74379341, grad/param norm = 1.8817e-01, time/batch = 16.9549s	
18792/25300 (epoch 37.138), train_loss = 0.66703678, grad/param norm = 1.7647e-01, time/batch = 16.5483s	
18793/25300 (epoch 37.140), train_loss = 0.65187932, grad/param norm = 2.0624e-01, time/batch = 16.6515s	
18794/25300 (epoch 37.142), train_loss = 0.86355438, grad/param norm = 2.5033e-01, time/batch = 16.9775s	
18795/25300 (epoch 37.144), train_loss = 0.82771490, grad/param norm = 2.1207e-01, time/batch = 15.9069s	
18796/25300 (epoch 37.146), train_loss = 0.76063045, grad/param norm = 2.6142e-01, time/batch = 16.3032s	
18797/25300 (epoch 37.148), train_loss = 0.74957601, grad/param norm = 1.9526e-01, time/batch = 17.3141s	
18798/25300 (epoch 37.150), train_loss = 0.78961029, grad/param norm = 2.4050e-01, time/batch = 15.7211s	
18799/25300 (epoch 37.152), train_loss = 0.89321186, grad/param norm = 2.6055e-01, time/batch = 16.8125s	
18800/25300 (epoch 37.154), train_loss = 0.64722919, grad/param norm = 1.9700e-01, time/batch = 16.7376s	
18801/25300 (epoch 37.156), train_loss = 0.79167979, grad/param norm = 2.3796e-01, time/batch = 15.8923s	
18802/25300 (epoch 37.158), train_loss = 0.65576787, grad/param norm = 2.0002e-01, time/batch = 16.0590s	
18803/25300 (epoch 37.160), train_loss = 0.76304563, grad/param norm = 2.3592e-01, time/batch = 15.8018s	
18804/25300 (epoch 37.162), train_loss = 0.71065968, grad/param norm = 2.2409e-01, time/batch = 15.9074s	
18805/25300 (epoch 37.164), train_loss = 0.80565604, grad/param norm = 2.3199e-01, time/batch = 16.4566s	
18806/25300 (epoch 37.166), train_loss = 0.76723639, grad/param norm = 1.9401e-01, time/batch = 15.8189s	
18807/25300 (epoch 37.168), train_loss = 0.70955660, grad/param norm = 1.8637e-01, time/batch = 19.7828s	
18808/25300 (epoch 37.170), train_loss = 0.70786060, grad/param norm = 2.0490e-01, time/batch = 16.8948s	
18809/25300 (epoch 37.172), train_loss = 0.65246348, grad/param norm = 1.8486e-01, time/batch = 15.8820s	
18810/25300 (epoch 37.174), train_loss = 0.68755147, grad/param norm = 2.2186e-01, time/batch = 15.5275s	
18811/25300 (epoch 37.176), train_loss = 0.66045332, grad/param norm = 2.3054e-01, time/batch = 18.8744s	
18812/25300 (epoch 37.178), train_loss = 0.90228019, grad/param norm = 2.2926e-01, time/batch = 17.3867s	
18813/25300 (epoch 37.180), train_loss = 0.61406134, grad/param norm = 2.0865e-01, time/batch = 15.4151s	
18814/25300 (epoch 37.182), train_loss = 0.73217063, grad/param norm = 2.1164e-01, time/batch = 16.9106s	
18815/25300 (epoch 37.184), train_loss = 0.67164081, grad/param norm = 2.3141e-01, time/batch = 18.1511s	
18816/25300 (epoch 37.186), train_loss = 0.63760770, grad/param norm = 2.1610e-01, time/batch = 15.9730s	
18817/25300 (epoch 37.188), train_loss = 0.76444410, grad/param norm = 2.4509e-01, time/batch = 15.4828s	
18818/25300 (epoch 37.190), train_loss = 0.77328491, grad/param norm = 2.2652e-01, time/batch = 15.7266s	
18819/25300 (epoch 37.192), train_loss = 0.71491064, grad/param norm = 2.0139e-01, time/batch = 15.9877s	
18820/25300 (epoch 37.194), train_loss = 0.70384829, grad/param norm = 2.2356e-01, time/batch = 15.4762s	
18821/25300 (epoch 37.196), train_loss = 0.86199980, grad/param norm = 2.8736e-01, time/batch = 16.0659s	
18822/25300 (epoch 37.198), train_loss = 0.71304228, grad/param norm = 2.5075e-01, time/batch = 16.8947s	
18823/25300 (epoch 37.200), train_loss = 0.74517269, grad/param norm = 2.1623e-01, time/batch = 16.8041s	
18824/25300 (epoch 37.202), train_loss = 0.75080873, grad/param norm = 2.1320e-01, time/batch = 16.5742s	
18825/25300 (epoch 37.204), train_loss = 0.75093310, grad/param norm = 2.3501e-01, time/batch = 16.4078s	
18826/25300 (epoch 37.206), train_loss = 0.84322257, grad/param norm = 2.3562e-01, time/batch = 16.5694s	
18827/25300 (epoch 37.208), train_loss = 0.67111152, grad/param norm = 2.0812e-01, time/batch = 16.1299s	
18828/25300 (epoch 37.209), train_loss = 0.64332466, grad/param norm = 2.0757e-01, time/batch = 16.2333s	
18829/25300 (epoch 37.211), train_loss = 0.73076712, grad/param norm = 2.0516e-01, time/batch = 16.2169s	
18830/25300 (epoch 37.213), train_loss = 0.77381460, grad/param norm = 2.3455e-01, time/batch = 15.7401s	
18831/25300 (epoch 37.215), train_loss = 0.78676910, grad/param norm = 2.1538e-01, time/batch = 16.0639s	
18832/25300 (epoch 37.217), train_loss = 0.77920264, grad/param norm = 2.7313e-01, time/batch = 15.5710s	
18833/25300 (epoch 37.219), train_loss = 0.81867471, grad/param norm = 2.4150e-01, time/batch = 16.8250s	
18834/25300 (epoch 37.221), train_loss = 0.87671555, grad/param norm = 2.4617e-01, time/batch = 16.7283s	
18835/25300 (epoch 37.223), train_loss = 0.82325154, grad/param norm = 2.5496e-01, time/batch = 15.8121s	
18836/25300 (epoch 37.225), train_loss = 1.03080677, grad/param norm = 3.5116e-01, time/batch = 17.3927s	
18837/25300 (epoch 37.227), train_loss = 0.87480197, grad/param norm = 2.2577e-01, time/batch = 17.7907s	
18838/25300 (epoch 37.229), train_loss = 0.72700962, grad/param norm = 2.0212e-01, time/batch = 16.3092s	
18839/25300 (epoch 37.231), train_loss = 0.76877497, grad/param norm = 2.6350e-01, time/batch = 15.5771s	
18840/25300 (epoch 37.233), train_loss = 0.81701599, grad/param norm = 2.6372e-01, time/batch = 15.4748s	
18841/25300 (epoch 37.235), train_loss = 0.74376429, grad/param norm = 2.1765e-01, time/batch = 16.3923s	
18842/25300 (epoch 37.237), train_loss = 0.89027280, grad/param norm = 2.6172e-01, time/batch = 15.3215s	
18843/25300 (epoch 37.239), train_loss = 0.72235499, grad/param norm = 2.3866e-01, time/batch = 15.8136s	
18844/25300 (epoch 37.241), train_loss = 0.89107197, grad/param norm = 2.2398e-01, time/batch = 17.0735s	
18845/25300 (epoch 37.243), train_loss = 1.01343246, grad/param norm = 2.9690e-01, time/batch = 16.4611s	
18846/25300 (epoch 37.245), train_loss = 0.73982872, grad/param norm = 2.4557e-01, time/batch = 15.2342s	
18847/25300 (epoch 37.247), train_loss = 0.82673421, grad/param norm = 2.4514e-01, time/batch = 15.9669s	
18848/25300 (epoch 37.249), train_loss = 0.69197215, grad/param norm = 2.3186e-01, time/batch = 15.5807s	
18849/25300 (epoch 37.251), train_loss = 0.67782254, grad/param norm = 2.1719e-01, time/batch = 15.7325s	
18850/25300 (epoch 37.253), train_loss = 0.74761513, grad/param norm = 2.2724e-01, time/batch = 15.8825s	
18851/25300 (epoch 37.255), train_loss = 0.70796887, grad/param norm = 2.2795e-01, time/batch = 15.7012s	
18852/25300 (epoch 37.257), train_loss = 0.73270070, grad/param norm = 2.5410e-01, time/batch = 15.9705s	
18853/25300 (epoch 37.259), train_loss = 0.91726157, grad/param norm = 2.9249e-01, time/batch = 15.3658s	
18854/25300 (epoch 37.261), train_loss = 0.87571350, grad/param norm = 2.7916e-01, time/batch = 15.1955s	
18855/25300 (epoch 37.263), train_loss = 0.90314279, grad/param norm = 2.6154e-01, time/batch = 15.4485s	
18856/25300 (epoch 37.265), train_loss = 0.91504308, grad/param norm = 2.6054e-01, time/batch = 15.2091s	
18857/25300 (epoch 37.267), train_loss = 0.81609864, grad/param norm = 2.5872e-01, time/batch = 15.4766s	
18858/25300 (epoch 37.269), train_loss = 0.65835156, grad/param norm = 2.0516e-01, time/batch = 16.7157s	
18859/25300 (epoch 37.271), train_loss = 0.71955027, grad/param norm = 2.3162e-01, time/batch = 15.7021s	
18860/25300 (epoch 37.273), train_loss = 0.84794648, grad/param norm = 3.0402e-01, time/batch = 17.1966s	
18861/25300 (epoch 37.275), train_loss = 0.73410333, grad/param norm = 2.1289e-01, time/batch = 17.3799s	
18862/25300 (epoch 37.277), train_loss = 0.69325642, grad/param norm = 2.2129e-01, time/batch = 17.6443s	
18863/25300 (epoch 37.279), train_loss = 0.77172985, grad/param norm = 2.3755e-01, time/batch = 15.3162s	
18864/25300 (epoch 37.281), train_loss = 0.93282520, grad/param norm = 2.7581e-01, time/batch = 15.4760s	
18865/25300 (epoch 37.283), train_loss = 0.70798076, grad/param norm = 2.1255e-01, time/batch = 16.6561s	
18866/25300 (epoch 37.285), train_loss = 0.75606954, grad/param norm = 2.3861e-01, time/batch = 15.3800s	
18867/25300 (epoch 37.287), train_loss = 0.87793529, grad/param norm = 2.0131e-01, time/batch = 16.4669s	
18868/25300 (epoch 37.289), train_loss = 0.73699529, grad/param norm = 2.2856e-01, time/batch = 15.8120s	
18869/25300 (epoch 37.291), train_loss = 0.73155325, grad/param norm = 2.1633e-01, time/batch = 16.7216s	
18870/25300 (epoch 37.292), train_loss = 0.93519976, grad/param norm = 2.1061e-01, time/batch = 17.3877s	
18871/25300 (epoch 37.294), train_loss = 0.80212698, grad/param norm = 2.1554e-01, time/batch = 16.2209s	
18872/25300 (epoch 37.296), train_loss = 0.69347544, grad/param norm = 1.9148e-01, time/batch = 16.7881s	
18873/25300 (epoch 37.298), train_loss = 0.83958785, grad/param norm = 2.2267e-01, time/batch = 17.2934s	
18874/25300 (epoch 37.300), train_loss = 0.86130684, grad/param norm = 2.2989e-01, time/batch = 17.2189s	
18875/25300 (epoch 37.302), train_loss = 0.64299249, grad/param norm = 2.4143e-01, time/batch = 16.1373s	
18876/25300 (epoch 37.304), train_loss = 0.91145541, grad/param norm = 2.3662e-01, time/batch = 18.0444s	
18877/25300 (epoch 37.306), train_loss = 0.61382392, grad/param norm = 1.9614e-01, time/batch = 15.8899s	
18878/25300 (epoch 37.308), train_loss = 0.84342281, grad/param norm = 2.1155e-01, time/batch = 16.5504s	
18879/25300 (epoch 37.310), train_loss = 0.67376244, grad/param norm = 2.2562e-01, time/batch = 15.9522s	
18880/25300 (epoch 37.312), train_loss = 0.79360099, grad/param norm = 2.0658e-01, time/batch = 16.3944s	
18881/25300 (epoch 37.314), train_loss = 0.66534661, grad/param norm = 2.0417e-01, time/batch = 16.8828s	
18882/25300 (epoch 37.316), train_loss = 0.79299103, grad/param norm = 2.1079e-01, time/batch = 15.8768s	
18883/25300 (epoch 37.318), train_loss = 0.62758244, grad/param norm = 1.9798e-01, time/batch = 15.8130s	
18884/25300 (epoch 37.320), train_loss = 0.69989016, grad/param norm = 1.9484e-01, time/batch = 16.1427s	
18885/25300 (epoch 37.322), train_loss = 0.89987228, grad/param norm = 2.8062e-01, time/batch = 15.8697s	
18886/25300 (epoch 37.324), train_loss = 0.69457348, grad/param norm = 2.1082e-01, time/batch = 15.7073s	
18887/25300 (epoch 37.326), train_loss = 0.62721400, grad/param norm = 2.2034e-01, time/batch = 15.2292s	
18888/25300 (epoch 37.328), train_loss = 0.62969699, grad/param norm = 2.0021e-01, time/batch = 15.3265s	
18889/25300 (epoch 37.330), train_loss = 0.73054867, grad/param norm = 2.0482e-01, time/batch = 16.2346s	
18890/25300 (epoch 37.332), train_loss = 0.79648299, grad/param norm = 2.3929e-01, time/batch = 15.8191s	
18891/25300 (epoch 37.334), train_loss = 0.62144343, grad/param norm = 1.9059e-01, time/batch = 15.9825s	
18892/25300 (epoch 37.336), train_loss = 0.64238911, grad/param norm = 2.0994e-01, time/batch = 16.0789s	
18893/25300 (epoch 37.338), train_loss = 0.64881413, grad/param norm = 2.0700e-01, time/batch = 16.8817s	
18894/25300 (epoch 37.340), train_loss = 0.70252376, grad/param norm = 2.0939e-01, time/batch = 17.3851s	
18895/25300 (epoch 37.342), train_loss = 0.71581435, grad/param norm = 2.6125e-01, time/batch = 15.8164s	
18896/25300 (epoch 37.344), train_loss = 0.80770484, grad/param norm = 2.2430e-01, time/batch = 16.3967s	
18897/25300 (epoch 37.346), train_loss = 0.70773704, grad/param norm = 2.1812e-01, time/batch = 15.6524s	
18898/25300 (epoch 37.348), train_loss = 0.68861564, grad/param norm = 2.2550e-01, time/batch = 15.8141s	
18899/25300 (epoch 37.350), train_loss = 0.72281113, grad/param norm = 2.1845e-01, time/batch = 15.5727s	
18900/25300 (epoch 37.352), train_loss = 0.75505303, grad/param norm = 2.3607e-01, time/batch = 16.1187s	
18901/25300 (epoch 37.354), train_loss = 0.70900309, grad/param norm = 2.1852e-01, time/batch = 28.6354s	
18902/25300 (epoch 37.356), train_loss = 0.73471304, grad/param norm = 2.0477e-01, time/batch = 16.2343s	
18903/25300 (epoch 37.358), train_loss = 0.75759785, grad/param norm = 2.0639e-01, time/batch = 16.3814s	
18904/25300 (epoch 37.360), train_loss = 0.68083402, grad/param norm = 2.0160e-01, time/batch = 15.4878s	
18905/25300 (epoch 37.362), train_loss = 0.63715832, grad/param norm = 2.1177e-01, time/batch = 15.7458s	
18906/25300 (epoch 37.364), train_loss = 0.67591939, grad/param norm = 2.4239e-01, time/batch = 15.7558s	
18907/25300 (epoch 37.366), train_loss = 0.65885126, grad/param norm = 2.3287e-01, time/batch = 16.1322s	
18908/25300 (epoch 37.368), train_loss = 0.72124794, grad/param norm = 2.0705e-01, time/batch = 16.0769s	
18909/25300 (epoch 37.370), train_loss = 0.68277010, grad/param norm = 2.4998e-01, time/batch = 16.6489s	
18910/25300 (epoch 37.372), train_loss = 0.67328236, grad/param norm = 2.5792e-01, time/batch = 16.8089s	
18911/25300 (epoch 37.374), train_loss = 0.63820371, grad/param norm = 2.3264e-01, time/batch = 15.5740s	
18912/25300 (epoch 37.375), train_loss = 0.83479978, grad/param norm = 2.5290e-01, time/batch = 16.1574s	
18913/25300 (epoch 37.377), train_loss = 0.81262929, grad/param norm = 2.2771e-01, time/batch = 16.9844s	
18914/25300 (epoch 37.379), train_loss = 0.78848883, grad/param norm = 2.2212e-01, time/batch = 16.4917s	
18915/25300 (epoch 37.381), train_loss = 0.71598703, grad/param norm = 2.0196e-01, time/batch = 16.0647s	
18916/25300 (epoch 37.383), train_loss = 0.68628914, grad/param norm = 2.1512e-01, time/batch = 18.9761s	
18917/25300 (epoch 37.385), train_loss = 0.76067944, grad/param norm = 1.9820e-01, time/batch = 17.0452s	
18918/25300 (epoch 37.387), train_loss = 0.73462040, grad/param norm = 2.1606e-01, time/batch = 16.8785s	
18919/25300 (epoch 37.389), train_loss = 0.72781298, grad/param norm = 2.3213e-01, time/batch = 16.4031s	
18920/25300 (epoch 37.391), train_loss = 0.71326533, grad/param norm = 2.1634e-01, time/batch = 16.5534s	
18921/25300 (epoch 37.393), train_loss = 0.76418575, grad/param norm = 2.7932e-01, time/batch = 16.3902s	
18922/25300 (epoch 37.395), train_loss = 0.61656014, grad/param norm = 1.9536e-01, time/batch = 15.6147s	
18923/25300 (epoch 37.397), train_loss = 0.57583489, grad/param norm = 2.2213e-01, time/batch = 18.3068s	
18924/25300 (epoch 37.399), train_loss = 0.64471552, grad/param norm = 2.1946e-01, time/batch = 15.8993s	
18925/25300 (epoch 37.401), train_loss = 0.79070660, grad/param norm = 2.7113e-01, time/batch = 16.4801s	
18926/25300 (epoch 37.403), train_loss = 0.78411820, grad/param norm = 3.0424e-01, time/batch = 15.4977s	
18927/25300 (epoch 37.405), train_loss = 0.69765355, grad/param norm = 2.1631e-01, time/batch = 18.0531s	
18928/25300 (epoch 37.407), train_loss = 0.72078082, grad/param norm = 2.1947e-01, time/batch = 16.7407s	
18929/25300 (epoch 37.409), train_loss = 0.67250300, grad/param norm = 1.9984e-01, time/batch = 16.2972s	
18930/25300 (epoch 37.411), train_loss = 0.69261336, grad/param norm = 2.3611e-01, time/batch = 15.1633s	
18931/25300 (epoch 37.413), train_loss = 0.60834171, grad/param norm = 1.9550e-01, time/batch = 17.1400s	
18932/25300 (epoch 37.415), train_loss = 0.65717176, grad/param norm = 1.9881e-01, time/batch = 16.1248s	
18933/25300 (epoch 37.417), train_loss = 0.62912458, grad/param norm = 2.0713e-01, time/batch = 15.9846s	
18934/25300 (epoch 37.419), train_loss = 0.55170309, grad/param norm = 1.6398e-01, time/batch = 15.7328s	
18935/25300 (epoch 37.421), train_loss = 0.62774064, grad/param norm = 1.6967e-01, time/batch = 15.7305s	
18936/25300 (epoch 37.423), train_loss = 0.62988163, grad/param norm = 2.0090e-01, time/batch = 16.7150s	
18937/25300 (epoch 37.425), train_loss = 0.72352318, grad/param norm = 4.6423e-01, time/batch = 15.7202s	
18938/25300 (epoch 37.427), train_loss = 0.82247746, grad/param norm = 2.3303e-01, time/batch = 15.6232s	
18939/25300 (epoch 37.429), train_loss = 0.84093366, grad/param norm = 2.7681e-01, time/batch = 15.4683s	
18940/25300 (epoch 37.431), train_loss = 0.74853604, grad/param norm = 2.1778e-01, time/batch = 16.0354s	
18941/25300 (epoch 37.433), train_loss = 0.78874949, grad/param norm = 2.1709e-01, time/batch = 15.8916s	
18942/25300 (epoch 37.435), train_loss = 0.68274565, grad/param norm = 2.8909e-01, time/batch = 15.3979s	
18943/25300 (epoch 37.437), train_loss = 0.67558845, grad/param norm = 2.4949e-01, time/batch = 16.9741s	
18944/25300 (epoch 37.439), train_loss = 0.76222821, grad/param norm = 2.3547e-01, time/batch = 15.7925s	
18945/25300 (epoch 37.441), train_loss = 0.80207538, grad/param norm = 2.6928e-01, time/batch = 18.3815s	
18946/25300 (epoch 37.443), train_loss = 0.88823403, grad/param norm = 2.4309e-01, time/batch = 17.0486s	
18947/25300 (epoch 37.445), train_loss = 0.82575468, grad/param norm = 2.7540e-01, time/batch = 15.7366s	
18948/25300 (epoch 37.447), train_loss = 0.67706482, grad/param norm = 1.9666e-01, time/batch = 17.2273s	
18949/25300 (epoch 37.449), train_loss = 0.62596630, grad/param norm = 2.3934e-01, time/batch = 16.1437s	
18950/25300 (epoch 37.451), train_loss = 0.93104372, grad/param norm = 2.6300e-01, time/batch = 18.5493s	
18951/25300 (epoch 37.453), train_loss = 0.80983539, grad/param norm = 2.5087e-01, time/batch = 15.7971s	
18952/25300 (epoch 37.455), train_loss = 0.78003921, grad/param norm = 2.7456e-01, time/batch = 16.3007s	
18953/25300 (epoch 37.457), train_loss = 0.67952289, grad/param norm = 2.2671e-01, time/batch = 17.3075s	
18954/25300 (epoch 37.458), train_loss = 0.70752020, grad/param norm = 2.2297e-01, time/batch = 17.4542s	
18955/25300 (epoch 37.460), train_loss = 0.73011662, grad/param norm = 2.2121e-01, time/batch = 15.8827s	
18956/25300 (epoch 37.462), train_loss = 0.52135386, grad/param norm = 1.9600e-01, time/batch = 16.5827s	
18957/25300 (epoch 37.464), train_loss = 0.79446381, grad/param norm = 2.4702e-01, time/batch = 15.4130s	
18958/25300 (epoch 37.466), train_loss = 0.74526035, grad/param norm = 2.0937e-01, time/batch = 15.4674s	
18959/25300 (epoch 37.468), train_loss = 0.76404859, grad/param norm = 1.8154e-01, time/batch = 15.3773s	
18960/25300 (epoch 37.470), train_loss = 0.71513184, grad/param norm = 2.0076e-01, time/batch = 17.3153s	
18961/25300 (epoch 37.472), train_loss = 0.62814484, grad/param norm = 2.0965e-01, time/batch = 17.3900s	
18962/25300 (epoch 37.474), train_loss = 0.76603822, grad/param norm = 2.0706e-01, time/batch = 15.7219s	
18963/25300 (epoch 37.476), train_loss = 0.70397108, grad/param norm = 2.4267e-01, time/batch = 16.0530s	
18964/25300 (epoch 37.478), train_loss = 0.75930184, grad/param norm = 2.1182e-01, time/batch = 17.9922s	
18965/25300 (epoch 37.480), train_loss = 0.69832248, grad/param norm = 2.1203e-01, time/batch = 16.1363s	
18966/25300 (epoch 37.482), train_loss = 0.77214322, grad/param norm = 2.6732e-01, time/batch = 15.8314s	
18967/25300 (epoch 37.484), train_loss = 0.79181388, grad/param norm = 2.4472e-01, time/batch = 15.6397s	
18968/25300 (epoch 37.486), train_loss = 0.73342289, grad/param norm = 2.2140e-01, time/batch = 15.7828s	
18969/25300 (epoch 37.488), train_loss = 0.90366242, grad/param norm = 2.8930e-01, time/batch = 15.8021s	
18970/25300 (epoch 37.490), train_loss = 0.76667028, grad/param norm = 2.2178e-01, time/batch = 15.6366s	
18971/25300 (epoch 37.492), train_loss = 0.85259580, grad/param norm = 2.1478e-01, time/batch = 16.3982s	
18972/25300 (epoch 37.494), train_loss = 0.73631699, grad/param norm = 2.0426e-01, time/batch = 16.0608s	
18973/25300 (epoch 37.496), train_loss = 0.79416876, grad/param norm = 2.4206e-01, time/batch = 15.4633s	
18974/25300 (epoch 37.498), train_loss = 0.72292116, grad/param norm = 1.9568e-01, time/batch = 16.0611s	
18975/25300 (epoch 37.500), train_loss = 0.86052412, grad/param norm = 2.3197e-01, time/batch = 16.0645s	
18976/25300 (epoch 37.502), train_loss = 0.80768895, grad/param norm = 2.5950e-01, time/batch = 16.2123s	
18977/25300 (epoch 37.504), train_loss = 0.70567927, grad/param norm = 2.0736e-01, time/batch = 16.1191s	
18978/25300 (epoch 37.506), train_loss = 0.63750996, grad/param norm = 2.3772e-01, time/batch = 16.4703s	
18979/25300 (epoch 37.508), train_loss = 0.73687854, grad/param norm = 2.4730e-01, time/batch = 15.7449s	
18980/25300 (epoch 37.510), train_loss = 0.71546615, grad/param norm = 2.4802e-01, time/batch = 17.7060s	
18981/25300 (epoch 37.512), train_loss = 0.57700823, grad/param norm = 2.0041e-01, time/batch = 17.8131s	
18982/25300 (epoch 37.514), train_loss = 0.71907831, grad/param norm = 2.0807e-01, time/batch = 15.9659s	
18983/25300 (epoch 37.516), train_loss = 0.81355734, grad/param norm = 2.4310e-01, time/batch = 17.5541s	
18984/25300 (epoch 37.518), train_loss = 0.82999891, grad/param norm = 2.4387e-01, time/batch = 16.3792s	
18985/25300 (epoch 37.520), train_loss = 0.60591993, grad/param norm = 1.7562e-01, time/batch = 16.1294s	
18986/25300 (epoch 37.522), train_loss = 0.68225301, grad/param norm = 2.1810e-01, time/batch = 18.3719s	
18987/25300 (epoch 37.524), train_loss = 0.67650839, grad/param norm = 2.1223e-01, time/batch = 17.6138s	
18988/25300 (epoch 37.526), train_loss = 0.85244985, grad/param norm = 2.2325e-01, time/batch = 17.9413s	
18989/25300 (epoch 37.528), train_loss = 0.86825547, grad/param norm = 2.5938e-01, time/batch = 17.5613s	
18990/25300 (epoch 37.530), train_loss = 0.79187501, grad/param norm = 2.2016e-01, time/batch = 16.1398s	
18991/25300 (epoch 37.532), train_loss = 0.70721008, grad/param norm = 2.0380e-01, time/batch = 15.7825s	
18992/25300 (epoch 37.534), train_loss = 0.69466029, grad/param norm = 2.0237e-01, time/batch = 16.5664s	
18993/25300 (epoch 37.536), train_loss = 0.58699302, grad/param norm = 2.3584e-01, time/batch = 18.2101s	
18994/25300 (epoch 37.538), train_loss = 0.64550089, grad/param norm = 1.9794e-01, time/batch = 16.7979s	
18995/25300 (epoch 37.540), train_loss = 0.64095342, grad/param norm = 2.0652e-01, time/batch = 15.6905s	
18996/25300 (epoch 37.542), train_loss = 0.61687725, grad/param norm = 1.9174e-01, time/batch = 15.7058s	
18997/25300 (epoch 37.543), train_loss = 0.60527039, grad/param norm = 1.8868e-01, time/batch = 16.3832s	
18998/25300 (epoch 37.545), train_loss = 0.91872640, grad/param norm = 2.8632e-01, time/batch = 15.2612s	
18999/25300 (epoch 37.547), train_loss = 0.80620207, grad/param norm = 2.3684e-01, time/batch = 15.4401s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch37.55_1.7679.t7	
19000/25300 (epoch 37.549), train_loss = 0.92443323, grad/param norm = 2.7509e-01, time/batch = 15.8864s	
19001/25300 (epoch 37.551), train_loss = 1.45278578, grad/param norm = 3.4312e-01, time/batch = 19.1291s	
19002/25300 (epoch 37.553), train_loss = 0.72233278, grad/param norm = 2.4830e-01, time/batch = 17.2198s	
19003/25300 (epoch 37.555), train_loss = 0.79350431, grad/param norm = 2.6196e-01, time/batch = 16.4016s	
19004/25300 (epoch 37.557), train_loss = 0.82556010, grad/param norm = 2.4699e-01, time/batch = 15.6935s	
19005/25300 (epoch 37.559), train_loss = 0.88444866, grad/param norm = 2.8998e-01, time/batch = 15.7815s	
19006/25300 (epoch 37.561), train_loss = 0.87593957, grad/param norm = 2.4266e-01, time/batch = 15.7625s	
19007/25300 (epoch 37.563), train_loss = 0.84879702, grad/param norm = 2.5031e-01, time/batch = 15.6297s	
19008/25300 (epoch 37.565), train_loss = 0.64526943, grad/param norm = 2.1338e-01, time/batch = 15.6347s	
19009/25300 (epoch 37.567), train_loss = 0.58907697, grad/param norm = 2.0637e-01, time/batch = 15.8836s	
19010/25300 (epoch 37.569), train_loss = 0.74764613, grad/param norm = 2.2594e-01, time/batch = 15.5290s	
19011/25300 (epoch 37.571), train_loss = 0.82019230, grad/param norm = 2.5197e-01, time/batch = 15.8916s	
19012/25300 (epoch 37.573), train_loss = 0.74333339, grad/param norm = 2.2549e-01, time/batch = 15.3693s	
19013/25300 (epoch 37.575), train_loss = 0.80102468, grad/param norm = 2.5161e-01, time/batch = 15.2324s	
19014/25300 (epoch 37.577), train_loss = 0.69713268, grad/param norm = 2.3269e-01, time/batch = 15.7045s	
19015/25300 (epoch 37.579), train_loss = 0.86216715, grad/param norm = 2.4311e-01, time/batch = 15.6355s	
19016/25300 (epoch 37.581), train_loss = 0.81749364, grad/param norm = 2.4401e-01, time/batch = 15.7097s	
19017/25300 (epoch 37.583), train_loss = 0.62043773, grad/param norm = 2.5042e-01, time/batch = 15.7869s	
19018/25300 (epoch 37.585), train_loss = 0.62272698, grad/param norm = 2.3501e-01, time/batch = 15.7052s	
19019/25300 (epoch 37.587), train_loss = 0.74006464, grad/param norm = 2.2254e-01, time/batch = 16.2281s	
19020/25300 (epoch 37.589), train_loss = 0.66650410, grad/param norm = 1.8030e-01, time/batch = 15.6377s	
19021/25300 (epoch 37.591), train_loss = 0.61743490, grad/param norm = 2.3779e-01, time/batch = 16.6211s	
19022/25300 (epoch 37.593), train_loss = 0.80381090, grad/param norm = 2.4451e-01, time/batch = 16.8052s	
19023/25300 (epoch 37.595), train_loss = 0.75129683, grad/param norm = 2.1973e-01, time/batch = 16.0351s	
19024/25300 (epoch 37.597), train_loss = 0.66392951, grad/param norm = 1.9714e-01, time/batch = 17.3880s	
19025/25300 (epoch 37.599), train_loss = 0.86057698, grad/param norm = 2.4832e-01, time/batch = 15.5543s	
19026/25300 (epoch 37.601), train_loss = 0.74880031, grad/param norm = 2.3396e-01, time/batch = 15.6489s	
19027/25300 (epoch 37.603), train_loss = 0.74210249, grad/param norm = 2.1680e-01, time/batch = 16.5761s	
19028/25300 (epoch 37.605), train_loss = 0.75106194, grad/param norm = 2.7828e-01, time/batch = 16.8783s	
19029/25300 (epoch 37.607), train_loss = 0.53976322, grad/param norm = 1.7193e-01, time/batch = 15.9757s	
19030/25300 (epoch 37.609), train_loss = 0.67465705, grad/param norm = 2.2157e-01, time/batch = 16.0524s	
19031/25300 (epoch 37.611), train_loss = 0.78035529, grad/param norm = 2.6173e-01, time/batch = 15.7136s	
19032/25300 (epoch 37.613), train_loss = 0.66411521, grad/param norm = 2.1159e-01, time/batch = 15.4751s	
19033/25300 (epoch 37.615), train_loss = 0.70098302, grad/param norm = 2.3474e-01, time/batch = 16.2073s	
19034/25300 (epoch 37.617), train_loss = 0.74252620, grad/param norm = 2.7396e-01, time/batch = 15.7092s	
19035/25300 (epoch 37.619), train_loss = 0.77991327, grad/param norm = 2.3620e-01, time/batch = 15.6497s	
19036/25300 (epoch 37.621), train_loss = 0.81603469, grad/param norm = 2.3344e-01, time/batch = 15.5305s	
19037/25300 (epoch 37.623), train_loss = 0.68335195, grad/param norm = 2.3949e-01, time/batch = 16.1397s	
19038/25300 (epoch 37.625), train_loss = 0.62791499, grad/param norm = 2.1308e-01, time/batch = 17.4743s	
19039/25300 (epoch 37.626), train_loss = 0.71025426, grad/param norm = 2.0235e-01, time/batch = 16.8892s	
19040/25300 (epoch 37.628), train_loss = 0.83731892, grad/param norm = 2.6203e-01, time/batch = 16.6329s	
19041/25300 (epoch 37.630), train_loss = 0.79085752, grad/param norm = 2.4121e-01, time/batch = 15.9044s	
19042/25300 (epoch 37.632), train_loss = 0.74726178, grad/param norm = 2.5781e-01, time/batch = 16.7910s	
19043/25300 (epoch 37.634), train_loss = 0.86436895, grad/param norm = 3.4490e-01, time/batch = 16.0511s	
19044/25300 (epoch 37.636), train_loss = 0.64043545, grad/param norm = 2.2162e-01, time/batch = 15.7142s	
19045/25300 (epoch 37.638), train_loss = 0.74622461, grad/param norm = 2.7004e-01, time/batch = 16.7247s	
19046/25300 (epoch 37.640), train_loss = 0.91864889, grad/param norm = 2.7620e-01, time/batch = 18.4605s	
19047/25300 (epoch 37.642), train_loss = 0.78755378, grad/param norm = 2.4220e-01, time/batch = 16.0508s	
19048/25300 (epoch 37.644), train_loss = 0.74248298, grad/param norm = 2.3123e-01, time/batch = 17.6206s	
19049/25300 (epoch 37.646), train_loss = 0.67679658, grad/param norm = 2.3366e-01, time/batch = 15.9792s	
19050/25300 (epoch 37.648), train_loss = 0.84175252, grad/param norm = 2.2009e-01, time/batch = 15.6384s	
19051/25300 (epoch 37.650), train_loss = 0.76383201, grad/param norm = 2.6191e-01, time/batch = 16.7094s	
19052/25300 (epoch 37.652), train_loss = 0.77739818, grad/param norm = 2.5952e-01, time/batch = 16.3901s	
19053/25300 (epoch 37.654), train_loss = 0.88501451, grad/param norm = 2.6088e-01, time/batch = 16.0650s	
19054/25300 (epoch 37.656), train_loss = 0.80279536, grad/param norm = 2.4870e-01, time/batch = 15.6348s	
19055/25300 (epoch 37.658), train_loss = 0.59494162, grad/param norm = 1.9846e-01, time/batch = 16.9763s	
19056/25300 (epoch 37.660), train_loss = 0.58978899, grad/param norm = 1.9955e-01, time/batch = 16.0563s	
19057/25300 (epoch 37.662), train_loss = 0.60829762, grad/param norm = 1.8549e-01, time/batch = 16.4866s	
19058/25300 (epoch 37.664), train_loss = 0.58858267, grad/param norm = 2.3024e-01, time/batch = 15.7982s	
19059/25300 (epoch 37.666), train_loss = 0.64283357, grad/param norm = 2.3423e-01, time/batch = 15.9983s	
19060/25300 (epoch 37.668), train_loss = 0.74513176, grad/param norm = 3.0157e-01, time/batch = 16.5746s	
19061/25300 (epoch 37.670), train_loss = 0.69103822, grad/param norm = 2.8854e-01, time/batch = 16.6347s	
19062/25300 (epoch 37.672), train_loss = 0.67959210, grad/param norm = 2.0650e-01, time/batch = 16.4791s	
19063/25300 (epoch 37.674), train_loss = 0.67003404, grad/param norm = 1.9455e-01, time/batch = 16.6894s	
19064/25300 (epoch 37.676), train_loss = 0.66992291, grad/param norm = 2.4300e-01, time/batch = 19.4652s	
19065/25300 (epoch 37.678), train_loss = 0.67480460, grad/param norm = 2.2756e-01, time/batch = 16.4693s	
19066/25300 (epoch 37.680), train_loss = 0.59906223, grad/param norm = 1.7898e-01, time/batch = 18.3127s	
19067/25300 (epoch 37.682), train_loss = 0.50749243, grad/param norm = 1.6237e-01, time/batch = 17.7117s	
19068/25300 (epoch 37.684), train_loss = 0.65652082, grad/param norm = 1.8127e-01, time/batch = 16.2369s	
19069/25300 (epoch 37.686), train_loss = 0.61874633, grad/param norm = 2.2487e-01, time/batch = 15.3921s	
19070/25300 (epoch 37.688), train_loss = 0.69858705, grad/param norm = 2.4006e-01, time/batch = 18.1356s	
19071/25300 (epoch 37.690), train_loss = 0.62002237, grad/param norm = 2.0409e-01, time/batch = 17.0675s	
19072/25300 (epoch 37.692), train_loss = 0.67345641, grad/param norm = 2.0201e-01, time/batch = 15.7968s	
19073/25300 (epoch 37.694), train_loss = 0.66529981, grad/param norm = 2.3959e-01, time/batch = 16.3974s	
19074/25300 (epoch 37.696), train_loss = 0.72149296, grad/param norm = 2.2761e-01, time/batch = 17.3980s	
19075/25300 (epoch 37.698), train_loss = 0.80232642, grad/param norm = 2.4135e-01, time/batch = 16.3192s	
19076/25300 (epoch 37.700), train_loss = 0.58547819, grad/param norm = 1.9709e-01, time/batch = 15.4877s	
19077/25300 (epoch 37.702), train_loss = 0.79477726, grad/param norm = 2.3890e-01, time/batch = 16.1535s	
19078/25300 (epoch 37.704), train_loss = 0.57272519, grad/param norm = 1.8061e-01, time/batch = 16.1554s	
19079/25300 (epoch 37.706), train_loss = 0.71725093, grad/param norm = 2.3296e-01, time/batch = 15.3812s	
19080/25300 (epoch 37.708), train_loss = 0.60929894, grad/param norm = 1.8861e-01, time/batch = 16.6450s	
19081/25300 (epoch 37.709), train_loss = 0.85469622, grad/param norm = 2.6049e-01, time/batch = 16.0601s	
19082/25300 (epoch 37.711), train_loss = 0.88672715, grad/param norm = 2.6304e-01, time/batch = 15.7113s	
19083/25300 (epoch 37.713), train_loss = 0.74720781, grad/param norm = 2.0005e-01, time/batch = 15.8997s	
19084/25300 (epoch 37.715), train_loss = 0.74871318, grad/param norm = 2.1184e-01, time/batch = 15.7266s	
19085/25300 (epoch 37.717), train_loss = 0.63827485, grad/param norm = 2.1180e-01, time/batch = 15.2298s	
19086/25300 (epoch 37.719), train_loss = 0.70250570, grad/param norm = 2.1333e-01, time/batch = 16.1609s	
19087/25300 (epoch 37.721), train_loss = 0.76029473, grad/param norm = 2.5931e-01, time/batch = 15.5701s	
19088/25300 (epoch 37.723), train_loss = 0.70691380, grad/param norm = 2.1168e-01, time/batch = 18.3986s	
19089/25300 (epoch 37.725), train_loss = 0.73194734, grad/param norm = 2.1436e-01, time/batch = 18.2933s	
19090/25300 (epoch 37.727), train_loss = 0.73078412, grad/param norm = 2.4310e-01, time/batch = 16.3978s	
19091/25300 (epoch 37.729), train_loss = 0.69381008, grad/param norm = 1.9996e-01, time/batch = 16.0808s	
19092/25300 (epoch 37.731), train_loss = 0.85204412, grad/param norm = 2.2057e-01, time/batch = 16.2398s	
19093/25300 (epoch 37.733), train_loss = 0.71649588, grad/param norm = 1.9257e-01, time/batch = 16.3139s	
19094/25300 (epoch 37.735), train_loss = 0.91563699, grad/param norm = 2.3102e-01, time/batch = 15.4599s	
19095/25300 (epoch 37.737), train_loss = 0.58987937, grad/param norm = 1.9944e-01, time/batch = 16.3020s	
19096/25300 (epoch 37.739), train_loss = 0.83854557, grad/param norm = 2.2506e-01, time/batch = 15.3328s	
19097/25300 (epoch 37.741), train_loss = 0.76486749, grad/param norm = 2.5415e-01, time/batch = 15.2994s	
19098/25300 (epoch 37.743), train_loss = 0.73613101, grad/param norm = 2.1962e-01, time/batch = 15.4865s	
19099/25300 (epoch 37.745), train_loss = 0.69886922, grad/param norm = 2.2461e-01, time/batch = 16.7980s	
19100/25300 (epoch 37.747), train_loss = 0.62003447, grad/param norm = 2.0574e-01, time/batch = 15.5574s	
19101/25300 (epoch 37.749), train_loss = 0.71031632, grad/param norm = 2.1636e-01, time/batch = 16.7196s	
19102/25300 (epoch 37.751), train_loss = 0.76745939, grad/param norm = 2.2052e-01, time/batch = 15.4426s	
19103/25300 (epoch 37.753), train_loss = 0.60305420, grad/param norm = 1.8685e-01, time/batch = 15.5167s	
19104/25300 (epoch 37.755), train_loss = 0.83195927, grad/param norm = 2.5887e-01, time/batch = 16.3897s	
19105/25300 (epoch 37.757), train_loss = 0.66053372, grad/param norm = 2.2247e-01, time/batch = 15.6361s	
19106/25300 (epoch 37.759), train_loss = 0.66556301, grad/param norm = 2.0231e-01, time/batch = 17.2027s	
19107/25300 (epoch 37.761), train_loss = 0.86418750, grad/param norm = 2.5833e-01, time/batch = 16.8929s	
19108/25300 (epoch 37.763), train_loss = 0.70469871, grad/param norm = 2.2053e-01, time/batch = 17.3820s	
19109/25300 (epoch 37.765), train_loss = 0.70542428, grad/param norm = 2.5974e-01, time/batch = 16.2180s	
19110/25300 (epoch 37.767), train_loss = 0.71714974, grad/param norm = 2.0393e-01, time/batch = 16.4034s	
19111/25300 (epoch 37.769), train_loss = 0.72638243, grad/param norm = 2.6885e-01, time/batch = 16.0603s	
19112/25300 (epoch 37.771), train_loss = 0.81931977, grad/param norm = 2.6276e-01, time/batch = 19.9654s	
19113/25300 (epoch 37.773), train_loss = 0.81173516, grad/param norm = 2.6155e-01, time/batch = 24.7796s	
19114/25300 (epoch 37.775), train_loss = 0.75501955, grad/param norm = 2.2865e-01, time/batch = 15.3741s	
19115/25300 (epoch 37.777), train_loss = 0.67964442, grad/param norm = 2.1953e-01, time/batch = 16.3071s	
19116/25300 (epoch 37.779), train_loss = 0.81344063, grad/param norm = 2.1454e-01, time/batch = 16.2386s	
19117/25300 (epoch 37.781), train_loss = 0.79740239, grad/param norm = 2.5678e-01, time/batch = 17.2289s	
19118/25300 (epoch 37.783), train_loss = 0.86693768, grad/param norm = 2.5232e-01, time/batch = 17.4649s	
19119/25300 (epoch 37.785), train_loss = 0.81365600, grad/param norm = 2.4193e-01, time/batch = 16.2079s	
19120/25300 (epoch 37.787), train_loss = 0.77677054, grad/param norm = 2.3154e-01, time/batch = 16.8188s	
19121/25300 (epoch 37.789), train_loss = 0.86874051, grad/param norm = 2.6241e-01, time/batch = 15.5330s	
19122/25300 (epoch 37.791), train_loss = 0.79450086, grad/param norm = 2.2240e-01, time/batch = 16.4450s	
19123/25300 (epoch 37.792), train_loss = 0.84741872, grad/param norm = 2.3760e-01, time/batch = 15.9704s	
19124/25300 (epoch 37.794), train_loss = 0.73102739, grad/param norm = 2.4788e-01, time/batch = 19.3692s	
19125/25300 (epoch 37.796), train_loss = 0.69817448, grad/param norm = 2.6133e-01, time/batch = 17.4713s	
19126/25300 (epoch 37.798), train_loss = 0.84068098, grad/param norm = 2.9035e-01, time/batch = 16.1268s	
19127/25300 (epoch 37.800), train_loss = 0.70725565, grad/param norm = 2.0940e-01, time/batch = 17.0617s	
19128/25300 (epoch 37.802), train_loss = 0.59912557, grad/param norm = 1.9494e-01, time/batch = 15.9790s	
19129/25300 (epoch 37.804), train_loss = 0.74123514, grad/param norm = 1.9480e-01, time/batch = 18.2123s	
19130/25300 (epoch 37.806), train_loss = 0.81202739, grad/param norm = 2.6568e-01, time/batch = 15.5769s	
19131/25300 (epoch 37.808), train_loss = 0.84626995, grad/param norm = 2.2618e-01, time/batch = 15.8981s	
19132/25300 (epoch 37.810), train_loss = 0.73494431, grad/param norm = 2.5607e-01, time/batch = 16.2346s	
19133/25300 (epoch 37.812), train_loss = 0.85235272, grad/param norm = 2.3226e-01, time/batch = 16.9521s	
19134/25300 (epoch 37.814), train_loss = 0.86122484, grad/param norm = 2.6240e-01, time/batch = 15.9826s	
19135/25300 (epoch 37.816), train_loss = 0.93524419, grad/param norm = 2.3206e-01, time/batch = 15.6254s	
19136/25300 (epoch 37.818), train_loss = 0.82664002, grad/param norm = 2.1020e-01, time/batch = 15.8091s	
19137/25300 (epoch 37.820), train_loss = 0.83684804, grad/param norm = 2.4762e-01, time/batch = 15.6145s	
19138/25300 (epoch 37.822), train_loss = 0.70082813, grad/param norm = 2.4802e-01, time/batch = 22.8143s	
19139/25300 (epoch 37.824), train_loss = 0.84273066, grad/param norm = 2.5672e-01, time/batch = 16.3233s	
19140/25300 (epoch 37.826), train_loss = 0.68747425, grad/param norm = 1.9962e-01, time/batch = 16.5466s	
19141/25300 (epoch 37.828), train_loss = 0.70256632, grad/param norm = 2.5308e-01, time/batch = 16.5467s	
19142/25300 (epoch 37.830), train_loss = 0.79132469, grad/param norm = 3.4115e-01, time/batch = 17.1568s	
19143/25300 (epoch 37.832), train_loss = 0.88528096, grad/param norm = 3.0890e-01, time/batch = 17.3974s	
19144/25300 (epoch 37.834), train_loss = 0.71790500, grad/param norm = 2.3456e-01, time/batch = 15.3889s	
19145/25300 (epoch 37.836), train_loss = 0.73372383, grad/param norm = 2.2494e-01, time/batch = 16.3201s	
19146/25300 (epoch 37.838), train_loss = 0.71158425, grad/param norm = 2.0571e-01, time/batch = 16.9646s	
19147/25300 (epoch 37.840), train_loss = 0.81438862, grad/param norm = 2.4643e-01, time/batch = 16.7080s	
19148/25300 (epoch 37.842), train_loss = 0.76671733, grad/param norm = 2.9426e-01, time/batch = 15.3051s	
19149/25300 (epoch 37.844), train_loss = 0.83563556, grad/param norm = 2.0740e-01, time/batch = 15.7186s	
19150/25300 (epoch 37.846), train_loss = 0.81404236, grad/param norm = 1.9666e-01, time/batch = 15.9852s	
19151/25300 (epoch 37.848), train_loss = 0.81763042, grad/param norm = 2.7036e-01, time/batch = 16.0402s	
19152/25300 (epoch 37.850), train_loss = 0.78900544, grad/param norm = 2.2824e-01, time/batch = 17.3042s	
19153/25300 (epoch 37.852), train_loss = 0.84479843, grad/param norm = 2.2219e-01, time/batch = 15.7277s	
19154/25300 (epoch 37.854), train_loss = 0.85616085, grad/param norm = 2.2187e-01, time/batch = 15.8197s	
19155/25300 (epoch 37.856), train_loss = 0.70752770, grad/param norm = 2.2342e-01, time/batch = 15.7135s	
19156/25300 (epoch 37.858), train_loss = 0.73013156, grad/param norm = 2.1939e-01, time/batch = 15.9591s	
19157/25300 (epoch 37.860), train_loss = 0.64331003, grad/param norm = 2.1779e-01, time/batch = 16.4025s	
19158/25300 (epoch 37.862), train_loss = 0.75193139, grad/param norm = 2.1709e-01, time/batch = 16.0532s	
19159/25300 (epoch 37.864), train_loss = 0.87049227, grad/param norm = 2.4587e-01, time/batch = 16.1417s	
19160/25300 (epoch 37.866), train_loss = 0.71538034, grad/param norm = 2.4557e-01, time/batch = 17.1440s	
19161/25300 (epoch 37.868), train_loss = 0.85532776, grad/param norm = 2.3542e-01, time/batch = 15.8159s	
19162/25300 (epoch 37.870), train_loss = 0.81695749, grad/param norm = 2.0038e-01, time/batch = 15.8828s	
19163/25300 (epoch 37.872), train_loss = 0.77307459, grad/param norm = 2.6034e-01, time/batch = 16.3085s	
19164/25300 (epoch 37.874), train_loss = 0.80727692, grad/param norm = 2.5789e-01, time/batch = 15.5683s	
19165/25300 (epoch 37.875), train_loss = 0.73230051, grad/param norm = 2.2780e-01, time/batch = 15.8029s	
19166/25300 (epoch 37.877), train_loss = 0.72080419, grad/param norm = 2.0443e-01, time/batch = 15.6928s	
19167/25300 (epoch 37.879), train_loss = 0.66908861, grad/param norm = 2.1379e-01, time/batch = 15.6431s	
19168/25300 (epoch 37.881), train_loss = 0.97634768, grad/param norm = 2.8207e-01, time/batch = 16.1586s	
19169/25300 (epoch 37.883), train_loss = 0.95136321, grad/param norm = 2.4652e-01, time/batch = 16.4626s	
19170/25300 (epoch 37.885), train_loss = 0.81284333, grad/param norm = 2.4195e-01, time/batch = 15.1963s	
19171/25300 (epoch 37.887), train_loss = 0.82620454, grad/param norm = 2.2736e-01, time/batch = 15.3474s	
19172/25300 (epoch 37.889), train_loss = 0.90384635, grad/param norm = 2.5379e-01, time/batch = 15.1914s	
19173/25300 (epoch 37.891), train_loss = 0.80728097, grad/param norm = 2.8431e-01, time/batch = 15.1756s	
19174/25300 (epoch 37.893), train_loss = 0.79895926, grad/param norm = 2.8480e-01, time/batch = 15.7458s	
19175/25300 (epoch 37.895), train_loss = 0.59246661, grad/param norm = 2.0417e-01, time/batch = 15.2984s	
19176/25300 (epoch 37.897), train_loss = 0.66847345, grad/param norm = 2.0695e-01, time/batch = 17.2907s	
19177/25300 (epoch 37.899), train_loss = 0.77174558, grad/param norm = 2.3992e-01, time/batch = 16.6234s	
19178/25300 (epoch 37.901), train_loss = 0.83044150, grad/param norm = 2.3503e-01, time/batch = 16.3841s	
19179/25300 (epoch 37.903), train_loss = 0.62435943, grad/param norm = 2.0737e-01, time/batch = 19.2850s	
19180/25300 (epoch 37.905), train_loss = 0.70573814, grad/param norm = 2.3234e-01, time/batch = 17.3801s	
19181/25300 (epoch 37.907), train_loss = 0.70855919, grad/param norm = 2.3337e-01, time/batch = 16.5909s	
19182/25300 (epoch 37.909), train_loss = 0.80266348, grad/param norm = 2.1912e-01, time/batch = 19.2078s	
19183/25300 (epoch 37.911), train_loss = 0.88320485, grad/param norm = 3.0020e-01, time/batch = 16.4727s	
19184/25300 (epoch 37.913), train_loss = 0.94634320, grad/param norm = 2.5881e-01, time/batch = 16.7926s	
19185/25300 (epoch 37.915), train_loss = 0.70629420, grad/param norm = 2.2015e-01, time/batch = 16.0540s	
19186/25300 (epoch 37.917), train_loss = 0.90531444, grad/param norm = 2.3603e-01, time/batch = 15.8140s	
19187/25300 (epoch 37.919), train_loss = 0.89822494, grad/param norm = 2.8622e-01, time/batch = 16.6493s	
19188/25300 (epoch 37.921), train_loss = 0.73776613, grad/param norm = 2.4208e-01, time/batch = 16.0365s	
19189/25300 (epoch 37.923), train_loss = 0.84024241, grad/param norm = 2.1632e-01, time/batch = 17.4484s	
19190/25300 (epoch 37.925), train_loss = 0.76593882, grad/param norm = 2.3576e-01, time/batch = 16.4870s	
19191/25300 (epoch 37.927), train_loss = 0.76029259, grad/param norm = 2.4192e-01, time/batch = 16.3857s	
19192/25300 (epoch 37.929), train_loss = 0.81945039, grad/param norm = 2.3876e-01, time/batch = 15.7073s	
19193/25300 (epoch 37.931), train_loss = 0.82277691, grad/param norm = 2.5387e-01, time/batch = 15.9728s	
19194/25300 (epoch 37.933), train_loss = 0.80490612, grad/param norm = 2.3500e-01, time/batch = 15.6186s	
19195/25300 (epoch 37.935), train_loss = 0.82413132, grad/param norm = 2.2937e-01, time/batch = 15.5244s	
19196/25300 (epoch 37.937), train_loss = 0.62668982, grad/param norm = 1.9433e-01, time/batch = 16.3904s	
19197/25300 (epoch 37.939), train_loss = 0.76732187, grad/param norm = 2.4211e-01, time/batch = 16.3893s	
19198/25300 (epoch 37.941), train_loss = 0.72580834, grad/param norm = 2.9116e-01, time/batch = 15.5547s	
19199/25300 (epoch 37.943), train_loss = 0.79814333, grad/param norm = 2.3294e-01, time/batch = 15.8895s	
19200/25300 (epoch 37.945), train_loss = 0.79923993, grad/param norm = 2.6081e-01, time/batch = 15.7288s	
19201/25300 (epoch 37.947), train_loss = 0.71193245, grad/param norm = 2.2628e-01, time/batch = 15.9816s	
19202/25300 (epoch 37.949), train_loss = 0.79577585, grad/param norm = 2.2371e-01, time/batch = 16.4480s	
19203/25300 (epoch 37.951), train_loss = 0.76522408, grad/param norm = 2.0754e-01, time/batch = 15.8650s	
19204/25300 (epoch 37.953), train_loss = 0.74568585, grad/param norm = 2.5722e-01, time/batch = 15.9744s	
19205/25300 (epoch 37.955), train_loss = 0.97104686, grad/param norm = 3.0926e-01, time/batch = 15.7172s	
19206/25300 (epoch 37.957), train_loss = 0.86665809, grad/param norm = 2.7749e-01, time/batch = 15.6330s	
19207/25300 (epoch 37.958), train_loss = 0.81415428, grad/param norm = 2.6607e-01, time/batch = 15.2779s	
19208/25300 (epoch 37.960), train_loss = 0.94148610, grad/param norm = 2.9059e-01, time/batch = 16.0426s	
19209/25300 (epoch 37.962), train_loss = 0.90211189, grad/param norm = 2.3430e-01, time/batch = 15.5533s	
19210/25300 (epoch 37.964), train_loss = 0.78792792, grad/param norm = 2.4227e-01, time/batch = 15.6168s	
19211/25300 (epoch 37.966), train_loss = 0.68310801, grad/param norm = 2.4474e-01, time/batch = 16.2129s	
19212/25300 (epoch 37.968), train_loss = 0.67207400, grad/param norm = 2.1481e-01, time/batch = 16.1321s	
19213/25300 (epoch 37.970), train_loss = 0.75092887, grad/param norm = 2.5007e-01, time/batch = 15.5314s	
19214/25300 (epoch 37.972), train_loss = 0.76559029, grad/param norm = 2.1779e-01, time/batch = 15.4846s	
19215/25300 (epoch 37.974), train_loss = 0.86874210, grad/param norm = 2.8823e-01, time/batch = 15.3966s	
19216/25300 (epoch 37.976), train_loss = 0.80119091, grad/param norm = 2.3331e-01, time/batch = 16.0688s	
19217/25300 (epoch 37.978), train_loss = 0.75160666, grad/param norm = 2.4980e-01, time/batch = 15.4635s	
19218/25300 (epoch 37.980), train_loss = 0.77404054, grad/param norm = 2.4766e-01, time/batch = 15.8102s	
19219/25300 (epoch 37.982), train_loss = 0.74016842, grad/param norm = 2.3368e-01, time/batch = 16.0672s	
19220/25300 (epoch 37.984), train_loss = 0.76864908, grad/param norm = 2.3485e-01, time/batch = 15.7315s	
19221/25300 (epoch 37.986), train_loss = 0.83087505, grad/param norm = 2.4727e-01, time/batch = 16.0599s	
19222/25300 (epoch 37.988), train_loss = 0.80822101, grad/param norm = 2.6763e-01, time/batch = 15.5607s	
19223/25300 (epoch 37.990), train_loss = 0.78814097, grad/param norm = 2.2403e-01, time/batch = 15.9086s	
19224/25300 (epoch 37.992), train_loss = 0.66972915, grad/param norm = 1.9713e-01, time/batch = 16.4934s	
19225/25300 (epoch 37.994), train_loss = 0.82474036, grad/param norm = 3.0443e-01, time/batch = 16.1244s	
19226/25300 (epoch 37.996), train_loss = 0.91860802, grad/param norm = 2.8522e-01, time/batch = 16.1590s	
19227/25300 (epoch 37.998), train_loss = 0.85072049, grad/param norm = 2.6758e-01, time/batch = 16.2309s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
19228/25300 (epoch 38.000), train_loss = 0.84425689, grad/param norm = 2.7535e-01, time/batch = 18.8810s	
19229/25300 (epoch 38.002), train_loss = 0.79129364, grad/param norm = 2.1407e-01, time/batch = 15.4890s	
19230/25300 (epoch 38.004), train_loss = 0.67607123, grad/param norm = 2.2842e-01, time/batch = 15.3133s	
19231/25300 (epoch 38.006), train_loss = 0.94038036, grad/param norm = 2.6031e-01, time/batch = 17.3195s	
19232/25300 (epoch 38.008), train_loss = 0.79732217, grad/param norm = 2.2733e-01, time/batch = 16.0570s	
19233/25300 (epoch 38.010), train_loss = 0.83977716, grad/param norm = 2.2729e-01, time/batch = 15.4512s	
19234/25300 (epoch 38.012), train_loss = 0.74069901, grad/param norm = 2.1128e-01, time/batch = 15.5420s	
19235/25300 (epoch 38.014), train_loss = 0.89478896, grad/param norm = 2.5107e-01, time/batch = 17.5513s	
19236/25300 (epoch 38.016), train_loss = 0.76378129, grad/param norm = 2.2955e-01, time/batch = 16.2031s	
19237/25300 (epoch 38.018), train_loss = 0.70485854, grad/param norm = 2.2418e-01, time/batch = 16.4666s	
19238/25300 (epoch 38.020), train_loss = 0.81668742, grad/param norm = 2.5243e-01, time/batch = 17.5414s	
19239/25300 (epoch 38.022), train_loss = 0.79992808, grad/param norm = 2.8742e-01, time/batch = 18.7900s	
19240/25300 (epoch 38.024), train_loss = 0.61948921, grad/param norm = 1.9257e-01, time/batch = 16.7163s	
19241/25300 (epoch 38.026), train_loss = 0.73933591, grad/param norm = 2.2413e-01, time/batch = 15.7362s	
19242/25300 (epoch 38.028), train_loss = 0.73506137, grad/param norm = 2.1329e-01, time/batch = 18.2211s	
19243/25300 (epoch 38.030), train_loss = 0.88413617, grad/param norm = 2.1114e-01, time/batch = 16.5591s	
19244/25300 (epoch 38.032), train_loss = 0.73461982, grad/param norm = 2.1858e-01, time/batch = 17.2288s	
19245/25300 (epoch 38.034), train_loss = 0.67512489, grad/param norm = 2.0361e-01, time/batch = 16.0648s	
19246/25300 (epoch 38.036), train_loss = 0.65547409, grad/param norm = 2.2649e-01, time/batch = 19.2921s	
19247/25300 (epoch 38.038), train_loss = 0.60014935, grad/param norm = 1.9828e-01, time/batch = 15.5565s	
19248/25300 (epoch 38.040), train_loss = 0.77361180, grad/param norm = 2.2671e-01, time/batch = 16.6470s	
19249/25300 (epoch 38.042), train_loss = 0.75216878, grad/param norm = 1.9304e-01, time/batch = 15.5469s	
19250/25300 (epoch 38.043), train_loss = 0.67057600, grad/param norm = 1.9244e-01, time/batch = 16.1203s	
19251/25300 (epoch 38.045), train_loss = 0.65065029, grad/param norm = 1.9585e-01, time/batch = 17.5443s	
19252/25300 (epoch 38.047), train_loss = 0.77278070, grad/param norm = 2.1402e-01, time/batch = 16.0522s	
19253/25300 (epoch 38.049), train_loss = 0.77581865, grad/param norm = 2.7150e-01, time/batch = 15.8777s	
19254/25300 (epoch 38.051), train_loss = 0.89198512, grad/param norm = 2.2484e-01, time/batch = 16.7927s	
19255/25300 (epoch 38.053), train_loss = 0.60764509, grad/param norm = 1.8899e-01, time/batch = 17.7141s	
19256/25300 (epoch 38.055), train_loss = 0.62925753, grad/param norm = 2.0368e-01, time/batch = 17.3847s	
19257/25300 (epoch 38.057), train_loss = 0.62858993, grad/param norm = 1.6924e-01, time/batch = 17.7849s	
19258/25300 (epoch 38.059), train_loss = 0.71451182, grad/param norm = 2.3184e-01, time/batch = 18.0429s	
19259/25300 (epoch 38.061), train_loss = 0.69679775, grad/param norm = 2.2417e-01, time/batch = 17.7930s	
19260/25300 (epoch 38.063), train_loss = 0.71422847, grad/param norm = 2.0869e-01, time/batch = 18.2733s	
19261/25300 (epoch 38.065), train_loss = 0.75613992, grad/param norm = 2.1681e-01, time/batch = 17.1942s	
19262/25300 (epoch 38.067), train_loss = 0.82105034, grad/param norm = 2.1417e-01, time/batch = 15.9790s	
19263/25300 (epoch 38.069), train_loss = 0.68207944, grad/param norm = 2.2899e-01, time/batch = 16.1449s	
19264/25300 (epoch 38.071), train_loss = 0.78622103, grad/param norm = 2.2842e-01, time/batch = 16.6178s	
19265/25300 (epoch 38.073), train_loss = 0.73318973, grad/param norm = 2.0227e-01, time/batch = 17.2203s	
19266/25300 (epoch 38.075), train_loss = 0.81779563, grad/param norm = 2.6852e-01, time/batch = 15.3562s	
19267/25300 (epoch 38.077), train_loss = 0.76871041, grad/param norm = 2.2597e-01, time/batch = 16.7339s	
19268/25300 (epoch 38.079), train_loss = 0.69405122, grad/param norm = 2.2772e-01, time/batch = 15.4826s	
19269/25300 (epoch 38.081), train_loss = 0.74737932, grad/param norm = 2.1135e-01, time/batch = 15.4848s	
19270/25300 (epoch 38.083), train_loss = 0.78171215, grad/param norm = 2.1048e-01, time/batch = 16.9887s	
19271/25300 (epoch 38.085), train_loss = 0.93785815, grad/param norm = 2.4094e-01, time/batch = 17.2931s	
19272/25300 (epoch 38.087), train_loss = 0.82423850, grad/param norm = 1.8978e-01, time/batch = 16.1326s	
19273/25300 (epoch 38.089), train_loss = 0.80013732, grad/param norm = 2.2492e-01, time/batch = 16.3856s	
19274/25300 (epoch 38.091), train_loss = 0.92086152, grad/param norm = 2.2689e-01, time/batch = 16.3999s	
19275/25300 (epoch 38.093), train_loss = 0.85602975, grad/param norm = 2.4510e-01, time/batch = 15.5387s	
19276/25300 (epoch 38.095), train_loss = 0.83054879, grad/param norm = 2.1826e-01, time/batch = 15.1600s	
19277/25300 (epoch 38.097), train_loss = 0.81551585, grad/param norm = 2.3573e-01, time/batch = 16.0863s	
19278/25300 (epoch 38.099), train_loss = 0.82079983, grad/param norm = 2.5623e-01, time/batch = 19.1278s	
19279/25300 (epoch 38.101), train_loss = 0.74570616, grad/param norm = 2.2320e-01, time/batch = 15.5461s	
19280/25300 (epoch 38.103), train_loss = 0.78581509, grad/param norm = 2.0638e-01, time/batch = 18.8036s	
19281/25300 (epoch 38.105), train_loss = 0.80170885, grad/param norm = 2.3052e-01, time/batch = 15.7468s	
19282/25300 (epoch 38.107), train_loss = 0.80274840, grad/param norm = 2.5203e-01, time/batch = 17.5405s	
19283/25300 (epoch 38.109), train_loss = 0.76464464, grad/param norm = 2.3239e-01, time/batch = 16.3863s	
19284/25300 (epoch 38.111), train_loss = 0.73302158, grad/param norm = 2.0499e-01, time/batch = 15.7904s	
19285/25300 (epoch 38.113), train_loss = 0.73810901, grad/param norm = 2.6768e-01, time/batch = 15.2799s	
19286/25300 (epoch 38.115), train_loss = 0.76946215, grad/param norm = 2.7527e-01, time/batch = 16.5541s	
19287/25300 (epoch 38.117), train_loss = 0.83853300, grad/param norm = 2.1537e-01, time/batch = 15.4868s	
19288/25300 (epoch 38.119), train_loss = 0.71122886, grad/param norm = 2.1361e-01, time/batch = 15.3853s	
19289/25300 (epoch 38.121), train_loss = 0.77106499, grad/param norm = 2.7235e-01, time/batch = 16.3080s	
19290/25300 (epoch 38.123), train_loss = 0.69949410, grad/param norm = 2.0693e-01, time/batch = 15.3946s	
19291/25300 (epoch 38.125), train_loss = 0.83923571, grad/param norm = 2.0726e-01, time/batch = 15.6449s	
19292/25300 (epoch 38.126), train_loss = 0.75483735, grad/param norm = 2.0555e-01, time/batch = 16.2304s	
19293/25300 (epoch 38.128), train_loss = 0.74970094, grad/param norm = 2.3047e-01, time/batch = 15.7342s	
19294/25300 (epoch 38.130), train_loss = 0.60052564, grad/param norm = 1.8573e-01, time/batch = 15.4674s	
19295/25300 (epoch 38.132), train_loss = 0.63200558, grad/param norm = 2.1164e-01, time/batch = 15.3867s	
19296/25300 (epoch 38.134), train_loss = 0.65322153, grad/param norm = 2.0516e-01, time/batch = 15.5282s	
19297/25300 (epoch 38.136), train_loss = 0.74233240, grad/param norm = 1.9738e-01, time/batch = 17.2995s	
19298/25300 (epoch 38.138), train_loss = 0.65178405, grad/param norm = 1.8127e-01, time/batch = 17.0466s	
19299/25300 (epoch 38.140), train_loss = 0.63142255, grad/param norm = 1.9659e-01, time/batch = 15.4026s	
19300/25300 (epoch 38.142), train_loss = 0.84428585, grad/param norm = 2.3768e-01, time/batch = 18.3978s	
19301/25300 (epoch 38.144), train_loss = 0.83834512, grad/param norm = 2.3154e-01, time/batch = 17.3822s	
19302/25300 (epoch 38.146), train_loss = 0.73722672, grad/param norm = 2.5332e-01, time/batch = 16.3388s	
19303/25300 (epoch 38.148), train_loss = 0.73561205, grad/param norm = 1.9666e-01, time/batch = 15.2878s	
19304/25300 (epoch 38.150), train_loss = 0.78574572, grad/param norm = 2.4150e-01, time/batch = 16.5663s	
19305/25300 (epoch 38.152), train_loss = 0.88695101, grad/param norm = 2.8113e-01, time/batch = 15.5538s	
19306/25300 (epoch 38.154), train_loss = 0.64666528, grad/param norm = 1.8889e-01, time/batch = 17.6263s	
19307/25300 (epoch 38.156), train_loss = 0.76798982, grad/param norm = 2.1301e-01, time/batch = 17.3192s	
19308/25300 (epoch 38.158), train_loss = 0.64910925, grad/param norm = 2.0853e-01, time/batch = 17.7955s	
19309/25300 (epoch 38.160), train_loss = 0.75744054, grad/param norm = 2.3680e-01, time/batch = 16.3127s	
19310/25300 (epoch 38.162), train_loss = 0.69277069, grad/param norm = 2.2383e-01, time/batch = 16.6312s	
19311/25300 (epoch 38.164), train_loss = 0.80383634, grad/param norm = 2.2226e-01, time/batch = 18.1142s	
19312/25300 (epoch 38.166), train_loss = 0.75467093, grad/param norm = 2.1877e-01, time/batch = 15.3920s	
19313/25300 (epoch 38.168), train_loss = 0.70527452, grad/param norm = 1.8566e-01, time/batch = 15.6555s	
19314/25300 (epoch 38.170), train_loss = 0.71314694, grad/param norm = 2.2407e-01, time/batch = 18.4769s	
19315/25300 (epoch 38.172), train_loss = 0.63984980, grad/param norm = 1.9508e-01, time/batch = 16.5459s	
19316/25300 (epoch 38.174), train_loss = 0.67135204, grad/param norm = 2.2055e-01, time/batch = 16.2201s	
19317/25300 (epoch 38.176), train_loss = 0.65799968, grad/param norm = 2.4093e-01, time/batch = 15.7027s	
19318/25300 (epoch 38.178), train_loss = 0.87110853, grad/param norm = 2.1643e-01, time/batch = 16.1664s	
19319/25300 (epoch 38.180), train_loss = 0.61295496, grad/param norm = 2.0351e-01, time/batch = 15.8054s	
19320/25300 (epoch 38.182), train_loss = 0.71423393, grad/param norm = 2.4890e-01, time/batch = 16.3996s	
19321/25300 (epoch 38.184), train_loss = 0.67702041, grad/param norm = 2.2622e-01, time/batch = 17.5401s	
19322/25300 (epoch 38.186), train_loss = 0.63505851, grad/param norm = 2.4359e-01, time/batch = 17.1332s	
19323/25300 (epoch 38.188), train_loss = 0.74520473, grad/param norm = 2.4242e-01, time/batch = 17.1297s	
19324/25300 (epoch 38.190), train_loss = 0.75251726, grad/param norm = 2.2066e-01, time/batch = 16.5316s	
19325/25300 (epoch 38.192), train_loss = 0.71478301, grad/param norm = 2.1491e-01, time/batch = 18.7148s	
19326/25300 (epoch 38.194), train_loss = 0.68541773, grad/param norm = 1.9899e-01, time/batch = 15.7206s	
19327/25300 (epoch 38.196), train_loss = 0.85227726, grad/param norm = 3.0826e-01, time/batch = 16.8126s	
19328/25300 (epoch 38.198), train_loss = 0.68787426, grad/param norm = 2.2423e-01, time/batch = 17.0545s	
19329/25300 (epoch 38.200), train_loss = 0.73195546, grad/param norm = 2.2924e-01, time/batch = 19.5180s	
19330/25300 (epoch 38.202), train_loss = 0.73853434, grad/param norm = 2.2034e-01, time/batch = 26.1907s	
19331/25300 (epoch 38.204), train_loss = 0.73025356, grad/param norm = 2.0713e-01, time/batch = 17.6463s	
19332/25300 (epoch 38.206), train_loss = 0.84055294, grad/param norm = 2.5668e-01, time/batch = 15.5327s	
19333/25300 (epoch 38.208), train_loss = 0.67341287, grad/param norm = 2.1266e-01, time/batch = 15.4486s	
19334/25300 (epoch 38.209), train_loss = 0.63028019, grad/param norm = 1.8499e-01, time/batch = 15.3626s	
19335/25300 (epoch 38.211), train_loss = 0.71464091, grad/param norm = 2.0504e-01, time/batch = 15.4444s	
19336/25300 (epoch 38.213), train_loss = 0.75767293, grad/param norm = 2.4426e-01, time/batch = 15.5029s	
19337/25300 (epoch 38.215), train_loss = 0.77383884, grad/param norm = 2.1571e-01, time/batch = 15.8787s	
19338/25300 (epoch 38.217), train_loss = 0.77315771, grad/param norm = 2.5436e-01, time/batch = 15.6340s	
19339/25300 (epoch 38.219), train_loss = 0.80787457, grad/param norm = 2.6415e-01, time/batch = 15.7115s	
19340/25300 (epoch 38.221), train_loss = 0.85239110, grad/param norm = 2.2704e-01, time/batch = 15.7287s	
19341/25300 (epoch 38.223), train_loss = 0.79818351, grad/param norm = 2.6809e-01, time/batch = 16.0621s	
19342/25300 (epoch 38.225), train_loss = 1.00623822, grad/param norm = 3.0551e-01, time/batch = 17.1447s	
19343/25300 (epoch 38.227), train_loss = 0.89120190, grad/param norm = 2.4563e-01, time/batch = 15.9806s	
19344/25300 (epoch 38.229), train_loss = 0.73046315, grad/param norm = 2.2050e-01, time/batch = 16.1464s	
19345/25300 (epoch 38.231), train_loss = 0.76163286, grad/param norm = 2.5479e-01, time/batch = 15.4018s	
19346/25300 (epoch 38.233), train_loss = 0.80237178, grad/param norm = 2.5420e-01, time/batch = 17.2412s	
19347/25300 (epoch 38.235), train_loss = 0.73682728, grad/param norm = 2.1764e-01, time/batch = 16.1439s	
19348/25300 (epoch 38.237), train_loss = 0.86724324, grad/param norm = 2.6963e-01, time/batch = 15.3194s	
19349/25300 (epoch 38.239), train_loss = 0.70272650, grad/param norm = 2.1533e-01, time/batch = 15.7914s	
19350/25300 (epoch 38.241), train_loss = 0.89322447, grad/param norm = 2.3083e-01, time/batch = 15.8763s	
19351/25300 (epoch 38.243), train_loss = 0.99690400, grad/param norm = 2.8030e-01, time/batch = 16.2924s	
19352/25300 (epoch 38.245), train_loss = 0.72609830, grad/param norm = 2.4905e-01, time/batch = 16.0720s	
19353/25300 (epoch 38.247), train_loss = 0.80092803, grad/param norm = 2.4550e-01, time/batch = 14.9933s	
19354/25300 (epoch 38.249), train_loss = 0.68028347, grad/param norm = 1.9132e-01, time/batch = 15.8817s	
19355/25300 (epoch 38.251), train_loss = 0.68157218, grad/param norm = 2.2824e-01, time/batch = 15.6421s	
19356/25300 (epoch 38.253), train_loss = 0.74688817, grad/param norm = 2.3343e-01, time/batch = 16.7272s	
19357/25300 (epoch 38.255), train_loss = 0.69952709, grad/param norm = 2.5503e-01, time/batch = 15.2226s	
19358/25300 (epoch 38.257), train_loss = 0.71729853, grad/param norm = 2.3347e-01, time/batch = 15.8889s	
19359/25300 (epoch 38.259), train_loss = 0.90286757, grad/param norm = 2.8192e-01, time/batch = 15.9521s	
19360/25300 (epoch 38.261), train_loss = 0.88619460, grad/param norm = 3.2890e-01, time/batch = 15.4557s	
19361/25300 (epoch 38.263), train_loss = 0.87826509, grad/param norm = 2.4676e-01, time/batch = 17.3893s	
19362/25300 (epoch 38.265), train_loss = 0.87910237, grad/param norm = 2.3864e-01, time/batch = 16.6226s	
19363/25300 (epoch 38.267), train_loss = 0.79716696, grad/param norm = 2.2934e-01, time/batch = 15.9622s	
19364/25300 (epoch 38.269), train_loss = 0.64541726, grad/param norm = 2.0691e-01, time/batch = 16.0733s	
19365/25300 (epoch 38.271), train_loss = 0.70085611, grad/param norm = 2.1142e-01, time/batch = 16.5572s	
19366/25300 (epoch 38.273), train_loss = 0.82041889, grad/param norm = 2.2803e-01, time/batch = 15.9656s	
19367/25300 (epoch 38.275), train_loss = 0.73409807, grad/param norm = 2.0611e-01, time/batch = 16.3116s	
19368/25300 (epoch 38.277), train_loss = 0.68620118, grad/param norm = 2.2477e-01, time/batch = 15.2924s	
19369/25300 (epoch 38.279), train_loss = 0.75845200, grad/param norm = 2.1700e-01, time/batch = 16.0748s	
19370/25300 (epoch 38.281), train_loss = 0.90199031, grad/param norm = 2.4308e-01, time/batch = 15.7290s	
19371/25300 (epoch 38.283), train_loss = 0.69059460, grad/param norm = 2.1791e-01, time/batch = 15.9603s	
19372/25300 (epoch 38.285), train_loss = 0.75000513, grad/param norm = 2.3344e-01, time/batch = 17.3697s	
19373/25300 (epoch 38.287), train_loss = 0.87063588, grad/param norm = 2.0034e-01, time/batch = 16.8840s	
19374/25300 (epoch 38.289), train_loss = 0.73303792, grad/param norm = 2.3598e-01, time/batch = 15.7836s	
19375/25300 (epoch 38.291), train_loss = 0.74349275, grad/param norm = 2.4986e-01, time/batch = 16.1616s	
19376/25300 (epoch 38.292), train_loss = 0.91879550, grad/param norm = 2.2168e-01, time/batch = 16.8717s	
19377/25300 (epoch 38.294), train_loss = 0.78253893, grad/param norm = 2.1237e-01, time/batch = 15.8058s	
19378/25300 (epoch 38.296), train_loss = 0.67974508, grad/param norm = 1.9942e-01, time/batch = 16.3169s	
19379/25300 (epoch 38.298), train_loss = 0.84214258, grad/param norm = 2.3286e-01, time/batch = 16.0638s	
19380/25300 (epoch 38.300), train_loss = 0.85235712, grad/param norm = 2.4596e-01, time/batch = 15.6497s	
19381/25300 (epoch 38.302), train_loss = 0.61693509, grad/param norm = 2.2515e-01, time/batch = 15.5427s	
19382/25300 (epoch 38.304), train_loss = 0.88564523, grad/param norm = 2.1715e-01, time/batch = 16.6521s	
19383/25300 (epoch 38.306), train_loss = 0.61098415, grad/param norm = 2.0848e-01, time/batch = 17.2269s	
19384/25300 (epoch 38.308), train_loss = 0.83357944, grad/param norm = 2.3584e-01, time/batch = 16.9667s	
19385/25300 (epoch 38.310), train_loss = 0.65967764, grad/param norm = 2.1025e-01, time/batch = 16.1388s	
19386/25300 (epoch 38.312), train_loss = 0.77766143, grad/param norm = 2.0339e-01, time/batch = 16.8191s	
19387/25300 (epoch 38.314), train_loss = 0.66342223, grad/param norm = 2.1160e-01, time/batch = 16.7867s	
19388/25300 (epoch 38.316), train_loss = 0.80033238, grad/param norm = 2.2144e-01, time/batch = 15.6264s	
19389/25300 (epoch 38.318), train_loss = 0.61552663, grad/param norm = 1.9974e-01, time/batch = 17.5564s	
19390/25300 (epoch 38.320), train_loss = 0.69663910, grad/param norm = 2.1451e-01, time/batch = 16.6561s	
19391/25300 (epoch 38.322), train_loss = 0.89927809, grad/param norm = 2.8857e-01, time/batch = 16.8988s	
19392/25300 (epoch 38.324), train_loss = 0.69535440, grad/param norm = 2.1515e-01, time/batch = 15.3827s	
19393/25300 (epoch 38.326), train_loss = 0.61129856, grad/param norm = 1.7810e-01, time/batch = 15.5647s	
19394/25300 (epoch 38.328), train_loss = 0.62513262, grad/param norm = 2.4592e-01, time/batch = 17.0537s	
19395/25300 (epoch 38.330), train_loss = 0.72777795, grad/param norm = 2.1461e-01, time/batch = 15.4396s	
19396/25300 (epoch 38.332), train_loss = 0.76029142, grad/param norm = 2.0812e-01, time/batch = 16.9691s	
19397/25300 (epoch 38.334), train_loss = 0.61849940, grad/param norm = 1.9763e-01, time/batch = 16.8073s	
19398/25300 (epoch 38.336), train_loss = 0.63540134, grad/param norm = 2.0968e-01, time/batch = 15.6950s	
19399/25300 (epoch 38.338), train_loss = 0.63448365, grad/param norm = 2.0699e-01, time/batch = 15.3013s	
19400/25300 (epoch 38.340), train_loss = 0.70016959, grad/param norm = 2.3829e-01, time/batch = 16.2400s	
19401/25300 (epoch 38.342), train_loss = 0.69494630, grad/param norm = 2.4062e-01, time/batch = 15.6386s	
19402/25300 (epoch 38.344), train_loss = 0.80087885, grad/param norm = 2.2211e-01, time/batch = 15.9891s	
19403/25300 (epoch 38.346), train_loss = 0.71025798, grad/param norm = 2.2209e-01, time/batch = 15.5633s	
19404/25300 (epoch 38.348), train_loss = 0.67180060, grad/param norm = 2.0986e-01, time/batch = 17.5488s	
19405/25300 (epoch 38.350), train_loss = 0.71432247, grad/param norm = 2.2819e-01, time/batch = 16.1279s	
19406/25300 (epoch 38.352), train_loss = 0.73394893, grad/param norm = 2.0478e-01, time/batch = 16.5656s	
19407/25300 (epoch 38.354), train_loss = 0.69205529, grad/param norm = 2.2857e-01, time/batch = 16.0427s	
19408/25300 (epoch 38.356), train_loss = 0.73533525, grad/param norm = 2.0246e-01, time/batch = 16.1542s	
19409/25300 (epoch 38.358), train_loss = 0.74035833, grad/param norm = 2.1200e-01, time/batch = 18.9708s	
19410/25300 (epoch 38.360), train_loss = 0.68398082, grad/param norm = 1.9341e-01, time/batch = 15.8692s	
19411/25300 (epoch 38.362), train_loss = 0.61791959, grad/param norm = 2.1164e-01, time/batch = 17.1453s	
19412/25300 (epoch 38.364), train_loss = 0.64932618, grad/param norm = 1.9535e-01, time/batch = 16.1867s	
19413/25300 (epoch 38.366), train_loss = 0.65617742, grad/param norm = 2.2002e-01, time/batch = 16.4888s	
19414/25300 (epoch 38.368), train_loss = 0.70394833, grad/param norm = 2.0511e-01, time/batch = 15.2566s	
19415/25300 (epoch 38.370), train_loss = 0.67829318, grad/param norm = 2.4374e-01, time/batch = 15.3133s	
19416/25300 (epoch 38.372), train_loss = 0.65952185, grad/param norm = 2.2487e-01, time/batch = 15.4125s	
19417/25300 (epoch 38.374), train_loss = 0.63521769, grad/param norm = 2.5167e-01, time/batch = 15.5427s	
19418/25300 (epoch 38.375), train_loss = 0.82873099, grad/param norm = 2.4667e-01, time/batch = 15.6648s	
19419/25300 (epoch 38.377), train_loss = 0.81570372, grad/param norm = 2.5258e-01, time/batch = 15.6294s	
19420/25300 (epoch 38.379), train_loss = 0.78032512, grad/param norm = 2.3339e-01, time/batch = 15.6309s	
19421/25300 (epoch 38.381), train_loss = 0.71361720, grad/param norm = 2.0821e-01, time/batch = 15.7774s	
19422/25300 (epoch 38.383), train_loss = 0.66819030, grad/param norm = 2.0142e-01, time/batch = 15.4668s	
19423/25300 (epoch 38.385), train_loss = 0.75519648, grad/param norm = 2.1796e-01, time/batch = 15.7412s	
19424/25300 (epoch 38.387), train_loss = 0.73715970, grad/param norm = 2.4187e-01, time/batch = 16.0738s	
19425/25300 (epoch 38.389), train_loss = 0.71834534, grad/param norm = 2.3475e-01, time/batch = 15.6403s	
19426/25300 (epoch 38.391), train_loss = 0.71020998, grad/param norm = 2.1426e-01, time/batch = 16.6329s	
19427/25300 (epoch 38.393), train_loss = 0.73779283, grad/param norm = 2.3384e-01, time/batch = 17.0558s	
19428/25300 (epoch 38.395), train_loss = 0.60656153, grad/param norm = 2.0617e-01, time/batch = 15.6236s	
19429/25300 (epoch 38.397), train_loss = 0.56766657, grad/param norm = 2.2328e-01, time/batch = 15.6317s	
19430/25300 (epoch 38.399), train_loss = 0.64023719, grad/param norm = 2.0190e-01, time/batch = 18.4747s	
19431/25300 (epoch 38.401), train_loss = 0.77963276, grad/param norm = 2.5866e-01, time/batch = 18.8058s	
19432/25300 (epoch 38.403), train_loss = 0.75875149, grad/param norm = 2.1344e-01, time/batch = 16.1332s	
19433/25300 (epoch 38.405), train_loss = 0.69565282, grad/param norm = 2.1436e-01, time/batch = 17.5532s	
19434/25300 (epoch 38.407), train_loss = 0.72475255, grad/param norm = 2.1812e-01, time/batch = 18.0567s	
19435/25300 (epoch 38.409), train_loss = 0.66762052, grad/param norm = 2.1993e-01, time/batch = 17.2909s	
19436/25300 (epoch 38.411), train_loss = 0.68289109, grad/param norm = 2.1463e-01, time/batch = 15.8954s	
19437/25300 (epoch 38.413), train_loss = 0.60981401, grad/param norm = 2.0556e-01, time/batch = 18.2972s	
19438/25300 (epoch 38.415), train_loss = 0.65472992, grad/param norm = 2.0408e-01, time/batch = 17.2048s	
19439/25300 (epoch 38.417), train_loss = 0.61386783, grad/param norm = 2.0259e-01, time/batch = 16.9662s	
19440/25300 (epoch 38.419), train_loss = 0.53801735, grad/param norm = 1.5909e-01, time/batch = 16.4801s	
19441/25300 (epoch 38.421), train_loss = 0.62755078, grad/param norm = 1.7685e-01, time/batch = 15.6642s	
19442/25300 (epoch 38.423), train_loss = 0.62196580, grad/param norm = 2.1584e-01, time/batch = 16.0467s	
19443/25300 (epoch 38.425), train_loss = 0.72485500, grad/param norm = 2.6824e-01, time/batch = 16.2249s	
19444/25300 (epoch 38.427), train_loss = 0.80376154, grad/param norm = 2.1487e-01, time/batch = 17.5645s	
19445/25300 (epoch 38.429), train_loss = 0.80981702, grad/param norm = 2.5787e-01, time/batch = 16.6403s	
19446/25300 (epoch 38.431), train_loss = 0.72926512, grad/param norm = 2.1422e-01, time/batch = 15.9667s	
19447/25300 (epoch 38.433), train_loss = 0.76004629, grad/param norm = 1.9888e-01, time/batch = 15.8919s	
19448/25300 (epoch 38.435), train_loss = 0.66984144, grad/param norm = 2.4654e-01, time/batch = 16.7292s	
19449/25300 (epoch 38.437), train_loss = 0.66896924, grad/param norm = 2.1246e-01, time/batch = 15.5322s	
19450/25300 (epoch 38.439), train_loss = 0.73794211, grad/param norm = 1.9429e-01, time/batch = 15.5739s	
19451/25300 (epoch 38.441), train_loss = 0.77288687, grad/param norm = 2.2837e-01, time/batch = 15.5585s	
19452/25300 (epoch 38.443), train_loss = 0.88041582, grad/param norm = 2.6998e-01, time/batch = 16.7373s	
19453/25300 (epoch 38.445), train_loss = 0.81034843, grad/param norm = 2.3670e-01, time/batch = 17.5457s	
19454/25300 (epoch 38.447), train_loss = 0.66663404, grad/param norm = 2.0188e-01, time/batch = 18.2921s	
19455/25300 (epoch 38.449), train_loss = 0.59621542, grad/param norm = 2.2556e-01, time/batch = 16.2881s	
19456/25300 (epoch 38.451), train_loss = 0.91792394, grad/param norm = 3.0743e-01, time/batch = 17.3095s	
19457/25300 (epoch 38.453), train_loss = 0.79761474, grad/param norm = 2.1029e-01, time/batch = 16.7018s	
19458/25300 (epoch 38.455), train_loss = 0.77314719, grad/param norm = 2.6722e-01, time/batch = 15.7116s	
19459/25300 (epoch 38.457), train_loss = 0.66250571, grad/param norm = 1.9531e-01, time/batch = 17.0693s	
19460/25300 (epoch 38.458), train_loss = 0.70372443, grad/param norm = 2.4940e-01, time/batch = 16.8639s	
19461/25300 (epoch 38.460), train_loss = 0.72390095, grad/param norm = 2.5261e-01, time/batch = 15.7897s	
19462/25300 (epoch 38.462), train_loss = 0.52822622, grad/param norm = 2.0702e-01, time/batch = 17.5490s	
19463/25300 (epoch 38.464), train_loss = 0.79235110, grad/param norm = 2.2427e-01, time/batch = 15.9072s	
19464/25300 (epoch 38.466), train_loss = 0.74449538, grad/param norm = 2.1174e-01, time/batch = 15.6381s	
19465/25300 (epoch 38.468), train_loss = 0.75301585, grad/param norm = 2.0027e-01, time/batch = 15.8952s	
19466/25300 (epoch 38.470), train_loss = 0.69290754, grad/param norm = 1.8977e-01, time/batch = 15.8817s	
19467/25300 (epoch 38.472), train_loss = 0.61137254, grad/param norm = 2.0867e-01, time/batch = 15.7341s	
19468/25300 (epoch 38.474), train_loss = 0.75396211, grad/param norm = 2.0404e-01, time/batch = 15.8996s	
19469/25300 (epoch 38.476), train_loss = 0.69139582, grad/param norm = 2.3789e-01, time/batch = 15.6275s	
19470/25300 (epoch 38.478), train_loss = 0.75883938, grad/param norm = 2.1918e-01, time/batch = 15.8686s	
19471/25300 (epoch 38.480), train_loss = 0.70281287, grad/param norm = 2.2849e-01, time/batch = 16.2972s	
19472/25300 (epoch 38.482), train_loss = 0.75299434, grad/param norm = 2.4818e-01, time/batch = 15.7080s	
19473/25300 (epoch 38.484), train_loss = 0.78523740, grad/param norm = 2.4315e-01, time/batch = 15.4670s	
19474/25300 (epoch 38.486), train_loss = 0.74282582, grad/param norm = 2.5903e-01, time/batch = 18.3645s	
19475/25300 (epoch 38.488), train_loss = 0.88702140, grad/param norm = 2.4210e-01, time/batch = 16.8768s	
19476/25300 (epoch 38.490), train_loss = 0.75182557, grad/param norm = 2.1607e-01, time/batch = 15.8065s	
19477/25300 (epoch 38.492), train_loss = 0.82744197, grad/param norm = 2.1603e-01, time/batch = 15.9581s	
19478/25300 (epoch 38.494), train_loss = 0.74868552, grad/param norm = 2.2630e-01, time/batch = 18.0606s	
19479/25300 (epoch 38.496), train_loss = 0.77169553, grad/param norm = 2.1784e-01, time/batch = 15.9661s	
19480/25300 (epoch 38.498), train_loss = 0.72015030, grad/param norm = 2.0125e-01, time/batch = 15.4637s	
19481/25300 (epoch 38.500), train_loss = 0.85255358, grad/param norm = 2.4827e-01, time/batch = 17.8101s	
19482/25300 (epoch 38.502), train_loss = 0.78776437, grad/param norm = 2.6420e-01, time/batch = 17.7060s	
19483/25300 (epoch 38.504), train_loss = 0.68076365, grad/param norm = 1.9807e-01, time/batch = 15.5454s	
19484/25300 (epoch 38.506), train_loss = 0.62424757, grad/param norm = 2.3601e-01, time/batch = 15.6531s	
19485/25300 (epoch 38.508), train_loss = 0.73126225, grad/param norm = 2.4640e-01, time/batch = 15.5614s	
19486/25300 (epoch 38.510), train_loss = 0.70533555, grad/param norm = 2.8781e-01, time/batch = 16.1359s	
19487/25300 (epoch 38.512), train_loss = 0.57361390, grad/param norm = 1.9512e-01, time/batch = 15.6379s	
19488/25300 (epoch 38.514), train_loss = 0.71516929, grad/param norm = 2.2475e-01, time/batch = 15.8152s	
19489/25300 (epoch 38.516), train_loss = 0.79802224, grad/param norm = 2.8476e-01, time/batch = 17.7262s	
19490/25300 (epoch 38.518), train_loss = 0.81733349, grad/param norm = 2.3741e-01, time/batch = 15.7025s	
19491/25300 (epoch 38.520), train_loss = 0.60611932, grad/param norm = 1.8856e-01, time/batch = 16.5668s	
19492/25300 (epoch 38.522), train_loss = 0.67637731, grad/param norm = 2.2124e-01, time/batch = 16.6456s	
19493/25300 (epoch 38.524), train_loss = 0.66478473, grad/param norm = 2.1848e-01, time/batch = 16.5498s	
19494/25300 (epoch 38.526), train_loss = 0.83313179, grad/param norm = 2.4895e-01, time/batch = 15.6300s	
19495/25300 (epoch 38.528), train_loss = 0.86066616, grad/param norm = 2.4513e-01, time/batch = 16.9583s	
19496/25300 (epoch 38.530), train_loss = 0.78971789, grad/param norm = 2.0695e-01, time/batch = 15.5121s	
19497/25300 (epoch 38.532), train_loss = 0.70968248, grad/param norm = 2.0996e-01, time/batch = 15.3457s	
19498/25300 (epoch 38.534), train_loss = 0.68600921, grad/param norm = 2.0570e-01, time/batch = 15.3635s	
19499/25300 (epoch 38.536), train_loss = 0.57977450, grad/param norm = 2.0752e-01, time/batch = 15.3837s	
19500/25300 (epoch 38.538), train_loss = 0.63334608, grad/param norm = 1.9023e-01, time/batch = 15.2925s	
19501/25300 (epoch 38.540), train_loss = 0.63383581, grad/param norm = 2.0328e-01, time/batch = 15.3701s	
19502/25300 (epoch 38.542), train_loss = 0.61121833, grad/param norm = 2.3435e-01, time/batch = 15.4494s	
19503/25300 (epoch 38.543), train_loss = 0.59588870, grad/param norm = 2.0440e-01, time/batch = 15.3470s	
19504/25300 (epoch 38.545), train_loss = 0.91276844, grad/param norm = 3.1454e-01, time/batch = 15.6256s	
19505/25300 (epoch 38.547), train_loss = 0.80807590, grad/param norm = 2.2972e-01, time/batch = 15.9527s	
19506/25300 (epoch 38.549), train_loss = 0.91344312, grad/param norm = 3.5551e-01, time/batch = 17.8828s	
19507/25300 (epoch 38.551), train_loss = 0.86644652, grad/param norm = 2.3151e-01, time/batch = 15.6366s	
19508/25300 (epoch 38.553), train_loss = 0.70660248, grad/param norm = 2.5770e-01, time/batch = 16.2887s	
19509/25300 (epoch 38.555), train_loss = 0.75511524, grad/param norm = 2.3489e-01, time/batch = 15.7877s	
19510/25300 (epoch 38.557), train_loss = 0.81757504, grad/param norm = 2.4004e-01, time/batch = 15.6547s	
19511/25300 (epoch 38.559), train_loss = 0.84979684, grad/param norm = 2.3281e-01, time/batch = 15.5471s	
19512/25300 (epoch 38.561), train_loss = 0.86850945, grad/param norm = 2.4300e-01, time/batch = 16.6257s	
19513/25300 (epoch 38.563), train_loss = 0.85190384, grad/param norm = 2.3581e-01, time/batch = 15.7184s	
19514/25300 (epoch 38.565), train_loss = 0.61982441, grad/param norm = 1.9559e-01, time/batch = 15.6397s	
19515/25300 (epoch 38.567), train_loss = 0.56921065, grad/param norm = 1.9313e-01, time/batch = 16.0576s	
19516/25300 (epoch 38.569), train_loss = 0.73452017, grad/param norm = 2.2290e-01, time/batch = 16.1338s	
19517/25300 (epoch 38.571), train_loss = 0.81069978, grad/param norm = 2.5808e-01, time/batch = 15.8081s	
19518/25300 (epoch 38.573), train_loss = 0.72783584, grad/param norm = 2.1817e-01, time/batch = 18.1277s	
19519/25300 (epoch 38.575), train_loss = 0.77770774, grad/param norm = 2.6959e-01, time/batch = 16.9639s	
19520/25300 (epoch 38.577), train_loss = 0.68715036, grad/param norm = 2.2791e-01, time/batch = 15.4612s	
19521/25300 (epoch 38.579), train_loss = 0.85873472, grad/param norm = 2.6378e-01, time/batch = 15.7688s	
19522/25300 (epoch 38.581), train_loss = 0.81769220, grad/param norm = 2.6337e-01, time/batch = 15.7928s	
19523/25300 (epoch 38.583), train_loss = 0.60642803, grad/param norm = 2.4652e-01, time/batch = 16.0508s	
19524/25300 (epoch 38.585), train_loss = 0.62268694, grad/param norm = 2.2775e-01, time/batch = 15.2128s	
19525/25300 (epoch 38.587), train_loss = 0.73744552, grad/param norm = 2.4518e-01, time/batch = 15.7175s	
19526/25300 (epoch 38.589), train_loss = 0.64906381, grad/param norm = 2.0607e-01, time/batch = 16.8559s	
19527/25300 (epoch 38.591), train_loss = 0.61876880, grad/param norm = 2.9899e-01, time/batch = 16.0664s	
19528/25300 (epoch 38.593), train_loss = 0.81804314, grad/param norm = 2.3455e-01, time/batch = 15.0606s	
19529/25300 (epoch 38.595), train_loss = 0.74877857, grad/param norm = 2.3293e-01, time/batch = 15.3178s	
19530/25300 (epoch 38.597), train_loss = 0.65370004, grad/param norm = 2.1957e-01, time/batch = 15.5625s	
19531/25300 (epoch 38.599), train_loss = 0.83553848, grad/param norm = 2.2403e-01, time/batch = 15.5497s	
19532/25300 (epoch 38.601), train_loss = 0.73991026, grad/param norm = 2.5372e-01, time/batch = 15.7385s	
19533/25300 (epoch 38.603), train_loss = 0.72969895, grad/param norm = 2.4067e-01, time/batch = 15.4950s	
19534/25300 (epoch 38.605), train_loss = 0.75361759, grad/param norm = 2.5167e-01, time/batch = 16.5577s	
19535/25300 (epoch 38.607), train_loss = 0.53150667, grad/param norm = 1.8281e-01, time/batch = 15.3870s	
19536/25300 (epoch 38.609), train_loss = 0.65849304, grad/param norm = 2.2641e-01, time/batch = 16.3961s	
19537/25300 (epoch 38.611), train_loss = 0.79567997, grad/param norm = 2.7562e-01, time/batch = 15.8219s	
19538/25300 (epoch 38.613), train_loss = 0.62651905, grad/param norm = 1.9378e-01, time/batch = 16.7918s	
19539/25300 (epoch 38.615), train_loss = 0.69329057, grad/param norm = 2.4144e-01, time/batch = 15.3893s	
19540/25300 (epoch 38.617), train_loss = 0.74634028, grad/param norm = 2.5041e-01, time/batch = 15.4593s	
19541/25300 (epoch 38.619), train_loss = 0.77945310, grad/param norm = 2.4128e-01, time/batch = 16.8008s	
19542/25300 (epoch 38.621), train_loss = 0.80437730, grad/param norm = 2.6145e-01, time/batch = 15.4585s	
19543/25300 (epoch 38.623), train_loss = 0.67282317, grad/param norm = 2.1283e-01, time/batch = 15.6540s	
19544/25300 (epoch 38.625), train_loss = 0.61499909, grad/param norm = 2.1067e-01, time/batch = 16.2249s	
19545/25300 (epoch 38.626), train_loss = 0.70874046, grad/param norm = 1.9584e-01, time/batch = 15.6553s	
19546/25300 (epoch 38.628), train_loss = 0.83546936, grad/param norm = 2.5925e-01, time/batch = 15.7135s	
19547/25300 (epoch 38.630), train_loss = 0.78040827, grad/param norm = 2.4487e-01, time/batch = 15.5613s	
19548/25300 (epoch 38.632), train_loss = 0.74134979, grad/param norm = 2.5251e-01, time/batch = 16.0722s	
19549/25300 (epoch 38.634), train_loss = 0.84766055, grad/param norm = 2.9413e-01, time/batch = 16.0648s	
19550/25300 (epoch 38.636), train_loss = 0.65019566, grad/param norm = 2.3159e-01, time/batch = 26.3020s	
19551/25300 (epoch 38.638), train_loss = 0.73946031, grad/param norm = 2.7008e-01, time/batch = 16.9433s	
19552/25300 (epoch 38.640), train_loss = 0.93361849, grad/param norm = 3.4761e-01, time/batch = 16.2369s	
19553/25300 (epoch 38.642), train_loss = 0.78719086, grad/param norm = 2.6147e-01, time/batch = 15.3661s	
19554/25300 (epoch 38.644), train_loss = 0.72759469, grad/param norm = 2.3945e-01, time/batch = 18.7201s	
19555/25300 (epoch 38.646), train_loss = 0.68615210, grad/param norm = 2.5317e-01, time/batch = 16.1420s	
19556/25300 (epoch 38.648), train_loss = 0.83409978, grad/param norm = 2.1597e-01, time/batch = 16.0663s	
19557/25300 (epoch 38.650), train_loss = 0.77311198, grad/param norm = 2.4915e-01, time/batch = 15.3112s	
19558/25300 (epoch 38.652), train_loss = 0.77511362, grad/param norm = 2.6932e-01, time/batch = 16.4680s	
19559/25300 (epoch 38.654), train_loss = 0.84701461, grad/param norm = 2.3116e-01, time/batch = 16.0582s	
19560/25300 (epoch 38.656), train_loss = 0.80255496, grad/param norm = 2.4042e-01, time/batch = 16.8110s	
19561/25300 (epoch 38.658), train_loss = 0.58976052, grad/param norm = 1.9959e-01, time/batch = 17.2287s	
19562/25300 (epoch 38.660), train_loss = 0.60638912, grad/param norm = 2.2870e-01, time/batch = 17.7209s	
19563/25300 (epoch 38.662), train_loss = 0.62398469, grad/param norm = 2.1001e-01, time/batch = 17.4553s	
19564/25300 (epoch 38.664), train_loss = 0.59107975, grad/param norm = 2.1710e-01, time/batch = 16.0544s	
19565/25300 (epoch 38.666), train_loss = 0.63297763, grad/param norm = 2.1482e-01, time/batch = 18.3778s	
19566/25300 (epoch 38.668), train_loss = 0.72657792, grad/param norm = 2.6001e-01, time/batch = 15.7196s	
19567/25300 (epoch 38.670), train_loss = 0.65923417, grad/param norm = 2.5435e-01, time/batch = 15.6080s	
19568/25300 (epoch 38.672), train_loss = 0.65583314, grad/param norm = 2.2949e-01, time/batch = 15.7301s	
19569/25300 (epoch 38.674), train_loss = 0.64969669, grad/param norm = 1.9881e-01, time/batch = 15.7683s	
19570/25300 (epoch 38.676), train_loss = 0.65976751, grad/param norm = 2.8206e-01, time/batch = 15.5062s	
19571/25300 (epoch 38.678), train_loss = 0.67278224, grad/param norm = 2.3840e-01, time/batch = 15.3952s	
19572/25300 (epoch 38.680), train_loss = 0.58777996, grad/param norm = 1.7132e-01, time/batch = 15.5772s	
19573/25300 (epoch 38.682), train_loss = 0.51115339, grad/param norm = 1.7282e-01, time/batch = 15.3078s	
19574/25300 (epoch 38.684), train_loss = 0.65283919, grad/param norm = 1.8944e-01, time/batch = 15.6634s	
19575/25300 (epoch 38.686), train_loss = 0.61378508, grad/param norm = 2.0153e-01, time/batch = 15.4792s	
19576/25300 (epoch 38.688), train_loss = 0.68597529, grad/param norm = 2.3653e-01, time/batch = 15.6507s	
19577/25300 (epoch 38.690), train_loss = 0.61094334, grad/param norm = 1.8610e-01, time/batch = 17.6187s	
19578/25300 (epoch 38.692), train_loss = 0.66704682, grad/param norm = 2.3414e-01, time/batch = 17.7955s	
19579/25300 (epoch 38.694), train_loss = 0.66844836, grad/param norm = 2.8403e-01, time/batch = 17.2200s	
19580/25300 (epoch 38.696), train_loss = 0.73043094, grad/param norm = 2.5991e-01, time/batch = 16.8877s	
19581/25300 (epoch 38.698), train_loss = 0.77445619, grad/param norm = 2.2003e-01, time/batch = 15.7173s	
19582/25300 (epoch 38.700), train_loss = 0.56881587, grad/param norm = 1.8422e-01, time/batch = 15.3506s	
19583/25300 (epoch 38.702), train_loss = 0.77486960, grad/param norm = 2.8494e-01, time/batch = 16.4587s	
19584/25300 (epoch 38.704), train_loss = 0.54637000, grad/param norm = 1.6977e-01, time/batch = 16.8951s	
19585/25300 (epoch 38.706), train_loss = 0.69658062, grad/param norm = 2.3101e-01, time/batch = 17.9783s	
19586/25300 (epoch 38.708), train_loss = 0.59700958, grad/param norm = 1.8243e-01, time/batch = 16.2104s	
19587/25300 (epoch 38.709), train_loss = 0.82570169, grad/param norm = 2.1679e-01, time/batch = 16.9647s	
19588/25300 (epoch 38.711), train_loss = 0.86616397, grad/param norm = 2.5828e-01, time/batch = 17.2250s	
19589/25300 (epoch 38.713), train_loss = 0.72771722, grad/param norm = 2.0124e-01, time/batch = 15.4553s	
19590/25300 (epoch 38.715), train_loss = 0.74358817, grad/param norm = 2.1431e-01, time/batch = 16.4814s	
19591/25300 (epoch 38.717), train_loss = 0.61818122, grad/param norm = 2.1574e-01, time/batch = 15.7920s	
19592/25300 (epoch 38.719), train_loss = 0.69514727, grad/param norm = 2.2722e-01, time/batch = 16.2390s	
19593/25300 (epoch 38.721), train_loss = 0.77378550, grad/param norm = 2.4752e-01, time/batch = 15.5687s	
19594/25300 (epoch 38.723), train_loss = 0.70506784, grad/param norm = 2.3782e-01, time/batch = 16.1484s	
19595/25300 (epoch 38.725), train_loss = 0.74456969, grad/param norm = 2.7024e-01, time/batch = 15.4077s	
19596/25300 (epoch 38.727), train_loss = 0.73887111, grad/param norm = 2.3893e-01, time/batch = 16.1454s	
19597/25300 (epoch 38.729), train_loss = 0.68971502, grad/param norm = 2.1474e-01, time/batch = 16.2144s	
19598/25300 (epoch 38.731), train_loss = 0.85509114, grad/param norm = 2.6797e-01, time/batch = 15.7263s	
19599/25300 (epoch 38.733), train_loss = 0.70994796, grad/param norm = 1.8187e-01, time/batch = 15.9692s	
19600/25300 (epoch 38.735), train_loss = 0.91714210, grad/param norm = 2.7329e-01, time/batch = 15.5404s	
19601/25300 (epoch 38.737), train_loss = 0.59174581, grad/param norm = 2.1843e-01, time/batch = 15.9767s	
19602/25300 (epoch 38.739), train_loss = 0.84665332, grad/param norm = 2.2731e-01, time/batch = 16.7255s	
19603/25300 (epoch 38.741), train_loss = 0.75926514, grad/param norm = 2.4395e-01, time/batch = 17.8932s	
19604/25300 (epoch 38.743), train_loss = 0.71350163, grad/param norm = 2.0023e-01, time/batch = 15.7202s	
19605/25300 (epoch 38.745), train_loss = 0.69359646, grad/param norm = 2.3718e-01, time/batch = 15.7223s	
19606/25300 (epoch 38.747), train_loss = 0.62271741, grad/param norm = 2.1207e-01, time/batch = 15.6464s	
19607/25300 (epoch 38.749), train_loss = 0.71230824, grad/param norm = 2.4686e-01, time/batch = 17.7281s	
19608/25300 (epoch 38.751), train_loss = 0.76255379, grad/param norm = 2.3735e-01, time/batch = 17.0246s	
19609/25300 (epoch 38.753), train_loss = 0.61831896, grad/param norm = 2.2544e-01, time/batch = 16.0557s	
19610/25300 (epoch 38.755), train_loss = 0.82856967, grad/param norm = 2.6742e-01, time/batch = 16.3197s	
19611/25300 (epoch 38.757), train_loss = 0.66764582, grad/param norm = 2.1151e-01, time/batch = 15.8483s	
19612/25300 (epoch 38.759), train_loss = 0.65854037, grad/param norm = 2.1816e-01, time/batch = 15.5628s	
19613/25300 (epoch 38.761), train_loss = 0.85326844, grad/param norm = 2.1961e-01, time/batch = 15.8956s	
19614/25300 (epoch 38.763), train_loss = 0.70820175, grad/param norm = 2.3235e-01, time/batch = 15.2369s	
19615/25300 (epoch 38.765), train_loss = 0.68530559, grad/param norm = 2.4656e-01, time/batch = 15.2143s	
19616/25300 (epoch 38.767), train_loss = 0.70267836, grad/param norm = 2.0596e-01, time/batch = 15.7071s	
19617/25300 (epoch 38.769), train_loss = 0.72384899, grad/param norm = 2.4499e-01, time/batch = 15.4808s	
19618/25300 (epoch 38.771), train_loss = 0.80626576, grad/param norm = 2.8618e-01, time/batch = 17.2263s	
19619/25300 (epoch 38.773), train_loss = 0.83564142, grad/param norm = 2.6328e-01, time/batch = 16.3799s	
19620/25300 (epoch 38.775), train_loss = 0.73729394, grad/param norm = 2.0536e-01, time/batch = 16.6458s	
19621/25300 (epoch 38.777), train_loss = 0.67945552, grad/param norm = 2.3790e-01, time/batch = 16.4991s	
19622/25300 (epoch 38.779), train_loss = 0.79606423, grad/param norm = 2.2404e-01, time/batch = 17.4643s	
19623/25300 (epoch 38.781), train_loss = 0.77421731, grad/param norm = 2.2971e-01, time/batch = 15.6204s	
19624/25300 (epoch 38.783), train_loss = 0.83967127, grad/param norm = 2.3406e-01, time/batch = 16.1988s	
19625/25300 (epoch 38.785), train_loss = 0.81475831, grad/param norm = 2.5006e-01, time/batch = 16.1366s	
19626/25300 (epoch 38.787), train_loss = 0.77764198, grad/param norm = 2.5163e-01, time/batch = 15.7107s	
19627/25300 (epoch 38.789), train_loss = 0.85173778, grad/param norm = 2.5089e-01, time/batch = 16.2266s	
19628/25300 (epoch 38.791), train_loss = 0.76326394, grad/param norm = 2.2570e-01, time/batch = 15.8307s	
19629/25300 (epoch 38.792), train_loss = 0.84657447, grad/param norm = 2.5029e-01, time/batch = 17.3869s	
19630/25300 (epoch 38.794), train_loss = 0.71807909, grad/param norm = 2.4635e-01, time/batch = 16.2087s	
19631/25300 (epoch 38.796), train_loss = 0.68532212, grad/param norm = 2.4414e-01, time/batch = 17.4785s	
19632/25300 (epoch 38.798), train_loss = 0.81566690, grad/param norm = 2.6576e-01, time/batch = 16.0279s	
19633/25300 (epoch 38.800), train_loss = 0.69655816, grad/param norm = 2.0252e-01, time/batch = 15.5432s	
19634/25300 (epoch 38.802), train_loss = 0.59814970, grad/param norm = 1.9865e-01, time/batch = 15.3900s	
19635/25300 (epoch 38.804), train_loss = 0.74494842, grad/param norm = 2.1990e-01, time/batch = 15.7140s	
19636/25300 (epoch 38.806), train_loss = 0.78192495, grad/param norm = 2.6330e-01, time/batch = 15.2033s	
19637/25300 (epoch 38.808), train_loss = 0.84096167, grad/param norm = 2.3708e-01, time/batch = 17.2144s	
19638/25300 (epoch 38.810), train_loss = 0.71221944, grad/param norm = 2.4753e-01, time/batch = 16.1397s	
19639/25300 (epoch 38.812), train_loss = 0.84999396, grad/param norm = 2.5350e-01, time/batch = 16.4880s	
19640/25300 (epoch 38.814), train_loss = 0.85474197, grad/param norm = 2.3247e-01, time/batch = 16.4890s	
19641/25300 (epoch 38.816), train_loss = 0.93351894, grad/param norm = 2.6506e-01, time/batch = 15.9752s	
19642/25300 (epoch 38.818), train_loss = 0.81724700, grad/param norm = 2.1216e-01, time/batch = 16.6553s	
19643/25300 (epoch 38.820), train_loss = 0.82413475, grad/param norm = 2.2882e-01, time/batch = 16.8081s	
19644/25300 (epoch 38.822), train_loss = 0.69691727, grad/param norm = 2.5300e-01, time/batch = 17.4500s	
19645/25300 (epoch 38.824), train_loss = 0.83000826, grad/param norm = 2.4667e-01, time/batch = 16.2209s	
19646/25300 (epoch 38.826), train_loss = 0.69267360, grad/param norm = 2.0865e-01, time/batch = 15.9177s	
19647/25300 (epoch 38.828), train_loss = 0.68162320, grad/param norm = 2.2565e-01, time/batch = 16.8873s	
19648/25300 (epoch 38.830), train_loss = 0.78046857, grad/param norm = 2.6430e-01, time/batch = 16.2182s	
19649/25300 (epoch 38.832), train_loss = 0.87813630, grad/param norm = 2.7709e-01, time/batch = 15.6587s	
19650/25300 (epoch 38.834), train_loss = 0.69554718, grad/param norm = 2.2199e-01, time/batch = 17.4017s	
19651/25300 (epoch 38.836), train_loss = 0.72351956, grad/param norm = 2.1190e-01, time/batch = 16.9893s	
19652/25300 (epoch 38.838), train_loss = 0.71612790, grad/param norm = 2.5495e-01, time/batch = 15.9627s	
19653/25300 (epoch 38.840), train_loss = 0.81296846, grad/param norm = 2.5180e-01, time/batch = 16.1383s	
19654/25300 (epoch 38.842), train_loss = 0.75552960, grad/param norm = 2.7029e-01, time/batch = 15.5579s	
19655/25300 (epoch 38.844), train_loss = 0.83157369, grad/param norm = 2.2215e-01, time/batch = 16.2254s	
19656/25300 (epoch 38.846), train_loss = 0.80989764, grad/param norm = 2.0398e-01, time/batch = 15.5639s	
19657/25300 (epoch 38.848), train_loss = 0.78821448, grad/param norm = 2.4155e-01, time/batch = 16.6477s	
19658/25300 (epoch 38.850), train_loss = 0.77893684, grad/param norm = 2.6160e-01, time/batch = 15.6460s	
19659/25300 (epoch 38.852), train_loss = 0.82959036, grad/param norm = 2.1568e-01, time/batch = 15.4784s	
19660/25300 (epoch 38.854), train_loss = 0.85828532, grad/param norm = 2.2985e-01, time/batch = 15.9763s	
19661/25300 (epoch 38.856), train_loss = 0.68898956, grad/param norm = 2.1420e-01, time/batch = 16.0608s	
19662/25300 (epoch 38.858), train_loss = 0.72333510, grad/param norm = 2.4553e-01, time/batch = 16.1640s	
19663/25300 (epoch 38.860), train_loss = 0.63099401, grad/param norm = 1.9282e-01, time/batch = 15.2085s	
19664/25300 (epoch 38.862), train_loss = 0.75035921, grad/param norm = 2.3027e-01, time/batch = 15.3391s	
19665/25300 (epoch 38.864), train_loss = 0.86391806, grad/param norm = 2.2664e-01, time/batch = 15.1263s	
19666/25300 (epoch 38.866), train_loss = 0.70760122, grad/param norm = 2.3048e-01, time/batch = 15.4500s	
19667/25300 (epoch 38.868), train_loss = 0.83942833, grad/param norm = 2.3232e-01, time/batch = 15.1341s	
19668/25300 (epoch 38.870), train_loss = 0.81059349, grad/param norm = 2.0672e-01, time/batch = 15.5352s	
19669/25300 (epoch 38.872), train_loss = 0.75214259, grad/param norm = 2.3804e-01, time/batch = 15.7962s	
19670/25300 (epoch 38.874), train_loss = 0.80111371, grad/param norm = 2.5076e-01, time/batch = 15.8994s	
19671/25300 (epoch 38.875), train_loss = 0.73534116, grad/param norm = 2.3504e-01, time/batch = 15.7093s	
19672/25300 (epoch 38.877), train_loss = 0.69987312, grad/param norm = 1.8564e-01, time/batch = 15.4908s	
19673/25300 (epoch 38.879), train_loss = 0.68108471, grad/param norm = 2.5125e-01, time/batch = 15.4896s	
19674/25300 (epoch 38.881), train_loss = 0.96902180, grad/param norm = 2.7764e-01, time/batch = 16.3165s	
19675/25300 (epoch 38.883), train_loss = 0.94995921, grad/param norm = 2.9059e-01, time/batch = 15.8765s	
19676/25300 (epoch 38.885), train_loss = 0.81729282, grad/param norm = 2.9596e-01, time/batch = 17.5456s	
19677/25300 (epoch 38.887), train_loss = 0.81509826, grad/param norm = 2.1457e-01, time/batch = 15.7146s	
19678/25300 (epoch 38.889), train_loss = 0.90928827, grad/param norm = 2.9484e-01, time/batch = 15.7713s	
19679/25300 (epoch 38.891), train_loss = 0.78809963, grad/param norm = 2.4695e-01, time/batch = 15.8715s	
19680/25300 (epoch 38.893), train_loss = 0.77094423, grad/param norm = 2.6400e-01, time/batch = 15.9071s	
19681/25300 (epoch 38.895), train_loss = 0.58683798, grad/param norm = 2.0161e-01, time/batch = 16.1633s	
19682/25300 (epoch 38.897), train_loss = 0.64351009, grad/param norm = 1.9154e-01, time/batch = 15.6448s	
19683/25300 (epoch 38.899), train_loss = 0.75847204, grad/param norm = 2.4771e-01, time/batch = 15.8254s	
19684/25300 (epoch 38.901), train_loss = 0.82388984, grad/param norm = 2.4003e-01, time/batch = 16.0809s	
19685/25300 (epoch 38.903), train_loss = 0.62435484, grad/param norm = 2.5235e-01, time/batch = 16.7296s	
19686/25300 (epoch 38.905), train_loss = 0.69725826, grad/param norm = 2.9587e-01, time/batch = 15.7791s	
19687/25300 (epoch 38.907), train_loss = 0.70044620, grad/param norm = 2.3959e-01, time/batch = 16.9826s	
19688/25300 (epoch 38.909), train_loss = 0.79159046, grad/param norm = 2.0698e-01, time/batch = 16.5576s	
19689/25300 (epoch 38.911), train_loss = 0.84796589, grad/param norm = 2.5812e-01, time/batch = 16.3665s	
19690/25300 (epoch 38.913), train_loss = 0.92887899, grad/param norm = 2.7905e-01, time/batch = 15.8201s	
19691/25300 (epoch 38.915), train_loss = 0.71849514, grad/param norm = 2.4037e-01, time/batch = 17.2023s	
19692/25300 (epoch 38.917), train_loss = 0.90684811, grad/param norm = 2.4419e-01, time/batch = 16.9007s	
19693/25300 (epoch 38.919), train_loss = 0.87843693, grad/param norm = 2.6915e-01, time/batch = 17.1400s	
19694/25300 (epoch 38.921), train_loss = 0.73133236, grad/param norm = 2.6786e-01, time/batch = 16.3790s	
19695/25300 (epoch 38.923), train_loss = 0.83399384, grad/param norm = 2.2950e-01, time/batch = 17.9663s	
19696/25300 (epoch 38.925), train_loss = 0.76041790, grad/param norm = 2.3888e-01, time/batch = 16.5473s	
19697/25300 (epoch 38.927), train_loss = 0.76692862, grad/param norm = 2.3411e-01, time/batch = 16.8907s	
19698/25300 (epoch 38.929), train_loss = 0.81140919, grad/param norm = 2.2725e-01, time/batch = 15.6408s	
19699/25300 (epoch 38.931), train_loss = 0.82085999, grad/param norm = 2.4628e-01, time/batch = 15.7351s	
19700/25300 (epoch 38.933), train_loss = 0.79408135, grad/param norm = 2.5446e-01, time/batch = 15.5466s	
19701/25300 (epoch 38.935), train_loss = 0.80980620, grad/param norm = 2.0816e-01, time/batch = 16.3192s	
19702/25300 (epoch 38.937), train_loss = 0.62760731, grad/param norm = 1.9915e-01, time/batch = 16.5720s	
19703/25300 (epoch 38.939), train_loss = 0.77420643, grad/param norm = 2.3243e-01, time/batch = 16.4893s	
19704/25300 (epoch 38.941), train_loss = 0.70772347, grad/param norm = 2.4897e-01, time/batch = 15.8837s	
19705/25300 (epoch 38.943), train_loss = 0.78769361, grad/param norm = 2.3165e-01, time/batch = 15.7906s	
19706/25300 (epoch 38.945), train_loss = 0.78688986, grad/param norm = 2.4936e-01, time/batch = 17.2413s	
19707/25300 (epoch 38.947), train_loss = 0.71846089, grad/param norm = 2.3378e-01, time/batch = 16.0299s	
19708/25300 (epoch 38.949), train_loss = 0.78749824, grad/param norm = 2.1437e-01, time/batch = 16.8881s	
19709/25300 (epoch 38.951), train_loss = 0.75896553, grad/param norm = 2.1748e-01, time/batch = 15.8973s	
19710/25300 (epoch 38.953), train_loss = 0.72459786, grad/param norm = 2.3097e-01, time/batch = 17.9592s	
19711/25300 (epoch 38.955), train_loss = 0.94963190, grad/param norm = 2.9566e-01, time/batch = 15.8829s	
19712/25300 (epoch 38.957), train_loss = 0.84101125, grad/param norm = 2.6328e-01, time/batch = 16.8701s	
19713/25300 (epoch 38.958), train_loss = 0.82280576, grad/param norm = 2.8056e-01, time/batch = 17.8055s	
19714/25300 (epoch 38.960), train_loss = 0.92066066, grad/param norm = 2.7629e-01, time/batch = 16.7111s	
19715/25300 (epoch 38.962), train_loss = 0.88479639, grad/param norm = 2.2246e-01, time/batch = 17.6472s	
19716/25300 (epoch 38.964), train_loss = 0.78144044, grad/param norm = 2.5694e-01, time/batch = 15.5662s	
19717/25300 (epoch 38.966), train_loss = 0.67531172, grad/param norm = 2.1788e-01, time/batch = 15.5488s	
19718/25300 (epoch 38.968), train_loss = 0.66796221, grad/param norm = 2.0051e-01, time/batch = 15.5238s	
19719/25300 (epoch 38.970), train_loss = 0.73662477, grad/param norm = 2.4321e-01, time/batch = 16.4777s	
19720/25300 (epoch 38.972), train_loss = 0.75417810, grad/param norm = 2.1551e-01, time/batch = 16.2179s	
19721/25300 (epoch 38.974), train_loss = 0.87377477, grad/param norm = 2.7528e-01, time/batch = 15.2042s	
19722/25300 (epoch 38.976), train_loss = 0.78919562, grad/param norm = 2.6036e-01, time/batch = 15.3006s	
19723/25300 (epoch 38.978), train_loss = 0.74179137, grad/param norm = 2.6080e-01, time/batch = 17.1368s	
19724/25300 (epoch 38.980), train_loss = 0.78774785, grad/param norm = 2.5921e-01, time/batch = 16.5508s	
19725/25300 (epoch 38.982), train_loss = 0.74294117, grad/param norm = 2.6335e-01, time/batch = 15.5313s	
19726/25300 (epoch 38.984), train_loss = 0.77052911, grad/param norm = 2.5300e-01, time/batch = 15.9005s	
19727/25300 (epoch 38.986), train_loss = 0.82343340, grad/param norm = 2.7692e-01, time/batch = 16.3157s	
19728/25300 (epoch 38.988), train_loss = 0.79198473, grad/param norm = 2.5080e-01, time/batch = 16.0844s	
19729/25300 (epoch 38.990), train_loss = 0.79288748, grad/param norm = 2.3478e-01, time/batch = 17.0553s	
19730/25300 (epoch 38.992), train_loss = 0.66957399, grad/param norm = 2.0762e-01, time/batch = 16.0661s	
19731/25300 (epoch 38.994), train_loss = 0.80023542, grad/param norm = 2.7430e-01, time/batch = 15.6347s	
19732/25300 (epoch 38.996), train_loss = 0.92089347, grad/param norm = 3.2077e-01, time/batch = 16.3965s	
19733/25300 (epoch 38.998), train_loss = 0.81948893, grad/param norm = 2.3891e-01, time/batch = 15.6982s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
19734/25300 (epoch 39.000), train_loss = 0.81341823, grad/param norm = 2.3523e-01, time/batch = 16.1399s	
19735/25300 (epoch 39.002), train_loss = 0.77262300, grad/param norm = 2.0865e-01, time/batch = 15.9718s	
19736/25300 (epoch 39.004), train_loss = 0.66792541, grad/param norm = 2.1033e-01, time/batch = 16.0516s	
19737/25300 (epoch 39.006), train_loss = 0.91817403, grad/param norm = 2.5980e-01, time/batch = 15.4792s	
19738/25300 (epoch 39.008), train_loss = 0.79255402, grad/param norm = 2.6377e-01, time/batch = 17.6470s	
19739/25300 (epoch 39.010), train_loss = 0.84000504, grad/param norm = 2.3680e-01, time/batch = 18.3061s	
19740/25300 (epoch 39.012), train_loss = 0.73871558, grad/param norm = 2.1259e-01, time/batch = 16.5280s	
19741/25300 (epoch 39.014), train_loss = 0.89187553, grad/param norm = 2.8784e-01, time/batch = 16.3950s	
19742/25300 (epoch 39.016), train_loss = 0.77700446, grad/param norm = 2.7885e-01, time/batch = 15.8189s	
19743/25300 (epoch 39.018), train_loss = 0.70776044, grad/param norm = 2.3316e-01, time/batch = 16.0626s	
19744/25300 (epoch 39.020), train_loss = 0.81087227, grad/param norm = 2.3251e-01, time/batch = 15.6414s	
19745/25300 (epoch 39.022), train_loss = 0.76867982, grad/param norm = 2.3926e-01, time/batch = 15.4068s	
19746/25300 (epoch 39.024), train_loss = 0.59450947, grad/param norm = 1.6570e-01, time/batch = 15.8234s	
19747/25300 (epoch 39.026), train_loss = 0.72297310, grad/param norm = 2.2120e-01, time/batch = 16.7266s	
19748/25300 (epoch 39.028), train_loss = 0.72519933, grad/param norm = 2.1687e-01, time/batch = 16.3005s	
19749/25300 (epoch 39.030), train_loss = 0.87676501, grad/param norm = 2.5637e-01, time/batch = 16.3899s	
19750/25300 (epoch 39.032), train_loss = 0.72855449, grad/param norm = 2.3304e-01, time/batch = 17.2008s	
19751/25300 (epoch 39.034), train_loss = 0.68266220, grad/param norm = 2.1427e-01, time/batch = 16.2009s	
19752/25300 (epoch 39.036), train_loss = 0.64705886, grad/param norm = 2.3944e-01, time/batch = 16.9702s	
19753/25300 (epoch 39.038), train_loss = 0.58017070, grad/param norm = 1.7732e-01, time/batch = 16.8081s	
19754/25300 (epoch 39.040), train_loss = 0.75240441, grad/param norm = 2.2029e-01, time/batch = 17.5450s	
19755/25300 (epoch 39.042), train_loss = 0.73682910, grad/param norm = 2.0033e-01, time/batch = 17.5480s	
19756/25300 (epoch 39.043), train_loss = 0.66036405, grad/param norm = 1.9115e-01, time/batch = 17.2260s	
19757/25300 (epoch 39.045), train_loss = 0.64626964, grad/param norm = 2.1060e-01, time/batch = 17.9781s	
19758/25300 (epoch 39.047), train_loss = 0.77334142, grad/param norm = 2.2547e-01, time/batch = 17.0328s	
19759/25300 (epoch 39.049), train_loss = 0.76537156, grad/param norm = 2.7554e-01, time/batch = 18.0487s	
19760/25300 (epoch 39.051), train_loss = 0.88089694, grad/param norm = 2.2523e-01, time/batch = 16.0482s	
19761/25300 (epoch 39.053), train_loss = 0.59752465, grad/param norm = 1.7493e-01, time/batch = 17.8788s	
19762/25300 (epoch 39.055), train_loss = 0.61699562, grad/param norm = 1.9769e-01, time/batch = 15.8854s	
19763/25300 (epoch 39.057), train_loss = 0.62188121, grad/param norm = 1.5936e-01, time/batch = 16.6361s	
19764/25300 (epoch 39.059), train_loss = 0.71608366, grad/param norm = 2.2858e-01, time/batch = 16.2465s	
19765/25300 (epoch 39.061), train_loss = 0.68537812, grad/param norm = 2.1925e-01, time/batch = 17.4569s	
19766/25300 (epoch 39.063), train_loss = 0.70704222, grad/param norm = 1.9219e-01, time/batch = 16.2435s	
19767/25300 (epoch 39.065), train_loss = 0.75244943, grad/param norm = 2.4169e-01, time/batch = 17.7088s	
19768/25300 (epoch 39.067), train_loss = 0.81048777, grad/param norm = 2.1723e-01, time/batch = 17.7167s	
19769/25300 (epoch 39.069), train_loss = 0.65059652, grad/param norm = 2.0442e-01, time/batch = 28.1413s	
19770/25300 (epoch 39.071), train_loss = 0.78850484, grad/param norm = 2.5258e-01, time/batch = 17.9655s	
19771/25300 (epoch 39.073), train_loss = 0.72703736, grad/param norm = 2.1863e-01, time/batch = 15.6396s	
19772/25300 (epoch 39.075), train_loss = 0.79631488, grad/param norm = 2.2831e-01, time/batch = 15.7204s	
19773/25300 (epoch 39.077), train_loss = 0.77469312, grad/param norm = 2.3847e-01, time/batch = 18.4710s	
19774/25300 (epoch 39.079), train_loss = 0.67448947, grad/param norm = 2.1177e-01, time/batch = 16.7312s	
19775/25300 (epoch 39.081), train_loss = 0.74318551, grad/param norm = 1.8886e-01, time/batch = 16.0391s	
19776/25300 (epoch 39.083), train_loss = 0.77627812, grad/param norm = 2.2491e-01, time/batch = 15.2283s	
19777/25300 (epoch 39.085), train_loss = 0.92478535, grad/param norm = 2.6043e-01, time/batch = 19.2091s	
19778/25300 (epoch 39.087), train_loss = 0.81498793, grad/param norm = 2.0901e-01, time/batch = 15.9888s	
19779/25300 (epoch 39.089), train_loss = 0.78925002, grad/param norm = 2.3526e-01, time/batch = 16.4711s	
19780/25300 (epoch 39.091), train_loss = 0.92342398, grad/param norm = 2.2981e-01, time/batch = 17.7108s	
19781/25300 (epoch 39.093), train_loss = 0.85435538, grad/param norm = 2.7421e-01, time/batch = 17.1505s	
19782/25300 (epoch 39.095), train_loss = 0.81476705, grad/param norm = 2.2688e-01, time/batch = 17.1314s	
19783/25300 (epoch 39.097), train_loss = 0.79943045, grad/param norm = 2.2594e-01, time/batch = 16.2101s	
19784/25300 (epoch 39.099), train_loss = 0.81535988, grad/param norm = 2.8199e-01, time/batch = 17.0593s	
19785/25300 (epoch 39.101), train_loss = 0.74682054, grad/param norm = 2.4170e-01, time/batch = 17.0480s	
19786/25300 (epoch 39.103), train_loss = 0.79569307, grad/param norm = 2.3174e-01, time/batch = 15.7825s	
19787/25300 (epoch 39.105), train_loss = 0.80228097, grad/param norm = 2.7527e-01, time/batch = 16.9822s	
19788/25300 (epoch 39.107), train_loss = 0.80025056, grad/param norm = 2.5234e-01, time/batch = 16.5614s	
19789/25300 (epoch 39.109), train_loss = 0.73216767, grad/param norm = 2.3316e-01, time/batch = 15.8730s	
19790/25300 (epoch 39.111), train_loss = 0.74764721, grad/param norm = 2.4248e-01, time/batch = 16.0623s	
19791/25300 (epoch 39.113), train_loss = 0.70662351, grad/param norm = 2.1982e-01, time/batch = 16.3878s	
19792/25300 (epoch 39.115), train_loss = 0.74489039, grad/param norm = 2.5888e-01, time/batch = 15.9046s	
19793/25300 (epoch 39.117), train_loss = 0.82391615, grad/param norm = 2.0583e-01, time/batch = 16.4732s	
19794/25300 (epoch 39.119), train_loss = 0.71277254, grad/param norm = 2.2869e-01, time/batch = 15.8225s	
19795/25300 (epoch 39.121), train_loss = 0.76434699, grad/param norm = 2.5824e-01, time/batch = 15.8990s	
19796/25300 (epoch 39.123), train_loss = 0.69463628, grad/param norm = 2.2489e-01, time/batch = 16.8062s	
19797/25300 (epoch 39.125), train_loss = 0.83855433, grad/param norm = 2.3386e-01, time/batch = 16.1321s	
19798/25300 (epoch 39.126), train_loss = 0.76487685, grad/param norm = 2.0243e-01, time/batch = 16.9786s	
19799/25300 (epoch 39.128), train_loss = 0.73975727, grad/param norm = 2.4687e-01, time/batch = 16.9031s	
19800/25300 (epoch 39.130), train_loss = 0.60105897, grad/param norm = 2.0968e-01, time/batch = 16.3000s	
19801/25300 (epoch 39.132), train_loss = 0.63328394, grad/param norm = 2.2266e-01, time/batch = 17.2128s	
19802/25300 (epoch 39.134), train_loss = 0.62524871, grad/param norm = 1.8523e-01, time/batch = 16.1466s	
19803/25300 (epoch 39.136), train_loss = 0.73014059, grad/param norm = 1.9685e-01, time/batch = 16.2026s	
19804/25300 (epoch 39.138), train_loss = 0.65285541, grad/param norm = 1.8910e-01, time/batch = 15.6266s	
19805/25300 (epoch 39.140), train_loss = 0.63442667, grad/param norm = 2.0186e-01, time/batch = 16.2433s	
19806/25300 (epoch 39.142), train_loss = 0.84373811, grad/param norm = 2.3743e-01, time/batch = 15.5752s	
19807/25300 (epoch 39.144), train_loss = 0.81146233, grad/param norm = 2.1550e-01, time/batch = 16.1280s	
19808/25300 (epoch 39.146), train_loss = 0.74041300, grad/param norm = 2.5229e-01, time/batch = 15.8774s	
19809/25300 (epoch 39.148), train_loss = 0.72843938, grad/param norm = 2.0638e-01, time/batch = 16.3271s	
19810/25300 (epoch 39.150), train_loss = 0.77646658, grad/param norm = 2.3879e-01, time/batch = 18.0470s	
19811/25300 (epoch 39.152), train_loss = 0.85990813, grad/param norm = 2.3549e-01, time/batch = 15.8913s	
19812/25300 (epoch 39.154), train_loss = 0.64435524, grad/param norm = 1.9670e-01, time/batch = 15.7200s	
19813/25300 (epoch 39.156), train_loss = 0.77444194, grad/param norm = 2.6925e-01, time/batch = 17.0530s	
19814/25300 (epoch 39.158), train_loss = 0.65532116, grad/param norm = 2.2505e-01, time/batch = 17.5491s	
19815/25300 (epoch 39.160), train_loss = 0.73988246, grad/param norm = 2.2654e-01, time/batch = 15.4573s	
19816/25300 (epoch 39.162), train_loss = 0.68615741, grad/param norm = 2.5224e-01, time/batch = 16.1457s	
19817/25300 (epoch 39.164), train_loss = 0.80526316, grad/param norm = 2.5236e-01, time/batch = 16.8862s	
19818/25300 (epoch 39.166), train_loss = 0.74555705, grad/param norm = 2.0409e-01, time/batch = 16.0549s	
19819/25300 (epoch 39.168), train_loss = 0.68062565, grad/param norm = 1.7266e-01, time/batch = 16.5448s	
19820/25300 (epoch 39.170), train_loss = 0.69094130, grad/param norm = 1.8864e-01, time/batch = 15.8107s	
19821/25300 (epoch 39.172), train_loss = 0.63424927, grad/param norm = 1.9850e-01, time/batch = 18.8891s	
19822/25300 (epoch 39.174), train_loss = 0.66303612, grad/param norm = 2.0396e-01, time/batch = 17.0179s	
19823/25300 (epoch 39.176), train_loss = 0.65922290, grad/param norm = 2.5437e-01, time/batch = 16.8646s	
19824/25300 (epoch 39.178), train_loss = 0.86855772, grad/param norm = 2.6915e-01, time/batch = 15.6041s	
19825/25300 (epoch 39.180), train_loss = 0.59130851, grad/param norm = 1.8859e-01, time/batch = 15.4349s	
19826/25300 (epoch 39.182), train_loss = 0.71225441, grad/param norm = 2.3780e-01, time/batch = 15.4398s	
19827/25300 (epoch 39.184), train_loss = 0.65594938, grad/param norm = 2.9670e-01, time/batch = 15.4536s	
19828/25300 (epoch 39.186), train_loss = 0.63038387, grad/param norm = 2.4796e-01, time/batch = 15.6090s	
19829/25300 (epoch 39.188), train_loss = 0.73292895, grad/param norm = 2.6548e-01, time/batch = 15.5361s	
19830/25300 (epoch 39.190), train_loss = 0.75057672, grad/param norm = 2.5135e-01, time/batch = 15.7478s	
19831/25300 (epoch 39.192), train_loss = 0.72536578, grad/param norm = 2.2842e-01, time/batch = 16.4790s	
19832/25300 (epoch 39.194), train_loss = 0.68151343, grad/param norm = 2.5054e-01, time/batch = 18.3045s	
19833/25300 (epoch 39.196), train_loss = 0.84649851, grad/param norm = 3.0518e-01, time/batch = 16.2168s	
19834/25300 (epoch 39.198), train_loss = 0.71431136, grad/param norm = 3.2113e-01, time/batch = 17.6482s	
19835/25300 (epoch 39.200), train_loss = 0.73882023, grad/param norm = 2.5297e-01, time/batch = 16.7899s	
19836/25300 (epoch 39.202), train_loss = 0.74362252, grad/param norm = 2.3305e-01, time/batch = 15.6510s	
19837/25300 (epoch 39.204), train_loss = 0.73155141, grad/param norm = 2.3811e-01, time/batch = 15.6815s	
19838/25300 (epoch 39.206), train_loss = 0.82549183, grad/param norm = 2.4821e-01, time/batch = 18.6273s	
19839/25300 (epoch 39.208), train_loss = 0.68543597, grad/param norm = 2.2612e-01, time/batch = 18.7061s	
19840/25300 (epoch 39.209), train_loss = 0.64258431, grad/param norm = 2.0409e-01, time/batch = 16.4508s	
19841/25300 (epoch 39.211), train_loss = 0.72461077, grad/param norm = 2.2410e-01, time/batch = 17.4688s	
19842/25300 (epoch 39.213), train_loss = 0.76843902, grad/param norm = 2.3403e-01, time/batch = 16.3679s	
19843/25300 (epoch 39.215), train_loss = 0.76873775, grad/param norm = 2.1562e-01, time/batch = 18.8656s	
19844/25300 (epoch 39.217), train_loss = 0.76843316, grad/param norm = 2.4319e-01, time/batch = 17.3770s	
19845/25300 (epoch 39.219), train_loss = 0.79018535, grad/param norm = 2.3942e-01, time/batch = 17.1256s	
19846/25300 (epoch 39.221), train_loss = 0.83500448, grad/param norm = 2.4197e-01, time/batch = 19.6842s	
19847/25300 (epoch 39.223), train_loss = 0.78355538, grad/param norm = 2.4717e-01, time/batch = 16.6184s	
19848/25300 (epoch 39.225), train_loss = 1.02137919, grad/param norm = 3.5753e-01, time/batch = 17.2185s	
19849/25300 (epoch 39.227), train_loss = 0.86435724, grad/param norm = 2.3659e-01, time/batch = 16.2244s	
19850/25300 (epoch 39.229), train_loss = 0.71957966, grad/param norm = 2.1884e-01, time/batch = 16.4850s	
19851/25300 (epoch 39.231), train_loss = 0.75828817, grad/param norm = 2.2597e-01, time/batch = 15.9831s	
19852/25300 (epoch 39.233), train_loss = 0.80011982, grad/param norm = 2.5769e-01, time/batch = 16.1565s	
19853/25300 (epoch 39.235), train_loss = 0.73612358, grad/param norm = 2.4858e-01, time/batch = 17.0644s	
19854/25300 (epoch 39.237), train_loss = 0.86496731, grad/param norm = 2.6506e-01, time/batch = 16.3917s	
19855/25300 (epoch 39.239), train_loss = 0.69552219, grad/param norm = 2.2928e-01, time/batch = 15.3376s	
19856/25300 (epoch 39.241), train_loss = 0.89460758, grad/param norm = 2.3239e-01, time/batch = 15.8095s	
19857/25300 (epoch 39.243), train_loss = 0.96458966, grad/param norm = 2.9644e-01, time/batch = 17.1285s	
19858/25300 (epoch 39.245), train_loss = 0.72419990, grad/param norm = 2.5883e-01, time/batch = 15.5825s	
19859/25300 (epoch 39.247), train_loss = 0.79906053, grad/param norm = 2.2661e-01, time/batch = 15.4689s	
19860/25300 (epoch 39.249), train_loss = 0.67275807, grad/param norm = 2.0212e-01, time/batch = 16.1290s	
19861/25300 (epoch 39.251), train_loss = 0.65836161, grad/param norm = 2.1185e-01, time/batch = 17.7092s	
19862/25300 (epoch 39.253), train_loss = 0.73836927, grad/param norm = 2.2151e-01, time/batch = 15.6392s	
19863/25300 (epoch 39.255), train_loss = 0.70198405, grad/param norm = 2.6787e-01, time/batch = 17.7257s	
19864/25300 (epoch 39.257), train_loss = 0.70362963, grad/param norm = 2.3893e-01, time/batch = 15.6487s	
19865/25300 (epoch 39.259), train_loss = 0.88654204, grad/param norm = 3.0069e-01, time/batch = 16.0572s	
19866/25300 (epoch 39.261), train_loss = 0.86714628, grad/param norm = 3.2725e-01, time/batch = 15.9052s	
19867/25300 (epoch 39.263), train_loss = 0.86013672, grad/param norm = 2.3454e-01, time/batch = 15.5693s	
19868/25300 (epoch 39.265), train_loss = 0.88660011, grad/param norm = 2.4911e-01, time/batch = 15.4010s	
19869/25300 (epoch 39.267), train_loss = 0.78196462, grad/param norm = 2.3004e-01, time/batch = 16.3147s	
19870/25300 (epoch 39.269), train_loss = 0.63533811, grad/param norm = 1.8865e-01, time/batch = 15.9883s	
19871/25300 (epoch 39.271), train_loss = 0.70801487, grad/param norm = 2.2687e-01, time/batch = 16.4867s	
19872/25300 (epoch 39.273), train_loss = 0.81046922, grad/param norm = 2.3735e-01, time/batch = 16.2697s	
19873/25300 (epoch 39.275), train_loss = 0.71308421, grad/param norm = 1.8656e-01, time/batch = 15.5801s	
19874/25300 (epoch 39.277), train_loss = 0.67126769, grad/param norm = 2.6510e-01, time/batch = 16.1314s	
19875/25300 (epoch 39.279), train_loss = 0.74714827, grad/param norm = 2.2086e-01, time/batch = 16.1443s	
19876/25300 (epoch 39.281), train_loss = 0.90563165, grad/param norm = 2.8770e-01, time/batch = 15.7859s	
19877/25300 (epoch 39.283), train_loss = 0.67662754, grad/param norm = 2.1068e-01, time/batch = 15.7179s	
19878/25300 (epoch 39.285), train_loss = 0.75180038, grad/param norm = 2.2902e-01, time/batch = 15.6463s	
19879/25300 (epoch 39.287), train_loss = 0.85621342, grad/param norm = 1.9606e-01, time/batch = 16.4025s	
19880/25300 (epoch 39.289), train_loss = 0.71176504, grad/param norm = 2.2249e-01, time/batch = 16.3991s	
19881/25300 (epoch 39.291), train_loss = 0.71446963, grad/param norm = 2.2595e-01, time/batch = 15.3079s	
19882/25300 (epoch 39.292), train_loss = 0.93321062, grad/param norm = 2.3746e-01, time/batch = 16.5531s	
19883/25300 (epoch 39.294), train_loss = 0.77892681, grad/param norm = 2.2140e-01, time/batch = 15.9076s	
19884/25300 (epoch 39.296), train_loss = 0.68189376, grad/param norm = 2.1842e-01, time/batch = 15.5468s	
19885/25300 (epoch 39.298), train_loss = 0.80913476, grad/param norm = 2.1726e-01, time/batch = 15.9767s	
19886/25300 (epoch 39.300), train_loss = 0.83357929, grad/param norm = 2.3983e-01, time/batch = 17.1971s	
19887/25300 (epoch 39.302), train_loss = 0.62017182, grad/param norm = 2.2076e-01, time/batch = 16.0597s	
19888/25300 (epoch 39.304), train_loss = 0.87953484, grad/param norm = 2.2005e-01, time/batch = 15.6991s	
19889/25300 (epoch 39.306), train_loss = 0.59529286, grad/param norm = 2.2942e-01, time/batch = 16.7864s	
19890/25300 (epoch 39.308), train_loss = 0.82240006, grad/param norm = 2.3410e-01, time/batch = 16.3236s	
19891/25300 (epoch 39.310), train_loss = 0.67031776, grad/param norm = 2.3038e-01, time/batch = 15.5447s	
19892/25300 (epoch 39.312), train_loss = 0.79233295, grad/param norm = 2.2457e-01, time/batch = 16.3139s	
19893/25300 (epoch 39.314), train_loss = 0.65150454, grad/param norm = 1.9856e-01, time/batch = 16.2131s	
19894/25300 (epoch 39.316), train_loss = 0.78259049, grad/param norm = 2.1067e-01, time/batch = 16.8077s	
19895/25300 (epoch 39.318), train_loss = 0.60883341, grad/param norm = 1.9816e-01, time/batch = 15.8877s	
19896/25300 (epoch 39.320), train_loss = 0.68544856, grad/param norm = 1.9805e-01, time/batch = 15.7768s	
19897/25300 (epoch 39.322), train_loss = 0.86936570, grad/param norm = 2.2601e-01, time/batch = 17.1302s	
19898/25300 (epoch 39.324), train_loss = 0.67847201, grad/param norm = 2.0989e-01, time/batch = 16.6545s	
19899/25300 (epoch 39.326), train_loss = 0.60277877, grad/param norm = 1.9070e-01, time/batch = 15.8747s	
19900/25300 (epoch 39.328), train_loss = 0.61713130, grad/param norm = 2.2877e-01, time/batch = 16.0634s	
19901/25300 (epoch 39.330), train_loss = 0.71879856, grad/param norm = 2.3003e-01, time/batch = 16.3899s	
19902/25300 (epoch 39.332), train_loss = 0.75755346, grad/param norm = 2.1867e-01, time/batch = 15.5692s	
19903/25300 (epoch 39.334), train_loss = 0.61353372, grad/param norm = 2.0960e-01, time/batch = 15.4044s	
19904/25300 (epoch 39.336), train_loss = 0.62812446, grad/param norm = 2.2181e-01, time/batch = 16.3042s	
19905/25300 (epoch 39.338), train_loss = 0.62983117, grad/param norm = 2.0977e-01, time/batch = 16.4924s	
19906/25300 (epoch 39.340), train_loss = 0.68870924, grad/param norm = 2.1493e-01, time/batch = 15.8101s	
19907/25300 (epoch 39.342), train_loss = 0.69774330, grad/param norm = 2.9295e-01, time/batch = 16.0802s	
19908/25300 (epoch 39.344), train_loss = 0.78864912, grad/param norm = 2.2056e-01, time/batch = 15.5661s	
19909/25300 (epoch 39.346), train_loss = 0.69451725, grad/param norm = 2.2508e-01, time/batch = 15.6426s	
19910/25300 (epoch 39.348), train_loss = 0.69294328, grad/param norm = 2.2479e-01, time/batch = 16.5311s	
19911/25300 (epoch 39.350), train_loss = 0.70649321, grad/param norm = 2.5913e-01, time/batch = 16.8929s	
19912/25300 (epoch 39.352), train_loss = 0.73848365, grad/param norm = 2.1224e-01, time/batch = 17.1513s	
19913/25300 (epoch 39.354), train_loss = 0.69647959, grad/param norm = 2.2921e-01, time/batch = 15.2197s	
19914/25300 (epoch 39.356), train_loss = 0.72671439, grad/param norm = 2.2353e-01, time/batch = 15.3232s	
19915/25300 (epoch 39.358), train_loss = 0.73839616, grad/param norm = 2.2992e-01, time/batch = 15.2301s	
19916/25300 (epoch 39.360), train_loss = 0.67498192, grad/param norm = 2.0794e-01, time/batch = 16.5622s	
19917/25300 (epoch 39.362), train_loss = 0.60794456, grad/param norm = 2.3366e-01, time/batch = 15.6271s	
19918/25300 (epoch 39.364), train_loss = 0.66528499, grad/param norm = 2.6718e-01, time/batch = 16.0620s	
19919/25300 (epoch 39.366), train_loss = 0.64709639, grad/param norm = 2.1429e-01, time/batch = 16.2271s	
19920/25300 (epoch 39.368), train_loss = 0.69109358, grad/param norm = 2.1463e-01, time/batch = 16.6427s	
19921/25300 (epoch 39.370), train_loss = 0.66403908, grad/param norm = 2.2210e-01, time/batch = 16.1371s	
19922/25300 (epoch 39.372), train_loss = 0.64834780, grad/param norm = 2.4453e-01, time/batch = 15.5365s	
19923/25300 (epoch 39.374), train_loss = 0.62566692, grad/param norm = 2.7663e-01, time/batch = 15.4873s	
19924/25300 (epoch 39.375), train_loss = 0.81783036, grad/param norm = 2.5748e-01, time/batch = 15.8058s	
19925/25300 (epoch 39.377), train_loss = 0.78263985, grad/param norm = 2.1840e-01, time/batch = 16.7164s	
19926/25300 (epoch 39.379), train_loss = 0.77252200, grad/param norm = 2.5597e-01, time/batch = 16.1239s	
19927/25300 (epoch 39.381), train_loss = 0.71601182, grad/param norm = 2.1022e-01, time/batch = 17.7050s	
19928/25300 (epoch 39.383), train_loss = 0.67670406, grad/param norm = 2.2120e-01, time/batch = 15.3052s	
19929/25300 (epoch 39.385), train_loss = 0.73270837, grad/param norm = 1.9637e-01, time/batch = 16.7952s	
19930/25300 (epoch 39.387), train_loss = 0.72767206, grad/param norm = 2.3997e-01, time/batch = 16.3945s	
19931/25300 (epoch 39.389), train_loss = 0.70813893, grad/param norm = 2.2112e-01, time/batch = 15.8291s	
19932/25300 (epoch 39.391), train_loss = 0.70039092, grad/param norm = 2.1825e-01, time/batch = 15.4844s	
19933/25300 (epoch 39.393), train_loss = 0.73969180, grad/param norm = 2.5994e-01, time/batch = 16.7853s	
19934/25300 (epoch 39.395), train_loss = 0.60250237, grad/param norm = 2.0346e-01, time/batch = 16.7039s	
19935/25300 (epoch 39.397), train_loss = 0.55638661, grad/param norm = 1.8590e-01, time/batch = 15.6336s	
19936/25300 (epoch 39.399), train_loss = 0.62067568, grad/param norm = 2.0852e-01, time/batch = 15.7102s	
19937/25300 (epoch 39.401), train_loss = 0.77461883, grad/param norm = 2.4818e-01, time/batch = 15.5649s	
19938/25300 (epoch 39.403), train_loss = 0.75688087, grad/param norm = 2.5115e-01, time/batch = 15.6633s	
19939/25300 (epoch 39.405), train_loss = 0.68257213, grad/param norm = 2.0809e-01, time/batch = 16.1297s	
19940/25300 (epoch 39.407), train_loss = 0.70879610, grad/param norm = 2.1687e-01, time/batch = 15.6542s	
19941/25300 (epoch 39.409), train_loss = 0.64861188, grad/param norm = 2.0893e-01, time/batch = 16.2210s	
19942/25300 (epoch 39.411), train_loss = 0.67697983, grad/param norm = 2.1506e-01, time/batch = 16.0692s	
19943/25300 (epoch 39.413), train_loss = 0.60979725, grad/param norm = 2.3296e-01, time/batch = 15.9798s	
19944/25300 (epoch 39.415), train_loss = 0.63704895, grad/param norm = 2.0302e-01, time/batch = 15.7351s	
19945/25300 (epoch 39.417), train_loss = 0.61640125, grad/param norm = 2.1511e-01, time/batch = 15.8251s	
19946/25300 (epoch 39.419), train_loss = 0.53346806, grad/param norm = 1.6786e-01, time/batch = 15.8394s	
19947/25300 (epoch 39.421), train_loss = 0.60511495, grad/param norm = 1.6741e-01, time/batch = 15.4557s	
19948/25300 (epoch 39.423), train_loss = 0.61472907, grad/param norm = 2.0184e-01, time/batch = 16.4048s	
19949/25300 (epoch 39.425), train_loss = 0.69618474, grad/param norm = 2.6623e-01, time/batch = 16.7470s	
19950/25300 (epoch 39.427), train_loss = 0.78508602, grad/param norm = 2.1633e-01, time/batch = 17.4734s	
19951/25300 (epoch 39.429), train_loss = 0.82025261, grad/param norm = 3.2382e-01, time/batch = 15.8899s	
19952/25300 (epoch 39.431), train_loss = 0.73496356, grad/param norm = 2.2986e-01, time/batch = 16.3808s	
19953/25300 (epoch 39.433), train_loss = 0.75500941, grad/param norm = 2.0365e-01, time/batch = 17.4701s	
19954/25300 (epoch 39.435), train_loss = 0.66268980, grad/param norm = 2.2725e-01, time/batch = 16.3090s	
19955/25300 (epoch 39.437), train_loss = 0.66545468, grad/param norm = 2.1606e-01, time/batch = 17.2189s	
19956/25300 (epoch 39.439), train_loss = 0.74801463, grad/param norm = 2.3613e-01, time/batch = 17.2113s	
19957/25300 (epoch 39.441), train_loss = 0.75870974, grad/param norm = 2.4213e-01, time/batch = 16.4765s	
19958/25300 (epoch 39.443), train_loss = 0.83888152, grad/param norm = 2.3196e-01, time/batch = 16.4629s	
19959/25300 (epoch 39.445), train_loss = 0.80314366, grad/param norm = 2.3054e-01, time/batch = 16.5611s	
19960/25300 (epoch 39.447), train_loss = 0.65928134, grad/param norm = 2.0734e-01, time/batch = 16.1359s	
19961/25300 (epoch 39.449), train_loss = 0.59041609, grad/param norm = 2.1205e-01, time/batch = 15.3937s	
19962/25300 (epoch 39.451), train_loss = 0.93280721, grad/param norm = 2.7538e-01, time/batch = 17.7961s	
19963/25300 (epoch 39.453), train_loss = 0.77396744, grad/param norm = 2.1192e-01, time/batch = 16.0700s	
19964/25300 (epoch 39.455), train_loss = 0.76292096, grad/param norm = 2.7354e-01, time/batch = 18.1088s	
19965/25300 (epoch 39.457), train_loss = 0.64895768, grad/param norm = 2.4259e-01, time/batch = 15.3632s	
19966/25300 (epoch 39.458), train_loss = 0.69475002, grad/param norm = 2.3691e-01, time/batch = 16.7854s	
19967/25300 (epoch 39.460), train_loss = 0.70722862, grad/param norm = 2.2639e-01, time/batch = 16.8031s	
19968/25300 (epoch 39.462), train_loss = 0.50100129, grad/param norm = 2.3635e-01, time/batch = 17.2805s	
19969/25300 (epoch 39.464), train_loss = 0.78287370, grad/param norm = 2.4213e-01, time/batch = 16.9692s	
19970/25300 (epoch 39.466), train_loss = 0.73650300, grad/param norm = 2.3600e-01, time/batch = 16.3003s	
19971/25300 (epoch 39.468), train_loss = 0.74534858, grad/param norm = 2.4284e-01, time/batch = 17.9520s	
19972/25300 (epoch 39.470), train_loss = 0.70544062, grad/param norm = 2.0932e-01, time/batch = 16.7341s	
19973/25300 (epoch 39.472), train_loss = 0.59635142, grad/param norm = 1.8497e-01, time/batch = 17.1311s	
19974/25300 (epoch 39.474), train_loss = 0.75109371, grad/param norm = 2.1830e-01, time/batch = 17.4705s	
19975/25300 (epoch 39.476), train_loss = 0.68822814, grad/param norm = 2.8198e-01, time/batch = 16.2310s	
19976/25300 (epoch 39.478), train_loss = 0.72816197, grad/param norm = 2.1608e-01, time/batch = 16.3119s	
19977/25300 (epoch 39.480), train_loss = 0.68499378, grad/param norm = 2.1225e-01, time/batch = 17.2288s	
19978/25300 (epoch 39.482), train_loss = 0.74476479, grad/param norm = 2.6213e-01, time/batch = 17.0345s	
19979/25300 (epoch 39.484), train_loss = 0.78790162, grad/param norm = 2.5583e-01, time/batch = 17.7955s	
19980/25300 (epoch 39.486), train_loss = 0.71198280, grad/param norm = 2.1119e-01, time/batch = 16.4099s	
19981/25300 (epoch 39.488), train_loss = 0.87008637, grad/param norm = 2.7389e-01, time/batch = 17.7282s	
19982/25300 (epoch 39.490), train_loss = 0.74672887, grad/param norm = 2.3525e-01, time/batch = 17.4652s	
19983/25300 (epoch 39.492), train_loss = 0.82765018, grad/param norm = 2.6590e-01, time/batch = 15.7311s	
19984/25300 (epoch 39.494), train_loss = 0.74517011, grad/param norm = 2.2980e-01, time/batch = 16.8112s	
19985/25300 (epoch 39.496), train_loss = 0.78046850, grad/param norm = 2.3195e-01, time/batch = 15.4836s	
19986/25300 (epoch 39.498), train_loss = 0.70585295, grad/param norm = 2.1943e-01, time/batch = 24.4439s	
19987/25300 (epoch 39.500), train_loss = 0.84758668, grad/param norm = 2.4794e-01, time/batch = 20.4320s	
19988/25300 (epoch 39.502), train_loss = 0.77605532, grad/param norm = 3.0007e-01, time/batch = 15.6074s	
19989/25300 (epoch 39.504), train_loss = 0.69174075, grad/param norm = 2.4190e-01, time/batch = 15.4485s	
19990/25300 (epoch 39.506), train_loss = 0.61375300, grad/param norm = 2.6176e-01, time/batch = 15.5281s	
19991/25300 (epoch 39.508), train_loss = 0.72684121, grad/param norm = 2.4631e-01, time/batch = 15.4282s	
19992/25300 (epoch 39.510), train_loss = 0.70593484, grad/param norm = 2.2633e-01, time/batch = 15.3498s	
19993/25300 (epoch 39.512), train_loss = 0.55174567, grad/param norm = 1.8305e-01, time/batch = 15.5930s	
19994/25300 (epoch 39.514), train_loss = 0.71289457, grad/param norm = 2.0490e-01, time/batch = 15.6247s	
19995/25300 (epoch 39.516), train_loss = 0.78329600, grad/param norm = 2.4713e-01, time/batch = 15.7970s	
19996/25300 (epoch 39.518), train_loss = 0.81544660, grad/param norm = 2.4543e-01, time/batch = 15.8207s	
19997/25300 (epoch 39.520), train_loss = 0.59640063, grad/param norm = 1.7776e-01, time/batch = 16.0411s	
19998/25300 (epoch 39.522), train_loss = 0.66767429, grad/param norm = 2.4049e-01, time/batch = 16.2287s	
19999/25300 (epoch 39.524), train_loss = 0.66100396, grad/param norm = 2.0988e-01, time/batch = 15.7427s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch39.53_1.7964.t7	
20000/25300 (epoch 39.526), train_loss = 0.81831728, grad/param norm = 2.2690e-01, time/batch = 15.3749s	
20001/25300 (epoch 39.528), train_loss = 1.52802302, grad/param norm = 3.3045e-01, time/batch = 15.4841s	
20002/25300 (epoch 39.530), train_loss = 0.80192975, grad/param norm = 2.4567e-01, time/batch = 15.3893s	
20003/25300 (epoch 39.532), train_loss = 0.70233374, grad/param norm = 2.1305e-01, time/batch = 15.1593s	
20004/25300 (epoch 39.534), train_loss = 0.71026855, grad/param norm = 2.7587e-01, time/batch = 15.5731s	
20005/25300 (epoch 39.536), train_loss = 0.57971781, grad/param norm = 2.1363e-01, time/batch = 15.7336s	
20006/25300 (epoch 39.538), train_loss = 0.62444476, grad/param norm = 1.7066e-01, time/batch = 16.3024s	
20007/25300 (epoch 39.540), train_loss = 0.63976588, grad/param norm = 2.0446e-01, time/batch = 15.4507s	
20008/25300 (epoch 39.542), train_loss = 0.60899767, grad/param norm = 2.1212e-01, time/batch = 15.4653s	
20009/25300 (epoch 39.543), train_loss = 0.58917360, grad/param norm = 1.8605e-01, time/batch = 15.4676s	
20010/25300 (epoch 39.545), train_loss = 0.90870688, grad/param norm = 3.1803e-01, time/batch = 16.1473s	
20011/25300 (epoch 39.547), train_loss = 0.79711940, grad/param norm = 2.4061e-01, time/batch = 15.5716s	
20012/25300 (epoch 39.549), train_loss = 0.93281923, grad/param norm = 3.3562e-01, time/batch = 15.9754s	
20013/25300 (epoch 39.551), train_loss = 0.84967276, grad/param norm = 2.7090e-01, time/batch = 15.9682s	
20014/25300 (epoch 39.553), train_loss = 0.70521320, grad/param norm = 2.3618e-01, time/batch = 17.4638s	
20015/25300 (epoch 39.555), train_loss = 0.75136880, grad/param norm = 2.3740e-01, time/batch = 17.1344s	
20016/25300 (epoch 39.557), train_loss = 0.82224137, grad/param norm = 2.7856e-01, time/batch = 17.4535s	
20017/25300 (epoch 39.559), train_loss = 0.84529859, grad/param norm = 2.7627e-01, time/batch = 16.4046s	
20018/25300 (epoch 39.561), train_loss = 0.86318162, grad/param norm = 2.8908e-01, time/batch = 16.1456s	
20019/25300 (epoch 39.563), train_loss = 0.84912330, grad/param norm = 2.7278e-01, time/batch = 15.3528s	
20020/25300 (epoch 39.565), train_loss = 0.63277087, grad/param norm = 2.3349e-01, time/batch = 16.4690s	
20021/25300 (epoch 39.567), train_loss = 0.57031175, grad/param norm = 2.0434e-01, time/batch = 15.4599s	
20022/25300 (epoch 39.569), train_loss = 0.74326326, grad/param norm = 2.4246e-01, time/batch = 16.7284s	
20023/25300 (epoch 39.571), train_loss = 0.80104604, grad/param norm = 2.5021e-01, time/batch = 17.4635s	
20024/25300 (epoch 39.573), train_loss = 0.73240764, grad/param norm = 2.4998e-01, time/batch = 15.3119s	
20025/25300 (epoch 39.575), train_loss = 0.77217654, grad/param norm = 2.3753e-01, time/batch = 17.8762s	
20026/25300 (epoch 39.577), train_loss = 0.69517719, grad/param norm = 2.7076e-01, time/batch = 17.8022s	
20027/25300 (epoch 39.579), train_loss = 0.83913554, grad/param norm = 2.1410e-01, time/batch = 16.7110s	
20028/25300 (epoch 39.581), train_loss = 0.79265353, grad/param norm = 2.4038e-01, time/batch = 16.6377s	
20029/25300 (epoch 39.583), train_loss = 0.59545555, grad/param norm = 2.4654e-01, time/batch = 17.2285s	
20030/25300 (epoch 39.585), train_loss = 0.60742701, grad/param norm = 1.9924e-01, time/batch = 17.7259s	
20031/25300 (epoch 39.587), train_loss = 0.71134530, grad/param norm = 2.3035e-01, time/batch = 16.8740s	
20032/25300 (epoch 39.589), train_loss = 0.63819303, grad/param norm = 1.8644e-01, time/batch = 16.0608s	
20033/25300 (epoch 39.591), train_loss = 0.60653825, grad/param norm = 2.5819e-01, time/batch = 18.3876s	
20034/25300 (epoch 39.593), train_loss = 0.79123433, grad/param norm = 2.2742e-01, time/batch = 15.7987s	
20035/25300 (epoch 39.595), train_loss = 0.72628247, grad/param norm = 2.0221e-01, time/batch = 15.4103s	
20036/25300 (epoch 39.597), train_loss = 0.65906899, grad/param norm = 1.9993e-01, time/batch = 15.9911s	
20037/25300 (epoch 39.599), train_loss = 0.83821532, grad/param norm = 2.3620e-01, time/batch = 16.0519s	
20038/25300 (epoch 39.601), train_loss = 0.72997030, grad/param norm = 2.6642e-01, time/batch = 15.9557s	
20039/25300 (epoch 39.603), train_loss = 0.71906979, grad/param norm = 2.1306e-01, time/batch = 16.9783s	
20040/25300 (epoch 39.605), train_loss = 0.73262655, grad/param norm = 2.4778e-01, time/batch = 16.3963s	
20041/25300 (epoch 39.607), train_loss = 0.52069864, grad/param norm = 1.7230e-01, time/batch = 17.3746s	
20042/25300 (epoch 39.609), train_loss = 0.64240592, grad/param norm = 2.0103e-01, time/batch = 15.7980s	
20043/25300 (epoch 39.611), train_loss = 0.76909130, grad/param norm = 2.6237e-01, time/batch = 18.9726s	
20044/25300 (epoch 39.613), train_loss = 0.64294259, grad/param norm = 2.1269e-01, time/batch = 16.0684s	
20045/25300 (epoch 39.615), train_loss = 0.69696664, grad/param norm = 3.0278e-01, time/batch = 15.6118s	
20046/25300 (epoch 39.617), train_loss = 0.73996711, grad/param norm = 2.6894e-01, time/batch = 16.3274s	
20047/25300 (epoch 39.619), train_loss = 0.78629692, grad/param norm = 2.8860e-01, time/batch = 16.1372s	
20048/25300 (epoch 39.621), train_loss = 0.81237946, grad/param norm = 2.4969e-01, time/batch = 16.3303s	
20049/25300 (epoch 39.623), train_loss = 0.65744623, grad/param norm = 2.4114e-01, time/batch = 15.9625s	
20050/25300 (epoch 39.625), train_loss = 0.60453310, grad/param norm = 1.9806e-01, time/batch = 15.4793s	
20051/25300 (epoch 39.626), train_loss = 0.69573849, grad/param norm = 2.2422e-01, time/batch = 17.7256s	
20052/25300 (epoch 39.628), train_loss = 0.85030091, grad/param norm = 2.7072e-01, time/batch = 17.1229s	
20053/25300 (epoch 39.630), train_loss = 0.76113925, grad/param norm = 2.3770e-01, time/batch = 16.8843s	
20054/25300 (epoch 39.632), train_loss = 0.71678663, grad/param norm = 2.3195e-01, time/batch = 18.2186s	
20055/25300 (epoch 39.634), train_loss = 0.83343750, grad/param norm = 2.3575e-01, time/batch = 18.3005s	
20056/25300 (epoch 39.636), train_loss = 0.64588087, grad/param norm = 2.5145e-01, time/batch = 15.7143s	
20057/25300 (epoch 39.638), train_loss = 0.71689772, grad/param norm = 2.5922e-01, time/batch = 16.0961s	
20058/25300 (epoch 39.640), train_loss = 0.93515390, grad/param norm = 3.2962e-01, time/batch = 18.3829s	
20059/25300 (epoch 39.642), train_loss = 0.77340075, grad/param norm = 2.6590e-01, time/batch = 16.1364s	
20060/25300 (epoch 39.644), train_loss = 0.73190935, grad/param norm = 2.4577e-01, time/batch = 16.2915s	
20061/25300 (epoch 39.646), train_loss = 0.68600824, grad/param norm = 3.1901e-01, time/batch = 15.4919s	
20062/25300 (epoch 39.648), train_loss = 0.82932631, grad/param norm = 2.2740e-01, time/batch = 15.2478s	
20063/25300 (epoch 39.650), train_loss = 0.76706796, grad/param norm = 2.2008e-01, time/batch = 15.8096s	
20064/25300 (epoch 39.652), train_loss = 0.76480925, grad/param norm = 2.4141e-01, time/batch = 16.0606s	
20065/25300 (epoch 39.654), train_loss = 0.86193025, grad/param norm = 2.4565e-01, time/batch = 16.8861s	
20066/25300 (epoch 39.656), train_loss = 0.77561830, grad/param norm = 2.3068e-01, time/batch = 17.2376s	
20067/25300 (epoch 39.658), train_loss = 0.58632087, grad/param norm = 2.5737e-01, time/batch = 16.2193s	
20068/25300 (epoch 39.660), train_loss = 0.60284614, grad/param norm = 2.2675e-01, time/batch = 15.6440s	
20069/25300 (epoch 39.662), train_loss = 0.61558968, grad/param norm = 1.9196e-01, time/batch = 16.2317s	
20070/25300 (epoch 39.664), train_loss = 0.57067267, grad/param norm = 2.0816e-01, time/batch = 16.4656s	
20071/25300 (epoch 39.666), train_loss = 0.62707647, grad/param norm = 2.1852e-01, time/batch = 16.3970s	
20072/25300 (epoch 39.668), train_loss = 0.73690586, grad/param norm = 3.3936e-01, time/batch = 15.8859s	
20073/25300 (epoch 39.670), train_loss = 0.66319235, grad/param norm = 2.8236e-01, time/batch = 18.8843s	
20074/25300 (epoch 39.672), train_loss = 0.66416912, grad/param norm = 2.4465e-01, time/batch = 15.5478s	
20075/25300 (epoch 39.674), train_loss = 0.64819647, grad/param norm = 2.1079e-01, time/batch = 17.8818s	
20076/25300 (epoch 39.676), train_loss = 0.64476508, grad/param norm = 2.4538e-01, time/batch = 15.7554s	
20077/25300 (epoch 39.678), train_loss = 0.67271485, grad/param norm = 2.4775e-01, time/batch = 17.0599s	
20078/25300 (epoch 39.680), train_loss = 0.58892633, grad/param norm = 2.2345e-01, time/batch = 15.7067s	
20079/25300 (epoch 39.682), train_loss = 0.49775607, grad/param norm = 1.7041e-01, time/batch = 17.2869s	
20080/25300 (epoch 39.684), train_loss = 0.63514913, grad/param norm = 2.1619e-01, time/batch = 17.0675s	
20081/25300 (epoch 39.686), train_loss = 0.59787740, grad/param norm = 2.0090e-01, time/batch = 16.2181s	
20082/25300 (epoch 39.688), train_loss = 0.67971093, grad/param norm = 2.6470e-01, time/batch = 19.3866s	
20083/25300 (epoch 39.690), train_loss = 0.61358656, grad/param norm = 2.0439e-01, time/batch = 18.8040s	
20084/25300 (epoch 39.692), train_loss = 0.65085030, grad/param norm = 2.1615e-01, time/batch = 18.0318s	
20085/25300 (epoch 39.694), train_loss = 0.65753354, grad/param norm = 2.7909e-01, time/batch = 17.7217s	
20086/25300 (epoch 39.696), train_loss = 0.71250657, grad/param norm = 3.3085e-01, time/batch = 16.7393s	
20087/25300 (epoch 39.698), train_loss = 0.78730990, grad/param norm = 2.9658e-01, time/batch = 16.9001s	
20088/25300 (epoch 39.700), train_loss = 0.57476022, grad/param norm = 1.8945e-01, time/batch = 15.6988s	
20089/25300 (epoch 39.702), train_loss = 0.78835305, grad/param norm = 2.6562e-01, time/batch = 16.3995s	
20090/25300 (epoch 39.704), train_loss = 0.54340760, grad/param norm = 1.8614e-01, time/batch = 15.9904s	
20091/25300 (epoch 39.706), train_loss = 0.68930003, grad/param norm = 2.1313e-01, time/batch = 17.3853s	
20092/25300 (epoch 39.708), train_loss = 0.59528121, grad/param norm = 1.9082e-01, time/batch = 16.2001s	
20093/25300 (epoch 39.709), train_loss = 0.81642504, grad/param norm = 2.4545e-01, time/batch = 16.6410s	
20094/25300 (epoch 39.711), train_loss = 0.87015992, grad/param norm = 2.8786e-01, time/batch = 18.5449s	
20095/25300 (epoch 39.713), train_loss = 0.72731194, grad/param norm = 2.0907e-01, time/batch = 15.2660s	
20096/25300 (epoch 39.715), train_loss = 0.72937579, grad/param norm = 2.0731e-01, time/batch = 16.3310s	
20097/25300 (epoch 39.717), train_loss = 0.62229859, grad/param norm = 2.1826e-01, time/batch = 17.9624s	
20098/25300 (epoch 39.719), train_loss = 0.69943535, grad/param norm = 2.5710e-01, time/batch = 16.5403s	
20099/25300 (epoch 39.721), train_loss = 0.73425118, grad/param norm = 2.3537e-01, time/batch = 15.6440s	
20100/25300 (epoch 39.723), train_loss = 0.70704692, grad/param norm = 2.3774e-01, time/batch = 17.6460s	
20101/25300 (epoch 39.725), train_loss = 0.71392079, grad/param norm = 2.6097e-01, time/batch = 16.4903s	
20102/25300 (epoch 39.727), train_loss = 0.72347311, grad/param norm = 2.3305e-01, time/batch = 15.9860s	
20103/25300 (epoch 39.729), train_loss = 0.69565674, grad/param norm = 2.2704e-01, time/batch = 15.8231s	
20104/25300 (epoch 39.731), train_loss = 0.85066410, grad/param norm = 2.3642e-01, time/batch = 16.3324s	
20105/25300 (epoch 39.733), train_loss = 0.72503563, grad/param norm = 2.1317e-01, time/batch = 15.9185s	
20106/25300 (epoch 39.735), train_loss = 0.91694857, grad/param norm = 2.6096e-01, time/batch = 16.0537s	
20107/25300 (epoch 39.737), train_loss = 0.58273997, grad/param norm = 2.0647e-01, time/batch = 16.3145s	
20108/25300 (epoch 39.739), train_loss = 0.83136666, grad/param norm = 2.6979e-01, time/batch = 15.4609s	
20109/25300 (epoch 39.741), train_loss = 0.72265152, grad/param norm = 2.2695e-01, time/batch = 16.7257s	
20110/25300 (epoch 39.743), train_loss = 0.72484234, grad/param norm = 2.2402e-01, time/batch = 15.6309s	
20111/25300 (epoch 39.745), train_loss = 0.69257311, grad/param norm = 2.3086e-01, time/batch = 15.5289s	
20112/25300 (epoch 39.747), train_loss = 0.61450962, grad/param norm = 1.8367e-01, time/batch = 15.7494s	
20113/25300 (epoch 39.749), train_loss = 0.71531526, grad/param norm = 2.5303e-01, time/batch = 16.5512s	
20114/25300 (epoch 39.751), train_loss = 0.74232145, grad/param norm = 2.2851e-01, time/batch = 15.5616s	
20115/25300 (epoch 39.753), train_loss = 0.60069033, grad/param norm = 2.1088e-01, time/batch = 16.8963s	
20116/25300 (epoch 39.755), train_loss = 0.81269265, grad/param norm = 2.8125e-01, time/batch = 16.8133s	
20117/25300 (epoch 39.757), train_loss = 0.64719241, grad/param norm = 2.0157e-01, time/batch = 15.7196s	
20118/25300 (epoch 39.759), train_loss = 0.64115161, grad/param norm = 2.0991e-01, time/batch = 16.7185s	
20119/25300 (epoch 39.761), train_loss = 0.86454970, grad/param norm = 2.4934e-01, time/batch = 16.5491s	
20120/25300 (epoch 39.763), train_loss = 0.70119002, grad/param norm = 2.0782e-01, time/batch = 16.5832s	
20121/25300 (epoch 39.765), train_loss = 0.68290190, grad/param norm = 2.5738e-01, time/batch = 16.1498s	
20122/25300 (epoch 39.767), train_loss = 0.69511488, grad/param norm = 1.9804e-01, time/batch = 15.9020s	
20123/25300 (epoch 39.769), train_loss = 0.72215569, grad/param norm = 2.5703e-01, time/batch = 17.7185s	
20124/25300 (epoch 39.771), train_loss = 0.78774967, grad/param norm = 2.4844e-01, time/batch = 15.9617s	
20125/25300 (epoch 39.773), train_loss = 0.82217259, grad/param norm = 2.5403e-01, time/batch = 15.6542s	
20126/25300 (epoch 39.775), train_loss = 0.72915399, grad/param norm = 2.0284e-01, time/batch = 15.6766s	
20127/25300 (epoch 39.777), train_loss = 0.67618349, grad/param norm = 2.2831e-01, time/batch = 15.6355s	
20128/25300 (epoch 39.779), train_loss = 0.80525097, grad/param norm = 2.0872e-01, time/batch = 15.3674s	
20129/25300 (epoch 39.781), train_loss = 0.77571175, grad/param norm = 2.5820e-01, time/batch = 15.7952s	
20130/25300 (epoch 39.783), train_loss = 0.84394877, grad/param norm = 2.3959e-01, time/batch = 17.0649s	
20131/25300 (epoch 39.785), train_loss = 0.81822320, grad/param norm = 2.5951e-01, time/batch = 16.6577s	
20132/25300 (epoch 39.787), train_loss = 0.76077335, grad/param norm = 2.4806e-01, time/batch = 16.6347s	
20133/25300 (epoch 39.789), train_loss = 0.86150643, grad/param norm = 2.7106e-01, time/batch = 16.9734s	
20134/25300 (epoch 39.791), train_loss = 0.78197969, grad/param norm = 2.5849e-01, time/batch = 16.3205s	
20135/25300 (epoch 39.792), train_loss = 0.81678577, grad/param norm = 2.3398e-01, time/batch = 15.8971s	
20136/25300 (epoch 39.794), train_loss = 0.68956031, grad/param norm = 2.2948e-01, time/batch = 17.3056s	
20137/25300 (epoch 39.796), train_loss = 0.67833578, grad/param norm = 2.5239e-01, time/batch = 15.7187s	
20138/25300 (epoch 39.798), train_loss = 0.81424184, grad/param norm = 2.6511e-01, time/batch = 16.6555s	
20139/25300 (epoch 39.800), train_loss = 0.68378134, grad/param norm = 2.0068e-01, time/batch = 16.2162s	
20140/25300 (epoch 39.802), train_loss = 0.58995824, grad/param norm = 2.0139e-01, time/batch = 18.9546s	
20141/25300 (epoch 39.804), train_loss = 0.72809703, grad/param norm = 2.0708e-01, time/batch = 18.4644s	
20142/25300 (epoch 39.806), train_loss = 0.77743268, grad/param norm = 2.4822e-01, time/batch = 16.2099s	
20143/25300 (epoch 39.808), train_loss = 0.82328790, grad/param norm = 2.1121e-01, time/batch = 17.2101s	
20144/25300 (epoch 39.810), train_loss = 0.70978804, grad/param norm = 2.4383e-01, time/batch = 15.6890s	
20145/25300 (epoch 39.812), train_loss = 0.83175472, grad/param norm = 2.3376e-01, time/batch = 15.8507s	
20146/25300 (epoch 39.814), train_loss = 0.84457683, grad/param norm = 2.3263e-01, time/batch = 15.6709s	
20147/25300 (epoch 39.816), train_loss = 0.91271855, grad/param norm = 2.4079e-01, time/batch = 15.6573s	
20148/25300 (epoch 39.818), train_loss = 0.81921166, grad/param norm = 2.0930e-01, time/batch = 15.5221s	
20149/25300 (epoch 39.820), train_loss = 0.79848009, grad/param norm = 2.3067e-01, time/batch = 15.6872s	
20150/25300 (epoch 39.822), train_loss = 0.68188157, grad/param norm = 2.8587e-01, time/batch = 15.7872s	
20151/25300 (epoch 39.824), train_loss = 0.80976904, grad/param norm = 2.5335e-01, time/batch = 15.7192s	
20152/25300 (epoch 39.826), train_loss = 0.66961646, grad/param norm = 2.0199e-01, time/batch = 16.5527s	
20153/25300 (epoch 39.828), train_loss = 0.67848751, grad/param norm = 2.4599e-01, time/batch = 15.4873s	
20154/25300 (epoch 39.830), train_loss = 0.76580504, grad/param norm = 2.1291e-01, time/batch = 15.3394s	
20155/25300 (epoch 39.832), train_loss = 0.85908557, grad/param norm = 3.1437e-01, time/batch = 15.6149s	
20156/25300 (epoch 39.834), train_loss = 0.68755093, grad/param norm = 2.2428e-01, time/batch = 16.2543s	
20157/25300 (epoch 39.836), train_loss = 0.71046734, grad/param norm = 2.0204e-01, time/batch = 15.3766s	
20158/25300 (epoch 39.838), train_loss = 0.70019580, grad/param norm = 2.0920e-01, time/batch = 17.3822s	
20159/25300 (epoch 39.840), train_loss = 0.79042487, grad/param norm = 2.4241e-01, time/batch = 15.9944s	
20160/25300 (epoch 39.842), train_loss = 0.73151500, grad/param norm = 2.5523e-01, time/batch = 15.6365s	
20161/25300 (epoch 39.844), train_loss = 0.83618905, grad/param norm = 2.1217e-01, time/batch = 15.9484s	
20162/25300 (epoch 39.846), train_loss = 0.81197466, grad/param norm = 2.2801e-01, time/batch = 16.4897s	
20163/25300 (epoch 39.848), train_loss = 0.79061987, grad/param norm = 2.5652e-01, time/batch = 15.9878s	
20164/25300 (epoch 39.850), train_loss = 0.77972217, grad/param norm = 2.6242e-01, time/batch = 16.4925s	
20165/25300 (epoch 39.852), train_loss = 0.81718149, grad/param norm = 2.2430e-01, time/batch = 15.7295s	
20166/25300 (epoch 39.854), train_loss = 0.85251813, grad/param norm = 2.4536e-01, time/batch = 15.9805s	
20167/25300 (epoch 39.856), train_loss = 0.68208694, grad/param norm = 2.2570e-01, time/batch = 15.9417s	
20168/25300 (epoch 39.858), train_loss = 0.72618135, grad/param norm = 2.5900e-01, time/batch = 16.9593s	
20169/25300 (epoch 39.860), train_loss = 0.63131677, grad/param norm = 2.2729e-01, time/batch = 16.3944s	
20170/25300 (epoch 39.862), train_loss = 0.72868491, grad/param norm = 2.3928e-01, time/batch = 16.1521s	
20171/25300 (epoch 39.864), train_loss = 0.86153298, grad/param norm = 2.1928e-01, time/batch = 17.1415s	
20172/25300 (epoch 39.866), train_loss = 0.69052641, grad/param norm = 2.3315e-01, time/batch = 15.4720s	
20173/25300 (epoch 39.868), train_loss = 0.83415122, grad/param norm = 2.1817e-01, time/batch = 15.9076s	
20174/25300 (epoch 39.870), train_loss = 0.81380028, grad/param norm = 2.3125e-01, time/batch = 16.2438s	
20175/25300 (epoch 39.872), train_loss = 0.75300530, grad/param norm = 2.5595e-01, time/batch = 15.5664s	
20176/25300 (epoch 39.874), train_loss = 0.79810659, grad/param norm = 2.5691e-01, time/batch = 15.3773s	
20177/25300 (epoch 39.875), train_loss = 0.73631362, grad/param norm = 2.7170e-01, time/batch = 15.5605s	
20178/25300 (epoch 39.877), train_loss = 0.69090347, grad/param norm = 1.9994e-01, time/batch = 18.0410s	
20179/25300 (epoch 39.879), train_loss = 0.67390418, grad/param norm = 2.1417e-01, time/batch = 16.2953s	
20180/25300 (epoch 39.881), train_loss = 0.95209332, grad/param norm = 2.7972e-01, time/batch = 15.7149s	
20181/25300 (epoch 39.883), train_loss = 0.93062445, grad/param norm = 2.5189e-01, time/batch = 15.4643s	
20182/25300 (epoch 39.885), train_loss = 0.81093038, grad/param norm = 2.7702e-01, time/batch = 17.2098s	
20183/25300 (epoch 39.887), train_loss = 0.81514524, grad/param norm = 2.2175e-01, time/batch = 15.7214s	
20184/25300 (epoch 39.889), train_loss = 0.89674384, grad/param norm = 3.1667e-01, time/batch = 15.6308s	
20185/25300 (epoch 39.891), train_loss = 0.79599547, grad/param norm = 3.1236e-01, time/batch = 15.3927s	
20186/25300 (epoch 39.893), train_loss = 0.75299299, grad/param norm = 2.5960e-01, time/batch = 15.8221s	
20187/25300 (epoch 39.895), train_loss = 0.59416380, grad/param norm = 2.3248e-01, time/batch = 15.7904s	
20188/25300 (epoch 39.897), train_loss = 0.64703059, grad/param norm = 2.1628e-01, time/batch = 16.4708s	
20189/25300 (epoch 39.899), train_loss = 0.76402516, grad/param norm = 2.7237e-01, time/batch = 15.7380s	
20190/25300 (epoch 39.901), train_loss = 0.81984116, grad/param norm = 2.5181e-01, time/batch = 15.8179s	
20191/25300 (epoch 39.903), train_loss = 0.61180532, grad/param norm = 2.2029e-01, time/batch = 15.6310s	
20192/25300 (epoch 39.905), train_loss = 0.67494820, grad/param norm = 2.3502e-01, time/batch = 16.3105s	
20193/25300 (epoch 39.907), train_loss = 0.68744967, grad/param norm = 2.3020e-01, time/batch = 15.6175s	
20194/25300 (epoch 39.909), train_loss = 0.80611991, grad/param norm = 2.9307e-01, time/batch = 16.0338s	
20195/25300 (epoch 39.911), train_loss = 0.83756995, grad/param norm = 2.5453e-01, time/batch = 15.3987s	
20196/25300 (epoch 39.913), train_loss = 0.91411885, grad/param norm = 2.8714e-01, time/batch = 15.6589s	
20197/25300 (epoch 39.915), train_loss = 0.69703625, grad/param norm = 2.1905e-01, time/batch = 16.8157s	
20198/25300 (epoch 39.917), train_loss = 0.91131469, grad/param norm = 2.5760e-01, time/batch = 22.1419s	
20199/25300 (epoch 39.919), train_loss = 0.86672198, grad/param norm = 2.7018e-01, time/batch = 21.6054s	
20200/25300 (epoch 39.921), train_loss = 0.73017269, grad/param norm = 2.4896e-01, time/batch = 16.6488s	
20201/25300 (epoch 39.923), train_loss = 0.81167157, grad/param norm = 2.4322e-01, time/batch = 15.7257s	
20202/25300 (epoch 39.925), train_loss = 0.74644455, grad/param norm = 2.5202e-01, time/batch = 16.0803s	
20203/25300 (epoch 39.927), train_loss = 0.73630621, grad/param norm = 2.3840e-01, time/batch = 15.9753s	
20204/25300 (epoch 39.929), train_loss = 0.80714444, grad/param norm = 2.3129e-01, time/batch = 16.5709s	
20205/25300 (epoch 39.931), train_loss = 0.80670684, grad/param norm = 2.5632e-01, time/batch = 15.8890s	
20206/25300 (epoch 39.933), train_loss = 0.78972168, grad/param norm = 2.5203e-01, time/batch = 18.2993s	
20207/25300 (epoch 39.935), train_loss = 0.82794821, grad/param norm = 2.3857e-01, time/batch = 18.7948s	
20208/25300 (epoch 39.937), train_loss = 0.62387648, grad/param norm = 2.0360e-01, time/batch = 15.7311s	
20209/25300 (epoch 39.939), train_loss = 0.75406689, grad/param norm = 2.2492e-01, time/batch = 15.7168s	
20210/25300 (epoch 39.941), train_loss = 0.70076047, grad/param norm = 2.9705e-01, time/batch = 16.9768s	
20211/25300 (epoch 39.943), train_loss = 0.77175173, grad/param norm = 2.2211e-01, time/batch = 18.1423s	
20212/25300 (epoch 39.945), train_loss = 0.77599932, grad/param norm = 2.3642e-01, time/batch = 15.9642s	
20213/25300 (epoch 39.947), train_loss = 0.70233144, grad/param norm = 2.3565e-01, time/batch = 18.5442s	
20214/25300 (epoch 39.949), train_loss = 0.77783300, grad/param norm = 2.0822e-01, time/batch = 15.4998s	
20215/25300 (epoch 39.951), train_loss = 0.76510074, grad/param norm = 2.2521e-01, time/batch = 16.0480s	
20216/25300 (epoch 39.953), train_loss = 0.71414229, grad/param norm = 2.4025e-01, time/batch = 15.3634s	
20217/25300 (epoch 39.955), train_loss = 0.93013416, grad/param norm = 2.5930e-01, time/batch = 15.3266s	
20218/25300 (epoch 39.957), train_loss = 0.85392876, grad/param norm = 2.6982e-01, time/batch = 15.2234s	
20219/25300 (epoch 39.958), train_loss = 0.77786784, grad/param norm = 2.7688e-01, time/batch = 15.3352s	
20220/25300 (epoch 39.960), train_loss = 0.91840741, grad/param norm = 2.8343e-01, time/batch = 15.1957s	
20221/25300 (epoch 39.962), train_loss = 0.88675150, grad/param norm = 2.4525e-01, time/batch = 15.2840s	
20222/25300 (epoch 39.964), train_loss = 0.78709798, grad/param norm = 2.8407e-01, time/batch = 15.7853s	
20223/25300 (epoch 39.966), train_loss = 0.66959921, grad/param norm = 2.4095e-01, time/batch = 15.6009s	
20224/25300 (epoch 39.968), train_loss = 0.68665882, grad/param norm = 2.6937e-01, time/batch = 15.2164s	
20225/25300 (epoch 39.970), train_loss = 0.74811677, grad/param norm = 2.6288e-01, time/batch = 15.1256s	
20226/25300 (epoch 39.972), train_loss = 0.76407800, grad/param norm = 2.3505e-01, time/batch = 15.2910s	
20227/25300 (epoch 39.974), train_loss = 0.84250929, grad/param norm = 2.5515e-01, time/batch = 16.4479s	
20228/25300 (epoch 39.976), train_loss = 0.78253140, grad/param norm = 2.4735e-01, time/batch = 15.9571s	
20229/25300 (epoch 39.978), train_loss = 0.72938638, grad/param norm = 2.3858e-01, time/batch = 18.1442s	
20230/25300 (epoch 39.980), train_loss = 0.77712727, grad/param norm = 2.4032e-01, time/batch = 15.9004s	
20231/25300 (epoch 39.982), train_loss = 0.72138656, grad/param norm = 2.5832e-01, time/batch = 16.4783s	
20232/25300 (epoch 39.984), train_loss = 0.76791446, grad/param norm = 2.6079e-01, time/batch = 17.3102s	
20233/25300 (epoch 39.986), train_loss = 0.80780104, grad/param norm = 2.5167e-01, time/batch = 16.0555s	
20234/25300 (epoch 39.988), train_loss = 0.77991122, grad/param norm = 2.5543e-01, time/batch = 17.0352s	
20235/25300 (epoch 39.990), train_loss = 0.76696919, grad/param norm = 2.3202e-01, time/batch = 16.5460s	
20236/25300 (epoch 39.992), train_loss = 0.65358750, grad/param norm = 1.9276e-01, time/batch = 16.0528s	
20237/25300 (epoch 39.994), train_loss = 0.79521924, grad/param norm = 2.6646e-01, time/batch = 15.7299s	
20238/25300 (epoch 39.996), train_loss = 0.91460979, grad/param norm = 3.4565e-01, time/batch = 15.4827s	
20239/25300 (epoch 39.998), train_loss = 0.83222642, grad/param norm = 2.7025e-01, time/batch = 15.4961s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
20240/25300 (epoch 40.000), train_loss = 0.83426731, grad/param norm = 2.9021e-01, time/batch = 15.9767s	
20241/25300 (epoch 40.002), train_loss = 0.78391593, grad/param norm = 2.3093e-01, time/batch = 16.4530s	
20242/25300 (epoch 40.004), train_loss = 0.65129558, grad/param norm = 2.3284e-01, time/batch = 15.9071s	
20243/25300 (epoch 40.006), train_loss = 0.90799541, grad/param norm = 2.7147e-01, time/batch = 16.1462s	
20244/25300 (epoch 40.008), train_loss = 0.78061437, grad/param norm = 2.1699e-01, time/batch = 18.7143s	
20245/25300 (epoch 40.010), train_loss = 0.83283437, grad/param norm = 2.6342e-01, time/batch = 15.5438s	
20246/25300 (epoch 40.012), train_loss = 0.74437820, grad/param norm = 2.2163e-01, time/batch = 15.2601s	
20247/25300 (epoch 40.014), train_loss = 0.89092119, grad/param norm = 2.5354e-01, time/batch = 16.4755s	
20248/25300 (epoch 40.016), train_loss = 0.76235651, grad/param norm = 2.5059e-01, time/batch = 15.7398s	
20249/25300 (epoch 40.018), train_loss = 0.69834214, grad/param norm = 2.4002e-01, time/batch = 15.8143s	
20250/25300 (epoch 40.020), train_loss = 0.79794496, grad/param norm = 2.4306e-01, time/batch = 16.1423s	
20251/25300 (epoch 40.022), train_loss = 0.77636929, grad/param norm = 2.4620e-01, time/batch = 16.0739s	
20252/25300 (epoch 40.024), train_loss = 0.59374938, grad/param norm = 1.8780e-01, time/batch = 16.2297s	
20253/25300 (epoch 40.026), train_loss = 0.72585875, grad/param norm = 2.3713e-01, time/batch = 15.4678s	
20254/25300 (epoch 40.028), train_loss = 0.71066238, grad/param norm = 2.0957e-01, time/batch = 16.2911s	
20255/25300 (epoch 40.030), train_loss = 0.88393872, grad/param norm = 2.7397e-01, time/batch = 15.3283s	
20256/25300 (epoch 40.032), train_loss = 0.70881772, grad/param norm = 2.2482e-01, time/batch = 15.8962s	
20257/25300 (epoch 40.034), train_loss = 0.68130772, grad/param norm = 2.2352e-01, time/batch = 15.8943s	
20258/25300 (epoch 40.036), train_loss = 0.62946833, grad/param norm = 2.0587e-01, time/batch = 16.8061s	
20259/25300 (epoch 40.038), train_loss = 0.56507995, grad/param norm = 1.8299e-01, time/batch = 16.6322s	
20260/25300 (epoch 40.040), train_loss = 0.77026160, grad/param norm = 2.2823e-01, time/batch = 15.8869s	
20261/25300 (epoch 40.042), train_loss = 0.74024218, grad/param norm = 2.0755e-01, time/batch = 15.7398s	
20262/25300 (epoch 40.043), train_loss = 0.65852083, grad/param norm = 1.8441e-01, time/batch = 16.7304s	
20263/25300 (epoch 40.045), train_loss = 0.63409331, grad/param norm = 1.9218e-01, time/batch = 16.0414s	
20264/25300 (epoch 40.047), train_loss = 0.76417403, grad/param norm = 2.3212e-01, time/batch = 16.0536s	
20265/25300 (epoch 40.049), train_loss = 0.77745737, grad/param norm = 3.7887e-01, time/batch = 17.7832s	
20266/25300 (epoch 40.051), train_loss = 0.89789025, grad/param norm = 2.4287e-01, time/batch = 17.0632s	
20267/25300 (epoch 40.053), train_loss = 0.59468444, grad/param norm = 1.7553e-01, time/batch = 17.7050s	
20268/25300 (epoch 40.055), train_loss = 0.62635926, grad/param norm = 2.3422e-01, time/batch = 16.0625s	
20269/25300 (epoch 40.057), train_loss = 0.61907716, grad/param norm = 1.7774e-01, time/batch = 16.7196s	
20270/25300 (epoch 40.059), train_loss = 0.70431272, grad/param norm = 2.1511e-01, time/batch = 15.5696s	
20271/25300 (epoch 40.061), train_loss = 0.68242090, grad/param norm = 1.9426e-01, time/batch = 16.7124s	
20272/25300 (epoch 40.063), train_loss = 0.71172595, grad/param norm = 1.9656e-01, time/batch = 16.5523s	
20273/25300 (epoch 40.065), train_loss = 0.76522766, grad/param norm = 2.5966e-01, time/batch = 17.8845s	
20274/25300 (epoch 40.067), train_loss = 0.80896646, grad/param norm = 2.1909e-01, time/batch = 17.7926s	
20275/25300 (epoch 40.069), train_loss = 0.66591650, grad/param norm = 2.2803e-01, time/batch = 16.4799s	
20276/25300 (epoch 40.071), train_loss = 0.79338638, grad/param norm = 2.8493e-01, time/batch = 17.7929s	
20277/25300 (epoch 40.073), train_loss = 0.72881830, grad/param norm = 2.2998e-01, time/batch = 16.8988s	
20278/25300 (epoch 40.075), train_loss = 0.79107252, grad/param norm = 2.5584e-01, time/batch = 15.9606s	
20279/25300 (epoch 40.077), train_loss = 0.75533532, grad/param norm = 2.2744e-01, time/batch = 15.3063s	
20280/25300 (epoch 40.079), train_loss = 0.67340624, grad/param norm = 2.1842e-01, time/batch = 16.7185s	
20281/25300 (epoch 40.081), train_loss = 0.73437368, grad/param norm = 2.0395e-01, time/batch = 16.6321s	
20282/25300 (epoch 40.083), train_loss = 0.76693877, grad/param norm = 2.2373e-01, time/batch = 16.2202s	
20283/25300 (epoch 40.085), train_loss = 0.91278660, grad/param norm = 2.4255e-01, time/batch = 15.5831s	
20284/25300 (epoch 40.087), train_loss = 0.80808073, grad/param norm = 1.9354e-01, time/batch = 17.6409s	
20285/25300 (epoch 40.089), train_loss = 0.77382008, grad/param norm = 2.2100e-01, time/batch = 16.5305s	
20286/25300 (epoch 40.091), train_loss = 0.91846267, grad/param norm = 2.6699e-01, time/batch = 16.8309s	
20287/25300 (epoch 40.093), train_loss = 0.84726569, grad/param norm = 2.5792e-01, time/batch = 17.8117s	
20288/25300 (epoch 40.095), train_loss = 0.81469706, grad/param norm = 2.5519e-01, time/batch = 19.5297s	
20289/25300 (epoch 40.097), train_loss = 0.80351688, grad/param norm = 2.3829e-01, time/batch = 16.3851s	
20290/25300 (epoch 40.099), train_loss = 0.81134779, grad/param norm = 2.5890e-01, time/batch = 15.6285s	
20291/25300 (epoch 40.101), train_loss = 0.74324586, grad/param norm = 2.3862e-01, time/batch = 18.1341s	
20292/25300 (epoch 40.103), train_loss = 0.77396383, grad/param norm = 2.1442e-01, time/batch = 16.1493s	
20293/25300 (epoch 40.105), train_loss = 0.79632464, grad/param norm = 2.3522e-01, time/batch = 16.7059s	
20294/25300 (epoch 40.107), train_loss = 0.78550163, grad/param norm = 2.4934e-01, time/batch = 16.6587s	
20295/25300 (epoch 40.109), train_loss = 0.74366459, grad/param norm = 2.3071e-01, time/batch = 18.3884s	
20296/25300 (epoch 40.111), train_loss = 0.73297513, grad/param norm = 2.2656e-01, time/batch = 15.7048s	
20297/25300 (epoch 40.113), train_loss = 0.71849113, grad/param norm = 2.5194e-01, time/batch = 16.2336s	
20298/25300 (epoch 40.115), train_loss = 0.73958240, grad/param norm = 2.4484e-01, time/batch = 16.8133s	
20299/25300 (epoch 40.117), train_loss = 0.82088014, grad/param norm = 2.2460e-01, time/batch = 17.2990s	
20300/25300 (epoch 40.119), train_loss = 0.70667659, grad/param norm = 2.2658e-01, time/batch = 16.0230s	
20301/25300 (epoch 40.121), train_loss = 0.74801745, grad/param norm = 2.6025e-01, time/batch = 15.9140s	
20302/25300 (epoch 40.123), train_loss = 0.69440761, grad/param norm = 2.2505e-01, time/batch = 16.2219s	
20303/25300 (epoch 40.125), train_loss = 0.85435074, grad/param norm = 2.7918e-01, time/batch = 17.2198s	
20304/25300 (epoch 40.126), train_loss = 0.75684820, grad/param norm = 2.0498e-01, time/batch = 17.2171s	
20305/25300 (epoch 40.128), train_loss = 0.71562456, grad/param norm = 2.1242e-01, time/batch = 16.7963s	
20306/25300 (epoch 40.130), train_loss = 0.59469455, grad/param norm = 1.9269e-01, time/batch = 15.9507s	
20307/25300 (epoch 40.132), train_loss = 0.62057084, grad/param norm = 2.4514e-01, time/batch = 16.0407s	
20308/25300 (epoch 40.134), train_loss = 0.63925599, grad/param norm = 2.1787e-01, time/batch = 16.2106s	
20309/25300 (epoch 40.136), train_loss = 0.73211317, grad/param norm = 2.2170e-01, time/batch = 16.3044s	
20310/25300 (epoch 40.138), train_loss = 0.65673749, grad/param norm = 2.0451e-01, time/batch = 15.2102s	
20311/25300 (epoch 40.140), train_loss = 0.61786911, grad/param norm = 1.9508e-01, time/batch = 15.3619s	
20312/25300 (epoch 40.142), train_loss = 0.84073356, grad/param norm = 2.6465e-01, time/batch = 15.3479s	
20313/25300 (epoch 40.144), train_loss = 0.81809633, grad/param norm = 2.3651e-01, time/batch = 15.3737s	
20314/25300 (epoch 40.146), train_loss = 0.71760877, grad/param norm = 2.6487e-01, time/batch = 15.6426s	
20315/25300 (epoch 40.148), train_loss = 0.73599082, grad/param norm = 2.1178e-01, time/batch = 15.4602s	
20316/25300 (epoch 40.150), train_loss = 0.75933295, grad/param norm = 2.2657e-01, time/batch = 16.0497s	
20317/25300 (epoch 40.152), train_loss = 0.84499427, grad/param norm = 2.4963e-01, time/batch = 16.3979s	
20318/25300 (epoch 40.154), train_loss = 0.63096671, grad/param norm = 2.1205e-01, time/batch = 16.9621s	
20319/25300 (epoch 40.156), train_loss = 0.75587047, grad/param norm = 2.5263e-01, time/batch = 16.8877s	
20320/25300 (epoch 40.158), train_loss = 0.64137004, grad/param norm = 2.0978e-01, time/batch = 17.2230s	
20321/25300 (epoch 40.160), train_loss = 0.72920412, grad/param norm = 2.3864e-01, time/batch = 15.7271s	
20322/25300 (epoch 40.162), train_loss = 0.66565847, grad/param norm = 2.1309e-01, time/batch = 15.7366s	
20323/25300 (epoch 40.164), train_loss = 0.80072987, grad/param norm = 2.4722e-01, time/batch = 17.0451s	
20324/25300 (epoch 40.166), train_loss = 0.72022256, grad/param norm = 1.9880e-01, time/batch = 16.8215s	
20325/25300 (epoch 40.168), train_loss = 0.68598040, grad/param norm = 1.8572e-01, time/batch = 15.7826s	
20326/25300 (epoch 40.170), train_loss = 0.68085449, grad/param norm = 2.4440e-01, time/batch = 15.9782s	
20327/25300 (epoch 40.172), train_loss = 0.62481720, grad/param norm = 2.0860e-01, time/batch = 15.5064s	
20328/25300 (epoch 40.174), train_loss = 0.66226563, grad/param norm = 2.2987e-01, time/batch = 15.4840s	
20329/25300 (epoch 40.176), train_loss = 0.63923442, grad/param norm = 2.6230e-01, time/batch = 16.3027s	
20330/25300 (epoch 40.178), train_loss = 0.85838575, grad/param norm = 2.3998e-01, time/batch = 16.1166s	
20331/25300 (epoch 40.180), train_loss = 0.59486335, grad/param norm = 2.1591e-01, time/batch = 16.6401s	
20332/25300 (epoch 40.182), train_loss = 0.69918655, grad/param norm = 2.5879e-01, time/batch = 15.6019s	
20333/25300 (epoch 40.184), train_loss = 0.66306638, grad/param norm = 2.4838e-01, time/batch = 15.5363s	
20334/25300 (epoch 40.186), train_loss = 0.63281178, grad/param norm = 2.6401e-01, time/batch = 16.8074s	
20335/25300 (epoch 40.188), train_loss = 0.73855927, grad/param norm = 3.1652e-01, time/batch = 16.8783s	
20336/25300 (epoch 40.190), train_loss = 0.75223652, grad/param norm = 2.2748e-01, time/batch = 15.3800s	
20337/25300 (epoch 40.192), train_loss = 0.69522323, grad/param norm = 2.0230e-01, time/batch = 18.2129s	
20338/25300 (epoch 40.194), train_loss = 0.68011565, grad/param norm = 2.1941e-01, time/batch = 16.3920s	
20339/25300 (epoch 40.196), train_loss = 0.80740342, grad/param norm = 2.6607e-01, time/batch = 15.7883s	
20340/25300 (epoch 40.198), train_loss = 0.69915641, grad/param norm = 2.6906e-01, time/batch = 15.6324s	
20341/25300 (epoch 40.200), train_loss = 0.72234586, grad/param norm = 2.5600e-01, time/batch = 16.5662s	
20342/25300 (epoch 40.202), train_loss = 0.72326664, grad/param norm = 2.4130e-01, time/batch = 17.2898s	
20343/25300 (epoch 40.204), train_loss = 0.70788470, grad/param norm = 2.0222e-01, time/batch = 16.2936s	
20344/25300 (epoch 40.206), train_loss = 0.82731716, grad/param norm = 2.5763e-01, time/batch = 15.7402s	
20345/25300 (epoch 40.208), train_loss = 0.67561829, grad/param norm = 2.1511e-01, time/batch = 15.8122s	
20346/25300 (epoch 40.209), train_loss = 0.62448467, grad/param norm = 2.1243e-01, time/batch = 15.9822s	
20347/25300 (epoch 40.211), train_loss = 0.70642943, grad/param norm = 2.1717e-01, time/batch = 15.9671s	
20348/25300 (epoch 40.213), train_loss = 0.75256608, grad/param norm = 2.5213e-01, time/batch = 16.1152s	
20349/25300 (epoch 40.215), train_loss = 0.76567823, grad/param norm = 2.1209e-01, time/batch = 16.3216s	
20350/25300 (epoch 40.217), train_loss = 0.78803728, grad/param norm = 3.3658e-01, time/batch = 15.3978s	
20351/25300 (epoch 40.219), train_loss = 0.78479797, grad/param norm = 2.7113e-01, time/batch = 15.8756s	
20352/25300 (epoch 40.221), train_loss = 0.83804255, grad/param norm = 2.4729e-01, time/batch = 16.2197s	
20353/25300 (epoch 40.223), train_loss = 0.79737347, grad/param norm = 2.7968e-01, time/batch = 16.3613s	
20354/25300 (epoch 40.225), train_loss = 1.00165920, grad/param norm = 3.8880e-01, time/batch = 16.1310s	
20355/25300 (epoch 40.227), train_loss = 0.88210605, grad/param norm = 2.4286e-01, time/batch = 15.8199s	
20356/25300 (epoch 40.229), train_loss = 0.71853083, grad/param norm = 2.2751e-01, time/batch = 16.9727s	
20357/25300 (epoch 40.231), train_loss = 0.75913970, grad/param norm = 2.8387e-01, time/batch = 16.8109s	
20358/25300 (epoch 40.233), train_loss = 0.80736444, grad/param norm = 2.9083e-01, time/batch = 16.3852s	
20359/25300 (epoch 40.235), train_loss = 0.71311313, grad/param norm = 2.0827e-01, time/batch = 16.5615s	
20360/25300 (epoch 40.237), train_loss = 0.85485476, grad/param norm = 2.6828e-01, time/batch = 15.9844s	
20361/25300 (epoch 40.239), train_loss = 0.68684265, grad/param norm = 2.1487e-01, time/batch = 18.2113s	
20362/25300 (epoch 40.241), train_loss = 0.87836200, grad/param norm = 2.2181e-01, time/batch = 15.6343s	
20363/25300 (epoch 40.243), train_loss = 0.97144216, grad/param norm = 2.7576e-01, time/batch = 16.7256s	
20364/25300 (epoch 40.245), train_loss = 0.71776944, grad/param norm = 2.4369e-01, time/batch = 16.7382s	
20365/25300 (epoch 40.247), train_loss = 0.78403276, grad/param norm = 2.2742e-01, time/batch = 16.8672s	
20366/25300 (epoch 40.249), train_loss = 0.67020588, grad/param norm = 2.0064e-01, time/batch = 16.3151s	
20367/25300 (epoch 40.251), train_loss = 0.65276473, grad/param norm = 2.1412e-01, time/batch = 16.7244s	
20368/25300 (epoch 40.253), train_loss = 0.72434020, grad/param norm = 2.3290e-01, time/batch = 16.8954s	
20369/25300 (epoch 40.255), train_loss = 0.69191047, grad/param norm = 2.4536e-01, time/batch = 16.2180s	
20370/25300 (epoch 40.257), train_loss = 0.70222850, grad/param norm = 2.4407e-01, time/batch = 15.3690s	
20371/25300 (epoch 40.259), train_loss = 0.86237373, grad/param norm = 3.2552e-01, time/batch = 16.0776s	
20372/25300 (epoch 40.261), train_loss = 0.83753482, grad/param norm = 2.8676e-01, time/batch = 16.8133s	
20373/25300 (epoch 40.263), train_loss = 0.85575051, grad/param norm = 2.5691e-01, time/batch = 16.6298s	
20374/25300 (epoch 40.265), train_loss = 0.87204070, grad/param norm = 2.6958e-01, time/batch = 17.6442s	
20375/25300 (epoch 40.267), train_loss = 0.77937527, grad/param norm = 2.3995e-01, time/batch = 17.7388s	
20376/25300 (epoch 40.269), train_loss = 0.63412290, grad/param norm = 2.1566e-01, time/batch = 16.8882s	
20377/25300 (epoch 40.271), train_loss = 0.68971796, grad/param norm = 2.8524e-01, time/batch = 15.6487s	
20378/25300 (epoch 40.273), train_loss = 0.80756738, grad/param norm = 2.7119e-01, time/batch = 17.6410s	
20379/25300 (epoch 40.275), train_loss = 0.72370673, grad/param norm = 2.0629e-01, time/batch = 17.8800s	
20380/25300 (epoch 40.277), train_loss = 0.65966348, grad/param norm = 2.7817e-01, time/batch = 16.0413s	
20381/25300 (epoch 40.279), train_loss = 0.74815873, grad/param norm = 2.4476e-01, time/batch = 15.5716s	
20382/25300 (epoch 40.281), train_loss = 0.89696688, grad/param norm = 2.6173e-01, time/batch = 15.3908s	
20383/25300 (epoch 40.283), train_loss = 0.69201701, grad/param norm = 2.5511e-01, time/batch = 15.1561s	
20384/25300 (epoch 40.285), train_loss = 0.73715085, grad/param norm = 2.3653e-01, time/batch = 16.0698s	
20385/25300 (epoch 40.287), train_loss = 0.85184463, grad/param norm = 2.1899e-01, time/batch = 18.1428s	
20386/25300 (epoch 40.289), train_loss = 0.72333122, grad/param norm = 2.4199e-01, time/batch = 16.4066s	
20387/25300 (epoch 40.291), train_loss = 0.72576194, grad/param norm = 2.5642e-01, time/batch = 15.9467s	
20388/25300 (epoch 40.292), train_loss = 0.93210734, grad/param norm = 2.4090e-01, time/batch = 15.8975s	
20389/25300 (epoch 40.294), train_loss = 0.76966842, grad/param norm = 2.4106e-01, time/batch = 15.6219s	
20390/25300 (epoch 40.296), train_loss = 0.67112762, grad/param norm = 2.1776e-01, time/batch = 16.2826s	
20391/25300 (epoch 40.298), train_loss = 0.82864923, grad/param norm = 2.4537e-01, time/batch = 15.8662s	
20392/25300 (epoch 40.300), train_loss = 0.82160307, grad/param norm = 2.2805e-01, time/batch = 17.8846s	
20393/25300 (epoch 40.302), train_loss = 0.61909553, grad/param norm = 3.4702e-01, time/batch = 17.4712s	
20394/25300 (epoch 40.304), train_loss = 0.86626821, grad/param norm = 2.1202e-01, time/batch = 16.8908s	
20395/25300 (epoch 40.306), train_loss = 0.59479304, grad/param norm = 1.9683e-01, time/batch = 16.3902s	
20396/25300 (epoch 40.308), train_loss = 0.82426391, grad/param norm = 2.3436e-01, time/batch = 19.1156s	
20397/25300 (epoch 40.310), train_loss = 0.65533662, grad/param norm = 2.5406e-01, time/batch = 16.7126s	
20398/25300 (epoch 40.312), train_loss = 0.77341688, grad/param norm = 1.9999e-01, time/batch = 16.2054s	
20399/25300 (epoch 40.314), train_loss = 0.64526157, grad/param norm = 1.9064e-01, time/batch = 16.6170s	
20400/25300 (epoch 40.316), train_loss = 0.76763634, grad/param norm = 2.2358e-01, time/batch = 17.1265s	
20401/25300 (epoch 40.318), train_loss = 0.60683107, grad/param norm = 2.0279e-01, time/batch = 17.0598s	
20402/25300 (epoch 40.320), train_loss = 0.67308927, grad/param norm = 1.8554e-01, time/batch = 18.1298s	
20403/25300 (epoch 40.322), train_loss = 0.87664699, grad/param norm = 2.3423e-01, time/batch = 17.2347s	
20404/25300 (epoch 40.324), train_loss = 0.67298832, grad/param norm = 2.0439e-01, time/batch = 17.3909s	
20405/25300 (epoch 40.326), train_loss = 0.60408901, grad/param norm = 1.8908e-01, time/batch = 16.3104s	
20406/25300 (epoch 40.328), train_loss = 0.61115644, grad/param norm = 2.2476e-01, time/batch = 16.3056s	
20407/25300 (epoch 40.330), train_loss = 0.69339916, grad/param norm = 2.1262e-01, time/batch = 16.8837s	
20408/25300 (epoch 40.332), train_loss = 0.75232015, grad/param norm = 2.7277e-01, time/batch = 16.3864s	
20409/25300 (epoch 40.334), train_loss = 0.59388970, grad/param norm = 2.1202e-01, time/batch = 16.7934s	
20410/25300 (epoch 40.336), train_loss = 0.62850416, grad/param norm = 2.3660e-01, time/batch = 15.6431s	
20411/25300 (epoch 40.338), train_loss = 0.63547127, grad/param norm = 2.2266e-01, time/batch = 18.2080s	
20412/25300 (epoch 40.340), train_loss = 0.68787008, grad/param norm = 2.3711e-01, time/batch = 16.0451s	
20413/25300 (epoch 40.342), train_loss = 0.69864850, grad/param norm = 2.5385e-01, time/batch = 15.8945s	
20414/25300 (epoch 40.344), train_loss = 0.78620613, grad/param norm = 2.5097e-01, time/batch = 15.9885s	
20415/25300 (epoch 40.346), train_loss = 0.68867102, grad/param norm = 2.2953e-01, time/batch = 18.1879s	
20416/25300 (epoch 40.348), train_loss = 0.66015076, grad/param norm = 2.3179e-01, time/batch = 30.4039s	
20417/25300 (epoch 40.350), train_loss = 0.68557593, grad/param norm = 2.2042e-01, time/batch = 15.5665s	
20418/25300 (epoch 40.352), train_loss = 0.72532753, grad/param norm = 2.2770e-01, time/batch = 16.1488s	
20419/25300 (epoch 40.354), train_loss = 0.69811728, grad/param norm = 2.5759e-01, time/batch = 18.4580s	
20420/25300 (epoch 40.356), train_loss = 0.71643216, grad/param norm = 2.2309e-01, time/batch = 15.7167s	
20421/25300 (epoch 40.358), train_loss = 0.71713365, grad/param norm = 2.1699e-01, time/batch = 17.0589s	
20422/25300 (epoch 40.360), train_loss = 0.67402864, grad/param norm = 2.3147e-01, time/batch = 15.9645s	
20423/25300 (epoch 40.362), train_loss = 0.61056541, grad/param norm = 2.2270e-01, time/batch = 17.7274s	
20424/25300 (epoch 40.364), train_loss = 0.64115029, grad/param norm = 2.3158e-01, time/batch = 16.3974s	
20425/25300 (epoch 40.366), train_loss = 0.63389782, grad/param norm = 2.2919e-01, time/batch = 16.0471s	
20426/25300 (epoch 40.368), train_loss = 0.69654978, grad/param norm = 2.2181e-01, time/batch = 16.8864s	
20427/25300 (epoch 40.370), train_loss = 0.65965580, grad/param norm = 2.4363e-01, time/batch = 18.7122s	
20428/25300 (epoch 40.372), train_loss = 0.66064191, grad/param norm = 2.7319e-01, time/batch = 17.4446s	
20429/25300 (epoch 40.374), train_loss = 0.60190460, grad/param norm = 2.0499e-01, time/batch = 16.6276s	
20430/25300 (epoch 40.375), train_loss = 0.80462131, grad/param norm = 2.6785e-01, time/batch = 16.2394s	
20431/25300 (epoch 40.377), train_loss = 0.77729444, grad/param norm = 2.3096e-01, time/batch = 15.6352s	
20432/25300 (epoch 40.379), train_loss = 0.74477698, grad/param norm = 2.2243e-01, time/batch = 16.3026s	
20433/25300 (epoch 40.381), train_loss = 0.71021377, grad/param norm = 2.3794e-01, time/batch = 15.7278s	
20434/25300 (epoch 40.383), train_loss = 0.66366707, grad/param norm = 1.9988e-01, time/batch = 15.6515s	
20435/25300 (epoch 40.385), train_loss = 0.73142521, grad/param norm = 2.1282e-01, time/batch = 16.8220s	
20436/25300 (epoch 40.387), train_loss = 0.72459700, grad/param norm = 2.5392e-01, time/batch = 16.5536s	
20437/25300 (epoch 40.389), train_loss = 0.69891120, grad/param norm = 2.2077e-01, time/batch = 16.8888s	
20438/25300 (epoch 40.391), train_loss = 0.70145231, grad/param norm = 2.0790e-01, time/batch = 16.4810s	
20439/25300 (epoch 40.393), train_loss = 0.70166611, grad/param norm = 2.1198e-01, time/batch = 18.8799s	
20440/25300 (epoch 40.395), train_loss = 0.58175711, grad/param norm = 1.9309e-01, time/batch = 15.9633s	
20441/25300 (epoch 40.397), train_loss = 0.55111869, grad/param norm = 2.2312e-01, time/batch = 17.0523s	
20442/25300 (epoch 40.399), train_loss = 0.62278878, grad/param norm = 2.2593e-01, time/batch = 16.4544s	
20443/25300 (epoch 40.401), train_loss = 0.75615107, grad/param norm = 2.7669e-01, time/batch = 15.7165s	
20444/25300 (epoch 40.403), train_loss = 0.77872906, grad/param norm = 3.4182e-01, time/batch = 15.7022s	
20445/25300 (epoch 40.405), train_loss = 0.67803960, grad/param norm = 2.4147e-01, time/batch = 17.5672s	
20446/25300 (epoch 40.407), train_loss = 0.71390520, grad/param norm = 2.2635e-01, time/batch = 17.5645s	
20447/25300 (epoch 40.409), train_loss = 0.63837505, grad/param norm = 2.0220e-01, time/batch = 15.7187s	
20448/25300 (epoch 40.411), train_loss = 0.66714910, grad/param norm = 2.5033e-01, time/batch = 17.5534s	
20449/25300 (epoch 40.413), train_loss = 0.59702600, grad/param norm = 2.3467e-01, time/batch = 16.8224s	
20450/25300 (epoch 40.415), train_loss = 0.62527195, grad/param norm = 1.8719e-01, time/batch = 17.7768s	
20451/25300 (epoch 40.417), train_loss = 0.60555811, grad/param norm = 2.0858e-01, time/batch = 16.0715s	
20452/25300 (epoch 40.419), train_loss = 0.51604133, grad/param norm = 1.6076e-01, time/batch = 15.9007s	
20453/25300 (epoch 40.421), train_loss = 0.60637125, grad/param norm = 1.7466e-01, time/batch = 16.4894s	
20454/25300 (epoch 40.423), train_loss = 0.59441798, grad/param norm = 2.0089e-01, time/batch = 15.3162s	
20455/25300 (epoch 40.425), train_loss = 0.69464320, grad/param norm = 2.5708e-01, time/batch = 15.5725s	
20456/25300 (epoch 40.427), train_loss = 0.76836567, grad/param norm = 2.3134e-01, time/batch = 15.8067s	
20457/25300 (epoch 40.429), train_loss = 0.80742895, grad/param norm = 2.5573e-01, time/batch = 15.8939s	
20458/25300 (epoch 40.431), train_loss = 0.71380709, grad/param norm = 2.2148e-01, time/batch = 15.7127s	
20459/25300 (epoch 40.433), train_loss = 0.74682754, grad/param norm = 1.8165e-01, time/batch = 16.6417s	
20460/25300 (epoch 40.435), train_loss = 0.64112501, grad/param norm = 2.0670e-01, time/batch = 16.0586s	
20461/25300 (epoch 40.437), train_loss = 0.63923299, grad/param norm = 2.1418e-01, time/batch = 16.2055s	
20462/25300 (epoch 40.439), train_loss = 0.73272728, grad/param norm = 2.1813e-01, time/batch = 15.6295s	
20463/25300 (epoch 40.441), train_loss = 0.76124112, grad/param norm = 2.9022e-01, time/batch = 16.4611s	
20464/25300 (epoch 40.443), train_loss = 0.84272513, grad/param norm = 2.5051e-01, time/batch = 16.5597s	
20465/25300 (epoch 40.445), train_loss = 0.79991633, grad/param norm = 2.3247e-01, time/batch = 15.5472s	
20466/25300 (epoch 40.447), train_loss = 0.63807109, grad/param norm = 1.9020e-01, time/batch = 16.3012s	
20467/25300 (epoch 40.449), train_loss = 0.56908579, grad/param norm = 2.0822e-01, time/batch = 15.9792s	
20468/25300 (epoch 40.451), train_loss = 0.90076069, grad/param norm = 2.5958e-01, time/batch = 17.5561s	
20469/25300 (epoch 40.453), train_loss = 0.78615956, grad/param norm = 2.6783e-01, time/batch = 16.0290s	
20470/25300 (epoch 40.455), train_loss = 0.75148332, grad/param norm = 2.6287e-01, time/batch = 16.2992s	
20471/25300 (epoch 40.457), train_loss = 0.65026943, grad/param norm = 2.3279e-01, time/batch = 15.9536s	
20472/25300 (epoch 40.458), train_loss = 0.68268067, grad/param norm = 2.3826e-01, time/batch = 15.7003s	
20473/25300 (epoch 40.460), train_loss = 0.68250840, grad/param norm = 2.1448e-01, time/batch = 15.6648s	
20474/25300 (epoch 40.462), train_loss = 0.50425134, grad/param norm = 2.0651e-01, time/batch = 15.4085s	
20475/25300 (epoch 40.464), train_loss = 0.77477387, grad/param norm = 2.3227e-01, time/batch = 15.4928s	
20476/25300 (epoch 40.466), train_loss = 0.72618284, grad/param norm = 2.3570e-01, time/batch = 16.1077s	
20477/25300 (epoch 40.468), train_loss = 0.74990031, grad/param norm = 2.5222e-01, time/batch = 15.4189s	
20478/25300 (epoch 40.470), train_loss = 0.69277413, grad/param norm = 1.9326e-01, time/batch = 16.7243s	
20479/25300 (epoch 40.472), train_loss = 0.59242506, grad/param norm = 2.0317e-01, time/batch = 16.1272s	
20480/25300 (epoch 40.474), train_loss = 0.75095982, grad/param norm = 2.2834e-01, time/batch = 15.4349s	
20481/25300 (epoch 40.476), train_loss = 0.67235172, grad/param norm = 2.4070e-01, time/batch = 15.5554s	
20482/25300 (epoch 40.478), train_loss = 0.73734087, grad/param norm = 2.4479e-01, time/batch = 16.3828s	
20483/25300 (epoch 40.480), train_loss = 0.68263071, grad/param norm = 2.0987e-01, time/batch = 15.8854s	
20484/25300 (epoch 40.482), train_loss = 0.73171209, grad/param norm = 2.2386e-01, time/batch = 15.6279s	
20485/25300 (epoch 40.484), train_loss = 0.76448639, grad/param norm = 2.4172e-01, time/batch = 16.9717s	
20486/25300 (epoch 40.486), train_loss = 0.71192094, grad/param norm = 2.5786e-01, time/batch = 17.3912s	
20487/25300 (epoch 40.488), train_loss = 0.87535334, grad/param norm = 3.2576e-01, time/batch = 16.1203s	
20488/25300 (epoch 40.490), train_loss = 0.72127039, grad/param norm = 2.3416e-01, time/batch = 16.1327s	
20489/25300 (epoch 40.492), train_loss = 0.82334621, grad/param norm = 2.2124e-01, time/batch = 15.4847s	
20490/25300 (epoch 40.494), train_loss = 0.72442705, grad/param norm = 2.1326e-01, time/batch = 16.1527s	
20491/25300 (epoch 40.496), train_loss = 0.76584574, grad/param norm = 2.3566e-01, time/batch = 16.2912s	
20492/25300 (epoch 40.498), train_loss = 0.70903820, grad/param norm = 2.2059e-01, time/batch = 15.5335s	
20493/25300 (epoch 40.500), train_loss = 0.82985515, grad/param norm = 2.2894e-01, time/batch = 16.1413s	
20494/25300 (epoch 40.502), train_loss = 0.79462951, grad/param norm = 3.0175e-01, time/batch = 15.7961s	
20495/25300 (epoch 40.504), train_loss = 0.67897014, grad/param norm = 2.1112e-01, time/batch = 15.6264s	
20496/25300 (epoch 40.506), train_loss = 0.59832125, grad/param norm = 2.1904e-01, time/batch = 16.8065s	
20497/25300 (epoch 40.508), train_loss = 0.71114249, grad/param norm = 2.5614e-01, time/batch = 16.2020s	
20498/25300 (epoch 40.510), train_loss = 0.69622191, grad/param norm = 2.4698e-01, time/batch = 15.5453s	
20499/25300 (epoch 40.512), train_loss = 0.56127299, grad/param norm = 1.9946e-01, time/batch = 15.3851s	
20500/25300 (epoch 40.514), train_loss = 0.70432702, grad/param norm = 2.1300e-01, time/batch = 15.5592s	
20501/25300 (epoch 40.516), train_loss = 0.77072077, grad/param norm = 2.4553e-01, time/batch = 15.3172s	
20502/25300 (epoch 40.518), train_loss = 0.78692848, grad/param norm = 2.3148e-01, time/batch = 16.2996s	
20503/25300 (epoch 40.520), train_loss = 0.59489906, grad/param norm = 1.9702e-01, time/batch = 15.7983s	
20504/25300 (epoch 40.522), train_loss = 0.66212912, grad/param norm = 3.2554e-01, time/batch = 15.9791s	
20505/25300 (epoch 40.524), train_loss = 0.63951740, grad/param norm = 2.1360e-01, time/batch = 16.2160s	
20506/25300 (epoch 40.526), train_loss = 0.82503362, grad/param norm = 2.6059e-01, time/batch = 16.2120s	
20507/25300 (epoch 40.528), train_loss = 0.87225169, grad/param norm = 2.6812e-01, time/batch = 15.6409s	
20508/25300 (epoch 40.530), train_loss = 0.78540791, grad/param norm = 2.4446e-01, time/batch = 16.3898s	
20509/25300 (epoch 40.532), train_loss = 0.70065804, grad/param norm = 2.4372e-01, time/batch = 16.2308s	
20510/25300 (epoch 40.534), train_loss = 0.67765747, grad/param norm = 2.3355e-01, time/batch = 15.8006s	
20511/25300 (epoch 40.536), train_loss = 0.58117462, grad/param norm = 2.3864e-01, time/batch = 15.9570s	
20512/25300 (epoch 40.538), train_loss = 0.61769701, grad/param norm = 1.9042e-01, time/batch = 15.7418s	
20513/25300 (epoch 40.540), train_loss = 0.61196790, grad/param norm = 2.0268e-01, time/batch = 15.8980s	
20514/25300 (epoch 40.542), train_loss = 0.59061037, grad/param norm = 1.9448e-01, time/batch = 15.7180s	
20515/25300 (epoch 40.543), train_loss = 0.59073799, grad/param norm = 2.1134e-01, time/batch = 15.8972s	
20516/25300 (epoch 40.545), train_loss = 0.89217289, grad/param norm = 3.0923e-01, time/batch = 15.6259s	
20517/25300 (epoch 40.547), train_loss = 0.78567787, grad/param norm = 2.2175e-01, time/batch = 15.8013s	
20518/25300 (epoch 40.549), train_loss = 0.89419200, grad/param norm = 3.0185e-01, time/batch = 15.8875s	
20519/25300 (epoch 40.551), train_loss = 0.82829831, grad/param norm = 2.2904e-01, time/batch = 15.7214s	
20520/25300 (epoch 40.553), train_loss = 0.67717753, grad/param norm = 2.6386e-01, time/batch = 15.6322s	
20521/25300 (epoch 40.555), train_loss = 0.72897506, grad/param norm = 2.2596e-01, time/batch = 15.9748s	
20522/25300 (epoch 40.557), train_loss = 0.78933473, grad/param norm = 2.5970e-01, time/batch = 16.3846s	
20523/25300 (epoch 40.559), train_loss = 0.83227895, grad/param norm = 2.3559e-01, time/batch = 16.2280s	
20524/25300 (epoch 40.561), train_loss = 0.86322146, grad/param norm = 2.8147e-01, time/batch = 15.7381s	
20525/25300 (epoch 40.563), train_loss = 0.83200170, grad/param norm = 2.6461e-01, time/batch = 15.7887s	
20526/25300 (epoch 40.565), train_loss = 0.61987229, grad/param norm = 2.2499e-01, time/batch = 15.7152s	
20527/25300 (epoch 40.567), train_loss = 0.55742130, grad/param norm = 2.0272e-01, time/batch = 15.7130s	
20528/25300 (epoch 40.569), train_loss = 0.72838543, grad/param norm = 2.4513e-01, time/batch = 16.3732s	
20529/25300 (epoch 40.571), train_loss = 0.80192873, grad/param norm = 2.4944e-01, time/batch = 15.6949s	
20530/25300 (epoch 40.573), train_loss = 0.71276317, grad/param norm = 2.3142e-01, time/batch = 16.1246s	
20531/25300 (epoch 40.575), train_loss = 0.74784284, grad/param norm = 2.4635e-01, time/batch = 17.6432s	
20532/25300 (epoch 40.577), train_loss = 0.67690938, grad/param norm = 2.4578e-01, time/batch = 16.5470s	
20533/25300 (epoch 40.579), train_loss = 0.85549422, grad/param norm = 2.6639e-01, time/batch = 16.4721s	
20534/25300 (epoch 40.581), train_loss = 0.78539404, grad/param norm = 2.6981e-01, time/batch = 15.3729s	
20535/25300 (epoch 40.583), train_loss = 0.58292487, grad/param norm = 2.3851e-01, time/batch = 16.8885s	
20536/25300 (epoch 40.585), train_loss = 0.58934544, grad/param norm = 1.9565e-01, time/batch = 15.3690s	
20537/25300 (epoch 40.587), train_loss = 0.70255712, grad/param norm = 2.0996e-01, time/batch = 15.7104s	
20538/25300 (epoch 40.589), train_loss = 0.63907133, grad/param norm = 1.8676e-01, time/batch = 16.0572s	
20539/25300 (epoch 40.591), train_loss = 0.60770909, grad/param norm = 3.1160e-01, time/batch = 16.1518s	
20540/25300 (epoch 40.593), train_loss = 0.80472393, grad/param norm = 2.5251e-01, time/batch = 15.3720s	
20541/25300 (epoch 40.595), train_loss = 0.71168920, grad/param norm = 2.2041e-01, time/batch = 15.9717s	
20542/25300 (epoch 40.597), train_loss = 0.64303539, grad/param norm = 2.2431e-01, time/batch = 16.3244s	
20543/25300 (epoch 40.599), train_loss = 0.82926424, grad/param norm = 2.7552e-01, time/batch = 15.4742s	
20544/25300 (epoch 40.601), train_loss = 0.72296329, grad/param norm = 2.8055e-01, time/batch = 15.3822s	
20545/25300 (epoch 40.603), train_loss = 0.71718074, grad/param norm = 2.5988e-01, time/batch = 15.6445s	
20546/25300 (epoch 40.605), train_loss = 0.72205654, grad/param norm = 2.6935e-01, time/batch = 16.6281s	
20547/25300 (epoch 40.607), train_loss = 0.51343631, grad/param norm = 1.7288e-01, time/batch = 15.7775s	
20548/25300 (epoch 40.609), train_loss = 0.64599432, grad/param norm = 2.3698e-01, time/batch = 15.6289s	
20549/25300 (epoch 40.611), train_loss = 0.78111225, grad/param norm = 3.7875e-01, time/batch = 16.1432s	
20550/25300 (epoch 40.613), train_loss = 0.63414924, grad/param norm = 2.2301e-01, time/batch = 16.0622s	
20551/25300 (epoch 40.615), train_loss = 0.67749293, grad/param norm = 2.8573e-01, time/batch = 15.3784s	
20552/25300 (epoch 40.617), train_loss = 0.72395130, grad/param norm = 2.6426e-01, time/batch = 16.0724s	
20553/25300 (epoch 40.619), train_loss = 0.79063984, grad/param norm = 2.7551e-01, time/batch = 15.9785s	
20554/25300 (epoch 40.621), train_loss = 0.78915504, grad/param norm = 2.5831e-01, time/batch = 16.1459s	
20555/25300 (epoch 40.623), train_loss = 0.66785315, grad/param norm = 2.0758e-01, time/batch = 15.8530s	
20556/25300 (epoch 40.625), train_loss = 0.59682194, grad/param norm = 2.0416e-01, time/batch = 16.5339s	
20557/25300 (epoch 40.626), train_loss = 0.69541000, grad/param norm = 2.4484e-01, time/batch = 15.9002s	
20558/25300 (epoch 40.628), train_loss = 0.82909258, grad/param norm = 2.5911e-01, time/batch = 16.2102s	
20559/25300 (epoch 40.630), train_loss = 0.76014046, grad/param norm = 2.4518e-01, time/batch = 15.4895s	
20560/25300 (epoch 40.632), train_loss = 0.71313178, grad/param norm = 2.3557e-01, time/batch = 16.1388s	
20561/25300 (epoch 40.634), train_loss = 0.80428295, grad/param norm = 2.5576e-01, time/batch = 16.2257s	
20562/25300 (epoch 40.636), train_loss = 0.65459450, grad/param norm = 2.5770e-01, time/batch = 15.6365s	
20563/25300 (epoch 40.638), train_loss = 0.72297391, grad/param norm = 2.7709e-01, time/batch = 15.5319s	
20564/25300 (epoch 40.640), train_loss = 0.91480921, grad/param norm = 3.8772e-01, time/batch = 15.8749s	
20565/25300 (epoch 40.642), train_loss = 0.76869390, grad/param norm = 2.5077e-01, time/batch = 15.8963s	
20566/25300 (epoch 40.644), train_loss = 0.73236419, grad/param norm = 2.2033e-01, time/batch = 15.8688s	
20567/25300 (epoch 40.646), train_loss = 0.67066951, grad/param norm = 2.8384e-01, time/batch = 16.2209s	
20568/25300 (epoch 40.648), train_loss = 0.81584239, grad/param norm = 2.3157e-01, time/batch = 15.5368s	
20569/25300 (epoch 40.650), train_loss = 0.75315968, grad/param norm = 3.0986e-01, time/batch = 15.7206s	
20570/25300 (epoch 40.652), train_loss = 0.77749215, grad/param norm = 2.8212e-01, time/batch = 15.6229s	
20571/25300 (epoch 40.654), train_loss = 0.83840300, grad/param norm = 2.2603e-01, time/batch = 15.9763s	
20572/25300 (epoch 40.656), train_loss = 0.77193009, grad/param norm = 2.3339e-01, time/batch = 16.3853s	
20573/25300 (epoch 40.658), train_loss = 0.58181534, grad/param norm = 1.9307e-01, time/batch = 15.7147s	
20574/25300 (epoch 40.660), train_loss = 0.58943367, grad/param norm = 2.0930e-01, time/batch = 15.5573s	
20575/25300 (epoch 40.662), train_loss = 0.61053873, grad/param norm = 2.1439e-01, time/batch = 15.7283s	
20576/25300 (epoch 40.664), train_loss = 0.55657684, grad/param norm = 2.1136e-01, time/batch = 15.3865s	
20577/25300 (epoch 40.666), train_loss = 0.63019118, grad/param norm = 2.4528e-01, time/batch = 16.2942s	
20578/25300 (epoch 40.668), train_loss = 0.71449729, grad/param norm = 2.8201e-01, time/batch = 15.7756s	
20579/25300 (epoch 40.670), train_loss = 0.65947327, grad/param norm = 2.7423e-01, time/batch = 15.5619s	
20580/25300 (epoch 40.672), train_loss = 0.65690579, grad/param norm = 2.2012e-01, time/batch = 15.7953s	
20581/25300 (epoch 40.674), train_loss = 0.62686380, grad/param norm = 2.0086e-01, time/batch = 15.7015s	
20582/25300 (epoch 40.676), train_loss = 0.64696283, grad/param norm = 2.3165e-01, time/batch = 15.7122s	
20583/25300 (epoch 40.678), train_loss = 0.67369328, grad/param norm = 2.7608e-01, time/batch = 15.4744s	
20584/25300 (epoch 40.680), train_loss = 0.59029165, grad/param norm = 2.1016e-01, time/batch = 15.9816s	
20585/25300 (epoch 40.682), train_loss = 0.49148116, grad/param norm = 1.7181e-01, time/batch = 15.3661s	
20586/25300 (epoch 40.684), train_loss = 0.62695552, grad/param norm = 1.8795e-01, time/batch = 15.8385s	
20587/25300 (epoch 40.686), train_loss = 0.60457324, grad/param norm = 1.9444e-01, time/batch = 15.5521s	
20588/25300 (epoch 40.688), train_loss = 0.68759376, grad/param norm = 2.8227e-01, time/batch = 16.1389s	
20589/25300 (epoch 40.690), train_loss = 0.59693014, grad/param norm = 2.1929e-01, time/batch = 15.8639s	
20590/25300 (epoch 40.692), train_loss = 0.63164223, grad/param norm = 2.1081e-01, time/batch = 16.0623s	
20591/25300 (epoch 40.694), train_loss = 0.64260229, grad/param norm = 2.2294e-01, time/batch = 15.8812s	
20592/25300 (epoch 40.696), train_loss = 0.70461101, grad/param norm = 2.4720e-01, time/batch = 16.2925s	
20593/25300 (epoch 40.698), train_loss = 0.76726446, grad/param norm = 2.2726e-01, time/batch = 16.5529s	
20594/25300 (epoch 40.700), train_loss = 0.57074770, grad/param norm = 2.1175e-01, time/batch = 15.9540s	
20595/25300 (epoch 40.702), train_loss = 0.76867341, grad/param norm = 2.2760e-01, time/batch = 15.9719s	
20596/25300 (epoch 40.704), train_loss = 0.54603081, grad/param norm = 1.9311e-01, time/batch = 15.7990s	
20597/25300 (epoch 40.706), train_loss = 0.67710275, grad/param norm = 2.2663e-01, time/batch = 16.1300s	
20598/25300 (epoch 40.708), train_loss = 0.59564070, grad/param norm = 1.7245e-01, time/batch = 15.3031s	
20599/25300 (epoch 40.709), train_loss = 0.80497150, grad/param norm = 2.2344e-01, time/batch = 15.5704s	
20600/25300 (epoch 40.711), train_loss = 0.84877386, grad/param norm = 2.4530e-01, time/batch = 15.6425s	
20601/25300 (epoch 40.713), train_loss = 0.71504080, grad/param norm = 1.9287e-01, time/batch = 15.8102s	
20602/25300 (epoch 40.715), train_loss = 0.72187933, grad/param norm = 2.0984e-01, time/batch = 16.0548s	
20603/25300 (epoch 40.717), train_loss = 0.61971335, grad/param norm = 2.1720e-01, time/batch = 15.8119s	
20604/25300 (epoch 40.719), train_loss = 0.67401074, grad/param norm = 2.7228e-01, time/batch = 15.2010s	
20605/25300 (epoch 40.721), train_loss = 0.73919355, grad/param norm = 2.3734e-01, time/batch = 16.0481s	
20606/25300 (epoch 40.723), train_loss = 0.69476568, grad/param norm = 2.3100e-01, time/batch = 15.7991s	
20607/25300 (epoch 40.725), train_loss = 0.72290281, grad/param norm = 2.4808e-01, time/batch = 15.9502s	
20608/25300 (epoch 40.727), train_loss = 0.70775021, grad/param norm = 2.2192e-01, time/batch = 15.3934s	
20609/25300 (epoch 40.729), train_loss = 0.67775732, grad/param norm = 2.1613e-01, time/batch = 15.9778s	
20610/25300 (epoch 40.731), train_loss = 0.84107766, grad/param norm = 2.5213e-01, time/batch = 15.8094s	
20611/25300 (epoch 40.733), train_loss = 0.69746697, grad/param norm = 1.8763e-01, time/batch = 15.8738s	
20612/25300 (epoch 40.735), train_loss = 0.89145679, grad/param norm = 2.4940e-01, time/batch = 15.4836s	
20613/25300 (epoch 40.737), train_loss = 0.56016690, grad/param norm = 2.0821e-01, time/batch = 15.5511s	
20614/25300 (epoch 40.739), train_loss = 0.82628945, grad/param norm = 2.2909e-01, time/batch = 16.0310s	
20615/25300 (epoch 40.741), train_loss = 0.73573537, grad/param norm = 2.5625e-01, time/batch = 15.7220s	
20616/25300 (epoch 40.743), train_loss = 0.71720356, grad/param norm = 2.4411e-01, time/batch = 15.8080s	
20617/25300 (epoch 40.745), train_loss = 0.68193343, grad/param norm = 2.1878e-01, time/batch = 16.1268s	
20618/25300 (epoch 40.747), train_loss = 0.60705227, grad/param norm = 2.2424e-01, time/batch = 15.6458s	
20619/25300 (epoch 40.749), train_loss = 0.72107363, grad/param norm = 2.7554e-01, time/batch = 15.7934s	
20620/25300 (epoch 40.751), train_loss = 0.75322054, grad/param norm = 2.5349e-01, time/batch = 15.6380s	
20621/25300 (epoch 40.753), train_loss = 0.60291422, grad/param norm = 2.2258e-01, time/batch = 15.6957s	
20622/25300 (epoch 40.755), train_loss = 0.81974436, grad/param norm = 2.7338e-01, time/batch = 15.6488s	
20623/25300 (epoch 40.757), train_loss = 0.66553782, grad/param norm = 2.7440e-01, time/batch = 15.2147s	
20624/25300 (epoch 40.759), train_loss = 0.63531586, grad/param norm = 2.0058e-01, time/batch = 15.4738s	
20625/25300 (epoch 40.761), train_loss = 0.83608047, grad/param norm = 2.0695e-01, time/batch = 15.3220s	
20626/25300 (epoch 40.763), train_loss = 0.68635432, grad/param norm = 2.4421e-01, time/batch = 16.0434s	
20627/25300 (epoch 40.765), train_loss = 0.66901855, grad/param norm = 2.3683e-01, time/batch = 15.8696s	
20628/25300 (epoch 40.767), train_loss = 0.67783459, grad/param norm = 2.0305e-01, time/batch = 15.5548s	
20629/25300 (epoch 40.769), train_loss = 0.71452057, grad/param norm = 2.7018e-01, time/batch = 15.6499s	
20630/25300 (epoch 40.771), train_loss = 0.77967533, grad/param norm = 2.6793e-01, time/batch = 15.6866s	
20631/25300 (epoch 40.773), train_loss = 0.81185788, grad/param norm = 2.4724e-01, time/batch = 16.1457s	
20632/25300 (epoch 40.775), train_loss = 0.72080736, grad/param norm = 2.1440e-01, time/batch = 15.8767s	
20633/25300 (epoch 40.777), train_loss = 0.65712324, grad/param norm = 2.3053e-01, time/batch = 15.3121s	
20634/25300 (epoch 40.779), train_loss = 0.78982676, grad/param norm = 2.3233e-01, time/batch = 15.2127s	
20635/25300 (epoch 40.781), train_loss = 0.75830274, grad/param norm = 2.3879e-01, time/batch = 15.5337s	
20636/25300 (epoch 40.783), train_loss = 0.82590121, grad/param norm = 2.4119e-01, time/batch = 16.0429s	
20637/25300 (epoch 40.785), train_loss = 0.79175049, grad/param norm = 2.8248e-01, time/batch = 16.5590s	
20638/25300 (epoch 40.787), train_loss = 0.74894606, grad/param norm = 2.5850e-01, time/batch = 28.5420s	
20639/25300 (epoch 40.789), train_loss = 0.82045151, grad/param norm = 2.6981e-01, time/batch = 16.6284s	
20640/25300 (epoch 40.791), train_loss = 0.79952128, grad/param norm = 2.4947e-01, time/batch = 15.8708s	
20641/25300 (epoch 40.792), train_loss = 0.82615278, grad/param norm = 2.5472e-01, time/batch = 15.6619s	
20642/25300 (epoch 40.794), train_loss = 0.68771473, grad/param norm = 2.4787e-01, time/batch = 15.6650s	
20643/25300 (epoch 40.796), train_loss = 0.66714856, grad/param norm = 2.4098e-01, time/batch = 15.6840s	
20644/25300 (epoch 40.798), train_loss = 0.84055284, grad/param norm = 4.8884e-01, time/batch = 15.2622s	
20645/25300 (epoch 40.800), train_loss = 0.67075508, grad/param norm = 1.9502e-01, time/batch = 15.7663s	
20646/25300 (epoch 40.802), train_loss = 0.58632930, grad/param norm = 2.1654e-01, time/batch = 15.6512s	
20647/25300 (epoch 40.804), train_loss = 0.71487479, grad/param norm = 2.1104e-01, time/batch = 16.5444s	
20648/25300 (epoch 40.806), train_loss = 0.79768405, grad/param norm = 2.5689e-01, time/batch = 15.5192s	
20649/25300 (epoch 40.808), train_loss = 0.84984622, grad/param norm = 2.5940e-01, time/batch = 15.4709s	
20650/25300 (epoch 40.810), train_loss = 0.73445589, grad/param norm = 2.9479e-01, time/batch = 15.6364s	
20651/25300 (epoch 40.812), train_loss = 0.82821332, grad/param norm = 2.7106e-01, time/batch = 15.6364s	
20652/25300 (epoch 40.814), train_loss = 0.84523520, grad/param norm = 2.4366e-01, time/batch = 15.6070s	
20653/25300 (epoch 40.816), train_loss = 0.93379745, grad/param norm = 2.9094e-01, time/batch = 15.7995s	
20654/25300 (epoch 40.818), train_loss = 0.82171604, grad/param norm = 2.4934e-01, time/batch = 15.4679s	
20655/25300 (epoch 40.820), train_loss = 0.79860067, grad/param norm = 2.2693e-01, time/batch = 15.6253s	
20656/25300 (epoch 40.822), train_loss = 0.66034962, grad/param norm = 2.0830e-01, time/batch = 15.8678s	
20657/25300 (epoch 40.824), train_loss = 0.80668063, grad/param norm = 2.5897e-01, time/batch = 15.6347s	
20658/25300 (epoch 40.826), train_loss = 0.67873439, grad/param norm = 2.0128e-01, time/batch = 15.9729s	
20659/25300 (epoch 40.828), train_loss = 0.67771522, grad/param norm = 2.2833e-01, time/batch = 16.2256s	
20660/25300 (epoch 40.830), train_loss = 0.75024079, grad/param norm = 2.2266e-01, time/batch = 15.5427s	
20661/25300 (epoch 40.832), train_loss = 0.86029418, grad/param norm = 2.7592e-01, time/batch = 15.5544s	
20662/25300 (epoch 40.834), train_loss = 0.69327256, grad/param norm = 2.2436e-01, time/batch = 15.5669s	
20663/25300 (epoch 40.836), train_loss = 0.71257254, grad/param norm = 2.6997e-01, time/batch = 16.6932s	
20664/25300 (epoch 40.838), train_loss = 0.68011974, grad/param norm = 2.0169e-01, time/batch = 15.4754s	
20665/25300 (epoch 40.840), train_loss = 0.78189020, grad/param norm = 2.7373e-01, time/batch = 15.8931s	
20666/25300 (epoch 40.842), train_loss = 0.72553233, grad/param norm = 2.4534e-01, time/batch = 15.5432s	
20667/25300 (epoch 40.844), train_loss = 0.82190254, grad/param norm = 2.0969e-01, time/batch = 15.6922s	
20668/25300 (epoch 40.846), train_loss = 0.80738409, grad/param norm = 2.4812e-01, time/batch = 15.4407s	
20669/25300 (epoch 40.848), train_loss = 0.77880437, grad/param norm = 2.4794e-01, time/batch = 15.7211s	
20670/25300 (epoch 40.850), train_loss = 0.77704470, grad/param norm = 2.3991e-01, time/batch = 15.3803s	
20671/25300 (epoch 40.852), train_loss = 0.80505383, grad/param norm = 2.2296e-01, time/batch = 15.4620s	
20672/25300 (epoch 40.854), train_loss = 0.83550791, grad/param norm = 2.2759e-01, time/batch = 15.9619s	
20673/25300 (epoch 40.856), train_loss = 0.68774971, grad/param norm = 2.1514e-01, time/batch = 15.9636s	
20674/25300 (epoch 40.858), train_loss = 0.71449398, grad/param norm = 2.6299e-01, time/batch = 15.9650s	
20675/25300 (epoch 40.860), train_loss = 0.62906422, grad/param norm = 1.9612e-01, time/batch = 15.5294s	
20676/25300 (epoch 40.862), train_loss = 0.72775683, grad/param norm = 2.2512e-01, time/batch = 15.6278s	
20677/25300 (epoch 40.864), train_loss = 0.87196529, grad/param norm = 2.4684e-01, time/batch = 15.9583s	
20678/25300 (epoch 40.866), train_loss = 0.68784763, grad/param norm = 2.6697e-01, time/batch = 15.6188s	
20679/25300 (epoch 40.868), train_loss = 0.80766949, grad/param norm = 2.5050e-01, time/batch = 15.3758s	
20680/25300 (epoch 40.870), train_loss = 0.80525183, grad/param norm = 2.2661e-01, time/batch = 15.5317s	
20681/25300 (epoch 40.872), train_loss = 0.76225087, grad/param norm = 2.5888e-01, time/batch = 15.5946s	
20682/25300 (epoch 40.874), train_loss = 0.78422260, grad/param norm = 2.4307e-01, time/batch = 15.2704s	
20683/25300 (epoch 40.875), train_loss = 0.72029062, grad/param norm = 2.4226e-01, time/batch = 15.4159s	
20684/25300 (epoch 40.877), train_loss = 0.70150234, grad/param norm = 2.1027e-01, time/batch = 15.1187s	
20685/25300 (epoch 40.879), train_loss = 0.66033277, grad/param norm = 2.1886e-01, time/batch = 15.6419s	
20686/25300 (epoch 40.881), train_loss = 0.93377707, grad/param norm = 2.9837e-01, time/batch = 16.1971s	
20687/25300 (epoch 40.883), train_loss = 0.91380149, grad/param norm = 2.6108e-01, time/batch = 15.8022s	
20688/25300 (epoch 40.885), train_loss = 0.81038202, grad/param norm = 2.9975e-01, time/batch = 15.8076s	
20689/25300 (epoch 40.887), train_loss = 0.81032783, grad/param norm = 2.1763e-01, time/batch = 15.2906s	
20690/25300 (epoch 40.889), train_loss = 0.88666348, grad/param norm = 2.6541e-01, time/batch = 15.4550s	
20691/25300 (epoch 40.891), train_loss = 0.76363659, grad/param norm = 2.5330e-01, time/batch = 15.8603s	
20692/25300 (epoch 40.893), train_loss = 0.75280555, grad/param norm = 2.8846e-01, time/batch = 16.0597s	
20693/25300 (epoch 40.895), train_loss = 0.57309639, grad/param norm = 1.9551e-01, time/batch = 16.1341s	
20694/25300 (epoch 40.897), train_loss = 0.63791093, grad/param norm = 2.1048e-01, time/batch = 15.6116s	
20695/25300 (epoch 40.899), train_loss = 0.75259659, grad/param norm = 2.5966e-01, time/batch = 15.6300s	
20696/25300 (epoch 40.901), train_loss = 0.81219764, grad/param norm = 2.7097e-01, time/batch = 16.1239s	
20697/25300 (epoch 40.903), train_loss = 0.62650314, grad/param norm = 2.5530e-01, time/batch = 16.2179s	
20698/25300 (epoch 40.905), train_loss = 0.66199569, grad/param norm = 2.1723e-01, time/batch = 15.9595s	
20699/25300 (epoch 40.907), train_loss = 0.68918923, grad/param norm = 2.6062e-01, time/batch = 16.0285s	
20700/25300 (epoch 40.909), train_loss = 0.78671944, grad/param norm = 2.4807e-01, time/batch = 16.4753s	
20701/25300 (epoch 40.911), train_loss = 0.84369689, grad/param norm = 2.9910e-01, time/batch = 16.4599s	
20702/25300 (epoch 40.913), train_loss = 0.91773130, grad/param norm = 2.7637e-01, time/batch = 15.6320s	
20703/25300 (epoch 40.915), train_loss = 0.69537506, grad/param norm = 2.1287e-01, time/batch = 15.7155s	
20704/25300 (epoch 40.917), train_loss = 0.90063262, grad/param norm = 2.7393e-01, time/batch = 15.2724s	
20705/25300 (epoch 40.919), train_loss = 0.86239320, grad/param norm = 3.3112e-01, time/batch = 15.6948s	
20706/25300 (epoch 40.921), train_loss = 0.71016245, grad/param norm = 2.5296e-01, time/batch = 16.3849s	
20707/25300 (epoch 40.923), train_loss = 0.83512101, grad/param norm = 2.3915e-01, time/batch = 15.2871s	
20708/25300 (epoch 40.925), train_loss = 0.73243756, grad/param norm = 2.4846e-01, time/batch = 15.8041s	
20709/25300 (epoch 40.927), train_loss = 0.74484392, grad/param norm = 2.3426e-01, time/batch = 15.3722s	
20710/25300 (epoch 40.929), train_loss = 0.82415781, grad/param norm = 2.3645e-01, time/batch = 27.1353s	
20711/25300 (epoch 40.931), train_loss = 0.80725831, grad/param norm = 3.0653e-01, time/batch = 31.0844s	
20712/25300 (epoch 40.933), train_loss = 0.77210438, grad/param norm = 2.3731e-01, time/batch = 27.6890s	
20713/25300 (epoch 40.935), train_loss = 0.80469701, grad/param norm = 2.1851e-01, time/batch = 31.4806s	
20714/25300 (epoch 40.937), train_loss = 0.60781546, grad/param norm = 2.0567e-01, time/batch = 31.1779s	
20715/25300 (epoch 40.939), train_loss = 0.75087034, grad/param norm = 2.3692e-01, time/batch = 33.3902s	
20716/25300 (epoch 40.941), train_loss = 0.67882647, grad/param norm = 2.4718e-01, time/batch = 32.4346s	
20717/25300 (epoch 40.943), train_loss = 0.76209282, grad/param norm = 2.2014e-01, time/batch = 33.3289s	
20718/25300 (epoch 40.945), train_loss = 0.76736926, grad/param norm = 2.2425e-01, time/batch = 33.3372s	
20719/25300 (epoch 40.947), train_loss = 0.69434891, grad/param norm = 2.4546e-01, time/batch = 32.4149s	
20720/25300 (epoch 40.949), train_loss = 0.76322692, grad/param norm = 2.2626e-01, time/batch = 29.6686s	
20721/25300 (epoch 40.951), train_loss = 0.75754849, grad/param norm = 2.1534e-01, time/batch = 19.1063s	
20722/25300 (epoch 40.953), train_loss = 0.69928797, grad/param norm = 2.2906e-01, time/batch = 17.0385s	
20723/25300 (epoch 40.955), train_loss = 0.93357157, grad/param norm = 2.8910e-01, time/batch = 17.7765s	
20724/25300 (epoch 40.957), train_loss = 0.83376053, grad/param norm = 2.6443e-01, time/batch = 18.6012s	
20725/25300 (epoch 40.958), train_loss = 0.78941369, grad/param norm = 2.8988e-01, time/batch = 18.2745s	
20726/25300 (epoch 40.960), train_loss = 0.91487618, grad/param norm = 2.8984e-01, time/batch = 17.9542s	
20727/25300 (epoch 40.962), train_loss = 0.86876192, grad/param norm = 2.2601e-01, time/batch = 18.0416s	
20728/25300 (epoch 40.964), train_loss = 0.77811309, grad/param norm = 2.5154e-01, time/batch = 18.9352s	
20729/25300 (epoch 40.966), train_loss = 0.63709193, grad/param norm = 2.2002e-01, time/batch = 18.4151s	
20730/25300 (epoch 40.968), train_loss = 0.64554393, grad/param norm = 1.9279e-01, time/batch = 18.2237s	
20731/25300 (epoch 40.970), train_loss = 0.74167091, grad/param norm = 3.1884e-01, time/batch = 18.6359s	
20732/25300 (epoch 40.972), train_loss = 0.75493913, grad/param norm = 2.2558e-01, time/batch = 18.0502s	
20733/25300 (epoch 40.974), train_loss = 0.86017793, grad/param norm = 3.0411e-01, time/batch = 25.0100s	
20734/25300 (epoch 40.976), train_loss = 0.78945565, grad/param norm = 2.7078e-01, time/batch = 15.7852s	
20735/25300 (epoch 40.978), train_loss = 0.70781200, grad/param norm = 2.4140e-01, time/batch = 15.3148s	
20736/25300 (epoch 40.980), train_loss = 0.77191867, grad/param norm = 2.6303e-01, time/batch = 16.7882s	
20737/25300 (epoch 40.982), train_loss = 0.71840281, grad/param norm = 2.1791e-01, time/batch = 16.2911s	
20738/25300 (epoch 40.984), train_loss = 0.73934659, grad/param norm = 2.3040e-01, time/batch = 15.7971s	
20739/25300 (epoch 40.986), train_loss = 0.80845887, grad/param norm = 2.5328e-01, time/batch = 16.7127s	
20740/25300 (epoch 40.988), train_loss = 0.76050488, grad/param norm = 2.5075e-01, time/batch = 15.8881s	
20741/25300 (epoch 40.990), train_loss = 0.76110187, grad/param norm = 2.1978e-01, time/batch = 15.7360s	
20742/25300 (epoch 40.992), train_loss = 0.64763652, grad/param norm = 2.0492e-01, time/batch = 15.6911s	
20743/25300 (epoch 40.994), train_loss = 0.78596060, grad/param norm = 3.3685e-01, time/batch = 16.2127s	
20744/25300 (epoch 40.996), train_loss = 0.89793890, grad/param norm = 3.0784e-01, time/batch = 16.8905s	
20745/25300 (epoch 40.998), train_loss = 0.80587745, grad/param norm = 2.5177e-01, time/batch = 15.5453s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
20746/25300 (epoch 41.000), train_loss = 0.82184092, grad/param norm = 2.7825e-01, time/batch = 15.8902s	
20747/25300 (epoch 41.002), train_loss = 0.77029120, grad/param norm = 2.0754e-01, time/batch = 15.3057s	
20748/25300 (epoch 41.004), train_loss = 0.64020188, grad/param norm = 2.0875e-01, time/batch = 16.2970s	
20749/25300 (epoch 41.006), train_loss = 0.90018166, grad/param norm = 2.6497e-01, time/batch = 15.8066s	
20750/25300 (epoch 41.008), train_loss = 0.76874889, grad/param norm = 3.2435e-01, time/batch = 16.3809s	
20751/25300 (epoch 41.010), train_loss = 0.82279706, grad/param norm = 2.2816e-01, time/batch = 15.9666s	
20752/25300 (epoch 41.012), train_loss = 0.73772099, grad/param norm = 2.2381e-01, time/batch = 16.2125s	
20753/25300 (epoch 41.014), train_loss = 0.87704628, grad/param norm = 2.3920e-01, time/batch = 15.9605s	
20754/25300 (epoch 41.016), train_loss = 0.75547891, grad/param norm = 2.5326e-01, time/batch = 16.1264s	
20755/25300 (epoch 41.018), train_loss = 0.68543728, grad/param norm = 2.2871e-01, time/batch = 16.0332s	
20756/25300 (epoch 41.020), train_loss = 0.80254121, grad/param norm = 2.4738e-01, time/batch = 16.2034s	
20757/25300 (epoch 41.022), train_loss = 0.78188201, grad/param norm = 3.2215e-01, time/batch = 16.1216s	
20758/25300 (epoch 41.024), train_loss = 0.60769533, grad/param norm = 2.2961e-01, time/batch = 16.1433s	
20759/25300 (epoch 41.026), train_loss = 0.71183569, grad/param norm = 2.3451e-01, time/batch = 16.2202s	
20760/25300 (epoch 41.028), train_loss = 0.70265995, grad/param norm = 2.1241e-01, time/batch = 15.5545s	
20761/25300 (epoch 41.030), train_loss = 0.86661326, grad/param norm = 2.2916e-01, time/batch = 15.5511s	
20762/25300 (epoch 41.032), train_loss = 0.69874567, grad/param norm = 2.2475e-01, time/batch = 15.7225s	
20763/25300 (epoch 41.034), train_loss = 0.67221539, grad/param norm = 2.2182e-01, time/batch = 16.1344s	
20764/25300 (epoch 41.036), train_loss = 0.62979407, grad/param norm = 2.2347e-01, time/batch = 16.0208s	
20765/25300 (epoch 41.038), train_loss = 0.55635735, grad/param norm = 1.8450e-01, time/batch = 15.5396s	
20766/25300 (epoch 41.040), train_loss = 0.73701364, grad/param norm = 2.1876e-01, time/batch = 15.4337s	
20767/25300 (epoch 41.042), train_loss = 0.72729717, grad/param norm = 1.9731e-01, time/batch = 16.3812s	
20768/25300 (epoch 41.043), train_loss = 0.66403105, grad/param norm = 1.9888e-01, time/batch = 15.7220s	
20769/25300 (epoch 41.045), train_loss = 0.63253896, grad/param norm = 2.0594e-01, time/batch = 15.6396s	
20770/25300 (epoch 41.047), train_loss = 0.73998010, grad/param norm = 1.9876e-01, time/batch = 15.7343s	
20771/25300 (epoch 41.049), train_loss = 0.74911479, grad/param norm = 2.6848e-01, time/batch = 15.8772s	
20772/25300 (epoch 41.051), train_loss = 0.90130763, grad/param norm = 2.6989e-01, time/batch = 15.5423s	
20773/25300 (epoch 41.053), train_loss = 0.59246973, grad/param norm = 1.8578e-01, time/batch = 15.6385s	
20774/25300 (epoch 41.055), train_loss = 0.61268320, grad/param norm = 2.0847e-01, time/batch = 15.9949s	
20775/25300 (epoch 41.057), train_loss = 0.61140939, grad/param norm = 1.7025e-01, time/batch = 15.2858s	
20776/25300 (epoch 41.059), train_loss = 0.69823520, grad/param norm = 2.1004e-01, time/batch = 15.9386s	
20777/25300 (epoch 41.061), train_loss = 0.67488837, grad/param norm = 2.3430e-01, time/batch = 16.1241s	
20778/25300 (epoch 41.063), train_loss = 0.70784297, grad/param norm = 1.9362e-01, time/batch = 17.2026s	
20779/25300 (epoch 41.065), train_loss = 0.74357438, grad/param norm = 2.2565e-01, time/batch = 16.2100s	
20780/25300 (epoch 41.067), train_loss = 0.80664961, grad/param norm = 2.4218e-01, time/batch = 17.2891s	
20781/25300 (epoch 41.069), train_loss = 0.65993016, grad/param norm = 2.1552e-01, time/batch = 16.7145s	
20782/25300 (epoch 41.071), train_loss = 0.77381830, grad/param norm = 2.2665e-01, time/batch = 15.8074s	
20783/25300 (epoch 41.073), train_loss = 0.71491562, grad/param norm = 2.0156e-01, time/batch = 16.7204s	
20784/25300 (epoch 41.075), train_loss = 0.77561177, grad/param norm = 2.2211e-01, time/batch = 16.0702s	
20785/25300 (epoch 41.077), train_loss = 0.73810560, grad/param norm = 2.2244e-01, time/batch = 16.9811s	
20786/25300 (epoch 41.079), train_loss = 0.67595634, grad/param norm = 2.2402e-01, time/batch = 15.5480s	
20787/25300 (epoch 41.081), train_loss = 0.73609617, grad/param norm = 2.0018e-01, time/batch = 17.4626s	
20788/25300 (epoch 41.083), train_loss = 0.76578185, grad/param norm = 2.2351e-01, time/batch = 16.3007s	
20789/25300 (epoch 41.085), train_loss = 0.90054548, grad/param norm = 2.2554e-01, time/batch = 15.5581s	
20790/25300 (epoch 41.087), train_loss = 0.78781953, grad/param norm = 2.0190e-01, time/batch = 16.2003s	
20791/25300 (epoch 41.089), train_loss = 0.76551348, grad/param norm = 2.1631e-01, time/batch = 16.6422s	
20792/25300 (epoch 41.091), train_loss = 0.91162685, grad/param norm = 2.2747e-01, time/batch = 16.1452s	
20793/25300 (epoch 41.093), train_loss = 0.82924516, grad/param norm = 2.4244e-01, time/batch = 15.5589s	
20794/25300 (epoch 41.095), train_loss = 0.79691851, grad/param norm = 2.0474e-01, time/batch = 16.6340s	
20795/25300 (epoch 41.097), train_loss = 0.79206886, grad/param norm = 2.2841e-01, time/batch = 15.7401s	
20796/25300 (epoch 41.099), train_loss = 0.78095201, grad/param norm = 2.5346e-01, time/batch = 16.3931s	
20797/25300 (epoch 41.101), train_loss = 0.72954092, grad/param norm = 2.4184e-01, time/batch = 15.4641s	
20798/25300 (epoch 41.103), train_loss = 0.77067761, grad/param norm = 2.0499e-01, time/batch = 15.3412s	
20799/25300 (epoch 41.105), train_loss = 0.77323281, grad/param norm = 2.1286e-01, time/batch = 15.3380s	
20800/25300 (epoch 41.107), train_loss = 0.79126004, grad/param norm = 3.9023e-01, time/batch = 15.2620s	
20801/25300 (epoch 41.109), train_loss = 0.73195717, grad/param norm = 2.5298e-01, time/batch = 15.4405s	
20802/25300 (epoch 41.111), train_loss = 0.72744827, grad/param norm = 2.3050e-01, time/batch = 15.6214s	
20803/25300 (epoch 41.113), train_loss = 0.69126760, grad/param norm = 2.1948e-01, time/batch = 15.5436s	
20804/25300 (epoch 41.115), train_loss = 0.72882875, grad/param norm = 2.6645e-01, time/batch = 15.5923s	
20805/25300 (epoch 41.117), train_loss = 0.82553431, grad/param norm = 2.3508e-01, time/batch = 15.7885s	
20806/25300 (epoch 41.119), train_loss = 0.69306023, grad/param norm = 2.2038e-01, time/batch = 17.1276s	
20807/25300 (epoch 41.121), train_loss = 0.76063949, grad/param norm = 3.4753e-01, time/batch = 16.7932s	
20808/25300 (epoch 41.123), train_loss = 0.68637462, grad/param norm = 2.3308e-01, time/batch = 16.1265s	
20809/25300 (epoch 41.125), train_loss = 0.84667905, grad/param norm = 2.5481e-01, time/batch = 15.5458s	
20810/25300 (epoch 41.126), train_loss = 0.75004164, grad/param norm = 2.2664e-01, time/batch = 16.1281s	
20811/25300 (epoch 41.128), train_loss = 0.72671610, grad/param norm = 2.6990e-01, time/batch = 16.3855s	
20812/25300 (epoch 41.130), train_loss = 0.58947088, grad/param norm = 1.9308e-01, time/batch = 16.0429s	
20813/25300 (epoch 41.132), train_loss = 0.61170268, grad/param norm = 2.2803e-01, time/batch = 15.7228s	
20814/25300 (epoch 41.134), train_loss = 0.62023127, grad/param norm = 1.8514e-01, time/batch = 16.0453s	
20815/25300 (epoch 41.136), train_loss = 0.72670142, grad/param norm = 2.0867e-01, time/batch = 16.4695s	
20816/25300 (epoch 41.138), train_loss = 0.63986609, grad/param norm = 1.9670e-01, time/batch = 15.8065s	
20817/25300 (epoch 41.140), train_loss = 0.60443105, grad/param norm = 1.9281e-01, time/batch = 15.5647s	
20818/25300 (epoch 41.142), train_loss = 0.83511492, grad/param norm = 2.6050e-01, time/batch = 16.7287s	
20819/25300 (epoch 41.144), train_loss = 0.80478195, grad/param norm = 2.4656e-01, time/batch = 16.1902s	
20820/25300 (epoch 41.146), train_loss = 0.71511031, grad/param norm = 2.6745e-01, time/batch = 16.1957s	
20821/25300 (epoch 41.148), train_loss = 0.72112446, grad/param norm = 2.3454e-01, time/batch = 16.0161s	
20822/25300 (epoch 41.150), train_loss = 0.75099705, grad/param norm = 2.4994e-01, time/batch = 16.3835s	
20823/25300 (epoch 41.152), train_loss = 0.84468366, grad/param norm = 2.5638e-01, time/batch = 15.7778s	
20824/25300 (epoch 41.154), train_loss = 0.62938826, grad/param norm = 2.0791e-01, time/batch = 15.3846s	
20825/25300 (epoch 41.156), train_loss = 0.76625962, grad/param norm = 2.7926e-01, time/batch = 15.8035s	
20826/25300 (epoch 41.158), train_loss = 0.62893127, grad/param norm = 2.2010e-01, time/batch = 16.6427s	
20827/25300 (epoch 41.160), train_loss = 0.72012363, grad/param norm = 2.3138e-01, time/batch = 15.6288s	
20828/25300 (epoch 41.162), train_loss = 0.66016841, grad/param norm = 2.1466e-01, time/batch = 15.7965s	
20829/25300 (epoch 41.164), train_loss = 0.78533737, grad/param norm = 2.4892e-01, time/batch = 16.1925s	
20830/25300 (epoch 41.166), train_loss = 0.71909802, grad/param norm = 1.9797e-01, time/batch = 15.9444s	
20831/25300 (epoch 41.168), train_loss = 0.66995473, grad/param norm = 1.9407e-01, time/batch = 16.4589s	
20832/25300 (epoch 41.170), train_loss = 0.67748222, grad/param norm = 2.1332e-01, time/batch = 15.8898s	
20833/25300 (epoch 41.172), train_loss = 0.62324876, grad/param norm = 2.1277e-01, time/batch = 16.0509s	
20834/25300 (epoch 41.174), train_loss = 0.64419412, grad/param norm = 2.1575e-01, time/batch = 15.8699s	
20835/25300 (epoch 41.176), train_loss = 0.63721559, grad/param norm = 2.5609e-01, time/batch = 15.8986s	
20836/25300 (epoch 41.178), train_loss = 0.85218768, grad/param norm = 2.7270e-01, time/batch = 15.8008s	
20837/25300 (epoch 41.180), train_loss = 0.58949560, grad/param norm = 2.5622e-01, time/batch = 15.9860s	
20838/25300 (epoch 41.182), train_loss = 0.69570226, grad/param norm = 2.4739e-01, time/batch = 15.7131s	
20839/25300 (epoch 41.184), train_loss = 0.64237211, grad/param norm = 2.2804e-01, time/batch = 15.5711s	
20840/25300 (epoch 41.186), train_loss = 0.62132645, grad/param norm = 2.3875e-01, time/batch = 15.5635s	
20841/25300 (epoch 41.188), train_loss = 0.73721126, grad/param norm = 2.6853e-01, time/batch = 15.4874s	
20842/25300 (epoch 41.190), train_loss = 0.74850417, grad/param norm = 2.4323e-01, time/batch = 15.6917s	
20843/25300 (epoch 41.192), train_loss = 0.69701840, grad/param norm = 2.1261e-01, time/batch = 17.6152s	
20844/25300 (epoch 41.194), train_loss = 0.65714080, grad/param norm = 2.1093e-01, time/batch = 17.2954s	
20845/25300 (epoch 41.196), train_loss = 0.80829129, grad/param norm = 2.6149e-01, time/batch = 15.9609s	
20846/25300 (epoch 41.198), train_loss = 0.67590951, grad/param norm = 2.5424e-01, time/batch = 16.0614s	
20847/25300 (epoch 41.200), train_loss = 0.71000069, grad/param norm = 2.2419e-01, time/batch = 15.7780s	
20848/25300 (epoch 41.202), train_loss = 0.72334398, grad/param norm = 2.4560e-01, time/batch = 17.7182s	
20849/25300 (epoch 41.204), train_loss = 0.70014672, grad/param norm = 2.3712e-01, time/batch = 19.7268s	
20850/25300 (epoch 41.206), train_loss = 0.80756946, grad/param norm = 2.3661e-01, time/batch = 24.6805s	
20851/25300 (epoch 41.208), train_loss = 0.67674800, grad/param norm = 2.2269e-01, time/batch = 17.5294s	
20852/25300 (epoch 41.209), train_loss = 0.63186147, grad/param norm = 2.1194e-01, time/batch = 16.1243s	
20853/25300 (epoch 41.211), train_loss = 0.70363846, grad/param norm = 2.0891e-01, time/batch = 15.7363s	
20854/25300 (epoch 41.213), train_loss = 0.76158118, grad/param norm = 2.6661e-01, time/batch = 16.0565s	
20855/25300 (epoch 41.215), train_loss = 0.77324512, grad/param norm = 2.3116e-01, time/batch = 16.7987s	
20856/25300 (epoch 41.217), train_loss = 0.74784885, grad/param norm = 2.6560e-01, time/batch = 16.3932s	
20857/25300 (epoch 41.219), train_loss = 0.78186522, grad/param norm = 2.7280e-01, time/batch = 16.7241s	
20858/25300 (epoch 41.221), train_loss = 0.81312519, grad/param norm = 2.4092e-01, time/batch = 17.8781s	
20859/25300 (epoch 41.223), train_loss = 0.77832946, grad/param norm = 2.9714e-01, time/batch = 16.1393s	
20860/25300 (epoch 41.225), train_loss = 1.00510648, grad/param norm = 3.5435e-01, time/batch = 15.7987s	
20861/25300 (epoch 41.227), train_loss = 0.85878243, grad/param norm = 2.3803e-01, time/batch = 16.4658s	
20862/25300 (epoch 41.229), train_loss = 0.69065768, grad/param norm = 2.0057e-01, time/batch = 16.3601s	
20863/25300 (epoch 41.231), train_loss = 0.74881631, grad/param norm = 2.5407e-01, time/batch = 17.9583s	
20864/25300 (epoch 41.233), train_loss = 0.78078938, grad/param norm = 2.6552e-01, time/batch = 16.5573s	
20865/25300 (epoch 41.235), train_loss = 0.70831609, grad/param norm = 2.0780e-01, time/batch = 15.9332s	
20866/25300 (epoch 41.237), train_loss = 0.86481282, grad/param norm = 3.2582e-01, time/batch = 15.6373s	
20867/25300 (epoch 41.239), train_loss = 0.68470956, grad/param norm = 2.2668e-01, time/batch = 15.4765s	
20868/25300 (epoch 41.241), train_loss = 0.86518283, grad/param norm = 2.2723e-01, time/batch = 15.7349s	
20869/25300 (epoch 41.243), train_loss = 0.96260108, grad/param norm = 2.8047e-01, time/batch = 16.1488s	
20870/25300 (epoch 41.245), train_loss = 0.68793643, grad/param norm = 2.4983e-01, time/batch = 16.2866s	
20871/25300 (epoch 41.247), train_loss = 0.77841828, grad/param norm = 2.4335e-01, time/batch = 16.2889s	
20872/25300 (epoch 41.249), train_loss = 0.66286942, grad/param norm = 1.9854e-01, time/batch = 16.3046s	
20873/25300 (epoch 41.251), train_loss = 0.64924191, grad/param norm = 2.2058e-01, time/batch = 16.7390s	
20874/25300 (epoch 41.253), train_loss = 0.71089516, grad/param norm = 2.1028e-01, time/batch = 16.1351s	
20875/25300 (epoch 41.255), train_loss = 0.69451067, grad/param norm = 2.2487e-01, time/batch = 17.1503s	
20876/25300 (epoch 41.257), train_loss = 0.68536915, grad/param norm = 2.3781e-01, time/batch = 15.9601s	
20877/25300 (epoch 41.259), train_loss = 0.86994193, grad/param norm = 3.3692e-01, time/batch = 15.5534s	
20878/25300 (epoch 41.261), train_loss = 0.83926513, grad/param norm = 3.0210e-01, time/batch = 15.3908s	
20879/25300 (epoch 41.263), train_loss = 0.85194356, grad/param norm = 2.4678e-01, time/batch = 16.3965s	
20880/25300 (epoch 41.265), train_loss = 0.87180116, grad/param norm = 2.6520e-01, time/batch = 16.8173s	
20881/25300 (epoch 41.267), train_loss = 0.78404426, grad/param norm = 2.5962e-01, time/batch = 16.1414s	
20882/25300 (epoch 41.269), train_loss = 0.62812978, grad/param norm = 2.1081e-01, time/batch = 15.9964s	
20883/25300 (epoch 41.271), train_loss = 0.69538649, grad/param norm = 2.2428e-01, time/batch = 16.6306s	
20884/25300 (epoch 41.273), train_loss = 0.79692439, grad/param norm = 2.3165e-01, time/batch = 16.3794s	
20885/25300 (epoch 41.275), train_loss = 0.71419735, grad/param norm = 2.1799e-01, time/batch = 16.0317s	
20886/25300 (epoch 41.277), train_loss = 0.65170838, grad/param norm = 2.2587e-01, time/batch = 15.7991s	
20887/25300 (epoch 41.279), train_loss = 0.72044619, grad/param norm = 2.1669e-01, time/batch = 15.5579s	
20888/25300 (epoch 41.281), train_loss = 0.87539381, grad/param norm = 2.6376e-01, time/batch = 15.8797s	
20889/25300 (epoch 41.283), train_loss = 0.65688921, grad/param norm = 2.0969e-01, time/batch = 15.5677s	
20890/25300 (epoch 41.285), train_loss = 0.73157408, grad/param norm = 2.2466e-01, time/batch = 16.0602s	
20891/25300 (epoch 41.287), train_loss = 0.83568436, grad/param norm = 2.0662e-01, time/batch = 16.7125s	
20892/25300 (epoch 41.289), train_loss = 0.71327397, grad/param norm = 2.2343e-01, time/batch = 16.0331s	
20893/25300 (epoch 41.291), train_loss = 0.71961666, grad/param norm = 2.5811e-01, time/batch = 15.9780s	
20894/25300 (epoch 41.292), train_loss = 0.91570058, grad/param norm = 2.4035e-01, time/batch = 16.3075s	
20895/25300 (epoch 41.294), train_loss = 0.76767971, grad/param norm = 2.3334e-01, time/batch = 17.7207s	
20896/25300 (epoch 41.296), train_loss = 0.66472634, grad/param norm = 2.3013e-01, time/batch = 15.6304s	
20897/25300 (epoch 41.298), train_loss = 0.81302953, grad/param norm = 2.4345e-01, time/batch = 16.5607s	
20898/25300 (epoch 41.300), train_loss = 0.82433565, grad/param norm = 2.4998e-01, time/batch = 15.9019s	
20899/25300 (epoch 41.302), train_loss = 0.61830902, grad/param norm = 2.4237e-01, time/batch = 15.9702s	
20900/25300 (epoch 41.304), train_loss = 0.85540434, grad/param norm = 2.1330e-01, time/batch = 16.3025s	
20901/25300 (epoch 41.306), train_loss = 0.59247922, grad/param norm = 2.2743e-01, time/batch = 15.9063s	
20902/25300 (epoch 41.308), train_loss = 0.80631129, grad/param norm = 2.3263e-01, time/batch = 15.7212s	
20903/25300 (epoch 41.310), train_loss = 0.63943357, grad/param norm = 2.3115e-01, time/batch = 16.4457s	
20904/25300 (epoch 41.312), train_loss = 0.77462088, grad/param norm = 2.1513e-01, time/batch = 16.1329s	
20905/25300 (epoch 41.314), train_loss = 0.64402100, grad/param norm = 2.1804e-01, time/batch = 16.8135s	
20906/25300 (epoch 41.316), train_loss = 0.76847828, grad/param norm = 2.1705e-01, time/batch = 16.7276s	
20907/25300 (epoch 41.318), train_loss = 0.59598361, grad/param norm = 2.6294e-01, time/batch = 15.3902s	
20908/25300 (epoch 41.320), train_loss = 0.67734635, grad/param norm = 2.0440e-01, time/batch = 16.8100s	
20909/25300 (epoch 41.322), train_loss = 0.87076988, grad/param norm = 2.6558e-01, time/batch = 16.0631s	
20910/25300 (epoch 41.324), train_loss = 0.67067721, grad/param norm = 2.4153e-01, time/batch = 16.9766s	
20911/25300 (epoch 41.326), train_loss = 0.59335841, grad/param norm = 1.8635e-01, time/batch = 16.5466s	
20912/25300 (epoch 41.328), train_loss = 0.60636782, grad/param norm = 2.2428e-01, time/batch = 17.5455s	
20913/25300 (epoch 41.330), train_loss = 0.70968491, grad/param norm = 2.4995e-01, time/batch = 17.2102s	
20914/25300 (epoch 41.332), train_loss = 0.74123068, grad/param norm = 2.7898e-01, time/batch = 15.6591s	
20915/25300 (epoch 41.334), train_loss = 0.60579564, grad/param norm = 2.1752e-01, time/batch = 17.4609s	
20916/25300 (epoch 41.336), train_loss = 0.62681013, grad/param norm = 2.5462e-01, time/batch = 16.1178s	
20917/25300 (epoch 41.338), train_loss = 0.62800642, grad/param norm = 2.3135e-01, time/batch = 16.8068s	
20918/25300 (epoch 41.340), train_loss = 0.67607469, grad/param norm = 2.3555e-01, time/batch = 15.5525s	
20919/25300 (epoch 41.342), train_loss = 0.67551359, grad/param norm = 2.5661e-01, time/batch = 16.8102s	
20920/25300 (epoch 41.344), train_loss = 0.77309588, grad/param norm = 2.2363e-01, time/batch = 15.0296s	
20921/25300 (epoch 41.346), train_loss = 0.68885088, grad/param norm = 2.4905e-01, time/batch = 15.4484s	
20922/25300 (epoch 41.348), train_loss = 0.65646592, grad/param norm = 2.1163e-01, time/batch = 16.2095s	
20923/25300 (epoch 41.350), train_loss = 0.68655948, grad/param norm = 2.4581e-01, time/batch = 15.8963s	
20924/25300 (epoch 41.352), train_loss = 0.71525412, grad/param norm = 2.1385e-01, time/batch = 16.8858s	
20925/25300 (epoch 41.354), train_loss = 0.68655554, grad/param norm = 2.3324e-01, time/batch = 15.8144s	
20926/25300 (epoch 41.356), train_loss = 0.71264050, grad/param norm = 2.2034e-01, time/batch = 15.4146s	
20927/25300 (epoch 41.358), train_loss = 0.72267166, grad/param norm = 2.5195e-01, time/batch = 15.9880s	
20928/25300 (epoch 41.360), train_loss = 0.66920991, grad/param norm = 2.3277e-01, time/batch = 16.3150s	
20929/25300 (epoch 41.362), train_loss = 0.60078791, grad/param norm = 2.2248e-01, time/batch = 15.1926s	
20930/25300 (epoch 41.364), train_loss = 0.64539111, grad/param norm = 2.4509e-01, time/batch = 16.3013s	
20931/25300 (epoch 41.366), train_loss = 0.62777106, grad/param norm = 2.0407e-01, time/batch = 15.5446s	
20932/25300 (epoch 41.368), train_loss = 0.68220643, grad/param norm = 2.1755e-01, time/batch = 17.0428s	
20933/25300 (epoch 41.370), train_loss = 0.64083002, grad/param norm = 2.3601e-01, time/batch = 16.1343s	
20934/25300 (epoch 41.372), train_loss = 0.63209662, grad/param norm = 2.4291e-01, time/batch = 15.9852s	
20935/25300 (epoch 41.374), train_loss = 0.61557037, grad/param norm = 2.5656e-01, time/batch = 16.6485s	
20936/25300 (epoch 41.375), train_loss = 0.80254840, grad/param norm = 2.3556e-01, time/batch = 15.9694s	
20937/25300 (epoch 41.377), train_loss = 0.77903033, grad/param norm = 2.2749e-01, time/batch = 16.4752s	
20938/25300 (epoch 41.379), train_loss = 0.75484169, grad/param norm = 2.3770e-01, time/batch = 15.6473s	
20939/25300 (epoch 41.381), train_loss = 0.69993536, grad/param norm = 2.1184e-01, time/batch = 16.7314s	
20940/25300 (epoch 41.383), train_loss = 0.66612963, grad/param norm = 2.1555e-01, time/batch = 16.0211s	
20941/25300 (epoch 41.385), train_loss = 0.72800779, grad/param norm = 1.9820e-01, time/batch = 16.2236s	
20942/25300 (epoch 41.387), train_loss = 0.72715856, grad/param norm = 2.4221e-01, time/batch = 15.9847s	
20943/25300 (epoch 41.389), train_loss = 0.68554179, grad/param norm = 2.2785e-01, time/batch = 15.7146s	
20944/25300 (epoch 41.391), train_loss = 0.68083573, grad/param norm = 2.1162e-01, time/batch = 15.5514s	
20945/25300 (epoch 41.393), train_loss = 0.72742108, grad/param norm = 2.9085e-01, time/batch = 16.3752s	
20946/25300 (epoch 41.395), train_loss = 0.57862814, grad/param norm = 1.9775e-01, time/batch = 15.6413s	
20947/25300 (epoch 41.397), train_loss = 0.54342489, grad/param norm = 2.0483e-01, time/batch = 15.8137s	
20948/25300 (epoch 41.399), train_loss = 0.61661124, grad/param norm = 2.1474e-01, time/batch = 15.6342s	
20949/25300 (epoch 41.401), train_loss = 0.75347136, grad/param norm = 2.4536e-01, time/batch = 16.6484s	
20950/25300 (epoch 41.403), train_loss = 0.76593823, grad/param norm = 4.4724e-01, time/batch = 15.6526s	
20951/25300 (epoch 41.405), train_loss = 0.67844422, grad/param norm = 2.2236e-01, time/batch = 15.6420s	
20952/25300 (epoch 41.407), train_loss = 0.68407513, grad/param norm = 2.2966e-01, time/batch = 15.8885s	
20953/25300 (epoch 41.409), train_loss = 0.64337973, grad/param norm = 2.1281e-01, time/batch = 15.8150s	
20954/25300 (epoch 41.411), train_loss = 0.66910364, grad/param norm = 2.2493e-01, time/batch = 15.8040s	
20955/25300 (epoch 41.413), train_loss = 0.59700605, grad/param norm = 2.0335e-01, time/batch = 15.3732s	
20956/25300 (epoch 41.415), train_loss = 0.62061657, grad/param norm = 2.1438e-01, time/batch = 16.1508s	
20957/25300 (epoch 41.417), train_loss = 0.58169572, grad/param norm = 1.8507e-01, time/batch = 17.5494s	
20958/25300 (epoch 41.419), train_loss = 0.51651870, grad/param norm = 1.6429e-01, time/batch = 16.1236s	
20959/25300 (epoch 41.421), train_loss = 0.60491581, grad/param norm = 1.7125e-01, time/batch = 15.6176s	
20960/25300 (epoch 41.423), train_loss = 0.59563167, grad/param norm = 1.9906e-01, time/batch = 15.2424s	
20961/25300 (epoch 41.425), train_loss = 0.68692438, grad/param norm = 2.7107e-01, time/batch = 15.6559s	
20962/25300 (epoch 41.427), train_loss = 0.76630745, grad/param norm = 2.3673e-01, time/batch = 15.7269s	
20963/25300 (epoch 41.429), train_loss = 0.79027464, grad/param norm = 2.5995e-01, time/batch = 15.5567s	
20964/25300 (epoch 41.431), train_loss = 0.70931183, grad/param norm = 2.1826e-01, time/batch = 15.4708s	
20965/25300 (epoch 41.433), train_loss = 0.72829388, grad/param norm = 2.0083e-01, time/batch = 15.6527s	
20966/25300 (epoch 41.435), train_loss = 0.65154828, grad/param norm = 2.4909e-01, time/batch = 15.7047s	
20967/25300 (epoch 41.437), train_loss = 0.63984446, grad/param norm = 2.2600e-01, time/batch = 15.7156s	
20968/25300 (epoch 41.439), train_loss = 0.73331808, grad/param norm = 2.4759e-01, time/batch = 16.1295s	
20969/25300 (epoch 41.441), train_loss = 0.74740728, grad/param norm = 2.5054e-01, time/batch = 16.2229s	
20970/25300 (epoch 41.443), train_loss = 0.84100497, grad/param norm = 2.4529e-01, time/batch = 15.7708s	
20971/25300 (epoch 41.445), train_loss = 0.79287563, grad/param norm = 2.4066e-01, time/batch = 16.3135s	
20972/25300 (epoch 41.447), train_loss = 0.63962617, grad/param norm = 2.0235e-01, time/batch = 16.3037s	
20973/25300 (epoch 41.449), train_loss = 0.56616188, grad/param norm = 2.0730e-01, time/batch = 17.1219s	
20974/25300 (epoch 41.451), train_loss = 0.89574723, grad/param norm = 2.7362e-01, time/batch = 16.1267s	
20975/25300 (epoch 41.453), train_loss = 0.76603016, grad/param norm = 2.4591e-01, time/batch = 16.6282s	
20976/25300 (epoch 41.455), train_loss = 0.72950435, grad/param norm = 2.4275e-01, time/batch = 17.0421s	
20977/25300 (epoch 41.457), train_loss = 0.63462585, grad/param norm = 1.9703e-01, time/batch = 16.1970s	
20978/25300 (epoch 41.458), train_loss = 0.67862092, grad/param norm = 2.3500e-01, time/batch = 16.2149s	
20979/25300 (epoch 41.460), train_loss = 0.68149878, grad/param norm = 2.4387e-01, time/batch = 16.1473s	
20980/25300 (epoch 41.462), train_loss = 0.48648385, grad/param norm = 2.1474e-01, time/batch = 16.2971s	
20981/25300 (epoch 41.464), train_loss = 0.76720608, grad/param norm = 2.5119e-01, time/batch = 16.5430s	
20982/25300 (epoch 41.466), train_loss = 0.70892733, grad/param norm = 2.2959e-01, time/batch = 16.4703s	
20983/25300 (epoch 41.468), train_loss = 0.72748301, grad/param norm = 2.2169e-01, time/batch = 15.6345s	
20984/25300 (epoch 41.470), train_loss = 0.69384725, grad/param norm = 2.3710e-01, time/batch = 16.3803s	
20985/25300 (epoch 41.472), train_loss = 0.57518498, grad/param norm = 1.9399e-01, time/batch = 15.7105s	
20986/25300 (epoch 41.474), train_loss = 0.74849773, grad/param norm = 2.3958e-01, time/batch = 16.4822s	
20987/25300 (epoch 41.476), train_loss = 0.65118801, grad/param norm = 2.5435e-01, time/batch = 16.2831s	
20988/25300 (epoch 41.478), train_loss = 0.73076726, grad/param norm = 2.8462e-01, time/batch = 16.3802s	
20989/25300 (epoch 41.480), train_loss = 0.69883591, grad/param norm = 2.4847e-01, time/batch = 15.7285s	
20990/25300 (epoch 41.482), train_loss = 0.72163674, grad/param norm = 2.5624e-01, time/batch = 15.8979s	
20991/25300 (epoch 41.484), train_loss = 0.75458381, grad/param norm = 2.3460e-01, time/batch = 16.4797s	
20992/25300 (epoch 41.486), train_loss = 0.70922471, grad/param norm = 2.7386e-01, time/batch = 16.2970s	
20993/25300 (epoch 41.488), train_loss = 0.85720961, grad/param norm = 2.7540e-01, time/batch = 15.7227s	
20994/25300 (epoch 41.490), train_loss = 0.71655722, grad/param norm = 2.6229e-01, time/batch = 15.3183s	
20995/25300 (epoch 41.492), train_loss = 0.81650173, grad/param norm = 2.3717e-01, time/batch = 15.6427s	
20996/25300 (epoch 41.494), train_loss = 0.71807108, grad/param norm = 2.2670e-01, time/batch = 15.4470s	
20997/25300 (epoch 41.496), train_loss = 0.76747927, grad/param norm = 2.3581e-01, time/batch = 15.6543s	
20998/25300 (epoch 41.498), train_loss = 0.68657506, grad/param norm = 1.9547e-01, time/batch = 16.6346s	
20999/25300 (epoch 41.500), train_loss = 0.81380973, grad/param norm = 2.2907e-01, time/batch = 16.1352s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch41.50_1.8300.t7	
21000/25300 (epoch 41.502), train_loss = 0.75610451, grad/param norm = 2.7673e-01, time/batch = 17.2995s	
21001/25300 (epoch 41.504), train_loss = 1.28774255, grad/param norm = 3.6349e-01, time/batch = 16.0527s	
21002/25300 (epoch 41.506), train_loss = 0.60421872, grad/param norm = 2.3304e-01, time/batch = 16.2852s	
21003/25300 (epoch 41.508), train_loss = 0.70666581, grad/param norm = 2.3990e-01, time/batch = 16.7268s	
21004/25300 (epoch 41.510), train_loss = 0.69116384, grad/param norm = 2.3759e-01, time/batch = 16.2098s	
21005/25300 (epoch 41.512), train_loss = 0.55502613, grad/param norm = 1.8762e-01, time/batch = 15.8241s	
21006/25300 (epoch 41.514), train_loss = 0.69824128, grad/param norm = 2.2538e-01, time/batch = 15.5686s	
21007/25300 (epoch 41.516), train_loss = 0.78126530, grad/param norm = 2.6307e-01, time/batch = 15.8908s	
21008/25300 (epoch 41.518), train_loss = 0.80270440, grad/param norm = 2.6905e-01, time/batch = 15.6360s	
21009/25300 (epoch 41.520), train_loss = 0.57864231, grad/param norm = 1.8417e-01, time/batch = 15.6368s	
21010/25300 (epoch 41.522), train_loss = 0.68487968, grad/param norm = 2.5726e-01, time/batch = 16.1379s	
21011/25300 (epoch 41.524), train_loss = 0.63668879, grad/param norm = 2.1164e-01, time/batch = 15.5594s	
21012/25300 (epoch 41.526), train_loss = 0.80216590, grad/param norm = 2.2576e-01, time/batch = 15.7224s	
21013/25300 (epoch 41.528), train_loss = 0.85160943, grad/param norm = 2.4378e-01, time/batch = 16.2196s	
21014/25300 (epoch 41.530), train_loss = 0.78867121, grad/param norm = 2.4986e-01, time/batch = 15.8988s	
21015/25300 (epoch 41.532), train_loss = 0.68232303, grad/param norm = 2.2113e-01, time/batch = 15.8625s	
21016/25300 (epoch 41.534), train_loss = 0.69261632, grad/param norm = 2.4358e-01, time/batch = 16.3082s	
21017/25300 (epoch 41.536), train_loss = 0.60287742, grad/param norm = 3.1185e-01, time/batch = 15.7218s	
21018/25300 (epoch 41.538), train_loss = 0.61468316, grad/param norm = 1.9234e-01, time/batch = 16.7326s	
21019/25300 (epoch 41.540), train_loss = 0.62761942, grad/param norm = 2.4653e-01, time/batch = 15.7995s	
21020/25300 (epoch 41.542), train_loss = 0.60320781, grad/param norm = 2.3831e-01, time/batch = 16.5594s	
21021/25300 (epoch 41.543), train_loss = 0.59406475, grad/param norm = 1.8943e-01, time/batch = 15.3179s	
21022/25300 (epoch 41.545), train_loss = 0.87995630, grad/param norm = 2.9756e-01, time/batch = 15.3085s	
21023/25300 (epoch 41.547), train_loss = 0.78112795, grad/param norm = 2.4100e-01, time/batch = 16.3586s	
21024/25300 (epoch 41.549), train_loss = 0.90539778, grad/param norm = 3.6578e-01, time/batch = 16.4725s	
21025/25300 (epoch 41.551), train_loss = 0.80682495, grad/param norm = 2.2828e-01, time/batch = 15.2947s	
21026/25300 (epoch 41.553), train_loss = 0.70547001, grad/param norm = 2.7503e-01, time/batch = 15.2930s	
21027/25300 (epoch 41.555), train_loss = 0.75114780, grad/param norm = 2.6951e-01, time/batch = 15.3998s	
21028/25300 (epoch 41.557), train_loss = 0.78892583, grad/param norm = 2.5984e-01, time/batch = 15.5616s	
21029/25300 (epoch 41.559), train_loss = 0.83177186, grad/param norm = 2.8601e-01, time/batch = 16.2996s	
21030/25300 (epoch 41.561), train_loss = 0.84767775, grad/param norm = 2.6463e-01, time/batch = 15.6415s	
21031/25300 (epoch 41.563), train_loss = 0.81525965, grad/param norm = 2.5086e-01, time/batch = 16.1337s	
21032/25300 (epoch 41.565), train_loss = 0.61843301, grad/param norm = 2.4280e-01, time/batch = 15.9652s	
21033/25300 (epoch 41.567), train_loss = 0.56154049, grad/param norm = 2.0889e-01, time/batch = 15.7383s	
21034/25300 (epoch 41.569), train_loss = 0.71367238, grad/param norm = 2.2097e-01, time/batch = 15.8008s	
21035/25300 (epoch 41.571), train_loss = 0.78457154, grad/param norm = 2.7044e-01, time/batch = 15.9069s	
21036/25300 (epoch 41.573), train_loss = 0.69898058, grad/param norm = 2.1533e-01, time/batch = 16.2841s	
21037/25300 (epoch 41.575), train_loss = 0.73394022, grad/param norm = 2.2873e-01, time/batch = 16.0580s	
21038/25300 (epoch 41.577), train_loss = 0.67049815, grad/param norm = 2.3168e-01, time/batch = 16.4444s	
21039/25300 (epoch 41.579), train_loss = 0.82944652, grad/param norm = 2.4562e-01, time/batch = 17.0623s	
21040/25300 (epoch 41.581), train_loss = 0.77696835, grad/param norm = 2.5114e-01, time/batch = 15.9036s	
21041/25300 (epoch 41.583), train_loss = 0.58174599, grad/param norm = 2.5457e-01, time/batch = 15.4631s	
21042/25300 (epoch 41.585), train_loss = 0.61134176, grad/param norm = 2.2168e-01, time/batch = 17.0452s	
21043/25300 (epoch 41.587), train_loss = 0.68900323, grad/param norm = 2.2787e-01, time/batch = 16.5762s	
21044/25300 (epoch 41.589), train_loss = 0.62363887, grad/param norm = 1.8401e-01, time/batch = 18.2901s	
21045/25300 (epoch 41.591), train_loss = 0.58857181, grad/param norm = 2.4834e-01, time/batch = 16.0522s	
21046/25300 (epoch 41.593), train_loss = 0.79075204, grad/param norm = 2.3646e-01, time/batch = 16.6194s	
21047/25300 (epoch 41.595), train_loss = 0.71914025, grad/param norm = 2.1712e-01, time/batch = 16.3034s	
21048/25300 (epoch 41.597), train_loss = 0.64371369, grad/param norm = 2.1934e-01, time/batch = 16.2244s	
21049/25300 (epoch 41.599), train_loss = 0.82239766, grad/param norm = 2.4857e-01, time/batch = 15.7292s	
21050/25300 (epoch 41.601), train_loss = 0.71379600, grad/param norm = 2.7537e-01, time/batch = 16.0656s	
21051/25300 (epoch 41.603), train_loss = 0.69719352, grad/param norm = 2.3683e-01, time/batch = 16.0432s	
21052/25300 (epoch 41.605), train_loss = 0.69664484, grad/param norm = 2.1973e-01, time/batch = 16.5577s	
21053/25300 (epoch 41.607), train_loss = 0.50628760, grad/param norm = 1.6702e-01, time/batch = 16.2228s	
21054/25300 (epoch 41.609), train_loss = 0.63419011, grad/param norm = 2.1173e-01, time/batch = 16.7313s	
21055/25300 (epoch 41.611), train_loss = 0.79008523, grad/param norm = 2.7962e-01, time/batch = 17.0516s	
21056/25300 (epoch 41.613), train_loss = 0.63852055, grad/param norm = 2.0753e-01, time/batch = 15.3053s	
21057/25300 (epoch 41.615), train_loss = 0.69166138, grad/param norm = 2.9713e-01, time/batch = 16.0706s	
21058/25300 (epoch 41.617), train_loss = 0.72190738, grad/param norm = 2.3847e-01, time/batch = 15.9842s	
21059/25300 (epoch 41.619), train_loss = 0.78961625, grad/param norm = 2.7274e-01, time/batch = 16.2977s	
21060/25300 (epoch 41.621), train_loss = 0.79172092, grad/param norm = 2.9007e-01, time/batch = 16.4690s	
21061/25300 (epoch 41.623), train_loss = 0.66948679, grad/param norm = 2.4507e-01, time/batch = 15.7316s	
21062/25300 (epoch 41.625), train_loss = 0.59575989, grad/param norm = 2.2122e-01, time/batch = 15.9683s	
21063/25300 (epoch 41.626), train_loss = 0.69220806, grad/param norm = 2.1133e-01, time/batch = 21.2220s	
21064/25300 (epoch 41.628), train_loss = 0.81454815, grad/param norm = 2.6704e-01, time/batch = 24.1013s	
21065/25300 (epoch 41.630), train_loss = 0.76228749, grad/param norm = 2.6577e-01, time/batch = 15.7297s	
21066/25300 (epoch 41.632), train_loss = 0.70342776, grad/param norm = 2.5429e-01, time/batch = 15.7214s	
21067/25300 (epoch 41.634), train_loss = 0.81940173, grad/param norm = 3.3993e-01, time/batch = 15.4884s	
21068/25300 (epoch 41.636), train_loss = 0.63418399, grad/param norm = 2.8273e-01, time/batch = 15.7261s	
21069/25300 (epoch 41.638), train_loss = 0.70246498, grad/param norm = 3.0457e-01, time/batch = 15.5344s	
21070/25300 (epoch 41.640), train_loss = 0.91625494, grad/param norm = 3.2724e-01, time/batch = 15.4587s	
21071/25300 (epoch 41.642), train_loss = 0.77964177, grad/param norm = 3.0462e-01, time/batch = 17.1265s	
21072/25300 (epoch 41.644), train_loss = 0.73592592, grad/param norm = 2.6426e-01, time/batch = 16.3262s	
21073/25300 (epoch 41.646), train_loss = 0.66636984, grad/param norm = 2.9090e-01, time/batch = 15.9006s	
21074/25300 (epoch 41.648), train_loss = 0.82749103, grad/param norm = 2.3433e-01, time/batch = 15.6401s	
21075/25300 (epoch 41.650), train_loss = 0.74881232, grad/param norm = 2.2382e-01, time/batch = 16.3837s	
21076/25300 (epoch 41.652), train_loss = 0.75611836, grad/param norm = 2.7030e-01, time/batch = 15.6513s	
21077/25300 (epoch 41.654), train_loss = 0.83397958, grad/param norm = 2.5972e-01, time/batch = 15.8833s	
21078/25300 (epoch 41.656), train_loss = 0.77705400, grad/param norm = 2.6439e-01, time/batch = 16.1342s	
21079/25300 (epoch 41.658), train_loss = 0.56431273, grad/param norm = 1.8204e-01, time/batch = 15.7164s	
21080/25300 (epoch 41.660), train_loss = 0.57613711, grad/param norm = 2.3372e-01, time/batch = 16.5592s	
21081/25300 (epoch 41.662), train_loss = 0.59717825, grad/param norm = 1.9104e-01, time/batch = 15.8899s	
21082/25300 (epoch 41.664), train_loss = 0.56280120, grad/param norm = 2.1424e-01, time/batch = 15.6190s	
21083/25300 (epoch 41.666), train_loss = 0.61072497, grad/param norm = 2.3140e-01, time/batch = 15.6348s	
21084/25300 (epoch 41.668), train_loss = 0.71162527, grad/param norm = 3.0843e-01, time/batch = 16.4764s	
21085/25300 (epoch 41.670), train_loss = 0.65164188, grad/param norm = 3.1465e-01, time/batch = 15.4725s	
21086/25300 (epoch 41.672), train_loss = 0.65910466, grad/param norm = 2.5514e-01, time/batch = 16.8099s	
21087/25300 (epoch 41.674), train_loss = 0.62704344, grad/param norm = 2.0295e-01, time/batch = 15.6334s	
21088/25300 (epoch 41.676), train_loss = 0.64693246, grad/param norm = 2.9449e-01, time/batch = 15.3842s	
21089/25300 (epoch 41.678), train_loss = 0.64797575, grad/param norm = 2.2473e-01, time/batch = 15.6336s	
21090/25300 (epoch 41.680), train_loss = 0.56416906, grad/param norm = 2.0010e-01, time/batch = 16.0492s	
21091/25300 (epoch 41.682), train_loss = 0.49033355, grad/param norm = 1.7782e-01, time/batch = 16.4657s	
21092/25300 (epoch 41.684), train_loss = 0.62259089, grad/param norm = 1.8844e-01, time/batch = 16.1420s	
21093/25300 (epoch 41.686), train_loss = 0.58034716, grad/param norm = 2.1424e-01, time/batch = 16.3949s	
21094/25300 (epoch 41.688), train_loss = 0.68064761, grad/param norm = 2.8826e-01, time/batch = 15.7301s	
21095/25300 (epoch 41.690), train_loss = 0.60240381, grad/param norm = 2.3207e-01, time/batch = 15.5566s	
21096/25300 (epoch 41.692), train_loss = 0.63471690, grad/param norm = 2.4903e-01, time/batch = 15.9632s	
21097/25300 (epoch 41.694), train_loss = 0.64690921, grad/param norm = 2.4590e-01, time/batch = 16.4820s	
21098/25300 (epoch 41.696), train_loss = 0.69742937, grad/param norm = 2.7409e-01, time/batch = 16.3979s	
21099/25300 (epoch 41.698), train_loss = 0.75488151, grad/param norm = 2.1870e-01, time/batch = 16.4001s	
21100/25300 (epoch 41.700), train_loss = 0.57717356, grad/param norm = 2.1371e-01, time/batch = 15.6275s	
21101/25300 (epoch 41.702), train_loss = 0.75009868, grad/param norm = 2.6485e-01, time/batch = 16.3847s	
21102/25300 (epoch 41.704), train_loss = 0.56086307, grad/param norm = 2.0209e-01, time/batch = 15.7257s	
21103/25300 (epoch 41.706), train_loss = 0.68881942, grad/param norm = 2.5305e-01, time/batch = 16.5607s	
21104/25300 (epoch 41.708), train_loss = 0.59345819, grad/param norm = 1.9911e-01, time/batch = 15.4743s	
21105/25300 (epoch 41.709), train_loss = 0.79425322, grad/param norm = 2.1249e-01, time/batch = 16.3187s	
21106/25300 (epoch 41.711), train_loss = 0.84243954, grad/param norm = 2.8673e-01, time/batch = 15.9125s	
21107/25300 (epoch 41.713), train_loss = 0.71272475, grad/param norm = 2.0453e-01, time/batch = 15.8117s	
21108/25300 (epoch 41.715), train_loss = 0.70767553, grad/param norm = 2.0973e-01, time/batch = 15.6422s	
21109/25300 (epoch 41.717), train_loss = 0.61238420, grad/param norm = 2.0961e-01, time/batch = 16.3123s	
21110/25300 (epoch 41.719), train_loss = 0.68500845, grad/param norm = 2.2915e-01, time/batch = 16.6375s	
21111/25300 (epoch 41.721), train_loss = 0.72821085, grad/param norm = 2.4870e-01, time/batch = 15.6171s	
21112/25300 (epoch 41.723), train_loss = 0.68657531, grad/param norm = 2.2018e-01, time/batch = 15.6447s	
21113/25300 (epoch 41.725), train_loss = 0.71079779, grad/param norm = 2.5132e-01, time/batch = 16.5698s	
21114/25300 (epoch 41.727), train_loss = 0.69535220, grad/param norm = 2.3647e-01, time/batch = 16.4062s	
21115/25300 (epoch 41.729), train_loss = 0.67292604, grad/param norm = 2.3078e-01, time/batch = 16.2007s	
21116/25300 (epoch 41.731), train_loss = 0.82525921, grad/param norm = 2.4109e-01, time/batch = 15.1599s	
21117/25300 (epoch 41.733), train_loss = 0.69779725, grad/param norm = 2.0372e-01, time/batch = 15.5673s	
21118/25300 (epoch 41.735), train_loss = 0.89222613, grad/param norm = 2.5097e-01, time/batch = 15.7315s	
21119/25300 (epoch 41.737), train_loss = 0.58188903, grad/param norm = 2.2739e-01, time/batch = 15.8008s	
21120/25300 (epoch 41.739), train_loss = 0.81242595, grad/param norm = 2.6526e-01, time/batch = 15.3201s	
21121/25300 (epoch 41.741), train_loss = 0.70663584, grad/param norm = 2.3574e-01, time/batch = 15.3812s	
21122/25300 (epoch 41.743), train_loss = 0.70772119, grad/param norm = 2.1537e-01, time/batch = 15.1857s	
21123/25300 (epoch 41.745), train_loss = 0.66956669, grad/param norm = 2.3706e-01, time/batch = 15.2785s	
21124/25300 (epoch 41.747), train_loss = 0.60331331, grad/param norm = 2.0030e-01, time/batch = 15.2992s	
21125/25300 (epoch 41.749), train_loss = 0.70038551, grad/param norm = 2.4677e-01, time/batch = 15.1099s	
21126/25300 (epoch 41.751), train_loss = 0.73537475, grad/param norm = 2.2420e-01, time/batch = 15.2815s	
21127/25300 (epoch 41.753), train_loss = 0.60146815, grad/param norm = 2.3313e-01, time/batch = 15.5331s	
21128/25300 (epoch 41.755), train_loss = 0.80496685, grad/param norm = 2.8355e-01, time/batch = 16.0263s	
21129/25300 (epoch 41.757), train_loss = 0.65238659, grad/param norm = 2.2569e-01, time/batch = 16.2169s	
21130/25300 (epoch 41.759), train_loss = 0.62126062, grad/param norm = 2.2367e-01, time/batch = 15.3549s	
21131/25300 (epoch 41.761), train_loss = 0.82845323, grad/param norm = 2.3996e-01, time/batch = 16.9835s	
21132/25300 (epoch 41.763), train_loss = 0.69435006, grad/param norm = 2.2531e-01, time/batch = 15.5637s	
21133/25300 (epoch 41.765), train_loss = 0.66369999, grad/param norm = 2.8425e-01, time/batch = 16.5603s	
21134/25300 (epoch 41.767), train_loss = 0.66770313, grad/param norm = 1.9806e-01, time/batch = 15.3926s	
21135/25300 (epoch 41.769), train_loss = 0.69762674, grad/param norm = 3.1040e-01, time/batch = 16.6464s	
21136/25300 (epoch 41.771), train_loss = 0.76951219, grad/param norm = 2.6874e-01, time/batch = 16.6344s	
21137/25300 (epoch 41.773), train_loss = 0.79807766, grad/param norm = 2.4774e-01, time/batch = 16.4602s	
21138/25300 (epoch 41.775), train_loss = 0.71817236, grad/param norm = 2.1444e-01, time/batch = 16.7090s	
21139/25300 (epoch 41.777), train_loss = 0.65620812, grad/param norm = 2.3076e-01, time/batch = 16.0560s	
21140/25300 (epoch 41.779), train_loss = 0.76624743, grad/param norm = 2.2975e-01, time/batch = 16.4573s	
21141/25300 (epoch 41.781), train_loss = 0.75282402, grad/param norm = 2.4005e-01, time/batch = 15.9307s	
21142/25300 (epoch 41.783), train_loss = 0.81962198, grad/param norm = 2.4014e-01, time/batch = 15.2470s	
21143/25300 (epoch 41.785), train_loss = 0.78217558, grad/param norm = 2.5895e-01, time/batch = 15.3093s	
21144/25300 (epoch 41.787), train_loss = 0.76583997, grad/param norm = 2.5838e-01, time/batch = 16.3819s	
21145/25300 (epoch 41.789), train_loss = 0.82912567, grad/param norm = 2.5645e-01, time/batch = 15.7030s	
21146/25300 (epoch 41.791), train_loss = 0.76347210, grad/param norm = 2.2029e-01, time/batch = 15.9641s	
21147/25300 (epoch 41.792), train_loss = 0.81698463, grad/param norm = 2.4131e-01, time/batch = 15.8841s	
21148/25300 (epoch 41.794), train_loss = 0.68801771, grad/param norm = 2.6137e-01, time/batch = 16.6428s	
21149/25300 (epoch 41.796), train_loss = 0.65396958, grad/param norm = 2.1862e-01, time/batch = 15.6336s	
21150/25300 (epoch 41.798), train_loss = 0.81297897, grad/param norm = 3.1636e-01, time/batch = 15.6651s	
21151/25300 (epoch 41.800), train_loss = 0.67302919, grad/param norm = 2.0644e-01, time/batch = 15.7079s	
21152/25300 (epoch 41.802), train_loss = 0.57710482, grad/param norm = 1.9774e-01, time/batch = 15.5563s	
21153/25300 (epoch 41.804), train_loss = 0.70151810, grad/param norm = 1.8455e-01, time/batch = 15.5550s	
21154/25300 (epoch 41.806), train_loss = 0.76575833, grad/param norm = 2.7432e-01, time/batch = 15.6441s	
21155/25300 (epoch 41.808), train_loss = 0.81445590, grad/param norm = 2.0836e-01, time/batch = 15.2390s	
21156/25300 (epoch 41.810), train_loss = 0.69260819, grad/param norm = 2.2122e-01, time/batch = 15.3025s	
21157/25300 (epoch 41.812), train_loss = 0.81588085, grad/param norm = 2.6143e-01, time/batch = 15.5582s	
21158/25300 (epoch 41.814), train_loss = 0.83054641, grad/param norm = 3.3092e-01, time/batch = 16.0621s	
21159/25300 (epoch 41.816), train_loss = 0.92724817, grad/param norm = 2.8091e-01, time/batch = 16.1075s	
21160/25300 (epoch 41.818), train_loss = 0.80637172, grad/param norm = 2.0967e-01, time/batch = 15.5408s	
21161/25300 (epoch 41.820), train_loss = 0.77599613, grad/param norm = 2.4350e-01, time/batch = 15.6481s	
21162/25300 (epoch 41.822), train_loss = 0.65218808, grad/param norm = 2.3930e-01, time/batch = 16.0735s	
21163/25300 (epoch 41.824), train_loss = 0.81644405, grad/param norm = 2.6999e-01, time/batch = 15.7256s	
21164/25300 (epoch 41.826), train_loss = 0.66447545, grad/param norm = 2.1188e-01, time/batch = 15.9586s	
21165/25300 (epoch 41.828), train_loss = 0.66624327, grad/param norm = 2.3102e-01, time/batch = 16.0581s	
21166/25300 (epoch 41.830), train_loss = 0.75309898, grad/param norm = 2.4955e-01, time/batch = 16.5678s	
21167/25300 (epoch 41.832), train_loss = 0.84925368, grad/param norm = 2.9807e-01, time/batch = 15.8045s	
21168/25300 (epoch 41.834), train_loss = 0.66955327, grad/param norm = 2.0391e-01, time/batch = 15.9633s	
21169/25300 (epoch 41.836), train_loss = 0.69714905, grad/param norm = 2.1609e-01, time/batch = 16.2349s	
21170/25300 (epoch 41.838), train_loss = 0.68905866, grad/param norm = 2.2029e-01, time/batch = 17.3949s	
21171/25300 (epoch 41.840), train_loss = 0.76757508, grad/param norm = 2.6098e-01, time/batch = 16.2101s	
21172/25300 (epoch 41.842), train_loss = 0.72622438, grad/param norm = 2.7469e-01, time/batch = 16.8883s	
21173/25300 (epoch 41.844), train_loss = 0.80690562, grad/param norm = 1.9841e-01, time/batch = 15.5657s	
21174/25300 (epoch 41.846), train_loss = 0.80115751, grad/param norm = 2.1190e-01, time/batch = 17.1465s	
21175/25300 (epoch 41.848), train_loss = 0.75947608, grad/param norm = 2.7501e-01, time/batch = 16.0431s	
21176/25300 (epoch 41.850), train_loss = 0.77222077, grad/param norm = 2.3723e-01, time/batch = 15.8112s	
21177/25300 (epoch 41.852), train_loss = 0.79303222, grad/param norm = 2.2847e-01, time/batch = 15.3892s	
21178/25300 (epoch 41.854), train_loss = 0.83741264, grad/param norm = 2.5835e-01, time/batch = 16.3067s	
21179/25300 (epoch 41.856), train_loss = 0.66885278, grad/param norm = 2.4768e-01, time/batch = 15.3992s	
21180/25300 (epoch 41.858), train_loss = 0.68465780, grad/param norm = 2.3510e-01, time/batch = 15.7012s	
21181/25300 (epoch 41.860), train_loss = 0.61197510, grad/param norm = 2.0837e-01, time/batch = 17.0642s	
21182/25300 (epoch 41.862), train_loss = 0.73645184, grad/param norm = 2.5593e-01, time/batch = 15.8856s	
21183/25300 (epoch 41.864), train_loss = 0.86132529, grad/param norm = 2.3708e-01, time/batch = 15.5435s	
21184/25300 (epoch 41.866), train_loss = 0.66787132, grad/param norm = 2.3524e-01, time/batch = 15.8061s	
21185/25300 (epoch 41.868), train_loss = 0.79309404, grad/param norm = 2.1288e-01, time/batch = 16.4896s	
21186/25300 (epoch 41.870), train_loss = 0.79252409, grad/param norm = 2.2224e-01, time/batch = 15.6315s	
21187/25300 (epoch 41.872), train_loss = 0.75428026, grad/param norm = 2.8361e-01, time/batch = 16.7956s	
21188/25300 (epoch 41.874), train_loss = 0.78426526, grad/param norm = 2.5583e-01, time/batch = 15.8261s	
21189/25300 (epoch 41.875), train_loss = 0.70370623, grad/param norm = 2.1418e-01, time/batch = 17.3733s	
21190/25300 (epoch 41.877), train_loss = 0.68303720, grad/param norm = 2.3669e-01, time/batch = 16.5399s	
21191/25300 (epoch 41.879), train_loss = 0.65527915, grad/param norm = 2.1810e-01, time/batch = 16.1423s	
21192/25300 (epoch 41.881), train_loss = 0.91156079, grad/param norm = 2.7340e-01, time/batch = 15.9032s	
21193/25300 (epoch 41.883), train_loss = 0.89092420, grad/param norm = 2.5334e-01, time/batch = 16.6174s	
21194/25300 (epoch 41.885), train_loss = 0.79139321, grad/param norm = 3.0792e-01, time/batch = 17.5535s	
21195/25300 (epoch 41.887), train_loss = 0.79895771, grad/param norm = 2.2130e-01, time/batch = 16.0537s	
21196/25300 (epoch 41.889), train_loss = 0.85135282, grad/param norm = 2.4907e-01, time/batch = 15.2893s	
21197/25300 (epoch 41.891), train_loss = 0.74150864, grad/param norm = 2.3532e-01, time/batch = 15.6285s	
21198/25300 (epoch 41.893), train_loss = 0.73308518, grad/param norm = 2.4350e-01, time/batch = 15.8973s	
21199/25300 (epoch 41.895), train_loss = 0.56575422, grad/param norm = 2.0645e-01, time/batch = 16.4896s	
21200/25300 (epoch 41.897), train_loss = 0.63219286, grad/param norm = 2.4394e-01, time/batch = 15.4906s	
21201/25300 (epoch 41.899), train_loss = 0.73811848, grad/param norm = 2.5520e-01, time/batch = 16.2163s	
21202/25300 (epoch 41.901), train_loss = 0.80214517, grad/param norm = 2.4497e-01, time/batch = 15.6482s	
21203/25300 (epoch 41.903), train_loss = 0.60032401, grad/param norm = 2.0251e-01, time/batch = 15.7223s	
21204/25300 (epoch 41.905), train_loss = 0.68485785, grad/param norm = 3.0827e-01, time/batch = 15.9725s	
21205/25300 (epoch 41.907), train_loss = 0.68717524, grad/param norm = 3.9139e-01, time/batch = 15.6415s	
21206/25300 (epoch 41.909), train_loss = 0.77184549, grad/param norm = 2.3374e-01, time/batch = 16.3833s	
21207/25300 (epoch 41.911), train_loss = 0.83626627, grad/param norm = 3.1787e-01, time/batch = 15.7321s	
21208/25300 (epoch 41.913), train_loss = 0.92586080, grad/param norm = 2.9251e-01, time/batch = 15.8145s	
21209/25300 (epoch 41.915), train_loss = 0.69470273, grad/param norm = 2.4912e-01, time/batch = 15.9789s	
21210/25300 (epoch 41.917), train_loss = 0.88775982, grad/param norm = 2.5484e-01, time/batch = 16.0549s	
21211/25300 (epoch 41.919), train_loss = 0.85461439, grad/param norm = 2.8770e-01, time/batch = 15.5559s	
21212/25300 (epoch 41.921), train_loss = 0.70669908, grad/param norm = 2.3612e-01, time/batch = 15.2325s	
21213/25300 (epoch 41.923), train_loss = 0.81353151, grad/param norm = 2.5727e-01, time/batch = 15.2988s	
21214/25300 (epoch 41.925), train_loss = 0.74205395, grad/param norm = 2.8842e-01, time/batch = 15.3999s	
21215/25300 (epoch 41.927), train_loss = 0.75980921, grad/param norm = 2.6894e-01, time/batch = 16.2306s	
21216/25300 (epoch 41.929), train_loss = 0.79777870, grad/param norm = 2.3567e-01, time/batch = 15.6335s	
21217/25300 (epoch 41.931), train_loss = 0.76676103, grad/param norm = 2.6073e-01, time/batch = 16.6423s	
21218/25300 (epoch 41.933), train_loss = 0.76614490, grad/param norm = 2.3248e-01, time/batch = 15.7324s	
21219/25300 (epoch 41.935), train_loss = 0.79959542, grad/param norm = 2.1495e-01, time/batch = 15.4691s	
21220/25300 (epoch 41.937), train_loss = 0.60365069, grad/param norm = 2.0587e-01, time/batch = 15.5549s	
21221/25300 (epoch 41.939), train_loss = 0.73437993, grad/param norm = 2.2054e-01, time/batch = 15.9712s	
21222/25300 (epoch 41.941), train_loss = 0.68391344, grad/param norm = 2.9792e-01, time/batch = 16.4809s	
21223/25300 (epoch 41.943), train_loss = 0.77085129, grad/param norm = 2.4060e-01, time/batch = 15.3048s	
21224/25300 (epoch 41.945), train_loss = 0.76474674, grad/param norm = 2.8345e-01, time/batch = 15.8030s	
21225/25300 (epoch 41.947), train_loss = 0.68387306, grad/param norm = 2.3973e-01, time/batch = 15.5609s	
21226/25300 (epoch 41.949), train_loss = 0.76368190, grad/param norm = 2.6059e-01, time/batch = 15.5722s	
21227/25300 (epoch 41.951), train_loss = 0.74831256, grad/param norm = 2.2008e-01, time/batch = 15.7050s	
21228/25300 (epoch 41.953), train_loss = 0.68339285, grad/param norm = 2.1511e-01, time/batch = 15.8955s	
21229/25300 (epoch 41.955), train_loss = 0.90638970, grad/param norm = 3.1951e-01, time/batch = 15.5683s	
21230/25300 (epoch 41.957), train_loss = 0.83897674, grad/param norm = 3.4182e-01, time/batch = 16.2373s	
21231/25300 (epoch 41.958), train_loss = 0.76682358, grad/param norm = 2.8575e-01, time/batch = 15.5396s	
21232/25300 (epoch 41.960), train_loss = 0.89618560, grad/param norm = 3.0421e-01, time/batch = 15.9048s	
21233/25300 (epoch 41.962), train_loss = 0.87421951, grad/param norm = 2.4434e-01, time/batch = 15.7893s	
21234/25300 (epoch 41.964), train_loss = 0.78338305, grad/param norm = 2.7192e-01, time/batch = 16.7991s	
21235/25300 (epoch 41.966), train_loss = 0.64049473, grad/param norm = 2.3634e-01, time/batch = 16.5518s	
21236/25300 (epoch 41.968), train_loss = 0.65176120, grad/param norm = 2.0489e-01, time/batch = 16.7989s	
21237/25300 (epoch 41.970), train_loss = 0.71646426, grad/param norm = 2.5226e-01, time/batch = 15.8062s	
21238/25300 (epoch 41.972), train_loss = 0.75031322, grad/param norm = 2.2869e-01, time/batch = 15.8192s	
21239/25300 (epoch 41.974), train_loss = 0.83656895, grad/param norm = 2.7256e-01, time/batch = 15.9752s	
21240/25300 (epoch 41.976), train_loss = 0.78122471, grad/param norm = 2.5210e-01, time/batch = 15.8708s	
21241/25300 (epoch 41.978), train_loss = 0.71665397, grad/param norm = 2.4187e-01, time/batch = 16.5532s	
21242/25300 (epoch 41.980), train_loss = 0.77813791, grad/param norm = 2.9001e-01, time/batch = 15.8015s	
21243/25300 (epoch 41.982), train_loss = 0.69977692, grad/param norm = 2.1197e-01, time/batch = 16.3965s	
21244/25300 (epoch 41.984), train_loss = 0.73138932, grad/param norm = 2.6772e-01, time/batch = 15.5659s	
21245/25300 (epoch 41.986), train_loss = 0.79324910, grad/param norm = 2.6027e-01, time/batch = 16.5582s	
21246/25300 (epoch 41.988), train_loss = 0.75680702, grad/param norm = 2.6870e-01, time/batch = 16.3723s	
21247/25300 (epoch 41.990), train_loss = 0.74915226, grad/param norm = 2.6360e-01, time/batch = 15.9763s	
21248/25300 (epoch 41.992), train_loss = 0.64556847, grad/param norm = 2.0467e-01, time/batch = 16.3938s	
21249/25300 (epoch 41.994), train_loss = 0.78217800, grad/param norm = 2.7021e-01, time/batch = 16.1210s	
21250/25300 (epoch 41.996), train_loss = 0.88504826, grad/param norm = 3.4341e-01, time/batch = 15.3930s	
21251/25300 (epoch 41.998), train_loss = 0.78676762, grad/param norm = 2.7821e-01, time/batch = 15.8073s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
21252/25300 (epoch 42.000), train_loss = 0.79938711, grad/param norm = 2.8454e-01, time/batch = 16.8109s	
21253/25300 (epoch 42.002), train_loss = 0.76193074, grad/param norm = 2.0435e-01, time/batch = 16.2177s	
21254/25300 (epoch 42.004), train_loss = 0.62917175, grad/param norm = 2.1474e-01, time/batch = 16.3799s	
21255/25300 (epoch 42.006), train_loss = 0.89658239, grad/param norm = 2.7034e-01, time/batch = 15.6547s	
21256/25300 (epoch 42.008), train_loss = 0.74757596, grad/param norm = 2.1558e-01, time/batch = 17.1374s	
21257/25300 (epoch 42.010), train_loss = 0.81981618, grad/param norm = 2.3519e-01, time/batch = 15.4647s	
21258/25300 (epoch 42.012), train_loss = 0.71006536, grad/param norm = 2.1032e-01, time/batch = 16.4792s	
21259/25300 (epoch 42.014), train_loss = 0.87359557, grad/param norm = 2.6009e-01, time/batch = 15.2922s	
21260/25300 (epoch 42.016), train_loss = 0.73320679, grad/param norm = 2.4655e-01, time/batch = 14.9885s	
21261/25300 (epoch 42.018), train_loss = 0.68630181, grad/param norm = 2.3615e-01, time/batch = 15.2868s	
21262/25300 (epoch 42.020), train_loss = 0.78145237, grad/param norm = 2.5238e-01, time/batch = 17.0548s	
21263/25300 (epoch 42.022), train_loss = 0.76051649, grad/param norm = 2.9699e-01, time/batch = 16.7078s	
21264/25300 (epoch 42.024), train_loss = 0.59204599, grad/param norm = 1.8938e-01, time/batch = 15.5558s	
21265/25300 (epoch 42.026), train_loss = 0.71214874, grad/param norm = 2.5117e-01, time/batch = 15.5544s	
21266/25300 (epoch 42.028), train_loss = 0.67951404, grad/param norm = 1.9772e-01, time/batch = 15.3165s	
21267/25300 (epoch 42.030), train_loss = 0.86281261, grad/param norm = 2.1993e-01, time/batch = 15.4010s	
21268/25300 (epoch 42.032), train_loss = 0.69182204, grad/param norm = 2.2065e-01, time/batch = 15.9525s	
21269/25300 (epoch 42.034), train_loss = 0.66956228, grad/param norm = 2.1953e-01, time/batch = 15.7993s	
21270/25300 (epoch 42.036), train_loss = 0.62004777, grad/param norm = 2.2762e-01, time/batch = 15.2247s	
21271/25300 (epoch 42.038), train_loss = 0.55149521, grad/param norm = 1.7423e-01, time/batch = 15.8938s	
21272/25300 (epoch 42.040), train_loss = 0.73417679, grad/param norm = 2.3275e-01, time/batch = 15.8044s	
21273/25300 (epoch 42.042), train_loss = 0.72665338, grad/param norm = 2.1689e-01, time/batch = 15.6417s	
21274/25300 (epoch 42.043), train_loss = 0.65467187, grad/param norm = 1.9333e-01, time/batch = 16.0568s	
21275/25300 (epoch 42.045), train_loss = 0.61730292, grad/param norm = 2.0557e-01, time/batch = 16.4711s	
21276/25300 (epoch 42.047), train_loss = 0.73730800, grad/param norm = 2.1206e-01, time/batch = 15.6460s	
21277/25300 (epoch 42.049), train_loss = 0.74546638, grad/param norm = 2.4349e-01, time/batch = 16.2164s	
21278/25300 (epoch 42.051), train_loss = 0.88789679, grad/param norm = 2.5275e-01, time/batch = 16.0035s	
21279/25300 (epoch 42.053), train_loss = 0.58813658, grad/param norm = 1.7076e-01, time/batch = 15.8001s	
21280/25300 (epoch 42.055), train_loss = 0.60197666, grad/param norm = 2.3580e-01, time/batch = 15.8002s	
21281/25300 (epoch 42.057), train_loss = 0.60362571, grad/param norm = 1.7171e-01, time/batch = 16.7389s	
21282/25300 (epoch 42.059), train_loss = 0.67824726, grad/param norm = 2.1269e-01, time/batch = 16.3053s	
21283/25300 (epoch 42.061), train_loss = 0.67778954, grad/param norm = 2.3493e-01, time/batch = 15.9614s	
21284/25300 (epoch 42.063), train_loss = 0.70752740, grad/param norm = 2.0737e-01, time/batch = 16.7208s	
21285/25300 (epoch 42.065), train_loss = 0.73131541, grad/param norm = 2.3732e-01, time/batch = 15.5685s	
21286/25300 (epoch 42.067), train_loss = 0.77894349, grad/param norm = 2.0508e-01, time/batch = 15.2024s	
21287/25300 (epoch 42.069), train_loss = 0.64463837, grad/param norm = 2.1371e-01, time/batch = 27.8730s	
21288/25300 (epoch 42.071), train_loss = 0.76384025, grad/param norm = 2.4108e-01, time/batch = 15.8231s	
21289/25300 (epoch 42.073), train_loss = 0.70216191, grad/param norm = 1.9380e-01, time/batch = 15.2097s	
21290/25300 (epoch 42.075), train_loss = 0.76622443, grad/param norm = 2.4001e-01, time/batch = 15.4269s	
21291/25300 (epoch 42.077), train_loss = 0.74164845, grad/param norm = 2.4078e-01, time/batch = 15.3664s	
21292/25300 (epoch 42.079), train_loss = 0.65024415, grad/param norm = 1.9297e-01, time/batch = 15.1401s	
21293/25300 (epoch 42.081), train_loss = 0.72079187, grad/param norm = 2.1757e-01, time/batch = 15.2973s	
21294/25300 (epoch 42.083), train_loss = 0.76165236, grad/param norm = 2.2376e-01, time/batch = 15.7875s	
21295/25300 (epoch 42.085), train_loss = 0.88916388, grad/param norm = 2.4855e-01, time/batch = 15.6387s	
21296/25300 (epoch 42.087), train_loss = 0.78878816, grad/param norm = 2.1060e-01, time/batch = 15.7317s	
21297/25300 (epoch 42.089), train_loss = 0.75979247, grad/param norm = 2.0866e-01, time/batch = 15.1472s	
21298/25300 (epoch 42.091), train_loss = 0.89956828, grad/param norm = 2.5230e-01, time/batch = 15.7892s	
21299/25300 (epoch 42.093), train_loss = 0.80747261, grad/param norm = 2.6591e-01, time/batch = 15.2305s	
21300/25300 (epoch 42.095), train_loss = 0.78921983, grad/param norm = 2.1118e-01, time/batch = 15.7456s	
21301/25300 (epoch 42.097), train_loss = 0.79014166, grad/param norm = 2.4382e-01, time/batch = 16.1242s	
21302/25300 (epoch 42.099), train_loss = 0.78029632, grad/param norm = 2.5360e-01, time/batch = 15.5665s	
21303/25300 (epoch 42.101), train_loss = 0.72993624, grad/param norm = 2.3711e-01, time/batch = 15.4638s	
21304/25300 (epoch 42.103), train_loss = 0.78036104, grad/param norm = 2.5008e-01, time/batch = 16.5416s	
21305/25300 (epoch 42.105), train_loss = 0.77373725, grad/param norm = 2.2743e-01, time/batch = 15.7889s	
21306/25300 (epoch 42.107), train_loss = 0.75589341, grad/param norm = 2.7597e-01, time/batch = 16.2031s	
21307/25300 (epoch 42.109), train_loss = 0.71737456, grad/param norm = 2.5068e-01, time/batch = 15.7313s	
21308/25300 (epoch 42.111), train_loss = 0.70647811, grad/param norm = 2.4009e-01, time/batch = 16.9766s	
21309/25300 (epoch 42.113), train_loss = 0.68974767, grad/param norm = 2.1686e-01, time/batch = 15.2278s	
21310/25300 (epoch 42.115), train_loss = 0.73273589, grad/param norm = 2.3437e-01, time/batch = 16.3855s	
21311/25300 (epoch 42.117), train_loss = 0.78858063, grad/param norm = 2.0804e-01, time/batch = 16.0498s	
21312/25300 (epoch 42.119), train_loss = 0.68000692, grad/param norm = 2.1546e-01, time/batch = 16.1301s	
21313/25300 (epoch 42.121), train_loss = 0.76876782, grad/param norm = 3.2900e-01, time/batch = 15.8026s	
21314/25300 (epoch 42.123), train_loss = 0.68315559, grad/param norm = 2.2362e-01, time/batch = 15.5699s	
21315/25300 (epoch 42.125), train_loss = 0.83649487, grad/param norm = 2.5235e-01, time/batch = 15.7248s	
21316/25300 (epoch 42.126), train_loss = 0.74054490, grad/param norm = 2.0978e-01, time/batch = 15.9586s	
21317/25300 (epoch 42.128), train_loss = 0.70442937, grad/param norm = 2.1831e-01, time/batch = 15.9806s	
21318/25300 (epoch 42.130), train_loss = 0.58376587, grad/param norm = 2.1271e-01, time/batch = 15.8997s	
21319/25300 (epoch 42.132), train_loss = 0.59848676, grad/param norm = 2.2031e-01, time/batch = 15.8114s	
21320/25300 (epoch 42.134), train_loss = 0.60797279, grad/param norm = 1.9111e-01, time/batch = 15.5601s	
21321/25300 (epoch 42.136), train_loss = 0.71443024, grad/param norm = 2.2540e-01, time/batch = 15.6477s	
21322/25300 (epoch 42.138), train_loss = 0.63725572, grad/param norm = 1.9960e-01, time/batch = 15.6336s	
21323/25300 (epoch 42.140), train_loss = 0.59751862, grad/param norm = 1.9325e-01, time/batch = 16.3166s	
21324/25300 (epoch 42.142), train_loss = 0.82461060, grad/param norm = 2.3772e-01, time/batch = 15.7038s	
21325/25300 (epoch 42.144), train_loss = 0.79597508, grad/param norm = 2.3017e-01, time/batch = 15.8908s	
21326/25300 (epoch 42.146), train_loss = 0.70822546, grad/param norm = 2.5749e-01, time/batch = 15.5587s	
21327/25300 (epoch 42.148), train_loss = 0.71826186, grad/param norm = 2.4694e-01, time/batch = 15.7211s	
21328/25300 (epoch 42.150), train_loss = 0.74514173, grad/param norm = 2.3003e-01, time/batch = 15.6284s	
21329/25300 (epoch 42.152), train_loss = 0.82858903, grad/param norm = 2.5067e-01, time/batch = 15.8116s	
21330/25300 (epoch 42.154), train_loss = 0.62625450, grad/param norm = 1.9878e-01, time/batch = 16.0469s	
21331/25300 (epoch 42.156), train_loss = 0.74046658, grad/param norm = 2.4790e-01, time/batch = 16.3773s	
21332/25300 (epoch 42.158), train_loss = 0.62109069, grad/param norm = 2.1030e-01, time/batch = 15.8967s	
21333/25300 (epoch 42.160), train_loss = 0.70771749, grad/param norm = 2.2037e-01, time/batch = 16.3960s	
21334/25300 (epoch 42.162), train_loss = 0.65536121, grad/param norm = 2.3867e-01, time/batch = 15.7349s	
21335/25300 (epoch 42.164), train_loss = 0.78910683, grad/param norm = 2.6617e-01, time/batch = 15.5453s	
21336/25300 (epoch 42.166), train_loss = 0.71896542, grad/param norm = 2.0842e-01, time/batch = 16.1411s	
21337/25300 (epoch 42.168), train_loss = 0.66328772, grad/param norm = 1.9192e-01, time/batch = 15.5470s	
21338/25300 (epoch 42.170), train_loss = 0.66867217, grad/param norm = 2.2256e-01, time/batch = 16.2288s	
21339/25300 (epoch 42.172), train_loss = 0.60948112, grad/param norm = 2.0604e-01, time/batch = 15.2991s	
21340/25300 (epoch 42.174), train_loss = 0.64878124, grad/param norm = 2.1875e-01, time/batch = 15.5730s	
21341/25300 (epoch 42.176), train_loss = 0.63011754, grad/param norm = 3.0164e-01, time/batch = 15.9723s	
21342/25300 (epoch 42.178), train_loss = 0.83790832, grad/param norm = 2.5056e-01, time/batch = 15.5555s	
21343/25300 (epoch 42.180), train_loss = 0.59121158, grad/param norm = 2.3140e-01, time/batch = 16.2653s	
21344/25300 (epoch 42.182), train_loss = 0.67365158, grad/param norm = 2.1772e-01, time/batch = 16.1434s	
21345/25300 (epoch 42.184), train_loss = 0.63165109, grad/param norm = 1.9608e-01, time/batch = 16.4690s	
21346/25300 (epoch 42.186), train_loss = 0.61635153, grad/param norm = 2.4714e-01, time/batch = 15.7125s	
21347/25300 (epoch 42.188), train_loss = 0.73548452, grad/param norm = 2.8747e-01, time/batch = 16.7226s	
21348/25300 (epoch 42.190), train_loss = 0.74075005, grad/param norm = 2.3896e-01, time/batch = 16.3892s	
21349/25300 (epoch 42.192), train_loss = 0.68201143, grad/param norm = 2.4194e-01, time/batch = 15.3703s	
21350/25300 (epoch 42.194), train_loss = 0.67012390, grad/param norm = 2.5935e-01, time/batch = 15.8728s	
21351/25300 (epoch 42.196), train_loss = 0.79313128, grad/param norm = 2.3959e-01, time/batch = 17.1307s	
21352/25300 (epoch 42.198), train_loss = 0.65287233, grad/param norm = 2.4730e-01, time/batch = 15.9804s	
21353/25300 (epoch 42.200), train_loss = 0.71376880, grad/param norm = 2.9253e-01, time/batch = 15.6603s	
21354/25300 (epoch 42.202), train_loss = 0.71460413, grad/param norm = 2.3257e-01, time/batch = 15.6346s	
21355/25300 (epoch 42.204), train_loss = 0.69660766, grad/param norm = 1.9882e-01, time/batch = 16.0596s	
21356/25300 (epoch 42.206), train_loss = 0.79559330, grad/param norm = 2.4990e-01, time/batch = 16.0551s	
21357/25300 (epoch 42.208), train_loss = 0.66935622, grad/param norm = 2.1749e-01, time/batch = 16.1393s	
21358/25300 (epoch 42.209), train_loss = 0.62074771, grad/param norm = 2.0758e-01, time/batch = 15.4767s	
21359/25300 (epoch 42.211), train_loss = 0.70057175, grad/param norm = 2.2248e-01, time/batch = 16.3977s	
21360/25300 (epoch 42.213), train_loss = 0.72296518, grad/param norm = 2.2777e-01, time/batch = 16.0011s	
21361/25300 (epoch 42.215), train_loss = 0.75002392, grad/param norm = 2.2095e-01, time/batch = 15.5820s	
21362/25300 (epoch 42.217), train_loss = 0.74309093, grad/param norm = 2.6196e-01, time/batch = 15.2322s	
21363/25300 (epoch 42.219), train_loss = 0.77629437, grad/param norm = 3.2127e-01, time/batch = 14.9817s	
21364/25300 (epoch 42.221), train_loss = 0.81711470, grad/param norm = 2.6752e-01, time/batch = 16.4761s	
21365/25300 (epoch 42.223), train_loss = 0.77078565, grad/param norm = 2.7237e-01, time/batch = 15.9648s	
21366/25300 (epoch 42.225), train_loss = 0.97055371, grad/param norm = 3.1268e-01, time/batch = 17.1525s	
21367/25300 (epoch 42.227), train_loss = 0.86270694, grad/param norm = 2.5851e-01, time/batch = 16.9706s	
21368/25300 (epoch 42.229), train_loss = 0.69317495, grad/param norm = 2.2350e-01, time/batch = 16.5354s	
21369/25300 (epoch 42.231), train_loss = 0.75471326, grad/param norm = 3.3738e-01, time/batch = 16.6306s	
21370/25300 (epoch 42.233), train_loss = 0.77991534, grad/param norm = 2.7636e-01, time/batch = 17.4731s	
21371/25300 (epoch 42.235), train_loss = 0.72005119, grad/param norm = 2.2868e-01, time/batch = 16.2610s	
21372/25300 (epoch 42.237), train_loss = 0.84993581, grad/param norm = 2.9411e-01, time/batch = 16.1199s	
21373/25300 (epoch 42.239), train_loss = 0.68267554, grad/param norm = 2.2717e-01, time/batch = 16.4787s	
21374/25300 (epoch 42.241), train_loss = 0.87912389, grad/param norm = 2.4138e-01, time/batch = 16.5543s	
21375/25300 (epoch 42.243), train_loss = 0.95020880, grad/param norm = 2.9387e-01, time/batch = 16.7263s	
21376/25300 (epoch 42.245), train_loss = 0.69811237, grad/param norm = 2.3851e-01, time/batch = 15.6074s	
21377/25300 (epoch 42.247), train_loss = 0.76708453, grad/param norm = 2.4402e-01, time/batch = 16.9665s	
21378/25300 (epoch 42.249), train_loss = 0.66219953, grad/param norm = 2.0031e-01, time/batch = 16.0625s	
21379/25300 (epoch 42.251), train_loss = 0.66265787, grad/param norm = 2.5569e-01, time/batch = 16.3742s	
21380/25300 (epoch 42.253), train_loss = 0.71224518, grad/param norm = 2.7358e-01, time/batch = 16.3855s	
21381/25300 (epoch 42.255), train_loss = 0.67073763, grad/param norm = 2.3536e-01, time/batch = 16.5490s	
21382/25300 (epoch 42.257), train_loss = 0.68955646, grad/param norm = 2.3668e-01, time/batch = 15.6449s	
21383/25300 (epoch 42.259), train_loss = 0.83613532, grad/param norm = 2.6951e-01, time/batch = 16.2103s	
21384/25300 (epoch 42.261), train_loss = 0.83913677, grad/param norm = 2.9587e-01, time/batch = 16.4592s	
21385/25300 (epoch 42.263), train_loss = 0.83110541, grad/param norm = 2.4023e-01, time/batch = 16.6355s	
21386/25300 (epoch 42.265), train_loss = 0.85122158, grad/param norm = 2.4863e-01, time/batch = 15.9059s	
21387/25300 (epoch 42.267), train_loss = 0.76581421, grad/param norm = 2.4163e-01, time/batch = 15.4455s	
21388/25300 (epoch 42.269), train_loss = 0.60840939, grad/param norm = 1.9191e-01, time/batch = 17.3879s	
21389/25300 (epoch 42.271), train_loss = 0.68618007, grad/param norm = 2.3578e-01, time/batch = 15.7422s	
21390/25300 (epoch 42.273), train_loss = 0.78812543, grad/param norm = 2.4927e-01, time/batch = 16.8035s	
21391/25300 (epoch 42.275), train_loss = 0.71224863, grad/param norm = 2.0281e-01, time/batch = 15.9709s	
21392/25300 (epoch 42.277), train_loss = 0.65398908, grad/param norm = 2.6580e-01, time/batch = 17.3902s	
21393/25300 (epoch 42.279), train_loss = 0.74294679, grad/param norm = 2.9471e-01, time/batch = 16.7148s	
21394/25300 (epoch 42.281), train_loss = 0.86687818, grad/param norm = 2.5849e-01, time/batch = 16.3783s	
21395/25300 (epoch 42.283), train_loss = 0.65727500, grad/param norm = 2.1439e-01, time/batch = 16.6360s	
21396/25300 (epoch 42.285), train_loss = 0.73043781, grad/param norm = 2.6142e-01, time/batch = 16.3113s	
21397/25300 (epoch 42.287), train_loss = 0.83961389, grad/param norm = 2.1705e-01, time/batch = 15.3037s	
21398/25300 (epoch 42.289), train_loss = 0.70895287, grad/param norm = 2.3598e-01, time/batch = 16.2197s	
21399/25300 (epoch 42.291), train_loss = 0.71161996, grad/param norm = 2.6321e-01, time/batch = 15.1659s	
21400/25300 (epoch 42.292), train_loss = 0.91491750, grad/param norm = 2.3596e-01, time/batch = 15.3236s	
21401/25300 (epoch 42.294), train_loss = 0.76522667, grad/param norm = 2.3816e-01, time/batch = 16.0686s	
21402/25300 (epoch 42.296), train_loss = 0.63870790, grad/param norm = 1.9485e-01, time/batch = 15.2345s	
21403/25300 (epoch 42.298), train_loss = 0.81796335, grad/param norm = 2.6495e-01, time/batch = 15.7348s	
21404/25300 (epoch 42.300), train_loss = 0.80943849, grad/param norm = 3.0827e-01, time/batch = 15.1543s	
21405/25300 (epoch 42.302), train_loss = 0.60582541, grad/param norm = 2.4486e-01, time/batch = 15.3538s	
21406/25300 (epoch 42.304), train_loss = 0.85042086, grad/param norm = 2.3101e-01, time/batch = 16.3765s	
21407/25300 (epoch 42.306), train_loss = 0.58440448, grad/param norm = 2.1320e-01, time/batch = 16.1546s	
21408/25300 (epoch 42.308), train_loss = 0.81405871, grad/param norm = 2.5910e-01, time/batch = 15.6483s	
21409/25300 (epoch 42.310), train_loss = 0.64140834, grad/param norm = 2.2224e-01, time/batch = 15.3097s	
21410/25300 (epoch 42.312), train_loss = 0.76434021, grad/param norm = 2.1588e-01, time/batch = 15.9651s	
21411/25300 (epoch 42.314), train_loss = 0.64079596, grad/param norm = 2.2830e-01, time/batch = 16.1383s	
21412/25300 (epoch 42.316), train_loss = 0.75539319, grad/param norm = 2.1464e-01, time/batch = 16.3069s	
21413/25300 (epoch 42.318), train_loss = 0.58060417, grad/param norm = 1.8712e-01, time/batch = 15.3813s	
21414/25300 (epoch 42.320), train_loss = 0.66757357, grad/param norm = 2.1081e-01, time/batch = 16.3144s	
21415/25300 (epoch 42.322), train_loss = 0.85826070, grad/param norm = 2.9317e-01, time/batch = 15.9835s	
21416/25300 (epoch 42.324), train_loss = 0.66125502, grad/param norm = 2.1985e-01, time/batch = 15.8130s	
21417/25300 (epoch 42.326), train_loss = 0.58280662, grad/param norm = 2.2316e-01, time/batch = 15.3773s	
21418/25300 (epoch 42.328), train_loss = 0.60059822, grad/param norm = 2.0313e-01, time/batch = 16.3990s	
21419/25300 (epoch 42.330), train_loss = 0.68892582, grad/param norm = 2.1947e-01, time/batch = 15.7439s	
21420/25300 (epoch 42.332), train_loss = 0.74417531, grad/param norm = 2.5900e-01, time/batch = 15.2248s	
21421/25300 (epoch 42.334), train_loss = 0.60155881, grad/param norm = 3.1531e-01, time/batch = 15.3930s	
21422/25300 (epoch 42.336), train_loss = 0.62991427, grad/param norm = 2.6424e-01, time/batch = 16.5551s	
21423/25300 (epoch 42.338), train_loss = 0.62072355, grad/param norm = 2.1354e-01, time/batch = 15.6388s	
21424/25300 (epoch 42.340), train_loss = 0.67042125, grad/param norm = 2.1193e-01, time/batch = 16.0522s	
21425/25300 (epoch 42.342), train_loss = 0.67367915, grad/param norm = 2.7924e-01, time/batch = 15.2655s	
21426/25300 (epoch 42.344), train_loss = 0.79048726, grad/param norm = 2.5806e-01, time/batch = 15.2409s	
21427/25300 (epoch 42.346), train_loss = 0.68836235, grad/param norm = 2.4040e-01, time/batch = 16.5500s	
21428/25300 (epoch 42.348), train_loss = 0.65672446, grad/param norm = 2.2936e-01, time/batch = 15.2913s	
21429/25300 (epoch 42.350), train_loss = 0.67079258, grad/param norm = 2.2858e-01, time/batch = 15.5355s	
21430/25300 (epoch 42.352), train_loss = 0.72494387, grad/param norm = 2.4824e-01, time/batch = 15.5218s	
21431/25300 (epoch 42.354), train_loss = 0.67372573, grad/param norm = 2.1855e-01, time/batch = 15.2814s	
21432/25300 (epoch 42.356), train_loss = 0.69994663, grad/param norm = 2.1839e-01, time/batch = 15.2765s	
21433/25300 (epoch 42.358), train_loss = 0.70505605, grad/param norm = 2.8926e-01, time/batch = 15.4022s	
21434/25300 (epoch 42.360), train_loss = 0.65956469, grad/param norm = 2.5135e-01, time/batch = 15.6443s	
21435/25300 (epoch 42.362), train_loss = 0.59590391, grad/param norm = 2.5691e-01, time/batch = 16.8781s	
21436/25300 (epoch 42.364), train_loss = 0.62326129, grad/param norm = 2.3785e-01, time/batch = 15.6202s	
21437/25300 (epoch 42.366), train_loss = 0.62378173, grad/param norm = 2.3576e-01, time/batch = 15.4608s	
21438/25300 (epoch 42.368), train_loss = 0.67254446, grad/param norm = 1.9770e-01, time/batch = 16.7177s	
21439/25300 (epoch 42.370), train_loss = 0.64952123, grad/param norm = 2.3356e-01, time/batch = 15.9629s	
21440/25300 (epoch 42.372), train_loss = 0.63668811, grad/param norm = 2.7546e-01, time/batch = 15.3105s	
21441/25300 (epoch 42.374), train_loss = 0.59077520, grad/param norm = 2.2635e-01, time/batch = 16.7240s	
21442/25300 (epoch 42.375), train_loss = 0.78384045, grad/param norm = 2.5526e-01, time/batch = 16.0712s	
21443/25300 (epoch 42.377), train_loss = 0.75432629, grad/param norm = 2.4383e-01, time/batch = 16.2068s	
21444/25300 (epoch 42.379), train_loss = 0.74270810, grad/param norm = 2.1787e-01, time/batch = 16.6297s	
21445/25300 (epoch 42.381), train_loss = 0.68703550, grad/param norm = 2.2329e-01, time/batch = 15.8074s	
21446/25300 (epoch 42.383), train_loss = 0.66063807, grad/param norm = 2.0870e-01, time/batch = 16.6522s	
21447/25300 (epoch 42.385), train_loss = 0.72699684, grad/param norm = 2.1984e-01, time/batch = 15.8013s	
21448/25300 (epoch 42.387), train_loss = 0.70187824, grad/param norm = 2.1994e-01, time/batch = 17.2268s	
21449/25300 (epoch 42.389), train_loss = 0.69287660, grad/param norm = 2.4448e-01, time/batch = 15.8855s	
21450/25300 (epoch 42.391), train_loss = 0.69591178, grad/param norm = 2.3415e-01, time/batch = 15.7189s	
21451/25300 (epoch 42.393), train_loss = 0.70187672, grad/param norm = 2.5719e-01, time/batch = 15.7338s	
21452/25300 (epoch 42.395), train_loss = 0.56748288, grad/param norm = 1.9269e-01, time/batch = 16.0455s	
21453/25300 (epoch 42.397), train_loss = 0.53770467, grad/param norm = 2.3387e-01, time/batch = 15.9140s	
21454/25300 (epoch 42.399), train_loss = 0.60443990, grad/param norm = 2.0432e-01, time/batch = 16.5449s	
21455/25300 (epoch 42.401), train_loss = 0.75677439, grad/param norm = 2.6663e-01, time/batch = 15.5557s	
21456/25300 (epoch 42.403), train_loss = 0.74621191, grad/param norm = 3.2561e-01, time/batch = 15.3233s	
21457/25300 (epoch 42.405), train_loss = 0.66309185, grad/param norm = 2.4224e-01, time/batch = 15.4884s	
21458/25300 (epoch 42.407), train_loss = 0.69226119, grad/param norm = 2.3091e-01, time/batch = 15.2895s	
21459/25300 (epoch 42.409), train_loss = 0.63302123, grad/param norm = 2.5561e-01, time/batch = 15.2176s	
21460/25300 (epoch 42.411), train_loss = 0.65752323, grad/param norm = 2.2229e-01, time/batch = 15.2050s	
21461/25300 (epoch 42.413), train_loss = 0.58514288, grad/param norm = 2.0644e-01, time/batch = 16.1522s	
21462/25300 (epoch 42.415), train_loss = 0.61864811, grad/param norm = 2.2798e-01, time/batch = 15.7106s	
21463/25300 (epoch 42.417), train_loss = 0.59179699, grad/param norm = 2.1137e-01, time/batch = 15.7093s	
21464/25300 (epoch 42.419), train_loss = 0.50325376, grad/param norm = 1.6395e-01, time/batch = 15.9787s	
21465/25300 (epoch 42.421), train_loss = 0.60681206, grad/param norm = 1.8014e-01, time/batch = 16.0206s	
21466/25300 (epoch 42.423), train_loss = 0.59697512, grad/param norm = 2.0938e-01, time/batch = 15.4487s	
21467/25300 (epoch 42.425), train_loss = 0.70359355, grad/param norm = 2.7164e-01, time/batch = 15.3061s	
21468/25300 (epoch 42.427), train_loss = 0.74641191, grad/param norm = 2.5658e-01, time/batch = 15.6139s	
21469/25300 (epoch 42.429), train_loss = 0.77233538, grad/param norm = 2.4160e-01, time/batch = 16.0505s	
21470/25300 (epoch 42.431), train_loss = 0.70000737, grad/param norm = 2.3142e-01, time/batch = 15.3972s	
21471/25300 (epoch 42.433), train_loss = 0.73305754, grad/param norm = 1.9391e-01, time/batch = 16.0705s	
21472/25300 (epoch 42.435), train_loss = 0.64304264, grad/param norm = 2.9978e-01, time/batch = 16.2189s	
21473/25300 (epoch 42.437), train_loss = 0.63341472, grad/param norm = 2.2063e-01, time/batch = 16.0289s	
21474/25300 (epoch 42.439), train_loss = 0.72133187, grad/param norm = 2.3152e-01, time/batch = 15.5543s	
21475/25300 (epoch 42.441), train_loss = 0.73634334, grad/param norm = 2.4036e-01, time/batch = 15.9774s	
21476/25300 (epoch 42.443), train_loss = 0.82442502, grad/param norm = 2.6432e-01, time/batch = 15.8883s	
21477/25300 (epoch 42.445), train_loss = 0.77690135, grad/param norm = 2.4508e-01, time/batch = 15.5497s	
21478/25300 (epoch 42.447), train_loss = 0.62706961, grad/param norm = 1.9548e-01, time/batch = 15.6547s	
21479/25300 (epoch 42.449), train_loss = 0.55752784, grad/param norm = 2.0957e-01, time/batch = 15.8085s	
21480/25300 (epoch 42.451), train_loss = 0.89080819, grad/param norm = 3.0096e-01, time/batch = 15.3128s	
21481/25300 (epoch 42.453), train_loss = 0.74451985, grad/param norm = 2.3291e-01, time/batch = 15.6955s	
21482/25300 (epoch 42.455), train_loss = 0.71972595, grad/param norm = 2.3982e-01, time/batch = 15.6294s	
21483/25300 (epoch 42.457), train_loss = 0.62300871, grad/param norm = 2.2206e-01, time/batch = 15.5408s	
21484/25300 (epoch 42.458), train_loss = 0.66778989, grad/param norm = 2.1334e-01, time/batch = 15.8882s	
21485/25300 (epoch 42.460), train_loss = 0.66292533, grad/param norm = 2.1858e-01, time/batch = 15.3788s	
21486/25300 (epoch 42.462), train_loss = 0.48578211, grad/param norm = 2.5988e-01, time/batch = 15.4107s	
21487/25300 (epoch 42.464), train_loss = 0.76390065, grad/param norm = 2.5167e-01, time/batch = 15.1569s	
21488/25300 (epoch 42.466), train_loss = 0.72272891, grad/param norm = 2.5692e-01, time/batch = 15.5675s	
21489/25300 (epoch 42.468), train_loss = 0.72005148, grad/param norm = 2.1480e-01, time/batch = 15.6371s	
21490/25300 (epoch 42.470), train_loss = 0.67251211, grad/param norm = 2.1532e-01, time/batch = 15.8943s	
21491/25300 (epoch 42.472), train_loss = 0.58244196, grad/param norm = 1.9320e-01, time/batch = 15.5707s	
21492/25300 (epoch 42.474), train_loss = 0.73910456, grad/param norm = 2.3905e-01, time/batch = 16.1280s	
21493/25300 (epoch 42.476), train_loss = 0.66168503, grad/param norm = 2.6346e-01, time/batch = 16.4584s	
21494/25300 (epoch 42.478), train_loss = 0.72122412, grad/param norm = 2.6109e-01, time/batch = 15.4695s	
21495/25300 (epoch 42.480), train_loss = 0.69006584, grad/param norm = 2.5355e-01, time/batch = 15.4691s	
21496/25300 (epoch 42.482), train_loss = 0.71306047, grad/param norm = 2.5806e-01, time/batch = 15.8837s	
21497/25300 (epoch 42.484), train_loss = 0.75541500, grad/param norm = 2.7008e-01, time/batch = 16.5547s	
21498/25300 (epoch 42.486), train_loss = 0.70003389, grad/param norm = 2.7251e-01, time/batch = 15.3967s	
21499/25300 (epoch 42.488), train_loss = 0.85673291, grad/param norm = 2.9462e-01, time/batch = 17.1316s	
21500/25300 (epoch 42.490), train_loss = 0.73580351, grad/param norm = 2.7965e-01, time/batch = 15.8000s	
21501/25300 (epoch 42.492), train_loss = 0.80040897, grad/param norm = 2.2496e-01, time/batch = 15.6444s	
21502/25300 (epoch 42.494), train_loss = 0.71152768, grad/param norm = 2.1584e-01, time/batch = 16.5592s	
21503/25300 (epoch 42.496), train_loss = 0.74166784, grad/param norm = 2.4563e-01, time/batch = 16.2196s	
21504/25300 (epoch 42.498), train_loss = 0.68121111, grad/param norm = 2.1786e-01, time/batch = 15.9519s	
21505/25300 (epoch 42.500), train_loss = 0.81996838, grad/param norm = 2.4862e-01, time/batch = 16.0384s	
21506/25300 (epoch 42.502), train_loss = 0.74363375, grad/param norm = 2.5547e-01, time/batch = 15.2276s	
21507/25300 (epoch 42.504), train_loss = 0.68294666, grad/param norm = 2.2413e-01, time/batch = 15.9714s	
21508/25300 (epoch 42.506), train_loss = 0.59259602, grad/param norm = 2.8404e-01, time/batch = 16.1410s	
21509/25300 (epoch 42.508), train_loss = 0.70738958, grad/param norm = 2.4090e-01, time/batch = 16.6340s	
21510/25300 (epoch 42.510), train_loss = 0.69541048, grad/param norm = 2.9699e-01, time/batch = 16.6424s	
21511/25300 (epoch 42.512), train_loss = 0.55394721, grad/param norm = 2.0224e-01, time/batch = 28.4602s	
21512/25300 (epoch 42.514), train_loss = 0.69691057, grad/param norm = 2.3173e-01, time/batch = 15.2032s	
21513/25300 (epoch 42.516), train_loss = 0.78171264, grad/param norm = 2.5677e-01, time/batch = 15.0517s	
21514/25300 (epoch 42.518), train_loss = 0.78858076, grad/param norm = 2.8012e-01, time/batch = 15.0531s	
21515/25300 (epoch 42.520), train_loss = 0.58117724, grad/param norm = 1.8287e-01, time/batch = 15.6982s	
21516/25300 (epoch 42.522), train_loss = 0.64690577, grad/param norm = 2.1158e-01, time/batch = 14.9723s	
21517/25300 (epoch 42.524), train_loss = 0.62248996, grad/param norm = 1.9565e-01, time/batch = 15.6163s	
21518/25300 (epoch 42.526), train_loss = 0.78389961, grad/param norm = 1.9815e-01, time/batch = 15.6281s	
21519/25300 (epoch 42.528), train_loss = 0.83352387, grad/param norm = 2.3881e-01, time/batch = 15.8814s	
21520/25300 (epoch 42.530), train_loss = 0.77131859, grad/param norm = 2.1998e-01, time/batch = 15.6116s	
21521/25300 (epoch 42.532), train_loss = 0.65886941, grad/param norm = 2.0723e-01, time/batch = 15.6958s	
21522/25300 (epoch 42.534), train_loss = 0.66454317, grad/param norm = 2.3250e-01, time/batch = 15.7786s	
21523/25300 (epoch 42.536), train_loss = 0.57480696, grad/param norm = 2.2873e-01, time/batch = 16.7979s	
21524/25300 (epoch 42.538), train_loss = 0.60494099, grad/param norm = 1.8826e-01, time/batch = 15.7831s	
21525/25300 (epoch 42.540), train_loss = 0.61680356, grad/param norm = 2.1946e-01, time/batch = 15.3069s	
21526/25300 (epoch 42.542), train_loss = 0.57799549, grad/param norm = 1.9489e-01, time/batch = 15.9841s	
21527/25300 (epoch 42.543), train_loss = 0.57968664, grad/param norm = 2.2095e-01, time/batch = 15.4571s	
21528/25300 (epoch 42.545), train_loss = 0.88099304, grad/param norm = 3.0594e-01, time/batch = 15.4818s	
21529/25300 (epoch 42.547), train_loss = 0.78282481, grad/param norm = 2.3084e-01, time/batch = 15.7756s	
21530/25300 (epoch 42.549), train_loss = 0.90173581, grad/param norm = 3.2754e-01, time/batch = 15.4840s	
21531/25300 (epoch 42.551), train_loss = 0.81662699, grad/param norm = 2.3354e-01, time/batch = 15.6415s	
21532/25300 (epoch 42.553), train_loss = 0.67888519, grad/param norm = 3.0225e-01, time/batch = 15.7350s	
21533/25300 (epoch 42.555), train_loss = 0.74329297, grad/param norm = 2.4657e-01, time/batch = 15.1376s	
21534/25300 (epoch 42.557), train_loss = 0.80033533, grad/param norm = 2.7201e-01, time/batch = 15.8052s	
21535/25300 (epoch 42.559), train_loss = 0.81712915, grad/param norm = 2.6124e-01, time/batch = 15.8181s	
21536/25300 (epoch 42.561), train_loss = 0.85593666, grad/param norm = 2.8965e-01, time/batch = 15.3317s	
21537/25300 (epoch 42.563), train_loss = 0.81682878, grad/param norm = 2.7869e-01, time/batch = 15.4774s	
21538/25300 (epoch 42.565), train_loss = 0.60367440, grad/param norm = 2.0769e-01, time/batch = 15.6528s	
21539/25300 (epoch 42.567), train_loss = 0.55744456, grad/param norm = 2.0733e-01, time/batch = 15.5344s	
21540/25300 (epoch 42.569), train_loss = 0.71082238, grad/param norm = 2.4224e-01, time/batch = 16.4719s	
21541/25300 (epoch 42.571), train_loss = 0.78368924, grad/param norm = 2.6422e-01, time/batch = 16.8765s	
21542/25300 (epoch 42.573), train_loss = 0.70050802, grad/param norm = 2.2609e-01, time/batch = 16.8162s	
21543/25300 (epoch 42.575), train_loss = 0.71339883, grad/param norm = 2.4996e-01, time/batch = 16.0684s	
21544/25300 (epoch 42.577), train_loss = 0.65413082, grad/param norm = 2.3841e-01, time/batch = 15.6322s	
21545/25300 (epoch 42.579), train_loss = 0.84841346, grad/param norm = 2.6598e-01, time/batch = 15.5583s	
21546/25300 (epoch 42.581), train_loss = 0.77361848, grad/param norm = 2.7664e-01, time/batch = 15.3943s	
21547/25300 (epoch 42.583), train_loss = 0.56657519, grad/param norm = 2.2869e-01, time/batch = 15.6382s	
21548/25300 (epoch 42.585), train_loss = 0.58690214, grad/param norm = 2.0746e-01, time/batch = 15.7016s	
21549/25300 (epoch 42.587), train_loss = 0.68269468, grad/param norm = 2.1467e-01, time/batch = 15.8077s	
21550/25300 (epoch 42.589), train_loss = 0.61517477, grad/param norm = 1.8890e-01, time/batch = 15.4004s	
21551/25300 (epoch 42.591), train_loss = 0.57501887, grad/param norm = 2.4564e-01, time/batch = 16.2291s	
21552/25300 (epoch 42.593), train_loss = 0.77326551, grad/param norm = 2.3848e-01, time/batch = 15.5470s	
21553/25300 (epoch 42.595), train_loss = 0.71488826, grad/param norm = 2.1858e-01, time/batch = 16.3985s	
21554/25300 (epoch 42.597), train_loss = 0.63522757, grad/param norm = 2.1383e-01, time/batch = 15.4800s	
21555/25300 (epoch 42.599), train_loss = 0.82013886, grad/param norm = 2.6471e-01, time/batch = 16.2185s	
21556/25300 (epoch 42.601), train_loss = 0.70249049, grad/param norm = 2.4930e-01, time/batch = 15.8314s	
21557/25300 (epoch 42.603), train_loss = 0.70279212, grad/param norm = 2.5505e-01, time/batch = 15.4881s	
21558/25300 (epoch 42.605), train_loss = 0.71473987, grad/param norm = 2.7668e-01, time/batch = 15.8069s	
21559/25300 (epoch 42.607), train_loss = 0.49772839, grad/param norm = 1.7466e-01, time/batch = 15.1341s	
21560/25300 (epoch 42.609), train_loss = 0.62399011, grad/param norm = 2.1079e-01, time/batch = 15.4818s	
21561/25300 (epoch 42.611), train_loss = 0.76176386, grad/param norm = 2.5113e-01, time/batch = 16.5561s	
21562/25300 (epoch 42.613), train_loss = 0.62580547, grad/param norm = 2.2183e-01, time/batch = 16.1500s	
21563/25300 (epoch 42.615), train_loss = 0.66685045, grad/param norm = 2.4425e-01, time/batch = 15.7200s	
21564/25300 (epoch 42.617), train_loss = 0.71154982, grad/param norm = 2.5088e-01, time/batch = 16.7145s	
21565/25300 (epoch 42.619), train_loss = 0.76584463, grad/param norm = 2.7853e-01, time/batch = 16.3765s	
21566/25300 (epoch 42.621), train_loss = 0.76322319, grad/param norm = 2.4333e-01, time/batch = 16.7255s	
21567/25300 (epoch 42.623), train_loss = 0.64734401, grad/param norm = 2.3387e-01, time/batch = 15.2851s	
21568/25300 (epoch 42.625), train_loss = 0.58147055, grad/param norm = 1.9828e-01, time/batch = 17.3046s	
21569/25300 (epoch 42.626), train_loss = 0.67687056, grad/param norm = 2.0437e-01, time/batch = 16.3051s	
21570/25300 (epoch 42.628), train_loss = 0.83693434, grad/param norm = 3.0981e-01, time/batch = 16.4751s	
21571/25300 (epoch 42.630), train_loss = 0.74217530, grad/param norm = 2.5973e-01, time/batch = 15.4458s	
21572/25300 (epoch 42.632), train_loss = 0.68778118, grad/param norm = 2.2562e-01, time/batch = 16.1458s	
21573/25300 (epoch 42.634), train_loss = 0.82828715, grad/param norm = 3.6002e-01, time/batch = 16.9685s	
21574/25300 (epoch 42.636), train_loss = 0.62169067, grad/param norm = 2.1663e-01, time/batch = 16.2015s	
21575/25300 (epoch 42.638), train_loss = 0.70805898, grad/param norm = 3.2281e-01, time/batch = 15.9859s	
21576/25300 (epoch 42.640), train_loss = 0.89307011, grad/param norm = 2.9887e-01, time/batch = 15.5541s	
21577/25300 (epoch 42.642), train_loss = 0.76932868, grad/param norm = 2.8238e-01, time/batch = 15.4671s	
21578/25300 (epoch 42.644), train_loss = 0.71989209, grad/param norm = 2.4448e-01, time/batch = 15.8634s	
21579/25300 (epoch 42.646), train_loss = 0.65857529, grad/param norm = 2.7031e-01, time/batch = 15.6486s	
21580/25300 (epoch 42.648), train_loss = 0.80332383, grad/param norm = 2.2421e-01, time/batch = 15.3203s	
21581/25300 (epoch 42.650), train_loss = 0.72818802, grad/param norm = 2.3147e-01, time/batch = 16.3067s	
21582/25300 (epoch 42.652), train_loss = 0.74111315, grad/param norm = 2.4614e-01, time/batch = 15.6107s	
21583/25300 (epoch 42.654), train_loss = 0.80063966, grad/param norm = 2.2258e-01, time/batch = 16.4529s	
21584/25300 (epoch 42.656), train_loss = 0.76605778, grad/param norm = 2.3865e-01, time/batch = 16.3958s	
21585/25300 (epoch 42.658), train_loss = 0.56900017, grad/param norm = 2.1810e-01, time/batch = 16.2023s	
21586/25300 (epoch 42.660), train_loss = 0.57682242, grad/param norm = 1.9833e-01, time/batch = 16.4544s	
21587/25300 (epoch 42.662), train_loss = 0.60389222, grad/param norm = 1.8862e-01, time/batch = 16.0737s	
21588/25300 (epoch 42.664), train_loss = 0.55179820, grad/param norm = 2.0270e-01, time/batch = 15.6542s	
21589/25300 (epoch 42.666), train_loss = 0.60215856, grad/param norm = 2.0964e-01, time/batch = 15.3910s	
21590/25300 (epoch 42.668), train_loss = 0.70941600, grad/param norm = 3.6671e-01, time/batch = 16.9642s	
21591/25300 (epoch 42.670), train_loss = 0.64296086, grad/param norm = 2.6305e-01, time/batch = 15.9760s	
21592/25300 (epoch 42.672), train_loss = 0.65106574, grad/param norm = 2.0455e-01, time/batch = 16.4013s	
21593/25300 (epoch 42.674), train_loss = 0.63856679, grad/param norm = 2.0406e-01, time/batch = 16.0501s	
21594/25300 (epoch 42.676), train_loss = 0.64467325, grad/param norm = 3.0006e-01, time/batch = 17.3021s	
21595/25300 (epoch 42.678), train_loss = 0.63975656, grad/param norm = 2.4832e-01, time/batch = 15.5712s	
21596/25300 (epoch 42.680), train_loss = 0.56639473, grad/param norm = 1.9411e-01, time/batch = 15.1770s	
21597/25300 (epoch 42.682), train_loss = 0.47795832, grad/param norm = 1.7859e-01, time/batch = 15.6411s	
21598/25300 (epoch 42.684), train_loss = 0.61647575, grad/param norm = 1.9827e-01, time/batch = 15.9879s	
21599/25300 (epoch 42.686), train_loss = 0.58159366, grad/param norm = 2.1340e-01, time/batch = 15.8943s	
21600/25300 (epoch 42.688), train_loss = 0.65842799, grad/param norm = 2.7435e-01, time/batch = 16.1031s	
21601/25300 (epoch 42.690), train_loss = 0.56620920, grad/param norm = 1.8992e-01, time/batch = 16.0671s	
21602/25300 (epoch 42.692), train_loss = 0.63158808, grad/param norm = 2.1833e-01, time/batch = 15.9159s	
21603/25300 (epoch 42.694), train_loss = 0.64693404, grad/param norm = 2.5388e-01, time/batch = 15.4922s	
21604/25300 (epoch 42.696), train_loss = 0.68550488, grad/param norm = 2.3343e-01, time/batch = 16.6221s	
21605/25300 (epoch 42.698), train_loss = 0.75708067, grad/param norm = 2.6231e-01, time/batch = 16.1360s	
21606/25300 (epoch 42.700), train_loss = 0.57107031, grad/param norm = 2.3277e-01, time/batch = 16.6255s	
21607/25300 (epoch 42.702), train_loss = 0.74053481, grad/param norm = 2.3070e-01, time/batch = 16.3966s	
21608/25300 (epoch 42.704), train_loss = 0.54106427, grad/param norm = 1.9106e-01, time/batch = 15.8028s	
21609/25300 (epoch 42.706), train_loss = 0.66864231, grad/param norm = 2.3143e-01, time/batch = 16.8763s	
21610/25300 (epoch 42.708), train_loss = 0.59336634, grad/param norm = 2.0419e-01, time/batch = 15.4755s	
21611/25300 (epoch 42.709), train_loss = 0.79895539, grad/param norm = 2.5406e-01, time/batch = 15.4650s	
21612/25300 (epoch 42.711), train_loss = 0.82820285, grad/param norm = 2.5812e-01, time/batch = 15.3981s	
21613/25300 (epoch 42.713), train_loss = 0.69012928, grad/param norm = 1.8413e-01, time/batch = 16.0535s	
21614/25300 (epoch 42.715), train_loss = 0.70481031, grad/param norm = 2.3450e-01, time/batch = 16.3946s	
21615/25300 (epoch 42.717), train_loss = 0.60888605, grad/param norm = 2.4146e-01, time/batch = 15.2816s	
21616/25300 (epoch 42.719), train_loss = 0.66853457, grad/param norm = 2.2082e-01, time/batch = 17.3841s	
21617/25300 (epoch 42.721), train_loss = 0.72744152, grad/param norm = 2.5594e-01, time/batch = 15.9012s	
21618/25300 (epoch 42.723), train_loss = 0.68541257, grad/param norm = 2.3442e-01, time/batch = 16.7306s	
21619/25300 (epoch 42.725), train_loss = 0.69634803, grad/param norm = 2.4434e-01, time/batch = 16.2977s	
21620/25300 (epoch 42.727), train_loss = 0.70006454, grad/param norm = 2.2822e-01, time/batch = 17.0632s	
21621/25300 (epoch 42.729), train_loss = 0.65937374, grad/param norm = 2.3002e-01, time/batch = 16.4713s	
21622/25300 (epoch 42.731), train_loss = 0.81196204, grad/param norm = 2.3840e-01, time/batch = 16.9633s	
21623/25300 (epoch 42.733), train_loss = 0.68515916, grad/param norm = 1.9838e-01, time/batch = 16.0681s	
21624/25300 (epoch 42.735), train_loss = 0.87599507, grad/param norm = 2.9376e-01, time/batch = 15.5246s	
21625/25300 (epoch 42.737), train_loss = 0.54951128, grad/param norm = 1.9973e-01, time/batch = 15.6782s	
21626/25300 (epoch 42.739), train_loss = 0.81211491, grad/param norm = 2.7513e-01, time/batch = 15.6867s	
21627/25300 (epoch 42.741), train_loss = 0.69276541, grad/param norm = 2.4916e-01, time/batch = 15.6215s	
21628/25300 (epoch 42.743), train_loss = 0.70447933, grad/param norm = 2.2768e-01, time/batch = 15.6930s	
21629/25300 (epoch 42.745), train_loss = 0.67189241, grad/param norm = 2.6133e-01, time/batch = 15.5650s	
21630/25300 (epoch 42.747), train_loss = 0.60029851, grad/param norm = 2.3621e-01, time/batch = 15.5389s	
21631/25300 (epoch 42.749), train_loss = 0.70220667, grad/param norm = 2.9217e-01, time/batch = 15.7192s	
21632/25300 (epoch 42.751), train_loss = 0.72915936, grad/param norm = 2.2566e-01, time/batch = 15.3873s	
21633/25300 (epoch 42.753), train_loss = 0.59326560, grad/param norm = 2.4208e-01, time/batch = 15.7209s	
21634/25300 (epoch 42.755), train_loss = 0.79843402, grad/param norm = 2.7484e-01, time/batch = 15.6075s	
21635/25300 (epoch 42.757), train_loss = 0.64958564, grad/param norm = 2.3222e-01, time/batch = 16.0539s	
21636/25300 (epoch 42.759), train_loss = 0.60998415, grad/param norm = 2.0394e-01, time/batch = 15.2962s	
21637/25300 (epoch 42.761), train_loss = 0.83470787, grad/param norm = 2.4359e-01, time/batch = 15.2254s	
21638/25300 (epoch 42.763), train_loss = 0.67176920, grad/param norm = 2.3098e-01, time/batch = 15.9596s	
21639/25300 (epoch 42.765), train_loss = 0.66767364, grad/param norm = 2.8659e-01, time/batch = 17.5294s	
21640/25300 (epoch 42.767), train_loss = 0.69431156, grad/param norm = 2.4661e-01, time/batch = 16.4869s	
21641/25300 (epoch 42.769), train_loss = 0.70086575, grad/param norm = 2.6118e-01, time/batch = 16.0404s	
21642/25300 (epoch 42.771), train_loss = 0.76648188, grad/param norm = 3.0312e-01, time/batch = 16.6502s	
21643/25300 (epoch 42.773), train_loss = 0.79926399, grad/param norm = 2.7235e-01, time/batch = 16.4770s	
21644/25300 (epoch 42.775), train_loss = 0.70765781, grad/param norm = 2.1550e-01, time/batch = 15.3206s	
21645/25300 (epoch 42.777), train_loss = 0.63997352, grad/param norm = 2.3778e-01, time/batch = 15.7300s	
21646/25300 (epoch 42.779), train_loss = 0.76541967, grad/param norm = 2.1262e-01, time/batch = 16.1430s	
21647/25300 (epoch 42.781), train_loss = 0.75517160, grad/param norm = 2.4565e-01, time/batch = 15.4609s	
21648/25300 (epoch 42.783), train_loss = 0.80818456, grad/param norm = 2.7115e-01, time/batch = 15.8079s	
21649/25300 (epoch 42.785), train_loss = 0.78921202, grad/param norm = 2.7624e-01, time/batch = 15.3138s	
21650/25300 (epoch 42.787), train_loss = 0.73492692, grad/param norm = 2.5752e-01, time/batch = 15.5764s	
21651/25300 (epoch 42.789), train_loss = 0.82890454, grad/param norm = 2.8054e-01, time/batch = 15.3773s	
21652/25300 (epoch 42.791), train_loss = 0.77145758, grad/param norm = 2.3275e-01, time/batch = 16.0552s	
21653/25300 (epoch 42.792), train_loss = 0.80605232, grad/param norm = 2.4656e-01, time/batch = 15.4634s	
21654/25300 (epoch 42.794), train_loss = 0.67111403, grad/param norm = 2.4207e-01, time/batch = 15.6520s	
21655/25300 (epoch 42.796), train_loss = 0.64867570, grad/param norm = 2.7487e-01, time/batch = 15.6678s	
21656/25300 (epoch 42.798), train_loss = 0.77886277, grad/param norm = 2.8724e-01, time/batch = 16.0582s	
21657/25300 (epoch 42.800), train_loss = 0.67152463, grad/param norm = 2.1237e-01, time/batch = 16.2411s	
21658/25300 (epoch 42.802), train_loss = 0.56285471, grad/param norm = 2.0158e-01, time/batch = 16.8172s	
21659/25300 (epoch 42.804), train_loss = 0.69897473, grad/param norm = 1.8722e-01, time/batch = 16.4084s	
21660/25300 (epoch 42.806), train_loss = 0.76187629, grad/param norm = 2.4976e-01, time/batch = 15.4517s	
21661/25300 (epoch 42.808), train_loss = 0.82366294, grad/param norm = 2.7123e-01, time/batch = 16.7912s	
21662/25300 (epoch 42.810), train_loss = 0.69110934, grad/param norm = 2.5734e-01, time/batch = 16.4889s	
21663/25300 (epoch 42.812), train_loss = 0.82142208, grad/param norm = 2.8712e-01, time/batch = 16.8015s	
21664/25300 (epoch 42.814), train_loss = 0.83958881, grad/param norm = 2.7553e-01, time/batch = 15.7273s	
21665/25300 (epoch 42.816), train_loss = 0.91976861, grad/param norm = 3.0006e-01, time/batch = 17.0605s	
21666/25300 (epoch 42.818), train_loss = 0.80163113, grad/param norm = 2.2210e-01, time/batch = 16.0639s	
21667/25300 (epoch 42.820), train_loss = 0.75803664, grad/param norm = 2.2585e-01, time/batch = 15.5656s	
21668/25300 (epoch 42.822), train_loss = 0.66103045, grad/param norm = 2.3536e-01, time/batch = 15.1628s	
21669/25300 (epoch 42.824), train_loss = 0.79274078, grad/param norm = 2.6381e-01, time/batch = 16.0635s	
21670/25300 (epoch 42.826), train_loss = 0.66026746, grad/param norm = 2.0543e-01, time/batch = 16.5687s	
21671/25300 (epoch 42.828), train_loss = 0.66505222, grad/param norm = 2.9507e-01, time/batch = 16.9609s	
21672/25300 (epoch 42.830), train_loss = 0.74181719, grad/param norm = 2.4506e-01, time/batch = 17.8005s	
21673/25300 (epoch 42.832), train_loss = 0.82936468, grad/param norm = 2.3774e-01, time/batch = 15.9014s	
21674/25300 (epoch 42.834), train_loss = 0.68117293, grad/param norm = 2.4893e-01, time/batch = 16.6326s	
21675/25300 (epoch 42.836), train_loss = 0.67334859, grad/param norm = 2.1046e-01, time/batch = 16.7185s	
21676/25300 (epoch 42.838), train_loss = 0.68616111, grad/param norm = 2.1973e-01, time/batch = 16.8944s	
21677/25300 (epoch 42.840), train_loss = 0.75291897, grad/param norm = 2.4068e-01, time/batch = 16.3095s	
21678/25300 (epoch 42.842), train_loss = 0.70268648, grad/param norm = 2.4540e-01, time/batch = 17.0354s	
21679/25300 (epoch 42.844), train_loss = 0.81791746, grad/param norm = 2.1463e-01, time/batch = 15.6496s	
21680/25300 (epoch 42.846), train_loss = 0.79295533, grad/param norm = 2.3081e-01, time/batch = 16.2113s	
21681/25300 (epoch 42.848), train_loss = 0.76776675, grad/param norm = 2.5733e-01, time/batch = 18.7989s	
21682/25300 (epoch 42.850), train_loss = 0.75114852, grad/param norm = 2.4602e-01, time/batch = 17.3805s	
21683/25300 (epoch 42.852), train_loss = 0.79985064, grad/param norm = 2.4040e-01, time/batch = 15.6537s	
21684/25300 (epoch 42.854), train_loss = 0.83256381, grad/param norm = 2.5172e-01, time/batch = 17.3125s	
21685/25300 (epoch 42.856), train_loss = 0.66246261, grad/param norm = 2.5742e-01, time/batch = 15.6335s	
21686/25300 (epoch 42.858), train_loss = 0.68188741, grad/param norm = 2.3906e-01, time/batch = 17.3792s	
21687/25300 (epoch 42.860), train_loss = 0.62342502, grad/param norm = 2.0883e-01, time/batch = 15.9795s	
21688/25300 (epoch 42.862), train_loss = 0.71391407, grad/param norm = 2.3728e-01, time/batch = 15.5722s	
21689/25300 (epoch 42.864), train_loss = 0.85686971, grad/param norm = 2.4454e-01, time/batch = 15.6505s	
21690/25300 (epoch 42.866), train_loss = 0.65773311, grad/param norm = 2.4967e-01, time/batch = 15.5691s	
21691/25300 (epoch 42.868), train_loss = 0.79689735, grad/param norm = 2.2625e-01, time/batch = 15.9907s	
21692/25300 (epoch 42.870), train_loss = 0.76872540, grad/param norm = 2.0899e-01, time/batch = 16.4806s	
21693/25300 (epoch 42.872), train_loss = 0.73649461, grad/param norm = 2.5028e-01, time/batch = 15.5702s	
21694/25300 (epoch 42.874), train_loss = 0.77787673, grad/param norm = 2.5234e-01, time/batch = 16.4029s	
21695/25300 (epoch 42.875), train_loss = 0.70732122, grad/param norm = 2.4161e-01, time/batch = 16.0750s	
21696/25300 (epoch 42.877), train_loss = 0.68147496, grad/param norm = 2.2344e-01, time/batch = 16.4636s	
21697/25300 (epoch 42.879), train_loss = 0.66087169, grad/param norm = 2.4435e-01, time/batch = 16.0650s	
21698/25300 (epoch 42.881), train_loss = 0.90909974, grad/param norm = 2.7786e-01, time/batch = 16.3190s	
21699/25300 (epoch 42.883), train_loss = 0.88372108, grad/param norm = 2.5124e-01, time/batch = 17.8994s	
21700/25300 (epoch 42.885), train_loss = 0.78051005, grad/param norm = 2.8295e-01, time/batch = 15.8686s	
21701/25300 (epoch 42.887), train_loss = 0.78378600, grad/param norm = 2.1666e-01, time/batch = 16.4918s	
21702/25300 (epoch 42.889), train_loss = 0.86553085, grad/param norm = 2.7794e-01, time/batch = 16.9003s	
21703/25300 (epoch 42.891), train_loss = 0.75055946, grad/param norm = 2.6879e-01, time/batch = 17.3062s	
21704/25300 (epoch 42.893), train_loss = 0.71681900, grad/param norm = 2.4192e-01, time/batch = 17.4660s	
21705/25300 (epoch 42.895), train_loss = 0.56400426, grad/param norm = 1.9740e-01, time/batch = 16.2142s	
21706/25300 (epoch 42.897), train_loss = 0.62588440, grad/param norm = 2.3871e-01, time/batch = 17.2284s	
21707/25300 (epoch 42.899), train_loss = 0.72843127, grad/param norm = 2.5177e-01, time/batch = 15.9749s	
21708/25300 (epoch 42.901), train_loss = 0.78872274, grad/param norm = 2.3944e-01, time/batch = 16.1358s	
21709/25300 (epoch 42.903), train_loss = 0.59730716, grad/param norm = 2.3109e-01, time/batch = 16.5695s	
21710/25300 (epoch 42.905), train_loss = 0.67389765, grad/param norm = 2.6810e-01, time/batch = 17.3909s	
21711/25300 (epoch 42.907), train_loss = 0.67323333, grad/param norm = 2.6251e-01, time/batch = 15.8821s	
21712/25300 (epoch 42.909), train_loss = 0.75551430, grad/param norm = 2.3142e-01, time/batch = 17.2374s	
21713/25300 (epoch 42.911), train_loss = 0.80905394, grad/param norm = 2.5030e-01, time/batch = 17.4669s	
21714/25300 (epoch 42.913), train_loss = 0.90903117, grad/param norm = 2.8214e-01, time/batch = 15.5298s	
21715/25300 (epoch 42.915), train_loss = 0.69625213, grad/param norm = 2.2354e-01, time/batch = 15.3948s	
21716/25300 (epoch 42.917), train_loss = 0.87202248, grad/param norm = 2.5700e-01, time/batch = 15.7495s	
21717/25300 (epoch 42.919), train_loss = 0.83120488, grad/param norm = 3.0382e-01, time/batch = 15.4847s	
21718/25300 (epoch 42.921), train_loss = 0.69092583, grad/param norm = 2.4226e-01, time/batch = 15.9031s	
21719/25300 (epoch 42.923), train_loss = 0.80221200, grad/param norm = 2.3125e-01, time/batch = 16.9766s	
21720/25300 (epoch 42.925), train_loss = 0.72233704, grad/param norm = 2.4137e-01, time/batch = 17.8090s	
21721/25300 (epoch 42.927), train_loss = 0.73269057, grad/param norm = 2.2192e-01, time/batch = 17.3766s	
21722/25300 (epoch 42.929), train_loss = 0.80523275, grad/param norm = 2.5004e-01, time/batch = 15.9010s	
21723/25300 (epoch 42.931), train_loss = 0.76560445, grad/param norm = 2.5840e-01, time/batch = 16.6460s	
21724/25300 (epoch 42.933), train_loss = 0.75304045, grad/param norm = 2.1538e-01, time/batch = 17.7325s	
21725/25300 (epoch 42.935), train_loss = 0.80266256, grad/param norm = 2.2972e-01, time/batch = 16.0625s	
21726/25300 (epoch 42.937), train_loss = 0.59188919, grad/param norm = 1.9408e-01, time/batch = 17.2182s	
21727/25300 (epoch 42.939), train_loss = 0.73575902, grad/param norm = 2.2161e-01, time/batch = 16.3167s	
21728/25300 (epoch 42.941), train_loss = 0.65812321, grad/param norm = 2.2380e-01, time/batch = 16.3179s	
21729/25300 (epoch 42.943), train_loss = 0.77619943, grad/param norm = 2.3348e-01, time/batch = 15.5641s	
21730/25300 (epoch 42.945), train_loss = 0.77565043, grad/param norm = 2.5893e-01, time/batch = 16.4908s	
21731/25300 (epoch 42.947), train_loss = 0.68911508, grad/param norm = 2.6605e-01, time/batch = 16.4775s	
21732/25300 (epoch 42.949), train_loss = 0.74225135, grad/param norm = 2.2940e-01, time/batch = 21.9759s	
21733/25300 (epoch 42.951), train_loss = 0.74974653, grad/param norm = 2.0820e-01, time/batch = 25.0660s	
21734/25300 (epoch 42.953), train_loss = 0.67248368, grad/param norm = 2.3690e-01, time/batch = 15.7113s	
21735/25300 (epoch 42.955), train_loss = 0.91434036, grad/param norm = 2.9995e-01, time/batch = 16.6438s	
21736/25300 (epoch 42.957), train_loss = 0.82347803, grad/param norm = 2.6188e-01, time/batch = 16.3217s	
21737/25300 (epoch 42.958), train_loss = 0.76472416, grad/param norm = 2.8036e-01, time/batch = 15.8134s	
21738/25300 (epoch 42.960), train_loss = 0.87668495, grad/param norm = 2.8110e-01, time/batch = 15.4165s	
21739/25300 (epoch 42.962), train_loss = 0.86243464, grad/param norm = 2.2716e-01, time/batch = 15.6610s	
21740/25300 (epoch 42.964), train_loss = 0.76352986, grad/param norm = 2.5263e-01, time/batch = 15.9899s	
21741/25300 (epoch 42.966), train_loss = 0.61853629, grad/param norm = 2.3812e-01, time/batch = 17.1459s	
21742/25300 (epoch 42.968), train_loss = 0.64455788, grad/param norm = 2.1704e-01, time/batch = 15.7356s	
21743/25300 (epoch 42.970), train_loss = 0.70282426, grad/param norm = 2.4646e-01, time/batch = 15.4593s	
21744/25300 (epoch 42.972), train_loss = 0.73452734, grad/param norm = 2.3168e-01, time/batch = 16.2201s	
21745/25300 (epoch 42.974), train_loss = 0.82760546, grad/param norm = 2.9161e-01, time/batch = 17.1551s	
21746/25300 (epoch 42.976), train_loss = 0.77071471, grad/param norm = 2.4175e-01, time/batch = 16.3077s	
21747/25300 (epoch 42.978), train_loss = 0.71541034, grad/param norm = 2.8498e-01, time/batch = 16.8077s	
21748/25300 (epoch 42.980), train_loss = 0.76829438, grad/param norm = 2.8431e-01, time/batch = 15.9047s	
21749/25300 (epoch 42.982), train_loss = 0.70439965, grad/param norm = 2.5639e-01, time/batch = 16.0785s	
21750/25300 (epoch 42.984), train_loss = 0.73584856, grad/param norm = 2.4411e-01, time/batch = 15.3976s	
21751/25300 (epoch 42.986), train_loss = 0.79654735, grad/param norm = 2.6962e-01, time/batch = 15.4876s	
21752/25300 (epoch 42.988), train_loss = 0.76090526, grad/param norm = 2.6664e-01, time/batch = 15.7423s	
21753/25300 (epoch 42.990), train_loss = 0.76154826, grad/param norm = 2.4672e-01, time/batch = 16.5696s	
21754/25300 (epoch 42.992), train_loss = 0.64086435, grad/param norm = 2.0760e-01, time/batch = 16.0661s	
21755/25300 (epoch 42.994), train_loss = 0.76944542, grad/param norm = 3.0041e-01, time/batch = 16.8927s	
21756/25300 (epoch 42.996), train_loss = 0.89830464, grad/param norm = 3.6795e-01, time/batch = 16.3234s	
21757/25300 (epoch 42.998), train_loss = 0.79231423, grad/param norm = 2.4070e-01, time/batch = 15.7282s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
21758/25300 (epoch 43.000), train_loss = 0.81159950, grad/param norm = 2.8108e-01, time/batch = 17.1393s	
21759/25300 (epoch 43.002), train_loss = 0.78599082, grad/param norm = 2.2544e-01, time/batch = 16.4738s	
21760/25300 (epoch 43.004), train_loss = 0.63911877, grad/param norm = 2.2154e-01, time/batch = 16.3779s	
21761/25300 (epoch 43.006), train_loss = 0.88373855, grad/param norm = 2.5297e-01, time/batch = 16.7722s	
21762/25300 (epoch 43.008), train_loss = 0.75071639, grad/param norm = 2.1359e-01, time/batch = 17.3069s	
21763/25300 (epoch 43.010), train_loss = 0.81587842, grad/param norm = 2.3345e-01, time/batch = 16.9586s	
21764/25300 (epoch 43.012), train_loss = 0.71401422, grad/param norm = 2.3231e-01, time/batch = 17.0454s	
21765/25300 (epoch 43.014), train_loss = 0.86647914, grad/param norm = 2.8917e-01, time/batch = 16.1428s	
21766/25300 (epoch 43.016), train_loss = 0.73904675, grad/param norm = 2.5964e-01, time/batch = 16.2203s	
21767/25300 (epoch 43.018), train_loss = 0.67205373, grad/param norm = 2.3756e-01, time/batch = 17.9781s	
21768/25300 (epoch 43.020), train_loss = 0.80018362, grad/param norm = 2.6299e-01, time/batch = 15.9720s	
21769/25300 (epoch 43.022), train_loss = 0.75363856, grad/param norm = 2.8451e-01, time/batch = 16.6582s	
21770/25300 (epoch 43.024), train_loss = 0.58281167, grad/param norm = 1.8097e-01, time/batch = 15.5824s	
21771/25300 (epoch 43.026), train_loss = 0.69731198, grad/param norm = 2.3274e-01, time/batch = 18.2979s	
21772/25300 (epoch 43.028), train_loss = 0.69184240, grad/param norm = 2.1050e-01, time/batch = 16.2138s	
21773/25300 (epoch 43.030), train_loss = 0.85004512, grad/param norm = 2.2433e-01, time/batch = 17.1375s	
21774/25300 (epoch 43.032), train_loss = 0.67909110, grad/param norm = 2.1381e-01, time/batch = 16.9743s	
21775/25300 (epoch 43.034), train_loss = 0.67539428, grad/param norm = 2.1643e-01, time/batch = 16.7128s	
21776/25300 (epoch 43.036), train_loss = 0.62826270, grad/param norm = 2.1430e-01, time/batch = 17.0518s	
21777/25300 (epoch 43.038), train_loss = 0.53693567, grad/param norm = 1.8059e-01, time/batch = 15.8053s	
21778/25300 (epoch 43.040), train_loss = 0.75155775, grad/param norm = 2.8202e-01, time/batch = 17.7274s	
21779/25300 (epoch 43.042), train_loss = 0.72233662, grad/param norm = 2.2437e-01, time/batch = 15.9752s	
21780/25300 (epoch 43.043), train_loss = 0.64928692, grad/param norm = 1.9631e-01, time/batch = 15.5677s	
21781/25300 (epoch 43.045), train_loss = 0.61183914, grad/param norm = 1.9477e-01, time/batch = 15.8990s	
21782/25300 (epoch 43.047), train_loss = 0.74412523, grad/param norm = 2.2743e-01, time/batch = 16.6498s	
21783/25300 (epoch 43.049), train_loss = 0.74020967, grad/param norm = 2.4074e-01, time/batch = 16.0706s	
21784/25300 (epoch 43.051), train_loss = 0.87830834, grad/param norm = 2.6554e-01, time/batch = 18.0496s	
21785/25300 (epoch 43.053), train_loss = 0.56882756, grad/param norm = 1.7279e-01, time/batch = 17.2138s	
21786/25300 (epoch 43.055), train_loss = 0.58140583, grad/param norm = 2.0512e-01, time/batch = 16.3824s	
21787/25300 (epoch 43.057), train_loss = 0.59891776, grad/param norm = 1.7455e-01, time/batch = 16.4750s	
21788/25300 (epoch 43.059), train_loss = 0.68357692, grad/param norm = 2.2842e-01, time/batch = 15.3731s	
21789/25300 (epoch 43.061), train_loss = 0.67080172, grad/param norm = 2.3878e-01, time/batch = 15.5925s	
21790/25300 (epoch 43.063), train_loss = 0.70142768, grad/param norm = 2.0714e-01, time/batch = 15.6893s	
21791/25300 (epoch 43.065), train_loss = 0.73184120, grad/param norm = 2.3940e-01, time/batch = 15.6970s	
21792/25300 (epoch 43.067), train_loss = 0.78021618, grad/param norm = 2.2360e-01, time/batch = 15.6759s	
21793/25300 (epoch 43.069), train_loss = 0.63591928, grad/param norm = 2.0907e-01, time/batch = 15.7048s	
21794/25300 (epoch 43.071), train_loss = 0.77017044, grad/param norm = 2.5311e-01, time/batch = 15.8728s	
21795/25300 (epoch 43.073), train_loss = 0.71043019, grad/param norm = 2.0497e-01, time/batch = 15.4027s	
21796/25300 (epoch 43.075), train_loss = 0.75283225, grad/param norm = 2.3337e-01, time/batch = 15.8122s	
21797/25300 (epoch 43.077), train_loss = 0.71020816, grad/param norm = 2.2232e-01, time/batch = 16.2218s	
21798/25300 (epoch 43.079), train_loss = 0.65324506, grad/param norm = 2.1430e-01, time/batch = 15.4691s	
21799/25300 (epoch 43.081), train_loss = 0.70927342, grad/param norm = 2.0303e-01, time/batch = 16.5472s	
21800/25300 (epoch 43.083), train_loss = 0.74238886, grad/param norm = 2.0471e-01, time/batch = 15.2776s	
21801/25300 (epoch 43.085), train_loss = 0.88161937, grad/param norm = 2.2698e-01, time/batch = 15.2225s	
21802/25300 (epoch 43.087), train_loss = 0.78133013, grad/param norm = 2.0221e-01, time/batch = 15.8230s	
21803/25300 (epoch 43.089), train_loss = 0.75123882, grad/param norm = 2.0704e-01, time/batch = 15.7405s	
21804/25300 (epoch 43.091), train_loss = 0.89505679, grad/param norm = 2.3693e-01, time/batch = 16.0638s	
21805/25300 (epoch 43.093), train_loss = 0.81988297, grad/param norm = 2.5383e-01, time/batch = 15.3794s	
21806/25300 (epoch 43.095), train_loss = 0.79583222, grad/param norm = 2.3319e-01, time/batch = 15.0073s	
21807/25300 (epoch 43.097), train_loss = 0.78214872, grad/param norm = 2.3160e-01, time/batch = 15.2021s	
21808/25300 (epoch 43.099), train_loss = 0.77218054, grad/param norm = 2.5411e-01, time/batch = 15.6638s	
21809/25300 (epoch 43.101), train_loss = 0.72040656, grad/param norm = 2.4815e-01, time/batch = 15.3684s	
21810/25300 (epoch 43.103), train_loss = 0.76558505, grad/param norm = 2.4267e-01, time/batch = 15.8093s	
21811/25300 (epoch 43.105), train_loss = 0.75792558, grad/param norm = 2.0953e-01, time/batch = 15.8924s	
21812/25300 (epoch 43.107), train_loss = 0.76782447, grad/param norm = 2.7280e-01, time/batch = 16.6253s	
21813/25300 (epoch 43.109), train_loss = 0.70391373, grad/param norm = 2.6009e-01, time/batch = 15.5591s	
21814/25300 (epoch 43.111), train_loss = 0.69832131, grad/param norm = 2.4303e-01, time/batch = 16.9736s	
21815/25300 (epoch 43.113), train_loss = 0.67785721, grad/param norm = 2.2863e-01, time/batch = 15.1491s	
21816/25300 (epoch 43.115), train_loss = 0.71468525, grad/param norm = 2.5293e-01, time/batch = 15.4643s	
21817/25300 (epoch 43.117), train_loss = 0.81696597, grad/param norm = 2.4944e-01, time/batch = 15.2881s	
21818/25300 (epoch 43.119), train_loss = 0.67834416, grad/param norm = 2.2265e-01, time/batch = 16.1677s	
21819/25300 (epoch 43.121), train_loss = 0.73104638, grad/param norm = 2.7389e-01, time/batch = 15.4461s	
21820/25300 (epoch 43.123), train_loss = 0.66513665, grad/param norm = 2.0940e-01, time/batch = 15.2196s	
21821/25300 (epoch 43.125), train_loss = 0.81108456, grad/param norm = 2.3310e-01, time/batch = 15.7340s	
21822/25300 (epoch 43.126), train_loss = 0.72719268, grad/param norm = 2.2498e-01, time/batch = 15.4045s	
21823/25300 (epoch 43.128), train_loss = 0.69433890, grad/param norm = 2.2821e-01, time/batch = 15.3974s	
21824/25300 (epoch 43.130), train_loss = 0.57160583, grad/param norm = 2.0173e-01, time/batch = 15.3893s	
21825/25300 (epoch 43.132), train_loss = 0.57802317, grad/param norm = 2.1457e-01, time/batch = 15.6538s	
21826/25300 (epoch 43.134), train_loss = 0.60511329, grad/param norm = 1.9873e-01, time/batch = 17.3071s	
21827/25300 (epoch 43.136), train_loss = 0.71785686, grad/param norm = 2.2253e-01, time/batch = 17.4861s	
21828/25300 (epoch 43.138), train_loss = 0.62724340, grad/param norm = 2.0808e-01, time/batch = 17.1391s	
21829/25300 (epoch 43.140), train_loss = 0.58122099, grad/param norm = 1.8686e-01, time/batch = 16.4819s	
21830/25300 (epoch 43.142), train_loss = 0.79804456, grad/param norm = 2.3046e-01, time/batch = 16.7118s	
21831/25300 (epoch 43.144), train_loss = 0.77298859, grad/param norm = 2.1078e-01, time/batch = 16.7141s	
21832/25300 (epoch 43.146), train_loss = 0.68332540, grad/param norm = 2.1835e-01, time/batch = 18.7078s	
21833/25300 (epoch 43.148), train_loss = 0.70525129, grad/param norm = 2.1267e-01, time/batch = 16.8010s	
21834/25300 (epoch 43.150), train_loss = 0.73763601, grad/param norm = 2.4324e-01, time/batch = 16.7332s	
21835/25300 (epoch 43.152), train_loss = 0.82571481, grad/param norm = 2.7022e-01, time/batch = 17.5619s	
21836/25300 (epoch 43.154), train_loss = 0.62227356, grad/param norm = 1.9336e-01, time/batch = 18.3696s	
21837/25300 (epoch 43.156), train_loss = 0.72851529, grad/param norm = 3.7688e-01, time/batch = 16.3110s	
21838/25300 (epoch 43.158), train_loss = 0.63271969, grad/param norm = 2.3839e-01, time/batch = 15.5474s	
21839/25300 (epoch 43.160), train_loss = 0.71272014, grad/param norm = 2.4677e-01, time/batch = 17.4481s	
21840/25300 (epoch 43.162), train_loss = 0.64005841, grad/param norm = 2.2211e-01, time/batch = 18.3759s	
21841/25300 (epoch 43.164), train_loss = 0.76441021, grad/param norm = 2.6635e-01, time/batch = 15.3925s	
21842/25300 (epoch 43.166), train_loss = 0.70790069, grad/param norm = 2.2570e-01, time/batch = 15.8934s	
21843/25300 (epoch 43.168), train_loss = 0.65337347, grad/param norm = 1.9052e-01, time/batch = 15.4831s	
21844/25300 (epoch 43.170), train_loss = 0.66221789, grad/param norm = 1.8939e-01, time/batch = 17.2991s	
21845/25300 (epoch 43.172), train_loss = 0.59615561, grad/param norm = 1.9428e-01, time/batch = 16.3067s	
21846/25300 (epoch 43.174), train_loss = 0.63369913, grad/param norm = 2.0682e-01, time/batch = 16.0528s	
21847/25300 (epoch 43.176), train_loss = 0.63459663, grad/param norm = 2.7687e-01, time/batch = 15.7221s	
21848/25300 (epoch 43.178), train_loss = 0.82908225, grad/param norm = 2.6063e-01, time/batch = 16.6366s	
21849/25300 (epoch 43.180), train_loss = 0.56695563, grad/param norm = 1.9633e-01, time/batch = 15.7172s	
21850/25300 (epoch 43.182), train_loss = 0.68147811, grad/param norm = 2.3814e-01, time/batch = 17.6350s	
21851/25300 (epoch 43.184), train_loss = 0.62909523, grad/param norm = 2.3836e-01, time/batch = 15.5520s	
21852/25300 (epoch 43.186), train_loss = 0.60512482, grad/param norm = 2.3543e-01, time/batch = 16.6390s	
21853/25300 (epoch 43.188), train_loss = 0.71494629, grad/param norm = 2.4688e-01, time/batch = 16.3075s	
21854/25300 (epoch 43.190), train_loss = 0.73428057, grad/param norm = 2.3529e-01, time/batch = 18.3697s	
21855/25300 (epoch 43.192), train_loss = 0.65859831, grad/param norm = 2.0429e-01, time/batch = 17.6463s	
21856/25300 (epoch 43.194), train_loss = 0.64140280, grad/param norm = 1.9469e-01, time/batch = 15.7040s	
21857/25300 (epoch 43.196), train_loss = 0.78515121, grad/param norm = 2.6749e-01, time/batch = 16.7012s	
21858/25300 (epoch 43.198), train_loss = 0.65983387, grad/param norm = 2.4173e-01, time/batch = 17.8892s	
21859/25300 (epoch 43.200), train_loss = 0.70311859, grad/param norm = 2.2512e-01, time/batch = 15.8206s	
21860/25300 (epoch 43.202), train_loss = 0.69737038, grad/param norm = 2.2511e-01, time/batch = 16.2838s	
21861/25300 (epoch 43.204), train_loss = 0.68158246, grad/param norm = 2.1226e-01, time/batch = 16.4941s	
21862/25300 (epoch 43.206), train_loss = 0.78865017, grad/param norm = 2.5362e-01, time/batch = 16.2291s	
21863/25300 (epoch 43.208), train_loss = 0.66358504, grad/param norm = 2.6484e-01, time/batch = 16.2294s	
21864/25300 (epoch 43.209), train_loss = 0.62198634, grad/param norm = 2.1971e-01, time/batch = 15.5739s	
21865/25300 (epoch 43.211), train_loss = 0.69258359, grad/param norm = 2.1832e-01, time/batch = 15.4960s	
21866/25300 (epoch 43.213), train_loss = 0.73075346, grad/param norm = 2.6495e-01, time/batch = 15.7239s	
21867/25300 (epoch 43.215), train_loss = 0.74804503, grad/param norm = 2.2634e-01, time/batch = 16.1318s	
21868/25300 (epoch 43.217), train_loss = 0.71630578, grad/param norm = 2.4294e-01, time/batch = 16.4743s	
21869/25300 (epoch 43.219), train_loss = 0.76099436, grad/param norm = 2.3773e-01, time/batch = 16.4691s	
21870/25300 (epoch 43.221), train_loss = 0.80455702, grad/param norm = 2.5807e-01, time/batch = 16.7186s	
21871/25300 (epoch 43.223), train_loss = 0.75174859, grad/param norm = 2.5004e-01, time/batch = 15.7222s	
21872/25300 (epoch 43.225), train_loss = 0.97833455, grad/param norm = 3.1624e-01, time/batch = 15.5494s	
21873/25300 (epoch 43.227), train_loss = 0.83712755, grad/param norm = 2.3898e-01, time/batch = 16.2403s	
21874/25300 (epoch 43.229), train_loss = 0.68794768, grad/param norm = 2.1593e-01, time/batch = 15.9711s	
21875/25300 (epoch 43.231), train_loss = 0.72012829, grad/param norm = 2.5588e-01, time/batch = 16.3052s	
21876/25300 (epoch 43.233), train_loss = 0.77285284, grad/param norm = 2.9278e-01, time/batch = 16.4764s	
21877/25300 (epoch 43.235), train_loss = 0.69968823, grad/param norm = 2.1903e-01, time/batch = 16.9024s	
21878/25300 (epoch 43.237), train_loss = 0.83895996, grad/param norm = 2.9145e-01, time/batch = 15.7285s	
21879/25300 (epoch 43.239), train_loss = 0.68342639, grad/param norm = 2.4735e-01, time/batch = 15.9004s	
21880/25300 (epoch 43.241), train_loss = 0.85619418, grad/param norm = 2.1546e-01, time/batch = 15.4710s	
21881/25300 (epoch 43.243), train_loss = 0.93050394, grad/param norm = 2.8777e-01, time/batch = 16.3023s	
21882/25300 (epoch 43.245), train_loss = 0.69441703, grad/param norm = 2.3071e-01, time/batch = 15.7029s	
21883/25300 (epoch 43.247), train_loss = 0.75397902, grad/param norm = 2.4453e-01, time/batch = 17.2402s	
21884/25300 (epoch 43.249), train_loss = 0.63781299, grad/param norm = 1.8993e-01, time/batch = 15.9831s	
21885/25300 (epoch 43.251), train_loss = 0.64636429, grad/param norm = 2.3020e-01, time/batch = 15.8089s	
21886/25300 (epoch 43.253), train_loss = 0.68863066, grad/param norm = 2.1331e-01, time/batch = 15.6706s	
21887/25300 (epoch 43.255), train_loss = 0.66986904, grad/param norm = 2.1693e-01, time/batch = 16.3203s	
21888/25300 (epoch 43.257), train_loss = 0.68022334, grad/param norm = 2.3832e-01, time/batch = 15.9785s	
21889/25300 (epoch 43.259), train_loss = 0.82089405, grad/param norm = 2.9573e-01, time/batch = 15.1342s	
21890/25300 (epoch 43.261), train_loss = 0.81666400, grad/param norm = 2.6441e-01, time/batch = 15.7126s	
21891/25300 (epoch 43.263), train_loss = 0.82510659, grad/param norm = 2.6184e-01, time/batch = 17.4666s	
21892/25300 (epoch 43.265), train_loss = 0.84880574, grad/param norm = 2.7404e-01, time/batch = 15.9786s	
21893/25300 (epoch 43.267), train_loss = 0.74447755, grad/param norm = 2.3153e-01, time/batch = 15.9516s	
21894/25300 (epoch 43.269), train_loss = 0.60052652, grad/param norm = 1.9255e-01, time/batch = 17.8080s	
21895/25300 (epoch 43.271), train_loss = 0.68169325, grad/param norm = 2.4975e-01, time/batch = 17.0598s	
21896/25300 (epoch 43.273), train_loss = 0.77868193, grad/param norm = 2.5790e-01, time/batch = 16.3812s	
21897/25300 (epoch 43.275), train_loss = 0.69191330, grad/param norm = 1.8965e-01, time/batch = 16.7043s	
21898/25300 (epoch 43.277), train_loss = 0.64174535, grad/param norm = 2.4451e-01, time/batch = 16.9932s	
21899/25300 (epoch 43.279), train_loss = 0.71901083, grad/param norm = 2.2791e-01, time/batch = 18.0594s	
21900/25300 (epoch 43.281), train_loss = 0.86536253, grad/param norm = 2.7393e-01, time/batch = 16.2205s	
21901/25300 (epoch 43.283), train_loss = 0.64865540, grad/param norm = 2.0865e-01, time/batch = 17.4710s	
21902/25300 (epoch 43.285), train_loss = 0.71726134, grad/param norm = 2.2369e-01, time/batch = 15.9877s	
21903/25300 (epoch 43.287), train_loss = 0.82872581, grad/param norm = 2.1275e-01, time/batch = 17.0538s	
21904/25300 (epoch 43.289), train_loss = 0.70571337, grad/param norm = 2.3788e-01, time/batch = 17.1498s	
21905/25300 (epoch 43.291), train_loss = 0.69727015, grad/param norm = 2.3288e-01, time/batch = 16.4667s	
21906/25300 (epoch 43.292), train_loss = 0.89510584, grad/param norm = 2.3752e-01, time/batch = 16.3848s	
21907/25300 (epoch 43.294), train_loss = 0.75368534, grad/param norm = 2.5037e-01, time/batch = 15.8011s	
21908/25300 (epoch 43.296), train_loss = 0.64172162, grad/param norm = 2.1434e-01, time/batch = 16.9860s	
21909/25300 (epoch 43.298), train_loss = 0.80321604, grad/param norm = 2.4244e-01, time/batch = 15.8810s	
21910/25300 (epoch 43.300), train_loss = 0.80753730, grad/param norm = 2.6647e-01, time/batch = 18.6349s	
21911/25300 (epoch 43.302), train_loss = 0.58690376, grad/param norm = 2.1454e-01, time/batch = 15.4672s	
21912/25300 (epoch 43.304), train_loss = 0.84767422, grad/param norm = 2.3219e-01, time/batch = 17.1421s	
21913/25300 (epoch 43.306), train_loss = 0.57770325, grad/param norm = 2.1876e-01, time/batch = 16.2398s	
21914/25300 (epoch 43.308), train_loss = 0.78948729, grad/param norm = 2.3718e-01, time/batch = 17.8803s	
21915/25300 (epoch 43.310), train_loss = 0.61563048, grad/param norm = 2.1524e-01, time/batch = 2.3327s	
21916/25300 (epoch 43.312), train_loss = 0.75616968, grad/param norm = 2.1861e-01, time/batch = 0.6608s	
21917/25300 (epoch 43.314), train_loss = 0.61764868, grad/param norm = 1.9216e-01, time/batch = 0.6616s	
21918/25300 (epoch 43.316), train_loss = 0.75064919, grad/param norm = 2.4845e-01, time/batch = 0.6612s	
21919/25300 (epoch 43.318), train_loss = 0.58081598, grad/param norm = 2.1402e-01, time/batch = 0.6658s	
21920/25300 (epoch 43.320), train_loss = 0.65927870, grad/param norm = 1.9228e-01, time/batch = 0.6629s	
21921/25300 (epoch 43.322), train_loss = 0.86501599, grad/param norm = 2.9396e-01, time/batch = 0.6615s	
21922/25300 (epoch 43.324), train_loss = 0.66911455, grad/param norm = 2.3046e-01, time/batch = 0.6570s	
21923/25300 (epoch 43.326), train_loss = 0.57602465, grad/param norm = 2.0559e-01, time/batch = 0.6574s	
21924/25300 (epoch 43.328), train_loss = 0.60026286, grad/param norm = 2.6338e-01, time/batch = 0.6573s	
21925/25300 (epoch 43.330), train_loss = 0.67653827, grad/param norm = 2.2699e-01, time/batch = 0.6587s	
21926/25300 (epoch 43.332), train_loss = 0.72136499, grad/param norm = 2.4960e-01, time/batch = 0.6573s	
21927/25300 (epoch 43.334), train_loss = 0.59514774, grad/param norm = 2.3419e-01, time/batch = 0.6629s	
21928/25300 (epoch 43.336), train_loss = 0.60387000, grad/param norm = 2.3001e-01, time/batch = 0.6646s	
21929/25300 (epoch 43.338), train_loss = 0.60675568, grad/param norm = 2.1576e-01, time/batch = 0.6673s	
21930/25300 (epoch 43.340), train_loss = 0.66410085, grad/param norm = 2.5366e-01, time/batch = 0.9112s	
21931/25300 (epoch 43.342), train_loss = 0.67363874, grad/param norm = 2.5124e-01, time/batch = 0.9792s	
21932/25300 (epoch 43.344), train_loss = 0.75968317, grad/param norm = 2.2700e-01, time/batch = 0.9731s	
21933/25300 (epoch 43.346), train_loss = 0.67062104, grad/param norm = 2.2210e-01, time/batch = 0.9639s	
21934/25300 (epoch 43.348), train_loss = 0.64019576, grad/param norm = 2.2121e-01, time/batch = 0.9717s	
21935/25300 (epoch 43.350), train_loss = 0.67296495, grad/param norm = 2.2149e-01, time/batch = 1.5479s	
21936/25300 (epoch 43.352), train_loss = 0.68986457, grad/param norm = 2.0550e-01, time/batch = 1.8020s	
21937/25300 (epoch 43.354), train_loss = 0.68589029, grad/param norm = 2.4496e-01, time/batch = 1.8496s	
21938/25300 (epoch 43.356), train_loss = 0.69686915, grad/param norm = 2.2516e-01, time/batch = 16.0599s	
21939/25300 (epoch 43.358), train_loss = 0.68484003, grad/param norm = 2.3596e-01, time/batch = 18.3924s	
21940/25300 (epoch 43.360), train_loss = 0.65068646, grad/param norm = 2.2862e-01, time/batch = 16.1415s	
21941/25300 (epoch 43.362), train_loss = 0.59995019, grad/param norm = 2.3692e-01, time/batch = 16.9912s	
21942/25300 (epoch 43.364), train_loss = 0.61924961, grad/param norm = 2.5123e-01, time/batch = 16.0762s	
21943/25300 (epoch 43.366), train_loss = 0.61725802, grad/param norm = 2.3364e-01, time/batch = 15.9003s	
21944/25300 (epoch 43.368), train_loss = 0.67005028, grad/param norm = 2.0918e-01, time/batch = 17.3222s	
21945/25300 (epoch 43.370), train_loss = 0.63100205, grad/param norm = 2.8267e-01, time/batch = 16.9014s	
21946/25300 (epoch 43.372), train_loss = 0.61799316, grad/param norm = 2.5455e-01, time/batch = 16.9932s	
21947/25300 (epoch 43.374), train_loss = 0.59548865, grad/param norm = 2.3170e-01, time/batch = 15.9799s	
21948/25300 (epoch 43.375), train_loss = 0.77075223, grad/param norm = 2.7389e-01, time/batch = 16.2375s	
21949/25300 (epoch 43.377), train_loss = 0.77172302, grad/param norm = 2.3642e-01, time/batch = 17.4762s	
21950/25300 (epoch 43.379), train_loss = 0.73092203, grad/param norm = 2.5342e-01, time/batch = 16.7291s	
21951/25300 (epoch 43.381), train_loss = 0.69593514, grad/param norm = 2.8562e-01, time/batch = 15.3216s	
21952/25300 (epoch 43.383), train_loss = 0.65178734, grad/param norm = 2.1987e-01, time/batch = 16.2376s	
21953/25300 (epoch 43.385), train_loss = 0.72261081, grad/param norm = 2.0763e-01, time/batch = 17.7272s	
21954/25300 (epoch 43.387), train_loss = 0.70423557, grad/param norm = 2.3735e-01, time/batch = 7.3794s	
21955/25300 (epoch 43.389), train_loss = 0.67785041, grad/param norm = 2.3023e-01, time/batch = 0.6676s	
21956/25300 (epoch 43.391), train_loss = 0.66477291, grad/param norm = 2.1000e-01, time/batch = 0.6806s	
21957/25300 (epoch 43.393), train_loss = 0.70053211, grad/param norm = 2.2823e-01, time/batch = 0.6809s	
21958/25300 (epoch 43.395), train_loss = 0.57506919, grad/param norm = 2.1228e-01, time/batch = 0.6722s	
21959/25300 (epoch 43.397), train_loss = 0.54147538, grad/param norm = 2.5113e-01, time/batch = 0.6721s	
21960/25300 (epoch 43.399), train_loss = 0.61053928, grad/param norm = 2.2831e-01, time/batch = 0.6714s	
21961/25300 (epoch 43.401), train_loss = 0.74878344, grad/param norm = 2.8278e-01, time/batch = 0.6820s	
21962/25300 (epoch 43.403), train_loss = 0.73244463, grad/param norm = 2.5141e-01, time/batch = 0.6728s	
21963/25300 (epoch 43.405), train_loss = 0.64956799, grad/param norm = 2.1852e-01, time/batch = 0.6908s	
21964/25300 (epoch 43.407), train_loss = 0.67151085, grad/param norm = 2.4024e-01, time/batch = 0.6809s	
21965/25300 (epoch 43.409), train_loss = 0.62968136, grad/param norm = 2.0867e-01, time/batch = 0.6790s	
21966/25300 (epoch 43.411), train_loss = 0.65275107, grad/param norm = 2.2815e-01, time/batch = 0.6752s	
21967/25300 (epoch 43.413), train_loss = 0.57870133, grad/param norm = 2.1608e-01, time/batch = 0.6795s	
21968/25300 (epoch 43.415), train_loss = 0.60903522, grad/param norm = 2.2294e-01, time/batch = 0.6797s	
21969/25300 (epoch 43.417), train_loss = 0.58235987, grad/param norm = 2.1366e-01, time/batch = 0.6720s	
21970/25300 (epoch 43.419), train_loss = 0.49118134, grad/param norm = 1.6421e-01, time/batch = 0.6745s	
21971/25300 (epoch 43.421), train_loss = 0.58753841, grad/param norm = 1.7721e-01, time/batch = 0.6734s	
21972/25300 (epoch 43.423), train_loss = 0.58301024, grad/param norm = 2.2815e-01, time/batch = 0.6733s	
21973/25300 (epoch 43.425), train_loss = 0.69813181, grad/param norm = 5.1026e-01, time/batch = 0.6694s	
21974/25300 (epoch 43.427), train_loss = 0.74700049, grad/param norm = 2.3681e-01, time/batch = 0.6714s	
21975/25300 (epoch 43.429), train_loss = 0.78887825, grad/param norm = 2.8286e-01, time/batch = 0.6741s	
21976/25300 (epoch 43.431), train_loss = 0.69508201, grad/param norm = 2.3941e-01, time/batch = 0.6759s	
21977/25300 (epoch 43.433), train_loss = 0.73220210, grad/param norm = 2.0133e-01, time/batch = 0.6804s	
21978/25300 (epoch 43.435), train_loss = 0.62181158, grad/param norm = 2.3691e-01, time/batch = 0.6729s	
21979/25300 (epoch 43.437), train_loss = 0.61679874, grad/param norm = 1.9830e-01, time/batch = 0.6727s	
21980/25300 (epoch 43.439), train_loss = 0.72007031, grad/param norm = 2.3864e-01, time/batch = 0.6711s	
21981/25300 (epoch 43.441), train_loss = 0.75218352, grad/param norm = 2.7823e-01, time/batch = 0.6710s	
21982/25300 (epoch 43.443), train_loss = 0.81984646, grad/param norm = 2.7615e-01, time/batch = 0.6688s	
21983/25300 (epoch 43.445), train_loss = 0.77672620, grad/param norm = 2.4337e-01, time/batch = 0.6731s	
21984/25300 (epoch 43.447), train_loss = 0.62586070, grad/param norm = 2.2212e-01, time/batch = 0.6685s	
21985/25300 (epoch 43.449), train_loss = 0.55724861, grad/param norm = 2.7088e-01, time/batch = 0.6699s	
21986/25300 (epoch 43.451), train_loss = 0.88615966, grad/param norm = 2.7958e-01, time/batch = 0.6680s	
21987/25300 (epoch 43.453), train_loss = 0.74465003, grad/param norm = 2.5510e-01, time/batch = 0.6696s	
21988/25300 (epoch 43.455), train_loss = 0.73410539, grad/param norm = 3.1518e-01, time/batch = 0.6711s	
21989/25300 (epoch 43.457), train_loss = 0.62457689, grad/param norm = 2.3141e-01, time/batch = 0.6817s	
21990/25300 (epoch 43.458), train_loss = 0.67041762, grad/param norm = 2.4810e-01, time/batch = 0.6729s	
21991/25300 (epoch 43.460), train_loss = 0.66490595, grad/param norm = 2.3625e-01, time/batch = 0.6735s	
21992/25300 (epoch 43.462), train_loss = 0.47727188, grad/param norm = 1.9841e-01, time/batch = 0.6725s	
21993/25300 (epoch 43.464), train_loss = 0.74154506, grad/param norm = 2.3079e-01, time/batch = 0.6823s	
21994/25300 (epoch 43.466), train_loss = 0.70061115, grad/param norm = 2.3374e-01, time/batch = 0.6815s	
21995/25300 (epoch 43.468), train_loss = 0.70087425, grad/param norm = 2.0061e-01, time/batch = 0.6775s	
21996/25300 (epoch 43.470), train_loss = 0.67924928, grad/param norm = 2.2094e-01, time/batch = 0.6723s	
21997/25300 (epoch 43.472), train_loss = 0.56962538, grad/param norm = 1.9750e-01, time/batch = 0.6742s	
21998/25300 (epoch 43.474), train_loss = 0.73711837, grad/param norm = 2.1634e-01, time/batch = 0.6729s	
21999/25300 (epoch 43.476), train_loss = 0.64189240, grad/param norm = 2.4934e-01, time/batch = 0.6707s	
evaluating loss over split index 2	
1/27...	
2/27...	
3/27...	
4/27...	
5/27...	
6/27...	
7/27...	
8/27...	
9/27...	
10/27...	
11/27...	
12/27...	
13/27...	
14/27...	
15/27...	
16/27...	
17/27...	
18/27...	
19/27...	
20/27...	
21/27...	
22/27...	
23/27...	
24/27...	
25/27...	
26/27...	
27/27...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_matlab_epoch43.48_1.8502.t7	
22000/25300 (epoch 43.478), train_loss = 0.71139278, grad/param norm = 2.6916e-01, time/batch = 0.6756s	
22001/25300 (epoch 43.480), train_loss = 1.12938131, grad/param norm = 3.3199e-01, time/batch = 0.6789s	
22002/25300 (epoch 43.482), train_loss = 0.72783447, grad/param norm = 2.7639e-01, time/batch = 0.6718s	
22003/25300 (epoch 43.484), train_loss = 0.74849496, grad/param norm = 2.5622e-01, time/batch = 0.6739s	
22004/25300 (epoch 43.486), train_loss = 0.69467095, grad/param norm = 2.2349e-01, time/batch = 0.6734s	
22005/25300 (epoch 43.488), train_loss = 0.84344914, grad/param norm = 2.9093e-01, time/batch = 0.6715s	
22006/25300 (epoch 43.490), train_loss = 0.72114248, grad/param norm = 2.6288e-01, time/batch = 0.6734s	
22007/25300 (epoch 43.492), train_loss = 0.78457870, grad/param norm = 2.3374e-01, time/batch = 0.6710s	
22008/25300 (epoch 43.494), train_loss = 0.71140125, grad/param norm = 2.2700e-01, time/batch = 0.6719s	
22009/25300 (epoch 43.496), train_loss = 0.75274184, grad/param norm = 2.5758e-01, time/batch = 0.6799s	
22010/25300 (epoch 43.498), train_loss = 0.67156643, grad/param norm = 1.9637e-01, time/batch = 0.6752s	
22011/25300 (epoch 43.500), train_loss = 0.82465347, grad/param norm = 2.4336e-01, time/batch = 0.6743s	
22012/25300 (epoch 43.502), train_loss = 0.71518499, grad/param norm = 2.2170e-01, time/batch = 0.6647s	
22013/25300 (epoch 43.504), train_loss = 0.68249497, grad/param norm = 2.4325e-01, time/batch = 0.6708s	
22014/25300 (epoch 43.506), train_loss = 0.57297202, grad/param norm = 2.5401e-01, time/batch = 0.6737s	
22015/25300 (epoch 43.508), train_loss = 0.68919549, grad/param norm = 2.2710e-01, time/batch = 0.6706s	
22016/25300 (epoch 43.510), train_loss = 0.67941175, grad/param norm = 2.6064e-01, time/batch = 0.6734s	
22017/25300 (epoch 43.512), train_loss = 0.53564158, grad/param norm = 2.0508e-01, time/batch = 0.6755s	
22018/25300 (epoch 43.514), train_loss = 0.70004320, grad/param norm = 2.6794e-01, time/batch = 0.6769s	
22019/25300 (epoch 43.516), train_loss = 0.76350960, grad/param norm = 2.8599e-01, time/batch = 0.6779s	
22020/25300 (epoch 43.518), train_loss = 0.76132714, grad/param norm = 2.2843e-01, time/batch = 0.6787s	
22021/25300 (epoch 43.520), train_loss = 0.57733239, grad/param norm = 1.8501e-01, time/batch = 0.6753s	
22022/25300 (epoch 43.522), train_loss = 0.65918034, grad/param norm = 2.7043e-01, time/batch = 0.6761s	
22023/25300 (epoch 43.524), train_loss = 0.61639305, grad/param norm = 2.1844e-01, time/batch = 0.6792s	
22024/25300 (epoch 43.526), train_loss = 0.78599883, grad/param norm = 2.1821e-01, time/batch = 0.6767s	
22025/25300 (epoch 43.528), train_loss = 0.83059322, grad/param norm = 2.4871e-01, time/batch = 0.6780s	
22026/25300 (epoch 43.530), train_loss = 0.76659141, grad/param norm = 2.2620e-01, time/batch = 0.6786s	
22027/25300 (epoch 43.532), train_loss = 0.66130607, grad/param norm = 2.0619e-01, time/batch = 0.6742s	
22028/25300 (epoch 43.534), train_loss = 0.68635785, grad/param norm = 3.2742e-01, time/batch = 0.6692s	
22029/25300 (epoch 43.536), train_loss = 0.56443962, grad/param norm = 2.4671e-01, time/batch = 0.6649s	
22030/25300 (epoch 43.538), train_loss = 0.59115628, grad/param norm = 2.2647e-01, time/batch = 0.6733s	
22031/25300 (epoch 43.540), train_loss = 0.60565348, grad/param norm = 2.0786e-01, time/batch = 0.6810s	
22032/25300 (epoch 43.542), train_loss = 0.57876544, grad/param norm = 1.9292e-01, time/batch = 0.6780s	
22033/25300 (epoch 43.543), train_loss = 0.57518181, grad/param norm = 2.0318e-01, time/batch = 0.6686s	
22034/25300 (epoch 43.545), train_loss = 0.88721304, grad/param norm = 3.5952e-01, time/batch = 0.6742s	
22035/25300 (epoch 43.547), train_loss = 0.80472179, grad/param norm = 2.6223e-01, time/batch = 0.6674s	
22036/25300 (epoch 43.549), train_loss = 0.89480316, grad/param norm = 3.5032e-01, time/batch = 0.6767s	
22037/25300 (epoch 43.551), train_loss = 0.79812013, grad/param norm = 2.4321e-01, time/batch = 0.6744s	
22038/25300 (epoch 43.553), train_loss = 0.66428532, grad/param norm = 2.2977e-01, time/batch = 0.6692s	
22039/25300 (epoch 43.555), train_loss = 0.72418925, grad/param norm = 2.3892e-01, time/batch = 0.6669s	
22040/25300 (epoch 43.557), train_loss = 0.79080003, grad/param norm = 2.5823e-01, time/batch = 0.6720s	
22041/25300 (epoch 43.559), train_loss = 0.81875770, grad/param norm = 2.6082e-01, time/batch = 0.6916s	
22042/25300 (epoch 43.561), train_loss = 0.84005476, grad/param norm = 2.9958e-01, time/batch = 0.6814s	
22043/25300 (epoch 43.563), train_loss = 0.80383859, grad/param norm = 2.7261e-01, time/batch = 0.6699s	
22044/25300 (epoch 43.565), train_loss = 0.58989350, grad/param norm = 2.1637e-01, time/batch = 0.6739s	
22045/25300 (epoch 43.567), train_loss = 0.55573639, grad/param norm = 2.0950e-01, time/batch = 0.6735s	
22046/25300 (epoch 43.569), train_loss = 0.70056551, grad/param norm = 2.1742e-01, time/batch = 0.6721s	
22047/25300 (epoch 43.571), train_loss = 0.77892305, grad/param norm = 2.5491e-01, time/batch = 0.6677s	
22048/25300 (epoch 43.573), train_loss = 0.70492415, grad/param norm = 2.4438e-01, time/batch = 0.6696s	
22049/25300 (epoch 43.575), train_loss = 0.71377643, grad/param norm = 2.2441e-01, time/batch = 0.6714s	
22050/25300 (epoch 43.577), train_loss = 0.65596738, grad/param norm = 2.4511e-01, time/batch = 0.6685s	
22051/25300 (epoch 43.579), train_loss = 0.81984740, grad/param norm = 2.3012e-01, time/batch = 0.6694s	
22052/25300 (epoch 43.581), train_loss = 0.75840165, grad/param norm = 2.5793e-01, time/batch = 0.6735s	
22053/25300 (epoch 43.583), train_loss = 0.55872734, grad/param norm = 2.3735e-01, time/batch = 0.6706s	
22054/25300 (epoch 43.585), train_loss = 0.57902419, grad/param norm = 2.2712e-01, time/batch = 0.6716s	
22055/25300 (epoch 43.587), train_loss = 0.68741771, grad/param norm = 2.4939e-01, time/batch = 0.6753s	
22056/25300 (epoch 43.589), train_loss = 0.61191472, grad/param norm = 1.8026e-01, time/batch = 0.6722s	
22057/25300 (epoch 43.591), train_loss = 0.57905124, grad/param norm = 3.1726e-01, time/batch = 0.6698s	
22058/25300 (epoch 43.593), train_loss = 0.77274894, grad/param norm = 2.5583e-01, time/batch = 0.6700s	
22059/25300 (epoch 43.595), train_loss = 0.69878908, grad/param norm = 2.1448e-01, time/batch = 0.6693s	
22060/25300 (epoch 43.597), train_loss = 0.63654542, grad/param norm = 2.1630e-01, time/batch = 0.6763s	
22061/25300 (epoch 43.599), train_loss = 0.81936884, grad/param norm = 2.5311e-01, time/batch = 0.6685s	
22062/25300 (epoch 43.601), train_loss = 0.70978398, grad/param norm = 2.8500e-01, time/batch = 0.6671s	
22063/25300 (epoch 43.603), train_loss = 0.69468584, grad/param norm = 2.5355e-01, time/batch = 0.6694s	
22064/25300 (epoch 43.605), train_loss = 0.70614203, grad/param norm = 2.7761e-01, time/batch = 0.6663s	
22065/25300 (epoch 43.607), train_loss = 0.49046592, grad/param norm = 1.7084e-01, time/batch = 0.6711s	
22066/25300 (epoch 43.609), train_loss = 0.62287594, grad/param norm = 2.5447e-01, time/batch = 0.6673s	
22067/25300 (epoch 43.611), train_loss = 0.74481145, grad/param norm = 2.2471e-01, time/batch = 0.6723s	
22068/25300 (epoch 43.613), train_loss = 0.62259503, grad/param norm = 2.1389e-01, time/batch = 0.6712s	
22069/25300 (epoch 43.615), train_loss = 0.65462013, grad/param norm = 2.3440e-01, time/batch = 0.6703s	
22070/25300 (epoch 43.617), train_loss = 0.71978843, grad/param norm = 2.5660e-01, time/batch = 0.6701s	
22071/25300 (epoch 43.619), train_loss = 0.73303289, grad/param norm = 2.2161e-01, time/batch = 0.6726s	
22072/25300 (epoch 43.621), train_loss = 0.76184900, grad/param norm = 2.8118e-01, time/batch = 0.6686s	
22073/25300 (epoch 43.623), train_loss = 0.66085654, grad/param norm = 2.5603e-01, time/batch = 0.6696s	
22074/25300 (epoch 43.625), train_loss = 0.59019442, grad/param norm = 2.1336e-01, time/batch = 0.6700s	
22075/25300 (epoch 43.626), train_loss = 0.66558018, grad/param norm = 2.1827e-01, time/batch = 0.6714s	
22076/25300 (epoch 43.628), train_loss = 0.80058972, grad/param norm = 2.5645e-01, time/batch = 0.6690s	
22077/25300 (epoch 43.630), train_loss = 0.75382447, grad/param norm = 2.8765e-01, time/batch = 0.6705s	
22078/25300 (epoch 43.632), train_loss = 0.69640467, grad/param norm = 2.5480e-01, time/batch = 0.6710s	
22079/25300 (epoch 43.634), train_loss = 0.80307952, grad/param norm = 2.8265e-01, time/batch = 0.6719s	
22080/25300 (epoch 43.636), train_loss = 0.61123950, grad/param norm = 2.1816e-01, time/batch = 0.6718s	
22081/25300 (epoch 43.638), train_loss = 0.69585091, grad/param norm = 3.1178e-01, time/batch = 0.6753s	
22082/25300 (epoch 43.640), train_loss = 0.86942234, grad/param norm = 3.6148e-01, time/batch = 0.6763s	
22083/25300 (epoch 43.642), train_loss = 0.74356114, grad/param norm = 2.6302e-01, time/batch = 0.6721s	
22084/25300 (epoch 43.644), train_loss = 0.71513712, grad/param norm = 2.3666e-01, time/batch = 0.6709s	
22085/25300 (epoch 43.646), train_loss = 0.64302620, grad/param norm = 2.7093e-01, time/batch = 0.6754s	
22086/25300 (epoch 43.648), train_loss = 0.80486757, grad/param norm = 2.3500e-01, time/batch = 0.6744s	
22087/25300 (epoch 43.650), train_loss = 0.74148331, grad/param norm = 2.4896e-01, time/batch = 0.6722s	
22088/25300 (epoch 43.652), train_loss = 0.73846832, grad/param norm = 2.6380e-01, time/batch = 0.6749s	
22089/25300 (epoch 43.654), train_loss = 0.80631443, grad/param norm = 2.5373e-01, time/batch = 0.6773s	
22090/25300 (epoch 43.656), train_loss = 0.74802019, grad/param norm = 2.4658e-01, time/batch = 0.6735s	
22091/25300 (epoch 43.658), train_loss = 0.55549070, grad/param norm = 1.8894e-01, time/batch = 0.6722s	
22092/25300 (epoch 43.660), train_loss = 0.57716557, grad/param norm = 2.6755e-01, time/batch = 0.6727s	
22093/25300 (epoch 43.662), train_loss = 0.57249884, grad/param norm = 1.8828e-01, time/batch = 0.6728s	
22094/25300 (epoch 43.664), train_loss = 0.54402933, grad/param norm = 2.4116e-01, time/batch = 0.6712s	
22095/25300 (epoch 43.666), train_loss = 0.61215281, grad/param norm = 2.4355e-01, time/batch = 0.6740s	
22096/25300 (epoch 43.668), train_loss = 0.71642157, grad/param norm = 3.7661e-01, time/batch = 0.6729s	
22097/25300 (epoch 43.670), train_loss = 0.65437948, grad/param norm = 3.6803e-01, time/batch = 0.6736s	
22098/25300 (epoch 43.672), train_loss = 0.65087063, grad/param norm = 2.5045e-01, time/batch = 0.6747s	
22099/25300 (epoch 43.674), train_loss = 0.61561071, grad/param norm = 1.9338e-01, time/batch = 0.6733s	
22100/25300 (epoch 43.676), train_loss = 0.63338589, grad/param norm = 2.4949e-01, time/batch = 0.6759s	
22101/25300 (epoch 43.678), train_loss = 0.63105274, grad/param norm = 2.2735e-01, time/batch = 0.6752s	
22102/25300 (epoch 43.680), train_loss = 0.54114036, grad/param norm = 1.5690e-01, time/batch = 0.6724s	
22103/25300 (epoch 43.682), train_loss = 0.48410074, grad/param norm = 1.9506e-01, time/batch = 0.6708s	
22104/25300 (epoch 43.684), train_loss = 0.61257253, grad/param norm = 1.8166e-01, time/batch = 0.6718s	
22105/25300 (epoch 43.686), train_loss = 0.57895532, grad/param norm = 2.0152e-01, time/batch = 0.6768s	
22106/25300 (epoch 43.688), train_loss = 0.64558853, grad/param norm = 2.7103e-01, time/batch = 0.6715s	
22107/25300 (epoch 43.690), train_loss = 0.57530885, grad/param norm = 2.3223e-01, time/batch = 0.6784s	
22108/25300 (epoch 43.692), train_loss = 0.63307459, grad/param norm = 2.4194e-01, time/batch = 0.6706s	
22109/25300 (epoch 43.694), train_loss = 0.64112795, grad/param norm = 2.7682e-01, time/batch = 0.6695s	
22110/25300 (epoch 43.696), train_loss = 0.65792545, grad/param norm = 2.2008e-01, time/batch = 0.6704s	
22111/25300 (epoch 43.698), train_loss = 0.76206094, grad/param norm = 2.6361e-01, time/batch = 0.6718s	
22112/25300 (epoch 43.700), train_loss = 0.55582391, grad/param norm = 1.9538e-01, time/batch = 0.6702s	
22113/25300 (epoch 43.702), train_loss = 0.74180651, grad/param norm = 2.5002e-01, time/batch = 0.6707s	
22114/25300 (epoch 43.704), train_loss = 0.53058437, grad/param norm = 1.7833e-01, time/batch = 0.6680s	
22115/25300 (epoch 43.706), train_loss = 0.65893419, grad/param norm = 2.2462e-01, time/batch = 0.6709s	
22116/25300 (epoch 43.708), train_loss = 0.58170947, grad/param norm = 1.9839e-01, time/batch = 0.6674s	
22117/25300 (epoch 43.709), train_loss = 0.80018922, grad/param norm = 2.1401e-01, time/batch = 0.6657s	
22118/25300 (epoch 43.711), train_loss = 0.81687672, grad/param norm = 2.6494e-01, time/batch = 0.6731s	
22119/25300 (epoch 43.713), train_loss = 0.69210086, grad/param norm = 2.1716e-01, time/batch = 0.6817s	
22120/25300 (epoch 43.715), train_loss = 0.68896698, grad/param norm = 2.0824e-01, time/batch = 0.6817s	
22121/25300 (epoch 43.717), train_loss = 0.60484687, grad/param norm = 2.2450e-01, time/batch = 0.6746s	
22122/25300 (epoch 43.719), train_loss = 0.67284803, grad/param norm = 2.5685e-01, time/batch = 0.6678s	
22123/25300 (epoch 43.721), train_loss = 0.69791156, grad/param norm = 2.3104e-01, time/batch = 0.6691s	
22124/25300 (epoch 43.723), train_loss = 0.67419387, grad/param norm = 2.3219e-01, time/batch = 0.6709s	
22125/25300 (epoch 43.725), train_loss = 0.69571792, grad/param norm = 2.3149e-01, time/batch = 0.6749s	
22126/25300 (epoch 43.727), train_loss = 0.67958887, grad/param norm = 2.3446e-01, time/batch = 0.6727s	
22127/25300 (epoch 43.729), train_loss = 0.65176352, grad/param norm = 2.3362e-01, time/batch = 0.6678s	
22128/25300 (epoch 43.731), train_loss = 0.80338156, grad/param norm = 2.3343e-01, time/batch = 0.6682s	
22129/25300 (epoch 43.733), train_loss = 0.68744452, grad/param norm = 1.9576e-01, time/batch = 0.6680s	
22130/25300 (epoch 43.735), train_loss = 0.86134017, grad/param norm = 2.5920e-01, time/batch = 0.6766s	
22131/25300 (epoch 43.737), train_loss = 0.54908952, grad/param norm = 2.0396e-01, time/batch = 0.6784s	
22132/25300 (epoch 43.739), train_loss = 0.80901967, grad/param norm = 2.5852e-01, time/batch = 0.6784s	
22133/25300 (epoch 43.741), train_loss = 0.68561977, grad/param norm = 2.5500e-01, time/batch = 0.6868s	
22134/25300 (epoch 43.743), train_loss = 0.69704819, grad/param norm = 2.2638e-01, time/batch = 0.6689s	
22135/25300 (epoch 43.745), train_loss = 0.68137891, grad/param norm = 2.4007e-01, time/batch = 0.6699s	
22136/25300 (epoch 43.747), train_loss = 0.58109996, grad/param norm = 2.0436e-01, time/batch = 0.6709s	
22137/25300 (epoch 43.749), train_loss = 0.70639899, grad/param norm = 2.9776e-01, time/batch = 0.6717s	
22138/25300 (epoch 43.751), train_loss = 0.72382073, grad/param norm = 2.5709e-01, time/batch = 0.6704s	
22139/25300 (epoch 43.753), train_loss = 0.58383679, grad/param norm = 2.1915e-01, time/batch = 0.6693s	
22140/25300 (epoch 43.755), train_loss = 0.80397439, grad/param norm = 2.7150e-01, time/batch = 0.6751s	
22141/25300 (epoch 43.757), train_loss = 0.64351713, grad/param norm = 2.2950e-01, time/batch = 0.6732s	
22142/25300 (epoch 43.759), train_loss = 0.61804295, grad/param norm = 2.1657e-01, time/batch = 0.6715s	
22143/25300 (epoch 43.761), train_loss = 0.82106285, grad/param norm = 2.1450e-01, time/batch = 0.6705s	
22144/25300 (epoch 43.763), train_loss = 0.65630248, grad/param norm = 2.1015e-01, time/batch = 0.6735s	
22145/25300 (epoch 43.765), train_loss = 0.63672502, grad/param norm = 2.3183e-01, time/batch = 0.6700s	
22146/25300 (epoch 43.767), train_loss = 0.66813575, grad/param norm = 2.6983e-01, time/batch = 0.6705s	
22147/25300 (epoch 43.769), train_loss = 0.68948400, grad/param norm = 2.5978e-01, time/batch = 0.6745s	
22148/25300 (epoch 43.771), train_loss = 0.74936057, grad/param norm = 2.7697e-01, time/batch = 0.6752s	
22149/25300 (epoch 43.773), train_loss = 0.77818315, grad/param norm = 2.4549e-01, time/batch = 0.6710s	
22150/25300 (epoch 43.775), train_loss = 0.68946894, grad/param norm = 2.0535e-01, time/batch = 0.6726s	
22151/25300 (epoch 43.777), train_loss = 0.63134171, grad/param norm = 2.2202e-01, time/batch = 0.6779s	
22152/25300 (epoch 43.779), train_loss = 0.76408988, grad/param norm = 2.4468e-01, time/batch = 0.6733s	
22153/25300 (epoch 43.781), train_loss = 0.75096900, grad/param norm = 2.4429e-01, time/batch = 0.6721s	
22154/25300 (epoch 43.783), train_loss = 0.80329724, grad/param norm = 2.6566e-01, time/batch = 0.6733s	
22155/25300 (epoch 43.785), train_loss = 0.77270078, grad/param norm = 2.5742e-01, time/batch = 0.6723s	
22156/25300 (epoch 43.787), train_loss = 0.74212038, grad/param norm = 2.6351e-01, time/batch = 0.6734s	
22157/25300 (epoch 43.789), train_loss = 0.79718575, grad/param norm = 2.6279e-01, time/batch = 0.6741s	
22158/25300 (epoch 43.791), train_loss = 0.78237921, grad/param norm = 2.5974e-01, time/batch = 0.6889s	
22159/25300 (epoch 43.792), train_loss = 0.80664076, grad/param norm = 2.3812e-01, time/batch = 0.6759s	
22160/25300 (epoch 43.794), train_loss = 0.66399871, grad/param norm = 2.3954e-01, time/batch = 0.6748s	
22161/25300 (epoch 43.796), train_loss = 0.63948579, grad/param norm = 2.1630e-01, time/batch = 0.6766s	
22162/25300 (epoch 43.798), train_loss = 0.79236395, grad/param norm = 3.1529e-01, time/batch = 0.6776s	
22163/25300 (epoch 43.800), train_loss = 0.66558625, grad/param norm = 2.0360e-01, time/batch = 0.6758s	
22164/25300 (epoch 43.802), train_loss = 0.56174367, grad/param norm = 2.1994e-01, time/batch = 0.6755s	
22165/25300 (epoch 43.804), train_loss = 0.68648607, grad/param norm = 2.0330e-01, time/batch = 0.6754s	
22166/25300 (epoch 43.806), train_loss = 0.74396894, grad/param norm = 2.4306e-01, time/batch = 0.6740s	
22167/25300 (epoch 43.808), train_loss = 0.80511615, grad/param norm = 2.1529e-01, time/batch = 0.6710s	
22168/25300 (epoch 43.810), train_loss = 0.68461435, grad/param norm = 2.6216e-01, time/batch = 0.6716s	
22169/25300 (epoch 43.812), train_loss = 0.77795635, grad/param norm = 2.2692e-01, time/batch = 0.6711s	
22170/25300 (epoch 43.814), train_loss = 0.82917005, grad/param norm = 2.5740e-01, time/batch = 0.6696s	
22171/25300 (epoch 43.816), train_loss = 0.89559125, grad/param norm = 2.8428e-01, time/batch = 0.6746s	
22172/25300 (epoch 43.818), train_loss = 0.80210919, grad/param norm = 2.5314e-01, time/batch = 0.6701s	
22173/25300 (epoch 43.820), train_loss = 0.75180267, grad/param norm = 2.2812e-01, time/batch = 0.6719s	
22174/25300 (epoch 43.822), train_loss = 0.63864529, grad/param norm = 2.1720e-01, time/batch = 0.6719s	
22175/25300 (epoch 43.824), train_loss = 0.77715321, grad/param norm = 2.3529e-01, time/batch = 0.6733s	
22176/25300 (epoch 43.826), train_loss = 0.64698288, grad/param norm = 2.0703e-01, time/batch = 0.6724s	
22177/25300 (epoch 43.828), train_loss = 0.65199959, grad/param norm = 2.2303e-01, time/batch = 0.6699s	
22178/25300 (epoch 43.830), train_loss = 0.71872510, grad/param norm = 2.6175e-01, time/batch = 0.6707s	
22179/25300 (epoch 43.832), train_loss = 0.82361093, grad/param norm = 2.6563e-01, time/batch = 0.6698s	
22180/25300 (epoch 43.834), train_loss = 0.66632685, grad/param norm = 2.2112e-01, time/batch = 0.6714s	
22181/25300 (epoch 43.836), train_loss = 0.67611215, grad/param norm = 2.3322e-01, time/batch = 0.6714s	
22182/25300 (epoch 43.838), train_loss = 0.67728560, grad/param norm = 2.1298e-01, time/batch = 0.6707s	
22183/25300 (epoch 43.840), train_loss = 0.75598034, grad/param norm = 2.7206e-01, time/batch = 0.6710s	
22184/25300 (epoch 43.842), train_loss = 0.69291736, grad/param norm = 2.3364e-01, time/batch = 0.6696s	
22185/25300 (epoch 43.844), train_loss = 0.78369639, grad/param norm = 1.9644e-01, time/batch = 0.6771s	
22186/25300 (epoch 43.846), train_loss = 0.77262661, grad/param norm = 2.1912e-01, time/batch = 0.6784s	
22187/25300 (epoch 43.848), train_loss = 0.75181971, grad/param norm = 2.5330e-01, time/batch = 0.6748s	
22188/25300 (epoch 43.850), train_loss = 0.75143587, grad/param norm = 2.4716e-01, time/batch = 0.6755s	
22189/25300 (epoch 43.852), train_loss = 0.77687569, grad/param norm = 2.2336e-01, time/batch = 0.6767s	
22190/25300 (epoch 43.854), train_loss = 0.81677385, grad/param norm = 2.7041e-01, time/batch = 0.6723s	
22191/25300 (epoch 43.856), train_loss = 0.66615302, grad/param norm = 2.5727e-01, time/batch = 0.6768s	
22192/25300 (epoch 43.858), train_loss = 0.67669297, grad/param norm = 2.4822e-01, time/batch = 0.6735s	
22193/25300 (epoch 43.860), train_loss = 0.62475029, grad/param norm = 1.9942e-01, time/batch = 0.6798s	
22194/25300 (epoch 43.862), train_loss = 0.71084073, grad/param norm = 2.3351e-01, time/batch = 0.6800s	
22195/25300 (epoch 43.864), train_loss = 0.85812073, grad/param norm = 2.4884e-01, time/batch = 0.6811s	
22196/25300 (epoch 43.866), train_loss = 0.65014662, grad/param norm = 2.4598e-01, time/batch = 0.6785s	
22197/25300 (epoch 43.868), train_loss = 0.78486497, grad/param norm = 2.4131e-01, time/batch = 0.6723s	
22198/25300 (epoch 43.870), train_loss = 0.76827596, grad/param norm = 2.0721e-01, time/batch = 0.6710s	
22199/25300 (epoch 43.872), train_loss = 0.73044646, grad/param norm = 2.7104e-01, time/batch = 0.6728s	
22200/25300 (epoch 43.874), train_loss = 0.78228179, grad/param norm = 2.6665e-01, time/batch = 0.6682s	
22201/25300 (epoch 43.875), train_loss = 0.67658928, grad/param norm = 2.2043e-01, time/batch = 0.6687s	
22202/25300 (epoch 43.877), train_loss = 0.67928344, grad/param norm = 2.3856e-01, time/batch = 0.6670s	
22203/25300 (epoch 43.879), train_loss = 0.63787891, grad/param norm = 2.2902e-01, time/batch = 0.6649s	
22204/25300 (epoch 43.881), train_loss = 0.91066960, grad/param norm = 2.8932e-01, time/batch = 0.6672s	
22205/25300 (epoch 43.883), train_loss = 0.87034579, grad/param norm = 2.4943e-01, time/batch = 0.6672s	
22206/25300 (epoch 43.885), train_loss = 0.76719619, grad/param norm = 2.4935e-01, time/batch = 0.6672s	
22207/25300 (epoch 43.887), train_loss = 0.79441230, grad/param norm = 2.4299e-01, time/batch = 0.6748s	
22208/25300 (epoch 43.889), train_loss = 0.86999249, grad/param norm = 3.9888e-01, time/batch = 0.6787s	
22209/25300 (epoch 43.891), train_loss = 0.75244149, grad/param norm = 3.0209e-01, time/batch = 0.6816s	
22210/25300 (epoch 43.893), train_loss = 0.72053946, grad/param norm = 2.9368e-01, time/batch = 0.6700s	
22211/25300 (epoch 43.895), train_loss = 0.55934635, grad/param norm = 1.9559e-01, time/batch = 0.6681s	
22212/25300 (epoch 43.897), train_loss = 0.61222216, grad/param norm = 2.1103e-01, time/batch = 0.6741s	
22213/25300 (epoch 43.899), train_loss = 0.72100190, grad/param norm = 2.5600e-01, time/batch = 0.6704s	
22214/25300 (epoch 43.901), train_loss = 0.77491372, grad/param norm = 2.3600e-01, time/batch = 0.6684s	
22215/25300 (epoch 43.903), train_loss = 0.60220768, grad/param norm = 2.6731e-01, time/batch = 0.6645s	
22216/25300 (epoch 43.905), train_loss = 0.64346839, grad/param norm = 2.4354e-01, time/batch = 0.6718s	
22217/25300 (epoch 43.907), train_loss = 0.65895283, grad/param norm = 2.4590e-01, time/batch = 0.6717s	
22218/25300 (epoch 43.909), train_loss = 0.74780079, grad/param norm = 2.4112e-01, time/batch = 0.6863s	
22219/25300 (epoch 43.911), train_loss = 0.80501538, grad/param norm = 2.9472e-01, time/batch = 0.6739s	
22220/25300 (epoch 43.913), train_loss = 0.90852993, grad/param norm = 3.0055e-01, time/batch = 0.6780s	
22221/25300 (epoch 43.915), train_loss = 0.67873362, grad/param norm = 2.3199e-01, time/batch = 0.6783s	
22222/25300 (epoch 43.917), train_loss = 0.87013046, grad/param norm = 2.6559e-01, time/batch = 0.6716s	
22223/25300 (epoch 43.919), train_loss = 0.81340978, grad/param norm = 3.0254e-01, time/batch = 0.6780s	
22224/25300 (epoch 43.921), train_loss = 0.69024906, grad/param norm = 2.3503e-01, time/batch = 0.6648s	
22225/25300 (epoch 43.923), train_loss = 0.78786881, grad/param norm = 2.6788e-01, time/batch = 0.6704s	
22226/25300 (epoch 43.925), train_loss = 0.72640123, grad/param norm = 2.4892e-01, time/batch = 0.6674s	
22227/25300 (epoch 43.927), train_loss = 0.71487180, grad/param norm = 2.2969e-01, time/batch = 0.6716s	
22228/25300 (epoch 43.929), train_loss = 0.79507139, grad/param norm = 2.1866e-01, time/batch = 0.6778s	
22229/25300 (epoch 43.931), train_loss = 0.77821661, grad/param norm = 2.8365e-01, time/batch = 0.6752s	
22230/25300 (epoch 43.933), train_loss = 0.76969467, grad/param norm = 2.5826e-01, time/batch = 0.6664s	
22231/25300 (epoch 43.935), train_loss = 0.78724599, grad/param norm = 2.3731e-01, time/batch = 0.6722s	
22232/25300 (epoch 43.937), train_loss = 0.58663871, grad/param norm = 1.8799e-01, time/batch = 0.6731s	
22233/25300 (epoch 43.939), train_loss = 0.72390556, grad/param norm = 2.3293e-01, time/batch = 0.6668s	
22234/25300 (epoch 43.941), train_loss = 0.67407802, grad/param norm = 2.3467e-01, time/batch = 0.6682s	
22235/25300 (epoch 43.943), train_loss = 0.73875173, grad/param norm = 2.2610e-01, time/batch = 0.6704s	
22236/25300 (epoch 43.945), train_loss = 0.75850896, grad/param norm = 2.5227e-01, time/batch = 0.6685s	
22237/25300 (epoch 43.947), train_loss = 0.67045808, grad/param norm = 2.2777e-01, time/batch = 0.6693s	
22238/25300 (epoch 43.949), train_loss = 0.73766513, grad/param norm = 2.1713e-01, time/batch = 0.6678s	
22239/25300 (epoch 43.951), train_loss = 0.73821551, grad/param norm = 2.1191e-01, time/batch = 0.6640s	
22240/25300 (epoch 43.953), train_loss = 0.66720849, grad/param norm = 2.2381e-01, time/batch = 0.6671s	
22241/25300 (epoch 43.955), train_loss = 0.90331623, grad/param norm = 2.9900e-01, time/batch = 0.6738s	
22242/25300 (epoch 43.957), train_loss = 0.81851052, grad/param norm = 2.7368e-01, time/batch = 0.6716s	
22243/25300 (epoch 43.958), train_loss = 0.74229667, grad/param norm = 2.8404e-01, time/batch = 0.6716s	
22244/25300 (epoch 43.960), train_loss = 0.87663946, grad/param norm = 2.8654e-01, time/batch = 0.6706s	
22245/25300 (epoch 43.962), train_loss = 0.85731511, grad/param norm = 2.4236e-01, time/batch = 0.6726s	
22246/25300 (epoch 43.964), train_loss = 0.75426052, grad/param norm = 2.6623e-01, time/batch = 0.6695s	
22247/25300 (epoch 43.966), train_loss = 0.60922492, grad/param norm = 2.1235e-01, time/batch = 0.6742s	
22248/25300 (epoch 43.968), train_loss = 0.64247480, grad/param norm = 2.1245e-01, time/batch = 0.6743s	
22249/25300 (epoch 43.970), train_loss = 0.69917947, grad/param norm = 2.6344e-01, time/batch = 0.6722s	
22250/25300 (epoch 43.972), train_loss = 0.74812675, grad/param norm = 2.4567e-01, time/batch = 0.6697s	
22251/25300 (epoch 43.974), train_loss = 0.83297359, grad/param norm = 2.8841e-01, time/batch = 0.6702s	
22252/25300 (epoch 43.976), train_loss = 0.77007765, grad/param norm = 2.6208e-01, time/batch = 0.6715s	
22253/25300 (epoch 43.978), train_loss = 0.71163757, grad/param norm = 2.9921e-01, time/batch = 0.6708s	
22254/25300 (epoch 43.980), train_loss = 0.77405653, grad/param norm = 2.7966e-01, time/batch = 0.6719s	
22255/25300 (epoch 43.982), train_loss = 0.70152148, grad/param norm = 2.4509e-01, time/batch = 0.6689s	
22256/25300 (epoch 43.984), train_loss = 0.72710561, grad/param norm = 2.7341e-01, time/batch = 0.6716s	
22257/25300 (epoch 43.986), train_loss = 0.77812134, grad/param norm = 2.5698e-01, time/batch = 0.6716s	
22258/25300 (epoch 43.988), train_loss = 0.75518707, grad/param norm = 2.9917e-01, time/batch = 0.6713s	
22259/25300 (epoch 43.990), train_loss = 0.74398584, grad/param norm = 2.4823e-01, time/batch = 0.6710s	
22260/25300 (epoch 43.992), train_loss = 0.62016979, grad/param norm = 2.0718e-01, time/batch = 0.6702s	
22261/25300 (epoch 43.994), train_loss = 0.77199916, grad/param norm = 3.4144e-01, time/batch = 0.6735s	
22262/25300 (epoch 43.996), train_loss = 0.91021810, grad/param norm = 4.6436e-01, time/batch = 0.6709s	
22263/25300 (epoch 43.998), train_loss = 0.81309936, grad/param norm = 3.3317e-01, time/batch = 0.6729s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
22264/25300 (epoch 44.000), train_loss = 0.78073097, grad/param norm = 2.8250e-01, time/batch = 0.6715s	
22265/25300 (epoch 44.002), train_loss = 0.79078122, grad/param norm = 2.3097e-01, time/batch = 0.6703s	
22266/25300 (epoch 44.004), train_loss = 0.62106316, grad/param norm = 2.3047e-01, time/batch = 0.6702s	
22267/25300 (epoch 44.006), train_loss = 0.87892800, grad/param norm = 2.7342e-01, time/batch = 0.6733s	
22268/25300 (epoch 44.008), train_loss = 0.74086407, grad/param norm = 2.5142e-01, time/batch = 0.6710s	
22269/25300 (epoch 44.010), train_loss = 0.81125081, grad/param norm = 2.5736e-01, time/batch = 0.6722s	
22270/25300 (epoch 44.012), train_loss = 0.71824995, grad/param norm = 2.2529e-01, time/batch = 0.6787s	
22271/25300 (epoch 44.014), train_loss = 0.84940295, grad/param norm = 2.4253e-01, time/batch = 0.6751s	
22272/25300 (epoch 44.016), train_loss = 0.72290507, grad/param norm = 2.5940e-01, time/batch = 0.6712s	
22273/25300 (epoch 44.018), train_loss = 0.67500067, grad/param norm = 2.2956e-01, time/batch = 0.6714s	
22274/25300 (epoch 44.020), train_loss = 0.77725055, grad/param norm = 2.4702e-01, time/batch = 0.6704s	
22275/25300 (epoch 44.022), train_loss = 0.75009172, grad/param norm = 2.4842e-01, time/batch = 0.6728s	
22276/25300 (epoch 44.024), train_loss = 0.60278218, grad/param norm = 2.0634e-01, time/batch = 0.6725s	
22277/25300 (epoch 44.026), train_loss = 0.69993797, grad/param norm = 2.3518e-01, time/batch = 0.6710s	
22278/25300 (epoch 44.028), train_loss = 0.68617415, grad/param norm = 2.1121e-01, time/batch = 0.6709s	
22279/25300 (epoch 44.030), train_loss = 0.84965909, grad/param norm = 2.3011e-01, time/batch = 0.6712s	
22280/25300 (epoch 44.032), train_loss = 0.66831653, grad/param norm = 2.3760e-01, time/batch = 0.6721s	
22281/25300 (epoch 44.034), train_loss = 0.66312578, grad/param norm = 2.1612e-01, time/batch = 0.6706s	
22282/25300 (epoch 44.036), train_loss = 0.62339287, grad/param norm = 2.4423e-01, time/batch = 0.6735s	
22283/25300 (epoch 44.038), train_loss = 0.53446077, grad/param norm = 1.8469e-01, time/batch = 0.6737s	
22284/25300 (epoch 44.040), train_loss = 0.73161216, grad/param norm = 2.6657e-01, time/batch = 0.6691s	
22285/25300 (epoch 44.042), train_loss = 0.71106914, grad/param norm = 2.1192e-01, time/batch = 0.6712s	
22286/25300 (epoch 44.043), train_loss = 0.63757277, grad/param norm = 1.9404e-01, time/batch = 0.6744s	
22287/25300 (epoch 44.045), train_loss = 0.61215527, grad/param norm = 2.0942e-01, time/batch = 0.6756s	
22288/25300 (epoch 44.047), train_loss = 0.72612538, grad/param norm = 2.1117e-01, time/batch = 0.6701s	
22289/25300 (epoch 44.049), train_loss = 0.72373559, grad/param norm = 2.7145e-01, time/batch = 0.6725s	
22290/25300 (epoch 44.051), train_loss = 0.87333138, grad/param norm = 2.3653e-01, time/batch = 0.6723s	
22291/25300 (epoch 44.053), train_loss = 0.56051054, grad/param norm = 1.7996e-01, time/batch = 0.6722s	
22292/25300 (epoch 44.055), train_loss = 0.59967704, grad/param norm = 2.1004e-01, time/batch = 0.6696s	
22293/25300 (epoch 44.057), train_loss = 0.59606344, grad/param norm = 1.8248e-01, time/batch = 0.6696s	
22294/25300 (epoch 44.059), train_loss = 0.66822046, grad/param norm = 2.2738e-01, time/batch = 0.6701s	
22295/25300 (epoch 44.061), train_loss = 0.66808238, grad/param norm = 2.1266e-01, time/batch = 0.6800s	
22296/25300 (epoch 44.063), train_loss = 0.69145538, grad/param norm = 2.0500e-01, time/batch = 0.6765s	
22297/25300 (epoch 44.065), train_loss = 0.72435755, grad/param norm = 2.5077e-01, time/batch = 0.6785s	
22298/25300 (epoch 44.067), train_loss = 0.78371798, grad/param norm = 2.3679e-01, time/batch = 0.6818s	
22299/25300 (epoch 44.069), train_loss = 0.64207087, grad/param norm = 2.4290e-01, time/batch = 0.6734s	
22300/25300 (epoch 44.071), train_loss = 0.76408926, grad/param norm = 2.5097e-01, time/batch = 0.6724s	
22301/25300 (epoch 44.073), train_loss = 0.69791209, grad/param norm = 2.0401e-01, time/batch = 0.6743s	
22302/25300 (epoch 44.075), train_loss = 0.74206467, grad/param norm = 2.1472e-01, time/batch = 0.6680s	
22303/25300 (epoch 44.077), train_loss = 0.72040320, grad/param norm = 2.3231e-01, time/batch = 0.6690s	
22304/25300 (epoch 44.079), train_loss = 0.65739676, grad/param norm = 2.1902e-01, time/batch = 0.6685s	
22305/25300 (epoch 44.081), train_loss = 0.70481703, grad/param norm = 2.0456e-01, time/batch = 0.6720s	
22306/25300 (epoch 44.083), train_loss = 0.74940866, grad/param norm = 2.1445e-01, time/batch = 0.6685s	
22307/25300 (epoch 44.085), train_loss = 0.86161689, grad/param norm = 2.3606e-01, time/batch = 0.6660s	
22308/25300 (epoch 44.087), train_loss = 0.76541404, grad/param norm = 2.1403e-01, time/batch = 0.6688s	
22309/25300 (epoch 44.089), train_loss = 0.73498776, grad/param norm = 2.1137e-01, time/batch = 0.6689s	
22310/25300 (epoch 44.091), train_loss = 0.88904455, grad/param norm = 2.4444e-01, time/batch = 0.6725s	
22311/25300 (epoch 44.093), train_loss = 0.80308316, grad/param norm = 2.6955e-01, time/batch = 0.6730s	
22312/25300 (epoch 44.095), train_loss = 0.76847263, grad/param norm = 2.1633e-01, time/batch = 0.6741s	
22313/25300 (epoch 44.097), train_loss = 0.76653419, grad/param norm = 2.3152e-01, time/batch = 0.6697s	
22314/25300 (epoch 44.099), train_loss = 0.75211340, grad/param norm = 2.3752e-01, time/batch = 0.6712s	
22315/25300 (epoch 44.101), train_loss = 0.70760568, grad/param norm = 2.4977e-01, time/batch = 0.6701s	
22316/25300 (epoch 44.103), train_loss = 0.74920848, grad/param norm = 2.1913e-01, time/batch = 0.6719s	
22317/25300 (epoch 44.105), train_loss = 0.75175523, grad/param norm = 2.2820e-01, time/batch = 0.6781s	
22318/25300 (epoch 44.107), train_loss = 0.74060113, grad/param norm = 2.7332e-01, time/batch = 0.6692s	
22319/25300 (epoch 44.109), train_loss = 0.68859312, grad/param norm = 2.4540e-01, time/batch = 0.6679s	
22320/25300 (epoch 44.111), train_loss = 0.68930407, grad/param norm = 2.5507e-01, time/batch = 0.6669s	
22321/25300 (epoch 44.113), train_loss = 0.67701076, grad/param norm = 2.7496e-01, time/batch = 0.6702s	
22322/25300 (epoch 44.115), train_loss = 0.70712638, grad/param norm = 2.6338e-01, time/batch = 0.6706s	
22323/25300 (epoch 44.117), train_loss = 0.78679899, grad/param norm = 2.0888e-01, time/batch = 0.6768s	
22324/25300 (epoch 44.119), train_loss = 0.67976682, grad/param norm = 2.2694e-01, time/batch = 0.6700s	
22325/25300 (epoch 44.121), train_loss = 0.74220760, grad/param norm = 4.2549e-01, time/batch = 0.6699s	
22326/25300 (epoch 44.123), train_loss = 0.66255516, grad/param norm = 2.4886e-01, time/batch = 0.6707s	
22327/25300 (epoch 44.125), train_loss = 0.81385859, grad/param norm = 2.3608e-01, time/batch = 0.6718s	
22328/25300 (epoch 44.126), train_loss = 0.72916153, grad/param norm = 2.1316e-01, time/batch = 0.6680s	
22329/25300 (epoch 44.128), train_loss = 0.69789803, grad/param norm = 2.3509e-01, time/batch = 0.6754s	
22330/25300 (epoch 44.130), train_loss = 0.56272399, grad/param norm = 1.9827e-01, time/batch = 0.6787s	
22331/25300 (epoch 44.132), train_loss = 0.58112109, grad/param norm = 2.2488e-01, time/batch = 0.6818s	
22332/25300 (epoch 44.134), train_loss = 0.60608731, grad/param norm = 1.9127e-01, time/batch = 0.6802s	
22333/25300 (epoch 44.136), train_loss = 0.70713589, grad/param norm = 2.2214e-01, time/batch = 0.6800s	
22334/25300 (epoch 44.138), train_loss = 0.62518543, grad/param norm = 2.0100e-01, time/batch = 0.6785s	
22335/25300 (epoch 44.140), train_loss = 0.57701755, grad/param norm = 2.1571e-01, time/batch = 0.6784s	
22336/25300 (epoch 44.142), train_loss = 0.81116106, grad/param norm = 2.4135e-01, time/batch = 0.6757s	
22337/25300 (epoch 44.144), train_loss = 0.77563707, grad/param norm = 2.3800e-01, time/batch = 0.6708s	
22338/25300 (epoch 44.146), train_loss = 0.68660098, grad/param norm = 2.5361e-01, time/batch = 0.6708s	
22339/25300 (epoch 44.148), train_loss = 0.69408193, grad/param norm = 2.1927e-01, time/batch = 0.6730s	
22340/25300 (epoch 44.150), train_loss = 0.72502984, grad/param norm = 2.2717e-01, time/batch = 0.6714s	
22341/25300 (epoch 44.152), train_loss = 0.80618635, grad/param norm = 2.6218e-01, time/batch = 0.6750s	
22342/25300 (epoch 44.154), train_loss = 0.61081128, grad/param norm = 2.1623e-01, time/batch = 0.6726s	
22343/25300 (epoch 44.156), train_loss = 0.74433910, grad/param norm = 3.0109e-01, time/batch = 0.6705s	
22344/25300 (epoch 44.158), train_loss = 0.60976316, grad/param norm = 2.4780e-01, time/batch = 0.6724s	
22345/25300 (epoch 44.160), train_loss = 0.68378405, grad/param norm = 2.2332e-01, time/batch = 0.6720s	
22346/25300 (epoch 44.162), train_loss = 0.63531584, grad/param norm = 2.2291e-01, time/batch = 0.6714s	
22347/25300 (epoch 44.164), train_loss = 0.76864176, grad/param norm = 2.8342e-01, time/batch = 0.6739s	
22348/25300 (epoch 44.166), train_loss = 0.69562505, grad/param norm = 2.1679e-01, time/batch = 0.6829s	
22349/25300 (epoch 44.168), train_loss = 0.65433762, grad/param norm = 2.0739e-01, time/batch = 0.6817s	
22350/25300 (epoch 44.170), train_loss = 0.65708866, grad/param norm = 2.0979e-01, time/batch = 0.6768s	
22351/25300 (epoch 44.172), train_loss = 0.58619646, grad/param norm = 2.4266e-01, time/batch = 0.6764s	
22352/25300 (epoch 44.174), train_loss = 0.62981473, grad/param norm = 2.4506e-01, time/batch = 0.6791s	
22353/25300 (epoch 44.176), train_loss = 0.62015506, grad/param norm = 3.3884e-01, time/batch = 0.6656s	
22354/25300 (epoch 44.178), train_loss = 0.82509113, grad/param norm = 2.9131e-01, time/batch = 0.6712s	
22355/25300 (epoch 44.180), train_loss = 0.57756472, grad/param norm = 2.3151e-01, time/batch = 0.6721s	
22356/25300 (epoch 44.182), train_loss = 0.66460857, grad/param norm = 2.7234e-01, time/batch = 0.6725s	
22357/25300 (epoch 44.184), train_loss = 0.63307156, grad/param norm = 2.3529e-01, time/batch = 0.6722s	
22358/25300 (epoch 44.186), train_loss = 0.59542224, grad/param norm = 2.5978e-01, time/batch = 0.6729s	
22359/25300 (epoch 44.188), train_loss = 0.70863858, grad/param norm = 2.7580e-01, time/batch = 0.6740s	
22360/25300 (epoch 44.190), train_loss = 0.72394827, grad/param norm = 2.3416e-01, time/batch = 0.6779s	
22361/25300 (epoch 44.192), train_loss = 0.68385627, grad/param norm = 2.2284e-01, time/batch = 0.6799s	
22362/25300 (epoch 44.194), train_loss = 0.63509975, grad/param norm = 2.0044e-01, time/batch = 0.6798s	
22363/25300 (epoch 44.196), train_loss = 0.77456618, grad/param norm = 2.6185e-01, time/batch = 0.6802s	
22364/25300 (epoch 44.198), train_loss = 0.67187416, grad/param norm = 2.4767e-01, time/batch = 0.6753s	
22365/25300 (epoch 44.200), train_loss = 0.68659619, grad/param norm = 2.1662e-01, time/batch = 0.6750s	
22366/25300 (epoch 44.202), train_loss = 0.70001112, grad/param norm = 2.2092e-01, time/batch = 0.6761s	
22367/25300 (epoch 44.204), train_loss = 0.68105765, grad/param norm = 2.2955e-01, time/batch = 0.6781s	
22368/25300 (epoch 44.206), train_loss = 0.77026743, grad/param norm = 2.4809e-01, time/batch = 0.6764s	
22369/25300 (epoch 44.208), train_loss = 0.66470459, grad/param norm = 2.3222e-01, time/batch = 0.6779s	
22370/25300 (epoch 44.209), train_loss = 0.62620661, grad/param norm = 2.7697e-01, time/batch = 0.6731s	
22371/25300 (epoch 44.211), train_loss = 0.68748407, grad/param norm = 2.2619e-01, time/batch = 0.6765s	
22372/25300 (epoch 44.213), train_loss = 0.72073733, grad/param norm = 2.6582e-01, time/batch = 0.6743s	
22373/25300 (epoch 44.215), train_loss = 0.74362482, grad/param norm = 2.2247e-01, time/batch = 0.6732s	
22374/25300 (epoch 44.217), train_loss = 0.72634142, grad/param norm = 2.7240e-01, time/batch = 0.6712s	
22375/25300 (epoch 44.219), train_loss = 0.73875808, grad/param norm = 2.4296e-01, time/batch = 0.6752s	
22376/25300 (epoch 44.221), train_loss = 0.78765422, grad/param norm = 2.4106e-01, time/batch = 0.6734s	
22377/25300 (epoch 44.223), train_loss = 0.72513449, grad/param norm = 2.4683e-01, time/batch = 0.6763s	
22378/25300 (epoch 44.225), train_loss = 0.95384679, grad/param norm = 4.3883e-01, time/batch = 0.6748s	
22379/25300 (epoch 44.227), train_loss = 0.85746621, grad/param norm = 2.8081e-01, time/batch = 0.6730s	
22380/25300 (epoch 44.229), train_loss = 0.67906631, grad/param norm = 2.2853e-01, time/batch = 0.6737s	
22381/25300 (epoch 44.231), train_loss = 0.72678622, grad/param norm = 2.3599e-01, time/batch = 0.6745s	
22382/25300 (epoch 44.233), train_loss = 0.75899076, grad/param norm = 2.5391e-01, time/batch = 0.6722s	
22383/25300 (epoch 44.235), train_loss = 0.70110463, grad/param norm = 2.4646e-01, time/batch = 0.9137s	
22384/25300 (epoch 44.237), train_loss = 0.84280478, grad/param norm = 3.0118e-01, time/batch = 0.9782s	
22385/25300 (epoch 44.239), train_loss = 0.68386563, grad/param norm = 2.5130e-01, time/batch = 0.9898s	
22386/25300 (epoch 44.241), train_loss = 0.84641395, grad/param norm = 2.3153e-01, time/batch = 1.8825s	
22387/25300 (epoch 44.243), train_loss = 0.91456559, grad/param norm = 3.0212e-01, time/batch = 1.0640s	
22388/25300 (epoch 44.245), train_loss = 0.68218443, grad/param norm = 2.3721e-01, time/batch = 0.6692s	
22389/25300 (epoch 44.247), train_loss = 0.75336357, grad/param norm = 2.4791e-01, time/batch = 0.6671s	
22390/25300 (epoch 44.249), train_loss = 0.65237177, grad/param norm = 2.0704e-01, time/batch = 0.6577s	
22391/25300 (epoch 44.251), train_loss = 0.62368629, grad/param norm = 2.0184e-01, time/batch = 0.6652s	
22392/25300 (epoch 44.253), train_loss = 0.69375086, grad/param norm = 2.3810e-01, time/batch = 0.6603s	
