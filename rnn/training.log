tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 655, val: 35, test: 0	
vocab size: 125	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 278781	
cloning rnn	
cloning criterion	
1/32750 (epoch 0.002), train_loss = 4.83573615, grad/param norm = 5.9677e-01, time/batch = 0.6752s	
2/32750 (epoch 0.003), train_loss = 4.42528592, grad/param norm = 1.9859e+00, time/batch = 0.6560s	
3/32750 (epoch 0.005), train_loss = 3.73992579, grad/param norm = 1.2070e+00, time/batch = 0.6743s	
4/32750 (epoch 0.006), train_loss = 3.51211893, grad/param norm = 8.6526e-01, time/batch = 0.6406s	
5/32750 (epoch 0.008), train_loss = 3.40643657, grad/param norm = 8.0688e-01, time/batch = 0.6354s	
6/32750 (epoch 0.009), train_loss = 3.47332936, grad/param norm = 7.8261e-01, time/batch = 0.6339s	
7/32750 (epoch 0.011), train_loss = 3.32272348, grad/param norm = 7.0682e-01, time/batch = 0.6457s	
8/32750 (epoch 0.012), train_loss = 3.56400805, grad/param norm = 9.0247e-01, time/batch = 0.6389s	
9/32750 (epoch 0.014), train_loss = 3.52055479, grad/param norm = 6.2710e-01, time/batch = 0.6340s	
10/32750 (epoch 0.015), train_loss = 3.43958524, grad/param norm = 8.6521e-01, time/batch = 0.6357s	
11/32750 (epoch 0.017), train_loss = 3.30570812, grad/param norm = 8.9696e-01, time/batch = 0.6323s	
12/32750 (epoch 0.018), train_loss = 3.43303684, grad/param norm = 6.9480e-01, time/batch = 0.6303s	
13/32750 (epoch 0.020), train_loss = 3.40537325, grad/param norm = 9.3734e-01, time/batch = 0.6304s	
14/32750 (epoch 0.021), train_loss = 3.27846245, grad/param norm = 8.4469e-01, time/batch = 0.6304s	
15/32750 (epoch 0.023), train_loss = 3.29316359, grad/param norm = 5.5509e-01, time/batch = 0.6310s	
16/32750 (epoch 0.024), train_loss = 3.35839369, grad/param norm = 8.4215e-01, time/batch = 0.6326s	
17/32750 (epoch 0.026), train_loss = 3.31384432, grad/param norm = 6.0947e-01, time/batch = 0.6316s	
18/32750 (epoch 0.027), train_loss = 3.49349507, grad/param norm = 6.8321e-01, time/batch = 0.6641s	
19/32750 (epoch 0.029), train_loss = 3.32463766, grad/param norm = 6.7157e-01, time/batch = 0.6611s	
20/32750 (epoch 0.031), train_loss = 3.36512933, grad/param norm = 5.3909e-01, time/batch = 0.6330s	
21/32750 (epoch 0.032), train_loss = 3.39821943, grad/param norm = 5.6836e-01, time/batch = 0.6307s	
22/32750 (epoch 0.034), train_loss = 3.41040585, grad/param norm = 7.3010e-01, time/batch = 0.6365s	
23/32750 (epoch 0.035), train_loss = 3.38237359, grad/param norm = 6.0405e-01, time/batch = 0.6333s	
24/32750 (epoch 0.037), train_loss = 3.34751830, grad/param norm = 5.7096e-01, time/batch = 0.6312s	
25/32750 (epoch 0.038), train_loss = 3.38627773, grad/param norm = 6.3088e-01, time/batch = 0.6312s	
26/32750 (epoch 0.040), train_loss = 3.32661474, grad/param norm = 4.9327e-01, time/batch = 0.6314s	
27/32750 (epoch 0.041), train_loss = 3.47749188, grad/param norm = 6.1273e-01, time/batch = 0.6321s	
28/32750 (epoch 0.043), train_loss = 3.33271170, grad/param norm = 4.7502e-01, time/batch = 0.6295s	
29/32750 (epoch 0.044), train_loss = 3.31755043, grad/param norm = 5.3594e-01, time/batch = 0.6304s	
30/32750 (epoch 0.046), train_loss = 3.27643343, grad/param norm = 5.6557e-01, time/batch = 0.6314s	
31/32750 (epoch 0.047), train_loss = 3.27319668, grad/param norm = 6.7554e-01, time/batch = 0.6326s	
32/32750 (epoch 0.049), train_loss = 3.36556797, grad/param norm = 6.9836e-01, time/batch = 0.6433s	
33/32750 (epoch 0.050), train_loss = 3.39825114, grad/param norm = 7.7412e-01, time/batch = 0.6405s	
34/32750 (epoch 0.052), train_loss = 3.29590966, grad/param norm = 4.7947e-01, time/batch = 0.6722s	
35/32750 (epoch 0.053), train_loss = 3.32742408, grad/param norm = 7.2229e-01, time/batch = 0.6456s	
36/32750 (epoch 0.055), train_loss = 3.36500281, grad/param norm = 7.5028e-01, time/batch = 0.6302s	
37/32750 (epoch 0.056), train_loss = 3.35440613, grad/param norm = 5.8892e-01, time/batch = 0.6305s	
38/32750 (epoch 0.058), train_loss = 3.15396543, grad/param norm = 7.0386e-01, time/batch = 0.6324s	
39/32750 (epoch 0.060), train_loss = 3.34851435, grad/param norm = 8.1191e-01, time/batch = 0.6311s	
40/32750 (epoch 0.061), train_loss = 3.43276287, grad/param norm = 6.7173e-01, time/batch = 0.6318s	
41/32750 (epoch 0.063), train_loss = 3.30411197, grad/param norm = 6.9818e-01, time/batch = 0.6335s	
42/32750 (epoch 0.064), train_loss = 3.31155150, grad/param norm = 7.5063e-01, time/batch = 0.6319s	
43/32750 (epoch 0.066), train_loss = 3.37178377, grad/param norm = 6.5626e-01, time/batch = 0.6315s	
44/32750 (epoch 0.067), train_loss = 3.33401306, grad/param norm = 4.5141e-01, time/batch = 0.6312s	
45/32750 (epoch 0.069), train_loss = 3.49827824, grad/param norm = 7.3061e-01, time/batch = 0.6296s	
46/32750 (epoch 0.070), train_loss = 3.34664065, grad/param norm = 5.4706e-01, time/batch = 0.6316s	
47/32750 (epoch 0.072), train_loss = 3.29386826, grad/param norm = 5.6911e-01, time/batch = 0.6313s	
48/32750 (epoch 0.073), train_loss = 3.26092770, grad/param norm = 5.0281e-01, time/batch = 0.6331s	
49/32750 (epoch 0.075), train_loss = 3.44170949, grad/param norm = 8.7486e-01, time/batch = 0.6607s	
50/32750 (epoch 0.076), train_loss = 3.37402028, grad/param norm = 5.5282e-01, time/batch = 0.6721s	
51/32750 (epoch 0.078), train_loss = 3.45923183, grad/param norm = 6.2975e-01, time/batch = 0.6330s	
52/32750 (epoch 0.079), train_loss = 3.33629703, grad/param norm = 6.1981e-01, time/batch = 0.6321s	
53/32750 (epoch 0.081), train_loss = 3.31295364, grad/param norm = 5.9602e-01, time/batch = 0.6312s	
54/32750 (epoch 0.082), train_loss = 3.37144489, grad/param norm = 6.8951e-01, time/batch = 0.6337s	
55/32750 (epoch 0.084), train_loss = 3.34117959, grad/param norm = 6.2795e-01, time/batch = 0.6342s	
56/32750 (epoch 0.085), train_loss = 3.19017924, grad/param norm = 5.7922e-01, time/batch = 0.6314s	
57/32750 (epoch 0.087), train_loss = 3.36656910, grad/param norm = 5.1374e-01, time/batch = 0.6485s	
58/32750 (epoch 0.089), train_loss = 3.27501969, grad/param norm = 6.8764e-01, time/batch = 0.6496s	
59/32750 (epoch 0.090), train_loss = 3.40503229, grad/param norm = 8.3449e-01, time/batch = 0.6310s	
60/32750 (epoch 0.092), train_loss = 3.24796107, grad/param norm = 6.9667e-01, time/batch = 0.6327s	
61/32750 (epoch 0.093), train_loss = 3.31751933, grad/param norm = 6.9642e-01, time/batch = 0.6412s	
62/32750 (epoch 0.095), train_loss = 3.31073622, grad/param norm = 6.4661e-01, time/batch = 0.6338s	
63/32750 (epoch 0.096), train_loss = 3.32350869, grad/param norm = 6.9287e-01, time/batch = 0.6378s	
64/32750 (epoch 0.098), train_loss = 3.37872125, grad/param norm = 6.4150e-01, time/batch = 0.6332s	
65/32750 (epoch 0.099), train_loss = 3.30614308, grad/param norm = 5.5047e-01, time/batch = 0.6697s	
66/32750 (epoch 0.101), train_loss = 3.34618050, grad/param norm = 7.1463e-01, time/batch = 0.6546s	
67/32750 (epoch 0.102), train_loss = 3.30201465, grad/param norm = 5.1501e-01, time/batch = 0.6307s	
68/32750 (epoch 0.104), train_loss = 3.36565984, grad/param norm = 5.7803e-01, time/batch = 0.6322s	
69/32750 (epoch 0.105), train_loss = 3.31112181, grad/param norm = 6.0649e-01, time/batch = 0.6335s	
70/32750 (epoch 0.107), train_loss = 3.28168393, grad/param norm = 7.0085e-01, time/batch = 0.6376s	
71/32750 (epoch 0.108), train_loss = 3.52081549, grad/param norm = 6.1816e-01, time/batch = 0.6347s	
72/32750 (epoch 0.110), train_loss = 3.37268207, grad/param norm = 5.7742e-01, time/batch = 0.6354s	
73/32750 (epoch 0.111), train_loss = 3.38541332, grad/param norm = 5.5621e-01, time/batch = 0.6322s	
74/32750 (epoch 0.113), train_loss = 3.42099916, grad/param norm = 5.4284e-01, time/batch = 0.6333s	
75/32750 (epoch 0.115), train_loss = 3.26913334, grad/param norm = 6.3945e-01, time/batch = 0.6309s	
76/32750 (epoch 0.116), train_loss = 3.27789171, grad/param norm = 7.1400e-01, time/batch = 0.6319s	
77/32750 (epoch 0.118), train_loss = 3.38949250, grad/param norm = 4.6988e-01, time/batch = 0.6314s	
78/32750 (epoch 0.119), train_loss = 3.40649445, grad/param norm = 5.5406e-01, time/batch = 0.6360s	
79/32750 (epoch 0.121), train_loss = 3.33625056, grad/param norm = 5.1994e-01, time/batch = 0.6562s	
80/32750 (epoch 0.122), train_loss = 3.26828444, grad/param norm = 6.1857e-01, time/batch = 0.6453s	
81/32750 (epoch 0.124), train_loss = 3.42119326, grad/param norm = 8.8812e-01, time/batch = 0.6492s	
82/32750 (epoch 0.125), train_loss = 3.30745514, grad/param norm = 9.5226e-01, time/batch = 0.6455s	
83/32750 (epoch 0.127), train_loss = 3.35981335, grad/param norm = 6.1278e-01, time/batch = 0.6344s	
84/32750 (epoch 0.128), train_loss = 3.29815840, grad/param norm = 6.3200e-01, time/batch = 0.6334s	
85/32750 (epoch 0.130), train_loss = 3.34403160, grad/param norm = 5.8702e-01, time/batch = 0.6333s	
86/32750 (epoch 0.131), train_loss = 3.33513836, grad/param norm = 6.9653e-01, time/batch = 0.6318s	
87/32750 (epoch 0.133), train_loss = 3.35333686, grad/param norm = 5.3890e-01, time/batch = 0.6349s	
88/32750 (epoch 0.134), train_loss = 3.36320675, grad/param norm = 4.8749e-01, time/batch = 0.6458s	
89/32750 (epoch 0.136), train_loss = 3.37721197, grad/param norm = 5.8295e-01, time/batch = 0.6332s	
90/32750 (epoch 0.137), train_loss = 3.36304098, grad/param norm = 5.0999e-01, time/batch = 0.6333s	
91/32750 (epoch 0.139), train_loss = 3.40958225, grad/param norm = 6.1127e-01, time/batch = 0.6336s	
92/32750 (epoch 0.140), train_loss = 3.32877845, grad/param norm = 6.4236e-01, time/batch = 0.6318s	
93/32750 (epoch 0.142), train_loss = 3.41208429, grad/param norm = 1.0217e+00, time/batch = 0.6334s	
94/32750 (epoch 0.144), train_loss = 3.36403152, grad/param norm = 7.8005e-01, time/batch = 0.6397s	
95/32750 (epoch 0.145), train_loss = 3.25604761, grad/param norm = 5.1571e-01, time/batch = 0.6386s	
96/32750 (epoch 0.147), train_loss = 3.23133817, grad/param norm = 4.4723e-01, time/batch = 0.6335s	
97/32750 (epoch 0.148), train_loss = 3.35376361, grad/param norm = 5.5787e-01, time/batch = 0.6340s	
98/32750 (epoch 0.150), train_loss = 3.27753748, grad/param norm = 6.0683e-01, time/batch = 0.6351s	
99/32750 (epoch 0.151), train_loss = 3.37428528, grad/param norm = 7.0116e-01, time/batch = 0.6306s	
100/32750 (epoch 0.153), train_loss = 3.41031963, grad/param norm = 6.7192e-01, time/batch = 0.6308s	
101/32750 (epoch 0.154), train_loss = 3.20577451, grad/param norm = 4.5920e-01, time/batch = 0.6330s	
102/32750 (epoch 0.156), train_loss = 3.29401308, grad/param norm = 5.1214e-01, time/batch = 0.6311s	
103/32750 (epoch 0.157), train_loss = 3.32802405, grad/param norm = 5.6290e-01, time/batch = 0.6303s	
104/32750 (epoch 0.159), train_loss = 3.36797827, grad/param norm = 4.8008e-01, time/batch = 0.6331s	
105/32750 (epoch 0.160), train_loss = 3.32685475, grad/param norm = 4.9492e-01, time/batch = 0.6447s	
106/32750 (epoch 0.162), train_loss = 3.27519852, grad/param norm = 4.7396e-01, time/batch = 0.6531s	
107/32750 (epoch 0.163), train_loss = 3.38778517, grad/param norm = 9.1711e-01, time/batch = 0.6512s	
108/32750 (epoch 0.165), train_loss = 3.29975243, grad/param norm = 1.0636e+00, time/batch = 0.6324s	
109/32750 (epoch 0.166), train_loss = 3.22968220, grad/param norm = 7.7379e-01, time/batch = 0.6311s	
110/32750 (epoch 0.168), train_loss = 3.40914877, grad/param norm = 4.8731e-01, time/batch = 0.6342s	
111/32750 (epoch 0.169), train_loss = 3.37455338, grad/param norm = 5.2303e-01, time/batch = 0.6401s	
112/32750 (epoch 0.171), train_loss = 3.26287787, grad/param norm = 5.9342e-01, time/batch = 0.6733s	
113/32750 (epoch 0.173), train_loss = 3.28278818, grad/param norm = 6.3175e-01, time/batch = 0.6501s	
114/32750 (epoch 0.174), train_loss = 3.26546615, grad/param norm = 6.7882e-01, time/batch = 0.6317s	
115/32750 (epoch 0.176), train_loss = 3.40841959, grad/param norm = 5.9575e-01, time/batch = 0.6336s	
116/32750 (epoch 0.177), train_loss = 3.41293573, grad/param norm = 4.8771e-01, time/batch = 0.6380s	
117/32750 (epoch 0.179), train_loss = 3.29974992, grad/param norm = 7.1107e-01, time/batch = 0.6342s	
118/32750 (epoch 0.180), train_loss = 3.33584034, grad/param norm = 6.9953e-01, time/batch = 0.6332s	
119/32750 (epoch 0.182), train_loss = 3.25860050, grad/param norm = 6.9628e-01, time/batch = 0.6340s	
120/32750 (epoch 0.183), train_loss = 3.34121963, grad/param norm = 7.1512e-01, time/batch = 0.6403s	
121/32750 (epoch 0.185), train_loss = 3.15241233, grad/param norm = 8.5038e-01, time/batch = 0.6352s	
122/32750 (epoch 0.186), train_loss = 3.31064227, grad/param norm = 7.6579e-01, time/batch = 0.6403s	
123/32750 (epoch 0.188), train_loss = 3.38208998, grad/param norm = 5.9171e-01, time/batch = 0.6529s	
124/32750 (epoch 0.189), train_loss = 3.22627817, grad/param norm = 4.6565e-01, time/batch = 0.6330s	
125/32750 (epoch 0.191), train_loss = 3.29147249, grad/param norm = 4.3777e-01, time/batch = 0.6331s	
126/32750 (epoch 0.192), train_loss = 3.21119040, grad/param norm = 4.0682e-01, time/batch = 0.6323s	
127/32750 (epoch 0.194), train_loss = 3.19859019, grad/param norm = 3.9844e-01, time/batch = 0.6352s	
128/32750 (epoch 0.195), train_loss = 3.25976617, grad/param norm = 7.2767e-01, time/batch = 0.6320s	
129/32750 (epoch 0.197), train_loss = 3.34176665, grad/param norm = 1.1596e+00, time/batch = 0.6325s	
130/32750 (epoch 0.198), train_loss = 3.21548319, grad/param norm = 1.1445e+00, time/batch = 0.6311s	
131/32750 (epoch 0.200), train_loss = 3.27195541, grad/param norm = 8.0082e-01, time/batch = 0.6314s	
132/32750 (epoch 0.202), train_loss = 3.27267412, grad/param norm = 5.7498e-01, time/batch = 0.6407s	
133/32750 (epoch 0.203), train_loss = 3.25578065, grad/param norm = 3.6216e-01, time/batch = 0.6350s	
134/32750 (epoch 0.205), train_loss = 3.13874718, grad/param norm = 4.1007e-01, time/batch = 0.6326s	
135/32750 (epoch 0.206), train_loss = 2.97311594, grad/param norm = 5.1584e-01, time/batch = 0.6356s	
136/32750 (epoch 0.208), train_loss = 3.26512871, grad/param norm = 7.8240e-01, time/batch = 0.6334s	
137/32750 (epoch 0.209), train_loss = 3.22748441, grad/param norm = 8.3970e-01, time/batch = 0.6319s	
138/32750 (epoch 0.211), train_loss = 3.15840820, grad/param norm = 7.8485e-01, time/batch = 0.6320s	
139/32750 (epoch 0.212), train_loss = 3.09935363, grad/param norm = 6.9430e-01, time/batch = 0.6314s	
140/32750 (epoch 0.214), train_loss = 3.19707443, grad/param norm = 8.0785e-01, time/batch = 0.6323s	
141/32750 (epoch 0.215), train_loss = 3.20092689, grad/param norm = 6.7736e-01, time/batch = 0.6386s	
142/32750 (epoch 0.217), train_loss = 3.13087920, grad/param norm = 4.9048e-01, time/batch = 0.6343s	
143/32750 (epoch 0.218), train_loss = 3.03050795, grad/param norm = 4.0520e-01, time/batch = 0.6656s	
144/32750 (epoch 0.220), train_loss = 3.08738447, grad/param norm = 4.8767e-01, time/batch = 0.6602s	
145/32750 (epoch 0.221), train_loss = 3.10686538, grad/param norm = 6.0356e-01, time/batch = 0.6332s	
146/32750 (epoch 0.223), train_loss = 3.08268406, grad/param norm = 6.9751e-01, time/batch = 0.6327s	
147/32750 (epoch 0.224), train_loss = 3.24873738, grad/param norm = 9.0043e-01, time/batch = 0.6323s	
148/32750 (epoch 0.226), train_loss = 3.07945395, grad/param norm = 9.2660e-01, time/batch = 0.6345s	
149/32750 (epoch 0.227), train_loss = 3.16690260, grad/param norm = 7.5721e-01, time/batch = 0.6329s	
150/32750 (epoch 0.229), train_loss = 3.09705144, grad/param norm = 5.7337e-01, time/batch = 0.6327s	
151/32750 (epoch 0.231), train_loss = 3.11481685, grad/param norm = 4.8050e-01, time/batch = 0.6338s	
152/32750 (epoch 0.232), train_loss = 3.10000045, grad/param norm = 4.7051e-01, time/batch = 0.6340s	
153/32750 (epoch 0.234), train_loss = 3.15905005, grad/param norm = 5.3935e-01, time/batch = 0.6318s	
154/32750 (epoch 0.235), train_loss = 3.11204246, grad/param norm = 5.5908e-01, time/batch = 0.6320s	
155/32750 (epoch 0.237), train_loss = 3.08029282, grad/param norm = 4.8575e-01, time/batch = 0.6335s	
156/32750 (epoch 0.238), train_loss = 3.08316723, grad/param norm = 5.6615e-01, time/batch = 0.6321s	
157/32750 (epoch 0.240), train_loss = 3.02961541, grad/param norm = 6.6785e-01, time/batch = 0.6348s	
158/32750 (epoch 0.241), train_loss = 3.11052312, grad/param norm = 8.6624e-01, time/batch = 0.6418s	
159/32750 (epoch 0.243), train_loss = 3.24230282, grad/param norm = 1.5003e+00, time/batch = 0.6735s	
160/32750 (epoch 0.244), train_loss = 3.31238313, grad/param norm = 1.3630e+00, time/batch = 0.6483s	
161/32750 (epoch 0.246), train_loss = 3.10320707, grad/param norm = 5.1541e-01, time/batch = 0.6343s	
162/32750 (epoch 0.247), train_loss = 3.08575356, grad/param norm = 3.1058e-01, time/batch = 0.6330s	
163/32750 (epoch 0.249), train_loss = 3.11163249, grad/param norm = 3.3463e-01, time/batch = 0.6339s	
164/32750 (epoch 0.250), train_loss = 3.18903905, grad/param norm = 4.0076e-01, time/batch = 0.6354s	
165/32750 (epoch 0.252), train_loss = 3.01481360, grad/param norm = 3.8848e-01, time/batch = 0.6335s	
166/32750 (epoch 0.253), train_loss = 3.16542057, grad/param norm = 5.7612e-01, time/batch = 0.6344s	
167/32750 (epoch 0.255), train_loss = 3.10426152, grad/param norm = 6.0860e-01, time/batch = 0.6326s	
168/32750 (epoch 0.256), train_loss = 3.00267448, grad/param norm = 7.7123e-01, time/batch = 0.6329s	
169/32750 (epoch 0.258), train_loss = 3.06026655, grad/param norm = 6.9369e-01, time/batch = 0.6320s	
170/32750 (epoch 0.260), train_loss = 3.03311603, grad/param norm = 6.2458e-01, time/batch = 0.6324s	
171/32750 (epoch 0.261), train_loss = 3.13141116, grad/param norm = 7.6714e-01, time/batch = 0.6342s	
172/32750 (epoch 0.263), train_loss = 3.01027019, grad/param norm = 5.9929e-01, time/batch = 0.6387s	
173/32750 (epoch 0.264), train_loss = 2.98755793, grad/param norm = 1.0230e+00, time/batch = 0.6459s	
174/32750 (epoch 0.266), train_loss = 3.02465005, grad/param norm = 1.2356e+00, time/batch = 0.6587s	
175/32750 (epoch 0.267), train_loss = 3.06171031, grad/param norm = 9.4740e-01, time/batch = 0.6702s	
176/32750 (epoch 0.269), train_loss = 2.99690273, grad/param norm = 6.1020e-01, time/batch = 0.6480s	
177/32750 (epoch 0.270), train_loss = 3.13708579, grad/param norm = 4.7378e-01, time/batch = 0.6356s	
178/32750 (epoch 0.272), train_loss = 3.00906239, grad/param norm = 3.9258e-01, time/batch = 0.6322s	
179/32750 (epoch 0.273), train_loss = 3.08753743, grad/param norm = 5.5398e-01, time/batch = 0.6420s	
180/32750 (epoch 0.275), train_loss = 2.99741573, grad/param norm = 5.5310e-01, time/batch = 0.6424s	
181/32750 (epoch 0.276), train_loss = 3.12345491, grad/param norm = 6.8753e-01, time/batch = 0.6356s	
182/32750 (epoch 0.278), train_loss = 3.00402108, grad/param norm = 5.7336e-01, time/batch = 0.6370s	
183/32750 (epoch 0.279), train_loss = 3.05948300, grad/param norm = 4.6570e-01, time/batch = 0.6394s	
184/32750 (epoch 0.281), train_loss = 3.00302752, grad/param norm = 3.4034e-01, time/batch = 0.6346s	
185/32750 (epoch 0.282), train_loss = 2.78826629, grad/param norm = 3.9975e-01, time/batch = 0.6341s	
186/32750 (epoch 0.284), train_loss = 3.29016645, grad/param norm = 1.8037e+00, time/batch = 0.6333s	
187/32750 (epoch 0.285), train_loss = 3.07969368, grad/param norm = 1.6807e+00, time/batch = 0.6332s	
188/32750 (epoch 0.287), train_loss = 3.07627126, grad/param norm = 1.3243e+00, time/batch = 0.6374s	
189/32750 (epoch 0.289), train_loss = 3.09566002, grad/param norm = 7.6536e-01, time/batch = 0.6466s	
190/32750 (epoch 0.290), train_loss = 3.03924062, grad/param norm = 9.9584e-01, time/batch = 0.6607s	
191/32750 (epoch 0.292), train_loss = 2.96480716, grad/param norm = 6.1961e-01, time/batch = 0.6516s	
192/32750 (epoch 0.293), train_loss = 2.80233590, grad/param norm = 6.7105e-01, time/batch = 0.6349s	
193/32750 (epoch 0.295), train_loss = 3.02815438, grad/param norm = 6.4215e-01, time/batch = 0.6337s	
194/32750 (epoch 0.296), train_loss = 2.98104750, grad/param norm = 4.6924e-01, time/batch = 0.6344s	
195/32750 (epoch 0.298), train_loss = 2.83919203, grad/param norm = 5.7747e-01, time/batch = 0.6347s	
196/32750 (epoch 0.299), train_loss = 2.89366747, grad/param norm = 5.5329e-01, time/batch = 0.6330s	
197/32750 (epoch 0.301), train_loss = 2.92164693, grad/param norm = 4.3932e-01, time/batch = 0.6344s	
198/32750 (epoch 0.302), train_loss = 2.79877500, grad/param norm = 4.2370e-01, time/batch = 0.6329s	
199/32750 (epoch 0.304), train_loss = 2.85960989, grad/param norm = 4.7079e-01, time/batch = 0.6343s	
200/32750 (epoch 0.305), train_loss = 2.86723552, grad/param norm = 6.4228e-01, time/batch = 0.6327s	
201/32750 (epoch 0.307), train_loss = 3.00265789, grad/param norm = 9.0055e-01, time/batch = 0.6335s	
202/32750 (epoch 0.308), train_loss = 3.10069754, grad/param norm = 9.2953e-01, time/batch = 0.6335s	
203/32750 (epoch 0.310), train_loss = 3.05227622, grad/param norm = 7.6766e-01, time/batch = 0.6341s	
204/32750 (epoch 0.311), train_loss = 2.86115345, grad/param norm = 3.8418e-01, time/batch = 0.6345s	
205/32750 (epoch 0.313), train_loss = 3.02455511, grad/param norm = 4.3479e-01, time/batch = 0.6597s	
206/32750 (epoch 0.315), train_loss = 2.99633645, grad/param norm = 4.0434e-01, time/batch = 0.6736s	
207/32750 (epoch 0.316), train_loss = 2.85252119, grad/param norm = 2.8395e-01, time/batch = 0.6334s	
208/32750 (epoch 0.318), train_loss = 2.75927716, grad/param norm = 5.1317e-01, time/batch = 0.6338s	
209/32750 (epoch 0.319), train_loss = 2.90519343, grad/param norm = 8.8202e-01, time/batch = 0.6323s	
210/32750 (epoch 0.321), train_loss = 2.84514141, grad/param norm = 9.5537e-01, time/batch = 0.6417s	
211/32750 (epoch 0.322), train_loss = 2.94608782, grad/param norm = 1.3254e+00, time/batch = 0.6364s	
212/32750 (epoch 0.324), train_loss = 3.00910589, grad/param norm = 1.2141e+00, time/batch = 0.6346s	
213/32750 (epoch 0.325), train_loss = 2.87655245, grad/param norm = 8.1603e-01, time/batch = 0.6345s	
214/32750 (epoch 0.327), train_loss = 2.86570784, grad/param norm = 5.0001e-01, time/batch = 0.6333s	
215/32750 (epoch 0.328), train_loss = 2.86128757, grad/param norm = 4.0235e-01, time/batch = 0.6337s	
216/32750 (epoch 0.330), train_loss = 2.78210094, grad/param norm = 3.6382e-01, time/batch = 0.6345s	
217/32750 (epoch 0.331), train_loss = 2.93169072, grad/param norm = 6.8616e-01, time/batch = 0.6328s	
218/32750 (epoch 0.333), train_loss = 2.85767782, grad/param norm = 2.4088e+00, time/batch = 0.6340s	
219/32750 (epoch 0.334), train_loss = 3.21019946, grad/param norm = 1.1157e+00, time/batch = 0.6349s	
220/32750 (epoch 0.336), train_loss = 2.85154818, grad/param norm = 3.4648e-01, time/batch = 0.6358s	
221/32750 (epoch 0.337), train_loss = 2.75703870, grad/param norm = 3.9809e-01, time/batch = 0.6704s	
222/32750 (epoch 0.339), train_loss = 3.06448845, grad/param norm = 6.2191e-01, time/batch = 0.6589s	
223/32750 (epoch 0.340), train_loss = 2.71822958, grad/param norm = 6.7810e-01, time/batch = 0.6325s	
224/32750 (epoch 0.342), train_loss = 2.88036467, grad/param norm = 5.5242e-01, time/batch = 0.6335s	
225/32750 (epoch 0.344), train_loss = 2.96041222, grad/param norm = 6.4640e-01, time/batch = 0.6343s	
226/32750 (epoch 0.345), train_loss = 2.80961758, grad/param norm = 1.0805e+00, time/batch = 0.6424s	
227/32750 (epoch 0.347), train_loss = 2.92268103, grad/param norm = 8.2043e-01, time/batch = 0.6548s	
228/32750 (epoch 0.348), train_loss = 2.84228862, grad/param norm = 4.1785e-01, time/batch = 0.6490s	
229/32750 (epoch 0.350), train_loss = 2.94890017, grad/param norm = 4.4553e-01, time/batch = 0.6352s	
230/32750 (epoch 0.351), train_loss = 2.90172724, grad/param norm = 3.5208e-01, time/batch = 0.6342s	
231/32750 (epoch 0.353), train_loss = 2.81442763, grad/param norm = 3.9095e-01, time/batch = 0.6324s	
232/32750 (epoch 0.354), train_loss = 2.83224567, grad/param norm = 4.7898e-01, time/batch = 0.6337s	
233/32750 (epoch 0.356), train_loss = 2.76147854, grad/param norm = 5.4162e-01, time/batch = 0.6385s	
234/32750 (epoch 0.357), train_loss = 2.79628816, grad/param norm = 6.3389e-01, time/batch = 0.6326s	
235/32750 (epoch 0.359), train_loss = 2.81044734, grad/param norm = 6.8191e-01, time/batch = 0.6350s	
236/32750 (epoch 0.360), train_loss = 2.86210065, grad/param norm = 8.3023e-01, time/batch = 0.6348s	
237/32750 (epoch 0.362), train_loss = 2.79780768, grad/param norm = 1.0444e+00, time/batch = 0.6320s	
238/32750 (epoch 0.363), train_loss = 2.78439671, grad/param norm = 9.1982e-01, time/batch = 0.6343s	
239/32750 (epoch 0.365), train_loss = 2.72068703, grad/param norm = 7.3454e-01, time/batch = 0.6337s	
240/32750 (epoch 0.366), train_loss = 2.76208645, grad/param norm = 6.1338e-01, time/batch = 0.6323s	
241/32750 (epoch 0.368), train_loss = 2.92086688, grad/param norm = 5.5623e-01, time/batch = 0.6362s	
242/32750 (epoch 0.369), train_loss = 2.83711394, grad/param norm = 3.7406e-01, time/batch = 0.6354s	
243/32750 (epoch 0.371), train_loss = 2.78023032, grad/param norm = 3.1120e-01, time/batch = 0.6336s	
244/32750 (epoch 0.373), train_loss = 2.75596081, grad/param norm = 4.1030e-01, time/batch = 0.6340s	
245/32750 (epoch 0.374), train_loss = 2.82481503, grad/param norm = 4.5460e-01, time/batch = 0.6319s	
246/32750 (epoch 0.376), train_loss = 2.68896395, grad/param norm = 8.0924e-01, time/batch = 0.6335s	
247/32750 (epoch 0.377), train_loss = 2.90001172, grad/param norm = 1.3247e+00, time/batch = 0.6363s	
248/32750 (epoch 0.379), train_loss = 2.92591272, grad/param norm = 9.0472e-01, time/batch = 0.6346s	
249/32750 (epoch 0.380), train_loss = 2.90497345, grad/param norm = 5.6577e-01, time/batch = 0.6328s	
250/32750 (epoch 0.382), train_loss = 2.72506778, grad/param norm = 4.0943e-01, time/batch = 0.6330s	
251/32750 (epoch 0.383), train_loss = 2.79825992, grad/param norm = 4.0183e-01, time/batch = 0.6430s	
252/32750 (epoch 0.385), train_loss = 2.73181630, grad/param norm = 3.0829e-01, time/batch = 0.6656s	
253/32750 (epoch 0.386), train_loss = 2.88839710, grad/param norm = 3.9176e-01, time/batch = 0.6672s	
254/32750 (epoch 0.388), train_loss = 2.74774048, grad/param norm = 4.1130e-01, time/batch = 0.6347s	
255/32750 (epoch 0.389), train_loss = 2.76791281, grad/param norm = 4.1945e-01, time/batch = 0.6343s	
256/32750 (epoch 0.391), train_loss = 2.71709300, grad/param norm = 4.3973e-01, time/batch = 0.6318s	
257/32750 (epoch 0.392), train_loss = 2.69616677, grad/param norm = 3.7315e-01, time/batch = 0.6342s	
258/32750 (epoch 0.394), train_loss = 2.78064236, grad/param norm = 3.5893e-01, time/batch = 0.6329s	
259/32750 (epoch 0.395), train_loss = 2.66615423, grad/param norm = 3.9709e-01, time/batch = 0.6333s	
260/32750 (epoch 0.397), train_loss = 2.94092068, grad/param norm = 6.7869e-01, time/batch = 0.6346s	
261/32750 (epoch 0.398), train_loss = 2.84325273, grad/param norm = 1.0077e+00, time/batch = 0.6357s	
262/32750 (epoch 0.400), train_loss = 2.82231825, grad/param norm = 1.0160e+00, time/batch = 0.6339s	
263/32750 (epoch 0.402), train_loss = 2.83497498, grad/param norm = 7.5238e-01, time/batch = 0.6327s	
264/32750 (epoch 0.403), train_loss = 2.84209906, grad/param norm = 6.4724e-01, time/batch = 0.6342s	
265/32750 (epoch 0.405), train_loss = 2.85387204, grad/param norm = 6.7191e-01, time/batch = 0.6359s	
266/32750 (epoch 0.406), train_loss = 2.76458425, grad/param norm = 5.1135e-01, time/batch = 0.6546s	
267/32750 (epoch 0.408), train_loss = 2.67418220, grad/param norm = 5.2912e-01, time/batch = 0.6454s	
268/32750 (epoch 0.409), train_loss = 2.86317054, grad/param norm = 6.3301e-01, time/batch = 0.6746s	
269/32750 (epoch 0.411), train_loss = 2.81125463, grad/param norm = 7.9852e-01, time/batch = 0.6529s	
270/32750 (epoch 0.412), train_loss = 2.79669838, grad/param norm = 9.6909e-01, time/batch = 0.6470s	
271/32750 (epoch 0.414), train_loss = 2.77228849, grad/param norm = 8.7700e-01, time/batch = 0.6355s	
272/32750 (epoch 0.415), train_loss = 2.78421053, grad/param norm = 6.7935e-01, time/batch = 0.6325s	
273/32750 (epoch 0.417), train_loss = 2.66335472, grad/param norm = 8.3736e-01, time/batch = 0.6635s	
274/32750 (epoch 0.418), train_loss = 2.90067858, grad/param norm = 8.8099e-01, time/batch = 0.6322s	
275/32750 (epoch 0.420), train_loss = 2.74738070, grad/param norm = 6.9258e-01, time/batch = 0.6324s	
276/32750 (epoch 0.421), train_loss = 2.91598598, grad/param norm = 4.5492e-01, time/batch = 0.6321s	
277/32750 (epoch 0.423), train_loss = 2.70267112, grad/param norm = 5.0444e-01, time/batch = 0.6319s	
278/32750 (epoch 0.424), train_loss = 2.64578391, grad/param norm = 3.7676e-01, time/batch = 0.6296s	
279/32750 (epoch 0.426), train_loss = 2.72208914, grad/param norm = 4.6706e-01, time/batch = 0.6304s	
280/32750 (epoch 0.427), train_loss = 2.59741517, grad/param norm = 5.1429e-01, time/batch = 0.6300s	
281/32750 (epoch 0.429), train_loss = 2.61619884, grad/param norm = 4.6899e-01, time/batch = 0.6332s	
282/32750 (epoch 0.431), train_loss = 2.86372507, grad/param norm = 4.8757e-01, time/batch = 0.6569s	
283/32750 (epoch 0.432), train_loss = 2.67018362, grad/param norm = 6.1609e-01, time/batch = 0.6804s	
284/32750 (epoch 0.434), train_loss = 2.80729296, grad/param norm = 5.7256e-01, time/batch = 0.6747s	
285/32750 (epoch 0.435), train_loss = 2.69106924, grad/param norm = 4.8805e-01, time/batch = 0.6668s	
286/32750 (epoch 0.437), train_loss = 2.73051253, grad/param norm = 3.6286e-01, time/batch = 0.6620s	
287/32750 (epoch 0.438), train_loss = 2.84343457, grad/param norm = 4.1721e-01, time/batch = 0.6514s	
288/32750 (epoch 0.440), train_loss = 2.68797148, grad/param norm = 4.9558e-01, time/batch = 0.6477s	
289/32750 (epoch 0.441), train_loss = 2.73884254, grad/param norm = 5.3914e-01, time/batch = 0.6328s	
290/32750 (epoch 0.443), train_loss = 2.66414549, grad/param norm = 7.0990e-01, time/batch = 0.6331s	
291/32750 (epoch 0.444), train_loss = 2.76609904, grad/param norm = 8.4116e-01, time/batch = 0.6331s	
292/32750 (epoch 0.446), train_loss = 2.78091737, grad/param norm = 7.3268e-01, time/batch = 0.6481s	
293/32750 (epoch 0.447), train_loss = 2.78689793, grad/param norm = 7.4275e-01, time/batch = 0.6328s	
294/32750 (epoch 0.449), train_loss = 2.84606535, grad/param norm = 8.2132e-01, time/batch = 0.6316s	
295/32750 (epoch 0.450), train_loss = 2.83809583, grad/param norm = 6.8196e-01, time/batch = 0.6326s	
296/32750 (epoch 0.452), train_loss = 2.72709744, grad/param norm = 3.3004e-01, time/batch = 0.6294s	
297/32750 (epoch 0.453), train_loss = 2.64667314, grad/param norm = 3.6690e-01, time/batch = 0.6335s	
298/32750 (epoch 0.455), train_loss = 2.66831642, grad/param norm = 3.2583e-01, time/batch = 0.6432s	
299/32750 (epoch 0.456), train_loss = 2.63865630, grad/param norm = 2.8092e-01, time/batch = 0.6732s	
300/32750 (epoch 0.458), train_loss = 2.79063473, grad/param norm = 2.6484e-01, time/batch = 0.6469s	
301/32750 (epoch 0.460), train_loss = 2.84981682, grad/param norm = 3.8812e-01, time/batch = 0.6383s	
302/32750 (epoch 0.461), train_loss = 2.70976075, grad/param norm = 6.1888e-01, time/batch = 0.6405s	
303/32750 (epoch 0.463), train_loss = 2.65200040, grad/param norm = 5.6807e-01, time/batch = 0.6323s	
304/32750 (epoch 0.464), train_loss = 2.82335419, grad/param norm = 3.4484e-01, time/batch = 0.6353s	
305/32750 (epoch 0.466), train_loss = 2.75530752, grad/param norm = 4.0941e-01, time/batch = 0.6362s	
306/32750 (epoch 0.467), train_loss = 2.90330347, grad/param norm = 5.5183e-01, time/batch = 0.6330s	
307/32750 (epoch 0.469), train_loss = 2.68256614, grad/param norm = 8.2018e-01, time/batch = 0.6346s	
308/32750 (epoch 0.470), train_loss = 2.80102746, grad/param norm = 9.1898e-01, time/batch = 0.6366s	
309/32750 (epoch 0.472), train_loss = 2.68516021, grad/param norm = 5.9135e-01, time/batch = 0.6534s	
310/32750 (epoch 0.473), train_loss = 2.68011467, grad/param norm = 6.3960e-01, time/batch = 0.6479s	
311/32750 (epoch 0.475), train_loss = 2.76665877, grad/param norm = 8.9299e-01, time/batch = 0.6515s	
312/32750 (epoch 0.476), train_loss = 2.79511638, grad/param norm = 8.0549e-01, time/batch = 0.6505s	
313/32750 (epoch 0.478), train_loss = 2.82529111, grad/param norm = 4.6496e-01, time/batch = 0.6483s	
314/32750 (epoch 0.479), train_loss = 2.88376333, grad/param norm = 4.1126e-01, time/batch = 0.6633s	
315/32750 (epoch 0.481), train_loss = 2.95265532, grad/param norm = 3.3944e-01, time/batch = 0.6678s	
316/32750 (epoch 0.482), train_loss = 2.85906606, grad/param norm = 4.5317e-01, time/batch = 0.6460s	
317/32750 (epoch 0.484), train_loss = 2.73430278, grad/param norm = 3.5394e-01, time/batch = 0.6469s	
318/32750 (epoch 0.485), train_loss = 2.58872911, grad/param norm = 4.3708e-01, time/batch = 0.6462s	
319/32750 (epoch 0.487), train_loss = 2.67534605, grad/param norm = 5.7776e-01, time/batch = 0.6562s	
320/32750 (epoch 0.489), train_loss = 2.61922255, grad/param norm = 5.1947e-01, time/batch = 0.6322s	
321/32750 (epoch 0.490), train_loss = 2.63478424, grad/param norm = 5.1175e-01, time/batch = 0.6323s	
322/32750 (epoch 0.492), train_loss = 2.81158631, grad/param norm = 5.4933e-01, time/batch = 0.6314s	
323/32750 (epoch 0.493), train_loss = 2.76907219, grad/param norm = 6.5202e-01, time/batch = 0.6322s	
324/32750 (epoch 0.495), train_loss = 2.95200429, grad/param norm = 8.3251e-01, time/batch = 0.6315s	
325/32750 (epoch 0.496), train_loss = 2.66306897, grad/param norm = 8.5242e-01, time/batch = 0.6311s	
326/32750 (epoch 0.498), train_loss = 2.71923258, grad/param norm = 4.5262e-01, time/batch = 0.6313s	
327/32750 (epoch 0.499), train_loss = 2.83123625, grad/param norm = 3.9362e-01, time/batch = 0.6292s	
328/32750 (epoch 0.501), train_loss = 2.87883439, grad/param norm = 3.4056e-01, time/batch = 0.6365s	
329/32750 (epoch 0.502), train_loss = 2.78914775, grad/param norm = 6.6179e-01, time/batch = 0.6316s	
330/32750 (epoch 0.504), train_loss = 2.79816953, grad/param norm = 5.8315e-01, time/batch = 0.6309s	
331/32750 (epoch 0.505), train_loss = 2.71108522, grad/param norm = 4.2423e-01, time/batch = 0.6324s	
332/32750 (epoch 0.507), train_loss = 2.69197869, grad/param norm = 5.0112e-01, time/batch = 0.6335s	
333/32750 (epoch 0.508), train_loss = 2.65184593, grad/param norm = 7.6019e-01, time/batch = 0.6359s	
334/32750 (epoch 0.510), train_loss = 2.69886042, grad/param norm = 8.1993e-01, time/batch = 0.6354s	
335/32750 (epoch 0.511), train_loss = 2.61197676, grad/param norm = 5.8194e-01, time/batch = 0.6415s	
336/32750 (epoch 0.513), train_loss = 2.57110088, grad/param norm = 6.5786e-01, time/batch = 0.6465s	
337/32750 (epoch 0.515), train_loss = 2.80152148, grad/param norm = 6.6969e-01, time/batch = 0.6366s	
338/32750 (epoch 0.516), train_loss = 2.75404044, grad/param norm = 7.2205e-01, time/batch = 0.6339s	
339/32750 (epoch 0.518), train_loss = 2.67895212, grad/param norm = 4.0078e-01, time/batch = 0.6327s	
340/32750 (epoch 0.519), train_loss = 2.74104836, grad/param norm = 3.4096e-01, time/batch = 0.6322s	
341/32750 (epoch 0.521), train_loss = 2.52552163, grad/param norm = 3.3524e-01, time/batch = 0.6337s	
342/32750 (epoch 0.522), train_loss = 2.67981657, grad/param norm = 5.2395e-01, time/batch = 0.6344s	
343/32750 (epoch 0.524), train_loss = 2.58674480, grad/param norm = 7.2861e-01, time/batch = 0.6326s	
344/32750 (epoch 0.525), train_loss = 2.63903595, grad/param norm = 6.0924e-01, time/batch = 0.6406s	
345/32750 (epoch 0.527), train_loss = 2.68719401, grad/param norm = 4.2764e-01, time/batch = 0.6535s	
346/32750 (epoch 0.528), train_loss = 2.60099054, grad/param norm = 4.8463e-01, time/batch = 0.6724s	
347/32750 (epoch 0.530), train_loss = 2.76294173, grad/param norm = 5.3194e-01, time/batch = 0.6342s	
348/32750 (epoch 0.531), train_loss = 2.60301433, grad/param norm = 4.9257e-01, time/batch = 0.6324s	
349/32750 (epoch 0.533), train_loss = 2.62230266, grad/param norm = 5.8377e-01, time/batch = 0.6336s	
350/32750 (epoch 0.534), train_loss = 2.68362510, grad/param norm = 5.2402e-01, time/batch = 0.6349s	
351/32750 (epoch 0.536), train_loss = 2.48796446, grad/param norm = 3.0236e-01, time/batch = 0.6353s	
352/32750 (epoch 0.537), train_loss = 2.56995175, grad/param norm = 4.2527e-01, time/batch = 0.6345s	
353/32750 (epoch 0.539), train_loss = 2.71038686, grad/param norm = 3.8792e-01, time/batch = 0.6327s	
354/32750 (epoch 0.540), train_loss = 2.60562463, grad/param norm = 3.1685e-01, time/batch = 0.6350s	
355/32750 (epoch 0.542), train_loss = 2.68687773, grad/param norm = 5.2496e-01, time/batch = 0.6331s	
356/32750 (epoch 0.544), train_loss = 2.73331292, grad/param norm = 7.3507e-01, time/batch = 0.6325s	
357/32750 (epoch 0.545), train_loss = 2.58717150, grad/param norm = 3.6043e-01, time/batch = 0.6326s	
358/32750 (epoch 0.547), train_loss = 2.57924705, grad/param norm = 3.1713e-01, time/batch = 0.6326s	
359/32750 (epoch 0.548), train_loss = 2.67224794, grad/param norm = 4.5545e-01, time/batch = 0.6487s	
360/32750 (epoch 0.550), train_loss = 2.71477798, grad/param norm = 5.3056e-01, time/batch = 0.6437s	
361/32750 (epoch 0.551), train_loss = 2.62315136, grad/param norm = 5.9301e-01, time/batch = 0.6575s	
362/32750 (epoch 0.553), train_loss = 2.63814190, grad/param norm = 7.5065e-01, time/batch = 0.6578s	
363/32750 (epoch 0.554), train_loss = 2.64460789, grad/param norm = 8.7506e-01, time/batch = 0.6490s	
364/32750 (epoch 0.556), train_loss = 2.71451566, grad/param norm = 7.3160e-01, time/batch = 0.6332s	
365/32750 (epoch 0.557), train_loss = 2.65923631, grad/param norm = 5.0752e-01, time/batch = 0.6360s	
366/32750 (epoch 0.559), train_loss = 2.60886774, grad/param norm = 3.3717e-01, time/batch = 0.6518s	
367/32750 (epoch 0.560), train_loss = 2.54733108, grad/param norm = 3.7884e-01, time/batch = 0.6386s	
368/32750 (epoch 0.562), train_loss = 2.58948793, grad/param norm = 4.2205e-01, time/batch = 0.6376s	
369/32750 (epoch 0.563), train_loss = 2.62409838, grad/param norm = 3.5034e-01, time/batch = 0.6351s	
370/32750 (epoch 0.565), train_loss = 2.61788373, grad/param norm = 3.4393e-01, time/batch = 0.6332s	
371/32750 (epoch 0.566), train_loss = 2.61253521, grad/param norm = 2.8090e-01, time/batch = 0.6341s	
372/32750 (epoch 0.568), train_loss = 2.66347989, grad/param norm = 3.1684e-01, time/batch = 0.6339s	
373/32750 (epoch 0.569), train_loss = 2.66978836, grad/param norm = 3.3573e-01, time/batch = 0.6358s	
374/32750 (epoch 0.571), train_loss = 2.54938525, grad/param norm = 4.4442e-01, time/batch = 0.6341s	
375/32750 (epoch 0.573), train_loss = 2.62431600, grad/param norm = 7.2042e-01, time/batch = 0.6379s	
376/32750 (epoch 0.574), train_loss = 2.68760133, grad/param norm = 8.7490e-01, time/batch = 0.6379s	
377/32750 (epoch 0.576), train_loss = 2.58568533, grad/param norm = 6.6235e-01, time/batch = 0.6350s	
378/32750 (epoch 0.577), train_loss = 2.73375484, grad/param norm = 5.7094e-01, time/batch = 0.6422s	
379/32750 (epoch 0.579), train_loss = 2.53167673, grad/param norm = 4.8077e-01, time/batch = 0.6361s	
380/32750 (epoch 0.580), train_loss = 2.61192128, grad/param norm = 3.7652e-01, time/batch = 0.6343s	
381/32750 (epoch 0.582), train_loss = 2.61241364, grad/param norm = 4.1176e-01, time/batch = 0.6368s	
382/32750 (epoch 0.583), train_loss = 2.63058474, grad/param norm = 5.4247e-01, time/batch = 0.6371s	
383/32750 (epoch 0.585), train_loss = 2.58784090, grad/param norm = 5.3558e-01, time/batch = 0.6362s	
384/32750 (epoch 0.586), train_loss = 2.73348296, grad/param norm = 4.6515e-01, time/batch = 0.6363s	
385/32750 (epoch 0.588), train_loss = 2.63046044, grad/param norm = 4.1690e-01, time/batch = 0.6340s	
386/32750 (epoch 0.589), train_loss = 2.60451557, grad/param norm = 3.3723e-01, time/batch = 0.6323s	
387/32750 (epoch 0.591), train_loss = 2.68131493, grad/param norm = 3.9878e-01, time/batch = 0.6350s	
388/32750 (epoch 0.592), train_loss = 2.54739451, grad/param norm = 3.3846e-01, time/batch = 0.6328s	
389/32750 (epoch 0.594), train_loss = 2.51775114, grad/param norm = 4.4635e-01, time/batch = 0.6322s	
390/32750 (epoch 0.595), train_loss = 2.58566091, grad/param norm = 5.5003e-01, time/batch = 0.6319s	
391/32750 (epoch 0.597), train_loss = 2.55472822, grad/param norm = 4.5822e-01, time/batch = 0.6349s	
392/32750 (epoch 0.598), train_loss = 2.44687118, grad/param norm = 5.2975e-01, time/batch = 0.6359s	
393/32750 (epoch 0.600), train_loss = 2.74788722, grad/param norm = 6.6130e-01, time/batch = 0.6348s	
394/32750 (epoch 0.602), train_loss = 2.90880867, grad/param norm = 6.1103e-01, time/batch = 0.6337s	
395/32750 (epoch 0.603), train_loss = 3.20255388, grad/param norm = 6.9855e-01, time/batch = 0.6348s	
396/32750 (epoch 0.605), train_loss = 2.84908015, grad/param norm = 2.0344e+00, time/batch = 0.6395s	
397/32750 (epoch 0.606), train_loss = 2.59406489, grad/param norm = 5.3221e-01, time/batch = 0.6348s	
398/32750 (epoch 0.608), train_loss = 2.72711748, grad/param norm = 6.6749e-01, time/batch = 0.6338s	
399/32750 (epoch 0.609), train_loss = 2.58551532, grad/param norm = 7.8508e-01, time/batch = 0.6333s	
400/32750 (epoch 0.611), train_loss = 2.65619685, grad/param norm = 6.0405e-01, time/batch = 0.6326s	
401/32750 (epoch 0.612), train_loss = 2.48811539, grad/param norm = 3.4362e-01, time/batch = 0.6348s	
402/32750 (epoch 0.614), train_loss = 2.49690633, grad/param norm = 3.1553e-01, time/batch = 0.6344s	
403/32750 (epoch 0.615), train_loss = 2.62710403, grad/param norm = 3.0226e-01, time/batch = 0.6329s	
404/32750 (epoch 0.617), train_loss = 2.55605030, grad/param norm = 3.0104e-01, time/batch = 0.6342s	
405/32750 (epoch 0.618), train_loss = 2.53224389, grad/param norm = 3.4202e-01, time/batch = 0.6389s	
406/32750 (epoch 0.620), train_loss = 2.52969315, grad/param norm = 3.7318e-01, time/batch = 0.6544s	
407/32750 (epoch 0.621), train_loss = 2.62366863, grad/param norm = 5.8022e-01, time/batch = 0.6377s	
408/32750 (epoch 0.623), train_loss = 2.58573535, grad/param norm = 6.1876e-01, time/batch = 0.6737s	
409/32750 (epoch 0.624), train_loss = 2.71378093, grad/param norm = 4.1213e-01, time/batch = 0.6515s	
410/32750 (epoch 0.626), train_loss = 2.62113771, grad/param norm = 2.4636e-01, time/batch = 0.6453s	
411/32750 (epoch 0.627), train_loss = 2.74047904, grad/param norm = 3.5786e-01, time/batch = 0.6361s	
412/32750 (epoch 0.629), train_loss = 2.53448172, grad/param norm = 3.8702e-01, time/batch = 0.6474s	
413/32750 (epoch 0.631), train_loss = 2.71968347, grad/param norm = 4.3427e-01, time/batch = 0.6370s	
414/32750 (epoch 0.632), train_loss = 2.56258568, grad/param norm = 3.9089e-01, time/batch = 0.6347s	
415/32750 (epoch 0.634), train_loss = 2.67591804, grad/param norm = 3.8033e-01, time/batch = 0.6348s	
416/32750 (epoch 0.635), train_loss = 2.51242826, grad/param norm = 5.2064e-01, time/batch = 0.6343s	
417/32750 (epoch 0.637), train_loss = 2.77783820, grad/param norm = 5.6943e-01, time/batch = 0.6332s	
418/32750 (epoch 0.638), train_loss = 2.57929931, grad/param norm = 3.8769e-01, time/batch = 0.6331s	
419/32750 (epoch 0.640), train_loss = 2.59600535, grad/param norm = 3.4116e-01, time/batch = 0.6320s	
420/32750 (epoch 0.641), train_loss = 2.53137877, grad/param norm = 3.6558e-01, time/batch = 0.6340s	
421/32750 (epoch 0.643), train_loss = 2.52939274, grad/param norm = 3.1792e-01, time/batch = 0.6358s	
422/32750 (epoch 0.644), train_loss = 2.45909891, grad/param norm = 3.1261e-01, time/batch = 0.6361s	
423/32750 (epoch 0.646), train_loss = 2.46932908, grad/param norm = 5.7995e-01, time/batch = 0.6336s	
424/32750 (epoch 0.647), train_loss = 2.66846506, grad/param norm = 6.7672e-01, time/batch = 0.6337s	
425/32750 (epoch 0.649), train_loss = 2.58758783, grad/param norm = 4.2524e-01, time/batch = 0.6372s	
426/32750 (epoch 0.650), train_loss = 2.71399159, grad/param norm = 4.6857e-01, time/batch = 0.6333s	
427/32750 (epoch 0.652), train_loss = 2.50490210, grad/param norm = 5.9053e-01, time/batch = 0.6312s	
428/32750 (epoch 0.653), train_loss = 2.49203228, grad/param norm = 5.8185e-01, time/batch = 0.6329s	
429/32750 (epoch 0.655), train_loss = 2.70981791, grad/param norm = 3.5063e-01, time/batch = 0.6348s	
430/32750 (epoch 0.656), train_loss = 2.52724821, grad/param norm = 3.6222e-01, time/batch = 0.6309s	
431/32750 (epoch 0.658), train_loss = 2.61800327, grad/param norm = 3.5758e-01, time/batch = 0.6334s	
432/32750 (epoch 0.660), train_loss = 2.59353102, grad/param norm = 3.5849e-01, time/batch = 0.6335s	
433/32750 (epoch 0.661), train_loss = 2.64512496, grad/param norm = 3.3145e-01, time/batch = 0.6323s	
434/32750 (epoch 0.663), train_loss = 2.52309653, grad/param norm = 2.4836e-01, time/batch = 0.6381s	
435/32750 (epoch 0.664), train_loss = 2.58702889, grad/param norm = 4.9160e-01, time/batch = 0.6313s	
436/32750 (epoch 0.666), train_loss = 2.68316865, grad/param norm = 5.3164e-01, time/batch = 0.6320s	
437/32750 (epoch 0.667), train_loss = 2.61461340, grad/param norm = 5.0406e-01, time/batch = 0.6324s	
438/32750 (epoch 0.669), train_loss = 2.59805577, grad/param norm = 5.6663e-01, time/batch = 0.6335s	
439/32750 (epoch 0.670), train_loss = 2.63207706, grad/param norm = 4.9996e-01, time/batch = 0.6335s	
440/32750 (epoch 0.672), train_loss = 2.48111228, grad/param norm = 4.2861e-01, time/batch = 0.6331s	
441/32750 (epoch 0.673), train_loss = 2.56879391, grad/param norm = 3.8302e-01, time/batch = 0.6330s	
442/32750 (epoch 0.675), train_loss = 2.55375504, grad/param norm = 3.6429e-01, time/batch = 0.6332s	
443/32750 (epoch 0.676), train_loss = 2.54645824, grad/param norm = 3.3601e-01, time/batch = 0.6363s	
444/32750 (epoch 0.678), train_loss = 2.59337698, grad/param norm = 3.8045e-01, time/batch = 0.6736s	
445/32750 (epoch 0.679), train_loss = 2.56119022, grad/param norm = 4.2785e-01, time/batch = 0.6488s	
446/32750 (epoch 0.681), train_loss = 2.59048579, grad/param norm = 3.2923e-01, time/batch = 0.6363s	
447/32750 (epoch 0.682), train_loss = 2.56732914, grad/param norm = 3.6312e-01, time/batch = 0.6310s	
448/32750 (epoch 0.684), train_loss = 2.61267283, grad/param norm = 3.5236e-01, time/batch = 0.6320s	
449/32750 (epoch 0.685), train_loss = 2.60022619, grad/param norm = 3.8317e-01, time/batch = 0.6336s	
450/32750 (epoch 0.687), train_loss = 2.44513820, grad/param norm = 3.7045e-01, time/batch = 0.6331s	
451/32750 (epoch 0.689), train_loss = 2.61710064, grad/param norm = 4.0719e-01, time/batch = 0.6344s	
452/32750 (epoch 0.690), train_loss = 2.48079227, grad/param norm = 5.0593e-01, time/batch = 0.6339s	
453/32750 (epoch 0.692), train_loss = 2.66682048, grad/param norm = 6.0314e-01, time/batch = 0.6615s	
454/32750 (epoch 0.693), train_loss = 2.51600436, grad/param norm = 4.5471e-01, time/batch = 0.6428s	
455/32750 (epoch 0.695), train_loss = 2.39292481, grad/param norm = 4.4527e-01, time/batch = 0.6809s	
456/32750 (epoch 0.696), train_loss = 2.51297392, grad/param norm = 5.2245e-01, time/batch = 0.6592s	
457/32750 (epoch 0.698), train_loss = 2.55148858, grad/param norm = 4.7561e-01, time/batch = 0.6514s	
458/32750 (epoch 0.699), train_loss = 2.54517408, grad/param norm = 3.7390e-01, time/batch = 0.6385s	
459/32750 (epoch 0.701), train_loss = 2.43473503, grad/param norm = 3.4230e-01, time/batch = 0.6335s	
460/32750 (epoch 0.702), train_loss = 2.50449377, grad/param norm = 5.1153e-01, time/batch = 0.6348s	
461/32750 (epoch 0.704), train_loss = 2.66621293, grad/param norm = 6.5725e-01, time/batch = 0.6334s	
462/32750 (epoch 0.705), train_loss = 2.70790908, grad/param norm = 5.8951e-01, time/batch = 0.6389s	
463/32750 (epoch 0.707), train_loss = 2.56137867, grad/param norm = 4.9451e-01, time/batch = 0.6308s	
464/32750 (epoch 0.708), train_loss = 2.56832352, grad/param norm = 3.8353e-01, time/batch = 0.6305s	
465/32750 (epoch 0.710), train_loss = 2.45512052, grad/param norm = 3.1148e-01, time/batch = 0.6317s	
466/32750 (epoch 0.711), train_loss = 2.58412889, grad/param norm = 3.1700e-01, time/batch = 0.6436s	
467/32750 (epoch 0.713), train_loss = 2.51364227, grad/param norm = 3.5383e-01, time/batch = 0.6390s	
468/32750 (epoch 0.715), train_loss = 2.53832712, grad/param norm = 2.9085e-01, time/batch = 0.6334s	
469/32750 (epoch 0.716), train_loss = 2.59271929, grad/param norm = 3.2184e-01, time/batch = 0.6352s	
470/32750 (epoch 0.718), train_loss = 2.52598851, grad/param norm = 3.0969e-01, time/batch = 0.6435s	
471/32750 (epoch 0.719), train_loss = 2.60103671, grad/param norm = 2.8658e-01, time/batch = 0.6390s	
472/32750 (epoch 0.721), train_loss = 2.56647391, grad/param norm = 3.2814e-01, time/batch = 0.6355s	
473/32750 (epoch 0.722), train_loss = 2.63436294, grad/param norm = 3.6192e-01, time/batch = 0.6338s	
474/32750 (epoch 0.724), train_loss = 2.55344530, grad/param norm = 3.0460e-01, time/batch = 0.6317s	
475/32750 (epoch 0.725), train_loss = 2.49452408, grad/param norm = 3.0394e-01, time/batch = 0.6340s	
476/32750 (epoch 0.727), train_loss = 2.44225527, grad/param norm = 3.5534e-01, time/batch = 0.6341s	
477/32750 (epoch 0.728), train_loss = 2.47977994, grad/param norm = 3.3713e-01, time/batch = 0.6336s	
478/32750 (epoch 0.730), train_loss = 2.35621992, grad/param norm = 4.2773e-01, time/batch = 0.6323s	
479/32750 (epoch 0.731), train_loss = 2.60176723, grad/param norm = 5.5650e-01, time/batch = 0.6350s	
480/32750 (epoch 0.733), train_loss = 2.60285261, grad/param norm = 6.8992e-01, time/batch = 0.6320s	
481/32750 (epoch 0.734), train_loss = 2.53015403, grad/param norm = 8.4734e-01, time/batch = 0.6335s	
482/32750 (epoch 0.736), train_loss = 2.58288676, grad/param norm = 5.6546e-01, time/batch = 0.6328s	
483/32750 (epoch 0.737), train_loss = 2.42495903, grad/param norm = 4.9214e-01, time/batch = 0.6314s	
484/32750 (epoch 0.739), train_loss = 2.45445248, grad/param norm = 5.1157e-01, time/batch = 0.6413s	
485/32750 (epoch 0.740), train_loss = 2.60861380, grad/param norm = 6.3365e-01, time/batch = 0.6316s	
486/32750 (epoch 0.742), train_loss = 2.53043566, grad/param norm = 4.6401e-01, time/batch = 0.6319s	
487/32750 (epoch 0.744), train_loss = 2.42201637, grad/param norm = 2.7531e-01, time/batch = 0.6336s	
488/32750 (epoch 0.745), train_loss = 2.48007926, grad/param norm = 3.5285e-01, time/batch = 0.6315s	
489/32750 (epoch 0.747), train_loss = 2.52319488, grad/param norm = 2.6888e-01, time/batch = 0.6439s	
490/32750 (epoch 0.748), train_loss = 2.44224528, grad/param norm = 2.6824e-01, time/batch = 0.6598s	
491/32750 (epoch 0.750), train_loss = 2.53789449, grad/param norm = 3.4093e-01, time/batch = 0.6774s	
492/32750 (epoch 0.751), train_loss = 2.52570954, grad/param norm = 4.3401e-01, time/batch = 0.6385s	
493/32750 (epoch 0.753), train_loss = 2.56810952, grad/param norm = 4.7688e-01, time/batch = 0.6326s	
494/32750 (epoch 0.754), train_loss = 2.60521881, grad/param norm = 3.3363e-01, time/batch = 0.6317s	
495/32750 (epoch 0.756), train_loss = 2.67816587, grad/param norm = 3.5386e-01, time/batch = 0.6332s	
496/32750 (epoch 0.757), train_loss = 2.43006031, grad/param norm = 3.7912e-01, time/batch = 0.6332s	
497/32750 (epoch 0.759), train_loss = 2.45329185, grad/param norm = 2.9710e-01, time/batch = 0.6312s	
498/32750 (epoch 0.760), train_loss = 2.56127856, grad/param norm = 3.3441e-01, time/batch = 0.6328s	
499/32750 (epoch 0.762), train_loss = 2.55662860, grad/param norm = 4.0768e-01, time/batch = 0.6347s	
500/32750 (epoch 0.763), train_loss = 2.47280381, grad/param norm = 3.9896e-01, time/batch = 0.6391s	
501/32750 (epoch 0.765), train_loss = 2.51407780, grad/param norm = 3.1024e-01, time/batch = 0.6343s	
502/32750 (epoch 0.766), train_loss = 2.59461961, grad/param norm = 2.9089e-01, time/batch = 0.6331s	
503/32750 (epoch 0.768), train_loss = 2.56266239, grad/param norm = 3.3195e-01, time/batch = 0.6317s	
504/32750 (epoch 0.769), train_loss = 2.52603266, grad/param norm = 4.1341e-01, time/batch = 0.6357s	
505/32750 (epoch 0.771), train_loss = 2.54267267, grad/param norm = 3.2344e-01, time/batch = 0.6368s	
506/32750 (epoch 0.773), train_loss = 2.33305336, grad/param norm = 3.0781e-01, time/batch = 0.6642s	
507/32750 (epoch 0.774), train_loss = 2.55611398, grad/param norm = 5.1792e-01, time/batch = 0.6648s	
508/32750 (epoch 0.776), train_loss = 2.45580002, grad/param norm = 7.3957e-01, time/batch = 0.6326s	
509/32750 (epoch 0.777), train_loss = 2.49499449, grad/param norm = 5.9683e-01, time/batch = 0.6358s	
510/32750 (epoch 0.779), train_loss = 2.44884074, grad/param norm = 5.2483e-01, time/batch = 0.6347s	
511/32750 (epoch 0.780), train_loss = 2.58352370, grad/param norm = 3.6788e-01, time/batch = 0.6343s	
512/32750 (epoch 0.782), train_loss = 2.58594610, grad/param norm = 4.1598e-01, time/batch = 0.6334s	
513/32750 (epoch 0.783), train_loss = 2.45154713, grad/param norm = 4.4509e-01, time/batch = 0.6336s	
514/32750 (epoch 0.785), train_loss = 2.40399394, grad/param norm = 2.5270e-01, time/batch = 0.6340s	
515/32750 (epoch 0.786), train_loss = 2.49344335, grad/param norm = 2.5711e-01, time/batch = 0.6329s	
516/32750 (epoch 0.788), train_loss = 2.57174440, grad/param norm = 3.1344e-01, time/batch = 0.6413s	
517/32750 (epoch 0.789), train_loss = 2.56400584, grad/param norm = 3.6133e-01, time/batch = 0.6583s	
518/32750 (epoch 0.791), train_loss = 2.50752339, grad/param norm = 2.7631e-01, time/batch = 0.6590s	
519/32750 (epoch 0.792), train_loss = 2.38159376, grad/param norm = 2.4398e-01, time/batch = 0.6525s	
520/32750 (epoch 0.794), train_loss = 2.49823384, grad/param norm = 2.6452e-01, time/batch = 0.6341s	
521/32750 (epoch 0.795), train_loss = 2.57925312, grad/param norm = 3.6045e-01, time/batch = 0.6421s	
522/32750 (epoch 0.797), train_loss = 2.42604673, grad/param norm = 5.8836e-01, time/batch = 0.6448s	
523/32750 (epoch 0.798), train_loss = 2.59175480, grad/param norm = 5.8705e-01, time/batch = 0.6336s	
524/32750 (epoch 0.800), train_loss = 2.44338097, grad/param norm = 4.6428e-01, time/batch = 0.6328s	
525/32750 (epoch 0.802), train_loss = 2.54444294, grad/param norm = 3.2742e-01, time/batch = 0.6310s	
526/32750 (epoch 0.803), train_loss = 2.55420687, grad/param norm = 3.0815e-01, time/batch = 0.6351s	
527/32750 (epoch 0.805), train_loss = 2.52744522, grad/param norm = 4.3303e-01, time/batch = 0.6322s	
528/32750 (epoch 0.806), train_loss = 2.53471465, grad/param norm = 3.6148e-01, time/batch = 0.6315s	
529/32750 (epoch 0.808), train_loss = 2.57738946, grad/param norm = 3.3998e-01, time/batch = 0.6332s	
530/32750 (epoch 0.809), train_loss = 2.51259650, grad/param norm = 3.3864e-01, time/batch = 0.6339s	
531/32750 (epoch 0.811), train_loss = 2.59803715, grad/param norm = 3.4196e-01, time/batch = 0.6379s	
532/32750 (epoch 0.812), train_loss = 2.42806158, grad/param norm = 3.6823e-01, time/batch = 0.6350s	
533/32750 (epoch 0.814), train_loss = 2.46667839, grad/param norm = 2.9453e-01, time/batch = 0.6318s	
534/32750 (epoch 0.815), train_loss = 2.61590404, grad/param norm = 3.3075e-01, time/batch = 0.6342s	
535/32750 (epoch 0.817), train_loss = 2.59326483, grad/param norm = 3.1872e-01, time/batch = 0.6362s	
536/32750 (epoch 0.818), train_loss = 2.36469878, grad/param norm = 3.1731e-01, time/batch = 0.6329s	
537/32750 (epoch 0.820), train_loss = 2.44722401, grad/param norm = 3.6264e-01, time/batch = 0.6354s	
538/32750 (epoch 0.821), train_loss = 2.55651881, grad/param norm = 3.2767e-01, time/batch = 0.6327s	
539/32750 (epoch 0.823), train_loss = 2.44343533, grad/param norm = 3.8832e-01, time/batch = 0.6341s	
540/32750 (epoch 0.824), train_loss = 2.50942387, grad/param norm = 4.3501e-01, time/batch = 0.6340s	
541/32750 (epoch 0.826), train_loss = 2.59875183, grad/param norm = 3.9975e-01, time/batch = 0.6328s	
542/32750 (epoch 0.827), train_loss = 2.59613419, grad/param norm = 4.5265e-01, time/batch = 0.6334s	
543/32750 (epoch 0.829), train_loss = 2.66785235, grad/param norm = 3.8358e-01, time/batch = 0.6331s	
544/32750 (epoch 0.831), train_loss = 2.27977292, grad/param norm = 3.9587e-01, time/batch = 0.6316s	
545/32750 (epoch 0.832), train_loss = 2.49934262, grad/param norm = 5.9784e-01, time/batch = 0.6328s	
546/32750 (epoch 0.834), train_loss = 2.56828261, grad/param norm = 5.0733e-01, time/batch = 0.6400s	
547/32750 (epoch 0.835), train_loss = 2.40220164, grad/param norm = 3.8725e-01, time/batch = 0.6480s	
548/32750 (epoch 0.837), train_loss = 2.56477310, grad/param norm = 3.1412e-01, time/batch = 0.6461s	
549/32750 (epoch 0.838), train_loss = 2.38957500, grad/param norm = 3.3722e-01, time/batch = 0.6366s	
550/32750 (epoch 0.840), train_loss = 2.41828740, grad/param norm = 3.5594e-01, time/batch = 0.6389s	
551/32750 (epoch 0.841), train_loss = 2.47854493, grad/param norm = 3.9383e-01, time/batch = 0.6441s	
552/32750 (epoch 0.843), train_loss = 2.49738745, grad/param norm = 3.3834e-01, time/batch = 0.6477s	
553/32750 (epoch 0.844), train_loss = 2.55016392, grad/param norm = 2.8244e-01, time/batch = 0.6747s	
554/32750 (epoch 0.846), train_loss = 2.40695012, grad/param norm = 2.9882e-01, time/batch = 0.6573s	
555/32750 (epoch 0.847), train_loss = 2.38867402, grad/param norm = 4.6769e-01, time/batch = 0.6337s	
556/32750 (epoch 0.849), train_loss = 2.49705733, grad/param norm = 5.6405e-01, time/batch = 0.6311s	
557/32750 (epoch 0.850), train_loss = 2.57954254, grad/param norm = 4.3271e-01, time/batch = 0.6331s	
558/32750 (epoch 0.852), train_loss = 2.43878014, grad/param norm = 3.3817e-01, time/batch = 0.6332s	
559/32750 (epoch 0.853), train_loss = 2.51474164, grad/param norm = 3.1040e-01, time/batch = 0.6316s	
560/32750 (epoch 0.855), train_loss = 2.50094671, grad/param norm = 2.8183e-01, time/batch = 0.6347s	
561/32750 (epoch 0.856), train_loss = 2.44237205, grad/param norm = 3.4185e-01, time/batch = 0.6504s	
562/32750 (epoch 0.858), train_loss = 2.47549136, grad/param norm = 4.3472e-01, time/batch = 0.6444s	
563/32750 (epoch 0.860), train_loss = 2.38937167, grad/param norm = 3.4983e-01, time/batch = 0.6346s	
564/32750 (epoch 0.861), train_loss = 2.40238841, grad/param norm = 3.0393e-01, time/batch = 0.6314s	
565/32750 (epoch 0.863), train_loss = 2.62463731, grad/param norm = 2.7442e-01, time/batch = 0.6317s	
566/32750 (epoch 0.864), train_loss = 2.48579124, grad/param norm = 3.2315e-01, time/batch = 0.6338s	
567/32750 (epoch 0.866), train_loss = 2.37904811, grad/param norm = 4.0616e-01, time/batch = 0.6311s	
568/32750 (epoch 0.867), train_loss = 2.38059086, grad/param norm = 4.2376e-01, time/batch = 0.6458s	
569/32750 (epoch 0.869), train_loss = 2.51225152, grad/param norm = 4.9960e-01, time/batch = 0.6731s	
570/32750 (epoch 0.870), train_loss = 2.43606722, grad/param norm = 4.0661e-01, time/batch = 0.6389s	
571/32750 (epoch 0.872), train_loss = 2.49538269, grad/param norm = 3.3570e-01, time/batch = 0.6356s	
572/32750 (epoch 0.873), train_loss = 2.41717811, grad/param norm = 3.4387e-01, time/batch = 0.6568s	
573/32750 (epoch 0.875), train_loss = 2.59583837, grad/param norm = 3.8373e-01, time/batch = 0.6486s	
574/32750 (epoch 0.876), train_loss = 2.58891394, grad/param norm = 3.7354e-01, time/batch = 0.6455s	
575/32750 (epoch 0.878), train_loss = 2.32503097, grad/param norm = 2.8178e-01, time/batch = 0.6393s	
576/32750 (epoch 0.879), train_loss = 2.45856837, grad/param norm = 3.3144e-01, time/batch = 0.6367s	
577/32750 (epoch 0.881), train_loss = 2.52910370, grad/param norm = 5.0102e-01, time/batch = 0.6321s	
578/32750 (epoch 0.882), train_loss = 2.36728441, grad/param norm = 5.5759e-01, time/batch = 0.6371s	
579/32750 (epoch 0.884), train_loss = 2.55638524, grad/param norm = 5.5970e-01, time/batch = 0.6376s	
580/32750 (epoch 0.885), train_loss = 2.47743387, grad/param norm = 4.1836e-01, time/batch = 0.6329s	
581/32750 (epoch 0.887), train_loss = 2.59771848, grad/param norm = 3.5301e-01, time/batch = 0.6335s	
582/32750 (epoch 0.889), train_loss = 2.48413760, grad/param norm = 2.8798e-01, time/batch = 0.6366s	
583/32750 (epoch 0.890), train_loss = 2.44162338, grad/param norm = 2.7579e-01, time/batch = 0.6400s	
584/32750 (epoch 0.892), train_loss = 2.58571246, grad/param norm = 2.8011e-01, time/batch = 0.6688s	
585/32750 (epoch 0.893), train_loss = 2.58057701, grad/param norm = 3.7001e-01, time/batch = 0.6603s	
586/32750 (epoch 0.895), train_loss = 2.40807296, grad/param norm = 3.1437e-01, time/batch = 0.6334s	
587/32750 (epoch 0.896), train_loss = 2.41691401, grad/param norm = 3.2600e-01, time/batch = 0.6316s	
588/32750 (epoch 0.898), train_loss = 2.53797848, grad/param norm = 3.1397e-01, time/batch = 0.6388s	
589/32750 (epoch 0.899), train_loss = 2.53026704, grad/param norm = 3.3362e-01, time/batch = 0.6421s	
590/32750 (epoch 0.901), train_loss = 2.51144960, grad/param norm = 4.1611e-01, time/batch = 0.6458s	
591/32750 (epoch 0.902), train_loss = 2.45518515, grad/param norm = 3.6804e-01, time/batch = 0.6338s	
592/32750 (epoch 0.904), train_loss = 2.39709833, grad/param norm = 2.8042e-01, time/batch = 0.6421s	
593/32750 (epoch 0.905), train_loss = 2.52269586, grad/param norm = 2.8977e-01, time/batch = 0.6529s	
594/32750 (epoch 0.907), train_loss = 2.63303564, grad/param norm = 3.0590e-01, time/batch = 0.6482s	
595/32750 (epoch 0.908), train_loss = 2.54427805, grad/param norm = 2.4776e-01, time/batch = 0.6417s	
596/32750 (epoch 0.910), train_loss = 2.37937053, grad/param norm = 3.5523e-01, time/batch = 0.6514s	
597/32750 (epoch 0.911), train_loss = 2.40858304, grad/param norm = 2.7707e-01, time/batch = 0.6433s	
598/32750 (epoch 0.913), train_loss = 2.35700052, grad/param norm = 2.3785e-01, time/batch = 0.6483s	
599/32750 (epoch 0.915), train_loss = 2.33087045, grad/param norm = 3.0078e-01, time/batch = 0.6476s	
600/32750 (epoch 0.916), train_loss = 2.47567945, grad/param norm = 3.0593e-01, time/batch = 0.6457s	
601/32750 (epoch 0.918), train_loss = 2.61646943, grad/param norm = 4.4585e-01, time/batch = 0.6497s	
602/32750 (epoch 0.919), train_loss = 2.59626760, grad/param norm = 4.5579e-01, time/batch = 0.6493s	
603/32750 (epoch 0.921), train_loss = 2.51509529, grad/param norm = 4.0900e-01, time/batch = 0.6467s	
604/32750 (epoch 0.922), train_loss = 2.41514380, grad/param norm = 3.7287e-01, time/batch = 0.6444s	
605/32750 (epoch 0.924), train_loss = 2.44604817, grad/param norm = 3.7182e-01, time/batch = 0.6488s	
606/32750 (epoch 0.925), train_loss = 2.42084971, grad/param norm = 3.4029e-01, time/batch = 0.6435s	
607/32750 (epoch 0.927), train_loss = 2.49260575, grad/param norm = 3.9373e-01, time/batch = 0.6497s	
608/32750 (epoch 0.928), train_loss = 2.52800260, grad/param norm = 3.2554e-01, time/batch = 0.6437s	
609/32750 (epoch 0.930), train_loss = 2.41759743, grad/param norm = 3.1808e-01, time/batch = 0.6457s	
610/32750 (epoch 0.931), train_loss = 2.40938820, grad/param norm = 2.6140e-01, time/batch = 0.6693s	
611/32750 (epoch 0.933), train_loss = 2.50472139, grad/param norm = 2.7227e-01, time/batch = 0.6661s	
612/32750 (epoch 0.934), train_loss = 2.38068219, grad/param norm = 2.7377e-01, time/batch = 0.6311s	
613/32750 (epoch 0.936), train_loss = 2.54049391, grad/param norm = 3.5705e-01, time/batch = 0.6344s	
614/32750 (epoch 0.937), train_loss = 2.49083605, grad/param norm = 3.1609e-01, time/batch = 0.6328s	
615/32750 (epoch 0.939), train_loss = 2.47725679, grad/param norm = 2.8128e-01, time/batch = 0.6341s	
616/32750 (epoch 0.940), train_loss = 2.45699881, grad/param norm = 2.7497e-01, time/batch = 0.6343s	
617/32750 (epoch 0.942), train_loss = 2.34177050, grad/param norm = 2.8490e-01, time/batch = 0.6346s	
618/32750 (epoch 0.944), train_loss = 2.44786884, grad/param norm = 3.0922e-01, time/batch = 0.6379s	
619/32750 (epoch 0.945), train_loss = 2.39897396, grad/param norm = 3.4906e-01, time/batch = 0.6341s	
620/32750 (epoch 0.947), train_loss = 2.48492877, grad/param norm = 3.5458e-01, time/batch = 0.6327s	
621/32750 (epoch 0.948), train_loss = 2.44192489, grad/param norm = 3.8258e-01, time/batch = 0.6343s	
622/32750 (epoch 0.950), train_loss = 2.45539680, grad/param norm = 3.4999e-01, time/batch = 0.6339s	
623/32750 (epoch 0.951), train_loss = 2.37607211, grad/param norm = 2.8185e-01, time/batch = 0.6336s	
624/32750 (epoch 0.953), train_loss = 2.32674291, grad/param norm = 3.2432e-01, time/batch = 0.6371s	
625/32750 (epoch 0.954), train_loss = 2.46279433, grad/param norm = 2.5160e-01, time/batch = 0.6427s	
626/32750 (epoch 0.956), train_loss = 2.47653363, grad/param norm = 3.0908e-01, time/batch = 0.6731s	
627/32750 (epoch 0.957), train_loss = 2.44717385, grad/param norm = 4.4548e-01, time/batch = 0.6624s	
628/32750 (epoch 0.959), train_loss = 2.40447952, grad/param norm = 5.8703e-01, time/batch = 0.6544s	
629/32750 (epoch 0.960), train_loss = 2.45721880, grad/param norm = 6.1869e-01, time/batch = 0.6332s	
630/32750 (epoch 0.962), train_loss = 2.38368705, grad/param norm = 4.4541e-01, time/batch = 0.6361s	
631/32750 (epoch 0.963), train_loss = 2.47365166, grad/param norm = 3.1968e-01, time/batch = 0.6366s	
632/32750 (epoch 0.965), train_loss = 2.45065947, grad/param norm = 2.4486e-01, time/batch = 0.6362s	
633/32750 (epoch 0.966), train_loss = 2.46264527, grad/param norm = 2.6136e-01, time/batch = 0.6386s	
634/32750 (epoch 0.968), train_loss = 2.29586784, grad/param norm = 3.0956e-01, time/batch = 0.6339s	
635/32750 (epoch 0.969), train_loss = 2.32282630, grad/param norm = 2.4066e-01, time/batch = 0.6389s	
636/32750 (epoch 0.971), train_loss = 2.41971122, grad/param norm = 3.1529e-01, time/batch = 0.6342s	
637/32750 (epoch 0.973), train_loss = 2.46473337, grad/param norm = 3.2428e-01, time/batch = 0.6334s	
638/32750 (epoch 0.974), train_loss = 2.40285469, grad/param norm = 2.5805e-01, time/batch = 0.6346s	
639/32750 (epoch 0.976), train_loss = 2.40230988, grad/param norm = 2.5516e-01, time/batch = 0.6431s	
640/32750 (epoch 0.977), train_loss = 2.55255351, grad/param norm = 3.7551e-01, time/batch = 0.6521s	
641/32750 (epoch 0.979), train_loss = 2.40794193, grad/param norm = 4.5312e-01, time/batch = 0.6706s	
642/32750 (epoch 0.980), train_loss = 2.46863146, grad/param norm = 3.2564e-01, time/batch = 0.6690s	
643/32750 (epoch 0.982), train_loss = 2.45068483, grad/param norm = 2.6933e-01, time/batch = 0.6334s	
644/32750 (epoch 0.983), train_loss = 2.40624623, grad/param norm = 3.0451e-01, time/batch = 0.6419s	
645/32750 (epoch 0.985), train_loss = 2.30628257, grad/param norm = 3.0734e-01, time/batch = 0.6319s	
646/32750 (epoch 0.986), train_loss = 2.29309599, grad/param norm = 2.9751e-01, time/batch = 0.6331s	
647/32750 (epoch 0.988), train_loss = 2.40530555, grad/param norm = 3.4280e-01, time/batch = 0.6362s	
648/32750 (epoch 0.989), train_loss = 2.46336292, grad/param norm = 3.9968e-01, time/batch = 0.6486s	
649/32750 (epoch 0.991), train_loss = 2.48040536, grad/param norm = 3.2619e-01, time/batch = 0.6470s	
650/32750 (epoch 0.992), train_loss = 2.35027514, grad/param norm = 4.4475e-01, time/batch = 0.6413s	
651/32750 (epoch 0.994), train_loss = 2.50150754, grad/param norm = 3.4313e-01, time/batch = 0.6303s	
652/32750 (epoch 0.995), train_loss = 2.46537799, grad/param norm = 2.7176e-01, time/batch = 0.6310s	
653/32750 (epoch 0.997), train_loss = 2.49276376, grad/param norm = 3.1774e-01, time/batch = 0.6322s	
654/32750 (epoch 0.998), train_loss = 2.44866179, grad/param norm = 3.1321e-01, time/batch = 0.6319s	
655/32750 (epoch 1.000), train_loss = 2.32494928, grad/param norm = 2.7514e-01, time/batch = 0.6337s	
656/32750 (epoch 1.002), train_loss = 2.46343277, grad/param norm = 3.4615e-01, time/batch = 0.6390s	
657/32750 (epoch 1.003), train_loss = 2.39981418, grad/param norm = 3.6796e-01, time/batch = 0.6730s	
658/32750 (epoch 1.005), train_loss = 2.48699544, grad/param norm = 3.3007e-01, time/batch = 0.6484s	
659/32750 (epoch 1.006), train_loss = 2.52809820, grad/param norm = 3.7661e-01, time/batch = 0.6431s	
660/32750 (epoch 1.008), train_loss = 2.52502099, grad/param norm = 2.9617e-01, time/batch = 0.6583s	
661/32750 (epoch 1.009), train_loss = 2.38008291, grad/param norm = 2.7105e-01, time/batch = 0.6703s	
662/32750 (epoch 1.011), train_loss = 2.29845727, grad/param norm = 3.3379e-01, time/batch = 0.6683s	
663/32750 (epoch 1.012), train_loss = 2.49514335, grad/param norm = 4.0705e-01, time/batch = 0.6652s	
664/32750 (epoch 1.014), train_loss = 2.59119347, grad/param norm = 3.3113e-01, time/batch = 0.6551s	
665/32750 (epoch 1.015), train_loss = 2.48902475, grad/param norm = 3.2155e-01, time/batch = 0.6421s	
666/32750 (epoch 1.017), train_loss = 2.32129085, grad/param norm = 3.3871e-01, time/batch = 0.6413s	
667/32750 (epoch 1.018), train_loss = 2.42175668, grad/param norm = 3.0764e-01, time/batch = 0.6411s	
668/32750 (epoch 1.020), train_loss = 2.44628324, grad/param norm = 2.8421e-01, time/batch = 0.6342s	
669/32750 (epoch 1.021), train_loss = 2.37708828, grad/param norm = 3.8295e-01, time/batch = 0.6406s	
670/32750 (epoch 1.023), train_loss = 2.26259122, grad/param norm = 3.3801e-01, time/batch = 0.6368s	
671/32750 (epoch 1.024), train_loss = 2.49016440, grad/param norm = 3.3835e-01, time/batch = 0.6360s	
672/32750 (epoch 1.026), train_loss = 2.34890568, grad/param norm = 4.0278e-01, time/batch = 0.6670s	
673/32750 (epoch 1.027), train_loss = 2.48999594, grad/param norm = 3.7774e-01, time/batch = 0.6605s	
674/32750 (epoch 1.029), train_loss = 2.39197930, grad/param norm = 3.4415e-01, time/batch = 0.6327s	
675/32750 (epoch 1.031), train_loss = 2.39110375, grad/param norm = 3.0355e-01, time/batch = 0.6319s	
676/32750 (epoch 1.032), train_loss = 2.40606228, grad/param norm = 3.4433e-01, time/batch = 0.6378s	
677/32750 (epoch 1.034), train_loss = 2.44081217, grad/param norm = 3.4688e-01, time/batch = 0.6334s	
678/32750 (epoch 1.035), train_loss = 2.24827975, grad/param norm = 2.5663e-01, time/batch = 0.6344s	
679/32750 (epoch 1.037), train_loss = 2.38964748, grad/param norm = 3.0707e-01, time/batch = 0.6307s	
680/32750 (epoch 1.038), train_loss = 2.45253522, grad/param norm = 2.9284e-01, time/batch = 0.6309s	
681/32750 (epoch 1.040), train_loss = 2.47849787, grad/param norm = 2.9803e-01, time/batch = 0.6334s	
682/32750 (epoch 1.041), train_loss = 2.49809785, grad/param norm = 3.9172e-01, time/batch = 0.6333s	
683/32750 (epoch 1.043), train_loss = 2.38589128, grad/param norm = 3.5147e-01, time/batch = 0.6313s	
684/32750 (epoch 1.044), train_loss = 2.32140816, grad/param norm = 3.4667e-01, time/batch = 0.6302s	
685/32750 (epoch 1.046), train_loss = 2.40354817, grad/param norm = 3.7238e-01, time/batch = 0.6306s	
686/32750 (epoch 1.047), train_loss = 2.31991275, grad/param norm = 3.9946e-01, time/batch = 0.6389s	
687/32750 (epoch 1.049), train_loss = 2.35155731, grad/param norm = 2.8887e-01, time/batch = 0.6374s	
688/32750 (epoch 1.050), train_loss = 2.20162679, grad/param norm = 2.7807e-01, time/batch = 0.6728s	
689/32750 (epoch 1.052), train_loss = 2.27049132, grad/param norm = 3.2894e-01, time/batch = 0.6472s	
690/32750 (epoch 1.053), train_loss = 2.40549993, grad/param norm = 2.7132e-01, time/batch = 0.6316s	
691/32750 (epoch 1.055), train_loss = 2.43459068, grad/param norm = 2.9576e-01, time/batch = 0.6345s	
692/32750 (epoch 1.056), train_loss = 2.45751720, grad/param norm = 3.6815e-01, time/batch = 0.6378s	
693/32750 (epoch 1.058), train_loss = 2.28545887, grad/param norm = 2.9869e-01, time/batch = 0.6349s	
694/32750 (epoch 1.060), train_loss = 2.30225068, grad/param norm = 3.4892e-01, time/batch = 0.6482s	
695/32750 (epoch 1.061), train_loss = 2.46513621, grad/param norm = 3.0620e-01, time/batch = 0.6552s	
696/32750 (epoch 1.063), train_loss = 2.40566939, grad/param norm = 2.9809e-01, time/batch = 0.6371s	
697/32750 (epoch 1.064), train_loss = 2.37604194, grad/param norm = 3.0071e-01, time/batch = 0.6465s	
698/32750 (epoch 1.066), train_loss = 2.25826997, grad/param norm = 3.4553e-01, time/batch = 0.6511s	
699/32750 (epoch 1.067), train_loss = 2.37498561, grad/param norm = 3.6056e-01, time/batch = 0.6727s	
700/32750 (epoch 1.069), train_loss = 2.56969813, grad/param norm = 2.9593e-01, time/batch = 0.6384s	
701/32750 (epoch 1.070), train_loss = 2.35171722, grad/param norm = 3.1080e-01, time/batch = 0.6332s	
702/32750 (epoch 1.072), train_loss = 2.39450393, grad/param norm = 3.1318e-01, time/batch = 0.6364s	
703/32750 (epoch 1.073), train_loss = 2.21115393, grad/param norm = 2.6718e-01, time/batch = 0.6340s	
704/32750 (epoch 1.075), train_loss = 2.36582399, grad/param norm = 2.6811e-01, time/batch = 0.6349s	
705/32750 (epoch 1.076), train_loss = 2.52041157, grad/param norm = 2.8441e-01, time/batch = 0.6496s	
706/32750 (epoch 1.078), train_loss = 2.48635808, grad/param norm = 3.0955e-01, time/batch = 0.6361s	
707/32750 (epoch 1.079), train_loss = 2.47630809, grad/param norm = 2.9081e-01, time/batch = 0.6340s	
708/32750 (epoch 1.081), train_loss = 2.26243183, grad/param norm = 3.1896e-01, time/batch = 0.6336s	
709/32750 (epoch 1.082), train_loss = 2.28706071, grad/param norm = 3.5177e-01, time/batch = 0.6317s	
710/32750 (epoch 1.084), train_loss = 2.34731367, grad/param norm = 3.3627e-01, time/batch = 0.6384s	
711/32750 (epoch 1.085), train_loss = 2.30997227, grad/param norm = 3.1785e-01, time/batch = 0.6504s	
712/32750 (epoch 1.087), train_loss = 2.44894251, grad/param norm = 3.7024e-01, time/batch = 0.6522s	
713/32750 (epoch 1.089), train_loss = 2.39622365, grad/param norm = 3.6668e-01, time/batch = 0.6709s	
714/32750 (epoch 1.090), train_loss = 2.44341124, grad/param norm = 4.0775e-01, time/batch = 0.6753s	
715/32750 (epoch 1.092), train_loss = 2.27969895, grad/param norm = 3.6356e-01, time/batch = 0.6704s	
716/32750 (epoch 1.093), train_loss = 2.36914779, grad/param norm = 3.0417e-01, time/batch = 0.6657s	
717/32750 (epoch 1.095), train_loss = 2.38443656, grad/param norm = 3.3474e-01, time/batch = 0.6722s	
718/32750 (epoch 1.096), train_loss = 2.38646453, grad/param norm = 3.3256e-01, time/batch = 0.6704s	
719/32750 (epoch 1.098), train_loss = 2.40569805, grad/param norm = 3.2920e-01, time/batch = 0.6528s	
720/32750 (epoch 1.099), train_loss = 2.36674101, grad/param norm = 3.6247e-01, time/batch = 0.6495s	
721/32750 (epoch 1.101), train_loss = 2.31107886, grad/param norm = 3.5976e-01, time/batch = 0.6524s	
722/32750 (epoch 1.102), train_loss = 2.37153935, grad/param norm = 3.1340e-01, time/batch = 0.6337s	
723/32750 (epoch 1.104), train_loss = 2.36049672, grad/param norm = 2.2002e-01, time/batch = 0.6367s	
724/32750 (epoch 1.105), train_loss = 2.37176201, grad/param norm = 2.7094e-01, time/batch = 0.6333s	
725/32750 (epoch 1.107), train_loss = 2.35397770, grad/param norm = 3.2776e-01, time/batch = 0.6353s	
726/32750 (epoch 1.108), train_loss = 2.55151385, grad/param norm = 3.6496e-01, time/batch = 0.6338s	
727/32750 (epoch 1.110), train_loss = 2.42330989, grad/param norm = 3.8258e-01, time/batch = 0.6317s	
728/32750 (epoch 1.111), train_loss = 2.46956851, grad/param norm = 2.6258e-01, time/batch = 0.6308s	
729/32750 (epoch 1.113), train_loss = 2.37005884, grad/param norm = 2.6211e-01, time/batch = 0.6540s	
730/32750 (epoch 1.115), train_loss = 2.34727536, grad/param norm = 2.9418e-01, time/batch = 0.6711s	
731/32750 (epoch 1.116), train_loss = 2.32285022, grad/param norm = 3.7944e-01, time/batch = 0.6321s	
732/32750 (epoch 1.118), train_loss = 2.39699060, grad/param norm = 3.2161e-01, time/batch = 0.6553s	
733/32750 (epoch 1.119), train_loss = 2.45485204, grad/param norm = 2.6148e-01, time/batch = 0.6444s	
734/32750 (epoch 1.121), train_loss = 2.34609510, grad/param norm = 2.4690e-01, time/batch = 0.6646s	
735/32750 (epoch 1.122), train_loss = 2.30593871, grad/param norm = 2.9711e-01, time/batch = 0.6586s	
736/32750 (epoch 1.124), train_loss = 2.44170324, grad/param norm = 3.1103e-01, time/batch = 0.6528s	
737/32750 (epoch 1.125), train_loss = 2.30411158, grad/param norm = 3.3770e-01, time/batch = 0.6342s	
738/32750 (epoch 1.127), train_loss = 2.48896628, grad/param norm = 3.2172e-01, time/batch = 0.6402s	
739/32750 (epoch 1.128), train_loss = 2.32493076, grad/param norm = 3.4404e-01, time/batch = 0.6415s	
740/32750 (epoch 1.130), train_loss = 2.37948915, grad/param norm = 3.8029e-01, time/batch = 0.6409s	
741/32750 (epoch 1.131), train_loss = 2.42040183, grad/param norm = 3.3272e-01, time/batch = 0.6446s	
742/32750 (epoch 1.133), train_loss = 2.37756545, grad/param norm = 2.2592e-01, time/batch = 0.6351s	
743/32750 (epoch 1.134), train_loss = 2.35610076, grad/param norm = 2.8070e-01, time/batch = 0.6387s	
744/32750 (epoch 1.136), train_loss = 2.48280779, grad/param norm = 2.5028e-01, time/batch = 0.6441s	
745/32750 (epoch 1.137), train_loss = 2.43363832, grad/param norm = 2.6932e-01, time/batch = 0.6619s	
746/32750 (epoch 1.139), train_loss = 2.47405536, grad/param norm = 2.6411e-01, time/batch = 0.6418s	
747/32750 (epoch 1.140), train_loss = 2.26061091, grad/param norm = 2.8109e-01, time/batch = 0.6404s	
748/32750 (epoch 1.142), train_loss = 2.41728024, grad/param norm = 2.6751e-01, time/batch = 0.6346s	
749/32750 (epoch 1.144), train_loss = 2.37290983, grad/param norm = 3.0379e-01, time/batch = 0.6369s	
750/32750 (epoch 1.145), train_loss = 2.27824638, grad/param norm = 3.6831e-01, time/batch = 0.6331s	
751/32750 (epoch 1.147), train_loss = 2.20844285, grad/param norm = 3.4570e-01, time/batch = 0.6357s	
752/32750 (epoch 1.148), train_loss = 2.50359975, grad/param norm = 3.1910e-01, time/batch = 0.6342s	
753/32750 (epoch 1.150), train_loss = 2.28980610, grad/param norm = 2.7957e-01, time/batch = 0.6308s	
754/32750 (epoch 1.151), train_loss = 2.35055912, grad/param norm = 2.9571e-01, time/batch = 0.6327s	
755/32750 (epoch 1.153), train_loss = 2.40862346, grad/param norm = 2.7141e-01, time/batch = 0.6324s	
756/32750 (epoch 1.154), train_loss = 2.33560520, grad/param norm = 3.2108e-01, time/batch = 0.6326s	
757/32750 (epoch 1.156), train_loss = 2.28803088, grad/param norm = 3.3845e-01, time/batch = 0.6327s	
758/32750 (epoch 1.157), train_loss = 2.29198148, grad/param norm = 3.5054e-01, time/batch = 0.6320s	
759/32750 (epoch 1.159), train_loss = 2.30849040, grad/param norm = 3.8801e-01, time/batch = 0.6298s	
760/32750 (epoch 1.160), train_loss = 2.36357867, grad/param norm = 3.4395e-01, time/batch = 0.6325s	
761/32750 (epoch 1.162), train_loss = 2.36120183, grad/param norm = 3.1456e-01, time/batch = 0.6318s	
762/32750 (epoch 1.163), train_loss = 2.41624832, grad/param norm = 3.1107e-01, time/batch = 0.6332s	
763/32750 (epoch 1.165), train_loss = 2.25402154, grad/param norm = 2.8802e-01, time/batch = 0.6372s	
764/32750 (epoch 1.166), train_loss = 2.37270771, grad/param norm = 2.7653e-01, time/batch = 0.6321s	
765/32750 (epoch 1.168), train_loss = 2.45201501, grad/param norm = 2.8454e-01, time/batch = 0.6328s	
766/32750 (epoch 1.169), train_loss = 2.32775355, grad/param norm = 2.5811e-01, time/batch = 0.6318s	
767/32750 (epoch 1.171), train_loss = 2.19042434, grad/param norm = 2.6596e-01, time/batch = 0.6306s	
768/32750 (epoch 1.173), train_loss = 2.52903611, grad/param norm = 3.6170e-01, time/batch = 0.6352s	
769/32750 (epoch 1.174), train_loss = 2.25942290, grad/param norm = 3.8006e-01, time/batch = 0.6366s	
770/32750 (epoch 1.176), train_loss = 2.40578114, grad/param norm = 2.9989e-01, time/batch = 0.6398s	
771/32750 (epoch 1.177), train_loss = 2.61027750, grad/param norm = 2.8593e-01, time/batch = 0.6375s	
772/32750 (epoch 1.179), train_loss = 2.40065451, grad/param norm = 3.3651e-01, time/batch = 0.6340s	
773/32750 (epoch 1.180), train_loss = 2.48532831, grad/param norm = 3.3994e-01, time/batch = 0.6357s	
774/32750 (epoch 1.182), train_loss = 2.28090943, grad/param norm = 2.7047e-01, time/batch = 0.6331s	
775/32750 (epoch 1.183), train_loss = 2.37396642, grad/param norm = 2.9304e-01, time/batch = 0.6325s	
776/32750 (epoch 1.185), train_loss = 2.15334622, grad/param norm = 3.7677e-01, time/batch = 0.6327s	
777/32750 (epoch 1.186), train_loss = 2.34831854, grad/param norm = 4.2826e-01, time/batch = 0.6312s	
778/32750 (epoch 1.188), train_loss = 2.45720610, grad/param norm = 3.5717e-01, time/batch = 0.6305s	
779/32750 (epoch 1.189), train_loss = 2.33178424, grad/param norm = 2.8513e-01, time/batch = 0.6398s	
780/32750 (epoch 1.191), train_loss = 2.42684220, grad/param norm = 2.7629e-01, time/batch = 0.6409s	
781/32750 (epoch 1.192), train_loss = 2.25289434, grad/param norm = 3.0648e-01, time/batch = 0.6743s	
782/32750 (epoch 1.194), train_loss = 2.27660559, grad/param norm = 2.4983e-01, time/batch = 0.6474s	
783/32750 (epoch 1.195), train_loss = 2.31724873, grad/param norm = 2.5786e-01, time/batch = 0.6333s	
784/32750 (epoch 1.197), train_loss = 2.35841594, grad/param norm = 2.6215e-01, time/batch = 0.6323s	
785/32750 (epoch 1.198), train_loss = 2.31737328, grad/param norm = 3.1983e-01, time/batch = 0.6348s	
786/32750 (epoch 1.200), train_loss = 2.31369543, grad/param norm = 2.9886e-01, time/batch = 0.6324s	
787/32750 (epoch 1.202), train_loss = 2.42971032, grad/param norm = 2.3672e-01, time/batch = 0.6328s	
788/32750 (epoch 1.203), train_loss = 2.36097745, grad/param norm = 2.8051e-01, time/batch = 0.6335s	
789/32750 (epoch 1.205), train_loss = 2.31541126, grad/param norm = 2.8423e-01, time/batch = 0.6295s	
790/32750 (epoch 1.206), train_loss = 2.22946117, grad/param norm = 3.1446e-01, time/batch = 0.6311s	
791/32750 (epoch 1.208), train_loss = 2.39757861, grad/param norm = 3.2843e-01, time/batch = 0.6327s	
792/32750 (epoch 1.209), train_loss = 2.37088963, grad/param norm = 3.0661e-01, time/batch = 0.6321s	
793/32750 (epoch 1.211), train_loss = 2.32448236, grad/param norm = 3.3053e-01, time/batch = 0.6318s	
794/32750 (epoch 1.212), train_loss = 2.26461381, grad/param norm = 3.0433e-01, time/batch = 0.6316s	
795/32750 (epoch 1.214), train_loss = 2.38211229, grad/param norm = 3.1804e-01, time/batch = 0.6322s	
796/32750 (epoch 1.215), train_loss = 2.37844012, grad/param norm = 2.9168e-01, time/batch = 0.6577s	
797/32750 (epoch 1.217), train_loss = 2.38814107, grad/param norm = 2.6277e-01, time/batch = 0.6730s	
798/32750 (epoch 1.218), train_loss = 2.19391527, grad/param norm = 2.1830e-01, time/batch = 0.6332s	
799/32750 (epoch 1.220), train_loss = 2.33147670, grad/param norm = 2.8490e-01, time/batch = 0.6351s	
800/32750 (epoch 1.221), train_loss = 2.27600637, grad/param norm = 2.2332e-01, time/batch = 0.6334s	
801/32750 (epoch 1.223), train_loss = 2.18449116, grad/param norm = 2.3518e-01, time/batch = 0.6366s	
802/32750 (epoch 1.224), train_loss = 2.52811177, grad/param norm = 2.9126e-01, time/batch = 0.6344s	
803/32750 (epoch 1.226), train_loss = 2.23278469, grad/param norm = 2.6655e-01, time/batch = 0.6351s	
804/32750 (epoch 1.227), train_loss = 2.28108921, grad/param norm = 3.3240e-01, time/batch = 0.6331s	
805/32750 (epoch 1.229), train_loss = 2.33743718, grad/param norm = 3.0741e-01, time/batch = 0.6333s	
806/32750 (epoch 1.231), train_loss = 2.35838991, grad/param norm = 3.6100e-01, time/batch = 0.6369s	
807/32750 (epoch 1.232), train_loss = 2.33111687, grad/param norm = 3.4515e-01, time/batch = 0.6436s	
808/32750 (epoch 1.234), train_loss = 2.30499112, grad/param norm = 2.6947e-01, time/batch = 0.6340s	
809/32750 (epoch 1.235), train_loss = 2.29777456, grad/param norm = 2.3872e-01, time/batch = 0.6314s	
810/32750 (epoch 1.237), train_loss = 2.30207080, grad/param norm = 2.3898e-01, time/batch = 0.6374s	
811/32750 (epoch 1.238), train_loss = 2.25993631, grad/param norm = 2.9186e-01, time/batch = 0.6358s	
812/32750 (epoch 1.240), train_loss = 2.34086839, grad/param norm = 3.1084e-01, time/batch = 0.6340s	
813/32750 (epoch 1.241), train_loss = 2.44193913, grad/param norm = 2.9571e-01, time/batch = 0.6330s	
814/32750 (epoch 1.243), train_loss = 2.47570260, grad/param norm = 2.7474e-01, time/batch = 0.6310s	
815/32750 (epoch 1.244), train_loss = 2.48871499, grad/param norm = 3.7941e-01, time/batch = 0.6331s	
816/32750 (epoch 1.246), train_loss = 2.27402796, grad/param norm = 3.8548e-01, time/batch = 0.6416s	
817/32750 (epoch 1.247), train_loss = 2.35667272, grad/param norm = 2.7050e-01, time/batch = 0.6739s	
818/32750 (epoch 1.249), train_loss = 2.26107812, grad/param norm = 2.8261e-01, time/batch = 0.6506s	
819/32750 (epoch 1.250), train_loss = 2.50641579, grad/param norm = 3.1838e-01, time/batch = 0.6373s	
820/32750 (epoch 1.252), train_loss = 2.24227360, grad/param norm = 3.1099e-01, time/batch = 0.6355s	
821/32750 (epoch 1.253), train_loss = 2.38901531, grad/param norm = 3.2518e-01, time/batch = 0.6358s	
822/32750 (epoch 1.255), train_loss = 2.40240382, grad/param norm = 2.5411e-01, time/batch = 0.6329s	
823/32750 (epoch 1.256), train_loss = 2.21834355, grad/param norm = 2.4876e-01, time/batch = 0.6348s	
824/32750 (epoch 1.258), train_loss = 2.40334114, grad/param norm = 2.7677e-01, time/batch = 0.6363s	
825/32750 (epoch 1.260), train_loss = 2.41098242, grad/param norm = 2.9031e-01, time/batch = 0.6384s	
826/32750 (epoch 1.261), train_loss = 2.42949099, grad/param norm = 3.1073e-01, time/batch = 0.6528s	
827/32750 (epoch 1.263), train_loss = 2.28618603, grad/param norm = 2.5939e-01, time/batch = 0.6434s	
828/32750 (epoch 1.264), train_loss = 2.32307949, grad/param norm = 2.4979e-01, time/batch = 0.6428s	
829/32750 (epoch 1.266), train_loss = 2.25114778, grad/param norm = 2.5002e-01, time/batch = 0.6433s	
830/32750 (epoch 1.267), train_loss = 2.36468047, grad/param norm = 2.5227e-01, time/batch = 0.6393s	
831/32750 (epoch 1.269), train_loss = 2.25225873, grad/param norm = 2.7414e-01, time/batch = 0.6414s	
832/32750 (epoch 1.270), train_loss = 2.47342846, grad/param norm = 2.3791e-01, time/batch = 0.6621s	
833/32750 (epoch 1.272), train_loss = 2.30842240, grad/param norm = 2.2823e-01, time/batch = 0.6644s	
834/32750 (epoch 1.273), train_loss = 2.43324129, grad/param norm = 2.5528e-01, time/batch = 0.6375s	
835/32750 (epoch 1.275), train_loss = 2.37939387, grad/param norm = 2.4939e-01, time/batch = 0.6376s	
836/32750 (epoch 1.276), train_loss = 2.39048708, grad/param norm = 3.7433e-01, time/batch = 0.6318s	
837/32750 (epoch 1.278), train_loss = 2.35492262, grad/param norm = 3.0173e-01, time/batch = 0.6321s	
838/32750 (epoch 1.279), train_loss = 2.46006826, grad/param norm = 2.5748e-01, time/batch = 0.6315s	
839/32750 (epoch 1.281), train_loss = 2.34109011, grad/param norm = 2.3504e-01, time/batch = 0.6311s	
840/32750 (epoch 1.282), train_loss = 2.24620666, grad/param norm = 4.1617e-01, time/batch = 0.6335s	
841/32750 (epoch 1.284), train_loss = 2.62993817, grad/param norm = 5.0183e-01, time/batch = 0.6449s	
842/32750 (epoch 1.285), train_loss = 2.47684374, grad/param norm = 7.1174e-01, time/batch = 0.6371s	
843/32750 (epoch 1.287), train_loss = 2.34792880, grad/param norm = 2.7574e-01, time/batch = 0.6329s	
844/32750 (epoch 1.289), train_loss = 2.39559611, grad/param norm = 3.0188e-01, time/batch = 0.6329s	
845/32750 (epoch 1.290), train_loss = 2.27960827, grad/param norm = 2.2267e-01, time/batch = 0.6327s	
846/32750 (epoch 1.292), train_loss = 2.33546942, grad/param norm = 2.7467e-01, time/batch = 0.6331s	
847/32750 (epoch 1.293), train_loss = 2.24765098, grad/param norm = 3.1800e-01, time/batch = 0.6374s	
848/32750 (epoch 1.295), train_loss = 2.38666327, grad/param norm = 2.9361e-01, time/batch = 0.6732s	
849/32750 (epoch 1.296), train_loss = 2.34292410, grad/param norm = 2.3849e-01, time/batch = 0.6483s	
850/32750 (epoch 1.298), train_loss = 2.20228023, grad/param norm = 2.3521e-01, time/batch = 0.6343s	
851/32750 (epoch 1.299), train_loss = 2.21214041, grad/param norm = 2.3918e-01, time/batch = 0.6320s	
852/32750 (epoch 1.301), train_loss = 2.24788964, grad/param norm = 2.3521e-01, time/batch = 0.6341s	
853/32750 (epoch 1.302), train_loss = 2.18882811, grad/param norm = 2.8156e-01, time/batch = 0.6317s	
854/32750 (epoch 1.304), train_loss = 2.28901294, grad/param norm = 3.3513e-01, time/batch = 0.6316s	
855/32750 (epoch 1.305), train_loss = 2.32072759, grad/param norm = 2.8141e-01, time/batch = 0.6329s	
856/32750 (epoch 1.307), train_loss = 2.43557430, grad/param norm = 2.9584e-01, time/batch = 0.6309s	
857/32750 (epoch 1.308), train_loss = 2.41978813, grad/param norm = 2.5382e-01, time/batch = 0.6347s	
858/32750 (epoch 1.310), train_loss = 2.44386874, grad/param norm = 3.0806e-01, time/batch = 0.6343s	
859/32750 (epoch 1.311), train_loss = 2.32255516, grad/param norm = 2.9556e-01, time/batch = 0.6337s	
860/32750 (epoch 1.313), train_loss = 2.36863611, grad/param norm = 3.0193e-01, time/batch = 0.6350s	
861/32750 (epoch 1.315), train_loss = 2.40792610, grad/param norm = 2.8474e-01, time/batch = 0.6345s	
862/32750 (epoch 1.316), train_loss = 2.40434308, grad/param norm = 2.3450e-01, time/batch = 0.6403s	
863/32750 (epoch 1.318), train_loss = 2.22743086, grad/param norm = 3.1065e-01, time/batch = 0.6543s	
864/32750 (epoch 1.319), train_loss = 2.37185292, grad/param norm = 3.4390e-01, time/batch = 0.6727s	
865/32750 (epoch 1.321), train_loss = 2.31564290, grad/param norm = 2.9335e-01, time/batch = 0.6338s	
866/32750 (epoch 1.322), train_loss = 2.35171081, grad/param norm = 3.6008e-01, time/batch = 0.6332s	
867/32750 (epoch 1.324), train_loss = 2.41539385, grad/param norm = 3.2770e-01, time/batch = 0.6309s	
868/32750 (epoch 1.325), train_loss = 2.31684908, grad/param norm = 3.0650e-01, time/batch = 0.6316s	
869/32750 (epoch 1.327), train_loss = 2.16733769, grad/param norm = 2.3115e-01, time/batch = 0.6339s	
870/32750 (epoch 1.328), train_loss = 2.21109915, grad/param norm = 2.1446e-01, time/batch = 0.6560s	
871/32750 (epoch 1.330), train_loss = 2.24299050, grad/param norm = 2.3152e-01, time/batch = 0.6417s	
872/32750 (epoch 1.331), train_loss = 2.31573479, grad/param norm = 2.4235e-01, time/batch = 0.6333s	
873/32750 (epoch 1.333), train_loss = 2.20532480, grad/param norm = 2.3088e-01, time/batch = 0.6339s	
874/32750 (epoch 1.334), train_loss = 2.45638837, grad/param norm = 2.3188e-01, time/batch = 0.6339s	
875/32750 (epoch 1.336), train_loss = 2.23759127, grad/param norm = 2.3004e-01, time/batch = 0.6332s	
876/32750 (epoch 1.337), train_loss = 2.21067767, grad/param norm = 2.8401e-01, time/batch = 0.6322s	
877/32750 (epoch 1.339), train_loss = 2.54407970, grad/param norm = 2.7789e-01, time/batch = 0.6363s	
878/32750 (epoch 1.340), train_loss = 2.18296596, grad/param norm = 2.8139e-01, time/batch = 0.6463s	
879/32750 (epoch 1.342), train_loss = 2.33293802, grad/param norm = 2.8267e-01, time/batch = 0.6753s	
880/32750 (epoch 1.344), train_loss = 2.43580177, grad/param norm = 2.9616e-01, time/batch = 0.6609s	
881/32750 (epoch 1.345), train_loss = 2.36555885, grad/param norm = 3.0245e-01, time/batch = 0.6435s	
882/32750 (epoch 1.347), train_loss = 2.34033525, grad/param norm = 2.7211e-01, time/batch = 0.6335s	
883/32750 (epoch 1.348), train_loss = 2.34877785, grad/param norm = 2.6074e-01, time/batch = 0.6374s	
884/32750 (epoch 1.350), train_loss = 2.44083207, grad/param norm = 2.6096e-01, time/batch = 0.6314s	
885/32750 (epoch 1.351), train_loss = 2.43980579, grad/param norm = 2.3391e-01, time/batch = 0.6373s	
886/32750 (epoch 1.353), train_loss = 2.31763839, grad/param norm = 2.7316e-01, time/batch = 0.6328s	
887/32750 (epoch 1.354), train_loss = 2.25458268, grad/param norm = 2.8359e-01, time/batch = 0.6314s	
888/32750 (epoch 1.356), train_loss = 2.29952964, grad/param norm = 3.5594e-01, time/batch = 0.6404s	
889/32750 (epoch 1.357), train_loss = 2.19362967, grad/param norm = 3.2054e-01, time/batch = 0.6329s	
890/32750 (epoch 1.359), train_loss = 2.34459591, grad/param norm = 3.4341e-01, time/batch = 0.6383s	
891/32750 (epoch 1.360), train_loss = 2.28633289, grad/param norm = 3.4643e-01, time/batch = 0.6362s	
892/32750 (epoch 1.362), train_loss = 2.22946292, grad/param norm = 2.4801e-01, time/batch = 0.6345s	
893/32750 (epoch 1.363), train_loss = 2.17158560, grad/param norm = 2.5670e-01, time/batch = 0.6334s	
894/32750 (epoch 1.365), train_loss = 2.20896708, grad/param norm = 3.2036e-01, time/batch = 0.6369s	
895/32750 (epoch 1.366), train_loss = 2.24836522, grad/param norm = 3.5621e-01, time/batch = 0.6330s	
896/32750 (epoch 1.368), train_loss = 2.46337677, grad/param norm = 2.8170e-01, time/batch = 0.6330s	
897/32750 (epoch 1.369), train_loss = 2.39789945, grad/param norm = 2.5105e-01, time/batch = 0.6379s	
898/32750 (epoch 1.371), train_loss = 2.29441689, grad/param norm = 2.6984e-01, time/batch = 0.6524s	
899/32750 (epoch 1.373), train_loss = 2.27617744, grad/param norm = 2.7066e-01, time/batch = 0.6388s	
900/32750 (epoch 1.374), train_loss = 2.38074838, grad/param norm = 3.0900e-01, time/batch = 0.6312s	
901/32750 (epoch 1.376), train_loss = 2.16029910, grad/param norm = 2.6515e-01, time/batch = 0.6317s	
902/32750 (epoch 1.377), train_loss = 2.28559817, grad/param norm = 2.1740e-01, time/batch = 0.6336s	
903/32750 (epoch 1.379), train_loss = 2.27212353, grad/param norm = 2.7802e-01, time/batch = 0.6321s	
904/32750 (epoch 1.380), train_loss = 2.43643713, grad/param norm = 2.8698e-01, time/batch = 0.6335s	
905/32750 (epoch 1.382), train_loss = 2.27614471, grad/param norm = 2.8316e-01, time/batch = 0.6326s	
906/32750 (epoch 1.383), train_loss = 2.37325816, grad/param norm = 3.2518e-01, time/batch = 0.6318s	
907/32750 (epoch 1.385), train_loss = 2.31922157, grad/param norm = 3.2844e-01, time/batch = 0.6317s	
908/32750 (epoch 1.386), train_loss = 2.38863237, grad/param norm = 3.0471e-01, time/batch = 0.6342s	
909/32750 (epoch 1.388), train_loss = 2.27790432, grad/param norm = 2.5076e-01, time/batch = 0.6342s	
910/32750 (epoch 1.389), train_loss = 2.25873568, grad/param norm = 2.5645e-01, time/batch = 0.6360s	
911/32750 (epoch 1.391), train_loss = 2.16360484, grad/param norm = 2.5320e-01, time/batch = 0.6336s	
912/32750 (epoch 1.392), train_loss = 2.24163556, grad/param norm = 2.7448e-01, time/batch = 0.6334s	
913/32750 (epoch 1.394), train_loss = 2.26321569, grad/param norm = 2.7755e-01, time/batch = 0.6334s	
914/32750 (epoch 1.395), train_loss = 2.22010319, grad/param norm = 2.6989e-01, time/batch = 0.6330s	
915/32750 (epoch 1.397), train_loss = 2.41047988, grad/param norm = 2.7131e-01, time/batch = 0.6313s	
916/32750 (epoch 1.398), train_loss = 2.36319598, grad/param norm = 2.7887e-01, time/batch = 0.6328s	
917/32750 (epoch 1.400), train_loss = 2.24644764, grad/param norm = 2.0748e-01, time/batch = 0.6315s	
918/32750 (epoch 1.402), train_loss = 2.27615486, grad/param norm = 2.5604e-01, time/batch = 0.6317s	
919/32750 (epoch 1.403), train_loss = 2.31706453, grad/param norm = 2.5789e-01, time/batch = 0.6430s	
920/32750 (epoch 1.405), train_loss = 2.31815095, grad/param norm = 2.7061e-01, time/batch = 0.6453s	
921/32750 (epoch 1.406), train_loss = 2.16776601, grad/param norm = 2.7241e-01, time/batch = 0.6575s	
922/32750 (epoch 1.408), train_loss = 2.10380747, grad/param norm = 2.4344e-01, time/batch = 0.6527s	
923/32750 (epoch 1.409), train_loss = 2.36356027, grad/param norm = 2.3814e-01, time/batch = 0.6492s	
924/32750 (epoch 1.411), train_loss = 2.23395676, grad/param norm = 2.7261e-01, time/batch = 0.6386s	
925/32750 (epoch 1.412), train_loss = 2.20532290, grad/param norm = 2.9109e-01, time/batch = 0.6361s	
926/32750 (epoch 1.414), train_loss = 2.16572038, grad/param norm = 3.0413e-01, time/batch = 0.6382s	
927/32750 (epoch 1.415), train_loss = 2.28595595, grad/param norm = 2.9116e-01, time/batch = 0.6346s	
928/32750 (epoch 1.417), train_loss = 2.11997069, grad/param norm = 3.6054e-01, time/batch = 0.6384s	
929/32750 (epoch 1.418), train_loss = 2.35200634, grad/param norm = 3.4257e-01, time/batch = 0.6318s	
930/32750 (epoch 1.420), train_loss = 2.23643970, grad/param norm = 2.9575e-01, time/batch = 0.6599s	
931/32750 (epoch 1.421), train_loss = 2.35879358, grad/param norm = 2.5278e-01, time/batch = 0.6713s	
932/32750 (epoch 1.423), train_loss = 2.20361674, grad/param norm = 3.1161e-01, time/batch = 0.6309s	
933/32750 (epoch 1.424), train_loss = 2.15697588, grad/param norm = 2.5164e-01, time/batch = 0.6312s	
934/32750 (epoch 1.426), train_loss = 2.19059845, grad/param norm = 2.6908e-01, time/batch = 0.6305s	
935/32750 (epoch 1.427), train_loss = 2.21533766, grad/param norm = 3.4805e-01, time/batch = 0.6336s	
936/32750 (epoch 1.429), train_loss = 2.15479606, grad/param norm = 2.4238e-01, time/batch = 0.6376s	
937/32750 (epoch 1.431), train_loss = 2.36137016, grad/param norm = 2.5450e-01, time/batch = 0.6312s	
938/32750 (epoch 1.432), train_loss = 2.22927537, grad/param norm = 2.4940e-01, time/batch = 0.6326s	
939/32750 (epoch 1.434), train_loss = 2.29728781, grad/param norm = 2.4853e-01, time/batch = 0.6322s	
940/32750 (epoch 1.435), train_loss = 2.20129204, grad/param norm = 2.5400e-01, time/batch = 0.6308s	
941/32750 (epoch 1.437), train_loss = 2.24066290, grad/param norm = 2.3355e-01, time/batch = 0.6344s	
942/32750 (epoch 1.438), train_loss = 2.46952928, grad/param norm = 2.8273e-01, time/batch = 0.6321s	
943/32750 (epoch 1.440), train_loss = 2.24384005, grad/param norm = 2.4384e-01, time/batch = 0.6335s	
944/32750 (epoch 1.441), train_loss = 2.32451107, grad/param norm = 2.5040e-01, time/batch = 0.6346s	
945/32750 (epoch 1.443), train_loss = 2.06238060, grad/param norm = 2.6904e-01, time/batch = 0.6322s	
946/32750 (epoch 1.444), train_loss = 2.25848439, grad/param norm = 3.2498e-01, time/batch = 0.6649s	
947/32750 (epoch 1.446), train_loss = 2.20780442, grad/param norm = 2.9378e-01, time/batch = 0.6618s	
948/32750 (epoch 1.447), train_loss = 2.41629839, grad/param norm = 3.1730e-01, time/batch = 0.6337s	
949/32750 (epoch 1.449), train_loss = 2.31562862, grad/param norm = 2.7108e-01, time/batch = 0.6356s	
950/32750 (epoch 1.450), train_loss = 2.35869003, grad/param norm = 2.9115e-01, time/batch = 0.6360s	
951/32750 (epoch 1.452), train_loss = 2.34819917, grad/param norm = 2.4419e-01, time/batch = 0.6390s	
952/32750 (epoch 1.453), train_loss = 2.16928624, grad/param norm = 2.6049e-01, time/batch = 0.6622s	
953/32750 (epoch 1.455), train_loss = 2.20133619, grad/param norm = 2.2323e-01, time/batch = 0.6623s	
954/32750 (epoch 1.456), train_loss = 2.28635384, grad/param norm = 2.1407e-01, time/batch = 0.6372s	
955/32750 (epoch 1.458), train_loss = 2.39832255, grad/param norm = 2.4191e-01, time/batch = 0.6426s	
956/32750 (epoch 1.460), train_loss = 2.35613652, grad/param norm = 2.7786e-01, time/batch = 0.6367s	
957/32750 (epoch 1.461), train_loss = 2.28462035, grad/param norm = 3.5916e-01, time/batch = 0.6380s	
958/32750 (epoch 1.463), train_loss = 2.21193480, grad/param norm = 3.1979e-01, time/batch = 0.6372s	
959/32750 (epoch 1.464), train_loss = 2.40226175, grad/param norm = 2.3444e-01, time/batch = 0.6362s	
960/32750 (epoch 1.466), train_loss = 2.32275368, grad/param norm = 2.6313e-01, time/batch = 0.6349s	
961/32750 (epoch 1.467), train_loss = 2.60066025, grad/param norm = 2.6614e-01, time/batch = 0.6497s	
962/32750 (epoch 1.469), train_loss = 2.24728203, grad/param norm = 2.4912e-01, time/batch = 0.6736s	
963/32750 (epoch 1.470), train_loss = 2.33543389, grad/param norm = 2.7904e-01, time/batch = 0.6417s	
964/32750 (epoch 1.472), train_loss = 2.29989234, grad/param norm = 2.3596e-01, time/batch = 0.6340s	
965/32750 (epoch 1.473), train_loss = 2.25479804, grad/param norm = 2.2467e-01, time/batch = 0.6341s	
966/32750 (epoch 1.475), train_loss = 2.30967253, grad/param norm = 2.4452e-01, time/batch = 0.6379s	
967/32750 (epoch 1.476), train_loss = 2.28130953, grad/param norm = 2.2726e-01, time/batch = 0.6325s	
968/32750 (epoch 1.478), train_loss = 2.46905686, grad/param norm = 2.6166e-01, time/batch = 0.6330s	
969/32750 (epoch 1.479), train_loss = 2.50845891, grad/param norm = 2.8187e-01, time/batch = 0.6342s	
970/32750 (epoch 1.481), train_loss = 2.68269519, grad/param norm = 2.6066e-01, time/batch = 0.6343s	
971/32750 (epoch 1.482), train_loss = 2.41905366, grad/param norm = 3.0496e-01, time/batch = 0.6341s	
972/32750 (epoch 1.484), train_loss = 2.19680391, grad/param norm = 2.8993e-01, time/batch = 0.6404s	
973/32750 (epoch 1.485), train_loss = 2.28993204, grad/param norm = 2.8852e-01, time/batch = 0.6344s	
974/32750 (epoch 1.487), train_loss = 2.31726406, grad/param norm = 3.4554e-01, time/batch = 0.6378s	
975/32750 (epoch 1.489), train_loss = 2.21617278, grad/param norm = 2.9458e-01, time/batch = 0.6390s	
976/32750 (epoch 1.490), train_loss = 2.31286652, grad/param norm = 2.5792e-01, time/batch = 0.6386s	
977/32750 (epoch 1.492), train_loss = 2.32410773, grad/param norm = 2.2519e-01, time/batch = 0.6696s	
978/32750 (epoch 1.493), train_loss = 2.35696541, grad/param norm = 2.3257e-01, time/batch = 0.6616s	
979/32750 (epoch 1.495), train_loss = 2.49394388, grad/param norm = 2.6407e-01, time/batch = 0.6372s	
980/32750 (epoch 1.496), train_loss = 2.16381207, grad/param norm = 2.6148e-01, time/batch = 0.6362s	
981/32750 (epoch 1.498), train_loss = 2.27247351, grad/param norm = 2.4344e-01, time/batch = 0.6362s	
982/32750 (epoch 1.499), train_loss = 2.36339100, grad/param norm = 2.3894e-01, time/batch = 0.6388s	
983/32750 (epoch 1.501), train_loss = 2.48192784, grad/param norm = 2.5733e-01, time/batch = 0.6354s	
984/32750 (epoch 1.502), train_loss = 2.37280705, grad/param norm = 2.9622e-01, time/batch = 0.6357s	
985/32750 (epoch 1.504), train_loss = 2.33530704, grad/param norm = 2.7693e-01, time/batch = 0.6342s	
986/32750 (epoch 1.505), train_loss = 2.29738671, grad/param norm = 2.3883e-01, time/batch = 0.6419s	
987/32750 (epoch 1.507), train_loss = 2.23213129, grad/param norm = 2.7841e-01, time/batch = 0.6338s	
988/32750 (epoch 1.508), train_loss = 2.23210726, grad/param norm = 2.7616e-01, time/batch = 0.6376s	
989/32750 (epoch 1.510), train_loss = 2.26757867, grad/param norm = 2.6040e-01, time/batch = 0.6326s	
990/32750 (epoch 1.511), train_loss = 2.21642521, grad/param norm = 2.1127e-01, time/batch = 0.6359s	
991/32750 (epoch 1.513), train_loss = 2.12696219, grad/param norm = 2.4751e-01, time/batch = 0.6401s	
992/32750 (epoch 1.515), train_loss = 2.26308591, grad/param norm = 2.3932e-01, time/batch = 0.6491s	
993/32750 (epoch 1.516), train_loss = 2.24162708, grad/param norm = 2.5057e-01, time/batch = 0.6739s	
994/32750 (epoch 1.518), train_loss = 2.36425960, grad/param norm = 3.0264e-01, time/batch = 0.6438s	
995/32750 (epoch 1.519), train_loss = 2.39873934, grad/param norm = 2.7282e-01, time/batch = 0.6347s	
996/32750 (epoch 1.521), train_loss = 2.21237338, grad/param norm = 2.5144e-01, time/batch = 0.6340s	
997/32750 (epoch 1.522), train_loss = 2.33287093, grad/param norm = 2.9236e-01, time/batch = 0.6359s	
998/32750 (epoch 1.524), train_loss = 2.12733563, grad/param norm = 2.8192e-01, time/batch = 0.6360s	
999/32750 (epoch 1.525), train_loss = 2.16145264, grad/param norm = 2.1658e-01, time/batch = 0.6351s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_ubersein_epoch1.53_2.3065.t7	
1000/32750 (epoch 1.527), train_loss = 2.26244046, grad/param norm = 2.7647e-01, time/batch = 0.6395s	
1001/32750 (epoch 1.528), train_loss = 2.23846187, grad/param norm = 2.7728e-01, time/batch = 0.6508s	
1002/32750 (epoch 1.530), train_loss = 2.36240369, grad/param norm = 2.5187e-01, time/batch = 0.6372s	
1003/32750 (epoch 1.531), train_loss = 2.21115203, grad/param norm = 2.4122e-01, time/batch = 0.6617s	
1004/32750 (epoch 1.533), train_loss = 2.31473071, grad/param norm = 2.9070e-01, time/batch = 0.6412s	
1005/32750 (epoch 1.534), train_loss = 2.36577509, grad/param norm = 3.1547e-01, time/batch = 0.6415s	
1006/32750 (epoch 1.536), train_loss = 2.06307619, grad/param norm = 1.9752e-01, time/batch = 0.6348s	
1007/32750 (epoch 1.537), train_loss = 2.20515493, grad/param norm = 2.4979e-01, time/batch = 0.6462s	
1008/32750 (epoch 1.539), train_loss = 2.36545271, grad/param norm = 2.5149e-01, time/batch = 0.6364s	
1009/32750 (epoch 1.540), train_loss = 2.21511927, grad/param norm = 2.2903e-01, time/batch = 0.6345s	
1010/32750 (epoch 1.542), train_loss = 2.21780418, grad/param norm = 3.0166e-01, time/batch = 0.6464s	
1011/32750 (epoch 1.544), train_loss = 2.27628933, grad/param norm = 3.1784e-01, time/batch = 0.6443s	
1012/32750 (epoch 1.545), train_loss = 2.21332690, grad/param norm = 2.2426e-01, time/batch = 0.6389s	
1013/32750 (epoch 1.547), train_loss = 2.17234202, grad/param norm = 2.1485e-01, time/batch = 0.6368s	
1014/32750 (epoch 1.548), train_loss = 2.30223968, grad/param norm = 2.3786e-01, time/batch = 0.6676s	
1015/32750 (epoch 1.550), train_loss = 2.29484480, grad/param norm = 2.4725e-01, time/batch = 0.6587s	
1016/32750 (epoch 1.551), train_loss = 2.23044015, grad/param norm = 2.7406e-01, time/batch = 0.6343s	
1017/32750 (epoch 1.553), train_loss = 2.22243023, grad/param norm = 2.4404e-01, time/batch = 0.6513s	
1018/32750 (epoch 1.554), train_loss = 2.22307375, grad/param norm = 2.2959e-01, time/batch = 0.6463s	
1019/32750 (epoch 1.556), train_loss = 2.37727762, grad/param norm = 2.5499e-01, time/batch = 0.6343s	
1020/32750 (epoch 1.557), train_loss = 2.22010933, grad/param norm = 2.2885e-01, time/batch = 0.6346s	
1021/32750 (epoch 1.559), train_loss = 2.26636022, grad/param norm = 2.4008e-01, time/batch = 0.6366s	
1022/32750 (epoch 1.560), train_loss = 2.17891254, grad/param norm = 2.8102e-01, time/batch = 0.6352s	
1023/32750 (epoch 1.562), train_loss = 2.22831425, grad/param norm = 2.9161e-01, time/batch = 0.6327s	
1024/32750 (epoch 1.563), train_loss = 2.29412853, grad/param norm = 2.1417e-01, time/batch = 0.6332s	
1025/32750 (epoch 1.565), train_loss = 2.21679744, grad/param norm = 2.4149e-01, time/batch = 0.6389s	
1026/32750 (epoch 1.566), train_loss = 2.19238311, grad/param norm = 2.2299e-01, time/batch = 0.6410s	
1027/32750 (epoch 1.568), train_loss = 2.29005928, grad/param norm = 2.6456e-01, time/batch = 0.6372s	
1028/32750 (epoch 1.569), train_loss = 2.31201326, grad/param norm = 2.8005e-01, time/batch = 0.6360s	
1029/32750 (epoch 1.571), train_loss = 2.15961671, grad/param norm = 2.4986e-01, time/batch = 0.6521s	
1030/32750 (epoch 1.573), train_loss = 2.25225329, grad/param norm = 2.0247e-01, time/batch = 0.6479s	
1031/32750 (epoch 1.574), train_loss = 2.26554965, grad/param norm = 2.3145e-01, time/batch = 0.6490s	
1032/32750 (epoch 1.576), train_loss = 2.18659036, grad/param norm = 2.3600e-01, time/batch = 0.6340s	
1033/32750 (epoch 1.577), train_loss = 2.30623488, grad/param norm = 2.3441e-01, time/batch = 0.6330s	
1034/32750 (epoch 1.579), train_loss = 2.14305247, grad/param norm = 2.3127e-01, time/batch = 0.6382s	
1035/32750 (epoch 1.580), train_loss = 2.24893323, grad/param norm = 2.5109e-01, time/batch = 0.6341s	
1036/32750 (epoch 1.582), train_loss = 2.21804452, grad/param norm = 2.2134e-01, time/batch = 0.6386s	
1037/32750 (epoch 1.583), train_loss = 2.26889155, grad/param norm = 2.8046e-01, time/batch = 0.6690s	
1038/32750 (epoch 1.585), train_loss = 2.23979320, grad/param norm = 3.1267e-01, time/batch = 0.6687s	
1039/32750 (epoch 1.586), train_loss = 2.39266760, grad/param norm = 3.6729e-01, time/batch = 0.6712s	
1040/32750 (epoch 1.588), train_loss = 2.28504895, grad/param norm = 3.1720e-01, time/batch = 0.6526s	
1041/32750 (epoch 1.589), train_loss = 2.24279031, grad/param norm = 2.3477e-01, time/batch = 0.6502s	
1042/32750 (epoch 1.591), train_loss = 2.22785829, grad/param norm = 2.4003e-01, time/batch = 0.6376s	
1043/32750 (epoch 1.592), train_loss = 2.16749995, grad/param norm = 2.2388e-01, time/batch = 0.6514s	
1044/32750 (epoch 1.594), train_loss = 2.13564116, grad/param norm = 2.6253e-01, time/batch = 0.6512s	
1045/32750 (epoch 1.595), train_loss = 2.14072125, grad/param norm = 2.6340e-01, time/batch = 0.6737s	
1046/32750 (epoch 1.597), train_loss = 2.23899534, grad/param norm = 2.1285e-01, time/batch = 0.6629s	
1047/32750 (epoch 1.598), train_loss = 2.02583074, grad/param norm = 2.4841e-01, time/batch = 0.6543s	
1048/32750 (epoch 1.600), train_loss = 2.36283601, grad/param norm = 2.9965e-01, time/batch = 0.6320s	
1049/32750 (epoch 1.602), train_loss = 2.59198940, grad/param norm = 2.4835e-01, time/batch = 0.6322s	
1050/32750 (epoch 1.603), train_loss = 2.85636237, grad/param norm = 4.4827e-01, time/batch = 0.6419s	
1051/32750 (epoch 1.605), train_loss = 2.33574745, grad/param norm = 4.7762e-01, time/batch = 0.6511s	
1052/32750 (epoch 1.606), train_loss = 2.23181288, grad/param norm = 2.9953e-01, time/batch = 0.6507s	
1053/32750 (epoch 1.608), train_loss = 2.25071278, grad/param norm = 2.9599e-01, time/batch = 0.6506s	
1054/32750 (epoch 1.609), train_loss = 2.11403927, grad/param norm = 2.7222e-01, time/batch = 0.6514s	
1055/32750 (epoch 1.611), train_loss = 2.29062156, grad/param norm = 2.6940e-01, time/batch = 0.6618s	
1056/32750 (epoch 1.612), train_loss = 2.15680673, grad/param norm = 2.3130e-01, time/batch = 0.6329s	
1057/32750 (epoch 1.614), train_loss = 2.09516976, grad/param norm = 2.2027e-01, time/batch = 0.6358s	
1058/32750 (epoch 1.615), train_loss = 2.29063183, grad/param norm = 2.2281e-01, time/batch = 0.6360s	
1059/32750 (epoch 1.617), train_loss = 2.13550522, grad/param norm = 2.3661e-01, time/batch = 0.6330s	
1060/32750 (epoch 1.618), train_loss = 2.18253411, grad/param norm = 2.4537e-01, time/batch = 0.6552s	
1061/32750 (epoch 1.620), train_loss = 2.20156532, grad/param norm = 2.4915e-01, time/batch = 0.6696s	
1062/32750 (epoch 1.621), train_loss = 2.27909687, grad/param norm = 2.9961e-01, time/batch = 0.6326s	
1063/32750 (epoch 1.623), train_loss = 2.21960251, grad/param norm = 3.2186e-01, time/batch = 0.6324s	
1064/32750 (epoch 1.624), train_loss = 2.39337896, grad/param norm = 2.7013e-01, time/batch = 0.6376s	
1065/32750 (epoch 1.626), train_loss = 2.28161692, grad/param norm = 2.0791e-01, time/batch = 0.6362s	
1066/32750 (epoch 1.627), train_loss = 2.31099331, grad/param norm = 2.7382e-01, time/batch = 0.6333s	
1067/32750 (epoch 1.629), train_loss = 2.20819864, grad/param norm = 2.5564e-01, time/batch = 0.6336s	
1068/32750 (epoch 1.631), train_loss = 2.28780374, grad/param norm = 2.6664e-01, time/batch = 0.6318s	
1069/32750 (epoch 1.632), train_loss = 2.26357030, grad/param norm = 2.3133e-01, time/batch = 0.6330s	
1070/32750 (epoch 1.634), train_loss = 2.40469418, grad/param norm = 2.2998e-01, time/batch = 0.6345s	
1071/32750 (epoch 1.635), train_loss = 2.17906727, grad/param norm = 2.6493e-01, time/batch = 0.6387s	
1072/32750 (epoch 1.637), train_loss = 2.42943174, grad/param norm = 2.6549e-01, time/batch = 0.6331s	
1073/32750 (epoch 1.638), train_loss = 2.23083875, grad/param norm = 2.2465e-01, time/batch = 0.6324s	
1074/32750 (epoch 1.640), train_loss = 2.20303379, grad/param norm = 2.4726e-01, time/batch = 0.6356s	
1075/32750 (epoch 1.641), train_loss = 2.20473504, grad/param norm = 2.4007e-01, time/batch = 0.6366s	
1076/32750 (epoch 1.643), train_loss = 2.12122891, grad/param norm = 2.2505e-01, time/batch = 0.6733s	
1077/32750 (epoch 1.644), train_loss = 2.14267244, grad/param norm = 2.4076e-01, time/batch = 0.6526s	
1078/32750 (epoch 1.646), train_loss = 2.12752137, grad/param norm = 2.4692e-01, time/batch = 0.6331s	
1079/32750 (epoch 1.647), train_loss = 2.23532659, grad/param norm = 2.7420e-01, time/batch = 0.6345s	
1080/32750 (epoch 1.649), train_loss = 2.27503593, grad/param norm = 2.3267e-01, time/batch = 0.6348s	
1081/32750 (epoch 1.650), train_loss = 2.36989719, grad/param norm = 2.1480e-01, time/batch = 0.6366s	
1082/32750 (epoch 1.652), train_loss = 2.16995695, grad/param norm = 2.7450e-01, time/batch = 0.6353s	
1083/32750 (epoch 1.653), train_loss = 2.10239499, grad/param norm = 2.3198e-01, time/batch = 0.6355s	
1084/32750 (epoch 1.655), train_loss = 2.44418122, grad/param norm = 2.6394e-01, time/batch = 0.6334s	
1085/32750 (epoch 1.656), train_loss = 2.21801318, grad/param norm = 2.4083e-01, time/batch = 0.6328s	
1086/32750 (epoch 1.658), train_loss = 2.31953031, grad/param norm = 2.4857e-01, time/batch = 0.6434s	
1087/32750 (epoch 1.660), train_loss = 2.24950315, grad/param norm = 2.5654e-01, time/batch = 0.6397s	
1088/32750 (epoch 1.661), train_loss = 2.34113925, grad/param norm = 2.7314e-01, time/batch = 0.6380s	
1089/32750 (epoch 1.663), train_loss = 2.24742422, grad/param norm = 2.2029e-01, time/batch = 0.6359s	
1090/32750 (epoch 1.664), train_loss = 2.25946073, grad/param norm = 2.7632e-01, time/batch = 0.6328s	
1091/32750 (epoch 1.666), train_loss = 2.37324372, grad/param norm = 2.7428e-01, time/batch = 0.6531s	
1092/32750 (epoch 1.667), train_loss = 2.25696114, grad/param norm = 2.5675e-01, time/batch = 0.6739s	
1093/32750 (epoch 1.669), train_loss = 2.28822153, grad/param norm = 3.2877e-01, time/batch = 0.6353s	
1094/32750 (epoch 1.670), train_loss = 2.27758856, grad/param norm = 2.7773e-01, time/batch = 0.6327s	
1095/32750 (epoch 1.672), train_loss = 2.11481618, grad/param norm = 2.4976e-01, time/batch = 0.6349s	
1096/32750 (epoch 1.673), train_loss = 2.19567442, grad/param norm = 2.3864e-01, time/batch = 0.6493s	
1097/32750 (epoch 1.675), train_loss = 2.26773500, grad/param norm = 2.3678e-01, time/batch = 0.6504s	
1098/32750 (epoch 1.676), train_loss = 2.18478809, grad/param norm = 2.3999e-01, time/batch = 0.6428s	
1099/32750 (epoch 1.678), train_loss = 2.24435371, grad/param norm = 2.2550e-01, time/batch = 0.6460s	
1100/32750 (epoch 1.679), train_loss = 2.20575426, grad/param norm = 2.6948e-01, time/batch = 0.6343s	
1101/32750 (epoch 1.681), train_loss = 2.19873394, grad/param norm = 2.3500e-01, time/batch = 0.6426s	
1102/32750 (epoch 1.682), train_loss = 2.27200225, grad/param norm = 2.5925e-01, time/batch = 0.6488s	
1103/32750 (epoch 1.684), train_loss = 2.22760578, grad/param norm = 2.3650e-01, time/batch = 0.6355s	
1104/32750 (epoch 1.685), train_loss = 2.22893415, grad/param norm = 2.1096e-01, time/batch = 0.6362s	
1105/32750 (epoch 1.687), train_loss = 2.15905954, grad/param norm = 2.3622e-01, time/batch = 0.6466s	
1106/32750 (epoch 1.689), train_loss = 2.24133430, grad/param norm = 2.2322e-01, time/batch = 0.6584s	
1107/32750 (epoch 1.690), train_loss = 2.08690995, grad/param norm = 2.4550e-01, time/batch = 0.6730s	
1108/32750 (epoch 1.692), train_loss = 2.32887454, grad/param norm = 2.4915e-01, time/batch = 0.6524s	
1109/32750 (epoch 1.693), train_loss = 2.18127219, grad/param norm = 2.3428e-01, time/batch = 0.6327s	
1110/32750 (epoch 1.695), train_loss = 2.08593296, grad/param norm = 3.2025e-01, time/batch = 0.6351s	
1111/32750 (epoch 1.696), train_loss = 2.18971566, grad/param norm = 2.9092e-01, time/batch = 0.6527s	
1112/32750 (epoch 1.698), train_loss = 2.25833143, grad/param norm = 2.5785e-01, time/batch = 0.6373s	
1113/32750 (epoch 1.699), train_loss = 2.23539238, grad/param norm = 2.7798e-01, time/batch = 0.6326s	
1114/32750 (epoch 1.701), train_loss = 2.09821840, grad/param norm = 2.3782e-01, time/batch = 0.6333s	
1115/32750 (epoch 1.702), train_loss = 2.17338805, grad/param norm = 2.7226e-01, time/batch = 0.6321s	
1116/32750 (epoch 1.704), train_loss = 2.31988557, grad/param norm = 2.3440e-01, time/batch = 0.6308s	
1117/32750 (epoch 1.705), train_loss = 2.38186129, grad/param norm = 2.4721e-01, time/batch = 0.6325s	
1118/32750 (epoch 1.707), train_loss = 2.23405636, grad/param norm = 2.5981e-01, time/batch = 0.6340s	
1119/32750 (epoch 1.708), train_loss = 2.20813808, grad/param norm = 2.6206e-01, time/batch = 0.6308s	
1120/32750 (epoch 1.710), train_loss = 2.16208143, grad/param norm = 2.5881e-01, time/batch = 0.6325s	
1121/32750 (epoch 1.711), train_loss = 2.29840240, grad/param norm = 2.1955e-01, time/batch = 0.6316s	
1122/32750 (epoch 1.713), train_loss = 2.24481667, grad/param norm = 2.3515e-01, time/batch = 0.6346s	
1123/32750 (epoch 1.715), train_loss = 2.16603561, grad/param norm = 2.2749e-01, time/batch = 0.6410s	
1124/32750 (epoch 1.716), train_loss = 2.25350236, grad/param norm = 2.3990e-01, time/batch = 0.6312s	
1125/32750 (epoch 1.718), train_loss = 2.19996650, grad/param norm = 2.3088e-01, time/batch = 0.6310s	
1126/32750 (epoch 1.719), train_loss = 2.25798177, grad/param norm = 2.2699e-01, time/batch = 0.6329s	
1127/32750 (epoch 1.721), train_loss = 2.20941129, grad/param norm = 2.6124e-01, time/batch = 0.6613s	
1128/32750 (epoch 1.722), train_loss = 2.30065645, grad/param norm = 2.9304e-01, time/batch = 0.6638s	
1129/32750 (epoch 1.724), train_loss = 2.28006903, grad/param norm = 2.4430e-01, time/batch = 0.6310s	
1130/32750 (epoch 1.725), train_loss = 2.12198604, grad/param norm = 2.4250e-01, time/batch = 0.6306s	
1131/32750 (epoch 1.727), train_loss = 2.13689962, grad/param norm = 2.7647e-01, time/batch = 0.6330s	
1132/32750 (epoch 1.728), train_loss = 2.15477102, grad/param norm = 2.4913e-01, time/batch = 0.6395s	
1133/32750 (epoch 1.730), train_loss = 2.09641105, grad/param norm = 2.5012e-01, time/batch = 0.6341s	
1134/32750 (epoch 1.731), train_loss = 2.23750199, grad/param norm = 2.3629e-01, time/batch = 0.6346s	
1135/32750 (epoch 1.733), train_loss = 2.24644173, grad/param norm = 2.6547e-01, time/batch = 0.6317s	
1136/32750 (epoch 1.734), train_loss = 2.13191017, grad/param norm = 3.1646e-01, time/batch = 0.6353s	
1137/32750 (epoch 1.736), train_loss = 2.17305770, grad/param norm = 2.1249e-01, time/batch = 0.6332s	
1138/32750 (epoch 1.737), train_loss = 2.08132135, grad/param norm = 2.1156e-01, time/batch = 0.6330s	
1139/32750 (epoch 1.739), train_loss = 2.21567038, grad/param norm = 2.7748e-01, time/batch = 0.6327s	
1140/32750 (epoch 1.740), train_loss = 2.28776044, grad/param norm = 3.8645e-01, time/batch = 0.6358s	
1141/32750 (epoch 1.742), train_loss = 2.20762117, grad/param norm = 3.1104e-01, time/batch = 0.6400s	
1142/32750 (epoch 1.744), train_loss = 2.11621302, grad/param norm = 2.2803e-01, time/batch = 0.6416s	
1143/32750 (epoch 1.745), train_loss = 2.20824042, grad/param norm = 2.3458e-01, time/batch = 0.6393s	
1144/32750 (epoch 1.747), train_loss = 2.18906377, grad/param norm = 2.3127e-01, time/batch = 0.6348s	
1145/32750 (epoch 1.748), train_loss = 2.15939759, grad/param norm = 2.1005e-01, time/batch = 0.6358s	
1146/32750 (epoch 1.750), train_loss = 2.20645314, grad/param norm = 2.3056e-01, time/batch = 0.6461s	
1147/32750 (epoch 1.751), train_loss = 2.25856513, grad/param norm = 2.8513e-01, time/batch = 0.6510s	
1148/32750 (epoch 1.753), train_loss = 2.22927022, grad/param norm = 3.0957e-01, time/batch = 0.6492s	
1149/32750 (epoch 1.754), train_loss = 2.25680820, grad/param norm = 2.3784e-01, time/batch = 0.6496s	
1150/32750 (epoch 1.756), train_loss = 2.35139713, grad/param norm = 2.4570e-01, time/batch = 0.6540s	
1151/32750 (epoch 1.757), train_loss = 2.12985591, grad/param norm = 2.2698e-01, time/batch = 0.6534s	
1152/32750 (epoch 1.759), train_loss = 2.22158464, grad/param norm = 2.2187e-01, time/batch = 0.6509s	
1153/32750 (epoch 1.760), train_loss = 2.25674950, grad/param norm = 2.1354e-01, time/batch = 0.6614s	
1154/32750 (epoch 1.762), train_loss = 2.27917525, grad/param norm = 2.3186e-01, time/batch = 0.6753s	
1155/32750 (epoch 1.763), train_loss = 2.18541627, grad/param norm = 2.2035e-01, time/batch = 0.6554s	
1156/32750 (epoch 1.765), train_loss = 2.19935137, grad/param norm = 2.1741e-01, time/batch = 0.6718s	
1157/32750 (epoch 1.766), train_loss = 2.28576511, grad/param norm = 2.5024e-01, time/batch = 0.6626s	
1158/32750 (epoch 1.768), train_loss = 2.16310211, grad/param norm = 2.5494e-01, time/batch = 0.6635s	
1159/32750 (epoch 1.769), train_loss = 2.15925161, grad/param norm = 2.6726e-01, time/batch = 0.6693s	
1160/32750 (epoch 1.771), train_loss = 2.24773049, grad/param norm = 2.6007e-01, time/batch = 0.6529s	
1161/32750 (epoch 1.773), train_loss = 2.05599121, grad/param norm = 2.5526e-01, time/batch = 0.6536s	
1162/32750 (epoch 1.774), train_loss = 2.20220225, grad/param norm = 2.3809e-01, time/batch = 0.6393s	
1163/32750 (epoch 1.776), train_loss = 2.04954274, grad/param norm = 2.3290e-01, time/batch = 0.6406s	
1164/32750 (epoch 1.777), train_loss = 2.18983173, grad/param norm = 2.3499e-01, time/batch = 0.6428s	
1165/32750 (epoch 1.779), train_loss = 2.08977342, grad/param norm = 2.0806e-01, time/batch = 0.6323s	
1166/32750 (epoch 1.780), train_loss = 2.32971698, grad/param norm = 3.1754e-01, time/batch = 0.6310s	
1167/32750 (epoch 1.782), train_loss = 2.33733191, grad/param norm = 3.4581e-01, time/batch = 0.6306s	
1168/32750 (epoch 1.783), train_loss = 2.22156667, grad/param norm = 3.0813e-01, time/batch = 0.6326s	
1169/32750 (epoch 1.785), train_loss = 2.14779767, grad/param norm = 2.0627e-01, time/batch = 0.6729s	
1170/32750 (epoch 1.786), train_loss = 2.22316435, grad/param norm = 2.2131e-01, time/batch = 0.6511s	
1171/32750 (epoch 1.788), train_loss = 2.31192268, grad/param norm = 2.0935e-01, time/batch = 0.6320s	
1172/32750 (epoch 1.789), train_loss = 2.24995975, grad/param norm = 2.2610e-01, time/batch = 0.6335s	
1173/32750 (epoch 1.791), train_loss = 2.27822267, grad/param norm = 2.2860e-01, time/batch = 0.6396s	
1174/32750 (epoch 1.792), train_loss = 2.14031047, grad/param norm = 2.5120e-01, time/batch = 0.6608s	
1175/32750 (epoch 1.794), train_loss = 2.20455826, grad/param norm = 2.4162e-01, time/batch = 0.6410s	
1176/32750 (epoch 1.795), train_loss = 2.29687110, grad/param norm = 2.9724e-01, time/batch = 0.6447s	
1177/32750 (epoch 1.797), train_loss = 2.08484824, grad/param norm = 3.3505e-01, time/batch = 0.6364s	
1178/32750 (epoch 1.798), train_loss = 2.22178113, grad/param norm = 2.5835e-01, time/batch = 0.6379s	
1179/32750 (epoch 1.800), train_loss = 2.12756755, grad/param norm = 2.5212e-01, time/batch = 0.6364s	
1180/32750 (epoch 1.802), train_loss = 2.26218588, grad/param norm = 2.2202e-01, time/batch = 0.6381s	
1181/32750 (epoch 1.803), train_loss = 2.31216953, grad/param norm = 2.2142e-01, time/batch = 0.6375s	
1182/32750 (epoch 1.805), train_loss = 2.24375184, grad/param norm = 2.6456e-01, time/batch = 0.6429s	
1183/32750 (epoch 1.806), train_loss = 2.22111993, grad/param norm = 2.1558e-01, time/batch = 0.6355s	
1184/32750 (epoch 1.808), train_loss = 2.32507280, grad/param norm = 2.3044e-01, time/batch = 0.6551s	
1185/32750 (epoch 1.809), train_loss = 2.20068486, grad/param norm = 2.3092e-01, time/batch = 0.6704s	
1186/32750 (epoch 1.811), train_loss = 2.38413488, grad/param norm = 2.4364e-01, time/batch = 0.6328s	
1187/32750 (epoch 1.812), train_loss = 2.07901615, grad/param norm = 2.2871e-01, time/batch = 0.6330s	
1188/32750 (epoch 1.814), train_loss = 2.22468870, grad/param norm = 2.2274e-01, time/batch = 0.6429s	
1189/32750 (epoch 1.815), train_loss = 2.34303564, grad/param norm = 2.5295e-01, time/batch = 0.6587s	
1190/32750 (epoch 1.817), train_loss = 2.31101343, grad/param norm = 2.4577e-01, time/batch = 0.6350s	
1191/32750 (epoch 1.818), train_loss = 2.06149114, grad/param norm = 2.3967e-01, time/batch = 0.6482s	
1192/32750 (epoch 1.820), train_loss = 2.09465690, grad/param norm = 2.3240e-01, time/batch = 0.6411s	
1193/32750 (epoch 1.821), train_loss = 2.25124839, grad/param norm = 2.2271e-01, time/batch = 0.6357s	
1194/32750 (epoch 1.823), train_loss = 2.16202212, grad/param norm = 2.1547e-01, time/batch = 0.6353s	
1195/32750 (epoch 1.824), train_loss = 2.21394316, grad/param norm = 2.6018e-01, time/batch = 0.6400s	
1196/32750 (epoch 1.826), train_loss = 2.36046600, grad/param norm = 2.1649e-01, time/batch = 0.6355s	
1197/32750 (epoch 1.827), train_loss = 2.27261433, grad/param norm = 2.2071e-01, time/batch = 0.6333s	
1198/32750 (epoch 1.829), train_loss = 2.37801686, grad/param norm = 2.2445e-01, time/batch = 0.6324s	
1199/32750 (epoch 1.831), train_loss = 1.93787993, grad/param norm = 2.2332e-01, time/batch = 0.6315s	
1200/32750 (epoch 1.832), train_loss = 2.18383551, grad/param norm = 3.0632e-01, time/batch = 0.6728s	
1201/32750 (epoch 1.834), train_loss = 2.16877886, grad/param norm = 2.7208e-01, time/batch = 0.6549s	
1202/32750 (epoch 1.835), train_loss = 2.07019987, grad/param norm = 3.0947e-01, time/batch = 0.6348s	
1203/32750 (epoch 1.837), train_loss = 2.30301127, grad/param norm = 2.1710e-01, time/batch = 0.6341s	
1204/32750 (epoch 1.838), train_loss = 2.10634367, grad/param norm = 2.1429e-01, time/batch = 0.6339s	
1205/32750 (epoch 1.840), train_loss = 2.08673676, grad/param norm = 2.1055e-01, time/batch = 0.6405s	
1206/32750 (epoch 1.841), train_loss = 2.24338348, grad/param norm = 2.4242e-01, time/batch = 0.6387s	
1207/32750 (epoch 1.843), train_loss = 2.28390878, grad/param norm = 2.2288e-01, time/batch = 0.6334s	
1208/32750 (epoch 1.844), train_loss = 2.29178404, grad/param norm = 2.3616e-01, time/batch = 0.6349s	
1209/32750 (epoch 1.846), train_loss = 2.15200458, grad/param norm = 2.2872e-01, time/batch = 0.6329s	
1210/32750 (epoch 1.847), train_loss = 2.07552214, grad/param norm = 2.5387e-01, time/batch = 0.6325s	
1211/32750 (epoch 1.849), train_loss = 2.20413421, grad/param norm = 2.7064e-01, time/batch = 0.6358s	
1212/32750 (epoch 1.850), train_loss = 2.30704765, grad/param norm = 2.3923e-01, time/batch = 0.6343s	
1213/32750 (epoch 1.852), train_loss = 2.08568760, grad/param norm = 2.3260e-01, time/batch = 0.6361s	
1214/32750 (epoch 1.853), train_loss = 2.23820298, grad/param norm = 2.3750e-01, time/batch = 0.6532s	
1215/32750 (epoch 1.855), train_loss = 2.20822929, grad/param norm = 2.2243e-01, time/batch = 0.6622s	
1216/32750 (epoch 1.856), train_loss = 2.21331235, grad/param norm = 2.5319e-01, time/batch = 0.6734s	
1217/32750 (epoch 1.858), train_loss = 2.16519374, grad/param norm = 2.7719e-01, time/batch = 0.6314s	
1218/32750 (epoch 1.860), train_loss = 2.11318306, grad/param norm = 2.4654e-01, time/batch = 0.6316s	
1219/32750 (epoch 1.861), train_loss = 2.12518916, grad/param norm = 2.3759e-01, time/batch = 0.6310s	
1220/32750 (epoch 1.863), train_loss = 2.31266587, grad/param norm = 2.2948e-01, time/batch = 0.6506s	
1221/32750 (epoch 1.864), train_loss = 2.19367990, grad/param norm = 2.6958e-01, time/batch = 0.6452s	
1222/32750 (epoch 1.866), train_loss = 2.09676836, grad/param norm = 2.2330e-01, time/batch = 0.6409s	
1223/32750 (epoch 1.867), train_loss = 2.05797640, grad/param norm = 2.4086e-01, time/batch = 0.6366s	
1224/32750 (epoch 1.869), train_loss = 2.20162865, grad/param norm = 2.5677e-01, time/batch = 0.6337s	
1225/32750 (epoch 1.870), train_loss = 2.16009459, grad/param norm = 2.4358e-01, time/batch = 0.6379s	
1226/32750 (epoch 1.872), train_loss = 2.21631875, grad/param norm = 2.3644e-01, time/batch = 0.6416s	
1227/32750 (epoch 1.873), train_loss = 2.15497308, grad/param norm = 2.1767e-01, time/batch = 0.6351s	
1228/32750 (epoch 1.875), train_loss = 2.29789014, grad/param norm = 2.5111e-01, time/batch = 0.6316s	
1229/32750 (epoch 1.876), train_loss = 2.34375327, grad/param norm = 2.8871e-01, time/batch = 0.6386s	
1230/32750 (epoch 1.878), train_loss = 2.09578980, grad/param norm = 2.4836e-01, time/batch = 0.6317s	
1231/32750 (epoch 1.879), train_loss = 2.15311162, grad/param norm = 2.2296e-01, time/batch = 0.6733s	
1232/32750 (epoch 1.881), train_loss = 2.24108970, grad/param norm = 2.9640e-01, time/batch = 0.6539s	
1233/32750 (epoch 1.882), train_loss = 2.07838330, grad/param norm = 2.7863e-01, time/batch = 0.6325s	
1234/32750 (epoch 1.884), train_loss = 2.25495301, grad/param norm = 2.4155e-01, time/batch = 0.6308s	
1235/32750 (epoch 1.885), train_loss = 2.20093343, grad/param norm = 2.0554e-01, time/batch = 0.6318s	
1236/32750 (epoch 1.887), train_loss = 2.28250616, grad/param norm = 2.6763e-01, time/batch = 0.6375s	
1237/32750 (epoch 1.889), train_loss = 2.20441766, grad/param norm = 2.0823e-01, time/batch = 0.6332s	
1238/32750 (epoch 1.890), train_loss = 2.12706868, grad/param norm = 2.2910e-01, time/batch = 0.6337s	
1239/32750 (epoch 1.892), train_loss = 2.36003044, grad/param norm = 2.5839e-01, time/batch = 0.6326s	
1240/32750 (epoch 1.893), train_loss = 2.35398991, grad/param norm = 3.0640e-01, time/batch = 0.6341s	
1241/32750 (epoch 1.895), train_loss = 2.08728546, grad/param norm = 2.0671e-01, time/batch = 0.6355s	
1242/32750 (epoch 1.896), train_loss = 2.15086908, grad/param norm = 2.2407e-01, time/batch = 0.6361s	
1243/32750 (epoch 1.898), train_loss = 2.28787258, grad/param norm = 2.5707e-01, time/batch = 0.6328s	
1244/32750 (epoch 1.899), train_loss = 2.23290254, grad/param norm = 2.4982e-01, time/batch = 0.6348s	
1245/32750 (epoch 1.901), train_loss = 2.21552552, grad/param norm = 2.3741e-01, time/batch = 0.6332s	
1246/32750 (epoch 1.902), train_loss = 2.18298716, grad/param norm = 2.2048e-01, time/batch = 0.6477s	
1247/32750 (epoch 1.904), train_loss = 2.07692199, grad/param norm = 2.2544e-01, time/batch = 0.6730s	
1248/32750 (epoch 1.905), train_loss = 2.25124442, grad/param norm = 2.5889e-01, time/batch = 0.6385s	
1249/32750 (epoch 1.907), train_loss = 2.35496350, grad/param norm = 2.3395e-01, time/batch = 0.6315s	
1250/32750 (epoch 1.908), train_loss = 2.33625357, grad/param norm = 2.0633e-01, time/batch = 0.6308s	
1251/32750 (epoch 1.910), train_loss = 2.11368654, grad/param norm = 2.2467e-01, time/batch = 0.6362s	
1252/32750 (epoch 1.911), train_loss = 2.16680984, grad/param norm = 2.2459e-01, time/batch = 0.6524s	
1253/32750 (epoch 1.913), train_loss = 2.09844193, grad/param norm = 2.1373e-01, time/batch = 0.6583s	
1254/32750 (epoch 1.915), train_loss = 2.05752914, grad/param norm = 2.2293e-01, time/batch = 0.6448s	
1255/32750 (epoch 1.916), train_loss = 2.19435693, grad/param norm = 2.4247e-01, time/batch = 0.6480s	
1256/32750 (epoch 1.918), train_loss = 2.37828021, grad/param norm = 3.2217e-01, time/batch = 0.6428s	
1257/32750 (epoch 1.919), train_loss = 2.32246194, grad/param norm = 2.8386e-01, time/batch = 0.6609s	
1258/32750 (epoch 1.921), train_loss = 2.22954117, grad/param norm = 2.3132e-01, time/batch = 0.6529s	
1259/32750 (epoch 1.922), train_loss = 2.12191340, grad/param norm = 2.1106e-01, time/batch = 0.6448s	
1260/32750 (epoch 1.924), train_loss = 2.17376953, grad/param norm = 2.4643e-01, time/batch = 0.6447s	
1261/32750 (epoch 1.925), train_loss = 2.19308303, grad/param norm = 2.4103e-01, time/batch = 0.6459s	
1262/32750 (epoch 1.927), train_loss = 2.28258026, grad/param norm = 2.6245e-01, time/batch = 0.6746s	
1263/32750 (epoch 1.928), train_loss = 2.27259941, grad/param norm = 2.2467e-01, time/batch = 0.6599s	
1264/32750 (epoch 1.930), train_loss = 2.17206109, grad/param norm = 2.3746e-01, time/batch = 0.6454s	
1265/32750 (epoch 1.931), train_loss = 2.14676233, grad/param norm = 2.0398e-01, time/batch = 0.6434s	
1266/32750 (epoch 1.933), train_loss = 2.21992976, grad/param norm = 2.3171e-01, time/batch = 0.6482s	
1267/32750 (epoch 1.934), train_loss = 2.12676395, grad/param norm = 2.3531e-01, time/batch = 0.6484s	
1268/32750 (epoch 1.936), train_loss = 2.30468392, grad/param norm = 2.7482e-01, time/batch = 0.6430s	
1269/32750 (epoch 1.937), train_loss = 2.13710913, grad/param norm = 2.0822e-01, time/batch = 0.6523s	
1270/32750 (epoch 1.939), train_loss = 2.23513879, grad/param norm = 2.1574e-01, time/batch = 0.6474s	
1271/32750 (epoch 1.940), train_loss = 2.21066718, grad/param norm = 2.4704e-01, time/batch = 0.6354s	
1272/32750 (epoch 1.942), train_loss = 2.07853878, grad/param norm = 2.7926e-01, time/batch = 0.6380s	
1273/32750 (epoch 1.944), train_loss = 2.20829218, grad/param norm = 2.2986e-01, time/batch = 0.6330s	
1274/32750 (epoch 1.945), train_loss = 2.12231082, grad/param norm = 2.2892e-01, time/batch = 0.6322s	
1275/32750 (epoch 1.947), train_loss = 2.20994180, grad/param norm = 2.3423e-01, time/batch = 0.6350s	
1276/32750 (epoch 1.948), train_loss = 2.15507702, grad/param norm = 2.4180e-01, time/batch = 0.6372s	
1277/32750 (epoch 1.950), train_loss = 2.15986005, grad/param norm = 2.3676e-01, time/batch = 0.6548s	
1278/32750 (epoch 1.951), train_loss = 2.13045578, grad/param norm = 2.1973e-01, time/batch = 0.6714s	
1279/32750 (epoch 1.953), train_loss = 2.07010454, grad/param norm = 2.3619e-01, time/batch = 0.6326s	
1280/32750 (epoch 1.954), train_loss = 2.17560921, grad/param norm = 1.9492e-01, time/batch = 0.6333s	
1281/32750 (epoch 1.956), train_loss = 2.25149828, grad/param norm = 2.5918e-01, time/batch = 0.6409s	
1282/32750 (epoch 1.957), train_loss = 2.15224741, grad/param norm = 2.5586e-01, time/batch = 0.6544s	
1283/32750 (epoch 1.959), train_loss = 2.11268447, grad/param norm = 2.6617e-01, time/batch = 0.6405s	
1284/32750 (epoch 1.960), train_loss = 2.16339297, grad/param norm = 2.9938e-01, time/batch = 0.6477s	
1285/32750 (epoch 1.962), train_loss = 2.15288269, grad/param norm = 2.6736e-01, time/batch = 0.6407s	
1286/32750 (epoch 1.963), train_loss = 2.19128076, grad/param norm = 2.3910e-01, time/batch = 0.6391s	
1287/32750 (epoch 1.965), train_loss = 2.26050092, grad/param norm = 2.2968e-01, time/batch = 0.6333s	
1288/32750 (epoch 1.966), train_loss = 2.26458196, grad/param norm = 2.4557e-01, time/batch = 0.6402s	
1289/32750 (epoch 1.968), train_loss = 2.06283721, grad/param norm = 2.4743e-01, time/batch = 0.6360s	
1290/32750 (epoch 1.969), train_loss = 2.05127357, grad/param norm = 2.0610e-01, time/batch = 0.6369s	
1291/32750 (epoch 1.971), train_loss = 2.22343670, grad/param norm = 2.3201e-01, time/batch = 0.6375s	
1292/32750 (epoch 1.973), train_loss = 2.25146009, grad/param norm = 2.4787e-01, time/batch = 0.6365s	
1293/32750 (epoch 1.974), train_loss = 2.21053029, grad/param norm = 2.3186e-01, time/batch = 0.6735s	
1294/32750 (epoch 1.976), train_loss = 2.22889097, grad/param norm = 2.1853e-01, time/batch = 0.6598s	
1295/32750 (epoch 1.977), train_loss = 2.35796622, grad/param norm = 2.4432e-01, time/batch = 0.6372s	
1296/32750 (epoch 1.979), train_loss = 2.16582981, grad/param norm = 2.7587e-01, time/batch = 0.6362s	
1297/32750 (epoch 1.980), train_loss = 2.21813916, grad/param norm = 2.1200e-01, time/batch = 0.6411s	
1298/32750 (epoch 1.982), train_loss = 2.19310003, grad/param norm = 2.1211e-01, time/batch = 0.6369s	
1299/32750 (epoch 1.983), train_loss = 2.09816652, grad/param norm = 2.3073e-01, time/batch = 0.6325s	
1300/32750 (epoch 1.985), train_loss = 2.02391225, grad/param norm = 2.3114e-01, time/batch = 0.6332s	
1301/32750 (epoch 1.986), train_loss = 2.02544332, grad/param norm = 2.5301e-01, time/batch = 0.6341s	
1302/32750 (epoch 1.988), train_loss = 2.12785913, grad/param norm = 2.3705e-01, time/batch = 0.6350s	
1303/32750 (epoch 1.989), train_loss = 2.18025973, grad/param norm = 2.5747e-01, time/batch = 0.6325s	
1304/32750 (epoch 1.991), train_loss = 2.20981237, grad/param norm = 2.1217e-01, time/batch = 0.6348s	
1305/32750 (epoch 1.992), train_loss = 2.10827951, grad/param norm = 2.1921e-01, time/batch = 0.6488s	
1306/32750 (epoch 1.994), train_loss = 2.21179806, grad/param norm = 2.1484e-01, time/batch = 0.6362s	
1307/32750 (epoch 1.995), train_loss = 2.14737490, grad/param norm = 2.0366e-01, time/batch = 0.6320s	
1308/32750 (epoch 1.997), train_loss = 2.21585137, grad/param norm = 2.2156e-01, time/batch = 0.6320s	
1309/32750 (epoch 1.998), train_loss = 2.22480483, grad/param norm = 2.3061e-01, time/batch = 0.6314s	
1310/32750 (epoch 2.000), train_loss = 2.08076082, grad/param norm = 2.0947e-01, time/batch = 0.6321s	
1311/32750 (epoch 2.002), train_loss = 2.22255832, grad/param norm = 2.2862e-01, time/batch = 0.6341s	
1312/32750 (epoch 2.003), train_loss = 2.14591472, grad/param norm = 2.2955e-01, time/batch = 0.6407s	
1313/32750 (epoch 2.005), train_loss = 2.26742763, grad/param norm = 2.7674e-01, time/batch = 0.6403s	
1314/32750 (epoch 2.006), train_loss = 2.33328502, grad/param norm = 2.7593e-01, time/batch = 0.6364s	
1315/32750 (epoch 2.008), train_loss = 2.28376190, grad/param norm = 2.2616e-01, time/batch = 0.6330s	
1316/32750 (epoch 2.009), train_loss = 2.09069457, grad/param norm = 2.0130e-01, time/batch = 0.6323s	
1317/32750 (epoch 2.011), train_loss = 2.01358111, grad/param norm = 2.5876e-01, time/batch = 0.6345s	
1318/32750 (epoch 2.012), train_loss = 2.23904190, grad/param norm = 2.6053e-01, time/batch = 0.6326s	
1319/32750 (epoch 2.014), train_loss = 2.36697730, grad/param norm = 2.1851e-01, time/batch = 0.6405s	
1320/32750 (epoch 2.015), train_loss = 2.24798271, grad/param norm = 2.2044e-01, time/batch = 0.6335s	
1321/32750 (epoch 2.017), train_loss = 2.08365680, grad/param norm = 2.3205e-01, time/batch = 0.6339s	
1322/32750 (epoch 2.018), train_loss = 2.23328926, grad/param norm = 2.6046e-01, time/batch = 0.6359s	
1323/32750 (epoch 2.020), train_loss = 2.19490989, grad/param norm = 2.5904e-01, time/batch = 0.6328s	
1324/32750 (epoch 2.021), train_loss = 2.10434036, grad/param norm = 2.4622e-01, time/batch = 0.6658s	
1325/32750 (epoch 2.023), train_loss = 2.04605674, grad/param norm = 2.4635e-01, time/batch = 0.6596s	
1326/32750 (epoch 2.024), train_loss = 2.26246094, grad/param norm = 2.2782e-01, time/batch = 0.6366s	
1327/32750 (epoch 2.026), train_loss = 2.10304641, grad/param norm = 2.3425e-01, time/batch = 0.6337s	
1328/32750 (epoch 2.027), train_loss = 2.21588389, grad/param norm = 2.1870e-01, time/batch = 0.6328s	
1329/32750 (epoch 2.029), train_loss = 2.14884080, grad/param norm = 2.2052e-01, time/batch = 0.6363s	
1330/32750 (epoch 2.031), train_loss = 2.16045505, grad/param norm = 2.4790e-01, time/batch = 0.6476s	
1331/32750 (epoch 2.032), train_loss = 2.16517634, grad/param norm = 2.8621e-01, time/batch = 0.6559s	
1332/32750 (epoch 2.034), train_loss = 2.16995011, grad/param norm = 2.3300e-01, time/batch = 0.6544s	
1333/32750 (epoch 2.035), train_loss = 2.03490805, grad/param norm = 1.9731e-01, time/batch = 0.6432s	
1334/32750 (epoch 2.037), train_loss = 2.19172458, grad/param norm = 2.0733e-01, time/batch = 0.6337s	
1335/32750 (epoch 2.038), train_loss = 2.27245873, grad/param norm = 2.2642e-01, time/batch = 0.6363s	
1336/32750 (epoch 2.040), train_loss = 2.25739336, grad/param norm = 2.3657e-01, time/batch = 0.6353s	
1337/32750 (epoch 2.041), train_loss = 2.19624839, grad/param norm = 2.4163e-01, time/batch = 0.6344s	
1338/32750 (epoch 2.043), train_loss = 2.18473978, grad/param norm = 2.2219e-01, time/batch = 0.6351s	
1339/32750 (epoch 2.044), train_loss = 2.05700048, grad/param norm = 2.2033e-01, time/batch = 0.6467s	
1340/32750 (epoch 2.046), train_loss = 2.17534833, grad/param norm = 2.1697e-01, time/batch = 0.6732s	
1341/32750 (epoch 2.047), train_loss = 2.10407573, grad/param norm = 2.7966e-01, time/batch = 0.6426s	
1342/32750 (epoch 2.049), train_loss = 2.08300930, grad/param norm = 2.6339e-01, time/batch = 0.6345s	
1343/32750 (epoch 2.050), train_loss = 1.97698540, grad/param norm = 2.6661e-01, time/batch = 0.6327s	
1344/32750 (epoch 2.052), train_loss = 2.03691743, grad/param norm = 2.1995e-01, time/batch = 0.6449s	
1345/32750 (epoch 2.053), train_loss = 2.14980205, grad/param norm = 2.1269e-01, time/batch = 0.6339s	
1346/32750 (epoch 2.055), train_loss = 2.24584860, grad/param norm = 2.3305e-01, time/batch = 0.6345s	
1347/32750 (epoch 2.056), train_loss = 2.23341678, grad/param norm = 2.3236e-01, time/batch = 0.6480s	
1348/32750 (epoch 2.058), train_loss = 2.07028519, grad/param norm = 2.4041e-01, time/batch = 0.6375s	
1349/32750 (epoch 2.060), train_loss = 2.06837767, grad/param norm = 2.4396e-01, time/batch = 0.6339s	
1350/32750 (epoch 2.061), train_loss = 2.26203509, grad/param norm = 1.9927e-01, time/batch = 0.6344s	
1351/32750 (epoch 2.063), train_loss = 2.21119699, grad/param norm = 2.3765e-01, time/batch = 0.6377s	
1352/32750 (epoch 2.064), train_loss = 2.13967522, grad/param norm = 2.6162e-01, time/batch = 0.6359s	
1353/32750 (epoch 2.066), train_loss = 2.01365652, grad/param norm = 2.4579e-01, time/batch = 0.6356s	
1354/32750 (epoch 2.067), train_loss = 2.17724208, grad/param norm = 2.1074e-01, time/batch = 0.6345s	
1355/32750 (epoch 2.069), train_loss = 2.37239557, grad/param norm = 2.5966e-01, time/batch = 0.6356s	
1356/32750 (epoch 2.070), train_loss = 2.15348496, grad/param norm = 2.2665e-01, time/batch = 0.6360s	
1357/32750 (epoch 2.072), train_loss = 2.13935661, grad/param norm = 2.2494e-01, time/batch = 0.6335s	
1358/32750 (epoch 2.073), train_loss = 1.98533657, grad/param norm = 2.0466e-01, time/batch = 0.6339s	
1359/32750 (epoch 2.075), train_loss = 2.06668611, grad/param norm = 2.2209e-01, time/batch = 0.6338s	
1360/32750 (epoch 2.076), train_loss = 2.33945784, grad/param norm = 2.3806e-01, time/batch = 0.6365s	
1361/32750 (epoch 2.078), train_loss = 2.25835739, grad/param norm = 2.4465e-01, time/batch = 0.6361s	
1362/32750 (epoch 2.079), train_loss = 2.22949076, grad/param norm = 2.3344e-01, time/batch = 0.6342s	
1363/32750 (epoch 2.081), train_loss = 2.04789616, grad/param norm = 2.2669e-01, time/batch = 0.6328s	
1364/32750 (epoch 2.082), train_loss = 2.08930282, grad/param norm = 2.2279e-01, time/batch = 0.6334s	
1365/32750 (epoch 2.084), train_loss = 2.10359325, grad/param norm = 2.1239e-01, time/batch = 0.6332s	
1366/32750 (epoch 2.085), train_loss = 2.03658409, grad/param norm = 2.2103e-01, time/batch = 0.6369s	
1367/32750 (epoch 2.087), train_loss = 2.17958903, grad/param norm = 2.1484e-01, time/batch = 0.6347s	
1368/32750 (epoch 2.089), train_loss = 2.17191841, grad/param norm = 2.0710e-01, time/batch = 0.6425s	
1369/32750 (epoch 2.090), train_loss = 2.16673022, grad/param norm = 2.3698e-01, time/batch = 0.6369s	
1370/32750 (epoch 2.092), train_loss = 2.04738533, grad/param norm = 2.4751e-01, time/batch = 0.6332s	
1371/32750 (epoch 2.093), train_loss = 2.14335898, grad/param norm = 2.2752e-01, time/batch = 0.6328s	
1372/32750 (epoch 2.095), train_loss = 2.15363865, grad/param norm = 2.0942e-01, time/batch = 0.6333s	
1373/32750 (epoch 2.096), train_loss = 2.13451058, grad/param norm = 2.2655e-01, time/batch = 0.6413s	
1374/32750 (epoch 2.098), train_loss = 2.17890221, grad/param norm = 2.2365e-01, time/batch = 0.6388s	
1375/32750 (epoch 2.099), train_loss = 2.15390665, grad/param norm = 2.4074e-01, time/batch = 0.6497s	
1376/32750 (epoch 2.101), train_loss = 2.08849435, grad/param norm = 2.2481e-01, time/batch = 0.6405s	
1377/32750 (epoch 2.102), train_loss = 2.16609177, grad/param norm = 2.1909e-01, time/batch = 0.6620s	
1378/32750 (epoch 2.104), train_loss = 2.16049939, grad/param norm = 2.0682e-01, time/batch = 0.6697s	
1379/32750 (epoch 2.105), train_loss = 2.11092538, grad/param norm = 2.3033e-01, time/batch = 0.6430s	
1380/32750 (epoch 2.107), train_loss = 2.13016532, grad/param norm = 2.9436e-01, time/batch = 0.6348s	
1381/32750 (epoch 2.108), train_loss = 2.32986638, grad/param norm = 2.8536e-01, time/batch = 0.6389s	
1382/32750 (epoch 2.110), train_loss = 2.18396247, grad/param norm = 2.5565e-01, time/batch = 0.6362s	
1383/32750 (epoch 2.111), train_loss = 2.20146988, grad/param norm = 2.1614e-01, time/batch = 0.6336s	
1384/32750 (epoch 2.113), train_loss = 2.18525284, grad/param norm = 2.0901e-01, time/batch = 0.6349s	
1385/32750 (epoch 2.115), train_loss = 2.13356426, grad/param norm = 2.2792e-01, time/batch = 0.6494s	
1386/32750 (epoch 2.116), train_loss = 2.10102178, grad/param norm = 2.3517e-01, time/batch = 0.6650s	
1387/32750 (epoch 2.118), train_loss = 2.13426268, grad/param norm = 1.9914e-01, time/batch = 0.6704s	
1388/32750 (epoch 2.119), train_loss = 2.24960950, grad/param norm = 2.0521e-01, time/batch = 0.6629s	
1389/32750 (epoch 2.121), train_loss = 2.12391730, grad/param norm = 1.8943e-01, time/batch = 0.6542s	
1390/32750 (epoch 2.122), train_loss = 2.05703566, grad/param norm = 2.2644e-01, time/batch = 0.6340s	
1391/32750 (epoch 2.124), train_loss = 2.22317703, grad/param norm = 2.4717e-01, time/batch = 0.6407s	
1392/32750 (epoch 2.125), train_loss = 2.08792786, grad/param norm = 2.5719e-01, time/batch = 0.6344s	
1393/32750 (epoch 2.127), train_loss = 2.24866642, grad/param norm = 2.2580e-01, time/batch = 0.6330s	
1394/32750 (epoch 2.128), train_loss = 2.13088442, grad/param norm = 2.2664e-01, time/batch = 0.6326s	
1395/32750 (epoch 2.130), train_loss = 2.16417336, grad/param norm = 2.4671e-01, time/batch = 0.6359s	
1396/32750 (epoch 2.131), train_loss = 2.18737093, grad/param norm = 2.5867e-01, time/batch = 0.6348s	
1397/32750 (epoch 2.133), train_loss = 2.20016068, grad/param norm = 1.9294e-01, time/batch = 0.6374s	
1398/32750 (epoch 2.134), train_loss = 2.10736547, grad/param norm = 2.1762e-01, time/batch = 0.6344s	
1399/32750 (epoch 2.136), train_loss = 2.30984571, grad/param norm = 2.0727e-01, time/batch = 0.6452s	
1400/32750 (epoch 2.137), train_loss = 2.23186659, grad/param norm = 2.1764e-01, time/batch = 0.6536s	
1401/32750 (epoch 2.139), train_loss = 2.20353576, grad/param norm = 2.1806e-01, time/batch = 0.6597s	
1402/32750 (epoch 2.140), train_loss = 2.06268231, grad/param norm = 2.2614e-01, time/batch = 0.6744s	
1403/32750 (epoch 2.142), train_loss = 2.18221376, grad/param norm = 2.1641e-01, time/batch = 0.6581s	
1404/32750 (epoch 2.144), train_loss = 2.16447748, grad/param norm = 2.3131e-01, time/batch = 0.6434s	
1405/32750 (epoch 2.145), train_loss = 2.06687674, grad/param norm = 2.1530e-01, time/batch = 0.6473s	
1406/32750 (epoch 2.147), train_loss = 1.98694057, grad/param norm = 2.1548e-01, time/batch = 0.6664s	
1407/32750 (epoch 2.148), train_loss = 2.25709340, grad/param norm = 2.4229e-01, time/batch = 0.6586s	
1408/32750 (epoch 2.150), train_loss = 2.09122491, grad/param norm = 2.1601e-01, time/batch = 0.6506s	
1409/32750 (epoch 2.151), train_loss = 2.11134968, grad/param norm = 2.3555e-01, time/batch = 0.6517s	
1410/32750 (epoch 2.153), train_loss = 2.11841530, grad/param norm = 2.1147e-01, time/batch = 0.6402s	
1411/32750 (epoch 2.154), train_loss = 2.15023487, grad/param norm = 2.1234e-01, time/batch = 0.6334s	
1412/32750 (epoch 2.156), train_loss = 2.06244017, grad/param norm = 1.9944e-01, time/batch = 0.6376s	
1413/32750 (epoch 2.157), train_loss = 2.02124190, grad/param norm = 2.3615e-01, time/batch = 0.6341s	
1414/32750 (epoch 2.159), train_loss = 2.01751103, grad/param norm = 2.3707e-01, time/batch = 0.6325s	
1415/32750 (epoch 2.160), train_loss = 2.13844170, grad/param norm = 2.3644e-01, time/batch = 0.6381s	
1416/32750 (epoch 2.162), train_loss = 2.14979768, grad/param norm = 2.0719e-01, time/batch = 0.6315s	
1417/32750 (epoch 2.163), train_loss = 2.16873782, grad/param norm = 2.1352e-01, time/batch = 0.6323s	
1418/32750 (epoch 2.165), train_loss = 2.00796229, grad/param norm = 1.9730e-01, time/batch = 0.6327s	
1419/32750 (epoch 2.166), train_loss = 2.12724200, grad/param norm = 2.1009e-01, time/batch = 0.6323s	
1420/32750 (epoch 2.168), train_loss = 2.22677205, grad/param norm = 2.3031e-01, time/batch = 0.6340s	
1421/32750 (epoch 2.169), train_loss = 2.13180171, grad/param norm = 2.0097e-01, time/batch = 0.6349s	
1422/32750 (epoch 2.171), train_loss = 1.96744844, grad/param norm = 2.3221e-01, time/batch = 0.6424s	
1423/32750 (epoch 2.173), train_loss = 2.30351903, grad/param norm = 2.7876e-01, time/batch = 0.6346s	
1424/32750 (epoch 2.174), train_loss = 2.04733566, grad/param norm = 2.7411e-01, time/batch = 0.6358s	
1425/32750 (epoch 2.176), train_loss = 2.13822999, grad/param norm = 2.0413e-01, time/batch = 0.6346s	
1426/32750 (epoch 2.177), train_loss = 2.38950936, grad/param norm = 2.2874e-01, time/batch = 0.6353s	
1427/32750 (epoch 2.179), train_loss = 2.20568064, grad/param norm = 2.5635e-01, time/batch = 0.6367s	
1428/32750 (epoch 2.180), train_loss = 2.26848594, grad/param norm = 2.2583e-01, time/batch = 0.6350s	
1429/32750 (epoch 2.182), train_loss = 2.05437625, grad/param norm = 2.0796e-01, time/batch = 0.6350s	
1430/32750 (epoch 2.183), train_loss = 2.11680136, grad/param norm = 2.1391e-01, time/batch = 0.6333s	
1431/32750 (epoch 2.185), train_loss = 1.89551765, grad/param norm = 2.5459e-01, time/batch = 0.6392s	
1432/32750 (epoch 2.186), train_loss = 2.10994575, grad/param norm = 2.5091e-01, time/batch = 0.6404s	
1433/32750 (epoch 2.188), train_loss = 2.23701864, grad/param norm = 2.5293e-01, time/batch = 0.6734s	
1434/32750 (epoch 2.189), train_loss = 2.12798709, grad/param norm = 1.8948e-01, time/batch = 0.6471s	
1435/32750 (epoch 2.191), train_loss = 2.16185330, grad/param norm = 1.9912e-01, time/batch = 0.6361s	
1436/32750 (epoch 2.192), train_loss = 2.00902464, grad/param norm = 2.3752e-01, time/batch = 0.6326s	
1437/32750 (epoch 2.194), train_loss = 2.03285009, grad/param norm = 2.2648e-01, time/batch = 0.6332s	
1438/32750 (epoch 2.195), train_loss = 2.02797005, grad/param norm = 1.9985e-01, time/batch = 0.6367s	
1439/32750 (epoch 2.197), train_loss = 2.13040778, grad/param norm = 2.4481e-01, time/batch = 0.6340s	
1440/32750 (epoch 2.198), train_loss = 2.06729458, grad/param norm = 2.4736e-01, time/batch = 0.6346s	
1441/32750 (epoch 2.200), train_loss = 2.10801552, grad/param norm = 2.1916e-01, time/batch = 0.6356s	
1442/32750 (epoch 2.202), train_loss = 2.19762109, grad/param norm = 2.0408e-01, time/batch = 0.6375s	
1443/32750 (epoch 2.203), train_loss = 2.17383213, grad/param norm = 2.3782e-01, time/batch = 0.6352s	
1444/32750 (epoch 2.205), train_loss = 2.08115795, grad/param norm = 2.0575e-01, time/batch = 0.6354s	
1445/32750 (epoch 2.206), train_loss = 2.01959422, grad/param norm = 2.2042e-01, time/batch = 0.6328s	
1446/32750 (epoch 2.208), train_loss = 2.16305284, grad/param norm = 2.1212e-01, time/batch = 0.6347s	
1447/32750 (epoch 2.209), train_loss = 2.14226233, grad/param norm = 2.0067e-01, time/batch = 0.6339s	
1448/32750 (epoch 2.211), train_loss = 2.10892027, grad/param norm = 2.3265e-01, time/batch = 0.6553s	
1449/32750 (epoch 2.212), train_loss = 2.03226707, grad/param norm = 2.2011e-01, time/batch = 0.6714s	
1450/32750 (epoch 2.214), train_loss = 2.13275767, grad/param norm = 2.2491e-01, time/batch = 0.6340s	
1451/32750 (epoch 2.215), train_loss = 2.13804445, grad/param norm = 2.4396e-01, time/batch = 0.6377s	
1452/32750 (epoch 2.217), train_loss = 2.17530163, grad/param norm = 2.2387e-01, time/batch = 0.6430s	
1453/32750 (epoch 2.218), train_loss = 1.98069587, grad/param norm = 1.9442e-01, time/batch = 0.6346s	
1454/32750 (epoch 2.220), train_loss = 2.14340528, grad/param norm = 2.3150e-01, time/batch = 0.6335s	
1455/32750 (epoch 2.221), train_loss = 2.04850528, grad/param norm = 1.9210e-01, time/batch = 0.6325s	
1456/32750 (epoch 2.223), train_loss = 1.97488057, grad/param norm = 2.0379e-01, time/batch = 0.6404s	
1457/32750 (epoch 2.224), train_loss = 2.31970849, grad/param norm = 2.6030e-01, time/batch = 0.6616s	
1458/32750 (epoch 2.226), train_loss = 2.00134772, grad/param norm = 2.1665e-01, time/batch = 0.6327s	
1459/32750 (epoch 2.227), train_loss = 2.01599456, grad/param norm = 2.3673e-01, time/batch = 0.6341s	
1460/32750 (epoch 2.229), train_loss = 2.08542584, grad/param norm = 2.5052e-01, time/batch = 0.6352s	
1461/32750 (epoch 2.231), train_loss = 2.16491775, grad/param norm = 2.8861e-01, time/batch = 0.6361s	
1462/32750 (epoch 2.232), train_loss = 2.09942579, grad/param norm = 2.7384e-01, time/batch = 0.6391s	
1463/32750 (epoch 2.234), train_loss = 2.01323248, grad/param norm = 2.0808e-01, time/batch = 0.6410s	
1464/32750 (epoch 2.235), train_loss = 2.08007020, grad/param norm = 2.2037e-01, time/batch = 0.6739s	
1465/32750 (epoch 2.237), train_loss = 2.08912543, grad/param norm = 2.1072e-01, time/batch = 0.6516s	
1466/32750 (epoch 2.238), train_loss = 2.00839355, grad/param norm = 2.2567e-01, time/batch = 0.6329s	
1467/32750 (epoch 2.240), train_loss = 2.13213064, grad/param norm = 2.3364e-01, time/batch = 0.6333s	
1468/32750 (epoch 2.241), train_loss = 2.27442476, grad/param norm = 2.4562e-01, time/batch = 0.6526s	
1469/32750 (epoch 2.243), train_loss = 2.20015716, grad/param norm = 2.3485e-01, time/batch = 0.6407s	
1470/32750 (epoch 2.244), train_loss = 2.22444776, grad/param norm = 2.3352e-01, time/batch = 0.6318s	
1471/32750 (epoch 2.246), train_loss = 2.03432179, grad/param norm = 2.1686e-01, time/batch = 0.6442s	
1472/32750 (epoch 2.247), train_loss = 2.15173055, grad/param norm = 2.1085e-01, time/batch = 0.6403s	
1473/32750 (epoch 2.249), train_loss = 1.99530834, grad/param norm = 2.3248e-01, time/batch = 0.6353s	
1474/32750 (epoch 2.250), train_loss = 2.27146422, grad/param norm = 2.3449e-01, time/batch = 0.6361s	
1475/32750 (epoch 2.252), train_loss = 2.02322660, grad/param norm = 2.0794e-01, time/batch = 0.6371s	
1476/32750 (epoch 2.253), train_loss = 2.05967722, grad/param norm = 2.4202e-01, time/batch = 0.6352s	
1477/32750 (epoch 2.255), train_loss = 2.24118958, grad/param norm = 2.1419e-01, time/batch = 0.6413s	
1478/32750 (epoch 2.256), train_loss = 1.99341367, grad/param norm = 1.9311e-01, time/batch = 0.6338s	
1479/32750 (epoch 2.258), train_loss = 2.22159390, grad/param norm = 2.3109e-01, time/batch = 0.6525s	
1480/32750 (epoch 2.260), train_loss = 2.22073942, grad/param norm = 2.4714e-01, time/batch = 0.6733s	
1481/32750 (epoch 2.261), train_loss = 2.22270068, grad/param norm = 2.3901e-01, time/batch = 0.6341s	
1482/32750 (epoch 2.263), train_loss = 2.14208069, grad/param norm = 2.0426e-01, time/batch = 0.6427s	
1483/32750 (epoch 2.264), train_loss = 2.09771473, grad/param norm = 1.8971e-01, time/batch = 0.6486s	
1484/32750 (epoch 2.266), train_loss = 2.02206259, grad/param norm = 2.0448e-01, time/batch = 0.6374s	
1485/32750 (epoch 2.267), train_loss = 2.16772552, grad/param norm = 2.0177e-01, time/batch = 0.6331s	
1486/32750 (epoch 2.269), train_loss = 2.01186748, grad/param norm = 2.1957e-01, time/batch = 0.6326s	
1487/32750 (epoch 2.270), train_loss = 2.23196253, grad/param norm = 2.0690e-01, time/batch = 0.6326s	
1488/32750 (epoch 2.272), train_loss = 2.11662386, grad/param norm = 2.0146e-01, time/batch = 0.6357s	
1489/32750 (epoch 2.273), train_loss = 2.20979506, grad/param norm = 2.1990e-01, time/batch = 0.6320s	
1490/32750 (epoch 2.275), train_loss = 2.17171101, grad/param norm = 2.1170e-01, time/batch = 0.6326s	
1491/32750 (epoch 2.276), train_loss = 2.16433904, grad/param norm = 2.4863e-01, time/batch = 0.6354s	
1492/32750 (epoch 2.278), train_loss = 2.13808434, grad/param norm = 2.0615e-01, time/batch = 0.6321s	
1493/32750 (epoch 2.279), train_loss = 2.26466760, grad/param norm = 2.2205e-01, time/batch = 0.6375s	
1494/32750 (epoch 2.281), train_loss = 2.10818293, grad/param norm = 1.9521e-01, time/batch = 0.6620s	
1495/32750 (epoch 2.282), train_loss = 2.03403875, grad/param norm = 2.6880e-01, time/batch = 0.6742s	
1496/32750 (epoch 2.284), train_loss = 2.38769178, grad/param norm = 3.2533e-01, time/batch = 0.6587s	
1497/32750 (epoch 2.285), train_loss = 2.26559066, grad/param norm = 3.0128e-01, time/batch = 0.6389s	
1498/32750 (epoch 2.287), train_loss = 2.09600471, grad/param norm = 1.9151e-01, time/batch = 0.6315s	
1499/32750 (epoch 2.289), train_loss = 2.17172625, grad/param norm = 2.1772e-01, time/batch = 0.6361s	
1500/32750 (epoch 2.290), train_loss = 2.05321189, grad/param norm = 1.9736e-01, time/batch = 0.6355s	
1501/32750 (epoch 2.292), train_loss = 2.11806785, grad/param norm = 2.3716e-01, time/batch = 0.6335s	
1502/32750 (epoch 2.293), train_loss = 2.01797299, grad/param norm = 2.0648e-01, time/batch = 0.6345s	
1503/32750 (epoch 2.295), train_loss = 2.18733270, grad/param norm = 2.2724e-01, time/batch = 0.6363s	
1504/32750 (epoch 2.296), train_loss = 2.11093722, grad/param norm = 2.0996e-01, time/batch = 0.6369s	
1505/32750 (epoch 2.298), train_loss = 2.01179433, grad/param norm = 1.9056e-01, time/batch = 0.6330s	
1506/32750 (epoch 2.299), train_loss = 2.02256582, grad/param norm = 1.8927e-01, time/batch = 0.6383s	
1507/32750 (epoch 2.301), train_loss = 2.07344817, grad/param norm = 2.1247e-01, time/batch = 0.6363s	
1508/32750 (epoch 2.302), train_loss = 1.97174270, grad/param norm = 2.3482e-01, time/batch = 0.6429s	
1509/32750 (epoch 2.304), train_loss = 2.10663923, grad/param norm = 2.4855e-01, time/batch = 0.6333s	
1510/32750 (epoch 2.305), train_loss = 2.11150194, grad/param norm = 2.1639e-01, time/batch = 0.6689s	
1511/32750 (epoch 2.307), train_loss = 2.20994651, grad/param norm = 2.2128e-01, time/batch = 0.6777s	
1512/32750 (epoch 2.308), train_loss = 2.16578108, grad/param norm = 2.0517e-01, time/batch = 0.6516s	
1513/32750 (epoch 2.310), train_loss = 2.14454555, grad/param norm = 2.0452e-01, time/batch = 0.6564s	
1514/32750 (epoch 2.311), train_loss = 2.08203963, grad/param norm = 2.1014e-01, time/batch = 0.6527s	
1515/32750 (epoch 2.313), train_loss = 2.12970674, grad/param norm = 2.3313e-01, time/batch = 0.6533s	
1516/32750 (epoch 2.315), train_loss = 2.14955408, grad/param norm = 2.2998e-01, time/batch = 0.6565s	
1517/32750 (epoch 2.316), train_loss = 2.20740357, grad/param norm = 1.9808e-01, time/batch = 0.6492s	
1518/32750 (epoch 2.318), train_loss = 2.02905416, grad/param norm = 2.5517e-01, time/batch = 0.6508s	
1519/32750 (epoch 2.319), train_loss = 2.17394631, grad/param norm = 2.5686e-01, time/batch = 0.6508s	
1520/32750 (epoch 2.321), train_loss = 2.13484662, grad/param norm = 2.2999e-01, time/batch = 0.6544s	
1521/32750 (epoch 2.322), train_loss = 2.16957874, grad/param norm = 2.5783e-01, time/batch = 0.6385s	
1522/32750 (epoch 2.324), train_loss = 2.17911433, grad/param norm = 2.3330e-01, time/batch = 0.6360s	
1523/32750 (epoch 2.325), train_loss = 2.13388727, grad/param norm = 2.5988e-01, time/batch = 0.6356s	
1524/32750 (epoch 2.327), train_loss = 1.98404902, grad/param norm = 1.9181e-01, time/batch = 0.6352s	
1525/32750 (epoch 2.328), train_loss = 1.96287492, grad/param norm = 1.9055e-01, time/batch = 0.6392s	
1526/32750 (epoch 2.330), train_loss = 2.04122204, grad/param norm = 1.9154e-01, time/batch = 0.6732s	
1527/32750 (epoch 2.331), train_loss = 2.08688613, grad/param norm = 2.1619e-01, time/batch = 0.6485s	
1528/32750 (epoch 2.333), train_loss = 1.97386260, grad/param norm = 1.9017e-01, time/batch = 0.6328s	
1529/32750 (epoch 2.334), train_loss = 2.26105936, grad/param norm = 2.0371e-01, time/batch = 0.6326s	
1530/32750 (epoch 2.336), train_loss = 2.04720484, grad/param norm = 1.9847e-01, time/batch = 0.6425s	
1531/32750 (epoch 2.337), train_loss = 2.00298948, grad/param norm = 2.1284e-01, time/batch = 0.6356s	
1532/32750 (epoch 2.339), train_loss = 2.35527681, grad/param norm = 2.4166e-01, time/batch = 0.6338s	
1533/32750 (epoch 2.340), train_loss = 1.97014930, grad/param norm = 2.2284e-01, time/batch = 0.6335s	
1534/32750 (epoch 2.342), train_loss = 2.18098490, grad/param norm = 2.4168e-01, time/batch = 0.6319s	
1535/32750 (epoch 2.344), train_loss = 2.24516677, grad/param norm = 2.0752e-01, time/batch = 0.6327s	
1536/32750 (epoch 2.345), train_loss = 2.17520043, grad/param norm = 2.2091e-01, time/batch = 0.6325s	
1537/32750 (epoch 2.347), train_loss = 2.16164917, grad/param norm = 2.5167e-01, time/batch = 0.6331s	
1538/32750 (epoch 2.348), train_loss = 2.11870762, grad/param norm = 2.1492e-01, time/batch = 0.6337s	
1539/32750 (epoch 2.350), train_loss = 2.20238515, grad/param norm = 2.0214e-01, time/batch = 0.6352s	
1540/32750 (epoch 2.351), train_loss = 2.25077200, grad/param norm = 2.0514e-01, time/batch = 0.6329s	
1541/32750 (epoch 2.353), train_loss = 2.07146048, grad/param norm = 2.2735e-01, time/batch = 0.6566s	
1542/32750 (epoch 2.354), train_loss = 1.99992119, grad/param norm = 2.2758e-01, time/batch = 0.6715s	
1543/32750 (epoch 2.356), train_loss = 2.09765834, grad/param norm = 2.3648e-01, time/batch = 0.6325s	
1544/32750 (epoch 2.357), train_loss = 1.94034765, grad/param norm = 2.2442e-01, time/batch = 0.6327s	
1545/32750 (epoch 2.359), train_loss = 2.14022577, grad/param norm = 2.3273e-01, time/batch = 0.6332s	
1546/32750 (epoch 2.360), train_loss = 2.01101624, grad/param norm = 2.2969e-01, time/batch = 0.6413s	
1547/32750 (epoch 2.362), train_loss = 2.04720240, grad/param norm = 2.4115e-01, time/batch = 0.6344s	
1548/32750 (epoch 2.363), train_loss = 1.98510994, grad/param norm = 2.2271e-01, time/batch = 0.6527s	
1549/32750 (epoch 2.365), train_loss = 2.02105032, grad/param norm = 2.0863e-01, time/batch = 0.6512s	
1550/32750 (epoch 2.366), train_loss = 2.02139247, grad/param norm = 2.0945e-01, time/batch = 0.6429s	
1551/32750 (epoch 2.368), train_loss = 2.25168467, grad/param norm = 2.3714e-01, time/batch = 0.6318s	
1552/32750 (epoch 2.369), train_loss = 2.22650732, grad/param norm = 2.1236e-01, time/batch = 0.6345s	
1553/32750 (epoch 2.371), train_loss = 2.07595328, grad/param norm = 2.1743e-01, time/batch = 0.6313s	
1554/32750 (epoch 2.373), train_loss = 2.07091755, grad/param norm = 1.9841e-01, time/batch = 0.6352s	
1555/32750 (epoch 2.374), train_loss = 2.17427243, grad/param norm = 2.4330e-01, time/batch = 0.6360s	
1556/32750 (epoch 2.376), train_loss = 1.96190945, grad/param norm = 2.2763e-01, time/batch = 0.6320s	
1557/32750 (epoch 2.377), train_loss = 2.07711924, grad/param norm = 1.8937e-01, time/batch = 0.6732s	
1558/32750 (epoch 2.379), train_loss = 2.04550621, grad/param norm = 2.2378e-01, time/batch = 0.6542s	
1559/32750 (epoch 2.380), train_loss = 2.22775371, grad/param norm = 2.4215e-01, time/batch = 0.6321s	
1560/32750 (epoch 2.382), train_loss = 2.10436567, grad/param norm = 2.2894e-01, time/batch = 0.6325s	
1561/32750 (epoch 2.383), train_loss = 2.12902607, grad/param norm = 2.3748e-01, time/batch = 0.6504s	
1562/32750 (epoch 2.385), train_loss = 2.13154831, grad/param norm = 2.2431e-01, time/batch = 0.6611s	
1563/32750 (epoch 2.386), train_loss = 2.19560735, grad/param norm = 2.3790e-01, time/batch = 0.6391s	
1564/32750 (epoch 2.388), train_loss = 2.09596076, grad/param norm = 2.0957e-01, time/batch = 0.6447s	
1565/32750 (epoch 2.389), train_loss = 2.06962603, grad/param norm = 1.9948e-01, time/batch = 0.6411s	
1566/32750 (epoch 2.391), train_loss = 1.95981882, grad/param norm = 2.1504e-01, time/batch = 0.6331s	
1567/32750 (epoch 2.392), train_loss = 2.04007786, grad/param norm = 2.2097e-01, time/batch = 0.6342s	
1568/32750 (epoch 2.394), train_loss = 2.04035914, grad/param norm = 2.2400e-01, time/batch = 0.6349s	
1569/32750 (epoch 2.395), train_loss = 2.04595486, grad/param norm = 2.4643e-01, time/batch = 0.6345s	
1570/32750 (epoch 2.397), train_loss = 2.24050106, grad/param norm = 2.5497e-01, time/batch = 0.6419s	
1571/32750 (epoch 2.398), train_loss = 2.18022847, grad/param norm = 2.3193e-01, time/batch = 0.6466s	
1572/32750 (epoch 2.400), train_loss = 2.06675684, grad/param norm = 1.8644e-01, time/batch = 0.6545s	
1573/32750 (epoch 2.402), train_loss = 2.05427751, grad/param norm = 2.1768e-01, time/batch = 0.6744s	
1574/32750 (epoch 2.403), train_loss = 2.10537021, grad/param norm = 2.0624e-01, time/batch = 0.6451s	
1575/32750 (epoch 2.405), train_loss = 2.11876355, grad/param norm = 2.0515e-01, time/batch = 0.6367s	
1576/32750 (epoch 2.406), train_loss = 1.89081261, grad/param norm = 2.0530e-01, time/batch = 0.6363s	
1577/32750 (epoch 2.408), train_loss = 1.85658113, grad/param norm = 1.8400e-01, time/batch = 0.6414s	
1578/32750 (epoch 2.409), train_loss = 2.18541445, grad/param norm = 2.2043e-01, time/batch = 0.6342s	
1579/32750 (epoch 2.411), train_loss = 1.97054298, grad/param norm = 2.1300e-01, time/batch = 0.6330s	
1580/32750 (epoch 2.412), train_loss = 1.95228264, grad/param norm = 2.3038e-01, time/batch = 0.6333s	
1581/32750 (epoch 2.414), train_loss = 1.88377892, grad/param norm = 2.2612e-01, time/batch = 0.6372s	
1582/32750 (epoch 2.415), train_loss = 1.99004748, grad/param norm = 2.1666e-01, time/batch = 0.6331s	
1583/32750 (epoch 2.417), train_loss = 1.88186826, grad/param norm = 2.6363e-01, time/batch = 0.6360s	
1584/32750 (epoch 2.418), train_loss = 2.11174288, grad/param norm = 2.3259e-01, time/batch = 0.6341s	
1585/32750 (epoch 2.420), train_loss = 2.03339938, grad/param norm = 2.2025e-01, time/batch = 0.6348s	
1586/32750 (epoch 2.421), train_loss = 2.07788342, grad/param norm = 2.1783e-01, time/batch = 0.6341s	
1587/32750 (epoch 2.423), train_loss = 1.96949366, grad/param norm = 2.5605e-01, time/batch = 0.6349s	
1588/32750 (epoch 2.424), train_loss = 1.93368731, grad/param norm = 2.1104e-01, time/batch = 0.6338s	
1589/32750 (epoch 2.426), train_loss = 1.99367665, grad/param norm = 2.3441e-01, time/batch = 0.6326s	
1590/32750 (epoch 2.427), train_loss = 1.99101426, grad/param norm = 2.6811e-01, time/batch = 0.6323s	
1591/32750 (epoch 2.429), train_loss = 1.95593215, grad/param norm = 1.9391e-01, time/batch = 0.6333s	
1592/32750 (epoch 2.431), train_loss = 2.12191425, grad/param norm = 2.1630e-01, time/batch = 0.6325s	
1593/32750 (epoch 2.432), train_loss = 2.05221466, grad/param norm = 2.1479e-01, time/batch = 0.6348s	
1594/32750 (epoch 2.434), train_loss = 2.06740664, grad/param norm = 2.0126e-01, time/batch = 0.6341s	
1595/32750 (epoch 2.435), train_loss = 1.94941709, grad/param norm = 2.0291e-01, time/batch = 0.6331s	
1596/32750 (epoch 2.437), train_loss = 2.03710333, grad/param norm = 2.1018e-01, time/batch = 0.6320s	
1597/32750 (epoch 2.438), train_loss = 2.30585057, grad/param norm = 2.2648e-01, time/batch = 0.6370s	
1598/32750 (epoch 2.440), train_loss = 2.05168007, grad/param norm = 2.2982e-01, time/batch = 0.6319s	
1599/32750 (epoch 2.441), train_loss = 2.14809796, grad/param norm = 2.2219e-01, time/batch = 0.6350s	
1600/32750 (epoch 2.443), train_loss = 1.81024282, grad/param norm = 2.0045e-01, time/batch = 0.6332s	
1601/32750 (epoch 2.444), train_loss = 2.01647463, grad/param norm = 2.3325e-01, time/batch = 0.6368s	
1602/32750 (epoch 2.446), train_loss = 1.96225006, grad/param norm = 2.0139e-01, time/batch = 0.6352s	
1603/32750 (epoch 2.447), train_loss = 2.26150885, grad/param norm = 2.1629e-01, time/batch = 0.6331s	
1604/32750 (epoch 2.449), train_loss = 2.06994118, grad/param norm = 2.0623e-01, time/batch = 0.6325s	
1605/32750 (epoch 2.450), train_loss = 2.16780389, grad/param norm = 2.3614e-01, time/batch = 0.6331s	
1606/32750 (epoch 2.452), train_loss = 2.19785830, grad/param norm = 2.1076e-01, time/batch = 0.6319s	
1607/32750 (epoch 2.453), train_loss = 1.94172051, grad/param norm = 1.9990e-01, time/batch = 0.6329s	
1608/32750 (epoch 2.455), train_loss = 2.00951677, grad/param norm = 1.9324e-01, time/batch = 0.6595s	
1609/32750 (epoch 2.456), train_loss = 2.12316348, grad/param norm = 1.8948e-01, time/batch = 0.6719s	
1610/32750 (epoch 2.458), train_loss = 2.24484626, grad/param norm = 2.3641e-01, time/batch = 0.6397s	
1611/32750 (epoch 2.460), train_loss = 2.12363074, grad/param norm = 2.2203e-01, time/batch = 0.6338s	
1612/32750 (epoch 2.461), train_loss = 2.12760094, grad/param norm = 2.5134e-01, time/batch = 0.6330s	
1613/32750 (epoch 2.463), train_loss = 1.99168358, grad/param norm = 2.5600e-01, time/batch = 0.6317s	
1614/32750 (epoch 2.464), train_loss = 2.17345876, grad/param norm = 1.8902e-01, time/batch = 0.6328s	
1615/32750 (epoch 2.466), train_loss = 2.15375241, grad/param norm = 2.2378e-01, time/batch = 0.6360s	
1616/32750 (epoch 2.467), train_loss = 2.46170036, grad/param norm = 2.3596e-01, time/batch = 0.6347s	
1617/32750 (epoch 2.469), train_loss = 2.04331567, grad/param norm = 2.2331e-01, time/batch = 0.6348s	
1618/32750 (epoch 2.470), train_loss = 2.16081190, grad/param norm = 2.4132e-01, time/batch = 0.6331s	
1619/32750 (epoch 2.472), train_loss = 2.11154650, grad/param norm = 2.0112e-01, time/batch = 0.6390s	
1620/32750 (epoch 2.473), train_loss = 2.05854526, grad/param norm = 1.9344e-01, time/batch = 0.6374s	
1621/32750 (epoch 2.475), train_loss = 2.10551659, grad/param norm = 2.0616e-01, time/batch = 0.6366s	
1622/32750 (epoch 2.476), train_loss = 2.05951777, grad/param norm = 1.9242e-01, time/batch = 0.6321s	
1623/32750 (epoch 2.478), train_loss = 2.27935710, grad/param norm = 2.5475e-01, time/batch = 0.6330s	
1624/32750 (epoch 2.479), train_loss = 2.26530209, grad/param norm = 2.3407e-01, time/batch = 0.6729s	
1625/32750 (epoch 2.481), train_loss = 2.48056022, grad/param norm = 2.2157e-01, time/batch = 0.6537s	
1626/32750 (epoch 2.482), train_loss = 2.23132279, grad/param norm = 2.5280e-01, time/batch = 0.6342s	
1627/32750 (epoch 2.484), train_loss = 1.98237208, grad/param norm = 2.5373e-01, time/batch = 0.6379s	
1628/32750 (epoch 2.485), train_loss = 2.12055490, grad/param norm = 2.2042e-01, time/batch = 0.6366s	
1629/32750 (epoch 2.487), train_loss = 2.10526409, grad/param norm = 2.3784e-01, time/batch = 0.6337s	
1630/32750 (epoch 2.489), train_loss = 2.02136876, grad/param norm = 1.8735e-01, time/batch = 0.6371s	
1631/32750 (epoch 2.490), train_loss = 2.13979591, grad/param norm = 1.9930e-01, time/batch = 0.6337s	
1632/32750 (epoch 2.492), train_loss = 2.10689145, grad/param norm = 2.0971e-01, time/batch = 0.6516s	
1633/32750 (epoch 2.493), train_loss = 2.21299520, grad/param norm = 2.1469e-01, time/batch = 0.6633s	
1634/32750 (epoch 2.495), train_loss = 2.29157393, grad/param norm = 2.2773e-01, time/batch = 0.6675s	
1635/32750 (epoch 2.496), train_loss = 1.98662408, grad/param norm = 2.0696e-01, time/batch = 0.6671s	
1636/32750 (epoch 2.498), train_loss = 2.05371846, grad/param norm = 2.1047e-01, time/batch = 0.6646s	
1637/32750 (epoch 2.499), train_loss = 2.13819645, grad/param norm = 1.9246e-01, time/batch = 0.6656s	
1638/32750 (epoch 2.501), train_loss = 2.28495013, grad/param norm = 2.2669e-01, time/batch = 0.6467s	
1639/32750 (epoch 2.502), train_loss = 2.16099694, grad/param norm = 2.2404e-01, time/batch = 0.6588s	
1640/32750 (epoch 2.504), train_loss = 2.13149136, grad/param norm = 2.3071e-01, time/batch = 0.6683s	
1641/32750 (epoch 2.505), train_loss = 2.11084083, grad/param norm = 2.2189e-01, time/batch = 0.6345s	
1642/32750 (epoch 2.507), train_loss = 2.07221687, grad/param norm = 2.3239e-01, time/batch = 0.6331s	
1643/32750 (epoch 2.508), train_loss = 2.08092278, grad/param norm = 2.1879e-01, time/batch = 0.6379s	
1644/32750 (epoch 2.510), train_loss = 2.08445450, grad/param norm = 2.2442e-01, time/batch = 0.6465s	
1645/32750 (epoch 2.511), train_loss = 2.03090581, grad/param norm = 2.0522e-01, time/batch = 0.6507s	
1646/32750 (epoch 2.513), train_loss = 1.93205066, grad/param norm = 2.3072e-01, time/batch = 0.6424s	
1647/32750 (epoch 2.515), train_loss = 2.03550573, grad/param norm = 2.2398e-01, time/batch = 0.6365s	
1648/32750 (epoch 2.516), train_loss = 2.06518376, grad/param norm = 2.1780e-01, time/batch = 0.6363s	
1649/32750 (epoch 2.518), train_loss = 2.16819813, grad/param norm = 2.2212e-01, time/batch = 0.6315s	
1650/32750 (epoch 2.519), train_loss = 2.18341878, grad/param norm = 2.1867e-01, time/batch = 0.6314s	
1651/32750 (epoch 2.521), train_loss = 2.07357775, grad/param norm = 1.9390e-01, time/batch = 0.6344s	
1652/32750 (epoch 2.522), train_loss = 2.10566057, grad/param norm = 2.3026e-01, time/batch = 0.6326s	
1653/32750 (epoch 2.524), train_loss = 1.91436573, grad/param norm = 2.1184e-01, time/batch = 0.6342s	
1654/32750 (epoch 2.525), train_loss = 1.92748483, grad/param norm = 1.9385e-01, time/batch = 0.6464s	
1655/32750 (epoch 2.527), train_loss = 2.06752159, grad/param norm = 2.3944e-01, time/batch = 0.6462s	
1656/32750 (epoch 2.528), train_loss = 1.97079354, grad/param norm = 2.3362e-01, time/batch = 0.6547s	
1657/32750 (epoch 2.530), train_loss = 2.16524366, grad/param norm = 2.3987e-01, time/batch = 0.6527s	
1658/32750 (epoch 2.531), train_loss = 2.02191904, grad/param norm = 1.9863e-01, time/batch = 0.6389s	
1659/32750 (epoch 2.533), train_loss = 2.15853458, grad/param norm = 2.3090e-01, time/batch = 0.6351s	
1660/32750 (epoch 2.534), train_loss = 2.13155553, grad/param norm = 2.2619e-01, time/batch = 0.6333s	
1661/32750 (epoch 2.536), train_loss = 1.86894276, grad/param norm = 2.0349e-01, time/batch = 0.6383s	
1662/32750 (epoch 2.537), train_loss = 1.99540018, grad/param norm = 2.1763e-01, time/batch = 0.6351s	
1663/32750 (epoch 2.539), train_loss = 2.17746546, grad/param norm = 2.1988e-01, time/batch = 0.6373s	
1664/32750 (epoch 2.540), train_loss = 2.06206046, grad/param norm = 2.0809e-01, time/batch = 0.6340s	
1665/32750 (epoch 2.542), train_loss = 1.99517036, grad/param norm = 2.2134e-01, time/batch = 0.6343s	
1666/32750 (epoch 2.544), train_loss = 2.01210766, grad/param norm = 2.3150e-01, time/batch = 0.6313s	
1667/32750 (epoch 2.545), train_loss = 2.03062687, grad/param norm = 2.0105e-01, time/batch = 0.6322s	
1668/32750 (epoch 2.547), train_loss = 1.99878425, grad/param norm = 1.9674e-01, time/batch = 0.6328s	
1669/32750 (epoch 2.548), train_loss = 2.11911471, grad/param norm = 2.0144e-01, time/batch = 0.6332s	
1670/32750 (epoch 2.550), train_loss = 2.07631670, grad/param norm = 2.1310e-01, time/batch = 0.6549s	
1671/32750 (epoch 2.551), train_loss = 2.06187320, grad/param norm = 1.9962e-01, time/batch = 0.6730s	
1672/32750 (epoch 2.553), train_loss = 2.01633318, grad/param norm = 2.1557e-01, time/batch = 0.6331s	
1673/32750 (epoch 2.554), train_loss = 2.03469368, grad/param norm = 2.0595e-01, time/batch = 0.6356s	
1674/32750 (epoch 2.556), train_loss = 2.23794459, grad/param norm = 2.2713e-01, time/batch = 0.6336s	
1675/32750 (epoch 2.557), train_loss = 1.99576457, grad/param norm = 1.9871e-01, time/batch = 0.6322s	
1676/32750 (epoch 2.559), train_loss = 2.06153920, grad/param norm = 2.0148e-01, time/batch = 0.6329s	
1677/32750 (epoch 2.560), train_loss = 1.95467733, grad/param norm = 2.3220e-01, time/batch = 0.6366s	
1678/32750 (epoch 2.562), train_loss = 2.04897497, grad/param norm = 2.1160e-01, time/batch = 0.6335s	
1679/32750 (epoch 2.563), train_loss = 2.13030266, grad/param norm = 2.0277e-01, time/batch = 0.6346s	
1680/32750 (epoch 2.565), train_loss = 2.04674500, grad/param norm = 2.1836e-01, time/batch = 0.6345s	
1681/32750 (epoch 2.566), train_loss = 1.97877911, grad/param norm = 1.9840e-01, time/batch = 0.6350s	
1682/32750 (epoch 2.568), train_loss = 2.14411670, grad/param norm = 2.2612e-01, time/batch = 0.6329s	
1683/32750 (epoch 2.569), train_loss = 2.12749679, grad/param norm = 2.1947e-01, time/batch = 0.6335s	
1684/32750 (epoch 2.571), train_loss = 1.96640084, grad/param norm = 2.2296e-01, time/batch = 0.6338s	
1685/32750 (epoch 2.573), train_loss = 2.10553389, grad/param norm = 2.0410e-01, time/batch = 0.6343s	
1686/32750 (epoch 2.574), train_loss = 2.09428301, grad/param norm = 2.0207e-01, time/batch = 0.6712s	
1687/32750 (epoch 2.576), train_loss = 2.00552173, grad/param norm = 1.9923e-01, time/batch = 0.6589s	
1688/32750 (epoch 2.577), train_loss = 2.08131559, grad/param norm = 1.9565e-01, time/batch = 0.6389s	
1689/32750 (epoch 2.579), train_loss = 1.94443330, grad/param norm = 1.9280e-01, time/batch = 0.6348s	
1690/32750 (epoch 2.580), train_loss = 2.07614709, grad/param norm = 2.1109e-01, time/batch = 0.6340s	
1691/32750 (epoch 2.582), train_loss = 2.01761839, grad/param norm = 2.0255e-01, time/batch = 0.6488s	
1692/32750 (epoch 2.583), train_loss = 2.07069366, grad/param norm = 2.2357e-01, time/batch = 0.6369s	
1693/32750 (epoch 2.585), train_loss = 2.01553686, grad/param norm = 2.1953e-01, time/batch = 0.6336s	
1694/32750 (epoch 2.586), train_loss = 2.16294683, grad/param norm = 2.5431e-01, time/batch = 0.6369s	
1695/32750 (epoch 2.588), train_loss = 2.07914968, grad/param norm = 2.5211e-01, time/batch = 0.6347s	
1696/32750 (epoch 2.589), train_loss = 2.05672557, grad/param norm = 2.0911e-01, time/batch = 0.6321s	
1697/32750 (epoch 2.591), train_loss = 2.00431075, grad/param norm = 1.8788e-01, time/batch = 0.6339s	
1698/32750 (epoch 2.592), train_loss = 1.98277590, grad/param norm = 1.8936e-01, time/batch = 0.6327s	
1699/32750 (epoch 2.594), train_loss = 1.95909956, grad/param norm = 2.1007e-01, time/batch = 0.6328s	
1700/32750 (epoch 2.595), train_loss = 1.90053405, grad/param norm = 2.0361e-01, time/batch = 0.6343s	
1701/32750 (epoch 2.597), train_loss = 2.07713708, grad/param norm = 1.9488e-01, time/batch = 0.6498s	
1702/32750 (epoch 2.598), train_loss = 1.85276019, grad/param norm = 1.9715e-01, time/batch = 0.6745s	
1703/32750 (epoch 2.600), train_loss = 2.15996700, grad/param norm = 2.3746e-01, time/batch = 0.6385s	
1704/32750 (epoch 2.602), train_loss = 2.37669236, grad/param norm = 2.2412e-01, time/batch = 0.6349s	
1705/32750 (epoch 2.603), train_loss = 2.45656787, grad/param norm = 3.9858e-01, time/batch = 0.6337s	
1706/32750 (epoch 2.605), train_loss = 2.15208337, grad/param norm = 3.4640e-01, time/batch = 0.6349s	
1707/32750 (epoch 2.606), train_loss = 2.05485525, grad/param norm = 2.0889e-01, time/batch = 0.6375s	
1708/32750 (epoch 2.608), train_loss = 2.01874844, grad/param norm = 2.3105e-01, time/batch = 0.6348s	
1709/32750 (epoch 2.609), train_loss = 1.91652080, grad/param norm = 1.9208e-01, time/batch = 0.6344s	
1710/32750 (epoch 2.611), train_loss = 2.08903198, grad/param norm = 2.0877e-01, time/batch = 0.6476s	
1711/32750 (epoch 2.612), train_loss = 1.97835776, grad/param norm = 2.0434e-01, time/batch = 0.6730s	
1712/32750 (epoch 2.614), train_loss = 1.95763108, grad/param norm = 1.9694e-01, time/batch = 0.6572s	
1713/32750 (epoch 2.615), train_loss = 2.13153813, grad/param norm = 2.0566e-01, time/batch = 0.6542s	
1714/32750 (epoch 2.617), train_loss = 1.94508439, grad/param norm = 1.9532e-01, time/batch = 0.6495s	
1715/32750 (epoch 2.618), train_loss = 2.03861611, grad/param norm = 2.0181e-01, time/batch = 0.6458s	
1716/32750 (epoch 2.620), train_loss = 1.98341386, grad/param norm = 2.0557e-01, time/batch = 0.6504s	
1717/32750 (epoch 2.621), train_loss = 2.07034582, grad/param norm = 2.2988e-01, time/batch = 0.6754s	
1718/32750 (epoch 2.623), train_loss = 1.96524943, grad/param norm = 2.2734e-01, time/batch = 0.6640s	
1719/32750 (epoch 2.624), train_loss = 2.22470559, grad/param norm = 2.2836e-01, time/batch = 0.6495s	
1720/32750 (epoch 2.626), train_loss = 2.12482774, grad/param norm = 2.0048e-01, time/batch = 0.6492s	
1721/32750 (epoch 2.627), train_loss = 2.06172244, grad/param norm = 2.2971e-01, time/batch = 0.6506s	
1722/32750 (epoch 2.629), train_loss = 1.99368195, grad/param norm = 2.2379e-01, time/batch = 0.6517s	
1723/32750 (epoch 2.631), train_loss = 2.02208493, grad/param norm = 2.0933e-01, time/batch = 0.6505s	
1724/32750 (epoch 2.632), train_loss = 2.10557861, grad/param norm = 2.0302e-01, time/batch = 0.6470s	
1725/32750 (epoch 2.634), train_loss = 2.22679891, grad/param norm = 2.0283e-01, time/batch = 0.6488s	
1726/32750 (epoch 2.635), train_loss = 1.98885599, grad/param norm = 2.0266e-01, time/batch = 0.6447s	
1727/32750 (epoch 2.637), train_loss = 2.19325872, grad/param norm = 2.0617e-01, time/batch = 0.6395s	
1728/32750 (epoch 2.638), train_loss = 2.03752772, grad/param norm = 2.0310e-01, time/batch = 0.6547s	
1729/32750 (epoch 2.640), train_loss = 1.99051032, grad/param norm = 2.0734e-01, time/batch = 0.6400s	
1730/32750 (epoch 2.641), train_loss = 1.99822925, grad/param norm = 2.0957e-01, time/batch = 0.6327s	
1731/32750 (epoch 2.643), train_loss = 1.90217110, grad/param norm = 2.1322e-01, time/batch = 0.6330s	
1732/32750 (epoch 2.644), train_loss = 1.95003016, grad/param norm = 2.1086e-01, time/batch = 0.6610s	
1733/32750 (epoch 2.646), train_loss = 1.89641395, grad/param norm = 2.1541e-01, time/batch = 0.6667s	
1734/32750 (epoch 2.647), train_loss = 2.03266925, grad/param norm = 2.2922e-01, time/batch = 0.6339s	
1735/32750 (epoch 2.649), train_loss = 2.12491318, grad/param norm = 2.2934e-01, time/batch = 0.6348s	
1736/32750 (epoch 2.650), train_loss = 2.20055850, grad/param norm = 1.9731e-01, time/batch = 0.6328s	
1737/32750 (epoch 2.652), train_loss = 1.96961561, grad/param norm = 2.3965e-01, time/batch = 0.6340s	
1738/32750 (epoch 2.653), train_loss = 1.90842848, grad/param norm = 1.8852e-01, time/batch = 0.6340s	
1739/32750 (epoch 2.655), train_loss = 2.30524437, grad/param norm = 2.3462e-01, time/batch = 0.6338s	
1740/32750 (epoch 2.656), train_loss = 2.07971009, grad/param norm = 2.1879e-01, time/batch = 0.6344s	
1741/32750 (epoch 2.658), train_loss = 2.10186463, grad/param norm = 2.1147e-01, time/batch = 0.6402s	
1742/32750 (epoch 2.660), train_loss = 2.05471725, grad/param norm = 2.2450e-01, time/batch = 0.6456s	
1743/32750 (epoch 2.661), train_loss = 2.13087272, grad/param norm = 2.2865e-01, time/batch = 0.6371s	
1744/32750 (epoch 2.663), train_loss = 2.10104959, grad/param norm = 1.9198e-01, time/batch = 0.6333s	
1745/32750 (epoch 2.664), train_loss = 2.11092207, grad/param norm = 2.2429e-01, time/batch = 0.6378s	
1746/32750 (epoch 2.666), train_loss = 2.11977355, grad/param norm = 2.2103e-01, time/batch = 0.6338s	
1747/32750 (epoch 2.667), train_loss = 2.09249383, grad/param norm = 2.0461e-01, time/batch = 0.6473s	
1748/32750 (epoch 2.669), train_loss = 2.09997140, grad/param norm = 2.3332e-01, time/batch = 0.6743s	
1749/32750 (epoch 2.670), train_loss = 2.03787065, grad/param norm = 2.2775e-01, time/batch = 0.6698s	
1750/32750 (epoch 2.672), train_loss = 1.91850621, grad/param norm = 1.9563e-01, time/batch = 0.6500s	
1751/32750 (epoch 2.673), train_loss = 2.02148751, grad/param norm = 2.0821e-01, time/batch = 0.6397s	
1752/32750 (epoch 2.675), train_loss = 2.10863933, grad/param norm = 1.9975e-01, time/batch = 0.6460s	
1753/32750 (epoch 2.676), train_loss = 2.01923581, grad/param norm = 2.1356e-01, time/batch = 0.6446s	
1754/32750 (epoch 2.678), train_loss = 2.05651083, grad/param norm = 1.9686e-01, time/batch = 0.6375s	
1755/32750 (epoch 2.679), train_loss = 2.01119608, grad/param norm = 2.2316e-01, time/batch = 0.6363s	
1756/32750 (epoch 2.681), train_loss = 1.97133291, grad/param norm = 2.0622e-01, time/batch = 0.6353s	
1757/32750 (epoch 2.682), train_loss = 2.04922314, grad/param norm = 2.0380e-01, time/batch = 0.6333s	
1758/32750 (epoch 2.684), train_loss = 2.02509674, grad/param norm = 1.9024e-01, time/batch = 0.6341s	
1759/32750 (epoch 2.685), train_loss = 2.03549529, grad/param norm = 1.9367e-01, time/batch = 0.6312s	
1760/32750 (epoch 2.687), train_loss = 2.00257223, grad/param norm = 2.0804e-01, time/batch = 0.6330s	
1761/32750 (epoch 2.689), train_loss = 2.04372586, grad/param norm = 2.0353e-01, time/batch = 0.6351s	
1762/32750 (epoch 2.690), train_loss = 1.89606782, grad/param norm = 2.0815e-01, time/batch = 0.6336s	
1763/32750 (epoch 2.692), train_loss = 2.15007231, grad/param norm = 2.1893e-01, time/batch = 0.6599s	
1764/32750 (epoch 2.693), train_loss = 2.00020798, grad/param norm = 2.0598e-01, time/batch = 0.6706s	
1765/32750 (epoch 2.695), train_loss = 1.89387355, grad/param norm = 2.5910e-01, time/batch = 0.6502s	
1766/32750 (epoch 2.696), train_loss = 1.99287893, grad/param norm = 2.3522e-01, time/batch = 0.6434s	
1767/32750 (epoch 2.698), train_loss = 2.08858596, grad/param norm = 2.3886e-01, time/batch = 0.6347s	
1768/32750 (epoch 2.699), train_loss = 2.04600069, grad/param norm = 2.3447e-01, time/batch = 0.6319s	
1769/32750 (epoch 2.701), train_loss = 1.91602314, grad/param norm = 1.7958e-01, time/batch = 0.6337s	
1770/32750 (epoch 2.702), train_loss = 1.99768878, grad/param norm = 1.9976e-01, time/batch = 0.6331s	
1771/32750 (epoch 2.704), train_loss = 2.11583428, grad/param norm = 1.9340e-01, time/batch = 0.6339s	
1772/32750 (epoch 2.705), train_loss = 2.23634430, grad/param norm = 2.1698e-01, time/batch = 0.6364s	
1773/32750 (epoch 2.707), train_loss = 2.12051814, grad/param norm = 2.3339e-01, time/batch = 0.6339s	
1774/32750 (epoch 2.708), train_loss = 2.03637850, grad/param norm = 2.5442e-01, time/batch = 0.6335s	
1775/32750 (epoch 2.710), train_loss = 1.99576230, grad/param norm = 2.0291e-01, time/batch = 0.6332s	
1776/32750 (epoch 2.711), train_loss = 2.11857767, grad/param norm = 1.9630e-01, time/batch = 0.6354s	
1777/32750 (epoch 2.713), train_loss = 2.09297312, grad/param norm = 2.0043e-01, time/batch = 0.6435s	
1778/32750 (epoch 2.715), train_loss = 1.99169680, grad/param norm = 1.8273e-01, time/batch = 0.6520s	
1779/32750 (epoch 2.716), train_loss = 2.08469914, grad/param norm = 2.0752e-01, time/batch = 0.6434s	
1780/32750 (epoch 2.718), train_loss = 1.97935997, grad/param norm = 2.1016e-01, time/batch = 0.6371s	
1781/32750 (epoch 2.719), train_loss = 2.06410795, grad/param norm = 2.0223e-01, time/batch = 0.6360s	
1782/32750 (epoch 2.721), train_loss = 2.04118823, grad/param norm = 2.0782e-01, time/batch = 0.6373s	
1783/32750 (epoch 2.722), train_loss = 2.10004625, grad/param norm = 2.1901e-01, time/batch = 0.6356s	
1784/32750 (epoch 2.724), train_loss = 2.11371621, grad/param norm = 2.1402e-01, time/batch = 0.6372s	
1785/32750 (epoch 2.725), train_loss = 1.94077345, grad/param norm = 2.1759e-01, time/batch = 0.6346s	
1786/32750 (epoch 2.727), train_loss = 1.96693329, grad/param norm = 2.1417e-01, time/batch = 0.6325s	
1787/32750 (epoch 2.728), train_loss = 1.97570484, grad/param norm = 2.0469e-01, time/batch = 0.6345s	
1788/32750 (epoch 2.730), train_loss = 1.94560050, grad/param norm = 2.2456e-01, time/batch = 0.6350s	
1789/32750 (epoch 2.731), train_loss = 2.08309790, grad/param norm = 2.1196e-01, time/batch = 0.6338s	
1790/32750 (epoch 2.733), train_loss = 2.09451938, grad/param norm = 2.1243e-01, time/batch = 0.6323s	
1791/32750 (epoch 2.734), train_loss = 1.92622871, grad/param norm = 2.4212e-01, time/batch = 0.6337s	
1792/32750 (epoch 2.736), train_loss = 1.99064432, grad/param norm = 1.9728e-01, time/batch = 0.6338s	
1793/32750 (epoch 2.737), train_loss = 1.91249681, grad/param norm = 1.9039e-01, time/batch = 0.6368s	
1794/32750 (epoch 2.739), train_loss = 2.05394283, grad/param norm = 2.4627e-01, time/batch = 0.6498s	
1795/32750 (epoch 2.740), train_loss = 2.08923087, grad/param norm = 2.7461e-01, time/batch = 0.6742s	
1796/32750 (epoch 2.742), train_loss = 2.03119690, grad/param norm = 2.2414e-01, time/batch = 0.6382s	
1797/32750 (epoch 2.744), train_loss = 1.93206934, grad/param norm = 1.9766e-01, time/batch = 0.6337s	
1798/32750 (epoch 2.745), train_loss = 2.08543609, grad/param norm = 2.1498e-01, time/batch = 0.6329s	
1799/32750 (epoch 2.747), train_loss = 2.01575466, grad/param norm = 2.1144e-01, time/batch = 0.6425s	
1800/32750 (epoch 2.748), train_loss = 1.98875334, grad/param norm = 1.8404e-01, time/batch = 0.6335s	
1801/32750 (epoch 2.750), train_loss = 2.03837329, grad/param norm = 2.0268e-01, time/batch = 0.6357s	
1802/32750 (epoch 2.751), train_loss = 2.10896769, grad/param norm = 2.3293e-01, time/batch = 0.6354s	
1803/32750 (epoch 2.753), train_loss = 2.00943868, grad/param norm = 2.4226e-01, time/batch = 0.6364s	
1804/32750 (epoch 2.754), train_loss = 2.06944181, grad/param norm = 1.9314e-01, time/batch = 0.6341s	
1805/32750 (epoch 2.756), train_loss = 2.15891981, grad/param norm = 2.0932e-01, time/batch = 0.6372s	
1806/32750 (epoch 2.757), train_loss = 1.94722931, grad/param norm = 1.8602e-01, time/batch = 0.6394s	
1807/32750 (epoch 2.759), train_loss = 2.06487811, grad/param norm = 2.0274e-01, time/batch = 0.6327s	
1808/32750 (epoch 2.760), train_loss = 2.07924872, grad/param norm = 1.9807e-01, time/batch = 0.6335s	
1809/32750 (epoch 2.762), train_loss = 2.12110989, grad/param norm = 2.0755e-01, time/batch = 0.6340s	
1810/32750 (epoch 2.763), train_loss = 1.97354873, grad/param norm = 1.8613e-01, time/batch = 0.6440s	
1811/32750 (epoch 2.765), train_loss = 2.02332969, grad/param norm = 2.0630e-01, time/batch = 0.6462s	
1812/32750 (epoch 2.766), train_loss = 2.06472945, grad/param norm = 2.0908e-01, time/batch = 0.6601s	
1813/32750 (epoch 2.768), train_loss = 1.96288315, grad/param norm = 2.0968e-01, time/batch = 0.6409s	
1814/32750 (epoch 2.769), train_loss = 1.98013469, grad/param norm = 2.0877e-01, time/batch = 0.6520s	
1815/32750 (epoch 2.771), train_loss = 2.05187287, grad/param norm = 2.3481e-01, time/batch = 0.6579s	
1816/32750 (epoch 2.773), train_loss = 1.91381779, grad/param norm = 2.4765e-01, time/batch = 0.6438s	
1817/32750 (epoch 2.774), train_loss = 1.99486279, grad/param norm = 2.2816e-01, time/batch = 0.6329s	
1818/32750 (epoch 2.776), train_loss = 1.86898194, grad/param norm = 2.0249e-01, time/batch = 0.6494s	
1819/32750 (epoch 2.777), train_loss = 2.01336604, grad/param norm = 2.0364e-01, time/batch = 0.6457s	
1820/32750 (epoch 2.779), train_loss = 1.90462199, grad/param norm = 1.8139e-01, time/batch = 0.6345s	
1821/32750 (epoch 2.780), train_loss = 2.16151636, grad/param norm = 2.4330e-01, time/batch = 0.6337s	
1822/32750 (epoch 2.782), train_loss = 2.14625831, grad/param norm = 2.4439e-01, time/batch = 0.6328s	
1823/32750 (epoch 2.783), train_loss = 2.08006198, grad/param norm = 2.4203e-01, time/batch = 0.6327s	
1824/32750 (epoch 2.785), train_loss = 1.95366082, grad/param norm = 1.8386e-01, time/batch = 0.6329s	
1825/32750 (epoch 2.786), train_loss = 2.10083429, grad/param norm = 1.9453e-01, time/batch = 0.6470s	
1826/32750 (epoch 2.788), train_loss = 2.13749644, grad/param norm = 1.8901e-01, time/batch = 0.6740s	
1827/32750 (epoch 2.789), train_loss = 2.06310496, grad/param norm = 2.0132e-01, time/batch = 0.6422s	
1828/32750 (epoch 2.791), train_loss = 2.13361287, grad/param norm = 2.0222e-01, time/batch = 0.6339s	
1829/32750 (epoch 2.792), train_loss = 2.02505624, grad/param norm = 2.0866e-01, time/batch = 0.6354s	
1830/32750 (epoch 2.794), train_loss = 2.02990797, grad/param norm = 2.0722e-01, time/batch = 0.6326s	
1831/32750 (epoch 2.795), train_loss = 2.12133595, grad/param norm = 2.2791e-01, time/batch = 0.6346s	
1832/32750 (epoch 2.797), train_loss = 1.89339724, grad/param norm = 2.1539e-01, time/batch = 0.6339s	
1833/32750 (epoch 2.798), train_loss = 2.02650182, grad/param norm = 2.0640e-01, time/batch = 0.6326s	
1834/32750 (epoch 2.800), train_loss = 1.93370811, grad/param norm = 2.1470e-01, time/batch = 0.6359s	
1835/32750 (epoch 2.802), train_loss = 2.08057265, grad/param norm = 1.8830e-01, time/batch = 0.6343s	
1836/32750 (epoch 2.803), train_loss = 2.18804356, grad/param norm = 2.0361e-01, time/batch = 0.6320s	
1837/32750 (epoch 2.805), train_loss = 2.09614038, grad/param norm = 2.2025e-01, time/batch = 0.6328s	
1838/32750 (epoch 2.806), train_loss = 2.02866485, grad/param norm = 1.9619e-01, time/batch = 0.6320s	
1839/32750 (epoch 2.808), train_loss = 2.15994642, grad/param norm = 2.0876e-01, time/batch = 0.6328s	
1840/32750 (epoch 2.809), train_loss = 2.01463023, grad/param norm = 2.0464e-01, time/batch = 0.6364s	
1841/32750 (epoch 2.811), train_loss = 2.21711026, grad/param norm = 2.0976e-01, time/batch = 0.6706s	
1842/32750 (epoch 2.812), train_loss = 1.91727801, grad/param norm = 1.9044e-01, time/batch = 0.6687s	
1843/32750 (epoch 2.814), train_loss = 2.06497478, grad/param norm = 1.9866e-01, time/batch = 0.6613s	
1844/32750 (epoch 2.815), train_loss = 2.17512998, grad/param norm = 2.1768e-01, time/batch = 0.6520s	
1845/32750 (epoch 2.817), train_loss = 2.13867139, grad/param norm = 2.1317e-01, time/batch = 0.6385s	
1846/32750 (epoch 2.818), train_loss = 1.93227354, grad/param norm = 2.1386e-01, time/batch = 0.6318s	
1847/32750 (epoch 2.820), train_loss = 1.91593149, grad/param norm = 1.9717e-01, time/batch = 0.6351s	
1848/32750 (epoch 2.821), train_loss = 2.06731533, grad/param norm = 2.0067e-01, time/batch = 0.6347s	
1849/32750 (epoch 2.823), train_loss = 2.00335401, grad/param norm = 2.0211e-01, time/batch = 0.6396s	
1850/32750 (epoch 2.824), train_loss = 2.07437036, grad/param norm = 2.3653e-01, time/batch = 0.6672s	
1851/32750 (epoch 2.826), train_loss = 2.21318928, grad/param norm = 1.9496e-01, time/batch = 0.6397s	
1852/32750 (epoch 2.827), train_loss = 2.07302308, grad/param norm = 1.9853e-01, time/batch = 0.6434s	
1853/32750 (epoch 2.829), train_loss = 2.20676600, grad/param norm = 2.1777e-01, time/batch = 0.6384s	
1854/32750 (epoch 2.831), train_loss = 1.77714801, grad/param norm = 2.0643e-01, time/batch = 0.6345s	
1855/32750 (epoch 2.832), train_loss = 2.01164778, grad/param norm = 2.4241e-01, time/batch = 0.6319s	
1856/32750 (epoch 2.834), train_loss = 1.96744809, grad/param norm = 2.0147e-01, time/batch = 0.6443s	
1857/32750 (epoch 2.835), train_loss = 1.88417336, grad/param norm = 2.2664e-01, time/batch = 0.6745s	
1858/32750 (epoch 2.837), train_loss = 2.16548964, grad/param norm = 1.9723e-01, time/batch = 0.6404s	
1859/32750 (epoch 2.838), train_loss = 1.96237712, grad/param norm = 1.9841e-01, time/batch = 0.6341s	
1860/32750 (epoch 2.840), train_loss = 1.88912896, grad/param norm = 1.9847e-01, time/batch = 0.6335s	
1861/32750 (epoch 2.841), train_loss = 2.09452575, grad/param norm = 2.1771e-01, time/batch = 0.6344s	
1862/32750 (epoch 2.843), train_loss = 2.18192544, grad/param norm = 2.0205e-01, time/batch = 0.6340s	
1863/32750 (epoch 2.844), train_loss = 2.11410355, grad/param norm = 1.9426e-01, time/batch = 0.6341s	
1864/32750 (epoch 2.846), train_loss = 1.99277908, grad/param norm = 1.8351e-01, time/batch = 0.6324s	
1865/32750 (epoch 2.847), train_loss = 1.90737237, grad/param norm = 1.9786e-01, time/batch = 0.6327s	
1866/32750 (epoch 2.849), train_loss = 2.05699727, grad/param norm = 2.2464e-01, time/batch = 0.6318s	
1867/32750 (epoch 2.850), train_loss = 2.16567067, grad/param norm = 2.1191e-01, time/batch = 0.6332s	
1868/32750 (epoch 2.852), train_loss = 1.89347576, grad/param norm = 2.0256e-01, time/batch = 0.6321s	
1869/32750 (epoch 2.853), train_loss = 2.02166708, grad/param norm = 2.0280e-01, time/batch = 0.6341s	
1870/32750 (epoch 2.855), train_loss = 2.03569941, grad/param norm = 2.0106e-01, time/batch = 0.6333s	
1871/32750 (epoch 2.856), train_loss = 2.04917986, grad/param norm = 2.1690e-01, time/batch = 0.6366s	
1872/32750 (epoch 2.858), train_loss = 1.96754908, grad/param norm = 2.1743e-01, time/batch = 0.6682s	
1873/32750 (epoch 2.860), train_loss = 1.95573647, grad/param norm = 2.1255e-01, time/batch = 0.6633s	
1874/32750 (epoch 2.861), train_loss = 1.94640481, grad/param norm = 2.1257e-01, time/batch = 0.6325s	
1875/32750 (epoch 2.863), train_loss = 2.12945227, grad/param norm = 2.2154e-01, time/batch = 0.6372s	
1876/32750 (epoch 2.864), train_loss = 1.96410814, grad/param norm = 2.3219e-01, time/batch = 0.6551s	
1877/32750 (epoch 2.866), train_loss = 1.91558049, grad/param norm = 2.0438e-01, time/batch = 0.6728s	
1878/32750 (epoch 2.867), train_loss = 1.85487450, grad/param norm = 2.2319e-01, time/batch = 0.6684s	
1879/32750 (epoch 2.869), train_loss = 2.02321353, grad/param norm = 2.1901e-01, time/batch = 0.6629s	
1880/32750 (epoch 2.870), train_loss = 1.97668294, grad/param norm = 2.1202e-01, time/batch = 0.6481s	
1881/32750 (epoch 2.872), train_loss = 2.06772602, grad/param norm = 2.1069e-01, time/batch = 0.6379s	
1882/32750 (epoch 2.873), train_loss = 1.97444120, grad/param norm = 1.8866e-01, time/batch = 0.6338s	
1883/32750 (epoch 2.875), train_loss = 2.09790747, grad/param norm = 2.1275e-01, time/batch = 0.6339s	
1884/32750 (epoch 2.876), train_loss = 2.13911046, grad/param norm = 2.4389e-01, time/batch = 0.6433s	
1885/32750 (epoch 2.878), train_loss = 1.94341604, grad/param norm = 2.1118e-01, time/batch = 0.6339s	
1886/32750 (epoch 2.879), train_loss = 1.96383508, grad/param norm = 1.9569e-01, time/batch = 0.6340s	
1887/32750 (epoch 2.881), train_loss = 2.04159433, grad/param norm = 2.2063e-01, time/batch = 0.6499s	
1888/32750 (epoch 2.882), train_loss = 1.87899105, grad/param norm = 2.0570e-01, time/batch = 0.6735s	
1889/32750 (epoch 2.884), train_loss = 2.04001875, grad/param norm = 2.1214e-01, time/batch = 0.6409s	
1890/32750 (epoch 2.885), train_loss = 2.03026428, grad/param norm = 1.9630e-01, time/batch = 0.6350s	
1891/32750 (epoch 2.887), train_loss = 2.06091493, grad/param norm = 2.1885e-01, time/batch = 0.6336s	
1892/32750 (epoch 2.889), train_loss = 2.03683150, grad/param norm = 1.8833e-01, time/batch = 0.6342s	
1893/32750 (epoch 2.890), train_loss = 1.93325666, grad/param norm = 1.9191e-01, time/batch = 0.6338s	
1894/32750 (epoch 2.892), train_loss = 2.21029419, grad/param norm = 2.5118e-01, time/batch = 0.6343s	
1895/32750 (epoch 2.893), train_loss = 2.20695922, grad/param norm = 2.3091e-01, time/batch = 0.6343s	
1896/32750 (epoch 2.895), train_loss = 1.90579217, grad/param norm = 1.8514e-01, time/batch = 0.6347s	
1897/32750 (epoch 2.896), train_loss = 1.95422089, grad/param norm = 1.8877e-01, time/batch = 0.6331s	
1898/32750 (epoch 2.898), train_loss = 2.10991629, grad/param norm = 2.1738e-01, time/batch = 0.6339s	
1899/32750 (epoch 2.899), train_loss = 2.05226713, grad/param norm = 2.1872e-01, time/batch = 0.6322s	
1900/32750 (epoch 2.901), train_loss = 2.03648855, grad/param norm = 2.0761e-01, time/batch = 0.6312s	
1901/32750 (epoch 2.902), train_loss = 2.03458575, grad/param norm = 2.1671e-01, time/batch = 0.6334s	
1902/32750 (epoch 2.904), train_loss = 1.88488222, grad/param norm = 2.0618e-01, time/batch = 0.6317s	
1903/32750 (epoch 2.905), train_loss = 2.06100399, grad/param norm = 2.2777e-01, time/batch = 0.6561s	
1904/32750 (epoch 2.907), train_loss = 2.20576082, grad/param norm = 2.2072e-01, time/batch = 0.6390s	
1905/32750 (epoch 2.908), train_loss = 2.17824830, grad/param norm = 1.9539e-01, time/batch = 0.6423s	
1906/32750 (epoch 2.910), train_loss = 1.96914438, grad/param norm = 1.9729e-01, time/batch = 0.6405s	
1907/32750 (epoch 2.911), train_loss = 1.98326364, grad/param norm = 1.8830e-01, time/batch = 0.6328s	
1908/32750 (epoch 2.913), train_loss = 1.91251813, grad/param norm = 1.9954e-01, time/batch = 0.6355s	
1909/32750 (epoch 2.915), train_loss = 1.91117236, grad/param norm = 2.0811e-01, time/batch = 0.6355s	
1910/32750 (epoch 2.916), train_loss = 2.05079863, grad/param norm = 1.9246e-01, time/batch = 0.6348s	
1911/32750 (epoch 2.918), train_loss = 2.19238857, grad/param norm = 2.3052e-01, time/batch = 0.6328s	
1912/32750 (epoch 2.919), train_loss = 2.13582197, grad/param norm = 2.1646e-01, time/batch = 0.6358s	
1913/32750 (epoch 2.921), train_loss = 2.03321593, grad/param norm = 1.9451e-01, time/batch = 0.6317s	
1914/32750 (epoch 2.922), train_loss = 1.94839556, grad/param norm = 1.8236e-01, time/batch = 0.6330s	
1915/32750 (epoch 2.924), train_loss = 1.98370312, grad/param norm = 2.0046e-01, time/batch = 0.6336s	
1916/32750 (epoch 2.925), train_loss = 2.01985324, grad/param norm = 2.1816e-01, time/batch = 0.6310s	
1917/32750 (epoch 2.927), train_loss = 2.14713261, grad/param norm = 2.2602e-01, time/batch = 0.6336s	
1918/32750 (epoch 2.928), train_loss = 2.13412022, grad/param norm = 1.9244e-01, time/batch = 0.6388s	
1919/32750 (epoch 2.930), train_loss = 2.00492554, grad/param norm = 2.0153e-01, time/batch = 0.6331s	
1920/32750 (epoch 2.931), train_loss = 2.00785608, grad/param norm = 1.9046e-01, time/batch = 0.6327s	
1921/32750 (epoch 2.933), train_loss = 2.04098420, grad/param norm = 2.1523e-01, time/batch = 0.6353s	
1922/32750 (epoch 2.934), train_loss = 1.97349807, grad/param norm = 2.0597e-01, time/batch = 0.6336s	
1923/32750 (epoch 2.936), train_loss = 2.13339650, grad/param norm = 2.2561e-01, time/batch = 0.6339s	
1924/32750 (epoch 2.937), train_loss = 1.91373993, grad/param norm = 1.8534e-01, time/batch = 0.6337s	
1925/32750 (epoch 2.939), train_loss = 2.09905965, grad/param norm = 1.9599e-01, time/batch = 0.6329s	
1926/32750 (epoch 2.940), train_loss = 2.04269365, grad/param norm = 2.0384e-01, time/batch = 0.6345s	
1927/32750 (epoch 2.942), train_loss = 1.90943951, grad/param norm = 2.1258e-01, time/batch = 0.6342s	
1928/32750 (epoch 2.944), train_loss = 2.07105410, grad/param norm = 2.0619e-01, time/batch = 0.6389s	
1929/32750 (epoch 2.945), train_loss = 1.95825670, grad/param norm = 1.9949e-01, time/batch = 0.6324s	
1930/32750 (epoch 2.947), train_loss = 2.04429846, grad/param norm = 2.3150e-01, time/batch = 0.6296s	
1931/32750 (epoch 2.948), train_loss = 1.97567227, grad/param norm = 2.1802e-01, time/batch = 0.6321s	
1932/32750 (epoch 2.950), train_loss = 2.00578667, grad/param norm = 2.0032e-01, time/batch = 0.6318s	
1933/32750 (epoch 2.951), train_loss = 1.96582983, grad/param norm = 1.9151e-01, time/batch = 0.6319s	
1934/32750 (epoch 2.953), train_loss = 1.93471969, grad/param norm = 2.0098e-01, time/batch = 0.6529s	
1935/32750 (epoch 2.954), train_loss = 2.00766253, grad/param norm = 1.7022e-01, time/batch = 0.6415s	
1936/32750 (epoch 2.956), train_loss = 2.08156616, grad/param norm = 2.1877e-01, time/batch = 0.6439s	
1937/32750 (epoch 2.957), train_loss = 1.96659771, grad/param norm = 1.9169e-01, time/batch = 0.6359s	
1938/32750 (epoch 2.959), train_loss = 1.95327737, grad/param norm = 2.1244e-01, time/batch = 0.6423s	
1939/32750 (epoch 2.960), train_loss = 2.01218641, grad/param norm = 2.3362e-01, time/batch = 0.6624s	
1940/32750 (epoch 2.962), train_loss = 2.03230174, grad/param norm = 2.1916e-01, time/batch = 0.6628s	
1941/32750 (epoch 2.963), train_loss = 2.01135481, grad/param norm = 2.1796e-01, time/batch = 0.6343s	
1942/32750 (epoch 2.965), train_loss = 2.12834814, grad/param norm = 2.0846e-01, time/batch = 0.6348s	
1943/32750 (epoch 2.966), train_loss = 2.11632390, grad/param norm = 2.1621e-01, time/batch = 0.6368s	
1944/32750 (epoch 2.968), train_loss = 1.91486682, grad/param norm = 2.0774e-01, time/batch = 0.6342s	
1945/32750 (epoch 2.969), train_loss = 1.87296916, grad/param norm = 1.9921e-01, time/batch = 0.6328s	
1946/32750 (epoch 2.971), train_loss = 2.08158337, grad/param norm = 2.0785e-01, time/batch = 0.6310s	
1947/32750 (epoch 2.973), train_loss = 2.08186139, grad/param norm = 2.0519e-01, time/batch = 0.6364s	
1948/32750 (epoch 2.974), train_loss = 2.06840346, grad/param norm = 2.0082e-01, time/batch = 0.6409s	
1949/32750 (epoch 2.976), train_loss = 2.11238250, grad/param norm = 2.1696e-01, time/batch = 0.6374s	
1950/32750 (epoch 2.977), train_loss = 2.23650237, grad/param norm = 2.2645e-01, time/batch = 0.6438s	
1951/32750 (epoch 2.979), train_loss = 2.00425308, grad/param norm = 2.2990e-01, time/batch = 0.6348s	
1952/32750 (epoch 2.980), train_loss = 2.08336910, grad/param norm = 2.0645e-01, time/batch = 0.6364s	
1953/32750 (epoch 2.982), train_loss = 2.01519449, grad/param norm = 2.0002e-01, time/batch = 0.6318s	
1954/32750 (epoch 2.983), train_loss = 1.89707363, grad/param norm = 2.0378e-01, time/batch = 0.6422s	
1955/32750 (epoch 2.985), train_loss = 1.82474579, grad/param norm = 2.0178e-01, time/batch = 0.6732s	
1956/32750 (epoch 2.986), train_loss = 1.85979829, grad/param norm = 2.0816e-01, time/batch = 0.6457s	
1957/32750 (epoch 2.988), train_loss = 1.96698317, grad/param norm = 2.0236e-01, time/batch = 0.6311s	
1958/32750 (epoch 2.989), train_loss = 1.99829017, grad/param norm = 2.0261e-01, time/batch = 0.6388s	
1959/32750 (epoch 2.991), train_loss = 2.07246170, grad/param norm = 1.8894e-01, time/batch = 0.6375s	
1960/32750 (epoch 2.992), train_loss = 1.94389609, grad/param norm = 1.9186e-01, time/batch = 0.6361s	
1961/32750 (epoch 2.994), train_loss = 2.02685509, grad/param norm = 1.9687e-01, time/batch = 0.6321s	
1962/32750 (epoch 2.995), train_loss = 1.96708765, grad/param norm = 1.9138e-01, time/batch = 0.6320s	
1963/32750 (epoch 2.997), train_loss = 2.02598635, grad/param norm = 2.0234e-01, time/batch = 0.6326s	
1964/32750 (epoch 2.998), train_loss = 2.12947054, grad/param norm = 2.0955e-01, time/batch = 0.6330s	
1965/32750 (epoch 3.000), train_loss = 1.94272055, grad/param norm = 1.8398e-01, time/batch = 0.6363s	
1966/32750 (epoch 3.002), train_loss = 2.06275035, grad/param norm = 2.0769e-01, time/batch = 0.6380s	
1967/32750 (epoch 3.003), train_loss = 2.02272099, grad/param norm = 2.2920e-01, time/batch = 0.6321s	
1968/32750 (epoch 3.005), train_loss = 2.12417287, grad/param norm = 2.5563e-01, time/batch = 0.6324s	
1969/32750 (epoch 3.006), train_loss = 2.19371817, grad/param norm = 2.3094e-01, time/batch = 0.6310s	
1970/32750 (epoch 3.008), train_loss = 2.12175020, grad/param norm = 2.0316e-01, time/batch = 0.6327s	
1971/32750 (epoch 3.009), train_loss = 1.94008602, grad/param norm = 1.9203e-01, time/batch = 0.6387s	
1972/32750 (epoch 3.011), train_loss = 1.85640972, grad/param norm = 2.0843e-01, time/batch = 0.6352s	
1973/32750 (epoch 3.012), train_loss = 2.08356840, grad/param norm = 2.0410e-01, time/batch = 0.6335s	
1974/32750 (epoch 3.014), train_loss = 2.22773368, grad/param norm = 2.0698e-01, time/batch = 0.6389s	
1975/32750 (epoch 3.015), train_loss = 2.08511188, grad/param norm = 1.9905e-01, time/batch = 0.6456s	
1976/32750 (epoch 3.017), train_loss = 2.00585922, grad/param norm = 2.2083e-01, time/batch = 0.6359s	
1977/32750 (epoch 3.018), train_loss = 2.10967460, grad/param norm = 2.4738e-01, time/batch = 0.6329s	
1978/32750 (epoch 3.020), train_loss = 2.01752328, grad/param norm = 2.2049e-01, time/batch = 0.6364s	
1979/32750 (epoch 3.021), train_loss = 1.96614361, grad/param norm = 1.9547e-01, time/batch = 0.6330s	
1980/32750 (epoch 3.023), train_loss = 1.88772706, grad/param norm = 2.0571e-01, time/batch = 0.6327s	
1981/32750 (epoch 3.024), train_loss = 2.13986091, grad/param norm = 1.9536e-01, time/batch = 0.6367s	
1982/32750 (epoch 3.026), train_loss = 1.97475711, grad/param norm = 1.8852e-01, time/batch = 0.6415s	
1983/32750 (epoch 3.027), train_loss = 2.05513516, grad/param norm = 2.0556e-01, time/batch = 0.6468s	
1984/32750 (epoch 3.029), train_loss = 1.98255760, grad/param norm = 1.9881e-01, time/batch = 0.6526s	
1985/32750 (epoch 3.031), train_loss = 2.01829717, grad/param norm = 2.2086e-01, time/batch = 0.6524s	
1986/32750 (epoch 3.032), train_loss = 2.01690193, grad/param norm = 2.1635e-01, time/batch = 0.6314s	
1987/32750 (epoch 3.034), train_loss = 1.99062782, grad/param norm = 2.0457e-01, time/batch = 0.6368s	
1988/32750 (epoch 3.035), train_loss = 1.90100316, grad/param norm = 1.9045e-01, time/batch = 0.6401s	
1989/32750 (epoch 3.037), train_loss = 2.03855964, grad/param norm = 1.8651e-01, time/batch = 0.6332s	
1990/32750 (epoch 3.038), train_loss = 2.18574098, grad/param norm = 2.0296e-01, time/batch = 0.6449s	
1991/32750 (epoch 3.040), train_loss = 2.11909537, grad/param norm = 1.9553e-01, time/batch = 0.6754s	
1992/32750 (epoch 3.041), train_loss = 2.00339793, grad/param norm = 1.9332e-01, time/batch = 0.6413s	
1993/32750 (epoch 3.043), train_loss = 2.04558932, grad/param norm = 1.9804e-01, time/batch = 0.6333s	
1994/32750 (epoch 3.044), train_loss = 1.90253396, grad/param norm = 1.9610e-01, time/batch = 0.6309s	
1995/32750 (epoch 3.046), train_loss = 2.04619402, grad/param norm = 1.9856e-01, time/batch = 0.6325s	
1996/32750 (epoch 3.047), train_loss = 1.96369281, grad/param norm = 2.1870e-01, time/batch = 0.6357s	
1997/32750 (epoch 3.049), train_loss = 1.88180014, grad/param norm = 2.1689e-01, time/batch = 0.6377s	
1998/32750 (epoch 3.050), train_loss = 1.76641565, grad/param norm = 2.0687e-01, time/batch = 0.6329s	
1999/32750 (epoch 3.052), train_loss = 1.86146477, grad/param norm = 1.7703e-01, time/batch = 0.6359s	
evaluating loss over split index 2	
1/35...	
2/35...	
3/35...	
4/35...	
5/35...	
6/35...	
7/35...	
8/35...	
9/35...	
10/35...	
11/35...	
12/35...	
13/35...	
14/35...	
15/35...	
16/35...	
17/35...	
18/35...	
19/35...	
20/35...	
21/35...	
22/35...	
23/35...	
24/35...	
25/35...	
26/35...	
27/35...	
28/35...	
29/35...	
30/35...	
31/35...	
32/35...	
33/35...	
34/35...	
35/35...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_ubersein_epoch3.05_2.0590.t7	
2000/32750 (epoch 3.053), train_loss = 1.98506277, grad/param norm = 1.9658e-01, time/batch = 0.6329s	
2001/32750 (epoch 3.055), train_loss = 2.17564232, grad/param norm = 2.2317e-01, time/batch = 0.6413s	
2002/32750 (epoch 3.056), train_loss = 2.09449122, grad/param norm = 2.1802e-01, time/batch = 0.6337s	
2003/32750 (epoch 3.058), train_loss = 1.93568881, grad/param norm = 2.2419e-01, time/batch = 0.6380s	
2004/32750 (epoch 3.060), train_loss = 1.90017649, grad/param norm = 2.2060e-01, time/batch = 0.6410s	
2005/32750 (epoch 3.061), train_loss = 2.12694168, grad/param norm = 1.9411e-01, time/batch = 0.6385s	
2006/32750 (epoch 3.063), train_loss = 2.05699933, grad/param norm = 2.0662e-01, time/batch = 0.6405s	
2007/32750 (epoch 3.064), train_loss = 1.96231728, grad/param norm = 2.2769e-01, time/batch = 0.6393s	
2008/32750 (epoch 3.066), train_loss = 1.84377810, grad/param norm = 1.8699e-01, time/batch = 0.6359s	
2009/32750 (epoch 3.067), train_loss = 2.04326034, grad/param norm = 2.0104e-01, time/batch = 0.6375s	
2010/32750 (epoch 3.069), train_loss = 2.24972425, grad/param norm = 2.2939e-01, time/batch = 0.6382s	
2011/32750 (epoch 3.070), train_loss = 2.02087537, grad/param norm = 1.9322e-01, time/batch = 0.6346s	
2012/32750 (epoch 3.072), train_loss = 1.98252601, grad/param norm = 2.0074e-01, time/batch = 0.6587s	
2013/32750 (epoch 3.073), train_loss = 1.84140479, grad/param norm = 1.7845e-01, time/batch = 0.6678s	
2014/32750 (epoch 3.075), train_loss = 1.87514869, grad/param norm = 1.9853e-01, time/batch = 0.6331s	
2015/32750 (epoch 3.076), train_loss = 2.19718225, grad/param norm = 2.0628e-01, time/batch = 0.6330s	
2016/32750 (epoch 3.078), train_loss = 2.10376539, grad/param norm = 2.1371e-01, time/batch = 0.6337s	
2017/32750 (epoch 3.079), train_loss = 2.03817479, grad/param norm = 2.0027e-01, time/batch = 0.6336s	
2018/32750 (epoch 3.081), train_loss = 1.91264135, grad/param norm = 1.9812e-01, time/batch = 0.6558s	
2019/32750 (epoch 3.082), train_loss = 1.95708449, grad/param norm = 2.0910e-01, time/batch = 0.6558s	
2020/32750 (epoch 3.084), train_loss = 1.96308249, grad/param norm = 1.9096e-01, time/batch = 0.6564s	
2021/32750 (epoch 3.085), train_loss = 1.85373581, grad/param norm = 2.0027e-01, time/batch = 0.6507s	
2022/32750 (epoch 3.087), train_loss = 2.05409761, grad/param norm = 1.9592e-01, time/batch = 0.6409s	
2023/32750 (epoch 3.089), train_loss = 2.03333854, grad/param norm = 1.9732e-01, time/batch = 0.6353s	
2024/32750 (epoch 3.090), train_loss = 2.01235095, grad/param norm = 2.1619e-01, time/batch = 0.6335s	
2025/32750 (epoch 3.092), train_loss = 1.91746087, grad/param norm = 2.4669e-01, time/batch = 0.6347s	
2026/32750 (epoch 3.093), train_loss = 1.99566544, grad/param norm = 2.1357e-01, time/batch = 0.6348s	
2027/32750 (epoch 3.095), train_loss = 2.02625879, grad/param norm = 1.9492e-01, time/batch = 0.6414s	
2028/32750 (epoch 3.096), train_loss = 1.99135220, grad/param norm = 2.1595e-01, time/batch = 0.6732s	
2029/32750 (epoch 3.098), train_loss = 2.04068294, grad/param norm = 2.0379e-01, time/batch = 0.6471s	
2030/32750 (epoch 3.099), train_loss = 2.02685654, grad/param norm = 2.1860e-01, time/batch = 0.6449s	
2031/32750 (epoch 3.101), train_loss = 1.95710818, grad/param norm = 2.0253e-01, time/batch = 0.6428s	
2032/32750 (epoch 3.102), train_loss = 2.05865640, grad/param norm = 2.0375e-01, time/batch = 0.6337s	
2033/32750 (epoch 3.104), train_loss = 2.02501924, grad/param norm = 1.8866e-01, time/batch = 0.6329s	
2034/32750 (epoch 3.105), train_loss = 1.95686883, grad/param norm = 2.1589e-01, time/batch = 0.6391s	
2035/32750 (epoch 3.107), train_loss = 1.94248814, grad/param norm = 2.2712e-01, time/batch = 0.6338s	
2036/32750 (epoch 3.108), train_loss = 2.16863148, grad/param norm = 2.0799e-01, time/batch = 0.6336s	
2037/32750 (epoch 3.110), train_loss = 2.02010319, grad/param norm = 2.2071e-01, time/batch = 0.6312s	
2038/32750 (epoch 3.111), train_loss = 2.01758180, grad/param norm = 1.9221e-01, time/batch = 0.6348s	
2039/32750 (epoch 3.113), train_loss = 2.03143148, grad/param norm = 2.0005e-01, time/batch = 0.6319s	
2040/32750 (epoch 3.115), train_loss = 2.00763526, grad/param norm = 2.1807e-01, time/batch = 0.6337s	
2041/32750 (epoch 3.116), train_loss = 1.95696374, grad/param norm = 2.0583e-01, time/batch = 0.6349s	
2042/32750 (epoch 3.118), train_loss = 1.97470466, grad/param norm = 1.9072e-01, time/batch = 0.6347s	
2043/32750 (epoch 3.119), train_loss = 2.10507808, grad/param norm = 1.9161e-01, time/batch = 0.6530s	
2044/32750 (epoch 3.121), train_loss = 1.97658072, grad/param norm = 1.8352e-01, time/batch = 0.6355s	
2045/32750 (epoch 3.122), train_loss = 1.91423363, grad/param norm = 2.0765e-01, time/batch = 0.6319s	
2046/32750 (epoch 3.124), train_loss = 2.09665048, grad/param norm = 2.2117e-01, time/batch = 0.6315s	
2047/32750 (epoch 3.125), train_loss = 1.94548982, grad/param norm = 1.9927e-01, time/batch = 0.6312s	
2048/32750 (epoch 3.127), train_loss = 2.10120775, grad/param norm = 2.0587e-01, time/batch = 0.6324s	
2049/32750 (epoch 3.128), train_loss = 1.98345692, grad/param norm = 1.9859e-01, time/batch = 0.6323s	
2050/32750 (epoch 3.130), train_loss = 2.03262602, grad/param norm = 2.1017e-01, time/batch = 0.6395s	
2051/32750 (epoch 3.131), train_loss = 2.03486468, grad/param norm = 2.0869e-01, time/batch = 0.6350s	
2052/32750 (epoch 3.133), train_loss = 2.05720916, grad/param norm = 1.8641e-01, time/batch = 0.6326s	
2053/32750 (epoch 3.134), train_loss = 1.97219595, grad/param norm = 1.9220e-01, time/batch = 0.6341s	
2054/32750 (epoch 3.136), train_loss = 2.19814304, grad/param norm = 1.9757e-01, time/batch = 0.6418s	
2055/32750 (epoch 3.137), train_loss = 2.09673085, grad/param norm = 1.9644e-01, time/batch = 0.6440s	
2056/32750 (epoch 3.139), train_loss = 2.00475025, grad/param norm = 1.9979e-01, time/batch = 0.6349s	
2057/32750 (epoch 3.140), train_loss = 1.93749053, grad/param norm = 2.0220e-01, time/batch = 0.6330s	
2058/32750 (epoch 3.142), train_loss = 2.07272168, grad/param norm = 2.1052e-01, time/batch = 0.6351s	
2059/32750 (epoch 3.144), train_loss = 2.00410644, grad/param norm = 2.0818e-01, time/batch = 0.6710s	
2060/32750 (epoch 3.145), train_loss = 1.92532768, grad/param norm = 1.9499e-01, time/batch = 0.6549s	
2061/32750 (epoch 3.147), train_loss = 1.86818193, grad/param norm = 1.9832e-01, time/batch = 0.6328s	
2062/32750 (epoch 3.148), train_loss = 2.07242318, grad/param norm = 2.0763e-01, time/batch = 0.6327s	
2063/32750 (epoch 3.150), train_loss = 1.96888220, grad/param norm = 1.8980e-01, time/batch = 0.6352s	
2064/32750 (epoch 3.151), train_loss = 1.93832485, grad/param norm = 2.1015e-01, time/batch = 0.6384s	
2065/32750 (epoch 3.153), train_loss = 1.93631476, grad/param norm = 1.9281e-01, time/batch = 0.6383s	
2066/32750 (epoch 3.154), train_loss = 2.00540344, grad/param norm = 1.9598e-01, time/batch = 0.6324s	
2067/32750 (epoch 3.156), train_loss = 1.93500797, grad/param norm = 1.9010e-01, time/batch = 0.6335s	
2068/32750 (epoch 3.157), train_loss = 1.85028854, grad/param norm = 2.1040e-01, time/batch = 0.6529s	
2069/32750 (epoch 3.159), train_loss = 1.82077740, grad/param norm = 1.9001e-01, time/batch = 0.6711s	
2070/32750 (epoch 3.160), train_loss = 1.99118038, grad/param norm = 2.1079e-01, time/batch = 0.6511s	
2071/32750 (epoch 3.162), train_loss = 2.03646413, grad/param norm = 1.9448e-01, time/batch = 0.6563s	
2072/32750 (epoch 3.163), train_loss = 1.99583841, grad/param norm = 1.9811e-01, time/batch = 0.6566s	
2073/32750 (epoch 3.165), train_loss = 1.86916615, grad/param norm = 1.7764e-01, time/batch = 0.6558s	
2074/32750 (epoch 3.166), train_loss = 1.94718776, grad/param norm = 1.8925e-01, time/batch = 0.6641s	
2075/32750 (epoch 3.168), train_loss = 2.06797181, grad/param norm = 1.9724e-01, time/batch = 0.6723s	
2076/32750 (epoch 3.169), train_loss = 2.00699668, grad/param norm = 1.8801e-01, time/batch = 0.6523s	
2077/32750 (epoch 3.171), train_loss = 1.81736692, grad/param norm = 2.2942e-01, time/batch = 0.6547s	
2078/32750 (epoch 3.173), train_loss = 2.15334655, grad/param norm = 2.3731e-01, time/batch = 0.6568s	
2079/32750 (epoch 3.174), train_loss = 1.89577148, grad/param norm = 2.0675e-01, time/batch = 0.6382s	
2080/32750 (epoch 3.176), train_loss = 1.96516929, grad/param norm = 1.8806e-01, time/batch = 0.6405s	
2081/32750 (epoch 3.177), train_loss = 2.22659868, grad/param norm = 2.1803e-01, time/batch = 0.6378s	
2082/32750 (epoch 3.179), train_loss = 2.11041942, grad/param norm = 2.1858e-01, time/batch = 0.6356s	
2083/32750 (epoch 3.180), train_loss = 2.12982503, grad/param norm = 2.1361e-01, time/batch = 0.6338s	
2084/32750 (epoch 3.182), train_loss = 1.91405363, grad/param norm = 1.8704e-01, time/batch = 0.6366s	
2085/32750 (epoch 3.183), train_loss = 1.93745766, grad/param norm = 1.8959e-01, time/batch = 0.6339s	
2086/32750 (epoch 3.185), train_loss = 1.75708385, grad/param norm = 2.1188e-01, time/batch = 0.6344s	
2087/32750 (epoch 3.186), train_loss = 1.95587492, grad/param norm = 1.9991e-01, time/batch = 0.6339s	
2088/32750 (epoch 3.188), train_loss = 2.08433229, grad/param norm = 2.0954e-01, time/batch = 0.6440s	
2089/32750 (epoch 3.189), train_loss = 2.00664896, grad/param norm = 1.7655e-01, time/batch = 0.6375s	
2090/32750 (epoch 3.191), train_loss = 2.00282244, grad/param norm = 1.8362e-01, time/batch = 0.6729s	
2091/32750 (epoch 3.192), train_loss = 1.84350612, grad/param norm = 2.0235e-01, time/batch = 0.6472s	
2092/32750 (epoch 3.194), train_loss = 1.88768278, grad/param norm = 1.9995e-01, time/batch = 0.6320s	
2093/32750 (epoch 3.195), train_loss = 1.84676511, grad/param norm = 1.7762e-01, time/batch = 0.6344s	
2094/32750 (epoch 3.197), train_loss = 1.97043983, grad/param norm = 1.9011e-01, time/batch = 0.6347s	
2095/32750 (epoch 3.198), train_loss = 1.87190133, grad/param norm = 2.1300e-01, time/batch = 0.6328s	
2096/32750 (epoch 3.200), train_loss = 1.98304895, grad/param norm = 1.9957e-01, time/batch = 0.6348s	
2097/32750 (epoch 3.202), train_loss = 2.04081227, grad/param norm = 1.9179e-01, time/batch = 0.6359s	
2098/32750 (epoch 3.203), train_loss = 2.01487347, grad/param norm = 2.1926e-01, time/batch = 0.6344s	
2099/32750 (epoch 3.205), train_loss = 1.92756706, grad/param norm = 1.9755e-01, time/batch = 0.6314s	
2100/32750 (epoch 3.206), train_loss = 1.85707829, grad/param norm = 2.1247e-01, time/batch = 0.6318s	
2101/32750 (epoch 3.208), train_loss = 2.00015021, grad/param norm = 1.8848e-01, time/batch = 0.6354s	
2102/32750 (epoch 3.209), train_loss = 1.96279003, grad/param norm = 1.8420e-01, time/batch = 0.6357s	
2103/32750 (epoch 3.211), train_loss = 1.96431818, grad/param norm = 2.0504e-01, time/batch = 0.6339s	
2104/32750 (epoch 3.212), train_loss = 1.89840491, grad/param norm = 1.8471e-01, time/batch = 0.6337s	
2105/32750 (epoch 3.214), train_loss = 1.95394783, grad/param norm = 1.9450e-01, time/batch = 0.6547s	
2106/32750 (epoch 3.215), train_loss = 1.97109706, grad/param norm = 2.3201e-01, time/batch = 0.6721s	
2107/32750 (epoch 3.217), train_loss = 2.02630589, grad/param norm = 2.1288e-01, time/batch = 0.6341s	
2108/32750 (epoch 3.218), train_loss = 1.82022918, grad/param norm = 1.9664e-01, time/batch = 0.6343s	
2109/32750 (epoch 3.220), train_loss = 2.04565490, grad/param norm = 2.2838e-01, time/batch = 0.6348s	
2110/32750 (epoch 3.221), train_loss = 1.91340135, grad/param norm = 1.7909e-01, time/batch = 0.6322s	
2111/32750 (epoch 3.223), train_loss = 1.83672783, grad/param norm = 1.8238e-01, time/batch = 0.6640s	
2112/32750 (epoch 3.224), train_loss = 2.17640279, grad/param norm = 2.3507e-01, time/batch = 0.6388s	
2113/32750 (epoch 3.226), train_loss = 1.83378809, grad/param norm = 1.9390e-01, time/batch = 0.6529s	
2114/32750 (epoch 3.227), train_loss = 1.84377368, grad/param norm = 1.9433e-01, time/batch = 0.6508s	
2115/32750 (epoch 3.229), train_loss = 1.94894164, grad/param norm = 2.0083e-01, time/batch = 0.6361s	
2116/32750 (epoch 3.231), train_loss = 2.03663638, grad/param norm = 2.5083e-01, time/batch = 0.6310s	
2117/32750 (epoch 3.232), train_loss = 1.95541685, grad/param norm = 2.2037e-01, time/batch = 0.6360s	
2118/32750 (epoch 3.234), train_loss = 1.85727751, grad/param norm = 1.8305e-01, time/batch = 0.6390s	
2119/32750 (epoch 3.235), train_loss = 1.92359500, grad/param norm = 1.9882e-01, time/batch = 0.6494s	
2120/32750 (epoch 3.237), train_loss = 1.96014615, grad/param norm = 1.7875e-01, time/batch = 0.6350s	
2121/32750 (epoch 3.238), train_loss = 1.87428278, grad/param norm = 1.8986e-01, time/batch = 0.6356s	
2122/32750 (epoch 3.240), train_loss = 1.99878510, grad/param norm = 1.9326e-01, time/batch = 0.6344s	
2123/32750 (epoch 3.241), train_loss = 2.16657347, grad/param norm = 2.2142e-01, time/batch = 0.6329s	
2124/32750 (epoch 3.243), train_loss = 2.01886496, grad/param norm = 2.0317e-01, time/batch = 0.6325s	
2125/32750 (epoch 3.244), train_loss = 2.07437953, grad/param norm = 2.0627e-01, time/batch = 0.6337s	
2126/32750 (epoch 3.246), train_loss = 1.89824021, grad/param norm = 1.7213e-01, time/batch = 0.6331s	
2127/32750 (epoch 3.247), train_loss = 2.01155446, grad/param norm = 1.8606e-01, time/batch = 0.6348s	
2128/32750 (epoch 3.249), train_loss = 1.79921131, grad/param norm = 1.8921e-01, time/batch = 0.6427s	
2129/32750 (epoch 3.250), train_loss = 2.10269094, grad/param norm = 1.9683e-01, time/batch = 0.6343s	
2130/32750 (epoch 3.252), train_loss = 1.87975497, grad/param norm = 1.7868e-01, time/batch = 0.6326s	
2131/32750 (epoch 3.253), train_loss = 1.85683608, grad/param norm = 1.9284e-01, time/batch = 0.6406s	
2132/32750 (epoch 3.255), train_loss = 2.11473362, grad/param norm = 2.0130e-01, time/batch = 0.6338s	
2133/32750 (epoch 3.256), train_loss = 1.84886559, grad/param norm = 1.7568e-01, time/batch = 0.6352s	
2134/32750 (epoch 3.258), train_loss = 2.07693327, grad/param norm = 2.1575e-01, time/batch = 0.6350s	
2135/32750 (epoch 3.260), train_loss = 2.11250556, grad/param norm = 2.1145e-01, time/batch = 0.6342s	
2136/32750 (epoch 3.261), train_loss = 2.07913824, grad/param norm = 2.0547e-01, time/batch = 0.6341s	
2137/32750 (epoch 3.263), train_loss = 2.04352187, grad/param norm = 1.9819e-01, time/batch = 0.6532s	
2138/32750 (epoch 3.264), train_loss = 1.94958608, grad/param norm = 1.8108e-01, time/batch = 0.6525s	
2139/32750 (epoch 3.266), train_loss = 1.85605731, grad/param norm = 1.8309e-01, time/batch = 0.6632s	
2140/32750 (epoch 3.267), train_loss = 2.05503219, grad/param norm = 1.8580e-01, time/batch = 0.6542s	
2141/32750 (epoch 3.269), train_loss = 1.85625285, grad/param norm = 1.9311e-01, time/batch = 0.6395s	
2142/32750 (epoch 3.270), train_loss = 2.07487603, grad/param norm = 2.0449e-01, time/batch = 0.6372s	
2143/32750 (epoch 3.272), train_loss = 1.96383792, grad/param norm = 1.9175e-01, time/batch = 0.6340s	
2144/32750 (epoch 3.273), train_loss = 2.05922830, grad/param norm = 1.9855e-01, time/batch = 0.6333s	
2145/32750 (epoch 3.275), train_loss = 2.00070207, grad/param norm = 1.9301e-01, time/batch = 0.6348s	
2146/32750 (epoch 3.276), train_loss = 2.06355373, grad/param norm = 2.1803e-01, time/batch = 0.6341s	
2147/32750 (epoch 3.278), train_loss = 2.00801743, grad/param norm = 2.0015e-01, time/batch = 0.6443s	
2148/32750 (epoch 3.279), train_loss = 2.14375120, grad/param norm = 2.0295e-01, time/batch = 0.6333s	
2149/32750 (epoch 3.281), train_loss = 1.95617008, grad/param norm = 1.9198e-01, time/batch = 0.6365s	
2150/32750 (epoch 3.282), train_loss = 1.90289826, grad/param norm = 2.2160e-01, time/batch = 0.6390s	
2151/32750 (epoch 3.284), train_loss = 2.21352628, grad/param norm = 2.4138e-01, time/batch = 0.6359s	
2152/32750 (epoch 3.285), train_loss = 2.11724761, grad/param norm = 2.2067e-01, time/batch = 0.6692s	
2153/32750 (epoch 3.287), train_loss = 1.94866524, grad/param norm = 1.7340e-01, time/batch = 0.6579s	
2154/32750 (epoch 3.289), train_loss = 2.05585429, grad/param norm = 1.9420e-01, time/batch = 0.6326s	
2155/32750 (epoch 3.290), train_loss = 1.94801642, grad/param norm = 1.9289e-01, time/batch = 0.6334s	
2156/32750 (epoch 3.292), train_loss = 1.93665895, grad/param norm = 2.1490e-01, time/batch = 0.6333s	
2157/32750 (epoch 3.293), train_loss = 1.86437016, grad/param norm = 1.9963e-01, time/batch = 0.6337s	
2158/32750 (epoch 3.295), train_loss = 2.02412567, grad/param norm = 2.1595e-01, time/batch = 0.6444s	
2159/32750 (epoch 3.296), train_loss = 1.94278564, grad/param norm = 1.9274e-01, time/batch = 0.6337s	
2160/32750 (epoch 3.298), train_loss = 1.88922438, grad/param norm = 1.7785e-01, time/batch = 0.6359s	
2161/32750 (epoch 3.299), train_loss = 1.90073177, grad/param norm = 1.8223e-01, time/batch = 0.6347s	
2162/32750 (epoch 3.301), train_loss = 1.96087730, grad/param norm = 2.0662e-01, time/batch = 0.6356s	
2163/32750 (epoch 3.302), train_loss = 1.83032877, grad/param norm = 2.2906e-01, time/batch = 0.6341s	
2164/32750 (epoch 3.304), train_loss = 1.97275569, grad/param norm = 2.1431e-01, time/batch = 0.6349s	
2165/32750 (epoch 3.305), train_loss = 1.99976322, grad/param norm = 2.0084e-01, time/batch = 0.6357s	
2166/32750 (epoch 3.307), train_loss = 2.06063889, grad/param norm = 1.9629e-01, time/batch = 0.6381s	
2167/32750 (epoch 3.308), train_loss = 1.98114793, grad/param norm = 1.8198e-01, time/batch = 0.6513s	
2168/32750 (epoch 3.310), train_loss = 1.98297633, grad/param norm = 1.7398e-01, time/batch = 0.6419s	
2169/32750 (epoch 3.311), train_loss = 1.93738694, grad/param norm = 1.8932e-01, time/batch = 0.6388s	
2170/32750 (epoch 3.313), train_loss = 1.97883845, grad/param norm = 1.9671e-01, time/batch = 0.6333s	
2171/32750 (epoch 3.315), train_loss = 1.96921654, grad/param norm = 2.0158e-01, time/batch = 0.6332s	
2172/32750 (epoch 3.316), train_loss = 2.04510161, grad/param norm = 1.8719e-01, time/batch = 0.6334s	
2173/32750 (epoch 3.318), train_loss = 1.90330035, grad/param norm = 2.1298e-01, time/batch = 0.6337s	
2174/32750 (epoch 3.319), train_loss = 2.04394993, grad/param norm = 2.1184e-01, time/batch = 0.6337s	
2175/32750 (epoch 3.321), train_loss = 2.02324797, grad/param norm = 2.0491e-01, time/batch = 0.6352s	
2176/32750 (epoch 3.322), train_loss = 2.02118084, grad/param norm = 2.2348e-01, time/batch = 0.6357s	
2177/32750 (epoch 3.324), train_loss = 2.00502124, grad/param norm = 1.9164e-01, time/batch = 0.6401s	
2178/32750 (epoch 3.325), train_loss = 2.00622769, grad/param norm = 2.2088e-01, time/batch = 0.6361s	
2179/32750 (epoch 3.327), train_loss = 1.87523997, grad/param norm = 1.7289e-01, time/batch = 0.6327s	
2180/32750 (epoch 3.328), train_loss = 1.80607764, grad/param norm = 1.6692e-01, time/batch = 0.6348s	
2181/32750 (epoch 3.330), train_loss = 1.91523053, grad/param norm = 1.7252e-01, time/batch = 0.6345s	
2182/32750 (epoch 3.331), train_loss = 1.92279436, grad/param norm = 1.9382e-01, time/batch = 0.6334s	
2183/32750 (epoch 3.333), train_loss = 1.82032316, grad/param norm = 1.7083e-01, time/batch = 0.6599s	
2184/32750 (epoch 3.334), train_loss = 2.09951212, grad/param norm = 1.8273e-01, time/batch = 0.6668s	
2185/32750 (epoch 3.336), train_loss = 1.93404206, grad/param norm = 1.9457e-01, time/batch = 0.6323s	
2186/32750 (epoch 3.337), train_loss = 1.86796093, grad/param norm = 2.0007e-01, time/batch = 0.6326s	
2187/32750 (epoch 3.339), train_loss = 2.22541022, grad/param norm = 2.1321e-01, time/batch = 0.6324s	
2188/32750 (epoch 3.340), train_loss = 1.79301804, grad/param norm = 1.8819e-01, time/batch = 0.6323s	
2189/32750 (epoch 3.342), train_loss = 2.03530117, grad/param norm = 2.1224e-01, time/batch = 0.6410s	
2190/32750 (epoch 3.344), train_loss = 2.11807956, grad/param norm = 1.8228e-01, time/batch = 0.6325s	
2191/32750 (epoch 3.345), train_loss = 2.06138158, grad/param norm = 2.0997e-01, time/batch = 0.6333s	
2192/32750 (epoch 3.347), train_loss = 2.02675007, grad/param norm = 2.1912e-01, time/batch = 0.6319s	
2193/32750 (epoch 3.348), train_loss = 1.95572121, grad/param norm = 1.8672e-01, time/batch = 0.6312s	
2194/32750 (epoch 3.350), train_loss = 2.05184406, grad/param norm = 1.8908e-01, time/batch = 0.6322s	
2195/32750 (epoch 3.351), train_loss = 2.12061700, grad/param norm = 1.8841e-01, time/batch = 0.6323s	
2196/32750 (epoch 3.353), train_loss = 1.91681716, grad/param norm = 1.9394e-01, time/batch = 0.6337s	
2197/32750 (epoch 3.354), train_loss = 1.85089765, grad/param norm = 2.0063e-01, time/batch = 0.6341s	
2198/32750 (epoch 3.356), train_loss = 1.96765442, grad/param norm = 2.1259e-01, time/batch = 0.6359s	
2199/32750 (epoch 3.357), train_loss = 1.77393719, grad/param norm = 2.0137e-01, time/batch = 0.6731s	
2200/32750 (epoch 3.359), train_loss = 2.00322601, grad/param norm = 2.0883e-01, time/batch = 0.6510s	
2201/32750 (epoch 3.360), train_loss = 1.82594932, grad/param norm = 2.0042e-01, time/batch = 0.6323s	
2202/32750 (epoch 3.362), train_loss = 1.91816158, grad/param norm = 2.0859e-01, time/batch = 0.6314s	
2203/32750 (epoch 3.363), train_loss = 1.84442496, grad/param norm = 2.0935e-01, time/batch = 0.6327s	
2204/32750 (epoch 3.365), train_loss = 1.88610325, grad/param norm = 1.7997e-01, time/batch = 0.6380s	
2205/32750 (epoch 3.366), train_loss = 1.90157266, grad/param norm = 1.9020e-01, time/batch = 0.6525s	
2206/32750 (epoch 3.368), train_loss = 2.10158986, grad/param norm = 2.0717e-01, time/batch = 0.6406s	
2207/32750 (epoch 3.369), train_loss = 2.08667583, grad/param norm = 2.0626e-01, time/batch = 0.6437s	
2208/32750 (epoch 3.371), train_loss = 1.91813257, grad/param norm = 2.0127e-01, time/batch = 0.6365s	
2209/32750 (epoch 3.373), train_loss = 1.95167982, grad/param norm = 1.8595e-01, time/batch = 0.6473s	
2210/32750 (epoch 3.374), train_loss = 2.02288187, grad/param norm = 2.0263e-01, time/batch = 0.6499s	
2211/32750 (epoch 3.376), train_loss = 1.81630334, grad/param norm = 1.9146e-01, time/batch = 0.6430s	
2212/32750 (epoch 3.377), train_loss = 1.94315181, grad/param norm = 1.8300e-01, time/batch = 0.6515s	
2213/32750 (epoch 3.379), train_loss = 1.89587023, grad/param norm = 2.0894e-01, time/batch = 0.6391s	
2214/32750 (epoch 3.380), train_loss = 2.08943478, grad/param norm = 2.2108e-01, time/batch = 0.6593s	
2215/32750 (epoch 3.382), train_loss = 1.96909233, grad/param norm = 2.0866e-01, time/batch = 0.6703s	
2216/32750 (epoch 3.383), train_loss = 1.96452178, grad/param norm = 2.0283e-01, time/batch = 0.6557s	
2217/32750 (epoch 3.385), train_loss = 2.01437994, grad/param norm = 1.9742e-01, time/batch = 0.6462s	
2218/32750 (epoch 3.386), train_loss = 2.05089657, grad/param norm = 2.1111e-01, time/batch = 0.6355s	
2219/32750 (epoch 3.388), train_loss = 1.97549884, grad/param norm = 1.9807e-01, time/batch = 0.6383s	
2220/32750 (epoch 3.389), train_loss = 1.93464588, grad/param norm = 1.8285e-01, time/batch = 0.6542s	
2221/32750 (epoch 3.391), train_loss = 1.82430716, grad/param norm = 1.9140e-01, time/batch = 0.6394s	
2222/32750 (epoch 3.392), train_loss = 1.89996446, grad/param norm = 1.9753e-01, time/batch = 0.6371s	
2223/32750 (epoch 3.394), train_loss = 1.91155432, grad/param norm = 1.9255e-01, time/batch = 0.6438s	
2224/32750 (epoch 3.395), train_loss = 1.92489463, grad/param norm = 2.1867e-01, time/batch = 0.6377s	
2225/32750 (epoch 3.397), train_loss = 2.10930735, grad/param norm = 2.2076e-01, time/batch = 0.6439s	
2226/32750 (epoch 3.398), train_loss = 2.06772368, grad/param norm = 2.2732e-01, time/batch = 0.6524s	
2227/32750 (epoch 3.400), train_loss = 1.95047755, grad/param norm = 1.8445e-01, time/batch = 0.6406s	
2228/32750 (epoch 3.402), train_loss = 1.93603418, grad/param norm = 2.0389e-01, time/batch = 0.6396s	
2229/32750 (epoch 3.403), train_loss = 1.97220085, grad/param norm = 1.9491e-01, time/batch = 0.6414s	
2230/32750 (epoch 3.405), train_loss = 2.00099427, grad/param norm = 1.9356e-01, time/batch = 0.6375s	
2231/32750 (epoch 3.406), train_loss = 1.71785450, grad/param norm = 1.8705e-01, time/batch = 0.6461s	
2232/32750 (epoch 3.408), train_loss = 1.72150345, grad/param norm = 1.6882e-01, time/batch = 0.6561s	
2233/32750 (epoch 3.409), train_loss = 2.06524854, grad/param norm = 2.0750e-01, time/batch = 0.6436s	
2234/32750 (epoch 3.411), train_loss = 1.77493511, grad/param norm = 1.8394e-01, time/batch = 0.6440s	
2235/32750 (epoch 3.412), train_loss = 1.78127898, grad/param norm = 1.9156e-01, time/batch = 0.6473s	
2236/32750 (epoch 3.414), train_loss = 1.69840790, grad/param norm = 1.9006e-01, time/batch = 0.6651s	
2237/32750 (epoch 3.415), train_loss = 1.79647062, grad/param norm = 1.9158e-01, time/batch = 0.6523s	
2238/32750 (epoch 3.417), train_loss = 1.76051379, grad/param norm = 2.3024e-01, time/batch = 0.6381s	
2239/32750 (epoch 3.418), train_loss = 1.95070151, grad/param norm = 2.0643e-01, time/batch = 0.6367s	
2240/32750 (epoch 3.420), train_loss = 1.89841328, grad/param norm = 1.8799e-01, time/batch = 0.6535s	
2241/32750 (epoch 3.421), train_loss = 1.90009691, grad/param norm = 1.9935e-01, time/batch = 0.6504s	
2242/32750 (epoch 3.423), train_loss = 1.80919728, grad/param norm = 2.1375e-01, time/batch = 0.6425s	
2243/32750 (epoch 3.424), train_loss = 1.81009842, grad/param norm = 1.8764e-01, time/batch = 0.6381s	
2244/32750 (epoch 3.426), train_loss = 1.85260042, grad/param norm = 2.0902e-01, time/batch = 0.6356s	
2245/32750 (epoch 3.427), train_loss = 1.83742998, grad/param norm = 2.3132e-01, time/batch = 0.6638s	
2246/32750 (epoch 3.429), train_loss = 1.83561324, grad/param norm = 1.7515e-01, time/batch = 0.6634s	
2247/32750 (epoch 3.431), train_loss = 1.95774257, grad/param norm = 1.8599e-01, time/batch = 0.6358s	
2248/32750 (epoch 3.432), train_loss = 1.92176583, grad/param norm = 2.0116e-01, time/batch = 0.6368s	
2249/32750 (epoch 3.434), train_loss = 1.93052149, grad/param norm = 1.9199e-01, time/batch = 0.6338s	
2250/32750 (epoch 3.435), train_loss = 1.79407545, grad/param norm = 1.7900e-01, time/batch = 0.6336s	
2251/32750 (epoch 3.437), train_loss = 1.91797910, grad/param norm = 1.8075e-01, time/batch = 0.6372s	
2252/32750 (epoch 3.438), train_loss = 2.19304331, grad/param norm = 2.0931e-01, time/batch = 0.6484s	
2253/32750 (epoch 3.440), train_loss = 1.92334877, grad/param norm = 2.1788e-01, time/batch = 0.6361s	
2254/32750 (epoch 3.441), train_loss = 2.04655041, grad/param norm = 2.0624e-01, time/batch = 0.6391s	
2255/32750 (epoch 3.443), train_loss = 1.68093338, grad/param norm = 1.7614e-01, time/batch = 0.6341s	
2256/32750 (epoch 3.444), train_loss = 1.85989035, grad/param norm = 2.0048e-01, time/batch = 0.6341s	
2257/32750 (epoch 3.446), train_loss = 1.82484152, grad/param norm = 1.7547e-01, time/batch = 0.6339s	
2258/32750 (epoch 3.447), train_loss = 2.13585609, grad/param norm = 2.0482e-01, time/batch = 0.6459s	
2259/32750 (epoch 3.449), train_loss = 1.91495152, grad/param norm = 1.9798e-01, time/batch = 0.6325s	
2260/32750 (epoch 3.450), train_loss = 2.01555025, grad/param norm = 2.0795e-01, time/batch = 0.6320s	
2261/32750 (epoch 3.452), train_loss = 2.08607963, grad/param norm = 1.9905e-01, time/batch = 0.6333s	
2262/32750 (epoch 3.453), train_loss = 1.80084473, grad/param norm = 1.7708e-01, time/batch = 0.6390s	
2263/32750 (epoch 3.455), train_loss = 1.85800471, grad/param norm = 1.8798e-01, time/batch = 0.6500s	
2264/32750 (epoch 3.456), train_loss = 2.00239269, grad/param norm = 1.8495e-01, time/batch = 0.6354s	
2265/32750 (epoch 3.458), train_loss = 2.09749604, grad/param norm = 2.0455e-01, time/batch = 0.6346s	
2266/32750 (epoch 3.460), train_loss = 1.98888350, grad/param norm = 1.9540e-01, time/batch = 0.6352s	
2267/32750 (epoch 3.461), train_loss = 2.00947797, grad/param norm = 2.0628e-01, time/batch = 0.6367s	
2268/32750 (epoch 3.463), train_loss = 1.83110999, grad/param norm = 2.1261e-01, time/batch = 0.6396s	
2269/32750 (epoch 3.464), train_loss = 2.04353056, grad/param norm = 1.7856e-01, time/batch = 0.6408s	
2270/32750 (epoch 3.466), train_loss = 2.01949918, grad/param norm = 1.9345e-01, time/batch = 0.6357s	
2271/32750 (epoch 3.467), train_loss = 2.33851766, grad/param norm = 2.1688e-01, time/batch = 0.6358s	
2272/32750 (epoch 3.469), train_loss = 1.91894362, grad/param norm = 2.0393e-01, time/batch = 0.6347s	
2273/32750 (epoch 3.470), train_loss = 2.03825256, grad/param norm = 2.1140e-01, time/batch = 0.6354s	
2274/32750 (epoch 3.472), train_loss = 1.96939292, grad/param norm = 1.8869e-01, time/batch = 0.6419s	
2275/32750 (epoch 3.473), train_loss = 1.93141100, grad/param norm = 1.8409e-01, time/batch = 0.6453s	
2276/32750 (epoch 3.475), train_loss = 1.97817241, grad/param norm = 1.9591e-01, time/batch = 0.6599s	
2277/32750 (epoch 3.476), train_loss = 1.90514621, grad/param norm = 1.7744e-01, time/batch = 0.6685s	
2278/32750 (epoch 3.478), train_loss = 2.11977646, grad/param norm = 2.1528e-01, time/batch = 0.6330s	
2279/32750 (epoch 3.479), train_loss = 2.07118328, grad/param norm = 2.0308e-01, time/batch = 0.6338s	
2280/32750 (epoch 3.481), train_loss = 2.29943439, grad/param norm = 2.1333e-01, time/batch = 0.6325s	
2281/32750 (epoch 3.482), train_loss = 2.11643648, grad/param norm = 2.2411e-01, time/batch = 0.6338s	
2282/32750 (epoch 3.484), train_loss = 1.83839958, grad/param norm = 2.1890e-01, time/batch = 0.6391s	
2283/32750 (epoch 3.485), train_loss = 1.99872503, grad/param norm = 2.1382e-01, time/batch = 0.6384s	
2284/32750 (epoch 3.487), train_loss = 1.98638287, grad/param norm = 2.1827e-01, time/batch = 0.6330s	
2285/32750 (epoch 3.489), train_loss = 1.88645396, grad/param norm = 1.7082e-01, time/batch = 0.6343s	
2286/32750 (epoch 3.490), train_loss = 2.00270627, grad/param norm = 1.9386e-01, time/batch = 0.6320s	
2287/32750 (epoch 3.492), train_loss = 1.97069704, grad/param norm = 1.9104e-01, time/batch = 0.6317s	
2288/32750 (epoch 3.493), train_loss = 2.10555732, grad/param norm = 2.0574e-01, time/batch = 0.6334s	
2289/32750 (epoch 3.495), train_loss = 2.15138723, grad/param norm = 2.1226e-01, time/batch = 0.6336s	
2290/32750 (epoch 3.496), train_loss = 1.86289020, grad/param norm = 1.9937e-01, time/batch = 0.6346s	
2291/32750 (epoch 3.498), train_loss = 1.91443336, grad/param norm = 1.8713e-01, time/batch = 0.6481s	
2292/32750 (epoch 3.499), train_loss = 2.00118642, grad/param norm = 1.8121e-01, time/batch = 0.6525s	
2293/32750 (epoch 3.501), train_loss = 2.11818618, grad/param norm = 2.0533e-01, time/batch = 0.6381s	
2294/32750 (epoch 3.502), train_loss = 2.02135032, grad/param norm = 1.9096e-01, time/batch = 0.6440s	
2295/32750 (epoch 3.504), train_loss = 1.99579398, grad/param norm = 2.0319e-01, time/batch = 0.6337s	
2296/32750 (epoch 3.505), train_loss = 1.97667195, grad/param norm = 1.9977e-01, time/batch = 0.6346s	
2297/32750 (epoch 3.507), train_loss = 1.94091501, grad/param norm = 2.0039e-01, time/batch = 0.6398s	
2298/32750 (epoch 3.508), train_loss = 1.98897902, grad/param norm = 1.9281e-01, time/batch = 0.6459s	
2299/32750 (epoch 3.510), train_loss = 1.95539401, grad/param norm = 2.0435e-01, time/batch = 0.6630s	
2300/32750 (epoch 3.511), train_loss = 1.90516735, grad/param norm = 1.8899e-01, time/batch = 0.6554s	
2301/32750 (epoch 3.513), train_loss = 1.79807123, grad/param norm = 1.9776e-01, time/batch = 0.6414s	
2302/32750 (epoch 3.515), train_loss = 1.85986595, grad/param norm = 2.0954e-01, time/batch = 0.6355s	
2303/32750 (epoch 3.516), train_loss = 1.92102331, grad/param norm = 1.9581e-01, time/batch = 0.6316s	
2304/32750 (epoch 3.518), train_loss = 2.03980736, grad/param norm = 2.1271e-01, time/batch = 0.6355s	
2305/32750 (epoch 3.519), train_loss = 2.05976195, grad/param norm = 2.0934e-01, time/batch = 0.6315s	
2306/32750 (epoch 3.521), train_loss = 1.95602593, grad/param norm = 1.8307e-01, time/batch = 0.6341s	
2307/32750 (epoch 3.522), train_loss = 1.95641896, grad/param norm = 2.0079e-01, time/batch = 0.6541s	
2308/32750 (epoch 3.524), train_loss = 1.76920328, grad/param norm = 1.8191e-01, time/batch = 0.6725s	
2309/32750 (epoch 3.525), train_loss = 1.78385709, grad/param norm = 1.8467e-01, time/batch = 0.6311s	
2310/32750 (epoch 3.527), train_loss = 1.93376967, grad/param norm = 2.1944e-01, time/batch = 0.6337s	
2311/32750 (epoch 3.528), train_loss = 1.82601142, grad/param norm = 1.9194e-01, time/batch = 0.6487s	
2312/32750 (epoch 3.530), train_loss = 2.00382698, grad/param norm = 1.9639e-01, time/batch = 0.6448s	
2313/32750 (epoch 3.531), train_loss = 1.87225520, grad/param norm = 1.7757e-01, time/batch = 0.6415s	
2314/32750 (epoch 3.533), train_loss = 2.04288598, grad/param norm = 2.0593e-01, time/batch = 0.6618s	
2315/32750 (epoch 3.534), train_loss = 1.96213209, grad/param norm = 2.0409e-01, time/batch = 0.6517s	
2316/32750 (epoch 3.536), train_loss = 1.71954796, grad/param norm = 1.8675e-01, time/batch = 0.6420s	
2317/32750 (epoch 3.537), train_loss = 1.84520029, grad/param norm = 1.8360e-01, time/batch = 0.6447s	
2318/32750 (epoch 3.539), train_loss = 2.04574554, grad/param norm = 2.0878e-01, time/batch = 0.6480s	
2319/32750 (epoch 3.540), train_loss = 1.93530756, grad/param norm = 1.9915e-01, time/batch = 0.6411s	
2320/32750 (epoch 3.542), train_loss = 1.85313894, grad/param norm = 1.9486e-01, time/batch = 0.6523s	
2321/32750 (epoch 3.544), train_loss = 1.83618596, grad/param norm = 2.0580e-01, time/batch = 0.6545s	
2322/32750 (epoch 3.545), train_loss = 1.91034352, grad/param norm = 1.8566e-01, time/batch = 0.6570s	
2323/32750 (epoch 3.547), train_loss = 1.86515164, grad/param norm = 1.8940e-01, time/batch = 0.6750s	
2324/32750 (epoch 3.548), train_loss = 1.97155014, grad/param norm = 1.9143e-01, time/batch = 0.6547s	
2325/32750 (epoch 3.550), train_loss = 1.91963815, grad/param norm = 1.9021e-01, time/batch = 0.6445s	
2326/32750 (epoch 3.551), train_loss = 1.94235889, grad/param norm = 2.0061e-01, time/batch = 0.6453s	
2327/32750 (epoch 3.553), train_loss = 1.87942013, grad/param norm = 2.0142e-01, time/batch = 0.6450s	
2328/32750 (epoch 3.554), train_loss = 1.89105359, grad/param norm = 1.8200e-01, time/batch = 0.6450s	
2329/32750 (epoch 3.556), train_loss = 2.11090582, grad/param norm = 2.0262e-01, time/batch = 0.6509s	
2330/32750 (epoch 3.557), train_loss = 1.83287616, grad/param norm = 1.7957e-01, time/batch = 0.6429s	
2331/32750 (epoch 3.559), train_loss = 1.91919549, grad/param norm = 1.8737e-01, time/batch = 0.6332s	
2332/32750 (epoch 3.560), train_loss = 1.79359001, grad/param norm = 2.0406e-01, time/batch = 0.6330s	
2333/32750 (epoch 3.562), train_loss = 1.94494977, grad/param norm = 1.8813e-01, time/batch = 0.6484s	
2334/32750 (epoch 3.563), train_loss = 2.00199897, grad/param norm = 2.0196e-01, time/batch = 0.6738s	
2335/32750 (epoch 3.565), train_loss = 1.91176779, grad/param norm = 1.9200e-01, time/batch = 0.6385s	
2336/32750 (epoch 3.566), train_loss = 1.83403143, grad/param norm = 1.8319e-01, time/batch = 0.6324s	
2337/32750 (epoch 3.568), train_loss = 2.03881764, grad/param norm = 2.0281e-01, time/batch = 0.6342s	
2338/32750 (epoch 3.569), train_loss = 2.02082213, grad/param norm = 1.9312e-01, time/batch = 0.6321s	
2339/32750 (epoch 3.571), train_loss = 1.82362560, grad/param norm = 1.8771e-01, time/batch = 0.6344s	
2340/32750 (epoch 3.573), train_loss = 1.97909047, grad/param norm = 1.9340e-01, time/batch = 0.6309s	
2341/32750 (epoch 3.574), train_loss = 1.96019075, grad/param norm = 1.8580e-01, time/batch = 0.6336s	
2342/32750 (epoch 3.576), train_loss = 1.88955777, grad/param norm = 1.8984e-01, time/batch = 0.6325s	
2343/32750 (epoch 3.577), train_loss = 1.94015996, grad/param norm = 1.7401e-01, time/batch = 0.6327s	
2344/32750 (epoch 3.579), train_loss = 1.80110461, grad/param norm = 1.7010e-01, time/batch = 0.6376s	
2345/32750 (epoch 3.580), train_loss = 1.95111621, grad/param norm = 1.9950e-01, time/batch = 0.6334s	
2346/32750 (epoch 3.582), train_loss = 1.87742689, grad/param norm = 1.8703e-01, time/batch = 0.6322s	
2347/32750 (epoch 3.583), train_loss = 1.93949391, grad/param norm = 2.1610e-01, time/batch = 0.6340s	
2348/32750 (epoch 3.585), train_loss = 1.84768512, grad/param norm = 2.0716e-01, time/batch = 0.6342s	
2349/32750 (epoch 3.586), train_loss = 2.00615763, grad/param norm = 2.1709e-01, time/batch = 0.6637s	
2350/32750 (epoch 3.588), train_loss = 1.92908155, grad/param norm = 2.2621e-01, time/batch = 0.6629s	
2351/32750 (epoch 3.589), train_loss = 1.91624849, grad/param norm = 1.8522e-01, time/batch = 0.6358s	
2352/32750 (epoch 3.591), train_loss = 1.86817609, grad/param norm = 1.7707e-01, time/batch = 0.6337s	
2353/32750 (epoch 3.592), train_loss = 1.86839593, grad/param norm = 1.8449e-01, time/batch = 0.6369s	
2354/32750 (epoch 3.594), train_loss = 1.84626813, grad/param norm = 1.8661e-01, time/batch = 0.6634s	
2355/32750 (epoch 3.595), train_loss = 1.74740955, grad/param norm = 1.8110e-01, time/batch = 0.6544s	
2356/32750 (epoch 3.597), train_loss = 1.95813341, grad/param norm = 1.9253e-01, time/batch = 0.6339s	
2357/32750 (epoch 3.598), train_loss = 1.73999487, grad/param norm = 1.8022e-01, time/batch = 0.6343s	
2358/32750 (epoch 3.600), train_loss = 2.00978173, grad/param norm = 2.0897e-01, time/batch = 0.6340s	
2359/32750 (epoch 3.602), train_loss = 2.22617270, grad/param norm = 2.2729e-01, time/batch = 0.6336s	
2360/32750 (epoch 3.603), train_loss = 2.12197273, grad/param norm = 2.1194e-01, time/batch = 0.6360s	
2361/32750 (epoch 3.605), train_loss = 1.95110639, grad/param norm = 1.9706e-01, time/batch = 0.6349s	
2362/32750 (epoch 3.606), train_loss = 1.94927806, grad/param norm = 1.6842e-01, time/batch = 0.6348s	
2363/32750 (epoch 3.608), train_loss = 1.84035431, grad/param norm = 1.9757e-01, time/batch = 0.6459s	
2364/32750 (epoch 3.609), train_loss = 1.79428229, grad/param norm = 1.7507e-01, time/batch = 0.6579s	
2365/32750 (epoch 3.611), train_loss = 1.94893386, grad/param norm = 1.8394e-01, time/batch = 0.6733s	
2366/32750 (epoch 3.612), train_loss = 1.86005984, grad/param norm = 1.8310e-01, time/batch = 0.6566s	
2367/32750 (epoch 3.614), train_loss = 1.86149223, grad/param norm = 1.8624e-01, time/batch = 0.6625s	
2368/32750 (epoch 3.615), train_loss = 2.01774272, grad/param norm = 1.8905e-01, time/batch = 0.6350s	
2369/32750 (epoch 3.617), train_loss = 1.82893344, grad/param norm = 1.9313e-01, time/batch = 0.6366s	
2370/32750 (epoch 3.618), train_loss = 1.93277493, grad/param norm = 1.9301e-01, time/batch = 0.6395s	
2371/32750 (epoch 3.620), train_loss = 1.83575493, grad/param norm = 1.8275e-01, time/batch = 0.6375s	
2372/32750 (epoch 3.621), train_loss = 1.91662191, grad/param norm = 1.9925e-01, time/batch = 0.6357s	
2373/32750 (epoch 3.623), train_loss = 1.81237994, grad/param norm = 1.8412e-01, time/batch = 0.6381s	
2374/32750 (epoch 3.624), train_loss = 2.08444503, grad/param norm = 2.0933e-01, time/batch = 0.6368s	
2375/32750 (epoch 3.626), train_loss = 2.00670066, grad/param norm = 1.8849e-01, time/batch = 0.6391s	
2376/32750 (epoch 3.627), train_loss = 1.89764806, grad/param norm = 1.9253e-01, time/batch = 0.6351s	
2377/32750 (epoch 3.629), train_loss = 1.86095417, grad/param norm = 1.9867e-01, time/batch = 0.6359s	
2378/32750 (epoch 3.631), train_loss = 1.82734103, grad/param norm = 1.8656e-01, time/batch = 0.6455s	
2379/32750 (epoch 3.632), train_loss = 1.98599263, grad/param norm = 1.8453e-01, time/batch = 0.6416s	
2380/32750 (epoch 3.634), train_loss = 2.09787490, grad/param norm = 1.9027e-01, time/batch = 0.6663s	
2381/32750 (epoch 3.635), train_loss = 1.85992120, grad/param norm = 1.8052e-01, time/batch = 0.6611s	
2382/32750 (epoch 3.637), train_loss = 2.03557860, grad/param norm = 2.0026e-01, time/batch = 0.6358s	
2383/32750 (epoch 3.638), train_loss = 1.91050441, grad/param norm = 1.9408e-01, time/batch = 0.6340s	
2384/32750 (epoch 3.640), train_loss = 1.84706913, grad/param norm = 2.0147e-01, time/batch = 0.6350s	
2385/32750 (epoch 3.641), train_loss = 1.85558493, grad/param norm = 1.8575e-01, time/batch = 0.6328s	
2386/32750 (epoch 3.643), train_loss = 1.76876730, grad/param norm = 1.8090e-01, time/batch = 0.6343s	
2387/32750 (epoch 3.644), train_loss = 1.81563067, grad/param norm = 1.9034e-01, time/batch = 0.6322s	
2388/32750 (epoch 3.646), train_loss = 1.72842665, grad/param norm = 2.0165e-01, time/batch = 0.6335s	
2389/32750 (epoch 3.647), train_loss = 1.88817090, grad/param norm = 2.0535e-01, time/batch = 0.6334s	
2390/32750 (epoch 3.649), train_loss = 2.00392513, grad/param norm = 2.2583e-01, time/batch = 0.6422s	
2391/32750 (epoch 3.650), train_loss = 2.07354836, grad/param norm = 1.9114e-01, time/batch = 0.6582s	
2392/32750 (epoch 3.652), train_loss = 1.83453328, grad/param norm = 2.0274e-01, time/batch = 0.6439s	
2393/32750 (epoch 3.653), train_loss = 1.80216607, grad/param norm = 1.7671e-01, time/batch = 0.6369s	
2394/32750 (epoch 3.655), train_loss = 2.19101169, grad/param norm = 2.1062e-01, time/batch = 0.6403s	
2395/32750 (epoch 3.656), train_loss = 1.97012587, grad/param norm = 2.0621e-01, time/batch = 0.6464s	
2396/32750 (epoch 3.658), train_loss = 1.96697017, grad/param norm = 1.9639e-01, time/batch = 0.6733s	
2397/32750 (epoch 3.660), train_loss = 1.90462912, grad/param norm = 1.9697e-01, time/batch = 0.6476s	
2398/32750 (epoch 3.661), train_loss = 1.98814417, grad/param norm = 2.1396e-01, time/batch = 0.6346s	
2399/32750 (epoch 3.663), train_loss = 2.01166080, grad/param norm = 1.8044e-01, time/batch = 0.6342s	
2400/32750 (epoch 3.664), train_loss = 2.01631815, grad/param norm = 1.9626e-01, time/batch = 0.6358s	
2401/32750 (epoch 3.666), train_loss = 1.96393356, grad/param norm = 1.9098e-01, time/batch = 0.6360s	
2402/32750 (epoch 3.667), train_loss = 1.97152398, grad/param norm = 1.7843e-01, time/batch = 0.6349s	
2403/32750 (epoch 3.669), train_loss = 1.98775767, grad/param norm = 2.0832e-01, time/batch = 0.6369s	
2404/32750 (epoch 3.670), train_loss = 1.88164397, grad/param norm = 2.0714e-01, time/batch = 0.6414s	
2405/32750 (epoch 3.672), train_loss = 1.78729739, grad/param norm = 1.8635e-01, time/batch = 0.6492s	
2406/32750 (epoch 3.673), train_loss = 1.90217676, grad/param norm = 1.9040e-01, time/batch = 0.6398s	
2407/32750 (epoch 3.675), train_loss = 1.97908925, grad/param norm = 1.8619e-01, time/batch = 0.6348s	
2408/32750 (epoch 3.676), train_loss = 1.92000785, grad/param norm = 1.8875e-01, time/batch = 0.6327s	
2409/32750 (epoch 3.678), train_loss = 1.92951278, grad/param norm = 1.7898e-01, time/batch = 0.6336s	
2410/32750 (epoch 3.679), train_loss = 1.88066026, grad/param norm = 1.9734e-01, time/batch = 0.6312s	
2411/32750 (epoch 3.681), train_loss = 1.83359743, grad/param norm = 1.8736e-01, time/batch = 0.6699s	
2412/32750 (epoch 3.682), train_loss = 1.90379949, grad/param norm = 1.8275e-01, time/batch = 0.6697s	
2413/32750 (epoch 3.684), train_loss = 1.88730727, grad/param norm = 1.8283e-01, time/batch = 0.6368s	
2414/32750 (epoch 3.685), train_loss = 1.92253413, grad/param norm = 1.7784e-01, time/batch = 0.6311s	
2415/32750 (epoch 3.687), train_loss = 1.87770981, grad/param norm = 1.9068e-01, time/batch = 0.6309s	
2416/32750 (epoch 3.689), train_loss = 1.92799109, grad/param norm = 1.8537e-01, time/batch = 0.6315s	
2417/32750 (epoch 3.690), train_loss = 1.75875180, grad/param norm = 1.8197e-01, time/batch = 0.6320s	
2418/32750 (epoch 3.692), train_loss = 2.01761554, grad/param norm = 1.9776e-01, time/batch = 0.6316s	
2419/32750 (epoch 3.693), train_loss = 1.87619975, grad/param norm = 1.9548e-01, time/batch = 0.6317s	
2420/32750 (epoch 3.695), train_loss = 1.76114061, grad/param norm = 2.2641e-01, time/batch = 0.6403s	
2421/32750 (epoch 3.696), train_loss = 1.85256601, grad/param norm = 1.9988e-01, time/batch = 0.6329s	
2422/32750 (epoch 3.698), train_loss = 1.95533516, grad/param norm = 2.1025e-01, time/batch = 0.6405s	
2423/32750 (epoch 3.699), train_loss = 1.91576250, grad/param norm = 2.0638e-01, time/batch = 0.6333s	
2424/32750 (epoch 3.701), train_loss = 1.79432433, grad/param norm = 1.5911e-01, time/batch = 0.6339s	
2425/32750 (epoch 3.702), train_loss = 1.89526136, grad/param norm = 1.7156e-01, time/batch = 0.6334s	
2426/32750 (epoch 3.704), train_loss = 1.97699313, grad/param norm = 1.8134e-01, time/batch = 0.6325s	
2427/32750 (epoch 3.705), train_loss = 2.12954197, grad/param norm = 2.1186e-01, time/batch = 0.6389s	
2428/32750 (epoch 3.707), train_loss = 2.02911988, grad/param norm = 2.1850e-01, time/batch = 0.6362s	
2429/32750 (epoch 3.708), train_loss = 1.91152254, grad/param norm = 2.4114e-01, time/batch = 0.6326s	
2430/32750 (epoch 3.710), train_loss = 1.88219927, grad/param norm = 1.9042e-01, time/batch = 0.6318s	
2431/32750 (epoch 3.711), train_loss = 1.99658524, grad/param norm = 1.8768e-01, time/batch = 0.6318s	
2432/32750 (epoch 3.713), train_loss = 1.96314227, grad/param norm = 1.9262e-01, time/batch = 0.6313s	
2433/32750 (epoch 3.715), train_loss = 1.85359776, grad/param norm = 1.7322e-01, time/batch = 0.6337s	
2434/32750 (epoch 3.716), train_loss = 1.96707365, grad/param norm = 1.9663e-01, time/batch = 0.6318s	
2435/32750 (epoch 3.718), train_loss = 1.83725620, grad/param norm = 1.8945e-01, time/batch = 0.6314s	
2436/32750 (epoch 3.719), train_loss = 1.92127117, grad/param norm = 1.7938e-01, time/batch = 0.6334s	
2437/32750 (epoch 3.721), train_loss = 1.91967929, grad/param norm = 1.8714e-01, time/batch = 0.6321s	
2438/32750 (epoch 3.722), train_loss = 1.97727550, grad/param norm = 1.9336e-01, time/batch = 0.6382s	
2439/32750 (epoch 3.724), train_loss = 2.00142115, grad/param norm = 1.9193e-01, time/batch = 0.6353s	
2440/32750 (epoch 3.725), train_loss = 1.82068771, grad/param norm = 1.8927e-01, time/batch = 0.6524s	
2441/32750 (epoch 3.727), train_loss = 1.87915865, grad/param norm = 1.9629e-01, time/batch = 0.6489s	
2442/32750 (epoch 3.728), train_loss = 1.88443976, grad/param norm = 1.9677e-01, time/batch = 0.6500s	
2443/32750 (epoch 3.730), train_loss = 1.83831197, grad/param norm = 1.9737e-01, time/batch = 0.6470s	
2444/32750 (epoch 3.731), train_loss = 1.99042028, grad/param norm = 1.8489e-01, time/batch = 0.6489s	
2445/32750 (epoch 3.733), train_loss = 1.98897256, grad/param norm = 1.9622e-01, time/batch = 0.6355s	
2446/32750 (epoch 3.734), train_loss = 1.77865261, grad/param norm = 2.1171e-01, time/batch = 0.6690s	
2447/32750 (epoch 3.736), train_loss = 1.86735601, grad/param norm = 1.8051e-01, time/batch = 0.6541s	
2448/32750 (epoch 3.737), train_loss = 1.77938185, grad/param norm = 1.8125e-01, time/batch = 0.6496s	
2449/32750 (epoch 3.739), train_loss = 1.92206860, grad/param norm = 2.1946e-01, time/batch = 0.6491s	
2450/32750 (epoch 3.740), train_loss = 1.95356058, grad/param norm = 2.1679e-01, time/batch = 0.6503s	
2451/32750 (epoch 3.742), train_loss = 1.89947261, grad/param norm = 2.0008e-01, time/batch = 0.6346s	
2452/32750 (epoch 3.744), train_loss = 1.80770151, grad/param norm = 1.8058e-01, time/batch = 0.6365s	
2453/32750 (epoch 3.745), train_loss = 1.98827171, grad/param norm = 2.0281e-01, time/batch = 0.6664s	
2454/32750 (epoch 3.747), train_loss = 1.89841131, grad/param norm = 1.9139e-01, time/batch = 0.6610s	
2455/32750 (epoch 3.748), train_loss = 1.86634074, grad/param norm = 1.7421e-01, time/batch = 0.6316s	
2456/32750 (epoch 3.750), train_loss = 1.93741823, grad/param norm = 1.9177e-01, time/batch = 0.6321s	
2457/32750 (epoch 3.751), train_loss = 2.00866988, grad/param norm = 2.1430e-01, time/batch = 0.6315s	
2458/32750 (epoch 3.753), train_loss = 1.86383082, grad/param norm = 1.9400e-01, time/batch = 0.6316s	
2459/32750 (epoch 3.754), train_loss = 1.94986168, grad/param norm = 1.8016e-01, time/batch = 0.6340s	
2460/32750 (epoch 3.756), train_loss = 2.03284960, grad/param norm = 1.9069e-01, time/batch = 0.6322s	
2461/32750 (epoch 3.757), train_loss = 1.81993311, grad/param norm = 1.7731e-01, time/batch = 0.6341s	
2462/32750 (epoch 3.759), train_loss = 1.97617535, grad/param norm = 1.9715e-01, time/batch = 0.6335s	
2463/32750 (epoch 3.760), train_loss = 1.96531400, grad/param norm = 1.9066e-01, time/batch = 0.6338s	
2464/32750 (epoch 3.762), train_loss = 1.99969865, grad/param norm = 1.9852e-01, time/batch = 0.6316s	
2465/32750 (epoch 3.763), train_loss = 1.85662507, grad/param norm = 1.7997e-01, time/batch = 0.6325s	
2466/32750 (epoch 3.765), train_loss = 1.87977638, grad/param norm = 2.0022e-01, time/batch = 0.6317s	
2467/32750 (epoch 3.766), train_loss = 1.92834840, grad/param norm = 2.0147e-01, time/batch = 0.6316s	
2468/32750 (epoch 3.768), train_loss = 1.81713610, grad/param norm = 1.8753e-01, time/batch = 0.6382s	
2469/32750 (epoch 3.769), train_loss = 1.84163856, grad/param norm = 1.8168e-01, time/batch = 0.6734s	
2470/32750 (epoch 3.771), train_loss = 1.91840992, grad/param norm = 2.1217e-01, time/batch = 0.6502s	
2471/32750 (epoch 3.773), train_loss = 1.78504322, grad/param norm = 2.1230e-01, time/batch = 0.6341s	
2472/32750 (epoch 3.774), train_loss = 1.86127498, grad/param norm = 2.0536e-01, time/batch = 0.6323s	
2473/32750 (epoch 3.776), train_loss = 1.72248419, grad/param norm = 1.8813e-01, time/batch = 0.6333s	
2474/32750 (epoch 3.777), train_loss = 1.88112006, grad/param norm = 1.9110e-01, time/batch = 0.6344s	
2475/32750 (epoch 3.779), train_loss = 1.78485127, grad/param norm = 1.7334e-01, time/batch = 0.6352s	
2476/32750 (epoch 3.780), train_loss = 2.03187074, grad/param norm = 2.2903e-01, time/batch = 0.6339s	
2477/32750 (epoch 3.782), train_loss = 2.01232083, grad/param norm = 2.1119e-01, time/batch = 0.6365s	
2478/32750 (epoch 3.783), train_loss = 1.96405607, grad/param norm = 2.1408e-01, time/batch = 0.6341s	
2479/32750 (epoch 3.785), train_loss = 1.82425911, grad/param norm = 1.6760e-01, time/batch = 0.6351s	
2480/32750 (epoch 3.786), train_loss = 2.01192813, grad/param norm = 1.7093e-01, time/batch = 0.6337s	
2481/32750 (epoch 3.788), train_loss = 2.01107708, grad/param norm = 1.8275e-01, time/batch = 0.6376s	
2482/32750 (epoch 3.789), train_loss = 1.95796701, grad/param norm = 1.8394e-01, time/batch = 0.6401s	
2483/32750 (epoch 3.791), train_loss = 2.02127086, grad/param norm = 1.9317e-01, time/batch = 0.6360s	
2484/32750 (epoch 3.792), train_loss = 1.93655934, grad/param norm = 1.8559e-01, time/batch = 0.6651s	
2485/32750 (epoch 3.794), train_loss = 1.89071261, grad/param norm = 1.9828e-01, time/batch = 0.6712s	
2486/32750 (epoch 3.795), train_loss = 1.99989334, grad/param norm = 2.0858e-01, time/batch = 0.6393s	
2487/32750 (epoch 3.797), train_loss = 1.77102170, grad/param norm = 1.9343e-01, time/batch = 0.6444s	
2488/32750 (epoch 3.798), train_loss = 1.89723235, grad/param norm = 1.9431e-01, time/batch = 0.6389s	
2489/32750 (epoch 3.800), train_loss = 1.79487860, grad/param norm = 1.8854e-01, time/batch = 0.6345s	
2490/32750 (epoch 3.802), train_loss = 1.94332412, grad/param norm = 1.7905e-01, time/batch = 0.6341s	
2491/32750 (epoch 3.803), train_loss = 2.07758688, grad/param norm = 1.8718e-01, time/batch = 0.6333s	
2492/32750 (epoch 3.805), train_loss = 2.00819357, grad/param norm = 2.4621e-01, time/batch = 0.6340s	
2493/32750 (epoch 3.806), train_loss = 1.90637777, grad/param norm = 1.8921e-01, time/batch = 0.6393s	
2494/32750 (epoch 3.808), train_loss = 2.06361512, grad/param norm = 1.9772e-01, time/batch = 0.6335s	
2495/32750 (epoch 3.809), train_loss = 1.89598515, grad/param norm = 1.8635e-01, time/batch = 0.6349s	
2496/32750 (epoch 3.811), train_loss = 2.08738579, grad/param norm = 2.0002e-01, time/batch = 0.6481s	
2497/32750 (epoch 3.812), train_loss = 1.80941905, grad/param norm = 1.7359e-01, time/batch = 0.6365s	
2498/32750 (epoch 3.814), train_loss = 1.93963928, grad/param norm = 1.8838e-01, time/batch = 0.6340s	
2499/32750 (epoch 3.815), train_loss = 2.06753690, grad/param norm = 2.0384e-01, time/batch = 0.6343s	
2500/32750 (epoch 3.817), train_loss = 2.00787278, grad/param norm = 2.0471e-01, time/batch = 0.6753s	
2501/32750 (epoch 3.818), train_loss = 1.83121875, grad/param norm = 1.9214e-01, time/batch = 0.6517s	
2502/32750 (epoch 3.820), train_loss = 1.80687205, grad/param norm = 1.8659e-01, time/batch = 0.6354s	
2503/32750 (epoch 3.821), train_loss = 1.95060013, grad/param norm = 1.8702e-01, time/batch = 0.6328s	
2504/32750 (epoch 3.823), train_loss = 1.89682322, grad/param norm = 1.9347e-01, time/batch = 0.6349s	
2505/32750 (epoch 3.824), train_loss = 1.96976915, grad/param norm = 2.1337e-01, time/batch = 0.6348s	
2506/32750 (epoch 3.826), train_loss = 2.08761506, grad/param norm = 1.8420e-01, time/batch = 0.6358s	
2507/32750 (epoch 3.827), train_loss = 1.92247687, grad/param norm = 1.9368e-01, time/batch = 0.6421s	
2508/32750 (epoch 3.829), train_loss = 2.06620113, grad/param norm = 1.8927e-01, time/batch = 0.6602s	
2509/32750 (epoch 3.831), train_loss = 1.66117338, grad/param norm = 1.9658e-01, time/batch = 0.6671s	
2510/32750 (epoch 3.832), train_loss = 1.88151739, grad/param norm = 2.1437e-01, time/batch = 0.6712s	
2511/32750 (epoch 3.834), train_loss = 1.84007003, grad/param norm = 1.8324e-01, time/batch = 0.6692s	
2512/32750 (epoch 3.835), train_loss = 1.75505419, grad/param norm = 1.8564e-01, time/batch = 0.6637s	
2513/32750 (epoch 3.837), train_loss = 2.04372624, grad/param norm = 1.9242e-01, time/batch = 0.6631s	
2514/32750 (epoch 3.838), train_loss = 1.86625218, grad/param norm = 1.8428e-01, time/batch = 0.6400s	
2515/32750 (epoch 3.840), train_loss = 1.76303775, grad/param norm = 1.9425e-01, time/batch = 0.6379s	
2516/32750 (epoch 3.841), train_loss = 1.98372211, grad/param norm = 1.8998e-01, time/batch = 0.6387s	
2517/32750 (epoch 3.843), train_loss = 2.10226938, grad/param norm = 1.8906e-01, time/batch = 0.6331s	
2518/32750 (epoch 3.844), train_loss = 2.00626456, grad/param norm = 1.8305e-01, time/batch = 0.6335s	
2519/32750 (epoch 3.846), train_loss = 1.87970333, grad/param norm = 1.6907e-01, time/batch = 0.6351s	
2520/32750 (epoch 3.847), train_loss = 1.77220422, grad/param norm = 1.8431e-01, time/batch = 0.6452s	
2521/32750 (epoch 3.849), train_loss = 1.94344509, grad/param norm = 2.1513e-01, time/batch = 0.6366s	
2522/32750 (epoch 3.850), train_loss = 2.05938137, grad/param norm = 2.0207e-01, time/batch = 0.6344s	
2523/32750 (epoch 3.852), train_loss = 1.75855078, grad/param norm = 1.8299e-01, time/batch = 0.6339s	
2524/32750 (epoch 3.853), train_loss = 1.84399385, grad/param norm = 1.8526e-01, time/batch = 0.6341s	
2525/32750 (epoch 3.855), train_loss = 1.91123273, grad/param norm = 1.8725e-01, time/batch = 0.6336s	
2526/32750 (epoch 3.856), train_loss = 1.93409683, grad/param norm = 1.9511e-01, time/batch = 0.6334s	
2527/32750 (epoch 3.858), train_loss = 1.83586854, grad/param norm = 1.8858e-01, time/batch = 0.6332s	
2528/32750 (epoch 3.860), train_loss = 1.84187653, grad/param norm = 1.9299e-01, time/batch = 0.6308s	
2529/32750 (epoch 3.861), train_loss = 1.80698791, grad/param norm = 1.9822e-01, time/batch = 0.6331s	
2530/32750 (epoch 3.863), train_loss = 2.01701517, grad/param norm = 2.0014e-01, time/batch = 0.6473s	
2531/32750 (epoch 3.864), train_loss = 1.78250055, grad/param norm = 2.0938e-01, time/batch = 0.6749s	
2532/32750 (epoch 3.866), train_loss = 1.77214487, grad/param norm = 1.8632e-01, time/batch = 0.6484s	
2533/32750 (epoch 3.867), train_loss = 1.71605266, grad/param norm = 1.9523e-01, time/batch = 0.6342s	
2534/32750 (epoch 3.869), train_loss = 1.91129950, grad/param norm = 2.1197e-01, time/batch = 0.6341s	
2535/32750 (epoch 3.870), train_loss = 1.83916017, grad/param norm = 2.0194e-01, time/batch = 0.6415s	
2536/32750 (epoch 3.872), train_loss = 1.95993651, grad/param norm = 1.9815e-01, time/batch = 0.6417s	
2537/32750 (epoch 3.873), train_loss = 1.82166890, grad/param norm = 1.7178e-01, time/batch = 0.6367s	
2538/32750 (epoch 3.875), train_loss = 1.94230252, grad/param norm = 1.9042e-01, time/batch = 0.6340s	
2539/32750 (epoch 3.876), train_loss = 1.99422701, grad/param norm = 2.0859e-01, time/batch = 0.6328s	
2540/32750 (epoch 3.878), train_loss = 1.82103043, grad/param norm = 1.8772e-01, time/batch = 0.6328s	
2541/32750 (epoch 3.879), train_loss = 1.84341122, grad/param norm = 1.9418e-01, time/batch = 0.6358s	
2542/32750 (epoch 3.881), train_loss = 1.91419834, grad/param norm = 2.0079e-01, time/batch = 0.6396s	
2543/32750 (epoch 3.882), train_loss = 1.75021050, grad/param norm = 1.8663e-01, time/batch = 0.6447s	
2544/32750 (epoch 3.884), train_loss = 1.88747787, grad/param norm = 1.9052e-01, time/batch = 0.6381s	
2545/32750 (epoch 3.885), train_loss = 1.90934201, grad/param norm = 1.8589e-01, time/batch = 0.6341s	
2546/32750 (epoch 3.887), train_loss = 1.93002446, grad/param norm = 1.9455e-01, time/batch = 0.6555s	
2547/32750 (epoch 3.889), train_loss = 1.90449092, grad/param norm = 1.7421e-01, time/batch = 0.6706s	
2548/32750 (epoch 3.890), train_loss = 1.82046885, grad/param norm = 1.8275e-01, time/batch = 0.6324s	
2549/32750 (epoch 3.892), train_loss = 2.08467730, grad/param norm = 2.3097e-01, time/batch = 0.6319s	
2550/32750 (epoch 3.893), train_loss = 2.09457588, grad/param norm = 2.1941e-01, time/batch = 0.6310s	
2551/32750 (epoch 3.895), train_loss = 1.77703113, grad/param norm = 1.7207e-01, time/batch = 0.6328s	
2552/32750 (epoch 3.896), train_loss = 1.80963469, grad/param norm = 1.7860e-01, time/batch = 0.6346s	
2553/32750 (epoch 3.898), train_loss = 1.97555807, grad/param norm = 1.9935e-01, time/batch = 0.6326s	
2554/32750 (epoch 3.899), train_loss = 1.93925388, grad/param norm = 2.0649e-01, time/batch = 0.6318s	
2555/32750 (epoch 3.901), train_loss = 1.91756264, grad/param norm = 1.9439e-01, time/batch = 0.6418s	
2556/32750 (epoch 3.902), train_loss = 1.92580330, grad/param norm = 2.0473e-01, time/batch = 0.6434s	
2557/32750 (epoch 3.904), train_loss = 1.76043907, grad/param norm = 1.9315e-01, time/batch = 0.6343s	
2558/32750 (epoch 3.905), train_loss = 1.93539302, grad/param norm = 2.0876e-01, time/batch = 0.6338s	
2559/32750 (epoch 3.907), train_loss = 2.09750839, grad/param norm = 2.0949e-01, time/batch = 0.6306s	
2560/32750 (epoch 3.908), train_loss = 2.04802869, grad/param norm = 1.7531e-01, time/batch = 0.6309s	
2561/32750 (epoch 3.910), train_loss = 1.86519289, grad/param norm = 1.8012e-01, time/batch = 0.6357s	
2562/32750 (epoch 3.911), train_loss = 1.85756948, grad/param norm = 1.7190e-01, time/batch = 0.6733s	
2563/32750 (epoch 3.913), train_loss = 1.78929049, grad/param norm = 1.7795e-01, time/batch = 0.6567s	
2564/32750 (epoch 3.915), train_loss = 1.79680798, grad/param norm = 1.9266e-01, time/batch = 0.6367s	
2565/32750 (epoch 3.916), train_loss = 1.96928109, grad/param norm = 1.8450e-01, time/batch = 0.6374s	
2566/32750 (epoch 3.918), train_loss = 2.05673499, grad/param norm = 2.0803e-01, time/batch = 0.6365s	
2567/32750 (epoch 3.919), train_loss = 2.00914022, grad/param norm = 2.0119e-01, time/batch = 0.6361s	
2568/32750 (epoch 3.921), train_loss = 1.88306381, grad/param norm = 1.9260e-01, time/batch = 0.6372s	
2569/32750 (epoch 3.922), train_loss = 1.83197366, grad/param norm = 1.6648e-01, time/batch = 0.6346s	
2570/32750 (epoch 3.924), train_loss = 1.83934579, grad/param norm = 1.8060e-01, time/batch = 0.6409s	
2571/32750 (epoch 3.925), train_loss = 1.88804219, grad/param norm = 2.0067e-01, time/batch = 0.6377s	
2572/32750 (epoch 3.927), train_loss = 2.04109339, grad/param norm = 2.0359e-01, time/batch = 0.6351s	
2573/32750 (epoch 3.928), train_loss = 2.04260961, grad/param norm = 1.8458e-01, time/batch = 0.6322s	
2574/32750 (epoch 3.930), train_loss = 1.88700962, grad/param norm = 1.8582e-01, time/batch = 0.6352s	
2575/32750 (epoch 3.931), train_loss = 1.90613931, grad/param norm = 1.7573e-01, time/batch = 0.6358s	
2576/32750 (epoch 3.933), train_loss = 1.90568653, grad/param norm = 1.9296e-01, time/batch = 0.6344s	
2577/32750 (epoch 3.934), train_loss = 1.85398696, grad/param norm = 1.9273e-01, time/batch = 0.6641s	
2578/32750 (epoch 3.936), train_loss = 2.00889574, grad/param norm = 2.0419e-01, time/batch = 0.6739s	
2579/32750 (epoch 3.937), train_loss = 1.77375478, grad/param norm = 1.7263e-01, time/batch = 0.6389s	
2580/32750 (epoch 3.939), train_loss = 1.99358305, grad/param norm = 1.8610e-01, time/batch = 0.6474s	
2581/32750 (epoch 3.940), train_loss = 1.91798283, grad/param norm = 1.8718e-01, time/batch = 0.6530s	
2582/32750 (epoch 3.942), train_loss = 1.81460219, grad/param norm = 1.9676e-01, time/batch = 0.6372s	
2583/32750 (epoch 3.944), train_loss = 1.95095949, grad/param norm = 1.8927e-01, time/batch = 0.6340s	
2584/32750 (epoch 3.945), train_loss = 1.83766222, grad/param norm = 1.7741e-01, time/batch = 0.6328s	
2585/32750 (epoch 3.947), train_loss = 1.91571095, grad/param norm = 2.0773e-01, time/batch = 0.6319s	
2586/32750 (epoch 3.948), train_loss = 1.85055293, grad/param norm = 1.8641e-01, time/batch = 0.6328s	
2587/32750 (epoch 3.950), train_loss = 1.90376921, grad/param norm = 1.9373e-01, time/batch = 0.6364s	
2588/32750 (epoch 3.951), train_loss = 1.84852430, grad/param norm = 1.7711e-01, time/batch = 0.6404s	
2589/32750 (epoch 3.953), train_loss = 1.80939542, grad/param norm = 1.8318e-01, time/batch = 0.6477s	
2590/32750 (epoch 3.954), train_loss = 1.88428194, grad/param norm = 1.6905e-01, time/batch = 0.6459s	
2591/32750 (epoch 3.956), train_loss = 1.96203830, grad/param norm = 2.0009e-01, time/batch = 0.6365s	
2592/32750 (epoch 3.957), train_loss = 1.83785364, grad/param norm = 1.7911e-01, time/batch = 0.6365s	
2593/32750 (epoch 3.959), train_loss = 1.85332417, grad/param norm = 1.9352e-01, time/batch = 0.6718s	
2594/32750 (epoch 3.960), train_loss = 1.89928122, grad/param norm = 2.0084e-01, time/batch = 0.6582s	
2595/32750 (epoch 3.962), train_loss = 1.92429217, grad/param norm = 1.9133e-01, time/batch = 0.6343s	
2596/32750 (epoch 3.963), train_loss = 1.87509865, grad/param norm = 2.0698e-01, time/batch = 0.6358s	
2597/32750 (epoch 3.965), train_loss = 2.02806276, grad/param norm = 1.8643e-01, time/batch = 0.6382s	
2598/32750 (epoch 3.966), train_loss = 2.01455253, grad/param norm = 1.8632e-01, time/batch = 0.6351s	
2599/32750 (epoch 3.968), train_loss = 1.81559355, grad/param norm = 1.8985e-01, time/batch = 0.6367s	
2600/32750 (epoch 3.969), train_loss = 1.76905829, grad/param norm = 1.8498e-01, time/batch = 0.6352s	
2601/32750 (epoch 3.971), train_loss = 1.96999958, grad/param norm = 1.8355e-01, time/batch = 0.6377s	
2602/32750 (epoch 3.973), train_loss = 1.97332876, grad/param norm = 1.9530e-01, time/batch = 0.6353s	
2603/32750 (epoch 3.974), train_loss = 1.95167539, grad/param norm = 1.9042e-01, time/batch = 0.6372s	
2604/32750 (epoch 3.976), train_loss = 2.00429694, grad/param norm = 1.9464e-01, time/batch = 0.6349s	
2605/32750 (epoch 3.977), train_loss = 2.13483575, grad/param norm = 1.9815e-01, time/batch = 0.6385s	
2606/32750 (epoch 3.979), train_loss = 1.87757151, grad/param norm = 2.0059e-01, time/batch = 0.6344s	
2607/32750 (epoch 3.980), train_loss = 1.97083730, grad/param norm = 1.9714e-01, time/batch = 0.6329s	
2608/32750 (epoch 3.982), train_loss = 1.88409837, grad/param norm = 1.9515e-01, time/batch = 0.6522s	
2609/32750 (epoch 3.983), train_loss = 1.75672893, grad/param norm = 1.8876e-01, time/batch = 0.6732s	
2610/32750 (epoch 3.985), train_loss = 1.66723615, grad/param norm = 1.8079e-01, time/batch = 0.6401s	
2611/32750 (epoch 3.986), train_loss = 1.74368260, grad/param norm = 1.8507e-01, time/batch = 0.6371s	
2612/32750 (epoch 3.988), train_loss = 1.86387526, grad/param norm = 1.8166e-01, time/batch = 0.6348s	
2613/32750 (epoch 3.989), train_loss = 1.87545936, grad/param norm = 1.8682e-01, time/batch = 0.6349s	
2614/32750 (epoch 3.991), train_loss = 1.96871335, grad/param norm = 1.8317e-01, time/batch = 0.6527s	
2615/32750 (epoch 3.992), train_loss = 1.82316797, grad/param norm = 1.8447e-01, time/batch = 0.6359s	
2616/32750 (epoch 3.994), train_loss = 1.88468738, grad/param norm = 1.8939e-01, time/batch = 0.6362s	
2617/32750 (epoch 3.995), train_loss = 1.84912603, grad/param norm = 1.8437e-01, time/batch = 0.6520s	
2618/32750 (epoch 3.997), train_loss = 1.88551860, grad/param norm = 1.8689e-01, time/batch = 0.6346s	
2619/32750 (epoch 3.998), train_loss = 2.06253794, grad/param norm = 1.9666e-01, time/batch = 0.6567s	
2620/32750 (epoch 4.000), train_loss = 1.84477422, grad/param norm = 1.8320e-01, time/batch = 0.6574s	
2621/32750 (epoch 4.002), train_loss = 1.96464330, grad/param norm = 2.0841e-01, time/batch = 0.6690s	
2622/32750 (epoch 4.003), train_loss = 1.94169273, grad/param norm = 2.1928e-01, time/batch = 0.6627s	
2623/32750 (epoch 4.005), train_loss = 2.00955581, grad/param norm = 2.2367e-01, time/batch = 0.6560s	
2624/32750 (epoch 4.006), train_loss = 2.06125455, grad/param norm = 2.0224e-01, time/batch = 0.6750s	
2625/32750 (epoch 4.008), train_loss = 2.00039626, grad/param norm = 1.9390e-01, time/batch = 0.6638s	
2626/32750 (epoch 4.009), train_loss = 1.83344038, grad/param norm = 1.8407e-01, time/batch = 0.6564s	
2627/32750 (epoch 4.011), train_loss = 1.75396072, grad/param norm = 1.8336e-01, time/batch = 0.6529s	
2628/32750 (epoch 4.012), train_loss = 1.96459843, grad/param norm = 1.8503e-01, time/batch = 0.6519s	
2629/32750 (epoch 4.014), train_loss = 2.11219577, grad/param norm = 2.0726e-01, time/batch = 0.6560s	
2630/32750 (epoch 4.015), train_loss = 1.96857641, grad/param norm = 1.8920e-01, time/batch = 0.6362s	
2631/32750 (epoch 4.017), train_loss = 1.94094417, grad/param norm = 2.0688e-01, time/batch = 0.6465s	
2632/32750 (epoch 4.018), train_loss = 2.01377462, grad/param norm = 2.1578e-01, time/batch = 0.6565s	
2633/32750 (epoch 4.020), train_loss = 1.90355079, grad/param norm = 2.0548e-01, time/batch = 0.6354s	
2634/32750 (epoch 4.021), train_loss = 1.87838551, grad/param norm = 1.8770e-01, time/batch = 0.6355s	
2635/32750 (epoch 4.023), train_loss = 1.76286696, grad/param norm = 1.8395e-01, time/batch = 0.6353s	
2636/32750 (epoch 4.024), train_loss = 2.03853445, grad/param norm = 1.8066e-01, time/batch = 0.6324s	
2637/32750 (epoch 4.026), train_loss = 1.89141510, grad/param norm = 1.8578e-01, time/batch = 0.6317s	
2638/32750 (epoch 4.027), train_loss = 1.93779578, grad/param norm = 1.9516e-01, time/batch = 0.6323s	
2639/32750 (epoch 4.029), train_loss = 1.88161660, grad/param norm = 1.9102e-01, time/batch = 0.6483s	
2640/32750 (epoch 4.031), train_loss = 1.91176228, grad/param norm = 2.0102e-01, time/batch = 0.6371s	
2641/32750 (epoch 4.032), train_loss = 1.92239003, grad/param norm = 2.0142e-01, time/batch = 0.6355s	
2642/32750 (epoch 4.034), train_loss = 1.84794040, grad/param norm = 1.8860e-01, time/batch = 0.6345s	
2643/32750 (epoch 4.035), train_loss = 1.79627541, grad/param norm = 1.8044e-01, time/batch = 0.6338s	
2644/32750 (epoch 4.037), train_loss = 1.91790168, grad/param norm = 1.8068e-01, time/batch = 0.6422s	
2645/32750 (epoch 4.038), train_loss = 2.11159655, grad/param norm = 1.9675e-01, time/batch = 0.6372s	
2646/32750 (epoch 4.040), train_loss = 2.01110210, grad/param norm = 1.8406e-01, time/batch = 0.6326s	
2647/32750 (epoch 4.041), train_loss = 1.86209282, grad/param norm = 1.8273e-01, time/batch = 0.6317s	
2648/32750 (epoch 4.043), train_loss = 1.93008565, grad/param norm = 1.9145e-01, time/batch = 0.6326s	
2649/32750 (epoch 4.044), train_loss = 1.81298109, grad/param norm = 1.8307e-01, time/batch = 0.6316s	
2650/32750 (epoch 4.046), train_loss = 1.95647083, grad/param norm = 1.9599e-01, time/batch = 0.6317s	
2651/32750 (epoch 4.047), train_loss = 1.85993580, grad/param norm = 1.9101e-01, time/batch = 0.6366s	
2652/32750 (epoch 4.049), train_loss = 1.76174736, grad/param norm = 1.8956e-01, time/batch = 0.6327s	
2653/32750 (epoch 4.050), train_loss = 1.64667829, grad/param norm = 1.7616e-01, time/batch = 0.6342s	
2654/32750 (epoch 4.052), train_loss = 1.73405681, grad/param norm = 1.6807e-01, time/batch = 0.6346s	
2655/32750 (epoch 4.053), train_loss = 1.86146271, grad/param norm = 1.8953e-01, time/batch = 0.6348s	
2656/32750 (epoch 4.055), train_loss = 2.04922987, grad/param norm = 2.1125e-01, time/batch = 0.6338s	
2657/32750 (epoch 4.056), train_loss = 1.97931423, grad/param norm = 1.9344e-01, time/batch = 0.6336s	
2658/32750 (epoch 4.058), train_loss = 1.84581402, grad/param norm = 2.0909e-01, time/batch = 0.6449s	
2659/32750 (epoch 4.060), train_loss = 1.78133476, grad/param norm = 1.9161e-01, time/batch = 0.6466s	
2660/32750 (epoch 4.061), train_loss = 2.01253299, grad/param norm = 1.8059e-01, time/batch = 0.6314s	
2661/32750 (epoch 4.063), train_loss = 1.92572207, grad/param norm = 1.9516e-01, time/batch = 0.6360s	
2662/32750 (epoch 4.064), train_loss = 1.84115803, grad/param norm = 2.1057e-01, time/batch = 0.6402s	
2663/32750 (epoch 4.066), train_loss = 1.72199563, grad/param norm = 1.6931e-01, time/batch = 0.6359s	
2664/32750 (epoch 4.067), train_loss = 1.94882132, grad/param norm = 1.9712e-01, time/batch = 0.6437s	
2665/32750 (epoch 4.069), train_loss = 2.15190739, grad/param norm = 2.1439e-01, time/batch = 0.6693s	
2666/32750 (epoch 4.070), train_loss = 1.91495243, grad/param norm = 1.7589e-01, time/batch = 0.6324s	
2667/32750 (epoch 4.072), train_loss = 1.86428282, grad/param norm = 1.8390e-01, time/batch = 0.6335s	
2668/32750 (epoch 4.073), train_loss = 1.76354422, grad/param norm = 1.7156e-01, time/batch = 0.6390s	
2669/32750 (epoch 4.075), train_loss = 1.75384394, grad/param norm = 1.8648e-01, time/batch = 0.6350s	
2670/32750 (epoch 4.076), train_loss = 2.09243459, grad/param norm = 1.9676e-01, time/batch = 0.6543s	
2671/32750 (epoch 4.078), train_loss = 1.98512991, grad/param norm = 1.9687e-01, time/batch = 0.6495s	
2672/32750 (epoch 4.079), train_loss = 1.90500900, grad/param norm = 1.9308e-01, time/batch = 0.6341s	
2673/32750 (epoch 4.081), train_loss = 1.81957066, grad/param norm = 1.8243e-01, time/batch = 0.6421s	
2674/32750 (epoch 4.082), train_loss = 1.84167768, grad/param norm = 1.8006e-01, time/batch = 0.6314s	
2675/32750 (epoch 4.084), train_loss = 1.84140363, grad/param norm = 1.8155e-01, time/batch = 0.6498s	
2676/32750 (epoch 4.085), train_loss = 1.71640444, grad/param norm = 1.8146e-01, time/batch = 0.6426s	
2677/32750 (epoch 4.087), train_loss = 1.94585753, grad/param norm = 1.9199e-01, time/batch = 0.6344s	
2678/32750 (epoch 4.089), train_loss = 1.94942615, grad/param norm = 1.9429e-01, time/batch = 0.6365s	
2679/32750 (epoch 4.090), train_loss = 1.89855163, grad/param norm = 2.0573e-01, time/batch = 0.6347s	
2680/32750 (epoch 4.092), train_loss = 1.81794144, grad/param norm = 2.1772e-01, time/batch = 0.6344s	
2681/32750 (epoch 4.093), train_loss = 1.88710316, grad/param norm = 1.9710e-01, time/batch = 0.6341s	
2682/32750 (epoch 4.095), train_loss = 1.92921378, grad/param norm = 1.8958e-01, time/batch = 0.6330s	
2683/32750 (epoch 4.096), train_loss = 1.88586592, grad/param norm = 2.0903e-01, time/batch = 0.6341s	
2684/32750 (epoch 4.098), train_loss = 1.94652072, grad/param norm = 1.8462e-01, time/batch = 0.6331s	
2685/32750 (epoch 4.099), train_loss = 1.93411385, grad/param norm = 1.9441e-01, time/batch = 0.6352s	
2686/32750 (epoch 4.101), train_loss = 1.86136487, grad/param norm = 1.8921e-01, time/batch = 0.6385s	
2687/32750 (epoch 4.102), train_loss = 1.97739286, grad/param norm = 1.9475e-01, time/batch = 0.6341s	
2688/32750 (epoch 4.104), train_loss = 1.93126358, grad/param norm = 1.8417e-01, time/batch = 0.6329s	
2689/32750 (epoch 4.105), train_loss = 1.82033405, grad/param norm = 2.0575e-01, time/batch = 0.6340s	
2690/32750 (epoch 4.107), train_loss = 1.79717595, grad/param norm = 2.0338e-01, time/batch = 0.6351s	
2691/32750 (epoch 4.108), train_loss = 2.04324450, grad/param norm = 1.8629e-01, time/batch = 0.6344s	
2692/32750 (epoch 4.110), train_loss = 1.92104394, grad/param norm = 1.9647e-01, time/batch = 0.6349s	
2693/32750 (epoch 4.111), train_loss = 1.89846220, grad/param norm = 1.9277e-01, time/batch = 0.6327s	
2694/32750 (epoch 4.113), train_loss = 1.90037440, grad/param norm = 1.9499e-01, time/batch = 0.6347s	
2695/32750 (epoch 4.115), train_loss = 1.88933531, grad/param norm = 2.0402e-01, time/batch = 0.6338s	
2696/32750 (epoch 4.116), train_loss = 1.83483700, grad/param norm = 1.9660e-01, time/batch = 0.6399s	
2697/32750 (epoch 4.118), train_loss = 1.88296164, grad/param norm = 1.8929e-01, time/batch = 0.6475s	
2698/32750 (epoch 4.119), train_loss = 1.98363957, grad/param norm = 1.7457e-01, time/batch = 0.6322s	
2699/32750 (epoch 4.121), train_loss = 1.85809340, grad/param norm = 1.7882e-01, time/batch = 0.6323s	
2700/32750 (epoch 4.122), train_loss = 1.81300587, grad/param norm = 2.0159e-01, time/batch = 0.6326s	
2701/32750 (epoch 4.124), train_loss = 2.01415733, grad/param norm = 2.0145e-01, time/batch = 0.6344s	
2702/32750 (epoch 4.125), train_loss = 1.85187270, grad/param norm = 1.8813e-01, time/batch = 0.6368s	
2703/32750 (epoch 4.127), train_loss = 1.99480259, grad/param norm = 1.9231e-01, time/batch = 0.6335s	
2704/32750 (epoch 4.128), train_loss = 1.88942081, grad/param norm = 1.8065e-01, time/batch = 0.6333s	
2705/32750 (epoch 4.130), train_loss = 1.94657370, grad/param norm = 2.0723e-01, time/batch = 0.6344s	
2706/32750 (epoch 4.131), train_loss = 1.94753668, grad/param norm = 1.9445e-01, time/batch = 0.6509s	
2707/32750 (epoch 4.133), train_loss = 1.95930294, grad/param norm = 1.7350e-01, time/batch = 0.6736s	
2708/32750 (epoch 4.134), train_loss = 1.85943184, grad/param norm = 1.7159e-01, time/batch = 0.6351s	
2709/32750 (epoch 4.136), train_loss = 2.09980297, grad/param norm = 1.9301e-01, time/batch = 0.6328s	
2710/32750 (epoch 4.137), train_loss = 1.98830495, grad/param norm = 1.7982e-01, time/batch = 0.6335s	
2711/32750 (epoch 4.139), train_loss = 1.85734986, grad/param norm = 1.8478e-01, time/batch = 0.6324s	
2712/32750 (epoch 4.140), train_loss = 1.83345721, grad/param norm = 1.7896e-01, time/batch = 0.6330s	
2713/32750 (epoch 4.142), train_loss = 1.99087642, grad/param norm = 1.9938e-01, time/batch = 0.6356s	
2714/32750 (epoch 4.144), train_loss = 1.87839813, grad/param norm = 1.8580e-01, time/batch = 0.6339s	
2715/32750 (epoch 4.145), train_loss = 1.81617153, grad/param norm = 1.8463e-01, time/batch = 0.6326s	
2716/32750 (epoch 4.147), train_loss = 1.78073143, grad/param norm = 1.8804e-01, time/batch = 0.6329s	
2717/32750 (epoch 4.148), train_loss = 1.93141576, grad/param norm = 1.9766e-01, time/batch = 0.6331s	
2718/32750 (epoch 4.150), train_loss = 1.88445418, grad/param norm = 1.7777e-01, time/batch = 0.6404s	
2719/32750 (epoch 4.151), train_loss = 1.80652726, grad/param norm = 1.8655e-01, time/batch = 0.6333s	
2720/32750 (epoch 4.153), train_loss = 1.81491823, grad/param norm = 1.8023e-01, time/batch = 0.6346s	
2721/32750 (epoch 4.154), train_loss = 1.89015117, grad/param norm = 1.7662e-01, time/batch = 0.6353s	
2722/32750 (epoch 4.156), train_loss = 1.83947911, grad/param norm = 1.8082e-01, time/batch = 0.6676s	
2723/32750 (epoch 4.157), train_loss = 1.73475391, grad/param norm = 1.9219e-01, time/batch = 0.6605s	
2724/32750 (epoch 4.159), train_loss = 1.69845957, grad/param norm = 1.7590e-01, time/batch = 0.6344s	
2725/32750 (epoch 4.160), train_loss = 1.87316309, grad/param norm = 1.8512e-01, time/batch = 0.6384s	
2726/32750 (epoch 4.162), train_loss = 1.93920943, grad/param norm = 1.8852e-01, time/batch = 0.6373s	
2727/32750 (epoch 4.163), train_loss = 1.86741988, grad/param norm = 1.8745e-01, time/batch = 0.6338s	
2728/32750 (epoch 4.165), train_loss = 1.77614471, grad/param norm = 1.7684e-01, time/batch = 0.6339s	
2729/32750 (epoch 4.166), train_loss = 1.82312982, grad/param norm = 1.7809e-01, time/batch = 0.6331s	
2730/32750 (epoch 4.168), train_loss = 1.96937459, grad/param norm = 1.9263e-01, time/batch = 0.6335s	
2731/32750 (epoch 4.169), train_loss = 1.91141196, grad/param norm = 1.8180e-01, time/batch = 0.6345s	
2732/32750 (epoch 4.171), train_loss = 1.68505970, grad/param norm = 2.0550e-01, time/batch = 0.6375s	
2733/32750 (epoch 4.173), train_loss = 2.01965144, grad/param norm = 1.9502e-01, time/batch = 0.6401s	
2734/32750 (epoch 4.174), train_loss = 1.79099768, grad/param norm = 1.8241e-01, time/batch = 0.6345s	
2735/32750 (epoch 4.176), train_loss = 1.83715449, grad/param norm = 1.7943e-01, time/batch = 0.6400s	
2736/32750 (epoch 4.177), train_loss = 2.10625853, grad/param norm = 2.0502e-01, time/batch = 0.6368s	
2737/32750 (epoch 4.179), train_loss = 2.04166412, grad/param norm = 1.9746e-01, time/batch = 0.6352s	
2738/32750 (epoch 4.180), train_loss = 2.02651187, grad/param norm = 2.0190e-01, time/batch = 0.6331s	
2739/32750 (epoch 4.182), train_loss = 1.79575407, grad/param norm = 1.7649e-01, time/batch = 0.6334s	
2740/32750 (epoch 4.183), train_loss = 1.81752116, grad/param norm = 1.7983e-01, time/batch = 0.6315s	
2741/32750 (epoch 4.185), train_loss = 1.65198716, grad/param norm = 1.8241e-01, time/batch = 0.6349s	
2742/32750 (epoch 4.186), train_loss = 1.84918575, grad/param norm = 1.8270e-01, time/batch = 0.6316s	
2743/32750 (epoch 4.188), train_loss = 1.96817218, grad/param norm = 2.0005e-01, time/batch = 0.6304s	
2744/32750 (epoch 4.189), train_loss = 1.90879349, grad/param norm = 1.7586e-01, time/batch = 0.6299s	
2745/32750 (epoch 4.191), train_loss = 1.88307114, grad/param norm = 1.7718e-01, time/batch = 0.6307s	
2746/32750 (epoch 4.192), train_loss = 1.72751412, grad/param norm = 1.9452e-01, time/batch = 0.6298s	
2747/32750 (epoch 4.194), train_loss = 1.78385894, grad/param norm = 1.9172e-01, time/batch = 0.6304s	
2748/32750 (epoch 4.195), train_loss = 1.72903715, grad/param norm = 1.6718e-01, time/batch = 0.6321s	
2749/32750 (epoch 4.197), train_loss = 1.86776902, grad/param norm = 2.0046e-01, time/batch = 0.6362s	
2750/32750 (epoch 4.198), train_loss = 1.73951949, grad/param norm = 1.9359e-01, time/batch = 0.6335s	
2751/32750 (epoch 4.200), train_loss = 1.87507662, grad/param norm = 1.9115e-01, time/batch = 0.6343s	
2752/32750 (epoch 4.202), train_loss = 1.93709692, grad/param norm = 1.8514e-01, time/batch = 0.6315s	
2753/32750 (epoch 4.203), train_loss = 1.89259819, grad/param norm = 1.8783e-01, time/batch = 0.6543s	
2754/32750 (epoch 4.205), train_loss = 1.82247535, grad/param norm = 1.8015e-01, time/batch = 0.6710s	
2755/32750 (epoch 4.206), train_loss = 1.73471304, grad/param norm = 1.9179e-01, time/batch = 0.6320s	
2756/32750 (epoch 4.208), train_loss = 1.88926284, grad/param norm = 1.7684e-01, time/batch = 0.6313s	
2757/32750 (epoch 4.209), train_loss = 1.84509840, grad/param norm = 1.7362e-01, time/batch = 0.6325s	
2758/32750 (epoch 4.211), train_loss = 1.85306681, grad/param norm = 1.9550e-01, time/batch = 0.6330s	
2759/32750 (epoch 4.212), train_loss = 1.81254286, grad/param norm = 1.8079e-01, time/batch = 0.6320s	
2760/32750 (epoch 4.214), train_loss = 1.83893550, grad/param norm = 1.7975e-01, time/batch = 0.6318s	
2761/32750 (epoch 4.215), train_loss = 1.83348552, grad/param norm = 2.1583e-01, time/batch = 0.6349s	
2762/32750 (epoch 4.217), train_loss = 1.91904309, grad/param norm = 1.9564e-01, time/batch = 0.6325s	
2763/32750 (epoch 4.218), train_loss = 1.70285060, grad/param norm = 1.9101e-01, time/batch = 0.6360s	
2764/32750 (epoch 4.220), train_loss = 1.95116503, grad/param norm = 2.0903e-01, time/batch = 0.6447s	
2765/32750 (epoch 4.221), train_loss = 1.82243781, grad/param norm = 1.6846e-01, time/batch = 0.6631s	
2766/32750 (epoch 4.223), train_loss = 1.74728541, grad/param norm = 1.7764e-01, time/batch = 1.0144s	
2767/32750 (epoch 4.224), train_loss = 2.06533546, grad/param norm = 2.1082e-01, time/batch = 1.2009s	
2768/32750 (epoch 4.226), train_loss = 1.70784693, grad/param norm = 1.7372e-01, time/batch = 0.6610s	
2769/32750 (epoch 4.227), train_loss = 1.74092478, grad/param norm = 1.8279e-01, time/batch = 0.6362s	
2770/32750 (epoch 4.229), train_loss = 1.86135161, grad/param norm = 1.8816e-01, time/batch = 0.6364s	
2771/32750 (epoch 4.231), train_loss = 1.93083724, grad/param norm = 2.2445e-01, time/batch = 0.6387s	
2772/32750 (epoch 4.232), train_loss = 1.84669435, grad/param norm = 1.8628e-01, time/batch = 0.6677s	
