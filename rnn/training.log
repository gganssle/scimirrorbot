tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 643, val: 34, test: 0	
vocab size: 165	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 304421	
cloning rnn	
cloning criterion	
1/32150 (epoch 0.002), train_loss = 5.11848357, grad/param norm = 5.5219e-01, time/batch = 0.7358s	
2/32150 (epoch 0.003), train_loss = 4.89057546, grad/param norm = 1.2565e+00, time/batch = 0.6987s	
3/32150 (epoch 0.005), train_loss = 4.05815678, grad/param norm = 1.7265e+00, time/batch = 0.6935s	
4/32150 (epoch 0.006), train_loss = 3.55900404, grad/param norm = 1.4121e+00, time/batch = 0.6860s	
5/32150 (epoch 0.008), train_loss = 3.69605680, grad/param norm = 9.1647e-01, time/batch = 0.6812s	
6/32150 (epoch 0.009), train_loss = 3.52730369, grad/param norm = 8.7030e-01, time/batch = 0.6835s	
7/32150 (epoch 0.011), train_loss = 3.40954304, grad/param norm = 8.2605e-01, time/batch = 0.6850s	
8/32150 (epoch 0.012), train_loss = 3.44759310, grad/param norm = 9.4609e-01, time/batch = 0.6930s	
9/32150 (epoch 0.014), train_loss = 3.46068375, grad/param norm = 6.4541e-01, time/batch = 0.6889s	
10/32150 (epoch 0.016), train_loss = 3.34061949, grad/param norm = 8.5694e-01, time/batch = 0.6914s	
11/32150 (epoch 0.017), train_loss = 3.57641394, grad/param norm = 8.8770e-01, time/batch = 0.6889s	
12/32150 (epoch 0.019), train_loss = 3.47894244, grad/param norm = 6.3347e-01, time/batch = 0.6921s	
13/32150 (epoch 0.020), train_loss = 3.44964951, grad/param norm = 7.6205e-01, time/batch = 0.6924s	
14/32150 (epoch 0.022), train_loss = 3.36498695, grad/param norm = 7.6272e-01, time/batch = 0.6893s	
15/32150 (epoch 0.023), train_loss = 3.58187503, grad/param norm = 6.7531e-01, time/batch = 0.6832s	
16/32150 (epoch 0.025), train_loss = 3.92121957, grad/param norm = 8.3222e-01, time/batch = 0.6866s	
17/32150 (epoch 0.026), train_loss = 3.72645563, grad/param norm = 8.7697e-01, time/batch = 0.6974s	
18/32150 (epoch 0.028), train_loss = 3.79710266, grad/param norm = 7.3376e-01, time/batch = 0.6946s	
19/32150 (epoch 0.030), train_loss = 3.68126094, grad/param norm = 7.2167e-01, time/batch = 0.7014s	
20/32150 (epoch 0.031), train_loss = 3.45144756, grad/param norm = 5.8922e-01, time/batch = 0.7011s	
21/32150 (epoch 0.033), train_loss = 3.79293198, grad/param norm = 8.0532e-01, time/batch = 0.7062s	
22/32150 (epoch 0.034), train_loss = 3.66739603, grad/param norm = 7.4806e-01, time/batch = 0.6953s	
23/32150 (epoch 0.036), train_loss = 3.43912568, grad/param norm = 1.1128e+00, time/batch = 0.6871s	
24/32150 (epoch 0.037), train_loss = 3.53020967, grad/param norm = 6.7787e-01, time/batch = 0.6946s	
25/32150 (epoch 0.039), train_loss = 3.53741754, grad/param norm = 4.9552e-01, time/batch = 0.6826s	
26/32150 (epoch 0.040), train_loss = 3.48103311, grad/param norm = 6.6255e-01, time/batch = 0.6810s	
27/32150 (epoch 0.042), train_loss = 3.46677784, grad/param norm = 6.3025e-01, time/batch = 0.6839s	
28/32150 (epoch 0.044), train_loss = 3.44152819, grad/param norm = 6.6779e-01, time/batch = 0.6857s	
29/32150 (epoch 0.045), train_loss = 3.55726563, grad/param norm = 9.4297e-01, time/batch = 0.6890s	
30/32150 (epoch 0.047), train_loss = 3.45396569, grad/param norm = 8.1681e-01, time/batch = 0.6828s	
31/32150 (epoch 0.048), train_loss = 3.63369764, grad/param norm = 8.3051e-01, time/batch = 0.6989s	
32/32150 (epoch 0.050), train_loss = 3.49497641, grad/param norm = 6.3858e-01, time/batch = 0.6883s	
33/32150 (epoch 0.051), train_loss = 3.78906640, grad/param norm = 1.1142e+00, time/batch = 0.6897s	
34/32150 (epoch 0.053), train_loss = 3.76359702, grad/param norm = 8.4281e-01, time/batch = 0.6902s	
35/32150 (epoch 0.054), train_loss = 3.67397663, grad/param norm = 7.2904e-01, time/batch = 0.6892s	
36/32150 (epoch 0.056), train_loss = 3.43390912, grad/param norm = 8.6536e-01, time/batch = 0.6891s	
37/32150 (epoch 0.058), train_loss = 3.50727085, grad/param norm = 6.8906e-01, time/batch = 0.6871s	
38/32150 (epoch 0.059), train_loss = 3.55348139, grad/param norm = 5.5664e-01, time/batch = 0.6792s	
39/32150 (epoch 0.061), train_loss = 3.49705976, grad/param norm = 6.1277e-01, time/batch = 0.6786s	
40/32150 (epoch 0.062), train_loss = 3.65836452, grad/param norm = 8.8337e-01, time/batch = 0.7056s	
41/32150 (epoch 0.064), train_loss = 3.41016257, grad/param norm = 7.1722e-01, time/batch = 0.6838s	
42/32150 (epoch 0.065), train_loss = 3.42985086, grad/param norm = 6.6037e-01, time/batch = 0.6927s	
43/32150 (epoch 0.067), train_loss = 3.85110520, grad/param norm = 9.4833e-01, time/batch = 0.6872s	
44/32150 (epoch 0.068), train_loss = 3.57206632, grad/param norm = 6.8508e-01, time/batch = 0.6934s	
45/32150 (epoch 0.070), train_loss = 3.40486686, grad/param norm = 7.6336e-01, time/batch = 0.6850s	
46/32150 (epoch 0.072), train_loss = 3.52130770, grad/param norm = 6.9614e-01, time/batch = 0.6800s	
47/32150 (epoch 0.073), train_loss = 3.43152605, grad/param norm = 8.0465e-01, time/batch = 0.6848s	
48/32150 (epoch 0.075), train_loss = 3.52823927, grad/param norm = 6.8599e-01, time/batch = 0.6947s	
49/32150 (epoch 0.076), train_loss = 3.41375461, grad/param norm = 6.1693e-01, time/batch = 0.7011s	
50/32150 (epoch 0.078), train_loss = 3.52175862, grad/param norm = 4.9632e-01, time/batch = 0.6994s	
51/32150 (epoch 0.079), train_loss = 3.45789283, grad/param norm = 5.2770e-01, time/batch = 0.6937s	
52/32150 (epoch 0.081), train_loss = 3.35873209, grad/param norm = 6.5780e-01, time/batch = 0.6860s	
53/32150 (epoch 0.082), train_loss = 3.40347868, grad/param norm = 5.2480e-01, time/batch = 0.6929s	
54/32150 (epoch 0.084), train_loss = 3.33883279, grad/param norm = 6.8331e-01, time/batch = 0.6940s	
55/32150 (epoch 0.086), train_loss = 3.40610539, grad/param norm = 7.1316e-01, time/batch = 0.6945s	
56/32150 (epoch 0.087), train_loss = 3.36068014, grad/param norm = 7.0894e-01, time/batch = 0.6928s	
57/32150 (epoch 0.089), train_loss = 3.45645530, grad/param norm = 7.6233e-01, time/batch = 0.6940s	
58/32150 (epoch 0.090), train_loss = 3.52896188, grad/param norm = 6.9131e-01, time/batch = 0.6910s	
59/32150 (epoch 0.092), train_loss = 3.52763975, grad/param norm = 5.3121e-01, time/batch = 0.6909s	
60/32150 (epoch 0.093), train_loss = 3.39789083, grad/param norm = 5.0393e-01, time/batch = 0.6970s	
61/32150 (epoch 0.095), train_loss = 3.48279876, grad/param norm = 5.1921e-01, time/batch = 0.6945s	
62/32150 (epoch 0.096), train_loss = 3.44066129, grad/param norm = 6.0716e-01, time/batch = 0.6894s	
63/32150 (epoch 0.098), train_loss = 3.44788350, grad/param norm = 7.3445e-01, time/batch = 0.6942s	
64/32150 (epoch 0.100), train_loss = 3.60988063, grad/param norm = 6.9663e-01, time/batch = 0.7008s	
65/32150 (epoch 0.101), train_loss = 3.39168131, grad/param norm = 5.8706e-01, time/batch = 0.6894s	
66/32150 (epoch 0.103), train_loss = 3.48523303, grad/param norm = 5.7015e-01, time/batch = 0.6918s	
67/32150 (epoch 0.104), train_loss = 3.37011735, grad/param norm = 5.4730e-01, time/batch = 0.7007s	
68/32150 (epoch 0.106), train_loss = 3.45628348, grad/param norm = 6.6752e-01, time/batch = 0.6982s	
69/32150 (epoch 0.107), train_loss = 3.50113666, grad/param norm = 5.0570e-01, time/batch = 0.6964s	
70/32150 (epoch 0.109), train_loss = 3.40176406, grad/param norm = 5.5607e-01, time/batch = 0.6943s	
71/32150 (epoch 0.110), train_loss = 3.53729617, grad/param norm = 6.1375e-01, time/batch = 0.6935s	
72/32150 (epoch 0.112), train_loss = 3.40287532, grad/param norm = 4.7762e-01, time/batch = 0.6988s	
73/32150 (epoch 0.114), train_loss = 3.45031280, grad/param norm = 5.4912e-01, time/batch = 0.6936s	
74/32150 (epoch 0.115), train_loss = 3.50205090, grad/param norm = 5.6926e-01, time/batch = 0.6904s	
75/32150 (epoch 0.117), train_loss = 3.42893756, grad/param norm = 5.6446e-01, time/batch = 0.6928s	
76/32150 (epoch 0.118), train_loss = 3.69028007, grad/param norm = 7.5320e-01, time/batch = 0.6973s	
77/32150 (epoch 0.120), train_loss = 3.44688109, grad/param norm = 7.5032e-01, time/batch = 0.7014s	
78/32150 (epoch 0.121), train_loss = 3.31441801, grad/param norm = 6.2292e-01, time/batch = 0.6933s	
79/32150 (epoch 0.123), train_loss = 3.43179087, grad/param norm = 8.4019e-01, time/batch = 0.6917s	
80/32150 (epoch 0.124), train_loss = 3.40475485, grad/param norm = 5.1372e-01, time/batch = 0.6920s	
81/32150 (epoch 0.126), train_loss = 3.43032525, grad/param norm = 5.9618e-01, time/batch = 0.6863s	
82/32150 (epoch 0.128), train_loss = 3.59348024, grad/param norm = 5.3783e-01, time/batch = 0.7148s	
83/32150 (epoch 0.129), train_loss = 3.46762721, grad/param norm = 6.5122e-01, time/batch = 0.7031s	
84/32150 (epoch 0.131), train_loss = 3.52069299, grad/param norm = 8.0996e-01, time/batch = 0.6941s	
85/32150 (epoch 0.132), train_loss = 3.41463889, grad/param norm = 6.2474e-01, time/batch = 0.6944s	
86/32150 (epoch 0.134), train_loss = 3.54541937, grad/param norm = 6.2072e-01, time/batch = 0.6929s	
87/32150 (epoch 0.135), train_loss = 3.53860510, grad/param norm = 5.9690e-01, time/batch = 0.6899s	
88/32150 (epoch 0.137), train_loss = 3.47214869, grad/param norm = 6.1488e-01, time/batch = 0.6893s	
89/32150 (epoch 0.138), train_loss = 3.35495999, grad/param norm = 5.9089e-01, time/batch = 0.6932s	
90/32150 (epoch 0.140), train_loss = 3.50393510, grad/param norm = 6.9992e-01, time/batch = 0.6982s	
91/32150 (epoch 0.142), train_loss = 3.31969387, grad/param norm = 4.2984e-01, time/batch = 0.7008s	
92/32150 (epoch 0.143), train_loss = 3.38045744, grad/param norm = 6.7128e-01, time/batch = 0.6938s	
93/32150 (epoch 0.145), train_loss = 3.27767104, grad/param norm = 5.1537e-01, time/batch = 0.6947s	
94/32150 (epoch 0.146), train_loss = 3.59773943, grad/param norm = 7.8645e-01, time/batch = 0.6965s	
95/32150 (epoch 0.148), train_loss = 3.49776618, grad/param norm = 6.8049e-01, time/batch = 0.6937s	
96/32150 (epoch 0.149), train_loss = 3.53012754, grad/param norm = 5.7861e-01, time/batch = 0.6963s	
97/32150 (epoch 0.151), train_loss = 3.37114377, grad/param norm = 7.1668e-01, time/batch = 0.7014s	
98/32150 (epoch 0.152), train_loss = 3.57703092, grad/param norm = 6.9132e-01, time/batch = 0.6928s	
99/32150 (epoch 0.154), train_loss = 3.37052840, grad/param norm = 7.0350e-01, time/batch = 0.7002s	
100/32150 (epoch 0.156), train_loss = 3.53070870, grad/param norm = 5.3980e-01, time/batch = 0.7057s	
101/32150 (epoch 0.157), train_loss = 3.47387725, grad/param norm = 4.8672e-01, time/batch = 0.7052s	
102/32150 (epoch 0.159), train_loss = 3.49868821, grad/param norm = 5.4591e-01, time/batch = 0.7024s	
103/32150 (epoch 0.160), train_loss = 3.41380465, grad/param norm = 5.1120e-01, time/batch = 0.7004s	
104/32150 (epoch 0.162), train_loss = 3.52930366, grad/param norm = 6.0045e-01, time/batch = 0.6996s	
105/32150 (epoch 0.163), train_loss = 3.43040403, grad/param norm = 4.7490e-01, time/batch = 0.7010s	
106/32150 (epoch 0.165), train_loss = 3.30526565, grad/param norm = 7.2392e-01, time/batch = 0.7009s	
107/32150 (epoch 0.166), train_loss = 3.89673187, grad/param norm = 6.4879e-01, time/batch = 0.7051s	
108/32150 (epoch 0.168), train_loss = 3.78574241, grad/param norm = 7.2809e-01, time/batch = 0.6986s	
109/32150 (epoch 0.170), train_loss = 3.82710514, grad/param norm = 4.9091e-01, time/batch = 0.6951s	
110/32150 (epoch 0.171), train_loss = 3.79113633, grad/param norm = 8.4305e-01, time/batch = 0.6893s	
111/32150 (epoch 0.173), train_loss = 3.59876642, grad/param norm = 4.9760e-01, time/batch = 0.7025s	
112/32150 (epoch 0.174), train_loss = 3.48498835, grad/param norm = 3.9350e-01, time/batch = 0.6945s	
113/32150 (epoch 0.176), train_loss = 3.30241773, grad/param norm = 4.8818e-01, time/batch = 0.6951s	
114/32150 (epoch 0.177), train_loss = 3.56421141, grad/param norm = 4.9969e-01, time/batch = 0.6939s	
115/32150 (epoch 0.179), train_loss = 3.45307143, grad/param norm = 4.1858e-01, time/batch = 0.7024s	
116/32150 (epoch 0.180), train_loss = 3.50028291, grad/param norm = 5.0547e-01, time/batch = 0.6907s	
117/32150 (epoch 0.182), train_loss = 3.50514796, grad/param norm = 3.7447e-01, time/batch = 0.6866s	
118/32150 (epoch 0.184), train_loss = 3.43490974, grad/param norm = 4.0551e-01, time/batch = 0.6969s	
119/32150 (epoch 0.185), train_loss = 3.45707942, grad/param norm = 4.4659e-01, time/batch = 0.6952s	
120/32150 (epoch 0.187), train_loss = 3.32370621, grad/param norm = 6.8505e-01, time/batch = 0.6948s	
121/32150 (epoch 0.188), train_loss = 3.45626497, grad/param norm = 1.0899e+00, time/batch = 0.6911s	
122/32150 (epoch 0.190), train_loss = 3.59784648, grad/param norm = 6.5845e-01, time/batch = 0.6936s	
123/32150 (epoch 0.191), train_loss = 3.40085478, grad/param norm = 6.1250e-01, time/batch = 0.6896s	
124/32150 (epoch 0.193), train_loss = 3.33863789, grad/param norm = 4.8827e-01, time/batch = 0.6843s	
125/32150 (epoch 0.194), train_loss = 3.43279545, grad/param norm = 4.3030e-01, time/batch = 0.7023s	
126/32150 (epoch 0.196), train_loss = 3.41773276, grad/param norm = 4.3993e-01, time/batch = 0.7011s	
127/32150 (epoch 0.198), train_loss = 3.42938866, grad/param norm = 5.2038e-01, time/batch = 0.6910s	
128/32150 (epoch 0.199), train_loss = 3.31201839, grad/param norm = 5.7555e-01, time/batch = 0.6997s	
129/32150 (epoch 0.201), train_loss = 3.37172915, grad/param norm = 7.2168e-01, time/batch = 0.6954s	
130/32150 (epoch 0.202), train_loss = 3.26476218, grad/param norm = 7.5835e-01, time/batch = 0.6953s	
131/32150 (epoch 0.204), train_loss = 3.47924512, grad/param norm = 9.9396e-01, time/batch = 0.6819s	
132/32150 (epoch 0.205), train_loss = 3.30410109, grad/param norm = 7.2880e-01, time/batch = 0.6918s	
133/32150 (epoch 0.207), train_loss = 3.20629398, grad/param norm = 4.0023e-01, time/batch = 0.6911s	
134/32150 (epoch 0.208), train_loss = 3.30931190, grad/param norm = 3.6689e-01, time/batch = 0.6960s	
135/32150 (epoch 0.210), train_loss = 3.21493018, grad/param norm = 4.0033e-01, time/batch = 0.6901s	
136/32150 (epoch 0.212), train_loss = 3.31016302, grad/param norm = 5.2626e-01, time/batch = 0.6971s	
137/32150 (epoch 0.213), train_loss = 3.34367175, grad/param norm = 7.0373e-01, time/batch = 0.6924s	
138/32150 (epoch 0.215), train_loss = 3.33614393, grad/param norm = 6.3341e-01, time/batch = 0.6865s	
139/32150 (epoch 0.216), train_loss = 3.28834079, grad/param norm = 6.4395e-01, time/batch = 0.6903s	
140/32150 (epoch 0.218), train_loss = 3.22009405, grad/param norm = 6.1678e-01, time/batch = 0.6913s	
141/32150 (epoch 0.219), train_loss = 3.36193904, grad/param norm = 5.7382e-01, time/batch = 0.6939s	
142/32150 (epoch 0.221), train_loss = 3.42902020, grad/param norm = 3.9822e-01, time/batch = 0.6926s	
143/32150 (epoch 0.222), train_loss = 3.27314128, grad/param norm = 5.3943e-01, time/batch = 0.6944s	
144/32150 (epoch 0.224), train_loss = 3.52258620, grad/param norm = 7.3889e-01, time/batch = 0.6951s	
145/32150 (epoch 0.226), train_loss = 3.63527824, grad/param norm = 4.7823e-01, time/batch = 0.6845s	
146/32150 (epoch 0.227), train_loss = 3.56683284, grad/param norm = 1.1001e+00, time/batch = 0.6890s	
147/32150 (epoch 0.229), train_loss = 4.09991250, grad/param norm = 1.8421e+00, time/batch = 0.6936s	
148/32150 (epoch 0.230), train_loss = 3.49758170, grad/param norm = 1.5059e+00, time/batch = 0.6893s	
149/32150 (epoch 0.232), train_loss = 3.57261251, grad/param norm = 5.5363e-01, time/batch = 0.6906s	
150/32150 (epoch 0.233), train_loss = 3.62288240, grad/param norm = 5.7009e-01, time/batch = 0.6919s	
151/32150 (epoch 0.235), train_loss = 3.69800761, grad/param norm = 6.0072e-01, time/batch = 0.6922s	
152/32150 (epoch 0.236), train_loss = 3.49546765, grad/param norm = 1.3551e+00, time/batch = 0.6923s	
153/32150 (epoch 0.238), train_loss = 3.37674260, grad/param norm = 4.5768e-01, time/batch = 0.7037s	
154/32150 (epoch 0.240), train_loss = 3.34907452, grad/param norm = 4.1790e-01, time/batch = 0.6996s	
155/32150 (epoch 0.241), train_loss = 3.17633151, grad/param norm = 4.3182e-01, time/batch = 0.6986s	
156/32150 (epoch 0.243), train_loss = 3.22807197, grad/param norm = 4.1342e-01, time/batch = 0.6968s	
157/32150 (epoch 0.244), train_loss = 3.14841529, grad/param norm = 4.6530e-01, time/batch = 0.7066s	
158/32150 (epoch 0.246), train_loss = 3.36848911, grad/param norm = 7.6060e-01, time/batch = 0.6946s	
159/32150 (epoch 0.247), train_loss = 3.35683905, grad/param norm = 5.6308e-01, time/batch = 0.6979s	
160/32150 (epoch 0.249), train_loss = 3.31745082, grad/param norm = 4.5156e-01, time/batch = 0.7037s	
161/32150 (epoch 0.250), train_loss = 3.18058037, grad/param norm = 5.4111e-01, time/batch = 0.6988s	
162/32150 (epoch 0.252), train_loss = 3.25259846, grad/param norm = 7.8823e-01, time/batch = 0.6943s	
163/32150 (epoch 0.253), train_loss = 3.22656222, grad/param norm = 7.8955e-01, time/batch = 0.7040s	
164/32150 (epoch 0.255), train_loss = 3.24935550, grad/param norm = 5.2938e-01, time/batch = 0.6962s	
165/32150 (epoch 0.257), train_loss = 3.25647843, grad/param norm = 4.8587e-01, time/batch = 0.6995s	
166/32150 (epoch 0.258), train_loss = 3.11564831, grad/param norm = 4.4757e-01, time/batch = 0.6981s	
167/32150 (epoch 0.260), train_loss = 3.21266369, grad/param norm = 6.9755e-01, time/batch = 0.6929s	
168/32150 (epoch 0.261), train_loss = 3.16634685, grad/param norm = 1.2353e+00, time/batch = 0.7031s	
169/32150 (epoch 0.263), train_loss = 3.36243038, grad/param norm = 6.7020e-01, time/batch = 0.7007s	
170/32150 (epoch 0.264), train_loss = 3.15875934, grad/param norm = 4.3683e-01, time/batch = 0.6981s	
171/32150 (epoch 0.266), train_loss = 3.10389090, grad/param norm = 2.8057e-01, time/batch = 0.7003s	
172/32150 (epoch 0.267), train_loss = 3.11816468, grad/param norm = 3.2836e-01, time/batch = 0.7016s	
173/32150 (epoch 0.269), train_loss = 3.03390836, grad/param norm = 5.0619e-01, time/batch = 0.6979s	
174/32150 (epoch 0.271), train_loss = 3.19178660, grad/param norm = 6.5816e-01, time/batch = 0.6975s	
175/32150 (epoch 0.272), train_loss = 3.06893609, grad/param norm = 1.1655e+00, time/batch = 0.6962s	
176/32150 (epoch 0.274), train_loss = 3.33790554, grad/param norm = 9.7543e-01, time/batch = 0.6985s	
177/32150 (epoch 0.275), train_loss = 3.11644957, grad/param norm = 5.0570e-01, time/batch = 0.7046s	
178/32150 (epoch 0.277), train_loss = 3.11887368, grad/param norm = 5.7394e-01, time/batch = 0.7039s	
179/32150 (epoch 0.278), train_loss = 3.16655198, grad/param norm = 6.0058e-01, time/batch = 0.6969s	
180/32150 (epoch 0.280), train_loss = 3.08322774, grad/param norm = 7.9868e-01, time/batch = 0.6979s	
181/32150 (epoch 0.281), train_loss = 3.49405234, grad/param norm = 1.4807e+00, time/batch = 0.7081s	
182/32150 (epoch 0.283), train_loss = 3.39635909, grad/param norm = 1.7382e+00, time/batch = 0.7108s	
183/32150 (epoch 0.285), train_loss = 3.19410794, grad/param norm = 6.7051e-01, time/batch = 0.7056s	
184/32150 (epoch 0.286), train_loss = 3.21926903, grad/param norm = 3.5663e-01, time/batch = 0.7013s	
185/32150 (epoch 0.288), train_loss = 3.18509233, grad/param norm = 4.6191e-01, time/batch = 0.6992s	
186/32150 (epoch 0.289), train_loss = 3.17973294, grad/param norm = 7.5682e-01, time/batch = 0.6951s	
187/32150 (epoch 0.291), train_loss = 3.16262275, grad/param norm = 6.5898e-01, time/batch = 0.6940s	
188/32150 (epoch 0.292), train_loss = 2.98314655, grad/param norm = 5.1144e-01, time/batch = 0.6961s	
189/32150 (epoch 0.294), train_loss = 3.09554107, grad/param norm = 4.9142e-01, time/batch = 0.6957s	
190/32150 (epoch 0.295), train_loss = 3.08522388, grad/param norm = 5.0070e-01, time/batch = 0.6956s	
191/32150 (epoch 0.297), train_loss = 3.14307084, grad/param norm = 4.7239e-01, time/batch = 0.7052s	
192/32150 (epoch 0.299), train_loss = 3.13968900, grad/param norm = 4.7691e-01, time/batch = 0.6976s	
193/32150 (epoch 0.300), train_loss = 3.02064892, grad/param norm = 4.9776e-01, time/batch = 0.6959s	
194/32150 (epoch 0.302), train_loss = 3.05723411, grad/param norm = 6.7331e-01, time/batch = 0.6942s	
195/32150 (epoch 0.303), train_loss = 3.38791021, grad/param norm = 1.1104e+00, time/batch = 0.6945s	
196/32150 (epoch 0.305), train_loss = 3.24984911, grad/param norm = 8.3300e-01, time/batch = 0.6931s	
197/32150 (epoch 0.306), train_loss = 3.12908041, grad/param norm = 4.9017e-01, time/batch = 0.7023s	
198/32150 (epoch 0.308), train_loss = 3.08354275, grad/param norm = 4.7036e-01, time/batch = 0.6937s	
199/32150 (epoch 0.309), train_loss = 3.20708431, grad/param norm = 6.5306e-01, time/batch = 0.6991s	
200/32150 (epoch 0.311), train_loss = 3.05406104, grad/param norm = 7.4634e-01, time/batch = 0.6960s	
201/32150 (epoch 0.313), train_loss = 3.05277657, grad/param norm = 7.7372e-01, time/batch = 0.6792s	
202/32150 (epoch 0.314), train_loss = 3.05818543, grad/param norm = 6.0155e-01, time/batch = 0.6799s	
203/32150 (epoch 0.316), train_loss = 3.01568972, grad/param norm = 3.8422e-01, time/batch = 0.6878s	
204/32150 (epoch 0.317), train_loss = 3.03133717, grad/param norm = 6.7515e-01, time/batch = 0.6869s	
205/32150 (epoch 0.319), train_loss = 3.05051237, grad/param norm = 8.5054e-01, time/batch = 0.6938s	
206/32150 (epoch 0.320), train_loss = 3.00975242, grad/param norm = 6.6147e-01, time/batch = 0.6931s	
207/32150 (epoch 0.322), train_loss = 2.99163173, grad/param norm = 4.3512e-01, time/batch = 0.6953s	
208/32150 (epoch 0.323), train_loss = 3.06073101, grad/param norm = 4.1547e-01, time/batch = 0.6936s	
209/32150 (epoch 0.325), train_loss = 3.19238868, grad/param norm = 4.0999e-01, time/batch = 0.6893s	
210/32150 (epoch 0.327), train_loss = 3.27867951, grad/param norm = 3.7612e-01, time/batch = 0.6893s	
211/32150 (epoch 0.328), train_loss = 3.10377320, grad/param norm = 7.2188e-01, time/batch = 0.6958s	
212/32150 (epoch 0.330), train_loss = 3.21347369, grad/param norm = 1.2178e+00, time/batch = 0.6964s	
213/32150 (epoch 0.331), train_loss = 3.16170160, grad/param norm = 1.0925e+00, time/batch = 0.6976s	
214/32150 (epoch 0.333), train_loss = 3.08644457, grad/param norm = 4.3601e-01, time/batch = 0.6929s	
215/32150 (epoch 0.334), train_loss = 3.06325545, grad/param norm = 4.6657e-01, time/batch = 0.7039s	
216/32150 (epoch 0.336), train_loss = 3.10639165, grad/param norm = 4.5375e-01, time/batch = 0.6974s	
217/32150 (epoch 0.337), train_loss = 3.25236097, grad/param norm = 7.6282e-01, time/batch = 0.6955s	
218/32150 (epoch 0.339), train_loss = 3.28708618, grad/param norm = 1.2664e+00, time/batch = 0.6843s	
219/32150 (epoch 0.341), train_loss = 3.16515362, grad/param norm = 8.1443e-01, time/batch = 0.6953s	
220/32150 (epoch 0.342), train_loss = 2.98291563, grad/param norm = 5.3975e-01, time/batch = 0.6977s	
221/32150 (epoch 0.344), train_loss = 2.86456407, grad/param norm = 5.4256e-01, time/batch = 0.6910s	
222/32150 (epoch 0.345), train_loss = 3.00562020, grad/param norm = 7.3327e-01, time/batch = 0.6917s	
223/32150 (epoch 0.347), train_loss = 2.98236006, grad/param norm = 7.9552e-01, time/batch = 0.6887s	
224/32150 (epoch 0.348), train_loss = 2.96511812, grad/param norm = 7.9388e-01, time/batch = 0.6916s	
225/32150 (epoch 0.350), train_loss = 3.12105413, grad/param norm = 6.5221e-01, time/batch = 0.6927s	
226/32150 (epoch 0.351), train_loss = 3.21644551, grad/param norm = 6.4945e-01, time/batch = 0.6993s	
227/32150 (epoch 0.353), train_loss = 3.09228685, grad/param norm = 5.6863e-01, time/batch = 0.6933s	
228/32150 (epoch 0.355), train_loss = 3.01029804, grad/param norm = 5.7730e-01, time/batch = 0.6959s	
229/32150 (epoch 0.356), train_loss = 3.17085269, grad/param norm = 7.3983e-01, time/batch = 0.6980s	
230/32150 (epoch 0.358), train_loss = 3.04466589, grad/param norm = 7.4756e-01, time/batch = 0.7030s	
231/32150 (epoch 0.359), train_loss = 2.98572616, grad/param norm = 4.9866e-01, time/batch = 0.6926s	
232/32150 (epoch 0.361), train_loss = 3.09555433, grad/param norm = 4.9847e-01, time/batch = 0.6802s	
233/32150 (epoch 0.362), train_loss = 3.12905577, grad/param norm = 4.1043e-01, time/batch = 0.6925s	
234/32150 (epoch 0.364), train_loss = 3.03684869, grad/param norm = 3.5635e-01, time/batch = 0.6948s	
235/32150 (epoch 0.365), train_loss = 3.05084543, grad/param norm = 3.2774e-01, time/batch = 0.6996s	
236/32150 (epoch 0.367), train_loss = 3.09033338, grad/param norm = 4.9527e-01, time/batch = 0.6857s	
237/32150 (epoch 0.369), train_loss = 2.99361273, grad/param norm = 7.3633e-01, time/batch = 0.6851s	
238/32150 (epoch 0.370), train_loss = 3.03763678, grad/param norm = 1.0127e+00, time/batch = 0.6938s	
239/32150 (epoch 0.372), train_loss = 3.16416668, grad/param norm = 1.1305e+00, time/batch = 0.7034s	
240/32150 (epoch 0.373), train_loss = 3.18468050, grad/param norm = 6.3363e-01, time/batch = 0.6934s	
241/32150 (epoch 0.375), train_loss = 3.05695246, grad/param norm = 5.2410e-01, time/batch = 0.6984s	
242/32150 (epoch 0.376), train_loss = 3.12359410, grad/param norm = 6.0291e-01, time/batch = 0.6935s	
243/32150 (epoch 0.378), train_loss = 3.07733340, grad/param norm = 4.8537e-01, time/batch = 0.6906s	
244/32150 (epoch 0.379), train_loss = 2.96004802, grad/param norm = 4.0287e-01, time/batch = 0.6944s	
245/32150 (epoch 0.381), train_loss = 3.05750176, grad/param norm = 4.0360e-01, time/batch = 0.6987s	
246/32150 (epoch 0.383), train_loss = 2.94269379, grad/param norm = 4.8389e-01, time/batch = 0.6954s	
247/32150 (epoch 0.384), train_loss = 3.00322101, grad/param norm = 8.3913e-01, time/batch = 0.7040s	
248/32150 (epoch 0.386), train_loss = 3.01897895, grad/param norm = 9.8528e-01, time/batch = 0.7020s	
249/32150 (epoch 0.387), train_loss = 3.02478045, grad/param norm = 6.0028e-01, time/batch = 0.6948s	
250/32150 (epoch 0.389), train_loss = 2.83045574, grad/param norm = 5.6395e-01, time/batch = 0.7018s	
251/32150 (epoch 0.390), train_loss = 3.09828165, grad/param norm = 6.0652e-01, time/batch = 0.7148s	
252/32150 (epoch 0.392), train_loss = 3.06790009, grad/param norm = 5.0484e-01, time/batch = 0.6951s	
253/32150 (epoch 0.393), train_loss = 3.02906129, grad/param norm = 4.8162e-01, time/batch = 0.6953s	
254/32150 (epoch 0.395), train_loss = 2.92416608, grad/param norm = 3.9679e-01, time/batch = 0.6953s	
255/32150 (epoch 0.397), train_loss = 3.03373154, grad/param norm = 4.3958e-01, time/batch = 0.6945s	
256/32150 (epoch 0.398), train_loss = 3.03212385, grad/param norm = 4.5753e-01, time/batch = 0.6948s	
257/32150 (epoch 0.400), train_loss = 3.17736428, grad/param norm = 5.3687e-01, time/batch = 0.6974s	
258/32150 (epoch 0.401), train_loss = 3.06026699, grad/param norm = 5.6248e-01, time/batch = 0.6894s	
259/32150 (epoch 0.403), train_loss = 2.95704918, grad/param norm = 5.3676e-01, time/batch = 0.6969s	
260/32150 (epoch 0.404), train_loss = 2.93221662, grad/param norm = 7.1553e-01, time/batch = 0.6932s	
261/32150 (epoch 0.406), train_loss = 3.01420780, grad/param norm = 1.0072e+00, time/batch = 0.6958s	
262/32150 (epoch 0.407), train_loss = 3.06817454, grad/param norm = 8.6493e-01, time/batch = 0.6920s	
263/32150 (epoch 0.409), train_loss = 2.95842190, grad/param norm = 6.4157e-01, time/batch = 0.6953s	
264/32150 (epoch 0.411), train_loss = 3.05798498, grad/param norm = 3.3928e-01, time/batch = 0.6969s	
265/32150 (epoch 0.412), train_loss = 3.09119467, grad/param norm = 3.4317e-01, time/batch = 0.6928s	
266/32150 (epoch 0.414), train_loss = 2.89178369, grad/param norm = 6.8718e-01, time/batch = 0.6901s	
267/32150 (epoch 0.415), train_loss = 2.94213830, grad/param norm = 6.8146e-01, time/batch = 0.6894s	
268/32150 (epoch 0.417), train_loss = 3.09961375, grad/param norm = 5.0456e-01, time/batch = 0.6803s	
269/32150 (epoch 0.418), train_loss = 2.93436628, grad/param norm = 6.1308e-01, time/batch = 0.6916s	
270/32150 (epoch 0.420), train_loss = 3.08722678, grad/param norm = 8.8477e-01, time/batch = 0.6936s	
271/32150 (epoch 0.421), train_loss = 3.10811954, grad/param norm = 9.9327e-01, time/batch = 0.6978s	
272/32150 (epoch 0.423), train_loss = 2.94622585, grad/param norm = 6.5542e-01, time/batch = 0.6983s	
273/32150 (epoch 0.425), train_loss = 2.88141673, grad/param norm = 3.5118e-01, time/batch = 0.7023s	
274/32150 (epoch 0.426), train_loss = 2.90219486, grad/param norm = 2.9608e-01, time/batch = 0.6825s	
275/32150 (epoch 0.428), train_loss = 2.95912061, grad/param norm = 3.4503e-01, time/batch = 0.6867s	
276/32150 (epoch 0.429), train_loss = 3.22186920, grad/param norm = 5.0425e-01, time/batch = 0.6943s	
277/32150 (epoch 0.431), train_loss = 3.01795602, grad/param norm = 5.6547e-01, time/batch = 0.6863s	
278/32150 (epoch 0.432), train_loss = 2.96422469, grad/param norm = 6.2391e-01, time/batch = 0.7024s	
279/32150 (epoch 0.434), train_loss = 2.98453645, grad/param norm = 7.6077e-01, time/batch = 0.6992s	
280/32150 (epoch 0.435), train_loss = 3.08010605, grad/param norm = 5.1867e-01, time/batch = 0.7049s	
281/32150 (epoch 0.437), train_loss = 2.93855946, grad/param norm = 4.4970e-01, time/batch = 0.7105s	
282/32150 (epoch 0.439), train_loss = 2.96424759, grad/param norm = 5.7441e-01, time/batch = 0.7010s	
283/32150 (epoch 0.440), train_loss = 2.81681348, grad/param norm = 5.9965e-01, time/batch = 0.6953s	
284/32150 (epoch 0.442), train_loss = 2.86446591, grad/param norm = 5.1784e-01, time/batch = 0.6969s	
285/32150 (epoch 0.443), train_loss = 2.76754327, grad/param norm = 3.6226e-01, time/batch = 0.6938s	
286/32150 (epoch 0.445), train_loss = 2.97268844, grad/param norm = 5.5937e-01, time/batch = 0.6924s	
287/32150 (epoch 0.446), train_loss = 2.84854676, grad/param norm = 8.5328e-01, time/batch = 0.7051s	
288/32150 (epoch 0.448), train_loss = 2.89523647, grad/param norm = 7.1372e-01, time/batch = 0.6955s	
289/32150 (epoch 0.449), train_loss = 2.80624089, grad/param norm = 4.6183e-01, time/batch = 0.6880s	
290/32150 (epoch 0.451), train_loss = 3.03200435, grad/param norm = 6.3058e-01, time/batch = 0.6835s	
291/32150 (epoch 0.453), train_loss = 2.98429146, grad/param norm = 8.6049e-01, time/batch = 0.6964s	
292/32150 (epoch 0.454), train_loss = 2.95685353, grad/param norm = 8.2752e-01, time/batch = 0.6868s	
293/32150 (epoch 0.456), train_loss = 2.86209869, grad/param norm = 5.4981e-01, time/batch = 0.6912s	
294/32150 (epoch 0.457), train_loss = 2.84318505, grad/param norm = 3.1410e-01, time/batch = 0.6918s	
295/32150 (epoch 0.459), train_loss = 2.85192715, grad/param norm = 4.4121e-01, time/batch = 0.6996s	
296/32150 (epoch 0.460), train_loss = 2.92372656, grad/param norm = 5.9348e-01, time/batch = 0.6918s	
297/32150 (epoch 0.462), train_loss = 2.98453207, grad/param norm = 6.1836e-01, time/batch = 0.6941s	
298/32150 (epoch 0.463), train_loss = 2.87651024, grad/param norm = 6.3534e-01, time/batch = 0.6911s	
299/32150 (epoch 0.465), train_loss = 2.82313898, grad/param norm = 6.8341e-01, time/batch = 0.6904s	
300/32150 (epoch 0.467), train_loss = 2.80705974, grad/param norm = 6.2169e-01, time/batch = 0.6969s	
301/32150 (epoch 0.468), train_loss = 2.91526110, grad/param norm = 6.3175e-01, time/batch = 0.7023s	
302/32150 (epoch 0.470), train_loss = 2.97231741, grad/param norm = 5.8417e-01, time/batch = 0.7006s	
303/32150 (epoch 0.471), train_loss = 2.93796327, grad/param norm = 4.1258e-01, time/batch = 0.6856s	
304/32150 (epoch 0.473), train_loss = 2.95803012, grad/param norm = 4.7213e-01, time/batch = 0.7040s	
305/32150 (epoch 0.474), train_loss = 2.83258393, grad/param norm = 6.4219e-01, time/batch = 0.7036s	
306/32150 (epoch 0.476), train_loss = 2.87717031, grad/param norm = 5.1134e-01, time/batch = 0.6946s	
307/32150 (epoch 0.477), train_loss = 3.00767484, grad/param norm = 8.1626e-01, time/batch = 0.7051s	
308/32150 (epoch 0.479), train_loss = 2.99835830, grad/param norm = 8.5594e-01, time/batch = 0.6996s	
309/32150 (epoch 0.481), train_loss = 3.04129341, grad/param norm = 6.5086e-01, time/batch = 0.6886s	
310/32150 (epoch 0.482), train_loss = 2.92687345, grad/param norm = 3.4385e-01, time/batch = 0.6835s	
311/32150 (epoch 0.484), train_loss = 2.78797671, grad/param norm = 2.8128e-01, time/batch = 0.6949s	
312/32150 (epoch 0.485), train_loss = 2.93434379, grad/param norm = 2.9120e-01, time/batch = 0.6956s	
313/32150 (epoch 0.487), train_loss = 2.90129942, grad/param norm = 6.1269e-01, time/batch = 0.7014s	
314/32150 (epoch 0.488), train_loss = 2.89786480, grad/param norm = 7.0916e-01, time/batch = 0.6860s	
315/32150 (epoch 0.490), train_loss = 2.85265901, grad/param norm = 7.0246e-01, time/batch = 0.6899s	
316/32150 (epoch 0.491), train_loss = 2.80127750, grad/param norm = 5.9919e-01, time/batch = 0.7030s	
317/32150 (epoch 0.493), train_loss = 3.08031029, grad/param norm = 6.3745e-01, time/batch = 0.7085s	
318/32150 (epoch 0.495), train_loss = 2.84018328, grad/param norm = 6.4457e-01, time/batch = 0.7300s	
319/32150 (epoch 0.496), train_loss = 2.88224248, grad/param norm = 4.1136e-01, time/batch = 0.7190s	
320/32150 (epoch 0.498), train_loss = 2.91590035, grad/param norm = 4.8260e-01, time/batch = 0.7059s	
321/32150 (epoch 0.499), train_loss = 2.90245011, grad/param norm = 6.5225e-01, time/batch = 0.7109s	
322/32150 (epoch 0.501), train_loss = 2.83805386, grad/param norm = 5.6588e-01, time/batch = 0.7028s	
323/32150 (epoch 0.502), train_loss = 2.87433636, grad/param norm = 3.9144e-01, time/batch = 0.7080s	
324/32150 (epoch 0.504), train_loss = 2.78587274, grad/param norm = 4.4763e-01, time/batch = 0.7050s	
325/32150 (epoch 0.505), train_loss = 2.74697825, grad/param norm = 3.6476e-01, time/batch = 0.7025s	
326/32150 (epoch 0.507), train_loss = 2.71510410, grad/param norm = 3.0236e-01, time/batch = 0.7194s	
327/32150 (epoch 0.509), train_loss = 2.80475752, grad/param norm = 3.6007e-01, time/batch = 0.7081s	
328/32150 (epoch 0.510), train_loss = 2.85774128, grad/param norm = 3.6732e-01, time/batch = 0.7025s	
329/32150 (epoch 0.512), train_loss = 2.82329809, grad/param norm = 3.9109e-01, time/batch = 0.7035s	
330/32150 (epoch 0.513), train_loss = 2.86440515, grad/param norm = 3.4247e-01, time/batch = 0.7078s	
331/32150 (epoch 0.515), train_loss = 2.96414689, grad/param norm = 3.3543e-01, time/batch = 0.7104s	
332/32150 (epoch 0.516), train_loss = 2.96788699, grad/param norm = 5.2790e-01, time/batch = 0.7101s	
333/32150 (epoch 0.518), train_loss = 2.94893869, grad/param norm = 1.3135e+00, time/batch = 0.7025s	
334/32150 (epoch 0.519), train_loss = 3.12132438, grad/param norm = 1.4045e+00, time/batch = 0.6990s	
335/32150 (epoch 0.521), train_loss = 3.02211792, grad/param norm = 1.0830e+00, time/batch = 0.7021s	
336/32150 (epoch 0.523), train_loss = 2.82795342, grad/param norm = 7.3000e-01, time/batch = 0.6892s	
337/32150 (epoch 0.524), train_loss = 2.88968076, grad/param norm = 4.5424e-01, time/batch = 0.7030s	
338/32150 (epoch 0.526), train_loss = 2.92276293, grad/param norm = 4.5172e-01, time/batch = 0.6962s	
339/32150 (epoch 0.527), train_loss = 3.05695955, grad/param norm = 4.7846e-01, time/batch = 0.6875s	
340/32150 (epoch 0.529), train_loss = 2.89088745, grad/param norm = 3.4868e-01, time/batch = 0.6893s	
341/32150 (epoch 0.530), train_loss = 2.91199520, grad/param norm = 5.0516e-01, time/batch = 0.7003s	
342/32150 (epoch 0.532), train_loss = 2.73954397, grad/param norm = 5.3932e-01, time/batch = 0.7058s	
343/32150 (epoch 0.533), train_loss = 2.93068038, grad/param norm = 7.2468e-01, time/batch = 0.6927s	
344/32150 (epoch 0.535), train_loss = 2.90745159, grad/param norm = 6.5207e-01, time/batch = 0.6995s	
345/32150 (epoch 0.537), train_loss = 2.81635877, grad/param norm = 2.8527e-01, time/batch = 0.7133s	
346/32150 (epoch 0.538), train_loss = 2.78166975, grad/param norm = 3.5218e-01, time/batch = 0.6909s	
347/32150 (epoch 0.540), train_loss = 2.98524909, grad/param norm = 6.0992e-01, time/batch = 0.6860s	
348/32150 (epoch 0.541), train_loss = 2.93423981, grad/param norm = 4.6872e-01, time/batch = 0.6864s	
349/32150 (epoch 0.543), train_loss = 2.87122792, grad/param norm = 4.5555e-01, time/batch = 0.6839s	
350/32150 (epoch 0.544), train_loss = 3.02073386, grad/param norm = 4.5599e-01, time/batch = 0.6820s	
351/32150 (epoch 0.546), train_loss = 2.76621484, grad/param norm = 3.9095e-01, time/batch = 0.6905s	
352/32150 (epoch 0.547), train_loss = 2.91095839, grad/param norm = 4.4398e-01, time/batch = 0.6891s	
353/32150 (epoch 0.549), train_loss = 2.83332993, grad/param norm = 4.7324e-01, time/batch = 0.6918s	
354/32150 (epoch 0.551), train_loss = 2.91807303, grad/param norm = 3.5428e-01, time/batch = 0.6829s	
355/32150 (epoch 0.552), train_loss = 2.76290970, grad/param norm = 2.9804e-01, time/batch = 0.7021s	
356/32150 (epoch 0.554), train_loss = 2.96626075, grad/param norm = 4.8857e-01, time/batch = 0.6961s	
357/32150 (epoch 0.555), train_loss = 2.83459288, grad/param norm = 5.5416e-01, time/batch = 0.6958s	
358/32150 (epoch 0.557), train_loss = 2.78683018, grad/param norm = 6.9293e-01, time/batch = 0.6983s	
359/32150 (epoch 0.558), train_loss = 2.82806384, grad/param norm = 8.2554e-01, time/batch = 0.6881s	
360/32150 (epoch 0.560), train_loss = 2.86904857, grad/param norm = 4.5892e-01, time/batch = 0.6897s	
361/32150 (epoch 0.561), train_loss = 2.82207659, grad/param norm = 2.6636e-01, time/batch = 0.7033s	
362/32150 (epoch 0.563), train_loss = 2.81625090, grad/param norm = 3.8648e-01, time/batch = 0.7016s	
363/32150 (epoch 0.565), train_loss = 2.73537220, grad/param norm = 5.3559e-01, time/batch = 0.7019s	
364/32150 (epoch 0.566), train_loss = 2.93253852, grad/param norm = 4.8153e-01, time/batch = 0.6958s	
365/32150 (epoch 0.568), train_loss = 2.72672667, grad/param norm = 3.3238e-01, time/batch = 0.6888s	
366/32150 (epoch 0.569), train_loss = 2.79735821, grad/param norm = 3.3246e-01, time/batch = 0.6866s	
367/32150 (epoch 0.571), train_loss = 2.88080874, grad/param norm = 3.1658e-01, time/batch = 0.6870s	
368/32150 (epoch 0.572), train_loss = 2.79420227, grad/param norm = 3.7763e-01, time/batch = 0.6901s	
369/32150 (epoch 0.574), train_loss = 2.79395339, grad/param norm = 4.9017e-01, time/batch = 0.6853s	
370/32150 (epoch 0.575), train_loss = 2.86492407, grad/param norm = 5.9123e-01, time/batch = 0.6895s	
371/32150 (epoch 0.577), train_loss = 2.79805120, grad/param norm = 5.7273e-01, time/batch = 0.6854s	
372/32150 (epoch 0.579), train_loss = 2.89665656, grad/param norm = 6.1648e-01, time/batch = 0.6858s	
373/32150 (epoch 0.580), train_loss = 2.90103626, grad/param norm = 5.3527e-01, time/batch = 0.6824s	
374/32150 (epoch 0.582), train_loss = 2.90882012, grad/param norm = 5.0355e-01, time/batch = 0.6849s	
375/32150 (epoch 0.583), train_loss = 2.80921759, grad/param norm = 4.9073e-01, time/batch = 0.6859s	
376/32150 (epoch 0.585), train_loss = 2.81040352, grad/param norm = 5.0275e-01, time/batch = 0.6839s	
377/32150 (epoch 0.586), train_loss = 2.87141751, grad/param norm = 4.8280e-01, time/batch = 0.6876s	
378/32150 (epoch 0.588), train_loss = 2.74785162, grad/param norm = 3.8719e-01, time/batch = 0.6877s	
379/32150 (epoch 0.589), train_loss = 2.73335655, grad/param norm = 3.7619e-01, time/batch = 0.6855s	
380/32150 (epoch 0.591), train_loss = 2.97775843, grad/param norm = 3.1690e-01, time/batch = 0.6893s	
381/32150 (epoch 0.593), train_loss = 2.74619767, grad/param norm = 3.3491e-01, time/batch = 0.6849s	
382/32150 (epoch 0.594), train_loss = 2.74627932, grad/param norm = 3.2264e-01, time/batch = 0.6851s	
383/32150 (epoch 0.596), train_loss = 2.86157707, grad/param norm = 3.9176e-01, time/batch = 0.6857s	
384/32150 (epoch 0.597), train_loss = 2.83145375, grad/param norm = 3.4362e-01, time/batch = 0.6892s	
385/32150 (epoch 0.599), train_loss = 2.81036147, grad/param norm = 3.7362e-01, time/batch = 0.6956s	
386/32150 (epoch 0.600), train_loss = 2.80241607, grad/param norm = 2.9633e-01, time/batch = 0.6947s	
387/32150 (epoch 0.602), train_loss = 2.90098456, grad/param norm = 4.2644e-01, time/batch = 0.6880s	
388/32150 (epoch 0.603), train_loss = 2.75154938, grad/param norm = 6.1348e-01, time/batch = 0.6866s	
389/32150 (epoch 0.605), train_loss = 2.94090542, grad/param norm = 7.2675e-01, time/batch = 0.6870s	
390/32150 (epoch 0.607), train_loss = 2.97846785, grad/param norm = 6.7842e-01, time/batch = 0.6829s	
391/32150 (epoch 0.608), train_loss = 2.70427842, grad/param norm = 4.4315e-01, time/batch = 0.6851s	
392/32150 (epoch 0.610), train_loss = 2.83918684, grad/param norm = 4.3188e-01, time/batch = 0.6842s	
393/32150 (epoch 0.611), train_loss = 2.70736165, grad/param norm = 7.0335e-01, time/batch = 0.6870s	
394/32150 (epoch 0.613), train_loss = 2.84102546, grad/param norm = 7.9582e-01, time/batch = 0.6885s	
395/32150 (epoch 0.614), train_loss = 2.80282294, grad/param norm = 5.8560e-01, time/batch = 0.6853s	
396/32150 (epoch 0.616), train_loss = 2.92274129, grad/param norm = 4.6654e-01, time/batch = 0.6864s	
397/32150 (epoch 0.617), train_loss = 2.75886925, grad/param norm = 5.6279e-01, time/batch = 0.6898s	
398/32150 (epoch 0.619), train_loss = 2.73183772, grad/param norm = 6.5265e-01, time/batch = 0.6902s	
399/32150 (epoch 0.621), train_loss = 2.78618961, grad/param norm = 5.6166e-01, time/batch = 0.6934s	
400/32150 (epoch 0.622), train_loss = 2.65966265, grad/param norm = 5.4993e-01, time/batch = 0.6937s	
401/32150 (epoch 0.624), train_loss = 2.82577794, grad/param norm = 5.0360e-01, time/batch = 0.6943s	
402/32150 (epoch 0.625), train_loss = 2.76607323, grad/param norm = 5.8704e-01, time/batch = 0.6930s	
403/32150 (epoch 0.627), train_loss = 2.74702769, grad/param norm = 4.5698e-01, time/batch = 0.6940s	
404/32150 (epoch 0.628), train_loss = 2.78411379, grad/param norm = 3.2744e-01, time/batch = 0.6887s	
405/32150 (epoch 0.630), train_loss = 2.70825390, grad/param norm = 3.0395e-01, time/batch = 0.6845s	
406/32150 (epoch 0.631), train_loss = 2.80195752, grad/param norm = 2.7002e-01, time/batch = 0.6840s	
407/32150 (epoch 0.633), train_loss = 2.66071669, grad/param norm = 3.1533e-01, time/batch = 0.7036s	
408/32150 (epoch 0.635), train_loss = 2.78369515, grad/param norm = 3.5724e-01, time/batch = 0.6962s	
409/32150 (epoch 0.636), train_loss = 2.83986848, grad/param norm = 3.9040e-01, time/batch = 0.7129s	
410/32150 (epoch 0.638), train_loss = 2.79612746, grad/param norm = 5.7350e-01, time/batch = 0.7093s	
411/32150 (epoch 0.639), train_loss = 2.89081582, grad/param norm = 7.6440e-01, time/batch = 0.7095s	
412/32150 (epoch 0.641), train_loss = 2.84963256, grad/param norm = 8.0431e-01, time/batch = 0.7004s	
413/32150 (epoch 0.642), train_loss = 2.79486106, grad/param norm = 4.5877e-01, time/batch = 0.7219s	
414/32150 (epoch 0.644), train_loss = 2.74282951, grad/param norm = 3.9116e-01, time/batch = 0.7018s	
415/32150 (epoch 0.645), train_loss = 2.83840771, grad/param norm = 2.7555e-01, time/batch = 0.6920s	
416/32150 (epoch 0.647), train_loss = 2.82041847, grad/param norm = 3.1582e-01, time/batch = 0.6830s	
417/32150 (epoch 0.649), train_loss = 2.62361481, grad/param norm = 3.4684e-01, time/batch = 0.6905s	
418/32150 (epoch 0.650), train_loss = 2.84486373, grad/param norm = 6.9301e-01, time/batch = 0.7111s	
419/32150 (epoch 0.652), train_loss = 2.86722029, grad/param norm = 7.7654e-01, time/batch = 0.6902s	
420/32150 (epoch 0.653), train_loss = 2.81069589, grad/param norm = 4.4587e-01, time/batch = 0.6973s	
421/32150 (epoch 0.655), train_loss = 3.12485478, grad/param norm = 5.0419e-01, time/batch = 0.6931s	
422/32150 (epoch 0.656), train_loss = 3.09333119, grad/param norm = 6.7978e-01, time/batch = 0.6841s	
423/32150 (epoch 0.658), train_loss = 2.92158176, grad/param norm = 5.7359e-01, time/batch = 0.6879s	
424/32150 (epoch 0.659), train_loss = 3.13722252, grad/param norm = 6.5246e-01, time/batch = 0.6903s	
425/32150 (epoch 0.661), train_loss = 2.81349300, grad/param norm = 5.0739e-01, time/batch = 0.6824s	
426/32150 (epoch 0.663), train_loss = 2.69342606, grad/param norm = 4.5979e-01, time/batch = 0.6856s	
427/32150 (epoch 0.664), train_loss = 2.66450838, grad/param norm = 5.6548e-01, time/batch = 0.6835s	
428/32150 (epoch 0.666), train_loss = 2.91152391, grad/param norm = 3.9265e-01, time/batch = 0.6863s	
429/32150 (epoch 0.667), train_loss = 2.84734787, grad/param norm = 2.7894e-01, time/batch = 0.6766s	
430/32150 (epoch 0.669), train_loss = 2.79514885, grad/param norm = 4.1008e-01, time/batch = 0.6875s	
431/32150 (epoch 0.670), train_loss = 2.77080906, grad/param norm = 4.4403e-01, time/batch = 0.7016s	
432/32150 (epoch 0.672), train_loss = 2.82920580, grad/param norm = 4.0162e-01, time/batch = 0.6860s	
433/32150 (epoch 0.673), train_loss = 2.81799283, grad/param norm = 4.1751e-01, time/batch = 0.6863s	
434/32150 (epoch 0.675), train_loss = 2.81180672, grad/param norm = 2.9767e-01, time/batch = 0.6863s	
435/32150 (epoch 0.677), train_loss = 2.81405872, grad/param norm = 3.9914e-01, time/batch = 0.6830s	
436/32150 (epoch 0.678), train_loss = 2.82254233, grad/param norm = 4.6245e-01, time/batch = 0.6836s	
437/32150 (epoch 0.680), train_loss = 2.81221424, grad/param norm = 4.1253e-01, time/batch = 0.6820s	
438/32150 (epoch 0.681), train_loss = 2.71332412, grad/param norm = 4.6998e-01, time/batch = 0.6824s	
439/32150 (epoch 0.683), train_loss = 2.79478131, grad/param norm = 3.6366e-01, time/batch = 0.6832s	
440/32150 (epoch 0.684), train_loss = 2.84797364, grad/param norm = 2.6201e-01, time/batch = 0.6824s	
441/32150 (epoch 0.686), train_loss = 2.73372668, grad/param norm = 3.2547e-01, time/batch = 0.6856s	
442/32150 (epoch 0.687), train_loss = 2.72576502, grad/param norm = 2.8350e-01, time/batch = 0.6879s	
443/32150 (epoch 0.689), train_loss = 2.69822884, grad/param norm = 3.0228e-01, time/batch = 0.6899s	
444/32150 (epoch 0.691), train_loss = 2.59694598, grad/param norm = 3.0590e-01, time/batch = 0.6854s	
445/32150 (epoch 0.692), train_loss = 2.70769102, grad/param norm = 4.8796e-01, time/batch = 0.6866s	
446/32150 (epoch 0.694), train_loss = 2.70429710, grad/param norm = 6.4325e-01, time/batch = 0.6910s	
447/32150 (epoch 0.695), train_loss = 2.73115369, grad/param norm = 6.2772e-01, time/batch = 0.6875s	
448/32150 (epoch 0.697), train_loss = 2.72086698, grad/param norm = 6.1530e-01, time/batch = 0.6782s	
449/32150 (epoch 0.698), train_loss = 2.76746382, grad/param norm = 5.4024e-01, time/batch = 0.6780s	
450/32150 (epoch 0.700), train_loss = 2.71590368, grad/param norm = 4.9960e-01, time/batch = 0.6784s	
451/32150 (epoch 0.701), train_loss = 2.71717261, grad/param norm = 4.4254e-01, time/batch = 0.6913s	
452/32150 (epoch 0.703), train_loss = 2.80058664, grad/param norm = 3.6317e-01, time/batch = 0.6829s	
453/32150 (epoch 0.705), train_loss = 2.77391124, grad/param norm = 3.1833e-01, time/batch = 0.6830s	
454/32150 (epoch 0.706), train_loss = 2.78454927, grad/param norm = 3.3239e-01, time/batch = 0.6959s	
455/32150 (epoch 0.708), train_loss = 2.91304901, grad/param norm = 3.5063e-01, time/batch = 0.6859s	
456/32150 (epoch 0.709), train_loss = 2.74187338, grad/param norm = 2.7481e-01, time/batch = 0.6887s	
457/32150 (epoch 0.711), train_loss = 2.67754282, grad/param norm = 3.5234e-01, time/batch = 0.6826s	
458/32150 (epoch 0.712), train_loss = 2.86109510, grad/param norm = 3.9652e-01, time/batch = 0.6855s	
459/32150 (epoch 0.714), train_loss = 2.76608799, grad/param norm = 5.2200e-01, time/batch = 0.6904s	
460/32150 (epoch 0.715), train_loss = 2.73482367, grad/param norm = 4.5785e-01, time/batch = 0.6904s	
461/32150 (epoch 0.717), train_loss = 2.82237427, grad/param norm = 4.8681e-01, time/batch = 0.6924s	
462/32150 (epoch 0.719), train_loss = 2.73485865, grad/param norm = 4.9631e-01, time/batch = 0.6896s	
463/32150 (epoch 0.720), train_loss = 2.74692634, grad/param norm = 4.7541e-01, time/batch = 0.6882s	
464/32150 (epoch 0.722), train_loss = 2.65539974, grad/param norm = 5.4865e-01, time/batch = 0.6902s	
465/32150 (epoch 0.723), train_loss = 2.72929594, grad/param norm = 4.1891e-01, time/batch = 0.6893s	
466/32150 (epoch 0.725), train_loss = 2.65266557, grad/param norm = 3.3680e-01, time/batch = 0.6902s	
467/32150 (epoch 0.726), train_loss = 2.68753377, grad/param norm = 3.2028e-01, time/batch = 0.6901s	
468/32150 (epoch 0.728), train_loss = 2.69669597, grad/param norm = 4.1601e-01, time/batch = 0.6898s	
469/32150 (epoch 0.729), train_loss = 2.73786768, grad/param norm = 5.9840e-01, time/batch = 0.6926s	
470/32150 (epoch 0.731), train_loss = 2.78233175, grad/param norm = 7.0918e-01, time/batch = 0.6890s	
471/32150 (epoch 0.733), train_loss = 2.76915790, grad/param norm = 5.8745e-01, time/batch = 0.6986s	
472/32150 (epoch 0.734), train_loss = 2.74837430, grad/param norm = 4.5858e-01, time/batch = 0.6915s	
473/32150 (epoch 0.736), train_loss = 2.60808258, grad/param norm = 3.7685e-01, time/batch = 0.6972s	
474/32150 (epoch 0.737), train_loss = 2.67819932, grad/param norm = 4.0936e-01, time/batch = 0.7002s	
475/32150 (epoch 0.739), train_loss = 2.69479808, grad/param norm = 4.1438e-01, time/batch = 0.6858s	
476/32150 (epoch 0.740), train_loss = 2.52466114, grad/param norm = 3.2547e-01, time/batch = 0.6900s	
477/32150 (epoch 0.742), train_loss = 2.59329817, grad/param norm = 3.0721e-01, time/batch = 0.6931s	
478/32150 (epoch 0.743), train_loss = 2.69364839, grad/param norm = 4.8676e-01, time/batch = 0.6920s	
479/32150 (epoch 0.745), train_loss = 2.63046929, grad/param norm = 4.3461e-01, time/batch = 0.6988s	
480/32150 (epoch 0.747), train_loss = 2.74519844, grad/param norm = 2.9926e-01, time/batch = 0.6965s	
481/32150 (epoch 0.748), train_loss = 2.83798879, grad/param norm = 2.9638e-01, time/batch = 0.6969s	
482/32150 (epoch 0.750), train_loss = 2.72633962, grad/param norm = 3.0094e-01, time/batch = 0.6879s	
483/32150 (epoch 0.751), train_loss = 2.62331014, grad/param norm = 3.4052e-01, time/batch = 0.6877s	
484/32150 (epoch 0.753), train_loss = 2.67410828, grad/param norm = 3.8341e-01, time/batch = 0.6850s	
485/32150 (epoch 0.754), train_loss = 2.71760683, grad/param norm = 3.8130e-01, time/batch = 0.6874s	
486/32150 (epoch 0.756), train_loss = 2.55072311, grad/param norm = 3.8910e-01, time/batch = 0.6928s	
487/32150 (epoch 0.757), train_loss = 2.76287572, grad/param norm = 3.6254e-01, time/batch = 0.6934s	
488/32150 (epoch 0.759), train_loss = 2.77063337, grad/param norm = 3.4641e-01, time/batch = 0.6922s	
489/32150 (epoch 0.760), train_loss = 2.63434872, grad/param norm = 4.0643e-01, time/batch = 0.6914s	
490/32150 (epoch 0.762), train_loss = 2.72321913, grad/param norm = 7.1031e-01, time/batch = 0.6929s	
491/32150 (epoch 0.764), train_loss = 2.85599473, grad/param norm = 6.2329e-01, time/batch = 0.6905s	
492/32150 (epoch 0.765), train_loss = 2.60047063, grad/param norm = 3.5268e-01, time/batch = 0.6903s	
493/32150 (epoch 0.767), train_loss = 2.72596957, grad/param norm = 4.5202e-01, time/batch = 0.6909s	
494/32150 (epoch 0.768), train_loss = 2.70749807, grad/param norm = 4.9698e-01, time/batch = 0.6873s	
495/32150 (epoch 0.770), train_loss = 2.71250101, grad/param norm = 4.4487e-01, time/batch = 0.6908s	
496/32150 (epoch 0.771), train_loss = 2.98401951, grad/param norm = 4.1147e-01, time/batch = 0.6923s	
497/32150 (epoch 0.773), train_loss = 2.83145180, grad/param norm = 4.0438e-01, time/batch = 0.6954s	
498/32150 (epoch 0.774), train_loss = 2.67396899, grad/param norm = 2.8779e-01, time/batch = 0.6982s	
499/32150 (epoch 0.776), train_loss = 2.77809324, grad/param norm = 2.9798e-01, time/batch = 0.6864s	
500/32150 (epoch 0.778), train_loss = 2.55187944, grad/param norm = 3.0155e-01, time/batch = 0.6905s	
501/32150 (epoch 0.779), train_loss = 2.77351514, grad/param norm = 4.2457e-01, time/batch = 0.6941s	
502/32150 (epoch 0.781), train_loss = 2.86330961, grad/param norm = 4.3947e-01, time/batch = 0.6988s	
503/32150 (epoch 0.782), train_loss = 2.75132731, grad/param norm = 4.5722e-01, time/batch = 0.6952s	
504/32150 (epoch 0.784), train_loss = 2.86651285, grad/param norm = 5.1770e-01, time/batch = 0.7021s	
505/32150 (epoch 0.785), train_loss = 2.63150342, grad/param norm = 3.3624e-01, time/batch = 0.7030s	
506/32150 (epoch 0.787), train_loss = 2.66640311, grad/param norm = 3.1639e-01, time/batch = 0.7093s	
507/32150 (epoch 0.788), train_loss = 2.70133320, grad/param norm = 3.5824e-01, time/batch = 0.6965s	
508/32150 (epoch 0.790), train_loss = 2.71171146, grad/param norm = 2.8414e-01, time/batch = 0.6920s	
509/32150 (epoch 0.792), train_loss = 2.64917548, grad/param norm = 3.0096e-01, time/batch = 0.6931s	
510/32150 (epoch 0.793), train_loss = 2.68655237, grad/param norm = 3.1703e-01, time/batch = 0.6975s	
511/32150 (epoch 0.795), train_loss = 2.63514022, grad/param norm = 3.9647e-01, time/batch = 0.6929s	
512/32150 (epoch 0.796), train_loss = 2.68919897, grad/param norm = 3.5344e-01, time/batch = 0.6932s	
513/32150 (epoch 0.798), train_loss = 2.55308074, grad/param norm = 3.7043e-01, time/batch = 0.6872s	
514/32150 (epoch 0.799), train_loss = 2.64198704, grad/param norm = 3.8741e-01, time/batch = 0.6930s	
515/32150 (epoch 0.801), train_loss = 2.78669498, grad/param norm = 3.2403e-01, time/batch = 0.6957s	
516/32150 (epoch 0.802), train_loss = 2.67556599, grad/param norm = 3.3826e-01, time/batch = 0.6940s	
517/32150 (epoch 0.804), train_loss = 2.76769148, grad/param norm = 3.0702e-01, time/batch = 0.6894s	
518/32150 (epoch 0.806), train_loss = 2.77137384, grad/param norm = 3.6174e-01, time/batch = 0.6950s	
519/32150 (epoch 0.807), train_loss = 2.81562977, grad/param norm = 5.3258e-01, time/batch = 0.6834s	
520/32150 (epoch 0.809), train_loss = 2.74962065, grad/param norm = 7.3719e-01, time/batch = 0.6819s	
521/32150 (epoch 0.810), train_loss = 2.72786325, grad/param norm = 5.3403e-01, time/batch = 0.6840s	
522/32150 (epoch 0.812), train_loss = 2.62413733, grad/param norm = 3.4283e-01, time/batch = 0.6913s	
523/32150 (epoch 0.813), train_loss = 2.67500741, grad/param norm = 3.1740e-01, time/batch = 0.6945s	
524/32150 (epoch 0.815), train_loss = 2.55940187, grad/param norm = 3.9197e-01, time/batch = 0.6906s	
525/32150 (epoch 0.816), train_loss = 2.52886175, grad/param norm = 3.6223e-01, time/batch = 0.6957s	
526/32150 (epoch 0.818), train_loss = 2.48730523, grad/param norm = 2.9811e-01, time/batch = 0.6905s	
527/32150 (epoch 0.820), train_loss = 2.64046768, grad/param norm = 3.3785e-01, time/batch = 0.6882s	
528/32150 (epoch 0.821), train_loss = 2.74665627, grad/param norm = 3.4655e-01, time/batch = 0.6928s	
529/32150 (epoch 0.823), train_loss = 2.64501626, grad/param norm = 4.4870e-01, time/batch = 0.6956s	
530/32150 (epoch 0.824), train_loss = 2.77885710, grad/param norm = 4.3475e-01, time/batch = 0.6975s	
531/32150 (epoch 0.826), train_loss = 2.60260047, grad/param norm = 5.3976e-01, time/batch = 0.6948s	
532/32150 (epoch 0.827), train_loss = 2.87139877, grad/param norm = 6.0896e-01, time/batch = 0.6935s	
533/32150 (epoch 0.829), train_loss = 2.72267837, grad/param norm = 5.2858e-01, time/batch = 0.6918s	
534/32150 (epoch 0.830), train_loss = 2.61002960, grad/param norm = 4.1601e-01, time/batch = 0.6952s	
535/32150 (epoch 0.832), train_loss = 2.61944242, grad/param norm = 2.9624e-01, time/batch = 0.6847s	
536/32150 (epoch 0.834), train_loss = 2.75310847, grad/param norm = 3.1873e-01, time/batch = 0.6944s	
537/32150 (epoch 0.835), train_loss = 2.69876512, grad/param norm = 2.9011e-01, time/batch = 0.6822s	
538/32150 (epoch 0.837), train_loss = 2.70605988, grad/param norm = 2.7304e-01, time/batch = 0.6838s	
539/32150 (epoch 0.838), train_loss = 2.77124088, grad/param norm = 3.0310e-01, time/batch = 0.6856s	
540/32150 (epoch 0.840), train_loss = 2.58413865, grad/param norm = 3.1297e-01, time/batch = 0.6808s	
541/32150 (epoch 0.841), train_loss = 2.61328106, grad/param norm = 3.0446e-01, time/batch = 0.6896s	
542/32150 (epoch 0.843), train_loss = 2.64635739, grad/param norm = 3.5764e-01, time/batch = 0.6869s	
543/32150 (epoch 0.844), train_loss = 2.57892123, grad/param norm = 3.8379e-01, time/batch = 0.6853s	
544/32150 (epoch 0.846), train_loss = 2.49635638, grad/param norm = 3.7799e-01, time/batch = 0.6857s	
545/32150 (epoch 0.848), train_loss = 2.77315306, grad/param norm = 5.3842e-01, time/batch = 0.6830s	
546/32150 (epoch 0.849), train_loss = 2.86990389, grad/param norm = 1.0079e+00, time/batch = 0.6820s	
547/32150 (epoch 0.851), train_loss = 2.79564664, grad/param norm = 7.2466e-01, time/batch = 0.6853s	
548/32150 (epoch 0.852), train_loss = 3.01931409, grad/param norm = 7.5557e-01, time/batch = 0.6962s	
549/32150 (epoch 0.854), train_loss = 2.92623315, grad/param norm = 6.2102e-01, time/batch = 0.6956s	
550/32150 (epoch 0.855), train_loss = 2.92825837, grad/param norm = 3.7938e-01, time/batch = 0.6887s	
551/32150 (epoch 0.857), train_loss = 2.77453101, grad/param norm = 3.0895e-01, time/batch = 0.6979s	
552/32150 (epoch 0.858), train_loss = 2.95945150, grad/param norm = 2.9822e-01, time/batch = 0.7055s	
553/32150 (epoch 0.860), train_loss = 2.81559823, grad/param norm = 2.7943e-01, time/batch = 0.6942s	
554/32150 (epoch 0.862), train_loss = 2.85681511, grad/param norm = 3.7738e-01, time/batch = 0.6923s	
555/32150 (epoch 0.863), train_loss = 2.64995184, grad/param norm = 3.4620e-01, time/batch = 0.6948s	
556/32150 (epoch 0.865), train_loss = 2.55886159, grad/param norm = 3.2272e-01, time/batch = 0.6910s	
557/32150 (epoch 0.866), train_loss = 2.58232202, grad/param norm = 2.5445e-01, time/batch = 0.7027s	
558/32150 (epoch 0.868), train_loss = 2.70326102, grad/param norm = 3.8908e-01, time/batch = 0.7000s	
559/32150 (epoch 0.869), train_loss = 2.60378143, grad/param norm = 5.7856e-01, time/batch = 0.7013s	
560/32150 (epoch 0.871), train_loss = 2.60204679, grad/param norm = 5.3307e-01, time/batch = 0.6889s	
561/32150 (epoch 0.872), train_loss = 2.84171627, grad/param norm = 4.3486e-01, time/batch = 0.6911s	
562/32150 (epoch 0.874), train_loss = 2.58764039, grad/param norm = 3.5200e-01, time/batch = 0.6923s	
563/32150 (epoch 0.876), train_loss = 2.52577924, grad/param norm = 2.7736e-01, time/batch = 0.6946s	
564/32150 (epoch 0.877), train_loss = 2.59230388, grad/param norm = 3.8049e-01, time/batch = 0.6856s	
565/32150 (epoch 0.879), train_loss = 2.67299499, grad/param norm = 3.4199e-01, time/batch = 0.6912s	
566/32150 (epoch 0.880), train_loss = 2.65797508, grad/param norm = 2.9151e-01, time/batch = 0.6938s	
567/32150 (epoch 0.882), train_loss = 2.64813711, grad/param norm = 2.5175e-01, time/batch = 0.6907s	
568/32150 (epoch 0.883), train_loss = 2.83114439, grad/param norm = 3.6245e-01, time/batch = 0.6896s	
569/32150 (epoch 0.885), train_loss = 2.64214443, grad/param norm = 4.8819e-01, time/batch = 0.6895s	
570/32150 (epoch 0.886), train_loss = 2.69056849, grad/param norm = 5.0582e-01, time/batch = 0.6923s	
571/32150 (epoch 0.888), train_loss = 2.60926961, grad/param norm = 3.0982e-01, time/batch = 0.6805s	
572/32150 (epoch 0.890), train_loss = 2.74494477, grad/param norm = 2.8617e-01, time/batch = 0.6972s	
573/32150 (epoch 0.891), train_loss = 2.73320394, grad/param norm = 3.1303e-01, time/batch = 0.6882s	
574/32150 (epoch 0.893), train_loss = 2.60333585, grad/param norm = 2.3283e-01, time/batch = 0.6901s	
575/32150 (epoch 0.894), train_loss = 2.53457213, grad/param norm = 2.7679e-01, time/batch = 0.6906s	
576/32150 (epoch 0.896), train_loss = 2.64180876, grad/param norm = 2.4710e-01, time/batch = 0.6930s	
577/32150 (epoch 0.897), train_loss = 2.64090237, grad/param norm = 2.6619e-01, time/batch = 0.6928s	
578/32150 (epoch 0.899), train_loss = 2.66732844, grad/param norm = 2.9220e-01, time/batch = 0.6907s	
579/32150 (epoch 0.900), train_loss = 2.71242358, grad/param norm = 3.9365e-01, time/batch = 0.7019s	
580/32150 (epoch 0.902), train_loss = 2.70967633, grad/param norm = 5.5016e-01, time/batch = 0.6915s	
581/32150 (epoch 0.904), train_loss = 2.72816843, grad/param norm = 4.6326e-01, time/batch = 0.6929s	
582/32150 (epoch 0.905), train_loss = 2.80703596, grad/param norm = 3.3862e-01, time/batch = 0.7022s	
583/32150 (epoch 0.907), train_loss = 2.72318548, grad/param norm = 3.6964e-01, time/batch = 0.6886s	
584/32150 (epoch 0.908), train_loss = 2.70844936, grad/param norm = 3.3195e-01, time/batch = 0.7007s	
585/32150 (epoch 0.910), train_loss = 2.73659625, grad/param norm = 4.7178e-01, time/batch = 0.6960s	
586/32150 (epoch 0.911), train_loss = 2.54192753, grad/param norm = 5.1592e-01, time/batch = 0.6977s	
587/32150 (epoch 0.913), train_loss = 2.59411718, grad/param norm = 2.8443e-01, time/batch = 0.7091s	
588/32150 (epoch 0.914), train_loss = 2.65620112, grad/param norm = 2.9548e-01, time/batch = 0.7076s	
589/32150 (epoch 0.916), train_loss = 2.59696908, grad/param norm = 4.1385e-01, time/batch = 0.7064s	
590/32150 (epoch 0.918), train_loss = 2.69643565, grad/param norm = 4.2252e-01, time/batch = 0.7079s	
591/32150 (epoch 0.919), train_loss = 2.72354802, grad/param norm = 4.1842e-01, time/batch = 0.6990s	
592/32150 (epoch 0.921), train_loss = 2.69514626, grad/param norm = 3.0153e-01, time/batch = 0.7005s	
593/32150 (epoch 0.922), train_loss = 2.56789481, grad/param norm = 3.6024e-01, time/batch = 0.6940s	
594/32150 (epoch 0.924), train_loss = 2.68154140, grad/param norm = 5.1524e-01, time/batch = 0.6980s	
595/32150 (epoch 0.925), train_loss = 2.61018374, grad/param norm = 3.1544e-01, time/batch = 0.6949s	
596/32150 (epoch 0.927), train_loss = 2.52833218, grad/param norm = 2.7581e-01, time/batch = 0.6983s	
597/32150 (epoch 0.928), train_loss = 2.61330220, grad/param norm = 3.5446e-01, time/batch = 0.7001s	
598/32150 (epoch 0.930), train_loss = 2.59384674, grad/param norm = 3.3960e-01, time/batch = 0.6997s	
599/32150 (epoch 0.932), train_loss = 2.57149347, grad/param norm = 3.3147e-01, time/batch = 0.6982s	
600/32150 (epoch 0.933), train_loss = 2.67876641, grad/param norm = 3.4014e-01, time/batch = 0.6973s	
601/32150 (epoch 0.935), train_loss = 2.56552005, grad/param norm = 4.0816e-01, time/batch = 0.6957s	
602/32150 (epoch 0.936), train_loss = 2.69580684, grad/param norm = 3.6075e-01, time/batch = 0.6866s	
603/32150 (epoch 0.938), train_loss = 2.54446266, grad/param norm = 3.4386e-01, time/batch = 0.6964s	
604/32150 (epoch 0.939), train_loss = 2.79223690, grad/param norm = 4.3933e-01, time/batch = 0.7055s	
605/32150 (epoch 0.941), train_loss = 2.58648737, grad/param norm = 6.2030e-01, time/batch = 0.6930s	
606/32150 (epoch 0.942), train_loss = 2.74481259, grad/param norm = 4.3704e-01, time/batch = 0.6970s	
607/32150 (epoch 0.944), train_loss = 2.62510705, grad/param norm = 2.4435e-01, time/batch = 0.6881s	
608/32150 (epoch 0.946), train_loss = 2.63819917, grad/param norm = 2.6771e-01, time/batch = 0.6957s	
609/32150 (epoch 0.947), train_loss = 2.65365349, grad/param norm = 3.2634e-01, time/batch = 0.6824s	
610/32150 (epoch 0.949), train_loss = 2.66523565, grad/param norm = 4.1162e-01, time/batch = 0.6838s	
611/32150 (epoch 0.950), train_loss = 2.61991710, grad/param norm = 3.4892e-01, time/batch = 0.6895s	
612/32150 (epoch 0.952), train_loss = 2.48726421, grad/param norm = 3.3184e-01, time/batch = 0.6860s	
613/32150 (epoch 0.953), train_loss = 2.47816177, grad/param norm = 3.6854e-01, time/batch = 0.6839s	
614/32150 (epoch 0.955), train_loss = 2.48036786, grad/param norm = 4.1339e-01, time/batch = 0.6846s	
615/32150 (epoch 0.956), train_loss = 2.55333168, grad/param norm = 5.5069e-01, time/batch = 0.6855s	
616/32150 (epoch 0.958), train_loss = 2.55199265, grad/param norm = 4.5061e-01, time/batch = 0.6981s	
617/32150 (epoch 0.960), train_loss = 2.54823763, grad/param norm = 2.7735e-01, time/batch = 0.6917s	
618/32150 (epoch 0.961), train_loss = 2.56457275, grad/param norm = 2.9069e-01, time/batch = 0.6917s	
619/32150 (epoch 0.963), train_loss = 2.60588736, grad/param norm = 3.2823e-01, time/batch = 0.6898s	
620/32150 (epoch 0.964), train_loss = 2.57839629, grad/param norm = 3.3833e-01, time/batch = 0.7017s	
621/32150 (epoch 0.966), train_loss = 2.65857162, grad/param norm = 2.4158e-01, time/batch = 0.7031s	
622/32150 (epoch 0.967), train_loss = 2.52052302, grad/param norm = 2.9441e-01, time/batch = 0.6909s	
623/32150 (epoch 0.969), train_loss = 2.63519057, grad/param norm = 3.6213e-01, time/batch = 0.7007s	
624/32150 (epoch 0.970), train_loss = 2.57679952, grad/param norm = 3.7557e-01, time/batch = 0.6964s	
625/32150 (epoch 0.972), train_loss = 2.69968704, grad/param norm = 2.6989e-01, time/batch = 0.6843s	
626/32150 (epoch 0.974), train_loss = 2.69214010, grad/param norm = 3.0013e-01, time/batch = 0.6880s	
627/32150 (epoch 0.975), train_loss = 2.54894566, grad/param norm = 3.0158e-01, time/batch = 0.6834s	
628/32150 (epoch 0.977), train_loss = 2.56558262, grad/param norm = 3.1854e-01, time/batch = 0.6822s	
629/32150 (epoch 0.978), train_loss = 2.50744502, grad/param norm = 4.0057e-01, time/batch = 0.6902s	
630/32150 (epoch 0.980), train_loss = 2.66389550, grad/param norm = 4.0303e-01, time/batch = 0.6851s	
631/32150 (epoch 0.981), train_loss = 2.63499290, grad/param norm = 3.3243e-01, time/batch = 0.6954s	
632/32150 (epoch 0.983), train_loss = 2.52490923, grad/param norm = 3.5256e-01, time/batch = 0.6880s	
633/32150 (epoch 0.984), train_loss = 2.52739459, grad/param norm = 4.4739e-01, time/batch = 0.6775s	
634/32150 (epoch 0.986), train_loss = 2.58282836, grad/param norm = 4.2586e-01, time/batch = 0.6796s	
635/32150 (epoch 0.988), train_loss = 2.42490622, grad/param norm = 2.7818e-01, time/batch = 0.6849s	
636/32150 (epoch 0.989), train_loss = 2.58960087, grad/param norm = 2.4506e-01, time/batch = 0.6998s	
637/32150 (epoch 0.991), train_loss = 2.51809544, grad/param norm = 3.0128e-01, time/batch = 0.6988s	
638/32150 (epoch 0.992), train_loss = 2.47953389, grad/param norm = 3.4984e-01, time/batch = 0.6982s	
639/32150 (epoch 0.994), train_loss = 2.64241027, grad/param norm = 5.0576e-01, time/batch = 0.6944s	
640/32150 (epoch 0.995), train_loss = 2.67790291, grad/param norm = 4.6054e-01, time/batch = 0.6954s	
641/32150 (epoch 0.997), train_loss = 2.71893132, grad/param norm = 3.3450e-01, time/batch = 0.6977s	
642/32150 (epoch 0.998), train_loss = 2.57899793, grad/param norm = 3.0290e-01, time/batch = 0.6907s	
643/32150 (epoch 1.000), train_loss = 2.63820793, grad/param norm = 3.2059e-01, time/batch = 0.6874s	
644/32150 (epoch 1.002), train_loss = 2.95171466, grad/param norm = 4.4425e-01, time/batch = 0.6899s	
645/32150 (epoch 1.003), train_loss = 2.84951401, grad/param norm = 8.0982e-01, time/batch = 0.7015s	
646/32150 (epoch 1.005), train_loss = 2.54095821, grad/param norm = 3.0785e-01, time/batch = 0.6972s	
647/32150 (epoch 1.006), train_loss = 2.58052105, grad/param norm = 3.0462e-01, time/batch = 0.6948s	
648/32150 (epoch 1.008), train_loss = 2.71522116, grad/param norm = 3.7734e-01, time/batch = 0.6966s	
649/32150 (epoch 1.009), train_loss = 2.45050426, grad/param norm = 3.4708e-01, time/batch = 0.6916s	
650/32150 (epoch 1.011), train_loss = 2.59834061, grad/param norm = 3.7292e-01, time/batch = 0.6988s	
651/32150 (epoch 1.012), train_loss = 2.51516066, grad/param norm = 4.1273e-01, time/batch = 0.7021s	
652/32150 (epoch 1.014), train_loss = 2.56091864, grad/param norm = 2.5806e-01, time/batch = 0.6879s	
653/32150 (epoch 1.016), train_loss = 2.59344059, grad/param norm = 2.8270e-01, time/batch = 0.6875s	
654/32150 (epoch 1.017), train_loss = 2.59498635, grad/param norm = 3.2152e-01, time/batch = 0.6868s	
655/32150 (epoch 1.019), train_loss = 2.57015585, grad/param norm = 2.9574e-01, time/batch = 0.6864s	
656/32150 (epoch 1.020), train_loss = 2.57946057, grad/param norm = 4.2857e-01, time/batch = 0.6895s	
657/32150 (epoch 1.022), train_loss = 2.54992477, grad/param norm = 5.6516e-01, time/batch = 0.6861s	
658/32150 (epoch 1.023), train_loss = 2.61045126, grad/param norm = 5.8335e-01, time/batch = 0.6865s	
659/32150 (epoch 1.025), train_loss = 2.77544237, grad/param norm = 3.2145e-01, time/batch = 0.6887s	
660/32150 (epoch 1.026), train_loss = 2.63284010, grad/param norm = 3.1177e-01, time/batch = 0.6866s	
661/32150 (epoch 1.028), train_loss = 2.56886825, grad/param norm = 3.0527e-01, time/batch = 0.7010s	
662/32150 (epoch 1.030), train_loss = 2.69418721, grad/param norm = 2.4787e-01, time/batch = 0.6926s	
663/32150 (epoch 1.031), train_loss = 2.57302465, grad/param norm = 2.1425e-01, time/batch = 0.6913s	
664/32150 (epoch 1.033), train_loss = 2.78816776, grad/param norm = 3.3646e-01, time/batch = 0.6887s	
665/32150 (epoch 1.034), train_loss = 2.66425447, grad/param norm = 2.5482e-01, time/batch = 0.6819s	
666/32150 (epoch 1.036), train_loss = 2.55084313, grad/param norm = 4.2002e-01, time/batch = 0.6956s	
667/32150 (epoch 1.037), train_loss = 2.63421688, grad/param norm = 3.9058e-01, time/batch = 0.6902s	
668/32150 (epoch 1.039), train_loss = 2.66984667, grad/param norm = 2.8658e-01, time/batch = 0.6839s	
669/32150 (epoch 1.040), train_loss = 2.68133276, grad/param norm = 2.5117e-01, time/batch = 0.6896s	
670/32150 (epoch 1.042), train_loss = 2.64692655, grad/param norm = 2.6044e-01, time/batch = 0.7032s	
671/32150 (epoch 1.044), train_loss = 2.60085471, grad/param norm = 2.5339e-01, time/batch = 0.6866s	
672/32150 (epoch 1.045), train_loss = 2.44359098, grad/param norm = 2.8850e-01, time/batch = 0.6943s	
673/32150 (epoch 1.047), train_loss = 2.54413089, grad/param norm = 3.2007e-01, time/batch = 0.6899s	
674/32150 (epoch 1.048), train_loss = 2.61543595, grad/param norm = 2.8017e-01, time/batch = 0.6885s	
675/32150 (epoch 1.050), train_loss = 2.61437005, grad/param norm = 3.3393e-01, time/batch = 0.6818s	
676/32150 (epoch 1.051), train_loss = 2.66944701, grad/param norm = 3.0807e-01, time/batch = 0.6937s	
677/32150 (epoch 1.053), train_loss = 2.55723530, grad/param norm = 3.0114e-01, time/batch = 0.6937s	
678/32150 (epoch 1.054), train_loss = 2.55914662, grad/param norm = 2.4726e-01, time/batch = 0.6933s	
679/32150 (epoch 1.056), train_loss = 2.57330190, grad/param norm = 2.8416e-01, time/batch = 0.7006s	
680/32150 (epoch 1.058), train_loss = 2.52211916, grad/param norm = 3.0282e-01, time/batch = 0.7032s	
681/32150 (epoch 1.059), train_loss = 2.53789669, grad/param norm = 2.9369e-01, time/batch = 0.7061s	
682/32150 (epoch 1.061), train_loss = 2.62425282, grad/param norm = 3.4953e-01, time/batch = 0.7084s	
683/32150 (epoch 1.062), train_loss = 2.64954081, grad/param norm = 3.8175e-01, time/batch = 0.7061s	
684/32150 (epoch 1.064), train_loss = 2.44096655, grad/param norm = 3.4373e-01, time/batch = 0.6941s	
685/32150 (epoch 1.065), train_loss = 2.61530515, grad/param norm = 2.9847e-01, time/batch = 0.6894s	
686/32150 (epoch 1.067), train_loss = 2.71034290, grad/param norm = 3.9100e-01, time/batch = 0.7060s	
687/32150 (epoch 1.068), train_loss = 2.64426222, grad/param norm = 4.0831e-01, time/batch = 0.6946s	
688/32150 (epoch 1.070), train_loss = 2.54847563, grad/param norm = 3.7845e-01, time/batch = 0.6928s	
689/32150 (epoch 1.072), train_loss = 2.62316398, grad/param norm = 3.6280e-01, time/batch = 0.6937s	
690/32150 (epoch 1.073), train_loss = 2.60901075, grad/param norm = 2.8530e-01, time/batch = 0.6898s	
691/32150 (epoch 1.075), train_loss = 2.58466866, grad/param norm = 3.6133e-01, time/batch = 0.6988s	
692/32150 (epoch 1.076), train_loss = 2.64121221, grad/param norm = 4.4421e-01, time/batch = 0.7109s	
693/32150 (epoch 1.078), train_loss = 2.68605113, grad/param norm = 3.8218e-01, time/batch = 0.6943s	
694/32150 (epoch 1.079), train_loss = 2.51522320, grad/param norm = 2.6893e-01, time/batch = 0.6899s	
695/32150 (epoch 1.081), train_loss = 2.54452012, grad/param norm = 3.2915e-01, time/batch = 0.6865s	
696/32150 (epoch 1.082), train_loss = 2.53190952, grad/param norm = 2.7242e-01, time/batch = 0.6914s	
697/32150 (epoch 1.084), train_loss = 2.57406231, grad/param norm = 3.2663e-01, time/batch = 0.6889s	
698/32150 (epoch 1.086), train_loss = 2.49328157, grad/param norm = 4.1209e-01, time/batch = 0.6905s	
699/32150 (epoch 1.087), train_loss = 2.55866262, grad/param norm = 5.2564e-01, time/batch = 0.7024s	
700/32150 (epoch 1.089), train_loss = 2.55685452, grad/param norm = 4.3491e-01, time/batch = 0.7105s	
701/32150 (epoch 1.090), train_loss = 2.56620300, grad/param norm = 2.3468e-01, time/batch = 0.7155s	
702/32150 (epoch 1.092), train_loss = 2.58090470, grad/param norm = 2.5794e-01, time/batch = 0.7104s	
703/32150 (epoch 1.093), train_loss = 2.50710658, grad/param norm = 2.5777e-01, time/batch = 0.7228s	
704/32150 (epoch 1.095), train_loss = 2.53547898, grad/param norm = 2.7417e-01, time/batch = 0.7215s	
705/32150 (epoch 1.096), train_loss = 2.57348462, grad/param norm = 2.9599e-01, time/batch = 0.7111s	
706/32150 (epoch 1.098), train_loss = 2.50772383, grad/param norm = 2.8342e-01, time/batch = 0.7049s	
707/32150 (epoch 1.100), train_loss = 2.57556199, grad/param norm = 2.6055e-01, time/batch = 0.7038s	
708/32150 (epoch 1.101), train_loss = 2.47588394, grad/param norm = 2.4844e-01, time/batch = 0.7105s	
709/32150 (epoch 1.103), train_loss = 2.53922043, grad/param norm = 2.3799e-01, time/batch = 0.7094s	
710/32150 (epoch 1.104), train_loss = 2.44754657, grad/param norm = 2.9140e-01, time/batch = 0.6988s	
711/32150 (epoch 1.106), train_loss = 2.60320878, grad/param norm = 2.4688e-01, time/batch = 0.6917s	
712/32150 (epoch 1.107), train_loss = 2.63751726, grad/param norm = 2.9486e-01, time/batch = 0.7025s	
713/32150 (epoch 1.109), train_loss = 2.54007296, grad/param norm = 2.6582e-01, time/batch = 0.7066s	
714/32150 (epoch 1.110), train_loss = 2.56434733, grad/param norm = 3.0070e-01, time/batch = 0.7138s	
715/32150 (epoch 1.112), train_loss = 2.50960197, grad/param norm = 3.0748e-01, time/batch = 0.7093s	
716/32150 (epoch 1.114), train_loss = 2.48832824, grad/param norm = 2.5037e-01, time/batch = 0.7044s	
717/32150 (epoch 1.115), train_loss = 2.63640000, grad/param norm = 2.5622e-01, time/batch = 0.7064s	
718/32150 (epoch 1.117), train_loss = 2.51878372, grad/param norm = 2.5103e-01, time/batch = 0.7042s	
719/32150 (epoch 1.118), train_loss = 2.58285480, grad/param norm = 3.5761e-01, time/batch = 0.7084s	
720/32150 (epoch 1.120), train_loss = 2.66871430, grad/param norm = 4.1070e-01, time/batch = 0.6940s	
721/32150 (epoch 1.121), train_loss = 2.35444917, grad/param norm = 2.6878e-01, time/batch = 0.6887s	
722/32150 (epoch 1.123), train_loss = 2.54480807, grad/param norm = 3.0535e-01, time/batch = 0.6854s	
723/32150 (epoch 1.124), train_loss = 2.51071642, grad/param norm = 2.1200e-01, time/batch = 0.6874s	
724/32150 (epoch 1.126), train_loss = 2.52356390, grad/param norm = 2.5124e-01, time/batch = 0.6908s	
725/32150 (epoch 1.128), train_loss = 2.63487254, grad/param norm = 2.9828e-01, time/batch = 0.6854s	
726/32150 (epoch 1.129), train_loss = 2.57279655, grad/param norm = 2.6738e-01, time/batch = 0.6885s	
727/32150 (epoch 1.131), train_loss = 2.63033299, grad/param norm = 3.9003e-01, time/batch = 0.6839s	
728/32150 (epoch 1.132), train_loss = 2.52077047, grad/param norm = 2.8627e-01, time/batch = 0.6804s	
729/32150 (epoch 1.134), train_loss = 2.54229346, grad/param norm = 2.6980e-01, time/batch = 0.6813s	
730/32150 (epoch 1.135), train_loss = 2.52302506, grad/param norm = 3.0252e-01, time/batch = 0.6920s	
731/32150 (epoch 1.137), train_loss = 2.46407833, grad/param norm = 3.1016e-01, time/batch = 0.6862s	
732/32150 (epoch 1.138), train_loss = 2.56266984, grad/param norm = 3.7622e-01, time/batch = 0.6922s	
733/32150 (epoch 1.140), train_loss = 2.59124319, grad/param norm = 4.9273e-01, time/batch = 0.6807s	
734/32150 (epoch 1.142), train_loss = 2.53573858, grad/param norm = 4.0939e-01, time/batch = 0.6775s	
735/32150 (epoch 1.143), train_loss = 2.44021780, grad/param norm = 4.4468e-01, time/batch = 0.6794s	
736/32150 (epoch 1.145), train_loss = 2.36289000, grad/param norm = 4.0267e-01, time/batch = 0.6790s	
737/32150 (epoch 1.146), train_loss = 2.43402475, grad/param norm = 3.5495e-01, time/batch = 0.6791s	
738/32150 (epoch 1.148), train_loss = 2.30769082, grad/param norm = 3.3070e-01, time/batch = 0.6885s	
739/32150 (epoch 1.149), train_loss = 2.61760708, grad/param norm = 3.6028e-01, time/batch = 0.6885s	
740/32150 (epoch 1.151), train_loss = 2.43986299, grad/param norm = 3.8026e-01, time/batch = 0.6923s	
741/32150 (epoch 1.152), train_loss = 2.58582336, grad/param norm = 3.1892e-01, time/batch = 0.6920s	
742/32150 (epoch 1.154), train_loss = 2.38058309, grad/param norm = 3.5204e-01, time/batch = 0.6883s	
743/32150 (epoch 1.156), train_loss = 2.44802623, grad/param norm = 3.3490e-01, time/batch = 0.6860s	
744/32150 (epoch 1.157), train_loss = 2.59489867, grad/param norm = 2.9275e-01, time/batch = 0.6873s	
745/32150 (epoch 1.159), train_loss = 2.52553973, grad/param norm = 3.4787e-01, time/batch = 0.6931s	
746/32150 (epoch 1.160), train_loss = 2.65589908, grad/param norm = 3.4011e-01, time/batch = 0.6914s	
747/32150 (epoch 1.162), train_loss = 2.58078337, grad/param norm = 2.8436e-01, time/batch = 0.6870s	
748/32150 (epoch 1.163), train_loss = 2.51300323, grad/param norm = 2.6790e-01, time/batch = 0.6868s	
749/32150 (epoch 1.165), train_loss = 2.55005744, grad/param norm = 3.0966e-01, time/batch = 0.6849s	
750/32150 (epoch 1.166), train_loss = 2.72601902, grad/param norm = 3.6752e-01, time/batch = 0.6861s	
751/32150 (epoch 1.168), train_loss = 2.58980297, grad/param norm = 3.1130e-01, time/batch = 0.6854s	
752/32150 (epoch 1.170), train_loss = 2.71992500, grad/param norm = 3.5613e-01, time/batch = 0.6840s	
753/32150 (epoch 1.171), train_loss = 2.68539080, grad/param norm = 3.8240e-01, time/batch = 0.6851s	
754/32150 (epoch 1.173), train_loss = 2.58616532, grad/param norm = 2.9705e-01, time/batch = 0.6885s	
755/32150 (epoch 1.174), train_loss = 2.47133025, grad/param norm = 3.7745e-01, time/batch = 0.6927s	
756/32150 (epoch 1.176), train_loss = 2.40452263, grad/param norm = 3.7528e-01, time/batch = 0.7061s	
757/32150 (epoch 1.177), train_loss = 2.70599020, grad/param norm = 3.3852e-01, time/batch = 0.6900s	
758/32150 (epoch 1.179), train_loss = 2.47447789, grad/param norm = 2.9495e-01, time/batch = 0.7013s	
759/32150 (epoch 1.180), train_loss = 2.59135556, grad/param norm = 2.8102e-01, time/batch = 0.6913s	
760/32150 (epoch 1.182), train_loss = 2.49007193, grad/param norm = 2.6549e-01, time/batch = 0.6932s	
761/32150 (epoch 1.184), train_loss = 2.54051002, grad/param norm = 3.1352e-01, time/batch = 0.6851s	
762/32150 (epoch 1.185), train_loss = 2.53449921, grad/param norm = 2.9925e-01, time/batch = 0.6857s	
763/32150 (epoch 1.187), train_loss = 2.45503295, grad/param norm = 2.7617e-01, time/batch = 0.6854s	
764/32150 (epoch 1.188), train_loss = 2.55483479, grad/param norm = 3.1746e-01, time/batch = 0.6870s	
765/32150 (epoch 1.190), train_loss = 2.75813448, grad/param norm = 2.5947e-01, time/batch = 0.6839s	
766/32150 (epoch 1.191), train_loss = 2.63780404, grad/param norm = 3.7095e-01, time/batch = 0.7088s	
767/32150 (epoch 1.193), train_loss = 2.59769371, grad/param norm = 4.4935e-01, time/batch = 0.6989s	
768/32150 (epoch 1.194), train_loss = 2.67738432, grad/param norm = 3.2819e-01, time/batch = 0.6878s	
769/32150 (epoch 1.196), train_loss = 2.66946574, grad/param norm = 2.8087e-01, time/batch = 0.6925s	
770/32150 (epoch 1.198), train_loss = 2.53089944, grad/param norm = 2.5470e-01, time/batch = 0.7055s	
771/32150 (epoch 1.199), train_loss = 2.44019411, grad/param norm = 2.8796e-01, time/batch = 0.7082s	
772/32150 (epoch 1.201), train_loss = 2.47583767, grad/param norm = 3.1002e-01, time/batch = 0.6989s	
773/32150 (epoch 1.202), train_loss = 2.52386894, grad/param norm = 3.1857e-01, time/batch = 0.6941s	
774/32150 (epoch 1.204), train_loss = 2.62254491, grad/param norm = 3.1717e-01, time/batch = 0.7035s	
775/32150 (epoch 1.205), train_loss = 2.56639590, grad/param norm = 2.6946e-01, time/batch = 0.6953s	
776/32150 (epoch 1.207), train_loss = 2.36973975, grad/param norm = 2.9767e-01, time/batch = 0.7000s	
777/32150 (epoch 1.208), train_loss = 2.36089168, grad/param norm = 3.8187e-01, time/batch = 0.7048s	
778/32150 (epoch 1.210), train_loss = 2.37407484, grad/param norm = 3.2288e-01, time/batch = 0.6955s	
779/32150 (epoch 1.212), train_loss = 2.50865866, grad/param norm = 3.1057e-01, time/batch = 0.6908s	
780/32150 (epoch 1.213), train_loss = 2.43504543, grad/param norm = 2.7635e-01, time/batch = 0.6960s	
781/32150 (epoch 1.215), train_loss = 2.44108906, grad/param norm = 3.3670e-01, time/batch = 0.6925s	
782/32150 (epoch 1.216), train_loss = 2.54936541, grad/param norm = 3.4135e-01, time/batch = 0.6924s	
783/32150 (epoch 1.218), train_loss = 2.42589370, grad/param norm = 3.7690e-01, time/batch = 0.6939s	
784/32150 (epoch 1.219), train_loss = 2.39910071, grad/param norm = 3.5970e-01, time/batch = 0.6926s	
785/32150 (epoch 1.221), train_loss = 2.68368827, grad/param norm = 3.2801e-01, time/batch = 0.7054s	
786/32150 (epoch 1.222), train_loss = 2.52302117, grad/param norm = 2.5245e-01, time/batch = 0.6987s	
787/32150 (epoch 1.224), train_loss = 2.57569133, grad/param norm = 3.0760e-01, time/batch = 0.6857s	
788/32150 (epoch 1.226), train_loss = 2.48234769, grad/param norm = 2.8571e-01, time/batch = 0.6821s	
789/32150 (epoch 1.227), train_loss = 2.49512939, grad/param norm = 3.1961e-01, time/batch = 0.6836s	
790/32150 (epoch 1.229), train_loss = 2.70180033, grad/param norm = 4.0431e-01, time/batch = 0.6846s	
791/32150 (epoch 1.230), train_loss = 2.49583245, grad/param norm = 4.7652e-01, time/batch = 0.6880s	
792/32150 (epoch 1.232), train_loss = 2.51058323, grad/param norm = 4.9261e-01, time/batch = 0.6885s	
793/32150 (epoch 1.233), train_loss = 2.55436311, grad/param norm = 3.7288e-01, time/batch = 0.6869s	
794/32150 (epoch 1.235), train_loss = 2.61207778, grad/param norm = 2.7284e-01, time/batch = 0.6968s	
795/32150 (epoch 1.236), train_loss = 2.59439108, grad/param norm = 3.1953e-01, time/batch = 0.6899s	
796/32150 (epoch 1.238), train_loss = 2.56499383, grad/param norm = 2.9268e-01, time/batch = 0.6789s	
797/32150 (epoch 1.240), train_loss = 2.63266301, grad/param norm = 3.4125e-01, time/batch = 0.6829s	
798/32150 (epoch 1.241), train_loss = 2.51054584, grad/param norm = 2.7213e-01, time/batch = 0.6801s	
799/32150 (epoch 1.243), train_loss = 2.57178473, grad/param norm = 2.7178e-01, time/batch = 0.6791s	
800/32150 (epoch 1.244), train_loss = 2.45893825, grad/param norm = 2.3729e-01, time/batch = 0.6868s	
801/32150 (epoch 1.246), train_loss = 2.67638969, grad/param norm = 2.9933e-01, time/batch = 0.6950s	
802/32150 (epoch 1.247), train_loss = 2.61525065, grad/param norm = 2.4705e-01, time/batch = 0.6858s	
803/32150 (epoch 1.249), train_loss = 2.56313328, grad/param norm = 3.3175e-01, time/batch = 0.6805s	
804/32150 (epoch 1.250), train_loss = 2.57267639, grad/param norm = 3.6657e-01, time/batch = 0.6826s	
805/32150 (epoch 1.252), train_loss = 2.50661817, grad/param norm = 4.1642e-01, time/batch = 0.6879s	
806/32150 (epoch 1.253), train_loss = 2.65895120, grad/param norm = 3.9386e-01, time/batch = 0.6821s	
807/32150 (epoch 1.255), train_loss = 2.45973071, grad/param norm = 2.9763e-01, time/batch = 0.6866s	
808/32150 (epoch 1.257), train_loss = 2.53594541, grad/param norm = 3.4627e-01, time/batch = 0.6894s	
809/32150 (epoch 1.258), train_loss = 2.41006563, grad/param norm = 2.6021e-01, time/batch = 0.6861s	
810/32150 (epoch 1.260), train_loss = 2.64571928, grad/param norm = 2.7300e-01, time/batch = 0.6904s	
811/32150 (epoch 1.261), train_loss = 2.46426147, grad/param norm = 3.0006e-01, time/batch = 0.6892s	
812/32150 (epoch 1.263), train_loss = 2.64604050, grad/param norm = 2.3765e-01, time/batch = 0.6874s	
813/32150 (epoch 1.264), train_loss = 2.51875056, grad/param norm = 2.4190e-01, time/batch = 0.6898s	
814/32150 (epoch 1.266), train_loss = 2.43361800, grad/param norm = 2.5421e-01, time/batch = 0.6859s	
815/32150 (epoch 1.267), train_loss = 2.42427787, grad/param norm = 2.6945e-01, time/batch = 0.6873s	
816/32150 (epoch 1.269), train_loss = 2.40193594, grad/param norm = 2.7184e-01, time/batch = 0.6836s	
817/32150 (epoch 1.271), train_loss = 2.36080734, grad/param norm = 2.2446e-01, time/batch = 0.6817s	
818/32150 (epoch 1.272), train_loss = 2.38494591, grad/param norm = 3.9988e-01, time/batch = 0.6874s	
819/32150 (epoch 1.274), train_loss = 2.67543343, grad/param norm = 4.2682e-01, time/batch = 0.7018s	
820/32150 (epoch 1.275), train_loss = 2.55300622, grad/param norm = 2.9375e-01, time/batch = 0.6896s	
821/32150 (epoch 1.277), train_loss = 2.51674592, grad/param norm = 2.5310e-01, time/batch = 0.6918s	
822/32150 (epoch 1.278), train_loss = 2.49884253, grad/param norm = 3.1355e-01, time/batch = 0.6810s	
823/32150 (epoch 1.280), train_loss = 2.59405417, grad/param norm = 3.8591e-01, time/batch = 0.6998s	
824/32150 (epoch 1.281), train_loss = 2.62888040, grad/param norm = 3.3423e-01, time/batch = 0.7091s	
825/32150 (epoch 1.283), train_loss = 2.59375219, grad/param norm = 2.7715e-01, time/batch = 0.6884s	
826/32150 (epoch 1.285), train_loss = 2.46805437, grad/param norm = 2.5669e-01, time/batch = 0.6814s	
827/32150 (epoch 1.286), train_loss = 2.62178154, grad/param norm = 3.0406e-01, time/batch = 0.6809s	
828/32150 (epoch 1.288), train_loss = 2.56635993, grad/param norm = 3.1650e-01, time/batch = 0.6826s	
829/32150 (epoch 1.289), train_loss = 2.55694390, grad/param norm = 4.4957e-01, time/batch = 0.6829s	
830/32150 (epoch 1.291), train_loss = 2.42724965, grad/param norm = 3.3675e-01, time/batch = 0.6828s	
831/32150 (epoch 1.292), train_loss = 2.48401250, grad/param norm = 2.5380e-01, time/batch = 0.6836s	
832/32150 (epoch 1.294), train_loss = 2.50770910, grad/param norm = 2.9471e-01, time/batch = 0.6839s	
833/32150 (epoch 1.295), train_loss = 2.58376402, grad/param norm = 3.5520e-01, time/batch = 0.6849s	
834/32150 (epoch 1.297), train_loss = 2.50886941, grad/param norm = 3.0251e-01, time/batch = 0.6877s	
835/32150 (epoch 1.299), train_loss = 2.66655308, grad/param norm = 3.2896e-01, time/batch = 0.6871s	
836/32150 (epoch 1.300), train_loss = 2.55167634, grad/param norm = 3.2420e-01, time/batch = 0.6877s	
837/32150 (epoch 1.302), train_loss = 2.48432879, grad/param norm = 3.1702e-01, time/batch = 0.6972s	
838/32150 (epoch 1.303), train_loss = 2.66620448, grad/param norm = 3.1846e-01, time/batch = 0.6892s	
839/32150 (epoch 1.305), train_loss = 2.68595075, grad/param norm = 3.0574e-01, time/batch = 0.6866s	
840/32150 (epoch 1.306), train_loss = 2.51850171, grad/param norm = 2.8555e-01, time/batch = 0.6852s	
841/32150 (epoch 1.308), train_loss = 2.50698453, grad/param norm = 2.7870e-01, time/batch = 0.6849s	
842/32150 (epoch 1.309), train_loss = 2.62686234, grad/param norm = 3.2895e-01, time/batch = 0.6972s	
843/32150 (epoch 1.311), train_loss = 2.36110739, grad/param norm = 2.9086e-01, time/batch = 0.6998s	
844/32150 (epoch 1.313), train_loss = 2.47875702, grad/param norm = 2.7942e-01, time/batch = 0.7146s	
845/32150 (epoch 1.314), train_loss = 2.56091913, grad/param norm = 2.4928e-01, time/batch = 0.6971s	
846/32150 (epoch 1.316), train_loss = 2.46871648, grad/param norm = 2.6839e-01, time/batch = 0.6994s	
847/32150 (epoch 1.317), train_loss = 2.47478916, grad/param norm = 2.6293e-01, time/batch = 0.6975s	
848/32150 (epoch 1.319), train_loss = 2.44227969, grad/param norm = 2.9158e-01, time/batch = 0.7029s	
849/32150 (epoch 1.320), train_loss = 2.46718861, grad/param norm = 2.3992e-01, time/batch = 0.7163s	
850/32150 (epoch 1.322), train_loss = 2.46662114, grad/param norm = 2.4629e-01, time/batch = 0.6861s	
851/32150 (epoch 1.323), train_loss = 2.45378876, grad/param norm = 3.1893e-01, time/batch = 0.6895s	
852/32150 (epoch 1.325), train_loss = 2.51556685, grad/param norm = 2.9027e-01, time/batch = 0.6936s	
853/32150 (epoch 1.327), train_loss = 2.73563013, grad/param norm = 2.6799e-01, time/batch = 0.6858s	
854/32150 (epoch 1.328), train_loss = 2.36674689, grad/param norm = 2.8878e-01, time/batch = 0.6985s	
855/32150 (epoch 1.330), train_loss = 2.57747498, grad/param norm = 3.4973e-01, time/batch = 0.7041s	
856/32150 (epoch 1.331), train_loss = 2.57904434, grad/param norm = 3.9299e-01, time/batch = 0.7113s	
857/32150 (epoch 1.333), train_loss = 2.55087408, grad/param norm = 3.1579e-01, time/batch = 0.7088s	
858/32150 (epoch 1.334), train_loss = 2.52988029, grad/param norm = 2.5723e-01, time/batch = 0.7065s	
859/32150 (epoch 1.336), train_loss = 2.59511993, grad/param norm = 2.3340e-01, time/batch = 0.7025s	
860/32150 (epoch 1.337), train_loss = 2.62359020, grad/param norm = 2.6553e-01, time/batch = 0.6892s	
861/32150 (epoch 1.339), train_loss = 2.75091580, grad/param norm = 2.8994e-01, time/batch = 0.7027s	
862/32150 (epoch 1.341), train_loss = 2.56224615, grad/param norm = 2.7696e-01, time/batch = 0.7069s	
863/32150 (epoch 1.342), train_loss = 2.36166398, grad/param norm = 3.0481e-01, time/batch = 0.6926s	
864/32150 (epoch 1.344), train_loss = 2.26608706, grad/param norm = 3.5100e-01, time/batch = 0.6922s	
865/32150 (epoch 1.345), train_loss = 2.45635991, grad/param norm = 4.1015e-01, time/batch = 0.6844s	
866/32150 (epoch 1.347), train_loss = 2.50078628, grad/param norm = 3.3986e-01, time/batch = 0.6831s	
867/32150 (epoch 1.348), train_loss = 2.40285899, grad/param norm = 3.4560e-01, time/batch = 0.6844s	
868/32150 (epoch 1.350), train_loss = 2.59032331, grad/param norm = 2.7544e-01, time/batch = 0.6927s	
869/32150 (epoch 1.351), train_loss = 2.55071351, grad/param norm = 3.1315e-01, time/batch = 0.6837s	
870/32150 (epoch 1.353), train_loss = 2.53616841, grad/param norm = 4.2218e-01, time/batch = 0.6854s	
871/32150 (epoch 1.355), train_loss = 2.38382082, grad/param norm = 2.5527e-01, time/batch = 0.6858s	
872/32150 (epoch 1.356), train_loss = 2.54311389, grad/param norm = 2.6337e-01, time/batch = 0.6820s	
873/32150 (epoch 1.358), train_loss = 2.49074995, grad/param norm = 2.7755e-01, time/batch = 0.6871s	
874/32150 (epoch 1.359), train_loss = 2.43468309, grad/param norm = 2.7739e-01, time/batch = 0.6847s	
875/32150 (epoch 1.361), train_loss = 2.60886954, grad/param norm = 2.8771e-01, time/batch = 0.6821s	
876/32150 (epoch 1.362), train_loss = 2.49995618, grad/param norm = 2.5241e-01, time/batch = 0.6767s	
877/32150 (epoch 1.364), train_loss = 2.48234737, grad/param norm = 2.9097e-01, time/batch = 0.6763s	
878/32150 (epoch 1.365), train_loss = 2.63557026, grad/param norm = 2.7042e-01, time/batch = 0.6860s	
879/32150 (epoch 1.367), train_loss = 2.54361779, grad/param norm = 2.5474e-01, time/batch = 0.6807s	
880/32150 (epoch 1.369), train_loss = 2.48059461, grad/param norm = 2.9787e-01, time/batch = 0.6859s	
881/32150 (epoch 1.370), train_loss = 2.44401315, grad/param norm = 2.8105e-01, time/batch = 0.6863s	
882/32150 (epoch 1.372), train_loss = 2.55102064, grad/param norm = 3.1088e-01, time/batch = 0.6913s	
883/32150 (epoch 1.373), train_loss = 2.62499627, grad/param norm = 3.6968e-01, time/batch = 0.6836s	
884/32150 (epoch 1.375), train_loss = 2.37067157, grad/param norm = 2.6946e-01, time/batch = 0.6802s	
885/32150 (epoch 1.376), train_loss = 2.56886467, grad/param norm = 3.0639e-01, time/batch = 0.6777s	
886/32150 (epoch 1.378), train_loss = 2.51977942, grad/param norm = 2.5079e-01, time/batch = 0.6877s	
887/32150 (epoch 1.379), train_loss = 2.46200272, grad/param norm = 2.6442e-01, time/batch = 0.6790s	
888/32150 (epoch 1.381), train_loss = 2.55472239, grad/param norm = 2.5833e-01, time/batch = 0.6829s	
889/32150 (epoch 1.383), train_loss = 2.36682405, grad/param norm = 2.4037e-01, time/batch = 0.6844s	
890/32150 (epoch 1.384), train_loss = 2.38102695, grad/param norm = 3.7132e-01, time/batch = 0.6967s	
891/32150 (epoch 1.386), train_loss = 2.48702383, grad/param norm = 4.5948e-01, time/batch = 0.6913s	
892/32150 (epoch 1.387), train_loss = 2.55369336, grad/param norm = 4.0181e-01, time/batch = 0.6888s	
893/32150 (epoch 1.389), train_loss = 2.37912212, grad/param norm = 3.9160e-01, time/batch = 0.6831s	
894/32150 (epoch 1.390), train_loss = 2.51806688, grad/param norm = 3.0293e-01, time/batch = 0.7010s	
895/32150 (epoch 1.392), train_loss = 2.47483922, grad/param norm = 2.2792e-01, time/batch = 0.7038s	
896/32150 (epoch 1.393), train_loss = 2.48836553, grad/param norm = 2.6048e-01, time/batch = 0.6918s	
897/32150 (epoch 1.395), train_loss = 2.29589881, grad/param norm = 2.2501e-01, time/batch = 0.6813s	
898/32150 (epoch 1.397), train_loss = 2.54101411, grad/param norm = 2.4896e-01, time/batch = 0.6804s	
899/32150 (epoch 1.398), train_loss = 2.53002615, grad/param norm = 3.0324e-01, time/batch = 0.6739s	
900/32150 (epoch 1.400), train_loss = 2.66146766, grad/param norm = 2.8705e-01, time/batch = 0.6797s	
901/32150 (epoch 1.401), train_loss = 2.56978274, grad/param norm = 2.6304e-01, time/batch = 0.6845s	
902/32150 (epoch 1.403), train_loss = 2.43650568, grad/param norm = 3.1352e-01, time/batch = 0.6836s	
903/32150 (epoch 1.404), train_loss = 2.36997434, grad/param norm = 2.6726e-01, time/batch = 0.6810s	
904/32150 (epoch 1.406), train_loss = 2.51793481, grad/param norm = 2.8751e-01, time/batch = 0.6885s	
905/32150 (epoch 1.407), train_loss = 2.53439744, grad/param norm = 2.8987e-01, time/batch = 0.6909s	
906/32150 (epoch 1.409), train_loss = 2.46871954, grad/param norm = 2.5614e-01, time/batch = 0.6763s	
907/32150 (epoch 1.411), train_loss = 2.58029767, grad/param norm = 2.7878e-01, time/batch = 0.6816s	
908/32150 (epoch 1.412), train_loss = 2.61528299, grad/param norm = 2.6314e-01, time/batch = 0.6781s	
909/32150 (epoch 1.414), train_loss = 2.40455006, grad/param norm = 3.7309e-01, time/batch = 0.6857s	
910/32150 (epoch 1.415), train_loss = 2.41571867, grad/param norm = 3.4665e-01, time/batch = 0.6976s	
911/32150 (epoch 1.417), train_loss = 2.59855594, grad/param norm = 2.8574e-01, time/batch = 0.6825s	
912/32150 (epoch 1.418), train_loss = 2.54445851, grad/param norm = 2.5223e-01, time/batch = 0.6947s	
913/32150 (epoch 1.420), train_loss = 2.46911872, grad/param norm = 3.0705e-01, time/batch = 0.6965s	
914/32150 (epoch 1.421), train_loss = 2.58257583, grad/param norm = 4.3742e-01, time/batch = 0.6826s	
915/32150 (epoch 1.423), train_loss = 2.33884808, grad/param norm = 4.2270e-01, time/batch = 0.6853s	
916/32150 (epoch 1.425), train_loss = 2.35447550, grad/param norm = 2.2840e-01, time/batch = 0.6901s	
917/32150 (epoch 1.426), train_loss = 2.46763239, grad/param norm = 2.5707e-01, time/batch = 0.6923s	
918/32150 (epoch 1.428), train_loss = 2.50365925, grad/param norm = 2.5149e-01, time/batch = 0.6978s	
919/32150 (epoch 1.429), train_loss = 2.58994423, grad/param norm = 3.1140e-01, time/batch = 0.6851s	
920/32150 (epoch 1.431), train_loss = 2.56292817, grad/param norm = 2.8587e-01, time/batch = 0.6835s	
921/32150 (epoch 1.432), train_loss = 2.41950972, grad/param norm = 3.1456e-01, time/batch = 0.6890s	
922/32150 (epoch 1.434), train_loss = 2.52387039, grad/param norm = 2.9466e-01, time/batch = 0.6857s	
923/32150 (epoch 1.435), train_loss = 2.47917446, grad/param norm = 2.5297e-01, time/batch = 0.6889s	
924/32150 (epoch 1.437), train_loss = 2.49151865, grad/param norm = 3.0318e-01, time/batch = 0.7018s	
925/32150 (epoch 1.439), train_loss = 2.37320667, grad/param norm = 3.1292e-01, time/batch = 0.6978s	
926/32150 (epoch 1.440), train_loss = 2.22512591, grad/param norm = 2.9629e-01, time/batch = 0.6835s	
927/32150 (epoch 1.442), train_loss = 2.36894337, grad/param norm = 2.6332e-01, time/batch = 0.6844s	
928/32150 (epoch 1.443), train_loss = 2.10514192, grad/param norm = 2.2375e-01, time/batch = 0.6839s	
929/32150 (epoch 1.445), train_loss = 2.43713049, grad/param norm = 2.6585e-01, time/batch = 0.7041s	
930/32150 (epoch 1.446), train_loss = 2.27412343, grad/param norm = 2.9130e-01, time/batch = 0.6979s	
931/32150 (epoch 1.448), train_loss = 2.24799818, grad/param norm = 2.5045e-01, time/batch = 0.7006s	
932/32150 (epoch 1.449), train_loss = 2.35782512, grad/param norm = 2.2865e-01, time/batch = 0.6865s	
933/32150 (epoch 1.451), train_loss = 2.53166223, grad/param norm = 2.8807e-01, time/batch = 0.6852s	
934/32150 (epoch 1.453), train_loss = 2.51406007, grad/param norm = 2.3684e-01, time/batch = 0.6823s	
935/32150 (epoch 1.454), train_loss = 2.27236331, grad/param norm = 2.6867e-01, time/batch = 0.6793s	
936/32150 (epoch 1.456), train_loss = 2.35179207, grad/param norm = 2.6746e-01, time/batch = 0.6963s	
937/32150 (epoch 1.457), train_loss = 2.42411270, grad/param norm = 2.2680e-01, time/batch = 0.6844s	
938/32150 (epoch 1.459), train_loss = 2.47048863, grad/param norm = 2.8392e-01, time/batch = 0.6983s	
939/32150 (epoch 1.460), train_loss = 2.41822317, grad/param norm = 2.9997e-01, time/batch = 0.7018s	
940/32150 (epoch 1.462), train_loss = 2.51790444, grad/param norm = 2.7331e-01, time/batch = 0.6803s	
941/32150 (epoch 1.463), train_loss = 2.45095130, grad/param norm = 2.9371e-01, time/batch = 0.7142s	
942/32150 (epoch 1.465), train_loss = 2.44334473, grad/param norm = 3.0941e-01, time/batch = 0.6863s	
943/32150 (epoch 1.467), train_loss = 2.41377025, grad/param norm = 2.9801e-01, time/batch = 0.6890s	
944/32150 (epoch 1.468), train_loss = 2.46794115, grad/param norm = 4.0929e-01, time/batch = 0.6920s	
945/32150 (epoch 1.470), train_loss = 2.46901148, grad/param norm = 3.1352e-01, time/batch = 0.6887s	
946/32150 (epoch 1.471), train_loss = 2.49594820, grad/param norm = 2.7905e-01, time/batch = 0.6793s	
947/32150 (epoch 1.473), train_loss = 2.44025459, grad/param norm = 2.5996e-01, time/batch = 0.6790s	
948/32150 (epoch 1.474), train_loss = 2.40696224, grad/param norm = 3.4573e-01, time/batch = 0.7089s	
949/32150 (epoch 1.476), train_loss = 2.50019510, grad/param norm = 3.0656e-01, time/batch = 0.6963s	
950/32150 (epoch 1.477), train_loss = 2.48843695, grad/param norm = 2.7568e-01, time/batch = 0.6916s	
951/32150 (epoch 1.479), train_loss = 2.52156396, grad/param norm = 2.4030e-01, time/batch = 0.6975s	
952/32150 (epoch 1.481), train_loss = 2.63857535, grad/param norm = 2.9995e-01, time/batch = 0.6914s	
953/32150 (epoch 1.482), train_loss = 2.47305539, grad/param norm = 2.7079e-01, time/batch = 0.7024s	
954/32150 (epoch 1.484), train_loss = 2.33638197, grad/param norm = 2.7296e-01, time/batch = 0.6857s	
955/32150 (epoch 1.485), train_loss = 2.46039848, grad/param norm = 3.0825e-01, time/batch = 0.6791s	
956/32150 (epoch 1.487), train_loss = 2.44854719, grad/param norm = 2.8867e-01, time/batch = 0.6822s	
957/32150 (epoch 1.488), train_loss = 2.40011404, grad/param norm = 2.6122e-01, time/batch = 0.6822s	
958/32150 (epoch 1.490), train_loss = 2.38642196, grad/param norm = 3.5533e-01, time/batch = 0.6780s	
959/32150 (epoch 1.491), train_loss = 2.33957956, grad/param norm = 2.8187e-01, time/batch = 0.6928s	
960/32150 (epoch 1.493), train_loss = 2.51900244, grad/param norm = 2.4547e-01, time/batch = 0.6849s	
961/32150 (epoch 1.495), train_loss = 2.44426882, grad/param norm = 2.3174e-01, time/batch = 0.6834s	
962/32150 (epoch 1.496), train_loss = 2.48006804, grad/param norm = 3.2612e-01, time/batch = 0.6901s	
963/32150 (epoch 1.498), train_loss = 2.54559255, grad/param norm = 3.3832e-01, time/batch = 0.6813s	
964/32150 (epoch 1.499), train_loss = 2.38432183, grad/param norm = 3.7663e-01, time/batch = 0.6855s	
965/32150 (epoch 1.501), train_loss = 2.37011151, grad/param norm = 2.8772e-01, time/batch = 0.6858s	
966/32150 (epoch 1.502), train_loss = 2.45585680, grad/param norm = 2.5579e-01, time/batch = 0.6856s	
967/32150 (epoch 1.504), train_loss = 2.29802437, grad/param norm = 2.3112e-01, time/batch = 0.6915s	
968/32150 (epoch 1.505), train_loss = 2.32072545, grad/param norm = 2.5460e-01, time/batch = 0.6896s	
969/32150 (epoch 1.507), train_loss = 2.28031607, grad/param norm = 2.8412e-01, time/batch = 0.6895s	
970/32150 (epoch 1.509), train_loss = 2.42012300, grad/param norm = 2.8801e-01, time/batch = 0.7145s	
971/32150 (epoch 1.510), train_loss = 2.42429660, grad/param norm = 2.7697e-01, time/batch = 0.7071s	
972/32150 (epoch 1.512), train_loss = 2.28900685, grad/param norm = 3.1643e-01, time/batch = 0.7077s	
973/32150 (epoch 1.513), train_loss = 2.46124491, grad/param norm = 2.7976e-01, time/batch = 0.7109s	
974/32150 (epoch 1.515), train_loss = 2.54964963, grad/param norm = 2.4126e-01, time/batch = 0.6961s	
975/32150 (epoch 1.516), train_loss = 2.53895152, grad/param norm = 2.6985e-01, time/batch = 0.7009s	
976/32150 (epoch 1.518), train_loss = 2.52375540, grad/param norm = 2.3700e-01, time/batch = 0.6956s	
977/32150 (epoch 1.519), train_loss = 2.51841558, grad/param norm = 2.7777e-01, time/batch = 0.6962s	
978/32150 (epoch 1.521), train_loss = 2.48486548, grad/param norm = 2.7524e-01, time/batch = 0.6977s	
979/32150 (epoch 1.523), train_loss = 2.38735314, grad/param norm = 2.8455e-01, time/batch = 0.6964s	
980/32150 (epoch 1.524), train_loss = 2.49859664, grad/param norm = 2.7920e-01, time/batch = 0.6825s	
981/32150 (epoch 1.526), train_loss = 2.55807154, grad/param norm = 3.4966e-01, time/batch = 0.6805s	
982/32150 (epoch 1.527), train_loss = 2.62986818, grad/param norm = 3.4603e-01, time/batch = 0.6872s	
983/32150 (epoch 1.529), train_loss = 2.48891091, grad/param norm = 2.4881e-01, time/batch = 0.6914s	
984/32150 (epoch 1.530), train_loss = 2.42002896, grad/param norm = 2.6430e-01, time/batch = 0.6850s	
985/32150 (epoch 1.532), train_loss = 2.32059814, grad/param norm = 3.0414e-01, time/batch = 0.6855s	
986/32150 (epoch 1.533), train_loss = 2.54899895, grad/param norm = 4.0791e-01, time/batch = 0.6931s	
987/32150 (epoch 1.535), train_loss = 2.55477230, grad/param norm = 3.6878e-01, time/batch = 0.6932s	
988/32150 (epoch 1.537), train_loss = 2.46039605, grad/param norm = 2.4443e-01, time/batch = 0.6856s	
989/32150 (epoch 1.538), train_loss = 2.45499882, grad/param norm = 2.5140e-01, time/batch = 0.6911s	
990/32150 (epoch 1.540), train_loss = 2.54011163, grad/param norm = 2.9124e-01, time/batch = 0.6950s	
991/32150 (epoch 1.541), train_loss = 2.57946099, grad/param norm = 2.4749e-01, time/batch = 0.6874s	
992/32150 (epoch 1.543), train_loss = 2.51684104, grad/param norm = 2.3213e-01, time/batch = 0.6869s	
993/32150 (epoch 1.544), train_loss = 2.63140149, grad/param norm = 2.7832e-01, time/batch = 0.6925s	
994/32150 (epoch 1.546), train_loss = 2.32197965, grad/param norm = 2.7637e-01, time/batch = 0.6945s	
995/32150 (epoch 1.547), train_loss = 2.44464882, grad/param norm = 2.9951e-01, time/batch = 0.6894s	
996/32150 (epoch 1.549), train_loss = 2.47970268, grad/param norm = 3.2142e-01, time/batch = 0.6900s	
997/32150 (epoch 1.551), train_loss = 2.54764014, grad/param norm = 2.3278e-01, time/batch = 0.6902s	
998/32150 (epoch 1.552), train_loss = 2.45483818, grad/param norm = 2.7630e-01, time/batch = 0.6888s	
999/32150 (epoch 1.554), train_loss = 2.65082328, grad/param norm = 3.1369e-01, time/batch = 0.6860s	
evaluating loss over split index 2	
1/34...	
2/34...	
3/34...	
4/34...	
5/34...	
6/34...	
7/34...	
8/34...	
9/34...	
10/34...	
11/34...	
12/34...	
13/34...	
14/34...	
15/34...	
16/34...	
17/34...	
18/34...	
19/34...	
20/34...	
21/34...	
22/34...	
23/34...	
24/34...	
25/34...	
26/34...	
27/34...	
28/34...	
29/34...	
30/34...	
31/34...	
32/34...	
33/34...	
34/34...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_andre_epoch1.56_2.4687.t7	
1000/32150 (epoch 1.555), train_loss = 2.41404136, grad/param norm = 2.8098e-01, time/batch = 0.6852s	
1001/32150 (epoch 1.557), train_loss = 2.37954501, grad/param norm = 2.4465e-01, time/batch = 0.7076s	
1002/32150 (epoch 1.558), train_loss = 2.41567588, grad/param norm = 2.3003e-01, time/batch = 0.6972s	
1003/32150 (epoch 1.560), train_loss = 2.52337082, grad/param norm = 3.1114e-01, time/batch = 0.6881s	
1004/32150 (epoch 1.561), train_loss = 2.51479510, grad/param norm = 3.6601e-01, time/batch = 0.6859s	
1005/32150 (epoch 1.563), train_loss = 2.41143998, grad/param norm = 2.8957e-01, time/batch = 0.6867s	
1006/32150 (epoch 1.565), train_loss = 2.23558798, grad/param norm = 2.9884e-01, time/batch = 0.7028s	
1007/32150 (epoch 1.566), train_loss = 2.58405435, grad/param norm = 3.1061e-01, time/batch = 0.6903s	
1008/32150 (epoch 1.568), train_loss = 2.32196917, grad/param norm = 2.2816e-01, time/batch = 0.6849s	
1009/32150 (epoch 1.569), train_loss = 2.50015662, grad/param norm = 2.4068e-01, time/batch = 0.6837s	
1010/32150 (epoch 1.571), train_loss = 2.52553338, grad/param norm = 2.8181e-01, time/batch = 0.6904s	
1011/32150 (epoch 1.572), train_loss = 2.49534829, grad/param norm = 3.1366e-01, time/batch = 0.6828s	
1012/32150 (epoch 1.574), train_loss = 2.51130230, grad/param norm = 3.0750e-01, time/batch = 0.6879s	
1013/32150 (epoch 1.575), train_loss = 2.52604969, grad/param norm = 3.0636e-01, time/batch = 0.6954s	
1014/32150 (epoch 1.577), train_loss = 2.37759010, grad/param norm = 2.4576e-01, time/batch = 0.6835s	
1015/32150 (epoch 1.579), train_loss = 2.54652672, grad/param norm = 2.9784e-01, time/batch = 0.6822s	
1016/32150 (epoch 1.580), train_loss = 2.50426275, grad/param norm = 2.9341e-01, time/batch = 0.6909s	
1017/32150 (epoch 1.582), train_loss = 2.49260909, grad/param norm = 2.5614e-01, time/batch = 0.6910s	
1018/32150 (epoch 1.583), train_loss = 2.33873506, grad/param norm = 2.0745e-01, time/batch = 0.6937s	
1019/32150 (epoch 1.585), train_loss = 2.38337373, grad/param norm = 2.2205e-01, time/batch = 0.6881s	
1020/32150 (epoch 1.586), train_loss = 2.48460437, grad/param norm = 2.3708e-01, time/batch = 0.6869s	
1021/32150 (epoch 1.588), train_loss = 2.34485430, grad/param norm = 2.8049e-01, time/batch = 0.6943s	
1022/32150 (epoch 1.589), train_loss = 2.40120539, grad/param norm = 3.3546e-01, time/batch = 0.6885s	
1023/32150 (epoch 1.591), train_loss = 2.70132104, grad/param norm = 2.4128e-01, time/batch = 0.6855s	
1024/32150 (epoch 1.593), train_loss = 2.46486389, grad/param norm = 2.8717e-01, time/batch = 0.6968s	
1025/32150 (epoch 1.594), train_loss = 2.39963882, grad/param norm = 2.8058e-01, time/batch = 0.7067s	
1026/32150 (epoch 1.596), train_loss = 2.52113382, grad/param norm = 2.6882e-01, time/batch = 0.6947s	
1027/32150 (epoch 1.597), train_loss = 2.36948274, grad/param norm = 2.1619e-01, time/batch = 0.6855s	
1028/32150 (epoch 1.599), train_loss = 2.39518970, grad/param norm = 2.1567e-01, time/batch = 0.6897s	
1029/32150 (epoch 1.600), train_loss = 2.40493111, grad/param norm = 2.4336e-01, time/batch = 0.6866s	
1030/32150 (epoch 1.602), train_loss = 2.58871502, grad/param norm = 2.7601e-01, time/batch = 0.6875s	
1031/32150 (epoch 1.603), train_loss = 2.39094175, grad/param norm = 2.6129e-01, time/batch = 0.6858s	
1032/32150 (epoch 1.605), train_loss = 2.39754907, grad/param norm = 2.6654e-01, time/batch = 0.6852s	
1033/32150 (epoch 1.607), train_loss = 2.60659315, grad/param norm = 2.2893e-01, time/batch = 0.6861s	
1034/32150 (epoch 1.608), train_loss = 2.22449909, grad/param norm = 2.5733e-01, time/batch = 0.6887s	
1035/32150 (epoch 1.610), train_loss = 2.41910023, grad/param norm = 2.3892e-01, time/batch = 0.6894s	
1036/32150 (epoch 1.611), train_loss = 2.29855371, grad/param norm = 2.6120e-01, time/batch = 0.6900s	
1037/32150 (epoch 1.613), train_loss = 2.28596275, grad/param norm = 2.6949e-01, time/batch = 0.6922s	
1038/32150 (epoch 1.614), train_loss = 2.36913430, grad/param norm = 2.8385e-01, time/batch = 0.6927s	
1039/32150 (epoch 1.616), train_loss = 2.50629366, grad/param norm = 2.7995e-01, time/batch = 0.6842s	
1040/32150 (epoch 1.617), train_loss = 2.34746681, grad/param norm = 3.3552e-01, time/batch = 0.6870s	
1041/32150 (epoch 1.619), train_loss = 2.30329938, grad/param norm = 3.8686e-01, time/batch = 0.6953s	
1042/32150 (epoch 1.621), train_loss = 2.41727960, grad/param norm = 3.3333e-01, time/batch = 0.6842s	
1043/32150 (epoch 1.622), train_loss = 2.25437106, grad/param norm = 3.0654e-01, time/batch = 0.6922s	
1044/32150 (epoch 1.624), train_loss = 2.45259439, grad/param norm = 2.7052e-01, time/batch = 0.6984s	
1045/32150 (epoch 1.625), train_loss = 2.29098629, grad/param norm = 2.7265e-01, time/batch = 0.6964s	
1046/32150 (epoch 1.627), train_loss = 2.37516222, grad/param norm = 2.5671e-01, time/batch = 0.6880s	
1047/32150 (epoch 1.628), train_loss = 2.36364327, grad/param norm = 2.4448e-01, time/batch = 0.6864s	
1048/32150 (epoch 1.630), train_loss = 2.31615050, grad/param norm = 2.3304e-01, time/batch = 0.6889s	
1049/32150 (epoch 1.631), train_loss = 2.49362863, grad/param norm = 2.3449e-01, time/batch = 0.6874s	
1050/32150 (epoch 1.633), train_loss = 2.33935604, grad/param norm = 2.6132e-01, time/batch = 0.6832s	
1051/32150 (epoch 1.635), train_loss = 2.41079151, grad/param norm = 2.7042e-01, time/batch = 0.6848s	
1052/32150 (epoch 1.636), train_loss = 2.47970726, grad/param norm = 2.2568e-01, time/batch = 0.6841s	
1053/32150 (epoch 1.638), train_loss = 2.48239382, grad/param norm = 3.5286e-01, time/batch = 0.6832s	
1054/32150 (epoch 1.639), train_loss = 2.58754736, grad/param norm = 2.6625e-01, time/batch = 0.6877s	
1055/32150 (epoch 1.641), train_loss = 2.40513955, grad/param norm = 2.3766e-01, time/batch = 0.6866s	
1056/32150 (epoch 1.642), train_loss = 2.47408806, grad/param norm = 2.4705e-01, time/batch = 0.6914s	
1057/32150 (epoch 1.644), train_loss = 2.39976427, grad/param norm = 2.6385e-01, time/batch = 0.6873s	
1058/32150 (epoch 1.645), train_loss = 2.55450807, grad/param norm = 2.6315e-01, time/batch = 0.6957s	
1059/32150 (epoch 1.647), train_loss = 2.47049841, grad/param norm = 2.9676e-01, time/batch = 0.6955s	
1060/32150 (epoch 1.649), train_loss = 2.30416227, grad/param norm = 2.2940e-01, time/batch = 0.6972s	
1061/32150 (epoch 1.650), train_loss = 2.35851594, grad/param norm = 2.7073e-01, time/batch = 0.6928s	
1062/32150 (epoch 1.652), train_loss = 2.45644399, grad/param norm = 2.5861e-01, time/batch = 0.6927s	
1063/32150 (epoch 1.653), train_loss = 2.47017692, grad/param norm = 3.2174e-01, time/batch = 0.7039s	
1064/32150 (epoch 1.655), train_loss = 2.77558472, grad/param norm = 4.6036e-01, time/batch = 0.7005s	
1065/32150 (epoch 1.656), train_loss = 2.69212745, grad/param norm = 4.2841e-01, time/batch = 0.6883s	
1066/32150 (epoch 1.658), train_loss = 2.55726139, grad/param norm = 3.2258e-01, time/batch = 0.6900s	
1067/32150 (epoch 1.659), train_loss = 2.71572486, grad/param norm = 3.3186e-01, time/batch = 0.7001s	
1068/32150 (epoch 1.661), train_loss = 2.49864648, grad/param norm = 2.7755e-01, time/batch = 0.6941s	
1069/32150 (epoch 1.663), train_loss = 2.35210254, grad/param norm = 2.5030e-01, time/batch = 0.6938s	
1070/32150 (epoch 1.664), train_loss = 2.29261573, grad/param norm = 2.8260e-01, time/batch = 0.6946s	
1071/32150 (epoch 1.666), train_loss = 2.53541506, grad/param norm = 2.6502e-01, time/batch = 0.6990s	
1072/32150 (epoch 1.667), train_loss = 2.49305247, grad/param norm = 2.4457e-01, time/batch = 0.6922s	
1073/32150 (epoch 1.669), train_loss = 2.45843378, grad/param norm = 2.7985e-01, time/batch = 0.6940s	
1074/32150 (epoch 1.670), train_loss = 2.43665420, grad/param norm = 2.5450e-01, time/batch = 0.6890s	
1075/32150 (epoch 1.672), train_loss = 2.46076319, grad/param norm = 2.4980e-01, time/batch = 0.6962s	
1076/32150 (epoch 1.673), train_loss = 2.44155391, grad/param norm = 2.1916e-01, time/batch = 0.6850s	
1077/32150 (epoch 1.675), train_loss = 2.49328953, grad/param norm = 2.3406e-01, time/batch = 0.6936s	
1078/32150 (epoch 1.677), train_loss = 2.49873181, grad/param norm = 2.8334e-01, time/batch = 0.6920s	
1079/32150 (epoch 1.678), train_loss = 2.51137516, grad/param norm = 2.9929e-01, time/batch = 0.6994s	
1080/32150 (epoch 1.680), train_loss = 2.47035509, grad/param norm = 2.6342e-01, time/batch = 0.6868s	
1081/32150 (epoch 1.681), train_loss = 2.35377950, grad/param norm = 3.0751e-01, time/batch = 0.6824s	
1082/32150 (epoch 1.683), train_loss = 2.43357123, grad/param norm = 2.2724e-01, time/batch = 0.6840s	
1083/32150 (epoch 1.684), train_loss = 2.52717207, grad/param norm = 2.4087e-01, time/batch = 0.6865s	
1084/32150 (epoch 1.686), train_loss = 2.38351302, grad/param norm = 2.7255e-01, time/batch = 0.6818s	
1085/32150 (epoch 1.687), train_loss = 2.40714089, grad/param norm = 2.4508e-01, time/batch = 0.6838s	
1086/32150 (epoch 1.689), train_loss = 2.25991421, grad/param norm = 2.1879e-01, time/batch = 0.6778s	
1087/32150 (epoch 1.691), train_loss = 2.14688336, grad/param norm = 2.2329e-01, time/batch = 0.6896s	
1088/32150 (epoch 1.692), train_loss = 2.28710236, grad/param norm = 2.5144e-01, time/batch = 0.6816s	
1089/32150 (epoch 1.694), train_loss = 2.32338244, grad/param norm = 2.2524e-01, time/batch = 0.6941s	
1090/32150 (epoch 1.695), train_loss = 2.37009481, grad/param norm = 2.3591e-01, time/batch = 0.6924s	
1091/32150 (epoch 1.697), train_loss = 2.33693435, grad/param norm = 2.2878e-01, time/batch = 0.7035s	
1092/32150 (epoch 1.698), train_loss = 2.39284000, grad/param norm = 2.3283e-01, time/batch = 0.7209s	
1093/32150 (epoch 1.700), train_loss = 2.39353186, grad/param norm = 2.6535e-01, time/batch = 0.7291s	
1094/32150 (epoch 1.701), train_loss = 2.30475926, grad/param norm = 2.7268e-01, time/batch = 0.7243s	
1095/32150 (epoch 1.703), train_loss = 2.44152031, grad/param norm = 2.5462e-01, time/batch = 0.7081s	
1096/32150 (epoch 1.705), train_loss = 2.42201554, grad/param norm = 2.6550e-01, time/batch = 0.7140s	
1097/32150 (epoch 1.706), train_loss = 2.42369612, grad/param norm = 2.3190e-01, time/batch = 0.7092s	
1098/32150 (epoch 1.708), train_loss = 2.57254812, grad/param norm = 3.0922e-01, time/batch = 0.7037s	
1099/32150 (epoch 1.709), train_loss = 2.40058344, grad/param norm = 2.9845e-01, time/batch = 0.7011s	
1100/32150 (epoch 1.711), train_loss = 2.35690681, grad/param norm = 3.1537e-01, time/batch = 0.7014s	
1101/32150 (epoch 1.712), train_loss = 2.61955684, grad/param norm = 3.3571e-01, time/batch = 0.7064s	
1102/32150 (epoch 1.714), train_loss = 2.41901011, grad/param norm = 2.7640e-01, time/batch = 0.7092s	
1103/32150 (epoch 1.715), train_loss = 2.46911237, grad/param norm = 3.0478e-01, time/batch = 0.7012s	
1104/32150 (epoch 1.717), train_loss = 2.44472686, grad/param norm = 3.1223e-01, time/batch = 0.7180s	
1105/32150 (epoch 1.719), train_loss = 2.37214910, grad/param norm = 2.5293e-01, time/batch = 0.7036s	
1106/32150 (epoch 1.720), train_loss = 2.36125091, grad/param norm = 2.2870e-01, time/batch = 0.7002s	
1107/32150 (epoch 1.722), train_loss = 2.33730767, grad/param norm = 2.4781e-01, time/batch = 0.7148s	
1108/32150 (epoch 1.723), train_loss = 2.46338591, grad/param norm = 2.4660e-01, time/batch = 0.6995s	
1109/32150 (epoch 1.725), train_loss = 2.35028767, grad/param norm = 2.8975e-01, time/batch = 0.6960s	
1110/32150 (epoch 1.726), train_loss = 2.37251766, grad/param norm = 2.8941e-01, time/batch = 0.6955s	
1111/32150 (epoch 1.728), train_loss = 2.32008327, grad/param norm = 3.3132e-01, time/batch = 0.7050s	
1112/32150 (epoch 1.729), train_loss = 2.41227302, grad/param norm = 3.4281e-01, time/batch = 0.7050s	
1113/32150 (epoch 1.731), train_loss = 2.42613188, grad/param norm = 3.3308e-01, time/batch = 0.6946s	
1114/32150 (epoch 1.733), train_loss = 2.35901561, grad/param norm = 2.5874e-01, time/batch = 0.6972s	
1115/32150 (epoch 1.734), train_loss = 2.39420906, grad/param norm = 2.8752e-01, time/batch = 0.6911s	
1116/32150 (epoch 1.736), train_loss = 2.21524842, grad/param norm = 2.3322e-01, time/batch = 0.6914s	
1117/32150 (epoch 1.737), train_loss = 2.41156535, grad/param norm = 2.5623e-01, time/batch = 0.6961s	
1118/32150 (epoch 1.739), train_loss = 2.31212739, grad/param norm = 2.3383e-01, time/batch = 0.6977s	
1119/32150 (epoch 1.740), train_loss = 2.16244420, grad/param norm = 2.8851e-01, time/batch = 0.6880s	
1120/32150 (epoch 1.742), train_loss = 2.16239093, grad/param norm = 3.0427e-01, time/batch = 0.6890s	
1121/32150 (epoch 1.743), train_loss = 2.25338750, grad/param norm = 2.7881e-01, time/batch = 0.6972s	
1122/32150 (epoch 1.745), train_loss = 2.19740582, grad/param norm = 2.4361e-01, time/batch = 0.6910s	
1123/32150 (epoch 1.747), train_loss = 2.40311265, grad/param norm = 2.5619e-01, time/batch = 0.6899s	
1124/32150 (epoch 1.748), train_loss = 2.53010718, grad/param norm = 2.2973e-01, time/batch = 0.6947s	
1125/32150 (epoch 1.750), train_loss = 2.38375494, grad/param norm = 2.4284e-01, time/batch = 0.6878s	
1126/32150 (epoch 1.751), train_loss = 2.32814799, grad/param norm = 2.7228e-01, time/batch = 0.7027s	
1127/32150 (epoch 1.753), train_loss = 2.33283617, grad/param norm = 2.5798e-01, time/batch = 0.6916s	
1128/32150 (epoch 1.754), train_loss = 2.41836438, grad/param norm = 2.3682e-01, time/batch = 0.6837s	
1129/32150 (epoch 1.756), train_loss = 2.23094860, grad/param norm = 2.5595e-01, time/batch = 0.6840s	
1130/32150 (epoch 1.757), train_loss = 2.48514545, grad/param norm = 2.5058e-01, time/batch = 0.6804s	
1131/32150 (epoch 1.759), train_loss = 2.42447900, grad/param norm = 3.0446e-01, time/batch = 0.6811s	
1132/32150 (epoch 1.760), train_loss = 2.33672545, grad/param norm = 2.2419e-01, time/batch = 0.6784s	
1133/32150 (epoch 1.762), train_loss = 2.38934436, grad/param norm = 2.4091e-01, time/batch = 0.6864s	
1134/32150 (epoch 1.764), train_loss = 2.57384553, grad/param norm = 2.8798e-01, time/batch = 0.6945s	
1135/32150 (epoch 1.765), train_loss = 2.22811603, grad/param norm = 2.7924e-01, time/batch = 0.6838s	
1136/32150 (epoch 1.767), train_loss = 2.45330189, grad/param norm = 2.7364e-01, time/batch = 0.6902s	
1137/32150 (epoch 1.768), train_loss = 2.37776732, grad/param norm = 2.4962e-01, time/batch = 0.6889s	
1138/32150 (epoch 1.770), train_loss = 2.39933961, grad/param norm = 2.8356e-01, time/batch = 0.6861s	
1139/32150 (epoch 1.771), train_loss = 2.60340887, grad/param norm = 3.3955e-01, time/batch = 0.6858s	
1140/32150 (epoch 1.773), train_loss = 2.60307937, grad/param norm = 3.1698e-01, time/batch = 0.6842s	
1141/32150 (epoch 1.774), train_loss = 2.39443501, grad/param norm = 2.2851e-01, time/batch = 0.6876s	
1142/32150 (epoch 1.776), train_loss = 2.44537808, grad/param norm = 2.9106e-01, time/batch = 0.7079s	
1143/32150 (epoch 1.778), train_loss = 2.20766917, grad/param norm = 2.8752e-01, time/batch = 0.7082s	
1144/32150 (epoch 1.779), train_loss = 2.41981675, grad/param norm = 3.4273e-01, time/batch = 0.7015s	
1145/32150 (epoch 1.781), train_loss = 2.46560734, grad/param norm = 3.2337e-01, time/batch = 0.7020s	
1146/32150 (epoch 1.782), train_loss = 2.40063010, grad/param norm = 2.8737e-01, time/batch = 0.7048s	
1147/32150 (epoch 1.784), train_loss = 2.54045698, grad/param norm = 2.3266e-01, time/batch = 0.6863s	
1148/32150 (epoch 1.785), train_loss = 2.34807572, grad/param norm = 2.5978e-01, time/batch = 0.6893s	
1149/32150 (epoch 1.787), train_loss = 2.38785024, grad/param norm = 2.7557e-01, time/batch = 0.6863s	
1150/32150 (epoch 1.788), train_loss = 2.38143358, grad/param norm = 2.9505e-01, time/batch = 0.6814s	
1151/32150 (epoch 1.790), train_loss = 2.35056616, grad/param norm = 2.5843e-01, time/batch = 0.6796s	
1152/32150 (epoch 1.792), train_loss = 2.33723728, grad/param norm = 2.3334e-01, time/batch = 0.6809s	
1153/32150 (epoch 1.793), train_loss = 2.41170557, grad/param norm = 2.3884e-01, time/batch = 0.6803s	
1154/32150 (epoch 1.795), train_loss = 2.26156522, grad/param norm = 2.6364e-01, time/batch = 0.6799s	
1155/32150 (epoch 1.796), train_loss = 2.29392353, grad/param norm = 2.2846e-01, time/batch = 0.6799s	
1156/32150 (epoch 1.798), train_loss = 2.20274409, grad/param norm = 2.1552e-01, time/batch = 0.6868s	
1157/32150 (epoch 1.799), train_loss = 2.36528958, grad/param norm = 2.2592e-01, time/batch = 0.6964s	
1158/32150 (epoch 1.801), train_loss = 2.57564606, grad/param norm = 2.5717e-01, time/batch = 0.6834s	
1159/32150 (epoch 1.802), train_loss = 2.37538007, grad/param norm = 2.3532e-01, time/batch = 0.7036s	
1160/32150 (epoch 1.804), train_loss = 2.52048175, grad/param norm = 2.3340e-01, time/batch = 0.6975s	
1161/32150 (epoch 1.806), train_loss = 2.49229689, grad/param norm = 2.3739e-01, time/batch = 0.6839s	
1162/32150 (epoch 1.807), train_loss = 2.46004245, grad/param norm = 2.6805e-01, time/batch = 0.6840s	
1163/32150 (epoch 1.809), train_loss = 2.40481050, grad/param norm = 3.3982e-01, time/batch = 0.6909s	
1164/32150 (epoch 1.810), train_loss = 2.39913849, grad/param norm = 2.8459e-01, time/batch = 0.6849s	
1165/32150 (epoch 1.812), train_loss = 2.33965308, grad/param norm = 2.5584e-01, time/batch = 0.6864s	
1166/32150 (epoch 1.813), train_loss = 2.44267243, grad/param norm = 2.6564e-01, time/batch = 0.6939s	
1167/32150 (epoch 1.815), train_loss = 2.13912416, grad/param norm = 2.5531e-01, time/batch = 0.6898s	
1168/32150 (epoch 1.816), train_loss = 2.24696788, grad/param norm = 3.2223e-01, time/batch = 0.6899s	
1169/32150 (epoch 1.818), train_loss = 2.18318934, grad/param norm = 2.5270e-01, time/batch = 0.6878s	
1170/32150 (epoch 1.820), train_loss = 2.38372026, grad/param norm = 2.8980e-01, time/batch = 0.6853s	
1171/32150 (epoch 1.821), train_loss = 2.48062256, grad/param norm = 2.4499e-01, time/batch = 0.6857s	
1172/32150 (epoch 1.823), train_loss = 2.34397693, grad/param norm = 2.6354e-01, time/batch = 0.6851s	
1173/32150 (epoch 1.824), train_loss = 2.43573955, grad/param norm = 2.5027e-01, time/batch = 0.6892s	
1174/32150 (epoch 1.826), train_loss = 2.27266150, grad/param norm = 3.0395e-01, time/batch = 0.7048s	
1175/32150 (epoch 1.827), train_loss = 2.50740407, grad/param norm = 2.7703e-01, time/batch = 0.6815s	
1176/32150 (epoch 1.829), train_loss = 2.37025498, grad/param norm = 2.5759e-01, time/batch = 0.6814s	
1177/32150 (epoch 1.830), train_loss = 2.30957477, grad/param norm = 2.4600e-01, time/batch = 0.6807s	
1178/32150 (epoch 1.832), train_loss = 2.32891535, grad/param norm = 2.6764e-01, time/batch = 0.6854s	
1179/32150 (epoch 1.834), train_loss = 2.49263378, grad/param norm = 2.4188e-01, time/batch = 0.7053s	
1180/32150 (epoch 1.835), train_loss = 2.33802946, grad/param norm = 2.8778e-01, time/batch = 0.7032s	
1181/32150 (epoch 1.837), train_loss = 2.39327927, grad/param norm = 2.5043e-01, time/batch = 0.6922s	
1182/32150 (epoch 1.838), train_loss = 2.52458284, grad/param norm = 2.4235e-01, time/batch = 0.6955s	
1183/32150 (epoch 1.840), train_loss = 2.27916532, grad/param norm = 2.4640e-01, time/batch = 0.6915s	
1184/32150 (epoch 1.841), train_loss = 2.31933602, grad/param norm = 2.3702e-01, time/batch = 0.6959s	
1185/32150 (epoch 1.843), train_loss = 2.31692955, grad/param norm = 3.1463e-01, time/batch = 0.6824s	
1186/32150 (epoch 1.844), train_loss = 2.16939072, grad/param norm = 3.1291e-01, time/batch = 0.6976s	
1187/32150 (epoch 1.846), train_loss = 2.10977292, grad/param norm = 2.5991e-01, time/batch = 0.6880s	
1188/32150 (epoch 1.848), train_loss = 2.47533200, grad/param norm = 2.9519e-01, time/batch = 0.7005s	
1189/32150 (epoch 1.849), train_loss = 2.55292491, grad/param norm = 3.7415e-01, time/batch = 0.6917s	
1190/32150 (epoch 1.851), train_loss = 2.35678404, grad/param norm = 3.4415e-01, time/batch = 0.6866s	
1191/32150 (epoch 1.852), train_loss = 2.57046565, grad/param norm = 4.2203e-01, time/batch = 0.6884s	
1192/32150 (epoch 1.854), train_loss = 2.58052601, grad/param norm = 2.1915e-01, time/batch = 0.6873s	
1193/32150 (epoch 1.855), train_loss = 2.50615843, grad/param norm = 2.4052e-01, time/batch = 0.6796s	
1194/32150 (epoch 1.857), train_loss = 2.45251817, grad/param norm = 2.3254e-01, time/batch = 0.6804s	
1195/32150 (epoch 1.858), train_loss = 2.67932795, grad/param norm = 2.6604e-01, time/batch = 0.6874s	
1196/32150 (epoch 1.860), train_loss = 2.44483443, grad/param norm = 2.8181e-01, time/batch = 0.6837s	
1197/32150 (epoch 1.862), train_loss = 2.61224445, grad/param norm = 2.9314e-01, time/batch = 0.6805s	
1198/32150 (epoch 1.863), train_loss = 2.36752489, grad/param norm = 2.7637e-01, time/batch = 0.6749s	
1199/32150 (epoch 1.865), train_loss = 2.19465737, grad/param norm = 2.2970e-01, time/batch = 0.6781s	
1200/32150 (epoch 1.866), train_loss = 2.25087556, grad/param norm = 2.0843e-01, time/batch = 0.6772s	
1201/32150 (epoch 1.868), train_loss = 2.46817194, grad/param norm = 2.4738e-01, time/batch = 0.6831s	
1202/32150 (epoch 1.869), train_loss = 2.23265754, grad/param norm = 3.1334e-01, time/batch = 0.6879s	
1203/32150 (epoch 1.871), train_loss = 2.29133544, grad/param norm = 3.2445e-01, time/batch = 0.6975s	
1204/32150 (epoch 1.872), train_loss = 2.58015867, grad/param norm = 3.3962e-01, time/batch = 0.6890s	
1205/32150 (epoch 1.874), train_loss = 2.30928094, grad/param norm = 2.6123e-01, time/batch = 0.6800s	
1206/32150 (epoch 1.876), train_loss = 2.18879557, grad/param norm = 2.4337e-01, time/batch = 0.6810s	
1207/32150 (epoch 1.877), train_loss = 2.34779774, grad/param norm = 2.8328e-01, time/batch = 0.6788s	
1208/32150 (epoch 1.879), train_loss = 2.39949498, grad/param norm = 2.5453e-01, time/batch = 0.6791s	
1209/32150 (epoch 1.880), train_loss = 2.42917217, grad/param norm = 2.6603e-01, time/batch = 0.6778s	
1210/32150 (epoch 1.882), train_loss = 2.29561150, grad/param norm = 2.1632e-01, time/batch = 0.6829s	
1211/32150 (epoch 1.883), train_loss = 2.50038324, grad/param norm = 2.9997e-01, time/batch = 0.6817s	
1212/32150 (epoch 1.885), train_loss = 2.29141701, grad/param norm = 3.1842e-01, time/batch = 0.6789s	
1213/32150 (epoch 1.886), train_loss = 2.36753680, grad/param norm = 2.5939e-01, time/batch = 0.7099s	
1214/32150 (epoch 1.888), train_loss = 2.30148946, grad/param norm = 2.2314e-01, time/batch = 0.6908s	
1215/32150 (epoch 1.890), train_loss = 2.48988138, grad/param norm = 2.3180e-01, time/batch = 0.6813s	
1216/32150 (epoch 1.891), train_loss = 2.42873041, grad/param norm = 2.3888e-01, time/batch = 0.6865s	
1217/32150 (epoch 1.893), train_loss = 2.33085606, grad/param norm = 2.3373e-01, time/batch = 0.6795s	
1218/32150 (epoch 1.894), train_loss = 2.23034997, grad/param norm = 2.6077e-01, time/batch = 0.6786s	
1219/32150 (epoch 1.896), train_loss = 2.34541997, grad/param norm = 2.4722e-01, time/batch = 0.6770s	
1220/32150 (epoch 1.897), train_loss = 2.38627488, grad/param norm = 2.9124e-01, time/batch = 0.6792s	
1221/32150 (epoch 1.899), train_loss = 2.35732883, grad/param norm = 2.7669e-01, time/batch = 0.6803s	
1222/32150 (epoch 1.900), train_loss = 2.41642298, grad/param norm = 3.0788e-01, time/batch = 0.6756s	
1223/32150 (epoch 1.902), train_loss = 2.40997846, grad/param norm = 3.4026e-01, time/batch = 0.6752s	
1224/32150 (epoch 1.904), train_loss = 2.42273595, grad/param norm = 3.2107e-01, time/batch = 0.6796s	
1225/32150 (epoch 1.905), train_loss = 2.52539618, grad/param norm = 2.5996e-01, time/batch = 0.6772s	
1226/32150 (epoch 1.907), train_loss = 2.42186544, grad/param norm = 2.9894e-01, time/batch = 0.6785s	
1227/32150 (epoch 1.908), train_loss = 2.43508765, grad/param norm = 2.5899e-01, time/batch = 0.6858s	
1228/32150 (epoch 1.910), train_loss = 2.34063467, grad/param norm = 2.8278e-01, time/batch = 0.6778s	
1229/32150 (epoch 1.911), train_loss = 2.19908838, grad/param norm = 2.3840e-01, time/batch = 0.6793s	
1230/32150 (epoch 1.913), train_loss = 2.35163304, grad/param norm = 2.3070e-01, time/batch = 0.6802s	
1231/32150 (epoch 1.914), train_loss = 2.41301535, grad/param norm = 2.2485e-01, time/batch = 0.6861s	
1232/32150 (epoch 1.916), train_loss = 2.26406814, grad/param norm = 2.4826e-01, time/batch = 0.6822s	
1233/32150 (epoch 1.918), train_loss = 2.42059460, grad/param norm = 2.9686e-01, time/batch = 0.6806s	
1234/32150 (epoch 1.919), train_loss = 2.44801148, grad/param norm = 2.7193e-01, time/batch = 0.6852s	
1235/32150 (epoch 1.921), train_loss = 2.45952585, grad/param norm = 2.6193e-01, time/batch = 0.6813s	
1236/32150 (epoch 1.922), train_loss = 2.29503369, grad/param norm = 3.1346e-01, time/batch = 0.6848s	
1237/32150 (epoch 1.924), train_loss = 2.39341956, grad/param norm = 3.4167e-01, time/batch = 0.6799s	
1238/32150 (epoch 1.925), train_loss = 2.37653601, grad/param norm = 2.2830e-01, time/batch = 0.6830s	
1239/32150 (epoch 1.927), train_loss = 2.22778299, grad/param norm = 2.3621e-01, time/batch = 0.6808s	
1240/32150 (epoch 1.928), train_loss = 2.46785766, grad/param norm = 2.5886e-01, time/batch = 0.6899s	
1241/32150 (epoch 1.930), train_loss = 2.34279829, grad/param norm = 2.7830e-01, time/batch = 0.6945s	
1242/32150 (epoch 1.932), train_loss = 2.35621247, grad/param norm = 2.6090e-01, time/batch = 0.6853s	
1243/32150 (epoch 1.933), train_loss = 2.41734829, grad/param norm = 2.3760e-01, time/batch = 0.6828s	
1244/32150 (epoch 1.935), train_loss = 2.22511050, grad/param norm = 2.4826e-01, time/batch = 0.6846s	
1245/32150 (epoch 1.936), train_loss = 2.35690172, grad/param norm = 2.1324e-01, time/batch = 0.6836s	
1246/32150 (epoch 1.938), train_loss = 2.22474429, grad/param norm = 2.4158e-01, time/batch = 0.6809s	
1247/32150 (epoch 1.939), train_loss = 2.50932554, grad/param norm = 2.6920e-01, time/batch = 0.6811s	
1248/32150 (epoch 1.941), train_loss = 2.21945627, grad/param norm = 3.0690e-01, time/batch = 0.6820s	
1249/32150 (epoch 1.942), train_loss = 2.49754527, grad/param norm = 3.1335e-01, time/batch = 0.6803s	
1250/32150 (epoch 1.944), train_loss = 2.31184075, grad/param norm = 3.3279e-01, time/batch = 0.6869s	
1251/32150 (epoch 1.946), train_loss = 2.29750716, grad/param norm = 2.5715e-01, time/batch = 0.7038s	
1252/32150 (epoch 1.947), train_loss = 2.38639625, grad/param norm = 2.5221e-01, time/batch = 0.6880s	
1253/32150 (epoch 1.949), train_loss = 2.35135669, grad/param norm = 2.4442e-01, time/batch = 0.6870s	
1254/32150 (epoch 1.950), train_loss = 2.34381028, grad/param norm = 2.3719e-01, time/batch = 0.6891s	
1255/32150 (epoch 1.952), train_loss = 2.13626447, grad/param norm = 2.7572e-01, time/batch = 0.6914s	
1256/32150 (epoch 1.953), train_loss = 2.14916877, grad/param norm = 2.6419e-01, time/batch = 0.6862s	
1257/32150 (epoch 1.955), train_loss = 2.14579739, grad/param norm = 2.3677e-01, time/batch = 0.6937s	
1258/32150 (epoch 1.956), train_loss = 2.17704251, grad/param norm = 2.6500e-01, time/batch = 0.6856s	
1259/32150 (epoch 1.958), train_loss = 2.23981514, grad/param norm = 2.4140e-01, time/batch = 0.6852s	
1260/32150 (epoch 1.960), train_loss = 2.34143964, grad/param norm = 2.2970e-01, time/batch = 0.6849s	
1261/32150 (epoch 1.961), train_loss = 2.31892906, grad/param norm = 2.3500e-01, time/batch = 0.6907s	
1262/32150 (epoch 1.963), train_loss = 2.34363930, grad/param norm = 2.4709e-01, time/batch = 0.6851s	
1263/32150 (epoch 1.964), train_loss = 2.38026148, grad/param norm = 2.6487e-01, time/batch = 0.6835s	
1264/32150 (epoch 1.966), train_loss = 2.47852755, grad/param norm = 2.1892e-01, time/batch = 0.6826s	
1265/32150 (epoch 1.967), train_loss = 2.23989208, grad/param norm = 2.5526e-01, time/batch = 0.6998s	
1266/32150 (epoch 1.969), train_loss = 2.29243187, grad/param norm = 2.1859e-01, time/batch = 0.7075s	
1267/32150 (epoch 1.970), train_loss = 2.31402722, grad/param norm = 2.7973e-01, time/batch = 0.7025s	
1268/32150 (epoch 1.972), train_loss = 2.44210333, grad/param norm = 2.3627e-01, time/batch = 0.6995s	
1269/32150 (epoch 1.974), train_loss = 2.51454012, grad/param norm = 3.7786e-01, time/batch = 0.6931s	
1270/32150 (epoch 1.975), train_loss = 2.27834792, grad/param norm = 2.9099e-01, time/batch = 0.6900s	
1271/32150 (epoch 1.977), train_loss = 2.32528455, grad/param norm = 2.4309e-01, time/batch = 0.6881s	
1272/32150 (epoch 1.978), train_loss = 2.23179659, grad/param norm = 2.4220e-01, time/batch = 0.6814s	
1273/32150 (epoch 1.980), train_loss = 2.33314120, grad/param norm = 2.6604e-01, time/batch = 0.6800s	
1274/32150 (epoch 1.981), train_loss = 2.34038056, grad/param norm = 2.4421e-01, time/batch = 0.6841s	
1275/32150 (epoch 1.983), train_loss = 2.27018890, grad/param norm = 2.4282e-01, time/batch = 0.6954s	
1276/32150 (epoch 1.984), train_loss = 2.26634929, grad/param norm = 2.5092e-01, time/batch = 0.6877s	
1277/32150 (epoch 1.986), train_loss = 2.25494714, grad/param norm = 2.2408e-01, time/batch = 0.6920s	
1278/32150 (epoch 1.988), train_loss = 2.13226735, grad/param norm = 2.6923e-01, time/batch = 0.6823s	
1279/32150 (epoch 1.989), train_loss = 2.33423002, grad/param norm = 2.7864e-01, time/batch = 0.6936s	
1280/32150 (epoch 1.991), train_loss = 2.27453683, grad/param norm = 2.3573e-01, time/batch = 0.7095s	
1281/32150 (epoch 1.992), train_loss = 2.18013598, grad/param norm = 2.2438e-01, time/batch = 0.6937s	
1282/32150 (epoch 1.994), train_loss = 2.33826134, grad/param norm = 2.7021e-01, time/batch = 0.6867s	
1283/32150 (epoch 1.995), train_loss = 2.39636263, grad/param norm = 3.5364e-01, time/batch = 0.6848s	
1284/32150 (epoch 1.997), train_loss = 2.48868512, grad/param norm = 2.8046e-01, time/batch = 0.6863s	
1285/32150 (epoch 1.998), train_loss = 2.33093973, grad/param norm = 2.7089e-01, time/batch = 0.6884s	
1286/32150 (epoch 2.000), train_loss = 2.43263659, grad/param norm = 2.5890e-01, time/batch = 0.6879s	
1287/32150 (epoch 2.002), train_loss = 2.64406052, grad/param norm = 2.4946e-01, time/batch = 0.6872s	
1288/32150 (epoch 2.003), train_loss = 2.52498349, grad/param norm = 2.4446e-01, time/batch = 0.6858s	
1289/32150 (epoch 2.005), train_loss = 2.25679776, grad/param norm = 2.1953e-01, time/batch = 0.6863s	
1290/32150 (epoch 2.006), train_loss = 2.35333981, grad/param norm = 2.4883e-01, time/batch = 0.6830s	
1291/32150 (epoch 2.008), train_loss = 2.39362552, grad/param norm = 3.0387e-01, time/batch = 0.6855s	
1292/32150 (epoch 2.009), train_loss = 2.11716209, grad/param norm = 2.4442e-01, time/batch = 0.6802s	
1293/32150 (epoch 2.011), train_loss = 2.38074678, grad/param norm = 2.6628e-01, time/batch = 0.6827s	
1294/32150 (epoch 2.012), train_loss = 2.30249581, grad/param norm = 3.7228e-01, time/batch = 0.6986s	
1295/32150 (epoch 2.014), train_loss = 2.36771221, grad/param norm = 2.4935e-01, time/batch = 0.6935s	
1296/32150 (epoch 2.016), train_loss = 2.36617815, grad/param norm = 2.8590e-01, time/batch = 0.6934s	
1297/32150 (epoch 2.017), train_loss = 2.37187132, grad/param norm = 2.5030e-01, time/batch = 0.6960s	
1298/32150 (epoch 2.019), train_loss = 2.32452580, grad/param norm = 2.3025e-01, time/batch = 0.6955s	
1299/32150 (epoch 2.020), train_loss = 2.35584703, grad/param norm = 2.7306e-01, time/batch = 0.6830s	
1300/32150 (epoch 2.022), train_loss = 2.27994106, grad/param norm = 2.6629e-01, time/batch = 0.6808s	
1301/32150 (epoch 2.023), train_loss = 2.21374898, grad/param norm = 2.5479e-01, time/batch = 0.6833s	
1302/32150 (epoch 2.025), train_loss = 2.48265512, grad/param norm = 2.3678e-01, time/batch = 0.6908s	
1303/32150 (epoch 2.026), train_loss = 2.39445862, grad/param norm = 2.6077e-01, time/batch = 0.6901s	
1304/32150 (epoch 2.028), train_loss = 2.18174317, grad/param norm = 2.9099e-01, time/batch = 0.6862s	
1305/32150 (epoch 2.030), train_loss = 2.38868189, grad/param norm = 2.3240e-01, time/batch = 0.6858s	
1306/32150 (epoch 2.031), train_loss = 2.33579404, grad/param norm = 2.1068e-01, time/batch = 0.6914s	
1307/32150 (epoch 2.033), train_loss = 2.54597036, grad/param norm = 2.3757e-01, time/batch = 0.6999s	
1308/32150 (epoch 2.034), train_loss = 2.37710420, grad/param norm = 2.0391e-01, time/batch = 0.6896s	
1309/32150 (epoch 2.036), train_loss = 2.35433998, grad/param norm = 3.3716e-01, time/batch = 0.6926s	
1310/32150 (epoch 2.037), train_loss = 2.33844023, grad/param norm = 2.8706e-01, time/batch = 0.6788s	
1311/32150 (epoch 2.039), train_loss = 2.38141599, grad/param norm = 2.3678e-01, time/batch = 0.6882s	
1312/32150 (epoch 2.040), train_loss = 2.45759131, grad/param norm = 2.3334e-01, time/batch = 0.6804s	
1313/32150 (epoch 2.042), train_loss = 2.41130138, grad/param norm = 2.1607e-01, time/batch = 0.6788s	
1314/32150 (epoch 2.044), train_loss = 2.41259830, grad/param norm = 2.2223e-01, time/batch = 0.6788s	
1315/32150 (epoch 2.045), train_loss = 2.20561008, grad/param norm = 2.4763e-01, time/batch = 0.6772s	
1316/32150 (epoch 2.047), train_loss = 2.25935148, grad/param norm = 2.7891e-01, time/batch = 0.6766s	
1317/32150 (epoch 2.048), train_loss = 2.38960306, grad/param norm = 2.6208e-01, time/batch = 0.6777s	
1318/32150 (epoch 2.050), train_loss = 2.32892633, grad/param norm = 2.3966e-01, time/batch = 0.6789s	
1319/32150 (epoch 2.051), train_loss = 2.41469664, grad/param norm = 2.4672e-01, time/batch = 0.6838s	
1320/32150 (epoch 2.053), train_loss = 2.26428185, grad/param norm = 2.3417e-01, time/batch = 0.6878s	
1321/32150 (epoch 2.054), train_loss = 2.27583535, grad/param norm = 2.1943e-01, time/batch = 0.6874s	
1322/32150 (epoch 2.056), train_loss = 2.30805870, grad/param norm = 2.3796e-01, time/batch = 0.6879s	
1323/32150 (epoch 2.058), train_loss = 2.19230033, grad/param norm = 2.2798e-01, time/batch = 0.6908s	
1324/32150 (epoch 2.059), train_loss = 2.30087836, grad/param norm = 2.5548e-01, time/batch = 0.6878s	
1325/32150 (epoch 2.061), train_loss = 2.39664610, grad/param norm = 2.4240e-01, time/batch = 0.6897s	
1326/32150 (epoch 2.062), train_loss = 2.34419687, grad/param norm = 2.9561e-01, time/batch = 0.6835s	
1327/32150 (epoch 2.064), train_loss = 2.17303496, grad/param norm = 2.5600e-01, time/batch = 0.6848s	
1328/32150 (epoch 2.065), train_loss = 2.38497088, grad/param norm = 2.6863e-01, time/batch = 0.6866s	
1329/32150 (epoch 2.067), train_loss = 2.39959955, grad/param norm = 2.8314e-01, time/batch = 0.6876s	
1330/32150 (epoch 2.068), train_loss = 2.34865885, grad/param norm = 2.5394e-01, time/batch = 0.6899s	
1331/32150 (epoch 2.070), train_loss = 2.24842308, grad/param norm = 2.4839e-01, time/batch = 0.6970s	
1332/32150 (epoch 2.072), train_loss = 2.36967152, grad/param norm = 2.5376e-01, time/batch = 0.6997s	
1333/32150 (epoch 2.073), train_loss = 2.36109983, grad/param norm = 2.4462e-01, time/batch = 0.6917s	
1334/32150 (epoch 2.075), train_loss = 2.32971829, grad/param norm = 2.5706e-01, time/batch = 0.6894s	
1335/32150 (epoch 2.076), train_loss = 2.44642019, grad/param norm = 2.8170e-01, time/batch = 0.6844s	
1336/32150 (epoch 2.078), train_loss = 2.44911338, grad/param norm = 2.4556e-01, time/batch = 0.6829s	
1337/32150 (epoch 2.079), train_loss = 2.23532501, grad/param norm = 2.1640e-01, time/batch = 0.6799s	
1338/32150 (epoch 2.081), train_loss = 2.27889897, grad/param norm = 2.9031e-01, time/batch = 0.6829s	
1339/32150 (epoch 2.082), train_loss = 2.30547358, grad/param norm = 2.8302e-01, time/batch = 0.6793s	
1340/32150 (epoch 2.084), train_loss = 2.36918367, grad/param norm = 3.2690e-01, time/batch = 0.6839s	
1341/32150 (epoch 2.086), train_loss = 2.27727149, grad/param norm = 3.2304e-01, time/batch = 0.6827s	
1342/32150 (epoch 2.087), train_loss = 2.22175196, grad/param norm = 3.0579e-01, time/batch = 0.6915s	
1343/32150 (epoch 2.089), train_loss = 2.28992519, grad/param norm = 2.9161e-01, time/batch = 0.6975s	
1344/32150 (epoch 2.090), train_loss = 2.21867254, grad/param norm = 2.0536e-01, time/batch = 0.6923s	
1345/32150 (epoch 2.092), train_loss = 2.31841263, grad/param norm = 2.2168e-01, time/batch = 0.6844s	
1346/32150 (epoch 2.093), train_loss = 2.18921041, grad/param norm = 2.2438e-01, time/batch = 0.6912s	
1347/32150 (epoch 2.095), train_loss = 2.26529680, grad/param norm = 2.2835e-01, time/batch = 0.6923s	
1348/32150 (epoch 2.096), train_loss = 2.29244332, grad/param norm = 2.3051e-01, time/batch = 0.6910s	
1349/32150 (epoch 2.098), train_loss = 2.23344692, grad/param norm = 2.6674e-01, time/batch = 0.6877s	
1350/32150 (epoch 2.100), train_loss = 2.25234912, grad/param norm = 2.5749e-01, time/batch = 0.6872s	
1351/32150 (epoch 2.101), train_loss = 2.17292341, grad/param norm = 2.6115e-01, time/batch = 0.6821s	
1352/32150 (epoch 2.103), train_loss = 2.31387095, grad/param norm = 2.1256e-01, time/batch = 0.6931s	
1353/32150 (epoch 2.104), train_loss = 2.18046992, grad/param norm = 2.3429e-01, time/batch = 0.7030s	
1354/32150 (epoch 2.106), train_loss = 2.30673698, grad/param norm = 2.0316e-01, time/batch = 0.6961s	
1355/32150 (epoch 2.107), train_loss = 2.35806254, grad/param norm = 2.4583e-01, time/batch = 0.6936s	
1356/32150 (epoch 2.109), train_loss = 2.29502161, grad/param norm = 2.2612e-01, time/batch = 0.7013s	
1357/32150 (epoch 2.110), train_loss = 2.31292698, grad/param norm = 2.7452e-01, time/batch = 0.7037s	
1358/32150 (epoch 2.112), train_loss = 2.27016163, grad/param norm = 2.3782e-01, time/batch = 0.7125s	
1359/32150 (epoch 2.114), train_loss = 2.25781907, grad/param norm = 2.0723e-01, time/batch = 0.7049s	
1360/32150 (epoch 2.115), train_loss = 2.34052868, grad/param norm = 2.2941e-01, time/batch = 0.6873s	
1361/32150 (epoch 2.117), train_loss = 2.32338419, grad/param norm = 2.3137e-01, time/batch = 0.6854s	
1362/32150 (epoch 2.118), train_loss = 2.22273193, grad/param norm = 2.5431e-01, time/batch = 0.7014s	
1363/32150 (epoch 2.120), train_loss = 2.44996389, grad/param norm = 2.9718e-01, time/batch = 0.6920s	
1364/32150 (epoch 2.121), train_loss = 2.15689850, grad/param norm = 2.3585e-01, time/batch = 0.6826s	
1365/32150 (epoch 2.123), train_loss = 2.32145220, grad/param norm = 2.4308e-01, time/batch = 0.6970s	
1366/32150 (epoch 2.124), train_loss = 2.31115928, grad/param norm = 2.0566e-01, time/batch = 0.7099s	
1367/32150 (epoch 2.126), train_loss = 2.32245701, grad/param norm = 2.1682e-01, time/batch = 0.6867s	
1368/32150 (epoch 2.128), train_loss = 2.29630568, grad/param norm = 2.3743e-01, time/batch = 0.6884s	
1369/32150 (epoch 2.129), train_loss = 2.29388823, grad/param norm = 2.2221e-01, time/batch = 0.6964s	
1370/32150 (epoch 2.131), train_loss = 2.38312447, grad/param norm = 3.0925e-01, time/batch = 0.6938s	
1371/32150 (epoch 2.132), train_loss = 2.25469025, grad/param norm = 3.1959e-01, time/batch = 0.6895s	
1372/32150 (epoch 2.134), train_loss = 2.31119094, grad/param norm = 2.3975e-01, time/batch = 0.6963s	
1373/32150 (epoch 2.135), train_loss = 2.25467812, grad/param norm = 2.2731e-01, time/batch = 0.6953s	
1374/32150 (epoch 2.137), train_loss = 2.21401884, grad/param norm = 2.3131e-01, time/batch = 0.6897s	
1375/32150 (epoch 2.138), train_loss = 2.32495207, grad/param norm = 2.3704e-01, time/batch = 0.6880s	
1376/32150 (epoch 2.140), train_loss = 2.32796501, grad/param norm = 2.9607e-01, time/batch = 0.6846s	
1377/32150 (epoch 2.142), train_loss = 2.33066204, grad/param norm = 2.6257e-01, time/batch = 0.6875s	
1378/32150 (epoch 2.143), train_loss = 2.16708934, grad/param norm = 3.0471e-01, time/batch = 0.6936s	
1379/32150 (epoch 2.145), train_loss = 2.09225750, grad/param norm = 2.5221e-01, time/batch = 0.6943s	
1380/32150 (epoch 2.146), train_loss = 2.07903559, grad/param norm = 2.5304e-01, time/batch = 0.6926s	
1381/32150 (epoch 2.148), train_loss = 1.99395608, grad/param norm = 2.5219e-01, time/batch = 0.6879s	
1382/32150 (epoch 2.149), train_loss = 2.35671413, grad/param norm = 2.4645e-01, time/batch = 0.6864s	
1383/32150 (epoch 2.151), train_loss = 2.20401531, grad/param norm = 3.0218e-01, time/batch = 0.6918s	
1384/32150 (epoch 2.152), train_loss = 2.34547790, grad/param norm = 2.4185e-01, time/batch = 0.6931s	
1385/32150 (epoch 2.154), train_loss = 2.13155651, grad/param norm = 2.6012e-01, time/batch = 0.6985s	
1386/32150 (epoch 2.156), train_loss = 2.15301766, grad/param norm = 2.6794e-01, time/batch = 0.6947s	
1387/32150 (epoch 2.157), train_loss = 2.37429621, grad/param norm = 2.3563e-01, time/batch = 0.6864s	
1388/32150 (epoch 2.159), train_loss = 2.30331282, grad/param norm = 2.5952e-01, time/batch = 0.7000s	
1389/32150 (epoch 2.160), train_loss = 2.45455123, grad/param norm = 2.4977e-01, time/batch = 0.6846s	
1390/32150 (epoch 2.162), train_loss = 2.35219491, grad/param norm = 2.2613e-01, time/batch = 0.6841s	
1391/32150 (epoch 2.163), train_loss = 2.21666021, grad/param norm = 2.1480e-01, time/batch = 0.6875s	
1392/32150 (epoch 2.165), train_loss = 2.34509941, grad/param norm = 2.5420e-01, time/batch = 0.6851s	
1393/32150 (epoch 2.166), train_loss = 2.43386895, grad/param norm = 2.7431e-01, time/batch = 0.6867s	
1394/32150 (epoch 2.168), train_loss = 2.30676414, grad/param norm = 2.8819e-01, time/batch = 0.6867s	
1395/32150 (epoch 2.170), train_loss = 2.36712501, grad/param norm = 2.7948e-01, time/batch = 0.6888s	
1396/32150 (epoch 2.171), train_loss = 2.36146840, grad/param norm = 2.7639e-01, time/batch = 0.6899s	
1397/32150 (epoch 2.173), train_loss = 2.32550836, grad/param norm = 2.3344e-01, time/batch = 0.6948s	
1398/32150 (epoch 2.174), train_loss = 2.14151078, grad/param norm = 2.9271e-01, time/batch = 0.6963s	
1399/32150 (epoch 2.176), train_loss = 2.08341791, grad/param norm = 2.4301e-01, time/batch = 0.6887s	
1400/32150 (epoch 2.177), train_loss = 2.34629896, grad/param norm = 2.6283e-01, time/batch = 0.6884s	
1401/32150 (epoch 2.179), train_loss = 2.21975330, grad/param norm = 2.0882e-01, time/batch = 0.6891s	
1402/32150 (epoch 2.180), train_loss = 2.30594983, grad/param norm = 2.3991e-01, time/batch = 0.6861s	
1403/32150 (epoch 2.182), train_loss = 2.21173053, grad/param norm = 2.5581e-01, time/batch = 0.6827s	
1404/32150 (epoch 2.184), train_loss = 2.21819743, grad/param norm = 2.5432e-01, time/batch = 0.6797s	
1405/32150 (epoch 2.185), train_loss = 2.19035008, grad/param norm = 2.6941e-01, time/batch = 0.6974s	
1406/32150 (epoch 2.187), train_loss = 2.19032013, grad/param norm = 2.5126e-01, time/batch = 0.6987s	
1407/32150 (epoch 2.188), train_loss = 2.28614768, grad/param norm = 2.2784e-01, time/batch = 0.7029s	
1408/32150 (epoch 2.190), train_loss = 2.46416013, grad/param norm = 2.2763e-01, time/batch = 0.6828s	
1409/32150 (epoch 2.191), train_loss = 2.39473849, grad/param norm = 2.8649e-01, time/batch = 0.6824s	
1410/32150 (epoch 2.193), train_loss = 2.40767748, grad/param norm = 3.4129e-01, time/batch = 0.6853s	
1411/32150 (epoch 2.194), train_loss = 2.40551471, grad/param norm = 2.6715e-01, time/batch = 0.6946s	
1412/32150 (epoch 2.196), train_loss = 2.41103499, grad/param norm = 2.4242e-01, time/batch = 0.6940s	
1413/32150 (epoch 2.198), train_loss = 2.27227355, grad/param norm = 2.2320e-01, time/batch = 0.6888s	
1414/32150 (epoch 2.199), train_loss = 2.20384066, grad/param norm = 2.5180e-01, time/batch = 0.6923s	
1415/32150 (epoch 2.201), train_loss = 2.30644926, grad/param norm = 2.4742e-01, time/batch = 0.6859s	
1416/32150 (epoch 2.202), train_loss = 2.32041864, grad/param norm = 2.7179e-01, time/batch = 0.6879s	
1417/32150 (epoch 2.204), train_loss = 2.42520349, grad/param norm = 2.6109e-01, time/batch = 0.6970s	
1418/32150 (epoch 2.205), train_loss = 2.34944317, grad/param norm = 2.7821e-01, time/batch = 0.6979s	
1419/32150 (epoch 2.207), train_loss = 2.16980835, grad/param norm = 2.8779e-01, time/batch = 0.7141s	
1420/32150 (epoch 2.208), train_loss = 2.11975991, grad/param norm = 2.4048e-01, time/batch = 0.7061s	
1421/32150 (epoch 2.210), train_loss = 2.15625688, grad/param norm = 2.1604e-01, time/batch = 0.6985s	
1422/32150 (epoch 2.212), train_loss = 2.25067611, grad/param norm = 2.1701e-01, time/batch = 0.6917s	
1423/32150 (epoch 2.213), train_loss = 2.21831991, grad/param norm = 2.5131e-01, time/batch = 0.6971s	
1424/32150 (epoch 2.215), train_loss = 2.17511198, grad/param norm = 2.6142e-01, time/batch = 0.6975s	
1425/32150 (epoch 2.216), train_loss = 2.25322897, grad/param norm = 2.4018e-01, time/batch = 0.6941s	
1426/32150 (epoch 2.218), train_loss = 2.23188342, grad/param norm = 2.6414e-01, time/batch = 0.6917s	
1427/32150 (epoch 2.219), train_loss = 2.13225669, grad/param norm = 2.2787e-01, time/batch = 0.6855s	
1428/32150 (epoch 2.221), train_loss = 2.43858599, grad/param norm = 2.4471e-01, time/batch = 0.6817s	
1429/32150 (epoch 2.222), train_loss = 2.26141707, grad/param norm = 2.3413e-01, time/batch = 0.6833s	
1430/32150 (epoch 2.224), train_loss = 2.25873278, grad/param norm = 2.8377e-01, time/batch = 0.6800s	
1431/32150 (epoch 2.226), train_loss = 2.17951823, grad/param norm = 2.4314e-01, time/batch = 0.6835s	
1432/32150 (epoch 2.227), train_loss = 2.16108784, grad/param norm = 2.5791e-01, time/batch = 0.6803s	
1433/32150 (epoch 2.229), train_loss = 2.35057377, grad/param norm = 2.4869e-01, time/batch = 0.6822s	
1434/32150 (epoch 2.230), train_loss = 2.26693648, grad/param norm = 2.9938e-01, time/batch = 0.7018s	
1435/32150 (epoch 2.232), train_loss = 2.15628134, grad/param norm = 2.4924e-01, time/batch = 0.6983s	
1436/32150 (epoch 2.233), train_loss = 2.18567623, grad/param norm = 2.1778e-01, time/batch = 0.6871s	
1437/32150 (epoch 2.235), train_loss = 2.24687514, grad/param norm = 2.5492e-01, time/batch = 0.6874s	
1438/32150 (epoch 2.236), train_loss = 2.31633930, grad/param norm = 2.5846e-01, time/batch = 0.6930s	
1439/32150 (epoch 2.238), train_loss = 2.36786732, grad/param norm = 2.5345e-01, time/batch = 0.7078s	
1440/32150 (epoch 2.240), train_loss = 2.32563525, grad/param norm = 2.8562e-01, time/batch = 0.6889s	
1441/32150 (epoch 2.241), train_loss = 2.34035972, grad/param norm = 2.5121e-01, time/batch = 0.6930s	
1442/32150 (epoch 2.243), train_loss = 2.33921517, grad/param norm = 2.5714e-01, time/batch = 0.6820s	
1443/32150 (epoch 2.244), train_loss = 2.24322756, grad/param norm = 2.4268e-01, time/batch = 0.6997s	
1444/32150 (epoch 2.246), train_loss = 2.46894763, grad/param norm = 2.5942e-01, time/batch = 0.6882s	
1445/32150 (epoch 2.247), train_loss = 2.40801840, grad/param norm = 1.9967e-01, time/batch = 0.6902s	
1446/32150 (epoch 2.249), train_loss = 2.27516707, grad/param norm = 2.5285e-01, time/batch = 0.6863s	
1447/32150 (epoch 2.250), train_loss = 2.33434009, grad/param norm = 2.7260e-01, time/batch = 0.7069s	
1448/32150 (epoch 2.252), train_loss = 2.26007905, grad/param norm = 2.6390e-01, time/batch = 0.7124s	
1449/32150 (epoch 2.253), train_loss = 2.44236858, grad/param norm = 2.9688e-01, time/batch = 0.6952s	
1450/32150 (epoch 2.255), train_loss = 2.23633121, grad/param norm = 2.2909e-01, time/batch = 0.6974s	
1451/32150 (epoch 2.257), train_loss = 2.32302435, grad/param norm = 2.5133e-01, time/batch = 0.6856s	
1452/32150 (epoch 2.258), train_loss = 2.23645538, grad/param norm = 2.0170e-01, time/batch = 0.6917s	
1453/32150 (epoch 2.260), train_loss = 2.43610505, grad/param norm = 2.2637e-01, time/batch = 0.6988s	
1454/32150 (epoch 2.261), train_loss = 2.26917558, grad/param norm = 2.8620e-01, time/batch = 0.7020s	
1455/32150 (epoch 2.263), train_loss = 2.44385071, grad/param norm = 2.4445e-01, time/batch = 0.6887s	
1456/32150 (epoch 2.264), train_loss = 2.28465435, grad/param norm = 2.6973e-01, time/batch = 0.6801s	
1457/32150 (epoch 2.266), train_loss = 2.20824722, grad/param norm = 2.4119e-01, time/batch = 0.6782s	
1458/32150 (epoch 2.267), train_loss = 2.06985529, grad/param norm = 2.1938e-01, time/batch = 0.6899s	
1459/32150 (epoch 2.269), train_loss = 2.18074584, grad/param norm = 2.3328e-01, time/batch = 0.6821s	
1460/32150 (epoch 2.271), train_loss = 2.10721453, grad/param norm = 2.1363e-01, time/batch = 0.6991s	
1461/32150 (epoch 2.272), train_loss = 2.16461758, grad/param norm = 2.7836e-01, time/batch = 0.6953s	
1462/32150 (epoch 2.274), train_loss = 2.40904075, grad/param norm = 3.0774e-01, time/batch = 0.6982s	
1463/32150 (epoch 2.275), train_loss = 2.37881707, grad/param norm = 2.6283e-01, time/batch = 0.7043s	
1464/32150 (epoch 2.277), train_loss = 2.30422549, grad/param norm = 2.2172e-01, time/batch = 0.6867s	
1465/32150 (epoch 2.278), train_loss = 2.28756315, grad/param norm = 2.7189e-01, time/batch = 0.6854s	
1466/32150 (epoch 2.280), train_loss = 2.36939498, grad/param norm = 2.8933e-01, time/batch = 0.6983s	
1467/32150 (epoch 2.281), train_loss = 2.28477582, grad/param norm = 2.4950e-01, time/batch = 0.6866s	
1468/32150 (epoch 2.283), train_loss = 2.36677873, grad/param norm = 2.2511e-01, time/batch = 0.6870s	
1469/32150 (epoch 2.285), train_loss = 2.21338755, grad/param norm = 2.1646e-01, time/batch = 0.6821s	
1470/32150 (epoch 2.286), train_loss = 2.35730966, grad/param norm = 2.5294e-01, time/batch = 0.6910s	
1471/32150 (epoch 2.288), train_loss = 2.36118855, grad/param norm = 2.5980e-01, time/batch = 0.6933s	
1472/32150 (epoch 2.289), train_loss = 2.21246299, grad/param norm = 2.8485e-01, time/batch = 0.7017s	
1473/32150 (epoch 2.291), train_loss = 2.17802113, grad/param norm = 2.5385e-01, time/batch = 0.6896s	
1474/32150 (epoch 2.292), train_loss = 2.31086767, grad/param norm = 2.8990e-01, time/batch = 0.6799s	
1475/32150 (epoch 2.294), train_loss = 2.29938910, grad/param norm = 2.6904e-01, time/batch = 0.6906s	
1476/32150 (epoch 2.295), train_loss = 2.33193609, grad/param norm = 2.8715e-01, time/batch = 0.6843s	
1477/32150 (epoch 2.297), train_loss = 2.26999200, grad/param norm = 2.3075e-01, time/batch = 0.7002s	
1478/32150 (epoch 2.299), train_loss = 2.44610061, grad/param norm = 2.4967e-01, time/batch = 0.6947s	
1479/32150 (epoch 2.300), train_loss = 2.41137469, grad/param norm = 2.5939e-01, time/batch = 0.6849s	
1480/32150 (epoch 2.302), train_loss = 2.26351495, grad/param norm = 2.6484e-01, time/batch = 0.6860s	
1481/32150 (epoch 2.303), train_loss = 2.37281847, grad/param norm = 2.7761e-01, time/batch = 0.6820s	
1482/32150 (epoch 2.305), train_loss = 2.44494816, grad/param norm = 2.9792e-01, time/batch = 0.6993s	
1483/32150 (epoch 2.306), train_loss = 2.30800795, grad/param norm = 2.4667e-01, time/batch = 0.6916s	
1484/32150 (epoch 2.308), train_loss = 2.30674911, grad/param norm = 2.4987e-01, time/batch = 0.6827s	
1485/32150 (epoch 2.309), train_loss = 2.39345751, grad/param norm = 2.7543e-01, time/batch = 0.6870s	
1486/32150 (epoch 2.311), train_loss = 2.09430574, grad/param norm = 2.6670e-01, time/batch = 0.6840s	
1487/32150 (epoch 2.313), train_loss = 2.25843013, grad/param norm = 2.3414e-01, time/batch = 0.6819s	
1488/32150 (epoch 2.314), train_loss = 2.33509097, grad/param norm = 2.2253e-01, time/batch = 0.6819s	
1489/32150 (epoch 2.316), train_loss = 2.23152358, grad/param norm = 2.2689e-01, time/batch = 0.6858s	
1490/32150 (epoch 2.317), train_loss = 2.35213877, grad/param norm = 2.4499e-01, time/batch = 0.6899s	
1491/32150 (epoch 2.319), train_loss = 2.24016643, grad/param norm = 2.3057e-01, time/batch = 0.6957s	
1492/32150 (epoch 2.320), train_loss = 2.26540287, grad/param norm = 2.1871e-01, time/batch = 0.7048s	
1493/32150 (epoch 2.322), train_loss = 2.29720379, grad/param norm = 2.4169e-01, time/batch = 0.6856s	
1494/32150 (epoch 2.323), train_loss = 2.23536712, grad/param norm = 2.6248e-01, time/batch = 0.7006s	
1495/32150 (epoch 2.325), train_loss = 2.26740025, grad/param norm = 2.5150e-01, time/batch = 0.7240s	
1496/32150 (epoch 2.327), train_loss = 2.40719755, grad/param norm = 2.4255e-01, time/batch = 0.7241s	
1497/32150 (epoch 2.328), train_loss = 2.15504244, grad/param norm = 2.4136e-01, time/batch = 0.7161s	
1498/32150 (epoch 2.330), train_loss = 2.32879205, grad/param norm = 3.1214e-01, time/batch = 0.7034s	
1499/32150 (epoch 2.331), train_loss = 2.38938775, grad/param norm = 3.1556e-01, time/batch = 0.7079s	
1500/32150 (epoch 2.333), train_loss = 2.30946675, grad/param norm = 2.3369e-01, time/batch = 0.7036s	
1501/32150 (epoch 2.334), train_loss = 2.31209080, grad/param norm = 2.2517e-01, time/batch = 0.7027s	
1502/32150 (epoch 2.336), train_loss = 2.42641920, grad/param norm = 2.2269e-01, time/batch = 0.6983s	
1503/32150 (epoch 2.337), train_loss = 2.38489571, grad/param norm = 2.2498e-01, time/batch = 0.7134s	
1504/32150 (epoch 2.339), train_loss = 2.48829430, grad/param norm = 2.4045e-01, time/batch = 0.7077s	
1505/32150 (epoch 2.341), train_loss = 2.35998665, grad/param norm = 2.1142e-01, time/batch = 0.7068s	
1506/32150 (epoch 2.342), train_loss = 2.08887747, grad/param norm = 2.1125e-01, time/batch = 0.6979s	
1507/32150 (epoch 2.344), train_loss = 2.02040504, grad/param norm = 2.1409e-01, time/batch = 0.7019s	
1508/32150 (epoch 2.345), train_loss = 2.22620999, grad/param norm = 3.0018e-01, time/batch = 0.7079s	
1509/32150 (epoch 2.347), train_loss = 2.28275515, grad/param norm = 2.3489e-01, time/batch = 0.7053s	
1510/32150 (epoch 2.348), train_loss = 2.21008343, grad/param norm = 2.6106e-01, time/batch = 0.6977s	
1511/32150 (epoch 2.350), train_loss = 2.29488902, grad/param norm = 2.2443e-01, time/batch = 0.6929s	
1512/32150 (epoch 2.351), train_loss = 2.27684280, grad/param norm = 2.5225e-01, time/batch = 0.6942s	
1513/32150 (epoch 2.353), train_loss = 2.24575245, grad/param norm = 2.4419e-01, time/batch = 0.6979s	
1514/32150 (epoch 2.355), train_loss = 2.16172966, grad/param norm = 2.3205e-01, time/batch = 0.7071s	
1515/32150 (epoch 2.356), train_loss = 2.32395720, grad/param norm = 2.3626e-01, time/batch = 0.6962s	
1516/32150 (epoch 2.358), train_loss = 2.28640122, grad/param norm = 2.2607e-01, time/batch = 0.7042s	
1517/32150 (epoch 2.359), train_loss = 2.13034937, grad/param norm = 2.0640e-01, time/batch = 0.6867s	
1518/32150 (epoch 2.361), train_loss = 2.36361265, grad/param norm = 2.6049e-01, time/batch = 0.6865s	
1519/32150 (epoch 2.362), train_loss = 2.23783833, grad/param norm = 2.2105e-01, time/batch = 0.6856s	
1520/32150 (epoch 2.364), train_loss = 2.17772548, grad/param norm = 2.6898e-01, time/batch = 0.6827s	
1521/32150 (epoch 2.365), train_loss = 2.42644896, grad/param norm = 2.6811e-01, time/batch = 0.6844s	
1522/32150 (epoch 2.367), train_loss = 2.32244987, grad/param norm = 2.4176e-01, time/batch = 0.6871s	
1523/32150 (epoch 2.369), train_loss = 2.26752830, grad/param norm = 2.4314e-01, time/batch = 0.6782s	
1524/32150 (epoch 2.370), train_loss = 2.19336570, grad/param norm = 2.2918e-01, time/batch = 0.6811s	
1525/32150 (epoch 2.372), train_loss = 2.31321894, grad/param norm = 2.4194e-01, time/batch = 0.7009s	
1526/32150 (epoch 2.373), train_loss = 2.33074068, grad/param norm = 2.5948e-01, time/batch = 0.6918s	
1527/32150 (epoch 2.375), train_loss = 2.08311494, grad/param norm = 2.1357e-01, time/batch = 0.6975s	
1528/32150 (epoch 2.376), train_loss = 2.26609122, grad/param norm = 2.4197e-01, time/batch = 0.6909s	
1529/32150 (epoch 2.378), train_loss = 2.26424263, grad/param norm = 2.4296e-01, time/batch = 0.6894s	
1530/32150 (epoch 2.379), train_loss = 2.22708877, grad/param norm = 2.3240e-01, time/batch = 0.7047s	
1531/32150 (epoch 2.381), train_loss = 2.36444505, grad/param norm = 2.2072e-01, time/batch = 0.6994s	
1532/32150 (epoch 2.383), train_loss = 2.12531310, grad/param norm = 2.5350e-01, time/batch = 0.6829s	
1533/32150 (epoch 2.384), train_loss = 2.22902561, grad/param norm = 2.9250e-01, time/batch = 0.6879s	
1534/32150 (epoch 2.386), train_loss = 2.28023736, grad/param norm = 2.8859e-01, time/batch = 0.6901s	
1535/32150 (epoch 2.387), train_loss = 2.32236325, grad/param norm = 2.5152e-01, time/batch = 0.6886s	
1536/32150 (epoch 2.389), train_loss = 2.16889538, grad/param norm = 2.7358e-01, time/batch = 0.6939s	
1537/32150 (epoch 2.390), train_loss = 2.27805380, grad/param norm = 2.8818e-01, time/batch = 0.6910s	
1538/32150 (epoch 2.392), train_loss = 2.20062448, grad/param norm = 2.0051e-01, time/batch = 0.6961s	
1539/32150 (epoch 2.393), train_loss = 2.25178443, grad/param norm = 2.3403e-01, time/batch = 0.6972s	
1540/32150 (epoch 2.395), train_loss = 2.03556660, grad/param norm = 1.8968e-01, time/batch = 0.6874s	
1541/32150 (epoch 2.397), train_loss = 2.26973016, grad/param norm = 2.2398e-01, time/batch = 0.6941s	
1542/32150 (epoch 2.398), train_loss = 2.26381511, grad/param norm = 2.4332e-01, time/batch = 0.6885s	
1543/32150 (epoch 2.400), train_loss = 2.40726137, grad/param norm = 2.2970e-01, time/batch = 0.6816s	
1544/32150 (epoch 2.401), train_loss = 2.39347830, grad/param norm = 2.8890e-01, time/batch = 0.6830s	
1545/32150 (epoch 2.403), train_loss = 2.20613199, grad/param norm = 2.5532e-01, time/batch = 0.7026s	
1546/32150 (epoch 2.404), train_loss = 2.16018163, grad/param norm = 2.1848e-01, time/batch = 0.6858s	
1547/32150 (epoch 2.406), train_loss = 2.27414954, grad/param norm = 2.2336e-01, time/batch = 0.6871s	
1548/32150 (epoch 2.407), train_loss = 2.28389087, grad/param norm = 2.3996e-01, time/batch = 0.6834s	
1549/32150 (epoch 2.409), train_loss = 2.27507075, grad/param norm = 2.2561e-01, time/batch = 0.7023s	
1550/32150 (epoch 2.411), train_loss = 2.29965651, grad/param norm = 2.4459e-01, time/batch = 0.6955s	
1551/32150 (epoch 2.412), train_loss = 2.41763973, grad/param norm = 2.2171e-01, time/batch = 0.6837s	
1552/32150 (epoch 2.414), train_loss = 2.12017153, grad/param norm = 2.8112e-01, time/batch = 0.7025s	
1553/32150 (epoch 2.415), train_loss = 2.13934893, grad/param norm = 2.5922e-01, time/batch = 0.6917s	
1554/32150 (epoch 2.417), train_loss = 2.36906597, grad/param norm = 2.3785e-01, time/batch = 0.6937s	
1555/32150 (epoch 2.418), train_loss = 2.35105601, grad/param norm = 2.1728e-01, time/batch = 0.6949s	
1556/32150 (epoch 2.420), train_loss = 2.22318001, grad/param norm = 2.3835e-01, time/batch = 0.6825s	
1557/32150 (epoch 2.421), train_loss = 2.33742209, grad/param norm = 3.3874e-01, time/batch = 0.6831s	
1558/32150 (epoch 2.423), train_loss = 2.06565348, grad/param norm = 3.4260e-01, time/batch = 0.6822s	
1559/32150 (epoch 2.425), train_loss = 2.17098677, grad/param norm = 2.3473e-01, time/batch = 0.6833s	
1560/32150 (epoch 2.426), train_loss = 2.24818913, grad/param norm = 2.6932e-01, time/batch = 0.6823s	
1561/32150 (epoch 2.428), train_loss = 2.30362923, grad/param norm = 3.3371e-01, time/batch = 0.6866s	
1562/32150 (epoch 2.429), train_loss = 2.21268438, grad/param norm = 2.3676e-01, time/batch = 0.6820s	
1563/32150 (epoch 2.431), train_loss = 2.34087733, grad/param norm = 2.4266e-01, time/batch = 0.6886s	
1564/32150 (epoch 2.432), train_loss = 2.12071865, grad/param norm = 2.1355e-01, time/batch = 0.6852s	
1565/32150 (epoch 2.434), train_loss = 2.30893403, grad/param norm = 2.2016e-01, time/batch = 0.6862s	
1566/32150 (epoch 2.435), train_loss = 2.19371699, grad/param norm = 2.2499e-01, time/batch = 0.6909s	
1567/32150 (epoch 2.437), train_loss = 2.17569280, grad/param norm = 2.1513e-01, time/batch = 0.6822s	
1568/32150 (epoch 2.439), train_loss = 2.05108773, grad/param norm = 2.3072e-01, time/batch = 0.6842s	
1569/32150 (epoch 2.440), train_loss = 1.91797741, grad/param norm = 2.0793e-01, time/batch = 0.6851s	
1570/32150 (epoch 2.442), train_loss = 2.14622980, grad/param norm = 2.1822e-01, time/batch = 0.6844s	
1571/32150 (epoch 2.443), train_loss = 1.89037249, grad/param norm = 1.9015e-01, time/batch = 0.6884s	
1572/32150 (epoch 2.445), train_loss = 2.21853072, grad/param norm = 2.1283e-01, time/batch = 0.6922s	
1573/32150 (epoch 2.446), train_loss = 2.02619014, grad/param norm = 2.4264e-01, time/batch = 0.6925s	
1574/32150 (epoch 2.448), train_loss = 2.06123512, grad/param norm = 2.3572e-01, time/batch = 0.6962s	
1575/32150 (epoch 2.449), train_loss = 2.13189295, grad/param norm = 2.1803e-01, time/batch = 0.6954s	
1576/32150 (epoch 2.451), train_loss = 2.30320804, grad/param norm = 2.6745e-01, time/batch = 0.6860s	
1577/32150 (epoch 2.453), train_loss = 2.35287563, grad/param norm = 2.7785e-01, time/batch = 0.6882s	
1578/32150 (epoch 2.454), train_loss = 1.98777293, grad/param norm = 2.1268e-01, time/batch = 0.7025s	
1579/32150 (epoch 2.456), train_loss = 2.06568299, grad/param norm = 2.0723e-01, time/batch = 0.6921s	
1580/32150 (epoch 2.457), train_loss = 2.26573489, grad/param norm = 2.3395e-01, time/batch = 0.7041s	
1581/32150 (epoch 2.459), train_loss = 2.28105516, grad/param norm = 2.5169e-01, time/batch = 0.6991s	
1582/32150 (epoch 2.460), train_loss = 2.23738334, grad/param norm = 2.7988e-01, time/batch = 0.7000s	
1583/32150 (epoch 2.462), train_loss = 2.29744063, grad/param norm = 2.2206e-01, time/batch = 0.7015s	
1584/32150 (epoch 2.463), train_loss = 2.24615011, grad/param norm = 2.4553e-01, time/batch = 0.6999s	
1585/32150 (epoch 2.465), train_loss = 2.25716008, grad/param norm = 2.3916e-01, time/batch = 0.6908s	
1586/32150 (epoch 2.467), train_loss = 2.17718520, grad/param norm = 2.4524e-01, time/batch = 0.6904s	
1587/32150 (epoch 2.468), train_loss = 2.26553767, grad/param norm = 2.8893e-01, time/batch = 0.6868s	
1588/32150 (epoch 2.470), train_loss = 2.23247888, grad/param norm = 2.4357e-01, time/batch = 0.6825s	
1589/32150 (epoch 2.471), train_loss = 2.32201954, grad/param norm = 2.4415e-01, time/batch = 0.6874s	
1590/32150 (epoch 2.473), train_loss = 2.23873036, grad/param norm = 2.2498e-01, time/batch = 0.6848s	
1591/32150 (epoch 2.474), train_loss = 2.16100752, grad/param norm = 2.4646e-01, time/batch = 0.6844s	
1592/32150 (epoch 2.476), train_loss = 2.31937373, grad/param norm = 2.4124e-01, time/batch = 0.6828s	
1593/32150 (epoch 2.477), train_loss = 2.28246448, grad/param norm = 2.3827e-01, time/batch = 0.6879s	
1594/32150 (epoch 2.479), train_loss = 2.33031255, grad/param norm = 2.2668e-01, time/batch = 0.6877s	
1595/32150 (epoch 2.481), train_loss = 2.45165881, grad/param norm = 2.3820e-01, time/batch = 0.7005s	
1596/32150 (epoch 2.482), train_loss = 2.22050122, grad/param norm = 2.6622e-01, time/batch = 0.6845s	
1597/32150 (epoch 2.484), train_loss = 2.12377092, grad/param norm = 1.9978e-01, time/batch = 0.6965s	
1598/32150 (epoch 2.485), train_loss = 2.19761641, grad/param norm = 2.2556e-01, time/batch = 0.6821s	
1599/32150 (epoch 2.487), train_loss = 2.29078785, grad/param norm = 2.2805e-01, time/batch = 0.6936s	
1600/32150 (epoch 2.488), train_loss = 2.15119644, grad/param norm = 2.2739e-01, time/batch = 0.6903s	
1601/32150 (epoch 2.490), train_loss = 2.14268127, grad/param norm = 2.2799e-01, time/batch = 0.6854s	
1602/32150 (epoch 2.491), train_loss = 2.12425715, grad/param norm = 2.4145e-01, time/batch = 0.6886s	
1603/32150 (epoch 2.493), train_loss = 2.28815908, grad/param norm = 2.4491e-01, time/batch = 0.6961s	
1604/32150 (epoch 2.495), train_loss = 2.30039482, grad/param norm = 2.2676e-01, time/batch = 0.6914s	
1605/32150 (epoch 2.496), train_loss = 2.31303868, grad/param norm = 2.8523e-01, time/batch = 0.7000s	
1606/32150 (epoch 2.498), train_loss = 2.38431484, grad/param norm = 2.5232e-01, time/batch = 0.6976s	
1607/32150 (epoch 2.499), train_loss = 2.06360012, grad/param norm = 2.7191e-01, time/batch = 0.6920s	
1608/32150 (epoch 2.501), train_loss = 2.11795748, grad/param norm = 2.2263e-01, time/batch = 0.6901s	
1609/32150 (epoch 2.502), train_loss = 2.22005239, grad/param norm = 2.1015e-01, time/batch = 0.6922s	
1610/32150 (epoch 2.504), train_loss = 2.07217380, grad/param norm = 2.0152e-01, time/batch = 0.6910s	
1611/32150 (epoch 2.505), train_loss = 2.09791853, grad/param norm = 2.4327e-01, time/batch = 0.7075s	
1612/32150 (epoch 2.507), train_loss = 2.07137682, grad/param norm = 2.7812e-01, time/batch = 0.7099s	
1613/32150 (epoch 2.509), train_loss = 2.25240710, grad/param norm = 2.1885e-01, time/batch = 0.7017s	
1614/32150 (epoch 2.510), train_loss = 2.20401986, grad/param norm = 2.4232e-01, time/batch = 0.7050s	
1615/32150 (epoch 2.512), train_loss = 2.04642735, grad/param norm = 2.8500e-01, time/batch = 0.6840s	
1616/32150 (epoch 2.513), train_loss = 2.23524390, grad/param norm = 2.3549e-01, time/batch = 0.6826s	
1617/32150 (epoch 2.515), train_loss = 2.32772299, grad/param norm = 2.2140e-01, time/batch = 0.6785s	
1618/32150 (epoch 2.516), train_loss = 2.36051151, grad/param norm = 2.2685e-01, time/batch = 0.6934s	
1619/32150 (epoch 2.518), train_loss = 2.37340734, grad/param norm = 2.3030e-01, time/batch = 0.6801s	
1620/32150 (epoch 2.519), train_loss = 2.26850828, grad/param norm = 2.3549e-01, time/batch = 0.6793s	
1621/32150 (epoch 2.521), train_loss = 2.22828137, grad/param norm = 2.3386e-01, time/batch = 0.6803s	
1622/32150 (epoch 2.523), train_loss = 2.13864139, grad/param norm = 2.3045e-01, time/batch = 0.6850s	
1623/32150 (epoch 2.524), train_loss = 2.26576303, grad/param norm = 2.3419e-01, time/batch = 0.6944s	
1624/32150 (epoch 2.526), train_loss = 2.35751573, grad/param norm = 2.6006e-01, time/batch = 0.6885s	
1625/32150 (epoch 2.527), train_loss = 2.38144462, grad/param norm = 2.8443e-01, time/batch = 0.6979s	
1626/32150 (epoch 2.529), train_loss = 2.27519111, grad/param norm = 2.3332e-01, time/batch = 0.7039s	
1627/32150 (epoch 2.530), train_loss = 2.20983722, grad/param norm = 2.3163e-01, time/batch = 0.6929s	
1628/32150 (epoch 2.532), train_loss = 2.10552852, grad/param norm = 2.7774e-01, time/batch = 0.7008s	
1629/32150 (epoch 2.533), train_loss = 2.31619783, grad/param norm = 3.3679e-01, time/batch = 0.7095s	
1630/32150 (epoch 2.535), train_loss = 2.36218248, grad/param norm = 2.7863e-01, time/batch = 0.6943s	
1631/32150 (epoch 2.537), train_loss = 2.29283537, grad/param norm = 2.2810e-01, time/batch = 0.7003s	
1632/32150 (epoch 2.538), train_loss = 2.30781742, grad/param norm = 2.3075e-01, time/batch = 0.6996s	
1633/32150 (epoch 2.540), train_loss = 2.29210858, grad/param norm = 2.5620e-01, time/batch = 0.6887s	
1634/32150 (epoch 2.541), train_loss = 2.37377071, grad/param norm = 2.2693e-01, time/batch = 0.6892s	
1635/32150 (epoch 2.543), train_loss = 2.27362163, grad/param norm = 2.1693e-01, time/batch = 0.6817s	
1636/32150 (epoch 2.544), train_loss = 2.43289662, grad/param norm = 2.1840e-01, time/batch = 0.6784s	
1637/32150 (epoch 2.546), train_loss = 2.06266331, grad/param norm = 2.1447e-01, time/batch = 0.6867s	
1638/32150 (epoch 2.547), train_loss = 2.19875736, grad/param norm = 2.5938e-01, time/batch = 0.6774s	
1639/32150 (epoch 2.549), train_loss = 2.25049370, grad/param norm = 2.8993e-01, time/batch = 0.6864s	
1640/32150 (epoch 2.551), train_loss = 2.39394513, grad/param norm = 2.2208e-01, time/batch = 0.7050s	
1641/32150 (epoch 2.552), train_loss = 2.31677556, grad/param norm = 2.6114e-01, time/batch = 0.6924s	
1642/32150 (epoch 2.554), train_loss = 2.43459873, grad/param norm = 2.1058e-01, time/batch = 0.6854s	
1643/32150 (epoch 2.555), train_loss = 2.18124703, grad/param norm = 2.0979e-01, time/batch = 0.7060s	
1644/32150 (epoch 2.557), train_loss = 2.08026037, grad/param norm = 2.0641e-01, time/batch = 0.6997s	
1645/32150 (epoch 2.558), train_loss = 2.18581146, grad/param norm = 2.1503e-01, time/batch = 0.6934s	
1646/32150 (epoch 2.560), train_loss = 2.34803090, grad/param norm = 2.2665e-01, time/batch = 0.7001s	
1647/32150 (epoch 2.561), train_loss = 2.30164801, grad/param norm = 2.4974e-01, time/batch = 0.6819s	
1648/32150 (epoch 2.563), train_loss = 2.18727635, grad/param norm = 2.5209e-01, time/batch = 0.6828s	
1649/32150 (epoch 2.565), train_loss = 2.09420850, grad/param norm = 2.6457e-01, time/batch = 0.6835s	
1650/32150 (epoch 2.566), train_loss = 2.37476380, grad/param norm = 2.7064e-01, time/batch = 0.6824s	
1651/32150 (epoch 2.568), train_loss = 2.08543025, grad/param norm = 2.1783e-01, time/batch = 0.6890s	
1652/32150 (epoch 2.569), train_loss = 2.29776403, grad/param norm = 2.7253e-01, time/batch = 0.6866s	
1653/32150 (epoch 2.571), train_loss = 2.32181827, grad/param norm = 2.2736e-01, time/batch = 0.6834s	
1654/32150 (epoch 2.572), train_loss = 2.26354858, grad/param norm = 2.2207e-01, time/batch = 0.7023s	
1655/32150 (epoch 2.574), train_loss = 2.33776512, grad/param norm = 2.5249e-01, time/batch = 0.6923s	
1656/32150 (epoch 2.575), train_loss = 2.32076776, grad/param norm = 2.5954e-01, time/batch = 0.6758s	
1657/32150 (epoch 2.577), train_loss = 2.18313836, grad/param norm = 2.2059e-01, time/batch = 0.6846s	
1658/32150 (epoch 2.579), train_loss = 2.31239009, grad/param norm = 3.0832e-01, time/batch = 0.6787s	
1659/32150 (epoch 2.580), train_loss = 2.23440422, grad/param norm = 2.0931e-01, time/batch = 0.6762s	
1660/32150 (epoch 2.582), train_loss = 2.25558029, grad/param norm = 2.2321e-01, time/batch = 0.6759s	
1661/32150 (epoch 2.583), train_loss = 2.10631863, grad/param norm = 1.9689e-01, time/batch = 0.6785s	
1662/32150 (epoch 2.585), train_loss = 2.11130107, grad/param norm = 2.0356e-01, time/batch = 0.6791s	
1663/32150 (epoch 2.586), train_loss = 2.24940109, grad/param norm = 2.0512e-01, time/batch = 0.6873s	
1664/32150 (epoch 2.588), train_loss = 2.18901208, grad/param norm = 3.2330e-01, time/batch = 0.6972s	
1665/32150 (epoch 2.589), train_loss = 2.18632793, grad/param norm = 2.7438e-01, time/batch = 0.6853s	
1666/32150 (epoch 2.591), train_loss = 2.54133659, grad/param norm = 2.2403e-01, time/batch = 0.6825s	
1667/32150 (epoch 2.593), train_loss = 2.27904869, grad/param norm = 2.3533e-01, time/batch = 0.6841s	
1668/32150 (epoch 2.594), train_loss = 2.17263471, grad/param norm = 2.1333e-01, time/batch = 0.6908s	
1669/32150 (epoch 2.596), train_loss = 2.34421605, grad/param norm = 2.2383e-01, time/batch = 0.7039s	
1670/32150 (epoch 2.597), train_loss = 2.10240094, grad/param norm = 1.8726e-01, time/batch = 0.6764s	
1671/32150 (epoch 2.599), train_loss = 2.18698946, grad/param norm = 2.2085e-01, time/batch = 0.6830s	
1672/32150 (epoch 2.600), train_loss = 2.18213751, grad/param norm = 2.3103e-01, time/batch = 0.6817s	
1673/32150 (epoch 2.602), train_loss = 2.39512824, grad/param norm = 2.5809e-01, time/batch = 0.6864s	
1674/32150 (epoch 2.603), train_loss = 2.19268249, grad/param norm = 2.1432e-01, time/batch = 0.6846s	
1675/32150 (epoch 2.605), train_loss = 2.08462349, grad/param norm = 2.2658e-01, time/batch = 0.6827s	
1676/32150 (epoch 2.607), train_loss = 2.38239628, grad/param norm = 2.1543e-01, time/batch = 0.6802s	
1677/32150 (epoch 2.608), train_loss = 1.97423345, grad/param norm = 2.3468e-01, time/batch = 0.6829s	
1678/32150 (epoch 2.610), train_loss = 2.19633728, grad/param norm = 2.0562e-01, time/batch = 0.6814s	
1679/32150 (epoch 2.611), train_loss = 2.06406461, grad/param norm = 2.0887e-01, time/batch = 0.6827s	
1680/32150 (epoch 2.613), train_loss = 1.99434047, grad/param norm = 2.3350e-01, time/batch = 0.6803s	
1681/32150 (epoch 2.614), train_loss = 2.10237021, grad/param norm = 2.4919e-01, time/batch = 0.6860s	
1682/32150 (epoch 2.616), train_loss = 2.24995758, grad/param norm = 2.4927e-01, time/batch = 0.6833s	
1683/32150 (epoch 2.617), train_loss = 2.10640178, grad/param norm = 2.7672e-01, time/batch = 0.6973s	
1684/32150 (epoch 2.619), train_loss = 2.08857402, grad/param norm = 2.6809e-01, time/batch = 0.6942s	
1685/32150 (epoch 2.621), train_loss = 2.17207003, grad/param norm = 2.4016e-01, time/batch = 0.6759s	
1686/32150 (epoch 2.622), train_loss = 2.04089465, grad/param norm = 1.8808e-01, time/batch = 0.6806s	
1687/32150 (epoch 2.624), train_loss = 2.18851941, grad/param norm = 2.3498e-01, time/batch = 0.6852s	
1688/32150 (epoch 2.625), train_loss = 2.12593687, grad/param norm = 2.1691e-01, time/batch = 0.6901s	
1689/32150 (epoch 2.627), train_loss = 2.18572735, grad/param norm = 2.1460e-01, time/batch = 0.6836s	
1690/32150 (epoch 2.628), train_loss = 2.15424468, grad/param norm = 2.1089e-01, time/batch = 0.6833s	
1691/32150 (epoch 2.630), train_loss = 2.06577011, grad/param norm = 2.4203e-01, time/batch = 0.6866s	
1692/32150 (epoch 2.631), train_loss = 2.35163479, grad/param norm = 2.3882e-01, time/batch = 0.6854s	
1693/32150 (epoch 2.633), train_loss = 2.18831269, grad/param norm = 2.7567e-01, time/batch = 0.6807s	
1694/32150 (epoch 2.635), train_loss = 2.20594938, grad/param norm = 2.3548e-01, time/batch = 0.7043s	
1695/32150 (epoch 2.636), train_loss = 2.27620512, grad/param norm = 2.1414e-01, time/batch = 0.6924s	
1696/32150 (epoch 2.638), train_loss = 2.29406104, grad/param norm = 2.5012e-01, time/batch = 0.6955s	
1697/32150 (epoch 2.639), train_loss = 2.33564088, grad/param norm = 2.5173e-01, time/batch = 0.6993s	
1698/32150 (epoch 2.641), train_loss = 2.19583460, grad/param norm = 2.1476e-01, time/batch = 0.7038s	
1699/32150 (epoch 2.642), train_loss = 2.29492861, grad/param norm = 2.1947e-01, time/batch = 0.7044s	
1700/32150 (epoch 2.644), train_loss = 2.22855119, grad/param norm = 2.4171e-01, time/batch = 0.7020s	
1701/32150 (epoch 2.645), train_loss = 2.34820554, grad/param norm = 2.2030e-01, time/batch = 0.7015s	
1702/32150 (epoch 2.647), train_loss = 2.30572719, grad/param norm = 2.6845e-01, time/batch = 0.6928s	
1703/32150 (epoch 2.649), train_loss = 2.15464429, grad/param norm = 2.0404e-01, time/batch = 0.6864s	
1704/32150 (epoch 2.650), train_loss = 2.15687404, grad/param norm = 2.3318e-01, time/batch = 0.6842s	
1705/32150 (epoch 2.652), train_loss = 2.25447600, grad/param norm = 2.1714e-01, time/batch = 0.6974s	
1706/32150 (epoch 2.653), train_loss = 2.30151391, grad/param norm = 3.0698e-01, time/batch = 0.6940s	
1707/32150 (epoch 2.655), train_loss = 2.57716703, grad/param norm = 3.4873e-01, time/batch = 0.6839s	
1708/32150 (epoch 2.656), train_loss = 2.50415080, grad/param norm = 2.6628e-01, time/batch = 0.6800s	
1709/32150 (epoch 2.658), train_loss = 2.34154600, grad/param norm = 2.4123e-01, time/batch = 0.6798s	
1710/32150 (epoch 2.659), train_loss = 2.53945061, grad/param norm = 2.8443e-01, time/batch = 0.6770s	
1711/32150 (epoch 2.661), train_loss = 2.30484093, grad/param norm = 2.4223e-01, time/batch = 0.6854s	
1712/32150 (epoch 2.663), train_loss = 2.15054846, grad/param norm = 2.1495e-01, time/batch = 0.6871s	
1713/32150 (epoch 2.664), train_loss = 2.09890137, grad/param norm = 2.2884e-01, time/batch = 0.7051s	
1714/32150 (epoch 2.666), train_loss = 2.34006097, grad/param norm = 2.5011e-01, time/batch = 0.6815s	
1715/32150 (epoch 2.667), train_loss = 2.32262592, grad/param norm = 2.2292e-01, time/batch = 0.6809s	
1716/32150 (epoch 2.669), train_loss = 2.27651805, grad/param norm = 2.4770e-01, time/batch = 0.6981s	
1717/32150 (epoch 2.670), train_loss = 2.25521460, grad/param norm = 2.6023e-01, time/batch = 0.6980s	
1718/32150 (epoch 2.672), train_loss = 2.21789277, grad/param norm = 2.1829e-01, time/batch = 0.6877s	
1719/32150 (epoch 2.673), train_loss = 2.22977346, grad/param norm = 2.1677e-01, time/batch = 0.6871s	
1720/32150 (epoch 2.675), train_loss = 2.30550293, grad/param norm = 2.0228e-01, time/batch = 0.6863s	
1721/32150 (epoch 2.677), train_loss = 2.28795335, grad/param norm = 2.4380e-01, time/batch = 0.6878s	
1722/32150 (epoch 2.678), train_loss = 2.32049436, grad/param norm = 2.4261e-01, time/batch = 0.6850s	
1723/32150 (epoch 2.680), train_loss = 2.25969803, grad/param norm = 2.2141e-01, time/batch = 0.6835s	
1724/32150 (epoch 2.681), train_loss = 2.18006048, grad/param norm = 2.3298e-01, time/batch = 0.6758s	
1725/32150 (epoch 2.683), train_loss = 2.22337988, grad/param norm = 2.0489e-01, time/batch = 0.6786s	
1726/32150 (epoch 2.684), train_loss = 2.32649705, grad/param norm = 2.2487e-01, time/batch = 0.6800s	
1727/32150 (epoch 2.686), train_loss = 2.14908744, grad/param norm = 2.4739e-01, time/batch = 0.6831s	
1728/32150 (epoch 2.687), train_loss = 2.19234941, grad/param norm = 2.2358e-01, time/batch = 0.6802s	
1729/32150 (epoch 2.689), train_loss = 1.97985068, grad/param norm = 2.2506e-01, time/batch = 0.6782s	
1730/32150 (epoch 2.691), train_loss = 1.88860123, grad/param norm = 2.1051e-01, time/batch = 0.6785s	
1731/32150 (epoch 2.692), train_loss = 2.06783128, grad/param norm = 2.1410e-01, time/batch = 0.6851s	
1732/32150 (epoch 2.694), train_loss = 2.09827990, grad/param norm = 2.0680e-01, time/batch = 0.6843s	
1733/32150 (epoch 2.695), train_loss = 2.18071857, grad/param norm = 2.0026e-01, time/batch = 0.6800s	
1734/32150 (epoch 2.697), train_loss = 2.19363126, grad/param norm = 2.0236e-01, time/batch = 0.6928s	
1735/32150 (epoch 2.698), train_loss = 2.18601682, grad/param norm = 2.0756e-01, time/batch = 0.7014s	
1736/32150 (epoch 2.700), train_loss = 2.21671569, grad/param norm = 2.1532e-01, time/batch = 0.6975s	
1737/32150 (epoch 2.701), train_loss = 2.07476058, grad/param norm = 2.0504e-01, time/batch = 0.6796s	
1738/32150 (epoch 2.703), train_loss = 2.16993078, grad/param norm = 2.1490e-01, time/batch = 0.6839s	
1739/32150 (epoch 2.705), train_loss = 2.12614676, grad/param norm = 2.2805e-01, time/batch = 0.6779s	
1740/32150 (epoch 2.706), train_loss = 2.19688150, grad/param norm = 2.0500e-01, time/batch = 0.6775s	
1741/32150 (epoch 2.708), train_loss = 2.37038142, grad/param norm = 2.5048e-01, time/batch = 0.6801s	
1742/32150 (epoch 2.709), train_loss = 2.15309294, grad/param norm = 2.3971e-01, time/batch = 0.7086s	
1743/32150 (epoch 2.711), train_loss = 2.18950437, grad/param norm = 2.7775e-01, time/batch = 0.6979s	
1744/32150 (epoch 2.712), train_loss = 2.50146095, grad/param norm = 3.0228e-01, time/batch = 0.6911s	
1745/32150 (epoch 2.714), train_loss = 2.23955134, grad/param norm = 2.2694e-01, time/batch = 0.6988s	
1746/32150 (epoch 2.715), train_loss = 2.32199341, grad/param norm = 2.2569e-01, time/batch = 0.6861s	
1747/32150 (epoch 2.717), train_loss = 2.21406741, grad/param norm = 2.1039e-01, time/batch = 0.6874s	
1748/32150 (epoch 2.719), train_loss = 2.12115469, grad/param norm = 2.1742e-01, time/batch = 0.6868s	
1749/32150 (epoch 2.720), train_loss = 2.16977262, grad/param norm = 2.0898e-01, time/batch = 0.6863s	
1750/32150 (epoch 2.722), train_loss = 2.16760850, grad/param norm = 2.3862e-01, time/batch = 0.7022s	
1751/32150 (epoch 2.723), train_loss = 2.33722564, grad/param norm = 2.3569e-01, time/batch = 0.6809s	
1752/32150 (epoch 2.725), train_loss = 2.15438208, grad/param norm = 2.6724e-01, time/batch = 0.6779s	
1753/32150 (epoch 2.726), train_loss = 2.18784827, grad/param norm = 2.4527e-01, time/batch = 0.6857s	
1754/32150 (epoch 2.728), train_loss = 2.09058873, grad/param norm = 2.4751e-01, time/batch = 0.6802s	
1755/32150 (epoch 2.729), train_loss = 2.16719561, grad/param norm = 2.2489e-01, time/batch = 0.6793s	
1756/32150 (epoch 2.731), train_loss = 2.21888012, grad/param norm = 2.6962e-01, time/batch = 0.6791s	
1757/32150 (epoch 2.733), train_loss = 2.15236283, grad/param norm = 2.2403e-01, time/batch = 0.6851s	
1758/32150 (epoch 2.734), train_loss = 2.19475059, grad/param norm = 2.6911e-01, time/batch = 0.6886s	
1759/32150 (epoch 2.736), train_loss = 2.01829637, grad/param norm = 2.2321e-01, time/batch = 0.6818s	
1760/32150 (epoch 2.737), train_loss = 2.21423391, grad/param norm = 2.2988e-01, time/batch = 0.6880s	
1761/32150 (epoch 2.739), train_loss = 2.11081318, grad/param norm = 2.3022e-01, time/batch = 0.6927s	
1762/32150 (epoch 2.740), train_loss = 1.94010338, grad/param norm = 2.2885e-01, time/batch = 0.6840s	
1763/32150 (epoch 2.742), train_loss = 1.93272514, grad/param norm = 2.0998e-01, time/batch = 0.6893s	
1764/32150 (epoch 2.743), train_loss = 1.99602940, grad/param norm = 2.1681e-01, time/batch = 0.6960s	
1765/32150 (epoch 2.745), train_loss = 1.95329755, grad/param norm = 2.0829e-01, time/batch = 0.6885s	
1766/32150 (epoch 2.747), train_loss = 2.13861479, grad/param norm = 2.0175e-01, time/batch = 0.6875s	
1767/32150 (epoch 2.748), train_loss = 2.35344172, grad/param norm = 2.4462e-01, time/batch = 0.6869s	
1768/32150 (epoch 2.750), train_loss = 2.21593831, grad/param norm = 2.4509e-01, time/batch = 0.6913s	
1769/32150 (epoch 2.751), train_loss = 2.12872213, grad/param norm = 2.6682e-01, time/batch = 0.6902s	
1770/32150 (epoch 2.753), train_loss = 2.08310630, grad/param norm = 2.0171e-01, time/batch = 0.6874s	
1771/32150 (epoch 2.754), train_loss = 2.20619108, grad/param norm = 2.0330e-01, time/batch = 0.7001s	
1772/32150 (epoch 2.756), train_loss = 2.05621654, grad/param norm = 2.3297e-01, time/batch = 0.6863s	
1773/32150 (epoch 2.757), train_loss = 2.34671989, grad/param norm = 2.1836e-01, time/batch = 0.6879s	
1774/32150 (epoch 2.759), train_loss = 2.18674134, grad/param norm = 2.1048e-01, time/batch = 0.6988s	
1775/32150 (epoch 2.760), train_loss = 2.15859827, grad/param norm = 2.2052e-01, time/batch = 0.6969s	
1776/32150 (epoch 2.762), train_loss = 2.21956975, grad/param norm = 2.1904e-01, time/batch = 0.6797s	
1777/32150 (epoch 2.764), train_loss = 2.40932731, grad/param norm = 2.5655e-01, time/batch = 0.6810s	
1778/32150 (epoch 2.765), train_loss = 2.03225617, grad/param norm = 2.3313e-01, time/batch = 0.6855s	
1779/32150 (epoch 2.767), train_loss = 2.26101879, grad/param norm = 2.3196e-01, time/batch = 0.6892s	
1780/32150 (epoch 2.768), train_loss = 2.14196520, grad/param norm = 2.4911e-01, time/batch = 0.6888s	
1781/32150 (epoch 2.770), train_loss = 2.19826903, grad/param norm = 2.4523e-01, time/batch = 0.6927s	
1782/32150 (epoch 2.771), train_loss = 2.31838025, grad/param norm = 2.6938e-01, time/batch = 0.6892s	
1783/32150 (epoch 2.773), train_loss = 2.48235719, grad/param norm = 2.7089e-01, time/batch = 0.6831s	
1784/32150 (epoch 2.774), train_loss = 2.20608361, grad/param norm = 2.3132e-01, time/batch = 0.6860s	
1785/32150 (epoch 2.776), train_loss = 2.24157824, grad/param norm = 2.4481e-01, time/batch = 0.7052s	
1786/32150 (epoch 2.778), train_loss = 1.94713368, grad/param norm = 2.1398e-01, time/batch = 0.6951s	
1787/32150 (epoch 2.779), train_loss = 2.17096582, grad/param norm = 2.3116e-01, time/batch = 0.6969s	
1788/32150 (epoch 2.781), train_loss = 2.23299447, grad/param norm = 2.3323e-01, time/batch = 0.6803s	
1789/32150 (epoch 2.782), train_loss = 2.17399732, grad/param norm = 2.5265e-01, time/batch = 0.6805s	
1790/32150 (epoch 2.784), train_loss = 2.35381316, grad/param norm = 2.3183e-01, time/batch = 0.6825s	
1791/32150 (epoch 2.785), train_loss = 2.16829550, grad/param norm = 2.3467e-01, time/batch = 0.6835s	
1792/32150 (epoch 2.787), train_loss = 2.22138407, grad/param norm = 2.2615e-01, time/batch = 0.6830s	
1793/32150 (epoch 2.788), train_loss = 2.16208178, grad/param norm = 2.0652e-01, time/batch = 0.6857s	
1794/32150 (epoch 2.790), train_loss = 2.12915872, grad/param norm = 2.0532e-01, time/batch = 0.6963s	
1795/32150 (epoch 2.792), train_loss = 2.14028013, grad/param norm = 2.6195e-01, time/batch = 0.6873s	
1796/32150 (epoch 2.793), train_loss = 2.25988526, grad/param norm = 2.3835e-01, time/batch = 0.6835s	
1797/32150 (epoch 2.795), train_loss = 2.06036051, grad/param norm = 2.3787e-01, time/batch = 0.6817s	
1798/32150 (epoch 2.796), train_loss = 2.03410574, grad/param norm = 2.0842e-01, time/batch = 0.6797s	
1799/32150 (epoch 2.798), train_loss = 2.00368527, grad/param norm = 2.1960e-01, time/batch = 0.6827s	
1800/32150 (epoch 2.799), train_loss = 2.21857265, grad/param norm = 2.0551e-01, time/batch = 0.6865s	
1801/32150 (epoch 2.801), train_loss = 2.40842572, grad/param norm = 2.4185e-01, time/batch = 0.7065s	
1802/32150 (epoch 2.802), train_loss = 2.18956506, grad/param norm = 2.4067e-01, time/batch = 0.6924s	
1803/32150 (epoch 2.804), train_loss = 2.36126239, grad/param norm = 2.2369e-01, time/batch = 0.7002s	
1804/32150 (epoch 2.806), train_loss = 2.31370654, grad/param norm = 2.4374e-01, time/batch = 0.6950s	
1805/32150 (epoch 2.807), train_loss = 2.24920201, grad/param norm = 2.3645e-01, time/batch = 0.6873s	
1806/32150 (epoch 2.809), train_loss = 2.17867564, grad/param norm = 2.3744e-01, time/batch = 0.6856s	
1807/32150 (epoch 2.810), train_loss = 2.26096133, grad/param norm = 2.0627e-01, time/batch = 0.6831s	
1808/32150 (epoch 2.812), train_loss = 2.15872600, grad/param norm = 2.1030e-01, time/batch = 0.6945s	
1809/32150 (epoch 2.813), train_loss = 2.30037201, grad/param norm = 2.1641e-01, time/batch = 0.6870s	
1810/32150 (epoch 2.815), train_loss = 1.90575222, grad/param norm = 2.3684e-01, time/batch = 0.6947s	
1811/32150 (epoch 2.816), train_loss = 2.07565908, grad/param norm = 2.7621e-01, time/batch = 0.7075s	
1812/32150 (epoch 2.818), train_loss = 2.03279508, grad/param norm = 2.3945e-01, time/batch = 0.6924s	
1813/32150 (epoch 2.820), train_loss = 2.16523939, grad/param norm = 2.6685e-01, time/batch = 0.6877s	
1814/32150 (epoch 2.821), train_loss = 2.31168737, grad/param norm = 2.0105e-01, time/batch = 0.7041s	
1815/32150 (epoch 2.823), train_loss = 2.18841109, grad/param norm = 2.7326e-01, time/batch = 0.7085s	
1816/32150 (epoch 2.824), train_loss = 2.25181571, grad/param norm = 2.3750e-01, time/batch = 0.7068s	
1817/32150 (epoch 2.826), train_loss = 2.10147241, grad/param norm = 2.4120e-01, time/batch = 0.7011s	
1818/32150 (epoch 2.827), train_loss = 2.29443007, grad/param norm = 2.2291e-01, time/batch = 0.7011s	
1819/32150 (epoch 2.829), train_loss = 2.13830798, grad/param norm = 1.8733e-01, time/batch = 0.6764s	
1820/32150 (epoch 2.830), train_loss = 2.12616637, grad/param norm = 2.3492e-01, time/batch = 0.6858s	
1821/32150 (epoch 2.832), train_loss = 2.15031328, grad/param norm = 2.6306e-01, time/batch = 0.6890s	
1822/32150 (epoch 2.834), train_loss = 2.31134454, grad/param norm = 2.1293e-01, time/batch = 0.6919s	
1823/32150 (epoch 2.835), train_loss = 2.09147382, grad/param norm = 2.2526e-01, time/batch = 0.6877s	
1824/32150 (epoch 2.837), train_loss = 2.18816624, grad/param norm = 2.0759e-01, time/batch = 0.6893s	
1825/32150 (epoch 2.838), train_loss = 2.34265123, grad/param norm = 2.3827e-01, time/batch = 0.6874s	
1826/32150 (epoch 2.840), train_loss = 2.11002137, grad/param norm = 2.4213e-01, time/batch = 0.6839s	
1827/32150 (epoch 2.841), train_loss = 2.10702219, grad/param norm = 2.4022e-01, time/batch = 0.6865s	
1828/32150 (epoch 2.843), train_loss = 2.11577301, grad/param norm = 2.2611e-01, time/batch = 0.6882s	
1829/32150 (epoch 2.844), train_loss = 1.92910059, grad/param norm = 2.3387e-01, time/batch = 0.6815s	
1830/32150 (epoch 2.846), train_loss = 1.89671048, grad/param norm = 2.3811e-01, time/batch = 0.6840s	
1831/32150 (epoch 2.848), train_loss = 2.27091671, grad/param norm = 2.6612e-01, time/batch = 0.6896s	
1832/32150 (epoch 2.849), train_loss = 2.35577560, grad/param norm = 2.7684e-01, time/batch = 0.7061s	
1833/32150 (epoch 2.851), train_loss = 2.14297102, grad/param norm = 2.6602e-01, time/batch = 0.6973s	
1834/32150 (epoch 2.852), train_loss = 2.31341352, grad/param norm = 2.8750e-01, time/batch = 0.7089s	
1835/32150 (epoch 2.854), train_loss = 2.39910181, grad/param norm = 2.1966e-01, time/batch = 0.7016s	
1836/32150 (epoch 2.855), train_loss = 2.23816750, grad/param norm = 2.2049e-01, time/batch = 0.6881s	
1837/32150 (epoch 2.857), train_loss = 2.25808965, grad/param norm = 2.2010e-01, time/batch = 0.6963s	
1838/32150 (epoch 2.858), train_loss = 2.46154874, grad/param norm = 2.4030e-01, time/batch = 0.6815s	
1839/32150 (epoch 2.860), train_loss = 2.20461368, grad/param norm = 2.5225e-01, time/batch = 0.6817s	
1840/32150 (epoch 2.862), train_loss = 2.42717152, grad/param norm = 2.5429e-01, time/batch = 0.6805s	
1841/32150 (epoch 2.863), train_loss = 2.17214754, grad/param norm = 2.3351e-01, time/batch = 0.6823s	
1842/32150 (epoch 2.865), train_loss = 1.97933067, grad/param norm = 2.0895e-01, time/batch = 0.6779s	
1843/32150 (epoch 2.866), train_loss = 2.05030216, grad/param norm = 1.9998e-01, time/batch = 0.6783s	
1844/32150 (epoch 2.868), train_loss = 2.30292069, grad/param norm = 2.2444e-01, time/batch = 0.6817s	
1845/32150 (epoch 2.869), train_loss = 2.04644795, grad/param norm = 2.7354e-01, time/batch = 0.6898s	
1846/32150 (epoch 2.871), train_loss = 2.08949278, grad/param norm = 2.3910e-01, time/batch = 0.7004s	
1847/32150 (epoch 2.872), train_loss = 2.38012436, grad/param norm = 2.5358e-01, time/batch = 0.7008s	
1848/32150 (epoch 2.874), train_loss = 2.10140604, grad/param norm = 2.4316e-01, time/batch = 0.6851s	
1849/32150 (epoch 2.876), train_loss = 1.98678975, grad/param norm = 2.0542e-01, time/batch = 0.6865s	
1850/32150 (epoch 2.877), train_loss = 2.15767581, grad/param norm = 2.4408e-01, time/batch = 0.6850s	
1851/32150 (epoch 2.879), train_loss = 2.21846837, grad/param norm = 2.1563e-01, time/batch = 0.6874s	
1852/32150 (epoch 2.880), train_loss = 2.24359100, grad/param norm = 2.2989e-01, time/batch = 0.6854s	
1853/32150 (epoch 2.882), train_loss = 2.05329198, grad/param norm = 2.0358e-01, time/batch = 0.6921s	
1854/32150 (epoch 2.883), train_loss = 2.24119585, grad/param norm = 2.3015e-01, time/batch = 0.7022s	
1855/32150 (epoch 2.885), train_loss = 2.06054694, grad/param norm = 2.3114e-01, time/batch = 0.7077s	
1856/32150 (epoch 2.886), train_loss = 2.21512714, grad/param norm = 2.3923e-01, time/batch = 0.7051s	
1857/32150 (epoch 2.888), train_loss = 2.03477929, grad/param norm = 2.0618e-01, time/batch = 0.7021s	
1858/32150 (epoch 2.890), train_loss = 2.29198118, grad/param norm = 2.2183e-01, time/batch = 0.6953s	
1859/32150 (epoch 2.891), train_loss = 2.21691176, grad/param norm = 2.1890e-01, time/batch = 0.7025s	
1860/32150 (epoch 2.893), train_loss = 2.11826840, grad/param norm = 2.1128e-01, time/batch = 0.7036s	
1861/32150 (epoch 2.894), train_loss = 2.04787913, grad/param norm = 2.1538e-01, time/batch = 0.6986s	
1862/32150 (epoch 2.896), train_loss = 2.12891501, grad/param norm = 2.2797e-01, time/batch = 0.6972s	
1863/32150 (epoch 2.897), train_loss = 2.19535081, grad/param norm = 2.4409e-01, time/batch = 0.6913s	
1864/32150 (epoch 2.899), train_loss = 2.11885644, grad/param norm = 2.2354e-01, time/batch = 0.6933s	
1865/32150 (epoch 2.900), train_loss = 2.17264620, grad/param norm = 2.3758e-01, time/batch = 0.6930s	
1866/32150 (epoch 2.902), train_loss = 2.16397751, grad/param norm = 2.6184e-01, time/batch = 0.6858s	
1867/32150 (epoch 2.904), train_loss = 2.20529694, grad/param norm = 2.7854e-01, time/batch = 0.6841s	
1868/32150 (epoch 2.905), train_loss = 2.29965530, grad/param norm = 2.4131e-01, time/batch = 0.6814s	
1869/32150 (epoch 2.907), train_loss = 2.10600800, grad/param norm = 2.6435e-01, time/batch = 0.6838s	
1870/32150 (epoch 2.908), train_loss = 2.24077403, grad/param norm = 2.4684e-01, time/batch = 0.6885s	
1871/32150 (epoch 2.910), train_loss = 2.02767196, grad/param norm = 2.1655e-01, time/batch = 0.7065s	
1872/32150 (epoch 2.911), train_loss = 2.00657908, grad/param norm = 2.2472e-01, time/batch = 0.7033s	
1873/32150 (epoch 2.913), train_loss = 2.18108876, grad/param norm = 2.2874e-01, time/batch = 0.7081s	
1874/32150 (epoch 2.914), train_loss = 2.29026497, grad/param norm = 2.5406e-01, time/batch = 0.7176s	
1875/32150 (epoch 2.916), train_loss = 2.03768882, grad/param norm = 2.1118e-01, time/batch = 0.6957s	
1876/32150 (epoch 2.918), train_loss = 2.22481507, grad/param norm = 2.8012e-01, time/batch = 0.6918s	
1877/32150 (epoch 2.919), train_loss = 2.26012898, grad/param norm = 2.2679e-01, time/batch = 0.6981s	
1878/32150 (epoch 2.921), train_loss = 2.28296506, grad/param norm = 2.2063e-01, time/batch = 0.6905s	
1879/32150 (epoch 2.922), train_loss = 2.07998503, grad/param norm = 2.1764e-01, time/batch = 0.6809s	
1880/32150 (epoch 2.924), train_loss = 2.17040385, grad/param norm = 2.4320e-01, time/batch = 0.6804s	
1881/32150 (epoch 2.925), train_loss = 2.19485969, grad/param norm = 2.0339e-01, time/batch = 0.6843s	
1882/32150 (epoch 2.927), train_loss = 1.99811959, grad/param norm = 2.0897e-01, time/batch = 0.6983s	
1883/32150 (epoch 2.928), train_loss = 2.39748804, grad/param norm = 2.7535e-01, time/batch = 0.7013s	
1884/32150 (epoch 2.930), train_loss = 2.14585263, grad/param norm = 2.5347e-01, time/batch = 0.6998s	
1885/32150 (epoch 2.932), train_loss = 2.17380471, grad/param norm = 2.5881e-01, time/batch = 0.6852s	
1886/32150 (epoch 2.933), train_loss = 2.26681975, grad/param norm = 2.2033e-01, time/batch = 0.6860s	
1887/32150 (epoch 2.935), train_loss = 2.02832817, grad/param norm = 2.4097e-01, time/batch = 0.6766s	
1888/32150 (epoch 2.936), train_loss = 2.08955973, grad/param norm = 1.8787e-01, time/batch = 0.6749s	
1889/32150 (epoch 2.938), train_loss = 2.06762086, grad/param norm = 2.1848e-01, time/batch = 0.6765s	
1890/32150 (epoch 2.939), train_loss = 2.29441792, grad/param norm = 2.1678e-01, time/batch = 0.6718s	
1891/32150 (epoch 2.941), train_loss = 1.99450974, grad/param norm = 2.1468e-01, time/batch = 0.6773s	
1892/32150 (epoch 2.942), train_loss = 2.33529061, grad/param norm = 2.1710e-01, time/batch = 0.6805s	
1893/32150 (epoch 2.944), train_loss = 2.06821988, grad/param norm = 2.1817e-01, time/batch = 0.6829s	
1894/32150 (epoch 2.946), train_loss = 1.99579173, grad/param norm = 2.0357e-01, time/batch = 0.7041s	
1895/32150 (epoch 2.947), train_loss = 2.16302582, grad/param norm = 2.1799e-01, time/batch = 0.6918s	
1896/32150 (epoch 2.949), train_loss = 2.13737675, grad/param norm = 1.9150e-01, time/batch = 0.6899s	
1897/32150 (epoch 2.950), train_loss = 2.14319180, grad/param norm = 2.0796e-01, time/batch = 0.7033s	
1898/32150 (epoch 2.952), train_loss = 1.87744412, grad/param norm = 2.1246e-01, time/batch = 0.7216s	
1899/32150 (epoch 2.953), train_loss = 1.90232091, grad/param norm = 2.1436e-01, time/batch = 0.7238s	
1900/32150 (epoch 2.955), train_loss = 1.93529202, grad/param norm = 2.1063e-01, time/batch = 0.7026s	
1901/32150 (epoch 2.956), train_loss = 1.92796728, grad/param norm = 2.1521e-01, time/batch = 0.7064s	
1902/32150 (epoch 2.958), train_loss = 2.08580386, grad/param norm = 2.4739e-01, time/batch = 0.7077s	
1903/32150 (epoch 2.960), train_loss = 2.21011303, grad/param norm = 2.2551e-01, time/batch = 0.7086s	
1904/32150 (epoch 2.961), train_loss = 2.11075903, grad/param norm = 2.5016e-01, time/batch = 0.7021s	
1905/32150 (epoch 2.963), train_loss = 2.18884473, grad/param norm = 2.3649e-01, time/batch = 0.6986s	
1906/32150 (epoch 2.964), train_loss = 2.23787001, grad/param norm = 2.4566e-01, time/batch = 0.6990s	
1907/32150 (epoch 2.966), train_loss = 2.34513638, grad/param norm = 2.0843e-01, time/batch = 0.7252s	
1908/32150 (epoch 2.967), train_loss = 2.00362007, grad/param norm = 2.0337e-01, time/batch = 0.7025s	
1909/32150 (epoch 2.969), train_loss = 2.08485897, grad/param norm = 2.2271e-01, time/batch = 0.7021s	
1910/32150 (epoch 2.970), train_loss = 2.11393611, grad/param norm = 2.2951e-01, time/batch = 0.7062s	
1911/32150 (epoch 2.972), train_loss = 2.27037021, grad/param norm = 2.3175e-01, time/batch = 0.7006s	
1912/32150 (epoch 2.974), train_loss = 2.35758249, grad/param norm = 3.1666e-01, time/batch = 0.6952s	
1913/32150 (epoch 2.975), train_loss = 2.10297713, grad/param norm = 2.5707e-01, time/batch = 0.6947s	
1914/32150 (epoch 2.977), train_loss = 2.13854564, grad/param norm = 2.1008e-01, time/batch = 0.6884s	
1915/32150 (epoch 2.978), train_loss = 2.06680697, grad/param norm = 2.0127e-01, time/batch = 0.6855s	
1916/32150 (epoch 2.980), train_loss = 2.08842847, grad/param norm = 2.4489e-01, time/batch = 0.7002s	
1917/32150 (epoch 2.981), train_loss = 2.11636786, grad/param norm = 2.1790e-01, time/batch = 0.7004s	
1918/32150 (epoch 2.983), train_loss = 2.09163989, grad/param norm = 2.3300e-01, time/batch = 0.6893s	
1919/32150 (epoch 2.984), train_loss = 2.10007120, grad/param norm = 2.1131e-01, time/batch = 0.6830s	
1920/32150 (epoch 2.986), train_loss = 2.05115178, grad/param norm = 2.0367e-01, time/batch = 0.6793s	
1921/32150 (epoch 2.988), train_loss = 1.93444617, grad/param norm = 1.8872e-01, time/batch = 0.6853s	
1922/32150 (epoch 2.989), train_loss = 2.18496682, grad/param norm = 2.4541e-01, time/batch = 0.6801s	
1923/32150 (epoch 2.991), train_loss = 2.09621894, grad/param norm = 2.0811e-01, time/batch = 0.6820s	
1924/32150 (epoch 2.992), train_loss = 1.99093391, grad/param norm = 1.9794e-01, time/batch = 0.6964s	
1925/32150 (epoch 2.994), train_loss = 2.11624173, grad/param norm = 2.5556e-01, time/batch = 0.6965s	
1926/32150 (epoch 2.995), train_loss = 2.20940620, grad/param norm = 2.9762e-01, time/batch = 0.6876s	
1927/32150 (epoch 2.997), train_loss = 2.30905120, grad/param norm = 2.3987e-01, time/batch = 0.6929s	
1928/32150 (epoch 2.998), train_loss = 2.17755048, grad/param norm = 2.2088e-01, time/batch = 0.6887s	
1929/32150 (epoch 3.000), train_loss = 2.26793089, grad/param norm = 2.2149e-01, time/batch = 0.6829s	
1930/32150 (epoch 3.002), train_loss = 2.46607677, grad/param norm = 2.5530e-01, time/batch = 0.6885s	
1931/32150 (epoch 3.003), train_loss = 2.35751080, grad/param norm = 2.2924e-01, time/batch = 0.7005s	
1932/32150 (epoch 3.005), train_loss = 2.09786076, grad/param norm = 2.1846e-01, time/batch = 0.6980s	
1933/32150 (epoch 3.006), train_loss = 2.19169347, grad/param norm = 2.2449e-01, time/batch = 0.7004s	
1934/32150 (epoch 3.008), train_loss = 2.14056656, grad/param norm = 2.4021e-01, time/batch = 0.6827s	
1935/32150 (epoch 3.009), train_loss = 1.90406988, grad/param norm = 2.1871e-01, time/batch = 0.6821s	
1936/32150 (epoch 3.011), train_loss = 2.27687454, grad/param norm = 2.4144e-01, time/batch = 0.6879s	
1937/32150 (epoch 3.012), train_loss = 2.05985427, grad/param norm = 2.7846e-01, time/batch = 0.6794s	
1938/32150 (epoch 3.014), train_loss = 2.20455295, grad/param norm = 2.2441e-01, time/batch = 0.6757s	
1939/32150 (epoch 3.016), train_loss = 2.17723241, grad/param norm = 2.0128e-01, time/batch = 0.6763s	
1940/32150 (epoch 3.017), train_loss = 2.14998536, grad/param norm = 2.0875e-01, time/batch = 0.6769s	
1941/32150 (epoch 3.019), train_loss = 2.14871169, grad/param norm = 2.1466e-01, time/batch = 0.6852s	
1942/32150 (epoch 3.020), train_loss = 2.20082666, grad/param norm = 2.1692e-01, time/batch = 0.6859s	
1943/32150 (epoch 3.022), train_loss = 2.12483622, grad/param norm = 2.3808e-01, time/batch = 0.6857s	
1944/32150 (epoch 3.023), train_loss = 2.00363335, grad/param norm = 2.0926e-01, time/batch = 0.6805s	
1945/32150 (epoch 3.025), train_loss = 2.25221746, grad/param norm = 2.2207e-01, time/batch = 0.6861s	
1946/32150 (epoch 3.026), train_loss = 2.21093011, grad/param norm = 2.2424e-01, time/batch = 0.6829s	
1947/32150 (epoch 3.028), train_loss = 1.92714344, grad/param norm = 2.3595e-01, time/batch = 0.6945s	
1948/32150 (epoch 3.030), train_loss = 2.20341950, grad/param norm = 2.5895e-01, time/batch = 0.6839s	
1949/32150 (epoch 3.031), train_loss = 2.14817915, grad/param norm = 1.9662e-01, time/batch = 0.6832s	
1950/32150 (epoch 3.033), train_loss = 2.38492797, grad/param norm = 2.1612e-01, time/batch = 0.6877s	
1951/32150 (epoch 3.034), train_loss = 2.18347148, grad/param norm = 1.7843e-01, time/batch = 0.6904s	
1952/32150 (epoch 3.036), train_loss = 2.17078634, grad/param norm = 2.7267e-01, time/batch = 0.6930s	
1953/32150 (epoch 3.037), train_loss = 2.12171059, grad/param norm = 2.5882e-01, time/batch = 0.6854s	
1954/32150 (epoch 3.039), train_loss = 2.19530780, grad/param norm = 2.2486e-01, time/batch = 0.6934s	
1955/32150 (epoch 3.040), train_loss = 2.31480018, grad/param norm = 2.0391e-01, time/batch = 0.6956s	
1956/32150 (epoch 3.042), train_loss = 2.23402431, grad/param norm = 2.0223e-01, time/batch = 0.6952s	
1957/32150 (epoch 3.044), train_loss = 2.25996740, grad/param norm = 1.9762e-01, time/batch = 0.6949s	
1958/32150 (epoch 3.045), train_loss = 2.05142263, grad/param norm = 2.2316e-01, time/batch = 0.7044s	
1959/32150 (epoch 3.047), train_loss = 2.04047424, grad/param norm = 2.6471e-01, time/batch = 0.6937s	
1960/32150 (epoch 3.048), train_loss = 2.20543464, grad/param norm = 2.2658e-01, time/batch = 0.7009s	
1961/32150 (epoch 3.050), train_loss = 2.14293236, grad/param norm = 2.2859e-01, time/batch = 0.6961s	
1962/32150 (epoch 3.051), train_loss = 2.22949536, grad/param norm = 2.2453e-01, time/batch = 0.6898s	
1963/32150 (epoch 3.053), train_loss = 2.06974888, grad/param norm = 2.1298e-01, time/batch = 0.6900s	
1964/32150 (epoch 3.054), train_loss = 2.11959586, grad/param norm = 2.1124e-01, time/batch = 0.6897s	
1965/32150 (epoch 3.056), train_loss = 2.13732642, grad/param norm = 2.0708e-01, time/batch = 0.7041s	
1966/32150 (epoch 3.058), train_loss = 1.98569443, grad/param norm = 2.0557e-01, time/batch = 0.6952s	
1967/32150 (epoch 3.059), train_loss = 2.12338394, grad/param norm = 2.9753e-01, time/batch = 0.6878s	
1968/32150 (epoch 3.061), train_loss = 2.21065616, grad/param norm = 1.9450e-01, time/batch = 0.6911s	
1969/32150 (epoch 3.062), train_loss = 2.12508575, grad/param norm = 2.5621e-01, time/batch = 0.6977s	
1970/32150 (epoch 3.064), train_loss = 1.96525995, grad/param norm = 2.2739e-01, time/batch = 0.6941s	
1971/32150 (epoch 3.065), train_loss = 2.20838938, grad/param norm = 2.4294e-01, time/batch = 0.7018s	
1972/32150 (epoch 3.067), train_loss = 2.17569714, grad/param norm = 2.5102e-01, time/batch = 0.6889s	
1973/32150 (epoch 3.068), train_loss = 2.17086292, grad/param norm = 2.3405e-01, time/batch = 0.6995s	
1974/32150 (epoch 3.070), train_loss = 2.05063750, grad/param norm = 2.2239e-01, time/batch = 0.6882s	
1975/32150 (epoch 3.072), train_loss = 2.14393448, grad/param norm = 2.1904e-01, time/batch = 0.6889s	
1976/32150 (epoch 3.073), train_loss = 2.17903666, grad/param norm = 2.1994e-01, time/batch = 0.6932s	
1977/32150 (epoch 3.075), train_loss = 2.15150695, grad/param norm = 2.1434e-01, time/batch = 0.6831s	
1978/32150 (epoch 3.076), train_loss = 2.29245303, grad/param norm = 2.6510e-01, time/batch = 0.6823s	
1979/32150 (epoch 3.078), train_loss = 2.25382781, grad/param norm = 2.2093e-01, time/batch = 0.6888s	
1980/32150 (epoch 3.079), train_loss = 2.04651970, grad/param norm = 2.0071e-01, time/batch = 0.6830s	
1981/32150 (epoch 3.081), train_loss = 2.10479071, grad/param norm = 2.5631e-01, time/batch = 0.6832s	
1982/32150 (epoch 3.082), train_loss = 2.13630397, grad/param norm = 2.1705e-01, time/batch = 0.6822s	
1983/32150 (epoch 3.084), train_loss = 2.19836129, grad/param norm = 2.4989e-01, time/batch = 0.6819s	
1984/32150 (epoch 3.086), train_loss = 2.10828092, grad/param norm = 2.5684e-01, time/batch = 0.6805s	
1985/32150 (epoch 3.087), train_loss = 2.02878980, grad/param norm = 2.1217e-01, time/batch = 0.6735s	
1986/32150 (epoch 3.089), train_loss = 2.08166186, grad/param norm = 2.4607e-01, time/batch = 0.6787s	
1987/32150 (epoch 3.090), train_loss = 1.99742105, grad/param norm = 2.0406e-01, time/batch = 0.6765s	
1988/32150 (epoch 3.092), train_loss = 2.12567600, grad/param norm = 2.0716e-01, time/batch = 0.6808s	
1989/32150 (epoch 3.093), train_loss = 1.94641206, grad/param norm = 2.1708e-01, time/batch = 0.7007s	
1990/32150 (epoch 3.095), train_loss = 2.10510867, grad/param norm = 2.3565e-01, time/batch = 0.6885s	
1991/32150 (epoch 3.096), train_loss = 2.11681602, grad/param norm = 2.1209e-01, time/batch = 0.6889s	
1992/32150 (epoch 3.098), train_loss = 2.01194842, grad/param norm = 2.2581e-01, time/batch = 0.6844s	
1993/32150 (epoch 3.100), train_loss = 2.02364116, grad/param norm = 2.1130e-01, time/batch = 0.6833s	
1994/32150 (epoch 3.101), train_loss = 1.96829595, grad/param norm = 2.2445e-01, time/batch = 0.6833s	
1995/32150 (epoch 3.103), train_loss = 2.15010084, grad/param norm = 2.0213e-01, time/batch = 0.6953s	
1996/32150 (epoch 3.104), train_loss = 1.95408244, grad/param norm = 2.1643e-01, time/batch = 0.6840s	
1997/32150 (epoch 3.106), train_loss = 2.12280695, grad/param norm = 1.8846e-01, time/batch = 0.6800s	
1998/32150 (epoch 3.107), train_loss = 2.16613546, grad/param norm = 2.1674e-01, time/batch = 0.6836s	
1999/32150 (epoch 3.109), train_loss = 2.13946115, grad/param norm = 2.0171e-01, time/batch = 0.6876s	
evaluating loss over split index 2	
1/34...	
2/34...	
3/34...	
4/34...	
5/34...	
6/34...	
7/34...	
8/34...	
9/34...	
10/34...	
11/34...	
12/34...	
13/34...	
14/34...	
15/34...	
16/34...	
17/34...	
18/34...	
19/34...	
20/34...	
21/34...	
22/34...	
23/34...	
24/34...	
25/34...	
26/34...	
27/34...	
28/34...	
29/34...	
30/34...	
31/34...	
32/34...	
33/34...	
34/34...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_andre_epoch3.11_2.2064.t7	
2000/32150 (epoch 3.110), train_loss = 2.13011253, grad/param norm = 2.3125e-01, time/batch = 0.6843s	
2001/32150 (epoch 3.112), train_loss = 2.13582651, grad/param norm = 2.2051e-01, time/batch = 0.6986s	
2002/32150 (epoch 3.114), train_loss = 2.12698930, grad/param norm = 1.9697e-01, time/batch = 0.7022s	
2003/32150 (epoch 3.115), train_loss = 2.11392644, grad/param norm = 2.0557e-01, time/batch = 0.6963s	
2004/32150 (epoch 3.117), train_loss = 2.15043963, grad/param norm = 2.0860e-01, time/batch = 0.6965s	
2005/32150 (epoch 3.118), train_loss = 2.01453068, grad/param norm = 2.2699e-01, time/batch = 0.7015s	
2006/32150 (epoch 3.120), train_loss = 2.28925357, grad/param norm = 2.5906e-01, time/batch = 0.7024s	
2007/32150 (epoch 3.121), train_loss = 1.99526375, grad/param norm = 2.1835e-01, time/batch = 0.6963s	
2008/32150 (epoch 3.123), train_loss = 2.16702907, grad/param norm = 2.2733e-01, time/batch = 0.7042s	
2009/32150 (epoch 3.124), train_loss = 2.18061383, grad/param norm = 1.9577e-01, time/batch = 0.7012s	
2010/32150 (epoch 3.126), train_loss = 2.18374061, grad/param norm = 2.0169e-01, time/batch = 0.7056s	
2011/32150 (epoch 3.128), train_loss = 2.08136732, grad/param norm = 2.1727e-01, time/batch = 0.7037s	
2012/32150 (epoch 3.129), train_loss = 2.07376000, grad/param norm = 1.7887e-01, time/batch = 0.7038s	
2013/32150 (epoch 3.131), train_loss = 2.20152195, grad/param norm = 2.5080e-01, time/batch = 0.6930s	
2014/32150 (epoch 3.132), train_loss = 2.03924318, grad/param norm = 2.2970e-01, time/batch = 0.6911s	
2015/32150 (epoch 3.134), train_loss = 2.18830173, grad/param norm = 2.3984e-01, time/batch = 0.6859s	
2016/32150 (epoch 3.135), train_loss = 2.04556021, grad/param norm = 2.1533e-01, time/batch = 0.6882s	
2017/32150 (epoch 3.137), train_loss = 2.02161654, grad/param norm = 2.1617e-01, time/batch = 0.6876s	
2018/32150 (epoch 3.138), train_loss = 2.15086091, grad/param norm = 2.1196e-01, time/batch = 0.6946s	
2019/32150 (epoch 3.140), train_loss = 2.14971159, grad/param norm = 2.5893e-01, time/batch = 0.6851s	
2020/32150 (epoch 3.142), train_loss = 2.16068791, grad/param norm = 2.1801e-01, time/batch = 0.6799s	
2021/32150 (epoch 3.143), train_loss = 1.97774919, grad/param norm = 2.4418e-01, time/batch = 0.6820s	
2022/32150 (epoch 3.145), train_loss = 1.89249126, grad/param norm = 2.0771e-01, time/batch = 0.6825s	
2023/32150 (epoch 3.146), train_loss = 1.85586350, grad/param norm = 2.1169e-01, time/batch = 0.6860s	
2024/32150 (epoch 3.148), train_loss = 1.74301070, grad/param norm = 1.9821e-01, time/batch = 0.6967s	
2025/32150 (epoch 3.149), train_loss = 2.11670874, grad/param norm = 2.4189e-01, time/batch = 0.7019s	
2026/32150 (epoch 3.151), train_loss = 2.01703960, grad/param norm = 2.4783e-01, time/batch = 0.6927s	
2027/32150 (epoch 3.152), train_loss = 2.19845424, grad/param norm = 2.2234e-01, time/batch = 0.6917s	
2028/32150 (epoch 3.154), train_loss = 1.92313292, grad/param norm = 2.2319e-01, time/batch = 0.6875s	
2029/32150 (epoch 3.156), train_loss = 1.95893682, grad/param norm = 2.4501e-01, time/batch = 0.6929s	
2030/32150 (epoch 3.157), train_loss = 2.19200978, grad/param norm = 2.3404e-01, time/batch = 0.6871s	
2031/32150 (epoch 3.159), train_loss = 2.14457029, grad/param norm = 1.9739e-01, time/batch = 0.6954s	
2032/32150 (epoch 3.160), train_loss = 2.28132668, grad/param norm = 2.0951e-01, time/batch = 0.6908s	
2033/32150 (epoch 3.162), train_loss = 2.18529731, grad/param norm = 2.0924e-01, time/batch = 0.6844s	
2034/32150 (epoch 3.163), train_loss = 1.99239799, grad/param norm = 1.9595e-01, time/batch = 0.6957s	
2035/32150 (epoch 3.165), train_loss = 2.18017447, grad/param norm = 2.1793e-01, time/batch = 0.7019s	
2036/32150 (epoch 3.166), train_loss = 2.21482491, grad/param norm = 2.4339e-01, time/batch = 0.7029s	
2037/32150 (epoch 3.168), train_loss = 2.07753239, grad/param norm = 2.3646e-01, time/batch = 0.6829s	
2038/32150 (epoch 3.170), train_loss = 2.13077733, grad/param norm = 2.4449e-01, time/batch = 0.6882s	
2039/32150 (epoch 3.171), train_loss = 2.14566462, grad/param norm = 2.2337e-01, time/batch = 0.6822s	
2040/32150 (epoch 3.173), train_loss = 2.13963310, grad/param norm = 2.0418e-01, time/batch = 0.6888s	
2041/32150 (epoch 3.174), train_loss = 1.94813022, grad/param norm = 2.2196e-01, time/batch = 0.7306s	
2042/32150 (epoch 3.176), train_loss = 1.87612097, grad/param norm = 2.0845e-01, time/batch = 0.7215s	
2043/32150 (epoch 3.177), train_loss = 2.10380162, grad/param norm = 2.3735e-01, time/batch = 0.6940s	
2044/32150 (epoch 3.179), train_loss = 2.06455444, grad/param norm = 2.0284e-01, time/batch = 0.6925s	
2045/32150 (epoch 3.180), train_loss = 2.12112389, grad/param norm = 2.2107e-01, time/batch = 0.6933s	
2046/32150 (epoch 3.182), train_loss = 2.01221295, grad/param norm = 2.2582e-01, time/batch = 0.6838s	
2047/32150 (epoch 3.184), train_loss = 1.96757706, grad/param norm = 2.0036e-01, time/batch = 0.6978s	
2048/32150 (epoch 3.185), train_loss = 1.94601676, grad/param norm = 2.5426e-01, time/batch = 0.6944s	
2049/32150 (epoch 3.187), train_loss = 1.96522999, grad/param norm = 2.3138e-01, time/batch = 0.6966s	
2050/32150 (epoch 3.188), train_loss = 2.08459342, grad/param norm = 2.1676e-01, time/batch = 0.6891s	
2051/32150 (epoch 3.190), train_loss = 2.26261084, grad/param norm = 2.6543e-01, time/batch = 0.6954s	
2052/32150 (epoch 3.191), train_loss = 2.20443766, grad/param norm = 3.0331e-01, time/batch = 0.6809s	
2053/32150 (epoch 3.193), train_loss = 2.26249772, grad/param norm = 2.7754e-01, time/batch = 0.6931s	
2054/32150 (epoch 3.194), train_loss = 2.22932893, grad/param norm = 2.5646e-01, time/batch = 0.6916s	
2055/32150 (epoch 3.196), train_loss = 2.23611976, grad/param norm = 2.4937e-01, time/batch = 0.6978s	
2056/32150 (epoch 3.198), train_loss = 2.10929651, grad/param norm = 2.2550e-01, time/batch = 0.6911s	
2057/32150 (epoch 3.199), train_loss = 2.02843037, grad/param norm = 2.3233e-01, time/batch = 0.6906s	
2058/32150 (epoch 3.201), train_loss = 2.14430486, grad/param norm = 2.1496e-01, time/batch = 0.7009s	
2059/32150 (epoch 3.202), train_loss = 2.14603536, grad/param norm = 2.2910e-01, time/batch = 0.6932s	
2060/32150 (epoch 3.204), train_loss = 2.26165142, grad/param norm = 2.3352e-01, time/batch = 0.6912s	
2061/32150 (epoch 3.205), train_loss = 2.18425963, grad/param norm = 2.4580e-01, time/batch = 0.6955s	
2062/32150 (epoch 3.207), train_loss = 1.99630410, grad/param norm = 2.0650e-01, time/batch = 0.6960s	
2063/32150 (epoch 3.208), train_loss = 2.00014644, grad/param norm = 2.2081e-01, time/batch = 0.6916s	
2064/32150 (epoch 3.210), train_loss = 2.01929394, grad/param norm = 1.9376e-01, time/batch = 0.6960s	
2065/32150 (epoch 3.212), train_loss = 2.07473806, grad/param norm = 1.9699e-01, time/batch = 0.6953s	
2066/32150 (epoch 3.213), train_loss = 2.04551263, grad/param norm = 2.6285e-01, time/batch = 0.6894s	
2067/32150 (epoch 3.215), train_loss = 1.99297723, grad/param norm = 2.4964e-01, time/batch = 0.6905s	
2068/32150 (epoch 3.216), train_loss = 2.03334945, grad/param norm = 2.1510e-01, time/batch = 0.6926s	
2069/32150 (epoch 3.218), train_loss = 2.07817033, grad/param norm = 2.3650e-01, time/batch = 0.7010s	
2070/32150 (epoch 3.219), train_loss = 1.93281041, grad/param norm = 2.0320e-01, time/batch = 0.6996s	
2071/32150 (epoch 3.221), train_loss = 2.27166303, grad/param norm = 2.2874e-01, time/batch = 0.6949s	
2072/32150 (epoch 3.222), train_loss = 2.09577042, grad/param norm = 2.1806e-01, time/batch = 0.6980s	
2073/32150 (epoch 3.224), train_loss = 2.03143078, grad/param norm = 2.0520e-01, time/batch = 0.6905s	
2074/32150 (epoch 3.226), train_loss = 1.96718378, grad/param norm = 1.8897e-01, time/batch = 0.6966s	
2075/32150 (epoch 3.227), train_loss = 1.95384534, grad/param norm = 2.0787e-01, time/batch = 0.6986s	
2076/32150 (epoch 3.229), train_loss = 2.16485095, grad/param norm = 2.2829e-01, time/batch = 0.6977s	
2077/32150 (epoch 3.230), train_loss = 2.09211144, grad/param norm = 2.5113e-01, time/batch = 0.6929s	
2078/32150 (epoch 3.232), train_loss = 1.97311073, grad/param norm = 2.1050e-01, time/batch = 0.6951s	
2079/32150 (epoch 3.233), train_loss = 1.99007646, grad/param norm = 1.9028e-01, time/batch = 0.6908s	
2080/32150 (epoch 3.235), train_loss = 2.04013982, grad/param norm = 2.4841e-01, time/batch = 0.6882s	
2081/32150 (epoch 3.236), train_loss = 2.17791206, grad/param norm = 2.0621e-01, time/batch = 0.6904s	
2082/32150 (epoch 3.238), train_loss = 2.22759220, grad/param norm = 2.2303e-01, time/batch = 0.6967s	
2083/32150 (epoch 3.240), train_loss = 2.11325130, grad/param norm = 2.4760e-01, time/batch = 0.6925s	
2084/32150 (epoch 3.241), train_loss = 2.23021105, grad/param norm = 2.2670e-01, time/batch = 0.6924s	
2085/32150 (epoch 3.243), train_loss = 2.15097211, grad/param norm = 2.6513e-01, time/batch = 0.6928s	
2086/32150 (epoch 3.244), train_loss = 2.08574049, grad/param norm = 2.0653e-01, time/batch = 0.6914s	
2087/32150 (epoch 3.246), train_loss = 2.28842946, grad/param norm = 2.2216e-01, time/batch = 0.6945s	
2088/32150 (epoch 3.247), train_loss = 2.26210983, grad/param norm = 2.0459e-01, time/batch = 0.6837s	
2089/32150 (epoch 3.249), train_loss = 2.05534150, grad/param norm = 2.0499e-01, time/batch = 0.6950s	
2090/32150 (epoch 3.250), train_loss = 2.13313020, grad/param norm = 2.2542e-01, time/batch = 0.6934s	
2091/32150 (epoch 3.252), train_loss = 2.09965108, grad/param norm = 2.3059e-01, time/batch = 0.6939s	
2092/32150 (epoch 3.253), train_loss = 2.27004062, grad/param norm = 2.6829e-01, time/batch = 0.6938s	
2093/32150 (epoch 3.255), train_loss = 2.07586693, grad/param norm = 2.1590e-01, time/batch = 0.7022s	
2094/32150 (epoch 3.257), train_loss = 2.18297691, grad/param norm = 2.2487e-01, time/batch = 0.6965s	
2095/32150 (epoch 3.258), train_loss = 2.12323622, grad/param norm = 1.8057e-01, time/batch = 0.6930s	
2096/32150 (epoch 3.260), train_loss = 2.28669020, grad/param norm = 1.9949e-01, time/batch = 0.6966s	
2097/32150 (epoch 3.261), train_loss = 2.13854143, grad/param norm = 2.3854e-01, time/batch = 0.6961s	
2098/32150 (epoch 3.263), train_loss = 2.27404311, grad/param norm = 2.0705e-01, time/batch = 0.6967s	
2099/32150 (epoch 3.264), train_loss = 2.09187580, grad/param norm = 2.3265e-01, time/batch = 0.6972s	
2100/32150 (epoch 3.266), train_loss = 2.00284074, grad/param norm = 1.9927e-01, time/batch = 0.6958s	
2101/32150 (epoch 3.267), train_loss = 1.81917739, grad/param norm = 1.8499e-01, time/batch = 0.6997s	
2102/32150 (epoch 3.269), train_loss = 2.05594793, grad/param norm = 2.1231e-01, time/batch = 0.6966s	
2103/32150 (epoch 3.271), train_loss = 1.93265601, grad/param norm = 2.0037e-01, time/batch = 0.6939s	
2104/32150 (epoch 3.272), train_loss = 1.99580979, grad/param norm = 2.6469e-01, time/batch = 0.6938s	
2105/32150 (epoch 3.274), train_loss = 2.20264474, grad/param norm = 2.7269e-01, time/batch = 0.6967s	
2106/32150 (epoch 3.275), train_loss = 2.22206903, grad/param norm = 2.4547e-01, time/batch = 0.6959s	
2107/32150 (epoch 3.277), train_loss = 2.13765979, grad/param norm = 2.3395e-01, time/batch = 0.6924s	
2108/32150 (epoch 3.278), train_loss = 2.11696809, grad/param norm = 2.8686e-01, time/batch = 0.6923s	
2109/32150 (epoch 3.280), train_loss = 2.19697727, grad/param norm = 2.4711e-01, time/batch = 0.6797s	
2110/32150 (epoch 3.281), train_loss = 2.05529012, grad/param norm = 2.3027e-01, time/batch = 0.6849s	
2111/32150 (epoch 3.283), train_loss = 2.22077339, grad/param norm = 2.2141e-01, time/batch = 0.6916s	
2112/32150 (epoch 3.285), train_loss = 2.03923318, grad/param norm = 2.0352e-01, time/batch = 0.6999s	
2113/32150 (epoch 3.286), train_loss = 2.17292545, grad/param norm = 2.4249e-01, time/batch = 0.6930s	
2114/32150 (epoch 3.288), train_loss = 2.20243774, grad/param norm = 2.3006e-01, time/batch = 0.6984s	
2115/32150 (epoch 3.289), train_loss = 2.01282981, grad/param norm = 2.3405e-01, time/batch = 0.7123s	
2116/32150 (epoch 3.291), train_loss = 1.96930641, grad/param norm = 2.0643e-01, time/batch = 0.6975s	
2117/32150 (epoch 3.292), train_loss = 2.15704247, grad/param norm = 2.0195e-01, time/batch = 0.6892s	
2118/32150 (epoch 3.294), train_loss = 2.12120997, grad/param norm = 2.1295e-01, time/batch = 0.6991s	
2119/32150 (epoch 3.295), train_loss = 2.12401304, grad/param norm = 2.3212e-01, time/batch = 0.6945s	
2120/32150 (epoch 3.297), train_loss = 2.09645013, grad/param norm = 2.0472e-01, time/batch = 0.6925s	
2121/32150 (epoch 3.299), train_loss = 2.27050752, grad/param norm = 2.3759e-01, time/batch = 0.7074s	
2122/32150 (epoch 3.300), train_loss = 2.27540719, grad/param norm = 2.2945e-01, time/batch = 0.7066s	
2123/32150 (epoch 3.302), train_loss = 2.08903922, grad/param norm = 2.2535e-01, time/batch = 0.7046s	
2124/32150 (epoch 3.303), train_loss = 2.16347800, grad/param norm = 2.6095e-01, time/batch = 0.6895s	
2125/32150 (epoch 3.305), train_loss = 2.26778484, grad/param norm = 2.9070e-01, time/batch = 0.6872s	
2126/32150 (epoch 3.306), train_loss = 2.13712429, grad/param norm = 2.1884e-01, time/batch = 0.6894s	
2127/32150 (epoch 3.308), train_loss = 2.14365125, grad/param norm = 2.0967e-01, time/batch = 0.6859s	
2128/32150 (epoch 3.309), train_loss = 2.20358224, grad/param norm = 2.2813e-01, time/batch = 0.7115s	
2129/32150 (epoch 3.311), train_loss = 1.91233482, grad/param norm = 2.1588e-01, time/batch = 0.6895s	
2130/32150 (epoch 3.313), train_loss = 2.07340726, grad/param norm = 2.0620e-01, time/batch = 0.6836s	
2131/32150 (epoch 3.314), train_loss = 2.10588184, grad/param norm = 2.3970e-01, time/batch = 0.6864s	
2132/32150 (epoch 3.316), train_loss = 2.07118797, grad/param norm = 2.1976e-01, time/batch = 0.6885s	
2133/32150 (epoch 3.317), train_loss = 2.23173352, grad/param norm = 2.4271e-01, time/batch = 0.6888s	
2134/32150 (epoch 3.319), train_loss = 2.06626093, grad/param norm = 2.0622e-01, time/batch = 0.7027s	
2135/32150 (epoch 3.320), train_loss = 2.10614425, grad/param norm = 1.9764e-01, time/batch = 0.6822s	
2136/32150 (epoch 3.322), train_loss = 2.16139922, grad/param norm = 2.2178e-01, time/batch = 0.6885s	
2137/32150 (epoch 3.323), train_loss = 2.07037402, grad/param norm = 2.2989e-01, time/batch = 0.6900s	
2138/32150 (epoch 3.325), train_loss = 2.08321829, grad/param norm = 2.3359e-01, time/batch = 0.7073s	
2139/32150 (epoch 3.327), train_loss = 2.18791338, grad/param norm = 2.3530e-01, time/batch = 0.7063s	
2140/32150 (epoch 3.328), train_loss = 1.99894018, grad/param norm = 2.0150e-01, time/batch = 0.7059s	
2141/32150 (epoch 3.330), train_loss = 2.14250687, grad/param norm = 2.6365e-01, time/batch = 0.7097s	
2142/32150 (epoch 3.331), train_loss = 2.25006252, grad/param norm = 2.6703e-01, time/batch = 0.6921s	
2143/32150 (epoch 3.333), train_loss = 2.12346350, grad/param norm = 2.2351e-01, time/batch = 0.6936s	
2144/32150 (epoch 3.334), train_loss = 2.16239432, grad/param norm = 1.9819e-01, time/batch = 0.6949s	
2145/32150 (epoch 3.336), train_loss = 2.28317418, grad/param norm = 2.2453e-01, time/batch = 0.6878s	
2146/32150 (epoch 3.337), train_loss = 2.20891864, grad/param norm = 2.3409e-01, time/batch = 0.6900s	
2147/32150 (epoch 3.339), train_loss = 2.27398896, grad/param norm = 2.0619e-01, time/batch = 0.6870s	
2148/32150 (epoch 3.341), train_loss = 2.21900951, grad/param norm = 1.9871e-01, time/batch = 0.6877s	
2149/32150 (epoch 3.342), train_loss = 1.90833061, grad/param norm = 2.0469e-01, time/batch = 0.6861s	
2150/32150 (epoch 3.344), train_loss = 1.89093487, grad/param norm = 2.0070e-01, time/batch = 0.6885s	
2151/32150 (epoch 3.345), train_loss = 2.05274452, grad/param norm = 2.7293e-01, time/batch = 0.6840s	
2152/32150 (epoch 3.347), train_loss = 2.13008659, grad/param norm = 2.1817e-01, time/batch = 0.6903s	
2153/32150 (epoch 3.348), train_loss = 2.06887407, grad/param norm = 2.3065e-01, time/batch = 0.6928s	
2154/32150 (epoch 3.350), train_loss = 2.07371699, grad/param norm = 1.9670e-01, time/batch = 0.6944s	
2155/32150 (epoch 3.351), train_loss = 2.08389636, grad/param norm = 2.3190e-01, time/batch = 0.6913s	
2156/32150 (epoch 3.353), train_loss = 2.04885560, grad/param norm = 2.1334e-01, time/batch = 0.6877s	
2157/32150 (epoch 3.355), train_loss = 1.97087407, grad/param norm = 2.2722e-01, time/batch = 0.6895s	
2158/32150 (epoch 3.356), train_loss = 2.17518354, grad/param norm = 2.2433e-01, time/batch = 0.6799s	
2159/32150 (epoch 3.358), train_loss = 2.12674043, grad/param norm = 2.1677e-01, time/batch = 0.6791s	
2160/32150 (epoch 3.359), train_loss = 1.90100167, grad/param norm = 1.9113e-01, time/batch = 0.6804s	
2161/32150 (epoch 3.361), train_loss = 2.17625149, grad/param norm = 2.2095e-01, time/batch = 0.6858s	
2162/32150 (epoch 3.362), train_loss = 2.05949416, grad/param norm = 2.1392e-01, time/batch = 0.7086s	
2163/32150 (epoch 3.364), train_loss = 1.96796327, grad/param norm = 2.0495e-01, time/batch = 0.6997s	
2164/32150 (epoch 3.365), train_loss = 2.26187341, grad/param norm = 2.2485e-01, time/batch = 0.7065s	
2165/32150 (epoch 3.367), train_loss = 2.17019493, grad/param norm = 2.4180e-01, time/batch = 0.6859s	
2166/32150 (epoch 3.369), train_loss = 2.07892553, grad/param norm = 2.1931e-01, time/batch = 0.6847s	
2167/32150 (epoch 3.370), train_loss = 2.02283961, grad/param norm = 2.0361e-01, time/batch = 0.6870s	
2168/32150 (epoch 3.372), train_loss = 2.16018173, grad/param norm = 2.3339e-01, time/batch = 0.6940s	
2169/32150 (epoch 3.373), train_loss = 2.19105826, grad/param norm = 2.3063e-01, time/batch = 0.6900s	
2170/32150 (epoch 3.375), train_loss = 1.90899208, grad/param norm = 1.8749e-01, time/batch = 0.6912s	
2171/32150 (epoch 3.376), train_loss = 2.09082616, grad/param norm = 2.1119e-01, time/batch = 0.7001s	
2172/32150 (epoch 3.378), train_loss = 2.12428941, grad/param norm = 2.1848e-01, time/batch = 0.6936s	
2173/32150 (epoch 3.379), train_loss = 2.07420089, grad/param norm = 2.2838e-01, time/batch = 0.6901s	
2174/32150 (epoch 3.381), train_loss = 2.25022172, grad/param norm = 2.1087e-01, time/batch = 0.6874s	
2175/32150 (epoch 3.383), train_loss = 1.93182237, grad/param norm = 2.1567e-01, time/batch = 0.6912s	
2176/32150 (epoch 3.384), train_loss = 2.11722055, grad/param norm = 2.6310e-01, time/batch = 0.7015s	
2177/32150 (epoch 3.386), train_loss = 2.14847090, grad/param norm = 2.2385e-01, time/batch = 0.7016s	
2178/32150 (epoch 3.387), train_loss = 2.14139702, grad/param norm = 2.3382e-01, time/batch = 0.6818s	
2179/32150 (epoch 3.389), train_loss = 2.01889130, grad/param norm = 2.3223e-01, time/batch = 0.6823s	
2180/32150 (epoch 3.390), train_loss = 2.09448902, grad/param norm = 2.4547e-01, time/batch = 0.6810s	
2181/32150 (epoch 3.392), train_loss = 2.02457681, grad/param norm = 2.0144e-01, time/batch = 0.6872s	
2182/32150 (epoch 3.393), train_loss = 2.09506619, grad/param norm = 2.3108e-01, time/batch = 0.6842s	
2183/32150 (epoch 3.395), train_loss = 1.87096394, grad/param norm = 2.0686e-01, time/batch = 0.6852s	
2184/32150 (epoch 3.397), train_loss = 2.07071746, grad/param norm = 2.0411e-01, time/batch = 0.6837s	
2185/32150 (epoch 3.398), train_loss = 2.06189371, grad/param norm = 2.0533e-01, time/batch = 0.6834s	
2186/32150 (epoch 3.400), train_loss = 2.22762465, grad/param norm = 2.1038e-01, time/batch = 0.6903s	
2187/32150 (epoch 3.401), train_loss = 2.25053531, grad/param norm = 2.9218e-01, time/batch = 0.6949s	
2188/32150 (epoch 3.403), train_loss = 2.05111978, grad/param norm = 2.3486e-01, time/batch = 0.6824s	
2189/32150 (epoch 3.404), train_loss = 2.01242370, grad/param norm = 2.0048e-01, time/batch = 0.6845s	
2190/32150 (epoch 3.406), train_loss = 2.10449598, grad/param norm = 1.9494e-01, time/batch = 0.6902s	
2191/32150 (epoch 3.407), train_loss = 2.09060038, grad/param norm = 2.0892e-01, time/batch = 0.7063s	
2192/32150 (epoch 3.409), train_loss = 2.11213366, grad/param norm = 2.2157e-01, time/batch = 0.6879s	
2193/32150 (epoch 3.411), train_loss = 2.11359662, grad/param norm = 2.3551e-01, time/batch = 0.6824s	
2194/32150 (epoch 3.412), train_loss = 2.26217599, grad/param norm = 2.0620e-01, time/batch = 0.6834s	
2195/32150 (epoch 3.414), train_loss = 1.90452278, grad/param norm = 2.3358e-01, time/batch = 0.6852s	
2196/32150 (epoch 3.415), train_loss = 1.91693142, grad/param norm = 2.0473e-01, time/batch = 0.6859s	
2197/32150 (epoch 3.417), train_loss = 2.18919321, grad/param norm = 2.2068e-01, time/batch = 0.6866s	
2198/32150 (epoch 3.418), train_loss = 2.22772693, grad/param norm = 2.0473e-01, time/batch = 0.6807s	
2199/32150 (epoch 3.420), train_loss = 2.06904333, grad/param norm = 2.3106e-01, time/batch = 0.6804s	
2200/32150 (epoch 3.421), train_loss = 2.14996285, grad/param norm = 2.7068e-01, time/batch = 0.6811s	
2201/32150 (epoch 3.423), train_loss = 1.87238153, grad/param norm = 2.3612e-01, time/batch = 0.6789s	
2202/32150 (epoch 3.425), train_loss = 1.99548433, grad/param norm = 2.0593e-01, time/batch = 0.6906s	
2203/32150 (epoch 3.426), train_loss = 2.08161994, grad/param norm = 2.2929e-01, time/batch = 0.6856s	
2204/32150 (epoch 3.428), train_loss = 2.11450572, grad/param norm = 2.6918e-01, time/batch = 0.6761s	
2205/32150 (epoch 3.429), train_loss = 1.96587465, grad/param norm = 2.0714e-01, time/batch = 0.6751s	
2206/32150 (epoch 3.431), train_loss = 2.15762699, grad/param norm = 2.2144e-01, time/batch = 0.6716s	
2207/32150 (epoch 3.432), train_loss = 1.92937443, grad/param norm = 1.9351e-01, time/batch = 0.6958s	
2208/32150 (epoch 3.434), train_loss = 2.16841613, grad/param norm = 2.0773e-01, time/batch = 0.6893s	
2209/32150 (epoch 3.435), train_loss = 1.97176062, grad/param norm = 2.0250e-01, time/batch = 0.6830s	
2210/32150 (epoch 3.437), train_loss = 1.92622221, grad/param norm = 2.1805e-01, time/batch = 0.6935s	
2211/32150 (epoch 3.439), train_loss = 1.80102838, grad/param norm = 1.9914e-01, time/batch = 0.6953s	
2212/32150 (epoch 3.440), train_loss = 1.73248121, grad/param norm = 1.8290e-01, time/batch = 0.6828s	
2213/32150 (epoch 3.442), train_loss = 2.01789950, grad/param norm = 2.1187e-01, time/batch = 0.6816s	
2214/32150 (epoch 3.443), train_loss = 1.75519772, grad/param norm = 1.8633e-01, time/batch = 0.6858s	
2215/32150 (epoch 3.445), train_loss = 2.06380601, grad/param norm = 1.9572e-01, time/batch = 0.6876s	
2216/32150 (epoch 3.446), train_loss = 1.85487270, grad/param norm = 2.0728e-01, time/batch = 0.6823s	
2217/32150 (epoch 3.448), train_loss = 1.91959850, grad/param norm = 2.1072e-01, time/batch = 0.6866s	
2218/32150 (epoch 3.449), train_loss = 1.96198273, grad/param norm = 2.1710e-01, time/batch = 0.7001s	
2219/32150 (epoch 3.451), train_loss = 2.12720769, grad/param norm = 2.2984e-01, time/batch = 0.6930s	
2220/32150 (epoch 3.453), train_loss = 2.21293982, grad/param norm = 2.4699e-01, time/batch = 0.6976s	
2221/32150 (epoch 3.454), train_loss = 1.83770173, grad/param norm = 2.1681e-01, time/batch = 0.6875s	
2222/32150 (epoch 3.456), train_loss = 1.88700846, grad/param norm = 1.9355e-01, time/batch = 0.6817s	
2223/32150 (epoch 3.457), train_loss = 2.16046010, grad/param norm = 2.2428e-01, time/batch = 0.6831s	
2224/32150 (epoch 3.459), train_loss = 2.12128453, grad/param norm = 2.4540e-01, time/batch = 0.6835s	
2225/32150 (epoch 3.460), train_loss = 2.07401724, grad/param norm = 2.5860e-01, time/batch = 0.6886s	
2226/32150 (epoch 3.462), train_loss = 2.16250064, grad/param norm = 2.0912e-01, time/batch = 0.6792s	
2227/32150 (epoch 3.463), train_loss = 2.10042164, grad/param norm = 2.0710e-01, time/batch = 0.6899s	
2228/32150 (epoch 3.465), train_loss = 2.09880671, grad/param norm = 2.2434e-01, time/batch = 0.6795s	
2229/32150 (epoch 3.467), train_loss = 2.00108955, grad/param norm = 2.0803e-01, time/batch = 0.6828s	
2230/32150 (epoch 3.468), train_loss = 2.10678753, grad/param norm = 2.4162e-01, time/batch = 0.6805s	
2231/32150 (epoch 3.470), train_loss = 2.03229100, grad/param norm = 2.1400e-01, time/batch = 0.6847s	
2232/32150 (epoch 3.471), train_loss = 2.16327798, grad/param norm = 2.0272e-01, time/batch = 0.6904s	
2233/32150 (epoch 3.473), train_loss = 2.08771203, grad/param norm = 2.0371e-01, time/batch = 0.6984s	
2234/32150 (epoch 3.474), train_loss = 1.97226090, grad/param norm = 2.2319e-01, time/batch = 0.6948s	
2235/32150 (epoch 3.476), train_loss = 2.18875565, grad/param norm = 2.1849e-01, time/batch = 0.6931s	
2236/32150 (epoch 3.477), train_loss = 2.11018430, grad/param norm = 2.3906e-01, time/batch = 0.6854s	
2237/32150 (epoch 3.479), train_loss = 2.17898297, grad/param norm = 2.0080e-01, time/batch = 0.6831s	
2238/32150 (epoch 3.481), train_loss = 2.31974336, grad/param norm = 2.2206e-01, time/batch = 0.6816s	
2239/32150 (epoch 3.482), train_loss = 2.03190448, grad/param norm = 1.9273e-01, time/batch = 0.6810s	
2240/32150 (epoch 3.484), train_loss = 1.96823558, grad/param norm = 1.9963e-01, time/batch = 0.6826s	
2241/32150 (epoch 3.485), train_loss = 2.01926856, grad/param norm = 2.0816e-01, time/batch = 0.6806s	
2242/32150 (epoch 3.487), train_loss = 2.18095034, grad/param norm = 1.9894e-01, time/batch = 0.6813s	
2243/32150 (epoch 3.488), train_loss = 2.00055044, grad/param norm = 1.9902e-01, time/batch = 0.6766s	
2244/32150 (epoch 3.490), train_loss = 1.95530992, grad/param norm = 2.1553e-01, time/batch = 0.6826s	
2245/32150 (epoch 3.491), train_loss = 1.99201344, grad/param norm = 2.6751e-01, time/batch = 0.6846s	
2246/32150 (epoch 3.493), train_loss = 2.10948681, grad/param norm = 2.2151e-01, time/batch = 0.6838s	
2247/32150 (epoch 3.495), train_loss = 2.18765200, grad/param norm = 2.1502e-01, time/batch = 0.6969s	
2248/32150 (epoch 3.496), train_loss = 2.16524701, grad/param norm = 2.4124e-01, time/batch = 0.6834s	
2249/32150 (epoch 3.498), train_loss = 2.25089512, grad/param norm = 2.1536e-01, time/batch = 0.6851s	
2250/32150 (epoch 3.499), train_loss = 1.89042646, grad/param norm = 1.9729e-01, time/batch = 0.6862s	
2251/32150 (epoch 3.501), train_loss = 1.97099157, grad/param norm = 2.0325e-01, time/batch = 0.6868s	
2252/32150 (epoch 3.502), train_loss = 2.05113692, grad/param norm = 1.9659e-01, time/batch = 0.6839s	
2253/32150 (epoch 3.504), train_loss = 1.90909118, grad/param norm = 1.8765e-01, time/batch = 0.6987s	
2254/32150 (epoch 3.505), train_loss = 1.94445412, grad/param norm = 2.2013e-01, time/batch = 0.6969s	
2255/32150 (epoch 3.507), train_loss = 1.92760705, grad/param norm = 2.1009e-01, time/batch = 0.6825s	
2256/32150 (epoch 3.509), train_loss = 2.10435957, grad/param norm = 2.1709e-01, time/batch = 0.7015s	
2257/32150 (epoch 3.510), train_loss = 2.02845216, grad/param norm = 2.1266e-01, time/batch = 0.6930s	
2258/32150 (epoch 3.512), train_loss = 1.87229918, grad/param norm = 2.4531e-01, time/batch = 0.6883s	
2259/32150 (epoch 3.513), train_loss = 2.07993666, grad/param norm = 2.0563e-01, time/batch = 0.6869s	
2260/32150 (epoch 3.515), train_loss = 2.18463037, grad/param norm = 2.2452e-01, time/batch = 0.6905s	
2261/32150 (epoch 3.516), train_loss = 2.19499220, grad/param norm = 2.1071e-01, time/batch = 0.7084s	
2262/32150 (epoch 3.518), train_loss = 2.24437822, grad/param norm = 2.3061e-01, time/batch = 0.6976s	
2263/32150 (epoch 3.519), train_loss = 2.10079429, grad/param norm = 2.1229e-01, time/batch = 0.6877s	
2264/32150 (epoch 3.521), train_loss = 2.05450872, grad/param norm = 1.9665e-01, time/batch = 0.6933s	
2265/32150 (epoch 3.523), train_loss = 1.97122213, grad/param norm = 2.1026e-01, time/batch = 0.6836s	
2266/32150 (epoch 3.524), train_loss = 2.07049661, grad/param norm = 2.1035e-01, time/batch = 0.6899s	
2267/32150 (epoch 3.526), train_loss = 2.19961167, grad/param norm = 2.0486e-01, time/batch = 0.6914s	
2268/32150 (epoch 3.527), train_loss = 2.19473303, grad/param norm = 2.2238e-01, time/batch = 0.6914s	
2269/32150 (epoch 3.529), train_loss = 2.10146952, grad/param norm = 2.2728e-01, time/batch = 0.6972s	
2270/32150 (epoch 3.530), train_loss = 2.08021882, grad/param norm = 2.2250e-01, time/batch = 0.7079s	
2271/32150 (epoch 3.532), train_loss = 1.96490547, grad/param norm = 2.3844e-01, time/batch = 0.7152s	
2272/32150 (epoch 3.533), train_loss = 2.12778743, grad/param norm = 2.7604e-01, time/batch = 0.7173s	
2273/32150 (epoch 3.535), train_loss = 2.22649896, grad/param norm = 2.5384e-01, time/batch = 0.7080s	
2274/32150 (epoch 3.537), train_loss = 2.16133852, grad/param norm = 2.1263e-01, time/batch = 0.7058s	
2275/32150 (epoch 3.538), train_loss = 2.18315584, grad/param norm = 2.0283e-01, time/batch = 0.7069s	
2276/32150 (epoch 3.540), train_loss = 2.10460372, grad/param norm = 2.0187e-01, time/batch = 0.7062s	
2277/32150 (epoch 3.541), train_loss = 2.21793436, grad/param norm = 2.1243e-01, time/batch = 0.7000s	
2278/32150 (epoch 3.543), train_loss = 2.09837678, grad/param norm = 2.1163e-01, time/batch = 0.7050s	
2279/32150 (epoch 3.544), train_loss = 2.29822995, grad/param norm = 2.0875e-01, time/batch = 0.7065s	
2280/32150 (epoch 3.546), train_loss = 1.85852534, grad/param norm = 1.9600e-01, time/batch = 0.6948s	
2281/32150 (epoch 3.547), train_loss = 2.02279470, grad/param norm = 2.1705e-01, time/batch = 0.7009s	
2282/32150 (epoch 3.549), train_loss = 2.06054892, grad/param norm = 2.2299e-01, time/batch = 0.6928s	
2283/32150 (epoch 3.551), train_loss = 2.27955488, grad/param norm = 2.0314e-01, time/batch = 0.6991s	
2284/32150 (epoch 3.552), train_loss = 2.16991440, grad/param norm = 2.3330e-01, time/batch = 0.7018s	
2285/32150 (epoch 3.554), train_loss = 2.29383471, grad/param norm = 1.8442e-01, time/batch = 0.7064s	
2286/32150 (epoch 3.555), train_loss = 2.00105727, grad/param norm = 1.8753e-01, time/batch = 0.6953s	
2287/32150 (epoch 3.557), train_loss = 1.93391514, grad/param norm = 1.8994e-01, time/batch = 0.6967s	
2288/32150 (epoch 3.558), train_loss = 2.01683793, grad/param norm = 2.0240e-01, time/batch = 0.6985s	
2289/32150 (epoch 3.560), train_loss = 2.22432619, grad/param norm = 2.1623e-01, time/batch = 0.7038s	
2290/32150 (epoch 3.561), train_loss = 2.16185308, grad/param norm = 2.0640e-01, time/batch = 0.6948s	
2291/32150 (epoch 3.563), train_loss = 2.03713768, grad/param norm = 2.3222e-01, time/batch = 0.6905s	
2292/32150 (epoch 3.565), train_loss = 1.95476224, grad/param norm = 2.2513e-01, time/batch = 0.6851s	
2293/32150 (epoch 3.566), train_loss = 2.19911906, grad/param norm = 2.2551e-01, time/batch = 0.6898s	
2294/32150 (epoch 3.568), train_loss = 1.90937747, grad/param norm = 1.8354e-01, time/batch = 0.6992s	
2295/32150 (epoch 3.569), train_loss = 2.15146659, grad/param norm = 2.1182e-01, time/batch = 0.6931s	
2296/32150 (epoch 3.571), train_loss = 2.16157572, grad/param norm = 2.0912e-01, time/batch = 0.6880s	
2297/32150 (epoch 3.572), train_loss = 2.09408496, grad/param norm = 1.9906e-01, time/batch = 0.6880s	
2298/32150 (epoch 3.574), train_loss = 2.17490954, grad/param norm = 2.2239e-01, time/batch = 0.6791s	
2299/32150 (epoch 3.575), train_loss = 2.16972695, grad/param norm = 2.5308e-01, time/batch = 0.6856s	
2300/32150 (epoch 3.577), train_loss = 2.06737142, grad/param norm = 2.1348e-01, time/batch = 0.6952s	
2301/32150 (epoch 3.579), train_loss = 2.12840168, grad/param norm = 2.3620e-01, time/batch = 0.6834s	
2302/32150 (epoch 3.580), train_loss = 2.02841835, grad/param norm = 1.9200e-01, time/batch = 0.6859s	
2303/32150 (epoch 3.582), train_loss = 2.10773197, grad/param norm = 2.1492e-01, time/batch = 0.6828s	
2304/32150 (epoch 3.583), train_loss = 1.93274908, grad/param norm = 1.9833e-01, time/batch = 0.6819s	
2305/32150 (epoch 3.585), train_loss = 1.90278424, grad/param norm = 1.8593e-01, time/batch = 0.6818s	
2306/32150 (epoch 3.586), train_loss = 2.11260702, grad/param norm = 1.8131e-01, time/batch = 0.6781s	
2307/32150 (epoch 3.588), train_loss = 2.05713860, grad/param norm = 2.8534e-01, time/batch = 0.6797s	
2308/32150 (epoch 3.589), train_loss = 1.99882176, grad/param norm = 2.3830e-01, time/batch = 0.6789s	
2309/32150 (epoch 3.591), train_loss = 2.40043088, grad/param norm = 2.1938e-01, time/batch = 0.6803s	
2310/32150 (epoch 3.593), train_loss = 2.13491988, grad/param norm = 2.2205e-01, time/batch = 0.6864s	
2311/32150 (epoch 3.594), train_loss = 1.98720644, grad/param norm = 2.0533e-01, time/batch = 0.7008s	
2312/32150 (epoch 3.596), train_loss = 2.21344302, grad/param norm = 2.3103e-01, time/batch = 0.6955s	
2313/32150 (epoch 3.597), train_loss = 1.94063935, grad/param norm = 1.8443e-01, time/batch = 0.6867s	
2314/32150 (epoch 3.599), train_loss = 2.03189684, grad/param norm = 2.1431e-01, time/batch = 0.6969s	
2315/32150 (epoch 3.600), train_loss = 2.02472523, grad/param norm = 1.9229e-01, time/batch = 0.6865s	
2316/32150 (epoch 3.602), train_loss = 2.26619428, grad/param norm = 2.7407e-01, time/batch = 0.6887s	
2317/32150 (epoch 3.603), train_loss = 2.05098714, grad/param norm = 2.0770e-01, time/batch = 0.6930s	
2318/32150 (epoch 3.605), train_loss = 1.84757161, grad/param norm = 2.1191e-01, time/batch = 0.6847s	
2319/32150 (epoch 3.607), train_loss = 2.23639086, grad/param norm = 2.1587e-01, time/batch = 0.6846s	
2320/32150 (epoch 3.608), train_loss = 1.79060136, grad/param norm = 1.9739e-01, time/batch = 0.6825s	
2321/32150 (epoch 3.610), train_loss = 2.06759407, grad/param norm = 1.9122e-01, time/batch = 0.6848s	
2322/32150 (epoch 3.611), train_loss = 1.90959867, grad/param norm = 1.9706e-01, time/batch = 0.6804s	
2323/32150 (epoch 3.613), train_loss = 1.80739230, grad/param norm = 2.2805e-01, time/batch = 0.6826s	
2324/32150 (epoch 3.614), train_loss = 1.88668064, grad/param norm = 2.1828e-01, time/batch = 0.6803s	
2325/32150 (epoch 3.616), train_loss = 2.07386042, grad/param norm = 2.2274e-01, time/batch = 0.7027s	
2326/32150 (epoch 3.617), train_loss = 1.92239076, grad/param norm = 2.2680e-01, time/batch = 0.6974s	
2327/32150 (epoch 3.619), train_loss = 1.95808841, grad/param norm = 2.1492e-01, time/batch = 0.6895s	
2328/32150 (epoch 3.621), train_loss = 2.00979602, grad/param norm = 2.0939e-01, time/batch = 0.6881s	
2329/32150 (epoch 3.622), train_loss = 1.86989346, grad/param norm = 1.6715e-01, time/batch = 0.6957s	
2330/32150 (epoch 3.624), train_loss = 1.98365071, grad/param norm = 2.1865e-01, time/batch = 0.6891s	
2331/32150 (epoch 3.625), train_loss = 2.01478624, grad/param norm = 1.9450e-01, time/batch = 0.6950s	
2332/32150 (epoch 3.627), train_loss = 2.03871278, grad/param norm = 2.0592e-01, time/batch = 0.6871s	
2333/32150 (epoch 3.628), train_loss = 2.02231184, grad/param norm = 1.9522e-01, time/batch = 0.6886s	
2334/32150 (epoch 3.630), train_loss = 1.88668660, grad/param norm = 1.9785e-01, time/batch = 0.6837s	
2335/32150 (epoch 3.631), train_loss = 2.20409014, grad/param norm = 2.5411e-01, time/batch = 0.6810s	
2336/32150 (epoch 3.633), train_loss = 2.07170284, grad/param norm = 2.5418e-01, time/batch = 0.6861s	
2337/32150 (epoch 3.635), train_loss = 2.03846359, grad/param norm = 2.2375e-01, time/batch = 0.6846s	
2338/32150 (epoch 3.636), train_loss = 2.13596889, grad/param norm = 2.0943e-01, time/batch = 0.6823s	
2339/32150 (epoch 3.638), train_loss = 2.17415674, grad/param norm = 2.2957e-01, time/batch = 0.6839s	
2340/32150 (epoch 3.639), train_loss = 2.16446838, grad/param norm = 2.2166e-01, time/batch = 0.6817s	
2341/32150 (epoch 3.641), train_loss = 2.05606208, grad/param norm = 2.0163e-01, time/batch = 0.6842s	
2342/32150 (epoch 3.642), train_loss = 2.18633045, grad/param norm = 2.1080e-01, time/batch = 0.6838s	
2343/32150 (epoch 3.644), train_loss = 2.10430267, grad/param norm = 2.1268e-01, time/batch = 0.6836s	
2344/32150 (epoch 3.645), train_loss = 2.19687888, grad/param norm = 2.0016e-01, time/batch = 0.7062s	
2345/32150 (epoch 3.647), train_loss = 2.16351398, grad/param norm = 2.3395e-01, time/batch = 0.6920s	
2346/32150 (epoch 3.649), train_loss = 2.03810824, grad/param norm = 1.8311e-01, time/batch = 0.6856s	
2347/32150 (epoch 3.650), train_loss = 1.99303362, grad/param norm = 2.1932e-01, time/batch = 0.6782s	
2348/32150 (epoch 3.652), train_loss = 2.07331200, grad/param norm = 2.1024e-01, time/batch = 0.6993s	
2349/32150 (epoch 3.653), train_loss = 2.17880636, grad/param norm = 2.5681e-01, time/batch = 0.6809s	
2350/32150 (epoch 3.655), train_loss = 2.42461205, grad/param norm = 2.6761e-01, time/batch = 0.6785s	
2351/32150 (epoch 3.656), train_loss = 2.39109553, grad/param norm = 2.6522e-01, time/batch = 0.6852s	
2352/32150 (epoch 3.658), train_loss = 2.14373207, grad/param norm = 2.0560e-01, time/batch = 0.6830s	
2353/32150 (epoch 3.659), train_loss = 2.36549335, grad/param norm = 2.3502e-01, time/batch = 0.6825s	
2354/32150 (epoch 3.661), train_loss = 2.15906591, grad/param norm = 2.4083e-01, time/batch = 0.6852s	
2355/32150 (epoch 3.663), train_loss = 2.01339143, grad/param norm = 2.4052e-01, time/batch = 0.6848s	
2356/32150 (epoch 3.664), train_loss = 1.95849980, grad/param norm = 1.9885e-01, time/batch = 0.6828s	
2357/32150 (epoch 3.666), train_loss = 2.18487197, grad/param norm = 2.3499e-01, time/batch = 0.6841s	
2358/32150 (epoch 3.667), train_loss = 2.18973946, grad/param norm = 2.0895e-01, time/batch = 0.6938s	
2359/32150 (epoch 3.669), train_loss = 2.15442512, grad/param norm = 2.3562e-01, time/batch = 0.7014s	
2360/32150 (epoch 3.670), train_loss = 2.13367640, grad/param norm = 2.5439e-01, time/batch = 0.6910s	
2361/32150 (epoch 3.672), train_loss = 2.05205367, grad/param norm = 2.0882e-01, time/batch = 0.6993s	
2362/32150 (epoch 3.673), train_loss = 2.06379584, grad/param norm = 2.0627e-01, time/batch = 0.6900s	
2363/32150 (epoch 3.675), train_loss = 2.17568431, grad/param norm = 2.0840e-01, time/batch = 0.6914s	
2364/32150 (epoch 3.677), train_loss = 2.12755866, grad/param norm = 1.9826e-01, time/batch = 0.6852s	
2365/32150 (epoch 3.678), train_loss = 2.19521282, grad/param norm = 2.4221e-01, time/batch = 0.6845s	
2366/32150 (epoch 3.680), train_loss = 2.13222338, grad/param norm = 1.9907e-01, time/batch = 0.6784s	
2367/32150 (epoch 3.681), train_loss = 2.07961304, grad/param norm = 2.1909e-01, time/batch = 0.6812s	
2368/32150 (epoch 3.683), train_loss = 2.06789325, grad/param norm = 2.0548e-01, time/batch = 0.6834s	
2369/32150 (epoch 3.684), train_loss = 2.17703765, grad/param norm = 2.0622e-01, time/batch = 0.6793s	
2370/32150 (epoch 3.686), train_loss = 2.00312344, grad/param norm = 2.1681e-01, time/batch = 0.6831s	
2371/32150 (epoch 3.687), train_loss = 2.03881780, grad/param norm = 2.0341e-01, time/batch = 0.6854s	
2372/32150 (epoch 3.689), train_loss = 1.80191840, grad/param norm = 1.9571e-01, time/batch = 0.6965s	
2373/32150 (epoch 3.691), train_loss = 1.68681901, grad/param norm = 2.1272e-01, time/batch = 0.7068s	
2374/32150 (epoch 3.692), train_loss = 1.90567358, grad/param norm = 2.1360e-01, time/batch = 0.6905s	
2375/32150 (epoch 3.694), train_loss = 1.95347565, grad/param norm = 1.9461e-01, time/batch = 0.6896s	
2376/32150 (epoch 3.695), train_loss = 2.04693698, grad/param norm = 1.9372e-01, time/batch = 0.6834s	
2377/32150 (epoch 3.697), train_loss = 2.08469874, grad/param norm = 1.9274e-01, time/batch = 0.6911s	
2378/32150 (epoch 3.698), train_loss = 2.05295018, grad/param norm = 1.8835e-01, time/batch = 0.6888s	
2379/32150 (epoch 3.700), train_loss = 2.09476192, grad/param norm = 2.0944e-01, time/batch = 0.6959s	
2380/32150 (epoch 3.701), train_loss = 1.91338659, grad/param norm = 1.8151e-01, time/batch = 0.7043s	
2381/32150 (epoch 3.703), train_loss = 1.98571461, grad/param norm = 2.4871e-01, time/batch = 0.7098s	
2382/32150 (epoch 3.705), train_loss = 1.92079293, grad/param norm = 1.9568e-01, time/batch = 0.7101s	
2383/32150 (epoch 3.706), train_loss = 2.04165623, grad/param norm = 1.9271e-01, time/batch = 0.6895s	
2384/32150 (epoch 3.708), train_loss = 2.22709522, grad/param norm = 2.6638e-01, time/batch = 0.6960s	
2385/32150 (epoch 3.709), train_loss = 1.98492686, grad/param norm = 2.2087e-01, time/batch = 0.6906s	
2386/32150 (epoch 3.711), train_loss = 2.07322774, grad/param norm = 2.2129e-01, time/batch = 0.6988s	
2387/32150 (epoch 3.712), train_loss = 2.38998607, grad/param norm = 2.4506e-01, time/batch = 0.7171s	
2388/32150 (epoch 3.714), train_loss = 2.11831462, grad/param norm = 2.0578e-01, time/batch = 0.7056s	
2389/32150 (epoch 3.715), train_loss = 2.20575092, grad/param norm = 2.0509e-01, time/batch = 0.6904s	
2390/32150 (epoch 3.717), train_loss = 2.03679290, grad/param norm = 1.8615e-01, time/batch = 0.6980s	
2391/32150 (epoch 3.719), train_loss = 1.91508052, grad/param norm = 1.9098e-01, time/batch = 0.6892s	
2392/32150 (epoch 3.720), train_loss = 2.02857377, grad/param norm = 2.0262e-01, time/batch = 0.6832s	
2393/32150 (epoch 3.722), train_loss = 2.05121314, grad/param norm = 2.3733e-01, time/batch = 0.6847s	
2394/32150 (epoch 3.723), train_loss = 2.23848812, grad/param norm = 2.2199e-01, time/batch = 0.6924s	
2395/32150 (epoch 3.725), train_loss = 2.02715435, grad/param norm = 2.2898e-01, time/batch = 0.7030s	
2396/32150 (epoch 3.726), train_loss = 2.05281526, grad/param norm = 2.1676e-01, time/batch = 0.6886s	
2397/32150 (epoch 3.728), train_loss = 1.95718864, grad/param norm = 2.1990e-01, time/batch = 0.6893s	
2398/32150 (epoch 3.729), train_loss = 2.02276113, grad/param norm = 2.0402e-01, time/batch = 0.6890s	
2399/32150 (epoch 3.731), train_loss = 2.09582584, grad/param norm = 2.3165e-01, time/batch = 0.6870s	
2400/32150 (epoch 3.733), train_loss = 2.00671894, grad/param norm = 2.0986e-01, time/batch = 0.6869s	
2401/32150 (epoch 3.734), train_loss = 2.02585880, grad/param norm = 2.1511e-01, time/batch = 0.6955s	
2402/32150 (epoch 3.736), train_loss = 1.86385423, grad/param norm = 2.0280e-01, time/batch = 0.6899s	
2403/32150 (epoch 3.737), train_loss = 2.06844773, grad/param norm = 2.1631e-01, time/batch = 0.6827s	
2404/32150 (epoch 3.739), train_loss = 2.00675686, grad/param norm = 2.3107e-01, time/batch = 0.6849s	
2405/32150 (epoch 3.740), train_loss = 1.80505748, grad/param norm = 2.1984e-01, time/batch = 0.6854s	
2406/32150 (epoch 3.742), train_loss = 1.80407149, grad/param norm = 1.7964e-01, time/batch = 0.6817s	
2407/32150 (epoch 3.743), train_loss = 1.82799136, grad/param norm = 1.8619e-01, time/batch = 0.6810s	
2408/32150 (epoch 3.745), train_loss = 1.81002077, grad/param norm = 1.9561e-01, time/batch = 0.6836s	
2409/32150 (epoch 3.747), train_loss = 1.96834750, grad/param norm = 1.8547e-01, time/batch = 0.6999s	
2410/32150 (epoch 3.748), train_loss = 2.22097608, grad/param norm = 2.3107e-01, time/batch = 0.6804s	
2411/32150 (epoch 3.750), train_loss = 2.06861089, grad/param norm = 2.2224e-01, time/batch = 0.6910s	
2412/32150 (epoch 3.751), train_loss = 1.97210089, grad/param norm = 2.2751e-01, time/batch = 0.6885s	
2413/32150 (epoch 3.753), train_loss = 1.90083650, grad/param norm = 1.8620e-01, time/batch = 0.6936s	
2414/32150 (epoch 3.754), train_loss = 2.06277219, grad/param norm = 1.9008e-01, time/batch = 0.6841s	
2415/32150 (epoch 3.756), train_loss = 1.93872842, grad/param norm = 2.0888e-01, time/batch = 0.6849s	
2416/32150 (epoch 3.757), train_loss = 2.24081121, grad/param norm = 2.1994e-01, time/batch = 0.6781s	
2417/32150 (epoch 3.759), train_loss = 2.03598721, grad/param norm = 1.9304e-01, time/batch = 0.6851s	
2418/32150 (epoch 3.760), train_loss = 2.04644627, grad/param norm = 2.3664e-01, time/batch = 0.6842s	
2419/32150 (epoch 3.762), train_loss = 2.06794333, grad/param norm = 2.2326e-01, time/batch = 0.6917s	
2420/32150 (epoch 3.764), train_loss = 2.25609723, grad/param norm = 2.3677e-01, time/batch = 0.6967s	
2421/32150 (epoch 3.765), train_loss = 1.87111714, grad/param norm = 2.2065e-01, time/batch = 0.7014s	
2422/32150 (epoch 3.767), train_loss = 2.13007593, grad/param norm = 2.2021e-01, time/batch = 0.6876s	
2423/32150 (epoch 3.768), train_loss = 1.95298261, grad/param norm = 2.3766e-01, time/batch = 0.6855s	
2424/32150 (epoch 3.770), train_loss = 2.04511289, grad/param norm = 2.0718e-01, time/batch = 0.6844s	
2425/32150 (epoch 3.771), train_loss = 2.11810163, grad/param norm = 2.3706e-01, time/batch = 0.6870s	
2426/32150 (epoch 3.773), train_loss = 2.37054963, grad/param norm = 2.1176e-01, time/batch = 0.6851s	
2427/32150 (epoch 3.774), train_loss = 2.04948864, grad/param norm = 1.8763e-01, time/batch = 0.6836s	
2428/32150 (epoch 3.776), train_loss = 2.07556263, grad/param norm = 2.1143e-01, time/batch = 0.6856s	
2429/32150 (epoch 3.778), train_loss = 1.75305894, grad/param norm = 2.0161e-01, time/batch = 0.6881s	
2430/32150 (epoch 3.779), train_loss = 2.02094548, grad/param norm = 2.2079e-01, time/batch = 0.6858s	
2431/32150 (epoch 3.781), train_loss = 2.09829950, grad/param norm = 2.0391e-01, time/batch = 0.6944s	
2432/32150 (epoch 3.782), train_loss = 2.01807080, grad/param norm = 2.3873e-01, time/batch = 0.6916s	
2433/32150 (epoch 3.784), train_loss = 2.21521771, grad/param norm = 2.3880e-01, time/batch = 0.6902s	
2434/32150 (epoch 3.785), train_loss = 2.04790926, grad/param norm = 2.1471e-01, time/batch = 0.6963s	
2435/32150 (epoch 3.787), train_loss = 2.10521481, grad/param norm = 2.1081e-01, time/batch = 0.6901s	
2436/32150 (epoch 3.788), train_loss = 2.04517358, grad/param norm = 1.7852e-01, time/batch = 0.6865s	
2437/32150 (epoch 3.790), train_loss = 1.98072693, grad/param norm = 1.8676e-01, time/batch = 0.6903s	
2438/32150 (epoch 3.792), train_loss = 2.01026222, grad/param norm = 2.2069e-01, time/batch = 0.6825s	
2439/32150 (epoch 3.793), train_loss = 2.14069689, grad/param norm = 2.2271e-01, time/batch = 0.6935s	
2440/32150 (epoch 3.795), train_loss = 1.91368489, grad/param norm = 2.2135e-01, time/batch = 0.6849s	
2441/32150 (epoch 3.796), train_loss = 1.86979023, grad/param norm = 1.8612e-01, time/batch = 0.7002s	
2442/32150 (epoch 3.798), train_loss = 1.85195508, grad/param norm = 2.3647e-01, time/batch = 0.6829s	
2443/32150 (epoch 3.799), train_loss = 2.10225536, grad/param norm = 2.0297e-01, time/batch = 0.6936s	
2444/32150 (epoch 3.801), train_loss = 2.26995579, grad/param norm = 2.3527e-01, time/batch = 0.6848s	
2445/32150 (epoch 3.802), train_loss = 2.07003790, grad/param norm = 2.0956e-01, time/batch = 0.6847s	
2446/32150 (epoch 3.804), train_loss = 2.25440336, grad/param norm = 2.2566e-01, time/batch = 0.6964s	
2447/32150 (epoch 3.806), train_loss = 2.19721488, grad/param norm = 2.2340e-01, time/batch = 0.7051s	
2448/32150 (epoch 3.807), train_loss = 2.08613719, grad/param norm = 1.9399e-01, time/batch = 0.7028s	
2449/32150 (epoch 3.809), train_loss = 2.02236343, grad/param norm = 2.1453e-01, time/batch = 0.6970s	
2450/32150 (epoch 3.810), train_loss = 2.14406839, grad/param norm = 1.9856e-01, time/batch = 0.7044s	
2451/32150 (epoch 3.812), train_loss = 2.03759964, grad/param norm = 1.9809e-01, time/batch = 0.6890s	
2452/32150 (epoch 3.813), train_loss = 2.17269331, grad/param norm = 2.0762e-01, time/batch = 0.6837s	
2453/32150 (epoch 3.815), train_loss = 1.75276244, grad/param norm = 1.9682e-01, time/batch = 0.6861s	
2454/32150 (epoch 3.816), train_loss = 1.93056221, grad/param norm = 2.0706e-01, time/batch = 0.6896s	
2455/32150 (epoch 3.818), train_loss = 1.94180785, grad/param norm = 2.1108e-01, time/batch = 0.6868s	
2456/32150 (epoch 3.820), train_loss = 1.98040913, grad/param norm = 2.1041e-01, time/batch = 0.6835s	
2457/32150 (epoch 3.821), train_loss = 2.21248429, grad/param norm = 1.9894e-01, time/batch = 0.6835s	
2458/32150 (epoch 3.823), train_loss = 2.04158222, grad/param norm = 2.0582e-01, time/batch = 0.6852s	
2459/32150 (epoch 3.824), train_loss = 2.10927437, grad/param norm = 2.1235e-01, time/batch = 0.6880s	
2460/32150 (epoch 3.826), train_loss = 1.97557988, grad/param norm = 2.1107e-01, time/batch = 0.6770s	
2461/32150 (epoch 3.827), train_loss = 2.13088638, grad/param norm = 2.0309e-01, time/batch = 0.6793s	
2462/32150 (epoch 3.829), train_loss = 1.99764181, grad/param norm = 1.8007e-01, time/batch = 0.6909s	
2463/32150 (epoch 3.830), train_loss = 1.97824770, grad/param norm = 2.3293e-01, time/batch = 0.6820s	
2464/32150 (epoch 3.832), train_loss = 2.00253268, grad/param norm = 2.2380e-01, time/batch = 0.6805s	
2465/32150 (epoch 3.834), train_loss = 2.16989173, grad/param norm = 2.2095e-01, time/batch = 0.6903s	
2466/32150 (epoch 3.835), train_loss = 1.93467215, grad/param norm = 2.0596e-01, time/batch = 0.6966s	
2467/32150 (epoch 3.837), train_loss = 2.04106912, grad/param norm = 1.8554e-01, time/batch = 0.7064s	
2468/32150 (epoch 3.838), train_loss = 2.19934219, grad/param norm = 2.2801e-01, time/batch = 0.6928s	
2469/32150 (epoch 3.840), train_loss = 1.98390834, grad/param norm = 2.3757e-01, time/batch = 0.6971s	
2470/32150 (epoch 3.841), train_loss = 1.94601501, grad/param norm = 2.7454e-01, time/batch = 0.6825s	
2471/32150 (epoch 3.843), train_loss = 1.98980095, grad/param norm = 2.0566e-01, time/batch = 0.6793s	
2472/32150 (epoch 3.844), train_loss = 1.80185676, grad/param norm = 2.2156e-01, time/batch = 0.6807s	
2473/32150 (epoch 3.846), train_loss = 1.76734482, grad/param norm = 2.1406e-01, time/batch = 0.6784s	
2474/32150 (epoch 3.848), train_loss = 2.10072864, grad/param norm = 2.0389e-01, time/batch = 0.6814s	
2475/32150 (epoch 3.849), train_loss = 2.22591598, grad/param norm = 2.2646e-01, time/batch = 0.6840s	
2476/32150 (epoch 3.851), train_loss = 2.00122247, grad/param norm = 2.3486e-01, time/batch = 0.6866s	
2477/32150 (epoch 3.852), train_loss = 2.20306552, grad/param norm = 2.0870e-01, time/batch = 0.6902s	
2478/32150 (epoch 3.854), train_loss = 2.26538249, grad/param norm = 1.9244e-01, time/batch = 0.6906s	
2479/32150 (epoch 3.855), train_loss = 2.05579463, grad/param norm = 2.1928e-01, time/batch = 0.6892s	
2480/32150 (epoch 3.857), train_loss = 2.13885329, grad/param norm = 2.0991e-01, time/batch = 0.6942s	
2481/32150 (epoch 3.858), train_loss = 2.33257498, grad/param norm = 2.0602e-01, time/batch = 0.6925s	
2482/32150 (epoch 3.860), train_loss = 2.05640813, grad/param norm = 2.1806e-01, time/batch = 0.6897s	
2483/32150 (epoch 3.862), train_loss = 2.29071634, grad/param norm = 2.4312e-01, time/batch = 0.6920s	
2484/32150 (epoch 3.863), train_loss = 2.03413542, grad/param norm = 2.0323e-01, time/batch = 0.6838s	
2485/32150 (epoch 3.865), train_loss = 1.87543159, grad/param norm = 1.9695e-01, time/batch = 0.6852s	
2486/32150 (epoch 3.866), train_loss = 1.91314624, grad/param norm = 1.8924e-01, time/batch = 0.6851s	
2487/32150 (epoch 3.868), train_loss = 2.18336607, grad/param norm = 2.1860e-01, time/batch = 0.6857s	
2488/32150 (epoch 3.869), train_loss = 1.93350236, grad/param norm = 2.5745e-01, time/batch = 0.6991s	
2489/32150 (epoch 3.871), train_loss = 1.94972546, grad/param norm = 2.1787e-01, time/batch = 0.6857s	
2490/32150 (epoch 3.872), train_loss = 2.23853736, grad/param norm = 2.3092e-01, time/batch = 0.7010s	
2491/32150 (epoch 3.874), train_loss = 1.94721424, grad/param norm = 2.1077e-01, time/batch = 0.6883s	
2492/32150 (epoch 3.876), train_loss = 1.85701979, grad/param norm = 1.9777e-01, time/batch = 0.6878s	
2493/32150 (epoch 3.877), train_loss = 2.02330081, grad/param norm = 2.3723e-01, time/batch = 0.6863s	
2494/32150 (epoch 3.879), train_loss = 2.08288399, grad/param norm = 1.9265e-01, time/batch = 0.6935s	
2495/32150 (epoch 3.880), train_loss = 2.08106552, grad/param norm = 2.1234e-01, time/batch = 0.6913s	
2496/32150 (epoch 3.882), train_loss = 1.88301176, grad/param norm = 1.8596e-01, time/batch = 0.6948s	
2497/32150 (epoch 3.883), train_loss = 2.09137852, grad/param norm = 2.0675e-01, time/batch = 0.6941s	
2498/32150 (epoch 3.885), train_loss = 1.92600246, grad/param norm = 2.0087e-01, time/batch = 0.6952s	
2499/32150 (epoch 3.886), train_loss = 2.09411508, grad/param norm = 1.9363e-01, time/batch = 0.6916s	
2500/32150 (epoch 3.888), train_loss = 1.86879114, grad/param norm = 1.7950e-01, time/batch = 0.6869s	
2501/32150 (epoch 3.890), train_loss = 2.17822866, grad/param norm = 2.1174e-01, time/batch = 0.6887s	
2502/32150 (epoch 3.891), train_loss = 2.10048903, grad/param norm = 2.0179e-01, time/batch = 0.6869s	
2503/32150 (epoch 3.893), train_loss = 1.97770974, grad/param norm = 2.0247e-01, time/batch = 0.6858s	
2504/32150 (epoch 3.894), train_loss = 1.93680802, grad/param norm = 1.8555e-01, time/batch = 0.6843s	
2505/32150 (epoch 3.896), train_loss = 1.98115371, grad/param norm = 1.9527e-01, time/batch = 0.6822s	
2506/32150 (epoch 3.897), train_loss = 2.08108154, grad/param norm = 2.1225e-01, time/batch = 0.6820s	
2507/32150 (epoch 3.899), train_loss = 1.95938297, grad/param norm = 1.9368e-01, time/batch = 0.6925s	
2508/32150 (epoch 3.900), train_loss = 2.00806999, grad/param norm = 2.1053e-01, time/batch = 0.6932s	
2509/32150 (epoch 3.902), train_loss = 2.00794099, grad/param norm = 2.2165e-01, time/batch = 0.6849s	
2510/32150 (epoch 3.904), train_loss = 2.02564422, grad/param norm = 2.3792e-01, time/batch = 0.7157s	
2511/32150 (epoch 3.905), train_loss = 2.13630317, grad/param norm = 2.2834e-01, time/batch = 0.7076s	
2512/32150 (epoch 3.907), train_loss = 1.90489870, grad/param norm = 2.4581e-01, time/batch = 0.6904s	
2513/32150 (epoch 3.908), train_loss = 2.10781294, grad/param norm = 2.4919e-01, time/batch = 0.6967s	
2514/32150 (epoch 3.910), train_loss = 1.85893608, grad/param norm = 1.9331e-01, time/batch = 0.6901s	
2515/32150 (epoch 3.911), train_loss = 1.86077060, grad/param norm = 1.9464e-01, time/batch = 0.6854s	
2516/32150 (epoch 3.913), train_loss = 2.05393220, grad/param norm = 2.0200e-01, time/batch = 0.6831s	
2517/32150 (epoch 3.914), train_loss = 2.17856981, grad/param norm = 2.0889e-01, time/batch = 0.6838s	
2518/32150 (epoch 3.916), train_loss = 1.87791180, grad/param norm = 1.9506e-01, time/batch = 0.6862s	
2519/32150 (epoch 3.918), train_loss = 2.06137281, grad/param norm = 2.2786e-01, time/batch = 0.6890s	
2520/32150 (epoch 3.919), train_loss = 2.14594989, grad/param norm = 2.0743e-01, time/batch = 0.6963s	
2521/32150 (epoch 3.921), train_loss = 2.14164294, grad/param norm = 2.1182e-01, time/batch = 0.6953s	
2522/32150 (epoch 3.922), train_loss = 1.96634859, grad/param norm = 2.1039e-01, time/batch = 0.6868s	
2523/32150 (epoch 3.924), train_loss = 2.01887345, grad/param norm = 2.3326e-01, time/batch = 0.6822s	
2524/32150 (epoch 3.925), train_loss = 2.06155403, grad/param norm = 1.8856e-01, time/batch = 0.6865s	
2525/32150 (epoch 3.927), train_loss = 1.83849622, grad/param norm = 1.8582e-01, time/batch = 0.6849s	
2526/32150 (epoch 3.928), train_loss = 2.30152731, grad/param norm = 2.5724e-01, time/batch = 0.6855s	
2527/32150 (epoch 3.930), train_loss = 1.99997670, grad/param norm = 2.1432e-01, time/batch = 0.6847s	
2528/32150 (epoch 3.932), train_loss = 2.02902738, grad/param norm = 2.5670e-01, time/batch = 0.6881s	
2529/32150 (epoch 3.933), train_loss = 2.15285970, grad/param norm = 2.1170e-01, time/batch = 0.6836s	
2530/32150 (epoch 3.935), train_loss = 1.87975300, grad/param norm = 2.4042e-01, time/batch = 0.6807s	
2531/32150 (epoch 3.936), train_loss = 1.93465637, grad/param norm = 1.8234e-01, time/batch = 0.6804s	
2532/32150 (epoch 3.938), train_loss = 1.95231730, grad/param norm = 2.0196e-01, time/batch = 0.6864s	
2533/32150 (epoch 3.939), train_loss = 2.14324377, grad/param norm = 2.0241e-01, time/batch = 0.6993s	
2534/32150 (epoch 3.941), train_loss = 1.83310738, grad/param norm = 1.9076e-01, time/batch = 0.6893s	
2535/32150 (epoch 3.942), train_loss = 2.18931088, grad/param norm = 1.9836e-01, time/batch = 0.6891s	
2536/32150 (epoch 3.944), train_loss = 1.92212473, grad/param norm = 1.8668e-01, time/batch = 0.6874s	
2537/32150 (epoch 3.946), train_loss = 1.80084466, grad/param norm = 1.8819e-01, time/batch = 0.6874s	
2538/32150 (epoch 3.947), train_loss = 1.97474239, grad/param norm = 1.9076e-01, time/batch = 0.6830s	
2539/32150 (epoch 3.949), train_loss = 1.99241581, grad/param norm = 1.7394e-01, time/batch = 0.6897s	
2540/32150 (epoch 3.950), train_loss = 1.99230855, grad/param norm = 1.9310e-01, time/batch = 0.6867s	
2541/32150 (epoch 3.952), train_loss = 1.71415893, grad/param norm = 1.9539e-01, time/batch = 0.6865s	
2542/32150 (epoch 3.953), train_loss = 1.70109038, grad/param norm = 1.9261e-01, time/batch = 0.6790s	
2543/32150 (epoch 3.955), train_loss = 1.77852463, grad/param norm = 1.8526e-01, time/batch = 0.6797s	
2544/32150 (epoch 3.956), train_loss = 1.78912402, grad/param norm = 2.0216e-01, time/batch = 0.6808s	
2545/32150 (epoch 3.958), train_loss = 1.96734439, grad/param norm = 2.1611e-01, time/batch = 0.6797s	
2546/32150 (epoch 3.960), train_loss = 2.11684257, grad/param norm = 2.3622e-01, time/batch = 0.6843s	
2547/32150 (epoch 3.961), train_loss = 1.92317906, grad/param norm = 2.1489e-01, time/batch = 0.6791s	
2548/32150 (epoch 3.963), train_loss = 2.05417446, grad/param norm = 1.9348e-01, time/batch = 0.6836s	
2549/32150 (epoch 3.964), train_loss = 2.10589690, grad/param norm = 2.3002e-01, time/batch = 0.6848s	
2550/32150 (epoch 3.966), train_loss = 2.25308010, grad/param norm = 2.0832e-01, time/batch = 0.6854s	
2551/32150 (epoch 3.967), train_loss = 1.86338816, grad/param norm = 1.8264e-01, time/batch = 0.6941s	
2552/32150 (epoch 3.969), train_loss = 1.93202167, grad/param norm = 2.2453e-01, time/batch = 0.6805s	
2553/32150 (epoch 3.970), train_loss = 1.98454931, grad/param norm = 2.1571e-01, time/batch = 0.6858s	
2554/32150 (epoch 3.972), train_loss = 2.16867805, grad/param norm = 2.3724e-01, time/batch = 0.6973s	
2555/32150 (epoch 3.974), train_loss = 2.24311155, grad/param norm = 2.2911e-01, time/batch = 0.6854s	
2556/32150 (epoch 3.975), train_loss = 1.97680005, grad/param norm = 2.1237e-01, time/batch = 1.3788s	
2557/32150 (epoch 3.977), train_loss = 2.01465566, grad/param norm = 1.9168e-01, time/batch = 0.9136s	
2558/32150 (epoch 3.978), train_loss = 1.92722109, grad/param norm = 1.7862e-01, time/batch = 0.6837s	
2559/32150 (epoch 3.980), train_loss = 1.93366792, grad/param norm = 2.1845e-01, time/batch = 0.6807s	
2560/32150 (epoch 3.981), train_loss = 1.97304966, grad/param norm = 2.0212e-01, time/batch = 0.6824s	
2561/32150 (epoch 3.983), train_loss = 1.94037860, grad/param norm = 2.1840e-01, time/batch = 0.6804s	
2562/32150 (epoch 3.984), train_loss = 1.98860065, grad/param norm = 1.9088e-01, time/batch = 0.7188s	
2563/32150 (epoch 3.986), train_loss = 1.90834428, grad/param norm = 1.8620e-01, time/batch = 0.6879s	
2564/32150 (epoch 3.988), train_loss = 1.81754642, grad/param norm = 1.8087e-01, time/batch = 0.6822s	
2565/32150 (epoch 3.989), train_loss = 2.07225819, grad/param norm = 1.9601e-01, time/batch = 0.6857s	
2566/32150 (epoch 3.991), train_loss = 1.98602802, grad/param norm = 1.9798e-01, time/batch = 0.6806s	
2567/32150 (epoch 3.992), train_loss = 1.86225400, grad/param norm = 1.8455e-01, time/batch = 0.6880s	
