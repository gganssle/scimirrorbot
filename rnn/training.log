tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 455, val: 24, test: 0	
vocab size: 167	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 305703	
cloning rnn	
cloning criterion	
1/22750 (epoch 0.002), train_loss = 5.09721118, grad/param norm = 4.1292e-01, time/batch = 0.7765s	
2/22750 (epoch 0.004), train_loss = 4.77010475, grad/param norm = 1.4888e+00, time/batch = 0.7159s	
3/22750 (epoch 0.007), train_loss = 4.29072892, grad/param norm = 1.0968e+00, time/batch = 0.7061s	
4/22750 (epoch 0.009), train_loss = 4.61846826, grad/param norm = 1.2378e+00, time/batch = 0.7382s	
5/22750 (epoch 0.011), train_loss = 4.32260996, grad/param norm = 1.0794e+00, time/batch = 0.7190s	
6/22750 (epoch 0.013), train_loss = 4.35623602, grad/param norm = 7.9464e-01, time/batch = 0.6993s	
7/22750 (epoch 0.015), train_loss = 4.24686416, grad/param norm = 6.1236e-01, time/batch = 0.6945s	
8/22750 (epoch 0.018), train_loss = 4.23696722, grad/param norm = 5.6177e-01, time/batch = 0.7054s	
9/22750 (epoch 0.020), train_loss = 4.26972774, grad/param norm = 6.4742e-01, time/batch = 0.7016s	
10/22750 (epoch 0.022), train_loss = 4.21803980, grad/param norm = 7.1547e-01, time/batch = 0.6958s	
11/22750 (epoch 0.024), train_loss = 4.10627629, grad/param norm = 6.0702e-01, time/batch = 0.7018s	
12/22750 (epoch 0.026), train_loss = 4.33948658, grad/param norm = 8.9670e-01, time/batch = 0.7038s	
13/22750 (epoch 0.029), train_loss = 4.17702946, grad/param norm = 9.2428e-01, time/batch = 0.7003s	
14/22750 (epoch 0.031), train_loss = 4.45303672, grad/param norm = 8.5426e-01, time/batch = 0.6974s	
15/22750 (epoch 0.033), train_loss = 4.36719507, grad/param norm = 4.8566e-01, time/batch = 0.7027s	
16/22750 (epoch 0.035), train_loss = 4.34913377, grad/param norm = 7.1507e-01, time/batch = 0.6979s	
17/22750 (epoch 0.037), train_loss = 4.38080194, grad/param norm = 5.5927e-01, time/batch = 0.6980s	
18/22750 (epoch 0.040), train_loss = 4.30641058, grad/param norm = 7.4206e-01, time/batch = 0.7012s	
19/22750 (epoch 0.042), train_loss = 4.32661646, grad/param norm = 4.6530e-01, time/batch = 0.7050s	
20/22750 (epoch 0.044), train_loss = 4.22582494, grad/param norm = 7.1318e-01, time/batch = 0.6988s	
21/22750 (epoch 0.046), train_loss = 4.05638776, grad/param norm = 8.0192e-01, time/batch = 0.7028s	
22/22750 (epoch 0.048), train_loss = 4.18185808, grad/param norm = 8.2153e-01, time/batch = 0.6959s	
23/22750 (epoch 0.051), train_loss = 4.18061437, grad/param norm = 6.4739e-01, time/batch = 0.7009s	
24/22750 (epoch 0.053), train_loss = 4.17862542, grad/param norm = 7.6203e-01, time/batch = 0.6999s	
25/22750 (epoch 0.055), train_loss = 4.35683233, grad/param norm = 6.4828e-01, time/batch = 0.7039s	
26/22750 (epoch 0.057), train_loss = 4.22379745, grad/param norm = 7.2841e-01, time/batch = 0.6986s	
27/22750 (epoch 0.059), train_loss = 4.24749123, grad/param norm = 5.9709e-01, time/batch = 0.7009s	
28/22750 (epoch 0.062), train_loss = 4.15507573, grad/param norm = 5.6424e-01, time/batch = 0.7009s	
29/22750 (epoch 0.064), train_loss = 4.10994731, grad/param norm = 7.4910e-01, time/batch = 0.6970s	
30/22750 (epoch 0.066), train_loss = 3.94137728, grad/param norm = 5.9111e-01, time/batch = 0.6969s	
31/22750 (epoch 0.068), train_loss = 4.13859606, grad/param norm = 1.0643e+00, time/batch = 0.7035s	
32/22750 (epoch 0.070), train_loss = 3.90578065, grad/param norm = 1.2052e+00, time/batch = 0.7015s	
33/22750 (epoch 0.073), train_loss = 4.06569778, grad/param norm = 7.7661e-01, time/batch = 0.7198s	
34/22750 (epoch 0.075), train_loss = 4.17158813, grad/param norm = 5.6096e-01, time/batch = 0.7064s	
35/22750 (epoch 0.077), train_loss = 4.04790278, grad/param norm = 5.4535e-01, time/batch = 0.7048s	
36/22750 (epoch 0.079), train_loss = 3.92155731, grad/param norm = 7.1104e-01, time/batch = 0.6989s	
37/22750 (epoch 0.081), train_loss = 4.16011858, grad/param norm = 8.0361e-01, time/batch = 0.7013s	
38/22750 (epoch 0.084), train_loss = 4.21836724, grad/param norm = 7.0903e-01, time/batch = 0.6983s	
39/22750 (epoch 0.086), train_loss = 4.24073574, grad/param norm = 7.4814e-01, time/batch = 0.7012s	
40/22750 (epoch 0.088), train_loss = 4.12748379, grad/param norm = 5.9654e-01, time/batch = 0.7038s	
41/22750 (epoch 0.090), train_loss = 4.18457370, grad/param norm = 6.2748e-01, time/batch = 0.7010s	
42/22750 (epoch 0.092), train_loss = 4.20166961, grad/param norm = 7.5727e-01, time/batch = 0.6966s	
43/22750 (epoch 0.095), train_loss = 4.22537622, grad/param norm = 5.7661e-01, time/batch = 0.6990s	
44/22750 (epoch 0.097), train_loss = 4.22888286, grad/param norm = 5.5113e-01, time/batch = 0.7071s	
45/22750 (epoch 0.099), train_loss = 4.24796850, grad/param norm = 5.6525e-01, time/batch = 0.6990s	
46/22750 (epoch 0.101), train_loss = 4.11073626, grad/param norm = 5.6529e-01, time/batch = 0.7007s	
47/22750 (epoch 0.103), train_loss = 4.16760221, grad/param norm = 1.7116e+00, time/batch = 0.7006s	
48/22750 (epoch 0.105), train_loss = 4.09434707, grad/param norm = 1.1982e+00, time/batch = 0.7026s	
49/22750 (epoch 0.108), train_loss = 4.05560855, grad/param norm = 1.9812e+00, time/batch = 0.7033s	
50/22750 (epoch 0.110), train_loss = 4.04694312, grad/param norm = 7.0581e-01, time/batch = 0.7036s	
51/22750 (epoch 0.112), train_loss = 3.95920981, grad/param norm = 5.4017e-01, time/batch = 0.6987s	
52/22750 (epoch 0.114), train_loss = 3.77479366, grad/param norm = 6.5542e-01, time/batch = 0.6970s	
53/22750 (epoch 0.116), train_loss = 3.70144288, grad/param norm = 4.8145e-01, time/batch = 0.7010s	
54/22750 (epoch 0.119), train_loss = 3.82856810, grad/param norm = 5.5176e-01, time/batch = 0.6980s	
55/22750 (epoch 0.121), train_loss = 3.87182315, grad/param norm = 7.2951e-01, time/batch = 0.6983s	
56/22750 (epoch 0.123), train_loss = 3.73841775, grad/param norm = 5.5333e-01, time/batch = 0.6997s	
57/22750 (epoch 0.125), train_loss = 3.71960465, grad/param norm = 5.1348e-01, time/batch = 0.7031s	
58/22750 (epoch 0.127), train_loss = 3.66878748, grad/param norm = 5.1442e-01, time/batch = 0.7023s	
59/22750 (epoch 0.130), train_loss = 3.79687100, grad/param norm = 5.5933e-01, time/batch = 0.7145s	
60/22750 (epoch 0.132), train_loss = 3.68850334, grad/param norm = 6.6329e-01, time/batch = 0.7043s	
61/22750 (epoch 0.134), train_loss = 3.80027181, grad/param norm = 8.5956e-01, time/batch = 0.7057s	
62/22750 (epoch 0.136), train_loss = 3.76414562, grad/param norm = 1.8906e+00, time/batch = 0.7007s	
63/22750 (epoch 0.138), train_loss = 3.64370238, grad/param norm = 6.6937e-01, time/batch = 0.7030s	
64/22750 (epoch 0.141), train_loss = 3.75188986, grad/param norm = 5.9364e-01, time/batch = 0.6980s	
65/22750 (epoch 0.143), train_loss = 3.63764134, grad/param norm = 6.0826e-01, time/batch = 0.7029s	
66/22750 (epoch 0.145), train_loss = 3.68046210, grad/param norm = 5.5697e-01, time/batch = 0.7013s	
67/22750 (epoch 0.147), train_loss = 3.53982483, grad/param norm = 4.6986e-01, time/batch = 0.7041s	
68/22750 (epoch 0.149), train_loss = 3.57620191, grad/param norm = 5.1765e-01, time/batch = 0.7024s	
69/22750 (epoch 0.152), train_loss = 3.61802701, grad/param norm = 6.2889e-01, time/batch = 0.7030s	
70/22750 (epoch 0.154), train_loss = 3.64801967, grad/param norm = 5.2289e-01, time/batch = 0.7070s	
71/22750 (epoch 0.156), train_loss = 3.77713279, grad/param norm = 6.1940e-01, time/batch = 0.7070s	
72/22750 (epoch 0.158), train_loss = 3.89989268, grad/param norm = 1.7582e+00, time/batch = 0.7110s	
73/22750 (epoch 0.160), train_loss = 3.65838790, grad/param norm = 4.6099e-01, time/batch = 0.7221s	
74/22750 (epoch 0.163), train_loss = 3.61638084, grad/param norm = 5.9369e-01, time/batch = 0.7146s	
75/22750 (epoch 0.165), train_loss = 3.71225466, grad/param norm = 6.8692e-01, time/batch = 0.7238s	
76/22750 (epoch 0.167), train_loss = 3.68215552, grad/param norm = 6.0298e-01, time/batch = 0.7228s	
77/22750 (epoch 0.169), train_loss = 3.70361315, grad/param norm = 4.3974e-01, time/batch = 0.7114s	
78/22750 (epoch 0.171), train_loss = 3.60723664, grad/param norm = 4.4431e-01, time/batch = 0.7038s	
79/22750 (epoch 0.174), train_loss = 3.47399619, grad/param norm = 4.1663e-01, time/batch = 0.7067s	
80/22750 (epoch 0.176), train_loss = 3.48728256, grad/param norm = 4.5068e-01, time/batch = 0.7038s	
81/22750 (epoch 0.178), train_loss = 3.67747443, grad/param norm = 4.6992e-01, time/batch = 0.7052s	
82/22750 (epoch 0.180), train_loss = 3.66532699, grad/param norm = 5.1306e-01, time/batch = 0.7045s	
83/22750 (epoch 0.182), train_loss = 3.66876542, grad/param norm = 5.3338e-01, time/batch = 0.7039s	
84/22750 (epoch 0.185), train_loss = 3.61422024, grad/param norm = 5.5718e-01, time/batch = 0.7060s	
85/22750 (epoch 0.187), train_loss = 3.69587120, grad/param norm = 5.4494e-01, time/batch = 0.7021s	
86/22750 (epoch 0.189), train_loss = 3.57819790, grad/param norm = 4.9975e-01, time/batch = 0.7169s	
87/22750 (epoch 0.191), train_loss = 3.55014752, grad/param norm = 5.0425e-01, time/batch = 0.7090s	
88/22750 (epoch 0.193), train_loss = 3.55330075, grad/param norm = 3.6701e-01, time/batch = 0.7018s	
89/22750 (epoch 0.196), train_loss = 3.81388640, grad/param norm = 5.8564e-01, time/batch = 0.7098s	
90/22750 (epoch 0.198), train_loss = 3.66151936, grad/param norm = 9.7036e-01, time/batch = 0.6998s	
91/22750 (epoch 0.200), train_loss = 3.75476027, grad/param norm = 1.0319e+00, time/batch = 0.7005s	
92/22750 (epoch 0.202), train_loss = 3.80714956, grad/param norm = 4.8233e-01, time/batch = 0.7082s	
93/22750 (epoch 0.204), train_loss = 3.77143342, grad/param norm = 5.1312e-01, time/batch = 0.7301s	
94/22750 (epoch 0.207), train_loss = 3.46850251, grad/param norm = 5.4616e-01, time/batch = 0.7268s	
95/22750 (epoch 0.209), train_loss = 3.82626809, grad/param norm = 6.2729e-01, time/batch = 0.7252s	
96/22750 (epoch 0.211), train_loss = 3.55966605, grad/param norm = 6.5591e-01, time/batch = 0.7142s	
97/22750 (epoch 0.213), train_loss = 3.68249586, grad/param norm = 5.3157e-01, time/batch = 0.6966s	
98/22750 (epoch 0.215), train_loss = 3.81956919, grad/param norm = 6.8990e-01, time/batch = 0.7002s	
99/22750 (epoch 0.218), train_loss = 3.45765906, grad/param norm = 7.0479e-01, time/batch = 0.6984s	
100/22750 (epoch 0.220), train_loss = 3.81192045, grad/param norm = 1.0985e+00, time/batch = 0.7063s	
101/22750 (epoch 0.222), train_loss = 3.61466679, grad/param norm = 6.5254e-01, time/batch = 0.7054s	
102/22750 (epoch 0.224), train_loss = 3.69499253, grad/param norm = 5.8829e-01, time/batch = 0.7006s	
103/22750 (epoch 0.226), train_loss = 3.57308229, grad/param norm = 5.5773e-01, time/batch = 0.7046s	
104/22750 (epoch 0.229), train_loss = 3.77586798, grad/param norm = 6.5435e-01, time/batch = 0.7042s	
105/22750 (epoch 0.231), train_loss = 3.75537380, grad/param norm = 1.1235e+00, time/batch = 0.7024s	
106/22750 (epoch 0.233), train_loss = 3.71139041, grad/param norm = 7.6257e-01, time/batch = 0.7013s	
107/22750 (epoch 0.235), train_loss = 3.50689719, grad/param norm = 5.2078e-01, time/batch = 0.7048s	
108/22750 (epoch 0.237), train_loss = 3.51309209, grad/param norm = 5.9572e-01, time/batch = 0.7055s	
109/22750 (epoch 0.240), train_loss = 3.80153097, grad/param norm = 5.8140e-01, time/batch = 0.7057s	
110/22750 (epoch 0.242), train_loss = 3.53765136, grad/param norm = 5.2178e-01, time/batch = 0.7001s	
111/22750 (epoch 0.244), train_loss = 3.46599551, grad/param norm = 5.7969e-01, time/batch = 0.7046s	
112/22750 (epoch 0.246), train_loss = 3.81103895, grad/param norm = 6.7228e-01, time/batch = 0.7011s	
113/22750 (epoch 0.248), train_loss = 3.39887212, grad/param norm = 9.1796e-01, time/batch = 0.7031s	
114/22750 (epoch 0.251), train_loss = 3.60201614, grad/param norm = 8.7497e-01, time/batch = 0.6993s	
115/22750 (epoch 0.253), train_loss = 3.39700558, grad/param norm = 7.5227e-01, time/batch = 0.7000s	
116/22750 (epoch 0.255), train_loss = 3.58469240, grad/param norm = 7.0047e-01, time/batch = 0.6986s	
117/22750 (epoch 0.257), train_loss = 3.56294707, grad/param norm = 8.4463e-01, time/batch = 0.7066s	
118/22750 (epoch 0.259), train_loss = 3.57509562, grad/param norm = 7.7307e-01, time/batch = 0.6981s	
119/22750 (epoch 0.262), train_loss = 3.49741613, grad/param norm = 1.0596e+00, time/batch = 0.7001s	
120/22750 (epoch 0.264), train_loss = 3.59064673, grad/param norm = 9.3607e-01, time/batch = 0.6989s	
121/22750 (epoch 0.266), train_loss = 3.37065325, grad/param norm = 4.7621e-01, time/batch = 0.7016s	
122/22750 (epoch 0.268), train_loss = 3.33562172, grad/param norm = 3.9616e-01, time/batch = 0.7062s	
123/22750 (epoch 0.270), train_loss = 3.24245955, grad/param norm = 7.0559e-01, time/batch = 0.7044s	
124/22750 (epoch 0.273), train_loss = 3.32089860, grad/param norm = 6.2948e-01, time/batch = 0.7066s	
125/22750 (epoch 0.275), train_loss = 3.21426714, grad/param norm = 7.6727e-01, time/batch = 0.7066s	
126/22750 (epoch 0.277), train_loss = 3.57062415, grad/param norm = 9.1519e-01, time/batch = 0.7086s	
127/22750 (epoch 0.279), train_loss = 3.28926917, grad/param norm = 1.2233e+00, time/batch = 0.7022s	
128/22750 (epoch 0.281), train_loss = 3.20906601, grad/param norm = 7.0805e-01, time/batch = 0.7027s	
129/22750 (epoch 0.284), train_loss = 3.07658760, grad/param norm = 4.8012e-01, time/batch = 0.7032s	
130/22750 (epoch 0.286), train_loss = 3.26544021, grad/param norm = 4.8430e-01, time/batch = 0.7034s	
131/22750 (epoch 0.288), train_loss = 3.30878190, grad/param norm = 4.2683e-01, time/batch = 0.7045s	
132/22750 (epoch 0.290), train_loss = 3.07160088, grad/param norm = 5.8411e-01, time/batch = 0.7077s	
133/22750 (epoch 0.292), train_loss = 3.29920507, grad/param norm = 1.1807e+00, time/batch = 0.7073s	
134/22750 (epoch 0.295), train_loss = 3.32398617, grad/param norm = 1.5508e+00, time/batch = 0.7027s	
135/22750 (epoch 0.297), train_loss = 3.16450685, grad/param norm = 4.7503e-01, time/batch = 0.7309s	
136/22750 (epoch 0.299), train_loss = 3.26805584, grad/param norm = 3.9728e-01, time/batch = 0.7037s	
137/22750 (epoch 0.301), train_loss = 3.37550683, grad/param norm = 4.2566e-01, time/batch = 0.7137s	
138/22750 (epoch 0.303), train_loss = 3.28202875, grad/param norm = 4.0846e-01, time/batch = 0.7064s	
139/22750 (epoch 0.305), train_loss = 3.40687328, grad/param norm = 5.9728e-01, time/batch = 0.7022s	
140/22750 (epoch 0.308), train_loss = 3.14047314, grad/param norm = 7.8052e-01, time/batch = 0.7010s	
141/22750 (epoch 0.310), train_loss = 2.99944160, grad/param norm = 7.5520e-01, time/batch = 0.7059s	
142/22750 (epoch 0.312), train_loss = 3.11806430, grad/param norm = 8.2960e-01, time/batch = 0.6980s	
143/22750 (epoch 0.314), train_loss = 3.26892686, grad/param norm = 5.5660e-01, time/batch = 0.7013s	
144/22750 (epoch 0.316), train_loss = 3.09226476, grad/param norm = 4.0874e-01, time/batch = 0.7157s	
145/22750 (epoch 0.319), train_loss = 3.14930874, grad/param norm = 5.7482e-01, time/batch = 0.7045s	
146/22750 (epoch 0.321), train_loss = 3.21067452, grad/param norm = 6.6200e-01, time/batch = 0.7056s	
147/22750 (epoch 0.323), train_loss = 2.72519019, grad/param norm = 5.4453e-01, time/batch = 0.7001s	
148/22750 (epoch 0.325), train_loss = 3.08022773, grad/param norm = 6.5790e-01, time/batch = 0.7036s	
149/22750 (epoch 0.327), train_loss = 3.52480345, grad/param norm = 6.9543e-01, time/batch = 0.7010s	
150/22750 (epoch 0.330), train_loss = 3.25660661, grad/param norm = 6.7021e-01, time/batch = 0.7020s	
151/22750 (epoch 0.332), train_loss = 3.14711718, grad/param norm = 4.7170e-01, time/batch = 0.7077s	
152/22750 (epoch 0.334), train_loss = 3.12595270, grad/param norm = 7.7282e-01, time/batch = 0.7105s	
153/22750 (epoch 0.336), train_loss = 3.12414162, grad/param norm = 9.0822e-01, time/batch = 0.7071s	
154/22750 (epoch 0.338), train_loss = 3.35726464, grad/param norm = 6.3389e-01, time/batch = 0.7052s	
155/22750 (epoch 0.341), train_loss = 3.04255917, grad/param norm = 4.3435e-01, time/batch = 0.7075s	
156/22750 (epoch 0.343), train_loss = 3.00106661, grad/param norm = 3.0598e-01, time/batch = 0.7032s	
157/22750 (epoch 0.345), train_loss = 3.20109035, grad/param norm = 3.7097e-01, time/batch = 0.7012s	
158/22750 (epoch 0.347), train_loss = 3.07319258, grad/param norm = 4.7581e-01, time/batch = 0.7074s	
159/22750 (epoch 0.349), train_loss = 2.88907658, grad/param norm = 8.4049e-01, time/batch = 0.7105s	
160/22750 (epoch 0.352), train_loss = 3.15783234, grad/param norm = 8.9271e-01, time/batch = 0.7239s	
161/22750 (epoch 0.354), train_loss = 3.17208938, grad/param norm = 6.8542e-01, time/batch = 0.7264s	
162/22750 (epoch 0.356), train_loss = 3.16608241, grad/param norm = 5.0160e-01, time/batch = 0.7263s	
163/22750 (epoch 0.358), train_loss = 2.97607824, grad/param norm = 3.8184e-01, time/batch = 0.7252s	
164/22750 (epoch 0.360), train_loss = 3.25602322, grad/param norm = 4.1899e-01, time/batch = 0.7279s	
165/22750 (epoch 0.363), train_loss = 3.21954137, grad/param norm = 7.5652e-01, time/batch = 0.7190s	
166/22750 (epoch 0.365), train_loss = 2.69819196, grad/param norm = 8.6309e-01, time/batch = 0.7185s	
167/22750 (epoch 0.367), train_loss = 2.61783865, grad/param norm = 9.3302e-01, time/batch = 0.7137s	
168/22750 (epoch 0.369), train_loss = 2.87953800, grad/param norm = 5.9048e-01, time/batch = 0.7086s	
169/22750 (epoch 0.371), train_loss = 2.83344405, grad/param norm = 3.1483e-01, time/batch = 0.7145s	
170/22750 (epoch 0.374), train_loss = 2.67632476, grad/param norm = 3.9468e-01, time/batch = 0.7176s	
171/22750 (epoch 0.376), train_loss = 3.08786411, grad/param norm = 7.0804e-01, time/batch = 0.7106s	
172/22750 (epoch 0.378), train_loss = 2.93195164, grad/param norm = 7.5696e-01, time/batch = 0.7090s	
173/22750 (epoch 0.380), train_loss = 3.15079826, grad/param norm = 6.2745e-01, time/batch = 0.7235s	
174/22750 (epoch 0.382), train_loss = 2.86666256, grad/param norm = 5.8212e-01, time/batch = 0.7096s	
175/22750 (epoch 0.385), train_loss = 3.05870162, grad/param norm = 6.8437e-01, time/batch = 0.7158s	
176/22750 (epoch 0.387), train_loss = 2.99326574, grad/param norm = 6.2235e-01, time/batch = 0.7100s	
177/22750 (epoch 0.389), train_loss = 2.70372911, grad/param norm = 6.0638e-01, time/batch = 0.7029s	
178/22750 (epoch 0.391), train_loss = 2.77634087, grad/param norm = 4.0236e-01, time/batch = 0.7023s	
179/22750 (epoch 0.393), train_loss = 2.82520090, grad/param norm = 5.7035e-01, time/batch = 0.7066s	
180/22750 (epoch 0.396), train_loss = 3.01429399, grad/param norm = 4.2473e-01, time/batch = 0.7067s	
181/22750 (epoch 0.398), train_loss = 2.95846240, grad/param norm = 8.4526e-01, time/batch = 0.7146s	
182/22750 (epoch 0.400), train_loss = 3.05314646, grad/param norm = 8.4749e-01, time/batch = 0.7073s	
183/22750 (epoch 0.402), train_loss = 3.11181950, grad/param norm = 4.3371e-01, time/batch = 0.7105s	
184/22750 (epoch 0.404), train_loss = 3.10988210, grad/param norm = 4.1376e-01, time/batch = 0.7162s	
185/22750 (epoch 0.407), train_loss = 3.01089613, grad/param norm = 4.2534e-01, time/batch = 0.7148s	
186/22750 (epoch 0.409), train_loss = 2.99198378, grad/param norm = 4.3330e-01, time/batch = 0.7103s	
187/22750 (epoch 0.411), train_loss = 2.91855261, grad/param norm = 5.9521e-01, time/batch = 0.7274s	
188/22750 (epoch 0.413), train_loss = 2.95852643, grad/param norm = 7.1637e-01, time/batch = 0.7195s	
189/22750 (epoch 0.415), train_loss = 2.85031346, grad/param norm = 4.7057e-01, time/batch = 0.7221s	
190/22750 (epoch 0.418), train_loss = 2.68175300, grad/param norm = 4.1236e-01, time/batch = 0.7231s	
191/22750 (epoch 0.420), train_loss = 3.10344197, grad/param norm = 4.4243e-01, time/batch = 0.7216s	
192/22750 (epoch 0.422), train_loss = 3.12835922, grad/param norm = 4.6526e-01, time/batch = 0.7037s	
193/22750 (epoch 0.424), train_loss = 3.31618579, grad/param norm = 6.6803e-01, time/batch = 0.7018s	
194/22750 (epoch 0.426), train_loss = 3.09199545, grad/param norm = 6.7799e-01, time/batch = 0.6901s	
195/22750 (epoch 0.429), train_loss = 2.63216586, grad/param norm = 8.0584e-01, time/batch = 0.6924s	
196/22750 (epoch 0.431), train_loss = 2.85495550, grad/param norm = 6.6860e-01, time/batch = 0.6891s	
197/22750 (epoch 0.433), train_loss = 2.67596454, grad/param norm = 4.9554e-01, time/batch = 0.7076s	
198/22750 (epoch 0.435), train_loss = 3.02866404, grad/param norm = 5.4540e-01, time/batch = 0.7039s	
199/22750 (epoch 0.437), train_loss = 3.07877960, grad/param norm = 5.5736e-01, time/batch = 0.6972s	
200/22750 (epoch 0.440), train_loss = 3.16895509, grad/param norm = 8.3140e-01, time/batch = 0.6984s	
201/22750 (epoch 0.442), train_loss = 3.11360888, grad/param norm = 7.4651e-01, time/batch = 0.6954s	
202/22750 (epoch 0.444), train_loss = 3.21419030, grad/param norm = 4.5571e-01, time/batch = 0.6920s	
203/22750 (epoch 0.446), train_loss = 2.98612830, grad/param norm = 9.9194e-01, time/batch = 0.6875s	
204/22750 (epoch 0.448), train_loss = 3.22606651, grad/param norm = 7.2749e-01, time/batch = 0.6903s	
205/22750 (epoch 0.451), train_loss = 3.16718296, grad/param norm = 4.8284e-01, time/batch = 0.6895s	
206/22750 (epoch 0.453), train_loss = 3.25491447, grad/param norm = 4.6137e-01, time/batch = 0.6892s	
207/22750 (epoch 0.455), train_loss = 3.25842228, grad/param norm = 7.8133e-01, time/batch = 0.6943s	
208/22750 (epoch 0.457), train_loss = 3.38632683, grad/param norm = 1.9399e+00, time/batch = 0.6970s	
209/22750 (epoch 0.459), train_loss = 3.29228145, grad/param norm = 1.9142e+00, time/batch = 0.7057s	
210/22750 (epoch 0.462), train_loss = 2.99467293, grad/param norm = 5.5032e-01, time/batch = 0.7047s	
211/22750 (epoch 0.464), train_loss = 2.67106211, grad/param norm = 3.9540e-01, time/batch = 0.7025s	
212/22750 (epoch 0.466), train_loss = 2.84033581, grad/param norm = 3.9367e-01, time/batch = 0.7003s	
213/22750 (epoch 0.468), train_loss = 2.70555457, grad/param norm = 4.0430e-01, time/batch = 0.6986s	
214/22750 (epoch 0.470), train_loss = 2.94652767, grad/param norm = 4.5254e-01, time/batch = 0.7020s	
215/22750 (epoch 0.473), train_loss = 2.87629006, grad/param norm = 4.9914e-01, time/batch = 0.6996s	
216/22750 (epoch 0.475), train_loss = 2.98475950, grad/param norm = 4.3425e-01, time/batch = 0.6957s	
217/22750 (epoch 0.477), train_loss = 2.78739760, grad/param norm = 5.8592e-01, time/batch = 0.6895s	
218/22750 (epoch 0.479), train_loss = 2.87583185, grad/param norm = 4.5813e-01, time/batch = 0.7117s	
219/22750 (epoch 0.481), train_loss = 2.77913747, grad/param norm = 4.6558e-01, time/batch = 0.7024s	
220/22750 (epoch 0.484), train_loss = 2.73183012, grad/param norm = 3.4540e-01, time/batch = 0.6959s	
221/22750 (epoch 0.486), train_loss = 2.90468928, grad/param norm = 4.8981e-01, time/batch = 0.6984s	
222/22750 (epoch 0.488), train_loss = 2.56133371, grad/param norm = 7.0507e-01, time/batch = 0.6879s	
223/22750 (epoch 0.490), train_loss = 2.75352179, grad/param norm = 5.2793e-01, time/batch = 0.6938s	
224/22750 (epoch 0.492), train_loss = 2.92384309, grad/param norm = 4.0014e-01, time/batch = 0.6874s	
225/22750 (epoch 0.495), train_loss = 2.70444060, grad/param norm = 4.8763e-01, time/batch = 0.6844s	
226/22750 (epoch 0.497), train_loss = 2.84350366, grad/param norm = 5.9270e-01, time/batch = 0.6845s	
227/22750 (epoch 0.499), train_loss = 2.89896520, grad/param norm = 5.5962e-01, time/batch = 0.6867s	
228/22750 (epoch 0.501), train_loss = 2.76111256, grad/param norm = 3.6891e-01, time/batch = 0.6856s	
229/22750 (epoch 0.503), train_loss = 2.86102415, grad/param norm = 3.4280e-01, time/batch = 0.6963s	
230/22750 (epoch 0.505), train_loss = 2.76955275, grad/param norm = 3.8132e-01, time/batch = 0.6946s	
231/22750 (epoch 0.508), train_loss = 2.70001384, grad/param norm = 6.3625e-01, time/batch = 0.6888s	
232/22750 (epoch 0.510), train_loss = 2.81305099, grad/param norm = 6.3444e-01, time/batch = 0.6909s	
233/22750 (epoch 0.512), train_loss = 2.66766506, grad/param norm = 5.7086e-01, time/batch = 0.6892s	
234/22750 (epoch 0.514), train_loss = 2.95032049, grad/param norm = 4.7937e-01, time/batch = 0.6867s	
235/22750 (epoch 0.516), train_loss = 2.74756496, grad/param norm = 5.3980e-01, time/batch = 0.6907s	
236/22750 (epoch 0.519), train_loss = 2.98143561, grad/param norm = 6.6764e-01, time/batch = 0.6930s	
237/22750 (epoch 0.521), train_loss = 2.85832986, grad/param norm = 9.9091e-01, time/batch = 0.6926s	
238/22750 (epoch 0.523), train_loss = 2.76023996, grad/param norm = 9.9354e-01, time/batch = 0.6872s	
239/22750 (epoch 0.525), train_loss = 2.93836220, grad/param norm = 4.1938e-01, time/batch = 0.6858s	
240/22750 (epoch 0.527), train_loss = 2.85462488, grad/param norm = 4.4017e-01, time/batch = 0.6870s	
241/22750 (epoch 0.530), train_loss = 2.90406995, grad/param norm = 5.0771e-01, time/batch = 0.6881s	
242/22750 (epoch 0.532), train_loss = 2.92344991, grad/param norm = 6.5338e-01, time/batch = 0.6910s	
243/22750 (epoch 0.534), train_loss = 2.86847450, grad/param norm = 5.6075e-01, time/batch = 0.6918s	
244/22750 (epoch 0.536), train_loss = 2.86269572, grad/param norm = 4.6845e-01, time/batch = 0.6966s	
245/22750 (epoch 0.538), train_loss = 3.00870606, grad/param norm = 4.0258e-01, time/batch = 0.7130s	
246/22750 (epoch 0.541), train_loss = 2.58489998, grad/param norm = 3.8625e-01, time/batch = 0.7119s	
247/22750 (epoch 0.543), train_loss = 2.56411908, grad/param norm = 4.3298e-01, time/batch = 0.7021s	
248/22750 (epoch 0.545), train_loss = 2.78343000, grad/param norm = 3.6619e-01, time/batch = 0.7096s	
249/22750 (epoch 0.547), train_loss = 2.70652858, grad/param norm = 3.2323e-01, time/batch = 0.7027s	
250/22750 (epoch 0.549), train_loss = 2.68948019, grad/param norm = 4.2670e-01, time/batch = 0.6975s	
251/22750 (epoch 0.552), train_loss = 2.79044983, grad/param norm = 4.6035e-01, time/batch = 0.6970s	
252/22750 (epoch 0.554), train_loss = 2.76525739, grad/param norm = 6.4002e-01, time/batch = 0.6930s	
253/22750 (epoch 0.556), train_loss = 2.94701231, grad/param norm = 9.0020e-01, time/batch = 0.6896s	
254/22750 (epoch 0.558), train_loss = 3.04625143, grad/param norm = 9.0061e-01, time/batch = 0.6928s	
255/22750 (epoch 0.560), train_loss = 2.96016090, grad/param norm = 1.0215e+00, time/batch = 0.6928s	
256/22750 (epoch 0.563), train_loss = 3.01256543, grad/param norm = 7.2876e-01, time/batch = 0.6902s	
257/22750 (epoch 0.565), train_loss = 3.02135433, grad/param norm = 5.1830e-01, time/batch = 0.6910s	
258/22750 (epoch 0.567), train_loss = 2.72831436, grad/param norm = 4.9073e-01, time/batch = 0.7009s	
259/22750 (epoch 0.569), train_loss = 2.89179984, grad/param norm = 6.8848e-01, time/batch = 0.7140s	
260/22750 (epoch 0.571), train_loss = 2.77514982, grad/param norm = 5.6652e-01, time/batch = 0.7012s	
261/22750 (epoch 0.574), train_loss = 2.59214577, grad/param norm = 3.9703e-01, time/batch = 0.6957s	
262/22750 (epoch 0.576), train_loss = 2.62845712, grad/param norm = 3.2516e-01, time/batch = 0.6930s	
263/22750 (epoch 0.578), train_loss = 2.72139104, grad/param norm = 4.1884e-01, time/batch = 0.7089s	
264/22750 (epoch 0.580), train_loss = 2.73595273, grad/param norm = 3.4824e-01, time/batch = 0.7021s	
265/22750 (epoch 0.582), train_loss = 2.66559972, grad/param norm = 4.1330e-01, time/batch = 0.6940s	
266/22750 (epoch 0.585), train_loss = 2.49505386, grad/param norm = 4.4497e-01, time/batch = 0.6896s	
267/22750 (epoch 0.587), train_loss = 2.65058652, grad/param norm = 4.7896e-01, time/batch = 0.6893s	
268/22750 (epoch 0.589), train_loss = 2.76265173, grad/param norm = 5.2261e-01, time/batch = 0.6923s	
269/22750 (epoch 0.591), train_loss = 2.89562523, grad/param norm = 8.6182e-01, time/batch = 0.6904s	
270/22750 (epoch 0.593), train_loss = 3.15722587, grad/param norm = 2.4212e+00, time/batch = 0.6925s	
271/22750 (epoch 0.596), train_loss = 2.86822752, grad/param norm = 1.0507e+00, time/batch = 0.6924s	
272/22750 (epoch 0.598), train_loss = 2.85232315, grad/param norm = 2.8892e-01, time/batch = 0.6883s	
273/22750 (epoch 0.600), train_loss = 2.64398071, grad/param norm = 3.5429e-01, time/batch = 0.6963s	
274/22750 (epoch 0.602), train_loss = 2.69192629, grad/param norm = 4.2291e-01, time/batch = 0.6878s	
275/22750 (epoch 0.604), train_loss = 2.76311180, grad/param norm = 4.6606e-01, time/batch = 0.6915s	
276/22750 (epoch 0.607), train_loss = 2.51274250, grad/param norm = 5.3159e-01, time/batch = 0.6898s	
277/22750 (epoch 0.609), train_loss = 2.56184040, grad/param norm = 6.2125e-01, time/batch = 0.6873s	
278/22750 (epoch 0.611), train_loss = 2.62308343, grad/param norm = 4.7659e-01, time/batch = 0.6923s	
279/22750 (epoch 0.613), train_loss = 2.54252348, grad/param norm = 3.9786e-01, time/batch = 0.6964s	
280/22750 (epoch 0.615), train_loss = 2.65677662, grad/param norm = 5.4046e-01, time/batch = 0.6921s	
281/22750 (epoch 0.618), train_loss = 2.45510626, grad/param norm = 6.6729e-01, time/batch = 0.6935s	
282/22750 (epoch 0.620), train_loss = 2.62764142, grad/param norm = 5.6728e-01, time/batch = 0.6982s	
283/22750 (epoch 0.622), train_loss = 2.54021620, grad/param norm = 4.4017e-01, time/batch = 0.6937s	
284/22750 (epoch 0.624), train_loss = 2.96762760, grad/param norm = 5.7352e-01, time/batch = 0.6881s	
285/22750 (epoch 0.626), train_loss = 3.01286196, grad/param norm = 7.1226e-01, time/batch = 0.6946s	
286/22750 (epoch 0.629), train_loss = 2.81627882, grad/param norm = 6.7030e-01, time/batch = 0.7092s	
287/22750 (epoch 0.631), train_loss = 2.89363949, grad/param norm = 6.0527e-01, time/batch = 0.6952s	
288/22750 (epoch 0.633), train_loss = 2.74254621, grad/param norm = 5.5333e-01, time/batch = 0.6944s	
289/22750 (epoch 0.635), train_loss = 2.93772676, grad/param norm = 4.8240e-01, time/batch = 0.6906s	
290/22750 (epoch 0.637), train_loss = 2.99830975, grad/param norm = 4.7699e-01, time/batch = 0.6892s	
291/22750 (epoch 0.640), train_loss = 2.93667958, grad/param norm = 6.0710e-01, time/batch = 0.6942s	
292/22750 (epoch 0.642), train_loss = 2.96902127, grad/param norm = 5.1606e-01, time/batch = 0.6954s	
293/22750 (epoch 0.644), train_loss = 2.73947920, grad/param norm = 3.1417e-01, time/batch = 0.6985s	
294/22750 (epoch 0.646), train_loss = 2.64750431, grad/param norm = 3.6227e-01, time/batch = 0.6929s	
295/22750 (epoch 0.648), train_loss = 2.83255560, grad/param norm = 3.5990e-01, time/batch = 0.6947s	
296/22750 (epoch 0.651), train_loss = 2.80895799, grad/param norm = 3.9711e-01, time/batch = 0.6977s	
297/22750 (epoch 0.653), train_loss = 2.64690977, grad/param norm = 4.0171e-01, time/batch = 0.6927s	
298/22750 (epoch 0.655), train_loss = 2.72018163, grad/param norm = 4.8536e-01, time/batch = 0.6940s	
299/22750 (epoch 0.657), train_loss = 2.72312317, grad/param norm = 4.0633e-01, time/batch = 0.6930s	
300/22750 (epoch 0.659), train_loss = 2.69951487, grad/param norm = 4.2143e-01, time/batch = 0.6926s	
301/22750 (epoch 0.662), train_loss = 2.90669891, grad/param norm = 4.8146e-01, time/batch = 0.6972s	
302/22750 (epoch 0.664), train_loss = 2.84108956, grad/param norm = 7.6827e-01, time/batch = 0.6985s	
303/22750 (epoch 0.666), train_loss = 2.84807872, grad/param norm = 8.7321e-01, time/batch = 0.6990s	
304/22750 (epoch 0.668), train_loss = 2.77650615, grad/param norm = 5.8080e-01, time/batch = 0.6960s	
305/22750 (epoch 0.670), train_loss = 2.71630529, grad/param norm = 3.8346e-01, time/batch = 0.6964s	
306/22750 (epoch 0.673), train_loss = 2.71540142, grad/param norm = 4.1866e-01, time/batch = 0.6934s	
307/22750 (epoch 0.675), train_loss = 2.97167176, grad/param norm = 5.2126e-01, time/batch = 0.6897s	
308/22750 (epoch 0.677), train_loss = 2.78781150, grad/param norm = 4.8303e-01, time/batch = 0.6926s	
309/22750 (epoch 0.679), train_loss = 3.04993217, grad/param norm = 4.0934e-01, time/batch = 0.6925s	
310/22750 (epoch 0.681), train_loss = 2.77841031, grad/param norm = 4.0035e-01, time/batch = 0.6985s	
311/22750 (epoch 0.684), train_loss = 2.78941167, grad/param norm = 5.1875e-01, time/batch = 0.7144s	
312/22750 (epoch 0.686), train_loss = 2.76239623, grad/param norm = 5.1179e-01, time/batch = 0.7111s	
313/22750 (epoch 0.688), train_loss = 2.77378329, grad/param norm = 4.2778e-01, time/batch = 0.7270s	
314/22750 (epoch 0.690), train_loss = 2.65453788, grad/param norm = 4.4291e-01, time/batch = 0.7251s	
315/22750 (epoch 0.692), train_loss = 2.67990043, grad/param norm = 4.7902e-01, time/batch = 0.7099s	
316/22750 (epoch 0.695), train_loss = 2.67220093, grad/param norm = 4.1632e-01, time/batch = 0.7078s	
317/22750 (epoch 0.697), train_loss = 2.60292936, grad/param norm = 4.7044e-01, time/batch = 0.7044s	
318/22750 (epoch 0.699), train_loss = 2.81887110, grad/param norm = 1.2012e+00, time/batch = 0.7094s	
319/22750 (epoch 0.701), train_loss = 2.85925883, grad/param norm = 1.6603e+00, time/batch = 0.7032s	
320/22750 (epoch 0.703), train_loss = 2.68934762, grad/param norm = 1.2184e+00, time/batch = 0.7004s	
321/22750 (epoch 0.705), train_loss = 2.50623395, grad/param norm = 5.5172e-01, time/batch = 0.7180s	
322/22750 (epoch 0.708), train_loss = 2.72725443, grad/param norm = 4.4123e-01, time/batch = 0.7089s	
323/22750 (epoch 0.710), train_loss = 2.60065696, grad/param norm = 4.4818e-01, time/batch = 0.6999s	
324/22750 (epoch 0.712), train_loss = 2.65081870, grad/param norm = 3.1050e-01, time/batch = 0.7059s	
325/22750 (epoch 0.714), train_loss = 2.59695451, grad/param norm = 3.6594e-01, time/batch = 0.7072s	
326/22750 (epoch 0.716), train_loss = 2.67911138, grad/param norm = 4.3339e-01, time/batch = 0.7019s	
327/22750 (epoch 0.719), train_loss = 2.75623973, grad/param norm = 5.1582e-01, time/batch = 0.6962s	
328/22750 (epoch 0.721), train_loss = 2.65683846, grad/param norm = 5.6719e-01, time/batch = 0.6929s	
329/22750 (epoch 0.723), train_loss = 2.69606887, grad/param norm = 4.9791e-01, time/batch = 0.6895s	
330/22750 (epoch 0.725), train_loss = 2.56215868, grad/param norm = 4.0792e-01, time/batch = 0.7058s	
331/22750 (epoch 0.727), train_loss = 2.48206205, grad/param norm = 4.0304e-01, time/batch = 0.7130s	
332/22750 (epoch 0.730), train_loss = 2.37740002, grad/param norm = 3.7043e-01, time/batch = 0.7143s	
333/22750 (epoch 0.732), train_loss = 2.51332729, grad/param norm = 4.3026e-01, time/batch = 0.7045s	
334/22750 (epoch 0.734), train_loss = 2.32356480, grad/param norm = 5.5425e-01, time/batch = 0.6967s	
335/22750 (epoch 0.736), train_loss = 2.65398212, grad/param norm = 5.5283e-01, time/batch = 0.7031s	
336/22750 (epoch 0.738), train_loss = 2.50330399, grad/param norm = 4.2636e-01, time/batch = 0.7021s	
337/22750 (epoch 0.741), train_loss = 2.65754291, grad/param norm = 3.0501e-01, time/batch = 0.7044s	
338/22750 (epoch 0.743), train_loss = 2.68248811, grad/param norm = 2.9465e-01, time/batch = 0.7046s	
339/22750 (epoch 0.745), train_loss = 2.55020496, grad/param norm = 2.9120e-01, time/batch = 0.7111s	
340/22750 (epoch 0.747), train_loss = 2.41859447, grad/param norm = 3.5689e-01, time/batch = 0.7087s	
341/22750 (epoch 0.749), train_loss = 2.71279889, grad/param norm = 4.2121e-01, time/batch = 0.7007s	
342/22750 (epoch 0.752), train_loss = 2.42154971, grad/param norm = 5.4315e-01, time/batch = 0.6977s	
343/22750 (epoch 0.754), train_loss = 2.67902350, grad/param norm = 6.8638e-01, time/batch = 0.7086s	
344/22750 (epoch 0.756), train_loss = 2.48092185, grad/param norm = 7.6941e-01, time/batch = 0.7110s	
345/22750 (epoch 0.758), train_loss = 2.51394721, grad/param norm = 7.2011e-01, time/batch = 0.7024s	
346/22750 (epoch 0.760), train_loss = 2.73783777, grad/param norm = 4.2732e-01, time/batch = 0.6972s	
347/22750 (epoch 0.763), train_loss = 2.54180900, grad/param norm = 3.4049e-01, time/batch = 0.6988s	
348/22750 (epoch 0.765), train_loss = 2.47211973, grad/param norm = 4.2258e-01, time/batch = 0.6974s	
349/22750 (epoch 0.767), train_loss = 2.50880135, grad/param norm = 4.1805e-01, time/batch = 0.6926s	
350/22750 (epoch 0.769), train_loss = 2.66693716, grad/param norm = 3.7020e-01, time/batch = 0.7025s	
351/22750 (epoch 0.771), train_loss = 2.58057031, grad/param norm = 5.4897e-01, time/batch = 0.7030s	
352/22750 (epoch 0.774), train_loss = 2.76682129, grad/param norm = 1.0401e+00, time/batch = 0.6983s	
353/22750 (epoch 0.776), train_loss = 2.66372616, grad/param norm = 7.3604e-01, time/batch = 0.7081s	
354/22750 (epoch 0.778), train_loss = 2.81177128, grad/param norm = 3.7472e-01, time/batch = 0.7049s	
355/22750 (epoch 0.780), train_loss = 2.76791970, grad/param norm = 5.1088e-01, time/batch = 0.7036s	
356/22750 (epoch 0.782), train_loss = 2.67243699, grad/param norm = 5.2073e-01, time/batch = 0.6972s	
357/22750 (epoch 0.785), train_loss = 2.67890359, grad/param norm = 4.2521e-01, time/batch = 0.6936s	
358/22750 (epoch 0.787), train_loss = 2.56749779, grad/param norm = 4.5547e-01, time/batch = 0.6946s	
359/22750 (epoch 0.789), train_loss = 2.46740234, grad/param norm = 4.4263e-01, time/batch = 0.6938s	
360/22750 (epoch 0.791), train_loss = 2.56775001, grad/param norm = 3.3152e-01, time/batch = 0.7093s	
361/22750 (epoch 0.793), train_loss = 2.56255699, grad/param norm = 3.3290e-01, time/batch = 0.7099s	
362/22750 (epoch 0.796), train_loss = 2.49389438, grad/param norm = 2.7151e-01, time/batch = 0.7038s	
363/22750 (epoch 0.798), train_loss = 2.42619632, grad/param norm = 2.7190e-01, time/batch = 0.7044s	
364/22750 (epoch 0.800), train_loss = 2.53365865, grad/param norm = 2.8230e-01, time/batch = 0.7210s	
365/22750 (epoch 0.802), train_loss = 2.70443766, grad/param norm = 3.4297e-01, time/batch = 0.7179s	
366/22750 (epoch 0.804), train_loss = 2.74183054, grad/param norm = 3.3407e-01, time/batch = 0.7177s	
367/22750 (epoch 0.807), train_loss = 2.64527084, grad/param norm = 3.3957e-01, time/batch = 0.7128s	
368/22750 (epoch 0.809), train_loss = 2.91042074, grad/param norm = 5.3805e-01, time/batch = 0.7114s	
369/22750 (epoch 0.811), train_loss = 2.67634388, grad/param norm = 8.6045e-01, time/batch = 0.7199s	
370/22750 (epoch 0.813), train_loss = 2.85836044, grad/param norm = 6.5346e-01, time/batch = 0.7125s	
371/22750 (epoch 0.815), train_loss = 2.71961992, grad/param norm = 6.1597e-01, time/batch = 0.7245s	
372/22750 (epoch 0.818), train_loss = 2.77517507, grad/param norm = 5.6548e-01, time/batch = 0.7155s	
373/22750 (epoch 0.820), train_loss = 2.73092968, grad/param norm = 3.4774e-01, time/batch = 0.7206s	
374/22750 (epoch 0.822), train_loss = 2.55791651, grad/param norm = 3.0839e-01, time/batch = 0.7149s	
375/22750 (epoch 0.824), train_loss = 2.66900394, grad/param norm = 3.6938e-01, time/batch = 0.7078s	
376/22750 (epoch 0.826), train_loss = 2.63983013, grad/param norm = 3.4676e-01, time/batch = 0.7016s	
377/22750 (epoch 0.829), train_loss = 2.66477418, grad/param norm = 4.3624e-01, time/batch = 0.7046s	
378/22750 (epoch 0.831), train_loss = 2.66202338, grad/param norm = 5.3849e-01, time/batch = 0.7212s	
379/22750 (epoch 0.833), train_loss = 2.78568093, grad/param norm = 3.6414e-01, time/batch = 0.7228s	
380/22750 (epoch 0.835), train_loss = 2.70247592, grad/param norm = 3.3339e-01, time/batch = 0.7056s	
381/22750 (epoch 0.837), train_loss = 2.61143168, grad/param norm = 3.4961e-01, time/batch = 0.7102s	
382/22750 (epoch 0.840), train_loss = 2.68765813, grad/param norm = 3.7452e-01, time/batch = 0.7081s	
383/22750 (epoch 0.842), train_loss = 2.71474641, grad/param norm = 3.8673e-01, time/batch = 0.7042s	
384/22750 (epoch 0.844), train_loss = 2.67825453, grad/param norm = 5.1429e-01, time/batch = 0.7211s	
385/22750 (epoch 0.846), train_loss = 2.42280952, grad/param norm = 5.2708e-01, time/batch = 0.7058s	
386/22750 (epoch 0.848), train_loss = 2.53263390, grad/param norm = 5.2739e-01, time/batch = 0.7022s	
387/22750 (epoch 0.851), train_loss = 2.48457237, grad/param norm = 5.8573e-01, time/batch = 0.7058s	
388/22750 (epoch 0.853), train_loss = 2.46800234, grad/param norm = 4.5924e-01, time/batch = 0.7066s	
389/22750 (epoch 0.855), train_loss = 2.48081004, grad/param norm = 3.4010e-01, time/batch = 0.7121s	
390/22750 (epoch 0.857), train_loss = 2.53758777, grad/param norm = 3.3514e-01, time/batch = 0.7014s	
391/22750 (epoch 0.859), train_loss = 2.61098696, grad/param norm = 3.0299e-01, time/batch = 0.6991s	
392/22750 (epoch 0.862), train_loss = 2.57617592, grad/param norm = 3.1221e-01, time/batch = 0.7025s	
393/22750 (epoch 0.864), train_loss = 2.77451829, grad/param norm = 3.8977e-01, time/batch = 0.7052s	
394/22750 (epoch 0.866), train_loss = 2.51825755, grad/param norm = 3.5166e-01, time/batch = 0.7027s	
395/22750 (epoch 0.868), train_loss = 2.75335819, grad/param norm = 4.6424e-01, time/batch = 0.7162s	
396/22750 (epoch 0.870), train_loss = 2.37699601, grad/param norm = 4.0374e-01, time/batch = 0.7275s	
397/22750 (epoch 0.873), train_loss = 2.59342617, grad/param norm = 4.4309e-01, time/batch = 0.7025s	
398/22750 (epoch 0.875), train_loss = 2.58337327, grad/param norm = 4.8009e-01, time/batch = 0.7032s	
399/22750 (epoch 0.877), train_loss = 2.63783105, grad/param norm = 6.6772e-01, time/batch = 0.7074s	
400/22750 (epoch 0.879), train_loss = 2.74617604, grad/param norm = 6.7110e-01, time/batch = 0.7152s	
401/22750 (epoch 0.881), train_loss = 2.58766929, grad/param norm = 6.0679e-01, time/batch = 0.7126s	
402/22750 (epoch 0.884), train_loss = 2.76003282, grad/param norm = 6.1043e-01, time/batch = 0.7094s	
403/22750 (epoch 0.886), train_loss = 2.64727184, grad/param norm = 7.2986e-01, time/batch = 0.7254s	
404/22750 (epoch 0.888), train_loss = 2.55779038, grad/param norm = 3.7543e-01, time/batch = 0.7275s	
405/22750 (epoch 0.890), train_loss = 2.74861447, grad/param norm = 4.2616e-01, time/batch = 0.7284s	
406/22750 (epoch 0.892), train_loss = 2.89195921, grad/param norm = 4.7662e-01, time/batch = 0.7326s	
407/22750 (epoch 0.895), train_loss = 2.83045108, grad/param norm = 4.9143e-01, time/batch = 0.7267s	
408/22750 (epoch 0.897), train_loss = 2.64756280, grad/param norm = 4.0730e-01, time/batch = 0.7204s	
409/22750 (epoch 0.899), train_loss = 2.75968373, grad/param norm = 3.6196e-01, time/batch = 0.7290s	
410/22750 (epoch 0.901), train_loss = 2.65717719, grad/param norm = 3.3531e-01, time/batch = 0.7158s	
411/22750 (epoch 0.903), train_loss = 2.69136336, grad/param norm = 5.1289e-01, time/batch = 0.7263s	
412/22750 (epoch 0.905), train_loss = 2.58999297, grad/param norm = 4.9329e-01, time/batch = 0.7200s	
413/22750 (epoch 0.908), train_loss = 2.50384777, grad/param norm = 3.6761e-01, time/batch = 0.7064s	
414/22750 (epoch 0.910), train_loss = 2.50546991, grad/param norm = 4.5979e-01, time/batch = 0.7189s	
415/22750 (epoch 0.912), train_loss = 2.39349410, grad/param norm = 3.9849e-01, time/batch = 0.7252s	
416/22750 (epoch 0.914), train_loss = 2.42157362, grad/param norm = 5.7355e-01, time/batch = 0.7240s	
417/22750 (epoch 0.916), train_loss = 2.36806986, grad/param norm = 4.1624e-01, time/batch = 0.7157s	
418/22750 (epoch 0.919), train_loss = 2.26809773, grad/param norm = 2.9527e-01, time/batch = 0.7116s	
419/22750 (epoch 0.921), train_loss = 2.32221091, grad/param norm = 3.2430e-01, time/batch = 0.7123s	
420/22750 (epoch 0.923), train_loss = 2.55299964, grad/param norm = 2.9738e-01, time/batch = 0.7054s	
421/22750 (epoch 0.925), train_loss = 2.51838526, grad/param norm = 3.7363e-01, time/batch = 0.7215s	
422/22750 (epoch 0.927), train_loss = 2.28111542, grad/param norm = 4.7024e-01, time/batch = 0.7149s	
423/22750 (epoch 0.930), train_loss = 2.41280573, grad/param norm = 5.0272e-01, time/batch = 0.7095s	
424/22750 (epoch 0.932), train_loss = 2.73604357, grad/param norm = 4.5893e-01, time/batch = 0.7032s	
425/22750 (epoch 0.934), train_loss = 2.37801961, grad/param norm = 4.1159e-01, time/batch = 0.7172s	
426/22750 (epoch 0.936), train_loss = 2.59973334, grad/param norm = 4.1116e-01, time/batch = 0.7212s	
427/22750 (epoch 0.938), train_loss = 2.60743974, grad/param norm = 5.0720e-01, time/batch = 0.7146s	
428/22750 (epoch 0.941), train_loss = 2.91930552, grad/param norm = 6.3279e-01, time/batch = 0.7082s	
429/22750 (epoch 0.943), train_loss = 2.61697801, grad/param norm = 6.4820e-01, time/batch = 0.7010s	
430/22750 (epoch 0.945), train_loss = 2.56083913, grad/param norm = 4.1854e-01, time/batch = 0.7053s	
431/22750 (epoch 0.947), train_loss = 2.58042926, grad/param norm = 3.8012e-01, time/batch = 0.7034s	
432/22750 (epoch 0.949), train_loss = 2.46784954, grad/param norm = 3.3002e-01, time/batch = 0.7045s	
433/22750 (epoch 0.952), train_loss = 2.46222420, grad/param norm = 3.1393e-01, time/batch = 0.7015s	
434/22750 (epoch 0.954), train_loss = 2.40104622, grad/param norm = 2.8438e-01, time/batch = 0.7313s	
435/22750 (epoch 0.956), train_loss = 2.48043687, grad/param norm = 3.1836e-01, time/batch = 0.7093s	
436/22750 (epoch 0.958), train_loss = 2.54601055, grad/param norm = 3.7826e-01, time/batch = 0.7040s	
437/22750 (epoch 0.960), train_loss = 2.51901392, grad/param norm = 4.5123e-01, time/batch = 0.7099s	
438/22750 (epoch 0.963), train_loss = 2.41051399, grad/param norm = 3.9958e-01, time/batch = 0.7130s	
439/22750 (epoch 0.965), train_loss = 2.46983157, grad/param norm = 3.5521e-01, time/batch = 0.7172s	
440/22750 (epoch 0.967), train_loss = 2.54998122, grad/param norm = 3.5792e-01, time/batch = 0.7072s	
441/22750 (epoch 0.969), train_loss = 2.43559333, grad/param norm = 3.3318e-01, time/batch = 0.7125s	
442/22750 (epoch 0.971), train_loss = 2.44208855, grad/param norm = 2.6206e-01, time/batch = 0.7122s	
443/22750 (epoch 0.974), train_loss = 2.43003344, grad/param norm = 2.7115e-01, time/batch = 0.7029s	
444/22750 (epoch 0.976), train_loss = 2.53893578, grad/param norm = 3.3710e-01, time/batch = 0.6996s	
445/22750 (epoch 0.978), train_loss = 2.40782002, grad/param norm = 4.2263e-01, time/batch = 0.7066s	
446/22750 (epoch 0.980), train_loss = 2.44808774, grad/param norm = 3.7305e-01, time/batch = 0.7066s	
447/22750 (epoch 0.982), train_loss = 2.52552726, grad/param norm = 5.0977e-01, time/batch = 0.6953s	
448/22750 (epoch 0.985), train_loss = 2.78228811, grad/param norm = 6.1514e-01, time/batch = 0.7040s	
449/22750 (epoch 0.987), train_loss = 2.43474994, grad/param norm = 3.3846e-01, time/batch = 0.7015s	
450/22750 (epoch 0.989), train_loss = 2.42259185, grad/param norm = 3.0386e-01, time/batch = 0.7078s	
451/22750 (epoch 0.991), train_loss = 2.53450114, grad/param norm = 3.5352e-01, time/batch = 0.7029s	
452/22750 (epoch 0.993), train_loss = 2.52277922, grad/param norm = 3.7924e-01, time/batch = 0.6993s	
453/22750 (epoch 0.996), train_loss = 2.41115180, grad/param norm = 3.2106e-01, time/batch = 0.7014s	
454/22750 (epoch 0.998), train_loss = 2.64058450, grad/param norm = 3.7250e-01, time/batch = 0.6997s	
455/22750 (epoch 1.000), train_loss = 2.72905672, grad/param norm = 5.6194e-01, time/batch = 0.7046s	
456/22750 (epoch 1.002), train_loss = 2.68908361, grad/param norm = 7.3928e-01, time/batch = 0.7028s	
457/22750 (epoch 1.004), train_loss = 2.71269274, grad/param norm = 5.2376e-01, time/batch = 0.6997s	
458/22750 (epoch 1.007), train_loss = 2.68483883, grad/param norm = 5.4992e-01, time/batch = 0.6968s	
459/22750 (epoch 1.009), train_loss = 2.84775941, grad/param norm = 4.7196e-01, time/batch = 0.6982s	
460/22750 (epoch 1.011), train_loss = 2.56192291, grad/param norm = 4.1209e-01, time/batch = 0.6928s	
461/22750 (epoch 1.013), train_loss = 2.60281163, grad/param norm = 4.3236e-01, time/batch = 0.7001s	
462/22750 (epoch 1.015), train_loss = 2.47983022, grad/param norm = 3.1190e-01, time/batch = 0.7007s	
463/22750 (epoch 1.018), train_loss = 2.44863032, grad/param norm = 2.8921e-01, time/batch = 0.6986s	
464/22750 (epoch 1.020), train_loss = 2.57256424, grad/param norm = 3.7115e-01, time/batch = 0.7001s	
465/22750 (epoch 1.022), train_loss = 2.46441591, grad/param norm = 3.4689e-01, time/batch = 0.7004s	
466/22750 (epoch 1.024), train_loss = 2.36929892, grad/param norm = 2.9804e-01, time/batch = 0.6974s	
467/22750 (epoch 1.026), train_loss = 2.65585429, grad/param norm = 4.3295e-01, time/batch = 0.6980s	
468/22750 (epoch 1.029), train_loss = 2.35211864, grad/param norm = 4.7271e-01, time/batch = 0.7046s	
469/22750 (epoch 1.031), train_loss = 2.77693542, grad/param norm = 4.4765e-01, time/batch = 0.7136s	
470/22750 (epoch 1.033), train_loss = 2.62649339, grad/param norm = 3.3937e-01, time/batch = 0.7007s	
471/22750 (epoch 1.035), train_loss = 2.61134840, grad/param norm = 3.2533e-01, time/batch = 0.6998s	
472/22750 (epoch 1.037), train_loss = 2.74913941, grad/param norm = 3.4757e-01, time/batch = 0.6992s	
473/22750 (epoch 1.040), train_loss = 2.51404783, grad/param norm = 3.6368e-01, time/batch = 0.6957s	
474/22750 (epoch 1.042), train_loss = 2.58157378, grad/param norm = 3.3771e-01, time/batch = 0.6955s	
475/22750 (epoch 1.044), train_loss = 2.44550512, grad/param norm = 3.6103e-01, time/batch = 0.6983s	
476/22750 (epoch 1.046), train_loss = 2.44254641, grad/param norm = 4.1929e-01, time/batch = 0.7010s	
477/22750 (epoch 1.048), train_loss = 2.59222864, grad/param norm = 4.2127e-01, time/batch = 0.7005s	
478/22750 (epoch 1.051), train_loss = 2.64011702, grad/param norm = 3.3541e-01, time/batch = 0.6950s	
479/22750 (epoch 1.053), train_loss = 2.37250103, grad/param norm = 2.8420e-01, time/batch = 0.6949s	
480/22750 (epoch 1.055), train_loss = 2.60961121, grad/param norm = 4.3545e-01, time/batch = 0.6938s	
481/22750 (epoch 1.057), train_loss = 2.49433367, grad/param norm = 5.2775e-01, time/batch = 0.7011s	
482/22750 (epoch 1.059), train_loss = 2.42927880, grad/param norm = 5.4603e-01, time/batch = 0.6989s	
483/22750 (epoch 1.062), train_loss = 2.40299835, grad/param norm = 4.1826e-01, time/batch = 0.6962s	
484/22750 (epoch 1.064), train_loss = 2.45577331, grad/param norm = 3.4290e-01, time/batch = 0.7001s	
485/22750 (epoch 1.066), train_loss = 2.19464882, grad/param norm = 2.8555e-01, time/batch = 0.7104s	
486/22750 (epoch 1.068), train_loss = 2.31942265, grad/param norm = 2.7096e-01, time/batch = 0.6956s	
487/22750 (epoch 1.070), train_loss = 2.14516099, grad/param norm = 3.4143e-01, time/batch = 0.6974s	
488/22750 (epoch 1.073), train_loss = 2.34323377, grad/param norm = 3.5479e-01, time/batch = 0.6975s	
489/22750 (epoch 1.075), train_loss = 2.44092524, grad/param norm = 3.0668e-01, time/batch = 0.7121s	
490/22750 (epoch 1.077), train_loss = 2.24088982, grad/param norm = 3.6209e-01, time/batch = 0.7212s	
491/22750 (epoch 1.079), train_loss = 2.29450100, grad/param norm = 3.8231e-01, time/batch = 0.7264s	
492/22750 (epoch 1.081), train_loss = 2.45719116, grad/param norm = 4.9716e-01, time/batch = 0.7203s	
493/22750 (epoch 1.084), train_loss = 2.39592011, grad/param norm = 3.8988e-01, time/batch = 0.7153s	
494/22750 (epoch 1.086), train_loss = 2.43909825, grad/param norm = 3.6294e-01, time/batch = 0.7134s	
495/22750 (epoch 1.088), train_loss = 2.40916015, grad/param norm = 4.0882e-01, time/batch = 0.6883s	
496/22750 (epoch 1.090), train_loss = 2.48987418, grad/param norm = 4.0554e-01, time/batch = 0.7004s	
497/22750 (epoch 1.092), train_loss = 2.58443070, grad/param norm = 3.5140e-01, time/batch = 0.6961s	
498/22750 (epoch 1.095), train_loss = 2.42260607, grad/param norm = 3.7525e-01, time/batch = 0.6963s	
499/22750 (epoch 1.097), train_loss = 2.45881361, grad/param norm = 3.1622e-01, time/batch = 0.7231s	
500/22750 (epoch 1.099), train_loss = 2.65393966, grad/param norm = 5.2049e-01, time/batch = 0.7247s	
501/22750 (epoch 1.101), train_loss = 2.58195351, grad/param norm = 6.5106e-01, time/batch = 0.7049s	
502/22750 (epoch 1.103), train_loss = 2.31845883, grad/param norm = 3.7598e-01, time/batch = 0.7028s	
503/22750 (epoch 1.105), train_loss = 2.56348686, grad/param norm = 3.8847e-01, time/batch = 0.7049s	
504/22750 (epoch 1.108), train_loss = 2.41490945, grad/param norm = 4.0417e-01, time/batch = 0.7057s	
505/22750 (epoch 1.110), train_loss = 2.43810659, grad/param norm = 4.5398e-01, time/batch = 0.7020s	
506/22750 (epoch 1.112), train_loss = 2.30089189, grad/param norm = 3.6090e-01, time/batch = 0.7036s	
507/22750 (epoch 1.114), train_loss = 2.16467700, grad/param norm = 2.8056e-01, time/batch = 0.6980s	
508/22750 (epoch 1.116), train_loss = 2.26910651, grad/param norm = 2.9009e-01, time/batch = 0.7163s	
509/22750 (epoch 1.119), train_loss = 2.40943135, grad/param norm = 3.1607e-01, time/batch = 0.7049s	
510/22750 (epoch 1.121), train_loss = 2.48908972, grad/param norm = 3.1635e-01, time/batch = 0.6999s	
511/22750 (epoch 1.123), train_loss = 2.30947239, grad/param norm = 2.7949e-01, time/batch = 0.7187s	
512/22750 (epoch 1.125), train_loss = 2.48482875, grad/param norm = 2.7879e-01, time/batch = 0.7113s	
513/22750 (epoch 1.127), train_loss = 2.42472766, grad/param norm = 2.8771e-01, time/batch = 0.7152s	
514/22750 (epoch 1.130), train_loss = 2.51150775, grad/param norm = 3.0403e-01, time/batch = 0.6982s	
515/22750 (epoch 1.132), train_loss = 2.35783472, grad/param norm = 3.4791e-01, time/batch = 0.7090s	
516/22750 (epoch 1.134), train_loss = 2.43464688, grad/param norm = 4.2277e-01, time/batch = 0.6972s	
517/22750 (epoch 1.136), train_loss = 2.33846747, grad/param norm = 3.3398e-01, time/batch = 0.6957s	
518/22750 (epoch 1.138), train_loss = 2.39196017, grad/param norm = 4.4573e-01, time/batch = 0.6980s	
519/22750 (epoch 1.141), train_loss = 2.41878893, grad/param norm = 4.0839e-01, time/batch = 0.7133s	
520/22750 (epoch 1.143), train_loss = 2.37624070, grad/param norm = 3.1356e-01, time/batch = 0.7156s	
521/22750 (epoch 1.145), train_loss = 2.51486100, grad/param norm = 3.6680e-01, time/batch = 0.7038s	
522/22750 (epoch 1.147), train_loss = 2.42646989, grad/param norm = 3.5715e-01, time/batch = 0.6982s	
523/22750 (epoch 1.149), train_loss = 2.45392111, grad/param norm = 4.5261e-01, time/batch = 0.6999s	
524/22750 (epoch 1.152), train_loss = 2.52999849, grad/param norm = 5.5303e-01, time/batch = 0.6978s	
525/22750 (epoch 1.154), train_loss = 2.43461450, grad/param norm = 4.4788e-01, time/batch = 0.6972s	
526/22750 (epoch 1.156), train_loss = 2.43952160, grad/param norm = 3.1598e-01, time/batch = 0.7013s	
527/22750 (epoch 1.158), train_loss = 2.48613113, grad/param norm = 2.7842e-01, time/batch = 0.7028s	
528/22750 (epoch 1.160), train_loss = 2.42716156, grad/param norm = 3.1282e-01, time/batch = 0.7200s	
529/22750 (epoch 1.163), train_loss = 2.54014097, grad/param norm = 3.0186e-01, time/batch = 0.7094s	
530/22750 (epoch 1.165), train_loss = 2.45081457, grad/param norm = 3.2333e-01, time/batch = 0.7059s	
531/22750 (epoch 1.167), train_loss = 2.27661622, grad/param norm = 3.1244e-01, time/batch = 0.7069s	
532/22750 (epoch 1.169), train_loss = 2.34248300, grad/param norm = 3.3561e-01, time/batch = 0.7028s	
533/22750 (epoch 1.171), train_loss = 2.34060220, grad/param norm = 2.9155e-01, time/batch = 0.6995s	
534/22750 (epoch 1.174), train_loss = 2.21282682, grad/param norm = 2.7816e-01, time/batch = 0.7010s	
535/22750 (epoch 1.176), train_loss = 2.33871721, grad/param norm = 3.2840e-01, time/batch = 0.7000s	
536/22750 (epoch 1.178), train_loss = 2.38380777, grad/param norm = 3.6023e-01, time/batch = 0.6988s	
537/22750 (epoch 1.180), train_loss = 2.47021532, grad/param norm = 3.8306e-01, time/batch = 0.7004s	
538/22750 (epoch 1.182), train_loss = 2.46525445, grad/param norm = 3.2665e-01, time/batch = 0.7121s	
539/22750 (epoch 1.185), train_loss = 2.35616329, grad/param norm = 2.8935e-01, time/batch = 0.7059s	
540/22750 (epoch 1.187), train_loss = 2.32067721, grad/param norm = 3.1239e-01, time/batch = 0.6989s	
541/22750 (epoch 1.189), train_loss = 2.33150281, grad/param norm = 3.1651e-01, time/batch = 0.7025s	
542/22750 (epoch 1.191), train_loss = 2.28513279, grad/param norm = 3.9260e-01, time/batch = 0.6981s	
543/22750 (epoch 1.193), train_loss = 2.35020709, grad/param norm = 3.4842e-01, time/batch = 0.6971s	
544/22750 (epoch 1.196), train_loss = 2.51331618, grad/param norm = 3.2736e-01, time/batch = 0.7030s	
545/22750 (epoch 1.198), train_loss = 2.29260777, grad/param norm = 2.6054e-01, time/batch = 0.7034s	
546/22750 (epoch 1.200), train_loss = 2.43264162, grad/param norm = 2.7105e-01, time/batch = 0.7054s	
547/22750 (epoch 1.202), train_loss = 2.69069721, grad/param norm = 3.0082e-01, time/batch = 0.7046s	
548/22750 (epoch 1.204), train_loss = 2.61710691, grad/param norm = 3.4055e-01, time/batch = 0.7051s	
549/22750 (epoch 1.207), train_loss = 2.28588993, grad/param norm = 3.5207e-01, time/batch = 0.7009s	
550/22750 (epoch 1.209), train_loss = 2.41464917, grad/param norm = 3.2130e-01, time/batch = 0.7008s	
551/22750 (epoch 1.211), train_loss = 2.36584436, grad/param norm = 4.1148e-01, time/batch = 0.7022s	
552/22750 (epoch 1.213), train_loss = 2.37230455, grad/param norm = 5.6805e-01, time/batch = 0.7054s	
553/22750 (epoch 1.215), train_loss = 2.43925822, grad/param norm = 5.5786e-01, time/batch = 0.6987s	
554/22750 (epoch 1.218), train_loss = 2.17315097, grad/param norm = 4.7426e-01, time/batch = 0.7024s	
555/22750 (epoch 1.220), train_loss = 2.44870381, grad/param norm = 3.6804e-01, time/batch = 0.7076s	
556/22750 (epoch 1.222), train_loss = 2.24580065, grad/param norm = 3.3865e-01, time/batch = 0.7033s	
557/22750 (epoch 1.224), train_loss = 2.46823322, grad/param norm = 3.5416e-01, time/batch = 0.7075s	
558/22750 (epoch 1.226), train_loss = 2.34521933, grad/param norm = 3.1226e-01, time/batch = 0.7036s	
559/22750 (epoch 1.229), train_loss = 2.51885451, grad/param norm = 3.0732e-01, time/batch = 0.7001s	
560/22750 (epoch 1.231), train_loss = 2.44757203, grad/param norm = 2.9448e-01, time/batch = 0.7045s	
561/22750 (epoch 1.233), train_loss = 2.43866759, grad/param norm = 3.0871e-01, time/batch = 0.7068s	
562/22750 (epoch 1.235), train_loss = 2.24779148, grad/param norm = 3.1090e-01, time/batch = 0.7109s	
563/22750 (epoch 1.237), train_loss = 2.41428254, grad/param norm = 4.0813e-01, time/batch = 0.6972s	
564/22750 (epoch 1.240), train_loss = 2.66326214, grad/param norm = 5.2929e-01, time/batch = 0.7024s	
565/22750 (epoch 1.242), train_loss = 2.72852205, grad/param norm = 6.4751e-01, time/batch = 0.6987s	
566/22750 (epoch 1.244), train_loss = 2.56958079, grad/param norm = 7.1410e-01, time/batch = 0.7073s	
567/22750 (epoch 1.246), train_loss = 2.73251817, grad/param norm = 4.2674e-01, time/batch = 0.7146s	
568/22750 (epoch 1.248), train_loss = 2.25283312, grad/param norm = 3.5701e-01, time/batch = 0.7014s	
569/22750 (epoch 1.251), train_loss = 2.55692723, grad/param norm = 3.6741e-01, time/batch = 0.6991s	
570/22750 (epoch 1.253), train_loss = 2.39010359, grad/param norm = 2.5177e-01, time/batch = 0.7192s	
571/22750 (epoch 1.255), train_loss = 2.56410603, grad/param norm = 2.8924e-01, time/batch = 0.7064s	
572/22750 (epoch 1.257), train_loss = 2.41998412, grad/param norm = 3.7806e-01, time/batch = 0.7025s	
573/22750 (epoch 1.259), train_loss = 2.40611076, grad/param norm = 3.0584e-01, time/batch = 0.7189s	
574/22750 (epoch 1.262), train_loss = 2.34366683, grad/param norm = 3.5298e-01, time/batch = 0.7164s	
575/22750 (epoch 1.264), train_loss = 2.48524503, grad/param norm = 2.9470e-01, time/batch = 0.7090s	
576/22750 (epoch 1.266), train_loss = 2.21979074, grad/param norm = 3.3372e-01, time/batch = 0.7112s	
577/22750 (epoch 1.268), train_loss = 2.38280207, grad/param norm = 2.6569e-01, time/batch = 0.7032s	
578/22750 (epoch 1.270), train_loss = 2.22724426, grad/param norm = 3.0647e-01, time/batch = 0.7108s	
579/22750 (epoch 1.273), train_loss = 2.41469421, grad/param norm = 3.9877e-01, time/batch = 0.7072s	
580/22750 (epoch 1.275), train_loss = 2.31117222, grad/param norm = 3.0577e-01, time/batch = 0.7020s	
581/22750 (epoch 1.277), train_loss = 2.44893959, grad/param norm = 3.1781e-01, time/batch = 0.7080s	
582/22750 (epoch 1.279), train_loss = 2.19515658, grad/param norm = 3.0513e-01, time/batch = 0.7078s	
583/22750 (epoch 1.281), train_loss = 2.28920417, grad/param norm = 2.9229e-01, time/batch = 0.7103s	
584/22750 (epoch 1.284), train_loss = 2.24247792, grad/param norm = 2.9780e-01, time/batch = 0.7237s	
585/22750 (epoch 1.286), train_loss = 2.33510183, grad/param norm = 3.2911e-01, time/batch = 0.7126s	
586/22750 (epoch 1.288), train_loss = 2.44715750, grad/param norm = 3.1230e-01, time/batch = 0.7220s	
587/22750 (epoch 1.290), train_loss = 2.22843727, grad/param norm = 3.0326e-01, time/batch = 0.7044s	
588/22750 (epoch 1.292), train_loss = 2.29143059, grad/param norm = 2.6282e-01, time/batch = 0.7184s	
589/22750 (epoch 1.295), train_loss = 2.37876864, grad/param norm = 3.0398e-01, time/batch = 0.7039s	
590/22750 (epoch 1.297), train_loss = 2.25703349, grad/param norm = 3.2271e-01, time/batch = 0.7007s	
591/22750 (epoch 1.299), train_loss = 2.45977988, grad/param norm = 3.3300e-01, time/batch = 0.7078s	
592/22750 (epoch 1.301), train_loss = 2.42670308, grad/param norm = 3.3488e-01, time/batch = 0.7035s	
593/22750 (epoch 1.303), train_loss = 2.47764561, grad/param norm = 3.6539e-01, time/batch = 0.7067s	
594/22750 (epoch 1.305), train_loss = 2.49211324, grad/param norm = 3.2605e-01, time/batch = 0.7149s	
595/22750 (epoch 1.308), train_loss = 2.35699259, grad/param norm = 3.1853e-01, time/batch = 0.7069s	
596/22750 (epoch 1.310), train_loss = 2.22602530, grad/param norm = 3.1371e-01, time/batch = 0.7059s	
597/22750 (epoch 1.312), train_loss = 2.30943656, grad/param norm = 3.1718e-01, time/batch = 0.7023s	
598/22750 (epoch 1.314), train_loss = 2.40214096, grad/param norm = 3.1592e-01, time/batch = 0.7124s	
599/22750 (epoch 1.316), train_loss = 2.34034754, grad/param norm = 3.1360e-01, time/batch = 0.7110s	
600/22750 (epoch 1.319), train_loss = 2.41481985, grad/param norm = 3.2034e-01, time/batch = 0.6954s	
601/22750 (epoch 1.321), train_loss = 2.32074758, grad/param norm = 3.5724e-01, time/batch = 0.7053s	
602/22750 (epoch 1.323), train_loss = 2.10464902, grad/param norm = 3.1975e-01, time/batch = 0.7013s	
603/22750 (epoch 1.325), train_loss = 2.16104684, grad/param norm = 2.6179e-01, time/batch = 0.7088s	
604/22750 (epoch 1.327), train_loss = 2.63481694, grad/param norm = 3.6293e-01, time/batch = 0.7124s	
605/22750 (epoch 1.330), train_loss = 2.59291167, grad/param norm = 3.5652e-01, time/batch = 0.7029s	
606/22750 (epoch 1.332), train_loss = 2.34273783, grad/param norm = 3.2879e-01, time/batch = 0.7043s	
607/22750 (epoch 1.334), train_loss = 2.26104010, grad/param norm = 3.2157e-01, time/batch = 0.7047s	
608/22750 (epoch 1.336), train_loss = 2.36135205, grad/param norm = 3.2831e-01, time/batch = 0.6972s	
609/22750 (epoch 1.338), train_loss = 2.52382123, grad/param norm = 4.8172e-01, time/batch = 0.7082s	
610/22750 (epoch 1.341), train_loss = 2.38796064, grad/param norm = 3.5904e-01, time/batch = 0.7044s	
611/22750 (epoch 1.343), train_loss = 2.23438591, grad/param norm = 2.7169e-01, time/batch = 0.7100s	
612/22750 (epoch 1.345), train_loss = 2.57328630, grad/param norm = 3.1204e-01, time/batch = 0.7210s	
613/22750 (epoch 1.347), train_loss = 2.51495588, grad/param norm = 3.0985e-01, time/batch = 0.7148s	
614/22750 (epoch 1.349), train_loss = 2.09295929, grad/param norm = 3.6901e-01, time/batch = 0.7092s	
615/22750 (epoch 1.352), train_loss = 2.40332064, grad/param norm = 3.8148e-01, time/batch = 0.7111s	
616/22750 (epoch 1.354), train_loss = 2.42219302, grad/param norm = 3.1462e-01, time/batch = 0.7112s	
617/22750 (epoch 1.356), train_loss = 2.47151232, grad/param norm = 3.2169e-01, time/batch = 0.7096s	
618/22750 (epoch 1.358), train_loss = 2.21497295, grad/param norm = 3.1223e-01, time/batch = 0.7097s	
619/22750 (epoch 1.360), train_loss = 2.57679502, grad/param norm = 3.1626e-01, time/batch = 0.7119s	
620/22750 (epoch 1.363), train_loss = 2.44469810, grad/param norm = 2.7227e-01, time/batch = 0.6950s	
621/22750 (epoch 1.365), train_loss = 2.01899561, grad/param norm = 3.0720e-01, time/batch = 0.7063s	
622/22750 (epoch 1.367), train_loss = 1.92683107, grad/param norm = 2.9027e-01, time/batch = 0.7075s	
623/22750 (epoch 1.369), train_loss = 2.22325648, grad/param norm = 2.8728e-01, time/batch = 0.7072s	
624/22750 (epoch 1.371), train_loss = 2.25025709, grad/param norm = 3.5077e-01, time/batch = 0.7039s	
625/22750 (epoch 1.374), train_loss = 2.12113089, grad/param norm = 4.1565e-01, time/batch = 0.7105s	
626/22750 (epoch 1.376), train_loss = 2.43965587, grad/param norm = 3.7346e-01, time/batch = 0.7122s	
627/22750 (epoch 1.378), train_loss = 2.23023883, grad/param norm = 3.4195e-01, time/batch = 0.7026s	
628/22750 (epoch 1.380), train_loss = 2.47314713, grad/param norm = 3.5957e-01, time/batch = 0.7040s	
629/22750 (epoch 1.382), train_loss = 2.23078397, grad/param norm = 3.6747e-01, time/batch = 0.7022s	
630/22750 (epoch 1.385), train_loss = 2.33585295, grad/param norm = 4.1246e-01, time/batch = 0.7342s	
631/22750 (epoch 1.387), train_loss = 2.43091183, grad/param norm = 3.8937e-01, time/batch = 0.7262s	
632/22750 (epoch 1.389), train_loss = 2.05396594, grad/param norm = 3.4394e-01, time/batch = 0.7208s	
633/22750 (epoch 1.391), train_loss = 2.00235437, grad/param norm = 3.9663e-01, time/batch = 0.7061s	
634/22750 (epoch 1.393), train_loss = 2.25272047, grad/param norm = 4.1181e-01, time/batch = 0.7143s	
635/22750 (epoch 1.396), train_loss = 2.36007999, grad/param norm = 3.3621e-01, time/batch = 0.7059s	
636/22750 (epoch 1.398), train_loss = 2.26950190, grad/param norm = 4.2681e-01, time/batch = 0.7068s	
637/22750 (epoch 1.400), train_loss = 2.30496261, grad/param norm = 4.2285e-01, time/batch = 0.7080s	
638/22750 (epoch 1.402), train_loss = 2.32701957, grad/param norm = 3.6587e-01, time/batch = 0.6988s	
639/22750 (epoch 1.404), train_loss = 2.42724383, grad/param norm = 3.1221e-01, time/batch = 0.7003s	
640/22750 (epoch 1.407), train_loss = 2.32522905, grad/param norm = 2.9318e-01, time/batch = 0.7035s	
641/22750 (epoch 1.409), train_loss = 2.34675037, grad/param norm = 3.0195e-01, time/batch = 0.7020s	
642/22750 (epoch 1.411), train_loss = 2.33001320, grad/param norm = 2.8813e-01, time/batch = 0.6946s	
643/22750 (epoch 1.413), train_loss = 2.29983189, grad/param norm = 3.1425e-01, time/batch = 0.7038s	
644/22750 (epoch 1.415), train_loss = 2.15076772, grad/param norm = 3.3253e-01, time/batch = 0.7016s	
645/22750 (epoch 1.418), train_loss = 2.05046400, grad/param norm = 2.7122e-01, time/batch = 0.7020s	
646/22750 (epoch 1.420), train_loss = 2.42116803, grad/param norm = 3.0048e-01, time/batch = 0.7063s	
647/22750 (epoch 1.422), train_loss = 2.60587923, grad/param norm = 3.1677e-01, time/batch = 0.7045s	
648/22750 (epoch 1.424), train_loss = 2.61489076, grad/param norm = 3.2905e-01, time/batch = 0.7005s	
649/22750 (epoch 1.426), train_loss = 2.53962036, grad/param norm = 2.8926e-01, time/batch = 0.7011s	
650/22750 (epoch 1.429), train_loss = 2.06612209, grad/param norm = 3.2295e-01, time/batch = 0.7042s	
651/22750 (epoch 1.431), train_loss = 2.18151622, grad/param norm = 3.8936e-01, time/batch = 0.7085s	
652/22750 (epoch 1.433), train_loss = 2.18482491, grad/param norm = 3.6535e-01, time/batch = 0.7008s	
653/22750 (epoch 1.435), train_loss = 2.21454324, grad/param norm = 3.9982e-01, time/batch = 0.7018s	
654/22750 (epoch 1.437), train_loss = 2.15745212, grad/param norm = 2.7351e-01, time/batch = 0.7094s	
655/22750 (epoch 1.440), train_loss = 2.56122546, grad/param norm = 3.1495e-01, time/batch = 0.7147s	
656/22750 (epoch 1.442), train_loss = 2.38173425, grad/param norm = 3.7865e-01, time/batch = 0.7089s	
657/22750 (epoch 1.444), train_loss = 2.59354583, grad/param norm = 5.8074e-01, time/batch = 0.7120s	
658/22750 (epoch 1.446), train_loss = 2.44096139, grad/param norm = 4.6088e-01, time/batch = 0.7113s	
659/22750 (epoch 1.448), train_loss = 2.55988160, grad/param norm = 3.1396e-01, time/batch = 0.7090s	
660/22750 (epoch 1.451), train_loss = 2.44415180, grad/param norm = 3.2325e-01, time/batch = 0.7068s	
661/22750 (epoch 1.453), train_loss = 2.58388058, grad/param norm = 4.8629e-01, time/batch = 0.7158s	
662/22750 (epoch 1.455), train_loss = 2.52924764, grad/param norm = 3.9191e-01, time/batch = 0.7026s	
663/22750 (epoch 1.457), train_loss = 2.52924108, grad/param norm = 3.1735e-01, time/batch = 0.7040s	
664/22750 (epoch 1.459), train_loss = 2.38103986, grad/param norm = 2.9842e-01, time/batch = 0.6999s	
665/22750 (epoch 1.462), train_loss = 2.25097992, grad/param norm = 2.4508e-01, time/batch = 0.7065s	
666/22750 (epoch 1.464), train_loss = 2.12210531, grad/param norm = 2.6898e-01, time/batch = 0.7075s	
667/22750 (epoch 1.466), train_loss = 2.40856533, grad/param norm = 2.5930e-01, time/batch = 0.7196s	
668/22750 (epoch 1.468), train_loss = 2.25430413, grad/param norm = 3.2110e-01, time/batch = 0.7257s	
669/22750 (epoch 1.470), train_loss = 2.36338078, grad/param norm = 3.0040e-01, time/batch = 0.7227s	
670/22750 (epoch 1.473), train_loss = 2.34224147, grad/param norm = 2.6463e-01, time/batch = 0.7144s	
671/22750 (epoch 1.475), train_loss = 2.44157542, grad/param norm = 2.6501e-01, time/batch = 0.7124s	
672/22750 (epoch 1.477), train_loss = 2.17622841, grad/param norm = 2.9311e-01, time/batch = 0.7072s	
673/22750 (epoch 1.479), train_loss = 2.28992953, grad/param norm = 2.9086e-01, time/batch = 0.7038s	
674/22750 (epoch 1.481), train_loss = 2.19214446, grad/param norm = 3.2659e-01, time/batch = 0.7125s	
675/22750 (epoch 1.484), train_loss = 2.07126627, grad/param norm = 3.3361e-01, time/batch = 0.7050s	
676/22750 (epoch 1.486), train_loss = 2.28865242, grad/param norm = 3.6263e-01, time/batch = 0.7091s	
677/22750 (epoch 1.488), train_loss = 1.95283486, grad/param norm = 4.1779e-01, time/batch = 0.7171s	
678/22750 (epoch 1.490), train_loss = 2.17251210, grad/param norm = 3.1981e-01, time/batch = 0.7149s	
679/22750 (epoch 1.492), train_loss = 2.37589642, grad/param norm = 3.6628e-01, time/batch = 0.7080s	
680/22750 (epoch 1.495), train_loss = 2.23143992, grad/param norm = 3.4913e-01, time/batch = 0.7001s	
681/22750 (epoch 1.497), train_loss = 2.31916487, grad/param norm = 2.9284e-01, time/batch = 0.7096s	
682/22750 (epoch 1.499), train_loss = 2.24292033, grad/param norm = 2.7358e-01, time/batch = 0.7118s	
683/22750 (epoch 1.501), train_loss = 2.18572251, grad/param norm = 2.7324e-01, time/batch = 0.7276s	
684/22750 (epoch 1.503), train_loss = 2.34426633, grad/param norm = 2.8868e-01, time/batch = 0.7270s	
685/22750 (epoch 1.505), train_loss = 2.15414357, grad/param norm = 3.0928e-01, time/batch = 0.7191s	
686/22750 (epoch 1.508), train_loss = 2.08193445, grad/param norm = 3.0133e-01, time/batch = 0.7132s	
687/22750 (epoch 1.510), train_loss = 2.20089593, grad/param norm = 2.9005e-01, time/batch = 0.7082s	
688/22750 (epoch 1.512), train_loss = 2.12976273, grad/param norm = 2.7082e-01, time/batch = 0.7049s	
689/22750 (epoch 1.514), train_loss = 2.33543086, grad/param norm = 3.7121e-01, time/batch = 0.7001s	
690/22750 (epoch 1.516), train_loss = 2.10523583, grad/param norm = 3.3049e-01, time/batch = 0.7026s	
691/22750 (epoch 1.519), train_loss = 2.32990440, grad/param norm = 3.4910e-01, time/batch = 0.7081s	
692/22750 (epoch 1.521), train_loss = 2.14292624, grad/param norm = 3.1586e-01, time/batch = 0.7036s	
693/22750 (epoch 1.523), train_loss = 2.13955393, grad/param norm = 3.2005e-01, time/batch = 0.7052s	
694/22750 (epoch 1.525), train_loss = 2.37490743, grad/param norm = 3.1730e-01, time/batch = 0.7062s	
695/22750 (epoch 1.527), train_loss = 2.22564453, grad/param norm = 2.9754e-01, time/batch = 0.7085s	
696/22750 (epoch 1.530), train_loss = 2.22185398, grad/param norm = 4.3666e-01, time/batch = 0.7070s	
697/22750 (epoch 1.532), train_loss = 2.29810962, grad/param norm = 4.4119e-01, time/batch = 0.7058s	
698/22750 (epoch 1.534), train_loss = 2.36519200, grad/param norm = 3.7715e-01, time/batch = 0.7017s	
699/22750 (epoch 1.536), train_loss = 2.33298994, grad/param norm = 3.3218e-01, time/batch = 0.7047s	
700/22750 (epoch 1.538), train_loss = 2.44546087, grad/param norm = 3.0822e-01, time/batch = 0.7080s	
701/22750 (epoch 1.541), train_loss = 1.97181740, grad/param norm = 2.8705e-01, time/batch = 0.7035s	
702/22750 (epoch 1.543), train_loss = 1.95799810, grad/param norm = 2.3157e-01, time/batch = 0.7133s	
703/22750 (epoch 1.545), train_loss = 2.37354802, grad/param norm = 3.0636e-01, time/batch = 0.7231s	
704/22750 (epoch 1.547), train_loss = 2.12469376, grad/param norm = 2.5353e-01, time/batch = 0.7062s	
705/22750 (epoch 1.549), train_loss = 2.06854727, grad/param norm = 2.7856e-01, time/batch = 0.7149s	
706/22750 (epoch 1.552), train_loss = 2.32144913, grad/param norm = 2.9479e-01, time/batch = 0.7108s	
707/22750 (epoch 1.554), train_loss = 2.25647649, grad/param norm = 2.9051e-01, time/batch = 0.6984s	
708/22750 (epoch 1.556), train_loss = 2.28946944, grad/param norm = 3.5443e-01, time/batch = 0.6942s	
709/22750 (epoch 1.558), train_loss = 2.44510410, grad/param norm = 3.7047e-01, time/batch = 0.6927s	
710/22750 (epoch 1.560), train_loss = 2.25224821, grad/param norm = 3.2524e-01, time/batch = 0.7044s	
711/22750 (epoch 1.563), train_loss = 2.31485085, grad/param norm = 3.3447e-01, time/batch = 0.7102s	
712/22750 (epoch 1.565), train_loss = 2.49447732, grad/param norm = 2.8887e-01, time/batch = 0.6847s	
713/22750 (epoch 1.567), train_loss = 2.20862672, grad/param norm = 3.1712e-01, time/batch = 0.6840s	
714/22750 (epoch 1.569), train_loss = 2.29145807, grad/param norm = 3.7147e-01, time/batch = 0.6837s	
715/22750 (epoch 1.571), train_loss = 2.27945171, grad/param norm = 3.4013e-01, time/batch = 0.6853s	
716/22750 (epoch 1.574), train_loss = 2.10160142, grad/param norm = 3.4837e-01, time/batch = 0.6850s	
717/22750 (epoch 1.576), train_loss = 2.22016343, grad/param norm = 2.8707e-01, time/batch = 0.6920s	
718/22750 (epoch 1.578), train_loss = 2.11070826, grad/param norm = 2.9673e-01, time/batch = 0.6879s	
719/22750 (epoch 1.580), train_loss = 2.26748399, grad/param norm = 3.0964e-01, time/batch = 0.6886s	
720/22750 (epoch 1.582), train_loss = 2.11257035, grad/param norm = 3.3862e-01, time/batch = 0.6870s	
721/22750 (epoch 1.585), train_loss = 2.00146628, grad/param norm = 2.9915e-01, time/batch = 0.6874s	
722/22750 (epoch 1.587), train_loss = 2.14231028, grad/param norm = 2.8552e-01, time/batch = 0.7011s	
723/22750 (epoch 1.589), train_loss = 2.18239278, grad/param norm = 3.0600e-01, time/batch = 0.7076s	
724/22750 (epoch 1.591), train_loss = 2.25501255, grad/param norm = 2.9285e-01, time/batch = 0.6880s	
725/22750 (epoch 1.593), train_loss = 2.38839558, grad/param norm = 3.1321e-01, time/batch = 0.6865s	
726/22750 (epoch 1.596), train_loss = 2.27902075, grad/param norm = 2.6396e-01, time/batch = 0.6854s	
727/22750 (epoch 1.598), train_loss = 2.41301129, grad/param norm = 2.5507e-01, time/batch = 0.6826s	
728/22750 (epoch 1.600), train_loss = 2.15235950, grad/param norm = 2.9519e-01, time/batch = 0.6865s	
729/22750 (epoch 1.602), train_loss = 2.02218140, grad/param norm = 3.0432e-01, time/batch = 0.6844s	
730/22750 (epoch 1.604), train_loss = 2.22982599, grad/param norm = 2.9689e-01, time/batch = 0.6845s	
731/22750 (epoch 1.607), train_loss = 1.83681963, grad/param norm = 2.5513e-01, time/batch = 0.6885s	
732/22750 (epoch 1.609), train_loss = 1.96005524, grad/param norm = 2.4869e-01, time/batch = 0.6896s	
733/22750 (epoch 1.611), train_loss = 2.12454978, grad/param norm = 3.0702e-01, time/batch = 0.7014s	
734/22750 (epoch 1.613), train_loss = 2.07377570, grad/param norm = 3.4038e-01, time/batch = 0.6833s	
735/22750 (epoch 1.615), train_loss = 2.17533773, grad/param norm = 3.8033e-01, time/batch = 0.7021s	
736/22750 (epoch 1.618), train_loss = 2.08939733, grad/param norm = 3.6668e-01, time/batch = 0.6906s	
737/22750 (epoch 1.620), train_loss = 2.16967106, grad/param norm = 3.3400e-01, time/batch = 0.7022s	
738/22750 (epoch 1.622), train_loss = 2.08721086, grad/param norm = 4.5644e-01, time/batch = 0.6996s	
739/22750 (epoch 1.624), train_loss = 2.45017345, grad/param norm = 4.7786e-01, time/batch = 0.6962s	
740/22750 (epoch 1.626), train_loss = 2.39817796, grad/param norm = 6.7667e-01, time/batch = 0.7156s	
741/22750 (epoch 1.629), train_loss = 2.30556100, grad/param norm = 4.7663e-01, time/batch = 0.7070s	
742/22750 (epoch 1.631), train_loss = 2.34456452, grad/param norm = 2.5425e-01, time/batch = 0.7046s	
743/22750 (epoch 1.633), train_loss = 2.05400653, grad/param norm = 2.6638e-01, time/batch = 0.7051s	
744/22750 (epoch 1.635), train_loss = 2.38459707, grad/param norm = 2.8416e-01, time/batch = 0.6850s	
745/22750 (epoch 1.637), train_loss = 2.37594649, grad/param norm = 3.3551e-01, time/batch = 0.6838s	
746/22750 (epoch 1.640), train_loss = 2.46168296, grad/param norm = 2.8894e-01, time/batch = 0.6840s	
747/22750 (epoch 1.642), train_loss = 2.36114026, grad/param norm = 2.7205e-01, time/batch = 0.6851s	
748/22750 (epoch 1.644), train_loss = 2.20468376, grad/param norm = 2.5876e-01, time/batch = 0.6880s	
749/22750 (epoch 1.646), train_loss = 2.17928687, grad/param norm = 2.9221e-01, time/batch = 0.6967s	
750/22750 (epoch 1.648), train_loss = 2.24364561, grad/param norm = 2.9181e-01, time/batch = 0.7091s	
751/22750 (epoch 1.651), train_loss = 2.35807933, grad/param norm = 3.0691e-01, time/batch = 0.6874s	
752/22750 (epoch 1.653), train_loss = 2.18769392, grad/param norm = 3.0662e-01, time/batch = 0.6919s	
753/22750 (epoch 1.655), train_loss = 2.25183371, grad/param norm = 3.3881e-01, time/batch = 0.7062s	
754/22750 (epoch 1.657), train_loss = 2.36699836, grad/param norm = 2.4405e-01, time/batch = 0.7083s	
755/22750 (epoch 1.659), train_loss = 2.34334983, grad/param norm = 2.7492e-01, time/batch = 0.7116s	
756/22750 (epoch 1.662), train_loss = 2.51305047, grad/param norm = 2.9898e-01, time/batch = 0.7057s	
757/22750 (epoch 1.664), train_loss = 2.28062148, grad/param norm = 3.3454e-01, time/batch = 0.6910s	
758/22750 (epoch 1.666), train_loss = 2.24921907, grad/param norm = 4.3461e-01, time/batch = 0.6952s	
759/22750 (epoch 1.668), train_loss = 2.23426158, grad/param norm = 3.0375e-01, time/batch = 0.7102s	
760/22750 (epoch 1.670), train_loss = 2.25453919, grad/param norm = 3.1002e-01, time/batch = 0.7029s	
761/22750 (epoch 1.673), train_loss = 2.28138553, grad/param norm = 3.0808e-01, time/batch = 0.6918s	
762/22750 (epoch 1.675), train_loss = 2.58023981, grad/param norm = 3.7987e-01, time/batch = 0.6970s	
763/22750 (epoch 1.677), train_loss = 2.36580686, grad/param norm = 3.5294e-01, time/batch = 0.6873s	
764/22750 (epoch 1.679), train_loss = 2.49261650, grad/param norm = 2.5801e-01, time/batch = 0.6859s	
765/22750 (epoch 1.681), train_loss = 2.32166245, grad/param norm = 2.8396e-01, time/batch = 0.6944s	
766/22750 (epoch 1.684), train_loss = 2.37070168, grad/param norm = 2.8114e-01, time/batch = 0.6915s	
767/22750 (epoch 1.686), train_loss = 2.28047205, grad/param norm = 2.8527e-01, time/batch = 0.6876s	
768/22750 (epoch 1.688), train_loss = 2.31637916, grad/param norm = 2.9824e-01, time/batch = 0.6942s	
769/22750 (epoch 1.690), train_loss = 2.25157463, grad/param norm = 3.0794e-01, time/batch = 0.6987s	
770/22750 (epoch 1.692), train_loss = 2.36676083, grad/param norm = 3.1514e-01, time/batch = 0.6847s	
771/22750 (epoch 1.695), train_loss = 2.24428952, grad/param norm = 2.7628e-01, time/batch = 0.6862s	
772/22750 (epoch 1.697), train_loss = 2.11177548, grad/param norm = 2.7020e-01, time/batch = 0.6849s	
773/22750 (epoch 1.699), train_loss = 2.30791446, grad/param norm = 2.8969e-01, time/batch = 0.6880s	
774/22750 (epoch 1.701), train_loss = 2.23680953, grad/param norm = 2.6078e-01, time/batch = 0.6902s	
775/22750 (epoch 1.703), train_loss = 2.23698151, grad/param norm = 3.0229e-01, time/batch = 0.6874s	
776/22750 (epoch 1.705), train_loss = 2.04500909, grad/param norm = 2.9373e-01, time/batch = 0.6889s	
777/22750 (epoch 1.708), train_loss = 2.31288597, grad/param norm = 2.5759e-01, time/batch = 0.6851s	
778/22750 (epoch 1.710), train_loss = 2.03732713, grad/param norm = 3.1276e-01, time/batch = 0.6883s	
779/22750 (epoch 1.712), train_loss = 2.15588675, grad/param norm = 3.0189e-01, time/batch = 0.6932s	
780/22750 (epoch 1.714), train_loss = 2.08413835, grad/param norm = 2.9926e-01, time/batch = 0.6936s	
781/22750 (epoch 1.716), train_loss = 2.18351435, grad/param norm = 3.0736e-01, time/batch = 0.6921s	
782/22750 (epoch 1.719), train_loss = 2.32877743, grad/param norm = 4.0311e-01, time/batch = 0.6904s	
783/22750 (epoch 1.721), train_loss = 2.27690384, grad/param norm = 4.0242e-01, time/batch = 0.6913s	
784/22750 (epoch 1.723), train_loss = 2.22273025, grad/param norm = 2.8844e-01, time/batch = 0.6884s	
785/22750 (epoch 1.725), train_loss = 2.13385599, grad/param norm = 2.5376e-01, time/batch = 0.6877s	
786/22750 (epoch 1.727), train_loss = 2.07279842, grad/param norm = 2.7978e-01, time/batch = 0.6858s	
787/22750 (epoch 1.730), train_loss = 2.00638661, grad/param norm = 2.6011e-01, time/batch = 0.6909s	
788/22750 (epoch 1.732), train_loss = 2.22430496, grad/param norm = 3.4907e-01, time/batch = 0.7000s	
789/22750 (epoch 1.734), train_loss = 1.88221647, grad/param norm = 5.0332e-01, time/batch = 0.7104s	
790/22750 (epoch 1.736), train_loss = 2.17081266, grad/param norm = 3.7427e-01, time/batch = 0.6913s	
791/22750 (epoch 1.738), train_loss = 2.05022906, grad/param norm = 3.1464e-01, time/batch = 0.6934s	
792/22750 (epoch 1.741), train_loss = 2.26325090, grad/param norm = 2.4633e-01, time/batch = 0.6885s	
793/22750 (epoch 1.743), train_loss = 2.30977421, grad/param norm = 2.7517e-01, time/batch = 0.6947s	
794/22750 (epoch 1.745), train_loss = 2.08869169, grad/param norm = 3.0703e-01, time/batch = 0.6987s	
795/22750 (epoch 1.747), train_loss = 2.06111717, grad/param norm = 3.0766e-01, time/batch = 0.6941s	
796/22750 (epoch 1.749), train_loss = 2.30672808, grad/param norm = 3.1522e-01, time/batch = 0.6897s	
797/22750 (epoch 1.752), train_loss = 2.09046054, grad/param norm = 2.7072e-01, time/batch = 0.6930s	
798/22750 (epoch 1.754), train_loss = 2.24634493, grad/param norm = 3.6557e-01, time/batch = 0.6998s	
799/22750 (epoch 1.756), train_loss = 2.06441260, grad/param norm = 4.7327e-01, time/batch = 0.7095s	
800/22750 (epoch 1.758), train_loss = 2.01445562, grad/param norm = 3.2065e-01, time/batch = 0.6946s	
801/22750 (epoch 1.760), train_loss = 2.31484637, grad/param norm = 3.2408e-01, time/batch = 0.6934s	
802/22750 (epoch 1.763), train_loss = 2.17645997, grad/param norm = 3.3582e-01, time/batch = 0.7024s	
803/22750 (epoch 1.765), train_loss = 2.09419371, grad/param norm = 2.8507e-01, time/batch = 0.7095s	
804/22750 (epoch 1.767), train_loss = 2.05771261, grad/param norm = 2.2063e-01, time/batch = 0.7097s	
805/22750 (epoch 1.769), train_loss = 2.28746162, grad/param norm = 2.8131e-01, time/batch = 0.7023s	
806/22750 (epoch 1.771), train_loss = 2.19540292, grad/param norm = 3.0938e-01, time/batch = 0.6917s	
807/22750 (epoch 1.774), train_loss = 2.19399200, grad/param norm = 3.0918e-01, time/batch = 0.6943s	
808/22750 (epoch 1.776), train_loss = 2.17819897, grad/param norm = 3.1924e-01, time/batch = 0.6949s	
809/22750 (epoch 1.778), train_loss = 2.37461751, grad/param norm = 2.8385e-01, time/batch = 0.6970s	
810/22750 (epoch 1.780), train_loss = 2.26155698, grad/param norm = 3.0601e-01, time/batch = 0.6933s	
811/22750 (epoch 1.782), train_loss = 2.29597850, grad/param norm = 3.0963e-01, time/batch = 0.6932s	
812/22750 (epoch 1.785), train_loss = 2.26657395, grad/param norm = 2.7211e-01, time/batch = 0.6910s	
813/22750 (epoch 1.787), train_loss = 2.11912871, grad/param norm = 2.4389e-01, time/batch = 0.6884s	
814/22750 (epoch 1.789), train_loss = 2.01559088, grad/param norm = 2.3781e-01, time/batch = 0.6866s	
815/22750 (epoch 1.791), train_loss = 2.14824791, grad/param norm = 2.3076e-01, time/batch = 0.6889s	
816/22750 (epoch 1.793), train_loss = 2.14094098, grad/param norm = 2.6546e-01, time/batch = 0.6941s	
817/22750 (epoch 1.796), train_loss = 2.03890482, grad/param norm = 2.4467e-01, time/batch = 0.6972s	
818/22750 (epoch 1.798), train_loss = 2.13927296, grad/param norm = 2.7976e-01, time/batch = 0.6940s	
819/22750 (epoch 1.800), train_loss = 2.17940564, grad/param norm = 3.0434e-01, time/batch = 0.6920s	
820/22750 (epoch 1.802), train_loss = 2.30545586, grad/param norm = 2.9349e-01, time/batch = 0.6981s	
821/22750 (epoch 1.804), train_loss = 2.37542307, grad/param norm = 2.4402e-01, time/batch = 0.6925s	
822/22750 (epoch 1.807), train_loss = 2.18999696, grad/param norm = 2.2942e-01, time/batch = 0.6928s	
823/22750 (epoch 1.809), train_loss = 2.42933534, grad/param norm = 2.8568e-01, time/batch = 0.6885s	
824/22750 (epoch 1.811), train_loss = 2.19325069, grad/param norm = 2.8524e-01, time/batch = 0.6917s	
825/22750 (epoch 1.813), train_loss = 2.36122457, grad/param norm = 2.5587e-01, time/batch = 0.6942s	
826/22750 (epoch 1.815), train_loss = 2.34286701, grad/param norm = 3.5156e-01, time/batch = 0.6920s	
827/22750 (epoch 1.818), train_loss = 2.40375814, grad/param norm = 3.6078e-01, time/batch = 0.6981s	
828/22750 (epoch 1.820), train_loss = 2.38381094, grad/param norm = 3.1911e-01, time/batch = 0.6924s	
829/22750 (epoch 1.822), train_loss = 2.26839819, grad/param norm = 2.7893e-01, time/batch = 0.6943s	
830/22750 (epoch 1.824), train_loss = 2.26567707, grad/param norm = 2.7358e-01, time/batch = 0.6961s	
831/22750 (epoch 1.826), train_loss = 2.17803052, grad/param norm = 2.8145e-01, time/batch = 0.6961s	
832/22750 (epoch 1.829), train_loss = 2.32193402, grad/param norm = 2.7177e-01, time/batch = 0.6980s	
833/22750 (epoch 1.831), train_loss = 2.28030594, grad/param norm = 2.7523e-01, time/batch = 0.6950s	
834/22750 (epoch 1.833), train_loss = 2.40462183, grad/param norm = 2.5781e-01, time/batch = 0.6968s	
835/22750 (epoch 1.835), train_loss = 2.26173509, grad/param norm = 2.5495e-01, time/batch = 0.6914s	
836/22750 (epoch 1.837), train_loss = 2.21732014, grad/param norm = 2.6384e-01, time/batch = 0.6961s	
837/22750 (epoch 1.840), train_loss = 2.26979920, grad/param norm = 3.6098e-01, time/batch = 0.6952s	
838/22750 (epoch 1.842), train_loss = 2.28302873, grad/param norm = 3.6492e-01, time/batch = 0.6910s	
839/22750 (epoch 1.844), train_loss = 2.35518875, grad/param norm = 3.5868e-01, time/batch = 0.7047s	
840/22750 (epoch 1.846), train_loss = 2.07779383, grad/param norm = 2.9008e-01, time/batch = 0.7093s	
841/22750 (epoch 1.848), train_loss = 2.06523633, grad/param norm = 3.6271e-01, time/batch = 0.7175s	
842/22750 (epoch 1.851), train_loss = 2.15460848, grad/param norm = 3.9418e-01, time/batch = 0.6999s	
843/22750 (epoch 1.853), train_loss = 2.12245788, grad/param norm = 2.9467e-01, time/batch = 0.7151s	
844/22750 (epoch 1.855), train_loss = 2.02984940, grad/param norm = 2.3976e-01, time/batch = 0.7023s	
845/22750 (epoch 1.857), train_loss = 2.21419691, grad/param norm = 2.6021e-01, time/batch = 0.7028s	
846/22750 (epoch 1.859), train_loss = 2.20804710, grad/param norm = 2.7603e-01, time/batch = 0.7182s	
847/22750 (epoch 1.862), train_loss = 2.28033240, grad/param norm = 2.6426e-01, time/batch = 0.7032s	
848/22750 (epoch 1.864), train_loss = 2.28080954, grad/param norm = 2.9245e-01, time/batch = 0.6973s	
849/22750 (epoch 1.866), train_loss = 2.16479459, grad/param norm = 2.7093e-01, time/batch = 0.7025s	
850/22750 (epoch 1.868), train_loss = 2.21368787, grad/param norm = 2.7676e-01, time/batch = 0.6970s	
851/22750 (epoch 1.870), train_loss = 1.95158589, grad/param norm = 2.4703e-01, time/batch = 0.7032s	
852/22750 (epoch 1.873), train_loss = 2.16915778, grad/param norm = 2.7543e-01, time/batch = 0.7039s	
853/22750 (epoch 1.875), train_loss = 2.21100061, grad/param norm = 2.8476e-01, time/batch = 0.6968s	
854/22750 (epoch 1.877), train_loss = 2.08199341, grad/param norm = 2.9083e-01, time/batch = 0.6963s	
855/22750 (epoch 1.879), train_loss = 2.30859907, grad/param norm = 3.4099e-01, time/batch = 0.6917s	
856/22750 (epoch 1.881), train_loss = 2.22727965, grad/param norm = 3.4617e-01, time/batch = 0.6901s	
857/22750 (epoch 1.884), train_loss = 2.29432529, grad/param norm = 3.4354e-01, time/batch = 0.6917s	
858/22750 (epoch 1.886), train_loss = 2.25186996, grad/param norm = 3.0624e-01, time/batch = 0.6937s	
859/22750 (epoch 1.888), train_loss = 2.20333336, grad/param norm = 3.3414e-01, time/batch = 0.6912s	
860/22750 (epoch 1.890), train_loss = 2.20476078, grad/param norm = 3.8288e-01, time/batch = 0.6914s	
861/22750 (epoch 1.892), train_loss = 2.61653387, grad/param norm = 3.6566e-01, time/batch = 0.6874s	
862/22750 (epoch 1.895), train_loss = 2.39577270, grad/param norm = 3.0821e-01, time/batch = 0.6906s	
863/22750 (epoch 1.897), train_loss = 2.28347016, grad/param norm = 2.6363e-01, time/batch = 0.6935s	
864/22750 (epoch 1.899), train_loss = 2.32945954, grad/param norm = 2.6569e-01, time/batch = 0.6895s	
865/22750 (epoch 1.901), train_loss = 2.32608528, grad/param norm = 2.4910e-01, time/batch = 0.6914s	
866/22750 (epoch 1.903), train_loss = 2.25573990, grad/param norm = 2.8391e-01, time/batch = 0.6987s	
867/22750 (epoch 1.905), train_loss = 2.16139807, grad/param norm = 2.6114e-01, time/batch = 0.6893s	
868/22750 (epoch 1.908), train_loss = 2.20101561, grad/param norm = 3.2076e-01, time/batch = 0.6948s	
869/22750 (epoch 1.910), train_loss = 2.05141635, grad/param norm = 3.3002e-01, time/batch = 0.6918s	
870/22750 (epoch 1.912), train_loss = 2.03478103, grad/param norm = 2.8936e-01, time/batch = 0.6905s	
871/22750 (epoch 1.914), train_loss = 2.02350192, grad/param norm = 2.5652e-01, time/batch = 0.6865s	
872/22750 (epoch 1.916), train_loss = 1.93188373, grad/param norm = 2.1078e-01, time/batch = 0.6946s	
873/22750 (epoch 1.919), train_loss = 1.97266502, grad/param norm = 2.1615e-01, time/batch = 0.6965s	
874/22750 (epoch 1.921), train_loss = 1.84894583, grad/param norm = 2.4245e-01, time/batch = 0.6927s	
875/22750 (epoch 1.923), train_loss = 2.14293992, grad/param norm = 2.6062e-01, time/batch = 0.6933s	
876/22750 (epoch 1.925), train_loss = 2.13963922, grad/param norm = 2.5584e-01, time/batch = 0.6897s	
877/22750 (epoch 1.927), train_loss = 1.89772444, grad/param norm = 2.8239e-01, time/batch = 0.6934s	
878/22750 (epoch 1.930), train_loss = 2.00963337, grad/param norm = 3.0752e-01, time/batch = 0.6900s	
879/22750 (epoch 1.932), train_loss = 2.40747477, grad/param norm = 3.2509e-01, time/batch = 0.6904s	
880/22750 (epoch 1.934), train_loss = 1.89954802, grad/param norm = 3.0834e-01, time/batch = 0.6922s	
881/22750 (epoch 1.936), train_loss = 2.28171431, grad/param norm = 3.4370e-01, time/batch = 0.6991s	
882/22750 (epoch 1.938), train_loss = 2.20600889, grad/param norm = 3.4815e-01, time/batch = 0.6926s	
883/22750 (epoch 1.941), train_loss = 2.56088003, grad/param norm = 4.2464e-01, time/batch = 0.6966s	
884/22750 (epoch 1.943), train_loss = 2.26841557, grad/param norm = 3.3351e-01, time/batch = 0.6912s	
885/22750 (epoch 1.945), train_loss = 2.20446787, grad/param norm = 2.5541e-01, time/batch = 0.6880s	
886/22750 (epoch 1.947), train_loss = 2.25631163, grad/param norm = 2.9037e-01, time/batch = 0.6931s	
887/22750 (epoch 1.949), train_loss = 2.05616507, grad/param norm = 2.8829e-01, time/batch = 0.6874s	
888/22750 (epoch 1.952), train_loss = 2.09428487, grad/param norm = 2.4887e-01, time/batch = 0.6923s	
889/22750 (epoch 1.954), train_loss = 2.08713194, grad/param norm = 2.5668e-01, time/batch = 0.6935s	
890/22750 (epoch 1.956), train_loss = 2.15754402, grad/param norm = 2.8045e-01, time/batch = 0.6941s	
891/22750 (epoch 1.958), train_loss = 2.15697424, grad/param norm = 2.4527e-01, time/batch = 0.6890s	
892/22750 (epoch 1.960), train_loss = 2.14016037, grad/param norm = 2.6043e-01, time/batch = 0.6885s	
893/22750 (epoch 1.963), train_loss = 2.14470808, grad/param norm = 2.5904e-01, time/batch = 0.6887s	
894/22750 (epoch 1.965), train_loss = 2.15130542, grad/param norm = 2.7421e-01, time/batch = 0.6912s	
895/22750 (epoch 1.967), train_loss = 2.22243937, grad/param norm = 2.6138e-01, time/batch = 0.6928s	
896/22750 (epoch 1.969), train_loss = 2.13373262, grad/param norm = 2.4923e-01, time/batch = 0.6954s	
897/22750 (epoch 1.971), train_loss = 2.11710135, grad/param norm = 2.2893e-01, time/batch = 0.6918s	
898/22750 (epoch 1.974), train_loss = 2.13972675, grad/param norm = 2.5970e-01, time/batch = 0.6986s	
899/22750 (epoch 1.976), train_loss = 2.25565283, grad/param norm = 2.6405e-01, time/batch = 0.6928s	
900/22750 (epoch 1.978), train_loss = 2.08825396, grad/param norm = 3.0508e-01, time/batch = 0.6880s	
901/22750 (epoch 1.980), train_loss = 2.17967880, grad/param norm = 2.7581e-01, time/batch = 0.6962s	
902/22750 (epoch 1.982), train_loss = 2.10787733, grad/param norm = 2.9049e-01, time/batch = 0.6962s	
903/22750 (epoch 1.985), train_loss = 2.36614393, grad/param norm = 2.9729e-01, time/batch = 0.6917s	
904/22750 (epoch 1.987), train_loss = 2.02089081, grad/param norm = 3.1670e-01, time/batch = 0.6961s	
905/22750 (epoch 1.989), train_loss = 2.04772780, grad/param norm = 2.4878e-01, time/batch = 0.6928s	
906/22750 (epoch 1.991), train_loss = 2.23201265, grad/param norm = 2.5972e-01, time/batch = 0.6891s	
907/22750 (epoch 1.993), train_loss = 2.18005511, grad/param norm = 2.6848e-01, time/batch = 0.6923s	
908/22750 (epoch 1.996), train_loss = 2.09737515, grad/param norm = 2.5706e-01, time/batch = 0.6903s	
909/22750 (epoch 1.998), train_loss = 2.32294917, grad/param norm = 2.6015e-01, time/batch = 0.6928s	
910/22750 (epoch 2.000), train_loss = 2.29994974, grad/param norm = 2.5875e-01, time/batch = 0.6959s	
911/22750 (epoch 2.002), train_loss = 2.33135359, grad/param norm = 3.0709e-01, time/batch = 0.7054s	
912/22750 (epoch 2.004), train_loss = 2.27805018, grad/param norm = 3.6757e-01, time/batch = 0.7115s	
913/22750 (epoch 2.007), train_loss = 2.28813323, grad/param norm = 4.2105e-01, time/batch = 0.7027s	
914/22750 (epoch 2.009), train_loss = 2.45108782, grad/param norm = 3.9289e-01, time/batch = 0.6930s	
915/22750 (epoch 2.011), train_loss = 2.30050097, grad/param norm = 3.4516e-01, time/batch = 0.6913s	
916/22750 (epoch 2.013), train_loss = 2.28276570, grad/param norm = 3.3675e-01, time/batch = 0.6947s	
917/22750 (epoch 2.015), train_loss = 2.22311723, grad/param norm = 2.5413e-01, time/batch = 0.6913s	
918/22750 (epoch 2.018), train_loss = 2.13130915, grad/param norm = 2.4102e-01, time/batch = 0.6984s	
919/22750 (epoch 2.020), train_loss = 2.23815269, grad/param norm = 2.6613e-01, time/batch = 0.6898s	
920/22750 (epoch 2.022), train_loss = 2.15501110, grad/param norm = 2.5342e-01, time/batch = 0.7056s	
921/22750 (epoch 2.024), train_loss = 2.10528639, grad/param norm = 2.6198e-01, time/batch = 0.7061s	
922/22750 (epoch 2.026), train_loss = 2.35594392, grad/param norm = 3.5217e-01, time/batch = 0.7049s	
923/22750 (epoch 2.029), train_loss = 1.97787799, grad/param norm = 2.8652e-01, time/batch = 0.7023s	
924/22750 (epoch 2.031), train_loss = 2.40872871, grad/param norm = 2.6718e-01, time/batch = 0.7030s	
925/22750 (epoch 2.033), train_loss = 2.21196901, grad/param norm = 2.6932e-01, time/batch = 0.7256s	
926/22750 (epoch 2.035), train_loss = 2.29462273, grad/param norm = 2.7731e-01, time/batch = 0.7250s	
927/22750 (epoch 2.037), train_loss = 2.37740973, grad/param norm = 2.8175e-01, time/batch = 0.7205s	
928/22750 (epoch 2.040), train_loss = 2.10467622, grad/param norm = 2.9620e-01, time/batch = 0.7059s	
929/22750 (epoch 2.042), train_loss = 2.25680204, grad/param norm = 2.4172e-01, time/batch = 0.7286s	
930/22750 (epoch 2.044), train_loss = 2.09055762, grad/param norm = 2.8557e-01, time/batch = 0.7226s	
931/22750 (epoch 2.046), train_loss = 2.14839044, grad/param norm = 3.1660e-01, time/batch = 0.7223s	
932/22750 (epoch 2.048), train_loss = 2.20005773, grad/param norm = 3.5919e-01, time/batch = 0.7248s	
933/22750 (epoch 2.051), train_loss = 2.31036528, grad/param norm = 3.1679e-01, time/batch = 0.7310s	
934/22750 (epoch 2.053), train_loss = 2.02084914, grad/param norm = 2.8972e-01, time/batch = 0.7195s	
935/22750 (epoch 2.055), train_loss = 2.26889781, grad/param norm = 3.1223e-01, time/batch = 0.7039s	
936/22750 (epoch 2.057), train_loss = 2.20665897, grad/param norm = 3.1930e-01, time/batch = 0.7010s	
937/22750 (epoch 2.059), train_loss = 1.99633964, grad/param norm = 3.3233e-01, time/batch = 0.6992s	
938/22750 (epoch 2.062), train_loss = 2.01797603, grad/param norm = 2.5933e-01, time/batch = 0.7041s	
939/22750 (epoch 2.064), train_loss = 2.16637618, grad/param norm = 2.6252e-01, time/batch = 0.7048s	
940/22750 (epoch 2.066), train_loss = 1.95480316, grad/param norm = 2.4053e-01, time/batch = 0.6973s	
941/22750 (epoch 2.068), train_loss = 1.99783643, grad/param norm = 2.6037e-01, time/batch = 0.6981s	
942/22750 (epoch 2.070), train_loss = 1.83854329, grad/param norm = 2.6973e-01, time/batch = 0.6977s	
943/22750 (epoch 2.073), train_loss = 2.08344978, grad/param norm = 3.2505e-01, time/batch = 0.6982s	
944/22750 (epoch 2.075), train_loss = 2.17785575, grad/param norm = 2.5145e-01, time/batch = 0.6981s	
945/22750 (epoch 2.077), train_loss = 1.86182164, grad/param norm = 2.7723e-01, time/batch = 0.7035s	
946/22750 (epoch 2.079), train_loss = 2.06384483, grad/param norm = 2.6458e-01, time/batch = 0.7009s	
947/22750 (epoch 2.081), train_loss = 2.13770066, grad/param norm = 3.1661e-01, time/batch = 0.7191s	
948/22750 (epoch 2.084), train_loss = 2.06309842, grad/param norm = 2.8197e-01, time/batch = 0.7076s	
949/22750 (epoch 2.086), train_loss = 2.10928031, grad/param norm = 3.0077e-01, time/batch = 0.7007s	
950/22750 (epoch 2.088), train_loss = 2.11827309, grad/param norm = 2.8220e-01, time/batch = 0.7038s	
951/22750 (epoch 2.090), train_loss = 2.13123900, grad/param norm = 3.0978e-01, time/batch = 0.7053s	
952/22750 (epoch 2.092), train_loss = 2.27093224, grad/param norm = 2.8576e-01, time/batch = 0.7008s	
953/22750 (epoch 2.095), train_loss = 2.04334762, grad/param norm = 2.9912e-01, time/batch = 0.7026s	
954/22750 (epoch 2.097), train_loss = 2.08245211, grad/param norm = 2.7184e-01, time/batch = 0.6996s	
955/22750 (epoch 2.099), train_loss = 2.26113386, grad/param norm = 3.5079e-01, time/batch = 0.7006s	
956/22750 (epoch 2.101), train_loss = 2.19273313, grad/param norm = 3.1830e-01, time/batch = 0.7062s	
957/22750 (epoch 2.103), train_loss = 1.99504704, grad/param norm = 2.5768e-01, time/batch = 0.7217s	
958/22750 (epoch 2.105), train_loss = 2.32445948, grad/param norm = 2.8331e-01, time/batch = 0.7048s	
959/22750 (epoch 2.108), train_loss = 2.05825820, grad/param norm = 2.6425e-01, time/batch = 0.7076s	
960/22750 (epoch 2.110), train_loss = 2.07511923, grad/param norm = 2.8043e-01, time/batch = 0.7099s	
961/22750 (epoch 2.112), train_loss = 1.88740989, grad/param norm = 2.5854e-01, time/batch = 0.7222s	
962/22750 (epoch 2.114), train_loss = 1.86712764, grad/param norm = 2.6582e-01, time/batch = 0.7247s	
963/22750 (epoch 2.116), train_loss = 1.98449234, grad/param norm = 3.2546e-01, time/batch = 0.7149s	
964/22750 (epoch 2.119), train_loss = 2.07176532, grad/param norm = 2.5127e-01, time/batch = 0.7259s	
965/22750 (epoch 2.121), train_loss = 2.23325285, grad/param norm = 2.7176e-01, time/batch = 0.7208s	
966/22750 (epoch 2.123), train_loss = 2.03739748, grad/param norm = 2.4708e-01, time/batch = 0.7228s	
967/22750 (epoch 2.125), train_loss = 2.24717417, grad/param norm = 2.5895e-01, time/batch = 0.7064s	
968/22750 (epoch 2.127), train_loss = 2.19459420, grad/param norm = 2.9645e-01, time/batch = 0.7258s	
969/22750 (epoch 2.130), train_loss = 2.17747269, grad/param norm = 2.5960e-01, time/batch = 0.7079s	
970/22750 (epoch 2.132), train_loss = 2.15272022, grad/param norm = 2.5396e-01, time/batch = 0.6998s	
971/22750 (epoch 2.134), train_loss = 2.12834588, grad/param norm = 2.8874e-01, time/batch = 0.7025s	
972/22750 (epoch 2.136), train_loss = 2.03385810, grad/param norm = 2.5645e-01, time/batch = 0.6972s	
973/22750 (epoch 2.138), train_loss = 2.07334691, grad/param norm = 3.3645e-01, time/batch = 0.7062s	
974/22750 (epoch 2.141), train_loss = 2.02538322, grad/param norm = 3.4438e-01, time/batch = 0.7061s	
975/22750 (epoch 2.143), train_loss = 2.04651708, grad/param norm = 2.9618e-01, time/batch = 0.7120s	
976/22750 (epoch 2.145), train_loss = 2.16067900, grad/param norm = 2.8233e-01, time/batch = 0.7018s	
977/22750 (epoch 2.147), train_loss = 2.13703857, grad/param norm = 2.5144e-01, time/batch = 0.7008s	
978/22750 (epoch 2.149), train_loss = 2.14239420, grad/param norm = 2.6748e-01, time/batch = 0.7055s	
979/22750 (epoch 2.152), train_loss = 2.13766459, grad/param norm = 2.8434e-01, time/batch = 0.7129s	
980/22750 (epoch 2.154), train_loss = 1.99628089, grad/param norm = 2.6689e-01, time/batch = 0.7107s	
981/22750 (epoch 2.156), train_loss = 2.11493261, grad/param norm = 2.7262e-01, time/batch = 0.7051s	
982/22750 (epoch 2.158), train_loss = 2.11538638, grad/param norm = 2.6903e-01, time/batch = 0.7258s	
983/22750 (epoch 2.160), train_loss = 2.15603573, grad/param norm = 2.3328e-01, time/batch = 0.7096s	
984/22750 (epoch 2.163), train_loss = 2.28160505, grad/param norm = 2.8074e-01, time/batch = 0.7003s	
985/22750 (epoch 2.165), train_loss = 2.21115490, grad/param norm = 2.6702e-01, time/batch = 0.6981s	
986/22750 (epoch 2.167), train_loss = 1.99571969, grad/param norm = 2.6284e-01, time/batch = 0.7006s	
987/22750 (epoch 2.169), train_loss = 2.09291100, grad/param norm = 2.6277e-01, time/batch = 0.7007s	
988/22750 (epoch 2.171), train_loss = 2.04721743, grad/param norm = 2.4212e-01, time/batch = 0.7033s	
989/22750 (epoch 2.174), train_loss = 1.88405136, grad/param norm = 2.5356e-01, time/batch = 0.7034s	
990/22750 (epoch 2.176), train_loss = 2.08696820, grad/param norm = 2.6892e-01, time/batch = 0.7043s	
991/22750 (epoch 2.178), train_loss = 2.01965098, grad/param norm = 2.7001e-01, time/batch = 0.7157s	
992/22750 (epoch 2.180), train_loss = 2.18609027, grad/param norm = 2.9149e-01, time/batch = 0.7264s	
993/22750 (epoch 2.182), train_loss = 2.14538275, grad/param norm = 2.8407e-01, time/batch = 0.7247s	
994/22750 (epoch 2.185), train_loss = 2.09700049, grad/param norm = 2.6281e-01, time/batch = 0.7593s	
995/22750 (epoch 2.187), train_loss = 1.97261662, grad/param norm = 3.1327e-01, time/batch = 0.7289s	
996/22750 (epoch 2.189), train_loss = 2.02726842, grad/param norm = 3.0218e-01, time/batch = 0.7146s	
997/22750 (epoch 2.191), train_loss = 1.95794722, grad/param norm = 2.7464e-01, time/batch = 0.7494s	
998/22750 (epoch 2.193), train_loss = 2.09147786, grad/param norm = 2.5951e-01, time/batch = 0.7277s	
999/22750 (epoch 2.196), train_loss = 2.15055932, grad/param norm = 2.5448e-01, time/batch = 0.7170s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch2.20_2.0764.t7	
1000/22750 (epoch 2.198), train_loss = 1.92268552, grad/param norm = 2.2317e-01, time/batch = 0.7243s	
1001/22750 (epoch 2.200), train_loss = 2.23626523, grad/param norm = 2.3907e-01, time/batch = 0.7078s	
1002/22750 (epoch 2.202), train_loss = 2.39004174, grad/param norm = 2.6490e-01, time/batch = 0.7175s	
1003/22750 (epoch 2.204), train_loss = 2.33343522, grad/param norm = 2.5848e-01, time/batch = 0.7339s	
1004/22750 (epoch 2.207), train_loss = 2.02060331, grad/param norm = 2.6830e-01, time/batch = 0.7269s	
1005/22750 (epoch 2.209), train_loss = 2.06969619, grad/param norm = 2.3406e-01, time/batch = 0.7139s	
1006/22750 (epoch 2.211), train_loss = 2.07694446, grad/param norm = 2.5593e-01, time/batch = 0.7114s	
1007/22750 (epoch 2.213), train_loss = 1.97845517, grad/param norm = 3.2431e-01, time/batch = 0.7155s	
1008/22750 (epoch 2.215), train_loss = 2.08543933, grad/param norm = 3.0685e-01, time/batch = 0.7166s	
1009/22750 (epoch 2.218), train_loss = 1.89002770, grad/param norm = 3.1061e-01, time/batch = 0.7211s	
1010/22750 (epoch 2.220), train_loss = 2.14874075, grad/param norm = 2.9256e-01, time/batch = 0.7123s	
1011/22750 (epoch 2.222), train_loss = 1.94820742, grad/param norm = 2.8135e-01, time/batch = 0.7138s	
1012/22750 (epoch 2.224), train_loss = 2.09152432, grad/param norm = 2.7893e-01, time/batch = 0.7228s	
1013/22750 (epoch 2.226), train_loss = 2.09200192, grad/param norm = 2.6188e-01, time/batch = 0.7257s	
1014/22750 (epoch 2.229), train_loss = 2.21257947, grad/param norm = 2.7525e-01, time/batch = 0.7234s	
1015/22750 (epoch 2.231), train_loss = 2.12567980, grad/param norm = 2.5885e-01, time/batch = 0.7144s	
1016/22750 (epoch 2.233), train_loss = 2.10086428, grad/param norm = 2.3914e-01, time/batch = 0.7273s	
1017/22750 (epoch 2.235), train_loss = 1.95639329, grad/param norm = 2.7920e-01, time/batch = 0.7267s	
1018/22750 (epoch 2.237), train_loss = 2.07862389, grad/param norm = 2.8436e-01, time/batch = 0.7213s	
1019/22750 (epoch 2.240), train_loss = 2.25357638, grad/param norm = 2.6890e-01, time/batch = 0.7247s	
1020/22750 (epoch 2.242), train_loss = 2.42267853, grad/param norm = 2.5628e-01, time/batch = 0.7187s	
1021/22750 (epoch 2.244), train_loss = 2.26760770, grad/param norm = 3.9144e-01, time/batch = 0.7249s	
1022/22750 (epoch 2.246), train_loss = 2.43518254, grad/param norm = 3.2940e-01, time/batch = 0.7047s	
1023/22750 (epoch 2.248), train_loss = 2.02399236, grad/param norm = 2.7909e-01, time/batch = 0.7081s	
1024/22750 (epoch 2.251), train_loss = 2.30526188, grad/param norm = 2.7693e-01, time/batch = 0.7169s	
1025/22750 (epoch 2.253), train_loss = 2.16222937, grad/param norm = 2.2488e-01, time/batch = 0.7136s	
1026/22750 (epoch 2.255), train_loss = 2.26469053, grad/param norm = 2.6779e-01, time/batch = 0.7163s	
1027/22750 (epoch 2.257), train_loss = 2.08531572, grad/param norm = 3.0222e-01, time/batch = 0.7120s	
1028/22750 (epoch 2.259), train_loss = 2.16280944, grad/param norm = 2.6454e-01, time/batch = 0.7212s	
1029/22750 (epoch 2.262), train_loss = 2.08494928, grad/param norm = 2.7238e-01, time/batch = 0.7194s	
1030/22750 (epoch 2.264), train_loss = 2.15877697, grad/param norm = 2.4581e-01, time/batch = 0.7189s	
1031/22750 (epoch 2.266), train_loss = 1.96200548, grad/param norm = 2.9475e-01, time/batch = 0.7248s	
1032/22750 (epoch 2.268), train_loss = 2.15750462, grad/param norm = 2.5949e-01, time/batch = 0.7261s	
1033/22750 (epoch 2.270), train_loss = 1.98085254, grad/param norm = 3.0585e-01, time/batch = 0.7266s	
1034/22750 (epoch 2.273), train_loss = 2.23508266, grad/param norm = 3.1790e-01, time/batch = 0.7261s	
1035/22750 (epoch 2.275), train_loss = 2.06882179, grad/param norm = 2.5926e-01, time/batch = 0.7210s	
1036/22750 (epoch 2.277), train_loss = 2.15633438, grad/param norm = 2.6474e-01, time/batch = 0.7181s	
1037/22750 (epoch 2.279), train_loss = 1.88942095, grad/param norm = 2.2468e-01, time/batch = 0.7135s	
1038/22750 (epoch 2.281), train_loss = 2.01500188, grad/param norm = 2.2565e-01, time/batch = 0.7105s	
1039/22750 (epoch 2.284), train_loss = 1.97314260, grad/param norm = 2.2219e-01, time/batch = 0.7110s	
1040/22750 (epoch 2.286), train_loss = 2.04559913, grad/param norm = 2.3980e-01, time/batch = 0.7233s	
1041/22750 (epoch 2.288), train_loss = 2.19917088, grad/param norm = 2.2842e-01, time/batch = 0.7245s	
1042/22750 (epoch 2.290), train_loss = 1.98584813, grad/param norm = 2.5818e-01, time/batch = 0.7196s	
1043/22750 (epoch 2.292), train_loss = 2.01788226, grad/param norm = 2.4497e-01, time/batch = 0.7208s	
1044/22750 (epoch 2.295), train_loss = 2.11843664, grad/param norm = 2.7224e-01, time/batch = 0.7197s	
1045/22750 (epoch 2.297), train_loss = 1.99716011, grad/param norm = 2.8175e-01, time/batch = 0.7107s	
1046/22750 (epoch 2.299), train_loss = 2.23070665, grad/param norm = 3.2525e-01, time/batch = 0.7227s	
1047/22750 (epoch 2.301), train_loss = 2.15631351, grad/param norm = 2.7080e-01, time/batch = 0.7261s	
1048/22750 (epoch 2.303), train_loss = 2.21104049, grad/param norm = 3.1484e-01, time/batch = 0.7276s	
1049/22750 (epoch 2.305), train_loss = 2.24224086, grad/param norm = 3.2111e-01, time/batch = 0.7255s	
1050/22750 (epoch 2.308), train_loss = 2.09187278, grad/param norm = 2.6134e-01, time/batch = 0.7194s	
1051/22750 (epoch 2.310), train_loss = 1.99785799, grad/param norm = 2.5636e-01, time/batch = 0.7273s	
1052/22750 (epoch 2.312), train_loss = 2.04746850, grad/param norm = 2.4269e-01, time/batch = 0.7265s	
1053/22750 (epoch 2.314), train_loss = 2.10623981, grad/param norm = 2.4629e-01, time/batch = 0.7184s	
1054/22750 (epoch 2.316), train_loss = 2.04678958, grad/param norm = 2.5511e-01, time/batch = 0.7245s	
1055/22750 (epoch 2.319), train_loss = 2.14397649, grad/param norm = 2.5369e-01, time/batch = 0.7213s	
1056/22750 (epoch 2.321), train_loss = 2.05119453, grad/param norm = 2.8894e-01, time/batch = 0.7325s	
1057/22750 (epoch 2.323), train_loss = 1.92927454, grad/param norm = 2.6818e-01, time/batch = 0.7215s	
1058/22750 (epoch 2.325), train_loss = 1.83184258, grad/param norm = 2.3444e-01, time/batch = 0.7243s	
1059/22750 (epoch 2.327), train_loss = 2.21438224, grad/param norm = 2.8175e-01, time/batch = 0.7228s	
1060/22750 (epoch 2.330), train_loss = 2.34759235, grad/param norm = 2.6645e-01, time/batch = 0.7116s	
1061/22750 (epoch 2.332), train_loss = 2.07011947, grad/param norm = 2.5259e-01, time/batch = 0.7140s	
1062/22750 (epoch 2.334), train_loss = 1.89753746, grad/param norm = 2.7929e-01, time/batch = 0.7145s	
1063/22750 (epoch 2.336), train_loss = 2.13356357, grad/param norm = 2.5128e-01, time/batch = 0.7241s	
1064/22750 (epoch 2.338), train_loss = 2.17429241, grad/param norm = 3.1047e-01, time/batch = 0.7253s	
1065/22750 (epoch 2.341), train_loss = 2.07276980, grad/param norm = 2.4035e-01, time/batch = 0.7191s	
1066/22750 (epoch 2.343), train_loss = 1.91887011, grad/param norm = 2.6801e-01, time/batch = 0.7189s	
1067/22750 (epoch 2.345), train_loss = 2.30180388, grad/param norm = 2.8025e-01, time/batch = 0.7138s	
1068/22750 (epoch 2.347), train_loss = 2.25031437, grad/param norm = 2.6830e-01, time/batch = 0.7076s	
1069/22750 (epoch 2.349), train_loss = 1.78888810, grad/param norm = 2.8097e-01, time/batch = 0.7221s	
1070/22750 (epoch 2.352), train_loss = 2.13595681, grad/param norm = 2.9993e-01, time/batch = 0.7209s	
1071/22750 (epoch 2.354), train_loss = 2.19379940, grad/param norm = 2.7155e-01, time/batch = 0.7154s	
1072/22750 (epoch 2.356), train_loss = 2.24730744, grad/param norm = 2.6462e-01, time/batch = 0.7182s	
1073/22750 (epoch 2.358), train_loss = 1.98094116, grad/param norm = 2.5309e-01, time/batch = 0.7123s	
1074/22750 (epoch 2.360), train_loss = 2.32691804, grad/param norm = 2.4852e-01, time/batch = 0.7219s	
1075/22750 (epoch 2.363), train_loss = 2.15934078, grad/param norm = 2.4767e-01, time/batch = 0.7265s	
1076/22750 (epoch 2.365), train_loss = 1.77577163, grad/param norm = 2.9980e-01, time/batch = 0.7166s	
1077/22750 (epoch 2.367), train_loss = 1.73829742, grad/param norm = 2.7096e-01, time/batch = 0.7085s	
1078/22750 (epoch 2.369), train_loss = 2.00231252, grad/param norm = 2.6004e-01, time/batch = 0.7106s	
1079/22750 (epoch 2.371), train_loss = 1.98598133, grad/param norm = 2.8606e-01, time/batch = 0.7123s	
1080/22750 (epoch 2.374), train_loss = 1.87706866, grad/param norm = 3.2872e-01, time/batch = 0.7127s	
1081/22750 (epoch 2.376), train_loss = 2.18167254, grad/param norm = 2.8156e-01, time/batch = 0.7123s	
1082/22750 (epoch 2.378), train_loss = 1.96117950, grad/param norm = 2.2571e-01, time/batch = 0.7109s	
1083/22750 (epoch 2.380), train_loss = 2.21462217, grad/param norm = 2.6992e-01, time/batch = 0.7135s	
1084/22750 (epoch 2.382), train_loss = 1.96765179, grad/param norm = 2.9382e-01, time/batch = 0.7150s	
1085/22750 (epoch 2.385), train_loss = 2.06255089, grad/param norm = 2.5555e-01, time/batch = 0.7245s	
1086/22750 (epoch 2.387), train_loss = 2.16169060, grad/param norm = 2.7613e-01, time/batch = 0.7242s	
1087/22750 (epoch 2.389), train_loss = 1.74968321, grad/param norm = 3.0611e-01, time/batch = 0.7256s	
1088/22750 (epoch 2.391), train_loss = 1.63618048, grad/param norm = 2.5741e-01, time/batch = 0.7198s	
1089/22750 (epoch 2.393), train_loss = 1.94429572, grad/param norm = 3.0848e-01, time/batch = 0.7168s	
1090/22750 (epoch 2.396), train_loss = 2.07576952, grad/param norm = 2.7215e-01, time/batch = 0.7219s	
1091/22750 (epoch 2.398), train_loss = 2.03089542, grad/param norm = 3.3977e-01, time/batch = 0.7258s	
1092/22750 (epoch 2.400), train_loss = 2.01638235, grad/param norm = 2.6559e-01, time/batch = 0.7402s	
1093/22750 (epoch 2.402), train_loss = 2.07225177, grad/param norm = 3.0425e-01, time/batch = 0.7411s	
1094/22750 (epoch 2.404), train_loss = 2.20703730, grad/param norm = 2.7402e-01, time/batch = 0.7261s	
1095/22750 (epoch 2.407), train_loss = 2.10574455, grad/param norm = 3.0203e-01, time/batch = 0.7250s	
1096/22750 (epoch 2.409), train_loss = 2.07012732, grad/param norm = 2.6759e-01, time/batch = 0.7195s	
1097/22750 (epoch 2.411), train_loss = 2.09511017, grad/param norm = 2.5766e-01, time/batch = 0.7134s	
1098/22750 (epoch 2.413), train_loss = 2.03934812, grad/param norm = 2.8793e-01, time/batch = 0.7204s	
1099/22750 (epoch 2.415), train_loss = 1.84315176, grad/param norm = 2.9075e-01, time/batch = 0.7122s	
1100/22750 (epoch 2.418), train_loss = 1.86351482, grad/param norm = 2.3435e-01, time/batch = 0.7237s	
1101/22750 (epoch 2.420), train_loss = 2.21253356, grad/param norm = 2.7073e-01, time/batch = 0.7162s	
1102/22750 (epoch 2.422), train_loss = 2.34219618, grad/param norm = 2.5218e-01, time/batch = 0.7084s	
1103/22750 (epoch 2.424), train_loss = 2.32159898, grad/param norm = 2.4617e-01, time/batch = 0.7080s	
1104/22750 (epoch 2.426), train_loss = 2.30332236, grad/param norm = 2.2967e-01, time/batch = 0.7106s	
1105/22750 (epoch 2.429), train_loss = 1.83418131, grad/param norm = 2.3564e-01, time/batch = 0.7081s	
1106/22750 (epoch 2.431), train_loss = 1.86267733, grad/param norm = 2.6598e-01, time/batch = 0.7084s	
1107/22750 (epoch 2.433), train_loss = 1.91442875, grad/param norm = 2.4524e-01, time/batch = 0.7100s	
1108/22750 (epoch 2.435), train_loss = 1.86319171, grad/param norm = 2.6970e-01, time/batch = 0.7076s	
1109/22750 (epoch 2.437), train_loss = 1.80106245, grad/param norm = 2.4270e-01, time/batch = 0.7208s	
1110/22750 (epoch 2.440), train_loss = 2.31824144, grad/param norm = 3.1793e-01, time/batch = 0.7090s	
1111/22750 (epoch 2.442), train_loss = 2.08313524, grad/param norm = 2.9952e-01, time/batch = 0.7146s	
1112/22750 (epoch 2.444), train_loss = 2.27198993, grad/param norm = 4.7018e-01, time/batch = 0.7150s	
1113/22750 (epoch 2.446), train_loss = 2.18169690, grad/param norm = 3.9281e-01, time/batch = 0.7179s	
1114/22750 (epoch 2.448), train_loss = 2.29006359, grad/param norm = 3.0213e-01, time/batch = 0.7171s	
1115/22750 (epoch 2.451), train_loss = 2.20419518, grad/param norm = 2.7259e-01, time/batch = 0.7112s	
1116/22750 (epoch 2.453), train_loss = 2.30209687, grad/param norm = 2.7478e-01, time/batch = 0.7110s	
1117/22750 (epoch 2.455), train_loss = 2.28882189, grad/param norm = 2.5493e-01, time/batch = 0.7124s	
1118/22750 (epoch 2.457), train_loss = 2.24877653, grad/param norm = 3.0810e-01, time/batch = 0.7147s	
1119/22750 (epoch 2.459), train_loss = 2.09022379, grad/param norm = 2.5951e-01, time/batch = 0.7183s	
1120/22750 (epoch 2.462), train_loss = 1.97476239, grad/param norm = 2.2022e-01, time/batch = 0.7119s	
1121/22750 (epoch 2.464), train_loss = 1.88352510, grad/param norm = 2.3851e-01, time/batch = 0.7127s	
1122/22750 (epoch 2.466), train_loss = 2.22550789, grad/param norm = 2.2663e-01, time/batch = 0.7145s	
1123/22750 (epoch 2.468), train_loss = 2.06205647, grad/param norm = 2.8514e-01, time/batch = 0.7116s	
1124/22750 (epoch 2.470), train_loss = 2.15199283, grad/param norm = 2.6929e-01, time/batch = 0.7123s	
1125/22750 (epoch 2.473), train_loss = 2.08760949, grad/param norm = 2.4194e-01, time/batch = 0.7094s	
1126/22750 (epoch 2.475), train_loss = 2.18976117, grad/param norm = 2.3251e-01, time/batch = 0.7163s	
1127/22750 (epoch 2.477), train_loss = 1.91889422, grad/param norm = 2.6215e-01, time/batch = 0.7105s	
1128/22750 (epoch 2.479), train_loss = 2.02252120, grad/param norm = 2.3279e-01, time/batch = 0.7120s	
1129/22750 (epoch 2.481), train_loss = 1.91635174, grad/param norm = 2.8382e-01, time/batch = 0.7142s	
1130/22750 (epoch 2.484), train_loss = 1.76947175, grad/param norm = 3.0373e-01, time/batch = 0.7155s	
1131/22750 (epoch 2.486), train_loss = 2.03120937, grad/param norm = 3.2450e-01, time/batch = 0.7218s	
1132/22750 (epoch 2.488), train_loss = 1.67763980, grad/param norm = 3.2657e-01, time/batch = 0.7190s	
1133/22750 (epoch 2.490), train_loss = 1.91445730, grad/param norm = 3.1739e-01, time/batch = 0.7233s	
1134/22750 (epoch 2.492), train_loss = 2.16181365, grad/param norm = 3.1016e-01, time/batch = 0.7241s	
1135/22750 (epoch 2.495), train_loss = 2.01077127, grad/param norm = 2.9949e-01, time/batch = 0.7234s	
1136/22750 (epoch 2.497), train_loss = 2.10713869, grad/param norm = 2.8696e-01, time/batch = 0.7180s	
1137/22750 (epoch 2.499), train_loss = 1.98598978, grad/param norm = 2.4600e-01, time/batch = 0.7214s	
1138/22750 (epoch 2.501), train_loss = 1.97773709, grad/param norm = 2.2779e-01, time/batch = 0.7221s	
1139/22750 (epoch 2.503), train_loss = 2.08214732, grad/param norm = 2.4666e-01, time/batch = 0.7213s	
1140/22750 (epoch 2.505), train_loss = 1.90198310, grad/param norm = 2.7255e-01, time/batch = 0.7214s	
1141/22750 (epoch 2.508), train_loss = 1.81949327, grad/param norm = 2.5940e-01, time/batch = 0.7214s	
1142/22750 (epoch 2.510), train_loss = 1.89648310, grad/param norm = 2.6555e-01, time/batch = 0.7131s	
1143/22750 (epoch 2.512), train_loss = 1.92090895, grad/param norm = 2.4053e-01, time/batch = 0.7137s	
1144/22750 (epoch 2.514), train_loss = 2.02784697, grad/param norm = 2.8211e-01, time/batch = 0.7112s	
1145/22750 (epoch 2.516), train_loss = 1.83789093, grad/param norm = 2.4834e-01, time/batch = 0.7120s	
1146/22750 (epoch 2.519), train_loss = 2.02685899, grad/param norm = 2.6551e-01, time/batch = 0.7088s	
1147/22750 (epoch 2.521), train_loss = 1.81659509, grad/param norm = 2.4532e-01, time/batch = 0.7124s	
1148/22750 (epoch 2.523), train_loss = 1.85366404, grad/param norm = 2.5826e-01, time/batch = 0.7124s	
1149/22750 (epoch 2.525), train_loss = 2.13396122, grad/param norm = 2.6949e-01, time/batch = 0.7095s	
1150/22750 (epoch 2.527), train_loss = 1.99520799, grad/param norm = 2.4633e-01, time/batch = 0.7093s	
1151/22750 (epoch 2.530), train_loss = 1.90873759, grad/param norm = 3.0287e-01, time/batch = 0.7100s	
1152/22750 (epoch 2.532), train_loss = 1.99756267, grad/param norm = 2.8602e-01, time/batch = 0.7125s	
1153/22750 (epoch 2.534), train_loss = 2.13513725, grad/param norm = 2.8694e-01, time/batch = 0.7093s	
1154/22750 (epoch 2.536), train_loss = 2.07675019, grad/param norm = 2.8516e-01, time/batch = 0.7170s	
1155/22750 (epoch 2.538), train_loss = 2.16774464, grad/param norm = 2.4166e-01, time/batch = 0.7164s	
1156/22750 (epoch 2.541), train_loss = 1.72075729, grad/param norm = 2.3628e-01, time/batch = 0.7128s	
1157/22750 (epoch 2.543), train_loss = 1.72711533, grad/param norm = 2.3242e-01, time/batch = 0.7104s	
1158/22750 (epoch 2.545), train_loss = 2.15274370, grad/param norm = 2.6297e-01, time/batch = 0.7226s	
1159/22750 (epoch 2.547), train_loss = 1.81276626, grad/param norm = 2.1859e-01, time/batch = 0.7159s	
1160/22750 (epoch 2.549), train_loss = 1.83052790, grad/param norm = 2.5807e-01, time/batch = 0.7083s	
1161/22750 (epoch 2.552), train_loss = 2.11521335, grad/param norm = 2.7692e-01, time/batch = 0.7174s	
1162/22750 (epoch 2.554), train_loss = 2.06497755, grad/param norm = 2.5471e-01, time/batch = 0.7106s	
1163/22750 (epoch 2.556), train_loss = 2.00189027, grad/param norm = 2.6926e-01, time/batch = 0.7156s	
1164/22750 (epoch 2.558), train_loss = 2.16367163, grad/param norm = 2.6241e-01, time/batch = 0.7132s	
1165/22750 (epoch 2.560), train_loss = 1.88997880, grad/param norm = 2.3109e-01, time/batch = 0.7142s	
1166/22750 (epoch 2.563), train_loss = 2.00883177, grad/param norm = 2.5352e-01, time/batch = 0.7088s	
1167/22750 (epoch 2.565), train_loss = 2.20215395, grad/param norm = 2.4521e-01, time/batch = 0.7032s	
1168/22750 (epoch 2.567), train_loss = 1.97850843, grad/param norm = 2.4588e-01, time/batch = 0.7129s	
1169/22750 (epoch 2.569), train_loss = 1.98393181, grad/param norm = 2.7052e-01, time/batch = 0.7322s	
1170/22750 (epoch 2.571), train_loss = 2.03463497, grad/param norm = 2.7142e-01, time/batch = 0.7337s	
1171/22750 (epoch 2.574), train_loss = 1.82640975, grad/param norm = 2.6277e-01, time/batch = 0.7334s	
1172/22750 (epoch 2.576), train_loss = 2.00783675, grad/param norm = 2.4405e-01, time/batch = 0.7112s	
1173/22750 (epoch 2.578), train_loss = 1.82758963, grad/param norm = 2.6488e-01, time/batch = 0.7097s	
1174/22750 (epoch 2.580), train_loss = 2.04608249, grad/param norm = 2.5031e-01, time/batch = 0.7042s	
1175/22750 (epoch 2.582), train_loss = 1.82572890, grad/param norm = 2.7706e-01, time/batch = 0.7076s	
1176/22750 (epoch 2.585), train_loss = 1.70678928, grad/param norm = 2.3000e-01, time/batch = 0.7081s	
1177/22750 (epoch 2.587), train_loss = 1.86436341, grad/param norm = 2.5529e-01, time/batch = 0.7080s	
1178/22750 (epoch 2.589), train_loss = 1.87971974, grad/param norm = 2.5975e-01, time/batch = 0.7185s	
1179/22750 (epoch 2.591), train_loss = 2.04112343, grad/param norm = 2.7551e-01, time/batch = 0.7052s	
1180/22750 (epoch 2.593), train_loss = 2.15232382, grad/param norm = 2.5687e-01, time/batch = 0.7140s	
1181/22750 (epoch 2.596), train_loss = 2.06941316, grad/param norm = 2.1949e-01, time/batch = 0.7120s	
1182/22750 (epoch 2.598), train_loss = 2.17009576, grad/param norm = 2.5463e-01, time/batch = 0.7150s	
1183/22750 (epoch 2.600), train_loss = 1.95842824, grad/param norm = 2.4994e-01, time/batch = 0.7103s	
1184/22750 (epoch 2.602), train_loss = 1.75158623, grad/param norm = 2.4474e-01, time/batch = 0.7146s	
1185/22750 (epoch 2.604), train_loss = 1.95768201, grad/param norm = 2.7223e-01, time/batch = 0.7131s	
1186/22750 (epoch 2.607), train_loss = 1.58296321, grad/param norm = 2.1663e-01, time/batch = 0.7018s	
1187/22750 (epoch 2.609), train_loss = 1.67451226, grad/param norm = 2.2300e-01, time/batch = 0.7043s	
1188/22750 (epoch 2.611), train_loss = 1.91137364, grad/param norm = 2.5049e-01, time/batch = 0.7041s	
1189/22750 (epoch 2.613), train_loss = 1.81553510, grad/param norm = 2.7350e-01, time/batch = 0.7081s	
1190/22750 (epoch 2.615), train_loss = 1.93735157, grad/param norm = 2.7016e-01, time/batch = 0.7040s	
1191/22750 (epoch 2.618), train_loss = 1.93376507, grad/param norm = 2.9417e-01, time/batch = 0.7078s	
1192/22750 (epoch 2.620), train_loss = 1.95041796, grad/param norm = 2.6303e-01, time/batch = 0.7036s	
1193/22750 (epoch 2.622), train_loss = 1.83539130, grad/param norm = 3.4180e-01, time/batch = 0.7031s	
1194/22750 (epoch 2.624), train_loss = 2.17547404, grad/param norm = 2.9535e-01, time/batch = 0.7015s	
1195/22750 (epoch 2.626), train_loss = 2.01556455, grad/param norm = 3.4890e-01, time/batch = 0.7002s	
1196/22750 (epoch 2.629), train_loss = 2.05312135, grad/param norm = 3.5855e-01, time/batch = 0.7032s	
1197/22750 (epoch 2.631), train_loss = 2.09501569, grad/param norm = 2.8775e-01, time/batch = 0.7112s	
1198/22750 (epoch 2.633), train_loss = 1.76407449, grad/param norm = 2.5924e-01, time/batch = 0.7070s	
1199/22750 (epoch 2.635), train_loss = 2.14069431, grad/param norm = 2.4303e-01, time/batch = 0.7214s	
1200/22750 (epoch 2.637), train_loss = 2.09592204, grad/param norm = 2.7403e-01, time/batch = 0.7235s	
1201/22750 (epoch 2.640), train_loss = 2.22287778, grad/param norm = 2.6389e-01, time/batch = 0.7154s	
1202/22750 (epoch 2.642), train_loss = 2.12873667, grad/param norm = 2.5071e-01, time/batch = 0.7070s	
1203/22750 (epoch 2.644), train_loss = 1.97935561, grad/param norm = 2.4846e-01, time/batch = 0.7074s	
1204/22750 (epoch 2.646), train_loss = 2.01998715, grad/param norm = 2.8618e-01, time/batch = 0.7018s	
1205/22750 (epoch 2.648), train_loss = 2.00692170, grad/param norm = 2.5727e-01, time/batch = 0.7051s	
1206/22750 (epoch 2.651), train_loss = 2.17308558, grad/param norm = 2.5542e-01, time/batch = 0.7054s	
1207/22750 (epoch 2.653), train_loss = 1.97474539, grad/param norm = 2.7249e-01, time/batch = 0.7019s	
1208/22750 (epoch 2.655), train_loss = 2.00599763, grad/param norm = 3.0564e-01, time/batch = 0.7114s	
1209/22750 (epoch 2.657), train_loss = 2.19135031, grad/param norm = 2.4407e-01, time/batch = 0.7056s	
1210/22750 (epoch 2.659), train_loss = 2.17957850, grad/param norm = 2.3077e-01, time/batch = 0.7159s	
1211/22750 (epoch 2.662), train_loss = 2.31026941, grad/param norm = 2.4342e-01, time/batch = 0.7115s	
1212/22750 (epoch 2.664), train_loss = 2.06006366, grad/param norm = 2.8419e-01, time/batch = 0.7084s	
1213/22750 (epoch 2.666), train_loss = 1.95888855, grad/param norm = 3.1039e-01, time/batch = 0.7126s	
1214/22750 (epoch 2.668), train_loss = 1.99575428, grad/param norm = 2.4601e-01, time/batch = 0.7207s	
1215/22750 (epoch 2.670), train_loss = 2.04943548, grad/param norm = 2.5736e-01, time/batch = 0.7179s	
1216/22750 (epoch 2.673), train_loss = 2.10693303, grad/param norm = 2.7757e-01, time/batch = 0.7072s	
1217/22750 (epoch 2.675), train_loss = 2.45206322, grad/param norm = 3.8739e-01, time/batch = 0.7087s	
1218/22750 (epoch 2.677), train_loss = 2.19254101, grad/param norm = 3.4111e-01, time/batch = 0.7077s	
1219/22750 (epoch 2.679), train_loss = 2.28119593, grad/param norm = 2.5304e-01, time/batch = 0.7110s	
1220/22750 (epoch 2.681), train_loss = 2.10875299, grad/param norm = 2.6336e-01, time/batch = 0.7066s	
1221/22750 (epoch 2.684), train_loss = 2.15722202, grad/param norm = 2.5519e-01, time/batch = 0.7063s	
1222/22750 (epoch 2.686), train_loss = 2.08688734, grad/param norm = 2.7356e-01, time/batch = 0.7096s	
1223/22750 (epoch 2.688), train_loss = 2.12837731, grad/param norm = 2.6213e-01, time/batch = 0.7088s	
1224/22750 (epoch 2.690), train_loss = 2.04661274, grad/param norm = 2.4778e-01, time/batch = 0.7122s	
1225/22750 (epoch 2.692), train_loss = 2.16884810, grad/param norm = 2.3244e-01, time/batch = 0.7108s	
1226/22750 (epoch 2.695), train_loss = 1.99266967, grad/param norm = 2.3420e-01, time/batch = 0.7095s	
1227/22750 (epoch 2.697), train_loss = 1.89763726, grad/param norm = 2.5017e-01, time/batch = 0.7113s	
1228/22750 (epoch 2.699), train_loss = 2.08182114, grad/param norm = 2.5680e-01, time/batch = 0.7099s	
1229/22750 (epoch 2.701), train_loss = 1.97555973, grad/param norm = 2.2346e-01, time/batch = 0.7264s	
1230/22750 (epoch 2.703), train_loss = 2.03942195, grad/param norm = 2.4924e-01, time/batch = 0.7269s	
1231/22750 (epoch 2.705), train_loss = 1.83266162, grad/param norm = 2.8535e-01, time/batch = 0.7325s	
1232/22750 (epoch 2.708), train_loss = 2.06789145, grad/param norm = 2.0789e-01, time/batch = 0.7158s	
1233/22750 (epoch 2.710), train_loss = 1.76850888, grad/param norm = 2.4606e-01, time/batch = 0.7079s	
1234/22750 (epoch 2.712), train_loss = 1.88521366, grad/param norm = 2.2939e-01, time/batch = 0.7098s	
1235/22750 (epoch 2.714), train_loss = 1.81203913, grad/param norm = 2.5880e-01, time/batch = 0.7074s	
1236/22750 (epoch 2.716), train_loss = 1.95730687, grad/param norm = 2.6561e-01, time/batch = 0.7077s	
1237/22750 (epoch 2.719), train_loss = 2.12930700, grad/param norm = 3.1443e-01, time/batch = 0.7080s	
1238/22750 (epoch 2.721), train_loss = 2.05063483, grad/param norm = 2.9126e-01, time/batch = 0.7145s	
1239/22750 (epoch 2.723), train_loss = 1.97067321, grad/param norm = 2.5058e-01, time/batch = 0.7113s	
1240/22750 (epoch 2.725), train_loss = 1.95254826, grad/param norm = 2.4267e-01, time/batch = 0.7116s	
1241/22750 (epoch 2.727), train_loss = 1.87647298, grad/param norm = 2.3063e-01, time/batch = 0.7280s	
1242/22750 (epoch 2.730), train_loss = 1.85234292, grad/param norm = 2.1994e-01, time/batch = 0.7320s	
1243/22750 (epoch 2.732), train_loss = 2.02294123, grad/param norm = 2.4642e-01, time/batch = 0.7335s	
1244/22750 (epoch 2.734), train_loss = 1.61821647, grad/param norm = 3.3003e-01, time/batch = 0.7326s	
1245/22750 (epoch 2.736), train_loss = 1.93153036, grad/param norm = 2.9569e-01, time/batch = 0.7151s	
1246/22750 (epoch 2.738), train_loss = 1.84946003, grad/param norm = 2.7761e-01, time/batch = 0.7147s	
1247/22750 (epoch 2.741), train_loss = 2.06771137, grad/param norm = 2.3047e-01, time/batch = 0.7170s	
1248/22750 (epoch 2.743), train_loss = 2.09283867, grad/param norm = 2.4335e-01, time/batch = 0.7308s	
1249/22750 (epoch 2.745), train_loss = 1.81192299, grad/param norm = 2.5256e-01, time/batch = 0.7144s	
1250/22750 (epoch 2.747), train_loss = 1.87865103, grad/param norm = 2.5347e-01, time/batch = 0.7109s	
1251/22750 (epoch 2.749), train_loss = 2.11114332, grad/param norm = 2.9089e-01, time/batch = 0.7079s	
1252/22750 (epoch 2.752), train_loss = 1.86834240, grad/param norm = 2.2550e-01, time/batch = 0.7205s	
1253/22750 (epoch 2.754), train_loss = 2.05520759, grad/param norm = 3.1985e-01, time/batch = 0.7230s	
1254/22750 (epoch 2.756), train_loss = 1.81076641, grad/param norm = 3.7953e-01, time/batch = 0.7535s	
1255/22750 (epoch 2.758), train_loss = 1.75616395, grad/param norm = 2.6537e-01, time/batch = 0.7345s	
1256/22750 (epoch 2.760), train_loss = 2.07647333, grad/param norm = 2.4803e-01, time/batch = 0.7403s	
1257/22750 (epoch 2.763), train_loss = 1.95897922, grad/param norm = 2.3989e-01, time/batch = 0.7294s	
1258/22750 (epoch 2.765), train_loss = 1.85190234, grad/param norm = 2.4038e-01, time/batch = 0.7244s	
1259/22750 (epoch 2.767), train_loss = 1.85928768, grad/param norm = 2.2039e-01, time/batch = 0.7220s	
1260/22750 (epoch 2.769), train_loss = 2.06470834, grad/param norm = 2.5843e-01, time/batch = 0.7168s	
1261/22750 (epoch 2.771), train_loss = 2.01120822, grad/param norm = 2.6278e-01, time/batch = 0.7153s	
1262/22750 (epoch 2.774), train_loss = 1.91158813, grad/param norm = 2.5006e-01, time/batch = 0.7134s	
1263/22750 (epoch 2.776), train_loss = 1.95247160, grad/param norm = 2.8779e-01, time/batch = 0.7128s	
1264/22750 (epoch 2.778), train_loss = 2.16284143, grad/param norm = 2.6106e-01, time/batch = 0.7127s	
1265/22750 (epoch 2.780), train_loss = 2.02494828, grad/param norm = 2.6790e-01, time/batch = 0.7150s	
1266/22750 (epoch 2.782), train_loss = 2.08097273, grad/param norm = 2.5287e-01, time/batch = 0.7188s	
1267/22750 (epoch 2.785), train_loss = 2.04006943, grad/param norm = 2.3902e-01, time/batch = 0.7196s	
1268/22750 (epoch 2.787), train_loss = 1.88571341, grad/param norm = 2.3961e-01, time/batch = 0.7146s	
1269/22750 (epoch 2.789), train_loss = 1.81244464, grad/param norm = 2.1818e-01, time/batch = 0.7131s	
1270/22750 (epoch 2.791), train_loss = 1.92612171, grad/param norm = 2.0930e-01, time/batch = 0.7114s	
1271/22750 (epoch 2.793), train_loss = 1.93766563, grad/param norm = 2.4266e-01, time/batch = 0.7158s	
1272/22750 (epoch 2.796), train_loss = 1.85216021, grad/param norm = 2.3621e-01, time/batch = 0.7134s	
1273/22750 (epoch 2.798), train_loss = 1.91436039, grad/param norm = 2.2700e-01, time/batch = 0.7174s	
1274/22750 (epoch 2.800), train_loss = 1.90932000, grad/param norm = 2.4211e-01, time/batch = 0.7168s	
1275/22750 (epoch 2.802), train_loss = 2.03619979, grad/param norm = 2.5571e-01, time/batch = 0.7102s	
1276/22750 (epoch 2.804), train_loss = 2.20085967, grad/param norm = 2.3123e-01, time/batch = 0.7125s	
1277/22750 (epoch 2.807), train_loss = 1.96877326, grad/param norm = 2.3379e-01, time/batch = 0.7076s	
1278/22750 (epoch 2.809), train_loss = 2.19495731, grad/param norm = 2.5011e-01, time/batch = 0.7133s	
1279/22750 (epoch 2.811), train_loss = 1.92836465, grad/param norm = 2.4065e-01, time/batch = 0.7125s	
1280/22750 (epoch 2.813), train_loss = 2.09868731, grad/param norm = 2.1444e-01, time/batch = 0.7143s	
1281/22750 (epoch 2.815), train_loss = 2.14749956, grad/param norm = 2.7613e-01, time/batch = 0.7137s	
1282/22750 (epoch 2.818), train_loss = 2.16540893, grad/param norm = 2.7914e-01, time/batch = 0.7134s	
1283/22750 (epoch 2.820), train_loss = 2.19969000, grad/param norm = 2.3737e-01, time/batch = 0.7085s	
1284/22750 (epoch 2.822), train_loss = 2.05124035, grad/param norm = 2.2932e-01, time/batch = 0.7109s	
1285/22750 (epoch 2.824), train_loss = 2.05547440, grad/param norm = 2.3955e-01, time/batch = 0.7115s	
1286/22750 (epoch 2.826), train_loss = 1.96537074, grad/param norm = 2.3882e-01, time/batch = 0.7115s	
1287/22750 (epoch 2.829), train_loss = 2.13502592, grad/param norm = 2.4409e-01, time/batch = 0.7115s	
1288/22750 (epoch 2.831), train_loss = 2.09956655, grad/param norm = 2.5452e-01, time/batch = 0.7055s	
1289/22750 (epoch 2.833), train_loss = 2.20292954, grad/param norm = 2.5328e-01, time/batch = 0.7060s	
1290/22750 (epoch 2.835), train_loss = 2.01584730, grad/param norm = 2.4045e-01, time/batch = 0.7117s	
1291/22750 (epoch 2.837), train_loss = 2.01710822, grad/param norm = 2.4967e-01, time/batch = 0.7094s	
1292/22750 (epoch 2.840), train_loss = 2.02474067, grad/param norm = 2.8422e-01, time/batch = 0.7151s	
1293/22750 (epoch 2.842), train_loss = 1.97823111, grad/param norm = 2.6196e-01, time/batch = 0.7175s	
1294/22750 (epoch 2.844), train_loss = 2.19142089, grad/param norm = 2.7733e-01, time/batch = 0.7155s	
1295/22750 (epoch 2.846), train_loss = 1.88226099, grad/param norm = 2.1525e-01, time/batch = 0.7139s	
1296/22750 (epoch 2.848), train_loss = 1.82876320, grad/param norm = 2.8710e-01, time/batch = 0.7108s	
1297/22750 (epoch 2.851), train_loss = 1.91975162, grad/param norm = 3.0929e-01, time/batch = 0.7137s	
1298/22750 (epoch 2.853), train_loss = 1.91545358, grad/param norm = 2.5138e-01, time/batch = 0.7128s	
1299/22750 (epoch 2.855), train_loss = 1.76836281, grad/param norm = 2.2226e-01, time/batch = 0.7179s	
1300/22750 (epoch 2.857), train_loss = 1.98261727, grad/param norm = 2.1720e-01, time/batch = 0.7167s	
1301/22750 (epoch 2.859), train_loss = 1.99964562, grad/param norm = 2.4358e-01, time/batch = 0.7162s	
1302/22750 (epoch 2.862), train_loss = 2.10325625, grad/param norm = 2.4720e-01, time/batch = 0.7122s	
1303/22750 (epoch 2.864), train_loss = 2.00729724, grad/param norm = 2.3641e-01, time/batch = 0.7107s	
1304/22750 (epoch 2.866), train_loss = 1.95953795, grad/param norm = 2.2982e-01, time/batch = 0.7066s	
1305/22750 (epoch 2.868), train_loss = 2.00096506, grad/param norm = 2.5098e-01, time/batch = 0.7132s	
1306/22750 (epoch 2.870), train_loss = 1.74359073, grad/param norm = 2.3307e-01, time/batch = 0.7164s	
1307/22750 (epoch 2.873), train_loss = 1.92213422, grad/param norm = 2.2942e-01, time/batch = 0.7077s	
1308/22750 (epoch 2.875), train_loss = 1.99046454, grad/param norm = 2.3273e-01, time/batch = 0.7092s	
1309/22750 (epoch 2.877), train_loss = 1.79843177, grad/param norm = 2.1106e-01, time/batch = 0.7117s	
1310/22750 (epoch 2.879), train_loss = 2.11328254, grad/param norm = 2.8763e-01, time/batch = 0.7044s	
1311/22750 (epoch 2.881), train_loss = 2.04530373, grad/param norm = 3.2172e-01, time/batch = 0.7081s	
1312/22750 (epoch 2.884), train_loss = 2.00710787, grad/param norm = 2.9531e-01, time/batch = 0.7034s	
1313/22750 (epoch 2.886), train_loss = 2.06603608, grad/param norm = 2.6292e-01, time/batch = 0.7075s	
1314/22750 (epoch 2.888), train_loss = 2.01057053, grad/param norm = 2.5739e-01, time/batch = 0.7062s	
1315/22750 (epoch 2.890), train_loss = 1.99550293, grad/param norm = 2.8694e-01, time/batch = 0.7059s	
1316/22750 (epoch 2.892), train_loss = 2.39945852, grad/param norm = 3.1675e-01, time/batch = 0.7072s	
1317/22750 (epoch 2.895), train_loss = 2.12295799, grad/param norm = 2.6248e-01, time/batch = 0.7075s	
1318/22750 (epoch 2.897), train_loss = 2.06669256, grad/param norm = 2.4870e-01, time/batch = 0.7059s	
1319/22750 (epoch 2.899), train_loss = 2.05977623, grad/param norm = 2.3860e-01, time/batch = 0.7092s	
1320/22750 (epoch 2.901), train_loss = 2.13369944, grad/param norm = 2.2464e-01, time/batch = 0.7035s	
1321/22750 (epoch 2.903), train_loss = 1.99568081, grad/param norm = 2.3924e-01, time/batch = 0.7085s	
1322/22750 (epoch 2.905), train_loss = 1.95530532, grad/param norm = 2.0348e-01, time/batch = 0.7119s	
1323/22750 (epoch 2.908), train_loss = 1.97750813, grad/param norm = 2.7557e-01, time/batch = 0.7128s	
1324/22750 (epoch 2.910), train_loss = 1.80986185, grad/param norm = 2.6314e-01, time/batch = 0.7080s	
1325/22750 (epoch 2.912), train_loss = 1.81042438, grad/param norm = 2.5362e-01, time/batch = 0.7126s	
1326/22750 (epoch 2.914), train_loss = 1.84409094, grad/param norm = 2.4801e-01, time/batch = 0.7116s	
1327/22750 (epoch 2.916), train_loss = 1.73803693, grad/param norm = 2.2415e-01, time/batch = 0.7183s	
1328/22750 (epoch 2.919), train_loss = 1.82737850, grad/param norm = 2.3114e-01, time/batch = 0.7122s	
1329/22750 (epoch 2.921), train_loss = 1.58424203, grad/param norm = 2.2936e-01, time/batch = 0.7062s	
1330/22750 (epoch 2.923), train_loss = 1.91127301, grad/param norm = 2.3554e-01, time/batch = 0.7139s	
1331/22750 (epoch 2.925), train_loss = 1.91131835, grad/param norm = 2.2866e-01, time/batch = 0.7262s	
1332/22750 (epoch 2.927), train_loss = 1.68699228, grad/param norm = 2.5143e-01, time/batch = 0.7258s	
1333/22750 (epoch 2.930), train_loss = 1.79940144, grad/param norm = 2.9623e-01, time/batch = 0.7241s	
1334/22750 (epoch 2.932), train_loss = 2.19605315, grad/param norm = 2.7926e-01, time/batch = 0.7236s	
1335/22750 (epoch 2.934), train_loss = 1.61359712, grad/param norm = 2.3606e-01, time/batch = 0.7214s	
1336/22750 (epoch 2.936), train_loss = 2.07670372, grad/param norm = 2.8858e-01, time/batch = 0.7215s	
1337/22750 (epoch 2.938), train_loss = 1.95941870, grad/param norm = 2.6457e-01, time/batch = 0.7292s	
1338/22750 (epoch 2.941), train_loss = 2.32319269, grad/param norm = 2.9166e-01, time/batch = 0.7456s	
1339/22750 (epoch 2.943), train_loss = 2.05383600, grad/param norm = 2.7308e-01, time/batch = 0.7072s	
1340/22750 (epoch 2.945), train_loss = 1.98036831, grad/param norm = 2.4446e-01, time/batch = 0.7108s	
1341/22750 (epoch 2.947), train_loss = 2.02681229, grad/param norm = 2.7113e-01, time/batch = 0.7127s	
1342/22750 (epoch 2.949), train_loss = 1.81809908, grad/param norm = 2.6303e-01, time/batch = 0.7187s	
1343/22750 (epoch 2.952), train_loss = 1.86086774, grad/param norm = 2.2235e-01, time/batch = 0.7154s	
1344/22750 (epoch 2.954), train_loss = 1.85718601, grad/param norm = 2.4116e-01, time/batch = 0.7118s	
1345/22750 (epoch 2.956), train_loss = 1.95752863, grad/param norm = 2.3716e-01, time/batch = 0.7140s	
1346/22750 (epoch 2.958), train_loss = 1.92372301, grad/param norm = 2.3761e-01, time/batch = 0.7126s	
1347/22750 (epoch 2.960), train_loss = 1.95740391, grad/param norm = 2.4151e-01, time/batch = 0.7255s	
1348/22750 (epoch 2.963), train_loss = 2.01574939, grad/param norm = 2.4203e-01, time/batch = 0.7076s	
1349/22750 (epoch 2.965), train_loss = 1.99467557, grad/param norm = 2.3282e-01, time/batch = 0.7102s	
1350/22750 (epoch 2.967), train_loss = 2.01490957, grad/param norm = 2.5219e-01, time/batch = 0.7111s	
1351/22750 (epoch 2.969), train_loss = 1.94072849, grad/param norm = 2.2707e-01, time/batch = 0.7179s	
1352/22750 (epoch 2.971), train_loss = 1.90643271, grad/param norm = 2.1265e-01, time/batch = 0.7155s	
1353/22750 (epoch 2.974), train_loss = 1.96526454, grad/param norm = 2.6146e-01, time/batch = 0.7080s	
1354/22750 (epoch 2.976), train_loss = 2.05789970, grad/param norm = 2.3749e-01, time/batch = 0.7087s	
1355/22750 (epoch 2.978), train_loss = 1.87454312, grad/param norm = 2.6988e-01, time/batch = 0.7094s	
1356/22750 (epoch 2.980), train_loss = 2.02198301, grad/param norm = 2.5985e-01, time/batch = 0.7236s	
1357/22750 (epoch 2.982), train_loss = 1.88566659, grad/param norm = 2.3960e-01, time/batch = 0.7268s	
1358/22750 (epoch 2.985), train_loss = 2.16804425, grad/param norm = 2.7097e-01, time/batch = 0.7111s	
1359/22750 (epoch 2.987), train_loss = 1.77491657, grad/param norm = 2.6628e-01, time/batch = 0.7121s	
1360/22750 (epoch 2.989), train_loss = 1.83169177, grad/param norm = 2.0800e-01, time/batch = 0.7056s	
1361/22750 (epoch 2.991), train_loss = 2.03016915, grad/param norm = 2.3040e-01, time/batch = 0.7083s	
1362/22750 (epoch 2.993), train_loss = 1.98704070, grad/param norm = 2.5204e-01, time/batch = 0.7096s	
1363/22750 (epoch 2.996), train_loss = 1.91101840, grad/param norm = 2.5600e-01, time/batch = 0.7340s	
1364/22750 (epoch 2.998), train_loss = 2.10125385, grad/param norm = 2.2511e-01, time/batch = 0.7241s	
1365/22750 (epoch 3.000), train_loss = 2.07166339, grad/param norm = 2.4527e-01, time/batch = 0.7163s	
1366/22750 (epoch 3.002), train_loss = 2.11099312, grad/param norm = 2.5851e-01, time/batch = 0.7090s	
1367/22750 (epoch 3.004), train_loss = 2.01083816, grad/param norm = 3.2674e-01, time/batch = 0.7099s	
1368/22750 (epoch 3.007), train_loss = 2.08391663, grad/param norm = 3.2219e-01, time/batch = 0.7080s	
1369/22750 (epoch 3.009), train_loss = 2.20604016, grad/param norm = 2.6909e-01, time/batch = 0.7151s	
1370/22750 (epoch 3.011), train_loss = 2.13255362, grad/param norm = 2.7216e-01, time/batch = 0.7087s	
1371/22750 (epoch 3.013), train_loss = 2.05221218, grad/param norm = 2.5765e-01, time/batch = 0.7154s	
1372/22750 (epoch 3.015), train_loss = 2.04379728, grad/param norm = 2.3607e-01, time/batch = 0.7054s	
1373/22750 (epoch 3.018), train_loss = 1.98330703, grad/param norm = 2.3837e-01, time/batch = 0.7138s	
1374/22750 (epoch 3.020), train_loss = 2.04843213, grad/param norm = 2.3537e-01, time/batch = 0.7117s	
1375/22750 (epoch 3.022), train_loss = 1.94402214, grad/param norm = 2.1849e-01, time/batch = 0.7105s	
1376/22750 (epoch 3.024), train_loss = 1.93152157, grad/param norm = 2.4688e-01, time/batch = 0.7100s	
1377/22750 (epoch 3.026), train_loss = 2.14796514, grad/param norm = 2.8855e-01, time/batch = 0.7126s	
1378/22750 (epoch 3.029), train_loss = 1.75853363, grad/param norm = 2.3951e-01, time/batch = 0.7106s	
1379/22750 (epoch 3.031), train_loss = 2.20887175, grad/param norm = 2.3528e-01, time/batch = 0.7116s	
1380/22750 (epoch 3.033), train_loss = 1.98447669, grad/param norm = 2.2217e-01, time/batch = 0.7109s	
1381/22750 (epoch 3.035), train_loss = 2.06120064, grad/param norm = 2.4091e-01, time/batch = 0.7104s	
1382/22750 (epoch 3.037), train_loss = 2.15375959, grad/param norm = 2.6649e-01, time/batch = 0.7124s	
1383/22750 (epoch 3.040), train_loss = 1.89021354, grad/param norm = 2.5778e-01, time/batch = 0.7103s	
1384/22750 (epoch 3.042), train_loss = 2.06005337, grad/param norm = 2.3862e-01, time/batch = 0.7148s	
1385/22750 (epoch 3.044), train_loss = 1.86756956, grad/param norm = 2.5715e-01, time/batch = 0.7174s	
1386/22750 (epoch 3.046), train_loss = 1.98151372, grad/param norm = 2.8726e-01, time/batch = 0.7290s	
1387/22750 (epoch 3.048), train_loss = 1.96844784, grad/param norm = 2.8809e-01, time/batch = 0.7145s	
1388/22750 (epoch 3.051), train_loss = 2.06576841, grad/param norm = 2.5790e-01, time/batch = 0.7081s	
1389/22750 (epoch 3.053), train_loss = 1.77949177, grad/param norm = 2.4597e-01, time/batch = 0.7071s	
1390/22750 (epoch 3.055), train_loss = 2.05264971, grad/param norm = 2.5701e-01, time/batch = 0.7089s	
1391/22750 (epoch 3.057), train_loss = 2.02654086, grad/param norm = 2.7688e-01, time/batch = 0.7130s	
1392/22750 (epoch 3.059), train_loss = 1.69678958, grad/param norm = 2.7966e-01, time/batch = 0.7078s	
1393/22750 (epoch 3.062), train_loss = 1.79346562, grad/param norm = 2.5195e-01, time/batch = 0.7006s	
1394/22750 (epoch 3.064), train_loss = 2.01078100, grad/param norm = 2.5226e-01, time/batch = 0.7020s	
1395/22750 (epoch 3.066), train_loss = 1.75309890, grad/param norm = 2.1540e-01, time/batch = 0.7049s	
1396/22750 (epoch 3.068), train_loss = 1.77711472, grad/param norm = 2.3249e-01, time/batch = 0.7101s	
1397/22750 (epoch 3.070), train_loss = 1.67002033, grad/param norm = 2.2850e-01, time/batch = 0.7048s	
1398/22750 (epoch 3.073), train_loss = 1.87969800, grad/param norm = 2.8082e-01, time/batch = 0.7083s	
1399/22750 (epoch 3.075), train_loss = 1.97145344, grad/param norm = 2.2577e-01, time/batch = 0.7057s	
1400/22750 (epoch 3.077), train_loss = 1.59610168, grad/param norm = 2.2406e-01, time/batch = 0.7035s	
1401/22750 (epoch 3.079), train_loss = 1.89191650, grad/param norm = 2.3568e-01, time/batch = 0.7077s	
1402/22750 (epoch 3.081), train_loss = 1.93298795, grad/param norm = 2.5864e-01, time/batch = 0.6993s	
1403/22750 (epoch 3.084), train_loss = 1.84145471, grad/param norm = 2.4296e-01, time/batch = 0.7043s	
1404/22750 (epoch 3.086), train_loss = 1.84984684, grad/param norm = 2.4704e-01, time/batch = 0.7052s	
1405/22750 (epoch 3.088), train_loss = 1.90272886, grad/param norm = 2.3936e-01, time/batch = 0.7109s	
1406/22750 (epoch 3.090), train_loss = 1.89341320, grad/param norm = 2.4021e-01, time/batch = 0.7095s	
1407/22750 (epoch 3.092), train_loss = 2.04821875, grad/param norm = 2.3403e-01, time/batch = 0.7151s	
1408/22750 (epoch 3.095), train_loss = 1.80003768, grad/param norm = 2.4712e-01, time/batch = 0.7058s	
1409/22750 (epoch 3.097), train_loss = 1.85674983, grad/param norm = 2.2927e-01, time/batch = 0.7167s	
1410/22750 (epoch 3.099), train_loss = 2.02681096, grad/param norm = 2.8365e-01, time/batch = 0.7234s	
1411/22750 (epoch 3.101), train_loss = 1.97020918, grad/param norm = 2.5562e-01, time/batch = 0.7201s	
1412/22750 (epoch 3.103), train_loss = 1.81882939, grad/param norm = 2.2922e-01, time/batch = 0.7033s	
1413/22750 (epoch 3.105), train_loss = 2.17408101, grad/param norm = 2.5770e-01, time/batch = 0.7019s	
1414/22750 (epoch 3.108), train_loss = 1.85322139, grad/param norm = 2.2716e-01, time/batch = 0.7017s	
1415/22750 (epoch 3.110), train_loss = 1.90385010, grad/param norm = 2.5068e-01, time/batch = 0.7183s	
1416/22750 (epoch 3.112), train_loss = 1.63424856, grad/param norm = 2.1678e-01, time/batch = 0.7232s	
1417/22750 (epoch 3.114), train_loss = 1.64714332, grad/param norm = 2.2826e-01, time/batch = 0.7066s	
1418/22750 (epoch 3.116), train_loss = 1.75377555, grad/param norm = 3.1384e-01, time/batch = 0.7075s	
1419/22750 (epoch 3.119), train_loss = 1.84794781, grad/param norm = 2.4053e-01, time/batch = 0.7148s	
1420/22750 (epoch 3.121), train_loss = 2.04356873, grad/param norm = 2.4341e-01, time/batch = 0.7224s	
1421/22750 (epoch 3.123), train_loss = 1.85150121, grad/param norm = 2.1173e-01, time/batch = 0.7246s	
1422/22750 (epoch 3.125), train_loss = 2.08175516, grad/param norm = 2.3444e-01, time/batch = 0.7228s	
1423/22750 (epoch 3.127), train_loss = 2.01712782, grad/param norm = 2.4730e-01, time/batch = 0.7104s	
1424/22750 (epoch 3.130), train_loss = 1.96964317, grad/param norm = 2.2803e-01, time/batch = 0.7111s	
1425/22750 (epoch 3.132), train_loss = 2.01094690, grad/param norm = 2.4199e-01, time/batch = 0.7283s	
1426/22750 (epoch 3.134), train_loss = 1.92175488, grad/param norm = 2.4736e-01, time/batch = 0.7241s	
1427/22750 (epoch 3.136), train_loss = 1.82039495, grad/param norm = 2.1981e-01, time/batch = 0.7103s	
1428/22750 (epoch 3.138), train_loss = 1.87166172, grad/param norm = 2.7511e-01, time/batch = 0.7115s	
1429/22750 (epoch 3.141), train_loss = 1.80128585, grad/param norm = 2.6403e-01, time/batch = 0.7112s	
1430/22750 (epoch 3.143), train_loss = 1.78020272, grad/param norm = 2.2932e-01, time/batch = 0.7128s	
1431/22750 (epoch 3.145), train_loss = 1.96059248, grad/param norm = 2.6792e-01, time/batch = 0.7133s	
1432/22750 (epoch 3.147), train_loss = 1.97648317, grad/param norm = 2.3450e-01, time/batch = 0.7096s	
1433/22750 (epoch 3.149), train_loss = 1.93938385, grad/param norm = 2.4558e-01, time/batch = 0.7117s	
1434/22750 (epoch 3.152), train_loss = 1.90599313, grad/param norm = 2.7014e-01, time/batch = 0.7118s	
1435/22750 (epoch 3.154), train_loss = 1.71987705, grad/param norm = 2.3554e-01, time/batch = 0.7318s	
1436/22750 (epoch 3.156), train_loss = 1.88339762, grad/param norm = 2.6192e-01, time/batch = 0.7199s	
1437/22750 (epoch 3.158), train_loss = 1.87791255, grad/param norm = 2.6978e-01, time/batch = 0.7100s	
1438/22750 (epoch 3.160), train_loss = 1.97418699, grad/param norm = 2.5280e-01, time/batch = 0.7023s	
1439/22750 (epoch 3.163), train_loss = 2.10263889, grad/param norm = 2.4229e-01, time/batch = 0.7163s	
1440/22750 (epoch 3.165), train_loss = 2.05532999, grad/param norm = 2.3626e-01, time/batch = 0.7171s	
1441/22750 (epoch 3.167), train_loss = 1.79963886, grad/param norm = 2.1917e-01, time/batch = 0.7069s	
1442/22750 (epoch 3.169), train_loss = 1.91731520, grad/param norm = 2.2350e-01, time/batch = 0.7020s	
1443/22750 (epoch 3.171), train_loss = 1.83054625, grad/param norm = 2.4165e-01, time/batch = 0.7046s	
1444/22750 (epoch 3.174), train_loss = 1.65802689, grad/param norm = 2.3267e-01, time/batch = 0.7108s	
1445/22750 (epoch 3.176), train_loss = 1.92343574, grad/param norm = 2.4461e-01, time/batch = 0.7280s	
1446/22750 (epoch 3.178), train_loss = 1.82901475, grad/param norm = 2.2221e-01, time/batch = 0.7065s	
1447/22750 (epoch 3.180), train_loss = 2.02270434, grad/param norm = 2.8569e-01, time/batch = 0.7063s	
1448/22750 (epoch 3.182), train_loss = 1.91843725, grad/param norm = 2.3418e-01, time/batch = 0.7149s	
1449/22750 (epoch 3.185), train_loss = 1.92082434, grad/param norm = 2.2698e-01, time/batch = 0.7310s	
1450/22750 (epoch 3.187), train_loss = 1.75844144, grad/param norm = 2.6295e-01, time/batch = 0.7206s	
1451/22750 (epoch 3.189), train_loss = 1.81377893, grad/param norm = 2.5917e-01, time/batch = 0.7245s	
1452/22750 (epoch 3.191), train_loss = 1.75328544, grad/param norm = 2.4242e-01, time/batch = 0.7238s	
1453/22750 (epoch 3.193), train_loss = 1.93250823, grad/param norm = 2.5699e-01, time/batch = 0.7228s	
1454/22750 (epoch 3.196), train_loss = 1.93798014, grad/param norm = 2.4709e-01, time/batch = 0.7246s	
1455/22750 (epoch 3.198), train_loss = 1.68116158, grad/param norm = 2.0815e-01, time/batch = 0.7179s	
1456/22750 (epoch 3.200), train_loss = 1.97221107, grad/param norm = 2.1370e-01, time/batch = 0.7081s	
1457/22750 (epoch 3.202), train_loss = 2.19831225, grad/param norm = 2.5364e-01, time/batch = 0.7129s	
1458/22750 (epoch 3.204), train_loss = 2.13095582, grad/param norm = 2.4445e-01, time/batch = 0.7038s	
1459/22750 (epoch 3.207), train_loss = 1.85493332, grad/param norm = 2.3876e-01, time/batch = 0.7032s	
1460/22750 (epoch 3.209), train_loss = 1.84665498, grad/param norm = 2.1150e-01, time/batch = 0.7037s	
1461/22750 (epoch 3.211), train_loss = 1.88096431, grad/param norm = 2.1183e-01, time/batch = 0.7101s	
1462/22750 (epoch 3.213), train_loss = 1.75392760, grad/param norm = 2.2562e-01, time/batch = 0.7087s	
1463/22750 (epoch 3.215), train_loss = 1.84674779, grad/param norm = 2.1468e-01, time/batch = 0.7082s	
1464/22750 (epoch 3.218), train_loss = 1.69729206, grad/param norm = 2.6384e-01, time/batch = 0.7074s	
1465/22750 (epoch 3.220), train_loss = 1.96606219, grad/param norm = 2.8063e-01, time/batch = 0.7050s	
1466/22750 (epoch 3.222), train_loss = 1.73244285, grad/param norm = 2.6016e-01, time/batch = 0.7091s	
1467/22750 (epoch 3.224), train_loss = 1.84365085, grad/param norm = 2.4507e-01, time/batch = 0.7045s	
1468/22750 (epoch 3.226), train_loss = 1.91364659, grad/param norm = 2.4155e-01, time/batch = 0.7104s	
1469/22750 (epoch 3.229), train_loss = 2.02101206, grad/param norm = 2.3224e-01, time/batch = 0.7071s	
1470/22750 (epoch 3.231), train_loss = 1.87957778, grad/param norm = 2.2071e-01, time/batch = 0.7027s	
1471/22750 (epoch 3.233), train_loss = 1.86561694, grad/param norm = 2.2746e-01, time/batch = 0.7057s	
1472/22750 (epoch 3.235), train_loss = 1.76431792, grad/param norm = 2.4230e-01, time/batch = 0.7054s	
1473/22750 (epoch 3.237), train_loss = 1.87420496, grad/param norm = 2.2928e-01, time/batch = 0.7069s	
1474/22750 (epoch 3.240), train_loss = 2.04816667, grad/param norm = 2.3632e-01, time/batch = 0.7085s	
1475/22750 (epoch 3.242), train_loss = 2.29662931, grad/param norm = 2.3728e-01, time/batch = 0.7092s	
1476/22750 (epoch 3.244), train_loss = 2.09598990, grad/param norm = 2.9982e-01, time/batch = 0.7045s	
1477/22750 (epoch 3.246), train_loss = 2.21336861, grad/param norm = 2.4262e-01, time/batch = 0.7058s	
1478/22750 (epoch 3.248), train_loss = 1.83931806, grad/param norm = 2.4958e-01, time/batch = 0.7039s	
1479/22750 (epoch 3.251), train_loss = 2.12449288, grad/param norm = 2.4383e-01, time/batch = 0.7039s	
1480/22750 (epoch 3.253), train_loss = 1.97214162, grad/param norm = 2.2572e-01, time/batch = 0.7046s	
1481/22750 (epoch 3.255), train_loss = 2.03331573, grad/param norm = 2.4092e-01, time/batch = 0.7056s	
1482/22750 (epoch 3.257), train_loss = 1.88560742, grad/param norm = 2.6205e-01, time/batch = 0.7038s	
1483/22750 (epoch 3.259), train_loss = 2.01512843, grad/param norm = 2.6785e-01, time/batch = 0.7037s	
1484/22750 (epoch 3.262), train_loss = 1.92670802, grad/param norm = 2.4648e-01, time/batch = 0.7006s	
1485/22750 (epoch 3.264), train_loss = 1.91476407, grad/param norm = 2.1072e-01, time/batch = 0.7035s	
1486/22750 (epoch 3.266), train_loss = 1.80499848, grad/param norm = 2.4379e-01, time/batch = 0.7049s	
1487/22750 (epoch 3.268), train_loss = 1.97500098, grad/param norm = 2.2588e-01, time/batch = 0.7060s	
1488/22750 (epoch 3.270), train_loss = 1.78647559, grad/param norm = 2.8197e-01, time/batch = 0.7084s	
1489/22750 (epoch 3.273), train_loss = 2.10008028, grad/param norm = 2.7964e-01, time/batch = 0.7083s	
1490/22750 (epoch 3.275), train_loss = 1.89215030, grad/param norm = 2.3425e-01, time/batch = 0.7088s	
1491/22750 (epoch 3.277), train_loss = 1.97631990, grad/param norm = 2.5110e-01, time/batch = 0.7088s	
1492/22750 (epoch 3.279), train_loss = 1.69691983, grad/param norm = 2.0677e-01, time/batch = 0.7026s	
1493/22750 (epoch 3.281), train_loss = 1.85269927, grad/param norm = 2.2007e-01, time/batch = 0.7057s	
1494/22750 (epoch 3.284), train_loss = 1.77842261, grad/param norm = 2.0433e-01, time/batch = 0.7059s	
1495/22750 (epoch 3.286), train_loss = 1.90609225, grad/param norm = 2.2463e-01, time/batch = 0.7190s	
1496/22750 (epoch 3.288), train_loss = 2.04305292, grad/param norm = 2.1621e-01, time/batch = 0.7117s	
1497/22750 (epoch 3.290), train_loss = 1.78878635, grad/param norm = 2.3799e-01, time/batch = 0.7105s	
1498/22750 (epoch 3.292), train_loss = 1.85697164, grad/param norm = 2.3539e-01, time/batch = 0.7058s	
1499/22750 (epoch 3.295), train_loss = 1.92538895, grad/param norm = 2.4674e-01, time/batch = 0.7094s	
1500/22750 (epoch 3.297), train_loss = 1.79746207, grad/param norm = 2.3318e-01, time/batch = 0.7087s	
1501/22750 (epoch 3.299), train_loss = 2.05251023, grad/param norm = 2.6565e-01, time/batch = 0.7104s	
1502/22750 (epoch 3.301), train_loss = 1.96113722, grad/param norm = 2.3197e-01, time/batch = 0.7095s	
1503/22750 (epoch 3.303), train_loss = 2.03551774, grad/param norm = 2.4491e-01, time/batch = 0.7087s	
1504/22750 (epoch 3.305), train_loss = 2.05278329, grad/param norm = 2.6255e-01, time/batch = 0.7256s	
1505/22750 (epoch 3.308), train_loss = 1.91457237, grad/param norm = 2.2436e-01, time/batch = 0.7283s	
1506/22750 (epoch 3.310), train_loss = 1.84968237, grad/param norm = 2.3503e-01, time/batch = 0.7387s	
1507/22750 (epoch 3.312), train_loss = 1.88138486, grad/param norm = 2.3039e-01, time/batch = 0.7178s	
1508/22750 (epoch 3.314), train_loss = 1.89411511, grad/param norm = 2.2806e-01, time/batch = 0.7139s	
1509/22750 (epoch 3.316), train_loss = 1.86353384, grad/param norm = 2.4658e-01, time/batch = 0.7094s	
1510/22750 (epoch 3.319), train_loss = 1.94765798, grad/param norm = 2.1701e-01, time/batch = 0.7130s	
1511/22750 (epoch 3.321), train_loss = 1.86192932, grad/param norm = 2.4901e-01, time/batch = 0.7134s	
1512/22750 (epoch 3.323), train_loss = 1.79045907, grad/param norm = 2.5121e-01, time/batch = 0.7135s	
1513/22750 (epoch 3.325), train_loss = 1.61841491, grad/param norm = 2.3664e-01, time/batch = 0.7143s	
1514/22750 (epoch 3.327), train_loss = 1.95636159, grad/param norm = 2.3116e-01, time/batch = 0.7159s	
1515/22750 (epoch 3.330), train_loss = 2.19196487, grad/param norm = 2.3965e-01, time/batch = 0.7115s	
1516/22750 (epoch 3.332), train_loss = 1.91932949, grad/param norm = 2.3426e-01, time/batch = 0.7058s	
1517/22750 (epoch 3.334), train_loss = 1.65018498, grad/param norm = 2.1620e-01, time/batch = 0.7092s	
1518/22750 (epoch 3.336), train_loss = 1.96989235, grad/param norm = 2.2879e-01, time/batch = 0.7098s	
1519/22750 (epoch 3.338), train_loss = 1.94240692, grad/param norm = 2.5114e-01, time/batch = 0.7093s	
1520/22750 (epoch 3.341), train_loss = 1.86683678, grad/param norm = 2.2053e-01, time/batch = 0.7074s	
1521/22750 (epoch 3.343), train_loss = 1.71062218, grad/param norm = 2.3270e-01, time/batch = 0.7080s	
1522/22750 (epoch 3.345), train_loss = 2.07501943, grad/param norm = 2.6341e-01, time/batch = 0.7102s	
1523/22750 (epoch 3.347), train_loss = 2.05386425, grad/param norm = 2.5555e-01, time/batch = 0.7079s	
1524/22750 (epoch 3.349), train_loss = 1.58763640, grad/param norm = 2.5614e-01, time/batch = 0.7082s	
1525/22750 (epoch 3.352), train_loss = 1.98219613, grad/param norm = 2.8895e-01, time/batch = 0.7078s	
1526/22750 (epoch 3.354), train_loss = 2.04708612, grad/param norm = 2.3940e-01, time/batch = 0.7085s	
1527/22750 (epoch 3.356), train_loss = 2.09641254, grad/param norm = 2.4303e-01, time/batch = 0.7053s	
1528/22750 (epoch 3.358), train_loss = 1.83368171, grad/param norm = 2.3677e-01, time/batch = 0.7082s	
1529/22750 (epoch 3.360), train_loss = 2.14318155, grad/param norm = 2.4052e-01, time/batch = 0.7062s	
1530/22750 (epoch 3.363), train_loss = 1.93640666, grad/param norm = 2.2439e-01, time/batch = 0.7083s	
1531/22750 (epoch 3.365), train_loss = 1.60915524, grad/param norm = 2.5548e-01, time/batch = 0.7124s	
1532/22750 (epoch 3.367), train_loss = 1.57758160, grad/param norm = 2.2193e-01, time/batch = 0.7117s	
1533/22750 (epoch 3.369), train_loss = 1.84433857, grad/param norm = 2.5421e-01, time/batch = 0.7081s	
1534/22750 (epoch 3.371), train_loss = 1.81884191, grad/param norm = 2.4321e-01, time/batch = 0.7073s	
1535/22750 (epoch 3.374), train_loss = 1.69564507, grad/param norm = 2.3806e-01, time/batch = 0.7074s	
1536/22750 (epoch 3.376), train_loss = 1.97973782, grad/param norm = 2.3616e-01, time/batch = 0.7111s	
1537/22750 (epoch 3.378), train_loss = 1.79716323, grad/param norm = 2.3021e-01, time/batch = 0.7118s	
1538/22750 (epoch 3.380), train_loss = 2.01759892, grad/param norm = 2.5151e-01, time/batch = 0.7114s	
1539/22750 (epoch 3.382), train_loss = 1.77653139, grad/param norm = 2.4058e-01, time/batch = 0.7116s	
1540/22750 (epoch 3.385), train_loss = 1.89095754, grad/param norm = 2.0864e-01, time/batch = 0.7080s	
1541/22750 (epoch 3.387), train_loss = 1.97772598, grad/param norm = 2.3644e-01, time/batch = 0.7107s	
1542/22750 (epoch 3.389), train_loss = 1.53390199, grad/param norm = 2.7075e-01, time/batch = 0.7052s	
1543/22750 (epoch 3.391), train_loss = 1.40508566, grad/param norm = 2.4342e-01, time/batch = 0.7091s	
1544/22750 (epoch 3.393), train_loss = 1.72420602, grad/param norm = 2.5932e-01, time/batch = 0.7115s	
1545/22750 (epoch 3.396), train_loss = 1.87620470, grad/param norm = 2.5045e-01, time/batch = 0.7129s	
1546/22750 (epoch 3.398), train_loss = 1.83941232, grad/param norm = 2.6991e-01, time/batch = 0.7211s	
1547/22750 (epoch 3.400), train_loss = 1.84774620, grad/param norm = 2.2389e-01, time/batch = 0.7131s	
1548/22750 (epoch 3.402), train_loss = 1.87208925, grad/param norm = 2.3394e-01, time/batch = 0.7074s	
1549/22750 (epoch 3.404), train_loss = 2.07531519, grad/param norm = 2.6122e-01, time/batch = 0.7108s	
1550/22750 (epoch 3.407), train_loss = 1.94443410, grad/param norm = 2.5157e-01, time/batch = 0.7095s	
1551/22750 (epoch 3.409), train_loss = 1.88551630, grad/param norm = 2.5912e-01, time/batch = 0.7066s	
1552/22750 (epoch 3.411), train_loss = 1.89991007, grad/param norm = 2.4574e-01, time/batch = 0.7111s	
1553/22750 (epoch 3.413), train_loss = 1.82637219, grad/param norm = 2.6023e-01, time/batch = 0.7182s	
1554/22750 (epoch 3.415), train_loss = 1.64650419, grad/param norm = 2.6017e-01, time/batch = 0.7091s	
1555/22750 (epoch 3.418), train_loss = 1.74741354, grad/param norm = 2.2323e-01, time/batch = 0.7089s	
1556/22750 (epoch 3.420), train_loss = 2.08708204, grad/param norm = 2.5468e-01, time/batch = 0.7087s	
1557/22750 (epoch 3.422), train_loss = 2.15994929, grad/param norm = 2.3013e-01, time/batch = 0.7099s	
1558/22750 (epoch 3.424), train_loss = 2.16413905, grad/param norm = 2.2866e-01, time/batch = 0.7089s	
1559/22750 (epoch 3.426), train_loss = 2.15218597, grad/param norm = 2.1888e-01, time/batch = 0.7081s	
1560/22750 (epoch 3.429), train_loss = 1.65502915, grad/param norm = 2.1388e-01, time/batch = 0.7065s	
1561/22750 (epoch 3.431), train_loss = 1.64330043, grad/param norm = 2.1597e-01, time/batch = 0.7087s	
1562/22750 (epoch 3.433), train_loss = 1.71550369, grad/param norm = 2.1205e-01, time/batch = 0.7093s	
1563/22750 (epoch 3.435), train_loss = 1.63974781, grad/param norm = 2.4157e-01, time/batch = 0.7094s	
1564/22750 (epoch 3.437), train_loss = 1.58241713, grad/param norm = 2.1641e-01, time/batch = 0.7057s	
1565/22750 (epoch 3.440), train_loss = 2.10852711, grad/param norm = 2.7092e-01, time/batch = 0.7127s	
1566/22750 (epoch 3.442), train_loss = 1.87524365, grad/param norm = 2.4333e-01, time/batch = 0.7074s	
1567/22750 (epoch 3.444), train_loss = 2.01805207, grad/param norm = 3.6452e-01, time/batch = 0.7078s	
1568/22750 (epoch 3.446), train_loss = 1.96565607, grad/param norm = 3.1937e-01, time/batch = 0.7082s	
1569/22750 (epoch 3.448), train_loss = 2.12038576, grad/param norm = 2.6545e-01, time/batch = 0.7007s	
1570/22750 (epoch 3.451), train_loss = 2.04126615, grad/param norm = 2.6041e-01, time/batch = 0.7001s	
1571/22750 (epoch 3.453), train_loss = 2.15147981, grad/param norm = 2.6287e-01, time/batch = 0.6970s	
1572/22750 (epoch 3.455), train_loss = 2.16804889, grad/param norm = 2.4210e-01, time/batch = 0.7023s	
1573/22750 (epoch 3.457), train_loss = 2.05027983, grad/param norm = 2.5850e-01, time/batch = 0.6937s	
1574/22750 (epoch 3.459), train_loss = 1.91587616, grad/param norm = 2.3867e-01, time/batch = 0.6923s	
1575/22750 (epoch 3.462), train_loss = 1.83635323, grad/param norm = 2.0221e-01, time/batch = 0.7021s	
1576/22750 (epoch 3.464), train_loss = 1.71413394, grad/param norm = 2.1464e-01, time/batch = 0.6983s	
1577/22750 (epoch 3.466), train_loss = 2.10407234, grad/param norm = 2.1934e-01, time/batch = 0.7018s	
1578/22750 (epoch 3.468), train_loss = 1.87272939, grad/param norm = 2.4534e-01, time/batch = 0.7097s	
1579/22750 (epoch 3.470), train_loss = 2.02329799, grad/param norm = 2.5299e-01, time/batch = 0.7008s	
1580/22750 (epoch 3.473), train_loss = 1.90196029, grad/param norm = 2.1966e-01, time/batch = 0.7084s	
1581/22750 (epoch 3.475), train_loss = 1.99204918, grad/param norm = 2.2074e-01, time/batch = 0.7077s	
1582/22750 (epoch 3.477), train_loss = 1.70130325, grad/param norm = 2.3326e-01, time/batch = 0.6938s	
1583/22750 (epoch 3.479), train_loss = 1.79333330, grad/param norm = 2.1507e-01, time/batch = 0.6955s	
1584/22750 (epoch 3.481), train_loss = 1.74052697, grad/param norm = 2.7260e-01, time/batch = 0.6866s	
1585/22750 (epoch 3.484), train_loss = 1.54699138, grad/param norm = 2.5127e-01, time/batch = 0.6952s	
1586/22750 (epoch 3.486), train_loss = 1.82480966, grad/param norm = 2.7730e-01, time/batch = 0.6903s	
1587/22750 (epoch 3.488), train_loss = 1.47637814, grad/param norm = 2.5740e-01, time/batch = 0.6861s	
1588/22750 (epoch 3.490), train_loss = 1.71380928, grad/param norm = 2.4546e-01, time/batch = 0.7123s	
1589/22750 (epoch 3.492), train_loss = 2.00907822, grad/param norm = 2.8109e-01, time/batch = 0.7110s	
1590/22750 (epoch 3.495), train_loss = 1.82485804, grad/param norm = 2.7984e-01, time/batch = 0.7217s	
1591/22750 (epoch 3.497), train_loss = 1.95545480, grad/param norm = 2.5750e-01, time/batch = 0.7136s	
1592/22750 (epoch 3.499), train_loss = 1.82192811, grad/param norm = 2.2544e-01, time/batch = 0.7107s	
1593/22750 (epoch 3.501), train_loss = 1.84682942, grad/param norm = 2.0880e-01, time/batch = 0.7135s	
1594/22750 (epoch 3.503), train_loss = 1.89095482, grad/param norm = 2.2654e-01, time/batch = 0.7011s	
1595/22750 (epoch 3.505), train_loss = 1.70930862, grad/param norm = 2.2200e-01, time/batch = 0.7216s	
1596/22750 (epoch 3.508), train_loss = 1.64264377, grad/param norm = 2.3086e-01, time/batch = 0.7137s	
1597/22750 (epoch 3.510), train_loss = 1.68087444, grad/param norm = 2.3358e-01, time/batch = 0.6998s	
1598/22750 (epoch 3.512), train_loss = 1.77442705, grad/param norm = 2.2354e-01, time/batch = 0.6817s	
1599/22750 (epoch 3.514), train_loss = 1.79784945, grad/param norm = 2.2604e-01, time/batch = 0.6967s	
1600/22750 (epoch 3.516), train_loss = 1.66955930, grad/param norm = 2.4014e-01, time/batch = 0.6996s	
1601/22750 (epoch 3.519), train_loss = 1.85833423, grad/param norm = 2.5426e-01, time/batch = 0.6864s	
1602/22750 (epoch 3.521), train_loss = 1.66586728, grad/param norm = 2.4872e-01, time/batch = 0.6903s	
1603/22750 (epoch 3.523), train_loss = 1.72968130, grad/param norm = 2.6249e-01, time/batch = 0.6973s	
1604/22750 (epoch 3.525), train_loss = 1.97004901, grad/param norm = 2.6312e-01, time/batch = 0.7005s	
1605/22750 (epoch 3.527), train_loss = 1.83249547, grad/param norm = 2.2663e-01, time/batch = 0.6769s	
1606/22750 (epoch 3.530), train_loss = 1.72460431, grad/param norm = 2.4564e-01, time/batch = 0.6824s	
1607/22750 (epoch 3.532), train_loss = 1.78261636, grad/param norm = 2.3481e-01, time/batch = 0.6876s	
1608/22750 (epoch 3.534), train_loss = 1.97960344, grad/param norm = 2.4996e-01, time/batch = 0.7099s	
1609/22750 (epoch 3.536), train_loss = 1.87853774, grad/param norm = 2.4767e-01, time/batch = 0.7048s	
1610/22750 (epoch 3.538), train_loss = 1.95069558, grad/param norm = 2.0919e-01, time/batch = 0.7121s	
1611/22750 (epoch 3.541), train_loss = 1.55845631, grad/param norm = 2.0454e-01, time/batch = 0.7274s	
1612/22750 (epoch 3.543), train_loss = 1.56807863, grad/param norm = 2.1269e-01, time/batch = 0.7261s	
1613/22750 (epoch 3.545), train_loss = 1.98763669, grad/param norm = 2.2911e-01, time/batch = 0.7179s	
1614/22750 (epoch 3.547), train_loss = 1.60410039, grad/param norm = 2.2090e-01, time/batch = 0.7051s	
1615/22750 (epoch 3.549), train_loss = 1.68608689, grad/param norm = 2.4103e-01, time/batch = 0.7134s	
1616/22750 (epoch 3.552), train_loss = 1.94206394, grad/param norm = 2.5943e-01, time/batch = 0.7036s	
1617/22750 (epoch 3.554), train_loss = 1.93710904, grad/param norm = 2.2715e-01, time/batch = 0.7208s	
1618/22750 (epoch 3.556), train_loss = 1.81932936, grad/param norm = 2.3152e-01, time/batch = 0.7262s	
1619/22750 (epoch 3.558), train_loss = 1.98536063, grad/param norm = 2.2526e-01, time/batch = 0.7077s	
1620/22750 (epoch 3.560), train_loss = 1.67543230, grad/param norm = 2.2113e-01, time/batch = 0.6983s	
1621/22750 (epoch 3.563), train_loss = 1.84700822, grad/param norm = 2.2670e-01, time/batch = 0.6977s	
1622/22750 (epoch 3.565), train_loss = 2.02577725, grad/param norm = 2.1525e-01, time/batch = 0.7001s	
1623/22750 (epoch 3.567), train_loss = 1.82437617, grad/param norm = 2.2478e-01, time/batch = 0.7043s	
1624/22750 (epoch 3.569), train_loss = 1.79524228, grad/param norm = 2.3915e-01, time/batch = 0.7090s	
1625/22750 (epoch 3.571), train_loss = 1.87905695, grad/param norm = 2.5254e-01, time/batch = 0.6998s	
1626/22750 (epoch 3.574), train_loss = 1.64273372, grad/param norm = 2.3489e-01, time/batch = 0.7013s	
1627/22750 (epoch 3.576), train_loss = 1.85811993, grad/param norm = 2.2239e-01, time/batch = 0.6973s	
1628/22750 (epoch 3.578), train_loss = 1.64589792, grad/param norm = 2.3772e-01, time/batch = 0.7053s	
1629/22750 (epoch 3.580), train_loss = 1.90849069, grad/param norm = 2.2855e-01, time/batch = 0.6989s	
1630/22750 (epoch 3.582), train_loss = 1.60907430, grad/param norm = 2.4909e-01, time/batch = 0.7015s	
1631/22750 (epoch 3.585), train_loss = 1.52487748, grad/param norm = 2.0499e-01, time/batch = 0.6990s	
1632/22750 (epoch 3.587), train_loss = 1.64896164, grad/param norm = 2.1128e-01, time/batch = 0.7026s	
1633/22750 (epoch 3.589), train_loss = 1.67323769, grad/param norm = 2.3505e-01, time/batch = 0.6975s	
1634/22750 (epoch 3.591), train_loss = 1.89032742, grad/param norm = 2.5696e-01, time/batch = 0.6978s	
1635/22750 (epoch 3.593), train_loss = 2.00181528, grad/param norm = 2.2211e-01, time/batch = 0.7002s	
1636/22750 (epoch 3.596), train_loss = 1.94878742, grad/param norm = 2.0453e-01, time/batch = 0.7070s	
1637/22750 (epoch 3.598), train_loss = 2.03059350, grad/param norm = 2.4117e-01, time/batch = 0.6994s	
1638/22750 (epoch 3.600), train_loss = 1.82823179, grad/param norm = 2.1680e-01, time/batch = 0.7138s	
1639/22750 (epoch 3.602), train_loss = 1.59008480, grad/param norm = 2.0088e-01, time/batch = 0.7070s	
1640/22750 (epoch 3.604), train_loss = 1.76257597, grad/param norm = 2.4292e-01, time/batch = 0.6965s	
1641/22750 (epoch 3.607), train_loss = 1.44639525, grad/param norm = 2.0215e-01, time/batch = 0.6985s	
1642/22750 (epoch 3.609), train_loss = 1.48638570, grad/param norm = 1.9688e-01, time/batch = 0.6982s	
1643/22750 (epoch 3.611), train_loss = 1.73743647, grad/param norm = 2.4456e-01, time/batch = 0.7000s	
1644/22750 (epoch 3.613), train_loss = 1.66507920, grad/param norm = 2.4550e-01, time/batch = 0.6981s	
1645/22750 (epoch 3.615), train_loss = 1.76685249, grad/param norm = 2.3587e-01, time/batch = 0.6990s	
1646/22750 (epoch 3.618), train_loss = 1.80728240, grad/param norm = 2.6786e-01, time/batch = 0.6995s	
1647/22750 (epoch 3.620), train_loss = 1.78286499, grad/param norm = 2.4362e-01, time/batch = 0.7014s	
1648/22750 (epoch 3.622), train_loss = 1.64091250, grad/param norm = 2.9362e-01, time/batch = 0.6985s	
1649/22750 (epoch 3.624), train_loss = 1.98686154, grad/param norm = 2.6907e-01, time/batch = 0.6941s	
1650/22750 (epoch 3.626), train_loss = 1.78718306, grad/param norm = 3.0738e-01, time/batch = 0.6968s	
1651/22750 (epoch 3.629), train_loss = 1.86960608, grad/param norm = 2.7853e-01, time/batch = 0.6993s	
1652/22750 (epoch 3.631), train_loss = 1.89933953, grad/param norm = 2.3250e-01, time/batch = 0.6927s	
1653/22750 (epoch 3.633), train_loss = 1.56746524, grad/param norm = 2.2416e-01, time/batch = 0.6923s	
1654/22750 (epoch 3.635), train_loss = 1.95337014, grad/param norm = 2.2339e-01, time/batch = 0.6915s	
1655/22750 (epoch 3.637), train_loss = 1.91504708, grad/param norm = 2.4335e-01, time/batch = 0.6932s	
1656/22750 (epoch 3.640), train_loss = 2.05162471, grad/param norm = 2.5883e-01, time/batch = 0.6938s	
1657/22750 (epoch 3.642), train_loss = 1.96992497, grad/param norm = 2.4688e-01, time/batch = 0.6965s	
1658/22750 (epoch 3.644), train_loss = 1.82334463, grad/param norm = 2.3293e-01, time/batch = 0.6981s	
1659/22750 (epoch 3.646), train_loss = 1.90439971, grad/param norm = 2.6701e-01, time/batch = 0.7001s	
1660/22750 (epoch 3.648), train_loss = 1.86433730, grad/param norm = 2.5330e-01, time/batch = 0.7004s	
1661/22750 (epoch 3.651), train_loss = 2.00924729, grad/param norm = 2.4263e-01, time/batch = 0.6947s	
1662/22750 (epoch 3.653), train_loss = 1.80474745, grad/param norm = 2.2431e-01, time/batch = 0.6936s	
1663/22750 (epoch 3.655), train_loss = 1.82884874, grad/param norm = 2.4010e-01, time/batch = 0.7123s	
1664/22750 (epoch 3.657), train_loss = 2.02968309, grad/param norm = 2.0782e-01, time/batch = 0.7118s	
1665/22750 (epoch 3.659), train_loss = 2.04880453, grad/param norm = 2.2122e-01, time/batch = 0.7156s	
1666/22750 (epoch 3.662), train_loss = 2.15742504, grad/param norm = 2.2969e-01, time/batch = 0.6922s	
1667/22750 (epoch 3.664), train_loss = 1.89064625, grad/param norm = 2.4374e-01, time/batch = 0.7141s	
1668/22750 (epoch 3.666), train_loss = 1.73801181, grad/param norm = 2.5520e-01, time/batch = 0.7138s	
1669/22750 (epoch 3.668), train_loss = 1.85723942, grad/param norm = 2.2929e-01, time/batch = 0.6902s	
1670/22750 (epoch 3.670), train_loss = 1.88332004, grad/param norm = 2.3247e-01, time/batch = 0.6910s	
1671/22750 (epoch 3.673), train_loss = 1.99951281, grad/param norm = 2.9175e-01, time/batch = 0.6959s	
1672/22750 (epoch 3.675), train_loss = 2.32554345, grad/param norm = 3.1142e-01, time/batch = 0.6959s	
1673/22750 (epoch 3.677), train_loss = 2.05941597, grad/param norm = 2.5888e-01, time/batch = 0.7089s	
1674/22750 (epoch 3.679), train_loss = 2.13205555, grad/param norm = 2.3485e-01, time/batch = 0.7216s	
1675/22750 (epoch 3.681), train_loss = 1.97470888, grad/param norm = 2.3844e-01, time/batch = 0.7371s	
1676/22750 (epoch 3.684), train_loss = 1.99766781, grad/param norm = 2.3398e-01, time/batch = 0.7231s	
1677/22750 (epoch 3.686), train_loss = 1.96491663, grad/param norm = 2.5519e-01, time/batch = 0.7103s	
1678/22750 (epoch 3.688), train_loss = 1.97116261, grad/param norm = 2.4270e-01, time/batch = 0.7164s	
1679/22750 (epoch 3.690), train_loss = 1.89213355, grad/param norm = 2.3082e-01, time/batch = 0.7019s	
1680/22750 (epoch 3.692), train_loss = 2.05178696, grad/param norm = 2.2920e-01, time/batch = 0.6983s	
1681/22750 (epoch 3.695), train_loss = 1.83742931, grad/param norm = 2.3357e-01, time/batch = 0.7064s	
1682/22750 (epoch 3.697), train_loss = 1.75561681, grad/param norm = 2.5673e-01, time/batch = 0.7003s	
1683/22750 (epoch 3.699), train_loss = 1.91567355, grad/param norm = 2.3148e-01, time/batch = 0.6893s	
1684/22750 (epoch 3.701), train_loss = 1.77905992, grad/param norm = 2.1578e-01, time/batch = 0.7077s	
1685/22750 (epoch 3.703), train_loss = 1.89494267, grad/param norm = 2.2525e-01, time/batch = 0.7000s	
1686/22750 (epoch 3.705), train_loss = 1.67072643, grad/param norm = 2.0534e-01, time/batch = 0.7090s	
1687/22750 (epoch 3.708), train_loss = 1.87484112, grad/param norm = 2.0454e-01, time/batch = 0.7244s	
1688/22750 (epoch 3.710), train_loss = 1.60279075, grad/param norm = 2.2763e-01, time/batch = 0.7150s	
1689/22750 (epoch 3.712), train_loss = 1.70785838, grad/param norm = 2.1537e-01, time/batch = 0.7193s	
1690/22750 (epoch 3.714), train_loss = 1.61927647, grad/param norm = 2.2442e-01, time/batch = 0.6935s	
1691/22750 (epoch 3.716), train_loss = 1.76895923, grad/param norm = 2.4067e-01, time/batch = 0.6950s	
1692/22750 (epoch 3.719), train_loss = 1.98746143, grad/param norm = 2.9281e-01, time/batch = 0.6954s	
1693/22750 (epoch 3.721), train_loss = 1.89621294, grad/param norm = 2.5350e-01, time/batch = 0.6975s	
1694/22750 (epoch 3.723), train_loss = 1.78691159, grad/param norm = 2.1902e-01, time/batch = 0.6993s	
1695/22750 (epoch 3.725), train_loss = 1.80879245, grad/param norm = 2.3903e-01, time/batch = 0.7007s	
1696/22750 (epoch 3.727), train_loss = 1.72257360, grad/param norm = 2.0953e-01, time/batch = 0.6928s	
1697/22750 (epoch 3.730), train_loss = 1.73872767, grad/param norm = 2.0762e-01, time/batch = 0.6931s	
1698/22750 (epoch 3.732), train_loss = 1.84828335, grad/param norm = 2.1061e-01, time/batch = 0.6975s	
1699/22750 (epoch 3.734), train_loss = 1.43899217, grad/param norm = 2.3992e-01, time/batch = 0.6996s	
1700/22750 (epoch 3.736), train_loss = 1.74766021, grad/param norm = 2.3706e-01, time/batch = 0.7136s	
1701/22750 (epoch 3.738), train_loss = 1.71945154, grad/param norm = 2.3899e-01, time/batch = 0.6993s	
1702/22750 (epoch 3.741), train_loss = 1.91996300, grad/param norm = 2.0781e-01, time/batch = 0.6962s	
1703/22750 (epoch 3.743), train_loss = 1.91672480, grad/param norm = 2.3246e-01, time/batch = 0.6944s	
1704/22750 (epoch 3.745), train_loss = 1.62047179, grad/param norm = 2.2711e-01, time/batch = 0.6952s	
1705/22750 (epoch 3.747), train_loss = 1.73709628, grad/param norm = 2.3149e-01, time/batch = 0.6964s	
1706/22750 (epoch 3.749), train_loss = 1.97584559, grad/param norm = 2.5182e-01, time/batch = 0.6940s	
1707/22750 (epoch 3.752), train_loss = 1.70665000, grad/param norm = 2.1832e-01, time/batch = 0.6920s	
1708/22750 (epoch 3.754), train_loss = 1.92054294, grad/param norm = 2.8027e-01, time/batch = 0.6947s	
1709/22750 (epoch 3.756), train_loss = 1.63823272, grad/param norm = 3.0692e-01, time/batch = 0.6938s	
1710/22750 (epoch 3.758), train_loss = 1.55654315, grad/param norm = 2.1503e-01, time/batch = 0.6921s	
1711/22750 (epoch 3.760), train_loss = 1.88993962, grad/param norm = 2.1921e-01, time/batch = 0.6947s	
1712/22750 (epoch 3.763), train_loss = 1.82825433, grad/param norm = 2.1422e-01, time/batch = 0.7127s	
1713/22750 (epoch 3.765), train_loss = 1.69671158, grad/param norm = 2.3482e-01, time/batch = 0.6999s	
1714/22750 (epoch 3.767), train_loss = 1.72551713, grad/param norm = 2.2882e-01, time/batch = 0.6903s	
1715/22750 (epoch 3.769), train_loss = 1.92315939, grad/param norm = 2.4712e-01, time/batch = 0.7008s	
1716/22750 (epoch 3.771), train_loss = 1.89076206, grad/param norm = 2.4296e-01, time/batch = 0.7257s	
1717/22750 (epoch 3.774), train_loss = 1.75106467, grad/param norm = 2.3655e-01, time/batch = 0.7255s	
1718/22750 (epoch 3.776), train_loss = 1.79947807, grad/param norm = 2.3782e-01, time/batch = 0.7318s	
1719/22750 (epoch 3.778), train_loss = 1.99402777, grad/param norm = 2.2152e-01, time/batch = 0.7220s	
1720/22750 (epoch 3.780), train_loss = 1.86029649, grad/param norm = 2.5173e-01, time/batch = 0.7238s	
1721/22750 (epoch 3.782), train_loss = 1.93361753, grad/param norm = 2.4042e-01, time/batch = 0.7405s	
1722/22750 (epoch 3.785), train_loss = 1.87612411, grad/param norm = 2.2339e-01, time/batch = 0.7253s	
1723/22750 (epoch 3.787), train_loss = 1.73038823, grad/param norm = 2.2999e-01, time/batch = 0.7292s	
1724/22750 (epoch 3.789), train_loss = 1.69437142, grad/param norm = 2.0863e-01, time/batch = 0.7255s	
1725/22750 (epoch 3.791), train_loss = 1.76232125, grad/param norm = 1.8350e-01, time/batch = 0.7364s	
1726/22750 (epoch 3.793), train_loss = 1.78011592, grad/param norm = 2.2594e-01, time/batch = 0.7209s	
1727/22750 (epoch 3.796), train_loss = 1.69815138, grad/param norm = 2.1569e-01, time/batch = 0.7212s	
1728/22750 (epoch 3.798), train_loss = 1.72407726, grad/param norm = 2.0169e-01, time/batch = 0.7373s	
1729/22750 (epoch 3.800), train_loss = 1.69838180, grad/param norm = 2.1867e-01, time/batch = 0.7045s	
1730/22750 (epoch 3.802), train_loss = 1.84308213, grad/param norm = 2.3506e-01, time/batch = 0.7180s	
1731/22750 (epoch 3.804), train_loss = 2.07120551, grad/param norm = 2.2149e-01, time/batch = 0.7207s	
1732/22750 (epoch 3.807), train_loss = 1.81118223, grad/param norm = 2.2146e-01, time/batch = 0.7263s	
1733/22750 (epoch 3.809), train_loss = 2.04806880, grad/param norm = 2.5106e-01, time/batch = 0.7089s	
1734/22750 (epoch 3.811), train_loss = 1.76071968, grad/param norm = 2.2386e-01, time/batch = 0.6970s	
1735/22750 (epoch 3.813), train_loss = 1.90041439, grad/param norm = 1.9530e-01, time/batch = 0.7046s	
1736/22750 (epoch 3.815), train_loss = 1.99854781, grad/param norm = 2.4964e-01, time/batch = 0.7243s	
1737/22750 (epoch 3.818), train_loss = 1.98924181, grad/param norm = 2.2924e-01, time/batch = 0.7071s	
1738/22750 (epoch 3.820), train_loss = 2.06567452, grad/param norm = 2.1648e-01, time/batch = 0.7068s	
1739/22750 (epoch 3.822), train_loss = 1.89006461, grad/param norm = 2.1148e-01, time/batch = 0.7041s	
1740/22750 (epoch 3.824), train_loss = 1.89370456, grad/param norm = 2.1814e-01, time/batch = 0.7028s	
1741/22750 (epoch 3.826), train_loss = 1.82652232, grad/param norm = 2.1417e-01, time/batch = 0.7075s	
1742/22750 (epoch 3.829), train_loss = 1.99908984, grad/param norm = 2.4352e-01, time/batch = 0.7236s	
1743/22750 (epoch 3.831), train_loss = 1.96579481, grad/param norm = 2.5171e-01, time/batch = 0.7072s	
1744/22750 (epoch 3.833), train_loss = 2.02088344, grad/param norm = 2.3579e-01, time/batch = 0.6962s	
1745/22750 (epoch 3.835), train_loss = 1.82514526, grad/param norm = 2.2927e-01, time/batch = 0.7031s	
1746/22750 (epoch 3.837), train_loss = 1.83011592, grad/param norm = 2.3259e-01, time/batch = 0.7041s	
1747/22750 (epoch 3.840), train_loss = 1.85317985, grad/param norm = 2.3759e-01, time/batch = 0.7133s	
1748/22750 (epoch 3.842), train_loss = 1.77095492, grad/param norm = 2.2531e-01, time/batch = 0.7236s	
1749/22750 (epoch 3.844), train_loss = 2.04683691, grad/param norm = 2.4800e-01, time/batch = 0.7246s	
1750/22750 (epoch 3.846), train_loss = 1.75039358, grad/param norm = 2.1515e-01, time/batch = 0.7297s	
1751/22750 (epoch 3.848), train_loss = 1.65718690, grad/param norm = 2.3723e-01, time/batch = 0.7269s	
1752/22750 (epoch 3.851), train_loss = 1.72059533, grad/param norm = 2.3884e-01, time/batch = 0.7254s	
1753/22750 (epoch 3.853), train_loss = 1.76510402, grad/param norm = 2.3590e-01, time/batch = 0.7272s	
1754/22750 (epoch 3.855), train_loss = 1.59061366, grad/param norm = 2.0708e-01, time/batch = 0.7250s	
1755/22750 (epoch 3.857), train_loss = 1.81161351, grad/param norm = 2.0380e-01, time/batch = 0.7248s	
1756/22750 (epoch 3.859), train_loss = 1.84307134, grad/param norm = 2.3325e-01, time/batch = 0.7211s	
1757/22750 (epoch 3.862), train_loss = 1.96760347, grad/param norm = 2.4141e-01, time/batch = 0.7247s	
1758/22750 (epoch 3.864), train_loss = 1.83529915, grad/param norm = 2.1842e-01, time/batch = 0.7244s	
1759/22750 (epoch 3.866), train_loss = 1.82353475, grad/param norm = 2.0080e-01, time/batch = 0.7286s	
1760/22750 (epoch 3.868), train_loss = 1.83740626, grad/param norm = 2.1333e-01, time/batch = 0.7284s	
1761/22750 (epoch 3.870), train_loss = 1.60314044, grad/param norm = 2.1554e-01, time/batch = 0.7090s	
1762/22750 (epoch 3.873), train_loss = 1.75945464, grad/param norm = 2.0552e-01, time/batch = 0.7104s	
1763/22750 (epoch 3.875), train_loss = 1.84422614, grad/param norm = 2.1579e-01, time/batch = 0.7125s	
1764/22750 (epoch 3.877), train_loss = 1.64289709, grad/param norm = 1.9676e-01, time/batch = 0.7290s	
1765/22750 (epoch 3.879), train_loss = 1.93890172, grad/param norm = 2.3821e-01, time/batch = 0.7253s	
1766/22750 (epoch 3.881), train_loss = 1.89111321, grad/param norm = 2.3850e-01, time/batch = 0.7261s	
1767/22750 (epoch 3.884), train_loss = 1.79399993, grad/param norm = 2.6402e-01, time/batch = 0.7234s	
1768/22750 (epoch 3.886), train_loss = 1.90800951, grad/param norm = 2.2503e-01, time/batch = 0.7109s	
1769/22750 (epoch 3.888), train_loss = 1.86419286, grad/param norm = 2.2092e-01, time/batch = 0.7067s	
1770/22750 (epoch 3.890), train_loss = 1.86340464, grad/param norm = 2.5613e-01, time/batch = 0.7088s	
1771/22750 (epoch 3.892), train_loss = 2.27950448, grad/param norm = 3.1053e-01, time/batch = 0.7115s	
1772/22750 (epoch 3.895), train_loss = 1.94220958, grad/param norm = 2.3461e-01, time/batch = 0.7093s	
1773/22750 (epoch 3.897), train_loss = 1.91487811, grad/param norm = 2.3846e-01, time/batch = 0.6989s	
1774/22750 (epoch 3.899), train_loss = 1.87217293, grad/param norm = 2.1638e-01, time/batch = 0.7014s	
1775/22750 (epoch 3.901), train_loss = 1.99647805, grad/param norm = 2.0956e-01, time/batch = 0.6959s	
1776/22750 (epoch 3.903), train_loss = 1.81962129, grad/param norm = 2.1713e-01, time/batch = 0.7072s	
1777/22750 (epoch 3.905), train_loss = 1.82146280, grad/param norm = 1.9947e-01, time/batch = 0.7189s	
1778/22750 (epoch 3.908), train_loss = 1.82838511, grad/param norm = 2.4743e-01, time/batch = 0.7043s	
1779/22750 (epoch 3.910), train_loss = 1.64626051, grad/param norm = 2.3634e-01, time/batch = 0.6990s	
1780/22750 (epoch 3.912), train_loss = 1.65997258, grad/param norm = 2.3099e-01, time/batch = 0.6991s	
1781/22750 (epoch 3.914), train_loss = 1.71766431, grad/param norm = 2.2403e-01, time/batch = 0.7230s	
1782/22750 (epoch 3.916), train_loss = 1.58220040, grad/param norm = 2.0194e-01, time/batch = 0.7279s	
1783/22750 (epoch 3.919), train_loss = 1.69942549, grad/param norm = 2.3080e-01, time/batch = 0.7193s	
1784/22750 (epoch 3.921), train_loss = 1.41176248, grad/param norm = 2.0610e-01, time/batch = 0.7119s	
1785/22750 (epoch 3.923), train_loss = 1.75564384, grad/param norm = 2.1478e-01, time/batch = 0.7179s	
1786/22750 (epoch 3.925), train_loss = 1.75642810, grad/param norm = 2.0889e-01, time/batch = 0.7122s	
1787/22750 (epoch 3.927), train_loss = 1.53861319, grad/param norm = 2.2147e-01, time/batch = 0.7000s	
1788/22750 (epoch 3.930), train_loss = 1.63277636, grad/param norm = 2.5214e-01, time/batch = 0.6998s	
1789/22750 (epoch 3.932), train_loss = 1.99842095, grad/param norm = 2.4894e-01, time/batch = 0.7002s	
1790/22750 (epoch 3.934), train_loss = 1.44005110, grad/param norm = 2.0482e-01, time/batch = 0.7011s	
1791/22750 (epoch 3.936), train_loss = 1.93204621, grad/param norm = 2.5139e-01, time/batch = 0.7073s	
1792/22750 (epoch 3.938), train_loss = 1.80486448, grad/param norm = 2.3199e-01, time/batch = 0.7058s	
1793/22750 (epoch 3.941), train_loss = 2.15367913, grad/param norm = 2.3867e-01, time/batch = 0.7039s	
1794/22750 (epoch 3.943), train_loss = 1.89957735, grad/param norm = 2.2762e-01, time/batch = 0.7044s	
1795/22750 (epoch 3.945), train_loss = 1.82088618, grad/param norm = 2.2464e-01, time/batch = 0.7097s	
1796/22750 (epoch 3.947), train_loss = 1.85030383, grad/param norm = 2.4425e-01, time/batch = 0.7185s	
1797/22750 (epoch 3.949), train_loss = 1.66579578, grad/param norm = 2.3195e-01, time/batch = 0.6978s	
1798/22750 (epoch 3.952), train_loss = 1.69337791, grad/param norm = 2.1284e-01, time/batch = 0.7015s	
1799/22750 (epoch 3.954), train_loss = 1.69392843, grad/param norm = 2.1720e-01, time/batch = 0.6981s	
1800/22750 (epoch 3.956), train_loss = 1.81101456, grad/param norm = 2.2780e-01, time/batch = 0.7001s	
1801/22750 (epoch 3.958), train_loss = 1.76539648, grad/param norm = 2.1794e-01, time/batch = 0.7118s	
1802/22750 (epoch 3.960), train_loss = 1.80480443, grad/param norm = 2.3505e-01, time/batch = 0.7238s	
1803/22750 (epoch 3.963), train_loss = 1.92053576, grad/param norm = 2.3506e-01, time/batch = 0.7072s	
1804/22750 (epoch 3.965), train_loss = 1.87028372, grad/param norm = 2.2634e-01, time/batch = 0.7017s	
1805/22750 (epoch 3.967), train_loss = 1.84011387, grad/param norm = 2.1820e-01, time/batch = 0.6953s	
1806/22750 (epoch 3.969), train_loss = 1.78173457, grad/param norm = 2.1090e-01, time/batch = 0.7020s	
1807/22750 (epoch 3.971), train_loss = 1.75363439, grad/param norm = 2.0476e-01, time/batch = 0.7002s	
1808/22750 (epoch 3.974), train_loss = 1.83050434, grad/param norm = 2.5449e-01, time/batch = 0.6941s	
1809/22750 (epoch 3.976), train_loss = 1.91447988, grad/param norm = 2.2051e-01, time/batch = 0.6953s	
1810/22750 (epoch 3.978), train_loss = 1.70133182, grad/param norm = 2.4369e-01, time/batch = 0.6982s	
1811/22750 (epoch 3.980), train_loss = 1.90524764, grad/param norm = 2.5219e-01, time/batch = 0.7007s	
1812/22750 (epoch 3.982), train_loss = 1.73352264, grad/param norm = 2.1797e-01, time/batch = 0.7241s	
1813/22750 (epoch 3.985), train_loss = 2.03664056, grad/param norm = 2.6224e-01, time/batch = 0.7044s	
1814/22750 (epoch 3.987), train_loss = 1.61561382, grad/param norm = 2.2559e-01, time/batch = 0.6959s	
1815/22750 (epoch 3.989), train_loss = 1.67493004, grad/param norm = 1.8892e-01, time/batch = 0.6965s	
1816/22750 (epoch 3.991), train_loss = 1.88514927, grad/param norm = 2.2298e-01, time/batch = 0.6979s	
1817/22750 (epoch 3.993), train_loss = 1.86401572, grad/param norm = 2.3997e-01, time/batch = 0.6944s	
1818/22750 (epoch 3.996), train_loss = 1.75698344, grad/param norm = 2.4240e-01, time/batch = 0.6998s	
1819/22750 (epoch 3.998), train_loss = 1.95012320, grad/param norm = 2.1349e-01, time/batch = 0.6948s	
1820/22750 (epoch 4.000), train_loss = 1.90139323, grad/param norm = 2.3011e-01, time/batch = 0.7000s	
1821/22750 (epoch 4.002), train_loss = 1.96077323, grad/param norm = 2.4576e-01, time/batch = 0.7094s	
1822/22750 (epoch 4.004), train_loss = 1.80594880, grad/param norm = 2.9013e-01, time/batch = 0.7238s	
1823/22750 (epoch 4.007), train_loss = 1.90982016, grad/param norm = 2.5333e-01, time/batch = 0.7018s	
1824/22750 (epoch 4.009), train_loss = 2.05902720, grad/param norm = 2.3137e-01, time/batch = 0.6962s	
1825/22750 (epoch 4.011), train_loss = 2.00032686, grad/param norm = 2.4191e-01, time/batch = 0.6945s	
1826/22750 (epoch 4.013), train_loss = 1.88466423, grad/param norm = 2.3439e-01, time/batch = 0.6949s	
1827/22750 (epoch 4.015), train_loss = 1.89268427, grad/param norm = 2.2605e-01, time/batch = 0.7047s	
1828/22750 (epoch 4.018), train_loss = 1.88105658, grad/param norm = 2.3652e-01, time/batch = 0.7009s	
1829/22750 (epoch 4.020), train_loss = 1.91901651, grad/param norm = 2.1329e-01, time/batch = 0.7107s	
1830/22750 (epoch 4.022), train_loss = 1.79767954, grad/param norm = 2.0277e-01, time/batch = 0.7051s	
1831/22750 (epoch 4.024), train_loss = 1.78999390, grad/param norm = 2.1946e-01, time/batch = 0.7138s	
1832/22750 (epoch 4.026), train_loss = 1.99423535, grad/param norm = 2.4355e-01, time/batch = 0.7254s	
1833/22750 (epoch 4.029), train_loss = 1.58513359, grad/param norm = 2.1502e-01, time/batch = 0.7017s	
1834/22750 (epoch 4.031), train_loss = 2.08356577, grad/param norm = 2.2616e-01, time/batch = 0.7083s	
1835/22750 (epoch 4.033), train_loss = 1.82907963, grad/param norm = 2.0125e-01, time/batch = 0.7039s	
1836/22750 (epoch 4.035), train_loss = 1.89411182, grad/param norm = 2.2057e-01, time/batch = 0.7012s	
1837/22750 (epoch 4.037), train_loss = 1.99475963, grad/param norm = 2.5113e-01, time/batch = 0.7037s	
1838/22750 (epoch 4.040), train_loss = 1.73330931, grad/param norm = 2.3819e-01, time/batch = 0.6952s	
1839/22750 (epoch 4.042), train_loss = 1.90693377, grad/param norm = 2.2153e-01, time/batch = 0.6978s	
1840/22750 (epoch 4.044), train_loss = 1.72239919, grad/param norm = 2.3674e-01, time/batch = 0.6998s	
1841/22750 (epoch 4.046), train_loss = 1.85982700, grad/param norm = 2.6128e-01, time/batch = 0.7207s	
1842/22750 (epoch 4.048), train_loss = 1.81765269, grad/param norm = 2.5656e-01, time/batch = 0.7246s	
1843/22750 (epoch 4.051), train_loss = 1.89373221, grad/param norm = 2.4088e-01, time/batch = 0.7229s	
1844/22750 (epoch 4.053), train_loss = 1.61616327, grad/param norm = 2.2424e-01, time/batch = 0.7035s	
1845/22750 (epoch 4.055), train_loss = 1.86520813, grad/param norm = 2.3070e-01, time/batch = 0.7047s	
1846/22750 (epoch 4.057), train_loss = 1.88870713, grad/param norm = 2.4250e-01, time/batch = 0.7232s	
1847/22750 (epoch 4.059), train_loss = 1.49399066, grad/param norm = 2.3401e-01, time/batch = 0.7274s	
1848/22750 (epoch 4.062), train_loss = 1.62157860, grad/param norm = 2.1526e-01, time/batch = 0.7243s	
1849/22750 (epoch 4.064), train_loss = 1.89053518, grad/param norm = 2.4783e-01, time/batch = 0.7207s	
1850/22750 (epoch 4.066), train_loss = 1.59911885, grad/param norm = 2.0509e-01, time/batch = 0.7072s	
1851/22750 (epoch 4.068), train_loss = 1.62976740, grad/param norm = 2.1350e-01, time/batch = 0.7221s	
1852/22750 (epoch 4.070), train_loss = 1.53300228, grad/param norm = 2.0650e-01, time/batch = 0.7133s	
1853/22750 (epoch 4.073), train_loss = 1.71508749, grad/param norm = 2.4751e-01, time/batch = 0.7114s	
1854/22750 (epoch 4.075), train_loss = 1.81190953, grad/param norm = 2.1460e-01, time/batch = 0.7046s	
1855/22750 (epoch 4.077), train_loss = 1.43809463, grad/param norm = 2.1189e-01, time/batch = 0.7142s	
1856/22750 (epoch 4.079), train_loss = 1.75014548, grad/param norm = 2.2765e-01, time/batch = 0.7131s	
1857/22750 (epoch 4.081), train_loss = 1.78204370, grad/param norm = 2.2508e-01, time/batch = 0.7179s	
1858/22750 (epoch 4.084), train_loss = 1.67658081, grad/param norm = 2.1166e-01, time/batch = 0.7040s	
1859/22750 (epoch 4.086), train_loss = 1.67820035, grad/param norm = 2.1777e-01, time/batch = 0.6981s	
1860/22750 (epoch 4.088), train_loss = 1.74459115, grad/param norm = 2.1752e-01, time/batch = 0.6940s	
1861/22750 (epoch 4.090), train_loss = 1.72991662, grad/param norm = 2.2141e-01, time/batch = 0.7247s	
1862/22750 (epoch 4.092), train_loss = 1.89378371, grad/param norm = 2.2290e-01, time/batch = 0.7230s	
1863/22750 (epoch 4.095), train_loss = 1.63994327, grad/param norm = 2.1212e-01, time/batch = 0.7128s	
1864/22750 (epoch 4.097), train_loss = 1.71364350, grad/param norm = 2.2168e-01, time/batch = 0.6944s	
1865/22750 (epoch 4.099), train_loss = 1.84701215, grad/param norm = 2.4841e-01, time/batch = 0.6940s	
1866/22750 (epoch 4.101), train_loss = 1.78843844, grad/param norm = 2.2325e-01, time/batch = 0.6911s	
1867/22750 (epoch 4.103), train_loss = 1.69503404, grad/param norm = 2.2531e-01, time/batch = 0.7016s	
1868/22750 (epoch 4.105), train_loss = 2.05134120, grad/param norm = 2.5324e-01, time/batch = 0.6986s	
1869/22750 (epoch 4.108), train_loss = 1.71788277, grad/param norm = 2.1968e-01, time/batch = 0.6986s	
1870/22750 (epoch 4.110), train_loss = 1.78296449, grad/param norm = 2.3996e-01, time/batch = 0.7023s	
1871/22750 (epoch 4.112), train_loss = 1.48315614, grad/param norm = 2.1273e-01, time/batch = 0.7136s	
1872/22750 (epoch 4.114), train_loss = 1.49331200, grad/param norm = 2.1298e-01, time/batch = 0.7171s	
1873/22750 (epoch 4.116), train_loss = 1.58860042, grad/param norm = 2.3779e-01, time/batch = 0.6999s	
1874/22750 (epoch 4.119), train_loss = 1.66269234, grad/param norm = 1.9888e-01, time/batch = 0.7050s	
1875/22750 (epoch 4.121), train_loss = 1.90024447, grad/param norm = 2.3078e-01, time/batch = 0.7032s	
1876/22750 (epoch 4.123), train_loss = 1.69037328, grad/param norm = 1.9082e-01, time/batch = 0.7224s	
1877/22750 (epoch 4.125), train_loss = 1.94379408, grad/param norm = 2.1846e-01, time/batch = 0.6953s	
1878/22750 (epoch 4.127), train_loss = 1.87175959, grad/param norm = 2.4362e-01, time/batch = 0.6905s	
1879/22750 (epoch 4.130), train_loss = 1.82417377, grad/param norm = 2.1032e-01, time/batch = 0.6859s	
1880/22750 (epoch 4.132), train_loss = 1.88934630, grad/param norm = 2.3491e-01, time/batch = 0.6894s	
1881/22750 (epoch 4.134), train_loss = 1.74244796, grad/param norm = 2.2358e-01, time/batch = 0.6924s	
1882/22750 (epoch 4.136), train_loss = 1.64617087, grad/param norm = 1.9278e-01, time/batch = 0.6863s	
1883/22750 (epoch 4.138), train_loss = 1.74301955, grad/param norm = 2.3824e-01, time/batch = 0.6840s	
1884/22750 (epoch 4.141), train_loss = 1.64012270, grad/param norm = 2.1224e-01, time/batch = 0.6851s	
1885/22750 (epoch 4.143), train_loss = 1.60375321, grad/param norm = 2.1265e-01, time/batch = 0.6850s	
1886/22750 (epoch 4.145), train_loss = 1.83546673, grad/param norm = 2.4038e-01, time/batch = 0.6872s	
1887/22750 (epoch 4.147), train_loss = 1.84779870, grad/param norm = 2.2163e-01, time/batch = 0.6804s	
1888/22750 (epoch 4.149), train_loss = 1.78159444, grad/param norm = 2.2082e-01, time/batch = 0.6800s	
1889/22750 (epoch 4.152), train_loss = 1.72713151, grad/param norm = 2.2613e-01, time/batch = 0.6800s	
1890/22750 (epoch 4.154), train_loss = 1.53253628, grad/param norm = 2.1546e-01, time/batch = 0.6770s	
1891/22750 (epoch 4.156), train_loss = 1.67518337, grad/param norm = 2.3245e-01, time/batch = 0.7072s	
1892/22750 (epoch 4.158), train_loss = 1.71416295, grad/param norm = 2.3429e-01, time/batch = 0.6859s	
1893/22750 (epoch 4.160), train_loss = 1.82650265, grad/param norm = 2.3399e-01, time/batch = 0.6848s	
1894/22750 (epoch 4.163), train_loss = 1.98548404, grad/param norm = 2.3559e-01, time/batch = 0.6782s	
1895/22750 (epoch 4.165), train_loss = 1.92534138, grad/param norm = 2.2564e-01, time/batch = 0.6772s	
1896/22750 (epoch 4.167), train_loss = 1.65754033, grad/param norm = 2.0578e-01, time/batch = 0.6825s	
1897/22750 (epoch 4.169), train_loss = 1.80142090, grad/param norm = 2.1555e-01, time/batch = 0.6777s	
1898/22750 (epoch 4.171), train_loss = 1.66998162, grad/param norm = 2.2569e-01, time/batch = 0.6822s	
1899/22750 (epoch 4.174), train_loss = 1.49235926, grad/param norm = 1.9779e-01, time/batch = 0.6897s	
1900/22750 (epoch 4.176), train_loss = 1.78773749, grad/param norm = 2.0603e-01, time/batch = 0.6848s	
1901/22750 (epoch 4.178), train_loss = 1.69364124, grad/param norm = 2.0085e-01, time/batch = 0.6849s	
1902/22750 (epoch 4.180), train_loss = 1.88884000, grad/param norm = 2.6407e-01, time/batch = 0.6881s	
1903/22750 (epoch 4.182), train_loss = 1.77790396, grad/param norm = 2.0354e-01, time/batch = 0.6945s	
1904/22750 (epoch 4.185), train_loss = 1.79588298, grad/param norm = 2.1719e-01, time/batch = 0.6840s	
1905/22750 (epoch 4.187), train_loss = 1.60974244, grad/param norm = 2.2889e-01, time/batch = 0.6895s	
1906/22750 (epoch 4.189), train_loss = 1.65580994, grad/param norm = 2.2634e-01, time/batch = 0.6785s	
1907/22750 (epoch 4.191), train_loss = 1.60375406, grad/param norm = 2.1728e-01, time/batch = 0.6815s	
1908/22750 (epoch 4.193), train_loss = 1.82805059, grad/param norm = 2.4502e-01, time/batch = 0.6806s	
1909/22750 (epoch 4.196), train_loss = 1.77320994, grad/param norm = 2.2430e-01, time/batch = 0.6800s	
1910/22750 (epoch 4.198), train_loss = 1.50252406, grad/param norm = 2.0029e-01, time/batch = 0.6816s	
1911/22750 (epoch 4.200), train_loss = 1.82368523, grad/param norm = 2.0589e-01, time/batch = 0.6810s	
1912/22750 (epoch 4.202), train_loss = 2.04792325, grad/param norm = 2.4916e-01, time/batch = 0.6815s	
1913/22750 (epoch 4.204), train_loss = 1.96131788, grad/param norm = 2.2779e-01, time/batch = 0.6874s	
1914/22750 (epoch 4.207), train_loss = 1.72577345, grad/param norm = 2.3313e-01, time/batch = 0.6861s	
1915/22750 (epoch 4.209), train_loss = 1.67233913, grad/param norm = 2.0890e-01, time/batch = 0.6877s	
1916/22750 (epoch 4.211), train_loss = 1.75423435, grad/param norm = 2.2086e-01, time/batch = 0.6951s	
1917/22750 (epoch 4.213), train_loss = 1.61871618, grad/param norm = 2.0823e-01, time/batch = 0.6844s	
1918/22750 (epoch 4.215), train_loss = 1.67929180, grad/param norm = 2.0974e-01, time/batch = 0.6813s	
1919/22750 (epoch 4.218), train_loss = 1.55535750, grad/param norm = 2.3493e-01, time/batch = 0.6806s	
1920/22750 (epoch 4.220), train_loss = 1.79557776, grad/param norm = 2.5838e-01, time/batch = 0.6850s	
1921/22750 (epoch 4.222), train_loss = 1.58723066, grad/param norm = 2.4031e-01, time/batch = 0.7166s	
1922/22750 (epoch 4.224), train_loss = 1.66836891, grad/param norm = 2.1768e-01, time/batch = 0.7120s	
1923/22750 (epoch 4.226), train_loss = 1.80109987, grad/param norm = 2.4268e-01, time/batch = 0.6837s	
1924/22750 (epoch 4.229), train_loss = 1.85496806, grad/param norm = 2.2511e-01, time/batch = 0.6817s	
1925/22750 (epoch 4.231), train_loss = 1.71465484, grad/param norm = 1.9953e-01, time/batch = 0.6804s	
1926/22750 (epoch 4.233), train_loss = 1.67269521, grad/param norm = 2.0583e-01, time/batch = 0.6826s	
1927/22750 (epoch 4.235), train_loss = 1.61608412, grad/param norm = 2.1606e-01, time/batch = 0.6919s	
1928/22750 (epoch 4.237), train_loss = 1.70851384, grad/param norm = 2.2124e-01, time/batch = 0.7109s	
1929/22750 (epoch 4.240), train_loss = 1.87950168, grad/param norm = 2.1156e-01, time/batch = 0.7034s	
1930/22750 (epoch 4.242), train_loss = 2.18451936, grad/param norm = 2.4422e-01, time/batch = 0.7214s	
1931/22750 (epoch 4.244), train_loss = 1.98129370, grad/param norm = 2.9436e-01, time/batch = 0.6910s	
1932/22750 (epoch 4.246), train_loss = 2.06108543, grad/param norm = 2.2085e-01, time/batch = 0.6935s	
1933/22750 (epoch 4.248), train_loss = 1.71988573, grad/param norm = 2.3271e-01, time/batch = 0.6835s	
1934/22750 (epoch 4.251), train_loss = 1.98583470, grad/param norm = 2.2660e-01, time/batch = 0.6844s	
1935/22750 (epoch 4.253), train_loss = 1.81719211, grad/param norm = 2.1218e-01, time/batch = 0.6856s	
1936/22750 (epoch 4.255), train_loss = 1.85947370, grad/param norm = 2.2502e-01, time/batch = 0.6802s	
1937/22750 (epoch 4.257), train_loss = 1.74763796, grad/param norm = 2.3137e-01, time/batch = 0.6829s	
1938/22750 (epoch 4.259), train_loss = 1.90407492, grad/param norm = 2.5568e-01, time/batch = 0.6789s	
1939/22750 (epoch 4.262), train_loss = 1.78601739, grad/param norm = 2.3665e-01, time/batch = 0.6830s	
1940/22750 (epoch 4.264), train_loss = 1.72367024, grad/param norm = 2.1793e-01, time/batch = 0.6792s	
1941/22750 (epoch 4.266), train_loss = 1.71469714, grad/param norm = 2.2779e-01, time/batch = 0.6784s	
1942/22750 (epoch 4.268), train_loss = 1.85188299, grad/param norm = 2.1099e-01, time/batch = 0.6800s	
1943/22750 (epoch 4.270), train_loss = 1.65121258, grad/param norm = 2.3862e-01, time/batch = 0.6804s	
1944/22750 (epoch 4.273), train_loss = 1.99270234, grad/param norm = 2.5968e-01, time/batch = 0.6778s	
1945/22750 (epoch 4.275), train_loss = 1.76505923, grad/param norm = 2.1987e-01, time/batch = 0.6831s	
1946/22750 (epoch 4.277), train_loss = 1.82828784, grad/param norm = 2.2987e-01, time/batch = 0.6852s	
1947/22750 (epoch 4.279), train_loss = 1.56545761, grad/param norm = 1.9403e-01, time/batch = 0.6822s	
1948/22750 (epoch 4.281), train_loss = 1.75196921, grad/param norm = 2.1806e-01, time/batch = 0.6792s	
1949/22750 (epoch 4.284), train_loss = 1.64422866, grad/param norm = 1.9586e-01, time/batch = 0.7037s	
1950/22750 (epoch 4.286), train_loss = 1.82519452, grad/param norm = 2.2176e-01, time/batch = 0.6970s	
1951/22750 (epoch 4.288), train_loss = 1.91289827, grad/param norm = 2.0986e-01, time/batch = 0.6921s	
1952/22750 (epoch 4.290), train_loss = 1.64132083, grad/param norm = 2.1110e-01, time/batch = 0.7148s	
1953/22750 (epoch 4.292), train_loss = 1.73827152, grad/param norm = 2.2558e-01, time/batch = 0.6910s	
1954/22750 (epoch 4.295), train_loss = 1.77294837, grad/param norm = 2.1273e-01, time/batch = 0.6817s	
1955/22750 (epoch 4.297), train_loss = 1.67881897, grad/param norm = 2.1232e-01, time/batch = 0.6814s	
1956/22750 (epoch 4.299), train_loss = 1.90213400, grad/param norm = 2.2574e-01, time/batch = 0.6838s	
1957/22750 (epoch 4.301), train_loss = 1.82328873, grad/param norm = 2.1015e-01, time/batch = 0.6840s	
1958/22750 (epoch 4.303), train_loss = 1.90725507, grad/param norm = 2.3324e-01, time/batch = 0.6813s	
1959/22750 (epoch 4.305), train_loss = 1.92341791, grad/param norm = 2.2719e-01, time/batch = 0.6778s	
1960/22750 (epoch 4.308), train_loss = 1.79096319, grad/param norm = 2.0374e-01, time/batch = 0.6812s	
1961/22750 (epoch 4.310), train_loss = 1.72958255, grad/param norm = 2.2739e-01, time/batch = 0.6827s	
1962/22750 (epoch 4.312), train_loss = 1.75869728, grad/param norm = 2.1327e-01, time/batch = 0.7108s	
1963/22750 (epoch 4.314), train_loss = 1.74283824, grad/param norm = 2.0864e-01, time/batch = 0.6936s	
1964/22750 (epoch 4.316), train_loss = 1.71414442, grad/param norm = 2.1674e-01, time/batch = 0.6787s	
1965/22750 (epoch 4.319), train_loss = 1.81520931, grad/param norm = 2.1026e-01, time/batch = 0.6777s	
1966/22750 (epoch 4.321), train_loss = 1.73717382, grad/param norm = 2.3660e-01, time/batch = 0.6827s	
1967/22750 (epoch 4.323), train_loss = 1.67167984, grad/param norm = 2.2767e-01, time/batch = 0.6752s	
1968/22750 (epoch 4.325), train_loss = 1.46169332, grad/param norm = 2.1201e-01, time/batch = 0.6785s	
1969/22750 (epoch 4.327), train_loss = 1.80112783, grad/param norm = 2.2339e-01, time/batch = 0.6782s	
1970/22750 (epoch 4.330), train_loss = 2.06264517, grad/param norm = 2.2920e-01, time/batch = 0.6835s	
1971/22750 (epoch 4.332), train_loss = 1.82295737, grad/param norm = 2.2112e-01, time/batch = 0.6889s	
1972/22750 (epoch 4.334), train_loss = 1.48507576, grad/param norm = 1.9640e-01, time/batch = 0.6892s	
1973/22750 (epoch 4.336), train_loss = 1.81668132, grad/param norm = 2.0742e-01, time/batch = 0.6897s	
1974/22750 (epoch 4.338), train_loss = 1.78037494, grad/param norm = 2.2410e-01, time/batch = 0.6881s	
1975/22750 (epoch 4.341), train_loss = 1.72387007, grad/param norm = 2.1297e-01, time/batch = 0.6977s	
1976/22750 (epoch 4.343), train_loss = 1.57099695, grad/param norm = 2.2306e-01, time/batch = 0.6895s	
1977/22750 (epoch 4.345), train_loss = 1.91613755, grad/param norm = 2.3808e-01, time/batch = 0.6819s	
1978/22750 (epoch 4.347), train_loss = 1.88862574, grad/param norm = 2.2821e-01, time/batch = 0.6968s	
1979/22750 (epoch 4.349), train_loss = 1.46052004, grad/param norm = 2.3416e-01, time/batch = 0.6891s	
1980/22750 (epoch 4.352), train_loss = 1.85339145, grad/param norm = 2.4987e-01, time/batch = 0.6806s	
1981/22750 (epoch 4.354), train_loss = 1.94286062, grad/param norm = 2.2550e-01, time/batch = 0.6882s	
1982/22750 (epoch 4.356), train_loss = 1.95560828, grad/param norm = 2.0944e-01, time/batch = 0.7033s	
1983/22750 (epoch 4.358), train_loss = 1.71436434, grad/param norm = 2.2659e-01, time/batch = 0.7047s	
1984/22750 (epoch 4.360), train_loss = 1.99797077, grad/param norm = 2.4100e-01, time/batch = 0.6860s	
1985/22750 (epoch 4.363), train_loss = 1.76293324, grad/param norm = 2.0723e-01, time/batch = 0.6845s	
1986/22750 (epoch 4.365), train_loss = 1.49064478, grad/param norm = 2.2954e-01, time/batch = 0.6840s	
1987/22750 (epoch 4.367), train_loss = 1.46253896, grad/param norm = 1.8656e-01, time/batch = 0.6823s	
1988/22750 (epoch 4.369), train_loss = 1.70852231, grad/param norm = 2.4368e-01, time/batch = 0.6810s	
1989/22750 (epoch 4.371), train_loss = 1.68496436, grad/param norm = 2.3509e-01, time/batch = 0.6848s	
1990/22750 (epoch 4.374), train_loss = 1.56975943, grad/param norm = 2.3459e-01, time/batch = 0.6847s	
1991/22750 (epoch 4.376), train_loss = 1.81588135, grad/param norm = 2.1770e-01, time/batch = 0.6853s	
1992/22750 (epoch 4.378), train_loss = 1.67331337, grad/param norm = 2.1294e-01, time/batch = 0.7009s	
1993/22750 (epoch 4.380), train_loss = 1.87851823, grad/param norm = 2.3561e-01, time/batch = 0.7083s	
1994/22750 (epoch 4.382), train_loss = 1.64188768, grad/param norm = 2.0798e-01, time/batch = 0.6811s	
1995/22750 (epoch 4.385), train_loss = 1.76807324, grad/param norm = 1.8920e-01, time/batch = 0.6831s	
1996/22750 (epoch 4.387), train_loss = 1.83966974, grad/param norm = 2.1304e-01, time/batch = 0.6787s	
1997/22750 (epoch 4.389), train_loss = 1.38602859, grad/param norm = 2.3881e-01, time/batch = 0.6797s	
1998/22750 (epoch 4.391), train_loss = 1.22456338, grad/param norm = 1.9998e-01, time/batch = 0.6802s	
1999/22750 (epoch 4.393), train_loss = 1.55861042, grad/param norm = 2.2199e-01, time/batch = 0.6817s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch4.40_1.7480.t7	
2000/22750 (epoch 4.396), train_loss = 1.73519479, grad/param norm = 2.3567e-01, time/batch = 0.6885s	
2001/22750 (epoch 4.398), train_loss = 1.93869673, grad/param norm = 2.4878e-01, time/batch = 0.7049s	
2002/22750 (epoch 4.400), train_loss = 1.71371534, grad/param norm = 2.0652e-01, time/batch = 0.7004s	
2003/22750 (epoch 4.402), train_loss = 1.73339542, grad/param norm = 2.1079e-01, time/batch = 0.6930s	
2004/22750 (epoch 4.404), train_loss = 1.97241131, grad/param norm = 2.5001e-01, time/batch = 0.6810s	
2005/22750 (epoch 4.407), train_loss = 1.82931432, grad/param norm = 2.2093e-01, time/batch = 0.6919s	
2006/22750 (epoch 4.409), train_loss = 1.73739381, grad/param norm = 2.2698e-01, time/batch = 0.7064s	
2007/22750 (epoch 4.411), train_loss = 1.74601372, grad/param norm = 2.0740e-01, time/batch = 0.6934s	
2008/22750 (epoch 4.413), train_loss = 1.64875345, grad/param norm = 2.2727e-01, time/batch = 0.7199s	
2009/22750 (epoch 4.415), train_loss = 1.50468225, grad/param norm = 2.2880e-01, time/batch = 0.7122s	
2010/22750 (epoch 4.418), train_loss = 1.64874946, grad/param norm = 2.0893e-01, time/batch = 0.7294s	
2011/22750 (epoch 4.420), train_loss = 1.98181817, grad/param norm = 2.3683e-01, time/batch = 0.7135s	
2012/22750 (epoch 4.422), train_loss = 2.03583968, grad/param norm = 2.2861e-01, time/batch = 0.7006s	
2013/22750 (epoch 4.424), train_loss = 2.05369082, grad/param norm = 2.3730e-01, time/batch = 0.6925s	
2014/22750 (epoch 4.426), train_loss = 2.01929132, grad/param norm = 2.0627e-01, time/batch = 0.6950s	
2015/22750 (epoch 4.429), train_loss = 1.50067511, grad/param norm = 2.0249e-01, time/batch = 0.7059s	
2016/22750 (epoch 4.431), train_loss = 1.49304536, grad/param norm = 2.0253e-01, time/batch = 0.7235s	
2017/22750 (epoch 4.433), train_loss = 1.56944835, grad/param norm = 1.9526e-01, time/batch = 0.6984s	
2018/22750 (epoch 4.435), train_loss = 1.47715521, grad/param norm = 2.2032e-01, time/batch = 0.6934s	
2019/22750 (epoch 4.437), train_loss = 1.43032535, grad/param norm = 1.9706e-01, time/batch = 0.6969s	
2020/22750 (epoch 4.440), train_loss = 1.92411584, grad/param norm = 2.3921e-01, time/batch = 0.6990s	
2021/22750 (epoch 4.442), train_loss = 1.72635881, grad/param norm = 2.2001e-01, time/batch = 0.6972s	
2022/22750 (epoch 4.444), train_loss = 1.83053152, grad/param norm = 2.9709e-01, time/batch = 0.6944s	
2023/22750 (epoch 4.446), train_loss = 1.78138733, grad/param norm = 2.5162e-01, time/batch = 0.7104s	
2024/22750 (epoch 4.448), train_loss = 2.01130522, grad/param norm = 2.3245e-01, time/batch = 0.7047s	
2025/22750 (epoch 4.451), train_loss = 1.92624930, grad/param norm = 2.4036e-01, time/batch = 0.7026s	
2026/22750 (epoch 4.453), train_loss = 2.04009237, grad/param norm = 2.6281e-01, time/batch = 0.7152s	
2027/22750 (epoch 4.455), train_loss = 2.06168409, grad/param norm = 2.2134e-01, time/batch = 0.6985s	
2028/22750 (epoch 4.457), train_loss = 1.91702484, grad/param norm = 2.4381e-01, time/batch = 0.6961s	
2029/22750 (epoch 4.459), train_loss = 1.79090593, grad/param norm = 2.1277e-01, time/batch = 0.6935s	
2030/22750 (epoch 4.462), train_loss = 1.75104086, grad/param norm = 1.8852e-01, time/batch = 0.7028s	
2031/22750 (epoch 4.464), train_loss = 1.58868418, grad/param norm = 2.0480e-01, time/batch = 0.6974s	
2032/22750 (epoch 4.466), train_loss = 1.99681049, grad/param norm = 2.2666e-01, time/batch = 0.6966s	
2033/22750 (epoch 4.468), train_loss = 1.72356377, grad/param norm = 2.2703e-01, time/batch = 0.6981s	
2034/22750 (epoch 4.470), train_loss = 1.91441489, grad/param norm = 2.4180e-01, time/batch = 0.7031s	
2035/22750 (epoch 4.473), train_loss = 1.77472477, grad/param norm = 2.2292e-01, time/batch = 0.7114s	
2036/22750 (epoch 4.475), train_loss = 1.83704518, grad/param norm = 2.0880e-01, time/batch = 0.7222s	
2037/22750 (epoch 4.477), train_loss = 1.55098520, grad/param norm = 2.1245e-01, time/batch = 0.6978s	
2038/22750 (epoch 4.479), train_loss = 1.61077958, grad/param norm = 1.8928e-01, time/batch = 0.6956s	
2039/22750 (epoch 4.481), train_loss = 1.58381989, grad/param norm = 2.2527e-01, time/batch = 0.6935s	
2040/22750 (epoch 4.484), train_loss = 1.37983082, grad/param norm = 2.1863e-01, time/batch = 0.7027s	
2041/22750 (epoch 4.486), train_loss = 1.66869741, grad/param norm = 2.4850e-01, time/batch = 0.7023s	
2042/22750 (epoch 4.488), train_loss = 1.35830733, grad/param norm = 2.4353e-01, time/batch = 0.6966s	
2043/22750 (epoch 4.490), train_loss = 1.59319670, grad/param norm = 2.1863e-01, time/batch = 0.7011s	
2044/22750 (epoch 4.492), train_loss = 1.89400362, grad/param norm = 2.6437e-01, time/batch = 0.6919s	
2045/22750 (epoch 4.495), train_loss = 1.67441982, grad/param norm = 2.5200e-01, time/batch = 0.7117s	
2046/22750 (epoch 4.497), train_loss = 1.83269695, grad/param norm = 2.3207e-01, time/batch = 0.7210s	
2047/22750 (epoch 4.499), train_loss = 1.69931944, grad/param norm = 2.0779e-01, time/batch = 0.6988s	
2048/22750 (epoch 4.501), train_loss = 1.73945591, grad/param norm = 2.0729e-01, time/batch = 0.7004s	
2049/22750 (epoch 4.503), train_loss = 1.73768198, grad/param norm = 2.1560e-01, time/batch = 0.7018s	
2050/22750 (epoch 4.505), train_loss = 1.56443390, grad/param norm = 2.0152e-01, time/batch = 0.6978s	
2051/22750 (epoch 4.508), train_loss = 1.51955909, grad/param norm = 2.2715e-01, time/batch = 0.7046s	
2052/22750 (epoch 4.510), train_loss = 1.53516059, grad/param norm = 2.0781e-01, time/batch = 0.6973s	
2053/22750 (epoch 4.512), train_loss = 1.63610795, grad/param norm = 2.0415e-01, time/batch = 0.6967s	
2054/22750 (epoch 4.514), train_loss = 1.63323480, grad/param norm = 2.0360e-01, time/batch = 0.6964s	
2055/22750 (epoch 4.516), train_loss = 1.55337586, grad/param norm = 2.2905e-01, time/batch = 0.7105s	
2056/22750 (epoch 4.519), train_loss = 1.74116455, grad/param norm = 2.4029e-01, time/batch = 0.7176s	
2057/22750 (epoch 4.521), train_loss = 1.57491277, grad/param norm = 2.5229e-01, time/batch = 0.6974s	
2058/22750 (epoch 4.523), train_loss = 1.63446166, grad/param norm = 2.6119e-01, time/batch = 0.7025s	
2059/22750 (epoch 4.525), train_loss = 1.86294918, grad/param norm = 2.3746e-01, time/batch = 0.6973s	
2060/22750 (epoch 4.527), train_loss = 1.72416184, grad/param norm = 2.2558e-01, time/batch = 0.6953s	
2061/22750 (epoch 4.530), train_loss = 1.59049236, grad/param norm = 2.2054e-01, time/batch = 0.6972s	
2062/22750 (epoch 4.532), train_loss = 1.62519900, grad/param norm = 2.0557e-01, time/batch = 0.6994s	
2063/22750 (epoch 4.534), train_loss = 1.86493101, grad/param norm = 2.4441e-01, time/batch = 0.6987s	
2064/22750 (epoch 4.536), train_loss = 1.71445631, grad/param norm = 2.1619e-01, time/batch = 0.7004s	
2065/22750 (epoch 4.538), train_loss = 1.77618878, grad/param norm = 1.9463e-01, time/batch = 0.7109s	
2066/22750 (epoch 4.541), train_loss = 1.44492846, grad/param norm = 2.0301e-01, time/batch = 0.7345s	
2067/22750 (epoch 4.543), train_loss = 1.46467248, grad/param norm = 1.9967e-01, time/batch = 0.7086s	
2068/22750 (epoch 4.545), train_loss = 1.86578112, grad/param norm = 2.2010e-01, time/batch = 0.7034s	
2069/22750 (epoch 4.547), train_loss = 1.46916733, grad/param norm = 2.0127e-01, time/batch = 0.7008s	
2070/22750 (epoch 4.549), train_loss = 1.58464032, grad/param norm = 2.3763e-01, time/batch = 0.7124s	
2071/22750 (epoch 4.552), train_loss = 1.81598109, grad/param norm = 2.5044e-01, time/batch = 0.7030s	
2072/22750 (epoch 4.554), train_loss = 1.83677152, grad/param norm = 2.1055e-01, time/batch = 0.7043s	
2073/22750 (epoch 4.556), train_loss = 1.67701009, grad/param norm = 2.1622e-01, time/batch = 0.6992s	
2074/22750 (epoch 4.558), train_loss = 1.87261937, grad/param norm = 2.0831e-01, time/batch = 0.7008s	
2075/22750 (epoch 4.560), train_loss = 1.54238691, grad/param norm = 1.9561e-01, time/batch = 0.7214s	
2076/22750 (epoch 4.563), train_loss = 1.75283469, grad/param norm = 2.1624e-01, time/batch = 0.7154s	
2077/22750 (epoch 4.565), train_loss = 1.90098061, grad/param norm = 2.0087e-01, time/batch = 0.7016s	
2078/22750 (epoch 4.567), train_loss = 1.71231220, grad/param norm = 2.0831e-01, time/batch = 0.7027s	
2079/22750 (epoch 4.569), train_loss = 1.66051229, grad/param norm = 2.1834e-01, time/batch = 0.6999s	
2080/22750 (epoch 4.571), train_loss = 1.75396955, grad/param norm = 2.3327e-01, time/batch = 0.7051s	
2081/22750 (epoch 4.574), train_loss = 1.52936161, grad/param norm = 2.1987e-01, time/batch = 0.7065s	
2082/22750 (epoch 4.576), train_loss = 1.73992792, grad/param norm = 2.0491e-01, time/batch = 0.7029s	
2083/22750 (epoch 4.578), train_loss = 1.51292420, grad/param norm = 2.0801e-01, time/batch = 0.7031s	
2084/22750 (epoch 4.580), train_loss = 1.79048837, grad/param norm = 2.2059e-01, time/batch = 0.6993s	
2085/22750 (epoch 4.582), train_loss = 1.46881386, grad/param norm = 2.2241e-01, time/batch = 0.7257s	
2086/22750 (epoch 4.585), train_loss = 1.39746971, grad/param norm = 1.8918e-01, time/batch = 0.7217s	
2087/22750 (epoch 4.587), train_loss = 1.50501934, grad/param norm = 1.8659e-01, time/batch = 0.7021s	
2088/22750 (epoch 4.589), train_loss = 1.52433286, grad/param norm = 2.1903e-01, time/batch = 0.7048s	
2089/22750 (epoch 4.591), train_loss = 1.75735278, grad/param norm = 2.4608e-01, time/batch = 0.7021s	
2090/22750 (epoch 4.593), train_loss = 1.89824402, grad/param norm = 2.0603e-01, time/batch = 0.7198s	
2091/22750 (epoch 4.596), train_loss = 1.84733792, grad/param norm = 2.0229e-01, time/batch = 0.7006s	
2092/22750 (epoch 4.598), train_loss = 1.91222845, grad/param norm = 2.1680e-01, time/batch = 0.7201s	
2093/22750 (epoch 4.600), train_loss = 1.74432258, grad/param norm = 2.0696e-01, time/batch = 0.7326s	
2094/22750 (epoch 4.602), train_loss = 1.49432235, grad/param norm = 1.8497e-01, time/batch = 0.7400s	
2095/22750 (epoch 4.604), train_loss = 1.64256123, grad/param norm = 2.0801e-01, time/batch = 0.7308s	
2096/22750 (epoch 4.607), train_loss = 1.35045508, grad/param norm = 1.8712e-01, time/batch = 0.7217s	
2097/22750 (epoch 4.609), train_loss = 1.35233635, grad/param norm = 1.8486e-01, time/batch = 0.7164s	
2098/22750 (epoch 4.611), train_loss = 1.60186229, grad/param norm = 2.1951e-01, time/batch = 0.7320s	
2099/22750 (epoch 4.613), train_loss = 1.53888882, grad/param norm = 2.2436e-01, time/batch = 0.7323s	
2100/22750 (epoch 4.615), train_loss = 1.63075422, grad/param norm = 2.2201e-01, time/batch = 0.7005s	
2101/22750 (epoch 4.618), train_loss = 1.69820072, grad/param norm = 2.3894e-01, time/batch = 0.7149s	
2102/22750 (epoch 4.620), train_loss = 1.65119613, grad/param norm = 2.1135e-01, time/batch = 0.7077s	
2103/22750 (epoch 4.622), train_loss = 1.49713965, grad/param norm = 2.4162e-01, time/batch = 0.6988s	
2104/22750 (epoch 4.624), train_loss = 1.83618572, grad/param norm = 2.4267e-01, time/batch = 0.7161s	
2105/22750 (epoch 4.626), train_loss = 1.61621514, grad/param norm = 2.6083e-01, time/batch = 0.7251s	
2106/22750 (epoch 4.629), train_loss = 1.72362090, grad/param norm = 2.4020e-01, time/batch = 0.7075s	
2107/22750 (epoch 4.631), train_loss = 1.76195821, grad/param norm = 2.2388e-01, time/batch = 0.7066s	
2108/22750 (epoch 4.633), train_loss = 1.43619550, grad/param norm = 2.2143e-01, time/batch = 0.7018s	
2109/22750 (epoch 4.635), train_loss = 1.80962497, grad/param norm = 2.1613e-01, time/batch = 0.7052s	
2110/22750 (epoch 4.637), train_loss = 1.79247008, grad/param norm = 2.2480e-01, time/batch = 0.7062s	
2111/22750 (epoch 4.640), train_loss = 1.91014833, grad/param norm = 2.4239e-01, time/batch = 0.7067s	
2112/22750 (epoch 4.642), train_loss = 1.83893000, grad/param norm = 2.4298e-01, time/batch = 0.6965s	
2113/22750 (epoch 4.644), train_loss = 1.69986009, grad/param norm = 2.1645e-01, time/batch = 0.7026s	
2114/22750 (epoch 4.646), train_loss = 1.81382506, grad/param norm = 2.4851e-01, time/batch = 0.7175s	
2115/22750 (epoch 4.648), train_loss = 1.75116095, grad/param norm = 2.4566e-01, time/batch = 0.7223s	
2116/22750 (epoch 4.651), train_loss = 1.87913371, grad/param norm = 2.3351e-01, time/batch = 0.6963s	
2117/22750 (epoch 4.653), train_loss = 1.70007699, grad/param norm = 2.0840e-01, time/batch = 0.6980s	
2118/22750 (epoch 4.655), train_loss = 1.68806164, grad/param norm = 2.1394e-01, time/batch = 0.6993s	
2119/22750 (epoch 4.657), train_loss = 1.90813026, grad/param norm = 1.9955e-01, time/batch = 0.7017s	
2120/22750 (epoch 4.659), train_loss = 1.94639194, grad/param norm = 2.1678e-01, time/batch = 0.7002s	
2121/22750 (epoch 4.662), train_loss = 2.02936764, grad/param norm = 2.2681e-01, time/batch = 0.7083s	
2122/22750 (epoch 4.664), train_loss = 1.78496963, grad/param norm = 2.3698e-01, time/batch = 0.7031s	
2123/22750 (epoch 4.666), train_loss = 1.58404913, grad/param norm = 2.1996e-01, time/batch = 0.7016s	
2124/22750 (epoch 4.668), train_loss = 1.74476185, grad/param norm = 2.0943e-01, time/batch = 0.7220s	
2125/22750 (epoch 4.670), train_loss = 1.74584704, grad/param norm = 2.0931e-01, time/batch = 0.7208s	
2126/22750 (epoch 4.673), train_loss = 1.91486259, grad/param norm = 2.6213e-01, time/batch = 0.7035s	
2127/22750 (epoch 4.675), train_loss = 2.20822713, grad/param norm = 2.7705e-01, time/batch = 0.7073s	
2128/22750 (epoch 4.677), train_loss = 1.95891878, grad/param norm = 2.4120e-01, time/batch = 0.7056s	
2129/22750 (epoch 4.679), train_loss = 2.01778671, grad/param norm = 2.1968e-01, time/batch = 0.6983s	
2130/22750 (epoch 4.681), train_loss = 1.86914851, grad/param norm = 2.2665e-01, time/batch = 0.6974s	
2131/22750 (epoch 4.684), train_loss = 1.87521662, grad/param norm = 2.1925e-01, time/batch = 0.6951s	
2132/22750 (epoch 4.686), train_loss = 1.84980395, grad/param norm = 2.3339e-01, time/batch = 0.6976s	
2133/22750 (epoch 4.688), train_loss = 1.84005745, grad/param norm = 2.2069e-01, time/batch = 0.6970s	
2134/22750 (epoch 4.690), train_loss = 1.78558238, grad/param norm = 2.1798e-01, time/batch = 0.7013s	
2135/22750 (epoch 4.692), train_loss = 1.95622180, grad/param norm = 2.2581e-01, time/batch = 0.6942s	
2136/22750 (epoch 4.695), train_loss = 1.73284551, grad/param norm = 2.2407e-01, time/batch = 0.6945s	
2137/22750 (epoch 4.697), train_loss = 1.65590811, grad/param norm = 2.5036e-01, time/batch = 0.6934s	
2138/22750 (epoch 4.699), train_loss = 1.77718847, grad/param norm = 2.1531e-01, time/batch = 0.6928s	
2139/22750 (epoch 4.701), train_loss = 1.62256368, grad/param norm = 2.1035e-01, time/batch = 0.6938s	
2140/22750 (epoch 4.703), train_loss = 1.76008884, grad/param norm = 2.0710e-01, time/batch = 0.6927s	
2141/22750 (epoch 4.705), train_loss = 1.56049257, grad/param norm = 1.9008e-01, time/batch = 0.6923s	
2142/22750 (epoch 4.708), train_loss = 1.73635377, grad/param norm = 1.8821e-01, time/batch = 0.6995s	
2143/22750 (epoch 4.710), train_loss = 1.49306877, grad/param norm = 2.2161e-01, time/batch = 0.7051s	
2144/22750 (epoch 4.712), train_loss = 1.57805814, grad/param norm = 2.0772e-01, time/batch = 0.7001s	
2145/22750 (epoch 4.714), train_loss = 1.48505349, grad/param norm = 2.1972e-01, time/batch = 0.6979s	
2146/22750 (epoch 4.716), train_loss = 1.62645846, grad/param norm = 2.2851e-01, time/batch = 0.7103s	
2147/22750 (epoch 4.719), train_loss = 1.86981747, grad/param norm = 2.7998e-01, time/batch = 0.7103s	
2148/22750 (epoch 4.721), train_loss = 1.77792156, grad/param norm = 2.3167e-01, time/batch = 0.6918s	
2149/22750 (epoch 4.723), train_loss = 1.66286898, grad/param norm = 2.0104e-01, time/batch = 0.6921s	
2150/22750 (epoch 4.725), train_loss = 1.68732951, grad/param norm = 2.4170e-01, time/batch = 0.6916s	
2151/22750 (epoch 4.727), train_loss = 1.60153315, grad/param norm = 1.9779e-01, time/batch = 0.6962s	
2152/22750 (epoch 4.730), train_loss = 1.63162515, grad/param norm = 2.0017e-01, time/batch = 0.6890s	
2153/22750 (epoch 4.732), train_loss = 1.71154970, grad/param norm = 2.0565e-01, time/batch = 0.6935s	
2154/22750 (epoch 4.734), train_loss = 1.32836903, grad/param norm = 2.2500e-01, time/batch = 0.7186s	
2155/22750 (epoch 4.736), train_loss = 1.60795491, grad/param norm = 2.1584e-01, time/batch = 0.7226s	
2156/22750 (epoch 4.738), train_loss = 1.63630435, grad/param norm = 2.2545e-01, time/batch = 0.7008s	
2157/22750 (epoch 4.741), train_loss = 1.80843463, grad/param norm = 2.0181e-01, time/batch = 0.6994s	
2158/22750 (epoch 4.743), train_loss = 1.78711206, grad/param norm = 2.3068e-01, time/batch = 0.6998s	
2159/22750 (epoch 4.745), train_loss = 1.48010724, grad/param norm = 1.9795e-01, time/batch = 0.7003s	
2160/22750 (epoch 4.747), train_loss = 1.61872686, grad/param norm = 2.1591e-01, time/batch = 0.7035s	
2161/22750 (epoch 4.749), train_loss = 1.88255022, grad/param norm = 2.3307e-01, time/batch = 0.6957s	
2162/22750 (epoch 4.752), train_loss = 1.59510569, grad/param norm = 2.1165e-01, time/batch = 0.6955s	
2163/22750 (epoch 4.754), train_loss = 1.83736018, grad/param norm = 2.5689e-01, time/batch = 0.7157s	
2164/22750 (epoch 4.756), train_loss = 1.49890099, grad/param norm = 2.5668e-01, time/batch = 0.7193s	
2165/22750 (epoch 4.758), train_loss = 1.43487983, grad/param norm = 2.1127e-01, time/batch = 0.6931s	
2166/22750 (epoch 4.760), train_loss = 1.74483946, grad/param norm = 2.1434e-01, time/batch = 0.6893s	
2167/22750 (epoch 4.763), train_loss = 1.72810673, grad/param norm = 2.1011e-01, time/batch = 0.6924s	
2168/22750 (epoch 4.765), train_loss = 1.59021341, grad/param norm = 2.2806e-01, time/batch = 0.6933s	
2169/22750 (epoch 4.767), train_loss = 1.62779165, grad/param norm = 2.1799e-01, time/batch = 0.6934s	
2170/22750 (epoch 4.769), train_loss = 1.81905446, grad/param norm = 2.3890e-01, time/batch = 0.6972s	
2171/22750 (epoch 4.771), train_loss = 1.82211566, grad/param norm = 2.4183e-01, time/batch = 0.7036s	
2172/22750 (epoch 4.774), train_loss = 1.62489413, grad/param norm = 2.2470e-01, time/batch = 0.7011s	
2173/22750 (epoch 4.776), train_loss = 1.69413364, grad/param norm = 2.2101e-01, time/batch = 0.6949s	
2174/22750 (epoch 4.778), train_loss = 1.87411846, grad/param norm = 2.0095e-01, time/batch = 0.7241s	
2175/22750 (epoch 4.780), train_loss = 1.74724119, grad/param norm = 2.4061e-01, time/batch = 0.7086s	
2176/22750 (epoch 4.782), train_loss = 1.82153522, grad/param norm = 2.2711e-01, time/batch = 0.6960s	
2177/22750 (epoch 4.785), train_loss = 1.74373911, grad/param norm = 2.0719e-01, time/batch = 0.7172s	
2178/22750 (epoch 4.787), train_loss = 1.59955499, grad/param norm = 2.1147e-01, time/batch = 0.7261s	
2179/22750 (epoch 4.789), train_loss = 1.60003909, grad/param norm = 1.9806e-01, time/batch = 0.7192s	
2180/22750 (epoch 4.791), train_loss = 1.65602596, grad/param norm = 1.8160e-01, time/batch = 0.6979s	
2181/22750 (epoch 4.793), train_loss = 1.65780159, grad/param norm = 2.2158e-01, time/batch = 0.6959s	
2182/22750 (epoch 4.796), train_loss = 1.57786753, grad/param norm = 2.0823e-01, time/batch = 0.6969s	
2183/22750 (epoch 4.798), train_loss = 1.57690401, grad/param norm = 1.9119e-01, time/batch = 0.7024s	
2184/22750 (epoch 4.800), train_loss = 1.54635857, grad/param norm = 2.0310e-01, time/batch = 0.7261s	
2185/22750 (epoch 4.802), train_loss = 1.69084792, grad/param norm = 2.1613e-01, time/batch = 0.6999s	
2186/22750 (epoch 4.804), train_loss = 1.95067922, grad/param norm = 2.0285e-01, time/batch = 0.7114s	
2187/22750 (epoch 4.807), train_loss = 1.69815962, grad/param norm = 2.0488e-01, time/batch = 0.7176s	
2188/22750 (epoch 4.809), train_loss = 1.94102654, grad/param norm = 2.3051e-01, time/batch = 0.7024s	
2189/22750 (epoch 4.811), train_loss = 1.63300125, grad/param norm = 1.9541e-01, time/batch = 0.6913s	
2190/22750 (epoch 4.813), train_loss = 1.78001214, grad/param norm = 2.1250e-01, time/batch = 0.6909s	
2191/22750 (epoch 4.815), train_loss = 1.89274253, grad/param norm = 2.4014e-01, time/batch = 0.7012s	
2192/22750 (epoch 4.818), train_loss = 1.85966857, grad/param norm = 2.0837e-01, time/batch = 0.7245s	
2193/22750 (epoch 4.820), train_loss = 1.95528688, grad/param norm = 2.0154e-01, time/batch = 0.7178s	
2194/22750 (epoch 4.822), train_loss = 1.75460651, grad/param norm = 2.0305e-01, time/batch = 0.7269s	
2195/22750 (epoch 4.824), train_loss = 1.75269023, grad/param norm = 2.0342e-01, time/batch = 0.7169s	
2196/22750 (epoch 4.826), train_loss = 1.71475302, grad/param norm = 2.0385e-01, time/batch = 0.7112s	
2197/22750 (epoch 4.829), train_loss = 1.88944847, grad/param norm = 2.4678e-01, time/batch = 0.6985s	
2198/22750 (epoch 4.831), train_loss = 1.87318187, grad/param norm = 2.7693e-01, time/batch = 0.6978s	
2199/22750 (epoch 4.833), train_loss = 1.86693050, grad/param norm = 2.2913e-01, time/batch = 0.7024s	
2200/22750 (epoch 4.835), train_loss = 1.66884394, grad/param norm = 2.0997e-01, time/batch = 0.6964s	
2201/22750 (epoch 4.837), train_loss = 1.67606387, grad/param norm = 2.1545e-01, time/batch = 0.7167s	
2202/22750 (epoch 4.840), train_loss = 1.71369704, grad/param norm = 2.1855e-01, time/batch = 0.7249s	
2203/22750 (epoch 4.842), train_loss = 1.62277747, grad/param norm = 2.0594e-01, time/batch = 0.7242s	
2204/22750 (epoch 4.844), train_loss = 1.93359470, grad/param norm = 2.2968e-01, time/batch = 0.7227s	
2205/22750 (epoch 4.846), train_loss = 1.65215290, grad/param norm = 2.0272e-01, time/batch = 0.7193s	
2206/22750 (epoch 4.848), train_loss = 1.53050055, grad/param norm = 2.1441e-01, time/batch = 0.7121s	
2207/22750 (epoch 4.851), train_loss = 1.58308316, grad/param norm = 2.1300e-01, time/batch = 0.6904s	
2208/22750 (epoch 4.853), train_loss = 1.66190808, grad/param norm = 2.1729e-01, time/batch = 0.6938s	
2209/22750 (epoch 4.855), train_loss = 1.47434508, grad/param norm = 1.9654e-01, time/batch = 0.6904s	
2210/22750 (epoch 4.857), train_loss = 1.68327349, grad/param norm = 1.9590e-01, time/batch = 0.6924s	
2211/22750 (epoch 4.859), train_loss = 1.72368162, grad/param norm = 2.2668e-01, time/batch = 0.6958s	
2212/22750 (epoch 4.862), train_loss = 1.86915857, grad/param norm = 2.3404e-01, time/batch = 0.6940s	
2213/22750 (epoch 4.864), train_loss = 1.70448408, grad/param norm = 2.0342e-01, time/batch = 0.7139s	
2214/22750 (epoch 4.866), train_loss = 1.71247676, grad/param norm = 1.9612e-01, time/batch = 0.7222s	
2215/22750 (epoch 4.868), train_loss = 1.70745734, grad/param norm = 2.0355e-01, time/batch = 0.6935s	
2216/22750 (epoch 4.870), train_loss = 1.48487587, grad/param norm = 2.0945e-01, time/batch = 0.6931s	
2217/22750 (epoch 4.873), train_loss = 1.65224906, grad/param norm = 2.0178e-01, time/batch = 0.6997s	
2218/22750 (epoch 4.875), train_loss = 1.73870503, grad/param norm = 2.0855e-01, time/batch = 0.6925s	
2219/22750 (epoch 4.877), train_loss = 1.55862857, grad/param norm = 1.9639e-01, time/batch = 0.7007s	
2220/22750 (epoch 4.879), train_loss = 1.81519566, grad/param norm = 2.2211e-01, time/batch = 0.6934s	
2221/22750 (epoch 4.881), train_loss = 1.79207369, grad/param norm = 2.1802e-01, time/batch = 0.7019s	
2222/22750 (epoch 4.884), train_loss = 1.63458280, grad/param norm = 2.4661e-01, time/batch = 0.7051s	
2223/22750 (epoch 4.886), train_loss = 1.78446286, grad/param norm = 2.1061e-01, time/batch = 0.7012s	
2224/22750 (epoch 4.888), train_loss = 1.75171453, grad/param norm = 2.0329e-01, time/batch = 0.6988s	
2225/22750 (epoch 4.890), train_loss = 1.76304508, grad/param norm = 2.2249e-01, time/batch = 0.6995s	
2226/22750 (epoch 4.892), train_loss = 2.16226091, grad/param norm = 2.7367e-01, time/batch = 0.7022s	
2227/22750 (epoch 4.895), train_loss = 1.80033375, grad/param norm = 2.1290e-01, time/batch = 0.7174s	
2228/22750 (epoch 4.897), train_loss = 1.80891457, grad/param norm = 2.2673e-01, time/batch = 0.7100s	
2229/22750 (epoch 4.899), train_loss = 1.75961728, grad/param norm = 2.0511e-01, time/batch = 0.6958s	
2230/22750 (epoch 4.901), train_loss = 1.90243366, grad/param norm = 2.0799e-01, time/batch = 0.6912s	
2231/22750 (epoch 4.903), train_loss = 1.69181611, grad/param norm = 2.0494e-01, time/batch = 0.6953s	
2232/22750 (epoch 4.905), train_loss = 1.72594943, grad/param norm = 1.8907e-01, time/batch = 0.7006s	
2233/22750 (epoch 4.908), train_loss = 1.70440866, grad/param norm = 2.1897e-01, time/batch = 0.7000s	
2234/22750 (epoch 4.910), train_loss = 1.51896922, grad/param norm = 2.3184e-01, time/batch = 0.7078s	
2235/22750 (epoch 4.912), train_loss = 1.53884627, grad/param norm = 2.2108e-01, time/batch = 0.7042s	
2236/22750 (epoch 4.914), train_loss = 1.62148881, grad/param norm = 1.9953e-01, time/batch = 0.7006s	
2237/22750 (epoch 4.916), train_loss = 1.46223824, grad/param norm = 1.9436e-01, time/batch = 0.6972s	
2238/22750 (epoch 4.919), train_loss = 1.59238468, grad/param norm = 2.1553e-01, time/batch = 0.7030s	
2239/22750 (epoch 4.921), train_loss = 1.29007845, grad/param norm = 1.8899e-01, time/batch = 0.6994s	
2240/22750 (epoch 4.923), train_loss = 1.64711959, grad/param norm = 2.1060e-01, time/batch = 0.7000s	
2241/22750 (epoch 4.925), train_loss = 1.64281423, grad/param norm = 2.0838e-01, time/batch = 0.6936s	
2242/22750 (epoch 4.927), train_loss = 1.43072533, grad/param norm = 1.9741e-01, time/batch = 0.7005s	
2243/22750 (epoch 4.930), train_loss = 1.49805565, grad/param norm = 2.0671e-01, time/batch = 0.6958s	
2244/22750 (epoch 4.932), train_loss = 1.83415989, grad/param norm = 2.2457e-01, time/batch = 0.6946s	
2245/22750 (epoch 4.934), train_loss = 1.31416540, grad/param norm = 1.8719e-01, time/batch = 0.6994s	
2246/22750 (epoch 4.936), train_loss = 1.82523968, grad/param norm = 2.3665e-01, time/batch = 0.6982s	
2247/22750 (epoch 4.938), train_loss = 1.69958790, grad/param norm = 2.1731e-01, time/batch = 0.7023s	
2248/22750 (epoch 4.941), train_loss = 2.01850384, grad/param norm = 2.2590e-01, time/batch = 0.7008s	
2249/22750 (epoch 4.943), train_loss = 1.78221403, grad/param norm = 2.1003e-01, time/batch = 0.7071s	
2250/22750 (epoch 4.945), train_loss = 1.70372502, grad/param norm = 2.0550e-01, time/batch = 0.7000s	
2251/22750 (epoch 4.947), train_loss = 1.71524282, grad/param norm = 2.2485e-01, time/batch = 0.6997s	
2252/22750 (epoch 4.949), train_loss = 1.55568770, grad/param norm = 2.2165e-01, time/batch = 0.7021s	
2253/22750 (epoch 4.952), train_loss = 1.57731705, grad/param norm = 2.0314e-01, time/batch = 0.7187s	
2254/22750 (epoch 4.954), train_loss = 1.57527426, grad/param norm = 1.9795e-01, time/batch = 0.7153s	
2255/22750 (epoch 4.956), train_loss = 1.69638732, grad/param norm = 2.1036e-01, time/batch = 0.6962s	
2256/22750 (epoch 4.958), train_loss = 1.64117184, grad/param norm = 2.0299e-01, time/batch = 0.6966s	
2257/22750 (epoch 4.960), train_loss = 1.66627436, grad/param norm = 2.0614e-01, time/batch = 0.7102s	
2258/22750 (epoch 4.963), train_loss = 1.82815757, grad/param norm = 2.2285e-01, time/batch = 0.6985s	
2259/22750 (epoch 4.965), train_loss = 1.76652015, grad/param norm = 2.2441e-01, time/batch = 0.7009s	
2260/22750 (epoch 4.967), train_loss = 1.71669037, grad/param norm = 2.1958e-01, time/batch = 0.7020s	
2261/22750 (epoch 4.969), train_loss = 1.65445683, grad/param norm = 2.0788e-01, time/batch = 0.7005s	
2262/22750 (epoch 4.971), train_loss = 1.63531570, grad/param norm = 2.0225e-01, time/batch = 0.7229s	
2263/22750 (epoch 4.974), train_loss = 1.71398422, grad/param norm = 2.3928e-01, time/batch = 0.7271s	
2264/22750 (epoch 4.976), train_loss = 1.80679697, grad/param norm = 2.1560e-01, time/batch = 0.7129s	
2265/22750 (epoch 4.978), train_loss = 1.57074348, grad/param norm = 2.1078e-01, time/batch = 0.7066s	
2266/22750 (epoch 4.980), train_loss = 1.81070572, grad/param norm = 2.4109e-01, time/batch = 0.7009s	
2267/22750 (epoch 4.982), train_loss = 1.61197677, grad/param norm = 2.0000e-01, time/batch = 0.7025s	
2268/22750 (epoch 4.985), train_loss = 1.93208283, grad/param norm = 2.4461e-01, time/batch = 0.7028s	
2269/22750 (epoch 4.987), train_loss = 1.49458674, grad/param norm = 2.0859e-01, time/batch = 0.6979s	
2270/22750 (epoch 4.989), train_loss = 1.56972409, grad/param norm = 1.8111e-01, time/batch = 0.6979s	
2271/22750 (epoch 4.991), train_loss = 1.77217064, grad/param norm = 2.1383e-01, time/batch = 0.7040s	
2272/22750 (epoch 4.993), train_loss = 1.77016724, grad/param norm = 2.2665e-01, time/batch = 0.7005s	
2273/22750 (epoch 4.996), train_loss = 1.64370855, grad/param norm = 2.2728e-01, time/batch = 0.7260s	
2274/22750 (epoch 4.998), train_loss = 1.83886212, grad/param norm = 2.1155e-01, time/batch = 0.7047s	
2275/22750 (epoch 5.000), train_loss = 1.77036153, grad/param norm = 2.1700e-01, time/batch = 0.7221s	
2276/22750 (epoch 5.002), train_loss = 1.85499625, grad/param norm = 2.2999e-01, time/batch = 0.7197s	
2277/22750 (epoch 5.004), train_loss = 1.65843709, grad/param norm = 2.7038e-01, time/batch = 0.7237s	
2278/22750 (epoch 5.007), train_loss = 1.77333209, grad/param norm = 2.2972e-01, time/batch = 0.7066s	
2279/22750 (epoch 5.009), train_loss = 1.97286165, grad/param norm = 2.1981e-01, time/batch = 0.6998s	
2280/22750 (epoch 5.011), train_loss = 1.89872091, grad/param norm = 2.2046e-01, time/batch = 0.6976s	
2281/22750 (epoch 5.013), train_loss = 1.76148635, grad/param norm = 2.1465e-01, time/batch = 0.7140s	
2282/22750 (epoch 5.015), train_loss = 1.77856134, grad/param norm = 2.1629e-01, time/batch = 0.7028s	
2283/22750 (epoch 5.018), train_loss = 1.78603992, grad/param norm = 2.2258e-01, time/batch = 0.7024s	
2284/22750 (epoch 5.020), train_loss = 1.83682969, grad/param norm = 2.0607e-01, time/batch = 0.6969s	
2285/22750 (epoch 5.022), train_loss = 1.70358743, grad/param norm = 1.9806e-01, time/batch = 0.6997s	
2286/22750 (epoch 5.024), train_loss = 1.68153204, grad/param norm = 2.1068e-01, time/batch = 0.7043s	
2287/22750 (epoch 5.026), train_loss = 1.87858881, grad/param norm = 2.2735e-01, time/batch = 0.6981s	
2288/22750 (epoch 5.029), train_loss = 1.45627695, grad/param norm = 1.9942e-01, time/batch = 0.6917s	
2289/22750 (epoch 5.031), train_loss = 1.97513987, grad/param norm = 2.1884e-01, time/batch = 0.6962s	
2290/22750 (epoch 5.033), train_loss = 1.71449602, grad/param norm = 1.9421e-01, time/batch = 0.7031s	
2291/22750 (epoch 5.035), train_loss = 1.77787589, grad/param norm = 2.1250e-01, time/batch = 0.7081s	
2292/22750 (epoch 5.037), train_loss = 1.87135690, grad/param norm = 2.2304e-01, time/batch = 0.7067s	
2293/22750 (epoch 5.040), train_loss = 1.61934402, grad/param norm = 2.3180e-01, time/batch = 0.7071s	
2294/22750 (epoch 5.042), train_loss = 1.79656532, grad/param norm = 2.1705e-01, time/batch = 0.7105s	
2295/22750 (epoch 5.044), train_loss = 1.60842965, grad/param norm = 2.2008e-01, time/batch = 0.7090s	
2296/22750 (epoch 5.046), train_loss = 1.75492836, grad/param norm = 2.4120e-01, time/batch = 0.6966s	
2297/22750 (epoch 5.048), train_loss = 1.69853175, grad/param norm = 2.3357e-01, time/batch = 0.7028s	
2298/22750 (epoch 5.051), train_loss = 1.75063544, grad/param norm = 2.2519e-01, time/batch = 0.6931s	
2299/22750 (epoch 5.053), train_loss = 1.49391786, grad/param norm = 2.0605e-01, time/batch = 0.6994s	
2300/22750 (epoch 5.055), train_loss = 1.71827522, grad/param norm = 2.2100e-01, time/batch = 0.6991s	
2301/22750 (epoch 5.057), train_loss = 1.78704868, grad/param norm = 2.2417e-01, time/batch = 0.6983s	
2302/22750 (epoch 5.059), train_loss = 1.35986413, grad/param norm = 2.1401e-01, time/batch = 0.6958s	
2303/22750 (epoch 5.062), train_loss = 1.49702845, grad/param norm = 1.9711e-01, time/batch = 0.7007s	
2304/22750 (epoch 5.064), train_loss = 1.77769760, grad/param norm = 2.3960e-01, time/batch = 0.7010s	
2305/22750 (epoch 5.066), train_loss = 1.47218922, grad/param norm = 1.8568e-01, time/batch = 0.6984s	
2306/22750 (epoch 5.068), train_loss = 1.51765387, grad/param norm = 2.0036e-01, time/batch = 0.7026s	
2307/22750 (epoch 5.070), train_loss = 1.42703066, grad/param norm = 1.9182e-01, time/batch = 0.6982s	
2308/22750 (epoch 5.073), train_loss = 1.58365336, grad/param norm = 2.1288e-01, time/batch = 0.6961s	
2309/22750 (epoch 5.075), train_loss = 1.67752727, grad/param norm = 2.1137e-01, time/batch = 0.6974s	
2310/22750 (epoch 5.077), train_loss = 1.31585815, grad/param norm = 2.1074e-01, time/batch = 0.6953s	
2311/22750 (epoch 5.079), train_loss = 1.62708905, grad/param norm = 2.1346e-01, time/batch = 0.7066s	
2312/22750 (epoch 5.081), train_loss = 1.67151750, grad/param norm = 2.1331e-01, time/batch = 0.7043s	
2313/22750 (epoch 5.084), train_loss = 1.55984841, grad/param norm = 2.0814e-01, time/batch = 0.6957s	
2314/22750 (epoch 5.086), train_loss = 1.56317590, grad/param norm = 1.9979e-01, time/batch = 0.7047s	
2315/22750 (epoch 5.088), train_loss = 1.60944407, grad/param norm = 2.0352e-01, time/batch = 0.7083s	
2316/22750 (epoch 5.090), train_loss = 1.61811949, grad/param norm = 2.0289e-01, time/batch = 0.7120s	
2317/22750 (epoch 5.092), train_loss = 1.78748317, grad/param norm = 2.1030e-01, time/batch = 0.7162s	
2318/22750 (epoch 5.095), train_loss = 1.52182251, grad/param norm = 2.0727e-01, time/batch = 0.7136s	
2319/22750 (epoch 5.097), train_loss = 1.59833978, grad/param norm = 2.0473e-01, time/batch = 0.7117s	
2320/22750 (epoch 5.099), train_loss = 1.70620783, grad/param norm = 2.2234e-01, time/batch = 0.7148s	
2321/22750 (epoch 5.101), train_loss = 1.64166969, grad/param norm = 2.0606e-01, time/batch = 0.7091s	
2322/22750 (epoch 5.103), train_loss = 1.60997377, grad/param norm = 2.1910e-01, time/batch = 0.7063s	
2323/22750 (epoch 5.105), train_loss = 1.95391728, grad/param norm = 2.4607e-01, time/batch = 0.7247s	
2324/22750 (epoch 5.108), train_loss = 1.60819831, grad/param norm = 2.0640e-01, time/batch = 0.7246s	
2325/22750 (epoch 5.110), train_loss = 1.68624974, grad/param norm = 2.1922e-01, time/batch = 0.7223s	
2326/22750 (epoch 5.112), train_loss = 1.37544825, grad/param norm = 1.9593e-01, time/batch = 0.7203s	
2327/22750 (epoch 5.114), train_loss = 1.37129260, grad/param norm = 1.9921e-01, time/batch = 0.7499s	
2328/22750 (epoch 5.116), train_loss = 1.47124058, grad/param norm = 1.9928e-01, time/batch = 0.7263s	
2329/22750 (epoch 5.119), train_loss = 1.54657986, grad/param norm = 2.0116e-01, time/batch = 0.7408s	
2330/22750 (epoch 5.121), train_loss = 1.78655355, grad/param norm = 2.2938e-01, time/batch = 0.7276s	
2331/22750 (epoch 5.123), train_loss = 1.57374976, grad/param norm = 1.8644e-01, time/batch = 0.7184s	
2332/22750 (epoch 5.125), train_loss = 1.84180354, grad/param norm = 2.0712e-01, time/batch = 0.7043s	
2333/22750 (epoch 5.127), train_loss = 1.74923744, grad/param norm = 2.3390e-01, time/batch = 0.7284s	
2334/22750 (epoch 5.130), train_loss = 1.71200005, grad/param norm = 2.0589e-01, time/batch = 0.7546s	
2335/22750 (epoch 5.132), train_loss = 1.79298437, grad/param norm = 2.3945e-01, time/batch = 0.7231s	
2336/22750 (epoch 5.134), train_loss = 1.61139534, grad/param norm = 2.1088e-01, time/batch = 0.7421s	
2337/22750 (epoch 5.136), train_loss = 1.51372727, grad/param norm = 2.0218e-01, time/batch = 0.7174s	
2338/22750 (epoch 5.138), train_loss = 1.65174454, grad/param norm = 2.1657e-01, time/batch = 0.7083s	
2339/22750 (epoch 5.141), train_loss = 1.52117047, grad/param norm = 1.9835e-01, time/batch = 0.6975s	
2340/22750 (epoch 5.143), train_loss = 1.47814179, grad/param norm = 1.9737e-01, time/batch = 0.7020s	
2341/22750 (epoch 5.145), train_loss = 1.74358035, grad/param norm = 2.1486e-01, time/batch = 0.7157s	
2342/22750 (epoch 5.147), train_loss = 1.75265347, grad/param norm = 2.1119e-01, time/batch = 0.7007s	
2343/22750 (epoch 5.149), train_loss = 1.65757666, grad/param norm = 2.1240e-01, time/batch = 0.6988s	
2344/22750 (epoch 5.152), train_loss = 1.60056926, grad/param norm = 2.1435e-01, time/batch = 0.6964s	
2345/22750 (epoch 5.154), train_loss = 1.40474088, grad/param norm = 1.9870e-01, time/batch = 0.6977s	
2346/22750 (epoch 5.156), train_loss = 1.52477249, grad/param norm = 2.0764e-01, time/batch = 0.7120s	
2347/22750 (epoch 5.158), train_loss = 1.59894654, grad/param norm = 2.1422e-01, time/batch = 0.7248s	
2348/22750 (epoch 5.160), train_loss = 1.71296922, grad/param norm = 2.2873e-01, time/batch = 0.7210s	
2349/22750 (epoch 5.163), train_loss = 1.89768060, grad/param norm = 2.3239e-01, time/batch = 0.7133s	
2350/22750 (epoch 5.165), train_loss = 1.79674366, grad/param norm = 2.1394e-01, time/batch = 0.7161s	
2351/22750 (epoch 5.167), train_loss = 1.56252939, grad/param norm = 2.0224e-01, time/batch = 0.7221s	
2352/22750 (epoch 5.169), train_loss = 1.70333037, grad/param norm = 2.1201e-01, time/batch = 0.7075s	
2353/22750 (epoch 5.171), train_loss = 1.53872548, grad/param norm = 2.0749e-01, time/batch = 0.7228s	
2354/22750 (epoch 5.174), train_loss = 1.38331421, grad/param norm = 1.8808e-01, time/batch = 0.7242s	
2355/22750 (epoch 5.176), train_loss = 1.67246263, grad/param norm = 1.9075e-01, time/batch = 0.7051s	
2356/22750 (epoch 5.178), train_loss = 1.59422940, grad/param norm = 1.9437e-01, time/batch = 0.7171s	
2357/22750 (epoch 5.180), train_loss = 1.78470574, grad/param norm = 2.4787e-01, time/batch = 0.7195s	
2358/22750 (epoch 5.182), train_loss = 1.69995366, grad/param norm = 1.8984e-01, time/batch = 0.7003s	
2359/22750 (epoch 5.185), train_loss = 1.71835103, grad/param norm = 2.1150e-01, time/batch = 0.7079s	
2360/22750 (epoch 5.187), train_loss = 1.50770732, grad/param norm = 2.0240e-01, time/batch = 0.7275s	
2361/22750 (epoch 5.189), train_loss = 1.54136368, grad/param norm = 2.0138e-01, time/batch = 0.7180s	
2362/22750 (epoch 5.191), train_loss = 1.48437071, grad/param norm = 1.9834e-01, time/batch = 0.7139s	
2363/22750 (epoch 5.193), train_loss = 1.73048680, grad/param norm = 2.1701e-01, time/batch = 0.6961s	
2364/22750 (epoch 5.196), train_loss = 1.64077180, grad/param norm = 2.0727e-01, time/batch = 0.6978s	
2365/22750 (epoch 5.198), train_loss = 1.37579820, grad/param norm = 1.8045e-01, time/batch = 0.6937s	
2366/22750 (epoch 5.200), train_loss = 1.69988126, grad/param norm = 2.0081e-01, time/batch = 0.7010s	
2367/22750 (epoch 5.202), train_loss = 1.90178035, grad/param norm = 2.3644e-01, time/batch = 0.7119s	
2368/22750 (epoch 5.204), train_loss = 1.81508053, grad/param norm = 2.1277e-01, time/batch = 0.6998s	
2369/22750 (epoch 5.207), train_loss = 1.61437951, grad/param norm = 2.2254e-01, time/batch = 0.6946s	
2370/22750 (epoch 5.209), train_loss = 1.53494678, grad/param norm = 2.1020e-01, time/batch = 0.6991s	
2371/22750 (epoch 5.211), train_loss = 1.64799473, grad/param norm = 2.2044e-01, time/batch = 0.6926s	
2372/22750 (epoch 5.213), train_loss = 1.50913651, grad/param norm = 2.0232e-01, time/batch = 0.7007s	
2373/22750 (epoch 5.215), train_loss = 1.54934140, grad/param norm = 2.1246e-01, time/batch = 0.7173s	
2374/22750 (epoch 5.218), train_loss = 1.44321235, grad/param norm = 2.2469e-01, time/batch = 0.7183s	
2375/22750 (epoch 5.220), train_loss = 1.66787820, grad/param norm = 2.5325e-01, time/batch = 0.7095s	
2376/22750 (epoch 5.222), train_loss = 1.47135006, grad/param norm = 2.2499e-01, time/batch = 0.6980s	
2377/22750 (epoch 5.224), train_loss = 1.55776339, grad/param norm = 2.0277e-01, time/batch = 0.7179s	
2378/22750 (epoch 5.226), train_loss = 1.70062551, grad/param norm = 2.2632e-01, time/batch = 0.7061s	
2379/22750 (epoch 5.229), train_loss = 1.71677206, grad/param norm = 2.1488e-01, time/batch = 0.7090s	
2380/22750 (epoch 5.231), train_loss = 1.60193574, grad/param norm = 1.9954e-01, time/batch = 0.7053s	
2381/22750 (epoch 5.233), train_loss = 1.53127702, grad/param norm = 1.9611e-01, time/batch = 0.7095s	
2382/22750 (epoch 5.235), train_loss = 1.49710760, grad/param norm = 2.0415e-01, time/batch = 0.6908s	
2383/22750 (epoch 5.237), train_loss = 1.56549739, grad/param norm = 2.1089e-01, time/batch = 0.6894s	
2384/22750 (epoch 5.240), train_loss = 1.75482349, grad/param norm = 1.9402e-01, time/batch = 0.6974s	
2385/22750 (epoch 5.242), train_loss = 2.07293022, grad/param norm = 2.4178e-01, time/batch = 0.6945s	
2386/22750 (epoch 5.244), train_loss = 1.86858825, grad/param norm = 2.6329e-01, time/batch = 0.6951s	
2387/22750 (epoch 5.246), train_loss = 1.93349745, grad/param norm = 2.0413e-01, time/batch = 0.6958s	
2388/22750 (epoch 5.248), train_loss = 1.62340169, grad/param norm = 2.2450e-01, time/batch = 0.6975s	
2389/22750 (epoch 5.251), train_loss = 1.88354766, grad/param norm = 2.1259e-01, time/batch = 0.6961s	
2390/22750 (epoch 5.253), train_loss = 1.70372675, grad/param norm = 1.9802e-01, time/batch = 0.7245s	
2391/22750 (epoch 5.255), train_loss = 1.72570645, grad/param norm = 2.0515e-01, time/batch = 0.6986s	
2392/22750 (epoch 5.257), train_loss = 1.64291327, grad/param norm = 2.1380e-01, time/batch = 0.6971s	
2393/22750 (epoch 5.259), train_loss = 1.82113683, grad/param norm = 2.3934e-01, time/batch = 0.6957s	
2394/22750 (epoch 5.262), train_loss = 1.66766960, grad/param norm = 2.1994e-01, time/batch = 0.6976s	
2395/22750 (epoch 5.264), train_loss = 1.57844570, grad/param norm = 2.0854e-01, time/batch = 0.7230s	
2396/22750 (epoch 5.266), train_loss = 1.64556682, grad/param norm = 2.1875e-01, time/batch = 0.7244s	
2397/22750 (epoch 5.268), train_loss = 1.76688095, grad/param norm = 2.0725e-01, time/batch = 0.7275s	
2398/22750 (epoch 5.270), train_loss = 1.56744661, grad/param norm = 2.1402e-01, time/batch = 0.7279s	
2399/22750 (epoch 5.273), train_loss = 1.90658007, grad/param norm = 2.4367e-01, time/batch = 0.7094s	
2400/22750 (epoch 5.275), train_loss = 1.67510966, grad/param norm = 2.1394e-01, time/batch = 0.6955s	
2401/22750 (epoch 5.277), train_loss = 1.69637429, grad/param norm = 2.1378e-01, time/batch = 0.7027s	
2402/22750 (epoch 5.279), train_loss = 1.45849522, grad/param norm = 1.8507e-01, time/batch = 0.6955s	
2403/22750 (epoch 5.281), train_loss = 1.68004268, grad/param norm = 2.0807e-01, time/batch = 0.6922s	
2404/22750 (epoch 5.284), train_loss = 1.54178424, grad/param norm = 1.8434e-01, time/batch = 0.6939s	
2405/22750 (epoch 5.286), train_loss = 1.74500864, grad/param norm = 2.1281e-01, time/batch = 0.6917s	
2406/22750 (epoch 5.288), train_loss = 1.82068816, grad/param norm = 2.0608e-01, time/batch = 0.6931s	
2407/22750 (epoch 5.290), train_loss = 1.54224621, grad/param norm = 1.9383e-01, time/batch = 0.6989s	
2408/22750 (epoch 5.292), train_loss = 1.63999934, grad/param norm = 2.2078e-01, time/batch = 0.6938s	
2409/22750 (epoch 5.295), train_loss = 1.65085164, grad/param norm = 1.9075e-01, time/batch = 0.6939s	
2410/22750 (epoch 5.297), train_loss = 1.58272493, grad/param norm = 2.0067e-01, time/batch = 0.7263s	
2411/22750 (epoch 5.299), train_loss = 1.79806858, grad/param norm = 2.0841e-01, time/batch = 0.7260s	
2412/22750 (epoch 5.301), train_loss = 1.71629488, grad/param norm = 2.0348e-01, time/batch = 0.7218s	
2413/22750 (epoch 5.303), train_loss = 1.80130022, grad/param norm = 2.3095e-01, time/batch = 0.6992s	
2414/22750 (epoch 5.305), train_loss = 1.83411216, grad/param norm = 2.1368e-01, time/batch = 0.6953s	
2415/22750 (epoch 5.308), train_loss = 1.70893504, grad/param norm = 2.0637e-01, time/batch = 0.6929s	
2416/22750 (epoch 5.310), train_loss = 1.62357205, grad/param norm = 2.1965e-01, time/batch = 0.6946s	
2417/22750 (epoch 5.312), train_loss = 1.66985923, grad/param norm = 2.0920e-01, time/batch = 0.7021s	
2418/22750 (epoch 5.314), train_loss = 1.63364753, grad/param norm = 2.0167e-01, time/batch = 0.7073s	
2419/22750 (epoch 5.316), train_loss = 1.58754109, grad/param norm = 1.9229e-01, time/batch = 0.6962s	
2420/22750 (epoch 5.319), train_loss = 1.71281412, grad/param norm = 1.9580e-01, time/batch = 0.6977s	
2421/22750 (epoch 5.321), train_loss = 1.62639515, grad/param norm = 2.2270e-01, time/batch = 0.7059s	
2422/22750 (epoch 5.323), train_loss = 1.59409934, grad/param norm = 2.2250e-01, time/batch = 0.7217s	
2423/22750 (epoch 5.325), train_loss = 1.35760884, grad/param norm = 2.0640e-01, time/batch = 0.7078s	
2424/22750 (epoch 5.327), train_loss = 1.69555607, grad/param norm = 2.1640e-01, time/batch = 0.6910s	
2425/22750 (epoch 5.330), train_loss = 1.95287766, grad/param norm = 2.1566e-01, time/batch = 0.6889s	
2426/22750 (epoch 5.332), train_loss = 1.73932344, grad/param norm = 2.0071e-01, time/batch = 0.6971s	
2427/22750 (epoch 5.334), train_loss = 1.37567542, grad/param norm = 1.8938e-01, time/batch = 0.6923s	
2428/22750 (epoch 5.336), train_loss = 1.70523786, grad/param norm = 1.9722e-01, time/batch = 0.6928s	
2429/22750 (epoch 5.338), train_loss = 1.64804968, grad/param norm = 2.0632e-01, time/batch = 0.6902s	
2430/22750 (epoch 5.341), train_loss = 1.60607122, grad/param norm = 2.0828e-01, time/batch = 0.6949s	
2431/22750 (epoch 5.343), train_loss = 1.46586752, grad/param norm = 2.0686e-01, time/batch = 0.7191s	
2432/22750 (epoch 5.345), train_loss = 1.81854372, grad/param norm = 2.3288e-01, time/batch = 0.7251s	
2433/22750 (epoch 5.347), train_loss = 1.77876960, grad/param norm = 2.1770e-01, time/batch = 0.7107s	
2434/22750 (epoch 5.349), train_loss = 1.35414815, grad/param norm = 2.1709e-01, time/batch = 0.7050s	
2435/22750 (epoch 5.352), train_loss = 1.74933363, grad/param norm = 2.2497e-01, time/batch = 0.7014s	
2436/22750 (epoch 5.354), train_loss = 1.85538504, grad/param norm = 2.2254e-01, time/batch = 0.7054s	
2437/22750 (epoch 5.356), train_loss = 1.84328512, grad/param norm = 1.9996e-01, time/batch = 0.7110s	
2438/22750 (epoch 5.358), train_loss = 1.61954993, grad/param norm = 2.1949e-01, time/batch = 0.6956s	
2439/22750 (epoch 5.360), train_loss = 1.88160499, grad/param norm = 2.2948e-01, time/batch = 0.6958s	
2440/22750 (epoch 5.363), train_loss = 1.63819025, grad/param norm = 2.0286e-01, time/batch = 0.6941s	
2441/22750 (epoch 5.365), train_loss = 1.39779144, grad/param norm = 2.0897e-01, time/batch = 0.7042s	
2442/22750 (epoch 5.367), train_loss = 1.37549610, grad/param norm = 1.8460e-01, time/batch = 0.7045s	
2443/22750 (epoch 5.369), train_loss = 1.60050379, grad/param norm = 2.3324e-01, time/batch = 0.7049s	
2444/22750 (epoch 5.371), train_loss = 1.57258452, grad/param norm = 2.1573e-01, time/batch = 0.7262s	
2445/22750 (epoch 5.374), train_loss = 1.46327076, grad/param norm = 2.3374e-01, time/batch = 0.7210s	
2446/22750 (epoch 5.376), train_loss = 1.68546986, grad/param norm = 2.0684e-01, time/batch = 0.7081s	
2447/22750 (epoch 5.378), train_loss = 1.58252986, grad/param norm = 2.0358e-01, time/batch = 0.6892s	
2448/22750 (epoch 5.380), train_loss = 1.77804693, grad/param norm = 2.1385e-01, time/batch = 0.6909s	
2449/22750 (epoch 5.382), train_loss = 1.54596117, grad/param norm = 1.9578e-01, time/batch = 0.6898s	
2450/22750 (epoch 5.385), train_loss = 1.67394375, grad/param norm = 1.8401e-01, time/batch = 0.6912s	
2451/22750 (epoch 5.387), train_loss = 1.72409359, grad/param norm = 2.0535e-01, time/batch = 0.7064s	
2452/22750 (epoch 5.389), train_loss = 1.27306938, grad/param norm = 2.1118e-01, time/batch = 0.6946s	
2453/22750 (epoch 5.391), train_loss = 1.10236469, grad/param norm = 1.7550e-01, time/batch = 0.7171s	
2454/22750 (epoch 5.393), train_loss = 1.44230513, grad/param norm = 1.9554e-01, time/batch = 0.7265s	
2455/22750 (epoch 5.396), train_loss = 1.62418122, grad/param norm = 2.2086e-01, time/batch = 0.7236s	
2456/22750 (epoch 5.398), train_loss = 1.61273003, grad/param norm = 2.1480e-01, time/batch = 0.7371s	
2457/22750 (epoch 5.400), train_loss = 1.60909751, grad/param norm = 1.9943e-01, time/batch = 0.7352s	
2458/22750 (epoch 5.402), train_loss = 1.63822780, grad/param norm = 2.0116e-01, time/batch = 0.7202s	
2459/22750 (epoch 5.404), train_loss = 1.86534315, grad/param norm = 2.2242e-01, time/batch = 0.7200s	
2460/22750 (epoch 5.407), train_loss = 1.73297050, grad/param norm = 1.9891e-01, time/batch = 0.7051s	
2461/22750 (epoch 5.409), train_loss = 1.63011402, grad/param norm = 2.1023e-01, time/batch = 0.6984s	
2462/22750 (epoch 5.411), train_loss = 1.63770987, grad/param norm = 1.9587e-01, time/batch = 0.7121s	
2463/22750 (epoch 5.413), train_loss = 1.50620830, grad/param norm = 2.1545e-01, time/batch = 0.7099s	
2464/22750 (epoch 5.415), train_loss = 1.39795135, grad/param norm = 2.2262e-01, time/batch = 0.7015s	
2465/22750 (epoch 5.418), train_loss = 1.58441671, grad/param norm = 2.0654e-01, time/batch = 0.6965s	
2466/22750 (epoch 5.420), train_loss = 1.88175022, grad/param norm = 2.3225e-01, time/batch = 0.7162s	
2467/22750 (epoch 5.422), train_loss = 1.95494785, grad/param norm = 2.2924e-01, time/batch = 0.6985s	
2468/22750 (epoch 5.424), train_loss = 1.95367814, grad/param norm = 2.3935e-01, time/batch = 0.6993s	
2469/22750 (epoch 5.426), train_loss = 1.90124525, grad/param norm = 1.9763e-01, time/batch = 0.6987s	
2470/22750 (epoch 5.429), train_loss = 1.38925322, grad/param norm = 1.9967e-01, time/batch = 0.6989s	
2471/22750 (epoch 5.431), train_loss = 1.38196736, grad/param norm = 1.9218e-01, time/batch = 0.6941s	
2472/22750 (epoch 5.433), train_loss = 1.47089216, grad/param norm = 1.8678e-01, time/batch = 0.6976s	
2473/22750 (epoch 5.435), train_loss = 1.36336820, grad/param norm = 2.0581e-01, time/batch = 0.7027s	
2474/22750 (epoch 5.437), train_loss = 1.30105220, grad/param norm = 1.9407e-01, time/batch = 0.6995s	
2475/22750 (epoch 5.440), train_loss = 1.80470843, grad/param norm = 2.2444e-01, time/batch = 0.6991s	
2476/22750 (epoch 5.442), train_loss = 1.62899786, grad/param norm = 2.1356e-01, time/batch = 0.6989s	
2477/22750 (epoch 5.444), train_loss = 1.70086773, grad/param norm = 2.8636e-01, time/batch = 0.6998s	
2478/22750 (epoch 5.446), train_loss = 1.65512168, grad/param norm = 2.3971e-01, time/batch = 0.6980s	
2479/22750 (epoch 5.448), train_loss = 1.92313822, grad/param norm = 2.3238e-01, time/batch = 0.6951s	
2480/22750 (epoch 5.451), train_loss = 1.83335917, grad/param norm = 2.3444e-01, time/batch = 0.7064s	
2481/22750 (epoch 5.453), train_loss = 1.94812509, grad/param norm = 2.6902e-01, time/batch = 0.7057s	
2482/22750 (epoch 5.455), train_loss = 1.97790092, grad/param norm = 2.1267e-01, time/batch = 0.7199s	
2483/22750 (epoch 5.457), train_loss = 1.81783972, grad/param norm = 2.4599e-01, time/batch = 0.7274s	
2484/22750 (epoch 5.459), train_loss = 1.69355315, grad/param norm = 1.9998e-01, time/batch = 0.7217s	
2485/22750 (epoch 5.462), train_loss = 1.67735811, grad/param norm = 1.7857e-01, time/batch = 0.7096s	
2486/22750 (epoch 5.464), train_loss = 1.48286719, grad/param norm = 1.9333e-01, time/batch = 0.7143s	
2487/22750 (epoch 5.466), train_loss = 1.90833718, grad/param norm = 2.2193e-01, time/batch = 0.7106s	
2488/22750 (epoch 5.468), train_loss = 1.60915155, grad/param norm = 2.1597e-01, time/batch = 0.7118s	
2489/22750 (epoch 5.470), train_loss = 1.83667679, grad/param norm = 2.3406e-01, time/batch = 0.7098s	
2490/22750 (epoch 5.473), train_loss = 1.66423071, grad/param norm = 2.2447e-01, time/batch = 0.7081s	
2491/22750 (epoch 5.475), train_loss = 1.72671954, grad/param norm = 2.0493e-01, time/batch = 0.7130s	
2492/22750 (epoch 5.477), train_loss = 1.44725760, grad/param norm = 1.9425e-01, time/batch = 0.7059s	
2493/22750 (epoch 5.479), train_loss = 1.49446453, grad/param norm = 1.8409e-01, time/batch = 0.7106s	
2494/22750 (epoch 5.481), train_loss = 1.45644855, grad/param norm = 2.0904e-01, time/batch = 0.7086s	
2495/22750 (epoch 5.484), train_loss = 1.26958066, grad/param norm = 2.0290e-01, time/batch = 0.7175s	
2496/22750 (epoch 5.486), train_loss = 1.53705557, grad/param norm = 2.3094e-01, time/batch = 0.7000s	
2497/22750 (epoch 5.488), train_loss = 1.26544300, grad/param norm = 2.3153e-01, time/batch = 0.6963s	
2498/22750 (epoch 5.490), train_loss = 1.51468014, grad/param norm = 2.0737e-01, time/batch = 0.6919s	
2499/22750 (epoch 5.492), train_loss = 1.79869356, grad/param norm = 2.4537e-01, time/batch = 0.6999s	
2500/22750 (epoch 5.495), train_loss = 1.55139782, grad/param norm = 2.3075e-01, time/batch = 0.6954s	
2501/22750 (epoch 5.497), train_loss = 1.73206544, grad/param norm = 2.2320e-01, time/batch = 0.7003s	
2502/22750 (epoch 5.499), train_loss = 1.59815438, grad/param norm = 2.0949e-01, time/batch = 0.6961s	
2503/22750 (epoch 5.501), train_loss = 1.65361707, grad/param norm = 2.0684e-01, time/batch = 0.6996s	
2504/22750 (epoch 5.503), train_loss = 1.62209286, grad/param norm = 2.0955e-01, time/batch = 0.6955s	
2505/22750 (epoch 5.505), train_loss = 1.46038570, grad/param norm = 1.9072e-01, time/batch = 0.6967s	
2506/22750 (epoch 5.508), train_loss = 1.42258571, grad/param norm = 2.1697e-01, time/batch = 0.7011s	
2507/22750 (epoch 5.510), train_loss = 1.43467833, grad/param norm = 1.8589e-01, time/batch = 0.7024s	
2508/22750 (epoch 5.512), train_loss = 1.51943841, grad/param norm = 1.9152e-01, time/batch = 0.6931s	
2509/22750 (epoch 5.514), train_loss = 1.52067585, grad/param norm = 1.9203e-01, time/batch = 0.6926s	
2510/22750 (epoch 5.516), train_loss = 1.46083684, grad/param norm = 1.9888e-01, time/batch = 0.6976s	
2511/22750 (epoch 5.519), train_loss = 1.66392185, grad/param norm = 2.3393e-01, time/batch = 0.7048s	
2512/22750 (epoch 5.521), train_loss = 1.49558516, grad/param norm = 2.3384e-01, time/batch = 0.7004s	
2513/22750 (epoch 5.523), train_loss = 1.55073962, grad/param norm = 2.4982e-01, time/batch = 0.7029s	
2514/22750 (epoch 5.525), train_loss = 1.78957067, grad/param norm = 2.3000e-01, time/batch = 0.7066s	
2515/22750 (epoch 5.527), train_loss = 1.63288334, grad/param norm = 2.1038e-01, time/batch = 0.7044s	
2516/22750 (epoch 5.530), train_loss = 1.49339629, grad/param norm = 2.1777e-01, time/batch = 0.7221s	
2517/22750 (epoch 5.532), train_loss = 1.50534293, grad/param norm = 1.9086e-01, time/batch = 1.1423s	
2518/22750 (epoch 5.534), train_loss = 1.76065580, grad/param norm = 2.3823e-01, time/batch = 1.2195s	
2519/22750 (epoch 5.536), train_loss = 1.61082669, grad/param norm = 1.9954e-01, time/batch = 0.7120s	
2520/22750 (epoch 5.538), train_loss = 1.65673993, grad/param norm = 1.8325e-01, time/batch = 0.6849s	
2521/22750 (epoch 5.541), train_loss = 1.36605041, grad/param norm = 2.0153e-01, time/batch = 0.6959s	
2522/22750 (epoch 5.543), train_loss = 1.38013171, grad/param norm = 1.8777e-01, time/batch = 0.6889s	
